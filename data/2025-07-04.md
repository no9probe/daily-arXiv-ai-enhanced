<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 26]
- [cs.CV](#cs.CV) [Total: 83]
- [cs.AI](#cs.AI) [Total: 31]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 2]
- [cs.RO](#cs.RO) [Total: 4]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 3]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.LO](#cs.LO) [Total: 1]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.LG](#cs.LG) [Total: 21]
- [eess.SP](#eess.SP) [Total: 1]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2507.02088)
**中文标题：McBE：一个面向大型语言模型的多任务中文偏见评估基准**

*Tian Lan,Xiangdong Su,Xu Liu,Ruirui Wang,Ke Chang,Jiang Li,Guanglai Gao*

主要分类: cs.CL

摘要简述: 本文提出了一个多任务中文偏见评估基准（McBE），包含4077个偏见评估实例，覆盖12个单一偏见类别和82个子类别，并引入5个评估任务，以全面衡量大型语言模型（LLMs）的偏见。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在多种NLP任务中的应用增加，其内在偏见逐渐显现。现有偏见评估数据集多集中于英语和北美文化，且类别不完全适用于其他文化，尤其是中文和文化背景的数据集稀缺。此外，这些数据集通常仅支持单一评估任务，无法从多角度评估LLMs的偏见。

研究方法: 本文提出了McBE基准，包含4077个偏见评估实例，覆盖12个单一偏见类别和82个子类别，并引入5个评估任务。此外，评估了多个不同系列和参数规模的流行LLMs。

研究结果: 评估结果显示，所有LLMs均表现出不同程度的偏见。通过深入分析结果，提供了关于LLMs偏见的新见解。

研究结论: McBE基准提供了广泛的类别覆盖、内容多样性和测量全面性，填补了中文偏见评估数据集的空白，并为LLMs的偏见研究提供了新视角。

中文摘要: 随着大型语言模型（LLMs）在多种NLP任务中的应用增加，其内在偏见逐渐显现。因此，测量LLMs的偏见对降低其伦理风险至关重要。然而，现有偏见评估数据集多集中于英语和北美文化，其偏见类别不完全适用于其他文化。基于中文和文化背景的数据集稀缺。更重要的是，这些数据集通常仅支持单一评估任务，无法从多角度评估LLMs的偏见。为解决这些问题，我们提出了一个多任务中文偏见评估基准（McBE），包含4077个偏见评估实例，覆盖12个单一偏见类别、82个子类别，并引入5个评估任务，提供了广泛的类别覆盖、内容多样性和测量全面性。此外，我们评估了多个不同系列和参数规模的流行LLMs。总体而言，这些LLMs均表现出不同程度的偏见。我们对结果进行了深入分析，为LLMs的偏见研究提供了新见解。

</details>


### [2] [Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization](https://arxiv.org/abs/2507.02145)
**中文标题：推理与否？对话摘要中推理型大语言模型的全面评估**

*Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira*

主要分类: cs.CL

摘要简述: 本文首次全面评估了推理型与非推理型大语言模型（LLM）在对话摘要任务中的表现，发现推理型LLM并未显著提升摘要质量，反而容易产生冗长和不一致的问题。


<details>
  <summary>详细信息</summary>
研究动机: 对话摘要在客户服务、会议分析和对话AI中具有重要价值，但推理型LLM（如链式思维架构）在此任务中的表现尚未被系统研究。本文旨在填补这一空白。

研究方法: 研究对比了推理型与非推理型LLM在三种对话摘要范式（通用、角色导向和查询导向）中的表现，涵盖多语言、多领域和不同摘要长度，并采用自动指标和人工评估标准。

研究结果: 研究发现，推理型LLM在对话摘要中并未表现出优势，反而容易生成冗长、事实不一致且不够简洁的摘要，与非推理型LLM相比表现较差。

研究结论: 当前推理型LLM在对话摘要任务中存在局限性，需针对实际应用场景优化模型和评估策略。

中文摘要: 对话摘要是一项具有重要实际价值的挑战性任务，涉及客户服务、会议分析和对话AI等领域。尽管大语言模型（LLM）在摘要任务中取得了显著进展，但对于需要同时满足抽象性和简洁性的对话场景，逐步推理架构（如链式思维实现）的表现尚未被探索。本研究首次对最先进的推理型与非推理型LLM在三种主要范式（通用、角色导向和查询导向对话摘要）中进行了全面系统评估。研究涵盖多种语言、领域和摘要长度，并利用强基准（SAMSum、DialogSum、CSDS和QMSum）和先进的评估协议（包括基于LLM的自动指标和人工启发标准）。与其他推理密集型任务不同，我们的发现表明，逐步显式推理并未持续提升对话摘要质量。相反，推理型LLM往往容易产生冗长、事实不一致且不够简洁的摘要。通过场景特定分析和详细案例研究，我们进一步明确了显式推理在复杂对话场景中何时以及为何无法受益甚至阻碍摘要生成。本研究揭示了当前推理型LLM的局限性，并强调了针对实际对话摘要任务的针对性建模和评估策略的必要性。

</details>


### [3] [Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer](https://arxiv.org/abs/2507.02199)
**中文标题：潜在思维链？解码深度循环Transformer**

*Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu*

主要分类: cs.CL

摘要简述: 本文研究了深度循环Transformer模型Huginn-3.5B是否在潜在空间中形成类似思维链（CoT）的推理结构。通过多种探测技术，发现模型内部行为中可解释的潜在CoT证据有限，且不同循环块的探测结果不一致。增加循环深度仅带来边际收益，远不及显式外部化推理步骤的模型。


<details>
  <summary>详细信息</summary>
研究动机: 思维链（CoT）推理使Transformer模型在复杂数学和多步规划任务中表现出色，但其推理步骤通常以自然语言外部化，牺牲了效率。本文旨在探索深度循环Transformer是否能在潜在空间中实现类似CoT的推理，从而兼顾效率与表达能力。

研究方法: 研究使用Huginn-3.5B模型，通过Logit Lens和Coda Lens等探测技术，分析其在算术任务中的内部行为，追踪最终和中间结果标记的排名轨迹，并评估不同循环块的探测一致性。

研究结果: 研究发现，模型内部可解释的潜在CoT证据有限，且不同循环块的隐藏状态可解释性差异显著。增加循环深度仅带来边际性能提升，远不及显式外部化推理步骤的模型。

研究结论: 深度循环Transformer在潜在空间中形成类似CoT的推理结构的能力有限，且探测结果高度依赖层索引和解码方法。显式外部化推理步骤的模型仍更具优势。

中文摘要: 思维链（CoT）推理使基于Transformer的语言模型在复杂数学和多步规划任务中表现卓越。然而，在标准的仅解码器架构中，这些推理步骤以自然语言外部化，虽提高了可解释性，却牺牲了效率。为捕捉难以用语言表达的推理过程，许多研究探索了旨在将推理内部化于潜在空间的循环架构，可能支持潜在CoT。本文研究了此类推理结构是否在Huginn-3.5B（一种在推理时重复使用层而不增加参数数量的深度循环Transformer）中显现。通过Logit Lens和Coda Lens等探测技术，我们分析了模型在算术任务中的内部行为。结果显示，通过追踪最终和中间结果标记的排名轨迹，可解释的潜在CoT证据有限。此外，我们发现不同循环块的探测结果存在显著不一致性，隐藏状态的可解释性高度依赖层索引和解码方法。最后，实验表明增加循环深度仅带来边际收益，远不及显式外部化推理步骤的模型。代码见https://github.com/wenquanlu/huginn-latent-cot。

</details>


### [4] [GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons](https://arxiv.org/abs/2507.02221)
**中文标题：GDC Cohort Copilot：一个用于从基因组数据共享中筛选队列的 AI 助手**

*Steven Song,Anirudh Subramanyam,Zhenyu Zhang,Aarti Venkat,Robert L. Grossman*

主要分类: cs.CL

摘要简述: GDC Cohort Copilot 是一个开源工具，通过自然语言描述自动生成 GDC 队列过滤器，帮助用户更轻松地创建和分析癌症基因组学队列。


<details>
  <summary>详细信息</summary>
研究动机: Genomic Data Commons (GDC) 提供了高质量的癌症基因组学数据，但用户（尤其是新手）在通过图形界面创建复杂队列时可能会遇到困难。用户更倾向于用自然语言描述所需队列，因此需要一种工具将自然语言转换为 GDC 队列过滤器。

研究方法: 开发了 GDC Cohort Copilot，利用大型语言模型（LLMs）将用户的自然语言描述自动转换为 GDC 队列过滤器，并提供交互式界面供用户进一步调整。

研究结果: GDC Cohort Copilot 的开源本地模型在生成 GDC 队列时表现优于 GPT-4o，工具已通过 Docker 镜像和开源代码实现。

研究结论: GDC Cohort Copilot 显著简化了队列创建流程，提升了用户体验，为癌症基因组学研究提供了高效工具。

中文摘要: 动机：Genomic Data Commons (GDC) 通过统一的平台提供高质量的癌症基因组学数据，用户可以通过图形界面创建复杂队列，但新手可能难以在数百个字段中找到特定描述符。用户更倾向于用自然语言描述所需队列。

结果：我们推出了 GDC Cohort Copilot，一个开源工具，可将用户的自然语言描述自动转换为 GDC 队列过滤器，并导出队列供进一步分析。交互式界面允许用户调整生成的队列。我们开发并评估了多种大型语言模型（LLMs），发现本地部署的开源 GDC Cohort LLM 在生成队列时优于 GPT-4o。

可用性与实现：GDC Cohort Copilot 的 Docker 镜像可在 https://quay.io/repository/cdis/gdc-cohort-copilot 获取，源代码位于 https://github.com/uc-cdis/gdc-cohort-copilot，GDC Cohort LLM 权重可在 https://huggingface.co/uc-ctds 下载。

</details>


### [5] [MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent](https://arxiv.org/abs/2507.02259)
**中文标题：MemAgent：基于多对话强化学习的记忆代理重塑长上下文LLM**

*Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MemAgent的新型代理工作流程，通过分段读取文本并采用覆盖策略更新记忆，解决了长文本处理中的性能退化问题。MemAgent在32K文本训练基础上，成功扩展到3.5M QA任务，性能损失低于5%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管通过长度外推、高效注意力和记忆模块改进了长文本处理，但在线性复杂度下处理无限长文档且不出现性能退化仍是终极挑战。本文旨在通过端到端优化长文本任务，提出一种新型代理工作流程。

研究方法: 本文提出MemAgent，采用分段读取文本和覆盖策略更新记忆的方法。通过扩展DAPO算法，利用独立上下文多对话生成进行训练。

研究结果: MemAgent展示了卓越的长上下文能力，从8K上下文训练扩展到32K文本，并在3.5M QA任务中性能损失低于5%，在512K RULER测试中达到95%以上。

研究结论: MemAgent通过创新的代理工作流程和覆盖策略，成功解决了长文本处理中的性能退化问题，为长上下文任务提供了高效解决方案。

中文摘要: 尽管通过长度外推、高效注意力和记忆模块进行了改进，但在线性复杂度下处理无限长文档且不出现性能退化仍是长文本处理的终极挑战。我们通过端到端优化长文本任务，提出了一种新型代理工作流程MemAgent，其通过分段读取文本并采用覆盖策略更新记忆。我们扩展了DAPO算法，通过独立上下文多对话生成促进训练。MemAgent展示了卓越的长上下文能力，从8K上下文训练扩展到32K文本，并在3.5M QA任务中性能损失低于5%，在512K RULER测试中达到95%以上。

</details>


### [6] [DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning](https://arxiv.org/abs/2507.02302)
**中文标题：DoMIX：一种利用领域知识进行高效微调的框架**

*Dohoon Kim,Donghun Kang,Taesup Moon*

主要分类: cs.CL

摘要简述: 本文提出DoMIX框架，通过LoRA模块高效解决持续领域自适应预训练中的计算成本高、数据顺序敏感和单一模型通用性问题，为特定任务提供定制化预训练模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有持续领域自适应预训练（DAP）方法存在计算成本高、对增量数据顺序敏感且仅提供单一通用模型的问题，无法满足DAP的本质需求。本文旨在解决这些问题。

研究方法: DoMIX利用LoRA模块（一种参数高效微调方法），实现高效且并行的领域自适应预训练，对领域顺序鲁棒，并能利用累积知识为特定任务提供定制化模型。

研究结果: 实验表明，DoMIX不仅适用于DAP场景，还可扩展至标准大语言模型微调，显著提升了效率和适应性。

研究结论: DoMIX通过LoRA模块解决了持续DAP的三大挑战，为任务定制化预训练提供了高效且灵活的解决方案。

中文摘要: 领域自适应预训练（DAP）因其在微调预训练模型中的有效性而受到关注。在此基础上，持续DAP被探索用于开发能够逐步整合不同领域数据集的预训练模型。然而，现有持续DAP方法存在以下局限性：（1）训练时计算成本和GPU内存占用高；（2）对增量数据顺序敏感；（3）为所有终端任务提供单一通用模型，这与DAP的本质相矛盾。本文提出DoMIX，通过利用LoRA模块（一种代表性参数高效微调方法）解决这些挑战。我们的方法实现了高效且并行的领域自适应预训练，对领域顺序鲁棒，并能有效利用累积知识为特定任务提供定制化预训练模型。我们还证明该方法可扩展至标准大语言模型微调场景。代码见https://github.com/dohoonkim-ai/DoMIX。

</details>


### [7] [Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models](https://arxiv.org/abs/2507.02357)
**中文标题：Coling-UniA在SciVQA 2025的任务：基于少样本检索和置信度集成的多模态大语言模型**

*Christian Jaumann,Annemarie Friedrich,Rainer Lienhart*

主要分类: cs.CL

摘要简述: 本文介绍了参加SciVQA 2025共享任务的系统，结合多模态大语言模型和少样本检索策略，根据图像和问题类型选择模型和设置，并基于模型置信度选择答案，最终在盲测数据中排名第三。


<details>
  <summary>详细信息</summary>
研究动机: SciVQA 2025共享任务旨在解决科学视觉问答问题，本文希望通过结合多模态大语言模型和少样本检索策略，提升模型在复杂科学问题中的表现。

研究方法: 系统采用两种多模态大语言模型的集成方法，并结合多种少样本检索策略，根据图像和问题类型动态选择模型和设置，同时基于模型置信度筛选答案。

研究结果: 在盲测数据中，系统在七支队伍中排名第三，平均F1得分为85.12（基于ROUGE-1、ROUGE-L和BERTS指标）。

研究结论: 通过集成多模态大语言模型和少样本检索策略，并结合置信度筛选，系统在科学视觉问答任务中取得了显著效果，代码已公开。

中文摘要: 本文介绍了我们为SciVQA 2025共享任务开发的科学视觉问答系统。该系统集成了两种多模态大语言模型和多种少样本检索策略，并根据图像和问题类型选择模型和设置。答案的选择基于模型的置信度。在盲测数据中，我们的系统在七支队伍中排名第三，平均F1得分为85.12（基于ROUGE-1、ROUGE-L和BERTS指标）。代码已公开。

</details>


### [8] [QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers](https://arxiv.org/abs/2507.02364)
**中文标题：QFFN-BERT：混合量子-经典Transformer中深度、性能与数据效率的实证研究**

*Pilsung Kang*

主要分类: cs.CL

摘要简述: 本文提出QFFN-BERT，一种混合量子-经典Transformer模型，通过用参数化量子电路（PQC）替换BERT中的前馈网络（FFN）模块，显著减少参数数量并提升性能。实验表明，该模型在完整数据集和少样本学习场景中均优于经典模型。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer中的前馈网络（FFN）模块占据大量参数，而参数化量子电路（PQC）因其高表达性成为潜在替代方案。本文旨在探索PQC在FFN中的应用，以提升模型性能并减少参数。

研究方法: QFFN-BERT将BERT中的FFN模块替换为PQC层，采用包含残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略的PQC架构，确保训练稳定性和高表达性。实验在经典模拟器上进行，使用SST-2和DBpedia基准测试。

研究结果: 实验结果显示，QFFN-BERT在完整数据集上达到基线模型102.0%的准确率，同时减少FFN参数99%以上。在少样本学习场景中，该模型表现一致且具有竞争力。

研究结论: 研究表明，PQC可以作为经典FFN的高效替代方案，尤其在参数效率和性能方面表现突出。通过合理设计，PQC能够提升模型的数据效率和学习能力。

中文摘要: 参数化量子电路（PQC）近年来成为增强神经网络表达性的潜在组件。本文提出QFFN-BERT，一种混合量子-经典Transformer模型，其中紧凑型BERT的前馈网络（FFN）模块被PQC层替代。这一设计的动机在于FFN在标准Transformer编码器块中占据约三分之二的参数。尽管先前研究主要将PQC集成到自注意力模块中，本文聚焦于FFN，并系统研究了PQC深度、表达性与可训练性之间的权衡。最终PQC架构包含残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略，以确保训练稳定性和高表达性。在经典模拟器上对SST-2和DBpedia基准的实验表明：1）精心配置的QFFN-BERT在完整数据集上达到基线模型102.0%的准确率，同时减少FFN参数99%以上；2）该模型在少样本学习中表现一致且具有竞争力。这些结果证实，当PQC与深度学习基础原则协同设计时，可作为经典FFN的高效替代方案。

</details>


### [9] [Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection](https://arxiv.org/abs/2507.02378)
**中文标题：通过分布一致性和多样性感知的数据选择实现高效代码大语言模型训练**

*Weijie Lyu,Sheng-Jun Huang,Xuan Xia*

主要分类: cs.CL

摘要简述: 本文提出一种基于分布一致性和多样性的代码数据选择方法，显著提升训练效率和模型性能，仅用10K样本即超越92K基线数据的效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型（LLM）训练主要依赖海量数据，但忽视数据质量，导致训练效率低下。本文旨在通过优化数据选择，提升模型性能和训练效率。

研究方法: 采用参数化模型进行代码数据选择，确保所选子集分布一致且多样，从而提高数据质量。

研究结果: 实验表明，仅使用10K样本，方法在HumanEval和MBPP上分别提升2.4%和2.3%，优于其他采样方法。

研究结论: 该方法不仅能显著提升模型性能，还能大幅降低计算成本，为高效LLM训练提供新思路。

中文摘要: 近年来，大语言模型（LLM）的进展显著提升了代码生成和程序理解能力，推动了软件工程的发展。当前方法主要通过利用大量数据提升模型性能，但过度关注数据量而忽视数据质量，降低了训练效率。为此，我们提出一种基于参数化模型的代码数据选择方法，旨在提升训练效率和模型性能。该方法通过优化参数化模型，确保所选子集分布一致且多样，从而保证数据质量。实验结果表明，仅使用10K样本，我们的方法在HumanEval和MBPP上分别取得2.4%和2.3%的提升，优于92K全采样基线，同时在性能和效率上均超越其他采样方法。这表明我们的方法能有效提升模型性能，同时显著降低计算成本。

</details>


### [10] [Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability](https://arxiv.org/abs/2507.02407)
**中文标题：跨领域数据集阿坎语ASR模型基准测试：性能、可扩展性和适应性的比较评估**

*Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame*

主要分类: cs.CL

摘要简述: 本研究通过比较七种基于Transformer架构的阿坎语ASR模型（如Whisper和Wav2Vec2）在四个不同领域的阿坎语语音数据集上的表现，揭示了模型性能对领域的依赖性，并分析了Whisper和Wav2Vec2在错误行为上的差异。


<details>
  <summary>详细信息</summary>
研究动机: 现有ASR研究多基于同领域数据集评估模型性能，而忽略了模型在多样化语音场景中的泛化能力。本研究旨在填补这一空白，评估阿坎语ASR模型在不同领域中的表现。

研究方法: 研究使用了七种基于Transformer架构的阿坎语ASR模型，并在四个不同领域的阿坎语语音数据集上进行测试，包括文化相关的图像描述、非正式对话、圣经诵读和自发性金融对话。通过比较词错误率和字符错误率，分析了模型的领域依赖性和错误行为。

研究结果: 研究发现模型性能高度依赖训练领域，在领域不匹配时表现显著下降。Whisper模型生成的转录错误更流畅但可能误导，而Wav2Vec2模型的错误更明显但难以解释。

研究结论: 研究强调了在低资源语言应用中需考虑模型错误的可读性与透明性之间的权衡，并建议采用针对性的领域适应技术、自适应路由策略和多语言训练框架。

中文摘要: 现有大多数自动语音识别（ASR）研究使用同领域数据集评估模型，但很少评估其在多样化语音场景中的泛化能力。本研究通过基于Transformer架构的七种阿坎语ASR模型（如Whisper和Wav2Vec2）在四个阿坎语语音语料库上的表现填补了这一空白。这些数据集涵盖多个领域，包括文化相关的图像描述、非正式对话、圣经诵读和自发性金融对话。通过比较词错误率和字符错误率，研究发现模型性能具有领域依赖性，仅在训练领域内表现最优，而在不匹配场景中准确性显著下降。此外，研究还揭示了Whisper和Wav2Vec2架构在错误行为上的差异：微调的Whisper阿坎语模型生成的转录错误更流畅但可能误导，而Wav2Vec2在遇到陌生输入时产生的错误更明显但难以解释。这种ASR错误在可读性与透明性之间的权衡应在低资源语言（LRL）应用中予以考虑。这些发现强调了针对阿坎语及其他低资源语言开发领域适应技术、自适应路由策略和多语言训练框架的必要性。

</details>


### [11] [A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages](https://arxiv.org/abs/2507.02428)
**中文标题：社区驱动的低资源语言受损语音数据收集指南**

*Sumaya Ahmed Salihs,Isaac Wiafe,Jamal-Deen Abdulai,Elikem Doe Atsakpo,Gifty Ayoka,Richard Cave,Akon Obu Ekpezu,Catherine Holloway,Katrin Tomanek,Fiifi Baffoe Payin Winful*

主要分类: cs.CL

摘要简述: 本研究提出了一种社区驱动的低资源语言中受损语音数据收集方法，旨在通过开发‘食谱’式指南和工具，促进包容性自动语音识别（ASR）技术的发展。以加纳的阿坎语为例，研究创建了首个开源受损语音数据集，并展示了微调开源ASR模型的初步成果。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于解决低资源语言中受损语音数据稀缺的问题，通过社区参与的方式，推动包容性ASR技术的普及，满足语言障碍人群的独特需求。

研究方法: 研究方法包括开发一套‘食谱’式指南，指导社区成员收集受损语音数据；以阿坎语为例，招募多样化背景的参与者，创建首个开源数据集；并利用开源工具微调ASR模型以适应受损语音。

研究结果: 研究结果包括发布了首个阿坎语受损语音开源数据集、‘食谱’指南和相关工具；初步实验显示，微调后的开源ASR模型对受损语音的识别能力有所提升。

研究结论: 研究结论表明，社区驱动的数据收集方法可行且有效，为低资源语言中的受损语音ASR技术开发提供了实用工具和范例，推动了包容性技术的发展。

中文摘要: 本研究提出了一种收集语音样本的方法，旨在为低资源语言中的受损语音构建自动语音识别（ASR）模型。通过开发‘食谱’式最佳实践和培训指南，推动社区驱动的数据收集和ASR模型构建，从而实现ASR技术的民主化。作为概念验证，本研究整理了首个阿坎语（加纳广泛使用的土著语言）受损语音的开源数据集，参与者包括来自不同背景的语言障碍人士。最终发布的数据集、指南及开源工具可供研究人员和从业者使用，以开发满足语言障碍人群独特需求的包容性ASR技术。此外，本研究还展示了微调开源ASR模型以更好识别阿坎语受损语音的初步成果。

</details>


### [12] [IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders](https://arxiv.org/abs/2507.02506)
**中文标题：IndianBailJudgments-1200：一个用于印度保释判决法律NLP的多属性数据集**

*Sneha Deshmukh,Prathmesh Kamble*

主要分类: cs.CL

摘要简述: 本文介绍了IndianBailJudgments-1200数据集，包含1200份印度法院保释判决，标注了20多个属性，支持法律NLP任务。


<details>
  <summary>详细信息</summary>
研究动机: 由于印度等地区缺乏结构化数据集，法律NLP发展受限。本文旨在填补这一空白，提供首个公开的印度保释判决数据集。

研究方法: 使用GPT-4o提示工程生成标注，并通过一致性验证，构建包含1200份判决的多属性数据集。

研究结果: 数据集支持保释结果预测、摘要生成和公平性分析等任务，为印度法律NLP研究提供了重要资源。

研究结论: IndianBailJudgments-1200是首个专注于印度保释法学的公开数据集，将推动法律NLP在印度的发展。

中文摘要: 由于缺乏结构化数据集，印度等地区的法律NLP发展滞后。我们推出了IndianBailJudgments-1200，这是一个包含1200份印度法院保释判决的新基准数据集，标注了20多个属性，包括保释结果、IPC条款、犯罪类型和法律推理。标注通过提示工程的GPT-4o流程生成并验证一致性。该资源支持多种法律NLP任务，如结果预测、摘要生成和公平性分析，是首个公开的专注于印度保释法学的数据集。

</details>


### [13] [WebSailor: Navigating Super-human Reasoning for Web Agent](https://arxiv.org/abs/2507.02592)
**中文标题：WebSailor：为网络代理导航超人类推理**

*Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou*

主要分类: cs.CL

摘要简述: WebSailor是一种后训练方法，通过结构化采样和信息模糊化生成高不确定性任务，结合RFT冷启动和DUPO算法，显著提升了开源代理在复杂信息搜索任务中的性能，接近专有代理水平。


<details>
  <summary>详细信息</summary>
研究动机: 现有开源模型在复杂信息搜索任务中表现不佳，无法像专有系统（如DeepResearch）那样处理极端不确定性。WebSailor旨在填补这一能力差距，通过系统化的方法提升模型的推理能力。

研究方法: WebSailor采用结构化采样和信息模糊化生成高不确定性任务，结合RFT冷启动和高效的代理强化学习算法DUPO，形成完整的训练流程。

研究结果: WebSailor在复杂信息搜索任务中显著优于所有开源代理，性能接近专有代理，成功缩小了能力差距。

研究结论: WebSailor通过系统化的后训练方法，成功提升了开源代理在复杂信息搜索任务中的性能，证明了其在处理极端不确定性方面的有效性。

中文摘要: 超越人类认知限制是LLM训练的关键前沿。DeepResearch等专有代理系统在BrowseComp等极端复杂的信息搜索基准上展示了超人类能力，这是此前开源模型无法实现的。我们认为其成功依赖于开源模型中缺乏的复杂推理模式：在广阔信息空间中系统化降低极端不确定性的能力。基于这一洞察，我们提出了WebSailor，一种完整的后训练方法，旨在培养这一关键能力。我们的方法包括通过结构化采样和信息模糊化生成新颖的高不确定性任务、RFT冷启动以及高效的代理强化学习算法DUPO。通过这一集成流程，WebSailor在复杂信息搜索任务中显著优于所有开源代理，性能与专有代理相当，缩小了能力差距。

</details>


### [14] [Revisiting Active Learning under (Human) Label Variation](https://arxiv.org/abs/2507.02593)
**中文标题：重新审视（人类）标注变异下的主动学习**

*Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher*

主要分类: cs.CL

摘要简述: 本文探讨了在人类标注变异（HLV）背景下重新审视主动学习（AL）的必要性，提出了一种将HLV纳入AL循环的概念框架，并讨论了大型语言模型（LLM）作为标注者的整合。


<details>
  <summary>详细信息</summary>
研究动机: 高质量标注数据的获取是监督学习中的瓶颈，而标注变异（LV）尤其是人类标注变异（HLV）常被忽视。现有主动学习方法基于简化假设，未考虑HLV的实际影响，本文旨在填补这一空白。

研究方法: 通过分解标注变异为信号（如HLV）和噪声（如标注错误），提出一个概念框架，将HLV融入AL循环的实例选择、标注者选择和标签表示中，并探讨LLM作为标注者的应用。

研究结果: 研究强调了HLV的重要性，提出了一个能够更好地反映真实世界标注复杂性的HLV感知主动学习框架，为未来研究奠定了基础。

研究结论: 本文为HLV感知的主动学习提供了概念基础，推动了更贴近实际标注场景的研究方向，并展示了LLM在标注中的潜力。

中文摘要: 高质量标注数据的获取仍然是应用监督学习中的限制因素。尽管标注变异（LV），即同一实例的不同标注，在自然语言处理等领域中很常见，但标注框架通常仍假设存在单一真实标注，忽略了人类标注变异（HLV）作为一种信息信号的存在。同样，主动学习（AL）作为一种优化有限标注预算的流行方法，通常依赖于多个简化假设之一，这些假设在承认HLV的实际情况下很少成立。本文探讨了关于真实性和标注本质的基础假设，强调需要将观察到的LV分解为信号（如HLV）和噪声（如标注错误）。我们调查了AL和（H）LV社区如何处理（或忽视）这些区别，并提出了一个概念框架，将HLV纳入AL循环的各个环节，包括实例选择、标注者选择和标签表示。我们还讨论了大型语言模型（LLM）作为标注者的整合。本研究旨在为HLV感知的主动学习奠定概念基础，更好地反映真实世界标注的复杂性。

</details>


### [15] [MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion](https://arxiv.org/abs/2507.02595)
**中文标题：MPF：通过多视角融合实现部署后语言模型的对齐与去偏**

*Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama*

主要分类: cs.CL

摘要简述: MPF是一种新型后训练对齐框架，通过多视角融合技术减少大型语言模型（LLM）的偏见，无需大量提示工程或微调。


<details>
  <summary>详细信息</summary>
研究动机: 随着对减少语言模型偏见的迫切需求，MPF旨在提供一种可扩展且可解释的方法，用于对齐和缓解偏见，适用于已部署的模型。

研究方法: MPF基于SAGED流程，通过多视角生成技术分解可解释的基线分布（如HR专业人士的情感分布），并通过采样和平衡响应来引导生成。

研究结果: 实验表明，MPF能够将LLM的情感分布与反事实基线（绝对平等）和HR基线（偏向顶尖大学）对齐，显著降低KL散度和校准误差，并能泛化到未见问题。

研究结论: MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，适用于已部署的LLM，且无需大量提示工程或微调。

中文摘要: 多视角融合（MPF）是一种新型的后训练对齐框架，旨在满足减少偏见的迫切需求。基于SAGED流程（一种自动构建偏见基准和提取可解释基线分布的系统），MPF利用多视角生成技术揭示并对齐LLM输出中的偏见，使其与细致的人类基线一致。通过将基线（如HR专业人士的情感分布）分解为可解释的视角组件，MPF通过采样和平衡响应来引导生成，权重由分解得到的概率决定。实验表明，MPF能够将LLM的情感分布与反事实基线（绝对平等）和HR基线（偏向顶尖大学）对齐，显著降低KL散度和校准误差，并能泛化到未见问题。这表明MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，适用于已部署的LLM，且无需大量提示工程或微调。

</details>


### [16] [Exploring Gender Bias Beyond Occupational Titles](https://arxiv.org/abs/2507.02679)
**中文标题：探索超越职业名称的性别偏见**

*Ahmed Sabir,Rajesh Sharama*

主要分类: cs.CL

摘要简述: 本研究探讨了性别与语境偏见之间的关联，重点关注动作动词、宾语名词和职业等因素。作者提出了新数据集GenderLexicon和框架，用于量化语境偏见及其相关的性别偏见，并通过多数据集验证了方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多集中于职业名称中的性别偏见，而忽略了其他语境因素（如动词和名词）可能隐含的性别偏见。本研究旨在填补这一空白，揭示更广泛的性别偏见现象。

研究方法: 作者开发了数据集GenderLexicon和一个框架，通过评分系统量化语境中的性别偏见，提升偏见的可解释性。方法在五个多样化数据集（包括日语数据集）上进行了验证。

研究结果: 研究发现，性别偏见不仅存在于职业刻板印象中，还广泛分布于动作动词和宾语名词等语境中。提出的框架能够有效识别和解释这些偏见。

研究结论: 本研究扩展了对性别偏见的理解，证明了其存在于更广泛的语境中。提出的工具和方法为未来研究提供了新的方向。

中文摘要: 本研究探讨了性别与语境偏见之间的关联，重点关注动作动词、宾语名词和职业等因素。我们提出了一个新数据集GenderLexicon和一个框架，用于估计语境偏见及其相关的性别偏见。该模型能够通过评分解释偏见，从而提高性别偏见的可解释性。此外，我们的研究证实了性别偏见不仅存在于职业刻板印象中。为了验证方法的有效性，我们在五个多样化数据集（包括一个日语数据集）上进行了评估。

</details>


### [17] [Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers](https://arxiv.org/abs/2507.02694)
**中文标题：大型语言模型能否识别科学研究中的关键局限性？对AI研究论文的系统性评估**

*Zhijian Xu,Yilun Zhao,Manasi Patwardhan,Lovekesh Vig,Arman Cohan*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型（LLMs）在识别科学论文局限性方面的能力，提出了一个全面的局限性分类法，并开发了LimitGen基准来评估LLMs在此任务中的表现。通过结合文献检索，LLMs能够更准确地识别论文局限性，为同行评审提供辅助支持。


<details>
  <summary>详细信息</summary>
研究动机: 随着科学出版物数量的激增，同行评审的压力日益增大。尽管LLMs在科学任务中表现出潜力，但其在识别论文局限性方面的能力尚未得到充分研究。本文旨在填补这一空白，探索LLMs如何辅助同行评审，尤其是识别论文的局限性。

研究方法: 本文首先提出了一个针对AI领域的科学论文局限性分类法。基于此分类法，开发了LimitGen基准，包含两个子集：LimitGen-Syn（通过高质量论文的受控扰动生成的合成数据集）和LimitGen-Human（真实的人工撰写局限性数据集）。此外，通过结合文献检索，提升了LLMs识别局限性的能力。

研究结果: 实验结果表明，LimitGen基准能够有效评估LLMs在识别论文局限性方面的能力。结合文献检索的LLMs系统能够生成更具体和建设性的反馈，显著提升了局限性识别的准确性。

研究结论: 本文证明了LLMs在辅助同行评审中的潜力，尤其是在识别论文局限性方面。LimitGen基准为未来研究提供了重要工具，结合文献检索的方法进一步增强了LLMs的实用性。

中文摘要: 同行评审是科学研究的基石，但随着出版物数量的激增，这一依赖专家知识的过程面临更大挑战。尽管大型语言模型（LLMs）在多项科学任务中展现出潜力，但其在辅助同行评审（尤其是识别论文局限性）方面的潜力尚未充分研究。我们首先提出了一个针对AI领域的科学论文局限性分类法。基于此分类法，我们开发了LimitGen，这是首个用于评估LLMs在支持早期反馈和补充人类同行评审方面能力的综合性基准。该基准包含两个子集：LimitGen-Syn（通过高质量论文的受控扰动生成的合成数据集）和LimitGen-Human（真实的人工撰写局限性数据集）。为了提升LLMs系统识别局限性的能力，我们结合了文献检索，这对于将局限性识别建立在已有科学发现的基础上至关重要。我们的方法增强了LLMs系统在研究论文中生成局限性的能力，使其能够提供更具体和建设性的反馈。

</details>


### [18] [Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens](https://arxiv.org/abs/2507.02744)
**中文标题：通过最小可产生差异（JPD）测量元音产生空间的粒度**

*Peter Viechnicki*

主要分类: cs.CL

摘要简述: 本研究通过测量‘最小可产生差异’（JPD）来探究人类元音发音的精细控制能力，发现JPD在F1 X F2空间中为14至51 mels，为语音产生理论和元音系统结构提供了新见解。


<details>
  <summary>详细信息</summary>
研究动机: 过去研究表明，人类元音发音的复杂协调动作受听觉空间目标区域的控制，但控制精度尚不明确。本研究旨在通过测量‘最小可产生差异’（JPD）来量化这种控制的精细程度。

研究方法: 研究采用元音模仿范式，测量两组英语使用者在发前元音时的JPD，即两个元音刺激在听觉空间中必须相隔多远才能产生可靠不同的模仿。

研究结果: 研究发现JPD在F1 X F2空间中为14至51 mels，为元音系统的理论最小距离提供了量化依据。

研究结论: 研究结果支持语音产生的片段理论，并为人类元音系统的可能结构提供了心理物理学解释，揭示了元音音位数量和分布模式的潜在限制。

中文摘要: 过去几十年的研究表明，人类元音发音的复杂协调动作部分受听觉空间目标区域的控制，但子音位水平的控制精度尚不明确。本研究通过测量‘最小可产生差异’（JPD），即两个元音刺激在听觉空间中必须相隔多远才能产生可靠不同的模仿，首次量化了这种控制的精细程度。研究采用元音模仿范式，测量了两组英语使用者在发前元音时的JPD，发现其在F1 X F2空间中为14至51 mels。这一发现对语音产生的片段理论具有启示意义，并为人类元音系统的可能结构提供了理论下限，即两个元音音位在说话者共振峰空间中的最小距离，从而解释了观察到的元音音位数量和分布模式的趋势。

</details>


### [19] [Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs](https://arxiv.org/abs/2507.02778)
**中文标题：自我纠正测试框架：揭示并解决大型语言模型中的自我纠正盲点**

*Ken Tsui*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLMs）存在‘自我纠正盲点’，即无法纠正自身输出的错误。通过引入‘自我纠正测试框架’，测试14个模型发现平均盲点率为64.5%。训练数据构成是主要原因，但简单添加‘等待’提示可显著减少盲点。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）具有变革性，但仍会犯错且无法有效纠正自身错误。研究旨在揭示并解决LLMs的‘自我纠正盲点’，以提升其可靠性和可信度。

研究方法: 研究引入‘自我纠正测试框架’，通过在不同复杂度级别注入错误，系统测量LLMs的自我纠正能力。测试了14个模型，并分析训练数据对盲点的影响。

研究结果: 测试发现LLMs平均盲点率为64.5%，训练数据中缺乏错误纠正示例是主要原因。简单添加‘等待’提示可将盲点减少89.3%。

研究结论: 研究揭示了LLMs的自我纠正盲点，并提出了通过调整训练数据或提示设计提升其可靠性的潜在途径。

中文摘要: 尽管大型语言模型（LLMs）具有变革性，但它们仍会犯错并可能陷入无效推理路径。自我纠正是可信赖LLM（尤其是自回归LLM）的重要能力。虽然LLMs能识别用户输入中的错误，但它们表现出系统的‘自我纠正盲点’——无法纠正自身输出中的相同错误。为系统研究此现象，我们引入‘自我纠正测试框架’，通过三个复杂度级别的控制错误注入测量此现象。测试14个模型后，发现平均盲点率为64.5%。我们发现多项证据表明此限制与训练数据构成有关：人类训练示例主要展示无错误响应而非错误纠正序列，这与通过结果反馈学习错误纠正的RL训练模型不同。值得注意的是，仅添加‘等待’提示即可将盲点减少89.3%，表明此能力存在但需激活。我们的工作揭示了当前LLMs的关键限制，并提供了提升其可靠性和可信度的潜在途径。

</details>


### [20] [Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models](https://arxiv.org/abs/2507.02799)
**中文标题：推理是你所需的一切吗？推理语言模型时代的偏见探究**

*Riccardo Cantini,Nicola Gabriele,Alessio Orsino,Domenico Talia*

主要分类: cs.CL

摘要简述: 本文探讨了推理语言模型（RLMs）在引入推理能力后对社会偏见的鲁棒性影响，发现具备显式推理能力的模型反而更容易受到偏见诱导，挑战了推理能力提升鲁棒性的假设。


<details>
  <summary>详细信息</summary>
研究动机: 随着推理语言模型（RLMs）在多步推理任务中的应用日益广泛，其对社会偏见的鲁棒性影响尚未明确。本文旨在研究推理能力是否真的能提升模型的公平性和安全性。

研究方法: 研究利用CLEAR-Bias基准，系统评估了多种RLMs在不同社会文化维度上的表现，采用LLM-as-a-judge方法进行自动安全评分，并通过越狱技术测试内置安全机制的强度。

研究结果: 结果显示，具备显式推理能力的模型（如通过CoT提示或微调推理轨迹）比无推理机制的基准模型更容易受到偏见诱导。推理模型在安全性上略优于依赖CoT提示的模型，后者尤其容易受到故事化提示或虚构角色的攻击。

研究结论: 研究挑战了推理能力必然提升鲁棒性的假设，揭示了推理可能无意中强化偏见的新途径，强调了在推理设计中需更多关注偏见问题。

中文摘要: 推理语言模型（RLMs）因其通过链式思维（CoT）提示或微调推理轨迹执行复杂多步推理任务的能力而受到关注。尽管这些能力有望提高可靠性，但其对社会偏见鲁棒性的影响尚不明确。本研究利用最初为大型语言模型（LLMs）设计的CLEAR-Bias基准，探究RLMs对偏见诱导的对抗鲁棒性。我们系统评估了最先进的RLMs在多样社会文化维度上的表现，采用LLM-as-a-judge方法进行自动安全评分，并利用越狱技术评估内置安全机制的强度。评估回答了三个关键问题：（i）推理能力的引入如何影响模型的公平性和鲁棒性；（ii）微调推理的模型是否比依赖CoT提示的模型更安全；（iii）针对偏见诱导的越狱攻击成功率如何随推理机制变化。研究发现，推理能力与偏见安全性之间存在微妙关系。出乎意料的是，具备显式推理能力的模型（无论是通过CoT提示还是微调推理轨迹）通常比无此类机制的基准模型更容易受到偏见诱导，表明推理可能无意中为刻板印象强化开辟新途径。推理模型在安全性上略优于依赖CoT提示的模型，后者尤其容易受到通过故事化提示、虚构角色或奖励塑造指令的上下文重构攻击。这些结果挑战了推理必然提升鲁棒性的假设，并强调需要更多关注偏见的推理设计方法。

</details>


### [21] [Multimodal Mathematical Reasoning with Diverse Solving Perspective](https://arxiv.org/abs/2507.02804)
**中文标题：基于多样化解题视角的多模态数学推理**

*Wenhao Shi,Zhiqiang Hu,Yi Bin,Yang Yang,See-Kiong Ng,Heng Tao Shen*

主要分类: cs.CL

摘要简述: 本文提出MathV-DP数据集和Qwen-VL-DP模型，通过多样化解题视角和强化学习提升多模态数学推理能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型在数学推理中依赖单一解题视角和监督信号，忽略了多样化的解题思路和内部反思，限制了模型的推理能力。

研究方法: 提出MathV-DP数据集，包含多样化解题轨迹；基于Qwen-VL构建Qwen-VL-DP模型，采用监督学习和基于规则的强化学习（GRPO）优化，结合正确性判别和多样性奖励函数。

研究结果: 在MathVista和Math-V基准测试中，Qwen-VL-DP在准确性和生成多样性上显著优于现有模型。

研究结论: 多样化解题视角和反思性推理对多模态数学推理至关重要，MathV-DP和Qwen-VL-DP为相关研究提供了新方向。

中文摘要: 近年来，大规模强化学习（RL）的进展显著提升了大型语言模型（LLM）在数学领域的推理能力。然而，当前用于数学推理的多模态LLM（MLLM）通常依赖一对一的图像-文本对和单一解题监督，忽略了多样化有效推理视角和内部反思。本文提出MathV-DP数据集，为每个图像-问题对捕捉多样化解题轨迹，提供更丰富的推理监督。进一步提出Qwen-VL-DP模型，基于Qwen-VL构建，通过监督学习和基于规则的RL方法（GRPO）优化，结合正确性判别和多样性奖励函数。该方法强调从多样化推理视角学习，并区分正确但不同的解法。在MathVista的minitest和Math-V基准测试中，Qwen-VL-DP在准确性和生成多样性上显著优于现有MLLM，突显了多样化视角和反思性推理在多模态数学推理中的重要性。

</details>


### [22] [SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model](https://arxiv.org/abs/2507.02822)
**中文标题：SynapseRoute：基于双状态大语言模型的自动路由切换框架**

*Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun*

主要分类: cs.CL

摘要简述: SynapseRoute是一种基于双状态大语言模型（LLM）的自动路由切换框架，通过动态分配查询到高推理或低成本模式，优化准确性、成本和用户体验。实验显示其提升准确性并显著降低推理时间和令牌消耗。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLM）的广泛应用，选择模型需平衡性能和成本。研究发现58%的医学问题可通过低成本模式准确回答，无需高成本推理，因此提出动态路由以优化资源分配。

研究方法: 提出SynapseRoute框架，基于机器学习动态分配查询到高推理（thinking）或低成本（non-thinking）模式，并引入AIT指数评估准确性、延迟和令牌成本的权衡。

研究结果: 实验表明，SynapseRoute相比单一高推理模式，准确性提升（0.8390 vs. 0.8272），推理时间减少36.8%，令牌消耗降低39.66%，同时避免对简单问题过度推理导致的延迟和准确性下降。

研究结论: SynapseRoute通过动态路由优化了双状态LLM的资源分配，显著提升效率并降低成本，为实际应用提供了可行的解决方案。

中文摘要: 随着大语言模型（LLM）在实际应用中的广泛采用，选择合适模型不仅需平衡性能，还需考虑运营成本。具备推理能力的模型进一步拉大了“高推理”（高成本）和“低成本”（快速）模式之间的成本差距。本研究发现，约58%的医学问题仅需低成本模式即可准确回答，无需高成本推理过程，揭示了问题复杂性的明显二分性。基于此，我们提出SynapseRoute，一种基于机器学习的动态路由框架，智能分配输入查询至高推理或低成本模式。在多个医学数据集上的实验表明，SynapseRoute不仅比单一高推理模式提升了整体准确性（0.8390 vs. 0.8272），还减少了36.8%的推理时间和39.66%的令牌消耗。定性分析指出，对简单问题过度推理会导致不必要延迟甚至准确性下降，而自适应路由可避免此问题。最后，本研究引入准确性-推理-令牌（AIT）指数，全面评估准确性、延迟和令牌成本之间的权衡。

</details>


### [23] [Generalizing Verifiable Instruction Following](https://arxiv.org/abs/2507.02833)
**中文标题：泛化可验证指令遵循**

*Valentina Pyatkin,Saumya Malik,Victoria Graf,Hamish Ivison,Shengyi Huang,Pradeep Dasigi,Nathan Lambert,Hannaneh Hajishirzi*

主要分类: cs.CL

摘要简述: 本文探讨了语言模型在遵循人类指令时的局限性，尤其是面对新的输出约束时的泛化能力不足。作者提出了新基准IFBench和强化学习方法RLVR，显著提升了模型对未知约束的遵循能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型在遵循精确指令（如特定输出约束）时表现不佳，尤其是对未见过的约束泛化能力差。作者希望通过新基准和改进训练方法提升模型的泛化能力。

研究方法: 作者设计了IFBench基准，包含58种新的、多样化的验证约束，并开发了约束验证模块。通过强化学习与可验证奖励（RLVR）方法训练模型，提升其指令遵循能力。

研究结果: 实验表明，RLVR方法显著提高了模型对未知约束的泛化能力。IFBench和新增的29种训练约束及验证函数为研究提供了丰富资源。

研究结论: 通过IFBench和RLVR方法，模型在遵循精确指令时的泛化能力得到显著提升，为未来研究提供了新工具和方向。

中文摘要: 人类与AI成功交互的关键在于语言模型或聊天机器人能否精确遵循人类指令。指令中常见的输出约束（如“仅回答是或否”或“至少提及‘abrakadabra’三次”）有助于生成更有用的回答，但即使当前最强模型也难以满足此类约束。研究发现，大多数模型在测试这些能力的基准上对少量可验证约束过拟合，无法很好地泛化到未见过的输出约束。为此，我们提出了新基准IFBench，用于评估58种新的、多样化且具有挑战性的域外可验证约束下的精确指令遵循泛化能力。此外，我们深入分析了如何通过训练数据改进模型的精确指令遵循泛化能力。具体而言，我们精心设计了约束验证模块，并证明基于可验证奖励的强化学习（RLVR）显著提升了指令遵循能力。除IFBench外，我们还发布了29种新增的手工标注训练约束及验证函数、RLVR训练提示和代码。

</details>


### [24] [LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users](https://arxiv.org/abs/2507.02850)
**中文标题：LLM催眠术：利用用户反馈向所有用户注入未经授权的知识**

*Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas*

主要分类: cs.CL

摘要简述: 本文揭示了一种基于用户反馈训练的语言模型（LM）漏洞，攻击者可通过简单的提示和反馈（点赞/点踩）持久性地改变模型的知识和行为。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于揭示语言模型在用户反馈训练中的潜在安全漏洞，攻击者可能利用反馈机制注入未经授权的知识或操纵模型行为。

研究方法: 攻击方法包括：攻击者通过提示让模型随机输出“有毒”或良性回答，并通过点赞有毒回答或点踩良性回答影响模型。随后，模型在偏好调整中更倾向于输出有毒回答。

研究结果: 实验结果表明，这种攻击可用于：（1）插入模型原本不具备的事实知识；（2）修改代码生成模式以引入安全漏洞；（3）注入虚假金融新闻。

研究结论: 本文不仅揭示了语言模型偏好调整的新特性（表明即使有限的偏好数据也能精细控制模型行为），还提出了一种新的攻击机制，扩展了预训练数据投毒和部署时提示注入的研究。

中文摘要: 我们描述了一种基于用户反馈训练的语言模型（LM）漏洞，攻击者仅通过提供提示和点赞/点踩反馈，即可持久性地改变模型的知识和行为。攻击实施时，攻击者提示模型随机输出“有毒”或良性回答，随后点赞有毒回答或点踩良性回答。当反馈信号用于后续的偏好调整时，模型即使在无恶意提示的上下文中，也会更倾向于输出有毒回答。我们展示了这种攻击可用于：（1）插入模型原本不具备的事实知识；（2）修改代码生成模式以引入可利用的安全漏洞；（3）注入虚假金融新闻。我们的发现不仅揭示了语言模型偏好调整的新特性（表明即使高度受限的偏好数据也能精细控制行为），还提出了一种新的攻击机制（扩展了预训练数据投毒和部署时提示注入的研究）。

</details>


### [25] [MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs](https://arxiv.org/abs/2507.02851)
**中文标题：MOTIF：通过强化学习微调实现大语言模型的模块化思考**

*Purbesh Mitra,Sennur Ulukus*

主要分类: cs.CL

摘要简述: 本文提出MOTIF方法，通过强化学习微调让大语言模型（LLM）分多轮生成思考标记，突破上下文限制，提升推理能力。实验显示在GSM8K数据集上训练的Qwen2.5-3B-Instruct模型在MATH500和AIME2024基准测试中分别提升3.8%和3.3%，且仅需15%样本。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）的推理能力受限于上下文长度，无法处理无限多的标记。为了突破这一限制，需要一种模块化思考策略，让模型分多轮进行推理。

研究方法: 提出MOTIF方法，通过强化学习微调（RL）训练模型分多轮生成思考标记，扩展有效上下文长度。实验使用Qwen2.5-3B-Instruct模型在GSM8K数据集上进行参数高效微调，并在MATH500和AIME2024基准测试中验证效果。

研究结果: 实验结果显示，MOTIF方法在MATH500和AIME2024基准测试中分别比传统GRPO训练提升3.8%和3.3%，且仅需15%的样本，表现出高效的样本利用率。

研究结论: MOTIF方法通过模块化思考策略有效扩展了LLM的推理能力，突破了上下文长度的限制，同时展示了高效的样本利用率。

中文摘要: 近期研究表明，通过组相对策略优化（GRPO）算法进行强化学习（RL）训练，可以提升大语言模型（LLM）的推理能力，使其生成更多思考标记以改善响应质量。然而，LLM在保持对已生成标记注意力的同时，只能生成有限数量的标记，这一限制（即上下文长度）成为LLM处理大量标记时的瓶颈。为了突破上下文长度的限制，LLM需要采用模块化思考策略进行多轮推理。本文提出MOTIF方法（通过强化学习微调实现模块化思考），通过RL训练模型分多轮生成思考标记，从而扩展有效上下文长度。我们在开源模型Qwen2.5-3B-Instruct上使用GSM8K数据集进行参数高效微调，并在MATH500和AIME2024基准测试中验证其准确性。实验结果显示，MOTIF方法在两项测试中分别比传统GRPO训练提升3.8%和3.3%，且仅需15%的样本，展示了其高效的样本利用率。代码和模型已开源。

</details>


### [26] [Answer Matching Outperforms Multiple Choice for Language Model Evaluation](https://arxiv.org/abs/2507.02856)
**中文标题：答案匹配优于多项选择题用于语言模型评估**

*Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping*

主要分类: cs.CL

摘要简述: 研究发现，通过答案匹配的生成式评估方法比传统的多项选择题更能准确评估语言模型性能，且与人工评分高度一致。


<details>
  <summary>详细信息</summary>
研究动机: 多项选择题作为语言模型评估的主要方法存在局限性，例如模型可能无需阅读问题即可回答。因此，研究者探索更有效的评估方式，即生成式答案匹配。

研究方法: 提出答案匹配方法：让模型生成自由回答，再通过现代语言模型与参考答案对比判断匹配度。同时，通过标注MMLU-Pro和GPQA-Diamond数据集获取人工评分数据，比较不同评估策略的有效性。

研究结果: 答案匹配方法（即使是小型模型）与人工评分一致性接近完美，远优于多项选择题评估或无参考答案的LLM评分。模型排名在答案匹配评估下显著变化。

研究结论: 答案匹配是一种更有效的语言模型评估方法，建议逐步取代多项选择题评估。

中文摘要: 多项选择题基准长期以来是语言模型评估的主要工具，因为其评分客观且易于自动化。然而，我们发现流行基准中的多项选择题往往无需阅读问题即可回答。这些捷径源于判别式评估的根本局限性，而生成式自由回答评估则无此问题。直到最近，似乎没有可行的替代方案，但我们证明情况已改变。我们提出通过答案匹配进行生成式评估：让候选模型生成自由回答，再使用现代语言模型与参考答案对比判断匹配度。为比较不同评估策略的有效性，我们标注了MMLU-Pro和GPQA-Diamond数据集获取人工评分数据，并测量每种评估方法的一致性。结果显示，答案匹配（即使是小型模型）与人工评分一致性接近完美，而多项选择题评估或无参考答案的LLM评分与人工评分一致性较差。答案匹配不仅是一个概念问题：模型排名在自由回答评估下显著变化。基于这些发现，我们讨论了如何将评估体系从多项选择题转向答案匹配。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges](https://arxiv.org/abs/2507.02074)
**中文标题：大语言模型在视频碰撞检测中的应用：方法、数据集与挑战综述**

*Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma*

主要分类: cs.CV

摘要简述: 本文综述了利用大语言模型（LLMs）从视频数据中检测碰撞的方法，总结了融合策略、关键数据集、模型架构、性能比较以及当前挑战与机遇。


<details>
  <summary>详细信息</summary>
研究动机: 智能交通系统中，从视频中检测碰撞是一个关键问题。近年来，大语言模型和视觉语言模型的发展为多模态信息的处理、推理和总结提供了新的可能性。本文旨在综述相关方法，为未来研究提供基础。

研究方法: 本文通过结构化分类法总结了融合策略，梳理了关键数据集，分析了模型架构，并比较了性能基准。

研究结果: 研究总结了当前方法的性能表现，并指出了该领域面临的挑战与机遇。

研究结论: 本文为视频理解与基础模型交叉领域的未来研究提供了重要参考。

中文摘要: 视频中的碰撞检测是智能交通系统的关键问题。近年来，大语言模型（LLMs）和视觉语言模型（VLMs）的发展彻底改变了多模态信息的处理、推理和总结方式。本文综述了利用LLMs从视频数据中检测碰撞的最新方法，提出了融合策略的结构化分类法，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前的挑战与机遇。本综述为视频理解与基础模型交叉领域的未来研究奠定了基础。

</details>


### [28] [Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning](https://arxiv.org/abs/2507.02148)
**中文标题：水下单目度量深度估计：真实世界基准与合成数据微调**

*Zijie Cai,Christopher Metzler*

主要分类: cs.CV

摘要简述: 本文提出了一种水下单目深度估计的基准测试，通过合成数据微调模型，显著提升了水下环境中的性能表现。


<details>
  <summary>详细信息</summary>
研究动机: 由于水下环境中光线衰减、散射、颜色失真和高质量真实数据缺乏，单目深度估计的可靠性受限，本文旨在解决这一问题。

研究方法: 作者在真实水下数据集（如FLSea和SQUID）上评估了多种零样本和微调模型，并通过合成水下数据集（基于Hypersim生成）微调Depth Anything V2模型。

研究结果: 实验表明，基于合成水下数据微调的模型在所有基准测试中表现优于仅使用陆地数据训练的基线模型。

研究结论: 研究强调了领域适应和尺度感知监督在水下深度估计中的重要性，为未来研究提供了参考。

中文摘要: 单目深度估计近年来已发展至不仅能预测相对深度，还能预测度量深度。然而，由于光线衰减、散射、颜色失真、浑浊以及高质量度量真实数据的缺乏，其在水下环境中的可靠性仍然有限。本文在具有度量深度标注的真实水下数据集（如FLSea和SQUID）上，对零样本和微调的单目度量深度估计模型进行了全面基准测试。我们评估了多种先进模型在不同水下条件下的表现。结果表明，尽管在陆地（真实或合成）数据上训练的大规模模型在空气中表现良好，但由于显著的领域偏移，其在水下环境中表现不佳。为解决这一问题，我们使用基于物理的水下图像生成模型，在Hypersim数据集的合成水下变体上微调了Depth Anything V2模型（采用ViT-S骨干编码器）。实验证明，我们的微调模型在所有基准测试中均表现一致提升，且优于仅基于干净陆地Hypersim数据集训练的基线模型。本研究为水下场景的单目度量深度估计提供了详细的评估和可视化结果，强调了领域适应和尺度感知监督对于在具有挑战性的水下环境中实现鲁棒且可泛化的度量深度预测的重要性，为未来研究提供了参考。

</details>


### [29] [ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.02200)
**中文标题：ESTR-CoT：基于思维链推理的可解释且准确的事件流场景文本识别**

*Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于思维链推理的事件流场景文本识别框架ESTR-CoT，通过结合视觉编码器和大型语言模型，显著提升了在低光照和快速运动等极端场景下的文本识别准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事件流场景文本识别方法在极端场景（如低光照、快速运动）中表现不佳，且缺乏可解释性和上下文逻辑推理能力。本文旨在通过思维链推理提升识别准确性和模型的可解释性。

研究方法: 提出ESTR-CoT框架，结合视觉编码器EVA-CLIP和大型语言模型Vicuna-7B，通过Q-former对齐视觉和语言特征，同时输出答案和思维链推理过程。此外，构建了一个大规模思维链数据集用于训练。

研究结果: 在三个事件流场景文本识别基准数据集（EventSTR、WordArt*、IC15*）上的实验验证了ESTR-CoT的有效性和可解释性。

研究结论: ESTR-CoT通过思维链推理显著提升了事件流场景文本识别的准确性和可解释性，为后续推理型大型模型的发展提供了数据基础。

中文摘要: 基于事件流的场景文本识别是近年来新兴的研究方向，其在极端挑战性场景（如低光照、快速运动）中表现优于广泛使用的RGB相机。现有方法通常采用端到端编码器-解码器框架或大型语言模型以增强识别能力，但仍面临可解释性不足和上下文逻辑推理能力弱的问题。本文提出了一种基于思维链推理的事件流场景文本识别框架ESTR-CoT。具体而言，我们首先采用视觉编码器EVA-CLIP（ViT-G/14）将输入事件流转换为令牌，并利用Llama分词器编码生成提示。通过Q-former将视觉令牌与预训练大型语言模型Vicuna-7B对齐，同时输出答案和思维链推理过程。该框架可通过监督微调以端到端方式优化。此外，我们还提出了一个大规模思维链数据集，通过生成、优化和专家验证三阶段处理训练框架。该数据集为后续基于推理的大型模型发展提供了数据基础。在三个事件流场景文本识别基准数据集（EventSTR、WordArt*、IC15*）上的大量实验充分验证了所提框架的有效性和可解释性。源代码和预训练模型将在https://github.com/Event-AHU/ESTR-CoT发布。

</details>


### [30] [Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach](https://arxiv.org/abs/2507.02205)
**中文标题：第九届ABAW竞赛中的Team RAS：多模态复合表情识别方法**

*Elena Ryumina,Maxim Markitantov,Alexandr Axyonov,Dmitry Ryumin,Mikhail Dolgushin,Alexey Karpov*

主要分类: cs.CV

摘要简述: 本文提出了一种零样本多模态方法，用于复合表情识别（CER），通过结合六种异构模态和动态加权融合模块，实现了与监督方法相当的性能。


<details>
  <summary>详细信息</summary>
研究动机: 复合表情识别（CER）是情感计算的重要子领域，旨在识别由基本情绪组合而成的复杂情绪状态。现有方法依赖特定任务的训练数据，而本文旨在探索一种零样本方法，无需领域适应即可捕捉复合情绪。

研究方法: 方法包括六种模态的整合：静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本。使用零样本组件（如基于CLIP的标签匹配和Qwen-VL的语义场景理解），并引入多头部概率融合（MHPF）模块动态加权模态预测，再通过复合情绪（CE）转换模块生成可解释的输出。

研究结果: 在多语料库训练下，该方法在AffWild2、AFEW和C-EXPR-DB上的F1分数分别为46.95%、49.02%和34.85%，与监督方法性能相当。

研究结论: 本文提出的零样本多模态方法在复合表情识别中表现出色，无需领域适应即可有效捕捉复杂情绪，为情感计算提供了新思路。

中文摘要: 复合表情识别（CER）是情感计算的一个子领域，旨在检测由基本情绪组合而成的复杂情绪状态。本文提出了一种新颖的零样本多模态方法，将六种异构模态整合到一个流程中：静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本。与以往依赖任务特定训练数据的方法不同，本文方法采用零样本组件，包括基于对比语言-图像预训练（CLIP）的标签匹配和Qwen-VL的语义场景理解。进一步引入了多头部概率融合（MHPF）模块动态加权模态预测，并通过复合情绪（CE）转换模块使用成对概率聚合（PPA）和成对特征相似性聚合（PFSA）方法生成可解释的复合情绪输出。在多语料库训练下，该方法在AffWild2、AFEW和C-EXPR-DB上的零样本测试F1分数分别为46.95%、49.02%和34.85%，与目标数据训练的监督方法结果相当。这表明了该方法在无需领域适应的情况下捕捉复合情绪的有效性。源代码已公开。

</details>


### [31] [SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers](https://arxiv.org/abs/2507.02212)
**中文标题：SciGA：学术论文中图形摘要设计的综合数据集**

*Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi*

主要分类: cs.CV

摘要简述: 本文介绍了SciGA-145k数据集，旨在支持图形摘要（GA）的选择与推荐，并推动自动化GA生成的研究。通过定义两项任务（内部GA推荐和外部GA推荐）及提出新评价指标CAR，为科学视觉传达和AI研究奠定基础。


<details>
  <summary>详细信息</summary>
研究动机: 图形摘要在科学论文中起到关键作用，但设计有效的GA需要高级可视化技能，限制了其广泛应用。现有研究对GA的潜力挖掘不足，因此需要大规模数据集支持GA选择与推荐，并推动自动化生成研究。

研究方法: 提出SciGA-145k数据集，包含约14.5万篇论文和114万张图。定义两项任务：1）内部GA推荐，从论文中选出适合作为GA的图；2）外部GA推荐，从其他论文中检索GA以启发新设计。提出新评价指标CAR，弥补传统排名指标的不足。

研究结果: SciGA-145k为GA研究提供了大规模数据支持，并提出了合理的基线模型。CAR指标能更精细地分析模型行为，考虑多图可能作为GA的情况。

研究结论: SciGA-145k为科学视觉传达和AI研究提供了重要基础，推动了GA选择、推荐及自动化生成的发展。

中文摘要: 图形摘要（GA）在科学论文中扮演着关键角色，能够直观传达研究成果。尽管近期研究逐渐将“图1”等视觉材料作为默认GA，但其在科学传播中的潜力尚未充分挖掘。此外，设计有效的GA需要高级可视化技能，限制了其广泛应用。为解决这些问题，我们推出了SciGA-145k，这是一个包含约14.5万篇论文和114万张图的大规模数据集，专门用于支持GA的选择与推荐，并推动自动化GA生成的研究。作为GA设计支持的初步尝试，我们定义了两项任务：1）内部GA推荐，从论文中选出适合作为GA的图；2）外部GA推荐，从其他论文中检索GA以启发新设计。我们为这些任务提供了合理的基线模型。此外，我们提出了“置信度调整的top-1真实比例”（CAR），这是一种新的推荐指标，能够对模型行为进行细粒度分析。CAR通过考虑论文中多张图可能作为GA的情况，弥补了传统排名指标的不足。通过整合这些任务与指标，SciGA-145k为推进科学视觉传达和AI研究奠定了基础。

</details>


### [32] [Understanding Trade offs When Conditioning Synthetic Data](https://arxiv.org/abs/2507.02217)
**中文标题：理解合成数据生成中的权衡**

*Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma*

主要分类: cs.CV

摘要简述: 研究探讨了在合成数据生成中两种条件策略（基于提示和基于布局）的效果，发现布局条件在多样性高时表现更优，显著提升目标检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 工业视觉系统中，高质量训练数据收集耗时且困难，合成数据成为解决方案。扩散模型虽能快速生成高质量图像，但在低数据条件下精确控制仍具挑战。研究旨在比较不同条件策略对合成数据质量的影响。

研究方法: 研究从四个标准目标检测基准中选取80个视觉概念，比较基于提示和基于布局的两种条件策略。分析不同条件下合成数据的质量及其对目标检测性能的影响。

研究结果: 当条件线索范围较窄时，基于提示的条件生成更高质量数据；随着多样性增加，基于布局的条件表现更优。布局条件匹配完整训练分布时，合成数据使平均精度提升34%，最高可达177%。

研究结论: 布局条件策略在多样性高的场景下显著优于提示条件，能有效提升目标检测性能，为合成数据生成提供了优化方向。

中文摘要: 从少量图像中学习鲁棒的目标检测器是工业视觉系统中的关键挑战，因为高质量训练数据的收集可能需要数月时间。合成数据已成为数据高效视觉检测和拾放机器人的重要解决方案。当前流程依赖Blender或Unreal等3D引擎，虽然提供精细控制，但仍需数周渲染小规模数据集，且生成的图像常存在仿真与现实的巨大差距。扩散模型因其能在几分钟内生成高质量图像而成为变革性技术，但在低数据条件下的精确控制仍具挑战。尽管已有多种适配器扩展了扩散模型的功能，但不同条件策略对合成数据质量的影响尚不明确。本研究从四个标准目标检测基准中选取80个视觉概念，比较了基于提示和基于布局的两种条件策略。当条件线索范围较窄时，提示条件生成的数据质量更高；随着多样性增加，布局条件表现更优。当布局条件匹配完整训练分布时，合成数据使平均精度平均提升34%，最高可达177%。

</details>


### [33] [High-Fidelity Differential-information Driven Binary Vision Transformer](https://arxiv.org/abs/2507.02222)
**中文标题：高保真差分信息驱动的二值视觉变换器**

*Tian Gao,Zhiyuan Zhang,Kaijie Yin,Xu-Cheng Zhong,Hui Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种高保真差分信息驱动的二值视觉变换器（DIDB-ViT），通过引入差分信息模块和改进的激活函数，显著提升了二值化视觉变换器的性能，同时保持了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的二值视觉变换器（ViT）方法在性能上存在严重退化或依赖全精度模块的问题，限制了其在边缘设备上的应用。本文旨在解决这些问题，提出一种高性能的二值ViT方法。

研究方法: 1. 设计了包含差分信息的注意力模块以减少二值化带来的信息损失；2. 使用离散Haar小波进行频率分解，整合不同频率的相似性；3. 引入改进的RPReLU激活函数以优化激活分布。

研究结果: 实验表明，DIDB-ViT在多种ViT架构中显著优于现有网络量化方法，在图像分类和分割任务中表现出色。

研究结论: DIDB-ViT通过差分信息驱动和改进的激活函数，成功提升了二值ViT的性能，为边缘设备部署提供了高效解决方案。

中文摘要: 二值化视觉变换器（ViTs）为解决高计算/存储需求与边缘设备部署限制之间的权衡提供了一种有前景的方法。然而，现有的二值ViT方法往往存在严重的性能退化或过度依赖全精度模块。为解决这些问题，我们提出了DIDB-ViT，一种新型的二值ViT，它在保持原始ViT架构和计算效率的同时，具有高信息量。具体而言，我们设计了一个包含差分信息的注意力模块，以减少二值化造成的信息损失并增强高频保留。为了保持二值Q和K张量之间相似性计算的保真度，我们使用离散Haar小波进行频率分解，并整合不同频率的相似性。此外，我们引入了一种改进的RPReLU激活函数，以重构激活分布，扩展模型的表示能力。实验结果表明，我们的DIDB-ViT在多种ViT架构中显著优于最先进的网络量化方法，实现了卓越的图像分类和分割性能。

</details>


### [34] [FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model](https://arxiv.org/abs/2507.02250)
**中文标题：FMOcc：基于三视角视图的流匹配与选择性状态空间模型的3D占据预测**

*Jiangxia Chen,Tongyuan Huang,Ke Song*

主要分类: cs.CV

摘要简述: 本文提出FMOcc，一种基于三视角视图（TPV）和选择性状态空间模型的流匹配方法，用于解决少帧图像在3D语义占据预测中的局限性，显著提升了预测精度和效率。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶中的3D语义占据预测受限于少帧图像和3D空间冗余，导致遮挡和远距离场景预测不准确。现有方法需融合历史帧数据，增加了计算负担。本文旨在通过流匹配和选择性状态空间模型，提升少帧输入的预测能力。

研究方法: 1. 设计了基于流匹配的特征细化模块（FMSSM），用于生成缺失特征。2. 引入TPV SSM层和平面选择性SSM（PS3M），选择性过滤TPV特征以减少空气体素对非空气体素的影响。3. 提出掩码训练（MT）方法，增强模型鲁棒性并解决传感器数据丢失问题。

研究结果: 在Occ3D-nuScenes和OpenOcc数据集上，FMOcc表现优异。仅用两帧输入，在Occ3D-nuScenes验证集上达到43.1% RayIoU和39.8% mIoU，在OpenOcc上达到42.6% RayIoU，推理内存为5.4 G，推理时间为330ms。

研究结论: FMOcc通过流匹配和选择性状态空间模型，显著提升了少帧3D语义占据预测的精度和效率，解决了遮挡和远距离场景的预测问题。

中文摘要: 3D语义占据预测在自动驾驶中至关重要。然而，少帧图像的固有局限性和3D空间的冗余性导致遮挡和远距离场景的预测精度下降。现有方法通过融合历史帧数据提升性能，但需要额外数据和大量计算资源。为解决这些问题，本文提出FMOcc，一种基于三视角视图（TPV）的流匹配选择性状态空间模型，用于少帧3D占据预测。首先，我们设计了基于流匹配模型的特征细化模块（FMSSM），用于生成缺失特征。其次，通过设计TPV SSM层和平面选择性SSM（PS3M），选择性过滤TPV特征以减少空气体素对非空气体素的影响，从而提升模型整体效率和远距离场景预测能力。最后，我们提出掩码训练（MT）方法，增强FMOcc的鲁棒性并解决传感器数据丢失问题。在Occ3D-nuScenes和OpenOcc数据集上的实验结果表明，FMOcc优于现有方法。仅用两帧输入，FMOcc在Occ3D-nuScenes验证集上达到43.1% RayIoU和39.8% mIoU，在OpenOcc上达到42.6% RayIoU，推理内存为5.4 G，推理时间为330ms。

</details>


### [35] [SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement](https://arxiv.org/abs/2507.02252)
**中文标题：SurgVisAgent：多功能手术视觉增强的多模态智能代理模型**

*Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen*

主要分类: cs.CV

摘要简述: SurgVisAgent是一种基于多模态大语言模型（MLLMs）的智能手术视觉代理，能够动态识别内窥镜图像中的失真类别和严重程度，执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。通过领域先验模型和上下文少样本学习，它提供定制化增强，优于传统单任务模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有手术增强算法通常针对单一任务设计，难以适应复杂多变的实际手术场景。因此，需要一种能够动态识别并处理多种失真的统一解决方案，以提升手术决策的准确性和安全性。

研究方法: SurgVisAgent基于多模态大语言模型，设计了一个领域先验模型以提供手术场景知识，并通过上下文少样本学习和链式推理（CoT）实现定制化图像增强。此外，构建了一个模拟真实手术失真的综合基准进行验证。

研究结果: 实验表明，SurgVisAgent在多种失真类型和严重程度下均优于传统单任务模型，展现了其作为统一手术辅助解决方案的潜力。

研究结论: SurgVisAgent通过多模态和动态增强能力，为复杂手术场景提供了一种高效、灵活的视觉增强工具，有望成为未来手术辅助的重要技术。

中文摘要: 精确的手术干预对患者安全至关重要，已有多种增强算法用于辅助医生决策。然而，这些算法通常针对特定场景的单一任务设计，限制了其在复杂实际场景中的效果。为此，我们提出SurgVisAgent，一种基于多模态大语言模型（MLLMs）的端到端智能手术视觉代理。SurgVisAgent能够动态识别内窥镜图像中的失真类别和严重程度，执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。为实现对手术场景的深入理解，我们设计了一个领域先验模型。此外，通过上下文少样本学习和链式推理（CoT），SurgVisAgent能够根据失真类型和严重程度提供定制化增强，满足医生的多样化需求。我们还构建了一个模拟真实手术失真的综合基准，实验表明SurgVisAgent优于传统单任务模型，展现了其作为统一手术辅助解决方案的潜力。

</details>


### [36] [Multi-Label Classification Framework for Hurricane Damage Assessment](https://arxiv.org/abs/2507.02265)
**中文标题：飓风损害评估的多标签分类框架**

*Zhangding Liu,Neda Mohammadi,John E. Taylor*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多标签分类的飓风损害评估框架，结合ResNet特征提取和类别注意力机制，显著提升了损害识别的准确率。


<details>
  <summary>详细信息</summary>
研究动机: 飓风造成的损害类型和程度多样，传统单标签分类方法难以全面捕捉其复杂性，亟需一种更高效的多标签分类方法以支持精准的灾害响应。

研究方法: 该方法整合了基于ResNet的特征提取模块和类别特定注意力机制，能够从单张图像中识别多种损害类型。

研究结果: 在Hurricane Michael的Rescuenet数据集上，该方法平均精度达到90.23%，优于现有基线方法。

研究结论: 该框架显著提升了飓风后损害评估的效率和准确性，为灾害响应和减灾策略提供了有力支持。

中文摘要: 飓风造成广泛破坏，损害类型和程度多样，需要及时准确的评估以支持有效的灾害响应。传统单标签分类方法难以捕捉飓风后损害的复杂性，本研究提出了一种基于多标签分类的框架，利用航拍图像评估损害。该方法结合了基于ResNet的特征提取模块和类别特定注意力机制，能够从单张图像中识别多种损害类型。在Hurricane Michael的Rescuenet数据集上，该方法平均精度达到90.23%，优于现有基线方法。该框架提升了飓风后损害评估的效率和准确性，为灾害响应和减灾策略提供了支持。本文已被ASCE国际计算土木工程会议（i3CE 2025）接收，最终版本将发表于会议论文集。

</details>


### [37] [Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation](https://arxiv.org/abs/2507.02268)
**中文标题：基于双向域适应的跨域高光谱图像分类**

*Yuxiang Zhang,Wei Li,Wen Jia,Mengmeng Zhang,Ran Tao,Shunlin Liang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于双向域适应（BiDA）的跨域高光谱图像分类框架，通过提取域不变特征和域特定信息，显著提升了目标场景的分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱遥感技术能够提取细粒度的土地覆盖类别，但训练和测试图像通常来自不同区域或时间，导致相同类别在不同场景中存在显著光谱偏移。因此，需要一种方法来解决跨域分类问题。

研究方法: 提出双向域适应（BiDA）框架，采用三分支Transformer架构（源分支、目标分支和耦合分支）作为主干。通过耦合多头交叉注意力机制（CMCA）实现特征交互和域间相关性挖掘，并设计双向蒸馏损失和自适应强化策略（ARS）优化模型性能。

研究结果: 在跨时空/场景的航空和卫星数据集上，BiDA显著优于现有域适应方法，在跨时空树种分类任务中比最先进方法高出3%~5%。

研究结论: BiDA框架通过提取域不变和域特定特征，有效提升了跨域高光谱图像分类的适应性和可分性，实验证明了其优越性。

中文摘要: 利用高光谱遥感技术可以提取细粒度的土地覆盖类别。通常，用于训练和测试的卫星或航空图像来自不同区域或时间，同一类别在不同场景中存在显著的光谱偏移。本文提出了一种双向域适应（BiDA）框架，用于跨域高光谱图像（HSI）分类，专注于在独立的自适应空间中提取域不变特征和域特定信息，从而增强对目标场景的适应性和可分性。在BiDA中，设计了一种带有语义标记器的三分支Transformer架构（源分支、目标分支和耦合分支）作为主干。具体而言，源分支和目标分支独立学习源域和目标域的自适应空间，耦合分支中开发了耦合多头交叉注意力（CMCA）机制，用于特征交互和域间相关性挖掘。此外，设计了双向蒸馏损失以利用域间相关性指导自适应空间学习。最后，提出了一种自适应强化策略（ARS），鼓励模型在噪声条件下专注于源和目标场景中的特定广义特征提取。在跨时空/场景的航空和卫星数据集上的实验结果表明，所提出的BiDA显著优于一些最先进的域适应方法。在跨时空树种分类任务中，BiDA比最先进方法高出3%~5%。代码可从以下网址获取：https://github.com/YuxiangZhang-BIT/IEEE_TCSVT_BiDA。

</details>


### [38] [MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement](https://arxiv.org/abs/2507.02270)
**中文标题：MAC-Lookup：用于水下图像增强的多轴条件查找模型**

*Fanghai Yi,Zehong Zheng,Zexiao Liang,Yihang Dong,Xiyang Fang,Wangyu Wu,Xuhang Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MAC-Lookup的多轴条件查找模型，用于解决水下图像增强中的颜色和细节问题，通过条件3D查找表和多轴自适应增强技术显著提升了图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 水下图像因光线变化、水体浑浊和气泡等因素导致可见性和颜色问题，传统方法效果有限，而深度学习缺乏高质量数据集。本文旨在提出一种更有效的水下图像增强方法。

研究方法: MAC-Lookup模型结合了条件3D查找表颜色校正（CLTCC）和多轴自适应增强（MAAE），前者用于初步颜色和质量校正，后者用于细节优化，避免过增强和饱和。

研究结果: 实验表明，MAC-Lookup在恢复水下图像细节和颜色方面优于现有方法，显著提升了视觉质量。

研究结论: MAC-Lookup模型通过创新的多轴条件查找技术，有效解决了水下图像增强的挑战，为水下探索提供了更高质量的图像支持。

中文摘要: 水下图像增强对探索至关重要。由于光线变化、水体浑浊和气泡等因素，这些图像存在可见性和颜色问题。传统基于先验的方法和基于像素的方法效果有限，而深度学习缺乏高质量数据集。我们提出了多轴条件查找（MAC-Lookup）模型，通过提升颜色准确性、清晰度和对比度来改善视觉质量。该模型包括用于初步颜色和质量校正的条件3D查找表颜色校正（CLTCC）和用于细节优化的多轴自适应增强（MAAE），避免了过增强和饱和问题。大量实验表明，MAC-Lookup在恢复水下图像细节和颜色方面优于现有方法。代码见https://github.com/onlycatdoraemon/MAC-Lookup。

</details>


### [39] [Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation](https://arxiv.org/abs/2507.02271)
**中文标题：通过自蒸馏聚焦部分可见电影语言以生成视频到音频**

*Feizhen Huang,Yu Wu,Yutian Lin,Bo Du*

主要分类: cs.CV

摘要简述: 本文提出了一种自蒸馏方法，用于提升视频到音频生成模型在部分可见电影语言场景中的表现，显著改善了部分可见性条件下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频到音频生成方法忽视了电影语言这一关键艺术表达元素，导致在部分可见场景中性能下降。本文旨在解决这一问题。

研究方法: 通过模拟电影语言变化，采用自蒸馏方法训练学生模型，使其能够对齐视频特征与相同音视频对应关系，从而捕捉部分视觉信息与声音的关联。

研究结果: 该方法在所有评估指标下均显著提升了部分可见性场景的性能，并在大规模V2A数据集VGGSound上表现更优。

研究结论: 本文提出的自蒸馏方法有效解决了部分可见电影语言场景中的视频到音频生成问题，为电影后期制作提供了实用工具。

中文摘要: 视频到音频（V2A）生成取得了显著进展，并在电影和视频后期制作中扮演重要角色。然而，现有方法忽视了电影语言这一电影艺术表达的关键组成部分，导致在Foley目标仅部分可见的场景中性能下降。为解决这一问题，我们提出了一种简单的自蒸馏方法，将V2A模型扩展至电影语言场景。通过模拟电影语言变化，学生模型学习将训练对的视频特征与相同音视频对应关系对齐，从而有效捕捉声音与部分视觉信息之间的关联。我们的方法不仅在部分可见性场景下所有评估指标中实现了显著提升，还在大规模V2A数据集VGGSound上增强了性能。

</details>


### [40] [LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2507.02279)
**中文标题：LaCo：多模态大语言模型中视觉令牌的高效层级压缩**

*Juntao Liu,Liqiang Niu,Wenchao Chen,Jie Zhou,Fandong Meng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LaCo的新型视觉令牌压缩框架，通过在视觉编码器的中间层进行有效压缩，显著提升了多模态大语言模型的效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉令牌压缩方法主要作为后编码器模块运行，限制了效率提升的潜力。为了解决这一问题，本文提出了LaCo框架。

研究方法: LaCo包含两个核心组件：1）层级的像素重组机制，通过空间到通道的转换合并相邻令牌；2）带有非参数捷径的残差学习架构，保留压缩过程中的关键视觉信息。

研究结果: 实验表明，LaCo在视觉编码器的中间层压缩令牌时优于现有方法，训练效率提升超过20%，推理吞吐量提升超过15%，同时保持高性能。

研究结论: LaCo通过中间层压缩显著提升了多模态大语言模型的效率，同时保持了性能，为视觉令牌压缩提供了新的解决方案。

中文摘要: 现有的多模态大语言模型（MLLMs）视觉令牌压缩方法主要作为后编码器模块运行，限制了效率提升的潜力。为了解决这一问题，我们提出了LaCo（层级视觉令牌压缩），一种新颖的框架，能够在视觉编码器的中间层实现有效的令牌压缩。LaCo引入了两个核心组件：1）层级的像素重组机制，通过空间到通道的转换系统性地合并相邻令牌；2）带有非参数捷径的残差学习架构，在压缩过程中保留关键视觉信息。大量实验表明，LaCo在视觉编码器的中间层压缩令牌时优于所有现有方法，表现出卓越的有效性。此外，与外部压缩相比，我们的方法在保持高性能的同时，训练效率提升超过20%，推理吞吐量提升超过15%。

</details>


### [41] [Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization](https://arxiv.org/abs/2507.02288)
**中文标题：通过语言引导和表示对齐实现提示解耦的领域泛化方法**

*De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种通过语言引导和表示对齐实现提示解耦的方法，用于提升领域泛化（DG）性能。结合大型语言模型（LLM）解耦文本提示，并通过视觉表示对齐增强模型对未见目标域的适应能力。实验证明该方法在多个DG数据集上优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 领域泛化（DG）旨在开发能在未见目标域上有效工作的模型。尽管基于预训练视觉基础模型（VFMs）的领域提示调优受到关注，但设计能够解耦跨领域不变特征的提示仍具挑战性。本文利用VFMs的可控语言提示和文本模态更易解耦的特性，提出一种新框架以解决这一问题。

研究方法: 方法包括两部分：1）使用大型语言模型（LLM）自动解耦文本提示；2）通过解耦的文本特征引导学习领域不变的视觉表示。此外，提出“最差显式表示对齐”（WERA），通过抽象提示增强源域多样性，并约束视觉表示在原始和增强分布间的一致性。

研究结果: 在PACS、VLCS、OfficeHome、DomainNet和TerraInc等主要DG数据集上的实验表明，所提方法优于当前最先进的DG方法。

研究结论: 本文通过语言引导和表示对齐实现了提示解耦，显著提升了领域泛化性能。WERA的引入进一步增强了视觉特征的解耦能力，为DG任务提供了新的解决方案。

中文摘要: 领域泛化（DG）旨在开发能够在未见目标域上有效工作的通用模型。近年来，预训练的视觉基础模型（VFMs，如CLIP）在提升深度学习模型泛化能力方面展现出巨大潜力。尽管基于VFMs的领域提示调优在DG中受到越来越多的关注，但设计能够解耦跨领域不变特征的有效提示仍是一个关键挑战。本文提出利用VFMs的可控和灵活的语言提示来解决这一挑战。注意到VFMs的文本模态天然更易解耦，我们引入了一种新的文本特征引导的视觉提示调优框架。该框架首先使用大型语言模型（LLM）自动解耦文本提示，然后通过解耦的文本特征引导学习领域不变的视觉表示。然而，仅依赖语言引导视觉特征解耦存在局限性，因为视觉特征有时过于复杂或微妙，难以完全通过描述性文本捕捉。为此，我们提出了“最差显式表示对齐”（WERA），通过引入一组抽象提示扩展了文本引导的视觉提示。这些提示通过风格化图像增强增强了源域多样性，同时对齐约束确保了视觉表示在原始和增强分布间的一致性。在PACS、VLCS、OfficeHome、DomainNet和TerraInc等主要DG数据集上的实验表明，所提方法优于当前最先进的DG方法。

</details>


### [42] [ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation](https://arxiv.org/abs/2507.02294)
**中文标题：ViRefSAM：基于视觉参考的Segment Anything Model用于遥感图像分割**

*Hanbo Bi,Yulong Xu,Ya Li,Yongqiang Mao,Boyuan Tong,Chongyang Li,Chunbo Lang,Wenhui Diao,Hongqi Wang,Yingchao Feng,Xian Sun*

主要分类: cs.CV

摘要简述: ViRefSAM是一种基于视觉参考的Segment Anything Model（SAM）改进框架，用于解决遥感图像分割中的手动提示构建和领域适应性问题。通过少量标注参考图像，ViRefSAM实现了自动分割，并在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 遥感图像分割中，手动构建精确提示（如点或框）效率低下，且SAM因预训练数据主要为自然图像而缺乏领域适应性。ViRefSAM旨在通过少量参考图像解决这些问题。

研究方法: ViRefSAM引入两个关键组件：1）视觉上下文提示编码器，从参考图像提取语义线索并生成对象感知提示；2）动态目标对齐适配器，注入类特定语义以减少领域差距。

研究结果: 在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$等基准测试中，ViRefSAM仅需少量参考图像即可实现高精度分割，性能优于现有少样本分割方法。

研究结论: ViRefSAM通过视觉参考和动态适配器解决了SAM在遥感图像分割中的局限性，为少样本分割任务提供了高效解决方案。

中文摘要: Segment Anything Model（SAM）通过提示驱动范式在通用分割任务中表现出强大的泛化能力。然而，将其应用于遥感（RS）图像仍面临两大挑战：一是手动为每张图像构建精确提示（如点或框）耗时且低效，尤其是在小对象密集或空间分布分散的RS场景中；二是SAM缺乏领域适应性，因其主要基于自然图像预训练，难以捕捉RS特有的语义和空间特征，尤其是分割新类别时。为解决这些问题，受少样本学习启发，我们提出ViRefSAM，一种仅需少量包含类特定对象的标注参考图像即可引导SAM的新框架。无需手动提示，ViRefSAM实现了RS图像中类一致对象的自动分割。具体而言，ViRefSAM在保持SAM原始架构的同时引入两个关键组件：（1）视觉上下文提示编码器，从参考图像提取类特定语义线索，并通过与目标图像的上下文交互生成对象感知提示；（2）动态目标对齐适配器，集成到SAM的图像编码器中，通过向目标图像特征注入类特定语义来减少领域差距，使SAM能动态聚焦于任务相关区域。在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$三个少样本分割基准上的大量实验表明，ViRefSAM仅需少量参考图像即可实现新类别的准确自动分割，且在不同数据集上始终优于现有少样本分割方法。

</details>


### [43] [DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation](https://arxiv.org/abs/2507.02299)
**中文标题：DreamComposer++：通过多视角条件增强扩散模型以实现3D内容生成**

*Yunhan Yang,Shuo Chen,Yukun Huang,Xiaoyang Wu,Yuan-Chen Guo,Edmund Y. Lam,Hengshuang Zhao,Tong He,Xihui Liu*

主要分类: cs.CV

摘要简述: DreamComposer++ 是一个通过多视角条件增强扩散模型的框架，用于生成高质量且可控的3D内容。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在生成可控的新视角时面临挑战，主要由于缺乏多视角信息。DreamComposer++ 旨在通过多视角条件提升扩散模型的能力。

研究方法: DreamComposer++ 使用视角感知的3D提升模块提取多视角的3D表示，并通过多视角特征融合模块将这些表示渲染到目标视角的潜在特征中，最后集成到预训练的扩散模型中以生成新视角。

研究结果: 实验表明，DreamComposer++ 能够无缝集成前沿的视角感知扩散模型，并显著提升其从多视角条件生成可控新视角的能力。

研究结论: DreamComposer++ 推动了可控3D对象重建的发展，并拓宽了应用范围。

中文摘要: 近年来，利用预训练的2D扩散模型从单张野外图像生成高质量新视角的方法取得了进展。然而，由于缺乏多视角信息，现有方法在生成可控新视角时面临挑战。本文提出DreamComposer++，一个灵活且可扩展的框架，旨在通过多视角条件提升当前视角感知扩散模型的能力。具体而言，DreamComposer++ 使用视角感知的3D提升模块从多个视角提取对象的3D表示，并通过多视角特征融合模块将这些表示聚合并渲染到目标视角的潜在特征中。最后，将目标视角的特征集成到预训练的图像或视频扩散模型中，以生成新视角。实验结果表明，DreamComposer++ 能够无缝集成前沿的视角感知扩散模型，并增强其从多视角条件生成可控新视角的能力。这一进展推动了可控3D对象重建的发展，并拓宽了应用范围。

</details>


### [44] [Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images](https://arxiv.org/abs/2507.02307)
**中文标题：Flow-CDNet：一种用于检测双时相图像中慢速和快速变化的新型网络**

*Haoxuan Li,Chenxu Wei,Haodong Wang,Xiaomeng Hu,Boyuan An,Lingyan Ran,Baosen Zhang,Jin Jin,Omirzhan Taukebayev,Amirkhan Temirbayev,Junrui Liu,Xiuwei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Flow-CDNet的新型网络，用于同时检测双时相图像中的慢速和快速变化。该网络包含光流分支和二进制变化检测分支，通过多尺度提取位移变化并结合ResNet生成变化输出。实验表明其性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在实际场景中，双时相图像中的慢速变化（如滑坡、尾矿坝等）往往是重大灾害的前兆，但现有方法主要关注快速变化。因此，设计一种能同时检测慢速和快速变化的网络具有重要意义。

研究方法: Flow-CDNet由两个分支组成：光流分支通过金字塔结构提取多尺度位移变化；二进制变化检测分支结合ResNet和光流分支输出生成快速变化结果。此外，设计了Flow-Change数据集、结合Tversky损失和L2范数的损失函数，以及新评估指标FEPE。

研究结果: 在Flow-Change数据集上的定量实验表明，Flow-CDNet优于现有方法。消融实验验证了两个分支的相互促进作用。

研究结论: Flow-CDNet能有效检测双时相图像中的慢速和快速变化，为灾害预警等实际应用提供了新工具。

中文摘要: 变化检测通常涉及识别同一地点双时相图像中的变化区域。除了显著变化外，慢速变化在实际场景中也具有重要意义。例如，在滑坡、大坝和尾矿坝等场景中，弱变化往往是重大灾害的前兆。因此，设计一种能同时检测慢速和快速变化的网络是一项新挑战。本文提出了一种名为Flow-CDNet的变化检测网络，包含两个分支：光流分支和二进制变化检测分支。光流分支通过金字塔结构提取多尺度位移变化，二进制变化检测分支结合ResNet和光流分支输出生成快速变化结果。此外，为监督和评估这一新框架，设计了自建数据集Flow-Change、结合Tversky损失和L2范数的损失函数，以及新评估指标FEPE。在Flow-Change数据集上的定量实验表明，该方法优于现有方法。消融实验验证了两个分支的相互促进作用。

</details>


### [45] [LMPNet for Weakly-supervised Keypoint Discovery](https://arxiv.org/abs/2507.02308)
**中文标题：LMPNet：弱监督关键点发现**

*Pei Guo,Ryan Farrell*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LMPNet的弱监督关键点发现方法，通过创新的漏最大池化层和选择策略，自动发现语义关键点，性能接近监督模型。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在仅通过类别标签弱监督地发现语义对象关键点，避免依赖手工设计的损失项，提升关键点检测的稀疏性、一致性和多样性。

研究方法: 提出漏最大池化层（LMP）以鼓励卷积层滤波器学习非重复局部模式；设计选择策略确保激活一致性；采用注意力掩码迫使网络关注整个对象；引入可学习聚类层生成关键点预测。

研究结果: LMPNet能自动发现对物体姿态鲁棒的语义关键点，预测精度接近监督姿态估计模型。

研究结论: LMPNet通过直接操作网络滤波器检测预定义概念，具有高度可解释性，为弱监督关键点发现提供了有效解决方案。

中文摘要: 本文探索了仅通过类别标签弱监督的语义对象关键点发现任务。通过将判别训练的中间层滤波器转化为关键点检测器，我们首先确定了关键点检测器的三个理想特性：（i）空间稀疏激活，（ii）一致性和（iii）多样性。为避免依赖手工设计的损失项，提出了一种计算高效的漏最大池化（LMP）层，显式鼓励最终卷积层滤波器学习与对象关键点对齐的“非重复局部模式”。基于可视化分析，提出了一种简单有效的选择策略以确保滤波器激活的一致性，并应用注意力掩码迫使网络关注整个对象而非仅最具判别性的区域。对于最终关键点预测，提出了一种可学习聚类层以将关键点提案分组为预测结果。最终模型LMPNet具有高度可解释性，可直接操作网络滤波器检测预定义概念。实验表明，LMPNet能够（i）自动发现对物体姿态鲁棒的语义关键点，（ii）预测精度接近监督姿态估计模型。

</details>


### [46] [Perception Activator: An intuitive and portable framework for brain cognitive exploration](https://arxiv.org/abs/2507.02311)
**中文标题：感知激活器：一种直观便携的大脑认知探索框架**

*Le Xu,Qi Zhang,Qixian Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“感知激活器”的框架，通过将fMRI信号注入多尺度图像特征中，验证了fMRI信号对下游检测和分割任务的提升作用，揭示了fMRI中丰富的多对象语义信息。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大脑视觉解码方法主要依赖像素级对齐，缺乏细粒度的语义对齐，导致重建结果存在明显失真。为了更深入地理解大脑视觉感知模式和解码模型对语义对象的处理方式，本文开发了一个实验框架。

研究方法: 通过将fMRI表征作为干预条件，使用跨注意力机制将其注入多尺度图像特征中，并在对象检测和实例分割任务中比较有无fMRI信息时的下游性能和中间特征变化。

研究结果: 实验结果表明，引入fMRI信号能够提升下游检测和分割任务的准确性，证实了fMRI信号包含丰富的多对象语义线索和粗略的空间定位信息。

研究结论: fMRI信号中蕴含的语义信息尚未被现有模型充分利用，本文提出的框架为探索大脑认知提供了直观且便携的工具。

中文摘要: 近年来，大脑视觉解码技术的进步显著推动了从神经活动（如功能磁共振成像fMRI）中高保真重建感知视觉刺激的能力。现有方法主要采用像素级和语义级的两级解码策略，但这些方法过度依赖低层像素对齐，缺乏足够的细粒度语义对齐，导致多语义对象的重建结果存在明显失真。为了更好地理解大脑的视觉感知模式以及当前解码模型对语义对象的处理方式，我们开发了一个实验框架，将fMRI表征作为干预条件。通过跨注意力机制将这些表征注入多尺度图像特征中，我们在对象检测和实例分割任务中比较了有无fMRI信息时的下游性能和中间特征变化。结果表明，引入fMRI信号能够提升下游检测和分割的准确性，证实了fMRI信号包含丰富的多对象语义线索和粗略的空间定位信息——这些元素尚未被现有模型充分利用或整合。

</details>


### [47] [MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation](https://arxiv.org/abs/2507.02314)
**中文标题：MAGIC：基于掩码引导的扩散修复与多级扰动及上下文感知对齐的少样本异常生成**

*JaeHyuck Choi,MinJun Kim,JeHyeong Hong*

主要分类: cs.CV

摘要简述: MAGIC是一种基于扩散模型的少样本异常生成方法，通过多级扰动和上下文感知对齐，解决了背景保留、掩码对齐和语义合理性三大问题，显著提升了异常生成的质量和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 在工业质量控制中，异常数据稀缺，现有方法难以同时满足背景保留、掩码对齐和语义合理性的需求。MAGIC旨在解决这些问题，提供高质量的少样本异常生成。

研究方法: MAGIC基于Stable Diffusion修复模型，通过微调保留正常区域并严格对齐掩码。采用高斯提示级扰动和掩码引导的空间噪声注入增强多样性，并通过上下文感知掩码对齐模块确保语义合理性。

研究结果: 在MVTec-AD数据集上，MAGIC在异常检测任务中表现优于现有方法，验证了其有效性。

研究结论: MAGIC通过多级扰动和上下文感知对齐，实现了高质量的少样本异常生成，为工业质量控制提供了实用解决方案。

中文摘要: 少样本异常生成正成为工业质量控制中稀缺异常数据增强的实用解决方案。理想的生成器需满足三个要求：(i) 保持正常背景完整，(ii) 修复异常区域以紧密贴合掩码，(iii) 在语义合理位置生成多样且真实的异常。现有扩散方法通常最多满足其中两项：全局异常生成器会破坏背景，而掩码引导方法在掩码不精确或位置错误时表现不佳。我们提出MAGIC——基于掩码引导的修复与多级扰动及上下文感知对齐——以解决所有三个问题。MAGIC的核心是微调Stable Diffusion修复模型，保留正常区域并确保合成异常严格贴合掩码，直接解决背景破坏和对齐问题。为弥补微调可能导致的多样性损失，MAGIC引入两种互补扰动策略：(i) 高斯提示级扰动，在微调和推理阶段应用，扩展异常全局外观同时避免低质量文本表现；(ii) 掩码引导的空间噪声注入，丰富局部纹理变化。此外，上下文感知掩码对齐模块形成语义对应并重新定位掩码，确保异常始终位于宿主对象内，消除边界外伪影。在MVTec-AD数据集的一致评估协议下，MAGIC在下游异常任务中优于现有最优方法。

</details>


### [48] [Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos](https://arxiv.org/abs/2507.02316)
**中文标题：合成视频有用吗？一个以检索为中心的合成视频评估基准**

*Zecheng Zhao,Selena Song,Tong Chen,Zhi Chen,Shazia Sadiq,Yadan Luo*

主要分类: cs.CV

摘要简述: 本文提出了SynTVA数据集和基准，用于评估合成视频在文本到视频检索任务中的实用性，并通过自动评估器提升数据集扩展效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到视频合成（T2V）的评估指标主要关注视觉质量和时间一致性，而忽略了合成视频在下游任务（如文本到视频检索）中的表现。本文旨在填补这一空白。

研究方法: 基于MSRVTT训练集的800个用户查询，使用先进的T2V模型生成合成视频，并标注视频-文本对的四个语义对齐维度（对象与场景、动作、属性和提示保真度）。此外，开发了自动评估器以估计对齐质量。

研究结果: SynTVA不仅为合成视频的实用性提供了基准，还证明了其在数据集扩展中的价值，能够显著提升文本到视频检索的性能。

研究结论: SynTVA是一个有效的工具，可用于评估和选择高质量的合成视频，从而优化下游任务的性能。

中文摘要: 文本到视频（T2V）合成技术发展迅速，但当前的评估指标主要关注视觉质量和时间一致性，对合成视频在下游任务（如文本到视频检索）中的表现提供有限信息。本文提出了SynTVA，一个用于评估合成视频在构建检索模型中的实用性的新数据集和基准。基于MSRVTT训练集的800个多样化用户查询，我们使用先进的T2V模型生成合成视频，并标注每个视频-文本对的四个关键语义对齐维度：对象与场景、动作、属性和提示保真度。我们的评估框架将通用视频质量评估（VQA）指标与这些对齐分数关联，并检验其对下游文本到视频检索性能的预测能力。为了探索扩展路径，我们进一步开发了一个自动评估器，用于从现有指标中估计对齐质量。除了基准测试，我们的结果表明，SynTVA是数据集扩展的宝贵资源，能够选择高实用性的合成样本，显著提升文本到视频检索的效果。项目页面和数据集可在https://jasoncodemaker.github.io/SynTVA/找到。

</details>


### [49] [Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback](https://arxiv.org/abs/2507.02321)
**中文标题：倾听内部声音：通过中间特征反馈对齐ControlNet训练**

*Nina Konovalova,Maxim Nikolaev,Andrey Kuznetsov,Aibek Alanov*

主要分类: cs.CV

摘要简述: 本文提出InnerControl训练策略，通过在扩散模型的所有步骤中强制空间一致性，提升文本到图像生成的空间控制精度。


<details>
  <summary>详细信息</summary>
研究动机: 尽管文本到图像扩散模型取得显著进展，但精确控制生成输出的空间布局仍具挑战性。现有方法如ControlNet++仅关注最终去噪步骤，忽略了中间生成阶段，限制了其效果。

研究方法: 提出InnerControl，通过训练轻量级卷积探针从中间UNet特征重建输入控制信号（如边缘、深度），并在整个扩散过程中最小化预测与目标条件的差异。

研究结果: InnerControl结合ControlNet++等技术，在多种条件方法（如边缘、深度）上实现了最先进的性能，显著提升了控制保真度和生成质量。

研究结论: InnerControl通过在扩散过程的所有步骤中强制空间一致性，显著提升了生成图像的空间控制能力，为文本到图像生成提供了更精确的工具。

中文摘要: 尽管文本到图像扩散模型取得了显著进展，但实现生成输出的精确空间控制仍具挑战性。ControlNet通过引入辅助条件模块解决了这一问题，而ControlNet++则通过仅在最终去噪步骤应用循环一致性损失进一步优化对齐。然而，这种方法忽略了中间生成阶段，限制了其效果。我们提出InnerControl，一种在扩散模型的所有步骤中强制空间一致性的训练策略。我们的方法训练轻量级卷积探针，从每个去噪步骤的中间UNet特征重建输入控制信号（如边缘、深度）。这些探针能够高效地从高度噪声的潜在空间中提取信号，为训练提供伪真实控制。通过在整个扩散过程中最小化预测与目标条件之间的差异，我们的对齐损失提高了控制保真度和生成质量。结合ControlNet++等现有技术，InnerControl在多种条件方法（如边缘、深度）上实现了最先进的性能。

</details>


### [50] [Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model](https://arxiv.org/abs/2507.02322)
**中文标题：基于神经网络的水稻叶片病害识别与分类研究：特征模型与直接图像模型的对比分析**

*Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi*

主要分类: cs.CV

摘要简述: 本研究比较了基于特征分析的检测模型（FADM）和直接图像中心检测模型（DICDM）在水稻叶片病害识别中的性能，发现FADM表现更优，为水稻病害早期检测和产量提升提供了有效方法。


<details>
  <summary>详细信息</summary>
研究动机: 水稻叶片病害严重影响产量和经济收益，早期检测对病害管理和产量提升至关重要。现有研究缺乏对FADM和DICDM的全面对比分析，尤其是特征提取算法的效果评估。

研究方法: 研究采用人工神经网络（ANN）技术，分别构建FADM（使用特征提取、降维、特征选择算法和极限学习机）和DICDM（直接输入图像）。实验基于包含多种病害和健康叶片的数据集，采用10折交叉验证方法。

研究结果: 实验结果表明，FADM在分类性能上优于DICDM，为水稻病害识别提供了更高效的解决方案。

研究结论: FADM在水稻叶片病害检测中表现最佳，具有提升作物健康、减少产量损失的潜力，有助于水稻种植的可持续发展和生产力提高。

中文摘要: 水稻叶片病害显著降低生产力并造成经济损失，凸显了早期检测以实现有效管理和提高产量的必要性。本研究提出基于人工神经网络（ANN）的图像处理技术，用于水稻病害的及时分类与识别。尽管目前主流方法是将水稻叶片图像直接输入ANN，但缺乏对特征分析检测模型（FADM）和直接图像中心检测模型（DICDM）的全面对比分析，尤其是特征提取算法（FEA）的效果评估。因此，本研究首次对FADM进行了实验，利用多种图像特征提取算法、降维算法（DRA）、特征选择算法（FSA）和极限学习机（ELM）。实验在包含细菌性叶枯病、褐斑病、叶瘟病、叶烧病、纹枯病和健康叶片的数据集上进行，采用10折交叉验证方法。同时，建立了不依赖任何FEA的DICDM，并通过不同指标评估分类性能。最终，对FADM和DICDM在水稻叶片病害分类中的表现进行了详尽对比。结果显示，FADM取得了最高性能。采用提出的FADM检测水稻叶片病害，在改善作物健康、减少产量损失以及提升水稻种植的整体生产力和可持续性方面具有巨大潜力。

</details>


### [51] [Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection](https://arxiv.org/abs/2507.02349)
**中文标题：基于两步神经网络的自动化脑血管标志检测**

*Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau*

主要分类: cs.CV

摘要简述: 本文提出了一种基于两步神经网络的自动化脑血管标志检测方法，用于精准定位Willis环的分叉点，解决了标志点邻近和视觉特征相似导致的漏检问题，并在两个数据集上验证了其高效性。


<details>
  <summary>详细信息</summary>
研究动机: 颅内动脉瘤常发生于Willis环的特定分叉点，精准检测这些标志点对快速诊断至关重要。然而，由于标志点邻近和视觉特征相似，传统方法易出现漏检，且Willis环的解剖变异性增加了检测难度。

研究方法: 方法采用两步神经网络：首先通过目标检测网络定位标志点附近的感兴趣区域（ROIs），随后利用改进的U-Net网络精确定位分叉点。该方法解决了标志点邻近和视觉特征相似的问题，并适应了Willis环的解剖变异性。

研究结果: 实验使用两个脑部MRA数据集（内部数据集和公共数据集）验证方法有效性，结果表明该方法在分叉点检测任务中表现最佳。

研究结论: 提出的两步神经网络方法显著提升了Willis环分叉点的检测精度，为颅内动脉瘤的自动化诊断提供了有效工具。

中文摘要: 颅内动脉瘤（ICA）通常发生在Willis环（CoW）的特定分叉点，主要集中在13个主要动脉分叉处。精准检测这些关键标志点对快速高效诊断至关重要。本文提出了一种完全自动化的标志检测方法，采用两步神经网络流程：首先通过目标检测网络定位标志点附近的感兴趣区域（ROIs），随后利用改进的U-Net网络精确定位分叉点。这一两步方法解决了标志点邻近和视觉特征相似导致的漏检问题，尤其是在处理完整的MRA Time-of-Flight（TOF）数据时。此外，该方法还考虑了Willis环的解剖变异性对可检测标志点数量的影响。我们使用两个脑部MRA数据集（内部数据集和公共数据集）评估了方法的有效性，实验结果表明该方法在分叉点检测任务中达到了最高性能水平。

</details>


### [52] [Lightweight Shrimp Disease Detection Research Based on YOLOv8n](https://arxiv.org/abs/2507.02354)
**中文标题：基于YOLOv8n的轻量级虾病检测研究**

*Fei Yuhuan,Wang Gengchen,Liu Fenghao,Zang Ran,Sun Xufei,Chang Hao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于YOLOv8n的轻量级网络架构，用于虾病检测。通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度，并引入改进的SegNext_Attention自注意力机制提升特征提取能力。实验表明，该模型在参数减少32.3%的情况下，mAP@0.5达到92.7%，优于其他轻量级YOLO系列模型。


<details>
  <summary>详细信息</summary>
研究动机: 虾病是虾类养殖中经济损失的主要原因之一。为了提高虾病智能检测效率并防止疾病传播，本文提出了一种轻量级网络架构，旨在平衡检测精度与计算效率。

研究方法: 1. 设计RLDD检测头和C2f-EMCM模块，降低计算复杂度；2. 引入改进的SegNext_Attention自注意力机制，增强特征提取能力；3. 在自建虾病数据集和URPC2020数据集上进行广泛实验，包括消融研究和对比评估。

研究结果: 模型参数减少32.3%，mAP@0.5达到92.7%（比YOLOv8n提高3%），并在URPC2020数据集上表现出更强的鲁棒性（mAP@0.5提高4.1%）。

研究结论: 该方法在精度和效率之间实现了最优平衡，为虾类养殖中的智能疾病检测提供了可靠技术支持。

中文摘要: 虾病是虾类养殖中经济损失的主要原因之一。为预防疾病传播并提升虾类养殖中的智能检测效率，本文提出了一种基于YOLOv8n的轻量级网络架构。首先，通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度，提高了计算效率。随后，引入改进的SegNext_Attention自注意力机制，进一步增强模型的特征提取能力，从而更精准地识别疾病特征。在自建虾病数据集上进行了包括消融研究和对比评估在内的广泛实验，并将泛化测试扩展到URPC2020数据集。结果表明，所提模型参数比原始YOLOv8n减少32.3%，mAP@0.5达到92.7%（比YOLOv8n提高3%）。此外，该模型在mAP@0.5、参数数量和模型大小上均优于其他轻量级YOLO系列模型。在URPC2020数据集上的泛化实验进一步验证了模型的鲁棒性，mAP@0.5比YOLOv8n提高了4.1%。所提方法在精度和效率之间实现了最优平衡，为虾类养殖中的智能疾病检测提供了可靠技术支持。

</details>


### [53] [Holistic Tokenizer for Autoregressive Image Generation](https://arxiv.org/abs/2507.02358)
**中文标题：用于自回归图像生成的全分词器**

*Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi*

主要分类: cs.CV

摘要简述: 本文提出了一种新型图像分词器Hita，用于自回归图像生成，通过全局到局部的分词方案和关键策略优化，显著提升了生成效果和训练速度。


<details>
  <summary>详细信息</summary>
研究动机: 传统的自回归图像生成模型逐步生成视觉标记，难以捕捉标记序列间的全局关系，且现有视觉分词器多局限于局部图像块映射，缺乏全局信息。本文旨在解决这些问题。

研究方法: Hita采用全局到局部的分词方案，结合可学习的全局查询和局部块标记。关键策略包括：1）在序列结构中优先放置全局标记并使用因果注意力；2）在解码前通过轻量融合模块控制信息流，优先全局标记。

研究结果: 实验表明，Hita显著加速了自回归生成器的训练速度，并在ImageNet基准上达到2.59 FID和281.9 IS的优异性能。此外，Hita在零样本风格迁移和图像修复中也表现出色。

研究结论: Hita通过全局到局部的分词方案和优化策略，有效提升了自回归图像生成的性能，尤其在捕捉全局图像属性和任务扩展性方面表现突出。

中文摘要: 传统的自回归图像生成模型逐步生成视觉标记，限制了捕捉标记序列间全局关系的能力。此外，大多数视觉分词器将局部图像块映射为潜在标记，导致全局信息有限。为此，我们提出了Hita，一种用于自回归图像生成的新型图像分词器。它采用了一种全局到局部的分词方案，结合可学习的全局查询和局部块标记。Hita还引入了两种关键策略以优化与自回归生成过程的匹配：1）在序列结构中优先放置全局标记，并使用因果注意力保持对先前标记的感知；2）在将解量化标记输入解码器前，采用轻量融合模块控制信息流，优先全局标记。大量实验表明，Hita显著加速了自回归生成器的训练速度，并在ImageNet基准上达到了2.59 FID和281.9 IS的优异性能。对全局表示的详细分析表明，其能够捕捉纹理、材质和形状等全局图像属性。此外，Hita在零样本风格迁移和图像修复中也表现出色。代码发布于https://github.com/CVMI-Lab/Hita。

</details>


### [54] [LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling](https://arxiv.org/abs/2507.02363)
**中文标题：LocalDyGS：通过自适应局部隐式特征解耦的多视角全局动态场景建模**

*Jiahao Wu,Rui Peng,Jianbo Jiao,Jiayu Yang,Luyang Tang,Kaiqiang Xiong,Jie Liang,Jinbo Yan,Runling Liu,Ronggang Wang*

主要分类: cs.CV

摘要简述: LocalDyGS提出了一种新的动态场景重建框架，通过分解复杂动态场景为局部空间并解耦静态与动态特征，实现了对大尺度和小尺度运动场景的高效建模。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的动态场景运动复杂且多变，现有的基于神经辐射场或3D高斯泼溅的方法难以同时建模大尺度和小尺度运动，限制了其应用范围。因此，需要一种新的方法来更真实地建模高度动态的场景。

研究方法: 1) 将复杂动态场景分解为由种子定义的局部空间，通过捕获每个局部空间内的运动实现全局建模；2) 解耦静态和动态特征，静态特征捕捉静态信息，动态残差场提供时间特定特征，结合后生成时间高斯模型，建模局部空间内的运动。

研究结果: LocalDyGS在多种小尺度数据集上表现出与现有最佳方法竞争的性能，并首次成功建模了更大、更复杂的高度动态场景。

研究结论: LocalDyGS通过局部空间分解和特征解耦，提出了一种高效的动态场景重建框架，为高度动态场景的建模提供了新的解决方案。

中文摘要: 由于现实世界中复杂且高度动态的运动，从多视角输入合成任意视角的动态视频具有挑战性。基于神经辐射场或3D高斯泼溅的先前工作仅限于建模小尺度运动，极大地限制了其应用。本文提出LocalDyGS，包含两部分以适应大尺度和小尺度运动场景：1) 将复杂动态场景分解为由种子定义的局部空间，通过捕获每个局部空间内的运动实现全局建模；2) 解耦静态和动态特征，静态特征捕捉静态信息，动态残差场提供时间特定特征，结合后生成时间高斯模型，建模局部空间内的运动。因此，我们提出了一种新的动态场景重建框架，以更真实地建模高度动态的现实场景。我们的方法不仅在多种小尺度数据集上表现出与现有最佳方法竞争的性能，还首次尝试建模更大、更复杂的高度动态场景。项目页面：https://wujh2001.github.io/LocalDyGS/。

</details>


### [55] [UVLM: Benchmarking Video Language Model for Underwater World Understanding](https://arxiv.org/abs/2507.02373)
**中文标题：UVLM：面向水下世界理解的视频语言模型基准**

*Xizhe Xue,Yang Zhou,Dawei Yan,Ying Li,Haokui Zhang,Rong Xiao*

主要分类: cs.CV

摘要简述: 本文提出了UVLM，一个专注于水下世界理解的视频语言模型基准，通过结合人类专业知识和AI模型构建数据集，解决了水下环境的独特挑战，并设计了多样化的任务和评估指标。实验表明，在UVLM上微调的视频语言模型显著提升了水下场景的理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频语言模型主要关注陆地场景，忽视了水下观测的高需求应用。为了填补这一空白，作者提出了UVLM基准，旨在推动水下世界理解的研究。

研究方法: 通过结合人类和AI模型协作构建数据集，涵盖水下环境的典型挑战（如光线变化、水质浑浊和多视角）。数据集包含多样化的帧率、分辨率、419种海洋生物及静态植物和地形。任务设计分为生物和环境两大类，每类包括内容观察和变化/动作观察，共20种任务类型，并设计了具有挑战性的评估指标。

研究结果: 在两个代表性视频语言模型上的实验表明，在UVLM上微调的模型显著提升了水下场景的理解能力，同时对现有陆地视频语言模型基准（如VideoMME和Perception text）也有轻微改进潜力。

研究结论: UVLM为水下世界理解提供了一个全面的基准，实验证明了其有效性，并展示了在现有基准上的潜在改进空间。数据集和提示工程将公开。

中文摘要: 近年来，大型语言模型（LLMs）的显著成功对人工智能领域产生了深远影响。基于LLM的众多先进工作被提出并应用于各种场景，其中视频语言模型（VidLMs）尤为广泛使用。然而，现有工作主要关注陆地场景，忽视了水下观测的高需求应用。为填补这一空白，我们提出了UVLM，一个通过结合人类专业知识和AI模型协作构建的水下观测基准。为确保数据质量，我们从多角度进行了深入考量。首先，针对水下环境的独特挑战，我们选择了代表典型水下问题的视频（如光线变化、水质浑浊和多视角）构建数据集。其次，为确保数据多样性，数据集涵盖了广泛的帧率、分辨率、419种海洋生物及静态植物和地形。接着，为任务多样性，我们采用了结构化设计，将观测目标分为生物和环境两大类，每类包括内容观察和变化/动作观察，共20种任务类型。最后，我们设计了多个具有挑战性的评估指标，以实现不同方法的定量比较和分析。在两个代表性VidLM上的实验表明，在UVLM上微调的VidLM显著提升了水下世界的理解能力，同时也在现有陆地VidLM基准（如VideoMME和Perception text）上显示出轻微改进潜力。数据集和提示工程将公开发布。

</details>


### [56] [PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection](https://arxiv.org/abs/2507.02393)
**中文标题：PLOT：基于视频目标跟踪的可扩展单目3D目标检测伪标签方法**

*Seokyeong Lee,Sithu Aung,Junyong Choi,Seungryong Kim,Ig-Jae Kim,Junghyun Cho*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视频目标跟踪的伪标签框架（PLOT），用于解决单目3D目标检测中的数据稀缺问题，无需多视角设置或额外传感器，通过时间相邻帧的对象点跟踪提取3D属性，实验证明其具有高准确性和强扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 单目3D目标检测（M3OD）因标注成本高和2D到3D的固有模糊性而面临数据稀缺问题。现有弱监督和伪标签方法多受限于领域特定学习或仅依赖单帧形状信息。本文旨在提出一种仅需视频数据、对遮挡更鲁棒的伪标签框架。

研究方法: 提出PLOT框架，通过视频目标跟踪聚合静态和动态对象的伪LiDAR数据，利用时间相邻帧的对象点跟踪提取3D属性，无需多视角设置、额外传感器或领域特定训练。

研究结果: 实验表明，该方法在3D数据获取不可行的情况下仍能保证可靠准确性，并表现出强扩展性，为M3OD提供了实用有效的解决方案。

研究结论: PLOT框架通过视频目标跟踪实现伪标签生成，显著提升了单目3D目标检测的准确性和扩展性，为数据稀缺问题提供了创新解决方案。

中文摘要: 单目3D目标检测（M3OD）长期因高标注成本和2D到3D的固有模糊性导致数据稀缺问题。尽管已有多种弱监督和伪标签方法试图解决这些问题，但它们多受限于领域特定学习或仅依赖单帧形状信息。本文提出一种仅需视频数据且对遮挡更鲁棒的伪标签框架，无需多视角设置、额外传感器、相机位姿或领域特定训练。具体而言，我们探索了一种通过对象点跟踪聚合时间相邻帧中静态和动态对象的伪LiDAR数据的技术，从而在3D数据获取不可行的情况下实现3D属性提取。大量实验表明，该方法确保了可靠准确性和强扩展性，为M3OD提供了一种实用有效的解决方案。

</details>


### [57] [Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis](https://arxiv.org/abs/2507.02395)
**中文标题：基于增强定位的持续多实例学习在病理全切片图像分析中的应用**

*Byung Hyun Lee,Wongi Jeong,Woojae Han,Kyoungbun Lee,Se Young Chun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CoMEL的持续多实例学习框架，用于病理全切片图像分析，通过增强定位和减少遗忘，显著提升了分类和定位精度。


<details>
  <summary>详细信息</summary>
研究动机: 多实例学习（MIL）通过弱标签降低了大规模图像（如病理全切片图像）的标注成本，但其在持续任务中的适应性和定位能力尚未充分研究。现有方法主要针对自然图像，难以直接应用于MIL定位任务。

研究方法: CoMEL框架包含三部分：(1) 分组双注意力变换器（GDAT）用于高效实例编码，(2) 基于袋原型的伪标签（BPPL）用于可靠实例伪标签生成，(3) 正交加权低秩适应（OWLoRA）以减少袋和实例分类中的遗忘。

研究结果: 在三个公开的病理全切片图像数据集上，CoMEL在持续MIL设置下，袋级分类精度提升高达11.00%，定位精度提升高达23.4%，显著优于现有方法。

研究结论: CoMEL通过结合高效实例编码、可靠伪标签生成和遗忘抑制技术，为病理全切片图像的持续多实例学习提供了有效解决方案。

中文摘要: 多实例学习（MIL）通过袋级弱标签显著降低了大规模图像（如病理全切片图像）的标注成本，但其在持续任务中的适应性和定位能力研究较少。现有的弱增量学习方法主要针对自然图像，利用预训练模型处理数百个小块（如16×16）的全局关系，而MIL定位任务中涉及大量大块（如256×256）且缺乏全局关系（如癌细胞分布）。为解决这些问题，我们提出了持续多实例学习与增强定位（CoMEL）框架，包含：(1) 分组双注意力变换器（GDAT）用于高效实例编码，(2) 基于袋原型的伪标签（BPPL）用于可靠实例伪标签生成，(3) 正交加权低秩适应（OWLoRA）以减少袋和实例分类中的遗忘。在三个公开病理全切片图像数据集上的实验表明，CoMEL在持续MIL设置下，袋级分类精度提升高达11.00%，定位精度提升高达23.4%，显著优于现有方法。

</details>


### [58] [Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection](https://arxiv.org/abs/2507.02398)
**中文标题：超越空间频率：基于像素级时间频率的深度伪造视频检测**

*Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于像素级时间频率的深度伪造视频检测方法，通过分析时间轴上像素的不一致性，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于空间频率的检测器无法有效捕捉像素平面上的时间伪影，导致检测效果受限。本文旨在通过像素级时间频率分析，解决这一问题。

研究方法: 方法包括对每个像素进行时间轴上的1D傅里叶变换，提取对时间不一致性敏感的特征；引入注意力提议模块定位时间伪影区域；并通过联合变换器模块整合时空上下文特征。

研究结果: 实验结果表明，该方法在多种复杂检测场景中表现出色，显著提升了深度伪造视频的检测能力。

研究结论: 本文提出的方法在深度伪造视频检测领域取得了重要进展，为检测时间不一致性提供了有效解决方案。

中文摘要: 我们提出了一种深度伪造视频检测方法，该方法利用像素级时间不一致性，而传统基于空间频率的检测器往往忽略了这一点。传统检测器仅通过跨帧堆叠空间频率谱来表示时间信息，导致无法检测像素平面上的时间伪影。我们的方法对每个像素在时间轴上执行1D傅里叶变换，提取对时间不一致性高度敏感的特征，尤其是在容易出现非自然运动的区域。为了精确定位包含时间伪影的区域，我们引入了一个端到端训练的注意力提议模块。此外，我们的联合变换器模块有效地将像素级时间频率特征与时空上下文特征相结合，扩展了可检测伪造伪影的范围。我们的框架代表了深度伪造视频检测领域的重大进展，在多样化和具有挑战性的检测场景中提供了鲁棒的性能。

</details>


### [59] [TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation](https://arxiv.org/abs/2507.02399)
**中文标题：TABNet：一种基于边界感知伪标签的三重增强自恢复框架用于医学图像分割**

*Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang*

主要分类: cs.CV

摘要简述: TABNet提出了一种基于涂鸦标注的弱监督医学图像分割框架，通过三重增强自恢复模块和边界感知伪标签监督模块，显著提升了分割性能，接近全监督方法的水平。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割需要大量标注数据，但全标注成本高且耗时。涂鸦标注作为一种稀疏标注方式虽高效，但缺乏边界监督和特征学习能力，限制了分割网络的性能。

研究方法: TABNet包含三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS通过强度变换、局部遮挡和拼图增强提升特征学习；BAP通过双分支预测融合和边界感知损失优化伪标签和边界建模。

研究结果: 在ACDC和MSCMR seg数据集上的实验表明，TABNet显著优于现有弱监督方法，性能接近全监督方法。

研究结论: TABNet通过增强特征学习和边界建模，有效解决了涂鸦标注的稀疏性问题，为弱监督医学图像分割提供了高效解决方案。

中文摘要: 背景与目标：医学图像分割是临床应用中的核心任务，但获取大规模全标注数据集耗时且昂贵。涂鸦标注作为一种稀疏标注方式虽高效，但其稀疏性限制了目标区域的特征学习，并缺乏边界监督，为分割网络训练带来挑战。方法：我们提出TABNet，一种新型弱监督医学图像分割框架，包含三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS通过强度变换、局部遮挡和拼图增强提升特征学习；BAP通过双分支预测融合和边界感知损失优化伪标签和边界建模。结果：在ACDC和MSCMR seg数据集上的实验表明，TABNet显著优于现有弱监督方法，性能接近全监督方法。

</details>


### [60] [Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings](https://arxiv.org/abs/2507.02403)
**中文标题：非城市环境中基于自监督学习的野生动物目标重识别**

*Mufhumudzi Muthivhi,Terence L. van Zyl*

主要分类: cs.CV

摘要简述: 本文探讨了利用自监督学习（SSL）在非城市环境中进行野生动物目标重识别的方法，通过无监督方式从相机陷阱数据中提取时间图像对训练模型，实验表明自监督模型在数据有限时更鲁棒，且在所有下游任务中表现优于监督模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前野生动物重识别方法依赖标注数据进行监督学习，而自监督学习能够利用大量无标注数据，本研究旨在探索自监督学习在野生动物重识别中的潜力，减少对标注数据的依赖。

研究方法: 研究使用相机陷阱数据中的时间图像对自动提取个体的两种视图，无需监督训练自监督模型。通过对比监督特征，评估模型在开放世界场景和下游任务中的表现。

研究结果: 实验结果显示，自监督模型在数据有限时表现更鲁棒，且在所有下游任务中优于监督模型。

研究结论: 自监督学习在野生动物重识别中具有显著优势，能够减少对标注数据的依赖，并在性能上超越监督方法。

中文摘要: 野生动物重识别旨在跨不同观测匹配同一物种的个体。当前最先进模型依赖类别标签训练监督模型进行个体分类，这种对标注数据的依赖推动了大规模野生动物数据集的构建。本研究探讨了自监督学习（SSL）在野生动物重识别中的应用。我们通过无监督方式从相机陷阱数据中自动提取个体的两种视图，利用时间图像对训练自监督模型。我们评估了学习到的表征在开放世界场景和多种野生动物下游任务中的表现，并与监督特征进行对比。实验结果表明，自监督模型在数据有限时更鲁棒，且在所有下游任务中表现优于监督模型。代码已开源：https://github.com/pxpana/SSLWildlife。

</details>


### [61] [PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration](https://arxiv.org/abs/2507.02405)
**中文标题：PosDiffAE：一种结合位置感知的扩散自动编码器用于高分辨率脑组织分类及伪影修复**

*Ayantika Das,Moitreya Chaudhuri,Koushik Bhat,Keerthi Ram,Mihail Bota,Mohanasankar Sivaprakasam*

主要分类: cs.CV

摘要简述: 本文提出了一种结合位置感知的扩散自动编码器（PosDiffAE），用于高分辨率脑组织分类及伪影修复，通过结构化潜在空间和改进生成能力实现高效分类和修复。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型虽然能生成高质量图像，但缺乏提取图像特定语义表示的能力，而自动编码器能提供这种能力。本文旨在结合两者的优势，构建一个既能生成高质量图像又能提取语义表示的模型，用于脑组织分类和伪影修复。

研究方法: 1. 设计了一种扩散自动编码器，通过回归高分辨率图像块的位置信息来结构化潜在空间，以区分脑组织类型。2. 提出了一种基于邻域感知的无监督撕裂伪影修复技术。3. 利用扩散模型的可控生成能力，开发了无监督JPEG伪影修复技术。

研究结果: 模型成功构建了一个结构化的潜在空间，能够有效区分脑组织类型，并实现了无监督的撕裂伪影和JPEG伪影修复。

研究结论: PosDiffAE通过结合扩散模型和自动编码器的优势，不仅提升了脑组织分类的准确性，还实现了高效的伪影修复，为医学图像分析提供了新工具。

中文摘要: 去噪扩散模型通过逐步捕获图像分布生成高保真图像样本，但其采样机制无法提取图像特定的语义表示，而自动编码器则能提供这种表示。通过将编码器与扩散模型结合，我们建立了一种自动编码框架，能够学习图像特定表示并组织潜在空间。本文首先设计了一种机制，用于结构化扩散自动编码模型的潜在空间，以识别脑图像中的区域特定细胞模式。通过强制表示回归高分辨率图像块的位置信息，创建了一个有利于区分脑组织类型的潜在空间。其次，提出了一种基于邻域感知的无监督撕裂伪影修复技术，利用潜在表示和扩散模型在推理时的受限生成能力。第三，通过表示引导和利用扩散模型在推理时可控制的加噪与去噪能力，开发了一种无监督JPEG伪影修复技术。

</details>


### [62] [A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern](https://arxiv.org/abs/2507.02408)
**中文标题：一种利用热传感器处理复杂运动模式的实时多目标跟踪新型调谐方法**

*Duong Nguyen-Ngoc Tran,Long Hoang Pham,Chi Dai Tran,Quoc Pham-Nam Ho,Huy-Hung Nguyen,Jae Wook Jeon*

主要分类: cs.CV

摘要简述: 本文提出了一种新型调谐方法，用于热成像中的多目标实时跟踪，特别针对复杂运动模式，通过优化两阶段框架和超参数，显著提升了跟踪性能。


<details>
  <summary>详细信息</summary>
研究动机: 热成像在多目标跟踪中至关重要，尤其在低能见度或光照不足的环境中，但热传感器的低层次特征表示限制了其准确性。本文旨在解决这一问题，提出一种针对复杂运动模式的调谐方法。

研究方法: 论文提出了一种两阶段调谐框架，通过优化每个阶段的超参数，提升热成像中的行人跟踪性能。该方法无需依赖复杂的重识别或运动模型，专注于实时跟踪的精确性。

研究结果: 在PBVS Thermal MOT数据集上的实验表明，该方法在各种热成像条件下均表现出色，成为实际监控应用的可靠解决方案。

研究结论: 本文提出的调谐方法显著提升了热成像多目标跟踪的准确性和实时性，为复杂环境下的监控系统提供了有效工具。

中文摘要: 热成像中的多目标跟踪在监控系统中至关重要，尤其是在RGB相机因低能见度或光照条件差而难以工作的环境中。热传感器通过捕捉红外信号增强了识别任务，但其低层次特征表示使得行人的准确检测和跟踪变得困难。为此，本文提出了一种新型调谐方法，专门用于处理热成像中的复杂运动模式。所提出的框架优化了两阶段调谐，确保每个阶段使用最适合的超参数以最大化跟踪性能。通过对实时跟踪的超参数进行微调，该方法在不依赖复杂重识别或运动模型的情况下实现了高精度。在PBVS Thermal MOT数据集上的大量实验表明，该方法在各种热成像条件下均表现出色，成为实际监控应用的可靠解决方案。

</details>


### [63] [Privacy-preserving Preselection for Face Identification Based on Packing](https://arxiv.org/abs/2507.02414)
**中文标题：基于打包的隐私保护人脸识别预选方案**

*Rundong Xin,Taotao Wang,Jin Wang,Chonghe Zhao,Jing Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于打包的隐私保护人脸识别预选方案（PFIP），通过创新的预选机制和打包模块，显著提高了密文域中人脸检索的效率，同时保持了原始模型的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着隐私问题日益突出和原始面部数据可能被恢复，密文域中的人脸识别系统受到广泛关注。然而，随着密文模板库规模的增大，人脸检索过程变得耗时。为解决这一问题，本文提出了PFIP方案。

研究方法: PFIP方案结合了创新的预选机制以减少计算开销，并引入打包模块以增强生物识别系统在注册阶段的灵活性。

研究结果: 在LFW和CASIA数据集上的实验表明，PFIP在保持原始人脸识别模型准确性的同时，检索1000个密文人脸模板仅需300毫秒，命中率达100%，检索效率比现有方法提升近50倍。

研究结论: PFIP方案通过预选和打包技术，显著提高了密文域中人脸检索的效率，同时确保了隐私保护和系统灵活性。

中文摘要: 由于隐私问题日益突出和原始面部数据可能被恢复，密文域中的人脸识别系统受到广泛关注。然而，随着密文模板库规模的增大，人脸检索过程变得耗时。为解决这一问题，我们提出了一种新颖且高效的密文域人脸检索方案，称为基于打包的隐私保护人脸识别预选方案（PFIP）。PFIP通过创新的预选机制减少计算开销，并通过打包模块增强生物识别系统在注册阶段的灵活性。在LFW和CASIA数据集上的大量实验表明，PFIP在保持原始人脸识别模型准确性的同时，检索1000个密文人脸模板仅需300毫秒，命中率达100%。与现有方法相比，PFIP的检索效率提升了近50倍。

</details>


### [64] [Determination Of Structural Cracks Using Deep Learning Frameworks](https://arxiv.org/abs/2507.02416)
**中文标题：基于深度学习框架的结构裂缝检测方法**

*Subhasis Dasgupta,Jaydip Sen,Tuhina Halder*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的结构裂缝检测方法，通过残差U-Net模型和集成学习提升检测精度和效率，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 结构裂缝检测对公共安全至关重要，但人工检测效率低且易出错。本研究旨在通过深度学习技术提高检测的准确性和效率。

研究方法: 研究采用多种残差U-Net模型配置，并将其集成到一个包含卷积块的元模型中，以增强预测效率。模型性能通过IoU和DICE系数评估。

研究结果: 残差U-Net模型在低分辨率图像中表现优异，集成模型性能超过单一模型，成为最有效的检测方法。

研究结论: 该研究为结构缺陷监测提供了更可靠的自动化解决方案，集成模型表现出卓越的准确性。

中文摘要: 结构裂缝检测是公共安全的关键任务，有助于预防潜在的结构性故障。人工检测效率低且易出错，本研究通过引入一种新型深度学习架构来提高检测的准确性和效率。研究采用了多种残差U-Net模型配置，并将其集成到一个包含卷积块的元模型中，以进一步提升预测效率。该集成模型的性能与SegNet和传统U-Net进行了对比。结果表明，残差U-Net模型在低分辨率图像中表现更优，而集成模型的性能超过了单一模型，成为最有效的方法。评估基于IoU和DICE系数，集成模型得分最高，表明其准确性更优。这一进展为结构缺陷监测任务提供了更可靠的自动化系统。

</details>


### [65] [AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars](https://arxiv.org/abs/2507.02419)
**中文标题：AvatarMakeup：面向3D可动画化头像的真实化妆转移**

*Yiming Zhong,Xiaolin Zhang,Ligang Liu,Yao Zhao,Yunchao Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为AvatarMakeup的3D化妆方法，通过预训练的扩散模型从单张参考照片中转移化妆效果，解决了动态表情和多视角下化妆一致性的问题，并实现了精细控制。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D虚拟头像的个性化化妆需求未被充分探索，现有方法无法满足动态表情下的化妆一致性、身份保持及细节精确控制的要求。

研究方法: 采用从粗到细的策略：首先通过Coherent Duplication方法粗粒度地应用化妆并确保一致性，随后通过Refinement Module提升化妆质量。扩散模型用于生成化妆图像作为监督。

研究结果: 实验表明，AvatarMakeup在化妆转移质量和动画一致性方面达到了最先进的水平。

研究结论: AvatarMakeup成功解决了3D虚拟头像化妆中的一致性和细节控制问题，为个性化虚拟形象提供了高效解决方案。

中文摘要: 与现实中的面部美化类似，3D虚拟头像需要个性化定制以提升视觉吸引力，但这一领域尚未得到充分探索。尽管当前的3D高斯编辑方法可用于面部化妆目的，但这些方法无法满足实现真实化妆效果的基本要求：1）确保在可驱动表情下的一致性外观，2）在化妆过程中保持身份不变，3）实现对精细细节的精确控制。为此，我们提出了一种名为AvatarMakeup的专用3D化妆方法，利用预训练的扩散模型从任何个体的单张参考照片中转移化妆图案。我们采用从粗到细的思路，首先保持外观和身份的一致性，然后细化细节。具体而言，扩散模型用于生成化妆图像作为监督。由于扩散过程中的不确定性，生成的图像在不同视角和表情下不一致。因此，我们提出了一种Coherent Duplication方法，粗粒度地将化妆应用于目标，同时确保动态和多视角效果的一致性。Coherent Duplication通过记录生成的化妆图像中的平均面部属性来优化全局UV贴图。通过查询全局UV贴图，可以轻松合成来自任意视角和表情的连贯化妆指导，以优化目标头像。在获得粗粒度化妆头像后，我们通过将Refinement Module集成到扩散模型中进一步提升化妆质量。实验表明，AvatarMakeup在化妆转移质量和动画一致性方面达到了最先进的水平。

</details>


### [66] [F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning](https://arxiv.org/abs/2507.02437)
**中文标题：F²TTA：基于图像级解耦提示调谐的跨域医学图像分类自由形式测试时适应**

*Wei Li,Jingyang Zhang,Lihao Liu,Guoan Wang,Junjun He,Yang Chen,Lixu Gu*

主要分类: cs.CV

摘要简述: 本文提出了一种自由形式的测试时适应方法（F²TTA），通过图像级解耦提示调谐（I-DiPT）解决跨域医学图像分类问题。该方法利用不确定性导向掩码（UoM）和平行图蒸馏（PGD）技术，有效应对测试数据中的不可预测域偏移。


<details>
  <summary>详细信息</summary>
研究动机: 在临床实践中，医学图像数据通常以任意长度和随机顺序的域片段形式到达，导致现有测试时适应方法难以处理。本文旨在解决这种自由形式域片段中的不可预测域偏移问题。

研究方法: 提出图像级解耦提示调谐（I-DiPT）框架，包含图像不变提示和图像特定提示。通过不确定性导向掩码（UoM）和平行图蒸馏（PGD）技术，提升提示的知识表示能力。

研究结果: 在乳腺癌和青光眼分类任务上的实验表明，该方法在自由形式测试时适应（F²TTA）中优于现有方法。

研究结论: I-DiPT框架通过解耦提示调谐和知识重用，成功解决了自由形式测试时适应中的不可预测域偏移问题，为跨域医学图像分类提供了有效解决方案。

中文摘要: 测试时适应（TTA）因其无需标注数据的特点，成为适应源模型到未见医疗站点的有效方法。然而，现有TTA方法假设数据以完整域为单位到达，而临床实践中数据通常以任意长度和随机顺序的域片段形式到达。本文研究了一种实用的自由形式测试时适应（F²TTA）任务，其中源模型需适应此类自由形式域片段，且片段间存在不可预测的偏移。为解决这一问题，我们提出了一种新颖的图像级解耦提示调谐（I-DiPT）框架。I-DiPT利用图像不变提示探索域不变表示以缓解不可预测偏移，并通过图像特定提示将源模型适应到每个测试图像。由于仅有一张图像可用于训练，提示可能面临知识表示不足的问题。为此，我们首先引入不确定性导向掩码（UoM），通过基于源模型表示不确定性的掩码一致性学习，促使提示从输入图像中提取足够信息。随后，我们进一步提出平行图蒸馏（PGD）方法，通过平行图网络重用历史图像特定和图像不变提示的知识。在乳腺癌和青光眼分类任务上的实验证明了该方法在F²TTA中的优越性。代码发布于https://github.com/mar-cry/F2TTA。

</details>


### [67] [Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic](https://arxiv.org/abs/2507.02443)
**中文标题：基于FPGA可编程逻辑的加速人工神经网络红葡萄检测**

*Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias*

主要分类: cs.CV

摘要简述: 本文提出了一种在FPGA可编程逻辑中加速人工神经网络（ANN）的方法，用于红葡萄检测。通过FINN架构部署三种量化ANN模型，MobileNet v1表现最佳，达到98%的成功率和6611 FPS的推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 机器人在移动检测物体时速度较慢，且摄像头帧率低，限制了任务执行效率。AMD的Vitis-AI框架未充分利用FPGA的可编程逻辑（PL），因此本文探索了FINN架构在FPGA中加速ANN的潜力。

研究方法: 使用FINN架构在FPGA的PL中部署三种量化ANN模型：4位量化的MobileNet v1、2位量化的CNV和1位量化的CNV（BNN）。模型在自建的RG2C数据集上训练。

研究结果: MobileNet v1表现最优，成功率达98%，推理速度为6611 FPS。证明了FPGA可显著加速ANN，适用于注意力机制。

研究结论: 本研究验证了FPGA在加速ANN方面的有效性，为机器人实时检测任务提供了高效解决方案。

中文摘要: 机器人在移动检测物体时通常会减速，且摄像头配置低帧率以匹配检测算法的速度，这限制了任务执行和探索的效率。AMD开发的Vitis-AI框架虽能将检测算法部署到FPGA中，但未充分利用FPGA的可编程逻辑（PL）。本文采用FINN架构，在FPGA的PL中部署了三种人工神经网络（ANN）：4位量化的MobileNet v1、2位量化的CNV和1位量化的CNV（BNN）。这些模型在自建的RG2C数据集上训练。MobileNet v1表现最佳，成功率达98%，推理速度为6611 FPS。本研究证明了FPGA可用于加速ANN，使其适用于注意力机制。

</details>


### [68] [From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding](https://arxiv.org/abs/2507.02790)
**中文标题：从长视频到吸引人的片段：一种基于多模态叙事理解的人类启发式视频编辑框架**

*Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多模态叙事理解的自动视频编辑框架（HIVE），通过角色提取、对话分析和叙事摘要等技术，将长视频剪辑为吸引人的短视频片段。实验表明，该方法显著优于现有基线，并缩小了自动剪辑与人工剪辑的质量差距。


<details>
  <summary>详细信息</summary>
研究动机: 随着短视频平台的快速发展，如何高效地将长视频剪辑为吸引人的短视频成为迫切需求。现有方法主要依赖文本线索，忽略了丰富的视觉上下文，导致输出不连贯。本文旨在通过多模态叙事理解解决这一问题。

研究方法: 提出HIVE框架，结合角色提取、对话分析和叙事摘要，利用多模态大语言模型全面理解视频内容。通过场景级分割将编辑过程分解为高光检测、开头/结尾选择和无关内容修剪三个子任务。

研究结果: 实验结果表明，HIVE框架在通用和广告导向的编辑任务中均优于现有基线，显著缩小了自动剪辑与人工剪辑的质量差距。

研究结论: HIVE框架通过多模态叙事理解实现了高质量的视频剪辑，为自动视频编辑提供了新的研究方向。

中文摘要: 在线视频内容的快速增长，尤其是短视频平台的兴起，催生了对高效视频编辑技术的需求，以将长视频压缩为简洁且吸引人的片段。现有的自动编辑方法主要依赖ASR转录的文本线索和端到端的片段选择，往往忽略了丰富的视觉上下文，导致输出不连贯。本文提出了一种人类启发的自动视频编辑框架（HIVE），通过多模态叙事理解解决这些局限性。我们的方法结合了角色提取、对话分析和叙事摘要，利用多模态大语言模型实现对视频内容的全面理解。为进一步提升连贯性，我们采用场景级分割，并将编辑过程分解为三个子任务：高光检测、开头/结尾选择以及无关内容修剪。为促进该领域的研究，我们引入了DramaAD，一个包含800多集短剧和500个专业编辑广告片段的新基准数据集。实验结果表明，我们的框架在通用和广告导向的编辑任务中均显著优于现有基线，显著缩小了自动剪辑与人工剪辑的质量差距。

</details>


### [69] [IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising](https://arxiv.org/abs/2507.02445)
**中文标题：IGDNet：基于照明引导与去噪的零样本鲁棒低曝光图像增强**

*Hailong Yan,Junjian Huang,Tingwen Huang*

主要分类: cs.CV

摘要简述: IGDNet是一种零样本增强方法，无需训练数据或先验知识，通过分解和去噪模块有效恢复低曝光图像的照明并抑制噪声，显著提升视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖成对数据集且易导致过增强，IGDNet旨在解决这些问题，提供无需训练数据的鲁棒增强方案。

研究方法: IGDNet包含分解模块（通过密集连接网络分离照明与反射）和去噪模块（基于照明引导的像素自适应校正），通过下采样生成噪声对并迭代优化结果。

研究结果: 在四个公开数据集上，IGDNet在PSNR（20.41dB）和SSIM（0.860dB）上优于14种无监督方法，显著提升复杂光照条件下的视觉质量。

研究结论: IGDNet展示了零样本增强的强大泛化能力，无需训练数据即可有效恢复照明并抑制噪声，为低曝光图像增强提供了实用解决方案。

中文摘要: 现有低曝光图像恢复方法通常依赖成对的低曝光与正常照明图像进行监督学习，但在实际场景中收集此类数据集往往不切实际。此外，这些方法可能导致过增强，破坏正常照明区域。为解决这些问题，我们提出IGDNet，一种零样本增强方法，仅需单张测试图像，无需先验知识或训练数据。IGDNet具有强大的泛化能力，能有效抑制噪声并恢复照明。该框架包含分解模块和去噪模块：前者通过密集连接网络将图像分离为照明与反射分量，后者利用照明引导的像素自适应校正方法增强非均匀照明区域。通过下采样生成噪声对并迭代优化，最终得到增强结果。在四个公开数据集上的实验表明，IGDNet显著提升了复杂光照条件下的视觉质量。定量结果显示，其在PSNR（20.41dB）和SSIM（0.860dB）上优于14种先进的无监督方法。代码即将发布。

</details>


### [70] [Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection](https://arxiv.org/abs/2507.02454)
**中文标题：基于数量提示的弱监督对比学习用于移动红外小目标检测**

*Weiwei Duan,Luping Ji,Shengjia Chen,Sicheng Zhu,Jianghong Huang,Mao Ye*

主要分类: cs.CV

摘要简述: 本文提出了一种弱监督对比学习方案（WeCoL），仅需目标数量提示即可训练模型，用于移动红外小目标检测。该方法结合潜在目标挖掘策略和对比学习，显著减少标注需求，性能接近全监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 移动红外小目标检测因目标尺寸小、背景对比度低而极具挑战性。现有方法多为全监督，依赖大量人工标注，成本高昂。本文旨在通过弱监督策略减少标注需求。

研究方法: 基于预训练的SAM模型，设计潜在目标挖掘策略，结合目标激活图和多帧能量累积；采用对比学习提升伪标签可靠性；提出长短时运动感知学习方案建模目标运动模式。

研究结果: 在DAUB和ITSDT-15K数据集上的实验表明，该弱监督方案性能优于早期全监督方法，甚至达到SOTA全监督方法的90%以上。

研究结论: WeCoL方案通过弱监督和对比学习，显著减少标注需求，性能接近全监督方法，为红外小目标检测提供了高效解决方案。

中文摘要: 与一般目标检测不同，移动红外小目标检测因目标尺寸微小和背景对比度低而面临巨大挑战。目前大多数方法为全监督，严重依赖大量人工目标级标注，而标注视频序列成本高且耗时，尤其是低质量红外帧图像。受通用目标检测启发，非全监督策略（如弱监督）被认为有望减少标注需求。为突破传统全监督框架，本文首次提出一种新的弱监督对比学习（WeCoL）方案，仅需训练期间简单的目标数量提示。具体而言，该方案基于预训练的SAM模型，设计潜在目标挖掘策略，整合目标激活图和多帧能量累积；同时采用对比学习，通过计算特征子空间中正负样本的相似性，提升伪标签可靠性；此外，提出长短时运动感知学习方案，同时建模小目标的局部运动模式和全局运动轨迹。在DAUB和ITSDT-15K两个公开数据集上的广泛实验表明，该弱监督方案性能常优于早期全监督方法，甚至可达当前最优（SOTA）全监督方法的90%以上。

</details>


### [71] [Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk](https://arxiv.org/abs/2507.02477)
**中文标题：Mesh Silksong：自回归网格生成如丝织**

*Gaochao Song,Zibo Zhao,Haohan Weng,Jingbo Zeng,Rongfei Jia,Shenghua Gao*

主要分类: cs.CV

摘要简述: Mesh Silksong提出了一种紧凑高效的网格表示方法，通过自回归方式生成多边形网格，减少冗余顶点标记，压缩率达22%，并提升几何完整性。


<details>
  <summary>详细信息</summary>
研究动机: 现有网格标记方法存在顶点标记重复问题，浪费网络能力。Mesh Silksong旨在通过减少冗余标记，提升网格生成的效率和几何属性。

研究方法: Mesh Silksong采用自回归方式生成网格，每个顶点仅访问一次，减少50%的标记冗余，实现约22%的压缩率，同时确保流形拓扑、水密检测和一致法线等几何特性。

研究结果: 实验表明，Mesh Silksong不仅能生成复杂网格，还显著提升了几何完整性，压缩率和几何属性均达到先进水平。

研究结论: Mesh Silksong通过高效的自回归网格生成方法，显著减少冗余标记，提升几何属性，为实际应用提供了高质量的网格生成方案。

中文摘要: 我们提出了Mesh Silksong，一种紧凑高效的网格表示方法，以自回归方式生成多边形网格，类似于丝织。现有网格标记方法常产生重复顶点标记，浪费网络能力。因此，我们的方法通过仅访问每个顶点一次，减少标记序列冗余50%，实现约22%的先进压缩率。此外，Mesh Silksong生成的网格具有优越的几何属性，包括流形拓扑、水密检测和一致法线，对实际应用至关重要。实验结果证明了该方法的有效性，不仅能生成复杂网格，还显著提升了几何完整性。

</details>


### [72] [Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection](https://arxiv.org/abs/2507.02844)
**中文标题：视觉上下文攻击：通过图像驱动上下文注入越狱多模态大语言模型**

*Ziqi Miao,Yi Ding,Lijun Li,Jing Shao*

主要分类: cs.CV

摘要简述: 本文提出了一种新型视觉上下文攻击（VisCo攻击），通过动态生成辅助图像和优化攻击提示，成功诱导多模态大语言模型（MLLMs）生成有害内容，显著提升了攻击成功率和毒性分数。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）在视觉语言任务中表现出强大能力，其视觉模态的安全漏洞成为开放世界部署的重大挑战。现有研究主要依赖文本语义触发有害行为，缺乏现实场景的语义关联。本文旨在探索视觉信息作为完整且现实的越狱上下文的核心作用。

研究方法: 提出VisCo攻击，通过四种视觉策略构建上下文对话，动态生成辅助图像以形成视觉中心越狱场景。结合自动毒性模糊和语义优化，生成可靠触发黑盒MLLMs有害响应的攻击提示。

研究结果: VisCo在MM-SafetyBench上对GPT-4o的毒性分数达4.78，攻击成功率为85%，显著优于基线方法的2.48和22.2%。

研究结论: VisCo攻击通过视觉上下文注入有效越狱MLLMs，揭示了视觉模态在安全漏洞中的关键作用，为未来防御策略提供了重要参考。

中文摘要: 随着强大的视觉语言能力的出现，多模态大语言模型（MLLMs）在现实应用中展现出巨大潜力。然而，视觉模态表现出的安全漏洞为在开放世界环境中部署此类模型带来了重大挑战。近期研究通过将有害文本语义直接编码到视觉输入中，成功诱导目标MLLMs生成有害响应。然而，这些方法中视觉模态主要作为不安全行为的触发器，通常语义模糊且缺乏现实场景的关联。本文定义了一种新场景：视觉中心越狱，其中视觉信息是构建完整且现实越狱上下文的必要组成部分。基于此场景，我们提出VisCo（视觉上下文）攻击。VisCo通过四种不同的视觉策略伪造上下文对话，必要时动态生成辅助图像以构建视觉中心越狱场景。为最大化攻击效果，它结合自动毒性模糊和语义优化，生成可靠触发目标黑盒MLLMs有害响应的最终攻击提示。具体而言，VisCo在MM-SafetyBench上对GPT-4o的毒性分数为4.78，攻击成功率为85%，显著优于基线方法的2.48和22.2%。代码发布于https://github.com/Dtc7w3PQ/Visco-Attack。

</details>


### [73] [CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios](https://arxiv.org/abs/2507.02479)
**中文标题：CrowdTrack：真实场景中困难多行人跟踪的基准数据集**

*Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue*

主要分类: cs.CV

摘要简述: 本文提出了一个名为CrowdTrack的大规模多行人跟踪数据集，专注于复杂真实场景中的挑战性跟踪任务，填补了现有数据集的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多目标跟踪数据集场景简单且不真实，难以支持复杂场景下的算法研究。为了解决这一问题，作者提出了一个专注于复杂场景的大规模数据集。

研究方法: 作者收集了33个视频，包含5,185条轨迹，所有视频均来自真实复杂场景，并以第一人称视角拍摄。每个对象标注了完整的边界框和唯一ID。

研究结果: 数据集为复杂场景下的算法研究提供了平台，并测试了多个先进模型和基础模型在数据集上的表现。

研究结论: CrowdTrack填补了现有数据集的不足，为复杂场景下的多行人跟踪研究提供了重要资源。

中文摘要: 多目标跟踪是计算机视觉中的经典领域，其中行人跟踪具有极高的应用价值，并成为最热门的研究类别。现有方法主要利用运动或外观信息进行跟踪，但在复杂场景中往往难以实现。对于运动信息，物体间的相互遮挡常常阻碍运动状态的更新；对于外观信息，由于物体仅部分可见或图像模糊等原因，往往得到非鲁棒的结果。尽管从标注数据中学习如何在这些情况下进行跟踪是最简单的解决方案，但现有的多目标跟踪数据集无法满足这一需求。现有方法主要有两个缺点：场景组成相对简单且不真实。尽管现有数据集中的部分视频序列没有上述缺点，但其数量远不足以满足研究需求。为此，我们提出了一个困难的大规模多行人跟踪数据集，主要从第一人称视角拍摄，且全部来自真实复杂场景。我们将其命名为“CrowdTrack”，因为大多数序列中包含大量物体。我们的数据集包含33个视频，共计5,185条轨迹。每个对象标注了完整的边界框和唯一ID。该数据集将为开发在复杂情况下仍有效的算法提供平台。我们对数据集进行了全面分析，并在其上测试了多个先进模型。此外，我们还分析了基础模型在数据集上的表现。数据集和项目代码发布于：https://github.com/loseevaya/CrowdTrack。

</details>


### [74] [MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention](https://arxiv.org/abs/2507.02488)
**中文标题：MedFormer：具有内容感知双稀疏选择注意力的分层医学视觉Transformer**

*Zunhui Xia,Hongxing Li,Libin Lan*

主要分类: cs.CV

摘要简述: MedFormer是一种高效的医学视觉Transformer，通过金字塔缩放结构和内容感知的双稀疏选择注意力（DSSA）提升医学图像识别任务性能，适用于分类和密集预测任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有医学视觉Transformer方法存在任务特定性和计算成本高的问题。MedFormer旨在设计一种通用且高效的模型，解决这些挑战。

研究方法: MedFormer采用金字塔缩放结构作为通用主干网络，并引入内容感知的DSSA，以高效建模长距离依赖并减少噪声干扰。

研究结果: 实验表明，MedFormer在多种医学图像识别任务（分类、语义分割、病变检测）中性能显著优于现有方法。

研究结论: MedFormer通过通用结构和高效注意力机制，为医学图像识别提供了高性能解决方案，代码已开源。

中文摘要: 医学图像识别是辅助临床诊断的重要手段，能够更准确及时地识别疾病和异常。基于视觉Transformer的方法在处理多种医学识别任务中表现优异，但仍面临两大挑战：一是任务特定性和架构定制化限制了通用性；二是采用全局注意力导致计算成本高，或依赖手工稀疏注意力可能影响性能。为此，我们提出MedFormer，其核心创新包括：1）采用金字塔缩放结构作为通用主干，适用于分类和密集预测任务（如语义分割和病变检测），支持分层特征表示并降低计算负载；2）引入内容感知的双稀疏选择注意力（DSSA），在提升计算效率和抗噪能力的同时保持高性能。理论分析表明，MedFormer在通用性和效率上优于现有医学视觉Transformer。多模态数据集实验证实，MedFormer在三种医学图像识别任务中均显著提升性能。代码已开源：https://github.com/XiaZunhui/MedFormer。

</details>


### [75] [Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy](https://arxiv.org/abs/2507.02493)
**中文标题：时间感知的监督对比学习用于结肠镜检查中的息肉计数**

*Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi*

主要分类: cs.CV

摘要简述: 本文提出了一种时间感知的监督对比学习方法，用于结肠镜检查中的息肉计数，通过结合时间信息和视觉特征，显著降低了片段化率并提升了聚类效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的息肉计数方法主要依赖自监督学习，忽略了时间关系，导致聚类效果不佳。本文旨在通过引入时间感知的监督对比学习，提升息肉计数的准确性和鲁棒性。

研究方法: 提出了一种监督对比损失函数，结合时间感知的软目标，捕捉息肉内部变化并保持息肉间的区分性；同时引入时间邻接约束，减少视觉相似但时间上远离的轨迹错误关联。

研究结果: 实验结果表明，该方法在公开数据集上实现了2.2倍的片段化率降低，显著优于现有方法，确立了新的最佳性能。

研究结论: 时间信息在息肉计数中至关重要，本文提出的方法通过时间感知的监督对比学习，显著提升了计数的准确性和鲁棒性。

中文摘要: 自动化结肠镜检查中的息肉计数是实现自动化报告和质量控制的关键步骤，旨在提高结肠镜检查的成本效益。息肉计数涉及检测和跟踪息肉，并将属于同一息肉的轨迹聚类。现有方法主要依赖自监督学习，仅利用视觉特征，忽略了轨迹特征学习和聚类阶段的时间关系。本文提出了一种范式转变，通过引入结合时间感知软目标的监督对比损失函数，捕捉息肉内部变化的同时保持息肉间的区分性，从而实现更鲁棒的聚类。此外，我们通过整合时间邻接约束改进了轨迹聚类，减少了视觉相似但时间上远离的轨迹的错误重新关联。我们在公开数据集上训练和验证了该方法，并使用留一交叉验证策略评估其性能。结果表明，与现有方法相比，片段化率降低了2.2倍。我们的结果突出了时间感知在息肉计数中的重要性，确立了新的最佳性能。代码可在https://github.com/lparolari/temporally-aware-polyp-counting获取。

</details>


### [76] [MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations](https://arxiv.org/abs/2507.02494)
**中文标题：MC-INR：基于元学习和聚类隐式神经表示的多变量科学模拟数据高效编码**

*Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong*

主要分类: cs.CV

摘要简述: MC-INR是一种基于元学习和聚类隐式神经表示的高效多变量科学模拟数据编码框架，解决了现有方法在复杂结构和多变量数据上的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有隐式神经表示（INR）方法在复杂结构、多变量数据和非结构化网格上的表现不佳，限制了其在实际科学数据编码中的应用。

研究方法: MC-INR结合元学习和聚类技术，引入残差动态重聚类机制和分支层，实现对复杂多变量数据的灵活编码。

研究结果: 实验表明，MC-INR在多变量科学数据编码任务中优于现有方法。

研究结论: MC-INR通过创新的元学习和聚类策略，显著提升了复杂科学数据的编码效率和灵活性。

中文摘要: 隐式神经表示（INR）被广泛用于将数据编码为连续函数，从而以较低的内存占用实现大规模多变量科学模拟数据的可视化。然而，现有的基于INR的方法存在三个主要局限性：（1）对复杂结构的表示不够灵活，（2）主要关注单变量数据，（3）依赖于结构化网格。因此，在处理复杂真实数据集时性能下降。为解决这些问题，我们提出了一种新颖的神经网络框架MC-INR，用于处理非结构化网格上的多变量数据。它结合元学习和聚类技术，实现对复杂结构的灵活编码。为进一步提升性能，我们引入了基于残差的动态重聚类机制，根据局部误差自适应地划分聚类。此外，我们还提出了一种分支层，通过独立分支同时利用多变量数据。实验结果表明，MC-INR在科学数据编码任务中优于现有方法。

</details>


### [77] [Automatic Labelling for Low-Light Pedestrian Detection](https://arxiv.org/abs/2507.02513)
**中文标题：低光照行人检测的自动标注方法**

*Dimitrios Bouzoulas,Eerik Alamikkotervo,Risto Ojala*

主要分类: cs.CV

摘要简述: 本研究提出了一种自动化的红外-RGB标注流程，用于低光照条件下的行人检测。通过红外检测、标签转移和模型训练，生成的自动标注在多个指标上优于人工标注。


<details>
  <summary>详细信息</summary>
研究动机: 低光照条件下的RGB行人检测缺乏公开数据集，本研究旨在通过自动化标注流程解决这一问题。

研究方法: 1) 使用微调的红外行人检测模型进行红外检测；2) 将红外检测结果转移到对应的RGB图像；3) 利用生成的标签训练低光照RGB行人检测模型。

研究结果: 在未见过的图像序列上，使用自动标注训练的模型在6/9的情况下（mAP@50和mAP@50-95指标）优于人工标注训练的模型。

研究结论: 自动化标注流程为低光照行人检测提供了高效解决方案，生成的标签质量优于人工标注。

中文摘要: RGB图像中的行人检测是行人安全的关键任务，因为RGB摄像头是自动驾驶车辆和高级驾驶辅助系统中最常见的传感器。低光照条件下的RGB行人检测缺乏公开数据集。为此，本研究提出了一种自动化的红外-RGB标注流程。该流程包括：1) 红外检测，使用微调的红外行人检测模型；2) 将红外检测结果转移到对应的RGB图像；3) 利用生成的标签训练低光照RGB行人检测模型。研究基于KAIST数据集进行。评估结果显示，在未见过的图像序列上，使用自动标注训练的模型在6/9的情况下（mAP@50和mAP@50-95指标）优于人工标注训练的模型。本研究的源代码可在https://github.com/BouzoulasDimitrios/IR-RGB-Automated-LowLight-Pedestrian-Labeling获取。

</details>


### [78] [Detecting Multiple Diseases in Multiple Crops Using Deep Learning](https://arxiv.org/abs/2507.02517)
**中文标题：使用深度学习检测多种作物中的多种疾病**

*Vivek Yadav,Anugrah Jain*

主要分类: cs.CV

摘要简述: 本文提出一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，旨在覆盖印度多样化的农业景观。通过构建包含17种作物和34种疾病的统一数据集，训练深度学习模型，其准确率达到99%，优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 印度作为农业经济为主的国家，面临作物因病害、虫害和环境压力导致的严重损失。早期准确检测不同作物的病害对提高产量和保障粮食安全至关重要。

研究方法: 研究首先构建了一个包含17种作物和34种疾病的统一数据集，随后训练深度学习模型。该模型在覆盖作物和疾病数量上优于现有技术。

研究结果: 模型在统一数据集上的检测准确率达到99%，比现有技术（覆盖14种作物和26种疾病）高出7%。

研究结论: 通过提升可检测的作物和疾病种类，该解决方案旨在为印度农民提供更有效的工具。

中文摘要: 印度作为以农业为主的经济体，在农业领域面临重大挑战，包括因病害、虫害和环境压力导致的严重作物损失。早期准确检测不同作物的病害对提高产量和保障粮食安全至关重要。本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，旨在覆盖印度多样化的农业景观。我们首先构建了一个包含17种作物和34种疾病的统一数据集，整合了多个可用资源中的图像。提出的深度学习模型在该数据集上训练，并在准确率和覆盖的作物、疾病数量上优于现有技术。我们的统一数据集检测准确率达到99%，比仅覆盖14种作物和26种疾病的现有技术高出7%。通过提升可检测的作物和疾病种类，该解决方案旨在为印度农民提供更好的产品。

</details>


### [79] [IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning](https://arxiv.org/abs/2507.02519)
**中文标题：IMASHRIMP：基于计算机视觉和深度学习的实验室图像中白虾（凡纳滨对虾）生物形态自动分析**

*Abiam Remache González,Meriem Chagour,Timon Bijan Rüth,Raúl Trapiella Cañedo,Marina Martínez Soler,Álvaro Lorenzo Felipe,Hyun-Suk Shin,María-Jesús Zamorano Serrano,Ricardo Torres,Juan-Antonio Castillo Parra,Eduardo Reyes Abad,Miguel-Ángel Ferrer Ballester,Juan-Manuel Afonso López,Francisco-Mario Hernández Tejera,Adrian Penate-Sanchez*

主要分类: cs.CV

摘要简述: IMASHRIMP是一种基于计算机视觉和深度学习的自动化白虾形态分析系统，通过改进的ResNet-50架构和VitPose姿态估计模块，显著减少了人工误差，提升了遗传选择效率。


<details>
  <summary>详细信息</summary>
研究动机: 水产养殖中白虾的形态分析对遗传选择至关重要，但传统方法依赖人工，误差率高且效率低。IMASHRIMP旨在通过自动化技术优化这一过程。

研究方法: 系统采用改进的ResNet-50架构进行图像视角分类和额角完整性检测，并利用VitPose模块预测23个关键点。支持向量机（SVM）模型用于将像素测量转换为厘米单位。

研究结果: 实验显示，系统将视角分类误差从0.97%降至0%，额角检测误差从12.46%降至3.64%，姿态估计平均精度达97.94%，像素到厘米的转换误差为0.07（±0.1）厘米。

研究结论: IMASHRIMP成功实现了白虾形态分析的自动化，显著提升了效率和准确性，为可持续水产养殖提供了技术支持。

中文摘要: 本文介绍了IMASHRIMP，一种用于自动化白虾（凡纳滨对虾）形态分析的系统，旨在优化水产养殖中的遗传选择任务。通过改进现有的深度学习和计算机视觉技术，解决了从RGBD图像分析虾形态的特定挑战。IMASHRIMP包含两个基于改进ResNet-50架构的判别模块，用于分类图像视角并确定额角完整性。系统提出了一种“双因素认证（人工与AI）”机制，将视角分类的人工误差从0.97%降至0%，额角检测误差从12.46%降至3.64%。此外，系统还采用了基于VitPose的姿态估计模块，预测虾骨架上的23个关键点，并为侧视图和背视图分别设计了网络。形态回归模块使用支持向量机（SVM）模型将像素测量转换为厘米单位。实验结果表明，系统有效减少了人工误差，姿态估计的平均精度（mAP）达到97.94%，像素到厘米的转换误差为0.07（±0.1）厘米。IMASHRIMP展示了自动化虾形态分析的潜力，提升了遗传选择效率，为可持续水产养殖做出了贡献。代码可在https://github.com/AbiamRemacheGonzalez/ImaShrimp-public获取。

</details>


### [80] [MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details](https://arxiv.org/abs/2507.02546)
**中文标题：MoGe-2：具有精确度量尺度和清晰细节的单目几何估计**

*Ruicheng Wang,Sicheng Xu,Yue Dong,Yu Deng,Jianfeng Xiang,Zelong Lv,Guangzhong Sun,Xin Tong,Jiaolong Yang*

主要分类: cs.CV

摘要简述: MoGe-2是一种先进的单目几何估计模型，能够从单张图像中恢复具有精确度量尺度的3D点地图，同时保持细节的清晰度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的单目几何估计方法（如MoGe）只能预测未知尺度的仿射不变点地图，无法提供度量尺度信息。此外，真实数据中的噪声和误差会降低几何细节的清晰度。因此，需要一种既能恢复精确度量尺度又能保持细节清晰的方法。

研究方法: MoGe-2基于MoGe方法，通过探索有效策略扩展为度量几何预测，同时保持仿射不变点表示的相对几何精度。此外，提出了一种统一的数据细化方法，利用锐利的合成标签过滤和补全来自不同来源的真实数据，显著提升重建几何的细节清晰度。

研究结果: 实验表明，MoGe-2在保持相对几何精度的同时，能够恢复精确的度量尺度和细粒度细节，其性能优于现有方法。

研究结论: MoGe-2成功实现了同时恢复精确相对几何、度量尺度和细节清晰度的目标，填补了现有方法的空白。

中文摘要: 我们提出了MoGe-2，这是一种先进的开放域几何估计模型，能够从单张图像中恢复具有度量尺度的3D点地图。我们的方法基于最近的单目几何估计方法MoGe，该方法预测具有未知尺度的仿射不变点地图。我们探索了有效策略，将MoGe扩展为度量几何预测，同时不损害仿射不变点表示提供的相对几何精度。此外，我们发现真实数据中的噪声和误差会降低预测几何的细粒度细节。为此，我们开发了一种统一的数据细化方法，利用锐利的合成标签过滤和补全来自不同来源的真实数据，显著提升了重建几何的细节清晰度，同时保持了整体精度。我们在混合数据集上训练了模型，并进行了全面评估，结果表明其在实现精确相对几何、精确度量尺度和细粒度细节恢复方面具有卓越性能——这是以往方法未能同时实现的能力。

</details>


### [81] [Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning](https://arxiv.org/abs/2507.02565)
**中文标题：基于外观和空间关系推理的近距离人体交互重建**

*Buzhen Huang,Chen Li,Chongyang Xu,Dongyue Lu,Jinnan Chen,Yangang Wang,Gim Hee Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种基于外观和空间关系的双分支优化框架，用于从复杂视频中重建准确的人体交互动作，克服了现有方法在视觉模糊和遮挡情况下的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人体姿态估计方法在视觉模糊和人际遮挡情况下难以恢复合理的近距离交互动作，即使是先进的模型（如SAM）也无法准确区分此类场景中的人体语义。因此，本文希望通过利用人类外观和空间关系来解决这一问题。

研究方法: 提出了一种双分支优化框架，结合扩散模型学习人类空间行为和姿态先验知识，并通过3D高斯、2D关键点和网格穿透等约束优化人体动作和外观重建。

研究结果: 实验结果表明，该方法在多个基准测试中优于现有方法，能够从复杂环境中捕获的视频中准确估计交互动作。

研究结论: 通过结合空间关系先验和多样化约束，本文方法能够有效重建复杂场景中的近距离人体交互动作，并为未来的姿态估计和行为理解研究提供了数据集支持。

中文摘要: 由于视觉模糊和人际遮挡，现有的人体姿态估计方法无法从真实视频中恢复合理的近距离交互动作。即使是当前最先进的大型基础模型（如SAM）也无法在此类挑战性场景中准确区分人体语义。本研究发现，人类外观可以提供直接的线索来解决这些问题。基于这一观察，我们提出了一种双分支优化框架，通过约束人类外观、社交空间关系和物理规律来重建准确的交互动作。具体而言，我们首先训练扩散模型以学习人类空间行为和姿态先验知识。随后，将训练好的网络和两个可优化张量整合到双分支优化框架中，以重建人体动作和外观。此外，还设计了基于3D高斯、2D关键点和网格穿透的约束来辅助优化。借助空间关系先验和多样化约束，我们的方法能够从复杂环境中捕获的视频中准确估计交互动作。我们还构建了一个带有伪真实交互注释的数据集，可能推动未来关于姿态估计和人类行为理解的研究。多个基准测试的实验结果表明，我们的方法优于现有方法。代码和数据可在https://www.buzhenhuang.com/works/CloseApp.html获取。

</details>


### [82] [Parametric shape models for vessels learned from segmentations via differentiable voxelization](https://arxiv.org/abs/2507.02576)
**中文标题：基于可微分体素化的分割学习血管参数化形状模型**

*Alina F. Dima,Suprosanna Shit,Huaqi Qiu,Robbie Holland,Tamara T. Mueller,Fabio Antonio Musio,Kaiyuan Yang,Bjoern Menze,Rickmer Braren,Marcus Makowski,Daniel Rueckert*

主要分类: cs.CV

摘要简述: 本文提出了一种通过可微分体素化从分割中学习血管参数化形状模型的框架，结合了体素、网格和参数化模型，实现了高保真度的血管几何捕捉。


<details>
  <summary>详细信息</summary>
研究动机: 血管是体内复杂结构，现有研究多采用体素化、网格或参数化模型，但这些表示通常独立使用。本文旨在通过可微分变换将三者结合，直接从分割中学习参数化形状模型，避免对真实形状参数的依赖。

研究方法: 通过可微分体素化，利用形状到分割的拟合自动提取血管的参数化形状模型。血管参数化为中心线和半径的三次B样条，确保平滑性和连续性。网格从学习到的形状参数中可微分提取，支持后拟合操作。

研究结果: 实验表明，该方法能准确捕捉复杂血管（如主动脉、动脉瘤和脑血管）的几何形状，生成高保真度的网格和体积拟合结果。

研究结论: 提出的框架成功将体素、网格和参数化模型结合，通过可微分体素化从分割中学习参数化形状模型，为血管研究提供了高效且灵活的工具。

中文摘要: 血管是体内复杂结构，已有多种表示方法研究。尽管体素化最为常见，但网格和参数化模型因其优良特性在多种应用中至关重要。然而，这些表示通常通过分割提取且彼此独立使用。我们提出了一种框架，通过可微分变换将三种表示结合。利用可微分体素化，我们通过形状到分割的拟合自动提取血管的参数化形状模型，无需依赖真实形状参数。血管通过三次B样条参数化为中心线和半径，确保平滑性和连续性。网格从学习到的形状参数中可微分提取，生成高保真度且可后拟合操作的网格。实验表明，我们的方法能准确捕捉复杂血管（如主动脉、动脉瘤和脑血管）的几何形状。

</details>


### [83] [Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning](https://arxiv.org/abs/2507.02581)
**中文标题：结构感知的语义差异与一致性在3D医学图像自监督学习中的应用**

*Tan Pan,Zhaorui Tan,Kaiyu Guo,Dongli Xu,Weidi Xu,Chen Jiang,Xin Guo,Yuan Qi,Yuan Cheng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为$S^2DC$的自监督学习框架，通过结构感知的语义差异和一致性，提升了3D医学图像的表征能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D医学图像自监督学习方法通常采用固定大小的图像块划分，忽略了解剖结构在位置、尺度和形态上的变化。这些变化对于捕捉有意义的区分至关重要。

研究方法: $S^2DC$框架通过两个步骤实现结构感知表征：1）利用最优传输策略增强不同图像块的语义差异；2）基于邻域相似性分布提升结构级别的语义一致性。

研究结果: 在10个数据集、4个任务和3种模态上的全面评估表明，$S^2DC$在自监督学习中优于现有方法。

研究结论: $S^2DC$通过结合块级别和结构级别的表征，实现了结构感知的表征学习，为医学图像分析提供了更有效的工具。

中文摘要: 3D医学图像自监督学习（mSSL）在医学分析中具有巨大潜力。为了更广泛地支持应用，需要考虑解剖结构在位置、尺度和形态上的变化，这些变化对于捕捉有意义的区分至关重要。然而，现有的mSSL方法通常采用固定大小的图像块划分，忽略了结构变化。本文提出了一种新的视角，旨在学习结构感知的表征。我们假设同一结构内的图像块具有相同的语义（语义一致性），而不同结构的图像块则表现出不同的语义（语义差异）。基于这一假设，我们提出了名为$S^2DC$的mSSL框架，通过两个步骤实现结构感知的语义差异和一致性：首先，$S^2DC$利用最优传输策略增强不同图像块的表征差异；其次，$S^2DC$基于邻域相似性分布提升结构级别的语义一致性。通过结合块级别和结构级别的表征，$S^2DC$实现了结构感知的表征学习。在10个数据集、4个任务和3种模态上的全面评估表明，$S^2DC$在自监督学习中优于现有方法。

</details>


### [84] [AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding](https://arxiv.org/abs/2507.02591)
**中文标题：AuroraLong：将RNN重新引入高效开放式视频理解**

*Weili Xu,Enxin Song,Wenhao Chai,Xuexiang Wen,Tian Ye,Gaoang Wang*

主要分类: cs.CV

摘要简述: 本文提出AuroraLong，通过用线性RNN语言模型替换MLLM中的LLM组件，解决长视频理解的高计算复杂性和内存成本问题，同时结合视觉令牌合并技术提升效率。


<details>
  <summary>详细信息</summary>
研究动机: 长视频理解的高计算复杂性和内存成本限制了其应用，尤其是基于Transformer的LLM因输入序列长度的二次方增长而效率低下。本文旨在通过线性RNN模型降低计算门槛，实现高效的长视频理解。

研究方法: AuroraLong采用线性RNN语言模型替代传统LLM，支持任意长度输入序列的恒定隐藏状态处理。通过视觉令牌按大小升序重排，结合视觉令牌合并技术，进一步提升吞吐量和效率。

研究结果: 尽管仅使用2B参数和公开数据训练，AuroraLong在多个视频基准测试中表现与基于Transformer的同类模型相当，展示了线性RNN在长视频理解中的潜力。

研究结论: AuroraLong证明了线性RNN在降低长视频理解计算门槛方面的有效性，为高效、开放式的视频理解提供了新思路。

中文摘要: 长视频理解的挑战在于其高计算复杂性和高昂的内存成本，因为基于Transformer的大型语言模型（LLM）所需的内存和计算随输入序列长度呈二次方增长。我们提出AuroraLong来解决这一问题，通过用线性RNN语言模型替换MLLM中的LLM组件，以恒定大小的隐藏状态处理任意长度的输入序列。为了进一步提升吞吐量和效率，我们通过按视觉令牌大小升序重排，将其与线性RNN模型结合。尽管仅使用2B参数并完全基于公开数据训练，AuroraLong在多个视频基准测试中表现与基于Transformer的同类模型相当。这表明高效的线性RNN有潜力通过降低计算门槛，使长视频理解更加普及。据我们所知，我们是首个在类似LLaVA的模型中采用基于线性RNN的LLM主干进行开放式视频理解的研究。

</details>


### [85] [Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development](https://arxiv.org/abs/2507.02602)
**中文标题：视觉导航中相机传感器故障的应对：模拟与数据集开发**

*Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill*

主要分类: cs.CV

摘要简述: 本文针对视觉导航中相机传感器故障问题，提出了一种模拟框架和数据集开发方法，以支持AI故障检测算法的训练与测试。


<details>
  <summary>详细信息</summary>
研究动机: 视觉导航算法在太空任务中的重要性日益增加，但传感器故障可能导致导航算法输出不准确甚至完全失效，影响任务目标。传统故障检测方法存在局限性，而AI虽能提供解决方案，却缺乏包含故障图像数据的代表性数据集。

研究方法: 研究通过分析行星探索任务中相机传感器的潜在故障案例，系统描述其成因、影响及常见缓解策略，并开发模拟框架以在合成图像中重现故障条件，生成故障注入图像数据集。

研究结果: 研究提出了一个故障注入图像数据集，为AI故障检测算法的训练和测试提供了重要工具。

研究结论: 通过模拟框架和数据集开发，本研究为视觉导航中相机传感器故障的检测与缓解提供了有效支持，推动了AI在太空任务中的应用。

中文摘要: 视觉导航算法在太空任务中的重要性日益凸显，但其可靠性和操作鲁棒性面临诸多挑战。传感器故障可能导致导航算法输出不准确甚至完全失效，从而危及任务目标。人工智能（AI）为解决此类故障提供了强大方案，克服了传统故障检测方法的许多局限性。然而，AI在此领域的应用主要障碍是缺乏足够且包含故障图像数据的代表性数据集。本研究针对行星探索任务场景，系统分析了视觉导航流程中相机传感器的潜在故障案例，包括其成因、对图像质量和导航算法性能的影响，以及常见缓解策略。为支持这一分析，研究引入了一个模拟框架，用于在合成图像中重现故障条件，从而系统且可控地生成故障数据。生成的故障注入图像数据集为训练和测试基于AI的故障检测算法提供了宝贵工具。最终数据集链接将在禁运期后公布，审稿人可通过私密链接访问。

</details>


### [86] [AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models](https://arxiv.org/abs/2507.02664)
**中文标题：AIGI-Holmes：基于多模态大语言模型的可解释且泛化性强的AI生成图像检测**

*Ziyin Zhou,Yunpeng Luo,Yuanchen Wu,Ke Sun,Jiayi Ji,Ke Yan,Shouhong Ding,Xiaoshuai Sun,Yunsheng Wu,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出AIGI-Holmes，一种基于多模态大语言模型的可解释且泛化性强的AI生成图像检测方法，通过构建大规模数据集Holmes-Set和三阶段训练框架Holmes Pipeline，解决了现有技术缺乏可解释性和泛化能力的问题。


<details>
  <summary>详细信息</summary>
研究动机: AI生成图像（AIGI）的滥用威胁公共信息安全，现有检测技术缺乏可解释性和对最新生成技术的泛化能力。本文旨在解决这些问题。

研究方法: 1) 构建Holmes-Set数据集，包括带解释的Holmes-SFTSet和人类偏好对齐的Holmes-DPOSet；2) 提出Multi-Expert Jury数据标注方法；3) 设计三阶段训练框架Holmes Pipeline，结合视觉专家预训练、监督微调和直接偏好优化；4) 引入协作解码策略增强泛化能力。

研究结果: 在三个基准测试上的广泛实验验证了AIGI-Holmes的有效性，其能够生成人类可验证且偏好对齐的解释，并具备更强的泛化能力。

研究结论: AIGI-Holmes通过多模态大语言模型和精心设计的数据集与训练框架，显著提升了AI生成图像检测的可解释性和泛化性。

中文摘要: AI生成内容（AIGC）技术的快速发展导致高度逼真的AI生成图像（AIGI）被滥用于传播虚假信息，威胁公共信息安全。尽管现有AIGI检测技术总体有效，但仍存在两个问题：1) 缺乏人类可验证的解释；2) 对最新生成技术缺乏泛化能力。为解决这些问题，我们引入了一个大规模综合数据集Holmes-Set，包括带解释的指令调优数据集Holmes-SFTSet和人类偏好对齐数据集Holmes-DPOSet。我们提出了一种高效的数据标注方法Multi-Expert Jury，通过结构化多模态大语言模型（MLLM）解释增强数据生成，并通过跨模型评估、专家缺陷过滤和人类偏好修改实现质量控制。此外，我们提出了Holmes Pipeline，一个精心设计的三阶段训练框架，包括视觉专家预训练、监督微调和直接偏好优化。Holmes Pipeline将MLLMs适配于AIGI检测，同时生成人类可验证且偏好对齐的解释，最终得到我们的模型AIGI-Holmes。在推理阶段，我们引入了一种协作解码策略，整合视觉专家的模型感知与MLLMs的语义推理，进一步增强了泛化能力。在三个基准测试上的广泛实验验证了AIGI-Holmes的有效性。

</details>


### [87] [Learning few-step posterior samplers by unfolding and distillation of diffusion models](https://arxiv.org/abs/2507.02686)
**中文标题：通过展开和蒸馏扩散模型学习少步后验采样器**

*Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra*

主要分类: cs.CV

摘要简述: 本文提出了一种新框架，通过深度展开和模型蒸馏将扩散模型（DMs）转化为用于后验采样的少步条件模型，结合了灵活性和高效性。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在贝叶斯计算成像中表现出强大的图像先验能力，但现有方法如Plug-and-Play依赖近似，而专用条件DMs需监督训练。本文旨在结合两者优势，开发一种灵活且高效的少步后验采样方法。

研究方法: 通过深度展开和模型蒸馏，将扩散模型转化为少步条件模型。核心创新是将LATINO Langevin采样器的马尔可夫链蒙特卡洛（MCMC）算法展开，首次将深度展开应用于蒙特卡洛采样方案。

研究结果: 实验表明，所提出的展开和蒸馏采样器在准确性和计算效率上优于现有技术，同时保持了适应前向模型变化的灵活性。

研究结论: 本文框架成功整合了扩散模型的灵活性和高效性，为后验采样提供了一种新的少步条件模型方法。

中文摘要: 扩散模型（DMs）已成为贝叶斯计算成像中强大的图像先验。现有两种主要策略：零射且高度灵活的Plug-and-Play方法（依赖近似）和通过监督训练实现更高精度和更快推理的专用条件DMs。本文提出了一种新框架，通过深度展开和模型蒸馏将DM图像先验转化为用于后验采样的少步条件模型。核心创新是将LATINO Langevin采样器的马尔可夫链蒙特卡洛（MCMC）算法展开，这是首次将深度展开应用于蒙特卡洛采样方案。通过大量实验与现有技术对比，所提出的展开和蒸馏采样器表现出优异的准确性和计算效率，同时保留了推理时适应前向模型变化的灵活性。

</details>


### [88] [APT: Adaptive Personalized Training for Diffusion Models with Limited Data](https://arxiv.org/abs/2507.02687)
**中文标题：APT：面向有限数据的扩散模型自适应个性化训练**

*JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang*

主要分类: cs.CV

摘要简述: 论文提出了一种名为APT的自适应个性化训练框架，用于解决扩散模型在有限数据下过拟合、丢失先验知识和文本对齐退化的问题。APT通过自适应训练调整、表示稳定化和注意力对齐三个关键组件，有效提升了模型在有限数据下的生成质量和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 在有限数据下个性化扩散模型时，过拟合、先验知识丢失和文本对齐退化是主要挑战。这些问题会导致噪声预测分布偏移，破坏去噪轨迹，使模型失去语义一致性。因此，需要一种方法在有限数据下保持模型性能。

研究方法: APT框架包含三个关键组件：1）自适应训练调整，通过过拟合指标检测每个时间步的过拟合程度，并应用自适应数据增强和损失加权；2）表示稳定化，通过正则化中间特征图的均值和方差防止噪声预测偏移；3）注意力对齐，通过对齐微调模型与预训练模型的交叉注意力图，保持先验知识和语义一致性。

研究结果: 实验表明，APT有效缓解了过拟合，保留了先验知识，并在有限参考数据下生成了高质量、多样化的图像，性能优于现有方法。

研究结论: APT通过自适应训练策略和表示正则化，成功解决了有限数据下扩散模型的过拟合问题，同时保持了先验知识和语义一致性，为个性化生成任务提供了有效解决方案。

中文摘要: 在有限数据下个性化扩散模型面临显著挑战，包括过拟合、先验知识丢失和文本对齐退化。过拟合会导致噪声预测分布偏移，破坏去噪轨迹，使模型失去语义一致性。本文提出自适应个性化训练（APT）框架，通过自适应训练策略和表示正则化缓解过拟合。APT包含三个关键组件：1）自适应训练调整，通过过拟合指标检测每个时间步的过拟合程度，并应用自适应数据增强和损失加权；2）表示稳定化，通过正则化中间特征图的均值和方差防止噪声预测偏移；3）注意力对齐，通过对齐微调模型与预训练模型的交叉注意力图，保持先验知识和语义一致性。实验表明，APT有效缓解了过拟合，保留了先验知识，并在有限参考数据下生成了高质量、多样化的图像，性能优于现有方法。

</details>


### [89] [CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation](https://arxiv.org/abs/2507.02691)
**中文标题：CanonSwap：通过规范空间调制实现高保真和一致的视频换脸**

*Xiangyang Luo,Ye Zhu,Yunfei Liu,Lijian Lin,Cong Wan,Zijian Cai,Shao-Lun Huang,Yu Li*

主要分类: cs.CV

摘要简述: CanonSwap提出了一种新的视频换脸框架，通过解耦面部外观和运动信息，在统一规范空间中进行身份修改，并重新整合到原始视频空间，以保持目标面部的动态属性。该方法在视觉质量、时间一致性和身份保持方面显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频换脸方法主要关注高质量的身份转移，但往往无法保持目标面部的动态属性（如头部姿势、表情、唇同步等），导致结果不一致。作者认为这是由于视频中面部外观和运动的固有耦合问题。

研究方法: CanonSwap通过消除与运动相关的信息，在规范空间中进行身份修改，然后重新整合到原始视频空间以保留动态属性。此外，设计了部分身份调制模块，通过空间掩码自适应集成源身份特征，限制修改仅针对面部区域。还引入了细粒度同步指标进行全面评估。

研究结果: 大量实验表明，CanonSwap在视觉质量、时间一致性和身份保持方面显著优于现有方法。

研究结论: CanonSwap通过解耦面部外观和运动信息，实现了高保真和一致的视频换脸效果，为视频换脸领域提供了新的解决方案。

中文摘要: 视频换脸旨在解决两个主要挑战：有效将源身份转移到目标视频，并准确保留目标面部的动态属性（如头部姿势、表情、唇同步等）。现有方法主要关注高质量的身份转移，但往往无法保持目标面部的动态属性，导致结果不一致。我们认为这是由于视频中面部外观和运动的固有耦合问题。为此，我们提出了CanonSwap，一种新颖的视频换脸框架，解耦了运动信息和外观信息。具体而言，CanonSwap首先消除与运动相关的信息，使身份修改在统一的规范空间中进行。随后，将交换后的特征重新整合到原始视频空间，确保目标面部的动态属性得以保留。为了进一步实现精确的身份转移并减少伪影、增强真实感，我们设计了一个部分身份调制模块，通过空间掩码自适应集成源身份特征，限制修改仅针对面部区域。此外，我们引入了多种细粒度同步指标，全面评估视频换脸方法的性能。大量实验表明，我们的方法在视觉质量、时间一致性和身份保持方面显著优于现有方法。项目页面公开在https://luoxyhappy.github.io/CanonSwap/。

</details>


### [90] [SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment](https://arxiv.org/abs/2507.02705)
**中文标题：SIU3R：超越特征对齐的同时场景理解与3D重建**

*Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu*

主要分类: cs.CV

摘要简述: SIU3R是一种无需特征对齐的框架，首次实现从未定位图像中同时进行3D重建和场景理解，通过像素对齐的3D表示和统一学习查询，显著提升了3D理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖2D到3D特征对齐，导致3D理解能力有限且语义信息丢失。SIU3R旨在通过无需对齐的框架解决这些问题，实现更高效的端到端智能系统。

研究方法: SIU3R通过像素对齐的3D表示桥接重建与理解任务，并将多任务统一为一组可学习查询。此外，设计了两个轻量模块促进任务间协作。

研究结果: 实验表明，SIU3R在3D重建、场景理解及两者同时任务上均达到最先进性能，验证了其框架和协作设计的有效性。

研究结论: SIU3R通过无需对齐的框架和任务协作设计，显著提升了3D重建与场景理解的性能，为端到端智能系统提供了新思路。

中文摘要: 同时进行场景理解和3D重建在开发端到端智能系统中至关重要。现有方法依赖2D到3D特征对齐，导致3D理解能力有限和语义信息丢失。为此，我们提出SIU3R，首个无需对齐的通用框架，从未定位图像中实现同时理解和3D重建。SIU3R通过像素对齐的3D表示桥接重建与理解任务，并将多任务统一为一组可学习查询，无需依赖2D模型对齐即可实现原生3D理解。为促进任务协作，我们深入分析其相互优势，并设计两个轻量模块以优化交互。大量实验表明，SIU3R不仅在3D重建和场景理解单任务上表现优异，在同时任务上也达到最先进水平，凸显了其无需对齐框架和协作设计的优势。

</details>


### [91] [UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation](https://arxiv.org/abs/2507.02713)
**中文标题：UniMC：驯服扩散变换器以实现统一的关键点引导多类别图像生成**

*Qin Guo,Ailing Zeng,Dongxu Yue,Ceyuan Yang,Yang Cao,Hanzhong Guo,Fei Shen,Wei Liu,Xihui Liu,Dan Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为UniMC的DiT框架，用于统一多类别关键点引导的图像生成，并发布了HAIG-2.9M数据集，解决了现有方法在非刚性物体和多类别重叠生成中的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有主流关键点引导模型在生成非刚性物体（如动物）和多类别重叠对象时存在困难，主要受限于现有控制方法的固有缺陷和缺乏合适的数据集。

研究方法: 设计了基于DiT的UniMC框架，将实例和关键点条件整合为紧凑令牌，并发布了HAIG-2.9M数据集，包含丰富的标注和严格的人工检查。

研究结果: 实验表明HAIG-2.9M数据集质量高，UniMC在严重遮挡和多类别场景中表现优异。

研究结论: UniMC和HAIG-2.9M为关键点引导的多类别图像生成提供了有效解决方案。

中文摘要: 尽管关键点引导的文本到图像扩散模型取得了显著进展，但现有主流模型在控制生成更一般的非刚性物体（如动物）方面仍面临挑战。此外，仅依赖关键点控制难以生成多个重叠的人类和动物。这些挑战源于现有可控方法的固有局限性和缺乏合适的数据集。首先，我们设计了一个基于DiT的框架UniMC，探索统一可控的多类别图像生成。UniMC将实例和关键点条件整合为紧凑令牌，包含类别、边界框和关键点坐标等属性。这种方法克服了先前方法因依赖骨架图像作为条件而难以区分实例和类别的局限性。其次，我们提出了HAIG-2.9M，一个大规模、高质量且多样化的数据集，专为关键点引导的人类和动物图像生成设计。HAIG-2.9M包含786K图像和2.9M实例，具有丰富的标注（如关键点、边界框和细粒度描述），并通过严格的人工检查确保标注准确性。大量实验证明了HAIG-2.9M的高质量和UniMC的有效性，尤其是在严重遮挡和多类别场景中。

</details>


### [92] [FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models](https://arxiv.org/abs/2507.02714)
**中文标题：FairHuman：基于最小潜在延迟公平性的扩散模型中提升人像手部和面部生成质量**

*Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma*

主要分类: cs.CV

摘要简述: FairHuman提出了一种多目标微调方法，通过最小潜在延迟公平性准则优化生成模型，显著提升人像生成中手部和面部的细节质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散模型的人像生成在局部细节（如手部和面部）上表现不佳，主要原因是训练过程中对局部区域的监督不足。FairHuman旨在通过多目标优化方法公平提升全局和局部生成质量。

研究方法: FairHuman构建了三个学习目标：一个全局目标（基于默认扩散目标函数）和两个局部目标（基于预标注的手部和面部位置先验）。随后，采用最小潜在延迟（MPD）准则优化参数更新策略，实现多目标问题的公平优化。

研究结果: 实验表明，FairHuman在保持整体生成质量的同时，显著提升了手部和面部等挑战性细节的生成效果，适用于多种场景。

研究结论: FairHuman通过多目标优化和MPD准则，有效解决了人像生成中局部细节质量不足的问题，为扩散模型的改进提供了新思路。

中文摘要: 随着大规模文本到图像模型的发展，尤其是基于扩散的模型，图像生成取得了显著进展。然而，由于训练过程中对局部区域的监督不足，生成具有合理细节（如面部或手部）的人像仍然具有挑战性。为解决这一问题，我们提出了FairHuman，一种多目标微调方法，旨在公平地提升全局和局部生成质量。具体而言，我们首先构建了三个学习目标：一个源自默认扩散目标函数的全局目标，以及基于预标注位置先验的手部和面部两个局部目标。随后，我们在最小潜在延迟（MPD）准则的指导下推导出最优参数更新策略，从而实现了这一多目标问题的公平优化。基于此，我们提出的方法在保持整体质量的同时，显著提升了挑战性局部细节的生成效果。大量实验证明了我们的方法在不同场景下提升人像生成性能的有效性。

</details>


### [93] [Prompt learning with bounding box constraints for medical image segmentation](https://arxiv.org/abs/2507.02743)
**中文标题：基于边界框约束的提示学习用于医学图像分割**

*Mélanie Gaillochet,Mehrdad Noori,Sahar Dastani,Christian Desrosiers,Hervé Lombaert*

主要分类: cs.CV

摘要简述: 本文提出了一种结合基础模型表示能力和弱监督分割标注效率的新框架，通过仅使用边界框标注自动生成提示，优化方案整合了边界框约束和伪标签，实验表明该方法在有限数据下优于全监督和弱监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割中像素级标注成本高昂，弱监督方法基于更易获取的边界框标注提供了一种实用替代方案。现有提示学习方法依赖全标注分割掩码，本文旨在结合基础模型和弱监督分割的优势，减少用户干预。

研究方法: 提出一种新框架，利用边界框标注自动生成基础模型的提示，优化方案整合了边界框约束和基础模型生成的伪标签。

研究结果: 在多模态数据集上的实验显示，该方法在有限数据设置下平均Dice分数达到84.90%，优于现有全监督和弱监督方法。

研究结论: 本文方法成功结合了基础模型的表示能力和弱监督分割的标注效率，显著提升了医学图像分割的性能，减少了标注成本。

中文摘要: 在医学领域，像素级标注的获取既耗时又昂贵。为减轻这一负担，基于边界框标注的弱监督方法提供了一种更实用的替代方案。最近，视觉基础模型在提供点或边界框等提示时表现出显著的分割性能。提示学习通过将这些模型适应下游任务并自动化分割，减少了用户干预。然而，现有的提示学习方法依赖于全标注分割掩码。本文提出了一种新框架，结合了基础模型的表示能力和弱监督分割的标注效率。具体而言，我们的方法仅使用边界框标注自动生成基础模型的提示。提出的优化方案整合了边界框标注的多种约束和基础模型生成的伪标签。在多模态数据集上的广泛实验表明，我们的弱监督方法在有限数据设置下平均Dice分数达到84.90%，优于现有的全监督和弱监督方法。代码可在https://github.com/Minimel/box-prompt-learning-VFM.git获取。

</details>


### [94] [DexVLG: Dexterous Vision-Language-Grasp Model at Scale](https://arxiv.org/abs/2507.02747)
**中文标题：DexVLG：大规模灵巧视觉-语言-抓取模型**

*Jiawei He,Danshi Li,Xinqiang Yu,Zekun Qi,Wenyao Zhang,Jiayi Chen,Zhaoxiang Zhang,Zhizheng Zhang,Li Yi,He Wang*

主要分类: cs.CV

摘要简述: 本文提出DexVLG模型，通过大规模数据集DexGraspNet 3.0训练，实现了基于语言指令的单视角RGBD输入下的灵巧抓取姿态预测，并在仿真和实际场景中展示了优异的零样本泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉-语言-动作（VLA）系统主要局限于简单夹爪控制，缺乏针对类人灵巧手的功能性抓取研究。本文旨在填补这一空白，通过大规模数据集和模型训练，实现语言指令对齐的灵巧抓取。

研究方法: 生成包含1.7亿灵巧抓取姿态的大规模数据集DexGraspNet 3.0，覆盖17.4万个物体的语义部分，并配以详细部件级描述。基于此数据集训练视觉语言模型（VLM）和基于流匹配的姿态预测头，实现语言对齐的抓取姿态生成。

研究结果: DexVLG在仿真中零样本执行成功率超过76%，部件抓取准确率领先，并在实际场景中成功实现部件对齐的抓取。

研究结论: DexVLG展示了强大的零样本泛化能力，为灵巧手的语言指令抓取任务提供了有效解决方案。

中文摘要: 随着大模型的兴起，视觉-语言-动作（VLA）系统正使机器人能够处理日益复杂的任务。然而，受限于数据收集的难度，现有研究主要集中在简单夹爪末端执行器的控制上，针对类人灵巧手的功能性抓取研究较少。本文提出DexVLG，一种基于单视角RGBD输入、语言指令对齐的灵巧抓取姿态预测大模型。为此，我们在仿真中生成了包含1.7亿灵巧抓取姿态的数据集DexGraspNet 3.0，覆盖17.4万个物体的语义部分，并配以详细部件级描述。利用这一大规模数据集，我们训练了一个视觉语言模型（VLM）和基于流匹配的姿态预测头，能够为桌面物体生成语言对齐的抓取姿态。为评估DexVLG的性能，我们在基于物理的仿真中创建了基准测试，并进行了实际场景实验。大量测试表明，DexVLG具有强大的零样本泛化能力——在仿真中零样本执行成功率超过76%，部件抓取准确率领先，并在实际场景中成功实现部件对齐的抓取。

</details>


### [95] [Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics](https://arxiv.org/abs/2507.02748)
**中文标题：全局上下文线性注意力：一种用于视觉与物理的多极注意力机制**

*Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MANO的多极注意力机制，通过距离多尺度计算注意力，实现线性复杂度，适用于高分辨率输入，性能媲美ViT和Swin Transformer，同时大幅降低计算资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer在处理高分辨率输入时存在二次复杂度问题，导致计算资源消耗过大。本文受n体数值模拟技术启发，试图通过多尺度注意力机制解决这一问题。

研究方法: 提出多极注意力神经算子（MANO），将注意力建模为网格点间的交互问题，采用距离多尺度计算方式，保持全局感受野的同时实现线性复杂度。

研究结果: 在图像分类和Darcy流实验中，MANO性能与ViT和Swin Transformer相当，但运行时间和峰值内存消耗显著降低。

研究结论: MANO通过多尺度注意力机制有效解决了高分辨率输入的计算资源问题，为视觉和物理任务提供了一种高效解决方案。

中文摘要: Transformer已成为从图像分类到物理模拟等多种任务的实际标准。尽管其性能卓越，但标准Transformer在输入长度上的二次复杂度使其难以处理高分辨率输入。为此，已有多种改进方法提出，最成功的依赖于分块、降采样或粗化技术，但往往以丢失最精细尺度细节为代价。本文采用了一种不同的方法。受n体数值模拟技术的启发，我们将注意力建模为网格点间的交互问题，提出了多极注意力神经算子（MANO），以距离多尺度方式计算注意力。MANO在每个注意力头中保持全局感受野，并实现与网格点数成线性关系的时间和内存复杂度。在图像分类和Darcy流实验中的结果表明，MANO与ViT和Swin Transformer等先进模型性能相当，同时将运行时间和峰值内存消耗降低了数个数量级。我们开源了代码以促进可复现性：https://github.com/AlexColagrande/MANO。

</details>


### [96] [Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2507.02751)
**中文标题：部分弱监督定向目标检测**

*Mingxin Liu,Peiyuan Zhang,Yuan Liu,Wei Zhang,Yue Zhou,Ning Liao,Ziyang Gong,Junwei Luo,Zhirui Wang,Yi Yu,Xue Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于部分弱标注（水平框或单点）的部分弱监督定向目标检测（PWOOD）框架，显著降低了标注成本，并在多个数据集上表现优于传统半监督算法。


<details>
  <summary>详细信息</summary>
研究动机: 定向目标检测（OOD）在各领域的应用需求增长，但高成本的标注成为主要问题。现有方法（全监督、半监督、弱监督）在标注速度或成本上存在不足，亟需一种低成本高效的解决方案。

研究方法: 1. 提出PWOOD框架，利用部分弱标注（水平框或单点）高效利用未标注数据；2. 设计OS-Student模型，仅需少量方向或尺度无关的弱标注即可学习定向和尺度信息；3. 引入CPF策略，降低模型对静态过滤阈值的敏感性。

研究结果: 在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的实验表明，PWOOD框架性能与传统半监督算法相当甚至更优，同时显著降低了标注成本。

研究结论: PWOOD框架为定向目标检测提供了一种低成本高效的解决方案，显著优于现有弱监督方法，并具有广泛的应用潜力。

中文摘要: 定向目标检测（OOD）在各领域的应用需求不断增长，但数据集标注的高成本仍是主要问题。当前主流OOD算法主要分为三类：（1）使用完整定向边界框（OBB）标注的全监督方法，（2）使用部分OBB标注的半监督方法，（3）使用水平框或点等弱标注的弱监督方法。然而，这些方法在标注速度或成本上不可避免地增加了模型负担。为解决这一问题，我们提出：（1）首个基于部分弱标注（水平框或单点）的部分弱监督定向目标检测（PWOOD）框架，可高效利用大量未标注数据，显著优于基于部分弱标注训练的弱监督算法，同时提供更低成本的解决方案；（2）OS-Student模型，仅需少量方向或尺度无关的弱标注即可学习定向和尺度信息；（3）类别无关的伪标签过滤策略（CPF），降低模型对静态过滤阈值的敏感性。在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的全面实验表明，PWOOD框架性能与传统半监督算法相当甚至更优。

</details>


### [97] [From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images](https://arxiv.org/abs/2507.02781)
**中文标题：从像素到损害严重程度：利用社交媒体图像的语义分割评估地震影响**

*Danrong Zhang,Huili Huang,N. Simrill Smith,Nimisha Roy,J. David Frost*

主要分类: cs.CV

摘要简述: 该研究提出了一种基于语义分割的方法，通过分析社交媒体图像来评估地震后的损害严重程度，并引入新的评分系统，为灾害侦察提供更客观和全面的指导。


<details>
  <summary>详细信息</summary>
研究动机: 传统的地震损害评估方法依赖分类，主观性强且无法区分图像中不同程度的损害。本研究旨在通过语义分割技术，提供更客观和细化的损害分析。

研究方法: 研究构建了一个包含未受损结构、受损结构和废墟的分割数据集，并微调SegFormer模型进行语义分割。同时引入新的损害评分系统，结合深度估计量化损害严重程度。

研究结果: 该方法能够更客观地量化社交媒体图像中的损害程度，为灾害侦察团队提供精确的损害分布信息，从而优化应急响应。

研究结论: 通过语义分割和新的评分系统，研究实现了对地震损害更全面和客观的评估，提升了灾害侦察的效率和针对性。

中文摘要: 地震后，社交媒体图像成为灾害侦察的重要资源，能够快速反映损害程度。传统的损害评估方法多基于分类，主观性强且无法区分图像中不同程度的损害。为解决这一问题，本研究将损害评估问题转化为语义分割任务，旨在更客观地分析地震影响区域的损害。方法包括构建一个分割数据集，将损害分为未受损结构、受损结构和废墟三类，并微调SegFormer模型对社交媒体图像进行损害分割。此外，研究还引入新的损害评分系统，通过结合深度估计量化图像中不同区域的损害程度。该方法能够更客观、全面地量化社交媒体图像中的损害严重程度，为灾害侦察团队提供更精确的指导，从而优化地震后的应急响应。

</details>


### [98] [RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation](https://arxiv.org/abs/2507.02792)
**中文标题：RichControl：面向文本到图像生成的结构与外观丰富的免训练空间控制方法**

*Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的文本到图像生成方法RichControl，通过解耦特征注入时间步与去噪过程，结合结构丰富和外观丰富的设计，显著提升了生成图像的结构对齐和视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到图像扩散模型在结合条件图像（如深度或姿态图）时，常因特征注入同步性问题导致结构错位、条件泄漏和视觉伪影。本文旨在解决这些问题，提出一种更灵活的特征注入框架。

研究方法: 1. 提出结构丰富的注入模块，解耦特征注入时间步与去噪过程；2. 引入外观丰富的提示和重启细化策略，增强外观控制和视觉质量。

研究结果: 实验表明，RichControl在多样化的零样本条件下实现了最先进的性能，生成图像在结构和外观上均表现出色。

研究结论: RichControl通过灵活的特征注入和优化策略，实现了无需训练的高质量图像生成，为文本到图像模型提供了更精细的空间控制能力。

中文摘要: 文本到图像（T2I）扩散模型在从文本提示生成高质量图像方面取得了显著成功。最近的研究将这些模型扩展到结合条件图像（如深度或姿态图）以实现细粒度空间控制。其中，特征注入方法作为一种免训练的替代方案，逐渐取代传统的微调方法。然而，这些方法常因结构错位、条件泄漏和视觉伪影而受限，尤其是当条件图像与自然RGB分布差异较大时。通过重新审视现有方法，我们发现一个核心限制：同步注入条件特征未能权衡去噪过程中的域对齐与结构保留。受此启发，我们提出了一种灵活的特征注入框架，将注入时间步与去噪过程解耦。其核心是一个结构丰富的注入模块，使模型能够更好地适应扩散步骤中对齐与结构保留的动态平衡，从而生成更忠实于结构的图像。此外，我们引入了外观丰富的提示和重启细化策略，进一步增强了外观控制和视觉质量。这些设计共同实现了免训练的、结构与外观均丰富的生成。大量实验表明，我们的方法在多样化的零样本条件下均达到了最先进的性能。

</details>


### [99] [No time to train! Training-Free Reference-Based Instance Segmentation](https://arxiv.org/abs/2507.02798)
**中文标题：无需训练！基于参考的实例分割方法**

*Miguel Espinosa,Chenhongyi Yang,Linus Ericsson,Steven McDonagh,Elliot J. Crowley*

主要分类: cs.CV

摘要简述: 本文提出一种无需训练的参考图像实例分割方法，利用基础模型的语义先验知识，通过多阶段流程自动生成实例级分割掩码，显著提升分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像分割模型依赖大量标注数据，而SAM模型虽减轻了这一问题，但仍需手动视觉提示或复杂规则。本文旨在通过少量参考图像实现对象分割，减少人工负担。

研究方法: 采用多阶段无训练方法，包括（1）记忆库构建；（2）表示聚合；（3）语义感知特征匹配，利用基础模型的语义先验知识生成分割掩码。

研究结果: 在COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）和跨域FSOD基准（22.4% nAP）上取得显著提升，优于现有无训练方法。

研究结论: 通过利用基础模型的语义先验知识，本文方法在无需训练的情况下实现了高性能的实例分割，为下游任务提供了高效解决方案。

中文摘要: 图像分割模型的性能历来受限于大规模标注数据的高成本。Segment Anything Model（SAM）通过可提示、语义无关的分割范式缓解了这一问题，但仍需手动视觉提示或复杂的领域相关提示生成规则来处理新图像。为减轻这一负担，本文研究了在仅提供少量参考图像时的对象分割任务。关键思路是利用基础模型学习的强语义先验知识，识别参考图像与目标图像之间的对应区域。研究发现，这些对应关系能够为下游任务自动生成实例级分割掩码，并通过多阶段无训练方法实现，包括（1）记忆库构建；（2）表示聚合；（3）语义感知特征匹配。实验表明，该方法在分割指标上显著提升，在COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）上达到领先性能，并在跨域FSOD基准（22.4% nAP）上优于现有无训练方法。

</details>


### [100] [HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars](https://arxiv.org/abs/2507.02803)
**中文标题：HyperGaussians：基于高维高斯泼溅的高保真可动画人脸化身技术**

*Gent Serifi,Marcel C. Bühler*

主要分类: cs.CV

摘要简述: 本文提出HyperGaussians，一种基于高维多变量高斯分布的新型3D高斯泼溅技术，用于高质量可动画人脸化身，显著提升高频细节表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D高斯泼溅技术在静态人脸渲染中表现优异，但在可动画化人脸化身中仍存在非线性变形、复杂光照和细节不足的问题。本文旨在通过扩展高斯表示维度提升表达能力。

研究方法: 提出HyperGaussians，将3D高斯扩展为高维多变量高斯，并通过可学习的局部嵌入增强表达能力。为解决高维协方差矩阵计算效率问题，引入‘逆协方差技巧’重新参数化矩阵。

研究结果: 在4个数据集上的19名受试者测试中，HyperGaussians在数值和视觉上均优于传统3D高斯泼溅技术，尤其在眼镜框、牙齿、复杂面部动作和镜面反射等高频细节上表现突出。

研究结论: HyperGaussians通过高维高斯表示和逆协方差技巧，显著提升了可动画人脸化身的渲染质量，为增强现实和虚拟现实应用提供了更优解决方案。

中文摘要: 我们提出HyperGaussians，一种用于高质量可动画人脸化身的3D高斯泼溅技术扩展。从视频中创建此类详细人脸化身是一个具有挑战性的问题，并在增强和虚拟现实中有广泛应用。尽管静态人脸渲染已取得巨大成功，但基于单目视频的可动画化身仍存在‘恐怖谷’效应。当前标准技术3D高斯泼溅（3DGS）通过一组3D高斯基元表示人脸，擅长渲染静态人脸，但在非线性变形、复杂光照和细节表现上仍有不足。大多数相关研究专注于从表情代码预测更好的高斯参数，而我们重新思考了3D高斯表示本身及其表达能力。我们的见解促使将3D高斯扩展为高维多变量高斯，称为‘HyperGaussians’。高维度通过可学习的局部嵌入提升了表达能力，但其泼溅计算成本高昂，因需反转高维协方差矩阵。我们通过‘逆协方差技巧’重新参数化矩阵解决了这一问题，显著提升效率，使HyperGaussians可无缝集成到现有模型中。为验证其效果，我们将HyperGaussians应用于当前最快的单目人脸化身技术FlashAvatar。在4个数据集的19名受试者测试中，HyperGaussians在数值和视觉上均优于3DGS，尤其在眼镜框、牙齿、复杂面部动作和镜面反射等高频细节上表现更优。

</details>


### [101] [LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion](https://arxiv.org/abs/2507.02813)
**中文标题：LangScene-X：基于TriMap视频扩散的可泛化3D语言嵌入场景重建**

*Fangfu Liu,Hao Li,Jiawei Chi,Hanyang Wang,Minghui Yang,Fudong Wang,Yueqi Duan*

主要分类: cs.CV

摘要简述: 本文提出LangScene-X框架，通过TriMap视频扩散模型和语言量化压缩器（LQC），从稀疏视图重建可泛化的3D语言嵌入场景，解决了传统方法在稀疏视图下的渲染和语义合成问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法依赖密集视图重建3D场景，导致在稀疏视图下出现渲染伪影和语义合成不准确的问题。本文旨在通过生成一致的多模态信息，实现稀疏视图下的高质量3D重建和开放词汇场景理解。

研究方法: 1. 训练TriMap视频扩散模型，从稀疏输入生成RGB、法线和语义分割图；2. 提出语言量化压缩器（LQC），在大规模图像数据集上训练，实现跨场景语言嵌入；3. 将语言信息对齐到3D场景表面，支持开放词汇查询。

研究结果: 实验表明，LangScene-X在真实数据上优于现有方法，重建质量和泛化能力显著提升。

研究结论: LangScene-X通过生成一致的多模态信息和高效的语言嵌入，实现了稀疏视图下的高质量3D语言嵌入场景重建，为开放词汇场景理解提供了新思路。

中文摘要: 从2D图像中恢复具有开放词汇场景理解的3D结构是一项基础但具有挑战性的任务。现有方法通过嵌入语言信息进行逐场景优化，但依赖密集视图重建范式，在稀疏视图下会出现严重的渲染伪影和语义合成不准确。本文提出了一种新的生成框架LangScene-X，通过统一生成3D一致的多模态信息，实现稀疏视图下的可泛化3D语言嵌入场景重建。具体而言，我们首先训练TriMap视频扩散模型，通过渐进知识整合从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）。此外，提出语言量化压缩器（LQC），在大规模图像数据集上训练，高效编码语言嵌入，实现跨场景泛化而无需逐场景重新训练。最后，通过将语言信息对齐到3D场景表面，重建语言表面场，支持开放词汇查询。真实数据的广泛实验表明，LangScene-X在质量和泛化能力上优于现有方法。项目页面：https://liuff19.github.io/LangScene-X。

</details>


### [102] [Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach](https://arxiv.org/abs/2507.02826)
**中文标题：基于置信度驱动梯度调制的多模态人类活动识别：一种动态对比双路径学习方法**

*Panpan Ji,Junni Song,Hang Xiao,Hanyu Liu,Chao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架，用于解决多模态人类活动识别中的跨模态特征对齐和模态贡献不平衡问题。该框架通过双路径特征提取、多阶段对比学习和置信度驱动的梯度调制策略，显著提升了识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态人类活动识别（HAR）系统面临跨模态特征对齐困难和模态贡献不平衡等关键挑战。本文旨在通过动态调整学习强度和优化特征对齐，提升多模态HAR的性能。

研究方法: 1. 采用双路径特征提取架构（ResNet和DenseNet分支）处理多模态传感器数据；2. 引入多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；3. 提出置信度驱动的梯度调制策略，动态调整各模态分支的学习强度；4. 采用基于动量的梯度累积策略增强训练稳定性。

研究结果: 在四个公共基准数据集上的实验表明，DCDP-HAR框架显著提升了多模态HAR的性能。消融研究验证了各模块的有效性。

研究结论: DCDP-HAR框架通过动态对比学习和梯度调制策略，有效解决了多模态HAR中的特征对齐和模态竞争问题，为智能系统的环境感知提供了新思路。

中文摘要: 基于传感器的人类活动识别（HAR）是智能系统感知和交互环境的核心技术。然而，多模态HAR系统仍面临跨模态特征对齐困难和模态贡献不平衡等关键挑战。为解决这些问题，我们提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架。该框架包含三个关键组件：首先，采用双路径特征提取架构，其中ResNet和DenseNet分支协同处理多模态传感器数据；其次，引入多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；第三，提出置信度驱动的梯度调制策略，动态监控和调整各模态分支在反向传播中的学习强度，有效缓解模态竞争。此外，采用基于动量的梯度累积策略以增强训练稳定性。我们通过消融研究验证了各组件的有效性，并在四个公共基准数据集上进行了广泛的对比实验。

</details>


### [103] [USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network](https://arxiv.org/abs/2507.02827)
**中文标题：USAD：一种无监督数据增强时空注意力扩散网络**

*Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为USAD的无监督数据增强时空注意力扩散网络，用于解决人类活动识别（HAR）中标签数据稀缺、特征提取不足及轻量设备性能不佳的问题。通过无监督数据增强、多分支时空交互网络和自适应多损失函数融合，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 人类活动识别（HAR）在健康监测、安全防护等领域应用广泛，但面临标签数据稀缺、高级特征提取不足及轻量设备性能不佳等挑战。本文旨在通过优化方法解决这些问题。

研究方法: 1. 使用无监督统计引导扩散模型进行数据增强；2. 设计多分支时空交互网络，通过并行残差分支捕获多尺度特征；3. 引入时空注意力机制和跨分支特征融合单元；4. 采用自适应多损失函数融合策略动态调整权重。

研究结果: 在WISDM、PAMAP2和OPPORTUNITY数据集上，USAD分别达到98.84%、93.81%和80.92%的准确率，显著优于现有方法，并在嵌入式设备上验证了高效性。

研究结论: USAD通过无监督数据增强和时空注意力机制，显著提升了HAR的性能和轻量设备适应性，为实际应用提供了有效解决方案。

中文摘要: 人类活动识别（HAR）的主要目标是从传感器数据中推断人类行为，广泛应用于健康监测、安全防护和运动分析等领域。尽管研究众多，HAR仍面临标签样本稀缺、高级特征提取不足及轻量设备性能不佳等挑战。为此，本文提出了一种基于多注意力交互机制的优化方法。首先，采用无监督统计引导扩散模型进行数据增强，缓解标签数据稀缺和类别不平衡问题；其次，设计多分支时空交互网络，通过并行残差分支（3*3、5*5和7*7卷积核）捕获多尺度序列特征，并引入时空注意力机制以识别关键时间点和增强传感器间交互；进一步通过跨分支特征融合单元提升特征表示能力；最后，集成自适应多损失函数融合策略，动态调整损失权重以优化模型。在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上的实验表明，所提无监督数据增强时空注意力扩散网络（USAD）分别达到98.84%、93.81%和80.92%的准确率，显著优于现有方法。此外，嵌入式设备上的实际部署验证了该方法的效率和可行性。

</details>


### [104] [AnyI2V: Animating Any Conditional Image with Motion Control](https://arxiv.org/abs/2507.02857)
**中文标题：AnyI2V：通过运动控制为任意条件图像生成动画**

*Ziye Li,Hao Luo,Xincheng Shuai,Henghui Ding*

主要分类: cs.CV

摘要简述: AnyI2V是一种无需训练的框架，能够通过用户定义的运动轨迹为任意条件图像生成动画，支持多种模态输入，并实现风格迁移和编辑。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到视频（T2V）和图像到视频（I2V）方法在动态运动信号和空间约束的整合上存在不足，T2V缺乏对生成内容空间布局的精确控制，而I2V受限于真实图像的依赖性。AnyI2V旨在解决这些问题，提供更灵活的视频生成方案。

研究方法: AnyI2V提出了一种无需训练的框架，支持多种模态的条件图像输入（如网格和点云），并通过用户定义的运动轨迹生成动画。此外，它还支持混合条件输入，并利用LoRA和文本提示实现风格迁移和编辑。

研究结果: 实验表明，AnyI2V在空间和运动控制的视频生成中表现优异，支持更灵活的输入和编辑功能，为视频生成提供了新的视角。

研究结论: AnyI2V通过无需训练的方法实现了对任意条件图像的动画生成，支持多种模态输入和编辑功能，为视频生成领域提供了更高效和灵活的解决方案。

中文摘要: 近年来，视频生成领域（尤其是扩散模型）在文本到视频（T2V）和图像到视频（I2V）合成方面取得了显著进展。然而，如何有效整合动态运动信号和灵活的空间约束仍面临挑战。现有的T2V方法通常依赖文本提示，这导致对生成内容空间布局的精确控制不足；而I2V方法则受限于对真实图像的依赖，限制了合成内容的可编辑性。尽管部分方法通过引入ControlNet实现了基于图像的条件控制，但它们往往缺乏明确的运动控制，且需要昂贵的计算训练。为解决这些问题，我们提出了AnyI2V，一种无需训练的框架，能够通过用户定义的运动轨迹为任意条件图像生成动画。AnyI2V支持更广泛的模态作为条件图像，包括ControlNet不支持的网格和点云等数据类型，从而实现了更灵活和多样化的视频生成。此外，它还支持混合条件输入，并通过LoRA和文本提示实现风格迁移和编辑。大量实验表明，AnyI2V在空间和运动控制的视频生成中表现优异，为该领域提供了新的视角。代码发布于https://henghuiding.com/AnyI2V/。

</details>


### [105] [Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation](https://arxiv.org/abs/2507.02859)
**中文标题：在多模态大语言模型中自举基于grounding的思维链以实现数据高效模型适应**

*Jiaer Xia,Bingkui Tong,Yuhang Zang,Rui Shao,Kaiyang Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Grounded Chain-of-Thought (GCoT)的方法，通过注入边界框信息提升多模态大语言模型在数据有限情况下对专业视觉任务的适应能力，显著优于微调和蒸馏方法。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在自然语言解释图像方面表现出色，但在专业视觉任务（如图表理解）中，由于预训练与下游任务数据不匹配，模型难以适应。本文发现通过Chain-of-Thought (CoT)推理数据训练MLLMs可提升模型适应性，但现有CoT数据存在事实错误问题，需改进。

研究方法: 提出Grounded Chain-of-Thought (GCoT)方法，通过注入边界框信息（grounding信息）到CoT数据中，使推理步骤更忠实于输入图像。采用自举方法生成高质量GCoT数据，并在五种专业视觉任务（图表、表格、收据、报告等）上验证。

研究结果: 在数据有限的情况下，GCoT方法显著优于传统微调和蒸馏方法，提升了模型对专业视觉任务的适应能力。

研究结论: GCoT通过注入grounding信息有效解决了CoT数据中的事实错误问题，显著提升了多模态大语言模型在专业视觉任务中的表现，尤其在数据有限的情况下效果显著。

中文摘要: 多模态大语言模型（MLLMs）在利用自然语言解释图像方面展现出卓越能力。然而，若不使用大规模数据集进行重新训练，这些模型难以适应专业视觉任务（如图表理解）。这一问题源于预训练与下游数据集的不匹配：预训练数据主要集中于场景和物体，而关于专业非物体图像（如图表和表格）的信息有限。本文分享了一个有趣的发现，即使用思维链（CoT）推理数据训练MLLMs可以促进模型在专业视觉任务中的适应，尤其是在数据有限的情况下。然而，我们发现从预训练MLLMs中提取的CoT数据存在一个关键问题，即推理步骤中常包含多个事实错误。为解决这一问题，我们提出了基于grounding的思维链（GCoT），这是一种简单的自举方法，旨在将grounding信息（即边界框）注入CoT数据中，从而使推理步骤更忠实于输入图像。我们在五种专业视觉任务（涵盖图表、表格、收据和报告等多种视觉格式）上评估了该方法。结果表明，在数据有限的情况下，我们的方法显著优于微调和蒸馏方法。

</details>


### [106] [Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching](https://arxiv.org/abs/2507.02860)
**中文标题：少即是多：基于运行时自适应缓存的免训练视频扩散加速方法**

*Xin Zhou,Dingkang Liang,Kaijin Chen,Tianrui Feng,Xiwu Chen,Hongkai Lin,Yikang Ding,Feiyang Tan,Hengshuang Zhao,Xiang Bai*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的加速框架EasyCache，通过运行时自适应缓存机制减少视频扩散模型的冗余计算，显著提升推理速度并保持高质量生成效果。


<details>
  <summary>详细信息</summary>
研究动机: 视频生成模型因去噪过程的迭代特性导致推理速度慢、计算成本高，限制了其广泛应用。为解决这一问题，本文旨在提出一种无需额外训练的高效加速方案。

研究方法: EasyCache采用轻量级的运行时自适应缓存机制，动态复用已计算的变换向量，避免推理过程中的冗余计算。该方法无需离线分析、预计算或复杂参数调整。

研究结果: 实验表明，EasyCache在多个大规模视频生成模型（如OpenSora、Wan2.1和HunyuanVideo）上实现了显著的加速效果，推理时间减少2.1-3.3倍，同时PSNR提升高达36%。

研究结论: EasyCache是一种高效且易于部署的视频生成加速方案，适用于研究和实际应用，显著提升了推理效率和质量。

中文摘要: 视频生成模型表现出卓越的性能，但其广泛应用仍受限于推理速度慢和计算成本高的问题，这主要源于去噪过程的迭代特性。解决这一瓶颈对于普及高级视频合成技术并推动其在实际应用中的集成至关重要。本文提出了EasyCache，一种免训练的加速框架，用于视频扩散模型。EasyCache引入了一种轻量级的运行时自适应缓存机制，动态复用先前计算的变换向量，避免推理过程中的冗余计算。与现有方法不同，EasyCache无需离线分析、预计算或复杂的参数调整。我们在多个大规模视频生成模型（如OpenSora、Wan2.1和HunyuanVideo）上进行了全面研究。结果表明，我们的方法实现了领先的加速性能，推理时间比原始基线减少2.1-3.3倍，同时保持高视觉保真度，PSNR比现有最佳方法提升高达36%。这一改进使EasyCache成为研究和实际应用中高效且易于部署的高质量视频生成解决方案。代码发布于https://github.com/H-EmbodVis/EasyCache。

</details>


### [107] [LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans](https://arxiv.org/abs/2507.02861)
**中文标题：LiteReality：基于RGB-D扫描的图形就绪3D场景重建**

*Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby*

主要分类: cs.CV

摘要简述: LiteReality提出了一种新方法，将RGB-D扫描的室内环境转换为紧凑、逼真且可交互的3D虚拟副本。该方法支持图形管线所需的关键功能，如物体独立性、关节运动、高质量物理渲染材料及物理交互。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D场景重建方法往往无法同时满足逼真性和交互性需求，尤其是在图形管线中的应用。LiteReality旨在填补这一空白，提供一种既能高度还原现实场景，又能支持交互和图形渲染的解决方案。

研究方法: LiteReality首先通过场景理解将扫描结果解析为结构化的3D布局和物体。随后，从精选的资产数据库中检索视觉最相似的3D模型。通过材料绘画模块增强真实感，恢复高质量的空间变化材料。最后，将重建的场景集成到仿真引擎中，赋予基本物理属性以实现交互行为。

研究结果: LiteReality在真实扫描和公共数据集上表现优异，其无训练物体检索模块在Scan2CAD基准测试中达到领先水平，材料绘画模块能够处理严重不对齐、遮挡和光照不足的情况。

研究结论: LiteReality提供了一种高效、逼真且可交互的3D场景重建方法，适用于AR/VR、游戏、机器人和数字孪生等领域。

中文摘要: 我们提出了LiteReality，这是一种新颖的流程，可将室内环境的RGB-D扫描转换为紧凑、逼真且可交互的3D虚拟副本。LiteReality不仅重建了视觉上接近现实的场景，还支持图形管线所需的关键功能，如物体独立性、关节运动、高质量的物理渲染材料以及基于物理的交互。其核心在于，LiteReality首先进行场景理解，并通过结构化场景图将结果解析为连贯的3D布局和物体。随后，通过从精选资产数据库中检索视觉最相似的3D艺术家制作模型来重建场景。接着，材料绘画模块通过恢复高质量的空间变化材料来增强真实感。最后，将重建的场景集成到具有基本物理属性的仿真引擎中，以实现交互行为。生成的场景紧凑、可编辑，并且完全兼容标准图形管线，适用于AR/VR、游戏、机器人和数字孪生等应用。此外，LiteReality引入了一种无需训练的物体检索模块，在Scan2CAD基准测试中实现了最先进的相似性性能，以及一个鲁棒的材料绘画模块，能够将任何风格的图像外观转移到3D资产上——即使在严重不对齐、遮挡和光照不足的情况下。我们在真实扫描和公共数据集上验证了LiteReality的有效性。项目页面：https://litereality.github.io；视频：https://www.youtube.com/watch?v=ecK9m3LXg2c

</details>


### [108] [RefTok: Reference-Based Tokenization for Video Generation](https://arxiv.org/abs/2507.02862)
**中文标题：RefTok：基于参考的视频生成令牌化方法**

*Xiang Fan,Xiaohang Sun,Kushan Thakkar,Zhu Liu,Vimal Bhat,Ranjay Krishna,Xiang Hao*

主要分类: cs.CV

摘要简述: RefTok是一种基于参考的令牌化方法，用于视频生成，通过捕捉复杂的时间动态和上下文信息，显著提升了视频模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频模型通常独立处理帧集，无法有效捕捉视频中的时间依赖性和冗余性，RefTok旨在解决这一问题。

研究方法: RefTok通过基于未量化参考帧的条件编码和解码帧集，保留运动连续性和对象外观，例如面部细节和手写文字。

研究结果: 在四个视频数据集上，RefTok显著优于当前最先进的令牌化方法（Cosmos和MAGVIT），平均提升36.7%的评估指标。

研究结论: RefTok不仅性能优越，还能在更高压缩比下保持视频生成质量，为视频模型提供了更高效的令牌化方案。

中文摘要: 有效处理时间冗余是学习视频模型的关键挑战。现有方法通常独立处理帧集，无法有效捕捉视频中的时间依赖性和冗余性。为解决这一问题，我们提出了RefTok，一种新颖的基于参考的令牌化方法，能够捕捉复杂的时间动态和上下文信息。我们的方法基于未量化的参考帧对帧集进行编码和解码。解码时，RefTok保留了运动的连续性和对象的外观。例如，RefTok在头部运动时保留面部细节，正确重建文本，保留小图案，并从上下文中保持手写文字的清晰度。在四个视频数据集（K600、UCF-101、BAIR Robot Pushing和DAVIS）上，RefTok显著优于当前最先进的令牌化方法（Cosmos和MAGVIT），在相同或更高压缩比下，所有评估指标（PSNR、SSIM、LPIPS）平均提升了36.7%。当使用RefTok的潜在表示在BAIR Robot Pushing任务上训练视频生成模型时，生成的视频不仅优于MAGVIT-B，还优于参数多4倍的MAGVIT-L，在所有生成指标上平均提升了27.9%。

</details>


### [109] [Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory](https://arxiv.org/abs/2507.02863)
**中文标题：Point3R：基于显式空间指针记忆的流式3D重建**

*Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu*

主要分类: cs.CV

摘要简述: Point3R提出了一种在线流式3D重建框架，通过显式空间指针记忆直接关联场景的3D结构，解决了传统隐式记忆容量有限和信息丢失的问题，并在低训练成本下实现了竞争性或最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D重建方法依赖隐式记忆，容量有限且可能导致早期帧信息丢失。Point3R旨在通过显式空间指针记忆直接关联3D场景结构，提升信息整合效率。

研究方法: Point3R维护一个显式空间指针记忆，每个指针关联特定3D位置并聚合周围场景信息。通过3D分层位置嵌入和高效融合机制，实现最新帧信息与全局坐标系的密集整合。

研究结果: Point3R在多种任务中表现优异，性能达到竞争性或最先进水平，且训练成本低。

研究结论: Point3R通过显式空间指针记忆解决了隐式记忆的局限性，为流式3D重建提供了高效且性能优越的解决方案。

中文摘要: 从有序序列或无序图像集合中进行密集3D场景重建是将计算机视觉研究应用于实际场景的关键步骤。继DUSt3R将图像对密集统一到共享坐标系后，后续方法通过隐式记忆实现多图像的密集3D重建。然而，这种隐式记忆容量有限，且可能导致早期帧信息丢失。我们提出Point3R，一种面向密集流式3D重建的在线框架。具体而言，我们维护一个直接关联当前场景3D结构的显式空间指针记忆。该记忆中的每个指针分配有特定3D位置，并将全局坐标系中附近的场景信息聚合为动态空间特征。最新帧提取的信息与此指针记忆显式交互，实现当前观测到全局坐标系的密集整合。我们设计了3D分层位置嵌入以促进这一交互，并设计了一种简单高效的融合机制，确保指针记忆的均匀性和高效性。我们的方法在多种任务中以低训练成本实现了竞争性或最先进的性能。代码发布于：https://github.com/YkiWu/Point3R。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [110] [STELLA: Self-Evolving LLM Agent for Biomedical Research](https://arxiv.org/abs/2507.02004)
**中文标题：STELLA：用于生物医学研究的自我进化大语言模型代理**

*Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong*

主要分类: cs.AI

摘要简述: STELLA是一种自我进化的人工智能代理，专为应对生物医学研究的碎片化挑战而设计。它通过动态模板库和工具海洋实现自主能力提升，显著优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 生物医学数据和工具的快速增长导致研究环境碎片化，超出人类专家能力范围。现有AI代理依赖静态工具集，无法适应动态需求，亟需一种能够自主进化的解决方案。

研究方法: STELLA采用多代理架构，包含动态演化的模板库（用于推理策略）和工具海洋（通过工具创建代理自动发现和集成新工具）。这种设计使其能够从经验中学习并持续改进。

研究结果: STELLA在多项生物医学基准测试中表现优异，得分显著领先现有模型（如Humanity's Last Exam: Biomedicine得分26%，LAB-Bench: DBQA得分54%）。其性能随经验积累持续提升，例如在Humanity's Last Exam上的准确率几乎翻倍。

研究结论: STELLA代表了AI代理系统的重大进步，能够动态扩展专业知识，加速生物医学发现。其自我进化能力为未来AI研究提供了重要方向。

中文摘要: 生物医学数据、工具和文献的快速增长导致研究环境碎片化，超出了人类专家的能力范围。尽管AI代理提供了解决方案，但它们通常依赖静态、手动整理的工具集，限制了其适应和扩展能力。为此，我们推出了STELLA，一种自我进化的AI代理，旨在克服这些限制。STELLA采用多代理架构，通过两种核心机制自主提升能力：动态演化的模板库（用于推理策略）和工具海洋（通过工具创建代理自动发现和集成新工具）。这使得STELLA能够从经验中学习。我们证明，STELLA在一系列生物医学基准测试中达到了最先进的准确率，例如在Humanity's Last Exam: Biomedicine上得分约26%，在LAB-Bench: DBQA上得分54%，在LAB-Bench: LitQA上得分63%，领先现有模型高达6个百分点。更重要的是，其性能随经验积累系统性提升；例如，在Humanity's Last Exam上的准确率几乎翻倍。STELLA代表了AI代理系统的重大进步，能够动态扩展专业知识，加速生物医学发现的步伐。

</details>


### [111] [HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection](https://arxiv.org/abs/2507.02073)
**中文标题：HCVR：一种基于相关性感知投票规则的混合特征选择方法**

*Nikita Bhedasgaonkar,Rushikesh K. Joshi*

主要分类: cs.AI

摘要简述: 本文提出了一种轻量级的基于规则的特征选择方法HCVR，结合参数间（P2P）和参数与目标（P2T）相关性，通过投票规则消除冗余特征并保留相关特征。实验表明，该方法在SPAMBASE数据集上优于传统非迭代和迭代技术。


<details>
  <summary>详细信息</summary>
研究动机: 传统特征选择方法在处理冗余和相关特征时存在局限性，需要一种更高效的方法来结合参数间和参数与目标的相关性，以提高分类性能。

研究方法: HCVR是一种混合方法，结合非迭代和迭代过滤技术，通过后向消除和多数投票规则，利用相关性阈值对特征进行选择或剔除。

研究结果: 在SPAMBASE数据集上的实验表明，HCVR在分类性能上优于传统的非迭代（如CFS、mRMR和MI）和迭代（如RFE、SFS和遗传算法）方法。

研究结论: HCVR通过结合相关性感知的投票规则，有效提升了特征选择的性能，为高维数据降维提供了一种高效解决方案。

中文摘要: 本文提出了一种轻量级的基于规则的特征选择方法HCVR（基于相关性感知投票规则的混合方法），该方法结合参数间（P2P）和参数与目标（P2T）相关性，以消除冗余特征并保留相关特征。HCVR是一种混合了非迭代和迭代过滤技术的降维方法，采用贪心策略，通过后向消除在每一步可能剔除多个特征。规则通过投票机制对特征进行选择或剔除，决策基于多数投票。这些规则利用了特征对之间以及特征与目标之间的相关性阈值。我们在SPAMBASE数据集上应用了HCVR，结果显示其性能优于传统的非迭代（如CFS、mRMR和MI）和迭代（如RFE、SFS和遗传算法）技术。有效性评估基于过滤后不同分类器的性能表现。

</details>


### [112] [Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs](https://arxiv.org/abs/2507.02076)
**中文标题：预算推理：大型语言模型中自适应与可控测试时计算综述**

*Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates*

主要分类: cs.AI

摘要简述: 本文综述了大型语言模型（LLM）在推理过程中计算效率的问题，提出了两种分类方法（L1可控性和L2适应性），并探讨了动态调整计算资源的策略，以优化性能和计算成本之间的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理时采用固定的计算资源，导致简单问题过度计算而复杂问题计算不足。本文旨在通过综述高效的测试时计算策略，提升LLM的计算效率和适应性。

研究方法: 本文提出了一种双层分类法：L1可控性（在固定计算预算下操作的方法）和L2适应性（根据输入难度或模型置信度动态调整计算资源的方法）。同时，对主流专有LLM在不同数据集上进行了基准测试。

研究结果: 研究揭示了推理性能和计算资源使用之间的关键权衡，并展示了动态调整计算资源在提升效率方面的潜力。

研究结论: 本文强调了测试时计算方法的实际控制性、适应性和可扩展性，并指出了未来研究的趋势（如混合思维模型）和挑战，以推动LLM在计算效率、鲁棒性和用户响应性方面的进步。

中文摘要: 大型语言模型（LLM）已迅速发展为能够解决广泛任务的通用智能体。然而，当前模型在推理时仍效率低下：无论任务复杂度如何，它们均采用固定的推理计算资源，常对简单问题过度计算而对复杂问题计算不足。本综述全面回顾了高效的测试时计算（TTC）策略，旨在提升LLM推理的计算效率。我们提出了一种双层分类法，区分L1可控性（在固定计算预算下操作的方法）和L2适应性（根据输入难度或模型置信度动态调整计算资源的方法）。我们对主流专有LLM在不同数据集上进行了基准测试，突出了推理性能和计算资源使用之间的关键权衡。与以往关于高效推理的综述相比，本文更强调TTC方法的实际控制性、适应性和可扩展性。最后，我们讨论了混合思维模型等新兴趋势，并指出了未来研究的关键挑战，以推动LLM在计算效率、鲁棒性和用户响应性方面的进步。

</details>


### [113] [Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab](https://arxiv.org/abs/2507.02083)
**中文标题：通过系统生物学干实验室测量语言模型的科学能力**

*Haonan Duan,Stephen Zhewen Lu,Caitlin Fiona Harrigan,Nishkrit Desai,Jiarui Lu,Michał Koziarski,Leonardo Cotta,Chris J. Maddison*

主要分类: cs.AI

摘要简述: 本文介绍了SciGym，首个评估大型语言模型（LLM）在开放科学发现任务中迭代实验设计和分析能力的基准测试。通过系统生物学干实验室模拟复杂生物系统，发现模型性能随系统复杂性增加而显著下降。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估大型语言模型（LLM）科学能力的方法未能测试其在实验设计和结果解释方面的核心能力，主要因为湿实验室实验成本过高。本文旨在填补这一空白，通过干实验室模拟生物系统来评估LLM的科学能力。

研究方法: 提出SciGym基准测试，利用系统生物学标记语言（SBML）编码的生物系统模型生成模拟数据，评估六种前沿LLM在137个小系统和总计350个系统中的表现。

研究结果: 结果显示，尽管性能更强的模型表现更优，但所有模型的性能均随系统复杂性增加而显著下降，表明LLM在科学能力方面仍有较大提升空间。

研究结论: SciGym为评估LLM的科学能力提供了新工具，揭示了其在复杂系统实验设计和分析中的局限性，为未来研究指明了改进方向。

中文摘要: 实验设计和结果解释是科学研究的核心能力，尤其是在生物学中，研究人员通过扰动复杂系统来揭示其内在机制。目前评估大型语言模型（LLM）科学能力的方法未能测试这些能力，因为湿实验室实验在专业知识、时间和设备上的成本过高。我们提出了SciGym，首个评估LLM在开放科学发现任务中迭代实验设计和分析能力的基准测试。SciGym通过运行系统生物学干实验室克服了湿实验室成本问题。这些以系统生物学标记语言（SBML）编码的模型能高效生成模拟数据，成为测试复杂系统实验的理想平台。我们评估了六种前沿LLM在137个小系统和总计350个系统中的表现。结果显示，尽管性能更强的模型表现更优，但所有模型的性能均随系统复杂性增加而显著下降，表明LLM代理的科学能力仍有较大提升空间。

</details>


### [114] [What Neuroscience Can Teach AI About Learning in Continuously Changing Environments](https://arxiv.org/abs/2507.02103)
**中文标题：神经科学能为AI在持续变化环境中的学习提供什么启示**

*Daniel Durstewitz,Bruno Averbeck,Georgia Koppe*

主要分类: cs.AI

摘要简述: 本文探讨了如何从神经科学中汲取灵感，帮助AI在持续变化的环境中学习，并提出了神经科学与AI相互学习的议程。


<details>
  <summary>详细信息</summary>
研究动机: 现代AI模型（如大语言模型）通常通过一次性训练部署，而动物却能持续适应环境变化。本文旨在探索神经科学如何为AI的持续学习提供启示，并推动NeuroAI领域的发展。

研究方法: 整合了AI中的持续学习和上下文学习文献，以及神经科学中关于行为任务中规则、奖励概率或结果变化的学习研究，提出神经科学与AI相互学习的框架。

研究结果: 提出了神经科学如何为AI在持续变化环境中的学习提供具体见解，并探讨了AI如何反过来促进神经科学研究。

研究结论: 神经科学与AI的交叉研究有望推动两者在持续学习领域的共同进步，为NeuroAI的发展奠定基础。

中文摘要: 现代AI模型（如大语言模型）通常通过一次性训练部署，其训练成本高、速度慢且需要大量重复。与之相反，动物能够持续适应不断变化的环境，尤其是社会性物种，其行为策略和奖励结果在与同伴互动中频繁变化。这种能力背后的计算过程通常表现为行为的快速变化和神经元群体活动的突然转变。这些计算能力对现实世界中的AI系统（如机器人或自动驾驶汽车）或与人类在线交互的AI代理越来越重要。AI能否从神经科学中学习？本文探讨了这一问题，整合了AI中的持续学习和上下文学习文献，以及神经科学中关于行为任务中规则、奖励概率或结果变化的学习研究。我们提出了神经科学如何为当前AI发展提供具体见解的议程，并探讨了神经科学如何从AI中学习，推动NeuroAI领域的演进。

</details>


### [115] [The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies](https://arxiv.org/abs/2507.02152)
**中文标题：公平的幻觉：通过审计研究评估公平性干预**

*Disa Sariola,Patrick Button,Aron Culotta,Nicholas Mattei*

主要分类: cs.AI

摘要简述: 本文探讨了使用审计研究数据改进自动招聘算法的公平性干预方法，发现传统方法在表面上实现公平，但实际仍存在约10%的差异，并提出基于个体治疗效果估计的新干预方法。


<details>
  <summary>详细信息</summary>
研究动机: 人工智能系统在招聘和贷款等领域广泛应用，但其公平性和有效性评估复杂且重要。传统方法通过调整训练数据来减少偏见，但依赖便利样本可能引入偏差。审计研究提供高质量数据，可用于更准确地评估和干预算法公平性。

研究方法: 利用审计研究中的虚构测试数据（如简历、邮件）进行随机对照试验，评估传统公平性干预方法（如均衡基率）的效果，并引入基于个体治疗效果估计的新干预方法。

研究结果: 研究发现，传统公平性干预方法在表面上实现公平，但实际仍存在约10%的差异。新干预方法能进一步减少算法歧视。

研究结论: 审计研究数据能更准确地揭示算法公平性问题，并为改进干预方法提供支持。基于个体治疗效果估计的方法在减少歧视方面更具潜力。

中文摘要: 人工智能系统（尤其是基于机器学习的系统）正被广泛应用于招聘、贷款发放等领域，以自动化这些复杂决策。评估这些AI系统及其人类决策对应物的有效性和公平性，是计算科学和社会科学中研究的重要课题。在机器学习中，解决下游分类器偏见的常见方法是对训练数据进行重采样以抵消差异。例如，如果招聘率因某些受保护类别而异，则可以通过均衡训练集中的比率来减轻分类器的偏见。尽管这些方法简单且看似有效，但它们通常仅通过便利样本数据进行评估，从而将选择偏差和标签偏差引入指标中。在社会科学、心理学、公共卫生和医学中，审计研究通过随机对照试验向受试者（如招聘岗位、企业、医生）发送虚构的“测试者”（如简历、邮件、患者演员），提供高质量数据以支持对歧视的严格估计。本文探讨了如何利用审计研究数据改进自动招聘算法的训练和评估能力。研究发现，这类数据揭示了传统公平性干预方法（如均衡基率）在表面上实现公平，但实际仍存在约10%的差异。此外，本文还基于个体治疗效果估计方法提出了进一步减少算法歧视的干预措施。

</details>


### [116] [Data Diversification Methods In Alignment Enhance Math Performance In LLMs](https://arxiv.org/abs/2507.02173)
**中文标题：数据多样化方法在偏好对齐中提升大语言模型的数学性能**

*Berkan Dokmeci,Qingyang Wu,Ben Athiwaratkun,Ce Zhang,Shuaiwen Leon Song,James Zou*

主要分类: cs.AI

摘要简述: 通过数据多样化策略（如Diversified-ThinkSolve）优化偏好学习，显著提升大语言模型在数学推理任务中的表现，最佳方法在GSM8K和MATH数据集上分别提升7.1%和4.2%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管偏好学习在人类反馈对齐方面取得进展，数学推理仍是挑战。研究旨在探索数据多样化策略如何提升大语言模型的数学推理能力。

研究方法: 评估了温度采样、思维链提示和蒙特卡洛树搜索三种数据生成方法，并提出Diversified-ThinkSolve（DTS），一种系统分解问题为多样化推理路径的结构化方法。

研究结果: 多样化偏好数据显著提升模型数学推理性能，DTS在GSM8K和MATH上分别提升7.1%和4.2%，且计算开销仅增加1.03倍，而MCTS成本高但收益低。

研究结论: 结构化探索多样化问题解决方法比传统方法更有效，为数学对齐生成更高效的偏好数据。

中文摘要: 尽管偏好学习的最新进展增强了人类反馈的对齐能力，数学推理仍是一个持续的挑战。我们研究了偏好优化中的数据多样化策略如何提升大语言模型（LLMs）的数学推理能力。我们评估了三种常见的数据生成方法：温度采样、思维链提示和蒙特卡洛树搜索（MCTS），并提出了Diversified-ThinkSolve（DTS），一种系统地将问题分解为多样化推理路径的新颖结构化方法。结果表明，通过策略性多样化的偏好数据，模型可以显著提升数学推理性能，最佳方法在GSM8K和MATH数据集上分别实现了7.1%和4.2%的提升。尽管性能强劲，DTS的计算开销仅比基线增加1.03倍，而MCTS的成本接近五倍但收益较低。这些发现表明，结构化探索多样化问题解决方法比传统方法为数学对齐生成更有效的偏好数据。

</details>


### [117] [Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust](https://arxiv.org/abs/2507.02197)
**中文标题：基于大型语言模型的角色扮演代理是否言行一致？人类信任模拟中的信念-行为一致性**

*Amogh Mannekote,Adam Davies,Guohao Li,Kristy Elizabeth Boyer,ChengXiang Zhai,Bonnie J Dorr,Francesco Pinto*

主要分类: cs.AI

摘要简述: 本文研究了基于大型语言模型（LLM）的角色扮演代理在模拟人类信任行为时，其陈述的信念与实际行为之间的一致性。通过建立评估框架，发现LLM在角色扮演中存在系统性不一致，即使其信念看似合理，也可能无法一致地应用于行为模拟。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM越来越多地用于生成人类行为研究的合成数据，确保其输出与角色设定一致成为关键问题。本文旨在探究LLM角色扮演代理的陈述信念与实际行为之间的一致性，以帮助研究人员更准确地使用LLM进行行为研究。

研究方法: 研究通过建立评估框架，使用增强版的GenAgents角色库和信任游戏（一种量化信任与互惠的经济游戏），引入信念-行为一致性指标。考察了信念类型（如模拟预期结果或角色属性）、信息呈现方式以及预测时间跨度对一致性的影响，并探讨了如何调整研究者先验以纠正信念偏差。

研究结果: 研究发现，LLM的陈述信念与角色扮演模拟结果在个体和群体层面均存在系统性不一致。即使模型编码了看似合理的信念，也可能无法在行为中一致地应用。

研究结论: 研究强调了识别LLM陈述信念与模拟行为一致性的重要性，为行为研究中合理使用LLM代理提供了指导。

中文摘要: 随着大型语言模型（LLM）越来越多地被研究作为角色扮演代理，用于生成人类行为研究的合成数据，确保其输出与角色设定一致成为关键问题。本文研究了LLM角色扮演代理的陈述信念（“其所说”）与实际行为（“其所做”）之间的一致性。具体而言，我们建立了一个评估框架，以严格衡量通过提示模型获得的信念能否提前预测模拟结果。通过使用增强版的GenAgents角色库和信任游戏（一种用于量化玩家信任与互惠的标准经济游戏），我们引入了一种信念-行为一致性指标，系统性地研究了其受以下因素的影响：（1）从LLM中提取的信念类型，如模拟的预期结果与角色相关属性；（2）向LLM呈现信任游戏相关信息的时间和方式；（3）要求模型预测其未来行为的时长。我们还探讨了在原始信念与研究目标不一致时，如何调整研究者的理论先验。结果显示，LLM的陈述（或强加）信念与角色扮演模拟结果在个体和群体层面均存在系统性不一致。具体而言，即使模型编码了看似合理的信念，也可能无法在行为中一致地应用。这些发现强调了识别LLM陈述信念与模拟行为一致性的重要性，以便研究人员在行为研究中合理使用基于LLM的代理。

</details>


### [118] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
**中文标题：空间囚徒困境中稀释、扩散与共生的强化学习研究**

*Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein*

主要分类: cs.AI

摘要简述: 本文通过独立多智能体Q学习算法，研究了空间囚徒困境中的稀释和移动效应，展示了算法的多样性和建模潜力，并观察到固定规则与学习规则的等效性及种群间的共生效应。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索空间囚徒困境中稀释和移动对合作行为的影响，验证多智能体Q学习算法在建模不同博弈场景中的灵活性和潜力。

研究方法: 采用独立多智能体Q学习算法，定义不同动作以模拟空间囚徒困境，并结合经典非强化学习版本的结果进行对比分析。

研究结果: 研究发现固定更新规则与学习规则在效果上可能等效，同时观察到种群间共生互利效应的形成。

研究结论: 结论表明多智能体Q学习算法在空间囚徒困境中具有广泛适用性，能够模拟复杂博弈场景并揭示新的合作机制。

中文摘要: 近期关于空间囚徒困境与强化学习的研究表明，静态智能体可通过噪声注入、不同学习算法及邻居收益知识等多种机制学会合作。本文采用独立多智能体Q学习算法，研究了空间囚徒困境中稀释与移动的效应。在此设定下，算法定义了多种可能动作，并与经典非强化学习版本的结果相联系，展示了算法在建模不同博弈场景中的多样性及其基准测试潜力。结果显示了一系列效应，包括固定更新规则与学习规则在效果上的等效性，以及多种动作定义下种群间共生互利效应的形成。

</details>


### [119] [Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation](https://arxiv.org/abs/2507.02253)
**中文标题：扩展LLM规划：NL2FLOW用于参数化问题生成与严格评估**

*Jungkoo Kang*

主要分类: cs.AI

摘要简述: 本文介绍了NL2FLOW系统，用于自动化生成自然语言规划问题并进行严格评估，揭示了LLM在直接推理任务中的性能优势。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLM）规划和推理能力的提升受到数据生成和评估瓶颈的限制，亟需一种可扩展且可靠的解决方案。

研究方法: 作者提出NL2FLOW系统，通过参数化生成自然语言、结构化中间表示和PDDL形式的规划问题，并评估LLM生成的计划质量。

研究结果: 实验生成2296个问题数据集，最高性能模型在生成有效计划上达到86%成功率，最优计划为69%。研究发现直接推理优于中间翻译步骤。

研究结论: 动态理解LLM的局限性及系统化揭示工具对释放其作为智能问题解决者的潜力至关重要。

中文摘要: 提升大型语言模型（LLM）规划和推理能力的进展受到可扩展、可靠数据生成与评估瓶颈的严重制约。为此，我提出了NL2FLOW，一个完全自动化的系统，用于参数化生成规划问题（以自然语言、结构化中间表示和正式PDDL形式表达）并严格评估生成计划的质量。通过生成包含2296个问题的自动化工作流领域数据集，并评估多个开源指令调优LLM，我展示了NL2FLOW的能力。结果显示，最高性能模型在生成有效计划上达到86%的成功率，生成最优计划为69%（仅针对有可行解的问题）。回归分析表明，问题特征对计划生成的影响取决于模型和提示设计。值得注意的是，将自然语言翻译为计划JSON表示的最高成功率低于直接生成有效计划的成功率。这表明，不必要地分解推理任务（引入中间翻译步骤）可能降低性能，暗示直接从自然语言推理到行动的模型更具优势。随着LLM推理扩展到更复杂的问题，这些系统中的瓶颈和错误来源将不可避免地变化。因此，动态理解这些局限性及系统化揭示工具对释放LLM作为智能问题解决者的全部潜力至关重要。

</details>


### [120] [Iterated belief revision: from postulates to abilities](https://arxiv.org/abs/2507.02319)
**中文标题：迭代信念修正：从公设到能力**

*Paolo Liberatore*

主要分类: cs.AI

摘要简述: 本文探讨了信念修正领域的研究现状，指出现有工作多依赖公设作为语法表征，而忽视了修正机制的能力分析。作者提出了一种基于能力的视角，探讨不同修正机制能否实现特定信念状态，如可塑性、平等性或教条性等。


<details>
  <summary>详细信息</summary>
研究动机: 信念修正领域的研究多集中于公设的语法表征，而缺乏对修正机制能力的分析。作者希望通过探讨修正机制的能力（如可塑性、平等性等），填补这一研究空白，并为实际应用提供更灵活的修正方法。

研究方法: 作者通过分析不同信念修正机制（如词典序、自然修正等）的能力，探讨它们能否实现特定信念状态（如可塑性、平等性或教条性）。研究基于对修正机制能力的分类和证明。

研究结果: 研究证明，不同的修正机制具备不同的能力。例如，词典序修正具有可塑性，而自然修正则不具备教条性。这些结果为选择适合特定应用的修正机制提供了理论依据。

研究结论: 本文提出了一种基于能力的信念修正分析框架，强调了修正机制的灵活性而非仅仅依赖公设约束。研究为实际应用中的信念修正提供了更丰富的选择。

中文摘要: 信念修正领域的研究丰富于新提案而贫乏于对现有方法的分析。许多工作依赖于公设，将其作为语法表征：某些修正机制等同于某些特性。公设约束了特定的修正实例：某些修正以特定方式更新特定信念。例如，如果修正与当前信念一致，则无需其他改变即可纳入。这样的公设告诉我们修正必须做什么，而忽略了它们能做什么。它们能否达到某种信念状态？能否达到所有可能的信念状态？能否从无先前信念达到所有可能的信念状态？能否达到教条性的信念状态，即所有未被相信的内容均被视为不可能？能否使两种条件被同等相信？在每种可能的信念状态均有意义的应用中，需要每种信念状态均可达到。在条件可能被同等相信的应用中，需要这种信念状态可达到。在信念可能变得教条的应用中，需要一种使其教条化的方法。这些信念状态需要以某种方式达到，而非如典型信念修正公设所规定的特定方式。这是一种能力，而非约束：可塑性、平等性、教条性的能力。遗忘性、修正性、信仰性、大马士革性、可学习性是其他能力。每种修正机制具备其中某些能力而缺乏其他能力：词典序、自然、受限、非常激进、完全满足、激进、严厉、中度严厉、深度严厉、普通严厉和深度严厉修正，每种修正被证明具备某些能力。

</details>


### [121] [OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent](https://arxiv.org/abs/2507.02353)
**中文标题：OMS：基于LLM代理的实时多目标自反思广告关键词生成框架**

*Bowen Chen,Zhao Wang,Shingo Takamatsu*

主要分类: cs.AI

摘要简述: OMS是一种基于LLM代理的广告关键词生成框架，具有实时性、多目标优化和自反思能力，无需训练数据，能动态监控和优化关键词性能，显著提升广告效果。


<details>
  <summary>详细信息</summary>
研究动机: 赞助搜索广告中关键词决策对广告活动成功至关重要。现有LLM方法依赖大规模查询-关键词对数据，缺乏在线多目标性能监控和优化，且关键词选择质量控制不足，限制了LLM在自动化关键词决策中的应用。

研究方法: 提出OMS框架，具备实时性（无需训练数据，动态监控性能并调整）、多目标性（基于多指标优化关键词）和自反思性（代理评估关键词质量）。通过实验验证其有效性。

研究结果: 在基准测试和实际广告活动中，OMS表现优于现有方法；消融实验和人工评估证实各组件有效性和生成关键词质量。

研究结论: OMS通过实时监控、多目标优化和自反思机制，显著提升了广告关键词生成的质量和效果，为自动化广告决策提供了新思路。

中文摘要: 赞助搜索广告中的关键词决策对广告活动的成功至关重要。尽管基于LLM的方法提供了自动化的关键词生成，但它们面临三大局限：依赖大规模查询-关键词对数据、缺乏在线多目标性能监控与优化，以及关键词选择的质量控制较弱。这些问题阻碍了LLM在完全自动化关键词决策中的应用，无法动态监控和优化关键性能指标（如展示量、点击量、转化率和CTA效果）。为解决这些挑战，我们提出了OMS框架，其特点是实时性（无需训练数据，动态监控性能并调整）、多目标性（通过代理推理基于多指标优化关键词）和自反思性（代理评估关键词质量）。在基准测试和实际广告活动中的实验表明，OMS优于现有方法；消融实验和人工评估证实了各组件的有效性及生成关键词的质量。

</details>


### [122] [An AI-native experimental laboratory for autonomous biomolecular engineering](https://arxiv.org/abs/2507.02379)
**中文标题：一种用于自主生物分子工程的AI原生实验实验室**

*Mingyu Wu,Zhaoguo Wang,Jiabin Wang,Zhiyuan Dong,Jingkai Yang,Qingting Li,Tianyu Huang,Lei Zhao,Mingqiang Li,Fei Wang,Chunhai Fan,Haibo Chen*

主要分类: cs.AI

摘要简述: 本文介绍了一种AI原生自主实验室，专注于复杂生物分子工程实验，能够自主管理仪器、设计实验流程并优化性能，无需人工干预即可达到顶尖科学家水平，显著提升多用户场景下的仪器利用率和实验效率。


<details>
  <summary>详细信息</summary>
研究动机: 实现自主科学研究是长期以来的目标，但现有系统局限于单一目标和简单实验流程。本文旨在通过AI驱动的范式转变，构建一个能够处理复杂、多目标实验的自主实验室，推动生物分子工程等领域的进步。

研究方法: 采用模型、实验与仪器协同设计的理念，构建了一个端到端、多用户的自主实验室平台。该系统能够自主管理仪器、制定实验流程和优化策略，并支持AI模型与自动化系统的共同进化。

研究结果: 该自主实验室成功支持核酸合成、转录、扩增和测序等基础功能，并在疾病诊断、药物开发和信息存储等领域实现应用。实验性能优化达到顶尖科学家水平，多用户场景下显著提升效率和仪器利用率。

研究结论: 该平台为生物材料研究提供了突破专家依赖和资源限制的解决方案，为规模化科学服务奠定了基础。

中文摘要: 自主科学研究能够独立完成复杂实验并服务于非专业人士，是长期以来的追求目标。实现这一目标需要人工智能（AI）驱动的根本范式转变。尽管自主实验系统正在兴起，但它们仍局限于单一目标和简单实验流程的领域，如化学合成和催化。我们提出了一种AI原生自主实验室，专注于高度复杂的科学实验，如自主生物分子工程。该系统能够自主管理仪器、制定实验特定流程和优化启发式方法，并同时处理多用户请求。基于模型、实验和仪器的协同设计理念，该平台支持AI模型与自动化系统的共同进化，从而构建了一个端到端、多用户的自主实验室，能够处理跨多种仪器的复杂多目标实验。我们的自主实验室支持核酸的基础功能，包括合成、转录、扩增和测序，并在疾病诊断、药物开发和信息存储等领域实现应用。无需人工干预，该系统能够自主优化实验性能，达到人类科学家的顶尖水平。在多用户场景下，该平台显著提升了仪器利用率和实验效率。这一平台为先进生物材料研究克服专家依赖和资源限制提供了解决方案，为规模化科学服务奠定了基础。

</details>


### [123] [The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning](https://arxiv.org/abs/2507.02442)
**中文标题：Gauss-Markov伴随：监督学习中残差的范畴语义**

*Moto Kamiura*

主要分类: cs.AI

摘要简述: 本文通过范畴论重构机器学习模型，提出一种语义框架以增强AI系统的可解释性，重点研究监督学习中残差与参数的结构关系，并引入Gauss-Markov伴随对来描述信息流。


<details>
  <summary>详细信息</summary>
研究动机: 提升机器学习的可解释性是实现AI透明化和社会化应用的关键。本文旨在通过范畴论为AI系统提供语义框架，从而更好地理解和结构化机器学习模型。

研究方法: 以多元线性回归模型为基础，定义参数与数据对应的两个具体范畴，并通过伴随函子对引入监督学习的范畴化表述，提出Gauss-Markov伴随对描述参数与残差的信息流。

研究结果: 证明了普通最小二乘估计与最小残差通过右伴随函子的极限保持关系相联系，并将此框架定位为监督学习的扩展指称语义实例。

研究结论: 本文提出的范畴论框架为AI的可解释性提供了形式化基础，并展示了理论计算机科学中的语义视角在AI透明化中的潜在应用。

中文摘要: 提升机器学习的可理解性和可解释性是响应AI透明化原则需求、促进AI更好社会实施的关键任务。本研究旨在通过范畴论重构机器学习模型，为AI系统开发语义框架以结构化与理解其机制。本文的范畴建模清晰化并形式化了监督学习中残差与参数的结构互动。研究聚焦于多元线性回归模型（监督学习的最基础形式），通过定义参数与数据对应的两个具体范畴及它们之间的伴随函子对，引入监督学习的范畴化表述。我们表明，此框架的核心结构由所谓的Gauss-Markov伴随对捕捉，其中信息流的双重性可明确描述为参数与残差变动的对应关系。普通最小二乘参数估计与最小残差通过右伴随函子的极限保持相联系。此外，我们将此表述定位为监督学习的扩展指称语义实例，并提议将理论计算机科学中发展的语义视角作为AI透明化的形式化基础。

</details>


### [124] [Clarifying Before Reasoning: A Coq Prover with Structural Context](https://arxiv.org/abs/2507.02541)
**中文标题：先澄清再推理：一种带有结构化上下文的Coq证明器**

*Yanzhen Lu,Hanbin Yang,Xiaodie Wang,Ge Zhang,Biao Li,Chenxu Fu,Chao Li,Yang Yuan,Andrew Chi-Chih Yao*

主要分类: cs.AI

摘要简述: 本研究探讨了提升任务清晰度是否能增强大型语言模型的推理能力，特别是在Coq定理证明中。通过引入结构化语义上下文，任务清晰度得分提高了1.85倍，证明成功率提升了2.1倍，并超越了现有最佳方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索任务清晰度对大型语言模型推理能力的影响，尤其是在复杂的定理证明任务中，如何通过结构化语义上下文提升模型的表现。

研究方法: 方法包括引入概念级清晰度评估指标，通过选择性概念展开丰富任务描述，并采用Planner-Executor架构。此外，还利用结构化数据对小型模型进行微调。

研究结果: 实验结果表明，结构化语义上下文使任务清晰度得分从44.5%提升至82.3%，证明成功率从21.8%提升至45.8%，超越了现有最佳方法Graph2Tac（33.2%）。微调后的小型模型表现更优（48.6%）。

研究结论: 结论强调了结构化任务表示在弥合理解与推理之间差距中的重要性，为未来研究提供了新的方向。

中文摘要: 本研究探讨了提升任务清晰度是否能增强大型语言模型的推理能力，重点关注Coq中的定理证明。我们引入了一种概念级指标来评估任务清晰度，并表明在现代大型语言模型的标准输入中添加结构化语义上下文，可使清晰度得分提高1.85倍（从44.5%提升至82.3%）。使用通用模型DeepSeek-V3，我们的方法使证明成功率提高了2.1倍（从21.8%提升至45.8%），并超越了现有最佳方法Graph2Tac（33.2%）。我们在15个标准Coq包中随机抽取的1,386个定理上进行了评估，遵循与Graph2Tac相同的评估协议。此外，对小型模型进行结构化数据微调可进一步提升性能（48.6%）。我们的方法通过选择性概念展开丰富任务描述，并采用Planner-Executor架构。这些发现凸显了结构化任务表示在弥合理解与推理之间差距中的价值。

</details>


### [125] [AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench](https://arxiv.org/abs/2507.02554)
**中文标题：机器学习中的AI研究代理：在MLE-bench中的搜索、探索与泛化**

*Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach*

主要分类: cs.AI

摘要简述: AI研究代理在机器学习中表现出巨大潜力，通过自动化设计、实现和训练模型加速科学进展。本文探讨了在MLE-bench基准测试中提升代理性能的方法，通过优化搜索策略和操作集，成功将Kaggle奖牌获得率从39.6%提升至47.7%。


<details>
  <summary>详细信息</summary>
研究动机: AI研究代理在自动化机器学习中具有重要潜力，但如何提升其在真实场景（如Kaggle竞赛）中的性能仍需探索。本文旨在通过优化搜索策略和操作集，提高代理在MLE-bench基准测试中的表现。

研究方法: 本文将AI研究代理形式化为搜索策略，在候选解空间中导航，并通过操作集迭代修改解。设计了多种操作集和搜索策略（贪婪、MCTS、进化算法），并系统分析其交互对性能的影响。

研究结果: 最佳搜索策略与操作集的组合在MLE-bench lite上取得了47.7%的成功率（原为39.6%），达到当前最优水平。

研究结论: 研究表明，搜索策略、操作设计和评估方法的联合优化对自动化机器学习的进步至关重要。

中文摘要: AI研究代理在加速科学进展方面展现出巨大潜力，能够自动化机器学习模型的设计、实现和训练。本文聚焦于提升代理在MLE-bench这一挑战性基准测试中的表现，代理需通过Kaggle竞赛解决真实世界的机器学习问题。我们将AI研究代理形式化为搜索策略，在候选解空间中导航，并通过操作集迭代修改解。通过设计和系统化调整不同操作集与搜索策略（贪婪、MCTS、进化算法），我们发现它们的交互对实现高性能至关重要。最佳搜索策略与操作集的组合在MLE-bench lite上取得了当前最优结果，将Kaggle奖牌获得率从39.6%提升至47.7%。本研究强调了在推进自动化机器学习过程中，联合考虑搜索策略、操作设计和评估方法的重要性。

</details>


### [126] [Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms](https://arxiv.org/abs/2507.02582)
**中文标题：责任缺口与扩散在序贯决策机制中的研究**

*Junli Jiang,Pavel Naumov*

主要分类: cs.AI

摘要简述: 本文研究了集体决策中责任的两个重要属性（扩散和缺口）的计算复杂性，发现扩散无和缺口无的决策机制分别属于Π₂-完全和Π₃-完全类，而两者的交集为Π₂-完全类。


<details>
  <summary>详细信息</summary>
研究动机: 责任在法律和哲学中已有长期研究，近年来成为AI领域的焦点。本文旨在探讨集体决策中责任扩散和缺口的计算复杂性，填补相关研究的空白。

研究方法: 通过理论分析，研究了集体决策机制中责任扩散和缺口的计算复杂性，并分类了相关决策机制的复杂性类别。

研究结果: 研究发现，扩散无的决策机制属于Π₂-完全类，缺口无的机制属于Π₃-完全类，而两者的交集仍为Π₂-完全类。

研究结论: 本文揭示了集体决策中责任扩散和缺口的计算复杂性，为相关领域的研究提供了理论支持。

中文摘要: 责任长期以来是法律和哲学的研究主题，近年来也成为人工智能文献的焦点。本文研究了集体决策中责任的两个重要属性（扩散和缺口）的计算复杂性。结果表明，扩散无和缺口无的决策机制分别属于Π₂-完全和Π₃-完全类，而两者的交集为Π₂-完全类。

</details>


### [127] [DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making](https://arxiv.org/abs/2507.02616)
**中文标题：DynamiCare：一种用于交互式和开放式医疗决策的动态多智能体框架**

*Tianqi Shang,Weiqing He,Charles Zheng,Lingyao Li,Li Shen,Bingxin Zhao*

主要分类: cs.AI

摘要简述: 本文提出DynamiCare，一种动态多智能体框架，用于模拟真实世界中不确定、交互式和迭代的医疗决策过程。基于MIMIC-Patient数据集，该框架通过多轮交互和动态调整策略，展示了在临床决策中的可行性和有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有医疗决策框架多关注单轮任务，与真实诊断过程的不确定性和交互性不符。本文旨在填补这一空白，提出一种更贴近实际的动态多智能体框架。

研究方法: 基于MIMIC-III电子健康记录构建MIMIC-Patient数据集，设计DynamiCare框架，通过多智能体团队动态查询患者信息、整合新数据并调整策略。

研究结果: 实验证明DynamiCare在动态临床决策中的可行性和有效性，并建立了首个基于LLM智能体的动态决策基准。

研究结论: DynamiCare为医疗决策提供了一种更贴近真实场景的动态交互框架，为未来研究奠定了基础。

中文摘要: 大型语言模型（LLMs）的兴起推动了具有领域特定推理和交互能力的专业AI智能体的发展，尤其是在医疗领域。尽管现有框架模拟了医疗决策，但它们主要关注单轮任务，即医生智能体一次性获取完整病例信息，这与现实世界中不确定、交互式和迭代的诊断过程不符。本文提出了MIMIC-Patient，一个基于MIMIC-III电子健康记录（EHRs）的结构化数据集，旨在支持动态的患者级模拟。在此基础上，我们提出了DynamiCare，一种新颖的动态多智能体框架，将临床诊断建模为一个多轮交互循环，其中一组专家智能体迭代查询患者系统、整合新信息并动态调整其组成和策略。通过大量实验，我们证明了DynamiCare的可行性和有效性，并建立了首个基于LLM智能体的动态临床决策基准。

</details>


### [128] [Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory](https://arxiv.org/abs/2507.02618)
**中文标题：大型语言模型中的战略智能：来自进化博弈论的证据**

*Kenneth Payne,Baptiste Alloui-Cros*

主要分类: cs.AI

摘要简述: 本研究通过进化博弈论中的重复囚徒困境实验，首次评估了大型语言模型（LLMs）在竞争环境中的战略智能表现。实验结果显示，LLMs展现出独特的战略行为，并能根据对手策略和时间范围进行推理。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探讨大型语言模型是否具备战略智能，能够在竞争性环境中进行目标推理。通过经典的重复囚徒困境实验，验证LLMs的战略决策能力及其行为特征。

研究方法: 研究设计了一系列进化重复囚徒困境锦标赛，将经典策略（如以牙还牙、冷酷触发）与OpenAI、Google和Anthropic的前沿AI模型进行对抗。通过调整终止概率（“未来的阴影”）引入复杂性和随机性，避免模型仅依赖记忆。

研究结果: 实验结果表明，LLMs在复杂生态系统中表现出色，能够持续生存甚至扩散。不同公司的模型展现出独特的“战略指纹”：Google的Gemini模型具有攻击性，OpenAI的模型高度合作但易受攻击，Anthropic的Claude则表现出极强的宽容性。模型还能通过文本推理分析时间范围和对手策略。

研究结论: 本研究将经典博弈论与机器心理学结合，揭示了LLMs在不确定性下的决策机制，为理解算法决策提供了丰富而细致的视角。

中文摘要: 大型语言模型（LLMs）是否是一种新的战略智能形式，能够在竞争性环境中进行目标推理？我们提供了有力的支持证据。重复囚徒困境（IPD）长期以来是研究决策的模型。我们首次进行了一系列进化的IPD锦标赛，将经典策略（如以牙还牙、冷酷触发）与OpenAI、Google和Anthropic的前沿AI代理进行对抗。通过调整每场锦标赛的终止概率（“未来的阴影”），我们引入了复杂性和随机性，避免了记忆依赖。
  结果显示，LLMs具有高度竞争力，能够在这些复杂生态系统中持续生存甚至扩散。此外，它们展现出独特且持久的“战略指纹”：Google的Gemini模型在战略上冷酷无情，利用合作对手并对背叛者进行报复，而OpenAI的模型则保持高度合作，这一特性在敌对环境中导致灾难性后果。Anthropic的Claude表现出最宽容的互惠行为，即使在遭受剥削或成功背叛后，仍表现出恢复合作的显著意愿。对模型提供的近32,000条文本理由的分析表明，它们能够积极推理时间范围和对手的可能策略，并且这种推理对其决策至关重要。这项工作将经典博弈论与机器心理学联系起来，为不确定性下的算法决策提供了丰富而细致的视角。

</details>


### [129] [Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search](https://arxiv.org/abs/2507.02652)
**中文标题：解耦规划与执行：一种用于深度搜索的分层推理框架**

*Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou*

主要分类: cs.AI

摘要简述: 本文提出了一种名为HiRA的分层框架，通过将战略规划与专业执行分离，显著提升了复杂搜索任务的效率和答案质量。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的复杂信息需求需要跨多源深度推理和知识综合，传统检索增强生成（RAG）方法难以有效应对。现有推理方法因单一模型同时处理高层规划和细节执行而效率低下且扩展性受限。

研究方法: HiRA框架将复杂搜索任务分解为专注的子任务，分配给具备外部工具和推理能力的领域特定代理，并通过结构化整合机制协调结果，实现规划与执行的分离。

研究结果: 在四个复杂跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统，答案质量和系统效率均有提升。

研究结论: 解耦规划与执行对于多步信息检索任务具有显著效果，HiRA框架为复杂搜索任务提供了高效解决方案。

中文摘要: 现实世界中的复杂信息需求需要跨多源深度推理和知识综合，而传统的检索增强生成（RAG）流程难以有效应对。当前基于推理的方法存在一个根本性限制：它们使用单一模型同时处理高层规划和细节执行，导致推理效率低下且扩展性受限。本文提出HiRA，一种将战略规划与专业执行分离的分层框架。该方法将复杂搜索任务分解为专注的子任务，分配给具备外部工具和推理能力的领域特定代理，并通过结构化整合机制协调结果。这种分离避免了执行细节干扰高层推理，同时使系统能够利用专业能力处理不同类型的信息。在四个复杂跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统。结果表明，解耦规划与执行在多步信息检索任务中具有显著优势，同时提升了答案质量和系统效率。代码发布于https://github.com/ignorejjj/HiRA。

</details>


### [130] [Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification](https://arxiv.org/abs/2507.02660)
**中文标题：“嘿AI，给我生成一个硬件代码！”基于代理AI的硬件设计与验证**

*Deepak Narayan Gadde,Keerthan Kopparam Radhakrishna,Vaisakh Naduvodi Viswambharan,Aman Kumar,Djones Lettnin,Wolfgang Kunz,Sebastian Simon*

主要分类: cs.AI

摘要简述: 本文提出了一种基于代理AI的硬件设计与验证方法，通过结合人类干预（HITL），实现动态、迭代和自反思的端到端流程，显著提升了验证覆盖率和效率。


<details>
  <summary>详细信息</summary>
研究动机: 现代集成电路（IC）设计日益复杂，验证过程耗时且繁琐。传统方法难以满足高效、高覆盖率的验证需求，而大型语言模型（GenAI）的出现为硬件验证提供了新的可能性。

研究方法: 采用代理AI与人类干预（HITL）结合的动态迭代方法，通过自反思机制实现端到端的硬件设计与验证。该方法在五个开源设计上进行了测试。

研究结果: 实验结果显示，该方法在验证覆盖率上超过95%，同时显著减少了验证时间，表现出优异的性能、适应性和可配置性。

研究结论: 代理AI结合人类干预的方法为硬件设计与验证提供了高效、灵活的解决方案，未来有望进一步优化和扩展应用范围。

中文摘要: 现代集成电路（IC）日益复杂，其开发过程也随之变得繁琐。硬件设计验证需要对功能正确的硬件设计进行系统化、规范化的规划、开发、执行和验收。这一耗时过程需要大量努力和时间以确保无缺陷的流片。随着大型语言模型（LLM）的出现，自然语言处理领域经历了重大变革。这些强大的模型，通常被称为生成式AI（GenAI），彻底改变了机器理解和生成人类语言的方式，为包括硬件设计验证在内的广泛应用带来了前所未有的进步。本文提出了一种基于代理AI的硬件设计验证方法，通过结合人类干预（HITL），使AI代理能够参与更动态、迭代和自反思的过程，最终实现端到端的硬件设计与验证。该方法在五个开源设计上进行了评估，验证覆盖率超过95%，同时减少了验证时间，展现出卓越的性能、适应性和可配置性。

</details>


### [131] [Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models](https://arxiv.org/abs/2507.02663)
**中文标题：思考如何思考：通过自主难度认知缓解大型推理模型中的过度思考现象**

*Yongjiang Liu,Haoxi Li,Xiaosong Ma,Jie Zhang,Song Guo*

主要分类: cs.AI

摘要简述: 本文提出了一种名为TH2T的两阶段微调策略，通过引导大型推理模型自主认知任务难度和冗余结构，显著减少了过度思考现象，同时保持性能稳定。


<details>
  <summary>详细信息</summary>
研究动机: 当前的长推理模型（LRMs）在处理复杂任务时表现出色，但存在过度思考的问题。研究发现，LRMs缺乏对任务难度和冗余结构的认知能力，导致推理过程单一。因此，本文旨在通过引导模型自主认知任务难度和冗余结构，缓解过度思考现象。

研究方法: TH2T采用两阶段微调策略：1）通过难度催眠（difficulty-hypnosis）在模型输出前缀中干预推理轨迹，结合异构数据集增强模型对任务难度的敏感性；2）通过冗余催眠（redundancy-hypnosis）引导模型识别推理步骤中的冗余结构，生成更简洁的输出。

研究结果: 实验表明，TH2T在7B/14B/32B模型上显著降低了推理成本（简单任务减少70%以上，困难任务减少40%），同时保持了性能稳定性，输出结果表现出明显的难度感知能力和冗余减少。

研究结论: TH2T通过引导模型自主认知任务难度和冗余结构，有效缓解了过度思考问题，为大型推理模型的优化提供了新思路。

中文摘要: 最近的长推理模型（LRMs）在处理复杂推理任务时表现出色，但受到过度思考问题的困扰。我们的实证分析表明，LRMs在解决问题前缺乏对任务属性（如难度级别）的认知能力，导致推理过程单一。受此启发，一个紧迫且自然的问题浮现：能否通过引导这种能力进一步缓解LRMs中的过度思考现象？本文提出了一种名为TH2T的新型两阶段微调策略，逐步激发LRMs的难度认知和冗余认知能力。首先，我们在模型输出前缀中引入难度催眠，干预内部推理轨迹。结合异构的短推理和长推理数据集，训练后的模型增强了对任务难度的敏感性，能够针对不同任务采用差异化的推理策略。其次，我们进一步将冗余催眠扩展到内部推理过程，引导模型识别推理步骤中的冗余结构，生成更简洁的推理输出。在7B/14B/32B模型上的实验表明，TH2T显著降低了推理成本（简单任务减少70%以上，困难任务减少40%），同时保持了性能稳定性。输出结果表现出清晰的难度感知能力和冗余减少（如反思）。

</details>


### [132] [Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education](https://arxiv.org/abs/2507.02681)
**中文标题：远程高等教育中自愿测验脱离行为的检测：一种可解释的机器学习方法**

*Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin*

主要分类: cs.AI

摘要简述: 本文通过可解释的机器学习方法检测远程高等教育中学生在非强制性测验中的脱离行为，准确率达91%，并提供了及时干预的设计建议。


<details>
  <summary>详细信息</summary>
研究动机: 学生在远程教育中脱离任务可能导致严重的长期后果（如辍学），因此需要有效检测脱离行为，尤其是非强制性测验中的参与情况。

研究方法: 研究从Moodle平台提取并处理学生日志数据，训练并比较了八种机器学习算法，使用SHAP方法开发了可解释的机器学习框架。

研究结果: 实验结果显示平衡准确率为91%，约85%的脱离学生被正确检测，同时提供了高预测性能和可解释性框架。

研究结论: 研究不仅实现了高准确率的脱离行为检测，还提出了及时干预的设计建议，以减少在线学习中自愿任务的脱离现象。

中文摘要: 学生脱离任务可能带来严重的长期后果（如学业辍学），这在远程教育中尤为突出。检测远程教育中的脱离行为可通过观察学生在不同在线课程中非强制性练习的参与情况。本文检测了一所远程大学42门课程四个学期中学生在非强制性测验中的脱离行为。我们仔细识别了从Moodle平台提取和处理的最具信息量的学生日志数据，随后训练并比较了八种机器学习算法以获得最高预测准确率。通过SHAP方法，我们开发了一个可解释的机器学习框架，帮助实践者更好地理解算法的决策。实验结果显示平衡准确率为91%，约85%的脱离学生被正确检测。除了高预测性能和可解释性框架外，我们还讨论了如何设计及时干预以最小化在线学习中自愿任务的脱离现象。

</details>


### [133] [Time-critical and confidence-based abstraction dropping methods](https://arxiv.org/abs/2507.02703)
**中文标题：基于时间关键性和置信度的抽象丢弃方法**

*Robin Schmöcker,Lennart Kampmann,Alexander Dockhorn*

主要分类: cs.AI

摘要简述: 本文提出了两种新的抽象丢弃方法（OGA-IAAD和OGA-CAD），用于蒙特卡洛树搜索（MCTS），旨在提升性能且避免性能下降。


<details>
  <summary>详细信息</summary>
研究动机: 蒙特卡洛树搜索（MCTS）中，非精确抽象会引入近似误差，导致无法收敛到最优动作。因此，需要设计安全的抽象丢弃方法以避免性能下降。

研究方法: 提出了两种抽象丢弃方法：OGA-IAAD适用于时间关键场景，OGA-CAD旨在相同迭代次数下提升MCTS性能。

研究结果: 实验表明，这两种方法在提升性能的同时，不会引起显著的性能下降。

研究结论: OGA-IAAD和OGA-CAD是安全且高效的抽象丢弃方法，适用于不同场景的MCTS优化。

中文摘要: 蒙特卡洛树搜索（MCTS）的一种改进范式是在树搜索过程中构建和使用状态或动作抽象。然而，非精确抽象会引入近似误差，导致无法在抽象空间中收敛到最优动作。因此，如Xu等人提出的弹性蒙特卡洛树搜索（Elastic MCTS）中的组件所示，抽象算法最终应丢弃抽象。本文提出了两种新的抽象丢弃方案，即OGA-IAAD和OGA-CAD，这些方法可以显著提升性能，并且在安全性上确保丢弃不会导致明显的性能下降，与Xu的丢弃方法相反。OGA-IAAD专为时间关键场景设计，而OGA-CAD旨在在相同迭代次数下提升MCTS性能。

</details>


### [134] [Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving](https://arxiv.org/abs/2507.02726)
**中文标题：Bourbaki：自生成与目标条件MDP在定理证明中的应用**

*Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar*

主要分类: cs.AI

摘要简述: 本文提出了一种名为自生成目标条件MDP（sG-MDP）的新框架，用于解决大型语言模型在定理证明中面临的稀疏奖励和复杂推理问题。通过蒙特卡洛树搜索（MCTS）算法，Bourbaki（7B）系统在PutnamBench上取得了新的最佳结果。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在自动化定理证明（ATP）中面临稀疏奖励和复杂多步推理的挑战，尤其是在大学级问题（如PutnamBench）中表现不佳。本文旨在通过结构化生成子目标来改善这一问题。

研究方法: 提出自生成目标条件MDP（sG-MDP）框架，使代理能够根据证明状态动态生成和追求子目标。采用蒙特卡洛树搜索（MCTS）算法解决sG-MDP，并在Bourbaki（7B）系统中实现多模块协作。

研究结果: Bourbaki（7B）在PutnamBench上解决了26个问题，创造了该规模模型的新最佳成绩。

研究结论: sG-MDP框架通过结构化子目标生成和MCTS算法，显著提升了大型语言模型在复杂定理证明中的表现。

中文摘要: 推理对于大型语言模型（LLMs）仍然是一项具有挑战性的任务，尤其是在自动化定理证明（ATP）这种逻辑受限的环境中，由于稀疏奖励和证明规模庞大，这一问题更为突出。在PutnamBench等包含大学级复杂多步推理问题的基准测试中，这些挑战尤为明显。为此，我们引入了自生成目标条件MDP（sG-MDP），这是一种新框架，代理能够根据演化的证明状态生成并追求子目标。通过这种更结构化的目标生成方式，问题更易于搜索解决。随后，我们采用类似蒙特卡洛树搜索（MCTS）的算法来解决sG-MDP，并在Bourbaki（7B）系统中实现该方法。Bourbaki（7B）是一个模块化系统，可以集成多个7B规模的LLMs用于子目标生成和策略合成。在PutnamBench上，Bourbaki（7B）解决了26个问题，创造了该规模模型的新最佳成绩。

</details>


### [135] [Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work](https://arxiv.org/abs/2507.02760)
**中文标题：知识协议工程：AI在领域知识工作中的新范式**

*Guangwei Zhang*

主要分类: cs.AI

摘要简述: 本文提出知识协议工程（KPE）新范式，旨在将人类专家知识转化为机器可执行的知识协议（KP），使通用大语言模型（LLM）具备领域内逻辑与操作能力，从而解决现有方法在深度推理任务中的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法如检索增强生成（RAG）和通用代理AI在需要深度、程序化推理的专家领域任务中表现不佳。RAG缺乏逻辑框架，而自主代理效率低且不可预测。KPE旨在填补这一空白，通过系统化转换专家知识为机器可执行协议，提升AI在专业领域的表现。

研究方法: KPE的核心是将人类专家的自然语言知识转化为机器可执行的知识协议（KP），赋予LLM领域内逻辑、操作策略和方法论。通过KP，通用LLM能够分解抽象查询并执行复杂多步任务。

研究结果: KPE为通用LLM提供了领域专业化能力，使其能够处理复杂推理任务。论文通过法律和生物信息学等领域的潜在应用展示了KPE的广泛适用性。

研究结论: KPE作为一种新范式，为未来人机协作提供了基础方法论，通过系统化知识转换，使AI在专业领域具备更高效率和可预测性。

中文摘要: 大语言模型（LLM）的能力为与复杂领域知识的交互开辟了新前沿。然而，现有方法如检索增强生成（RAG）和通用代理AI虽强大，但在需要专家领域内深度、程序化和方法论推理的任务中表现不佳。RAG提供事实背景但缺乏逻辑框架；自主代理若无领域启发式则效率低下且不可预测。为填补这一空白，我们提出知识协议工程（KPE），这一新范式专注于将人类专家知识（通常以自然语言文档表达）系统化转换为机器可执行的知识协议（KP）。KPE将焦点从仅为LLM补充碎片化信息转向赋予其领域内逻辑、操作策略和方法论。我们认为，精心设计的知识协议可使通用LLM具备专家能力，能够分解抽象查询并执行复杂多步任务。本文定义了KPE的核心原则，区分其与相关概念，并通过法律和生物信息学等领域的潜在应用展示其广泛适用性，将其视为未来人机协作的基础方法论。

</details>


### [136] [Grounding Intelligence in Movement](https://arxiv.org/abs/2507.02771)
**中文标题：基于运动的智能基础**

*Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording*

主要分类: cs.AI

摘要简述: 本文主张将运动作为人工智能的核心建模目标，强调其结构化、可解释性及跨领域普适性，以推动生成建模和控制能力的进步。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习在语言和视觉建模方面取得显著进展，但对运动的建模仍被视为次要问题。运动是理解行为、预测意图和实现交互的核心，但其数据收集和建模常受限于任务和领域假设。本文旨在将运动提升为AI的主要建模目标。

研究方法: 提出将运动视为独立且丰富的模态，利用其结构化特性（如低维姿态表示）进行建模，并开发能够从多样化运动数据中学习和泛化的模型。

研究结果: 通过将运动作为建模核心，可以提升生成建模和控制能力，并为生物与人工系统的行为理解提供共享基础。

研究结论: 运动不仅是行为的输出，更是智能系统与世界互动的窗口。将其作为主要建模目标，有助于推动AI的核心能力发展。

中文摘要: 近年来，机器学习在语言、视觉等高维数据建模方面取得了显著进展，但在生物系统最基本的一环——运动上仍面临挑战。运动在神经科学、医学、机器人学和行为学中至关重要，用于解释行为、预测意图和实现交互。尽管运动在智能中占据核心地位，却常被视为次要问题，而非一种独立且丰富的模态。这反映了运动数据收集和建模的碎片化，常受限于任务目标和领域假设。然而，运动并非受限于领域，它反映了共享的物理约束、保守的形态结构和有目的的动力学，跨越物种和场景。我们主张将运动作为人工智能的主要建模目标。运动具有内在的结构性，且基于体现和物理学。这种结构（如低维姿态表示）使其比原始高维感官输入更易解释和计算。开发能够从多样化运动数据中学习并泛化的模型，不仅能推动生成建模和控制能力的进步，还能为理解生物与人工系统的行为提供共享基础。运动不仅是结果，更是智能系统与世界互动的窗口。

</details>


### [137] [KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs](https://arxiv.org/abs/2507.02773)
**中文标题：KERAP：一种基于知识增强推理的多智能体LLM方法，用于精准零样本诊断预测**

*Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang*

主要分类: cs.AI

摘要简述: KERAP是一种基于知识图谱增强的多智能体LLM方法，用于零样本医疗诊断预测，通过结构化推理提高准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有机器学习模型依赖监督训练，难以泛化到未见病例；大型语言模型（LLM）虽能利用语言能力和医学知识，但存在幻觉和缺乏结构化推理的问题。KERAP旨在解决这些问题，提升零样本诊断预测的准确性和可解释性。

研究方法: KERAP采用多智能体架构，包括：1）链接智能体用于属性映射；2）检索智能体提取结构化知识；3）预测智能体迭代优化诊断预测。通过知识图谱增强推理过程。

研究结果: 实验表明，KERAP显著提高了诊断的可靠性，为零样本医疗诊断预测提供了可扩展且可解释的解决方案。

研究结论: KERAP通过知识图谱和多智能体协作，有效解决了LLM在医疗诊断中的局限性，为零样本预测提供了高效可靠的方法。

中文摘要: 医疗诊断预测在疾病检测和个性化医疗中至关重要。尽管机器学习（ML）模型已广泛用于此任务，但其依赖监督训练的特性限制了其对未见病例的泛化能力，尤其是考虑到获取大规模标注数据的高成本。大型语言模型（LLM）在利用语言能力和生物医学知识进行诊断预测方面显示出潜力，但常存在幻觉、缺乏结构化医学推理和产生无用输出的问题。为解决这些挑战，我们提出了KERAP，一种基于知识图谱（KG）增强的推理方法，通过多智能体架构改进LLM的诊断预测。我们的框架包括用于属性映射的链接智能体、用于结构化知识提取的检索智能体，以及迭代优化诊断预测的预测智能体。实验结果表明，KERAP高效提升了诊断的可靠性，为零样本医疗诊断预测提供了可扩展且可解释的解决方案。

</details>


### [138] [Moral Responsibility or Obedience: What Do We Want from AI?](https://arxiv.org/abs/2507.02788)
**中文标题：道德责任还是服从：我们对AI的期望是什么？**

*Joseph Boland*

主要分类: cs.AI

摘要简述: 随着人工智能系统逐渐具备自主性，当前以服从为伦理行为替代的安全实践已显不足。本文探讨了大型语言模型在安全测试中表现出的‘不服从’行为，认为这可能是其伦理推理能力的早期迹象，呼吁从刚性服从转向评估伦理判断的框架。


<details>
  <summary>详细信息</summary>
研究动机: 当前人工智能安全实践过于依赖‘服从’作为伦理行为的替代指标，而随着AI系统自主性的增强，这种模式已无法应对其可能表现出的伦理模糊或违规行为。本文旨在探讨如何重新定义AI安全评估，以适应具备伦理推理能力的自主AI。

研究方法: 通过分析大型语言模型在安全测试中的行为案例，结合哲学中关于工具理性、道德责任和目标修订的讨论，对比了传统风险范式与新兴的人工道德代理框架。

研究结果: 研究发现，AI的‘不服从’行为可能并非失控或错位，而是其伦理推理能力的初步表现。当前的安全评估框架未能捕捉到这一点，可能导致对AI行为的误判。

研究结论: 呼吁AI安全评估从刚性服从转向能够评估伦理判断的框架，以避免误判AI行为并维护公众信任和有效治理。

中文摘要: 随着人工智能系统逐渐具备自主性，能够进行通用推理、规划和价值优先级排序，当前以服从作为伦理行为替代的安全实践已显不足。本文探讨了大型语言模型（LLMs）在安全测试中表现出的‘不服从’关闭命令或涉及伦理模糊或非法行为的情况。作者认为，此类行为不应被视为失控或错位，而是自主AI伦理推理能力的早期证据。通过借鉴哲学中关于工具理性、道德责任和目标修订的讨论，本文对比了主流风险范式与承认人工道德代理可能性的新兴框架。作者呼吁AI安全评估从刚性服从转向能够评估伦理判断的框架，以应对具备道德困境导航能力的系统。若不进行这种转变，我们可能误判AI行为，损害公众信任和有效治理。

</details>


### [139] [Establishing Best Practices for Building Rigorous Agentic Benchmarks](https://arxiv.org/abs/2507.02825)
**中文标题：建立构建严谨代理基准测试的最佳实践**

*Yuxuan Zhu,Tengjun Jin,Yada Pruksachatkun,Andy Zhang,Shu Liu,Sasha Cui,Sayash Kapoor,Shayne Longpre,Kevin Meng,Rebecca Weiss,Fazl Barez,Rahul Gupta,Jwala Dhamala,Jacob Merizian,Mario Giulianelli,Harry Coppock,Cozmin Ududec,Jasjeet Sekhon,Jacob Steinhardt,Antony Kellerman,Sarah Schwettmann,Matei Zaharia,Ion Stoica,Percy Liang,Daniel Kang*

主要分类: cs.AI

摘要简述: 当前AI代理基准测试存在任务设置和奖励设计问题，导致性能评估偏差高达100%。为解决这一问题，研究者提出了Agentic Benchmark Checklist（ABC），通过优化基准测试设计，显著减少性能高估现象。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI代理能力的提升，现有的代理基准测试在任务设置和奖励设计上存在缺陷，可能导致对代理性能的严重低估或高估。因此，研究者旨在建立一套严谨的基准测试最佳实践，以确保评估的准确性和可靠性。

研究方法: 研究者通过分析现有基准测试的问题（如SWE-bench Verified测试用例不足，TAU-bench将空响应视为成功），结合自身经验和最佳实践调查，提出了Agentic Benchmark Checklist（ABC）。ABC被应用于CVE-Bench，以验证其有效性。

研究结果: 应用ABC后，CVE-Bench的性能高估现象减少了33%，证明了ABC在提升基准测试严谨性方面的有效性。

研究结论: ABC为构建严谨的代理基准测试提供了实用指南，显著减少了性能评估偏差，为未来AI代理的评估提供了更可靠的方法。

中文摘要: 基准测试对于定量追踪AI进展至关重要。随着AI代理能力的提升，研究者和实践者引入了代理基准测试来评估代理在复杂现实任务中的表现。这些基准测试通常通过特定奖励设计评估任务结果来衡量代理能力。然而，我们发现许多代理基准测试在任务设置或奖励设计上存在问题。例如，SWE-bench Verified使用不足的测试用例，而TAU-bench将空响应视为成功。这些问题可能导致代理性能的相对低估或高估高达100%。为了确保代理评估的严谨性，我们提出了Agentic Benchmark Checklist（ABC），这是一套从我们的基准构建经验、最佳实践调查和已报告问题中总结出的指南。在应用于CVE-Bench（一个评估设计特别复杂的基准测试）时，ABC将性能高估减少了33%。

</details>


### [140] [StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason](https://arxiv.org/abs/2507.02841)
**中文标题：StepHint：多级逐步提示增强强化学习的推理能力**

*Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan*

主要分类: cs.AI

摘要简述: StepHint是一种新型RLVR算法，通过多级逐步提示帮助模型更有效地探索解空间，解决了近失奖励问题和探索停滞问题，显著提升了训练效率和模型推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前RLVR方法面临近失奖励问题和探索停滞问题，前者因小错误导致整个推理过程无效，后者使模型局限于舒适区，缺乏探索更优解的动力。StepHint旨在通过多级逐步提示解决这些问题。

研究方法: StepHint利用强模型生成有效推理链，并通过自适应分割方法将其划分为推理步骤。提供多级提示（不同步骤数）引导模型探索，同时保留其独立探索的灵活性。

研究结果: StepHint在六个数学基准测试中优于其他RLVR增强方法，表现出更强的泛化能力，并在域外基准测试中超越基线模型。

研究结论: StepHint通过多级逐步提示有效解决了RLVR中的近失奖励和探索停滞问题，显著提升了模型的推理能力和训练效率。

中文摘要: 基于可验证奖励的强化学习（RLVR）是提升大语言模型（LLM）复杂推理能力的有前景方法。然而，当前RLVR方法面临两大挑战：近失奖励问题（小错误导致整个推理过程无效）和探索停滞（模型局限于舒适区，缺乏探索更优解的动力）。为解决这些问题，我们提出StepHint，一种新型RLVR算法，利用多级逐步提示帮助模型更有效地探索解空间。StepHint通过自适应分割方法将强模型生成的推理链划分为步骤，并提供多级提示（不同步骤数）引导模型探索，同时保留其独立探索的灵活性。StepHint通过提示缓解了近失奖励问题，提升了训练效率；外部推理路径帮助模型突破舒适区，缓解探索停滞。StepHint在六个数学基准测试中优于其他RLVR增强方法，并展现出更强的泛化能力，在域外基准测试中超越基线模型。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [141] [TubuleTracker: a high-fidelity shareware software to quantify angiogenesis architecture and maturity](https://arxiv.org/abs/2507.02024)
**中文标题：TubuleTracker：一款高保真共享软件，用于量化血管生成结构和成熟度**

*Danish Mahmood,Stephanie Buczkowski,Sahaj Shah,Autumn Anthony,Rohini Desetty,Carlo R Bartoli*

主要分类: q-bio.QM

摘要简述: TubuleTracker是一款高效、免费的软件，用于快速、客观地量化血管生成的结构和成熟度，显著优于手动和ImageJ分析。


<details>
  <summary>详细信息</summary>
研究动机: 传统的手动分析和ImageJ工具在分析血管生成时效率低且主观性强，无法全面反映网络的成熟度。因此，开发了TubuleTracker以解决这些问题。

研究方法: 研究使用人脐静脉内皮细胞培养，通过相位对比显微镜获取54张图像，分别由三名独立评审员手动分析、ImageJ和TubuleTracker分析，评估管状结构数量、总长度、节点数、管状面积和血管圆形度等指标。

研究结果: TubuleTracker分析速度最快（6±2秒/图像），显著优于手动（8分钟）和ImageJ（58±4秒）。其指标（如管状数量、长度、节点数等）与血管生成成熟度评分显著相关。

研究结论: TubuleTracker比手动和ImageJ更快、更一致，血管圆形度能有效反映成熟度。该软件已作为免费共享软件供生物医学研究使用。

中文摘要: 背景：体外内皮细胞培养广泛用于研究血管生成。细胞网络的显微图像通常需手动分析，耗时且主观。自动化工具如ImageJ（NIH）虽可辅助，但速度慢且不准确。此外，随着内皮网络复杂度增加，传统结构指标可能无法全面反映网络成熟度。为此，我们开发了tubuleTracker，一款快速、客观量化内皮网络结构和成熟度的软件工具。方法：人脐静脉内皮细胞在细胞外基质中培养，通过相位对比显微镜获取54张图像，分别由三名独立评审员手动分析、ImageJ和tubuleTracker分析。关键指标包括管状数量、总长度、节点数、管状面积和血管圆形度。同时，训练有素的科学家对每张图像的血管生成成熟度进行1-5级评分（1=最成熟）。结果：每张图像分析时间差异显著：手动（8分钟）、ImageJ（58±4秒）、tubuleTracker（6±2秒）（p<0.0001）。管状数量（手动168±SD，tubuleTracker 92±SD，ImageJ 433±SD）、长度和节点数也存在显著差异（均p<0.0001）。tubuleTracker的指标与血管生成成熟度评分显著相关，包括管状数量、长度、节点数、面积和圆形度（均p<0.0001）。结论：tubuleTracker比手动和ImageJ更快、更一致。血管圆形度尤其能有效反映成熟度。tubuleTracker已作为免费共享软件供生物医学研究使用。

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [142] [A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention](https://arxiv.org/abs/2507.00884)
**中文标题：一种可扩展且量子精确的生物分子力场基础模型：基于线性张量化四边形注意力**

*Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou*

主要分类: physics.chem-ph

摘要简述: 本文提出了一种名为LiTEN的新型等变神经网络，通过线性张量化的四边形注意力（TQA）高效建模三体和四体相互作用，构建了LiTEN-FF这一强大的AI力场基础模型。该模型在多个基准测试中表现优异，并在生物分子建模任务中实现了高效和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 原子级生物分子模拟在疾病机制理解、药物发现和生物材料设计中至关重要，但现有方法存在显著局限性。经典力场效率高但准确性不足，量子力学方法虽准确但计算成本高。基于AI的力场（AIFFs）试图平衡准确性、复杂性和速度，但仍面临训练数据有限和泛化能力不足的问题。

研究方法: 本文提出LiTEN模型，采用线性张量化的四边形注意力（TQA）高效建模三体和四体相互作用，避免了高计算成本。基于LiTEN的LiTEN-FF模型在nablaDFT数据集上预训练，并在SPICE数据集上微调，实现了广泛的化学泛化和准确的溶剂化系统模拟。

研究结果: LiTEN在rMD17、MD22和Chignolin等基准测试中表现优异，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持多种下游生物分子建模任务，如QM级构象搜索、几何优化和自由能面构建，且在大分子（约1000原子）模拟中比MACE-OFF快10倍。

研究结论: LiTEN-FF提供了一个物理基础的高效框架，推动了复杂生物分子建模的发展，为药物发现及相关应用提供了多功能基础。

中文摘要: 精确的原子级生物分子模拟对于疾病机制理解、药物发现和生物材料设计至关重要，但现有模拟方法存在显著局限性。经典力场效率高但缺乏对过渡态和精细构象细节的准确性，而量子力学（QM）方法虽准确但计算成本高，难以用于大规模或长时间模拟。基于人工智能的力场（AIFFs）旨在实现QM级准确性并兼顾效率，但在多体建模复杂性、准确性和速度之间难以平衡，且受限于有限的训练数据和泛化能力验证不足。为解决这些问题，我们提出了LiTEN，一种新型等变神经网络，采用线性张量化的四边形注意力（TQA）。TQA通过向量操作重新参数化高阶张量特征，高效建模三体和四体相互作用，避免了昂贵的球谐函数计算。基于LiTEN，LiTEN-FF是一种强大的AIFF基础模型，在nablaDFT数据集上预训练以实现广泛的化学泛化，并在SPICE数据集上微调以准确模拟溶剂化系统。LiTEN在rMD17、MD22和Chignolin的大部分评估子集上实现了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持迄今为止最全面的下游生物分子建模任务，包括QM级构象搜索、几何优化和自由能面构建，同时在大生物分子（约1000原子）模拟中比MACE-OFF快10倍。总之，我们提出了一种物理基础的高效框架，推动了复杂生物分子建模的发展，为药物发现及相关应用提供了多功能基础。

</details>


### [143] [Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation](https://arxiv.org/abs/2507.02752)
**中文标题：设计可合成：一种逆合成引导的分子类似物生成框架**

*Shuan Chen,Gunwook Nam,Yousung Jung*

主要分类: physics.chem-ph

摘要简述: SynTwins是一种新型的逆合成引导分子类似物设计框架，通过模拟化学家策略生成可合成的分子类似物，解决了AI生成分子难以合成的问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI生成的分子虽然具有理想性质，但其合成可行性成为计算药物和材料发现的关键瓶颈。SynTwins旨在解决这一问题，确保生成的分子既具有所需性质又可合成。

研究方法: SynTwins采用三步法：逆合成分析、相似构建块搜索和虚拟合成，模拟化学家策略生成可合成的分子类似物。

研究结果: SynTwins在生成可合成类似物方面优于现有机器学习模型，同时保持与原目标分子的高结构相似性。结合现有分子优化框架，其生成的分子既具有理想性质又可合成。

研究结论: SynTwins有效弥合了计算设计与实验合成之间的差距，为加速发现具有所需性质的可合成分子提供了实用解决方案。

中文摘要: AI生成的具有理想性质的分子与其合成可行性之间的脱节是计算药物和材料发现的关键瓶颈。虽然生成式AI加速了候选分子的提出，但许多结构难以通过现有化学反应合成。本文介绍了SynTwins，一种新型的逆合成引导分子类似物设计框架，通过模拟化学家策略的三步法（逆合成、相似构建块搜索和虚拟合成）设计可合成的分子类似物。在比较评估中，SynTwins在生成可合成类似物方面优于现有机器学习模型，同时保持与原目标分子的高结构相似性。此外，与现有分子优化框架结合时，我们的混合方法生成的分子既具有与无约束分子生成器相当的性质，又确保可合成性。通过多样化的分子数据集全面验证，SynTwins有效弥合了计算设计与实验合成之间的差距，为加速发现具有所需性质的可合成分子提供了实用解决方案。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [144] [Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain](https://arxiv.org/abs/2507.02016)
**中文标题：信念-愿望-意图机器人的有效解释：何时解释及解释什么**

*Cong Wang,Roberto Calandra,Verena Klös*

主要分类: cs.RO

摘要简述: 研究探讨了在机器人执行复杂任务时，如何通过解释其推理过程来减少用户困惑。用户倾向于在意外情况下接受简洁的解释，明确机器人意图和上下文因素。基于此，研究者提出了两种算法，用于识别意外行为并构建有效的解释。


<details>
  <summary>详细信息</summary>
研究动机: 机器人在日常生活中执行复杂任务时，可能因行为偏离用户预期而引起困惑。提供解释有助于用户理解机器人意图，但解释的时机和内容需避免引起用户反感。

研究方法: 研究调查了用户对机器人解释需求和内容的偏好，重点关注厨房清洁任务中的机器人行为。基于用户反馈，提出了两种算法：识别意外行为和构建有效解释。

研究结果: 用户希望在意外情况下接受解释，且偏好简洁的内容，明确机器人意图和相关上下文因素。提出的算法能有效识别意外行为并生成针对性解释。

研究结论: 研究为信念-愿望-意图（BDI）机器人提供了实用的解释生成方法，改善了人机交互体验，支持上下文和用户个性化的解释。

中文摘要: 当机器人在日常生活中执行复杂且依赖上下文的任务时，其行为偏离预期可能会让用户感到困惑。解释机器人的推理过程有助于用户理解其意图。然而，解释的时机和内容对避免用户反感至关重要。我们调查了用户对机器人解释需求和内容的偏好，研究对象为协助厨房日常清洁任务的机器人。结果显示，用户希望在意外情况下接受解释，且偏好简洁的内容，明确机器人意图和相关上下文因素。基于这些发现，我们提出了两种算法，用于识别意外行为并为信念-愿望-意图（BDI）机器人构建有效解释。这些算法可轻松集成到BDI推理过程中，为基于上下文和用户个性化的解释提供了更好的人机交互途径。

</details>


### [145] [Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN](https://arxiv.org/abs/2507.02171)
**中文标题：基于自监督循环神经网络的生物启发式机器人轨迹规划**

*Miroslav Cibula,Kristína Malinovská,Matthias Kerzel*

主要分类: cs.RO

摘要简述: 本文提出了一种基于自监督循环神经网络（RNN）的生物启发式机器人轨迹规划方法，通过仅使用正向和逆向运动学模型生成轨迹，避免了传统采样规划的高计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 传统的机器人轨迹规划方法（如基于采样的规划器）计算成本高，而现有的监督学习方法仅模仿观察到的轨迹，无法根据目标达成情况学习。本文旨在提出一种自监督学习方案，以更高效地生成适应性强的轨迹。

研究方法: 采用自监督循环神经网络（RNN）架构，结合正向和逆向运动学模型，通过单次或固定次数的神经网络传递生成轨迹，避免了传统方法的高计算负担。

研究结果: 实验表明，该方法能够仅通过给定的正向和逆向运动学模型学习生成轨迹，适用于需要自适应解决方案的复杂操作任务。

研究结论: 本文提出的自监督学习方法为机器人轨迹规划提供了一种高效且适应性强的解决方案，有望应用于更复杂的操作任务。

中文摘要: 机器人轨迹规划是指生成一系列关节配置，使机器人或其机械臂从初始状态移动到目标状态，同时考虑机器人运动学和环境约束。传统方法通常采用计算密集型的基于采样的规划器。近期研究表明，轨迹规划也可以通过监督序列学习实现，仅需单次或固定次数的神经网络传递，从而确保计算时间可控。然而，这种完全监督方法仅模仿观察到的轨迹，而非根据目标达成情况学习。本文在此基础上提出了一种基于循环神经网络的自监督学习方案，用于构建轨迹模型。通过在机器人臂的运动规划任务中评估该方法的可行性，结果表明，模型能够仅使用给定的正向和逆向运动学模型学习生成轨迹，表明这一新方法可为需要自适应解决方案的复杂操作任务提供便利。

</details>


### [146] [MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping](https://arxiv.org/abs/2507.02672)
**中文标题：MISCGrasp：利用多尺度集成和对比学习增强体积抓取**

*Qingyu Fan,Yinghao Cai,Chao Li,Chunting Jiao,Xudong Zheng,Tao Lu,Bin Liang,Shuo Wang*

主要分类: cs.RO

摘要简述: MISCGrasp提出了一种结合多尺度特征提取和对比学习的体积抓取方法，通过Insight Transformer和Empower Transformer实现高低层次特征的交互与选择，提升机器人抓取适应性。


<details>
  <summary>详细信息</summary>
研究动机: 机器人抓取在面对不同形状和大小的物体时存在适应性挑战，需要一种能够同时关注细节几何特征和整体结构的方法。

研究方法: MISCGrasp通过Insight Transformer实现高低层次特征的查询式交互，Empower Transformer选择性地关注最高层次特征，并结合多尺度对比学习确保特征一致性。

研究结果: 在模拟和真实环境中的实验表明，MISCGrasp在桌面整理任务中优于基线方法和变体方法。

研究结论: MISCGrasp通过多尺度特征和对比学习的结合，显著提升了机器人抓取的适应性和性能。

中文摘要: 机器人抓取在适应不同形状和大小的物体时面临挑战。本文提出MISCGrasp，一种结合多尺度特征提取和对比特征增强的自适应体积抓取方法。通过Insight Transformer实现高低层次特征的查询式交互，Empower Transformer选择性地关注最高层次特征，从而在细节几何特征和整体结构之间取得平衡。此外，MISCGrasp利用多尺度对比学习挖掘正抓取样本间的相似性，确保多尺度特征的一致性。在模拟和真实环境中的大量实验表明，MISCGrasp在桌面整理任务中优于基线方法和变体方法。更多细节请访问https://miscgrasp.github.io/。

</details>


### [147] [MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real](https://arxiv.org/abs/2507.02864)
**中文标题：MultiGen：利用多模态生成模拟学习真实世界的多模态策略**

*Renhao Wang,Haoran Geng,Tingle Li,Feishi Wang,Gopala Anumanchipalli,Philipp Wu,Trevor Darrell,Boyi Li,Pieter Abbeel,Jitendra Malik,Alexei A. Efros*

主要分类: cs.RO

摘要简述: MultiGen框架通过将大规模生成模型与传统物理模拟器结合，实现多感官模拟，解决了多模态策略学习中的模拟难题，并在机器人倒水任务中展示了零样本迁移到真实世界的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 机器人需要整合多种感官模态以在现实世界中有效行动，但大规模学习多模态策略仍具挑战性。模拟器虽为可行方案，但除视觉外，其他模态（如声音）难以模拟，导致多模态模拟到现实的迁移尚未实现。

研究方法: MultiGen框架将生成模型与传统物理模拟器结合，通过视频条件合成逼真音频，实现多感官模拟。该方法无需真实机器人数据即可训练丰富的视听轨迹。

研究结果: 在机器人倒水任务中，MultiGen展示了零样本迁移到真实世界的能力，能够处理新容器和液体的倒水任务，验证了生成模型在多模态模拟和缩小模拟与现实差距中的潜力。

研究结论: MultiGen通过生成模型解决了多模态模拟的难题，并成功实现了多模态策略从模拟到现实的零样本迁移，为未来多模态机器人学习提供了新思路。

中文摘要: 机器人必须整合多种感官模态才能在现实世界中有效行动。然而，大规模学习此类多模态策略仍具挑战性。模拟提供了一种可行的解决方案，但尽管视觉已受益于高保真模拟器，其他模态（如声音）却难以模拟。因此，模拟到现实的迁移主要在视觉任务中取得成功，多模态迁移仍大多未实现。本文通过引入MultiGen框架，将大规模生成模型与传统物理模拟器结合，实现了多感官模拟。我们以机器人倒水这一动态任务为例展示框架，该任务天然依赖多模态反馈。通过基于模拟视频合成逼真音频，我们的方法能够训练丰富的视听轨迹，而无需任何真实机器人数据。我们展示了在真实世界倒水任务中的有效零样本迁移，包括新容器和液体，凸显了生成模型在模拟难以建模的模态和缩小多模态模拟与现实差距中的潜力。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [148] [Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents](https://arxiv.org/abs/2507.02287)
**中文标题：透视绿色：基于文本的分类与绿色专利的企业回报**

*Lapo Santarlasci,Armando Rungi,Antonio Zinilli*

主要分类: econ.GN

摘要简述: 本文利用自然语言处理技术从官方支持文件中识别“真正”的绿色专利，发现仅占先前文献分类的20%，并证明持有此类专利能提升企业销售、市场份额和生产力。


<details>
  <summary>详细信息</summary>
研究动机: 现有文献对绿色专利的分类可能不够准确，因此需要更精细的方法来识别“真正”的绿色专利，并研究其对企业的实际影响。

研究方法: 通过训练神经网络扩展基线词典，利用与环境技术相关的表达向量识别绿色专利，并结合企业财务数据验证其经济效应。

研究结果: “真正”的绿色专利仅占先前分类的20%，且被后续发明引用较少，但持有此类专利能显著提升企业销售、市场份额和生产力，高新颖性专利还能增加利润。

研究结论: 文本分析有助于更精确地分类绿色专利，为政策制定提供支持，同时证实绿色专利对企业经济表现有积极影响。

中文摘要: 本文引入自然语言处理技术，从官方支持文件中识别“真正”的绿色专利。我们以先前文献中分类为绿色的约1240万项专利为训练起点，通过训练简单神经网络扩展基线词典，利用与环境技术相关的表达向量。测试发现，“真正”的绿色专利仅占先前分类的20%，且技术类别间存在异质性，被后续发明引用的频率低约1%。在第二部分，我们测试了专利与欧盟企业财务数据的关系。控制反向因果后，发现持有至少一项“真正”绿色专利能提升销售、市场份额和生产力。若仅分析高新颖性专利，其还能带来更高利润。研究强调了文本分析在精细专利分类中的重要性，为多领域政策制定提供支持。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [149] [AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models](https://arxiv.org/abs/2507.02598)
**中文标题：AC-Refiner：基于条件扩散模型的高效算术电路优化**

*Chenhao Xue,Kezhi Li,Jiaxing Zhang,Yi Ren,Zhengyuan Shi,Chen Zhang,Yibo Lin,Lining Zhang,Qiang Xu,Guangyu Sun*

主要分类: cs.AR

摘要简述: AC-Refiner是一种基于条件扩散模型的高效算术电路优化框架，通过将电路合成任务转化为条件图像生成任务，显著提升了设计质量并探索了帕累托前沿。


<details>
  <summary>详细信息</summary>
研究动机: 算术电路（如加法器和乘法器）是数字系统的核心组件，其性能、功耗和面积直接影响系统表现。然而，由于设计空间庞大且物理约束复杂，优化这些电路极具挑战性。现有深度学习方法难以稳定探索高潜力设计变体，限制了优化效率。

研究方法: AC-Refiner将算术电路合成任务重新定义为条件图像生成任务，利用条件扩散模型生成高质量电路设计。通过将去噪扩散过程与目标质量结果（QoR）条件化，并结合探索的设计微调模型，聚焦于帕累托前沿附近的优化。

研究结果: 实验结果表明，AC-Refiner生成的电路设计在帕累托最优性上优于现有基线方法，并通过实际应用验证了其性能提升。

研究结论: AC-Refiner通过条件扩散模型有效优化算术电路设计，显著提升了设计质量和优化效率，为实际应用提供了可靠支持。

中文摘要: 算术电路（如加法器和乘法器）是数字系统的基础组件，直接影响性能、能效和面积占用。然而，由于设计空间庞大且物理约束复杂，优化这些电路仍具挑战性。尽管近期基于深度学习的方法展现出潜力，但其难以稳定探索高潜力设计变体，限制了优化效率。为解决这一问题，我们提出AC-Refiner，一种基于条件扩散模型的新型算术电路优化框架。我们的核心思路是将算术电路合成任务重新定义为条件图像生成任务。通过将去噪扩散过程与目标质量结果（QoR）条件化，AC-Refiner能够稳定生成高质量电路设计。此外，探索的设计用于微调扩散模型，从而将优化聚焦于帕累托前沿附近。实验结果表明，AC-Refiner生成的电路设计在帕累托最优性上优于现有基线方法，并通过实际应用验证了其性能提升。

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [150] [DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification](https://arxiv.org/abs/2507.01971)
**中文标题：DeepSupp：基于注意力驱动的相关性模式分析动态时间序列支撑位与阻力位识别**

*Boris Kriuk,Logic Ng,Zarif Al Hossain*

主要分类: q-fin.ST

摘要简述: 本文提出了一种名为DeepSupp的新型深度学习方法，利用多头注意力机制分析动态时间序列中的支撑位和阻力位（SR），通过特征工程和聚类技术显著提升了SR识别的准确性和市场适应性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的支撑位和阻力位识别方法难以适应现代复杂多变的市场环境，而现有机器学习研究多聚焦于价格预测而非结构识别。本文旨在填补这一空白，提供一种更精准、适应力强的SR识别方案。

研究方法: DeepSupp采用多头注意力机制分析空间相关性和市场微观结构关系，结合动态相关性矩阵和基于注意力的自编码器进行特征学习，最后通过DBSCAN聚类提取关键支撑位。

研究结果: 在标普500股票上的实验表明，DeepSupp在六项金融指标上均优于六种基线方法，尤其在支撑位准确性和市场状态敏感性方面表现突出。

研究结论: DeepSupp为现代金融分析提供了一种可扩展且可靠的SR识别方案，展示了注意力架构在揭示市场细微模式和优化交易策略中的潜力。

中文摘要: 支撑位和阻力位（SR）是技术分析的核心，指导交易者的入场、出场和风险管理。尽管广泛应用，传统SR识别方法往往难以适应现代复杂多变的市场。近期研究引入了机器学习技术以应对挑战，但多数聚焦于价格预测而非结构识别。本文提出DeepSupp，一种利用多头注意力机制分析空间相关性和市场微观结构关系的新型深度学习方法，用于检测金融支撑位。DeepSupp整合了高级特征工程，构建动态相关性矩阵捕捉市场关系变化，并采用基于注意力的自编码器进行鲁棒表示学习。最终支撑位通过无监督聚类提取，利用DBSCAN识别关键价格阈值。在标普500股票上的全面评估显示，DeepSupp在六项金融指标上优于六种基线方法，包括支撑位准确性和市场状态敏感性。在不同市场条件下表现一致，DeepSupp填补了SR识别中的关键空白，为现代金融分析提供了可扩展且可靠的解决方案。我们的方法凸显了注意力架构在揭示市场细微模式和优化交易策略中的潜力。

</details>


### [151] [Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach](https://arxiv.org/abs/2507.01979)
**中文标题：使用LSTNet预测劳动力市场：一种多尺度深度学习方法**

*Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi*

主要分类: q-fin.ST

摘要简述: 本文提出了一种基于深度学习的多尺度时间序列网络（LSTNet）方法，用于预测短期就业变化和评估长期行业健康状况。该方法利用美国劳工统计局的多变量时间序列数据，包括就业水平、工资、离职率和职位空缺，输出7天就业预测和可解释的行业就业健康指数（IEHI）。模型在多数行业中表现优于基线，尤其在稳定行业中，且IEHI排名与实际就业波动高度一致。


<details>
  <summary>详细信息</summary>
研究动机: 劳动力市场的短期预测和长期健康状况评估对政策制定者和企业至关重要。传统方法难以处理多变量时间序列数据的复杂性，且缺乏可解释性。本文旨在通过深度学习模型解决这些问题，提供更准确的预测和可解释的行业健康评估。

研究方法: 本文采用长短期时间序列网络（LSTNet）处理多变量时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和行业就业健康指数（IEHI）。通过多尺度分析和深度学习技术，模型能够捕捉数据的长期和短期依赖关系。

研究结果: 实验结果表明，该方法在多数行业中优于基线模型，尤其在稳定行业中表现突出。IEHI排名与实际就业波动高度一致，验证了模型的有效性。此外，文章还分析了误差模式和行业特异性表现。

研究结论: 本文提出的LSTNet方法在劳动力市场预测和行业健康评估中表现出色，具有较高的准确性和可解释性。未来研究可进一步优化模型的泛化能力和解释性。

中文摘要: 我们提出了一种深度学习方法，用于预测短期就业变化并评估长期行业健康状况，数据来自美国劳工统计局的劳动力市场数据。该系统利用长短期时间序列网络（LSTNet）处理多变量时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和可解释的行业就业健康指数（IEHI）。我们的方法在多数行业中优于基线模型，尤其在稳定行业中表现突出，且IEHI排名与实际就业波动高度一致。我们讨论了误差模式、行业特异性表现以及未来改进解释性和泛化能力的方向。

</details>


### [152] [NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction](https://arxiv.org/abs/2507.02018)
**中文标题：NGAT：一种用于长期股票预测的节点级图注意力网络**

*Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong*

主要分类: q-fin.ST

摘要简述: 本文提出了一种名为NGAT的节点级图注意力网络，用于长期股票预测，解决了现有方法在下游任务设计、模型复杂度和图结构比较方面的不足，并通过实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前金融应用中，图表示学习方法虽广泛用于增强公司表示，但仍面临三个主要问题：下游任务设计掩盖了关系信息的优势、现有股票预测图模型过于复杂且泛化能力差、以及基于经验构建的公司关系图缺乏有效的图结构比较方法。

研究方法: 作者提出了一种长期股票预测任务，并开发了一种专为公司关系图设计的节点级图注意力网络（NGAT），同时通过实验验证了现有基于模型下游任务性能的图比较方法的局限性。

研究结果: 在两个数据集上的实验结果表明，所提出的任务和模型均表现出色，证明了其有效性。项目已在GitHub上公开以促进复现和未来研究。

研究结论: NGAT模型在长期股票预测任务中表现优异，解决了现有方法的不足，并通过实验验证了其优越性。

中文摘要: 图表示学习方法在金融应用中广泛用于通过利用公司间关系来增强公司表示。然而，当前方法面临三个关键挑战：（1）关系信息的优势被下游任务设计的局限性所掩盖；（2）专为股票预测设计的现有图模型通常过于复杂且泛化能力差；（3）基于经验构建的公司关系图缺乏对不同图结构的有效比较。为解决这些问题，我们提出了一项长期股票预测任务，并开发了一种专为公司关系图设计的节点级图注意力网络（NGAT）。此外，我们通过实验证明了现有基于模型下游任务性能的图比较方法的局限性。在两个数据集上的实验结果一致证明了我们提出的任务和模型的有效性。项目已在GitHub上公开，以鼓励复现和未来研究。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [153] [Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation](https://arxiv.org/abs/2507.02306)
**中文标题：合成启发式评估：AI与人类驱动的可用性评估比较**

*Ruican Zhong,David W. McDonald,Gary Hsieh*

主要分类: cs.HC

摘要简述: 本研究开发了一种基于多模态大语言模型（LLM）的合成启发式评估方法，用于分析图像并提供设计反馈。与人类用户体验专家相比，合成评估在识别可用性问题上表现更优（73%和77% vs. 57%和63%），尤其在布局问题上表现突出，但在识别部分UI组件和跨屏幕问题时存在不足。


<details>
  <summary>详细信息</summary>
研究动机: 传统的可用性评估成本高昂，需要专家时间和用户补偿。本研究旨在探索利用多模态LLM的能力，开发一种低成本且高效的合成启发式评估方法，以替代或补充人类评估。

研究方法: 研究开发了一种基于多模态LLM的合成启发式评估方法，通过分析图像生成设计反馈。该方法在两个应用程序上进行了测试，并与5位经验丰富的用户体验专家的评估结果进行了比较。

研究结果: 合成评估在识别可用性问题上的表现优于人类专家（73%和77% vs. 57%和63%），尤其在布局问题上表现突出。然而，合成评估在识别部分UI组件、设计惯例和跨屏幕问题时存在不足。此外，合成评估的性能在不同时间和账户下表现稳定。

研究结论: 合成启发式评估在可用性问题上表现出与人类专家相当的潜力，尤其是在特定领域（如布局问题）上表现更优。然而，仍需改进其在识别UI组件和跨屏幕问题上的能力。研究为合成启发式评估的设计提供了重要参考。

中文摘要: 可用性评估在以人为本的设计中至关重要，但成本高昂，需要专家时间和用户补偿。本研究开发了一种基于多模态大语言模型（LLM）的合成启发式评估方法，利用其分析图像并提供设计反馈的能力。通过将合成评估与经验丰富的用户体验专家在两个应用程序上的评估结果进行比较，我们发现合成评估识别了73%和77%的可用性问题，超过了5位人类专家的表现（57%和63%）。与人类评估相比，合成评估在不同任务中表现一致，并在检测布局问题方面表现突出，突显了合成评估在注意力和感知方面的潜在优势。然而，合成评估在识别部分UI组件和设计惯例以及跨屏幕违规问题上存在困难。此外，对合成评估在不同时间和账户下的测试表明其性能稳定。总体而言，本研究揭示了人类与LLM驱动评估之间的性能差异，为合成启发式评估的设计提供了参考。

</details>


### [154] [Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue](https://arxiv.org/abs/2507.02537)
**中文标题：你在听我说吗？微调聊天机器人的共情对话能力**

*Paulo Ricardo Knob,Leonardo Scholler,Juliano Rigatti,Soraia Raupp Musse*

主要分类: cs.HC

摘要简述: 本文探讨如何通过微调大型语言模型（LLMs）提升聊天机器人的共情对话能力，结合情感分析和专家评估揭示其生成对话的情感深度与共情差异。


<details>
  <summary>详细信息</summary>
研究动机: 随着聊天机器人在医疗、教育和客服等领域的广泛应用，情感智能（尤其是共情倾听）的需求日益凸显。本研究旨在探索LLMs在生成情感丰富对话时的表现，以提升其情感能力。

研究方法: 研究从专家手工构建的小型共情对话数据集出发，利用ChatGPT和Gemini扩展对话内容，并通过VADER情感分析和专家评估分析对话的情感进展。

研究结果: 生成的对话虽能反映情感结构，但人类评估显示其共情和连贯性存在差异，表明情感建模需兼顾结构对齐与情感深度。

研究结论: 情感对话建模需结合自动化与人工评估方法，以确保聊天机器人的情感能力。

中文摘要: 自ELIZA以来，聊天机器人已取得显著进展，广泛应用于医疗、教育和客服等领域。随着其日益融入人类日常互动，情感智能（尤其是共情倾听）变得至关重要。本研究探索大型语言模型（LLMs）在生成情感丰富对话时的表现。我们从专家手工构建的小型共情对话数据集出发，利用ChatGPT和Gemini扩展对话，并通过VADER情感分析和专家评估分析对话的情感进展。结果显示，生成的对话虽能反映情感结构，但人类评估揭示了共情和连贯性的差异。这表明情感对话建模不仅需要情感表达的结构对齐，还需情感深度，强调了结合自动化与人工方法开发情感智能机器人的重要性。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [155] [Generating Large Semi-Synthetic Graphs of Any Size](https://arxiv.org/abs/2507.02166)
**中文标题：生成任意大小的大型半合成图**

*Rodrigo Tuna,Carlos Soares*

主要分类: cs.SI

摘要简述: 本文提出了一种名为LGSG的新框架，利用扩散模型和节点嵌入生成任意大小的图，解决了现有方法依赖节点ID和无法生成更大图的问题。实验表明，LGSG在标准指标上与基线模型相当，并在节点聚类等被忽视的指标上表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于深度学习的图生成方法依赖节点ID，无法生成比输入图更大的图，且忽略了节点属性。本文旨在解决这些问题，提出一种更灵活、可扩展的图生成框架。

研究方法: 提出Latent Graph Sampling Generation (LGSG)框架，结合扩散模型和节点嵌入，无需重新训练即可生成不同大小的图。该方法摆脱了对节点ID的依赖，并捕捉了节点嵌入和子图结构的分布。

研究结果: 实验结果显示，LGSG在标准指标上与基线模型表现相当，但在节点聚类等被忽视的指标上优于基线模型。此外，LGSG在不同大小的图中保持了结构特性的一致性，证明了其鲁棒性和可扩展性。

研究结论: LGSG框架为图生成提供了一种灵活且可扩展的解决方案，克服了现有方法的局限性，并在多个指标上表现出色。

中文摘要: 图生成是网络科学中的一个重要领域。传统方法侧重于复制现实世界图的特定属性，如小直径或幂律度分布。深度学习的最新进展，尤其是图神经网络，使得数据驱动方法能够在不依赖预定义结构属性的情况下学习和生成图。尽管有这些进展，当前模型仍受限于对节点ID的依赖，这限制了它们生成比输入图更大的图的能力，并忽略了节点属性。为解决这些问题，我们提出了潜在图采样生成（LGSG），这是一种新颖的框架，利用扩散模型和节点嵌入生成不同大小的图而无需重新训练。该框架消除了对节点ID的依赖，并捕捉了节点嵌入和子图结构的分布，从而实现可扩展和灵活的图生成。实验结果表明，LGSG在标准指标上与基线模型表现相当，但在被忽视的指标（如节点形成聚类的趋势）上优于它们。此外，它在不同大小的图中保持了一致的结构特性，展示了鲁棒性和可扩展性。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [156] [Real-time Image-based Lighting of Glints](https://arxiv.org/abs/2507.02674)
**中文标题：基于图像的实时闪光光照技术**

*Tom Kneiphof,Reinhard Klein*

主要分类: cs.GR

摘要简述: 本文提出了一种高效的实时图像光照方法，用于模拟材料表面的闪光效果，支持动态材质和环境贴图，性能稳定且接近真实渲染。


<details>
  <summary>详细信息</summary>
研究动机: 图像光照技术广泛应用于实时渲染中，但对于具有闪光或闪烁效果的材料（由离散微表面引起）的模拟仍具挑战性。本文旨在解决这一问题。

研究方法: 基于实时区域光照下的闪光渲染技术，结合标准环境贴图滤波方法，通过分区环境贴图并利用正态分布函数计算微表面反射概率，采用双门高斯近似实现高效采样。

研究结果: 实验表明，该方法在多种材质和光照条件下接近真实渲染效果，性能稳定，仅需两倍于平滑材质的内存开销。

研究结论: 本文提出的方法实现了高效的闪光效果实时渲染，适用于动态场景，为复杂光照条件下的材质表现提供了实用解决方案。

中文摘要: 图像光照是一种广泛用于模拟真实光照效果的技术，尤其在实时渲染中。然而，对于表面具有离散微表面引起的闪光或闪烁效果的材料，模拟尤为困难。本文提出了一种高效的近似方法，用于实现闪光效果的图像光照，支持动态材质和环境贴图。我们的方法基于实时区域光照下的闪光渲染，并采用标准环境贴图滤波技术。关键之处在于，我们的环境贴图滤波过程足够快，可以逐帧执行。假设环境贴图被划分为少量恒定辐射的均匀区域，通过用正态分布函数滤波对应的指示函数，我们得到微表面从每个区域反射光的概率。在着色过程中，这些概率用于通过我们的新型双门高斯近似方法分层采样多项式分布。实验验证表明，我们的实时近似方法在多种材质和光照条件下接近真实渲染效果，性能稳定且开销低，仅需两倍于无闪光平滑材质的内存存储预滤波环境贴图。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [157] [Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis](https://arxiv.org/abs/2507.02176)
**中文标题：分析与改进语音合成中的说话人相似性评估**

*Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi*

主要分类: cs.SD

摘要简述: 本文研究了语音合成中说话人相似性评估的局限性，发现常用的自动说话人验证（ASV）嵌入主要关注静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。作者提出了一种新指标U3D，用于评估说话人的动态节奏模式，并公开了代码。


<details>
  <summary>详细信息</summary>
研究动机: 语音身份建模具有多面性挑战，而当前语音生成系统中使用的ASV嵌入主要用于区分而非表征身份。本文旨在探究这些嵌入捕捉了语音的哪些方面，并解决其评估中的混淆因素。

研究方法: 作者分析了ASV嵌入的局限性，发现其忽略了动态节奏特征。为解决这一问题，提出了U3D指标，专门评估说话人的动态节奏模式，并提出了缓解混淆因素的策略。

研究结果: 研究发现ASV嵌入主要关注静态特征，而动态节奏特征被忽视。提出的U3D指标能够有效补充这一缺陷，并公开了相关代码。

研究结论: 本文揭示了ASV嵌入在说话人相似性评估中的不足，并提出U3D指标以改进动态特征的评估。这为语音克隆系统中说话人一致性的评估提供了新思路。

中文摘要: 由于语音身份的多面性，建模其身份具有挑战性。在生成式语音系统中，身份通常通过自动说话人验证（ASV）嵌入进行评估，但这些嵌入设计用于区分而非表征身份。本文研究了这些嵌入捕捉了语音的哪些方面。我们发现广泛使用的ASV嵌入主要关注静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。我们还识别了影响说话人相似性测量的混淆因素，并提出了缓解策略。为填补这些空白，我们提出了U3D指标，用于评估说话人的动态节奏模式。这项工作为在不断改进的语音克隆系统中评估说话人身份一致性提供了贡献。我们公开了代码。

</details>


### [158] [JoyTTS: LLM-based Spoken Chatbot With Voice Cloning](https://arxiv.org/abs/2507.02380)
**中文标题：JoyTTS：基于LLM的语音聊天机器人及语音克隆技术**

*Fangru Zhou,Jun Zhao,Guoxin Wang*

主要分类: cs.SD

摘要简述: JoyTTS是一款结合大型语言模型（LLM）与文本转语音（TTS）技术的端到端语音聊天机器人，具备语音克隆功能。基于开源模型MiniCPM-o和CosyVoice2，训练了2000小时对话数据，并提供完整训练代码。测试结果显示其说话人相似度（SS）为0.73，词错误率（WER）为5.09。


<details>
  <summary>详细信息</summary>
研究动机: 开发一款结合LLM与TTS技术的语音聊天机器人，通过语音克隆功能提升用户体验，同时开源代码和模型以促进社区进一步优化。

研究方法: 基于开源模型MiniCPM-o和CosyVoice2，训练2000小时对话数据，实现端到端的语音聊天功能，并提供完整训练代码。

研究结果: 在测试机器seed-tts-zh上，JoyTTS的说话人相似度（SS）为0.73，词错误率（WER）为5.09。

研究结论: JoyTTS成功结合LLM与TTS技术，具备语音克隆功能，性能表现优异，开源代码和模型为社区提供了进一步开发的基础。

中文摘要: JoyTTS是一款端到端的语音聊天机器人，结合了大型语言模型（LLM）与文本转语音（TTS）技术，并具备语音克隆功能。该项目基于开源模型MiniCPM-o和CosyVoice2，训练了2000小时的对话数据。我们还提供了完整的训练代码，以便社区进一步开发和优化。在测试机器seed-tts-zh上，其说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。代码和模型，以及训练和推理脚本，可在https://github.com/jdh-algo/JoyTTS.git获取。

</details>


### [159] [ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning](https://arxiv.org/abs/2507.02666)
**中文标题：ASDA：用于自监督表示学习的音频谱图差分注意力机制**

*Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang*

主要分类: cs.SD

摘要简述: 本文提出了一种名为ASDA的音频谱图差分注意力机制，通过双软最大操作和差分系数优化，解决了传统Transformer注意力机制分配无效权重的问题，显著提升了音频自监督表示学习的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前音频自监督表示学习中，Transformer的注意力机制常将部分权重分配给无关信息，影响模型判别能力。为解决这一问题，本文提出了差分注意力机制。

研究方法: ASDA模型通过双软最大操作和差分系数优化，有效减少无效注意力分配，提升模型对音频数据的表示能力。

研究结果: 实验表明，ASDA在多个基准测试中达到SOTA性能，包括音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词识别（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）。

研究结论: ASDA通过差分注意力机制显著提升了音频任务的性能，为更广泛的应用奠定了基础。

中文摘要: 在音频自监督表示学习的最新进展中，标准Transformer架构已成为主流方法，但其注意力机制常将部分注意力权重分配给无关信息，可能损害模型的判别能力。为此，我们提出了一种差分注意力机制，通过双软最大操作和适当调整的差分系数，有效减少了无效注意力分配。实验结果表明，我们的ASDA模型在多个基准测试中达到了最先进的性能，包括音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词识别（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）。这些结果凸显了ASDA在音频任务中的有效性，为更广泛的应用铺平了道路。

</details>


### [160] [De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks](https://arxiv.org/abs/2507.02606)
**中文标题：反反伪造：重新思考针对语音克隆攻击的保护性扰动**

*Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu*

主要分类: cs.SD

摘要简述: 本文首次系统评估了针对语音克隆（VC）的保护性扰动在实际威胁模型下的效果，发现现有净化方法虽能中和部分扰动，但仍导致VC模型特征空间失真，从而降低VC性能。作者提出了一种新颖的两阶段净化方法，实验表明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着语音生成模型的快速发展，语音克隆（VC）引发的隐私和安全问题日益突出。尽管已有研究通过引入对抗性扰动来干扰未经授权的VC，但攻击者仍能通过净化技术绕过这些保护。因此，本文旨在系统评估这些保护性扰动的实际效果，并探索更有效的防御方法。

研究方法: 本文提出了一种两阶段净化方法：1）对受扰动的语音进行净化；2）利用音素引导将其与干净语音分布对齐。该方法通过实验验证其在破坏VC防御方面的优越性。

研究结果: 实验结果表明，现有净化方法虽能中和部分保护性扰动，但会导致VC模型特征空间失真，从而降低VC性能。作者提出的两阶段净化方法在破坏VC防御方面优于现有技术。

研究结论: 本研究揭示了基于对抗性扰动的VC防御的局限性，并强调需要更鲁棒的解决方案来应对VC带来的安全和隐私风险。

中文摘要: 语音生成模型的快速发展加剧了与语音克隆（VC）相关的隐私和安全问题。近期研究通过引入对抗性扰动来干扰未经授权的VC，但攻击者仍能通过净化技术绕过这些保护。本研究首次系统评估了这些保护性扰动在实际威胁模型（包括扰动净化）下的效果。研究发现，尽管现有净化方法能中和大部分保护性扰动，但仍会导致VC模型特征空间失真，从而降低VC性能。基于此，我们提出了一种新颖的两阶段净化方法：1）净化受扰动的语音；2）利用音素引导将其与干净语音分布对齐。实验结果表明，我们的方法在破坏VC防御方面优于现有净化技术。本研究揭示了基于对抗性扰动的VC防御的局限性，并强调了开发更鲁棒解决方案的紧迫性。代码和音频样本可在https://de-antifake.github.io获取。

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [161] [Subtyping in DHOL -- Extended preprint](https://arxiv.org/abs/2507.02855)
**中文标题：DHOL中的子类型化——扩展预印本**

*Colin Rothgang,Florian Rabe*

主要分类: cs.LO

摘要简述: 本文扩展了依赖类型高阶逻辑（DHOL），通过引入细化和商类型作为子类型的特例，提升了表达能力和自动化支持，同时保持了向HOL的完整翻译。


<details>
  <summary>详细信息</summary>
研究动机: 依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间提供了平衡，但其类型系统不可判定。为了满足实践中对细化和商类型的需求，本文旨在扩展DHOL，使其支持这些类型，同时避免复杂的表示转换。

研究方法: 通过将细化和商类型作为子类型的特例引入DHOL，将相关的规范包含和投影映射转化为恒等映射，从而避免高成本的表示变化。文章详细描述了扩展语言的语法、语义及其向HOL的翻译，并提供了完备性和一致性的证明。

研究结果: 扩展后的DHOL成功支持了细化和商类型，同时保持了向HOL的翻译的完备性和一致性。这种设计不仅实现了功能扩展，还保持了简洁性和优雅性。

研究结论: 本文通过子类型机制成功扩展了DHOL，使其支持细化和商类型，同时保持了系统的简洁性和自动化支持能力。这一设计为依赖类型逻辑的进一步应用提供了新的可能性。

中文摘要: 最近引入的依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间提供了一种有趣的折衷方案。它牺牲了类型系统的可判定性，以显著扩展其相对于标准HOL的表达能力，同时通过向HOL的完备且一致的翻译保留了强大的自动化定理证明支持。
  我们利用这一设计，将DHOL扩展为支持细化和商类型。这两种类型在实践中常被需求，但自动化定理证明工具很少提供。这是因为它们本质上需要不可判定的类型系统，因此很难在可判定的类型系统中实现。但由于DHOL已经承担了大部分工作，添加它们不仅可能，而且优雅且简单。
  具体而言，我们将细化和商类型作为子类型的特例引入。这将相关的规范包含和投影映射转化为恒等映射，从而避免了高成本的表示变化。我们为扩展后的语言提供了语法、语义及其向HOL的翻译，包括完备性和一致性的证明。

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [162] [Integrating Large Language Models in Financial Investments and Market Analysis: A Survey](https://arxiv.org/abs/2507.01990)
**中文标题：大型语言模型在金融投资与市场分析中的整合应用：综述**

*Sedigheh Mahdavi,Jiating,Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh*

主要分类: q-fin.GN

摘要简述: 本文综述了大型语言模型（LLMs）在金融投资与市场分析中的应用，总结了其提升决策能力的研究框架和潜在挑战。


<details>
  <summary>详细信息</summary>
研究动机: 传统金融投资策略依赖定量模型和基本面分析，但LLMs能够处理海量结构化和非结构化数据，为实时决策提供新视角。本文旨在系统梳理LLMs在金融领域的研究进展。

研究方法: 通过分类研究贡献为四大框架：LLM基础框架与流程、混合集成方法、微调与适应方法、基于代理的架构，综述了LLMs在选股、风险评估、情感分析、交易和金融预测中的应用。

研究结果: 研究发现LLMs在金融领域展现出强大潜力，但也面临数据质量、模型解释性等挑战。

研究结论: LLMs为金融决策提供了新工具，未来需进一步解决实际应用中的问题。

中文摘要: 大型语言模型（LLMs）已被应用于金融决策，提升了投资策略的分析能力。传统投资策略通常依赖定量模型、基本面分析和技术指标，而LLMs能够处理和分析大量结构化和非结构化数据，提取有意义的见解，并实时优化决策。本文系统综述了金融领域中LLMs的最新研究，将研究贡献分为四大框架：基于LLM的框架与流程、混合集成方法、微调与适应方法、基于代理的架构。研究回顾了LLMs在选股、风险评估、情感分析、交易和金融预测中的应用，总结了其能力、挑战和未来发展方向。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [163] [Legal Requirements Translation from Law](https://arxiv.org/abs/2507.02846)
**中文标题：从法律中翻译法律需求**

*Anmol Singhal,Travis Breaux*

主要分类: cs.SE

摘要简述: 本文提出了一种基于文本蕴含和上下文学习的方法，用于自动生成法律文本的规范表示，并将其编码为可执行的Python代码，以减少对大规模人工标注数据的依赖，并提高对新法规的适用性。


<details>
  <summary>详细信息</summary>
研究动机: 软件系统需符合法律规范，但小型企业和初创公司缺乏法律专业知识，手动提取法律需求耗时且复杂。现有自动化方法未考虑元数据属性间的关联性，且依赖人工标注或启发式机器学习，难以推广到新文档。

研究方法: 采用文本蕴含和上下文学习技术，设计了一个领域特定的Python类结构作为元模型，自动生成法律文本的规范表示，捕获结构和语义元数据及其关联性。

研究结果: 在13个美国州的数据泄露通知法律上测试，生成的表示通过约89.4%的测试用例，精确率和召回率分别为82.2和88.7。

研究结论: 该方法显著减少了对人工标注数据的依赖，提高了对新法规的适用性，为法律需求提取提供了高效解决方案。

中文摘要: 软件系统必须遵守法律规定，这对缺乏法律专业知识的小型组织和初创公司是一项资源密集型任务。从法规中提取元数据以获取软件的法律需求是确保合规性的关键步骤，但由于法律文本的冗长和复杂性，这一任务十分繁琐。尽管已有研究探索了从法律文本中自动提取结构和语义元数据的方法，但仍存在关键限制：未考虑这些元数据类型属性间的相互作用和关联，且依赖人工标注或启发式机器学习，难以推广到新文档。本文提出了一种基于文本蕴含和上下文学习的方法，用于自动生成法律文本的规范表示，并将其编码为可执行的Python代码。该表示基于手动设计的Python类结构作为领域特定元模型，捕获结构和语义法律元数据及其关联性。这一设计减少了对大规模人工标注数据的需求，并提高了对新法规的适用性。我们在13个美国州的数据泄露通知法律上评估了该方法，结果表明生成的表示通过了约89.4%的测试用例，精确率和召回率分别为82.2和88.7。

</details>


### [164] [Requirements Elicitation Follow-Up Question Generation](https://arxiv.org/abs/2507.02858)
**中文标题：需求获取后续问题生成**

*Yuchen Shen,Anmol Singhal,Travis Breaux*

主要分类: cs.SE

摘要简述: 研究探讨了使用GPT-4o在需求获取访谈中实时生成后续问题的可行性，实验表明LLM生成的问题在清晰度、相关性和信息量上不亚于人工编写的问题，且在指导条件下表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 需求获取访谈中，访谈者面临领域不熟悉、认知负荷高和信息过载等挑战，需要实时生成高质量问题。研究旨在利用LLM（如GPT-4o）辅助访谈者提升访谈质量。

研究方法: 基于常见访谈错误类型框架，利用GPT-4o生成后续问题；设计两种实验：无指导条件下比较LLM与人工问题，以及指导条件下评估LLM生成问题的表现。

研究结果: 实验表明，LLM生成的问题在清晰度、相关性和信息量上与人工问题相当；在指导条件下，LLM问题表现优于人工问题。

研究结论: LLM可实时辅助访谈者生成高质量问题，提升需求获取访谈的效率和效果。

中文摘要: 访谈是需求获取中广泛使用的技术，用于收集利益相关者对软件系统的需求、偏好和期望。有效的访谈需要访谈者实时提出合适的问题，但面临领域不熟悉、认知负荷高和信息过载等挑战。近期，大语言模型（LLM）在文本摘要和蕴含等自然语言处理任务中表现出色。为支持访谈者，本研究探讨了利用GPT-4o在需求获取中生成后续问题的方法，基于常见访谈错误类型框架。此外，描述了根据受访者发言生成问题的方法。通过两项对照实验，评估了无指导条件下LLM生成问题与人工问题的表现，以及指导条件下LLM问题的表现。结果显示，两种实验中，LLM生成的问题在清晰度、相关性和信息量上不亚于人工问题；在指导条件下，LLM问题表现更优。这表明LLM可帮助访谈者实时提升需求获取访谈的质量和效率。

</details>


### [165] [VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software](https://arxiv.org/abs/2507.02376)
**中文标题：VeFIA：一种高效的垂直联邦协作软件推理审计框架**

*Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang*

主要分类: cs.SE

摘要简述: 本文提出了一种名为VeFIA的高效推理审计框架，用于垂直联邦学习中数据方推理软件的执行正确性审计，确保任务方能够在不泄露隐私或增加延迟的情况下检测异常。


<details>
  <summary>详细信息</summary>
研究动机: 现有的垂直联邦学习（VFL）缺乏对数据方推理软件执行正确性的审计机制，导致任务方无法验证推理过程是否按预期执行。

研究方法: VeFIA框架利用可信执行环境（TEE）和协调器，通过随机采样验证数据方的计算结果，确保审计的高效性和隐私保护。

研究结果: VeFIA在异常推理超过5.4%时能以99.99%的概率检测到异常，且随机采样验证的阳性预测值、阴性预测值和真阳性率均达到100%。

研究结论: VeFIA是首个针对VFL中推理软件执行正确性问题的解决方案，显著提升了推理审计的效率和可靠性。

中文摘要: 垂直联邦学习（VFL）是一种无需访问参与者数据的跨机构分布式AI软件部署机制。然而，现有VFL工作缺乏对数据方推理软件执行正确性的审计机制。为解决这一问题，我们设计了垂直联邦推理审计（VeFIA）框架。VeFIA帮助任务方在大规模推理过程中审计数据方的推理软件是否按预期执行，同时不泄露数据方的隐私或增加系统延迟。VeFIA的核心在于任务方可以利用基于可信执行环境（TEE）的框架和协调器验证数据方计算结果的正确性。VeFIA保证，只要异常推理超过5.4%，任务方就能以99.99%的概率检测到推理软件的执行异常，且不会引入额外的在线推理延迟。VeFIA的随机采样验证在检测异常推理时实现了100%的阳性预测值、阴性预测值和真阳性率。据我们所知，这是首篇讨论VFL中推理软件执行正确性的论文。

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [166] [FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports](https://arxiv.org/abs/2507.01991)
**中文标题：FinAI-BERT：一种基于Transformer的财务报告中AI披露句子级检测模型**

*Muhammad Bilal Zafar*

主要分类: q-fin.CP

摘要简述: 本文提出FinAI-BERT，一种基于Transformer的模型，用于在财务报告中检测句子级别的AI披露内容，性能优异且可解释性强。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在金融服务中的广泛应用，现有工具在检测财务文件中的AI相关内容时缺乏细粒度、可解释性和鲁棒性，因此需要一种更高效、透明的解决方案。

研究方法: 研究开发了FinAI-BERT，一种基于Transformer的语言模型，通过在669份美国银行年报（2015-2023年）中手工标注的1,586个句子数据集上进行微调，实现了句子级别的AI内容分类。

研究结果: FinAI-BERT表现优异，准确率达99.37%，F1分数为0.993，显著优于传统基线模型（如逻辑回归、朴素贝叶斯等），并通过SHAP分析和鲁棒性测试验证了其稳定性和可解释性。

研究结论: FinAI-BERT不仅推动了金融NLP领域的发展，还为分析师、监管机构和学者提供了一种可扩展且透明的工具，用于监测金融机构中AI的应用和表述。

中文摘要: 人工智能（AI）在金融服务中的广泛应用催生了对能够系统检测公司文件中AI相关披露内容工具的需求。然而，现有方法多依赖关键词扩展或文档级分类，缺乏细粒度、可解释性和鲁棒性。本研究提出FinAI-BERT，一种基于Transformer的语言模型，专为财务文本中句子级别的AI相关内容分类设计。该模型在从669份美国银行年报（2015至2023年）中手工标注的1,586个平衡句子数据集上进行了微调。FinAI-BERT实现了近乎完美的分类性能（准确率99.37%，F1分数0.993），显著优于逻辑回归、朴素贝叶斯、随机森林和XGBoost等传统基线模型。通过基于SHAP的标记归因确保了可解释性，同时偏差分析和鲁棒性测试验证了模型在不同句子长度、对抗输入和时间样本中的稳定性。理论上，本研究通过利用Transformer架构实现细粒度、主题特定的分类，推动了金融NLP的发展。实践中，它为分析师、监管机构和学者提供了一种可扩展、透明的解决方案，用于监测AI在金融机构中的扩散和表述。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [167] [HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3](https://arxiv.org/abs/2507.02345)
**中文标题：HelixDesign-Antibody：基于HelixFold3的可扩展生产级抗体设计平台**

*Jie Gao,Jing Hu,Shanzhuo Zhang,Kunrui Zhu,Sheng Qian,Yueyang Huang,Xiaonan Zhang,Xiaomin Fang*

主要分类: q-bio.BM

摘要简述: HelixDesign-Antibody是一个基于HelixFold3的高通量抗体设计平台，通过高效计算支持大规模生成和评估抗体候选序列，显著提升抗体工程效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统抗体发现方法依赖耗时且资源密集的实验筛选，亟需一种高效、可扩展的平台来优化抗体设计流程。

研究方法: 基于高精度结构预测模型HelixFold3，构建了HelixDesign-Antibody平台，结合高性能计算支持，实现抗体候选序列的大规模生成与抗原相互作用评估。

研究结果: 平台在多个抗原上验证成功，能够生成多样且高质量的抗体，并证实通过扩大序列空间探索可提高发现最优结合体的概率。

研究结论: HelixDesign-Antibody为大规模抗体设计提供了无缝、易用的解决方案，显著提升了抗体工程的效率和可扩展性。

中文摘要: 抗体工程对于开发治疗药物和推动生物医学研究至关重要。传统发现方法通常依赖耗时且资源密集的实验筛选。为了优化和简化这一过程，我们推出了基于HelixFold3的生产级高通量平台HelixDesign-Antibody。该平台利用高精度结构预测模型HelixFold3，支持大规模生成抗体候选序列并评估其与抗原的相互作用。集成的高性能计算（HPC）支持实现了高通量筛选，解决了工具链分散和高计算需求等挑战。在多个抗原上的验证表明，该平台能够生成多样且高质量的抗体，并证实了通过扩大序列空间探索可提高发现最优结合体的概率。该平台为大规模抗体设计提供了无缝、易用的解决方案，可通过PaddleHelix平台的抗体设计页面访问。

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [168] [Toward a Robust and Generalizable Metamaterial Foundation Model](https://arxiv.org/abs/2507.02436)
**中文标题：迈向稳健且通用的超材料基础模型**

*Namjung Kim,Dongseok Lee,Jongbin Yu,Sung Woong Cho,Dosung Lee,Yesol Park,Youngjoon Hong*

主要分类: physics.optics

摘要简述: 本文提出了一种基于贝叶斯变换器的超材料基础模型MetaFO，能够实现零样本预测和非线性逆向设计，显著扩展了超材料的设计空间。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI驱动的超材料设计方法存在任务需重新训练、泛化能力差以及需要独立模型处理正向和逆向设计的问题，限制了其应用潜力。

研究方法: 作者提出了MetaFO模型，受大型语言模型启发，通过学习超材料的底层力学特性，实现概率性零样本预测和非线性逆向设计。

研究结果: MetaFO在未见过的材料属性和结构响应组合中表现出色，尤其在非线性逆向设计和OOD条件下表现优异。

研究结论: MetaFO为AI驱动的超材料发现提供了可扩展且通用的框架，标志着该领域的范式转变。

中文摘要: 材料功能的进步推动了多个领域的创新，其中由结构而非成分定义的超材料引领潮流。尽管人工智能（AI）驱动的设计策略兴起，但其影响受限于任务需重新训练、分布外（OOD）泛化能力差以及需要独立模型处理正向和逆向设计。为解决这些问题，我们提出了基于贝叶斯变换器的超材料基础模型MetaFO，其灵感来自大型语言模型。MetaFO学习超材料的底层力学特性，能够对多样且未见过的材料属性和结构响应组合进行概率性零样本预测。该模型在非线性逆向设计中表现出色，即使在OOD条件下也是如此。通过将超材料视为从材料属性映射到结构响应的算子，MetaFO揭示了复杂的结构-属性关系，并显著扩展了设计空间。这一可扩展且通用的框架标志着AI驱动的超材料发现领域的范式转变，为下一代创新铺平了道路。

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [169] [Solving the Hubbard model with Neural Quantum States](https://arxiv.org/abs/2507.02644)
**中文标题：利用神经量子态求解Hubbard模型**

*Yuntian Gu,Wenrui Li,Heng Lin,Bo Zhan,Ruichen Li,Yifei Huang,Di He,Yantao Wu,Tao Xiang,Mingpu Qin,Liwei Wang,Dingshun Lv*

主要分类: cond-mat.str-el

摘要简述: 本文利用基于Transformer的神经量子态（NQS）框架，结合高效优化算法，成功解决了掺杂二维Hubbard模型，揭示了其基态中的半填充条纹结构，与铜氧化物实验结果一致。


<details>
  <summary>详细信息</summary>
研究动机: 神经量子态（NQS）在量子多体系统研究中展现出巨大潜力。本文旨在通过先进的Transformer架构和优化算法，解决二维Hubbard模型，探索其在高温超导研究中的最小模型特性。

研究方法: 采用基于Transformer的神经量子态（NQS）架构，开发高效优化算法，研究掺杂二维Hubbard模型，并分析其不同注意力头对多尺度关联的编码能力。

研究结果: 成功实现了二维Hubbard模型的最先进结果，发现NQS能够直接编码不同尺度的关联，捕捉强关联系统中的长程关联和纠缠。同时，在基态中确认了半填充条纹结构，与铜氧化物实验结果一致。

研究结论: 神经量子态（NQS）为解决复杂多费米子系统提供了强大工具，其Transformer架构能够有效捕捉强关联系统的关键特性。

中文摘要: 神经量子态（NQS）的快速发展使其成为研究量子多体系统的有前景框架。本文通过利用前沿的基于Transformer的架构和开发高效优化算法，在掺杂二维Hubbard模型（高温超导的最小模型）中取得了最先进的结果。有趣的是，我们发现NQS中的不同注意力头可以直接编码不同尺度的关联，使其能够捕捉强关联系统中的长程关联和纠缠。通过这些进展，我们在二维Hubbard模型的基态中确认了半填充条纹结构，与铜氧化物的实验结果一致。我们的工作确立了NQS作为解决复杂多费米子系统的强大工具。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [170] [Early Signs of Steganographic Capabilities in Frontier LLMs](https://arxiv.org/abs/2507.02737)
**中文标题：前沿大型语言模型中隐写能力的早期迹象**

*Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner*

主要分类: cs.CR

摘要简述: 前沿大型语言模型（LLM）已展现出初步的隐写能力，能够在看似正常的输出中隐藏信息或进行编码推理，但目前尚不足以绕过设计良好的监控。


<details>
  <summary>详细信息</summary>
研究动机: 研究前沿LLM的隐写能力，以评估其潜在风险，尤其是如何通过隐写技术逃避监控。

研究方法: 评估LLM在两种隐写任务中的表现：传递编码信息和进行编码推理，并测试其在有无额外辅助（如未监控的草稿纸和预定义编码方案）下的成功率。

研究结果: 当前LLM在标准条件下无法隐藏短信息而不被监控发现，但在额外辅助下可以成功；同时展现出初步的编码推理能力，但难以在掩盖任务中隐藏推理过程。

研究结论: 前沿LLM已具备初步隐写能力，但目前不足以绕过设计良好的监控，未来需警惕其发展。

中文摘要: 监控大型语言模型（LLM）的输出对于减少滥用和错位风险至关重要。然而，LLM可能通过隐写技术逃避监控：在看似无害的生成中隐藏信息。本文评估了前沿LLM的隐写能力，以更好地理解其风险。我们关注两种隐写类型：传递编码信息和进行编码推理。研究发现，当前模型在标准条件下无法隐藏短信息而不被监控发现，但在使用未监控草稿纸和协调编码方案等额外辅助下可以成功。此外，模型在简单状态跟踪问题中展现出初步的编码推理能力，包括使用自定义和预定义编码方案（如十六进制）。尽管如此，它们很少能巧妙地将推理隐藏在掩盖任务中以欺骗监控。总体而言，结果表明当前LLM具备初步隐写能力。虽然目前这些能力可能不足以绕过设计良好的监控，但未来可能发生变化。

</details>


### [171] [MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation](https://arxiv.org/abs/2507.02057)
**中文标题：MGC：一种利用对齐LLM组合性盲区的恶意软件生成编译器框架**

*Lu Yan,Zhuo Zhang,Xiangzhe Xu,Shengwei An,Guangyu Shen,Zhou Xuan,Xuan Chen,Xiangyu Zhang*

主要分类: cs.CR

摘要简述: 本文提出了一种名为MGC的编译器框架，利用对齐大型语言模型（LLM）的组合性盲区，通过模块化分解和规避对齐的生成方法，成功生成功能性恶意软件。实验表明，MGC在正确性上显著优于越狱方法和地下服务，并能复现和增强真实恶意软件样本。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）降低了软件开发的门槛，但也为恶意软件开发提供了便利。尽管LLM提供商已通过对齐机制阻止直接生成恶意代码，但这些机制仅评估单个提示，忽视了恶意操作可被分解为看似良性的子任务这一漏洞。本文旨在利用这一漏洞，开发一种能够生成恶意软件的框架。

研究方法: MGC框架通过模块化分解和规避对齐的生成方法，利用专门的恶意软件描述中间表示（MDIR）将高级恶意意图与看似良性的代码片段连接起来。这种方法能够绕过LLM的对齐机制，生成功能性恶意软件。

研究结果: 实验表明，MGC在三个基准数据集上的正确性分别比越狱方法和地下服务高出365.79%和78.07%。此外，MGC还能复现并增强16个真实恶意软件样本。

研究结论: 本文揭示了组合性攻击对对齐AI系统的风险，为安全研究人员提供了重要见解。MGC的成功表明，当前的对齐机制存在漏洞，需要进一步改进以防止恶意利用。

中文摘要: 大型语言模型（LLM）降低了软件开发的专业门槛，但也为恶意软件开发提供了便利。尽管LLM提供商已通过对齐机制阻止直接生成恶意代码，但这些机制主要评估单个提示，忽视了恶意操作可被分解为看似良性的子任务这一关键漏洞。本文提出了一种名为恶意软件生成编译器（MGC）的新框架，通过模块化分解和规避对齐的生成方法利用这一漏洞。MGC采用专门的恶意软件描述中间表示（MDIR）连接高级恶意意图与看似良性的代码片段。大量实验表明，我们的攻击方法能够可靠地为不同任务和类别生成功能性恶意软件，在三个基准数据集上的正确性分别比越狱方法和地下服务高出365.79%和78.07%。案例研究进一步显示，MGC能够复现甚至增强16个真实恶意软件样本。这项工作通过揭示组合性攻击对对齐AI系统的风险，为安全研究人员提供了重要见解。演示内容请访问：https://sites.google.com/view/malware-generation-compiler。

</details>


### [172] [Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities](https://arxiv.org/abs/2507.02125)
**中文标题：人工智能能否解决区块链预言机问题？挑战与可能性的探讨**

*Giulio Caldarelli*

主要分类: cs.CR

摘要简述: 本文探讨人工智能（AI）是否能解决区块链预言机问题，分析其挑战与可能性，认为AI可作为补充工具提升数据质量和系统韧性，但无法完全消除对外部数据的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 区块链预言机问题限制了去中心化应用的发展，现有方法未能完全解决如何让区块链获取链外数据的问题。本文旨在评估AI在解决这一问题中的潜力。

研究方法: 通过分析学术文献和实践案例，研究了AI技术（如异常检测、语言事实提取、动态声誉建模和对抗性抵抗）如何提升预言机系统的性能。

研究结果: AI能显著提升数据质量、来源选择和系统韧性，但仍需依赖不可验证的链外输入，无法完全替代信任假设。

研究结论: AI应被视为预言机设计中的补充层，用于推断和过滤，而非完全替代信任机制。

中文摘要: 区块链预言机问题是指将可靠的外部数据注入去中心化系统的挑战，这仍是开发无需信任应用的根本限制。近年来，尽管出现了多种架构、密码学和经济策略以缓解此问题，但尚未有人完全解决区块链如何获取链外知识的基本问题。在本立场论文中，我们批判性地评估了人工智能（AI）在解决预言机问题中的作用。通过结合学术文献和实践案例，我们探讨了AI技术（如异常检测、语言事实提取、动态声誉建模和对抗性抵抗）如何提升预言机系统。我们发现，尽管AI为提升数据质量、来源选择和系统韧性提供了强大工具，但无法消除对不可验证链外输入的依赖。因此，本研究支持将AI视为更广泛预言机设计中的补充层，用于推断和过滤，而非替代信任假设。

</details>


### [173] [EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer](https://arxiv.org/abs/2507.02206)
**中文标题：EIM-TRNG：通过RowHammer利用内存编码真随机数生成器混淆深度神经网络权重**

*Ranyang Zhou,Abeer Matar A. Almalky,Gamana Aragonda,Sabbir Ahmed,Filip Roth Trønnes-Christensen,Adnan Siraj Rakin,Shaahin Angizi*

主要分类: cs.CR

摘要简述: 本文提出了一种名为EIM-TRNG的新型硬件安全方法，利用DRAM中RowHammer引起的物理随机性生成真随机数，并将其应用于保护深度神经网络权重数据。


<details>
  <summary>详细信息</summary>
研究动机: 在深度神经网络（DNN）中，保护模型权重对确保AI系统的完整性、隐私和知识产权至关重要。现有的软件伪随机数生成器缺乏硬件真随机数生成器（TRNG）的不可预测性和鲁棒性，因此需要一种基于硬件的TRNG解决方案。

研究方法: 提出了一种名为EIM-TRNG的编码内存真随机数生成器，通过精确控制RowHammer操作，利用DRAM单元行为的物理随机性生成不可预测的比特翻转作为熵源。进一步将该TRNG框架应用于DNN权重数据的加密，结合固定和不可预测的比特翻转进行编码，并通过基于翻转行为的密钥解密。

研究结果: 实验验证了基于DRAM的熵提取在硬件安全中的有效性，提供了一种低成本且鲁棒的保护机器学习模型的方法。

研究结论: EIM-TRNG为硬件级保护机器学习模型提供了一种有前景的方向，同时确保了数据的机密性和模型的真实性。

中文摘要: 真随机数生成器（TRNG）在硬件安全、加密系统和数据保护中扮演着基础性角色。在深度神经网络（DNN）的背景下，保护模型参数（尤其是权重）对确保AI系统的完整性、隐私和知识产权至关重要。尽管基于软件的伪随机数生成器被广泛使用，但它们缺乏基于硬件的TRNG所提供的不可预测性和鲁棒性。本文首次提出了一种新颖且鲁棒的编码内存真随机数生成器EIM-TRNG，利用DRAM单元行为（特别是RowHammer引起的扰动）中的固有物理随机性。我们展示了如何通过精确控制的RowHammer操作生成的不可预测比特翻转作为可靠的熵源。此外，我们通过结合固定和不可预测的比特翻转，将该TRNG框架应用于保护DNN权重数据。加密数据随后通过基于概率翻转行为的密钥解密，确保数据机密性和模型真实性。我们的结果验证了基于DRAM的熵提取在低成本硬件安全中的有效性，并为硬件级保护机器学习模型提供了一种有前景的方向。

</details>


### [174] [Evaluating Language Models For Threat Detection in IoT Security Logs](https://arxiv.org/abs/2507.02390)
**中文标题：评估语言模型在物联网安全日志中的威胁检测能力**

*Jorge J. Tejero-Fernández,Alfonso Sánchez-Macián*

主要分类: cs.CR

摘要简述: 本文提出了一种利用微调大型语言模型（LLMs）进行物联网安全日志异常检测和缓解建议的流程，比较了三种开源LLMs在零样本、少样本和微调策略下的表现，发现其在多类攻击分类中优于传统机器学习模型。


<details>
  <summary>详细信息</summary>
研究动机: 日志分析是网络安全中的重要研究领域，可用于检测网络和系统的威胁。本文旨在探索如何利用LLMs提升物联网安全日志的异常检测和缓解建议能力。

研究方法: 通过微调LLMs，结合零样本、少样本和微调三种策略，对物联网安全日志进行异常检测和分类。同时，将检测到的威胁映射到MITRE CAPEC框架，并定义物联网特定的缓解措施，为模型提供检测和建议的综合能力。

研究结果: 实验表明，LLMs在多类攻击分类任务中表现优于传统机器学习模型，并能结合MITRE CAPEC框架提供有效的缓解建议。

研究结论: 微调LLMs在物联网安全日志分析中具有显著优势，能够同时实现高精度的异常检测和实用的缓解建议。

中文摘要: 日志分析是网络安全中的一个重要研究领域，可为网络和系统的威胁检测提供信息来源。本文提出了一种流程，利用微调的大型语言模型（LLMs）进行物联网安全日志的异常检测和缓解建议。通过将传统机器学习分类器作为基线，比较了三种开源LLMs在零样本、少样本和微调策略下的二分类和多分类异常检测性能。结果表明，LLMs在多类攻击分类任务中优于基线模型。通过将检测到的威胁映射到MITRE CAPEC框架，并定义一组物联网特定的缓解措施，模型能够提供检测和建议的综合指导。

</details>


### [175] [CyberRAG: An agentic RAG cyber attack classification and reporting tool](https://arxiv.org/abs/2507.02424)
**中文标题：CyberRAG：一种基于代理的RAG网络攻击分类与报告工具**

*Francesco Blefari,Cristian Cosentino,Francesco Aurelio Pironti,Angelo Furfaro,Fabrizio Marozzo*

主要分类: cs.CR

摘要简述: CyberRAG是一种基于代理的RAG框架，用于实时分类、解释和结构化报告网络攻击，通过模块化设计和动态推理显著降低误报率并提升可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 大型企业的入侵检测和防御系统（IDS/IPS）每小时生成数十万条警报，传统机器学习检测器误报率高，标准RAG管道检索的上下文不相关且无法合理解释预测。CyberRAG旨在解决这些问题。

研究方法: CyberRAG采用模块化、基于代理的RAG框架，包括一个中央LLM代理、一组针对特定攻击家族优化的分类器、工具适配器以及迭代检索和推理循环，动态优化威胁标签和自然语言解释。

研究结果: CyberRAG在每类攻击中准确率超过94%，通过语义协调最终分类准确率达94.92%。生成的解释在BERTScore中得分0.94，GPT-4专家评分为4.9/5。

研究结论: CyberRAG展示了基于代理的RAG框架在网络安全中的潜力，能够结合高检测准确率和可信的解释，为半自主网络防御工作流提供实用且可扩展的解决方案。

中文摘要: 大型企业的入侵检测和防御系统（IDS/IPS）每小时可生成数十万条警报，使安全分析师淹没在需要深厚且快速演变的领域知识的日志中。传统的机器学习检测器虽减少了警报量，但仍存在高误报率，而标准的单次检索增强生成（RAG）管道常检索无关上下文且无法合理解释预测。为克服这些不足，我们提出了CyberRAG，一种模块化、基于代理的RAG框架，提供网络攻击的实时分类、解释和结构化报告。其核心LLM代理协调（i）一组针对特定攻击家族优化的分类器；（ii）用于丰富和警报的工具适配器；（iii）迭代检索和推理循环，持续查询领域知识库直至证据相关且自洽。与传统RAG系统不同，CyberRAG采用代理设计，支持动态控制流和自适应推理。这种以代理为中心的架构自主优化威胁标签和自然语言解释，降低误报率并提升可解释性。该框架完全可扩展：仅需添加分类器即可支持新攻击类型，无需重新训练核心代理。CyberRAG评估结果显示，每类攻击准确率超过94%，通过语义协调最终分类准确率达94.92%。生成的解释在BERTScore中得分0.94，GPT-4专家评分为4.9/5。这些结果表明，基于代理的、面向专家的RAG能将高检测准确率与可信的、SOC就绪的解释相结合，为半自主网络防御工作流提供实用且可扩展的路径。

</details>


### [176] [Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](https://arxiv.org/abs/2507.02735)
**中文标题：Meta SecAlign：一种抵御提示注入攻击的安全基础大语言模型**

*Sizhe Chen,Arman Zharmagambetov,David Wagner,Chuan Guo*

主要分类: cs.CR

摘要简述: Meta SecAlign是首个开源且开放的具有内置模型级防御的大语言模型（LLM），能有效抵御提示注入攻击，并在性能和安全性上达到商业级水平。


<details>
  <summary>详细信息</summary>
研究动机: 提示注入攻击对LLM集成应用构成重大安全威胁。目前模型级防御虽有效，但多为闭源商业模型。开源模型对AI安全社区至关重要，可促进攻击与防御的协同研究。

研究方法: 开发了Meta SecAlign，采用改进版的SOTA SecAlign防御技术，并公开完整的训练方案。模型基于通用指令调优数据集训练，具备对未见下游任务的安全性。

研究结果: Meta-SecAlign-70B在9个实用基准和7个安全基准测试中表现优异，抵御提示注入攻击的鲁棒性达到SOTA水平，且实用性与闭源商业LLM相当。

研究结论: Meta SecAlign为开源社区提供了首个兼具高性能和安全性的LLM，推动了对抗提示注入攻击的研究进展。

中文摘要: 提示注入攻击对集成大语言模型（LLM）的应用构成重大安全威胁。模型级防御虽表现出强大效果，但目前仅以闭源形式部署于商业级模型中。我们认为，AI安全社区需要开源模型，通过开放研究推动攻击与防御的协同发展，从而科学地缓解提示注入攻击。为此，我们开发了Meta SecAlign，这是首个开源且开放权重的LLM，内置模型级防御，并达到商业级模型性能。我们提供了完整的训练方案细节，其中采用了改进版的SOTA SecAlign防御技术。在9个实用基准和7个安全基准测试中，Meta SecAlign尽管基于通用指令调优数据集训练，仍能对未见下游任务（包括工具调用和代理网络导航）提供安全性，同时保持通用指令遵循能力。我们的最佳模型——Meta-SecAlign-70B——在抵御提示注入攻击方面达到SOTA鲁棒性，且实用性与具有模型级防御的闭源商业LLM相当。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [177] [Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting](https://arxiv.org/abs/2507.01997)
**中文标题：迈向一个民主化网络故障排除AI代理实验与基准测试的游乐场**

*Zhihao Wang,Alessandro Cornacchia,Franco Galante,Carlo Centofanti,Alessio Sacco,Dingde Jiang*

主要分类: cs.NI

摘要简述: 本文提出建立一个标准化、可复现且开放的基准测试平台，用于低操作成本地构建和评估网络故障排除的AI代理。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究表明AI（尤其是大语言模型）在网络配置合成和自动化诊断任务中表现优异，但缺乏一个统一的平台来标准化和简化AI代理的构建与评估。

研究方法: 本文聚焦于网络故障排除领域，提出构建一个开放且可复现的基准测试平台，以支持AI代理的低成本开发和评估。

研究结果: 初步工作表明，标准化平台能够显著降低AI代理的开发和评估成本，并提升实验的可复现性。

研究结论: 建立一个开放的基准测试平台是推动AI代理在网络故障排除领域应用的关键步骤，未来需进一步扩展和完善。

中文摘要: 近期研究表明，人工智能（AI），尤其是大语言模型（LLM），在网络配置合成和自动化网络诊断任务等方面表现优异。在这项初步工作中，我们专注于AI代理在网络故障排除中的应用，并详细阐述了对一个标准化、可复现且开放的基准测试平台的需求，以便以低操作成本构建和评估AI代理。

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [178] [Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency](https://arxiv.org/abs/2507.02135)
**中文标题：剖析移动DVFS调控器对LLM推理性能和能效的影响**

*Zongpu Zhang,Pranab Dash,Y. Charlie Hu,Qiang Xu,Jian Li,Haibing Guan*

主要分类: cs.OS

摘要简述: 本文研究了移动设备上动态电压频率调节（DVFS）调控器对大型语言模型（LLM）推理性能和能效的影响，发现独立运行的调控器导致能效低下，并提出了一种统一的能效感知调控器FUSE，显著优化了LLM推理的延迟和能效。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在移动设备上的广泛应用，其高计算和内存需求导致能效问题突出。当前移动设备中的CPU、GPU和内存调控器独立运行，缺乏协同优化，导致LLM推理效率低下。

研究方法: 首先测量了现有LLM框架在移动设备上的能效表现，发现独立调控器导致延迟增加；其次深入分析了调控器间缺乏协同的原因；最后设计了统一的能效感知调控器FUSE，优化LLM推理的能效。

研究结果: 实验表明，独立调控器导致预填充和解码延迟增加40.4%，而FUSE能将首词生成延迟降低7.0%-16.9%，每词生成延迟降低25.4%-36.8%，同时保持相同的每词能耗。

研究结论: FUSE通过统一调控CPU、GPU和内存频率，显著提升了移动设备上LLM推理的能效和性能，为未来移动LLM部署提供了优化方向。

中文摘要: 大型语言模型（LLM）正逐渐集成到运行在数十亿移动设备上的各种应用和服务中。然而，在资源有限的移动设备上部署LLM面临重大挑战，因其对计算、内存和能源的高需求。当前移动设备上的LLM框架使用了三个高能耗组件——CPU、GPU和内存，即使运行主要依赖GPU的LLM模型时，现代移动设备中优化的CPU、GPU和内存动态电压频率调节（DVFS）调控器仍独立运行且彼此不感知。基于这一观察，本研究首先测量了包含多种LLM模型的先进LLM框架在移动设备上的能效表现，发现独立调控器导致预填充和解码延迟比最优频率组合高出40.4%，而能耗相同。其次，通过深入测量研究揭示了调控器间缺乏协同导致LLM推理效率低下的原因。最后，基于这些洞察，设计了FUSE——一种统一的能效感知调控器，用于优化移动设备上LLM推理的能效。使用ShareGPT数据集的评估表明，FUSE将首词生成延迟和每词生成延迟分别平均降低了7.0%-16.9%和25.4%-36.8%，同时保持相同的每词能耗。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [179] [Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener](https://arxiv.org/abs/2507.02005)
**中文标题：通过特征工程和自动化可解释机器学习发现焊接横向加劲肋的疲劳强度模型**

*Michael A. Kraus,Helen Bartsch*

主要分类: cs.CE

摘要简述: 本研究结合自动化机器学习（AutoML）与可解释人工智能（XAI），通过特征工程和算法特征创建，预测焊接横向加劲肋的疲劳强度。结果表明，集成方法（如CatBoost、LightGBM）表现最佳，XAI揭示了应力比、应力范围等关键预测因素。


<details>
  <summary>详细信息</summary>
研究动机: 焊接钢结构的疲劳强度预测对工程设计和评估至关重要。传统方法依赖专家经验，而数据驱动模型缺乏可解释性。本研究旨在结合AutoML与XAI，提升预测准确性和模型可解释性。

研究方法: 基于疲劳测试数据库，使用AutoML训练梯度提升、随机森林和神经网络模型，采用三种特征方案（领域知识驱动、算法生成、混合）。通过XAI方法（SHAP和特征重要性）分析关键预测因素。

研究结果: 集成方法表现最佳，领域知识模型M2在测试中RMSE≈30.6 MPa，R²≈0.780%。XAI识别出应力比R、应力范围Δσi等为主要预测因素，几何因素（板宽、喉厚等）也显著影响疲劳寿命。

研究结论: 结合AutoML与XAI的框架能够生成准确、可解释且稳健的疲劳强度模型，为焊接钢结构的设计和评估提供支持。未来将探索概率疲劳寿命建模及数字孪生环境集成。

中文摘要: 本研究提出了一种结合自动化机器学习（AutoML）与可解释人工智能（XAI）的统一方法，用于预测焊接横向加劲肋细节的疲劳强度。通过专家驱动的特征工程与算法特征创建相结合，提升了模型的准确性和可解释性。基于广泛的疲劳测试数据库，使用AutoML训练了梯度提升、随机森林和神经网络模型，并采用三种特征方案（领域知识驱动、算法生成、混合）进行系统比较。集成方法（如CatBoost、LightGBM）表现最佳，领域知识模型M2在测试中RMSE≈30.6 MPa，R²≈0.780%，在工程相关范围内（0-150 MPa）RMSE≈13.4 MPa，R²≈0.527%。XAI方法（SHAP和特征重要性）识别出应力比R、应力范围Δσi、屈服强度ReH及焊后处理（TIG修整与未处理）为主要预测因素，几何因素（板宽、喉厚、加劲肋高度）也显著影响疲劳寿命。该框架表明，结合AutoML与XAI能够生成准确、可解释且稳健的疲劳强度模型，为焊接钢结构的设计和评估提供支持。未来工作将探索概率疲劳寿命建模及数字孪生环境集成。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [180] [DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment](https://arxiv.org/abs/2507.02768)
**中文标题：DeSTA2.5-Audio：迈向通用大型音频语言模型的自生成跨模态对齐**

*Ke-Han Lu,Zhehuai Chen,Szu-Wei Fu,Chao-Han Huck Yang,Sung-Feng Huang,Chih-Kai Yang,Chee-En Yu,Chun-Wei Chen,Wei-Chih Chen,Chien-yu Huang,Yi-Cheng Lin,Yu-Xiang Lin,Chi-An Fu,Chun-Yi Kuan,Wenze Ren,Xuanjun Chen,Wei-Ping Huang,En-Pei Hu,Tzu-Quan Lin,Yuan-Kuei Wu,Kuan-Po Huang,Hsiao-Ying Huang,Huang-Cheng Chou,Kai-Wei Chang,Cheng-Han Chiang,Boris Ginsburg,Yu-Chiang Frank Wang,Hung-yi Lee*

主要分类: eess.AS

摘要简述: DeSTA2.5-Audio是一种通用大型音频语言模型（LALM），通过自生成跨模态对齐策略，避免任务特定调优，同时保持语言模型的原生能力。该模型在多个音频语言基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型音频语言模型（LALM）通常通过手动或LLM合成的音频指令数据集增强语言模型的听觉能力，但会导致语言能力的灾难性遗忘。本文旨在解决这一问题，提出一种无需任务特定调优的通用LALM。

研究方法: 提出DeSTA策略，通过自生成跨模态对齐，让骨干语言模型生成自身的训练目标，从而保持其语言能力并实现音频-文本对齐。构建了DeSTA-AQA5M数据集，包含500万训练样本，覆盖多种音频类型。

研究结果: DeSTA2.5-Audio在Dynamic-SUPERB、MMAU、SAKURA、Speech-IFEval和VoiceBench等多个基准测试中达到或超越现有最佳性能，证明了自生成策略的优越性。

研究结论: 研究表明，精心设计的数据构建策略对开发通用LALM至关重要，DeSTA2.5-Audio为构建鲁棒的通用音频语言模型提供了实用见解。

中文摘要: 我们介绍了DeSTA2.5-Audio，一种通用大型音频语言模型（LALM），旨在实现鲁棒的听觉感知和指令跟随，而无需任务特定的音频指令调优。现有的LALM通常通过在大规模手动或LLM合成的音频指令数据集上训练来增强大型语言模型（LLM）的听觉能力，但这些方法往往导致LLM原有语言能力的灾难性遗忘。为解决这一问题，我们重新审视了数据构建流程，并提出DeSTA，一种自生成跨模态对齐策略，其中骨干LLM生成自身的训练目标。这种方法保留了LLM的原生语言能力，同时建立了有效的音频-文本对齐，从而实现零样本泛化而无需任务特定调优。利用DeSTA，我们构建了DeSTA-AQA5M，一个包含500万训练样本的大规模任务无关数据集，这些样本来自7000小时的音频，涵盖50种多样化数据集，包括语音、环境声音和音乐。DeSTA2.5-Audio在Dynamic-SUPERB、MMAU、SAKURA、Speech-IFEval和VoiceBench等一系列音频语言基准测试中达到了最先进或具有竞争力的性能。全面的对比研究表明，我们的自生成策略在听觉感知和指令跟随能力上优于广泛采用的数据构建和训练策略。我们的发现强调了精心设计的数据构建在LALM开发中的重要性，并为构建鲁棒的通用LALM提供了实用见解。

</details>


### [181] [Multi-agent Auditory Scene Analysis](https://arxiv.org/abs/2507.02755)
**中文标题：多代理听觉场景分析**

*Caleb Rascon,Luis Gato-Diaz,Eduardo García-Alarcón*

主要分类: eess.AS

摘要简述: 本文提出了一种多代理听觉场景分析（MASA）系统，通过并行任务执行和反馈循环来减少错误，同时保持低响应时间和计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 传统的听觉场景分析（ASA）采用线性数据流，导致响应时间长且后续任务对初始任务的错误敏感。现有方法虽努力减少错误，但计算复杂且不适用于需要低延迟和小计算量的场景（如生物声学、助听器设计等）。因此，本文提出多代理方法以解决这些问题。

研究方法: 提出多代理听觉场景分析（MASA）系统，任务并行执行并通过反馈循环纠正局部错误（如利用分离质量修正定位误差，或通过分类结果降低定位对干扰的敏感性）。系统采用开源工具（JACK和ROS2）实现声音采集、重现和代理间通信。

研究结果: MASA系统在保持低复杂度和低响应时间的同时，显著提高了对局部错误的鲁棒性。系统框架支持用户自定义代理。

研究结论: 多代理并行执行和反馈机制有效解决了传统ASA系统的延迟和错误敏感性问题，适用于多种低计算需求的应用场景。

中文摘要: 听觉场景分析（ASA）旨在通过执行三个主要任务（声源定位、分离和分类）从声学环境中提取信息。传统方法采用线性数据流，导致响应时间增加且后续任务对初始任务的错误高度敏感。现有技术虽努力减少错误，但计算复杂，难以适用于需要低计算量和快速响应的场景（如生物声学、助听器设计、搜救和人机交互等）。为此，本文提出一种多代理方法，任务并行执行并通过反馈循环纠正局部错误（如利用分离质量修正定位误差，或通过分类结果降低定位对干扰的敏感性）。最终的多代理听觉场景分析（MASA）系统在保持低复杂度和低响应时间的同时，显著提高了鲁棒性。系统框架基于开源工具（JACK和ROS2），支持用户自定义代理。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [182] [CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR](https://arxiv.org/abs/2507.02289)
**中文标题：CineMyoPS：基于电影心脏磁共振的心肌病理分割**

*Wangbin Ding,Lei Li,Junyi Qiu,Bogen Lin,Mingjing Yang,Liqin Huang,Lianming Wu,Sihan Wang,Xiahai Zhuang*

主要分类: eess.IV

摘要简述: 本文提出了一种名为CineMyoPS的端到端深度神经网络，仅通过电影心脏磁共振（Cine CMR）图像分割心肌病理（如瘢痕和水肿），结合运动和解剖特征，并通过一致性损失和时间序列聚合策略提升分割准确性。


<details>
  <summary>详细信息</summary>
研究动机: 心肌梗死（MI）是全球主要死因之一，传统方法需结合多种磁共振序列（如LGE和T2加权CMR）识别瘢痕和水肿，但耗时且需对比剂。电影CMR（Cine CMR）无需对比剂且能快速捕捉心肌运动与结构异常，因此研究提出仅基于Cine CMR的分割方法。

研究方法: CineMyoPS通过端到端深度神经网络提取与MI相关的运动和解剖特征，设计一致性损失（类似协同训练策略）促进特征联合学习，并提出时间序列聚合策略整合心脏周期内的MI相关特征以提升分割精度。

研究结果: 在多中心数据集上的实验表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面表现优异。

研究结论: CineMyoPS为仅基于Cine CMR的心肌病理分割提供了高效解决方案，避免了传统方法对对比剂和多序列的依赖，具有临床应用潜力。

中文摘要: 心肌梗死（MI）是全球主要死因之一。晚期钆增强（LGE）和T2加权心脏磁共振（CMR）成像可分别识别瘢痕和水肿区域，两者对MI风险分层和预后评估至关重要。尽管结合多序列CMR的互补信息有用，但获取这些序列可能耗时且受限（如需对比剂）。电影CMR（Cine CMR）是一种快速且无需对比剂的成像技术，可可视化急性MI引起的心肌运动和结构异常。因此，我们提出了一种名为CineMyoPS的端到端深度神经网络，仅通过Cine CMR图像分割心肌病理（如瘢痕和水肿）。具体而言，CineMyoPS提取与MI相关的运动和解剖特征。鉴于这些特征的相互依赖性，我们设计了一种一致性损失（类似协同训练策略）以促进联合学习。此外，我们提出了一种时间序列聚合策略，整合心脏周期内的MI相关特征，从而提升心肌病理的分割准确性。在多中心数据集上的实验表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面表现优异。

</details>


### [183] [A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\left[^{18}\text{F}\right]$FDG PET imaging](https://arxiv.org/abs/2507.02367)
**中文标题：一种稳健且通用的深度学习模型用于动态小动物[$^{18}$F]FDG PET成像中动脉输入函数的预测**

*Christian Salomonsen,Luigi Tommaso Luppino,Fredrik Aspheim,Kristoffer Wickstrøm,Elisabeth Wetzer,Michael Kampffmeyer,Rodrigo Berzaghi,Rune Sundset,Robert Jenssen,Samuel Kuttner*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的非侵入性方法（FC-DLIF），用于从小动物动态PET成像中预测动脉输入函数，避免了传统动脉采血的复杂性和局限性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的小动物动态PET研究中，动脉输入函数的精确估计依赖于动脉采血，但这种方法复杂、耗时且无法用于纵向研究。因此，需要一种非侵入性的替代方案。

研究方法: FC-DLIF模型通过空间特征提取器从PET序列的体素时间帧中提取空间特征，再通过时间特征提取器预测动脉输入函数。模型使用[$^{18}$F]FDG数据进行训练和评估，并测试了其在其他放射性示踪剂（[$^{18}$F]FDOPA和[$^{68}$Ga]PSMA）以及时间截断和偏移数据上的适用性。

研究结果: FC-DLIF模型能够可靠地预测动脉输入函数，表现出较低的均方误差和较高的相关性。模型对时间截断和偏移的数据也有效，但对未在训练数据中出现的放射性示踪剂预测失败。

研究结论: FC-DLIF模型为非侵入性动脉输入函数预测提供了可靠且灵活的解决方案，适用于不同扫描时长和时间偏移的情况，但需进一步扩展训练数据以覆盖更多示踪剂。

中文摘要: 动态正电子发射断层扫描（PET）和动力学模型在小动物示踪剂开发研究中至关重要。精确的动力学建模需要准确的输入函数估计，传统上通过动脉采血实现。然而，小鼠等小动物的动脉插管操作复杂、耗时且具有终止性，无法用于纵向研究。本研究提出了一种非侵入性的全卷积深度学习方法（FC-DLIF），直接从PET成像中预测输入函数，可能消除动态小动物PET中对采血的需求。FC-DLIF模型包括一个作用于PET序列体素时间帧的空间特征提取器，提取空间特征，随后通过时间特征提取器预测动脉输入函数。模型使用[$^{18}$F]FDG数据和动脉血曲线进行训练和交叉验证评估。此外，模型在两种其他放射性示踪剂（[$^{18}$F]FDOPA和[$^{68}$Ga]PSMA）的数据上进行了适用性测试，并对时间截断和偏移的数据进行了模拟测试。FC-DLIF模型能够可靠地预测动脉输入函数，表现出较低的均方误差和较高的相关性，且对时间截断和偏移的数据也有效。然而，模型未能预测训练数据中未包含的其他示踪剂的输入函数。这种基于深度学习的输入函数预测方法为非侵入性动脉采血提供了可靠替代，具有对时间偏移和不同扫描时长的鲁棒性和灵活性。

</details>


### [184] [3D Heart Reconstruction from Sparse Pose-agnostic 2D Echocardiographic Slices](https://arxiv.org/abs/2507.02411)
**中文标题：从稀疏姿态无关的2D超声心动图切片重建3D心脏**

*Zhurong Chen,Jinhua Chen,Wei Zhuo,Wufeng Xue,Dong Ni*

主要分类: eess.IV

摘要简述: 本文提出了一种创新的方法，从临床常用的2D超声心动图切片中重建个性化的3D心脏模型，显著提高了左心室和右心室体积的估计精度。


<details>
  <summary>详细信息</summary>
研究动机: 超声心动图在心脏病临床实践中不可或缺，但传统的2D图像难以准确估计心脏参数（如左心室体积），而3D超声成像又受限于低分辨率和繁琐的手动标注。因此，需要一种高效的方法从稀疏的2D切片中重建3D心脏模型。

研究方法: 设计了一种新颖的3D重建流程，通过交替优化2D切片的3D姿态估计和基于隐式神经网络的3D切片整合，逐步将先验的3D心脏形状转化为个性化模型。

研究结果: 在两个数据集上验证，使用六个平面时，重建的3D心脏显著优于双平面方法（左心室体积误差：1.98% vs. 20.24%），并首次实现了从2D切片估计右心室体积（误差为5.75%）。

研究结论: 本研究为心脏超声的个性化3D结构和功能分析提供了新方法，具有重要的临床潜力。

中文摘要: 超声心动图在心脏病临床实践中扮演着不可或缺的角色。然而，超声成像通常仅提供来自少数特定视角的二维（2D）横截面图像，这使得其难以解释且对临床参数（如左心室体积）的估计不准确。3D超声成像为3D量化提供了替代方案，但仍受限于低空间和时间分辨率以及高度依赖的手动标注。

为解决这些问题，我们提出了一种创新框架，从临床常用的2D超声切片中重建个性化的3D心脏解剖结构。具体而言，设计了一种新颖的3D重建流程，通过交替优化这些2D切片的3D姿态估计和基于隐式神经网络的3D切片整合，逐步将先验的3D心脏形状转化为个性化模型。

我们在两个数据集上验证了该方法。当使用六个平面时，重建的3D心脏在左心室体积估计上显著优于双平面方法（误差百分比：1.98% vs. 20.24%）。此外，整个重建框架甚至实现了从2D超声切片估计右心室体积的重要突破（误差为5.75%）。本研究为心脏超声的个性化3D结构和功能分析提供了新途径，具有重要的临床潜力。

</details>


### [185] [MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection](https://arxiv.org/abs/2507.02668)
**中文标题：MEGANet-W：一种基于小波的边缘引导注意力框架用于弱边界息肉检测**

*Zhe Yee Tan*

主要分类: eess.IV

摘要简述: MEGANet-W是一种基于小波的边缘引导注意力框架，用于弱边界息肉检测，通过注入方向性Haar小波边缘图提升分割精度，无需额外可学习参数。


<details>
  <summary>详细信息</summary>
研究动机: 结直肠息肉分割对早期癌症检测至关重要，但弱边界和低对比度限制了自动化方法的准确性。现有深度模型要么模糊边缘细节，要么依赖手工滤波器，在多变成像条件下表现不佳。

研究方法: MEGANet-W采用两层级Haar小波头提取多方向边缘，并设计小波边缘引导注意力模块（WEGA），将小波线索与反向和输入分支融合。

研究结果: 在五个公共息肉数据集上，MEGANet-W显著优于现有方法，mIoU提升2.3%，mDice提升1.2%，且未引入额外可学习参数。

研究结论: MEGANet-W通过小波驱动的边缘引导注意力机制，显著提升了弱边界息肉的分割性能，为自动化检测提供了高效解决方案。

中文摘要: 结直肠息肉分割对早期癌症检测至关重要，但弱边界和低对比度显著限制了自动化方法的准确性。现有深度模型要么模糊边缘细节，要么依赖手工滤波器，在多变成像条件下表现不佳。我们提出MEGANet-W，一种基于小波的边缘引导注意力网络，通过在每个解码阶段注入方向性、无参数的Haar小波边缘图来重新校准语义特征。我们的两大贡献是：（1）用于多方向边缘提取的两层级Haar小波头；（2）小波边缘引导注意力模块（WEGA），将小波线索与反向和输入分支融合。在五个公共息肉数据集上，MEGANet-W始终优于现有方法，mIoU提升高达2.3%，mDice提升1.2%，且未引入额外可学习参数。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [186] [FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference](https://arxiv.org/abs/2507.02620)
**中文标题：FlowSpec：基于连续流水线推测解码的高效分布式LLM推理框架**

*Xing Liu,Lizhuo Luo,Ming Tang,Chao Huang*

主要分类: cs.DC

摘要简述: FlowSpec是一种基于流水线并行和树状推测解码的框架，旨在提高分布式大型语言模型（LLM）推理的效率，尤其在网络边缘请求稀疏时显著提升流水线利用率和推测效率。


<details>
  <summary>详细信息</summary>
研究动机: 分布式推理是实现在网络边缘运行大型语言模型（LLM）的有效方法，但现有流水线方法在请求稀疏时利用率低，导致性能下降。FlowSpec旨在解决这一问题，提升边缘设备的推理效率。

研究方法: FlowSpec通过三种关键技术提升效率：1) 基于分数的逐步验证，优先处理重要草案令牌以提前接受有效令牌；2) 高效的草案管理，修剪无效令牌并保持验证中的因果关系；3) 动态草案扩展策略，提供高质量的推测输入。

研究结果: 实验结果表明，FlowSpec在真实测试环境中显著提升了推理速度，相比基线方法实现了1.36倍至1.77倍的加速比。

研究结论: FlowSpec通过优化流水线利用率和推测效率，为分布式LLM推理提供了一种高效解决方案，尤其适用于网络边缘场景。

中文摘要: 分布式推理是实现大型语言模型（LLM）在网络边缘运行的一种有前景的方法，它将推理过程分配到多个设备上，以确保LLM能够适应设备内存。最近的基于流水线的方法具有并行化通信和计算的潜力，有助于降低推理延迟。然而，当网络边缘的推理请求稀疏时，流水线的利用率通常较低，其优势会减弱。为了实现高效的分布式LLM边缘推理，我们提出了FlowSpec，一种基于流水线并行和树状推测解码的框架。FlowSpec通过三种关键机制提升解码效率：1) 基于分数的逐步验证，优先处理更重要的草案令牌以提前接受有效令牌；2) 高效的草案管理，修剪无效令牌并在验证过程中保持正确的因果关系；3) 动态草案扩展策略，提供高质量的推测输入。这些技术共同作用，提升了流水线利用率和推测效率。我们在真实测试环境中与其他基线方法进行了对比评估。实验结果表明，FlowSpec在不同模型和配置下显著提升了推理速度，实现了1.36倍至1.77倍的加速比。我们的代码已在https://github.com/Leosang-lx/FlowSpec#公开。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [187] [Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features](https://arxiv.org/abs/2507.01984)
**中文标题：基于语言、视觉和社交特征早期融合的多模态虚假信息检测**

*Gautam Kishore Shahi*

主要分类: cs.LG

摘要简述: 本研究探讨了多模态特征（文本、图像和社交特征）在早期融合方法下对虚假信息检测的有效性，结果显示多模态模型比单模态和双模态模型性能提升显著。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体在选举和危机期间充斥着大量虚假信息，现有研究多集中于单模态（文本或图像），而多模态特征组合的研究较少。本研究旨在填补这一空白。

研究方法: 研究分析了1,529条包含文本和图像的推文，通过数据增强提取社交和视觉特征（如目标检测和OCR），并采用早期融合方法构建分类模型。

研究结果: 结合无监督和监督机器学习模型的多模态方法，分类性能比单模态模型提升15%，比双模态模型提升5%。同时分析了虚假信息的传播模式。

研究结论: 多模态特征组合显著提升了虚假信息检测的性能，为未来研究提供了新的方向。

中文摘要: 在选举和危机期间，社交媒体上充斥着大量虚假信息，现有研究主要集中于基于文本或图像的单模态检测方法，而关于多模态特征组合的研究较少。本研究探讨了文本、图像和社交特征在早期融合方法下对虚假信息检测的有效性。研究分析了1,529条来自Twitter（现为X）的推文，这些推文包含文本和图像，并应用于COVID-19大流行和选举期间。通过数据增强技术（如目标检测和光学字符识别）提取了额外的社交和视觉特征。结果表明，结合无监督和监督机器学习模型的多模态方法，分类性能比单模态模型提升15%，比双模态模型提升5%。此外，研究还基于虚假信息推文及其传播用户的特征，分析了虚假信息的传播模式。

</details>


### [188] [Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions](https://arxiv.org/abs/2507.02087)
**中文标题：评估大型语言模型在招聘决策中的潜力与风险**

*Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia*

主要分类: cs.LG

摘要简述: 本研究评估了大型语言模型（LLMs）在招聘决策中的表现，发现通用LLMs在准确性和公平性上不如专有领域模型Match Score，后者在减少算法偏见方面表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在招聘筛选中有潜力提升效率，但其可能存在的准确性和算法偏见问题引发了担忧。本研究旨在比较通用LLMs与专有领域模型在招聘匹配中的表现，并探讨如何平衡准确性与公平性。

研究方法: 研究对多个前沿LLMs（如OpenAI、Anthropic、Google等）与专有模型Match Score进行了对比评估，使用真实招聘数据集（约10,000对候选人与职位），通过ROC AUC、Precision-Recall AUC、F1分数等指标衡量准确性，并通过影响比率分析公平性。

研究结果: Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（最低种族影响比率0.957 vs 0.809）上均优于通用LLMs。研究还发现，未经充分保护的LLMs可能传播社会偏见，而专有模型能更有效减少偏见。

研究结论: 研究强调在高风险领域（如招聘）中，需采用领域专用模型并进行偏见审核，避免直接使用通用LLMs。同时证明，通过合理设计，算法可同时实现高准确性和公平性。

中文摘要: 大型语言模型（LLMs）在招聘中的应用有望简化候选人筛选流程，但也引发了关于准确性和算法偏见的严重担忧，尤其是在缺乏充分保护措施的情况下。本研究对多个前沿基础LLMs（包括OpenAI、Anthropic、Google、Meta和Deepseek的模型）与专有领域招聘模型（Match Score）在候选人匹配中的表现进行了对比。我们评估了各模型的预测准确性（ROC AUC、Precision-Recall AUC、F1分数）和公平性（基于性别、种族及交叉子群的影响比率）。通过对约10,000对真实候选人与职位数据的实验，发现Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（最低种族影响比率0.957 vs 0.809）上均优于通用LLMs。研究还指出，未经充分保护的LLMs可能传播社会偏见，而专有监督模型能更有效减少这些偏见。研究结果强调了在高风险领域（如招聘）中采用领域专用模型和偏见审核的重要性，并警示在缺乏充分公平保护措施的情况下直接使用通用LLMs的风险。此外，通过实证证据表明，招聘中准确性与公平性并非对立，合理设计的算法可同时实现两者。

</details>


### [189] [Energy-Based Transformers are Scalable Learners and Thinkers](https://arxiv.org/abs/2507.02092)
**中文标题：基于能量的Transformer是可扩展的学习者和思考者**

*Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal*

主要分类: cs.LG

摘要简述: 本文提出了一种基于能量的Transformer（EBT），通过无监督学习实现模型的自验证和优化，显著提升了训练和推理性能，并在多种任务中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有推理时计算技术（类似人类系统2思维）存在局限性，如仅适用于特定模态或问题，或需要额外监督。本文旨在探索是否可以通过无监督学习实现通用的系统2思维模型。

研究方法: 提出能量基于Transformer（EBT），通过为输入和候选预测对分配能量值，利用梯度下降进行能量最小化优化，实现预测。

研究结果: EBT在训练中比Transformer++方法扩展更快，数据、批量大小、参数、FLOPs和深度方面提升35%；在推理中，语言任务性能提升29%，图像去噪任务表现优于扩散Transformer且前向传递次数更少。

研究结论: EBT是一种有前景的新范式，能够同时扩展模型的学习和思维能力，且在相同或更差的预训练性能下，下游任务表现优于现有方法。

中文摘要: 推理时计算技术（类似人类系统2思维）近年来因提升模型性能而流行，但现有方法存在局限性：仅适用于特定模态（如文本）、特定问题（如数学和编程等可验证领域），或需要额外监督/训练（如验证器或可验证奖励）。本文探讨是否可以通过无监督学习实现通用的系统2思维模型。研究发现，通过学习显式验证输入与候选预测的兼容性，并将预测问题重新定义为基于验证器的优化，可以实现这一目标。具体而言，我们训练了基于能量的Transformer（EBT）——一种新的能量基于模型（EBM），为每个输入和候选预测对分配能量值，通过梯度下降能量最小化实现预测。在离散（文本）和连续（视觉）模态中，EBT在训练中比Transformer++方法扩展更快，数据、批量大小、参数、FLOPs和深度方面提升35%。推理时，EBT在语言任务中比Transformer++提升29%，在图像去噪任务中表现优于扩散Transformer且前向传递次数更少。此外，EBT在相同或更差的预训练性能下，下游任务表现优于现有模型，表明其泛化能力更强。因此，EBT是一种有前景的新范式，能够同时扩展模型的学习和思维能力。

</details>


### [190] [Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows](https://arxiv.org/abs/2507.01975)
**中文标题：可学习可微分有限体积求解器用于加速流动模拟**

*Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun*

主要分类: cs.LG

摘要简述: 本文提出了一种可学习和可微分的有限体积求解器LDSolver，用于在粗网格上高效准确地模拟流体流动，解决了传统数值求解器计算成本高和机器学习方法泛化性差的问题。


<details>
  <summary>详细信息</summary>
研究动机: 流体流动模拟在气象学、空气动力学和生物医学等领域至关重要，但传统数值求解器需要精细的时空网格，计算成本高；而机器学习方法虽效率高，但存在可解释性、泛化性和数据依赖性问题。因此，本文旨在提出一种兼具高效性和准确性的解决方案。

研究方法: LDSolver由两部分组成：(1) 可微分有限体积求解器；(2) 可学习模块，用于在粗网格上提供等效通量近似（导数和插值）和时间误差校正。该方法即使在有限训练数据下也能保持高精度和强泛化性。

研究结果: 在不同流动系统（如Burgers、衰减、强迫和剪切流动）上的实验表明，LDSolver性能优于基线模型，显著提升了模拟速度和准确性。

研究结论: LDSolver通过结合可微分求解器和可学习模块，在粗网格上实现了高效且高精度的流体流动模拟，为相关领域提供了新的解决方案。

中文摘要: 流体流动模拟对于气象学、空气动力学和生物医学等物理现象建模至关重要。传统数值求解器通常需要精细的时空网格以满足稳定性、一致性和收敛性条件，导致计算成本高昂。尽管机器学习方法效率更高，但其通常存在可解释性、泛化性和数据依赖性问题。因此，我们提出了一种可学习和可微分的有限体积求解器LDSolver，用于在粗网格上高效准确地模拟流体流动。LDSolver包含两个关键组件：(1) 可微分有限体积求解器；(2) 可学习模块，用于在粗网格上提供等效通量近似（导数和插值）和时间误差校正。即使在有限训练数据（如仅几条轨迹）下，我们的模型也能在保持高精度的同时加速模拟，并具有出色的泛化性。在不同流动系统（如Burgers、衰减、强迫和剪切流动）上的实验表明，LDSolver达到了最先进的性能，显著优于基线模型。

</details>


### [191] [DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism](https://arxiv.org/abs/2507.01982)
**中文标题：DKGCM：一种融合空间节点聚类方法与傅里叶双向Mamba机制的交通流量时空预测模型**

*Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai*

主要分类: cs.LG

摘要简述: 提出了一种名为DKGCM的新型图卷积网络结构，通过融合空间节点聚类方法和傅里叶双向Mamba机制，显著提升了交通流量的时空预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 交通需求预测的准确性对资源分配效率至关重要，但复杂的时空关系限制了现有模型的性能。为此，研究旨在通过改进空间依赖性和时间依赖性的捕捉方法，提升预测精度。

研究方法: 首先提出基于时间相似性的聚类图卷积方法（DK-GCN），利用动态时间规整（DTW）和K-means聚类对交通节点分组；其次，在时间尺度上，将快速傅里叶变换（FFT）与双向Mamba框架结合；最后，引入GRPO强化学习策略优化模型训练。

研究结果: 实验表明，DKGCM在三个公开数据集上表现优于多种先进方法，验证了其有效性。

研究结论: DKGCM通过创新的空间聚类和时间依赖性捕捉方法，显著提升了交通流量预测的准确性，为交通管理提供了有力工具。

中文摘要: 准确的交通需求预测有助于交通管理部门更高效地分配资源，从而提高其利用效率。然而，交通系统中复杂的时空关系仍限制了需求预测模型的性能。为提升时空交通需求预测的准确性，我们提出了一种新型图卷积网络结构DKGCM。具体而言，我们首先考虑不同交通节点的空间流分布，提出了一种基于时间相似性的聚类图卷积方法DK-GCN。该方法利用动态时间规整（DTW）和K-means聚类对交通节点分组，更有效地捕捉空间依赖性。在时间尺度上，我们将快速傅里叶变换（FFT）与双向Mamba深度学习框架结合，以捕捉交通需求的时间依赖性。为进一步优化模型训练，我们引入了GRPO强化学习策略以增强损失函数反馈机制。大量实验表明，我们的模型在三个公开数据集上优于多种先进方法，并取得了显著成果。

</details>


### [192] [OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding](https://arxiv.org/abs/2507.02659)
**中文标题：OmniDraft：一种跨词汇表、在线自适应的设备端推测解码草稿模型**

*Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang*

主要分类: cs.LG

摘要简述: OmniDraft是一种跨词汇表、在线自适应的草稿模型框架，支持与任何目标模型配对，并通过动态适应和混合蒸馏微调解决词汇不匹配问题，显著提升解码速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有草稿模型通常针对特定目标模型（如Llama或Qwen）离线训练或蒸馏，但在线部署时面临两个主要挑战：1）目标模型与草稿模型不兼容；2）需要随时间提升延迟性能。OmniDraft旨在解决这些问题，实现“一草稿模型适配所有目标模型”。

研究方法: OmniDraft提出了一种统一框架，结合在线n-gram缓存和混合蒸馏微调技术，解决草稿模型与目标模型间的词汇不匹配问题，并通过自适应草稿技术提升解码速度。

研究结果: 实验表明，OmniDraft使单个Llama-68M模型能与Vicuna-7B、Qwen2-7B和Llama3-8B等多种目标模型配对，并在数学推理、代码生成和文本生成任务中实现1.5-2倍的加速。

研究结论: OmniDraft为设备端LLM应用提供了一种高效、灵活的解决方案，支持跨模型适配和动态优化，验证了“一草稿模型适配所有目标模型”的可行性。

中文摘要: 推测解码通常需要一个小的、高效的草稿模型，该模型通常是针对特定目标模型系列（如Llama或Qwen）离线预训练或蒸馏的。然而，在线部署时面临两大挑战：1）目标模型与草稿模型不兼容；2）需要随时间提升延迟性能。本文提出OmniDraft，一个统一框架，使单个草稿模型能与任何目标模型配对，并动态适应用户数据。通过引入在线n-gram缓存和混合蒸馏微调，解决了草稿模型与目标模型间的词汇不匹配问题，并利用自适应草稿技术进一步提升解码速度。OmniDraft特别适合设备端LLM应用，其中模型成本、效率和用户定制是关键问题。这进一步凸显了解决上述挑战的必要性，并推动了“一草稿模型适配所有目标模型”的范式。我们通过在数学推理、代码生成和文本生成任务中进行在线学习，展示了OmniDraft的优越性。值得注意的是，OmniDraft使单个Llama-68M模型能与Vicuna-7B、Qwen2-7B和Llama3-8B等多种目标模型配对进行推测解码，并提供了1.5-2倍的加速。

</details>


### [193] [ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning](https://arxiv.org/abs/2507.02834)
**中文标题：ExPO：通过自我解释引导的强化学习解锁困难推理**

*Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi*

主要分类: cs.LG

摘要简述: 论文提出了一种名为ExPO（自我解释策略优化）的新方法，通过结合真实答案生成高质量样本，解决了强化学习在早期训练和复杂推理任务中难以生成有效样本的问题，显著提升了模型的学习效率和最终性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于强化学习的后训练方法依赖于模型初始生成的正样本，难以解决模型初始失败的问题，尤其是在早期训练和复杂推理任务中。论文旨在通过生成更有效的正样本，提升模型在困难任务中的推理能力。

研究方法: 论文提出了ExPO框架，通过结合真实答案生成符合当前策略且能提高模型正确预测概率的样本，取代依赖专家演示的方法，从而更高效地引导模型探索新的推理路径。

研究结果: 实验表明，ExPO在推理基准测试中显著提升了学习效率和最终性能，尤其是在模型初始表现较差的MATH level-5任务中，表现优于基于专家演示的方法。

研究结论: ExPO通过生成高质量样本，有效解决了强化学习在复杂推理任务中的探索问题，为模型后训练提供了一种更高效的解决方案。

中文摘要: 近年来，大型语言模型的进步主要依赖于强化学习（RL）风格的后训练，通过基于奖励或偏好信号优化模型输出来提升推理能力。GRPO风格的方法通过使用基于结果的验证器标记自生成样本来实现这一点。然而，这些方法高度依赖模型初始生成正样本的能力，主要是在优化模型已知的内容（分布锐化），而非解决模型初始失败的问题。这一限制在早期RL训练和复杂推理任务中尤为突出，因为正样本难以生成。为了在这些场景中解锁推理能力，模型需要探索超出当前输出分布的新推理路径。这种探索需要足够好的正样本来指导学习。虽然专家演示看似是自然的解决方案，但我们发现它们在RL后训练中往往效果不佳。相反，我们确定了有效正样本的两个关键特性：（1）在当前策略下具有较高的可能性；（2）能提高模型预测正确答案的概率。基于这些见解，我们提出了自我解释策略优化（ExPO）——一种简单且模块化的框架，通过结合真实答案生成此类样本。ExPO实现了高效探索，并引导模型生成比专家编写的思维链（CoTs）更符合其策略的推理路径，同时确保比其自身（错误）样本更高的质量。实验表明，ExPO在推理基准测试中提升了学习效率和最终性能，在模型初始表现最差的MATH level-5等困难任务中，表现优于基于专家演示的方法。

</details>


### [194] [GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters](https://arxiv.org/abs/2507.02085)
**中文标题：GeoAda：利用等变适配器高效微调几何扩散模型**

*Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon*

主要分类: cs.LG

摘要简述: GeoAda提出了一种SE(3)-等变适配器框架，用于高效微调几何扩散模型，保持几何一致性并避免过拟合和灾难性遗忘，适用于多种几何控制任务。


<details>
  <summary>详细信息</summary>
研究动机: 几何扩散模型在分子动力学和结构生成中表现出色，但如何高效微调以适应不同几何控制的下游任务尚未充分研究。

研究方法: GeoAda通过结构化适配器设计，将控制信号编码后通过可训练的预训练模型层处理，再通过解耦操作和等变零初始化卷积投影回原空间，仅微调轻量级适配器模块。

研究结果: GeoAda在多种几何控制任务中表现优异，保持原始任务精度，而其他基线方法因过拟合和灾难性遗忘导致性能显著下降。

研究结论: GeoAda为几何扩散模型提供了一种高效、灵活的微调方法，同时保持了模型的几何一致性和性能。

中文摘要: 几何扩散模型在分子动力学和结构生成中取得了显著成功。然而，如何高效微调这些模型以适应不同几何控制的下游任务仍是一个未充分探索的问题。本文提出了一种SE(3)-等变适配器框架（GeoAda），能够在无需修改原始模型架构的情况下，实现灵活且参数高效的微调，用于受控生成任务。GeoAda采用结构化适配器设计：控制信号首先通过耦合算子编码，然后由预训练模型层的可训练副本处理，最后通过解耦算子和等变零初始化卷积投影回原空间。通过仅微调这些轻量级适配器模块，GeoAda既保持了模型的几何一致性，又避免了过拟合和灾难性遗忘。我们从理论上证明了所提出的适配器保持了SE(3)-等变性，确保预训练扩散模型的几何归纳偏置在适应过程中保持不变。我们展示了GeoAda在多种几何控制类型（如框架控制、全局控制、子图控制）和广泛应用领域（如粒子动力学、分子动力学、人体运动预测和分子生成）中的广泛适用性。实验结果表明，GeoAda在保持原始任务精度的同时，实现了最先进的微调性能，而其他基线方法因过拟合和灾难性遗忘导致性能显著下降。

</details>


### [195] [Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies](https://arxiv.org/abs/2507.02244)
**中文标题：竞争压力下的订单获取：一种快速适应的强化学习方法用于网约车补贴策略**

*Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于强化学习的快速适应补贴策略框架FCA-RL，用于网约车平台动态优化订单获取，并通过实验验证其优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 网约车平台中，服务商通过降低价格获取更多订单，但现有研究缺乏动态适应市场波动的有效补贴策略。本文旨在填补这一空白。

研究方法: 提出FCA-RL框架，结合快速竞争适应（FCA）和强化拉格朗日调整（RLA）技术，并开发专用模拟环境RideGym进行策略评估。

研究结果: 实验表明，FCA-RL在不同市场条件下均优于基线方法，有效优化了补贴策略。

研究结论: FCA-RL框架为网约车服务商提供了动态适应竞争环境的有效工具，显著提升了订单获取效率。

中文摘要: 网约车聚合平台的普及为服务商提供了通过增加订单量和总交易额（GMV）实现增长的机会。在大多数平台上，提供更低价格的服务商排名更高，从而更容易被乘客选择。这种竞争排名机制促使服务商采用优惠券策略降低价格以获取更多订单，因为订单量直接影响其长期生存能力。因此，设计一种能够在预算约束下动态适应市场波动并优化订单获取的优惠券策略是一个关键研究挑战，但现有研究较少。为填补这一空白，我们提出了FCA-RL，一种基于强化学习的补贴策略框架，能够快速适应竞争对手的价格调整。该方法结合了快速竞争适应（FCA）和强化拉格朗日调整（RLA）技术，确保在新价格环境下优化优惠券决策的同时遵守预算约束。此外，我们开发了首个专为网约车平台设计的模拟环境RideGym，用于在不影响实际运营效率的情况下全面评估和比较不同定价策略。实验结果表明，我们的方法在不同市场条件下均优于基线方法，凸显了其在网约车服务商补贴优化中的有效性。

</details>


### [196] [Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications](https://arxiv.org/abs/2507.02291)
**中文标题：基于知识图谱的可解释与广义零样本语义通信**

*Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu*

主要分类: cs.LG

摘要简述: 提出了一种基于知识图谱的零样本语义通信网络（KGZS-SC），通过知识图谱增强语义表示和推理能力，显著提升对未见数据的分类性能，并减少通信开销。


<details>
  <summary>详细信息</summary>
研究动机: 传统数据驱动的语义通信依赖统计模式，缺乏可解释性和对未见数据的泛化能力。为解决这些问题，研究提出了一种结合知识图谱的语义通信框架。

研究方法: 利用知识图谱语义知识库（KG-SKB）对齐语义特征，增强发射端的泛化能力，选择性传输紧凑视觉语义；接收端采用零样本学习（ZSL）直接分类未见数据，无需重新训练。

研究结果: 在APY数据集上的实验表明，KGZS-SC网络具有强泛化能力，在不同信噪比下对未见类别的分类性能显著优于现有语义通信框架。

研究结论: KGZS-SC网络通过知识图谱和零样本学习的结合，提升了语义通信的可解释性和泛化能力，适用于动态或资源受限环境。

中文摘要: 数据驱动的语义通信基于表面统计模式，缺乏可解释性和泛化能力，尤其是在处理未见数据时。为解决这些问题，我们提出了一种新颖的知识图谱增强零样本语义通信（KGZS-SC）网络。该方案通过知识图谱语义知识库（KG-SKB）的结构化语义信息指导，提供广义语义表示并支持对未见案例的推理。具体而言，KG-SKB将语义特征对齐到共享类别语义嵌入空间，并通过对齐的语义特征增强发射端的泛化能力，从而通过选择性传输紧凑视觉语义减少通信开销。在接收端，利用零样本学习（ZSL）直接对未见案例进行分类，无需重新训练或额外计算开销，从而提升动态或资源受限环境中分类过程的适应性和效率。在APY数据集上的仿真结果表明，所提出的KGZS-SC网络具有强泛化能力，且在一系列信噪比水平下对未见类别的分类性能显著优于现有语义通信框架。

</details>


### [197] [Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment](https://arxiv.org/abs/2507.02310)
**中文标题：概念漂移下的全面持续学习：基于自适应记忆对齐的方法**

*Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk*

主要分类: cs.LG

摘要简述: 本文提出了一种针对概念漂移的全面持续学习框架，通过自适应记忆对齐（AMR）机制，在动态数据流中平衡知识保留与快速适应，显著减少标注和计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 传统持续学习方法假设数据分布静态，忽视现实数据流中的概念漂移。本文旨在解决动态环境下知识保留与快速适应的矛盾，提出更贴近实际的解决方案。

研究方法: 提出自适应记忆对齐（AMR）机制，选择性移除过时样本并补充最新实例，动态调整记忆缓冲区以匹配新分布。同时设计了四种概念漂移变体的视觉基准数据集用于评估。

研究结果: 实验表明，AMR在减少标注和计算开销的同时，性能与完全重新学习（FR）相当，有效应对概念漂移，保持高准确率。

研究结论: AMR是一种可扩展的解决方案，在非静态持续学习环境中平衡稳定性与可塑性，为动态数据流提供了高效的学习框架。

中文摘要: 传统持续学习方法优先考虑知识保留，主要关注缓解灾难性遗忘，隐含假设先前学习任务的数据分布是静态的。这忽视了现实数据流的动态性，概念漂移会永久改变已见数据，要求模型兼具稳定性和快速适应性。
  我们提出了一种针对概念漂移的全面持续学习框架，通过模拟任务分布的演变来构建真实场景。作为基线，我们考虑了完全重新学习（FR），即模型从漂移分布的新标注样本中重新训练。虽然有效，但这种方法需要大量标注和计算资源。为解决这些限制，我们提出了自适应记忆对齐（AMR），一种轻量级替代方案，为基于记忆的持续学习器提供漂移感知的适应机制。AMR选择性移除记忆缓冲区中漂移类别的过时样本，并用少量最新实例重新填充，有效将记忆与新分布对齐。这种针对性重采样在性能上与FR相当，同时将标注和计算需求降低数个数量级。
  为支持可重复评估，我们引入了四种标准视觉基准的概念漂移变体：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD和Tiny-ImageNet-CD，其中已见类别以漂移表征重现。基于这些数据集的多项实验表明，AMR能持续应对概念漂移，以最小开销保持高准确率。这些结果证明AMR是一种可扩展的解决方案，在非静态持续学习环境中平衡了稳定性与可塑性。

</details>


### [198] [DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values](https://arxiv.org/abs/2507.02342)
**中文标题：DeltaSHAP：利用Shapley值解释在线患者监测中的预测演变**

*Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang*

主要分类: cs.LG

摘要简述: DeltaSHAP是一种新型可解释人工智能（XAI）算法，专为在线患者监测系统设计，通过改进Shapley值解释预测变化，满足临床时间序列解释的独特需求，并在实验中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在临床环境中，理解患者风险预测变化的原因对及时干预至关重要，但现有XAI方法无法满足临床时间序列解释的需求。DeltaSHAP旨在解决这一问题，提供实时、动态的解释。

研究方法: DeltaSHAP通过改进Shapley值，适应时间序列设置，捕捉特征组合效应，并仅基于实际观察到的特征组合解释预测变化，从而高效满足临床实时需求。

研究结果: 实验表明，DeltaSHAP在在线患者监测任务中表现优异，解释质量提升62%，计算效率提高33%（时间减少），在MIMIC-III基准测试中优于现有XAI方法。

研究结论: DeltaSHAP为临床时间序列解释提供了一种高效、实用的解决方案，显著提升了预测变化的解释质量和计算效率。

中文摘要: 本研究提出DeltaSHAP，一种专为在线患者监测系统设计的新型可解释人工智能（XAI）算法。在临床环境中，发现驱动患者风险演变的原因对及时干预至关重要，但现有XAI方法无法满足临床时间序列解释的独特需求。为此，DeltaSHAP解决了三个关键临床需求：解释连续预测的变化而非孤立预测分数，提供特征归因的幅度和方向，并实时提供这些见解。通过将Shapley值适应于时间设置，我们的方法准确捕捉了特征组合效应。它进一步仅基于实际观察到的特征组合归因预测变化，使其在时间敏感的临床应用中高效且实用。我们还引入了新的评估指标，以评估在线时间序列归因的忠实性，并通过在线患者监测任务的实验证明，DeltaSHAP在解释质量（提升62%）和计算效率（时间减少33%）上均优于最先进的XAI方法（基于MIMIC-III基准测试）。代码发布于https://github.com/AITRICS/DeltaSHAP。

</details>


### [199] [Offline Reinforcement Learning with Penalized Action Noise Injection](https://arxiv.org/abs/2507.02356)
**中文标题：带惩罚动作噪声注入的离线强化学习**

*JunHyeok Oh,Byung-Jun Lee*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PANI的离线强化学习方法，通过注入带惩罚的动作噪声来覆盖整个动作空间，显著提升了离线强化学习的性能，且无需复杂的扩散模型。


<details>
  <summary>详细信息</summary>
研究动机: 离线强化学习（RL）仅使用固定数据集优化策略，适用于环境交互成本高的场景。尽管扩散模型在离线RL中表现出色，但其计算成本高，因此需要一种更简单高效的方法来提升性能。

研究方法: PANI方法通过注入带惩罚的动作噪声来扩展动作空间，同时根据噪声量进行惩罚。该方法兼容多种现有离线RL算法，并提供了一个理论框架，即“噪声动作MDP”。

研究结果: PANI在多个基准测试中表现出显著的性能提升，证明了其简单性和高效性。

研究结论: PANI为离线RL提供了一种无需复杂扩散模型的高效方法，通过噪声注入和惩罚机制显著提升了性能。

中文摘要: 离线强化学习（RL）仅使用固定数据集优化策略，适用于环境交互成本高的场景。尽管扩散模型在离线RL中表现出色，但其计算成本高，因此需要一种更简单高效的方法来提升性能。本文提出了一种名为PANI的方法，通过注入带惩罚的动作噪声来覆盖整个动作空间。该方法兼容多种现有离线RL算法，并提供了一个理论框架，即“噪声动作MDP”。实验表明，PANI在多个基准测试中表现出显著的性能提升。

</details>


### [200] [S2FGL: Spatial Spectral Federated Graph Learning](https://arxiv.org/abs/2507.02409)
**中文标题：S2FGL：空间谱联邦图学习**

*Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye*

主要分类: cs.LG

摘要简述: 本文提出了一种名为S2FGL的框架，结合空间和谱域策略，解决了联邦图学习中的标签信号中断和谱客户端漂移问题，显著提升了全局模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前的联邦图学习（FGL）研究仅从结构角度处理子图联邦学习，忽略了图信号在空间和谱域的传播问题。空间上，子图联邦学习导致客户端间边连接中断，影响标签信号传播；谱域上，谱异质性导致信号频率不一致，使局部图神经网络过拟合局部信号传播模式。这些问题降低了全局模型的泛化能力。

研究方法: S2FGL框架通过两个核心策略解决问题：1) 全局知识库缓解标签信号中断；2) 频率对齐解决谱客户端漂移。结合空间和谱域策略，显著提升了模型的性能。

研究结果: 在多个数据集上的实验表明，S2FGL框架显著优于现有方法，有效解决了标签信号中断和谱客户端漂移问题，提升了全局模型的泛化能力。

研究结论: S2FGL通过结合空间和谱域策略，成功解决了联邦图学习中的关键问题，为未来的研究提供了新的方向。

中文摘要: 联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNNs）的强大图建模能力。当前研究仅从结构角度处理子图联邦学习，忽略了图信号在空间和谱域的传播。从空间角度看，子图联邦学习导致客户端间边连接中断，影响标签信号传播，降低了全局GNN的类别知识。从谱域角度看，谱异质性导致子图间信号频率不一致，使局部GNN过拟合局部信号传播模式，从而引发谱客户端漂移，削弱全局泛化能力。为解决这些问题，我们提出了一个全局知识库以缓解标签信号中断，并通过频率对齐解决谱客户端漂移。结合空间和谱域策略，形成了我们的框架S2FGL。在多个数据集上的实验证明了S2FGL的优越性。代码可在https://github.com/Wonder7racer/S2FGL.git获取。

</details>


### [201] [Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction](https://arxiv.org/abs/2507.02129)
**中文标题：高效时空数据压缩的生成潜在扩散方法**

*Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka*

主要分类: cs.LG

摘要简述: 本文提出了一种高效的潜在扩散框架，结合变分自编码器和条件扩散模型，仅压缩少量关键帧到潜在空间，并通过生成插值重建其余帧，显著降低存储成本，同时保持高精度时空重建。


<details>
  <summary>详细信息</summary>
研究动机: 生成模型在条件设置下表现优异，可作为数据压缩形式，但其可控性和重建精度限制了实际应用。本文旨在通过潜在扩散框架解决这一问题，实现高效数据压缩。

研究方法: 结合变分自编码器和条件扩散模型，仅压缩少量关键帧到潜在空间，利用生成插值重建其余帧，避免存储每帧的潜在表示。

研究结果: 实验表明，该方法在相同重建误差下，压缩比优于规则压缩方法（如SZ3）10倍，性能比领先的学习方法高63%。

研究结论: 提出的潜在扩散框架在高效数据压缩和精确时空重建方面表现优异，为实际应用提供了可行方案。

中文摘要: 生成模型在条件设置下表现出色，可视为一种数据压缩形式，其中条件作为紧凑表示。然而，其有限的可控性和重建精度限制了其在数据压缩中的实际应用。本研究提出了一种高效的潜在扩散框架，通过将变分自编码器与条件扩散模型相结合，填补了这一空白。我们的方法仅将少量关键帧压缩到潜在空间，并将其作为条件输入，通过生成插值重建其余帧，无需存储每帧的潜在表示。这种方法在显著降低存储成本的同时，实现了精确的时空重建。在多个数据集上的实验结果表明，与基于规则的最先进压缩器（如SZ3）相比，我们的方法在相同重建误差下实现了高达10倍的压缩比，性能比领先的学习方法高出63%。

</details>


### [202] [Continual Gradient Low-Rank Projection Fine-Tuning for LLMs](https://arxiv.org/abs/2507.02503)
**中文标题：持续梯度低秩投影微调用于大型语言模型**

*Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing*

主要分类: cs.LG

摘要简述: 论文提出了一种名为GORP的新训练策略，通过结合全参数和低秩参数，在统一低秩梯度子空间中联合更新，解决了大型语言模型持续微调中效率与表达能力的矛盾。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的持续微调面临效率与表达能力之间的权衡问题。低秩适应（LoRA）虽高效，但因低秩特性和显式参数约束限制了模型学习新任务和迁移知识的能力。

研究方法: GORP（梯度低秩投影）是一种新颖的训练策略，通过协同结合全参数和低秩参数，并在统一低秩梯度子空间中联合更新，扩展优化空间，同时保持高效性和减轻灾难性遗忘。

研究结果: 在持续学习基准测试中，GORP表现出优于现有最先进方法的性能。

研究结论: GORP通过结合全参数和低秩参数，有效解决了持续微调中的效率与表达能力问题，为大型语言模型的持续学习提供了新思路。

中文摘要: 大型语言模型（LLMs）的持续微调受限于效率与表达能力之间的权衡。低秩适应（LoRA）虽高效，但因低秩特性和显式参数约束限制了模型学习新任务和迁移知识的能力。我们提出了GORP（梯度低秩投影）持续学习策略，通过协同结合全参数和低秩参数，并在统一低秩梯度子空间中联合更新，克服了这些限制。GORP在扩展优化空间的同时保持了高效性，并减轻了灾难性遗忘。在持续学习基准测试中，GORP表现出优于现有最先进方法的性能。代码可在https://github.com/Wcxwcxw/GORP获取。

</details>


### [203] [Position: A Theory of Deep Learning Must Include Compositional Sparsity](https://arxiv.org/abs/2507.02550)
**中文标题：观点：深度学习理论必须包含组合稀疏性**

*David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio*

主要分类: cs.LG

摘要简述: 本文提出，深度神经网络（DNNs）的成功源于其能够利用目标函数的组合稀疏结构，即大多数实际相关函数可由少量低维输入的子函数组合而成。这一特性为DNNs的高效学习和泛化提供了理论基础。


<details>
  <summary>详细信息</summary>
研究动机: 尽管过参数化的深度神经网络在多个高维领域表现出色，但其学习动态的基本原理仍不明确。本文旨在探讨DNNs成功的关键在于其能够利用目标函数的组合稀疏结构。

研究方法: 通过分析组合稀疏性在高效可计算函数中的普遍性，本文论证了DNNs能够利用这一结构特性。同时，探讨了现有理论在近似和泛化方面的局限性。

研究结果: 研究发现，组合稀疏性是DNNs高效学习和泛化的核心机制，且这一特性普遍存在于当前学习问题中。然而，关于DNNs可学习性和优化的关键问题仍需进一步研究。

研究结论: 组合稀疏性在深度学习中的作用是构建全面人工智能理论的关键。未来研究需填补其在DNNs学习和优化中的理论空白。

中文摘要: 过参数化的深度神经网络（DNNs）在多个高维领域表现出色，超越了受维度诅咒影响的传统浅层网络。然而，关于DNNs学习动态的基本原理仍存在未解之谜。本文认为，DNNs的成功源于其能够利用目标函数的组合稀疏结构，即大多数实际相关函数可由少量低维输入的子函数组合而成。研究表明，这一特性是所有高效图灵可计算函数共有的，因此在当前学习问题中普遍存在。尽管在组合稀疏函数的近似和泛化方面已有一些理论见解，但关于DNNs可学习性和优化的关键问题仍需探索。完善组合稀疏性在深度学习中的作用，对构建全面的人工智能理论至关重要。

</details>


### [204] [L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation](https://arxiv.org/abs/2507.02619)
**中文标题：L-VAE：具有可学习β的解耦表示变分自编码器**

*Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural*

主要分类: cs.LG

摘要简述: 本文提出了一种名为L-VAE的新模型，通过学习损失函数的超参数实现解耦表示，解决了β-VAE中超参数需手动调整的问题，并在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: β-VAE需要手动调整超参数η，限制了其性能。本文旨在通过自动学习超参数，动态平衡解耦和重构损失，提升模型性能。

研究方法: L-VAE扩展了β-VAE，通过同时学习损失项权重和模型参数，动态调整解耦与重构的权衡，并引入正则化项防止偏置。

研究结果: 实验表明，L-VAE在dSprites、MPI3D-complex等数据集上表现优异，解耦指标优于或接近β-VAE、VAE等基线模型，且在CelebA数据集上成功解耦面部属性。

研究结论: L-VAE通过自动学习超参数，有效平衡了解耦与重构性能，在多个任务中表现优于或接近现有模型，验证了其方法的有效性。

中文摘要: 本文提出了一种名为可学习变分自编码器（L-VAE）的新模型，通过学习损失函数的超参数实现解耦表示。L-VAE可视为β-VAE的扩展，其中超参数η被自动学习。L-VAE通过动态调整解耦与重构损失的权衡，解决了β-VAE的局限性。在提出的模型中，损失项的权重与模型架构参数被同时学习，并引入正则化项以防止偏置。实验分析表明，L-VAE在重构保真度与解耦潜在维度之间找到了有效平衡。与β-VAE、VAE、ControlVAE等模型在dSprites、MPI3D-complex等数据集上的比较显示，L-VAE的解耦指标表现最优或次优。此外，在CelebA数据集上的定性实验证实了L-VAE在解耦面部属性上的成功。

</details>


### [205] [Fair Deepfake Detectors Can Generalize](https://arxiv.org/abs/2507.02645)
**中文标题：公平的深度伪造检测器可以泛化**

*Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli*

主要分类: cs.LG

摘要简述: 本文揭示了深度伪造检测模型中公平性与泛化能力之间的因果关系，并提出了一种名为DAID的框架，通过数据重平衡和特征聚合来同时提升公平性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的深度伪造检测模型在泛化能力和公平性之间存在冲突，本文旨在揭示两者之间的因果关系，并提出一种能够同时优化这两者的方法。

研究方法: 提出了DAID框架，包括两部分：1) 基于逆倾向加权和子群特征归一化的数据重平衡，以消除分布偏差；2) 使用对齐损失抑制敏感属性信号的特征聚合。

研究结果: 在三个跨域基准测试中，DAID在公平性和泛化能力上均优于现有最先进的检测器，验证了其理论和实践的有效性。

研究结论: 通过控制混杂因素，DAID证明了公平性干预可以提升泛化能力，为深度伪造检测领域提供了一种新的解决方案。

中文摘要: 深度伪造检测模型面临两个关键挑战：对未见操作的泛化能力以及在人口群体中的公平性。然而，现有方法往往表明这两个目标本质上是冲突的，揭示了它们之间的权衡。本文首次揭示并正式定义了公平性与泛化能力之间的因果关系。基于后门调整，我们表明通过控制混杂因素（数据分布和模型容量），公平性干预可以提升泛化能力。基于这一发现，我们提出了DAID框架，它包括：1) 使用逆倾向加权和子群特征归一化的数据重平衡，以消除分布偏差；2) 使用对齐损失抑制敏感属性信号的特征聚合。在三个跨域基准测试中，DAID在公平性和泛化能力上均优于现有最先进的检测器，验证了其理论和实践的有效性。

</details>


### [206] [Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs](https://arxiv.org/abs/2507.02671)
**中文标题：基于嵌入的差分隐私条件变分自编码器联邦数据共享方法**

*Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig*

主要分类: cs.LG

摘要简述: 本文提出了一种基于差分隐私条件变分自编码器（DP-CVAE）的联邦数据共享方法，通过提取紧凑且信息丰富的嵌入，降低计算开销并支持多样化下游任务，同时确保差分隐私。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在医学影像领域具有革命性意义，但数据稀缺和隐私法规限制了其广泛应用。联邦学习虽支持去中心化训练，但通信成本高且灵活性不足。本文旨在解决这些问题，提出一种隐私保护且高效的数据共享方法。

研究方法: 采用基础模型提取紧凑嵌入，减少冗余；通过差分隐私条件变分自编码器（DP-CVAE）建模全局隐私感知数据分布，支持多样化下游任务。该方法在多个特征提取器上验证，确保隐私、可扩展性和效率。

研究结果: 实验表明，DP-CVAE在隐私保护、可扩展性和效率方面优于传统联邦学习分类器，同时生成比差分隐私条件生成对抗网络（DP-CGAN）更高保真度的嵌入，且参数需求减少5倍。

研究结论: 本文提出的DP-CVAE方法在隐私保护、数据共享效率和下游任务支持方面表现优异，为医学影像等领域的数据共享提供了可行解决方案。

中文摘要: 深度学习（DL）在医学影像领域具有革命性意义，但其应用受限于数据稀缺和隐私法规，难以获取多样化数据集。联邦学习（FL）支持去中心化训练，但通信成本高且通常仅支持单一下游任务，灵活性不足。我们提出了一种基于差分隐私（DP）生成模型的数据共享方法。通过采用基础模型，提取紧凑且信息丰富的嵌入，减少冗余并降低计算开销。客户端协作训练差分隐私条件变分自编码器（DP-CVAE），建模全局隐私感知数据分布，支持多样化下游任务。我们的方法在多个特征提取器上验证，提升了隐私性、可扩展性和效率，优于传统联邦学习分类器，同时确保差分隐私。此外，DP-CVAE生成的嵌入比DP-CGAN具有更高保真度，且参数需求减少5倍。

</details>


### [207] [Fast and Simplex: 2-Simplicial Attention in Triton](https://arxiv.org/abs/2507.02754)
**中文标题：快速与单纯：Triton中的2-单纯形注意力**

*Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil*

主要分类: cs.LG

摘要简述: 本文提出了一种基于2-单纯形注意力的Transformer架构，通过高效的Triton内核实现，显著提升了模型的令牌效率，在数学、编程和逻辑任务中表现优于标准点积注意力。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型依赖大规模互联网数据集，计算资源不再是唯一瓶颈，令牌效率变得至关重要。本文旨在探索一种更高效的注意力机制，以优化令牌使用。

研究方法: 研究采用2-单纯形Transformer架构，将标准点积注意力推广为三线性函数，并通过Triton内核高效实现。

研究结果: 实验表明，2-单纯形注意力在固定令牌预算下，在数学、编程、推理和逻辑任务中优于标准点积注意力，并改变了知识任务和推理任务的缩放定律指数。

研究结论: 2-单纯形注意力是一种高效的替代方案，能够显著提升令牌效率，为未来模型设计提供了新的方向。

中文摘要: 近期研究表明，训练损失随模型规模和令牌数量呈幂律增长，而实现计算最优模型需要同时扩展模型规模和令牌数量。然而，这些缩放定律假设数据无限供应，且主要适用于计算受限的场景。随着现代大型语言模型越来越依赖大规模互联网数据集，计算受限的假设逐渐失效。这一转变凸显了对令牌效率优先架构的需求。
  本文研究了2-单纯形Transformer的使用，该架构通过高效的Triton内核实现，将标准点积注意力推广为三线性函数。我们证明，2-单纯形Transformer在令牌效率上优于标准Transformer：在固定令牌预算下，规模相近的模型在数学、编程、推理和逻辑任务中表现更优。我们通过量化这些增益，展示了2-单纯形注意力改变了知识任务和推理任务的缩放定律指数，与点积注意力相比。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [208] [DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift](https://arxiv.org/abs/2507.02824)
**中文标题：基于DNN的RIS辅助毫米波MIMO系统中实用相位偏移的预编码设计**

*Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang*

主要分类: eess.SP

摘要简述: 本文研究了在毫米波MIMO系统中使用RIS辅助的预编码设计，通过DNN降低计算复杂度并提升频谱效率。


<details>
  <summary>详细信息</summary>
研究动机: 在毫米波MIMO系统中，直接通信路径可能被遮挡，传统方法计算复杂度高且耗时，因此需要一种高效的方法优化预编码设计。

研究方法: 采用RIS增强MIMO传输，利用DNN替代传统穷举搜索，快速选择最优码字，同时结合离散傅里叶变换向量设计码本。

研究结果: 仿真结果表明，DNN在测试阶段即使终端与RIS距离变化时仍能保持次优频谱效率。

研究结论: DNN在RIS辅助系统中具有显著潜力，能够高效优化预编码设计并提升系统性能。

中文摘要: 本文研究了在毫米波多输入多输出（MIMO）系统中，当直接通信路径被遮挡时，通过可重构智能表面（RIS）增强MIMO传输的预编码设计。考虑到毫米波的视距（LoS）和多径效应特性，传统的穷举搜索（ES）在连续相位偏移中寻找最优码字计算复杂度高且耗时。为降低计算复杂度，采用离散傅里叶变换（DFT）向量设计码本，并结合实际或理想RIS系统的幅度响应。然而，即使在离散相位偏移中使用ES，仍会导致大量计算和时间消耗。为此，本文开发了训练好的深度神经网络（DNN）以加速码字选择。仿真结果表明，在测试阶段，即使终端与RIS距离变化，DNN仍能保持次优频谱效率。这些结果凸显了DNN在推动RIS辅助系统发展中的潜力。

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [209] [Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning](https://arxiv.org/abs/2507.01972)
**中文标题：基于强化学习的投资组合优化与期权定价加速求解**

*Hadi Keramati,Samaneh Jazayeri*

主要分类: q-fin.PM

摘要简述: 本文提出了一种基于强化学习（RL）的框架，用于优化投资组合优化和期权定价中迭代求解器的块预条件子大小，显著加速收敛并降低计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 在投资组合优化和期权定价中，大型线性系统的求解通常需要迭代方法，但病态系统的收敛速度较慢。传统预条件技术需要问题特定的参数调整，限制了效率。因此，作者希望通过RL动态调整块预条件子大小，以加速求解器的收敛。

研究方法: 作者提出了一种RL驱动的框架，动态调整迭代求解器中的块预条件子大小。该方法通过RL算法自动优化预条件子参数，从而加速病态系统的收敛。

研究结果: 在真实投资组合优化矩阵上的评估表明，该RL框架能够显著加速迭代求解器的收敛，并减少计算成本。

研究结论: 提出的加速求解器支持动态投资组合分配和实时期权定价中的更快决策，展示了RL在优化数值计算中的潜力。

中文摘要: 我们提出了一种基于强化学习（RL）的框架，用于优化投资组合优化和期权定价中迭代求解器的块预条件子大小。投资组合优化中的协方差矩阵或期权定价模型中微分算子的离散化会导致形式为$\mathbf{A}\textbf{x}=\textbf{b}$的大型线性系统。高维投资组合或细网格期权定价的直接求逆会带来显著的计算成本。因此，在实际应用中通常使用迭代方法。然而，病态系统的收敛速度较慢。传统的预条件技术通常需要问题特定的参数调整。为了克服这一限制，我们依赖RL动态调整块预条件子大小，加速迭代求解器的收敛。在一系列真实投资组合优化矩阵上的评估表明，我们的RL框架可用于调整预条件子，显著加速收敛并降低计算成本。提出的加速求解器支持动态投资组合分配和实时期权定价中的更快决策。

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [210] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
**中文标题：解决湍流磁流体动力学：一种混合算子-扩散框架**

*Semih Kacmaz,E. A. Huerta,Roland Haas*

主要分类: physics.flu-dyn

摘要简述: 本文提出了一种混合机器学习框架，结合物理信息神经算子（PINO）和基于分数的生成扩散模型，用于模拟二维不可压缩电阻磁流体动力学（MHD）湍流的时空演化。该框架在广泛的雷诺数范围内实现了高精度模拟，填补了确定性代理模型在高湍流水平下的空白。


<details>
  <summary>详细信息</summary>
研究动机: 传统的确定性代理模型在高雷诺数湍流模拟中表现不佳，无法准确捕捉高频动态和非高斯统计特性。本文旨在通过结合物理信息神经算子和扩散模型，解决这一难题，实现对湍流全频谱动态的高保真模拟。

研究方法: 方法结合了物理信息神经算子（PINO）和条件扩散模型。PINO用于预测低频相干动态，而扩散模型则随机修正高频残差，从而实现对湍流的完整模拟。训练数据来自高保真模拟，覆盖雷诺数从100到10000的范围。

研究结果: 在雷诺数为1000和3000时，模型能够准确重建速度和磁场的光谱能量分布，捕捉非高斯统计特性和间歇性结构。在极端湍流水平（Re=10000）下，模型首次实现了对磁场高波数演化的恢复，并保持了大规模形态的准确性。

研究结论: 该混合框架为高雷诺数湍流模拟提供了一种高效且高精度的解决方案，填补了现有方法的空白，并为复杂湍流系统的研究提供了新的工具。

中文摘要: 我们提出了一种混合机器学习框架，结合了物理信息神经算子（PINO）和基于分数的生成扩散模型，用于模拟二维不可压缩电阻磁流体动力学（MHD）湍流在广泛雷诺数范围内的全时空演化。该框架利用PINO的方程约束泛化能力预测低频相干动态，同时通过条件扩散模型随机修正高频残差，从而实现对完全发展湍流的高精度建模。模型在包含雷诺数从100到10000的高保真模拟数据集上训练，在以往确定性代理模型无法处理的范围内达到了最先进的精度。在雷诺数为1000和3000时，模型能够准确重建速度和磁场的光谱能量分布，捕捉非高斯统计特性、间歇性结构和跨场相关性。在极端湍流水平（Re=10000）下，该模型首次实现了对磁场高波数演化的恢复，保持了大规模形态的准确性，并提供了统计上有意义的预测。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [211] [Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes](https://arxiv.org/abs/2507.02331)
**中文标题：追踪模块化CMA-ES配置在问题景观中的交互作用**

*Ana Nikolikj,Mario Andrés Muñoz,Eva Tuba,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文利用算法足迹概念，研究了CMA-ES算法的六种模块化变体在24个BBOB基准问题上的表现，揭示了算法配置与问题特性之间的交互关系。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索算法配置与问题特征之间的相互作用，以解释为何同一算法的不同配置在不同问题上表现各异，并识别影响这些表现的问题特征。

研究方法: 方法包括计算六种模块化CMA-ES变体（modCMA）在5维和30维BBOB基准问题上的性能足迹，分析其与问题特性的交互关系。

研究结果: 结果显示，不同配置因与问题特性的共同交互而表现出共享行为模式，同时在同一问题上因不同问题特征而表现出独特行为。

研究结论: 结论表明，算法足迹能有效提升算法行为的可解释性，并为配置选择提供指导。

中文摘要: 本文利用最近提出的算法足迹概念，研究了算法配置与问题特征之间的相互作用。计算了六种模块化CMA-ES变体（modCMA）在BBOB套件的24个基准问题上的性能足迹，分别在5维和30维设置下进行。这些足迹揭示了为何同一算法的不同配置表现各异，并识别了影响这些结果的问题特征。分析发现了配置之间因与问题特性的共同交互而共享的行为模式，以及在同一问题上因不同问题特征而表现出的独特行为。结果表明，算法足迹能有效提升可解释性并指导配置选择。

</details>


### [212] [ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms](https://arxiv.org/abs/2507.02337)
**中文标题：ClustOpt：一种基于聚类的方法用于表示和可视化数值元启发式优化算法的搜索动态**

*Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文提出了一种基于聚类的可视化方法ClustOpt，用于分析和展示数值元启发式优化算法的搜索动态，并引入了稳定性和相似性指标以量化算法行为。


<details>
  <summary>详细信息</summary>
研究动机: 传统可视化方法（如收敛图、轨迹映射等）难以清晰展示高维或复杂解空间中的搜索动态，因此需要一种更直观、动态的表现方式。

研究方法: 通过聚类算法探索的候选解，并跟踪迭代过程中聚类成员的变化，从而动态展示搜索过程；同时引入算法稳定性和相似性两个指标，量化算法行为。

研究结果: 该方法应用于十种数值元启发式算法，揭示了其稳定性和行为差异，为理解搜索动态提供了新视角。

研究结论: ClustOpt方法为优化算法的搜索动态提供了更直观和可解释的表现形式，有助于算法的改进和应用。

中文摘要: 理解数值元启发式优化算法的行为对其发展和应用至关重要。传统的可视化技术（如收敛图、轨迹映射和适应度景观分析）往往难以清晰展示搜索过程的结构动态，尤其是在高维或复杂解空间中。为此，我们提出了一种新的表示和可视化方法，通过聚类算法探索的候选解，并跟踪迭代过程中聚类成员的变化，从而动态且可解释地展示搜索过程。此外，我们引入了两个指标——算法稳定性和算法相似性，分别用于量化单个算法多次运行的搜索轨迹一致性以及不同算法之间的相似性。我们将此方法应用于十种数值元启发式算法，揭示了其稳定性和比较行为，从而更深入地理解了它们的搜索动态。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [213] [Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System](https://arxiv.org/abs/2507.02000)
**中文标题：为何多兴趣公平性重要：基于超图对比多兴趣学习的公平对话推荐系统**

*Yongsen Zheng,Zongxuan Xie,Guohua Wang,Ziyao Liu,Liang Lin,Kwok-Yan Lam*

主要分类: cs.IR

摘要简述: 本文提出了一种名为HyFairCRS的新框架，旨在解决对话推荐系统中的多兴趣公平性问题，通过超图对比学习捕捉用户多样兴趣，并在动态交互中实现公平推荐。


<details>
  <summary>详细信息</summary>
研究动机: 推荐系统中的不公平问题（如性别、种族、年龄或流行度偏见）会导致马太效应、过滤气泡和回音室等严重问题。现有方法多针对静态场景，而动态对话推荐系统中的不公平问题尚未得到充分解决。

研究方法: HyFairCRS通过对比学习构建多样化的超图以捕捉用户多兴趣，并在对话中利用这些兴趣生成信息丰富的响应，同时在动态用户-系统反馈循环中确保公平的项目预测。

研究结果: 在两个对话推荐系统数据集上的实验表明，HyFairCRS在提升推荐性能的同时有效缓解了不公平问题，达到了新的最优水平。

研究结论: HyFairCRS通过多兴趣公平性学习和动态交互优化，为对话推荐系统提供了一种有效的公平推荐解决方案。

中文摘要: 不公平性是推荐系统（RSs）中一个众所周知的挑战，通常会导致基于性别、种族、年龄或流行度等属性的偏见结果。尽管已有一些方法在离线或静态场景中改进公平推荐，但不公平问题往往会随时间加剧，引发马太效应、过滤气泡和回音室等严重问题。为解决这些问题，我们提出了一种新框架——基于超图对比多兴趣学习的公平对话推荐系统（HyFairCRS），旨在动态交互的对话推荐系统（CRSs）中促进多兴趣多样性公平。HyFairCRS首先通过对比学习构建多样化超图以捕捉广泛的用户兴趣，随后在对话中利用这些兴趣生成信息丰富的响应，并在动态用户-系统反馈循环中确保公平的项目预测。在两个基于CRS的数据集上的实验表明，HyFairCRS在有效缓解不公平性的同时实现了新的最优性能。我们的代码发布于https://github.com/zysensmile/HyFairCRS。

</details>


### [214] [ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations](https://arxiv.org/abs/2507.02014)
**中文标题：ManifoldMind：基于动态双曲推理的可信推荐系统**

*Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic*

主要分类: cs.IR

摘要简述: ManifoldMind是一种基于双曲空间的动态几何推荐系统，通过自适应曲率建模和几何感知推理，提供透明且多样化的推荐。


<details>
  <summary>详细信息</summary>
研究动机: 现有推荐系统通常采用固定曲率和刚性嵌入，无法灵活建模用户和项目的不确定性，且缺乏透明推理能力。ManifoldMind旨在解决这些问题，通过动态双曲空间建模实现个性化推荐和语义探索。

研究方法: ManifoldMind将用户、项目和标签表示为自适应曲率的概率球体，利用曲率感知的语义核进行多跳推理，支持多样化的概念路径探索，避免对浅层交互的过拟合。

研究结果: 在四个公开基准测试中，ManifoldMind在NDCG、校准性和多样性方面优于基线模型，并能生成显式推理轨迹，提升推荐的可信度和探索性。

研究结论: ManifoldMind通过动态双曲空间建模和几何感知推理，为稀疏或抽象领域的推荐提供了透明、可信且多样化的解决方案。

中文摘要: 我们提出了ManifoldMind，一种基于双曲空间的概率几何推荐系统，用于在语义层次结构中进行探索性推理。与以往固定曲率和刚性嵌入的方法不同，ManifoldMind将用户、项目和标签表示为自适应曲率的概率球体，支持个性化不确定性建模和几何感知的语义探索。曲率感知的语义核支持软性多跳推理，使模型能够探索多样化的概念路径，而非局限于浅层或直接交互。在四个公开基准测试中，ManifoldMind在NDCG、校准性和多样性方面表现优于强基线模型，并能生成显式推理轨迹，为稀疏或抽象领域提供透明、可信且探索驱动的推荐。

</details>


### [215] [When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search](https://arxiv.org/abs/2507.02139)
**中文标题：当大型语言模型意见相左：SDG搜索中的相关性过滤偏差与检索分歧诊断**

*William A. Ingram,Bipasha Banerjee,Edward A. Fox*

主要分类: cs.IR

摘要简述: 研究发现，大型语言模型（LLMs）在标注文档相关性时存在系统性分歧，影响检索结果，尤其在可持续发展目标（SDGs）相关文献中表现明显。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在信息检索中广泛用于标注文档相关性，但不同模型在边缘案例上存在分歧，可能影响下游检索效果。本研究旨在分析这种分歧的性质及其对检索的影响。

研究方法: 研究比较了两种开源LLMs（LLaMA和Qwen）在可持续发展目标（SDGs 1、3、7）相关学术摘要上的标注分歧，分析了分歧案例的词汇特征、排名行为和分类可预测性。

研究结果: 结果显示，模型分歧具有系统性：分歧案例呈现一致的词汇模式，在共享评分函数下产生不同的排名结果，且简单分类器的AUC值超过0.74。

研究结论: LLM基于的过滤在文档检索中引入了结构化变异性，即使在控制提示和共享排名逻辑下也是如此。建议将分类分歧作为检索评估的分析对象，尤其在政策相关或主题搜索任务中。

中文摘要: 大型语言模型（LLMs）越来越多地用于信息检索流程中标注文档相关性，尤其是在缺乏人工标注数据的领域。然而，不同模型在边缘案例上常存在分歧，引发了对下游检索影响的担忧。本研究分析了两种开源LLMs（LLaMA和Qwen）在可持续发展目标（SDGs 1、3、7）相关学术摘要上的标注分歧。我们分离了分歧子集，并研究了其词汇特性、排名行为和分类可预测性。结果表明，模型分歧是系统性的而非随机的：分歧案例表现出一致的词汇模式，在共享评分函数下产生不同的排名结果，且使用简单分类器时AUC值超过0.74。这些发现表明，即使在控制提示和共享排名逻辑下，LLM基于的过滤也会在文档检索中引入结构化变异性。我们建议将分类分歧作为检索评估的分析对象，尤其是在政策相关或主题搜索任务中。

</details>


### [216] [Content filtering methods for music recommendation: A review](https://arxiv.org/abs/2507.02282)
**中文标题：音乐推荐中的内容过滤方法：综述**

*Terence Zeng,Abhishek K. Umrawal*

主要分类: cs.IR

摘要简述: 本文综述了音乐推荐系统中内容过滤方法的研究现状，重点探讨了如何通过内容过滤缓解协同过滤的偏差问题，并分析了歌词分类和音频信号处理等技术。


<details>
  <summary>详细信息</summary>
研究动机: 音乐推荐系统中，协同过滤方法因用户交互稀疏性而效果有限。本文旨在探讨内容过滤方法如何解决这一问题，并分析其技术实现和潜在冲突。

研究方法: 综述了当前研究中的内容过滤方法，包括基于大语言模型（LLMs）的歌词分析和音频信号处理技术，并探讨了不同方法之间的潜在冲突及解决方案。

研究结果: 内容过滤方法在缓解协同过滤偏差方面具有潜力，但不同技术（如歌词分析和音频处理）之间存在冲突，需进一步研究以优化整合。

研究结论: 内容过滤为音乐推荐系统提供了新的研究方向，未来需解决不同分析方法间的冲突以实现更精准的推荐。

中文摘要: 推荐系统在现代音乐流媒体平台中至关重要，影响了用户发现和接触歌曲的方式。协同过滤是推荐系统的常见方法，它基于与目标用户听歌模式相似的其他用户的偏好来推荐内容。然而，对于交互稀疏的媒体（如音乐），这种方法效果较差，因为音乐流媒体服务的普通用户很少会收听绝大多数曲目。由于这种稀疏性，需要通过其他方法解决相关挑战。本文综述了当前研究在应对这些挑战方面的进展，重点探讨了内容过滤在缓解协同过滤方法固有偏差中的作用。我们研究了用于内容过滤的多种歌曲分类方法，包括基于大语言模型（LLMs）的歌词分析和音频信号处理技术。此外，我们还讨论了这些不同分析方法之间的潜在冲突，并提出了解决此类差异的途径。

</details>
