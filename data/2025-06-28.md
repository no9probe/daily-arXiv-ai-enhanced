<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.CV](#cs.CV) [Total: 112]
- [cs.AI](#cs.AI) [Total: 13]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.LG](#cs.LG) [Total: 36]
- [cs.DL](#cs.DL) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.RO](#cs.RO) [Total: 5]
- [cs.DC](#cs.DC) [Total: 2]
- [eess.IV](#eess.IV) [Total: 8]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.SE](#cs.SE) [Total: 6]
- [cs.SD](#cs.SD) [Total: 5]
- [math.NA](#math.NA) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.HC](#cs.HC) [Total: 3]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [stat.ME](#stat.ME) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
**中文标题：面向表格数据的概率问答研究**

*Chen Shen,Sajjadur Rahman,Estevam Hruschka*

主要分类: cs.CL

摘要简述: 本文提出了一种针对表格数据的概率问答新方法，结合贝叶斯网络和大语言模型，显著提升了概率问题的回答能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于表格数据的问答系统（如NL2SQL）在处理事实性问题时表现良好，但在需要不确定性推理的概率问题上表现不足。本文旨在填补这一空白。

研究方法: 方法包括从表格中构建贝叶斯网络，将自然语言查询转化为概率查询，并利用大语言模型生成最终答案。

研究结果: 实验结果表明，该方法在基准测试LUCARIO上显著优于基线模型，展示了符号-神经混合推理的优势。

研究结论: 本文提出的框架为表格数据中的概率问答提供了有效解决方案，结合了符号推理和神经模型的优势。

中文摘要: 当前针对表格数据的问答方法（如NL2SQL系统）在处理事实性问题时表现良好，但在需要不确定性推理的概率问题上表现不足。本文提出了一个新的基准测试LUCARIO和一个针对大规模表格数据的概率问答框架。我们的方法从表格中构建贝叶斯网络，将自然语言查询转化为概率查询，并利用大语言模型生成最终答案。实验结果表明，该方法在基准测试上显著优于基线模型，凸显了符号-神经混合推理的优势。

</details>


### [2] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
**中文标题：大语言模型的多语言功能评估**

*Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian*

主要分类: cs.CL

摘要简述: 本文提出多语言功能评估基准（CL-GSM Symbolic和CL-IFEval），通过翻译现有英语功能基准至五种语言（法语、西班牙语、印地语、阿拉伯语和约鲁巴语），评估大语言模型在多语言环境中的实际性能和鲁棒性。结果显示，某些静态基准（如M-MMLU）与功能性能更接近，而模型在不同语言中的表现差异显著。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大语言模型多语言能力评估（如Belebele、M-MMLU和M-GSM）主要依赖静态数据基准，无法充分反映模型在多语言环境中的实际性能和鲁棒性。因此，作者希望通过创建多语言功能评估基准，更全面地评估模型的表现。

研究方法: 作者通过将现有的英语功能基准模板翻译为五种语言（法语、西班牙语、印地语、阿拉伯语和约鲁巴语），构建了两个多语言功能评估基准：跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令跟随评估（CL-IFEval）。

研究结果: 结果显示，某些静态多语言基准（如M-MMLU）与功能性能更接近（性能下降仅0.5%至3%），而其他基准（如M-GSM和Belebele）的性能下降显著（15%至24%）。此外，模型在不同语言中的鲁棒性差异显著，某些语言（如阿拉伯语和英语）表现更稳定。

研究结论: 研究表明，静态多语言基准与功能性能的关联性存在差异，且模型在不同语言中的鲁棒性不一致。多语言功能评估基准能更全面地反映模型的实际表现，为未来研究提供了重要参考。

中文摘要: 大语言模型的多语言能力通常通过静态数据基准（如Belebele、M-MMLU和M-GSM）进行评估，但这些评估往往无法充分反映模型在多语言环境中的实际性能和鲁棒性。为此，我们通过将现有的英语功能基准模板翻译为五种语言（法语、西班牙语、印地语、阿拉伯语和约鲁巴语），创建了多语言功能评估基准——跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令跟随评估（CL-IFEval）。结果显示，某些静态多语言基准（如M-MMLU）与功能性能更接近（性能下降仅0.5%至3%），而其他基准（如M-GSM和Belebele）的性能下降显著（15%至24%）。此外，模型在不同语言中的鲁棒性差异显著，某些语言（如阿拉伯语和英语）表现更稳定。

</details>


### [3] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
**中文标题：创意与执行的差距：LLM生成与人类研究想法的执行结果对比**

*Chenglei Si,Tatsunori Hashimoto,Diyi Yang*

主要分类: cs.CL

摘要简述: 研究发现，尽管LLM生成的研究想法在创意阶段被认为更具新颖性，但在实际执行后，其效果显著下降，甚至不如人类专家的想法。这表明当前LLM在生成真正有效的研究想法上存在局限。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在科学研究中展现出加速研究流程的潜力，但其生成的研究想法是否能在执行后产生更好的研究成果尚不明确。本文旨在验证LLM生成的想法是否优于人类专家的想法。

研究方法: 研究招募了43位专家研究人员，随机分配执行LLM生成或人类专家撰写的研究想法。每位专家花费超过100小时实施想法，并撰写4页的短论文记录实验。所有项目由NLP专家盲审，比较执行前后的评分变化。

研究结果: 执行后，LLM生成的想法在所有评估指标（新颖性、兴奋度、有效性和整体评分）上的评分显著下降（p < 0.05），甚至在某些指标上人类想法的评分反超LLM想法。

研究结论: 研究揭示了“创意-执行差距”，表明当前LLM在生成真正有效的研究想法上存在局限，同时也凸显了缺乏执行结果时评估研究想法的挑战。

中文摘要: 大型语言模型（LLM）在加速科学研究流程方面展现出潜力，其关键能力之一是生成新颖的研究想法。此前研究发现，在某些情境下，LLM生成的研究想法被认为比人类专家的想法更具新颖性。然而，一个好的想法不仅应看似新颖，还应在执行后产生更好的研究成果。为验证AI生成的想法是否能带来更好的研究结果，我们开展了一项执行研究，招募了43位专家研究人员，随机分配执行LLM生成或人类专家撰写的研究想法。每位专家花费超过100小时实施想法，并撰写4页的短论文记录实验。所有项目由NLP专家盲审。比较执行前后的评分发现，LLM生成的想法在所有评估指标（新颖性、兴奋度、有效性和整体评分）上的评分显著下降（p < 0.05），缩小了创意阶段观察到的LLM与人类想法之间的差距。在执行研究的汇总评分中，甚至发现许多指标上人类想法的评分反超LLM想法。这一“创意-执行差距”揭示了当前LLM在生成真正有效的研究想法上的局限性，以及缺乏执行结果时评估研究想法的挑战。

</details>


### [4] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
**中文标题：MultiFinRAG：一种优化的多模态检索增强生成框架，用于金融问答**

*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

主要分类: cs.CL

摘要简述: MultiFinRAG是一个专为金融问答设计的优化多模态检索增强生成框架，通过多模态提取、模态感知检索和分层回退策略，显著提升了复杂金融问题的回答准确性。


<details>
  <summary>详细信息</summary>
研究动机: 金融文档（如10-Ks、10-Qs和投资者演示文稿）通常包含数百页的多模态内容（如密集文本、结构化表格和复杂图表），传统大型语言模型（LLMs）和检索增强生成（RAG）方法因令牌限制、布局丢失和跨模态上下文碎片化而难以处理此类任务。

研究方法: MultiFinRAG首先通过轻量级开源多模态LLM对表格和图表进行批量处理，生成结构化JSON输出和简洁文本摘要；随后将这些输出与叙述性文本嵌入并索引，采用模态感知相似性阈值进行精确检索；最后通过分层回退策略动态调整上下文范围，实现跨模态推理。

研究结果: 在涉及文本、表格、图像和跨模态推理的复杂金融问答任务中，MultiFinRAG在普通硬件上运行时的准确率比免费版ChatGPT-4o高出19个百分点。

研究结论: MultiFinRAG通过优化的多模态处理和动态上下文调整，显著提升了金融问答的准确性和效率，为多模态金融文档分析提供了实用解决方案。

中文摘要: 金融文档（如10-Ks、10-Qs和投资者演示文稿）通常长达数百页，包含密集叙述性文本、结构化表格和复杂图表等多种模态。回答此类内容的问题通常需要跨模态联合推理，而传统大型语言模型（LLMs）和检索增强生成（RAG）方法因令牌限制、布局丢失和跨模态上下文碎片化而难以胜任。为此，我们提出了MultiFinRAG，一个专为金融问答设计的检索增强生成框架。MultiFinRAG首先通过轻量级开源多模态LLM对表格和图表进行批量处理，生成结构化JSON输出和简洁文本摘要；随后将这些输出与叙述性文本嵌入并索引，采用模态感知相似性阈值进行精确检索；最后通过分层回退策略动态调整上下文范围，实现跨模态推理。尽管运行在普通硬件上，MultiFinRAG在涉及文本、表格、图像和跨模态推理的复杂金融问答任务中的准确率比免费版ChatGPT-4o高出19个百分点。

</details>


### [5] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
**中文标题：揭示大型语言模型中的隐藏暴力倾向：基于行为情景的人口统计分析**

*Quintin Myers,Yanjun Gao*

主要分类: cs.CL

摘要简述: 本文首次使用社会科学的暴力行为情景问卷（VBVQ）评估大型语言模型（LLM）对现实冲突的反应，发现其表面文本生成与内部暴力倾向存在差异，且暴力倾向因人口统计特征而异。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）被提议用于检测和应对网络暴力内容，但其在道德模糊现实场景中的推理能力尚未充分研究。本文旨在填补这一空白，评估LLM的暴力倾向及其与人口统计特征的关系。

研究方法: 研究采用暴力行为情景问卷（VBVQ），通过基于角色的提示（涵盖种族、年龄和地理身份）评估六种不同地缘政治和组织背景下开发的LLM，统一采用零样本设置。

研究结果: 研究发现：（1）LLM的表面文本生成与内部暴力倾向不一致；（2）其暴力倾向因人口统计特征而异，且与犯罪学、社会科学和心理学的已知结论相矛盾。

研究结论: LLM在暴力倾向评估中存在表面与内部的不一致，且其反应受人口统计特征影响，这为LLM的道德推理能力提供了新见解。

中文摘要: 大型语言模型（LLM）越来越多地被提议用于检测和应对网络暴力内容，但其在道德模糊现实场景中的推理能力尚未充分研究。我们首次使用经过验证的社会科学工具——暴力行为情景问卷（VBVQ）评估LLM。为评估潜在偏见，我们引入了基于角色的提示，涵盖美国境内的种族、年龄和地理身份。在统一的零样本设置下，评估了六种不同地缘政治和组织背景下开发的LLM。研究发现：（1）LLM的表面文本生成常与其内部暴力倾向不一致；（2）其暴力倾向因人口统计特征而异，常与犯罪学、社会科学和心理学的已知结论相矛盾。

</details>


### [6] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
**中文标题：少做决定，多沟通：论医学端到端事实核查的构念效度**

*Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li*

主要分类: cs.CL

摘要简述: 本文研究了医学领域端到端事实核查系统的局限性，指出其难以应对模糊声明和主观真实性标签，建议将其视为交互式沟通问题而非端到端过程。


<details>
  <summary>详细信息</summary>
研究动机: 由于医学决策的高风险性和医学文献的复杂性，公众对自动事实核查系统的需求增加。然而，这类系统在实际应用中未被广泛采用。本文旨在探讨临床专家如何验证社交媒体上的医学声明，揭示端到端事实核查在医学领域的根本挑战。

研究方法: 通过研究临床专家如何综合医学证据验证社交媒体上的真实声明，探索端到端事实核查在医学领域的上限，并分析其面临的挑战。

研究结果: 研究发现，医学事实核查面临三大挑战：难以将实际声明与临床试验证据关联；模糊声明与意图不匹配的歧义性；以及真实性标签的主观性。

研究结论: 作者认为，事实核查应被视为交互式沟通问题而非端到端过程，并建议在评估时采用这一视角。

中文摘要: 技术进步使得自动事实核查等具有挑战性的任务取得了具体进展。由于医学决策的高风险性以及评估庞大且多样化的医学文献的困难，公众对在公共卫生和医学领域采用这些系统的兴趣日益增长。循证医学与每个人息息相关，但其技术性极强，导致大多数用户的医学素养不足以充分理解这一领域。医学沟通中的这些问题为端到端事实核查代理提供了土壤：根据当前医学文献核查声明并返回证据支持的结论。然而，这类系统仍未被广泛使用。为了理解这一现象，我们首次研究了临床专家如何通过综合医学证据验证社交媒体上的真实声明。在探索这一上限时，我们揭示了端到端事实核查在医学应用中的根本挑战：难以将实际声明与临床试验证据关联；模糊声明与意图不匹配的歧义性；以及真实性标签的主观性。我们认为，事实核查应被视为交互式沟通问题而非端到端过程，并在评估时采用这一视角。

</details>


### [7] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
**中文标题：优化语言模型以适应下游任务：后训练视角**

*Zhengyan Shi*

主要分类: cs.CL

摘要简述: 本文提出了一系列优化语言模型（LM）以适应下游任务的方法，包括利用未标记数据的持续预训练技术、参数高效微调方法以及改进的监督微调策略，显著提升了模型的鲁棒性、效率和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管语言模型在自然语言处理中表现出色，但如何高效且鲁棒地将其适应到特定任务仍具挑战性。传统微调方法存在未充分利用未标记数据、在小数据集上过拟合以及计算成本高等问题，限制了其在现实任务中的应用。

研究方法: 1. 提出一种新颖的持续预训练技术，从未标记数据中提取任务相关知识；2. 开发参数高效的微调方法，显著降低内存和计算成本；3. 改进监督微调方法，使模型在标记数据稀缺时仍能有效遵循指令；4. 设计新的评估方法和基准任务（如多跳空间推理任务），全面评估模型能力。

研究结果: 通过广泛的实验验证，这些方法显著提升了语言模型的鲁棒性、效率和泛化能力，使其能够更好地适应多样化的自然语言处理任务，包括开放式生成任务。

研究结论: 本文提出的方法为语言模型在下游任务中的应用提供了更高效和鲁棒的解决方案，推动了语言模型向更通用的人工智能目标迈进。

中文摘要: 语言模型（LM）在自然语言处理中展现出卓越能力，但如何高效且鲁棒地将其适应到特定任务仍具挑战性。随着模型规模和复杂性的增加，基于标记数据的微调往往未能充分利用未标记数据，容易在小规模任务数据集上过拟合，且计算成本高昂。这些问题限制了语言模型在现实语言任务中的广泛应用。

本文提出了一系列方法以更好地将语言模型适应到下游应用中。首先，我们探索了从未标记数据中提取任务相关知识的策略，提出了一种新颖的持续预训练技术，其性能优于当前最先进的半监督方法。其次，我们提出了一种参数高效的微调方法，显著降低了内存和计算成本，同时保持了竞争力。此外，我们还改进了监督微调方法，使语言模型在标记数据稀缺时仍能更好地遵循指令，从而提升其在多种自然语言处理任务（包括开放式生成）中的表现。最后，我们开发了新的评估方法和基准任务（如多跳空间推理任务），以更全面地评估语言模型的能力和适应性。

通过在不同自然语言任务中的广泛实验，结果表明这些方法显著提升了语言模型的鲁棒性、效率和泛化能力，使其能够更好地适应多样化的应用场景。这些进展标志着语言模型向更鲁棒和高效的方向迈出了重要一步，为实现通用人工智能的目标提供了支持。

</details>


### [8] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
**中文标题：FineWeb2：一流程适配所有语言——预训练数据处理的通用化**

*Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf*

主要分类: cs.CL

摘要简述: 本文提出了一种名为FineWeb2的新型多语言预训练数据集处理流程，能够自动适应任何语言，并通过实验验证其在九种语言上的有效性，最终扩展到1000多种语言，发布了一个20TB的多语言数据集。


<details>
  <summary>详细信息</summary>
研究动机: 当前，尽管英语预训练数据集的开发取得了显著进展，但多语言大型语言模型（LLM）的训练仍面临挑战，主要原因是难以针对多种语言定制数据过滤和去重流程。

研究方法: 基于FineWeb的数据集处理流程，通过自动适配支持任何语言，并在九种语言上进行了实验验证。此外，提出了一种基于重复计数和质量的数据集再平衡方法。

研究结果: 实验表明，该流程能够生成性能优于以往数据集的非英语语料库，并通过扩展到1000多种语言，发布了20TB的多语言数据集FineWeb2。

研究结论: FineWeb2流程为多语言LLM训练提供了高效的数据处理解决方案，并通过公开数据集和代码库促进了进一步研究。

中文摘要: 预训练最先进的大型语言模型（LLM）需要大量干净且多样化的文本数据。尽管英语预训练数据集的开放开发近年来取得了显著进展，但训练高性能的多语言LLM仍然是一个挑战，主要原因在于难以针对大量语言定制过滤和去重流程。本文提出了一种基于FineWeb的新型预训练数据集处理流程，能够自动适配支持任何语言。我们在九种语言上对流程设计进行了广泛实验，并通过基于可测量标准的新颖任务选择过程指导评估。结果表明，该流程能够生成性能优于以往数据集的非英语语料库。此外，我们还提出了一种简单且原则性的数据集再平衡方法，综合考虑了重复计数和质量，进一步提升了性能。最后，我们将流程扩展到1000多种语言，利用近100个Common Crawl快照生成了FineWeb2，这是一个20TB（50亿文档）的多语言数据集，并随流程、训练和评估代码库一同发布。

</details>


### [9] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
**中文标题：KaLM-Embedding-V2：卓越的训练技术与数据激发多功能嵌入模型**

*Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang*

主要分类: cs.CL

摘要简述: 本文提出了KaLM-Embedding-V2，一种多功能且紧凑的嵌入模型，通过先进的训练技术和数据，在通用文本嵌入任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 当前嵌入模型在性能和泛化能力上仍有提升空间，尤其是对于紧凑模型的需求日益增长。本文旨在通过创新的训练技术和丰富的数据集，提升嵌入模型的性能。

研究方法: 1. 采用完全双向Transformer架构和均值池化生成固定长度嵌入；2. 多阶段训练流程：预训练、微调和模型参数平均；3. 引入焦点式重加权机制和在线硬负样本混合策略；4. 收集大量预训练和微调数据以增强模型性能。

研究结果: 在MTEB中英文评测中，KaLM-Embedding-V2显著优于同类模型，并与更大规模的模型竞争，为紧凑嵌入模型设定了新标准。

研究结论: KaLM-Embedding-V2通过创新的训练技术和丰富的数据集，实现了高性能和强泛化能力，为紧凑嵌入模型的发展提供了新方向。

中文摘要: 本文提出KaLM-Embedding-V2，一种多功能且紧凑的嵌入模型，通过卓越的训练技术和数据，在通用文本嵌入任务中取得显著性能。主要创新包括：1. 采用完全双向Transformer架构和均值池化生成固定长度嵌入；2. 多阶段训练流程：预训练、微调和模型参数平均；3. 引入焦点式重加权机制和在线硬负样本混合策略；4. 收集20类预训练数据和100类微调数据以提升性能。在MTEB中英文评测中，该模型显著优于同类模型，并与更大规模的模型竞争，为紧凑嵌入模型设定了新标准。

</details>


### [10] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
**中文标题：梯度下降能模拟提示吗？**

*Eric Zhang,Leshem Choshen,Jacob Andreas*

主要分类: cs.CL

摘要简述: 本文探讨了梯度下降是否能模拟提示的效果，提出了一种元训练方法，使梯度更新能模拟提示的作用，结果显示梯度下降在某些任务上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型（LM）通常通过修改提示或参数（如微调）来整合新信息。提示在某些任务上表现更优，但参数更新无长期存储成本。本文旨在探索是否可以通过梯度下降模拟提示的效果。

研究方法: 采用基于梯度的元学习方法，以语言模型自身的提示预测为目标，无需真实标签。通过梯度下降训练，使模型在单次更新后能模拟提示的效果。

研究结果: 实验表明，梯度下降在某些任务上能完全或部分恢复提示模型的性能，例如在“反转诅咒”任务和文本问答任务中表现优异。

研究结论: 结果表明，通过适当的初始化，梯度下降具有惊人的表达能力，为长上下文建模提供了新思路，并揭示了梯度学习的泛化能力。

中文摘要: 语言模型（LM）整合新信息有两种主要方式：修改提示或修改参数（如微调）。参数更新无需长期存储成本，但提示在许多任务中表现更优：提示模型能从单例中泛化并完成逻辑推理，而标准微调则无法实现。能否通过修改模型使微调模拟提示的效果？本文提出了一种元训练方法，使梯度更新能模拟提示的作用。该方法基于梯度元学习工具，但以LM自身的提示预测为目标，无需真实标签。后续梯度下降训练在某些任务中能完全或部分恢复提示模型的性能，例如在“反转诅咒”任务和单次梯度更新后的文本问答任务中表现优异。这些结果表明，通过适当的初始化，梯度下降具有惊人的表达能力。研究结果为长上下文建模提供了新思路，并揭示了梯度学习的泛化能力。

</details>


### [11] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
**中文标题：SAC：一种用于测量和动态控制LLM人格特质强度的框架**

*Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SAC的框架，用于测量和动态控制大型语言模型（LLM）的人格特质强度，扩展了16PF模型以提供更精细的人格表达，并通过实验验证了其一致性和可控性。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多依赖大五人格模型（OCEAN），其维度较粗糙且缺乏对特质强度的动态控制。本文旨在填补这一空白，通过引入16PF模型和动态强度控制框架SAC，实现更精细和可控的LLM人格表达。

研究方法: 本文扩展了机器人格量表（MPI），引入16PF模型，并开发了SAC框架，通过形容词语义锚定和行为问题（频率、深度、阈值、努力和意愿）动态控制特质强度。

研究结果: 实验表明，将强度建模为连续谱比二元切换更一致和可控，且目标特质强度的变化会系统影响相关特质，表明LLM内化了多维人格结构。

研究结论: SAC框架为医疗、教育和面试等领域提供了更精细的人机交互可能性，推动了类人社交机器人的发展。

中文摘要: 近年来，大型语言模型（LLM）在多个领域获得了广泛应用，人们对其在交互中展现类人个性的期望也日益增长。为满足这一需求，许多研究提出了通过心理测量评估建模LLM人格的方法。然而，现有模型大多依赖大五人格（OCEAN）框架，仅提供粗略的人格维度，且缺乏控制特质强度的机制。本文通过扩展原本基于大五模型的机器人格量表（MPI），引入16种人格因素（16PF）模型，实现了对16种特质的精细控制。我们还开发了名为特定属性控制（SAC）的结构化框架，用于评估和动态诱导LLM的特质强度。该方法通过形容词语义锚定引导特质强度表达，并利用行为问题（频率、深度、阈值、努力和意愿）实现动态控制。实验表明，将强度建模为连续谱比二元切换更一致和可控，且目标特质强度的变化会系统影响相关特质，表明LLM内化了多维人格结构。我们的工作为医疗、教育和面试等领域提供了更精细的人机交互可能性，推动了类人社交机器人的发展。

</details>


### [12] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
**中文标题：大型语言模型在特许会计师考试中的卓越表现**

*Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta*

主要分类: cs.CL

摘要简述: 大型语言模型（LLMs）在财务领域的应用潜力巨大，但其对专业财务知识的掌握程度尚不明确。本文提出CA-Ben基准，评估LLMs在财务、法律和定量推理方面的能力，发现Claude 3.5 Sonnet和GPT-4o表现最佳，但在数值计算和法律解释方面仍有挑战。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在自然语言处理方面取得显著进展，但其在专业财务领域的实际应用能力尚不清楚。特别是在印度复杂的金融背景下，缺乏一个系统评估LLMs财务能力的基准。

研究方法: 本文设计了CA-Ben基准，基于印度特许会计师协会（ICAI）的考试题目，构建了涵盖基础、中级和高级阶段的问答数据集。评估了六种主流LLMs（如GPT-4o、Claude 3.5 Sonnet等）的表现。

研究结果: 评估结果显示，Claude 3.5 Sonnet和GPT-4o在概念和法律推理方面表现优异，但在数值计算和法律解释方面存在明显不足。

研究结论: 当前LLMs在财务领域的应用具有潜力，但仍需改进，尤其是在定量分析和法律解释方面。未来可通过混合推理和检索增强生成方法进一步提升性能。

中文摘要: 先进的智能系统，尤其是大型语言模型（LLMs），通过自然语言处理（NLP）的进步显著重塑了财务实践。然而，这些模型在多大程度上有效掌握并应用领域特定的财务知识仍不确定。针对印度广阔金融背景下的关键空白，本文提出了CA-Ben，一个专门用于评估LLMs在财务、法律和定量推理能力的特许会计师基准。CA-Ben包含基于印度特许会计师协会（ICAI）严格考试的结构化问答数据集，涵盖基础、中级和高级CA课程阶段。六种主流LLMs（包括GPT-4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4）通过标准化协议进行了评估。结果显示性能差异，Claude 3.5 Sonnet和GPT-4o表现最佳，尤其是在概念和法律推理方面。数值计算和法律解释方面存在显著挑战。研究结果强调了当前LLMs的优势和局限性，建议未来通过混合推理和检索增强生成方法改进，特别是在定量分析和准确法律解释方面。

</details>


### [13] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
**中文标题：一种半监督可扩展的电商查询分类统一框架**

*Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law*

主要分类: cs.CL

摘要简述: 本文提出了一种半监督可扩展的统一框架（SSUF），用于解决电商查询分类中的信息不足和标签依赖问题，通过知识增强、标签增强和结构增强模块显著提升分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 电商查询通常简短且缺乏上下文，现有方法依赖用户点击行为构建训练样本，导致马太效应，且缺乏统一框架，算法优化效率低。

研究方法: SSUF框架包含知识增强模块（利用世界知识增强查询表示）、标签增强模块（利用标签语义和半监督信号减少对后验标签的依赖）和结构增强模块（基于复杂标签关系增强标签表示），各模块高度可插拔。

研究结果: 离线和在线A/B实验表明，SSUF显著优于现有最优模型。

研究结论: SSUF通过统一框架和增强模块有效解决了电商查询分类中的信息不足和标签依赖问题，提升了分类性能。

中文摘要: 查询分类（包括意图和类别预测等多个子任务）对电商应用至关重要。电商查询通常简短且缺乏上下文，标签间信息无法利用，导致建模先验信息不足。现有工业方法多依赖用户点击行为构建训练样本，形成马太效应。此外，查询分类子任务缺乏统一框架，算法优化效率低。本文提出了一种半监督可扩展统一框架（SSUF），包含多个增强模块以统一查询分类任务。知识增强模块利用世界知识增强查询表示，解决查询信息不足问题；标签增强模块利用标签语义和半监督信号减少对后验标签的依赖；结构增强模块基于复杂标签关系增强标签表示。各模块高度可插拔，输入特征可根据子任务需求增减。大量离线和在线A/B实验表明，SSUF显著优于现有最优模型。

</details>


### [14] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
**中文标题：MT2-CSD：一种新的多目标多轮对话立场检测数据集及多语义知识融合方法**

*Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang*

主要分类: cs.CL

摘要简述: 本文提出了MT2-CSD数据集和LLM-CRAN方法，用于多目标多轮对话立场检测，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统立场检测研究多针对单例场景，难以模拟真实社交媒体中的多轮对话动态，且缺乏相关数据集。本文旨在填补这一空白。

研究方法: 提出LLM-CRAN方法，利用大语言模型的推理能力增强对话理解，并在MT2-CSD数据集上进行实验验证。

研究结果: 实验结果表明，LLM-CRAN在MT2-CSD数据集上显著优于基线模型。

研究结论: MT2-CSD数据集和LLM-CRAN方法为多目标多轮对话立场检测提供了新工具和方向。

中文摘要: 在当代社交媒体中，自动立场检测对意见挖掘至关重要，它通过分析和综合用户对争议话题的观点来揭示主流趋势和情感。传统立场检测研究多针对单例场景，难以模拟真实社交媒体中的多轮对话动态，这主要源于缺乏真实反映社交媒体交互动态的数据集，阻碍了对话立场检测的发展。本文提出了MT2-CSD，一个用于多目标多轮对话立场检测的综合数据集。据我们所知，MT2-CSD是目前该领域最大的数据集，包含24,457个标注实例，并具有最深的对话深度，为立场检测带来了新挑战。为应对这些挑战，我们提出了大语言模型增强的对话关系注意力网络（LLM-CRAN），利用大语言模型的推理能力提升对话理解。我们在MT2-CSD数据集上进行了大量实验，结果表明LLM-CRAN在对话立场检测任务中显著优于强基线模型。

</details>


### [15] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
**中文标题：DALR：双层次对齐学习的多模态句子表示学习方法**

*Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji*

主要分类: cs.CL

摘要简述: 本文提出DALR（双层次对齐学习），通过细粒度跨模态对齐和全局模态内对齐学习，解决了多模态句子表示学习中的跨模态偏差和模态内语义分歧问题，显著提升了表示质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在图像和文本对齐上较为粗糙，存在跨模态偏差和模态内语义分歧问题，影响了句子表示的质量。本文旨在通过双层次对齐学习解决这些问题。

研究方法: 提出DALR方法，包括跨模态一致性学习模块（软化负样本并利用辅助任务语义相似性实现细粒度对齐）和模态内全局对齐学习（结合排名蒸馏捕捉复杂句子关系）。

研究结果: 在语义文本相似性（STS）和迁移（TR）任务上的实验表明，DALR优于现有基线方法。

研究结论: DALR通过双层次对齐学习有效提升了多模态句子表示的质量，实验验证了其优越性。

中文摘要: 以往的多模态句子表示学习方法取得了显著成果，但多数方法仅关注粗粒度的图像与文本对齐，面临跨模态偏差和模态内语义分歧两大挑战，严重影响句子表示质量。为解决这些问题，我们提出DALR（双层次对齐学习的多模态句子表示方法）。在跨模态对齐方面，我们提出一致性学习模块，通过软化负样本并利用辅助任务的语义相似性实现细粒度对齐。此外，我们认为句子关系不仅限于二元正负标签，而是呈现更复杂的排序结构。为更好地捕捉这些关系并提升表示质量，我们将排名蒸馏与全局模态内对齐学习相结合。在语义文本相似性（STS）和迁移（TR）任务上的全面实验验证了该方法的有效性，其性能始终优于现有基线。

</details>


### [16] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
**中文标题：ComRAG：基于动态向量存储的检索增强生成框架用于工业实时社区问答**

*Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan*

主要分类: cs.CL

摘要简述: ComRAG是一种用于实时工业社区问答的检索增强生成框架，通过动态向量存储整合静态知识与动态历史问答对，显著提升性能并降低延迟。


<details>
  <summary>详细信息</summary>
研究动机: 社区问答平台是重要的知识库，但现有方法未能充分利用外部知识或动态历史问答上下文，且缺乏适合工业部署的记忆机制。

研究方法: ComRAG采用基于质心的记忆机制，结合静态知识和动态历史问答对，实现检索、生成和高效存储。

研究结果: 在三个工业CQA数据集上，ComRAG显著优于基线，向量相似性提升25.9%，延迟降低8.7%至23.3%，迭代中块增长从20.23%降至2.06%。

研究结论: ComRAG通过动态向量存储和高效记忆机制，为工业社区问答提供了高性能的实时解决方案。

中文摘要: 社区问答平台可视为社区中重要的知识库，但如何实时有效地利用历史交互和领域知识仍是一大挑战。现有方法常未能充分利用外部知识、未能整合动态历史问答上下文，或缺乏适合工业部署的记忆机制。我们提出ComRAG，一种用于实时工业社区问答的检索增强生成框架，通过基于质心的记忆机制整合静态知识与动态历史问答对，实现检索、生成和高效存储。在三个工业CQA数据集上的评估显示，ComRAG始终优于所有基线——向量相似性提升高达25.9%，延迟降低8.7%至23.3%，迭代中块增长从20.23%降至2.06%。

</details>


### [17] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
**中文标题：Progtuning：基于Transformer语言模型的渐进式微调框架**

*Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu*

主要分类: cs.CL

摘要简述: 本文提出Progtuning框架，通过渐进式减少Transformer块的更新数量，优化资源分配，减少约25%的参数更新，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着Transformer模型规模增大，全参数微调成本高昂，现有参数高效微调方法仍存在资源分配不均的问题。

研究方法: Progtuning结合渐进学习，根据Transformer块的贡献逐步减少更新块的数量，优化资源分配。

研究结果: Progtuning减少约25%的参数更新，性能仍具竞争力，且与参数高效微调方法兼容性高。

研究结论: Progtuning通过渐进式学习显著提升资源利用效率，适用于多种微调场景。

中文摘要: 微调是利用基于Transformer的语言模型进行下游任务的一种有效技术。随着模型规模持续增长，更新所有模型参数的成本越来越高。参数高效微调方法通过选择性更新少量参数有效解决了这一问题。然而，微调和大多数现有参数高效微调方法仍需更新与初始规模相同数量的参数，忽略了Transformer块之间的贡献不均，导致计算资源分配极不高效。本文提出Progtuning，一种结合渐进学习的新型微调框架，专门针对基于Transformer的语言模型。具体而言，Progtuning根据贡献逐步减少更新的Transformer块数量。值得注意的是，Progtuning优化了资源分配，减少了约25%的更新参数，同时仍保持竞争力性能。此外，它与参数高效微调方法高度兼容，在多种适应场景中表现出色。

</details>


### [18] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
**中文标题：用于文本扩散建模的压缩平滑潜在空间**

*Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Cosmos的新方法，通过在压缩且平滑的潜在空间中运行扩散模型来解决文本生成问题，显著提升了生成速度和质量。


<details>
  <summary>详细信息</summary>
研究动机: 自回归语言模型在文本生成中占主导地位，但其顺序性导致解码速度慢且全局一致性难以保持。扩散模型虽能并行生成，但受限于高维度的标记级表示。本文旨在通过压缩潜在空间解决这一问题。

研究方法: Cosmos方法在压缩且平滑的潜在空间中运行扩散模型，通过自编码器学习该空间，同时结合预训练语言编码器的冻结激活，实现语义基础和有效的扰动增强。

研究结果: 实验表明，Cosmos能将文本表示压缩8倍，生成质量与标记级扩散模型相当，且通过增加潜在序列长度，其性能超越扩散模型和自回归基线模型。在多项生成任务中表现优异，推理速度快2倍以上。

研究结论: Cosmos在文本生成任务中表现出色，不仅生成质量高，还显著提升了推理速度，为扩散模型在文本生成中的应用提供了新思路。

中文摘要: 自回归语言模型主导了现代文本生成，但其顺序性带来了根本性限制：解码速度慢且全局一致性难以保持。扩散模型通过并行生成和灵活控制提供了有前景的替代方案，但其在文本生成中的应用受限于标记级表示的高维度。我们提出了Cosmos，一种完全在压缩且平滑的潜在空间中运行的文本生成方法，该空间专为扩散模型设计。该空间通过自编码器学习，同时结合预训练语言编码器的冻结激活，提供强大的语义基础和有效的扰动增强。实验表明，文本表示可压缩8倍，同时生成质量与标记级扩散模型相当。此外，增加潜在序列长度使Cosmos超越扩散模型和自回归基线模型。我们在故事生成、问题生成、摘要和去毒化等四项生成任务中评估Cosmos，并与多种生成范式对比。Cosmos在生成质量上表现相当或更优，同时推理速度快2倍以上。

</details>


### [19] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
**中文标题：CBF-AFA：基于分块的多自监督学习融合自动流畅度评估方法**

*Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc*

主要分类: cs.CL

摘要简述: 本文提出了一种基于分块的多自监督学习融合方法（CBF-AFA），用于自动流畅度评估，通过结合多种自监督学习模型的优势，显著提升了评估性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动流畅度评估（AFA）在非母语者中仍具挑战性，尤其是在捕捉语音节奏、停顿和不流畅性方面。现有方法难以兼顾语音的声学和语言特征，因此需要一种更精细的评估框架。

研究方法: 采用分块策略，结合自监督学习模型（Wav2Vec2、HuBERT和WavLM），利用Silero-VAD将语音分割为呼吸组块，并通过可学习的加权机制融合特征。同时，引入分块级流畅度标记（如语速、停顿时长和n-gram重复），使用CNN-BiLSTM框架捕捉局部和长期依赖关系。

研究结果: 在Avalinguo和Speechocean762数据集上的实验表明，该方法显著优于单一自监督学习基线，F1分数分别提升了4.2和2.8，Pearson相关系数分别提升了4.0和6.2。

研究结论: 分块多自监督学习融合方法在流畅度评估中表现出色，但未来需进一步研究其在非规则韵律方言中的泛化能力。

中文摘要: 自动流畅度评估（AFA）仍具挑战性，尤其是在捕捉非母语者的语音节奏、停顿和不流畅性方面。本文提出了一种基于分块的方法，结合了自监督学习模型（Wav2Vec2、HuBERT和WavLM），利用Silero语音活动检测（Silero-VAD）将语音分割为呼吸组块，以实现细粒度的时间分析并避免过度分割。通过可学习的加权机制融合自监督学习嵌入，平衡声学和语言特征，并加入分块级流畅度标记（如语速、停顿时长和n-gram重复）。CNN-BiLSTM框架用于捕捉分块间的局部和长期依赖关系。在Avalinguo和Speechocean762数据集上的评估显示，该方法在Speechocean762上比单一自监督学习基线F1分数提升了2.8，Pearson相关系数提升了6.2；在Avalinguo上F1分数提升了4.2，Pearson相关系数提升了4.0，优于基于Pyannote.audio的分割基线。这些结果表明，分块多自监督学习融合方法在流畅度评估中具有鲁棒性，但未来需进一步研究其在非规则韵律方言中的泛化能力。

</details>


### [20] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
**中文标题：维护MTEB：确保嵌入基准的长期可用性与可复现性**

*Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen*

主要分类: cs.CL

摘要简述: 本文探讨了如何维护大规模文本嵌入基准（MTEB）的长期可用性和可复现性，重点介绍了工程实践和设计选择，以确保其持续扩展和质量。


<details>
  <summary>详细信息</summary>
研究动机: MTEB已成为文本嵌入模型的标准评估平台，但如何确保其长期可复现性和扩展性仍是一个挑战。本文旨在通过工程实践解决这些问题。

研究方法: 通过建立稳健的持续集成流程，验证数据集完整性，自动化测试执行，并评估结果的泛化能力。同时，设计了处理社区贡献和扩展新任务与数据集的策略。

研究结果: 这些工程实践成功提升了MTEB的可复现性和可用性，使其在扩展的同时保持了高质量和领域相关性。

研究结论: 本文的经验为机器学习评估框架的维护者提供了宝贵见解，强调了工程实践在确保可复现性和可用性中的重要性。

中文摘要: 大规模文本嵌入基准（MTEB）已成为文本嵌入模型的标准评估平台。尽管先前的研究已确立了核心基准方法，但本文聚焦于确保MTEB持续可复现性和扩展性的工程实践。我们介绍了维护稳健持续集成流程的方法，包括验证数据集完整性、自动化测试执行以及评估基准结果的泛化能力。我们还详细说明了增强可复现性和可用性的设计选择。此外，讨论了处理社区贡献和扩展新任务与数据集的策略。这些工程实践在扩展MTEB的同时保持了其质量和领域相关性。我们的经验为面临类似挑战的基准维护者提供了宝贵见解。MTEB仓库地址为：https://github.com/embeddings-benchmark/mteb。

</details>


### [21] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
**中文标题：基于提示的对话轮换预测**

*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

主要分类: cs.CL

摘要简述: 本文提出了一种基于文本提示的动态控制对话轮换预测模型，通过指令（如“更快”或“更平静”）直观调整预测行为，实验证明其提升了预测准确性并有效适应不同对话场景。


<details>
  <summary>详细信息</summary>
研究动机: 现有的对话轮换预测模型缺乏动态控制能力，无法根据对话场景和需求灵活调整。本文旨在通过文本提示实现直观且显式的动态控制，提升对话系统的适应性和用户体验。

研究方法: 基于Transformer的语音活动预测（VAP）模型，引入文本提示嵌入到通道级和跨通道Transformer中。利用大型语言模型（LLM）生成合成提示数据，并在950小时的人-人对话数据上进行评估。

研究结果: 实验结果表明，该模型显著提升了预测准确性，并能根据文本提示动态调整对话轮换时机行为。

研究结论: 本文提出的基于文本提示的对话轮换预测模型具有实用性和灵活性，为对话系统提供了更直观的控制方式。

中文摘要: 对话轮换预测模型是语音对话系统和会话机器人的核心组件。近期研究利用基于Transformer的架构实现实时连续的语音活动预测。本研究提出了一种新型模型，通过文本提示动态控制对话轮换预测。该方法允许通过“更快”或“更平静”等指令直观且显式地调整预测行为，动态适应对话伙伴和场景。该模型基于Transformer的语音活动预测（VAP）模型，将文本提示嵌入到通道级和跨通道Transformer中。我们使用超过950小时的人-人对话数据评估了该方法的可行性。由于现有数据集中缺乏相关文本提示数据，我们利用大型语言模型（LLM）生成了合成提示语句。实验结果表明，该模型提升了预测准确性，并能根据文本提示有效调整对话轮换时机行为。

</details>


### [22] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
**中文标题：通过语法检索增强大型语言模型的自动术语提取能力**

*Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim*

主要分类: cs.CL

摘要简述: 本文提出了一种基于语法检索的提示策略，用于增强大型语言模型在自动术语提取任务中的表现，通过语法相似性选择示例，显著提升了F1分数。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型在多种NLP任务中表现优异，但其在自动术语提取（ATE）中的应用尚未充分探索。本文旨在通过语法检索方法，提升模型在术语提取中的表现，尤其是在领域无关和跨领域场景下。

研究方法: 提出了一种基于语法检索的提示策略，通过语法相似性而非语义相似性选择示例，为术语边界提供更可靠的指导。该方法在少量示例设置下进行实验，并分析了查询句子与检索示例之间的词汇重叠对性能的影响。

研究结果: 在三个专门的ATE基准测试中，语法检索方法显著提升了F1分数，证明了语法线索在术语提取任务中的重要性。

研究结论: 研究表明，语法检索方法能够有效提升大型语言模型在术语提取任务中的表现，尤其是在领域无关和跨领域场景下，为未来研究提供了新的方向。

中文摘要: 自动术语提取（ATE）用于识别领域特定表达，对机器翻译和信息检索等下游任务至关重要。尽管大型语言模型（LLMs）显著推动了多种NLP任务的发展，但其在ATE中的潜力尚未充分研究。我们提出了一种基于检索的提示策略，在少量示例设置下，根据语法而非语义相似性选择示例。这种语法检索方法具有领域无关性，并为捕捉术语边界提供了更可靠的指导。我们在领域内和跨领域场景下评估了该方法，分析了查询句子与其检索示例之间的词汇重叠对性能的影响。在三个专门的ATE基准测试中，语法检索方法提升了F1分数。这些发现凸显了语法线索在将LLMs应用于术语提取任务中的重要性。

</details>


### [23] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
**中文标题：Agent-RewardBench：面向真实世界多模态智能体的感知、规划与安全性奖励建模统一基准**

*Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

主要分类: cs.CL

摘要简述: 本文提出了Agent-RewardBench，一个用于评估多模态大语言模型（MLLMs）在感知、规划和安全性等多维度任务中奖励建模能力的基准测试。该基准包含7个真实场景，支持步骤级奖励评估，并通过高质量数据验证模型性能。实验表明，当前最先进的多模态模型表现有限，凸显了专门训练的必要性。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）的发展，多模态智能体在真实任务中展现出潜力，但由于缺乏外部反馈，其自我修正和泛化能力受限。奖励模型作为外部反馈的潜力尚未明确，亟需一个针对智能体的奖励建模基准。

研究方法: 提出了Agent-RewardBench基准，包含三个关键特征：（1）多维度真实场景评估，涵盖感知、规划和安全性；（2）步骤级奖励评估，提供任务执行过程中更细粒度的性能分析；（3）高质量数据，通过10个多样化模型采样、难度控制和人工验证确保数据完整性。

研究结果: 实验表明，即使是当前最先进的多模态模型，在奖励建模任务中表现有限，说明需要针对智能体的专门训练。

研究结论: Agent-RewardBench为评估多模态智能体的奖励建模能力提供了统一基准，揭示了现有模型的局限性，并强调了进一步研究的必要性。

中文摘要: 随着多模态大语言模型（MLLMs）的进步，多模态智能体在网页导航和具身智能等真实任务中展现出潜力。然而，由于缺乏外部反馈，这些智能体在自我修正和泛化方面存在困难。奖励模型作为一种外部反馈方法具有潜力，但如何为智能体选择奖励模型尚不明确。为此，我们提出了Agent-RewardBench，一个用于评估MLLMs奖励建模能力的基准。该基准具有三个关键特征：（1）多维度真实场景评估，涵盖感知、规划和安全性，包含7个场景；（2）步骤级奖励评估，支持对任务执行过程中每一步的能力评估，提供更细粒度的性能分析；（3）适当难度与高质量数据，通过10个多样化模型采样、难度控制和人工验证确保数据完整性。实验表明，即使是当前最先进的多模态模型表现有限，凸显了奖励建模专门训练的必要性。代码已在github上发布。

</details>


### [24] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
**中文标题：猫鼠游戏——假文本生成能否超越检测系统？**

*Andrea McGlinchey,Peter J Barclay*

主要分类: cs.CL

摘要简述: 大型语言模型能生成逼真的“假文本”，但简单分类器能以较少资源实现较高检测准确率。研究表明，随着模型升级，某些模型（如Gemini）生成欺骗性文本的能力增强，但可靠检测仍可能持续可行。


<details>
  <summary>详细信息</summary>
研究动机: 探讨大型语言模型生成假文本的能力是否会超越检测系统，以及检测技术是否能在模型规模不断增长的情况下保持有效性。

研究方法: 通过统计分类器检测古典侦探小说风格的假文本，比较不同版本模型（如Gemini和GPT）生成欺骗性文本的能力。

研究结果: Gemini在版本升级后生成欺骗性文本的能力增强，而GPT未表现出类似趋势，表明检测技术仍可能有效。

研究结论: 尽管模型规模扩大可能提升欺骗能力，但简单的检测方法仍可能保持有效性，尤其是针对特定风格的文本。

中文摘要: 大型语言模型能够在学术写作、产品评论和政治新闻等领域生成逼真的“假文本”。尽管检测人工生成文本的方法多种多样，看似会引发一场无休止的“军备竞赛”，但我们注意到，新型大型语言模型使用越来越多的参数、训练数据和能源，而相对简单的分类器却能以较少的资源实现较高的检测准确率。为了探讨模型是否会在欺骗检测器方面达到瓶颈，我们研究了统计分类器在识别古典侦探小说风格“假文本”方面的能力。在0.5版本的升级中，我们发现Gemini生成欺骗性文本的能力有所提升，而GPT则没有。这表明，即使模型规模不断扩大，可靠检测假文本仍可能持续可行，但新模型架构可能会提升其欺骗性。

</details>


### [25] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
**中文标题：双重检查器：通过自我批判式微调增强慢思考大语言模型的推理能力**

*Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin*

主要分类: cs.CL

摘要简述: 本文提出Double-Checker框架，通过自我批判式微调提升慢思考大语言模型的推理能力，显著提高其在复杂推理任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 慢思考大语言模型（LLMs）虽然具备反思式推理能力，但其生成批判性反馈和优化解决方案的能力仍然有限。本文旨在通过自我批判和迭代优化，增强LLMs的推理能力。

研究方法: 作者提出Double-Checker框架，通过微调1,730个自我批判实例，使LLMs能够在推理过程中迭代批判和优化其输出，直至自我评估为正确。

研究结果: 实验表明，Double-Checker显著提升了慢思考LLMs的推理能力，在AIME基准测试中，pass@1性能从4.4%提升至18.2%。

研究结论: Double-Checker为开发更具信任度和有效性的LLMs提供了一种新方向，展示了自我批判式推理的潜力。

中文摘要: 尽管慢思考大语言模型（LLMs）表现出类似反思的推理能力（通常称为“顿悟时刻”），但其生成有信息量的批判性反馈和优化先前解决方案的能力仍然有限。本文提出了Double-Checker，这是一个旨在通过促进显式自我批判和迭代优化先前解决方案来增强慢思考LLMs推理能力的框架。通过在我们整理的1,730个自我批判实例上进行微调，Double-Checker使长链推理LLMs能够在推理过程中迭代批判和优化其输出，直至其自我评估为正确。我们在全面的推理基准测试中验证了Double-Checker的有效性，结果表明迭代自我批判显著提升了长链推理LLMs的能力。值得注意的是，与原始的长链推理LLMs相比，我们的Double-Checker在具有挑战性的AIME基准测试中将pass@1性能从4.4%提升至18.2%。这些结果突显了开发更具信任度和有效性的、能够进行结构化自我批判的LLMs的潜力。

</details>


### [26] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
**中文标题：小型编码器在检测真实性方面可媲美大型解码器**

*Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar*

主要分类: cs.CL

摘要简述: 研究表明，轻量级编码器模型（如RoBERTa和NomicBERT）在检测语言模型生成内容的真实性（groundedness）方面，能够媲美大型解码器（如Llama3 8B和GPT4o），同时显著降低推理延迟。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在外部上下文支持下表现优异，但当上下文信息不足时，容易生成不可靠或脱离实际的回答。确保生成内容的真实性（groundedness）对事实一致性和可信度至关重要。本研究旨在通过检测查询是否基于上下文，避免高成本的答案生成过程，从而减少推理时间和资源消耗。

研究方法: 研究使用轻量级编码器模型（如RoBERTa和NomicBERT），通过微调精选数据集，检测查询是否基于提供的上下文。这种方法避免了直接使用大型解码器模型生成答案的高成本。

研究结果: 实验表明，轻量级编码器模型在检测真实性方面与大型解码器模型（如Llama3 8B和GPT4o）表现相当，同时将推理延迟降低了数个数量级。

研究结论: 轻量级编码器模型能够高效检测生成内容的真实性，显著降低资源消耗和延迟，为语言模型的实际应用提供了更经济的解决方案。

中文摘要: 通过为大型语言模型（LLM）提供外部上下文，可以显著提升其在自然语言处理（NLP）任务中的表现。然而，当上下文信息不足时，LLM往往难以可靠地回答查询，转而依赖无根据的推测或内部知识。真实性（groundedness）——即生成严格基于上下文的回答——对确保事实一致性和可信度至关重要。本研究聚焦于在昂贵的答案生成之前，检测给定查询是否基于提供的上下文文档。这种检测机制可大幅减少推理时间和资源消耗。研究表明，经过精选数据集微调的轻量级任务特定编码器模型（如RoBERTa和NomicBERT），在真实性检测方面能够达到与先进LLM（如Llama3 8B和GPT4o）相当的准确度，同时将推理延迟降低了数个数量级。代码已开源：https://github.com/chandarlab/Hallucinate-less

</details>


### [27] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
**中文标题：基于自回归语言模型的视觉对话中指代表达式检测**

*Bram Willemsen,Gabriel Skantze*

主要分类: cs.CL

摘要简述: 本文探讨了仅使用自回归语言模型从视觉对话中提取指代表达式的有效性，发现仅依赖语言上下文即可取得较好效果，但任务本质是多模态的。


<details>
  <summary>详细信息</summary>
研究动机: 研究目的是探索仅通过语言上下文（而非视觉信息）检测视觉对话中指代表达式的可行性，以验证语言模型在此任务中的潜力。

研究方法: 采用预训练的大型语言模型（LLM），通过参数高效微调，利用下一个词预测任务标注对话中的指代表达式边界。

研究结果: 实验表明，即使使用中等规模的LLM和小数据集，仅依赖文本的方法也能有效检测指代表达式，凸显语言上下文的重要性。

研究结论: 尽管文本方法有效，但任务本质是多模态的，单模态方法存在固有局限性。

中文摘要: 本文探讨了一种仅基于文本的自回归语言建模方法，用于从视觉对话中提取指代表达式。具体目标是研究仅凭语言上下文能否有效检测对话中与视觉内容相关的指代表达式。为此，我们调整了一个预训练的大型语言模型（LLM），通过下一个词预测任务对对话中的指代表达式边界进行粗粒度标注。结果表明，即使使用中等规模的LLM、小数据集和参数高效微调，仅文本方法也能取得良好效果，凸显了语言上下文在此任务中的重要性。然而，我们认为该任务本质上是多模态问题，并讨论了单模态方法的固有局限性。

</details>


### [28] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
**中文标题：结构主义视角下的人工智能文学批评：利用格雷马斯符号学方阵提升大语言模型能力**

*Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen*

主要分类: cs.CL

摘要简述: 本文提出GLASS框架，基于格雷马斯符号学方阵（GSS），提升大语言模型（LLM）在文学批评中的深度分析能力，并通过实验验证其高效性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）在文本生成和理解方面表现出色，但在对思想深刻、叙事复杂的文学作品进行专业批评时存在困难。本文旨在通过结构化分析框架GLASS，弥补这一不足。

研究方法: 提出GLASS框架，基于GSS设计结构化分析方法；构建首个GSS文学批评数据集（含48部作品分析）；采用LLM-as-a-judge范式量化评估GSS批评效果。

研究结果: GLASS框架在多个作品和LLM上的表现优于专家批评，且应用于39部经典作品时，填补了现有研究空白，生成高质量分析。

研究结论: GLASS为文学研究和教育提供了AI工具，揭示了文学认知机制的新视角。

中文摘要: 大语言模型（LLM）在文本理解和生成方面表现出色，但在对思想深刻、叙事复杂的文学作品进行专业批评时存在困难。本文提出GLASS（基于格雷马斯符号学方阵的文学分析框架），通过结构化分析方法提升LLM的深度文学分析能力。GLASS能够快速解析叙事结构和深层含义。我们构建了首个基于GSS的文学批评数据集，包含48部作品的详细分析，并采用LLM-as-a-judge范式提出量化评估指标。实验结果表明，GLASS框架在多个作品和LLM上的表现优于专家批评。最后，我们将GLASS应用于39部经典作品，填补了现有研究空白，生成了原创且高质量的分析。本研究为文学研究和教育提供了基于AI的工具，并为文学认知机制提供了新见解。

</details>


### [29] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
**中文标题：利用LLM辅助查询理解提升实时检索增强生成**

*Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng*

主要分类: cs.CL

摘要简述: 本文提出Omni-RAG框架，通过LLM辅助查询理解提升实时检索增强生成（RAG）系统对复杂、模糊查询的处理能力，包括查询分解、意图感知检索和结果重排生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有RAG系统在处理真实场景中噪声多、模糊且多意图的查询时表现不佳，Omni-RAG旨在通过改进查询预处理和检索策略，提升系统在开放域实时应用中的鲁棒性。

研究方法: Omni-RAG包含三个核心模块：(1) 深度查询理解与分解，利用LLM去噪并分解多意图查询；(2) 意图感知知识检索，为子查询从FineWeb中检索并聚合结果；(3) 重排与生成，通过BGE重排文档后由Falcon-10B生成最终响应。

研究结果: Omni-RAG显著提升了RAG系统对复杂查询的处理能力，能够有效去噪、分解多意图查询并生成更准确的响应，适用于SIGIR 2025 LiveRAG挑战等实际场景。

研究结论: Omni-RAG通过LLM辅助查询理解填补了当前RAG系统与真实应用需求之间的差距，为开放域实时检索生成任务提供了更鲁棒的解决方案。

中文摘要: 现实中的实时检索增强生成（RAG）系统在处理用户查询时面临重大挑战，这些查询通常包含噪声、模糊且涉及多意图。尽管RAG通过外部知识增强了大型语言模型（LLM），但现有系统通常因训练或评估数据较干净而难以应对复杂输入。本文提出Omni-RAG，一种新颖框架，旨在提升RAG系统在开放域实时场景中的鲁棒性和有效性。Omni-RAG利用LLM辅助查询理解，通过三个关键模块预处理用户输入：(1) 深度查询理解与分解，使用定制提示的LLM去噪查询（如纠正拼写错误）并将多意图查询分解为结构化子查询；(2) 意图感知知识检索，从FineWeb（基于OpenSearch）中为每个子查询检索并聚合结果；(3) 重排与生成，通过BGE重排文档后由Falcon-10B使用思维链提示生成最终响应。Omni-RAG旨在通过鲁棒处理复杂和噪声查询，填补当前RAG能力与SIGIR 2025 LiveRAG挑战等实际需求之间的差距。

</details>


### [30] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
**中文标题：领域知识增强的大语言模型用于欺诈和概念漂移检测**

*Ali Şenol,Garima Agrawal,Huan Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种结合领域知识的LLM框架，用于检测动态平台上的欺诈和概念漂移，显著提升了分类准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 动态平台上语言模式的演变和概念漂移（CD）使得欺诈检测变得困难，现有LLM在风险敏感场景中易受上下文模糊和幻觉影响，亟需结合领域知识提升性能。

研究方法: 提出了一种领域知识增强的LLM框架，包含三个模块：DK-LLM检测欺诈对话、OCDD检测语义漂移、第二个DK-LLM分类漂移性质。基于LLaMA实现，结合结构化提示。

研究结果: 在虚假评论数据集和SEConvo对话数据集上验证，分类准确率达98%，显著优于零样本基线，提升了性能、可解释性和鲁棒性。

研究结论: 领域知识和漂移感知的引入显著提升了LLM在高风险NLP应用中的表现，为欺诈和概念漂移检测提供了有效解决方案。

中文摘要: 在动态平台上检测欺骗性对话因语言模式演变和概念漂移（CD）而日益困难。概念漂移指语义或主题随时间变化，可能掩盖恶意意图或模仿正常对话，导致分类困难。尽管大语言模型（LLM）在自然语言任务中表现优异，但在风险敏感场景中易受上下文模糊和幻觉影响。为解决这些问题，我们提出了一种领域知识（DK）增强的LLM框架，将预训练LLM与结构化任务特定知识结合，用于欺诈和概念漂移检测。该框架包含三个主要组件：（1）DK-LLM模块检测虚假对话；（2）漂移检测单元（OCDD）判断语义漂移；（3）第二个DK-LLM模块分类漂移性质（良性或欺诈）。我们首先在虚假评论数据集上验证领域知识的价值，随后将框架应用于SEConvo多轮对话数据集（包含多种欺诈和垃圾攻击）。结果显示，系统能高精度检测虚假对话并有效分类漂移性质。基于LLaMA的实现通过结构化提示达到98%的分类准确率。与零样本基线的对比研究表明，结合领域知识和漂移感知显著提升了高风险NLP应用的性能、可解释性和鲁棒性。

</details>


### [31] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
**中文标题：跨语言的Text2Cypher：评估超越英语的基础模型**

*Makbule Gulcin Ozsoy,William Tai*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型在多语言Text2Cypher任务中的表现，发现英语表现最佳，西班牙语次之，土耳其语最差，并指出训练数据差异和语言特性是主要原因。


<details>
  <summary>详细信息</summary>
研究动机: 当前大多数自然语言接口研究仅关注英语，缺乏对其他语言的评估。本文旨在填补这一空白，研究多语言环境下Text2Cypher任务的性能差异。

研究方法: 通过将英语问题翻译为西班牙语和土耳其语，并保留原始Cypher查询，创建多语言测试集。使用标准化提示和指标评估多个基础模型。

研究结果: 结果显示模型在英语上表现最佳，西班牙语次之，土耳其语最差。提示翻译对性能影响较小。

研究结论: 研究强调了多语言查询生成评估和开发的必要性，未来工作包括模式本地化和多语言微调。

中文摘要: 近期大型语言模型的进展使得自然语言接口能够将用户问题翻译为数据库查询，如Text2SQL、Text2SPARQL和Text2Cypher。尽管这些接口提升了数据库的可访问性，但当前研究大多仅关注英语，对其他语言的评估有限。本文研究了基础LLM在多语言Text2Cypher任务中的表现。我们通过将英语问题翻译为西班牙语和土耳其语，同时保留原始Cypher查询，创建并发布了一个多语言测试集，以实现公平的跨语言比较。我们使用标准化提示和指标评估了多个基础模型。结果显示一致的性能模式：英语最高，西班牙语次之，土耳其语最低。我们将其归因于训练数据可用性和语言特性的差异。此外，我们探讨了将任务提示翻译为西班牙语和土耳其语的影响。结果显示评估指标变化甚微，表明提示翻译影响较小。我们的发现强调了多语言查询生成中更包容的评估和开发的必要性。未来工作包括模式本地化和多语言微调。

</details>


### [32] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
**中文标题：基于用户交互的语音对话模型对齐**

*Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez*

主要分类: cs.CL

摘要简述: 本文提出了一种新颖的偏好对齐框架，通过用户交互改进实时语音对话模型。研究基于大规模标注数据集和离线对齐方法，显著提升了对话模型的真实性、安全性和上下文一致性。


<details>
  <summary>详细信息</summary>
研究动机: 当前偏好学习方法主要针对文本语言模型，无法直接适用于实时语音交互的复杂性（如打断、插话等）。本文旨在填补这一空白，通过用户交互数据改进语音对话模型。

研究方法: 研究构建了一个包含15万对偏好标注的大规模数据集，结合AI反馈，覆盖语言内容和时间上下文变化。采用离线对齐方法微调全双工自回归语音到语音模型。

研究结果: 实验表明，通用对话的反馈能显著提升语音对话模型的真实性、安全性和上下文对齐。部署后的人类评估验证了模型在多轮对话中的表现。

研究结论: 研究强调了在实时语音对话系统中平衡多种动态因素的重要性，为自然对话系统提供了重要启示。

中文摘要: 本文提出了一种新颖的偏好对齐框架，用于通过用户交互改进实时语音对话模型。当前的偏好学习方法主要针对文本语言模型，无法直接适用于实时语音交互的复杂性（如打断、插话等），且缺乏明确的说话轮次分割。我们构建了一个包含超过15万对偏好标注的大规模数据集，结合AI反馈，覆盖语言内容和时间上下文变化。利用离线对齐方法微调了一个全双工自回归语音到语音模型。大量实验表明，通用对话的反馈能持续有效地改进语音对话模型，使其生成更真实、更安全且更符合上下文的交互。我们部署了微调后的模型，并通过全面的人类评估评估了其超越单轮对话的影响。研究发现，平衡多种动态因素是自然实时语音对话系统的关键。

</details>


### [33] [TopK Language Models](https://arxiv.org/abs/2506.21468)
**中文标题：TopK语言模型**

*Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling*

主要分类: cs.CL

摘要简述: 本文提出了一种改进的Transformer架构，通过引入TopK激活函数，使模型的隐藏状态等同于TopK稀疏自编码器的潜在特征，从而无需后训练即可实现可解释性。TopK语言模型在模型大小、计算效率和可解释性之间取得了良好平衡，同时保持了原始能力。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏自编码器（SAE）在分析和解释基于Transformer的语言模型的激活空间时存在局限性，如后训练的不确定性、特征不稳定性和难以跨检查点比较。这些问题降低了SAE的实用性和内部有效性。

研究方法: 作者提出了一种改进的Transformer架构，在选定层中引入TopK激活函数，使隐藏状态直接等同于TopK稀疏自编码器的潜在特征。这种方法避免了后训练的需求，同时提供了与SAE相当的可解释性。

研究结果: 实验表明，TopK语言模型学习的稀疏表示能够通过定向神经元干预成功引导，并支持跨检查点和层的神经元形成过程详细分析。TopK模型在保持原始能力的同时，提供了稳定且可靠的可解释性工具。

研究结论: TopK语言模型为理解语言模型如何学习和表示概念提供了稳定可靠的工具，有望显著推动未来模型可解释性和可控性的研究。

中文摘要: 稀疏自编码器（SAE）已成为分析和解释基于Transformer的语言模型（LM）激活空间的重要工具。然而，SAE存在一些缺陷，降低了其实用性和内部有效性。由于SAE是后训练的，无法确定未能发现某个概念是由于SAE的失败还是底层LM未表示该概念。训练条件和架构选择进一步影响了SAE学习哪些特征。在追踪LM训练过程中如何学习概念时，特征的不稳定性也使得难以比较不同检查点之间的SAE特征。为解决这些问题，我们提出了一种改进的Transformer架构，在选定层中引入TopK激活函数，使模型的隐藏状态等同于TopK SAE的潜在特征。这种方法无需后训练，同时提供了与SAE相当的可解释性。TopK语言模型在模型大小、计算效率和可解释性之间取得了良好平衡。尽管架构简单，TopK语言模型保持了原始能力，同时提供了稳健的可解释性优势。实验表明，TopK语言模型学习的稀疏表示能够通过定向神经元干预成功引导，并支持跨检查点和层的神经元形成过程详细分析。这些特性使TopK语言模型成为理解和研究语言模型如何学习和表示概念的稳定可靠工具，有望显著推动未来模型可解释性和可控性的研究。

</details>


### [34] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
**中文标题：连接离线和在线强化学习用于大语言模型**

*Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov*

主要分类: cs.CL

摘要简述: 本文研究了离线到半在线再到完全在线强化学习方法在微调大语言模型中的效果，发现在线和半在线方法表现相似且优于离线方法，同时多任务学习能提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 探讨强化学习方法在微调大语言模型时的有效性，尤其是在从离线到半在线再到完全在线过渡的场景下，针对可验证和不可验证任务的表现。

研究方法: 通过实验比较在线和半在线直接偏好优化与群体奖励策略优化目标，分析训练动态和超参数选择策略，并研究多任务学习对性能的影响。

研究结果: 在线和半在线方法表现相似且显著优于离线方法，多任务学习可同时提升可验证和不可验证任务的性能。

研究结论: 在线和半在线强化学习方法在微调大语言模型中表现优异，多任务学习能进一步提升性能，为实际应用提供了有效策略。

中文摘要: 我们研究了强化学习方法在微调大语言模型时的有效性，尤其是在从离线到半在线再到完全在线过渡的场景下，针对可验证（如数学）和不可验证（如指令跟随）任务。实验比较了在线和半在线直接偏好优化与群体奖励策略优化目标，发现这些方法表现相似且显著优于离线方法。我们还详细分析了训练动态和超参数选择策略以实现最佳结果。最后，研究表明结合可验证和不可验证奖励的多任务学习能同时提升两类任务的性能。

</details>


### [35] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
**中文标题：通过交互式LLM对齐提升社交驱动对话中的用户参与度**

*Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li*

主要分类: cs.CL

摘要简述: 本文提出一种通过交互式大语言模型（LLM）对齐来提升社交驱动对话中用户参与度的方法，利用用户反应作为奖励信号，并通过i×MCTS和直接偏好优化（DPO）实现模型对齐。实验表明该方法在情感支持和说服对话中有效提升了用户参与度。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究虽然优化了模型在知识推理或对话行为规划上的能力，但未能明确保证社交驱动对话中的用户参与度。因此，本文旨在通过交互式LLM学习用户参与度，以更直接的用户反应信号作为奖励，提升对话体验。

研究方法: 方法包括：1）利用用户模拟器与目标交互式LLM互动；2）通过i×MCTS（交互式蒙特卡洛树搜索）探索用户与系统的交互；3）收集高低质量对话数据，并通过直接偏好优化（DPO）对齐LLM以提升用户参与度。

研究结果: 在情感支持和说服对话两种社交驱动场景下的实验表明，该方法显著提升了交互式LLM的用户参与度。

研究结论: 本文通过交互式LLM对齐和直接偏好优化，成功提升了社交驱动对话中的用户参与度，为未来研究提供了新思路。

中文摘要: 在社交驱动对话中，通过交互提升用户参与度至关重要。尽管先前研究优化了模型在相关知识推理或对话行为规划上的能力，但用户参与度与知识或对话行为之间的关系微妙，且无法保证社交驱动对话中的用户参与度。为此，我们通过利用对话未来发展的信号，使交互式大语言模型（LLM）学习用户参与度。具体而言，我们采用更直接且相关的用户参与度指标（即用户对对话意图的反应）作为奖励，对齐交互式LLM。为实现这一目标，我们开发了一个用户模拟器与目标交互式LLM互动，并通过i×MCTS（交互式蒙特卡洛树搜索）探索用户与系统的交互。通过这种方式，我们收集了包含高低质量对话体验的数据集，并利用直接偏好优化（DPO）对齐交互式LLM以提升用户参与度。在情感支持对话和说服对话两种社交驱动场景下的实验表明，我们的方法有效提升了交互式LLM的用户参与度。

</details>


### [36] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
**中文标题：skLEP：斯洛伐克通用语言理解基准**

*Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko*

主要分类: cs.CL

摘要简述: 本文介绍了skLEP，这是首个专为评估斯洛伐克自然语言理解（NLU）模型设计的综合基准，包含九项多样化任务，并提供了数据集、工具包和公开排行榜。


<details>
  <summary>详细信息</summary>
研究动机: 斯洛伐克语在自然语言理解领域缺乏专门的评估基准，因此作者开发了skLEP，旨在填补这一空白并推动相关研究。

研究方法: 作者通过整理新的斯洛伐克语数据集和翻译已有的英语NLU资源，构建了skLEP基准，并评估了多种预训练语言模型。

研究结果: skLEP基准成功评估了多种斯洛伐克语、多语言和英语预训练模型，并公开了数据集、工具包和排行榜。

研究结论: skLEP为斯洛伐克语NLU研究提供了重要工具，促进了该领域的可重复性和未来发展。

中文摘要: 本文介绍了skLEP，这是首个专为评估斯洛伐克自然语言理解（NLU）模型设计的综合基准。skLEP包含九项多样化任务，涵盖词级、句对级和文档级挑战，全面评估模型能力。为构建此基准，我们整理了新的斯洛伐克语原创数据集，并精心翻译了已有的英语NLU资源。此外，本文还首次对多种斯洛伐克语专用、多语言及英语预训练语言模型进行了系统且广泛的评估。最后，我们公开了完整的基准数据、开源工具包（支持模型微调和评估）以及公开排行榜（https://github.com/slovak-nlp/sklep），以期促进可重复性并推动斯洛伐克NLU的未来研究。

</details>


### [37] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
**中文标题：大型语言模型中的波将金理解**

*Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan*

主要分类: cs.CL

摘要简述: 本文探讨大型语言模型（LLMs）在基准测试中的表现是否真实反映其理解能力，提出“波将金理解”概念，即模型通过非人类方式回答问题制造的理解假象，并通过实验证明这种现象普遍存在。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估LLMs能力的基准测试（如AP考试）与人类测试相同，但若模型的理解方式与人类不同，则测试结果可能仅反映虚假理解。本文旨在验证这种“波将金理解”现象的存在及其普遍性。

研究方法: 提出两种量化“波将金理解”的方法：一是在三个领域设计专门基准测试，二是通过通用方法提供其普遍性的下限估计。

研究结果: 实验发现“波将金理解”现象在模型、任务和领域中普遍存在，且这种失败不仅源于错误理解，还反映了概念表征的内部不一致性。

研究结论: 基准测试可能无法真实反映LLMs的理解能力，因其可能通过非人类方式制造理解假象，需重新审视评估方法。

中文摘要: 大型语言模型（LLMs）通常通过基准数据集进行评估。但凭什么根据其对一组精选问题的回答来推断其能力？本文首先引入一个正式框架以解决这一问题。关键在于注意到用于测试LLMs的基准（如AP考试）同样用于测试人类。然而，这意味着这些基准仅在LLMs以与人类相似的方式误解概念时有效。否则，基准测试的成功仅展示了“波将金理解”：一种由与人类解释概念方式不符的答案驱动的理解假象。我们提出了两种量化“波将金理解”存在的方法：一种是在三个领域设计专门基准，另一种是通过通用程序提供其普遍性的下限估计。我们发现“波将金理解”在模型、任务和领域中普遍存在，且这些失败不仅反映错误理解，还揭示了概念表征的深层内部不一致性。

</details>


### [38] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
**中文标题：“医生，怎么了？”：分析用户如何在大规模对话AI数据集中寻求健康信息**

*Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal*

主要分类: cs.CL

摘要简述: 本文通过分析大规模对话AI数据集HealthChat-11K，研究了用户如何通过大型语言模型（LLMs）获取健康信息，揭示了用户行为的常见模式及潜在风险，强调了改进LLM在医疗支持能力上的必要性。


<details>
  <summary>详细信息</summary>
研究动机: 随着用户越来越多地通过交互式聊天机器人从大型语言模型（LLMs）获取健康信息，这些对话的性质和潜在风险尚未得到充分研究。本文旨在填补这一空白，系统分析用户行为及其对LLMs的需求。

研究方法: 研究通过筛选大规模对话AI数据集，构建了HealthChat-11K（包含11K真实对话和25K用户消息），并基于临床医生驱动的分类法，分析了21个不同健康领域的用户交互行为。

研究结果: 分析揭示了用户获取健康信息的常见模式、上下文不完整的情况、情感行为以及可能引发迎合行为的交互（如引导性问题），凸显了LLMs在医疗支持能力上的不足。

研究结论: 研究表明，用户通过LLMs获取健康信息的行为存在多种问题，需进一步改进LLMs的医疗支持能力，以提供更准确和安全的服务。

中文摘要: 人们越来越多地通过交互式聊天机器人从大型语言模型（LLMs）获取健康信息，但这些对话的性质和潜在风险尚未得到充分研究。本文通过筛选大规模对话AI数据集，构建了HealthChat-11K，这是一个包含11K真实对话和25K用户消息的精选数据集。我们利用HealthChat-11K和临床医生驱动的分类法，系统研究了用户在21个不同健康领域中与LLMs的交互行为。分析揭示了用户获取健康信息的方式和原因，如常见交互、上下文不完整的情况、情感行为以及可能引发迎合行为的交互（如引导性问题），强调了改进LLMs作为对话AI的医疗支持能力的必要性。代码和相关资源可在以下链接获取：https://github.com/yahskapar/HealthChat

</details>


### [39] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
**中文标题：语言模型训练中的数据效能**

*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

主要分类: cs.CL

摘要简述: 本文提出数据效能（Data Efficacy）概念，通过优化训练数据的组织提升语言模型性能，并设计DELT范式（包括数据评分、选择和排序），实验证明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究多关注数据效率（Data Efficiency），即通过筛选最小或最优数据子集提升性能，而数据组织方式（Data Efficacy）的作用尚未充分探索。本文旨在填补这一空白。

研究方法: 提出DELT范式，包含数据评分（如LQS，从梯度一致性角度评估数据可学习性和质量）、数据选择和排序（如FO，解决模型遗忘和数据分布偏差问题）。

研究结果: 实验表明：1) DELT在不增加数据量和模型规模的情况下提升性能；2) LQS与FO组合效果最佳；3) 数据效能与数据效率可协同实现。

研究结论: 数据效能是语言模型训练中具有潜力的基础研究方向，DELT为优化数据组织提供了通用框架。

中文摘要: 数据是语言模型（LM）训练的基础。近期研究专注于数据效率，旨在通过选择最小或最优训练数据子集最大化性能，其中数据过滤、采样和选择等技术至关重要。作为补充，我们定义了数据效能（Data Efficacy），其目标是通过优化训练数据的组织来最大化性能，目前研究较少。本文提出通用范式DELT，用于在LM训练中考虑数据效能，强调训练数据组织的重要性。DELT包含三个组件：数据评分、数据选择和排序。其中，我们设计了可学习性-质量评分（LQS）作为数据评分的新实例，从梯度一致性角度评估数据的可学习性和质量；还设计了折叠排序（FO）作为数据排序的新实例，解决模型遗忘和数据分布偏差等问题。综合实验验证了数据效能在LM训练中的价值：首先，DELT的多种实例在不增加数据规模和模型大小的情况下不同程度提升了LM性能；其次，LQS与FO的组合效果最显著；最后，通过数据选择可同时实现数据效能与效率。因此，我们认为数据效能是LM训练中极具潜力的基础研究方向。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport](https://arxiv.org/abs/2506.20741)
**中文标题：OTSurv：一种基于异质性感知最优传输的新型多实例学习生存预测框架**

*Qin Ren,Yifan Wang,Ruogu Fang,Haibin Ling,Chenyu You*

主要分类: cs.CV

摘要简述: 本文提出了一种名为OTSurv的新型多实例学习框架，通过最优传输方法解决全切片图像（WSI）生存预测中的病理异质性问题，显著提升了预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有多实例学习方法在全切片图像生存预测中难以显式捕捉病理异质性，包括全局的长尾形态分布和局部的切片级预测不确定性。最优传输方法为解决这一问题提供了理论支持。

研究方法: OTSurv将生存预测建模为异质性感知的最优传输问题，引入全局长尾约束和局部不确定性约束，并通过不平衡最优传输公式高效求解。

研究结果: 在六个流行基准测试中，OTSurv取得了新的最佳性能，平均C-index绝对提升3.6%，并在对数秩检验中表现出统计显著性。

研究结论: OTSurv不仅显著提升了生存预测性能，还具有高可解释性，是数字病理学中生存预测的强大工具。

中文摘要: 利用全切片图像（WSI）进行生存预测可以建模为多实例学习（MIL）问题。然而，现有MIL方法通常无法显式捕捉WSI中的病理异质性，包括全局的长尾形态分布和局部的切片级预测不确定性。最优传输（OT）通过引入边缘分布约束，为建模此类异质性提供了理论支持。基于此，我们提出OTSurv，一种从最优传输角度出发的新型MIL框架。具体而言，OTSurv将生存预测建模为异质性感知的OT问题，包含两个约束：（1）全局长尾约束，通过调节传输质量分配来避免模式崩溃和过度均匀化；（2）局部不确定性感知约束，通过逐步增加总传输质量来优先处理高置信度切片并抑制噪声。随后，我们将初始OT问题转化为不平衡OT公式，并通过高效的硬件友好矩阵缩放算法求解。实验表明，OTSurv在六个流行基准测试中取得了新的最佳性能，平均C-index绝对提升3.6%。此外，OTSurv在对数秩检验中表现出统计显著性，并具有高可解释性，成为数字病理学中生存预测的强大工具。代码发布于https://github.com/Y-Research-SBU/OTSurv。

</details>


### [41] [StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation](https://arxiv.org/abs/2506.20756)
**中文标题：StereoDiff：立体匹配与扩散协同的视频深度估计**

*Haodong Li,Chen Wang,Jiahui Lei,Kostas Daniilidis,Lingjie Liu*

主要分类: cs.CV

摘要简述: 本文提出StereoDiff，一种结合立体匹配和视频深度扩散的两阶段视频深度估计方法，通过互补优势提升静态和动态区域的深度一致性。


<details>
  <summary>详细信息</summary>
研究动机: 视频深度估计并非图像深度估计的简单扩展，静态和动态区域的时序一致性需求不同。静态区域（如背景）可通过立体匹配获得全局3D线索，而动态区域需依赖大规模视频深度数据学习平滑过渡。

研究方法: StereoDiff采用两阶段方法：1）利用立体匹配处理静态区域；2）通过视频深度扩散模型学习动态区域的平滑过渡。通过频域分析证明两者的互补性。

研究结果: 在零样本、真实世界动态视频深度基准测试中，StereoDiff在室内外场景均表现出色，实现了最先进的性能和更高的深度一致性。

研究结论: StereoDiff通过立体匹配和视频深度扩散的协同作用，显著提升了视频深度估计的准确性和一致性，为动态和静态区域提供了互补的解决方案。

中文摘要: 近期视频深度估计方法通过遵循图像深度估计的范式（通常基于预训练视频扩散模型和大规模数据微调）取得了显著性能。然而，我们认为视频深度估计并非图像深度估计的简单扩展。视频中动态和静态区域的时序一致性需求存在根本差异。静态区域（如背景）的深度一致性可通过跨帧立体匹配更有效地实现，其提供更强的全局3D线索；而动态区域的平滑过渡仍需依赖大规模视频深度数据学习，因其违反三角测量约束。基于此，我们提出StereoDiff，一种两阶段视频深度估计器，通过立体匹配处理静态区域，结合视频深度扩散模型保持动态区域的深度过渡一致性。通过频域分析，我们数学证明了立体匹配与视频深度扩散的互补优势，突显了二者协同的效能。在零样本、真实世界动态视频深度基准测试（包括室内外场景）中，StereoDiff展示了最先进的性能，证明了其在视频深度估计中的卓越一致性和准确性。

</details>


### [42] [ConViTac: Aligning Visual-Tactile Fusion with Contrastive Representations](https://arxiv.org/abs/2506.20757)
**中文标题：ConViTac：基于对比表示的视觉-触觉融合对齐**

*Zhiyuan Wu,Yongqiang Zhao,Shan Luo*

主要分类: cs.CV

摘要简述: ConViTac通过对比表示学习提升视觉-触觉特征融合的协同性，显著提高了下游任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉和触觉是机器人感知和操作任务中互补的感官模态，但现有方法在特征融合时往往效果不佳。本文旨在通过对比表示学习提升视觉-触觉特征的融合质量。

研究方法: 提出ConViTac网络，采用对比嵌入条件化（CEC）机制，通过自监督对比学习预训练的编码器将视觉和触觉输入投影到统一的潜在嵌入空间，并通过跨模态注意力实现特征融合。

研究结果: 实验表明，ConViTac在材料分类和抓取预测任务中比现有方法性能提升高达12.0%。

研究结论: ConViTac通过对比表示学习显著提升了视觉-触觉特征的融合效果，为机器人感知任务提供了更优的解决方案。

中文摘要: 视觉和触觉是机器人感知和操作任务中的两种基本感官模态，提供了互补的信息以增强感知能力。以往的研究尝试联合学习视觉-触觉表示以提取更有意义的信息，但这些方法通常依赖于直接组合（如特征相加或拼接）进行模态融合，导致特征整合效果不佳。本文提出ConViTac，一种视觉-触觉表示学习网络，旨在通过对比表示提升特征融合的协同性。我们的核心贡献是对比嵌入条件化（CEC）机制，利用自监督对比学习预训练的对比编码器将视觉和触觉输入投影到统一的潜在嵌入空间，并通过跨模态注意力实现视觉-触觉特征的耦合融合，以对齐统一表示并提升下游任务性能。通过大量实验，我们证明了ConViTac在现实任务中优于当前最先进方法，且所提出的CEC机制在材料分类和抓取预测任务中将准确率提升了高达12.0%。

</details>


### [43] [AI-Driven MRI-based Brain Tumour Segmentation Benchmarking](https://arxiv.org/abs/2506.20786)
**中文标题：基于AI驱动的MRI脑肿瘤分割基准测试**

*Connor Ludwig,Khashayar Namdar,Farzad Khalvati*

主要分类: cs.CV

摘要简述: 本研究比较了多种AI模型（如SAM、SAM 2、MedSAM、SAM-Med-3D和nnU-Net）在BraTS 2023数据集上的脑肿瘤分割性能，发现SAM和SAM 2在精确边界框提示下表现优异，但nnU-Net仍是最佳选择。微调后点提示性能提升显著，但仍不及边界框或nnU-Net。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，尽管出现了许多可提示的通用模型及其医学变体，但缺乏对这些模型在不同提示质量下的评估和比较。本研究旨在填补这一空白，通过对比多种模型在脑肿瘤分割任务中的表现。

研究方法: 研究使用SAM、SAM 2、MedSAM、SAM-Med-3D和nnU-Net模型，在BraTS 2023成人胶质瘤和儿科数据集上进行零样本推理，测试不同提示质量（点和边界框）的效果。随后对部分模型进行微调，进一步评估性能。

研究结果: SAM和SAM 2在精确边界框提示下表现最佳，Dice分数分别达到0.894和0.893，超过nnU-Net。但nnU-Net仍因无需高精度提示而占据优势。微调后点提示性能显著提升，但仍未超越边界框或nnU-Net。

研究结论: 尽管SAM系列模型在精确提示下表现优异，但nnU-Net仍是医学图像分割的首选。微调点提示性能的提升为未来研究提供了方向，但实际应用中仍需依赖边界框或nnU-Net。

中文摘要: 医学图像分割极大地辅助了医学诊断，其中基于U-Net的架构和nnU-Net提供了最先进的性能。近年来出现了许多通用可提示模型及其医学变体，但目前缺乏对这些模型在统一医学数据集上不同提示质量下的评估和比较。本研究使用Segment Anything Model（SAM）、Segment Anything Model 2（SAM 2）、MedSAM、SAM-Med-3D和nnU-Net，在BraTS 2023成人胶质瘤和儿科数据集上进行了零样本推理，测试了点和边界框的多种提示质量。其中部分模型表现出色，尤其是SAM和SAM 2在极精确边界框提示下的Dice分数分别达到0.894和0.893，超过了nnU-Net的分割性能。然而，由于提供高精度提示的不切实际性，nnU-Net仍是医学图像分割的主导网络。研究还通过微调SAM、SAM 2、MedSAM和SAM-Med-3D在儿科数据集上扩展了模型和提示的评估与比较。微调后点提示性能的显著提升为未来研究提供了希望，但仍无法超越边界框或nnU-Net的分割效果。

</details>


### [44] [How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?](https://arxiv.org/abs/2506.20795)
**中文标题：基础模型与基于骨架的方法在人机交互手势识别中的比较**

*Stephanie Käs,Anton Burenko,Louis Markert,Onur Alp Culha,Dennis Mack,Timm Linder,Bastian Leibe*

主要分类: cs.CV

摘要简述: 本文比较了基础模型与基于骨架的方法在机器人交互中手势识别的表现，发现基于骨架的HD-GCN表现最佳，但视觉基础模型V-JEPA接近其性能，为简化系统复杂度提供了可能。


<details>
  <summary>详细信息</summary>
研究动机: 手势在嘈杂环境中（如敏捷生产）是实现非语言人机交互的重要方式。传统深度学习依赖任务专用架构，而视觉基础模型（VFMs）和视觉语言模型（VLMs）因其强泛化能力可能替代专用模块，降低系统复杂度。本研究旨在探索这些模型在动态全身手势识别中的潜力。

研究方法: 研究比较了V-JEPA（先进的VFM）、Gemini Flash 2.0（多模态VLM）和HD-GCN（基于骨架的方法）在手势识别中的表现。使用专为人机交互设计的NUGGET数据集进行评估。

研究结果: HD-GCN表现最佳，但V-JEPA通过简单任务专用分类头接近其性能，为多任务共享模型提供了可能。Gemini在零样本设置中难以区分手势，表明需进一步研究输入表示。

研究结论: 基础模型在手势识别中展现出潜力，尤其是V-JEPA，可作为简化系统的共享模型。未来需优化输入表示以提升多模态模型的性能。

中文摘要: 手势在嘈杂环境（如敏捷生产）中实现了非语言人机交互。传统基于深度学习的手势识别依赖任务专用架构，使用图像、视频或骨架姿态估计作为输入。而视觉基础模型（VFMs）和视觉语言模型（VLMs）凭借其强大的泛化能力，有望通过替代专用模块降低系统复杂度。本研究探讨了这些模型在动态全身手势识别中的应用，比较了V-JEPA（先进的VFM）、Gemini Flash 2.0（多模态VLM）和HD-GCN（基于骨架的方法）。我们引入了专为物流环境人机交互设计的NUGGET数据集进行评估。实验表明，HD-GCN表现最佳，但V-JEPA通过简单任务专用分类头接近其性能，为共享多任务模型提供了可能。相比之下，Gemini在零样本设置中难以基于文本描述区分手势，凸显了对手势输入表示进一步研究的必要性。

</details>


### [45] [Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models](https://arxiv.org/abs/2506.20832)
**中文标题：利用视觉语言模型选择扩散模型生成的可信超分辨率样本**

*Cansu Korkmaz,Ahmet Murat Tekalp,Zafer Dogan*

主要分类: cs.CV

摘要简述: 本文提出一种利用视觉语言模型（VLM）从扩散模型生成的高分辨率图像中选择最可信样本的自动化框架，通过语义推理和混合信任度评分（TWS）提升超分辨率图像的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 超分辨率（SR）是一个病态逆问题，传统回归模型在保真度和感知质量之间难以平衡，而扩散模型生成的多样SR图像缺乏可信样本选择方法。本文旨在解决这一问题，通过VLM的语义推理能力选择最可信的SR样本。

研究方法: 利用BLIP-2、GPT-4o等视觉语言模型（VLM）通过结构化查询评估SR图像的语义正确性、视觉质量和伪影情况，并通过混合信任度评分（TWS）量化SR可靠性，结合CLIP嵌入的语义相似性、边缘图SSIM的结构完整性和多级小波分解的伪影敏感性。

研究结果: 实验表明，TWS与人类偏好高度相关，VLM引导的选择始终获得高TWS值，优于传统指标如PSNR和LPIPS，为扩散SR空间的不确定性提供了可扩展且通用的解决方案。

研究结论: 本文通过VLM和TWS的结合，为生成式超分辨率设定了新的可信度基准，其输出与人类期望和语义正确性高度一致。

中文摘要: 超分辨率（SR）是一个病态逆问题，对于给定的低分辨率图像存在多个可行解。一方面，回归SR模型试图在保真度和感知质量之间平衡以生成单一解，但这种权衡常引入伪影，导致在数字或字母识别等信息关键应用中产生模糊性。另一方面，扩散模型生成多样化的SR图像，但从中选择最可信的解仍具挑战性。本文提出一种鲁棒的自动化框架，利用视觉语言模型（VLM）的语义推理能力从扩散生成的集合中识别最可信的SR样本。具体而言，通过结构化查询提示BLIP-2、GPT-4o等VLM评估语义正确性、视觉质量和伪影存在性，并集成排名靠前的SR候选以低成本生成单一可信输出。为严格评估VLM选择样本的有效性，我们提出一种新颖的信任度评分（TWS），这是一种混合指标，通过CLIP嵌入的语义相似性、边缘图SSIM的结构完整性和多级小波分解的伪影敏感性量化SR可靠性。实验表明，TWS在模糊和自然图像中均与人类偏好高度相关，且VLM引导的选择始终获得高TWS值。与传统指标如PSNR、LPIPS（无法反映信息保真度）相比，我们的方法为导航扩散SR空间的不确定性提供了原则性、可扩展且通用的解决方案。通过使输出与人类期望和语义正确性一致，本研究为生成式SR的可信度设定了新基准。

</details>


### [46] [FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization](https://arxiv.org/abs/2506.20841)
**中文标题：FixCLR：用于半监督领域泛化的负类对比学习**

*Ha Min Son,Shahbaz Rezaei,Xin Liu*

主要分类: cs.CV

摘要简述: FixCLR是一种半监督领域泛化方法，通过负类对比学习实现显式领域不变性正则化，可与其他半监督方法结合提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 半监督领域泛化（SSDG）在标签稀缺的情况下难以泛化到分布外数据，现有方法未显式学习领域不变表示。FixCLR旨在通过对比学习解决这一问题。

研究方法: FixCLR利用伪标签的类别信息，仅使用排斥项进行对比学习，显式正则化领域不变表示，并可与其他半监督方法结合使用。

研究结果: FixCLR在多种实验中表现优异，包括与其他半监督方法的结合、预训练与非预训练模型的比较，以及多领域数据集的测试。

研究结论: FixCLR是一种有效的SSDG方法，尤其在与其他半监督方法结合时性能更优。

中文摘要: 半监督领域泛化（SSDG）旨在解决在仅有少量标签可用时泛化到分布外数据的问题。由于标签稀缺，传统的领域泛化方法表现不佳。现有的SSDG方法将半监督学习与各种正则化项结合，但未显式正则化学习所有领域的领域不变表示，而这正是领域泛化的关键目标。为此，我们提出了FixCLR。受自监督学习成功的启发，我们调整了两个关键组件以适应对比学习以实现显式领域不变性正则化：利用伪标签的类别信息，并仅使用排斥项。FixCLR还可与大多数现有SSDG和半监督方法结合，以补充性能提升。我们的研究包括广泛的实验，这些实验在SSDG研究中尚未被探索，包括对不同半监督方法改进的基准测试、预训练与非预训练模型的性能评估，以及多领域数据集的测试。总体而言，FixCLR被证明是一种有效的SSDG方法，尤其是与其他半监督方法结合时。

</details>


### [47] [Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision](https://arxiv.org/abs/2506.20850)
**中文标题：医学视觉中像素级预训练的向量对比学习方法**

*Yuting He,Shuo Li*

主要分类: cs.CV

摘要简述: 论文提出了一种向量对比学习方法（COVER），用于医学视觉中的像素级预训练，解决了传统对比学习在像素级特征相关性上的不足，显著提升了自监督预训练的效果。


<details>
  <summary>详细信息</summary>
研究动机: 传统对比学习（CL）在自监督预训练（SSP）中表现优异，但在像素级表示上存在特征过度分散问题，破坏了像素级特征相关性。医学视觉领域亟需一种能够保留像素级特征相关性的预训练方法。

研究方法: 论文将对比学习重新定义为向量回归问题，提出了COVER框架。该框架通过建模特征距离来量化像素级预训练中的特征分散，采用向量金字塔架构适应不同粒度，并保持从向量回归到距离建模的优化流程一致性。

研究结果: 在8个任务（涵盖2种维度和4种模态）上的实验表明，COVER显著提升了像素级自监督预训练的效果，为通用医学视觉基础模型提供了支持。

研究结论: 向量对比学习方法（COVER）有效解决了像素级预训练中的特征分散问题，保留了像素级特征相关性，为医学视觉领域的自监督预训练提供了新思路。

中文摘要: 对比学习（CL）已成为基础模型中自监督预训练（SSP）的基石，但将其扩展到对医学视觉至关重要的像素级表示仍是一个未解决的问题。标准CL将SSP表述为一个二元优化问题（二元CL），其中对特征分散的过度追求导致了过度分散问题，破坏了像素级特征相关性，从而扰乱了类内分布。我们的向量CL将CL重新表述为一个向量回归问题，通过建模特征距离来回归位移向量，实现了像素级预训练中的分散量化。为实现这一新范式，我们提出了基于向量回归的对比框架（COVER）。COVER建立了一个可扩展的基于向量的自学习机制，强制执行从向量回归到距离建模的一致优化流程，并利用向量金字塔架构进行粒度适应，从而在SSP中保留像素级特征相关性。在涵盖2种维度和4种模态的8个任务上的大量实验表明，COVER显著提升了像素级SSP，推动了通用医学视觉基础模型的进步。

</details>


### [48] [Enhancing Ambiguous Dynamic Facial Expression Recognition with Soft Label-based Data Augmentation](https://arxiv.org/abs/2506.20867)
**中文标题：基于软标签数据增强的动态模糊面部表情识别优化**

*Ryosuke Kawamura,Hideaki Hayashi,Shunsuke Otake,Noriko Takemura,Hajime Nagahara*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MIDAS的数据增强方法，通过软标签增强动态面部表情识别（DFER）中模糊表情的处理能力，实验证明其在DFEW和FERV39k-Plus数据集上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 动态面部表情识别（DFER）在实际应用中常遇到模糊表情的挑战，现有方法难以准确识别。本文旨在通过数据增强技术提升模型对模糊表情的处理能力。

研究方法: 提出MIDAS方法，利用软标签（多情感类别的概率表示）对视频帧及其情感标签进行凸组合，扩展了mixup方法以处理软标签视频数据。

研究结果: 在DFEW和FERV39k-Plus数据集上的实验表明，使用MIDAS增强数据训练的模型性能优于现有方法。

研究结论: MIDAS通过软标签数据增强显著提升了DFER中模糊表情的识别性能，是一种简单而高效的方法。

中文摘要: 动态面部表情识别（DFER）是通过面部表情视频序列估计情感的任务。在实际应用中，准确识别模糊表情（常见于自然场景数据）至关重要。本研究提出MIDAS，一种数据增强方法，利用代表多情感类别概率的软标签来提升DFER对模糊表情数据的性能。MIDAS通过凸组合视频帧及其对应情感标签来增强训练数据，将mixup方法扩展至软标签视频数据，为处理DFER中的模糊性提供了一种简单而高效的方法。为评估MIDAS，我们在DFEW数据集和新构建的FERV39k-Plus数据集（为现有DFER数据集分配软标签）上进行了实验。结果表明，使用MIDAS增强数据训练的模型性能优于基于原始数据集的最先进方法。

</details>


### [49] [THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion](https://arxiv.org/abs/2506.20877)
**中文标题：THIRDEYE：基于大脑启发的多阶段融合的线索感知单目深度估计**

*Calin Teodor Ioan*

主要分类: cs.CV

摘要简述: THIRDEYE提出了一种基于多阶段融合的单目深度估计方法，通过预训练的专家网络显式提供视觉线索，并结合大脑皮层层级结构进行融合，生成高分辨率视差图。


<details>
  <summary>详细信息</summary>
研究动机: 传统单目深度估计方法通过RGB像素隐式学习深度信息，忽略了人类视觉系统依赖的显式线索（如遮挡边界、阴影和透视）。THIRDEYE旨在通过显式提供这些线索，提升深度估计的准确性和可靠性。

研究方法: THIRDEYE采用预训练且冻结的专家网络显式提供视觉线索，并通过三阶段皮层层级（V1→V2→V3）融合这些线索，结合键值工作记忆模块动态加权。最终通过自适应分箱变换器生成高分辨率视差图。

研究结果: 由于冻结了专家网络，THIRDEYE继承了大量外部监督信息，仅需少量微调即可实现高性能。具体量化结果将在后续版本中公布。

研究结论: THIRDEYE通过显式视觉线索和多阶段融合，显著提升了单目深度估计的性能，同时减少了训练成本。

中文摘要: 传统单目深度估计方法通过RGB像素隐式学习深度信息，往往忽略了人类视觉系统依赖的显式线索（如遮挡边界、阴影和透视）。THIRDEYE提出了一种线索感知的流程，通过预训练且冻结的专家网络显式提供这些线索，并在三阶段皮层层级（V1→V2→V3）中融合，结合键值工作记忆模块动态加权。最终通过自适应分箱变换器生成高分辨率视差图。由于专家网络被冻结，THIRDEYE继承了大量外部监督信息，仅需少量微调。本扩展版本提供了更多架构细节、神经科学动机和实验协议；量化结果将在后续版本中公布。

</details>


### [50] [MultiHuman-Testbench: Benchmarking Image Generation for Multiple Humans](https://arxiv.org/abs/2506.20879)
**中文标题：MultiHuman-Testbench：多人图像生成的基准测试**

*Shubhankar Borse,Seokeon Choi,Sunghyun Park,Jeongho Kim,Shreya Kadambi,Risheek Garrepalli,Sungrack Yun,Munawar Hayat,Fatih Porikli*

主要分类: cs.CV

摘要简述: 本文提出了MultiHuman-Testbench，一个用于评估多人生成图像模型的新基准，包含1800个样本和5550张独特人脸图像，通过多维度指标评估模型性能，并提出了改进身份相似性的新方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏专门用于评估多人生成图像模型的基准，导致生成复杂动作且保留面部身份的图像成为挑战。本文旨在填补这一空白，提供一个标准化工具以推动相关研究。

研究方法: 提出了MultiHuman-Testbench基准，包含1800个样本和5550张多样化的独特人脸图像，并设计了四类关键指标（人脸数量、身份相似性、提示对齐和动作检测）进行评估。此外，提出了基于人体分割和匈牙利匹配的新技术以提升身份相似性。

研究结果: 通过对多种模型（包括零样本方法和基于训练的方法）的全面评估，发现提出的基准和技术显著提高了身份相似性，为多人生成图像研究提供了标准化工具和关键见解。

研究结论: MultiHuman-Testbench为多人生成图像研究提供了重要基准和技术支持，显著提升了身份相似性，并为未来研究提供了标准化工具。

中文摘要: 生成包含多人且保留面部身份的复杂动作图像是一项重大挑战，主要原因之一是缺乏专门的基准。为此，我们提出了MultiHuman-Testbench，一个用于严格评估多人生成模型的新基准。该基准包含1800个样本，包括精心设计的文本提示，描述从简单到复杂的人类动作。这些提示与5550张独特的人脸图像匹配，确保在年龄、种族背景和性别上的多样性。除了文本提示，我们还提供了与提示准确匹配的人体姿势条件图像。我们提出了一个多维度评估套件，使用四类关键指标量化人脸数量、身份相似性、提示对齐和动作检测。我们对多种模型进行了全面评估，包括零样本方法和基于训练的方法，无论是否使用区域先验。此外，我们提出了基于人体分割和匈牙利匹配的新技术，显著提升了身份相似性。我们提出的基准和关键发现为多人图像生成研究提供了宝贵的见解和标准化工具。

</details>


### [51] [The Role of Cyclopean-Eye in Stereo Vision](https://arxiv.org/abs/2506.20900)
**中文标题：Cyclopean Eye在立体视觉中的作用**

*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

主要分类: cs.CV

摘要简述: 本文研究了现代立体视觉系统的几何基础，重点探讨了3D结构和人类感知如何提升深度重建的准确性。通过重新审视Cyclopean Eye模型并提出新的几何约束，结合深度学习特征匹配和注意力机制，展示了结合几何先验与学习特征的优势。


<details>
  <summary>详细信息</summary>
研究动机: 现代立体视觉系统在深度重建中面临遮挡和深度不连续性的挑战。本文旨在通过结合几何先验与深度学习特征，提升系统的鲁棒性和准确性。

研究方法: 重新审视Cyclopean Eye模型，提出新的几何约束以处理遮挡和深度不连续性。结合深度学习模型的特征匹配和注意力机制，评估特征匹配质量并恢复有意义的3D表面。

研究结果: 理论和实证研究表明，结合几何先验与学习特征能够为立体视觉系统提供更准确的深度重建和内部抽象理解。

研究结论: 几何先验与学习特征的结合为立体视觉系统提供了更强大的理论基础和实际应用潜力。

中文摘要: 本研究探讨了现代立体视觉系统的几何基础，重点关注3D结构和人类感知如何促进准确的深度重建。我们重新审视了Cyclopean Eye模型，并提出了新的几何约束以处理遮挡和深度不连续性。分析包括对深度学习模型衍生的立体特征匹配质量的评估，以及注意力机制在恢复有意义的3D表面中的作用。通过理论见解和真实数据集的实证研究，我们证明结合强几何先验与学习特征能够为理解立体视觉系统提供内部抽象。

</details>


### [52] [FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing](https://arxiv.org/abs/2506.20911)
**中文标题：FaSTA$^*$：基于子程序挖掘的快慢工具路径代理用于高效多轮图像编辑**

*Advait Gupta,Rishie Raj,Dang Nguyen,Tianyi Zhou*

主要分类: cs.CV

摘要简述: FaSTA$^*$是一种高效的神经符号代理，通过结合大语言模型（LLMs）的快速高级子任务规划和局部A$^*$搜索的慢速精确工具使用，实现多轮图像编辑任务的高效处理。通过提取和复用子程序，显著降低了相似子任务的探索成本。


<details>
  <summary>详细信息</summary>
研究动机: 多轮图像编辑任务（如检测并重新着色物体、移除干扰物等）通常需要复杂的工具调用序列，现有方法在计算效率上存在不足。FaSTA$^*$旨在通过结合快速规划和慢速搜索，以及子程序的复用，提高任务处理的效率和成本效益。

研究方法: FaSTA$^*$结合大语言模型（LLMs）的快速子任务规划和局部A$^*$搜索的慢速精确工具使用。通过归纳推理提取常用子程序，并将其作为新工具复用，实现自适应快慢规划。高级子程序优先尝试，失败时再触发低级的A$^*$搜索。

研究结果: 与现有图像编辑方法相比，FaSTA$^*$在计算效率上显著提升，同时保持了与最先进基线相当的成功率。

研究结论: FaSTA$^*$通过快慢规划和子程序复用，高效解决了多轮图像编辑任务，显著降低了计算成本，同时保持了高成功率。

中文摘要: 我们开发了一种成本效益高的神经符号代理FaSTA$^*$，用于处理具有挑战性的多轮图像编辑任务，例如“检测图像中的长椅并将其重新着色为粉色，同时移除猫以获得更清晰的视野，并将墙壁重新着色为黄色”。该方法将大语言模型（LLMs）的快速高级子任务规划与局部A$^*$搜索的慢速精确工具使用相结合，以找到成本效益高的工具路径——即对AI工具的一系列调用序列。为了节省A$^*$在相似子任务上的成本，我们通过LLMs对先前成功的工具路径进行归纳推理，持续提取/优化常用子程序，并将其作为新工具用于未来任务的自适应快慢规划中。高级子程序优先探索，仅在失败时触发低级的A$^*$搜索。这些可复用的符号子程序显著降低了在相似图像上应用相同类型子任务的探索成本，形成了一种类似人类的快慢工具路径代理“FaSTA$^*$”：首先由LLMs尝试快速子任务规划和基于规则的子程序选择，预计覆盖大多数任务；而慢速A$^*$搜索仅针对新颖和具有挑战性的子任务触发。通过与近期图像编辑方法的比较，我们证明FaSTA$^*$在计算效率上显著更高，同时在成功率上与最先进的基线方法保持竞争力。

</details>


### [53] [M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization](https://arxiv.org/abs/2506.20922)
**中文标题：M2SFormer：基于多频多尺度注意力与边缘感知难度引导的图像伪造定位方法**

*Ju-Hyeon Nam,Dong-Hyun Moon,Sang-Chul Lee*

主要分类: cs.CV

摘要简述: M2SFormer是一种基于Transformer编码器的新型框架，通过多频和多尺度注意力机制以及边缘感知难度引导，显著提升了图像伪造定位的准确性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着图像编辑技术的快速发展，恶意篡改数字图像的行为日益增多。现有的深度学习方法在像素级伪造定位中虽取得一定成果，但仍面临计算开销大、对复杂或细微篡改表现不佳的问题。

研究方法: M2SFormer在跳跃连接中统一了多频和多尺度注意力机制，利用全局上下文更好地捕捉伪造痕迹。同时，通过全局先验图和难度引导注意力模块，有效解决了上采样过程中细节丢失的问题。

研究结果: 在多个基准数据集上的实验表明，M2SFormer在检测和定位伪造区域方面优于现有最先进模型，尤其在跨域泛化能力上表现突出。

研究结论: M2SFormer通过创新的注意力机制和难度引导模块，显著提升了图像伪造定位的性能，为未来研究提供了新的方向。

中文摘要: 图像编辑技术的快速发展既推动了创新应用，也助长了数字图像的恶意篡改。近年来，基于深度学习的方法在像素级伪造定位方面取得了较高精度，但仍面临计算开销大和表征能力有限的问题，尤其是对细微或复杂篡改的处理。本文提出M2SFormer，一种基于Transformer编码器的新型框架，旨在解决这些挑战。与分别处理空间和频率线索的方法不同，M2SFormer在跳跃连接中统一了多频和多尺度注意力机制，利用全局上下文更好地捕捉多样化的伪造痕迹。此外，我们的框架通过全局先验图（一种指示伪造定位难度的曲率度量）解决了上采样过程中细节丢失的问题，并利用难度引导注意力模块更有效地保留细微篡改痕迹。在多个基准数据集上的广泛实验表明，M2SFormer优于现有最先进模型，在检测和定位跨域伪造方面表现出卓越的泛化能力。

</details>


### [54] [PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling](https://arxiv.org/abs/2506.20936)
**中文标题：PhysRig：基于可微分物理的蒙皮和绑定框架，用于真实关节物体建模**

*Hao Zhang,Haolan Xu,Chun Feng,Varun Jampani,Narendra Ahuja*

主要分类: cs.CV

摘要简述: 本文提出PhysRig，一种基于可微分物理的蒙皮和绑定框架，通过将刚性骨骼嵌入体积表示（如四面体网格）中，模拟为可变形软体结构，解决了传统线性混合蒙皮（LBS）的体积损失和非自然变形问题，并支持弹性材料建模。


<details>
  <summary>详细信息</summary>
研究动机: 传统线性混合蒙皮（LBS）虽简单且可微分，但存在体积损失和非自然变形问题，且无法建模弹性材料（如软组织、毛发等）。本文旨在通过物理模拟克服这些限制，实现更真实的关节物体建模。

研究方法: PhysRig将刚性骨骼嵌入体积表示（如四面体网格），模拟为可变形软体结构，利用连续介质力学和欧拉背景网格离散化物体为粒子，确保对材料属性和骨骼运动的可微分性。此外，引入材料原型以减少学习空间。

研究结果: 在合成数据集（Objaverse、The Amazing Animals Zoo、MixaMo）上，PhysRig显著优于传统LBS方法，生成更真实且物理合理的结果，并在姿态迁移任务中展示了其多功能性。

研究结论: PhysRig通过物理模拟解决了LBS的局限性，支持弹性材料建模，生成更真实的关节物体动画，适用于多种应用场景。

中文摘要: 蒙皮和绑定是动画、关节物体重建、运动迁移和4D生成的基础组件。现有方法主要依赖线性混合蒙皮（LBS），因其简单性和可微分性。然而，LBS会引入体积损失和非自然变形等问题，且无法建模弹性材料（如软组织、毛发和柔性附属物）。本文提出PhysRig：一种基于可微分物理的蒙皮和绑定框架，通过将刚性骨骼嵌入体积表示（如四面体网格）中，模拟为可变形软体结构，克服了这些限制。我们的方法利用连续介质力学，并将物体离散为嵌入欧拉背景网格的粒子，确保对材料属性和骨骼运动的可微分性。此外，引入材料原型，显著减少学习空间的同时保持高表现力。为评估框架，我们使用Objaverse、The Amazing Animals Zoo和MixaMo的网格构建了综合合成数据集，涵盖多种物体类别和运动模式。我们的方法始终优于传统LBS方法，生成更真实且物理合理的结果。此外，我们在姿态迁移任务中展示了框架的适用性，突显其在关节物体建模中的多功能性。

</details>


### [55] [AIR-VIEW: The Aviation Image Repository for Visibility Estimation of Weather, A Dataset and Benchmark](https://arxiv.org/abs/2506.20939)
**中文标题：AIR-VIEW：航空天气能见度估计的图像存储库，数据集与基准**

*Chad Mourning,Zhewei Wang,Justin Murray*

主要分类: cs.CV

摘要简述: 本文介绍了一个名为AIR-VIEW的新数据集，专为航空天气能见度估计设计，填补了公开数据集的空白，并提供了基准测试结果。


<details>
  <summary>详细信息</summary>
研究动机: 航空天气能见度估计研究中缺乏公开、大规模且多样化的数据集，本文旨在填补这一空白，为机器学习提供高质量的训练数据。

研究方法: 通过为期一年的FAA天气摄像头网络数据收集活动，构建了AIR-VIEW数据集，并采用三种常用方法和通用基线进行基准测试。

研究结果: AIR-VIEW数据集在基准测试中表现出色，与ASTM标准相比具有竞争力，为航空能见度估计提供了可靠的数据支持。

研究结论: AIR-VIEW数据集为航空天气能见度估计研究提供了重要资源，未来可进一步优化模型性能。

中文摘要: 航空天气的机器学习研究正在成为传统昂贵天气传感器的低成本替代方案；然而，在航空相关距离、多样化地点、足够规模的公开能见度估计数据集方面仍存在空白。本文介绍了一个新数据集，该数据集是历时一年的FAA天气摄像头网络图像收集活动的成果，适用于此目的。我们还提供了一个基准测试，应用了三种常用方法和通用基线，并在三个公开数据集及我们自己的数据集上进行了训练和测试，与最近批准的ASTM标准进行了对比。

</details>


### [56] [Hierarchical Sub-action Tree for Continuous Sign Language Recognition](https://arxiv.org/abs/2506.20947)
**中文标题：分层子动作树用于连续手语识别**

*Dejie Yang,Zhu Xu,Xinjie Gao,Yang Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为HST-CSLR的分层子动作树方法，通过结合大语言模型中的文本知识，优化连续手语识别中的视觉与文本模态对齐，并在四个数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 连续手语识别（CSLR）面临数据集不足和标注不精确的问题，现有方法未能充分利用文本知识。本文旨在通过结合文本模态的层次化表示，提升视觉与文本模态的对齐效果。

研究方法: 提出分层子动作树（HST），利用大语言模型提取文本特征，逐步对齐视觉与文本模态，并通过树结构降低计算复杂度。同时引入对比对齐增强机制，缩小模态间差距。

研究结果: 在PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture四个数据集上的实验表明，HST-CSLR方法显著提升了识别效果。

研究结论: HST-CSLR通过层次化文本表示和对比对齐增强，有效提升了连续手语识别的性能，为模态对齐提供了新思路。

中文摘要: 连续手语识别（CSLR）旨在将未剪辑的视频转录为文本单词（即手语词）。近期研究表明，由于训练数据不足，缺乏大规模数据集和精确标注已成为CSLR的瓶颈。为解决这一问题，一些研究提出了跨模态解决方案以对齐视觉与文本模态。然而，这些方法通常仅从手语词中提取文本特征，未能充分利用其知识。本文提出分层子动作树（HST），即HST-CSLR，以高效结合手语词知识与视觉表示学习。通过从大语言模型中提取手语词特定知识，我们的方法更有效地利用了文本信息。具体而言，我们构建了HST用于文本信息表示，逐步对齐视觉与文本模态，并利用树结构降低计算复杂度。此外，我们引入对比对齐增强机制以缩小模态间差距。在四个数据集（PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture）上的实验验证了HST-CSLR的有效性。

</details>


### [57] [OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs](https://arxiv.org/abs/2506.20960)
**中文标题：OmniEval：一个用于评估全模态模型的基准测试，涵盖视觉、听觉和文本输入**

*Yiman Zhang,Ziheng Luo,Qiangyu Yan,Wei He,Borui Jiang,Xinghao Chen,Kai Han*

主要分类: cs.CV

摘要简述: 本文介绍了OmniEval，一个用于评估全模态模型（如MiniCPM-O 2.6）的基准测试，涵盖视觉、听觉和文本输入。其特点包括全模态协作、多样化的视频和任务，以及细粒度的评估任务。实验表明，OmniEval为全模态模型的评估提供了全面平台。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试无法全面评估全模态模型的协作能力，因此作者提出OmniEval，旨在填补这一空白，通过多样化的任务和视频数据，评估模型在多模态环境下的表现。

研究方法: OmniEval设计了全模态协作任务，包含810个音视频同步视频（285中文、525英文）和2617个问答对（1412开放题、1205选择题），分为3大类任务和12子任务，并引入细粒度的视频定位任务Grounding。

研究结果: 实验表明，OmniEval能够有效评估全模态模型的协作能力，为模型在多模态环境下的表现提供了全面基准。

研究结论: OmniEval为全模态模型的评估提供了多样化、细粒度的平台，有助于推动多模态研究的发展。代码和数据已公开。

中文摘要: 本文介绍了OmniEval，一个用于评估全模态模型（如MiniCPM-O 2.6）的基准测试，涵盖视觉、听觉和文本输入。与现有基准相比，OmniEval具有以下特点：（1）全模态协作：设计了强调音视频强耦合的任务，要求模型有效利用多模态协作感知；（2）视频多样性：包含810个音视频同步视频（285中文、525英文）；（3）任务多样性与细粒度：包含2617个问答对（1412开放题、1205选择题），分为3大类任务和12子任务，并引入细粒度的视频定位任务Grounding。实验表明，OmniEval为全模态模型的评估提供了全面平台。代码和数据可在https://omnieval.github.io/获取。

</details>


### [58] [Evidence-based diagnostic reasoning with multi-agent copilot for human pathology](https://arxiv.org/abs/2506.20964)
**中文标题：基于证据的诊断推理与多智能体协同系统在人类病理学中的应用**

*Chengkuan Chen,Luca L. Weishaupt,Drew F. K. Williamson,Richard J. Chen,Tong Ding,Bowen Chen,Anurag Vaidya,Long Phi Le,Guillaume Jaume,Ming Y. Lu,Faisal Mahmood*

主要分类: cs.CV

摘要简述: 本文介绍了PathChat+，一种专为病理学设计的多模态大语言模型，通过百万级病理学指令样本训练，显著优于现有模型，并结合SlideSeek系统实现高精度自主诊断。


<details>
  <summary>详细信息</summary>
研究动机: 当前病理学领域的多模态大语言模型存在训练数据不足、多图像理解支持有限及缺乏自主诊断能力等问题，亟需一种更先进的解决方案。

研究方法: 提出PathChat+模型，基于超过100万病理学指令样本和550万问答对训练，并结合SlideSeek系统实现迭代式分层诊断推理。

研究结果: PathChat+在多个病理学基准测试中显著优于现有模型，SlideSeek系统在DDxBench上达到高精度，并能生成可视化报告。

研究结论: PathChat+和SlideSeek系统为病理学诊断提供了高效、自主的解决方案，推动了人工智能在病理学中的应用。

中文摘要: 病理学正经历由全切片成像和人工智能驱动的快速数字化转型。尽管基于深度学习的计算病理学已取得显著成功，但传统模型主要关注图像分析，未整合自然语言指令或丰富的文本上下文。当前计算病理学中的多模态大语言模型（MLLMs）存在训练数据不足、多图像理解支持有限及缺乏自主诊断推理能力等局限性。为解决这些问题，我们提出了PathChat+，一种专为人类病理学设计的新型MLLM，训练数据包括超过100万多样化的病理学指令样本和近550万问答对。在多个病理学基准测试中的广泛评估表明，PathChat+显著优于先前的PathChat协同系统，以及最先进的通用模型和其他病理学专用模型。此外，我们还展示了SlideSeek，一种基于PathChat+的推理多智能体AI系统，通过迭代式分层诊断推理自主评估千兆像素全切片图像（WSIs），在DDxBench这一具有挑战性的开放式鉴别诊断基准测试中达到高精度，同时能够生成可视化、易于人类理解的总结报告。

</details>


### [59] [DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing](https://arxiv.org/abs/2506.20967)
**中文标题：DFVEdit：基于条件增量流向量的零样本视频编辑**

*Lingling Cai,Kang Zhao,Hangjie Yuan,Xiang Wang,Yingya Zhang,Kejie Huang*

主要分类: cs.CV

摘要简述: DFVEdit是一种针对视频扩散变换器（Video DiTs）的高效零样本视频编辑方法，通过流变换直接操作潜在空间，无需注意力修改或微调，显著提升计算效率和编辑质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频编辑方法在应用于视频扩散变换器时，常因注意力修改或微调导致计算资源消耗过大。DFVEdit旨在解决这一问题，提供一种高效且无需修改模型结构的编辑方案。

研究方法: DFVEdit基于连续流视角统一编辑与采样，提出条件增量流向量（CDFV），并结合隐式交叉注意力（ICA）指导和嵌入增强（ER）技术，进一步提升编辑质量。

研究结果: 实验表明，DFVEdit在推理速度上比基于注意力工程的方法快20倍以上，内存占用减少85%，并在结构保真度、时空一致性和编辑质量上达到最优性能。

研究结论: DFVEdit为视频扩散变换器提供了一种高效、高质量的零样本编辑解决方案，显著提升了实际应用中的计算效率和编辑效果。

中文摘要: 视频扩散变换器（Video DiTs）的出现标志着视频生成领域的重要进展。然而，直接将现有视频编辑方法应用于Video DiTs通常会导致巨大的计算开销，这是由于资源密集的注意力修改或微调。为解决这一问题，我们提出了DFVEdit，一种专为Video DiTs设计的高效零样本视频编辑方法。DFVEdit通过流变换直接操作潜在空间，无需注意力修改或微调。具体而言，我们发现编辑与采样可以在连续流视角下统一。基于此，我们提出了条件增量流向量（CDFV）——DFV的理论无偏估计——并结合隐式交叉注意力（ICA）指导和嵌入增强（ER）技术，进一步提升编辑质量。DFVEdit在实际效率上表现出色，与基于注意力工程的编辑方法相比，推理速度提升至少20倍，内存占用减少85%。大量定量和定性实验表明，DFVEdit可无缝应用于主流Video DiTs（如CogVideoX和Wan2.1），在结构保真度、时空一致性和编辑质量上达到最优性能。

</details>


### [60] [From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan Face Aging](https://arxiv.org/abs/2506.20977)
**中文标题：从摇篮到拐杖：一种高保真全生命周期人脸老化的双阶段框架**

*Tao Liu,Dafeng Zhang,Gengchen Li,Shizhuo Liu,Yongqi Song,Senmao Li,Shiqi Yang,Boqian Li,Kai Wang,Yaxing Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Cradle2Cane的双阶段人脸老化框架，通过自适应噪声注入和身份感知嵌入技术，解决了年龄准确性与身份一致性之间的权衡问题，显著提升了老化效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸老化方法在年龄准确性与身份一致性之间存在难以平衡的问题，尤其是在处理大年龄跨度或极端头部姿态时表现不佳。本文旨在解决这一核心挑战。

研究方法: 提出了一种双阶段框架：第一阶段通过自适应噪声注入（AdaNI）机制实现年龄准确性；第二阶段利用身份感知嵌入（IDEmb）增强身份一致性，同时保持年龄特征。两阶段联合训练，端到端优化。

研究结果: 在CelebA-HQ测试数据集上的实验表明，Cradle2Cane在年龄准确性和身份一致性方面优于现有方法，Face++和Qwen-VL评估协议验证了其优越性。

研究结论: Cradle2Cane通过双阶段设计有效解决了年龄与身份之间的权衡问题，为高保真的人脸老化提供了新思路。

中文摘要: 人脸老化已成为计算机视觉领域的重要任务，应用范围涵盖娱乐到医疗。然而，现有方法难以实现全生命周期的真实无缝老化，尤其是在处理大年龄跨度或极端头部姿态时。核心挑战在于平衡年龄准确性与身份一致性（即Age-ID权衡）。大多数现有方法要么以牺牲身份一致性为代价优先年龄变换，反之亦然。本文提出了一种基于少步文本到图像（T2I）扩散模型的双阶段人脸老化框架Cradle2Cane。第一阶段通过自适应噪声注入（AdaNI）机制解决年龄准确性，该机制以年龄和性别的文本描述为条件，并通过调整噪声水平控制老化强度。此阶段对身份一致性的保护较弱，以支持更强的年龄变换。第二阶段通过两种身份感知嵌入（IDEmb）——SVR-ArcFace和Rotate-CLIP——增强身份一致性，同时保持年龄特征。此阶段对第一阶段生成的图像进行去噪，确保身份一致性不受老化准确性的影响。两阶段联合训练，端到端优化。在CelebA-HQ测试数据集上的大量实验表明，Cradle2Cane在Face++和Qwen-VL评估协议下，年龄准确性和身份一致性均优于现有方法。

</details>


### [61] [3D Scene-Camera Representation with Joint Camera Photometric Optimization](https://arxiv.org/abs/2506.20979)
**中文标题：联合相机光度优化的3D场景-相机表示**

*Weichen Dai,Kangcheng Ma,Jiaxin Wang,Kecen Pan,Yuhang Ming,Hua Zhang,Wanzeng Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种联合相机光度优化的3D场景-相机表示方法，通过引入完整的光度模型和深度正则化，有效分离场景无关信息，提升3D场景表示质量。


<details>
  <summary>详细信息</summary>
研究动机: 多视角图像中的光度失真会降低图像质量，进而影响3D场景表示的准确性。现有方法未充分考虑相机成像的光度失真，导致场景表示中可能包含无关信息。本文旨在通过联合优化相机光度参数，解决这一问题。

研究方法: 提出了一种包含内外光度模型的完整光度模型，并基于此构建相机表示。通过同时优化相机表示参数和引入深度正则化，分离场景无关信息，并将相机模型作为映射过程的一部分，构建包含场景辐射场和相机光度模型的完整映射。

研究结果: 实验结果表明，即使在晕影和污垢等成像退化条件下，该方法仍能生成高质量的3D场景表示。

研究结论: 本文方法通过联合优化相机光度参数和引入深度正则化，有效提升了3D场景表示的质量，尤其在成像退化条件下表现优异。

中文摘要: 从多视角图像中表示场景是计算机视觉中的关键任务，具有广泛应用。然而，相机成像中固有的光度失真会显著降低图像质量。若不考虑这些失真，3D场景表示可能会无意中引入与场景无关的错误信息，从而降低表示质量。本文提出了一种新颖的联合相机光度优化的3D场景-相机表示方法。通过引入内外光度模型，我们提出了一种完整的光度模型及相应的相机表示。基于同时优化相机表示参数，该方法有效分离了3D场景表示中与场景无关的信息。此外，在优化光度参数时，我们引入了深度正则化，以防止3D场景表示拟合与场景无关的信息。通过将相机模型作为映射过程的一部分，该方法构建了一个包含场景辐射场和相机光度模型的完整映射。实验结果表明，即使在晕影和污垢等成像退化条件下，所提方法仍能实现高质量的3D场景表示。

</details>


### [62] [Rethink Sparse Signals for Pose-guided Text-to-image Generation](https://arxiv.org/abs/2506.20983)
**中文标题：重新思考稀疏信号在姿态引导的文本到图像生成中的作用**

*Wenjie Xuan,Jing Zhang,Juhua Liu,Bo Du,Dacheng Tao*

主要分类: cs.CV

摘要简述: 本文重新审视稀疏信号（如OpenPose）在姿态引导的文本到图像生成中的作用，提出了一种新型的Spatial-Pose ControlNet（SP-Ctrl），通过增强稀疏信号的可控性和表达力，在稀疏姿态引导下优于现有方法，甚至媲美基于密集信号的方法。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，密集信号（如深度图、DensePose）被广泛用于姿态引导的文本到图像生成，但其编辑困难且可能与文本提示不一致。稀疏信号（如OpenPose）因其简单性和形状无关性被忽视，本文旨在重新探索其潜力。

研究方法: 提出Spatial-Pose ControlNet（SP-Ctrl），将OpenPose扩展为可学习的空间表示，增强关键点嵌入的区分性和表达力；引入关键点概念学习，使关键点标记关注每个关键点的空间位置，从而提升姿态对齐。

研究结果: 在动物和人类图像生成任务中，SP-Ctrl在稀疏姿态引导下优于现有空间可控的文本到图像生成方法，甚至与基于密集信号的方法性能相当，同时展示了跨物种生成的潜力。

研究结论: 稀疏信号在姿态引导的图像生成中具有显著潜力，SP-Ctrl通过增强其可控性和表达力，为稀疏信号的应用提供了新方向。

中文摘要: 近期研究倾向于使用密集信号（如深度图、DensePose）替代稀疏信号（如OpenPose），以提供详细的空间引导用于姿态引导的文本到图像生成。然而，密集信号带来了编辑困难和与文本提示不一致的新挑战。这促使我们重新审视稀疏信号的潜力，因其简单性和形状无关性尚未被充分探索。本文提出了一种新型的Spatial-Pose ControlNet（SP-Ctrl），通过增强稀疏信号的可控性，为姿态引导的图像生成提供了新方法。具体而言，我们将OpenPose扩展为可学习的空间表示，使关键点嵌入更具区分性和表达力；同时引入关键点概念学习，鼓励关键点标记关注每个关键点的空间位置，从而提升姿态对齐。在动物和人类图像生成任务中的实验表明，我们的方法在稀疏姿态引导下优于现有空间可控的文本到图像生成方法，甚至与基于密集信号的方法性能相当。此外，SP-Ctrl通过稀疏信号展示了多样化和跨物种生成的潜力。代码将在https://github.com/DREAMXFAR/SP-Ctrl发布。

</details>


### [63] [EVA: Mixture-of-Experts Semantic Variant Alignment for Compositional Zero-Shot Learning](https://arxiv.org/abs/2506.20986)
**中文标题：EVA：基于专家混合的语义变体对齐组合零样本学习**

*Xiao Zhang,Yongqiang Ma,Haodong Jing,Nanning Zheng*

主要分类: cs.CV

摘要简述: 本文提出EVA框架，通过专家混合和语义变体对齐提升组合零样本学习的性能，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有组合零样本学习方法通过简单的组合-原型映射获取原始特征，忽略了语义子集的差异，且跨模态匹配忽视了相同状态或对象内的组合差异，限制了细粒度对齐。

研究方法: 提出EVA框架，引入领域专家适应机制，利用多专家实现令牌感知学习；提出语义变体对齐，选择语义相关表示进行图像-原始特征匹配。

研究结果: 在三个流行基准测试中，EVA在封闭和开放世界设置下均显著优于现有方法。

研究结论: EVA通过专家混合和语义变体对齐有效提升了组合零样本学习的性能。

中文摘要: 组合零样本学习（CZSL）研究基于学习到的原始概念识别未知状态-对象对的组合泛化能力。现有CZSL方法通常通过简单的组合-原型映射获取原始特征，这对于可划分为不同语义子集的个体集并不理想。此外，全对一跨模态原始特征匹配忽略了相同状态或对象内的组合差异，限制了细粒度图像-组合对齐。本研究提出EVA，一种基于专家混合的语义变体对齐框架。具体而言，我们引入领域专家适应机制，利用多专家实现令牌感知学习并建模高质量原始表示。为实现准确的组合泛化，我们进一步提出语义变体对齐，选择语义相关表示进行图像-原始特征匹配。我们的方法在三个流行基准测试的封闭和开放世界设置中显著优于其他最先进的CZSL方法，证明了所提见解的有效性。

</details>


### [64] [Segment Anything in Pathology Images with Natural Language](https://arxiv.org/abs/2506.20988)
**中文标题：使用自然语言对病理图像进行任意分割**

*Zhixuan Chen,Junlin Hou,Liqi Lin,Yihui Wang,Yequan Bie,Xi Wang,Yanning Zhou,Ronald Cheong Kin Chan,Hao Chen*

主要分类: cs.CV

摘要简述: 本文提出PathSegmentor，首个基于自然语言提示的病理图像分割基础模型，并发布最大病理分割数据集PathSeg。实验表明，PathSegmentor在准确性和泛化性上优于现有方法，为精准肿瘤学提供可解释AI支持。


<details>
  <summary>详细信息</summary>
研究动机: 当前病理图像分割方法因标注数据有限和类别定义狭窄，临床应用受限。为解决这些问题，本文提出首个基于自然语言提示的病理图像分割基础模型。

研究方法: 提出PathSegmentor模型，支持自然语言提示的语义分割，无需空间输入（如点或框）。同时构建PathSeg数据集，包含17个公开来源的275k图像-掩码-标签三元组，涵盖160个类别。

研究结果: PathSegmentor在整体Dice分数上分别超过现有空间提示和文本提示模型0.145和0.429，表现出更强的鲁棒性和泛化能力。其输出还可提升诊断模型的可解释性。

研究结论: PathSegmentor显著提升了病理图像分割的准确性和适用性，推动了精准肿瘤学中可解释AI的发展。

中文摘要: 病理图像分割在计算病理学中对分析癌症诊断和预后的组织学特征至关重要。然而，当前方法因标注数据有限和类别定义狭窄，在临床应用中面临重大挑战。为解决这些问题，我们提出PathSegmentor，首个专为病理图像设计的基于文本提示的分割基础模型。我们还发布了PathSeg，这是最大且最全面的病理分割数据集，包含来自17个公开来源的275k图像-掩码-标签三元组，涵盖160个多样类别。PathSegmentor允许用户通过自然语言提示进行语义分割，无需繁琐的空间输入（如点或框）。大量实验表明，PathSegmentor在准确性和广泛适用性上优于专用模型，同时保持紧凑架构。其整体Dice分数分别超过现有空间提示和文本提示模型0.145和0.429，在分割复杂结构和泛化到外部数据集上表现出强鲁棒性。此外，PathSegmentor的输出通过特征重要性估计和影像生物标志物发现，提升了诊断模型的可解释性，为病理学家提供基于证据的临床决策支持。这项工作推动了精准肿瘤学中可解释AI的发展。

</details>


### [65] [TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation](https://arxiv.org/abs/2506.20991)
**中文标题：TSDASeg：一种用于交互式点云分割的两阶段直接对齐模型**

*Chade Li,Pengju Zhang,Yihong Wu*

主要分类: cs.CV

摘要简述: 本文提出TSDASeg模型，通过两阶段设计和直接跨模态对齐模块，解决了点云分割中3D特征与文本上下文对齐不足的问题，显著提升了交互式分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在点级任务（如分割）中表现不佳，主要因为缺乏直接的3D-文本对齐，导致局部3D特征与文本上下文难以关联。本文旨在解决这一问题。

研究方法: TSDASeg采用两阶段模型，结合直接跨模态对齐模块和内存模块。对齐模块显式对齐3D点云与文本/2D图像数据，内存模块通过自注意力和跨注意力机制动态更新场景特征。

研究结果: 在多个3D指令、参考和语义分割数据集上的实验表明，该方法达到了最先进的性能。

研究结论: TSDASeg通过直接跨模态对齐和动态内存模块，有效解决了交互式分割中的不一致性问题，显著提升了分割效果。

中文摘要: 3D视觉语言模型（VLMs）的快速发展推动了交互式点云处理任务的广泛关注，尤其是实际应用中的需求。然而，现有方法在点级任务（如分割）中表现不佳，主要由于缺乏直接的3D-文本对齐，限制了局部3D特征与文本上下文的关联能力。为解决这一问题，我们提出了TSDASeg，一种结合直接跨模态对齐模块和内存模块的两阶段模型，用于交互式点云分割。我们引入直接跨模态对齐模块，以显式对齐3D点云与文本/2D图像数据。在内存模块中，我们采用多个专用内存库分别存储文本特征、视觉特征及其跨模态对应映射。这些内存库通过自注意力和跨注意力机制动态利用，基于先验存储数据更新场景特定特征，有效解决了不同场景下交互式分割结果的不一致性问题。在多个3D指令、参考和语义分割数据集上的实验表明，所提方法达到了最先进的性能。

</details>


### [66] [Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance](https://arxiv.org/abs/2506.20995)
**中文标题：基于负音频引导的逐步视频到音频合成方法**

*Akio Hayakawa,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji*

主要分类: cs.CV

摘要简述: 本文提出了一种逐步视频到音频合成方法，通过负音频引导生成多个语义不同的音频轨道，显著提升合成音频质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统视频到音频合成方法难以全面捕捉视频中的声音事件。本文旨在模仿传统Foley工作流程，逐步生成与视频中特定声音事件对应的音频轨道，以提升合成音频的全面性和质量。

研究方法: 提出了一种逐步生成方法，每一步生成一个音频轨道，并通过目标文本提示和先前生成的音频轨道进行引导。利用预训练的视频到音频模型，无需专用配对数据集，训练更灵活。

研究结果: 实验表明，该方法能为单个输入视频生成多个语义不同的音频轨道，合成音频质量显著优于现有基线方法。

研究结论: 本文方法通过逐步生成和负音频引导，显著提升了视频到音频合成的质量和多样性，为音频合成领域提供了新思路。

中文摘要: 我们提出了一种新颖的逐步视频到音频生成方法，该方法依次生成与视频中特定声音事件对应的单个音频轨道。我们的方法模仿了传统Foley工作流程，旨在全面捕捉视频中所有声音事件。每一步生成任务被设计为基于目标文本提示和先前生成的音频轨道的引导视频到音频合成任务。这一设计灵感来源于先前组合生成框架中的概念否定思想。为实现这种引导生成，我们引入了一种训练框架，利用预训练的视频到音频模型，无需专用配对数据集，可在更易获取的数据上进行训练。实验结果表明，我们的方法能为单个输入视频生成多个语义不同的音频轨道，从而合成比现有基线更高质量的复合音频。

</details>


### [67] [DBMovi-GS: Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting](https://arxiv.org/abs/2506.20998)
**中文标题：DBMovi-GS：基于稀疏控制高斯分布的模糊单目视频动态视角合成**

*Yeon-Ji Song,Jaein Kim,Byung-Ju Kim,Byoung-Tak Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DBMovi-GS的方法，用于从模糊的单目视频中合成动态场景的新视角，解决了现有方法在动态模糊场景中性能不足的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有新视角合成方法依赖高分辨率图像或静态几何假设，难以处理动态模糊场景，导致视觉质量下降。本文旨在解决这一问题。

研究方法: DBMovi-GS通过稀疏控制的高斯分布生成密集3D高斯，从模糊视频中恢复清晰图像并重建动态场景的详细3D几何结构。

研究结果: 该方法在动态模糊场景的新视角合成中表现稳健，为模糊单目视频输入设定了新的性能基准。

研究结论: DBMovi-GS有效解决了动态模糊场景的新视角合成问题，提升了视觉保真度和稳定性。

中文摘要: 新视角合成任务旨在从未见过的视角生成场景；然而，从模糊单目视频合成动态场景仍是一个尚未有效解决的挑战。现有方法通常依赖高分辨率图像或静态几何假设，导致在动态物体和相机运动的真实环境中性能不稳定且视觉质量下降。为此，我们提出了一种基于稀疏控制高斯分布的模糊单目视频动态视角合成方法（DBMovi-GS）。该方法通过生成密集3D高斯分布，从模糊视频中恢复清晰图像并重建受动态运动影响的场景3D几何细节。实验表明，该方法在动态模糊场景的新视角合成中表现稳健，为模糊单目视频输入设定了新的性能基准。

</details>


### [68] [Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology](https://arxiv.org/abs/2506.21001)
**中文标题：风格对齐的图像合成在细胞病理学异常细胞鲁棒检测中的应用**

*Qiuyi Qi,Xin Li,Ming Kong,Zikang Xu,Bingdi Chen,Qiang Zhu,S Kevin Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种风格对齐的图像合成方法（SAIC），用于增强细胞病理学中异常细胞检测模型的性能和鲁棒性。通过合成高质量且风格一致的病理图像，SAIC显著提升了尾部类别和不同染色风格的检测效果。


<details>
  <summary>详细信息</summary>
研究动机: 细胞病理学中异常细胞检测面临高质量标注不足、数据分布长尾和染色风格不一致等挑战，限制了神经网络的训练效果和鲁棒性。

研究方法: SAIC方法首先基于属性指导从异常细胞库中选择候选样本，然后通过高频特征重建实现异常细胞与病理背景的风格对齐和高保真合成，最后利用大型视觉语言模型筛选高质量合成图像。

研究结果: 实验表明，SAIC合成的图像显著提升了尾部类别和不同染色风格下异常细胞检测的性能和鲁棒性，综合质量评估进一步验证了其在临床应用中的泛化性和实用性。

研究结论: SAIC方法通过风格对齐的图像合成有效解决了细胞病理学检测中的关键挑战，为临床实践提供了可靠的技术支持。

中文摘要: 细胞病理学中异常细胞检测面临高质量标注不足、数据分布长尾和染色风格不一致等挑战，这些问题严重影响了神经网络训练的鲁棒性。本文提出了一种风格对齐的图像合成方法（SAIC），通过合成高保真且风格一致的病理图像，提升检测模型的效果和鲁棒性。SAIC无需额外训练，首先基于属性指导从异常细胞库中选择候选样本，然后通过高频特征重建实现异常细胞与病理背景的风格对齐和高保真合成，最后利用大型视觉语言模型筛选高质量合成图像。实验结果表明，SAIC合成的图像显著提升了尾部类别和不同染色风格下异常细胞检测的性能和鲁棒性，从而改善了整体检测效果。综合质量评估进一步证实了SAIC在临床应用中的泛化性和实用性。代码将在https://github.com/Joey-Qi/SAIC发布。

</details>


### [69] [Inverse Scene Text Removal](https://arxiv.org/abs/2506.21002)
**中文标题：逆向场景文本移除**

*Takumi Yoshimatsu,Shumpei Takezaki,Seiichi Uchida*

主要分类: cs.CV

摘要简述: 本文提出逆向场景文本移除（ISTR），旨在检测图像是否经过文本移除处理并定位被移除的文本区域，实验证明任务可行且准确率高，有助于防止滥用和改进文本移除技术。


<details>
  <summary>详细信息</summary>
研究动机: 场景文本移除（STR）技术可能被滥用，本文研究逆向STR（ISTR），以检测和定位被移除的文本，防止技术滥用并提升STR的可靠性。

研究方法: ISTR通过分析STR处理后的图像，实现二进制分类（检测图像是否经过STR）和定位被移除的文本区域，并尝试训练文本识别器恢复移除的文本内容。

研究结果: 实验表明，ISTR在检测和定位任务中均取得高准确率，同时揭示了恢复移除文本的难度。

研究结论: ISTR为检测STR滥用提供了有效工具，同时为改进STR技术提供了新思路。

中文摘要: 场景文本移除（STR）旨在从图像中擦除文本元素，最初用于移除自然场景图像中的隐私或不需要的文本，现也应用于排版图像。STR通常检测文本区域并进行修复。尽管STR通过神经网络和合成数据取得进展，但滥用风险增加。本文研究逆向STR（ISTR），分析STR处理后的图像，专注于二进制分类（检测图像是否经过STR）和定位被移除的文本区域。实验证明这些任务可实现高准确率，有助于检测潜在滥用并改进STR。我们还尝试通过训练文本识别器恢复移除的文本内容，以了解其难度。

</details>


### [70] [VisionGuard: Synergistic Framework for Helmet Violation Detection](https://arxiv.org/abs/2506.21005)
**中文标题：VisionGuard：协同框架用于头盔违规检测**

*Lam-Huy Nguyen,Thinh-Phuc Nguyen,Thanh-Hai Nguyen,Gia-Huy Dinh,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: VisionGuard是一个多阶段协同框架，用于检测摩托车骑手头盔违规行为，通过自适应标签和上下文扩展模块提升检测准确性和一致性，实验显示其mAP提升3.1%。


<details>
  <summary>详细信息</summary>
研究动机: 摩托车骑手佩戴头盔对道路安全至关重要，但现有自动检测方法因环境变化、摄像头角度和数据不一致等问题难以可靠检测。VisionGuard旨在解决这些问题，提升检测效果。

研究方法: VisionGuard包含两个核心模块：自适应标签模块（通过跟踪算法修正分类标签）和上下文扩展模块（生成虚拟边界框解决数据不平衡问题）。

研究结果: 实验结果表明，VisionGuard相比基线检测器整体mAP提升3.1%，验证了其在交通监控系统中的有效性。

研究结论: VisionGuard通过协同多阶段框架显著提升了头盔违规检测的准确性和一致性，具备实际部署潜力，有助于提升道路安全和法规遵从性。

中文摘要: 强制摩托车骑手佩戴头盔对提升道路安全和交通管理系统的有效性至关重要。然而，由于环境变化、摄像头角度和数据不一致等问题，头盔违规的自动检测面临重大挑战。这些因素阻碍了对摩托车和骑手的可靠检测，并破坏了对象分类的一致性。为解决这些问题，我们提出了VisionGuard，一个协同多阶段框架，旨在克服逐帧检测器的局限性，特别是在类别不平衡和标注不一致的场景中。VisionGuard整合了两个关键组件：自适应标签模块和上下文扩展模块。自适应标签模块是一种基于跟踪的优化技术，通过利用跟踪算法为帧间分配持久标签并修正错误分类，从而提升分类一致性。上下文扩展模块通过生成具有适当置信度的虚拟边界框，有效解决数据不平衡的影响，提升对少数类别的召回率。实验结果表明，VisionGuard相比基线检测器整体mAP提升了3.1%，证明了其在交通监控系统中的有效性和实际部署潜力，最终促进了安全和法规遵从性。

</details>


### [71] [Detection of Breast Cancer Lumpectomy Margin with SAM-incorporated Forward-Forward Contrastive Learning](https://arxiv.org/abs/2506.21006)
**中文标题：基于SAM与正向-正向对比学习的乳腺癌肿块切除术边缘检测**

*Tyler Ward,Xiaoqin Wang,Braxton McFarland,Md Atik Ahamed,Sahar Nozad,Talal Arshad,Hafsa Nebbache,Jin Chen,Abdullah Imran*

主要分类: cs.CV

摘要简述: 提出了一种结合Segment Anything Model (SAM)和Forward-Forward Contrastive Learning (FFCL)的新方法，用于乳腺癌肿块切除术中边缘检测，显著提高了分类和分割的准确性，并减少了手术时间。


<details>
  <summary>详细信息</summary>
研究动机: 目前用于评估乳腺癌肿块切除术中标本边缘状态的2D标本放射成像（SR）方法准确性有限，导致近四分之一的患者需要二次手术。为了解决这一问题，研究提出了一种新的深度学习框架。

研究方法: 结合SAM和FFCL，通过预训练ResNet-18骨干网络对SR图像进行边缘状态分类，并利用SAM进行精细化的肿瘤边缘分割。

研究结果: 该方法在边缘分类中AUC达到0.8455，分割边缘的Dice相似性比基线模型提高了27.4%，每张图像的推理时间缩短至47毫秒。

研究结论: FFCL-SAM显著提高了术中边缘评估的速度和准确性，有望降低乳腺癌治疗中的再切除率并改善手术效果。

中文摘要: 在乳腺癌肿块切除术中，完全切除肿瘤并确保阴性标本边缘对减少复发至关重要。然而，目前用于评估术中标本边缘状态的2D标本放射成像（SR）方法准确性有限，导致近四分之一的患者需要二次手术。为此，我们提出了一种结合Segment Anything Model (SAM)和正向-正向对比学习（FFCL）的新深度学习框架。FFCL是一种预训练策略，利用局部和全局对比学习对SR图像进行块级分类。在标注了已知恶性、非恶性组织及病理确认边缘的SR图像后，我们使用FFCL预训练ResNet-18骨干网络进行边缘状态分类，并通过重建粗二值掩码引导SAM进行精细化肿瘤边缘分割。我们的方法在边缘分类中AUC达到0.8455，分割边缘的Dice相似性比基线模型提高了27.4%，同时将每张图像的推理时间缩短至47毫秒。结果表明，FFCL-SAM显著提高了术中边缘评估的速度和准确性，有望降低再切除率并改善乳腺癌治疗的手术效果。代码发布于https://github.com/tbwa233/FFCL-SAM/。

</details>


### [72] [The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion](https://arxiv.org/abs/2506.21008)
**中文标题：衰老多元宇宙：通过无训练扩散生成条件感知的面部衰老树**

*Bang Gong,Luchao Qi,Jiaye Wu,Zhicheng Fu,Chunbo Song,David W. Jacobs,John Nicholson,Roni Sengupta*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“衰老多元宇宙”的框架，通过无训练扩散方法生成多种基于外部条件（如环境、健康、生活方式）的面部衰老轨迹，形成多样化的衰老树，解决了传统方法单一确定性路径的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 传统面部衰老模型通常仅生成单一确定性路径，无法反映外部条件对衰老的多样化影响。本文旨在通过多条件控制，生成更真实、多样化的衰老轨迹，满足数字叙事、健康教育和个性化可视化等需求。

研究方法: 提出了一种无训练的扩散方法，结合注意力混合技术调节编辑强度，并通过模拟衰老正则化策略稳定编辑效果。该方法在身份保持、年龄准确性和条件控制之间取得平衡。

研究结果: 实验和用户研究表明，该方法在身份保持、衰老真实性和条件对齐方面表现优异，优于现有编辑和衰老进展模型。

研究结论: 通过将衰老转化为多维、可控且可解释的过程，该方法为数字叙事、健康教育和个性化可视化开辟了新途径。

中文摘要: 本文介绍了“衰老多元宇宙”框架，能够从单张图像生成多种基于外部条件（如环境、健康、生活方式）的面部衰老轨迹，形成多样化的衰老树。与传统方法不同，我们的方法通过无训练扩散技术，在身份保持、年龄准确性和条件控制之间取得平衡。关键贡献包括注意力混合技术调节编辑强度，以及模拟衰老正则化策略稳定编辑效果。大量实验和用户研究表明，该方法在身份保持、衰老真实性和条件对齐方面表现优异，超越了现有编辑和衰老进展模型。通过将衰老转化为多维、可控且可解释的过程，我们的方法为数字叙事、健康教育和个性化可视化开辟了新途径。

</details>


### [73] [User-in-the-Loop View Sampling with Error Peaking Visualization](https://arxiv.org/abs/2506.21009)
**中文标题：基于误差峰值可视化的用户参与循环视图采样**

*Ayaka Yasunaga,Hideo Saito,Shohei Mori*

主要分类: cs.CV

摘要简述: 本文提出了一种基于局部重建光场和误差峰值可视化的方法，用于增强现实（AR）中的视图采样，减少用户负担并提高合成效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的AR视图采样方法依赖3D标注，限制了用户的场景探索范围且操作复杂。本文旨在通过可视化误差峰值，简化数据收集过程并扩大采样范围。

研究方法: 利用局部重建的光场技术，通过可视化需要消除的误差来引导用户插入新视图，从而减少对3D标注的依赖。

研究结果: 实验表明，误差峰值可视化方法侵入性更低，减少了用户对最终结果的失望感，并在移动视图合成系统中以更少的视图样本实现了满意效果。此外，该方法还能支持更大场景的辐射场重建。

研究结论: 本文提出的方法通过误差峰值可视化，显著降低了用户负担，提升了视图合成的效率和效果，适用于更广泛的场景。

中文摘要: 增强现实（AR）为新型视图合成提供了可视化缺失视图样本的方法。现有方法通过呈现3D标注来指导用户对齐AR显示拍摄图像，但这一数据收集任务对用户心智负担较大，且由于理想但限制性强的采样理论，仅适用于预定义的小范围场景。为解放用户对3D标注的依赖并扩展场景探索范围，我们提出利用局部重建的光场技术，并通过可视化需要消除的误差来引导新视图的插入。实验结果表明，误差峰值可视化方法侵入性更低，减少了用户对最终结果的失望感，并在移动视图合成系统中以更少的视图样本实现了满意效果。此外，我们还展示了该方法对更大场景（如3D高斯泼溅）的辐射场重建的贡献。

</details>


### [74] [Bridging Video Quality Scoring and Justification via Large Multimodal Models](https://arxiv.org/abs/2506.21011)
**中文标题：通过大型多模态模型桥接视频质量评分与解释**

*Qizhi Xie,Kun Yuan,Yunpeng Qu,Jiachao Gong,Mingda Wu,Ming Sun,Chao Zhou,Jihong Zhu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于评分指令生成（SIG）的自动化流程，通过大型多模态模型（LMMs）提升视频质量评估（VQA）的评分和解释能力。该方法生成包含32万条指令-响应对的数据集（S2I），并通过渐进式调优策略显著提升了视频LMMs的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统视频质量评估方法仅提供数值评分，无法全面描述视频的复杂质量维度，限制了其应用。本文旨在利用大型多模态模型的语言输出能力，通过指令调优解决这一问题。

研究方法: 提出Score-based Instruction Generation（SIG）流程，自动为未标注视频评分并将分数映射到文本定义的质量等级，同时引入分层链式思维（CoT）建模具体维度与整体质量的关系。生成Score2Instruct（S2I）数据集，并设计渐进式调优策略优化视频LMMs。

研究结果: 实验结果表明，SIG方法在S2I-Bench和现有基准测试中显著提升了视频LMMs的质量评分和解释能力。

研究结论: SIG方法通过自动化流程和高质量数据集，有效提升了视频LMMs在质量评估和解释方面的能力，为未来研究提供了新方向。

中文摘要: 传统视频质量评估（VQA）方法通过数值评分判断视频的视觉保真度和清晰度，但评分无法全面描述视频的复杂质量维度，限制了其适用性。得益于语言输出的优势，通过指令调优将视频大型多模态模型（LMMs）应用于VQA有望解决这一问题。该方法的核心在于视频质量为中心的指令数据。先前研究主要集中在图像领域，其数据生成过程严重依赖人工质量标注和专有系统，限制了数据的可扩展性和有效性。为解决这些问题，我们提出了基于评分的指令生成（SIG）流程。具体而言，SIG首先对未标注视频的多个质量维度进行评分，并将分数映射到文本定义的质量等级。随后，通过分层链式思维（CoT）显式建模具体维度与整体质量的关系，模拟人类视觉系统的推理过程。这一自动化流程消除了对专家撰写质量描述和专有系统的依赖，确保了数据的可扩展性和生成效率。最终生成的Score2Instruct（S2I）数据集包含超过32万条多样化的指令-响应对，为指令调优奠定了基础。此外，为同时提升视频LMMs的质量评分和解释能力，我们设计了一种渐进式调优策略，充分释放S2I的潜力。基于SIG，我们进一步构建了一个名为S2I-Bench的基准测试，包含400个开放式问题，以更好地评估视频LMMs的质量解释能力。在S2I-Bench和现有基准测试上的实验结果表明，我们的方法显著提升了多种视频LMMs的质量评分和解释能力。

</details>


### [75] [FedSC: Federated Learning with Semantic-Aware Collaboration](https://arxiv.org/abs/2506.21012)
**中文标题：FedSC：基于语义感知协作的联邦学习**

*Huan Wang,Haoran Li,Huaming Chen,Jun Yan,Jiahua Shi,Jun Shen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FedSC的联邦学习方法，通过语义感知协作解决数据异构性问题。FedSC利用关系原型和一致原型捕捉客户端特定和类别相关的知识，并通过对比学习和正则化优化模型。实验证明其有效性和关键组件的高效性。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习（FL）面临数据异构性挑战，即不同客户端的数据标签偏好存在偏差。现有方法多忽略客户端内部的语义信息，本文旨在利用这些语义知识解决数据异构性问题。

研究方法: FedSC通过构建关系原型和一致原型，捕捉客户端特定和类别相关的语义知识。采用对比学习策略使实例嵌入接近同类关系原型，并通过一致原型作为正则化约束局部模型优化。

研究结果: 实验结果表明，FedSC在多种挑战性场景下表现优异，关键组件高效，验证了其解决数据异构性问题的有效性。

研究结论: FedSC通过语义感知协作成功解决了联邦学习中的数据异构性问题，为未来研究提供了新思路。

中文摘要: 联邦学习（FL）旨在通过客户端协作训练模型，同时保护数据隐私。然而，数据异构性问题（即不同客户端的标签偏好偏差）是一个主要挑战。现有FL方法通常尝试在局部（如正则化局部模型）或全局（如微调全局模型）解决数据异构性，但往往忽略了客户端内部的语义信息。为探索利用客户端内部语义知识处理数据异构性的可能性，本文提出了一种基于语义感知协作的联邦学习方法（FedSC），以捕捉异构客户端间特定于客户端和类别相关的知识。FedSC的核心思想是在语义层面构建关系原型和一致原型，旨在通过原型协作方式提供丰富的类别底层知识和稳定的收敛信号。一方面，FedSC引入了一种对比学习策略，使实例级嵌入更接近具有相同语义的关系原型，远离不同类别。另一方面，FedSC通过差异聚合方式设计一致原型，作为正则化惩罚约束局部模型的优化区域。此外，本文还提供了FedSC的理论分析以确保收敛性保证。在多种挑战性场景下的实验结果表明，FedSC的有效性和关键组件的高效性。

</details>


### [76] [HybridQ: Hybrid Classical-Quantum Generative Adversarial Network for Skin Disease Image Generation](https://arxiv.org/abs/2506.21015)
**中文标题：HybridQ：用于皮肤疾病图像生成的混合经典-量子生成对抗网络**

*Qingyue Jiao,Kangyu Zheng,Yiyu Shi,Zhiding Liang*

主要分类: cs.CV

摘要简述: 本文提出了一种混合经典-量子生成对抗网络（HybridQ），用于生成高质量的皮肤疾病彩色图像，解决了传统生成模型计算资源需求高和量子生成图像质量低的问题。


<details>
  <summary>详细信息</summary>
研究动机: 皮肤疾病数据集常面临类别不平衡、隐私问题和对象偏差，数据增强至关重要。传统生成模型计算成本高，而现有量子生成方法仅能生成低质量灰度图像。本文旨在结合经典与量子技术的优势，提升图像生成质量和效率。

研究方法: 通过一种新颖的经典-量子潜在空间融合技术，构建了首个能够生成彩色医学图像的混合经典-量子生成对抗网络（GAN）。

研究结果: 该模型在图像生成质量和分类性能提升上优于经典深度卷积GAN和现有混合经典-量子GAN，且参数和训练周期大幅减少（参数减少25倍，训练周期减少10倍）。

研究结论: 研究展示了量子图像生成的潜力，随着量子硬件的发展，该方法有望成为高效的数据增强工具。

中文摘要: 机器学习辅助诊断在皮肤疾病检测中日益受到关注，但训练有效模型需要大量高质量数据。皮肤疾病数据集常面临类别不平衡、隐私问题和对象偏差，数据增强至关重要。传统生成模型虽广泛应用，但计算资源需求高且训练时间长。量子计算提供了有前景的替代方案，但现有量子图像生成方法仅能生成低质量灰度图像。通过一种新颖的经典-量子潜在空间融合技术，本文克服了这一限制，提出了首个能够生成彩色医学图像的混合经典-量子生成对抗网络（GAN）。该模型在图像生成质量和分类性能提升上优于经典深度卷积GAN和现有混合经典-量子GAN，且性能提升与最先进的经典生成模型相当，但参数减少25倍，训练周期减少10倍。这表明随着量子硬件的发展，量子图像生成具有广阔前景。最后，我们在真实IBM量子机器上验证了模型在硬件噪声下的稳健性能。

</details>


### [77] [Multimodal Prompt Alignment for Facial Expression Recognition](https://arxiv.org/abs/2506.21017)
**中文标题：多模态提示对齐的面部表情识别**

*Fuyan Ma,Yiran He,Bin Sun,Shutao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MPA-FER的多模态提示对齐框架，用于面部表情识别（FER），通过细粒度语义指导和跨模态对齐，显著提升了识别精度和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于视觉语言模型（VLM）的面部表情识别方法难以捕捉细粒度的文本-视觉关系，导致无法区分细微的表情差异。本文旨在解决这一问题。

研究方法: 提出MPA-FER框架，结合多粒度硬提示生成策略（利用ChatGPT生成详细表情描述）和原型引导的视觉特征对齐，同时引入跨模态全局-局部对齐模块，优化文本与视觉特征的对齐。

研究结果: 在三个FER基准数据集上的实验表明，MPA-FER优于现有方法，同时保留了预训练模型的优势并降低了计算成本。

研究结论: MPA-FER通过细粒度语义指导和跨模态对齐，显著提升了面部表情识别的性能，为相关领域提供了新的解决方案。

中文摘要: 提示学习已被广泛用于高效适配视觉语言模型（如CLIP）以完成各种下游任务。尽管取得了成功，当前基于VLM的面部表情识别（FER）方法仍难以捕捉细粒度的文本-视觉关系，而这对于区分细微的表情差异至关重要。为解决这一问题，我们提出了一种名为MPA-FER的多模态提示对齐框架，通过为提示视觉特征的学习过程提供细粒度语义指导，生成更精确且可解释的表征。具体而言，我们引入了一种多粒度硬提示生成策略，利用ChatGPT等大型语言模型为每种表情生成详细描述。通过最小化软提示与硬提示之间的特征差异，将基于LLM的外部知识注入软提示中。为保留预训练CLIP模型的泛化能力，我们的方法结合了原型引导的视觉特征对齐，确保冻结图像编码器生成的提示视觉特征与类别特定原型紧密对齐。此外，我们提出了一种跨模态全局-局部对齐模块，专注于与表情相关的面部特征，进一步优化文本与视觉特征的对齐。大量实验表明，我们的框架在三个FER基准数据集上优于现有方法，同时保留了预训练模型的优势并最小化了计算成本。

</details>


### [78] [LASFNet: A Lightweight Attention-Guided Self-Modulation Feature Fusion Network for Multimodal Object Detection](https://arxiv.org/abs/2506.21018)
**中文标题：LASFNet：一种轻量级注意力引导自调制特征融合网络用于多模态目标检测**

*Lei Hao,Lina Xu,Chang Liu,Yanni Dong*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级的注意力引导自调制特征融合网络（LASFNet），通过单一特征级融合单元简化训练过程，显著降低计算开销，同时提升检测精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态目标检测方法通常通过堆叠多个特征级融合单元实现，导致计算复杂度高且训练过程复杂。本文旨在设计一种高效且轻量化的特征融合方法，以简化训练并提升性能。

研究方法: 提出了一种新颖的注意力引导自调制特征融合（ASFF）模块，通过全局和局部注意力信息自适应调整融合特征响应；同时设计了轻量级特征注意力变换模块（FATM），以减少信息损失并增强对融合特征的关注。

研究结果: 在三个代表性数据集上的实验表明，LASFNet在减少90%参数和85%计算成本的同时，检测精度（mAP）提升了1%-3%，实现了高效与高精度的平衡。

研究结论: LASFNet通过轻量化的注意力引导特征融合方法，显著降低了计算开销并提升了检测性能，为多模态目标检测提供了高效的新基线。

中文摘要: 通过特征级融合实现有效的深度特征提取对多模态目标检测至关重要。然而，现有研究通常通过堆叠多个特征级融合单元来整合模态特定特征，导致计算开销显著增加。为解决这一问题，我们提出了一种新的融合检测基线，仅使用单一特征级融合单元即可实现高性能检测，从而简化训练过程。基于此方法，我们提出了一种轻量级注意力引导自调制特征融合网络（LASFNet），其引入了一种新颖的注意力引导自调制特征融合（ASFF）模块，能够根据来自不同模态的注意力信息自适应调整融合特征在全局和局部层面的响应，从而促进全面且丰富的特征生成。此外，在LASFNet的颈部设计了轻量级特征注意力变换模块（FATM），以增强对融合特征的关注并最小化信息损失。在三个代表性数据集上的大量实验表明，与现有最优方法相比，我们的方法在减少90%参数和85%计算成本的同时，检测精度（mAP）提升了1%-3%，实现了高效与高精度的平衡。代码将在https://github.com/leileilei2000/LASFNet开源。

</details>


### [79] [Instella-T2I: Pushing the Limits of 1D Discrete Latent Space Image Generation](https://arxiv.org/abs/2506.21022)
**中文标题：Instella-T2I：突破1D离散潜在空间图像生成的极限**

*Ze Wang,Hao Chen,Benran Hu,Jiang Liu,Ximeng Sun,Jialian Wu,Yusheng Su,Xiaodong Yu,Emad Barsoum,Zicheng Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Instella-T2I的新方法，通过引入1D二进制图像潜在空间，显著减少了高分辨率图像生成所需的标记数量，同时保持了细节和效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统的高分辨率图像生成方法需要大量计算资源，而现有的1D潜在空间方法虽然减少了标记数量，但仍存在效率问题。本文旨在通过1D二进制潜在空间进一步优化图像表示，提升生成效率。

研究方法: 采用1D二进制潜在空间表示图像，将图像编码为二进制向量序列，而非传统的一热码本标记。结合简单的模型架构，显著提升了训练和推理速度。

研究结果: 实验表明，该方法仅需128个离散标记即可生成1024x1024分辨率的图像，标记数量比标准VQ-VAEs减少32倍，且性能与现代图像生成模型相当。

研究结论: Instella-T2I提供了一种高效且可扩展的图像生成方法，无需私有训练数据或后训练优化，为传统标记化方法提供了替代方案。

中文摘要: 图像标记化在降低高分辨率图像建模的计算需求方面起着关键作用，显著提高了图像和多模态理解与生成的效率。近年来，1D潜在空间的进展通过消除对2D网格结构的需求，减少了所需的标记数量。本文通过引入1D二进制图像潜在空间，进一步推进了紧凑的离散图像表示。通过将每幅图像表示为二进制向量序列，而非传统的一热码本标记，我们的方法在保持1D潜在空间紧凑性的同时，保留了高分辨率细节。据我们所知，我们的文本到图像模型是首个仅使用128个离散标记即可为1024x1024图像在扩散和自回归生成中实现竞争性能的模型，标记数量比标准VQ-VAEs减少了32倍。所提出的1D二进制潜在空间结合简单模型架构，显著提升了训练和推理速度。我们的文本到图像模型在单个配备8个AMD MI300X GPU的节点上支持4096的全局批量大小，训练可在200 GPU天内完成。我们的模型无需任何内部私有训练数据或后训练优化，即可与现代图像生成模型竞争，为传统标记化方法提供了可扩展且高效的替代方案。

</details>


### [80] [DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation](https://arxiv.org/abs/2506.21034)
**中文标题：DidSee：基于扩散模型的材料无关机器人感知与操作的深度补全方法**

*Wenzhou Lyu,Jialing Lin,Wenqi Ren,Ruihao Xia,Feng Qian,Yang Tang*

主要分类: cs.CV

摘要简述: 论文提出了一种名为DidSee的扩散模型框架，用于解决非朗伯物体深度补全问题。通过改进噪声调度器和训练策略，结合语义增强器，显著提升了深度补全的精度和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 商用RGB-D相机在非朗伯物体上生成的深度图通常存在噪声和不完整问题。传统深度补全方法因训练数据多样性和规模有限而难以泛化。扩散模型虽能利用视觉先验，但训练与推理的不匹配偏差会显著影响性能。此外，非朗伯区域缺乏明显视觉特征，进一步阻碍了精确预测。

研究方法: 1. 采用重新缩放的噪声调度器，强制零终端信噪比以消除信号泄漏偏差。2. 提出噪声无关的单步训练策略，减少暴露偏差导致的误差累积，并使用任务特定损失优化模型。3. 引入语义增强器，实现深度补全与语义分割的联合优化，生成精细的深度图。

研究结果: DidSee在多个基准测试中达到最优性能，展现出强大的真实场景泛化能力，并有效提升了类别级姿态估计和机器人抓取等下游任务的表现。

研究结论: DidSee通过改进扩散框架和引入语义增强器，显著提升了非朗伯物体深度补全的精度和实用性，为机器人感知与操作提供了可靠支持。

中文摘要: 商用RGB-D相机在非朗伯物体上生成的深度图通常存在噪声和不完整问题。传统深度补全方法因训练数据多样性和规模有限而难以泛化。近期研究利用预训练的文本到图像扩散模型的视觉先验来增强密集预测任务的泛化能力。然而，我们发现扩散框架中训练与推理的不匹配偏差会显著影响深度补全性能。此外，非朗伯区域缺乏明显视觉特征，进一步阻碍了精确预测。为解决这些问题，我们提出DidSee，一种基于扩散模型的非朗伯物体深度补全框架。首先，我们采用重新缩放的噪声调度器，强制零终端信噪比以消除信号泄漏偏差。其次，设计噪声无关的单步训练策略，减少暴露偏差导致的误差累积，并使用任务特定损失优化模型。最后，引入语义增强器，实现深度补全与语义分割的联合优化，区分物体与背景并生成精细的深度图。DidSee在多个基准测试中达到最优性能，展现出强大的真实场景泛化能力，并有效提升了类别级姿态估计和机器人抓取等下游任务的表现。项目页面：https://wenzhoulyu.github.io/DidSee/

</details>


### [81] [Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability](https://arxiv.org/abs/2506.21042)
**中文标题：利用扩散模型提升领域泛化与自适应检测：适应性、泛化性与可迁移性**

*Boyong He,Yuxiang Ji,Zhuoyue Tan,Liaoni Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种利用扩散模型提升领域泛化（DG）和自适应检测（DA）性能的方法，通过单步扩散提取中间特征以减少75%推理时间，并构建对象中心辅助分支增强特征鲁棒性。实验在多个基准上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 现有检测器因训练与测试数据的领域差异导致性能下降，而现有扩散模型方法在领域泛化和自适应任务中仍面临高推理成本和未充分利用扩散模型潜力的问题。

研究方法: 1. 从单步扩散过程中提取中间特征以减少推理时间；2. 构建对象中心辅助分支，通过框掩码图像和类别提示提取鲁棒特征；3. 应用一致性损失对齐辅助分支与普通分支，平衡适应性与泛化性；4. 在统一框架中通过特征和对象级对齐提升跨领域检测性能。

研究结果: 在3个DA基准和5个DG基准上取得竞争性结果，并在COCO泛化基准上表现出显著优势，尤其在大领域差异和低数据场景中效率突出。

研究结论: 本文展示了扩散模型在领域泛化和自适应检测任务中的优越性，为跨领域视觉感知任务提供了有价值的见解。

中文摘要: 检测器常因训练与测试数据间的领域差异导致性能下降。近期方法探索了扩散模型在领域泛化（DG）和自适应（DA）任务中的应用，但仍面临高推理成本且未充分利用扩散模型潜力。我们提出从单步扩散过程中提取中间特征，改进特征收集与融合以减少75%推理时间，同时提升源领域性能（即适应性）。此外，通过框掩码图像和类别提示构建对象中心辅助分支，提取聚焦于对象的鲁棒且领域不变特征。应用一致性损失对齐辅助分支与普通分支，平衡适应性与泛化性，防止过拟合并提升目标领域性能（即泛化性）。在统一框架中，标准检测器通过特征级和对象级对齐在源领域（DG）和无标记目标领域（DA）中受扩散检测器指导，从而提升跨领域检测性能（即可迁移性）。我们的方法在3个DA基准和5个DG基准上取得竞争性结果。COCO泛化基准实验表明，该方法在大领域差异和低数据场景中保持显著优势且效率突出。本研究展示了扩散模型在领域泛化与自适应检测任务中的优越性，为跨领域视觉感知任务提供了宝贵见解。代码发布于\href{https://github.com/heboyong/Fitness-Generalization-Transferability}{Fitness-Generalization-Transferability}。

</details>


### [82] [Improving Diffusion-Based Image Editing Faithfulness via Guidance and Scheduling](https://arxiv.org/abs/2506.21045)
**中文标题：通过指导和调度提升基于扩散的图像编辑忠实性**

*Hansam Cho,Seoung Bum Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FGS（Faithfulness Guidance and Scheduling）的方法，通过引入忠实性指导和调度策略，在保持图像编辑能力的同时显著提升了编辑的忠实性。


<details>
  <summary>详细信息</summary>
研究动机: 文本引导的扩散模型在高质量图像合成和动态编辑中表现优异，但编辑能力与忠实性之间存在固有矛盾。本文旨在解决这一矛盾，提出一种方法以最小化对编辑能力的影响，同时显著提升忠实性。

研究方法: FGS方法结合了忠实性指导，以强化输入图像信息的保留，并引入调度策略解决编辑能力与忠实性之间的错位问题。

研究结果: 实验结果表明，FGS在保持编辑能力的同时实现了更高的忠实性，且与多种编辑方法兼容，适用于多样化任务。

研究结论: FGS方法有效平衡了编辑能力与忠实性，为高质量图像编辑提供了可靠解决方案。

中文摘要: 文本引导的扩散模型已成为高质量图像合成的关键工具，支持动态图像编辑。在图像编辑中，两个关键方面是可编辑性（决定修改的程度）和忠实性（反映未修改元素的保留程度）。然而，由于可编辑性与忠实性之间的固有矛盾，实现最优结果具有挑战性。为此，我们提出了忠实性指导与调度（FGS），以最小化对可编辑性的影响，同时提升忠实性。FGS通过忠实性指导强化输入图像信息的保留，并引入调度策略解决可编辑性与忠实性之间的错位问题。实验结果表明，FGS在保持可编辑性的同时实现了更高的忠实性。此外，其与多种编辑方法的兼容性使其能够适用于多样化任务，实现精确且高质量的图像编辑。

</details>


### [83] [Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features](https://arxiv.org/abs/2506.21046)
**中文标题：利用自监督视觉Transformer特征提升生成对抗迁移性**

*Shangbo Wu,Yu-an Tan,Ruinan Ma,Wencong Ma,Dehua Zhu,Yuanzhang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自监督视觉Transformer（ViT）特征的生成对抗攻击方法dSVA，通过结合对比学习（CL）和掩码图像建模（MIM）的双重特征，显著提升了对抗样本的黑盒迁移能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有对抗攻击方法多依赖于监督学习的特征，而自监督学习与Transformer架构的结合表现出色。本文探索自监督ViT特征是否能提升对抗迁移性，并提出双重自监督特征的攻击方法。

研究方法: 提出dSVA方法，利用对比学习（CL）的全局结构特征和掩码图像建模（MIM）的局部纹理特征，设计生成式训练框架，结合生成器和自监督ViT的注意力机制，生成对抗样本。

研究结果: 实验表明，CL和MIM使ViT关注不同特征倾向，双重特征的结合显著提升了对抗样本的黑盒迁移能力，优于现有方法。

研究结论: 自监督ViT的双重特征能够有效提升对抗样本的迁移性，为黑盒攻击提供了新思路。

中文摘要: 深度神经网络（DNNs）的能力源于从数据中提取和解释特征。通过利用DNNs的中间特征而非硬标签，我们生成了更具泛化性的对抗扰动，从而提升了黑盒迁移性。以往研究中的特征多来自监督学习。受自监督学习与Transformer架构协同效应的启发，本文探讨了利用自监督视觉Transformer（ViT）特征是否能提升对抗迁移性。我们提出了dSVA——一种生成式双重自监督ViT特征攻击方法，结合了对比学习（CL）的全局结构特征和掩码图像建模（MIM）的局部纹理特征，这是ViT的自监督学习范式。我们设计了一种新颖的生成式训练框架，包含生成器以创建黑盒对抗样本，并通过联合特征和自监督ViT的注意力机制训练生成器。实验表明，CL和MIM使ViT关注不同的特征倾向，双重特征的结合显著提升了对抗泛化能力。通过干扰自监督ViT提取的双重深度特征，我们在多种架构模型上实现了卓越的黑盒迁移性，超越了现有技术。代码发布于https://github.com/spencerwooo/dSVA。

</details>


### [84] [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277)
**中文标题：HumanOmniV2：从理解到基于上下文的全面多模态推理**

*Qize Yang,Shimin Yao,Weixuan Chen,Shenghao Fu,Detao Bai,Jiaxing Zhao,Boyuan Sun,Bowen Yin,Xihan Wei,Jingren Zhou*

主要分类: cs.CV

摘要简述: 本文提出HumanOmniV2模型，通过强化学习提升多模态大语言模型的全局上下文理解和推理能力，解决现有模型中的上下文理解不足和捷径问题，并在多模态基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型在理解人类意图时存在全局上下文理解不足和捷径问题，导致推理错误或忽略关键多模态线索。本文旨在通过强化学习提升模型的全局理解和复杂推理能力。

研究方法: 采用强化学习方法，引入由大语言模型判断的上下文奖励、格式奖励和准确性奖励，确保多模态信息的准确解读。同时，通过逻辑奖励评估推理过程是否成功整合多模态信息与逻辑方法。此外，提出了IntentBench基准测试以评估模型对复杂人类意图和情感的理解能力。

研究结果: HumanOmniV2在多个多模态基准测试中表现优于其他开源多模态模型，验证了其在全局上下文理解和复杂推理方面的有效性。

研究结论: 本文提出的方法通过强化学习显著提升了多模态大语言模型的全局上下文理解和推理能力，为解决现有模型中的问题提供了有效方案。

中文摘要: 随着多模态大语言模型的快速发展，深入理解和解释人类意图的能力成为关键需求，这需要细致且深思熟虑的推理。近期研究表明，强化学习（RL）在提升大语言模型（LLMs）的推理能力方面具有潜力。然而，将RL应用于多模态数据和格式的挑战仍未得到充分解决。本文指出现有多模态推理模型中的两个问题：全局上下文理解不足和捷径问题。上下文理解不足可能导致模型误解多模态上下文，从而给出错误答案；捷径问题则表现为模型忽视多模态输入中的关键线索，直接回答查询而忽略多模态信息。为解决这些问题，我们强调模型需基于对多模态输入中全局上下文的清晰理解进行推理。这种全局理解能有效防止模型忽略关键多模态线索，确保推理过程的全面性。为实现多模态上下文信息的准确解读，我们引入了由大语言模型判断的上下文奖励，以及格式和准确性奖励。此外，为提升复杂推理能力，我们利用LLM评估逻辑奖励，判断推理过程是否成功整合多模态信息与逻辑方法。我们还提出了IntentBench基准测试，旨在评估模型对复杂人类意图和情感的理解能力。与其他开源多模态模型相比，本文提出的方法在多个多模态基准测试中表现出卓越性能。

</details>


### [85] [Class-Agnostic Region-of-Interest Matching in Document Images](https://arxiv.org/abs/2506.21055)
**中文标题：文档图像中的类别无关兴趣区域匹配**

*Demin Zhang,Jiahao Lyu,Zhijie Shen,Yu Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“类别无关兴趣区域匹配”（RoI-Matching）的新任务，旨在灵活、高效地匹配用户自定义的文档区域。通过构建基准数据集RoI-Matching-Bench和提出RoI-Matcher框架，实验验证了方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有文档分析解决方案（如文档布局分析和关键信息提取）仅适用于固定类别和粒度，无法满足用户灵活定制需求。因此，本文提出RoI-Matching任务，以实现多粒度、开放集的灵活匹配。

研究方法: 提出RoI-Matcher框架，采用孪生网络提取参考文档和目标文档的多层次特征，并通过交叉注意力层整合和对齐不同域的相似语义。构建了RoI-Matching-Bench基准数据集，包含三个难度级别。

研究结果: 实验表明，RoI-Matcher在RoI-Matching-Bench上表现有效，为后续研究提供了基线。

研究结论: 本文提出的RoI-Matching任务和RoI-Matcher框架为文档分析提供了灵活、高效的解决方案，并推动了该领域的进一步研究。

中文摘要: 文档理解与分析因其广泛应用而备受关注。然而，现有的文档分析解决方案（如文档布局分析和关键信息提取）仅适用于固定类别定义和粒度，无法实现用户定制的灵活应用。因此，本文定义了一种名为“类别无关兴趣区域匹配”（简称“RoI-Matching”）的新任务，旨在以灵活、高效、多粒度和开放集的方式匹配用户自定义区域。参考文档和目标文档图像的视觉提示被输入到模型中，输出为目标文档图像中对应的边界框。为满足上述需求，我们构建了基准数据集RoI-Matching-Bench，根据真实场景设置了三个难度级别，并提出了宏观和微观评估指标。此外，我们还提出了新框架RoI-Matcher，采用孪生网络提取参考域和目标域的多层次特征，并通过交叉注意力层整合和对齐不同域的相似语义。实验表明，我们的方法在RoI-Matching-Bench上简单且有效，为后续研究提供了基线。代码发布于https://github.com/pd162/RoI-Matching。

</details>


### [86] [SAMURAI: Shape-Aware Multimodal Retrieval for 3D Object Identification](https://arxiv.org/abs/2506.21056)
**中文标题：SAMURAI：面向3D物体识别的形状感知多模态检索**

*Dinh-Khoi Vo,Van-Loc Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: SAMURAI是一种结合形状感知和多模态检索的方法，用于在复杂室内环境中仅通过掩膜2D图像和自然语言描述识别3D物体。该方法整合了CLIP语义匹配和形状引导重排序，显著提升了检索性能。


<details>
  <summary>详细信息</summary>
研究动机: 在复杂室内环境中，仅通过掩膜2D图像和自然语言描述检索3D物体面临巨大挑战，如视角扭曲、无纹理掩膜区域、模糊语言提示和噪声分割掩膜。为解决这些问题，研究提出了SAMURAI方法。

研究方法: SAMURAI结合了基于CLIP的语义匹配和从掩膜区域二值轮廓中提取的形状引导重排序，并采用多数投票策略。预处理流程通过提取最大连通分量和去除背景噪声提升掩膜质量。

研究结果: SAMURAI在ROOMELSA私有测试集上表现出色，证明了结合形状先验和语言理解对开放世界3D物体检索的重要性。

研究结论: SAMURAI通过整合形状和语言多模态信息，显著提升了3D物体检索的鲁棒性，为开放世界检索提供了有效解决方案。

中文摘要: 在复杂室内环境中，仅通过掩膜2D图像和自然语言描述检索3D物体具有显著挑战。ROOMELSA挑战限制了完整3D场景上下文的访问，增加了对物体外观、几何和语义推理的复杂性。这些挑战因扭曲视角、无纹理掩膜区域、模糊语言提示和噪声分割掩膜而加剧。为此，我们提出SAMURAI：面向3D物体识别的形状感知多模态检索。SAMURAI将基于CLIP的语义匹配与从掩膜区域二值轮廓中提取的形状引导重排序相结合，并采用鲁棒的多数投票策略。专用预处理流程通过提取最大连通分量和去除背景噪声提升掩膜质量。我们的混合检索框架利用语言和形状线索，在ROOMELSA私有测试集上取得了有竞争力的性能。这些结果凸显了结合形状先验与语言理解对鲁棒开放世界3D物体检索的重要性。

</details>


### [87] [PoseMaster: Generating 3D Characters in Arbitrary Poses from a Single Image](https://arxiv.org/abs/2506.21076)
**中文标题：PoseMaster：从单张图像生成任意姿势的3D角色**

*Hongyu Yan,Kunming Luo,Weiyu Li,Yixun Liang,Shengming Li,Jingwei Huang,Chunchao Guo,Ping Tan*

主要分类: cs.CV

摘要简述: PoseMaster是一种端到端的可控3D角色生成框架，通过统一姿势变换和3D角色生成，解决了传统方法在姿势标准化阶段导致的图像失真问题，并实现了对任意姿势的精确控制。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于图像的3D角色建模方法在姿势标准化阶段容易因自遮挡和视角问题导致图像失真，进而影响后续3D重建的几何质量。为了解决这些问题，本文提出了PoseMaster框架。

研究方法: PoseMaster将姿势变换和3D角色生成统一到一个基于流的3D原生生成框架中。利用可动画角色的3D骨骼作为姿势条件，并在训练中随机清空姿势和图像条件以提高控制效果和泛化能力。此外，还创建了一个高质量姿势控制数据集。

研究结果: 实验表明，PoseMaster在A姿势角色生成上优于现有技术，并在任意姿势控制方面表现出强大的能力。

研究结论: PoseMaster通过统一姿势变换和3D生成，显著提升了角色建模的效率和几何质量，同时实现了对任意姿势的精确控制。

中文摘要: 3D角色在日常娱乐中扮演着重要角色。为了提高3D角色建模的效率，近期基于图像的方法使用两个独立模型分别实现姿势标准化和A姿势角色的3D重建。然而，这些方法在姿势标准化阶段容易因自遮挡和视角问题生成失真和退化的图像，进而影响后续重建过程的几何质量。为解决这些问题，我们提出了PoseMaster，一种端到端的可控3D角色生成框架。具体而言，我们将姿势变换和3D角色生成统一到一个基于流的3D原生生成框架中。为实现精确的任意姿势控制，我们提出利用可动画角色骨骼中的3D骨骼作为姿势条件。此外，考虑到多条件控制的特殊性，我们在训练中随机清空姿势条件和图像条件，以提高姿势控制的有效性和泛化能力。最后，我们创建了一个基于真实角色动画数据的高质量姿势控制数据集，使模型能够学习骨骼与蒙皮权重之间的隐式关系。大量实验表明，PoseMaster在A姿势角色生成上优于当前最先进技术，并在任意姿势控制方面展现出强大的能力。

</details>


### [88] [EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception](https://arxiv.org/abs/2506.21080)
**中文标题：EgoAdapt：自适应多模态蒸馏与策略学习实现高效以自我为中心的感知**

*Sanjoy Chowdhury,Subrata Biswas,Sayan Nag,Tushar Nagarajan,Calvin Murdock,Ishwarya Ananthabhotla,Yijun Qian,Vamsi Krishna Ithapu,Dinesh Manocha,Ruohan Gao*

主要分类: cs.CV

摘要简述: 本文提出EgoAdapt框架，通过自适应多模态蒸馏和策略学习，显著提升以自我为中心感知任务的效率，减少计算资源消耗，同时保持或超越现有最佳模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代感知模型在以自我为中心的多模态任务中表现优异，但计算成本高昂，难以在资源受限的环境中部署。本文旨在通过自适应方法提升效率，同时保持高性能。

研究方法: EgoAdapt框架结合跨模态蒸馏和策略学习，自适应地优化不同任务（如动作识别、主动说话者定位和行为预测）的推理效率。策略模块可适应任务特定的动作空间，具有广泛适用性。

研究结果: 在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个数据集上的实验表明，EgoAdapt显著提升了效率，GMACs减少89.09%，参数减少82.02%，能耗降低9.6倍，性能与或优于现有最佳模型。

研究结论: EgoAdapt通过自适应多模态蒸馏和策略学习，有效解决了以自我为中心感知任务的高计算成本问题，为资源受限环境中的部署提供了高效解决方案。

中文摘要: 现代感知模型，尤其是为多模态以自我为中心任务设计的模型，虽然性能卓越，但通常伴随着高昂的计算成本。这些高需求在资源受限的实际部署环境中带来了挑战。本文提出EgoAdapt框架，通过自适应跨模态蒸馏和策略学习，实现了在以自我为中心感知任务（如动作识别、主动说话者定位和行为预测）中的高效推理。我们提出的策略模块可适应任务特定的动作空间，具有广泛适用性。在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个具有挑战性的数据集上的实验结果表明，我们的方法显著提升了效率，GMACs减少高达89.09%，参数减少高达82.02%，能耗降低高达9.6倍，同时性能与或优于现有最佳模型。

</details>


### [89] [ESMStereo: Enhanced ShuffleMixer Disparity Upsampling for Real-Time and Accurate Stereo Matching](https://arxiv.org/abs/2506.21091)
**中文标题：ESMStereo：用于实时高精度立体匹配的增强ShuffleMixer视差上采样方法**

*Mahmoud Tahmasebi,Saif Huq,Kevin Meehan,Marion McAfee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ESMStereo的方法，通过增强的ShuffleMixer技术提升小规模成本体积的视差上采样能力，实现了实时且高精度的立体匹配。该方法在高端GPU上达到116 FPS，AGX Orin上达到91 FPS。


<details>
  <summary>详细信息</summary>
研究动机: 立体匹配在现代自主系统中日益重要，但基于深度学习的模型在实现高精度和实时性能之间存在矛盾。大规模成本体积虽能提供高精度，但计算量大；小规模成本体积虽能实现实时性能，但精度不足。本文旨在解决这一矛盾。

研究方法: 提出增强的Shuffle Mixer（ESM），通过将主要特征整合到视差上采样单元中，恢复小规模成本体积丢失的细节。快速提取初始视差估计的特征并与图像特征融合，通过混洗和分层分割混合特征，再通过紧凑的特征引导沙漏网络细化，恢复更详细的场景几何结构。

研究结果: ESMStereo在高端GPU上达到116 FPS的推理速度，在AGX Orin上达到91 FPS，同时实现了高精度的视差图重建。

研究结论: ESMStereo通过高效的局部上下文连接和大感受野，以低计算成本实现了实时高精度的立体匹配，为现代自主系统提供了可行的解决方案。

中文摘要: 立体匹配已成为现代自主系统中日益重要的组成部分。开发基于深度学习的立体匹配模型，在实现高精度的同时保持实时性能，仍然是计算机视觉领域的主要挑战。在基于成本体积的立体匹配中，准确的视差估计高度依赖于大规模成本体积。然而，这种大规模体积存储了大量冗余信息，并且需要计算密集的聚合单元进行处理和回归，导致实时性能难以实现。相反，小规模成本体积结合轻量级聚合单元为实现实时性能提供了可能，但缺乏足够信息以确保高精度视差估计。为解决这一问题，我们提出了增强的Shuffle Mixer（ESM），以缓解小规模成本体积带来的信息丢失。ESM通过将主要特征整合到视差上采样单元中恢复关键细节。它快速从初始视差估计中提取特征并与图像特征融合，通过混洗和分层分割混合特征，再通过紧凑的特征引导沙漏网络细化，恢复更详细的场景几何结构。ESM专注于具有大感受野和低计算成本的局部上下文连接，从而实现了实时高精度视差图的重建。ESMStereo的紧凑版本在高端GPU上达到116 FPS的推理速度，在AGX Orin上达到91 FPS。

</details>


### [90] [OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography](https://arxiv.org/abs/2506.21101)
**中文标题：OracleFusion：基于结构约束语义排版的甲骨文解读辅助系统**

*Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,AndyPian Wu,Chaoyang Wang,Chengjie Wang,Taisong Jin,SevenShu,Yunsheng Wu,Yongge Liu,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出了一种名为OracleFusion的两阶段语义排版框架，用于辅助解读甲骨文。通过结合多模态大语言模型（MLLM）和甲骨结构向量融合（OSVF）技术，该方法在语义、视觉和字形保持方面优于现有基线模型，显著提升了甲骨文的可读性和美学质量。


<details>
  <summary>详细信息</summary>
研究动机: 甲骨文作为最早的古代文字之一，记录了古代文明的文化与智慧。然而，已发现的4500个甲骨文字中，仅有约1600个被解读。其余未解读的字符结构复杂、意象抽象，解读难度大。本文旨在通过技术手段辅助专家解读这些未解字符。

研究方法: OracleFusion采用两阶段框架：第一阶段利用增强空间感知推理（SAR）的多模态大语言模型（MLLM）分析甲骨文字形结构并定位关键部件；第二阶段引入甲骨结构向量融合（OSVF），结合字形结构约束和字形保持约束，生成语义丰富的矢量字体。

研究结果: 实验表明，OracleFusion在语义、视觉吸引力和字形保持方面均优于现有基线模型，显著提升了甲骨文的可读性和美学质量。此外，该方法还能为未见过的甲骨文字符提供专家级解读建议。

研究结论: OracleFusion为甲骨文解读提供了有效的技术辅助工具，通过结合多模态分析和结构约束，显著提升了未解字符的解读效率和准确性，具有重要的文化和学术价值。

中文摘要: 甲骨文作为最早的古代文字之一，承载了古代文明的文化记录和智慧表达。尽管已发现约4500个甲骨文字，但仅有约1600个被解读。其余未解字符结构复杂、意象抽象，解读难度极大。为解决这一问题，本文提出了一种名为OracleFusion的两阶段语义排版框架。第一阶段利用增强空间感知推理（SAR）的多模态大语言模型（MLLM）分析甲骨文字形结构并定位关键部件；第二阶段引入甲骨结构向量融合（OSVF），结合字形结构约束和字形保持约束，生成语义丰富的矢量字体。该方法在保持字形结构客观完整性的同时，提供了视觉增强的表达形式，辅助专家解读甲骨文。大量定性和定量实验表明，OracleFusion在语义、视觉吸引力和字形保持方面均优于现有基线模型，显著提升了可读性和美学质量。此外，OracleFusion还能为未见过的甲骨文字符提供专家级解读建议，成为推动甲骨文解读的重要工具。

</details>


### [91] [Logios : An open source Greek Polytonic Optical Character Recognition system](https://arxiv.org/abs/2506.21474)
**中文标题：Logios：一个开源希腊多调光学字符识别系统**

*Perifanos Konstantinos,Goutsos Dionisis*

主要分类: cs.CV

摘要简述: 本文介绍了一个专为希腊多调文本设计的开源光学字符识别（OCR）系统Logios，通过结合卷积层和循环层的优势，显著提升了识别准确率和效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统OCR方法在处理希腊多调文本时存在局限性，因此需要一种专门针对此类复杂脚本的高效识别系统。

研究方法: 系统采用卷积层进行特征提取，结合循环层进行序列学习，以解决希腊多调文本的独特挑战。

研究结果: 该系统在准确率和效率上均有显著提升，并作为开源库发布，供学术使用。

研究结论: Logios系统为希腊多调文本的数字化提供了高效解决方案，其开源特性将进一步推动相关研究。

中文摘要: 本文介绍了一种专为希腊多调文本设计的光学字符识别（OCR）系统，通过结合卷积层用于特征提取和循环层用于序列学习的优势，解决了希腊多调脚本带来的独特挑战。该方法旨在克服传统OCR方法的局限性，显著提升了准确率和效率。我们将底层模型作为开源库发布，并将OCR平台提供给学术使用。

</details>


### [92] [Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing Change Detection](https://arxiv.org/abs/2506.21109)
**中文标题：突破权衡边界：紧凑而高效的遥感变化检测**

*Luosheng Xu,Dalin Zhang,Zhaohui Song*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级遥感变化检测模型FlickCD，通过增强差异模块和多尺度局部-全局融合块，显著降低计算和存储开销，同时保持高精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度学习模型在遥感变化检测中复杂度高、计算需求大，但精度提升有限。研究旨在开发一种轻量级模型，兼顾高精度和低资源消耗，适用于卫星端处理。

研究方法: FlickCD引入增强差异模块（EDM）突出关键特征差异，抑制无关变化；解码器采用局部-全局融合块，结合Shifted Window自注意力和增强全局自注意力，高效捕获多尺度语义信息。

研究结果: 在四个基准数据集上的实验表明，FlickCD计算和存储开销降低超过一个数量级，同时达到或接近最优性能（F1分数损失<1%）。

研究结论: FlickCD突破了性能与资源的权衡边界，为轻量级遥感变化检测提供了高效解决方案，适用于资源受限场景。

中文摘要: 遥感变化检测对于监测城市扩张、灾害评估和资源管理至关重要，能够提供动态景观变化的及时、准确和大规模信息。尽管深度学习已彻底改变了变化检测领域，但现代模型日益增加的复杂性和计算需求并未带来显著的精度提升。本研究未追随这一趋势，而是探索了一种更高效的方法，专注于轻量级模型，在保持高精度的同时最小化资源消耗，这是卫星端处理的关键需求。为此，我们提出了FlickCD（意为快速轻弹即可获得优异结果），突破了性能与资源的权衡边界。FlickCD引入了增强差异模块（EDM），以放大时间相位间的关键特征差异，同时抑制光照和天气变化等无关变化，从而降低后续变化解码器的计算成本。此外，FlickCD解码器结合了局部-全局融合块，利用移位窗口自注意力（SWSA）和增强全局自注意力（EGSA）高效捕获多尺度语义信息，保留粗粒度和细粒度变化。在四个基准数据集上的大量实验表明，FlickCD将计算和存储开销降低了一个数量级以上，同时实现了最优性能或仅带来微小（F1分数<1%）的精度损失。实现代码已公开于https://github.com/xulsh8/FlickCD。

</details>


### [93] [IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes](https://arxiv.org/abs/2506.21116)
**中文标题：IPFormer-VideoLLM：增强多镜头场景的多模态视频理解能力**

*Yujia Liang,Jile Jiao,Zhicheng Wang,Xuetao Feng,Zixuan Ye,Yuan Wang,Hao Lu*

主要分类: cs.CV

摘要简述: 本文提出IPFormer-VideoLLM模型和MultiClip-Bench数据集，以解决视频大语言模型在多镜头场景中的理解不足问题，通过实例级特征注入显著提升了多场景视频理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频大语言模型在多镜头场景（如不同摄像机角度或场景切换）中表现不佳，容易出现实例身份遗忘和关键帧忽略问题。作者认为这是由于现有数据集缺乏多镜头标注，因此提出了新的数据集和模型来解决这一问题。

研究方法: 作者首先引入MultiClip-Bench数据集，包含针对多镜头场景的密集描述和基于指令的问答对。随后提出IPFormer-VideoLLM模型，通过基于注意力的连接器注入实例级特征作为提示，实现跨场景的实例信息聚合。

研究结果: 实验表明，提出的数据集和模型显著提升了多场景视频理解能力，并在多个视频基准测试中展现出明显优势。

研究结论: IPFormer-VideoLLM和MultiClip-Bench为多镜头视频理解提供了有效解决方案，同时为未来研究提供了可靠的数据和模型基础。

中文摘要: 视频大语言模型（VideoLLMs）已展现出卓越的理解能力，但在处理多镜头场景（如摄像机角度变化或场景切换的视频片段）时表现不佳，容易出现实例身份遗忘和关键帧忽略等问题。本文首先将这一挑战归因于现有数据集缺乏多镜头标注，因此提出了名为MultiClip-Bench的新数据集，包含针对多镜头场景的密集描述和基于指令的问答对。实证发现，训练集显著提升了多镜头性能，而测试基准为模型在多镜头场景中的能力提供了可靠衡量。进一步分析发现，现有模型仅以离散或有损方式编码实例特征，存在丢失身份信息的风险。为此，本文提出了新模型IPFormer-VideoLLM，其核心思想是通过高效的基于注意力的连接器注入实例级特征作为实例提示，实现跨场景的实例信息聚合。实验表明，提出的数据集和模型不仅显著提升了多场景视频理解能力，还在多个视频基准测试中展现出独特优势。

</details>


### [94] [HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation](https://arxiv.org/abs/2506.21546)
**中文标题：HalluSegBench：基于反事实视觉推理的分割幻觉评估**

*Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou*

主要分类: cs.CV

摘要简述: HalluSegBench是首个通过反事实视觉推理评估视觉基础中幻觉现象的基准，包含1340对反事实实例和新型指标，揭示视觉驱动的幻觉比标签驱动的更普遍。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言分割模型常因生成与图像内容无关的分割掩码或错误标记区域而产生幻觉，现有评估方法无法有效诊断此类问题。

研究方法: 提出HalluSegBench基准，包含1340对反事实实例和新型指标，通过视觉连贯的场景编辑量化幻觉敏感性。

研究结果: 实验表明，视觉驱动的幻觉比标签驱动的更普遍，模型常持续产生错误分割，凸显反事实推理的必要性。

研究结论: HalluSegBench为评估视觉基础中的幻觉提供了新工具，揭示了模型在反事实场景中的局限性。

中文摘要: 视觉语言分割的最新进展显著提升了基于视觉的理解能力。然而，这些模型常因生成与图像内容无关的分割掩码或错误标记区域而产生幻觉。现有的分割幻觉评估方法主要关注标签或文本幻觉，而未操纵视觉上下文，限制了其诊断关键问题的能力。为此，我们提出了HalluSegBench，这是首个通过反事实视觉推理评估视觉基础中幻觉的基准。我们的基准包含1340对反事实实例，涵盖281个独特对象类别，以及一组新提出的指标，用于量化视觉连贯场景编辑下的幻觉敏感性。在HalluSegBench上对最先进的视觉语言分割模型进行实验表明，视觉驱动的幻觉比标签驱动的更普遍，模型常持续产生错误分割，凸显了反事实推理在诊断基础保真度中的必要性。

</details>


### [95] [CL-Splats: Continual Learning of Gaussian Splatting with Local Optimization](https://arxiv.org/abs/2506.21117)
**中文标题：CL-Splats：基于局部优化的高斯泼溅持续学习**

*Jan Ackermann,Jonas Kulhanek,Shengqu Cai,Haofei Xu,Marc Pollefeys,Gordon Wetzstein,Leonidas Guibas,Songyou Peng*

主要分类: cs.CV

摘要简述: 本文提出CL-Splats，一种基于高斯泼溅的3D场景表示持续学习方法，通过局部优化和变化检测模块高效更新动态场景，避免全局重新计算，同时支持场景状态存储与恢复。


<details>
  <summary>详细信息</summary>
研究动机: 在动态3D环境中，实时更新场景表示对机器人、混合现实和具身AI应用至关重要。传统方法需要全局重新优化，计算开销大。本文旨在提出一种高效方法，通过局部优化实现高质量场景更新。

研究方法: CL-Splats通过变化检测模块分割场景中的动态和静态部分，仅对变化区域进行局部优化，避免全局重新计算。此外，支持场景状态的存储与恢复，便于时间分割和新应用开发。

研究结果: 实验表明，CL-Splats在更新效率和重建质量上优于现有方法，为实时3D场景重建任务提供了可靠基础。

研究结论: CL-Splats通过局部优化和变化检测实现了动态3D场景的高效更新，为未来实时适应任务提供了新思路。

中文摘要: 在动态3D环境中，随时间准确更新场景表示对机器人、混合现实和具身AI应用至关重要。随着场景变化，需要高效方法以纳入变化，而无需重新优化整个场景的计算开销。本文提出CL-Splats，通过稀疏场景捕获逐步更新基于高斯泼溅的3D表示。CL-Splats集成了一个鲁棒的变化检测模块，能够分割场景中更新和静态部分，从而支持聚焦的局部优化，避免不必要的重新计算。此外，CL-Splats支持存储和恢复先前的场景状态，便于时间分割和新场景分析应用。我们的广泛实验表明，CL-Splats在更新效率和重建质量上优于现有方法，为未来3D场景重建任务的实时适应奠定了坚实基础。

</details>


### [96] [GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction](https://arxiv.org/abs/2506.21121)
**中文标题：GoIRL：面向图的多模态轨迹预测逆向强化学习**

*Muleilan Pei,Shaoshuai Shi,Lu Zhang,Peiliang Li,Shaojie Shen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图导向逆向强化学习（GoIRL）的多模态轨迹预测框架，通过向量化上下文表示和特征适配器，结合最大熵逆向强化学习，显著提升了自动驾驶中轨迹预测的准确性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶中周围智能体的轨迹预测具有高度不确定性和多模态性，现有数据驱动方法主要依赖监督学习，难以充分捕捉复杂场景。本文旨在通过逆向强化学习框架，结合图结构特征，提升预测性能。

研究方法: 提出GoIRL框架，包括特征适配器将车道图特征聚合到网格空间，结合最大熵逆向强化学习推断奖励分布；通过分层参数化轨迹生成器和细化模块提升预测精度，并采用概率融合策略增强预测置信度。

研究结果: 在Argoverse和nuScenes运动预测基准测试中，GoIRL实现了最先进的性能，并展现出优于现有监督模型的泛化能力。

研究结论: GoIRL框架通过图导向逆向强化学习和多模态轨迹生成，显著提升了自动驾驶中轨迹预测的准确性和泛化性，为复杂场景下的预测问题提供了有效解决方案。

中文摘要: 自动驾驶中周围智能体的轨迹预测因其固有的不确定性和多模态性而极具挑战性。与主要依赖监督学习的现有数据驱动方法不同，本文提出了一种新颖的图导向逆向强化学习（GoIRL）框架，这是一种配备向量化上下文表示的基于逆向强化学习的预测器。我们开发了一个特征适配器，将车道图特征有效聚合到网格空间，使其能够与最大熵逆向强化学习范式无缝集成，从而推断奖励分布并获取可通过采样生成多个合理计划的策略。此外，基于采样的计划，我们实现了一个分层参数化轨迹生成器，配备细化模块以提升预测精度，并采用概率融合策略增强预测置信度。大量实验结果表明，我们的方法不仅在大规模Argoverse和nuScenes运动预测基准测试中实现了最先进的性能，而且与现有监督模型相比展现出更优的泛化能力。

</details>


### [97] [Learning to See in the Extremely Dark](https://arxiv.org/abs/2506.21132)
**中文标题：学习在极暗环境中视物**

*Hai Jiang,Binhao Guan,Zhen Liu,Xiaohong Liu,Jian Yu,Zheng Liu,Songchen Han,Shuaicheng Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种用于极暗场景（低至0.0001勒克斯）的RAW图像增强方法，通过生成配对数据集SIED和基于扩散模型的框架，实现了高质量的图像恢复。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于学习的方法在低光RAW图像增强方面取得进展，但对极暗场景（如0.0001勒克斯）的研究因缺乏数据集而受限。本文旨在填补这一空白。

研究方法: 提出了一种配对数据合成管道，生成极低光RAW图像（0.0001-0.001勒克斯）及其sRGB参考，构成SIED数据集。并设计了一个基于扩散模型的框架，结合自适应光照校正模块（AICM）和颜色一致性损失，实现高质量恢复。

研究结果: 在SIED和公开基准测试中，该方法表现出色，能够从极低信噪比的RAW输入中恢复视觉上令人满意的结果。

研究结论: 本文提出的数据集和方法为极暗场景的图像增强提供了有效解决方案，实验验证了其优越性。

中文摘要: 基于学习的方法在低光RAW图像增强方面取得了显著进展，但其在环境照度低至0.0001勒克斯的极暗场景中的能力仍有待探索，原因是缺乏相应的数据集。为此，我们提出了一种配对数据合成管道，能够生成三种精确照度范围（0.01-0.1勒克斯、0.001-0.01勒克斯和0.0001-0.001勒克斯）的极低光RAW图像，并配有高质量的sRGB参考图像，构成了一个名为“极暗视物”（SIED）的大规模配对数据集，用于评估低光RAW图像增强方法。此外，我们提出了一种基于扩散模型的框架，利用扩散模型的生成能力和固有去噪特性，从极低信噪比的RAW输入中恢复视觉上令人满意的结果。其中，自适应光照校正模块（AICM）和颜色一致性损失被引入以确保准确的曝光校正和颜色恢复。在提出的SIED数据集和公开基准测试上的广泛实验证明了我们方法的有效性。代码和数据集可在https://github.com/JianghaiSCU/SIED获取。

</details>


### [98] [YOLO-FDA: Integrating Hierarchical Attention and Detail Enhancement for Surface Defect Detection](https://arxiv.org/abs/2506.21135)
**中文标题：YOLO-FDA：结合层次化注意力与细节增强的表面缺陷检测方法**

*Jiawei Hu*

主要分类: cs.CV

摘要简述: YOLO-FDA提出了一种基于YOLO的缺陷检测框架，通过细粒度细节增强和注意力引导的特征融合，显著提升了工业场景中表面缺陷检测的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 工业场景中的表面缺陷检测面临缺陷类型多样、形状不规则、尺寸多变、细粒度要求高以及材料纹理复杂等挑战。现有方法存在特征冗余、细节敏感性不足和多尺度条件下鲁棒性弱的问题，亟需改进。

研究方法: YOLO-FDA采用BiFPN架构增强YOLOv5主干网络的双向多级特征聚合，并引入细节定向融合模块（DDFM）通过方向性非对称卷积丰富空间细节。此外，提出两种注意力融合策略（AC和CAF）以优化上下文表示并减少特征噪声。

研究结果: 在多个基准数据集上的实验表明，YOLO-FDA在多种缺陷类型和尺度下均优于现有最先进方法，表现出更高的准确性和鲁棒性。

研究结论: YOLO-FDA通过结合细粒度细节增强和注意力机制，有效解决了工业缺陷检测中的关键问题，为复杂场景下的缺陷检测提供了高效解决方案。

中文摘要: 工业场景中的表面缺陷检测由于缺陷类型多样、形状不规则、尺寸多变、细粒度要求高以及材料纹理复杂，具有重要性和技术挑战性。尽管基于AI的检测器近期取得了进展，但现有方法常存在特征冗余、细节敏感性不足和多尺度条件下鲁棒性弱的问题。为解决这些问题，我们提出了YOLO-FDA，一种基于YOLO的新型检测框架，整合了细粒度细节增强和注意力引导的特征融合。具体而言，我们采用BiFPN风格的架构以增强YOLOv5主干网络中的双向多级特征聚合。为更好地捕捉细微结构变化，我们引入了细节定向融合模块（DDFM），通过在次低层引入方向性非对称卷积以丰富空间细节，并将次低层与低层特征融合以增强语义一致性。此外，我们提出了两种新颖的基于注意力的融合策略——注意力加权拼接（AC）和跨层注意力融合（CAF），以改善上下文表示并减少特征噪声。在多个基准数据集上的广泛实验表明，YOLO-FDA在多种缺陷类型和尺度下均显著优于现有最先进方法，表现出更高的准确性和鲁棒性。

</details>


### [99] [Tree-based Semantic Losses: Application to Sparsely-supervised Large Multi-class Hyperspectral Segmentation](https://arxiv.org/abs/2506.21150)
**中文标题：基于树结构的语义损失：在稀疏标注大规模多类高光谱分割中的应用**

*Junwen Wang,Oscar Maccormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren*

主要分类: cs.CV

摘要简述: 本文提出两种基于树结构的语义损失函数，用于稀疏标注的大规模多类高光谱分割任务，通过利用标签空间的层次结构提升性能，并在实验中达到最先进水平。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱成像（HSI）在手术应用中潜力巨大，但现有学习方法对所有错误等同惩罚，未能利用标签空间的语义层次结构。本文旨在通过树状标签组织改进分割性能。

研究方法: 提出两种基于树结构的语义损失函数，结合稀疏标注训练方法，利用标签的层次关系优化模型。

研究结果: 实验表明，该方法在包含107个类别的稀疏标注HSI数据集上达到最先进性能，并能有效检测分布外像素。

研究结论: 树状语义损失函数显著提升了稀疏标注多类分割任务的性能，同时不影响分布内像素的分割效果。

中文摘要: 高光谱成像（HSI）在手术应用中展现出巨大潜力，能够揭示肉眼无法察觉的生物组织细微差异。目前正在通过精细化标注训练视觉系统区分大量细微变化的类别。然而，生物医学分割任务中常用的学习方法对所有错误等同惩罚，未能利用标签空间的语义关系。本文提出两种基于树状标签层次结构的语义损失函数，并将其与稀疏、无背景标注的训练方法结合。大量实验表明，所提方法在包含107个类别的稀疏标注HSI数据集上达到最先进性能，且能有效检测分布外像素，同时不影响分布内像素的分割效果。

</details>


### [100] [Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI with Noisy Labels](https://arxiv.org/abs/2506.21151)
**中文标题：基于噪声标签的心脏MRI心肌瘢痕分割的鲁棒深度学习方法**

*Aida Moafi,Danial Moafi,Evgeny M. Mirkes,Gerry P. McCann,Abbas S. Alatrany,Jayanth R. Arnold,Mostafa Mehdipour Ghazi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的鲁棒方法，用于心脏MRI中心肌瘢痕的自动分割，特别针对标签噪声、数据异质性和类别不平衡问题，通过KL损失和数据增强优化模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 心肌瘢痕的准确分割对临床评估和治疗规划至关重要，但现有方法面临标签噪声、数据异质性和类别不平衡的挑战，因此需要一种更鲁棒的自动化解决方案。

研究方法: 通过微调最先进的深度学习模型，结合Kullback-Leibler损失函数和大量数据增强技术，解决了标签噪声、数据异质性和类别不平衡问题。

研究结果: 该方法在急性和慢性病例中均表现出色，能够生成准确且平滑的分割结果，优于nnU-Net等现有模型，并在分布外测试集上展现了强大的泛化能力。

研究结论: 该研究为心肌瘢痕的自动化量化提供了可靠基础，并推动了深度学习在心脏影像中的广泛应用。

中文摘要: 心脏MRI中心肌瘢痕的准确分割对临床评估和治疗规划至关重要。本研究提出了一种鲁棒的深度学习流程，通过微调最先进的模型实现全自动心肌瘢痕检测与分割。该方法通过使用Kullback-Leibler损失和大量数据增强，明确解决了半自动标注带来的标签噪声、数据异质性和类别不平衡问题。我们在急性和慢性病例中评估了模型的性能，并展示了其在噪声标签下仍能生成准确且平滑分割结果的能力。特别是，我们的方法优于nnU-Net等现有模型，并在分布外测试集上表现出强大的泛化能力，凸显了其在不同成像条件和临床任务中的鲁棒性。这些结果为自动化心肌瘢痕量化奠定了可靠基础，并支持深度学习在心脏影像中的更广泛应用。

</details>


### [101] [Geometry and Perception Guided Gaussians for Multiview-consistent 3D Generation from a Single Image](https://arxiv.org/abs/2506.21152)
**中文标题：基于几何与感知引导的高斯方法：从单张图像生成多视角一致的3D对象**

*Pufan Li,Bi'an Du,Wei Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种结合几何和感知先验的方法，从单张图像生成多视角一致的3D对象，无需额外训练模型，显著提升了重建的几何细节和多视角一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法从单视图图像生成3D对象时，常因依赖预训练的2D扩散模型或直接生成3D信息而导致多视角一致性差和几何细节不足。本文旨在解决这些问题，提出一种无需额外训练的方法，结合几何和感知先验，生成更高质量的3D对象。

研究方法: 方法通过三个高斯分支（几何先验、感知先验和高斯噪声）初始化，几何先验捕捉粗略3D形状，感知先验利用预训练的2D扩散模型增强多视角信息。通过几何和感知先验的交互优化3D高斯分支，并采用基于重投影的策略增强深度一致性。

研究结果: 实验结果表明，该方法在3D重建和新视角合成方面优于现有方法，生成了更高保真度和一致性的3D对象。

研究结论: 本文提出的方法通过结合几何和感知先验，显著提升了从单张图像生成3D对象的质量和多视角一致性，为3D生成领域提供了新的解决方案。

中文摘要: 从单视图图像生成逼真的3D对象需要具备自然外观、3D一致性以及对未见区域的多重合理推断能力。现有方法通常依赖于微调预训练的2D扩散模型或通过快速网络推断或3D高斯泼溅直接生成3D信息，但其结果普遍存在多视角一致性差和几何细节不足的问题。为解决这些问题，我们提出了一种无需额外模型训练的新方法，无缝结合几何和感知先验，从单张图像重建详细的3D对象。具体而言，我们训练了三个不同的高斯分支，分别从几何先验、感知先验和高斯噪声初始化。几何先验捕捉粗略的3D形状，而感知先验利用预训练的2D扩散模型增强多视角信息。随后，通过几何和感知先验之间的交互优化3D高斯分支，并通过基于重投影的策略增强深度一致性。实验表明，我们的方法在3D重建和新视角合成方面优于现有方法，生成了更高保真度的重建结果，展示了鲁棒且一致的3D对象生成能力。

</details>


### [102] [Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition](https://arxiv.org/abs/2506.21165)
**中文标题：基于拓扑感知建模的无监督仿真到现实点云识别**

*Longkun Zou,Kangjun Liu,Ke Chen,Kailing Guo,Kui Jia,Yaowei Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于拓扑感知建模（TAM）的无监督仿真到现实点云识别方法，通过利用全局空间拓扑和局部几何特征的拓扑关系，结合自监督学习和自训练策略，有效缩小了仿真与真实数据之间的领域差距。


<details>
  <summary>详细信息</summary>
研究动机: 由于数据采集方式的差异，仿真数据与真实数据之间存在显著的几何变化，导致点分类器的泛化能力受限。现有的无监督领域适应（UDA）方法因缺乏鲁棒的、领域不敏感的描述符而难以应对这一问题。

研究方法: 提出了一种拓扑感知建模（TAM）框架，通过全局空间拓扑和局部几何特征的拓扑关系建模，结合自监督学习任务和跨域对比学习的自训练策略，减少噪声伪标签的影响。

研究结果: 在三个公开的Sim2Real基准测试中，TAM框架表现优于现有方法，验证了其有效性。

研究结论: TAM框架通过拓扑感知建模和自训练策略，显著提升了仿真到现实点云识别的性能，为领域适应问题提供了新的解决方案。

中文摘要: 学习3D物体形状点集的语义表示常因数据采集方法的差异而面临显著几何变化的挑战。通常，训练数据由点模拟器生成，而测试数据则由不同的3D传感器采集，导致仿真到现实（Sim2Real）领域差距，限制了点分类器的泛化能力。现有的无监督领域适应（UDA）技术因缺乏鲁棒的、领域不敏感的描述符而难以应对这一差距，导致对源域有限语义模式的过拟合。为解决这一问题，我们提出了一种新颖的拓扑感知建模（TAM）框架，用于对象点云的Sim2Real UDA。我们的方法通过利用全局空间拓扑（以低频、高频3D结构为特征）和通过自监督学习任务建模局部几何特征的拓扑关系，缩小了领域差距。此外，我们提出了一种结合跨域对比学习和自训练的高级自训练策略，有效减少了噪声伪标签的影响，增强了适应过程的鲁棒性。在三个公开的Sim2Real基准测试上的实验结果验证了TAM框架的有效性，在所有评估任务中均优于现有方法。本工作的源代码将在https://github.com/zou-longkun/TAG.git上提供。

</details>


### [103] [Task-Aware KV Compression For Cost-Effective Long Video Understanding](https://arxiv.org/abs/2506.21184)
**中文标题：面向任务感知的KV压缩：一种经济高效的长视频理解方法**

*Minghao Qin,Yan Shu,Peitian Zhang,Kun Lun,Huaying Yuan,Juenjie Zhou,Shitao Xiao,Bo Zhao,Zheng Liu*

主要分类: cs.CV

摘要简述: 本文提出Video-X^2L，通过双级KV压缩和选择性KV重加载，高效保留长视频理解任务中的关键信息，显著降低计算成本并优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 长视频理解（LVU）对现有多模态大语言模型（MLLMs）计算成本过高，现有KV压缩方法在高压缩比下信息损失严重，亟需一种高效且任务感知的压缩方案。

研究方法: Video-X^2L采用双级KV压缩（生成低压缩和高压缩KV）和选择性KV重加载（解码阶段动态选择KV），无需额外训练且兼容现有MLLMs。

研究结果: 在VideoMME、MLVU等基准测试中，Video-X^2L显著优于现有KV压缩方法，同时大幅节省计算成本。

研究结论: Video-X^2L通过任务感知的KV压缩策略，实现了长视频理解的高效与性能平衡，为实际应用提供了可行方案。

中文摘要: 长视频理解（LVU）对现有多模态大语言模型（MLLMs）仍是一个严峻挑战，主要源于高昂的计算成本。现有KV压缩方法在高压缩比下常导致显著信息丢失。本文提出Video-X^2L，通过双级KV压缩和选择性KV重加载，灵活保留各LVU任务的关键视频信息。Video-X^2L包含两项核心操作：1）双级KV压缩，在MLLM预填充阶段生成低压缩KV（L-KVs）以捕捉细粒度细节，高压缩KV（H-KVs）提供紧凑表示；2）选择性KV重加载，在解码阶段动态加载L-KVs至关键视频片段，其余使用H-KVs，确保任务信息充分利用且整体紧凑。Video-X^2L无需额外训练，兼容现有KV可压缩MLLMs。实验表明，在VideoMME、MLVU等基准测试中，Video-X^2L以显著优势超越现有方法，同时大幅节省计算成本。

</details>


### [104] [Out-of-Distribution Semantic Occupancy Prediction](https://arxiv.org/abs/2506.21185)
**中文标题：离群分布语义占用预测**

*Yuheng Zhang,Mengfei Duan,Kunyu Peng,Yuhang Wang,Ruiping Liu,Fei Teng,Kai Luo,Zhiyong Li,Kailun Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种用于3D语义占用预测的离群分布（OoD）检测方法，通过合成异常注入和几何-语义融合框架OccOoD，显著提升了OoD检测性能，同时保持了占用预测的竞争力。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D语义占用预测方法主要关注分布内场景，对离群分布（OoD）对象和长尾分布敏感，可能导致未检测到的异常和误判，带来安全隐患。本文旨在解决这一问题。

研究方法: 提出合成异常注入管道（Synthetic Anomaly Integration Pipeline）生成数据集VAA-KITTI和VAA-KITTI-360，并设计OccOoD框架，通过Voxel-BEV渐进融合（VBPF）和基于RWKV的分支增强几何-语义融合，实现OoD检测。

研究结果: OccOoD在1.2米区域内实现了67.34%的AuROC和29.21%的AuPRCr，达到OoD检测的先进水平，同时保持了占用预测的竞争力。

研究结论: 本文提出的OccOoD框架和合成数据集有效提升了3D语义占用预测中的OoD检测能力，为自动驾驶安全提供了重要支持。

中文摘要: 3D语义占用预测对自动驾驶至关重要，提供了密集且语义丰富的环境表示。然而，现有方法主要关注分布内场景，对离群分布（OoD）对象和长尾分布敏感，增加了未检测异常和误判的风险，带来安全隐患。为解决这些问题，我们提出了离群分布语义占用预测，专注于3D体素空间中的OoD检测。为填补数据集空白，我们设计了合成异常注入管道，在保持真实空间和遮挡模式的同时注入合成异常，生成了VAA-KITTI和VAA-KITTI-360两个数据集。我们提出了OccOoD框架，将OoD检测集成到3D语义占用预测中，通过Voxel-BEV渐进融合（VBPF）和基于RWKV的分支增强几何-语义融合。实验结果表明，OccOoD在1.2米区域内实现了67.34%的AuROC和29.21%的AuPRCr，达到OoD检测的先进水平，同时保持了占用预测的竞争力。数据集和源代码将在https://github.com/7uHeng/OccOoD公开。

</details>


### [105] [GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding](https://arxiv.org/abs/2506.21188)
**中文标题：GroundFlow：一种用于3D点云序列定位时序推理的插件模块**

*Zijun Lin,Shuting He,Cheston Tan,Bihan Wen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为GroundFlow的插件模块，用于在3D点云序列定位任务中进行时序推理，显著提升了现有3D视觉定位方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D视觉定位方法将多步骤文本指令视为整体，未能提取每一步的时序信息，而SG3D任务中的指令常包含代词（如“它”、“这里”），需要模型理解上下文并从历史步骤中检索相关信息。现有方法因缺乏有效的历史信息收集模块，难以适应SG3D任务。

研究方法: 提出GroundFlow模块，通过选择性提取短期和长期步骤信息，结合当前指令的相关性，实现对历史信息的全面利用，并保持时序理解优势。

研究结果: 在SG3D基准测试中，GroundFlow显著提升了基线方法的任务准确率（+7.5%和+10.2%），甚至优于在多数据集上预训练的3D大型语言模型。

研究结论: GroundFlow为现有3D视觉定位模型引入了时序推理能力，在SG3D基准测试中实现了最先进的性能。

中文摘要: 3D点云序列定位（SG3D）是指通过遵循日常活动的详细步骤文本指令来定位对象序列。当前的3D视觉定位（3DVG）方法将多步骤文本指令视为整体，未提取每一步的时序信息。然而，SG3D中的指令常包含“它”、“这里”等代词以使语言表达简洁，这要求定位方法理解上下文并从历史步骤中检索相关信息。由于缺乏有效的历史信息收集模块，现有3DVG方法在适应SG3D任务时面临挑战。为此，我们提出GroundFlow——一种用于3D点云序列定位时序推理的插件模块。实验表明，GroundFlow显著提升了3DVG基线方法的任务准确率（+7.5%和+10.2%），甚至优于在多数据集上预训练的3D大型语言模型。此外，我们根据当前指令的相关性选择性提取短期和长期步骤信息，使GroundFlow能全面利用历史信息并在步骤增加时保持时序理解优势。总体而言，我们的工作为现有3DVG模型引入了时序推理能力，并在SG3D基准测试中实现了最先进的性能。

</details>


### [106] [Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation](https://arxiv.org/abs/2506.21198)
**中文标题：解锁约束：无源遮挡感知无缝分割**

*Yihong Cao,Jiaming Zhang,Xu Zheng,Hao Shi,Kunyu Peng,Hang Liu,Kailun Yang,Hui Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需源数据的全景图像分割方法UNLOCK，通过Omni伪标签学习和Amodal上下文学习模块，实现了360度视角覆盖和遮挡感知推理，性能媲美依赖源数据的方法。


<details>
  <summary>详细信息</summary>
研究动机: 全景图像处理面临失真、遮挡和标注不足等挑战，现有方法需依赖源数据。本文旨在解决这些问题，提出更实用的无源数据任务SFOASS及其解决方案UNLOCK。

研究方法: UNLOCK包含两个关键模块：Omni伪标签学习和Amodal驱动的上下文学习，无需源数据或目标标签即可适应，提升模型的分割能力。

研究结果: 实验表明，UNLOCK在mAAP和mAP上分别达到10.9和11.6，mAPQ比仅使用源数据的方法提升+4.3，性能媲美依赖源数据的方法。

研究结论: UNLOCK为无源数据全景图像分割提供了高效解决方案，性能优越，代码和数据将公开。

中文摘要: 全景图像处理对全上下文感知至关重要，但面临失真、视角遮挡和标注有限等约束。以往的无监督域适应方法将知识从标注的针孔数据迁移到未标注的全景图像，但需要源针孔数据。为解决这些问题，我们提出了一种更实用的任务——无源遮挡感知无缝分割（SFOASS），并提出了其首个解决方案UNLOCK。UNLOCK包含两个关键模块：Omni伪标签学习和Amodal驱动的上下文学习。在不依赖源数据或目标标签的情况下，该框架提升了模型的分割能力，实现360度视角覆盖和遮挡感知推理。此外，我们通过真实到真实和合成到真实的适应设置对SFOASS任务进行了基准测试。实验结果表明，我们的无源方法性能与依赖源数据的方法相当，mAAP和mAP分别达到10.9和11.6，mAPQ比仅使用源数据的方法绝对提升+4.3。所有数据和代码将在https://github.com/yihong-97/UNLOCK公开。

</details>


### [107] [MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](https://arxiv.org/abs/2506.21199)
**中文标题：MedPrompt：基于权重路由的LLM-CNN融合框架用于医学图像分割与分类**

*Shadman Sobhan,Kazi Abrar Mahmud,Abduz Zami*

主要分类: cs.CV

摘要简述: MedPrompt是一个结合大型语言模型（LLM）和卷积神经网络（CNN）的统一框架，用于医学图像分割和分类。它通过动态路由任务特定权重实现灵活性和可扩展性，在19个公共数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前医学图像分析系统通常是任务特定的，缺乏灵活性，无法支持用户自定义工作流。为解决这些问题，作者提出了MedPrompt框架。

研究方法: MedPrompt结合了少样本提示的大型语言模型（Llama-4-17B）用于高级任务规划，以及模块化卷积神经网络（DeepFusionLab）用于低级图像处理。LLM解释用户指令并生成结构化输出来动态路由任务特定权重。

研究结果: MedPrompt在19个公共数据集上评估，覆盖12个任务和5种成像模态，实现了97%的端到端正确率，平均推理延迟为2.5秒。DeepFusionLab在分割（如肺部Dice 0.9856）和分类（如结核病F1 0.9744）任务中表现优异。

研究结论: MedPrompt通过结合LLM的可解释性和模块化CNN的效率，实现了可扩展的、提示驱动的医学图像分析。

中文摘要: 当前的医学图像分析系统通常是任务特定的，需要为分类和分割分别训练模型，且缺乏支持用户自定义工作流的灵活性。为解决这些问题，我们提出了MedPrompt，一个统一的框架，结合了少样本提示的大型语言模型（Llama-4-17B）用于高级任务规划，以及模块化卷积神经网络（DeepFusionLab）用于低级图像处理。LLM解释用户指令并生成结构化输出来动态路由任务特定预训练权重。这种权重路由方法避免了在添加新任务时重新训练整个框架，仅需任务特定权重，从而提高了可扩展性和部署效率。我们在19个公共数据集上评估了MedPrompt，覆盖12个任务和5种成像模态。该系统在解释和执行提示驱动指令时实现了97%的端到端正确率，平均推理延迟为2.5秒，适合近实时应用。DeepFusionLab在分割任务（如肺部Dice 0.9856）和分类任务（如结核病F1 0.9744）中表现优异。总体而言，MedPrompt通过结合LLM的可解释性和模块化CNN的效率，实现了可扩展的、提示驱动的医学图像分析。

</details>


### [108] [BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models](https://arxiv.org/abs/2506.21209)
**中文标题：BitMark无限：比特自回归图像生成模型的水印技术**

*Louis Kerner,Michel Meintz,Bihe Zhao,Franziska Boenisch,Adam Dziedzic*

主要分类: cs.CV

摘要简述: 本文提出BitMark，一种针对Infinity等比特自回归图像生成模型的鲁棒水印框架，旨在防止模型崩溃。通过在生成过程中嵌入比特级水印，BitMark保持视觉保真度和生成速度，同时抵抗多种去除技术，并具有放射性传播特性。


<details>
  <summary>详细信息</summary>
研究动机: 随着Infinity等文本到图像模型的快速发展，其生成的图像可能被重复用作训练数据，导致模型性能逐渐退化（模型崩溃）。水印技术可帮助识别生成内容，但现有方法难以在比特自回归模型中实现鲁棒性和放射性传播。

研究方法: BitMark在Infinity的图像生成过程中，直接在比特级别的令牌流中嵌入多尺度水印。该方法通过微妙影响比特位，保持视觉质量和生成速度，同时确保水印对多种去除技术具有鲁棒性，并能放射性传播到后续模型生成的图像中。

研究结果: 实验表明，BitMark在保持视觉保真度和生成速度的同时，能够抵抗多种水印去除技术。此外，水印具有放射性，即使对扩散或自回归模型进行微调，水印仍可检测。

研究结论: BitMark为图像生成模型提供了一种防止模型崩溃的可靠方法，通过比特级水印实现生成内容的可检测性，并具有放射性传播特性。

中文摘要: Infinity等最先进的文本到图像模型能以前所未有的速度生成逼真图像。这些模型基于离散令牌集的比特自回归方式运行，令牌集规模近乎无限。然而，其强大的生成能力伴随着风险：随着生成内容在互联网上的泛滥，它们可能被爬取并重新用作训练数据，甚至被同一模型使用。这种现象已被证明会导致模型崩溃，即重复使用生成内容训练模型（尤其是自身早期版本）会导致性能逐渐退化。水印是一种有前景的缓解策略，它能在生成图像中嵌入人眼不可见但可检测的信号，从而识别生成内容。本文提出BitMark，一种针对Infinity的鲁棒比特水印框架。该方法在Infinity的图像生成过程中，直接在比特级别的令牌流中嵌入多尺度水印。我们的比特水印通过微妙影响比特位，保持视觉保真度和生成速度，同时对多种去除技术具有鲁棒性。此外，它具有高放射性，即当水印生成图像用于训练其他图像生成模型时，第二个模型的输出也会携带水印。即使仅对扩散或图像自回归模型进行微调，放射性痕迹仍可检测。总体而言，我们的方法通过可靠检测生成内容，为防止图像生成模型的崩溃提供了原则性解决方案。

</details>


### [109] [ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.21233)
**中文标题：ReME：一种数据中心化框架用于无需训练的开集词汇分割**

*Xiwei Xuan,Ziquan Deng,Kwan-Liu Ma*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ReME的数据中心化框架，用于无需训练的开集词汇分割（OVS），通过构建高质量的参考集和简单的相似性检索，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有无需训练的开集词汇分割方法依赖预训练模型的注意力机制或生成合成数据，但其性能受限于模型能力或参考集质量。本文发现高质量参考集对提升分割效果至关重要，因此提出了一种以数据质量为核心的解决方案。

研究方法: ReME框架包括一个数据管道，用于构建具有良好配对的片段-文本嵌入的参考集，以及一个基于相似性的简单检索方法，以揭示数据质量对分割效果的关键影响。

研究结果: 在十个基准数据集上的广泛评估表明，ReME优于所有现有的无需训练OVS方法，突显了数据中心化设计在无需训练情况下提升OVS性能的重要性。

研究结论: 本文通过强调数据质量的重要性，提出了一种简单而高效的框架，显著提升了无需训练的开集词汇分割性能，为未来研究提供了新的方向。

中文摘要: 无需训练的开集词汇语义分割（OVS）旨在无需昂贵的模型微调情况下，根据一组任意文本类别分割图像。现有方法通常探索预训练模型（如CLIP）的注意力机制，或生成合成数据并设计复杂的检索过程来执行OVS。然而，其性能受限于依赖模型的能力或参考集的次优质量。本文研究了这一具有挑战性的密集场景理解任务中被忽视的数据质量问题，并发现高质量参考集能显著提升无需训练OVS的效果。基于这一观察，我们提出了一种以数据质量为导向的框架，包括一个数据管道用于构建具有良好配对的片段-文本嵌入的参考集，以及一个简单的基于相似性的检索方法，以揭示数据的本质作用。值得注意的是，在十个基准数据集上的广泛评估表明，我们的方法优于所有现有的无需训练OVS方法，突显了数据中心化设计在无需训练情况下推动OVS发展的重要性。我们的代码可在https://github.com/xiweix/ReME获取。

</details>


### [110] [Real-Time ESFP: Estimating, Smoothing, Filtering, and Pose-Mapping](https://arxiv.org/abs/2506.21234)
**中文标题：实时ESFP：估计、平滑、滤波与姿态映射**

*Qifei Cui,Yuang Zhou,Ruichen Deng*

主要分类: cs.CV

摘要简述: 本文提出ESFP，一种端到端流水线，将单目RGB视频转换为低成本4自由度桌面机械臂的可执行关节轨迹。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发一种高效方法，将视频中的动作实时转换为机械臂的可执行轨迹，适用于低成本设备。

研究方法: ESFP包含四个模块：(1) 估计：ROMP将每帧图像提升为24关节3D骨架；(2) 平滑：HPSTM（自注意力序列转换器）结合长时域上下文和可微分前向运动学解码器，确保骨骼长度恒定和解剖合理性；(3) 滤波：根据HPSTM的不确定性估计对轨迹进行方差加权，抑制噪声；(4) 姿态映射：几何重定向层将肩-肘-腕三元组转换为机械臂的极坐标工作空间，保留手腕方向。

研究结果: ESFP能够高效地将视频动作转换为机械臂轨迹，同时保持动作的平滑性和准确性。

研究结论: ESFP为低成本机械臂提供了一种实时动作转换解决方案，具有实际应用潜力。

中文摘要: 本文提出ESFP，一种端到端流水线，将单目RGB视频转换为低成本4自由度桌面机械臂的可执行关节轨迹。ESFP包含四个顺序模块：(1) 估计：ROMP将每帧图像提升为24关节3D骨架；(2) 平滑：提出的HPSTM（一种自注意力序列转换器）结合长时域上下文和可微分前向运动学解码器，确保骨骼长度恒定和解剖合理性，同时预测关节均值和完整协方差；(3) 滤波：根据HPSTM的不确定性估计对根归一化轨迹进行方差加权，抑制残余噪声；(4) 姿态映射：几何重定向层将肩-肘-腕三元组转换为机械臂的极坐标工作空间，保留手腕方向。

</details>


### [111] [DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation](https://arxiv.org/abs/2506.21237)
**中文标题：DiMPLe —— 解耦多模态提示学习：通过不变与虚假特征分离增强分布外对齐**

*Umaima Rahman,Mohammad Yaqub,Dwarikanath Mahapatra*

主要分类: cs.CV

摘要简述: DiMPLe提出了一种新型多模态提示学习方法，通过分离视觉和语言模态中的不变特征与虚假特征，提升分布外对齐能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在多模态学习中，视觉数据中的虚假相关性常导致分布外性能下降。现有方法仅关注图像特征，未能有效分离跨模态特征。DiMPLe旨在解决这一问题，通过分离不变与虚假特征，提升模型对新类别和分布变化的泛化能力。

研究方法: DiMPLe结合了三个关键目标：(1) 最小化不变特征与虚假特征的互信息，(2) 对虚假特征进行正则化，(3) 对不变特征进行对比学习。该方法在多模态学习中分离特征并保持对齐一致性。

研究结果: 实验表明，DiMPLe在11个数据集上平均性能优于CoOp-OOD，基础类别准确率提升15.27，新类别准确率提升44.31。

研究结论: DiMPLe通过分离不变与虚假特征，显著提升了多模态学习中的分布外对齐能力，为跨模态泛化提供了新思路。

中文摘要: 我们提出了DiMPLe（解耦多模态提示学习），一种在多模态学习中分离视觉和语言模态中不变与虚假特征的新方法。视觉数据中的虚假相关性常阻碍分布外性能。与仅关注图像特征的现有方法不同，DiMPLe在模态内和跨模态中分离特征，同时保持对齐一致性，从而更好地泛化到新类别并对分布变化具有鲁棒性。我们的方法结合了三个关键目标：(1) 最小化不变与虚假特征的互信息，(2) 对虚假特征进行正则化，(3) 对不变特征进行对比学习。大量实验表明，DiMPLe在11个数据集上的平均性能优于CoOp-OOD，基础类别准确率绝对提升15.27，新类别准确率绝对提升44.31。

</details>


### [112] [Temporal Rate Reduction Clustering for Human Motion Segmentation](https://arxiv.org/abs/2506.21249)
**中文标题：基于时间速率降低聚类的人体运动分割方法**

*Xianghan Meng,Zhengyu Tong,Zhiyuan Huang,Chun-Guang Li*

主要分类: cs.CV

摘要简述: 提出了一种名为Temporal Rate Reduction Clustering（TR²C）的新方法，用于解决复杂背景下的人体运动分割问题，通过联合学习结构化表示和亲和力，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人体运动分割方法主要基于子空间聚类，假设高维时间数据符合子空间联合分布，但在复杂背景和复杂人体运动下，这一假设可能不成立。因此，需要一种更有效的方法来适应实际场景。

研究方法: 提出了TR²C方法，通过联合学习结构化表示和亲和力，确保时间一致性并符合子空间联合分布，从而更好地分割视频帧序列。

研究结果: 在五个基准数据集上进行了广泛实验，使用不同特征提取器均取得了最先进的性能。

研究结论: TR²C方法在复杂背景下的人体运动分割任务中表现优异，验证了其有效性。

中文摘要: 人体运动分割（HMS）旨在将视频划分为不重叠的人体运动片段，近年来受到越来越多的研究关注。现有的HMS方法主要基于子空间聚类，其假设高维时间数据符合子空间联合分布（UoS）。然而，在复杂背景和复杂人体运动的视频中，帧可能并不完全符合UoS分布。本文提出了一种名为Temporal Rate Reduction Clustering（TR²C）的新方法，通过联合学习结构化表示和亲和力来分割视频帧序列。具体而言，TR²C学习到的结构化表示具有时间一致性，并且与UoS结构对齐，非常适合HMS任务。我们在五个基准HMS数据集上进行了广泛实验，使用不同特征提取器均取得了最先进的性能。

</details>


### [113] [DuET: Dual Incremental Object Detection via Exemplar-Free Task Arithmetic](https://arxiv.org/abs/2506.21260)
**中文标题：DuET：基于无示例任务算术的双增量目标检测**

*Munish Monga,Vishal Chudasama,Pankaj Wasnik,Biplab Banerjee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DuET的双增量目标检测方法，通过任务算术框架同时处理类别和域的变化，避免了灾难性遗忘和域适应问题，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现实中的目标检测系统（如自动驾驶和监控）需要持续学习新类别并适应环境变化。现有的类别增量目标检测（CIOD）和域增量目标检测（DIOD）方法仅解决单一问题，无法同时应对类别和域的变化。因此，本文提出双增量目标检测（DuIOD）及DuET框架，以更全面地满足实际需求。

研究方法: DuET基于任务算术框架，通过方向一致性损失（Directional Consistency Loss）缓解符号冲突，实现稳定的增量学习。该方法不依赖特定检测器，支持YOLO11和RT-DETR等模型作为实时增量检测器。

研究结果: 在Pascal Series和Diverse Weather Series数据集上的实验表明，DuET在Pascal Series（4任务）上实现了+13.12%的RAI提升，保留89.3%的Avg RI；在Diverse Weather Series（3任务）上实现了+11.39%的RAI提升，保留88.57%的Avg RI，优于现有方法。

研究结论: DuET通过任务算术框架和方向一致性损失，有效解决了类别和域增量学习的双重挑战，显著提升了检测性能，为实际应用提供了更灵活的解决方案。

中文摘要: 现实中的目标检测系统（如自动驾驶和监控）需要持续学习新类别并适应环境变化。现有方法（类别增量目标检测CIOD和域增量目标检测DIOD）仅解决单一问题：CIOD在未见域中表现不佳，DIOD在学习新类别时易发生灾难性遗忘，限制了其实际应用。为克服这些限制，我们提出了双增量目标检测（DuIOD），这是一种更实用的设置，可同时以无示例方式处理类别和域的变化。我们提出DuET，一种基于任务算术的模型融合框架，通过新颖的方向一致性损失（Directional Consistency Loss）缓解符号冲突，实现稳定的增量学习。与先前方法不同，DuET不依赖特定检测器，支持YOLO11和RT-DETR等模型作为实时增量检测器。为全面评估保留和适应能力，我们引入了保留-适应指数（RAI），将平均保留指数（Avg RI）和域适应的平均泛化指数结合为统一标准。在Pascal Series和Diverse Weather Series上的大量实验证明了DuET的有效性：在Pascal Series（4任务）上实现了+13.12%的RAI提升，保留89.3%的Avg RI；在Diverse Weather Series（3任务）上实现了+11.39%的RAI提升，保留88.57%的Avg RI，优于现有方法。

</details>


### [114] [Video Virtual Try-on with Conditional Diffusion Transformer Inpainter](https://arxiv.org/abs/2506.21270)
**中文标题：基于条件扩散变换器修复的视频虚拟试穿**

*Cheng Zou,Senlin Cheng,Bolei Xu,Dandan Zheng,Xiaobo Li,Jingdong Chen,Ming Yang*

主要分类: cs.CV

摘要简述: 本文提出ViTI方法，将视频虚拟试穿任务建模为条件视频修复任务，通过基于扩散变换器的3D时空注意力框架和多阶段训练，显著提升了时空一致性和细节保留能力。


<details>
  <summary>详细信息</summary>
研究动机: 视频虚拟试穿任务面临时空一致性和细节保留的双重挑战，现有基于图像的方法逐帧处理效果不佳，而现有扩散方法虽有所改进但仍存在不一致问题。本文旨在通过重新建模任务为视频修复问题，从根本上提升一致性。

研究方法: 提出ViTI方法，基于扩散变换器构建3D时空注意力框架，通过多阶段训练和掩码策略逐步适配视频服装修复任务，并引入服装条件确保细节符合预期。

研究结果: 实验表明，ViTI在定量和定性评估中均优于现有方法，显著提升了时空一致性和服装细节保留能力。

研究结论: ViTI通过将视频虚拟试穿任务重新建模为条件视频修复问题，结合扩散变换器和多阶段训练，有效解决了时空一致性和细节保留的挑战，为视频虚拟试穿提供了新思路。

中文摘要: 视频虚拟试穿旨在将服装自然地适配到目标人物的连续视频帧中。这是一项具有挑战性的任务，一方面输出视频需要具有良好的时空一致性，另一方面给定服装的细节需要在所有帧中保留良好。简单地逐帧使用基于图像的试穿方法会因严重不一致性而效果不佳。近期基于扩散的视频试穿方法虽然较少，但恰好采用了类似解决方案：在基于图像的试穿模型中插入时间注意力以适配视频试穿任务，虽有所改进但仍存在不一致性问题。本文提出ViTI（视频试穿修复器），将视频虚拟试穿任务建模为条件视频修复任务，与以往方法不同。通过这种方式，我们从视频生成问题而非基于图像的试穿问题出发，从一开始就具备更好的时空一致性。具体而言，首先基于扩散变换器构建具有完整3D时空注意力的视频修复框架，然后通过掩码策略和多阶段训练逐步适配视频服装修复任务。经过这些步骤，模型能够根据提示以良好的时空一致性修复掩码服装区域。最后，与其他试穿方法类似，添加服装条件以确保修复的服装外观和细节符合预期。定量和定性实验结果均表明，ViTI优于现有工作。

</details>


### [115] [WordCon: Word-level Typography Control in Scene Text Rendering](https://arxiv.org/abs/2506.21276)
**中文标题：WordCon：场景文本渲染中的词级排版控制**

*Wenda Shi,Yiren Song,Zihan Rao,Dengming Zhang,Jiaming Liu,Xingxing Zou*

主要分类: cs.CV

摘要简述: 论文提出WordCon方法，通过构建词级控制场景文本数据集和TIA框架，结合混合参数高效微调技术，实现图像生成中的精确词级排版控制，并在艺术文本渲染、文本编辑等任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前图像生成中词级排版控制仍具挑战性，论文旨在解决这一问题，提升文本到图像模型的精确控制能力。

研究方法: 论文构建了词级控制场景文本数据集，提出TIA框架利用跨模态对应关系增强模型训练，并设计WordCon方法，通过重参数化关键参数提升效率和可移植性，同时应用掩码损失和联合注意力损失增强可控性。

研究结果: 定性和定量实验表明，该方法在艺术文本渲染、文本编辑等任务中优于现有技术。

研究结论: WordCon方法在词级排版控制上表现出色，数据集和代码将为学术研究提供支持。

中文摘要: 在生成的图像中实现精确的词级排版控制仍是一个持续的挑战。为此，我们新构建了一个词级控制的场景文本数据集，并提出了文本-图像对齐（TIA）框架。该框架利用基础模型提供的文本与局部图像区域的跨模态对应关系，以增强文本到图像（T2I）模型的训练。此外，我们提出了WordCon，一种混合参数高效微调（PEFT）方法。WordCon通过重参数化选择性关键参数，提高了效率和可移植性，使其能够无缝集成到多种流程中，包括艺术文本渲染、文本编辑和图像条件文本渲染。为进一步增强可控性，我们在潜在层面应用掩码损失，引导模型专注于学习图像中的文本区域，同时联合注意力损失提供特征级监督，促进不同词之间的解耦。定性和定量结果均表明，我们的方法优于现有技术。数据集和源代码将供学术使用。

</details>


### [116] [HieraSurg: Hierarchy-Aware Diffusion Model for Surgical Video Generation](https://arxiv.org/abs/2506.21287)
**中文标题：HieraSurg：层次感知扩散模型用于手术视频生成**

*Diego Biagini,Nassir Navab,Azade Farshad*

主要分类: cs.CV

摘要简述: HieraSurg是一种层次感知的扩散模型，用于生成手术视频。它通过两阶段模型结合手术阶段和语义分割信息，显著提升了视频生成的质量和一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有手术视频生成方法多为无条件生成，缺乏对手术动作和阶段的语义理解，导致生成的视频与实际情况不一致。HieraSurg旨在通过层次化建模解决这一问题。

研究方法: HieraSurg采用两阶段扩散模型：第一阶段预测粗粒度语义变化（如分割图），第二阶段结合细粒度视觉特征生成最终视频。模型利用手术阶段、动作三元组和全景分割图等多层次信息。

研究结果: 在胆囊切除术视频生成任务中，HieraSurg在定量和定性上均显著优于现有方法，能够生成更高帧率的视频，并在提供现有分割图时表现出精细的语义一致性。

研究结论: HieraSurg通过层次化建模和多阶段生成，显著提升了手术视频的真实性和实用性，展示了在手术模拟中的潜在应用价值。

中文摘要: 手术视频合成已成为扩散模型在通用视频生成领域取得成功后的一个新兴研究方向。尽管现有方法能够生成高质量视频，但多为无条件生成，无法保持与手术动作和阶段的一致性，缺乏对手术的语义理解和细粒度指导。为此，我们提出了HieraSurg，一种层次感知的手术视频生成框架，包含两个专用扩散模型。给定手术阶段和初始帧，HieraSurg首先通过分割预测模型预测未来的粗粒度语义变化。随后，第二阶段模型将这些时序分割图与细粒度视觉特征结合，生成最终视频，实现有效的纹理渲染和语义信息整合。我们的方法利用了手术阶段、动作三元组和全景分割图等多层次抽象信息。在胆囊切除术视频生成任务上的实验结果表明，该模型在定量和定性上均显著优于现有方法，展示了强大的泛化能力和生成高帧率视频的能力。特别是在提供现有分割图时，模型表现出精细的语义一致性，显示了其在实际手术应用中的潜力。

</details>


### [117] [Continual Self-Supervised Learning with Masked Autoencoders in Remote Sensing](https://arxiv.org/abs/2506.21312)
**中文标题：基于掩码自编码器的遥感持续自监督学习**

*Lars Möllenbrok,Behnood Rasti,Begüm Demir*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的持续自监督学习方法CoSMAE，通过数据混合和模型混合知识蒸馏，有效减少遥感图像任务中的灾难性遗忘问题，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有遥感领域的持续学习方法需要大量标注数据，成本高且不现实。为解决这一问题，本文提出了一种自监督学习方法，减少对标注数据的依赖。

研究方法: CoSMAE包含两部分：1) 数据混合，通过插值当前任务与先前任务的图像保留历史数据分布；2) 模型混合知识蒸馏，通过插值历史模型与当前模型的权重形成教师模型进行知识蒸馏。

研究结果: 实验表明，CoSMAE在MAE上的性能比现有持续学习方法提升了4.94%。

研究结论: CoSMAE通过数据与模型层面的正则化，显著提升了持续学习中的泛化能力并减少了灾难性遗忘风险。

中文摘要: 持续学习（CL）方法的发展在遥感（RS）领域受到广泛关注，其目标是从连续获取的训练数据中顺序学习新任务。现有的RS持续学习方法在学习新任务时，通过使用大量标注训练样本来增强对灾难性遗忘的鲁棒性，但这些样本的获取成本高且不总是可行。为解决这一问题，我们提出了一种新型的持续自监督学习方法，基于掩码自编码器（称为CoSMAE）。CoSMAE包含两部分：1) 数据混合，通过插值当前任务与先前任务的图像保留历史数据分布；2) 模型混合知识蒸馏，通过插值历史模型与当前模型的权重形成教师模型进行知识蒸馏。这两部分相互补充，在数据和模型层面正则化MAE，以提升跨任务的泛化能力并减少灾难性遗忘风险。实验结果表明，CoSMAE在MAE上的性能比现有持续学习方法提升了4.94%。我们的代码已公开：https://git.tu-berlin.de/rsim/CoSMAE。

</details>


### [118] [DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images](https://arxiv.org/abs/2506.21316)
**中文标题：DrishtiKon：面向文本丰富文档图像的多粒度视觉定位**

*Badri Vishal Kasuba,Parag Chaudhuri,Ganesh Ramakrishnan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DrishtiKon的多粒度视觉定位框架，用于提升文本丰富文档图像的视觉问答（VQA）系统的可解释性和可信度。该方法结合多语言OCR、大语言模型和区域匹配算法，实现了从块级到点级的精准答案定位，并在新基准测试中取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前文档智能和视觉问答系统在文本丰富的文档图像中缺乏有效的视觉定位方法，导致可解释性和可信度不足。本文旨在解决这一问题，通过多粒度定位提升系统性能。

研究方法: 方法整合了多语言OCR技术、大语言模型和创新的区域匹配算法，支持块级、行级、词级和点级的答案定位。同时，构建了一个包含多粒度人工标注的新基准测试集。

研究结果: 实验表明，该方法在视觉定位任务中达到了最优性能，其中行级粒度在精度和召回率之间取得了最佳平衡。消融研究验证了多块和多行推理的有效性。

研究结论: 本文提出的结构化对齐方法显著提升了文档理解系统的鲁棒性和可解释性，为实际文本场景中的应用提供了新思路。代码和数据集已开源。

中文摘要: 文本丰富文档图像中的视觉定位是文档智能和视觉问答（VQA）系统中一个关键但尚未充分探索的挑战。我们提出了DrishtiKon，一种多粒度视觉定位框架，旨在提升复杂多语言文档VQA的可解释性和可信度。该方法结合了强大的多语言OCR、大语言模型和一种新颖的区域匹配算法，能够在块级、行级、词级和点级精准定位答案范围。我们从CircularsVQA测试集中构建了一个新基准，提供了多粒度的人工验证标注。大量实验表明，我们的方法在视觉定位任务中达到了最优性能，其中行级粒度在精度和召回率之间取得了最佳平衡。消融研究进一步验证了多块和多行推理的优势。与领先的视觉语言模型的对比评估揭示了当前VLM在精确定位上的局限性，凸显了我们基于结构化对齐方法的有效性。这些发现为实际文本场景中更鲁棒和可解释的文档理解系统铺平了道路。代码和数据集已发布于https://github.com/kasuba-badri-vishal/DhrishtiKon。

</details>


### [119] [LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning](https://arxiv.org/abs/2506.21317)
**中文标题：LLaVA-Pose：通过关键点整合指令微调增强人体姿态与动作理解**

*Dewen Zhang,Tahir Hussain,Wangpeng An,Hayaru Shouno*

主要分类: cs.CV

摘要简述: 本文提出LLaVA-Pose，通过结合人体关键点与传统视觉特征生成专用视觉语言指令数据，显著提升模型在人体姿态和动作理解任务中的表现。实验结果显示，改进后的模型性能提升33.2%。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言模型在通用视觉理解任务中表现良好，但在涉及复杂人体姿态和动作的任务中表现不足，主要原因是缺乏针对性的视觉语言指令数据。

研究方法: 作者提出一种方法，通过整合人体关键点与传统视觉特征（如标题和边界框）生成专用数据集（200,328个样本），并基于此微调LLaVA-1.5-7B模型。同时，建立扩展人体姿态与动作理解基准（E-HPAUB）评估模型性能。

研究结果: 实验结果表明，改进后的LLaVA-Pose模型在E-HPAUB基准上性能提升33.2%，显著优于原始LLaVA-1.5-7B模型。

研究结论: 研究证实，整合关键点数据的多模态模型能有效提升对人体姿态和动作的理解能力，为相关任务提供了新的解决方案。

中文摘要: 当前的视觉语言模型（VLMs）在通用视觉理解任务中表现良好，但在处理与人体姿态和动作相关的复杂视觉任务时表现不佳，主要原因是缺乏专门的视觉语言指令数据。我们提出一种方法，通过将人体关键点与传统视觉特征（如标题和边界框）结合，生成此类数据，从而更精确地理解以人为中心的场景。我们的方法构建了一个包含200,328个样本的数据集，专门用于微调模型以处理以人为中心的任务，重点关注对话、详细描述和复杂推理三个领域。我们建立了扩展人体姿态与动作理解基准（E-HPAUB）以评估模型性能。使用该数据集对LLaVA-1.5-7B模型进行微调，并在基准上评估得到的LLaVA-Pose模型，取得了显著改进。实验结果显示，与原始LLaVA-1.5-7B模型相比，整体性能提升了33.2%。这些发现突出了关键点整合数据在增强多模态模型对人体中心视觉理解方面的有效性。代码可在https://github.com/Ody-trek/LLaVA-Pose获取。

</details>


### [120] [Holistic Surgical Phase Recognition with Hierarchical Input Dependent State Space Models](https://arxiv.org/abs/2506.21330)
**中文标题：基于分层输入依赖状态空间模型的全景手术阶段识别**

*Haoyang Wu,Tsun-Hsuan Wang,Mathias Lechner,Ramin Hasani,Jennifer A. Eckhoff,Paul Pak,Ozanan R. Meireles,Guy Rosman,Yutong Ban,Daniela Rus*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的分层输入依赖状态空间模型，用于手术视频的全局分析，解决了传统方法因视频过长而效率低下的问题。该方法结合局部和全局动态捕捉能力，显著提升了手术阶段识别的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 机器人辅助手术中的工作流分析对手术视频的全面分析至关重要，但手术视频的时长过长，传统基于Transformer的方法因二次注意力机制效率低下。因此，需要一种能够高效处理长视频并捕捉局部和全局动态的新方法。

研究方法: 提出了一种分层输入依赖状态空间模型，包含局部聚合状态空间模块和全局关系状态空间模块，分别捕捉局部细节和全局时间依赖。采用混合离散-连续监督策略，结合离散阶段标签和连续阶段进展信号进行训练。

研究结果: 实验表明，该方法在Cholec80、MICCAI2016和Heichole数据集上分别以+2.8%、+4.3%和+12.9%的显著优势超越了当前最优方法。

研究结论: 该方法通过分层状态空间模型和混合监督策略，显著提升了手术阶段识别的性能，为长视频分析提供了高效解决方案。

中文摘要: 手术工作流分析在机器人辅助手术中至关重要，但此类手术的时长较长，对全面视频分析提出了重大挑战。现有方法主要依赖Transformer模型，但其二次注意力机制限制了长手术视频的高效处理。本文提出了一种新颖的分层输入依赖状态空间模型，利用状态空间模型的线性缩放特性，实现对全长视频的决策，同时捕捉局部和全局动态。我们的框架包含一个时间一致的视觉特征提取器，将状态空间模型头附加到视觉特征提取器上以传播时间信息。该模型由两个关键模块组成：局部聚合状态空间模块，有效捕捉复杂局部动态；全局关系状态空间模块，建模整个视频的时间依赖关系。模型采用混合离散-连续监督策略训练，离散阶段标签和连续阶段进展信号通过网络传播。实验表明，我们的方法在Cholec80、MICCAI2016和Heichole数据集上分别以+2.8%、+4.3%和+12.9%的优势大幅超越当前最优方法。代码将在论文接受后公开。

</details>


### [121] [PanSt3R: Multi-view Consistent Panoptic Segmentation](https://arxiv.org/abs/2506.21348)
**中文标题：PanSt3R：多视角一致的全景分割**

*Lojze Zust,Yohann Cabon,Juliette Marrie,Leonid Antsfeld,Boris Chidlovskii,Jerome Revaud,Gabriela Csurka*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PanSt3R的统一方法，通过单次前向传播联合预测3D几何和多视角全景分割，避免了传统方法中依赖2D分割和测试时优化的不足，显著提升了效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常依赖2D全景分割和隐式几何表示（如NeRF）进行3D场景分割，但这种方法未能充分利用多视角间的空间关系，且需要计算密集的测试时优化。本文旨在提出一种更高效、更统一的方法来解决这一问题。

研究方法: PanSt3R基于MUSt3R（一种可扩展的多视角3D重建方法），通过增强语义感知和多视角全景分割能力，实现了3D几何和多视角分割的联合预测。此外，改进了传统的掩码合并方法，并提出了基于PanSt3R和3DGS的新视角预测方法。

研究结果: PanSt3R在多个基准测试中达到了最先进的性能，且计算速度比现有方法快几个数量级。

研究结论: PanSt3R是一种概念简单、快速且可扩展的方法，通过联合预测3D几何和多视角分割，显著提升了全景分割的效率和准确性。

中文摘要: 3D场景的全景分割（包括对场景密集3D重建中的对象实例进行分割和分类）是一个具有挑战性的问题，尤其是在仅依赖未标定2D图像的情况下。现有方法通常利用现成模型提取单帧2D全景分割，然后优化隐式几何表示（如NeRF）以整合和融合2D预测。我们认为，依赖2D全景分割来解决本质上是3D和多视角的问题可能不够理想，因为它未能充分利用多视角间的空间关系。此外，这些方法不仅需要相机参数，还需要对每个场景进行计算密集的测试时优化。本文提出了一种统一且集成的方法PanSt3R，通过单次前向传播联合预测3D几何和多视角全景分割，从而避免了测试时优化的需求。我们的方法基于3D重建的最新进展，特别是MUSt3R（一种可扩展的多视角DUSt3R版本），并通过增强语义感知和多视角全景分割能力进一步优化。我们还重新审视了传统的掩码合并方法，并提出了更合理的多视角分割处理流程。此外，我们提出了一种基于PanSt3R和普通3DGS的新视角预测方法。总体而言，PanSt3R概念简单、快速且可扩展，在多个基准测试中达到了最先进的性能，同时计算速度比现有方法快几个数量级。

</details>


### [122] [Generalizable Neural Electromagnetic Inverse Scattering](https://arxiv.org/abs/2506.21349)
**中文标题：通用神经电磁逆散射方法**

*Yizhe Cheng,Chunxun Tian,Haoru Wang,Wentao Zhu,Xiaoxuan Ma,Yizhou Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于物理驱动的通用框架，用于解决电磁逆散射问题（EISP），通过将问题重新表述为两阶段逆传输-散射过程，并利用诱导电流作为通用中间表示，显著提升了重建精度、泛化能力和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 电磁逆散射问题（EISP）在医学成像等应用中至关重要，但其固有的不适定性和高度非线性使其极具挑战性。现有方法（如Img-Interiors）需要针对特定案例优化，泛化能力差且无法处理稀疏发射器设置。本文旨在通过物理驱动的通用框架解决这些问题。

研究方法: 本文提出了一种两阶段框架：1）电流估计器学习诱导电流作为入射场和散射场之间的物理桥梁；2）介电常数求解器直接从估计的诱导电流计算相对介电常数。该框架支持数据驱动训练和通用前馈预测。

研究结果: 实验表明，该方法在重建精度、泛化能力和鲁棒性上均优于现有技术，尤其在稀疏发射器设置下表现优异。

研究结论: 本文为电磁逆散射问题提供了全新的物理驱动视角，显著提升了实际应用中的成本效益和可行性。

中文摘要: 解决电磁逆散射问题（EISP）在医学成像等应用中至关重要，其目标是从散射电磁场重建相对介电常数。这一逆过程具有固有的不适定性和高度非线性，极具挑战性。近期基于机器学习的方法Img-Interiors通过利用连续隐函数展示了良好效果，但需要针对特定案例优化，泛化能力差，且在稀疏发射器设置（如仅一个发射器）下失效。为解决这些限制，我们从物理驱动的角度重新审视EISP，将其重新表述为两阶段逆传输-散射过程。这一表述揭示了诱导电流作为一种通用中间表示，有效解耦了非线性散射过程与不适定逆问题。基于这一洞察，我们提出了首个通用物理驱动框架，包含电流估计器和介电常数求解器，以端到端方式工作。电流估计器显式学习诱导电流作为入射场与散射场之间的物理桥梁，而介电常数求解器直接从估计的诱导电流计算相对介电常数。这一设计支持数据驱动训练和对未见数据的通用前馈预测，同时保持对发射器稀疏性的强鲁棒性。大量实验表明，我们的方法在重建精度、泛化能力和鲁棒性上均优于现有技术。这项工作为电磁逆散射提供了全新的视角，是迈向低成本实用电磁成像解决方案的重要一步。

</details>


### [123] [ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models](https://arxiv.org/abs/2506.21356)
**中文标题：ShotBench：视觉语言模型中的专家级电影理解**

*Hongbo Liu,Jingwen He,Yi Jin,Dian Zheng,Yuhao Dong,Fan Zhang,Ziqi Huang,Yinan He,Yangguang Li,Weichao Chen,Yu Qiao,Wanli Ouyang,Shengjie Zhao,Ziwei Liu*

主要分类: cs.CV

摘要简述: 本文介绍了ShotBench，一个专为电影语言理解设计的综合基准测试，揭示了现有视觉语言模型在电影语法理解上的局限性，并提出了改进方法。


<details>
  <summary>详细信息</summary>
研究动机: 电影摄影是电影的基本视觉语言，用于传达叙事、情感和美学质量。然而，现有的视觉语言模型在理解电影语法方面的能力尚未得到充分探索和评估，这限制了AI在视频生成中的精确性。

研究方法: 研究团队构建了ShotBench，包含3.5k专家标注的QA对，涵盖8个关键电影摄影维度。此外，还开发了ShotQA数据集（70k QA对），并通过监督微调和Group Relative Policy Optimization训练了ShotVL模型。

研究结果: 评估24个领先视觉语言模型后发现，其平均准确率不足60%，尤其在细粒度视觉线索和复杂空间推理方面表现不佳。ShotVL显著优于现有模型，达到最新技术水平。

研究结论: ShotBench填补了电影语言理解领域的空白，ShotVL的成功展示了改进潜力。研究团队开源了模型、数据和代码，以推动AI驱动的电影理解和生成的发展。

中文摘要: 电影摄影作为电影的基本视觉语言，对传达叙事、情感和美学质量至关重要。尽管近期的视觉语言模型（VLMs）表现出强大的通用视觉理解能力，但其在理解单个镜头中隐含的微妙电影语法方面的熟练程度仍未被充分探索，且缺乏稳健的评估。这一关键空白限制了细粒度视觉理解和AI辅助视频生成的精确性。为解决这一问题，我们提出了\textbf{ShotBench}，一个专为电影语言理解设计的综合基准测试。它包含来自200多部知名（主要为奥斯卡提名）电影的3.5k专家标注QA对，涵盖8个关键电影摄影维度。我们对24个领先的VLMs进行评估，发现其存在显著局限性：即使表现最佳的模型平均准确率也不足60\%，尤其在细粒度视觉线索和复杂空间推理方面表现不佳。为促进该领域的进步，我们构建了\textbf{ShotQA}，一个包含约70k电影QA对的大规模多模态数据集。基于ShotQA，我们通过监督微调和Group Relative Policy Optimization开发了\textbf{ShotVL}。ShotVL在ShotBench上显著优于所有现有开源和专有模型，确立了新的\textbf{最新技术水平}。我们开源了模型、数据和代码，以推动AI驱动的电影理解和生成这一关键领域的快速发展。

</details>


### [124] [CoPa-SG: Dense Scene Graphs with Parametric and Proto-Relations](https://arxiv.org/abs/2506.21357)
**中文标题：CoPa-SG：基于参数化与原型关系的密集场景图**

*Julian Lorenz,Mrunmai Phatak,Robin Schön,Katja Ludwig,Nico Hörmann,Annemarie Friedrich,Rainer Lienhart*

主要分类: cs.CV

摘要简述: 本文提出CoPa-SG，一个高精度合成场景图数据集，并引入参数化关系和原型关系，以解决现有场景图数据不足的问题，同时提升场景理解和推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前场景图研究面临数据不足和标注不精确的问题，限制了场景理解的发展。本文旨在通过合成数据集和新型关系类型解决这些问题。

研究方法: 提出CoPa-SG数据集，包含精确标注的场景图和两种新型关系：参数化关系（如角度、距离）和原型关系（描述假设关系）。通过该数据集评估多种场景图生成模型，并展示其在规划和推理任务中的应用。

研究结果: 实验表明，CoPa-SG数据集能够显著提升场景图生成模型的性能，同时参数化关系和原型关系增强了场景理解和推理能力。

研究结论: CoPa-SG为场景图研究提供了高质量数据支持，新型关系类型进一步扩展了场景图的应用潜力，尤其在规划和推理任务中表现突出。

中文摘要: 二维场景图为场景理解提供了结构化和可解释的框架。然而，当前研究仍受限于缺乏精确的场景图数据。为突破这一数据瓶颈，我们提出了CoPa-SG，一个具有高精度标注和全面对象间关系注释的合成场景图数据集。此外，我们引入了参数化关系和原型关系这两种场景图的新基础概念。前者通过为关系附加角度或距离等参数，提供了比传统关系更细粒度的表示；后者则编码了场景图中的假设关系，描述了新对象加入场景时可能形成的关系。利用CoPa-SG，我们比较了多种场景图生成模型的性能，并展示了如何将新型关系类型集成到下游应用中，以增强规划和推理能力。

</details>


### [125] [ToosiCubix: Monocular 3D Cuboid Labeling via Vehicle Part Annotations](https://arxiv.org/abs/2506.21358)
**中文标题：ToosiCubix：基于车辆部件标注的单目3D立方体标注方法**

*Behrooz Nasihatkon,Hossein Resani,Amirreza Mehrzadian*

主要分类: cs.CV

摘要简述: ToosiCubix是一种仅需单目图像和相机内参的3D立方体标注方法，通过用户少量点击和几何约束优化，实现车辆位置、方向和尺寸的高效标注，适用于大规模数据集。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D立方体标注方法依赖昂贵的多传感器设备，限制了大规模数据收集的可行性。ToosiCubix旨在提供一种低成本、高效的解决方案，仅需单目图像即可完成高质量标注。

研究方法: 通过用户标注车辆关键特征（如车轮、车标等），结合几何约束优化问题（PnP和最小二乘子问题交替求解），并引入概率尺寸先验，实现9自由度的立方体标注。

研究结果: 在KITTI和Cityscapes3D数据集上的验证表明，ToosiCubix能够以低成本实现高质量的3D立方体标注，且标注效率高（每车约10次点击）。

研究结论: ToosiCubix为大规模3D标注提供了一种经济、高效的解决方案，适用于无专用设备的现有数据集扩展。

中文摘要: 现有的车辆3D立方体标注方法通常依赖昂贵且需精确校准的相机-LiDAR或立体设备，限制了其在大规模数据收集中的适用性。我们提出了ToosiCubix，一种仅需单目图像和相机内参的简单而强大的方法，用于标注真实立方体。该方法每辆车仅需约10次用户点击，非常适合为原本未使用专用设备收集的数据集添加3D标注。通过标注车辆不同部件的特定特征（如车轮、车标、对称性等），我们能够准确估计车辆的位置、方向和尺寸（存在尺度模糊性，8自由度）。几何约束被表述为一个优化问题，采用坐标下降策略交替求解PnP和最小二乘子问题。为处理常见的模糊性问题（如尺度和未观测维度），我们引入了概率尺寸先验，实现9自由度的立方体标注。在KITTI和Cityscapes3D数据集上的验证表明，ToosiCubix为高质量3D立方体标注提供了一种经济、可扩展的解决方案。

</details>


### [126] [CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection](https://arxiv.org/abs/2506.21364)
**中文标题：CA-I2P：基于全局最优选择的通道自适应配准网络**

*Zhixin Cheng,Jiacheng Deng,Xinjun Li,Xiaotian Yin,Bohao Liao,Baoqun Yin,Wenfei Yang,Tianzhu Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种通道自适应配准网络（CA-I2P），通过通道自适应调整模块（CAA）和全局最优选择模块（GOS）解决了图像与点云特征匹配中的通道注意力差异和冗余对应问题，显著提升了配准精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无检测方法在图像与点云配准中，由于特征通道注意力差异和场景中相似结构导致的冗余对应问题，导致匹配结果下降和配准精度受损。本文旨在解决这些问题。

研究方法: 提出通道自适应调整模块（CAA）增强模态内特征并抑制跨模态敏感性，同时引入全局最优选择模块（GOS）替代局部选择，实现全局优化。

研究结果: 在RGB-D Scenes V2和7-Scenes数据集上的实验表明，该方法在图像到点云配准中达到了最先进的性能。

研究结论: CA-I2P通过CAA和GOS模块有效解决了跨模态匹配中的问题，显著提升了配准精度，为图像与点云配准提供了新的解决方案。

中文摘要: 无检测方法通常遵循从粗到精的流程，提取图像和点云特征进行块级匹配，并细化密集的像素到点对应关系。然而，图像和点云之间特征通道注意力的差异可能导致匹配结果下降，最终影响配准精度。此外，场景中的相似结构可能导致跨模态匹配中的冗余对应。为解决这些问题，我们提出了通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA增强模态内特征并抑制跨模态敏感性，而GOS通过全局优化替代局部选择。在RGB-D Scenes V2和7-Scenes上的实验证明了我们方法的优越性，实现了图像到点云配准的最先进性能。

</details>


### [127] [GenFlow: Interactive Modular System for Image Generation](https://arxiv.org/abs/2506.21369)
**中文标题：GenFlow：交互式模块化图像生成系统**

*Duc-Hung Nguyen,Huu-Phuc Huynh,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: GenFlow是一个创新的模块化系统，通过节点编辑器和智能助手简化图像生成流程，降低技术门槛，使生成艺术更易用。


<details>
  <summary>详细信息</summary>
研究动机: 生成艺术潜力巨大，但技术复杂性限制了非专业用户的使用。GenFlow旨在通过模块化设计和自然语言处理技术，让所有用户都能轻松创作生成艺术。

研究方法: GenFlow采用模块化框架，提供节点编辑器实现无缝定制，并集成自然语言处理的智能助手，自动化部署流程，降低技术难度。

研究结果: 用户研究表明，GenFlow能优化工作流程，缩短任务完成时间，并通过直观界面提升用户理解能力。

研究结论: GenFlow通过创新设计重新定义了生成艺术的易用性和效率，为广泛用户提供了前沿工具。

中文摘要: 生成艺术释放了无限的创意可能性，但由于高级架构概念和计算工作流程所需的技术专长，其全部潜力尚未被发掘。为了弥合这一差距，我们提出了GenFlow，一种新颖的模块化框架，使所有技能水平的用户都能轻松精确地生成图像。GenFlow配备了基于节点的编辑器以实现无缝定制，以及由自然语言处理驱动的智能助手，将复杂的工作流程创建转化为直观易用的体验。通过自动化部署流程和最小化技术障碍，我们的框架使前沿生成艺术工具对所有人开放。一项用户研究表明，GenFlow能够优化工作流程，减少任务完成时间，并通过其直观界面和自适应功能增强用户理解。这些结果使GenFlow成为一项突破性解决方案，重新定义了生成艺术领域的可访问性和效率。

</details>


### [128] [FastRef:Fast Prototype Refinement for Few-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.21398)
**中文标题：FastRef：少样本工业异常检测的快速原型细化**

*Long Tian,Yufei Li,Yuyang Dai,Wenchao Chen,Xiyang Liu,Bo Chen*

主要分类: cs.CV

摘要简述: FastRef是一种高效的原型细化框架，用于解决少样本工业异常检测（FS-IAD）中原型代表性问题。通过特征转移和异常抑制两阶段迭代优化，显著提升了检测效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有少样本工业异常检测方法主要依赖有限正常样本生成原型，但忽略了通过查询图像统计信息提升原型代表性。FastRef旨在通过系统整合查询特征优化原型。

研究方法: FastRef采用两阶段迭代优化：1) 通过可优化变换矩阵将查询特征转移至原型；2) 通过原型对齐抑制异常。特征转移通过线性重构实现，异常抑制则利用最优传输（OT）减少原型与细化版本的差距。

研究结果: FastRef在MVTec、ViSA、MPDD和RealIAD四个基准数据集上验证了其高效性，显著提升了1/2/4-shot设置下的检测性能。

研究结论: FastRef通过特征转移和异常抑制有效提升了少样本工业异常检测中原型的代表性，为数据稀缺环境下的自动化检测提供了高效解决方案。

中文摘要: 少样本工业异常检测（FS-IAD）是数据稀缺环境下自动化检测系统的关键挑战。现有方法主要从有限正常样本中提取原型，但通常未系统整合查询图像统计信息以提升原型代表性。为此，我们提出FastRef，一种高效的FS-IAD原型细化框架。该方法通过两阶段迭代过程实现：1) 通过可优化变换矩阵将查询特征转移至原型；2) 通过原型对齐抑制异常。特征转移通过原型线性重构查询特征实现，而异常抑制则基于FS-IAD中异常重构概率更高的观察，利用最优传输（OT）测量并最小化原型与细化版本的差距。为全面评估，我们将FastRef与三种原型FS-IAD方法（PatchCore、FastRecon、WinCLIP和AnomalyDINO）结合。在MVTec、ViSA、MPDD和RealIAD四个基准数据集上的实验表明，FastRef在1/2/4-shot设置下兼具高效性和计算效率。

</details>


### [129] [Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction](https://arxiv.org/abs/2506.21401)
**中文标题：面向3D参数曲线重建的曲线感知高斯泼溅方法**

*Zhirui Gao. Renjiao Yi,Yaqiao Dai,Xuening Zhu,Wei Chen,Chenyang Zhu,Kai Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种端到端框架，直接从多视角边缘图重建3D参数曲线，避免了传统两阶段方法的误差累积，并通过曲线感知的高斯表示和动态拓扑优化实现了高效且鲁棒的曲线重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有的两阶段方法（先重建边缘点云再拟合参数曲线）存在优化间隙导致的误差累积问题，且参数曲线本身不适合基于渲染的多视角优化。本文旨在提出一种单阶段方法，直接优化参数曲线并解决其渲染问题。

研究方法: 提出了一种双向耦合机制，将参数曲线与边缘导向的高斯组件结合，形成曲线感知的高斯表示（CurveGaussian），支持可微渲染。同时引入动态自适应拓扑优化框架，通过线性化、合并、分裂和修剪操作优化曲线结构。

研究结果: 在ABC数据集和真实场景基准测试中，本文方法优于两阶段方法，重建结果更干净且鲁棒性更强。此外，直接优化参数曲线显著减少了训练参数数量，提高了效率和性能。

研究结论: 本文提出的单阶段方法通过曲线感知的高斯表示和动态拓扑优化，实现了高效的3D参数曲线重建，避免了误差累积，并在性能和效率上优于现有方法。

中文摘要: 本文提出了一种端到端框架，用于直接从多视角边缘图重建3D参数曲线。与现有的两阶段方法（先重建边缘点云再拟合参数曲线）不同，我们的单阶段方法直接从2D边缘图优化3D参数曲线，避免了因优化间隙导致的误差累积。然而，参数曲线本身不适合基于渲染的多视角优化，因此需要一种互补表示，既能保留其几何特性，又能支持可微渲染。我们提出了一种参数曲线与边缘导向高斯组件之间的双向耦合机制，形成了一种曲线感知的高斯表示（CurveGaussian），支持3D曲线的可微渲染，从而实现基于多视角证据的直接优化。此外，我们在训练过程中引入了动态自适应拓扑优化框架，通过线性化、合并、分裂和修剪操作优化曲线结构。在ABC数据集和真实场景基准测试中的综合评估表明，我们的单阶段方法优于两阶段方法，尤其是在生成更干净且鲁棒的曲线重建方面。此外，通过直接优化参数曲线，我们的方法显著减少了训练参数数量，在效率和性能上均优于现有方法。

</details>


### [130] [XVerse: Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation](https://arxiv.org/abs/2506.21416)
**中文标题：XVerse：通过DiT调制实现身份与语义属性的多主题一致性控制**

*Bowen Chen,Mengyi Zhao,Haomiao Sun,Li Chen,Xu Wang,Kang Du,Xinglong Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为XVerse的多主题控制生成模型，通过将参考图像转换为特定令牌的文本流调制偏移量，实现了对多个主题身份和语义属性的精确独立控制，避免了图像潜在特征或特征的破坏。


<details>
  <summary>详细信息</summary>
研究动机: 在文本到图像生成中，尤其是多主题场景下，对主题身份和语义属性（如姿势、风格、照明）的细粒度控制常常会破坏扩散变换器（DiTs）的可编辑性和一致性。现有方法常引入伪影或属性纠缠问题。为解决这些问题，本文提出了XVerse模型。

研究方法: XVerse通过将参考图像转换为特定令牌的文本流调制偏移量，实现了对特定主题的精确独立控制，同时避免了对图像潜在特征或特征的干扰。这种方法支持高保真、可编辑的多主题图像合成。

研究结果: XVerse在保持高保真度的同时，实现了对多个主题身份和语义属性的独立控制，显著提升了复杂场景生成的个性化能力。

研究结论: XVerse通过创新的调制方法，解决了多主题控制中的属性纠缠问题，为复杂场景生成提供了高效且灵活的解决方案。

中文摘要: 在文本到图像生成中，尤其是多主题场景下，对主题身份和语义属性（如姿势、风格、照明）的细粒度控制常常会破坏扩散变换器（DiTs）的可编辑性和一致性。许多方法会引入伪影或面临属性纠缠问题。为解决这些挑战，我们提出了一种新型多主题控制生成模型XVerse。通过将参考图像转换为特定令牌的文本流调制偏移量，XVerse能够在不干扰图像潜在特征或特征的情况下，实现对特定主题的精确独立控制。因此，XVerse提供了高保真、可编辑的多主题图像合成能力，并具备对单个主题特征和语义属性的强大控制力。这一进展显著提升了复杂场景生成的个性化能力。

</details>


### [131] [EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian Splatting](https://arxiv.org/abs/2506.21420)
**中文标题：EndoFlow-SLAM：基于光流约束高斯泼溅的实时内窥镜SLAM**

*Taoyu Wu,Yiyi Miao,Zhuoxiao Li,Haocheng Zhao,Kang Dang,Jionglong Su,Limin Yu,Haoang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为EndoFlow-SLAM的实时内窥镜SLAM方法，通过引入光流损失作为几何约束，并结合深度正则化策略，解决了内窥镜场景中的光度不一致性和动态运动问题，显著提升了3D重建和相机位姿估计的性能。


<details>
  <summary>详细信息</summary>
研究动机: 内窥镜手术场景中，由于非朗伯表面的光度不一致性和呼吸引起的动态运动，传统的基于3D高斯泼溅（3DGS）的SLAM方法表现不佳。本文旨在通过引入几何约束和改进3DGS优化策略，提升内窥镜场景中的SLAM性能。

研究方法: 1. 引入光流损失作为几何约束，优化3D场景结构和相机运动；2. 提出深度正则化策略，解决光度不一致性问题；3. 改进3DGS细化策略，针对关键帧中渲染质量较差的视角进行优化。

研究结果: 在C3VD静态数据集和StereoMIS动态数据集上的实验表明，该方法在新型视图合成和位姿估计任务中优于现有最先进方法，在静态和动态手术场景中均表现出高性能。

研究结论: EndoFlow-SLAM通过结合光流约束和改进的3DGS优化策略，显著提升了内窥镜场景中的SLAM性能，为实时内窥镜手术提供了高效的三维重建和可视化解决方案。

中文摘要: 高效的三维重建和实时可视化在内窥镜等手术场景中至关重要。近年来，3D高斯泼溅（3DGS）在高效三维重建和渲染方面表现出色。大多数基于3DGS的同步定位与建图（SLAM）方法仅依赖外观约束优化3DGS和相机位姿。然而，在内窥镜场景中，非朗伯表面导致的光度不一致性和呼吸引起的动态运动会影响SLAM系统的性能。为解决这些问题，我们额外引入了光流损失作为几何约束，有效约束了场景的3D结构和相机运动。此外，我们提出了一种深度正则化策略，以缓解光度不一致性问题，并确保3DGS在内窥镜场景中的深度渲染有效性。同时，为提升SLAM系统中的场景表示能力，我们改进了3DGS细化策略，重点关注渲染质量较差的关键帧视角，从而获得更好的渲染效果。在C3VD静态数据集和StereoMIS动态数据集上的大量实验表明，我们的方法在新型视图合成和位姿估计任务中优于现有最先进方法，在静态和动态手术场景中均表现出高性能。源代码将在论文录用后公开。

</details>


### [132] [HyperSORT: Self-Organising Robust Training with hyper-networks](https://arxiv.org/abs/2506.21430)
**中文标题：HyperSORT：基于超网络的自组织鲁棒训练方法**

*Samuel Joutard,Marijn Stollenga,Marc Balle Sanchez,Mohammad Farid Azampour,Raphael Prevost*

主要分类: cs.CV

摘要简述: HyperSORT是一种利用超网络预测UNet参数的框架，用于处理医学影像数据中的异质性偏差，通过学习潜在向量和超网络参数，实现对数据集中系统偏差和错误样本的识别与结构化映射。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像数据集中常存在异质性偏差（如错误标签或不一致的标注风格），这些偏差会严重影响深度分割网络的性能。然而，识别和表征这些偏差是一项繁琐且具有挑战性的任务。

研究方法: HyperSORT通过超网络预测UNet参数，这些参数由代表图像和标注变异性的潜在向量生成。超网络参数和每个训练样本的潜在向量集合被联合学习，从而学习到UNet参数的复杂分布，低密度区域捕捉噪声模式，高密度区域则以稳健方式分割器官。

研究结果: 在AMOS数据集（合成扰动版本）和TotalSegmentator数据集（包含真实未知偏差）上的实验表明，HyperSORT能够结构化映射数据集，识别相关系统偏差和错误样本。潜在空间聚类生成的UNet参数能够根据学习到的系统偏差完成分割任务。

研究结论: HyperSORT通过超网络和潜在向量学习，有效识别和处理医学影像数据集中的异质性偏差，为分割任务提供了一种鲁棒且结构化的解决方案。

中文摘要: 医学影像数据集通常包含从错误标签到不一致标注风格的异质性偏差，这些偏差会严重影响深度分割网络的性能。然而，识别和表征这些偏差是一项特别繁琐且具有挑战性的任务。本文提出了HyperSORT框架，该框架使用超网络从代表图像和标注变异性的潜在向量预测UNet参数。超网络参数和训练集中每个样本对应的潜在向量集合被联合学习。因此，HyperSORT并非优化单一神经网络以适应数据集，而是学习UNet参数的复杂分布，其中低密度区域可以捕捉噪声特定模式，而较大的模式则以稳健且有意义的方式分割器官。我们在两个3D腹部CT公共数据集上验证了该方法：一个是AMOS数据集的合成扰动版本，另一个是TotalSegmentator数据集（包含真实未知偏差和错误）。实验表明，HyperSORT能够创建数据集的结构化映射，从而识别相关系统偏差和错误样本。潜在空间聚类生成的UNet参数能够根据学习到的系统偏差完成分割任务。代码及对TotalSegmentator数据集的分析已公开：https://github.com/ImFusionGmbH/HyperSORT

</details>


### [133] [Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation](https://arxiv.org/abs/2506.21444)
**中文标题：基于跨数据集评估的深度学习与视觉基础模型在非典型与正常有丝分裂分类中的基准测试**

*Sweta Banerjee,Viktoria Weiss,Taryn A. Donovan,Rutger A. Fick,Thomas Conrad,Jonas Ammeling,Nils Porsche,Robert Klopfleisch,Christopher Kaltenecker,Katharina Breininger,Marc Aubreville,Christof A. Bertram*

主要分类: cs.CV

摘要简述: 本文通过对比深度学习方法和视觉基础模型，对非典型与正常有丝分裂分类进行了跨数据集评估，发现基于LoRA的模型调整方法表现最佳，并公开了相关代码和数据。


<details>
  <summary>详细信息</summary>
研究动机: 非典型有丝分裂是肿瘤恶性程度的独立预后标志物，但其识别因低发生率、形态差异小、病理学家间一致性低以及数据集类别不平衡而具有挑战性。本研究旨在通过自动化方法解决这一问题。

研究方法: 研究基于乳腺癌非典型有丝分裂数据集（AMi-Br），比较了基线模型、线性探测的基础模型以及基于低秩适应（LoRA）微调的基础模型。同时引入了两个新的测试数据集AtNorM-Br和AtNorM-MD进行跨数据集评估。

研究结果: 在AMi-Br、AtNorM-Br和AtNorM-MD数据集上，基于LoRA调整的Virchow基础模型表现最佳，平衡准确率分别达到0.8135、0.7696和0.7705。

研究结论: 研究表明，尽管非典型有丝分裂分类具有挑战性，但通过迁移学习和模型微调技术可以有效解决。相关代码和数据已公开。

中文摘要: 非典型有丝分裂标志着细胞分裂过程中的异常，可作为肿瘤恶性程度的独立预后相关标志物。然而，由于其发生率低、与正常有丝分裂的形态差异有时细微、病理学家间一致性低以及数据集类别不平衡，其识别仍具挑战性。本研究基于乳腺癌非典型有丝分裂数据集（AMi-Br），全面比较了自动化非典型有丝分裂分类的深度学习方法，包括基线模型、线性探测的基础模型以及基于低秩适应（LoRA）微调的基础模型。为严格评估，我们还引入了两个新的测试数据集——AtNorM-Br（来自TCGA乳腺癌队列）和AtNorM-MD（来自MIDOG++训练集的多域数据集）。结果显示，在AMi-Br、AtNorM-Br和AtNorM-MD数据集上，基于LoRA调整的Virchow基础模型的平均平衡准确率分别达到0.8135、0.7696和0.7705。研究表明，尽管非典型有丝分裂分类具有挑战性，但通过迁移学习和模型微调技术可以有效解决。所有代码和数据已公开于GitHub仓库：https://github.com/DeepMicroscopy/AMi-Br_Benchmark。

</details>


### [134] [Controllable 3D Placement of Objects with Scene-Aware Diffusion Models](https://arxiv.org/abs/2506.21446)
**中文标题：基于场景感知扩散模型的可控3D物体放置**

*Mohamed Omran,Dimitris Kalatzis,Jens Petersen,Amirhossein Habibian,Auke Wiggers*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉地图和粗略物体掩码的高质量3D物体放置方法，通过设计条件信号解决模糊性，同时保持背景完整。


<details>
  <summary>详细信息</summary>
研究动机: 当前图像编辑方法在精确放置物体时仍需复杂的掩码或提示，本文旨在通过视觉地图和简单掩码实现高质量物体放置。

研究方法: 利用精心设计的视觉地图和粗略物体掩码作为条件信号，结合修复模型，实现背景不变的物体放置，支持形状和方向调整。

研究结果: 在汽车场景中验证了方法的有效性，能够精确控制物体位置和姿态，并支持非平凡形状变化。

研究结论: 该方法实现了精确位置控制和外观控制的结合，为场景中物体放置提供了灵活且高质量的解决方案。

中文摘要: 随着强大的文本条件生成模型的出现，图像编辑方法变得更加强大和灵活。然而，在环境中以精确的位置和方向放置物体仍然是一个挑战，因为这通常需要精心设计的修复掩码或提示。在这项工作中，我们表明，精心设计的视觉地图与粗略物体掩码相结合，足以实现高质量的物体放置。我们设计了一种条件信号，既能解决模糊性，又足够灵活以支持形状或物体方向的调整。通过基于修复模型的设计，我们保持了背景的完整性，与那些将物体和背景联合建模的方法形成对比。我们在汽车场景中展示了方法的有效性，通过比较不同条件信号在新型物体放置任务中的表现。这些任务不仅衡量外观编辑质量，还衡量姿态和位置准确性，包括需要非平凡形状变化的情况。最后，我们展示了精细位置控制可以与外观控制结合，将现有物体精确放置在场景中。

</details>


### [135] [A Comprehensive Dataset for Underground Miner Detection in Diverse Scenario](https://arxiv.org/abs/2506.21451)
**中文标题：面向多样化场景的地下矿工检测综合数据集**

*Cyrus Addy,Ajay Kumar Gurumadaiah,Yixiang Gao,Kwame Awuah-Offei*

主要分类: cs.CV

摘要简述: 本文提出了一种专为地下矿工检测设计的新型热成像数据集，用于开发和验证矿工检测系统，并评估了多种先进目标检测算法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 地下采矿作业面临重大安全挑战，机器人辅助搜救的可靠性依赖于矿工检测能力，但目前缺乏适用于地下环境的数据集。

研究方法: 通过系统采集不同采矿活动和场景的热成像数据，构建了一个全面的数据集，并评估了YOLOv8、YOLOv10、YOLO11和RT-DETR等算法的性能。

研究结果: 实验结果表明，热成像技术可用于矿工检测，数据集为未来研究提供了基础，但尚未覆盖所有紧急情况。

研究结论: 该研究验证了热成像技术在地下矿工检测中的可行性，并为未来关键安全应用的研究奠定了基础。

中文摘要: 地下采矿作业面临重大安全挑战，这使得应急响应能力至关重要。尽管机器人在辅助搜救行动中展现出潜力，但其有效性依赖于可靠的矿工检测能力。深度学习算法为自动化矿工检测提供了潜在解决方案，但需要全面的训练数据集，而目前针对地下采矿环境的数据集尚不完善。本文提出了一种新型热成像数据集，专门用于开发和验证潜在应急应用中的矿工检测系统。我们系统地采集了各种采矿活动和场景的热成像数据，为检测算法奠定了坚实基础。为了建立基准性能指标，我们在数据集上评估了包括YOLOv8、YOLOv10、YOLO11和RT-DETR在内的多种先进目标检测算法。尽管该数据集未涵盖所有可能的紧急情况，但它是开发可靠的热成像矿工检测系统的关键第一步，未来有望应用于实际应急场景。本研究证明了热成像技术用于矿工检测的可行性，并为这一关键安全应用的未来研究奠定了基础。

</details>


### [136] [Rethinking Oversaturation in Classifier-Free Guidance via Low Frequency](https://arxiv.org/abs/2506.21452)
**中文标题：基于低频信号重新思考无分类器引导中的过饱和问题**

*Kaiyu Song,Hanjiang Lai*

主要分类: cs.CV

摘要简述: 本文提出了一种基于低频信号的新视角，通过分析冗余信息积累导致的过饱和问题，提出了低频改进的无分类器引导（LF-CFG）方法，有效缓解了过饱和和不真实伪影。


<details>
  <summary>详细信息</summary>
研究动机: 无分类器引导（CFG）通过高引导尺度增强条件项性能，但常导致过饱和和不真实伪影。本文旨在从低频信号角度解决这一问题。

研究方法: 提出低频改进的无分类器引导（LF-CFG），通过自适应阈值测量定位冗余信息，分析低频信息变化率确定合理阈值，并采用降权策略减少冗余信息影响。

研究结果: 实验表明，LF-CFG在多种扩散模型（如Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5和SiT-XL）中有效缓解了过饱和和不真实伪影。

研究结论: 低频信号分析揭示了过饱和问题的根源，LF-CFG通过降权策略显著改善了生成质量，为扩散模型优化提供了新思路。

中文摘要: 无分类器引导（CFG）通过引导尺度平衡条件项和无条件项的影响，高引导尺度用于增强条件项性能，但常导致过饱和和不真实伪影。本文从低频信号角度出发，指出冗余信息在这些信号中的积累是过饱和和不真实伪影的关键因素。基于此，提出低频改进的无分类器引导（LF-CFG）以缓解这些问题。具体而言，引入基于自适应阈值的测量方法定位冗余信息位置，通过分析低频信息在前后步骤中的变化率确定合理阈值，并采用降权策略减少低频信号中冗余信息的影响。实验结果表明，LF-CFG在多种扩散模型（包括Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5和SiT-XL）中有效缓解了过饱和和不真实伪影。

</details>


### [137] [Evaluation of Traffic Signals for Daily Traffic Pattern](https://arxiv.org/abs/2506.21469)
**中文标题：基于日常交通模式的交通信号评估**

*Mohammad Shokrolah Shirazi,Hung-Fu Chang*

主要分类: cs.CV

摘要简述: 本文提出三种基于转向运动计数（TMC）的交通信号配置方法（动态、静态和混合），并通过交通摄像头开发视觉跟踪系统评估拉斯维加斯六个交叉路口的信号性能。实验表明，90秒和120秒的信号周期效果最佳，混合方法在高峰和非高峰时段表现优越。


<details>
  <summary>详细信息</summary>
研究动机: 转向运动计数数据对交通信号设计、交叉路口规划和拥堵分析至关重要。本文旨在通过开发新的信号配置方法，优化交通流管理，适应日常交通的双峰模式。

研究方法: 提出动态、静态和混合三种信号配置方法，利用交通摄像头开发视觉跟踪系统估算TMC，并通过仿真工具SUMO评估信号性能。混合方法根据高峰和非高峰时段切换动态和静态配置。

研究结果: 实验结果显示，90秒和120秒的信号周期效果最佳，动态配置在四个交叉路口表现更好，混合方法适应双峰交通模式，表现优越。

研究结论: 混合信号配置方法能有效适应高峰和非高峰时段的交通变化，优于单一静态或动态方法，尤其适用于交通分布不均的交叉路口。

中文摘要: 转向运动计数数据对交通信号设计、交叉路口几何规划、交通流和拥堵分析至关重要。本研究提出了三种基于TMC的交通信号配置方法：动态、静态和混合。开发了一种基于视觉的跟踪系统，利用交通摄像头估算拉斯维加斯六个交叉路口的TMC。交叉路口设计、车辆运动方向及信号配置文件以兼容格式合成，并导入SUMO仿真工具进行信号评估。基于等待时间的初步实验结果表明，90秒和120秒的信号周期对所有交叉路口效果最佳。此外，四个交叉路口在动态信号配置下表现更好，而另外两个表现较差的交叉路口总车辆数与车道数的比例较低。由于日常交通流常呈现双峰模式，我们提出一种混合信号方法，在高峰和非高峰时段切换动态和静态配置，以优化交通流管理。内置的交通生成模块创建了4小时的车辆路线（包括高峰时段），信号设计模块根据静态、动态和混合方法生成信号周期。各区域（西、北、东、南）的车辆计数分布权重不同，以生成多样化的交通模式。对6个交叉路口进行的4小时仿真实验表明，基于区域的交通模式分布影响信号设计选择。静态方法适用于交通分布均匀的区域，而混合方法在东西和南北区域交通权重较高的交叉路口表现更优。

</details>


### [138] [Global and Local Entailment Learning for Natural World Imagery](https://arxiv.org/abs/2506.21476)
**中文标题：自然世界图像中的全局与局部蕴含学习**

*Srikumar Sastry,Aayush Dhakal,Eric Xing,Subash Khanal,Nathan Jacobs*

主要分类: cs.CV

摘要简述: 本文提出了一种名为径向跨模态嵌入（RCME）的框架，用于显式建模视觉语言模型中的传递性蕴含关系，优化概念的部分顺序，并在生命之树的层次结构中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法未能显式建模蕴含关系的传递性，导致视觉语言模型在数据层次结构学习上的不足。本文旨在通过RCME框架解决这一问题，优化概念的部分顺序。

研究方法: 提出径向跨模态嵌入（RCME）框架，显式建模传递性蕴含关系，优化概念的部分顺序，并构建层次化视觉语言基础模型。

研究结果: 实验表明，RCME在层次化物种分类和层次化检索任务中优于现有最先进模型。

研究结论: RCME框架成功显式建模了传递性蕴含关系，为视觉语言模型中的层次结构学习提供了有效解决方案。

中文摘要: 学习视觉语言模型中数据的层次结构是一个重大挑战。先前的研究尝试通过蕴含学习解决这一问题，但这些方法未能显式建模蕴含的传递性，而这种传递性确立了表示空间中顺序与语义的关系。本文提出了径向跨模态嵌入（RCME）框架，能够显式建模传递性强制的蕴含关系。我们的框架优化了视觉语言模型中概念的部分顺序。通过利用该框架，我们开发了一个能够表示生命之树层次结构的层次化视觉语言基础模型。在层次化物种分类和层次化检索任务上的实验表明，我们的模型性能优于现有最先进模型。代码和模型已在https://vishu26.github.io/RCME/index.html开源。

</details>


### [139] [TITAN: Query-Token based Domain Adaptive Adversarial Learning](https://arxiv.org/abs/2506.21484)
**中文标题：TITAN：基于查询令牌的域自适应对抗学习**

*Tajamul Ashraf,Janibul Bashir*

主要分类: cs.CV

摘要简述: 本文提出了一种名为TITAN的方法，用于解决源数据不可用的无源域自适应目标检测问题。通过将目标图像分为与源域相似（易）和不相似（难）的子集，并结合查询令牌对抗模块，显著提升了伪标签的可靠性，从而在多个数据集上超越了现有最优方法。


<details>
  <summary>详细信息</summary>
研究动机: 在无源域自适应目标检测（SF-DAOD）问题中，由于源数据不可用，现有方法通常采用自监督的学生-教师框架生成伪标签进行微调。然而，伪标签的高噪声导致教师模型崩溃，学生模型性能急剧下降。本文旨在通过更可靠的伪标签生成方法解决这一问题。

研究方法: 提出TITAN方法，将目标图像分为易和难两个子集，通过估计方差进行划分。结合查询令牌对抗模块，减少特征表示之间的域差距，从而提升伪标签质量。

研究结果: 在四个自然图像数据集和两个医学数据集上的实验表明，TITAN显著优于现有最优方法，在C2F、C2B、S2C和K2C基准上分别实现了+22.7、+22.2、+21.1和+3.7的mAP提升。

研究结论: TITAN通过有效的目标图像划分和查询令牌对抗模块，显著提升了无源域自适应目标检测的性能，为领域自适应问题提供了新的解决方案。

中文摘要: 我们关注源数据在适应过程中不可用的无源域自适应目标检测（SF-DAOD）问题，模型必须适应未标记的目标域。大多数方法采用自监督的学生-教师（ST）框架，通过源预训练模型生成伪标签进行微调。我们观察到，由于伪标签的高噪声（源于域偏差、差异和显著的域偏移），教师模型的崩溃导致学生模型性能急剧下降。为获得可靠的伪标签，我们提出了一种基于目标的迭代查询令牌对抗网络（TITAN），将目标图像分为与源域相似（易）和不相似（难）的两个子集。我们提出了一种估计方差的策略来划分目标域，利用检测方差越高对应召回率越高且与源域相似性越大的特点。此外，我们在学生-教师基线框架中引入查询令牌对抗模块，以减少两种特征表示之间的域差距。在四个自然图像数据集和两个具有挑战性的医学数据集上的实验证实，TITAN的性能优于现有的最优方法。在C2F、C2B、S2C和K2C基准上，我们分别实现了+22.7、+22.2、+21.1和+3.7的mAP提升。

</details>


### [140] [Towards Reliable Detection of Empty Space: Conditional Marked Point Processes for Object Detection](https://arxiv.org/abs/2506.21486)
**中文标题：面向可靠空区域检测：基于条件标记点过程的目标检测**

*Tobias J. Riedlinger,Kira Maag,Hanno Gottschalk*

主要分类: cs.CV

摘要简述: 本文提出了一种基于空间统计学的目标检测模型，通过标记点过程量化未检测区域的置信度，解决了传统目标检测在空区域不确定性评估上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前目标检测模型在未检测区域的置信度评估上存在缺陷，无法准确判断空区域是否真正无障碍物，这在自动驾驶等安全关键应用中存在风险。本文旨在填补这一空白。

研究方法: 提出了一种基于标记点过程的空间统计学框架，将边界框数据视为标记点过程的实现，通过似然训练提供明确的区域可行驶性置信度估计。

研究结果: 实验表明，该方法在校准评估和性能测试中表现优异，能够有效量化空区域的置信度。

研究结论: 本文提出的统计框架为未检测区域的置信度评估提供了理论基础和实践方法，对安全关键应用具有重要意义。

中文摘要: 深度神经网络在边界框检测和语义分割等计算机视觉任务中达到了最先进的性能。目标检测和分割模型为预测分配置信分数，反映模型在目标检测或像素级分类中的不确定性。然而，这些置信估计通常校准不佳，因为其架构和损失函数是为任务性能而非概率基础设计的。即使预测校准良好，目标检测器也无法量化未检测边界框区域的不确定性，即模型未评估未检测区域是否真正无障碍物的概率。这在自动驾驶等应用中构成安全风险，因为空区域的不确定性未被探索。本文提出了一种基于空间统计学的目标检测模型。边界框数据匹配标记点过程的实现，通常用于描述作为边界框中心的空间点事件的概率发生，其中标记用于描述边界框的空间扩展和类别。我们的统计框架支持基于似然的训练，并为区域是否可行驶（即无障碍物）提供明确定义的置信估计。通过校准评估和性能测试，我们证明了该方法的有效性。

</details>


### [141] [Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration](https://arxiv.org/abs/2506.21509)
**中文标题：通过动态对数校准减轻大型视觉语言模型的幻觉问题**

*Jiahe Chen,Jiaying He,Qian Shao,Qiyuan Chen,Jiahe Ying,Hongxia Xu,Jintai Chen,Jianwei Zheng,Jian Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为动态对数校准（DLC）的新方法，用于减少大型视觉语言模型（LVLM）在生成文本时的幻觉现象。DLC通过动态调整输出对数，使生成的文本更符合视觉证据，从而显著减少幻觉，同时保持高效推理。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型在多模态理解方面取得了显著进展，但常因生成与视觉输入矛盾的文本（幻觉）而受限。现有方法存在静态约束、效率低下和细节丢失等问题，亟需一种动态且高效的解决方案。

研究方法: DLC是一种无需训练的推理框架，通过CLIP逐步评估图像与生成文本的语义对齐，动态计算候选词的相对视觉优势（RVA），并调整输出对数以偏向视觉支持的词。此外，自适应权重机制平衡视觉引导与文本质量。

研究结果: 在多个基准测试和不同LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上的实验表明，DLC显著减少了幻觉现象，优于现有方法，同时避免了多次前向传播，保持了高效推理。

研究结论: DLC提供了一种高效且有效的推理时解决方案，显著减少了LVLM的幻觉问题，提升了模型的可靠性。代码将在Github上发布。

中文摘要: 大型视觉语言模型（LVLM）在多模态理解方面取得了显著进展，但常因生成与视觉输入矛盾的文本（幻觉）而受限。现有的无需训练的解码策略存在静态约束无法适应生成过程中的语义漂移、因多次前向传播导致的效率低下以及过度干预规则导致的细节丢失等问题。为克服这些挑战，本文提出了动态对数校准（DLC），这是一种新颖的无需训练的推理框架，旨在推理时动态对齐文本生成与视觉证据。在解码阶段，DLC逐步使用CLIP评估输入图像与生成文本序列的语义对齐，并根据动态更新的上下文基线评估候选词的相对视觉优势（RVA），自适应调整输出对数以偏向视觉支持的词。此外，基于实时上下文对齐分数的自适应权重机制，在确保文本整体质量的同时，谨慎平衡视觉引导。在多种基准测试和不同LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上的广泛实验表明，DLC显著减少了幻觉现象，优于现有方法，同时通过避免多次前向传播保持了高效推理。总体而言，我们提出了一种高效且有效的推理时解决方案，以减少幻觉，从而提升LVLM在实际应用中的可靠性。代码将在Github上发布。

</details>


### [142] [GGTalker: Talking Head Systhesis with Generalizable Gaussian Priors and Identity-Specific Adaptation](https://arxiv.org/abs/2506.21513)
**中文标题：GGTalker：基于通用高斯先验与身份特定适应的说话头合成**

*Wentao Hu,Shunkai Li,Ziqiao Peng,Haoxian Zhang,Fan Shi,Xiaoqiang Liu,Pengfei Wan,Di Zhang,Hui Tian*

主要分类: cs.CV

摘要简述: GGTalker通过结合通用高斯先验和身份特定适应，解决了语音驱动3D说话头合成的挑战，实现了高质量的渲染效果和训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在固定视角和小规模音频变化下表现良好，但在大角度头部旋转和分布外音频下表现不佳，且需要耗时的身份特定训练。核心问题在于缺乏足够的3D先验，限制了合成说话头的泛化能力。

研究方法: GGTalker采用两阶段训练策略：先学习高斯头部先验（音频-表情和表情-视觉先验），再通过定制化适应精确建模个体特征。引入颜色MLP生成细粒度纹理，并使用身体修复器融合背景，生成逼真视频帧。

研究结果: 实验表明，GGTalker在渲染质量、3D一致性、唇同步准确性和训练效率上达到最先进水平。

研究结论: GGTalker通过通用先验和身份适应，显著提升了说话头合成的质量和泛化能力，为未来研究提供了新方向。

中文摘要: 高质量、可泛化的语音驱动3D说话头合成仍是一个持续挑战。现有方法在固定视角和小规模音频变化下表现良好，但在大角度头部旋转和分布外音频下表现不佳，且需要耗时的身份特定训练。我们认为核心问题在于缺乏足够的3D先验，限制了合成说话头的泛化能力。为此，我们提出GGTalker，通过结合通用先验和身份适应来合成说话头。我们引入两阶段先验-适应训练策略，学习高斯头部先验并适应个体特征。训练音频-表情和表情-视觉先验以捕捉唇部运动的通用模式和头部纹理的分布。在定制化适应阶段，精确建模个体说话风格和纹理细节。此外，引入颜色MLP生成细粒度、运动对齐的纹理，并使用身体修复器融合渲染结果与背景，生成难以区分的逼真视频帧。综合实验表明，GGTalker在渲染质量、3D一致性、唇同步准确性和训练效率上达到最先进水平。

</details>


### [143] [G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation](https://arxiv.org/abs/2506.21514)
**中文标题：G$^{2}$D：通过梯度引导蒸馏提升多模态学习**

*Mohammed Rakib,Arunkumar Bagavathi*

主要分类: cs.CV

摘要简述: 本文提出了一种名为G$^{2}$D的梯度引导蒸馏框架，通过动态模态优先级技术解决多模态学习中的模态不平衡问题，显著提升了弱模态的利用效率，并在分类和回归任务中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统多模态学习常因模态不平衡导致某些模态主导优化，弱模态利用不足。本文旨在通过梯度引导蒸馏框架解决这一问题，提升多模态模型的综合性能。

研究方法: 提出G$^{2}$D框架，结合单模态和多模态目标的损失函数，并引入动态顺序模态优先级（SMP）技术，确保各模态在训练中轮流主导，避免强模态压制弱模态。

研究结果: 在多个真实数据集上验证，G$^{2}$D显著提升了弱模态的重要性，并在分类和回归任务中表现优于现有方法。

研究结论: G$^{2}$D通过梯度引导蒸馏和动态模态优先级技术，有效解决了多模态学习中的模态不平衡问题，提升了模型性能。

中文摘要: 多模态学习旨在利用多样化的数据模态信息以实现更全面的性能。然而，传统的多模态模型常面临模态不平衡问题，即一个或少数模态主导模型优化，导致特征表示次优且弱模态利用不足。为解决这一问题，我们提出了梯度引导蒸馏（G$^{2}$D），这是一种知识蒸馏框架，通过融合单模态和多模态目标的自定义损失函数优化多模态模型。G$^{2}$D在学习过程中进一步引入了动态顺序模态优先级（SMP）技术，确保每个模态轮流主导学习过程，避免强模态压制弱模态。我们在多个真实数据集上验证了G$^{2}$D，结果表明G$^{2}$D在训练中显著提升了弱模态的重要性，并在分类和回归任务中优于现有方法。代码已开源：https://github.com/rAIson-Lab/G2D。

</details>


### [144] [MADrive: Memory-Augmented Driving Scene Modeling](https://arxiv.org/abs/2506.21520)
**中文标题：MADrive：基于记忆增强的驾驶场景建模**

*Polina Karpikova,Daniil Selikhanovych,Kirill Struminsky,Ruslan Musaev,Maria Golitsyna,Dmitry Baranchuk*

主要分类: cs.CV

摘要简述: MADrive提出了一种基于记忆增强的驾驶场景建模框架，通过从大规模外部记忆库中检索相似车辆3D资产，替换原始观测中的车辆，从而支持高度逼真的驾驶场景合成。


<details>
  <summary>详细信息</summary>
研究动机: 当前自动驾驶环境的三维高斯溅射建模虽能实现高度真实的场景重建，但仍局限于原始观测数据，难以支持显著改变或全新驾驶场景的逼真合成。MADrive旨在通过记忆增强技术扩展现有方法的场景重建能力。

研究方法: MADrive引入了一个检索模块，从大规模外部记忆库MAD-Cars（包含约70K 360度车辆视频）中检索视觉相似的车辆3D资产，并通过方向对齐和重光照技术将其整合到目标场景中。

研究结果: 实验表明，MADrive能够为场景中的车辆提供完整的多视角表示，支持显著改变配置的逼真合成。

研究结论: MADrive通过记忆增强技术显著提升了驾驶场景建模的灵活性和逼真度，为自动驾驶环境的高质量合成提供了新思路。

中文摘要: 近年来，场景重建技术的进步推动了基于三维高斯溅射的自动驾驶环境高度真实建模。然而，现有重建结果仍紧密依赖于原始观测数据，难以支持显著改变或全新驾驶场景的逼真合成。本文提出MADrive，一种记忆增强的重建框架，旨在通过从大规模外部记忆库中检索视觉相似的3D资产替换观测车辆，扩展现有场景重建方法的能力。具体而言，我们发布了MAD-Cars数据集，包含约70K 360度野外拍摄的车辆视频，并提出了一个检索模块，用于从记忆库中查找最相似的车辆实例，从视频中重建对应的3D资产，并通过方向对齐和重光照将其整合到目标场景中。实验表明，替换后的车辆在场景中提供了完整的多视角表示，支持显著改变配置的逼真合成。项目页面：https://yandex-research.github.io/madrive/

</details>


### [145] [WAFT: Warping-Alone Field Transforms for Optical Flow](https://arxiv.org/abs/2506.21526)
**中文标题：WAFT：基于单独变形场变换的光流方法**

*Yihan Wang,Jia Deng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为WAFT的简单高效光流方法，通过高分辨率变形替代传统成本体积，实现了更高精度和更低内存消耗。


<details>
  <summary>详细信息</summary>
研究动机: 传统光流方法依赖成本体积构建，但这种方式内存消耗大且复杂。WAFT旨在挑战这一传统观念，提出一种更简单、灵活且高效的替代方案。

研究方法: WAFT采用高分辨率变形技术替代成本体积，减少了内存需求并提升了性能。其设计简单，依赖最小归纳偏置，无需复杂定制。

研究结果: 在Spring和KITTI基准测试中，WAFT排名第一，并在KITTI上实现了最佳零样本泛化性能，速度比同类方法快4.1倍。

研究结论: WAFT证明了无需成本体积也能实现高性能光流，为未来研究提供了新的方向。

中文摘要: 我们提出了Warping-Alone Field Transforms（WAFT），一种简单高效的光流方法。WAFT与RAFT类似，但用高分辨率变形替代了成本体积，以更低的内存成本实现了更高的精度。这一设计挑战了传统观念，即构建成本体积是实现高性能的必要条件。WAFT是一种简单灵活的元架构，依赖最小归纳偏置和定制设计。与现有方法相比，WAFT在Spring和KITTI基准测试中排名第一，在KITTI上实现了最佳零样本泛化性能，同时比性能相近的方法快4.1倍。代码和模型权重可在https://github.com/princeton-vl/WAFT获取。

</details>


### [146] [Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval](https://arxiv.org/abs/2506.21538)
**中文标题：最大匹配的重要性：防止表示坍缩以实现鲁棒的跨模态检索**

*Hani Alomari,Anushka Sivakumar,Andrew Zhang,Chris Thomas*

主要分类: cs.CV

摘要简述: 本文提出了一种新的跨模态检索方法，通过最大化配对分配相似性和两种损失函数，解决了传统方法在捕捉多样语义关系时的局限性，并在MS-COCO和Flickr30k上取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 跨模态图像-文本检索的挑战在于不同模态内容之间的多样关联。传统单向量嵌入方法难以捕捉复杂的跨模态关系，而基于集合的方法虽然能表示更多样化的关系，但仍面临稀疏监督和集合坍缩的问题。

研究方法: 本文提出了最大配对分配相似性（Maximal Pair Assignment Similarity）来优化嵌入集合间的一对一匹配，并引入全局判别损失和集合内散度损失，以增强嵌入的区分性和防止集合坍缩。

研究结果: 在MS-COCO和Flickr30k数据集上，该方法无需外部数据即实现了最先进的性能。

研究结论: 通过优化嵌入集合的匹配和引入损失函数，本文方法有效提升了跨模态检索的鲁棒性和性能。

中文摘要: 跨模态图像-文本检索的挑战在于不同模态内容之间的多样关联。传统方法通过学习单向量嵌入表示每个样本的语义，但难以捕捉跨模态的细微和多样化关系。基于集合的方法通过多嵌入表示样本，能够捕捉更丰富和多样化的关系，但仍面临稀疏监督和集合坍缩的问题。本文提出最大配对分配相似性，优化嵌入集合间的一对一匹配以保留集合内的语义多样性，并引入全局判别损失和集合内散度损失以增强表示。该方法在MS-COCO和Flickr30k上无需外部数据即实现了最先进的性能。

</details>


### [147] [StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning](https://arxiv.org/abs/2506.21541)
**中文标题：StruMamba3D：探索结构Mamba用于自监督点云表示学习**

*Chuxin Wang,Yixin Zha,Wenfei Yang,Tianzhu Zhang*

主要分类: cs.CV

摘要简述: StruMamba3D是一种基于Mamba的自监督点云表示学习新方法，通过设计空间状态代理和状态更新策略，解决了传统方法破坏点云邻接关系和长序列记忆丢失的问题，并在多个下游任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于Mamba的点云表示学习方法在SSM处理过程中会破坏3D点的邻接关系，且无法随着输入长度增加保留长序列记忆，限制了SSM的潜力。

研究方法: 1. 设计空间状态代理以保留点之间的空间依赖关系；2. 通过状态更新策略和轻量卷积增强SSM，促进空间状态交互；3. 引入序列长度自适应策略，降低预训练模型对输入长度的敏感性。

研究结果: 在四个下游任务中表现优异，ModelNet40准确率达95.1%，ScanObjectNN最具挑战性分区的准确率达92.75%（无需投票策略）。

研究结论: StruMamba3D通过创新设计解决了传统方法的局限性，显著提升了点云表示学习的性能。

中文摘要: 近年来，基于Mamba的方法通过利用状态空间模型（SSM）的高效上下文建模能力和线性复杂度，在点云表示学习中表现出色。然而，这些方法仍面临两个关键问题：SSM处理过程中破坏3D点的邻接关系，以及随着下游任务输入长度增加无法保留长序列记忆。为解决这些问题，我们提出StruMamba3D，一种自监督点云表示学习的新范式。其优势包括：1. 设计空间状态代理以保留点之间的空间依赖关系；2. 通过状态更新策略和轻量卷积增强SSM，促进空间状态交互；3. 引入序列长度自适应策略，降低预训练模型对输入长度的敏感性。在四个下游任务中的实验结果表明，我们的方法性能优越。此外，无需投票策略，我们的方法在ModelNet40上达到95.1%的准确率，在ScanObjectNN最具挑战性分区上达到92.75%的准确率。

</details>


### [148] [DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion](https://arxiv.org/abs/2506.21544)
**中文标题：DeOcc-1-to-3：通过自监督多视角扩散从单张图像实现3D去遮挡**

*Yansong Qu,Shaohui Dai,Xinyang Li,Yuze Wang,You Shen,Liujuan Cao,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DeOcc-1-to-3的端到端框架，用于从单张遮挡图像生成结构一致的六视角视图，支持下游3D重建任务，无需依赖先验修复或人工标注。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于扩散的视图合成模型在处理遮挡图像时表现不佳，导致生成视图不一致且3D重建质量下降。本文旨在解决这一问题，提出一种能够直接处理遮挡图像并生成多视角视图的方法。

研究方法: 通过自监督训练流程，利用Pix2Gestalt数据集中的遮挡-非遮挡图像对和伪真实视图，训练模型进行结构感知的补全和视图一致性学习。无需修改原始架构，完全微调视图合成模型以联合学习补全和多视角生成。

研究结果: 提出的方法能够从单张遮挡图像生成六视角结构一致的视图，显著提升了3D重建质量。同时，本文还首次提出了一个遮挡感知重建的基准测试，涵盖多种遮挡程度、物体类别和掩模模式。

研究结论: DeOcc-1-to-3框架在遮挡图像的多视角生成和3D重建任务中表现出色，为未来研究提供了标准化评估协议。

中文摘要: 从单张图像重建3D物体是一个长期存在的挑战，尤其是在现实世界中的遮挡情况下。尽管最近的基于扩散的视图合成模型可以从单张RGB图像生成一致的新视角，但它们通常假设输入是完全可见的，并且在物体部分被遮挡时会失败，导致视图不一致和3D重建质量下降。为了克服这一限制，我们提出了一种端到端的遮挡感知多视角生成框架。我们的方法直接从单张部分遮挡图像合成六视角结构一致的新视图，支持下游3D重建任务，无需依赖先验修复或人工标注。我们利用Pix2Gestalt数据集构建了一个自监督训练流程，通过遮挡-非遮挡图像对和伪真实视图，训练模型进行结构感知的补全和视图一致性学习。在不修改原始架构的情况下，我们完全微调了视图合成模型以联合学习补全和多视角生成。此外，我们首次提出了一个遮挡感知重建的基准测试，涵盖多种遮挡程度、物体类别和掩模模式，为未来研究提供了标准化评估协议。我们的代码可在https://github.com/Quyans/DeOcc123获取。

</details>


### [149] [SAM4D: Segment Anything in Camera and LiDAR Streams](https://arxiv.org/abs/2506.21547)
**中文标题：SAM4D：相机与LiDAR流中的任意分割**

*Jianyun Xu,Song Wang,Ziqian Ni,Chunyong Hu,Sheng Yang,Jianke Zhu,Qiang Li*

主要分类: cs.CV

摘要简述: SAM4D是一个多模态时序基础模型，用于相机和LiDAR流中的可提示分割。通过统一多模态位置编码（UMPE）和运动感知跨模态记忆注意力（MCMA）实现跨模态交互与时间一致性，并通过自动化数据引擎生成伪标签，显著提升标注效率。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶场景中，相机和LiDAR数据的跨模态分割面临标注瓶颈和时间一致性问题。SAM4D旨在通过多模态基础模型解决这些问题，提升分割效率和鲁棒性。

研究方法: 1. 引入统一多模态位置编码（UMPE）对齐相机和LiDAR特征；2. 提出运动感知跨模态记忆注意力（MCMA）增强时间一致性；3. 开发多模态自动化数据引擎生成伪标签。

研究结果: 在Waymo-4DSeg数据集上的实验表明，SAM4D具有强大的跨模态分割能力，并能高效生成高质量伪标签。

研究结论: SAM4D通过多模态对齐和时间一致性增强，显著提升了自动驾驶场景中的分割性能和数据标注效率。

中文摘要: 我们提出了SAM4D，一种多模态时序基础模型，用于相机和LiDAR流中的可提示分割。通过引入统一多模态位置编码（UMPE），将相机和LiDAR特征对齐到共享的3D空间，实现无缝的跨模态提示与交互。此外，我们提出了运动感知跨模态记忆注意力（MCMA），利用自运动补偿增强时间一致性和长时程特征检索，确保在动态变化的自动驾驶场景中实现鲁棒分割。为避免标注瓶颈，我们开发了一种多模态自动化数据引擎，结合VFM驱动的视频掩码片段、时空4D重建和跨模态掩码片段融合。该框架以比人工标注快数个数量级的速度生成相机-LiDAR对齐的伪标签，同时保持点云表示中VFM衍生的语义保真度。我们在构建的Waymo-4DSeg数据集上进行了大量实验，证明了SAM4D强大的跨模态分割能力及其在数据标注中的巨大潜力。

</details>


### [150] [SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark](https://arxiv.org/abs/2506.21549)
**中文标题：SiM3D：单实例多视角多模态多配置的3D异常检测基准**

*Alex Costanzino,Pierluigi Zama Ramirez,Luigi Lella,Matteo Ragaglia,Alessandro Oliva,Giuseppe Lisanti,Luigi Di Stefano*

主要分类: cs.CV

摘要简述: SiM3D是首个结合多视角和多模态信息的3D异常检测与分割（ADS）基准，专注于单实例场景，并首次解决从合成训练数据泛化到真实测试数据的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D异常检测领域缺乏多视角和多模态信息的整合，且单实例场景和从合成数据到真实数据的泛化问题尚未被充分研究。SiM3D旨在填补这一空白，为制造业提供更全面的解决方案。

研究方法: SiM3D引入了一个多模态多视角数据集，包含高分辨率图像和点云数据，并提供了手动标注的3D分割真值。通过调整单视角方法，建立了多视角3D ADS任务的基准。

研究结果: SiM3D数据集包含333个实例的八类对象数据，并提供了新的评估指标。实验表明，单视角方法在多视角任务中表现有限，凸显了多视角整合的重要性。

研究结论: SiM3D为3D异常检测领域提供了首个多视角多模态基准，解决了单实例和合成数据泛化的挑战，为未来研究奠定了基础。

中文摘要: 我们提出了SiM3D，这是首个考虑整合多视角和多模态信息的3D异常检测与分割（ADS）基准，任务目标是生成基于体素的异常体积。此外，SiM3D专注于制造业中高度关注的场景：单实例异常检测，其中仅有一个真实或合成的对象可用于训练。在这方面，SiM3D作为首个ADS基准，解决了从合成训练数据泛化到真实测试数据的挑战。SiM3D包含一个新颖的多模态多视角数据集，采用顶级工业传感器和机器人采集。数据集包含333个实例的八类对象的多视角高分辨率图像（1200万像素）和点云（700万点），每类对象还配有CAD模型。我们还为异常测试样本提供了手动标注的3D分割真值。为了为提出的多视角3D ADS任务建立参考基线，我们调整了突出的单视角方法，并使用新的异常体积评估指标对其性能进行了评估。

</details>


### [151] [Whole-Body Conditioned Egocentric Video Prediction](https://arxiv.org/abs/2506.21552)
**中文标题：基于全身条件的第一人称视频预测**

*Yutong Bai,Danny Tran,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik*

主要分类: cs.CV

摘要简述: 该论文提出了一种通过人体动作预测第一人称视角视频的方法，利用3D身体姿态作为条件，结合自回归扩散变换器模型，实现了对复杂现实环境中人类行为的模拟。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索如何从第一人称视角模拟人类行为对环境的影响，解决复杂现实环境和具身代理行为的建模挑战。

研究方法: 方法包括利用Nymeria大规模数据集中的第一人称视频和身体姿态数据，训练自回归条件扩散变换器模型，并通过层次化评估协议分析模型的预测和控制能力。

研究结果: 结果表明，模型能够有效预测第一人称视角视频，并通过层次化评估验证了其在复杂任务中的表现。

研究结论: 结论指出，该研究为从人类视角建模复杂环境和行为提供了初步尝试，展示了视频预测在具身代理控制中的潜力。

中文摘要: 我们训练模型以预测第一人称视角视频（PEVA），给定过去的视频和由相对3D身体姿态表示的动作。通过以运动学姿态轨迹为条件，并结合身体的关节层次结构，我们的模型学会了从第一人称视角模拟物理人类行为如何塑造环境。我们在Nymeria（一个大规模的真实世界第一人称视频和身体姿态捕捉数据集）上训练了一个自回归条件扩散变换器。此外，我们设计了一个层次化评估协议，包含逐渐增加难度的任务，从而全面分析模型的具身预测和控制能力。我们的工作代表了从人类视角建模复杂现实环境和具身代理行为的初步尝试。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [152] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
**中文标题：新加坡共识：全球AI安全研究优先事项**

*Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić*

主要分类: cs.AI

摘要简述: 新加坡共识提出了全球AI安全研究的优先事项，旨在通过开发、评估和控制三个层面的研究，确保AI的可信、可靠与安全。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI能力的快速提升和自主性增强，如何确保AI的安全性（可信、可靠、安全）成为重要议题。构建可信的生态系统有助于人们放心使用AI，同时为创新提供空间。

研究方法: 通过2025年新加坡AI会议（SCAI），汇集全球AI科学家，基于国际AI安全报告，采用防御深度模型，将AI安全研究分为开发、评估和控制三大领域。

研究结果: 报告明确了AI安全研究的三大挑战：开发可信AI系统、评估其风险以及部署后的监控与干预。

研究结论: 通过多领域合作，新加坡共识为全球AI安全研究提供了框架，旨在平衡创新与安全。

中文摘要: AI能力的快速提升和自主性的增强带来了巨大的变革潜力，但也引发了如何确保AI安全性（即可信、可靠和安全）的激烈讨论。构建可信的生态系统至关重要——它有助于人们放心接受AI，同时为创新提供最大空间，避免反弹。

“2025年新加坡AI会议（SCAI）：AI安全国际科学交流”旨在通过汇集全球AI科学家，识别并整合AI安全研究的优先事项，支持这一领域的研究。本报告基于由Yoshua Bengio主持、33国政府支持的国际AI安全报告，采用防御深度模型，将AI安全研究领域分为三类：开发可信AI系统的挑战（开发）、评估其风险的挑战（评估）以及部署后监控与干预的挑战（控制）。

</details>


### [153] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
**中文标题：MAGPIE：一个用于多智能体上下文隐私评估的数据集**

*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

主要分类: cs.AI

摘要简述: 本文提出了一个名为MAGPIE的数据集，用于评估多智能体系统中的上下文隐私保护能力。研究发现，当前最先进的LLM（如GPT-4o和Claude-2.7-Sonnet）在理解上下文隐私方面表现不佳，且在明确隐私指令下仍频繁泄露隐私信息。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于LLM的智能体在多任务协作中的广泛应用，隐私保护成为关键问题。现有评估基准主要关注单轮简单任务，无法反映真实场景中隐私保护的复杂性。本文旨在填补这一空白，评估智能体在多轮对话中的隐私保护能力。

研究方法: 本文提出了MAGPIE数据集，包含158个高风险场景，覆盖15个领域。这些场景设计为完全排除隐私数据会阻碍任务完成，而过度共享则可能导致重大损失。随后，作者评估了当前最先进的LLM在理解上下文隐私和协作中保护隐私的能力。

研究结果: 实验结果表明，当前模型（如GPT-4o和Claude-2.7-Sonnet）对上下文隐私的理解不足，分别有25.2%和43.6%的隐私数据被错误分类为可共享。在多轮对话中，即使有明确隐私指令，模型仍分别有59.9%和50.5%的隐私泄露率。此外，多智能体系统在71%的场景中无法完成任务。

研究结论: 当前模型在上下文隐私保护和协作任务完成方面表现不佳，亟需改进以应对真实场景中的隐私挑战。

中文摘要: 基于LLM的智能体的普及推动了多智能体协作在任务调度、谈判、资源分配等方面的广泛应用。在此类系统中，隐私至关重要，因为智能体通常需要访问专有工具和特定领域数据库，这些数据需要严格保密。本文探讨了基于LLM的智能体是否具备对上下文隐私的理解能力，以及在明确指令下，这些系统是否能在非对抗性多轮对话中保护用户隐私。现有的评估基准主要针对单轮低复杂度任务，隐私信息可以轻易排除。我们首先提出了一个名为MAGPIE的基准数据集，包含158个现实生活中的高风险场景，覆盖15个领域。这些场景设计为完全排除隐私数据会阻碍任务完成，而过度共享则可能导致重大损失。随后，我们评估了当前最先进的LLM在（a）理解上下文隐私数据的能力和（b）在不侵犯用户隐私的情况下协作的能力。实验结果表明，包括GPT-4o和Claude-2.7-Sonnet在内的当前模型缺乏对上下文隐私的稳健理解，分别有25.2%和43.6%的隐私数据被错误分类为可共享。在多轮对话中，即使有明确隐私指令，这些模型仍分别有59.9%和50.5%的隐私泄露率。此外，多智能体系统在71%的场景中无法完成任务。这些结果表明，当前模型在上下文隐私保护和协作任务完成方面尚未达到理想水平。

</details>


### [154] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
**中文标题：领域特定AI应用的动态上下文感知提示推荐**

*Xinye Tang,Haijun Zhai,Chaitanya Belwal,Vineeth Thayanithi,Philip Baumann,Yogesh K Roy*

主要分类: cs.AI

摘要简述: 本文提出了一种动态上下文感知的提示推荐系统，专为领域特定的AI应用设计，通过结合上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，生成相关且可操作的提示建议。


<details>
  <summary>详细信息</summary>
研究动机: 由于LLM驱动的应用对用户提示质量高度敏感，尤其在领域特定应用中，高质量提示的编写具有挑战性。本文旨在解决这一问题，通过动态上下文感知的提示推荐系统提升提示质量。

研究方法: 系统结合了上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，利用行为遥测和两阶段分层推理动态选择和排名相关技能，并通过预定义和自适应模板生成提示，结合少样本学习增强效果。

研究结果: 在真实数据集上的实验表明，该方法在自动化和专家评估中均表现出高实用性和相关性。

研究结论: 本文提出的动态上下文感知提示推荐系统显著提升了领域特定AI应用中提示的质量和实用性。

中文摘要: LLM驱动的应用对用户提示质量高度敏感，而编写高质量提示在领域特定应用中尤为困难。本文提出了一种新颖的动态上下文感知提示推荐系统，专为领域特定AI应用设计。我们的解决方案结合了上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，以生成相关且可操作的提示建议。系统利用行为遥测和两阶段分层推理动态选择和排名相关技能，并通过预定义和自适应模板结合少样本学习生成提示。在真实数据集上的实验表明，我们的方法在自动化和专家评估中均表现出高实用性和相关性。

</details>


### [155] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
**中文标题：超越被动安全：通过长期模拟实现风险感知的语言模型对齐**

*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

主要分类: cs.AI

摘要简述: 本文提出了一种通过长期模拟评估语言模型安全性的框架，旨在预测模型建议对社会系统的宏观影响，并在新数据集上实现了20%以上的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 随着语言模型在高风险社会决策中的影响力增加，确保其建议的长期安全性变得至关重要。本文旨在通过长期模拟评估模型的潜在危害，以提升其安全性。

研究方法: 作者提出了一种概念验证框架，通过模拟模型生成建议在社会系统中的长期传播，评估其宏观影响。同时，引入了一个包含100个间接危害场景的数据集，测试模型对潜在不良后果的预见能力。

研究结果: 该方法在新数据集上实现了超过20%的性能提升，并在现有安全基准（如AdvBench、SafeRLHF、WildGuardMix）上平均胜率超过70%。

研究结论: 研究表明，通过长期模拟评估语言模型的潜在危害是一种有效的安全对齐方法，为开发更安全的智能代理提供了新方向。

中文摘要: 随着基于语言模型的智能体在公共政策和医疗等高风险社会决策中的影响力日益增强，确保其建议的积极影响需要理解其建议的深远意义。我们提出了一种概念验证框架，该框架能够模拟模型生成的建议在社会系统中的宏观传播过程，从而实现更稳健的对齐。为了评估语言模型的长期安全意识，我们还引入了一个包含100个间接危害场景的数据集，测试模型对看似无害用户提示可能导致的非明显不良后果的预见能力。我们的方法不仅在新数据集上实现了超过20%的性能提升，还在现有安全基准（AdvBench、SafeRLHF、WildGuardMix）上平均胜率超过70%，为开发更安全的智能代理提供了有前景的方向。

</details>


### [156] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
**中文标题：揭示大型语言模型中的因果推理：现实还是幻象？**

*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

主要分类: cs.AI

摘要简述: 本文探讨大型语言模型（LLMs）是否具备真正的因果推理能力，发现其仅能进行浅层（level-1）因果推理，并提出G^2-Reasoner方法以提升其能力。


<details>
  <summary>详细信息</summary>
研究动机: 因果推理能力是推动LLMs向强人工智能发展的关键。尽管LLMs在理解上下文因果关系方面表现出色，但其是否具备类似人类的真正因果推理能力尚不明确。本文旨在验证这一问题并提出改进方法。

研究方法: 通过分析LLMs的自回归机制，揭示其非因果性；提出新基准CausalProbe-2024测试LLMs的因果推理能力；设计G^2-Reasoner方法，结合通用知识和目标导向提示提升LLMs的推理能力。

研究结果: 实验表明，LLMs在CausalProbe-2024上表现显著下降，证实其仅能进行level-1因果推理；G^2-Reasoner显著提升了LLMs在新鲜和反事实语境中的推理能力。

研究结论: LLMs当前仅具备浅层因果推理能力，G^2-Reasoner为迈向level-2因果推理提供了新路径。

中文摘要: 因果推理能力是推动大型语言模型（LLMs）迈向强人工智能的关键。尽管多功能的LLMs似乎能够理解上下文因果关系并提供符合因果律的响应，但其是否具备类似人类的真正因果推理能力仍不明确。然而，现有证据表明情况恰恰相反。具体而言，LLMs仅能进行浅层（level-1）因果推理，主要依赖于其参数中嵌入的因果知识，而缺乏类似人类的深层（level-2）因果推理能力。为支持这一假设，方法上，我们深入研究了基于Transformer的LLMs的自回归机制，揭示其本质上并不具备因果性。实证上，我们引入了新的因果问答基准CausalProbe-2024，其语料对研究的LLMs而言是全新且几乎未见过的。LLMs在CausalProbe-2024上的表现显著低于早期基准，表明其主要进行level-1因果推理。为缩小与level-2因果推理的差距，我们从人类推理通常依赖通用知识和目标导向的事实中汲取灵感，提出了G^2-Reasoner方法，将通用知识和目标导向提示融入LLMs的因果推理过程。实验证明，G^2-Reasoner显著提升了LLMs的因果推理能力，尤其是在新鲜和反事实语境中。这项工作为LLMs迈向真正的因果推理提供了新路径，超越level-1并向level-2迈进。

</details>


### [157] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
**中文标题：世界感知规划叙事增强大型视觉语言模型规划器**

*Junhao Shi,Zhaoye Fei,Siyin Wang,Qipeng Guo,Jingjing Gong,Xipeng QIu*

主要分类: cs.AI

摘要简述: 本文提出了一种名为WAP的框架，通过增强大型视觉语言模型（LVLM）的环境认知能力，显著提升了其在复杂任务中的表现，特别是在常识推理和长时程规划方面。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大型视觉语言模型在复杂场景中表现不佳，尤其是面对陌生环境和多步目标时。现有方法依赖与环境无关的模仿学习，导致模型难以处理上下文敏感的指令，且过度依赖辅助提示而非视觉推理。

研究方法: 提出了World-Aware Planning Narrative Enhancement（WAP）框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和语法基础）增强LVLM的环境理解能力，并采用课程学习仅使用原始视觉观察进行模型开发和评估。

研究结果: 在EB-ALFRED基准测试中，Qwen2.5-VL模型的任务成功率显著提升（绝对提升60.7），尤其在常识推理（+60.0）和长时程规划（+70.0）方面表现突出。增强后的开源模型大幅优于GPT-4o和Claude-3.5-Sonnet等专有系统。

研究结论: WAP框架通过增强LVLM的环境认知能力，显著提升了其在复杂任务中的性能，为未来研究提供了新的方向。

中文摘要: 大型视觉语言模型（LVLM）在具身规划任务中表现出潜力，但在涉及陌生环境和多步目标的复杂场景中表现不佳。现有方法依赖与环境无关的模仿学习，导致指令与环境上下文脱节，使模型难以处理上下文敏感的指令，并在长时程交互中依赖辅助提示而非视觉推理。本文提出了World-Aware Planning Narrative Enhancement（WAP）框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和语法基础）增强LVLM的环境理解能力，并仅通过课程学习使用原始视觉观察开发和评估模型。在EB-ALFRED基准测试中，Qwen2.5-VL的任务成功率显著提升（绝对提升60.7），尤其在常识推理（+60.0）和长时程规划（+70.0）方面表现突出。值得注意的是，增强后的开源模型大幅优于GPT-4o和Claude-3.5-Sonnet等专有系统。

</details>


### [158] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
**中文标题：IXAII：一种用于决策支持系统的交互式可解释人工智能界面**

*Pauline Speckmann,Mario Nadj,Christian Janiesch*

主要分类: cs.AI

摘要简述: 本文提出了一种交互式可解释人工智能系统IXAII，结合了四种可解释AI方法（LIME、SHAP、Anchors和DiCE），并为五类用户群体提供定制化视图和解释控制。通过专家和普通用户的评估，IXAII被认为能有效提升透明度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的可解释AI方法多为静态且忽视用户视角，限制了其实际效果。因此，本文旨在开发一种交互式系统，结合多种可解释方法，并赋予用户对解释内容和形式的控制权，以提升透明度和实用性。

研究方法: 开发了交互式可解释智能系统IXAII，整合了LIME、SHAP、Anchors和DiCE四种可解释AI方法，并为五类用户群体提供定制化视图。通过专家和普通用户的访谈评估系统效果。

研究结果: 评估结果显示，IXAII通过提供多样化的解释和可视化选项，被用户认为有助于提升AI系统的透明度，并有效弥合了可解释AI方法与实际应用之间的差距。

研究结论: IXAII为可解释AI实践和人机交互提供了新视角，通过交互性和多方法整合，显著提升了AI系统的透明度和用户接受度。

中文摘要: 尽管已开发出多种后验可解释AI方法，但大多数是静态的且忽视用户视角，限制了其对目标受众的效果。为此，我们开发了名为IXAII的交互式可解释智能系统，提供来自四种可解释AI方法（LIME、SHAP、Anchors和DiCE）的解释。我们的原型为五类用户群体提供定制化视图，并赋予用户对解释内容及其格式的控制权。通过专家和普通用户的访谈评估IXAII，结果表明，IXAII通过提供多样化的解释和可视化选项，被认为有助于提升透明度。通过弥合可解释AI方法、交互性和实际实施之间的差距，我们为AI解释实践和人机交互提供了新视角。

</details>


### [159] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
**中文标题：用于科学发现的主动推理人工智能系统**

*Karthik Duraisamy*

主要分类: cs.AI

摘要简述: 本文提出了一种基于主动推理的人工智能系统，旨在解决科学发现中的抽象、推理和现实三大鸿沟，通过结合因果自监督模型、贝叶斯规划器和闭环实验验证，实现科学推理与实验现实的紧密结合。


<details>
  <summary>详细信息</summary>
研究动机: 当前人工智能系统在科学发现中存在局限性，如抽象能力不足、推理机制脆弱以及与实验现实的脱节。本文旨在通过解决这些鸿沟，推动AI在科学发现中的实际应用。

研究方法: 提出了一种主动推理AI系统架构，包括：(1) 基于因果自监督的长期研究记忆，(2) 配备贝叶斯防护的符号或神经符号规划器，(3) 动态知识图谱构建，(4) 通过闭环实验和高保真模拟器验证内部表征。

研究结果: 该系统能够实现科学发现中的因果推理、动态知识更新和实验验证，同时强调了人类判断在不确定性和模糊反馈中的不可或缺性。

研究结论: 主动推理AI系统通过结合内部模型与外部验证，为科学发现提供了新路径，同时指出人类需作为永久组成部分参与其中。

中文摘要: 人工智能的快速发展引发了对其在科学发现中变革性作用的期待，但现有系统仍受限于其架构、脆弱的推理机制及与实验现实的脱节。基于前期研究，我们认为AI驱动的科学进步需解决三大鸿沟——抽象鸿沟、推理鸿沟和现实鸿沟，而非依赖模型规模、数据或计算时间。科学推理需要支持行动与响应模拟的内部表征、区分相关性与机制的因果结构，以及持续校准。我们定义的主动推理AI系统具备以下特征：(1) 基于因果自监督的长期研究记忆，(2) 配备贝叶斯防护的符号或神经符号规划器，(3) 动态知识图谱构建，(4) 通过闭环实验和高保真模拟器验证内部表征。该系统通过内部模型与外部验证的交互实现科学发现，同时强调人类判断在不确定性和模糊反馈中的不可或缺性。

</details>


### [160] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
**中文标题：TableMoE：多模态表格理解中结构化专家推理的神经符号路由**

*Junwen Zhang,Pu Chen,Yin Zhang*

主要分类: cs.AI

摘要简述: TableMoE提出了一种神经符号混合专家架构，通过动态路由机制提升多模态表格理解的鲁棒性和结构化推理能力，显著优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态大语言模型在处理复杂表格结构时性能受限，TableMoE旨在解决这一问题，提升模型在真实场景中的表现。

研究方法: TableMoE采用神经符号路由机制，预测表格元素的语义角色并动态分配至专用专家模块，结合大规模预训练数据集TableMoE-Align进行对齐驱动训练。

研究结果: 实验表明，TableMoE在多个WildStruct基准测试中显著优于现有模型，并通过消融研究验证了其核心组件的有效性。

研究结论: TableMoE通过神经符号推理的集成，显著提升了多模态表格理解的鲁棒性和可解释性。

中文摘要: 由于表格结构的复杂性、符号密度以及视觉退化（如模糊、倾斜、水印、不完整结构或字体、多跨或分层嵌套布局），真实场景中的多模态表格理解极具挑战性。现有的多模态大语言模型（MLLMs）在此类WildStruct条件下表现不佳，导致性能受限且泛化能力差。为解决这些问题，我们提出了TableMoE，一种专为多模态表格数据设计的神经符号混合连接专家（MoCE）架构，支持鲁棒的结构化推理。TableMoE采用创新的神经符号路由机制，预测潜在语义标记角色（如标题、数据单元格、轴、公式），并基于符号推理图的置信感知门控策略，动态将表格元素路由至专用专家模块（Table-to-HTML、Table-to-JSON、Table-to-Code）。为促进有效的对齐驱动预训练，我们引入了大规模数据集TableMoE-Align，包含金融、科学、生物医学和工业领域的120万组表格-HTML-JSON-代码四元组，专用于模型预训练。为评估模型性能，我们策划并发布了四个具有挑战性的WildStruct基准测试：WMMFinQA、WMMTatQA、WMMTabDialog和WMMFinanceMath，旨在测试模型在真实多模态退化和结构复杂性下的表现。实验结果表明，TableMoE显著优于现有最先进模型。广泛的消融研究验证了其核心组件的有效性，突出了神经符号路由和结构化专家对齐的关键作用。通过定性分析，我们进一步展示了TableMoE的可解释性和增强的鲁棒性，证明了神经符号推理在多模态表格理解中的有效性。

</details>


### [161] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
**中文标题：从有限视角构建空间心理模型**

*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

主要分类: cs.AI

摘要简述: 本文探讨了视觉语言模型（VLMs）是否能像人类一样通过有限视角构建完整的空间心理模型。通过MindCube基准测试，发现现有VLMs表现接近随机水平。提出了一种协同方法“先绘图后推理”，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 人类能够通过有限视角构建空间心理模型，而现有视觉语言模型（VLMs）在此能力上表现不佳。本文旨在填补这一关键差距，探索如何帮助VLMs构建更鲁棒的空间心理模型。

研究方法: 通过MindCube基准测试（包含21,154个问题和3,268张图像），系统评估VLMs在空间心理建模中的表现。提出三种方法：生成中间视角、自然语言推理链和认知地图。最终采用“先绘图后推理”的协同方法，结合强化学习进一步提升性能。

研究结果: “先绘图后推理”方法将准确率从37.8%提升至60.8%（+23.0%），结合强化学习后达到70.7%（+32.9%）。表明构建和利用结构化空间表征能显著提升对不可见空间的理解。

研究结论: 本文证明通过主动构建和利用内部结构化空间表征，结合灵活的推理过程，可以显著提升VLMs对不可见空间的理解能力。这一发现为未来空间心理建模研究提供了重要方向。

中文摘要: 视觉语言模型（VLMs）能否像人类一样仅通过少数视角想象完整场景？人类通过构建空间心理模型（对不可见空间的内部表征）来推理布局、视角和运动。我们提出的MindCube基准测试包含21,154个问题和3,268张图像，揭示了现有VLMs在此关键能力上的表现接近随机水平。通过MindCube，我们系统评估了VLMs在构建鲁棒空间心理模型方面的表现，包括位置表征（认知绘图）、方向表征（视角转换）和动态表征（“假设”运动的心理模拟）。随后探索了三种方法帮助VLMs近似空间心理模型：生成不可见中间视角、自然语言推理链和认知地图。显著改进来自一种协同方法“先绘图后推理”，该方法联合训练模型首先生成认知地图，然后基于其进行推理。通过训练模型在这些内部地图上推理，准确率从37.8%提升至60.8%（+23.0%）。结合强化学习后性能进一步提升至70.7%（+32.9%）。我们的核心发现是，这种空间心理模型的“脚手架”方法（主动构建并利用内部结构化空间表征，结合灵活的推理过程）能显著提升对不可见空间的理解。

</details>


### [162] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
**中文标题：Ad-Hoc人类-AI协调挑战**

*Tin Dizdarević,Ravi Hammond,Tobias Gessler,Anisoara Calinescu,Jonathan Cook,Matteo Gallici,Andrei Lupu,Jakob Nicolaus Foerster*

主要分类: cs.AI

摘要简述: 本文提出了一种名为“Ad-Hoc Human-AI Coordination Challenge (AH2AC2)”的挑战，旨在解决人类与AI协调中的评估难题。通过开发人类代理代理，并开源有限的人类游戏数据，为数据高效方法的研究提供了基础。


<details>
  <summary>详细信息</summary>
研究动机: 现实应用中，人类与AI的无缝协调至关重要，但评估过程成本高且难以复现。本文旨在通过开发人类代理代理和开源数据集，克服这些限制，推动人类-AI协调研究。

研究方法: 本文开发了基于大规模人类数据集的“人类代理代理”，作为廉价、可复现的评估伙伴。同时开源了3,079局游戏数据，限制数据量以鼓励数据高效方法的研究。

研究结果: 研究提供了两玩家和三玩家Hanabi场景的基线结果，并通过受控评估系统确保公平性。

研究结论: AH2AC2挑战通过人类代理代理和开源数据集，为人类-AI协调研究提供了廉价、可复现的评估工具，推动了该领域的发展。

中文摘要: 实现AI代理与人类的无缝协调对实际应用至关重要，但这仍是一个重大挑战。Hanabi是一款合作卡牌游戏，具有不完美信息、受限通信、心智理论需求和协调行动等特点，是研究人类-AI协调的理想测试平台。然而，其用于人类-AI交互的潜力因人类评估的困难而受限。本文提出“Ad-Hoc人类-AI协调挑战(AH2AC2)”，以克服昂贵且难以复现的人类评估限制。我们基于大规模人类数据集开发了“人类代理代理”，作为AH2AC2中稳健、廉价且可复现的人类评估伙伴。为鼓励数据高效方法的发展，我们开源了3,079局游戏数据，故意限制可用的人类游戏数据量。我们展示了两玩家和三玩家Hanabi场景的基线结果。为确保公平评估，我们通过受控评估系统托管代理代理，而非公开释放。代码可在https://github.com/FLAIROx/ah2ac2获取。

</details>


### [163] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
**中文标题：Mind2Web 2：基于代理评判的自主搜索评估**

*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

主要分类: cs.AI

摘要简述: 本文提出了Mind2Web 2基准测试，用于评估自主搜索系统的性能，并提出了一种基于任务特定评判代理的自动评估框架。结果显示，最佳系统OpenAI Deep Research已达到人类性能的50-70%，且耗时仅为人类的一半。


<details>
  <summary>详细信息</summary>
研究动机: 随着自主搜索系统（如Deep Research）的复杂性增加，现有的评估方法已无法满足需求。这些方法通常假设搜索时间短且答案静态，而自主搜索需要长时间浏览和复杂信息合成。因此，需要一种新的评估基准和方法。

研究方法: 研究团队构建了Mind2Web 2基准测试，包含130个高质量、长时间跨度的任务，并通过1000多小时的人工劳动完成。提出了一种基于树状评分标准的Agent-as-a-Judge框架，用于自动评估答案正确性和来源标注。

研究结果: 对九种前沿自主搜索系统和人类表现进行了全面评估。最佳系统OpenAI Deep Research的性能达到人类的50-70%，且耗时仅为人类的一半。详细的错误分析为未来系统改进提供了方向。

研究结论: Mind2Web 2为下一代自主搜索系统的开发和评估提供了严格的基础，展示了自主搜索的巨大潜力。

中文摘要: 自主搜索（如Deep Research系统）通过大型语言模型自主浏览网页、合成信息并返回全面引用的答案，代表了用户与网络规模信息交互方式的重大变革。尽管其有望提高效率和减轻认知负担，但其日益增长的复杂性和开放性已超出当前评估基准和方法的能力范围，这些方法通常假设搜索时间短且答案静态。本文提出了Mind2Web 2，一个包含130个高质量、长时间跨度任务的基准测试，这些任务需要实时网页浏览和广泛信息合成，并通过1000多小时的人工劳动构建。为解决评估时间变化和复杂答案的挑战，我们提出了一种新颖的Agent-as-a-Judge框架。该方法基于树状评分标准构建任务特定的评判代理，自动评估答案正确性和来源标注。我们对九种前沿自主搜索系统和人类表现进行了全面评估，并通过详细错误分析为未来发展提供了洞见。表现最佳的系统OpenAI Deep Research已达到人类性能的50-70%，且耗时仅为人类的一半，显示出巨大潜力。总之，Mind2Web 2为下一代自主搜索系统的开发和评估提供了严格的基础。

</details>


### [164] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
**中文标题：PsyLite技术报告**

*Fangjun Ding,Renyu Zhang,Xinyu Feng,Chengye Xie,Zheng Zhang,Yanting Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种轻量级心理咨询大语言模型代理PsyLite，基于InternLM2.5-7B-chat开发，通过两阶段训练策略提升模型能力，并在部署中引入创新条件RAG以增强用户体验和对话安全性。


<details>
  <summary>详细信息</summary>
研究动机: 随着数字技术的发展，AI驱动的心理咨询成为心理健康领域的重要研究方向，但现有模型在对话安全、场景处理及轻量化部署方面仍有不足。

研究方法: 采用两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），结合Ollama和Open WebUI部署，设计条件RAG引入幽默元素并拒绝危险请求。

研究结果: PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中表现优于基线模型，心理咨询专业性提升47.6%，对话安全性提升2.4%。

研究结论: PsyLite通过轻量化部署（仅需5GB内存）为资源受限环境下的心理咨询应用提供了可行解决方案。

中文摘要: 随着数字技术的快速发展，AI驱动的心理咨询逐渐成为心理健康领域的重要研究方向。然而，现有模型在对话安全、详细场景处理和轻量化部署方面仍存在不足。为解决这些问题，本研究提出了PsyLite，一种基于InternLM2.5-7B-chat开发的轻量级心理咨询大语言模型代理。通过两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），PsyLite提升了模型的深度推理能力、心理咨询能力和安全对话能力。部署时使用Ollama和Open WebUI，并通过Pipelines创建自定义工作流。设计了一种创新的条件RAG，在心理咨询过程中适时引入相声幽默元素以提升用户体验，并拒绝危险请求以增强对话安全性。评估显示，PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中均优于基线模型，特别是在心理咨询专业性（CPsyCounE分数提升47.6%）和对话安全性（SafeDialBench分数提升2.4%）方面表现突出。此外，模型采用量化技术（GGUF q4_k_m）实现低硬件部署（仅需5GB内存即可运行），为资源受限环境下的心理咨询应用提供了可行方案。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [165] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
**中文标题：混合深度学习和信号处理在低资源环境下的阿拉伯方言识别**

*Ghazal Al-Shwayyat,Omer Nezih Gerek*

主要分类: eess.AS

摘要简述: 本文研究了在低资源环境下，结合信号处理技术和深度学习模型进行阿拉伯方言识别的方法。通过比较MFCC+CNN和DWT+RNN两种混合模型，发现MFCC+CNN在准确率和性能上显著优于DWT+RNN，为资源受限的方言识别提供了有效基线。


<details>
  <summary>详细信息</summary>
研究动机: 阿拉伯方言识别因语言多样性和标注数据稀缺而具有挑战性，尤其是在资源受限的情况下。本研究旨在通过结合传统信号处理和深度学习技术，探索高效的方言识别方法。

研究方法: 研究开发了两种混合模型：(1) 结合MFCC特征和CNN，(2) 结合DWT特征和RNN。使用Common Voice阿拉伯语数据集的方言标注子集进行训练和评估。

研究结果: 实验结果显示，MFCC+CNN模型表现最佳，准确率达91.2%，显著优于DWT+RNN模型的66.5%。MFCC+CNN在精确率、召回率和F1分数上均表现优异。

研究结论: 研究表明，在低资源环境下，结合频谱特征和卷积模型对阿拉伯方言识别具有显著优势。未来研究可扩展标注数据集、引入自监督学习技术或探索Transformer等先进架构。

中文摘要: 阿拉伯方言识别在语音技术中面临重大挑战，主要源于阿拉伯语的多样性以及标注数据的稀缺性，尤其是对少数方言的支持不足。本研究探讨了结合传统信号处理技术和深度学习架构的混合建模策略，以解决低资源环境下的方言识别问题。开发并评估了两种混合模型：(1) 梅尔频率倒谱系数（MFCC）与卷积神经网络（CNN）结合，(2) 离散小波变换（DWT）特征与循环神经网络（RNN）结合。模型在Common Voice阿拉伯语数据集的方言标注子集上训练，方言标签基于说话者元数据分配。实验结果表明，MFCC+CNN架构表现最优，准确率达91.2%，且精确率、召回率和F1分数均显著优于Wavelet+RNN配置（准确率66.5%）。这些发现表明，在标注数据有限的情况下，利用频谱特征与卷积模型对阿拉伯方言识别尤为有效。研究还指出了数据集规模、标签区域重叠和模型优化方面的局限性，为未来研究提供了方向。建议进一步改进包括采用更大的标注语料库、整合自监督学习技术以及探索Transformer等先进神经网络架构。总体而言，本研究为资源受限环境下的阿拉伯方言识别奠定了坚实基础。

</details>


### [166] [ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing](https://arxiv.org/abs/2506.21448)
**中文标题：ThinkSound：多模态大语言模型中的链式思维推理用于音频生成与编辑**

*Huadai Liu,Jialei Wang,Kaicheng Luo,Wen Wang,Qian Chen,Zhou Zhao,Wei Xue*

主要分类: eess.AS

摘要简述: ThinkSound是一种利用链式思维（CoT）推理的多模态大语言模型框架，通过分阶段生成和编辑视频音频，实现高保真音效。该方法在音频生成和编辑任务中表现优异，并在Movie Gen Audio基准测试中取得领先成绩。


<details>
  <summary>详细信息</summary>
研究动机: 尽管端到端的视频到音频生成技术已有显著进步，但生成能够真实反映视觉内容细节的高保真音频仍具挑战性。本文旨在通过链式思维推理，模拟专业人士的创作过程，提升音频生成和编辑的质量。

研究方法: ThinkSound将音频生成过程分为三个阶段：基础音效生成、交互式对象中心优化和自然语言指导的针对性编辑。每个阶段通过多模态大语言模型生成上下文对齐的链式思维推理，指导统一的音频基础模型。此外，还引入了AudioCoT数据集，用于连接视觉内容、文本描述和声音合成。

研究结果: 实验表明，ThinkSound在视频到音频生成任务中，无论是音频指标还是链式思维指标，均达到最先进水平，并在Movie Gen Audio基准测试中表现出色。

研究结论: ThinkSound通过链式思维推理和多模态大语言模型的结合，显著提升了音频生成和编辑的质量，为创意产业提供了强大的工具。

中文摘要: 尽管端到端的视频到音频生成技术已取得显著进展，但生成能够真实捕捉视觉内容细节的高保真音频仍具挑战性。与创意产业中的专业人士类似，此类生成需要对视觉动态、声学环境和时间关系等进行复杂推理。我们提出了ThinkSound，这是一种新颖的框架，利用链式思维（CoT）推理实现逐步、交互式的视频音频生成和编辑。我们的方法将过程分解为三个互补阶段：基础音效生成（创建语义连贯的音景）、通过精确用户交互的交互式对象中心优化，以及自然语言指令指导的针对性编辑。每个阶段中，多模态大语言模型生成上下文对齐的CoT推理，指导统一的音频基础模型。此外，我们还引入了AudioCoT，这是一个包含结构化推理注释的综合数据集，建立了视觉内容、文本描述和声音合成之间的联系。实验表明，ThinkSound在视频到音频生成任务中，无论是音频指标还是CoT指标，均达到最先进水平，并在Movie Gen Audio基准测试中表现出色。演示页面请访问https://ThinkSound-Demo.github.io。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [167] [Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems](https://arxiv.org/abs/2506.20685)
**中文标题：渐进式尺寸自适应联邦学习：异构多模态数据系统的综合框架**

*Sajid Hussain,Muhammad Sohail,Nauman Ali Khan,Naima Iltaf,Ihtesham ul Islam*

主要分类: cs.LG

摘要简述: 本文提出了一种基于数据集大小特性的渐进式自适应联邦学习框架（SAFL），通过多模态数据实验揭示了数据集大小对联邦学习效果的关键影响，并展示了SAFL在通信效率和性能上的优势。


<details>
  <summary>详细信息</summary>
研究动机: 现有联邦学习研究主要关注模型异构性和聚合技术，而忽略了数据集大小特性对训练动态的根本影响。本文旨在填补这一空白，探索数据集大小如何影响联邦学习效果。

研究方法: 提出SAFL框架，通过渐进式训练策略，根据数据集大小特性组织联邦学习。实验覆盖13个数据集和7种模态，分析数据集大小范围、模态性能层次及大规模数据集的性能退化。

研究结果: 实验发现：1) 联邦学习最佳数据集大小为1000-1500样本；2) 结构化数据（时间序列、传感器）性能显著优于非结构化数据（文本、多模态）；3) SAFL平均准确率达87.68%，结构化数据模态可达99%+。

研究结论: SAFL填补了数据特性驱动联邦学习策略的空白，为实际部署提供了理论和实践指导，同时展示了高效的通信和性能表现。

中文摘要: 联邦学习（FL）已成为一种在保护数据隐私的同时实现分布式机器学习的变革性范式。然而，现有方法主要关注模型异构性和聚合技术，很大程度上忽略了数据集大小特性对联邦训练动态的根本影响。本文提出了基于尺寸的自适应联邦学习（SAFL），这是一种新颖的渐进式训练框架，根据异构多模态数据的数据集大小特性系统地组织联邦学习。我们在涵盖7种模态（视觉、文本、时间序列、音频、传感器、医学视觉和多模态）的13个多样化数据集上进行了全面的实验评估，揭示了以下关键发现：1) 联邦学习效果最佳的数据集大小范围为1000-1500样本；2) 结构化数据（时间序列、传感器）性能显著优于非结构化数据（文本、多模态）；3) 超过2000样本的大规模数据集会出现系统性性能下降。SAFL在所有数据集上的平均准确率达到87.68%，结构化数据模态的准确率超过99%。该框架展示了卓越的通信效率，在558次通信中将总数据传输量减少至7.38 GB，同时保持高性能。我们的实时监控框架为系统资源利用、网络效率和训练动态提供了前所未有的洞察。这项工作填补了理解数据特性如何驱动联邦学习策略的关键空白，为神经网络和学习系统中实际FL部署提供了理论见解和实践指导。

</details>


### [168] [Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models](https://arxiv.org/abs/2506.20701)
**中文标题：扩散树采样：扩散模型的可扩展推理时对齐**

*Vineet Jain,Kusha Sareen,Mohammad Pedramfar,Siamak Ravanbakhsh*

主要分类: cs.LG

摘要简述: 本文提出了一种名为扩散树采样（DTS）的方法，通过将推理时对齐问题转化为搜索问题，并重用过去的计算，显著提升了扩散模型的样本质量和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的扩散模型在推理时对新目标的适应能力有限，尤其是在高噪声水平下，现有方法存在价值估计不准确和计算资源浪费的问题。本文旨在通过引入树搜索方法解决这些问题。

研究方法: 本文提出扩散树采样（DTS）方法，通过将推理时对齐问题视为搜索问题，利用蒙特卡洛树搜索的思想，将终端奖励反向传播至扩散链，并迭代优化价值估计。其贪婪变体DTS$^\star$则通过全局搜索寻找高奖励样本。

研究结果: 在MNIST和CIFAR-10的条件生成任务中，DTS以10倍更少的计算量达到最佳基线的FID分数。在文本到图像生成和语言完成任务中，DTS$^\star$以5倍更少的计算量匹配最佳样本。

研究结论: 扩散树采样方法通过重用过去生成的信息，将额外计算转化为持续改进的样本质量，为扩散模型的推理时对齐提供了可扩展的解决方案。

中文摘要: 在生成建模中，如何使预训练的扩散模型在推理时适应新目标仍是一个开放性问题。现有引导方法在高噪声水平下存在价值估计不准确的问题，导致引导偏差，且未重用过去运行的信息以提高样本质量，计算效率低下。受蒙特卡洛树搜索成功的启发，我们将推理时对齐问题转化为搜索问题，并重用过去的计算。我们提出了一种基于树的方法，通过将终端奖励反向传播至扩散链，并迭代优化价值估计，从奖励对齐的目标密度中采样。我们提出的扩散树采样（DTS）方法在无限次模拟的极限下生成目标分布的渐近精确样本，其贪婪变体DTS$^\star$则通过全局搜索寻找高奖励样本。在MNIST和CIFAR-10的条件生成任务中，DTS以10倍更少的计算量达到最佳基线的FID分数。在文本到图像生成和语言完成任务中，DTS$^\star$以5倍更少的计算量匹配最佳样本。通过重用过去生成的信息，我们获得了一种随时可用的算法，将额外计算转化为持续改进的样本质量，为扩散模型的推理时对齐提供了可扩展的解决方案。

</details>


### [169] [On Convolutions, Intrinsic Dimension, and Diffusion Models](https://arxiv.org/abs/2506.20705)
**中文标题：关于卷积、内在维度与扩散模型**

*Kin Kwan Leung,Rasa Hosseinzadeh,Gabriel Loaiza-Ganem*

主要分类: cs.LG

摘要简述: 本文证明了FLIPD（一种基于扩散模型的局部内在维度估计器）在现实假设下的正确性，并扩展了其理论支持，包括均匀卷积的情况。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型（DMs）在高维数据生成中表现出色，但其局部内在维度（LID）估计器FLIPD的理论基础仅在不现实的仿射子流形假设下被证明。本文旨在填补这一理论空白，并在更现实的假设下验证FLIPD的正确性。

研究方法: 通过理论分析，本文证明了FLIPD在现实假设下的正确性，并进一步探讨了将高斯卷积替换为均匀卷积时的类似结果。

研究结果: 研究证实了FLIPD在现实假设下的有效性，并表明均匀卷积也能实现类似的理论结果。

研究结论: 本文为FLIPD提供了更坚实的理论基础，扩展了其适用范围，并揭示了均匀卷积在LID估计中的潜力。

中文摘要: 流形假设认为，高维环境空间（如图像数据）中的数据位于未知的低维子流形上。扩散模型（DMs）通过逐步增加高斯噪声并学习逆转这一过程，已成为性能最优的生成模型，且已知能够学习低维支撑的分布。对于子流形中的某个数据点，我们直观上期望DMs能够隐式学习其局部内在维度（LID），即其所属子流形的维度。Kamkari等人（2024b）最近通过将LID与DM对数边际密度随噪声量的变化率联系起来，证明了这一点，并提出了一种名为FLIPD的LID估计器。LID估计器（如FLIPD）具有多种用途，例如量化数据复杂性、检测异常值、对抗样本和AI生成文本。FLIPD在LID估计中达到了最先进的性能，但其理论基础尚不完整，因为Kamkari等人（2024b）仅在高度不现实的仿射子流形假设下证明了其正确性。本文通过在实际假设下正式证明FLIPD的正确性填补了这一空白。此外，我们还证明了在高斯卷积替换为均匀卷积时类似结果成立，并讨论了这一结果的意义。

</details>


### [170] [Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset](https://arxiv.org/abs/2506.20729)
**中文标题：理论物理中的测试时扩展技术——基于TPBench数据集的方法比较**

*Zhiqi Gao,Tianyi Li,Yurii Kvasiuk,Sai Chaitanya Tadepalli,Maja Rudolph,Daniel J. H. Chung,Frederic Sala,Moritz Münchmeyer*

主要分类: cs.LG

摘要简述: 本文研究了测试时扩展技术在理论物理领域的应用，通过TPBench数据集比较了多种方法的有效性，并提出了一种新颖的符号弱验证框架，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在复杂推理中表现出色，但测试时扩展技术能否在高级理论物理领域推广尚不明确。本文旨在验证这些方法在物理问题中的有效性，并探索如何利用物理问题的结构提升性能。

研究方法: 研究在TPBench物理数据集上评估了多种测试时扩展方法，并与AIME数学基准结果对比。提出了一种符号弱验证框架，利用物理问题的结构优化并行扩展效果。

研究结果: 实验结果表明，符号弱验证框架在TPBench上显著优于现有测试时扩展方法，同时在AIME上也验证了其解决高级数学问题的有效性。

研究结论: 研究证明了逐步符号验证在解决复杂科学问题中的强大能力，为测试时扩展技术在理论物理领域的应用提供了新思路。

中文摘要: 大型语言模型（LLMs）在复杂推理中表现出强大能力，而测试时扩展技术能以较低成本提升其性能。这些方法已在数学推理基准（如AIME）上得到验证。本文探讨这些经验是否适用于高级理论物理领域。我们在TPBench物理数据集上评估了多种常见测试时扩展方法，并与AIME结果进行比较。为了更好地利用物理问题的结构，我们开发了一种新颖的符号弱验证框架，以优化并行扩展效果。实验结果表明，该方法在TPBench上显著优于现有测试时扩展方法。同时，在AIME上的验证也证实了其解决高级数学问题的有效性。我们的发现凸显了逐步符号验证在解决复杂科学问题中的潜力。

</details>


### [171] [Stochastic Parameter Decomposition](https://arxiv.org/abs/2506.20790)
**中文标题：随机参数分解**

*Lucius Bushnaq,Dan Braun,Lee Sharkey*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“随机参数分解”（SPD）的新方法，用于解决现有线性参数分解方法（如APD）的计算成本高和超参数敏感性问题。SPD更具可扩展性和鲁棒性，能够分解更大、更复杂的模型，并避免参数收缩等问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前主流的线性参数分解方法（如APD）存在计算成本高和对超参数敏感的问题，限制了其在大规模模型中的应用。本文旨在提出一种更高效、更稳健的分解方法，以推动神经网络逆向工程的研究。

研究方法: 本文提出了随机参数分解（SPD）方法，通过结合因果中介分析和网络分解技术，解决了APD方法的计算和超参数问题。SPD通过随机化策略提高了可扩展性，并优化了参数分解的鲁棒性。

研究结果: 实验表明，SPD能够分解比APD更大、更复杂的模型，避免了参数收缩问题，并在玩具模型中更准确地识别真实机制。此外，SPD的开源库为相关研究提供了工具支持。

研究结论: SPD方法通过改进线性参数分解的可扩展性和鲁棒性，为神经网络机理可解释性研究开辟了新方向。其开源实现进一步推动了该领域的应用与发展。

中文摘要: 逆向工程神经网络的一个关键步骤是将其分解为可以相对独立研究的更简单部分。线性参数分解——一种旨在解决当前分解方法问题的框架——将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，该框架中的当前主要方法——基于归因的参数分解（APD）——由于计算成本高和对超参数敏感而不实用。本文提出了“随机参数分解”（SPD），一种比APD更具可扩展性和超参数鲁棒性的方法，并通过分解比APD所能处理的更大、更复杂的模型进行了验证。我们还表明，SPD避免了其他问题，如学习参数的收缩，并在玩具模型中更好地识别了真实机制。通过将因果中介分析与网络分解方法相结合，这一演示为机理可解释性研究开辟了新的可能性，消除了将线性参数分解方法扩展到更大模型的障碍。我们在https://github.com/goodfire-ai/spd发布了运行SPD和复现实验的库。

</details>


### [172] [GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization](https://arxiv.org/abs/2506.20807)
**中文标题：GPU内核科学家：一种基于LLM的迭代内核优化框架**

*Martin Andrews,Sam Witteveen*

主要分类: cs.LG

摘要简述: 本文提出了一种基于大语言模型（LLM）的自动化方法“GPU Kernel Scientist”，用于迭代优化GPU内核，尤其适用于资源受限或硬件快速演进的场景。


<details>
  <summary>详细信息</summary>
研究动机: 优化GPU内核以提升性能是一项复杂任务，尤其在新架构或文档不足的硬件上，传统开发工具稀缺。本文旨在通过LLM驱动的自动化方法解决这一挑战。

研究方法: 方法采用多阶段进化过程：(a) 选择有潜力的旧代码版本作为新迭代基础；(b) 基于现有代码和GPU文献生成优化假设；(c) 通过代码修改和外部评估系统自主实现实验，仅用时序数据作为反馈。

研究结果: 由于性能竞赛的定量结果在提交时被限制，本文重点展示了架构设计、工作流程和定性见解，证明了LLM驱动代理在GPU内核优化中的潜力。

研究结论: LLM驱动的GPU内核优化方法有望降低技术门槛并加速优化过程，特别适用于资源受限或硬件快速变化的环境。

中文摘要: 优化GPU内核以实现高性能是一项复杂任务，通常需要深入的架构知识、大量性能分析和迭代实验。这一挑战在针对较新或文档较少的GPU架构时尤为突出，传统开发辅助工具稀缺。本文提出了一种基于大语言模型（LLM）的“GPU内核科学家”方法，用于自动化迭代优化加速器内核。

我们的方法采用多阶段进化过程：(a) 策略性地选择有潜力的旧代码版本作为新迭代的基础；(b) 基于现有代码和GPU文献生成优化实验假设；(c) 通过代码修改和外部评估系统自主实现这些实验，仅用时序数据作为性能反馈。我们详细描述了该方法如何应对AMD MI300目标架构的挑战，并利用LLM弥补领域特定人类专业知识的不足。

由于在论文提交时性能竞赛的定量结果受到限制，我们展示了架构设计、操作流程和定性见解，突出了LLM驱动代理在GPU内核优化中的潜力，尤其是在资源受限或硬件快速演进的环境中。

</details>


### [173] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
**中文标题：FINN-GL：面向FPGA加速LSTM的广义混合精度扩展**

*Shashwat Khandelwal,Jakoba Petri-Koenig,Thomas B. Preußer,Michaela Blott,Shreejith Shanker*

主要分类: cs.LG

摘要简述: 本文提出了一种基于FINN框架的广义混合精度扩展方法FINN-GL，用于在FPGA上高效部署LSTM模型，解决了现有工具主要针对前馈网络的问题，并通过量化技术和硬件映射优化实现了性能与资源消耗的平衡。


<details>
  <summary>详细信息</summary>
研究动机: LSTM等循环神经网络在时间序列任务中表现优异，但其计算复杂度高，难以在资源受限的环境中实时部署。FPGA虽能高效加速AI任务，但现有工具主要针对前馈网络，LSTM加速通常需要完全定制实现。本文旨在填补这一空白，通过扩展FINN框架实现LSTM的广义部署。

研究方法: 利用ONNX规范中的Scan操作符建模LSTM的循环计算特性，支持混合量化及功能验证；在FINN编译器中引入自定义变换，将量化后的ONNX计算图映射到FINN编译器和Vitis HLS的硬件块库中。

研究结果: 通过量化ConvLSTM模型在股票价格预测任务中的验证，生成的硬件IP在XCZU7EV设备上实现了性能（延迟）与资源消耗的平衡，同时保持了与现有高精度模型相当（或更优）的推理精度。

研究结论: 提出的FINN-GL流程具有通用性，为FPGA上资源高效的RNN加速器设计铺平了道路。

中文摘要: 循环神经网络（RNN），尤其是LSTM，在情感分析和短期股票预测等时间序列任务中表现优异。然而，其计算复杂度为资源受限环境中的实时部署带来挑战。尽管FPGA为高效能AI加速提供了理想平台，现有工具主要针对前馈网络，而LSTM加速通常需要完全定制实现。本文通过利用开源可扩展的FINN框架，填补了这一空白，实现了LSTM在FPGA上的广义部署。具体而言，我们利用开放神经网络交换（ONNX）规范中的Scan操作符建模LSTM的循环计算特性，支持其内部的混合量化及基于LSTM模型的功能验证。此外，我们在FINN编译器中引入自定义变换，将量化后的ONNX计算图映射到FINN编译器和Vitis HLS的硬件块库中。通过训练一个用于股票中间价预测任务的量化ConvLSTM模型，并使用广泛采用的数据集生成对应的硬件IP，我们验证了所提工具流程的有效性，目标设备为XCZU7EV。结果表明，生成的量化ConvLSTM加速器在性能（延迟）与资源消耗之间取得了平衡，同时与现有高精度模型的推理精度相当（或更优）。我们相信，所提流程的通用性将为FPGA上资源高效的RNN加速器设计开辟新途径。

</details>


### [174] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
**中文标题：更少的训练，更低的泄露：重新审视LoRA微调中LLM的记忆问题**

*Fei Wang,Baochun Li*

主要分类: cs.LG

摘要简述: 研究发现，LoRA微调显著降低大语言模型（LLM）的记忆风险，同时保持任务性能，与传统微调方法表现不同。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在微调过程中容易因记忆数据而面临数据提取攻击的风险。尽管预训练阶段的记忆问题已被广泛研究，但针对LoRA微调这一高效参数方法的研究较少。本文旨在重新审视微调中的记忆问题，并揭示LoRA微调与传统方法的不同表现。

研究方法: 通过使用基于相似性的记忆度量方法，对比分析了LoRA微调和全参数微调在模型规模和数据重复等因素下的记忆表现差异。

研究结果: 研究表明，LoRA微调显著降低了记忆风险，且任务性能不受影响，而模型规模和数据重复对记忆的影响与传统微调方法不同。

研究结论: LoRA微调是一种更安全的微调方法，能够有效减少记忆风险，同时保持模型性能，为LLM的实际应用提供了新的优化方向。

中文摘要: 大型语言模型（LLM）的记忆特性使其容易受到数据提取攻击。尽管预训练阶段的记忆问题已被广泛研究，但针对LoRA微调这一高效参数方法的研究较少。本文重新审视了微调中的记忆问题，并发现不同微调策略下的记忆表现与之前的研究结果存在显著差异。在LoRA微调中，模型规模和数据重复等对记忆有显著影响的因素与传统微调方法表现不同。通过使用更宽松的基于相似性的记忆度量方法，我们证明LoRA微调显著降低了记忆风险，同时仍能保持强大的任务性能。

</details>


### [175] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
**中文标题：SharpZO：基于混合锐度感知的视觉语言模型提示调优方法——仅需前向传播**

*Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种混合锐度感知零阶优化方法（SharpZO），通过仅使用前向传播优化视觉语言模型（VLM）的提示调优，显著提升了性能和收敛速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型微调方法依赖反向传播（BP），不适用于内存受限的边缘设备。虽然已有无反向传播的优化方法，但其性能较差。本文旨在解决这一问题。

研究方法: SharpZO采用两阶段优化：首先通过锐度感知进化策略（ES）全局探索和平滑损失曲面以构建强初始化，随后通过稀疏零阶优化进行细粒度局部搜索。整个过程仅需前向传播。

研究结果: 实验表明，SharpZO在CLIP模型上显著提升了准确性和收敛速度，平均性能优于现有仅前向方法7%。

研究结论: SharpZO为无反向传播的VLM微调提供了一种高效解决方案，适用于边缘设备。

中文摘要: 微调视觉语言模型（VLM）在下游任务中表现出色，但依赖反向传播（BP），不适用于内存受限的边缘设备。现有无BP方法多采用高方差进化策略（ES）或零阶（ZO）优化，性能不佳。本文提出混合锐度感知零阶优化（SharpZO），通过锐度感知预热训练提升ZO VLM微调性能。SharpZO采用两阶段优化：锐度感知ES阶段全局探索并平滑损失曲面以构建强初始化，随后通过稀疏ZO优化进行细粒度局部搜索。整个优化仅需前向传播。理论分析和CLIP模型实验表明，SharpZO显著提升准确性和收敛速度，平均性能优于现有仅前向方法7%。

</details>


### [176] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
**中文标题：利用知识图谱的高质量指令数据增强大语言模型的工具使用能力**

*Jingwei Wang,Zai Zhang,Hao Qian,Chunjing Gan,Binbin Hu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Bin Shi,Bo Dong*

主要分类: cs.LG

摘要简述: 本文提出了一种利用知识图谱生成高质量指令数据的新方法，显著提升大语言模型（LLM）的工具使用能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在工具使用方面的能力有限，主要因为生成的指令数据质量不足。知识图谱因其丰富的语义信息，可作为高质量指令数据的来源。

研究方法: 从知识图谱中提取查询路径，转化为多样化的用户查询；将实体间关系转化为可操作工具，并解析查询路径为详细解决步骤，生成高质量指令数据。

研究结果: 实验表明，仅需少量合成数据微调，即可显著提升大语言模型的工具使用能力和整体性能。

研究结论: 知识图谱生成的指令数据能有效提升大语言模型的工具使用能力，为未来研究提供了新方向。

中文摘要: 教导大语言模型（LLM）使用工具对于提升其问题解决能力和扩展应用至关重要。然而，有效使用工具具有挑战性，因为需要深入理解工具功能和用户意图。以往方法主要依赖LLM生成指令数据，但这些数据的质量往往不足。本文提出了一种新方法，利用知识图谱为LLM生成高质量指令数据。知识图谱是人工整理的富含语义信息的数据集。我们首先从给定知识图谱中提取多种查询路径，并将其转化为广泛的用户查询；随后将实体间关系转化为可操作工具，并将每条查询路径解析为详细的解决步骤，从而生成高质量指令数据。实验表明，仅需少量合成数据微调，即可显著提升LLM的工具使用能力和整体性能。

</details>


### [177] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
**中文标题：学习跳过Transformer的中间层**

*Tim Lawson,Laurence Aitchison*

主要分类: cs.LG

摘要简述: 本文提出了一种动态跳过Transformer中间层的架构，通过门控机制选择性跳过冗余层，但实验表明在验证交叉熵与FLOPs的权衡上未优于密集基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常独立跳过单个模块或层，但研究表明Transformer中间层冗余性较高。本文旨在通过动态跳过中间层来提升效率。

研究方法: 提出一种门控机制，动态跳过对称的中间层块，并采用门控注意力防止后续令牌关注跳过的位置。通过‘三明治’或‘perilayernorm’方案控制残差范数，并使用自适应正则化损失优化门稀疏性。

研究结果: 在验证交叉熵与FLOPs的权衡上，该方法未优于层数较少的密集基线。

研究结论: 尽管动态跳过中间层的设计具有潜力，但在当前规模下未能显著提升效率与性能的权衡。

中文摘要: 条件计算是提升Transformer效率的常用策略。现有方法通常针对单个模块（如混合专家层）或独立跳过层。然而，可解释性研究表明，Transformer的中间层冗余性较高，且早期层将信息聚合到令牌位置。基于这些发现，我们提出了一种新颖架构，动态从中间向外跳过可变数量的层。具体而言，学习的门控机制根据输入决定是否绕过对称的中间块，而门控注意力机制防止后续令牌关注跳过的位置。通过‘三明治’或‘perilayernorm’方案控制残差范数，并通过自适应正则化损失优化门稀疏性。我们旨在减少‘简单’令牌的计算需求，并可能促进多级表示层次的出现，但在研究规模内，该方法在验证交叉熵与估计FLOPs的权衡上未优于层数较少的密集基线。代码发布于https://github.com/tim-lawson/skip-middle。

</details>


### [178] [Omniwise: Predicting GPU Kernels Performance with LLMs](https://arxiv.org/abs/2506.20886)
**中文标题：Omniwise：利用大型语言模型预测GPU内核性能**

*Zixian Wang,Cole Ramos,Muhammad A. Awad,Keith Lowery*

主要分类: cs.LG

摘要简述: Omniwise是一种基于大型语言模型（LLM）的端到端自监督微调管道，用于预测GPU内核性能，无需执行代码或使用分析工具即可预测关键性能指标。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度神经网络（DNNs）的快速发展，GPU内核性能预测成为优化AI模型的重要需求。传统方法依赖代码执行或分析工具，效率低下。Omniwise旨在通过LLM实现高效、轻量级的性能预测。

研究方法: Omniwise采用自监督微调管道，直接通过GPU内核代码预测性能指标（如内存带宽、缓存命中率等）。该方法模型无关且轻量，支持小规模（3B参数）模型。

研究结果: 在AMD MI250和MI300X架构上，Omniwise的预测误差在10%以内的准确率超过90%。此外，还开发了在线推理服务器和Visual Studio Code插件，便于开发者集成。

研究结论: Omniwise为GPU内核性能预测提供了一种高效、准确的解决方案，显著提升了开发效率，并展示了LLM在性能分析中的潜力。

中文摘要: 近年来，深度神经网络（DNNs）的快速发展彻底改变了人工智能，使模型在理解、生成和处理复杂数据方面具备了前所未有的能力。这些强大的架构已广泛应用于下游任务，解决了人类难以企及的问题。本文介绍了Omniwise，这是首个端到端、自监督的微调管道，将大型语言模型（LLM）应用于GPU内核性能预测——性能分析中的一项新颖用例。Omniwise模型无关且轻量，即使使用3B参数的小模型也能取得优异结果。它可以直接从内核代码预测关键性能指标（如内存带宽、缓存命中率、GFLOPs和算术强度），无需执行代码或使用分析工具。我们的方法在AMD MI250和MI300X架构上运行的GPU内核中，预测误差在10%以内的准确率超过90%。除管道外，我们还开发了在线推理服务器和Visual Studio Code插件，将基于LLM的性能预测无缝集成到开发者工作流程中。

</details>


### [179] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
**中文标题：复杂度感知的微调方法**

*Andrey Goncharov,Daniil Vyazhev,Petr Sychev,Edvard Khalafyan,Alexey Zaytsev*

主要分类: cs.LG

摘要简述: 本文提出了一种基于熵识别复杂数据的高效微调方法，通过将训练数据按复杂度分类，结合监督微调和蒸馏技术，显著提升了小规模开源模型的性能，同时减少了数据需求。


<details>
  <summary>详细信息</summary>
研究动机: 通用大型语言模型（LLMs）通常通过监督微调（SFT）提升特定领域性能，但传统方法需要大量数据和昂贵调用。本文旨在通过识别复杂数据并针对性优化，实现高效微调。

研究方法: 通过单标记答案熵（ROC AUC 0.73）将训练数据分为复杂度类别，结合监督微调（SFT）和蒸馏技术，对两个小规模开源模型（≈3B）进行微调。

研究结果: 该方法显著优于标准SFT（平均准确率0.55 vs 0.43），与蒸馏性能相当，同时减少62%的数据使用（两者平均准确率均为0.55）。

研究结论: 提出的复杂度感知微调方法在提升性能的同时大幅降低数据需求，为高效微调提供了新思路。代码和数据已公开以促进后续研究。

中文摘要: 通用大型语言模型（LLMs）通常通过监督微调（SFT）提升特定领域性能。通过蒸馏更大模型的思维链可以取得更好结果，但需要大量昂贵调用和数据。我们提出了一种基于熵识别复杂数据的高效微调方法。具体而言，在两个小规模开源模型（≈3B）中，通过单标记答案熵（ROC AUC 0.73）将训练数据分为复杂度类别，结合SFT和蒸馏技术微调LLMs。结果表明，我们的方法显著优于标准SFT（平均准确率0.55 vs 0.43），与蒸馏性能相当，同时减少62%的数据使用（两者平均准确率均为0.55）。我们公开了代码和数据以促进相关研究。

</details>


### [180] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
**中文标题：DiLoCoX：一种低通信的大规模去中心化集群训练框架**

*Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich*

主要分类: cs.LG

摘要简述: DiLoCoX是一种低通信的大规模去中心化集群训练框架，通过结合流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案，显著提升了参数规模和模型预训练速度。实验证明，该框架能在1Gbps网络上预训练107B参数的基础模型，相比传统方法提速357倍。


<details>
  <summary>详细信息</summary>
研究动机: 当前分布式训练（尤其是大型语言模型）高度依赖高速网络和集中式集群，限制了在慢速网络或去中心化环境中的应用。DiLoCoX旨在解决这一问题，使大规模模型训练能够在低通信环境下高效进行。

研究方法: DiLoCoX结合了流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案。通过理论分析验证了这些方法的收敛性优势。

研究结果: 实验表明，DiLoCoX能在1Gbps网络上预训练107B参数的基础模型，相比传统AllReduce方法提速357倍，且模型收敛性几乎不受影响。

研究结论: DiLoCoX是首个成功应用于100B以上参数模型的去中心化训练框架，为慢速网络环境下的高效训练提供了可行方案。

中文摘要: 基础模型（尤其是大型语言模型）的分布式训练对通信要求极高，因此高度依赖具有快速可靠互连的集中式集群。我们能否在慢速网络上进行训练，从而释放去中心化集群在处理超过1000亿参数模型时的潜力？本文提出DiLoCoX，一种低通信的大规模去中心化集群训练框架。它结合了流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案，显著提升了参数规模和模型预训练速度。通过收敛性理论分析，我们验证了一步延迟重叠和自适应梯度压缩的优势。实验证明，DiLoCoX能够在1Gbps网络上预训练107B基础模型，相比传统AllReduce方法提速357倍，且模型收敛性几乎不受影响。据我们所知，这是首个成功应用于100B以上参数模型的去中心化训练框架。

</details>


### [181] [LLM-guided Chemical Process Optimization with a Multi-Agent Approach](https://arxiv.org/abs/2506.20921)
**中文标题：基于多智能体框架的LLM引导化学过程优化**

*Tong Zeng,Srivathsan Badrinarayanan,Janghoon Ock,Cheng-Kai Lai,Amir Barati Farimani*

主要分类: cs.LG

摘要简述: 本文提出了一种基于多智能体框架的化学过程优化方法，利用大型语言模型（LLM）智能体自主推断操作约束，并通过协作优化提升效率。该方法在计算效率和性能上均优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 化学过程优化通常依赖明确的约束条件，但在约束不明确或缺失时，传统方法难以适用。本文旨在解决这一问题，通过智能体框架自主推断约束并优化过程。

研究方法: 采用基于AutoGen的多智能体框架，包括约束生成、参数验证、模拟执行和优化指导等智能体，分两阶段实现：自主约束生成和迭代多智能体优化。

研究结果: 在氢化脱烷基过程中验证，该方法在成本、产量和产量-成本比等指标上表现优异，计算效率提升31倍，收敛时间少于20分钟。

研究结论: 该方法在约束不明确或缺失的优化场景中具有显著潜力，尤其适用于新兴过程和改造应用。

中文摘要: 化学过程优化对提升生产效率和经济效益至关重要。传统方法（如梯度求解器、进化算法和参数网格搜索）在操作约束不明确或缺失时难以适用，工程师需依赖主观启发式估计可行参数范围。为解决这一约束定义瓶颈，我们提出了一种基于大型语言模型（LLM）智能体的多智能体框架，能够从最小过程描述中自主推断操作约束，并协作指导优化。该框架基于AutoGen，采用OpenAI的o3模型，包含约束生成、参数验证、模拟执行和优化指导等专用智能体。通过两阶段（基于嵌入领域知识的自主约束生成和迭代多智能体优化），框架无需预定义操作边界。在氢化脱烷基过程中验证，该框架在成本、产量和产量-成本比等指标上与传统方法表现相当，但计算效率更高，收敛所需迭代次数更少。该方法在20分钟内收敛，比网格搜索快31倍。此外，其推理引导的搜索展示了高级过程理解能力，正确识别效用权衡并应用领域启发式。该方法在操作约束不明确或缺失的优化场景中具有显著潜力，尤其适用于新兴过程和改造应用。

</details>


### [182] [Interpretable Representation Learning for Additive Rule Ensembles](https://arxiv.org/abs/2506.20927)
**中文标题：可解释的加法规则集成表示学习**

*Shahrzad Behzadimanesh,Pierre Le Bodic,Geoffrey I. Webb,Mario Boley*

主要分类: cs.LG

摘要简述: 本文提出了一种可解释的加法规则集成学习方法，通过引入可学习的稀疏线性变换扩展传统规则集成，以生成具有斜面的决策区域，从而在保持高准确性的同时显著降低模型复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 传统的符号规则集成虽然具有高解释性，但依赖于精心设计的输入特征，否则需要增加规则数量和复杂性，从而降低模型解释性。本文旨在通过引入可学习的稀疏线性变换，提升规则集成的表达能力，同时保持其解释性。

研究方法: 本文扩展了经典规则集成，引入了可学习的稀疏线性变换（形式为$\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$），并提出了一种基于迭代加权逻辑回归的序列贪婪优化学习方法。

研究结果: 实验结果表明，该方法在十个基准数据集上能够高效构建与现有方法测试风险相当的规则集成，同时显著降低模型复杂度。

研究结论: 通过引入可学习的稀疏线性变换，本文方法在保持规则集成解释性的同时，显著提升了其表达能力，为可解释机器学习提供了新的思路。

中文摘要: 小型符号规则的加法集成提供了可解释的预测模型。传统上，这些集成使用基于单输入变量$x$和阈值$t$的简单阈值命题$x \geq t$的合取规则条件，几何上表现为轴平行多面体作为决策区域。虽然这种形式确保了单个规则的高度可解释性，并且可以通过梯度提升方法高效学习，但它依赖于一组精心设计的表达性和独立性输入特征，以便少量轴平行区域能够很好地描述目标变量。若缺乏此类特征，要达到足够的准确性需要增加规则数量和复杂性，从而降低模型的可解释性。本文通过引入可学习的稀疏线性变换（形式为$\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$）扩展了经典规则集成，其中$\mathbf{w}$是可学习的稀疏权重向量，从而生成具有斜面的通用多面体决策区域。我们提出了一种基于迭代加权逻辑回归的序列贪婪优化学习方法。实验结果表明，该方法在十个基准数据集上能够高效构建与现有方法测试风险相当的规则集成，同时显著降低模型复杂度。

</details>


### [183] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
**中文标题：潜在原型路由：在混合专家中实现近乎完美的负载平衡**

*Jiajie Yang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为潜在原型路由（LPR）的新方法，用于解决混合专家（MoE）架构中的负载不平衡问题，显著提高了专家利用率和计算资源效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前混合专家（MoE）系统存在严重的负载不平衡问题，仅少数专家在训练和推理中被激活，导致模型容量和计算资源的大量浪费。本文旨在通过改进路由机制，实现专家负载的均衡分配。

研究方法: 本文从聚类视角重新审视专家路由，提出了潜在原型路由（LPR）框架。LPR在保持下游性能的同时，通过推广现有方法，显著提升了专家负载的均衡性。

研究结果: 实验表明，LPR将专家负载的基尼系数从0.70降至0.035，最小-最大专家负载比从1e-6提升至0.70，实现了近乎完美的负载平衡。

研究结论: LPR是一种高效的专家路由框架，能够显著改善MoE系统的负载均衡性，同时不影响模型性能，为大规模语言模型的高效扩展提供了新思路。

中文摘要: 混合专家（MoE）架构已成为高效扩展大规模语言模型（LLM）的关键策略。然而，当前的MoE系统存在严重的负载不平衡问题，仅有少数专家在训练和推理中被持续激活，导致模型容量和计算资源的显著浪费。本文从聚类视角重新审视专家路由，提出了潜在原型路由（LPR），这是一种新型路由框架，既能推广现有方法，又能促进专家负载的均衡分配，同时不影响下游性能。在多个开源MoE模型（包括DeepSeek-V3、Qwen3-MoE和Mixtral）上的广泛实验表明，LPR将专家负载的基尼系数从0.70降至0.035，最小-最大专家负载比从1e-6提升至0.70，实现了近乎完美的负载平衡。

</details>


### [184] [Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding](https://arxiv.org/abs/2506.20957)
**中文标题：基于多尺度等变图扩散模型的抗体设计与优化以实现精准复杂抗原结合**

*Jiameng Chen,Xiantao Cai,Jia Wu,Wenbin Hu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为AbMEGD的端到端框架，通过多尺度等变图扩散模型实现抗体序列与结构的协同设计，显著提升了复杂抗原结合的准确性和功能性。


<details>
  <summary>详细信息</summary>
研究动机: 当前抗体设计方法在捕捉几何特征和泛化新型抗原界面方面存在局限性，无法准确模拟分子相互作用和保持结构完整性。本文旨在解决这些问题。

研究方法: AbMEGD结合了原子级几何特征和残基级嵌入，利用E(3)-等变扩散方法确保几何精度和计算效率，实现了局部原子细节与全局序列-结构交互的捕捉。

研究结果: 实验表明，AbMEGD在SAbDab数据库中，氨基酸恢复率提高了10.13%，改进百分比提升了3.32%，CDR-H3区域的均方根偏差减少了0.062 Å，优于现有模型DiffAb。

研究结论: AbMEGD在保持结构完整性的同时显著提升了功能性，为抗体序列-结构协同设计和亲和力优化设立了新标杆。

中文摘要: 抗体设计在治疗和诊断开发中仍是一个关键挑战，尤其是针对具有多样化结合界面的复杂抗原。当前计算方法存在两大局限：(1) 在保持对称性的同时捕捉几何特征，(2) 泛化新型抗原界面。尽管近期有所进展，这些方法仍难以准确模拟分子相互作用并保持结构完整性。为解决这些问题，我们提出了AbMEGD，一个端到端框架，整合了多尺度等变图扩散以实现抗体序列与结构的协同设计。通过先进的几何深度学习，AbMEGD将原子级几何特征与残基级嵌入相结合，捕捉局部原子细节和全局序列-结构交互。其E(3)-等变扩散方法确保了几何精度、计算效率以及对复杂抗原的强泛化能力。此外，基于SAbDab数据库的实验表明，与领先的抗体设计模型DiffAb相比，AbMEGD在关键CDR-H3区域的氨基酸恢复率提高了10.13%，改进百分比提升了3.32%，均方根偏差减少了0.062 Å。这些结果凸显了AbMEGD在平衡结构完整性与功能改进方面的能力，为序列-结构协同设计和亲和力优化设立了新标杆。代码已发布于：https://github.com/Patrick221215/AbMEGD。

</details>


### [185] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
**中文标题：通过随机变分子空间推理实现大型语言模型的可扩展贝叶斯低秩适应**

*Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ScalaBL的可扩展贝叶斯低秩适应方法，通过随机变分子空间推理，解决了大型语言模型（LLM）在不确定性量化中的计算扩展性问题。该方法仅需约1000额外参数，即可实现与现有技术竞争的性能，并成功应用于迄今为止最大的贝叶斯LLM。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）存在幻觉问题和校准不足，不确定性量化在高风险领域尤为重要。现有贝叶斯深度学习方法通过低秩适应（LoRA）参数进行推理，但难以扩展到更大的LLM，因为需要额外参数。本文旨在解决这一扩展性问题。

研究方法: 本文提出ScalaBL方法，在LoRA秩为r的r维子空间中进行贝叶斯推理，利用LoRA参数作为投影矩阵，将子空间样本映射到LLM的完整权重空间。通过随机变分推理学习所有参数，仅需少量额外参数。

研究结果: 实验表明，ScalaBL在低维子空间中实现了与现有技术竞争的性能，仅需约1000额外参数，并成功扩展至迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

研究结论: ScalaBL通过随机变分子空间推理，提供了一种可扩展的贝叶斯低秩适应方法，解决了LLM不确定性量化的扩展性问题，同时保持了高性能和低参数需求。

中文摘要: 尽管大型语言模型（LLM）被广泛使用，但它们存在幻觉错误信息和校准不足的问题，这使得其不确定性量化尤为重要，尤其是在高风险领域（如自主系统和医疗保健）。先前的研究通过低秩适应（LoRA）参数对微调模型进行推理，使贝叶斯深度学习方法更具可行性。然而，这些方法由于需要比LoRA更多的额外参数，难以扩展到更大的LLM。本文提出了一种名为ScalaBL（可扩展贝叶斯低秩适应）的方法，通过随机变分子空间推理，在LoRA秩为r的r维子空间中进行贝叶斯推理。通过将LoRA参数重新用作投影矩阵，我们可以将子空间样本映射到LLM的完整权重空间。这使得我们能够使用随机变分推理学习所有参数。尽管子空间维度较低，但我们的方法仅需约1000额外参数，即可实现与现有技术竞争的性能。此外，该方法使我们能够扩展至迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

</details>


### [186] [Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2506.21039)
**中文标题：严格子目标执行：分层强化学习中可靠的长时程规划**

*Jaebak Hwang,Sanghyeon Lee,Jeongmo Kim,Seungyul Han*

主要分类: cs.LG

摘要简述: 本文提出了一种名为严格子目标执行（SSE）的分层强化学习框架，通过强制单步子目标可达性和动态路径优化，显著提升了长时程任务中的规划效率和成功率。


<details>
  <summary>详细信息</summary>
研究动机: 长时程目标导向任务在强化学习中面临目标遥远和奖励稀疏的挑战，现有分层和图基方法常因子目标不可行或规划效率低而表现不佳。

研究方法: SSE通过结构约束高层决策确保单步子目标可达性，采用解耦探索策略系统遍历未探索目标区域，并通过动态调整边成本的失败感知路径优化提升子目标可靠性。

研究结果: 在多种长时程基准测试中，SSE在效率和成功率上均优于现有目标导向和分层强化学习方法。

研究结论: SSE通过严格子目标执行和动态路径优化，为长时程任务提供了一种高效可靠的规划解决方案。

中文摘要: 长时程目标导向任务对强化学习（RL）提出了根本性挑战，尤其是当目标遥远且奖励稀疏时。尽管分层和图基方法提供了部分解决方案，但它们常因子目标不可行和规划效率低下而受限。我们提出了严格子目标执行（SSE），一种基于图的分层RL框架，通过结构约束高层决策强制单步子目标可达性。为增强探索，SSE采用解耦探索策略系统遍历目标空间中未探索的区域。此外，失败感知路径优化通过根据观察到的低层成功率动态调整边成本，从而提升子目标可靠性。在多种长时程基准测试中的实验结果表明，SSE在效率和成功率上均优于现有目标导向RL和分层RL方法。

</details>


### [187] [Efficient Skill Discovery via Regret-Aware Optimization](https://arxiv.org/abs/2506.21044)
**中文标题：基于遗憾感知优化的高效技能发现**

*He Zhang,Ming Zhou,Shaopeng Zhai,Ying Sun,Hui Xiong*

主要分类: cs.LG

摘要简述: 本文提出了一种基于遗憾感知优化的高效技能发现方法，通过将技能发现建模为技能生成与策略学习的极小极大博弈，显著提升了高维环境下的效率和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无监督技能发现方法虽在探索性上表现良好，但在高维环境中效率不足。本文旨在通过优化技能生成与策略学习的对抗关系，提升技能发现的效率和多样性。

研究方法: 将技能发现建模为技能生成与策略学习的极小极大博弈，利用遗憾评分衡量技能强度的收敛程度，并通过可学习的技能生成器引导技能发现。为避免退化，技能生成来源于可升级的技能生成器群体。

研究结果: 实验表明，该方法在高维环境中比基线方法效率更高且多样性更优，零样本性能提升了15%。

研究结论: 本文提出的遗憾感知优化方法显著提升了技能发现的效率和多样性，尤其在高维环境中表现优异。

中文摘要: 无监督技能发现旨在开放强化学习中学习多样且可区分的行为。现有方法通过纯探索、互信息优化和时间表征学习提升多样性，但在高维环境中效率有限。本文提出将技能发现建模为技能生成与策略学习的极小极大博弈，通过遗憾感知方法在时间表征学习基础上扩展技能空间。关键思想是技能发现与策略学习是对抗的：强度弱的技能需进一步探索，而强度收敛的技能则减少探索。具体实现中，用遗憾评分技能强度的收敛程度，并通过可学习的技能生成器引导技能发现。为避免退化，技能生成来源于可升级的技能生成器群体。实验表明，该方法在高维环境中效率和多样性均优于基线，零样本性能提升15%。

</details>


### [188] [FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation](https://arxiv.org/abs/2506.21095)
**中文标题：FeDa4Fair：用于公平性评估的客户端级联邦数据集**

*Xenia Heilmann,Luca Corbucci,Mattia Cerrato,Anna Monreale*

主要分类: cs.LG

摘要简述: 本文介绍了FeDa4Fair，一个用于生成定制化表格数据集的库，旨在评估联邦学习中的公平性方法，并发布了四个具有异质偏见的基准数据集。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习（FL）允许多个客户端在不共享私有数据的情况下协作训练模型，但公平性仍是一个关键问题。由于客户端本地数据集的偏见可能影响整个联邦系统，且现有公平性解决方案多关注单一敏感属性，忽略了不同客户端的多样化需求，因此需要更全面的公平性评估工具。

研究方法: 本文提出FeDa4Fair库，用于生成适用于评估公平性FL方法的表格数据集；发布了四个具有异质偏见的基准数据集；提供了现成的公平性评估函数。

研究结果: 通过FeDa4Fair，研究者可以在受控环境中比较不同公平性缓解方法的效果，支持更稳健和可重复的公平性研究。

研究结论: FeDa4Fair为联邦学习中的公平性研究提供了标准化工具和基准数据集，有助于推动更全面的公平性评估方法的发展。

中文摘要: 联邦学习（FL）允许多个客户端在不共享私有数据的情况下协作训练模型，但公平性仍是一个关键问题。由于客户端本地数据集的偏见可能影响整个联邦系统，异质数据分布可能导致模型对某些客户端更公平。尽管已有多种公平性增强解决方案，但大多数关注单一敏感属性（通常是二元属性），忽略了不同客户端的多样化甚至冲突的公平需求。这种局限性可能影响公平性干预措施对不同客户端的有效性。为了支持更稳健和可重复的公平性研究，我们旨在为公平性感知的FL方法提供全球和客户端层面的一致性基准测试。本文的贡献包括：（1）介绍FeDa4Fair，一个用于生成定制化表格数据集的库，专门用于评估异质客户端偏见下的公平性FL方法；（2）发布四个具有异质偏见的基准数据集及相关测试，以在受控环境中比较公平性缓解方法；（3）提供现成的公平性评估函数。

</details>


### [189] [Interpretable Hierarchical Concept Reasoning through Attention-Guided Graph Learning](https://arxiv.org/abs/2506.21102)
**中文标题：通过注意力引导图学习实现可解释的层次概念推理**

*David Debot,Pietro Barbiero,Gabriele Dominici,Giuseppe Marra*

主要分类: cs.LG

摘要简述: 本文提出了一种名为H-CMR的新型概念推理模型，通过注意力机制和图学习实现概念和任务预测的可解释性，同时保持高性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的概念模型（CBMs）仅对最终任务预测提供解释，而概念预测本身仍依赖黑箱神经网络。本文旨在解决这一局限，提出一种同时对概念和任务预测提供解释的模型。

研究方法: H-CMR通过学习有向无环图建模概念间关系，边代表逻辑规则。推理时通过注意力机制选择规则子集，并分层预测所有概念和最终任务。

研究结果: 实验表明，H-CMR在保持高性能的同时，支持通过概念和模型干预增强人机交互，显著提升推理准确性和训练数据效率。

研究结论: H-CMR为概念和任务预测提供了可解释性，同时支持人机交互，为背景知识可用时的数据效率提升提供了可能。

中文摘要: 概念模型（CBMs）是一类通过高层概念解释预测的深度学习模型，但其仅对最终任务预测提供解释，而概念预测本身通常由黑箱神经网络完成。为解决这一问题，我们提出了层次概念记忆推理器（H-CMR），一种同时对概念和任务预测提供解释的新型CBM。H-CMR通过学习有向无环图建模概念间关系，边代表逻辑规则。推理时通过注意力机制选择规则子集，并分层预测所有概念和最终任务。实验结果表明，H-CMR在保持高性能的同时，支持通过概念和模型干预增强人机交互。前者可显著提升推理准确性，后者在背景知识可用时可提升训练数据效率。

</details>


### [190] [Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments](https://arxiv.org/abs/2506.21127)
**中文标题：无人机对抗环境中抗脆弱强化学习的稳健策略切换方法**

*Deepak Kumar Panda,Weisi Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种抗脆弱强化学习框架，通过基于折扣汤普森采样的策略切换机制，动态选择多种稳健策略，以应对无人机在对抗环境中的导航冲突问题。该方法在复杂环境中表现优异，路径更短且冲突率更低。


<details>
  <summary>详细信息</summary>
研究动机: 随着无人机导航自动化的增加，其易受对抗攻击的弱点暴露，现有稳健强化学习方法对分布外变化的适应性有限。本文旨在通过抗脆弱框架提升对更广泛分布变化的适应性。

研究方法: 提出了一种抗脆弱强化学习框架，首先通过考虑策略空间中的多种扰动生成多样化的稳健策略集合，然后将其建模为多臂老虎机问题，利用折扣汤普森采样动态选择最优策略以应对非静态对抗攻击。

研究结果: 在复杂导航环境中，该方法相较于传统稳健强化学习方法，表现出更短的导航路径和更高的无冲突轨迹率，尤其在面对强梯度下降和欺骗攻击时效果显著。

研究结论: 抗脆弱强化学习框架通过动态策略切换机制有效提升了无人机在对抗环境中的适应性，为未来研究提供了新的方向。

中文摘要: 无人机导航自动化的增加使其易受通过传感器操纵的对抗攻击，现有稳健强化学习方法对分布外变化的适应性有限。为此，本文提出了一种抗脆弱强化学习框架，通过基于折扣汤普森采样的策略切换机制动态选择多种稳健策略，以最小化对抗引起的状态-动作-价值分布变化。该方法首先生成多样化的稳健策略集合，并将其建模为多臂老虎机问题，利用折扣汤普森采样优化策略选择以应对非静态对抗攻击。理论分析表明，通过优化折扣汤普森采样以最小化分布变化带来的总体遗憾，能够有效适应未见过的对抗攻击，从而实现抗脆弱性。大量数值模拟验证了该框架在复杂导航环境中的有效性，相较于传统稳健强化学习方法，其导航路径更短且无冲突轨迹率更高。

</details>


### [191] [Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks](https://arxiv.org/abs/2506.21129)
**中文标题：课程引导的抗脆弱强化学习：观测空间攻击下的安全无人机避障**

*Deepak Kumar Panda,Adolfo Perrusquia,Weisi Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种抗脆弱的强化学习框架，通过渐进对抗扰动课程训练，使无人机在观测空间攻击下实现安全避障。该方法通过理论分析和实验验证，显著提升了抗攻击能力和决策稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 在无人机动态空域导航等安全关键系统中，强化学习策略容易受到观测空间分布外（OOD）对抗攻击的影响，导致决策性能下降。现有策略脆弱性高，亟需一种抗脆弱框架以应对未知攻击。

研究方法: 提出了一种抗脆弱强化学习框架，通过模拟攻击者逐步增加观测空间扰动强度，训练智能体适应更广泛的OOD观测。理论定义了脆弱性和抗脆弱性，并通过Wasserstein距离最小化实现专家引导的批评器对齐。

研究结果: 在无人机避障场景中，抗脆弱策略显著优于标准和鲁棒强化学习基线，面对梯度下降攻击和GPS欺骗攻击时，累积奖励提升15%，冲突事件减少30%。

研究结论: 抗脆弱强化学习框架在理论和实践上均可行，能够为动态威胁环境中的安全决策提供保障。

中文摘要: 在安全关键系统（如无人机动态空域导航）中部署的强化学习（RL）策略容易受到观测空间分布外（OOD）对抗攻击的影响。这些攻击导致分布偏移，显著降低价值估计，使现有策略变得脆弱。为解决这一问题，我们提出了一种抗脆弱RL框架，旨在通过渐进对抗扰动课程进行适应。该框架引入模拟攻击者，逐步增加观测空间扰动强度，使RL智能体能够适应更广泛的OOD观测并预测未知攻击。我们首先从理论上描述了脆弱性，将灾难性遗忘定义为价值函数分布随扰动强度增加的单调发散。在此基础上，将抗脆弱性定义为这种价值偏移的有界性，并推导出稳定遗忘的适应条件。我们的方法通过Wasserstein距离最小化，在渐进扰动观测上迭代实现专家引导的批评器对齐。我们在涉及动态3D障碍物的无人机避障场景中进行了实证评估。结果表明，抗脆弱策略在面对梯度下降攻击和GPS欺骗攻击时，始终优于标准和鲁棒RL基线，累积奖励提升15%，冲突事件减少30%。这些发现证明了抗脆弱强化学习在动态威胁环境中实现安全弹性决策的理论和实践可行性。

</details>


### [192] [DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding](https://arxiv.org/abs/2506.21140)
**中文标题：DBConformer：用于EEG解码的双分支卷积Transformer**

*Ziwei Wang,Hongbin Wang,Tianwang Jia,Xingyi He,Siyang Li,Dongrui Wu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DBConformer的双分支卷积Transformer网络，用于解决EEG解码中传统CNN难以捕捉长程时间依赖和全局通道关系的问题。通过结合时间分支和空间分支，并引入轻量级通道注意力模块，DBConformer在多个数据集上表现优异，且参数更少。


<details>
  <summary>详细信息</summary>
研究动机: 传统卷积神经网络（CNN）在EEG解码中难以捕捉长程时间依赖和全局通道关系，而现有的CNN-Transformer混合模型多为串行设计，未能有效整合局部和全局特征，且缺乏显式的通道建模。本文旨在解决这些问题。

研究方法: 提出DBConformer，一种双分支卷积Transformer网络。时间分支（Temporal Conformer）用于建模长程时间依赖，空间分支（Spatial Conformer）用于提取通道间交互。此外，引入轻量级通道注意力模块，通过数据驱动的方式优化通道重要性。

研究结果: 在五个运动想象（MI）数据集和两个癫痫检测数据集上的实验表明，DBConformer在三种评估设置下均优于10个基线模型，且参数比高性能EEG Conformer基线少八倍以上。可视化结果证实其提取的特征具有生理可解释性。

研究结论: DBConformer在性能和可解释性上均表现出色，为EEG解码提供了可靠且高效的解决方案。其代码已开源。

中文摘要: 基于脑电图（EEG）的脑机接口（BCI）将自发/诱发神经活动转化为外部通信的控制命令。尽管卷积神经网络（CNN）仍是EEG解码的主流架构，但其固有的短感受野难以捕捉长程时间依赖和全局通道关系。近期的CNN-Transformer混合模型（Conformers）部分解决了这一问题，但多数采用串行设计，导致局部和全局特征的整合不理想，且常忽略显式的通道建模。为解决这些局限，我们提出DBConformer，一种专为EEG解码设计的双分支卷积Transformer网络。它集成了时间Conformer以建模长程时间依赖，以及空间Conformer以提取通道间交互，从而同时捕捉EEG信号的时间动态和空间模式。一个轻量级通道注意力模块通过数据驱动的方式为EEG通道分配重要性，进一步优化空间表示。在五个运动想象（MI）数据集和两个癫痫检测数据集上的大量实验表明，DBConformer在三种评估设置下均优于10个竞争基线模型，且参数比高性能EEG Conformer基线少八倍以上。此外，可视化结果证实DBConformer提取的特征具有生理可解释性，并与MI中的感觉运动先验一致。DBConformer的卓越性能和可解释性使其成为稳健且可解释的EEG解码的可靠选择。代码已公开于https://github.com/wzwvv/DBConformer。

</details>


### [193] [Linearity-based neural network compression](https://arxiv.org/abs/2506.21146)
**中文标题：基于线性特性的神经网络压缩**

*Silas Dobler,Florian Lemmerich*

主要分类: cs.LG

摘要简述: 本文提出了一种基于线性特性的神经网络压缩新方法，通过合并行为接近线性的神经元层，实现无损压缩，可将模型大小减少至原始的四分之一。


<details>
  <summary>详细信息</summary>
研究动机: 当前神经网络压缩方法主要通过测量参数重要性和冗余性来减少不必要参数。为了进一步提升现有优化方案，本文提出基于线性特性的压缩方法，利用ReLU类激活函数中行为接近线性的神经元特性，实现更高效的压缩。

研究方法: 该方法基于理论分析，利用ReLU类激活函数中行为接近线性的神经元特性，通过合并后续层实现压缩。实验验证了该方法的有效性。

研究结果: 实验结果表明，该方法在多数测试模型上实现了无损压缩，模型大小减少至原始的四分之一。此外，该方法与基于重要性的剪枝方法结合时干扰极小，展示了多种压缩技术的成功组合潜力。

研究结论: 本文为一种新型神经网络压缩方法奠定了基础，能够实现更小、更高效的模型，为未来研究提供了新方向。

中文摘要: 在神经网络压缩领域，当前大多数方法通过测量参数重要性和冗余性来减少不必要的参数。为了进一步提升已高度优化的现有方案，我们提出了一种基于线性特性的压缩方法，作为一种减少神经网络权重的新途径。该方法基于以下直觉：对于ReLU类激活函数，那些几乎总是被激活的神经元表现出线性行为，从而允许合并后续层。我们介绍了支持这种压缩的理论，并通过实验评估了我们的方法。我们的新方法在大多数测试模型上实现了无损压缩，模型大小减少至原始的四分之一。将我们的方法应用于已基于重要性剪枝的模型时，显示出不同类型压缩之间的干扰极小，证明了多种技术成功结合的可能性。总体而言，我们的工作为一种新型压缩方法奠定了基础，能够实现更小、最终更高效的神经网络模型。

</details>


### [194] [rQdia: Regularizing Q-Value Distributions With Image Augmentation](https://arxiv.org/abs/2506.21367)
**中文标题：rQdia：通过图像增强正则化Q值分布**

*Sam Lerman,Jing Bi*

主要分类: cs.LG

摘要简述: rQdia通过图像增强正则化Q值分布，提升基于像素的深度强化学习性能，显著提高了DrQ、SAC和Data-Efficient Rainbow在多个任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 在基于像素的深度强化学习中，Q值分布的不稳定性可能影响模型性能。rQdia旨在通过图像增强技术正则化Q值分布，提升模型的样本效率和长期训练效果。

研究方法: rQdia通过引入一个简单的辅助损失函数，利用均方误差（MSE）均衡增强图像和原始图像的Q值分布，从而正则化Q值分布。

研究结果: 实验表明，rQdia显著提升了DrQ和SAC在MuJoCo连续控制任务中的表现（分别9/12和10/12任务），以及Data-Efficient Rainbow在Atari游戏中的表现（18/26环境）。此外，rQdia首次使基于像素的无模型连续控制超越了状态编码基线。

研究结论: rQdia通过正则化Q值分布，有效提升了基于像素的深度强化学习性能，为模型在样本效率和长期训练中的表现提供了显著改进。

中文摘要: rQdia通过增强图像正则化Q值分布，用于基于像素的深度强化学习。通过一个简单的辅助损失函数，利用均方误差（MSE）均衡这些分布，rQdia显著提升了DrQ和SAC在MuJoCo连续控制任务中的表现（分别9/12和10/12任务），以及Data-Efficient Rainbow在Atari游戏中的表现（18/26环境）。改进体现在样本效率和长期训练中。此外，rQdia首次使基于像素的无模型连续控制超越了状态编码基线。

</details>


### [195] [Pay Attention to Small Weights](https://arxiv.org/abs/2506.21374)
**中文标题：关注小权重**

*Chao Zhou,Tom Jacobs,Advait Gadhikar,Rebekka Burkholz*

主要分类: cs.LG

摘要简述: 微调大型预训练神经网络时，小权重与大幅梯度相关，NANOADAM方法动态更新小权重，提升效率并避免灾难性遗忘。


<details>
  <summary>详细信息</summary>
研究动机: 微调大型预训练模型资源消耗高，研究发现小权重与大幅梯度相关，尤其在微调中更显著，因此提出动态更新小权重的方法以优化效率。

研究方法: 提出NANOADAM方法，动态更新小权重，无需梯度计算即可确定参数子集，保留大权重以减少灾难性遗忘，并支持更大学习率。

研究结果: 实验表明，NANOADAM在NLP和视觉任务中表现优异，泛化性能更好，同时减少资源消耗。

研究结论: NANOADAM通过动态更新小权重，显著提升微调效率，避免灾难性遗忘，适用于多种任务。

中文摘要: 微调大型预训练神经网络在内存和计算成本上资源密集。为缓解这一问题，通常限制训练参数子集。通过分析微调中梯度与权重的关系，发现大幅梯度常与小权重相关，尤其在微调中更显著。基于此，提出NANOADAM，动态更新小权重，具有以下优势：1）无需梯度计算即可确定参数子集；2）保留大权重以减少灾难性遗忘；3）支持更大学习率，实验表明其在NLP和视觉任务中泛化性能更优。

</details>


### [196] [Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection](https://arxiv.org/abs/2506.21382)
**中文标题：基于时间感知图注意力网络的加密货币交易欺诈检测**

*Zhi Zheng,Bochuan Zhou,Yuping Song*

主要分类: cs.LG

摘要简述: 本文提出了一种增强型时间感知图注意力网络（ATGAT），用于加密货币交易欺诈检测，通过融合多尺度时间差特征和周期性位置编码、构建时间感知三重注意力机制以及采用加权BCE损失解决类别不平衡问题，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 加密货币交易欺诈检测面临复杂交易模式和严重类别不平衡的双重挑战，传统方法依赖人工特征工程且难以捕捉交易网络中的时间和结构依赖关系。

研究方法: ATGAT包含三个模块：(1) 高级时间嵌入模块，融合多尺度时间差特征与周期性位置编码；(2) 时间感知三重注意力机制，联合优化结构、时间和全局上下文注意力；(3) 加权BCE损失解决类别不平衡。

研究结果: 在Elliptic++数据集上，ATGAT的AUC达到0.9130，比传统方法XGBoost提升9.2%，比GCN提升12.0%，比标准GAT提升10.0%。

研究结论: ATGAT验证了时间感知和三重注意力机制对图神经网络的增强效果，为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广至其他时间图异常检测任务。

中文摘要: 加密货币交易欺诈检测面临日益复杂的交易模式和严重类别不平衡的双重挑战。传统方法依赖人工特征工程，难以捕捉交易网络中的时间和结构依赖关系。本文提出了一种增强型时间感知图注意力网络（ATGAT），通过三个模块提升检测性能：(1) 设计高级时间嵌入模块，融合多尺度时间差特征与周期性位置编码；(2) 构建时间感知三重注意力机制，联合优化结构、时间和全局上下文注意力；(3) 采用加权BCE损失解决类别不平衡。在Elliptic++加密货币数据集上的实验表明，ATGAT的AUC达到0.9130，比最佳传统方法XGBoost提升9.2%，比GCN提升12.0%，比标准GAT提升10.0%。该方法不仅验证了时间感知和三重注意力机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广至其他时间图异常检测任务。

</details>


### [197] [Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach for Efficiency and Low Storage](https://arxiv.org/abs/2506.21465)
**中文标题：优化四阶Runge-Kutta方法：一种动态启发式方法以实现高效和低存储**

*Gavin Lee Goodship,Luis Miralles-Pechuan,Stephen O'Sullivan*

主要分类: cs.LG

摘要简述: 本文提出了一种结合遗传算法（GA）和强化学习（RL）的动态启发式方法，用于优化低存储的四阶Runge-Kutta方法，显著提高了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 在科学和工程领域，如天气预报、空气动力学分析和复杂生物建模中，扩展稳定性Runge-Kutta（ESRK）方法至关重要。然而，高精度、低存储方案的准确性、稳定性和计算效率之间的平衡仍具挑战性。

研究方法: 研究采用混合遗传算法和强化学习方法，通过GA驱动的突变探索搜索空间，并利用RL启发的状态转移机制动态优化启发式选择，从而减少参数并保持四阶精度。

研究结果: 在1D和2D Brusselator系统及稳态Navier-Stokes方程上的测试表明，最优启发式方法比传统ESRK优化过程减少了25%的IPOPT运行时间，同时保持了数值稳定性和准确性。

研究结论: 该研究为数值方法的启发式优化建立了新范式，展示了自适应启发式发现在高保真模拟中提高资源效率的潜力，并拓宽了低存储Runge-Kutta方法在计算流体动力学等领域的应用。

中文摘要: 扩展稳定性Runge-Kutta（ESRK）方法在科学和工程领域的大规模计算问题中至关重要，如天气预报、空气动力学分析和复杂生物建模。然而，平衡高精度、低存储方案的准确性、稳定性和计算效率仍然具有挑战性。本研究提出了一种结合遗传算法（GA）和强化学习（RL）的混合方法，用于自动发现启发式，优化低存储ESRK方法。与传统依赖手动设计启发式或穷举数值搜索的方法不同，我们的方法利用GA驱动的突变探索搜索空间，并通过RL启发的状态转移机制动态优化启发式选择。这实现了系统性的参数减少，同时保持了四阶精度并显著提高了计算效率。所提出的GA-RL启发式优化框架通过在1D和2D Brusselator系统及稳态Navier-Stokes方程上的严格测试验证。最优启发式方法比传统ESRK优化过程减少了25%的IPOPT运行时间，同时保持了数值稳定性和准确性。这些发现表明，自适应启发式发现能够提高高保真模拟中的资源效率，并拓宽低存储Runge-Kutta方法在计算流体动力学、物理模拟等实际应用中的适用性。这项工作为数值方法的启发式优化建立了新范式，为基于深度强化学习和自动机器学习的启发式搜索进一步探索开辟了道路。

</details>


### [198] [Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems](https://arxiv.org/abs/2506.21502)
**中文标题：基于过程挖掘的建模与仿真提升信息物理系统的故障诊断能力**

*Francesco Vitale,Nicola Dall'Ora,Sebastiano Gaiardelli,Enrico Fraccaroli,Nicola Mazzocca,Franco Fummi*

主要分类: cs.LG

摘要简述: 本文提出了一种基于过程挖掘的新型无监督故障诊断方法，结合多变量时间序列分析、过程挖掘和随机模拟，用于提升信息物理系统的故障诊断能力。


<details>
  <summary>详细信息</summary>
研究动机: 信息物理系统（CPS）的故障诊断对系统可靠性和运行效率至关重要，但传统手动建模方法依赖专家知识且模型复杂易错。本文旨在解决这一问题。

研究方法: 方法包括：1）通过多变量时间序列分析检测集体异常；2）将异常转化为结构化事件日志；3）利用过程挖掘提取可解释的Petri网模型；4）结合时间分布进行随机模拟以支持根因分析。

研究结果: 在智能制造的Robotic Arm Dataset（RoAD）上验证了方法的有效性，成功建模、模拟和分类了CPS中的故障行为，并构建了全面的故障字典。

研究结论: 该方法能够支持预测性维护和工业环境中的数字孪生开发，为CPS故障诊断提供了高效且可解释的解决方案。

中文摘要: 信息物理系统（CPS）的故障诊断对于确保系统可靠性和运行效率至关重要，其核心是准确检测异常并识别其根本原因。然而，手动建模故障行为通常需要大量领域知识，且生成的模型复杂、易错且难以解释。为解决这一问题，我们提出了一种新型无监督故障诊断方法，结合多变量时间序列中的集体异常检测、过程挖掘和随机模拟。首先，通过多变量时间序列分析从低级传感器数据中检测集体异常；随后，将这些异常转化为结构化事件日志，通过过程挖掘发现可解释的过程模型；最后，将时间分布融入提取的Petri网中，支持故障行为的随机模拟，从而增强根因分析和行为理解。该方法在智能制造领域广泛认可的基准数据集Robotic Arm Dataset（RoAD）上进行了验证。实验结果表明，该方法能有效建模、模拟和分类CPS中的故障行为，支持构建全面的故障字典，为预测性维护和工业环境中的数字孪生开发提供了基础。

</details>


### [199] [mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale](https://arxiv.org/abs/2506.21550)
**中文标题：mTSBench：大规模多元时间序列异常检测与模型选择基准测试**

*Xiaona Zhou,Constantin Brif,Ismini Lourentzou*

主要分类: cs.LG

摘要简述: mTSBench是迄今为止最大的多元时间序列异常检测基准，涵盖19个数据集和12个应用领域的344个标记时间序列，评估了24种异常检测方法，并揭示了模型选择的重要性及其现有技术的不足。


<details>
  <summary>详细信息</summary>
研究动机: 多元时间序列异常检测（MTS-AD）在医疗、网络安全和工业监控等领域至关重要，但由于变量间复杂依赖关系、时间动态性和稀疏的异常标签，仍具有挑战性。当前缺乏统一的评估标准，因此需要建立一个全面的基准来推动技术进步。

研究方法: 研究团队构建了mTSBench，涵盖344个标记时间序列，涉及19个数据集和12个应用领域。评估了24种异常检测方法，包括基于大型语言模型（LLM）的检测器，并系统性地测试了无监督模型选择技术在标准化条件下的表现。

研究结果: 结果显示，没有单一检测器在所有数据集上表现优异，强调了模型选择的重要性。然而，即使是最先进的选择方法也远未达到最优，揭示了关键的技术缺口。

研究结论: mTSBench提供了一个统一的评估套件，支持严格、可复现的比较，并为未来自适应异常检测和鲁棒模型选择的研究提供了基础。

中文摘要: 多元时间序列异常检测（MTS-AD）在医疗、网络安全和工业监控等领域至关重要，但由于变量间复杂依赖关系、时间动态性和稀疏的异常标签，仍具有挑战性。我们提出了mTSBench，这是迄今为止最大的MTS-AD和无监督模型选择基准，涵盖19个数据集和12个应用领域的344个标记时间序列。mTSBench评估了24种异常检测方法，包括基于大型语言模型（LLM）的多元时间序列检测器，并在标准化条件下系统性地测试了无监督模型选择技术。与先前研究一致，我们的结果证实没有单一检测器在所有数据集上表现优异，强调了模型选择的重要性。然而，即使是最先进的选择方法也远未达到最优，揭示了关键的技术缺口。mTSBench提供了一个统一的评估套件，以支持严格、可复现的比较，并推动未来自适应异常检测和鲁棒模型选择的进步。

</details>


### [200] [Universal and Efficient Detection of Adversarial Data through Nonuniform Impact on Network Layers](https://arxiv.org/abs/2506.20816)
**中文标题：通过非均匀影响网络层实现对抗数据的通用高效检测**

*Furkan Mumcu,Yasin Yilmaz*

主要分类: cs.LG

摘要简述: 本文提出了一种通用且高效的方法，通过分析对抗样本对不同深度神经网络层的影响程度来检测对抗数据。该方法训练一个轻量级回归模型，预测深层特征并利用预测误差检测对抗样本，具有实时处理能力和跨领域适用性。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络（DNN）对对抗性输入设计非常脆弱，现有防御方法要么通过消除扰动效果提高鲁棒性，要么使用辅助模型检测对抗数据。然而，这些方法要么对最新攻击技术无效，要么计算效率低下。本文旨在提出一种更实用的对抗样本检测方法。

研究方法: 本文提出了一种新方法，通过分析对抗样本对不同DNN层的非均匀影响来检测对抗数据。具体而言，训练一个轻量级回归模型，从早期层特征预测深层特征，并利用预测误差检测对抗样本。该方法兼容任何DNN架构，适用于图像、视频和音频等领域。

研究结果: 通过理论分析和大量实验，本文证明所提出的检测方法高度有效，计算效率高，适合实时处理，且兼容不同DNN架构和跨领域应用。

研究结论: 本文提出的方法为对抗样本检测提供了一种通用且高效的解决方案，具有实时处理能力和广泛的适用性，为DNN安全防御提供了新的研究方向。

中文摘要: 深度神经网络（DNN）对对抗性输入设计非常脆弱，尤其是在有限噪声预算下。尽管已有许多通过细微修改原始输入的成功攻击方法，但针对这些攻击的防御技术研究相对不足。现有防御方法要么专注于通过消除扰动效果提高DNN鲁棒性，要么使用辅助模型检测对抗数据。尽管同样重要，但攻击检测方法（本文研究的重点）相比鲁棒性方法更具实用性。我们发现现有检测方法要么对最新攻击技术无效，要么计算效率低下，无法满足实时处理需求。本文提出了一种新颖的通用高效方法，通过分析攻击对不同DNN层的非均匀影响来检测对抗样本。我们的方法训练了一个轻量级回归模型，从早期层特征预测深层特征，并利用预测误差检测对抗样本。通过理论分析和大量实验，我们证明该检测方法高度有效，计算效率高，适合实时处理，兼容任何DNN架构，并适用于图像、视频和音频等不同领域。

</details>


### [201] [RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment](https://arxiv.org/abs/2506.21037)
**中文标题：RL-Selector：基于强化学习的冗余评估数据选择方法**

*Suorong Yang,Peijia Li,Furao Shen,Jian Zhao*

主要分类: cs.LG

摘要简述: RL-Selector是一种基于强化学习的数据选择方法，通过量化样本冗余性优化训练效率，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代深度学习依赖大规模数据集，但训练成本高且数据冗余严重。现有方法忽视样本动态变化，亟需更高效的数据选择方法。

研究方法: 提出epsilon-sample cover量化样本冗余性，将数据选择建模为强化学习问题，通过轻量级RL代理优化选择策略。

研究结果: 在多个基准数据集和架构上，RL-Selector表现优于现有方法，显著提升训练效率和模型泛化性能。

研究结论: RL-Selector通过动态评估样本冗余性，为高效训练提供新思路，具有广泛适用性。

中文摘要: 现代深度学习架构通常依赖大规模数据集，但训练这些数据集会带来高昂的计算和存储开销。现实数据集通常包含大量冗余，因此需要更高效的数据训练范式。数据选择通过识别最具代表性的样本，有望减少冗余，从而在不影响性能的情况下降低训练成本。现有方法通常依赖静态评分指标或预训练模型，忽视了所选样本及其在训练过程中动态变化的综合效应。我们引入了epsilon-sample cover的概念，基于样本间关系量化样本冗余性，捕捉数据集的内在结构。基于此，我们将数据选择重新表述为强化学习（RL）过程，并提出RL-Selector，其中轻量级RL代理通过利用从动态数据集分布中提取的epsilon-sample cover作为奖励信号来优化选择策略。在多个基准数据集和多样化架构上的广泛实验表明，我们的方法始终优于现有最先进的基线方法。使用我们选择的数据集训练的模型显示出更强的泛化性能和更高的训练效率。

</details>


### [202] [Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion](https://arxiv.org/abs/2506.21144)
**中文标题：基于双提示优化与交叉融合的个性化联邦学习**

*Yuguang Zhang,Kuangpu Guo,Zhihe Lu,Yunbo Wang,Jian Liang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于双提示学习和交叉融合的个性化联邦学习框架pFedDC，通过全局和局部提示捕获共享知识和客户端特定语义，结合交叉融合模块生成个性化表示，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在数据、计算和通信的异构性上面临挑战，现有方法仅依赖文本提示且忽视联合标签-域分布偏移。本文旨在通过双提示学习和交叉融合解决这些问题。

研究方法: 提出pFedDC框架，每个客户端维护视觉和语言模态的全局与局部提示：全局提示捕获共享知识，局部提示编码客户端特定语义。设计交叉融合模块自适应整合不同层级提示，生成个性化表示。

研究结果: 在九种异构数据集上的实验表明，pFedDC在性能上持续优于现有最先进方法。

研究结论: pFedDC通过双提示学习和交叉融合有效解决了联邦学习中的异构性问题，为个性化联邦学习提供了新思路。

中文摘要: 联邦学习（FL）支持跨去中心化客户端的协作模型训练而无需共享本地数据，但面临数据、计算和通信的异构性挑战。预训练的视觉语言模型（VLMs）凭借其强大的泛化能力和通过提示的轻量调优，提供了有前景的解决方案。然而，现有的联邦提示学习方法仅依赖文本提示，忽视了联合标签-域分布偏移。本文提出了一种基于双提示学习和交叉融合的个性化FL框架pFedDC。具体而言，每个客户端在视觉和语言模态上维护全局和局部提示：全局提示捕获联邦共享的通用知识，而局部提示编码客户端特定语义和域特征。同时，设计了一个交叉融合模块，自适应整合不同层级的提示，使模型能够生成与每个客户端独特数据分布对齐的个性化表示。在九种异构数据集上的广泛实验表明，pFedDC在性能上持续优于现有最先进方法。

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [203] [Automatic Reviewers Assignment to a Research Paper Based on Allied References and Publications Weight](https://arxiv.org/abs/2506.21331)
**中文标题：基于相关参考文献和发表权重的论文自动评审员分配**

*Tamim Al Mahmud,B M Mainul Hossain,Dilshad Ara*

主要分类: cs.DL

摘要简述: 本文提出了一种基于参考文献和作者权重的自动评审员分配方法，通过分析论文引用和作者学术指标，高效选择最适合的评审专家。


<details>
  <summary>详细信息</summary>
研究动机: 随着研究领域的扩展和论文数量的激增，传统人工选择评审员的方式效率低下且难以确保专业性。本文旨在通过自动化方法解决这一问题，确保每篇论文都能由相关领域的专家评审。

研究方法: 方法包括：1) 提取论文参考文献中的作者；2) 通过网络搜索获取研究主题关键词；3) 筛选特定主题的顶尖研究者并计算其h指数、i10指数和引用量；4) 根据评分排名并提取其邮箱地址；5) 排除其合作者，最终确定最适合的评审员。

研究结果: 该方法能够高效且准确地为每篇研究论文分配最合适的评审专家，显著提升了评审过程的专业性和效率。

研究结论: 本文提出的自动化评审员分配方法解决了传统人工选择的局限性，为学术期刊和会议提供了一种高效、可靠的评审员选择方案。

中文摘要: 每天有大量研究文档提交至会议、期刊、通讯等各类出版物。这些出版物通常依赖外部专家进行同行评审，但选择最合适的评审员并非易事。随着新兴研究领域的涌现和论文数量的激增，这一问题愈发突出。例如，通信技术领域的论文应由该领域的专家评审。因此，高效选择最佳评审员成为一大挑战。本研究提出并实现了一种新策略，通过自动分析论文参考文献中的作者及其学术指标（如h指数、i10指数和引用量），筛选出最适合的评审员。具体步骤包括提取参考文献作者、搜索研究主题关键词、筛选顶尖研究者并排除其合作者。最终，剩余的高分作者（通常是教授）成为论文的最佳评审人选。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [204] [Evaluating PDE discovery methods for multiscale modeling of biological signals](https://arxiv.org/abs/2506.20694)
**中文标题：评估偏微分方程发现方法在生物信号多尺度建模中的应用**

*Andréa Ducos,Audrey Denizot,Thomas Guyet,Hugues Berry*

主要分类: q-bio.QM

摘要简述: 本文评估了五种最先进的偏微分方程（PDE）发现方法，用于从微观数据中推断生物信号的多尺度建模，并展示了其在钙扩散模拟中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 生物系统具有非线性、包含未观测变量且动力学原理部分未知的特点，这使得其行为表征极具挑战性。尤其是其活动发生在多个相互依赖的时空尺度上，需要跨尺度的机制链接。

研究方法: 本文提出了一种结合粒子模拟和PDE发现的框架，并在控制环境中进行了初步实验，评估了五种PDE发现方法在星形胶质细胞钙扩散模拟中的表现。

研究结果: 结果显示，多种方法能够准确恢复扩散项，表明PDE发现方法在从微观数据中捕捉生物系统宏观动力学方面具有潜力。

研究结论: PDE发现方法在跨尺度建模中表现出色，尤其是在恢复扩散项方面，为生物系统的多尺度建模提供了有效工具。

中文摘要: 生物系统是非线性的，包含未观测变量，且其动力学原理部分未知，这使得其行为表征极具挑战性。特别是其活动发生在多个相互依赖的时空尺度上，需要跨尺度的机制链接。为了填补尺度间的空白，我们利用偏微分方程（PDE）发现方法。PDE发现能够从微观数据中推断中尺度动力学特征。本文提出了一种结合粒子模拟和PDE发现的框架，并在控制环境中进行了初步实验，评估了五种最先进的PDE发现方法在星形胶质细胞钙扩散模拟中的表现。这些方法的表现通过发现的方程形式和预测的钙浓度时间变化进行评估。结果显示，多种方法能够准确恢复扩散项，突出了PDE发现在从微观数据中捕捉生物系统宏观动力学方面的潜力。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [205] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
**中文标题：基于几何感知扩散与时序视频模型的一致性零样本3D纹理合成**

*Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik*

主要分类: cs.GR

摘要简述: 本文提出VideoTex框架，利用视频生成模型解决3D纹理合成中的空间和时间不一致问题，通过几何感知条件和结构化的UV扩散策略，生成高质量且时间稳定的纹理。


<details>
  <summary>详细信息</summary>
研究动机: 现有纹理合成方法因缺乏全局上下文和几何理解，导致纹理在固定视角下不一致。视频生成模型在时间一致性上表现优异，因此本文提出结合两者优势，解决3D纹理合成的时空一致性问题。

研究方法: VideoTex框架结合几何感知条件，利用3D网格结构信息，并提出结构化的UV扩散策略，通过保留语义信息增强遮挡区域的生成，实现更平滑的纹理过渡和时间稳定性。

研究结果: 实验表明，VideoTex在纹理保真度、接缝融合和时间稳定性上优于现有方法，适用于动态实时应用。

研究结论: VideoTex通过几何感知和视频生成模型的结合，显著提升了3D纹理合成的时空一致性，为高质量动态纹理应用提供了新思路。

中文摘要: 现有纹理合成方法因缺乏全局上下文和几何理解，导致固定视角下生成的纹理不一致。与此同时，视频生成模型在实现时间一致性方面取得了显著成功。本文提出VideoTex，一种新颖的无缝纹理合成框架，利用视频生成模型解决3D纹理中的空间和时间不一致问题。我们的方法结合几何感知条件，精确利用3D网格结构。此外，提出了一种结构化的UV扩散策略，通过保留语义信息增强遮挡区域的生成，从而生成更平滑、更连贯的纹理。VideoTex不仅在UV边界上实现了平滑过渡，还确保了视频帧间高质量、时间稳定的纹理。大量实验表明，VideoTex在纹理保真度、接缝融合和稳定性上优于现有方法，为需要视觉质量和时间一致性的动态实时应用铺平了道路。

</details>


### [206] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
**中文标题：生成式积木世界：在图片中移动物体**

*Vaibhav Vavilala,Seemandhar Jain,Rahul Vasanth,D. A. Forsyth,Anand Bhattad*

主要分类: cs.GR

摘要简述: 本文提出了一种通过操纵简单几何抽象来编辑生成图像场景的方法，利用3D基元表示场景，支持灵活编辑，并通过流式生成方法实现高质量图像重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在图像编辑中难以同时满足几何和纹理的一致性，且编辑灵活性不足。本文旨在通过3D基元表示和纹理提示技术，提升图像编辑的逼真度和可控性。

研究方法: 将场景表示为凸3D基元的组合，支持不同数量的基元表示同一场景。编辑后，基于深度和纹理提示的流式生成方法重建图像，纹理提示技术优于现有缓存方法。

研究结果: 定量和定性实验表明，该方法在视觉逼真度、编辑灵活性和组合泛化能力上优于现有技术。

研究结论: 通过3D基元表示和纹理提示技术，本文方法显著提升了生成图像编辑的质量和灵活性，为场景交互提供了新思路。

中文摘要: 我们描述了生成式积木世界，通过操纵简单的几何抽象来与生成图像中的场景交互。我们的方法将场景表示为凸3D基元的组合，同一场景可以用不同数量的基元表示，允许编辑者移动整个结构或小细节。一旦场景几何被编辑，图像通过基于流的方法生成，该方法以深度和纹理提示为条件。我们的纹理提示考虑了修改后的3D基元，超越了现有键值缓存技术提供的纹理一致性。这些纹理提示（a）支持准确的物体和相机移动，（b）在很大程度上保留了所描绘物体的身份。定量和定性实验表明，我们的方法在视觉逼真度、编辑灵活性和组合泛化能力上优于现有技术。

</details>


### [207] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
**中文标题：3DGH：基于可组合头发和脸部的3D头部生成**

*Chengan He,Junxuan Li,Tobias Kirschstein,Artem Sevastopolsky,Shunsuke Saito,Qingyang Tan,Javier Romero,Chen Cao,Holly Rushmeier,Giljoo Nam*

主要分类: cs.GR

摘要简述: 3DGH是一种无条件生成3D人头模型的生成模型，通过分离头发和脸部的建模，使用基于模板的3D高斯散射和可变形头发几何，实现了头发和脸部的组合生成。


<details>
  <summary>详细信息</summary>
研究动机: 以往的研究将头发和脸部建模混为一谈，限制了生成模型的灵活性和编辑能力。3DGH旨在通过分离头发和脸部的建模，实现更灵活的组合生成和编辑。

研究方法: 3DGH采用基于模板的3D高斯散射数据表示，引入可变形头发几何以捕捉不同发型的几何变化。模型采用双生成器的3D GAN架构，并通过交叉注意力机制建模头发和脸部的内在关联。训练时使用合成渲染和精心设计的目标函数以稳定训练并促进头发与脸部分离。

研究结果: 实验验证了3DGH的设计选择，并通过与多种先进3D GAN方法的定性和定量比较，展示了其在无条件全头图像合成和可组合3D发型编辑中的有效性。

研究结论: 3DGH通过分离头发和脸部的建模，实现了灵活的组合生成和编辑，为3D人头生成提供了新的解决方案。

中文摘要: 我们提出了3DGH，一种用于3D人头无条件生成的模型，支持头发和脸部的组合生成。与以往将头发和脸部建模混为一谈的研究不同，我们提出通过基于模板的3D高斯散射数据表示分离二者，并引入可变形头发几何以捕捉不同发型的几何变化。基于此数据表示，我们设计了一种双生成器的3D GAN架构，并采用交叉注意力机制建模头发和脸部的内在关联。模型通过合成渲染和精心设计的目标函数进行训练，以稳定训练并促进头发与脸部分离。我们通过大量实验验证了3DGH的设计选择，并与多种先进3D GAN方法进行了定性和定量比较，证明了其在无条件全头图像合成和可组合3D发型编辑中的有效性。更多细节请访问项目页面：https://c-he.github.io/projects/3dgh/。

</details>


### [208] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
**中文标题：FairyGen：从单张儿童绘画生成故事卡通视频**

*Jiayi Zheng,Xiaodong Cun*

主要分类: cs.GR

摘要简述: FairyGen是一个自动系统，能够从单张儿童绘画生成故事驱动的卡通视频，并忠实保留其独特的艺术风格。通过解耦角色建模与风格化背景生成，并结合电影级镜头设计，系统实现了富有表现力和连贯性的故事动画。


<details>
  <summary>详细信息</summary>
研究动机: 现有的故事动画方法主要关注角色一致性和基本动作，缺乏对风格化背景和电影级镜头设计的支持。FairyGen旨在填补这一空白，提供一种能够从儿童绘画生成个性化、风格一致且叙事连贯的卡通视频的系统。

研究方法: FairyGen首先使用MLLM生成结构化故事板，包含镜头级描述（环境、角色动作和视角）。通过风格传播适配器确保视觉一致性，将角色风格应用于背景。镜头设计模块通过帧裁剪和多视角合成增强视觉多样性和电影感。角色动画通过3D代理重建实现物理合理动作，并基于MMDiT的图像到视频扩散模型进行微调。两阶段运动定制适配器分别学习外观特征和时序动态。

研究结果: 实验表明，FairyGen生成的动画在风格上忠实于原始绘画，叙事结构清晰，动作自然，具有高度的个性化和吸引力。

研究结论: FairyGen通过解耦角色与背景风格、结合电影级镜头设计和物理合理动作，成功实现了从儿童绘画生成个性化、风格一致且叙事连贯的卡通视频，展示了其在个性化故事动画中的潜力。

中文摘要: 我们提出了FairyGen，一种从单张儿童绘画自动生成故事驱动卡通视频的系统，同时忠实保留其独特的艺术风格。与以往主要关注角色一致性和基本动作的故事动画方法不同，FairyGen明确解耦了角色建模与风格化背景生成，并引入电影级镜头设计以支持富有表现力和连贯性的叙事。给定一张角色草图，我们首先使用MLLM生成包含镜头级描述（环境设置、角色动作和视角）的结构化故事板。为确保视觉一致性，我们提出了一种风格传播适配器，捕捉角色的视觉风格并将其应用于背景，在合成风格一致的场景时完全保留角色的视觉特征。镜头设计模块通过帧裁剪和多视角合成进一步提升了视觉多样性和电影感。为动画化故事，我们重建角色的3D代理以生成物理合理的动作序列，并用于微调基于MMDiT的图像到视频扩散模型。我们还提出了一种两阶段运动定制适配器：第一阶段从时序无序的帧中学习外观特征，解耦身份与动作；第二阶段通过冻结身份权重的时序偏移策略建模时序动态。训练完成后，FairyGen可直接生成与故事板对齐的多样且连贯的视频场景。大量实验表明，我们的系统生成的动画在风格上忠实、叙事结构清晰且动作自然，凸显了其在个性化和引人入胜的故事动画中的潜力。代码将在https://github.com/GVCLab/FairyGen 发布。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [209] [Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends](https://arxiv.org/abs/2506.20966)
**中文标题：VLA模型后训练与人类运动学习的共性：进展、挑战与趋势**

*Tian-Yu Xiang,Ao-Qun Jin,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Sheng-Bin Duan,Fu-Chao Xie,Wen-Kai Wang,Si-Cheng Wang,Ling-Yun Li,Tian Tu,Zeng-Guang Hou*

主要分类: cs.RO

摘要简述: 本文从人类运动学习的角度，综述了视觉-语言-动作（VLA）模型的后训练策略，提出了一种基于环境、体现和任务的结构化分类法，并总结了关键挑战与未来趋势。


<details>
  <summary>详细信息</summary>
研究动机: VLA模型在机器人操作任务中表现出泛化能力，但在高精度任务中存在性能差距。通过借鉴人类运动学习的机制，研究旨在提升VLA模型的后训练效果，以更好地适应下游应用。

研究方法: 论文通过人类运动学习的视角，提出了一种结构化分类法，包括四个维度：增强环境感知、提升体现意识、深化任务理解以及多组件整合。

研究结果: 研究总结了VLA模型后训练的关键挑战和趋势，并建立了一个概念框架，为未来研究提供指导。

研究结论: 本文不仅从人类运动学习的角度全面综述了VLA模型的后训练方法，还为VLA模型开发提供了实用见解。

中文摘要: 视觉-语言-动作（VLA）模型通过整合动作生成模块扩展了视觉-语言模型（VLM），在机器人操作任务中展现出广泛的泛化能力。然而，高精度应用场景揭示了未经进一步适应的性能差距。多领域证据表明，后训练在将基础模型与下游应用对齐中起关键作用，推动了VLA模型后训练的广泛研究。VLA模型后训练旨在提升模型在特定任务中与环境交互的能力，类似于人类运动技能的习得过程。因此，本文从人类运动学习的视角，围绕环境、体现和任务三个维度，综述了VLA模型的后训练策略。提出了一种与人类学习机制对齐的结构化分类法：（1）增强环境感知，（2）提升体现意识，（3）深化任务理解，（4）多组件整合。最后，总结了VLA模型后训练的关键挑战与趋势，建立了一个指导未来研究的概念框架。本研究不仅从人类运动学习的角度全面概述了当前VLA模型后训练方法，还为VLA模型开发提供了实用见解。（项目网站：https://github.com/AoqunJin/Awesome-VLA-Post-Training）

</details>


### [210] [V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling](https://arxiv.org/abs/2506.21041)
**中文标题：V2X-REALM：基于视觉语言模型的自适应长尾建模鲁棒端到端协同自动驾驶**

*Junwei You,Pei Li,Zhuoyu Jiang,Zilin Huang,Rui Gan,Haotian Shi,Bin Ran*

主要分类: cs.RO

摘要简述: 本文提出V2X-REALM框架，通过视觉语言模型和自适应多模态学习，解决长尾场景下协同自动驾驶的鲁棒性问题，显著提升了复杂驾驶环境中的性能和安全性。


<details>
  <summary>详细信息</summary>
研究动机: 在城市环境中，自动驾驶在罕见、多样且视觉退化的长尾场景下的鲁棒规划和决策仍是一个关键挑战。协同驾驶中，车辆与基础设施需共同感知和推理复杂环境，这一问题更为突出。

研究方法: V2X-REALM提出三项创新：(i) 基于提示的长尾场景生成与评估流程，利用基础模型合成雪、雾等真实长尾条件；(ii) 门控多场景自适应注意力模块，通过场景先验重新校准模糊或损坏的特征；(iii) 多任务场景感知对比学习目标，提升多模态对齐和跨场景特征可分性。

研究结果: 实验表明，V2X-REALM在复杂驾驶条件下，显著优于现有基线方法，尤其在鲁棒性、语义推理、安全性和规划准确性方面表现突出。

研究结论: V2X-REALM通过自适应长尾建模和多模态学习，推动了端到端协同自动驾驶的可扩展性，为复杂环境下的自动驾驶提供了有效解决方案。

中文摘要: 在城市环境中，自动驾驶在罕见、多样且视觉退化的长尾场景下的鲁棒规划和决策仍是一个根本性挑战。这一问题在协同驾驶中更为关键，车辆与基础设施需共同感知和推理复杂环境。为解决这一挑战，我们提出V2X-REALM，一种基于视觉语言模型（VLM）的框架，通过自适应多模态学习实现长尾场景下的鲁棒协同自动驾驶。V2X-REALM包含三项核心创新：(i) 基于提示的长尾场景生成与评估流程，利用基础模型合成车辆和基础设施视角下的真实长尾条件（如雪、雾），高效丰富训练多样性；(ii) 门控多场景自适应注意力模块，通过场景先验重新校准模糊或损坏的特征；(iii) 多任务场景感知对比学习目标，提升多模态对齐和跨场景特征可分性。大量实验表明，V2X-REALM在复杂挑战性驾驶条件下，显著优于现有基线方法，尤其在鲁棒性、语义推理、安全性和规划准确性方面表现突出，推动了端到端协同自动驾驶的可扩展性。

</details>


### [211] [WorldVLA: Towards Autoregressive Action World Model](https://arxiv.org/abs/2506.21539)
**中文标题：WorldVLA：迈向自回归动作世界模型**

*Jun Cen,Chaohui Yu,Hangjie Yuan,Yuming Jiang,Siteng Huang,Jiayan Guo,Xin Li,Yibing Song,Hao Luo,Fan Wang,Deli Zhao,Hao Chen*

主要分类: cs.RO

摘要简述: WorldVLA是一种自回归动作世界模型，结合了视觉-语言-动作（VLA）模型与世界模型，通过动作和图像理解预测未来图像，同时生成后续动作。实验表明其优于独立模型，但自回归动作生成性能下降，提出注意力掩码策略以改善。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在统一动作与图像的理解与生成，通过结合VLA模型与世界模型，探索环境物理规律以优化动作生成，同时提升视觉理解能力。

研究方法: WorldVLA整合VLA模型与世界模型，利用动作和图像理解预测未来图像，并通过图像观察生成后续动作。针对自回归动作生成中的性能下降，提出选择性掩码先前动作的注意力掩码策略。

研究结果: WorldVLA在动作和世界模型任务中表现优于独立模型，但自回归动作生成时性能下降。注意力掩码策略显著提升了动作块生成任务的性能。

研究结论: WorldVLA展示了动作模型与世界模型的相互增强，但自回归动作生成存在局限性。注意力掩码策略有效缓解了性能下降问题，为未来研究提供了方向。

中文摘要: 我们提出了WorldVLA，一种自回归动作世界模型，统一了动作与图像的理解与生成。WorldVLA将视觉-语言-动作（VLA）模型与世界模型整合到一个框架中。世界模型通过动作和图像理解预测未来图像，旨在学习环境的物理规律以优化动作生成；同时，动作模型基于图像观察生成后续动作，辅助视觉理解并反过来促进世界模型的视觉生成。实验表明，WorldVLA优于独立的动作和世界模型，凸显了世界模型与动作模型的相互增强。此外，我们发现动作模型在自回归生成动作序列时性能下降，这归因于模型在动作预测上的泛化能力有限，导致早期动作误差传播到后续动作。为解决此问题，我们提出了一种注意力掩码策略，在生成当前动作时选择性掩码先前动作，显著提升了动作块生成任务的性能。

</details>


### [212] [Model-Based Real-Time Pose and Sag Estimation of Overhead Power Lines Using LiDAR for Drone Inspection](https://arxiv.org/abs/2506.20812)
**中文标题：基于模型的无人机LiDAR电力线实时姿态与弧垂估计**

*Alexandre Girard,Steven A. Parkison,Philippe Hamelin*

主要分类: cs.RO

摘要简述: 本文提出了一种基于模型的实时姿态和弧垂估计方法，利用LiDAR进行无人机电力线巡检，通过全局几何模型最小化误差，解决了导体点稀疏、部分检测和噪声干扰等问题，实验证明其高效性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 无人机巡检带电电力线时，LiDAR传感器面临导体点稀疏、部分检测和噪声干扰等问题，传统方法难以准确跟踪导体。本文旨在提出一种更高效的全局模型估计方法。

研究方法: 通过构建一个全局几何模型表示整个导体阵列，最小化LiDAR测量值与模型之间的误差，而非单独跟踪每个导体。该方法能够处理部分观测、噪声和异常点。

研究结果: 实验结果表明，该方法在电力线巡检数据中实现了高精度跟踪，每帧求解时间低于50毫秒，且对异常点的容忍度是有效导体测量点的两倍。

研究结论: 本文提出的全局模型估计方法在无人机电力线巡检中表现出高效性和鲁棒性，适用于复杂环境下的实时应用。

中文摘要: 无人机可以在电力线带电状态下进行巡检，显著简化了检查流程。然而，利用机载LiDAR传感器定位无人机相对于所有导体的位置存在以下挑战：(1) 导体表面极小，限制了LiDAR扫描中的导体点数；(2) 并非所有导体都能被持续检测到；(3) 区分LiDAR点对应的导体与其他物体（如树木和塔架）较为困难。本文提出了一种估计方法，通过最小化LiDAR测量值与表示整个导体阵列的单一几何模型之间的误差，而非单独跟踪每个导体。实验结果表明，该方法在电力线无人机巡检数据中实现了高精度跟踪，每帧求解时间低于50毫秒，即使在部分观测、噪声和异常点存在的情况下也能收敛。敏感性分析显示，该估计方法对异常点的容忍度是有效导体测量点的两倍。

</details>


### [213] [ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation](https://arxiv.org/abs/2506.20969)
**中文标题：ThermalDiffusion：用于自主导航的视觉到热成像图像转换**

*Shruti Bansal,Wenshan Wang,Yifei Liu,Parv Maheshwari*

主要分类: cs.RO

摘要简述: 本文提出了一种基于条件扩散模型的方法，将RGB图像转换为热成像图像，以解决自主系统中热成像数据不足的问题。


<details>
  <summary>详细信息</summary>
研究动机: 自主系统在夜间或恶劣环境（如雾、尘）中依赖热成像相机检测目标，但现有数据集缺乏热成像数据，限制了热成像相机的广泛应用。

研究方法: 采用条件扩散模型，利用自注意力机制学习真实物体的热特性，将RGB图像转换为合成热成像图像。

研究结果: 通过生成合成热成像数据，成功扩充了现有数据集，为热成像相机在自主系统中的快速应用提供了支持。

研究结论: 该方法有效解决了热成像数据不足的问题，推动了热成像相机在机器人技术和自动化领域的应用。

中文摘要: 自主系统依赖传感器感知周围环境，但相机、激光雷达和雷达各有局限性。在夜间或恶劣环境（如雾、尘）中，热成像相机能通过热特征提供目标物体的关键信息，便于识别温度较高的物体（如人类和车辆）。本文聚焦于热成像相机在机器人技术和自动化中的应用，主要障碍是数据不足。尽管已有多种多模态数据集支持场景分割、目标检测和深度估计等自主系统核心任务，但这些数据集缺乏热成像数据。本文提出一种解决方案，通过合成热成像数据扩充现有数据集，以促进热成像相机的快速普及。我们探索了条件扩散模型的使用，通过自注意力机制学习真实物体的热特性，将RGB图像转换为热成像图像。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [214] [ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data](https://arxiv.org/abs/2506.20673)
**中文标题：ClusterRCA：基于多模态数据的HPC系统网络故障诊断方法**

*Yongqian Sun,Xijie Pan,Xiao Xiong,Lei Tao,Jiaju Wang,Shenglin Zhang,Yuan Yuan,Yuqi Li,Kunlin Jian*

主要分类: cs.DC

摘要简述: ClusterRCA是一种用于高性能计算（HPC）系统中网络故障诊断的新框架，通过多模态数据定位故障节点和类型，结合分类器和图方法，实验证明其高准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 高性能计算（HPC）系统中的网络故障诊断因数据异构性和准确性不足而具有挑战性，现有方法难以直接应用，需开发新方法。

研究方法: ClusterRCA通过提取拓扑连接的网卡对特征分析多模态数据，结合分类器和图方法构建故障图，并通过定制随机游走定位根因。

研究结果: 实验表明，ClusterRCA在高性能计算系统中诊断网络故障具有高准确性，并在不同应用场景中保持鲁棒性能。

研究结论: ClusterRCA为HPC系统网络故障诊断提供了高效解决方案，结合多模态数据和混合方法，显著提升了诊断能力。

中文摘要: 网络故障诊断在高性能计算（HPC）系统中具有挑战性但至关重要。由于数据异构性和准确性不足，现有方法难以直接应用于HPC场景。本文提出了一种名为ClusterRCA的新框架，通过利用多模态数据定位故障节点并确定故障类型。ClusterRCA从拓扑连接的网卡对中提取特征，以分析HPC系统中的多样化多模态数据。为准确定位故障节点和确定故障类型，ClusterRCA结合了基于分类器和基于图的方法。根据状态分类器的输出构建故障图，并通过定制随机游走定位根因。在一家顶级全球HPC设备供应商收集的数据集上的实验表明，ClusterRCA在诊断HPC系统网络故障方面具有高准确性，并在不同应用场景中保持鲁棒性能。

</details>


### [215] [Utility-Driven Speculative Decoding for Mixture-of-Experts](https://arxiv.org/abs/2506.20675)
**中文标题：实用驱动的混合专家模型推测解码**

*Anish Saxena,Po-An Tsai,Hritvik Taneja,Aamer Jaleel,Moinuddin Qureshi*

主要分类: cs.DC

摘要简述: 本文提出了一种名为Cascade的实用驱动框架，用于动态调整推测解码的K值，以优化混合专家模型（MoE）的推理性能，避免传统推测解码在MoE中导致的性能下降。


<details>
  <summary>详细信息</summary>
研究动机: GPU内存带宽是大型语言模型（LLM）低延迟推理的主要瓶颈。推测解码通过轻量级草案生成器提出K个令牌，由LLM并行验证以提高令牌吞吐量。然而，混合专家模型（MoE）仅激活部分权重，推测解码会因草案令牌激活更多权重而增加数据移动和验证时间，导致性能下降。

研究方法: Cascade框架通过动态调整推测解码的K值，选择性启用推测解码以避免性能下降。它使用轻量级指标“推测效用”（令牌增益与验证成本的比率），并通过短测试和长设置阶段动态选择最优K值。

研究结果: 在五种流行的MoE模型上评估，Cascade将性能下降限制在5%（传统方法为1.5倍），吞吐量比静态K值提高7-14%，使推测解码在MoE中变得实用。

研究结论: Cascade通过动态调整推测解码的K值，成功解决了MoE中推测解码的性能问题，使其在实际应用中具有可行性。

中文摘要: GPU内存带宽是大型语言模型（LLM）低延迟推理的主要瓶颈。推测解码利用空闲GPU计算资源，通过轻量级草案生成器提出K个令牌，由LLM并行验证以提高令牌吞吐量。在传统密集LLM中，每次迭代都会加载所有模型权重，因此推测解码不会增加延迟开销。然而，新兴的混合专家模型（MoE）仅激活每个令牌的部分权重，大幅减少了数据移动。但我们发现，推测解码对MoE效果不佳：草案令牌会激活更多权重，导致数据移动和验证时间增加2-3倍。当令牌吞吐量增益无法抵消这一开销时，推测解码会导致性能下降高达1.5倍，使其不可行。即使有用，最优K值也会因任务、模型甚至请求和迭代的不同而变化。因此，尽管推测解码在密集LLM中广泛应用，但在主流MoE中仍不实用。

我们提出了Cascade，一种实用驱动框架，选择性启用推测解码以避免性能下降，并动态调整K值以加速MoE推理。Cascade使用轻量级指标“推测效用”（令牌增益与验证成本的比率），该指标具有迭代级局部性，通过短测试和长设置阶段实现周期性决策。对于每个请求，Cascade在测试阶段发现效用低于1时禁用推测解码；当效用超过1时，测试多个K值以选择效用最大化的K值用于设置阶段。我们在vLLM中实现了Cascade，并在五种流行的MoE模型上评估其性能，涵盖代码、数学、提取和混合任务。Cascade将性能下降限制在5%（传统方法为1.5倍），吞吐量比静态K值提高7-14%，使推测解码在MoE中变得实用。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [216] [Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG](https://arxiv.org/abs/2506.20683)
**中文标题：基于全局和局部对比学习的心脏MRI与ECG联合表征方法**

*Alexander Selivanov,Philip Müller,Özgün Turgut,Nil Stolt-Ansó,Daniel Rückert*

主要分类: eess.IV

摘要简述: 本文提出了一种名为PTACL的多模态对比学习框架，通过结合心脏磁共振（CMR）的时空信息增强心电图（ECG）的表征能力。PTACL通过全局和局部对比损失，实现了患者级别和时序级别的对齐，从而提升了ECG在心脏功能评估中的诊断能力。


<details>
  <summary>详细信息</summary>
研究动机: 心电图（ECG）是一种经济高效的检测心脏电活动异常的工具，但无法直接测量心室容积和射血分数等功能参数。心脏磁共振（CMR）虽能提供这些参数，但成本高且不易获取。为了弥补这一差距，作者提出PTACL框架，旨在通过结合CMR的时空信息增强ECG的表征能力。

研究方法: PTACL采用全局患者级别对比损失和局部时序级别对比损失。全局损失通过拉近同一患者的ECG和CMR表征，同时推开不同患者的表征，实现患者级别的对齐。局部损失通过对比编码的ECG片段和对应的CMR帧，实现细粒度时序对齐。该方法无需引入新的可学习参数。

研究结果: 在UK Biobank的27,951名受试者数据上，PTACL在两项临床相关任务中表现优于基线方法：（1）检索具有相似心脏表型的患者；（2）预测CMR衍生的心脏功能参数（如心室容积和射血分数）。

研究结论: PTACL通过结合CMR的时空信息，显著提升了ECG在非侵入性心脏诊断中的潜力，为心脏功能评估提供了新思路。

中文摘要: 心电图（ECG）是一种广泛使用的经济高效工具，用于检测心脏电活动异常。然而，它无法直接测量心室容积和射血分数等功能参数，而这些参数对评估心脏功能至关重要。心脏磁共振（CMR）是这些测量的金标准，可提供详细的结构和功能信息，但其成本高且不易获取。为了弥补这一差距，我们提出了PTACL（患者与时序对齐对比学习），一种多模态对比学习框架，通过整合CMR的时空信息增强ECG的表征能力。PTACL采用全局患者级别对比损失和局部时序级别对比损失。全局损失通过拉近同一患者的ECG和CMR表征，同时推开不同患者的表征，实现患者级别的对齐。局部损失通过对比编码的ECG片段和对应的CMR帧，实现细粒度时序对齐。这种方法在不引入新可学习参数的情况下，丰富了ECG的诊断信息，并实现了跨模态的更多信息传递。我们在UK Biobank的27,951名受试者的配对ECG-CMR数据上评估了PTACL。与基线方法相比，PTACL在两项临床相关任务中表现更优：（1）检索具有相似心脏表型的患者；（2）预测CMR衍生的心脏功能参数（如心室容积和射血分数）。我们的结果表明，PTACL有潜力通过ECG增强非侵入性心脏诊断。代码可在以下网址获取：https://github.com/alsalivan/ecgcmr

</details>


### [217] [U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs](https://arxiv.org/abs/2506.20689)
**中文标题：U-R-VEDA：结合UNet、残差连接、边缘与双注意力及视觉变换器实现心脏磁共振图像的精确语义分割**

*Racheal Mukisa,Arvind K. Bansal*

主要分类: eess.IV

摘要简述: 本文提出了一种名为U-R-Veda的深度学习模型，通过结合UNet、残差连接、边缘检测、双注意力机制和视觉变换器，实现了心脏磁共振图像的精确语义分割，平均准确率达95.2%。


<details>
  <summary>详细信息</summary>
研究动机: 心脏疾病的自动化诊断和管理需要精确的心脏图像分割。现有方法在分割精度和信息保留方面存在不足，因此需要一种更高效的模型来提升分割性能。

研究方法: U-R-Veda模型整合了卷积变换、视觉变换器、残差连接、通道注意力和空间注意力，并结合边缘检测的跳跃连接，以减少信息丢失。通过双注意力模块和局部特征提取，模型显著提升了分割精度。

研究结果: 实验结果表明，U-R-Veda的平均准确率为95.2%（基于DSC指标），在右心室和左心室心肌的分割上表现优于其他模型。

研究结论: U-R-Veda通过多模块集成显著提升了心脏磁共振图像的语义分割精度，为医学图像分析提供了高效工具。

中文摘要: 人工智能，尤其是深度学习模型，将在心脏疾病的自动化诊断和管理中发挥重要作用。心脏图像的精确自动化分割是量化分析和自动化诊断的第一步。本文提出了一种基于深度学习的增强UNet模型——U-R-Veda，该模型整合了卷积变换、视觉变换器、残差连接、通道注意力、空间注意力以及基于边缘检测的跳跃连接，以实现心脏磁共振（CMR）图像的精确全自动语义分割。模型通过卷积块和视觉变换器提取局部特征及其相互关系，并在卷积块中嵌入通道和空间注意力以识别重要特征及其空间定位。结合边缘信息的跳跃连接减少了卷积变换中的信息丢失。实验结果表明，U-R-Veda的平均准确率为95.2%（基于DSC指标），在右心室和左心室心肌的分割上表现优于其他模型。

</details>


### [218] [A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver Tumour Ablation](https://arxiv.org/abs/2506.21162)
**中文标题：一种将3D超声整合到经皮肝肿瘤消融中的新框架**

*Shuwei Xing,Derek W. Cool,David Tessier,Elvis C. S. Chen,Terry M. Peters,Aaron Fenster*

主要分类: eess.IV

摘要简述: 本文提出了一种将3D超声整合到经皮肝肿瘤消融中的新框架，通过2D超声-CT/MRI配准方法降低复杂性，并展示了高效的多模态图像可视化技术。结果显示配准误差显著降低，验证了该框架的临床潜力。


<details>
  <summary>详细信息</summary>
研究动机: 3D超声在经皮肝肿瘤消融中具有显著优势，但其临床整合面临肿瘤识别困难的挑战。本研究旨在解决这一问题，推动3D超声在治疗领域的应用。

研究方法: 提出了一种新框架，核心是临床可行的2D超声-CT/MRI配准方法，利用3D超声作为中介降低配准复杂性，并开发了直观的多模态图像可视化技术。

研究结果: 2D超声-CT/MRI配准的标记距离误差为2-4毫米，运行时间为每对图像0.22秒；非刚性配准比刚性配准平均对齐误差降低约40%。

研究结论: 该框架显著提升了3D超声在经皮肿瘤消融中的应用能力，展示了其在临床干预中扩展治疗角色的潜力。

中文摘要: 3D超声成像在提升经皮肝肿瘤消融效果方面显示出显著优势，其临床整合对于将3D超声引入治疗领域至关重要。然而，超声图像中肿瘤识别的挑战仍阻碍其广泛应用。本研究提出了一种将3D超声整合到标准消融流程中的新框架。我们展示了一个关键组件，即一种临床可行的2D超声-CT/MRI配准方法，利用3D超声作为中介降低配准复杂性。为便于高效验证配准流程，我们还提出了一种直观的多模态图像可视化技术。研究中，2D超声-CT/MRI配准的标记距离误差约为2-4毫米，每对图像运行时间为0.22秒。此外，非刚性配准比刚性配准的平均对齐误差降低了约40%。结果表明，所提出的2D超声-CT/MRI配准流程具有高效性。我们的整合框架提升了3D超声成像在改善经皮肿瘤消融中的能力，展示了其在临床干预中扩展治疗角色的潜力。

</details>


### [219] [Development of MR spectral analysis method robust against static magnetic field inhomogeneity](https://arxiv.org/abs/2506.20897)
**中文标题：抗静态磁场不均匀性的MR光谱分析方法的开发**

*Shuki Maruyama,Hidenori Takeshima*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的MR光谱分析方法，通过模拟B0不均匀性诱导的光谱变化，显著提高了光谱分析的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 静态磁场B0不均匀性会影响MR光谱分析的准确性，因此需要开发一种能够抵抗这种不均匀性的方法以提高分析精度。

研究方法: 作者提出了一种新方法，利用深度学习模型训练模拟光谱，这些光谱通过B0图和健康人脑代谢物比例生成。模型将B0图划分为子区域，分别估计代谢物和基线成分后整合。通过视觉和定量评估模拟光谱与实测光谱的接近程度，并使用实测、模拟和建模光谱训练分析模型。

研究结果: 模拟光谱根据B0不均匀性表现出光谱峰的展宽或变窄，且与实测光谱定量接近。使用建模光谱训练的模型比仅使用实测光谱的模型MSE降低了49.89%，比使用模拟光谱的模型降低了26.66%。在两种B0不均匀性条件下，该模型的MAPE显著低于LCModel。

研究结论: 开发了一种基于建模光谱训练的深度学习模型，结果表明该方法通过增加光谱训练样本，有望提高光谱分析的准确性。

中文摘要: 目的：开发一种在静态磁场B0不均匀性存在下提高光谱分析准确性的方法。方法：作者提出了一种新的光谱分析方法，利用深度学习模型训练模拟光谱，这些光谱能够一致地反映B0不均匀性诱导的光谱变化。模拟光谱通过健康人脑的B0图和代谢物比例生成。B0图被划分为子区域，分别估计代谢物和基线成分后整合。通过视觉和定量评估模拟光谱与实测光谱的接近程度。分析模型使用实测、模拟和建模光谱训练。通过代谢物比例的平均平方误差（MSE）评估方法性能，并与LCModel在两种B0不均匀性条件下分析的幻影光谱的平均绝对百分比误差（MAPE）进行比较。结果：模拟光谱根据B0不均匀性表现出光谱峰的展宽或变窄，且与实测光谱定量接近。使用建模光谱训练的模型比仅使用实测光谱的模型MSE降低了49.89%，比使用模拟光谱的模型降低了26.66%。在两种B0不均匀性条件下，该模型的MAPE显著低于LCModel。结论：开发了一种基于建模光谱训练的深度学习模型，结果表明该方法通过增加光谱训练样本，有望提高光谱分析的准确性。

</details>


### [220] [Uncover Treasures in DCT: Advancing JPEG Quality Enhancement by Exploiting Latent Correlations](https://arxiv.org/abs/2506.21171)
**中文标题：挖掘DCT中的宝藏：通过利用潜在相关性提升JPEG质量增强**

*Jing Yang,Qunliang Xing,Mai Xu,Minglang Qiao*

主要分类: eess.IV

摘要简述: 本文提出了一种基于DCT域的JPEG质量增强方法（AJQE），通过挖掘DCT系数中的潜在相关性，显著提升了性能并降低了计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的JPEG质量增强方法主要在像素域操作，计算成本高。而DCT域方法性能有限，因此需要一种更高效的方法来直接增强DCT域的JPEG图像。

研究方法: 作者识别了JPEG图像DCT系数中的两种关键相关性，并基于此提出了AJQE方法，将像素域模型适配到DCT域，充分利用这些相关性。

研究结果: 与像素域方法相比，AJQE方法在PSNR上平均提升了0.35 dB，增强吞吐量提高了60.5%。

研究结论: AJQE方法通过挖掘DCT域相关性，显著提升了JPEG图像质量增强的性能和效率，为DCT域方法提供了新的研究方向。

中文摘要: 联合图像专家组（JPEG）通过对离散余弦变换（DCT）系数进行量化实现数据压缩，但不可避免地引入了压缩伪影。现有的大多数JPEG质量增强方法在像素域操作，解码计算成本高。因此，直接在DCT域增强JPEG图像逐渐受到关注。然而，当前的DCT域方法性能有限。为解决这一问题，我们识别了JPEG图像DCT系数中的两种关键相关性。基于这一发现，我们提出了一种高级DCT域JPEG质量增强（AJQE）方法，充分利用这些相关性。AJQE方法能够将许多成熟的像素域模型适配到DCT域，以更低的计算复杂度实现更优的性能。与像素域方法相比，通过我们的方法衍生的DCT域模型在PSNR上平均提升了0.35 dB，增强吞吐量提高了60.5%。

</details>


### [221] [GANet-Seg: Adversarial Learning for Brain Tumor Segmentation with Hybrid Generative Models](https://arxiv.org/abs/2506.21245)
**中文标题：GANet-Seg：基于混合生成模型的对抗学习脑肿瘤分割方法**

*Qifei Cui,Xinyu Lu*

主要分类: eess.IV

摘要简述: GANet-Seg提出了一种结合预训练GAN和Unet的新框架，通过全局异常检测和精细化掩模生成网络，实现了高精度的脑肿瘤分割。该方法利用多模态MRI数据和合成图像增强，显著提升了在BraTS数据集上的分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 脑肿瘤分割在临床中具有重要意义，但现有方法依赖大量标注数据且性能有限。本研究旨在通过结合生成对抗网络和Unet架构，减少对标注数据的依赖并提升分割精度。

研究方法: 该方法结合了预训练的GAN和Unet架构，通过全局异常检测模块识别肿瘤敏感区域，并利用精细化掩模生成网络迭代优化分割结果。同时，采用多模态MRI数据和合成图像增强提升模型鲁棒性。

研究结果: 在BraTS数据集上的实验表明，该方法在Dice和HD95指标上均优于基线模型，实现了高灵敏度和准确性，同时减少了对全标注数据的依赖。

研究结论: GANet-Seg通过结合生成对抗学习和Unet架构，显著提升了脑肿瘤分割的性能和实用性，为临床实际应用提供了可行方案。

中文摘要: 本文提出了一种新颖的脑肿瘤分割框架，结合了预训练的生成对抗网络（GAN）和Unet架构。通过将全局异常检测模块与精细化掩模生成网络相结合，该模型能够准确识别肿瘤敏感区域，并利用对抗损失约束迭代提升分割精度。多模态MRI数据和合成图像增强技术的使用进一步提高了模型的鲁棒性，解决了标注数据不足的挑战。在BraTS数据集上的实验结果表明，该方法在病灶级别的Dice和HD95指标上均优于基线模型，表现出高灵敏度和准确性。这种可扩展的方法减少了对全标注数据的依赖，为临床实际应用提供了新的可能性。

</details>


### [222] [Lightweight Physics-Informed Zero-Shot Ultrasound Plane Wave Denoising](https://arxiv.org/abs/2506.21499)
**中文标题：轻量级物理启发的零样本超声平面波去噪**

*Hojat Asgariandehkordi,Mostafa Sharifzadeh,Hassan Rivaz*

主要分类: eess.IV

摘要简述: 本文提出一种轻量级零样本超声平面波去噪框架，通过自监督残差学习抑制噪声，无需额外训练数据，适用于低角度CPWC成像。


<details>
  <summary>详细信息</summary>
研究动机: 超声相干平面波复合（CPWC）通过多角度传输提升图像对比度，但增加角度会降低帧率并引入模糊伪影，且低角度传输易受噪声影响。传统方法需大量训练数据，限制了适用性。

研究方法: 将可用传输角度分为两个不相交子集，分别生成含噪声的复合图像，通过自监督残差学习训练轻量级深度模型，分离噪声与组织信号。

研究结果: 在仿真、体模和活体数据上验证，该方法在对比度增强和结构保留方面优于传统及基于深度学习的去噪方法。

研究结论: 该零样本去噪框架无需领域微调或配对数据，计算成本低，适用于不同解剖区域和采集设置。

中文摘要: 超声相干平面波复合（CPWC）通过组合多角度传输的回波提升图像对比度。然而，增加角度会显著降低帧率，并在快速移动目标中引入模糊伪影。此外，低角度传输的复合图像仍易受噪声影响。本文提出一种专为低角度CPWC采集设计的零样本去噪框架，无需依赖额外训练数据集即可提升对比度。该方法将可用传输角度分为两个不相交子集，分别生成含更高噪声的复合图像，并通过自监督残差学习训练深度模型，抑制非相干噪声并保留解剖结构。由于子集间角度依赖的伪影不同而组织响应相似，这种物理启发的配对使网络能够分离不一致的伪影与一致的组织信号。与监督方法不同，本模型无需领域微调或配对数据，适用于不同解剖区域和采集设置。整个流程采用仅含两个卷积层的轻量级架构，计算成本低。在仿真、体模和活体数据上的评估表明，该方法在对比度增强和结构保留方面优于传统及基于深度学习的去噪方法。

</details>


### [223] [Exploring the Design Space of 3D MLLMs for CT Report Generation](https://arxiv.org/abs/2506.21535)
**中文标题：探索用于CT报告生成的3D多模态大语言模型设计空间**

*Mohammed Baharoon,Jun Ma,Congyu Fang,Augustin Toma,Bo Wang*

主要分类: eess.IV

摘要简述: 本文系统研究了3D多模态大语言模型（MLLMs）在CT报告生成中的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和微调技术，并提出了两种基于知识的报告增强方法，性能提升达10%。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在自动化放射学报告生成（RRG）中显示出潜力，但3D MLLMs的设计空间尚未充分探索。本文旨在填补这一空白，并提升CT报告生成的性能。

研究方法: 研究了3D MLLMs的设计空间，包括视觉输入表示、投影器、LLMs和微调技术；提出了两种知识驱动的报告增强方法；在AMOS-MM数据集1,687例病例上验证了方法。

研究结果: 在MICCAI 2024 AMOS-MM挑战赛中排名第二，GREEN分数提升达10%；发现RRG性能与LLM大小无关，且更大的体积尺寸不一定提升性能；使用分割掩码可提升性能。

研究结论: 3D MLLMs的设计选择对CT报告生成至关重要，知识增强方法显著提升性能，代码已开源。

中文摘要: 多模态大语言模型（MLLMs）已成为自动化放射学报告生成（RRG）的有前景方法。本文系统研究了3D MLLMs的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和微调技术，用于3D CT报告生成。我们还提出了两种基于知识的报告增强方法，将GREEN分数性能提升高达10%，在MICCAI 2024 AMOS-MM挑战赛中排名第二。在AMOS-MM数据集的1,687例病例上的结果显示，在相同训练协议下，RRG性能与LLM大小无关。此外，如果原始ViT在较小体积尺寸上预训练，更大的体积尺寸并不总能提升性能。最后，我们发现使用分割掩码与CT体积结合可提升性能。代码已公开于https://github.com/bowang-lab/AMOS-MM-Solution。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [224] [Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis](https://arxiv.org/abs/2506.20806)
**中文标题：海报：通过基于代理的分析增强图神经网络在网络入侵检测中的鲁棒性**

*Zhonghao Zhan,Huichi Zhou,Hamed Haddadi*

主要分类: cs.CR

摘要简述: 本文提出了一种通过基于代理的分析增强图神经网络（GNN）在网络入侵检测中的鲁棒性的方法，利用大型语言模型（LLM）模拟网络安全专家，显著提升了GNN在对抗攻击下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前GNN在网络入侵检测系统（NIDS）中表现优异，但面临分布漂移和对抗攻击导致的性能下降问题，且现有鲁棒性评估方法依赖不现实的合成扰动。本文旨在通过LLM代理分析提升GNN的鲁棒性和泛化能力。

研究方法: 提出了一种新颖方法，利用LLM作为模拟网络安全专家代理，在网络流数据生成的图结构中识别并缓解可疑或对抗性扰动元素，再交由GNN处理。实验基于包含物理测试床数据的多样化对抗攻击框架。

研究结果: 实验表明，集成LLM分析显著提升了GNN在对抗攻击下的鲁棒性，验证了LLM代理作为入侵检测架构补充层的潜力。

研究结论: LLM代理能够有效增强GNN在网络入侵检测中的鲁棒性，为未来安全架构设计提供了新思路。

中文摘要: 图神经网络（GNN）在网络入侵检测系统（NIDS）中展现出巨大潜力，尤其是在物联网环境中，但由于分布漂移和对抗攻击的影响，其性能会下降。当前的鲁棒性评估通常依赖于不现实的合成扰动，且缺乏对不同类型对抗攻击（包括黑盒和白盒场景）的系统分析。本文提出了一种新颖方法，通过将大型语言模型（LLM）作为模拟网络安全专家代理，在网络流数据生成的图结构中识别并缓解可疑或对抗性扰动元素，从而增强GNN的鲁棒性和泛化能力。我们的实验使用了一个专为多样化对抗攻击设计的评估框架，并包含从物理测试床实验中收集的数据集。结果表明，集成LLM分析可以显著提升GNN在对抗攻击下的鲁棒性，展示了LLM代理作为入侵检测架构补充层的潜力。

</details>


### [225] [ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models](https://arxiv.org/abs/2506.20915)
**中文标题：ZKPROV：一种用于大型语言模型数据集来源的零知识方法**

*Mina Namazi,Alexander Nemecek,Erman Ayday*

主要分类: cs.CR

摘要简述: ZKPROV是一种新型加密框架，通过零知识证明技术验证大型语言模型（LLM）的数据来源，确保模型训练数据的可靠性，同时保护敏感信息不被泄露。


<details>
  <summary>详细信息</summary>
研究动机: 在敏感领域（如医疗）部署大型语言模型时，确保其数据来源的完整性至关重要。现有方法要么计算成本高，要么依赖可信执行环境，ZKPROV旨在提供一种高效且隐私保护的解决方案。

研究方法: ZKPROV通过零知识证明技术，将训练模型与授权数据集绑定，利用数据集签名的元数据和紧凑的模型参数承诺，避免验证每一步训练过程，从而降低计算成本。

研究结果: 实验证明，ZKPROV在生成和验证证明时具有高效性和可扩展性，适用于实际部署，并提供了形式化的安全保障。

研究结论: ZKPROV为大型语言模型的数据来源提供了一种隐私保护且可信的验证方法，解决了现有技术的局限性。

中文摘要: 随着大型语言模型（LLM）在敏感领域的广泛应用，确保其计算来源的完整性成为关键挑战，尤其是在医疗等受监管领域，对数据集使用有严格要求。我们提出ZKPROV，一种新型加密框架，通过零知识证明技术验证LLM的数据来源。该方法允许用户验证模型是否基于可靠数据集训练，同时不泄露数据集或其参数的敏感信息。与现有方法不同，ZKPROV既不完全验证训练过程（计算成本高），也不依赖可信执行环境，而是通过零知识证明将训练模型与授权数据集绑定，利用数据集签名的元数据和紧凑的模型参数承诺，提供隐私保护且可靠的来源证明。实验结果表明，ZKPROV在生成和验证证明时具有高效性和可扩展性，适用于实际部署。我们还提供了形式化的安全保障，证明该方法既能保护数据集机密性，又能确保可信的数据来源。

</details>


### [226] [PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction](https://arxiv.org/abs/2506.21106)
**中文标题：PhishKey：一种基于质心的自适应HTML组件提取增强钓鱼检测方法**

*Felipe Castaño,Eduardo Fidalgo,Enrique Alegre,Rocio Alaiz-Rodríguez,Raul Orduna,Francesco Zola*

主要分类: cs.CR

摘要简述: PhishKey是一种新型钓鱼检测方法，结合字符级URL分类和HTML内容的关键组件提取，通过软投票集成提高分类准确性，实验显示其F1分数高达98.70%，且对抗攻击表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 钓鱼攻击是网络安全的重要威胁，现有检测方法在适应性、鲁棒性和效率方面存在不足。PhishKey旨在通过自动特征提取和集成学习提升检测能力。

研究方法: PhishKey结合字符级URL分类（使用CNN）和HTML内容的关键组件提取（CAPE），避免数据裁剪，并通过软投票集成两类预测结果。

研究结果: 在四个先进数据集上的实验表明，PhishKey的F1分数高达98.70%，且对注入攻击等对抗操作表现出强抵抗力。

研究结论: PhishKey通过多模块集成和自适应特征提取，显著提升了钓鱼检测的准确性和鲁棒性，为网络安全提供了有效解决方案。

中文摘要: 钓鱼攻击是网络安全的重要威胁，其快速演变以绕过检测机制并利用人类弱点。本文提出PhishKey，以解决适应性、鲁棒性和效率的挑战。PhishKey是一种新型钓鱼检测方法，通过自动从混合源中提取特征。它结合字符级处理的卷积神经网络（CNN）用于URL分类，以及基于质心的关键组件钓鱼提取器（CAPE）用于HTML内容的词级处理。CAPE减少噪声并确保完整样本处理，避免对输入数据的裁剪操作。两类预测结果通过软投票集成实现更准确可靠的分类。在四个先进数据集上的实验评估证明了PhishKey的有效性，其F1分数高达98.70%，并对注入攻击等对抗操作表现出强抵抗力，性能下降极小。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [227] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
**中文标题：机器学习的敏捷管理：一项系统映射研究**

*Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski*

主要分类: cs.SE

摘要简述: 本文通过系统映射研究总结了机器学习（ML）敏捷管理的现状，识别了8个关键主题和主要挑战，并指出需要更多实证研究验证现有成果。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习驱动的系统具有动态性，传统项目管理难以应对其快速变化的数据和实验周期。敏捷方法因其灵活性可能适合ML开发，但如何有效应用尚不明确。

研究方法: 采用混合搜索策略（数据库检索与前后向滚雪球法结合）进行系统映射研究，分析了2008至2024年间发表的27篇论文。

研究结果: 研究识别出8个框架，并将建议和实践分为8个主题（如迭代灵活性、ML特定创新工件等），主要挑战是ML任务的工作量估算。

研究结论: 本研究梳理了ML敏捷管理的现状和空白，尽管已有相关研究，仍需更多实证评估验证其有效性。

中文摘要: [背景] 机器学习（ML）驱动的系统正推动社会数字化转型，但其动态性（如实验周期和数据快速变化）对传统项目管理提出挑战。敏捷方法因其灵活性和增量交付特性，可能适合应对这种动态性，但如何在ML系统中有效应用尚不明确。[目标] 本研究旨在概述ML系统敏捷管理的最新进展。[方法] 采用混合搜索策略（数据库检索与前后向滚雪球法结合）进行系统映射研究。[结果] 研究分析了2008至2024年间发表的27篇论文，识别出8个框架，并将建议和实践分为8个主题（如迭代灵活性、ML特定创新工件等），主要挑战是ML任务的工作量估算。[结论] 本研究梳理了ML敏捷管理的现状和空白，尽管已有相关研究，仍需更多实证评估验证其有效性。

</details>


### [228] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
**中文标题：通过自动化集成数据生成可靠的健康不良事件图谱（GRAPH-AID）：一种半自动化的本体构建方法**

*Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty*

主要分类: cs.SE

摘要简述: 本文提出了一种用户友好的方法，利用Python和rdflib库支持本体开发，解决了Neo4j数据库与OWL语言无缝集成的挑战，并通过FDA不良事件报告系统数据库展示了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据和知识的快速扩展，采用系统化的本体生成方法变得至关重要。然而，现有的Neo4j数据库与OWL语言的集成方法需要理解描述逻辑语法，对许多用户来说门槛较高。因此，需要一种更易用的方法来填补这一空白。

研究方法: 本文提出了一种基于Python和rdflib库的用户友好方法，通过自动生成所需的类及其公理，简化了Neo4j数据库与OWL语言的集成过程。该方法以FDA不良事件报告系统数据库为例进行了验证。

研究结果: 通过开发的Python脚本，成功实现了Neo4j数据库与OWL语言的无缝集成，自动生成了所需的类和公理，为快速增长的药物不良事件数据集的本体生成提供了实用解决方案。

研究结论: 本文提出的方法为药物不良事件数据集的本体生成提供了一种高效且易用的解决方案，有助于改善药物安全监测和公共卫生决策。

中文摘要: 随着数据和知识的迅速扩展，采用系统化的本体生成方法变得至关重要。数据量的每日增长和内容的频繁变化使得存储和检索信息以创建知识图谱的需求日益迫切。先前建立的知识获取与表示方法（KNARM）为解决这些挑战和创建知识图谱提供了系统化的方法。然而，遵循这一方法凸显了Neo4j数据库与Web本体语言（OWL）无缝集成的现有挑战。虽然之前已经讨论过将Neo4j数据集成到本体中的尝试，但这些方法通常需要理解描述逻辑（DL）语法，而这对许多用户来说可能并不熟悉。因此，需要一种更易用的方法来填补这一空白。本文提出了一种用户友好的方法，利用Python及其rdflib库支持本体开发。我们通过整合美国食品药品监督管理局（FDA）不良事件报告系统（FAERS）数据库创建的Neo4j数据库展示了这一新方法。利用该数据集，我们开发了一个Python脚本，自动生成所需的类及其公理，从而简化了集成过程。这一方法为快速增长的不良药物事件数据集的本体生成提供了实用解决方案，支持改善药物安全监测和公共卫生决策。

</details>


### [229] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
**中文标题：面向实际应用的RAG系统工程：设计、开发与评估**

*Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson*

主要分类: cs.SE

摘要简述: 本文介绍了五个针对真实场景的RAG系统应用，涵盖多个领域，并通过用户评估总结了十二个关键经验教训。


<details>
  <summary>详细信息</summary>
研究动机: 目前缺乏基于真实用例的RAG系统实证研究，本文旨在填补这一空白，通过实际应用和用户评估提供系统开发的经验教训。

研究方法: 开发了五个领域的RAG系统，结合多语言OCR、语义检索和领域适配LLM，并通过100名用户的网络评估验证系统性能。

研究结果: 用户评估显示系统在易用性、相关性、透明度等方面表现良好，同时总结了十二个影响RAG系统可靠性和可用性的关键挑战。

研究结论: RAG系统在真实场景中具有潜力，但需解决技术、操作和伦理挑战，以提升其可靠性和实用性。

中文摘要: 检索增强生成（RAG）系统正成为将大型语言模型（LLM）与外部知识结合的关键方法，以解决事实准确性和上下文相关性的局限。然而，目前缺乏基于真实用例的RAG系统实证研究，这些研究应通过用户参与评估并系统记录经验教训。本文介绍了五个针对治理、网络安全、农业、工业研究和医疗诊断等领域的RAG应用。每个系统结合了多语言OCR、基于向量嵌入的语义检索和领域适配LLM，并通过本地服务器或云API部署以满足用户需求。基于100名参与者的网络评估，系统在六个维度（易用性、相关性、透明度、响应性、准确性和推荐可能性）上进行了评估。根据用户反馈和开发经验，我们总结了十二个关键经验教训，突出了影响RAG系统可靠性和可用性的技术、操作和伦理挑战。

</details>


### [230] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
**中文标题：基于不确定人类指导的强化学习实现复杂模型转换**

*Kyanna Dagenais,Istvan David*

主要分类: cs.SE

摘要简述: 本文提出了一种通过强化学习（RL）结合不确定人类指导开发复杂模型转换（MT）序列的方法，显著提升了RL性能并优化了MT开发效率。


<details>
  <summary>详细信息</summary>
研究动机: 模型驱动工程中的复杂模型转换（如模型同步、自动修复和设计空间探索）通常需要大量手动操作，容易出错且难以实现。强化学习虽能解决部分问题，但在复杂场景中性能不足，而人类指导可以弥补这一缺陷。

研究方法: 本文提出了一种技术框架，将用户定义的MT映射到RL原语中，并通过RL程序执行以寻找最优MT序列。该方法结合了不确定的人类建议，平衡了建议的确定性和及时性。

研究结果: 评估表明，即使人类建议存在不确定性，也能显著提升RL性能，并更高效地开发复杂MT序列。

研究结论: 该方法为RL驱动的人机协同工程方法提供了新思路，通过结合人类指导优化了复杂MT的开发过程。

中文摘要: 模型驱动工程问题通常需要复杂的模型转换（MT），即由多个步骤组成的MT序列。这类问题的典型例子包括模型同步、自动化模型修复和设计空间探索。手动开发复杂MT容易出错且往往不可行。强化学习（RL）是缓解这些问题的有效方法。在RL中，自主代理通过试错探索状态空间，以识别有益的MT序列。然而，RL方法在复杂问题中表现不佳。此时，人类指导具有重要价值。本文提出了一种方法和框架，通过结合不确定的人类建议，利用RL开发复杂MT序列。该框架将用户定义的MT映射到RL原语中，并作为RL程序执行以寻找最优MT序列。评估表明，即使人类建议存在不确定性，也能显著提升RL性能，并更高效地开发复杂MT。通过权衡人类建议的确定性和及时性，该方法为RL驱动的人机协同工程方法提供了新思路。

</details>


### [231] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
**中文标题：合成需求的质量如何？评估LLM生成的数据集在AI4RE中的应用**

*Abdelkarim El-Hajjami,Camille Salinesi*

主要分类: cs.SE

摘要简述: 本文提出Synthline v1，一种改进的产品线方法，用于生成合成需求数据，并通过多样本提示、自动提示优化和后生成筛选技术提升数据质量。实验表明，合成需求数据在特定任务中可媲美或超越人工数据。


<details>
  <summary>详细信息</summary>
研究动机: 公开标记的需求数据集稀缺是推动人工智能在需求工程（AI4RE）领域发展的主要障碍。大语言模型虽能生成合成数据，但其质量控制和优化方法尚未充分探索。

研究方法: 提出Synthline v1，扩展了早期版本，采用多样本提示、自动提示优化（PACE）和相似性筛选技术，评估其在缺陷检测、功能与非功能分类、质量与非质量分类及安全与非安全分类任务中的表现。

研究结果: 多样本提示显著提升数据效用和多样性（F1分数提高6-44分）；PACE对功能分类效果显著（+32.5分），但对其他任务效果不一；相似性筛选增加多样性但可能降低分类性能。合成数据在安全（+7.8分）和缺陷分类（+15.4分）任务中超越人工数据。

研究结论: 合成需求数据在特定任务中表现优异，为缓解数据集稀缺问题提供了可行路径，并为AI4RE领域提供了实用见解。

中文摘要: 公开可用的标记需求数据集的短缺是推动人工智能在需求工程（AI4RE）领域发展的主要障碍。尽管大语言模型在合成数据生成方面展现出潜力，但控制和优化生成需求质量的系统性方法仍待探索。本文提出Synthline v1，一种改进的产品线方法，用于生成合成需求数据，扩展了早期版本v0，引入了先进的生成策略和筛选技术。我们研究了四个研究问题，评估提示策略、自动提示优化和后生成筛选如何影响四种分类任务的数据质量：缺陷检测、功能与非功能、质量与非质量、安全与非安全。实验表明，多样本提示显著提升了数据的效用和多样性，F1分数提高了6至44分。使用PACE（提示演员-评论家编辑）进行自动提示优化，结果因任务而异，功能分类表现大幅提升（+32.5分），但其他任务表现下降。有趣的是，基于相似性的筛选提高了多样性，但通常损害分类性能，表明一定冗余可能有助于机器学习模型。最重要的是，合成需求数据在特定任务中可媲美或超越人工数据，安全分类（+7.8分）和缺陷分类（+15.4分）任务中合成数据表现更优。这些发现为AI4RE提供了实用见解，并为通过系统性合成生成缓解数据集稀缺问题指明了可行路径。

</details>


### [232] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
**中文标题：$T^3$：基于多层次树形结构的大型语言模型自动程序修复**

*Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li*

主要分类: cs.SE

摘要简述: 本文提出了一种名为$T^3$的多层次树形自动程序修复框架，结合大型语言模型（LLMs）和思维链（CoT）技术，显著提升了自动程序修复（APR）任务的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 自动程序修复（APR）是软件开发与维护中的核心技术，但现有思维链（CoT）技术在APR领域的应用不足，尤其是在复杂逻辑和多步推理方面。本文旨在通过结合LLMs和树搜索技术，提升APR任务的修复精度和效率。

研究方法: 本文提出$T^3$框架，将LLMs的强大推理能力与树搜索相结合，通过多层次树形结构生成候选修复方案，并优化样本选择和修复策略。

研究结果: 实验表明，$T^3$框架显著提高了APR任务的修复精度，并为优化样本选择和修复策略提供了有效指导。

研究结论: $T^3$框架为高效自动调试提供了坚实基础，结合LLMs和树搜索技术，在APR任务中表现出色。

中文摘要: 自动程序修复（APR）是软件开发与维护中的核心技术，旨在通过最小化人工干预实现自动化缺陷修复。近年来，大型语言模型（LLMs）和思维链（CoT）技术的显著进步极大提升了模型的推理能力。然而，由于APR任务需要复杂的逻辑和多步推理能力，CoT技术在该领域的应用仍显不足。本研究系统评估了多种常见CoT技术在APR任务中的表现，并提出了一种创新框架$T^3$，该框架将LLMs的强大推理能力与树搜索相结合，有效提升了生成候选修复方案的精度。此外，$T^3$为APR任务中的样本选择和修复策略优化提供了宝贵指导，为高效自动调试建立了稳健的框架。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [233] [DRAGON: Distributional Rewards Optimize Diffusion Generative Models](https://arxiv.org/abs/2504.15217)
**中文标题：DRAGON：分布奖励优化扩散生成模型**

*Yatong Bai,Jonah Casebeer,Somayeh Sojoudi,Nicholas J. Bryan*

主要分类: cs.SD

摘要简述: 本文提出DRAGON框架，通过分布奖励优化扩散生成模型，支持多种奖励函数，提升生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统RLHF或DPO方法灵活性不足，无法适应多样化的奖励函数需求，DRAGON旨在提供更通用的优化框架。

研究方法: DRAGON通过选择编码器和参考样本构建奖励函数，利用正负样本对比优化生成模型，支持跨模态奖励。

研究结果: 在20种奖励函数测试中，DRAGON平均胜率达81.45%，且无需人类偏好标注即可提升音乐生成质量。

研究结论: DRAGON为奖励函数设计和优化提供了新思路，显著提升生成模型的感知质量。

中文摘要: 我们提出了分布奖励生成优化框架（DRAGON），用于微调媒体生成模型以实现目标结果。与传统的人类反馈强化学习（RLHF）或直接偏好优化（DPO）等成对偏好方法相比，DRAGON更具灵活性。它可以优化评估单个样本或其分布的奖励函数，兼容实例级、实例到分布和分布到分布的多种奖励。利用这种灵活性，我们通过选择编码器和参考样本构建新颖的奖励函数，创建示例分布。当使用跨模态编码器（如CLAP）时，参考样本可以是不同模态（如文本与音频）。DRAGON收集在线和策略生成样本，评分后构建正负示例集，并利用两者的对比最大化奖励。为评估效果，我们使用20种奖励函数微调音频域文本到音乐扩散模型，包括自定义音乐美学模型、CLAP分数、Vendi多样性和Frechet音频距离（FAD）。我们进一步比较实例级（单曲）和全数据集FAD设置，同时消融多种FAD编码器和参考集。在所有20种目标奖励中，DRAGON平均胜率达81.45%。此外，基于示例集的奖励函数确实提升了生成质量，与基于模型的奖励相当。通过合适的示例集，DRAGON在未使用人类偏好标注的情况下，实现了60.95%的人类投票音乐质量胜率。因此，DRAGON展示了设计和优化奖励函数以提升人类感知质量的新方法。音频示例见https://ml-dragon.github.io/web。

</details>


### [234] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
**中文标题：探索低资源音乐生成中适配器设计的权衡**

*Atharva Mehta,Shivam Chauhan,Monojit Choudhury*

主要分类: cs.SD

摘要简述: 本文研究了在低资源音乐生成任务中，不同适配器设计对模型性能的影响，发现卷积适配器擅长捕捉局部音乐细节，而Transformer适配器更适合长距离依赖，同时中等规模适配器在表达力和质量间取得最佳平衡。


<details>
  <summary>详细信息</summary>
研究动机: 由于微调大规模音乐生成模型（如MusicGen和Mustango）计算成本高昂，参数高效微调（PEFT）技术成为替代方案。然而，适配器的设计选择（如架构、位置和大小）多样，且缺乏针对低资源音乐类型的优化指导。本文旨在探索这些设计选择的影响。

研究方法: 研究针对MusicGen和Mustango两种音乐生成模型，在Hindustani古典音乐和土耳其Makam音乐两种类型上，测试了不同适配器配置（如卷积和Transformer架构），并分析了计算资源需求。

研究结果: 卷积适配器擅长捕捉局部音乐细节（如装饰音和短旋律），Transformer适配器更适合长距离依赖（如结构化即兴创作）。中等规模适配器（4000万参数）在表达力和质量间取得最佳平衡。Mustango生成更多样化输出但稳定性较差，而MusicGen训练更快且质量更高。

研究结论: 适配器设计需根据任务需求权衡局部细节与长距离依赖，中等规模适配器是低资源音乐生成的优选。Mustango适合多样化输出，而MusicGen在效率和生成质量上更优。

中文摘要: 微调大规模音乐生成模型（如MusicGen和Mustango）是一个计算成本高昂的过程，通常需要更新数十亿参数，因此需要大量硬件资源。参数高效微调（PEFT）技术，尤其是基于适配器的方法，成为一种有前景的替代方案，能够以最少的可训练参数实现模型适应，同时保持性能。然而，适配器的设计选择（如架构、位置和大小）多样，且不清楚哪些组合能为特定低资源音乐类型生成最优适配器及其原因。本文通过研究MusicGen和Mustango两种AI音乐模型在Hindustani古典音乐和土耳其Makam音乐上的不同适配器配置，试图回答这一问题。

我们的研究揭示了明显的权衡：基于卷积的适配器擅长捕捉细粒度的局部音乐细节（如装饰音和短旋律），而基于Transformer的适配器更适合保留长距离依赖（对结构化即兴创作至关重要）。此外，我们分析了不同规模适配器的计算资源需求，证明中等规模适配器（4000万参数）在表达力和质量间取得最佳平衡。我们还发现，基于扩散的模型Mustango生成更多样化的输出，且更符合输入提示的描述，但在音符稳定性、节奏对齐和美学上表现不足，且训练时间更长。相比之下，自回归模型如MusicGen训练更快、效率更高，生成质量更优，但输出略有冗余。

</details>


### [235] [A Hierarchical Deep Learning Approach for Minority Instrument Detection](https://arxiv.org/abs/2506.21167)
**中文标题：一种分层深度学习方法用于少数乐器检测**

*Dylan Sechet,Francesca Bugiotti,Matthieu Kowalski,Edouard d'Hérouville,Filip Langiewicz*

主要分类: cs.SD

摘要简述: 本文提出了一种分层深度学习方法，用于检测少数乐器，通过结合Hornbostel-Sachs分类系统，在MedleyDB数据集上验证了模型的有效性，提升了粗粒度乐器检测的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 音乐信息检索中，乐器活动的识别对音乐分类和发现至关重要。以往研究多关注数据充足的乐器类别，而少数乐器的检测因数据稀缺而受限。本文旨在通过分层分类方法，解决少数乐器检测的挑战。

研究方法: 基于Hornbostel-Sachs分类系统，设计分层分类模型，并在MedleyDB数据集上进行评估。通过整合层次结构到模型中，测试了新的分层音乐预测模型。

研究结果: 实验表明，该方法在粗粒度乐器检测上表现更可靠，填补了详细乐器识别与组别识别之间的空白。

研究结论: 本研究为分层音乐预测提供了新思路，推动了乐器检测领域的进一步发展。

中文摘要: 在音乐信息检索中，识别音频片段中的乐器活动对音乐分类和发现具有重要意义。以往的深度学习研究主要关注数据充足的乐器类别。最近的研究表明，分层分类方法可用于检测管弦乐中的乐器活动，即使在乐器级别的细粒度标注有限的情况下。基于Hornbostel-Sachs分类系统，本研究在MedleyDB数据集上评估了这种分层分类方法，该数据集以其多样性和丰富的乐器及音乐类型而闻名。本文提出了多种策略，将层次结构整合到模型中，并测试了一类新的分层音乐预测模型。通过填补详细乐器识别与组别识别之间的空白，本研究展示了更可靠的粗粒度乐器检测，为该领域的进一步发展铺平了道路。

</details>


### [236] [Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou](https://arxiv.org/abs/2506.21269)
**中文标题：整合车辆声学数据以增强城市交通管理：苏州速度分类研究**

*Pengfei Fan,Yuli Zhang,Xinheng Wang,Ruiyuan Jiang,Hankang Gu,Dongyao Jia,Shangbo Wang*

主要分类: cs.SD

摘要简述: 本研究提出了一种基于双模态特征融合的深度卷积神经网络（BMCNN），用于车辆噪声与行驶速度的分类，并在苏州城市道路声学数据集（SZUR-Acoustic Dataset）上取得了87.56%的分类准确率。该方法可应用于智能城市交通管理系统，优化交通流量控制并减少噪声污染。


<details>
  <summary>详细信息</summary>
研究动机: 随着智能城市的发展，实时监测交通噪声和车辆速度对优化交通管理和减少噪声污染至关重要。然而，现有方法在噪声干扰和特征融合方面存在不足，因此需要一种更高效且鲁棒的方法。

研究方法: 研究提出了一种双模态特征融合的深度卷积神经网络（BMCNN）。预处理阶段采用自适应去噪和归一化策略抑制环境背景干扰；网络架构中，并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，并通过跨模态注意力机制在中间特征空间融合，充分利用时频信息。

研究结果: BMCNN在苏州数据集上的分类准确率为87.56%，在公开的IDMT-Traffic数据集上达到96.28%。消融实验和鲁棒性测试验证了各模块对性能提升和过拟合缓解的贡献。

研究结论: 基于声学的速度分类方法可集成到智能城市交通管理系统中，实现实时噪声监测和速度估计，优化交通流量控制，减少路边噪声污染，支持可持续城市规划。

中文摘要: 本研究提出并公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提供了全面的数据采集协议和标注指南，以确保实验流程的透明性和可重复性。为建模车辆噪声与行驶速度的耦合关系，我们提出了一种双模态特征融合的深度卷积神经网络（BMCNN）。预处理阶段采用自适应去噪和归一化策略抑制环境背景干扰；网络架构中，并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，并通过跨模态注意力机制在中间特征空间融合，充分利用时频信息。实验结果表明，BMCNN在SZUR-Acoustic数据集上的分类准确率为87.56%，在公开的IDMT-Traffic数据集上达到96.28%。消融实验和鲁棒性测试进一步验证了各模块对性能提升和过拟合缓解的贡献。所提出的基于声学的速度分类方法可集成到智能城市交通管理系统中，实现实时噪声监测和速度估计，从而优化交通流量控制，减少路边噪声污染，支持可持续城市规划。

</details>


### [237] [SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture](https://arxiv.org/abs/2506.21478)
**中文标题：SmoothSinger：一种基于多分辨率架构的条件扩散模型用于歌唱声音合成**

*Kehan Sui,Jinxu Xiang,Fang Jin*

主要分类: cs.SD

摘要简述: SmoothSinger是一种基于条件扩散模型的歌唱声音合成方法，通过多分辨率架构和参考引导的双分支设计，显著提升了合成声音的自然度和质量，避免了传统两阶段流程中的失真问题。


<details>
  <summary>详细信息</summary>
研究动机: 歌唱声音合成（SVS）需要精确建模音高、时长和发音，但现有扩散模型在SVS中因复杂的声学和音乐特性而存在自然度不足的问题。SmoothSinger旨在通过统一框架直接优化低质量合成音频，避免传统方法中因使用声码器而引入的失真。

研究方法: SmoothSinger采用参考引导的双分支架构，利用低质量音频作为参考指导去噪过程，并结合并行低频上采样路径增强音高轮廓和长期频谱依赖的建模。训练时用退化真实音频替代参考音频，解决时间不匹配问题。

研究结果: 在Opencpop数据集上的实验表明，SmoothSinger在客观和主观评估中均达到最先进水平，消融实验证实其有效减少伪影并提升合成声音的自然度。

研究结论: SmoothSinger通过统一框架和多分辨率设计，显著提升了歌唱声音合成的质量和自然度，为SVS领域提供了新的解决方案。

中文摘要: 歌唱声音合成（SVS）旨在从乐谱生成富有表现力和高质量的歌声，需要对音高、时长和发音进行精确建模。尽管扩散模型在图像和视频生成中取得了显著成功，但其在SVS中的应用仍因歌唱的复杂声学和音乐特性而面临挑战，常导致伪影并降低自然度。本文提出SmoothSinger，一种条件扩散模型，用于合成高质量且自然的歌声。与依赖声码器作为最终阶段并常引入失真的现有方法不同，SmoothSinger在统一框架中直接优化低质量合成音频，缓解了两阶段流程的退化问题。该模型采用参考引导的双分支架构，利用来自任何基线系统的低质量音频作为参考指导去噪过程，实现更具表现力和上下文感知的合成。此外，它通过并行低频上采样路径增强传统U-Net，使模型能更好地捕捉音高轮廓和长期频谱依赖。为改善训练时的对齐，我们用退化的真实音频替代参考音频，解决参考信号与目标信号的时间不匹配问题。在Opencpop数据集（一个大规模中文歌唱语料库）上的实验表明，SmoothSinger在客观和主观评估中均达到最先进水平。大量消融实验证实其在减少伪影和提升合成声音自然度方面的有效性。

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [238] [On Uniform Weighted Deep Polynomial approximation](https://arxiv.org/abs/2506.21306)
**中文标题：关于均匀加权深度多项式逼近的研究**

*Kingsley Yeon,Steven B. Damelin*

主要分类: math.NA

摘要简述: 本文提出了一种加权深度多项式逼近方法，用于处理具有不对称行为的函数，通过结合可学习的深度多项式和单侧权重，显著提升了逼近效果，优于传统多项式逼近方法。


<details>
  <summary>详细信息</summary>
研究动机: 经典有理逼近理论表明，非光滑或奇异函数（如|x|和x^(1/p)）可通过有理函数高效逼近，而多项式逼近仅能实现代数收敛。近期研究表明，复合多项式结构可恢复指数逼近速率。本文旨在针对具有不对称行为的函数（一侧无界增长，另一侧衰减），设计一种加权深度多项式逼近方法。

研究方法: 本文提出了一种加权深度多项式逼近框架，通过将可学习的深度多项式与单侧权重相乘，捕捉局部非光滑性和全局增长特性。此外，提出了一种基于图的稳定参数化策略，用于实际优化。

研究结果: 数值实验表明，该方法在相同参数数量下，优于泰勒、切比雪夫和标准深度多项式逼近方法。

研究结论: 加权深度多项式逼近方法在处理不对称行为函数时表现出色，为相关领域提供了新的逼近工具。

中文摘要: 有理逼近理论中的经典结果表明，某些非光滑或奇异函数（如|x|和x^(1/p)）可通过有理函数以根指数收敛速度高效逼近，而多项式逼近仅能实现代数收敛（Jackson定理）。近期研究表明，复合多项式结构即使在不光滑情况下也能恢复指数逼近速率。本文提出并分析了一类加权深度多项式逼近方法，专门针对具有不对称行为的函数（一侧无界增长，另一侧衰减）。通过将可学习的深度多项式与单侧权重相乘，我们同时捕捉了局部非光滑性和全局增长特性。数值实验表明，该框架在相同参数数量下优于泰勒、切比雪夫和标准深度多项式逼近方法。为了实际优化这些逼近器，我们提出了一种基于图的稳定参数化策略。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [239] [Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs](https://arxiv.org/abs/2506.20980)
**中文标题：增强同质-异质分离：异质图中的关系感知学习**

*Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu*

主要分类: cs.SI

摘要简述: 本文提出了一种名为RASH的新型对比学习框架，用于在异质图中显式建模高阶语义并自适应分离同质和异质模式，解决了异质性和异质性的双重挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的网络通常具有节点异质性，即连接的节点具有不同的特征或标签。这一问题在同质图中已有广泛研究，但在异质图中仍未被充分探索。现有方法通常将异质图转换为同质图，导致潜在的异质性信息丢失。

研究方法: RASH框架通过引入双异质超图编码多关系二分子图，并基于关系重要性动态构建同质图和异质图。设计了一种多关系对比损失，通过最大化互信息对齐异质和同质/异质视图。

研究结果: 在多个基准数据集上的实验表明，RASH在各种下游任务中均表现出色。

研究结论: RASH成功解决了异质图中的异质性和异质性挑战，为相关研究提供了新的思路。

中文摘要: 现实世界中的网络通常具有节点异质性，即连接的节点通常具有不同的特征或标签。这一问题在同质图中已被广泛研究，但在异质图中仍未被充分探索。在异质图中捕捉节点异质性非常具有挑战性，因为需要同时考虑节点/边的异质性和节点异质性。现有方法通常将异质图转换为同质图以学习节点异质性，但这不可避免地会丢失异质关系传递的潜在异质性。为了填补这一空白，我们提出了关系感知的同质-异质分离（RASH），这是一种新型对比学习框架，显式建模异质交互的高阶语义并自适应分离同质和异质模式。具体而言，RASH引入双异质超图编码多关系二分子图，并基于关系重要性动态构建同质图和异质图。设计了一种多关系对比损失，通过最大化互信息对齐异质和同质/异质视图。通过这种方式，RASH同时解决了异质图中的异质性和异质性挑战。在多个基准数据集上的实验证明了RASH在各种下游任务中的有效性。代码可在以下网址获取：https://github.com/zhengziyu77/RASH。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [240] [Real-time and personalized product recommendations for large e-commerce platforms](https://arxiv.org/abs/2506.21368)
**中文标题：大型电商平台的实时个性化产品推荐**

*Matteo Tolloso,Davide Bacciu,Shahab Mokarizadeh,Marco Varesi*

主要分类: cs.IR

摘要简述: 本文提出了一种基于图神经网络和简约学习方法的实时个性化产品推荐方法，适用于大型电商平台（尤其是时尚零售），通过实验验证了其高效性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 大型电商平台需要实时且个性化的产品推荐以提升用户体验，但现有方法在响应时间和扩展性上存在不足。本文旨在解决这些问题，特别是在时尚零售领域。

研究方法: 采用图神经网络（GNN）和简约学习方法，设计了一种能够快速响应的推荐系统，专注于预测购买序列和处理多交互场景。

研究结果: 实验表明，该方法在大型电商平台数据集上表现优异，能够高效生成个性化推荐，并满足实时性需求。

研究结论: 本文提出的方法在实时性和个性化推荐方面具有显著优势，适用于大规模电商平台的实际应用。

中文摘要: 我们提出了一种为大型电商平台（尤其是时尚零售）提供实时个性化产品推荐的方法。该方法旨在通过图神经网络和简约学习方法，实现高准确性和可扩展性的推荐，同时确保最短的响应时间以提升用户满意度。通过对某大型电商平台数据集的广泛实验，验证了该方法在预测购买序列和处理多交互场景中的有效性，能够在实际约束下高效生成个性化推荐。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [241] [ResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers](https://arxiv.org/abs/2506.21537)
**中文标题：ResQ：一种在模拟Rydberg原子量子计算机上实现残差神经网络的新框架**

*Nicholas S. DiBrita,Jason Han,Tirthak Patel*

主要分类: quant-ph

摘要简述: 本文提出ResQ框架，利用模拟Rydberg原子量子计算机实现残差神经网络（ResNets），探索量子计算在机器学习中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 量子机器学习研究因量子计算的潜力而迅速发展，但基于神经常微分方程（神经ODE）的残差神经网络（ResNets）尚未被探索。本文旨在填补这一空白，并展示模拟Rydberg原子量子计算机在ResNets中的独特优势。

研究方法: 提出ResQ框架，通过优化Rydberg原子量子计算机的动力学，利用模拟量子神经ODE解决机器学习中的分类问题。

研究结果: 研究表明，模拟Rydberg原子量子计算机特别适合实现ResNets，ResQ框架能够有效解决分类问题。

研究结论: ResQ框架为量子机器学习提供了新的研究方向，展示了模拟量子计算机在ResNets中的潜力。

中文摘要: 量子机器学习的研究最近因量子计算加速机器学习的潜力而蓬勃发展。然而，基于神经常微分方程（神经ODE）的残差神经网络（ResNets）尚未被探索，其目标是通过常微分方程原理提升神经网络的有效性。本文中，我们阐述了模拟Rydberg原子量子计算机特别适合ResNets的原因，并介绍了ResQ框架，该框架通过优化Rydberg原子量子计算机的动力学，利用模拟量子神经ODE解决机器学习中的分类问题。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [242] [CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions](https://arxiv.org/abs/2506.21085)
**中文标题：CovDocker：基于任务、数据集和解决方案的共价药物设计基准测试**

*Yangzhe Peng,Kaiyuan Gao,Liang He,Yuheng Cong,Haiguang Liu,Kun He,Lijun Wu*

主要分类: q-bio.BM

摘要简述: CovDocker是一个针对共价药物设计的综合性基准测试，通过分解共价对接过程为三个任务，并利用先进模型验证其有效性，为共价药物研究提供了严格框架。


<details>
  <summary>详细信息</summary>
研究动机: 现有分子对接方法和深度学习模型大多未考虑共价键的形成及其伴随的结构变化，导致共价药物设计的研究受限。CovDocker旨在填补这一空白，提供更全面的共价对接基准。

研究方法: 将共价对接过程分解为三个任务：反应位点预测、共价反应预测和共价对接。采用Uni-Mol和Chemformer等先进模型建立基线性能，验证基准的准确性。

研究结果: 基准测试成功预测了相互作用位点并模拟了共价结合中的分子转化，证明了其在共价药物设计中的有效性。

研究结论: CovDocker为共价药物设计提供了严格的研究框架，展示了数据驱动方法在加速选择性共价抑制剂发现中的潜力。

中文摘要: 分子对接在预测配体与靶蛋白结合模式中起关键作用，而共价相互作用因形成配体与靶标间的共价键而具有持久结合特性，尤为重要。然而，现有对接方法和深度学习模型很少考虑共价键形成及其伴随的结构变化。为填补这一空白，我们提出了共价对接的综合基准CovDocker，旨在更好地捕捉共价结合的复杂性。我们将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过采用Uni-Mol和Chemformer等先进模型，我们建立了基线性能，并证明了基准在准确预测相互作用位点和模拟共价结合中分子转化的有效性。这些结果证实了该基准作为推动共价药物设计研究的严格框架的作用，凸显了数据驱动方法在加速选择性共价抑制剂发现中的潜力，并解决了治疗开发中的关键挑战。

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [243] [From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting](https://arxiv.org/abs/2506.21246)
**中文标题：从链上到宏观：评估数据源多样性在加密货币市场预测中的重要性**

*Giorgos Demosthenous,Chryssis Georgiou,Eliada Polydorou*

主要分类: q-fin.PM

摘要简述: 本研究探讨了数据源多样性对加密货币市场预测模型性能的影响，通过整合技术指标、链上指标、情感与兴趣指标、传统市场指数及宏观经济指标等多种数据类别，提出了Crypto100指数和一种新颖的特征降维算法。实验表明，数据源多样性显著提升了预测模型在不同时间范围内的表现。


<details>
  <summary>详细信息</summary>
研究动机: 加密货币市场的复杂性和波动性使得预测模型需要依赖多样化的数据源以提高准确性。本研究旨在通过整合多种数据类别，揭示不同数据源对短期和长期预测的重要性，从而为开发更精准和稳健的预测模型提供理论基础。

研究方法: 研究引入了Crypto100指数（代表市值前100的加密货币），并提出了一种特征降维算法，用于从多样化的数据源中筛选最具影响力和稳健性的特征。通过综合实验，评估了技术指标、链上指标、情感与兴趣指标、传统市场指数及宏观经济指标对预测模型性能的贡献。

研究结果: 实验结果表明，数据源多样性显著提升了预测模型的性能。链上指标对短期和长期预测均至关重要，而传统市场指数和宏观经济指标在长期预测中的作用逐渐增强。使用多样化数据源显著提高了模型的准确性。

研究结论: 本研究揭示了加密货币市场短期和长期的驱动因素，强调了数据源多样性对预测模型的重要性。研究结果为开发更准确和稳健的预测模型奠定了基础。

中文摘要: 本研究通过整合技术指标、链上指标、情感与兴趣指标、传统市场指数及宏观经济指标等多种数据类别，探讨了数据源多样性对加密货币预测模型性能的影响。我们引入了Crypto100指数（代表市值前100的加密货币），并提出了一种新颖的特征降维算法，用于从多样化数据源中识别最具影响力和稳健性的特征。综合实验表明，数据源多样性显著提升了预测模型在不同时间范围内的表现。关键发现包括：链上指标对短期和长期预测均至关重要；传统市场指数和宏观经济指标在长期预测中的作用逐渐增强；使用多样化数据源显著提高了模型的准确性。这些发现有助于揭示加密货币市场的短期和长期驱动因素，并为开发更准确和稳健的预测模型奠定了基础。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [244] [Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots](https://arxiv.org/abs/2506.20748)
**中文标题：探索聊天机器人拟人化与人类同理心对人类对聊天机器人亲社会行为的影响**

*Jingshu Li,Zicheng Zhu,Renwen Zhang,Yi-Chieh Lee*

主要分类: cs.HC

摘要简述: 研究探讨了聊天机器人拟人化（如人类身份、情感表达）如何通过激发人类同理心，促使用户对聊天机器人表现出亲社会行为和意图。


<details>
  <summary>详细信息</summary>
研究动机: 随着聊天机器人在生活中的广泛应用，人类帮助聊天机器人的现象逐渐增多，但相关研究较少。本文旨在探索聊天机器人拟人化如何通过激发同理心影响人类的亲社会行为。

研究方法: 通过在线实验（N=244），让聊天机器人在协作图像标注任务中犯错并向参与者解释原因，随后测量参与者的亲社会行为和意图。

研究结果: 研究发现，聊天机器人的人类身份和情感表达显著增加了用户的亲社会行为和意图，且同理心在其中起到中介作用。定性分析还揭示了两种动机：对聊天机器人的同理心和将其视为人类。

研究结论: 聊天机器人的拟人化设计能有效激发人类的同理心，从而促进亲社会行为，这对理解和优化人机互动具有重要意义。

中文摘要: 聊天机器人越来越多地融入人们的生活，并被广泛用于帮助人类。近年来，由于聊天机器人性能提升、人类福祉改善及协作成果优化等益处，人类帮助聊天机器人的现象也日益受到关注。然而，关于人类帮助聊天机器人的动机因素研究较少。为填补这一空白，我们基于“计算机是社会行动者”（CASA）框架，探讨聊天机器人的拟人化（包括人类身份、情感表达和非语言表达）如何影响人类对聊天机器人的同理心及其后续的亲社会行为和意图。我们还研究了人类对其亲社会行为的自我解释。通过一项在线实验（N=244），在协作图像标注任务中让聊天机器人犯错并向参与者解释原因，随后测量参与者的亲社会行为和意图。结果显示，聊天机器人的人类身份和情感表达显著增加了参与者的亲社会行为和意图，且同理心在其中起中介作用。定性分析进一步揭示了参与者亲社会行为的两种动机：对聊天机器人的同理心及将其视为人类。我们讨论了这些结果对理解和促进人类对聊天机器人亲社会行为的启示。

</details>


### [245] [A Systematic Review of Human-AI Co-Creativity](https://arxiv.org/abs/2506.21333)
**中文标题：人机协同创造的系统性综述**

*Saloni Singh,Koen Hndriks,Drik Heylen,Kim Baraka*

主要分类: cs.HC

摘要简述: 本文通过系统文献综述分析了62篇关于人机协同创造系统的论文，总结了系统设计的关键维度和24条设计建议，强调高用户控制和适应性主动系统对提升创造过程的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 人机协同创造领域在开发支持人类创造力的系统方面取得进展，但缺乏对设计维度的系统总结。本文旨在通过文献综述填补这一空白，为未来系统设计提供基础。

研究方法: 对62篇关于人机协同创造系统的论文进行系统性文献综述，分析应用领域、系统行为、用户控制等关键维度，并提取设计建议。

研究结果: 研究发现，高用户控制的系统能提升用户满意度和信任感，适应性主动系统可增强协作；同时总结了24条设计建议，如鼓励用户表达想法和提升系统透明度。

研究结论: 尽管人机协同创造系统取得进展，早期创意阶段支持不足和用户适应问题仍是挑战，未来研究需进一步优化系统设计。

中文摘要: 协同创造领域在开发更复杂和定制化的系统以支持和增强人类创造力方面取得了显著进展。先前工作的设计考虑可以作为未来系统的高效基础。为支持这一努力，我们对62篇关于协同创造系统的文献进行了系统性综述。这些论文涵盖了视觉艺术、设计和写作等多样化应用，其中AI不仅是工具，还是创意过程中的积极合作者。通过综述，我们确定了与系统设计相关的几个关键维度：创意过程的阶段、创意任务、系统的主动行为、用户控制、系统体现和AI模型类型。研究发现，提供高用户控制的系统能带来更高的满意度、信任感和对创意成果的拥有感。此外，适应性且上下文敏感的主动系统可以增强协作。我们还提取了24条设计建议，强调了鼓励用户表达想法和提升系统社交存在感与透明度以促进信任的价值。尽管最近取得进展，但仍存在重要空白，如对早期创意阶段（如问题澄清）的支持有限，以及用户适应AI系统的挑战。

</details>


### [246] [Multimodal LLMs for Visualization Reconstruction and Understanding](https://arxiv.org/abs/2506.21319)
**中文标题：用于可视化重建和理解的多模态大模型**

*Can Liu,Chunlin Da,Xiaoxiao Long,Yuxiao Yang,Yu Zhang,Yong Wang*

主要分类: cs.HC

摘要简述: 本文提出了一种针对可视化理解的多模态大模型，通过结合图表图像及其向量化表示、编码方案和数据特征，显著提升了数据提取准确性和图表重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 可视化在数据交流中至关重要，但现有多模态大模型在理解可视化时存在困难，无法解析数据到视觉的映射规则或提取结构化信息。

研究方法: 作者构建了一个新数据集，并训练了专门用于可视化理解的多模态大模型，结合图表图像、向量化表示、编码方案和数据特征。

研究结果: 实验结果表明，该方法在数据提取准确性和图表重建质量上均有显著提升。

研究结论: 该研究为可视化理解提供了一种有效方法，通过多模态大模型和向量化表示实现了更准确的数据提取和图表重建。

中文摘要: 可视化在数据交流中至关重要，但理解它们需要同时理解视觉元素及其底层数据关系。目前的多模态大模型虽然在自然图像理解上表现优异，但在可视化方面存在困难，因为它们无法解析数据到视觉的映射规则或提取结构化信息。为解决这些问题，我们提出了一种新数据集，并训练了专门用于可视化理解的多模态大模型。我们的方法结合了图表图像及其对应的向量化表示、编码方案和数据特征。所提出的向量格式能够紧凑且准确地重建可视化内容。实验结果表明，该方法在数据提取准确性和图表重建质量上均有显著提升。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [247] [IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation](https://arxiv.org/abs/2506.20696)
**中文标题：IMC-PINN-FE：一种基于物理信息的神经网络框架，用于患者特异性左心室有限元建模，结合图像运动一致性和生物力学参数估计**

*Siyu Mu,Wei Xuan Chan,Choon Hwai Yap*

主要分类: physics.med-ph

摘要简述: IMC-PINN-FE是一种基于物理信息的神经网络框架，用于快速、个性化的左心室生物力学建模，结合图像运动一致性和生物力学参数估计，显著提高了计算效率和运动匹配精度。


<details>
  <summary>详细信息</summary>
研究动机: 传统有限元方法计算成本高且难以准确模拟心脏运动，而临床影像无法直接推断心肌的生物力学行为。因此，需要一种高效且精确的方法来实现个性化的心脏生物力学建模。

研究方法: IMC-PINN-FE首先通过预训练的注意力网络或无监督循环正则化网络从MRI或超声心动图中估计心脏运动，并提取运动模式。随后，通过拟合临床压力测量快速估计心肌刚度和主动张力，并以75倍加速完成有限元建模。

研究结果: IMC-PINN-FE显著提高了运动匹配精度（Dice系数从0.849提升至0.927），同时保持了真实的压力-容积行为。计算时间从传统方法的数小时缩短至秒级。

研究结论: IMC-PINN-FE通过引入材料属性的反向计算和更高的运动保真度，为快速、个性化且图像一致的心脏生物力学建模提供了高效且稳健的解决方案。

中文摘要: 阐明心肌的生物力学行为对理解心脏生理学至关重要，但无法直接从临床影像中推断，通常需要有限元（FE）模拟。然而，传统有限元方法计算成本高，且难以准确再现观测到的心脏运动。我们提出IMC-PINN-FE，一种基于物理信息的神经网络（PINN）框架，将图像运动一致性（IMC）与有限元建模相结合，用于患者特异性左心室（LV）生物力学建模。首先通过预训练的注意力网络或无监督循环正则化网络从MRI或超声心动图中估计心脏运动，并提取运动模式。随后，IMC-PINN-FE通过拟合临床压力测量快速估计心肌刚度和主动张力，与传统逆向有限元方法相比，计算时间从数小时缩短至秒级。基于这些参数，它在心脏周期内完成有限元建模，速度提升75倍。通过运动约束，它更准确地匹配图像位移，将平均Dice系数从0.849提升至0.927，同时保持真实的压力-容积行为。IMC-PINN-FE通过引入材料属性的反向计算和更高的运动保真度，改进了先前的PINN-FE模型。此外，利用单个受试者的运动数据重建形状模式，避免了对大规模数据集的需求，并提高了患者特异性。IMC-PINN-FE为快速、个性化且图像一致的心脏生物力学建模提供了一种稳健且高效的解决方案。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [248] [Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution](https://arxiv.org/abs/2506.21278)
**中文标题：基于高效球形柯西分布的超球面变分自编码器**

*Lukas Sablica,Kurt Hornik*

主要分类: stat.ML

摘要简述: 本文提出了一种新型变分自编码器（VAE）架构，采用球形柯西（spCauchy）潜在分布，相比传统高斯或von Mises-Fisher（vMF）分布，能更自然地表示方向性数据，避免过正则化，且计算更高效。


<details>
  <summary>详细信息</summary>
研究动机: 传统VAE使用高斯或vMF潜在分布存在过正则化和数值不稳定性问题，spCauchy分布因其重尾特性和高效计算能力，有望提供更优的潜在空间表示。

研究方法: 提出基于spCauchy分布的VAE架构，利用Möbius变换实现高效重参数化，并通过快速收敛的幂级数计算KL散度，避免数值不稳定问题。

研究结果: spCauchy分布显著提升了潜在空间的表达能力，避免了vMF的数值不稳定性，同时训练过程更稳定且高效。

研究结论: spCauchy分布为高维生成模型提供了理论和实践优势，是VAE中潜在分布的有力替代方案。

中文摘要: 我们提出了一种新型变分自编码器（VAE）架构，采用球形柯西（spCauchy）潜在分布。与传统高斯潜在空间或广泛使用的von Mises-Fisher（vMF）分布相比，spCauchy能更自然地表示方向性数据，同时保持灵活性。其重尾特性避免了过正则化，确保潜在空间的高效利用，并提供更具表达力的表示。此外，spCauchy规避了vMF因计算涉及贝塞尔函数的归一化常数而导致的数值不稳定性问题。通过Möbius变换，spCauchy实现了完全可微分且高效的重参数化技巧，支持稳定且可扩展的训练。KL散度可通过快速收敛的幂级数计算，消除了与超几何函数比值评估相关的下溢或上溢问题。这些特性使spCauchy成为VAE的理想替代方案，为高维生成模型提供了理论和实践优势。

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [249] [Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation](https://arxiv.org/abs/2506.21154)
**中文标题：基于Transformer的时空反事实结果估计**

*He Li,Haoang Chi,Mingyu Liu,Wanrong Huang,Liyang Xu,Wenjing Yang*

主要分类: stat.ME

摘要简述: 本文提出了一种基于Transformer的时空反事实结果估计框架，相比传统统计模型具有更强的估计能力和泛化性能，并通过仿真和真实数据实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界具有时间和空间维度，而现有基于经典统计模型的反事实结果估计方法在性能和泛化能力上存在局限。因此，本文旨在利用Transformer提出一种更强大的时空反事实结果估计框架。

研究方法: 本文提出了一种基于Transformer的时空反事实结果估计框架。在温和假设下，该框架内的估计器具有一致性和渐近正态性。通过仿真实验和真实数据实验验证了方法的有效性。

研究结果: 仿真实验表明，本文提出的估计器比基线方法具有更强的估计能力。真实数据实验揭示了冲突对哥伦比亚森林损失的因果效应，提供了有价值的结论。

研究结论: 本文提出的基于Transformer的时空反事实结果估计框架在性能和泛化能力上优于传统方法，为时空数据分析提供了新的工具。

中文摘要: 现实世界天然具有时间和空间维度，因此估计具有时空属性的反事实结果是一个关键问题。然而，现有方法基于经典统计模型，在性能和泛化能力上仍存在局限。本文提出了一种利用Transformer估计时空反事实结果的新框架，展现出更强的估计能力。在温和假设下，该框架内的估计器具有一致性和渐近正态性。为验证方法的有效性，我们进行了仿真实验和真实数据实验。仿真实验表明，本文的估计器比基线方法具有更强的估计能力。真实数据实验为冲突对哥伦比亚森林损失的因果效应提供了有价值的结论。源代码可在https://github.com/lihe-maxsize/DeppSTCI_Release_Version-master获取。

</details>
