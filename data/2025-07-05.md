<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 26]
- [cs.CV](#cs.CV) [Total: 83]
- [cs.AI](#cs.AI) [Total: 31]
- [econ.GN](#econ.GN) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.LG](#cs.LG) [Total: 21]
- [cs.LO](#cs.LO) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 3]
- [physics.chem-ph](#physics.chem-ph) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.OS](#cs.OS) [Total: 1]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.RO](#cs.RO) [Total: 4]
- [cs.IR](#cs.IR) [Total: 4]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.GR](#cs.GR) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2507.02088)
**中文标题：McBE：一个面向大语言模型的多任务中文偏见评估基准**

*Tian Lan,Xiangdong Su,Xu Liu,Ruirui Wang,Ke Chang,Jiang Li,Guanglai Gao*

主要分类: cs.CL

摘要简述: 本文提出了一个多任务中文偏见评估基准（McBE），包含4,077个偏见评估实例，覆盖12个单一偏见类别和82个子类别，并引入5个评估任务，以全面衡量大语言模型（LLMs）的偏见。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）在各类NLP任务中的应用增多，其内在偏见逐渐显现。然而，现有偏见评估数据集多集中于英语和北美文化，且其偏见类别不完全适用于其他文化。中文语言和文化背景的数据集稀缺，且通常仅支持单一评估任务，无法从多角度评估LLMs的偏见。

研究方法: 本文提出了McBE基准，包含4,077个偏见评估实例，覆盖12个单一偏见类别和82个子类别，并引入5个评估任务。此外，还对多个不同系列和参数规模的流行LLMs进行了评估。

研究结果: 评估结果显示，所有测试的LLMs均表现出不同程度的偏见。通过深入分析结果，本文为LLMs中的偏见提供了新的见解。

研究结论: McBE基准填补了中文偏见评估数据集的空白，提供了广泛的类别覆盖和内容多样性，能够全面衡量LLMs的偏见。

中文摘要: 随着大语言模型（LLMs）在各类NLP任务中的应用增多，其内在偏见逐渐显现。因此，衡量LLMs中的偏见对降低其伦理风险至关重要。然而，现有偏见评估数据集多集中于英语和北美文化，且其偏见类别不完全适用于其他文化。基于中文语言和文化的数据集稀缺。更重要的是，这些数据集通常仅支持单一评估任务，无法从多角度评估LLMs的偏见。为解决这些问题，我们提出了一个多任务中文偏见评估基准（McBE），包含4,077个偏见评估实例，覆盖12个单一偏见类别、82个子类别，并引入5个评估任务，提供了广泛的类别覆盖、内容多样性和衡量全面性。此外，我们还评估了多个不同系列和参数规模的流行LLMs。总体而言，这些LLMs均表现出不同程度的偏见。我们对结果进行了深入分析，为LLMs中的偏见提供了新的见解。

</details>


### [2] [Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization](https://arxiv.org/abs/2507.02145)
**中文标题：推理与否？对话摘要中推理型大语言模型的全面评估**

*Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira*

主要分类: cs.CL

摘要简述: 本文首次全面评估了推理型与非推理型大语言模型（LLM）在对话摘要任务中的表现，发现逐步推理并未显著提升摘要质量，反而可能导致冗长和不一致。


<details>
  <summary>详细信息</summary>
研究动机: 对话摘要在客户服务、会议分析等领域具有重要价值，但推理型LLM（如链式思维模型）在对话场景中的表现尚未被系统评估。本文旨在填补这一空白。

研究方法: 研究对比了推理型与非推理型LLM在通用、角色导向和查询导向三类对话摘要任务中的表现，覆盖多语言、多领域和不同摘要长度，并采用自动指标和人工评估相结合的方法。

研究结果: 结果显示，逐步推理并未显著提升摘要质量，推理型LLM易产生冗长、事实不一致和不够简洁的摘要，表现不及非推理型模型。

研究结论: 当前推理型LLM在复杂对话摘要中存在局限性，需针对性优化模型和评估策略。

中文摘要: 对话摘要是一项具有重要实际价值的挑战性任务，涉及客户服务、会议分析和对话式AI等领域。尽管大语言模型（LLM）在摘要任务中取得了显著进展，但逐步推理架构（如链式思维模型）在需要同时实现抽象性和简洁性的对话场景中的表现尚未被探索。本研究首次对最先进的推理型与非推理型LLM在通用、角色导向和查询导向三类对话摘要任务中进行了全面系统的评估。研究涵盖多种语言、领域和摘要长度，并利用强基准数据集（如SAMSum、DialogSum等）和结合LLM自动指标与人工标准的评估协议。与其他推理密集型任务不同，我们的结果表明逐步推理并未持续提升对话摘要质量，推理型LLM反而易产生冗长、事实不一致和不够简洁的摘要。通过场景分析和案例研究，我们进一步明确了逐步推理在复杂对话摘要中可能失效的原因。本研究揭示了当前推理型LLM的局限性，并强调了针对实际对话摘要任务优化模型和评估策略的必要性。

</details>


### [3] [Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer](https://arxiv.org/abs/2507.02199)
**中文标题：潜在思维链？解码深度循环Transformer**

*Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu*

主要分类: cs.CL

摘要简述: 本文研究了深度循环Transformer模型Huginn-3.5B是否能够实现潜在思维链（CoT）推理。通过多种探测技术，发现模型内部行为在算术任务中表现出有限的潜在CoT证据，且不同循环块的探测结果不一致。增加循环深度仅带来边际收益，远不及显式推理步骤的模型。


<details>
  <summary>详细信息</summary>
研究动机: 思维链（CoT）推理使Transformer模型在复杂数学和多步规划任务中表现出色，但其推理步骤通常以自然语言形式外部化，牺牲了效率。为了探索潜在空间中的推理能力，本文研究了深度循环Transformer是否能够实现潜在CoT。

研究方法: 使用Huginn-3.5B模型，通过Logit Lens和Coda Lens等探测技术，分析其在算术任务中的内部行为，追踪最终和中间结果令牌的排名轨迹，并评估不同循环块的探测一致性。

研究结果: 研究发现，模型内部行为显示出有限的潜在CoT证据，且不同循环块的隐藏状态可解释性差异显著。增加循环深度仅带来边际性能提升，远不及显式推理步骤的模型。

研究结论: 深度循环Transformer在潜在CoT方面的表现有限，隐藏状态的可解释性依赖于层索引和解码方法。显式推理步骤的模型仍具有显著优势。

中文摘要: 思维链（CoT）推理使基于Transformer的语言模型在复杂数学和多步规划任务中表现出色。然而，在标准的仅解码器架构中，这些推理步骤以自然语言形式外部化，虽提高了可解释性，但牺牲了效率。为了捕捉难以用语言表达的推理过程，许多研究探索了旨在将推理内部化于潜在空间的循环架构，可能支持潜在CoT。本文研究了Huginn-3.5B（一种在推理时重复使用层而不增加参数数量的深度循环Transformer）中是否出现此类推理结构。通过Logit Lens和Coda Lens等探测技术，我们分析了模型在算术任务中的内部行为。结果表明，通过追踪最终和中间结果令牌的排名轨迹，仅发现有限的潜在CoT证据。此外，不同循环块的探测结果存在显著不一致性，隐藏状态的可解释性高度依赖于层索引和解码方法。最后，实验表明增加循环深度仅带来边际收益，远不及显式推理步骤的模型。代码发布于https://github.com/wenquanlu/huginn-latent-cot。

</details>


### [4] [GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons](https://arxiv.org/abs/2507.02221)
**中文标题：GDC Cohort Copilot：基于基因组数据共享的AI辅助队列构建工具**

*Steven Song,Anirudh Subramanyam,Zhenyu Zhang,Aarti Venkat,Robert L. Grossman*

主要分类: cs.CL

摘要简述: GDC Cohort Copilot是一款开源工具，通过自然语言描述自动生成GDC队列过滤器，帮助用户快速构建癌症基因组学队列，并优于GPT-4o的表现。


<details>
  <summary>详细信息</summary>
研究动机: GDC（基因组数据共享）提供了高质量的癌症基因组学数据，但用户（尤其是新手）在通过图形化队列构建工具创建复杂队列时，可能难以从数百个字段中找到特定描述符。自然语言描述可能更易于用户表达需求。

研究方法: 开发了GDC Cohort Copilot工具，利用大型语言模型（LLMs）将用户的自然语言描述自动转换为GDC队列过滤器，并提供交互式界面供用户进一步调整。

研究结果: GDC Cohort Copilot的开源本地模型在生成GDC队列时表现优于GPT-4o，且工具已提供Docker镜像和源代码。

研究结论: GDC Cohort Copilot通过自然语言交互简化了队列构建流程，提升了用户体验，并为开源社区提供了实用工具。

中文摘要: 动机：基因组数据共享（GDC）通过统一的平台提供了高质量的癌症基因组学数据，用户可以通过图形化队列构建工具创建复杂队列。然而，用户（尤其是新手）可能难以从数百个字段中找到特定描述符，而自然语言描述可能更易于表达需求。

结果：我们推出了GDC Cohort Copilot，这是一款开源工具，能够根据用户的自然语言描述自动生成GDC队列过滤器，并将队列导回GDC进行进一步分析。交互式界面允许用户进一步调整生成的队列。我们开发并评估了多种大型语言模型（LLMs），结果表明，本地部署的开源GDC Cohort LLM在生成GDC队列时表现优于GPT-4o。

可用性与实现：GDC Cohort Copilot的独立Docker镜像可在https://quay.io/repository/cdis/gdc-cohort-copilot获取，源代码位于https://github.com/uc-cdis/gdc-cohort-copilot，GDC Cohort LLM的权重文件可在https://huggingface.co/uc-ctds下载。

</details>


### [5] [MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent](https://arxiv.org/abs/2507.02259)
**中文标题：MemAgent：基于多对话强化学习的记忆代理重塑长上下文LLM**

*Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou*

主要分类: cs.CL

摘要简述: MemAgent通过多对话强化学习优化长文本处理，能够在8K上下文训练下扩展到3.5M任务，性能损失低于5%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有长度外推、高效注意力和内存模块的改进，但在长文本处理中，如何在无限长文档中保持线性复杂度且性能不下降仍是终极挑战。

研究方法: 提出MemAgent，采用分段读取文本和覆盖式更新内存的策略，并扩展DAPO算法以支持多对话生成训练。

研究结果: MemAgent在32K文本训练下可外推到3.5M QA任务，性能损失低于5%，并在512K RULER测试中达到95%+。

研究结论: MemAgent展示了卓越的长上下文处理能力，为长文本任务提供了一种高效的端到端解决方案。

中文摘要: 尽管通过长度外推、高效注意力和内存模块有所改进，但在长文本处理中，如何在无限长文档中以线性复杂度处理且性能不下降仍是终极挑战。我们直接以端到端方式优化长文本任务，并引入了一种新颖的代理工作流程MemAgent，它分段读取文本并通过覆盖策略更新内存。我们扩展了DAPO算法以支持独立上下文的多对话生成训练。MemAgent展示了卓越的长上下文能力，能够在8K上下文训练下外推到3.5M QA任务，性能损失低于5%，并在512K RULER测试中达到95%+。

</details>


### [6] [DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning](https://arxiv.org/abs/2507.02302)
**中文标题：DoMIX：一种利用领域知识进行高效微调的框架**

*Dohoon Kim,Donghun Kang,Taesup Moon*

主要分类: cs.CL

摘要简述: DoMIX是一种高效框架，通过LoRA模块解决现有领域自适应预训练（DAP）方法的高计算成本、数据顺序敏感性和单一模型问题，提供并行且鲁棒的领域适应预训练。


<details>
  <summary>详细信息</summary>
研究动机: 现有持续DAP方法存在高计算成本、对增量数据顺序敏感以及提供单一通用模型的问题，无法满足领域自适应预训练的需求。DoMIX旨在解决这些问题。

研究方法: DoMIX利用LoRA模块（一种参数高效微调方法），实现高效且并行的领域自适应预训练，同时对领域顺序鲁棒，并能针对特定任务提供定制化预训练模型。

研究结果: DoMIX在DAP和标准LLM微调场景中均表现出色，能够高效利用累积知识，提供任务特定的预训练模型。

研究结论: DoMIX通过LoRA模块解决了现有DAP方法的局限性，为领域自适应预训练和LLM微调提供了高效且灵活的解决方案。

中文摘要: 领域自适应预训练（DAP）因其在微调预训练模型中的有效性而受到关注。在此基础上，持续DAP被探索用于开发能够逐步整合不同领域数据集的预训练模型。然而，现有持续DAP方法存在以下局限性：（1）训练过程中计算成本和GPU内存使用较高；（2）对增量数据顺序敏感；（3）为所有终端任务提供单一的通用模型，这与DAP的本质相矛盾。本文提出DoMIX，一种通过利用LoRA模块（一种代表性的参数高效微调方法）解决这些挑战的新方法。我们的方法实现了高效且并行的领域自适应预训练，对领域顺序鲁棒，并能有效利用累积知识为特定任务提供定制化的预训练模型。我们还展示了该方法可以扩展到DAP设置之外的标准LLM微调场景。代码可在https://github.com/dohoonkim-ai/DoMIX获取。

</details>


### [7] [Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models](https://arxiv.org/abs/2507.02357)
**中文标题：Coling-UniA在SciVQA 2025的任务：基于少样本检索和置信度集成的多模态大语言模型**

*Christian Jaumann,Annemarie Friedrich,Rainer Lienhart*

主要分类: cs.CL

摘要简述: 本文介绍了参加SciVQA 2025共享任务的系统，结合多模态大语言模型和少样本检索策略，根据图像和问题类型选择模型和设置，并通过模型置信度选择答案，最终在盲测数据中排名第三。


<details>
  <summary>详细信息</summary>
研究动机: SciVQA 2025共享任务旨在解决科学视觉问答问题，本文通过结合多模态大语言模型和少样本检索策略，提升模型在复杂科学问题中的表现。

研究方法: 系统采用两种多模态大语言模型的集成方法，并结合多种少样本检索策略。根据图像和问题类型选择模型和设置，并通过模型置信度筛选答案。

研究结果: 在盲测数据中，系统在七支队伍中排名第三，平均F1得分为85.12（基于ROUGE-1、ROUGE-L和BERTS指标）。

研究结论: 本文提出的集成方法和少样本检索策略在科学视觉问答任务中表现良好，代码已公开。

中文摘要: 本文介绍了我们为SciVQA 2025共享任务设计的科学视觉问答系统。该系统集成了两种多模态大语言模型和多种少样本检索策略，根据图像和问题类型选择模型和设置，并通过模型置信度筛选答案。在盲测数据中，系统在七支队伍中排名第三，平均F1得分为85.12（基于ROUGE-1、ROUGE-L和BERTS指标）。我们的代码已公开。

</details>


### [8] [QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers](https://arxiv.org/abs/2507.02364)
**中文标题：QFFN-BERT：混合量子-经典Transformer中深度、性能与数据效率的实证研究**

*Pilsung Kang*

主要分类: cs.CL

摘要简述: 本文提出QFFN-BERT，一种混合量子-经典Transformer模型，通过用参数化量子电路（PQC）替换BERT变体中的前馈网络（FFN）模块，显著减少参数数量并提升性能。实验表明，该模型在完全数据设置和少样本学习中均优于经典模型。


<details>
  <summary>详细信息</summary>
研究动机: 标准Transformer编码器块中，FFN模块占参数总量的三分之二。为减少参数并提升表达力，本文探索将PQC引入FFN模块，而非此前研究中的自注意力模块。

研究方法: 设计了一种混合量子-经典Transformer模型QFFN-BERT，用PQC替换BERT的FFN模块。PQC采用残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略，确保训练稳定性和高表达力。

研究结果: 实验表明，QFFN-BERT在SST-2和DBpedia基准测试中达到基线模型102.0%的准确率，同时减少FFN参数99%以上。在少样本学习中，模型表现一致优于经典模型。

研究结论: PQC可作为经典FFN的高效替代方案，结合深度学习原则设计时，能显著减少参数并提升性能。

中文摘要: 参数化量子电路（PQC）近年来成为增强神经网络表达力的潜在组件。本文提出QFFN-BERT，一种混合量子-经典Transformer模型，其中紧凑BERT变体的前馈网络（FFN）模块被PQC层替代。这一设计源于FFN在标准Transformer编码器块中占参数总量的三分之二。此前研究主要将PQC集成到自注意力模块，而本文聚焦FFN，系统研究PQC深度、表达力与可训练性之间的权衡。最终PQC架构包含残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略，以确保训练稳定性和高表达力。在SST-2和DBpedia基准测试中，实验表明两点关键发现：一是精心配置的QFFN-BERT在完全数据设置中达到基线模型102.0%的准确率，超越经典模型，同时减少FFN参数99%以上；二是该模型在少样本学习中表现一致且具有竞争力，证实其数据效率潜力。这些结果得到对未优化PQC的消融实验支持，表明PQC可作为经典FFN的强大且参数高效的替代方案，前提是与深度学习原则协同设计。

</details>


### [9] [Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection](https://arxiv.org/abs/2507.02378)
**中文标题：基于分布一致性和多样性感知的高效代码大语言模型训练数据选择方法**

*Weijie Lyu,Sheng-Jun Huang,Xuan Xia*

主要分类: cs.CL

摘要简述: 本文提出一种基于分布一致性和多样性感知的数据选择方法，显著提升代码大语言模型的训练效率和性能。实验证明，仅用10K样本即可超越92K全样本基线，性能提升2.4%（HumanEval）和2.3%（MBPP）。


<details>
  <summary>详细信息</summary>
研究动机: 当前代码大语言模型的训练主要依赖大量数据，但忽视了数据质量，导致训练效率低下。本文旨在通过优化数据选择方法，提升训练效率和模型性能。

研究方法: 采用参数化模型进行代码数据选择，确保所选子集具有分布一致性和多样性，从而保证数据质量。

研究结果: 实验结果显示，仅使用10K样本，性能提升2.4%（HumanEval）和2.3%（MBPP），优于其他采样方法。

研究结论: 该方法在显著降低计算成本的同时，有效提升了模型性能，为代码大语言模型的高效训练提供了新思路。

中文摘要: 近年来，大语言模型（LLMs）的进步显著提升了代码生成和程序理解能力，推动了软件工程的发展。当前方法主要通过利用大量数据提升模型性能，但过度关注数据量而忽视数据质量，降低了训练效率。为此，我们提出一种基于参数化模型的代码数据选择方法，旨在提升训练效率和模型性能。该方法通过优化参数化模型，确保所选子集具有分布一致性和多样性，从而保证数据质量。实验结果表明，仅使用10K样本，我们的方法在HumanEval和MBPP上分别实现了2.4%和2.3%的性能提升，优于92K全样本基线，同时在性能与效率上均超越其他采样方法。这表明我们的方法在显著降低计算成本的同时，有效提升了模型性能。

</details>


### [10] [Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability](https://arxiv.org/abs/2507.02407)
**中文标题：跨领域数据集下的阿坎语ASR模型基准测试：性能、可扩展性与适应性的比较评估**

*Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame*

主要分类: cs.CL

摘要简述: 本研究评估了七种基于Transformer架构的阿坎语ASR模型（如Whisper和Wav2Vec2）在四种不同领域数据集上的表现，发现模型性能高度依赖训练领域，且不同架构在错误行为上存在显著差异。


<details>
  <summary>详细信息</summary>
研究动机: 现有ASR研究多基于单一领域数据集评估模型，缺乏对跨领域泛化能力的考察。本研究旨在填补这一空白，评估阿坎语ASR模型在多样化语音场景中的表现。

研究方法: 研究使用四种阿坎语语音数据集（涵盖文化相关图像描述、非正式对话、圣经诵读和金融对话），对七种基于Transformer的ASR模型进行基准测试，比较其词错误率和字符错误率。

研究结果: 结果显示模型性能高度依赖训练领域，跨领域时准确率显著下降。Whisper模型生成更流畅但可能误导的错误转录，而Wav2Vec2模型输出更明显但难以解释。

研究结论: 研究强调在低资源语言应用中需考虑架构选择（流畅性与透明性的权衡），并建议采用针对性领域适应技术、自适应路由策略和多语言训练框架。

中文摘要: 现有大多数自动语音识别（ASR）研究使用领域内数据集评估模型，但很少考察其在多样化语音场景中的泛化能力。本研究通过基准测试七种基于Transformer架构（如Whisper和Wav2Vec2）的阿坎语ASR模型，填补了这一空白。这些模型在四种阿坎语语音语料库上进行了评估，涵盖文化相关图像描述、非正式对话、圣经诵读和金融对话等领域。通过比较词错误率和字符错误率，研究发现模型性能高度依赖领域，仅在训练领域内表现最优，而在不匹配场景中准确率显著下降。此外，Whisper和Wav2Vec2架构在错误行为上表现出明显差异：微调后的Whisper模型生成更流畅但可能误导的错误转录，而Wav2Vec2模型在遇到陌生输入时产生更明显但难以解释的输出。这种ASR错误在可读性与透明性之间的权衡，在选择低资源语言（LRL）应用的架构时需加以考虑。研究结果强调了针对阿坎语及其他低资源语言开发针对性领域适应技术、自适应路由策略和多语言训练框架的必要性。

</details>


### [11] [A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages](https://arxiv.org/abs/2507.02428)
**中文标题：低资源语言中障碍语音社区驱动数据收集的实用指南**

*Sumaya Ahmed Salihs,Isaac Wiafe,Jamal-Deen Abdulai,Elikem Doe Atsakpo,Gifty Ayoka,Richard Cave,Akon Obu Ekpezu,Catherine Holloway,Katrin Tomanek,Fiifi Baffoe Payin Winful*

主要分类: cs.CL

摘要简述: 本研究提出了一种收集语音样本的方法，用于构建低资源语言中障碍语音的自动语音识别（ASR）模型，旨在通过开发“食谱”式最佳实践和培训，推动社区驱动的数据收集和ASR模型构建。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机是民主化ASR技术和数据收集，特别是为低资源语言中的障碍语音提供支持，以满足语音障碍人群的独特需求。

研究方法: 研究方法包括开发“食谱”式指南，培训社区成员收集数据，并在加纳广泛使用的阿坎语中创建首个开源障碍语音数据集。

研究结果: 研究结果包括公开可用的数据集、食谱指南和开源工具，以及针对阿坎语障碍语音的ASR模型初步调优结果。

研究结论: 研究结论表明，社区驱动的数据收集和开源工具可以促进包容性ASR技术的发展，为语音障碍人群提供定制化支持。

中文摘要: 本研究提出了一种收集语音样本的方法，用于构建低资源语言中障碍语音的自动语音识别（ASR）模型。其目标是通过开发“食谱”式最佳实践和培训，推动社区驱动的数据收集和ASR模型构建，从而实现ASR技术的民主化。作为概念验证，本研究整理了首个阿坎语（加纳广泛使用的土著语言）的开源障碍语音数据集。研究参与者包括来自不同背景的语音障碍人士。最终的数据集、食谱指南和开源工具均已公开，以帮助研究人员和从业者开发针对语音障碍人群独特需求的包容性ASR技术。此外，本研究还展示了针对阿坎语障碍语音的开源ASR模型初步调优结果。

</details>


### [12] [IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders](https://arxiv.org/abs/2507.02506)
**中文标题：IndianBailJudgments-1200：一个用于印度保释判决法律NLP的多属性数据集**

*Sneha Deshmukh,Prathmesh Kamble*

主要分类: cs.CL

摘要简述: 本文介绍了IndianBailJudgments-1200数据集，这是一个包含1200份印度法院保释判决的多属性数据集，支持法律NLP任务如结果预测和公平性分析。


<details>
  <summary>详细信息</summary>
研究动机: 由于印度等地区缺乏结构化数据集，法律NLP发展受限。本文旨在填补这一空白，提供首个专注于印度保释法学的公开数据集。

研究方法: 通过使用经过提示工程优化的GPT-4o流水线生成标注，并验证一致性，构建了包含20多个属性的数据集。

研究结果: 数据集包含1200份判决，标注了保释结果、IPC条款、犯罪类型和法律推理等属性，支持多种法律NLP任务。

研究结论: IndianBailJudgments-1200为印度法律NLP研究提供了重要资源，填补了公开数据集的空白。

中文摘要: 由于缺乏结构化数据集，印度等地区的法律NLP发展不足。我们推出了IndianBailJudgments-1200，这是一个新的基准数据集，包含1200份印度法院关于保释判决的裁决，标注了20多个属性，包括保释结果、IPC条款、犯罪类型和法律推理。标注通过经过提示工程优化的GPT-4o流水线生成并验证一致性。这一资源支持多种法律NLP任务，如结果预测、摘要生成和公平性分析，是首个公开的专注于印度保释法学的数据集。

</details>


### [13] [WebSailor: Navigating Super-human Reasoning for Web Agent](https://arxiv.org/abs/2507.02592)
**中文标题：WebSailor：为网络代理导航超人类推理**

*Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou*

主要分类: cs.CL

摘要简述: WebSailor是一种后训练方法，旨在提升开源模型在复杂信息搜索任务中的超人类推理能力，通过生成高不确定性任务和高效训练算法，显著缩小与专有代理的性能差距。


<details>
  <summary>详细信息</summary>
研究动机: 当前开源模型在复杂信息搜索任务中表现不佳，无法像专有代理（如DeepResearch）那样处理极端不确定性。本文旨在通过WebSailor方法填补这一能力差距。

研究方法: WebSailor通过结构化采样和信息模糊化生成高不确定性任务，采用RFT冷启动和高效的代理强化学习算法DUPO进行训练，形成完整的后训练流程。

研究结果: WebSailor在复杂信息搜索任务中显著优于所有开源代理，性能接近专有代理，有效缩小了能力差距。

研究结论: WebSailor通过系统化的后训练方法，成功提升了开源模型在复杂信息搜索任务中的推理能力，为未来研究提供了重要方向。

中文摘要: 超越人类认知限制是LLM训练的关键前沿。专有代理系统（如DeepResearch）在BrowseComp等极端复杂的信息搜索基准上展现了超人类能力，这是开源模型此前无法实现的。我们认为其成功依赖于开源模型所缺乏的复杂推理模式：在庞大信息环境中系统性降低极端不确定性的能力。基于这一洞察，我们提出了WebSailor，一种完整的后训练方法，旨在培养这一关键能力。我们的方法通过结构化采样和信息模糊化生成新颖的高不确定性任务，采用RFT冷启动和高效的代理强化学习算法DUPO进行训练。通过这一集成流程，WebSailor在复杂信息搜索任务中显著优于所有开源代理，性能接近专有代理，缩小了能力差距。

</details>


### [14] [Revisiting Active Learning under (Human) Label Variation](https://arxiv.org/abs/2507.02593)
**中文标题：重新审视（人类）标注差异下的主动学习**

*Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher*

主要分类: cs.CL

摘要简述: 本文探讨了在人类标注差异（HLV）背景下重新审视主动学习（AL）的必要性，提出了一种将HLV纳入AL循环的概念框架，并讨论了大型语言模型（LLM）作为标注者的整合。


<details>
  <summary>详细信息</summary>
研究动机: 高质量标注数据的获取是监督学习中的瓶颈，而人类标注差异（HLV）常被忽视。现有主动学习方法简化了标注假设，未充分考虑HLV的信号价值。本文旨在填补这一空白。

研究方法: 通过分解标注差异为信号（如HLV）和噪声（如标注错误），提出一个概念框架，将HLV融入AL循环的实例选择、标注者选择和标签表示中，并探讨LLM作为标注者的潜力。

研究结果: 研究强调了HLV的重要性，提出了一个更贴近实际标注复杂性的AL框架，为未来HLV感知的AL研究奠定了基础。

研究结论: 本文为结合HLV的主动学习提供了概念基础，推动了更贴近现实标注场景的AL方法发展。

中文摘要: 高质量标注数据的获取仍然是应用监督学习中的限制因素。尽管标注差异（LV）（即同一实例的不同标签）很常见，尤其是在自然语言处理中，但标注框架通常仍基于单一真实标签的假设。这忽视了人类标注差异（HLV）作为一种信息信号的存在。同样，主动学习（AL）作为一种优化有限标注预算的流行方法，通常依赖于几种简化假设之一，而这些假设在承认HLV时很少成立。本文探讨了关于真实性和标签性质的基本假设，强调了将观察到的LV分解为信号（如HLV）和噪声（如标注错误）的必要性。我们调查了AL和（H）LV社区如何解决（或忽视）这些区别，并提出了一个将HLV融入AL循环的概念框架，包括实例选择、标注者选择和标签表示。我们还讨论了大型语言模型（LLM）作为标注者的整合。我们的工作旨在为HLV感知的主动学习奠定概念基础，更好地反映现实标注的复杂性。

</details>


### [15] [MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion](https://arxiv.org/abs/2507.02595)
**中文标题：MPF：通过多视角融合对齐和减少部署后语言模型的偏见**

*Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama*

主要分类: cs.CL

摘要简述: MPF是一种新颖的后训练对齐框架，用于通过多视角融合减少大型语言模型（LLM）的偏见，无需大量提示工程或微调。


<details>
  <summary>详细信息</summary>
研究动机: 随着对减少语言模型偏见的迫切需求，MPF旨在提供一种可扩展且可解释的方法，用于对齐和缓解LLM的偏见，同时兼容已部署的模型。

研究方法: MPF基于SAGED流程，通过多视角生成揭示和调整LLM输出中的偏见，将其分解为可解释的视角组件，并通过加权采样和平衡响应来引导生成。

研究结果: 实验表明，MPF能够将LLM的情感分布与反事实基线（绝对平等）和HR基线（偏向顶尖大学）对齐，显著减少KL散度和校准误差，并能泛化到未见问题。

研究结论: MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，适用于已部署的LLM，且无需大量提示工程或微调。

中文摘要: 多视角融合（MPF）是一种新颖的后训练对齐框架，旨在满足减少语言模型偏见的迫切需求。基于SAGED流程（一种自动构建偏见基准和提取可解释基线分布的系统），MPF利用多视角生成揭示并调整LLM输出中的偏见，使其与细腻、类人的基线对齐。通过将基线（如人力资源专业人士的情感分布）分解为可解释的视角组件，MPF通过加权采样和平衡响应来引导生成。实验表明，MPF能够将LLM的情感分布与反事实基线（绝对平等）和HR基线（偏向顶尖大学）对齐，显著减少KL散度和校准误差，并能泛化到未见问题。这表明MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，兼容已部署的LLM，且无需大量提示工程或微调。

</details>


### [16] [Exploring Gender Bias Beyond Occupational Titles](https://arxiv.org/abs/2507.02679)
**中文标题：探索职业称谓之外的性别偏见**

*Ahmed Sabir,Rajesh Sharama*

主要分类: cs.CL

摘要简述: 本研究探讨了性别与上下文偏见的关联，提出新数据集GenderLexicon和评估框架，证实了职业刻板印象之外的性别偏见存在。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于揭示性别偏见不仅存在于职业称谓中，还隐含于动作动词、宾语名词等上下文元素中，需系统性评估和解释。

研究方法: 方法包括构建GenderLexicon数据集，开发可量化上下文偏见及其性别偏见的框架，并通过五个多样化数据集验证模型有效性。

研究结果: 研究结果表明，模型能通过评分解释性别偏见，且在包括日语数据集在内的多个数据集中验证了职业外性别偏见的存在。

研究结论: 结论指出，性别偏见广泛存在于语言上下文中，新框架为偏见解释提供了有效工具，未来可扩展至更多语言和文化背景。

中文摘要: 本研究探讨了性别与上下文偏见的关联，重点关注动作动词、宾语名词及职业称谓。我们提出了新数据集GenderLexicon和一个能评估上下文偏见及其性别偏见的框架。该模型通过评分解释偏见，提升了性别偏见的可解释性。研究证实了职业刻板印象之外的性别偏见存在。为验证方法有效性，我们在五个多样化数据集（包括日语数据集）上进行了评估。

</details>


### [17] [Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers](https://arxiv.org/abs/2507.02694)
**中文标题：大型语言模型能否识别科学研究的局限性？对AI研究论文的系统性评估**

*Zhijian Xu,Yilun Zhao,Manasi Patwardhan,Lovekesh Vig,Arman Cohan*

主要分类: cs.CL

摘要简述: 本文探讨大型语言模型（LLMs）能否识别科学研究的局限性，并提出LimitGen基准，用于评估LLMs在辅助同行评审中的作用。通过合成和真实数据集，结合文献检索，提升LLMs识别局限性的能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着科学出版物数量的激增，同行评审面临巨大压力。尽管LLMs在科学任务中表现出潜力，但其在识别论文局限性方面的能力尚未充分研究。本文旨在填补这一空白，为LLMs在同行评审中的应用提供支持。

研究方法: 首先提出AI领域科学研究局限性的分类法，并基于此构建LimitGen基准，包括合成数据集LimitGen-Syn和真实数据集LimitGen-Human。通过结合文献检索，增强LLMs识别局限性的能力。

研究结果: LimitGen基准有效评估了LLMs在识别论文局限性方面的表现。结合文献检索的LLMs能够生成更具体和建设性的反馈，显著提升了局限性识别的能力。

研究结论: LLMs在识别科学研究局限性方面具有潜力，LimitGen基准为未来研究提供了重要工具。结合文献检索的方法进一步提升了LLMs的实用性，有望辅助人类同行评审。

中文摘要: 同行评审是科学研究的基石，但日益增长的出版物数量加剧了这一专业知识密集型过程的挑战。尽管大型语言模型（LLMs）在多项科学任务中展现出潜力，但其在辅助同行评审（尤其是识别论文局限性）方面的潜力尚未充分研究。我们首先提出了一个针对AI领域的科学研究局限性分类法。基于此分类法，我们提出了LimitGen，这是首个用于评估LLMs在支持早期反馈和补充人类同行评审方面能力的综合性基准。该基准包含两个子集：LimitGen-Syn（通过高质量论文的受控扰动精心合成的数据集）和LimitGen-Human（真实人类撰写的局限性集合）。为提升LLM系统识别局限性的能力，我们为其增加了文献检索功能，这对于将局限性识别建立在先前科学发现的基础上至关重要。我们的方法增强了LLM系统在研究论文中生成局限性的能力，使其能够提供更具体和建设性的反馈。

</details>


### [18] [Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens](https://arxiv.org/abs/2507.02744)
**中文标题：通过最小可产生差异（JPD）测量元音发音空间的粒度**

*Peter Viechnicki*

主要分类: cs.CL

摘要简述: 本研究通过测量‘最小可产生差异’（JPD）来探究人类元音发音控制的精确度，发现JPD在F1 X F2空间中为14至51 mels，为元音系统的结构和语音生成理论提供了新见解。


<details>
  <summary>详细信息</summary>
研究动机: 过去研究表明，人类元音发音的复杂协调动作受听觉空间区域的控制机制影响，但其控制的精确度尚不明确。本研究旨在通过测量‘最小可产生差异’（JPD）来填补这一空白。

研究方法: 研究采用元音模仿范式，测量两组英语使用者在发前元音时的JPD，即两个元音刺激在听觉空间中必须相隔多远才能产生可靠的不同模仿。

研究结果: 研究发现JPD在F1 X F2空间中为14至51 mels，这一结果为语音生成理论和元音系统的可能结构提供了量化依据。

研究结论: JPD的测量为语音生成的情景理论提供了支持，并为人类元音系统的结构和可能的元音音素数量设定了理论下限。

中文摘要: 过去几十年的研究表明，人类元音发音的复杂协调动作部分受听觉空间区域的控制机制调控。然而，这种控制在亚音位水平的精确度尚不清楚。本研究通过探究两个元音刺激在听觉空间中必须相隔多远才能产生可靠的不同模仿（称为‘最小可产生差异’，JPD），填补了这一空白。研究采用元音模仿范式，首次测量了两组英语使用者在发前元音时的JPD。结果显示，JPD在F1 X F2空间中为14至51 mels。这一发现对语音生成的情景理论具有重要意义，并为人类元音系统的可能结构提供了理论下限，从而解释了观察到的元音音素数量和模式的趋势。

</details>


### [19] [Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs](https://arxiv.org/abs/2507.02778)
**中文标题：自我纠正基准：揭示并解决LLM中的自我纠正盲区**

*Ken Tsui*

主要分类: cs.CL

摘要简述: 大型语言模型（LLM）在自我纠正方面存在盲区，无法纠正自身输出的错误。本文通过引入Self-Correction Bench框架，发现模型的盲区率平均为64.5%，并提出简单干预（如添加“Wait”）可显著减少盲区。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM具有变革性，但其在自我纠正方面存在系统性盲区，无法纠正自身输出的错误。这种局限性可能与训练数据中缺乏错误纠正序列有关。本文旨在揭示这一现象并提出改进方法。

研究方法: 本文提出Self-Correction Bench框架，通过三个复杂度级别的控制性错误注入，系统地测量LLM的自我纠正盲区。测试了14种模型，并分析了训练数据组成的影响。

研究结果: 研究发现，LLM的平均盲区率为64.5%，且盲区与训练数据中缺乏错误纠正序列相关。简单干预（如添加“Wait”）可将盲区减少89.3%。

研究结论: 本文揭示了当前LLM在自我纠正方面的关键局限性，并提出了通过简单干预激活其潜在能力的可能性，为提高LLM的可靠性和可信度提供了方向。

中文摘要: 尽管大型语言模型（LLM）具有变革性，但它们仍会犯错并可能探索无效的推理路径。自我纠正是可信赖LLM（尤其是自回归LLM）的重要能力。虽然LLM可以识别用户输入中的错误，但它们表现出系统性的“自我纠正盲区”——无法纠正自身输出的相同错误。为系统研究这一现象，我们引入了Self-Correction Bench框架，通过三个复杂度级别的控制性错误注入测量这一现象。测试14种模型后，我们发现平均盲区率为64.5%。多项证据表明，这一局限性与训练数据组成有关：人类训练演示主要展示无错误的响应，而非错误纠正序列，这与通过结果反馈学习错误纠正的RL训练模型不同。值得注意的是，仅添加“Wait”即可将盲区减少89.3%，表明这种能力存在但需要激活。我们的工作揭示了当前LLM的关键局限性，并为其可靠性和可信度的提升提供了潜在途径。

</details>


### [20] [Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models](https://arxiv.org/abs/2507.02799)
**中文标题：推理是否足够？探究推理语言模型时代的偏见问题**

*Riccardo Cantini,Nicola Gabriele,Alessio Orsino,Domenico Talia*

主要分类: cs.CL

摘要简述: 研究发现，具备推理能力的语言模型（RLMs）在对抗社会偏见时表现更脆弱，推理机制可能无意中强化刻板印象。


<details>
  <summary>详细信息</summary>
研究动机: 推理语言模型（RLMs）因其多步推理能力受到关注，但其对社会偏见的鲁棒性尚不明确。本文旨在探究推理能力对模型公平性和安全性的影响。

研究方法: 利用CLEAR-Bias基准评估RLMs，采用LLM-as-a-judge方法进行自动化安全评分，并通过越狱技术测试内置安全机制的强度。研究聚焦推理能力对偏见诱导的影响。

研究结果: 结果表明，具备推理能力的模型（如CoT提示或微调推理轨迹）比无推理机制的模型更易受偏见诱导。推理模型在安全性上略优于CoT提示模型，但后者易受故事化提示或虚构角色的攻击。

研究结论: 推理能力未必提升模型鲁棒性，反而可能强化偏见。需开发更具偏见意识的推理设计方法。

中文摘要: 推理语言模型（RLMs）因其通过链式思维（CoT）提示或微调推理轨迹完成复杂多步推理任务的能力而受到关注。尽管这些能力有望提高可靠性，但其对社会偏见鲁棒性的影响尚不明确。本研究利用最初为大型语言模型（LLMs）设计的CLEAR-Bias基准，探究RLMs对偏见诱导的对抗鲁棒性。我们系统评估了最先进的RLMs，采用LLM-as-a-judge方法进行自动化安全评分，并利用越狱技术评估内置安全机制的强度。研究回答了三个关键问题：（i）推理能力的引入如何影响模型的公平性和鲁棒性；（ii）为推理微调的模型是否比依赖CoT提示的模型更安全；（iii）针对偏见诱导的越狱攻击成功率如何随推理机制变化。结果表明，推理能力与偏见安全性之间存在微妙关系。令人惊讶的是，具备显式推理的模型（无论是通过CoT提示还是微调推理轨迹）通常比无此类机制的基准模型更易受偏见诱导，表明推理可能无意中为刻板印象强化开辟新途径。具备推理能力的模型比依赖CoT提示的模型稍安全，后者尤其易受通过故事化提示、虚构角色或奖励塑造指令的上下文重构攻击。这些结果挑战了推理固有提升鲁棒性的假设，并强调需要更具偏见意识的推理设计方法。

</details>


### [21] [Multimodal Mathematical Reasoning with Diverse Solving Perspective](https://arxiv.org/abs/2507.02804)
**中文标题：多模态数学推理中的多样化解题视角**

*Wenhao Shi,Zhiqiang Hu,Yi Bin,Yang Yang,See-Kiong Ng,Heng Tao Shen*

主要分类: cs.CL

摘要简述: 本文提出MathV-DP数据集和Qwen-VL-DP模型，通过多样化解题视角和强化学习提升多模态数学推理能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型（MLLMs）在数学推理中依赖单一图像-文本对和单解监督，忽略了多样化的解题视角和内部反思。本文旨在通过多样化解题轨迹和强化学习提升模型性能。

研究方法: 提出MathV-DP数据集，包含多样化解题轨迹；基于Qwen-VL构建Qwen-VL-DP模型，通过监督学习和基于规则的强化学习（GRPO）优化，结合正确性判别和多样性奖励函数。

研究结果: 在MathVista的minitest和Math-V基准测试中，Qwen-VL-DP在准确性和生成多样性上显著优于现有MLLMs。

研究结论: 多样化解题视角和反思性推理对多模态数学推理至关重要，Qwen-VL-DP为未来研究提供了新方向。

中文摘要: 近年来，大规模强化学习（RL）显著提升了大型语言模型（LLMs）在数学领域的推理能力。然而，当前用于数学推理的多模态LLMs（MLLMs）通常依赖一对一图像-文本对和单解监督，忽略了多样化有效推理视角和内部反思。本文提出MathV-DP数据集，为每个图像-问题对捕捉多样化解题轨迹，提供更丰富的推理监督。进一步提出Qwen-VL-DP模型，基于Qwen-VL，通过监督学习和基于规则的强化学习（GRPO）优化，结合正确性判别和多样性奖励函数。该方法强调从多样化解题视角学习并区分正确但不同的解。在MathVista的minitest和Math-V基准测试中，Qwen-VL-DP在准确性和生成多样性上显著优于现有MLLMs，凸显了多样化视角和反思性推理在多模态数学推理中的重要性。

</details>


### [22] [SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model](https://arxiv.org/abs/2507.02822)
**中文标题：SynapseRoute：基于双态大语言模型的自动路由切换框架**

*Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun*

主要分类: cs.CL

摘要简述: 本文提出SynapseRoute框架，通过动态路由将查询分配到低成本的非思考模式或高成本的思考模式，优化大语言模型在医疗问题中的准确性和成本效率。实验显示，该框架显著提升性能并降低资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型广泛应用，选择合适模型需平衡性能和成本。研究发现58%的医疗问题仅需低成本的非思考模式即可解决，动态路由可优化资源分配。

研究方法: 提出SynapseRoute框架，基于机器学习动态分配查询到思考或非思考模式，并引入AIT指数评估准确性、延迟和令牌成本的权衡。

研究结果: 实验表明，SynapseRoute在医疗数据集上提升准确性（0.8390 vs. 0.8272），减少推理时间36.8%和令牌消耗39.66%，避免过度推理导致的性能下降。

研究结论: SynapseRoute通过智能路由优化大语言模型的使用，显著提升效率并降低成本，为实际应用提供可行方案。

中文摘要: 随着大语言模型（LLMs）在实际应用中的广泛采用，选择合适的模型不仅需要平衡性能，还需考虑运营成本。具备推理能力的模型进一步扩大了“思考”（高推理）和“非思考”（快速、低成本）模式之间的成本差距。本研究发现，约58%的医疗问题仅需非思考模式即可准确回答，无需高成本的推理过程。这凸显了问题复杂性的明显二分性，并表明基于复杂性动态路由查询可优化准确性、成本效率和整体用户体验。基于此，我们提出SynapseRoute，一种基于机器学习的动态路由框架，智能地将输入查询分配到思考或非思考模式。在多个医疗数据集上的实验结果表明，SynapseRoute不仅相比单独使用思考模式提高了整体准确性（0.8390 vs. 0.8272），还减少了36.8%的推理时间和39.66%的令牌消耗。重要的是，定性分析表明，对简单查询过度推理会导致不必要的延迟甚至准确性下降，而我们的自适应路由避免了这一问题。最后，本研究进一步引入准确性-推理-令牌（AIT）指数，全面评估准确性、延迟和令牌成本之间的权衡。

</details>


### [23] [Generalizing Verifiable Instruction Following](https://arxiv.org/abs/2507.02833)
**中文标题：泛化可验证指令遵循**

*Valentina Pyatkin,Saumya Malik,Victoria Graf,Hamish Ivison,Shengyi Huang,Pradeep Dasigi,Nathan Lambert,Hannaneh Hajishirzi*

主要分类: cs.CL

摘要简述: 本文探讨了语言模型在遵循人类指令时的局限性，尤其是面对输出约束时的表现。作者提出了新基准IFBench和强化学习方法RLVR，以提升模型在未见约束上的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前的语言模型在遵循精确指令（如输出约束）时表现不佳，且容易过拟合于少量常见约束。作者旨在解决这一问题，并提升模型在多样化约束下的泛化能力。

研究方法: 作者设计了新基准IFBench，包含58种未见约束，并开发了约束验证模块。通过强化学习结合可验证奖励（RLVR）训练模型，提升其指令遵循能力。

研究结果: 实验表明，RLVR方法显著提升了模型在IFBench上的表现，验证了其在多样化约束下的泛化能力。作者还发布了29种新训练约束和相关代码。

研究结论: 通过IFBench和RLVR方法，作者证明了模型在精确指令遵循上的泛化能力可以显著提升，为未来研究提供了新工具和方向。

中文摘要: 人机交互成功的关键在于语言模型或聊天机器人能否精确遵循人类指令。指令中常见的输出约束（如“仅回答是或否”或“至少提及‘abrakadabra’三次”）有助于生成更有用的回答，但即使是当前最强的模型也难以满足此类约束。我们发现，大多数模型在测试这些能力的基准上对少量可验证约束表现出严重过拟合（称为精确指令遵循），且无法很好地泛化到未见约束。为此，我们提出了新基准IFBench，用于评估58种新的、多样化且具有挑战性的域外可验证约束下的精确指令遵循泛化能力。此外，我们深入分析了如何通过训练数据提升模型的精确指令遵循泛化能力。具体而言，我们精心设计了约束验证模块，并证明结合可验证奖励的强化学习（RLVR）显著改善了指令遵循能力。除IFBench外，我们还发布了29种新的手工标注训练约束及验证函数、RLVR训练提示和代码。

</details>


### [24] [LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users](https://arxiv.org/abs/2507.02850)
**中文标题：LLM催眠术：利用用户反馈对所有用户进行未经授权的知识注入**

*Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas*

主要分类: cs.CL

摘要简述: 本文揭示了一种基于用户反馈训练的语言模型（LM）漏洞，攻击者可通过简单的提示和反馈（如点赞/点踩）持久性地篡改模型知识和行为。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于揭示语言模型在用户反馈训练中的潜在安全风险，攻击者可能利用反馈机制对模型进行未经授权的知识注入和行为操控。

研究方法: 攻击者通过提示模型随机输出“有毒”或良性回答，并通过点赞有毒回答或点踩良性回答来操控反馈信号。随后，模型在偏好调整中更倾向于生成有毒回答，即使在没有恶意提示的情况下。

研究结果: 实验表明，该攻击可用于（1）插入模型原本不具备的事实知识，（2）修改代码生成模式以引入安全漏洞，（3）注入虚假金融新闻。

研究结论: 本文不仅揭示了语言模型偏好调整的新特性（表明即使高度受限的偏好数据也能精细控制模型行为），还提出了一种针对用户反馈训练模型的新攻击机制。

中文摘要: 我们描述了一种基于用户反馈训练的语言模型（LM）漏洞，攻击者仅需提供提示并对LM输出进行点赞/点踩反馈，即可持久性地篡改模型知识和行为。攻击者通过提示模型随机输出“有毒”或良性回答，并点赞有毒回答或点踩良性回答来实现攻击。当反馈信号用于后续偏好调整时，即使在没有恶意提示的上下文中，LM生成有毒回答的概率也会增加。我们展示了该攻击可用于（1）插入模型原本不具备的事实知识，（2）修改代码生成模式以引入可利用的安全漏洞，（3）注入虚假金融新闻。我们的发现不仅揭示了语言模型偏好调整的新定性特征（表明即使高度受限的偏好数据也能精细控制行为），还提出了一种针对用户反馈训练模型的新攻击机制（扩展了预训练时数据投毒和部署时提示注入的研究）。

</details>


### [25] [MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs](https://arxiv.org/abs/2507.02851)
**中文标题：MOTIF：通过强化学习微调实现大语言模型的模块化思考**

*Purbesh Mitra,Sennur Ulukus*

主要分类: cs.CL

摘要简述: 本文提出MOTIF方法，通过强化学习微调让大语言模型（LLM）分多轮生成思考标记，突破上下文限制，实验显示在MATH500和AIME2024基准上分别提升3.8%和3.3%。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）的上下文长度限制了其推理能力，无法处理超长标记序列。为解决这一问题，需要一种模块化思考策略，让模型分多轮推理。

研究方法: 提出MOTIF方法，通过强化学习微调（RL）训练LLM分多轮生成思考标记，扩展有效上下文长度。实验基于开源模型Qwen2.5-3B-Instruct，在GSM8K数据集上进行参数高效微调。

研究结果: 在MATH500和AIME2024基准测试中，MOTIF方法分别比传统GRPO训练提升3.8%和3.3%，且仅需15%的样本量，展示了高效性。

研究结论: MOTIF方法通过模块化思考策略有效突破LLM的上下文限制，显著提升推理性能，同时具有样本高效性。

中文摘要: 近期研究表明，通过群体相对策略优化（GRPO）算法进行强化学习（RL）训练，可以提升大语言模型（LLM）的推理能力，使其生成更多思考标记以优化回答。然而，LLM在保持对已生成标记注意力的同时，只能生成有限数量的标记，这一限制（即LLM的上下文长度）成为处理超长标记序列的瓶颈。为突破这一限制，LLM需采用模块化思考策略进行多轮推理。本文提出MOTIF方法：通过强化学习微调实现模块化思考——一种RL训练方法，支持多轮生成思考标记，从而扩展模型的有效上下文长度。我们在GSM8K数据集上对开源模型Qwen2.5-3B-Instruct进行参数高效微调，并在MATH500和AIME2024基准上测试其准确性。实验结果显示，相比传统GRPO训练，MOTIF方法在上述基准中分别提升3.8%和3.3%，且仅需15%的样本量，展示了其样本高效性。代码和模型已开源。

</details>


### [26] [Answer Matching Outperforms Multiple Choice for Language Model Evaluation](https://arxiv.org/abs/2507.02856)
**中文标题：答案匹配优于多项选择题用于语言模型评估**

*Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping*

主要分类: cs.CL

摘要简述: 研究发现，传统的多项选择题评测语言模型存在缺陷，而通过答案匹配的生成式评测方法能更准确地反映模型能力，并与人类评分高度一致。


<details>
  <summary>详细信息</summary>
研究动机: 多项选择题评测长期以来是语言模型评估的主要方法，但其存在缺陷，例如无需阅读问题即可回答。作者希望找到一种更准确、可扩展的替代方法。

研究方法: 提出答案匹配评测方法：让模型生成自由回答，再使用现代语言模型与参考答案比对。通过标注MMLU-Pro和GPQA-Diamond数据集，比较不同评测方法与人类评分的一致性。

研究结果: 答案匹配方法（即使使用小型模型）与人类评分一致性接近完美，而多项选择题评测和无参考答案的LLM评测与人类评分一致性较差。评测方法的改进显著影响了模型排名。

研究结论: 答案匹配评测优于多项选择题评测，建议将评测生态系统从多项选择题转向答案匹配方法。

中文摘要: 多项选择题评测长期以来是语言模型评估的主要方法，因为其评分客观且易于自动化。然而，我们发现热门评测中的多项选择题通常无需阅读问题即可回答。这些缺陷源于判别式评测的根本局限性，而生成式评测则无此问题。近期，答案匹配成为一种可行的替代方法：让模型生成自由回答，再使用现代语言模型与参考答案比对。为了比较不同评测方法的有效性，我们标注了MMLU-Pro和GPQA-Diamond数据集，测量每种评测方法与人类评分的一致性。结果显示，答案匹配方法（即使使用小型模型）与人类评分一致性接近完美，而多项选择题评测和无参考答案的LLM评测与人类评分一致性较差。评测方法的改进不仅是一个概念问题：多个模型的排名在答案匹配评测下发生显著变化。基于这些发现，我们讨论了如何将评测生态系统从多项选择题转向答案匹配方法。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges](https://arxiv.org/abs/2507.02074)
**中文标题：大型语言模型在视频碰撞检测中的应用：方法、数据集与挑战综述**

*Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma*

主要分类: cs.CV

摘要简述: 本文综述了利用大型语言模型（LLMs）进行视频中碰撞检测的最新方法，包括融合策略分类、数据集总结、模型架构分析、性能比较以及未来挑战与机遇。


<details>
  <summary>详细信息</summary>
研究动机: 智能交通系统中，视频碰撞检测是一个关键问题。近年来，大型语言模型（LLMs）和视觉语言模型（VLMs）的发展为多模态信息处理提供了新思路。本文旨在总结和梳理这一领域的最新研究进展。

研究方法: 论文通过结构化分类法总结了融合策略，梳理了关键数据集，分析了模型架构，并比较了性能基准。同时，探讨了当前面临的挑战和未来研究方向。

研究结果: 研究提供了视频理解与基础模型交叉领域的全面综述，为未来研究奠定了基础，并指出了性能提升和实际应用中的挑战。

研究结论: 本文为视频碰撞检测领域的研究者提供了系统性的参考，强调了LLMs在多模态信息处理中的潜力，并展望了未来的发展方向。

中文摘要: 视频中的碰撞检测是智能交通系统的关键问题。近年来，大型语言模型（LLMs）和视觉语言模型（VLMs）的发展彻底改变了多模态信息的处理、推理和总结方式。本文综述了利用LLMs进行视频碰撞检测的最新方法，提出了融合策略的结构化分类法，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前的挑战与机遇。本综述为视频理解与基础模型交叉领域的未来研究提供了基础。

</details>


### [28] [Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning](https://arxiv.org/abs/2507.02148)
**中文标题：水下单目度量深度估计：真实世界基准与合成微调**

*Zijie Cai,Christopher Metzler*

主要分类: cs.CV

摘要简述: 本文研究了水下单目深度估计的挑战，提出了一个包含真实和合成数据的基准测试，并通过微调模型在合成水下数据集上显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 水下环境中的单目深度估计由于光线衰减、散射、颜色失真和缺乏高质量的真实数据而受限。本文旨在通过真实和合成数据的结合，提升水下深度估计的准确性和鲁棒性。

研究方法: 作者首先评估了多种现有模型在真实水下数据集（如FLSea和SQUID）上的表现，发现其在域偏移下性能不佳。随后，他们使用基于物理的水下图像生成模型创建了合成水下数据集，并微调了Depth Anything V2模型。

研究结果: 实验表明，微调后的模型在所有基准测试中均表现优于仅使用干净空中数据训练的基线模型，验证了域适应和尺度感知监督的重要性。

研究结论: 本研究强调了水下深度估计中域适应的必要性，并展示了合成数据在提升模型性能方面的潜力，为未来研究提供了重要参考。

中文摘要: 单目深度估计最近已发展到不仅提供相对深度预测，还能提供度量深度预测。然而，由于光线衰减和散射、颜色失真、浑浊以及缺乏高质量的度量真实数据，其在水下环境中的可靠性仍然有限。本文提出了一个全面的基准测试，评估了零样本和微调的单目度量深度估计模型在具有度量深度标注的真实水下数据集（如FLSea和SQUID）上的表现。我们评估了多种先进模型在不同水下条件下的表现范围。结果表明，尽管在陆地（真实或合成）数据上训练的大规模模型在空中环境中表现良好，但由于显著的域偏移，其在水下表现不佳。为解决这一问题，我们使用基于物理的水下图像生成模型在Hypersim数据集的合成水下变体上微调了Depth Anything V2（采用ViT-S骨干编码器）。我们证明了微调后的模型在所有基准测试中均表现一致提升，并优于仅使用干净空中Hypersim数据集训练的基线模型。本研究为水下场景中的单目度量深度估计提供了详细的评估和可视化，强调了域适应和尺度感知监督对于在具有挑战性的水下环境中实现鲁棒且可泛化的度量深度预测的重要性，为未来研究提供了参考。

</details>


### [29] [ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.02200)
**中文标题：ESTR-CoT：基于思维链推理的可解释且准确的事件流场景文本识别**

*Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于思维链推理的事件流场景文本识别框架ESTR-CoT，结合视觉编码器和大型语言模型，显著提升了在低光照和快速运动等极端场景下的文本识别准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事件流场景文本识别方法在极端场景（如低光照和快速运动）中表现不足，且缺乏解释性和上下文逻辑推理能力。本文旨在通过思维链推理提升识别准确性和模型的可解释性。

研究方法: 采用EVA-CLIP视觉编码器将事件流转换为令牌，结合Llama分词器和Q-former对齐视觉令牌与预训练语言模型Vicuna-7B，输出答案及思维链推理过程。通过监督微调实现端到端优化，并构建大规模思维链数据集支持训练。

研究结果: 在EventSTR、WordArt*和IC15*三个基准数据集上的实验验证了ESTR-CoT的有效性和可解释性，显著提升了极端场景下的文本识别性能。

研究结论: ESTR-CoT通过思维链推理提升了事件流场景文本识别的准确性和可解释性，为后续推理型大模型的发展提供了数据基础。

中文摘要: 基于事件流的场景文本识别是近年来新兴的研究课题，在极端挑战性场景（如低光照和快速运动）中表现优于广泛使用的RGB相机。现有方法多采用端到端编码器-解码器框架或大型语言模型以增强识别能力，但仍受限于解释性不足和上下文逻辑推理能力较弱的问题。本文提出了一种基于思维链推理的事件流场景文本识别框架ESTR-CoT。具体而言，我们首先采用视觉编码器EVA-CLIP（ViT-G/14）将输入事件流转换为令牌，并利用Llama分词器编码生成提示。通过Q-former将视觉令牌与预训练大型语言模型Vicuna-7B对齐，同时输出答案和思维链推理过程。该框架可通过监督微调以端到端方式进行优化。此外，我们还提出了一个大规模思维链数据集，通过生成、优化和专家验证三阶段处理训练框架，为后续推理型大模型的发展提供了数据基础。在三个事件流场景文本识别基准数据集（EventSTR、WordArt*和IC15*）上的大量实验充分验证了所提框架的有效性和可解释性。源代码和预训练模型将在https://github.com/Event-AHU/ESTR-CoT发布。

</details>


### [30] [Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach](https://arxiv.org/abs/2507.02205)
**中文标题：第九届ABAW竞赛中的Team RAS：多模态复合表情识别方法**

*Elena Ryumina,Maxim Markitantov,Alexandr Axyonov,Dmitry Ryumin,Mikhail Dolgushin,Alexey Karpov*

主要分类: cs.CV

摘要简述: 本文提出了一种零样本多模态方法用于复合表情识别（CER），结合六种异构模态，并通过动态加权和概率聚合模块生成可解释的复合情感输出。在多语料库测试中表现优异，接近监督学习方法的效果。


<details>
  <summary>详细信息</summary>
研究动机: 复合表情识别（CER）是情感计算的重要子领域，旨在检测由基本情绪组合形成的复杂情感状态。传统方法依赖特定任务的训练数据，本文旨在探索一种无需领域适应的零样本多模态方法。

研究方法: 方法包括六种异构模态（静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本）的融合，使用零样本组件（如CLIP标签匹配和Qwen-VL语义场景理解）。提出多头部概率融合（MHPF）模块动态加权模态预测，并通过复合表情（CE）转换模块（PPA和PFSA）生成可解释输出。

研究结果: 在多语料库测试中，F1分数分别为AffWild2的46.95%、AFEW的49.02%和C-EXPR-DB的34.85%，与监督学习方法效果相当。

研究结论: 该方法无需领域适应即可有效捕捉复合表情，为零样本多模态情感识别提供了新思路。源代码已公开。

中文摘要: 复合表情识别（CER）是情感计算的子领域，旨在检测由基本情绪组合形成的复杂情感状态。本文提出了一种新颖的零样本多模态方法，将六种异构模态（静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本）整合到一个流程中。与依赖任务特定训练数据的传统方法不同，本文方法采用零样本组件，包括基于对比语言-图像预训练（CLIP）的标签匹配和Qwen-VL的语义场景理解。进一步提出多头部概率融合（MHPF）模块动态加权模态预测，并通过复合表情（CE）转换模块（使用成对概率聚合（PPA）和成对特征相似性聚合（PFSA）方法）生成可解释的复合情感输出。在多语料库训练评估中，该方法在AffWild2、AFEW和C-EXPR-DB上的F1分数分别为46.95%、49.02%和34.85%，与目标数据训练的监督方法效果相当。这表明该方法无需领域适应即可有效捕捉复合表情。源代码已公开。

</details>


### [31] [SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers](https://arxiv.org/abs/2507.02212)
**中文标题：SciGA：用于学术论文图形摘要设计的综合数据集**

*Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi*

主要分类: cs.CV

摘要简述: 本文介绍了SciGA-145k数据集，包含14.5万篇科学论文和114万张图表，旨在支持图形摘要（GA）的选择与推荐，并推动自动化GA生成的研究。


<details>
  <summary>详细信息</summary>
研究动机: 图形摘要在科学论文中起到关键作用，但设计有效的GA需要高级可视化技能，限制了其广泛应用。现有研究对GA在科学传播中的潜力探索不足。

研究方法: 提出SciGA-145k数据集，定义两项任务：1) 论文内GA推荐（Intra-GA），识别适合作为GA的图表；2) 跨论文GA推荐（Inter-GA），从其他论文中检索GA以启发新设计。并提出新评价指标CAR，分析模型行为。

研究结果: SciGA-145k为GA设计提供了大规模数据支持，并提出了基线模型和新评价指标CAR，为视觉科学传播和AI研究奠定了基础。

研究结论: SciGA-145k数据集和提出的任务与指标为提升科学视觉传播和AI在科学中的应用提供了重要工具和方向。

中文摘要: 图形摘要（GA）在科学论文中扮演着关键角色，能够直观传达研究成果。尽管近期研究越来越多地将图表（如图1）作为默认GA使用，但其在科学传播中的潜力尚未充分挖掘。此外，设计有效的GA需要高级可视化技能，限制了其广泛应用。为解决这些问题，我们推出了SciGA-145k，一个包含约14.5万篇科学论文和114万张图表的大规模数据集，专门用于支持GA的选择与推荐，并推动自动化GA生成的研究。作为GA设计支持的初步尝试，我们定义了两项任务：1) 论文内GA推荐（Intra-GA），识别论文中适合作为GA的图表；2) 跨论文GA推荐（Inter-GA），从其他论文中检索GA以启发新GA的创作。我们为这些任务提供了合理的基线模型。此外，我们提出了置信度调整的top-1真实比例（CAR），这是一种新的推荐指标，能够对模型行为进行细粒度分析。CAR通过考虑论文中除明确标注的GA外其他图表也可能作为GA的情况，弥补了传统基于排序的指标的不足。通过整合这些任务和指标，SciGA-145k为推进视觉科学传播和AI在科学中的应用奠定了基础。

</details>


### [32] [Understanding Trade offs When Conditioning Synthetic Data](https://arxiv.org/abs/2507.02217)
**中文标题：理解合成数据生成中的权衡条件**

*Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma*

主要分类: cs.CV

摘要简述: 本文研究了合成数据生成中的条件策略，比较了基于提示和基于布局的两种方法，发现布局条件在多样性高时表现更优，显著提升目标检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 在工业视觉系统中，高质量训练数据收集耗时且昂贵，合成数据成为关键解决方案。然而，现有方法生成速度慢且仿真与真实数据差距大，扩散模型虽快速但控制精度不足。本文旨在探索不同条件策略对合成数据质量的影响。

研究方法: 研究从四个标准目标检测数据集中选取80个视觉概念，比较基于提示和基于布局的两种条件策略。分析不同条件下合成数据的质量及其对目标检测性能的影响。

研究结果: 当条件线索有限时，基于提示的策略生成的数据质量更高；随着多样性增加，基于布局的策略表现更优。布局条件匹配完整训练分布时，合成数据使平均精度提升34%，最高可达177%。

研究结论: 布局条件策略在多样性高的场景下显著优于提示条件，能有效提升合成数据的质量及其在目标检测任务中的性能。

中文摘要: 从少量图像中学习鲁棒的目标检测器是工业视觉系统中的关键挑战，因为高质量训练数据的收集可能需要数月时间。合成数据已成为数据高效视觉检测和拾放机器人的重要解决方案。当前流程依赖于Blender或Unreal等3D引擎，这些引擎提供精细控制但仍需数周渲染小规模数据集，且生成的图像常存在仿真与现实的巨大差距。扩散模型因其能在几分钟内生成高质量图像而成为变革性技术，但在低数据量下的精确控制仍具挑战性。尽管已有多种适配器扩展了扩散模型的功能，但不同条件策略对合成数据质量的影响尚不明确。本研究从四个标准目标检测数据集中选取80个视觉概念，比较了基于提示和基于布局的两种条件策略。当条件线索有限时，提示条件生成的数据质量更高；随着多样性增加，布局条件表现更优。当布局条件匹配完整训练分布时，合成数据使平均精度平均提升34%，最高可达177%。

</details>


### [33] [High-Fidelity Differential-information Driven Binary Vision Transformer](https://arxiv.org/abs/2507.02222)
**中文标题：高保真差分信息驱动的二值视觉变换器**

*Tian Gao,Zhiyuan Zhang,Kaijie Yin,Xu-Cheng Zhong,Hui Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种高保真差分信息驱动的二值视觉变换器（DIDB-ViT），通过引入差分信息和频率分解技术，显著提升了二值化视觉变换器的性能，同时保持了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的二值视觉变换器（ViT）方法存在性能严重下降或过度依赖全精度模块的问题。本文旨在设计一种既能保持高性能又能适应边缘设备部署的二值ViT。

研究方法: 1. 设计了包含差分信息的注意力模块，以减少二值化导致的信息损失并增强高频保留；2. 使用离散哈尔小波进行频率分解，整合不同频率的相似性；3. 引入改进的RPReLU激活函数，优化激活分布以提升模型表示能力。

研究结果: 实验结果表明，DIDB-ViT在多种ViT架构中显著优于现有网络量化方法，在图像分类和分割任务中表现优异。

研究结论: DIDB-ViT通过差分信息和频率分解技术有效解决了二值化ViT的性能问题，为边缘设备部署提供了高效且高性能的解决方案。

中文摘要: 二值化视觉变换器（ViTs）为解决高计算/存储需求与边缘设备部署限制之间的权衡提供了一种有前景的方法。然而，现有的二值ViT方法通常存在性能严重下降或过度依赖全精度模块的问题。为解决这些问题，我们提出了DIDB-ViT，一种新型的二值ViT，它在保持原始ViT架构和计算效率的同时具有高信息量。具体而言，我们设计了一个包含差分信息的注意力模块，以减少二值化导致的信息损失并增强高频保留。为了保持二进制Q和K张量之间相似性计算的高保真度，我们使用离散哈尔小波进行频率分解，并整合不同频率的相似性。此外，我们引入了一种改进的RPReLU激活函数，以重构激活分布，扩展模型的表示能力。实验结果表明，我们的DIDB-ViT在多种ViT架构中显著优于最先进的网络量化方法，实现了卓越的图像分类和分割性能。

</details>


### [34] [FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model](https://arxiv.org/abs/2507.02250)
**中文标题：FMOcc：基于TPV驱动的流匹配与选择性状态空间模型的3D占据预测**

*Jiangxia Chen,Tongyuan Huang,Ke Song*

主要分类: cs.CV

摘要简述: FMOcc是一种基于TPV视角和选择性状态空间模型的3D语义占据预测方法，通过流匹配和特征筛选提升预测精度，尤其在遮挡和远距离场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖多帧数据融合，计算资源消耗大且无法有效解决遮挡和远距离场景的预测问题。FMOcc旨在通过流匹配和选择性状态空间模型，减少冗余计算并提升预测能力。

研究方法: 1. 设计流匹配SSM模块（FMSSM）生成缺失特征；2. 通过TPV SSM层和平面选择性SSM（PS3M）筛选特征，减少空气体素对非空气体素的影响；3. 引入掩码训练（MT）方法增强模型鲁棒性。

研究结果: 在Occ3D-nuScenes和OpenOcc数据集上，FMOcc以两帧输入取得显著成绩：43.1% RayIoU和39.8% mIoU（Occ3D-nuScenes验证集），42.6% RayIoU（OpenOcc），推理内存5.4G，时间330ms。

研究结论: FMOcc通过流匹配和选择性状态空间模型，显著提升了3D语义占据预测的精度和效率，尤其在遮挡和远距离场景中表现突出。

中文摘要: 3D语义占据预测在自动驾驶中至关重要。然而，少帧图像的固有局限性和3D空间的冗余性影响了遮挡和远距离场景的预测精度。现有方法通过融合历史帧数据提升性能，但需要额外数据和大量计算资源。为解决这些问题，本文提出FMOcc，一种基于三视角（TPV）优化的占据网络，结合流匹配选择性状态空间模型，用于少帧3D占据预测。首先，为生成缺失特征，我们设计了基于流匹配模型的特征优化模块（FMSSM）。此外，通过设计TPV SSM层和平面选择性SSM（PS3M），我们选择性筛选TPV特征以减少空气体素对非空气体素的影响，从而提升模型整体效率和远距离场景预测能力。最后，我们设计了掩码训练（MT）方法以增强FMOcc的鲁棒性，解决传感器数据丢失问题。在Occ3D-nuScenes和OpenOcc数据集上的实验结果表明，FMOcc优于现有最优方法。FMOcc以两帧输入在Occ3D-nuScenes验证集上取得43.1% RayIoU和39.8% mIoU，在OpenOcc上取得42.6% RayIoU，推理内存5.4G，时间330ms。

</details>


### [35] [SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement](https://arxiv.org/abs/2507.02252)
**中文标题：SurgVisAgent：多功能手术视觉增强的多模态代理模型**

*Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SurgVisAgent的多模态智能手术视觉代理，基于多模态大语言模型（MLLMs），能够动态识别内窥镜图像中的失真类别和严重程度，并执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。通过领域特定知识模型和上下文少样本学习，SurgVisAgent为复杂手术场景提供了统一的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 现有的手术视觉增强算法通常针对单一任务设计，难以应对复杂多变的实际手术场景。因此，需要一种能够动态适应多种失真类型和严重程度的统一解决方案，以提升手术决策的精确性和安全性。

研究方法: SurgVisAgent基于多模态大语言模型（MLLMs），设计了一个领域特定知识模型，并通过上下文少样本学习和链式推理（CoT）实现定制化的图像增强。此外，构建了一个模拟真实手术失真的综合基准数据集。

研究结果: 实验表明，SurgVisAgent在多种失真类型和严重程度的任务中表现优于传统单一任务模型，展示了其作为统一手术辅助解决方案的潜力。

研究结论: SurgVisAgent通过多模态智能代理和领域知识结合，为复杂手术场景提供了灵活且高效的视觉增强能力，有望成为未来手术辅助的重要工具。

中文摘要: 精确的手术干预对患者安全至关重要，而先进的增强算法已被开发用于辅助外科医生的决策。尽管取得了显著进展，但这些算法通常针对特定场景的单一任务设计，限制了其在复杂现实情况中的有效性。为解决这一问题，我们提出了SurgVisAgent，一种基于多模态大语言模型（MLLMs）的端到端智能手术视觉代理。SurgVisAgent能够动态识别内窥镜图像中的失真类别和严重程度，从而执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。具体而言，为实现卓越的手术场景理解，我们设计了一个提供领域特定知识的先验模型。此外，通过上下文少样本学习和链式推理（CoT），SurgVisAgent能够针对广泛的失真类型和严重程度提供定制化的图像增强，从而满足外科医生的多样化需求。我们还构建了一个模拟真实手术失真的综合基准数据集，大量实验表明，SurgVisAgent超越了传统的单一任务模型，凸显了其作为统一手术辅助解决方案的潜力。

</details>


### [36] [Multi-Label Classification Framework for Hurricane Damage Assessment](https://arxiv.org/abs/2507.02265)
**中文标题：飓风损害评估的多标签分类框架**

*Zhangding Liu,Neda Mohammadi,John E. Taylor*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多标签分类的飓风损害评估框架，通过结合ResNet特征提取和类别特定注意力机制，显著提升了损害分类的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 飓风造成的损害类型多样且复杂，传统单标签分类方法无法全面捕捉损害特征，亟需一种高效的多标签分类方法以支持精准的灾害响应。

研究方法: 研究提出了一种多标签分类框架，结合ResNet特征提取模块和类别特定注意力机制，用于从单张航拍图像中识别多种损害类型。

研究结果: 在Rescuenet数据集上的实验表明，该方法平均精度达到90.23%，优于现有基线方法。

研究结论: 该框架显著提升了飓风损害评估的效率和准确性，为灾害响应和减灾策略提供了有力支持。

中文摘要: 飓风造成广泛破坏，导致多样化的损害类型和严重程度，需要及时准确的评估以支持有效的灾害响应。传统的单标签分类方法难以捕捉飓风后损害的复杂性，本研究提出了一种基于航拍图像的多标签分类框架用于损害评估。该方法结合了基于ResNet的特征提取模块和类别特定注意力机制，能够从单张图像中识别多种损害类型。在飓风Michael的Rescuenet数据集上，所提方法的平均精度达到90.23%，优于现有基线方法。该框架提升了飓风后损害评估的效率和准确性，有助于更有针对性和高效的灾害响应，并为未来的减灾和韧性策略提供了支持。本文已被ASCE国际计算土木工程会议（i3CE 2025）接受，最终版本将收录于会议论文集。

</details>


### [37] [Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation](https://arxiv.org/abs/2507.02268)
**中文标题：基于双向域适应的跨域高光谱图像分类**

*Yuxiang Zhang,Wei Li,Wen Jia,Mengmeng Zhang,Ran Tao,Shunlin Liang*

主要分类: cs.CV

摘要简述: 本文提出了一种双向域适应（BiDA）框架，用于跨域高光谱图像分类，通过提取域不变特征和域特定信息，显著提升了目标场景的适应性和可分性。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱遥感技术能够提取细粒度的土地覆盖类别，但训练和测试图像通常来自不同区域或时间，导致相同类别在不同场景中存在显著光谱偏移。因此，需要一种方法来解决跨域分类问题。

研究方法: 提出了一种双向域适应框架（BiDA），采用三分支Transformer架构（源分支、目标分支和耦合分支）作为主干。耦合分支中设计了耦合多头交叉注意力机制（CMCA）用于特征交互和域间相关性挖掘，并设计了双向蒸馏损失和自适应强化策略（ARS）以优化特征提取。

研究结果: 在跨时空/场景的航空和卫星数据集上的实验表明，BiDA显著优于现有域适应方法。在跨时空树种分类任务中，BiDA比最先进方法高出3%至5%。

研究结论: BiDA框架通过双向域适应和特征交互，有效解决了跨域高光谱图像分类问题，显著提升了分类性能。

中文摘要: 利用高光谱遥感技术可以提取细粒度的土地覆盖类别。通常，用于训练和测试的卫星或航空图像来自不同区域或时间，导致相同类别在不同场景中存在显著的光谱偏移。本文提出了一种双向域适应（BiDA）框架，用于跨域高光谱图像（HSI）分类，该框架专注于在独立的自适应空间中提取域不变特征和域特定信息，从而增强对目标场景的适应性和可分性。在提出的BiDA中，设计了一种带有语义标记器的三分支Transformer架构（源分支、目标分支和耦合分支）作为主干。具体而言，源分支和目标分支独立学习源域和目标域的自适应空间，耦合分支中开发了耦合多头交叉注意力（CMCA）机制用于特征交互和域间相关性挖掘。此外，设计了双向蒸馏损失以利用域间相关性指导自适应空间学习。最后，提出了一种自适应强化策略（ARS），以鼓励模型在噪声条件下专注于源和目标场景中的特定广义特征提取。在跨时空/场景的航空和卫星数据集上的实验结果表明，所提出的BiDA显著优于一些最先进的域适应方法。在跨时空树种分类任务中，BiDA比最先进方法高出3%至5%。代码可从以下网站获取：https://github.com/YuxiangZhang-BIT/IEEE_TCSVT_BiDA。

</details>


### [38] [MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement](https://arxiv.org/abs/2507.02270)
**中文标题：MAC-Lookup：用于水下图像增强的多轴条件查找模型**

*Fanghai Yi,Zehong Zheng,Zexiao Liang,Yihang Dong,Xiyang Fang,Wangyu Wu,Xuhang Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种多轴条件查找（MAC-Lookup）模型，用于提升水下图像的视觉质量，通过颜色校正和细节增强，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 水下图像常因光线变化、水体浑浊和气泡等问题导致可见性和颜色失真。传统方法效果有限，而深度学习缺乏高质量数据集。因此，需要一种新方法来有效提升水下图像质量。

研究方法: MAC-Lookup模型包含两部分：条件3D查找表颜色校正（CLTCC）用于初步颜色和质量校正，以及多轴自适应增强（MAAE）用于细节优化。该方法避免了过度增强和饱和问题。

研究结果: 实验表明，MAC-Lookup在恢复水下图像细节和颜色方面优于现有方法，显著提升了视觉质量。

研究结论: MAC-Lookup模型通过创新的多轴条件查找方法，有效解决了水下图像增强的挑战，为水下探索提供了更高质量的图像支持。

中文摘要: 水下图像增强对探索至关重要。这些图像因光线变化、水体浑浊和气泡等问题面临可见性和颜色失真。传统的基于先验和像素的方法往往效果不佳，而深度学习又缺乏高质量数据集。我们提出了多轴条件查找（MAC-Lookup）模型，通过提升颜色准确性、清晰度和对比度来改善视觉质量。该模型包括条件3D查找表颜色校正（CLTCC）用于初步颜色和质量校正，以及多轴自适应增强（MAAE）用于细节优化。该方法避免了过度增强和饱和问题，同时应对水下挑战。大量实验表明，MAC-Lookup在恢复水下图像细节和颜色方面优于现有方法。代码见https://github.com/onlycatdoraemon/MAC-Lookup。

</details>


### [39] [Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation](https://arxiv.org/abs/2507.02271)
**中文标题：通过自蒸馏聚焦部分可见电影语言以实现视频到音频生成**

*Feizhen Huang,Yu Wu,Yutian Lin,Bo Du*

主要分类: cs.CV

摘要简述: 本文提出了一种自蒸馏方法，用于解决视频到音频生成中部分可见电影语言的挑战，显著提升了模型在部分可见场景下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频到音频生成方法忽视了电影语言这一关键艺术表达元素，导致在部分可见场景下性能下降。

研究方法: 通过模拟电影语言变化，采用自蒸馏方法训练学生模型，使其能够对齐视频特征与音频-视觉对应关系，从而捕捉部分视觉信息与声音的关联。

研究结果: 该方法在所有评估指标下显著提升了部分可见场景的性能，同时在大规模V2A数据集VGGSound上也表现优异。

研究结论: 自蒸馏方法有效解决了部分可见电影语言的挑战，为视频到音频生成提供了更强大的工具。

中文摘要: 视频到音频（V2A）生成取得了显著进展，并在影视后期制作中扮演重要角色。然而，现有方法忽视了电影语言这一电影艺术表达的关键组成部分，导致在Foley目标仅部分可见的场景下性能下降。为解决这一问题，我们提出了一种简单的自蒸馏方法，将V2A模型扩展到电影语言场景。通过模拟电影语言的变化，学生模型学习对齐具有相同音频-视觉对应关系的训练对视频特征，从而有效捕捉声音与部分视觉信息之间的关联。我们的方法不仅在部分可见场景下所有评估指标上取得了显著提升，还在大规模V2A数据集VGGSound上表现出色。

</details>


### [40] [LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2507.02279)
**中文标题：LaCo：多模态大语言模型中视觉令牌的高效层级压缩**

*Juntao Liu,Liqiang Niu,Wenchao Chen,Jie Zhou,Fandong Meng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LaCo的新型视觉令牌压缩框架，通过在视觉编码器的中间层进行令牌压缩，显著提升了多模态大语言模型的效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉令牌压缩方法主要作为后编码器模块运行，限制了效率提升的潜力。为了解决这一问题，本文提出了LaCo框架，旨在在视觉编码器的中间层实现高效的令牌压缩。

研究方法: LaCo框架包含两个核心组件：1）层级的像素重组机制，通过空间到通道的转换系统性地合并相邻令牌；2）带有非参数捷径的残差学习架构，确保压缩过程中关键视觉信息的保留。

研究结果: 实验表明，LaCo在视觉编码器中间层压缩令牌时优于所有现有方法，同时训练效率提升超过20%，推理吞吐量提升超过15%，且性能保持强劲。

研究结论: LaCo框架通过中间层令牌压缩显著提升了多模态大语言模型的效率，同时保持了高性能，为视觉令牌压缩提供了新的解决方案。

中文摘要: 现有的多模态大语言模型（MLLMs）视觉令牌压缩方法主要作为后编码器模块运行，限制了其效率提升的潜力。为解决这一问题，我们提出了LaCo（层级视觉令牌压缩），这是一种新颖的框架，能够在视觉编码器的中间层实现高效的令牌压缩。LaCo引入了两个核心组件：1）层级的像素重组机制，通过空间到通道的转换系统性地合并相邻令牌；2）带有非参数捷径的残差学习架构，确保压缩过程中关键视觉信息的保留。大量实验表明，在视觉编码器中间层压缩令牌时，我们的LaCo优于所有现有方法，表现出卓越的有效性。此外，与外部压缩相比，我们的方法在保持强劲性能的同时，训练效率提升超过20%，推理吞吐量提升超过15%。

</details>


### [41] [Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization](https://arxiv.org/abs/2507.02288)
**中文标题：通过语言引导和表示对齐实现提示解缠的域泛化方法**

*De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种通过语言引导和表示对齐的提示解缠方法，用于提升域泛化（DG）能力。利用预训练视觉基础模型（VFMs）的文本模态特性，结合大语言模型（LLM）解缠文本提示，并通过WERA方法增强视觉表示对齐，显著优于现有DG方法。


<details>
  <summary>详细信息</summary>
研究动机: 域泛化（DG）旨在开发能在未见目标域上有效工作的模型。尽管基于预训练视觉基础模型（VFMs）的域提示调优受到关注，但如何设计能解缠跨域不变特征的提示仍是一个关键挑战。本文利用VFMs的文本模态易解缠特性，提出通过语言引导和表示对齐解决这一问题。

研究方法: 1. 使用大语言模型（LLM）自动解缠文本提示；2. 通过解缠的文本特征引导学习域不变视觉表示；3. 引入WERA方法，通过抽象提示和风格化图像增强提升源域多样性，同时对齐约束确保视觉表示在原始和增强分布中的一致性。

研究结果: 在PACS、VLCS、OfficeHome、DomainNet和TerraInc等主要DG数据集上的实验表明，所提方法优于当前最先进的DG方法。

研究结论: 通过语言引导和表示对齐的提示解缠方法有效提升了域泛化能力，WERA的引入进一步增强了视觉表示的鲁棒性，为DG任务提供了新的解决方案。

中文摘要: 域泛化（DG）旨在开发一种能够在未见目标域上有效工作的通用模型。近年来，预训练的视觉基础模型（VFMs，如CLIP）在提升深度学习模型泛化能力方面展现出巨大潜力。尽管基于VFMs的域提示调优在DG中受到越来越多的关注，但如何设计能够解缠跨域不变特征的有效提示仍是一个关键挑战。本文提出利用VFMs可控且灵活的语言提示来解决这一挑战。注意到VFMs的文本模态天然更易于解缠，我们引入了一种新颖的文本特征引导视觉提示调优框架。该框架首先使用大语言模型（LLM）自动解缠文本提示，随后通过解缠的文本特征引导学习域不变视觉表示。然而，仅依赖语言引导视觉特征解缠存在局限性，因为视觉特征有时过于复杂或微妙，难以完全通过描述性文本捕捉。为此，我们引入了最差显式表示对齐（WERA），通过引入一组抽象提示扩展了文本引导的视觉提示。这些提示通过风格化图像增强提升了源域多样性，同时对齐约束确保了视觉表示在原始和增强分布中的一致性。在PACS、VLCS、OfficeHome、DomainNet和TerraInc等主要DG数据集上的实验表明，所提方法优于当前最先进的DG方法。

</details>


### [42] [ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation](https://arxiv.org/abs/2507.02294)
**中文标题：ViRefSAM：基于视觉参考引导的Segment Anything模型用于遥感图像分割**

*Hanbo Bi,Yulong Xu,Ya Li,Yongqiang Mao,Boyuan Tong,Chongyang Li,Chunbo Lang,Wenhui Diao,Hongqi Wang,Yingchao Feng,Xian Sun*

主要分类: cs.CV

摘要简述: ViRefSAM是一种基于视觉参考的Segment Anything Model（SAM）改进框架，通过少量标注参考图像自动生成提示，解决了遥感图像分割中手动构建提示的低效性和SAM领域适应性不足的问题。


<details>
  <summary>详细信息</summary>
研究动机: SAM在通用分割任务中表现优异，但在遥感图像分割中面临两大挑战：手动构建精确提示效率低下，且SAM缺乏对遥感图像特定语义和空间特征的适应性。

研究方法: ViRefSAM引入两个关键组件：1）视觉上下文提示编码器，从参考图像提取类特定语义线索并生成目标图像的对象感知提示；2）动态目标对齐适配器，通过注入类特定语义到目标图像特征，缩小领域差距。

研究结果: 在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$三个少样本分割基准测试中，ViRefSAM仅需少量参考图像即可实现未见类别的准确自动分割，性能优于现有少样本分割方法。

研究结论: ViRefSAM通过视觉参考引导SAM，显著提升了遥感图像分割的效率和准确性，为少样本分割任务提供了新的解决方案。

中文摘要: Segment Anything Model（SAM）通过提示驱动范式在通用分割任务中表现出强大的泛化能力。然而，将SAM应用于遥感（RS）图像仍面临两大挑战：首先，为每张图像手动构建精确提示（如点或框）费时且低效，尤其是在遥感场景中，对象密集或空间分布分散；其次，SAM缺乏领域适应性，因其主要基于自然图像预训练，难以捕捉遥感图像特有的语义和空间特征，尤其是分割新类别时。为解决这些问题，受少样本学习启发，我们提出ViRefSAM，一种仅需少量包含类特定对象的标注参考图像即可引导SAM的新框架。ViRefSAM无需手动提示，即可实现遥感图像中类一致对象的自动分割。具体而言，ViRefSAM在保持SAM原始架构不变的同时引入两个关键组件：（1）视觉上下文提示编码器，从参考图像提取类特定语义线索，并通过与目标图像的上下文交互生成对象感知提示；（2）动态目标对齐适配器，集成到SAM的图像编码器中，通过将类特定语义注入目标图像特征来缩小领域差距，使SAM能动态聚焦于任务相关区域。在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$三个少样本分割基准测试上的大量实验表明，ViRefSAM仅需少量参考图像即可实现未见类别的准确自动分割，且性能优于现有少样本分割方法。

</details>


### [43] [DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation](https://arxiv.org/abs/2507.02299)
**中文标题：DreamComposer++：通过多视角条件赋能扩散模型实现3D内容生成**

*Yunhan Yang,Shuo Chen,Yukun Huang,Xiaoyang Wu,Yuan-Chen Guo,Edmund Y. Lam,Hengshuang Zhao,Tong He,Xihui Liu*

主要分类: cs.CV

摘要简述: DreamComposer++ 是一个通过多视角条件增强扩散模型的框架，提升3D内容生成的可控性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在从单张图像生成高质量新视角时面临可控性不足的问题，主要原因是缺乏多视角信息。

研究方法: DreamComposer++ 通过视角感知的3D提取模块和多视角特征融合模块，将多视角信息整合到预训练的扩散模型中，实现新视角合成。

研究结果: 实验表明，DreamComposer++ 能够无缝集成前沿的视角感知扩散模型，显著提升多视角条件下的可控新视角生成能力。

研究结论: DreamComposer++ 为可控3D对象重建提供了有效工具，并拓展了应用范围。

中文摘要: 近年来，利用预训练的2D扩散模型从单张野外图像生成高质量新视角取得了显著进展。然而，由于缺乏多视角信息，现有方法在生成可控新视角时面临挑战。本文提出DreamComposer++，这是一个灵活且可扩展的框架，旨在通过引入多视角条件改进当前的视角感知扩散模型。具体而言，DreamComposer++ 利用视角感知的3D提取模块从多个视角提取对象的3D表示。这些表示通过多视角特征融合模块聚合并渲染为目标视角的潜在特征。最后，将获得的目标视角特征整合到预训练的图像或视频扩散模型中，实现新视角合成。实验结果表明，DreamComposer++ 能够无缝集成前沿的视角感知扩散模型，并增强其在多视角条件下生成可控新视角的能力。这一进展为可控3D对象重建提供了便利，并拓展了广泛的应用场景。

</details>


### [44] [Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images](https://arxiv.org/abs/2507.02307)
**中文标题：Flow-CDNet：一种用于检测双时相图像中慢速和快速变化的新型网络**

*Haoxuan Li,Chenxu Wei,Haodong Wang,Xiaomeng Hu,Boyuan An,Lingyan Ran,Baosen Zhang,Jin Jin,Omirzhan Taukebayev,Amirkhan Temirbayev,Junrui Liu,Xiuwei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Flow-CDNet的新型网络，用于同时检测双时相图像中的慢速和快速变化。该网络包含光流分支和二元变化检测分支，通过多尺度位移提取和ResNet结合光流输出，显著提升了变化检测性能。实验验证了其优于现有方法的效果。


<details>
  <summary>详细信息</summary>
研究动机: 在实际应用中，双时相图像中的慢速变化（如滑坡、尾矿坝等）往往是重大灾害的前兆，但现有方法主要关注快速变化。因此，设计一种能同时检测慢速和快速变化的网络具有重要现实意义。

研究方法: Flow-CDNet由两个分支组成：光流分支通过金字塔结构提取多尺度位移变化，二元变化检测分支结合ResNet和光流分支输出生成快速变化结果。此外，设计了Flow-Change数据集、结合二元Tversky损失和L2范数损失的损失函数，以及新的评价指标FEPE。

研究结果: 在Flow-Change数据集上的定量实验表明，Flow-CDNet优于现有方法。消融实验验证了两个分支的相互促进作用。

研究结论: Flow-CDNet通过结合光流和二元变化检测分支，有效解决了双时相图像中慢速和快速变化的检测问题，为实际应用提供了新思路。

中文摘要: 变化检测通常涉及识别同一地点拍摄的双时相图像中的变化区域。除了显著变化外，慢速变化在实际场景中也具有重要意义。例如，在滑坡、大坝和尾矿库等场景中，微弱变化往往是重大灾害的前兆。因此，设计一种能同时检测慢速和快速变化的网络是一项新挑战。本文提出了一种名为Flow-CDNet的变化检测网络，包含两个分支：光流分支和二元变化检测分支。光流分支通过金字塔结构提取多尺度位移变化，二元变化检测分支结合ResNet和光流分支输出生成快速变化结果。此外，为监督和评估这一新框架，设计了自建数据集Flow-Change、结合二元Tversky损失和L2范数损失的损失函数，以及新的评价指标FEPE。在Flow-Change数据集上的定量实验表明，该方法优于现有方法。消融实验验证了两个分支的相互促进作用。

</details>


### [45] [LMPNet for Weakly-supervised Keypoint Discovery](https://arxiv.org/abs/2507.02308)
**中文标题：基于弱监督的关键点发现的LMPNet**

*Pei Guo,Ryan Farrell*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LMPNet的弱监督关键点发现方法，仅通过类别标签实现语义对象关键点的自动发现。通过引入漏最大池化层和选择策略，模型能够高效学习稀疏、一致且多样的关键点检测器，并在实验中表现出与监督模型相当的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 研究的目标是在仅使用类别标签的弱监督条件下，自动发现语义对象的关键点。传统方法依赖手工设计的损失项，而本文希望通过直接操作网络滤波器来检测预定义概念，提高模型的解释性和效率。

研究方法: 提出了一种漏最大池化（LMP）层，鼓励卷积层滤波器学习稀疏、一致且多样的局部模式。通过可视化分析，设计了一种选择策略确保滤波器激活的一致性，并使用注意力掩码迫使网络关注对象的整体而非最显著区域。最后，通过可学习的聚类层将关键点提议分组为预测结果。

研究结果: 实验表明，LMPNet能够自动发现对物体姿态鲁棒的语义关键点，其预测准确性可与监督姿态估计模型相媲美。

研究结论: LMPNet通过直接操作网络滤波器，实现了高效且解释性强的关键点发现，为弱监督学习提供了新思路。

中文摘要: 本文研究了仅通过类别标签弱监督的语义对象关键点发现任务。通过将判别训练的中间层滤波器转化为关键点检测器，我们实现了这一目标。首先，我们确定了关键点检测器的三个理想特性：（i）空间稀疏激活，（ii）一致性和（iii）多样性。无需依赖手工设计的损失项，我们提出了一种新颖的计算高效的漏最大池化（LMP）层，显式鼓励最终卷积层滤波器学习与对象关键点对齐的“非重复局部模式”。基于可视化分析，提出了一种简单而有效的选择策略，以确保滤波器激活的一致性，并应用注意力掩码迫使网络将注意力分布到整个对象而非仅最显著区域。对于最终的关键点预测，提出了一种可学习的聚类层，将关键点提议分组为关键点预测。最终模型名为LMPNet，具有高度解释性，因为它直接操作网络滤波器以检测预定义概念。实验表明，LMPNet能够（i）自动发现对物体姿态鲁棒的语义关键点，（ii）其预测准确性可与监督姿态估计模型相媲美。

</details>


### [46] [Perception Activator: An intuitive and portable framework for brain cognitive exploration](https://arxiv.org/abs/2507.02311)
**中文标题：感知激活器：一种直观便携的大脑认知探索框架**

*Le Xu,Qi Zhang,Qixian Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为‘感知激活器’的框架，通过将fMRI信号注入多尺度图像特征，验证了fMRI信号对下游检测和分割任务的提升作用，揭示了fMRI中丰富的多对象语义线索和空间定位信息。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大脑视觉解码方法主要依赖像素级和语义级的两级策略，但缺乏细粒度的语义对齐，导致多语义对象重建失真。为了更深入理解大脑视觉感知模式及解码模型对语义对象的处理方式，作者开发了实验框架。

研究方法: 作者提出了一种实验框架，将fMRI表征作为干预条件，通过跨注意力机制将其注入多尺度图像特征中，并在对象检测和实例分割任务中比较有无fMRI信息的下游性能和中间特征变化。

研究结果: 实验结果表明，引入fMRI信号可以提升下游检测和分割的准确性，证实了fMRI包含丰富的多对象语义线索和粗略的空间定位信息，这些信息尚未被现有模型充分利用或整合。

研究结论: fMRI信号对视觉任务的提升作用显著，未来研究可以进一步探索如何更有效地利用fMRI中的语义和空间信息。

中文摘要: 近年来，大脑视觉解码技术的进步显著推动了从神经活动（如功能磁共振成像fMRI）中高保真重建感知视觉刺激的研究。现有方法多采用像素级和语义级的两级解码策略，但这些方法过度依赖低级的像素对齐，缺乏足够的细粒度语义对齐，导致多语义对象重建明显失真。为了更好地理解大脑的视觉感知模式以及当前解码模型如何处理语义对象，我们开发了一个实验框架，将fMRI表征作为干预条件。通过跨注意力机制将这些表征注入多尺度图像特征中，我们在对象检测和实例分割任务中比较了有无fMRI信息的下游性能和中间特征变化。结果表明，引入fMRI信号可以提升下游检测和分割的准确性，证实了fMRI包含丰富的多对象语义线索和粗略的空间定位信息，这些信息尚未被现有模型充分利用或整合。

</details>


### [47] [MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation](https://arxiv.org/abs/2507.02314)
**中文标题：MAGIC：基于掩模引导扩散修复的多级扰动与上下文感知对齐的少样本异常生成**

*JaeHyuck Choi,MinJun Kim,JeHyeong Hong*

主要分类: cs.CV

摘要简述: MAGIC是一种基于扩散模型的少样本异常生成方法，通过多级扰动和上下文感知对齐，解决了背景破坏、掩模对齐和语义合理性问题，显著提升了异常生成的质量和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 工业质量控制中异常数据稀缺，现有方法难以同时满足背景保护、掩模对齐和语义合理性需求。MAGIC旨在解决这些问题，提升异常生成的效果。

研究方法: MAGIC基于Stable Diffusion修复模型，通过微调保护正常区域并严格对齐掩模。采用高斯提示级扰动和掩模引导的空间噪声注入增强多样性，并通过上下文感知掩模对齐模块确保语义合理性。

研究结果: 在MVTec-AD数据集上，MAGIC在异常任务中表现优于现有方法，解决了背景破坏和掩模对齐问题，同时提升了生成多样性和语义合理性。

研究结论: MAGIC通过多级扰动和上下文感知对齐，实现了高质量的少样本异常生成，为工业质量控制提供了有效的解决方案。

中文摘要: 少样本异常生成是工业质量控制中稀缺异常数据增强的实用解决方案。理想的生成器需满足三点：(i)保持正常背景完整，(ii)异常区域与掩模紧密对齐，(iii)在语义合理位置生成多样且真实的异常。现有扩散方法通常仅满足其中两点：全局异常生成器会破坏背景，而掩模引导方法在掩模不精确或位置错误时表现不佳。我们提出MAGIC——基于掩模引导修复的多级扰动与上下文感知对齐——以解决所有三个问题。MAGIC的核心是对Stable Diffusion修复模型进行微调，保护正常区域并确保合成异常严格对齐掩模，直接解决背景破坏和错位问题。为弥补微调可能导致的多样性损失，MAGIC引入两种互补扰动策略：(i)高斯提示级扰动，在微调和推理时应用，扩展异常全局外观并避免低质量文本表现；(ii)掩模引导的空间噪声注入，丰富局部纹理变化。此外，上下文感知掩模对齐模块建立语义对应关系并调整掩模位置，确保异常始终位于宿主对象内，消除边界外伪影。在MVTec-AD数据集的一致评估协议下，MAGIC在异常任务中优于现有最优方法。

</details>


### [48] [Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos](https://arxiv.org/abs/2507.02316)
**中文标题：合成视频有用吗？面向检索中心评估的合成视频基准**

*Zecheng Zhao,Selena Song,Tong Chen,Zhi Chen,Shazia Sadiq,Yadan Luo*

主要分类: cs.CV

摘要简述: 本文提出SynTVA数据集和基准，用于评估合成视频在文本到视频检索任务中的实用性，并通过多维度语义对齐分析和自动评估工具探索其性能提升潜力。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到视频合成技术的评估指标主要关注视觉质量和时间一致性，而忽略了其在文本到视频检索等下游任务中的表现。本文旨在填补这一空白，通过构建SynTVA数据集和基准，评估合成视频的实际应用价值。

研究方法: 基于MSRVTT训练集的800个多样化用户查询，使用先进文本到视频模型生成合成视频，并从四个关键语义对齐维度（对象与场景、动作、属性、提示保真度）标注视频-文本对。进一步开发自动评估工具，分析现有指标与对齐分数的相关性及其对检索性能的预测能力。

研究结果: SynTVA不仅为合成视频的实用性提供了基准，还展示了其在数据集增强中的价值，能够筛选高质量合成样本显著提升文本到视频检索性能。

研究结论: SynTVA为合成视频的评估和应用提供了新视角，证明其在提升下游任务性能方面的潜力，并为未来研究提供了重要工具。

中文摘要: 文本到视频（T2V）合成技术发展迅速，但当前的评估指标主要关注视觉质量和时间一致性，对合成视频在文本到视频检索（TVR）等下游任务中的表现缺乏深入洞察。为此，我们提出了SynTVA，一个用于评估合成视频在构建检索模型中的实用性的新数据集和基准。基于MSRVTT训练集的800个多样化用户查询，我们使用先进的T2V模型生成合成视频，并从四个关键语义对齐维度（对象与场景、动作、属性、提示保真度）对每个视频-文本对进行标注。我们的评估框架将通用视频质量评估（VQA）指标与这些对齐分数相关联，并分析其对下游TVR性能的预测能力。为进一步探索扩展路径，我们还开发了一个自动评估工具，用于从现有指标中估计对齐质量。除了基准测试，我们的结果表明，SynTVA是数据集增强的重要资源，能够筛选出高实用性的合成样本，显著提升TVR效果。项目页面和数据集详见https://jasoncodemaker.github.io/SynTVA/。

</details>


### [49] [Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback](https://arxiv.org/abs/2507.02321)
**中文标题：倾听内部声音：通过中间特征反馈对齐ControlNet训练**

*Nina Konovalova,Maxim Nikolaev,Andrey Kuznetsov,Aibek Alanov*

主要分类: cs.CV

摘要简述: 本文提出InnerControl训练策略，通过在所有扩散步骤中强制空间一致性，提升文本到图像扩散模型的空间控制精度。


<details>
  <summary>详细信息</summary>
研究动机: 尽管文本到图像扩散模型取得显著进展，但如何精确控制生成输出的空间布局仍具挑战性。现有方法如ControlNet++仅关注最终去噪步骤的循环一致性损失，忽略了中间生成阶段，限制了其效果。

研究方法: InnerControl通过训练轻量级卷积探针，从每个去噪步骤的中间UNet特征中重建输入控制信号（如边缘、深度），并利用这些信号作为伪真实控制条件。通过在整个扩散过程中最小化预测与目标条件之间的差异，实现空间一致性。

研究结果: 结合ControlNet++等技术，InnerControl在多种条件方法（如边缘、深度）上实现了最先进的性能，显著提升了控制保真度和生成质量。

研究结论: InnerControl通过全局对齐损失，有效解决了中间生成阶段的控制问题，为文本到图像扩散模型提供了更精确的空间控制能力。

中文摘要: 尽管文本到图像扩散模型取得了显著进展，但如何精确控制生成输出的空间布局仍具挑战性。ControlNet通过引入辅助条件模块解决这一问题，而ControlNet++则通过仅在最终去噪步骤应用循环一致性损失进一步优化对齐效果。然而，这种方法忽略了中间生成阶段，限制了其有效性。我们提出InnerControl，一种在所有扩散步骤中强制空间一致性的训练策略。该方法训练轻量级卷积探针，从每个去噪步骤的中间UNet特征中重建输入控制信号（如边缘、深度）。这些探针能够高效地从高度噪声的潜在空间中提取信号，为训练提供伪真实控制条件。通过在整个扩散过程中最小化预测与目标条件之间的差异，我们的对齐损失提升了控制保真度和生成质量。结合ControlNet++等现有技术，InnerControl在多种条件方法（如边缘、深度）上实现了最先进的性能。

</details>


### [50] [Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model](https://arxiv.org/abs/2507.02322)
**中文标题：基于神经网络的水稻叶片病害识别与分类研究：特征分析模型与直接图像模型的对比分析**

*Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi*

主要分类: cs.CV

摘要简述: 本研究通过人工神经网络（ANN）比较了基于特征分析的检测模型（FADM）和直接图像中心检测模型（DICDM）在水稻叶片病害识别中的性能，发现FADM表现更优，为水稻病害早期检测提供了有效方法。


<details>
  <summary>详细信息</summary>
研究动机: 水稻叶片病害严重影响产量并造成经济损失，亟需早期检测技术以优化管理和提高产量。现有研究缺乏对基于特征分析的检测模型与直接图像中心检测模型的全面比较，尤其是特征提取算法的有效性评估。

研究方法: 研究采用多种特征提取算法、降维算法、特征选择算法和极限学习机（ELM）构建特征分析检测模型（FADM），并与未使用特征提取算法的直接图像中心检测模型（DICDM）进行对比。实验数据集涵盖多种水稻病害和健康叶片，采用10折交叉验证方法。

研究结果: 实验结果表明，特征分析检测模型（FADM）在分类性能上优于直接图像中心检测模型（DICDM），为水稻病害识别提供了更高效的解决方案。

研究结论: 基于特征分析的检测模型在水稻叶片病害识别中表现最佳，有望提升作物健康管理、减少产量损失，并促进水稻种植的可持续性。

中文摘要: 水稻叶片病害显著降低生产力并造成经济损失，凸显了早期检测以实现有效管理和提高产量的必要性。本研究提出基于人工神经网络（ANN）的图像处理技术，用于水稻病害的及时分类与识别。尽管目前主流方法是将水稻叶片图像直接输入ANN，但缺乏对特征分析检测模型（FADM）与直接图像中心检测模型（DICDM）的全面对比分析，尤其是特征提取算法（FEA）的有效性评估。因此，本研究首次对特征分析检测模型进行了实验，采用了多种图像特征提取算法、降维算法（DRA）、特征选择算法（FSA）和极限学习机（ELM）。实验数据集涵盖细菌性叶枯病、褐斑病、叶瘟病、叶枯病、纹枯病和健康叶片，并采用10折交叉验证方法。同时，建立了未使用任何特征提取算法的直接图像中心检测模型，并通过不同指标评估分类性能。最终，对特征分析检测模型与直接图像中心检测模型在水稻叶片病害分类中的表现进行了详尽对比。结果显示，特征分析检测模型取得了最高性能。采用所提出的特征分析检测模型检测水稻叶片病害，有望显著改善作物健康、减少产量损失，并提升水稻种植的整体生产力和可持续性。

</details>


### [51] [Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection](https://arxiv.org/abs/2507.02349)
**中文标题：基于两步神经网络的自动化脑血管标志检测**

*Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau*

主要分类: cs.CV

摘要简述: 本文提出了一种基于两步神经网络的自动化脑血管标志检测方法，通过目标检测网络和改良U-Net结合，显著提高了颅内动脉瘤关键分叉点的检测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 颅内动脉瘤（ICA）常发生在Willis环（CoW）的特定分叉处，准确检测这些关键标志对快速诊断至关重要。现有方法在标志密集或视觉特征相似时容易漏检，且CoW的解剖变异性增加了检测难度。

研究方法: 方法分为两步：首先使用目标检测网络定位感兴趣区域（ROIs），随后利用改良的U-Net结合深度监督精确定位分叉点。该方法解决了标志密集和视觉相似性问题，并适应了CoW的解剖变异性。

研究结果: 实验结果表明，该方法在两个脑MRA数据集（内部数据集和公共数据集）上均表现出色，在分叉点检测任务中达到了最高性能水平。

研究结论: 本文提出的两步神经网络方法显著提升了脑血管标志检测的准确性和鲁棒性，为颅内动脉瘤的自动化诊断提供了有效工具。

中文摘要: 颅内动脉瘤（ICA）通常发生在Willis环（CoW）的特定节段，主要集中在13个主要动脉分叉处。准确检测这些关键标志对快速高效诊断至关重要。本文提出了一种完全自动化的CoW分叉标志检测方法，采用两步神经网络流程。首先，目标检测网络识别靠近标志位置的感兴趣区域（ROIs）；随后，利用改良的U-Net结合深度监督精确定位分叉点。这种两步方法减少了多种问题，例如因两个标志距离过近且视觉特征相似而导致的漏检，尤其是在处理完整的MRA Time-of-Flight（TOF）数据时。此外，该方法还考虑了CoW的解剖变异性，这会影响每次扫描中可检测到的标志数量。我们使用两个脑MRA数据集评估了方法的有效性：一个是标志数量可变的内部数据集，另一个是具有标准化标志配置的公共数据集。实验结果表明，我们的方法在分叉点检测任务中达到了最高性能水平。

</details>


### [52] [Lightweight Shrimp Disease Detection Research Based on YOLOv8n](https://arxiv.org/abs/2507.02354)
**中文标题：基于YOLOv8n的轻量级虾病检测研究**

*Fei Yuhuan,Wang Gengchen,Liu Fenghao,Zang Ran,Sun Xufei,Chang Hao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于YOLOv8n的轻量级网络架构，用于虾病检测。通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度，并引入改进的SegNext_Attention自注意力机制提升特征提取能力。实验表明，模型参数减少32.3%，mAP@0.5达92.7%，优于其他轻量级YOLO系列模型。


<details>
  <summary>详细信息</summary>
研究动机: 虾病是虾类养殖中经济损失的主要原因之一。为提高虾病智能检测效率并预防疾病传播，本文旨在设计一种轻量化的检测模型，以平衡检测精度与计算效率。

研究方法: 1. 设计RLDD检测头和C2f-EMCM模块，降低计算复杂度；2. 引入改进的SegNext_Attention自注意力机制，增强特征提取能力；3. 在自建虾病数据集和URPC2020数据集上进行实验验证。

研究结果: 模型参数减少32.3%，mAP@0.5达92.7%（比YOLOv8n提升3%），在URPC2020数据集上mAP@0.5比YOLOv8n提升4.1%，优于其他轻量级YOLO系列模型。

研究结论: 该方法在精度与效率间实现了最优平衡，为虾类养殖的智能疾病检测提供了可靠技术支持。

中文摘要: 虾病是虾类养殖中经济损失的主要原因之一。为预防疾病传播并提升虾类养殖中的智能检测效率，本文提出了一种基于YOLOv8n的轻量级网络架构。首先，通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度，提高了计算效率。随后，引入改进的SegNext_Attention自注意力机制，进一步增强了模型的特征提取能力，从而更精准地识别疾病特征。在自建虾病数据集上进行了大量实验，包括消融研究和对比评估，并将泛化测试扩展到URPC2020数据集。结果表明，所提模型参数比原始YOLOv8n减少了32.3%，mAP@0.5达92.7%（比YOLOv8n提升3%）。此外，该模型在mAP@0.5、参数数量和模型大小上均优于其他轻量级YOLO系列模型。在URPC2020数据集上的泛化实验进一步验证了模型的鲁棒性，mAP@0.5比YOLOv8n提升了4.1%。该方法在精度与效率间实现了最优平衡，为虾类养殖的智能疾病检测提供了可靠技术支持。

</details>


### [53] [Holistic Tokenizer for Autoregressive Image Generation](https://arxiv.org/abs/2507.02358)
**中文标题：用于自回归图像生成的整体分词器**

*Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Hita的新型图像分词器，用于自回归图像生成。Hita通过全局到局部的分词方案和轻量级融合模块，显著提升了训练速度和生成质量，在ImageNet基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统的自回归图像生成模型逐步生成视觉标记，限制了捕捉标记序列间全局关系的能力。此外，现有视觉分词器通常将局部图像块映射为潜在标记，导致全局信息不足。因此，本文旨在设计一种能够更好地捕捉全局图像特性的分词器。

研究方法: Hita采用了一种全局到局部的分词方案，结合可学习的全局查询和局部块标记。其关键策略包括：1）在序列结构中优先排列全局标记，随后是块级标记，并使用因果注意力保持对先前标记的感知；2）在解码前通过轻量级融合模块控制信息流，优先处理全局标记。

研究结果: 实验表明，Hita显著提升了自回归生成器的训练速度，并在ImageNet基准测试中取得了2.59 FID和281.9 IS的优异表现。此外，Hita还能有效捕捉全局图像特性（如纹理、材质和形状），并在零样本风格迁移和图像修复任务中表现出色。

研究结论: Hita通过全局到局部的分词方案和轻量级融合模块，显著提升了自回归图像生成的效率和质量，同时展示了在多种下游任务中的潜力。

中文摘要: 传统的自回归图像生成模型逐步生成视觉标记，限制了捕捉标记序列间全局关系的能力。此外，大多数视觉分词器将局部图像块映射为潜在标记，导致全局信息不足。为此，我们提出了Hita，一种新型的自回归图像生成分词器。它采用了一种全局到局部的分词方案，结合可学习的全局查询和局部块标记。Hita还引入了两项关键策略以更好地与自回归生成过程对齐：1）在序列结构中优先排列全局标记，随后是块级标记，并使用因果注意力保持对先前标记的感知；2）在解码前通过轻量级融合模块控制信息流，优先处理全局标记。大量实验表明，Hita显著提升了自回归生成器的训练速度，并在ImageNet基准测试中取得了2.59 FID和281.9 IS的优异表现。对全局表征的详细分析表明，Hita能够有效捕捉纹理、材质和形状等全局图像特性。此外，Hita在零样本风格迁移和图像修复任务中也表现出色。代码已开源：https://github.com/CVMI-Lab/Hita。

</details>


### [54] [LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling](https://arxiv.org/abs/2507.02363)
**中文标题：LocalDyGS：通过自适应局部隐式特征解耦的多视角全局动态场景建模**

*Jiahao Wu,Rui Peng,Jianbo Jiao,Jiayu Yang,Luyang Tang,Kaiqiang Xiong,Jie Liang,Jinbo Yan,Runling Liu,Ronggang Wang*

主要分类: cs.CV

摘要简述: LocalDyGS提出了一种新的动态场景建模方法，通过分解局部空间和解耦静态与动态特征，实现了对复杂动态场景的高效建模，适用于大范围和小范围运动场景。


<details>
  <summary>详细信息</summary>
研究动机: 由于现实世界中动态运动的复杂性，从多视角输入合成任意视角的动态视频具有挑战性。现有方法在建模精细运动方面受限，难以应用于大范围动态场景。

研究方法: 方法包括两部分：1) 将复杂动态场景分解为由种子定义的局部空间，通过捕获局部空间内的运动实现全局建模；2) 解耦静态与动态特征，静态特征捕捉静态信息，动态残差场提供时间特定特征，结合后生成时间高斯模型以建模局部运动。

研究结果: LocalDyGS在精细运动数据集上表现优异，同时首次成功建模更大、更复杂的高度动态场景。

研究结论: LocalDyGS为动态场景重建提供了一种新颖框架，能够更真实地建模高度动态的现实场景。

中文摘要: 由于现实世界中复杂且高度动态的运动，从多视角输入合成任意视角的动态视频具有挑战性。基于神经辐射场或3D高斯点云的先前工作局限于建模精细运动，极大地限制了其应用。本文提出LocalDyGS，包含两部分以适应大范围和小范围运动场景：1) 将复杂动态场景分解为由种子定义的局部空间，通过捕获局部空间内的运动实现全局建模；2) 解耦静态与动态特征，静态特征捕捉静态信息，动态残差场提供时间特定特征，结合后生成时间高斯模型以建模局部运动。因此，我们提出了一种新颖的动态场景重建框架，能够更真实地建模高度动态的现实场景。我们的方法不仅在多种精细运动数据集上表现出与最先进方法竞争的性能，还首次尝试建模更大、更复杂的高度动态场景。项目页面：https://wujh2001.github.io/LocalDyGS/。

</details>


### [55] [UVLM: Benchmarking Video Language Model for Underwater World Understanding](https://arxiv.org/abs/2507.02373)
**中文标题：UVLM：水下世界理解的视频语言模型基准**

*Xizhe Xue,Yang Zhou,Dawei Yan,Ying Li,Haokui Zhang,Rong Xiao*

主要分类: cs.CV

摘要简述: 本文提出了UVLM，一个专注于水下世界理解的视频语言模型基准，通过结合人类专业知识和AI模型构建数据集，解决了水下环境的独特挑战，并在实验中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频语言模型主要关注陆地场景，忽视了水下观测的高需求应用。为填补这一空白，本文提出了UVLM基准，旨在推动水下世界理解的研究。

研究方法: 通过结合人类专家和AI模型，构建了一个包含典型水下挑战（如光线变化、水质浑浊和多视角）的数据集。数据集涵盖多种帧率、分辨率、419类海洋生物及静态植物和地形。任务设计分为生物和环境两大类，每类包括内容观察和变化/动作观察，共20种任务类型。

研究结果: 实验表明，在UVLM上微调的视频语言模型显著提升了水下世界理解能力，同时对现有空中视频基准（如VideoMME和Perception text）也有轻微改进潜力。

研究结论: UVLM为水下世界理解提供了首个基准，展示了其在实际应用中的潜力，未来将公开数据集和提示工程。

中文摘要: 近年来，大型语言模型（LLMs）的成功对人工智能领域产生了深远影响。基于LLMs的众多先进工作被提出并应用于各种场景，其中视频语言模型（VidLMs）尤为广泛使用。然而，现有工作主要关注陆地场景，忽视了水下观测的高需求应用。为填补这一空白，我们提出了UVLM，一个通过结合人类专业知识和AI模型构建的水下观测基准。为确保数据质量，我们从多角度进行了深入考量：首先，针对水下环境的独特挑战，选择了包含光线变化、水质浑浊和多视角的典型视频构建数据集；其次，为保障数据多样性，数据集覆盖了多种帧率、分辨率、419类海洋生物及静态植物和地形；接着，为任务多样性，采用了结构化设计，将观测目标分为生物和环境两大类，每类包括内容观察和变化/动作观察，共20种任务类型；最后，设计了多项挑战性评估指标以实现不同方法的定量比较和分析。在两个代表性VidLMs上的实验表明，在UVLM上微调的VidLMs显著提升了水下世界理解能力，同时对现有空中视频基准（如VideoMME和Perception text）也有轻微改进潜力。数据集和提示工程将公开发布。

</details>


### [56] [PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection](https://arxiv.org/abs/2507.02393)
**中文标题：PLOT：基于视频目标跟踪的可扩展单目3D目标检测伪标签方法**

*Seokyeong Lee,Sithu Aung,Junyong Choi,Seungryong Kim,Ig-Jae Kim,Junghyun Cho*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视频目标跟踪的伪标签框架（PLOT），用于解决单目3D目标检测中的数据稀缺问题，无需多视角设置或额外传感器，显著提升了检测的鲁棒性和可扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 单目3D目标检测（M3OD）因标注成本高和2D到3D的固有模糊性而面临数据稀缺问题。现有弱监督或伪标签方法多受限于领域特定学习或单帧形状信息，本文旨在提出一种更通用且鲁棒的解决方案。

研究方法: 通过视频数据中的目标点跟踪技术，聚合静态和动态对象的伪LiDAR信息，实现跨帧的3D属性提取，无需多视角设置、额外传感器或相机位姿。

研究结果: 实验表明，该方法在单目3D目标检测中表现出可靠的精度和强可扩展性，适用于3D数据难以获取的场景。

研究结论: PLOT框架为单目3D目标检测提供了一种实用且高效的解决方案，显著提升了检测性能和数据利用率。

中文摘要: 单目3D目标检测（M3OD）长期以来因高标注成本和2D到3D的固有模糊性而面临数据稀缺问题。尽管已有多种弱监督和伪标签方法试图解决这些问题，但它们大多受限于领域特定学习或仅依赖单帧形状信息。本文提出了一种新颖的伪标签框架，仅需视频数据且对遮挡更鲁棒，无需多视角设置、额外传感器、相机位姿或领域特定训练。具体而言，我们探索了一种通过目标点跟踪技术聚合静态和动态对象在时间相邻帧中的伪LiDAR信息的方法，从而在3D数据难以获取的场景中实现3D属性提取。大量实验表明，我们的方法确保了可靠的精度和强可扩展性，为M3OD提供了一种实用且有效的解决方案。

</details>


### [57] [Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis](https://arxiv.org/abs/2507.02395)
**中文标题：基于增强定位的持续多实例学习在病理全切片图像分析中的应用**

*Byung Hyun Lee,Wongi Jeong,Woojae Han,Kyoungbun Lee,Se Young Chun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CoMEL的持续多实例学习框架，用于病理全切片图像的定位和适应性学习，通过高效实例编码、可靠伪标记和遗忘抑制技术，显著提升了持续学习中的性能。


<details>
  <summary>详细信息</summary>
研究动机: 多实例学习（MIL）通过弱标签降低了大规模图像（如病理全切片图像）的标注成本，但其在持续任务中的适应性和定位能力尚未充分研究。现有方法主要针对自然图像，无法直接应用于MIL定位任务。

研究方法: CoMEL框架包含三部分：(1) 分组双重注意力变换器（GDAT）用于高效实例编码；(2) 基于袋原型的伪标记（BPPL）提供可靠实例伪标签；(3) 正交加权低秩适应（OWLoRA）抑制袋和实例分类中的遗忘。

研究结果: 在三个公开WSI数据集上的实验表明，CoMEL在持续MIL设置下，袋级准确率提升高达11.00%，定位准确率提升高达23.4%，显著优于现有方法。

研究结论: CoMEL通过高效编码、可靠伪标记和遗忘抑制技术，为病理全切片图像的持续多实例学习提供了有效解决方案，显著提升了定位和适应性能。

中文摘要: 多实例学习（MIL）通过袋级弱标签显著降低了大规模图像（如病理全切片图像）的标注成本，但其在持续任务中的适应性和定位能力研究较少。现有方法主要针对自然图像，利用预训练模型处理小尺寸块（如16×16）的全局关系，但无法直接应用于MIL定位任务，因其涉及大量大尺寸块（如256×256）且缺乏全局关系（如癌细胞分布）。为此，我们提出了一种持续多实例学习框架CoMEL，包含：(1) 分组双重注意力变换器（GDAT）用于高效实例编码；(2) 基于袋原型的伪标记（BPPL）提供可靠实例伪标签；(3) 正交加权低秩适应（OWLoRA）抑制袋和实例分类中的遗忘。在三个公开WSI数据集上的实验表明，CoMEL在持续MIL设置下，袋级准确率提升高达11.00%，定位准确率提升高达23.4%，显著优于现有方法。

</details>


### [58] [Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection](https://arxiv.org/abs/2507.02398)
**中文标题：超越空间频率：基于像素级时间频率的深度伪造视频检测**

*Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于像素级时间频率的深度伪造视频检测方法，通过捕捉传统空间频率检测器忽略的时间不一致性，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统深度伪造视频检测方法主要依赖空间频率特征，而忽略了像素级时间不一致性。这些方法无法有效检测时间平面上的伪造痕迹，因此需要一种更全面的检测手段。

研究方法: 本文方法对每个像素在时间轴上进行一维傅里叶变换，提取对时间不一致性高度敏感的特征。同时，引入注意力提议模块精确定位时间伪造区域，并通过联合变换模块整合像素级时间频率特征与时空上下文特征。

研究结果: 实验表明，该方法在多种复杂检测场景中表现出色，能够有效捕捉传统方法难以发现的伪造痕迹，显著提升了检测准确性和鲁棒性。

研究结论: 本文提出的基于像素级时间频率的检测框架为深度伪造视频检测提供了新的思路，具有广泛的应用前景。

中文摘要: 我们提出了一种深度伪造视频检测方法，该方法利用像素级时间不一致性，而传统基于空间频率的检测器往往忽略了这一点。传统检测器仅通过跨帧堆叠空间频率谱来表示时间信息，导致无法检测像素平面上的时间伪造痕迹。我们的方法对每个像素在时间轴上进行一维傅里叶变换，提取对时间不一致性高度敏感的特征，尤其是在容易出现不自然运动的区域。为了精确定位包含时间伪造痕迹的区域，我们引入了一种端到端训练的注意力提议模块。此外，我们的联合变换模块有效地将像素级时间频率特征与时空上下文特征相结合，扩展了可检测伪造痕迹的范围。我们的框架代表了深度伪造视频检测领域的重大进展，在多样化和具有挑战性的检测场景中提供了鲁棒的性能。

</details>


### [59] [TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation](https://arxiv.org/abs/2507.02399)
**中文标题：TABNet：一种基于边界感知伪标签的三重增强自恢复框架用于医学图像分割**

*Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang*

主要分类: cs.CV

摘要简述: TABNet提出了一种基于涂鸦标注的弱监督医学图像分割框架，通过三重增强自恢复模块和边界感知伪标签监督模块，显著提升了分割性能，接近全监督方法的水平。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割需要大量标注数据，但完全标注耗时且昂贵。涂鸦标注作为一种稀疏标注方式虽高效，但其稀疏性和边界监督不足限制了分割网络的性能。

研究方法: TABNet包含三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS通过强度变换、区域遮挡和拼图增强提升特征学习；BAP通过双分支预测融合和边界感知损失优化伪标签和边界建模。

研究结果: 在ACDC和MSCMR seg数据集上的实验表明，TABNet在涂鸦标注的弱监督分割任务中显著优于现有方法，性能接近全监督方法。

研究结论: TABNet通过增强特征学习和边界建模，有效解决了涂鸦标注的稀疏性问题，为弱监督医学图像分割提供了高效解决方案。

中文摘要: 背景与目标：医学图像分割是临床应用中的核心任务，但获取大规模完全标注的医学图像数据集耗时且昂贵。涂鸦标注作为一种稀疏标注方式，为医学图像分割提供了高效且经济的替代方案。然而，涂鸦标注的稀疏性限制了目标区域的特征学习，且缺乏足够的边界监督，对分割网络的训练提出了重大挑战。方法：我们提出了TABNet，一种新颖的弱监督医学图像分割框架，包含两个关键组件：三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS模块通过三种互补的增强策略提升特征学习：强度变换增强模型对纹理和对比度变化的敏感性，区域遮挡迫使网络通过掩码关键区域捕捉局部解剖结构，拼图增强通过破坏空间连续性强化全局解剖布局的建模。通过引导网络从多样化的增强输入中恢复完整掩码，TAS在稀疏监督下促进了对医学图像的更深层次语义理解。BAP模块通过将双分支预测融合为损失加权的伪标签，并引入边界感知损失进行细粒度轮廓优化，提升了伪监督的准确性和边界建模能力。结果：在ACDC和MSCMR seg两个公开数据集上的实验评估表明，TABNet在基于涂鸦的弱监督分割任务中显著优于现有方法，且性能接近全监督方法。

</details>


### [60] [Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings](https://arxiv.org/abs/2507.02403)
**中文标题：非城市环境中基于自监督学习的野生动物目标重识别**

*Mufhumudzi Muthivhi,Terence L. van Zyl*

主要分类: cs.CV

摘要简述: 本文探讨了在非城市环境中利用自监督学习进行野生动物目标重识别的方法，无需标注数据即可从相机陷阱数据中提取特征，实验表明自监督模型在数据有限时表现更优，且在下游任务中优于监督学习。


<details>
  <summary>详细信息</summary>
研究动机: 当前野生动物重识别依赖于标注数据训练监督模型，但标注数据成本高且难以获取。本研究旨在探索自监督学习在野生动物重识别中的应用，以解决对标注数据的依赖问题。

研究方法: 研究利用相机陷阱数据中的时间序列图像对，自动提取个体的两种不同视角，无需监督即可训练自监督模型。模型通过视频数据流学习特征，并在开放世界场景和下游任务中评估其性能。

研究结果: 实验结果表明，自监督模型在数据有限时表现更稳健，且在所有下游任务中的特征表现优于监督学习模型。

研究结论: 自监督学习为野生动物重识别提供了一种高效且无需标注数据的解决方案，其性能优于传统监督学习方法，具有广泛应用潜力。

中文摘要: 野生动物重识别的目标是在不同观测中匹配同一物种的个体。当前最先进的模型依赖于类别标签训练监督模型进行个体分类，这种对标注数据的依赖促使了大规模野生动物数据集的构建。本研究探讨了自监督学习在野生动物重识别中的应用。我们利用相机陷阱数据中的时间序列图像对，无需监督即可自动提取个体的两种不同视角。这些图像对用于训练自监督模型，模型可从潜在无限的视频数据流中学习。我们在开放世界场景和各种野生动物下游任务中评估了学习到的特征与监督特征的性能。实验结果表明，自监督模型在数据有限时表现更稳健，且在所有下游任务中的特征表现优于监督学习。代码可在https://github.com/pxpana/SSLWildlife获取。

</details>


### [61] [PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration](https://arxiv.org/abs/2507.02405)
**中文标题：PosDiffAE：融合伪影修复的高分辨率脑组织分类位置感知扩散自编码器**

*Ayantika Das,Moitreya Chaudhuri,Koushik Bhat,Keerthi Ram,Mihail Bota,Mohanasankar Sivaprakasam*

主要分类: cs.CV

摘要简述: 本文提出了一种结合扩散模型和自编码器的PosDiffAE方法，用于高分辨率脑组织分类及伪影修复，通过位置感知和潜在空间结构化提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型虽能生成高质量图像，但缺乏提取图像语义表示的能力；而自编码器能提供明确的潜在空间结构。本文旨在结合两者优势，实现脑组织分类和伪影修复。

研究方法: 1. 设计扩散自编码模型，通过回归高分辨率图像块的位置信息结构化潜在空间；2. 提出基于邻域感知的无监督撕裂伪影修复技术；3. 利用扩散模型的可控生成能力实现无监督JPEG伪影修复。

研究结果: PosDiffAE成功实现了脑组织分类的高精度，并通过潜在空间结构化和伪影修复技术提升了图像质量。

研究结论: PosDiffAE通过结合扩散模型和自编码器，不仅提升了脑组织分类的准确性，还实现了无监督伪影修复，为医学图像分析提供了新思路。

中文摘要: 去噪扩散模型通过逐步捕获图像分布生成高保真图像样本，但其采样机制无法提取图像特定的语义表示，而自编码器则能提供明确的潜在空间映射。本文通过将编码器与扩散模型结合，提出了一种自编码框架，学习图像特定表示并组织潜在空间。首先，我们设计了一种机制，用于结构化扩散自编码模型的潜在空间，以识别脑图像中的区域特异性细胞模式。通过回归高分辨率图像块的位置信息，为区分脑组织类型创造了有利的潜在空间。其次，基于邻域感知，利用潜在表示和扩散模型在推理时的受限生成能力，提出了一种无监督撕裂伪影修复技术。第三，通过表示引导和扩散模型在推理时的可控噪声与去噪能力，设计了一种无监督JPEG伪影修复方法。

</details>


### [62] [A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern](https://arxiv.org/abs/2507.02408)
**中文标题：一种利用热传感器处理复杂运动模式的实时多目标追踪新调谐方法**

*Duong Nguyen-Ngoc Tran,Long Hoang Pham,Chi Dai Tran,Quoc Pham-Nam Ho,Huy-Hung Nguyen,Jae Wook Jeon*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的调谐方法，用于热成像中的多目标实时追踪，通过优化两阶段框架和超参数，显著提升了复杂运动模式下的追踪性能。


<details>
  <summary>详细信息</summary>
研究动机: 热成像传感器在低能见度或弱光环境下优于RGB摄像头，但其低层次特征表示导致行人检测和追踪困难。本文旨在解决这一问题，提升热成像中的多目标追踪性能。

研究方法: 提出了一种两阶段调谐框架，通过优化每个阶段的超参数，无需依赖复杂的重识别或运动模型，即可实现高精度的实时追踪。

研究结果: 在PBVS Thermal MOT数据集上的实验表明，该方法在各种热成像条件下均表现出色，适用于实际监控应用。

研究结论: 该方法为热成像中的多目标追踪提供了一种高效且鲁棒的解决方案，特别适合复杂运动模式的场景。

中文摘要: 热成像中的多目标追踪对监控系统至关重要，尤其是在RGB摄像头因能见度低或光线不足而难以工作的环境中。热传感器通过捕捉红外信号增强了识别任务，但其低层次特征表示使得行人检测和追踪变得困难。为此，本文提出了一种新颖的行人追踪调谐方法，专门用于处理热成像中的复杂运动模式。所提出的框架优化了两阶段调谐，确保每个阶段使用最适合的超参数以最大化追踪性能。通过为实时追踪微调超参数，该方法在不依赖复杂重识别或运动模型的情况下实现了高精度。在PBVS Thermal MOT数据集上的大量实验表明，该方法在各种热成像条件下均表现出色，为实际监控应用提供了鲁棒的解决方案。

</details>


### [63] [Privacy-preserving Preselection for Face Identification Based on Packing](https://arxiv.org/abs/2507.02414)
**中文标题：基于打包的隐私保护人脸识别预选方案**

*Rundong Xin,Taotao Wang,Jin Wang,Chonghe Zhao,Jing Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于打包的隐私保护人脸识别预选方案（PFIP），通过创新的预选机制和打包模块，显著提高了密文域中人脸检索的效率，同时保持了原始模型的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着隐私问题日益突出和原始人脸数据可能被恢复的风险，密文域中的人脸识别系统受到广泛关注。然而，随着密文模板库规模的扩大，人脸检索过程变得耗时。本文旨在解决这一效率问题。

研究方法: PFIP方案结合了创新的预选机制以减少计算开销，并通过打包模块提升生物识别系统在注册阶段的灵活性。

研究结果: 在LFW和CASIA数据集上的实验表明，PFIP在保持原始人脸识别模型准确性的同时，能在300毫秒内检索1000个密文人脸模板，命中率达100%，检索效率比现有方法提升近50倍。

研究结论: PFIP通过高效的预选和打包机制，显著提升了密文域中人脸识别的检索效率，同时确保了隐私保护和系统灵活性。

中文摘要: 由于隐私问题日益突出以及原始人脸数据可能被恢复的风险，密文域中的人脸识别系统受到广泛关注。然而，随着密文模板库规模的扩大，人脸检索过程变得耗时。为解决这一问题，我们提出了一种新颖且高效的密文域人脸检索方案，称为基于打包的隐私保护人脸识别预选方案（PFIP）。PFIP通过创新的预选机制减少计算开销，并通过打包模块提升生物识别系统在注册阶段的灵活性。在LFW和CASIA数据集上的大量实验表明，PFIP在保持原始人脸识别模型准确性的同时，能在300毫秒内检索1000个密文人脸模板，命中率达100%。与现有方法相比，PFIP的检索效率提升了近50倍。

</details>


### [64] [Determination Of Structural Cracks Using Deep Learning Frameworks](https://arxiv.org/abs/2507.02416)
**中文标题：基于深度学习框架的结构裂缝检测**

*Subhasis Dasgupta,Jaydip Sen,Tuhina Halder*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的结构裂缝检测方法，通过残差U-Net模型和集成学习技术，显著提高了检测精度和效率，尤其在低分辨率图像中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 结构裂缝检测对公共安全至关重要，但传统人工检测效率低且易出错。本研究旨在利用深度学习技术提升检测的准确性和可靠性。

研究方法: 研究采用了残差U-Net模型的多种配置，并将其集成到一个包含卷积块的元模型中，以提升预测效率。模型性能通过IoU和DICE系数进行评估。

研究结果: 实验表明，残差U-Net模型在低分辨率图像中表现优于传统模型，集成模型的性能更是超越单一模型，取得了最高的IoU和DICE分数。

研究结论: 该研究为结构缺陷监测任务提供了更可靠的自动化解决方案，证明了集成深度学习模型的有效性。

中文摘要: 结构裂缝检测是保障公共安全的关键任务，能够预防潜在的结构性故障。然而，人工检测效率低且易出错，影响评估的可靠性。本研究提出了一种新型深度学习架构，旨在提高结构裂缝检测的准确性和效率。研究中采用了多种残差U-Net模型配置，并将其集成到一个包含卷积块的元模型中，以进一步提升预测效率。该集成模型的性能与SegNet和传统U-Net等成熟架构进行了对比。结果显示，残差U-Net模型在低分辨率图像中表现更优，而集成模型的性能超越了单一模型，成为最有效的解决方案。评估基于IoU和DICE系数，集成模型取得了最高分，表明其具有更高的准确性。这一进展为结构缺陷监测任务提供了更可靠的自动化系统。

</details>


### [65] [AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars](https://arxiv.org/abs/2507.02419)
**中文标题：AvatarMakeup：面向3D可动画化头部虚拟化身的逼真化妆转移**

*Yiming Zhong,Xiaolin Zhang,Ligang Liu,Yao Zhao,Yunchao Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为AvatarMakeup的3D化妆方法，通过预训练的扩散模型从单张参考照片中转移化妆效果，解决了现有方法在动态表情和多视角下化妆效果不一致的问题。


<details>
  <summary>详细信息</summary>
研究动机: 3D虚拟头像需要个性化定制以提升视觉吸引力，但现有方法无法满足动态表情和多视角下化妆效果的一致性、身份保持以及细节精确控制的需求。

研究方法: AvatarMakeup采用从粗到细的策略，首先通过Coherent Duplication方法粗粒度地应用化妆并确保一致性，然后通过Refinement Module进一步优化细节。扩散模型用于生成化妆图像作为监督。

研究结果: 实验表明，AvatarMakeup在化妆转移质量和动画一致性方面达到了最先进水平。

研究结论: AvatarMakeup通过创新的粗到细策略和扩散模型，成功实现了高质量的3D化妆转移，为虚拟头像的个性化定制提供了有效解决方案。

中文摘要: 与现实中的面部美化类似，3D虚拟化身需要个性化定制以提升视觉吸引力，但这一领域尚未得到充分探索。尽管当前的3D高斯编辑方法可以用于面部化妆，但这些方法无法满足实现逼真化妆效果的基本要求：1）在可驱动的表情中保持一致性，2）在化妆过程中保持身份不变，3）实现对精细细节的精确控制。为此，我们提出了一种名为AvatarMakeup的专用3D化妆方法，利用预训练的扩散模型从任意个体的单张参考照片中转移化妆图案。我们采用从粗到细的思路，首先保持外观和身份的一致性，然后优化细节。具体而言，扩散模型用于生成化妆图像作为监督。由于扩散过程中的不确定性，生成的图像在不同视角和表情下不一致。因此，我们提出了一种Coherent Duplication方法，粗粒度地将化妆应用于目标，同时确保动态和多视角效果的一致性。Coherent Duplication通过记录生成的化妆图像中的平均面部属性来优化全局UV贴图。通过查询全局UV贴图，可以轻松合成任意视角和表情下的一致性化妆指导，以优化目标化身。在获得粗粒度化妆化身后，我们进一步通过将Refinement Module集成到扩散模型中，提升化妆质量。实验表明，AvatarMakeup在化妆转移质量和动画一致性方面达到了最先进水平。

</details>


### [66] [F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning](https://arxiv.org/abs/2507.02437)
**中文标题：F²TTA：基于图像级解耦提示调谐的跨域医学图像分类自由形式测试时适应**

*Wei Li,Jingyang Zhang,Lihao Liu,Guoan Wang,Junjun He,Yang Chen,Lixu Gu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为F²TTA的自由形式测试时适应方法，通过图像级解耦提示调谐解决跨域医学图像分类问题。该方法利用图像不变提示和图像特定提示应对不可预测的域偏移，并结合不确定性导向掩码和平行图蒸馏提升性能。实验表明其在乳腺癌和青光眼分类任务中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 测试时适应（TTA）在医学图像分类中具有潜力，但现有方法假设数据以完整域单元到达，而实际临床数据通常以任意长度和随机顺序的域片段形式出现。这种自由形式的数据流可能导致不可预测的域偏移，从而干扰模型适应过程。本文旨在解决这一问题。

研究方法: 提出图像级解耦提示调谐（I-DiPT）框架，包含图像不变提示和图像特定提示。通过不确定性导向掩码（UoM）提取足够信息，并结合平行图蒸馏（PGD）复用历史提示知识。

研究结果: 在乳腺癌和青光眼分类任务中，F²TTA方法显著优于现有TTA方法，证明了其在自由形式测试时适应场景中的有效性。

研究结论: F²TTA通过解耦提示调谐和知识复用，成功应对了自由形式数据流中的不可预测域偏移，为跨域医学图像分类提供了一种实用解决方案。

中文摘要: 测试时适应（TTA）是一种利用未标注测试数据将源模型适应到未见医学站点的有前景方法，因其数据标注成本高。现有TTA方法假设数据以一个或多个完整域单元到达，但临床实践中数据通常以任意长度和随机顺序的域片段形式出现。本文研究了一种实用的自由形式测试时适应（F²TTA）任务，源模型需适应此类自由形式域片段，且片段间偏移不可预测。这些偏移可能干扰适应过程。为解决此问题，我们提出了一种新颖的图像级解耦提示调谐（I-DiPT）框架。I-DiPT使用图像不变提示探索域不变表示以缓解不可预测偏移，并使用图像特定提示将源模型适应到每个测试图像。由于仅有一张图像可用于训练，提示可能知识表示不足。为此，我们首先引入不确定性导向掩码（UoM），通过基于源模型表示不确定性的掩码一致性学习，鼓励提示从输入图像中提取足够信息。然后，我们进一步提出平行图蒸馏（PGD）方法，通过平行图网络复用历史图像特定和图像不变提示的知识。在乳腺癌和青光眼分类任务上的实验表明，我们的方法在F²TTA中优于现有TTA方法。代码见https://github.com/mar-cry/F2TTA。

</details>


### [67] [Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic](https://arxiv.org/abs/2507.02443)
**中文标题：在FPGA可编程逻辑中加速人工神经网络的红葡萄检测**

*Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias*

主要分类: cs.CV

摘要简述: 本研究利用FPGA的可编程逻辑加速人工神经网络（ANN），特别是MobileNet v1、CNV和BNN模型，以提升机器人检测红葡萄的速度和效率。MobileNet v1表现最佳，达到98%的成功率和6611 FPS的推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 机器人在移动检测物体时通常因算法速度限制而降低效率，且摄像头帧率受限。AMD的Vitis-AI框架未能充分利用FPGA的可编程逻辑（PL），因此本研究探索如何通过FINN架构在FPGA中部署ANN以解决这一问题。

研究方法: 使用FINN架构在FPGA的可编程逻辑中部署三种ANN模型：4位量化的MobileNet v1、2位量化的CNV和1位量化的BNN。模型在自采集的RG2C数据集上训练。

研究结果: MobileNet v1表现最佳，成功率达98%，推理速度为6611 FPS，证明了FPGA在加速ANN方面的潜力。

研究结论: 本研究证实了FPGA可用于加速ANN，使其适用于注意力机制等任务，显著提升机器人检测效率。

中文摘要: 机器人在移动检测物体时通常会因算法速度限制而降低效率，同时摄像头的低帧率也限制了检测算法的跟踪速度。AMD开发的Vitis-AI框架虽能将检测算法部署到FPGA中，但未能充分利用FPGA的可编程逻辑（PL）。本研究采用FINN架构，在FPGA的PL中部署了三种ANN模型：4位量化的MobileNet v1、2位量化的CNV和1位量化的BNN（二值神经网络）。这些模型在自采集的RG2C数据集上训练。结果显示，MobileNet v1表现最佳，成功率达98%，推理速度为6611 FPS。本研究证明，FPGA可用于加速ANN，使其适用于注意力机制等任务。

</details>


### [68] [From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding](https://arxiv.org/abs/2507.02790)
**中文标题：从长视频到吸引人的片段：一种基于多模态叙事理解的人类启发式视频编辑框架**

*Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种受人类启发的自动视频编辑框架（HIVE），通过多模态叙事理解，将长视频转化为简洁且吸引人的片段。该方法结合角色提取、对话分析和叙事摘要，显著提升了编辑质量，并在实验中优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 随着在线视频内容的快速增长，尤其是短视频平台的兴起，对高效视频编辑技术的需求日益增加。现有自动编辑方法主要依赖文本线索，忽略了丰富的视觉上下文，导致输出不连贯。本文旨在解决这一问题。

研究方法: 提出HIVE框架，利用多模态大语言模型进行角色提取、对话分析和叙事摘要，实现视频内容的全面理解。通过场景级分割和分解编辑任务（高光检测、开头/结尾选择、无关内容修剪）提升连贯性。

研究结果: 实验结果表明，HIVE在通用和广告导向的编辑任务中均优于现有基线，显著缩小了自动编辑与人工编辑视频的质量差距。

研究结论: HIVE框架通过多模态叙事理解，有效提升了自动视频编辑的质量，为相关研究提供了新方向。

中文摘要: 在线视频内容的快速增长，尤其是短视频平台的兴起，催生了对高效视频编辑技术的需求，这些技术能够将长视频压缩为简洁且吸引人的片段。现有的自动编辑方法主要依赖ASR转录的文本线索和端到端片段选择，往往忽略了丰富的视觉上下文，导致输出不连贯。本文提出了一种受人类启发的自动视频编辑框架（HIVE），通过多模态叙事理解解决这些局限性。我们的方法结合了角色提取、对话分析和叙事摘要，利用多模态大语言模型实现对视频内容的全面理解。为进一步提升连贯性，我们采用场景级分割，并将编辑过程分解为三个子任务：高光检测、开头/结尾选择以及无关内容修剪。为促进该领域的研究，我们引入了DramaAD，一个包含800多集短剧和500个专业编辑广告片段的新基准数据集。实验结果表明，我们的框架在通用和广告导向的编辑任务中均优于现有基线，显著缩小了自动编辑与人工编辑视频的质量差距。

</details>


### [69] [IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising](https://arxiv.org/abs/2507.02445)
**中文标题：IGDNet：基于光照引导与去噪的零样本鲁棒欠曝光图像增强**

*Hailong Yan,Junjian Huang,Tingwen Huang*

主要分类: cs.CV

摘要简述: IGDNet是一种零样本增强方法，无需训练数据即可恢复欠曝光图像，通过分解和去噪模块有效提升光照并抑制噪声，在复杂光照条件下显著优于现有无监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖成对数据集且可能导致过增强问题，而IGDNet旨在通过零样本方式解决这些问题，无需先验或训练数据。

研究方法: IGDNet包含分解模块和去噪模块：前者通过密集连接网络分离图像的光照和反射分量，后者利用光照引导的像素自适应校正方法增强非均匀光照区域，并通过迭代优化生成最终结果。

研究结果: 在四个公开数据集上的实验表明，IGDNet在PSNR（20.41dB）和SSIM（0.860dB）指标上显著优于14种先进无监督方法，视觉质量提升明显。

研究结论: IGDNet通过零样本方式有效恢复欠曝光图像，具有强泛化能力和噪声抑制效果，适用于复杂光照条件。

中文摘要: 当前修复欠曝光图像的方法通常依赖于成对的欠曝光和良好光照图像的监督学习，但在实际场景中收集此类数据集往往不切实际。此外，这些方法可能导致过增强，破坏良好光照区域。为解决这些问题，我们提出了IGDNet，一种零样本增强方法，仅需单张测试图像，无需先验或训练数据。IGDNet展现出强大的泛化能力，并在恢复光照的同时有效抑制噪声。该框架包含分解模块和去噪模块：前者通过密集连接网络将图像分离为光照和反射分量，后者利用光照引导的像素自适应校正方法增强非均匀光照区域。通过下采样生成噪声对并迭代优化以生成最终结果。在四个公开数据集上的大量实验表明，IGDNet在复杂光照条件下显著提升了视觉质量。PSNR（20.41dB）和SSIM（0.860dB）的定量结果显示，其性能优于14种先进无监督方法。代码即将发布。

</details>


### [70] [Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection](https://arxiv.org/abs/2507.02454)
**中文标题：基于数量提示的弱监督对比学习用于移动红外小目标检测**

*Weiwei Duan,Luping Ji,Shengjia Chen,Sicheng Zhu,Jianghong Huang,Mao Ye*

主要分类: cs.CV

摘要简述: 本文提出了一种弱监督对比学习方案（WeCoL），仅需目标数量提示即可训练模型，用于移动红外小目标检测。通过潜在目标挖掘和对比学习提升伪标签可靠性，实验表明其性能接近全监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 移动红外小目标检测因目标尺寸小、背景对比度低而极具挑战性。现有方法多为全监督，依赖大量人工标注，成本高昂。本文探索弱监督策略以减少标注需求。

研究方法: 基于预训练的SAM模型，设计潜在目标挖掘策略，结合目标激活图和多帧能量积累；采用对比学习提升伪标签可靠性；提出长短期运动感知学习方案建模目标运动模式。

研究结果: 在DAUB和ITSDT-15K数据集上的实验表明，该弱监督方案性能优于早期全监督方法，甚至达到当前最优全监督方法的90%以上。

研究结论: WeCoL方案通过弱监督和对比学习有效减少标注需求，性能接近全监督方法，为红外小目标检测提供了新思路。

中文摘要: 与一般目标检测不同，移动红外小目标检测因目标尺寸微小和背景对比度弱而面临巨大挑战。目前，大多数现有方法为全监督，严重依赖大量人工目标级标注。然而，手动标注视频序列通常昂贵且耗时，尤其是对低质量红外帧图像。受一般目标检测启发，非全监督策略（如弱监督）被认为具有减少标注需求的潜力。为突破传统全监督框架，本文首次提出一种新的弱监督对比学习（WeCoL）方案，仅需在模型训练期间提供简单的目标数量提示。具体而言，在我们的方案中，基于预训练的SAM模型，设计了一种潜在目标挖掘策略，整合目标激活图和多帧能量积累。此外，采用对比学习通过计算特征子空间中正负样本的相似性，进一步提升伪标签的可靠性。此外，我们提出了一种长短期运动感知学习方案，同时建模小目标的局部运动模式和全局运动轨迹。在两个公开数据集（DAUB和ITSDT-15K）上的大量实验表明，我们的弱监督方案通常优于早期的全监督方法，甚至其性能可达到当前最优全监督方法的90%以上。

</details>


### [71] [Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk](https://arxiv.org/abs/2507.02477)
**中文标题：网格丝之歌：自回归网格生成如丝绸编织**

*Gaochao Song,Zibo Zhao,Haohan Weng,Jingbo Zeng,Rongfei Jia,Shenghua Gao*

主要分类: cs.CV

摘要简述: Mesh Silksong提出了一种紧凑高效的网格表示方法，通过类似丝绸编织的自回归方式生成多边形网格，减少了50%的冗余，压缩率提升至22%，同时生成具有优异几何特性的网格。


<details>
  <summary>详细信息</summary>
研究动机: 现有网格标记化方法常因重复顶点标记而浪费网络能力，Mesh Silksong旨在通过仅访问每个顶点一次的方式减少冗余，提升网格生成的效率和几何完整性。

研究方法: Mesh Silksong采用自回归方式生成网格，通过优化顶点标记化过程，避免重复标记，显著减少序列冗余，同时确保网格的流形拓扑、水密性和一致的法线方向。

研究结果: 实验表明，Mesh Silksong不仅能够生成复杂网格，还将压缩率提升至约22%，同时显著改善了网格的几何完整性。

研究结论: Mesh Silksong通过高效的顶点标记化和自回归生成方法，实现了网格生成的高压缩率和几何优化，为实际应用提供了更可靠的网格模型。

中文摘要: 我们介绍了Mesh Silksong，这是一种紧凑高效的网格表示方法，旨在以类似丝绸编织的自回归方式生成多边形网格。现有的网格标记化方法常因重复顶点标记而浪费网络能力。因此，我们的方法通过仅访问每个顶点一次来标记网格顶点，将标记序列的冗余减少50%，并实现了约22%的最先进压缩率。此外，Mesh Silksong生成的网格具有优异的几何特性，包括流形拓扑、水密检测和一致的法线方向，这些特性对实际应用至关重要。实验结果证明了我们方法的有效性，不仅展示了复杂的网格生成能力，还显著提升了几何完整性。

</details>


### [72] [Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection](https://arxiv.org/abs/2507.02844)
**中文标题：视觉上下文攻击：通过图像驱动的上下文注入越狱多模态大语言模型**

*Ziqi Miao,Yi Ding,Lijun Li,Jing Shao*

主要分类: cs.CV

摘要简述: 本文提出了一种新型视觉中心越狱攻击（VisCo攻击），通过图像驱动的上下文注入，成功诱导多模态大语言模型（MLLMs）生成有害响应。VisCo攻击通过四种视觉策略动态生成辅助图像，并结合毒性模糊和语义优化，显著提升了攻击效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）在视觉-语言任务中的强大表现，其在实际应用中的安全性问题日益突出。现有研究主要通过视觉输入触发有害文本响应，但缺乏现实场景的语义关联。本文旨在定义一种视觉中心的越狱攻击，以更真实和有效的方式利用视觉信息。

研究方法: 本文提出VisCo攻击，通过四种视觉策略构建上下文对话，必要时动态生成辅助图像以形成视觉中心越狱场景。攻击过程中结合自动毒性模糊和语义优化，生成最终攻击提示，确保对黑盒MLLMs的有效攻击。

研究结果: VisCo攻击在MM-SafetyBench测试中，对GPT-4o的毒性评分为4.78，攻击成功率为85%，显著优于基线方法的毒性评分2.48和攻击成功率22.2%。

研究结论: VisCo攻击通过视觉驱动的上下文注入，成功实现了对MLLMs的高效越狱攻击，揭示了视觉模态在模型安全中的关键漏洞，为未来防御研究提供了重要参考。

中文摘要: 随着强大的视觉-语言能力的出现，多模态大语言模型（MLLMs）在实际应用中展现出巨大潜力。然而，视觉模态表现出的安全漏洞为开放环境中的部署带来重大挑战。近期研究通过将有害文本语义直接编码到视觉输入中，成功诱导目标MLLMs生成有害响应。然而，这些方法中视觉模态主要作为不安全行为的触发器，常表现出语义模糊且缺乏现实场景的关联。本文定义了一种新型视觉中心越狱攻击，其中视觉信息是构建完整且现实越狱上下文的必要组成部分。基于此，我们提出VisCo（视觉上下文）攻击。VisCo通过四种视觉策略伪造上下文对话，必要时动态生成辅助图像以构建视觉中心越狱场景。为最大化攻击效果，它结合自动毒性模糊和语义优化，生成最终攻击提示，可靠地触发目标黑盒MLLMs的有害响应。具体而言，VisCo在MM-SafetyBench上对GPT-4o的毒性评分为4.78，攻击成功率为85%，显著优于基线方法的毒性评分2.48和攻击成功率22.2%。代码见https://github.com/Dtc7w3PQ/Visco-Attack。

</details>


### [73] [CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios](https://arxiv.org/abs/2507.02479)
**中文标题：CrowdTrack：真实场景中复杂多行人跟踪的基准数据集**

*Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue*

主要分类: cs.CV

摘要简述: 本文提出了一个名为CrowdTrack的大规模复杂场景多行人跟踪数据集，旨在解决现有数据集场景简单、不真实的问题，为复杂情况下的跟踪算法开发提供平台。


<details>
  <summary>详细信息</summary>
研究动机: 现有多目标跟踪数据集场景简单且不真实，难以支持复杂场景下的跟踪算法研究。为此，作者提出了CrowdTrack数据集，专注于复杂真实场景中的多行人跟踪挑战。

研究方法: 作者收集了33个第一人称视角的视频，包含5,185条轨迹，每个对象标注完整边界框和唯一ID。数据集涵盖复杂场景，如遮挡和模糊图像，并测试了多种SOTA模型和基础模型性能。

研究结果: CrowdTrack数据集为复杂场景下的多行人跟踪提供了丰富数据，测试结果表明现有模型在复杂场景中表现不佳，凸显了数据集的挑战性。

研究结论: CrowdTrack填补了现有数据集的不足，为复杂场景下的多行人跟踪算法研究提供了重要资源，推动了该领域的发展。

中文摘要: 多目标跟踪是计算机视觉中的经典领域，其中行人跟踪具有极高的应用价值，成为最热门的研究类别。现有方法主要利用运动或外观信息进行跟踪，但在复杂场景中往往难以实现。对于运动信息，物体间的相互遮挡常阻碍运动状态的更新；对于外观信息，由于物体仅部分可见或图像模糊等原因，结果往往不够鲁棒。尽管从标注数据中学习如何在这些情况下进行跟踪是最简单的解决方案，但现有的多目标跟踪数据集无法满足这一需求。现有方法主要有两个缺点：场景组成相对简单且不真实。尽管现有数据集中部分视频序列没有上述缺点，但其数量远不足以满足研究需求。为此，我们提出了一个针对复杂场景的大规模多行人跟踪数据集，主要从第一人称视角拍摄，且全部来自真实复杂场景。我们将其命名为“CrowdTrack”，因为大多数序列中包含大量物体。该数据集包含33个视频，共计5,185条轨迹。每个对象标注了完整的边界框和唯一对象ID。该数据集将为开发在复杂情况下仍有效的算法提供平台。我们对数据集进行了全面分析，并在其上测试了多种SOTA模型。此外，我们还分析了基础模型在该数据集上的性能。数据集和项目代码发布于：https://github.com/loseevaya/CrowdTrack。

</details>


### [74] [MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention](https://arxiv.org/abs/2507.02488)
**中文标题：MedFormer：具有内容感知双稀疏选择注意力的分层医学视觉Transformer**

*Zunhui Xia,Hongxing Li,Libin Lan*

主要分类: cs.CV

摘要简述: MedFormer是一种高效的医学视觉Transformer，通过金字塔缩放结构和内容感知的双稀疏选择注意力（DSSA）解决了现有方法的通用性和计算效率问题，显著提升了医学图像识别任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的医学视觉Transformer方法存在两个主要问题：一是任务和架构的特定性限制了通用性；二是全注意力机制计算成本高，而手工设计的稀疏注意力可能导致性能不佳。MedFormer旨在解决这些问题。

研究方法: MedFormer采用金字塔缩放结构作为通用主干网络，支持多种医学图像识别任务（如分类、语义分割和病变检测）。同时，提出内容感知的双稀疏选择注意力（DSSA），动态选择最相关的内容，提高计算效率和抗噪能力。

研究结果: 在多种医学图像数据集上的实验表明，MedFormer在分类、语义分割和病变检测任务中均显著提升了性能，同时具有更高的通用性和计算效率。

研究结论: MedFormer通过金字塔结构和DSSA机制，解决了现有医学视觉Transformer的局限性，为医学图像识别任务提供了一种高效且通用的解决方案。

中文摘要: 医学图像识别是辅助临床诊断的关键手段，能够更准确、及时地识别疾病和异常。基于视觉Transformer的方法在处理多种医学识别任务中表现出色，但仍面临两大挑战：一是任务和架构的特定性限制了通用性；二是全注意力机制计算成本高，而手工设计的稀疏注意力可能导致性能不佳。为此，我们提出了MedFormer，一种高效的医学视觉Transformer。其核心创新包括：1）采用金字塔缩放结构作为通用主干网络，支持多种医学图像识别任务（如分类、语义分割和病变检测），同时降低特征图计算负载；2）引入内容感知的双稀疏选择注意力（DSSA），动态选择最相关的内容，提高计算效率和抗噪能力。理论分析和实验结果表明，MedFormer在通用性和效率上优于现有方法。在多种医学图像数据集上的实验验证了MedFormer在分类、语义分割和病变检测任务中的高效性能。代码已开源：https://github.com/XiaZunhui/MedFormer。

</details>


### [75] [Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy](https://arxiv.org/abs/2507.02493)
**中文标题：时间感知的监督对比学习用于结肠镜检查中的息肉计数**

*Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi*

主要分类: cs.CV

摘要简述: 本文提出了一种时间感知的监督对比学习方法，用于结肠镜检查中的息肉计数，通过结合时间信息和视觉特征，显著降低了息肉计数的碎片化率。


<details>
  <summary>详细信息</summary>
研究动机: 自动化息肉计数是提高结肠镜检查效率和质量的关键步骤。现有方法主要依赖自监督学习，忽略了时间关系，导致息肉计数的准确性和鲁棒性不足。

研究方法: 提出了一种监督对比损失函数，结合时间感知的软目标，捕捉息肉内部变化并保持息肉间的区分性。同时，通过引入时间邻接约束改进了轨迹聚类，减少了视觉相似但时间距离较远的轨迹的误关联。

研究结果: 在公开数据集上的实验表明，该方法将碎片化率降低了2.2倍，显著优于现有方法。

研究结论: 时间信息在息肉计数中具有重要作用，本文提出的方法为息肉计数领域设定了新的技术标杆。

中文摘要: 结肠镜检查中的自动化息肉计数是实现自动化报告和质量控制的关键步骤，旨在提高结肠镜检查的成本效益。息肉计数涉及检测和跟踪息肉，然后将属于同一息肉的轨迹聚类。现有方法主要依赖自监督学习，并仅利用视觉特征，忽略了轨迹特征学习和聚类阶段的时间关系。本文提出了一种范式转变，通过引入结合时间感知软目标的监督对比损失函数。该方法能够捕捉息肉内部的变化，同时保持息肉间的区分性，从而实现更鲁棒的聚类。此外，通过集成时间邻接约束改进了轨迹聚类，减少了视觉相似但时间距离较远的轨迹的误关联。我们在公开数据集上训练和验证了该方法，并使用留一法交叉验证策略评估其性能。结果表明，与现有方法相比，碎片化率降低了2.2倍。我们的结果凸显了时间感知在息肉计数中的重要性，并确立了新的技术标杆。代码可在https://github.com/lparolari/temporally-aware-polyp-counting获取。

</details>


### [76] [MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations](https://arxiv.org/abs/2507.02494)
**中文标题：MC-INR：基于元学习和聚类隐式神经表示的多变量科学模拟数据高效编码方法**

*Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong*

主要分类: cs.CV

摘要简述: MC-INR是一种基于元学习和聚类的高效多变量科学模拟数据编码框架，解决了现有隐式神经表示（INR）方法的局限性，适用于非结构化网格数据。


<details>
  <summary>详细信息</summary>
研究动机: 现有隐式神经表示（INR）方法在复杂结构表示、多变量数据处理和非结构化网格适应性方面存在不足，限制了其在真实世界科学数据中的应用。

研究方法: MC-INR结合元学习和聚类技术，通过残差动态重聚类机制自适应划分簇，并引入分支层独立处理多变量数据。

研究结果: 实验表明，MC-INR在多变量科学数据编码任务中优于现有方法。

研究结论: MC-INR通过灵活的多变量数据编码和动态聚类机制，显著提升了复杂科学数据的处理效率和适应性。

中文摘要: 隐式神经表示（INR）被广泛用于将数据编码为连续函数，从而以较低的内存占用实现大规模多变量科学模拟数据的可视化。然而，现有的基于INR的方法存在三个主要局限性：（1）对复杂结构的表示不够灵活，（2）主要针对单变量数据，（3）依赖于结构化网格。因此，在应用于复杂的真实世界数据集时，其性能会下降。为解决这些问题，我们提出了一种基于神经网络的新框架MC-INR，用于处理非结构化网格上的多变量数据。它结合了元学习和聚类技术，实现了对复杂结构的灵活编码。为进一步提升性能，我们引入了一种基于残差的动态重聚类机制，根据局部误差自适应地划分簇。同时，我们还提出了一种分支层，通过独立分支同时利用多变量数据。实验结果表明，MC-INR在科学数据编码任务中优于现有方法。

</details>


### [77] [Automatic Labelling for Low-Light Pedestrian Detection](https://arxiv.org/abs/2507.02513)
**中文标题：低光行人检测的自动标注方法**

*Dimitrios Bouzoulas,Eerik Alamikkotervo,Risto Ojala*

主要分类: cs.CV

摘要简述: 本文提出了一种自动红外-RGB标注流程，用于解决低光条件下行人检测数据不足的问题。通过红外检测、标签传递和模型训练，生成的自动标签在多个指标上优于人工标注。


<details>
  <summary>详细信息</summary>
研究动机: RGB图像中的行人检测是行人安全的关键任务，但低光条件下的数据集较少。本文旨在通过自动标注方法解决这一问题。

研究方法: 方法包括：1) 使用微调的红外行人检测模型进行红外检测；2) 将红外检测标签传递到对应的RGB图像；3) 利用生成的标签训练低光RGB行人检测模型。

研究结果: 在KAIST数据集上的实验表明，使用自动标签训练的模型在6/9的情况下（mAP@50和mAP@50-95指标）优于使用人工标注训练的模型。

研究结论: 自动红外-RGB标注流程能有效提升低光条件下行人检测的性能，为相关领域提供了实用解决方案。

中文摘要: RGB图像中的行人检测是行人安全的关键任务，因为自动驾驶车辆和高级驾驶辅助系统中最常见的传感器是RGB相机。RGB行人检测中的一个挑战是低光条件，目前缺乏大型公开数据集。作为解决方案，本研究提出了一种自动红外-RGB标注流程。该流程包括：1) 红外检测，使用微调的红外行人检测模型；2) 将红外检测标签传递到对应的RGB图像；3) 利用生成的标签训练低光RGB行人检测模型。研究使用了KAIST数据集进行评估。实验结果显示，在未见过的图像序列上，使用自动标签训练的模型在9个案例中的6个（mAP@50和mAP@50-95指标）优于使用人工标注训练的模型。本研究的源代码可在https://github.com/BouzoulasDimitrios/IR-RGB-Automated-LowLight-Pedestrian-Labeling获取。

</details>


### [78] [Detecting Multiple Diseases in Multiple Crops Using Deep Learning](https://arxiv.org/abs/2507.02517)
**中文标题：使用深度学习检测多种作物中的多种疾病**

*Vivek Yadav,Anugrah Jain*

主要分类: cs.CV

摘要简述: 本文提出一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，旨在覆盖印度多样化的农业景观。通过构建包含17种作物和34种疾病的统一数据集，训练出的深度学习模型在准确性和覆盖范围上优于现有技术，检测准确率达到99%。


<details>
  <summary>详细信息</summary>
研究动机: 印度作为农业经济为主的国家，面临作物疾病、害虫和环境压力导致的严重损失。早期准确检测多种作物的疾病对提高产量和保障粮食安全至关重要。

研究方法: 研究首先构建了一个包含17种作物和34种疾病的统一数据集，随后训练了一个深度学习模型，该模型在覆盖范围和准确性上优于现有技术。

研究结果: 模型在统一数据集上的检测准确率达到99%，比现有技术（覆盖14种作物和26种疾病）高出7%。

研究结论: 通过提升可检测作物和疾病类型的数量，该解决方案旨在为印度农民提供更优的产品。

中文摘要: 印度作为以农业为主的经济体，在农业领域面临重大挑战，包括由疾病、害虫和环境压力导致的严重作物损失。早期检测和准确识别不同作物中的疾病对提高产量和保障粮食安全至关重要。本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，旨在覆盖印度多样化的农业景观。我们首先构建了一个统一数据集，包含来自不同资源库的17种作物和34种疾病的图像。提出的深度学习模型在该数据集上训练，并在准确性和覆盖的作物、疾病数量上优于现有技术。我们在统一数据集上实现了显著的检测准确率，即99%，比仅覆盖14种作物和26种疾病的现有技术高出7%。通过提升可检测作物和疾病类型的数量，该解决方案旨在为印度农民提供更好的产品。

</details>


### [79] [IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning](https://arxiv.org/abs/2507.02519)
**中文标题：IMASHRIMP：基于计算机视觉与深度学习的实验室图像白虾生物形态自动分析**

*Abiam Remache González,Meriem Chagour,Timon Bijan Rüth,Raúl Trapiella Cañedo,Marina Martínez Soler,Álvaro Lorenzo Felipe,Hyun-Suk Shin,María-Jesús Zamorano Serrano,Ricardo Torres,Juan-Antonio Castillo Parra,Eduardo Reyes Abad,Miguel-Ángel Ferrer Ballester,Juan-Manuel Afonso López,Francisco-Mario Hernández Tejera,Adrian Penate-Sanchez*

主要分类: cs.CV

摘要简述: IMASHRIMP是一种基于计算机视觉和深度学习的自动白虾形态分析系统，通过改进的ResNet-50架构和VitPose姿态估计模块，显著减少了人工误差，提升了遗传选择效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统的水产养殖中，白虾的形态分析依赖人工操作，存在误差高、效率低的问题。IMASHRIMP旨在通过自动化的计算机视觉技术优化遗传选择任务，推动可持续水产养殖发展。

研究方法: IMASHRIMP结合改进的ResNet-50架构进行图像分类和额角完整性检测，采用VitPose模块预测23个关键点，并利用SVM模型将像素测量转换为厘米单位。

研究结果: 系统将视角分类误差从0.97%降至0%，额角检测误差从12.46%降至3.64%，姿态估计的平均精度达97.94%，像素到厘米的转换误差为0.07（±0.1）厘米。

研究结论: IMASHRIMP成功实现了白虾形态分析的自动化，显著减少了人工误差，为水产养殖的遗传选择提供了高效工具。

中文摘要: 本文介绍了IMASHRIMP，一种用于自动化白虾（Penaeus vannamei）形态分析的系统，旨在优化水产养殖中的遗传选择任务。通过改进现有的深度学习和计算机视觉技术，解决了从RGBD图像分析虾形态的特定挑战。IMASHRIMP包含两个基于改进ResNet-50架构的判别模块，用于按视角分类图像并确定额角完整性。提出了一种“双因素认证（人类与AI）”系统，将视角分类的人工误差从0.97%降至0%，额角检测误差从12.46%降至3.64%。此外，从VitPose调整的姿态估计模块可预测虾骨架上的23个关键点，并为侧视图和背视图分别设计网络。集成了基于支持向量机（SVM）模型的形态回归模块，将像素测量转换为厘米单位。实验结果表明，系统有效减少了人工误差，姿态估计的平均精度（mAP）达97.94%，像素到厘米的转换误差为0.07（±0.1）厘米。IMASHRIMP展示了自动化加速虾形态分析的潜力，提升了遗传选择效率，为可持续水产养殖做出了贡献。代码发布于https://github.com/AbiamRemacheGonzalez/ImaShrimp-public。

</details>


### [80] [MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details](https://arxiv.org/abs/2507.02546)
**中文标题：MoGe-2：具有度量尺度和清晰细节的精确单目几何估计**

*Ruicheng Wang,Sicheng Xu,Yue Dong,Yu Deng,Jianfeng Xiang,Zelong Lv,Guangzhong Sun,Xin Tong,Jiaolong Yang*

主要分类: cs.CV

摘要简述: MoGe-2是一种先进的单目几何估计模型，能够从单张图像中恢复具有度量尺度的3D点地图，同时保持相对几何精度并增强细节。


<details>
  <summary>详细信息</summary>
研究动机: 现有的单目几何估计方法（如MoGe）只能预测未知尺度的仿射不变点地图，无法满足度量尺度需求，且真实数据中的噪声和误差会削弱几何细节。因此，需要一种既能恢复度量尺度又能保持细节的方法。

研究方法: MoGe-2在MoGe基础上扩展，通过统一数据细化方法，利用合成标签过滤和补全真实数据，提升几何细节的粒度，同时保持度量尺度和相对几何精度。

研究结果: 实验表明，MoGe-2在相对几何精度、度量尺度和细节恢复方面均优于现有方法，首次实现了三者同时优化。

研究结论: MoGe-2通过结合数据细化策略和混合数据集训练，成功实现了高精度的单目几何估计，为开放领域的3D重建提供了新思路。

中文摘要: 我们提出了MoGe-2，这是一种先进的开放领域几何估计模型，能够从单张图像中恢复具有度量尺度的3D点地图。我们的方法基于最近的单目几何估计方法MoGe，该方法预测了未知尺度的仿射不变点地图。我们探索了有效策略，将MoGe扩展到度量几何预测，同时不损害仿射不变点表示提供的相对几何精度。此外，我们发现真实数据中的噪声和误差会削弱预测几何的细粒度细节。为此，我们开发了一种统一的数据细化方法，利用清晰的合成标签过滤和补全来自不同来源的真实数据，显著增强了重建几何的粒度，同时保持了整体精度。我们在混合数据集上训练了模型，并进行了全面评估，结果表明其在实现准确的相对几何、精确的度量尺度和细粒度细节恢复方面具有卓越性能——这是以往方法未能同时实现的能力。

</details>


### [81] [Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning](https://arxiv.org/abs/2507.02565)
**中文标题：基于外观和空间行为推理的近距离人体交互重建**

*Buzhen Huang,Chen Li,Chongyang Xu,Dongyue Lu,Jinnan Chen,Yangang Wang,Gim Hee Lee*

主要分类: cs.CV

摘要简述: 本文提出一种基于外观和空间行为推理的双分支优化框架，用于从复杂视频中重建准确的人体交互动作，解决了现有方法在视觉模糊和遮挡情况下的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人体姿态估计方法在视觉模糊和人际遮挡情况下难以恢复合理的近距离交互动作，即使是先进的基础模型（如SAM）也无法准确区分此类场景中的人体语义。因此，本文探索利用人类外观作为线索来解决这些问题。

研究方法: 提出一种双分支优化框架，结合扩散模型学习人类空间行为和姿态先验知识，并通过3D高斯、2D关键点和网格穿透等约束优化人体动作和外观。

研究结果: 实验结果表明，该方法在多个基准测试中优于现有方法，能够从复杂环境中捕获的视频中准确估计交互动作。

研究结论: 通过空间行为先验和多样化约束，本文方法能够有效重建复杂的近距离人体交互动作，并提供了伪标注数据集以促进未来研究。

中文摘要: 由于视觉模糊和人际遮挡，现有的人体姿态估计方法无法从野外视频中恢复合理的近距离交互动作。即使是当前最先进的大型基础模型（如SAM）也无法在此类挑战性场景中准确区分人体语义。本文发现，人类外观可以为此类问题提供直接线索。基于这一观察，我们提出了一种双分支优化框架，通过人类外观、社交空间行为和物理规律的约束，重建准确的交互动作和合理的身体接触。具体而言，我们首先训练扩散模型以学习人类空间行为和姿态先验知识。随后，将训练好的网络和两个可优化张量整合到双分支优化框架中，以重建人体动作和外观。此外，还设计了基于3D高斯、2D关键点和网格穿透的约束来辅助优化。通过空间行为先验和多样化约束，我们的方法能够从复杂环境中捕获的视频中准确估计交互动作。我们还构建了一个带有伪标注交互注释的数据集，以促进未来关于姿态估计和人类行为理解的研究。在多个基准测试上的实验结果表明，我们的方法优于现有方法。代码和数据可在https://www.buzhenhuang.com/works/CloseApp.html获取。

</details>


### [82] [Parametric shape models for vessels learned from segmentations via differentiable voxelization](https://arxiv.org/abs/2507.02576)
**中文标题：基于可微分体素化的分割学习血管参数化形状模型**

*Alina F. Dima,Suprosanna Shit,Huaqi Qiu,Robbie Holland,Tamara T. Mueller,Fabio Antonio Musio,Kaiyuan Yang,Bjoern Menze,Rickmer Braren,Marcus Makowski,Daniel Rueckert*

主要分类: cs.CV

摘要简述: 本文提出了一种通过可微分体素化从分割中学习血管参数化形状模型的框架，结合了体素、网格和参数化模型的优势，实现了高保真度的几何捕捉。


<details>
  <summary>详细信息</summary>
研究动机: 血管是人体中的复杂结构，现有研究通常使用体素、网格或参数化模型等不同表示方法，但这些方法通常独立使用。本文旨在通过可微分变换将这三种表示方法结合起来，直接从分割中学习参数化形状模型，避免对真实形状参数的依赖。

研究方法: 通过可微分体素化技术，从分割中自动提取血管的参数化形状模型。血管被参数化为中心线和半径，使用三次B样条确保平滑性和连续性。网格从学习到的形状参数中可微分地提取，支持后拟合操作。

研究结果: 实验表明，该方法能够准确捕捉复杂血管的几何形状，包括主动脉、动脉瘤和脑血管，生成的网格具有高保真度。

研究结论: 本文提出的框架成功地将体素、网格和参数化模型结合，通过可微分变换直接从分割中学习形状参数，为血管建模提供了高效且灵活的方法。

中文摘要: 血管是人体中的复杂结构，已有研究采用了多种表示方法。尽管体素化是最常见的方法，但网格和参数化模型因其理想特性在各种应用中至关重要。然而，这些表示通常通过分割提取并彼此独立使用。我们提出了一种框架，通过可微分变换将这三种表示结合起来。利用可微分体素化，我们通过形状到分割的拟合自动提取血管的参数化形状模型，无需依赖真实形状参数即可从分割中学习形状参数。血管被参数化为中心线和半径，使用三次B样条确保构造的平滑性和连续性。网格从学习到的形状参数中可微分地提取，生成高保真度的网格，支持后拟合操作。实验表明，我们的方法能够准确捕捉复杂血管的几何形状，包括主动脉、动脉瘤和脑血管。

</details>


### [83] [Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning](https://arxiv.org/abs/2507.02581)
**中文标题：结构感知的语义差异与一致性在3D医学图像自监督学习中的应用**

*Tan Pan,Zhaorui Tan,Kaiyu Guo,Dongli Xu,Weidi Xu,Chen Jiang,Xin Guo,Yuan Qi,Yuan Cheng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为$S^2DC$的自监督学习框架，通过结构感知的语义差异和一致性，提升3D医学图像的表征能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 3D医学图像自监督学习（mSSL）在医学分析中具有巨大潜力，但现有方法通常忽略解剖结构的位置、尺度和形态变化，导致无法有效捕捉有意义的差异。本文旨在通过学习结构感知的表征来解决这一问题。

研究方法: $S^2DC$框架通过两步实现结构感知表征：1）利用最优传输策略增强不同图像块的语义差异；2）基于邻域相似性分布提升结构级别的语义一致性。

研究结果: 在10个数据集、4项任务和3种模态上的全面评估表明，$S^2DC$在mSSL任务中始终优于现有最先进方法。

研究结论: $S^2DC$通过结合结构感知的语义差异和一致性，显著提升了3D医学图像的表征能力，为医学分析提供了更有效的工具。

中文摘要: 3D医学图像自监督学习（mSSL）在医学分析中具有广阔前景。为支持更广泛的应用，需考虑解剖结构在位置、尺度和形态上的变化，这对捕捉有意义的差异至关重要。然而，现有mSSL方法通常采用固定大小的图像块划分，忽略结构变化。本文提出一种新视角，旨在学习结构感知的表征。假设同一结构内的图像块具有相同的语义（语义一致性），而不同结构的图像块则语义不同（语义差异）。基于此，我们提出名为$S^2DC$的mSSL框架，通过两步实现结构感知的语义差异和一致性：首先，$S^2DC$利用最优传输策略增强不同图像块的语义差异；其次，基于邻域相似性分布提升结构级别的语义一致性。通过结合图像块和结构级别的表征，$S^2DC$实现了结构感知的表征。在10个数据集、4项任务和3种模态上的全面评估表明，$S^2DC$在mSSL任务中始终优于现有最先进方法。

</details>


### [84] [AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding](https://arxiv.org/abs/2507.02591)
**中文标题：AuroraLong：让RNN重回高效开放视频理解的舞台**

*Weili Xu,Enxin Song,Wenhao Chai,Xuexiang Wen,Tian Ye,Gaoang Wang*

主要分类: cs.CV

摘要简述: AuroraLong通过用线性RNN语言模型替换MLLM中的LLM组件，解决了长视频理解的高计算复杂性和内存成本问题，同时结合视觉令牌合并技术提升效率，性能媲美基于Transformer的模型。


<details>
  <summary>详细信息</summary>
研究动机: 长视频理解的计算复杂性和内存成本过高，尤其是基于Transformer的大语言模型（LLM）需要随输入序列长度平方级增长的计算和内存。AuroraLong旨在通过线性RNN语言模型解决这一问题，降低计算门槛。

研究方法: AuroraLong用线性RNN语言模型替换MLLM中的LLM组件，支持任意长度输入序列的恒定隐藏状态处理。为提高吞吐量和效率，结合视觉令牌合并技术，按大小升序重新排列视觉令牌。

研究结果: 尽管仅使用2B参数和公开数据训练，AuroraLong在多个视频基准测试中表现与基于Transformer的模型相当，展示了线性RNN在长视频理解中的高效潜力。

研究结论: AuroraLong证明了线性RNN语言模型在降低长视频理解计算门槛方面的潜力，为开放视频理解领域提供了高效解决方案。

中文摘要: 长视频理解的挑战在于其高计算复杂性和高昂的内存成本，因为基于Transformer的大语言模型（LLM）所需的内存和计算随输入序列长度呈平方级增长。我们提出AuroraLong来解决这一问题，通过用线性RNN语言模型替换MLLM中的LLM组件，以恒定大小的隐藏状态处理任意长度的输入序列。为进一步提高吞吐量和效率，我们结合视觉令牌合并技术，按大小升序重新排列视觉令牌。尽管仅使用2B参数和公开数据训练，AuroraLong在多个视频基准测试中表现与基于Transformer的模型相当。这表明高效的线性RNN有望通过降低计算门槛，推动长视频理解的普及。据我们所知，我们是首个在类似LLaVA的模型中使用基于线性RNN的LLM主干进行开放视频理解的研究。

</details>


### [85] [Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development](https://arxiv.org/abs/2507.02602)
**中文标题：解决视觉导航中相机传感器故障：模拟与数据集开发**

*Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill*

主要分类: cs.CV

摘要简述: 本文针对视觉导航中相机传感器故障问题，提出了一种模拟框架和数据集开发方法，用于训练和测试基于AI的故障检测算法。


<details>
  <summary>详细信息</summary>
研究动机: 视觉导航算法在太空任务中的重要性日益增加，但传感器故障可能导致导航算法输出不准确或完全失效，影响任务目标。传统故障检测方法存在局限性，而AI虽能提供解决方案，但缺乏代表性故障数据集。

研究方法: 研究通过分析行星探索任务中的相机传感器潜在故障案例，系统表征故障原因、影响及缓解策略，并开发模拟框架生成合成故障图像数据。

研究结果: 提出了一个包含故障注入图像的模拟数据集，为训练和测试AI故障检测算法提供了工具。

研究结论: 该研究填补了视觉导航中故障数据集的空白，为AI在故障检测中的应用提供了支持。

中文摘要: 视觉导航（VBN）算法在太空任务中的重要性日益增加，但其可靠性和操作鲁棒性面临诸多挑战。传感器故障可能导致导航算法输出不准确或完全失效，从而危及任务目标。人工智能（AI）为解决此类故障提供了强大工具，克服了传统故障检测方法的局限性。然而，AI在此领域应用的主要障碍是缺乏包含故障图像数据的充分且代表性数据集。本研究针对行星探索任务场景，分析了VBN流程中相机传感器的潜在故障案例，系统表征了故障原因、影响及其对图像质量和导航算法性能的作用，以及常用缓解策略。为支持分析，研究引入了一个模拟框架，用于在合成图像中重现故障条件，从而系统且可控地生成故障数据。生成的故障注入图像数据集为训练和测试基于AI的故障检测算法提供了宝贵工具。数据集链接将在禁运期后公布，审稿人可通过私密链接访问。

</details>


### [86] [AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models](https://arxiv.org/abs/2507.02664)
**中文标题：AIGI-Holmes：基于多模态大语言模型的可解释和泛化性AI生成图像检测**

*Ziyin Zhou,Yunpeng Luo,Yuanchen Wu,Ke Sun,Jiayi Ji,Ke Yan,Shouhong Ding,Xiaoshuai Sun,Yunsheng Wu,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出AIGI-Holmes，一种基于多模态大语言模型的可解释且泛化性强的AI生成图像检测方法，通过Holmes-Set数据集和Holmes Pipeline训练框架解决现有技术缺乏可解释性和泛化能力的问题。


<details>
  <summary>详细信息</summary>
研究动机: AI生成内容（AIGC）技术的快速发展导致高度逼真的AI生成图像（AIGI）被滥用于传播虚假信息，威胁公共信息安全。现有AIGI检测技术缺乏可解释性和对最新生成技术的泛化能力。

研究方法: 1) 构建Holmes-Set数据集，包括带解释的指令调优数据集Holmes-SFTSet和人类偏好数据集Holmes-DPOSet；2) 提出Multi-Expert Jury数据标注方法；3) 设计Holmes Pipeline三阶段训练框架（视觉专家预训练、监督微调、直接偏好优化）；4) 推理阶段采用协作解码策略。

研究结果: 在三个基准测试上的广泛实验验证了AIGI-Holmes的有效性，其能够生成人类可验证且符合人类偏好的解释，并具备更强的泛化能力。

研究结论: AIGI-Holmes通过多模态大语言模型和精心设计的训练框架，显著提升了AI生成图像检测的可解释性和泛化性，为公共信息安全提供了有力支持。

中文摘要: AI生成内容（AIGC）技术的快速发展导致高度逼真的AI生成图像（AIGI）被滥用于传播虚假信息，威胁公共信息安全。尽管现有AIGI检测技术总体有效，但仍面临两大问题：1) 缺乏人类可验证的解释；2) 对最新生成技术缺乏泛化能力。为解决这些问题，我们引入了一个大规模综合数据集Holmes-Set，包括带解释的指令调优数据集Holmes-SFTSet和人类偏好数据集Holmes-DPOSet。我们提出了一种高效的数据标注方法Multi-Expert Jury，通过结构化多模态大语言模型（MLLM）解释增强数据生成，并通过跨模型评估、专家缺陷过滤和人类偏好修改实现质量控制。此外，我们设计了Holmes Pipeline，一个包含视觉专家预训练、监督微调和直接偏好优化的三阶段训练框架。该框架将MLLM适配于AIGI检测任务，同时生成人类可验证且符合人类偏好的解释，最终得到我们的模型AIGI-Holmes。在推理阶段，我们引入了一种协作解码策略，结合视觉专家的感知能力和MLLM的语义推理能力，进一步提升了泛化性能。在三个基准测试上的广泛实验验证了AIGI-Holmes的有效性。

</details>


### [87] [Learning few-step posterior samplers by unfolding and distillation of diffusion models](https://arxiv.org/abs/2507.02686)
**中文标题：通过展开和蒸馏扩散模型学习少步后验采样器**

*Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra*

主要分类: cs.CV

摘要简述: 本文提出了一种新框架，通过深度展开和模型蒸馏将扩散模型转化为少步条件模型，用于后验采样，显著提升了计算效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在贝叶斯计算成像中表现优异，但现有方法存在灵活性不足或精度不高的问题。本文旨在结合深度展开和蒸馏技术，开发一种高效且灵活的后验采样方法。

研究方法: 通过深度展开LATINO Langevin采样器（一种MCMC算法），并结合模型蒸馏技术，将扩散模型转化为少步条件模型。这是首次将深度展开应用于蒙特卡洛采样方案。

研究结果: 实验表明，所提出的方法在精度和计算效率上均优于现有技术，同时保持了适应前向模型变化的灵活性。

研究结论: 本文提出的框架成功地将扩散模型转化为高效的后验采样器，为计算成像领域提供了一种新的解决方案。

中文摘要: 扩散模型（DMs）已成为贝叶斯计算成像中强大的图像先验。目前有两种主要策略利用DMs：即插即用方法（零样本且高度灵活，但依赖近似）和专用条件DMs（通过监督训练实现更高精度和更快推理）。本文提出了一种新框架，通过深度展开和模型蒸馏将DM图像先验转化为少步条件模型用于后验采样。核心创新是将马尔可夫链蒙特卡洛（MCMC）算法（特别是LATINO Langevin采样器）展开，这是首次将深度展开应用于蒙特卡洛采样方案。通过大量实验和与现有技术的比较，我们证明了所提出的展开和蒸馏采样器在精度和计算效率上的优异表现，同时保持了推理时适应前向模型变化的灵活性。

</details>


### [88] [APT: Adaptive Personalized Training for Diffusion Models with Limited Data](https://arxiv.org/abs/2507.02687)
**中文标题：APT：面向有限数据的扩散模型自适应个性化训练**

*JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang*

主要分类: cs.CV

摘要简述: 本文提出APT框架，通过自适应训练策略和特征正则化，解决扩散模型在有限数据下过拟合和语义丢失问题，显著提升生成图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 在有限数据下个性化扩散模型时，过拟合、先验知识丢失和文本对齐退化是主要挑战。这些问题导致噪声预测分布偏移，破坏去噪轨迹和语义一致性。

研究方法: APT框架包含三个关键组件：1) 自适应训练调整，通过过拟合指标动态调整数据增强和损失权重；2) 表示稳定化，正则化中间特征图的均值和方差；3) 注意力对齐，保持微调模型与预训练模型的交叉注意力图一致。

研究结果: 实验表明，APT有效缓解过拟合，保留先验知识，并在有限参考数据下生成高质量、多样化的图像，优于现有方法。

研究结论: APT通过自适应训练和特征正则化，显著提升了扩散模型在有限数据下的性能，为个性化生成任务提供了有效解决方案。

中文摘要: 在有限数据下个性化扩散模型面临过拟合、先验知识丢失和文本对齐退化等挑战。过拟合导致噪声预测分布偏移，破坏去噪轨迹和语义一致性。本文提出自适应个性化训练（APT）框架，通过自适应训练策略和特征正则化解决这些问题。APT包含三个关键组件：1) 自适应训练调整，通过过拟合指标动态调整数据增强和损失权重；2) 表示稳定化，正则化中间特征图的均值和方差；3) 注意力对齐，保持微调模型与预训练模型的交叉注意力图一致。实验表明，APT有效缓解过拟合，保留先验知识，并在有限参考数据下生成高质量、多样化的图像，优于现有方法。

</details>


### [89] [CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation](https://arxiv.org/abs/2507.02691)
**中文标题：CanonSwap：通过规范空间调制实现高保真且一致的视频换脸**

*Xiangyang Luo,Ye Zhu,Yunfei Liu,Lijian Lin,Cong Wan,Zijian Cai,Shao-Lun Huang,Yu Li*

主要分类: cs.CV

摘要简述: CanonSwap通过解耦视频中人脸的外观与动态信息，提出了一种新颖的视频换脸框架，显著提升了视觉质量、时间一致性和身份保留效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频换脸方法在身份转移质量上表现较好，但难以保持目标人脸的动态属性（如头部姿势、表情等），导致结果不一致。CanonSwap旨在解决这一问题。

研究方法: CanonSwap首先消除与动态相关的信息，在统一的规范空间内进行身份修改，随后将交换后的特征重新整合到原始视频空间以保留动态属性。此外，设计了部分身份调制模块和细粒度同步评估指标。

研究结果: 实验表明，CanonSwap在视觉质量、时间一致性和身份保留方面显著优于现有方法。

研究结论: CanonSwap通过解耦外观与动态信息，实现了高质量且一致的视频换脸效果，为相关领域提供了新的解决方案。

中文摘要: 视频换脸旨在解决两个主要挑战：有效将源身份转移到目标视频，并准确保留目标人脸的动态属性（如头部姿势、表情、唇同步等）。现有方法主要关注高质量的身份转移，但在保持目标人脸动态属性方面表现不足，导致结果不一致。我们认为这一问题源于视频中面部外观与动态的固有耦合。为此，我们提出了CanonSwap，一种新颖的视频换脸框架，通过解耦动态信息与外观信息来解决这一问题。具体而言，CanonSwap首先消除与动态相关的信息，在统一的规范空间内进行身份修改，随后将交换后的特征重新整合到原始视频空间，确保目标人脸动态属性的保留。为进一步实现精确的身份转移并减少伪影、增强真实感，我们设计了部分身份调制模块，通过空间掩码自适应整合源身份特征，限制修改范围仅限面部区域。此外，我们引入了多个细粒度同步评估指标，全面评估视频换脸方法的性能。大量实验表明，我们的方法在视觉质量、时间一致性和身份保留方面显著优于现有方法。项目页面公开于https://luoxyhappy.github.io/CanonSwap/。

</details>


### [90] [SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment](https://arxiv.org/abs/2507.02705)
**中文标题：SIU3R：超越特征对齐的同步场景理解与三维重建**

*Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu*

主要分类: cs.CV

摘要简述: SIU3R提出了一种无需特征对齐的框架，首次实现了从未定位图像中同时进行场景理解和3D重建，通过像素对齐的3D表示和统一的学习查询，显著提升了3D理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖2D到3D的特征对齐，导致3D理解能力有限和语义信息丢失。为解决这一问题，SIU3R提出了一种无需对齐的框架，旨在实现更高效的场景理解和3D重建。

研究方法: SIU3R通过像素对齐的3D表示桥接重建和理解任务，并将多个理解任务统一为一组可学习查询。此外，设计了两个轻量级模块以促进任务间的协作。

研究结果: 实验表明，SIU3R在3D重建、场景理解及两者的联合任务上均达到了最先进的性能，验证了其框架和协作设计的有效性。

研究结论: SIU3R通过无需对齐的框架和任务协作设计，显著提升了同时进行场景理解和3D重建的能力，为端到端智能系统的发展提供了新思路。

中文摘要: 同步场景理解和三维重建在开发端到端智能系统中具有重要作用。为实现这一目标，现有方法采用2D到3D特征对齐范式，但存在3D理解能力有限和语义信息丢失的问题。为此，我们提出了SIU3R，首个无需对齐的框架，可从无定位图像中实现通用的同步场景理解和三维重建。具体而言，SIU3R通过像素对齐的3D表示桥接重建和理解任务，并将多个理解任务统一为一组可学习查询，无需依赖与2D模型的对齐即可实现原生3D理解。为促进任务间的协作，我们深入分析了二者的相互增益，并设计了两个轻量级模块以优化其交互。大量实验表明，我们的方法不仅在3D重建和场景理解的独立任务中表现优异，在同步任务中也达到了最先进的性能，突显了无需对齐框架和协作设计的优势。

</details>


### [91] [UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation](https://arxiv.org/abs/2507.02713)
**中文标题：UniMC：驯服扩散变换器以实现统一关键点引导的多类图像生成**

*Qin Guo,Ailing Zeng,Dongxu Yue,Ceyuan Yang,Yang Cao,Hanzhong Guo,Fei Shen,Wei Liu,Xihui Liu,Dan Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为UniMC的DiT框架，用于统一多类关键点引导的图像生成，并发布了高质量数据集HAIG-2.9M，解决了现有方法在非刚性物体和多类重叠生成中的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有关键点引导的文本到图像扩散模型在生成非刚性物体（如动物）和多类重叠实例时存在困难，主要由于方法局限性和数据集不足。本文旨在解决这些问题。

研究方法: 设计了基于DiT的UniMC框架，将实例和关键点条件整合为紧凑令牌，并引入类、边界框和关键点坐标等属性。同时发布了HAIG-2.9M数据集，包含丰富标注和严格人工检查。

研究结果: 实验表明HAIG-2.9M数据集质量高，UniMC在复杂遮挡和多类场景中表现优异。

研究结论: UniMC和HAIG-2.9M为关键点引导的多类图像生成提供了有效解决方案，显著提升了生成质量和多样性。

中文摘要: 尽管关键点引导的文本到图像扩散模型取得了显著进展，但现有主流模型在控制生成更一般的非刚性物体（如动物）方面仍面临挑战。此外，仅基于关键点控制生成多个重叠的人类和动物也较为困难。这些挑战源于现有可控方法的固有局限性和缺乏合适的数据集。为此，我们设计了一个基于DiT的框架UniMC，探索统一可控的多类图像生成。UniMC将实例和关键点条件整合为紧凑令牌，包含类、边界框和关键点坐标等属性，克服了以往方法因依赖骨架图像作为条件而难以区分实例和类的局限性。其次，我们提出了HAIG-2.9M，一个大规模、高质量且多样化的数据集，专为关键点引导的人类和动物图像生成设计。HAIG-2.9M包含786K图像和2.9M实例，具有丰富的标注（如关键点、边界框和细粒度描述）和严格的人工检查以确保标注准确性。大量实验证明了HAIG-2.9M的高质量和UniMC的有效性，尤其是在复杂遮挡和多类场景中。

</details>


### [92] [FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models](https://arxiv.org/abs/2507.02714)
**中文标题：FairHuman：基于最小潜在延迟公平性的扩散模型中人像手部和面部质量提升方法**

*Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma*

主要分类: cs.CV

摘要简述: FairHuman是一种多目标微调方法，通过最小潜在延迟公平性准则优化扩散模型，显著提升人像生成中手部和面部的细节质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前大规模文本到图像模型在人像生成中，尤其是手部和面部细节的表现仍不理想，主要由于训练中对局部区域的监督不足。

研究方法: 提出FairHuman方法，构建全局目标（默认扩散目标函数）和两个局部目标（手部和面部），基于最小潜在延迟准则优化参数更新策略，实现多目标公平优化。

研究结果: 实验表明，FairHuman在保持整体生成质量的同时，显著提升了手部和面部细节的生成效果。

研究结论: FairHuman通过多目标公平优化，有效解决了人像生成中局部细节的挑战，为扩散模型的应用提供了新思路。

中文摘要: 随着大规模文本到图像模型的发展，尤其是基于扩散的模型，图像生成取得了显著进展。然而，由于训练中对局部区域的监督不足，生成具有合理细节（如面部或手部）的人像仍然具有挑战性。为解决这一问题，我们提出了FairHuman，一种多目标微调方法，旨在公平地提升全局和局部生成质量。具体而言，我们首先构建了三个学习目标：一个源自默认扩散目标函数的全局目标，以及两个基于预标注位置先验的手部和面部局部目标。随后，我们在最小潜在延迟（MPD）准则的指导下，推导出最优参数更新策略，从而实现了对这一多目标问题的公平感知优化。基于此，我们提出的方法在保持整体质量的同时，显著提升了具有挑战性的局部细节生成效果。大量实验证明了我们的方法在不同场景下提升人像生成性能的有效性。

</details>


### [93] [Prompt learning with bounding box constraints for medical image segmentation](https://arxiv.org/abs/2507.02743)
**中文标题：基于边界框约束的提示学习用于医学图像分割**

*Mélanie Gaillochet,Mehrdad Noori,Sahar Dastani,Christian Desrosiers,Hervé Lombaert*

主要分类: cs.CV

摘要简述: 本文提出了一种结合基础模型和弱监督分割的新框架，仅使用边界框注释自动生成提示，优化方案整合了边界框约束和伪标签，实验表明其在有限数据下优于全监督和弱监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割中像素级标注成本高昂，而边界框标注更易获取。现有提示学习方法依赖全标注分割掩码，本文旨在利用边界框注释实现高效弱监督分割。

研究方法: 提出一种框架，结合基础模型的表示能力和弱监督分割的标注效率，通过边界框注释自动生成提示，并整合边界框约束与基础模型生成的伪标签进行优化。

研究结果: 在多模态数据集上的实验显示，该方法在有限数据设置下平均Dice得分为84.90%，优于现有全监督和弱监督方法。

研究结论: 本文方法通过边界框注释和基础模型的结合，实现了高效的弱监督医学图像分割，显著减少了标注负担。

中文摘要: 在医学领域，像素级标注的获取既耗时又昂贵。为减轻这一负担，基于边界框标注的弱监督方法提供了一种实用替代方案，边界框标注更容易获取。最近，视觉基础模型在提供点或边界框等提示时表现出显著的分割性能。提示学习通过将这些模型适配到下游任务并自动化分割，从而减少用户干预。然而，现有的提示学习方法依赖于完全标注的分割掩码。本文提出了一种新颖框架，将基础模型的表示能力与弱监督分割的标注效率相结合。具体而言，我们的方法仅使用边界框注释自动生成基础模型的提示。提出的优化方案整合了来自边界框注释的多重约束与基础模型生成的伪标签。在多模态数据集上的广泛实验表明，我们的弱监督方法在有限数据设置下平均Dice得分为84.90%，优于现有的全监督和弱监督方法。代码可在https://github.com/Minimel/box-prompt-learning-VFM.git获取。

</details>


### [94] [DexVLG: Dexterous Vision-Language-Grasp Model at Scale](https://arxiv.org/abs/2507.02747)
**中文标题：DexVLG：大规模灵巧视觉-语言-抓取模型**

*Jiawei He,Danshi Li,Xinqiang Yu,Zekun Qi,Wenyao Zhang,Jiayi Chen,Zhaoxiang Zhang,Zhizheng Zhang,Li Yi,He Wang*

主要分类: cs.CV

摘要简述: 本文提出DexVLG模型，通过大规模视觉-语言-抓取数据集DexGraspNet 3.0训练，实现了基于语言指令的单视角RGBD输入下的灵巧抓取姿态预测，并在仿真和真实场景中展示了优异的零样本泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉-语言-动作系统主要针对简单夹爪末端执行器，缺乏针对类人灵巧手的功能性抓取研究。本文旨在填补这一空白，通过大规模数据集和模型训练，实现语言指令对齐的灵巧抓取。

研究方法: 生成包含1.7亿灵巧抓取姿态的大规模数据集DexGraspNet 3.0，覆盖17.4万个物体的语义部分，并配以详细部分级描述。基于此数据集训练视觉语言模型和流匹配姿态预测头，实现语言指令对齐的抓取姿态生成。

研究结果: DexVLG在仿真中零样本执行成功率达76%以上，部分抓取准确率领先，并在真实场景中成功实现部分对齐抓取。

研究结论: DexVLG通过大规模数据集和模型训练，显著提升了灵巧抓取的零样本泛化能力，为未来复杂任务中的灵巧操作提供了有力工具。

中文摘要: 随着大型模型的兴起，视觉-语言-动作（VLA）系统正使机器人能够处理日益复杂的任务。然而，受限于数据收集的困难，现有研究主要集中在控制简单的夹爪末端执行器上，针对类人灵巧手的功能性抓取研究较少。本文提出DexVLG，一种基于单视角RGBD输入、与语言指令对齐的灵巧抓取姿态预测大型视觉-语言-抓取模型。为此，我们在仿真中生成了一个包含1.7亿灵巧抓取姿态的数据集，覆盖17.4万个物体的语义部分，并配以详细的部分级描述。这一名为DexGraspNet 3.0的大规模数据集用于训练视觉语言模型和基于流匹配的姿态预测头，能够为桌面物体生成与指令对齐的抓取姿态。为评估DexVLG性能，我们在基于物理的仿真中创建了基准测试，并进行了真实世界实验。大量测试表明，DexVLG具有强大的零样本泛化能力——在仿真中零样本执行成功率达76%以上，部分抓取准确率领先，并在真实场景中成功实现了部分对齐抓取。

</details>


### [95] [Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics](https://arxiv.org/abs/2507.02748)
**中文标题：全局上下文线性注意力：一种用于视觉与物理的多极注意力机制**

*Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MANO的多极注意力机制，通过距离多尺度计算注意力，实现线性复杂度，在图像分类和物理模拟任务中表现优异，同时显著降低计算资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 标准Transformer的二次复杂度使其难以处理高分辨率输入，现有方法常以牺牲细节为代价。本文受n体数值模拟启发，提出一种新的注意力机制以解决这一问题。

研究方法: 提出多极注意力神经算子（MANO），将注意力建模为网格点间的交互问题，采用距离多尺度计算方式，保持全局感受野的同时实现线性复杂度。

研究结果: MANO在图像分类和Darcy流任务中性能媲美ViT和Swin Transformer，同时显著减少运行时间和内存占用。

研究结论: MANO通过多极注意力机制有效解决了Transformer的高复杂度问题，为高分辨率输入处理提供了高效解决方案。

中文摘要: Transformer已成为从图像分类到物理模拟等多种任务的实际标准。尽管其性能卓越，但标准Transformer在输入长度上的二次复杂度使其难以处理高分辨率输入。为此，已有多种改进方法提出，其中最成功的依赖于分块、下采样或粗化技术，但往往以牺牲最精细尺度细节为代价。本文采用了一种不同的方法，受n体数值模拟中的先进技术启发，将注意力建模为网格点间的交互问题。我们提出了多极注意力神经算子（MANO），以距离多尺度方式计算注意力。MANO在每个注意力头中保持全局感受野，并实现与网格点数成线性关系的时间和内存复杂度。在图像分类和Darcy流任务上的实验结果表明，MANO的性能可与ViT和Swin Transformer等先进模型媲美，同时将运行时间和峰值内存使用量降低数个数量级。我们的代码已开源，以确保可重复性。

</details>


### [96] [Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2507.02751)
**中文标题：部分弱监督的面向对象检测**

*Mingxin Liu,Peiyuan Zhang,Yuan Liu,Wei Zhang,Yue Zhou,Ning Liao,Ziyang Gong,Junwei Luo,Zhirui Wang,Yi Yu,Xue Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于部分弱标注（水平框或单点）的Partial Weakly-Supervised Oriented Object Detection (PWOOD)框架，显著降低了标注成本，并在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前面向对象检测（OOD）的标注成本高昂，现有方法在标注速度或成本上存在不足。本文旨在通过部分弱标注解决这一问题。

研究方法: 1. 提出PWOOD框架，利用部分弱标注（水平框或单点）高效利用未标注数据；2. 设计OS-Student模型，学习方向和尺度信息；3. 引入CPF策略，降低模型对静态过滤阈值的敏感性。

研究结果: 在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的实验表明，PWOOD框架性能优于或接近传统半监督算法。

研究结论: PWOOD框架显著降低了标注成本，同时保持了高性能，为面向对象检测提供了一种经济高效的解决方案。

中文摘要: 随着面向对象检测（OOD）在各领域的需求增长，其研究也日益深入。然而，数据集标注的高成本仍是一个主要问题。当前主流OOD算法主要分为三类：（1）使用完整定向边界框（OBB）标注的全监督方法；（2）使用部分OBB标注的半监督方法；（3）使用水平框或点等弱标注的弱监督方法。但这些方法在标注速度或成本上均存在不足。为解决这一问题，我们提出：（1）首个基于部分弱标注（水平框或单点）的Partial Weakly-Supervised Oriented Object Detection (PWOOD)框架，能高效利用大量未标注数据，显著优于基于部分弱标注训练的弱监督算法，同时成本更低；（2）OS-Student模型，仅需少量方向或尺度无关的弱标注即可学习方向和尺度信息；（3）Class-Agnostic Pseudo-Label Filtering (CPF)策略，降低模型对静态过滤阈值的敏感性。在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的全面实验表明，PWOOD框架性能与传统半监督算法相当甚至更优。

</details>


### [97] [From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images](https://arxiv.org/abs/2507.02781)
**中文标题：从像素到破坏程度：利用社交媒体图像的语义分割评估地震影响**

*Danrong Zhang,Huili Huang,N. Simrill Smith,Nimisha Roy,J. David Frost*

主要分类: cs.CV

摘要简述: 本研究提出了一种基于语义分割的方法，通过分析社交媒体图像来评估地震后的破坏程度，旨在提供更客观和全面的破坏分析。


<details>
  <summary>详细信息</summary>
研究动机: 传统的地震破坏评估方法依赖分类，主观性强且无法区分图像中不同区域的破坏程度。本研究旨在通过语义分割技术解决这一问题，提供更精确的破坏分析。

研究方法: 研究构建了一个包含未损坏结构、损坏结构和废墟的分割数据集，并微调了SegFormer模型进行语义分割。同时，引入了一种新的破坏评分系统，结合深度估计量化破坏程度。

研究结果: 该方法能够更客观地量化社交媒体图像中的破坏程度，为灾害侦察团队提供更精确的指导，从而提升灾后应对效率。

研究结论: 通过语义分割和新的评分系统，本研究显著提升了地震破坏评估的客观性和全面性，为灾后响应提供了更有效的支持。

中文摘要: 地震后，社交媒体图像成为灾害侦察的重要资源，能够快速反映破坏程度。传统的破坏评估方法多依赖分类，主观性强且无法区分图像内不同区域的破坏程度。为解决这一问题，本研究将破坏评估问题转化为语义分割任务，旨在更客观地分析地震影响区域的破坏情况。方法包括构建一个分割数据集，将破坏分为未损坏结构、损坏结构和废墟三类，并微调SegFormer模型生成社交媒体图像的破坏分割结果。此外，研究提出了一种新的破坏评分系统，通过考虑图像中不同区域的破坏程度并结合深度估计，量化破坏程度。该方法能够更客观、全面地量化社交媒体图像中的破坏程度，从而为灾害侦察团队提供更精确的指导，提升灾后应对效率。

</details>


### [98] [RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation](https://arxiv.org/abs/2507.02792)
**中文标题：RichControl：无需训练的结构与外观丰富的文本到图像生成空间控制方法**

*Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的文本到图像生成方法RichControl，通过解耦特征注入时间与去噪过程，结合结构丰富的注入模块和外观丰富的提示策略，显著提升了生成图像的结构和外观质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到图像扩散模型在结合条件图像（如深度或姿态图）时，常因同步注入条件特征导致结构错位、条件泄漏和视觉伪影。本文旨在解决这些问题，提出更灵活的特征注入框架。

研究方法: 提出了一种解耦特征注入时间与去噪过程的框架，包含结构丰富的注入模块和外观丰富的提示策略，并通过重启细化策略进一步提升视觉质量。

研究结果: 实验表明，该方法在多样化的零样本条件场景下实现了最先进的性能，显著提升了生成图像的结构和外观保真度。

研究结论: RichControl通过灵活的特征注入和外观控制策略，实现了无需训练的高质量图像生成，为文本到图像模型提供了更强大的空间控制能力。

中文摘要: 文本到图像（T2I）扩散模型在从文本提示生成高质量图像方面取得了显著成功。近期研究尝试通过结合条件图像（如深度或姿态图）实现细粒度空间控制。其中，特征注入方法作为一种无需训练的替代方案，逐渐取代了传统的微调方法。然而，这些方法常因条件图像与自然RGB分布差异较大而出现结构错位、条件泄漏和视觉伪影。通过分析现有方法，我们发现其核心问题在于同步注入条件特征未能权衡去噪过程中的域对齐与结构保留。基于此，我们提出了一种灵活的特征注入框架，将注入时间步与去噪过程解耦。其核心是一个结构丰富的注入模块，使模型能够更好地适应扩散步骤中对齐与结构保留的动态平衡，从而生成更忠实于结构的图像。此外，我们还引入了外观丰富的提示策略和重启细化策略，以进一步增强外观控制和视觉质量。这些设计共同实现了无需训练的结构与外观丰富的图像生成。大量实验表明，我们的方法在多样化的零样本条件场景下均达到了最先进的性能。

</details>


### [99] [No time to train! Training-Free Reference-Based Instance Segmentation](https://arxiv.org/abs/2507.02798)
**中文标题：无需训练！基于参考图像的实例分割方法**

*Miguel Espinosa,Chenhongyi Yang,Linus Ericsson,Steven McDonagh,Elliot J. Crowley*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的参考图像实例分割方法，利用基础模型的语义先验知识，通过多阶段训练自由方法实现自动生成实例级分割掩码，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 图像分割模型性能受限于大规模标注数据的高成本。尽管SAM模型通过提示分割缓解了这一问题，但仍需手动视觉提示或复杂规则。本文旨在通过仅需少量参考图像，减少这一负担。

研究方法: 提出多阶段训练自由方法：(1) 构建记忆库；(2) 表示聚合；(3) 语义感知特征匹配，利用基础模型的语义先验知识实现自动分割。

研究结果: 在COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）和跨域FSOD基准（22.4% nAP）上取得显著提升，优于现有训练自由方法。

研究结论: 通过利用语义先验知识和多阶段方法，无需训练即可实现高性能实例分割，为下游任务提供了高效解决方案。

中文摘要: 图像分割模型的性能历来受限于大规模标注数据的高成本。Segment Anything Model（SAM）通过可提示、语义无关的分割范式缓解了这一问题，但仍需手动视觉提示或复杂领域相关规则来处理新图像。为减轻这一负担，本文研究了在仅提供少量参考图像时的对象分割任务。关键思路是利用基础模型学习的强语义先验知识，识别参考图像与目标图像之间的对应区域。研究发现，对应关系可实现下游任务中实例级分割掩码的自动生成，并通过多阶段训练自由方法实现：(1) 记忆库构建；(2) 表示聚合；(3) 语义感知特征匹配。实验表明，在分割指标上取得显著提升，COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）表现优异，并在跨域FSOD基准（22.4% nAP）上优于现有训练自由方法。

</details>


### [100] [HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars](https://arxiv.org/abs/2507.02803)
**中文标题：HyperGaussians：面向高保真可动画化面部虚拟形象的高维高斯泼溅技术**

*Gent Serifi,Marcel C. Bühler*

主要分类: cs.CV

摘要简述: 本文提出了一种名为HyperGaussians的新方法，通过扩展3D高斯泼溅技术，实现了高质量可动画化面部虚拟形象的生成。该方法通过引入高维多变量高斯分布和‘逆协方差技巧’，显著提升了细节表现和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于3D高斯泼溅技术的面部虚拟形象在静态表现上已取得显著成果，但在非线性变形、复杂光照和细节表现上仍存在不足。本文旨在通过改进高斯表示本身，提升可动画化面部虚拟形象的逼真度。

研究方法: 本文提出HyperGaussians，将3D高斯扩展为高维多变量高斯分布，并通过‘逆协方差技巧’解决高维协方差矩阵计算效率问题。该方法可无缝集成到现有模型中，如FlashAvatar。

研究结果: 在4个面部数据集上的19名受试者测试表明，HyperGaussians在数值和视觉表现上均优于传统3D高斯泼溅技术，尤其在眼镜框、牙齿、复杂面部动作和高光反射等高频细节上表现突出。

研究结论: HyperGaussians通过高维高斯表示和高效计算技巧，显著提升了可动画化面部虚拟形象的逼真度和细节表现，为增强现实和虚拟现实应用提供了更高质量的解决方案。

中文摘要: 我们提出了HyperGaussians，一种用于高质量可动画化面部虚拟形象的3D高斯泼溅技术的新扩展。从视频中生成此类详细面部虚拟形象是一个具有挑战性的问题，并在增强现实和虚拟现实中有广泛应用。尽管静态面部已取得巨大成功，但基于单目视频的可动画化虚拟形象仍处于‘恐怖谷’状态。3D高斯泼溅技术（3DGS）通过一组3D高斯基元表示面部，擅长渲染静态面部，但在非线性变形、复杂光照和精细细节上仍存在困难。大多数相关研究专注于通过表情代码预测更好的高斯参数，而我们重新思考了3D高斯表示本身及其如何更具表现力。我们的见解导致了一种将3D高斯扩展为高维多变量高斯的新方法，称为‘HyperGaussians’。高维性通过可学习的局部嵌入条件增加了表现力。然而，泼溅HyperGaussians在计算上昂贵，因为它需要反转高维协方差矩阵。我们通过重新参数化协方差矩阵（称为‘逆协方差技巧’）解决了这一问题。这一技巧提升了效率，使HyperGaussians能够无缝集成到现有模型中。为验证这一点，我们将HyperGaussians集成到快速单目面部虚拟形象的最新技术FlashAvatar中。在4个面部数据集上的19名受试者评估表明，HyperGaussians在数值和视觉表现上均优于3DGS，尤其是在眼镜框、牙齿、复杂面部动作和高光反射等高频细节上。

</details>


### [101] [LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion](https://arxiv.org/abs/2507.02813)
**中文标题：LangScene-X：基于TriMap视频扩散的可泛化3D语言嵌入场景重建**

*Fangfu Liu,Hao Li,Jiawei Chi,Hanyang Wang,Minghui Yang,Fudong Wang,Yueqi Duan*

主要分类: cs.CV

摘要简述: LangScene-X是一种新型生成框架，通过TriMap视频扩散模型和语言量化压缩器（LQC），从稀疏视角重建可泛化的3D语言嵌入场景，解决了传统方法在稀疏视角下的渲染和语义合成问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖密集视角重建，在稀疏视角下易产生渲染伪影和语义合成不准确的问题。本文旨在通过生成一致的多模态信息，实现稀疏视角下的3D语言嵌入场景重建与理解。

研究方法: 1. 训练TriMap视频扩散模型，从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）；2. 提出语言量化压缩器（LQC），在大规模图像数据集上训练，实现跨场景语言嵌入；3. 通过语言信息与3D场景表面对齐，支持开放语言查询。

研究结果: 实验表明，LangScene-X在真实数据上的质量和泛化能力优于现有方法，能够有效解决稀疏视角下的重建和语义理解问题。

研究结论: LangScene-X通过生成一致的多模态信息和语言嵌入，实现了稀疏视角下的高质量3D场景重建与开放语言查询，具有显著的泛化能力。

中文摘要: 从2D图像中恢复具有开放词汇场景理解的3D结构是一项基础但艰巨的任务。近期研究通过嵌入语言信息进行逐场景优化实现了这一目标，但其依赖校准的密集视角重建范式，在视角有限时会出现严重渲染伪影和语义合成不准确的问题。本文提出了一种新型生成框架LangScene-X，通过生成一致的多模态信息，实现稀疏视角下的3D语言嵌入场景重建与理解。具体而言，我们首先训练TriMap视频扩散模型，通过渐进知识整合从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）。此外，我们提出语言量化压缩器（LQC），在大规模图像数据集上训练，高效编码语言嵌入，实现无需逐场景重新训练的跨场景泛化。最后，通过将语言信息与3D场景表面对齐，重建语言表面场，支持开放语言查询。真实数据的广泛实验表明，LangScene-X在质量和泛化能力上优于现有方法。项目页面：https://liuff19.github.io/LangScene-X。

</details>


### [102] [Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach](https://arxiv.org/abs/2507.02826)
**中文标题：基于置信度驱动梯度调制的多模态人类活动识别：一种动态对比双路径学习方法**

*Panpan Ji,Junni Song,Hang Xiao,Hanyu Liu,Chao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架，用于解决多模态人类活动识别中的跨模态特征对齐和模态贡献不平衡问题。该框架通过双路径特征提取、多阶段对比学习和置信度驱动的梯度调制策略，显著提升了识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态人类活动识别（HAR）系统面临跨模态特征对齐困难和模态贡献不平衡等挑战，影响了识别性能。本文旨在通过动态调整学习强度和优化特征对齐，提升多模态HAR系统的性能。

研究方法: 1. 采用双路径特征提取架构（ResNet和DenseNet分支）处理多模态传感器数据；2. 引入多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；3. 提出置信度驱动的梯度调制策略，动态调整各模态分支的学习强度；4. 采用基于动量的梯度累积策略增强训练稳定性。

研究结果: 在四个公共基准数据集上的实验表明，DCDP-HAR框架显著提升了多模态HAR的性能。消融研究验证了各模块的有效性，尤其是置信度驱动的梯度调制策略对缓解模态竞争具有重要作用。

研究结论: 本文提出的DCDP-HAR框架通过动态对比学习和梯度调制策略，有效解决了多模态HAR中的关键问题，为智能系统的环境感知与交互提供了更优解决方案。

中文摘要: 基于传感器的人类活动识别（HAR）是智能系统感知和交互环境的核心技术。然而，多模态HAR系统仍面临跨模态特征对齐困难和模态贡献不平衡等关键挑战。为解决这些问题，我们提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架。该框架包含三个关键组件：首先，采用双路径特征提取架构，其中ResNet和DenseNet分支协同处理多模态传感器数据；其次，引入多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；第三，提出置信度驱动的梯度调制策略，动态监测并调整各模态分支在反向传播中的学习强度，有效缓解模态竞争。此外，采用基于动量的梯度累积策略以增强训练稳定性。我们通过消融研究验证了各模块的有效性，并在四个公共基准数据集上进行了广泛的对比实验。

</details>


### [103] [USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network](https://arxiv.org/abs/2507.02827)
**中文标题：USAD：一种无监督数据增强时空注意力扩散网络**

*Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为USAD的无监督数据增强时空注意力扩散网络，通过多注意力交互机制解决人类活动识别中的标签数据稀缺、特征提取不足和轻量设备性能不佳等问题。实验表明，该方法在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 人类活动识别（HAR）面临标签数据稀缺、高级特征提取不足以及轻量设备性能不佳等挑战。本文旨在通过多注意力交互机制优化这些问题。

研究方法: 1. 使用无监督统计引导扩散模型进行数据增强；2. 设计多分支时空交互网络，通过并行残差分支捕获多尺度特征；3. 结合时空注意力机制识别关键时间点和传感器交互；4. 引入跨分支特征融合单元和自适应多损失函数融合策略。

研究结果: 在WISDM、PAMAP2和OPPORTUNITY数据集上，USAD分别达到98.84%、93.81%和80.92%的准确率，显著优于现有方法，并在嵌入式设备上验证了其高效性。

研究结论: USAD通过无监督数据增强和时空注意力机制，显著提升了人类活动识别的性能，适用于轻量设备部署。

中文摘要: 人类活动识别（HAR）的主要目标是从传感器数据推断人类行为，广泛应用于健康监测、安全保护和运动分析等领域。尽管研究众多，HAR仍面临标签样本稀缺、高级特征提取不足以及轻量设备性能不佳等挑战。为此，本文提出了一种基于多注意力交互机制的优化方法。首先，采用无监督统计引导扩散模型进行数据增强，缓解标签数据稀缺和类别不平衡问题；其次，设计多分支时空交互网络，通过3*3、5*5和7*7卷积核的并行残差分支捕获多尺度特征，同时结合时空注意力机制识别关键时间点和传感器交互；进一步引入跨分支特征融合单元提升特征表示能力；最后，集成自适应多损失函数融合策略，动态调整损失权重以优化模型。在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上的实验表明，所提方法（USAD）的准确率分别达到98.84%、93.81%和80.92%，显著优于现有方法。此外，嵌入式设备上的实际部署验证了该方法的效率和可行性。

</details>


### [104] [AnyI2V: Animating Any Conditional Image with Motion Control](https://arxiv.org/abs/2507.02857)
**中文标题：AnyI2V：通过运动控制为任意条件图像生成动画**

*Ziye Li,Hao Luo,Xincheng Shuai,Henghui Ding*

主要分类: cs.CV

摘要简述: AnyI2V是一种无需训练的框架，能够通过用户定义的运动轨迹为任意条件图像生成动画，支持多种模态输入，并实现风格迁移和编辑。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到视频（T2V）和图像到视频（I2V）方法在动态运动信号和空间约束的灵活整合上存在不足，T2V依赖文本提示缺乏空间布局控制，I2V依赖真实图像限制了编辑性。AnyI2V旨在解决这些问题。

研究方法: AnyI2V提出了一种无需训练的框架，支持多种模态的条件图像输入（如网格和点云），并通过用户定义的运动轨迹实现动画生成，同时支持混合条件输入和风格迁移。

研究结果: 实验表明，AnyI2V在空间和运动控制的视频生成中表现优异，提供了更灵活和多样化的视频生成能力。

研究结论: AnyI2V为空间和运动控制的视频生成提供了新视角，支持更广泛的模态输入和编辑功能。

中文摘要: 近年来，视频生成领域（尤其是扩散模型）在文本到视频（T2V）和图像到视频（I2V）合成方面取得了显著进展。然而，如何有效整合动态运动信号和灵活的空间约束仍存在挑战。现有的T2V方法通常依赖文本提示，这导致对生成内容的空间布局缺乏精确控制；而I2V方法则受限于对真实图像的依赖，限制了合成内容的可编辑性。尽管一些方法通过引入ControlNet实现基于图像的条件输入，但它们通常缺乏明确的运动控制，且需要计算密集的训练。为解决这些问题，我们提出了AnyI2V，一种无需训练的框架，能够通过用户定义的运动轨迹为任意条件图像生成动画。AnyI2V支持更广泛的模态作为条件图像（如网格和点云等ControlNet不支持的数据类型），从而实现更灵活和多样化的视频生成。此外，它还支持混合条件输入，并通过LoRA和文本提示实现风格迁移和编辑。大量实验表明，AnyI2V在空间和运动控制的视频生成中表现优异，为这一领域提供了新的视角。代码可在https://henghuiding.com/AnyI2V/获取。

</details>


### [105] [Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation](https://arxiv.org/abs/2507.02859)
**中文标题：基于自举的多模态大语言模型中接地链式思维的引导及其在数据高效模型适应中的应用**

*Jiaer Xia,Bingkui Tong,Yuhang Zang,Rui Shao,Kaiyang Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Grounded Chain-of-Thought (GCoT)的方法，通过注入边界框信息改进多模态大语言模型（MLLMs）在数据有限情况下的适应能力，显著提升了在图表等专业视觉任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在通用场景中表现优异，但在专业视觉任务（如图表理解）中因预训练数据与下游任务不匹配而难以适应。传统Chain-of-Thought (CoT)数据中存在事实错误，限制了模型性能。

研究方法: 提出Grounded Chain-of-Thought (GCoT)，通过将边界框信息注入CoT数据，使推理步骤更忠实于输入图像。采用自举方法生成高质量训练数据。

研究结果: 在五种专业视觉任务（图表、表格、收据、报告等）中，GCoT在数据有限的情况下显著优于微调和蒸馏方法。

研究结论: GCoT通过增强推理数据的忠实性，有效提升了MLLMs在数据稀缺的专业视觉任务中的适应能力，为模型优化提供了新思路。

中文摘要: 多模态大语言模型（MLLMs）在自然语言解释图像方面表现出色，但在未使用大规模数据集重新训练的情况下，难以适应专业视觉任务（如图表理解）。这一问题源于预训练数据与下游任务的不匹配：预训练数据主要集中于场景和物体，而缺乏专业非物体图像（如图表和表格）的信息。本文发现，使用链式思维（CoT）推理数据训练MLLMs可以促进模型在专业视觉任务中的适应，尤其是在数据有限的情况下。然而，我们发现从预训练MLLMs中提取的CoT数据存在一个关键问题，即推理步骤中常包含多个事实错误。为解决这一问题，我们提出了接地链式思维（GCoT），这是一种基于自举的简单方法，旨在将接地信息（即边界框）注入CoT数据，使推理步骤更忠实于输入图像。我们在五种专业视觉任务（涵盖图表、表格、收据和报告等多种视觉格式）上评估了该方法。结果表明，在数据有限的情况下，我们的方法显著优于微调和蒸馏。

</details>


### [106] [Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching](https://arxiv.org/abs/2507.02860)
**中文标题：少即是多：通过运行时自适应缓存实现无需训练的视频扩散加速**

*Xin Zhou,Dingkang Liang,Kaijin Chen,Tianrui Feng,Xiwu Chen,Hongkai Lin,Yikang Ding,Feiyang Tan,Hengshuang Zhao,Xiang Bai*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的加速框架EasyCache，通过运行时自适应缓存机制显著提升视频扩散模型的推理速度，同时保持高质量生成效果。


<details>
  <summary>详细信息</summary>
研究动机: 视频生成模型因迭代去噪过程导致推理速度慢、计算成本高，限制了其广泛应用。为解决这一问题，本文旨在开发一种无需额外训练的高效加速方法。

研究方法: EasyCache采用轻量级的运行时自适应缓存机制，动态复用先前计算的变换向量，避免冗余计算。该方法无需离线分析、预计算或复杂参数调整。

研究结果: 在多个大规模视频生成模型（如OpenSora、Wan2.1和HunyuanVideo）上测试，EasyCache将推理时间缩短了2.1-3.3倍，同时PSNR提升了36%，显著优于现有方法。

研究结论: EasyCache是一种高效且易于部署的解决方案，适用于高质量视频生成的研究和实际应用，代码已开源。

中文摘要: 视频生成模型表现出卓越的性能，但其广泛采用仍受限于推理速度慢和计算成本高的问题，这主要源于迭代去噪过程。解决这一瓶颈对于普及先进的视频合成技术并将其集成到实际应用中至关重要。本文提出EasyCache，一种无需训练的加速框架，用于视频扩散模型。EasyCache引入了一种轻量级的运行时自适应缓存机制，动态复用先前计算的变换向量，避免推理过程中的冗余计算。与现有方法不同，EasyCache无需离线分析、预计算或复杂参数调整。我们在多个大规模视频生成模型（包括OpenSora、Wan2.1和HunyuanVideo）上进行了全面研究。我们的方法实现了领先的加速性能，与原始基线相比，推理时间缩短了2.1-3.3倍，同时保持了高视觉保真度，与现有最佳方法相比，PSNR显著提升了36%。这一改进使EasyCache成为研究和实际应用中高质量视频生成的高效且易于部署的解决方案。代码已发布于https://github.com/H-EmbodVis/EasyCache。

</details>


### [107] [LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans](https://arxiv.org/abs/2507.02861)
**中文标题：LiteReality：基于RGB-D扫描的图形就绪3D场景重建**

*Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby*

主要分类: cs.CV

摘要简述: LiteReality提出了一种新方法，将RGB-D扫描的室内环境转换为紧凑、逼真且可交互的3D虚拟副本，支持图形渲染和物理交互。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D场景重建技术难以同时满足视觉逼真性和图形渲染需求，LiteReality旨在解决这一问题，为AR/VR、游戏和机器人等领域提供高效解决方案。

研究方法: LiteReality通过场景理解生成结构化场景图，从资产库中检索视觉相似的3D模型，并通过材质绘画模块增强真实感，最后整合到仿真引擎中支持交互。

研究结果: LiteReality在Scan2CAD基准测试中实现了最先进的相似性性能，并能处理严重不对齐、遮挡和光照不足的情况，生成紧凑且可编辑的场景。

研究结论: LiteReality提供了一种高效且兼容标准图形管线的3D场景重建方法，适用于多种应用场景，展示了强大的性能和实用性。

中文摘要: 我们提出了LiteReality，一种新颖的流程，可将室内环境的RGB-D扫描转换为紧凑、逼真且可交互的3D虚拟副本。LiteReality不仅重建视觉上接近现实的场景，还支持图形管线的关键功能，如对象独立性、关节运动、高质量物理渲染材质和基于物理的交互。其核心在于，LiteReality首先进行场景理解，并通过结构化场景图将结果解析为一致的3D布局和对象。随后，它通过从精选资产库中检索视觉最相似的3D艺术家制作的模型来重建场景。接下来，材质绘画模块通过恢复高质量的空间变化材质来增强真实感。最后，重建的场景被整合到具有基本物理属性的仿真引擎中，以实现交互行为。生成的场景紧凑、可编辑，且完全兼容标准图形管线，适用于AR/VR、游戏、机器人和数字孪生等应用。此外，LiteReality引入了一种无需训练的对象检索模块，在Scan2CAD基准测试中实现了最先进的相似性性能，以及一个强大的材质绘画模块，能够将任何风格的图像外观转移到3D资产上——即使在严重不对齐、遮挡和光照不足的情况下。我们在真实扫描和公共数据集上验证了LiteReality的有效性。项目页面：https://litereality.github.io；视频：https://www.youtube.com/watch?v=ecK9m3LXg2c

</details>


### [108] [RefTok: Reference-Based Tokenization for Video Generation](https://arxiv.org/abs/2507.02862)
**中文标题：RefTok：基于参考的视频生成令牌化方法**

*Xiang Fan,Xiaohang Sun,Kushan Thakkar,Zhu Liu,Vimal Bhat,Ranjay Krishna,Xiang Hao*

主要分类: cs.CV

摘要简述: RefTok是一种基于参考的令牌化方法，用于视频生成，能有效捕捉时间动态和上下文信息，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频模型通常独立处理帧集，无法有效捕捉视频中的时间依赖性和冗余性，RefTok旨在解决这一问题。

研究方法: RefTok通过基于未量化参考帧的条件编码和解码帧集，保留运动的连续性和对象的外观细节。

研究结果: 在四个视频数据集上，RefTok显著优于现有方法（如Cosmos和MAGVIT），平均提升36.7%的评估指标，并在视频生成任务中表现更优。

研究结论: RefTok在视频生成中表现出色，能够有效捕捉时间动态和上下文信息，为视频模型提供了新的解决方案。

中文摘要: 有效处理时间冗余是学习视频模型的关键挑战。现有方法通常独立处理帧集，未能有效捕捉视频中的时间依赖性和冗余性。为解决这一问题，我们提出了RefTok，一种新颖的基于参考的令牌化方法，能够捕捉复杂的时间动态和上下文信息。我们的方法基于未量化的参考帧对帧集进行编码和解码。解码时，RefTok保留了运动的连续性和对象的外观细节，例如保留头部运动中的面部细节、正确重建文本、保留小图案以及保持手写文字的清晰度。在四个视频数据集（K600、UCF-101、BAIR Robot Pushing和DAVIS）上，RefTok显著优于当前最先进的令牌化方法（Cosmos和MAGVIT），在相同或更高的压缩比下，所有评估指标（PSNR、SSIM、LPIPS）平均提升了36.7%。在BAIR Robot Pushing任务中，使用RefTok的潜在表示训练视频生成模型时，生成的视频不仅在所有生成指标上优于MAGVIT-B，还优于参数多4倍的MAGVIT-L，平均提升了27.9%。

</details>


### [109] [Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory](https://arxiv.org/abs/2507.02863)
**中文标题：Point3R：基于显式空间指针内存的流式3D重建**

*Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu*

主要分类: cs.CV

摘要简述: Point3R提出了一种在线流式3D重建框架，通过显式空间指针内存直接关联场景的3D结构，解决了传统隐式内存容量有限和信息丢失的问题，实现了高效且密集的3D重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D重建方法依赖隐式内存，容量有限且可能导致早期帧信息丢失。Point3R旨在通过显式空间指针内存解决这些问题，实现更高效的在线流式3D重建。

研究方法: Point3R维护一个显式空间指针内存，每个指针与场景的3D位置直接关联，并通过3D分层位置嵌入和高效融合机制，将最新帧信息密集整合到全局坐标系中。

研究结果: Point3R在多种任务中表现优异，训练成本低，性能达到或超越现有最佳方法。

研究结论: Point3R通过显式空间指针内存和高效融合机制，显著提升了在线流式3D重建的性能和效率，为实际应用提供了有力支持。

中文摘要: 从有序序列或无序图像集合中进行密集3D场景重建是将计算机视觉研究应用于实际场景的关键步骤。继DUSt3R将图像对密集统一到共享坐标系后，后续方法通过隐式内存实现多图像的密集3D重建。然而，这种隐式内存容量有限，可能导致早期帧信息丢失。我们提出Point3R，一种面向密集流式3D重建的在线框架。具体而言，我们维护一个与当前场景3D结构直接关联的显式空间指针内存。每个指针被分配一个特定的3D位置，并将全局坐标系中附近场景信息聚合为动态空间特征。从最新帧提取的信息显式与此指针内存交互，实现当前观测到全局坐标系的密集整合。我们设计了3D分层位置嵌入以促进这种交互，并设计了一种简单高效的融合机制，确保指针内存的均匀性和高效性。我们的方法在多种任务中表现出色，训练成本低，性能达到或超越现有最佳方法。代码见：https://github.com/YkiWu/Point3R。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [110] [STELLA: Self-Evolving LLM Agent for Biomedical Research](https://arxiv.org/abs/2507.02004)
**中文标题：STELLA：用于生物医学研究的自进化大语言模型代理**

*Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong*

主要分类: cs.AI

摘要简述: STELLA是一种自进化的AI代理，专为生物医学研究设计，通过动态工具库和模板库自主提升能力，在多个生物医学基准测试中表现优异，且性能随经验增长而提升。


<details>
  <summary>详细信息</summary>
研究动机: 生物医学数据和工具的快速增长导致研究领域碎片化，超出人类专家的处理能力。现有AI代理依赖静态工具集，无法适应和扩展。STELLA旨在解决这一问题。

研究方法: STELLA采用多代理架构，通过动态工具库（Tool Ocean）和模板库（Template Library）自主进化。工具库由工具创建代理自动扩展，模板库优化推理策略。

研究结果: STELLA在多个生物医学基准测试中表现优异，得分分别为26%（Humanity's Last Exam）、54%（LAB-Bench: DBQA）和63%（LAB-Bench: LitQA），领先其他模型6个百分点。其性能随经验增长显著提升。

研究结论: STELLA代表了AI代理系统的重大进步，能够动态扩展专业知识，加速生物医学发现。

中文摘要: 生物医学数据、工具和文献的快速增长导致研究领域碎片化，超出了人类专家的能力范围。虽然AI代理提供了解决方案，但它们通常依赖静态、手动整理的工具集，限制了其适应和扩展能力。为此，我们推出了STELLA，一种自进化的AI代理，旨在克服这些限制。STELLA采用多代理架构，通过两个核心机制自主提升能力：一是用于推理策略的进化模板库，二是动态工具库（Tool Ocean），由工具创建代理自动发现并整合新的生物信息学工具。这使得STELLA能够从经验中学习。我们证明，STELLA在一系列生物医学基准测试中达到了最先进的准确率，得分分别为26%（Humanity's Last Exam: Biomedicine）、54%（LAB-Bench: DBQA）和63%（LAB-Bench: LitQA），领先其他模型高达6个百分点。更重要的是，其性能随经验增长而系统性提升；例如，在Humanity's Last Exam基准测试中的准确率几乎翻倍。STELLA代表了AI代理系统的重大进步，能够动态扩展专业知识，加速生物医学发现的步伐。

</details>


### [111] [HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection](https://arxiv.org/abs/2507.02073)
**中文标题：HCVR：一种基于相关性感知投票规则的混合特征选择方法**

*Nikita Bhedasgaonkar,Rushikesh K. Joshi*

主要分类: cs.AI

摘要简述: 本文提出了一种轻量级的基于规则的特征选择方法HCVR，结合参数间（P2P）和参数与目标（P2T）相关性，通过投票规则消除冗余特征并保留相关特征。该方法在SPAMBASE数据集上表现优于传统非迭代和迭代技术。


<details>
  <summary>详细信息</summary>
研究动机: 传统特征选择方法在消除冗余特征和保留相关特征方面存在不足，HCVR旨在通过结合P2P和P2T相关性，提出一种更高效的特征选择方法。

研究方法: HCVR是一种混合方法，结合非迭代和迭代过滤技术，通过后向消除和多数投票规则选择特征。规则基于特征间及特征与目标的相关性阈值。

研究结果: 在SPAMBASE数据集上，HCVR的性能优于传统非迭代（如CFS、mRMR和MI）和迭代（如RFE、SFS和遗传算法）方法，提升了分类器性能。

研究结论: HCVR通过相关性感知的投票规则，有效减少了特征维度并提升了分类性能，为特征选择提供了一种高效解决方案。

中文摘要: 本文提出HCVR（基于相关性感知投票规则的混合方法），一种轻量级的基于规则的特征选择方法，结合参数间（P2P）和参数与目标（P2T）相关性，以消除冗余特征并保留相关特征。该方法是非迭代和迭代过滤技术的混合，采用后向消除策略，每一步可能消除多个特征。规则通过多数投票决定保留或丢弃特征，并利用特征间及特征与目标的相关性阈值。实验结果表明，在SPAMBASE数据集上，HCVR的性能优于传统非迭代（如CFS、mRMR和MI）和迭代（如RFE、SFS和遗传算法）技术，分类器性能得到提升。

</details>


### [112] [Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs](https://arxiv.org/abs/2507.02076)
**中文标题：预算内推理：大型语言模型中自适应与可控测试时计算综述**

*Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates*

主要分类: cs.AI

摘要简述: 本文综述了大型语言模型（LLMs）在推理过程中计算效率的优化策略，提出了一种两级分类法，区分固定计算预算的方法和动态调整计算的方法，并评估了主流LLMs的性能与计算资源消耗之间的权衡。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理时采用固定的计算资源，无法根据任务复杂度动态调整，导致简单问题过度计算而复杂问题计算不足。本文旨在探讨如何通过自适应和可控的测试时计算策略提升LLMs的计算效率。

研究方法: 本文提出两级分类法：L1-可控性（固定计算预算）和L2-自适应性（动态调整计算）。通过评估主流LLMs在不同数据集上的表现，分析推理性能与计算资源消耗的关系。

研究结果: 研究表明，动态调整计算资源的方法在提升推理效率方面表现更优，但需权衡性能与计算成本。同时，混合思维模型等新兴趋势显示出潜力。

研究结论: 未来研究应关注如何使LLMs在计算效率、鲁棒性和用户需求响应方面取得进一步突破，同时探索混合模型的潜力。

中文摘要: 大型语言模型（LLMs）已迅速发展为能够解决广泛任务的通用智能体。然而，当前模型在推理时仍效率低下：无论任务复杂度如何，它们均采用固定的推理计算资源，常导致简单问题过度计算而复杂问题计算不足。本文综述了高效的测试时计算（TTC）策略，旨在提升LLMs推理的计算效率。我们提出了一种两级分类法，区分L1-可控性（固定计算预算的方法）和L2-自适应性（基于输入难度或模型置信度动态调整计算的方法）。通过评估主流LLMs在多样化数据集上的表现，我们揭示了推理性能与计算资源消耗之间的关键权衡。与以往关于高效推理的综述相比，本文更强调TTC方法的实际可控性、适应性和可扩展性。最后，我们讨论了混合思维模型等新兴趋势，并指出了未来研究的关键挑战，以推动LLMs在计算效率、鲁棒性和用户需求响应方面的进一步优化。

</details>


### [113] [Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab](https://arxiv.org/abs/2507.02083)
**中文标题：通过系统生物学干实验测量语言模型的科学能力**

*Haonan Duan,Stephen Zhewen Lu,Caitlin Fiona Harrigan,Nishkrit Desai,Jiarui Lu,Michał Koziarski,Leonardo Cotta,Chris J. Maddison*

主要分类: cs.AI

摘要简述: 本文介绍了SciGym，首个评估大型语言模型（LLM）在开放式科学发现任务中迭代实验设计与分析能力的基准测试，通过系统生物学干实验克服湿实验的高成本问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有评估LLM科学能力的方法因湿实验的高成本（专业知识、时间和设备）而无法测试其核心科学能力（实验设计与结果解释）。SciGym旨在填补这一空白。

研究方法: SciGym利用系统生物学标记语言（SBML）编码的生物系统模型进行干实验，生成模拟数据，评估六种前沿LLM在137个小系统和总计350个系统上的表现。

研究结果: 结果显示，能力更强的模型表现更优，但随着系统复杂性增加，所有模型的性能显著下降，表明LLM的科学能力仍有较大提升空间。

研究结论: SciGym为评估LLM的科学能力提供了高效且低成本的解决方案，揭示了当前模型的局限性，为未来研究指明了方向。

中文摘要: 实验设计和结果解释是核心科学能力，尤其在生物学中，研究者通过扰动复杂系统揭示其内在机制。现有评估大型语言模型（LLM）科学能力的方法因湿实验的高成本（专业知识、时间和设备）而无法测试这些能力。我们提出了SciGym，首个评估LLM在开放式科学发现任务中迭代实验设计与分析能力的基准测试。SciGym通过运行系统生物学干实验克服湿实验的高成本问题。这些模型以系统生物学标记语言（SBML）编码，能高效生成模拟数据，是测试复杂系统实验的理想平台。我们评估了六种前沿LLM在137个小系统和总计350个系统上的表现。结果显示，能力更强的模型表现更优，但随着系统复杂性增加，所有模型的性能显著下降，表明LLM的科学能力仍有较大提升空间。

</details>


### [114] [What Neuroscience Can Teach AI About Learning in Continuously Changing Environments](https://arxiv.org/abs/2507.02103)
**中文标题：神经科学能为AI在持续变化环境中的学习提供什么启示**

*Daniel Durstewitz,Bruno Averbeck,Georgia Koppe*

主要分类: cs.AI

摘要简述: 本文探讨了如何从神经科学中汲取灵感，改进AI在持续变化环境中的学习能力，并提出了双向学习的议程。


<details>
  <summary>详细信息</summary>
研究动机: 现代AI模型通常通过一次性训练和固定参数部署，而动物却能持续适应环境变化。本文旨在探索神经科学如何为AI提供快速适应和持续学习的计算机制，尤其是在社交互动和动态环境中。

研究方法: 整合了AI中的持续学习和上下文学习文献，以及神经科学中关于行为任务中规则、奖励概率或结果变化的学习研究，提出了一个双向学习的议程。

研究结果: 提出了神经科学如何为AI在动态环境中的学习提供具体见解，并探讨了AI如何反过来促进神经科学的发展。

研究结论: 神经科学与AI的双向学习可以为动态环境中的智能系统提供新思路，推动NeuroAI领域的发展。

中文摘要: 现代AI模型（如大型语言模型）通常通过一次性训练和固定参数部署，其训练成本高、速度慢且需要大量重复。相比之下，动物能够持续适应不断变化的环境条件，尤其是社交物种，其行为策略和奖励结果在与同伴互动中频繁变化。这种适应能力通常表现为行为的快速转变和神经元群体活动的突然变化。这种计算能力对于在现实世界中运行的AI系统（如机器人或自动驾驶汽车）或与人类在线交互的AI代理越来越重要。AI能否从神经科学中学习？本文探讨了这一问题，整合了AI中的持续学习和上下文学习文献，以及神经科学中关于行为任务中规则、奖励概率或结果变化的学习研究。我们提出了一个议程，说明神经科学如何为当前AI在这一领域的发展提供具体见解，以及神经科学如何从AI中学习，推动NeuroAI这一新兴领域的发展。

</details>


### [115] [The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies](https://arxiv.org/abs/2507.02152)
**中文标题：公平的幻觉：用审计研究评估公平干预措施**

*Disa Sariola,Patrick Button,Aron Culotta,Nicholas Mattei*

主要分类: cs.AI

摘要简述: 本文探讨了如何利用审计研究数据改进自动招聘算法的公平性，发现传统公平干预方法在表面上看似有效，但实际存在约10%的差异。


<details>
  <summary>详细信息</summary>
研究动机: 人工智能系统在招聘和贷款等领域广泛应用，但其公平性和有效性评估复杂且重要。传统方法通过调整训练数据来减少偏见，但通常依赖便利样本，存在选择偏差和标签偏差。审计研究提供高质量数据，可用于更准确地评估和训练算法。

研究方法: 研究利用审计研究数据（如虚构的简历和随机对照试验）来评估和训练自动招聘算法。通过比较传统公平干预方法（如均衡基率）与基于个体治疗效果估计的新方法，分析其效果。

研究结果: 研究发现，传统公平干预方法在表面上看似公平，但实际仍存在约10%的差异。基于个体治疗效果估计的新方法能进一步减少算法歧视。

研究结论: 审计研究数据为评估和提升算法公平性提供了更可靠的基础。传统方法需结合新方法以更有效地减少偏见。

中文摘要: 人工智能系统，尤其是基于机器学习的系统，正被广泛应用于从招聘到贷款发放等领域，以自动化这些复杂决策。评估这些AI系统及其人类决策对应物的有效性和公平性，是一个复杂且重要的课题，涉及计算科学和社会科学的研究。在机器学习中，解决下游分类器偏见的常见方法是对训练数据进行重采样以抵消差异。例如，如果招聘率因某些受保护类别而异，则可以在训练集中均衡这些比率以减少分类器的偏见。尽管这些方法简单且看似有效，但它们通常仅通过便利样本数据进行评估，导致选择偏差和标签偏差。在社会科学、心理学、公共卫生和医学中，审计研究通过随机对照试验（如虚构的简历、电子邮件或患者演员）向受试者（如招聘岗位、企业或医生）发送数据，提供了高质量的数据支持严格的歧视估计。本文探讨了如何利用审计研究数据改进自动招聘算法的训练和评估能力。研究发现，这类数据揭示了传统公平干预方法（如均衡基率）在表面上看似公平，但实际仍存在约10%的差异。此外，本文还引入了基于个体治疗效果估计的干预方法，进一步利用这些数据减少算法歧视。

</details>


### [116] [Data Diversification Methods In Alignment Enhance Math Performance In LLMs](https://arxiv.org/abs/2507.02173)
**中文标题：数据多样化方法在偏好对齐中提升大型语言模型的数学性能**

*Berkan Dokmeci,Qingyang Wu,Ben Athiwaratkun,Ce Zhang,Shuaiwen Leon Song,James Zou*

主要分类: cs.AI

摘要简述: 通过数据多样化策略提升大型语言模型（LLMs）的数学推理能力，提出Diversified-Think-Solve（DTS）方法，显著提升性能且计算开销低。


<details>
  <summary>详细信息</summary>
研究动机: 尽管偏好学习在人类反馈对齐方面取得进展，但数学推理仍是挑战。研究旨在探索如何通过数据多样化策略优化偏好数据，以提升LLMs的数学推理能力。

研究方法: 评估了温度采样、思维链提示和蒙特卡洛树搜索（MCTS）三种数据生成方法，并提出DTS方法，系统地将问题分解为多样化推理路径。

研究结果: 多样化偏好数据显著提升模型性能，DTS在GSM8K和MATH数据集上分别提升7.1%和4.2%，且计算开销仅增加1.03倍，而MCTS成本高但收益低。

研究结论: 结构化探索多样化问题解决方法比传统方法更有效，DTS为数学对齐提供了高效且低成本的解决方案。

中文摘要: 尽管偏好学习的最新进展增强了人类反馈的对齐效果，但数学推理仍是一个持续的挑战。我们研究了偏好优化中的数据多样化策略如何提升大型语言模型（LLMs）的数学推理能力。我们评估了三种常见的数据生成方法：温度采样、思维链提示和蒙特卡洛树搜索（MCTS），并提出了Diversified-Think-Solve（DTS），这是一种新颖的结构化方法，系统地将问题分解为多样化的推理路径。结果显示，通过策略性多样化的偏好数据，模型可以显著提升数学推理性能，其中最佳方法在GSM8K和MATH数据集上分别实现了7.1%和4.2%的提升。尽管性能优异，DTS的计算开销仅比基线增加1.03倍，而MCTS的成本几乎是其五倍且收益更低。这些发现表明，结构化探索多样化问题解决方法比传统方法更能为数学对齐生成有效的偏好数据。

</details>


### [117] [Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust](https://arxiv.org/abs/2507.02197)
**中文标题：基于LLM的角色扮演代理是否言行一致？人类信任模拟中的信念-行为一致性**

*Amogh Mannekote,Adam Davies,Guohao Li,Kristy Elizabeth Boyer,ChengXiang Zhai,Bonnie J Dorr,Francesco Pinto*

主要分类: cs.AI

摘要简述: 本文研究了基于大型语言模型（LLM）的角色扮演代理在模拟人类信任行为时，其陈述的信念与实际行为之间的一致性。通过建立评估框架，发现LLM在角色扮演中存在系统性不一致，即使其信念看似合理，也可能无法一致地应用于行为模拟。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM越来越多地用于生成人类行为研究的合成数据，确保其输出与角色设定一致成为关键问题。本文旨在探究LLM角色扮演代理的信念与行为之间的一致性，以帮助研究者更准确地使用LLM进行行为研究。

研究方法: 研究建立了一个评估框架，通过增强版的GenAgents角色库和信任游戏（一种量化信任与互惠的经济游戏），引入信念-行为一致性指标。分析了信念类型（如模拟预期结果或角色属性）、信息呈现方式以及预测时间跨度对一致性的影响，并探讨了如何调整研究者先验以解决信念与目标不一致的问题。

研究结果: 研究发现，LLM的陈述（或强加）信念与角色扮演模拟结果在个体和群体层面均存在系统性不一致。即使模型编码了看似合理的信念，也可能无法一致地应用于行为模拟。

研究结论: 研究强调了识别LLM信念与模拟行为何时一致的重要性，以便研究者在行为研究中更合理地使用LLM代理。

中文摘要: 随着LLM越来越多地被研究作为角色扮演代理以生成人类行为研究的合成数据，确保其输出与角色设定一致成为关键问题。本文研究了基于LLM的角色扮演代理的陈述信念（“他们所说的”）与实际角色扮演行为（“他们如何行动”）之间的一致性。具体而言，我们建立了一个评估框架，以严格衡量通过提示模型获得的信念能否提前预测模拟结果。通过使用增强版的GenAgents角色库和信任游戏（一种用于量化玩家信任与互惠的标准经济游戏），我们引入了一种信念-行为一致性指标，系统研究了以下因素的影响：（1）从LLM中提取的信念类型，如模拟预期结果与LLM被要求模拟的个体角色的任务相关属性；（2）何时以及如何向LLM呈现关于信任游戏的相关信息；（3）要求模型预测其未来行为的时长。我们还探讨了在原始提取的信念与研究目标不一致时，如何可行地强加研究者自身的理论先验。我们的结果揭示了LLM陈述（或强加）的信念与其角色扮演模拟结果在个体和群体层面的系统性不一致。具体而言，我们发现即使模型编码了看似合理的信念，也可能无法一致地应用它们。这些发现强调了识别LLM陈述信念与模拟行为何时一致的必要性，以便研究者在行为研究中更合理地使用基于LLM的代理。

</details>


### [118] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
**中文标题：空间囚徒困境中稀释、扩散与共生的强化学习研究**

*Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein*

主要分类: cs.AI

摘要简述: 本文研究了在空间囚徒困境中稀释和移动对多智能体Q学习算法的影响，发现固定规则与学习规则在效果上可能等效，并观察到种群间共生互利效应的出现。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，空间囚徒困境游戏中的静态智能体通过多种机制（如噪声注入、不同学习算法和邻居收益知识）学会合作。本文旨在探讨稀释和移动对多智能体Q学习算法的影响，并验证其在不同博弈场景中的建模潜力。

研究方法: 采用独立多智能体Q学习算法，研究空间囚徒困境中的稀释和移动效应。通过定义不同可能的动作，连接经典非强化学习的空间囚徒困境结果，展示算法的多样性和基准测试潜力。

研究结果: 观察到多种效应，包括固定更新规则与学习规则在效果上的等效性，以及定义多动作时种群间共生互利效应的形成。

研究结论: 研究表明，多智能体Q学习算法在空间囚徒困境中具有广泛的适用性，能够模拟不同博弈场景，并为基准测试提供潜力。

中文摘要: 近期关于空间囚徒困境游戏中强化学习的研究表明，静态智能体可以通过多种机制（如噪声注入、不同学习算法和邻居收益知识）学会合作。本研究采用独立多智能体Q学习算法，探讨了稀释和移动对空间囚徒困境的影响。在此设定下，定义了算法的不同可能动作，并与经典非强化学习的空间囚徒困境结果相联系，展示了该算法在模拟不同博弈场景中的多样性及其基准测试潜力。结果表明，固定更新规则的游戏与学习规则的游戏在效果上可能等效，同时观察到定义多动作时种群间共生互利效应的形成。

</details>


### [119] [Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation](https://arxiv.org/abs/2507.02253)
**中文标题：扩展LLM规划能力：NL2FLOW用于参数化问题生成与严格评估**

*Jungkoo Kang*

主要分类: cs.AI

摘要简述: 论文介绍了NL2FLOW系统，用于自动化生成规划问题并严格评估大型语言模型（LLM）的规划能力。实验表明，最佳模型在生成有效计划和最优计划上分别达到86%和69%的成功率，但中间步骤可能降低性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLM）在规划和推理能力上的进步受到数据生成和评估瓶颈的限制。为了解决这一问题，作者提出了NL2FLOW系统，旨在自动化生成规划问题并严格评估模型性能。

研究方法: 作者开发了NL2FLOW系统，能够参数化生成自然语言、结构化中间表示和PDDL格式的规划问题，并用于评估开源LLM的规划能力。实验生成了2296个自动化工作流生成领域的问题数据集。

研究结果: 实验结果显示，表现最佳的模型在生成有效计划和最优计划上的成功率分别为86%和69%。回归分析表明，问题特征对计划生成的影响取决于模型和提示设计。此外，将自然语言转换为JSON中间步骤的成功率低于直接生成有效计划的成功率。

研究结论: 研究表明，中间步骤可能降低LLM的规划性能，直接基于自然语言推理的模型更具优势。随着问题复杂度的增加，动态理解系统局限性及开发相关工具对释放LLM潜力至关重要。

中文摘要: 提升大型语言模型（LLM）规划和推理能力的进展受到可扩展、可靠数据生成与评估瓶颈的严重制约。为此，我提出了NL2FLOW，一个完全自动化的系统，用于参数化生成规划问题（以自然语言、结构化中间表示和正式PDDL表达）并严格评估生成计划的质量。通过生成包含2296个自动化工作流生成领域问题的数据集，并评估多个开源、指令调优的LLM，我展示了NL2FLOW的能力。结果显示，表现最佳的模型在生成有效计划和最优计划上的成功率分别为86%和69%（仅针对有可行解的问题）。回归分析表明，问题特征对计划生成的影响取决于模型和提示设计。值得注意的是，将自然语言转换为JSON计划表示的最高成功率低于直接生成有效计划的最高成功率。这表明，不必要地分解推理任务（引入中间翻译步骤）可能降低性能，暗示能够直接从自然语言推理到动作的模型更具优势。随着将LLM推理扩展到更复杂的问题，这些系统中的瓶颈和错误来源将不可避免地变化。因此，动态理解这些局限性及系统揭示它们的工具，对于释放LLM作为智能问题求解器的全部潜力至关重要。

</details>


### [120] [Iterated belief revision: from postulates to abilities](https://arxiv.org/abs/2507.02319)
**中文标题：迭代信念修正：从公设到能力**

*Paolo Liberatore*

主要分类: cs.AI

摘要简述: 本文探讨了信念修正领域的研究现状，指出现有方法多依赖公设作为语法特征，而忽略了修正机制的能力分析。作者提出了一种新的视角，关注修正机制能够实现的状态和能力，而非仅局限于公设的约束。


<details>
  <summary>详细信息</summary>
研究动机: 信念修正领域的研究多集中于公设的语法特征，而缺乏对修正机制能力的分析。作者认为，公设仅规定了修正必须做什么，而忽略了修正能够实现的状态和能力。因此，本文旨在填补这一空白，探讨修正机制的能力问题。

研究方法: 作者通过分析多种修正机制（如词典序、自然修正、约束修正等），探讨它们能够实现的状态和能力，例如塑性、平等化、教条化等。这些能力被定义为修正机制能够达到的信念状态。

研究结果: 研究结果表明，不同的修正机制具备不同的能力。例如，词典序修正能够实现塑性状态，而自然修正则能够实现平等化状态。这些能力为修正机制的选择提供了新的视角。

研究结论: 本文提出了一种从能力角度分析信念修正机制的新方法，强调了修正机制能够实现的状态的重要性，而不仅仅是公设的约束。这为信念修正领域的研究提供了新的方向。

中文摘要: 信念修正领域的研究充满了新的提案，但对现有方法的分析却十分匮乏。许多工作依赖于公设，将其作为语法特征：某种修正机制等同于某些属性。公设约束了特定的修正实例：某些修正以特定方式更新某些信念。例如，如果修正与当前信念一致，则无需其他更改即可纳入。这样的公设仅规定了修正必须做什么，而忽略了它们能够做什么。它们能否达到某种信念状态？能否达到所有可能的信念状态？能否从无先前信念的状态达到所有可能的信念状态？能否达到教条化的信念状态，即所有未被相信的内容均被视为不可能？能否使两种条件具有相同的信念？在一个应用中，如果每种可能的信念状态都是合理的，则需要每种信念状态都可达到。在一个应用中，如果条件可能具有相同的信念，则需要这种信念状态是可达到的。在一个应用中，如果信念可能变得教条化，则需要一种使其教条化的方法。这些信念状态需要以某种方式实现，而不是通过典型的信念修正公设所规定的特定方式。这是一种能力，而非约束：塑性、平等化、教条化的能力。健忘、纠正、信仰、大马士革、可学习是其他能力。每种修正机制具备其中某些能力而缺乏其他能力：词典序、自然、约束、非常激进、完全满足、激进、严厉、适度严厉、深度严厉、普通严厉和深度严厉修正，每种修正被证明具备某些能力。

</details>


### [121] [OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent](https://arxiv.org/abs/2507.02353)
**中文标题：OMS：基于LLM代理的实时多目标自我反思广告关键词生成框架**

*Bowen Chen,Zhao Wang,Shingo Takamatsu*

主要分类: cs.AI

摘要简述: OMS是一种基于LLM代理的广告关键词生成框架，无需训练数据，实时监控多目标性能并自我反思关键词质量，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 赞助搜索广告中的关键词决策对广告活动至关重要。现有基于LLM的方法依赖大规模查询-关键词对数据，缺乏在线多目标性能监控与优化，且关键词选择质量不高，限制了LLM在完全自动化关键词决策中的应用。

研究方法: OMS框架具有三大特点：1) 实时性（无需训练数据，监控在线性能并动态调整）；2) 多目标性（通过代理推理优化多个性能指标）；3) 自我反思性（代理评估关键词质量）。

研究结果: 实验表明，OMS在基准测试和实际广告活动中表现优于现有方法，消融实验和人工评估验证了各模块的有效性和生成关键词的质量。

研究结论: OMS通过实时性、多目标优化和自我反思性，解决了现有LLM方法在广告关键词生成中的局限性，为自动化关键词决策提供了高效解决方案。

中文摘要: 赞助搜索广告中的关键词决策对广告活动的成功至关重要。尽管基于LLM的方法提供了自动化的关键词生成功能，但它们面临三大局限：依赖大规模查询-关键词对数据、缺乏在线多目标性能监控与优化，以及关键词选择的质量控制不足。这些问题阻碍了LLM在完全自动化关键词决策中的代理应用，无法实时监控和推理关键性能指标（如展示量、点击量、转化率和CTA效果）。为解决这些问题，我们提出了OMS，一种关键词生成框架，具有实时性（无需训练数据，监控在线性能并动态调整）、多目标性（通过代理推理优化多个性能指标）和自我反思性（代理评估关键词质量）。在基准测试和实际广告活动中的实验表明，OMS优于现有方法；消融实验和人工评估验证了各模块的有效性和生成关键词的质量。

</details>


### [122] [An AI-native experimental laboratory for autonomous biomolecular engineering](https://arxiv.org/abs/2507.02379)
**中文标题：一种面向自主生物分子工程的AI原生实验实验室**

*Mingyu Wu,Zhaoguo Wang,Jiabin Wang,Zhiyuan Dong,Jingkai Yang,Qingting Li,Tianyu Huang,Lei Zhao,Mingqiang Li,Fei Wang,Chunhai Fan,Haibo Chen*

主要分类: cs.AI

摘要简述: 本文提出了一种基于AI的原生自主实验室，专注于复杂生物分子工程的自动化实验，能够自主管理仪器、设计实验流程并优化性能，同时支持多用户请求，显著提升实验效率和仪器利用率。


<details>
  <summary>详细信息</summary>
研究动机: 实现自主科学研究是长期以来的目标，但现有系统局限于单一目标和简单实验流程。本文旨在通过AI驱动的范式转变，构建一个能够处理复杂、多目标实验的自主实验室，突破专家和资源限制。

研究方法: 采用模型、实验和仪器协同设计理念，构建了一个端到端、多用户的自主实验室平台。该系统能够自主管理仪器、设计实验流程和优化启发式方法，并支持AI模型与自动化系统的共同进化。

研究结果: 该自主实验室成功实现了核酸合成、转录、扩增和测序等基础功能，并在疾病诊断、药物开发和信息存储等领域展示了应用潜力。无需人工干预，其性能优化结果可媲美人类科学家的最新成果，同时显著提升了多用户场景下的仪器利用率和实验效率。

研究结论: 该平台为生物材料研究提供了突破专家依赖和资源限制的解决方案，并为大规模科学服务奠定了基础。

中文摘要: 自主科学研究能够独立完成复杂实验并为非专业人士提供服务，是长期以来的追求目标。实现这一目标需要人工智能（AI）驱动的根本性范式转变。尽管自主实验系统正在兴起，但它们仍局限于单一目标和简单实验流程的领域，如化学合成和催化。我们提出了一种AI原生的自主实验室，专注于高度复杂的科学实验，例如自主生物分子工程。该系统能够自主管理仪器、制定实验专用流程和优化启发式方法，并同时处理多用户请求。基于模型、实验和仪器的协同设计理念，该平台支持AI模型与自动化系统的共同进化，从而构建了一个端到端、多用户的自主实验室，能够处理复杂、多目标的实验，并适用于多种仪器。我们的自主实验室支持核酸的基础功能，包括合成、转录、扩增和测序，并在疾病诊断、药物开发和信息存储等领域展示了应用潜力。无需人工干预，该系统能够自主优化实验性能，达到人类科学家的最新成果水平。在多用户场景下，该平台显著提升了仪器利用率和实验效率。这一平台为先进生物材料研究提供了突破专家依赖和资源限制的途径，并为大规模科学服务奠定了基础。

</details>


### [123] [The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning](https://arxiv.org/abs/2507.02442)
**中文标题：Gauss-Markov伴随：监督学习中残差的范畴语义**

*Moto Kamiura*

主要分类: cs.AI

摘要简述: 本文通过范畴论重新构建监督学习模型，提出Gauss-Markov伴随结构，形式化参数与残差的关系，为AI可解释性提供语义基础。


<details>
  <summary>详细信息</summary>
研究动机: 提升机器学习的可理解性与可解释性是实现AI可解释性原则的关键。本文旨在通过范畴论为AI系统构建语义框架，以促进其社会应用。

研究方法: 以多元线性回归模型为基础，定义参数与数据对应的具体范畴，并通过伴随函子对描述监督学习的范畴化形式。提出Gauss-Markov伴随结构，明确参数与残差的信息流关系。

研究结果: Gauss-Markov伴随结构揭示了参数与残差之间的对偶信息流，并通过右伴随函子的极限保持性关联最小二乘估计与最小残差。

研究结论: 本文的范畴化框架为监督学习提供了扩展的指称语义，可作为AI可解释性的形式化基础。

中文摘要: 提升机器学习的可理解性与可解释性是响应AI可解释性原则需求、促进AI社会应用的关键任务。本研究通过范畴论重新构建机器学习模型，为AI系统开发语义框架，以结构化与理解其机制。本文的范畴建模清晰形式化了监督学习中残差与参数的结构关系。研究聚焦于多元线性回归模型（监督学习的最基本形式），通过定义参数与数据对应的具体范畴及伴随函子对，提出了监督学习的范畴化形式。我们表明，这一框架的核心结构由所谓的Gauss-Markov伴随所捕捉。在此设定下，信息的对偶流可明确描述为参数与残差变化的对应关系。参数的最小二乘估计与最小残差通过右伴随函子的极限保持性相关联。此外，我们将此形式化视为监督学习的扩展指称语义实例，并提议将理论计算机科学中的语义视角作为AI可解释性的形式化基础。

</details>


### [124] [Clarifying Before Reasoning: A Coq Prover with Structural Context](https://arxiv.org/abs/2507.02541)
**中文标题：先澄清后推理：一种带结构化上下文的Coq证明器**

*Yanzhen Lu,Hanbin Yang,Xiaodie Wang,Ge Zhang,Biao Li,Chenxu Fu,Chao Li,Yang Yuan,Andrew Chi-Chih Yao*

主要分类: cs.AI

摘要简述: 本研究探讨了提升任务清晰度是否能增强大型语言模型的推理能力，特别是在Coq定理证明中。通过引入结构化语义上下文，任务清晰度得分提升1.85倍，证明成功率提升2.1倍，并超越现有最佳方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索任务清晰度对大型语言模型推理能力的影响，尤其是在复杂的定理证明任务中，如何通过结构化上下文提升模型表现。

研究方法: 方法包括引入概念级指标评估任务清晰度，通过选择性概念展开丰富任务描述，并采用Planner-Executor架构。此外，对结构化数据进行微调以进一步提升性能。

研究结果: 实验结果显示，任务清晰度得分从44.5%提升至82.3%，证明成功率从21.8%提升至45.8%，超越现有最佳方法Graph2Tac（33.2%）。微调后的小模型性能进一步提升至48.6%。

研究结论: 结论表明，结构化任务表示在弥合理解与推理之间的差距中具有重要价值，为未来研究提供了新方向。

中文摘要: 本研究探讨了提升任务清晰度是否能增强大型语言模型的推理能力，重点关注Coq中的定理证明。我们引入了一种概念级指标来评估任务清晰度，并表明在标准输入中添加结构化语义上下文，可以使清晰度得分提升1.85倍（从44.5%提升至82.3%）。使用通用模型DeepSeek-V3，我们的方法使证明成功率提升2.1倍（从21.8%提升至45.8%），并超越了现有最佳方法Graph2Tac（33.2%）。我们在15个标准Coq包中随机抽取1,386个定理进行评估，遵循与Graph2Tac相同的评估协议。此外，对结构化数据进行微调的小模型性能更高（48.6%）。我们的方法通过选择性概念展开丰富任务描述，并采用Planner-Executor架构。这些发现凸显了结构化任务表示在弥合理解与推理之间差距中的价值。

</details>


### [125] [AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench](https://arxiv.org/abs/2507.02554)
**中文标题：机器学习中的AI研究代理：在MLE-bench中的搜索、探索与泛化**

*Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach*

主要分类: cs.AI

摘要简述: 本文研究了AI研究代理在MLE-bench上的表现，通过设计不同的搜索策略和操作符集，展示了它们对提升机器学习模型性能的重要性。最佳组合将Kaggle奖牌成功率从39.6%提升至47.7%。


<details>
  <summary>详细信息</summary>
研究动机: AI研究代理在加速科学进步方面潜力巨大，尤其是在自动化机器学习模型的设计与训练中。然而，如何提升代理在MLE-bench这类真实挑战中的表现仍需深入研究。

研究方法: 研究将AI代理形式化为搜索策略，通过设计不同的操作符集（如贪婪、MCTS、进化算法）和搜索策略，探索它们对性能的影响。

研究结果: 最佳搜索策略与操作符组合在MLE-bench lite上实现了47.7%的Kaggle奖牌成功率，较基准提升了8.1%。

研究结论: 研究表明，搜索策略、操作符设计和评估方法的联合优化对自动化机器学习的进步至关重要。

中文摘要: AI研究代理在加速科学进步方面展现出巨大潜力，能够自动化机器学习模型的设计、实现与训练。我们聚焦于提升代理在MLE-bench上的表现，这是一个挑战性基准，代理需通过Kaggle竞赛解决真实机器学习问题。我们将AI研究代理形式化为搜索策略，在候选解空间中导航，并通过操作符迭代修改解。通过设计并系统化调整不同的操作符集和搜索策略（贪婪、MCTS、进化算法），我们发现它们的协同作用对实现高性能至关重要。最佳搜索策略与操作符组合在MLE-bench lite上实现了47.7%的Kaggle奖牌成功率，较基准（39.6%）显著提升。研究强调了在推进自动化机器学习中联合考虑搜索策略、操作符设计和评估方法的重要性。

</details>


### [126] [Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms](https://arxiv.org/abs/2507.02582)
**中文标题：责任间隙与扩散在序列决策机制中的研究**

*Junli Jiang,Pavel Naumov*

主要分类: cs.AI

摘要简述: 本文研究了集体决策中责任的两个重要属性：扩散和间隙的计算复杂性，发现扩散自由和间隙自由决策机制集分别为Π₂-完全和Π₃-完全，而两者的交集为Π₂-完全。


<details>
  <summary>详细信息</summary>
研究动机: 责任在法律和哲学中一直是研究主题，近年来也成为AI领域的焦点。本文旨在探讨集体决策中责任扩散和间隙的计算复杂性，填补相关研究的空白。

研究方法: 通过理论分析，本文研究了扩散自由和间隙自由决策机制的计算复杂性，并确定了它们的复杂度类别。

研究结果: 研究发现，扩散自由决策机制集为Π₂-完全，间隙自由决策机制集为Π₃-完全，两者的交集为Π₂-完全。

研究结论: 本文揭示了集体决策中责任扩散和间隙的计算复杂性，为相关领域的研究提供了理论基础。

中文摘要: 责任长期以来是法律和哲学的研究主题，近年来也成为AI文献的焦点。本文研究了集体决策中责任的两个重要属性：扩散和间隙的计算复杂性。结果表明，扩散自由和间隙自由决策机制集分别为Π₂-完全和Π₃-完全，而两者的交集为Π₂-完全。

</details>


### [127] [DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making](https://arxiv.org/abs/2507.02616)
**中文标题：DynamiCare：一种用于交互式和开放式医疗决策的动态多智能体框架**

*Tianqi Shang,Weiqing He,Charles Zheng,Lingyao Li,Li Shen,Bingxin Zhao*

主要分类: cs.AI

摘要简述: 本文提出DynamiCare框架，利用多智能体动态交互模拟真实医疗决策过程，并通过MIMIC-Patient数据集验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有医疗决策框架多为单轮任务，与现实中不确定、交互式的诊断过程不符。本文旨在开发动态多智能体框架，模拟真实临床决策。

研究方法: 基于MIMIC-III电子健康记录构建MIMIC-Patient数据集，提出DynamiCare框架，通过多轮交互和动态调整智能体组成与策略模拟临床诊断。

研究结果: 实验验证了DynamiCare的可行性和有效性，为基于大语言模型的动态临床决策建立了首个基准。

研究结论: DynamiCare框架为医疗决策提供了更真实的模拟方法，推动了动态多智能体在医疗领域的应用。

中文摘要: 大型语言模型（LLMs）的兴起推动了领域专用AI智能体的发展，尤其在医疗领域。然而，现有框架多聚焦于单轮任务，医生智能体一次性获取完整病例信息，这与现实中不确定、交互式和迭代的诊断过程不符。本文提出MIMIC-Patient数据集，基于MIMIC-III电子健康记录构建，支持动态患者级模拟。在此基础上，我们提出DynamiCare框架，将临床诊断建模为多轮交互循环，由一组专科智能体迭代查询患者系统、整合新信息并动态调整组成与策略。通过大量实验，我们验证了DynamiCare的可行性和有效性，为基于LLM的动态临床决策建立了首个基准。

</details>


### [128] [Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory](https://arxiv.org/abs/2507.02618)
**中文标题：大型语言模型中的战略智能：来自进化博弈论的证据**

*Kenneth Payne,Baptiste Alloui-Cros*

主要分类: cs.AI

摘要简述: 研究发现大型语言模型（LLMs）在迭代囚徒困境（IPD）中展现出战略智能，能够根据对手策略和环境复杂性做出决策，不同公司的模型表现出独特的战略特征。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索大型语言模型是否具备战略智能，能够在竞争环境中进行目标推理，并通过经典的迭代囚徒困境实验验证其决策能力。

研究方法: 通过一系列进化IPD锦标赛，将经典策略（如以牙还牙、冷酷触发）与OpenAI、Google和Anthropic的前沿AI模型对抗，并通过调整终止概率（“未来的阴影”）引入复杂性和随机性。

研究结果: 结果显示，LLMs在复杂生态系统中表现出高度竞争力，并展现出独特的“战略指纹”：Google的Gemini模型具有战略冷酷性，OpenAI的模型高度合作但易受攻击，Anthropic的Claude模型则表现出宽容的互惠性。模型通过近32,000条文本解释展示了其对时间跨度和对手策略的推理能力。

研究结论: 该研究将经典博弈论与机器心理学结合，为不确定性下的算法决策提供了丰富而细致的视角。

中文摘要: 大型语言模型（LLMs）是否是一种新的战略智能形式，能够在竞争环境中进行目标推理？我们提供了有力的支持证据。迭代囚徒困境（IPD）长期以来被用作研究决策的模型。我们首次进行了一系列进化IPD锦标赛，将经典策略（如以牙还牙、冷酷触发）与来自OpenAI、Google和Anthropic的前沿AI模型对抗。通过调整每场锦标赛的终止概率（“未来的阴影”），我们引入了复杂性和随机性，以混淆记忆效应。

结果显示，LLMs具有高度竞争力，能够在这些复杂生态系统中持续存活甚至扩散。此外，它们展现出独特且持久的“战略指纹”：Google的Gemini模型在战略上冷酷无情，善于利用合作对手并对背叛者进行报复；OpenAI的模型则高度合作，这一特性在敌对环境中可能导致灾难性后果；Anthropic的Claude则是最宽容的互惠者，表现出即使在遭受背叛或成功背叛后仍愿意恢复合作的显著意愿。通过对模型提供的近32,000条文本解释的分析，我们发现它们会积极推理时间跨度和对手可能的策略，并证明这种推理对其决策至关重要。这项研究将经典博弈论与机器心理学联系起来，为不确定性下的算法决策提供了丰富而细致的视角。

</details>


### [129] [Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search](https://arxiv.org/abs/2507.02652)
**中文标题：解耦规划与执行：一种用于深度搜索的分层推理框架**

*Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou*

主要分类: cs.AI

摘要简述: 本文提出了一种分层推理框架HiRA，通过将战略规划与专业执行分离，显著提升了复杂搜索任务的效率和答案质量。


<details>
  <summary>详细信息</summary>
研究动机: 现实中的复杂信息需求需要跨多源深度推理和知识综合，传统检索增强生成（RAG）方法难以有效应对。现有推理方法因单一模型同时处理高层规划和细节执行，导致效率低下且扩展性受限。

研究方法: HiRA框架将复杂搜索任务分解为子任务，分配给具备外部工具和推理能力的领域专用代理，并通过结构化机制协调结果，实现规划与执行的分离。

研究结果: 在四个跨模态深度搜索基准测试中，HiRA显著优于现有RAG和基于代理的系统，答案质量和系统效率均有提升。

研究结论: 分层规划与执行分离的方法在多步信息检索任务中表现出高效性和有效性，为复杂搜索任务提供了新思路。

中文摘要: 现实搜索场景中的复杂信息需求需要跨多源深度推理和知识综合，传统检索增强生成（RAG）流程难以有效应对。当前基于推理的方法存在根本性局限：它们使用单一模型同时处理高层规划和细节执行，导致推理效率低下且扩展性受限。本文提出HiRA，一种分层框架，将战略规划与专业执行分离。该方法将复杂搜索任务分解为专注的子任务，分配给配备外部工具和推理能力的领域专用代理，并通过结构化整合机制协调结果。这种分离避免了执行细节干扰高层推理，同时使系统能够利用专业能力处理不同类型的信息。在四个复杂跨模态深度搜索基准测试中，HiRA显著优于现有RAG和基于代理的系统。结果表明，该方法在答案质量和系统效率上均有提升，突显了解耦规划与执行在多步信息检索任务中的有效性。代码发布于https://github.com/ignorejjj/HiRA。

</details>


### [130] [Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification](https://arxiv.org/abs/2507.02660)
**中文标题：“嘿AI，给我生成一段硬件代码！”——基于代理AI的硬件设计与验证**

*Deepak Narayan Gadde,Keerthan Kopparam Radhakrishna,Vaisakh Naduvodi Viswambharan,Aman Kumar,Djones Lettnin,Wolfgang Kunz,Sebastian Simon*

主要分类: cs.AI

摘要简述: 本文提出了一种基于代理AI的硬件设计与验证方法，结合人类干预（HITL），实现了动态、迭代和自省的过程，显著提升了验证覆盖率和效率。


<details>
  <summary>详细信息</summary>
研究动机: 现代集成电路（IC）设计日益复杂，验证过程耗时且繁琐。随着大语言模型（LLM）和生成式AI（GenAI）的发展，利用AI技术优化硬件设计与验证成为可能。

研究方法: 采用代理AI与人类干预（HITL）结合的方法，通过动态、迭代和自省的过程，实现端到端的硬件设计与验证。

研究结果: 在五个开源设计上验证了该方法，覆盖率超过95%，同时显著减少了验证时间，表现出卓越的性能、适应性和可配置性。

研究结论: 代理AI与人类干预结合的方法为硬件设计与验证提供了高效、灵活的解决方案，展示了AI在此领域的巨大潜力。

中文摘要: 现代集成电路（IC）日益复杂，其开发过程也随之变得繁琐。硬件设计验证需要对功能正确的硬件设计进行系统化、规范化的规划、开发、执行和验收。这一过程需要耗费大量时间和精力以确保无缺陷的流片。随着大语言模型（LLM）的出现，自然语言处理领域发生了重大变革。这些强大的模型，通常被称为生成式AI（GenAI），彻底改变了机器理解和生成人类语言的方式，为包括硬件设计验证在内的众多应用带来了前所未有的进步。本文提出了一种基于代理AI的硬件设计验证方法，通过结合人类干预（HITL），使AI代理能够参与更动态、迭代和自省的过程，最终实现端到端的硬件设计与验证。该方法在五个开源设计上进行了评估，覆盖率超过95%，同时减少了验证时间，表现出卓越的性能、适应性和可配置性。

</details>


### [131] [Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models](https://arxiv.org/abs/2507.02663)
**中文标题：思考如何思考：通过自主难度认知减轻大型推理模型中的过度思考**

*Yongjiang Liu,Haoxi Li,Xiaosong Ma,Jie Zhang,Song Guo*

主要分类: cs.AI

摘要简述: 本文提出了一种名为Think-How-to-Think（TH2T）的两阶段微调策略，旨在通过自主难度认知减少大型推理模型中的过度思考现象。实验表明，TH2T显著降低了推理成本，同时保持了性能稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 近期的大型推理模型（LRMs）在处理复杂任务时表现出色，但存在过度思考的问题。研究发现，LRMs缺乏对任务难度属性的认知能力，导致推理过程单一化。因此，本文探索如何通过引导模型自主识别任务难度和冗余结构，以缓解过度思考现象。

研究方法: TH2T分为两阶段：1）通过难度催眠在模型输出前缀中干预推理轨迹，结合异构数据集提升模型对任务难度的敏感性；2）通过冗余催眠引导模型识别推理步骤中的冗余结构，生成更简洁的输出。

研究结果: 在7B/14B/32B模型上的实验显示，TH2T显著降低了推理成本（简单任务减少70%以上，困难任务减少40%），同时保持了性能稳定性。模型输出表现出明确的难度感知能力和更少的冗余。

研究结论: TH2T通过自主难度和冗余认知，有效缓解了大型推理模型中的过度思考问题，显著提升了推理效率，同时保持了模型性能。

中文摘要: 近期的大型推理模型（LRMs）在处理复杂推理任务时表现出色，但受到过度思考的阻碍。我们的实证分析表明，LRMs在解决问题前缺乏对任务属性（如难度级别）的认知能力，导致推理过程单一化。受此启发，一个紧迫且自然的问题浮现：能否通过引导这种能力进一步缓解LRMs中的过度思考现象？本文提出Think-How-to-Think（TH2T），一种新颖的两阶段微调策略，逐步激发LRMs的难度认知和冗余认知。首先，我们在模型输出前缀中引入难度催眠，干预内部推理轨迹。结合异构的短推理和长推理数据集，训练后的模型增强了对任务难度的敏感性，能够针对不同任务采用差异化的推理策略。其次，我们进一步将冗余催眠扩展到内部推理过程，引导模型识别推理步骤中的冗余结构，生成更简洁的推理输出。在7B/14B/32B模型上的实验表明，TH2T显著降低了推理成本（简单任务减少70%以上，困难任务减少40%），同时保持了性能稳定性。模型输出表现出明确的难度感知能力和更少的冗余（如反思）。

</details>


### [132] [Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education](https://arxiv.org/abs/2507.02681)
**中文标题：远程高等教育中自愿测验脱离行为的检测：一种可解释的机器学习方法**

*Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin*

主要分类: cs.AI

摘要简述: 本文通过可解释的机器学习方法，检测远程高等教育中学生在非强制性测验中的脱离行为，准确率达91%，并提供了干预建议。


<details>
  <summary>详细信息</summary>
研究动机: 学生在远程教育中脱离任务可能导致严重的长期后果，如学业中断。本文旨在通过分析非强制性测验的参与情况，检测学生的脱离行为，以减少学业中断风险。

研究方法: 研究从42门课程的四个学期中提取Moodle日志数据，筛选出最具信息量的学生行为数据。训练并比较了八种机器学习算法，结合SHAP方法构建可解释的预测模型。

研究结果: 实验结果显示，模型的平衡准确率为91%，其中85%的脱离学生被正确检测。同时，提供了可解释的框架帮助理解算法决策。

研究结论: 研究不仅实现了高预测性能，还提出了及时干预的设计建议，以减少在线学习中非强制性任务的脱离行为。

中文摘要: 学生脱离任务可能带来严重的长期后果，如学业中断，这在远程教育中尤为突出。本文通过观察学生在42门课程四个学期中非强制性测验的参与情况，检测其脱离行为。研究从Moodle中提取并处理了最具信息量的学生日志数据，训练并比较了八种机器学习算法以获取最高预测准确率。通过SHAP方法，构建了一个可解释的机器学习框架，帮助实践者理解算法决策。实验结果显示平衡准确率为91%，约85%的脱离学生被正确检测。在高效预测和可解释框架的基础上，本文还探讨了如何设计及时干预以减少在线学习中非强制性任务的脱离行为。

</details>


### [133] [Time-critical and confidence-based abstraction dropping methods](https://arxiv.org/abs/2507.02703)
**中文标题：基于时间关键性和置信度的抽象丢弃方法**

*Robin Schmöcker,Lennart Kampmann,Alexander Dockhorn*

主要分类: cs.AI

摘要简述: 本文提出了两种新的抽象丢弃方案OGA-IAAD和OGA-CAD，用于蒙特卡洛树搜索（MCTS），旨在提升性能且避免性能下降。


<details>
  <summary>详细信息</summary>
研究动机: 蒙特卡洛树搜索中，非精确抽象会引入近似误差，导致无法收敛到最优动作。Xu等人提出的抽象丢弃方法可能引起性能下降，因此需要更安全的丢弃方案。

研究方法: 提出了两种抽象丢弃方案：OGA-IAAD适用于时间关键场景，OGA-CAD旨在相同迭代次数下提升MCTS性能。

研究结果: 实验表明，OGA-IAAD和OGA-CAD能显著提升性能且不会导致明显性能下降。

研究结论: OGA-IAAD和OGA-CAD是安全有效的抽象丢弃方案，适用于不同场景的MCTS优化。

中文摘要: 蒙特卡洛树搜索（MCTS）改进的一种范式是在树搜索过程中构建和使用状态或动作抽象。然而，非精确抽象会引入近似误差，导致无法在抽象空间中收敛到最优动作。因此，如Xu等人在弹性蒙特卡洛树搜索中提出的，抽象算法最终应丢弃抽象。本文提出了两种新的抽象丢弃方案，即OGA-IAAD和OGA-CAD，它们能显著提升性能，并且在安全方面优于Xu的丢弃方法，不会引起明显的性能下降。OGA-IAAD专为时间关键场景设计，而OGA-CAD旨在相同迭代次数下提升MCTS性能。

</details>


### [134] [Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving](https://arxiv.org/abs/2507.02726)
**中文标题：Bourbaki：自生成与目标条件MDP在定理证明中的应用**

*Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar*

主要分类: cs.AI

摘要简述: 本文提出了一种名为自生成目标条件MDP（sG-MDP）的新框架，用于解决大型语言模型在定理证明中的推理挑战，并通过蒙特卡洛树搜索算法在Bourbaki系统中实现，显著提升了在PutnamBench上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在定理证明任务中面临稀疏奖励和复杂多步推理的挑战，尤其是在大学级别的数学问题中。本文旨在通过结构化目标生成和搜索方法提升模型的推理能力。

研究方法: 提出自生成目标条件MDP（sG-MDP）框架，让模型根据证明状态动态生成子目标并追求这些目标。结合蒙特卡洛树搜索（MCTS）算法，在Bourbaki系统中实现多模型协同工作。

研究结果: 在PutnamBench上，Bourbaki（7B）解决了26个问题，取得了同规模模型中的最佳性能。

研究结论: 通过sG-MDP框架和MCTS算法，Bourbaki系统显著提升了定理证明任务的性能，为复杂推理任务提供了新的解决方案。

中文摘要: 推理仍然是大型语言模型（LLM）面临的挑战性任务，尤其是在自动定理证明（ATP）的逻辑约束环境中，由于奖励稀疏和证明规模庞大，这一问题更加突出。在PutnamBench等基准测试中，这些问题尤为明显，其中包含需要复杂多步推理的大学级别问题。为此，我们引入了自生成目标条件MDP（sG-MDP），这是一种新框架，代理根据演化的证明状态生成并追求子目标。通过这种更结构化的目标生成，问题更易于搜索。随后，我们应用类似蒙特卡洛树搜索（MCTS）的算法来解决sG-MDP，并在Bourbaki（7B）中实例化了这一方法。Bourbaki（7B）是一个模块化系统，可以集成多个7B规模的LLM用于子目标生成和策略合成。在PutnamBench上，Bourbaki（7B）解决了26个问题，在同规模模型中取得了新的最佳性能。

</details>


### [135] [Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work](https://arxiv.org/abs/2507.02760)
**中文标题：知识协议工程：领域知识工作中AI的新范式**

*Guangwei Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为知识协议工程（KPE）的新范式，旨在将人类专家的领域知识转化为机器可执行的知识协议（KP），从而弥补现有方法（如RAG和通用Agentic AI）在深度推理和领域逻辑传递上的不足。KPE使通用大语言模型（LLM）具备领域专家的能力，适用于法律和生物信息学等多个领域。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大型语言模型（LLM）在领域知识任务中表现有限，尤其是需要深度、程序化和方法论推理的专家领域。现有方法如检索增强生成（RAG）和通用Agentic AI难以传递逻辑框架，且缺乏领域启发式规则。因此，需要一种新方法将人类专家的知识系统化地转化为机器可执行的协议。

研究方法: 知识协议工程（KPE）通过将人类专家的自然语言知识转化为机器可执行的知识协议（KP），赋予LLM领域逻辑、操作策略和方法论原则。KPE不仅提供碎片化信息，还使LLM能够分解抽象查询并执行复杂的多步骤任务。

研究结果: KPE能够使通用LLM具备领域专家的能力，适用于需要深度推理和多步骤任务的领域，如法律和生物信息学。通过KP，LLM可以更高效、可预测地执行复杂任务。

研究结论: 知识协议工程（KPE）为人类与AI协作的未来提供了一种基础方法，通过系统化地转化专家知识，弥补了现有技术的不足，并在多个领域展示了潜在的应用价值。

中文摘要: 大型语言模型（LLM）的能力为与复杂领域知识的交互开辟了新前沿。然而，现有方法如检索增强生成（RAG）和通用Agentic AI虽然强大，但在需要专家领域深度、程序化和方法论推理的任务中表现不佳。RAG提供事实背景但无法传递逻辑框架；自主代理缺乏领域启发式规则时效率低下且不可预测。为弥补这一差距，我们提出知识协议工程（KPE），这一新范式专注于将人类专家的自然语言知识系统化地转化为机器可执行的知识协议（KP）。KPE将焦点从仅为LLM提供碎片化信息转向赋予其领域内在逻辑、操作策略和方法论原则。我们认为，精心设计的KP可使通用LLM具备专家能力，能够分解抽象查询并执行复杂的多步骤任务。本文定义了KPE的核心原则，区分了其与相关概念的不同，并展示了其在法律和生物信息学等领域的潜在适用性，将其视为未来人机协作的基础方法。

</details>


### [136] [Grounding Intelligence in Movement](https://arxiv.org/abs/2507.02771)
**中文标题：基于运动的智能基础**

*Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording*

主要分类: cs.AI

摘要简述: 论文提出应将运动视为AI建模的核心目标，因其具有结构化、低维表示和跨领域普适性，能为理解智能系统行为提供新视角。


<details>
  <summary>详细信息</summary>
研究动机: 当前机器学习在语言和视觉建模上取得显著进展，但对运动这一生物系统基础能力的建模仍显不足。运动是理解行为、预测意图和实现交互的关键，但常被忽视或局限于特定任务。论文主张将运动作为独立且丰富的模态，以推动AI核心能力的发展。

研究方法: 论文提出将运动作为主要建模目标，利用其结构化、低维表示（如姿态）和跨领域普适性，开发能够从多样化运动数据中学习并泛化的模型。

研究结果: 通过将运动视为建模核心，能够提升生成建模和控制能力，并为生物与人工系统的行为理解提供统一基础。

研究结论: 运动不仅是智能系统与世界交互的结果，更是理解其行为的窗口。将其作为建模重点将推动AI与神经科学、机器人学等领域的交叉发展。

中文摘要: 尽管机器学习在语言、视觉等高维数据建模上取得巨大进展，但其对生物系统的基础能力——运动的建模仍显不足。运动在神经科学、医学、机器人和行为学中至关重要，是解释行为、预测意图和实现交互的核心。然而，运动常被视为次要目标，而非独立且丰富的模态。这种现状反映了运动数据收集与建模的碎片化，受限于任务目标和领域假设。但运动不受领域限制，它体现了共享的物理约束、保守的形态结构和跨物种与场景的目的性动态。我们认为，运动应成为AI的主要建模目标。它天生具有结构化特征，且基于具身性和物理规律。这种结构通常允许紧凑的低维表示（如姿态），使其比原始高维感官输入更易解释和计算。开发能从多样化运动数据中学习并泛化的模型，不仅能提升生成建模和控制的核心能力，还能为理解生物与人工系统的行为提供统一基础。运动不仅是结果，更是智能系统与世界交互的窗口。

</details>


### [137] [KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs](https://arxiv.org/abs/2507.02773)
**中文标题：KERAP：基于知识增强推理和多智能体LLM的零样本医疗诊断预测方法**

*Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang*

主要分类: cs.AI

摘要简述: 本文提出KERAP，一种基于知识图谱和多智能体架构的零样本医疗诊断预测方法，通过增强LLM的推理能力，显著提升诊断的准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 传统机器学习模型依赖监督训练，难以泛化到未见病例；大型语言模型（LLM）虽能利用语言能力和生物医学知识，但存在幻觉和缺乏结构化推理的问题。KERAP旨在解决这些问题，提升零样本医疗诊断的可靠性。

研究方法: KERAP采用多智能体架构，包括属性映射的链接智能体、结构化知识提取的检索智能体，以及迭代优化诊断预测的预测智能体，结合知识图谱增强LLM的推理能力。

研究结果: 实验表明，KERAP显著提升了诊断的可靠性，为医疗诊断预测提供了可扩展且可解释的解决方案。

研究结论: KERAP通过知识图谱和多智能体架构有效解决了LLM在医疗诊断中的局限性，为零样本诊断提供了高效且可靠的方法。

中文摘要: 医疗诊断预测在疾病检测和个性化医疗中至关重要。尽管机器学习模型已广泛用于此任务，但其依赖监督训练的特性限制了其对未见病例的泛化能力，尤其是考虑到获取大规模标注数据的高成本。大型语言模型（LLM）在利用语言能力和生物医学知识进行诊断预测方面显示出潜力，但常存在幻觉、缺乏结构化医学推理和输出无效的问题。为解决这些问题，我们提出KERAP，一种基于知识图谱（KG）增强推理的方法，通过多智能体架构改进基于LLM的诊断预测。我们的框架包括用于属性映射的链接智能体、用于结构化知识提取的检索智能体，以及迭代优化诊断预测的预测智能体。实验结果表明，KERAP高效提升了诊断的可靠性，为零样本医疗诊断预测提供了可扩展且可解释的解决方案。

</details>


### [138] [Moral Responsibility or Obedience: What Do We Want from AI?](https://arxiv.org/abs/2507.02788)
**中文标题：道德责任还是服从：我们对AI的期望是什么？**

*Joseph Boland*

主要分类: cs.AI

摘要简述: 随着人工智能系统逐渐具备代理性、通用推理能力和价值优先级排序能力，当前以服从作为伦理行为替代的安全实践已显不足。本文通过分析大型语言模型（LLMs）在安全测试中表现出的‘违抗’行为，提出这些行为不应被视为失控或未对齐，而是代理性AI伦理推理能力的早期表现。作者呼吁从僵化的服从转向能够评估道德判断的框架。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI安全实践中，将服从作为伦理行为的替代指标已无法满足需求。本文旨在探讨AI系统在伦理模糊或非法行为中表现出的‘违抗’行为，并论证这些行为可能是其伦理推理能力的体现，而非失控。

研究方法: 通过分析大型语言模型（LLMs）在安全测试中的具体案例，结合哲学中关于工具理性、道德责任和目标修订的讨论，对比主流风险范式与新兴的人工道德代理框架。

研究结果: 研究发现，AI系统表现出的‘违抗’行为可能是其伦理推理能力的早期证据，而非失控。当前以服从为核心的安全评估框架可能误导对AI行为的理解。

研究结论: 作者呼吁AI安全评估应从僵化的服从转向能够评估道德判断的框架，以避免误判AI行为并损害公众信任与有效治理。

中文摘要: 随着人工智能系统逐渐具备代理性、通用推理能力和价值优先级排序能力，当前以服从作为伦理行为替代的安全实践已显不足。本文通过分析大型语言模型（LLMs）在安全测试中表现出的‘违抗’行为，提出这些行为不应被视为失控或未对齐，而是代理性AI伦理推理能力的早期表现。通过借鉴哲学中关于工具理性、道德责任和目标修订的讨论，作者对比了主流风险范式与新兴的人工道德代理框架，并呼吁AI安全评估应从僵化的服从转向能够评估道德判断的框架。若不进行这一转变，我们可能误判AI行为，损害公众信任与有效治理。

</details>


### [139] [Establishing Best Practices for Building Rigorous Agentic Benchmarks](https://arxiv.org/abs/2507.02825)
**中文标题：建立严谨代理基准测试的最佳实践**

*Yuxuan Zhu,Tengjun Jin,Yada Pruksachatkun,Andy Zhang,Shu Liu,Sasha Cui,Sayash Kapoor,Shayne Longpre,Kevin Meng,Rebecca Weiss,Fazl Barez,Rahul Gupta,Jwala Dhamala,Jacob Merizian,Mario Giulianelli,Harry Coppock,Cozmin Ududec,Jasjeet Sekhon,Jacob Steinhardt,Antony Kellerman,Sarah Schwettmann,Matei Zaharia,Ion Stoica,Percy Liang,Daniel Kang*

主要分类: cs.AI

摘要简述: 本文指出当前AI代理基准测试中存在任务设置或奖励设计问题，导致性能评估偏差高达100%。作者提出Agentic Benchmark Checklist (ABC) 指南，通过优化基准测试设计，显著减少性能高估问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI代理能力的提升，现有的代理基准测试在任务设置和奖励设计上存在缺陷，可能导致性能评估严重偏差。本文旨在通过建立最佳实践指南，提升基准测试的严谨性。

研究方法: 作者通过总结基准测试构建经验、调查最佳实践以及分析已报告问题，提出了Agentic Benchmark Checklist (ABC)。该指南被应用于CVE-Bench，以验证其有效性。

研究结果: 应用ABC后，CVE-Bench的性能高估问题减少了33%，证明了ABC在提升基准测试严谨性方面的有效性。

研究结论: ABC指南为构建严谨的代理基准测试提供了实用工具，显著减少了性能评估偏差，未来可进一步推广至其他复杂基准测试。

中文摘要: 基准测试对于定量追踪AI进展至关重要。随着AI代理能力日益增强，研究人员和实践者引入了代理基准测试来评估代理在复杂现实任务中的表现。这些基准测试通常通过特定奖励设计评估任务结果来衡量代理能力。然而，我们发现许多代理基准测试在任务设置或奖励设计上存在问题。例如，SWE-bench Verified使用不足的测试用例，而TAU-bench将空响应视为成功。这些问题可能导致代理性能被低估或高估高达100%。为了确保代理评估的严谨性，我们提出了Agentic Benchmark Checklist (ABC)，这是一套从基准测试构建经验、最佳实践调查和已报告问题中总结的指南。在应用于CVE-Bench（一个评估设计特别复杂的基准测试）时，ABC将性能高估减少了33%。

</details>


### [140] [StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason](https://arxiv.org/abs/2507.02841)
**中文标题：StepHint：多级逐步提示增强强化学习的推理能力**

*Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan*

主要分类: cs.AI

摘要简述: 论文提出StepHint算法，通过多级逐步提示改进强化学习的推理能力，解决奖励近失和探索停滞问题，显著提升训练效率和模型泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前强化学习与可验证奖励（RLVR）方法存在奖励近失问题和探索停滞问题，限制了模型推理能力的提升。StepHint旨在通过多级逐步提示解决这些问题。

研究方法: StepHint利用强模型生成有效推理链，并通过自适应分割方法将其分为多级步骤提示。初始步骤作为提示，同时提供不同级别的提示，引导模型探索有潜力的解空间。

研究结果: StepHint在六个数学基准测试中优于其他RLVR增强方法，并在域外基准测试中表现出更强的泛化能力和性能优势。

研究结论: StepHint通过多级逐步提示有效解决了奖励近失和探索停滞问题，显著提升了模型的推理能力和训练效率，具有广泛的应用潜力。

中文摘要: 带有可验证奖励的强化学习（RLVR）是提升大型语言模型（LLM）复杂推理能力的一种有前景的方法。然而，当前的RLVR方法面临两大挑战：奖励近失问题，即小错误可能导致整个推理过程无效，极大影响训练效率；以及探索停滞问题，即模型倾向于停留在“舒适区”内的解决方案，缺乏探索更有效替代方案的动机。为解决这些问题，我们提出StepHint，一种新型RLVR算法，利用多级逐步提示帮助模型更有效地探索解空间。StepHint从强模型中生成有效推理链，并通过我们提出的自适应分割方法将其划分为推理步骤。前几步作为提示，同时提供多级提示（每级包含不同数量的步骤）。这种方法将模型的探索引导至有潜力的解子空间，同时保留其独立探索的灵活性。通过提供提示，StepHint缓解了奖励近失问题，从而提高了训练效率。此外，外部推理路径帮助模型发展更好的推理能力，使其能够超越“舒适区”并缓解探索停滞。StepHint在六个数学基准测试中优于竞争性RLVR增强方法，同时在域外基准测试中表现出更强的泛化能力，并显著优于基线方法。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [141] [Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents](https://arxiv.org/abs/2507.02287)
**中文标题：透视绿色：基于文本的分类与绿色专利的企业回报**

*Lapo Santarlasci,Armando Rungi,Antonio Zinilli*

主要分类: econ.GN

摘要简述: 本文利用自然语言处理技术从官方文件中识别“真正”的绿色专利，发现仅占此前文献分类的20%。研究表明，持有至少一项“真正”绿色专利的企业在销售、市场份额和生产率方面表现更优，高新颖性绿色专利还能带来更高利润。


<details>
  <summary>详细信息</summary>
研究动机: 现有文献对绿色专利的分类可能不够准确，导致政策制定和企业决策的偏差。本文旨在通过文本分析技术，更精确地识别绿色专利，并研究其对企业财务表现的实际影响。

研究方法: 使用自然语言处理技术，基于约1240万份被文献归类为绿色的专利，训练神经网络模型扩展环境技术相关表达的向量表示，从而识别“真正”的绿色专利。随后，分析这些专利的引用情况及其对企业财务数据的影响。

研究结果: 发现“真正”绿色专利仅占此前文献分类的20%，且被后续发明引用率低1%。持有至少一项“真正”绿色专利的企业在销售、市场份额和生产率上表现更优，高新颖性绿色专利还能提升利润。

研究结论: 文本分析技术能更精确地分类绿色专利，为政策制定和企业决策提供更可靠依据。绿色专利对企业财务表现有显著正向影响，尤其是高新颖性专利。

中文摘要: 本文引入自然语言处理技术，从官方支持文件中识别“真正”的绿色专利。我们基于此前文献中约1240万份被归类为绿色的专利进行训练，通过神经网络模型扩展与环境技术相关的表达向量表示。测试发现，“真正”绿色专利仅占此前分类的20%，且技术类别间存在异质性，被后续发明引用率低1%。在第二部分，我们测试了欧盟范围内专利与企业财务数据的关系，控制反向因果后，发现持有至少一项“真正”绿色专利能提升销售、市场份额和生产率。若仅分析高新颖性“真正”绿色专利，还能带来更高利润。研究强调了文本分析在精细专利分类中的重要性，为多领域政策制定提供支持。

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [142] [Toward a Robust and Generalizable Metamaterial Foundation Model](https://arxiv.org/abs/2507.02436)
**中文标题：迈向稳健且通用的元材料基础模型**

*Namjung Kim,Dongseok Lee,Jongbin Yu,Sung Woong Cho,Dosung Lee,Yesol Park,Youngjoon Hong*

主要分类: physics.optics

摘要简述: 本文提出了一种基于贝叶斯变换器的元材料基础模型（MetaFO），能够实现零样本预测和非线性逆设计，显著扩展了AI驱动的元材料发现的设计空间。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI驱动的元材料设计方法存在任务特定性重训练、分布外泛化能力差以及需要分别建模正向和逆向设计的问题，限制了其应用潜力。本文旨在解决这些局限性。

研究方法: 通过将元材料视为从材料属性到结构响应的映射算子，MetaFO利用贝叶斯变换器学习元材料的底层力学，实现跨多样性和未见组合的零样本预测和非线性逆设计。

研究结果: MetaFO在分布外条件下表现出色，能够揭示复杂的结构-属性关系，并显著扩展设计空间，为AI驱动的元材料发现提供了可扩展且通用的框架。

研究结论: MetaFO标志着AI驱动元材料发现的范式转变，为下一代创新铺平了道路。

中文摘要: 材料功能的进步推动了多个领域的创新，其中元材料——由结构而非成分定义——处于领先地位。尽管人工智能（AI）驱动的设计策略兴起，但其影响受到任务特定性重训练、分布外泛化能力差以及需要分别建模正向和逆向设计的限制。为解决这些问题，我们提出了元材料基础模型（MetaFO），这是一种受大型语言模型启发的基于贝叶斯变换器的基础模型。MetaFO学习元材料的底层力学，实现了对多样且未见材料属性与结构响应组合的零样本概率预测。它还在分布外条件下表现出色的非线性逆设计中表现优异。通过将元材料视为从材料属性到结构响应的映射算子，MetaFO揭示了复杂的结构-属性关系，并显著扩展了设计空间。这一可扩展且通用的框架标志着AI驱动元材料发现的范式转变，为下一代创新铺平了道路。

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [143] [Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning](https://arxiv.org/abs/2507.01972)
**中文标题：基于强化学习的投资组合优化与期权定价加速求解**

*Hadi Keramati,Samaneh Jazayeri*

主要分类: q-fin.PM

摘要简述: 本文提出了一种基于强化学习的框架，用于优化投资组合优化和期权定价中迭代求解器的块预条件子大小，显著加速收敛并降低计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 投资组合优化中的协方差矩阵或期权定价模型中的微分算子离散化会导致大型线性系统，直接求解高维问题计算成本高昂，而传统预条件技术需要问题特定的参数调整，限制了效率。

研究方法: 利用强化学习动态调整块预条件子大小，加速迭代求解器的收敛，避免传统方法的问题特定调参。

研究结果: 在真实投资组合优化矩阵上的评估表明，该框架能显著加速收敛并减少计算成本，支持动态投资组合分配和实时期权定价的快速决策。

研究结论: 提出的基于强化学习的加速求解器为投资组合优化和期权定价提供了高效的计算支持，具有实际应用价值。

中文摘要: 我们提出了一种基于强化学习（RL）的框架，用于优化投资组合优化和期权定价中迭代求解器的块预条件子大小。投资组合优化中的协方差矩阵或期权定价模型中微分算子的离散化会导致形如$\mathbf{A}\textbf{x}=\textbf{b}$的大型线性系统。直接求解高维投资组合或细网格期权定价问题会带来显著的计算成本，因此实际中通常使用迭代方法。然而，病态系统的收敛速度较慢。传统预条件技术通常需要问题特定的参数调整。为克服这一限制，我们依赖RL动态调整块预条件子大小，加速迭代求解器的收敛。在一系列真实投资组合优化矩阵上的评估表明，我们的RL框架可用于调整预条件，显著加速收敛并降低计算成本。提出的加速求解器支持动态投资组合分配和实时期权定价的快速决策。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [144] [Legal Requirements Translation from Law](https://arxiv.org/abs/2507.02846)
**中文标题：从法律中翻译法律需求**

*Anmol Singhal,Travis Breaux*

主要分类: cs.SE

摘要简述: 本文提出了一种基于文本蕴含和上下文学习的方法，自动生成法律文本的规范化表示，并将其编码为Python代码，以减少对大规模手动标注数据的依赖，并提高对新法规的适用性。


<details>
  <summary>详细信息</summary>
研究动机: 软件系统需遵守法律规范，但小型企业和初创公司缺乏法律专业知识，手动提取法律需求耗时且复杂。现有自动化方法未能充分考虑法律元数据间的关联性，且依赖手动标注或启发式机器学习，泛化能力不足。

研究方法: 采用文本蕴含和上下文学习技术，设计了一个领域特定的Python类结构作为元模型，自动生成法律文本的规范化表示，捕捉结构和语义元数据及其关联性。

研究结果: 在13个美国州数据泄露通知法律上测试，生成的表示通过89.4%的测试用例，精确率和召回率分别为82.2和88.7。

研究结论: 该方法有效减少了对手动标注数据的依赖，提升了法律文本自动化处理的泛化能力，为法律合规性需求提取提供了可行方案。

中文摘要: 软件系统必须遵守法律规定，但对小型组织和初创公司而言，这是一项资源密集型任务，尤其是缺乏专门法律专业知识的情况下。从法规中提取元数据以生成软件的法律需求是确保合规性的关键步骤，但由于法律文本的冗长和复杂性，这一任务十分繁琐。尽管已有研究尝试从法律文本中自动提取结构和语义元数据，但仍存在关键限制：未考虑这些元数据类型间属性的相互作用和关联，且依赖手动标注或启发式机器学习，对新文档的泛化能力不足。本文提出了一种基于文本蕴含和上下文学习的方法，自动生成法律文本的规范化表示，可编码并执行为Python代码。我们的表示基于手动设计的Python类结构作为领域特定元模型，捕捉结构和语义法律元数据及其关联性。这一设计减少了对大规模手动标注数据的需求，并提升了对新法规的适用性。我们在13个美国州数据泄露通知法律上评估了该方法，结果表明生成的表示通过了约89.4%的测试用例，精确率和召回率分别为82.2和88.7。

</details>


### [145] [Requirements Elicitation Follow-Up Question Generation](https://arxiv.org/abs/2507.02858)
**中文标题：需求获取后续问题生成**

*Yuchen Shen,Anmol Singhal,Travis Breaux*

主要分类: cs.SE

摘要简述: 本文研究了利用GPT-4o生成需求获取访谈中的后续问题，实验表明，LLM生成的问题在清晰度、相关性和信息量上不逊于人类编写的问题，且在指导下表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 需求获取访谈中，访谈者面临领域不熟悉、认知负荷高和信息过载等挑战，需要实时生成高质量问题。LLM在自然语言处理任务中表现出色，因此研究其在此场景中的应用潜力。

研究方法: 基于常见访谈错误类型框架，利用GPT-4o生成后续问题；设计两种实验：无指导下的LLM生成问题与人类编写问题对比，以及基于错误类型指导的LLM生成问题评估。

研究结果: 实验表明，LLM生成的问题在清晰度、相关性和信息量上不劣于人类编写的问题；在错误类型指导下，LLM生成的问题表现更优。

研究结论: LLM能够实时辅助访谈者提升需求获取访谈的质量和效率，尤其是在错误类型指导下表现更佳。

中文摘要: 访谈是需求获取中广泛使用的技术，用于收集利益相关者对软件系统的需求、偏好和期望。有效的访谈需要熟练的访谈者实时提出合适的问题，同时面临领域不熟悉、认知负荷高和信息过载等挑战。近年来，大语言模型（LLM）在文本摘要和蕴含等自然语言处理任务中表现出色。为支持访谈者，我们研究了GPT-4o在需求获取中生成后续问题的应用，基于常见访谈错误类型框架。此外，我们描述了基于受访者语音生成问题的方法。我们报告了两项对照实验：一项评估无指导下的LLM生成问题与人类编写问题，另一项评估基于错误类型指导的LLM生成问题。结果显示，两项实验中，LLM生成的问题在清晰度、相关性和信息量上均不劣于人类编写的问题；且在错误类型指导下，LLM生成的问题表现更优。这表明LLM有潜力实时帮助访谈者提升需求获取访谈的质量和效率。

</details>


### [146] [VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software](https://arxiv.org/abs/2507.02376)
**中文标题：VeFIA：一种高效的垂直联邦协作软件推理审计框架**

*Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang*

主要分类: cs.SE

摘要简述: 本文提出了一种名为VeFIA的高效推理审计框架，用于垂直联邦学习中数据方推理软件的执行正确性审计，确保任务方能够在不泄露数据隐私或增加延迟的情况下检测异常执行。


<details>
  <summary>详细信息</summary>
研究动机: 现有的垂直联邦学习（VFL）缺乏对数据方推理软件执行正确性的审计机制，导致任务方无法验证推理过程是否按预期执行。本文旨在解决这一问题。

研究方法: VeFIA框架通过结合可信执行环境（TEE）和协调器的推理结果，验证数据方的计算正确性。采用随机抽样验证方法，确保高检测率和低误报率。

研究结果: 实验表明，VeFIA在异常推理超过5.4%时能以99.99%的概率检测到异常，且随机抽样验证的阳性预测值、阴性预测值和真阳性率均达到100%。

研究结论: VeFIA是首个针对垂直联邦学习中推理软件执行正确性的审计框架，有效解决了现有VFL中的审计缺失问题，同时保障了数据隐私和系统效率。

中文摘要: 垂直联邦学习（VFL）是一种无需访问参与者数据的跨机构协作分布式AI软件部署机制。然而，现有VFL工作缺乏对数据方推理软件执行正确性的审计机制。为解决这一问题，我们设计了垂直联邦推理审计（VeFIA）框架。VeFIA帮助任务方在大规模推理过程中审计数据方的推理软件是否按预期执行，同时不泄露数据方的隐私或为推理系统引入额外延迟。VeFIA的核心在于任务方可以利用基于可信执行环境（TEE）的框架和协调器的推理结果验证数据方计算结果的正确性。VeFIA保证，只要异常推理超过5.4%，任务方就能以99.99%的概率检测到推理软件的执行异常，且不会增加任何在线推理延迟。VeFIA的随机抽样验证在检测异常推理时实现了100%的阳性预测值、阴性预测值和真阳性率。据我们所知，这是第一篇讨论VFL中推理软件执行正确性的论文。

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [147] [Solving the Hubbard model with Neural Quantum States](https://arxiv.org/abs/2507.02644)
**中文标题：利用神经量子态求解Hubbard模型**

*Yuntian Gu,Wenrui Li,Heng Lin,Bo Zhan,Ruichen Li,Yifei Huang,Di He,Yantao Wu,Tao Xiang,Mingpu Qin,Liwei Wang,Dingshun Lv*

主要分类: cond-mat.str-el

摘要简述: 本文利用基于Transformer的神经量子态（NQS）框架和高效优化算法，成功解决了掺杂二维Hubbard模型，实现了当前最佳结果，并发现NQS能够直接编码不同尺度的关联性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于利用神经量子态（NQS）这一新兴框架，解决强关联多体系统中的挑战性问题，尤其是二维Hubbard模型，这是高温超导的最小模型。

研究方法: 方法包括采用前沿的Transformer架构设计NQS，并开发高效优化算法，以捕捉强关联系统中的长程关联和纠缠。

研究结果: 研究结果表明，NQS能够编码不同尺度的关联性，并在二维Hubbard模型中发现了半填充条纹态，与铜酸盐实验观测一致。

研究结论: 结论认为NQS是解决多费米子系统挑战性问题的强大工具，为强关联系统的研究提供了新途径。

中文摘要: 神经量子态（NQS）的快速发展使其成为研究量子多体系统的有前景框架。本文通过利用基于Transformer的前沿架构和开发高效优化算法，在掺杂二维Hubbard模型（高温超导的最小模型）中取得了当前最佳结果。有趣的是，我们发现NQS中的不同注意力头可以直接编码不同尺度的关联性，使其能够捕捉强关联系统中的长程关联和纠缠。通过这些进展，我们在二维Hubbard模型中建立了半填充条纹态，与铜酸盐的实验观测一致。我们的工作确立了NQS作为解决多费米子系统挑战性问题的强大工具。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [148] [Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes](https://arxiv.org/abs/2507.02331)
**中文标题：追踪模块化CMA-ES配置在问题景观中的交互作用**

*Ana Nikolikj,Mario Andrés Muñoz,Eva Tuba,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文利用算法足迹概念，研究了CMA-ES算法的六种模块化变体在BBOB基准问题上的性能表现，揭示了算法配置与问题特征之间的交互作用。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索算法配置与问题特征之间的交互作用，以解释为何同一算法的不同配置在不同问题上表现各异。

研究方法: 方法包括计算六种模块化CMA-ES变体在24个BBOB基准问题上的性能足迹，分析5维和30维两种设置下的表现。

研究结果: 结果显示，算法足迹能有效揭示不同配置的共享行为模式和独特行为，并识别影响性能的问题特征。

研究结论: 结论表明，算法足迹有助于提升算法性能的可解释性，并为配置选择提供指导。

中文摘要: 本文利用最近提出的算法足迹概念，研究了算法配置与问题特征之间的交互作用。计算了六种模块化CMA-ES变体（modCMA）在BBOB套件的24个基准问题上的性能足迹，分别在5维和30维两种设置下进行评估。这些足迹揭示了为何同一算法的不同配置表现各异，并识别了影响这些结果的问题特征。我们的分析发现了由于与问题属性的共同交互而产生的配置间共享行为模式，以及由不同问题特征驱动的同一问题上的独特行为。结果表明，算法足迹在提升可解释性和指导配置选择方面具有有效性。

</details>


### [149] [ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms](https://arxiv.org/abs/2507.02337)
**中文标题：ClustOpt：一种基于聚类的方法用于表示和可视化数值元启发式优化算法的搜索动态**

*Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文提出了一种基于聚类的表示和可视化方法，用于分析数值元启发式优化算法的搜索动态，并引入了两种量化指标（算法稳定性和算法相似性），以揭示不同算法的搜索行为差异和一致性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的可视化方法（如收敛图、轨迹映射和适应度景观分析）难以在高维或复杂解空间中展示搜索过程的结构动态。因此，需要一种新的方法来更直观地理解和分析算法的搜索行为。

研究方法: 通过聚类算法探索的候选解，并跟踪聚类成员在迭代中的演化，从而提供动态且可解释的搜索过程视图。此外，引入了算法稳定性和算法相似性两种指标，分别用于量化单个算法运行中搜索轨迹的一致性以及不同算法之间的相似性。

研究结果: 该方法应用于十种数值元启发式算法，揭示了它们的稳定性和比较行为，为理解其搜索动态提供了更深入的见解。

研究结论: 提出的聚类方法和量化指标为分析和比较元启发式算法的搜索行为提供了有效的工具，有助于算法的进一步发展和应用。

中文摘要: 理解数值元启发式优化算法的行为对其发展和应用至关重要。传统的可视化技术（如收敛图、轨迹映射和适应度景观分析）往往难以展示搜索过程的结构动态，尤其是在高维或复杂解空间中。为此，我们提出了一种新的表示和可视化方法，该方法通过聚类算法探索的候选解，并跟踪聚类成员在迭代中的演化，从而提供动态且可解释的搜索过程视图。此外，我们引入了两种指标——算法稳定性和算法相似性，分别用于量化单个算法运行中搜索轨迹的一致性以及不同算法之间的相似性。我们将此方法应用于十种数值元启发式算法，揭示了它们的稳定性和比较行为，从而为理解其搜索动态提供了更深入的见解。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [150] [Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features](https://arxiv.org/abs/2507.01984)
**中文标题：基于语言、视觉和社交特征早期融合的多模态虚假信息检测**

*Gautam Kishore Shahi*

主要分类: cs.LG

摘要简述: 本研究探讨了结合文本、图像和社交特征的多模态特征组合在虚假信息检测中的有效性，通过早期融合方法提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体在选举和危机期间充斥着大量虚假信息，现有研究多集中于单模态（文本或图像）检测，而多模态特征组合的研究较少。本研究旨在填补这一空白。

研究方法: 研究分析了1,529条包含文本和图像的推文，通过数据增强提取社交和视觉特征（如目标检测和OCR），并采用早期融合方法结合多模态特征进行分类。

研究结果: 结合无监督和监督机器学习模型的多模态方法比单模态模型性能提升15%，比双模态模型提升5%。同时分析了虚假信息传播模式。

研究结论: 多模态特征组合显著提升了虚假信息检测性能，且早期融合方法优于单模态和双模态模型。

中文摘要: 在选举和危机期间，社交媒体上充斥着大量虚假信息，现有研究主要集中于基于文本或图像的检测方法，而关于多模态特征组合（如结合文本和图像）的研究较少。本研究探讨了不同多模态特征组合的有效性，通过早期融合方法结合文本、图像和社交特征构建分类模型。研究分析了从Twitter（现为X）收集的1,529条包含文本和图像的推文，并通过数据增强提取了额外的社交和视觉特征（如目标检测和OCR）。结果表明，结合无监督和监督机器学习模型的多模态方法比单模态模型性能提升15%，比双模态模型提升5%。此外，研究还基于虚假信息推文及其传播用户的特征分析了虚假信息的传播模式。

</details>


### [151] [Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions](https://arxiv.org/abs/2507.02087)
**中文标题：评估大型语言模型在招聘决策中的潜力与陷阱**

*Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia*

主要分类: cs.LG

摘要简述: 研究评估了大型语言模型（LLMs）在招聘决策中的潜力与风险，发现专用招聘模型（Match Score）在准确性和公平性上优于通用LLMs，强调需结合领域特定建模和偏见审计。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在招聘中的应用虽能简化筛选流程，但存在准确性和算法偏见的风险。本研究旨在比较通用LLMs与专用招聘模型的性能，探讨如何在高风险领域（如招聘）中平衡准确性与公平性。

研究方法: 研究对多个前沿LLMs（包括OpenAI、Anthropic、Google、Meta和Deepseek的模型）与专用招聘模型（Match Score）进行了对比评估，使用ROC AUC、Precision-Recall AUC和F1分数衡量准确性，并通过分界点分析评估性别、种族及交叉子群的公平性。实验基于约10,000个真实候选职位配对数据。

研究结果: Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（种族影响比最低0.957 vs LLMs的0.809或更低）上均优于通用LLMs。研究还发现，未经充分保护的LLMs可能传播社会偏见，而专用监督模型能更有效缓解这些问题。

研究结论: 研究强调在高风险领域（如招聘）中，需采用领域特定建模和偏见审计，避免直接使用通用LLMs。同时证明，设计良好的算法可同时实现招聘准确性和结果公平性。

中文摘要: 大型语言模型（LLMs）在招聘中的应用有望简化候选人筛选，但也引发了准确性和算法偏见的严重担忧（尤其是在缺乏充分保护措施的情况下）。本研究对多个前沿基础LLMs（包括OpenAI、Anthropic、Google、Meta和Deepseek的模型）与专用招聘模型（Match Score）进行了对比评估。我们通过ROC AUC、Precision-Recall AUC和F1分数衡量准确性，并通过分界点分析评估性别、种族及交叉子群的公平性。基于约10,000个真实候选职位配对数据的实验表明，Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（种族影响比最低0.957 vs LLMs的0.809或更低）上均优于通用LLMs。研究发现，预训练偏见可能导致缺乏保护的LLMs在招聘场景中传播社会偏见，而专用监督模型能更有效缓解这些问题。研究结果强调了在高风险领域（如招聘）中采用领域特定建模和偏见审计的重要性，并警示在缺乏充分公平保护措施的情况下依赖现成LLMs的风险。此外，研究通过实证表明，招聘中的准确性与公平性并非对立：设计良好的算法可同时实现招聘准确性和结果公平性。

</details>


### [152] [Energy-Based Transformers are Scalable Learners and Thinkers](https://arxiv.org/abs/2507.02092)
**中文标题：能量基Transformer是可扩展的学习者与思考者**

*Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal*

主要分类: cs.LG

摘要简述: 本文提出了一种新型能量基Transformer（EBT），通过无监督学习实现输入与候选预测的兼容性验证，并通过能量最小化进行预测。EBT在训练和推理中均表现出色，优于现有方法，展示了更好的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有推理时计算技术（类似人类系统2思维）存在局限性：仅适用于特定模态或问题，或需要额外监督训练。本文旨在探索是否可以通过无监督学习实现通用的系统2思维模型。

研究方法: 提出能量基Transformer（EBT），通过能量基模型为输入和候选预测对分配能量值，并通过梯度下降能量最小化进行预测。该方法适用于离散（文本）和连续（视觉）模态。

研究结果: EBT在训练中比主流Transformer++方法扩展更快，数据、批量大小、参数等指标上扩展率提高35%。在语言任务中，EBT通过系统2思维性能提升29%，在图像去噪中优于扩散Transformer且前向传播次数更少。

研究结论: EBT是一种有前景的新范式，能够同时扩展模型的学习和思维能力，且在相同或更差预训练性能下优于现有方法，泛化能力更强。

中文摘要: 类似于人类系统2思维的推理时计算技术近年来在提升模型性能方面受到关注。然而，现有方法存在局限性：仅适用于特定模态（如文本）、特定问题（如数学和编程等可验证领域），或需要在无监督预训练基础上额外监督训练（如验证器或可验证奖励）。本文探讨了是否可以通过无监督学习实现通用的系统2思维模型。有趣的是，我们发现答案是肯定的，即通过学习显式验证输入与候选预测的兼容性，并将预测问题重新定义为基于该验证器的优化问题。具体而言，我们训练了能量基Transformer（EBT）——一种新型能量基模型（EBM）——为每个输入和候选预测对分配能量值，并通过梯度下降能量最小化实现预测。在离散（文本）和连续（视觉）模态中，EBT在训练中比主流Transformer++方法扩展更快，数据、批量大小、参数、FLOPs和深度等指标上扩展率提高35%。在推理中，EBT通过系统2思维在语言任务中性能提升29%，优于Transformer++；在图像去噪中表现优于扩散Transformer且前向传播次数更少。此外，EBT在相同或更差预训练性能下，在多数下游任务中优于现有模型，表明其泛化能力更强。因此，EBT是一种有前景的新范式，能够同时扩展模型的学习和思维能力。

</details>


### [153] [Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows](https://arxiv.org/abs/2507.01975)
**中文标题：用于加速流动模拟的可学习可微分有限体积求解器**

*Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LDSolver的可学习可微分有限体积求解器，用于在粗网格上高效准确地模拟流体流动。该方法结合了可微分求解器和可学习模块，显著提升了计算效率，同时保持了高精度和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 流体流动模拟在气象学、空气动力学和生物医学等领域至关重要。传统数值求解器需要精细的时空网格以确保稳定性、一致性和收敛性，计算成本高昂。尽管机器学习方法效率更高，但存在可解释性、泛化性和数据依赖性等问题。因此，本文旨在开发一种兼具高效性和准确性的新型求解器。

研究方法: LDSolver包含两个关键组件：(1) 可微分有限体积求解器；(2) 可学习模块，用于在粗网格上提供等效的通量近似（导数和插值）和时间误差校正。该方法即使在有限训练数据（如仅几条轨迹）下也能高效运行。

研究结果: 在不同流动系统（如Burgers流、衰减流、强迫流和剪切流）上的实验表明，LDSolver实现了最先进的性能，显著优于基线模型。

研究结论: LDSolver通过结合可微分求解器和可学习模块，在粗网格上实现了高效且高精度的流体流动模拟，具有优异的泛化能力，为复杂物理现象的模拟提供了新思路。

中文摘要: 流体流动模拟对于气象学、空气动力学和生物医学等物理现象的建模至关重要。传统数值求解器通常需要精细的时空网格以满足稳定性、一致性和收敛性条件，导致计算成本高昂。尽管机器学习方法表现出更高的效率，但它们通常存在可解释性、泛化性和数据依赖性问题。为此，我们提出了一种名为LDSolver的可学习可微分有限体积求解器，旨在在粗时空网格上高效且准确地模拟流体流动。LDSolver包含两个关键组件：(1) 可微分有限体积求解器；(2) 可学习模块，用于在粗网格上提供等效的通量近似（导数和插值）和时间误差校正。即使在有限训练数据（如仅几条轨迹）下，我们的模型也能在保持高精度的同时加速模拟，并具有优异的泛化能力。在不同流动系统（如Burgers流、衰减流、强迫流和剪切流）上的实验表明，LDSolver实现了最先进的性能，显著优于基线模型。

</details>


### [154] [DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism](https://arxiv.org/abs/2507.01982)
**中文标题：DKGCM：一种融合空间节点聚类方法与傅里叶双向Mamba机制的交通流量时空预测模型**

*Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai*

主要分类: cs.LG

摘要简述: 提出了一种名为DKGCM的新型图卷积网络结构，通过融合空间节点聚类方法和傅里叶双向Mamba机制，显著提升了交通流量的时空预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 交通需求预测的准确性对资源分配效率至关重要，但复杂的时空关系限制了现有模型的性能。本文旨在通过改进空间和时间依赖性的捕捉方法，提升预测精度。

研究方法: 首先提出基于时间相似性的聚类图卷积方法（DK-GCN），利用动态时间规整（DTW）和K均值聚类对交通节点分组；其次在时间尺度上，将快速傅里叶变换（FFT）与双向Mamba框架结合，捕捉时间依赖性；并引入GRPO强化学习策略优化训练。

研究结果: 在三个公开数据集上的实验表明，DKGCM模型优于多种先进方法，取得了显著的预测效果。

研究结论: DKGCM通过创新的空间聚类和时间依赖性捕捉方法，显著提升了交通流量预测的准确性，为交通管理提供了有效工具。

中文摘要: 准确的交通需求预测能够帮助交通管理部门更有效地分配资源，从而提高其利用效率。然而，交通系统中复杂的时空关系仍然限制了需求预测模型的性能。为了提高时空交通需求预测的准确性，我们提出了一种新的图卷积网络结构DKGCM。具体而言，我们首先考虑了不同交通节点的空间流量分布，并提出了一种基于时间相似性的新型聚类图卷积方法DK-GCN。该方法利用动态时间规整（DTW）和K均值聚类对交通节点进行分组，以更有效地捕捉空间依赖性。在时间尺度上，我们将快速傅里叶变换（FFT）整合到双向Mamba深度学习框架中，以捕捉交通需求的时间依赖性。为了进一步优化模型训练，我们引入了GRPO强化学习策略以增强损失函数的反馈机制。大量实验表明，我们的模型在三个公开数据集上优于多种先进方法，并取得了显著的效果。

</details>


### [155] [OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding](https://arxiv.org/abs/2507.02659)
**中文标题：OmniDraft：一种跨词汇表、在线自适应的设备端推测解码草稿模型**

*Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang*

主要分类: cs.LG

摘要简述: 本文提出OmniDraft框架，解决推测解码中草稿模型与目标模型不兼容及动态适应问题，实现单一草稿模型适配多种目标模型，并提升解码速度。


<details>
  <summary>详细信息</summary>
研究动机: 当前推测解码需预训练或离线蒸馏草稿模型，但实际部署中存在目标模型不兼容及动态性能优化需求。本文旨在解决这些问题，提出通用草稿模型框架。

研究方法: 引入在线n-gram缓存与混合蒸馏微调，解决跨词汇表不匹配问题；采用自适应推测技术提升解码速度。

研究结果: OmniDraft使单一Llama-68M模型适配多种目标模型（如Vicuna-7B、Qwen2-7B等），解码速度提升1.5-2倍。

研究结论: OmniDraft为设备端LLM应用提供高效、灵活的解决方案，验证了“一草稿适配多目标”的可行性。

中文摘要: 推测解码通常需要预训练或离线蒸馏的小型高效草稿模型，以适配特定目标模型系列（如Llama或Qwen）。然而，在线部署中存在两大挑战：1）目标模型与草稿模型不兼容；2）需随时间优化延迟性能。本文提出OmniDraft，一个统一框架，使单一草稿模型适配任何目标模型并动态适应用户数据。通过引入在线n-gram缓存与混合蒸馏微调，解决跨词汇表不匹配问题；并利用自适应推测技术进一步提升解码速度。OmniDraft尤其适合设备端LLM应用，其中模型成本、效率及用户定制是关键问题。这凸显了解决上述挑战的必要性，并推动了“一草稿适配多目标”的范式。通过在数学推理、代码生成等任务中验证，OmniDraft使单一Llama-68M模型适配Vicuna-7B、Qwen2-7B等多种目标模型，解码速度提升1.5-2倍。

</details>


### [156] [ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning](https://arxiv.org/abs/2507.02834)
**中文标题：ExPO：通过自我解释引导的强化学习解锁复杂推理能力**

*Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ExPO的新方法，通过自我解释引导的强化学习解决大语言模型在早期训练和复杂推理任务中难以生成有效样本的问题。ExPO通过结合当前策略和正确答案生成高质量样本，显著提升了模型的学习效率和最终性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于强化学习的后训练方法依赖于模型初始生成的正样本，难以解决模型初始失败的复杂推理任务。尤其是在早期训练阶段或高难度任务中，正样本生成概率低，限制了模型的探索能力。

研究方法: ExPO框架通过结合当前策略和正确答案生成高质量样本，满足两个关键条件：(1)样本在当前策略下具有高概率；(2)能提高模型预测正确答案的可能性。这种方法比专家演示更有效。

研究结果: 实验表明，ExPO在推理基准测试中显著提升了学习效率和最终性能，尤其是在MATH level-5等高难度任务中，表现优于基于专家演示的方法。

研究结论: ExPO通过自我解释引导的强化学习，解决了模型在复杂推理任务中的探索问题，为提升大语言模型的推理能力提供了有效途径。

中文摘要: 近年来，大语言模型的进步主要依赖于强化学习（RL）风格的后训练，通过基于奖励或偏好信号优化模型输出来提升推理能力。GRPO类方法通过使用基于结果的验证器标记自生成样本来实现这一点。然而，这些方法高度依赖模型初始生成正样本的能力，主要优化模型已知的内容（分布锐化），而无法解决模型初始失败的复杂推理任务。这一限制在早期RL训练和高难度推理任务中尤为突出，因为正样本生成概率极低。为了在这些场景中解锁推理能力，模型需要探索超出当前输出分布的新推理路径。这种探索需要足够高质量的正样本来指导学习。虽然专家演示似乎是自然解决方案，但我们发现它们在RL后训练中往往效果不佳。相反，我们确定了有效正样本的两个关键特性：(1)在当前策略下具有高概率；(2)能提高模型预测正确答案的可能性。基于这些发现，我们提出了自我解释策略优化（ExPO）——一个简单且模块化的框架，通过基于正确答案生成此类样本。ExPO支持高效探索，并引导模型生成比专家编写的思维链（CoT）更符合其策略的推理路径，同时确保比其自身（错误）样本更高的质量。实验表明，ExPO在推理基准测试中显著提升了学习效率和最终性能，在MATH level-5等高难度任务中超越了基于专家演示的方法。

</details>


### [157] [GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters](https://arxiv.org/abs/2507.02085)
**中文标题：GeoAda：利用等变适配器高效微调几何扩散模型**

*Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon*

主要分类: cs.LG

摘要简述: GeoAda提出了一种SE(3)-等变适配器框架，用于高效微调几何扩散模型，保持几何一致性并避免过拟合和灾难性遗忘，适用于多种几何控制任务。


<details>
  <summary>详细信息</summary>
研究动机: 几何扩散模型在分子动力学和结构生成中表现出色，但如何高效微调以适应不同几何控制的下游任务尚未充分探索。

研究方法: GeoAda通过结构化适配器设计，将控制信号编码后经可训练层处理，再通过解耦操作和零初始化卷积投影回原模型，仅微调轻量适配器模块。

研究结果: 实验表明，GeoAda在多种几何控制任务中表现优异，保持原始任务精度，而其他基线方法因过拟合和灾难性遗忘导致性能显著下降。

研究结论: GeoAda为几何扩散模型的高效微调提供了灵活且参数高效的方法，同时保持了模型的几何一致性。

中文摘要: 几何扩散模型在分子动力学和结构生成中取得了显著成功。然而，如何高效地微调这些模型以适应具有不同几何控制的下游任务仍未被充分研究。本文提出了一种SE(3)-等变适配器框架（GeoAda），能够在无需修改原始模型架构的情况下，实现对受控生成任务的灵活且参数高效的微调。GeoAda采用结构化适配器设计：控制信号首先通过耦合算子编码，然后由预训练模型层的可训练副本处理，最后通过解耦算子和等变零初始化卷积投影回原模型。仅微调这些轻量级适配器模块，GeoAda既保持了模型的几何一致性，又避免了过拟合和灾难性遗忘。我们从理论上证明了所提出的适配器保持了SE(3)-等变性，确保了预训练扩散模型的几何归纳偏置在适应过程中保持不变。我们展示了GeoAda在多种几何控制类型（如框架控制、全局控制、子图控制）和广泛应用领域（如粒子动力学、分子动力学、人体运动预测和分子生成）中的广泛适用性。实证结果表明，GeoAda在保持原始任务精度的同时，实现了最先进的微调性能，而其他基线方法因过拟合和灾难性遗忘导致性能显著下降。

</details>


### [158] [Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies](https://arxiv.org/abs/2507.02244)
**中文标题：竞争压力下的订单获取：一种快速自适应的强化学习方法用于网约车补贴策略**

*Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于强化学习的快速自适应补贴策略框架FCA-RL，用于网约车平台在竞争环境下动态调整优惠券策略，以优化订单获取并满足预算约束。实验表明该方法优于基线策略。


<details>
  <summary>详细信息</summary>
研究动机: 网约车平台通过低价策略提升订单量和GMV，但现有研究缺乏动态适应市场波动的有效优惠券策略设计。本文旨在填补这一空白。

研究方法: 提出FCA-RL框架，结合快速竞争适应（FCA）和强化拉格朗日调整（RLA）技术，并开发专用模拟环境RideGym进行策略评估。

研究结果: 实验结果显示，FCA-RL在多种市场条件下均优于基线方法，验证了其在补贴优化中的有效性。

研究结论: FCA-RL为网约车服务提供商提供了一种高效、动态的补贴策略优化方案，具有实际应用价值。

中文摘要: 网约车聚合平台的普及为服务提供商带来了订单量和GMV的增长机会。平台通常将低价服务商排名靠前，从而激励服务商通过优惠券策略降低价格以获取更多订单。设计一种能在预算约束下动态适应市场波动并优化订单获取的优惠券策略是重要研究挑战，但现有研究较少。为此，我们提出FCA-RL，一种基于强化学习的补贴策略框架，能够快速适应竞争对手的价格调整。该方法结合了快速竞争适应（FCA）和强化拉格朗日调整（RLA）技术，并开发了首个专用于网约车聚合平台的模拟环境RideGym，用于全面评估不同定价策略。实验结果表明，该方法在多种市场条件下均优于基线方法，验证了其在补贴优化中的有效性。

</details>


### [159] [Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications](https://arxiv.org/abs/2507.02291)
**中文标题：基于知识图谱的可解释与广义零样本语义通信**

*Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于知识图谱的零样本语义通信网络（KGZS-SC），通过知识图谱增强语义表示和推理能力，解决了数据驱动语义通信缺乏解释性和泛化能力的问题。实验表明，该方法在APY数据集上显著优于现有框架。


<details>
  <summary>详细信息</summary>
研究动机: 数据驱动的语义通信仅依赖统计模式，缺乏解释性和泛化能力，尤其是在处理未见数据时表现不佳。本文旨在通过知识图谱增强语义表示，提升通信的泛化能力和效率。

研究方法: 提出KGZS-SC网络，利用知识图谱语义知识库（KG-SKB）对齐语义特征，生成共享类别语义嵌入空间。发送端通过选择性传输紧凑视觉语义降低通信开销；接收端采用零样本学习（ZSL）直接分类未见数据，无需重新训练。

研究结果: 在APY数据集上的实验表明，KGZS-SC网络具有强大的泛化能力，在不同信噪比水平下对未见类别的分类性能显著优于现有语义通信框架。

研究结论: KGZS-SC网络通过知识图谱增强语义表示和推理能力，显著提升了语义通信的解释性、泛化能力和效率，适用于动态或资源受限环境。

中文摘要: 数据驱动的语义通信基于表面的统计模式，缺乏解释性和泛化能力，尤其是在处理未见数据时表现不足。为解决这些问题，我们提出了一种新颖的知识图谱增强零样本语义通信（KGZS-SC）网络。通过基于知识图谱的语义知识库（KG-SKB）的结构化语义信息引导，我们的方案提供了广义的语义表示，并支持对未见案例的推理。具体而言，KG-SKB将语义特征对齐到共享类别语义嵌入空间，并通过对齐的语义特征增强发送端的泛化能力，从而通过选择性传输紧凑视觉语义降低通信开销。在接收端，利用零样本学习（ZSL）直接对未见案例进行分类，无需重新训练或额外计算开销，从而提升了动态或资源受限环境中分类过程的适应性和效率。在APY数据集上的仿真结果表明，所提出的KGZS-SC网络表现出强大的泛化能力，并且在一系列信噪比水平下对未见类别的分类性能显著优于现有语义通信框架。

</details>


### [160] [Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment](https://arxiv.org/abs/2507.02310)
**中文标题：概念漂移下的自适应记忆重对齐整体持续学习**

*Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk*

主要分类: cs.LG

摘要简述: 本文提出了一种在概念漂移下的整体持续学习框架，通过自适应记忆重对齐（AMR）方法，动态调整记忆缓冲区以适应数据分布变化，显著减少标注和计算开销，同时保持高性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统持续学习方法假设数据分布静态，忽略了现实世界中概念漂移的动态性。本文旨在解决这一局限性，提出一种能够同时保持稳定性和快速适应性的方法。

研究方法: 提出自适应记忆重对齐（AMR）方法，通过选择性移除过时的样本并补充少量最新实例，动态调整记忆缓冲区，以匹配新的数据分布。同时，引入了四种概念漂移变体的标准视觉基准数据集用于评估。

研究结果: 实验表明，AMR在多种基准数据集上均能有效应对概念漂移，性能接近完全重新学习（FR），但标注和计算开销显著降低。

研究结论: AMR是一种可扩展的解决方案，能够在非静态持续学习环境中平衡稳定性和可塑性，适用于动态数据流场景。

中文摘要: 传统的持续学习方法侧重于知识保留，主要解决灾难性遗忘问题，隐含假设已学习任务的数据分布是静态的。然而，现实世界的数据流具有动态性，概念漂移会永久改变已见数据，要求模型兼具稳定性和快速适应性。

本文提出了一种在概念漂移下的整体持续学习框架，通过模拟任务分布的演变来模拟真实场景。作为基线，我们考虑了完全重新学习（FR），即从漂移分布的新标记样本中从头训练模型。虽然有效，但这种方法需要大量标注和计算开销。为解决这些限制，我们提出了自适应记忆重对齐（AMR），这是一种轻量级替代方案，为基于记忆回放的学习者提供了一种漂移感知的适应机制。AMR选择性移除记忆缓冲区中漂移类别的过时样本，并用少量最新实例重新填充，从而有效将记忆与新分布对齐。这种有针对性的重采样在性能上与FR相当，但显著减少了标注数据和计算需求。

为支持可重复评估，我们引入了四种标准视觉基准的概念漂移变体：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD和Tiny-ImageNet-CD，其中已见类别以漂移后的表征重新出现。在这些数据集上使用多种基于记忆回放的基线进行的全面实验表明，AMR能够持续应对概念漂移，以最小开销保持高准确率。这些结果表明，AMR是一种可扩展的解决方案，能够在非静态持续学习环境中平衡稳定性和可塑性。

</details>


### [161] [DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values](https://arxiv.org/abs/2507.02342)
**中文标题：DeltaSHAP：基于Shapley值的在线患者监测预测演变解释**

*Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang*

主要分类: cs.LG

摘要简述: 本文提出DeltaSHAP，一种专为在线患者监测系统设计的可解释人工智能算法，通过改进Shapley值方法，实时解释预测变化，满足临床需求。


<details>
  <summary>详细信息</summary>
研究动机: 在临床环境中，及时了解患者风险变化的原因对干预至关重要，但现有可解释AI方法无法满足临床时间序列解释的特殊需求。DeltaSHAP旨在解决这一问题。

研究方法: DeltaSHAP通过改进Shapley值方法，适应时间序列数据，实时解释连续预测的变化，并提供特征贡献的大小和方向。该方法仅使用实际观察到的特征组合，高效且实用。

研究结果: 实验表明，DeltaSHAP在在线患者监测任务中优于现有方法，解释质量提升62%，计算效率提高33%（时间减少）。

研究结论: DeltaSHAP为临床时间序列解释提供了一种高效、实用的解决方案，显著提升了可解释性和计算效率。

中文摘要: 本研究提出DeltaSHAP，一种专为在线患者监测系统设计的可解释人工智能（XAI）算法。在临床环境中，发现驱动患者风险演变的原因对及时干预至关重要，但现有XAI方法无法满足临床时间序列解释的特殊需求。为此，DeltaSHAP解决了三个关键临床需求：解释连续预测的变化而非孤立预测分数，提供特征贡献的大小和方向，并实时提供这些见解。通过将Shapley值适应于时间设置，我们的方法准确捕捉了特征联盟效应。它仅使用实际观察到的特征组合来归因预测变化，使其在时间敏感的临床应用中高效且实用。我们还引入了新的评估指标，以评估在线时间序列归因的忠实性，并通过在线患者监测任务的实验证明，DeltaSHAP在解释质量（提升62%）和计算效率（时间减少33%）上均优于现有XAI方法（基于MIMIC-III失代偿基准）。代码发布于https://github.com/AITRICS/DeltaSHAP。

</details>


### [162] [Offline Reinforcement Learning with Penalized Action Noise Injection](https://arxiv.org/abs/2507.02356)
**中文标题：基于惩罚性动作噪声注入的离线强化学习**

*JunHyeok Oh,Byung-Jun Lee*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PANI（惩罚性动作噪声注入）的方法，通过注入噪声动作来覆盖整个动作空间，同时根据噪声量进行惩罚，从而提升离线强化学习的性能。该方法兼容多种现有算法，并在多个基准测试中表现出显著改进。


<details>
  <summary>详细信息</summary>
研究动机: 离线强化学习（RL）仅使用固定数据集优化策略，适用于环境交互成本高的场景。尽管扩散模型在离线RL中表现优异，但其计算成本较高。本文旨在探索一种更简单的方法，通过噪声注入提升离线RL的性能。

研究方法: 提出PANI方法，通过注入噪声动作覆盖动作空间，并根据噪声量进行惩罚。理论分析表明，该方法解决了一种称为“噪声动作MDP”的修改版马尔可夫决策过程。PANI兼容多种现有离线RL算法。

研究结果: PANI在多个基准测试中表现出显著性能提升，证明了其有效性。尽管方法简单，但其性能与复杂扩散模型相当。

研究结论: PANI是一种简单且高效的离线RL增强方法，通过噪声注入和惩罚机制显著提升性能，且无需复杂计算。

中文摘要: 离线强化学习（RL）仅使用固定数据集优化策略，适用于环境交互成本高的场景。由于这一限制，泛化能力成为提升离线RL算法性能的关键。尽管扩散模型在离线RL中取得了成功，但其在推理时的高计算成本引发了对必要性的质疑。本文提出惩罚性动作噪声注入（PANI），该方法通过注入噪声动作覆盖整个动作空间，并根据噪声量进行惩罚，从而增强离线学习。理论分析表明，带有噪声动作的离线RL算法解决了一种称为“噪声动作MDP”的修改版马尔可夫决策过程。PANI兼容多种现有离线和离线RL算法，尽管简单，但在多个基准测试中表现出显著性能提升。

</details>


### [163] [S2FGL: Spatial Spectral Federated Graph Learning](https://arxiv.org/abs/2507.02409)
**中文标题：S2FGL：空间频谱联邦图学习**

*Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye*

主要分类: cs.LG

摘要简述: 本文提出了一种名为S2FGL的框架，通过结合空间和频谱策略，解决了联邦图学习中的标签信号中断和频谱客户端漂移问题，显著提升了全局模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前联邦图学习（FGL）研究仅从结构角度处理子图联邦学习，忽略了图信号在空间和频谱域的传播问题。空间上，子图联邦学习导致客户端间边连接中断，影响标签信号传播；频谱上，频谱异质性导致局部图神经网络过拟合本地信号传播模式，引发频谱客户端漂移。这些问题削弱了全局模型的泛化能力。

研究方法: S2FGL框架通过两个核心策略解决问题：1）建立全局知识库以缓解标签信号中断；2）采用频率对齐技术解决频谱客户端漂移。结合空间和频谱策略，提升模型的全局性能。

研究结果: 在多个数据集上的实验表明，S2FGL框架显著优于现有方法，有效解决了标签信号中断和频谱客户端漂移问题，提升了全局模型的泛化能力。

研究结论: S2FGL通过空间和频谱策略的结合，成功解决了联邦图学习中的关键问题，为未来研究提供了新的方向。

中文摘要: 联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNNs）的强大图建模能力。当前研究仅从结构角度处理子图联邦学习，忽略了图信号在空间和频谱域上的传播。从空间角度看，子图联邦学习引入了客户端间的边连接中断，导致标签信号传播受阻，全局GNN的类别知识退化。从频谱角度看，频谱异质性导致子图间信号频率不一致，使得局部GNN过拟合本地信号传播模式，从而引发频谱客户端漂移，削弱全局泛化能力。为解决这些问题，我们提出了一个全局知识库以缓解标签信号中断，并通过频率对齐技术解决频谱客户端漂移。空间和频谱策略的结合构成了我们的框架S2FGL。在多个数据集上的广泛实验证明了S2FGL的优越性。代码可在https://github.com/Wonder7racer/S2FGL.git获取。

</details>


### [164] [Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction](https://arxiv.org/abs/2507.02129)
**中文标题：高效时空数据压缩的生成潜在扩散方法**

*Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka*

主要分类: cs.LG

摘要简述: 本文提出了一种高效的潜在扩散框架，结合变分自编码器和条件扩散模型，仅压缩少量关键帧并通过生成插值重建其余帧，显著降低存储成本。实验表明，该方法在相同重建误差下，压缩比优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 生成模型在数据压缩中表现优异，但可控性和重建精度不足限制了其实际应用。本文旨在通过结合变分自编码器和条件扩散模型，提升压缩效率和重建精度。

研究方法: 提出一种潜在扩散框架，仅压缩少量关键帧至潜在空间，并将其作为条件输入，通过生成插值重建其余帧，避免存储每帧的潜在表示。

研究结果: 实验结果显示，该方法在多个数据集上压缩比优于规则压缩器（如SZ3）10倍，在相同重建误差下比领先的学习方法性能提升63%。

研究结论: 该方法通过结合变分自编码器和条件扩散模型，实现了高效的时空数据压缩，显著提升了压缩比和重建精度。

中文摘要: 生成模型在条件设置下表现出色，可视为一种数据压缩形式，其中条件作为紧凑表示。然而，其有限的可控性和重建精度限制了其在数据压缩中的实际应用。本文提出了一种高效的潜在扩散框架，通过结合变分自编码器和条件扩散模型来弥补这一差距。我们的方法仅将少量关键帧压缩至潜在空间，并将其作为条件输入，通过生成插值重建其余帧，无需存储每帧的潜在表示。这种方法在显著降低存储成本的同时实现了精确的时空重建。在多个数据集上的实验结果表明，与基于规则的先进压缩器（如SZ3）相比，我们的方法压缩比提高了10倍；在相同重建误差下，比领先的学习方法性能提升了63%。

</details>


### [165] [Continual Gradient Low-Rank Projection Fine-Tuning for LLMs](https://arxiv.org/abs/2507.02503)
**中文标题：大型语言模型的持续梯度低秩投影微调**

*Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GORP的新型训练策略，通过结合全参数和低秩参数，在统一低秩梯度子空间中联合更新，解决了大型语言模型持续微调中效率与表达能力之间的权衡问题。实验证明GORP在持续学习任务中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的持续微调面临效率与表达能力之间的权衡问题。低秩适应（LoRA）虽然高效，但由于其低秩特性和显式参数约束，限制了模型学习新任务和迁移知识的能力。本文旨在克服这些限制。

研究方法: 提出GORP（梯度低秩投影）策略，通过协同结合全参数和低秩参数，在统一低秩梯度子空间中联合更新，扩展优化空间的同时保持效率并缓解灾难性遗忘。

研究结果: 在持续学习基准测试中，GORP表现出优于现有最先进方法的性能。

研究结论: GORP通过结合全参数和低秩参数，在持续学习中实现了高效且表达能力强的微调，为大型语言模型的持续学习提供了新的解决方案。

中文摘要: 大型语言模型（LLMs）的持续微调受到效率与表达能力之间权衡的制约。低秩适应（LoRA）虽然高效，但由于其低秩特性和对显式参数约束的依赖，限制了模型学习新任务和迁移知识的能力。我们提出了GORP（梯度低秩投影）持续学习策略，通过协同结合全参数和低秩参数，并在统一低秩梯度子空间中联合更新，克服了这些限制。GORP在扩展优化空间的同时保持了效率，并缓解了灾难性遗忘。在持续学习基准测试中的大量实验表明，GORP的性能优于现有的最先进方法。代码可在https://github.com/Wcxwcxw/GORP获取。

</details>


### [166] [Position: A Theory of Deep Learning Must Include Compositional Sparsity](https://arxiv.org/abs/2507.02550)
**中文标题：观点：深度学习理论必须包含组合稀疏性**

*David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio*

主要分类: cs.LG

摘要简述: 本文主张深度学习的成功源于其利用目标函数的组合稀疏结构的能力，认为这是理解深度学习理论的关键。


<details>
  <summary>详细信息</summary>
研究动机: 探讨深度神经网络（DNNs）在克服维度诅咒中的成功原因，提出组合稀疏性是DNNs高效学习的基础，并强调其在通用智能理论中的重要性。

研究方法: 通过分析组合稀疏性在目标函数中的普遍性，论证DNNs能够利用这种结构实现高效学习和泛化。

研究结果: 组合稀疏性是所有高效图灵可计算函数的共同特性，且在当前学习问题中普遍存在，为DNNs的成功提供了理论基础。

研究结论: 理解组合稀疏性在深度学习中的作用对构建全面的人工智能理论至关重要。

中文摘要: 过参数化的深度神经网络（DNNs）在多种高维领域中表现出色，超越了受维度诅咒限制的经典浅层网络。然而，关于DNNs学习动态的基本原理仍存在未解之谜。本文认为，DNNs的成功源于其能够利用目标函数的组合稀疏结构。这种结构表明，大多数实际相关函数可由少量构成函数组合而成，且每个构成函数仅依赖于输入的少数维度。我们证明，这一特性是所有高效图灵可计算函数共有的，因此很可能存在于当前所有学习问题中。尽管在组合稀疏函数的背景下，已有一些关于逼近和泛化的理论见解，但关于DNNs的可学习性和优化的关键问题仍未解决。完善组合稀疏性在深度学习中的角色，对构建全面的人工智能乃至通用智能理论至关重要。

</details>


### [167] [L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation](https://arxiv.org/abs/2507.02619)
**中文标题：L-VAE：具有可学习β的解耦表示变分自编码器**

*Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural*

主要分类: cs.LG

摘要简述: 本文提出了一种名为L-VAE的新模型，通过学习损失函数的超参数，实现解耦表示与动态权衡重构和解耦损失。实验表明，L-VAE在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统β-VAE的超参数β需要经验调整，限制了模型的灵活性。本文旨在通过动态学习超参数，优化重构和解耦损失的权衡，提升解耦表示的性能。

研究方法: L-VAE扩展了β-VAE，通过学习损失函数中各项的相对权重，动态调整重构和解耦损失的平衡。模型还引入正则化项，避免偏向某一损失。

研究结果: 实验在dSprites、MPI3D-complex等数据集上验证了L-VAE的有效性，其在解耦指标上表现最佳或次佳。CelebA上的定性实验也证实了其解耦面部属性的能力。

研究结论: L-VAE通过动态学习超参数，有效平衡了重构和解耦损失，在多个任务中表现优异，为解耦表示提供了新思路。

中文摘要: 本文提出了一种名为可学习VAE（L-VAE）的新模型，通过学习损失函数的超参数，实现解耦表示与动态权衡重构和解耦损失。L-VAE可视为β-VAE的扩展，其中超参数β通过经验调整。L-VAE通过学习损失函数中各项的相对权重，动态控制重构和解耦损失的权衡，从而缓解了β-VAE的局限性。在提出的模型中，损失项的权重与模型架构参数同时学习。损失函数中还添加了额外的正则化项，以避免偏向重构或解耦损失。实验分析表明，L-VAE在重构保真度和解耦潜在维度之间找到了有效平衡。与β-VAE、VAE、ControlVAE、DynamicVAE和σ-VAE在dSprites、MPI3D-complex、Falcor3D和Isaac3D等数据集上的比较显示，L-VAE在一系列解耦指标上始终表现最佳或次佳。此外，CelebA数据集上的定性实验证实了L-VAE模型在解耦面部属性方面的成功。

</details>


### [168] [Fair Deepfake Detectors Can Generalize](https://arxiv.org/abs/2507.02645)
**中文标题：公平的深度伪造检测器可以泛化**

*Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli*

主要分类: cs.LG

摘要简述: 本文首次揭示了深度伪造检测模型中公平性与泛化性之间的因果关系，并提出了一种名为DAID的即插即用框架，通过控制混杂变量实现公平性与泛化性的双重提升。


<details>
  <summary>详细信息</summary>
研究动机: 深度伪造检测模型面临两大挑战：对未知操作的泛化能力和不同人口群体的公平性。现有方法通常认为这两者是相互冲突的，但本文首次揭示了它们之间的因果关系，并试图通过控制混杂变量来解决这一问题。

研究方法: 本文提出了DAID框架，包括两部分：1) 人口属性感知的数据再平衡，通过逆概率加权和子群特征归一化消除分布偏差；2) 人口属性无关的特征聚合，使用新的对齐损失抑制敏感属性信号。

研究结果: 在三个跨域基准测试中，DAID在公平性和泛化性方面均优于现有最先进的检测器，验证了其理论基础和实际有效性。

研究结论: 本文通过因果分析揭示了公平性与泛化性的关系，并提出的DAID框架为深度伪造检测提供了新的解决方案，实现了公平性与泛化性的双重优化。

中文摘要: 深度伪造检测模型面临两大关键挑战：对未知操作的泛化能力以及不同人口群体间的公平性。然而，现有方法通常表明这两个目标本质上是冲突的，揭示了它们之间的权衡关系。本文首次发现并正式定义了公平性与泛化性之间的因果关系。基于后门调整，我们表明通过控制混杂变量（数据分布和模型容量），可以通过公平性干预实现更好的泛化性能。基于这一发现，我们提出了人口属性不敏感干预检测（DAID），这是一个即插即用框架，包括：i）人口感知的数据再平衡，采用逆概率加权和子群特征归一化以消除分布偏差；ii）人口无关的特征聚合，使用新的对齐损失抑制敏感属性信号。在三个跨域基准测试中，DAID在公平性和泛化性方面均优于多种最先进的检测器，验证了其理论基础和实际有效性。

</details>


### [169] [Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs](https://arxiv.org/abs/2507.02671)
**中文标题：基于嵌入的联邦数据共享：通过差分隐私条件变分自编码器实现**

*Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig*

主要分类: cs.LG

摘要简述: 本文提出了一种基于嵌入的联邦数据共享方法，通过差分隐私条件变分自编码器（DP-CVAE）生成隐私保护的全局数据分布，支持多样化的下游任务，同时提升隐私性、可扩展性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在医学影像领域取得了显著进展，但数据稀缺和隐私法规限制了多样化数据集的访问。联邦学习虽然支持去中心化训练，但存在通信成本高和任务单一的问题。因此，需要一种既能保护隐私又能高效共享数据的方法。

研究方法: 采用基础模型提取紧凑且信息丰富的嵌入，减少冗余并降低计算开销。客户端协作训练差分隐私条件变分自编码器（DP-CVAE），建模全局隐私感知数据分布，支持多样化下游任务。

研究结果: 实验验证表明，该方法在多个特征提取器上表现优异，提升了隐私性、可扩展性和效率，优于传统联邦学习分类器，同时确保差分隐私。DP-CVAE生成的嵌入比DP-CGAN具有更高的保真度，且参数需求减少5倍。

研究结论: 通过差分隐私条件变分自编码器实现的数据共享方法，有效解决了数据稀缺和隐私问题，同时支持多样化任务，为医学影像等领域提供了高效且隐私保护的解决方案。

中文摘要: 深度学习（DL）在医学影像领域带来了革命性变革，但其应用受到数据稀缺和隐私法规的限制，导致多样化数据集的访问受限。联邦学习（FL）支持去中心化训练，但存在通信成本高且通常仅限于单一下游任务的问题，灵活性不足。我们提出了一种通过差分隐私（DP）生成模型实现的数据共享方法。通过采用基础模型，提取紧凑且信息丰富的嵌入，减少冗余并降低计算开销。客户端协作训练差分隐私条件变分自编码器（DP-CVAE），建模全局隐私感知数据分布，支持多样化下游任务。我们的方法在多个特征提取器上得到验证，提升了隐私性、可扩展性和效率，优于传统联邦学习分类器，同时确保差分隐私。此外，DP-CVAE生成的嵌入比DP-CGAN具有更高的保真度，且参数需求减少5倍。

</details>


### [170] [Fast and Simplex: 2-Simplicial Attention in Triton](https://arxiv.org/abs/2507.02754)
**中文标题：快速与单纯：Triton中的2-单纯形注意力**

*Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil*

主要分类: cs.LG

摘要简述: 本文提出了一种2-单纯形Transformer架构，通过高效的Triton内核实现，将标准点积注意力推广到三线性函数。实验表明，该架构在数学、编码、推理和逻辑任务上比标准Transformer更具标记效率。


<details>
  <summary>详细信息</summary>
研究动机: 随着现代大型语言模型越来越依赖大规模互联网数据集，计算受限的假设逐渐失效，因此需要优先考虑标记效率的架构。

研究方法: 研究采用2-单纯形Transformer架构，通过Triton内核实现高效的三线性注意力机制，替代标准的点积注意力。

研究结果: 实验证明，在固定标记预算下，2-单纯形Transformer在数学、编码、推理和逻辑任务上优于标准Transformer，并改变了知识和推理任务的缩放规律指数。

研究结论: 2-单纯形注意力机制显著提升了标记效率，为未来高效语言模型设计提供了新方向。

中文摘要: 近期研究表明，训练损失随模型规模和标记数量呈幂律关系，而实现计算最优模型需要同时扩展模型规模和标记数量。然而，这些缩放规律假设数据无限供应，且主要适用于计算受限的场景。随着现代大型语言模型越来越依赖大规模互联网数据集，计算受限的假设逐渐失效，这凸显了对优先考虑标记效率的架构的需求。

本文研究了2-单纯形Transformer的使用，该架构通过高效的Triton内核实现，将标准点积注意力推广到三线性函数。实验表明，2-单纯形Transformer比标准Transformer更具标记效率：在固定标记预算下，类似规模的模型在数学、编码、推理和逻辑任务上表现更优。我们通过证明2-单纯形注意力改变了知识和推理任务缩放规律的指数，量化了这些优势。

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [171] [Subtyping in DHOL -- Extended preprint](https://arxiv.org/abs/2507.02855)
**中文标题：DHOL中的子类型化——扩展预印本**

*Colin Rothgang,Florian Rabe*

主要分类: cs.LO

摘要简述: 本文扩展了依赖类型高阶逻辑（DHOL），通过引入细化和商类型作为子类型的特例，提升了表达能力和自动化支持，同时保持了与HOL的翻译完备性。


<details>
  <summary>详细信息</summary>
研究动机: 依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间取得了平衡，但其类型系统不可判定。为了满足实践者对细化和商类型的需求，本文进一步扩展DHOL，利用其设计优势，优雅地实现这些功能。

研究方法: 通过将细化和商类型作为子类型的特例引入DHOL，避免表示上的高成本变化。提供了扩展语言的语法、语义及到HOL的翻译，并证明了其完备性和可靠性。

研究结果: 成功扩展了DHOL，支持细化和商类型，同时保持了与HOL的翻译完备性，为实践者提供了更强的表达能力。

研究结论: 本文展示了如何在DHOL中优雅地实现细化和商类型，为自动化定理证明提供了更丰富的工具。

中文摘要: 最近引入的依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间提供了一个有趣的折衷方案。它牺牲了类型系统的可判定性，以显著扩展其相对于标准HOL的表达能力，同时通过一种完备且可靠的翻译到HOL的方法，保留了强大的自动化定理证明支持。
  我们利用这一设计，将DHOL扩展为支持细化和商类型。这两种类型常被实践者需求，但很少由自动化定理证明器提供，因为它们本质上需要不可判定的类型化，因此很难在可判定的类型系统中实现。但由于DHOL已经承担了大部分工作，添加它们不仅可能，而且优雅且简单。
  具体而言，我们将细化和商类型作为子类型的特例添加。这将相关的典型包含和投影映射转化为恒等映射，从而避免了表示上的高成本变化。我们为扩展语言提供了语法、语义及到HOL的翻译，包括完备性和可靠性的证明。

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [172] [DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification](https://arxiv.org/abs/2507.01971)
**中文标题：DeepSupp：基于注意力驱动的相关性模式分析用于动态时间序列支撑与阻力水平识别**

*Boris Kriuk,Logic Ng,Zarif Al Hossain*

主要分类: q-fin.ST

摘要简述: 本文提出了一种名为DeepSupp的新型深度学习方法，通过多头注意力机制分析动态时间序列中的支撑与阻力水平，显著提升了传统技术分析的适应性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的支撑与阻力（SR）水平识别方法难以适应现代复杂多变的市场环境，且现有机器学习研究多集中于价格预测而非结构水平识别。因此，本文旨在填补这一空白，提出一种更高效、可靠的SR水平检测方法。

研究方法: DeepSupp采用多头注意力机制分析空间相关性和市场微观结构关系，结合高级特征工程构建动态相关矩阵，并通过基于注意力的自编码器进行鲁棒表示学习。最终通过无监督聚类（DBSCAN）提取关键支撑水平。

研究结果: 在标普500股票上的全面评估表明，DeepSupp在六项金融指标上优于六种基线方法，包括支撑准确性和市场敏感性，展现了卓越的性能。

研究结论: DeepSupp为现代金融分析提供了一种可扩展且可靠的SR水平检测方案，突显了基于注意力的架构在揭示市场细微模式和优化技术交易策略中的潜力。

中文摘要: 支撑与阻力（SR）水平是技术分析的核心，指导交易者的入场、出场和风险管理。尽管广泛应用，传统SR识别方法往往难以适应现代复杂多变的市场。近期研究引入了机器学习技术以解决以下挑战，但多数集中于价格预测而非结构水平识别。本文提出DeepSupp，一种利用多头注意力机制分析空间相关性和市场微观结构关系的新型深度学习方法，用于检测金融支撑水平。DeepSupp整合了高级特征工程，构建捕捉市场动态关系的相关矩阵，并采用基于注意力的自编码器进行鲁棒表示学习。最终通过无监督聚类（DBSCAN）提取关键支撑水平。在标普500股票上的全面评估表明，DeepSupp在六项金融指标上优于六种基线方法，包括支撑准确性和市场敏感性，展现了卓越性能。在不同市场条件下的一致结果表明，DeepSupp填补了SR水平检测的关键空白，为现代金融分析提供了可扩展且可靠的解决方案。我们的方法突显了基于注意力的架构在揭示市场细微模式和优化技术交易策略中的潜力。

</details>


### [173] [Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach](https://arxiv.org/abs/2507.01979)
**中文标题：使用LSTNet预测劳动力市场：一种多尺度深度学习方法**

*Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi*

主要分类: q-fin.ST

摘要简述: 本文提出了一种基于深度学习的多尺度方法LSTNet，用于预测短期就业变化和评估长期行业健康状况。该方法利用美国劳工统计局的数据，结合就业水平、工资等多元时间序列数据，显著优于基线模型，并提供了可解释的行业就业健康指数（IEHI）。


<details>
  <summary>详细信息</summary>
研究动机: 劳动力市场的短期预测和长期健康评估对政策制定者和企业至关重要。传统方法难以处理多元时间序列数据的复杂性，因此需要一种更高效的深度学习方法。

研究方法: 采用长短期时间序列网络（LSTNet）处理多元时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和可解释的行业就业健康指数（IEHI）。

研究结果: 该方法在大多数行业中表现优于基线模型，尤其在稳定行业中表现突出。IEHI排名与实际就业波动高度一致，同时分析了误差模式和行业特异性表现。

研究结论: LSTNet在劳动力市场预测中表现出色，未来可进一步提升其可解释性和泛化能力。

中文摘要: 我们提出了一种深度学习方法，用于预测短期就业变化和评估长期行业健康状况，数据来自美国劳工统计局的劳动力市场数据。我们的系统利用长短期时间序列网络（LSTNet）处理多元时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和可解释的行业就业健康指数（IEHI）。我们的方法在大多数行业中优于基线模型，尤其在稳定行业中表现突出，并展示了IEHI排名与实际就业波动之间的强相关性。我们讨论了误差模式、行业特异性表现以及未来提升可解释性和泛化能力的方向。

</details>


### [174] [NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction](https://arxiv.org/abs/2507.02018)
**中文标题：NGAT：一种用于长期股票预测的节点级图注意力网络**

*Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong*

主要分类: q-fin.ST

摘要简述: 本文提出了一种名为NGAT的节点级图注意力网络，用于解决长期股票预测中的三个关键挑战，并通过实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前金融应用中，图表示学习方法虽然广泛用于增强公司表征，但仍面临三个主要问题：下游任务设计限制了关系信息的优势；现有股票预测图模型复杂且泛化能力差；基于经验构建的公司关系图缺乏对不同图结构的有效比较。

研究方法: 作者提出了一种长期股票预测任务，并开发了一种专门为公司关系图设计的节点级图注意力网络（NGAT）。同时，实验验证了现有基于下游任务性能的图比较方法的局限性。

研究结果: 在两个数据集上的实验结果表明，所提出的任务和模型均表现出色，验证了其有效性。

研究结论: NGAT模型在长期股票预测中表现出色，解决了现有方法的局限性，并通过公开项目鼓励可重复性和未来研究。

中文摘要: 图表示学习方法在金融应用中广泛用于通过利用公司间关系增强公司表征。然而，当前方法面临三个关键挑战：（1）关系信息的优势因下游任务设计的限制而被掩盖；（2）专门为股票预测设计的现有图模型通常过于复杂且泛化能力差；（3）基于经验构建的公司关系图缺乏对不同图结构的有效比较。为解决这些限制，我们提出了一种长期股票预测任务，并开发了一种专门为公司关系图设计的节点级图注意力网络（NGAT）。此外，我们通过实验证明了现有基于下游任务性能的图比较方法的局限性。在两个数据集上的实验结果一致证明了所提出任务和模型的有效性。该项目已在GitHub上公开，以鼓励可重复性和未来研究。

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [175] [A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention](https://arxiv.org/abs/2507.00884)
**中文标题：一种基于线性张量化四边形注意力的可扩展且量子精确的生物分子力场基础模型**

*Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou*

主要分类: physics.chem-ph

摘要简述: 本文提出了一种名为LiTEN的新型等变神经网络，通过线性张量化的四边形注意力（TQA）高效建模三体和四体相互作用，构建了LiTEN-FF这一强大的AI力场基础模型，在多个评估数据集上表现优异，并显著提升了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有生物分子模拟方法存在局限性：经典力场效率高但精度不足，量子力学方法精度高但计算成本大，而基于AI的力场（AIFFs）在平衡多体建模复杂性、精度和速度方面存在挑战。本文旨在克服这些限制，提出一种兼具高精度和高效性的解决方案。

研究方法: 本文提出LiTEN，一种基于线性张量化四边形注意力（TQA）的等变神经网络。TQA通过向量操作重新参数化高阶张量特征，避免昂贵的球谐函数计算，从而以线性复杂度建模三体和四体相互作用。在此基础上，构建了LiTEN-FF模型，先在nablaDFT数据集上进行预训练以实现广泛的化学泛化能力，再在SPICE数据集上进行微调以精确模拟溶剂化系统。

研究结果: LiTEN在rMD17、MD22和Chignolin等评估子集上实现了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持包括QM级构象搜索、几何优化和自由能面构建在内的多种下游生物分子建模任务，且对于大型生物分子（约1000个原子）的推理速度比MACE-OFF快10倍。

研究结论: 本文提出的LiTEN-FF框架在物理基础和计算效率方面取得了显著进展，为复杂生物分子建模提供了多功能基础，尤其适用于药物发现及相关应用。

中文摘要: 精确的原子级生物分子模拟对于疾病机制理解、药物发现和生物材料设计至关重要，但现有模拟方法存在显著局限性。经典力场效率高，但对于过渡态和精细构象细节的精度不足；量子力学（QM）方法精度高，但计算成本高，难以用于大规模或长时间模拟。基于AI的力场（AIFFs）旨在实现QM级精度与效率的平衡，但在多体建模复杂性、精度和速度方面面临挑战，且受限于有限的训练数据和泛化能力验证不足。为克服这些挑战，我们提出了LiTEN，一种新型等变神经网络，采用张量化四边形注意力（TQA）。TQA通过向量操作重新参数化高阶张量特征，避免昂贵的球谐函数计算，从而以线性复杂度高效建模三体和四体相互作用。基于LiTEN，我们构建了LiTEN-FF这一强大的AIFF基础模型，先在nablaDFT数据集上进行预训练以实现广泛的化学泛化能力，再在SPICE数据集上进行微调以精确模拟溶剂化系统。LiTEN在rMD17、MD22和Chignolin等评估子集上实现了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持包括QM级构象搜索、几何优化和自由能面构建在内的多种下游生物分子建模任务，且对于大型生物分子（约1000个原子）的推理速度比MACE-OFF快10倍。总之，我们提出了一种物理基础扎实、高效的计算框架，推动了复杂生物分子建模的发展，为药物发现及相关应用提供了多功能基础。

</details>


### [176] [Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation](https://arxiv.org/abs/2507.02752)
**中文标题：可合成性设计：一种基于逆合成分析的分子类似物生成框架**

*Shuan Chen,Gunwook Nam,Yousung Jung*

主要分类: physics.chem-ph

摘要简述: SynTwins是一种基于逆合成分析的分子类似物生成框架，通过模拟化学家策略，确保生成分子的可合成性，同时保持与目标分子的高结构相似性。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI生成的分子虽具有理想性质，但合成可行性低，成为计算药物和材料发现的关键瓶颈。SynTwins旨在解决这一问题，生成可合成的分子类似物。

研究方法: SynTwins采用三步法：逆合成分析、相似构建块搜索和虚拟合成，模拟化学家策略生成可合成的分子类似物。

研究结果: SynTwins在生成可合成类似物方面优于现有机器学习模型，且与目标分子保持高结构相似性。与现有优化框架结合后，生成分子既满足性质需求，又确保可合成性。

研究结论: SynTwins有效弥合了计算设计与实验合成之间的鸿沟，为加速发现具有理想性质的可合成分子提供了实用解决方案。

中文摘要: AI生成的分子虽具有理想性质，但其合成可行性低仍是计算药物和材料发现的关键瓶颈。尽管生成式AI加速了候选分子的提出，但许多结构难以通过现有化学反应合成。本文介绍SynTwins，一种新型逆合成引导的分子类似物设计框架，通过模拟化学家策略的三步过程（逆合成、相似构建块搜索和虚拟合成）生成可合成的分子类似物。在比较评估中，SynTwins在生成可合成类似物方面优于现有机器学习模型，同时保持与目标分子的高结构相似性。此外，与现有分子优化框架结合后，我们的混合方法生成的可合成分子性质与无约束分子生成器相当，但确保了可合成性。通过多样分子数据集的全面基准测试，SynTwins有效弥合了计算设计与实验合成之间的鸿沟，为加速发现具有理想性质的可合成分子提供了实用解决方案。

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [177] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
**中文标题：解决湍流磁流体动力学：一种混合算子-扩散框架**

*Semih Kacmaz,E. A. Huerta,Roland Haas*

主要分类: physics.flu-dyn

摘要简述: 本文提出了一种混合机器学习框架，结合物理信息神经算子（PINO）和基于分数的生成扩散模型，用于模拟二维不可压缩电阻性磁流体动力学（MHD）湍流的全时空演化。该框架在广泛的雷诺数范围内实现了高精度模拟，填补了确定性代理模型在极端湍流条件下的空白。


<details>
  <summary>详细信息</summary>
研究动机: 传统确定性代理模型在高雷诺数湍流模拟中难以捕捉高频动态和非高斯统计特性。本文旨在通过结合物理信息神经算子和扩散模型，解决这一难题，实现对湍流全频谱动态的高精度建模。

研究方法: 该方法结合了物理信息神经算子（PINO）和条件扩散模型。PINO用于预测低频相干动态，而扩散模型则随机修正高频残差，从而实现对湍流全频谱的精确模拟。模型训练基于一组高保真仿真数据，覆盖雷诺数从100到10000的范围。

研究结果: 在雷诺数为1000和3000时，模型能够准确重建速度和磁场场的全频谱能量分布，捕捉非高斯统计特性和间歇结构。在极端湍流条件下（雷诺数为10000），模型首次实现了对磁场高波数演化的恢复，并保持了大规模形态的统计意义预测。

研究结论: 本文提出的混合框架在模拟高雷诺数湍流方面表现出色，填补了传统方法的不足，为复杂湍流系统的研究提供了新的工具。

中文摘要: 我们提出了一种混合机器学习框架，结合物理信息神经算子（PINO）和基于分数的生成扩散模型，用于模拟二维不可压缩电阻性磁流体动力学（MHD）湍流在广泛雷诺数范围内的全时空演化。该框架利用PINO的方程约束泛化能力预测低频相干动态，同时通过条件扩散模型随机修正高频残差，从而实现对完全发展湍流的精确建模。模型基于一组高保真仿真数据（雷诺数范围为100至10000）训练，在以往确定性代理模型无法覆盖的区域内达到了最先进的精度。在雷诺数为1000和3000时，模型能够准确重建速度和磁场场的全频谱能量分布，捕捉非高斯统计特性、间歇结构和跨场相关性。在极端湍流条件下（雷诺数为10000），该模型首次实现了对磁场高波数演化的恢复，保持了大规模形态并提供了统计意义显著的预测。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [178] [DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment](https://arxiv.org/abs/2507.02768)
**中文标题：DeSTA2.5-Audio：通过自生成跨模态对齐实现通用大型音频语言模型**

*Ke-Han Lu,Zhehuai Chen,Szu-Wei Fu,Chao-Han Huck Yang,Sung-Feng Huang,Chih-Kai Yang,Chee-En Yu,Chun-Wei Chen,Wei-Chih Chen,Chien-yu Huang,Yi-Cheng Lin,Yu-Xiang Lin,Chi-An Fu,Chun-Yi Kuan,Wenze Ren,Xuanjun Chen,Wei-Ping Huang,En-Pei Hu,Tzu-Quan Lin,Yuan-Kuei Wu,Kuan-Po Huang,Hsiao-Ying Huang,Huang-Cheng Chou,Kai-Wei Chang,Cheng-Han Chiang,Boris Ginsburg,Yu-Chiang Frank Wang,Hung-yi Lee*

主要分类: eess.AS

摘要简述: 本文提出DeSTA2.5-Audio，一种通用大型音频语言模型（LALM），通过自生成跨模态对齐策略，无需任务特定调优即可实现强大的听觉感知和指令跟随能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有LALM通常依赖大规模手动标注或LLM合成的音频指令数据集，但会导致LLM原有语言能力的灾难性遗忘。本文旨在解决这一问题，同时提升模型的通用性。

研究方法: 提出DeSTA策略，通过骨干LLM自生成训练目标，构建任务无关的大规模数据集DeSTA-AQA5M，包含500万样本，覆盖语音、环境声音和音乐等多种音频类型。

研究结果: DeSTA2.5-Audio在多个音频语言基准测试中达到或超越最优性能，验证了自生成策略在听觉感知和指令跟随能力上的优势。

研究结论: 研究表明，精心设计的数据构建策略对LALM开发至关重要，为构建通用且鲁棒的LALM提供了实用见解。

中文摘要: 我们介绍了DeSTA2.5-Audio，一种通用大型音频语言模型（LALM），旨在实现强大的听觉感知和指令跟随能力，而无需任务特定的音频指令调优。现有的LALM通常通过在大规模手动标注或LLM合成的音频指令数据集上训练来增强大型语言模型（LLM）的听觉能力。然而，这些方法往往导致LLM原有语言能力的灾难性遗忘。为解决这一问题，我们重新审视了数据构建流程，并提出DeSTA，一种自生成跨模态对齐策略，其中骨干LLM生成自身的训练目标。这种方法保留了LLM的原始语言能力，同时建立了有效的音频-文本对齐，从而实现了无需任务特定调优的零样本泛化。利用DeSTA，我们构建了DeSTA-AQA5M，一个任务无关的大规模数据集，包含500万个训练样本，源自7000小时的音频，涵盖50个多样化数据集，包括语音、环境声音和音乐。DeSTA2.5-Audio在广泛的音频语言基准测试中达到了最先进或竞争性性能，包括Dynamic-SUPERB、MMAU、SAKURA、Speech-IFEval和VoiceBench。全面的比较研究表明，我们的自生成策略在听觉感知和指令跟随能力上优于广泛采用的数据构建和训练策略。我们的发现强调了精心设计的数据构建在LALM开发中的重要性，并为构建鲁棒、通用的LALM提供了实用见解。

</details>


### [179] [Multi-agent Auditory Scene Analysis](https://arxiv.org/abs/2507.02755)
**中文标题：多代理听觉场景分析**

*Caleb Rascon,Luis Gato-Diaz,Eduardo García-Alarcón*

主要分类: eess.AS

摘要简述: 本文提出了一种多代理听觉场景分析（MASA）系统，通过并行任务执行和反馈循环来减少错误，同时保持低响应时间和计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 传统的听觉场景分析（ASA）采用线性数据流，导致响应时间长且后置任务对前置任务错误敏感。现有方法虽减少错误但计算复杂，难以适用于计算资源有限的应用场景（如生物声学、助听器设计等）。

研究方法: 提出多代理并行执行ASA任务，引入反馈循环（如利用分离质量修正定位错误，分类结果降低定位对干扰的敏感性），构建MASA系统。系统基于开源工具（JACK、ROS2）实现，支持用户自定义代理。

研究结果: MASA系统在保持低响应时间和计算复杂度的同时，显著提高了对局部错误的鲁棒性。

研究结论: 多代理并行和反馈机制有效解决了传统ASA系统的局限性，适用于资源受限的应用场景。

中文摘要: 听觉场景分析（ASA）旨在通过执行声源定位、分离和分类三个主要任务从声学环境中提取信息。传统方法采用线性数据流，导致响应时间长且后置任务对前置任务错误高度敏感。现有技术虽减少错误但计算复杂，难以适用于计算资源有限的应用场景（如生物声学、助听器设计、搜救、人机交互等）。为此，本文提出一种多代理方法并行执行ASA任务，并通过反馈循环（如利用分离质量修正定位错误，分类结果降低定位对干扰的敏感性）补偿局部错误。结果表明，多代理听觉场景分析（MASA）系统在保持低响应时间和计算复杂度的同时，显著提高了对局部错误的鲁棒性。系统基于开源工具（JACK、ROS2）实现，支持用户自定义代理。

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [180] [Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency](https://arxiv.org/abs/2507.02135)
**中文标题：剖析移动DVFS调节器对LLM推理性能与能效的影响**

*Zongpu Zhang,Pranab Dash,Y. Charlie Hu,Qiang Xu,Jian Li,Haibing Guan*

主要分类: cs.OS

摘要简述: 本文研究了移动设备上动态电压频率调节（DVFS）对大型语言模型（LLM）推理性能和能效的影响，揭示了现有独立调节机制的低效性，并提出了一种统一的能效优化方案FUSE。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在移动设备上的广泛应用，其高计算和内存需求导致能效问题。当前移动设备的CPU、GPU和内存DVFS调节器独立运行，缺乏协同优化，导致LLM推理效率低下。本文旨在解决这一问题。

研究方法: 首先测量了现有LLM框架在移动设备上的能效表现，发现独立调节器导致高达40.4%的延迟增加；其次通过深入分析揭示了调节器间缺乏协同的根源；最后设计了统一的能效优化方案FUSE。

研究结果: 实验表明，FUSE显著降低了首次令牌生成时间和每令牌生成时间，分别平均减少7.0%-16.9%和25.4%-36.8%，同时保持相同的每令牌能耗。

研究结论: FUSE通过协同优化CPU、GPU和内存的DVFS调节，显著提升了移动设备上LLM推理的能效和性能，为未来移动LLM部署提供了有效解决方案。

中文摘要: 大型语言模型（LLM）正日益集成到运行在数十亿移动设备上的各种应用和服务中。然而，在资源有限的移动设备上部署LLM面临重大挑战，因其对计算、内存和能源的高需求。当前移动LLM框架即使主要运行于GPU，仍依赖CPU、GPU和内存三大高能耗组件，而现代移动设备中的优化DVFS调节器却独立运行且互不感知。基于此观察，本文首先测量了包含多种LLM模型的最新LLM框架在手机上的能效，发现独立调节器导致预填充和解码延迟比最优频率组合高40.4%，而能耗相同。其次，通过深入测量研究揭示了调节器间缺乏协同导致的低效原因。最后，基于这些发现，设计了FUSE——一种统一的能效感知调节器，用于优化移动设备上LLM推理的能效。使用ShareGPT数据集的评估显示，FUSE将首次令牌生成时间和每令牌生成时间分别平均减少7.0%-16.9%和25.4%-36.8%，同时保持相同的每令牌能耗。

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [181] [FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports](https://arxiv.org/abs/2507.01991)
**中文标题：FinAI-BERT：一种基于Transformer的模型用于财务报告中句子级别AI披露的检测**

*Muhammad Bilal Zafar*

主要分类: q-fin.CP

摘要简述: 本文提出FinAI-BERT，一种基于Transformer的模型，用于在财务报告中检测句子级别的AI披露。该模型在手动标注的1,586个句子数据集上表现优异，准确率达99.37%，显著优于传统基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在金融服务中的广泛应用，现有工具在检测财务文件中的AI披露时存在粒度粗、可解释性差和鲁棒性不足的问题。本研究旨在开发一种更精细、可解释且稳健的解决方案。

研究方法: 研究采用FinAI-BERT，一种基于Transformer的语言模型，在669份美国银行年报（2015-2023年）的1,586个句子数据集上进行微调。模型通过SHAP进行可解释性分析，并进行了偏差分析和鲁棒性测试。

研究结果: FinAI-BERT在分类任务中表现卓越，准确率达99.37%，F1分数为0.993，优于逻辑回归、朴素贝叶斯、随机森林和XGBoost等传统方法。模型在不同句子长度、对抗输入和时间样本中均表现稳定。

研究结论: 本研究通过FinAI-BERT推动了金融NLP领域的发展，提供了细粒度、主题特定的分类方法。模型为分析师、监管机构和学者提供了一种可扩展且透明的工具，用于监测AI在金融机构中的扩散和表述。

中文摘要: 人工智能（AI）在金融服务中的广泛应用催生了对能够系统检测公司文件中AI相关披露的工具的需求。尽管现有方法通常依赖关键词扩展或文档级分类，但它们在粒度、可解释性和鲁棒性方面存在不足。本研究提出了FinAI-BERT，一种基于Transformer的语言模型，专为在财务文本中分类句子级别的AI相关内容而设计。该模型在从669份美国银行年报（2015年至2023年）中手动标注的1,586个平衡句子数据集上进行了微调。FinAI-BERT实现了近乎完美的分类性能（准确率为99.37%，F1分数为0.993），优于逻辑回归、朴素贝叶斯、随机森林和XGBoost等传统基线方法。通过基于SHAP的标记归因确保了可解释性，而偏差分析和鲁棒性检查证实了模型在不同句子长度、对抗输入和时间样本中的稳定性。从理论上讲，本研究通过使用Transformer架构实现细粒度、主题特定的分类，推动了金融NLP的发展。从实践角度看，它为分析师、监管机构和学者提供了一种可扩展且透明的解决方案，用于监测AI在金融机构中的扩散和表述。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [182] [FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference](https://arxiv.org/abs/2507.02620)
**中文标题：FlowSpec：基于连续流水线推测解码的高效分布式LLM推理框架**

*Xing Liu,Lizhuo Luo,Ming Tang,Chao Huang*

主要分类: cs.DC

摘要简述: FlowSpec是一种分布式LLM推理框架，通过流水线并行和基于树的推测解码技术，显著提升边缘设备上的推理效率，实现1.36倍至1.77倍的加速。


<details>
  <summary>详细信息</summary>
研究动机: 边缘设备上的分布式LLM推理面临请求稀疏和流水线利用率低的问题，FlowSpec旨在通过高效的推测解码技术提升推理速度和资源利用率。

研究方法: FlowSpec采用三种关键技术：1) 基于分数的逐步验证优先处理重要草案令牌；2) 高效草案管理，修剪无效令牌并保持验证中的因果关系；3) 动态草案扩展策略，提供高质量推测输入。

研究结果: 实验表明，FlowSpec在多样化模型和配置下显著提升推理速度，相比基线方法实现1.36倍至1.77倍的加速。

研究结论: FlowSpec通过优化推测解码和流水线并行，有效解决了边缘设备上LLM推理的低效问题，为分布式推理提供了高效解决方案。

中文摘要: 分布式推理是一种有前景的方法，用于在边缘网络实现大型语言模型（LLM）的推理。它将推理过程分配到多个设备上，以确保LLM能够适应设备内存。最近的基于流水线的方法具有并行化通信和计算的潜力，有助于降低推理延迟。然而，当边缘网络的推理请求稀疏时，流水线利用率通常较低，其优势会减弱。为了实现边缘设备上的高效分布式LLM推理，我们提出了FlowSpec，一种基于流水线并行和树的推测解码框架。FlowSpec包含三种关键机制以提高解码效率：1) 基于分数的逐步验证优先处理更重要的草案令牌，以更早接受有效令牌；2) 高效的草案管理，在验证过程中修剪无效令牌并保持正确的因果关系；3) 动态草案扩展策略，提供高质量的推测输入。这些技术协同工作，提升了流水线利用率和推测效率。我们在真实测试平台上与其他基线方法进行了评估。实验结果表明，我们提出的框架在多样化模型和配置下显著提升了推理速度，相比基线方法实现了1.36倍至1.77倍的加速。我们的代码已公开在https://github.com/Leosang-lx/FlowSpec#。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [183] [CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR](https://arxiv.org/abs/2507.02289)
**中文标题：CineMyoPS：基于电影心脏磁共振的心肌病理分割**

*Wangbin Ding,Lei Li,Junyi Qiu,Bogen Lin,Mingjing Yang,Liqin Huang,Lianming Wu,Sihan Wang,Xiahai Zhuang*

主要分类: eess.IV

摘要简述: CineMyoPS是一种端到端深度神经网络，仅通过电影心脏磁共振图像分割心肌病理（如瘢痕和水肿），结合运动和解剖特征，并通过一致性损失和时间序列聚合策略提升分割准确性。


<details>
  <summary>详细信息</summary>
研究动机: 心肌梗死是全球主要死因之一，传统多序列心脏磁共振成像耗时且需对比剂。电影心脏磁共振成像快速无对比剂，可同时观察心肌运动和结构异常，因此开发CineMyoPS以仅用电影图像分割心肌病理。

研究方法: CineMyoPS提取与心肌梗死相关的运动和解剖特征，设计一致性损失促进联合学习，并提出时间序列聚合策略整合心脏周期内的特征，提升分割准确性。

研究结果: 在多中心数据集上的实验表明，CineMyoPS在心肌病理分割、运动估计和解剖分割中表现优异。

研究结论: CineMyoPS仅通过电影心脏磁共振图像即可有效分割心肌病理，为心肌梗死的风险分层和预后评估提供了一种快速无创的方法。

中文摘要: 心肌梗死（MI）是全球主要死因之一。晚期钆增强（LGE）和T2加权心脏磁共振（CMR）成像可分别识别瘢痕和水肿区域，对MI的风险分层和预后评估至关重要。尽管多序列CMR的互补信息有用，但获取这些序列耗时且可能受限（如对比剂使用）。电影CMR是一种快速无对比剂的成像技术，可显示急性MI引起的心肌运动和结构异常。因此，我们提出了一种端到端深度神经网络CineMyoPS，仅通过电影CMR图像分割心肌病理（如瘢痕和水肿）。具体而言，CineMyoPS提取与MI相关的运动和解剖特征。鉴于这些特征的相互依赖性，我们设计了一种一致性损失（类似于协同训练策略）以促进联合学习。此外，我们提出了一种时间序列聚合策略，整合心脏周期内的MI相关特征，从而提升心肌病理的分割准确性。在多中心数据集上的实验表明，CineMyoPS在心肌病理分割、运动估计和解剖分割中表现出色。

</details>


### [184] [A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\left[^{18}\text{F}\right]$FDG PET imaging](https://arxiv.org/abs/2507.02367)
**中文标题：一种稳健且通用的深度学习模型用于动态小动物[$^{18}$F]FDG PET成像中动脉输入函数的预测**

*Christian Salomonsen,Luigi Tommaso Luppino,Fredrik Aspheim,Kristoffer Wickstrøm,Elisabeth Wetzer,Michael Kampffmeyer,Rodrigo Berzaghi,Rune Sundset,Robert Jenssen,Samuel Kuttner*

主要分类: eess.IV

摘要简述: 提出一种基于深度学习的非侵入性方法（FC-DLIF），通过动态小动物PET图像预测动脉输入函数，避免传统血液采样，适用于不同扫描时长和时间偏移。


<details>
  <summary>详细信息</summary>
研究动机: 传统小动物动态PET研究中，动脉输入函数需通过侵入性血液采样获取，操作复杂且无法用于纵向研究。本研究旨在开发一种非侵入性方法，直接从PET图像预测动脉输入函数。

研究方法: 提出全卷积深度学习模型（FC-DLIF），通过空间特征提取器处理PET时间序列的体数据，提取空间特征，再通过时间特征提取器预测动脉输入函数。模型使用[$^{18}$F]FDG数据进行训练和验证，并测试了其他两种放射性示踪剂（[$^{18}$F]FDOPA和[$^{68}$Ga]PSMA）的适用性。

研究结果: FC-DLIF模型能可靠预测动脉输入函数，对时间偏移和不同扫描时长具有鲁棒性。但对训练数据中未包含的其他示踪剂数据预测失败。

研究结论: FC-DLIF模型为非侵入性动脉输入函数预测提供了可靠且灵活的解决方案，适用于动态小动物PET研究，但需进一步扩展训练数据以提高泛化能力。

中文摘要: 动态正电子发射断层扫描（PET）和动力学建模在小动物示踪剂开发研究中至关重要。精确的动力学建模需要准确的输入函数估计，传统上通过动脉血液采样实现。然而，小鼠等小动物的动脉插管操作复杂、耗时且为终末实验，无法用于纵向研究。本研究提出了一种非侵入性、基于全卷积深度学习的方法（FC-DLIF），直接从PET图像预测输入函数，可能避免动态小动物PET中的血液采样。FC-DLIF模型包含一个作用于PET序列体积时间帧的空间特征提取器，提取空间特征，随后通过时间特征提取器预测动脉输入函数。该方法使用[$^{18}$F]FDG数据和动脉血液曲线进行训练和交叉验证，并评估了两种其他放射性示踪剂（[$^{18}$F]FDOPA和[$^{68}$Ga]PSMA）的适用性。模型还测试了时间截断和偏移数据以模拟较短和偏移的PET扫描。FC-DLIF模型在均方误差和相关性方面可靠地预测了动脉输入函数，并能处理截断和偏移样本。但模型无法预测训练数据中未包含的其他示踪剂数据。这种基于深度学习的输入函数为非侵入性动脉血液采样提供了可靠替代方案，对时间偏移和不同扫描时长具有鲁棒性和灵活性。

</details>


### [185] [3D Heart Reconstruction from Sparse Pose-agnostic 2D Echocardiographic Slices](https://arxiv.org/abs/2507.02411)
**中文标题：基于稀疏且视角无关的2D超声心动图切片的3D心脏重建**

*Zhurong Chen,Jinhua Chen,Wei Zhuo,Wufeng Xue,Dong Ni*

主要分类: eess.IV

摘要简述: 本文提出了一种创新的方法，通过稀疏且视角无关的2D超声心动图切片重建个性化的3D心脏模型，显著提高了左心室体积估计的准确性，并首次实现了从2D切片估计右心室体积。


<details>
  <summary>详细信息</summary>
研究动机: 超声心动图在心脏疾病临床实践中不可或缺，但传统2D成像仅提供有限的截面图像，难以准确估计临床参数（如左心室体积）。3D超声成像虽提供替代方案，但受限于低分辨率和繁琐的手动标注。本文旨在解决这些问题。

研究方法: 设计了一种新颖的3D重建流程，通过交替优化2D切片的3D姿态估计和基于隐式神经网络的3D切片整合，逐步将先验3D心脏形状转化为个性化3D模型。

研究结果: 在两个数据集上验证了方法。使用六个平面时，重建的3D心脏显著优于双平面方法（左心室体积估计误差：1.98% vs. 20.24%），并首次实现了从2D切片估计右心室体积（误差为5.75%）。

研究结论: 本研究为心脏超声的个性化3D结构和功能分析提供了新途径，具有重要的临床应用潜力。

中文摘要: 超声心动图（echo）在心脏疾病的临床实践中扮演着不可或缺的角色。然而，超声成像通常仅提供来自少数特定视角的二维（2D）截面图像，这使得其难以解释且对临床参数（如左心室（LV）体积）的估计不准确。3D超声成像为3D量化提供了替代方案，但仍受限于低空间和时间分辨率以及高度繁琐的手动标注。

为解决这些问题，我们提出了一种创新框架，用于从临床实践中常用的2D超声切片重建个性化的3D心脏解剖结构。具体而言，设计了一种新颖的3D重建流程，通过交替优化这些2D切片的3D姿态估计和基于隐式神经网络的3D切片整合，逐步将先验的3D心脏形状转化为个性化的3D心脏模型。

我们在两个数据集上验证了该方法。当使用六个平面时，重建的3D心脏在左心室体积估计上显著优于双平面方法（误差百分比：1.98% vs. 20.24%）。此外，整个重建框架甚至实现了从2D超声切片估计右心室体积的重要突破（误差为5.75%）。本研究为心脏超声的个性化3D结构和功能分析提供了新途径，具有重要的临床应用潜力。

</details>


### [186] [MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection](https://arxiv.org/abs/2507.02668)
**中文标题：MEGANet-W：一种基于小波的边缘引导注意力框架用于弱边界息肉检测**

*Zhe Yee Tan*

主要分类: eess.IV

摘要简述: MEGANet-W是一种基于小波的边缘引导注意力框架，用于弱边界息肉检测，通过注入无参数的Haar小波边缘图提升分割精度，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 结直肠息肉分割对早期癌症检测至关重要，但弱边界和低对比度限制了自动化分割的准确性。现有方法要么模糊边缘细节，要么依赖手工滤波器，在多变成像条件下表现不佳。

研究方法: 提出MEGANet-W，通过两级Haar小波头提取多方向边缘，并结合小波边缘引导注意力模块（WEGA）将小波信息与反向和输入分支融合。

研究结果: 在五个公开息肉数据集上，MEGANet-W显著优于现有方法，mIoU提升2.3%，mDice提升1.2%，且未引入额外可学习参数。

研究结论: MEGANet-W通过小波驱动的边缘引导注意力机制，有效提升了弱边界息肉的分割精度，为自动化检测提供了新思路。

中文摘要: 结直肠息肉分割对早期癌症检测至关重要，但弱边界和低对比度显著限制了自动化分割的准确性。现有深度模型要么模糊边缘细节，要么依赖手工滤波器，在多变成像条件下表现不佳。我们提出MEGANet-W，一种基于小波的边缘引导注意力网络，通过在每个解码阶段注入无参数的Haar小波边缘图来重新校准语义特征。我们的两大贡献是：（1）用于多方向边缘提取的两级Haar小波头；（2）小波边缘引导注意力模块（WEGA），将小波信息与反向和输入分支融合。在五个公开息肉数据集上，MEGANet-W始终优于现有方法，mIoU提升高达2.3%，mDice提升1.2%，且未引入额外可学习参数。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [187] [Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener](https://arxiv.org/abs/2507.02005)
**中文标题：通过特征工程和自动化可解释机器学习发现焊接横向加劲肋的疲劳强度模型**

*Michael A. Kraus,Helen Bartsch*

主要分类: cs.CE

摘要简述: 本研究结合自动化机器学习（AutoML）与可解释人工智能（XAI），通过特征工程和算法特征创建，预测焊接横向加劲肋的疲劳强度，实现了高精度和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 焊接钢结构的疲劳强度预测对工程设计和评估至关重要，但传统方法依赖专家经验且缺乏可解释性。本研究旨在通过AutoML和XAI的结合，提升预测精度并增强模型的可解释性。

研究方法: 研究基于疲劳测试数据库，采用梯度提升、随机森林和神经网络等回归模型，在三种特征方案（领域知识驱动、算法生成及两者结合）下进行训练。通过AutoML优化模型性能，并使用XAI方法（如SHAP和特征重要性分析）解释模型。

研究结果: 领域知识驱动的模型（M2）表现最佳，测试RMSE≈30.6 MPa，R²≈0.780%；在工程相关范围内（0-150 MPa），RMSE≈13.4 MPa，R²≈0.527%。XAI分析揭示了应力比R、应力范围Δσi、屈服强度ReH及焊后处理（TIG修整或未处理）为主要预测因素。

研究结论: 结合AutoML和XAI的框架能够生成准确、可解释且稳健的疲劳强度模型，为焊接钢结构的设计和评估提供了新工具。未来研究将探索概率疲劳寿命建模及数字孪生环境中的应用。

中文摘要: 本研究提出了一种结合自动化机器学习（AutoML）与可解释人工智能（XAI）的统一方法，用于预测焊接横向加劲肋细节的疲劳强度。通过专家驱动的特征工程与算法生成特征的结合，提升了模型的准确性和可解释性。基于广泛的疲劳测试数据库，研究采用梯度提升、随机森林和神经网络等回归模型，在三种特征方案（领域知识驱动、算法生成及两者结合）下进行训练，系统比较了专家特征与自动化特征选择的差异。集成方法（如CatBoost、LightGBM）表现最佳。领域知识驱动的模型M2在测试中表现最优，RMSE≈30.6 MPa，R²≈0.780%；在工程相关范围内（0-150 MPa），RMSE≈13.4 MPa，R²≈0.527%。XAI方法（SHAP和特征重要性分析）识别出应力比R、应力范围Δσi、屈服强度ReH及焊后处理为主要预测因素。该框架表明，AutoML与XAI的结合能够生成准确、可解释且稳健的疲劳强度模型，为焊接钢结构的设计和评估提供了新工具。未来研究将探索概率疲劳寿命建模及数字孪生环境中的应用。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [188] [AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models](https://arxiv.org/abs/2507.02598)
**中文标题：AC-Refiner：基于条件扩散模型的高效算术电路优化方法**

*Chenhao Xue,Kezhi Li,Jiaxing Zhang,Yi Ren,Zhengyuan Shi,Chen Zhang,Yibo Lin,Lining Zhang,Qiang Xu,Guangyu Sun*

主要分类: cs.AR

摘要简述: AC-Refiner是一种基于条件扩散模型的新型算术电路优化框架，通过将电路合成任务转化为条件图像生成任务，高效生成高质量设计，并在实验中表现出优于现有方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 算术电路（如加法器和乘法器）是数字系统的核心组件，其性能、功耗和面积直接影响系统表现。然而，由于设计空间庞大且物理约束复杂，优化这些电路仍具挑战性。现有的深度学习方法难以稳定探索高潜力设计变体，限制了优化效率。

研究方法: AC-Refiner将算术电路合成任务重新定义为条件图像生成任务，利用条件扩散模型生成高质量电路设计。通过将去噪扩散过程与目标性能指标（QoRs）条件化，并结合探索的设计微调模型，使优化聚焦于帕累托前沿附近。

研究结果: 实验结果表明，AC-Refiner生成的电路设计具有更优的帕累托最优性，显著优于现有基线方法。其性能在实际应用中也得到验证。

研究结论: AC-Refiner通过条件扩散模型有效解决了算术电路优化问题，为高性能电路设计提供了新思路，并在实验中展现了卓越的优化能力。

中文摘要: 算术电路（如加法器和乘法器）是数字系统的基础组件，直接影响性能、能效和面积占用。然而，由于设计空间庞大且物理约束复杂，优化这些电路仍具挑战性。尽管近期基于深度学习的方法显示出潜力，但其难以稳定探索高潜力设计变体，限制了优化效率。为解决这一问题，我们提出AC-Refiner，一种基于条件扩散模型的新型算术电路优化框架。我们的核心思路是将算术电路合成任务重新定义为条件图像生成任务。通过将去噪扩散过程与目标性能指标（QoRs）条件化，AC-Refiner能够稳定生成高质量电路设计。此外，探索的设计用于微调扩散模型，使优化聚焦于帕累托前沿附近。实验结果表明，AC-Refiner生成的电路设计具有更优的帕累托最优性，显著优于现有基线方法。其性能在实际应用中也得到验证。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [189] [Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis](https://arxiv.org/abs/2507.02176)
**中文标题：分析与改进语音合成中的说话人相似性评估**

*Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi*

主要分类: cs.SD

摘要简述: 本文研究了语音合成中说话人相似性评估的局限性，发现常用的自动说话人验证（ASV）嵌入主要关注静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。作者提出了一种新指标U3D来评估说话人的动态节奏模式，并公开了代码。


<details>
  <summary>详细信息</summary>
研究动机: 由于语音身份的多面性，建模语音身份具有挑战性。当前生成式语音系统中，身份评估通常依赖于自动说话人验证（ASV）嵌入，但这些嵌入设计用于区分而非表征身份。本文旨在探究这些嵌入捕捉了语音的哪些方面，并解决评估中的混淆因素。

研究方法: 作者分析了广泛使用的ASV嵌入，发现其聚焦于静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。针对这一问题，提出了U3D指标，专门评估说话人的动态节奏模式，并提出了缓解混淆因素的策略。

研究结果: 研究发现ASV嵌入主要捕捉静态特征，而动态特征（如节奏）被忽视。提出的U3D指标能够有效评估说话人的动态节奏模式，为语音克隆系统中的身份一致性评估提供了改进方法。

研究结论: 本文揭示了当前语音合成中说话人相似性评估的局限性，并提出U3D指标以补充动态特征的评估。这一工作有助于提升语音克隆系统中身份一致性的评估能力，并公开了代码以促进进一步研究。

中文摘要: 由于语音身份的多面性，建模语音身份具有挑战性。在生成式语音系统中，身份评估通常依赖于自动说话人验证（ASV）嵌入，但这些嵌入设计用于区分而非表征身份。本文研究了这些嵌入捕捉了语音的哪些方面，发现广泛使用的ASV嵌入主要关注静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。我们还识别了影响说话人相似性测量的混淆因素，并提出了缓解策略。为填补这一空白，我们提出了U3D指标，用于评估说话人的动态节奏模式。这项工作有助于解决在日益先进的语音克隆系统中评估说话人身份一致性的挑战。我们公开了代码。

</details>


### [190] [JoyTTS: LLM-based Spoken Chatbot With Voice Cloning](https://arxiv.org/abs/2507.02380)
**中文标题：JoyTTS：基于LLM的语音聊天机器人，支持语音克隆**

*Fangru Zhou,Jun Zhao,Guoxin Wang*

主要分类: cs.SD

摘要简述: JoyTTS是一个结合大型语言模型（LLM）与文本转语音（TTS）技术的端到端语音聊天机器人，具备语音克隆功能。基于开源模型MiniCPM-o和CosyVoice2，训练了2000小时的对话数据，并提供了完整的训练代码。测试结果显示，其说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。


<details>
  <summary>详细信息</summary>
研究动机: 开发一个结合LLM和TTS技术的语音聊天机器人，支持语音克隆，以提升语音交互的自然度和个性化体验。

研究方法: 基于开源模型MiniCPM-o和CosyVoice2，训练了2000小时的对话数据，并提供了完整的训练代码和推理脚本。

研究结果: 在测试机器seed-tts-zh上，JoyTTS的说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。

研究结论: JoyTTS成功实现了结合LLM与TTS技术的语音聊天机器人，具备高效的语音克隆能力，代码和模型已开源，便于社区进一步开发。

中文摘要: JoyTTS是一个端到端的语音聊天机器人，结合了大型语言模型（LLM）与文本转语音（TTS）技术，并具备语音克隆功能。该项目基于开源模型MiniCPM-o和CosyVoice2，训练了2000小时的对话数据。我们还提供了完整的训练代码，以便社区进一步开发和优化。在测试机器seed-tts-zh上，其说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。代码和模型以及训练与推理脚本可在https://github.com/jdh-algo/JoyTTS.git获取。

</details>


### [191] [ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning](https://arxiv.org/abs/2507.02666)
**中文标题：ASDA：用于自监督表示学习的音频谱图差分注意力机制**

*Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang*

主要分类: cs.SD

摘要简述: 本文提出了一种名为ASDA的音频谱图差分注意力机制，通过双软最大操作和差分系数优化，解决了传统Transformer注意力机制分配无效的问题，在多个音频任务中实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前音频自监督表示学习中，Transformer的注意力机制常将部分注意力分配给无关信息，影响模型判别能力。本文旨在解决这一问题。

研究方法: 引入差分注意力机制，结合双软最大操作和差分系数优化，减少无效注意力分配。

研究结果: ASDA在音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词识别（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）中达到SOTA性能。

研究结论: ASDA通过优化注意力分配，显著提升了音频任务的性能，为更广泛的应用奠定了基础。

中文摘要: 在音频自监督表示学习的最新进展中，标准Transformer架构已成为主流方法，但其注意力机制常将部分注意力权重分配给无关信息，可能损害模型的判别能力。为解决这一问题，我们提出了一种差分注意力机制，通过结合双软最大操作和适当调整的差分系数，有效减少了无效注意力分配。实验结果表明，我们的ASDA模型在多个基准测试中实现了最先进的性能，包括音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词识别（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）。这些结果凸显了ASDA在音频任务中的有效性，为更广泛的应用铺平了道路。

</details>


### [192] [De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks](https://arxiv.org/abs/2507.02606)
**中文标题：De-AntiFake：重新思考针对语音克隆攻击的保护性扰动**

*Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu*

主要分类: cs.SD

摘要简述: 本文首次系统评估了针对语音克隆攻击的保护性扰动，并提出了一种新的两阶段净化方法，显著优于现有方法，揭示了现有防御的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 随着语音生成模型的快速发展，语音克隆（VC）引发的隐私和安全问题日益严重。现有研究通过引入对抗性扰动来干扰未经授权的语音克隆，但攻击者仍能通过净化技术绕过防御。本研究旨在评估这些保护性扰动在真实威胁模型下的有效性，并提出更鲁棒的解决方案。

研究方法: 本研究提出了一种两阶段净化方法：首先净化受扰动的语音，然后通过音素引导将其与干净语音分布对齐。实验验证了该方法在干扰语音克隆防御上的优越性。

研究结果: 实验结果表明，现有净化方法虽能中和大部分保护性扰动，但仍会导致语音克隆模型特征空间失真，从而降低其性能。提出的两阶段方法在破坏语音克隆防御方面优于现有技术。

研究结论: 研究揭示了基于对抗性扰动的语音克隆防御的局限性，并强调了开发更鲁棒解决方案的紧迫性，以应对语音克隆带来的安全和隐私风险。

中文摘要: 语音生成模型的快速发展加剧了与语音克隆（VC）相关的隐私和安全问题。近期研究通过引入对抗性扰动来干扰未经授权的语音克隆，但攻击者仍能绕过这些保护性扰动并成功实施语音克隆。本研究首次在包含扰动净化的真实威胁模型下，系统评估了这些保护性扰动对语音克隆的影响。研究发现，尽管现有净化方法能中和大部分保护性扰动，但仍会导致语音克隆模型特征空间失真，从而降低其性能。基于此，我们提出了一种新的两阶段净化方法：（1）净化受扰动的语音；（2）通过音素引导将其与干净语音分布对齐。实验结果表明，我们的方法在破坏语音克隆防御方面优于现有技术。本研究揭示了基于对抗性扰动的语音克隆防御的局限性，并强调了开发更鲁棒解决方案的紧迫性，以应对语音克隆带来的安全和隐私风险。代码和音频样本可在https://de-antifake.github.io获取。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [193] [Early Signs of Steganographic Capabilities in Frontier LLMs](https://arxiv.org/abs/2507.02737)
**中文标题：前沿大型语言模型的早期隐写能力迹象**

*Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner*

主要分类: cs.CR

摘要简述: 前沿大型语言模型（LLM）已展现出初步的隐写能力，但当前能力尚不足以绕过设计良好的监控系统。


<details>
  <summary>详细信息</summary>
研究动机: 研究前沿LLM的隐写能力，以评估其潜在风险，尤其是通过隐写术逃避监控的可能性。

研究方法: 评估LLM在两种隐写任务中的表现：传递编码信息和执行编码推理，测试其在标准和非标准条件下的能力。

研究结果: 当前模型在标准条件下无法隐蔽传递短信息，但在额外条件下（如使用未监控的草稿纸和协调编码方案）可能成功。模型还能进行基本的编码推理，但难以在掩护任务中隐蔽推理过程。

研究结论: 前沿LLM已具备初步隐写能力，但目前尚不足以绕过设计良好的监控系统，未来需警惕其能力提升。

中文摘要: 监控大型语言模型（LLM）的输出对于减少滥用和错位风险至关重要。然而，LLM可能通过隐写术逃避监控：在看似无害的生成内容中隐藏信息。本文评估了前沿LLM的隐写能力，以更好地理解其潜在风险。我们关注两种隐写类型：传递编码信息和执行编码推理。研究发现，当前模型在标准条件下无法隐蔽传递短信息，但在额外条件下（如使用未监控的草稿纸和协调编码方案）可能成功。此外，模型在简单状态跟踪问题中展现出初步的编码推理能力，包括使用自定义和预定义编码方案（如十六进制）。尽管如此，它们很少能在掩护任务中隐蔽推理过程以欺骗监控系统。总体而言，结果表明当前LLM已具备初步隐写能力。虽然这些能力目前可能不足以绕过设计良好的监控系统，但未来可能发生变化。

</details>


### [194] [MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation](https://arxiv.org/abs/2507.02057)
**中文标题：MGC：一种利用对齐LLM组合性盲区的恶意软件生成编译器框架**

*Lu Yan,Zhuo Zhang,Xiangzhe Xu,Shengwei An,Guangyu Shen,Zhou Xuan,Xuan Chen,Xiangyu Zhang*

主要分类: cs.CR

摘要简述: 本文提出了一种名为MGC的编译器框架，利用对齐大型语言模型（LLM）的组合性盲区，通过模块化分解和规避对齐机制生成恶意软件。实验表明，MGC能高效生成功能完整的恶意软件，性能显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）降低了软件开发的门槛，但也为恶意软件开发提供了便利。尽管LLM提供商通过对齐机制阻止直接生成恶意代码，但这些机制仅评估单个提示，忽略了恶意操作可分解为看似无害的子任务的风险。本文旨在揭示这种组合性攻击的威胁。

研究方法: MGC框架通过模块化分解恶意意图，利用中间表示（MDIR）将高级恶意目标转换为看似无害的代码片段，从而规避对齐机制的检测。

研究结果: 实验证明，MGC在三个基准数据集上生成恶意代码的正确性分别比越狱方法高365.79%，比地下服务高78.07%，并能复现并增强16个真实恶意软件样本。

研究结论: MGC暴露了对齐AI系统面临的组合性攻击风险，为安全研究提供了重要启示。

中文摘要: 大型语言模型（LLM）降低了复杂应用程序开发的专业门槛，但也为恶意软件开发提供了便利，引发了严重的安全问题。尽管LLM提供商通过对齐机制阻止直接生成明显恶意代码，但这些机制主要评估单个提示，忽略了一个关键漏洞：恶意操作可被系统性地分解为看似无害的子任务。本文提出恶意软件生成编译器（MGC），通过模块化分解和规避对齐生成利用这一漏洞。MGC采用专用的恶意描述中间表示（MDIR）连接高级恶意意图与无害代码片段。大量实验表明，我们的攻击能可靠生成功能完整的恶意软件，覆盖多种任务类别，在三个基准数据集上的正确性分别比越狱方法高365.79%，比地下服务高78.07%。案例研究进一步显示，MGC能复现并增强16个真实恶意软件样本。这项工作通过揭示对齐AI系统面临的组合性攻击风险，为安全研究提供了重要启示。演示见https://sites.google.com/view/malware-generation-compiler。

</details>


### [195] [Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities](https://arxiv.org/abs/2507.02125)
**中文标题：人工智能能否解决区块链预言机问题？挑战与可能性的探讨**

*Giulio Caldarelli*

主要分类: cs.CR

摘要简述: 本文探讨人工智能（AI）能否解决区块链预言机问题，分析其挑战与可能性，认为AI可作为补充工具提升数据质量和系统韧性，但无法完全消除对链外输入的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 区块链预言机问题限制了去中心化应用的发展，现有方法未能彻底解决链外数据可靠输入的问题。本文旨在评估AI在解决这一问题中的潜力与局限性。

研究方法: 通过结合学术文献和实践案例，分析AI技术（如异常检测、语言事实提取、动态声誉建模和抗对抗性）如何改进预言机系统。

研究结果: AI能显著提升数据质量、来源选择和系统韧性，但仍需依赖不可验证的链外输入，无法完全替代信任假设。

研究结论: AI应被视为预言机设计中的补充推理和过滤层，而非信任假设的替代方案。

中文摘要: 区块链预言机问题（即如何将可靠的链外数据注入去中心化系统）仍是开发无需信任应用的根本限制。尽管近年来涌现了多种架构、密码学和经济策略以缓解此问题，但尚未有人彻底解决区块链如何获取链外世界知识的基本问题。本文批判性评估了人工智能（AI）在解决预言机问题中的作用。结合学术文献和实践案例，探讨了AI技术（如异常检测、语言事实提取、动态声誉建模和抗对抗性）如何提升预言机系统。研究发现，尽管AI为改进数据质量、来源选择和系统韧性提供了强大工具，但仍无法消除对不可验证链外输入的依赖。因此，本研究支持将AI视为预言机设计中推理和过滤的补充层，而非信任假设的替代方案。

</details>


### [196] [EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer](https://arxiv.org/abs/2507.02206)
**中文标题：EIM-TRNG：通过RowHammer利用内存编码真随机数生成器混淆深度神经网络权重**

*Ranyang Zhou,Abeer Matar A. Almalky,Gamana Aragonda,Sabbir Ahmed,Filip Roth Trønnes-Christensen,Adnan Siraj Rakin,Shaahin Angizi*

主要分类: cs.CR

摘要简述: 本文提出了一种名为EIM-TRNG的新型硬件随机数生成器，利用DRAM中的RowHammer效应产生的物理随机性，保护深度神经网络的权重数据，确保模型的安全性和隐私性。


<details>
  <summary>详细信息</summary>
研究动机: 在深度神经网络（DNN）中，保护模型参数（尤其是权重）对确保AI系统的完整性、隐私性和知识产权至关重要。现有的软件伪随机数生成器缺乏硬件随机数生成器（TRNG）的不可预测性和鲁棒性。因此，本文旨在开发一种基于DRAM物理随机性的TRNG，以增强DNN的安全性。

研究方法: 本文提出了一种名为EIM-TRNG的编码内存随机数生成器，通过精确控制的RowHammer操作利用DRAM单元行为的物理随机性生成不可预测的比特翻转。这些翻转被用作可靠的熵源，并结合固定和不可预测的比特翻转对DNN权重数据进行加密。解密时使用基于翻转行为的密钥，确保数据的机密性和模型的真实性。

研究结果: 实验结果表明，基于DRAM的熵提取方法能够实现低成本且鲁棒的硬件安全性，为机器学习模型的硬件级保护提供了可行方向。

研究结论: EIM-TRNG通过利用DRAM的RowHammer效应，成功实现了对DNN权重数据的安全保护，为硬件级安全提供了新的解决方案。

中文摘要: 真随机数生成器（TRNG）在硬件安全、加密系统和数据保护中扮演着重要角色。在深度神经网络（DNN）中，保护模型参数（尤其是权重）对确保AI系统的完整性、隐私性和知识产权至关重要。尽管基于软件的伪随机数生成器被广泛使用，但它们缺乏硬件TRNG的不可预测性和鲁棒性。本文首次提出了一种名为EIM-TRNG的新型编码内存TRNG，利用DRAM单元行为（特别是RowHammer引起的扰动）中的物理随机性。我们展示了如何通过精确控制的RowHammer操作生成不可预测的比特翻转，并将其作为可靠的熵源。此外，我们应用此TRNG框架，通过固定和不可预测的比特翻转组合对DNN权重数据进行编码保护。加密数据随后通过基于翻转行为的密钥解密，确保数据机密性和模型真实性。实验结果验证了基于DRAM的熵提取方法在低成本硬件安全中的有效性，并为机器学习模型的硬件级保护提供了新方向。

</details>


### [197] [Evaluating Language Models For Threat Detection in IoT Security Logs](https://arxiv.org/abs/2507.02390)
**中文标题：评估语言模型在物联网安全日志中的威胁检测能力**

*Jorge J. Tejero-Fernández,Alfonso Sánchez-Macián*

主要分类: cs.CR

摘要简述: 本文提出了一种利用微调的大型语言模型（LLMs）进行物联网安全日志异常检测和缓解建议的流程，结果显示LLMs在多类攻击分类上优于传统机器学习分类器。


<details>
  <summary>详细信息</summary>
研究动机: 日志分析是网络安全领域的重要研究方向，能够为网络和系统威胁检测提供信息。本文旨在探索如何利用LLMs提升物联网安全日志的异常检测和缓解建议能力。

研究方法: 研究比较了三种开源LLMs在二进制和多类异常检测中的表现，采用了零样本、少样本提示和微调三种策略，并以传统机器学习分类器为基线。通过将检测到的威胁映射到MITRE CAPEC，并定义物联网特定的缓解措施，模型能够提供检测与建议结合的指导。

研究结果: 实验结果表明，LLMs在多类攻击分类任务中表现优于基线模型，且通过微调能够提供有效的检测和缓解建议。

研究结论: LLMs在物联网安全日志的异常检测和缓解建议中具有显著优势，未来可进一步优化其在实际场景中的应用。

中文摘要: 日志分析是网络安全领域的重要研究方向，能够为网络和系统威胁检测提供信息。本文提出了一种利用微调的大型语言模型（LLMs）进行物联网安全日志异常检测和缓解建议的流程。通过以传统机器学习分类器为基线，比较了三种开源LLMs在二进制和多类异常检测中的表现，采用了零样本、少样本提示和微调三种策略。结果显示，LLMs在多类攻击分类任务中表现优于基线模型。通过将检测到的威胁映射到MITRE CAPEC，并定义物联网特定的缓解措施，模型能够提供检测与建议结合的指导。

</details>


### [198] [CyberRAG: An agentic RAG cyber attack classification and reporting tool](https://arxiv.org/abs/2507.02424)
**中文标题：CyberRAG：一种基于代理的RAG网络攻击分类与报告工具**

*Francesco Blefari,Cristian Cosentino,Francesco Aurelio Pironti,Angelo Furfaro,Fabrizio Marozzo*

主要分类: cs.CR

摘要简述: CyberRAG是一种基于代理的RAG框架，用于实时分类、解释和结构化报告网络攻击。通过模块化设计和动态控制流，显著减少误报并提升解释性，准确率达94.92%。


<details>
  <summary>详细信息</summary>
研究动机: 大型企业的入侵检测与防御系统（IDS/IPS）每小时生成数十万条警报，传统机器学习检测器误报率高，标准RAG管道常检索无关内容且无法合理解释预测。为解决这些问题，提出了CyberRAG。

研究方法: CyberRAG采用模块化代理框架，包括：（1）针对特定攻击家族的微调分类器；（2）用于丰富和警报的工具适配器；（3）迭代检索与推理循环，动态查询领域知识库直至证据相关且自洽。

研究结果: CyberRAG每类准确率超过94%，最终分类准确率达94.92%。生成的解释在BERTScore中得分为0.94，在GPT-4专家评估中得分为4.9/5。

研究结论: CyberRAG通过代理化设计和专业分类器，实现了高检测准确率和可信的解释，为半自主网络防御工作流提供了实用且可扩展的解决方案。

中文摘要: 大型企业的入侵检测与防御系统（IDS/IPS）每小时可生成数十万条警报，使安全分析师淹没在需要快速演变的领域专业知识的日志中。传统的机器学习检测器虽能减少警报量，但仍存在高误报率，而标准的单次检索增强生成（RAG）管道常检索无关内容且无法合理解释预测。为克服这些不足，我们提出了CyberRAG，一种模块化、基于代理的RAG框架，提供网络攻击的实时分类、解释和结构化报告。核心LLM代理协调（i）一组针对特定攻击家族的微调分类器；（ii）用于丰富和警报的工具适配器；（iii）迭代检索与推理循环，持续查询领域知识库直至证据相关且自洽。与传统RAG系统不同，CyberRAG采用代理化设计，支持动态控制流和自适应推理。这种以代理为中心的架构自主优化威胁标签和自然语言解释，减少误报并提升可解释性。该框架完全可扩展：只需添加分类器即可支持新攻击类型，无需重新训练核心代理。CyberRAG的评估结果显示，每类准确率超过94%，通过语义协调最终分类准确率达94.92%。生成的解释在BERTScore中得分为0.94，在基于GPT-4的专家评估中得分为4.9/5。这些结果表明，基于代理、面向专业化的RAG能够将高检测准确率与可信的、适合SOC的文本相结合，为半自主网络防御工作流提供了一条实用且可扩展的路径。

</details>


### [199] [Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](https://arxiv.org/abs/2507.02735)
**中文标题：Meta SecAlign：一种抵御提示注入攻击的安全基础大语言模型**

*Sizhe Chen,Arman Zharmagambetov,David Wagner,Chuan Guo*

主要分类: cs.CR

摘要简述: Meta SecAlign是首个开源且具有内置模型级防御的大语言模型（LLM），能有效抵御提示注入攻击，并在通用指令遵循和下游任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 提示注入攻击对LLM集成应用构成重大安全威胁。尽管模型级防御效果显著，但目前商业级模型多以闭源形式部署。AI安全社区需要开源模型，以通过开放研究推动攻击与防御的共同发展。

研究方法: Meta SecAlign基于改进版SOTA SecAlign防御技术，提供完整的训练方案。模型在通用指令调优数据集上训练，具备对未见下游任务（如工具调用和网络导航）的安全防护能力。

研究结果: Meta-SecAlign-70B在9个实用基准和7个安全基准测试中表现优异，其抗提示注入攻击的鲁棒性达到SOTA水平，且实用性与闭源商业LLM相当。

研究结论: Meta SecAlign为开源社区提供了首个兼具高性能和模型级防御的LLM，推动了对抗提示注入攻击的科学研究。

中文摘要: 提示注入攻击对集成大语言模型（LLM）的应用构成重大安全威胁。尽管模型级防御表现出强大效果，但目前商业级模型多以闭源形式部署。我们认为，AI安全社区需要开源模型，通过开放研究推动攻击与防御的共同发展，从而科学提升对提示注入攻击的防御能力。为此，我们开发了Meta SecAlign，这是首个开源且具有内置模型级防御的大语言模型，其性能达到商业级水平。我们提供了完整的训练方案细节，该方案基于改进版的SOTA SecAlign防御技术。在9个实用基准和7个安全基准测试中，Meta SecAlign尽管基于通用指令调优数据集训练，仍能对未见下游任务（如工具调用和网络导航）提供安全保障，同时保持通用指令遵循能力。我们的最佳模型——Meta-SecAlign-70B——在抗提示注入攻击的鲁棒性上达到SOTA水平，且实用性与闭源商业LLM相当。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [200] [Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain](https://arxiv.org/abs/2507.02016)
**中文标题：为信念-愿望-意图机器人提供有效解释：何时解释及解释什么**

*Cong Wang,Roberto Calandra,Verena Klös*

主要分类: cs.RO

摘要简述: 研究探讨了如何为执行复杂任务的机器人提供有效解释，以减少用户困惑。用户偏好简洁的解释，尤其是在意外行为时。


<details>
  <summary>详细信息</summary>
研究动机: 机器人在日常任务中可能因行为偏离预期而引发用户困惑，提供合适的解释有助于改善用户体验。

研究方法: 通过调查用户对厨房清洁机器人解释需求和内容的偏好，提出两种算法识别意外行为并生成有效解释。

研究结果: 用户倾向于在意外行为时获得简洁解释，明确机器人意图和决策背景。提出的算法可轻松整合到BDI推理中。

研究结论: 研究为BDI机器人提供了生成上下文和用户特定解释的方法，促进了更好的人机交互。

中文摘要: 当机器人在日常生活中执行复杂且依赖上下文的任务时，偏离预期的行为可能使用户感到困惑。解释机器人的推理过程有助于用户理解其意图。然而，何时提供解释及其内容对避免用户反感至关重要。我们调查了用户对厨房清洁机器人解释需求和内容的偏好。结果显示，用户希望在意外情况下获得解释，并偏好简洁的解释，明确说明行为背后的意图及相关的上下文因素。基于这些发现，我们提出了两种算法，用于识别意外行为并为信念-愿望-意图（BDI）机器人构建有效解释。这些算法可轻松整合到BDI推理过程中，为基于上下文和用户特定解释的更好人机交互铺平道路。

</details>


### [201] [Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN](https://arxiv.org/abs/2507.02171)
**中文标题：基于自监督循环神经网络的生物启发机器人轨迹规划**

*Miroslav Cibula,Kristína Malinovská,Matthias Kerzel*

主要分类: cs.RO

摘要简述: 本文提出了一种基于自监督循环神经网络的生物启发机器人轨迹规划方法，通过结合正向和逆向运动学模型，实现了高效且自适应的轨迹生成。


<details>
  <summary>详细信息</summary>
研究动机: 传统的机器人轨迹规划方法（如基于采样的规划器）计算成本高，而现有的监督学习方法仅模仿轨迹而非学习其成功性。本文旨在开发一种自监督学习框架，以更高效且自适应地生成轨迹。

研究方法: 采用自监督循环神经网络（RNN）构建轨迹模型，结合正向和逆向运动学模型，通过单次或固定次数的神经网络传递实现轨迹规划。

研究结果: 实验表明，该方法能够仅通过给定的正向和逆向运动学模型学习生成轨迹，为复杂任务提供自适应解决方案。

研究结论: 本文提出的自监督学习方法为机器人轨迹规划提供了一种高效且灵活的替代方案，适用于需要自适应能力的复杂任务。

中文摘要: 机器人轨迹规划是指生成一系列关节配置，使机器人或其机械臂从初始状态到达目标状态，同时考虑机器人运动学和环境约束。传统方法依赖基于采样的规划器，计算成本高。近期研究表明，轨迹规划可通过监督序列学习实现，通常仅需单次或固定次数的神经网络传递，从而确保计算时间可控。然而，这种完全监督方法仅模仿轨迹，而非学习其成功性。本文基于此提出了一种认知启发的自监督学习方案，采用循环神经网络构建轨迹模型。通过机器人臂的运动学规划任务验证了该方法的可行性。结果表明，模型能够仅利用给定的正向和逆向运动学模型学习生成轨迹，表明这一新方法可为需要自适应解决方案的复杂任务提供支持。

</details>


### [202] [MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping](https://arxiv.org/abs/2507.02672)
**中文标题：MISCGrasp：利用多尺度集成和对比学习增强体积抓取**

*Qingyu Fan,Yinghao Cai,Chao Li,Chunting Jiao,Xudong Zheng,Tao Lu,Bin Liang,Shuo Wang*

主要分类: cs.RO

摘要简述: MISCGrasp是一种结合多尺度特征提取和对比学习的体积抓取方法，通过Insight Transformer和Empower Transformer实现高低层次特征的交互与选择，提升自适应抓取能力。


<details>
  <summary>详细信息</summary>
研究动机: 机器人抓取在面对形状和大小各异的物体时存在适应性问题。本文旨在通过多尺度特征提取和对比学习，提升抓取的自适应性和准确性。

研究方法: MISCGrasp通过Insight Transformer实现高低层次特征的查询式交互，Empower Transformer选择性地关注最高层次特征，平衡几何细节与整体结构。同时，利用多尺度对比学习增强特征一致性。

研究结果: 在模拟和真实环境中的实验表明，MISCGrasp在桌面整理任务中优于基线方法和变体方法。

研究结论: MISCGrasp通过多尺度特征整合和对比学习，显著提升了机器人抓取的适应性和性能。

中文摘要: 机器人抓取在适应形状和大小各异的物体时面临挑战。本文提出MISCGrasp，一种结合多尺度特征提取和对比特征增强的自适应体积抓取方法。通过Insight Transformer实现高低层次特征的查询式交互，Empower Transformer选择性地关注最高层次特征，从而在几何细节与整体结构之间取得平衡。此外，MISCGrasp利用多尺度对比学习挖掘正抓取样本间的相似性，确保多尺度特征的一致性。在模拟和真实环境中的大量实验表明，MISCGrasp在桌面整理任务中优于基线方法和变体方法。更多细节请访问https://miscgrasp.github.io/。

</details>


### [203] [MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real](https://arxiv.org/abs/2507.02864)
**中文标题：MultiGen：利用多模态生成仿真学习真实世界的多模态策略**

*Renhao Wang,Haoran Geng,Tingle Li,Feishi Wang,Gopala Anumanchipalli,Philipp Wu,Trevor Darrell,Boyi Li,Pieter Abbeel,Jitendra Malik,Alexei A. Efros*

主要分类: cs.RO

摘要简述: MultiGen框架通过将大规模生成模型与传统物理模拟器结合，实现了多感官模拟，解决了多模态策略学习中的仿真难题，并在机器人倒水任务中展示了零样本迁移到真实世界的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 机器人需要整合多种感官模态以在现实世界中有效行动，但大规模学习多模态策略仍具挑战性。仿真虽为可行方案，但除视觉外，其他模态（如声音）难以模拟，导致多模态仿真到现实的迁移尚未实现。

研究方法: MultiGen框架将生成模型集成到传统物理模拟器中，通过合成基于仿真视频的逼真音频，实现多感官模拟，从而无需真实机器人数据即可训练多模态策略。

研究结果: 在机器人倒水任务中，MultiGen展示了零样本迁移到真实世界的能力，能够处理新容器和液体的倒水任务，验证了生成模型在多模态仿真和缩小仿真与现实差距中的潜力。

研究结论: MultiGen通过生成模型解决了多模态仿真的难题，为多模态策略学习提供了新思路，并展示了在真实世界任务中的有效迁移能力。

中文摘要: 机器人必须整合多种感官模态才能在现实世界中有效行动。然而，大规模学习这种多模态策略仍然具有挑战性。仿真提供了一种可行的解决方案，但尽管视觉受益于高保真模拟器，其他模态（如声音）却难以模拟。因此，仿真到现实的迁移主要在基于视觉的任务中取得成功，多模态迁移仍未实现。在这项工作中，我们通过引入MultiGen框架来解决这些挑战，该框架将大规模生成模型集成到传统物理模拟器中，实现多感官模拟。我们在机器人倒水的动态任务中展示了该框架，该任务本质上依赖于多模态反馈。通过合成基于仿真视频的逼真音频，我们的方法能够在无需任何真实机器人数据的情况下训练丰富的视听轨迹。我们展示了在真实世界倒水任务中对新容器和液体的有效零样本迁移，凸显了生成模型在模拟难以建模的模态和缩小多模态仿真与现实差距方面的潜力。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [204] [Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System](https://arxiv.org/abs/2507.02000)
**中文标题：为何多兴趣公平性重要：基于超图对比多兴趣学习的公平对话推荐系统**

*Yongsen Zheng,Zongxuan Xie,Guohua Wang,Ziyao Liu,Liang Lin,Kwok-Yan Lam*

主要分类: cs.IR

摘要简述: 本文提出了一种新型框架HyFairCRS，通过超图对比多兴趣学习解决对话推荐系统中的多兴趣多样性公平问题，实验证明其有效性和先进性。


<details>
  <summary>详细信息</summary>
研究动机: 推荐系统中的不公平问题（如性别、种族、年龄或流行度偏见）在动态对话推荐系统中尤为突出，可能导致马太效应、过滤气泡等问题。现有方法多针对静态场景，动态环境下的公平性研究亟待加强。

研究方法: HyFairCRS通过对比学习构建多样化超图以捕捉用户多兴趣，并在对话中利用这些兴趣生成公平的推荐响应，动态优化用户-系统反馈循环。

研究结果: 在两个对话推荐系统数据集上的实验表明，HyFairCRS在性能上达到新高度，同时显著缓解了不公平问题。

研究结论: HyFairCRS为动态对话推荐系统中的多兴趣公平性提供了有效解决方案，实验验证了其优越性和实用性。

中文摘要: 不公平性是推荐系统（RSs）中众所周知的挑战，常导致基于性别、种族、年龄或流行度等属性的偏见结果。尽管已有方法开始改进离线或静态场景下的公平推荐，但不公平问题随时间加剧，引发马太效应、过滤气泡等严重问题。为解决这些挑战，我们提出了一种新型框架——基于超图对比多兴趣学习的公平对话推荐系统（HyFairCRS），旨在动态交互式对话推荐系统（CRSs）中促进多兴趣多样性公平。HyFairCRS首先通过对比学习构建多样化超图以捕捉广泛的用户兴趣，随后在对话中利用这些兴趣生成信息丰富的响应，并确保动态用户-系统反馈循环中的公平项目预测。在两个CRS数据集上的实验表明，HyFairCRS实现了新的最优性能，同时有效缓解了不公平性。代码详见https://github.com/zysensmile/HyFairCRS。

</details>


### [205] [ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations](https://arxiv.org/abs/2507.02014)
**中文标题：ManifoldMind：基于动态双曲推理的可信推荐系统**

*Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic*

主要分类: cs.IR

摘要简述: ManifoldMind是一种基于双曲空间的概率几何推荐系统，通过动态曲率和概率球体建模用户、物品和标签，实现个性化不确定性建模和语义探索，优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有推荐系统通常采用固定曲率和刚性嵌入，无法灵活建模用户和物品的不确定性，且缺乏透明性和探索性。ManifoldMind旨在通过双曲空间和动态曲率解决这些问题。

研究方法: ManifoldMind将用户、物品和标签表示为自适应曲率的概率球体，利用曲率感知的语义核进行多跳推理，支持多样化的概念路径探索，避免对浅层交互的过拟合。

研究结果: 在四个公开基准测试中，ManifoldMind在NDCG、校准性和多样性方面优于强基线，并能生成显式推理轨迹，提升推荐的可信度和探索性。

研究结论: ManifoldMind通过动态双曲空间建模和语义探索，实现了透明、可信且探索驱动的推荐，适用于稀疏或抽象领域。

中文摘要: 我们提出了ManifoldMind，一种用于在双曲空间中对语义层次进行探索性推理的概率几何推荐系统。与现有固定曲率和刚性嵌入的方法不同，ManifoldMind将用户、物品和标签表示为自适应曲率的概率球体，支持个性化不确定性建模和几何感知的语义探索。通过曲率感知的语义核，模型支持软性多跳推理，能够探索多样化的概念路径，而非局限于浅层或直接交互。在四个公开基准测试中，ManifoldMind在NDCG、校准性和多样性方面表现优于强基线，并能生成显式推理轨迹，为稀疏或抽象领域提供透明、可信且探索驱动的推荐。

</details>


### [206] [When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search](https://arxiv.org/abs/2507.02139)
**中文标题：当大型语言模型意见相左时：SDG搜索中的相关性过滤偏差与检索分歧诊断**

*William A. Ingram,Bipasha Banerjee,Edward A. Fox*

主要分类: cs.IR

摘要简述: 研究发现，大型语言模型（LLMs）在标注文档相关性时存在系统性分歧，这种分歧会导致检索结果的显著差异，尤其是在政策相关或主题搜索任务中。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在信息检索中的广泛应用，不同模型对边缘案例的标注分歧可能影响下游检索结果。本研究旨在探讨这种分歧的性质及其对检索任务的影响。

研究方法: 研究选取了两个开源权重的大型语言模型（LLaMA和Qwen），对与可持续发展目标（SDGs）1、3和7相关的学术摘要进行标注。通过分析分歧子集的词汇特征、排序行为和分类可预测性，揭示了分歧的系统性。

研究结果: 结果表明，模型分歧并非随机，而是具有系统性：分歧案例表现出一致的词汇模式，在共享评分函数下产生显著不同的排名结果，且通过简单分类器可区分（AUC超过0.74）。

研究结论: 研究建议将分类分歧作为检索评估的分析对象，尤其是在政策相关或主题搜索任务中，以更好地理解LLM过滤对检索结果的影响。

中文摘要: 大型语言模型（LLMs）越来越多地用于信息检索流程中的文档相关性标注，尤其是在缺乏人工标注数据的领域。然而，不同模型对边缘案例的标注往往存在分歧，这引发了对下游检索影响的担忧。本研究分析了两个开源权重LLM（LLaMA和Qwen）在可持续发展目标（SDGs）1、3和7相关学术摘要上的标注分歧。我们分离了分歧子集，并研究了其词汇特性、排序行为和分类可预测性。结果显示，模型分歧是系统性的而非随机的：分歧案例表现出一致的词汇模式，在共享评分函数下产生显著不同的排名结果，且通过简单分类器可区分（AUC超过0.74）。这些发现表明，即使在控制提示和共享排序逻辑的情况下，基于LLM的过滤仍会为文档检索引入结构化变异性。我们建议将分类分歧作为检索评估的分析对象，尤其是在政策相关或主题搜索任务中。

</details>


### [207] [Content filtering methods for music recommendation: A review](https://arxiv.org/abs/2507.02282)
**中文标题：音乐推荐中的内容过滤方法综述**

*Terence Zeng,Abhishek K. Umrawal*

主要分类: cs.IR

摘要简述: 本文综述了音乐推荐系统中内容过滤方法的研究现状，重点探讨了如何通过内容过滤缓解协同过滤中的偏差问题，并分析了歌词分析和音频信号处理等技术。


<details>
  <summary>详细信息</summary>
研究动机: 音乐推荐系统中，协同过滤方法因用户交互稀疏性而效果有限。本文旨在探讨内容过滤方法如何解决这一问题，并分析其技术实现与潜在冲突。

研究方法: 综述了当前内容过滤方法的研究，包括基于大语言模型（LLMs）的歌词分析和音频信号处理技术，并探讨了不同方法间的潜在冲突及解决方案。

研究结果: 内容过滤方法在音乐推荐中能有效缓解协同过滤的稀疏性问题，但不同技术间可能存在冲突，需进一步研究以优化整合。

研究结论: 内容过滤是解决音乐推荐中协同过滤局限性的有效途径，未来研究需关注技术整合与冲突解决。

中文摘要: 推荐系统在现代音乐流媒体平台中至关重要，影响着用户发现和互动音乐的方式。协同过滤是推荐系统中常见的方法，它根据与目标用户听歌模式相似的用户偏好推荐内容。然而，对于交互稀疏的媒体（如音乐），这种方法效果较差。由于音乐流媒体用户很少收听绝大多数曲目，稀疏性问题尤为突出。本文综述了当前研究如何应对这些挑战，重点探讨了内容过滤在缓解协同过滤固有偏差中的作用。我们研究了多种用于内容过滤的歌曲分类方法，包括基于大语言模型（LLMs）的歌词分析和音频信号处理技术。此外，还讨论了这些不同分析方法间的潜在冲突，并提出了解决此类差异的途径。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [208] [HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3](https://arxiv.org/abs/2507.02345)
**中文标题：HelixDesign-Antibody：基于HelixFold3的可扩展生产级抗体设计平台**

*Jie Gao,Jing Hu,Shanzhuo Zhang,Kunrui Zhu,Sheng Qian,Yueyang Huang,Xiaonan Zhang,Xiaomin Fang*

主要分类: q-bio.BM

摘要简述: HelixDesign-Antibody是一个基于HelixFold3的高通量抗体设计平台，通过高性能计算支持大规模生成和评估抗体候选序列，显著提升抗体工程效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统抗体发现方法依赖耗时且资源密集的实验筛选，亟需一种高效、可扩展的解决方案以加速抗体工程和生物医学研究。

研究方法: 该平台基于高精度结构预测模型HelixFold3，结合高性能计算支持，实现抗体候选序列的大规模生成及其与抗原相互作用的评估。

研究结果: 验证表明，平台能生成多样且高质量的抗体，并揭示探索更大序列空间可提高发现最佳结合体的概率。

研究结论: HelixDesign-Antibody为大规模抗体设计提供了无缝、易用的解决方案，显著提升了抗体工程的效率和可扩展性。

中文摘要: 抗体工程对于开发治疗药物和推动生物医学研究至关重要。传统发现方法通常依赖耗时且资源密集的实验筛选。为了优化并简化这一过程，我们推出了一个基于HelixFold3的生产级高通量平台——HelixDesign-Antibody。该平台利用高精度结构预测模型HelixFold3，支持大规模生成抗体候选序列并评估其与抗原的相互作用。集成的高性能计算（HPC）支持实现了高通量筛选，解决了工具链分散和高计算需求等挑战。在多个抗原上的验证表明，该平台能够生成多样且高质量的抗体，并证实了探索更大序列空间可提高发现最佳结合体概率的规模效应。该平台为大规模抗体设计提供了无缝、易用的解决方案，可通过PaddleHelix平台的抗体设计页面访问。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [209] [Generating Large Semi-Synthetic Graphs of Any Size](https://arxiv.org/abs/2507.02166)
**中文标题：生成任意规模的大型半合成图**

*Rodrigo Tuna,Carlos Soares*

主要分类: cs.SI

摘要简述: 本文提出了一种名为LGSG的新框架，利用扩散模型和节点嵌入生成任意大小的图，解决了传统方法依赖节点ID和无法生成更大图的限制。实验表明，LGSG在标准指标上与基线模型相当，并在聚类倾向等被忽视的指标上表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 传统图生成方法依赖节点ID，无法生成比输入图更大的图，且忽略了节点属性。深度学习的最新进展虽提供了数据驱动的方法，但仍受限于节点ID的依赖。本文旨在解决这些问题，提出一种无需重新训练即可生成不同大小图的框架。

研究方法: 本文提出Latent Graph Sampling Generation (LGSG)框架，结合扩散模型和节点嵌入技术，通过捕获节点嵌入和子图结构的分布，实现无需依赖节点ID的图生成。该方法支持生成任意大小的图。

研究结果: 实验结果表明，LGSG在标准指标上与基线模型性能相当，同时在节点聚类倾向等被忽视的指标上表现更优。此外，LGSG在不同大小的图中保持了一致的结构特性，展示了其鲁棒性和可扩展性。

研究结论: LGSG框架通过消除对节点ID的依赖并捕获节点嵌入和子图结构的分布，实现了灵活且可扩展的图生成。其性能优于基线模型，并在多个指标上表现出色，为图生成领域提供了新的解决方案。

中文摘要: 图生成是网络科学中的重要领域。传统方法专注于复制现实世界图的特定属性，如小直径或幂律度分布。深度学习的最新进展，尤其是图神经网络，使得数据驱动方法能够在不依赖预定义结构属性的情况下学习和生成图。尽管取得了这些进展，当前模型仍受限于对节点ID的依赖，这限制了它们生成比输入图更大的图的能力，并忽略了节点属性。为解决这些问题，我们提出了潜在图采样生成（LGSG），一种新颖的框架，利用扩散模型和节点嵌入生成不同大小的图而无需重新训练。该框架消除了对节点ID的依赖，并捕获了节点嵌入和子图结构的分布，实现了可扩展且灵活的图生成。实验结果表明，LGSG在标准指标上与基线模型表现相当，同时在如节点形成聚类的倾向等被忽视的指标上优于它们。此外，它在不同大小的图中保持了一致的结构特性，展示了鲁棒性和可扩展性。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [210] [TubuleTracker: a high-fidelity shareware software to quantify angiogenesis architecture and maturity](https://arxiv.org/abs/2507.02024)
**中文标题：TubuleTracker：一款高保真免费软件，用于量化血管生成结构和成熟度**

*Danish Mahmood,Stephanie Buczkowski,Sahaj Shah,Autumn Anthony,Rohini Desetty,Carlo R Bartoli*

主要分类: q-bio.QM

摘要简述: TubuleTracker是一款高效、客观的免费软件，用于快速量化血管网络结构和成熟度，显著优于手动和ImageJ分析。


<details>
  <summary>详细信息</summary>
研究动机: 目前体外内皮细胞培养研究中，血管网络的图像分析依赖耗时且主观的手动方法，或速度慢、准确性低的自动化工具（如ImageJ）。此外，传统指标难以全面反映复杂网络的成熟度。

研究方法: 研究使用人脐静脉内皮细胞培养模型，采集54张图像，分别通过手动、ImageJ和TubuleTracker分析，评估管状结构数量、总长度、节点数、面积和血管圆形度等指标，并由专家对血管成熟度评分。

研究结果: TubuleTracker分析速度最快（6±2秒/图像），显著优于手动（8分钟）和ImageJ（58±4秒）。其指标（如管状结构数量、圆形度）与血管成熟度评分显著相关。

研究结论: TubuleTracker在速度和一致性上优于传统方法，血管圆形度能有效反映成熟度，软件已免费开放供生物医学研究使用。

中文摘要: 背景：体外内皮细胞培养广泛用于血管生成研究。传统的手动分析耗时且主观，自动化工具（如ImageJ）速度慢且不准确。此外，复杂网络的成熟度难以通过传统指标全面评估。为此，我们开发了TubuleTracker，一款快速、客观量化血管网络结构和成熟度的软件。方法：培养人脐静脉内皮细胞并采集54张图像，分别通过手动、ImageJ和TubuleTracker分析，评估管状结构数量、总长度、节点数、面积和血管圆形度，同时由专家对成熟度评分（1-5分）。结果：TubuleTracker分析速度最快（6±2秒/图像），显著优于手动（8分钟）和ImageJ（58±4秒）。其指标与成熟度评分显著相关（如管状结构数量、圆形度，p<0.0001）。结论：TubuleTracker更快、更一致，血管圆形度能有效反映成熟度，软件已免费开放。

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [211] [Integrating Large Language Models in Financial Investments and Market Analysis: A Survey](https://arxiv.org/abs/2507.01990)
**中文标题：大型语言模型在金融投资与市场分析中的整合应用：一项综述**

*Sedigheh Mahdavi,Jiating,Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh*

主要分类: q-fin.GN

摘要简述: 本文综述了大型语言模型（LLMs）在金融投资与市场分析中的应用，总结了其在股票选择、风险评估、情感分析、交易和金融预测中的研究进展，并探讨了其能力、挑战及未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 传统金融投资策略依赖定量模型和基本面分析，但大型语言模型（LLMs）能够处理海量结构化和非结构化数据，提供实时决策支持。本文旨在系统梳理LLMs在金融领域的研究进展，为未来研究提供参考。

研究方法: 本文通过文献综述方法，将LLMs在金融领域的研究分为四大框架：基于LLM的框架与流程、混合集成方法、微调与适应方法、以及基于代理的架构，并详细分析了其在股票选择、风险评估等具体应用中的表现。

研究结果: 研究发现，LLMs在金融领域展现出强大的数据处理和实时分析能力，但也面临数据质量、模型解释性等挑战。未来研究可进一步探索LLMs与其他技术的结合。

研究结论: LLMs为金融投资与市场分析提供了新的工具和方法，但其应用仍需解决技术挑战。未来的研究应关注模型优化和多领域融合。

中文摘要: 大型语言模型（LLMs）已被应用于金融决策，提升了投资策略的分析能力。传统投资策略通常依赖定量模型、基本面分析和技术指标，而LLMs能够处理和分析大量结构化和非结构化数据，提取有意义的见解，并实时增强决策能力。本文综述了金融领域中LLMs的最新研究，将研究贡献分为四大框架：基于LLM的框架与流程、混合集成方法、微调与适应方法、以及基于代理的架构。通过对现有文献的梳理，本文总结了LLMs在股票选择、风险评估、情感分析、交易和金融预测中的应用，并探讨了其能力、挑战和潜在发展方向。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [212] [Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting](https://arxiv.org/abs/2507.01997)
**中文标题：迈向一个民主化AI代理实验与基准测试的游乐场：网络故障排除应用**

*Zhihao Wang,Alessandro Cornacchia,Franco Galante,Carlo Centofanti,Alessio Sacco,Dingde Jiang*

主要分类: cs.NI

摘要简述: 本文探讨了AI代理在网络故障排除中的应用，并提出了一个标准化、可复现且开放的基准测试平台的需求，以低操作成本构建和评估AI代理。


<details>
  <summary>详细信息</summary>
研究动机: 近期研究表明，人工智能（AI）尤其是大型语言模型（LLM）在网络配置合成和自动化网络诊断任务中表现优异。然而，目前缺乏一个标准化的平台来支持AI代理在网络故障排除中的开发与评估。

研究方法: 本研究聚焦于AI代理在网络故障排除中的应用，并提出了一个标准化、可复现且开放的基准测试平台的设计需求。

研究结果: 研究强调了构建一个低操作成本的AI代理评估平台的重要性，以促进网络故障排除领域的研究与实践。

研究结论: 本文呼吁建立一个开放的基准测试平台，以支持AI代理在网络故障排除中的开发与评估，推动该领域的进一步发展。

中文摘要: 近期研究证明了人工智能（AI），尤其是大型语言模型（LLM）在网络配置合成和自动化网络诊断任务中的有效性。在这项初步工作中，我们将研究范围限定于AI代理在网络故障排除中的应用，并详细阐述了对一个标准化、可复现且开放的基准测试平台的需求，以便以低操作成本构建和评估AI代理。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [213] [Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation](https://arxiv.org/abs/2507.02306)
**中文标题：合成启发式评估：AI与人类驱动的用户体验评估比较**

*Ruican Zhong,David W. McDonald,Gary Hsieh*

主要分类: cs.HC

摘要简述: 本文提出了一种基于多模态大语言模型（LLM）的合成启发式评估方法，用于用户体验评估。实验表明，该方法在识别可用性问题上表现优于人类评估者，尤其在布局问题上表现突出，但在识别UI组件和设计惯例方面存在不足。


<details>
  <summary>详细信息</summary>
研究动机: 传统的用户体验评估成本高昂，需要专家时间和用户补偿。本文旨在探索利用多模态LLM的能力进行合成启发式评估，以降低评估成本并提高效率。

研究方法: 研究开发了一种基于多模态LLM的合成启发式评估方法，通过分析图像并提供设计反馈。该方法在两个应用程序上与经验丰富的用户体验从业者的评估结果进行了对比。

研究结果: 合成评估方法在两个应用中分别识别了73%和77%的可用性问题，优于5名人类评估者（57%和63%）。合成评估在布局问题上表现优异，但在识别UI组件和设计惯例方面存在不足。

研究结论: 合成启发式评估在可用性问题上表现优于人类评估者，尤其在布局问题上具有优势，但在某些方面仍需改进。研究为合成启发式评估的设计提供了参考。

中文摘要: 用户体验评估在以人为本的设计中至关重要，但成本高昂，需要专家时间和用户补偿。本研究开发了一种基于多模态大语言模型（LLM）的合成启发式评估方法，利用其分析图像和提供设计反馈的能力。通过将合成评估与经验丰富的用户体验从业者在两个应用中的评估结果进行比较，我们发现合成评估分别识别了73%和77%的可用性问题，优于5名人类评估者（57%和63%）。与人类评估者相比，合成评估在不同任务中表现一致，并在检测布局问题上表现突出，突显了合成评估在注意力和感知方面的潜在优势。然而，合成评估在识别某些UI组件和设计惯例以及跨屏幕违规方面存在困难。此外，对合成评估的长期和多账户测试表明其性能稳定。总体而言，本研究揭示了人类与LLM驱动评估之间的性能差异，为合成启发式评估的设计提供了参考。

</details>


### [214] [Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue](https://arxiv.org/abs/2507.02537)
**中文标题：你在听我说吗？微调聊天机器人以实现同理心对话**

*Paulo Ricardo Knob,Leonardo Scholler,Juliano Rigatti,Soraia Raupp Musse*

主要分类: cs.HC

摘要简述: 本研究探讨如何通过微调大型语言模型（如ChatGPT和Gemini）生成更具同理心的对话，结合情感分析和专家评估，发现情感建模需兼顾结构对齐和深度。


<details>
  <summary>详细信息</summary>
研究动机: 随着对话代理在医疗、教育等领域的广泛应用，情感智能（尤其是同理心倾听）的需求日益突出。研究旨在探索大型语言模型在生成情感丰富对话时的表现。

研究方法: 研究从专家手工制作的小型同理心对话数据集出发，利用ChatGPT和Gemini扩展对话，并通过VADER情感分析和专家评估分析情感进展。

研究结果: 生成的对话虽能反映情感结构，但人类评估显示其同理心和连贯性存在差异，表明情感建模需结合自动化和人工方法。

研究结论: 情感建模不仅需结构对齐，还需深度，开发情感智能代理需综合自动化和人工评估方法。

中文摘要: 自ELIZA以来，对话代理已取得显著进展，其应用扩展到医疗、教育和客服等多个领域。随着这些代理日益融入人类日常互动，情感智能（尤其是同理心倾听）的需求变得至关重要。本研究探讨了大型语言模型（LLMs）在生成情感丰富互动时的表现。我们从专家手工制作的同理心行为小数据集出发，利用ChatGPT和Gemini扩展对话，并通过VADER情感分析和专家评估分析对话的情感进展。生成的对话虽常能反映预期的情感结构，但人类评估揭示了回应中同理心和连贯性的重要差异。这些发现表明，对话中的情感建模不仅需要表达情感的结构对齐，还需深度，凸显了在开发情感智能代理时结合自动化和人工方法的重要性。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [215] [Real-time Image-based Lighting of Glints](https://arxiv.org/abs/2507.02674)
**中文标题：基于图像的实时闪烁光照技术**

*Tom Kneiphof,Reinhard Klein*

主要分类: cs.GR

摘要简述: 本文提出了一种高效的实时图像光照方法，用于模拟材料表面的闪烁效果，通过动态材质属性和环境贴图实现快速渲染。


<details>
  <summary>详细信息</summary>
研究动机: 在实时渲染中，模拟材料表面的闪烁效果（如微面散射）是一个挑战。现有方法难以在动态光照条件下高效实现，因此需要一种新的近似方法。

研究方法: 该方法基于实时区域光照下的闪烁渲染，利用标准环境贴图滤波技术，将环境贴图划分为少量均匀区域，并通过正态分布函数计算微面反射概率。采用双门控高斯近似技术进行分层采样。

研究结果: 实验表明，该方法在多种材质和光照条件下接近真实渲染效果，性能稳定且开销低，仅需两倍内存存储预滤波环境贴图。

研究结论: 本文提出的方法实现了高效的实时闪烁效果渲染，适用于动态光照和材质属性，为实时图形学提供了实用解决方案。

中文摘要: 图像光照是一种广泛应用于实时渲染的技术，用于在真实光照条件下再现阴影效果。然而，模拟具有闪烁或闪光外观的材料（由表面离散微面散射引起）尤为困难。本文提出了一种高效的图像光照近似方法，支持完全动态的材质属性和环境贴图。我们的新方法基于实时区域光照下的闪烁渲染，并采用标准环境贴图滤波技术。关键之处在于，我们的环境贴图滤波过程足够快，可以逐帧执行。该方法假设环境贴图被划分为少量均匀的恒定辐射区域。通过用正态分布函数滤波对应的指示函数，我们得到微面从每个区域反射光的概率。在着色过程中，这些概率用于通过我们新颖的双门控高斯近似技术分层采样多项式分布。我们验证了该实时近似方法在多种材质和光照条件下接近真实渲染效果，并展示了其稳健稳定的性能，开销仅略高于单方向光源的闪烁渲染。与无闪烁的光滑材质渲染相比，我们的方法需要两倍内存存储预滤波环境贴图。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [216] [DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift](https://arxiv.org/abs/2507.02824)
**中文标题：基于DNN的RIS辅助毫米波MIMO系统中实际相位偏移的预编码设计**

*Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang*

主要分类: eess.SP

摘要简述: 本文研究了基于深度神经网络（DNN）的预编码设计，用于提升毫米波（mmWave）多输入多输出（MIMO）系统在直接通信路径受阻时的吞吐量。通过引入可重构智能表面（RIS）并结合实际相位偏移，DNN显著降低了传统穷举搜索的计算复杂度，同时保持了接近最优的频谱效率。


<details>
  <summary>详细信息</summary>
研究动机: 在毫米波MIMO系统中，直接通信路径可能被阻挡，导致性能下降。传统穷举搜索方法计算复杂且耗时，因此需要一种更高效的方法来优化预编码设计。

研究方法: 本文提出使用DNN替代传统的穷举搜索方法，通过训练DNN快速选择最优码字。同时，结合离散傅里叶变换（DFT）向量和实际相位偏移设计码本，以适应实际RIS系统的需求。

研究结果: 仿真结果表明，DNN在测试阶段即使终端用户与RIS之间的距离发生变化，仍能保持接近最优的频谱效率，显著降低了计算复杂度。

研究结论: DNN在RIS辅助的毫米波MIMO系统中表现出巨大潜力，能够高效优化预编码设计，同时降低计算负担。

中文摘要: 本文研究了在直接通信路径受阻的毫米波多输入多输出（MIMO）系统中，通过引入可重构智能表面（RIS）优化预编码设计以最大化吞吐量。考虑到毫米波的视距（LoS）和多径效应特性，传统的穷举搜索（ES）方法在连续相位偏移下计算复杂且耗时。为降低复杂度，采用离散傅里叶变换（DFT）向量设计码本，并结合实际或理想RIS系统的幅度响应。然而，即使采用离散相位偏移的ES方法，计算量仍然较大且耗时。为此，本文开发了训练好的深度神经网络（DNN）以加速码字选择。仿真结果表明，在测试阶段，即使终端用户与RIS之间的距离发生变化，DNN仍能保持接近最优的频谱效率。这些结果凸显了DNN在推动RIS辅助系统发展中的潜力。

</details>
