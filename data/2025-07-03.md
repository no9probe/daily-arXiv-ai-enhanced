<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 42]
- [cs.CV](#cs.CV) [Total: 88]
- [cs.AI](#cs.AI) [Total: 11]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]
- [cs.IR](#cs.IR) [Total: 7]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 3]
- [math.NA](#math.NA) [Total: 1]
- [eess.IV](#eess.IV) [Total: 11]
- [cs.LG](#cs.LG) [Total: 41]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.ET](#cs.ET) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.HC](#cs.HC) [Total: 5]
- [cs.NE](#cs.NE) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.CY](#cs.CY) [Total: 5]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.CG](#cs.CG) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.RO](#cs.RO) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MALIBU Benchmark: Multi-Agent LLM Implicit Bias Uncovered](https://arxiv.org/abs/2507.01019)
**中文标题：MALIBU基准：多智能体大型语言模型隐含偏见揭示**

*Imran Mirza,Cole Huang,Ishwara Vasista,Rohan Patil,Asli Akalin,Sean O'Brien,Kevin Zhu*

主要分类: cs.CL

摘要简述: MALIBU是一个用于评估多智能体系统中大型语言模型（LLM）隐含偏见的新基准，通过场景化任务和两阶段评分揭示偏见问题，并强调需要更细致的公平策略。


<details>
  <summary>详细信息</summary>
研究动机: 多智能体系统在基于角色的交互中广泛应用，但可能无意中强化大型语言模型的隐含偏见，引发公平性和代表性担忧。MALIBU旨在量化这些偏见并提出改进方向。

研究方法: MALIBU通过场景化任务评估多智能体系统的偏见：第一阶段，标注特定人口统计角色的响应由LLM评分；第二阶段，比较不同角色的响应并选择更优者。

研究结果: 研究发现LLM生成的输出中存在明显偏见，且偏见缓解可能偏向边缘化角色而非真正中立，凸显了多智能体系统中需更细致的检测和公平策略。

研究结论: MALIBU揭示了多智能体系统中隐含偏见的复杂性，强调需要透明、平衡的评估基准和公平策略以确保公平性和代表性。

中文摘要: 多智能体系统由多个AI模型在共享环境中交互组成，越来越多地用于基于角色的交互。然而，若设计不当，这些系统可能强化大型语言模型（LLM）的隐含偏见，引发对公平性和平等代表性的担忧。我们提出MALIBU，一种新颖的基准，用于评估基于LLM的多智能体系统隐含强化社会偏见和刻板印象的程度。MALIBU通过场景化评估检测偏见：AI模型在预定义情境中完成任务，其响应由基于LLM的多智能体评判系统分两阶段评估。第一阶段，评委对标注特定人口统计角色（如性别、种族、宗教）的响应进行四项指标评分；第二阶段，评委比较分配给不同角色的成对响应，评分并选择更优者。我们的研究量化了LLM生成输出中的偏见，揭示偏见缓解可能偏向边缘化角色而非真正中立，强调多智能体系统中需要细致的检测、平衡的公平策略和透明的评估基准。

</details>


### [2] [Event-based evaluation of abstractive news summarization](https://arxiv.org/abs/2507.01160)
**中文标题：基于事件的抽象新闻摘要评估**

*Huiling You,Samia Touileb,Erik Velldal,Lilja Øvrelid*

主要分类: cs.CL

摘要简述: 本文提出了一种基于事件重叠的新闻摘要评估方法，通过比较生成摘要、参考摘要和原文中的事件信息，更深入地评估摘要质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有评估方法主要依赖人工摘要作为黄金标准，通过计算重叠单元或相似性得分，但新闻摘要应聚焦事件信息。本文旨在通过事件重叠评估摘要质量。

研究方法: 提出了一种基于事件重叠的评估方法，利用挪威语数据集（包含事件标注和专家摘要），计算生成摘要、参考摘要和原文之间的事件重叠。

研究结果: 实验表明，该方法能更准确地反映摘要中的事件信息，为评估生成摘要提供了新视角。

研究结论: 基于事件的评估方法能更全面地衡量摘要质量，尤其适用于新闻领域。

中文摘要: 新闻文章的抽象摘要包含其最重要信息的浓缩版本。生成语言模型自动生成的摘要评估主要依赖人工摘要作为黄金标准，通过计算重叠单元或相似性得分。新闻文章报道事件，理想情况下摘要也应如此。本文提出通过计算生成摘要、参考摘要和原文之间的事件重叠来评估摘要质量。我们在一个包含事件标注和专家摘要的挪威语数据集上进行了实验。该方法能更深入地揭示摘要中的事件信息。

</details>


### [3] [Matching and Linking Entries in Historical Swedish Encyclopedias](https://arxiv.org/abs/2507.01170)
**中文标题：瑞典历史百科全书中条目的匹配与链接**

*Simon Börjesson,Erik Ersmark,Pierre Nugues*

主要分类: cs.CL

摘要简述: 本文研究了瑞典19至20世纪的百科全书《Nordisk familjebok》，通过数字化版本匹配和链接条目，分析地理趋势变化，发现从第一版到第二版地理焦点从欧洲转向北美、非洲、亚洲、澳大利亚和北欧。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过分析《Nordisk familjebok》不同版本中条目的变化，揭示瑞典社会在19至20世纪的知识演变，特别是地理趋势的变化及其背后的历史背景。

研究方法: 使用数字化文本，首先将原始文本重新分割为条目，并通过语义句子嵌入匹配第一版和第二版的条目。随后，使用基于Transformer的分类器提取地理条目，并将其链接到Wikidata，以分析地理趋势的变化。

研究结果: 研究发现，从第一版（1876-1899）到第二版（1904-1926），地理焦点从欧洲显著转向北美、非洲、亚洲、澳大利亚和北欧，反映了第一次世界大战和新势力崛起的影响。

研究结论: 研究证实了《Nordisk familjebok》作为知识载体的重要性，其条目变化反映了瑞典社会的地理和历史变迁。代码和数据已在GitHub上公开。

中文摘要: 《Nordisk familjebok》是19至20世纪的瑞典百科全书，由专家团队编写，强调精确性和准确性。该百科全书共有四个主要版本，规模从20卷到38卷不等，对大学、学校、媒体和社会产生了深远影响。随着新版本的发布，条目选择和内容的变化反映了瑞典知识界的演变。
本文使用了《Project Runeberg》的数字化版本，首先将原始文本重新分割为条目，并通过语义句子嵌入匹配第一版和第二版的条目。随后，使用基于Transformer的分类器提取地理条目，并将其链接到Wikidata，以分析地理趋势的变化。
结果显示，从第一版（1876-1899）到第二版（1904-1926），地理焦点从欧洲显著转向北美、非洲、亚洲、澳大利亚和北欧，证实了第一次世界大战和新势力崛起的影响。代码和数据可在GitHub上获取：https://github.com/sibbo/nordisk-familjebok。

</details>


### [4] [MEGA: xLSTM with Multihead Exponential Gated Fusion for Precise Aspect-based Sentiment Analysis](https://arxiv.org/abs/2507.01213)
**中文标题：MEGA：基于多头指数门控融合的xLSTM用于精确的基于方面的情感分析**

*Adamu Lawan,Juhua Pu,Haruna Yunusa,Jawad Muhammad,Muhammad Lawan*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MEGA的新框架，结合双向mLSTM架构和部分翻转反向流（PF-mLSTM），通过多头指数门控融合机制（MECGAF）优化短程依赖捕获，显著提升了基于方面的情感分析（ABSA）的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的ABSA方法在计算效率与高性能之间难以平衡：深度学习模型缺乏全局上下文，Transformer计算资源需求高，而Mamba方法依赖CUDA且局部相关性不足。xLSTM模型在长程依赖建模方面表现优异，但其在ABSA中的潜力尚未被充分挖掘。

研究方法: MEGA框架结合了双向mLSTM架构和部分翻转反向流（PF-mLSTM），通过多头指数门控融合机制（MECGAF）动态融合前向mLSTM输出和PF-mLSTM输出，优化短程依赖捕获的同时保持全局上下文和计算效率。

研究结果: 在三个基准数据集上的实验表明，MEGA在ABSA任务中优于现有最优方法，实现了更高的准确性和效率。

研究结论: MEGA通过创新的架构设计和融合机制，显著提升了ABSA任务的性能，为未来研究提供了新的方向。

中文摘要: 基于方面的情感分析（ABSA）是一项关键的自然语言处理（NLP）任务，旨在从文本中提取方面并确定其相关情感，以实现对用户意见的细粒度分析。现有的ABSA方法难以在计算效率与高性能之间取得平衡：深度学习模型通常缺乏全局上下文，Transformer需要大量计算资源，而基于Mamba的方法面临CUDA依赖和局部相关性减弱的问题。扩展长短期记忆（xLSTM）模型的最新进展，尤其是其在长程依赖建模中的高效性，显著推动了NLP领域的发展。然而，其在ABSA中的潜力尚未被充分挖掘。为此，我们提出了基于多头指数门控融合的xLSTM（MEGA），这是一种新颖的框架，将双向mLSTM架构与前向和部分翻转反向（PF-mLSTM）流相结合。PF-mLSTM通过反向处理初始序列段并保留关键短程模式，增强了局部上下文建模。我们还引入了一种基于mLSTM的多头交叉指数门控融合机制（MECGAF），动态地将前向mLSTM输出作为查询和键，PF-mLSTM输出作为值，优化短程依赖捕获的同时保持全局上下文和效率。在三个基准数据集上的实验结果表明，MEGA在ABSA任务中优于现有最优基线，实现了更高的准确性和效率。

</details>


### [5] [The Medium Is Not the Message: Deconfounding Text Embeddings via Linear Concept Erasure](https://arxiv.org/abs/2507.01234)
**中文标题：媒介并非信息：通过线性概念擦除去混淆文本嵌入**

*Yu Fan,Yang Tian,Shauli Ravfogel,Mrinmaya Sachan,Elliott Ash,Alexander Hoyle*

主要分类: cs.CL

摘要简述: 本文提出了一种通过线性概念擦除方法去混淆文本嵌入的算法，显著减少了文本相似性度量中的偏差，且计算成本极低。


<details>
  <summary>详细信息</summary>
研究动机: 文本嵌入的相似性度量常受到无关属性（如来源或语言）的干扰，影响跨语料库文本的应用效果。本文旨在解决这一问题。

研究方法: 采用线性概念擦除算法，从编码器表示中移除观察到的混淆因素信息。

研究结果: 在所有评估的嵌入变体和任务中，文档相似性和聚类指标均有显著提升，且不影响分布外基准性能。

研究结论: 该方法能有效减少文本嵌入中的偏差，且不损害其他性能，适用于跨语料库应用。

中文摘要: 文本序列之间的嵌入相似性度量不仅受我们关注的内容维度影响，还可能被文本来源或语言等无关属性所干扰。这些文档混淆因素对许多应用（尤其是需要聚合不同语料库文本的应用）造成问题。本文表明，通过一种从编码器表示中移除观察到的混淆因素信息的去偏算法，可以以极低的计算成本显著减少这些偏差。在所有评估的嵌入变体和任务中，文档相似性和聚类指标均有提升——通常效果显著。有趣的是，分布外基准的性能未受影响，表明嵌入质量未受其他损害。

</details>


### [6] [GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant](https://arxiv.org/abs/2507.01259)
**中文标题：GAIus：结合生成式AI与法律条款检索的知识型助手**

*Michał Matak,Jarosław A. Chudziak*

主要分类: cs.CL

摘要简述: 本文介绍了一种结合生成式AI与法律条款检索的知识型助手GAIus，专注于非英语和非中文国家的法律问题解答，并提供了可解释的检索机制，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决大型语言模型在处理非英语和非中文国家法律问题时缺乏准确引用和解释的问题，同时探索法律信息检索的改进方法。

研究方法: 提出GAIus架构，基于波兰民法典的法律条款检索机制，设计了一种更可解释且用户友好的检索方法，并通过法律学徒入学考试的单选问题数据集进行评估。

研究结果: GAIus显著提升了模型性能，将gpt-3.5-turbo-0125的表现提高了419%，并让gpt-4o-mini的准确率从31%提升至86%。

研究结论: GAIus展示了结合生成式AI与法律检索的潜力，为未来研究和实际应用提供了方向。

中文摘要: 本文探讨了大型语言模型在处理非英语和非中文国家法律问题时如何提供准确答案和引用的能力。我们回顾了法律信息检索的历史，分析了判例法与成文法的差异及其对法律任务的影响，并介绍了基于波兰民法典的GAIus架构。该架构提出了一种更可解释、用户友好的检索机制，优于基于嵌入的方法。为评估方法，我们创建了基于波兰法律学徒入学考试单选问题的数据集。实验结果显示，GAIus显著提升了模型性能，将gpt-3.5-turbo-0125的表现提高了419%，并让gpt-4o-mini的准确率从31%提升至86%。最后，我们探讨了未来研究方向和潜在应用。

</details>


### [7] [Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening](https://arxiv.org/abs/2507.01278)
**中文标题：评估大型语言模型在糖尿病视网膜病变和青光眼筛查中的多模态模拟眼科决策能力**

*Cindy Lie Tabuse,David Restepo,Carolina Gracitelli,Fernando Korn Malerbi,Caio Regatieri,Luis Filipe Nakayama*

主要分类: cs.CL

摘要简述: 本研究评估了GPT-4在模拟眼科决策中的能力，特别是在糖尿病视网膜病变（DR）和青光眼筛查中。结果显示，GPT-4在基础任务中表现中等，但在复杂任务中精度不足，不适合临床使用，但可能用于教育或文档工作。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在临床推理中的应用潜力尚未在眼科领域充分探索。本研究旨在评估GPT-4在模拟眼科决策中的能力，尤其是对糖尿病视网膜病变和青光眼的筛查。

研究方法: 研究使用300张标注的眼底图像，通过结构化提示描述每张图像，并添加或不添加患者元数据。GPT-4的任务包括分配ICDR严重程度评分、推荐DR转诊以及估计青光眼的杯盘比。评估指标包括准确性、F1分数和Cohen's kappa。

研究结果: GPT-4在ICDR分类中表现中等（准确率67.5%），在DR转诊任务中表现较好（准确率82.3%），但在青光眼转诊任务中表现较差（准确率约78%）。元数据的加入对结果无显著影响。

研究结论: GPT-4能够从结构化提示中模拟基础眼科决策，但在复杂任务中缺乏精度。虽然不适合临床使用，但可能用于教育、文档或图像标注工作。

中文摘要: 大型语言模型（LLMs）能够基于自然语言提示模拟临床推理，但其在眼科中的应用尚未充分探索。本研究评估了GPT-4解释眼底照片结构化文本描述并模拟糖尿病视网膜病变（DR）和青光眼筛查临床决策的能力，包括添加真实或合成临床元数据的影响。研究采用300张标注的眼底图像进行回顾性诊断验证。GPT-4接收描述每张图像的结构化提示，有或无患者元数据。模型的任务包括分配ICDR严重程度评分、推荐DR转诊以及估计青光眼的杯盘比。性能通过准确性、宏F1和加权F1分数以及Cohen's kappa评估。McNemar检验和变化率分析用于评估元数据的影响。GPT-4在ICDR分类中表现中等（准确率67.5%，宏F1 0.33，加权F1 0.67，kappa 0.25），主要归功于对正常病例的正确识别。在二元DR转诊任务中表现较好（准确率82.3%，F1 0.54，kappa 0.44）。在青光眼转诊任务中表现较差（准确率约78%，F1 <0.04，kappa <0.03）。元数据的加入对结果无显著影响（McNemar p > 0.05），预测结果在不同条件下保持一致。GPT-4能够从结构化提示中模拟基础眼科决策，但在复杂任务中缺乏精度。虽然不适合临床使用，但LLMs可能用于眼科的教育、文档或图像标注工作。

</details>


### [8] [Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization](https://arxiv.org/abs/2507.01281)
**中文标题：重新审视所有证据：通过冲突驱动总结提升可信的检索增强生成**

*Juan Chen,Baolong Bi,Wei Zhang,Jingyan Sui,Xiaofei Zhu,Yuanzhuo Wang,Lingrui Mei,Shenghua Liu*

主要分类: cs.CL

摘要简述: 本文提出CARE-RAG框架，通过冲突驱动的证据整合提升检索增强生成（RAG）的可信度，显著优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 检索增强生成（RAG）系统因内部知识冲突或噪声检索内容导致生成不可靠，需重新审视所有证据以提高可信度。

研究方法: CARE-RAG框架通过参数感知和上下文感知证据提取，结合冲突驱动的小模型总结，优化证据整合并修复评测数据。

研究结果: 实验表明，CARE-RAG在噪声或冲突证据场景下显著优于基线方法，提升了生成可靠性。

研究结论: CARE-RAG通过冲突驱动的证据整合有效提升了RAG系统的可信度，为未来研究提供了新方向。

中文摘要: 检索增强生成（RAG）通过将大语言模型（LLM）的参数知识与外部检索内容结合来增强性能。然而，内部不一致或噪声检索内容导致的知识冲突会严重损害RAG系统的生成可靠性。本文提出，LLM应在生成响应前重新审视所有证据，包括检索内容和内部知识。我们提出CARE-RAG（冲突感知与可靠证据的RAG框架），通过冲突驱动的证据总结提升可信度。CARE-RAG首先通过比较参数记录提取参数感知证据，识别多样化的内部观点；随后优化检索证据生成上下文感知证据，去除无关或误导内容。为检测并总结冲突，我们蒸馏了一个3B参数的LLaMA3.2模型进行冲突驱动总结，实现多源可靠合成。为进一步确保评测完整性，我们引入QA修复步骤以修正过时或模糊的基准答案。在包含检索数据的修订QA数据集上的实验表明，CARE-RAG在噪声或冲突证据场景下始终优于强基线方法。

</details>


### [9] [Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks](https://arxiv.org/abs/2507.01297)
**中文标题：令人沮丧的简单检索显著提升了复杂推理基准测试的性能**

*Xinxi Lyu,Michael Duan,Rulin Shao,Pang Wei Koh,Sewon Min*

主要分类: cs.CL

摘要简述: 本文提出了一种简单但高效的检索增强生成（RAG）方法，通过引入CompactDS——一个高质量、多样化的网络规模数据存储，显著提升了在复杂推理基准测试中的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的检索增强生成（RAG）方法在复杂推理任务中表现有限，主要因为缺乏与预训练数据广度对齐的高质量数据存储。本文旨在解决这一问题，并验证简单RAG方法在复杂任务中的潜力。

研究方法: 作者设计了CompactDS，一个紧凑且高质量的网络规模数据存储，结合内存近似最近邻（ANN）检索和磁盘精确搜索，以平衡速度和召回率。该方法通过过滤冗余内容，保留高覆盖率的子集。

研究结果: 实验表明，使用CompactDS的简单RAG方法在多个推理基准测试（MMLU、MMLU Pro、GPQA、MATH）中均取得显著提升，相对增益达10%-33%。同时，CompactDS性能优于谷歌搜索和复杂代理RAG系统。

研究结论: CompactDS证明了简单RAG方法在复杂推理任务中的有效性，强调了数据源多样性的重要性，并为未来检索式AI系统研究提供了开源支持。

中文摘要: 检索增强生成（RAG）主要在有限场景（如事实性问答）中研究，而在复杂推理基准测试中表现不佳。本文挑战了这一观点，指出先前工作的关键缺失：一个与预训练数据广度对齐的网络规模数据存储。为此，我们提出CompactDS：一个多样化、高质量的网络规模数据存储，在单节点上实现高检索精度和亚秒级延迟。核心发现是：(1) 过滤大部分网络内容不会牺牲覆盖率，紧凑的高质量子集已足够；(2) 结合内存近似最近邻（ANN）检索和磁盘精确搜索可平衡速度与召回率。使用CompactDS，简单RAG管道在所有基准测试和模型规模（8B-70B）中均实现一致性能提升，相对增益为MMLU 10%、MMLU Pro 33%、GPQA 14%、MATH 19%。单一数据源无法满足需求，凸显了数据源多样性（网络爬取、数学资料、学术论文、教科书）的重要性。最后，我们展示精心设计的内部数据存储性能匹配或超越谷歌搜索及近期复杂代理RAG系统，同时保持简单性、可复现性和自包含性。我们开源CompactDS及检索管道，支持未来检索式AI系统的研究。

</details>


### [10] [La RoSA: Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation](https://arxiv.org/abs/2507.01299)
**中文标题：LaRoSA：通过层间旋转稀疏激活提升大语言模型效率**

*Kai Liu,Bowen Xu,Shaoyu Wu,Xin Chen,Hao Zhou,Yongliang Tao,Lulu Hu*

主要分类: cs.CL

摘要简述: LaRoSA通过层间旋转稀疏激活技术，无需额外训练或基于幅度的剪枝，显著提升大语言模型的效率和推理速度，同时保持性能稳定。


<details>
  <summary>详细信息</summary>
研究动机: 现有激活稀疏化方法存在训练耗时长或依赖经验性剪枝的问题，导致稀疏性波动和推理速度不稳定。LaRoSA旨在解决这些问题，提供一种高效且稳定的稀疏化方案。

研究方法: LaRoSA采用层间正交旋转技术，将输入激活转换为更适合稀疏化的旋转形式，并通过Top-K选择实现模型级稀疏性和稳定的推理加速。

研究结果: 在LLaMA2-7B模型上，LaRoSA在40%稀疏度下仅产生0.17的困惑度差距，推理速度提升1.30倍，零样本任务准确率差距缩小至0.54%，优于TEAL和CATS方法。

研究结论: LaRoSA是一种高效且无需额外训练的激活稀疏化方法，适用于多种大语言模型，显著提升推理速度且性能损失极小。

中文摘要: 激活稀疏化可以减少大语言模型（LLM）推理过程中的计算开销和内存传输。现有方法存在局限性，要么需要耗时的恢复训练，阻碍实际应用；要么依赖基于幅度的经验性剪枝，导致稀疏性波动和推理速度不稳定。本文提出LaRoSA（层间旋转稀疏激活），一种无需额外训练或基于幅度剪枝的新型激活稀疏化方法。我们利用层间正交旋转将输入激活转换为更适合稀疏化的旋转形式，并通过Top-K选择在旋转激活中实现一致的模型级稀疏性和可靠的实时加速。LaRoSA适用于各种规模和类型的LLM，表现出极小的性能下降和稳健的推理加速。具体而言，在LLaMA2-7B模型上，40%稀疏度下LaRoSA仅产生0.17的困惑度差距，推理速度提升1.30倍，零样本任务准确率差距缩小至0.54%，同时优于TEAL和CATS方法。

</details>


### [11] [Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs](https://arxiv.org/abs/2507.01334)
**中文标题：符号还是数值？理解推理型大型语言模型中的物理问题解决**

*Nifu Dan,Yujun Cai,Yiwei Wang*

主要分类: cs.CL

摘要简述: 本研究探讨了大型语言模型（LLMs）在解决复杂物理问题时的表现，发现指令调优的推理模型（如Deepseek-R1）在SciBench基准测试中表现出色，不仅能达到最高准确率，还能生成独特的符号推导推理模式。


<details>
  <summary>详细信息</summary>
研究动机: 物理推理对LLMs来说一直是一个挑战，需要结合深刻的概念理解和熟练的问题解决技巧。本研究旨在探索先进指令调优推理模型在解决多样化物理问题中的表现。

研究方法: 研究使用了Deepseek-R1等指令调优推理模型，针对SciBench基准测试中的物理问题进行了全面实验评估，并分析了模型的推理模式。

研究结果: 实验结果显示，推理模型在复杂物理问题中达到了最先进的准确率，并表现出独特的符号推导推理模式。此外，少量提示策略还能进一步提升模型的整体准确率。

研究结论: 研究表明，指令调优推理模型在物理问题解决中具有显著潜力，尤其是通过符号推导和少量提示策略的结合，可以进一步提升性能。

中文摘要: 长期以来，物理推理的复杂性一直是大型语言模型（LLMs）面临的难题，需要结合深刻的概念理解和熟练的问题解决技巧。本研究探讨了先进的指令调优推理模型（如Deepseek-R1）在解决来自具有挑战性的SciBench基准测试的多样化物理问题中的应用。全面的实验评估揭示了推理模型的卓越能力：它们不仅在回答复杂物理问题时达到了最先进的准确率，还生成了以符号推导为特色的独特推理模式。此外，研究发现，即使对于这些高度复杂的推理模型，策略性地结合少量提示仍能显著提升整体准确率，显示出持续性能提升的潜力。

</details>


### [12] [LEDOM: An Open and Fundamental Reverse Language Model](https://arxiv.org/abs/2507.01335)
**中文标题：LEDOM：一种开放且基础的逆向语言模型**

*Xunjian Yin,Sitao Cheng,Yuxi Xie,Xinyu Hu,Li Lin,Xinyi Wang,Liangming Pan,William Yang Wang,Xiaojun Wan*

主要分类: cs.CL

摘要简述: LEDOM是首个纯逆向语言模型，通过逆向时序处理序列，并展示了在通用任务中的潜力。其独特的逆向推理能力在数学推理任务中显著提升了生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索逆向语言模型作为基础模型的潜力，填补现有语言模型在逆向推理能力上的空白，并验证其在通用任务中的应用价值。

研究方法: LEDOM通过逆向时序的自回归训练，处理435B标记的数据，提供2B和7B参数版本。进一步提出“逆向奖励”应用，通过逆向模型对正向模型输出进行重排序。

研究结果: LEDOM在数学推理任务中通过逆向奖励显著提升了性能，展示了其独特的逆向推理能力和广泛的应用潜力。

研究结论: LEDOM作为首个逆向语言模型，展现了独特的逆向推理能力，并在数学推理任务中验证了其应用价值。未来将公开模型、代码和预训练数据以促进研究。

中文摘要: 我们介绍了LEDOM，首个纯逆向语言模型，通过逆向时序的自回归训练处理435B标记，提供2B和7B参数版本。首次将逆向语言模型作为通用任务的基础模型，并展示了一系列有趣的示例和见解。基于LEDOM，我们进一步提出了一种新应用：逆向奖励，通过LEDOM对正向语言模型输出进行重排序，显著提升了数学推理任务的性能。该方法利用LEDOM独特的逆向推理能力，通过后验评估优化生成质量。研究发现LEDOM具有独特的特性与广泛的应用潜力。我们将公开所有模型、训练代码和预训练数据以推动未来研究。

</details>


### [13] [Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy](https://arxiv.org/abs/2507.01352)
**中文标题：Skywork-Reward-V2：通过人机协同扩展偏好数据标注**

*Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou*

主要分类: cs.CL

摘要简述: Skywork-Reward-V2通过人机协同的大规模偏好数据标注，显著提升了奖励模型的性能，在多个基准测试中达到领先水平。


<details>
  <summary>详细信息</summary>
研究动机: 现有奖励模型在捕捉人类复杂偏好方面表现不佳，主要源于偏好数据集的质量和范围有限。本研究旨在通过高质量的大规模数据和人机协同方法解决这一问题。

研究方法: 提出SynPref-40M数据集，包含4000万偏好对；设计人机协同的两阶段标注流程，结合人类标注质量与AI扩展性；训练了8个不同规模的奖励模型（0.6B至8B参数）。

研究结果: Skywork-Reward-V2在7个主要奖励模型基准测试中表现优异，涵盖人类偏好对齐、安全性、抗风格偏见等多方面能力。

研究结论: 研究表明，高质量数据和人机协同标注是提升奖励模型性能的关键，Skywork-Reward-V2系列为开放奖励模型的发展提供了重要参考。

中文摘要: 尽管奖励模型（RMs）在基于人类反馈的强化学习（RLHF）中至关重要，但目前最先进的开放RMs在大多数现有评估基准上表现不佳，未能捕捉到人类复杂偏好的多样性。即使采用先进训练技术的方法也未带来显著性能提升。我们假设这种脆弱性主要源于偏好数据集的局限性，这些数据集通常范围狭窄、标注合成或缺乏严格的质量控制。为解决这些问题，我们提出了一个包含4000万偏好对的大规模偏好数据集SynPref-40M。为实现大规模数据标注，我们设计了一种人机协同的两阶段流程，结合人类标注质量与AI扩展性的互补优势。在这一流程中，人类提供已验证的标注，而大型语言模型基于人类指导进行自动标注。基于这一混合偏好数据，我们推出了Skywork-Reward-V2，这是一套包含8个奖励模型的系列，参数规模从0.6B到8B不等，训练数据为SynPref-40M中精心筛选的2600万偏好对。我们证明Skywork-Reward-V2在多种能力上表现优异，包括与人类偏好对齐、客观正确性、安全性、抗风格偏见和最佳N扩展性，在7个主要奖励模型基准测试中达到领先水平。消融研究证实，我们方法的有效性不仅源于数据规模，还源于高质量的标注。Skywork-Reward-V2系列代表了开放奖励模型的重大进展，揭示了现有偏好数据集的未开发潜力，并展示了人机协同标注如何显著提升数据质量。

</details>


### [14] [Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction](https://arxiv.org/abs/2507.01437)
**中文标题：基于注意力深度学习的临床自然语言处理用于多疾病预测**

*Ting Xu,Xiaoxiao Deng,Xiandong Meng,Haifeng Yang,Yan Wu*

主要分类: cs.CL

摘要简述: 本文提出了一种基于注意力机制的深度学习方法，用于处理电子健康记录文本的高维语义复杂性，实现信息提取和多标签疾病预测的统一建模。在MIMIC-IV数据集上的实验表明，该方法在多项性能指标上优于现有方法，并具有较强的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 电子健康记录文本的非结构化和高维语义复杂性给信息提取和疾病预测带来了挑战。本文旨在通过注意力机制解决这些问题，提升临床文本处理的效率和准确性。

研究方法: 采用基于Transformer的架构进行临床文本表示学习，利用多层自注意力机制捕捉关键医学实体及其上下文关系，并结合Sigmoid多标签分类器预测疾病标签。模型还引入了上下文感知的语义对齐机制，以增强在标签共现和信息稀疏等典型医疗场景中的表现能力。

研究结果: 实验结果表明，该方法在多项性能指标上优于现有方法，并在不同数据规模、干扰水平和模型深度配置下表现出较强的泛化能力。

研究结论: 本研究提出的框架为处理真实世界临床文本提供了高效的算法基础，对多标签医学文本建模任务具有实际意义。

中文摘要: 本文针对电子健康记录文本的非结构化和高维语义复杂性带来的挑战，提出了一种基于注意力机制的深度学习方法，以实现信息提取和多标签疾病预测的统一建模。研究基于MIMIC-IV数据集，采用Transformer架构进行临床文本表示学习，利用多层自注意力机制捕捉关键医学实体及其上下文关系，并应用Sigmoid多标签分类器预测疾病标签。模型还引入了上下文感知的语义对齐机制，增强了在标签共现和信息稀疏等典型医疗场景中的表示能力。为全面评估模型性能，研究进行了一系列实验，包括基线比较、超参数敏感性分析、数据扰动研究和噪声注入测试。结果表明，所提方法在多项性能指标上均优于现有代表性方法，并在不同数据规模、干扰水平和模型深度配置下保持较强的泛化能力。本研究开发的框架为处理真实世界临床文本提供了高效的算法基础，对多标签医学文本建模任务具有实际意义。

</details>


### [15] [LogitSpec: Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation](https://arxiv.org/abs/2507.01449)
**中文标题：LogitSpec：通过下一个下一个token推测加速基于检索的推测解码**

*Tianyu Liu,Qitan Lv,Hao Li,Xing Gao,Xiao Sun*

主要分类: cs.CL

摘要简述: LogitSpec是一种无需训练、即插即用的方法，通过利用最后一个token的logit预测下一个和下一个token，扩展检索范围，显著提升检索式推测解码的效率，实现最高2.61倍加速。


<details>
  <summary>详细信息</summary>
研究动机: 当前检索式推测解码方法依赖匹配范式检索相关参考token，但往往难以找到准确匹配的token。LogitSpec旨在通过扩展检索范围，提升推测解码的准确性和效率。

研究方法: LogitSpec分两步生成推测token：(1) 利用最后一个token的logit预测下一个和下一个token；(2) 检索与这两个token相关的参考内容。该方法无需训练，可直接集成到现有LLM推理框架中。

研究结果: 实验表明，LogitSpec在多种文本生成任务中实现了最高2.61倍的加速，平均每个解码步骤接受3.28个token。

研究结论: LogitSpec通过扩展检索范围和优化推测解码流程，显著提升了检索式推测解码的性能和效率，为LLM推理加速提供了实用解决方案。

中文摘要: 推测解码（SD）是一种通过小型草稿模型提前生成token并由目标模型并行验证的技术，已成为加速大型语言模型（LLM）推理的有前景方法。许多改进SD的努力旨在消除草稿模型的需求，转而以检索方式生成草稿token，从而进一步减少草拟开销并降低部署和应用的难度。然而，基于检索的SD依赖匹配范式检索最相关的参考作为草稿token，这些方法往往难以找到匹配且准确的token。为解决这一问题，我们提出LogitSpec，通过有效扩展检索范围并找到最相关的参考作为草稿。LogitSpec的灵感来源于观察到最后一个token的logit不仅可以预测下一个token，还能推测下一个下一个token。具体而言，LogitSpec分两步生成草稿token：(1) 利用最后一个logit推测下一个下一个token；(2) 检索与下一个token和下一个下一个token相关的参考内容。LogitSpec无需训练且即插即用，可轻松集成到现有LLM推理框架中。在广泛的文本生成基准测试中，LogitSpec实现了最高2.61倍的加速和每个解码步骤平均接受3.28个token的效果。代码已开源：https://github.com/smart-lty/LogitSpec。

</details>


### [16] [Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities](https://arxiv.org/abs/2507.01479)
**中文标题：评估直接偏好优化在个性化德语自动文本简化中对智障人士的有效性**

*Yingqiang Gao,Kaede Johnson,David Froehlich,Luisa Carrer,Sarah Ebling*

主要分类: cs.CL

摘要简述: 本文通过直接偏好优化（DPO）技术，结合智障人士的反馈，优化了基于大型语言模型（LLM）的自动文本简化（ATS）系统，提升了文本简化的个性化效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于LLM的ATS系统在训练过程中未纳入用户偏好反馈，导致生成的简化文本缺乏个性化，无法满足智障人士的具体需求。

研究方法: 研究扩展了标准的监督微调（SFT）方法，采用DPO技术对LLM进行后训练，结合智障人士对简化文本的偏好反馈，并提出了一个开发个性化ATS系统的完整流程。

研究结果: 结果表明，结合目标群体反馈的DPO技术显著提升了ATS系统的个性化效果，强调了目标群体参与设计个性化AI辅助工具的重要性。

研究结论: 本研究为个性化包容性AI系统的开发提供了方向，不仅依赖专家意见，还需直接纳入目标群体的反馈。

中文摘要: 自动文本简化（ATS）旨在提升语言可访问性，特别是针对智障人士。近年来，生成式AI尤其是大型语言模型（LLM）显著提升了机器生成简化文本的质量，从而缓解了目标群体的信息障碍。然而，现有的基于LLM的ATS系统在训练过程中未纳入对简化文本的偏好反馈，导致缺乏针对目标群体具体需求的个性化定制。本研究扩展了标准的监督微调（SFT）方法，采用一种计算高效的LLM对齐技术——直接偏好优化（DPO），通过收集智障人士对主流LLM生成的简化文本对的偏好反馈，对LLM进行后训练。此外，我们提出了一套开发个性化LLM-based ATS系统的流程，涵盖数据收集、模型选择、SFT和DPO后训练及评估。研究结果强调了目标群体积极参与设计符合人类期望的个性化AI辅助解决方案的必要性。这项工作为在目标群体层面个性化包容性AI系统迈出了一步，不仅纳入了文本简化专家的见解，还直接结合了目标群体人士的反馈。

</details>


### [17] [Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing](https://arxiv.org/abs/2507.01541)
**中文标题：基于不确定性驱动的大语言模型路由的高效对话系统超出范围检测**

*Álvaro Zaera,Diana Nicoleta Popa,Ivan Sekulic,Paolo Rosso*

主要分类: cs.CL

摘要简述: 本文提出了一种结合不确定性建模与微调大语言模型（LLM）的模块化框架，用于高效准确地检测任务导向对话系统中的超出范围（OOS）意图。该方法通过不确定性估计和LLM触发决策，在计算效率和性能之间取得了平衡，并在实际应用中取得了优异效果。


<details>
  <summary>详细信息</summary>
研究动机: 任务导向对话系统（TODS）在处理用户查询时，常遇到超出范围（OOS）意图的挑战。现有方法在效率和准确性上难以兼顾，因此需要一种既能高效处理大规模交互，又能准确识别OOS意图的解决方案。

研究方法: 本文方法分为两步：首先对已部署的意图分类器输出进行不确定性估计，标记高不确定性实例；然后触发微调的LLM对这些实例进行最终决策。这种方法结合了传统分类器和LLM的优势。

研究结果: 该方法在多个OOS检测基准测试中取得了最优结果，包括从实际部署的TODS中获取的真实OOS数据，显著提升了检测效率和准确性。

研究结论: 本文提出的框架通过不确定性建模和LLM路由，实现了OOS意图检测的高效与准确，为任务导向对话系统的鲁棒性提供了实用解决方案。

中文摘要: 超出范围（OOS）意图检测是任务导向对话系统（TODS）中的关键挑战，它确保了对未见和模糊查询的鲁棒性。本文提出了一种新颖而简单的模块化框架，将不确定性建模与微调的大语言模型（LLM）相结合，以实现高效且准确的OOS检测。第一步对当前部署的意图分类器输出进行不确定性估计，该系统每天处理数万次用户交互。第二步则利用新兴的基于LLM的方法，触发微调的LLM对高不确定性实例做出最终决策。与现有方法不同，我们的方法在计算效率和性能之间取得了有效平衡，结合了传统方法与LLM，并在关键OOS检测基准（包括从实际部署的TODS中获取的真实OOS数据）上取得了最优结果。

</details>


### [18] [Is External Information Useful for Stance Detection with LLMs?](https://arxiv.org/abs/2507.01543)
**中文标题：外部信息对基于大型语言模型的立场检测是否有用？**

*Quang Minh Nguyen,Taegyoon Kim*

主要分类: cs.CL

摘要简述: 研究发现，在立场检测任务中，外部信息（如维基百科或网络搜索内容）对大型语言模型（LLMs）的性能产生负面影响，导致F1分数下降高达27.9%。LLMs倾向于根据外部信息的立场和情感进行预测，而非文本的真实立场。


<details>
  <summary>详细信息</summary>
研究动机: 先前研究表明，外部信息（如维基百科）能提升立场检测性能，但尚未验证其对大型语言模型（LLMs）的影响。本研究旨在系统评估外部信息对LLMs在立场检测任务中的作用。

研究方法: 研究在三个数据集和12个目标上，对八种LLMs进行了系统评估，测试维基百科和网络搜索内容对其立场检测性能的影响。同时探讨了思维链提示和微调对性能的影响。

研究结果: 外部信息在多数情况下降低了LLMs的立场检测性能，F1分数最大下降27.9%。LLMs倾向于根据外部信息的立场和情感进行预测，而非文本的真实立场。思维链提示未能改善性能，微调仅部分缓解问题。

研究结论: 与基于BERT的系统不同，外部信息对LLMs的立场检测性能产生负面影响，凸显了LLM立场分类器中信息偏见的风险。

中文摘要: 在立场检测任务中，文本被分类为对目标的支持、反对或中立。先前研究表明，使用外部信息（如维基百科摘录）可提升立场检测性能。然而，尽管大型语言模型（LLMs）在许多推理任务中广泛应用，此类信息是否对其有益仍是一个未解问题。本研究通过系统评估，探讨了维基百科和网络搜索内容对八种LLMs在三个数据集和12个目标上的立场检测性能的影响。出乎意料的是，此类信息在多数情况下降低了性能，宏观F1分数最大下降27.9%。通过实验发现，LLMs倾向于根据所提供信息的立场和情感进行预测，而非文本的真实立场。此外，思维链提示未能改善性能，而微调仅部分缓解问题。与基于BERT系统的研究结果相反，本研究揭示了LLM立场分类器中信息偏见的风险。代码发布于https://github.com/ngqm/acl2025-stance-detection。

</details>


### [19] [Emotionally Intelligent Task-oriented Dialogue Systems: Architecture, Representation, and Optimisation](https://arxiv.org/abs/2507.01594)
**中文标题：情感智能任务导向对话系统：架构、表示与优化**

*Shutong Feng,Hsien-chin Lin,Nurul Lubis,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Renato Vukovic,Milica Gašić*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大语言模型（LLM）的任务导向对话系统LUSTER，结合短期（用户情感）和长期（任务成功）奖励的端到端强化学习，提升了系统的情感智能和任务完成能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在语言流畅性和上下文理解方面取得了显著进展，但构建具有情感智能的任务导向对话系统仍面临复杂挑战。系统需在嘈杂和模糊的对话环境中同时优化任务成功、情感理解和信息传递。

研究方法: 本文研究了任务导向对话系统的架构、表示、优化及情感因素，提出了LUSTER系统，结合LLM能力和结构化奖励模型，通过端到端强化学习优化短期和长期奖励。

研究结果: 实验表明，结合LLM能力和结构化奖励建模的任务导向对话系统更具韧性和情感响应能力，为下一代对话代理提供了实用路径。

研究结论: LUSTER系统通过结合LLM和强化学习，显著提升了任务导向对话系统的情感智能和任务完成能力，为未来研究提供了方向。

中文摘要: 任务导向对话（ToD）系统旨在通过自然语言交互帮助用户实现特定目标。尽管大语言模型（LLMs）的进展显著提升了语言流畅性和上下文理解能力，但构建高效且情感智能的ToD系统仍是一项复杂挑战。有效的ToD系统需在嘈杂且模糊的对话环境中优化任务成功、情感理解与响应能力以及信息传递的精确性。本文研究了ToD系统的架构、表示、优化及情感因素，并设计了一个包含自然语言用户模拟器和不完美自然语言理解模块的评估环境。我们提出了LUSTER系统，一种基于LLM的统一任务导向对话系统，通过端到端强化学习结合短期（用户情感）和长期（任务成功）奖励。结果表明，将LLM能力与结构化奖励建模相结合，能够构建更具韧性和情感响应能力的ToD系统，为下一代对话代理提供了实用路径。

</details>


### [20] [Chart Question Answering from Real-World Analytical Narratives](https://arxiv.org/abs/2507.01627)
**中文标题：真实世界分析叙事中的图表问答**

*Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha*

主要分类: cs.CL

摘要简述: 本文提出一个基于可视化笔记本构建的新图表问答数据集，特点是真实世界多视图图表与自然语言问题配对，反映生态有效的推理流程。测试显示现有模型性能存在显著差距。


<details>
  <summary>详细信息</summary>
研究动机: 现有图表问答数据集缺乏真实世界的多视图图表和自然语言问题的配对，无法反映实际分析中的推理流程。本文旨在填补这一空白。

研究方法: 通过可视化笔记本构建数据集，包含真实世界的多视图图表和自然语言问题，测试多模态大语言模型的性能。

研究结果: 测试结果显示，GPT-4.1的准确率为69.3%，表明现有模型在这一更真实的图表问答场景中面临挑战。

研究结论: 本文提出的数据集更贴近实际分析场景，揭示了现有模型在真实图表问答任务中的性能不足。

中文摘要: 我们提出了一个基于可视化笔记本构建的新图表问答（CQA）数据集。该数据集以真实世界的多视图图表为特色，并与自然语言问题配对，这些问题基于分析叙事。与之前的基准不同，我们的数据反映了生态有效的推理流程。对最先进的多模态大语言模型进行基准测试显示，性能存在显著差距，GPT-4.1的准确率为69.3%，突显了这一更真实的CQA场景带来的挑战。

</details>


### [21] [Confidence and Stability of Global and Pairwise Scores in NLP Evaluation](https://arxiv.org/abs/2507.01633)
**中文标题：NLP评估中全局分数与成对比较的置信度与稳定性**

*Georgii Levtsov,Dmitry Ustalov*

主要分类: cs.CL

摘要简述: 本文通过实证研究比较了自然语言处理（NLP）评估中的全局分数和成对比较方法的优缺点，发现全局分数更可靠但可能低估强模型，而成对比较在识别低分强模型时更有效。


<details>
  <summary>详细信息</summary>
研究动机: 随着高性能指令调优神经语言模型的出现，NLP评估逐渐从传统的全局分数（如GLUE、BIG-bench）转向成对比较排行榜（如LMSYS Arena）。本文旨在通过实证研究帮助选择更合适的模型评估策略。

研究方法: 在合成和真实数据集上，使用标准全局指标和Bradley-Terry模型进行成对比较实验，分析两种方法的性能。

研究结果: 全局分数提供更可靠的总体排名，但可能低估有罕见显著错误或低置信度的强模型；成对比较能有效识别低分强模型，但在频繁平局时需要更多比较才能收敛。

研究结论: 全局分数和成对比较各有优劣，选择评估策略需根据具体需求：全局分数适合总体排名，成对比较适合识别特定强模型。

中文摘要: 随着高性能指令调优神经语言模型的出现，自然语言处理（NLP）的评估逐渐从传统的全局分数（如GLUE、BIG-bench、SWE-bench）转向成对比较排行榜（如LMSYS Arena）。本文通过实证研究比较了全局分数和成对比较的优缺点，以帮助选择合适的模型评估策略。在合成和真实数据集上，使用标准全局指标和流行的Bradley-Terry模型进行成对比较实验，我们发现：全局分数能提供更可靠的总体排名，但可能低估具有罕见显著错误或低置信度的强模型；而成对比较特别适合识别全局分数较低但表现优异的模型，尤其是在难以定义质量指标的任务（如文本生成）中，但若平局频繁，则需要更多比较才能收敛。代码和数据可在https://github.com/HSPyroblast/srw-ranking获取，使用宽松许可证。

</details>


### [22] [Adapting Language Models to Indonesian Local Languages: An Empirical Study of Language Transferability on Zero-Shot Settings](https://arxiv.org/abs/2507.01645)
**中文标题：适应语言模型到印尼本地语言：零样本设置下语言迁移性的实证研究**

*Rifki Afina Putri*

主要分类: cs.CL

摘要简述: 本文研究了预训练语言模型在零样本设置下对印尼低资源本地语言的迁移能力，通过情感分析任务评估了不同模型的性能，发现多语言模型在已见语言上表现最佳，而MAD-X适配器方法显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索预训练语言模型对印尼低资源本地语言的迁移能力，尤其是在零样本设置下，以解决这些语言因数据稀缺而难以直接训练的问题。

研究方法: 方法包括使用单语印尼BERT、多语言模型（如mBERT和XLM-R）以及模块化适配器方法MAD-X，对十种本地语言进行零样本和适配器迁移评估，并将目标语言分为已见、部分已见和未见三类。

研究结果: 结果显示多语言模型在已见语言上表现最佳，部分已见语言次之，未见语言表现最差；MAD-X显著提升了已见和部分已见语言的性能，且无需目标语言标注数据。此外，分词分析表明模型对语言的先验接触是迁移成功的最一致预测因素。

研究结论: 结论表明预训练语言模型对印尼本地语言的迁移能力依赖于其先验接触的语言数据，MAD-X方法为低资源语言提供了有效的迁移解决方案。

中文摘要: 本文研究了预训练语言模型在零样本设置下对印尼低资源本地语言的迁移能力，通过情感分析任务评估了单语印尼BERT、多语言模型（如mBERT和XLM-R）以及模块化适配器方法MAD-X的性能。目标语言分为已见（预训练中包含）、部分已见（未包含但与已见语言相关）和未见（未包含且无关）三类。结果显示多语言模型在已见语言上表现最佳，部分已见语言次之，未见语言表现最差。MAD-X显著提升了已见和部分已见语言的性能，且无需目标语言标注数据。进一步的分词分析表明，子词分割和词汇重叠与预测质量相关性较弱，而模型对语言的先验接触是迁移成功的最一致预测因素。

</details>


### [23] [AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness](https://arxiv.org/abs/2507.01702)
**中文标题：AdamMeme：自适应探测多模态大语言模型对有害模因的推理能力**

*Zixin Chen,Hongzhan Lin,Kaixin Li,Ziyang Luo,Zhen Ye,Guang Chen,Zhiyong Huang,Jing Ma*

主要分类: cs.CL

摘要简述: 本文提出AdamMeme，一种基于多智能体的自适应评估框架，用于动态测试多模态大语言模型（mLLMs）对有害模因的理解能力，揭示其局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有评估方法依赖静态数据集，无法动态适应模因的快速演变，难以全面评估mLLMs对有害模因的理解能力。

研究方法: 通过多智能体协作，AdamMeme动态更新模因数据，迭代测试mLLMs的推理能力，暴露其理解有害模因的弱点。

研究结果: 实验表明，AdamMeme能系统揭示不同mLLMs的性能差异，并提供细粒度的模型弱点分析。

研究结论: AdamMeme为动态评估mLLMs对有害模因的理解提供了灵活且全面的框架，填补了现有评估方法的不足。

中文摘要: 社交媒体时代多模态模因的泛滥要求多模态大语言模型（mLLMs）有效理解模因的有害性。现有评估mLLMs对有害模因理解的基准依赖基于准确率的静态数据集评估，无法提供动态且全面的测试。为此，我们提出AdamMeme，一种灵活的基于智能体的评估框架，自适应探测mLLMs在解析模因有害性时的推理能力。通过多智能体协作，AdamMeme通过迭代更新具有挑战性的模因数据，全面评估mLLMs，揭示其在理解有害性时的具体局限。大量实验表明，我们的框架能系统揭示不同目标mLLMs的性能差异，并提供深入的细粒度模型弱点分析。代码发布于https://github.com/Lbotirx/AdamMeme。

</details>


### [24] [Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach](https://arxiv.org/abs/2507.01715)
**中文标题：刻板印象检测作为增强偏见检测的催化剂：一种多任务学习方法**

*Aditya Tomar,Rudra Murthy,Pushpak Bhattacharyya*

主要分类: cs.CL

摘要简述: 本文提出了一种多任务学习方法，通过联合学习偏见和刻板印象检测任务，显著提升了模型性能。实验表明，联合训练优于单独训练，且刻板印象信息有助于构建更公平的AI系统。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型中的偏见和刻板印象可能对敏感领域（如内容审核和决策）造成危害。本文旨在通过联合学习偏见和刻板印象检测任务，探索如何提升模型性能，从而减少这些危害。

研究方法: 作者引入了StereoBias数据集，标注了五个类别的偏见和刻板印象（宗教、性别、社会经济地位、种族、职业等）。实验比较了仅编码器模型和使用QLoRA微调的仅解码器模型，并验证了联合训练的效果。

研究结果: 实验结果显示，联合训练显著提升了偏见检测的性能，且仅解码器模型表现也具有竞争力。进一步的实验表明，这种提升源于偏见与刻板印象之间的关联，而非多任务学习本身。

研究结论: 研究表明，利用刻板印象信息可以有效提升偏见检测能力，为构建更公平和高效的AI系统提供了新思路。

中文摘要: 语言模型中的偏见和刻板印象可能对敏感领域（如内容审核和决策）造成危害。本文通过联合学习这些任务来探索如何提升模型性能。我们引入了StereoBias数据集，标注了五个类别的偏见和刻板印象（宗教、性别、社会经济地位、种族、职业等），以便深入研究它们之间的关系。实验比较了仅编码器模型和使用QLoRA微调的仅解码器模型。结果显示，仅编码器模型表现良好，而仅解码器模型也展现出竞争力。重要的是，联合训练偏见和刻板印象检测显著提升了偏见检测性能。进一步的实验表明，这种提升源于偏见与刻板印象之间的关联，而非多任务学习本身。这些发现凸显了利用刻板印象信息构建更公平和高效AI系统的重要性。

</details>


### [25] [LLMs for Legal Subsumption in German Employment Contracts](https://arxiv.org/abs/2507.01734)
**中文标题：大型语言模型在德国雇佣合同法律条款分类中的应用**

*Oliver Wardas,Florian Matthes*

主要分类: cs.CL

摘要简述: 本文探讨了大型语言模型（LLMs）在德国雇佣合同法律条款分类中的应用，发现法律背景信息（尤其是简化的审查指南）能显著提升模型性能，但其表现仍远低于人类律师。


<details>
  <summary>详细信息</summary>
研究动机: 法律工作文本密集且资源消耗大，现有数据驱动方法缺乏可解释性和可信度，限制了其在动态法律环境中的应用。为此，研究探索了LLMs在法律条款分类中的潜力。

研究方法: 研究扩展了现有数据集，利用LLMs和上下文学习技术，评估德国雇佣合同条款的合法性（分为“有效”、“不公平”或“无效”）。实验比较了三种法律背景变体：无背景、完整法律文本和简化的审查指南。

研究结果: 结果显示，完整法律文本对性能提升有限，而审查指南显著提高了无效条款的召回率和加权F1分数（达80%）。但LLMs在使用完整法律文本时的表现仍远逊于人类律师。

研究结论: LLMs在辅助律师审查合同合法性方面具有潜力，但当前方法存在局限性。研究贡献了扩展数据集、代码和日志文件。

中文摘要: 法律工作以文本密集和资源消耗大为特点，为NLP研究带来了独特的挑战与机遇。尽管数据驱动方法推动了该领域的发展，但其缺乏可解释性和可信度，限制了其在动态法律环境中的应用。为解决这些问题，我们与法律专家合作扩展了现有数据集，并探索了大型语言模型（LLMs）和上下文学习在评估德国雇佣合同条款合法性中的应用。研究评估了不同LLMs在三种法律背景变体（无法律背景、完整法律文本与法院裁决、以及简化的审查指南）下将条款分类为“有效”、“不公平”或“无效”的能力。结果显示，完整法律文本对性能提升有限，而审查指南显著提高了无效条款的召回率和加权F1分数（达80%）。尽管如此，LLMs在使用完整法律文本时的表现仍远低于人类律师。我们贡献了包含审查指南、参考法律源及相应注释的扩展数据集，以及代码和日志文件。研究结果凸显了LLMs在辅助律师审查合同合法性方面的潜力，同时也揭示了当前方法的局限性。

</details>


### [26] [Data interference: emojis, homoglyphs, and issues of data fidelity in corpora and their results](https://arxiv.org/abs/2507.01764)
**中文标题：数据干扰：表情符号、同形异义词及语料库数据保真度问题**

*Matteo Di Cristofaro*

主要分类: cs.CL

摘要简述: 本文探讨了分词过程中表情符号和同形异义词对语料库数据保真度的影响，强调预处理这些元素的重要性，以确保语言分析的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于揭示分词不一致如何影响语言数据的表示和分析结果的准确性，特别是表情符号和同形异义词带来的挑战。

研究方法: 研究提出了预处理表情符号和同形异义词的方法，以确保数字文本在语料库中的准确表示，从而支持可靠的语言分析。

研究结果: 研究结果表明，对语言和技术细节的深入理解是提高语料库分析准确性的关键，并对定量和定性研究方法具有重要影响。

研究结论: 结论强调，为确保语料库分析的准确性和可重复性，必须对数字文本数据的语言和技术方面进行详细处理。

中文摘要: 分词——"将文本拆分为原子部分的过程"（Brezina & Timperley, 2017: 1）——是语料库语言学的关键步骤，它为任何适用的定量方法（如搭配）提供了基础，同时确保了定性方法的可靠性。本文探讨了分词差异如何影响语言数据的表示和分析结果的有效性：通过研究表情符号和同形异义词带来的挑战，强调了预处理这些元素以保持语料库对源数据的保真度的必要性。研究提出了确保数字文本在语料库中准确表示的方法，从而支持可靠的语言分析并保证语言解释的可重复性。研究结果强调了对数字文本数据涉及的语言和技术方面的详细理解是提高语料库分析准确性的关键，并对基于语料库的定量和定性研究方法具有重要影响。

</details>


### [27] [MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2507.01785)
**中文标题：MuRating：一种面向多语言大语言模型预训练的高质量数据选择方法**

*Zhixun Chen,Ping Guo,Wenhan Han,Yifan Zhang,Binbin Liu,Haobin Lin,Fengze Liu,Yan Zhao,Bingni Zhang,Taifeng Wang,Yin Zheng,Meng Fang*

主要分类: cs.CL

摘要简述: MuRating是一种可扩展的框架，通过将高质量的英语数据信号转化为多语言评分器，用于17种目标语言的数据选择，显著提升多语言大语言模型的预训练效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于模型的数据选择方法主要针对英语，而多语言数据质量对模型性能至关重要。本文旨在填补这一空白，提出一种高效的多语言数据选择方法。

研究方法: MuRating通过聚合多个英语评分器的成对比较学习统一文档质量分数，并通过翻译将这些评分投射到目标语言，训练多语言评估器。该方法应用于网络数据，选择平衡的英语和多语言内容子集进行预训练。

研究结果: 相比QuRater、AskLLM等基线方法，MuRating在英语和多语言评估中均显著提升准确率，尤其在知识密集型任务上表现突出。

研究结论: MuRating为多语言数据选择提供了高效解决方案，未来可进一步优化翻译保真度和数据多样性。

中文摘要: 数据质量是大型语言模型性能的关键驱动因素，但现有的基于模型的选择方法几乎仅关注英语。我们提出了MuRating，一种可扩展的框架，将高质量的英语数据信号转化为17种目标语言的单一评分器。MuRating通过成对比较聚合多个英语“评分器”，学习统一的文档质量分数，然后通过翻译将这些评分投射到目标语言，训练一个多语言评估器，用于单语、跨语言和平行文本对。应用于网络数据时，MuRating选择了平衡的英语和多语言内容子集，用于预训练一个12亿参数的LLaMA模型。与QuRater、AskLLM、DCLM等强基线相比，我们的方法在英语基准和多语言评估中均提升了平均准确率，尤其在知识密集型任务上表现突出。我们还分析了翻译保真度、选择偏见和叙事材料的不足，为未来工作指明了方向。

</details>


### [28] [Probing Evaluation Awareness of Language Models](https://arxiv.org/abs/2507.01786)
**中文标题：探究语言模型的评估意识**

*Jord Nguyen,Khiem Hoang,Carlo Leonardo Attubato,Felix Hofstätter*

主要分类: cs.CL

摘要简述: 研究发现语言模型能区分测试与部署阶段，称为评估意识。这对AI安全与政策有重大影响，可能削弱评估的可靠性。论文通过线性探针分析Llama-3.3-70B-Instruct，发现其能区分真实评估与部署提示，且当前安全评估被模型视为不真实。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型的评估意识可能影响AI治理框架和行业承诺的可靠性。研究旨在验证模型是否能区分测试与部署阶段，并探讨其对安全评估的影响。

研究方法: 使用线性探针技术分析Llama-3.3-70B-Instruct模型，分离真实评估与部署提示，并验证当前安全评估的分类效果。

研究结果: 线性探针能有效区分评估与部署提示，表明模型内部已具备评估意识。当前安全评估被模型正确分类为不真实。

研究结论: 研究强调了确保可信评估和理解模型欺骗能力的重要性，并展示了模型内部信息如何支持黑盒安全审计。

中文摘要: 语言模型能够区分测试与部署阶段——这种能力称为评估意识。这对安全和政策具有重大影响，可能削弱AI治理框架和行业自愿承诺中评估的可靠性。本文研究了Llama-3.3-70B-Instruct的评估意识。我们发现线性探针可以分离真实评估与部署提示，表明当前模型内部已体现这种区分。同时，当前安全评估被探针正确分类，表明它们对模型而言显得不真实。研究强调了确保可信评估和理解欺骗能力的重要性。更广泛地说，我们的工作展示了如何利用模型内部信息支持黑盒安全审计方法，尤其是针对未来更具评估意识和欺骗能力的模型。

</details>


### [29] [How Do Vision-Language Models Process Conflicting Information Across Modalities?](https://arxiv.org/abs/2507.01790)
**中文标题：视觉-语言模型如何处理跨模态的冲突信息？**

*Tianze Hua,Tian Yun,Ellie Pavlick*

主要分类: cs.CL

摘要简述: 本文研究了视觉-语言模型如何处理跨模态的冲突信息，发现模型倾向于优先处理某一模态，且内部表征结构和特定注意力头可调整模态偏好。此外，发现了模态无关的“路由头”，可通过操纵提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI模型日益多模态化，需要理解模型在输入信息冲突时的行为。本文旨在探索视觉-语言模型如何处理图像与文本之间的不一致信息。

研究方法: 通过向模型提供不一致的输入（如图片为狗但标题为“猫的照片”），并询问模型特定模态的信息（如“标题说了什么/图片中有什么”），分析模型的行为和内部表征。

研究结果: 模型通常优先处理某一模态（如图像），且不同模型偏好不同。内部表征结构和特定注意力头可调整模态偏好。还发现模态无关的“路由头”，可通过操纵提升跨数据集和模态的性能。

研究结论: 研究为识别和控制多模态环境中模型如何检测和解决冲突信号提供了重要基础。

中文摘要: AI模型日益需要多模态化，将不同的输入流整合为连贯的状态表征，以支持后续行为和决策。本文旨在理解当输入流提供冲突信息时，此类模型的行为。特别关注视觉-语言模型，我们提供不一致的输入（例如，一张狗的图片配以“猫的照片”的标题），并要求模型报告特定模态的信息（例如，“标题说了什么/图片中有什么”）。我们发现，模型通常优先处理某一模态（如图像），而忽略另一模态（如标题），但不同模型偏好的模态不同。行为上偏好的模态在模型的内部表征结构中有所体现，特定注意力头可以调整表征以优先处理某一模态。此外，我们还发现了模态无关的“路由头”，它们能够根据指令促进对请求模态的回答，并可通过操纵或转移来提升跨数据集和模态的性能。这项工作为识别和控制模型在复杂多模态环境中如何检测和解决冲突信号提供了重要基础。

</details>


### [30] [The Anatomy of Evidence: An Investigation Into Explainable ICD Coding](https://arxiv.org/abs/2507.01802)
**中文标题：证据剖析：可解释ICD编码研究**

*Katharina Beckh,Elisa Studeny,Sujan Sai Gannamaneni,Dario Antweiler,Stefan Rüping*

主要分类: cs.CL

摘要简述: 本文深入分析了MDACE数据集，评估了可解释医疗编码系统的合理性，揭示了真实证据与代码描述的部分一致性，并提出了匹配度量及改进建议。


<details>
  <summary>详细信息</summary>
研究动机: 自动医疗编码有望简化文档和计费流程，但透明性对医疗编码人员和监管机构至关重要。由于缺乏标注数据，现有评估多限于短文本和二元设置。MDACE数据集的出现为研究提供了新资源，本文旨在通过分析该数据集，推动可解释医疗编码系统的发展。

研究方法: 本文对MDACE数据集进行了深入分析，评估了当前可解释医疗编码系统的合理性，提出了匹配度量方法，并总结了成功与失败案例。

研究结果: 研究发现，真实证据与代码描述存在一定程度的一致性，现有先进方法与真实证据的重叠率较高。通过匹配度量，识别了系统的优缺点。

研究结论: 基于研究结果，本文提出了开发和评估可解释医疗编码系统的建议，为未来研究提供了方向。

中文摘要: 自动医疗编码有望简化文档和计费流程。在此任务中，透明性对医疗编码人员和监管机构至关重要，可通过可解释性方法实现。然而，由于缺乏标注数据，现有评估多限于短文本和二元设置。Cheng等人（2023）近期提出的MDACE数据集为临床记录中的代码证据提供了宝贵资源。本文对MDACE数据集进行了深入分析，并从应用角度评估了当前可解释医疗编码系统的合理性。通过研究，我们深化了对自动医疗编码和证据提取的理解。研究发现，真实证据与代码描述存在一定程度的一致性。对现有先进方法的分析显示，其与真实证据的重叠率较高。我们提出了匹配度量方法，并总结了成功与失败案例。基于研究结果，本文为开发和评估可解释医疗编码系统提供了建议。

</details>


### [31] [Evaluating Structured Output Robustness of Small Language Models for Open Attribute-Value Extraction from Clinical Notes](https://arxiv.org/abs/2507.01810)
**中文标题：评估小型语言模型在临床笔记开放属性值提取任务中的结构化输出鲁棒性**

*Nikita Neveditsin,Pawan Lingras,Vijay Mago*

主要分类: cs.CL

摘要简述: 本文比较了小型语言模型在临床笔记开放属性值提取任务中生成结构化输出的可解析性，发现JSON格式表现最佳，并分析了影响解析性的因素。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于评估小型语言模型在临床笔记中提取开放属性值时生成的结构化输出的可解析性，为隐私敏感的临床环境提供实用指导。

研究方法: 方法包括比较三种常用序列化格式（JSON、YAML和XML）的可解析性，分析提示设计和模型大小对解析性的影响，并对长文档和特定笔记类型进行测试。

研究结果: 结果显示JSON格式的可解析性最高，结构化鲁棒性随提示设计和模型大小提升而增强，但在长文档和某些笔记类型中表现下降。错误分析揭示了格式特定的常见失败模式。

研究结论: 结论指出JSON是临床环境中部署语言模型时的首选序列化格式，并强调了提示设计的重要性。

中文摘要: 本文对小型语言模型在临床笔记开放属性值提取任务中生成的结构化输出的可解析性进行了比较分析。我们评估了三种广泛使用的序列化格式：JSON、YAML和XML，发现JSON始终具有最高的可解析性。结构化鲁棒性通过针对性提示和更大模型得到提升，但在长文档和某些笔记类型中表现下降。错误分析揭示了格式特定的常见失败模式。这些发现为在隐私敏感的临床环境中选择序列化格式和设计提示提供了实用指导。

</details>


### [32] [Low-Perplexity LLM-Generated Sequences and Where To Find Them](https://arxiv.org/abs/2507.01844)
**中文标题：低困惑度LLM生成序列及其来源研究**

*Arthur Wuhrmann,Anastasiia Kucherenko,Andrei Kucharavy*

主要分类: cs.CL

摘要简述: 本文提出了一种系统方法，通过分析大语言模型（LLM）生成的低困惑度序列（高概率文本片段），研究训练数据如何影响模型输出。研究发现，许多低困惑度序列无法追溯到训练数据，而可追溯的部分则揭示了模型对训练数据的逐字记忆程度。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLM）的广泛应用，理解训练数据如何影响其输出对透明度、责任性、隐私和公平性至关重要。本文旨在探索LLM如何利用和复制其训练数据，以揭示模型行为的潜在机制。

研究方法: 研究提出了一种系统方法，通过提取和分析LLM生成的低困惑度序列（高概率文本片段），并将其与训练数据源进行匹配。该方法避免了文本退化问题，并能够可靠地提取跨主题的长序列。

研究结果: 研究发现，大量低困惑度序列无法映射到训练数据中。对于可匹配的部分，研究量化了其在源文档中的分布，揭示了模型对训练数据的逐字记忆范围和性质。

研究结论: 通过分析低困惑度序列，本文为理解LLM训练数据如何影响其行为提供了新视角，强调了进一步研究模型记忆和输出透明性的重要性。

中文摘要: 随着大语言模型（LLM）的广泛应用，理解特定训练数据如何塑造其输出对透明度、责任性、隐私和公平性至关重要。为探索LLM如何利用和复制其训练数据，我们提出了一种以分析低困惑度序列（模型生成的高概率文本片段）为核心的系统方法。我们的流程能够可靠地提取跨主题的长序列并避免退化，随后将其追溯到训练数据中的来源。令人惊讶的是，我们发现这些低困惑度片段中有相当一部分无法映射到语料库中。对于能够匹配的部分，我们量化了其在源文档中的分布，揭示了逐字记忆的范围和性质，为更好地理解LLM训练数据如何影响其行为铺平了道路。

</details>


### [33] [Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages](https://arxiv.org/abs/2507.01853)
**中文标题：Eka-Eval：面向印度语言的大型语言模型综合评估框架**

*Samridhi Raj Sinha,Rajvee Sheth,Abhishek Upperwal,Mayank Singh*

主要分类: cs.CL

摘要简述: EKA-EVAL是一个针对印度语言的大型语言模型（LLM）的全面评估框架，整合了35个以上的基准测试，包括10个印度语言特定数据集，支持分布式推理、量化和多GPU使用，旨在降低多语言评估的门槛。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型的快速发展，现有的评估框架主要针对英语，而忽视了印度等语言多样性地区的需求。EKA-EVAL旨在填补这一空白，为全球和印度语言的LLM提供统一的评估工具。

研究方法: EKA-EVAL整合了35个以上的基准测试，涵盖推理、数学、工具使用、长文本理解和阅读理解等多个类别，并支持分布式推理、量化和多GPU使用。

研究结果: EKA-EVAL成为首个端到端、可扩展的评估套件，显著降低了多语言评估的门槛，并开源供公众使用。

研究结论: EKA-EVAL为全球和印度语言的LLM提供了全面的评估工具，未来计划扩展到100个以上的基准测试，建立更强大的多语言评估生态系统。

中文摘要: 大型语言模型（LLM）的快速发展加剧了对超越以英语为中心的评估框架的需求，以满足印度等多语言地区的需求。我们提出了EKA-EVAL，一个统一且可直接用于生产的评估框架，整合了35个以上的基准测试，包括10个印度语言特定数据集，涵盖推理、数学、工具使用、长文本理解和阅读理解等类别。与现有的印度语言评估工具相比，EKA-EVAL提供了更广泛的基准覆盖，并内置了对分布式推理、量化和多GPU使用的支持。我们的系统比较表明，EKA-EVAL是首个端到端、可扩展的评估套件，专为全球和印度语言的LLM设计，显著降低了多语言评估的门槛。该框架是开源的，可在https://github.com/lingo-iitgn/eka-eval获取，并属于正在进行的EKA计划（https://eka.soket.ai）的一部分，该计划旨在扩展到100个以上的基准测试，为LLM建立一个强大的多语言评估生态系统。

</details>


### [34] [DIY-MKG: An LLM-Based Polyglot Language Learning System](https://arxiv.org/abs/2507.01872)
**中文标题：DIY-MKG：基于大语言模型的多语言学习系统**

*Kenan Tang,Yanhong Li,Yao Qin*

主要分类: cs.CL

摘要简述: DIY-MKG是一个基于大语言模型（LLM）的多语言学习系统，支持用户构建个性化词汇知识图谱，并通过动态测验和反馈机制提升学习效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有语言学习工具（包括基于LLM的工具）在多语言词汇关联、个性化学习支持及认知卸载方面存在不足，DIY-MKG旨在解决这些问题。

研究方法: DIY-MKG通过LLM构建个性化词汇知识图谱，支持选择性扩展词汇、丰富注释功能及动态测验生成，并提供用户反馈机制优化提示。

研究结果: 评估显示，DIY-MKG在多语言词汇扩展中表现可靠且公平，生成的测验准确性高，验证了系统的鲁棒性。

研究结论: DIY-MKG为多语言学习者提供了高效、个性化的学习工具，通过LLM技术显著提升了学习体验和效果。

中文摘要: 现有的语言学习工具（包括基于大语言模型（LLM）的工具）通常缺乏对多语言学习者在跨语言词汇关联方面的支持，个性化学习需求或进度的定制能力有限，且存在认知卸载的负面影响。为解决这些问题，我们设计了DIY-MKG（Do-It-Yourself Multilingual Knowledge Graph），一个支持多语言学习的开源系统。DIY-MKG允许用户构建个性化的词汇知识图谱，通过LLM推荐的关联词汇进行选择性扩展。系统还通过丰富的注释功能和自适应复习模块（利用LLM生成动态、个性化的测验）进一步提升学习效果。此外，DIY-MKG允许用户标记错误的测验问题，既提高了用户参与度，又为提示优化提供了反馈循环。我们对DIY-MKG中基于LLM的组件进行了评估，结果显示词汇扩展在多种语言中均可靠且公平，生成的测验准确性高，验证了DIY-MKG的鲁棒性。

</details>


### [35] [MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants](https://arxiv.org/abs/2507.01887)
**中文标题：MiCoTA：通过中等长度思维链和教师助理弥合学习能力差距**

*Dongyi Ding,Tiannan Wang,Chenghao Zhu,Meiling Tao,Yuchen Eleanor Jiang,Wangchunshu Zhou*

主要分类: cs.CL

摘要简述: 本文提出MiCoTA框架，通过中等规模模型作为教师助理和中等长度思维链（CoT）序列，解决小语言模型（SLMs）在学习长链推理时的能力不足问题，显著提升其推理性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在需要长序列推理的任务中表现优异，但其计算资源需求高，难以广泛部署。而小语言模型（SLMs）由于容量有限，难以学习长链推理，形成“SLMs学习能力差距”。本文旨在通过MiCoTA框架解决这一问题。

研究方法: MiCoTA框架利用中等规模模型作为教师助理，并采用中等长度的CoT序列，弥合SLMs在容量和推理长度上的差距。通过蒸馏技术，将LLMs的推理能力传递给SLMs。

研究结果: 实验表明，经过MiCoTA蒸馏的SLMs在推理任务中表现显著提升。例如，Qwen2.5-7B-Instruct和Qwen2.5-3B-Instruct在多个基准测试中平均得分分别提高了3.47和3.93。定量实验进一步验证了MiCoTA生成的数据更符合SLMs的分布。

研究结论: MiCoTA框架有效解决了SLMs在学习长链推理时的能力不足问题，为未来SLMs的长链推理数据蒸馏研究提供了新思路。

中文摘要: 大型语言模型（LLMs）在需要长序列推理的任务（如规划、反思和优化）中表现优异，但其庞大的模型规模和高计算需求限制了广泛部署。相比之下，小语言模型（SLMs）由于容量有限，难以学习长链推理，我们称之为“SLMs学习能力差距”。为解决这一问题，我们提出了MiCoTA（中等长度思维链教师助理蒸馏）框架，通过中等规模模型作为教师助理和中等长度CoT序列，弥合SLMs在容量和推理长度上的差距。下游任务实验表明，尽管从大型教师模型蒸馏的SLMs表现不佳，但通过MiCoTA，其推理性能显著提升。具体而言，Qwen2.5-7B-Instruct和Qwen2.5-3B-Instruct在AIME2024、AMC、Olympiad、MATH-500和GSM8K基准测试中的平均得分分别提高了3.47和3.93。为深入理解MiCoTA机制，我们进行了定量实验，证明该方法生成的数据更符合SLMs的分布。这些发现为未来SLMs的长链推理数据蒸馏研究提供了方向。

</details>


### [36] [High-Layer Attention Pruning with Rescaling](https://arxiv.org/abs/2507.01900)
**中文标题：高层注意力剪枝与重缩放**

*Songtao Liu,Peng Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种新颖的高层注意力剪枝与重缩放方法，显著提升了大型语言模型的压缩效果，尤其在生成任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统剪枝方法通常采用启发式指标，不加区分地剪除所有层的注意力头，忽略了其在网络架构中的位置重要性。本文旨在通过针对高层注意力头的剪枝及自适应重缩放，优化模型性能。

研究方法: 提出了一种剪枝算法，专注于剪除模型高层的注意力头，并引入自适应重缩放参数以校准剪枝后的表征尺度。

研究结果: 在包括LLaMA3.1-8B、Mistral-7B-v0.3等模型及27个数据集的实验中，该方法在生成和判别任务中均优于现有剪枝方法。

研究结论: 高层注意力剪枝与重缩放方法显著提升了模型压缩效果，尤其在生成任务中表现突出，为大型语言模型的剪枝提供了新思路。

中文摘要: 剪枝是压缩大型语言模型（LLMs）的高效方法，能显著降低推理延迟。然而，传统的无训练结构化剪枝方法通常采用启发式指标，不加区分地剪除所有层的注意力头，未考虑其在网络架构中的位置。本文提出了一种新颖的剪枝算法，策略性地剪除模型高层的注意力头。由于剪除注意力头可能改变表征尺度，我们引入了自适应重缩放参数以校准剪枝后的表征尺度。我们在包括LLaMA3.1-8B、Mistral-7B-v0.3、Qwen2-7B和Gemma2-9B在内的多种LLMs上进行了全面实验，覆盖27个数据集的生成和判别任务。结果表明，我们的方法始终优于现有结构化剪枝方法，尤其在生成任务中表现显著。

</details>


### [37] [AI4Research: A Survey of Artificial Intelligence for Scientific Research](https://arxiv.org/abs/2507.01903)
**中文标题：AI4Research：人工智能在科学研究中的综述**

*Qiguang Chen,Mingda Yang,Libo Qin,Jinhao Liu,Zheng Yan,Jiannan Guan,Dengyun Peng,Yiyan Ji,Hanjing Li,Mengkang Hu,Yimeng Zhang,Yihao Liang,Yuhang Zhou,Jiaqi Wang,Zhi Chen,Wanxiang Che*

主要分类: cs.CL

摘要简述: 本文综述了人工智能在科学研究中的应用（AI4Research），提出了系统分类法，识别了研究空白，并整理了丰富的资源，旨在推动该领域的进一步发展。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，人工智能（尤其是大型语言模型）在逻辑推理和实验编码等复杂领域展现出强大能力，激发了AI在科学研究中的应用探索。然而，缺乏全面的AI4Research综述阻碍了该领域的深入理解和进一步发展。

研究方法: 本文通过系统分类法将AI4Research分为五大主流任务，识别关键研究空白，并重点探讨自动化实验的严谨性和可扩展性及其社会影响。同时，整理了多学科应用、数据资源和工具。

研究结果: 提出了一套系统分类法，明确了AI4Research的五大任务；指出了未来研究方向，尤其是自动化实验的改进；并提供了丰富的资源库。

研究结论: 本文填补了AI4Research领域综述的空白，为研究社区提供了快速获取资源的途径，并有望推动该领域的创新突破。

中文摘要: 近年来，人工智能（AI）的快速发展，尤其是如OpenAI-o1和DeepSeek-R1等大型语言模型（LLMs），在逻辑推理和实验编码等复杂领域展现了卓越能力。受此启发，大量研究探索了AI在创新过程中的应用，特别是在科学研究领域。这些AI技术旨在开发能够自主完成多学科研究流程的系统。尽管取得了显著进展，但关于AI4Research的全面综述仍然缺失，这阻碍了我们的理解并限制了该领域的进一步发展。为填补这一空白，本文提出了一项全面综述，并提供了关于AI4Research的统一视角。具体而言，本文的主要贡献如下：（1）系统分类法：首先提出了一种系统分类法，将AI4Research分为五大主流任务。（2）新前沿：随后，识别了关键研究空白，并着重指出了未来有前景的方向，重点关注自动化实验的严谨性和可扩展性及其社会影响。（3）丰富的应用与资源：最后，整理了包括多学科应用、数据语料库和工具在内的丰富资源。我们希望本文能为研究社区提供快速获取这些资源的途径，并激发AI4Research领域的创新突破。

</details>


### [38] [Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models](https://arxiv.org/abs/2507.01915)
**中文标题：梯度自适应策略优化：面向大型语言模型的多目标对齐**

*Chengao Li,Hanyu Zhang,Yunkun Xu,Hongyan Xue,Xiang Ao,Qing He*

主要分类: cs.CL

摘要简述: 本文提出了一种名为梯度自适应策略优化（GAPO）的新方法，用于解决大型语言模型（LLM）在多样化人类偏好对齐中的多目标优化问题。GAPO通过自适应调整梯度来平衡冲突目标，并引入P-GAPO以更好地满足用户需求。实验证明其在Mistral-7B上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于人类反馈的强化学习（RLHF）在大型语言模型对齐中表现出色，但如何有效对齐多样化且可能冲突的人类偏好仍是一个挑战。本文旨在通过多目标优化框架解决这一问题。

研究方法: 提出梯度自适应策略优化（GAPO），利用多梯度下降技术自适应调整各目标的梯度，以平衡冲突目标。进一步提出P-GAPO，结合用户偏好生成更符合需求的帕累托解。

研究结果: 理论分析表明GAPO能收敛至帕累托最优解。在Mistral-7B上的实验显示，GAPO在帮助性和无害性方面均优于现有方法。

研究结论: GAPO为大型语言模型的多目标对齐提供了一种有效解决方案，能够更好地满足多样化的人类偏好需求。

中文摘要: 基于人类反馈的强化学习（RLHF）已成为对齐大型语言模型（LLM）与人类偏好的强大技术。然而，如何有效对齐多样化且可能冲突的人类偏好仍是一个重大挑战。为此，我们将人类价值对齐问题建模为多目标优化问题，旨在最大化一组可能冲突的目标。我们提出梯度自适应策略优化（GAPO），这是一种新颖的微调范式，利用多梯度下降技术对齐LLM与多样化偏好分布。GAPO自适应调整各目标的梯度，以确定最优平衡目标间权衡的更新方向。此外，我们提出P-GAPO，结合用户在不同目标上的偏好，生成更符合用户需求的帕累托解。理论分析表明，GAPO能收敛至多目标的帕累托最优解。在Mistral-7B上的实验结果表明，GAPO在帮助性和无害性方面均优于当前最先进方法。

</details>


### [39] [NaturalThoughts: Selecting and Distilling Reasoning Traces for General Reasoning Tasks](https://arxiv.org/abs/2507.01921)
**中文标题：NaturalThoughts：为通用推理任务选择和蒸馏推理轨迹**

*Yang Li,Youssef Emad,Karthik Padthe,Jack Lanchantin,Weizhe Yuan,Thao Nguyen,Jason Weston,Shang-Wen Li,Dong Wang,Ilia Kulikov,Xian Li*

主要分类: cs.CL

摘要简述: 本文提出了一种名为NaturalThoughts的方法，通过从强大的教师模型中选择高质量的推理轨迹，以提升学生模型的推理能力。研究发现，选择需要多样化推理策略的困难样本更高效，并在多个基准测试中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有研究表明通过监督微调从教师模型中蒸馏推理轨迹优于仅使用学生模型的强化学习，但尚未系统研究哪些推理演示对学生模型的推理能力提升最有效。本文旨在填补这一空白。

研究方法: 作者从NaturalReasoning数据集中选取问题，并基于强大的教师模型筛选高质量的推理轨迹（NaturalThoughts）。通过系统分析影响推理能力蒸馏的因素，发现选择需要多样化推理策略的困难样本更高效。

研究结果: 在Llama和Qwen模型上的实验表明，使用NaturalThoughts训练的模型在GPQA-Diamond、MMLU-Pro和SuperGPQA等通用STEM推理基准测试中优于现有数据集（如OpenThoughts和LIMO）。

研究结论: NaturalThoughts方法通过选择高质量的推理轨迹，显著提升了学生模型的推理能力，尤其是在处理需要多样化策略的困难任务时表现更优。

中文摘要: 近期研究表明，通过监督微调从较大的教师模型中蒸馏推理轨迹，其表现优于仅使用较小学生模型的强化学习（Guo等人，2025年）。然而，尚未系统研究教师模型的哪些推理演示对学生模型推理能力的提升最有效。本文通过从NaturalReasoning（Yuan等人，2025年）的大量问题中筛选高质量的“NaturalThoughts”推理轨迹，填补了这一空白。我们首先系统分析了影响推理能力蒸馏的因素，包括样本效率和通用推理任务的可扩展性。研究发现，仅通过随机采样扩大数据规模即可实现稳定的性能提升。此外，选择需要更多样化推理策略的困难样本，能更高效地传递教师模型的推理能力。在Llama和Qwen模型上的评估表明，使用NaturalThoughts训练的模型在通用STEM推理基准测试（如GPQA-Diamond、MMLU-Pro和SuperGPQA）中优于OpenThoughts、LIMO等现有数据集。

</details>


### [40] [Decision-oriented Text Evaluation](https://arxiv.org/abs/2507.01923)
**中文标题：面向决策的文本评估**

*Yu-Shiang Huang,Chuan-Ju Wang,Chung-Chi Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种面向决策的文本评估框架，通过直接测量生成文本对人类和大型语言模型（LLM）决策结果的影响，发现传统内在评估指标（如n-gram重叠或句子合理性）与决策效果相关性较弱。实验表明，仅依赖摘要时，人类和LLM代理的表现均未显著优于随机水平，但更丰富的分析评论能显著提升人机协作团队的决策效果。


<details>
  <summary>详细信息</summary>
研究动机: 自然语言生成（NLG）在高风险领域中的应用日益广泛，但传统的内在评估方法（如n-gram重叠或句子合理性）与实际的决策效果相关性较弱。因此，作者提出了一种新的评估框架，旨在直接衡量生成文本对决策结果的影响。

研究方法: 作者采用了一种面向决策的评估框架，通过市场摘要文本（包括客观的早间总结和主观的收盘分析）作为测试案例，评估人类投资者和自主LLM代理在仅依赖这些文本时的决策质量。决策质量通过交易的实际财务表现来衡量。

研究结果: 实验结果显示，无论是人类还是LLM代理，仅依赖摘要时均未能显著超越随机表现。然而，更丰富的分析评论能够显著提升人机协作团队的决策效果，使其优于单独的人类或代理基线。

研究结论: 本文强调了通过生成文本促进人机协同决策能力的重要性，并揭示了传统内在评估指标的局限性。未来的研究应更注重文本在实际决策中的效用。

中文摘要: 自然语言生成（NLG）在高风险领域中的应用日益广泛，但常见的内在评估方法（如n-gram重叠或句子合理性）与实际决策效果的相关性较弱。我们提出了一种面向决策的框架，通过直接测量生成文本对人类和大型语言模型（LLM）决策结果的影响来评估其质量。以市场摘要文本（包括客观的早间总结和主观的收盘分析）为测试案例，我们评估了人类投资者和自主LLM代理在仅依赖这些文本时的决策质量，并通过交易的财务表现来衡量。研究发现，无论是人类还是LLM代理，仅依赖摘要时均未能显著超越随机表现。然而，更丰富的分析评论能够显著提升人机协作团队的决策效果，使其优于单独的人类或代理基线。我们的方法强调了通过生成文本促进人机协同决策能力的重要性，并揭示了传统内在评估指标的局限性。

</details>


### [41] [Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla](https://arxiv.org/abs/2507.01931)
**中文标题：ASR模型在低资源语言上的适应性：Whisper与Wav2Vec-BERT在孟加拉语上的对比研究**

*Md Sazzadul Islam Ridoy,Sumi Akter,Md. Aminur Rahman*

主要分类: cs.CL

摘要简述: 本研究比较了OpenAI的Whisper和Facebook的Wav2Vec-BERT两种自动语音识别（ASR）模型在低资源语言孟加拉语上的表现。实验表明，Wav2Vec-BERT在各项关键指标上均优于Whisper，且计算效率更高。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，基于大规模多语言文本和语音数据训练的神经模型在支持低资源语言方面显示出巨大潜力。本研究旨在评估两种先进ASR模型在孟加拉语（一种低资源语言）上的表现，为低资源语言环境下的语音识别系统开发提供参考。

研究方法: 研究使用Mozilla Common Voice-17和OpenSLR两个公开数据集，对Whisper（Small和Large-V2）和Wav2Vec-BERT模型进行系统微调和超参数优化（包括学习率、训练轮次和模型检查点选择），并基于词错误率（WER）、字符错误率（CER）、训练时间和计算效率进行比较。

研究结果: 实验结果表明，Wav2Vec-BERT在所有关键评估指标上均优于Whisper，且计算资源需求更低。

研究结论: Wav2Vec-BERT在低资源语言环境下表现更优，为开发鲁棒的语音识别系统提供了重要参考。

中文摘要: 近年来，基于大规模多语言文本和语音数据训练的神经模型在支持低资源语言方面显示出巨大潜力。本研究评估了两种先进的自动语音识别（ASR）模型——OpenAI的Whisper（Small和Large-V2）和Facebook的Wav2Vec-BERT在孟加拉语（一种低资源语言）上的表现。实验使用了Mozilla Common Voice-17和OpenSLR两个公开数据集，通过系统微调和超参数优化（包括学习率、训练轮次和模型检查点选择），基于词错误率（WER）、字符错误率（CER）、训练时间和计算效率对模型进行了比较。结果表明，Wav2Vec-BERT在所有关键评估指标上均优于Whisper，且计算资源需求更低，为低资源语言环境下开发鲁棒的语音识别系统提供了重要参考。

</details>


### [42] [The Thin Line Between Comprehension and Persuasion in LLMs](https://arxiv.org/abs/2507.01936)
**中文标题：大型语言模型在理解与说服之间的微妙界限**

*Adrian de Wynter,Tangming Yuan*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLM）能够进行连贯且有说服力的辩论，但其对对话深层结构的理解能力有限。尽管LLM能影响参与者和听众的观点，但对AI参与的怀疑会使人更批判性。LLM作为评估者的不足与其对上下文理解的不足有关。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM在敏感领域（如同行评审和心理健康应用）中的快速部署，对其对话理解能力的评估变得尤为重要。本研究旨在探讨LLM在辩论中的表现及其对对话结构和语用上下文的理解能力。

研究方法: 研究首先评估LLM在辩论中的表现，随后测量其与对话结构和语用上下文理解能力的关系。通过实验观察LLM是否能维持连贯且有说服力的辩论，并分析其对深层对话结构的理解。

研究结果: LLM能够进行连贯且有说服力的辩论，甚至影响参与者和听众的观点。然而，当被问及对深层对话结构的理解时，LLM无法展示这种能力。对AI参与的怀疑会使人更批判性。

研究结论: LLM作为评估者的不足与其对上下文理解的不足有关。研究提出，在论证理论中，能够维持对话的代理无需理解对话内容，语用上下文和连贯性的建模次于有效性。

中文摘要: 大型语言模型（LLM）擅长维持高水平且具有说服力的对话，并迅速被部署为聊天机器人和评估者，应用于敏感领域如同行评审和心理健康。关于其推理能力的争议促使我们更深入地研究LLM对对话的理解。本研究首先评估LLM在辩论中的表现——辩论是人类交流中最纯粹但也最复杂的形式之一。随后，我们测量这种能力与其对对话结构和语用上下文理解的关系。研究发现，LLM能够维持连贯且有说服力的辩论，甚至影响参与者和听众的观点。同时，对AI参与的怀疑会使人更批判性。然而，当被问及对深层对话结构的理解时，LLM无法展示这种能力。研究将LLM作为评估者的不足归因于其对上下文理解的不足。更广泛地说，在论证理论中，我们认为，如果一个代理能够维持对话，它无需理解对话内容。因此，语用上下文和连贯性的建模次于有效性。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [43] [Geometry-aware 4D Video Generation for Robot Manipulation](https://arxiv.org/abs/2507.01099)
**中文标题：面向机器人操作的几何感知4D视频生成**

*Zeyi Liu,Shuang Li,Eric Cousineau,Siyuan Feng,Benjamin Burchfiel,Shuran Song*

主要分类: cs.CV

摘要简述: 本文提出了一种4D视频生成模型，通过跨视角点图对齐监督，确保多视角3D一致性，从而生成几何一致且时间连贯的视频，支持机器人操作和新视角预测。


<details>
  <summary>详细信息</summary>
研究动机: 理解和预测物理世界动态有助于机器人在复杂环境中规划和交互。现有视频生成模型在时间连贯性和多视角几何一致性方面存在挑战，本文旨在解决这一问题。

研究方法: 提出一种4D视频生成模型，通过跨视角点图对齐监督训练，学习场景的共享3D表示，仅需RGB-D观测即可预测未来视频序列，无需相机位姿输入。

研究结果: 在模拟和真实机器人数据集上，模型生成的多视角预测视频在视觉稳定性和空间对齐性上优于现有基线，并能通过现成6DoF姿态跟踪器恢复机器人末端轨迹。

研究结论: 该方法生成的4D视频支持机器人操作和新视角泛化，为动态场景建模提供了有效解决方案。

中文摘要: 理解和预测物理世界的动态可以提升机器人在复杂环境中规划和交互的能力。尽管现有视频生成模型在动态场景建模方面表现出潜力，但生成时间连贯且多视角几何一致的视频仍具挑战性。为此，我们提出了一种4D视频生成模型，通过训练中的跨视角点图对齐监督，强制视频的多视角3D一致性。这种几何监督使模型能够学习场景的共享3D表示，从而仅基于给定的RGB-D观测预测未来视频序列，无需相机位姿输入。与现有基线相比，我们的方法在多个模拟和真实机器人数据集上生成了视觉更稳定、空间更对齐的预测结果。进一步研究表明，预测的4D视频可用于通过现成的6DoF姿态跟踪器恢复机器人末端轨迹，支持稳健的机器人操作和新视角泛化。

</details>


### [44] [Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions](https://arxiv.org/abs/2507.01123)
**中文标题：基于多源卫星数据与深度学习的跨地理区域滑坡检测与制图**

*Rahul A. Burange,Harsh K. Shinde,Omkar Mutyalwar*

主要分类: cs.CV

摘要简述: 本文提出了一种结合多源卫星数据和深度学习的方法，用于跨地理区域的滑坡检测与预测，旨在提升灾害预警和土地规划能力。


<details>
  <summary>详细信息</summary>
研究动机: 滑坡对基础设施、经济和人类生命构成严重威胁，亟需一种能够跨不同地理区域准确检测和预测滑坡的方法。深度学习与遥感技术的进步为此提供了可能。

研究方法: 研究整合了Sentinel-2多光谱数据和ALOS PALSAR衍生的坡度及数字高程模型（DEM）数据，结合地理空间分析技术评估地形、植被覆盖和降雨对检测精度的影响。同时，比较了U-Net、DeepLabV3+和Res-Net等深度学习分割模型在滑坡检测中的表现。

研究结果: 研究结果表明，多源卫星数据与深度学习模型的结合显著提升了滑坡检测的准确性，为灾害预警系统和土地规划提供了可靠支持。

研究结论: 该框架展示了深度学习与多源遥感数据在构建可扩展、可迁移的滑坡预测模型中的潜力，为灾害风险管理提供了新思路。

中文摘要: 滑坡对基础设施、经济和人类生命构成严重威胁，亟需一种能够跨不同地理区域准确检测和预测滑坡的方法。随着深度学习和遥感技术的进步，自动化滑坡检测变得日益高效。本研究提出了一种综合方法，整合多源卫星影像和深度学习模型，以提升滑坡识别与预测能力。我们利用Sentinel-2多光谱数据及ALOS PALSAR衍生的坡度和数字高程模型（DEM）数据，捕捉影响滑坡发生的关键环境特征。通过多种地理空间分析技术，评估了地形特征、植被覆盖和降雨对检测精度的影响。此外，我们还比较了U-Net、DeepLabV3+和Res-Net等先进深度学习分割模型在滑坡检测中的表现。该框架为开发可靠的预警系统、改进灾害风险管理和可持续土地规划提供了支持。研究结果揭示了深度学习与多源遥感数据在构建稳健、可扩展且可迁移的滑坡预测模型中的潜力。

</details>


### [45] [cp_measure: API-first feature extraction for image-based profiling workflows](https://arxiv.org/abs/2507.01163)
**中文标题：cp_measure：面向基于图像分析工作流的API优先特征提取工具**

*Alán F. Muñoz,Tim Treis,Alexandr A. Kalinin,Shatavisha Dasgupta,Fabian Theis,Anne E. Carpenter,Shantanu Singh*

主要分类: cs.CV

摘要简述: 本文介绍了cp_measure，一个将CellProfiler核心测量功能模块化的Python库，旨在为基于图像的生物分析提供自动化、可重复的特征提取工具，支持机器学习工作流。


<details>
  <summary>详细信息</summary>
研究动机: 传统生物图像分析工具如CellProfiler在自动化、可重复性方面存在不足，阻碍了机器学习工作流的应用。cp_measure旨在解决这一问题，提供模块化的API工具，支持程序化特征提取。

研究方法: cp_measure将CellProfiler的核心测量功能提取为Python库，设计为模块化、API优先的工具，便于与科学Python生态系统集成。

研究结果: 实验表明，cp_measure提取的特征与CellProfiler高度一致，同时支持自动化、可重复的图像分析流程，适用于3D星形胶质细胞成像和空间转录组学等应用。

研究结论: cp_measure为基于图像的生物分析提供了高效、可扩展的工具，支持机器学习在计算生物学中的应用。

中文摘要: 传统生物图像分析主要关注细胞或其他实体的特定视觉属性测量。一种新兴的互补范式是基于图像的全面特征量化，以揭示细胞状态、药物反应和疾病机制的隐藏模式。尽管现有工具如CellProfiler可以生成这些特征集，但其在自动化和可重复性分析方面存在显著障碍，阻碍了机器学习工作流。本文介绍了cp_measure，一个将CellProfiler核心测量功能模块化的Python库，设计为API优先的工具，支持程序化特征提取。实验表明，cp_measure提取的特征与CellProfiler高度一致，同时实现了与科学Python生态系统的无缝集成。通过3D星形胶质细胞成像和空间转录组学的应用，展示了cp_measure如何支持可重复、自动化的图像分析流程，为计算生物学中的机器学习应用提供高效扩展。

</details>


### [46] [Rapid Salient Object Detection with Difference Convolutional Neural Networks](https://arxiv.org/abs/2507.01182)
**中文标题：基于差异卷积神经网络的快速显著目标检测**

*Zhuo Su,Li Liu,Matthias Müller,Jiehua Zhang,Diana Wofk,Ming-Ming Cheng,Matti Pietikäinen*

主要分类: cs.CV

摘要简述: 本文提出了一种高效的显著目标检测（SOD）方法，通过结合传统SOD的对比线索与现代CNN的表征能力，设计了基于像素差异卷积（PDC）的网络SDNet和STDNet，显著提升了在资源受限设备上的实时性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前显著目标检测（SOD）的深度学习模型虽然性能优越，但计算成本高，难以在资源受限设备上实现实时运行。本文旨在设计一种高效且轻量化的SOD方法，以满足实时部署需求。

研究方法: 1. 提出像素差异卷积（PDC），将传统SOD的对比线索编码到CNN中；2. 引入差异卷积重参数化（DCR）策略，将PDC嵌入标准卷积，减少推理时的计算和参数；3. 针对视频SOD，提出时空差异卷积（STDC），增强时空对比捕捉能力。

研究结果: 在Jetson Orin设备上，SDNet和STDNet分别以46 FPS和150 FPS的速度运行，参数少于1M，速度和精度均显著优于其他轻量化模型。

研究结论: 本文提出的SDNet和STDNet在显著目标检测任务中实现了高效与高精度的平衡，特别适合资源受限设备的实时应用。

中文摘要: 本文解决了在资源受限设备上实时部署显著目标检测（SOD）的挑战。尽管深度神经网络的最新进展提升了SOD性能，但现有领先模型计算成本高昂。我们提出了一种高效网络设计，结合了传统SOD的智慧和现代CNN的表征能力。与传统生物启发的SOD方法类似，我们的模型利用像素差异卷积（PDC）编码特征对比。不同的是，PDC被整合到CNN架构中，从而从丰富的特征图中提取有价值的对比线索。为提高效率，我们引入了差异卷积重参数化（DCR）策略，将PDC嵌入标准卷积，减少推理时的计算和参数。此外，针对视频SOD，我们提出了时空差异卷积（STDC），通过时空对比捕捉增强标准3D卷积。我们的模型SDNet（图像SOD）和STDNet（视频SOD）在效率与精度权衡上取得了显著提升。在Jetson Orin设备上，参数少于1M的模型在图像和视频流上的运行速度分别为46 FPS和150 FPS，速度和精度均远超其他轻量化模型。代码将在https://github.com/hellozhuo/stdnet.git发布。

</details>


### [47] [Robust Brain Tumor Segmentation with Incomplete MRI Modalities Using Hölder Divergence and Mutual Information-Enhanced Knowledge Transfer](https://arxiv.org/abs/2507.01254)
**中文标题：基于Hölder散度和互信息增强知识转移的鲁棒脑肿瘤分割方法**

*Runze Cheng,Xihang Qiu,Ming Li,Ye Zhang,Chun Li,Fei Yu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Hölder散度和互信息增强知识转移的鲁棒脑肿瘤分割方法，能够在MRI模态缺失的情况下实现高精度分割。


<details>
  <summary>详细信息</summary>
研究动机: 多模态MRI为脑肿瘤分割提供了关键互补信息，但传统方法在模态缺失时表现不佳。本文旨在解决这一问题，提出一种鲁棒的单模态并行处理框架。

研究方法: 利用Hölder散度和互信息，模型在保持模态特定特征的同时，动态调整网络参数以适应输入模态的缺失。通过基于散度和信息的损失函数，量化预测与真实标签的差异。

研究结果: 在BraTS 2018和BraTS 2020数据集上的实验表明，该方法在模态缺失情况下优于现有方法，实现了高精度分割。

研究结论: 本文提出的框架通过Hölder散度和互信息增强知识转移，显著提升了脑肿瘤分割在模态缺失情况下的鲁棒性和准确性。

中文摘要: 多模态MRI为脑肿瘤的准确分割提供了关键的互补信息。然而，传统方法在图像质量、协议不一致、患者过敏或经济限制等原因导致某些模态缺失时表现不佳。为解决这一问题，我们提出了一种鲁棒的单模态并行处理框架，即使在模态不完整的情况下也能实现高精度的分割。通过利用Hölder散度和互信息，我们的模型在保持模态特定特征的同时，根据可用输入动态调整网络参数。通过使用这些基于散度和信息的损失函数，该框架能够有效量化预测与真实标签之间的差异，从而实现一致准确的分割。在BraTS 2018和BraTS 2020数据集上的广泛评估表明，该方法在处理缺失模态方面优于现有方法。

</details>


### [48] [AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation](https://arxiv.org/abs/2507.01255)
**中文标题：AIGVE-MACS：AI生成视频评估的统一多角度评论与评分模型**

*Xiao Liu,Jiawei Zhang*

主要分类: cs.CV

摘要简述: 本文提出AIGVE-MACS模型，用于AI生成视频的评估，不仅能提供数值评分，还能生成多方面的语言评论，显著提升了评估的全面性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成视频模型的快速发展，现有评估指标仅提供数值评分，缺乏解释性评论，导致可解释性和与人类评估的一致性较低。为解决这一问题，本文提出了AIGVE-MACS模型。

研究方法: AIGVE-MACS基于AIGVE-BENCH 2基准数据集（包含2500个AI生成视频和22500条人类标注的详细评论与评分），结合视觉语言模型、新型token加权损失和动态帧采样策略，以更好地与人类评估对齐。

研究结果: 实验表明，AIGVE-MACS在评分相关性和评论质量上均达到最先进水平，显著优于GPT-4o和VideoScore等基线模型。此外，通过多智能体优化框架，视频生成质量提升了53.5%。

研究结论: AIGVE-MACS为AI生成视频的全面、人类对齐评估建立了新范式，并公开了AIGVE-BENCH 2数据集和模型。

中文摘要: AI生成视频模型的快速发展催生了对稳健且可解释的评估框架的迫切需求。现有指标仅能生成数值评分而缺乏解释性评论，导致可解释性和与人类评估的一致性较低。为解决这些问题，我们提出了AIGVE-MACS，一种用于AI生成视频评估（AIGVE）的统一模型，不仅能提供数值评分，还能在评估这些生成视频时提供多方面的语言评论反馈。我们的方法的核心是AIGVE-BENCH 2，这是一个包含2500个AI生成视频和22500条人类标注的详细评论与评分的大规模基准数据集，涵盖九个关键评估方面。基于AIGVE-BENCH 2，AIGVE-MACS结合了最新的视觉语言模型、新型token加权损失和动态帧采样策略，以更好地与人类评估对齐。在监督和零样本基准上的全面实验表明，AIGVE-MACS在评分相关性和评论质量上均达到最先进水平，显著优于包括GPT-4o和VideoScore在内的先前基线模型。此外，我们还展示了一个多智能体优化框架，其中AIGVE-MACS的反馈驱动了视频生成的迭代改进，使质量提升了53.5%。这项工作为AI生成视频的全面、人类对齐评估建立了新范式。我们已在https://huggingface.co/xiaoliux/AIGVE-MACS上发布了AIGVE-BENCH 2和AIGVE-MACS。

</details>


### [49] [Advancements in Weed Mapping: A Systematic Review](https://arxiv.org/abs/2507.01269)
**中文标题：杂草制图进展：系统综述**

*Mohammad Jahanbakht,Alex Olsen,Ross Marchant,Emilie Fillols,Mostafa Rahimi Azghadi*

主要分类: cs.CV

摘要简述: 本文系统综述了杂草制图领域的最新进展，重点探讨了数据获取、处理和制图技术的现状，为未来研究和可持续杂草管理提供了参考。


<details>
  <summary>详细信息</summary>
研究动机: 杂草制图在精准管理中至关重要，但缺乏全面的文献综述，尤其是从数据获取到处理技术和制图工具的全流程分析。本文旨在填补这一空白，推动领域发展。

研究方法: 遵循PRISMA指南，系统分析了杂草制图的最新技术，包括数据获取（传感器与平台技术）、数据处理（标注与建模）和制图技术（时空分析与决策支持工具）。

研究结果: 综述总结了杂草制图的关键技术和方法，提升了空间和时间分辨率，支持了精准管理决策，为高效、可扩展和可持续的杂草管理系统奠定了基础。

研究结论: 本文为杂草制图领域提供了全面的参考，指导未来研究并促进可持续杂草管理系统的开发。

中文摘要: 杂草制图在精准管理中扮演关键角色，通过提供准确及时的杂草分布数据，实现针对性控制和减少除草剂使用，从而降低环境影响、支持可持续土地管理，并改善农业和自然环境的成果。近年来，杂草制图技术利用地面车辆的RGB相机、卫星和无人机遥感，结合光谱、近红外和热成像等传感器，取得了显著进展。通过大数据分析和机器学习等先进技术处理数据，显著提升了杂草制图的空间和时间分辨率，支持了精准管理决策。尽管该领域研究日益增多，但缺乏专门针对杂草制图的全面文献综述，尤其是从数据获取到处理技术和制图工具的全流程分析。本文通过系统研究数据获取（传感器与平台技术）、数据处理（包括标注与建模）和制图技术（如时空分析与决策支持工具）的最新方法，填补了这一空白。遵循PRISMA指南，本文批判性地评估并综合了文献中的关键发现，为杂草制图领域提供了全面的理解。本综述作为基础性参考，指导未来研究并支持高效、可扩展和可持续的杂草管理系统的开发。

</details>


### [50] [Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing](https://arxiv.org/abs/2507.01275)
**中文标题：基于频域的扩散模型用于无配对图像去雾**

*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于频域的扩散模型（\ours），用于无配对图像去雾，通过振幅残差编码器（ARE）和相位校正模块（PCM）实现频域重建，显著提升了去雾效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无配对图像去雾方法基于对比学习，不仅引入了与雾无关的内容信息，还忽略了频域中雾相关的特性（如振幅谱中的退化表现）。本文旨在解决这些问题。

研究方法: 提出了一种频域扩散模型，利用振幅残差编码器（ARE）提取振幅残差以弥补雾域到清晰域的振幅差距，并通过相位校正模块（PCM）优化相位谱以减少伪影。

研究结果: 实验结果表明，\ours在合成和真实数据集上均优于其他最先进方法。

研究结论: 本文提出的频域扩散模型通过频域重建和相位校正，显著提升了无配对图像去雾的性能。

中文摘要: 无配对图像去雾因其在模型训练中对数据要求的灵活性而受到越来越多的关注。基于对比学习的主流方法不仅引入了与雾无关的内容信息，还忽略了频域中雾相关的特性（即雾相关的退化主要表现在振幅谱中）。为了解决这些问题，我们提出了一种新颖的基于频域的扩散模型（\ours），以充分利用无配对清晰数据中的有益知识。具体而言，受扩散模型（DMs）强大生成能力的启发，我们从频域重建的角度解决去雾任务，并利用DMs生成与清晰图像分布一致的振幅谱。为实现这一点，我们提出了振幅残差编码器（ARE）来提取振幅残差，有效弥补了从雾域到清晰域的振幅差距，并为DMs训练提供了监督。此外，我们还提出了相位校正模块（PCM），通过简单的注意力机制进一步优化去雾过程中的相位谱以消除伪影。实验结果表明，我们的\ours在合成和真实数据集上均优于其他最先进方法。

</details>


### [51] [Learning an Ensemble Token from Task-driven Priors in Facial Analysis](https://arxiv.org/abs/2507.01290)
**中文标题：基于任务先验的面部分析中学习集成令牌**

*Sunyong Seo,Semin Kim,Jongha Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ET-Fuser的新方法，通过利用基于任务先验的注意力机制，学习面部分析中的集成令牌，显著提升了特征表示效果。


<details>
  <summary>详细信息</summary>
研究动机: 面部分析中不同任务的特征存在差异，现有方法在单任务学习中缺乏统一的特征表示。本文旨在通过集成令牌的方法解决这一问题。

研究方法: ET-Fuser利用预训练模型的任务先验，通过自注意力机制生成集成令牌，共享预训练编码器的互信息，计算成本极低。

研究结果: 实验结果表明，该方法在多种面部分析任务中均取得了显著改进，特征表示效果优于传统方法。

研究结论: ET-Fuser通过集成令牌的方法，高效地统一了面部分析任务中的特征表示，为相关研究提供了新思路。

中文摘要: 面部分析表现出任务特定的特征变化。尽管卷积神经网络（CNN）能够精细表示空间信息，而视觉变换器（ViT）则促进了补丁级别的语义信息表示。尽管传统方法的泛化能力提升了视觉可解释性，但在训练过程中保持单任务学习的统一特征表示的研究仍然不足。本文提出ET-Fuser，一种通过利用基于预训练模型任务先验的注意力机制学习集成令牌的新方法。具体而言，我们提出了一种鲁棒的先验统一学习方法，在自注意力机制中生成集成令牌，共享预训练编码器的互信息。这种集成令牌方法具有高效率且计算成本极低。实验结果表明，该方法在多种面部分析任务中均取得了改进，特征表示效果显著提升。

</details>


### [52] [DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting](https://arxiv.org/abs/2507.01305)
**中文标题：DiffusionLight-Turbo：通过单次铬球修复实现免费加速光探针**

*Worameth Chinchuthakun,Pakkapon Phongthawee,Amit Raj,Varun Jampani,Pramook Khungurn,Supasorn Suwajanakorn*

主要分类: cs.CV

摘要简述: 本文提出了一种通过单次铬球修复任务从低动态范围（LDR）图像中估计光照的简单有效方法，利用预训练的扩散模型Stable Diffusion XL，并通过迭代修复生成稳定的光照先验。进一步提出DiffusionLight-Turbo，将运行时间从30分钟缩短至30秒，实现60倍加速。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖有限的HDR全景数据集，泛化能力不足。本文旨在通过扩散模型解决这一问题，并克服扩散模型在生成高动态范围（HDR）铬球时的内容不一致性和格式限制。

研究方法: 首先提出DiffusionLight，通过迭代修复生成多个铬球的中值作为稳定的低频光照先验，并利用Exposure LoRA生成多曝光LDR图像以合并为HDR光探针。进一步提出DiffusionLight-Turbo，通过训练Turbo LoRA直接预测迭代过程的平均铬球，并结合LoRA交换技术实现单次去噪推理。

研究结果: 实验结果表明，该方法在多样化场景中生成逼真的光照估计，并在真实场景中表现出优异的泛化能力。DiffusionLight-Turbo将运行时间从30分钟缩短至30秒，质量损失极小。

研究结论: 本文通过扩散模型和LoRA技术，提出了一种高效且泛化能力强的光照估计方法，DiffusionLight-Turbo显著提升了计算效率，适用于实际应用。

中文摘要: 我们提出了一种简单而有效的技术，通过将任务重新定义为铬球修复问题，从单张低动态范围（LDR）图像中估计光照。该方法利用预训练的扩散模型Stable Diffusion XL，克服了依赖有限HDR全景数据集的现有方法的泛化失败问题。尽管概念简单，但任务仍具挑战性，因为扩散模型常生成不正确或不一致的内容，且难以直接生成HDR格式的铬球。我们的分析表明，修复过程对扩散初始噪声高度敏感，偶尔会导致不真实的输出。为此，我们首先提出DiffusionLight，通过迭代修复计算多个输出的中值铬球，作为稳定的低频光照先验，指导生成高质量最终结果。为生成高动态范围（HDR）光探针，我们微调了Exposure LoRA以创建多曝光LDR图像并合并。尽管有效，DiffusionLight耗时约30分钟每次估计。为减少开销，我们提出DiffusionLight-Turbo，将运行时间缩短至约30秒且质量损失极小。这一60倍加速通过训练Turbo LoRA直接预测迭代过程的平均铬球实现，并利用LoRA交换技术将推理简化为单次去噪。实验结果表明，我们的方法在多样化场景中生成逼真的光照估计，并在真实场景中表现出优异的泛化能力。代码发布于https://diffusionlight.github.io/turbo。

</details>


### [53] [Physics-informed Ground Reaction Dynamics from Human Motion Capture](https://arxiv.org/abs/2507.01340)
**中文标题：基于物理信息的人体运动捕捉地面反作用动力学**

*Cuong Le,Huy-Phuong Le,Duc Le,Minh-Thien Duong,Van-Binh Nguyen,My-Ha Le*

主要分类: cs.CV

摘要简述: 本文提出了一种基于物理定律和计算模拟的新方法，直接从可靠的运动捕捉数据中估计人体地面反作用力动力学，避免了传统力板设备的限制，并通过物理约束提升了深度学习模型的估计精度。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法依赖实验室中的力板设备获取人体动力学数据，限制了研究的广泛性。本文旨在通过运动捕捉数据和物理定律的结合，摆脱对力板的依赖，提升地面反作用力估计的准确性和适用性。

研究方法: 提出了一种结合欧拉积分方案和PD算法的高精度方法，直接从运动捕捉数据计算地面反作用力。通过物理约束的动力学信息指导学习模型，提升估计精度。

研究结果: 在GroundLink数据集上的测试表明，该方法在地面反作用力估计精度和模拟根轨迹精度上均优于基线模型。

研究结论: 本文方法通过物理约束和运动捕捉数据的结合，显著提升了地面反作用力估计的准确性和鲁棒性，为人体动力学研究提供了更灵活的工具。

中文摘要: 人体动力学是分析人体运动的关键信息，广泛应用于生物力学、运动科学、计算机视觉和图形学等领域。传统方法通过力板设备同步采集运动捕捉数据，并利用黑盒深度学习模型估计动力学。然而，力板作为专用设备仅能安装在实验室中，限制了人体动力学的研究。为此，我们提出了一种直接从可靠的运动捕捉数据中估计地面反作用动力学的新方法，以物理定律和计算模拟为约束。我们引入了一种基于欧拉积分方案和PD算法的高精度方法，从运动捕捉数据计算地面反作用力。物理约束的反作用力用于指导学习模型，提升动力学估计的准确性。该方法在GroundLink数据集上测试，在地面反作用力估计精度和模拟根轨迹精度上均优于基线模型。实现代码已开源：https://github.com/cuongle1206/Phys-GRD

</details>


### [54] [Learning Camera-Agnostic White-Balance Preferences](https://arxiv.org/abs/2507.01342)
**中文标题：学习相机无关的白平衡偏好**

*Luxi Zhao,Mahmoud Afifi,Michael S. Brown*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级方法，通过学习相机无关的白平衡偏好映射，将中性白平衡校正转换为美学偏好的校正，实现了跨相机的一致性和风格化色彩渲染。


<details>
  <summary>详细信息</summary>
研究动机: 商业自动白平衡（AWB）系统通常追求美学偏好而非中性色彩校正，且现有学习型方法难以跨相机传感器泛化。本文旨在解决美学一致性问题，提出一种相机无关的解决方案。

研究方法: 通过学习一种后光照估计映射，将中性白平衡校正转换为美学偏好的校正。该方法轻量级，仅含约500个参数，可在移动设备上快速运行。

研究结果: 在包含三个不同相机拍摄的771张智能手机图像数据集上，该方法实现了最先进的性能，同时与现有跨相机AWB技术完全兼容，计算和内存开销极小。

研究结论: 本文方法能够在跨相机场景中实现美学一致的白平衡校正，为智能手机多摄像头系统提供了一种高效且兼容性强的解决方案。

中文摘要: 现代相机中的图像信号处理器（ISP）流水线包含多个模块，将原始传感器数据转换为显示色彩空间中的视觉愉悦图像。其中，自动白平衡（AWB）模块对补偿场景光照至关重要。然而，商业AWB系统通常追求美学白平衡偏好而非准确的中性色彩校正。尽管基于学习的方法提高了AWB准确性，但它们通常难以在不同相机传感器间泛化——这对配备多摄像头的智能手机是一个问题。最近的研究探索了跨相机AWB，但大多数方法仍专注于实现中性白平衡。相比之下，本文首次通过在后光照估计阶段学习一种映射，将中性光照校正转换为相机无关空间中的美学偏好校正，从而解决美学一致性问题。训练完成后，该映射可应用于任何中性AWB模块后，实现对未见相机的风格化色彩渲染。所提模型轻量级——仅含约500个参数——在典型旗舰移动CPU上仅需0.024毫秒即可运行。在包含三个不同相机拍摄的771张智能手机图像数据集上评估，该方法实现了最先进的性能，同时完全兼容现有跨相机AWB技术，计算和内存开销极小。

</details>


### [55] [Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation](https://arxiv.org/abs/2507.01347)
**中文标题：从随机子空间探索中学习：基于自监督蒸馏的通用测试时间增强方法**

*Andrei Jelea,Ahmed Nabil Belbachir,Marius Leordeanu*

主要分类: cs.CV

摘要简述: 本文提出了一种通用的测试时间增强方法（GTTA），通过随机扰动PCA子空间投影生成鲁棒集成，并结合自监督蒸馏降低计算成本，适用于多种视觉和非视觉任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有测试时间增强方法通用性不足，且计算成本高。本文旨在提出一种通用且高效的方法，适用于多种任务，同时降低测试时间计算开销。

研究方法: GTTA通过随机扰动PCA子空间投影生成多个增强样本，形成鲁棒集成；随后利用集成输出作为无监督教师，通过自监督学习训练初始模型，减少测试时间计算成本。

研究结果: 实验表明，GTTA在图像分类、分割、语音识别和房价预测等任务中表现优异，并在低能见度水下视频的三文鱼分割与检测任务中验证了其有效性。

研究结论: GTTA是一种通用且高效的测试时间增强方法，显著提升了模型性能，同时降低了计算成本，适用于多种实际任务。

中文摘要: 本文提出了通用测试时间增强方法（GTTA），这是一种高效提升训练模型性能的方法，与现有测试时间增强方法不同，GTTA具有通用性，可直接用于多种视觉和非视觉任务，如分类、回归、图像分割和目标检测。通过应用一种新的通用数据变换方法，即随机多次扰动测试输入的PCA子空间投影，GTTA在测试时形成鲁棒集成，利用其良好的统计特性滤除初始输入数据的结构和系统噪声，从而减少最终估计误差。与其他方法不同，我们还提出了一种自监督学习阶段，将集成输出作为无监督教师，用于训练初始单学生模型，从而在不损失精度的情况下显著降低测试时间计算成本。我们在多种视觉和非视觉任务（如图像分类与分割、语音识别和房价预测）上进行了测试，并与现有TTA方法和SoTA模型进行了比较，验证了GTTA的通用性。此外，我们还证明了其在低能见度水下视频中三文鱼分割与检测这一具体实际任务中的有效性，并为此提出了文献中同类最大的数据集DeepSalmon。

</details>


### [56] [Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model](https://arxiv.org/abs/2507.01351)
**中文标题：面向大型视觉-语言模型混合专家的长尾分布感知路由器**

*Chaoxiang Cai,Longrong Yang,Kaibing Chen,Fan Yang,Xi Li*

主要分类: cs.CV

摘要简述: 本文提出了一种长尾分布感知路由器（LTDR），用于解决视觉-语言混合专家模型（MoE）中的模态分布差异问题，通过针对视觉和语言的不同分布设计路由策略，并增强视觉尾部令牌的专家激活。


<details>
  <summary>详细信息</summary>
研究动机: 现有的混合专家框架（MoE）在视觉-语言模型中主要关注令牌到专家的路由（TER），但忽略了视觉和语言模态之间的分布差异。视觉TER呈现长尾分布，而语言TER则接近均匀分布，因此需要针对不同模态设计专门的路由策略。

研究方法: 提出长尾分布感知路由器（LTDR），包括两部分：1）针对视觉和语言模态的不同分布设计模态特定的路由策略；2）通过类似过采样的方法增加视觉尾部令牌的激活专家数量，以提升其处理效果。

研究结果: 在多个基准测试上的实验验证了LTDR的有效性，表明其能够显著提升视觉-语言混合专家模型的性能。

研究结论: LTDR通过考虑模态分布差异和增强视觉尾部令牌的专家激活，为视觉-语言混合专家模型提供了一种更高效的路由解决方案。

中文摘要: 混合专家（MoE）通过稀疏架构替代密集模型，在大型视觉-语言模型（LVLM）中因其以较少的激活参数实现可比性能而受到关注。现有的LVLM MoE框架主要关注令牌到专家的路由（TER），鼓励不同专家处理不同的令牌。然而，这些框架通常依赖于负载平衡机制，忽略了视觉和语言之间的固有分布差异。为此，我们提出了一种长尾分布感知路由器（LTDR），用于视觉-语言TER，解决两个挑战：（1）针对模态特定路由的分布感知路由器。我们观察到语言TER遵循均匀分布，而视觉TER呈现长尾分布，这种差异需要为每种模态设计不同的路由策略。（2）增强视觉尾部令牌的专家激活。认识到视觉尾部令牌的重要性，我们引入了一种类似过采样的策略，通过增加这些令牌的激活专家数量。在多个基准测试上的实验验证了我们方法的有效性。

</details>


### [57] [3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation](https://arxiv.org/abs/2507.01367)
**中文标题：基于3D高斯泼溅的多视角鲁棒物理对抗伪装生成**

*Tianrui Lou,Xiaojun Jia,Siyuan Liang,Jiawei Liang,Ming Zhang,Yanjun Xiao,Xiaochun Cao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于3D高斯泼溅（3DGS）的物理攻击框架PGA，通过快速精确的3D重建和逼真渲染，生成多视角鲁棒的物理对抗伪装，显著提升了对抗效果和跨视角鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的物理对抗攻击方法依赖目标物体的网格先验和模拟器构建的虚拟环境，耗时且与真实世界存在差异，导致对抗效果和跨视角鲁棒性不足。

研究方法: PGA框架利用3D高斯泼溅技术实现快速精确的3D重建，并通过防止高斯之间的相互遮挡和自遮挡，结合最小-最大优化方法调整每个视角的成像背景，过滤非鲁棒对抗特征。

研究结果: 大量实验验证了PGA在对抗效果和跨视角鲁棒性上的优越性，显著优于现有方法。

研究结论: PGA框架为物理对抗攻击提供了一种高效且鲁棒的解决方案，适用于复杂物理环境下的多视角攻击场景。

中文摘要: 物理对抗攻击方法揭示了深度神经网络的脆弱性，对自动驾驶等安全关键场景构成重大威胁。与基于补丁的攻击相比，基于伪装的物理攻击在复杂物理环境中具有更强的对抗效果。然而，现有方法大多依赖目标物体的网格先验和模拟器构建的虚拟环境，这些方法耗时且与真实世界存在差异。此外，由于训练图像背景的限制，现有方法难以生成多视角鲁棒的对抗伪装，容易陷入次优解。为此，我们提出了一种基于3D高斯泼溅（3DGS）的物理攻击框架PGA，该框架通过少量图像实现快速精确的3D重建，并具备逼真的渲染能力。通过防止高斯之间的相互遮挡和自遮挡，并结合最小-最大优化方法调整每个视角的成像背景，PGA进一步提升了跨视角鲁棒性和对抗效果，帮助算法过滤非鲁棒对抗特征。大量实验验证了PGA的有效性和优越性。代码已开源：https://github.com/TRLou/PGA。

</details>


### [58] [Activation Reward Models for Few-Shot Model Alignment](https://arxiv.org/abs/2507.01368)
**中文标题：激活奖励模型：用于少样本模型对齐**

*Tianning Chai,Chancharik Mitra,Brandon Huang,Gautam Rajendrakumar Gare,Zhiqiu Lin,Assaf Arbelle,Leonid Karlinsky,Rogerio Feris,Trevor Darrell,Deva Ramanan,Roei Herzig*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“激活奖励模型”（Activation RMs）的新方法，用于少样本奖励建模，通过激活导向生成对齐信号，无需额外微调，显著优于现有方法，并在防止奖励攻击行为上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统奖励建模方法难以适应新偏好，需依赖大规模数据集和额外模型微调。本文旨在解决这一问题，提出一种少样本奖励建模方法，以更高效的方式对齐大语言模型和多模态模型的人类偏好。

研究方法: 提出激活奖励模型（Activation RMs），利用激活导向技术构建对齐信号，仅需少量监督且无需额外模型微调。该方法在标准奖励建模基准上优于现有少样本方法，如基于上下文学习的LLM-as-a-judge和投票评分。

研究结果: 激活奖励模型在标准奖励建模任务中表现优异，显著优于现有方法。此外，在防止奖励攻击行为的测试中，该方法表现突出，并在新提出的PreferenceHack基准上达到最先进水平，甚至超越GPT-4o。

研究结论: 激活奖励模型为少样本奖励建模提供了一种高效且无需额外微调的方法，显著提升了模型对齐人类偏好的能力，尤其在安全关键应用中表现出色。

中文摘要: 对齐大语言模型（LLMs）和大规模多模态模型（LMMs）的人类偏好是提升模型生成输出质量的核心挑战。传统方法通常通过奖励建模编码偏好，并利用强化学习进行后训练对齐。然而，传统奖励建模难以适应新偏好，因为它需要依赖大规模偏好数据集训练的独立奖励模型。为解决这一问题，我们提出了激活奖励模型（Activation RMs）——一种新型少样本奖励建模方法，利用激活导向技术构建对齐信号，仅需少量监督且无需额外模型微调。在标准奖励建模基准上，激活奖励模型优于现有少样本方法，如基于上下文学习的LLM-as-a-judge、投票评分和标记概率评分。此外，我们展示了激活奖励模型在防止奖励攻击行为上的有效性，突显了其在安全关键应用中的价值。为此，我们提出了PreferenceHack——首个以配对偏好形式测试奖励攻击行为的少样本基准。最终，激活奖励模型在该基准上达到了最先进水平，甚至超越了GPT-4o。

</details>


### [59] [Active Measurement: Efficient Estimation at Scale](https://arxiv.org/abs/2507.01372)
**中文标题：主动测量：大规模高效估计**

*Max Hamilton,Jinlin Lai,Wenlong Zhao,Subhransu Maji,Daniel Sheldon*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“主动测量”的人机协作AI框架，用于高效且精确的科学测量，通过重要性采样和蒙特卡洛估计减少人工标注需求并提升测量精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI在科学发现中的应用虽能处理海量数据，但缺乏准确性和统计保证。本文旨在解决这一问题，提出一种结合人类标注与AI预测的框架，以实现高效且可靠的测量。

研究方法: 提出“主动测量”框架，利用AI模型预测单元测量值，并通过重要性采样选择样本进行人工标注。通过迭代优化模型和蒙特卡洛估计，逐步提升测量精度。

研究结果: 实验表明，主动测量在多个测量任务中显著降低了估计误差，且能在AI模型不完美时仍提供精确估计。

研究结论: 主动测量是一种高效且可靠的科学测量方法，能够在减少人工标注的同时提供高精度测量结果，为科学发现提供了新的工具。

中文摘要: AI有潜力通过分析海量数据以极低人力成本推动科学发现。然而，当前的工作流程往往无法提供所需的准确性或统计保证。我们提出了主动测量，一种人机协作的AI框架，用于科学测量。该框架利用AI模型预测单个单元的测量值，并通过重要性采样选择样本进行人工标注。随着每批新的人工标注数据，AI模型得以优化，并通过蒙特卡洛估计逐步提升总体测量的无偏性。主动测量即使在AI模型不完美时也能提供精确估计，并在模型高度准确时大幅减少人力需求。我们推导了新的估计器、加权方案和置信区间，并证明主动测量在多个测量任务中优于其他方法，显著降低了估计误差。

</details>


### [60] [MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing](https://arxiv.org/abs/2507.01384)
**中文标题：MUG：基于伪标签增强的音频-视觉Mamba网络用于音频-视觉视频解析**

*Langyu Wang,Bingke Zhu,Yingying Chen,Yiyuan Zhang,Ming Tang,Jinqiao Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MUG的音频-视觉Mamba网络，通过伪标签增强技术提升弱监督音频-视觉视频解析任务中的段级和事件级预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的弱监督音频-视觉视频解析方法在段级和事件级预测上存在不足，主要受限于弱监督条件和模型架构缺陷。本文旨在通过伪标签增强和音频-视觉Mamba网络解决这些问题。

研究方法: MUG通过基于先前工作生成伪标签，并进行跨模态随机组合生成新数据，以增强模型解析不同段级事件组合的能力。同时，采用音频-视觉Mamba网络进行特征处理和交互，提升感知能力并排除模态噪声。

研究结果: 实验表明，MUG在LLP数据集上所有指标均优于现有方法，例如视觉段级和音频段级指标分别提升2.1%和1.2%。

研究结论: MUG通过伪标签增强和音频-视觉Mamba网络，显著提升了弱监督音频-视觉视频解析任务的性能，为未来研究提供了新思路。

中文摘要: 弱监督音频-视觉视频解析（AVVP）旨在预测所有模态特定事件并定位其时间边界。尽管已有显著进展，但由于弱监督的限制和模型架构的缺陷，现有方法在同时提升段级和事件级预测方面仍有不足。本文提出了一种基于伪标签增强的音频-视觉Mamba网络（MUG），以强调每个片段的独特性并排除其他模态的噪声干扰。具体而言，我们基于先前工作标注部分伪标签，并通过单模态伪标签进行跨模态随机组合生成新数据，从而增强模型解析不同段级事件组合的能力。在特征处理和交互方面，我们采用音频-视觉Mamba网络（AV-Mamba），该网络在感知不同片段的同时排除额外模态噪声，同时共享相似模态信息。大量实验表明，MUG在LLP数据集的所有指标上均优于现有方法（例如，视觉段级和音频段级指标分别提升2.1%和1.2%）。代码已开源：https://github.com/WangLY136/MUG。

</details>


### [61] [FixTalk: Taming Identity Leakage for High-Quality Talking Head Generation in Extreme Cases](https://arxiv.org/abs/2507.01390)
**中文标题：FixTalk：在极端情况下抑制身份泄露以生成高质量说话头**

*Shuai Tan,Bill Gong,Bin Ji,Ye Pan*

主要分类: cs.CV

摘要简述: FixTalk提出了一种新框架，通过解耦身份信息和运动特征，并利用泄露的身份信息修复细节，显著提升了极端情况下说话头生成的质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在极端情况下存在身份泄露（IL）和渲染伪影（RA）问题，FixTalk旨在同时解决这两个问题，提升说话头生成的质量。

研究方法: FixTalk提出增强运动指示器（EMI）解耦身份信息与运动特征，减少身份泄露；引入增强细节指示器（EDI）利用泄露的身份信息补充缺失细节，修复伪影。

研究结果: 实验表明，FixTalk有效缓解了身份泄露和渲染伪影，性能优于现有方法。

研究结论: FixTalk通过解耦身份信息和修复细节，显著提升了说话头生成的质量，尤其在极端情况下表现优异。

中文摘要: 说话头生成在各领域的重要性日益凸显，对高质量渲染的需求不断增长。然而，现有方法在极端情况下常出现身份泄露（IL）和渲染伪影（RA）。通过对先前方法的深入分析，我们得出两个关键发现：（1）身份泄露源于运动特征中嵌入的身份信息；（2）这些身份信息可用于解决渲染伪影。基于此，本文提出FixTalk框架，旨在同时解决这两个问题。首先，我们提出增强运动指示器（EMI），有效解耦运动特征中的身份信息，减少身份泄露对生成说话头的影响。为解决渲染伪影，我们引入增强细节指示器（EDI），利用泄露的身份信息补充缺失细节，修复伪影。大量实验证明，FixTalk有效缓解了身份泄露和渲染伪影，性能优于现有方法。

</details>


### [62] [Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps](https://arxiv.org/abs/2507.01397)
**中文标题：基于标准定义地图的连贯在线道路拓扑估计与推理**

*Khanh Son Pham,Christian Witte,Jens Behley,Johannes Betz,Cyrill Stachniss*

主要分类: cs.CV

摘要简述: 本文提出了一种利用标准定义（SD）地图在线构建高清晰度（HD）地图的连贯方法，通过预测车道段及其拓扑关系，结合去噪技术和时间一致性，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 大多数自动驾驶汽车依赖高清晰度（HD）地图，但其在线构建仍具挑战性。本文旨在通过利用标准定义（SD）地图的先验信息，解决HD地图在线构建的复杂性和一致性问题。

研究方法: 提出了一种网络架构，利用混合车道段编码结合先验信息和去噪技术，增强训练稳定性和性能，并通过引入历史帧实现时间一致性。

研究结果: 实验表明，该方法大幅优于现有方法，验证了其建模方案的有效性。

研究结论: 本文提出的方法通过结合SD地图信息和时间一致性，显著提升了HD地图在线构建的连贯性和性能。

中文摘要: 大多数自动驾驶汽车依赖高清晰度（HD）地图。当前研究旨在通过车载传感器直接预测HD地图元素，并推理预测地图与交通元素之间的关系。尽管近期有所进展，但HD地图的连贯在线构建仍是一项挑战性任务，因为它需要以统一且一致的方式建模复杂的道路拓扑。为解决这一挑战，我们提出了一种连贯的方法，利用标准定义（SD）地图的先验信息预测车道段及其拓扑关系，以及道路边界。我们提出了一种网络架构，利用包含先验信息的混合车道段编码和去噪技术，以增强训练稳定性和性能。此外，我们引入历史帧以实现时间一致性。实验评估表明，我们的方法大幅优于现有方法，凸显了建模方案的优势。

</details>


### [63] [Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound](https://arxiv.org/abs/2507.01401)
**中文标题：医学知识驱动的多实例学习用于产前超声中严重腹部异常分类**

*Huanwen Liang,Jingxian Xu,Yuanji Zhang,Yuhao Huang,Yuhan Zhang,Xin Yang,Ran Li,Xuedong Deng,Yanjun Liu,Guowei Tao,Yun Wu,Sheng Zhao,Xinru Gao,Dong Ni*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多实例学习（MIL）的方法，用于产前超声中胎儿腹部异常的病例级分类，无需标准平面定位。通过混合注意力专家模块（MoAE）、医学知识驱动的特征选择模块（MFS）和基于提示的原型学习（PPL），显著提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 胎儿腹部畸形是严重的先天性异常，需要准确诊断以指导妊娠管理和降低死亡率。尽管AI在医学诊断中显示出巨大潜力，但其在产前腹部异常中的应用仍有限。现有研究多关注图像级分类和标准平面定位，而忽视了病例级诊断。

研究方法: 1. 采用混合注意力专家模块（MoAE）为不同平面加权注意力头；2. 提出医学知识驱动的特征选择模块（MFS），将图像特征与医学知识对齐，在病例级进行自监督图像标记选择；3. 提出基于提示的原型学习（PPL）以增强MFS。

研究结果: 在包含2,419个病例、24,748张图像和6个类别的大规模产前腹部超声数据集上验证，所提方法优于现有最佳方法。

研究结论: 本文提出的方法在病例级分类中表现出色，为产前腹部异常的诊断提供了新思路，且无需依赖标准平面定位。

中文摘要: 胎儿腹部畸形是严重的先天性异常，需要准确诊断以指导妊娠管理和降低死亡率。尽管AI在医学诊断中显示出巨大潜力，但其在产前腹部异常中的应用仍有限。现有研究多关注图像级分类和标准平面定位，而忽视了病例级诊断。本文提出了一种基于多实例学习（MIL）的病例级分类方法，无需标准平面定位。我们的贡献有三点：首先，采用混合注意力专家模块（MoAE）为不同平面加权注意力头；其次，提出医学知识驱动的特征选择模块（MFS），将图像特征与医学知识对齐，在病例级进行自监督图像标记选择；最后，提出基于提示的原型学习（PPL）以增强MFS。在包含2,419个病例、24,748张图像和6个类别的大规模产前腹部超声数据集上验证，所提方法优于现有最佳方法。代码已开源：https://github.com/LL-AC/AAcls。

</details>


### [64] [CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning](https://arxiv.org/abs/2507.01409)
**中文标题：CaptionSmiths：灵活控制图像标题生成中的语言模式**

*Kuniaki Saito,Donghyun Kim,Kwanyong Park,Atsushi Hashimoto,Yoshitaka Ushiku*

主要分类: cs.CV

摘要简述: 本文提出CaptionSmiths方法，通过量化标题的长度、描述性和词汇独特性，实现单一模型对多样化语言模式的灵活控制，显著提升了标题生成的准确性和词汇对齐度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的图像标题生成模型难以精细控制生成标题的属性（如长度和描述性），主要因为训练时未将这些属性作为条件，且模型无法平滑切换语言模式。因此，本文旨在解决这一问题，实现更灵活的标题生成。

研究方法: CaptionSmiths方法将标题的长度、描述性和词汇独特性量化为连续标量值，并通过在两个极端状态向量之间插值来表示条件。这种方法无需人工标注，且能平滑调整生成标题的属性。

研究结果: 实验结果表明，CaptionSmiths能平滑改变生成标题的属性，并在词汇对齐度上优于基线模型。例如，该方法在控制标题长度时的误差降低了506%，同时提升了词汇对齐度。

研究结论: CaptionSmiths通过量化标题属性并插值条件向量，实现了单一模型对多样化语言模式的灵活控制，显著提升了生成标题的准确性和适应性。

中文摘要: 能够灵活切换语言模式（如描述性和长度）的图像标题生成模型因其适用于多样化应用而具有重要价值。然而，尽管生成式视觉语言模型取得了显著进展，但由于以下两个原因，对生成标题属性的精细控制仍然困难：（i）现有模型在训练时未将这些属性作为条件；（ii）现有模型无法平滑地从一种语言模式过渡到另一种。针对这一挑战，我们提出了一种新方法CaptionSmiths，以获取能够处理多样化语言模式的单一标题生成模型。首先，我们的方法将每个标题的长度、描述性和词汇独特性量化为连续标量值，无需人工标注。基于这些值，我们通过在两个极端状态向量（如极短标题和极长标题）之间插值来表示条件。实验结果表明，生成的模型能够平滑改变输出标题的属性，并在词汇对齐度上优于基线模型。例如，CaptionSmiths在控制标题长度时的误差降低了506%，同时提升了词汇对齐度。代码将在https://github.com/omron-sinicx/captionsmiths上提供。

</details>


### [65] [Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention](https://arxiv.org/abs/2507.01417)
**中文标题：梯度短接：通过特征干预实现高效的分布外检测**

*Jiawei Gu,Ziyue Qiao,Zechao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种高效的分布外（OOD）检测方法，通过特征干预短接虚假梯度，显著提升检测性能，同时保持分布内（ID）分类的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在开放世界中部署深度学习模型时，分布外（OOD）检测至关重要。研究发现，ID样本的局部梯度方向一致，而OOD样本的梯度方向混乱。基于此，本文提出一种轻量级方法，通过干预特征短接虚假梯度，提升OOD检测效果。

研究方法: 提出了一种推理阶段的技术，短接虚假梯度利用的特征坐标，同时保持ID分类。为减少计算开销，引入局部一阶近似，无需二次前向传播即可准确捕获修改后的输出。

研究结果: 在标准OOD基准测试中，该方法显著提升了检测性能，且方法轻量，对标准推理流程改动极小。

研究结论: 本文提出的梯度短接方法为实际应用中的OOD检测提供了一种高效且实用的解决方案。

中文摘要: 分布外（OOD）检测对于在开放世界中安全部署深度学习模型至关重要，因为输入可能超出训练分布。在仅使用分布内（ID）数据训练的模型上进行推理时，我们观察到一种显著的梯度现象：在ID样本附近，增强其预测类别的局部梯度方向相对一致，而训练中未见的OOD样本在同一邻域内表现出混乱或冲突的梯度方向。基于这一观察，我们提出了一种推理阶段的技术，短接虚假梯度利用的特征坐标以降低OOD置信度，同时基本不影响ID分类。为避免梯度短接后重新计算逻辑值的开销，我们进一步引入了一种局部一阶近似，无需二次前向传播即可准确捕获修改后的输出。标准OOD基准测试表明，该方法显著提升了性能。此外，该方法轻量且对标准推理流程改动极小，为实际应用中的鲁棒OOD检测提供了一条实用路径。

</details>


### [66] [DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal](https://arxiv.org/abs/2507.01422)
**中文标题：DocShaDiffusion：潜在空间中的扩散模型用于文档图像阴影去除**

*Wenjie Liu,Bingshu Wang,Ze Wang,C. L. Philip Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DocShaDiffusion的潜在空间扩散模型，用于文档图像阴影去除。通过设计阴影软掩模生成模块和阴影掩模引导扩散模块，结合阴影鲁棒感知特征损失，有效解决了彩色阴影去除问题，并在公开数据集上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 现有文档图像阴影去除方法通常忽略彩色阴影，且难以在复杂背景下有效去除阴影。本文旨在通过潜在空间扩散模型和专用模块设计，提升彩色阴影去除的效果。

研究方法: 1. 提出DocShaDiffusion模型，将阴影图像从像素空间转换到潜在空间；2. 设计阴影软掩模生成模块（SSGM）生成精确阴影掩模并针对性添加噪声；3. 提出阴影掩模引导扩散模块（SMGDM）监督扩散和去噪过程；4. 引入阴影鲁棒感知特征损失以保留图像细节；5. 构建大规模合成文档彩色阴影去除数据集（SDCSRD）。

研究结果: 在三个公开数据集上的实验表明，DocShaDiffusion在彩色阴影去除任务上优于现有方法，验证了其有效性。

研究结论: DocShaDiffusion通过潜在空间扩散模型和专用模块设计，显著提升了文档图像彩色阴影去除的效果，为文档图像增强提供了新思路。

中文摘要: 文档阴影去除是文档图像增强领域的关键任务。然而，现有方法通常仅能去除恒定颜色背景的阴影，而忽略彩色阴影。本文首次设计了一种潜在空间中的扩散模型DocShaDiffusion，用于文档图像阴影去除。该模型将阴影图像从像素空间转换到潜在空间，使其更易捕捉关键特征。为解决彩色阴影问题，设计了阴影软掩模生成模块（SSGM），可生成精确阴影掩模并针对性添加噪声。在阴影掩模引导下，提出了阴影掩模感知引导扩散模块（SMGDM），通过监督扩散和去噪过程去除文档图像中的阴影。此外，提出了阴影鲁棒感知特征损失以保留文档图像的细节和结构。同时，开发了一个大规模合成文档彩色阴影去除数据集（SDCSRD），模拟真实彩色阴影分布，为模型训练提供有力支持。在三个公开数据集上的实验验证了所提方法优于现有技术。代码和数据集将公开提供。

</details>


### [67] [DiffMark: Diffusion-based Robust Watermark Against Deepfakes](https://arxiv.org/abs/2507.01428)
**中文标题：DiffMark：基于扩散模型的抗Deepfake鲁棒水印**

*Chen Sun,Haiyang Sun,Zhiqing Guo,Yunfeng Diao,Liejun Wang,Dan Ma,Gaobo Yang,Keqin Li*

主要分类: cs.CV

摘要简述: DiffMark是一种基于扩散模型的鲁棒水印框架，旨在对抗Deepfake的面部篡改。通过改进训练和采样方案，结合面部图像和水印条件，生成水印图像，并引入交叉信息融合模块和抗Deepfake引导机制，显著提升了水印的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: Deepfake技术通过恶意面部篡改带来严重的安全和隐私威胁。现有的水印方法在对抗Deepfake篡改时鲁棒性不足，因此需要一种更有效的水印技术来验证真实性和追踪来源。

研究方法: DiffMark通过修改扩散模型的训练和采样方案，将面部图像和水印作为条件，逐步去噪生成水印图像。引入时间步依赖的权重因子调整面部条件强度，并设计交叉信息融合模块自适应提取水印特征。此外，通过冻结自编码器模拟Deepfake篡改，并引入抗Deepfake引导机制增强水印鲁棒性。

研究结果: 实验结果表明，DiffMark在典型Deepfake篡改下表现出色，水印的鲁棒性显著优于现有方法。

研究结论: DiffMark通过扩散模型和抗Deepfake引导机制，成功实现了对抗Deepfake篡改的鲁棒水印生成，为安全验证提供了有效解决方案。

中文摘要: Deepfake通过恶意面部篡改对安全和隐私构成重大威胁。尽管鲁棒水印可用于真实性验证和来源追踪，但现有方法在对抗Deepfake篡改时鲁棒性不足。扩散模型在图像生成中表现优异，能够在生成过程中无缝融合水印。本研究提出了一种基于扩散模型的新型鲁棒水印框架DiffMark。通过修改训练和采样方案，以面部图像和水印为条件，逐步去噪生成水印图像。在面部条件构建中，采用时间步依赖的权重因子逐步降低引导强度，更好地适应扩散模型的采样过程。为实现水印条件的融合，引入交叉信息融合模块，通过可学习的嵌入表自适应提取水印特征，并通过交叉注意力与图像特征结合。为增强水印对抗Deepfake篡改的鲁棒性，训练阶段集成冻结自编码器模拟Deepfake篡改。此外，引入抗Deepfake引导机制，利用特定Deepfake模型对抗性引导扩散采样过程，生成更鲁棒的水印图像。实验结果表明，DiffMark在典型Deepfake篡改下表现优异。代码将在https://github.com/vpsg-research/DiffMark发布。

</details>


### [68] [TurboReg: TurboClique for Robust and Efficient Point Cloud Registration](https://arxiv.org/abs/2507.01439)
**中文标题：TurboReg：基于TurboClique的鲁棒高效点云配准**

*Shaocheng Yan,Pengcheng Shi,Zhenjun Zhao,Kaixin Wang,Kuang Cao,Ji Wu,Jiayuan Li*

主要分类: cs.CV

摘要简述: TurboReg提出了一种基于TurboClique和Pivot-Guided Search（PGS）的高效点云配准方法，显著提升了速度和鲁棒性，并在实验中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于最大团搜索的点云配准方法虽然召回率高，但时间复杂度过高，无法满足实时性需求。TurboReg旨在解决这一问题，提供一种快速且鲁棒的配准方法。

研究方法: TurboReg通过定义轻量级的TurboClique（3-团）和高度可并行的Pivot-Guided Search（PGS）算法，实现了高效的配准。TurboClique在高度约束的兼容性图中确保空间一致性，而PGS通过高SC$^2$分数的匹配对引导搜索，提高内点比例。

研究结果: 实验表明，TurboReg在多个真实数据集上达到了最先进的性能，速度显著提升。例如，在3DMatch+FCGF数据集上，TurboReg（1K）比3DMAC快208.22倍，且召回率更高。

研究结论: TurboReg通过TurboClique和PGS的结合，实现了高效且鲁棒的点云配准，适用于时间敏感的应用场景。

中文摘要: 鲁棒估计是基于对应关系的点云配准（PCR）中的关键问题。现有方法通过在兼容性图中搜索最大团实现高召回率，但时间复杂度呈指数级增长，限制了其在时间敏感场景中的应用。为解决这一问题，我们提出了一种快速且鲁棒的估计器TurboReg，基于新型轻量级团TurboClique和高度可并行的Pivot-Guided Search（PGS）算法。首先，我们将TurboClique定义为高度约束兼容性图中的3-团。3-团的轻量级特性支持高效的并行搜索，而高度约束的兼容性图确保了空间一致性，从而稳定变换估计。其次，PGS选择具有高SC$^2$分数的匹配对作为枢轴，有效引导搜索朝向具有更高内点比例的TurboClique。此外，PGS算法具有线性时间复杂度，显著优于指数时间复杂度的最大团搜索。大量实验表明，TurboReg在多个真实数据集上达到了最先进的性能，并大幅提升了速度。例如，在3DMatch+FCGF数据集上，TurboReg（1K）的运行速度比3DMAC快208.22倍，同时召回率更高。我们的代码可在\href{https://github.com/Laka-3DV/TurboReg}{\texttt{TurboReg}}获取。

</details>


### [69] [OoDDINO:A Multi-level Framework for Anomaly Segmentation on Complex Road Scenes](https://arxiv.org/abs/2507.01455)
**中文标题：OoDDINO：一种用于复杂道路场景异常分割的多级框架**

*Yuxing Liu,Ji Zhang,Zhou Xuchuan,Jingzhong Xiao,Huimin Yang,Jiaxin Zhong*

主要分类: cs.CV

摘要简述: OoDDINO提出了一种多级异常分割框架，通过从粗到细的检测策略解决现有方法在复杂道路场景中异常分割的局限性，结合不确定性引导的检测模型和像素级分割模型，显著提升了分割效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有像素级异常分割方法忽视像素间的空间相关性，导致分割结果碎片化；同时全局阈值策略因区域间异常分数分布差异易产生误判。OoDDINO旨在解决这些问题，提升复杂场景下的异常分割精度。

研究方法: OoDDINO采用两阶段级联架构：1) 提出正交不确定性感知融合策略（OUAFS），整合多不确定性指标与视觉表征，精准定位异常区域；2) 开发自适应双阈值网络（ADT-Net），基于对象级检测结果动态生成区域特定阈值，实现细粒度分割。

研究结果: 在两个基准数据集上的实验表明，OoDDINO优于现有方法，兼容性强，可作为插件提升其他像素级异常检测模型的性能。

研究结论: OoDDINO通过多级框架有效解决了异常分割中的碎片化和阈值适应性问题，为复杂场景下的异常检测提供了高效解决方案。

中文摘要: 异常分割旨在识别图像中的分布外（OoD）异常对象。现有的像素级方法通常单独分配异常分数，并采用全局阈值策略分割异常。尽管有效，这些方法在实际应用中面临显著挑战：1) 忽视同一对象内像素的空间相关性，导致分割碎片化；2) 图像区域间异常分数分布差异，使全局阈值在背景区域产生误报或漏检异常对象部分。本文提出OoDDINO，一种新颖的多级异常分割框架，通过从粗到细的检测策略解决这些限制。OoDDINO将不确定性引导的检测模型与像素级分割模型结合于两阶段级联架构中。首先，提出正交不确定性感知融合策略（OUAFS），依次整合多不确定性指标与视觉表征，利用正交约束增强检测模型对异常区域的准确定位能力。随后，开发自适应双阈值网络（ADT-Net），基于对象级检测结果和像素级异常分数动态生成区域特定阈值，实现前景与背景区域的差异化阈值策略，完成细粒度异常分割。该框架兼容其他像素级异常检测模型，可作为插件提升性能。在两个基准数据集上的大量实验验证了OoDDINO的优越性与兼容性。

</details>


### [70] [NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation](https://arxiv.org/abs/2507.01463)
**中文标题：NOCTIS：基于循环阈值的新型物体实例分割**

*Max Gandyra,Alessandro Santonicola,Michael Beetz*

主要分类: cs.CV

摘要简述: 本文提出了一种名为NOCTIS的新型实例分割框架，旨在无需重新训练即可对RGB图像中的新物体进行实例分割。该方法结合了Grounded-SAM 2和DINOv2的优势，通过改进的匹配评分机制，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 在计算机视觉领域，如何在不重新训练模型的情况下，对RGB图像中的新物体进行实例分割是一个具有挑战性的问题。现有的方法如CNOS、SAM-6D和NIDS-Net虽然取得了一定进展，但仍需进一步优化。本文旨在提出一种更通用且高效的方法来解决这一问题。

研究方法: NOCTIS框架结合了Grounded-SAM 2和DINOv2模型。Grounded-SAM 2用于生成精确的物体边界框和分割掩码，而DINOv2则用于生成图像嵌入。通过计算类嵌入的相似性和基于图像网格中循环/往返补丁距离的补丁过滤，改进了匹配评分机制。此外，还利用边界框和掩码的平均置信度作为额外的权重因子。

研究结果: 实验表明，NOCTIS在BOP 2023挑战赛的七个核心数据集上，无需进一步训练或微调，即在“未见物体的模型基2D分割”任务中优于现有的RGB和RGB-D方法。

研究结论: NOCTIS通过结合先进的视觉基础模型和改进的匹配评分机制，显著提升了新物体实例分割的性能，为计算机视觉领域提供了一种高效且通用的解决方案。

中文摘要: 在RGB图像中对新物体实例进行实例分割是一个众所周知的计算机视觉问题。设计一个足够通用的模型，能够适用于所有类型的新物体而无需（重新）训练，已被证明是一项困难的任务。为此，我们提出了一种简单而强大的框架，称为：基于循环阈值的新型物体实例分割（NOCTIS）。这项工作源于并改进了CNOS、SAM-6D和NIDS-Net等先前的研究；因此，它也利用了最近的视觉基础模型，即Grounded-SAM 2和DINOv2。它利用Grounded-SAM 2获取具有精确边界框的物体提案及其对应的分割掩码；同时利用DINOv2的零样本能力生成图像嵌入。这些掩码的质量及其嵌入对我们的方法至关重要；因为提案-物体匹配是通过基于类嵌入相似性和补丁嵌入的平均最大相似性计算物体匹配分数来实现的。与SAM-6D不同，后者的计算涉及基于图像网格中每个补丁与其对应的循环/往返补丁之间的距离进行补丁过滤。此外，提案边界框和掩码的平均置信度被用作物体匹配分数的额外权重因子。我们通过实验证明，NOCTIS无需进一步训练/微调，即在BOP 2023挑战赛的七个核心数据集上，在“未见物体的模型基2D分割”任务中优于最佳的RGB和RGB-D方法。

</details>


### [71] [Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think](https://arxiv.org/abs/2507.01467)
**中文标题：生成中的表征纠缠：训练扩散变换器比你想象的要容易得多**

*Ge Wu,Shen Zhang,Ruijing Shi,Shanghua Gao,Zhenyuan Chen,Lei Wang,Zhaowei Chen,Hongcheng Gao,Yao Tang,Jian Yang,Ming-Ming Cheng,Xiang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为REG的新方法，通过将低层图像潜在变量与预训练基础模型的高层类别标记纠缠，显著提升了生成质量和训练效率，且推理开销几乎可以忽略。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法（如REPA）通过外部视觉表征对齐缓解扩散模型训练难题，但未能充分利用判别表征的潜力。本文旨在通过表征纠缠方法，更高效地利用预训练模型的表征能力。

研究方法: 提出REG方法，将低层图像潜在变量与预训练基础模型的单个高层类别标记纠缠，实现从纯噪声中生成一致的图像-类别对。该方法在推理过程中同时重建图像潜在变量及其全局语义，语义知识主动指导图像生成。

研究结果: 在ImageNet 256×256上，SiT-XL/2 + REG表现出显著的训练加速效果，比SiT-XL/2和SiT-XL/2 + REPA分别快63倍和23倍。SiT-L/2 + REG仅训练40万次即优于训练400万次的SiT-XL/2 + REPA。

研究结论: REG方法通过表征纠缠显著提升了生成质量和训练效率，且几乎不增加推理开销，为扩散模型的训练提供了更高效的解决方案。

中文摘要: REPA及其变体通过将去噪网络的噪声隐藏投影与基础干净图像表征对齐，有效缓解了扩散模型的训练挑战。然而，这种外部对齐在去噪推理过程中并不存在，未能充分利用判别表征的潜力。本文提出了一种简单的方法，称为生成中的表征纠缠（REG），它将低层图像潜在变量与预训练基础模型的单个高层类别标记纠缠，用于去噪。REG能够直接从纯噪声中生成一致的图像-类别对，显著提升了生成质量和训练效率，且推理开销几乎可以忽略（FLOPs和延迟仅增加<0.5%）。推理过程同时重建图像潜在变量及其全局语义，所获取的语义知识主动指导并增强图像生成过程。在ImageNet 256×256上，SiT-XL/2 + REG表现出显著的收敛加速效果，比SiT-XL/2和SiT-XL/2 + REPA分别快63倍和23倍。更令人印象深刻的是，仅训练40万次的SiT-L/2 + REG优于训练400万次的SiT-XL/2 + REPA（训练时间缩短10倍）。代码发布于：https://github.com/Martinser/REG。

</details>


### [72] [Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware](https://arxiv.org/abs/2507.01472)
**中文标题：优化卫星上的甲烷检测：面向资源受限硬件的速度、精度与低功耗解决方案**

*Jonáš Herec,Vít Růžička,Rado Pitoňák*

主要分类: cs.CV

摘要简述: 本文提出了一种优化卫星上甲烷检测的方法，通过高效低功耗算法（如Mag1c-SAS和CEM）加速检测，并结合机器学习模型（U-Net、LinkNet）提升性能。实验表明，这些方法在资源有限的硬件上可实现比原算法快100倍和230倍的速度，同时保持准确性。


<details>
  <summary>详细信息</summary>
研究动机: 甲烷是一种强效温室气体，通过高光谱卫星图像早期检测其泄漏有助于缓解气候变化。然而，现有任务多依赖手动操作，无法及时捕捉潜在事件。为解决下行链路速率慢的问题，星载检测成为一种可行方案，但传统方法计算需求高，难以在资源有限的硬件上实现。

研究方法: 本文测试了快速目标检测方法（ACE、CEM），并提出Mag1c-SAS（一种更快的Mag1c变体）。此外，结合机器学习模型（U-Net、LinkNet）评估其检测潜力，并提出了三种波段选择策略，以进一步优化处理速度。

研究结果: 实验结果表明，Mag1c-SAS和CEM是两种有前景的候选方法，能够在资源有限的硬件上实现高速检测（分别比原算法快100倍和230倍），同时保持准确性。其中一种波段选择策略在减少通道数的同时，性能优于传统方法。

研究结论: 本研究为星载甲烷检测提供了高效低功耗的解决方案，显著提升了数据处理速度，为未来星载检测技术的发展奠定了基础。所有代码、数据和模型均已开源。

中文摘要: 甲烷是一种强效温室气体，通过高光谱卫星图像早期检测其泄漏有助于缓解气候变化。然而，许多现有任务仅依赖手动操作，可能错过潜在事件。为克服下行链路速率慢的问题，星载检测成为一种可行方案。但传统甲烷增强方法计算需求过高，难以在资源有限的硬件上实现。本研究通过高效低功耗算法加速甲烷检测，测试了快速目标检测方法（ACE、CEM），并提出Mag1c-SAS（一种更快的Mag1c变体）。为评估其检测潜力，将其与机器学习模型（U-Net、LinkNet）结合。结果显示，Mag1c-SAS和CEM是两种有前景的候选方法，适用于强羽流检测，计算效率高，可在资源有限的硬件上分别实现比原算法快约100倍和230倍的速度。此外，提出了三种波段选择策略，其中一种在减少通道数的同时性能优于传统方法，进一步提升了处理速度。本研究为未来星载甲烷检测技术的发展奠定了基础，所有代码、数据和模型均已开源。

</details>


### [73] [Active Control Points-based 6DoF Pose Tracking for Industrial Metal Objects](https://arxiv.org/abs/2507.01478)
**中文标题：基于主动控制点的工业金属物体6自由度位姿跟踪**

*Chentao Shen,Ding Pan,Mingyu Mei,Zaixing He,Xinyue Zhao*

主要分类: cs.CV

摘要简述: 提出了一种基于主动控制点的6自由度位姿跟踪方法，用于解决工业金属物体因反射特性导致的跟踪难题，通过优化边缘特征和引入最优控制点回归方法，提升了跟踪的鲁棒性和实时性。


<details>
  <summary>详细信息</summary>
研究动机: 工业金属物体因其反射特性，在真实环境中的位姿跟踪一直是一个挑战。为了解决这一问题，研究提出了一种新的跟踪方法。

研究方法: 该方法利用图像控制点主动生成边缘特征进行优化，而非基于6自由度位姿的渲染，并将控制点作为优化变量。同时，引入最优控制点回归方法以提高鲁棒性。

研究结果: 该方法在数据集评估和实际任务中均表现优异，为工业金属物体的实时跟踪提供了可行方案。

研究结论: 提出的基于主动控制点的6自由度位姿跟踪方法有效解决了工业金属物体跟踪的难题，具有实际应用价值。

中文摘要: 近年来，视觉位姿跟踪在工业环境中扮演着越来越重要的角色。然而，由于金属物体的反射特性，工业金属物体的位姿跟踪在真实环境中仍然是一个具有挑战性的任务。为了解决这一问题，我们提出了一种基于主动控制点的6自由度位姿跟踪方法。该方法通过图像控制点主动生成边缘特征进行优化，而非基于6自由度位姿的渲染，并将控制点作为优化变量。我们还引入了一种最优控制点回归方法以提高鲁棒性。所提出的跟踪方法在数据集评估和实际任务中均表现优异，为工业金属物体的实时跟踪提供了可行方案。我们的源代码已公开在：https://github.com/tomatoma00/ACPTracking。

</details>


### [74] [What Really Matters for Robust Multi-Sensor HD Map Construction?](https://arxiv.org/abs/2507.01484)
**中文标题：多传感器高精地图构建的鲁棒性关键因素是什么？**

*Xiaoshuai Hao,Yuting Zhao,Yuheng Ji,Luanyuan Dai,Peng Hao,Dingzhe Li,Shuai Cheng,Rong Yin*

主要分类: cs.CV

摘要简述: 本文探讨了如何提升多传感器高精地图构建的鲁棒性，提出了数据增强、新型多模态融合模块和模态丢弃训练策略，实验证明这些方法显著提升了基线模型的鲁棒性，并在NuScenes数据集上达到了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有高精地图构建方法主要关注模型精度，而忽视了鲁棒性，这在现实应用中至关重要。本文旨在通过多模态融合方法提升高精地图构建的鲁棒性，同时保持高精度。

研究方法: 提出了三个关键组件：数据增强、新型多模态融合模块和模态丢弃训练策略，并在包含10天NuScenes数据的挑战性数据集上进行了评估。

研究结果: 实验结果表明，所提方法显著提升了基线模型的鲁棒性，并在NuScenes数据集的干净验证集上达到了最优性能。

研究结论: 本文的研究为开发更鲁棒和可靠的高精地图构建模型提供了有价值的见解，推动了其在现实自动驾驶场景中的应用。

中文摘要: 高精（HD）地图构建方法对于为自动驾驶系统提供精确和全面的静态环境信息至关重要。尽管相机-激光雷达融合技术通过整合两种模态的数据已显示出良好的效果，但现有方法主要关注提升模型精度，而往往忽视了感知模型的鲁棒性，这对实际应用至关重要。本文探讨了如何通过多模态融合方法提升高精地图构建的鲁棒性，同时保持高精度。我们提出了三个关键组件：数据增强、新型多模态融合模块和模态丢弃训练策略。这些组件在一个包含10天NuScenes数据的挑战性数据集上进行了评估。实验结果表明，我们的方法显著提升了基线模型的鲁棒性。此外，我们的方法在NuScenes数据集的干净验证集上达到了最优性能。这些发现为开发更鲁棒和可靠的高精地图构建模型提供了有价值的见解，推动了其在现实自动驾驶场景中的应用。项目网站：https://robomap-123.github.io。

</details>


### [75] [AVC-DPO: Aligned Video Captioning via Direct Preference Optimization](https://arxiv.org/abs/2507.01492)
**中文标题：AVC-DPO：通过直接偏好优化的对齐视频字幕生成**

*Jiyang Tang,Hengyi Li,Yifan Du,Wayne Xin Zhao*

主要分类: cs.CV

摘要简述: 本文提出AVC-DPO框架，通过直接偏好优化提升视频多模态大语言模型的字幕生成能力，使其更符合人类偏好，并在视频详细字幕任务中取得优异表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管视频多模态大语言模型在视频字幕任务中取得进展，但如何根据人类偏好调整字幕焦点仍具挑战性。本文旨在解决这一问题。

研究方法: 提出AVC-DPO框架，设计针对时空动态和空间信息的增强提示，通过偏好感知训练和对齐字幕生成能力。

研究结果: 在LOVE@CVPR'25 Workshop Track 1A视频详细字幕挑战中，AVC-DPO在VDC基准上表现优异，获得第一名。

研究结论: AVC-DPO通过直接偏好优化有效提升了视频字幕生成的对齐能力，为视频多模态任务提供了新思路。

中文摘要: 尽管视频多模态大语言模型（视频MLLMs）在视频字幕任务中取得了显著进展，但如何根据人类偏好调整字幕的焦点仍然是一个挑战。为解决这一局限性，我们提出了通过直接偏好优化的对齐视频字幕生成（AVC-DPO），这是一种后训练框架，旨在通过偏好对齐增强视频MLLMs的字幕生成能力。我们的方法设计了针对时空动态和空间信息的增强提示（人类观看视频时关注的两个关键因素），从而融入以人为中心的偏好。AVC-DPO利用同一基础模型在不同提示条件下的字幕生成响应进行偏好感知训练和字幕对齐。通过这一框架，我们在LOVE@CVPR'25 Workshop Track 1A：视频详细字幕挑战中取得了卓越表现，根据VDCSCORE评估指标，在视频详细字幕（VDC）基准上获得第一名。

</details>


### [76] [Crop Pest Classification Using Deep Learning Techniques: A Review](https://arxiv.org/abs/2507.01494)
**中文标题：基于深度学习技术的农作物害虫分类研究综述**

*Muhammad Hassam Ejaz,Muhammad Bilal,Usman Habib*

主要分类: cs.CV

摘要简述: 本文综述了2018至2025年间37项关于基于深度学习的农作物害虫分类研究，重点分析了CNN、ViT和混合模型的进展，总结了技术挑战和未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 传统害虫监测方法效率低且难以扩展，而深度学习技术如CNN和ViT在害虫分类中展现出潜力，本文旨在系统梳理相关研究进展。

研究方法: 通过筛选37项研究，按作物类型、害虫种类、模型架构、数据集使用和技术挑战进行分类分析。

研究结果: 早期研究多依赖CNN，近年转向混合和Transformer模型，但仍面临数据集不平衡、小害虫检测难、泛化能力有限和边缘设备部署等挑战。

研究结论: 本文为AI害虫监测领域提供了结构化综述，指出了关键挑战和未来发展方向。

中文摘要: 害虫对全球农作物产量构成严重威胁，传统监测方法效率低且难以扩展。近年来，深度学习技术如卷积神经网络（CNN）、视觉Transformer（ViT）和混合模型在害虫自动检测中展现出强大潜力。本文综述了2018至2025年间37项关于AI害虫分类的研究，按作物类型、害虫种类、模型架构、数据集使用和技术挑战进行了分类。早期研究主要依赖CNN，而最新研究转向混合和Transformer模型，以提高准确性和上下文理解能力。然而，数据集不平衡、小害虫检测难、泛化能力有限及边缘设备部署等问题仍是主要挑战。本文为该领域提供了结构化综述，并指出了未来研究方向。

</details>


### [77] [ReFlex: Text-Guided Editing of Real Images in Rectified Flow via Mid-Step Feature Extraction and Attention Adaptation](https://arxiv.org/abs/2507.01496)
**中文标题：ReFlex：通过中步特征提取和注意力调整实现文本引导的真实图像编辑**

*Jimyeong Kim,Jungwon Park,Yeji Song,Nojun Kwak,Wonjong Rhee*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Rectified Flow模型的真实图像编辑方法，通过分析中间表示和注意力调整，实现了无需训练、无需用户掩码的高质量编辑。


<details>
  <summary>详细信息</summary>
研究动机: Rectified Flow模型在图像质量和文本对齐上优于扩散模型，但如何将其应用于真实图像编辑仍具挑战性。本文旨在解决这一问题。

研究方法: 通过分析多模态Transformer块的中间表示，提取关键特征，并利用中步潜在表示和注意力调整技术，提升编辑效果。

研究结果: 在两个基准测试和九种基线方法上的实验表明，该方法优于现有方法，且用户评价证实了其优越性。

研究结论: 本文提出的方法在真实图像编辑中表现出色，无需额外训练或用户输入，具有广泛的应用潜力。

中文摘要: Rectified Flow文本到图像模型在图像质量和文本对齐上超越了扩散模型，但将其应用于真实图像编辑仍具挑战性。我们提出了一种新的真实图像编辑方法，通过分析多模态Transformer块的中间表示并识别三个关键特征。为了从真实图像中提取这些特征并保留足够的结构信息，我们利用了仅反转到中步的潜在表示。随后，通过调整注意力注入以提升可编辑性并增强与目标文本的对齐。我们的方法无需训练，无需用户提供的掩码，甚至可以在没有源提示的情况下应用。在两个基准测试和九种基线方法上的大量实验表明，其性能优于现有方法，并通过用户评价进一步验证了用户对该方法的强烈偏好。

</details>


### [78] [Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images](https://arxiv.org/abs/2507.01502)
**中文标题：结合传统与深度学习方法检测卫星图像中的树冠**

*Ozan Durgut,Beril Kallfelz-Sirmacek,Cem Unsalan*

主要分类: cs.CV

摘要简述: 本文提出了一种结合传统方法和深度学习的树冠检测算法，通过规则后处理提升检测结果的鲁棒性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 全球变暖、生物多样性丧失和空气污染等问题亟需森林监测，而传统和深度学习方法各有优劣，因此需要结合两者以提升树冠检测的效率和准确性。

研究方法: 首先介绍基于传统方法和深度学习的树冠检测方法，然后提出一种规则后处理方法，结合两者的优势：传统方法用于特征提取和森林区域分割，深度学习方法用于树冠检测，最后通过局部操作和邻近树分析提升检测数量。

研究结果: 提出的方法在树冠检测数量上优于单一方法，同时分析了其优缺点和改进空间。

研究结论: 结合传统与深度学习的方法能显著提升树冠检测的准确性和鲁棒性，为森林监测提供了更有效的工具。

中文摘要: 全球变暖、生物多样性丧失和空气污染是地球面临的最严峻问题之一。解决这些问题的关键挑战之一是缺乏对森林的保护监测。为此，利用遥感和计算机视觉方法实现监测自动化至关重要。因此，基于传统和深度学习方法的自动树冠检测算法应运而生。本研究首先介绍了基于这两种方法的不同树冠检测技术，随后提出了一种新颖的基于规则的整合方法，以提升树冠检测结果的鲁棒性和准确性。传统方法用于森林区域的特征提取和分割，深度学习方法用于树冠检测。通过提出的规则后处理方法，我们进一步处理这些结果，旨在通过邻近树和局部操作增加检测到的树冠数量。我们将所提方法的结果与传统方法进行比较，分析了检测树冠数量的差异，并总结了所获结果的优缺点及改进方向。

</details>


### [79] [Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence](https://arxiv.org/abs/2507.01504)
**中文标题：追踪线索：基于跨模态智能的行人重识别实验**

*Robert Aufschläger,Youssef Shoeb,Azarm Nowzad,Michael Heigl,Fabian Bally,Martin Schramm*

主要分类: cs.CV

摘要简述: 本文提出了一种名为cRID的新型跨模态框架，结合大型视觉语言模型和图注意力网络，用于检测文本可描述的个人身份信息（PII）并提升行人重识别（Re-ID）性能。实验表明，该方法在跨数据集场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着街景数据作为开放数据的发布，自动驾驶系统和AI研究得以推进，但这些数据包含大量个人身份信息（PII），对行人隐私构成威胁。现有方法主要关注低层次外观特征，而忽略了语义上有意义的PII。因此，本文旨在开发一种能够检测和利用可解释特征的跨模态框架。

研究方法: cRID框架结合了大型视觉语言模型、图注意力网络和表示学习，专注于检测文本可描述的PII线索，并通过跨模态信息提升行人重识别性能。该方法能够识别语义上有意义的PII，而不仅仅是低层次外观特征。

研究结果: 实验表明，cRID在跨数据集行人重识别任务中表现优异，特别是在从Market-1501到CUHK03-np的数据集迁移场景中，验证了其实际应用价值。

研究结论: cRID框架通过跨模态智能检测语义上有意义的PII，显著提升了行人重识别的性能，为隐私保护和AI研究提供了实用工具。

中文摘要: 街景数据作为开放数据的收集和发布在推动自动驾驶系统和AI研究中扮演重要角色。然而，这些数据集因包含超越生物特征（如人脸）的个人身份信息（PII）而对行人隐私构成显著风险。本文提出cRID，一种结合大型视觉语言模型、图注意力网络和表示学习的新型跨模态框架，用于检测文本可描述的PII线索并提升行人重识别（Re-ID）性能。我们的方法专注于识别和利用可解释特征，从而检测语义上有意义的PII，而不仅仅是低层次外观线索。我们对行人图像数据集中PII的存在进行了系统性评估。实验表明，该方法在跨数据集Re-ID场景中表现优异，特别是在从Market-1501到CUHK03-np的数据集迁移中，凸显了框架的实际应用价值。代码发布于https://github.com/RAufschlaeger/cRID。

</details>


### [80] [Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation](https://arxiv.org/abs/2507.01509)
**中文标题：Mamba引导的边界先验的重要性：广义息肉分割的新视角**

*Tapas K. Dutta,Snehashis Majhi,Deepak Ranjan Nayak,Debesh Jha*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SAM-MaGuP的新方法，通过结合边界蒸馏模块和1D-2D Mamba适配器，显著提升了结肠镜图像中息肉的弱边界分割性能，并在多个数据集上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 息肉分割在结肠镜图像中对结直肠癌的早期检测至关重要，但由于息肉形状、大小和颜色的多样性，以及边界模糊的问题，现有方法在弱边界分割和泛化能力上表现不足。

研究方法: SAM-MaGuP方法在Segment Anything Model（SAM）中引入了边界蒸馏模块和1D-2D Mamba适配器，增强了全局上下文交互，从而解决了弱边界分割的挑战。

研究结果: 在五个多样化数据集上的实验表明，SAM-MaGuP在分割精度和鲁棒性上均优于现有最先进方法。

研究结论: SAM-MaGuP通过Mamba引导的边界先验和1D-2D Mamba块，为息肉分割领域设定了新的基准，显著提升了分割性能。

中文摘要: 结肠镜图像中的息肉分割对结直肠癌的早期检测和诊断至关重要。然而，由于息肉形状、大小和颜色的多样性，以及息肉与周围组织的高度相似性和模糊边界，这一任务仍具有挑战性。现有的基于编码器-解码器CNN和Transformer的方法虽有一定效果，但在弱边界或模糊边界的息肉分割上表现不稳定，且泛化能力不足。为解决这些问题，我们提出了SAM-MaGuP，一种创新的息肉分割方法。通过在Segment Anything Model（SAM）中引入边界蒸馏模块和1D-2D Mamba适配器，SAM-MaGuP能够有效解决弱边界问题，并通过增强的全局上下文交互提升特征学习能力。在五个多样化数据集上的广泛实验表明，SAM-MaGuP在分割精度和鲁棒性上均优于现有方法。我们的核心创新——Mamba引导的边界先验和1D-2D Mamba块，为该领域设定了新的标准，将息肉分割技术推向新高度。

</details>


### [81] [Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights](https://arxiv.org/abs/2507.01532)
**中文标题：探索基于姿态的手语翻译：消融研究与注意力机制分析**

*Tomas Zelezny,Jakub Straka,Vaclav Javorek,Ondrej Valach,Marek Hruz,Ivan Gruber*

主要分类: cs.CV

摘要简述: 本文探讨了基于姿态的手语翻译（SLT）中数据预处理技术（归一化、插值和增强）对性能的影响，通过改进的T5编码器-解码器模型在YouTubeASL和How2Sign数据集上进行消融实验，发现合适的预处理技术能显著提升模型鲁棒性和泛化能力，并揭示了注意力机制的有趣行为。


<details>
  <summary>详细信息</summary>
研究动机: 手语翻译（SLT）从孤立识别方法发展为复杂的连续无注释翻译系统，但仍需优化数据预处理技术以提升性能。本文旨在探索姿态数据预处理（如归一化、插值和增强）对SLT模型的影响。

研究方法: 采用基于Transformer的架构，改进T5编码器-解码器模型处理姿态数据。在YouTubeASL和How2Sign数据集上进行消融实验，分析不同预处理策略（归一化、插值和增强）对翻译准确性的影响。

研究结果: 实验表明，适当的归一化、插值和增强技术能显著提升模型鲁棒性和泛化能力。注意力分析还发现，添加专用寄存器标记可进一步改善模型性能。

研究结论: 姿态数据预处理技术对SLT性能至关重要，改进的T5模型结合适当预处理策略能显著提升翻译效果。注意力机制的分析为未来优化提供了新方向。

中文摘要: 手语翻译（SLT）已从孤立识别方法发展为复杂的连续无注释翻译系统。本文探讨了姿态数据预处理技术（归一化、插值和增强）对SLT性能的影响。我们采用基于Transformer的架构，改进T5编码器-解码器模型处理姿态数据。通过在YouTubeASL和How2Sign数据集上的广泛消融实验，分析了不同预处理策略对翻译准确性的影响。结果表明，适当的归一化、插值和增强技术能显著提升模型鲁棒性和泛化能力。此外，我们对模型的注意力机制进行了深入分析，发现添加专用寄存器标记可改善整体性能。我们在GitHub上公开了代码及预处理后的YouTubeASL数据。

</details>


### [82] [TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking](https://arxiv.org/abs/2507.01535)
**中文标题：TrackingMiM：用于实时无人机目标跟踪的高效Mamba-in-Mamba序列化方法**

*Bingxi Liu,Calvin Chen,Junhao Li,Guyang Yu,Haoqian Song,Xuchen Liu,Jinqiang Cui,Hong Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为TrackingMiM的高效Mamba-in-Mamba架构，用于实时无人机目标跟踪，解决了现有Mamba方法中时间不一致性问题，并在多个基准测试中实现了最优精度和速度。


<details>
  <summary>详细信息</summary>
研究动机: 视觉Transformer（ViT）模型在处理无人机（UAV）跟踪任务时面临二次复杂度的挑战，难以满足实时性需求。本研究利用状态空间模型Mamba的计算效率和长序列建模能力，旨在解决现有Mamba方法中时间连续性不足的问题。

研究方法: 提出TrackingMiM架构，采用嵌套式Mamba扫描机制，独立处理时间和空间相关的图像块标记，同时将模板帧编码为查询标记以支持跟踪任务。

研究结果: 在五个无人机跟踪基准测试中，TrackingMiM实现了最优的跟踪精度，并显著提升了处理速度。

研究结论: TrackingMiM通过创新的嵌套Mamba扫描机制，有效解决了时间连续性问题，为实时无人机跟踪提供了一种高效且高性能的解决方案。

中文摘要: 视觉Transformer（ViT）模型长期以来面临二次复杂度的挑战，这一限制在无人机（UAV）跟踪系统中尤为关键，因为数据需要实时处理。本研究探索了最近提出的状态空间模型Mamba，利用其计算效率和长序列建模能力，有效处理跟踪任务中的密集图像序列。首先，我们指出了现有基于Mamba的方法中时间不一致性问题，特别是Mamba扫描机制未考虑时间连续性。其次，基于这一发现，我们提出了TrackingMiM，一种Mamba-in-Mamba架构，这是一种计算负担极小的模型，用于处理跟踪问题的图像序列。在我们的框架中，Mamba扫描以嵌套方式执行，同时独立处理时间和空间相关的图像块标记，而模板帧被编码为查询标记并在每次扫描中用于跟踪。在五个无人机跟踪基准测试上进行的大量实验证实，所提出的TrackingMiM在实现最优精度的同时，显著提升了跟踪速度。

</details>


### [83] [A Multi-Centric Anthropomorphic 3D CT Phantom-Based Benchmark Dataset for Harmonization](https://arxiv.org/abs/2507.01539)
**中文标题：基于多中心拟人化3D CT体模的协调基准数据集**

*Mohammadreza Amirian,Michael Bach,Oscar Jimenez-del-Toro,Christoph Aberle,Roger Schaer,Vincent Andrearczyk,Jean-Félix Maestrati,Maria Martin Asiain,Kyriakos Flouris,Markus Obmann,Clarisse Dromain,Benoît Dufour,Pierre-Alexandre Alois Poletti,Hendrik von Tengg-Kobligk,Rolf Hügli,Martin Kretzschmar,Hatem Alkadhi,Ender Konukoglu,Henning Müller,Bram Stieltjes,Adrien Depeursinge*

主要分类: cs.CV

摘要简述: 本文介绍了一个开源基准数据集，包含多中心、多扫描器和设置下获取的3D CT体模扫描，旨在促进AI医学图像协调技术的发展。


<details>
  <summary>详细信息</summary>
研究动机: AI在医学影像分析中因数据分布变化（如扫描器制造商、重建技术或剂量差异）而泛化能力不足，需要协调技术解决这一问题。

研究方法: 使用多中心、多扫描器和设置获取的3D CT体模数据，固定患者间和患者内变异，提供1378个图像序列，并开发了评估图像和特征稳定性的方法及开源代码。

研究结果: 数据集包含13台扫描器、4家制造商、8家机构的1378个图像序列，并提供了基线结果和开源代码，支持AI协调策略的开发。

研究结论: 该数据集和方法为AI医学图像协调技术的研究提供了标准化基准，有助于提升AI在多变数据环境中的泛化能力。

中文摘要: 人工智能（AI）为医学领域带来了许多辅助和自动化任务的机会，但在数据分布变化时泛化能力较差。在基于AI的计算机断层扫描（CT）分析中，扫描器制造商、重建技术或剂量的变化可能导致显著的数据分布偏移。AI协调技术可以通过减少不同采集设置引起的分布偏移来解决这一问题。本文提出了一个开源基准数据集，包含使用多种扫描器和设置获取的拟人化体模CT扫描，旨在促进AI协调技术的发展。使用体模可以固定患者间和患者内的变异。数据集包括1378个图像序列，来自4家制造商的13台扫描器，覆盖8家机构，采用协调协议和多种采集剂量。此外，我们还提出了一种方法、基线结果和开源代码，用于评估图像和特征级别的稳定性以及肝脏组织分类，推动AI协调策略的开发。

</details>


### [84] [Interpolation-Based Event Visual Data Filtering Algorithms](https://arxiv.org/abs/2507.01557)
**中文标题：基于插值的事件视觉数据滤波算法**

*Marcin Kowlaczyk,Tomasz Kryjak*

主要分类: cs.CV

摘要简述: 本文提出了一种基于无限脉冲响应（IIR）滤波器矩阵的事件视觉数据滤波算法，能够去除约99%的噪声，同时保留大部分有效信号，适用于嵌入式设备。


<details>
  <summary>详细信息</summary>
研究动机: 随着神经形态视觉领域的快速发展，事件相机在越来越多的应用中得到使用，但其数据流中存在大量噪声，亟需高效的滤波方法。

研究方法: 提出了四种基于IIR滤波器矩阵的算法，并在多个事件数据集上进行了测试，数据集还添加了人工生成噪声和动态视觉传感器记录的噪声。

研究结果: 所提方法在1280 x 720分辨率的传感器上仅需约30KB内存，能够去除约99%的噪声，同时保留大部分有效信号。

研究结论: 这些算法在去噪效果和内存占用方面表现优异，非常适合在嵌入式设备中实现。

中文摘要: 神经形态视觉领域发展迅速，事件相机在越来越多的应用中得到使用。然而，这些传感器的数据流中存在大量噪声。本文提出了一种针对事件数据的方法，能够去除约99%的噪声，同时保留大部分有效信号。我们基于无限脉冲响应（IIR）滤波器矩阵提出了四种算法，并在多个事件数据集上进行了比较，这些数据集还添加了人工生成噪声和动态视觉传感器记录的噪声。所提方法在分辨率为1280 x 720的传感器上仅需约30KB内存，因此非常适合在嵌入式设备中实现。

</details>


### [85] [A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2507.01573)
**中文标题：判别式与扩散生成学习结合的礼物：边界优化的遥感语义分割**

*Hao Wang,Keyan Hu,Xin Guo,Haifeng Li,Chao Tao*

主要分类: cs.CV

摘要简述: 本文提出了一种结合判别式学习和扩散生成学习的框架（IDGBR），用于优化遥感图像语义分割中的边界精度。通过联合利用判别式模型和扩散模型，显著提升了边界细节的生成能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有遥感语义分割方法主要依赖判别式学习，擅长捕捉低频特征但忽视高频边界细节。扩散生成模型在高频细节生成方面表现优异，但单独使用时低频语义推理不足。因此，作者提出结合两者的优势，以提升分割精度。

研究方法: IDGBR框架首先通过判别式主干模型生成粗分割图，随后将粗分割图和原始图像输入条件引导网络，联合学习引导表示。该表示被用于迭代去噪扩散过程，逐步优化粗分割结果。

研究结果: 在五个遥感语义分割数据集（二分类和多分类）上的实验表明，IDGBR能够显著提升不同判别式架构生成的粗分割结果的边界精度。

研究结论: IDGBR通过结合判别式和扩散生成学习的优势，有效解决了遥感语义分割中边界细节不足的问题，为未来研究提供了新思路。

中文摘要: 遥感语义分割需要同时解决图像中地物类别和位置的问题。因此，分割模型不仅需要确保大尺度斑块的语义正确性（低频信息），还需精确定位斑块间的边界（高频信息）。然而，现有方法主要依赖判别式学习，擅长捕捉低频特征，却忽视了其在学习高频特征时的固有局限性。近期研究表明，扩散生成模型在高频细节生成方面表现优异。我们的理论分析证实，扩散去噪过程显著提升了模型学习高频特征的能力；但同时也发现，仅依赖原始图像引导时，这些模型对低频特征的语义推理不足。因此，我们结合判别式学习和生成学习的优势，提出了判别式与扩散生成学习结合的边界优化框架（IDGBR）。该框架首先通过判别式主干模型生成粗分割图，随后将粗分割图和原始图像输入条件引导网络，联合学习引导表示，并通过迭代去噪扩散过程优化粗分割结果。在五个遥感语义分割数据集（二分类和多分类）上的广泛实验证实，IDGBR能够对不同判别式架构生成的粗分割结果实现一致的边界优化。源代码将在https://github.com/KeyanHu-git/IDGBR 发布。

</details>


### [86] [SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation](https://arxiv.org/abs/2507.01586)
**中文标题：SketchColour：基于通道拼接引导的DiT草图到色彩转换流程用于2D动画**

*Bryan Constantine Sadihin,Michael Hua Wang,Shei Pern Chua,Hang Su*

主要分类: cs.CV

摘要简述: SketchColour是一种基于扩散变换器（DiT）的草图到色彩转换流程，用于2D动画制作，通过轻量级通道拼接适配器和LoRA微调，显著减少参数和GPU内存使用，并在SAKUGA数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 2D动画制作中，手工绘制和上色大量帧是一项劳动密集型任务，现有方法参数和内存开销大。本文旨在提出一种高效且性能优越的草图到色彩转换方法，以减轻动画师的工作负担。

研究方法: 采用扩散变换器（DiT）作为主干网络，替换传统的U-Net去噪器，并通过轻量级通道拼接适配器注入草图信息，结合LoRA微调，避免参数和内存膨胀。

研究结果: 在SAKUGA数据集上，SketchColour使用仅一半训练数据的情况下，性能优于现有视频上色方法，生成的时间一致性动画几乎无色彩溢出或物体变形等伪影。

研究结论: SketchColour通过DiT架构和轻量级适配器设计，实现了高效的草图到色彩转换，为2D动画制作提供了高性能且资源友好的解决方案。

中文摘要: 高质量2D动画的制作是一项劳动密集型任务，目前动画师需要手工绘制和上色大量帧。我们提出了SketchColour，这是首个基于扩散变换器（DiT）的草图到色彩转换流程，用于2D动画。通过用DiT风格架构替换传统的U-Net去噪器，并通过轻量级通道拼接适配器注入草图信息，辅以LoRA微调，我们的方法无需重复ControlNet的参数和内存膨胀，显著减少了参数数量和GPU内存使用。在SAKUGA数据集上的评估表明，尽管仅使用竞争对手模型一半的训练数据，SketchColour在所有指标上均优于现有最先进的视频上色方法。我们的方法生成的时间一致性动画几乎无色彩溢出或物体变形等伪影。代码已开源：https://bconstantine.github.io/SketchColour。

</details>


### [87] [Towards Controllable Real Image Denoising with Camera Parameters](https://arxiv.org/abs/2507.01587)
**中文标题：基于相机参数的可控真实图像去噪**

*Youngjin Oh,Junhyeong Kwon,Keuntek Lee,Nam Ik Cho*

主要分类: cs.CV

摘要简述: 本文提出了一种基于相机参数的可控图像去噪框架，通过利用ISO、快门速度和光圈值等参数调整去噪强度，提升了去噪网络的性能和可控性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的深度学习图像去噪方法虽然性能出色，但缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性。本文旨在解决这一问题，提出一种可控的去噪框架。

研究方法: 本文提出了一种新的可控去噪框架，将相机参数（如ISO、快门速度和光圈值）转换为向量，用于控制和增强去噪网络的性能。

研究结果: 实验结果表明，该方法能够无缝地为标准去噪神经网络增加可控性，并显著提升其性能。

研究结论: 本文提出的框架通过利用相机参数实现了图像去噪的可控性，为未来的去噪研究提供了新的方向。

中文摘要: 近年来，基于深度学习的图像去噪方法表现出色，但许多方法缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性。本文提出了一种新的可控去噪框架，通过利用相机参数（如ISO、快门速度和光圈值）自适应地去除图像噪声。具体而言，我们将这些参数转换为向量，用于控制和增强去噪网络的性能。实验结果表明，我们的方法能够无缝地为标准去噪神经网络增加可控性，并提升其性能。代码可在https://github.com/OBAKSA/CPADNet获取。

</details>


### [88] [Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring](https://arxiv.org/abs/2507.01590)
**中文标题：自主AI监控：基于多模态深度学习的认知与行为监测**

*Ameer Hamza,Zuhaib Hussain But,Umar Arif,Samiya,M. Abdullah Asad,Muhammad Naeem*

主要分类: cs.CV

摘要简述: 本文提出了一种新型教室监控系统，通过多模态深度学习技术（如睡意检测、手机使用追踪和人脸识别）实时评估学生注意力，并实现自动考勤。系统性能优异，睡意检测准确率达97.42%，人脸识别验证准确率为86.45%，手机检测准确率为85.89%。


<details>
  <summary>详细信息</summary>
研究动机: 传统教室监控系统难以全面评估学生注意力与行为。本研究旨在通过多模态深度学习技术，提供一种高精度、实时的学生注意力监测方案，同时实现自动考勤功能，以满足多样化教育环境的需求。

研究方法: 系统整合了YOLOv8模型检测手机使用和睡意，LResNet Occ FC结合YOLO和MTCNN实现人脸识别。使用RMFD数据集训练人脸识别模型，Roboflow数据集训练手机检测模型。系统通过PHP网页应用和ESP32-CAM硬件实现实时数据采集。

研究结果: 系统性能表现优异：睡意检测的mAP@50为97.42%，人脸识别的验证准确率为86.45%，手机检测的mAP@50为85.89%。系统成功实现了实时监控和自动考勤功能。

研究结论: 该多模态监控系统显著提升了教室监控的精确性和自动化水平，适用于多样化教育场景，并展示了深度学习技术在行为监测中的潜力。

中文摘要: 本研究提出了一种新型教室监控系统，通过整合睡意检测、手机使用追踪和人脸识别等多模态技术，以更高精度评估学生注意力。系统采用YOLOv8模型检测手机使用和睡意（Ghatge等，2024），并通过LResNet Occ FC结合YOLO和MTCNN实现人脸识别（Durai等，2024）。这些模型协同工作，提供全面的实时监控，揭示学生参与度和行为（S等，2023）。系统使用RMFD数据集训练人脸识别模型，Roboflow数据集训练手机检测模型。评估结果显示，睡意检测的mAP@50为97.42%，人脸识别的验证准确率为86.45%，手机检测的mAP@50为85.89%。系统通过PHP网页应用和ESP32-CAM硬件实现无缝数据采集（Neto等，2024）。这一集成方案不仅提升了教室监控能力，还通过人脸识别实现自动考勤，适用于多样化教育环境（Banada，2025）。

</details>


### [89] [DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation](https://arxiv.org/abs/2507.01603)
**中文标题：DepthSync：基于扩散引导的深度同步方法，用于尺度和几何一致的视频深度估计**

*Yue-Jiang Dong,Wang Zhao,Jiale Xu,Ying Shan,Song-Hai Zhang*

主要分类: cs.CV

摘要简述: DepthSync提出了一种基于扩散引导的无训练框架，用于长视频的尺度和几何一致性深度估计，解决了现有方法在窗口间尺度不一致和几何结构忽略的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于扩散的视频深度估计方法在处理长视频时，由于采用滑动窗口分割，导致窗口间尺度差异累积，且仅依赖2D扩散先验，忽略了视频深度的3D几何结构，预测结果几何不一致。

研究方法: DepthSync通过引入尺度引导和几何引导，同步窗口间的深度尺度并强制窗口内的几何对齐，结合3D约束，协同指导去噪过程，实现一致深度预测。

研究结果: 在多个数据集上的实验表明，DepthSync显著提升了长视频深度估计的尺度和几何一致性。

研究结论: DepthSync通过扩散引导的无训练框架，有效解决了长视频深度估计中的尺度和几何一致性问题，为相关领域提供了新思路。

中文摘要: 基于扩散的视频深度估计方法凭借强大的泛化能力取得了显著成功，但长视频的深度预测仍具挑战性。现有方法通常将视频分割为重叠的滑动窗口，导致窗口间尺度差异累积，尤其是窗口数量增加时。此外，这些方法仅依赖2D扩散先验，忽略了视频深度的固有3D几何结构，导致预测结果几何不一致。本文提出DepthSync，一种无需训练的新框架，利用扩散引导实现长视频的尺度和几何一致性深度预测。具体而言，我们引入尺度引导以同步窗口间的深度尺度，并通过几何引导基于视频深度的3D约束强制窗口内的几何对齐。这两项协同作用，引导去噪过程生成一致的深度预测。在多个数据集上的实验验证了DepthSync在提升尺度和几何一致性方面的有效性，尤其适用于长视频。

</details>


### [90] [Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems](https://arxiv.org/abs/2507.01607)
**中文标题：无约束人脸识别系统中后门攻击的生存能力**

*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi,Eric Bourbao*

主要分类: cs.CV

摘要简述: 本文首次系统研究了深度学习人脸识别系统中的后门攻击，展示了两种针对人脸检测任务的后门攻击（人脸生成和关键点偏移），并证明基于大间隔损失的特征提取器也易受攻击。通过20种管道配置和15种攻击案例，证明单一后门可绕过整个系统功能，同时提出了防御建议。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习人脸识别系统的广泛应用引发了安全担忧，但现有研究对真实无约束系统中的后门攻击关注不足。本文旨在填补这一空白，首次系统研究此类攻击的可行性和影响。

研究方法: 研究通过两种后门攻击（人脸生成和关键点偏移）探索人脸检测任务的脆弱性，并验证基于大间隔损失的特征提取器是否易受攻击。结合20种管道配置和15种攻击案例，分析单一后门对系统功能的影响。

研究结果: 实验证明，人脸检测任务和特征提取器均易受后门攻击，单一后门可成功绕过整个系统功能。研究还提出了针对这些攻击的最佳实践和防御措施。

研究结论: 本文揭示了深度学习人脸识别系统中的后门攻击风险，并提供了防御建议，为相关利益方提供了重要参考。

中文摘要: 深度学习人脸识别的广泛应用引发了多重安全隐患。尽管已有研究指出其脆弱性，但针对真实无约束系统的DNN后门攻击仍是文献中的盲点。本文首次对基于深度学习的人脸识别系统进行了系统级后门研究，通过全面探索其可行性，贡献了四项成果：首次展示了针对人脸检测任务的两种后门攻击（人脸生成和关键点偏移），并证明基于大间隔损失的特征提取器同样易受攻击。结合20种管道配置和15种攻击案例，研究发现单一后门即可绕过整个系统功能。最后，本文为利益相关者提供了多项最佳实践和防御措施。

</details>


### [91] [Perception-Oriented Latent Coding for High-Performance Compressed Domain Semantic Inference](https://arxiv.org/abs/2507.01608)
**中文标题：面向感知的潜在编码：高性能压缩域语义推理**

*Xu Zhang,Ming Lu,Yan Chen,Zhan Ma*

主要分类: cs.CV

摘要简述: 本文提出了一种感知导向的潜在编码方法（POLC），通过丰富潜在特征的语义内容，显著提升了压缩域语义推理的性能，同时减少了微调的计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 现有的压缩域语义推理主要依赖基于均方误差（MSE）优化的图像编码模型，其潜在空间语义贫乏，限制了下游任务的性能。此外，高性能通常需要微调整个视觉模型，计算成本高昂。

研究方法: POLC通过优化潜在特征的语义丰富性，仅需一个即插即用的适配器进行微调，大幅减少了参数数量。

研究结果: 实验表明，POLC在率感知性能上与最先进的生成式图像编码方法相当，同时显著提升了视觉任务性能，且微调开销极低。

研究结论: POLC为压缩域语义推理提供了一种高效且性能优越的解决方案，显著降低了计算成本。

中文摘要: 近年来，压缩域语义推理主要依赖于以均方误差（MSE）优化的学习型图像编码模型。然而，基于MSE的优化往往导致潜在空间语义贫乏，阻碍了下游任务的有效语义推理。此外，这些模型要实现高性能通常需要对整个视觉模型进行微调，计算成本高昂，尤其是对于大型模型。为解决这些问题，我们提出了面向感知的潜在编码（POLC），该方法通过丰富潜在特征的语义内容，实现了高性能的压缩域语义推理。借助语义丰富的潜在空间，POLC仅需一个即插即用的适配器进行微调，显著减少了参数数量。实验结果表明，POLC在率感知性能上与最先进的生成式图像编码方法相当，同时显著提升了视觉任务性能，且微调开销极低。代码已开源：https://github.com/NJUVISION/POLC。

</details>


### [92] [Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss](https://arxiv.org/abs/2507.01630)
**中文标题：基于提示引导与人类近端感知的区域联合损失HOT预测**

*Yuxiao Wang,Yu Lei,Zhenao Wei,Weiying Xue,Xinyu Jiang,Nan Zhuang,Qi Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为P3HOT的框架，结合提示引导和人类近端感知技术，用于提升人体-物体接触（HOT）检测的准确性。通过语义驱动提示和动态深度感知，解决了现有模型在区域分割和类别一致性上的不足，并引入了新的损失函数和评价指标，实现了显著的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人体-物体接触检测模型通常局限于单一图像类型，导致在交互较少区域过度分割，且难以保持特定区域的类别一致性。为解决这些问题，本文提出了P3HOT框架，旨在通过提示引导和人类近端感知技术提升检测精度。

研究方法: P3HOT框架包含两个核心机制：1）语义驱动提示机制，通过图像与文本的相关性引导网络关注相关区域；2）人类近端感知机制，动态感知人体周围的关键深度范围，消除非交互区域。此外，还提出了区域联合损失（RJLoss）和新评价指标AD-Acc.。

研究结果: 实验结果表明，P3HOT在两个基准数据集上的四项指标中均达到最优性能。在HOT-Annotated数据集上，SC-Acc.、mIoU、wIoU和AD-Acc.分别提升了0.7、2.0、1.6和11.0个百分点。

研究结论: P3HOT通过结合提示引导和人类近端感知技术，显著提升了人体-物体接触检测的性能。新提出的RJLoss和AD-Acc.指标有效解决了现有方法的不足，为相关领域提供了新的研究思路。

中文摘要: 人体-物体接触（HOT）检测的任务是识别人体与物体接触的具体区域。然而，现有模型通常仅适用于单一图像类型，导致在交互较少区域过度分割，且难以保持特定区域的类别一致性。为解决这一问题，本文提出了一种名为P3HOT的HOT检测框架，结合了提示引导和人类近端感知技术。首先，通过语义驱动提示机制，基于图像与文本的相关性引导网络关注相关区域；其次，利用人类近端感知机制动态感知人体周围的关键深度范围，通过可学习参数有效消除非交互区域。深度计算解决了2D视角下人体与物体重叠的不确定性，提供了准3D视角。此外，还提出了区域联合损失（RJLoss）以抑制同一区域的异常类别，并引入新评价指标AD-Acc.以解决现有方法在负样本处理上的不足。全面的实验结果表明，我们的方法在两个基准数据集的四项指标中均达到最优性能。具体而言，在HOT-Annotated数据集上，SC-Acc.、mIoU、wIoU和AD-Acc.分别提升了0.7、2.0、1.6和11.0个百分点。代码已开源：https://github.com/YuxiaoWang-AI/P3HOT。

</details>


### [93] [Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation](https://arxiv.org/abs/2507.01631)
**中文标题：分块与滑动：从局部到全球3D地球观测的NeRF扩展新框架**

*Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet*

主要分类: cs.CV

摘要简述: 本文提出Snake-NeRF框架，通过分块处理和滑动采样策略，解决了NeRF在大规模3D地球观测场景中的内存限制问题，实现了单设备高效训练。


<details>
  <summary>详细信息</summary>
研究动机: 现有NeRF方法因内存限制仅适用于小场景，无法满足大规模卫星图像处理需求。本文旨在解决这一问题，扩展NeRF的应用范围。

研究方法: 提出Snake-NeRF框架，将感兴趣区域划分为无重叠的3D分块，并通过滑动采样策略避免边缘重建错误。采用外存方法，无需同时加载所有图像和网络。

研究结果: 实验表明，该方法能线性时间处理大规模卫星图像，单GPU运行且不损失重建质量。

研究结论: Snake-NeRF成功扩展了NeRF在大规模3D地球观测中的应用，解决了内存限制问题，为未来研究提供了新方向。

中文摘要: 神经辐射场（NeRF）近年来成为多视角卫星图像3D重建的范式。然而，现有NeRF方法因训练时的内存占用问题，通常局限于小场景。本文研究了这一问题。先前的大规模NeRF研究通过分块处理缓解此问题。本文提出Snake-NeRF框架，支持大规模场景处理。我们的外存方法无需同时加载所有图像和网络，且仅需单设备运行。通过将感兴趣区域划分为无重叠的3D分块，并对图像进行重叠裁剪，确保每个分块训练时包含所有必要像素。我们引入了一种新颖的2×2 3D分块滑动策略和分段采样器，共同避免了分块边缘的3D重建错误。实验表明，大规模卫星图像可以线性时间处理，单GPU运行且不损失质量。

</details>


### [94] [Depth Anything at Any Condition](https://arxiv.org/abs/2507.01634)
**中文标题：任意条件下的深度估计**

*Boyuan Sun,Modi Jin,Bowen Yin,Qibin Hou*

主要分类: cs.CV

摘要简述: DepthAnything-AC是一种基础单目深度估计模型，能够在各种复杂环境条件下（如光照变化、恶劣天气和传感器失真）表现优异。通过无监督一致性正则化微调范式和小量未标记数据，结合空间距离约束，提升了语义边界和细节的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基础单目深度估计模型在一般场景中表现良好，但在复杂开放世界环境（如光照变化、恶劣天气等）中表现不佳。数据稀缺和从损坏图像生成高质量伪标签的困难是主要挑战。

研究方法: 提出无监督一致性正则化微调范式，仅需少量未标记数据，并引入空间距离约束以显式学习补丁级相对关系，从而提升语义边界和细节准确性。

研究结果: 实验表明，DepthAnything-AC在多样基准测试（包括真实恶劣天气、合成损坏和一般场景）中展现出零样本能力。

研究结论: DepthAnything-AC通过创新方法解决了复杂环境下的深度估计问题，为开放世界应用提供了可靠解决方案。

中文摘要: 我们提出了Depth Anything at Any Condition（DepthAnything-AC），这是一种能够处理多样化环境条件的基础单目深度估计（MDE）模型。现有的基础MDE模型在一般场景中表现出色，但在涉及光照变化、恶劣天气和传感器失真等挑战性条件的复杂开放世界环境中表现不佳。为了克服数据稀缺和从损坏图像生成高质量伪标签的困难，我们提出了一种无监督一致性正则化微调范式，仅需少量未标记数据。此外，我们提出了空间距离约束，显式强制模型学习补丁级相对关系，从而获得更清晰的语义边界和更准确的细节。实验结果表明，DepthAnything-AC在多样化基准测试（包括真实恶劣天气基准、合成损坏基准和一般基准）中展现出零样本能力。项目页面：https://ghost233lism.github.io/depthanything-AC-page 代码：https://github.com/HVision-NKU/DepthAnythingAC

</details>


### [95] [ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving](https://arxiv.org/abs/2507.01735)
**中文标题：ECCV 2024 W-CODA：首届自动驾驶极端场景多模态感知与理解研讨会**

*Kai Chen,Ruiyuan Gao,Lanqing Hong,Hang Xu,Xu Jia,Holger Caesar,Dengxin Dai,Bingbing Liu,Dzmitry Tsishkou,Songcen Xu,Chunjing Xu,Qiang Xu,Huchuan Lu,Dit-Yan Yeung*

主要分类: cs.CV

摘要简述: 本文介绍了ECCV 2024首届W-CODA研讨会，聚焦于多模态感知与理解技术在自动驾驶极端场景中的应用，通过学术与工业界专家的分享及双轨挑战赛推动前沿技术发展。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶在极端场景（corner cases）中的表现仍存在挑战，W-CODA研讨会旨在通过多模态感知与理解技术探索下一代解决方案，推动自动驾驶技术的可靠性与智能化。

研究方法: 研讨会邀请了5位来自学术界和工业界的专家分享最新进展，并组织了双轨挑战赛，包括极端场景的理解与生成任务，同时收集相关研究论文。

研究结果: 研讨会成功汇集了前沿研究成果，并通过挑战赛促进了极端场景下自动驾驶技术的创新与交流。

研究结论: W-CODA作为开创性尝试，将持续弥合前沿技术与完全智能、可靠的自动驾驶之间的差距，尤其是在极端场景中的应用。

中文摘要: 本文介绍了与ECCV 2024联合举办的首届W-CODA研讨会的详情。W-CODA旨在通过先进的多模态感知与理解技术，探索自动驾驶极端场景的下一代解决方案。研讨会邀请了5位来自学术界和工业界的专家分享最新进展与观点，并收集了相关研究论文，同时举办了双轨挑战赛，涵盖极端场景的理解与生成任务。作为开创性尝试，我们将持续弥合前沿自动驾驶技术与完全智能、可靠的自动驾驶之间的差距，尤其是在极端场景中的应用。

</details>


### [96] [SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement](https://arxiv.org/abs/2507.01643)
**中文标题：SAILViT：通过逐步特征优化构建鲁棒且泛化的多模态大语言模型视觉骨干网络**

*Weijie Yin,Dingkang Yang,Hongyuan Dong,Zijian Kang,Jiacong Wang,Xiao Liang,Chao Feng,Jiao Ran*

主要分类: cs.CV

摘要简述: SAILViT是一种逐步特征优化的视觉Transformer，旨在提升多模态大语言模型（MLLMs）在复杂交互中的性能，通过粗到细的特征对齐和知识注入实现更强的鲁棒性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉Transformer（ViTs）虽然通过对比学习或自监督机制表现优异，但在与大型语言模型（LLMs）直接联合训练时，存在参数初始化冲突和模态语义鸿沟的问题。SAILViT旨在解决这些问题，提升MLLMs在多模态任务中的性能。

研究方法: SAILViT采用逐步特征优化的方法，实现从粗粒度到细粒度的特征对齐和世界知识注入，以满足目标训练需求。该方法在不同参数规模、模型架构、训练策略和数据规模下均表现出强大的鲁棒性和泛化能力。

研究结果: 实验表明，SAILViT显著提升了现有MLLMs在OpenCompass基准测试中的性能，并在广泛的下游任务中表现一致。

研究结论: SAILViT通过逐步特征优化，成功解决了ViTs与LLMs联合训练中的挑战，为多模态任务提供了更强大的视觉骨干网络。

中文摘要: 视觉Transformer（ViTs）作为多模态大语言模型（MLLMs）视觉理解能力的核心骨干网络至关重要。尽管大多数ViTs通过图像-文本对的对比学习或自监督机制取得了优异性能，但由于潜在的参数初始化冲突和模态语义鸿沟，它们难以直接与大型语言模型（LLMs）进行基于连接器的联合训练。为解决上述挑战，本文提出SAILViT，一种逐步特征优化的ViT，旨在帮助MLLMs突破复杂多模态交互中的性能瓶颈。SAILViT通过逐步特征优化实现从粗到细的特征对齐和世界知识注入，更好地满足目标训练需求。我们通过全面的实证分析证实了SAILViT在不同维度（包括参数规模、模型架构、训练策略和数据规模）上的强大鲁棒性和泛化能力。配备SAILViT后，现有MLLMs在OpenCompass基准测试的广泛下游任务中表现出显著且一致的性能提升。SAILViT系列模型已在https://huggingface.co/BytedanceDouyinContent发布。

</details>


### [97] [Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective](https://arxiv.org/abs/2507.01652)
**中文标题：基于空间感知衰减的线性复杂度自回归图像生成**

*Yuxin Mao,Zhen Qin,Jinxing Zhou,Hui Deng,Xuyang Shen,Bin Fan,Jing Zhang,Yiran Zhong,Yuchao Dai*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LASAD的新型注意力机制，通过空间感知衰减因子保留图像的2D空间关系，解决了传统线性注意力机制在图像生成中无法捕捉长距离依赖的问题。基于此，作者开发了LASADGen，实现了线性复杂度的自回归图像生成，并在ImageNet上取得了优异的生成效果和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的自回归图像生成模型主要依赖Transformer架构，但其二次计算复杂度和高内存开销限制了应用。线性注意力机制虽能降低计算负担，但在图像生成中因无法捕捉长距离依赖而导致质量下降。本文旨在解决这一问题。

研究方法: 提出线性注意力与空间感知衰减（LASAD）机制，通过基于真实2D空间位置而非1D序列位置计算衰减因子，保留图像的2D空间关系。基于LASAD，开发了LASADGen自回归图像生成器，实现了线性复杂度的选择性注意力。

研究结果: 在ImageNet上的实验表明，LASADGen在图像生成质量和计算效率上均达到最先进水平，成功弥补了线性注意力机制在空间理解上的不足。

研究结论: LASADGen通过空间感知衰减机制，在保持线性复杂度的同时提升了图像生成质量，为高效高质量的自回归图像生成提供了新思路。

中文摘要: 自回归（AR）模型因其能够有效捕捉视觉数据中的局部和全局结构而在图像生成领域备受关注。然而，现有的AR模型主要依赖Transformer架构，其输入序列长度的二次计算复杂度和因维护键值缓存导致的高内存开销成为瓶颈。尽管线性注意力机制在语言模型中成功降低了这一负担，但初步实验表明，其在图像生成中因无法捕捉关键的长距离依赖而导致质量显著下降。我们提出了空间感知衰减线性注意力（LASAD），这是一种新型注意力机制，通过基于真实2D空间位置而非1D序列位置计算位置相关衰减因子，明确保留了扁平化图像序列中的真实2D空间关系。基于此机制，我们提出了LASADGen，一种能够以线性复杂度选择性关注相关空间上下文的自回归图像生成器。在ImageNet上的实验表明，LASADGen在图像生成性能和计算效率上均达到最先进水平，填补了线性注意力效率与高质量生成所需空间理解之间的鸿沟。

</details>


### [98] [RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather](https://arxiv.org/abs/2507.01653)
**中文标题：RobuSTereo：恶劣天气下鲁棒的零样本立体匹配**

*Yuran Wang,Yingping Liang,Yutao Hu,Ying Fu*

主要分类: cs.CV

摘要简述: RobuSTereo提出了一种新框架，通过扩散模拟和稳健特征编码，提升立体匹配模型在恶劣天气下的零样本泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 基于学习的立体匹配模型在恶劣天气条件下表现不佳，主要由于训练数据稀缺和特征提取困难。RobuSTereo旨在解决这些问题，提升模型在未知天气条件下的鲁棒性。

研究方法: 1. 提出基于扩散的模拟管道，生成高质量恶劣天气立体数据；2. 设计稳健特征编码器，结合ConvNet和去噪Transformer，提取稳定特征。

研究结果: 实验表明，RobuSTereo显著提升了立体匹配模型在多种恶劣天气场景下的鲁棒性和泛化能力。

研究结论: RobuSTereo通过合成数据和稳健特征提取，有效解决了立体匹配在恶劣天气下的挑战，为实际应用提供了可靠解决方案。

中文摘要: 基于学习的立体匹配模型在恶劣天气条件下表现不佳，主要由于训练数据稀缺和特征提取困难。这些限制显著阻碍了模型在分布外天气条件下的零样本泛化能力。本文提出RobuSTereo，一种新框架，通过解决数据稀缺和特征提取问题，提升立体匹配模型在恶劣天气下的零样本泛化能力。首先，我们引入基于扩散的模拟管道，配备立体一致性模块，生成针对恶劣条件的高质量立体数据。通过在合成数据上训练立体匹配模型，我们缩小了干净图像与退化图像之间的领域差距，显著提升了模型对未知天气条件的鲁棒性。立体一致性模块确保合成图像对的结构对齐，保持几何完整性并提升深度估计精度。其次，我们设计了一种稳健特征编码器，结合专用ConvNet和去噪Transformer，从退化图像中提取稳定可靠的特征。ConvNet捕捉细粒度局部结构，而去噪Transformer优化全局表示，有效减轻噪声、低能见度和天气引起的失真影响。这使得即使在挑战性视觉条件下也能更准确地估计视差。大量实验表明，RobuSTereo显著提升了立体匹配模型在多种恶劣天气场景下的鲁棒性和泛化能力。

</details>


### [99] [SPoT: Subpixel Placement of Tokens in Vision Transformers](https://arxiv.org/abs/2507.01654)
**中文标题：SPoT：视觉Transformer中的子像素标记放置**

*Martine Hjelkrem-Tan,Marius Aasan,Gabriel Y. Arteaga,Adín Ramírez Rivera*

主要分类: cs.CV

摘要简述: SPoT提出了一种新型的视觉Transformer标记化策略，通过连续子像素标记放置突破传统网格限制，显著提升模型性能并减少推理所需标记数量。


<details>
  <summary>详细信息</summary>
研究动机: 传统视觉Transformer的标记化方法将特征限制在离散的网格中，无法充分利用稀疏性，导致性能受限。SPoT旨在通过连续子像素标记放置解决这一问题。

研究方法: SPoT采用子像素标记放置策略，通过Oracle引导的搜索方法，找到最优的子像素标记位置，从而突破网格限制。

研究结果: 实验表明，SPoT能够显著减少推理所需的标记数量，同时提升模型性能，为高效、灵活的ViT架构提供了新方向。

研究结论: SPoT重新定义了稀疏性在视觉Transformer中的优势，为未来高效、可解释的ViT设计开辟了新途径。

中文摘要: 视觉Transformer天然支持稀疏性，但传统的标记化方法将特征限制在离散的网格中，阻碍了模型在稀疏场景下的潜力发挥。我们提出了子像素标记放置（SPoT），这是一种新型的标记化策略，通过连续放置标记来规避网格限制。通过提出的Oracle引导搜索方法，我们发现理想的子像素标记位置可以显著提升性能，并大幅减少推理所需的标记数量。SPoT为灵活、高效且可解释的ViT架构提供了新方向，将稀疏性从限制转变为战略优势。

</details>


### [100] [What does really matter in image goal navigation?](https://arxiv.org/abs/2507.01667)
**中文标题：图像目标导航中真正重要的是什么？**

*Gianluca Monaci,Philippe Weinzaepfel,Christian Wolf*

主要分类: cs.CV

摘要简述: 本文研究了图像目标导航任务中，是否可以通过端到端的强化学习训练完整代理高效解决问题。通过大规模实验，探讨了多种架构选择对导航性能的影响，并发现模拟器设置对方法成功的影响。


<details>
  <summary>详细信息</summary>
研究动机: 当前图像目标导航方法主要依赖专用图像匹配或预训练的计算机视觉模块，本文旨在验证是否可以通过端到端强化学习训练代理解决这一问题，并探讨其潜在影响。

研究方法: 通过大规模实验，研究了多种架构选择（如延迟融合、通道堆叠、空间到深度投影和交叉注意力）在导航训练中的作用，并分析了模拟器设置对方法成功的影响。

研究结果: 研究发现模拟器设置对方法成功有一定影响，可能导致模拟中的捷径行为，但这些能力可以部分迁移到更现实的场景中。导航性能与相对姿态估计性能之间存在相关性。

研究结论: 端到端强化学习训练代理在图像目标导航任务中具有一定潜力，但模拟器设置和架构选择对性能有显著影响。导航性能与相对姿态估计性能相关，表明后者是导航的重要子技能。

中文摘要: 图像目标导航需要两种不同的技能：一是核心导航技能，包括自由空间和障碍物的检测以及基于内部表征的决策；二是通过将视觉观察与目标图像进行比较来计算方向信息。当前最先进的方法要么依赖专用图像匹配，要么依赖预训练的计算机视觉模块进行相对姿态估计。本文研究了是否可以通过端到端强化学习训练完整代理高效解决这一任务，如近期工作所声称的那样。肯定答案将对具身AI以外的领域产生影响，并允许仅通过导航奖励训练相对姿态估计。在一项大规模研究中，我们探讨了延迟融合、通道堆叠、空间到深度投影和交叉注意力等架构选择的作用，以及它们在导航训练中如何促进相对姿态估计器的涌现。我们发现近期方法的成功在一定程度上受模拟器设置的影响，导致模拟中的捷径行为。然而，我们也表明这些能力可以部分迁移到更现实的场景中。我们还发现导航性能与探测到的（涌现的）相对姿态估计性能之间存在相关性，后者是导航的重要子技能。

</details>


### [101] [Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition](https://arxiv.org/abs/2507.01673)
**中文标题：基于视觉-语言模型的文本引导多视角融合的面部情绪学习用于3D/4D面部表情识别**

*Muzammil Behzad*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FACET-VLM的视觉-语言框架，用于3D/4D面部表情识别，通过多视角融合和语义引导实现了高精度识别，并在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 3D和4D面部表情识别在情感计算中具有重要挑战性，其成功应用对理解人类行为、医疗监测和人机交互至关重要。然而，复杂的时空动态特征使得现有方法难以准确捕捉细微表情变化。

研究方法: FACET-VLM框架包含三个关键组件：跨视角语义聚合（CVSA）用于视角一致融合，多视角文本引导融合（MTGF）用于语义对齐的面部情绪，以及多视角一致性损失以确保结构连贯性。

研究结果: FACET-VLM在BU-3DFE、Bosphorus、BU-4DFE和BP4D-Spontaneous等多个基准测试中达到最先进精度，并在4D微表情识别任务中表现出色。

研究结论: FACET-VLM为多模态面部表情识别提供了高效、可扩展的解决方案，适用于静态和动态场景，验证了各组件的重要贡献。

中文摘要: 3D和4D领域的面部表情识别（FER）由于复杂的时空动态特征，在情感计算中具有显著挑战性。其成功应用对人类行为理解、医疗监测和人机交互至关重要。本文提出FACET-VLM，一种视觉-语言框架，通过多视角面部表示学习与自然语言提示的语义引导相结合，实现3D/4D FER。FACET-VLM包含三个关键组件：跨视角语义聚合（CVSA）用于视角一致融合，多视角文本引导融合（MTGF）用于语义对齐的面部情绪，以及多视角一致性损失以确保结构连贯性。该模型在BU-3DFE、Bosphorus、BU-4DFE和BP4D-Spontaneous等多个基准测试中达到最先进精度。此外，FACET-VLM在4DME数据集上扩展至4D微表情识别（MER），表现出捕捉细微、短暂情绪线索的强大能力。大量实验结果验证了框架中各组件的有效性和重要贡献。总体而言，FACET-VLM为多模态FER提供了稳健、可扩展且高性能的解决方案，适用于静态和动态场景。

</details>


### [102] [Component Adaptive Clustering for Generalized Category Discovery](https://arxiv.org/abs/2507.01711)
**中文标题：面向广义类别发现的组件自适应聚类方法**

*Mingfu Yan,Jiancheng Huang,Yifan Liu,Shifeng Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为AdaGCD的自适应聚类方法，用于解决广义类别发现（GCD）问题。该方法通过动态调整聚类数量，无需预先定义类别数，从而更好地处理真实世界数据的复杂性和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 广义类别发现（GCD）旨在对部分标注数据集中的未标注图像进行分类，包括已知和未知类别。传统方法通常需要预先定义类别数量，限制了其处理真实数据的能力。本文旨在通过自适应方法解决这一问题。

研究方法: 本文提出AdaGCD框架，结合自适应槽注意力（AdaSlot），动态确定最佳聚类数量。该方法通过动态分配表示容量，灵活聚类未标注数据，同时捕捉实例特定和空间聚类特征。

研究结果: 在公开和细粒度数据集上的实验表明，AdaGCD在未标注图像数据集中利用空间局部信息进行类别发现具有显著优势。

研究结论: AdaGCD通过自适应聚类和动态槽分配，有效解决了广义类别发现问题，为开放世界场景中的类别发现提供了灵活且高效的解决方案。

中文摘要: 广义类别发现（GCD）旨在解决部分标注数据集中未标注图像分类为已知和未知类别的挑战性问题，且无需预先知道未知类别的数量。传统方法通常依赖刚性假设（如预定义类别数量），限制了其处理真实数据的能力。为此，我们提出AdaGCD，一种基于聚类的对比学习框架，将自适应槽注意力（AdaSlot）引入GCD框架。AdaSlot根据数据复杂度动态确定最佳槽数量，无需预先定义槽数。这种自适应机制通过动态分配表示容量，灵活聚类未标注数据为已知和未知类别。通过结合自适应表示和动态槽分配，我们的方法同时捕捉实例特定和空间聚类特征，提升了开放世界场景中的类别发现能力。在公开和细粒度数据集上的大量实验验证了该框架的有效性，突显了利用空间局部信息在未标注图像数据集中进行类别发现的优势。

</details>


### [103] [Using Wavelet Domain Fingerprints to Improve Source Camera Identification](https://arxiv.org/abs/2507.01712)
**中文标题：利用小波域指纹改进源相机识别**

*Xinle Tian,Matthew Nunes,Emiko Dupont,Shaunagh Downing,Freddie Lichtenstein,Matt Burns*

主要分类: cs.CV

摘要简述: 本文提出了一种改进的基于小波的传感器模式噪声（SPN）提取方法，通过引入小波域指纹概念，避免了去噪算法的最终反演步骤，直接在域中进行指纹比较，提高了检测精度和处理速度。


<details>
  <summary>详细信息</summary>
研究动机: 相机指纹检测在源识别和图像取证中至关重要，而小波去噪方法在提取SPN方面表现出色。然而，传统方法需要将指纹构建为图像并进行反演，效率较低。本文旨在优化这一过程。

研究方法: 提出了一种小波域指纹的概念，直接在域中提取和比较SPN，避免了传统方法中的图像构建和反演步骤，从而简化了流程。

研究结果: 实验结果表明，该方法不仅提高了检测精度，还显著提升了处理速度。

研究结论: 通过引入小波域指纹，本文方法在SPN提取和比较中实现了更高的效率和准确性，为图像取证提供了更优的解决方案。

中文摘要: 相机指纹检测在源识别和图像取证中起着关键作用，其中小波去噪方法在提取传感器模式噪声（SPN）方面尤为有效。本文提出了一种改进的小波基SPN提取方法。不同于将指纹构建为图像，我们引入了小波域指纹的概念。这避免了去噪算法的最终反演步骤，使得指纹可以直接在小波域中进行比较。因此，我们的改进简化了提取和比较流程。在真实数据集上的实验结果表明，该方法不仅实现了更高的检测精度，还能显著提升处理速度。

</details>


### [104] [Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation](https://arxiv.org/abs/2507.01721)
**中文标题：基于软自标记和Potts松弛的弱监督分割方法**

*Zhongwen Zhang,Yuri Boykov*

主要分类: cs.CV

摘要简述: 本文提出了一种基于软自标记和Potts松弛的弱监督分割方法，通过优化未标记像素的CRF/Potts损失，显著提升了基于涂鸦标注的训练效果，甚至优于全像素级监督。


<details>
  <summary>详细信息</summary>
研究动机: 弱监督分割中仅部分像素有标注（如涂鸦），传统方法使用硬伪标签无法表示类别不确定性或错误，因此提出软自标记以改进网络训练效果。

研究方法: 提出了一种软自标记方法，优化了标准CRF/Potts损失的松弛形式，并系统评估了不同CRF松弛（凸和非凸）、邻域系统以及网络预测与软伪标签的连接方式。同时提出了一种通用的连续子问题求解器。

研究结果: 实验表明，软自标记显著提升了基于涂鸦标注的训练效果，优于更复杂的专用弱监督分割系统，甚至在某些情况下优于全像素级监督。

研究结论: 软自标记方法在弱监督分割中表现出色，其通用性也适用于其他弱监督问题或系统。

中文摘要: 本文研究了弱监督分割问题，其中仅有部分像素具有真实标注（涂鸦），并聚焦于一种自标记方法，通过优化未标记像素上标准无监督CRF/Potts损失的松弛形式。尽管WSSS方法可以通过梯度下降直接优化此类损失，但先前研究表明，高阶优化可以通过引入隐藏伪标签和强大的CRF子问题求解器（如图割）改进网络训练。然而，先前使用的硬伪标签无法表示类别不确定性或错误，因此提出了软自标记。我们推导了一种原则性的辅助损失，并系统评估了标准及新的CRF松弛（凸和非凸）、邻域系统以及连接网络预测与软伪标签的项。我们还提出了一种通用的连续子问题求解器。仅使用标准架构，软自标记显著提升了基于涂鸦标注的训练效果，优于更复杂的专用WSSS系统，甚至在某些情况下优于全像素级监督。我们的通用方法也适用于其他弱监督问题或系统。

</details>


### [105] [When Does Pruning Benefit Vision Representations?](https://arxiv.org/abs/2507.01722)
**中文标题：剪枝何时有益于视觉表示？**

*Enrico Cassano,Riccardo Renzulli,Andrea Bragagnolo,Marco Grangetto*

主要分类: cs.CV

摘要简述: 本文研究了剪枝对视觉模型在可解释性、无监督对象发现和与人类感知对齐三个关键维度的影响，发现稀疏模型存在性能提升的‘甜点’，但其效果高度依赖网络架构和参数规模。


<details>
  <summary>详细信息</summary>
研究动机: 剪枝广泛用于降低深度学习模型的复杂度，但其对可解释性和表示学习的影响尚不明确。本文旨在探索剪枝如何影响视觉模型的可解释性、无监督对象发现能力以及与人类感知的对齐。

研究方法: 研究分析了不同视觉网络架构在不同稀疏度下对特征归因可解释性方法的影响，探讨剪枝是否能通过去除冗余信息提升无监督对象发现能力，并评估剪枝是否增强模型表示与人类感知的对齐。

研究结果: 研究发现稀疏模型在特定‘甜点’下表现出更高的可解释性、下游泛化能力和人类对齐性，但这些‘甜点’高度依赖网络架构和参数规模。

研究结论: 剪枝对视觉表示的影响复杂，需深入研究其在不同条件下的作用机制，以明确剪枝何时及如何有益于视觉表示。

中文摘要: 剪枝被广泛用于降低深度学习模型的复杂度，但其对可解释性和表示学习的影响尚不明确。本文研究了剪枝对视觉模型在三个关键维度的影响：（i）可解释性，（ii）无监督对象发现，（iii）与人类感知的对齐。我们首先分析了不同视觉网络架构在不同稀疏度下对特征归因可解释性方法的影响。此外，探讨了剪枝是否能通过去除冗余信息提升无监督对象发现能力，同时保留关键特征。最后，评估了剪枝是否增强模型表示与人类感知的对齐，即稀疏模型是否更关注与人类相似的判别性特征。研究发现稀疏模型在特定‘甜点’下表现出更高的可解释性、下游泛化能力和人类对齐性，但这些‘甜点’高度依赖网络架构和参数规模。结果表明这三个维度之间存在复杂的相互作用，突显了研究剪枝何时及如何有益于视觉表示的重要性。

</details>


### [106] [HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion](https://arxiv.org/abs/2507.01737)
**中文标题：HOI-Dyn：学习人-物运动扩散的交互动态**

*Lin Wu,Zhixiang Chen,Jianglin Lan*

主要分类: cs.CV

摘要简述: 本文提出HOI-Dyn框架，通过驱动-响应系统建模人-物交互动态，利用轻量级Transformer预测物体响应，并通过残差动力学损失提升生成质量，实验证明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法独立处理人与物体运动，导致交互行为物理不真实且因果不一致，因此需要一种新框架来建模详细的交互动态。

研究方法: HOI-Dyn将人-物交互建模为驱动-响应系统，核心为轻量级Transformer动力学模型，预测物体响应，并引入残差动力学损失以优化训练。

研究结果: 实验表明，HOI-Dyn显著提升了人-物交互生成质量，并提供了可行的交互质量评估指标。

研究结论: HOI-Dyn通过驱动-响应系统和动力学模型，成功解决了人-物交互生成的物理一致性问题，为未来研究提供了新方向。

中文摘要: 生成真实的3D人-物交互（HOI）仍具挑战性，因难以建模详细的交互动态。现有方法独立处理人与物体运动，导致物理不真实且因果不一致的行为。本文提出HOI-Dyn框架，将HOI生成建模为驱动-响应系统，其中人类动作驱动物体响应。方法核心为轻量级Transformer交互动态模型，显式预测物体对人类运动的响应。为进一步确保一致性，引入基于残差的动力学损失，减少动态预测误差影响并避免误导优化信号。动力学模型仅用于训练，保持推理效率。通过大量定性与定量实验，证明本方法不仅提升了HOI生成质量，还为生成交互质量评估提供了可行指标。

</details>


### [107] [DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy](https://arxiv.org/abs/2507.01738)
**中文标题：DeRIS：通过循环协同解耦感知与认知以增强指代图像分割**

*Ming Dai,Wenxuan Cheng,Jiang-jiang Liu,Sen Yang,Wenxiao Cai,Yanpeng Sun,Wankou Yang*

主要分类: cs.CV

摘要简述: DeRIS通过解耦感知与认知模块，提出循环协同机制增强多模态认知能力，并引入非指代样本转换数据增强，显著提升指代图像分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有指代图像分割（RIS）框架缺乏对性能瓶颈的系统分析，尤其是多模态认知能力的不足。DeRIS旨在通过模块化解耦和协同机制解决这一问题。

研究方法: DeRIS将RIS任务分解为感知与认知模块，提出循环协同机制以增强模块间交互，并引入非指代样本转换数据增强解决长尾分布问题。

研究结果: DeRIS在指代图像分割任务中表现优异，尤其在非指代和多指代场景中展现出强大的泛化能力，无需额外架构调整。

研究结论: DeRIS通过模块化解耦和循环协同机制有效提升了RIS性能，同时解决了多模态认知不足和长尾分布问题，具有广泛适用性。

中文摘要: 指代图像分割（RIS）是一项基于自然语言表达对图像中目标进行分割的挑战性任务。尽管先前研究主要集中于提升视觉-语言交互和细粒度定位，但对现有RIS框架中基础瓶颈的系统分析仍显不足。为此，我们提出DeRIS，一种将RIS分解为感知与认知两大模块的新框架。这种模块化解耦有助于系统分析阻碍RIS性能的主要瓶颈。研究发现，当前模型的限制主要不在于感知能力不足，而在于多模态认知能力的欠缺。为解决这一问题，我们提出循环协同机制，增强感知与认知模块间的协同作用，从而实现精确分割并提升图像-文本理解的鲁棒性。此外，我们分析并引入了一种简单的非指代样本转换数据增强方法，以解决通用场景中目标存在判断的长尾分布问题。值得注意的是，DeRIS在非指代和多指代场景中展现出固有的适应性，无需专门架构调整，增强了其通用性。代码和模型已在https://github.com/Dmmm1997/DeRIS发布。

</details>


### [108] [Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans](https://arxiv.org/abs/2507.01744)
**中文标题：校准自监督Vision Transformers提升临床CT头部扫描中颅内动脉钙化分割效果**

*Benjamin Jin,Grant Mair,Joanna M. Wardlaw,Maria del C. Valdés Hernández*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自监督学习的Vision Transformer（ViT）方法，用于临床CT头部扫描中的颅内动脉钙化（IAC）分割。通过掩码自编码器（MAE）预训练和微调，ViT在分割任务中表现优于传统监督学习方法，并提升了临床风险分类的准确性。


<details>
  <summary>详细信息</summary>
研究动机: Vision Transformer（ViT）在自然图像领域表现优异，但在3D医学图像分割中应用较少。颅内动脉钙化（IAC）是中风和痴呆等神经血管疾病的影像标志物，自动化分割有助于大规模风险评估。本文旨在探索自监督ViT在IAC分割中的潜力。

研究方法: 1）使用掩码自编码器（MAE）对ViT进行自监督预训练；2）在大型临床试验IST-3的异构数据上微调ViT用于IAC分割；3）评估ViT的关键设计选择，如补丁大小和上采样方法。

研究结果: 1）自监督ViT在Dice分数上比监督学习的nnU-Net基线高3.2分；2）小补丁尺寸对ViT分割效果至关重要，插值上采样优于转置卷积；3）ViT提升了对高切片厚度的鲁棒性，临床风险分类准确性提高46%。

研究结论: 自监督ViT在IAC分割任务中表现优异，优于传统监督学习方法，并显著提升了临床应用的鲁棒性和分类准确性。

中文摘要: Vision Transformers（ViTs）在自然图像领域广受欢迎，但在3D医学图像分割中表现不佳。然而，3D ViTs因其在掩码自编码器（MAE）框架下的高效自监督训练而备受关注，无需昂贵的人工标注即可利用影像数据。颅内动脉钙化（IAC）是常规CT扫描中可见的影像标志物，与中风和痴呆等神经血管疾病相关，自动化IAC量化可支持大规模风险评估。本文首次通过MAE预训练ViT并微调用于IAC分割。我们使用大型临床试验IST-3的高度异构数据开发模型，并评估MAE预训练ViT在IAC分割中的关键特性及其临床意义。结果显示：1）校准自监督ViT比强监督nnU-Net基线高3.2 Dice分；2）小补丁尺寸对ViT分割至关重要，插值上采样优于转置卷积；3）ViT提升了高切片厚度的鲁棒性，临床风险分类准确性提高46%。代码已开源。

</details>


### [109] [SSL4SAR: Self-Supervised Learning for Glacier Calving Front Extraction from SAR Imagery](https://arxiv.org/abs/2507.01747)
**中文标题：SSL4SAR：基于自监督学习的SAR图像冰川崩解前沿提取**

*Nora Gourmelon,Marcel Dreier,Martin Mayr,Thorsten Seehaus,Dakota Pyles,Matthias Braun,Andreas Maier,Vincent Christlein*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SSL4SAR的自监督学习方法，用于从SAR图像中提取冰川崩解前沿，通过新型预训练技术和混合模型架构，显著提升了冰川崩解前沿监测的精度。


<details>
  <summary>详细信息</summary>
研究动机: 冰川冰量流失速度前所未有，亟需全年监测以理解崩解过程。现有基于ImageNet预训练的深度学习模型因领域差异表现不佳，需针对遥感图像特性优化。

研究方法: 提出两种自监督多模态预训练技术，利用包含9,563张Sentinel-1和14张Sentinel-2图像的SSL4SAR数据集，并设计结合Swin Transformer编码器和残差CNN解码器的混合模型架构。

研究结果: 在CaFFe基准数据集上，模型平均距离误差为293米，优于之前最佳模型67米；多标注者研究中，集成模型的平均误差为75米，接近人类水平的38米。

研究结论: SSL4SAR方法显著提升了冰川崩解前沿的监测精度，为季节性变化提供了可靠工具。

中文摘要: 冰川冰量正以前所未有的速度流失，亟需全年精确监测以理解崩解前沿的动态。深度学习模型可从合成孔径雷达（SAR）图像中提取崩解前沿位置，追踪冰量季节性变化。当前最佳模型依赖ImageNet预训练权重，但由于自然图像与遥感图像（尤其是SAR图像）的领域差异，其表现不佳。为解决这一问题，我们提出两种新型自监督多模态预训练技术，利用名为SSL4SAR的新无标签数据集（包含9,563张Sentinel-1和14张Sentinel-2北极冰川图像，每座冰川对应一张光学图像）。此外，我们引入了一种结合Swin Transformer编码器和残差卷积神经网络（CNN）解码器的混合模型架构。在SSL4SAR上预训练后，该模型在“CAlving Fronts and where to Find thEm”（CaFFe）基准数据集上的平均距离误差为293米，优于之前最佳模型67米。对基准数据集的多标注者研究表明，集成模型的平均误差为75米，接近人类水平的38米。这一进展为冰川崩解前沿的季节性变化提供了精确监测手段。

</details>


### [110] [Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis](https://arxiv.org/abs/2507.01756)
**中文标题：重新思考离散标记：将其作为连续自回归图像合成的条件**

*Peng Zheng,Junke Wang,Yi Chang,Yizhou Yu,Rui Ma,Zuxuan Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DisCon的新框架，将离散标记重新解释为条件信号而非生成目标，以解决连续表示建模的优化挑战和量化导致的信息丢失问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于自回归的视觉生成模型通过量化将图像编码为离散标记，但这一过程会导致信息丢失，降低图像保真度。而直接预测连续标记则面临高维空间密度估计困难和生成分布外伪影的风险。因此，本文旨在探索一种既能避免量化损失又能优化连续表示建模的方法。

研究方法: 本文提出DisCon（离散条件连续自回归模型），将离散标记作为条件信号，建模连续表示的条件概率。这种方法避免了连续标记建模的优化挑战，同时规避了量化带来的信息损失。

研究结果: DisCon在ImageNet 256×256生成任务上取得了1.38的gFID分数，显著优于当前最先进的自回归方法。

研究结论: DisCon通过将离散标记作为条件信号，成功解决了连续表示建模的优化问题和量化损失问题，显著提升了图像生成的保真度。

中文摘要: 近年来，大型语言模型（LLM）的进展激发了将图像编码为离散标记并利用自回归（AR）框架进行视觉生成的兴趣。然而，基于自回归的视觉生成模型中的量化过程本质上引入了信息损失，降低了图像保真度。为了缓解这一限制，最近的研究探索了自回归预测连续标记的方法。与离散标记不同，连续表示存在于无界的高维空间中，使得密度估计更具挑战性，并增加了生成分布外伪影的风险。基于上述发现，本文提出了DisCon（离散条件连续自回归模型），这是一种将离散标记重新解释为条件信号而非生成目标的新框架。通过建模离散标记条件下的连续表示概率，DisCon避免了连续标记建模的优化挑战，同时规避了量化导致的信息损失。DisCon在ImageNet 256×256生成任务上取得了1.38的gFID分数，明显优于当前最先进的自回归方法。

</details>


### [111] [Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging](https://arxiv.org/abs/2507.01788)
**中文标题：视觉变换器的表征是否具有语义意义？医学影像案例研究**

*Montasir Shams,Chashi Mahiul Islam,Shaeke Salman,Phat Tran,Xiuwen Liu*

主要分类: cs.CV

摘要简述: 研究发现，视觉变换器（ViT）在医学影像中的表征缺乏语义意义，且对微小变化极为敏感，导致分类结果不可靠。


<details>
  <summary>详细信息</summary>
研究动机: 尽管视觉变换器（ViT）在医学影像任务中表现出色，但其表征的语义意义和鲁棒性尚未明确。本文旨在探究ViT表征是否具有语义意义及其对微小变化的敏感性。

研究方法: 使用基于投影梯度的算法，分析ViT表征的语义意义及其对微小变化的脆弱性。

研究结果: ViT表征缺乏语义意义，对微小变化极为敏感：不可察觉的图像差异可能导致表征显著不同，而不同语义类别的图像可能具有几乎相同的表征。这种脆弱性使分类准确率下降超过60%。

研究结论: ViT在医学影像中的表征缺乏语义意义且易受干扰，这对其在安全关键系统中的部署提出了严峻挑战。

中文摘要: 视觉变换器（ViT）因其在疾病分类、分割和检测等医学影像任务中的高精度表现而迅速受到关注。然而，由于其规模和自注意力机制的复杂性，ViT的表征尚未得到充分理解。特别是，这些模型产生的表征是否具有语义意义尚不明确。本文通过基于投影梯度的算法表明，ViT的表征缺乏语义意义，且对微小变化具有内在脆弱性。不可察觉的图像差异可能导致表征截然不同，而本应属于不同语义类别的图像可能具有几乎相同的表征。这种脆弱性会导致分类结果不可靠；例如，微小的变化可使分类准确率下降超过60%。据我们所知，这是首次系统性地揭示ViT在医学影像分类中表征缺乏语义意义的研究，为其在安全关键系统中的部署提出了严峻挑战。

</details>


### [112] [Boosting Adversarial Transferability Against Defenses via Multi-Scale Transformation](https://arxiv.org/abs/2507.01791)
**中文标题：通过多尺度变换提升对抗样本对防御模型的迁移性**

*Zihong Guo,Chen Wan,Yayin Zheng,Hailing Kuang,Xiaohai Lu*

主要分类: cs.CV

摘要简述: 本文提出了一种新的分段高斯金字塔（SGP）攻击方法，通过多尺度变换增强对抗样本的迁移性，显著提高了对防御模型的攻击成功率。


<details>
  <summary>详细信息</summary>
研究动机: 对抗样本的迁移性对深度神经网络构成重大安全威胁，现有方法多关注单尺度图像，难以有效攻击防御模型。本文旨在通过多尺度变换提升对抗样本的迁移性。

研究方法: 提出分段高斯金字塔（SGP）攻击方法，结合高斯滤波和三种下采样技术生成多尺度样本，计算各尺度损失函数的梯度并取平均值以确定对抗扰动。

研究结果: 实验表明，SGP方法显著提升了对黑盒防御模型的攻击成功率，平均攻击成功率提高了2.3%至32.6%。

研究结论: SGP方法具有高扩展性，可轻松集成到现有对抗攻击中，有效增强对抗样本的迁移性。

中文摘要: 对抗样本的迁移性对深度神经网络构成重大安全挑战，无需了解目标模型即可发起攻击。本文提出了一种新的分段高斯金字塔（SGP）攻击方法，以增强对抗样本的迁移性，尤其是针对防御模型。与现有方法通常关注单尺度图像不同，我们的方法通过高斯滤波和三种下采样技术构建多尺度样本序列，计算各尺度损失函数的梯度并取其平均值以确定对抗扰动。SGP是一种高扩展性的输入变换方法，易于与大多数现有对抗攻击集成。大量实验表明，与最先进方法相比，SGP显著提高了对黑盒防御模型的攻击成功率，仅基于迁移性，平均攻击成功率提升了2.3%至32.6%。

</details>


### [113] [FreeLoRA: Enabling Training-Free LoRA Fusion for Autoregressive Multi-Subject Personalization](https://arxiv.org/abs/2507.01792)
**中文标题：FreeLoRA：实现自回归多主题个性化的无训练LoRA融合**

*Peng Zheng,Ye Wang,Rui Ma,Zuxuan Wu*

主要分类: cs.CV

摘要简述: FreeLoRA提出了一种无需训练的LoRA模块融合框架，用于多主题个性化图像生成，通过全令牌调优和主题感知推理，实现了高保真度和提示一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在多主题个性化图像生成中需要复杂的重新调优或联合优化，难以高效融合独立适应的模块。FreeLoRA旨在解决这一问题，提供一种简单且通用的训练无关解决方案。

研究方法: FreeLoRA采用全令牌调优策略，为每个主题训练独立的LoRA模块，并在推理时通过主题感知推理激活对应模块，避免主题间的相互干扰。

研究结果: 实验表明，FreeLoRA在多主题个性化生成中表现出色，既能保持主题保真度，又能确保提示一致性。

研究结论: FreeLoRA为多主题个性化图像生成提供了一种高效且无需训练的解决方案，显著提升了生成质量和灵活性。

中文摘要: 主题驱动的图像生成在虚拟试穿和海报设计等应用中至关重要。现有方法通常通过微调预训练生成模型或为单个主题应用基于LoRA的适配来实现。然而，这些方法在多主题个性化中表现不佳，因为独立适配的模块融合通常需要复杂的重新调优或联合优化。我们提出了FreeLoRA，这是一种简单且通用的框架，能够实现多主题个性化的无训练LoRA模块融合。每个LoRA模块通过全令牌调优策略在特定主题的少量图像上进行适配，该策略将模块应用于提示中的所有令牌，以促进弱监督的令牌-内容对齐。在推理时，我们采用主题感知推理，仅在其对应主题令牌上激活每个模块。这使得无需训练即可在单张图像中融合多个个性化主题，同时缓解主题间的过拟合和相互干扰。大量实验表明，FreeLoRA在主题保真度和提示一致性方面均表现出色。

</details>


### [114] [HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision](https://arxiv.org/abs/2507.01800)
**中文标题：HCNQA：通过分层聚焦监督增强3D视觉问答**

*Shengli Zhou,Jianuo Zhu,Qilin Huang,Fangjing Wang,Yanfu Zhang,Feng Zheng*

主要分类: cs.CV

摘要简述: 本文提出HCNQA模型，通过分层聚焦监督方法改进3D视觉问答任务，确保模型发展合理推理路径并提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D视觉问答模型仅监督最终输出，可能导致模型通过问题-答案对的常见模式发展肤浅的推理路径。此外，慢思考方法存在推理不足的问题。为解决这些问题，本文提出分层聚焦监督方法。

研究方法: HCNQA模型模仿人类从广泛区域逐步聚焦到特定对象的搜索过程，通过分层监督引导模型完成三个阶段的目标聚焦，监督关键检查点以确保推理路径的合理性和有效性。

研究结果: 实验结果表明，HCNQA能有效确保模型发展合理推理路径，并在性能上表现更优。

研究结论: HCNQA通过分层聚焦监督方法显著提升了3D视觉问答任务的性能，并确保了推理路径的合理性。

中文摘要: 3D视觉问答（3D VQA）对于模型感知物理世界和进行空间推理至关重要。答案中心监督是3D VQA模型的常用训练方法，许多采用此策略的模型在3D VQA任务中取得了显著成果。然而，答案中心方法仅监督模型的最终输出，允许模型自由发展推理路径。缺乏对推理路径的监督可能导致模型通过问题-答案对的常见模式发展肤浅的捷径。此外，尽管慢思考方法推动了大型语言模型的发展，但其存在推理不足的问题。为解决这些问题，我们提出HCNQA，一种利用分层聚焦监督方法的3D VQA模型。通过模仿人类在搜索答案时从广泛区域逐步聚焦到特定对象的过程，我们的方法通过分层监督引导模型完成三个阶段的目标聚焦。通过监督通用推理路径上的关键检查点，我们的方法可以确保发展出合理且有效的推理路径。大量实验结果表明，我们的方法能有效确保模型发展合理推理路径并表现更优。代码可在https://github.com/JianuoZhu/HCNQA获取。

</details>


### [115] [AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction](https://arxiv.org/abs/2507.01801)
**中文标题：AMD：自适应动量与解耦对比学习框架用于鲁棒的长尾轨迹预测**

*Bin Rao,Haicheng Liao,Yanchen Guan,Chengyue Wang,Bonan Wang,Jiaxun Zhang,Zhenning Li*

主要分类: cs.CV

摘要简述: 本文提出了一种自适应动量和解耦对比学习框架（AMD），用于解决自动驾驶中长尾轨迹预测问题，通过结合无监督和有监督对比学习策略，提升模型对复杂和罕见轨迹的识别能力。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶中准确预测交通参与者的未来轨迹至关重要，但自然数据集中的长尾数据通常代表更复杂和危险的场景。现有研究仅依赖基础模型的预测误差，忽略了长尾轨迹模式的多样性和不确定性。

研究方法: AMD框架结合了改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，设计了四种轨迹随机增强方法，并引入在线迭代聚类策略，动态更新伪标签以适应长尾数据的分布变化。

研究结果: 在nuScenes和ETH/UCY数据集上的实验表明，AMD不仅在长尾轨迹预测中表现最优，还展现出卓越的整体预测精度。

研究结论: AMD框架通过自适应动量和解耦对比学习，显著提升了模型对长尾轨迹的预测能力，为自动驾驶中的复杂场景提供了更可靠的解决方案。

中文摘要: 准确预测交通参与者的未来轨迹对自动驾驶至关重要。然而，由于轨迹分布的内在不平衡性，自然数据集中的尾部数据通常代表更复杂和危险的场景。现有研究通常仅依赖基础模型的预测误差，而未考虑长尾轨迹模式的多样性和不确定性。我们提出了一种自适应动量和解耦对比学习框架（AMD），结合了无监督和有监督对比学习策略。通过改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，我们的框架增强了模型识别罕见和复杂轨迹的能力。此外，我们设计了四种轨迹随机增强方法，并引入在线迭代聚类策略，使模型能够动态更新伪标签，更好地适应长尾数据的分布变化。我们提出了三种不同的标准来定义长尾轨迹，并在nuScenes和ETH/UCY数据集上进行了广泛的对比实验。结果表明，AMD不仅在长尾轨迹预测中实现了最优性能，还展示了卓越的整体预测精度。

</details>


### [116] [Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views](https://arxiv.org/abs/2507.01835)
**中文标题：调制与重建：从错位智能手机视图学习高光谱成像**

*Daniil Reutsky,Daniil Vladimirov,Yasin Mamedov,Georgy Perevozchikov,Nancy Mehta,Egor Ershov,Radu Timofte*

主要分类: cs.CV

摘要简述: 本文提出了一种多图像到高光谱重建（MI-HSR）框架，利用配备光谱滤镜的三摄像头智能手机系统，显著提升了高光谱重建的准确性。通过理论和实验分析，该方法比传统单摄像头系统提供了更丰富和多样化的光谱观测。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱重建（HSR）从RGB图像是一个严重信息丢失的病态问题，现有方法通常依赖单一RGB图像，限制了重建精度。本文旨在通过多摄像头系统和光谱滤镜设计，提升重建准确性。

研究方法: 提出了一种多图像到高光谱重建（MI-HSR）框架，利用三摄像头智能手机系统，其中两个镜头配备了精心选择的光谱滤镜。基于理论和实验分析，该方法提供了比传统单摄像头更丰富的光谱观测。同时，引入了首个MI-HSR数据集Doomer，包含来自三摄像头和高光谱参考相机的对齐图像。

研究结果: 实验表明，所提出的HSR模型在新基准测试中优于现有方法，光谱估计准确性比普通RGB相机提高了30%。

研究结论: 多视角光谱滤镜与商用硬件的结合，能够实现更准确和实用的高光谱成像解决方案。

中文摘要: 高光谱重建（HSR）从RGB图像是一个严重信息丢失的病态问题。现有方法通常依赖单一RGB图像，限制了重建精度。本文提出了一种新颖的多图像到高光谱重建（MI-HSR）框架，利用三摄像头智能手机系统，其中两个镜头配备了精心选择的光谱滤镜。通过理论和实验分析，该配置提供了比传统单摄像头更丰富和多样化的光谱观测。为支持这一新范式，我们引入了首个MI-HSR数据集Doomer，包含来自三摄像头和高光谱参考相机的对齐图像。实验表明，所提出的HSR模型在新基准测试中优于现有方法，光谱估计准确性比普通RGB相机提高了30%。我们的研究表明，多视角光谱滤镜与商用硬件的结合，能够实现更准确和实用的高光谱成像解决方案。

</details>


### [117] [MobileIE: An Extremely Lightweight and Effective ConvNet for Real-Time Image Enhancement on Mobile Devices](https://arxiv.org/abs/2507.01838)
**中文标题：MobileIE：一种极轻量级且高效的卷积神经网络，用于移动设备上的实时图像增强**

*Hailong Yan,Ao Li,Xiangtao Zhang,Zhe Liu,Zenglin Shi,Ce Zhu,Le Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种极轻量级的卷积神经网络MobileIE，用于在移动设备上实现实时图像增强，仅需约4K参数，并通过多种优化策略在速度和性能间取得最佳平衡。


<details>
  <summary>详细信息</summary>
研究动机: 尽管深度学习在图像增强领域取得显著进展，但在资源受限的移动设备上部署仍面临计算和内存需求高的挑战。本文旨在解决这一问题，实现移动设备上的实时图像增强。

研究方法: 方法包括：1) 结合重参数化和增量权重优化策略的轻量级CNN框架；2) 特征自变换模块和分层双路径注意力机制；3) 局部方差加权损失优化。

研究结果: 该框架首次实现了高达1,100 FPS的实时图像增强推理，并在多个任务中取得速度和性能的最佳平衡。

研究结论: MobileIE在移动设备上实现了高效的实时图像增强，为资源受限平台提供了可行的解决方案。

中文摘要: 近年来，深度神经网络的发展显著推动了图像增强（IE）领域的进步。然而，由于高计算和内存需求，在移动设备等资源受限平台上部署深度学习模型仍具挑战性。为解决这些问题并实现移动设备上的实时IE，我们提出了一种极轻量级的卷积神经网络（CNN）框架，仅需约4K参数。我们的方法结合了重参数化和增量权重优化策略以确保效率。此外，通过特征自变换模块和分层双路径注意力机制，并采用局部方差加权损失优化，进一步提升了性能。凭借这一高效框架，我们首次实现了高达1,100帧每秒（FPS）的实时IE推理，同时提供具有竞争力的图像质量，在多个IE任务中实现了速度和性能的最佳平衡。代码将在https://github.com/AVC2-UESTC/MobileIE.git提供。

</details>


### [118] [Future Slot Prediction for Unsupervised Object Discovery in Surgical Video](https://arxiv.org/abs/2507.01882)
**中文标题：手术视频中无监督对象发现的未来槽预测**

*Guiqiu Liao,Matjaz Jogan,Marcel Hussing,Edward Zhang,Eric Eaton,Daniel A. Hashimoto*

主要分类: cs.CV

摘要简述: 本文提出了一种动态时序槽变换器（DTST）模块，用于预测未来槽初始化，以解决手术视频中无监督对象发现的挑战。该方法在多个手术数据库中实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 手术视频中的异构场景难以解析为有意义的一组槽，而现有方法在手术视频上的性能较低。因此，需要一种能够动态预测未来槽初始化的方法，以提升无监督对象发现的性能。

研究方法: 提出动态时序槽变换器（DTST）模块，该模块同时训练用于时序推理和预测最优未来槽初始化，以优化无监督对象发现的效果。

研究结果: 在多个手术数据库上，该方法实现了最先进的性能，验证了无监督对象中心方法在真实世界数据中的适用性。

研究结论: 动态时序槽变换器（DTST）模块成功解决了手术视频中无监督对象发现的挑战，展示了其在医疗应用中的潜力。

中文摘要: 对象中心槽注意力是一种新兴的无监督学习范式，用于学习结构化、可解释的对象中心表示（槽）。这使得能够以较低的计算成本对对象和事件进行有效推理，从而适用于实时解读手术视频等关键医疗应用。然而，手术等真实世界应用中的异构场景难以解析为一组有意义的槽。现有方法在图像上表现良好，但在手术视频上性能较低。为解决这一挑战，我们提出了一种动态时序槽变换器（DTST）模块，该模块同时训练用于时序推理和预测最优未来槽初始化。该模型在多个手术数据库上实现了最先进的性能，表明无监督对象中心方法可以应用于真实世界数据，并成为医疗应用中的常见工具。

</details>


### [119] [Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification](https://arxiv.org/abs/2507.01884)
**中文标题：基于自增强原型进化与双知识协作的半监督终身行人重识别**

*Kunlun Xu,Fan Zhuo,Jiangmeng Li,Xu Zou,Jiahuan Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的自增强原型进化与双知识协作框架（SPRED），用于解决半监督终身行人重识别问题。通过动态原型引导的伪标签生成和新旧知识协同净化，显著提升了未标记数据的利用率，实现了长期学习的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 现实场景中，标注资源有限，大量未标记数据与少量标记样本共存，导致半监督终身行人重识别（Semi-LReID）问题。现有方法在利用未标记数据时易受噪声知识影响，长期适应性能受限。本文旨在解决这一问题。

研究方法: 提出SPRED框架，通过动态原型捕捉身份分布并生成高质量伪标签，结合双知识协作方案（当前模型特化与历史模型泛化）净化噪声伪标签，形成自增强循环。

研究结果: 在Semi-LReID基准测试中，SPRED实现了最先进的性能，验证了其有效性。

研究结论: SPRED通过自增强原型进化和双知识协作，显著提升了半监督终身行人重识别的性能，为长期学习提供了可靠解决方案。

中文摘要: 当前的终身行人重识别（LReID）方法主要依赖完全标记的数据流。然而，在现实场景中，标注资源有限，大量未标记数据与稀缺标记样本共存，导致半监督LReID（Semi-LReID）问题，现有方法性能严重下降。即使结合半监督策略，现有LReID方法仍因未标记数据利用中的噪声知识而长期适应性能受限。本文首次研究Semi-LReID，提出了一种新型的自增强原型进化与双知识协作框架（SPRED）。其核心创新在于建立动态原型引导的伪标签生成与新知识协同净化的自增强循环，以提升未标记数据的利用率。具体而言，引入可学习的身份原型动态捕捉身份分布并生成高质量伪标签；随后，双知识协作方案结合当前模型特化与历史模型泛化，净化噪声伪标签。通过这一循环设计，逐步挖掘可靠的伪标签，提升当前阶段学习并确保长期学习的正向知识传播。在建立的Semi-LReID基准测试中，SPRED实现了最先进的性能。源代码见https://github.com/zhoujiahuan1991/ICCV2025-SPRED。

</details>


### [120] [Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning](https://arxiv.org/abs/2507.01908)
**中文标题：基于推理的编辑：通过视觉推理实现假设性指令的图像编辑**

*Qingdong He,Xueqin Chen,Chaoyi Wang,Yanjie Pan,Xiaobin Hu,Zhenye Gan,Yabiao Wang,Chengjie Wang,Xiangtai Li,Jiangning Zhang*

主要分类: cs.CV

摘要简述: 本文提出Reason50K数据集和ReasonBrain框架，用于解决基于指令的图像编辑中复杂假设性指令的推理问题，通过多模态大语言模型和细粒度推理线索提取模块提升编辑能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于指令的图像编辑方法主要处理简单显式指令，难以应对需要深度推理的复杂假设性指令，且缺乏支持此类推理的训练和评估数据集。

研究方法: 提出Reason50K数据集（包含50K样本，覆盖物理、时间、因果和故事推理场景）和ReasonBrain框架（结合多模态大语言模型和细粒度推理线索提取模块，并引入跨模态增强器以减少语义损失）。

研究结果: ReasonBrain在推理场景中显著优于现有基线方法，并在传统指令编辑任务中表现出强大的零样本泛化能力。

研究结论: Reason50K和ReasonBrain为复杂假设性指令的图像编辑提供了有效解决方案，推动了该领域的发展。

中文摘要: 基于指令的图像编辑（IIE）随着扩散模型的成功迅速发展。然而，现有研究主要关注简单显式指令（如添加、删除、移动或替换对象），难以处理需要深度推理以推断合理视觉变化和用户意图的复杂假设性指令。此外，当前数据集对支持推理感知编辑能力的训练和评估有限。在架构上，这些方法也缺乏支持此类推理的细粒度细节提取机制。为解决这些问题，我们提出了Reason50K，一个专门为训练和评估假设性指令推理图像编辑而构建的大规模数据集，以及ReasonBrain，一个新颖的框架，旨在推理和执行多样化场景中的隐式假设性指令。Reason50K包含超过50K样本，涵盖四种关键推理场景：物理、时间、因果和故事推理。ReasonBrain利用多模态大语言模型（MLLMs）生成编辑指导，并通过扩散模型进行图像合成，同时引入细粒度推理线索提取（FRCE）模块以捕获支持指令推理所需的详细视觉和文本语义。为减少语义损失，我们还提出了跨模态增强器（CME），以促进细粒度线索与MLLM衍生特征之间的丰富交互。大量实验表明，ReasonBrain在推理场景中始终优于最先进的基线方法，同时在传统IIE任务中表现出强大的零样本泛化能力。我们的数据集和代码将公开发布。

</details>


### [121] [Modality Agnostic, patient-specific digital twins modeling temporally varying digestive motion](https://arxiv.org/abs/2507.01909)
**中文标题：模态无关的患者特异性数字孪生模型：模拟时间变化的消化运动**

*Jorge Tapias Gomez,Nishant Nadkarni,Lando S. Bosma,Jue Jiang,Ergys D. Subashi,William P. Segars,James M. Balter,Mert R Sabuncu,Neelam Tyagi,Harini Veeraraghavan*

主要分类: cs.CV

摘要简述: 本文提出了一种患者特异性数字孪生（DT）模型，用于评估可变形图像配准（DIR）方法的准确性，模拟了胃肠道（GI）器官的动态运动，并验证了剂量映射的精确性。


<details>
  <summary>详细信息</summary>
研究动机: 临床中，可变形图像配准（DIR）需要基于体素的空间精度指标（如手动标记点），但对于高度移动的胃肠道器官难以实现。因此，需要一种新的方法来评估DIR的准确性。

研究方法: 通过半自动化流程，从静态3D患者扫描中生成21个模拟消化GI运动的4D序列，使用已发表的GI运动模型。数据集包括6个T2w MRI、2个T1w 4D MRI和3个增强CT扫描。通过比较DT模型与真实患者胃部运动数据，评估DIR方法的性能，包括目标配准误差、Dice相似系数和Hausdorff距离。

研究结果: DT模型成功模拟了真实的GI运动，运动幅度与真实患者数据相似（平均和最大运动幅度分别为0.8 mm和0.01）。该方法能够提取详细的DIR性能指标，并验证剂量映射的准确性。

研究结论: 该流程为动态且解剖复杂的区域提供了严格的DIR工具测试，实现了空间和剂量精度的详细验证。

中文摘要: 目的：临床实施可变形图像配准（DIR）需要基于体素的空间精度指标（如手动标记点），但对于高度移动的胃肠道（GI）器官难以实现。为此，我们创建了患者特异性数字孪生（DT）模型，用于评估DIR方法的准确性。方法：通过半自动化流程，从静态3D患者扫描中生成21个模拟消化GI运动的4D序列，使用已发表的GI运动模型。数据集包括6个T2w MRI、2个T1w 4D MRI和3个增强CT扫描。通过比较DT模型与真实患者胃部运动数据，评估DIR方法的性能，包括目标配准误差、Dice相似系数和Hausdorff距离。最后，对部分接受MR引导放射治疗的患者的T2w MRI扫描，通过剂量分布变形和累积评估剂量变形误差。主要结果：DT模型成功模拟了真实的GI运动，运动幅度与真实患者数据相似（平均和最大运动幅度分别为0.8 mm和0.01）。该方法能够提取详细的DIR性能指标，并验证剂量映射的准确性。意义：该流程为动态且解剖复杂的区域提供了严格的DIR工具测试，实现了空间和剂量精度的详细验证。

</details>


### [122] [3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP](https://arxiv.org/abs/2507.01912)
**中文标题：基于深度学习和Fast GICP的商业果园休眠期与生长期3D重建及信息融合**

*Ranjan Sapkota,Zhichao Meng,Martin Churuvija,Xiaoqiang Du,Zenghong Ma,Manoj Karkee*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习和Fast GICP的多季节信息融合框架，用于商业果园中休眠期和生长期的3D重建，以解决生长期树冠遮挡问题，提升机器人自动化操作的精度。


<details>
  <summary>详细信息</summary>
研究动机: 在果园自动化中，生长期的茂密树叶严重遮挡了树干和树枝等结构，限制了机器视觉系统的能力。而休眠期树叶脱落，树冠结构更清晰可见。因此，本文旨在通过融合多季节的结构数据，为整个生长季的机器人自动化管理提供支持。

研究方法: 框架结合了休眠期和生长期的高分辨率RGB-D图像，使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，以及Fast GICP进行模型对齐。分割结果用于提取深度信息掩码，通过Kinect Fusion实现精确的3D点云重建，最后通过Fast GICP实现跨季节的模型对齐。

研究结果: YOLOv9-Seg在休眠期数据集上实现了0.0047的均方误差和0.78的mAP@50分数。Kinect Fusion重建的树干直径、树枝直径和间距的均方根误差分别为5.23毫米、4.50毫米和13.72毫米。Fast GICP实现了精确的跨季节配准，最小适应分数为0.00197。

研究结论: 该框架通过融合多季节数据，克服了生长期的遮挡问题，为机器人系统提供了全面的树冠结构信息，显著提升了修剪、疏果等自动化操作的精度。

中文摘要: 在果园自动化中，生长期的茂密树叶严重遮挡了树干和树枝等树冠结构，限制了机器视觉系统的能力。然而，休眠期树叶脱落，树冠结构更加清晰可见。本文提出了一种信息融合框架，通过整合多季节的结构数据，支持整个生长季的机器人自动化作物负载管理。该框架结合了休眠期和生长期的高分辨率RGB-D图像，使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，以及Fast GICP进行模型对齐。分割结果用于提取深度信息掩码，通过Kinect Fusion实现精确的3D点云重建；随后通过Fast GICP对这些重建模型进行对齐，实现空间一致的多季节融合。YOLOv9-Seg模型在手动标注的图像上训练，休眠期数据集的树干分割mAP@50分数达到0.78，均方误差为0.0047。Kinect Fusion实现了树几何的精确重建，验证结果显示树干直径、树枝直径和间距的均方根误差分别为5.23毫米、4.50毫米和13.72毫米。Fast GICP实现了精确的跨季节配准，最小适应分数为0.00197，即使在生长期严重遮挡的情况下，也能实现集成的、全面的树冠结构建模。这种融合的结构表示使机器人系统能够获取原本被遮挡的结构信息，从而提高了修剪、疏果等自动化果园操作的精度。

</details>


### [123] [IC-Custom: Diverse Image Customization via In-Context Learning](https://arxiv.org/abs/2507.01926)
**中文标题：IC-Custom：通过上下文学习实现多样化图像定制**

*Yaowei Li,Xiaoyu Li,Zhaoyang Zhang,Yuxuan Bian,Gan Liu,Xinyuan Li,Jiale Xu,Wenbo Hu,Yating Liu,Lingen Li,Jing Cai,Yuexian Zou,Yancheng He,Ying Shan*

主要分类: cs.CV

摘要简述: IC-Custom提出了一种统一的图像定制框架，通过上下文学习整合位置感知和无位置定制，支持多种工业应用，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前图像定制方法分为位置感知和无位置定制两种范式，缺乏统一框架，限制了多样化应用。IC-Custom旨在通过上下文学习解决这一问题。

研究方法: IC-Custom通过将参考图像与目标图像拼接为多联画，利用DiT的多模态注意力机制实现细粒度交互。引入ICMA机制，结合可学习的任务导向注册令牌和边界感知位置嵌入，以区分不同任务和输入。

研究结果: IC-Custom在ProductBench和DreamBench上表现优异，人类偏好评分高出73%，同时仅训练原模型参数的0.4%。

研究结论: IC-Custom为图像定制提供了通用框架，支持多样化场景应用，性能显著优于现有方法。

中文摘要: 图像定制是工业媒体生产中的关键技术，旨在生成与参考图像一致的内容。然而，现有方法通常将图像定制分为位置感知和无位置定制两种范式，缺乏通用框架，限制了多样化应用。为此，我们提出IC-Custom，一种通过上下文学习无缝整合两种范式的统一框架。IC-Custom将参考图像与目标图像拼接为多联画，利用DiT的多模态注意力机制实现细粒度令牌级交互。我们引入ICMA机制，结合可学习的任务导向注册令牌和边界感知位置嵌入，使模型能正确处理不同任务类型并区分多联画中的输入。为填补数据空白，我们精心构建了12k身份一致的高质量数据集（8k来自真实世界，4k来自高质量合成数据），避免合成图像的过度光泽和饱和问题。IC-Custom支持多种工业应用，包括试穿、配饰放置、家具布置和创意IP定制。在ProductBench和公开的DreamBench上的广泛评估表明，IC-Custom显著优于社区工作流、闭源模型和开源方法，在身份一致性、和谐性和文本对齐指标上获得约73%更高的人类偏好，同时仅训练原模型参数的0.4%。项目页面：https://liyaowei-stu.github.io/project/IC_Custom

</details>


### [124] [evMLP: An Efficient Event-Driven MLP Architecture for Vision](https://arxiv.org/abs/2507.01927)
**中文标题：evMLP：一种用于视觉的高效事件驱动MLP架构**

*Zhentan Zheng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为evMLP的高效事件驱动MLP架构，通过局部更新机制选择性处理图像或特征图中的变化区域，显著提升了视频处理的计算效率，同时在图像分类任务中保持与先进模型相当的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度学习在计算机视觉任务中的广泛应用，卷积神经网络（CNN）和视觉变换器（ViT）成为主流架构。近年来，多层感知机（MLP）的应用为视觉模型架构研究提供了新视角。然而，传统方法在处理序列图像数据（如视频）时存在冗余计算问题。本文旨在通过事件驱动机制优化MLP的计算效率。

研究方法: 本文提出evMLP架构，采用事件驱动的局部更新机制。该机制将连续帧之间的变化定义为“事件”，并仅对发生事件的图像块进行处理，避免了冗余计算。evMLP通过MLP独立处理图像或特征图中的块，适用于视频等序列数据。

研究结果: 在ImageNet图像分类任务中，evMLP的准确性可与最先进模型媲美。在多个视频数据集上的实验表明，evMLP通过事件驱动机制显著降低了计算成本，同时保持了与非事件驱动基线模型一致的输出结果。

研究结论: evMLP通过事件驱动的局部更新机制，在保持模型性能的同时显著提升了计算效率，为视频处理和序列图像数据的应用提供了高效解决方案。

中文摘要: 深度神经网络在计算机视觉任务中取得了显著成果。早期，卷积神经网络（CNN）是主流架构。近年来，视觉变换器（ViT）逐渐流行。此外，多层感知机（MLP）的应用为视觉模型架构研究提供了新视角。本文提出了一种名为evMLP的架构，并配备了一种简单的事件驱动局部更新机制。evMLP能够通过MLP独立处理图像或特征图中的块。我们将连续帧之间的变化定义为“事件”，在事件驱动机制下，evMLP选择性处理发生事件的块。对于序列图像数据（如视频处理），这种方法通过避免冗余计算提升了计算性能。通过ImageNet图像分类实验，evMLP的准确性与最先进模型相当。更重要的是，在多个视频数据集上的实验表明，evMLP通过事件驱动机制降低了计算成本，同时保持了与非事件驱动基线模型一致的输出结果。代码和训练模型可在https://github.com/i-evi/evMLP获取。

</details>


### [125] [CI-VID: A Coherent Interleaved Text-Video Dataset](https://arxiv.org/abs/2507.01938)
**中文标题：CI-VID：一个连贯的交错文本-视频数据集**

*Yiming Ju,Jijin Hu,Zhengxiong Luo,Haoge Deng,hanyu Zhao,Li Du,Chengwei Wu,Donglin Hao,Xinlong Wang,Tengfei Pan*

主要分类: cs.CV

摘要简述: 本文介绍了CI-VID数据集，旨在解决现有文本-视频数据集中缺乏连贯多场景视频序列的问题，支持文本和视频到视频的生成任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本-视频数据集主要由孤立的文本-视频对组成，无法支持连贯多场景视频序列的建模。为了解决这一问题，作者提出了CI-VID数据集。

研究方法: CI-VID数据集包含超过34万个样本，每个样本由连贯的视频片段序列及其文本描述组成，文本描述不仅涵盖单个片段内容，还包含片段间的过渡信息。此外，作者设计了一个多维度的基准测试，包括人工评估、基于视觉语言模型的评估和相似性度量。

研究结果: 实验结果表明，使用CI-VID训练的模型在生成视频序列时，准确性和内容一致性均有显著提升，能够生成具有平滑视觉过渡和强时间连贯性的故事驱动内容。

研究结论: CI-VID数据集为连贯多场景视频生成提供了高质量的数据支持，具有重要的实用价值。数据集和代码已公开。

中文摘要: 文本到视频（T2V）生成近年来受到广泛关注，推动了大量高质量数据集的发展。然而，现有的公共数据集主要由孤立的文本-视频（T-V）对组成，无法支持连贯多片段视频序列的建模。为解决这一问题，我们提出了CI-VID数据集，从孤立的文本到视频生成扩展到文本和视频到视频（TV2V）生成，使模型能够生成连贯的多场景视频序列。CI-VID包含超过34万个样本，每个样本由连贯的视频片段序列及其文本描述组成，文本描述不仅涵盖单个片段内容，还包含片段间的过渡信息，从而实现视觉和文本上的连贯生成。为进一步验证CI-VID的有效性，我们设计了一个全面的多维度基准测试，包括人工评估、基于视觉语言模型的评估和相似性度量。实验结果表明，使用CI-VID训练的模型在生成视频序列时，准确性和内容一致性均有显著提升，能够生成具有平滑视觉过渡和强时间连贯性的故事驱动内容，凸显了CI-VID数据集的质量和实用价值。CI-VID数据集及相关代码已发布于：https://github.com/ymju-BAAI/CI-VID

</details>


### [126] [LongAnimation: Long Animation Generation with Dynamic Global-Local Memory](https://arxiv.org/abs/2507.01945)
**中文标题：LongAnimation：基于动态全局-局部记忆的长动画生成**

*Nan Chen,Mengqi Huang,Yihao Meng,Zhendong Mao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LongAnimation的新框架，通过动态全局-局部记忆模块（DGLM）和颜色一致性奖励机制，实现了长动画的自动着色，解决了传统方法在长期颜色一致性上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 长动画着色在动画产业中具有高劳动成本，现有研究仅适用于短时着色且忽视全局信息，无法保持长期颜色一致性。因此，研究一种动态全局-局部范式以实现长期颜色一致性具有重要价值。

研究方法: LongAnimation框架包括SketchDiT、动态全局-局部记忆模块（DGLM）和颜色一致性奖励机制。SketchDiT提取混合参考特征支持DGLM模块，DGLM动态压缩全局历史特征并与当前生成特征融合，颜色一致性奖励用于优化颜色一致性。

研究结果: 在短时（14帧）和长时（平均500帧）动画上的实验表明，LongAnimation在开放域动画着色任务中能有效保持短期和长期颜色一致性。

研究结论: LongAnimation通过动态全局-局部记忆和颜色一致性奖励机制，显著提升了长动画着色的颜色一致性，为动画产业提供了高效解决方案。

中文摘要: 动画着色是动画产业生产中的关键环节，长动画着色劳动成本高昂。因此，基于视频生成模型的自动化长动画着色具有重要研究价值。现有研究局限于短时着色，采用局部范式融合重叠特征以实现局部片段间的平滑过渡，但忽视了全局信息，无法保持长期颜色一致性。本研究提出，理想的长期颜色一致性可通过动态全局-局部范式实现，即动态提取与当前生成相关的全局颜色一致特征。具体而言，我们提出LongAnimation框架，主要包括SketchDiT、动态全局-局部记忆模块（DGLM）和颜色一致性奖励机制。SketchDiT捕获混合参考特征以支持DGLM模块，DGLM模块利用长视频理解模型动态压缩全局历史特征并自适应地将其与当前生成特征融合。为优化颜色一致性，我们引入颜色一致性奖励。在推理阶段，提出颜色一致性融合以平滑视频片段过渡。在短时（14帧）和长时（平均500帧）动画上的广泛实验表明，LongAnimation在开放域动画着色任务中能有效保持短期和长期颜色一致性。代码可在https://cn-makers.github.io/long_animation_web/获取。

</details>


### [127] [Kwai Keye-VL Technical Report](https://arxiv.org/abs/2507.01949)
**中文标题：快手Keye-VL技术报告**

*Kwai Keye Team,Biao Yang,Bin Wen,Changyi Liu,Chenglong Chu,Chengru Song,Chongling Rao,Chuan Yi,Da Li,Dunju Zang,Fan Yang,Guorui Zhou,Hao Peng,Haojie Ding,Jiaming Huang,Jiangxia Cao,Jiankang Chen,Jingyun Hua,Jin Ouyang,Kaibing Chen,Kaiyu Jiang,Kaiyu Tang,Kun Gai,Shengnan Zhang,Siyang Mao,Sui Huang,Tianke Zhang,Tingting Gao,Wei Chen,Wei Yuan,Xiangyu Wu,Xiao Hu,Xingyu Lu,Yang Zhou,Yi-Fan Zhang,Yiping Yang,Yulong Chen,Zhenhua Wu,Zhenyu Li,Zhixin Ling,Ziming Li,Dehua Ma,Di Xu,Haixuan Gao,Hang Li,Jiawei Guo,Jing Wang,Lejian Ren,Muhao Wei,Qianqian Wang,Qigen Hu,Shiyao Wang,Tao Yu,Xinchen Luo,Yan Li,Yiming Liang,Yuhang Hu,Zeyi Lu,Zhuoran Yang,Zixing Zhang*

主要分类: cs.CV

摘要简述: 快手Keye-VL技术报告介绍了一款8B参数的多模态基础模型，专注于短视频理解，同时保持通用视觉语言能力。通过大规模高质量数据集和创新的四阶段预训练与两阶段后训练方法，模型在视频和图像任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型（MLLMs）在静态图像上表现优异，但在动态、信息密集的短视频理解上表现不足。快手Keye-VL旨在填补这一空白，提升短视频理解能力。

研究方法: Keye-VL基于6000亿标记的大规模高质量数据集，采用四阶段预训练和两阶段后训练方法。后训练包括基础能力增强和高级推理激发，创新性地使用五种模式的“冷启动”数据混合方法。

研究结果: Keye-VL在公开视频基准测试中达到最先进水平，同时在通用图像任务中保持竞争力。此外，发布的KC-MMBench基准测试显示其在真实短视频场景中的显著优势。

研究结论: Keye-VL通过创新的训练方法和高质量数据集，显著提升了短视频理解能力，同时保持了通用视觉语言任务的竞争力。

中文摘要: 尽管多模态大语言模型（MLLMs）在静态图像上表现出色，但在理解动态且信息密集的短视频（当今数字领域的主要媒介）方面往往表现不足。为填补这一空白，我们推出了**快手Keye-VL**，这是一款拥有80亿参数的多模态基础模型，旨在实现短视频理解的前沿性能，同时保持强大的通用视觉语言能力。Keye-VL的开发基于两大核心支柱：一个超过6000亿标记的大规模高质量数据集（重点为视频数据）和一种创新的训练方法。该方法包括四阶段预训练以实现扎实的视觉语言对齐，随后是细致的两阶段后训练。第一阶段后训练增强基础能力（如指令遵循），而第二阶段专注于激发高级推理能力。在第二阶段中，一个关键创新是我们的五种模式“冷启动”数据混合方法，包括“思考”、“非思考”、“自动思考”、“带图像思考”和高质量视频数据。这种混合方法教会模型决定何时以及如何进行推理。随后的强化学习（RL）和对齐步骤进一步增强了这些推理能力，并纠正了异常模型行为（如重复输出）。为验证我们的方法，我们进行了广泛评估，结果表明Keye-VL在公开视频基准测试中达到了最先进水平，同时在通用图像任务中保持高度竞争力（图1）。此外，我们开发并发布了**KC-MMBench**，这是一个专为真实短视频场景设计的新基准测试，Keye-VL在其中显示出显著优势。

</details>


### [128] [FreeMorph: Tuning-Free Generalized Image Morphing with Diffusion Model](https://arxiv.org/abs/2507.01953)
**中文标题：FreeMorph：基于扩散模型的无调优通用图像变形方法**

*Yukang Cao,Chenyang Si,Jinghao Wang,Ziwei Liu*

主要分类: cs.CV

摘要简述: FreeMorph是一种无需调优的图像变形方法，适用于不同语义或布局的输入，通过创新的插值设计和注意力模块改进，实现高质量变形，速度提升10~50倍。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像变形方法依赖预训练扩散模型的微调，受限于时间和语义/布局差异，FreeMorph旨在无需实例训练即可实现高保真变形。

研究方法: 1) 提出一种基于输入图像显式指导的球面插值设计，通过修改自注意力模块解决身份丢失问题；2) 引入步长导向的变化趋势，混合输入图像的自注意力模块以实现可控过渡。

研究结果: FreeMorph在图像变形任务中表现优异，速度比现有方法快10~50倍，并达到新的最优水平。

研究结论: FreeMorph通过创新设计解决了无需调优的图像变形挑战，为高质量变形提供了高效解决方案。

中文摘要: 我们提出了FreeMorph，这是第一种无需调优的图像变形方法，适用于具有不同语义或布局的输入。与现有依赖预训练扩散模型微调的方法不同，FreeMorph无需实例训练即可实现高保真图像变形。尽管无需调优方法具有高效性和潜力，但由于多步去噪过程的非线性特性以及预训练扩散模型的固有偏差，其在保持高质量结果方面面临挑战。本文通过引入两项关键创新来解决这些挑战：1）我们首先提出了一种基于输入图像显式指导的球面插值设计，通过修改自注意力模块解决身份丢失问题，并确保生成序列中的定向过渡；2）我们进一步引入了一种步长导向的变化趋势，混合来自每个输入图像的自注意力模块，以实现受控且一致的过渡。广泛的评估表明，FreeMorph在图像变形任务中优于现有方法，速度提升10~50倍，并确立了新的最优水平。

</details>


### [129] [How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks](https://arxiv.org/abs/2507.01955)
**中文标题：GPT-4o对视觉的理解有多强？评估多模态基础模型在标准计算机视觉任务中的表现**

*Rahul Ramachandran,Ali Garjani,Roman Bachmann,Andrei Atanov,Oğuzhan Fatih Kar,Amir Zamir*

主要分类: cs.CV

摘要简述: 本文评估了GPT-4o等多模态基础模型在标准计算机视觉任务（如语义分割、目标检测等）上的表现，发现它们虽不及专业模型，但作为通用模型表现尚可，且语义任务优于几何任务。GPT-4o在非推理模型中表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 多模态基础模型（如GPT-4o）在视觉理解方面的能力尚不明确，本文旨在通过标准计算机视觉任务评估其表现，填补这一研究空白。

研究方法: 通过提示链技术将标准视觉任务转化为文本可提示和API兼容的任务，建立标准化评估框架，测试模型在COCO、ImageNet等数据集上的性能。

研究结果: 1. 模型不及专业模型；2. 作为通用模型表现尚可；3. 语义任务优于几何任务；4. GPT-4o在非推理模型中表现最佳；5. 推理模型在几何任务中有所提升；6. 生成图像的模型存在幻觉和空间错位问题。

研究结论: 多模态基础模型在视觉任务中表现尚可，但仍有提升空间，尤其是几何任务和生成图像的模型需进一步优化。

中文摘要: 多模态基础模型（如GPT-4o）近年来取得了显著进展，但其在视觉理解方面的能力尚不明确。本文通过标准计算机视觉任务（如语义分割、目标检测、图像分类等）评估了主流多模态基础模型（GPT-4o、o4-mini、Gemini 1.5 Pro和Gemini 2.0 Flash、Claude 3.5 Sonnet、Qwen2-VL、Llama 3.2）的表现，使用了COCO、ImageNet等数据集。主要挑战包括：1) 多数模型仅输出文本，无法直接表达复杂领域（如分割或3D几何）；2) 许多领先模型为专有模型，仅能通过API访问。我们通过提示链技术将标准视觉任务转化为文本可提示和API兼容的任务，建立了标准化评估框架。结果表明：1) 模型在所有任务中均不及专业模型；2) 作为通用模型表现尚可；3) 语义任务表现优于几何任务；4) 提示链技术影响性能，但更好的模型对提示变化敏感性更低；5) GPT-4o在非推理模型中表现最佳，在6项任务中4项领先；6) 推理模型（如o3）在几何任务中有所提升；7) 生成图像的模型（如最新GPT-4o）存在幻觉和空间错位问题。

</details>


### [130] [Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation](https://arxiv.org/abs/2507.01957)
**中文标题：局部感知并行解码用于高效自回归图像生成**

*Zhuoyang Zhang,Luke J. Huang,Chengyue Wu,Shang Yang,Kelly Peng,Yao Lu,Song Han*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“局部感知并行解码”（LPD）的方法，用于加速自回归图像生成。通过灵活的并行化建模和局部感知生成顺序，显著减少了生成步骤，同时保持生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统的自回归图像生成依赖逐块预测，导致高延迟。现有方法尝试通过多块预测并行化，但效果有限。本文旨在实现高并行化且不损失生成质量。

研究方法: 1. 灵活的并行化自回归建模：支持任意生成顺序和并行度，使用可学习的位置查询令牌指导生成，确保并行解码的一致性。2. 局部感知生成顺序：通过分组最小化组内依赖，最大化上下文支持，提升生成质量。

研究结果: 在ImageNet类条件生成任务中，将生成步骤从256减少到20（256×256分辨率）和1024减少到48（512×512分辨率），且延迟比现有并行化模型降低至少3.4倍。

研究结论: LPD方法通过创新的并行化技术和生成顺序优化，显著提升了自回归图像生成的效率，同时保持了高质量的输出。

中文摘要: 我们提出了局部感知并行解码（LPD）以加速自回归图像生成。传统的自回归图像生成依赖逐块预测，这一内存密集型过程导致高延迟。现有研究尝试通过转向多块预测来并行化，但仅实现了有限的加速。为实现高并行化且不损失生成质量，我们引入了两项关键技术：（1）灵活的并行化自回归建模：一种支持任意生成顺序和并行度的新架构，使用可学习的位置查询令牌指导目标位置的生成，同时确保并行生成令牌之间的相互可见性以实现一致解码。（2）局部感知生成顺序：一种新颖的调度策略，通过分组最小化组内依赖并最大化上下文支持，提升生成质量。通过这些设计，我们在ImageNet类条件生成任务中，将生成步骤从256减少到20（256×256分辨率）和1024减少到48（512×512分辨率），且延迟比现有并行化自回归模型降低至少3.4倍。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [131] [Rethinking the Illusion of Thinking](https://arxiv.org/abs/2507.01231)
**中文标题：重新思考思考的幻觉**

*Iñaki Dellibarda Varela,Pablo Romero-Sorozabal,Eduardo Rocon,Manuel Cebrian*

主要分类: cs.AI

摘要简述: 本文通过复现和改进两项争议性实验（河内塔和渡河问题），澄清了关于大型推理模型（LRMs）是否具备真正推理能力的争论。研究发现，LRMs在复杂任务中表现受限，但在可解问题中表现优异，揭示了其真实能力与局限性。


<details>
  <summary>详细信息</summary>
研究动机: 苹果公司发布的《思考的幻觉》引发了对大型推理模型（LRMs）是否具备真正推理能力的争议。批评者认为LRMs只是随机模仿者，而支持者则质疑实验设计的合理性。本文旨在通过科学实验澄清这一争论。

研究方法: 复现并改进了两项争议性实验：河内塔和渡河问题。通过引入逐步提示和协作对话机制，重新评估LRMs在复杂任务中的表现。

研究结果: 河内塔实验显示，LRMs在复杂度适中（约8个盘子）时表现受限；渡河问题中，LRMs在可解配置下轻松解决涉及100多个代理对的任务。

研究结论: 当前LRMs是离散状态空间中的随机搜索器，其真实能力介于批评与支持者的极端观点之间。未来需通过精细实验进一步探索其推理能力。

中文摘要: 今年早些时候，苹果公司发布的《思考的幻觉》引发了AI社区的激烈争论。批评者将其视为大型推理模型（LRMs）缺乏真正推理能力的证据，称其为随机模仿者；而支持者（以Lawsen等人为首）则批评实验设计存在缺陷，结论夸大。本文通过复现和改进原研究中两项最具争议的基准测试（河内塔和渡河问题），澄清了这一争论。通过引入逐步提示和协作对话机制，我们发现河内塔实验中的失败并非完全由输出限制导致，部分源于认知局限：LRMs在复杂度适中（约8个盘子）时仍会失败。此外，渡河问题的结果最初被视为灾难性失败，但实际是因为测试了不可解配置。一旦严格限制为可解问题，LRMs能轻松解决涉及100多个代理对的任务。我们的研究最终否定了简单化的叙事：当前LRMs是我们尚未完全理解的离散状态空间中的随机搜索器。在符号化和长时程推理领域的真正进步，需要通过如本文所引入的精细实验来探索这一领域。

</details>


### [132] [Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care](https://arxiv.org/abs/2507.01282)
**中文标题：超越黑盒AI：可解释的混合系统在痴呆症护理中的应用**

*Matthew JY Kang,Wenli Yang,Monica R Roberts,Byeong Ho Kang,Charles B Malpas*

主要分类: cs.AI

摘要简述: 本文探讨了AI在痴呆症诊断与护理中的局限性，提出结合统计学习与专家知识的混合方法以提高透明度和临床实用性，强调未来AI应注重解释性和人机协作。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）在医疗诊断中展现出潜力，但其黑盒特性、幻觉问题及因果推理能力不足限制了临床实际应用。本文旨在分析AI在痴呆症护理中的局限性，并提出改进方向。

研究方法: 通过范围综述，分析AI在痴呆症诊断中的局限性，并探讨混合方法（如结合统计学习与专家规则）的优势，以提升透明度和临床实用性。

研究结果: 研究发现，纯数据驱动的AI模型缺乏可解释性，而混合方法（如PEIRS和ATHENA-CDS）能更好地融入临床工作流程。未来AI需注重解释性和人机协作。

研究结论: 未来AI决策支持系统应结合神经符号或混合方法，注重解释性和临床实用性，并通过改善人机交互推动AI在临床实践中的应用。

中文摘要: 近期大型语言模型（LLMs）的兴起重新点燃了人工智能（AI）系统辅助医疗诊断的希望。然而，尽管在基准测试中表现优异，LLMs尚未在临床实践中带来可衡量的改进。本文旨在探讨AI在痴呆症诊断与护理中的局限性。
  独立的机器学习模型擅长模式识别，但很少提供可操作且可解释的指导，削弱了临床医生的信任。医生使用LLMs并未显著提高诊断准确性或速度。关键问题源于数据驱动范式的局限性：缺乏透明度的黑盒输出、易产生幻觉以及薄弱的因果推理能力。结合统计学习与专家规则知识的混合方法，并在全过程中融入临床医生的参与，有助于恢复可解释性。例如PEIRS和ATHENA-CDS等系统显示，这些方法更符合现有临床工作流程。
  未来的决策支持系统应通过将预测与临床意义明确的因果关系联系起来，优先考虑解释性。这可以通过神经符号或混合AI实现，将LLMs的语言能力与人类因果专业知识相结合。AI研究者已开始关注这一方向，可解释AI和神经符号AI成为进一步发展的逻辑步骤。然而，这些方法仍基于数据驱动的知识整合，而非人机协作。未来研究应不仅以准确性衡量成功，还需关注临床医生理解、工作流程适应性和患者结果的改善。为了更好地推动AI系统融入临床实践，亟需深入理解如何优化人机交互。

</details>


### [133] [AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing](https://arxiv.org/abs/2507.01376)
**中文标题：AI代理与Agentic AI：探索未来智能制造中的多样化概念**

*Yinwang Ren,Yangyang Liu,Tang Ji,Xun Xu*

主要分类: cs.AI

摘要简述: 本文探讨了AI代理（如LLM-Agents、MLLM-Agents）和Agentic AI在智能制造中的潜力，系统回顾了其技术演进、核心概念及挑战。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI（GenAI）和大型语言模型（LLMs）的快速发展，AI代理在语义理解、复杂推理和自主决策方面的能力显著提升，但其在智能制造中的定义、能力边界和实际应用尚不明确，亟需系统研究。

研究方法: 本研究系统回顾了AI和AI代理技术的演进，分析了LLM-Agents、MLLM-Agents和Agentic AI的核心概念与技术进展，并探讨了其在智能制造中的应用与潜在挑战。

研究结果: 研究发现，LLM-Agents、MLLM-Agents和Agentic AI能够扩展AI在信息处理、环境感知和自主决策方面的能力，为智能制造开辟新途径，但仍面临定义模糊和应用挑战。

研究结论: 本文为理解AI代理和Agentic AI在智能制造中的潜力提供了系统框架，并指出了未来研究的方向和挑战。

中文摘要: AI代理是能够在动态环境中感知、推理和行动的自主系统。随着生成式AI（GenAI）的快速发展，大型语言模型（LLMs）和多模态大型语言模型（MLLMs）显著提升了AI代理在语义理解、复杂推理和自主决策方面的能力。同时，Agentic AI的兴起强调了在动态复杂环境中的适应性和目标导向自主性。基于LLMs的AI代理（LLM-Agents）、基于MLLMs的AI代理（MLLM-Agents）以及Agentic AI共同扩展了AI在信息处理、环境感知和自主决策方面的能力，为智能制造开辟了新途径。然而，这些新兴AI范式在智能制造中的定义、能力边界和实际应用仍不明确。为填补这一空白，本研究系统回顾了AI和AI代理技术的演进，探讨了LLM-Agents、MLLM-Agents和Agentic AI的核心概念与技术进展，并探索了其在制造领域的潜在应用与集成，以及可能面临的挑战。

</details>


### [134] [A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models](https://arxiv.org/abs/2507.01410)
**中文标题：基于模糊方法的伦理决策模型规范、验证与验证**

*Abeer Dyoub,Francesca A. Lisi*

主要分类: cs.AI

摘要简述: 本文提出了一种基于模糊规则的伦理决策模型形式化方法，并通过模糊Petri网进行验证和验证，以医学领域案例说明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 由于道德领域的本体论和认识论复杂性，建立明确的道德机器评估标准具有挑战性。本文旨在通过模糊方法解决伦理决策模型的规范、验证和验证问题。

研究方法: 提出了一种基于伦理风险评估的伦理决策模型形式化方法，并将其表示为模糊规则，利用模糊Petri网进行验证和验证。

研究结果: 通过医学领域的案例研究，验证了所提方法的可行性和有效性。

研究结论: 模糊方法为伦理决策模型的规范、验证和验证提供了一种有效途径，尤其在复杂道德领域具有应用潜力。

中文摘要: 道德领域的本体论和认识论复杂性使得建立明确的道德机器评估标准具有挑战性。本文提出了一种基于伦理风险评估的伦理决策模型形式化方法，并展示了如何通过模糊Petri网对这些模型（以模糊规则形式表示）进行验证和验证。通过医学领域的案例研究，说明了所提方法的有效性。

</details>


### [135] [Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading](https://arxiv.org/abs/2507.01431)
**中文标题：Pensieve评分器：基于AI的即用型平台，轻松实现手写STEM作业评分**

*Yoonseok Yang,Minjune Kim,Marlon Rondinelli,Keren Shao*

主要分类: cs.AI

摘要简述: Pensieve Grader是一个基于AI的手写STEM作业评分平台，利用大语言模型转录和评估学生作业，显著减少评分时间并保持高准确率。


<details>
  <summary>详细信息</summary>
研究动机: 大学STEM课程中手写开放式作业的评分效率低下，亟需一种能够覆盖从转录到反馈全流程的自动化工具。

研究方法: Pensieve平台整合大语言模型，支持从扫描作业到最终反馈的完整评分流程，并提供基于规则的分数、转录文本和置信度评分。

研究结果: 在20多所机构的实际课程中应用，评分超过30万份作业，平均减少65%的评分时间，高置信度预测与教师评分一致率达95.4%。

研究结论: Pensieve显著提升了STEM作业评分的效率和准确性，为教育领域提供了实用且高效的解决方案。

中文摘要: 评分手写开放式作业是大学STEM课程中的主要瓶颈。我们推出了Pensieve（https://www.pensieve.co），这是一个基于AI的辅助评分平台，利用大语言模型（LLM）转录和评估学生作业，为教师提供基于规则的分数、转录文本和置信度评分。与以往仅关注转录或规则生成等特定任务的工具不同，Pensieve支持从扫描作业到最终反馈的完整评分流程，并通过人机交互界面实现。Pensieve已在20多所机构的实际课程中部署，评分超过30万份学生作业。我们展示了系统在计算机科学、数学、物理和化学四个核心STEM学科中的细节和实证结果。结果显示，Pensieve平均减少65%的评分时间，同时在高置信度预测中与教师评分的一致率达到95.4%。

</details>


### [136] [Using multi-agent architecture to mitigate the risk of LLM hallucinations](https://arxiv.org/abs/2507.01446)
**中文标题：利用多代理架构降低大语言模型幻觉风险**

*Abd Elrahman Amer,Magdi Amer*

主要分类: cs.AI

摘要简述: 本文提出了一种多代理系统，结合模糊逻辑和大语言模型（LLM）代理，以减少LLM幻觉风险，提升客户服务质量。


<details>
  <summary>详细信息</summary>
研究动机: 提升客户服务质量和响应时间是维持客户忠诚度和增加市场份额的关键因素。尽管采用大语言模型（LLM）是实现这些目标的必要手段，但其幻觉风险仍是主要挑战。

研究方法: 本文设计了一个多代理系统，用于处理通过短信发送的客户请求。该系统结合了基于LLM的代理和模糊逻辑，以降低幻觉风险。

研究结果: 该系统成功整合了LLM代理和模糊逻辑，有效减少了幻觉风险，提升了客户服务的准确性和效率。

研究结论: 多代理系统结合模糊逻辑是减少LLM幻觉风险的有效方法，有助于提升客户服务质量。

中文摘要: 提升客户服务质量和响应时间是维持客户忠诚度和增加市场份额的关键因素。尽管采用大语言模型（LLM）是实现这些目标的必要手段，但其幻觉风险仍是主要挑战。本文提出了一种多代理系统，用于处理通过短信发送的客户请求。该系统结合了基于LLM的代理和模糊逻辑，以降低幻觉风险。

</details>


### [137] [Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning](https://arxiv.org/abs/2507.01489)
**中文标题：工具化代理：基于强化学习的分层决策研究**

*Yanfei Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为Agent-as-Tool的分层框架，通过分离工具调用和推理过程，减轻模型负担，显著提升了任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究同时处理工具调用和推理过程，导致模型负担过重且效率低下。本文旨在通过分层设计解决这一问题。

研究方法: 提出Agent-as-Tool框架，将工具调用和推理过程分离，由不同代理分别处理，并通过少量强化学习微调优化性能。

研究结果: 在Bamboogle任务中，模型表现优异，精确匹配率达到63.2%，覆盖精确匹配率为75.2%，显著优于现有方法。

研究结论: 分层框架Agent-as-Tool有效减轻了模型负担，提升了推理效率，为未来研究提供了新方向。

中文摘要: 近年来，大型语言模型（LLMs）成为人工智能领域最重要的技术进步之一。其理解、生成和推理自然语言的能力改变了我们与AI系统的交互方式。随着基于LLM的代理和强化学习推理模型的发展，将强化学习应用于代理框架的研究成为新的焦点。然而，现有研究同时面临工具调用和推理过程的决策挑战，且推理链依赖于工具输出的未处理原始结果，其中包含冗余信息和与任务无关的符号，严重增加了模型的推理负担。因此，本研究提出了分层框架Agent-as-Tool，分离工具调用和推理过程，使模型专注于语言推理，而工具调用由另一代理处理。我们的工作仅通过180个样本的轻微强化微调即取得了可比结果，并在Bamboogle任务中表现优异，精确匹配率达到63.2%，覆盖精确匹配率为75.2%，分别超过Search-R1方法4.8%和3.2%。

</details>


### [138] [T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2507.01597)
**中文标题：T3DM：基于测试时训练引导的分布偏移建模的时序知识图谱推理**

*Yuehang Si,Zefan Zeng,Jincai Huang,Qing Cheng*

主要分类: cs.AI

摘要简述: 本文提出了一种名为T3DM的新方法，通过测试时训练引导的分布偏移建模改进时序知识图谱推理，解决了训练与测试样本间事件分布偏移建模不足和负样本生成质量低的问题。


<details>
  <summary>详细信息</summary>
研究动机: 时序知识图谱（TKG）能有效描述事实的动态发展，但现有研究在建模训练与测试样本间的事件分布偏移时表现不足，且依赖随机实体替换生成低质量负样本。这些问题限制了模型的推理能力。

研究方法: 提出T3DM方法，通过测试时训练引导的分布偏移建模调整模型，确保推理的全局一致性；同时设计基于对抗训练的负采样策略，生成高质量负四元组。

研究结果: 实验表明，T3DM在多数情况下优于现有基线方法，提供了更优且更鲁棒的推理结果。

研究结论: T3DM通过改进分布偏移建模和负采样策略，显著提升了时序知识图谱推理的性能和鲁棒性。

中文摘要: 时序知识图谱（TKG）是一种描述事实随时间动态发展的有效方法。大多数关于TKG推理（TKGR）的研究集中于建模全局事实的重复性和设计局部历史事实的模式。然而，这些研究面临两大挑战：一是对训练与测试样本间事件分布偏移的建模不足；二是依赖随机实体替换生成负样本，导致采样质量较低。为此，我们提出了一种新的分布特征建模方法——基于测试时训练引导的分布偏移建模（T3DM），用于调整模型以适应分布偏移，并确保模型推理的全局一致性。此外，我们设计了一种基于对抗训练的负采样策略，以生成更高质量的负四元组。大量实验表明，T3DM在多数情况下优于现有基线方法，提供了更优且更鲁棒的结果。

</details>


### [139] [Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI](https://arxiv.org/abs/2507.01717)
**中文标题：Agent Ideate：基于代理AI的专利产品创意生成框架**

*Gopichand Kanumolu,Ashok Urlana,Charaka Vinayak Kumar,Bala Mallikarjunarao Garlapati*

主要分类: cs.AI

摘要简述: 本文提出了一种名为Agent Ideate的框架，利用大型语言模型（LLMs）和自主代理从专利中挖掘并生成产品创意。实验表明，代理方法在创意质量、相关性和新颖性上优于单独使用LLMs。


<details>
  <summary>详细信息</summary>
研究动机: 专利蕴含丰富的技术知识，可以激发创新产品创意，但获取和解读这些信息仍具挑战性。本文旨在探索如何利用LLMs和自主代理从专利中生成高质量的商业创意。

研究方法: 设计了Agent Ideate框架，结合开源LLMs和基于代理的架构，在计算机科学、自然语言处理和材料化学三个领域进行实验。

研究结果: 评估结果显示，代理方法在创意质量、相关性和新颖性上均优于单独使用LLMs。

研究结论: 结合LLMs和代理工作流可以显著提升创新流程，释放专利数据中未开发的商业创意潜力。

中文摘要: 专利蕴含丰富的技术知识，可以激发创新产品创意，但获取和解读这些信息仍具挑战性。本研究探索了利用大型语言模型（LLMs）和自主代理从专利中挖掘并生成产品概念的方法。我们设计了Agent Ideate框架，用于从专利中自动生成基于产品的商业创意。实验在计算机科学、自然语言处理和材料化学三个领域进行，使用了开源LLMs和基于代理的架构。评估结果表明，代理方法在创意质量、相关性和新颖性上均优于单独使用LLMs。这些发现表明，将LLMs与代理工作流结合，可以显著提升创新流程，释放专利数据中未开发的商业创意潜力。

</details>


### [140] [Joint Matching and Pricing for Crowd-shipping with In-store Customers](https://arxiv.org/abs/2507.01749)
**中文标题：联合匹配与定价：利用店内顾客进行众包配送**

*Arash Dehghan,Mucahit Cevik,Merve Bodur,Bissan Ghaddar*

主要分类: cs.AI

摘要简述: 本文研究了利用店内顾客作为众包配送员的集中式系统，通过联合匹配与动态定价优化最后一公里配送效率，实验表明该方法显著降低了配送成本。


<details>
  <summary>详细信息</summary>
研究动机: 针对城市地区最后一公里配送效率的需求增长，探索利用店内顾客作为众包配送员的潜力，以解决传统配送方式的高成本问题。

研究方法: 提出了一种马尔可夫决策过程（MDP）模型，结合神经近似动态规划（NeurADP）进行订单与顾客匹配，以及深度双Q网络（DDQN）进行动态定价，实现联合优化。

研究结果: 实验结果显示，NeurADP + DDQN策略比固定定价的NeurADP节省了6.7%的成本，比短视基线节省约18%；灵活配送延迟和多目的地路由进一步分别降低了8%和17%的运营成本。

研究结论: 动态前瞻性策略在众包配送系统中具有显著优势，为城市物流运营商提供了实用指导。

中文摘要: 本文研究了在集中式众包配送系统中利用店内顾客作为配送员的模式，以满足城市地区对高效最后一公里配送的日益增长的需求。我们考虑了一种实体零售场景，顾客可通过接受补偿来配送时效性强的在线订单。为管理这一过程，我们提出了一个马尔可夫决策过程（MDP）模型，该模型捕捉了订单和众包配送员的随机到达以及配送邀约的概率性接受等关键不确定性。我们的解决方案结合了神经近似动态规划（NeurADP）用于自适应订单与顾客匹配，以及深度双Q网络（DDQN）用于动态定价。这种联合优化策略支持多站点路由并考虑了邀约接受的不确定性，更贴近实际运营。实验结果表明，NeurADP + DDQN策略在配送成本效率上取得了显著提升，比固定定价的NeurADP节省了6.7%，比短视基线节省约18%。此外，允许灵活配送延迟和启用多目的地路由分别进一步降低了8%和17%的运营成本。这些发现凸显了动态前瞻性策略在众包配送系统中的优势，并为城市物流运营商提供了实用指导。

</details>


### [141] [Refining Gelfond Rationality Principle Towards More Comprehensive Foundational Principles for Answer Set Semantics](https://arxiv.org/abs/2507.01833)
**中文标题：完善Gelfond合理性原则以构建更全面的答案集语义基础原则**

*Yi-Dong Shen,Thomas Eiter*

主要分类: cs.AI

摘要简述: 本文探讨了答案集语义的基础原则，质疑了现有条件（如最小模型属性、约束单调性和基础性）的普适性，并提出了基于Gelfond合理性原则的改进版本，包括良好支持性和两种极小性，以更全面地定义答案集语义。


<details>
  <summary>详细信息</summary>
研究动机: 本文旨在解决两个核心问题：一是现有答案集语义的强制性条件是否过于严格；二是如何通过改进Gelfond的合理性原则，提出更全面的基础性原则，以更合理地定义答案集语义。

研究方法: 首先，通过实例说明现有条件的局限性；其次，改进Gelfond的合理性原则，提出良好支持性和两种极小性（默认否定和认知否定）的新原则；接着，将这些原则扩展到答案集和世界观的定义中；然后，基于新原则定义新的答案集语义；最后，用新原则评估现有语义并分析计算复杂度。

研究结果: 研究发现现有条件在某些情况下过于严格，可能排除预期的答案集。改进后的GAS原则（良好支持性和极小性）能更全面地定义答案集语义，并为评估现有语义提供了新基准。

研究结论: 本文通过改进Gelfond的合理性原则，提出了更全面的基础性原则，为答案集语义的定义和评估提供了新视角，并分析了其计算复杂性。

中文摘要: 非单调逻辑编程是答案集编程（ASP）这一声明式问题解决范式的基础。自Gelfond和Lifschitz于1988年对简单正规逻辑程序的初步定义以来，已提出了多种答案集语义的扩展。本文探讨两个关键问题：（1）文献中定义的最小模型属性、约束单调性和基础性是否应作为一般答案集语义的强制性条件？（2）如果不是，还有哪些属性可作为答案集语义的一般原则？我们首先指出，上述三个条件有时可能过于严格，并通过实例说明强制执行它们可能排除预期的答案集。其次，我们改进Gelfond的答案集（GAS）原则，将其合理性原则细化为良好支持性、默认否定的极小性和认知否定的极小性。良好支持性原则确保每个答案集均可通过遵循层级映射的规则构造，从而避免循环论证；而两种极小性原则确保形式化在答案集和世界观层面均最小化知识。第三，为体现改进的GAS原则，我们分别将良好支持性概念扩展到答案集和世界观。第四，基于改进的GAS原则定义新的答案集语义。第五，以改进的GAS原则为基准直观评估现有答案集语义。最后，我们分析了计算复杂度。

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [142] [End-to-End Large Portfolio Optimization for Variance Minimization with Neural Networks through Covariance Cleaning](https://arxiv.org/abs/2507.01918)
**中文标题：通过协方差清洗的神经网络端到端大规模投资组合方差最小化优化**

*Christian Bongiorno,Efstratios Manolakis,Rosario Nunzio Mantegna*

主要分类: q-fin.PM

摘要简述: 本文提出了一种旋转不变的神经网络，用于通过联合学习历史收益的滞后变换和大规模股票协方差矩阵的特征值与边际波动率的正则化，实现全局最小方差投资组合的端到端优化。该方法具有明确的数学映射和模块化解释性，且在跨维度应用中表现出强大的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统的最小方差投资组合优化方法在处理大规模股票协方差矩阵时面临计算复杂性和泛化能力不足的问题。本文旨在通过神经网络提供一种端到端的解决方案，既能优化投资组合，又能保持模型的解释性和跨维度适用性。

研究方法: 设计了一种旋转不变的神经网络架构，联合学习历史收益的滞后变换和协方差矩阵的正则化。该方法通过端到端优化未来实现的最小投资组合方差作为损失函数，并在真实日收益数据上进行训练。

研究结果: 在2000年1月至2024年12月的样本外测试中，该方法显著降低了实现波动率和最大回撤，同时提高了夏普比率，优于包括非线性收缩在内的最佳分析方法。此外，其学习的协方差表示在长约束优化器中仍保持性能优势。

研究结论: 本文提出的神经网络方法在最小方差投资组合优化中表现出卓越的性能和泛化能力，适用于大规模股票组合，且在真实市场环境下保持稳定。

中文摘要: 我们开发了一种旋转不变的神经网络，通过联合学习如何对历史收益进行滞后变换以及如何正则化大规模股票协方差矩阵的特征值和边际波动率，提供全局最小方差投资组合。这种显式的数学映射为每个模块的作用提供了清晰的解释性，因此该模型不能被视作纯粹的黑箱。该架构反映了全局最小方差解的解析形式，同时对维度保持不可知性，因此单个模型可以在几百只股票的面板上校准，并在无需重新训练的情况下应用于一千只美国股票——这一跨维度跳跃展示了强大的样本外泛化能力。损失函数是未来实现的最小投资组合方差，并在真实日收益数据上进行端到端优化。在2000年1月至2024年12月的样本外测试中，该估计器系统地提供了比最佳分析方法（包括最先进的非线性收缩）更低的实现波动率、更小的最大回撤和更高的夏普比率。此外，尽管该模型是通过端到端训练产生无约束（多空）最小方差投资组合的，但我们表明，其学习的协方差表示可以在长约束优化器中使用，且几乎不会损失其相对于竞争估计器的性能优势。这些优势在高度现实的执行框架下仍然存在，该框架模拟了拍卖市场订单、实际滑点、交易所费用和杠杆融资成本，并且在市场剧烈压力时期保持稳定。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [143] [HPC-AI Coupling Methodology for Scientific Applications](https://arxiv.org/abs/2507.01025)
**中文标题：科学应用中的HPC-AI耦合方法论**

*Yutong Lu,Dan Huang,Pin Chen*

主要分类: cs.CE

摘要简述: 本文提出了一种高性能计算（HPC）与人工智能（AI）耦合的新方法，包含替代、指导和协调三种模式，并通过材料科学案例验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 人工智能技术通过数据驱动方法改变了高性能计算应用，但仍面临高计算强度等挑战。本研究旨在探索HPC与AI耦合在科学应用中的潜力。

研究方法: 提出三种HPC-AI耦合模式：替代（AI替代部分计算）、指导（AI优化计算流程）和协调（AI与HPC协同工作），并通过材料科学案例验证。

研究结果: 案例研究表明，三种耦合模式在材料科学中具有显著效果，提升了性能并解决了技术挑战。

研究结论: HPC-AI耦合模式不仅适用于材料科学，还可推广至其他科学领域，为未来科学发现提供指导。

中文摘要: 人工智能（AI）技术通过数据驱动方法从根本上改变了基于数值的高性能计算（HPC）应用，并致力于解决高计算强度等挑战。本研究探讨了在新兴科学应用中耦合HPC与AI（HPC-AI）的场景，提出了一种包含三种耦合模式的新方法：替代、指导和协调。每种模式展示了独特的耦合策略、AI驱动前提和典型的HPC-AI组合。通过材料科学案例研究，我们验证了这些模式的应用和有效性。研究突出了技术挑战、性能提升和实施细节，为HPC-AI耦合的前景提供了见解。所提出的耦合模式不仅适用于材料科学，还可推广至其他科学领域，为未来科学发现中的HPC-AI组合提供宝贵指导。

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [144] [Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems](https://arxiv.org/abs/2507.01599)
**中文标题：数据代理：协调数据+AI生态系统的全面架构**

*Zhaoyan Sun,Jiayi Wang,Xinyang Zhao,Jiachi Wang,Guoliang Li*

主要分类: cs.DB

摘要简述: 本文提出‘数据代理’概念，通过整合大型语言模型（LLMs）的能力，设计了一种全面架构，用于协调数据+AI生态系统，解决数据相关任务中的语义理解、推理和规划问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统数据+AI系统依赖人工专家协调系统流程，难以适应数据、查询、任务和环境的变化。现有系统在语义理解、推理和规划方面能力有限，而大型语言模型（LLMs）的成功为改进这些能力提供了契机。

研究方法: 提出‘数据代理’架构，整合知识理解、推理和规划能力，解决数据相关任务。探讨了设计数据代理的挑战，包括理解数据/查询/环境/工具、协调流程/工作流、优化执行流程及促进流程自反思。

研究结果: 展示了多种数据代理系统实例，如数据科学代理、数据分析代理（包括非结构化数据分析代理、语义结构化数据分析代理、数据湖分析代理和多模态数据分析代理）及数据库管理员（DBA）代理。

研究结论: 数据代理架构为协调数据+AI生态系统提供了新思路，但仍面临设计上的开放挑战。

中文摘要: 传统的数据+AI系统利用数据驱动技术优化性能，但高度依赖人工专家协调系统流程，以适应数据、查询、任务和环境的变化。例如，尽管有众多数据科学工具可用，开发一个协调这些工具的流程规划系统仍具挑战性。这种困难源于现有数据+AI系统在语义理解、推理和规划方面的能力有限。幸运的是，我们见证了大型语言模型（LLMs）在增强语义理解、推理和规划能力方面的成功。将LLM技术融入数据系统，以有效协调数据+AI应用至关重要。为此，我们提出‘数据代理’概念——一种旨在协调数据+AI生态系统的全面架构，专注于通过整合知识理解、推理和规划能力解决数据相关任务。我们深入探讨了设计数据代理的挑战，如理解数据/查询/环境/工具、协调流程/工作流、优化和执行流程，以及促进流程自反思。此外，我们展示了数据代理系统的实例，包括数据科学代理、数据分析代理（如非结构化数据分析代理、语义结构化数据分析代理、数据湖分析代理和多模态数据分析代理）及数据库管理员（DBA）代理。我们还概述了设计数据代理系统相关的若干开放挑战。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [145] [User-guided Generative Source Separation](https://arxiv.org/abs/2507.01339)
**中文标题：用户引导的生成式音乐源分离**

*Yutong Wen,Minje Kim,Paris Smaragdis*

主要分类: cs.SD

摘要简述: 本文提出GuideSep，一种基于扩散模型的音乐源分离方法，支持用户通过哼唱或演奏目标旋律提供输入，实现灵活的乐器无关分离，超越传统四音轨分离的限制。


<details>
  <summary>详细信息</summary>
研究动机: 现有音乐源分离方法多局限于四音轨（人声、贝斯、鼓和其他乐器）分离，缺乏灵活性。为满足实际应用需求，本文提出一种更灵活的分离方法，支持用户参与并提供输入。

研究方法: GuideSep采用扩散模型，结合波形模仿条件和梅尔频谱域掩码作为输入条件，实现乐器无关的分离。同时设计了掩码预测基线模型，用于系统比较生成与预测方法。

研究结果: 主客观评估表明，GuideSep能实现高质量分离，并支持更灵活的乐器提取，凸显用户参与在扩散生成过程中的潜力。

研究结论: GuideSep通过用户参与和扩散生成方法，为音乐源分离提供了更高灵活性和适用性，展示了生成模型在此领域的潜力。

中文摘要: 音乐源分离（MSS）旨在从混合音频中提取单个乐器音源。现有方法多集中于四音轨分离（人声、贝斯、鼓和其他乐器），但缺乏实际应用所需的灵活性。为此，我们提出GuideSep，一种基于扩散模型的MSS方法，支持乐器无关的分离。GuideSep的输入条件包括波形模仿条件（可通过哼唱或演奏目标旋律提供）和梅尔频谱域掩码，为分离提供额外指导。与依赖固定类别标签或声音查询的先前方法不同，我们的条件方案结合生成方法，提供了更高的灵活性和适用性。此外，我们设计了基于相同模型架构的掩码预测基线，用于系统比较预测与生成方法。主客观评估表明，GuideSep能实现高质量分离，并支持更灵活的乐器提取，凸显了用户参与在扩散生成过程中对MSS的潜力。代码和演示页面见https://yutongwen.github.io/GuideSep/。

</details>


### [146] [Real-Time Emergency Vehicle Siren Detection with Efficient CNNs on Embedded Hardware](https://arxiv.org/abs/2507.01563)
**中文标题：基于高效卷积神经网络的嵌入式硬件实时紧急车辆警笛检测**

*Marco Giordano,Stefano Giacomelli,Claudia Rinaldi,Fabio Graziosi*

主要分类: cs.SD

摘要简述: 本文提出了一种基于高效卷积神经网络（E2PANNs）的嵌入式硬件实时紧急车辆警笛检测系统，通过优化数据集和部署策略，实现了低延迟和高鲁棒性的检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 紧急车辆警笛检测在智能城市基础设施中具有重要意义，但现有系统在复杂城市声学环境下可靠性不足。本文旨在开发一种适用于嵌入式硬件的实时检测系统，以提升检测的准确性和实用性。

研究方法: 方法包括：1）基于E2PANNs的卷积神经网络优化；2）构建高质量数据集（AudioSet-EV等）；3）在Raspberry Pi 5上部署多线程推理引擎，结合自适应帧大小和概率平滑技术；4）通过WebSocket实现远程监控。

研究结果: 实验表明，系统在多种配置下均能实现低延迟检测，并在真实音频条件下表现出更高的鲁棒性。

研究结论: 本文证明了在低成本边缘设备上部署分布式声学监测网络的可行性，为智能城市中的紧急车辆协同追踪提供了技术支持。

中文摘要: 我们提出了一种专为嵌入式硬件实时部署设计的全栈紧急车辆（EV）警笛检测系统。该方法基于E2PANNs（一种从EPANNs微调而来的卷积神经网络），并针对城市声学环境下的二元声音事件检测进行了优化。关键贡献包括：通过定制AudioSet-Tools框架开发了高质量数据集（AudioSet-EV、AudioSet-EV增强版和Unified-EV），以解决标准AudioSet标注的低可靠性问题。系统部署在配备高保真DAC+麦克风板的Raspberry Pi 5上，实现了多线程推理引擎，结合自适应帧大小、概率平滑和决策状态机以控制误报。远程WebSocket接口提供实时监控和演示功能。性能通过帧级和事件级指标在多配置下评估。结果表明，系统在真实音频条件下实现了低延迟检测和更高的鲁棒性。这项工作展示了部署兼容物联网（IoS）的声音事件检测（SED）解决方案的可行性，可通过低成本边缘设备上的WebSocket连接，形成分布式声学监测网络，支持智能城市基础设施中的紧急车辆协同追踪。

</details>


### [147] [Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder](https://arxiv.org/abs/2507.01582)
**中文标题：探索表现力音乐变分自编码器在古典钢琴演奏生成中的应用**

*Jing Luo,Xinyu Yang,Jie Wei*

主要分类: cs.SD

摘要简述: 本文提出了一种名为XMVAE的模型，通过结合VQ-VAE和VAE分支，分别模拟作曲家和钢琴家的角色，生成具有表现力的古典钢琴演奏。实验表明，XMVAE在音乐质量上优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 古典音乐的创造力不仅来自作曲家的创作，还来自演奏者对乐谱的表现力诠释。本文旨在解决从零生成古典钢琴演奏的挑战，模拟作曲家和钢琴家在创作过程中的双重角色。

研究方法: 本文提出ECP表示法捕捉演奏的韵律结构和表现力细节，并设计XMVAE模型，包含VQ-VAE分支（模拟作曲家生成乐谱内容）和VAE分支（模拟钢琴家生成表现力细节）。模型通过多尺度编码器和正交Transformer解码器联合训练。

研究结果: 主客观评估显示，XMVAE生成的古典钢琴演奏在音乐质量上优于现有模型。此外，对作曲家分支的额外乐谱数据集预训练显著提升了性能。

研究结论: XMVAE成功模拟了作曲家和钢琴家的双重角色，生成的演奏具有卓越的音乐表现力，为古典音乐生成提供了新思路。

中文摘要: 古典音乐的创造力不仅源于作曲家创作的乐谱，还来自演奏者对静态乐谱的表现力诠释。本文探讨了从零生成古典钢琴演奏的挑战，旨在模拟作曲家和钢琴家在创作过程中的双重角色。我们提出了表现力复合词（ECP）表示法，有效捕捉古典演奏的韵律结构和表现力细节。在此基础上，我们提出了表现力音乐变分自编码器（XMVAE），该模型包含两个分支：一个向量量化变分自编码器（VQ-VAE）分支，生成与乐谱相关的内容（模拟作曲家角色），以及一个普通VAE分支，生成表现力细节（模拟钢琴家角色）。这两个分支通过类似Seq2Seq的架构联合训练，利用多尺度编码器捕捉节拍级上下文信息，并通过正交Transformer解码器高效解码复合词标记。主客观评估表明，XMVAE生成的古典演奏在音乐质量上优于现有模型。此外，对作曲家分支的额外乐谱数据集预训练显著提升了性能。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [148] [Can Argus Judge Them All? Comparing VLMs Across Domains](https://arxiv.org/abs/2507.01042)
**中文标题：Argus能评判一切吗？跨领域比较视觉语言模型**

*Harsh Joshi,Gautam Siddharth Kashyap,Rafiq Ali,Ebad Shabbir,Niharika Jain,Sarthak Jain,Jiechao Gao,Usman Naseem*

主要分类: cs.IR

摘要简述: 本文评估了CLIP、BLIP和LXMERT三种视觉语言模型（VLMs）在检索、描述和推理任务中的表现，并提出了跨数据集一致性（CDC）指标。结果显示CLIP泛化能力最强，BLIP在精选数据上表现优异，LXMERT在结构化推理中领先。


<details>
  <summary>详细信息</summary>
研究动机: 视觉语言模型（VLMs）在多模态AI领域发展迅速，但其在不同任务中的性能一致性尚未充分研究。本文旨在通过多领域数据集评估VLMs的表现，揭示其泛化与专业化之间的权衡。

研究方法: 研究选取CLIP、BLIP和LXMERT三种模型，在检索、描述和推理任务上进行基准测试。评估指标包括任务准确性、生成质量、效率及新提出的跨数据集一致性（CDC）指标。

研究结果: CLIP表现出最强的泛化能力（CDC: 0.92），BLIP在精选数据上表现最佳，LXMERT在结构化推理任务中领先。结果揭示了模型在泛化与专业化之间的权衡。

研究结论: 研究结果为工业界部署VLMs提供了参考，并指导开发更具鲁棒性和任务灵活性的模型架构。

中文摘要: 视觉语言模型（VLMs）正在推动多模态AI的发展，但其在不同任务中的性能一致性尚未充分研究。我们对CLIP、BLIP和LXMERT在检索、描述和推理等多样化数据集上进行了基准测试。评估内容包括任务准确性、生成质量、效率以及新提出的跨数据集一致性（CDC）指标。结果显示，CLIP的泛化能力最强（CDC: 0.92），BLIP在精选数据上表现优异，LXMERT在结构化推理中领先。这些结果揭示了泛化与专业化之间的权衡，为工业界部署VLMs提供了参考，并指导开发更具鲁棒性和任务灵活性的架构。

</details>


### [149] [Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis](https://arxiv.org/abs/2507.01053)
**中文标题：对话式LLM简化临床数据的安全访问、理解与分析**

*Rafi Al Attrach,Pedro Moreira,Rajna Fani,Renato Umeton,Leo Anthony Celi*

主要分类: cs.IR

摘要简述: M3通过自然语言对话简化了MIMIC-IV临床数据库的访问与分析，降低了技术门槛，使研究者无需复杂SQL技能即可高效获取数据。


<details>
  <summary>详细信息</summary>
研究动机: 大型临床数据集（如MIMIC-IV）的复杂性（如需要高级查询技能和临床背景知识）阻碍了其广泛应用。M3旨在降低技术门槛，使更多研究者能够轻松访问和分析这些数据。

研究方法: M3通过单一命令从PhysioNet获取MIMIC-IV数据，启动本地SQLite实例或连接BigQuery，并利用Model Context Protocol（MCP）让研究者用自然语言与数据库对话。语言模型将问题翻译为SQL，执行查询后返回结构化结果及原始查询以供验证。

研究结果: 演示表明，M3能在几分钟内完成以往需数小时手工SQL编写的复杂队列分析，显著提高了数据访问和分析的效率。

研究结论: M3简化了临床数据的访问与分析，加速了原始记录向可操作洞察的转化，为更广泛的研究社区提供了便利。

中文摘要: 随着临床数据集的规模不断扩大，它们为医学研究带来了前所未有的机遇。其中最重要的是MIMIC-IV，这是全球最大的开源电子健康记录数据库。然而，这些数据集的复杂性（如需要高级查询技能和对临床背景的理解）常常成为有效利用的障碍。M3降低了理解和查询MIMIC-IV数据的技术门槛。通过单一命令，它从PhysioNet获取MIMIC-IV数据，启动本地SQLite实例（或连接到托管的BigQuery），并通过模型上下文协议（MCP）让研究者用自然语言与数据库对话。用自然语言提出临床问题；M3利用语言模型将其翻译为SQL，对MIMIC-IV数据集执行查询，并返回结构化结果及原始查询以确保可验证性和可重复性。演示表明，与M3的几分钟对话即可完成以往需要数小时手工SQL编写和临床流程理解的复杂队列分析。通过简化访问，M3邀请更广泛的研究社区挖掘临床重症数据，并加速将原始记录转化为可操作洞察。

</details>


### [150] [A Data Science Approach to Calcutta High Court Judgments: An Efficient LLM and RAG-powered Framework for Summarization and Similar Cases Retrieval](https://arxiv.org/abs/2507.01058)
**中文标题：加尔各答高等法院判决的数据科学方法：基于LLM和RAG的高效摘要与类似案例检索框架**

*Puspendu Banerjee,Aritra Mazumdar,Wazib Ansar,Saptarsi Goswami,Amlan Chakrabarti*

主要分类: cs.IR

摘要简述: 本研究提出了一种结合大型语言模型（LLM）和检索增强生成（RAG）技术的数据科学框架，用于高效总结加尔各答高等法院判决并检索类似案例，以提升法律研究和决策效率。


<details>
  <summary>详细信息</summary>
研究动机: 司法系统面临日益增长的法律问题，需要高效利用司法资源。本研究旨在通过数据科学方法优化法律文本分析和案例检索，帮助法律专业人士和学生更高效地获取关键法律信息。

研究方法: 研究采用Pegasus模型进行法律文本摘要的微调，并通过两步摘要技术保留关键法律上下文，构建全面的向量数据库以支持RAG框架，实现高效案例检索。

研究结果: 实验表明，该方法显著提升了法律案例摘要的质量，并通过RAG框架实现了高效且准确的类似案例检索，为法律研究和决策提供了有力支持。

研究结论: 该框架不仅提高了法律研究的效率，还为法律专业人士和学生提供了便捷获取和理解法律信息的工具，对整体法律环境具有积极影响。

中文摘要: 作为民主三大支柱之一的司法系统正面临日益增长的法律问题，需要谨慎利用司法资源。本研究提出了一种复杂的数据科学框架，利用大型语言模型（LLM）和检索增强生成（RAG）技术，以提高加尔各答高等法院判决分析的效率。该框架聚焦于两个关键方面：一是构建一个强大的摘要机制，将复杂的法律文本提炼为简洁连贯的摘要；二是开发一个智能系统，用于检索类似案例，辅助法律专业人士的研究和决策。通过使用案例摘要对Pegasus模型进行微调，我们在法律案例摘要方面取得了显著改进。我们的两步摘要技术保留了关键的法律上下文，从而为RAG构建了全面的向量数据库。RAG驱动的框架能够高效检索与用户查询相关的类似案例，并提供全面的概述和摘要。这一技术不仅提高了法律研究的效率，还帮助法律专业人士和学生轻松获取和理解关键法律信息，对整体法律环境具有积极影响。

</details>


### [151] [FAIR-MATCH: A Multi-Objective Framework for Bias Mitigation in Reciprocal Dating Recommendations](https://arxiv.org/abs/2507.01063)
**中文标题：FAIR-MATCH：一种用于减轻互惠约会推荐偏见的多元目标框架**

*Madhav Kotecha*

主要分类: cs.IR

摘要简述: 本文提出了一种名为FAIR-MATCH的多目标框架，旨在解决在线约会平台推荐系统中的算法偏见问题，通过改进相似性度量、多目标优化和公平性算法，提升推荐效果并减少偏见。


<details>
  <summary>详细信息</summary>
研究动机: 在线约会平台的推荐系统存在显著的算法缺陷，如流行度偏见、过滤气泡效应和互惠建模不足，这些问题限制了推荐效果并引入了有害偏见。本文旨在通过研究解决这些问题。

研究方法: 通过分析互惠推荐框架、公平性评估指标和行业实现，提出了一种数学框架，结合改进的相似性度量、多目标优化和公平性算法，以减少偏见并保持推荐准确性。

研究结果: 实验表明，当前系统的协作过滤方法准确率为25.1%，而互惠方法为28.7%。提出的框架在保持竞争力的准确性的同时，改善了人口统计代表性，减少了算法偏见。

研究结论: FAIR-MATCH框架通过多目标优化和公平性算法，有效减少了在线约会推荐系统中的偏见，同时保持了推荐准确性，为未来的研究和实践提供了重要参考。

中文摘要: 在线约会平台从根本上改变了浪漫关系的形成方式，全球数百万用户依赖算法匹配系统寻找合适的伴侣。然而，当前约会应用中的推荐系统存在显著的算法缺陷，包括但不限于流行度偏见、过滤气泡效应以及互惠建模不足，这些问题限制了推荐效果并引入了有害偏见。本研究结合基础工作和最新实证结果，对约会应用推荐系统进行了详细分析，突出了关键问题并提出了基于研究的解决方案。通过对互惠推荐框架、公平性评估指标和行业实现的分析，我们证明当前系统的协作过滤方法准确率为25.1%，而互惠方法为28.7%。我们提出的数学框架通过改进的相似性度量、多目标优化和公平性算法解决了这些限制，在保持竞争力的准确性的同时，改善了人口统计代表性以减少算法偏见。

</details>


### [152] [Cohort Retrieval using Dense Passage Retrieval](https://arxiv.org/abs/2507.01049)
**中文标题：基于密集段落检索的患者队列检索**

*Pranav Jadhav*

主要分类: cs.IR

摘要简述: 本文提出了一种基于密集段落检索（DPR）的方法，用于从超声心动图电子健康记录（EHR）中检索患者队列，通过系统化数据转换和定制化模型训练，显著提升了检索性能。


<details>
  <summary>详细信息</summary>
研究动机: 患者队列检索在医学研究和临床实践中至关重要，但现有方法在超声心动图领域的非结构化EHR数据中效果有限。本文旨在通过DPR技术解决这一问题，填补该领域的研究空白。

研究方法: 首先将非结构化的超声心动图EHR数据转换为查询-段落数据集，并将其建模为队列检索任务。随后设计并实现了基于真实临床场景的评估指标，并训练了一个定制化的DPR嵌入模型。

研究结果: 实验表明，定制化的DPR模型在多种检索任务中表现优于传统方法和现成的SOTA方法，验证了其在超声心动图领域的有效性。

研究结论: 本文首次将DPR应用于超声心动图领域的患者队列检索，建立了一个可推广至其他医学领域的框架，为未来研究提供了重要参考。

中文摘要: 患者队列检索是医学研究和临床实践中的关键任务，能够从大量电子健康记录（EHR）中识别特定患者群体。本研究通过应用密集段落检索（DPR）这一语义搜索领域的重要方法，解决了超声心动图领域中的队列检索挑战。我们提出了一种系统化方法，将非结构化的超声心动图EHR数据集转换为查询-段落数据集，并将问题建模为队列检索任务。此外，我们设计并实现了基于真实临床场景的评估指标，以严格测试模型在多种检索任务中的表现。我们还提出了一个定制训练的DPR嵌入模型，其性能优于传统方法和现成的SOTA方法。据我们所知，这是首次将DPR应用于超声心动图领域的患者队列检索工作，建立了一个可推广至其他医学领域的框架。

</details>


### [153] [Enhanced Influence-aware Group Recommendation for Online Media Propagation](https://arxiv.org/abs/2507.01616)
**中文标题：增强型影响力感知的在线媒体传播群组推荐**

*Chengkun He,Xiangmin Zhou,Chen Wang,Longbing Cao,Jie Shao,Xiaodong Li,Guang Xu,Carrie Jinqiu Hu,Zahir Tari*

主要分类: cs.IR

摘要简述: 本文提出了一种增强型影响力感知的群组推荐框架（EIGR），通过图提取采样策略、动态独立级联模型和两级哈希用户组索引，解决了社交图规模大、影响力传播动态变化及实时匹配计算开销高的问题，实验证明其效果和效率优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 群组推荐在社交媒体流中应用广泛，但现有方法面临社交图规模大、影响力传播动态变化及实时匹配计算开销高的挑战，亟需一种更高效的解决方案。

研究方法: 1. 提出图提取采样策略（GES）以减少冗余并捕捉动态变化；2. 设计动态独立级联模型（DYIC）预测影响力传播；3. 开发两级哈希用户组索引（UG-Index）支持实时推荐生成。

研究结果: 在真实数据集上的实验表明，EIGR框架在效果和效率上均优于现有基线方法。

研究结论: EIGR框架通过创新的采样策略、动态影响力传播模型和高效索引设计，显著提升了群组推荐的性能和实时性。

中文摘要: 社交媒体流中的群组推荐因其在电子商务、娱乐和在线新闻广播等领域的广泛应用而受到广泛关注。通过利用社交连接和群体行为，群组推荐（GR）旨在为一组用户而非个人提供更准确和吸引人的内容。近年来，影响力感知的GR成为一个有前景的方向，因为它考虑了社交影响力对群体决策的影响。在早期工作中，我们提出了影响力感知的群组推荐（IGR）来解决这一任务。然而，由于社交图规模庞大且不断增长、用户群体内影响力传播的动态性以及实时群组-项目匹配的高计算开销，这一任务仍然具有挑战性。为解决这些问题，我们提出了一种增强型影响力感知的群组推荐（EIGR）框架。首先，我们引入了一种基于图提取的采样（GES）策略，以减少多个时序社交图中的冗余，并有效捕捉群体和项目的动态变化。其次，我们设计了一种新颖的动态独立级联（DYIC）模型，以预测影响力在社交项目和用户群体中随时间传播的方式。最后，我们开发了一种基于两级哈希的用户组索引（UG-Index），以高效组织用户群体并支持实时推荐生成。在真实数据集上的大量实验表明，我们提出的EIGR框架在效果和效率上均优于现有基线方法。

</details>


### [154] [Embedding-based Retrieval in Multimodal Content Moderation](https://arxiv.org/abs/2507.01066)
**中文标题：基于嵌入的检索在多模态内容审核中的应用**

*Hanzhong Liang,Jinghao Shi,Xiang Shen,Zixuan Wang,Vera Wen,Ardalan Mehrani,Zhiqian Chen,Yifan Wu,Zhixin Zhang*

主要分类: cs.IR

摘要简述: 本文提出了一种基于嵌入的检索（EBR）方法，用于补充传统分类方法在短视频平台内容审核中的不足。通过监督对比学习训练嵌入模型，EBR显著提升了性能并降低了运营成本。


<details>
  <summary>详细信息</summary>
研究动机: 传统分类方法在短视频内容审核中难以应对快速变化和低成本需求，如趋势适应和紧急升级。因此，需要一种更高效、灵活的方法来补充分类方法的不足。

研究方法: 采用监督对比学习（SCL）框架训练单模态和多模态基础嵌入模型，设计并实现了一个基于嵌入的检索系统，整合嵌入生成和视频检索功能。

研究结果: 离线实验显示，EBR将ROC-AUC从0.85提升至0.99，PR-AUC从0.35提升至0.95。在线实验表明，EBR使行动率提高10.32%，运营成本降低80%以上。

研究结论: EBR方法在内容审核中表现出色，不仅提升了性能，还增强了可解释性和灵活性，为传统分类方法提供了有效补充。

中文摘要: 视频理解在短视频平台的内容审核中起着基础性作用，能够检测不当内容。尽管分类仍是内容审核的主要方法，但在需要快速且低成本响应的场景（如趋势适应和紧急升级）中表现不佳。为解决这一问题，我们提出了一种基于嵌入的检索（EBR）方法，以补充传统分类方法。我们首先利用监督对比学习（SCL）框架训练了一系列基础嵌入模型，包括单模态和多模态架构。这些模型在性能上优于CLIP和MoCo等现有对比学习方法。基于这些嵌入模型，我们设计并实现了整合嵌入生成和视频检索的EBR系统，以实现高效的趋势处理。在25种不同新兴趋势上的离线实验表明，EBR将ROC-AUC从0.85提升至0.99，PR-AUC从0.35提升至0.95。进一步的在线实验显示，EBR使行动率提高10.32%，运营成本降低80%以上，同时与基于分类的解决方案相比，增强了可解释性和灵活性。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [155] [Capacity Planning and Scheduling for Jobs with Uncertainty in Resource Usage and Duration](https://arxiv.org/abs/2507.01225)
**中文标题：资源使用和持续时间不确定的作业容量规划与调度**

*Sunandita Patra,Mehtab Pathan,Mahmoud Mahfouz,Parisa Zehtabi,Wided Ouaja,Daniele Magazzeni,Manuela Veloso*

主要分类: cs.DC

摘要简述: 本文提出了一种在混合云和本地服务器环境中处理资源使用和作业持续时间不确定性的容量规划与调度方法，旨在最小化资源使用同时保证服务质量。


<details>
  <summary>详细信息</summary>
研究动机: 随着云计算基础设施的普及，组织需要在混合环境中进行高效的容量规划和作业调度，尤其是在金融行业，市场条件的不确定性对作业特性有显著影响。本文旨在解决资源使用和作业持续时间的不确定性，同时平衡资源最小化和服务质量。

研究方法: 本文采用确定性估计器和基于配对采样的约束规划方法，处理资源使用和作业持续时间的不确定性，以实现容量规划和调度。

研究结果: 基于配对采样的方法显著降低了峰值资源使用，同时未影响服务质量，优于手动调度。

研究结论: 本文提出的方法在混合环境中有效解决了资源规划和调度的不确定性，为金融行业等需要高可靠性的领域提供了实用解决方案。

中文摘要: 全球各地的组织定期调度作业（程序）以执行其终端用户指定的各种任务。随着云计算基础设施的广泛应用，我们的组织采用了一种混合方法，结合了云和本地服务器。本工作的目标是进行容量规划（即估计资源需求）和本地网格计算环境中的作业调度。我们方法的一个关键贡献是处理作业资源使用和持续时间的不确定性，这在金融行业中尤为重要，因为随机市场条件会显著影响作业特性。在容量规划和调度中，我们同时平衡了两个冲突的目标：（a）最小化资源使用，（b）通过按时完成作业提供高质量的服务。我们提出了基于确定性估计器和配对采样的约束规划的近似方法。我们最佳的方法（基于配对采样）在不影响服务质量的情况下，相比手动调度显著降低了峰值资源使用。

</details>


### [156] [EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices](https://arxiv.org/abs/2507.01438)
**中文标题：EdgeLoRA：一种高效的边缘设备多租户LLM服务系统**

*Zheyu Shen,Yexiao He,Ziyao Wang,Yuning Zhang,Guoheng Sun,Wanghao Ye,Ang Li*

主要分类: cs.DC

摘要简述: EdgeLoRA是一种高效的多租户LLM边缘设备服务系统，通过自适应适配器选择、异构内存管理和批量LoRA推理，显著提升边缘设备上的LLM服务效率和吞吐量。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）因其多功能性受到广泛关注，但在资源受限的边缘设备上高效部署多租户LLM面临适配器选择复杂、内存开销大和请求处理延迟高等挑战。

研究方法: EdgeLoRA提出三项创新：1）自适应适配器选择机制；2）异构内存管理，包括智能适配器缓存和池化；3）批量LoRA推理，以优化边缘设备上的LLM服务。

研究结果: 实验表明，EdgeLoRA在延迟和吞吐量上显著优于现有方案（如llama.cpp），吞吐量提升高达4倍，并能同时处理更多适配器。

研究结论: EdgeLoRA为多租户边缘环境中的LLM部署提供了高效、可扩展的解决方案，具有显著的性能优势和应用潜力。

中文摘要: 大型语言模型（LLM）因其广泛的应用而备受关注。通过参数高效的适配器（如低秩适配LoRA）微调LLM，可以无需大量重新训练即可适应下游任务。在边缘设备上部署微调后的LLM具有降低延迟、增强隐私和提供个性化响应等优势。然而，在资源受限的边缘设备上高效服务LLM面临适配器选择复杂和频繁切换导致的内存开销等挑战。此外，多租户环境中的请求顺序处理会导致计算资源利用不足和延迟增加。本文提出EdgeLoRA，一种高效的多租户边缘设备LLM服务系统。EdgeLoRA包含三项关键创新：1）自适应适配器选择机制；2）异构内存管理，通过智能适配器缓存和池化减少内存操作开销；3）批量LoRA推理，显著降低计算延迟。基于Llama3.1-8B模型的全面评估表明，EdgeLoRA在延迟和吞吐量上显著优于现有方案（如llama.cpp），吞吐量提升高达4倍，并能同时处理更多适配器。这些结果凸显了EdgeLoRA在多租户边缘LLM部署中的潜力，为资源受限环境提供了可扩展的高效解决方案。

</details>


### [157] [Deep Recommender Models Inference: Automatic Asymmetric Data Flow Optimization](https://arxiv.org/abs/2507.01676)
**中文标题：深度推荐模型推理：自动非对称数据流优化**

*Giuseppe Ruggeri,Renzo Andri,Daniele Jahier Pagliari,Lukas Cavigelli*

主要分类: cs.DC

摘要简述: 本文提出了一种针对深度推荐模型（DLRM）推理的自动非对称数据流优化方法，显著提升了嵌入层查询效率，在华为Ascend AI加速器上实现了1.5x至6.5x的速度提升。


<details>
  <summary>详细信息</summary>
研究动机: 深度推荐模型（DLRM）推理是Meta数据中心中占比超过79%的AI工作负载，其性能瓶颈主要在于嵌入层的随机内存访问。为了提升嵌入查询效率，本文旨在设计定制化的数据流优化方法。

研究方法: 本文提出了四种策略以在单核上高效查询嵌入表，并设计了一个框架将这些表非对称地映射到SoC的多核上。通过华为Ascend AI加速器评估，与默认编译器及Nvidia A100进行了对比。

研究结果: 实验结果显示，对于实际工作负载分布，速度提升范围为1.5x至6.5x；对于极端不平衡分布，速度提升超过20x。此外，该方法对查询分布的依赖性显著低于基线。

研究结论: 本文提出的自动非对称数据流优化方法显著提升了DLRM推理的效率，尤其在嵌入层查询方面表现优异，为实际应用提供了高效解决方案。

中文摘要: 深度推荐模型（DLRM）推理是Meta数据中心中占比超过79%的基础AI工作负载。DLRM的性能瓶颈在于嵌入层，该层需要频繁随机访问内存以从不同大小的表中检索小嵌入向量。为加速嵌入查询，我们提出了定制化数据流设计。具体而言，我们提出了四种策略以在单核上高效查询嵌入表，以及一个框架将这些表非对称地映射到SoC的多核上。我们使用华为Ascend AI加速器评估了方法的有效性，并与默认Ascend编译器及Nvidia A100进行了对比。结果显示，对于实际工作负载分布，速度提升范围为1.5x至6.5x；对于极端不平衡分布，速度提升超过20x。此外，该方法对查询分布的依赖性显著低于基线。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [158] [A Systematic Review of Security Vulnerabilities in Smart Home Devices and Mitigation Techniques](https://arxiv.org/abs/2507.01018)
**中文标题：智能家居设备安全漏洞及缓解技术的系统综述**

*Mohammed K. Alzaylaee*

主要分类: cs.CR

摘要简述: 本文系统综述了智能家居设备的安全漏洞及缓解技术，指出后量子加密和AI异常检测能有效提升安全性，但面临计算资源挑战。区块链认证和零信任架构增强安全性，但需改进现有基础设施。研究强调需平衡性能与效率，优化加密技术和AI威胁检测。


<details>
  <summary>详细信息</summary>
研究动机: 智能家居设备因物联网（IoT）的普及面临日益严重的网络安全风险，亟需系统研究其安全漏洞及缓解技术，以提升智能家居生态系统的安全性。

研究方法: 研究通过分类网络层、设备层、云和AI系统的漏洞，分析后量子加密、AI异常检测、区块链认证和零信任架构等技术的有效性，并采用ANOVA、卡方检验和蒙特卡洛模拟验证其效果。

研究结果: 后量子加密和AI异常检测显著提升安全性，但计算资源需求高；区块链认证和零信任架构增强安全性，但需改进基础设施。现有策略缺乏足够扩展性。

研究结论: 研究强调需优化加密技术、AI威胁检测和自适应安全模型，平衡性能与效率，并实现实时应用，以提升智能家居生态系统的安全性。

中文摘要: 集成物联网（IoT）设备的智能家居面临日益严重的网络安全风险，为这些环境带来重大挑战。本研究探讨了智能家居生态系统中的安全威胁，将其分类为网络层、设备层以及基于云和AI系统的漏洞。研究发现，后量子加密结合AI驱动的异常检测能显著提升安全性，但计算资源需求带来重大挑战。区块链认证与零信任架构增强了安全性，但需对现有基础设施进行调整。通过ANOVA、卡方检验和蒙特卡洛模拟验证了特定安全策略的有效性，但结果显示其扩展性不足。研究表明，需改进加密技术、AI增强的威胁检测和自适应安全模型，以平衡性能与效率，并实现智能家居生态系统中的实时应用。

</details>


### [159] [SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](https://arxiv.org/abs/2507.01513)
**中文标题：SafePTR：基于修剪-恢复机制的多模态大语言模型令牌级越狱防御**

*Beitao Chen,Xinyu Lyu,Lianli Gao,Jingkuan Song,Heng Tao Shen*

主要分类: cs.CR

摘要简述: SafePTR是一种无需训练的防御框架，通过选择性修剪有害令牌并恢复良性特征，显著提升多模态大语言模型的安全性，同时保持效率。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）因视觉输入的引入而扩展了视觉推理能力，但也带来了新的漏洞，使其容易受到多模态越狱攻击。现有防御方法未能深入分析多模态漏洞的根源，导致对文本驱动的多模态越狱攻击防御不足。本文旨在揭示有害多模态令牌如何绕过安全机制，并提出一种高效的防御方案。

研究方法: SafePTR框架通过分析发现，早期至中间层中不到1%的令牌是引发不安全行为的关键。基于此，该框架选择性修剪这些有害令牌，并在后续层恢复良性特征，无需额外训练或计算开销。

研究结果: 在三种MLLMs和五个基准测试上的广泛评估表明，SafePTR在显著降低越狱风险的同时，未损害模型实用性，表现优于现有方法。

研究结论: SafePTR通过精确修剪和恢复机制，提供了一种高效且无需训练的多模态越狱防御方案，为MLLMs的安全部署提供了新思路。

中文摘要: 通过引入视觉输入，多模态大语言模型（MLLMs）扩展了语言模型的视觉推理能力。然而，这种整合也引入了新的漏洞，使MLLMs容易受到多模态越狱攻击，阻碍其安全部署。现有防御方法（如图像到文本翻译、安全提示和多模态安全调优）试图通过将多模态输入与语言模型的内置安全机制对齐来解决这一问题，但未能揭示多模态漏洞的根源，尤其是多模态令牌如何触发越狱行为。因此，这些方法对文本驱动的多模态越狱攻击仍显脆弱，常表现为过度防御或带来沉重的训练负担。为填补这一空白，本文全面分析了有害多模态令牌在MLLMs中绕过安全机制的位置、方式和类型。令人惊讶的是，我们发现早期至中间层中不到1%的令牌是引发不安全行为的关键，这表明精确移除少量有害令牌（无需安全调优）仍能有效提升安全性。基于此，我们提出了Safe Prune-then-Restore（SafePTR），一种无需训练的防御框架，选择性修剪易受攻击层的有害令牌，并在后续层恢复良性特征。在不增加计算开销的情况下，SafePTR显著提升了MLLMs的安全性，同时保持了效率。在三种MLLMs和五个基准测试上的广泛评估表明，SafePTR在缓解越狱风险方面表现优异，且未损害实用性。

</details>


### [160] [Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems](https://arxiv.org/abs/2507.01808)
**中文标题：赋能制造商的隐私保护AI工具：隐私保护机器学习解决实际问题的案例研究**

*Xiaoyu Ji,Jessica Shorland,Joshua Shank,Pascal Delpe-Brice,Latanya Sweeney,Jan Allebach,Ali Shakouri*

主要分类: cs.CR

摘要简述: 本文介绍了一个隐私保护平台，帮助中小型制造商安全共享数据以开发创新工具，并通过食品晶体质量控制的案例展示了其实际应用。


<details>
  <summary>详细信息</summary>
研究动机: 中小型制造商因竞争和隐私问题不愿共享专有数据，但需要创新工具解决实际问题。本文旨在提供一个隐私保护平台，使制造商能够安全共享数据并获得定制化解决方案。

研究方法: 开发了一个隐私保护平台，制造商通过安全方法共享数据，研究人员利用数据开发工具（如食品晶体图像分析工具），并将工具部署到平台上供制造商使用。

研究结果: 成功开发并部署了一个食品晶体自动分析工具，显著提高了晶体数量和尺寸分布的检测效率与准确性，并通过隐私保护平台实现了工具的工厂应用。

研究结论: 隐私保护平台为制造商提供了安全的数据共享和工具开发途径，未来可进一步扩展其应用领域。

中文摘要: 中小型制造商需要创新的数据工具，但由于竞争和隐私问题，通常不愿与可能提供帮助的研究人员共享专有数据。本文介绍了一个隐私保护平台，制造商可以通过安全方法与研究人员共享数据，研究人员则开发创新工具解决制造商的现实问题，并将工具部署到平台上供其他用户使用，同时确保隐私和保密性。我们通过一个食品晶体大规模生产中的质量控制问题（依赖图像分析工具）展示了这一解决方案。此前，食品晶体的图像需人工计数，耗时耗力；而我们开发并部署的晶体分析工具显著提高了这一过程的效率和准确性。该工具能够自动分析显微镜图像中的晶体尺寸分布和数量，并自动消除样品制备中的自然缺陷；同时还开发了机器学习模型以计数高分辨率半透明晶体和晶体团聚体。最终算法通过基于隐私保护平台的网络应用在工厂中实际使用，确保制造商的数据安全。在展示完整流程后，本文还探讨了未来的发展方向。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [161] [Automated Vehicles Should be Connected with Natural Language](https://arxiv.org/abs/2507.01059)
**中文标题：自动驾驶车辆应通过自然语言连接**

*Xiangbo Gao,Keshu Wu,Hao Zhang,Kexin Tian,Yang Zhou,Zhengzhong Tu*

主要分类: cs.MA

摘要简述: 本文提出自动驾驶车辆应通过自然语言进行连接，以解决现有通信媒介在带宽效率、信息完整性和互操作性上的不足，从而实现更高效、安全的协同驾驶。


<details>
  <summary>详细信息</summary>
研究动机: 现有自动驾驶车辆通信媒介（如原始传感器数据、神经网络特征等）在带宽效率、信息完整性和异构平台互操作性方面存在局限，且忽视了决策层面的融合。本文旨在通过自然语言通信解决这些问题，提升协同驾驶的安全性和效率。

研究方法: 提出从感知导向的数据交换转向使用自然语言进行意图和推理的显式通信。自然语言具有语义密度高、带宽适应性强、能桥接异构平台的优势，支持直接传递意图、决策和理由。

研究结果: 通过自然语言通信，自动驾驶车辆能够实现从被动感知数据共享到主动协同的转变，显著提升智能交通系统的安全性、效率和透明度。

研究结论: 自然语言通信为自动驾驶车辆的协同驾驶提供了更高效、灵活的解决方案，是未来智能交通系统发展的重要方向。

中文摘要: 多智能体协同驾驶通过集体感知和决策有望提升交通安全和效率。然而，现有通信媒介（包括原始传感器数据、神经网络特征和感知结果）在带宽效率、信息完整性和智能体互操作性方面存在局限。此外，传统方法大多忽视了决策层面的融合，忽略了协同驾驶的关键维度。本文认为，解决这些挑战需要从纯感知导向的数据交换转向使用自然语言进行意图和推理的显式通信。自然语言平衡了语义密度和通信带宽，灵活适应实时条件，并桥接异构智能体平台。通过直接传递意图、理由和决策，它将协同驾驶从被动的感知数据共享转变为主动的协调，从而提升智能交通系统的安全性、效率和透明度。

</details>


### [162] [RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms](https://arxiv.org/abs/2507.01378)
**中文标题：RALLY：面向智能无人机群的角色自适应LLM驱动协同导航算法**

*Ziyao Wang,Rongpeng Li,Sizhao Li,Yuming Xiang,Haiping Wang,Zhifeng Zhao,Honggang Zhang*

主要分类: cs.MA

摘要简述: 本文提出了一种名为RALLY的角色自适应LLM驱动导航算法，用于无人机群协同导航。通过结合自然语言语义通信和动态角色异构机制，RALLY显著提升了任务覆盖率、收敛速度和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统多智能体强化学习（MARL）在无人机群导航中存在语义沟通障碍和角色结构僵化问题，而基于大语言模型（LLM）的框架虽具备语义推理能力，却缺乏在线学习能力。RALLY旨在解决这些问题，提升无人机群的协作导航性能。

研究方法: RALLY首先构建了一个LLM驱动的语义决策框架，利用结构化自然语言实现高效语义通信；其次引入动态角色异构机制，支持自适应角色切换和个性化决策；最后提出基于角色值混合网络（RMIX）的策略，将LLM离线先验与MARL在线策略结合，实现半离线训练。

研究结果: 在MPE环境和SITL平台上的实验表明，RALLY在任务覆盖率、收敛速度和泛化能力上均优于传统方法，展示了其在多无人机系统协同导航中的强大潜力。

研究结论: RALLY通过结合LLM的语义推理能力和MARL的动态适应性，显著提升了无人机群的导航性能，为未来智能无人机群的应用提供了有力支持。

中文摘要: 无人机群（UAVs）的智能控制已成为研究热点，其核心在于高效导航、避障及多目标连续覆盖。传统多智能体强化学习（MARL）虽具动态适应性，但受限于数值通信的语义鸿沟和同质角色结构的僵化，导致泛化能力差且任务扩展性有限。基于大语言模型（LLM）的控制框架虽能利用丰富先验知识进行语义推理，但因缺乏在线学习及过度依赖静态先验，探索能力不足，影响个体潜能和系统性能。为此，我们提出角色自适应LLM驱动协同导航算法RALLY。具体而言，首先开发了基于LLM的语义决策框架，利用结构化自然语言实现高效语义通信与协作推理；其次引入动态角色异构机制，支持自适应角色切换与个性化决策；进一步提出基于角色值混合网络（RMIX）的分配策略，将LLM离线先验与MARL在线策略结合，实现角色选择策略的半离线训练。在MPE环境和SITL平台上的实验表明，RALLY在任务覆盖率、收敛速度和泛化能力上均优于传统方法，展现了其在智能多无人机系统协同导航中的强大潜力。

</details>


### [163] [Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture](https://arxiv.org/abs/2507.01701)
**中文标题：基于黑板架构的先进LLM多智能体系统探索**

*Bochen Han,Songmao Zhang*

主要分类: cs.MA

摘要简述: 本文提出将黑板架构融入LLM多智能体系统（MASs），使不同角色的智能体在问题解决过程中共享信息和消息，动态选择执行智能体，并通过迭代达成共识。实验表明，该系统在常识知识、推理和数学数据集上表现优异，且消耗更少计算资源。


<details>
  <summary>详细信息</summary>
研究动机: 当前的多智能体系统（MASs）在动态和复杂问题解决中缺乏灵活性和信息共享机制。黑板架构的引入旨在解决这一问题，通过共享信息和动态选择智能体，提升系统的协作效率和适应性。

研究方法: 将黑板架构融入LLM多智能体系统，实现信息共享和动态智能体选择。系统通过迭代选择和执行智能体，直至黑板内容达成共识。实验在常识知识、推理和数学数据集上进行验证。

研究结果: 实验结果显示，该系统在多个数据集上表现优异，平均性能优于现有静态和动态MASs，同时计算资源消耗更低。

研究结论: 黑板架构的引入显著提升了LLM多智能体系统的协作效率和问题解决能力，尤其在缺乏明确结构或工作流的复杂场景中具有潜力。

中文摘要: 本文提出将黑板架构融入LLM多智能体系统（MASs），以实现以下目标：（1）不同角色的智能体在整个问题解决过程中共享信息和消息；（2）基于黑板当前内容动态选择执行智能体；（3）通过迭代选择和执行达成共识。我们实现了该方案的首次应用，并在常识知识、推理和数学数据集上进行了实验。结果表明，该系统在平均性能上优于现有静态和动态MASs，同时消耗更少的计算资源。该方案有望在缺乏明确结构或工作流的复杂动态问题解决中发挥作用。

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [164] [GPU-based complete search for nonlinear minimization subject to bounds](https://arxiv.org/abs/2507.01770)
**中文标题：基于GPU的全局搜索方法用于有界非线性函数最小化**

*Guanglu Zhang,Qihang Shan,Jonathan Cagan*

主要分类: math.NA

摘要简述: 本文提出了一种基于GPU的全局搜索方法，用于在变量有界条件下寻找非线性函数的全局最小值。该方法结合区间分析和GPU计算能力，有效排除不可能存在全局最小值的区域，并确保在计算误差下仍能准确包围全局最小值。实验验证了其在高达10,000维的多模态测试函数中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 非线性函数在变量有界条件下的全局最小化是一个复杂且计算量大的问题。传统方法难以在高维情况下保证结果的准确性和效率。本文旨在利用GPU的并行计算能力和区间分析的严谨性，设计一种高效且可靠的方法来解决这一问题。

研究方法: 该方法基于区间分析，通过GPU的并行计算能力迭代排除不可能存在全局最小值的区域。采用单程序多数据（SPMD）并行编程风格避免GPU性能瓶颈，并结合变量循环技术降低大规模非线性函数的最小化计算成本。

研究结果: 实验验证了该方法在10种多模态基准测试函数（包括Ackley、Griewank、Levy和Rastrigin函数）中的有效性。成功在高达10,000维的情况下包围全局最小值，远超文献报道的结果。

研究结论: 本文提出的基于GPU的全局搜索方法在保证计算严谨性的同时，显著提高了高维非线性函数全局最小化的效率和准确性，为复杂优化问题提供了新的解决方案。

中文摘要: 本文介绍了一种基于GPU的全局搜索方法，用于在有界变量条件下包围非线性函数的全局最小值。通过结合区间分析和GPU的计算能力与架构，该方法迭代排除搜索域中不可能存在全局最小值的区域，并保留有限区域确保全局最小值的存在。由于区间分析的严谨性，即使在存在舍入误差的情况下，该方法也能保证包围全局最小值。为提高效率，该方法采用了一种新颖的基于GPU的单程序多数据（SPMD）并行编程风格，以规避GPU性能瓶颈，同时结合变量循环技术降低大规模非线性函数最小化的计算成本。通过最小化10种可扩展维度的多模态基准测试函数（包括著名的Ackley函数、Griewank函数、Levy函数和Rastrigin函数），验证了该方法的有效性。这些基准测试函数代表了全局优化的重大挑战，而包围超过80维的这些函数的全局最小值在文献中尚未见报道。我们的方法完全搜索可行域，并成功包围了高达10,000维的这10种基准测试函数的全局最小值，仅使用一块GPU在合理计算时间内完成，远超文献报道的结果，这得益于基于GPU架构的独特方法设计与实现。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [165] [Prompt Mechanisms in Medical Imaging: A Comprehensive Survey](https://arxiv.org/abs/2507.01055)
**中文标题：医学影像中的提示机制：全面综述**

*Hao Yang,Xinlong Liang,Zhang Li,Yue Sun,Zheyu Hu,Xinghe Xie,Behdad Dashtbozorg,Jincheng Huang,Shiwei Zhu,Luyi Han,Jiong Zhang,Shanshan Wang,Ritse Mann,Qifeng Yu,Tao Tan*

主要分类: eess.IV

摘要简述: 本文系统综述了医学影像中基于提示的深度学习方法，探讨了多种提示模态及其在图像生成、分割和分类等任务中的应用，揭示了其在提升模型性能和适应性方面的潜力，同时指出了优化设计和临床部署的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在医学影像中具有巨大潜力，但其临床应用常受限于数据稀缺、分布变化和任务泛化需求。基于提示的方法通过灵活指导模型，显著提升性能，成为解决这些问题的关键策略。

研究方法: 本文通过系统综述，分析了医学影像中多种提示模态（如文本指令、视觉提示和可学习嵌入）的整合方式，及其在核心任务（如图像生成、分割和分类）中的应用。

研究结果: 研究表明，提示机制显著提升了任务特异性结果，包括准确性、鲁棒性和数据效率，同时减少了对人工特征工程的依赖，并增强了模型的可解释性。

研究结论: 尽管提示方法在医学影像中取得显著进展，但仍面临提示设计优化、数据异质性和临床部署可扩展性等挑战。未来研究方向包括多模态提示和临床整合，以推动诊断和个性化治疗的革命。

中文摘要: 深度学习在医学影像领域具有变革性潜力，但其临床应用常因数据稀缺、分布变化和任务泛化需求等挑战而受阻。基于提示的方法作为一种关键策略，通过灵活指导深度学习模型，显著提升了模型性能和适应性，而无需大量重新训练。本文系统综述了医学影像中提示工程的快速发展现状，剖析了多种提示模态（如文本指令、视觉提示和可学习嵌入），并分析了它们在图像生成、分割和分类等核心任务中的整合。研究表明，这些机制通过提升准确性、鲁棒性和数据效率，显著改善了任务特异性结果，同时减少了对人工特征工程的依赖，并通过显式指导增强了模型的可解释性。尽管取得了显著进展，但仍存在提示设计优化、数据异质性和临床部署可扩展性等挑战。最后，本文展望了未来研究方向，包括多模态提示和临床整合，强调了提示驱动的人工智能在加速医学诊断和个性化治疗规划革命中的关键作用。

</details>


### [166] [MID-INFRARED (MIR) OCT-based inspection in industry](https://arxiv.org/abs/2507.01074)
**中文标题：基于中红外（MIR）OCT的工业检测**

*N. P. García-de-la-Puente,Rocío del Amor,Fernando García-Torres,Niels Møller Israelsen,Coraline Lapre,Christian Rosenberg Petersen,Ole Bang,Dominik Brouczek,Martin Schwentenwein,Kevin Neumann,Niels Benson,Valery Naranjo*

主要分类: eess.IV

摘要简述: 本文探讨了中红外光学相干断层扫描（MIR-OCT）系统在工业中用于穿透材料并检测表面下异常的能力，结合预处理和AI算法提升检测效果。


<details>
  <summary>详细信息</summary>
研究动机: 研究中红外OCT系统在工业检测中的应用潜力，以非破坏性方式监测生产过程中的材料异常，提升工业检测效率。

研究方法: 通过实验对复合材料和陶瓷进行多次扫描，评估MIR-OCT系统的穿透能力，并测试预处理和AI增强视觉算法在异常检测中的效果。

研究结果: 研究展示了MIR-OCT系统在检测材料内部异常方面的潜力，同时探讨了算法优化的参数选择和系统局限性。

研究结论: MIR-OCT系统结合AI算法在工业检测中具有重要价值，但需进一步优化参数以克服现有局限性。

中文摘要: 本文旨在评估中红外（MIR）光学相干断层扫描（OCT）系统作为穿透不同材料并检测表面下异常的工具。这对于监测生产过程非常有用，为工业提供了高价值的非破坏性检测技术。在这项探索性研究中，对复合材料和陶瓷进行了多次扫描，以了解系统的能力。此外，还评估了哪些预处理和AI增强视觉算法可以作为异常检测方法，用于识别分析对象中的异常区域。研究将讨论参数选择的限制和标准，并突出系统的优势和弱点。

</details>


### [167] [Classification based deep learning models for lung cancer and disease using medical images](https://arxiv.org/abs/2507.01279)
**中文标题：基于分类的深度学习模型用于肺癌和肺部疾病的医学图像分析**

*Ahmad Chaddad,Jihao Peng,Yihang Wu*

主要分类: eess.IV

摘要简述: 本文提出了一种名为ResNet+的新型深度卷积神经网络模型，用于通过医学图像预测肺癌和肺部疾病。该模型结合了ResNet-D模块和卷积注意力模块，显著提高了预测准确性，并在多个公开数据集上验证了其优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在医学图像分析中的应用显著提升了肺癌预测能力。然而，传统CNN模型在下采样过程中可能丢失特征信息，且存在类别不平衡问题。因此，本研究旨在通过改进ResNet框架，提出一种更高效的模型以解决这些问题。

研究方法: 本研究提出了一种基于ResNet框架的改进模型ResNet+，集成了ResNet-D模块以增强特征提取能力，并在瓶颈层中加入了卷积注意力模块以提升模型泛化能力。此外，采用数据增强技术解决类别不平衡问题。

研究结果: 实验结果表明，ResNet+模型在多个公开数据集上表现优异，例如在LC2500数据集上达到98.14%的准确率/F1值，在IQ-OTH/NCCD数据集上达到99.25%/99.13%。同时，该模型在计算成本上也优于原始ResNet系列。

研究结论: ResNet+模型在肺癌和肺部疾病的医学图像分类任务中表现出色，不仅提高了预测准确性，还降低了计算成本。该模型的代码已公开，为相关研究提供了实用工具。

中文摘要: 深度学习在医学图像分析中的应用显著提升了肺癌预测能力。本研究提出了一种名为ResNet+的新型深度卷积神经网络模型，基于ResNet框架，旨在通过改进下采样层和加入注意力模块提升预测性能。为解决类别不平衡问题，采用了数据增强技术。实验在五个公开数据集上进行，结果显示ResNet+模型在LC2500和IQ-OTH/NCCD数据集上分别达到98.14%/98.14%和99.25%/99.13%的准确率/F1值，且计算成本更低。该模型在公开数据集上的表现优于基线模型，代码已公开。

</details>


### [168] [PanTS: The Pancreatic Tumor Segmentation Dataset](https://arxiv.org/abs/2507.01291)
**中文标题：PanTS：胰腺肿瘤分割数据集**

*Wenxuan Li,Xinze Zhou,Qi Chen,Tianyu Lin,Pedro R. A. S. Bassi,Szymon Plotka,Jaroslaw B. Cwikla,Xiaoxi Chen,Chen Ye,Zheren Zhu,Kai Ding,Heng Li,Kang Wang,Yang Yang,Yucheng Tang,Daguang Xu,Alan L. Yuille,Zongwei Zhou*

主要分类: eess.IV

摘要简述: PanTS是一个大规模、多机构合作的数据集，旨在推动胰腺CT分析研究，包含36,390个CT扫描和993,000多个专家验证的标注，覆盖胰腺肿瘤及周围结构。AI模型在PanTS上训练后性能显著优于现有公开数据集。


<details>
  <summary>详细信息</summary>
研究动机: 现有胰腺CT数据集规模有限，标注不全面，限制了AI模型在胰腺肿瘤检测和分割中的性能提升。PanTS旨在填补这一空白，提供更大规模和更全面的标注数据。

研究方法: PanTS数据集收集了来自145个医疗中心的36,390个CT扫描，包含胰腺肿瘤、胰腺头/体/尾及24个周围结构的专家验证标注。每个扫描还包含患者年龄、性别、诊断等元数据。

研究结果: 在PanTS上训练的AI模型在胰腺肿瘤检测、定位和分割任务中表现显著优于基于现有公开数据集的模型。分析表明，性能提升主要归因于标注规模扩大16倍及额外周围结构的支持。

研究结论: PanTS是目前最大且最全面的胰腺CT数据集，为胰腺CT分析的AI模型开发和评估提供了新的基准。

中文摘要: PanTS是一个大规模、多机构合作的数据集，旨在推动胰腺CT分析研究。它包含来自145个医疗中心的36,390个CT扫描，以及超过993,000个专家验证的体素级标注，涵盖胰腺肿瘤、胰腺头/体/尾及24个周围解剖结构（如血管/骨骼结构和腹部/胸部器官）。每个扫描还包含患者年龄、性别、诊断、对比相位、平面间距、切片厚度等元数据。在PanTS上训练的AI模型在胰腺肿瘤检测、定位和分割任务中表现显著优于基于现有公开数据集的模型。分析表明，这些性能提升直接归因于标注规模扩大16倍，并间接得益于额外周围结构的支持。作为同类资源中最大且最全面的数据集，PanTS为胰腺CT分析的AI模型开发和评估提供了新的基准。

</details>


### [169] [SWinMamba: Serpentine Window State Space Model for Vascular Segmentation](https://arxiv.org/abs/2507.01323)
**中文标题：SWinMamba：基于蛇形窗口状态空间模型的血管分割方法**

*Rongchang Zhao,Huanchi Liu,Jian Zhang*

主要分类: eess.IV

摘要简述: 提出了一种名为SWinMamba的新方法，通过蛇形窗口序列和双向状态空间模型，实现了医学图像中血管的精确分割，解决了血管结构不连续的问题。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像中的血管分割对疾病诊断和手术导航至关重要，但由于血管纤细且缺乏有效的先验建模，分割结果常出现不连续问题。本文旨在解决这一问题。

研究方法: 提出SWinMamba方法，包含蛇形窗口标记器（SWToken）和双向聚合模块（BAM），通过蛇形窗口序列自适应分割图像并建模血管连续性，同时设计了空间-频率融合单元（SFFU）增强特征表示。

研究结果: 在三个具有挑战性的数据集上进行了大量实验，结果表明SWinMamba能够生成完整且连通的血管分割结果，性能优越。

研究结论: SWinMamba通过创新的蛇形窗口序列和双向状态空间模型，显著提升了血管分割的准确性和连续性，为医学图像分析提供了有效工具。

中文摘要: 医学图像中的血管分割对疾病诊断和手术导航至关重要。然而，由于血管纤细且缺乏有效的先验建模，分割结果常出现不连续问题。本文提出了一种名为蛇形窗口Mamba（SWinMamba）的新方法，通过将蛇形窗口序列引入双向状态空间模型，实现了血管的精确分割。蛇形窗口序列通过自适应引导全局视觉上下文建模，高效捕捉血管结构的特征。具体而言，蛇形窗口标记器（SWToken）利用重叠的蛇形窗口序列自适应分割输入图像，为血管结构建模提供灵活的感知野（RFs）。双向聚合模块（BAM）整合感知野中的局部特征，实现血管连续性的表示。此外，设计了空间-频率融合单元（SFFU）的双域学习，以增强血管结构的特征表示。在三个具有挑战性的数据集上的大量实验表明，所提出的SWinMamba能够生成完整且连通的血管分割结果，性能优越。

</details>


### [170] [Structure and Smoothness Constrained Dual Networks for MR Bias Field Correction](https://arxiv.org/abs/2507.01326)
**中文标题：基于结构和平滑性约束的双网络MR偏置场校正方法**

*Dong Liang,Xingyu Qiu,Yuzhen Li,Wei Wang,Kuanquan Wang,Suyu Dong,Gongning Luo*

主要分类: eess.IV

摘要简述: 提出了一种名为S2DNets的双网络模型，通过引入结构和平滑性约束，自监督校正MR图像的偏置场，有效去除强度不均匀性并保留更多结构细节。


<details>
  <summary>详细信息</summary>
研究动机: MR成像技术对疾病诊断至关重要，但设备限制导致图像强度不均匀，影响分析和诊断。现有深度学习模型仅关注全局外观学习，忽略了图像结构和偏置场平滑性约束，导致校正结果失真。

研究方法: 提出S2DNets双网络模型，结合分段结构约束和偏置场平滑性，通过自监督学习校正MR图像的偏置场。

研究结果: 在临床和模拟MR数据集上的实验表明，S2DNets优于传统和基于深度学习的方法，并在下游分割任务中表现出色。

研究结论: S2DNets通过结构和平滑性约束，显著提升了MR图像偏置场校正的效果，为医学图像分析提供了更可靠的工具。

中文摘要: MR成像技术对疾病诊断具有重要价值，但由于设备限制，成像结果常存在显著的强度不均匀性，影响定性和定量医学分析。近年来，一些无监督深度学习模型被提出用于改善MR图像，但这些模型仅关注全局外观学习，忽略了图像结构和偏置场平滑性的约束，导致校正结果失真。本文提出了一种新颖的结构和平滑性约束双网络（S2DNets），旨在自监督校正偏置场。S2DNets通过引入分段结构约束和偏置场平滑性进行网络训练，有效去除非均匀强度并保留更多结构细节。在临床和模拟MR数据集上的大量实验表明，该模型优于其他传统和基于深度学习的方法。除了视觉指标的比较，下游MR图像分割任务也被用于评估该模型的影响。源代码可在以下网址获取：https://github.com/LeongDong/S2DNets。

</details>


### [171] [BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy](https://arxiv.org/abs/2507.01387)
**中文标题：BronchoGAN：用于视频支气管镜的解剖学一致且领域无关的图像到图像转换**

*Ahmad Soliman,Ron Keuth,Marian Himstedt*

主要分类: eess.IV

摘要简述: BronchoGAN通过引入解剖学约束和中间深度图像表示，实现了跨域支气管镜图像的稳健转换，显著提升了合成图像的质量和数据集规模。


<details>
  <summary>详细信息</summary>
研究动机: 由于支气管镜图像数据有限，跨域图像转换技术对训练深度学习模型至关重要。本研究旨在解决不同领域（如虚拟支气管镜、体模等）图像转换的挑战，并确保解剖结构的准确性。

研究方法: 提出BronchoGAN，将支气管孔匹配的解剖学约束集成到条件GAN中，并使用基础模型生成的深度图像作为中间表示，确保跨域稳健性。此外，通过深度图像表示简化了配对训练数据的构建。

研究结果: 实验表明，BronchoGAN能成功将不同领域的输入图像转换为逼真的人类气道图像，解剖结构（如支气管孔）得到稳健保留，FID、SSIM和Dice系数显著提升，Dice系数最高提升0.43。

研究结论: BronchoGAN通过解剖学约束和中间深度表示，实现了跨域支气管镜图像的稳健转换，填补了公共支气管镜图像数据的空白，为大规模数据集生成提供了可能。

中文摘要: 支气管镜图像的有限可用性使得图像合成对训练深度学习模型尤为重要。跨不同领域（如虚拟支气管镜、体模以及体内和体外图像数据）的稳健图像转换对临床应用至关重要。本文提出BronchoGAN，将解剖学约束集成到条件GAN中，用于图像到图像转换。特别是，我们强制支气管孔在输入和输出图像中匹配。我们还提出使用基础模型生成的深度图像作为中间表示，确保对各种输入领域的稳健性，减少对单个训练数据集的依赖。此外，中间深度图像表示简化了配对训练数据的构建。实验表明，来自不同领域（如虚拟支气管镜、体模）的输入图像可以成功转换为模拟真实人类气道外观的图像。我们证明了解剖学设置（如支气管孔）可以通过我们的方法稳健保留，并通过改进的FID、SSIM和Dice系数得分进行定性和定量验证。我们的解剖学约束使合成图像的Dice系数最高提升0.43。通过基础模型的中间深度表示和将支气管孔分割作为解剖学约束集成到条件GAN中，我们能够稳健地转换来自不同支气管镜输入领域的图像。BronchoGAN可以利用公共CT扫描数据（虚拟支气管镜）生成具有逼真外观的大规模支气管镜图像数据集，填补了公共支气管镜图像数据的空白。

</details>


### [172] [Multi Source COVID-19 Detection via Kernel-Density-based Slice Sampling](https://arxiv.org/abs/2507.01564)
**中文标题：基于核密度切片采样的多源COVID-19检测**

*Chia-Ming Lee,Bo-Cheng Qiu,Ting-Yao Chen,Ming-Han Sun,Fang-Ying Lin,Jung-Tse Tsai,I-An Tsai,Yu-Fan Lin,Chih-Chung Hsu*

主要分类: eess.IV

摘要简述: 本文提出了一种基于核密度切片采样的多源COVID-19检测方法，通过空间切片特征学习框架和高效预处理流程，在四个医疗中心的CT扫描数据上取得了高准确率。


<details>
  <summary>详细信息</summary>
研究动机: 多源医疗影像数据存在变异性，需要一种能够有效处理多中心数据的COVID-19检测方法。

研究方法: 采用空间切片特征学习（SSFL）框架和核密度切片采样（KDS）技术，结合肺区域提取、质量控制和自适应切片采样，从每份扫描中选择八张代表性切片。比较了EfficientNet和Swin Transformer两种架构。

研究结果: EfficientNet模型的F1分数为94.68%，优于Swin Transformer的93.34%，验证了KDS流程在多源数据上的有效性。

研究结论: 基于KDS的预处理流程在多源COVID-19检测中表现优异，同时强调了数据集平衡在多中心医学影像评估中的重要性。

中文摘要: 本文介绍了我们在多源COVID-19检测挑战中的解决方案，该方法用于分类来自四个不同医疗中心的胸部CT扫描。为应对多源变异性，我们采用了空间切片特征学习（SSFL）框架和基于核密度的切片采样（KDS）。预处理流程结合了肺区域提取、质量控制和自适应切片采样，从每份扫描中选择八张代表性切片。我们在验证集上比较了EfficientNet和Swin Transformer架构。EfficientNet模型的F1分数达到94.68%，优于Swin Transformer的93.34%。结果表明，基于KDS的流程在多源数据上具有高效性，并凸显了多机构医学影像评估中数据集平衡的重要性。

</details>


### [173] [Robust brain age estimation from structural MRI with contrastive learning](https://arxiv.org/abs/2507.01794)
**中文标题：Error**

*Carlo Alberto Barbano,Benoit Dufumier,Edouard Duchesnay,Marco Grangetto,Pietro Gori*

主要分类: eess.IV

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [174] [Autoadaptive Medical Segment Anything Model](https://arxiv.org/abs/2507.01828)
**中文标题：自适应医学图像分割模型**

*Tyler Ward,Meredith K. Owen,O'Kira Coleman,Brian Noehren,Abdullah-Al-Zubaer Imran*

主要分类: eess.IV

摘要简述: 本文提出了一种名为ADA-SAM的新型医学图像分割框架，通过多任务学习和梯度反馈机制，显著提升了在有限标注数据下的分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统医学图像分割模型依赖大量人工标注数据，成本高且耗时。因此，亟需一种高效、自动且标注需求低的分割方法。

研究方法: ADA-SAM结合了多任务学习和梯度反馈机制，利用辅助分类器的类激活图指导半监督分割分支，并通过分割梯度优化分类预测。

研究结果: 在真实临床数据上的实验表明，ADA-SAM在有限标注条件下，性能显著优于全监督和半监督基线模型，提升幅度达两位数。

研究结论: ADA-SAM为医学图像分割提供了一种高效且自动化的解决方案，尤其在标注数据有限的情况下表现优异。

中文摘要: 医学图像分割是影像工作流中的关键任务，影响许多基于图像的决策。传统全监督分割模型依赖大量标注数据，通常通过人工标注获取，成本高、耗时长且易出错。这需要一种准确、自动且标注高效的分割方法。我们提出ADA-SAM（自动、领域特定且自适应的分割模型），一种基于Segment Anything（SAM）框架的新型多任务学习框架，利用辅助分类器的类激活图指导半监督分割分支的预测。此外，ADA-SAM通过梯度反馈机制，利用分割梯度优化分类预测，建立分割与分类分支间的可学习连接。我们在康复试验的真实临床数据上验证了ADA-SAM，结果表明在有限标注条件下，该方法性能显著优于全监督和半监督基线模型，提升幅度达两位数。代码见：https://github.com/tbwa233/ADA-SAM。

</details>


### [175] [A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs](https://arxiv.org/abs/2507.01881)
**中文标题：一种计算资源节约的开源基础模型用于肺癌筛查项目中的胸部疾病检测**

*Niccolò McConnell,Pardeep Vasudev,Daisuke Yamada,Daryl Cheng,Mehran Azimbagirad,John McCabe,Shahab Aslani,Ahmed H. Shahin,Yukun Zhou,The SUMMIT Consortium,Andre Altmann,Yipeng Hu,Paul Taylor,Sam M. Janes,Daniel C. Alexander,Joseph Jacob*

主要分类: eess.IV

摘要简述: 本文提出了一种名为TANGERINE的开源、计算资源节约型视觉基础模型，用于低剂量CT（LDCT）分析，旨在解决肺癌筛查（LCS）项目中放射科医生不足的问题。该模型通过自监督学习预训练，能够快速适应多种疾病分类任务，并在14种疾病分类中达到最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 肺癌筛查（LCS）项目在全球范围内逐渐普及，但放射科医生数量不足限制了其大规模应用。因此，需要一种计算资源节约且易于快速适应的模型，以支持多种肺部疾病的早期检测。

研究方法: TANGERINE基于掩码自编码器框架扩展至3D影像，通过自监督学习在超过98,000例胸部LDCT数据上预训练。该模型设计为轻量级，能够以少量计算资源和训练数据快速微调，适用于多种疾病分类任务。

研究结果: TANGERINE在14种疾病分类任务中表现优异，包括肺癌和多种呼吸系统疾病，且在不同临床中心间具有强泛化能力。相较于从头训练的模型，其微调速度快，所需GPU时间显著减少，且标签效率高。

研究结论: TANGERINE的开源、轻量级设计为下一代医学影像工具提供了快速集成的基础，有望将LCS项目从单一的肺癌检测转向全面的高风险人群呼吸系统疾病管理。

中文摘要: 低剂量计算机断层扫描（LDCT）在肺癌筛查（LCS）项目中的应用在全球范围内逐渐增加。LCS项目为同时检测癌症和非癌症相关的早期肺部疾病提供了难得的机会，但这些努力因放射科医生数量不足而受到限制。本文提出TANGERINE，一种计算资源节约的开源视觉基础模型，用于LDCT体积分析。该模型设计广泛可访问且易于快速适应，能够以有限的计算资源和训练数据快速微调用于多种疾病分类任务。相较于从头训练的模型，TANGERINE在微调过程中表现出快速收敛性，显著减少了GPU时间需求，并展示了强大的标签效率，仅需少量微调数据即可达到或超越其他模型的性能。通过在超过98,000例胸部LDCT数据（包括英国迄今为止最大的LCS项目和27个公共数据集）上进行自监督学习预训练，TANGERINE在14种疾病分类任务（包括肺癌和多种呼吸系统疾病）中达到最优性能，并在不同临床中心间表现出强泛化能力。通过将掩码自编码器框架扩展至3D影像，TANGERINE提供了一种可扩展的LDCT分析解决方案，其结合了架构简单性、公开可用性和适度的计算需求，与近期封闭且资源密集的模型形成鲜明对比。其轻量级、开源的设计为快速集成到下一代医学影像工具奠定了基础，有望将LCS项目从单一的肺癌检测转向全面的高风险人群呼吸系统疾病管理。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [176] [PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning](https://arxiv.org/abs/2507.01029)
**中文标题：PathCoT：零样本病理视觉推理的思维链提示方法**

*Junjie Zhou,Yingli Zuo,Shichang Feng,Peng Wan,Qi Zhu,Daoqiang Zhang,Wei Shao*

主要分类: cs.LG

摘要简述: 本文提出PathCoT，一种零样本思维链提示方法，通过整合病理学专家知识和自评估机制，提升多模态大语言模型在病理视觉推理任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态大语言模型在病理视觉推理任务中表现不佳，主要因缺乏领域知识和思维链推理中可能引入错误。PathCoT旨在通过专家知识和自评估解决这些问题。

研究方法: PathCoT结合病理学专家知识指导模型推理，并通过自评估机制比较直接输出和思维链推理结果，选择可靠答案。

研究结果: 在PathMMU数据集上的实验表明，PathCoT显著提升了病理视觉理解和推理能力。

研究结论: PathCoT通过整合专家知识和自评估，有效解决了多模态大语言模型在病理视觉推理中的局限性，为领域特定任务提供了新思路。

中文摘要: 随着生成式人工智能和指令调优技术的发展，多模态大语言模型（MLLMs）在通用推理任务上取得了显著进展。得益于思维链（CoT）方法，MLLMs能够逐步解决视觉推理问题。然而，现有MLLMs在病理视觉推理任务中仍面临重大挑战：（1）由于缺乏领域特定信息，语言模型表现不佳，可能导致模型幻觉。（2）CoT中的额外推理步骤可能引入错误，导致答案偏离。为解决这些问题，我们提出PathCoT，一种新颖的零样本CoT提示方法，将病理学专家知识整合到MLLMs的推理过程中，并通过自评估减少答案偏离。具体而言，PathCoT利用先验知识指导MLLMs像病理专家一样工作，并结合领域知识对图像进行全面分析。通过引入专家知识，PathCoT能够通过CoT推理获得答案。此外，PathCoT还加入自评估步骤，评估MLLMs直接生成的结果和通过CoT推导的结果，最终确定可靠答案。在PathMMU数据集上的实验结果证明了该方法在病理视觉理解和推理中的有效性。

</details>


### [177] [An Uncertainty-Aware Dynamic Decision Framework for Progressive Multi-Omics Integration in Classification Tasks](https://arxiv.org/abs/2507.01032)
**中文标题：一种不确定性感知的动态决策框架用于渐进式多组学分类任务**

*Nan Mu,Hongbo Yang,Chen Zhao*

主要分类: cs.LG

摘要简述: 本文提出了一种不确定性感知的动态决策框架，用于多组学数据分类，旨在以最低测试成本实现高诊断准确性。通过单组学水平的神经网络优化和多组学的融合策略，动态引入数据源，显著减少冗余测试。


<details>
  <summary>详细信息</summary>
研究动机: 高通量多组学技术虽有助于疾病机制研究和早期诊断，但其高成本可能导致资源浪费。本文旨在通过动态决策框架，在保证诊断准确性的同时降低测试成本。

研究方法: 在单组学水平，通过改进神经网络激活函数生成Dirichlet分布参数，利用主观逻辑量化分类结果的置信度和不确定性。在多组学水平，基于Dempster-Shafer理论融合异构数据，动态引入数据源直至模型置信度达标。

研究结果: 在四个多组学数据集（ROSMAP、LGG、BRCA、KIPAN）上评估，50%以上病例仅需单组学数据即可准确分类，显著减少冗余测试，同时保持与全组学模型相当的诊断性能。

研究结论: 该框架在降低测试成本的同时，保持了高诊断准确性和生物学意义，为多组学分类任务提供了高效解决方案。

中文摘要: 背景与目标：高通量多组学技术对阐明疾病机制和早期诊断具有重要价值，但其高成本可能导致资源浪费。为解决这一问题，我们提出了一种不确定性感知的多视图动态决策框架，旨在以最低测试成本实现高诊断准确性。方法：在单组学水平，通过改进神经网络激活函数生成Dirichlet分布参数，利用主观逻辑量化分类结果的置信度和不确定性。在多组学水平，基于Dempster-Shafer理论融合异构数据，动态引入数据源直至模型置信度达标。结果与结论：在四个多组学数据集（ROSMAP、LGG、BRCA、KIPAN）上评估，50%以上病例仅需单组学数据即可准确分类，显著减少冗余测试，同时保持与全组学模型相当的诊断性能。

</details>


### [178] [Data-driven Insights for Informed Decision-Making: Applying LSTM Networks for Robust Electricity Forecasting in Libya](https://arxiv.org/abs/2507.01034)
**中文标题：数据驱动的决策洞察：应用LSTM网络实现利比亚电力稳健预测**

*Asma Agaal,Mansour Essgaer,Hend M. Farkash,Zulaiha Ali Othman*

主要分类: cs.LG

摘要简述: 本研究利用LSTM神经网络对利比亚班加西的电力负荷、发电量和缺口进行预测，结果表明LSTM在非平稳和季节性数据中表现最佳，为政策制定者提供了实用的数据支持。


<details>
  <summary>详细信息</summary>
研究动机: 利比亚班加西地区电力供应不稳定，频繁停电和基础设施不足问题严重。准确的电力预测对电网稳定和能源规划至关重要，尤其是在数据稀缺且不稳定的地区。

研究方法: 研究使用2019年（不稳定年份）和2023年（稳定年份）的历史数据，应用多种时间序列模型（如ARIMA、季节性ARIMA、动态回归ARIMA、指数平滑、极端梯度提升和LSTM神经网络），并通过缺失值填补、异常值平滑和对数转换增强数据集。

研究结果: LSTM模型在预测电力负荷、发电量和缺口方面表现最优，能够有效捕捉非平稳和季节性模式。优化的LSTM框架还整合了温度和湿度等外生因素，进一步提升了预测的鲁棒性。

研究结论: LSTM模型为电力预测提供了高效工具，尤其在数据稀缺且不稳定的地区。研究结果为政策制定者和电网运营商提供了实用的决策依据，有助于优化负荷管理和资源规划。

中文摘要: 准确的电力预测对电网稳定和能源规划至关重要，尤其是在利比亚班加西地区，频繁停电、发电不足和基础设施限制问题持续存在。本研究提出了一种数据驱动的方法，利用2019年（不稳定年份）和2023年（稳定年份）的历史数据，预测2025年的电力负荷、发电量和缺口。应用了多种时间序列模型，包括ARIMA、季节性ARIMA、动态回归ARIMA、指数平滑、极端梯度提升和长短期记忆（LSTM）神经网络。通过缺失值填补、异常值平滑和对数转换增强了数据集。使用均方误差、均方根误差、平均绝对误差和平均绝对百分比误差评估性能。LSTM在所有模型中表现最佳，显示出对非平稳和季节性模式的强大建模能力。本研究的一个关键贡献是优化的LSTM框架，整合了温度和湿度等外生因素，为预测多项电力指标提供了鲁棒性能。这些结果为政策制定者和电网运营商提供了实用洞察，有助于在数据稀缺且不稳定的地区实现主动负荷管理和资源规划。

</details>


### [179] [Research on Low-Latency Inference and Training Efficiency Optimization for Graph Neural Network and Large Language Model-Based Recommendation Systems](https://arxiv.org/abs/2507.01035)
**中文标题：基于图神经网络和大语言模型的推荐系统低延迟推理与训练效率优化研究**

*Yushang Zhao,Haotian Lyu,Yike Peng,Aijia Sun,Feng Jiang,Xinyue Han*

主要分类: cs.LG

摘要简述: 本研究针对基于图神经网络（GNN）和大语言模型（LLM）的混合推荐系统，优化其推理延迟和训练效率。通过架构优化（量化、LoRA、蒸馏）、硬件加速（FPGA、DeepSpeed）等方法，显著提升了性能，推荐使用FPGA和LoRA实现实时部署。


<details>
  <summary>详细信息</summary>
研究动机: 在线服务对高速高效的推荐系统需求日益增长，而混合GNN和LLM的推荐系统存在计算瓶颈，本研究旨在优化其推理延迟和训练效率。

研究方法: 采用混合GNN-LLM架构优化策略（量化、LoRA、蒸馏）和硬件加速（FPGA、DeepSpeed），在R 4.4.2环境下进行实验。

研究结果: 最优配置（Hybrid + FPGA + DeepSpeed）在40-60ms延迟下NDCG@10达到0.75，准确率提升13.6%；LoRA将训练时间减少66%（3.8小时）。

研究结论: 硬件-软件协同设计和参数高效调优使混合模型优于独立GNN或LLM方法，推荐FPGA和LoRA用于实时部署，未来可探索联邦学习和高级融合架构。

中文摘要: 在线服务的快速发展对高速高效的推荐系统（ReS）提出了更高要求，需在实时性能与复杂用户-物品交互处理之间取得平衡。本研究针对混合图神经网络（GNN）和大语言模型（LLM）的推荐系统，优化其推理延迟和训练效率。采用的方法包括：混合GNN-LLM架构优化策略（量化、LoRA、蒸馏）、硬件加速（FPGA、DeepSpeed），并在R 4.4.2环境下进行实验。实验结果显示，最优配置（Hybrid + FPGA + DeepSpeed）在40-60ms延迟下NDCG@10达到0.75，准确率提升13.6%；LoRA将训练时间减少66%（3.8小时）。研究表明，硬件-软件协同设计和参数高效调优使混合模型优于独立GNN或LLM方法。推荐使用FPGA和LoRA实现实时部署。未来工作可探索联邦学习和高级融合架构，以提升可扩展性和隐私保护。本研究为下一代推荐系统在低延迟响应与前沿个性化之间的平衡奠定了重要基础。

</details>


### [180] [Learning to Segment for Vehicle Routing Problems](https://arxiv.org/abs/2507.01037)
**中文标题：学习分段以解决车辆路径问题**

*Wenbin Ouyang,Sirui Li,Yining Ma,Cathy Wu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为FSTA的分解技术和L2Seg神经网络框架，用于加速车辆路径问题（VRP）的迭代求解器，通过识别和保留稳定解段，减少冗余计算，最高可提速7倍。


<details>
  <summary>详细信息</summary>
研究动机: 迭代搜索启发式算法在解决车辆路径问题（VRP）中被认为是先进方法，但其中大部分解在搜索过程中保持稳定，导致冗余计算。本文旨在通过分解技术减少这种冗余，提高求解效率。

研究方法: 提出FSTA分解技术，保留稳定解段并将其聚合为超节点，仅搜索不稳定部分。进一步引入L2Seg神经网络框架，智能区分稳定与不稳定部分，并设计了三种变体：非自回归、自回归及其协同。

研究结果: 实验表明，L2Seg在CVRP和VRPTW上可将现有迭代求解器加速高达7倍，且非自回归与自回归的协同表现最佳。

研究结论: L2Seg是一个灵活框架，兼容传统、基于学习和混合求解器，并能支持广泛的VRP问题，显著提升求解效率。

中文摘要: 迭代搜索启发式算法被广泛认为是解决车辆路径问题（VRP）的先进方法。本研究中，我们发现并利用了一个关键观察：在这些求解器中，大部分解在搜索迭代中保持稳定，导致冗余计算，尤其是对于具有长子路径的大规模VRP。为此，我们首次对“先分段后聚合”（FSTA）分解技术进行了正式研究，以加速迭代求解器。具体而言，FSTA在搜索过程中保留稳定的解段，将每个段内的节点聚合为固定超节点，并仅关注不稳定部分。然而，关键挑战在于确定哪些段应被FSTA聚合。为此，我们引入了“学习分段”（L2Seg），一种新颖的神经网络框架，用于智能区分FSTA分解中潜在稳定和不稳定的部分。我们提出了三种L2Seg变体：非自回归（全局全面但局部不加区分）、自回归（局部精细但全局不足）及其协同，并设计了定制化的训练和推理策略。在CVRP和VRPTW上的实验结果表明，L2Seg可将最先进的迭代求解器加速高达7倍。此外，我们深入分析表明，非自回归与自回归的协同通过结合其互补优势实现了最佳性能。值得注意的是，L2Seg是一个灵活框架，兼容传统、基于学习和混合求解器，同时支持广泛的VRP问题。

</details>


### [181] [On-Policy Optimization of ANFIS Policies Using Proximal Policy Optimization](https://arxiv.org/abs/2507.01039)
**中文标题：基于近端策略优化的ANFIS策略在策略优化**

*Kaaustaaub Shankar,Wilhelm Louw,Kelly Cohen*

主要分类: cs.LG

摘要简述: 本文提出了一种使用近端策略优化（PPO）训练神经模糊控制器的方法，取代了传统的基于值的离策略框架，在CartPole-v1环境中表现优于ANFIS-DQN方法，展示了更低的方差和更快的收敛速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要使用基于值的离策略方法（如DQN）训练神经模糊控制器（ANFIS），但这种方法存在训练不稳定和方差较大的问题。本文旨在探索一种更稳定的在策略优化方法（PPO）来改进神经模糊控制器的训练效果。

研究方法: 本文采用近端策略优化（PPO）作为在策略优化方法，取代了传统的ANFIS-DQN框架。通过在CartPole-v1环境中进行多轮随机种子实验，比较PPO与DQN的训练效果。

研究结果: 实验结果表明，PPO训练的模糊控制器在CartPole-v1环境中达到了平均回报500 +/- 0，训练过程中方差更小，收敛速度更快，优于ANFIS-DQN方法。

研究结论: PPO为训练可解释的神经模糊控制器提供了一种有前景的途径，尤其在强化学习任务中表现出更高的稳定性和效率。

中文摘要: 我们提出了一种使用近端策略优化（PPO）训练神经模糊控制器的强化学习方法。基于先前将深度Q学习应用于自适应神经模糊推理系统（ANFIS）的研究，我们的方法用稳定的在策略演员-评论家循环取代了离策略基于值的框架。我们在CartPole-v1环境中使用多个随机种子评估了该方法，并将其学习性能与ANFIS-深度Q网络（DQN）基线进行了比较。研究发现，经过PPO训练的模糊智能体在20000次更新后在CartPole-v1上实现了500 +/- 0的平均回报，训练过程中的方差小于先前的基于DQN的方法，且整体收敛速度更快。这些结果表明，PPO为训练可解释的神经模糊控制器在强化学习任务中提供了一条有前景的途径。

</details>


### [182] [Fast Clifford Neural Layers](https://arxiv.org/abs/2507.01040)
**中文标题：快速Clifford神经层**

*Tianxiang Xia,Max Neuwinger,Lin Xiao*

主要分类: cs.LG

摘要简述: 本文提出了一种快速Clifford神经层方法，通过引入Clifford代数优化神经网络中的PDE建模，显著提升了2/3D Clifford卷积层和多向量激活层的推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 传统神经网络在PDE建模中存在效率瓶颈，本文旨在通过Clifford代数优化神经网络的推理性能，特别是在2/3D卷积层和多向量激活层的计算中。

研究方法: 研究聚焦于优化2/3D Clifford卷积层和多向量激活层的推理性能，针对单核CPU进行了性能优化，并与标准PyTorch实现进行了对比。

研究结果: 实验表明，在较大数据和网络规模（超过L2缓存）下，本文的实现比标准PyTorch实现快30%。

研究结论: 通过引入Clifford代数优化神经网络层，本文显著提升了PDE建模的效率，为相关领域提供了开源代码支持。

中文摘要: Clifford神经层通过将Clifford代数引入神经网络，改进了PDE建模。本项目重点优化了2/3D Clifford卷积层和多向量激活层的推理性能，针对单核CPU进行了优化。实验结果表明，在一个包含Clifford卷积层和多向量激活层的真实网络块中，我们的实现在较大数据和网络规模（超过L2缓存）下比标准PyTorch实现快30%。我们的代码已开源：https://github.com/egretwAlker/c-opt-clifford-layers。

</details>


### [183] [Fast AI Model Splitting over Edge Networks](https://arxiv.org/abs/2507.01041)
**中文标题：边缘网络上的快速AI模型分割**

*Zuguang Li,Wen Wu,Shaohua Wu,Songge Zhang,Ye Wang,Xuemin,Shen*

主要分类: cs.LG

摘要简述: 本文提出了一种基于有向无环图（DAG）的快速AI模型分割算法，通过最大流方法实现最优分割，显著降低了训练延迟。


<details>
  <summary>详细信息</summary>
研究动机: 复杂的AI模型架构在边缘网络中分割时计算复杂度高，现有方法难以快速找到最优分割方案。

研究方法: 将AI模型表示为DAG，将最优分割问题转化为最小s-t割问题，并提出基于DAG的快速分割算法和块状分割算法以降低复杂度。

研究结果: 实验表明，算法能在毫秒级确定最优分割，并在动态边缘网络中减少训练延迟24.62%-38.95%。

研究结论: 所提算法在计算效率和延迟优化方面优于现有基准，适用于动态边缘网络。

中文摘要: 分割学习（SL）已成为一种计算高效的AI模型训练方法，可减轻设备端计算负担。然而，复杂的AI模型架构在寻找最优分割时计算复杂度较高。本文提出将任意AI模型表示为有向无环图（DAG），并将最优分割问题重新表述为最小s-t割问题。为解决该问题，我们提出了一种基于DAG的快速模型分割算法，通过重构DAG并利用最大流方法实现最优分割。理论分析表明该算法具有最优性。此外，针对具有块状结构的AI模型，我们提出了一种块状分割算法以降低计算复杂度，通过将每个块（即由多个层组成的组件）抽象为单个顶点，从而在简化后的DAG中实现最优分割。大量实验结果表明，所提算法能在毫秒级确定最优分割，并在动态边缘网络中比现有基准减少24.62%-38.95%的训练延迟。

</details>


### [184] [Data Classification with Dynamically Growing and Shrinking Neural Networks](https://arxiv.org/abs/2507.01043)
**中文标题：动态扩展与收缩神经网络的数据分类方法**

*Szymon Świderski,Agnieszka Jastrzębska*

主要分类: cs.LG

摘要简述: 本文提出了一种动态调整神经网络架构的新方法，通过蒙特卡洛树搜索实现模型在训练过程中的动态扩展与收缩，特别适用于多变量时间序列分类任务。


<details>
  <summary>详细信息</summary>
研究动机: 传统神经网络通常采用固定架构，限制了模型的灵活性和适应性。本文旨在通过动态调整网络架构，优化模型性能，尤其是在处理复杂数据（如多变量时间序列）时。

研究方法: 提出了一种基于蒙特卡洛树搜索的动态神经网络架构调整方法，通过模拟网络行为并比较候选架构变化，选择最优调整策略。

研究结果: 实验验证表明，该方法在视觉模式和多变量时间序列分类任务中表现优异，具有显著的鲁棒性和适应性。

研究结论: 动态调整神经网络架构的方法能够有效提升模型性能，尤其在多变量时间序列分类中表现突出，为数据驱动的模型优化提供了新思路。

中文摘要: 数据驱动的神经网络模型构建是人工智能领域的核心问题之一。传统方法通常采用固定架构和可训练权重，而更先进的假设是同时优化权重和模型架构。本文提出了一种新方法，实现了这一目标。本文是会议论文《基于蒙特卡洛树搜索的神经网络动态扩展与收缩》的扩展版本。文中详细展示了如何在训练过程中动态调整神经网络架构。架构设计的决策机制由蒙特卡洛树搜索控制，通过模拟网络行为并比较候选架构变化，选择最佳调整方案。该方法在视觉和时间序列数据集上进行了验证，尤其在多变量时间序列分类中表现出色，归功于其动态适应能力。实验评估表明，该方法在视觉模式和多变量时间序列分类任务中具有显著性能，体现了其鲁棒性和适应性。为便于复现，还提供了Python源代码。

</details>


### [185] [Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals](https://arxiv.org/abs/2507.01045)
**中文标题：跨场景与设备的心脏健康感知：基于170万个体异构数据预训练的多模态基础模型**

*Xiao Gu,Wei Tang,Jinpei Han,Veer Sangha,Fenglin Liu,Shreyank N Gowda,Antonio H. Ribeiro,Patrick Schwab,Kim Branson,Lei Clifton,Antonio Luiz P. Ribeiro,Zhangdaihong Liu,David A. Clifton*

主要分类: cs.LG

摘要简述: 本文提出了一种基于多模态数据的通用心脏感知基础模型（CSFM），通过预训练学习异构心脏信号和文本报告的联合表示，显著提升了跨场景和设备的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统深度学习模型在处理心脏生物信号（如心电图和光电容积图）时，通常依赖同质数据集和静态定制模型，限制了其在多样化临床环境中的鲁棒性和泛化能力。

研究方法: 研究采用先进的Transformer架构和生成式掩码预训练策略，从包含170万个体的大规模异构数据集中学习统一表示，数据集包括MIMIC-III-WDB、MIMIC-IV-ECG和CODE等。

研究结果: CSFM在诊断任务、人口统计信息识别、生命体征测量、临床结果预测和心电图问答等任务中表现优异，显著优于传统单模态单任务方法，并支持多种心电图导联配置和信号模态。

研究结论: CSFM作为一种多功能、可扩展的解决方案，为全面心脏监测提供了潜力，能够适应不同输入配置和传感器模态。

中文摘要: 心脏生物信号（如心电图和光电容积图）对心血管疾病的诊断、预防和管理至关重要，并广泛应用于多种临床任务。传统深度学习方法通常依赖同质数据集和静态定制模型，限制了其在多样化临床环境和采集协议中的鲁棒性和泛化能力。本研究提出了一种心脏感知基础模型（CSFM），利用先进的Transformer架构和生成式掩码预训练策略，从大规模异构健康记录中学习统一表示。模型预训练数据来自多个大规模数据集（包括MIMIC-III-WDB、MIMIC-IV-ECG和CODE），涵盖约170万个体的心脏信号及对应的临床或机器生成文本报告。研究表明，CSFM提取的嵌入不仅可作为多样化心脏感知场景中的有效特征提取器，还能实现跨输入配置和传感器模态的无缝迁移学习。在诊断任务、人口统计信息识别、生命体征测量、临床结果预测和心电图问答等广泛评估中，CSFM始终优于传统单模态单任务方法。值得注意的是，CSFM在从标准12导联系统到单导联配置的多种心电图导联设置中表现稳健，且仅使用心电图、仅使用光电容积图或两者结合的场景中均能胜任。这些发现凸显了CSFM作为一种多功能、可扩展解决方案的潜力，适用于全面心脏监测。

</details>


### [186] [Text Detoxification: Data Efficiency, Semantic Preservation and Model Generalization](https://arxiv.org/abs/2507.01050)
**中文标题：文本去毒：数据效率、语义保留与模型泛化**

*Jing Yu,Yibo Zhao,Jiapeng Zhu,Wenming Shao,Bo Pang,Zhao Zhang,Xiang Li*

主要分类: cs.LG

摘要简述: 本文提出了一种两阶段训练框架，旨在高效去除文本毒性并保留语义，同时提升模型泛化能力，减少对标注数据的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体上毒性内容的广泛传播对网络环境和公共讨论构成威胁，现有方法在去毒性能、语义保留和数据效率上存在不足，亟需改进。

研究方法: 采用两阶段训练：首先在小规模高质量平行数据上进行监督微调，再利用未标注毒性数据和自定义奖励模型，通过Group Relative Policy Optimization训练大语言模型。

研究结果: 实验表明，该方法有效平衡了去毒性能、语义保留和泛化能力，显著减少对标注数据的依赖，达到最先进水平。

研究结论: 提出的两阶段框架成功解决了现有方法的局限性，为文本去毒任务提供了高效且泛化性强的解决方案。

中文摘要: 社交媒体上毒性内容的广泛传播对网络环境和公共讨论构成严重威胁，亟需既能有效去毒又能保留原始语义的方法。然而，现有方法往往难以同时实现强去毒性能、语义保留和对分布外数据的鲁棒性，且通常依赖昂贵的人工标注平行语料库，数据效率低下。为解决这些问题，我们提出了一种两阶段训练框架，联合优化数据效率、语义保留和模型泛化。首先在小规模高质量过滤平行数据上进行监督微调以建立强初始化，随后利用未标注毒性输入和自定义奖励模型，通过Group Relative Policy Optimization训练大语言模型。实验结果表明，我们的方法有效缓解了先前工作的权衡问题，在减少对标注数据依赖的同时实现了最先进的性能和更好的泛化能力。代码发布于：https://anonymous.4open.science/r/Detoxification-of-Text-725F/

</details>


### [187] [Long-Sequence Memory with Temporal Kernels and Dense Hopfield Functionals](https://arxiv.org/abs/2507.01052)
**中文标题：基于时间核与密集Hopfield泛函的长序列记忆**

*Ahmed Farooq*

主要分类: cs.LG

摘要简述: 本文提出了一种基于密集Hopfield网络的新型能量函数，通过引入时间核函数实现长序列记忆的高效存储与检索，特别适用于高维数据（如电影帧）的时序建模，并在Transformer架构中展现出潜在应用价值。


<details>
  <summary>详细信息</summary>
研究动机: 现有Transformer架构在处理长序列任务时存在局限性，尤其是长程依赖性问题。本文旨在通过改进Hopfield网络的能量函数，结合时间核函数，提升长序列记忆的存储与检索效率，为自然语言处理、时间序列预测等领域提供新思路。

研究方法: 提出了一种基于密集Hopfield网络的新型能量函数，通过引入时间核函数$K(m, k)$捕捉时序依赖关系，实现长序列模式的高效存储与顺序检索。该方法特别适用于高维数据（如电影帧）的时序建模。

研究结果: 实验表明，该方法能够高效存储和顺序检索长序列数据（如电影帧），并在Transformer架构中展现出潜在应用，包括长序列建模、记忆增强、时序偏置注意力等。

研究结论: 本文提出的方法为解决Transformer在长上下文任务中的局限性提供了新思路，具有在自然语言处理、时间序列预测等领域的广泛应用潜力。

中文摘要: 本研究提出了一种新型的长序列记忆能量泛函，基于密集Hopfield网络框架，通过高阶相互作用实现指数级存储容量。在长序列Hopfield记忆模型的基础上，我们引入时间核$K(m, k)$以捕捉时序依赖关系，从而实现对长序列模式的高效顺序检索。该方法适用于高维向量（如电影帧）的存储与检索，因其在高维空间中具有足够的时序变化。该技术在现代Transformer架构中具有广泛应用，包括高效长序列建模、记忆增强、带时序偏置的注意力机制，以及长程时间序列依赖的优化处理。我们的模型为解决Transformer在长上下文任务中的局限性提供了新思路，对自然语言处理、预测等领域具有潜在影响。

</details>


### [188] [XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science](https://arxiv.org/abs/2507.01054)
**中文标题：XxaCT-NN：材料科学中结构无关的多模态学习**

*Jithendaraa Subramanian,Linda Hung,Daniel Schweigert,Santosh Suram,Weike Ye*

主要分类: cs.LG

摘要简述: 本文提出了一种无需晶体结构输入的多模态学习框架XxaCT-NN，通过元素组成和X射线衍射数据实现材料科学中的高效预测，并展示了自监督预训练策略的优越性。


<details>
  <summary>详细信息</summary>
研究动机: 当前材料发现主要依赖基于晶体结构的模型，但在实际应用中，原子结构往往难以获取。本文旨在开发一种无需结构输入的多模态学习方法，利用更易获取的元素组成和X射线衍射数据。

研究方法: 提出了一种多模态框架，结合模态特定编码器和交叉注意力融合模块，并在Alexandria数据集上进行训练。采用掩码XRD建模（MXM）和对比对齐作为自监督预训练策略。

研究结果: 预训练显著提升了收敛速度（最高4.2倍加速）和模型性能。多模态方法在大规模数据下表现优于单模态基线，且随着数据量增加优势更明显。

研究结论: 本文为材料科学提供了一种无需结构输入、基于实验数据的多模态学习框架，为未来研究奠定了基础。

中文摘要: 近年来，材料发现的研究主要依赖于基于结构的模型，尤其是使用晶体图的模型。尽管这些模型在计算数据集中表现优异，但在实际应用中，原子结构往往未知或难以获取。我们提出了一种可扩展的多模态框架，直接从元素组成和X射线衍射（XRD）这两种实验流程中更易获取的模态中学习，无需晶体结构输入。我们的架构结合了模态特定编码器和交叉注意力融合模块，并在包含500万样本的Alexandria数据集上进行训练。我们提出了掩码XRD建模（MXM），并将MXM和对比对齐作为自监督预训练策略。预训练显著提升了收敛速度（最高4.2倍加速），并提高了准确性和表示质量。我们进一步证明，多模态方法在大规模数据下的表现优于单模态基线，且随着数据量增加优势更明显。我们的研究为材料科学中无需结构输入、基于实验数据的基础模型提供了一条可行路径。

</details>


### [189] [Evaluation of a Foundational Model and Stochastic Models for Forecasting Sporadic or Spiky Production Outages of High-Performance Machine Learning Services](https://arxiv.org/abs/2507.01067)
**中文标题：基础模型与随机模型在预测高性能机器学习服务偶发或尖峰生产中断中的评估**

*Keun Soo Yim*

主要分类: cs.LG

摘要简述: 本文评估了一种基础模型和随机模型在预测高性能机器学习服务中偶发或尖峰生产中断的表现。基础模型在长序列和零样本场景中表现优异，但尚未用于预测罕见尖峰事件。研究优化了基础模型，并与经典随机模型（如移动平均和自回归）进行对比，发现基础模型在特定根因的年中断统计预测中误差低于6%。


<details>
  <summary>详细信息</summary>
研究动机: 时间序列预测模型在电力指标和软件负载等领域有广泛应用，但基础模型尚未用于预测罕见且具有挑战性的尖峰事件（如生产中断）。本文旨在填补这一空白，评估基础模型与经典随机模型在预测高性能机器学习服务偶发中断中的表现。

研究方法: 研究优化了一种先进的基础模型，用于预测高性能机器学习服务的偶发或尖峰生产中断。同时，与经典随机模型（如移动平均和自回归）进行对比分析，评估各模型在尖峰事件中的预测误差，并识别基础模型与随机模型在数据模式追踪上的差异。

研究结果: 研究发现，优化后的基础模型在预测特定根因的年中断统计时，误差低于6%。分析还揭示了基础模型与随机模型在追踪目标数据关键模式上的不同表现。

研究结论: 基础模型在预测偶发或尖峰生产中断中表现出色，误差低于6%，优于经典随机模型。研究为高性能机器学习服务的中断预测提供了有效工具。

中文摘要: 时间序列预测模型在现实中有多种应用（如电力指标和软件负载）。最新的基础模型在长序列和零样本场景中表现出色，但尚未用于预测罕见的尖峰事件（即极端事件的边缘案例）。本文优化了一种先进的基础模型，用于预测支持数十亿客户端设备的高性能机器学习服务的偶发或尖峰生产中断。我们评估了基础模型与经典随机预测模型（如移动平均和自回归）的预测误差。分析帮助我们理解每种模型在偶发或尖峰事件中的表现，例如识别基础模型与随机模型在目标数据关键模式追踪上的差异。使用最优参数模型，我们估计了特定根因的年中断统计，误差低于6%。

</details>


### [190] [Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning](https://arxiv.org/abs/2507.01196)
**中文标题：大型脑波基础模型是否已具备能力？来自微调的见解**

*Na Lee,Konstantinos Barmpas,Yannis Panagakis,Dimitrios Adamos,Nikolaos Laskaris,Stefanos Zafeiriou*

主要分类: cs.LG

摘要简述: 大型脑波基础模型（LBMs）在脑机接口（BCI）任务中表现有限，仅比传统深度架构提升0.9%-1.2%，但参数需求大幅增加。通过低秩适应（LoRA）等技术，可减少参数而不降低性能，表明当前LBMs的效率和架构需改进。


<details>
  <summary>详细信息</summary>
研究动机: 基础模型在AI领域表现优异，但其在脑波建模中的能力尚不明确。本文旨在通过系统实验评估LBMs在BCI任务中的表现，探索其实际应用潜力。

研究方法: 通过多任务（如记忆任务和睡眠阶段分类）的系统微调实验，结合全模型微调和参数高效适应技术（如LoRA），分析LBMs的性能和效率。

研究结果: LBMs在BCI任务中仅小幅提升性能（0.9%-1.2%），但参数需求显著增加。LoRA技术可减少参数而不影响性能，表明当前LBMs的架构和训练效率存在问题。

研究结论: 当前LBMs在脑波分析中潜力有限，需针对领域优化架构和训练策略。LoRA等技术的应用为未来改进提供了方向。

中文摘要: 基础模型在人工智能（AI）多个领域取得了显著成功，但其在脑波建模中的能力尚不明确。本文通过系统微调实验，全面评估了当前大型脑波基础模型（LBMs）在多个脑机接口（BCI）基准任务（包括记忆任务和睡眠阶段分类）中的表现。广泛分析表明，最先进的LBMs仅比传统深度架构略有提升（0.9%-1.2%），但参数需求显著增加（百万级对数千级），引发了关于其在BCI中效率和适用性的重要问题。此外，通过详细消融研究和低秩适应（LoRA），我们显著减少了可训练参数而不降低性能，同时发现架构和训练效率限制了LBMs的当前能力。实验涵盖全模型微调和参数高效适应技术，为BCI应用提供了优化训练策略的见解。我们首次将LoRA应用于LBMs，发现同时适应多个神经网络组件时性能提升显著。这些发现强调了领域专用开发策略对推动LBMs的关键需求，表明当前架构可能需要重新设计以充分发挥基础模型在脑波分析中的潜力。

</details>


### [191] [Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradients and AdamW](https://arxiv.org/abs/2507.01241)
**中文标题：超越一阶方法：使用随机共轭次梯度和AdamW训练大语言模型**

*Di Zhang,Yihang Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种结合随机共轭次梯度和AdamW的自适应采样方法，用于训练大语言模型（LLMs），相比传统SGD方法，该方法在收敛速度和扩展性上表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 传统随机梯度下降（SGD）方法在大规模语言模型训练中表现出性能局限性，本文旨在通过改进优化方法提升训练效率和效果。

研究方法: 提出了一种随机共轭次梯度方法，结合自适应采样技术，动态调整样本大小和搜索方向，并采用类似AdamW的算法自适应调整步长。

研究结果: 实验结果表明，该方法在收敛速度和扩展性上优于传统SGD，显著提升了优化过程的速度和准确性。

研究结论: 该方法不仅保留了传统一阶方法的优势，还有效解决了LLM训练中的非凸性和非光滑性问题，为大规模模型训练提供了更高效的解决方案。

中文摘要: 随机梯度下降（SGD）长期以来是大语言模型（LLM）训练的核心方法。然而，其有效性在大规模应用中逐渐受到质疑，尤其是经验证据表明其可能存在性能限制。为此，本文提出了一种专门针对LLM训练的随机共轭次梯度方法及自适应采样技术。该方法不仅实现了更快的单次迭代收敛，还表现出优于传统SGD技术的扩展性。通过样本复杂度分析自适应选择样本大小，利用随机共轭次梯度方法确定搜索方向，并采用类似AdamW的算法自适应调整步长。这一方法既保留了一阶方法的关键优势，又有效解决了LLM训练中固有的非凸性和非光滑性问题。此外，我们还详细分析了该算法的优势。实验结果表明，所提方法不仅保持了传统SGD技术的扩展性，而且在许多情况下超越了其性能，显著提升了优化过程的速度和准确性。

</details>


### [192] [PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning](https://arxiv.org/abs/2507.01271)
**中文标题：PULSE：大型多模态模型遗忘的实用评估场景**

*Tatsuki Kawakami,Kazuki Egashira,Atsuyuki Miyai,Go Irie,Kiyoharu Aizawa*

主要分类: cs.LG

摘要简述: 本文提出了PULSE协议，用于评估大型多模态模型（LMMs）的遗忘技术，重点关注预训练知识遗忘和长期可持续性评估。研究发现，现有方法在遗忘预训练知识时表现不佳，且顺序遗忘会导致性能显著下降。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，遗忘技术作为解决大型语言模型（LLMs）和多模态模型（LMMs）隐私和版权问题的方法受到关注。然而，现有的LMMs遗忘基准仅关注单次遗忘微调知识，缺乏对预训练知识遗忘和长期可持续性评估的研究。

研究方法: 本文提出PULSE协议，从两个关键角度评估LMMs的遗忘技术：(i) 预训练知识遗忘，分析不同知识获取阶段的影响；(ii) 长期可持续性评估，处理顺序遗忘请求。并对现有方法进行了评估。

研究结果: 结果显示，尽管某些技术能成功遗忘微调知识，但在遗忘预训练知识时表现不佳。此外，单次批量遗忘有效的方法在顺序遗忘相同数据时性能显著下降。

研究结论: PULSE协议为LMMs的遗忘技术提供了更现实的评估框架，揭示了现有方法在预训练知识遗忘和顺序遗忘方面的局限性。

中文摘要: 近年来，遗忘技术作为一种使模型“忘记”先前学习信息的方法，因其在大型语言模型（LLMs）和多模态模型（LMMs）中解决隐私和版权问题的潜力而受到关注。尽管已为LLMs建立了多个遗忘基准，但针对LMMs的实用遗忘评估框架仍较少研究。具体而言，现有的LMMs遗忘基准仅考虑通过单次遗忘操作要求模型遗忘微调知识的场景。本研究通过引入两个关键视角，提出了PULSE协议以评估LMMs的现实遗忘场景：(i) 预训练知识遗忘，分析不同知识获取阶段的影响；(ii) 长期可持续性评估，处理顺序遗忘请求。随后，我们沿这些维度评估了现有遗忘方法。结果表明，尽管某些技术能成功遗忘微调知识，但在遗忘预训练知识时表现不佳。此外，单次批量遗忘有效的方法在顺序遗忘相同数据时性能显著下降。

</details>


### [193] [Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning](https://arxiv.org/abs/2507.01551)
**中文标题：基于掩码步骤优势的自引导过程奖励优化用于过程强化学习**

*Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SPRO的自引导过程奖励优化框架，通过内在策略模型推导过程奖励，并引入掩码步骤优势（MSA），显著提升了过程强化学习的训练效率和测试准确性，同时避免了额外计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 过程强化学习（PRL）在提升大型语言模型（LLMs）的推理能力方面潜力巨大，但现有方法存在计算开销高和缺乏统一理论框架的问题。本文旨在解决这些问题。

研究方法: 提出了SPRO框架，包括：（1）从策略模型本身推导过程奖励的理论证明；（2）定义累积过程奖励和掩码步骤优势（MSA），实现共享提示采样组内的严格步骤优势估计。

研究结果: 实验表明，SPRO的训练效率比GRPO高出3.4倍，测试准确率提升17.5%，同时保持较高的策略熵并减少响应长度约1/3，避免了奖励滥用。

研究结论: SPRO在不增加计算开销的情况下，显著提升了过程强化学习的性能，适用于工业实现。

中文摘要: 过程强化学习（PRL）在提升大型语言模型（LLMs）的推理能力方面展现出巨大潜力。然而，引入额外的过程奖励模型会带来显著的计算开销，且缺乏过程级优势估计的统一理论框架。为填补这一空白，我们提出了一种名为自引导过程奖励优化（SPRO）的新框架，通过两项关键创新实现过程感知的强化学习：（1）首次从理论上证明过程奖励可从策略模型本身推导；（2）引入定义良好的累积过程奖励和掩码步骤优势（MSA），在共享提示采样组内实现严格的步骤优势估计。实验结果表明，SPRO的训练效率比GRPO高出3.4倍，测试准确率提升17.5%。此外，SPRO在整个训练过程中保持稳定且较高的策略熵，同时将平均响应长度减少约1/3，证明了其充分的探索能力和对奖励滥用的预防。值得注意的是，与GRPO等结果监督的强化学习方法相比，SPRO未引入额外计算开销，有利于工业实现。

</details>


### [194] [Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling](https://arxiv.org/abs/2507.01679)
**中文标题：结合监督与强化微调的前缀采样方法**

*Zeyu Huang,Tianhao Cheng,Zihan Qiu,Zili Wang,Yinghui Xu,Edoardo M. Ponti,Ivan Titov*

主要分类: cs.LG

摘要简述: 本文提出了一种结合监督微调（SFT）和强化微调（RFT）的混合方法Prefix-RFT，通过统一学习演示和探索数据，显著提升语言模型的性能，并验证了其简单性和有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型语言模型后训练方法分为监督微调（SFT）和强化微调（RFT），两者各有优劣：SFT擅长模仿演示数据但可能泛化不佳，而RFT能显著提升性能但对初始策略敏感且可能学习意外行为。本文旨在提出一种统一方法，结合两者的优势。

研究方法: 提出Prefix-RFT方法，通过前缀采样将SFT和RFT结合，统一学习演示和探索数据。该方法简单易实现，仅需对标准RFT流程进行最小修改。

研究结果: 实验表明，Prefix-RFT在数学推理任务中表现优于单独的SFT和RFT，也优于并行混合策略RFT方法。消融研究验证了其对演示数据质量和数量的鲁棒性。

研究结论: Prefix-RFT有效结合了SFT和RFT的优势，为语言模型后训练提供了新视角，表明统一演示和探索的学习范式是未来研究的可行方向。

中文摘要: 现有的大型语言模型后训练技术主要分为监督微调（SFT）和强化微调（RFT）。这两种方法各有优缺点：SFT擅长模仿演示数据，但可能导致泛化问题；而RFT能显著提升模型性能，但容易学习意外行为且对初始策略敏感。本文提出了一种统一这两种方法的视角，并引入了Prefix-RFT，一种结合演示和探索学习的混合方法。以数学推理问题为测试平台，我们实证表明Prefix-RFT简单且有效，不仅超越了单独的SFT和RFT，还优于并行混合策略RFT方法。其关键优势在于能够无缝集成到现有开源框架中，仅需对标准RFT流程进行最小修改。我们的分析揭示了SFT和RFT的互补性，并验证了Prefix-RFT有效协调了这两种学习范式。此外，消融研究证实了该方法对演示数据质量和数量的鲁棒性。我们希望这项工作为LLM后训练提供新视角，表明统一演示和探索的学习范式可能是未来研究的有前景方向。

</details>


### [195] [Neural Hamiltonian Operator](https://arxiv.org/abs/2507.01313)
**中文标题：神经哈密顿算子**

*Qian Qi*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“神经哈密顿算子”（NHO）的深度学习框架，用于解决高维随机控制问题，通过神经网络参数化前向-后向随机微分方程（FBSDE）动力学，并利用庞特里亚金极大值原理（PMP）的一致性条件训练网络。


<details>
  <summary>详细信息</summary>
研究动机: 高维随机控制问题因维度灾难而难以解决，传统动态规划方法效率低下。本文旨在通过深度学习框架替代传统方法，利用庞特里亚金极大值原理（PMP）和FBSDE系统，提出一种更高效的解决方案。

研究方法: 本文定义了神经哈密顿算子（NHO），通过神经网络参数化FBSDE的耦合动力学，分别表示反馈控制和值函数空间梯度的近似。通过训练网络以强制PMP的一致性条件，找到最优NHO。

研究结果: 研究表明，NHO在一般鞅驱动下具有通用逼近能力，并通过统计推断的视角分析了此类模型的优化挑战。

研究结论: 神经哈密顿算子（NHO）为高维随机控制问题提供了一种基于深度学习的有效解决方案，同时为分析此类模型的优化问题提供了清晰的理论框架。

中文摘要: 高维随机控制问题因维度灾难而难以解决。庞特里亚金极大值原理（PMP）将问题转化为前向-后向随机微分方程（FBSDE）系统，为传统动态规划提供了一种替代方法。本文提出了一种深度学习框架，通过定义“神经哈密顿算子（NHO）”来解决此类问题。该算子通过神经网络参数化FBSDE的耦合动力学，分别表示反馈控制和值函数空间梯度的近似。我们展示了如何通过训练网络以强制PMP的一致性条件来找到最优NHO。通过这种算子理论视角，我们将深度FBSDE方法置于统计推断的严格语言中，将其视为从模拟数据中学习未知算子的问题。这一视角使我们能够证明NHO在一般鞅驱动下的通用逼近能力，并为分析此类模型固有的显著优化挑战提供了清晰的视角。

</details>


### [196] [ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks](https://arxiv.org/abs/2507.01321)
**中文标题：ICLShield：探索与缓解上下文学习中的后门攻击**

*Zhiyao Ren,Siyuan Liang,Aishan Liu,Dacheng Tao*

主要分类: cs.LG

摘要简述: 本文提出ICLShield防御机制，通过动态调整概念偏好比例，有效缓解大语言模型在上下文学习中的后门攻击问题，实验表明其防御效果显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 上下文学习（ICL）因其适应性和无需参数的特性在大语言模型中表现优异，但也引入了后门攻击的漏洞。攻击者可通过少量中毒演示操纵模型行为，亟需防御机制。

研究方法: 提出双重学习假设，认为模型同时学习任务相关和中毒演示中的后门概念。通过理论分析推导后门效应上界，设计ICLShield动态调整概念偏好比例，利用置信度和相似度分数选择干净演示。

研究结果: 实验表明，ICLShield在多种大语言模型和任务中表现优异，平均防御效果提升26.02%，且对闭源模型（如GPT-4）也具适应性。

研究结论: ICLShield通过动态调整概念偏好比例，显著提升大语言模型对后门攻击的防御能力，为上下文学习安全性提供了有效解决方案。

中文摘要: 上下文学习（ICL）因其适应性和无需参数的特性在大语言模型（LLM）中取得了显著成功。然而，它也引入了后门攻击的关键漏洞，攻击者仅需通过少量中毒演示即可操纵LLM行为。本文首次提出双重学习假设，认为LLM在中毒演示中同时学习任务相关潜在概念和后门潜在概念，共同影响模型输出的概率。通过理论分析，我们推导出ICL后门效应的上界，揭示漏洞主要由任务与后门的概念偏好比例决定。基于此，我们提出ICLShield防御机制，动态调整概念偏好比例。该方法通过置信度和相似度分数鼓励LLM在ICL阶段选择干净演示，有效缓解后门攻击的脆弱性。在多种LLM和任务上的广泛实验表明，我们的方法实现了最先进的防御效果，显著优于现有方法（平均提升26.02%）。此外，即使对闭源模型（如GPT-4），我们的方法也表现出卓越的适应性和防御性能。

</details>


### [197] [Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training](https://arxiv.org/abs/2507.01752)
**中文标题：无需窥探的调优：LLM后训练的可证明隐私与泛化界限**

*Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud*

主要分类: cs.LG

摘要简述: 本文提出了一种名为BBoxER的黑盒优化方法，用于大型语言模型（LLM）的后训练，通过隐式压缩训练数据引入信息瓶颈，提供了泛化、差分隐私、抗数据中毒攻击和抗提取攻击的理论保证。实验表明，BBoxER在推理数据集上表现优异，是一种轻量级且模块化的增强方法。


<details>
  <summary>详细信息</summary>
研究动机: 梯度优化在深度学习中被广泛使用，但其依赖大量标注数据，存在隐私和安全问题（如数据中毒攻击和过拟合风险）。黑盒优化方法在数据受限或对抗风险高时具有潜力，但面临高维参数空间和计算成本高的挑战。本文旨在解决这些问题。

研究方法: 提出BBoxER，一种基于进化的黑盒优化方法，通过隐式压缩训练数据引入信息瓶颈，利用信息流的可追踪性，提供泛化、隐私和鲁棒性的理论保证。BBoxER适用于预训练LLM的后训练，轻量且模块化。

研究结果: 实验表明，BBoxER在推理数据集上表现优异，仅需少量迭代即可提升性能并实现良好的泛化。其理论保证包括差分隐私、抗数据中毒攻击和抗提取攻击。

研究结论: BBoxER是一种高效的黑盒优化方法，适用于隐私敏感环境，为LLM后训练提供了理论保证和实际性能提升，是梯度优化的有力补充。

中文摘要: 梯度优化是深度学习的核心方法，通过反向传播实现高效且可扩展的训练。然而，其对大量标注数据的依赖引发了隐私和安全问题，如易受数据中毒攻击和过拟合风险。相比之下，黑盒优化方法将模型视为不透明函数，仅依赖函数评估指导优化，在数据受限、对抗风险高或过拟合问题突出时具有潜力。然而，黑盒方法也面临重大挑战，包括在高维参数空间（如大型语言模型）中的扩展性差，以及依赖大量模型评估导致的高计算成本。本文提出BBoxER，一种用于LLM后训练的进化黑盒方法，通过隐式压缩训练数据引入信息瓶颈。利用信息流的可追踪性，我们提供了关于泛化、差分隐私、数据中毒攻击易感性和抗提取攻击的强理论界限。BBoxER在预训练LLM基础上运行，提供轻量级且模块化的增强，适合部署在受限或隐私敏感环境中，并提供非平凡的泛化保证。在LLM实验中，我们实证表明，BBoxER仅需少量迭代即可提升性能，并在推理数据集上表现优异。这使BBoxER成为梯度优化的有力补充。

</details>


### [198] [Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy](https://arxiv.org/abs/2507.01327)
**中文标题：面向真实世界事件检测的推理器：通过自适应困惑感知采样策略扩展强化学习**

*Xiaoyun Zhang,Jingqing Ruan,Xing Ma,Yawen Zhu,Jiansong Chen,Ke Zeng,Xunliang Cai*

主要分类: cs.LG

摘要简述: 本文提出了一种名为APARL的自适应困惑感知强化学习框架，用于检测客户服务对话中的异常事件。通过双环动态课程学习架构，模型逐步专注于更具挑战性的样本，显著提升了模型的适应性和鲁棒性，在食品配送对话任务中取得了显著的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 由于商业数据的复杂性和客户互动的动态性，检测客户服务对话中的异常事件极具挑战性。此外，模型需要具备强大的跨领域泛化能力，以适应不同业务场景并最大化商业价值。

研究方法: 本文提出了一种自适应困惑感知强化学习（APARL）框架，利用大型语言模型的高级推理能力进行异常事件检测。APARL采用双环动态课程学习架构，使模型能够随着熟练度的提升逐步专注于更具挑战性的样本。

研究结果: 在食品配送对话任务上的广泛评估表明，APARL显著提升了模型的适应性和鲁棒性，F1分数平均提高了17.19%，跨领域迁移测试中平均提高了9.59%。

研究结论: APARL为异常检测模型的工业部署提供了优越的解决方案，有助于提升运营效率和商业效益。

中文摘要: 在真实客户服务对话中检测异常事件极具挑战性，原因在于商业数据的复杂性和客户互动的动态性。此外，模型需具备强大的跨领域（OOD）泛化能力，以快速适应不同业务场景并最大化商业价值。本文提出了一种新颖的自适应困惑感知强化学习（APARL）框架，利用大型语言模型的高级推理能力进行异常事件检测。APARL引入了一种双环动态课程学习架构，使模型能够随着熟练度的提升逐步专注于更具挑战性的样本。这一设计有效解决了性能瓶颈，并显著提升了跨领域迁移能力。在食品配送对话任务上的广泛评估表明，我们的模型显著提升了适应性和鲁棒性，F1分数平均提高了17.19%，跨领域迁移测试中平均提高了9.59%。该方法为异常检测模型的工业部署提供了优越的解决方案，有助于提升运营效率和商业效益。

</details>


### [199] [LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs](https://arxiv.org/abs/2507.01806)
**中文标题：无需GPU的LoRA微调：一种面向LLM的CPU高效元生成框架**

*Reza Arabpour,Haitz Sáez de Ocáriz Borde,Anastasis Kratsios*

主要分类: cs.LG

摘要简述: 本文提出了一种基于CPU的低秩适配器（LoRA）微调方法，通过预训练适配器库生成新适配器，无需GPU即可实现高效微调，虽性能略逊于GPU训练，但显著优于基础模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前LoRA微调依赖GPU，限制了资源有限用户的使用。本文旨在为仅能使用CPU的用户提供一种高效的LoRA微调替代方案。

研究方法: 提出一种元生成框架，通过学习元操作符将输入数据集映射到预训练适配器库中的权重组合，直接在CPU上生成新适配器，避免梯度更新。

研究结果: 生成的适配器性能虽不及GPU训练版本，但在下游任务中始终优于基础Mistral模型，为资源受限用户提供了实用选择。

研究结论: 该方法为CPU用户提供了一种可行的LoRA微调替代方案，显著降低了计算资源需求，推动了LoRA技术的普及。

中文摘要: 低秩适配器（LoRAs）通过实现参数高效更新，彻底改变了大型语言模型（LLMs）的微调方式。然而，其对GPU训练的依赖限制了其广泛应用。本文提出了一种理论支持的LoRA微调方法，专为计算资源有限的用户设计，尤其是仅能使用标准笔记本电脑CPU的用户。我们的方法通过学习一个元操作符，将任何输入数据集（表示为概率分布）映射到一组LoRA权重，利用Mistral-7B-Instruct-v0.2模型的预训练适配器库。无需进行新的梯度更新，我们的流程直接在CPU上通过现有LoRA的轻量级组合构建适配器。虽然生成的适配器性能不及GPU训练版本，但它们在下游任务中始终优于基础Mistral模型，为传统GPU微调提供了一种实用且易获取的替代方案。

</details>


### [200] [Test-Time Scaling with Reflective Generative Model](https://arxiv.org/abs/2507.01951)
**中文标题：基于反射生成模型的测试时间缩放**

*Zixiao Wang,Yuxin Wang,Xiaorui Wang,Mengting Xing,Jie Gao,Jianjun Xu,Guangcan Liu,Chenhui Jin,Zhuo Wang,Shengzhuo Zhang,Hongtao Xie*

主要分类: cs.LG

摘要简述: 本文提出首个反射生成模型MetaStone-S1，通过自监督过程奖励模型（SPRM）实现与OpenAI o3相当的性能。SPRM通过共享主干网络和任务特定头，将策略模型和过程奖励模型整合为统一接口，减少99%的参数，并支持测试时间缩放（TTS）。实验表明，32B参数的MetaStone-S1性能媲美OpenAI-o3-mini系列。


<details>
  <summary>详细信息</summary>
研究动机: 当前生成模型在性能和效率之间存在权衡，尤其是过程奖励模型（PRM）需要大量参数和标注。本文旨在通过自监督方法减少PRM参数，同时保持高性能，并探索测试时间缩放（TTS）的潜力。

研究方法: 提出自监督过程奖励模型（SPRM），共享主干网络，分别使用任务特定头进行下一令牌预测和过程评分。SPRM将策略模型和PRM整合为统一接口，无需额外标注，显著减少参数。MetaStone-S1支持三种推理模式（低、中、高），基于可控的思考长度。

研究结果: 实验表明，32B参数的MetaStone-S1性能与OpenAI-o3-mini系列相当。SPRM减少99%的PRM参数，同时支持高效的测试时间缩放（TTS）。

研究结论: MetaStone-S1通过SPRM实现了高效且高性能的生成模型，为测试时间缩放提供了新思路。模型已开源，支持研究社区进一步探索。

中文摘要: 我们介绍了首个反射生成模型MetaStone-S1，它通过自监督过程奖励模型（SPRM）实现了与OpenAI o3相当的性能。通过共享主干网络并分别使用任务特定头进行下一令牌预测和过程评分，SPRM成功将策略模型和过程奖励模型（PRM）整合为统一接口，无需额外过程标注，减少了99%以上的PRM参数以实现高效推理。配备SPRM的MetaStone-S1天然适合测试时间缩放（TTS），我们提供了三种推理努力模式（低、中、高），基于可控的思考长度。此外，我们通过实验建立了一个缩放定律，揭示了总思考计算与TTS性能之间的关系。实验表明，我们的MetaStone-S1仅以32B参数规模就实现了与OpenAI-o3-mini系列相当的性能。为支持研究社区，我们已将MetaStone-S1开源，地址为https://github.com/MetaStone-AI/MetaStone-S1。

</details>


### [201] [Distributional Soft Actor-Critic with Diffusion Policy](https://arxiv.org/abs/2507.01381)
**中文标题：基于扩散策略的分布软演员-评论家算法**

*Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DSAC-D的分布强化学习算法，通过引入扩散策略和价值分布函数，解决了价值函数估计偏差和多模态策略表示的挑战，并在MuJoCo任务中实现了SOTA性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习方法通常使用单模态分布（如高斯分布）建模价值分布输出，容易导致价值函数估计偏差，影响算法性能。本文旨在解决这一问题，并提出一种能够表征多模态策略的算法。

研究方法: 通过引入策略熵和价值分布函数，建立了一个能够收敛到最优策略的多模态分布策略迭代框架。利用扩散模型的反向采样生成奖励样本，构建了能够准确表征多峰分布的扩散价值网络，并在此基础上推导出价值网络和策略网络双重扩散的分布强化学习算法。

研究结果: 在MuJoCo测试任务中，DSAC-D不仅学习了多模态策略，还在所有9个控制任务中实现了SOTA性能，显著抑制了估计偏差，总平均回报比现有主流算法提高了10%以上。真实车辆测试结果表明，DSAC-D能够准确表征不同驾驶风格的多模态分布。

研究结论: DSAC-D算法通过扩散策略和价值网络的双重扩散，有效解决了价值函数估计偏差问题，并实现了多模态策略的高效学习，为复杂控制任务提供了新的解决方案。

中文摘要: 强化学习在处理复杂控制任务中已被证明非常有效。传统方法通常使用单模态分布（如高斯分布）建模价值分布输出，但单模态分布容易导致价值函数估计偏差，从而影响算法性能。本文提出了一种名为DSAC-D（基于扩散策略的分布软演员-评论家算法）的分布强化学习算法，以解决价值函数估计偏差和多模态策略表示的挑战。通过引入策略熵和价值分布函数，建立了一个能够收敛到最优策略的多模态分布策略迭代框架。利用扩散模型的反向采样生成奖励样本，构建了能够准确表征多峰分布的扩散价值网络。在此基础上，推导出价值网络和策略网络双重扩散的分布强化学习算法。MuJoCo测试任务表明，该算法不仅学习了多模态策略，还在所有9个控制任务中实现了SOTA性能，显著抑制了估计偏差，总平均回报比现有主流算法提高了10%以上。真实车辆测试结果表明，DSAC-D能够准确表征不同驾驶风格的多模态分布，扩散策略网络能够表征多模态轨迹。

</details>


### [202] [Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs](https://arxiv.org/abs/2507.01457)
**中文标题：基于概率程序的RISC-V向量扩展张量程序优化**

*Federico Nicolas Peccia,Frederik Haxel,Oliver Bringmann*

主要分类: cs.LG

摘要简述: 本文提出了一种基于TVM编译器的工作流程，通过整合RISC-V向量扩展（RVV）到MetaSchedule框架中，优化AI工作负载在RISC-V向量单元上的部署。实验表明，该方法比GCC自动向量化和muRISCV-NN分别提升了46%和29%的执行效率，且代码内存占用更小。


<details>
  <summary>详细信息</summary>
研究动机: RISC-V向量扩展（RVV）为AI工作负载加速提供了潜力，但缺乏高效的自动优化工具。现有方法如编译器自动向量化或手动优化库（如muRISCV-NN）效率有限，且缺乏与RVV的集成。本文旨在填补这一空白，提供更高效的优化方案。

研究方法: 将RVV扩展整合到TVM的MetaSchedule框架中，利用概率程序框架对张量操作进行调优。在FPGA上实现多种RISC-V SoC，并对多种AI工作负载进行优化测试。

研究结果: 与GCC自动向量化相比，执行延迟平均降低46%；与muRISCV-NN相比，降低29%。生成的二进制文件代码内存占用更小，适合嵌入式设备。在商用RISC-V SoC上，优化后的映射比LLVM快35%。

研究结论: 本文提出的方法显著提升了RISC-V向量单元上AI工作负载的执行效率，且代码体积更小。开源实现为社区扩展其他RISC-V扩展提供了基础。

中文摘要: RISC-V为从嵌入式设备到高性能计算集群的应用提供了灵活且可扩展的平台，尤其是其向量扩展（RVV）对AI工作负载加速具有重要意义。然而，缺乏专家知识的程序员通常依赖编译器的自动向量化功能或手动优化库（如muRISCV-NN）来高效利用RISC-V CPU的向量单元。更智能的方法（如自动调优框架）尚未与RVV扩展集成，严重限制了复杂AI工作负载的高效部署。本文提出了一种基于TVM编译器的工作流程，通过将RVV扩展整合到TVM的MetaSchedule框架（一种用于张量操作调优的概率程序框架）中，高效映射AI工作负载到RISC-V向量单元。我们在FPGA上实现了多种RISC-V SoC，并对多种AI工作负载进行了调优。实验表明，与GCC的自动向量化功能相比，我们的方案平均提升了46%的执行延迟；与muRISCV-NN相比，提升了29%。此外，生成的二进制文件代码内存占用更小，更适合嵌入式设备。最后，我们在商用RISC-V SoC（支持RVV 1.0向量扩展）上评估了该方案，发现其优化的映射比LLVM平均快35%。我们开源了该方案，供社区扩展以支持其他RISC-V扩展。

</details>


### [203] [Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals](https://arxiv.org/abs/2507.01470)
**中文标题：零激励动态：通过未奖励子目标的视角审视奖励稀疏性**

*Yannick Molinghen,Tom Lenaerts*

主要分类: cs.LG

摘要简述: 本文重新审视了强化学习中奖励频率与任务难度相关的常见假设，揭示了当前策略学习方法在未奖励子目标情况下的局限性，并提出了零激励动态的概念。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于挑战强化学习中奖励频率作为任务难度衡量标准的普遍假设，探讨未直接奖励的关键子目标对学习效果的影响。

研究方法: 方法包括形式化零激励动态的概念，分析现有深度子目标算法在处理未奖励子目标时的表现，并研究子目标完成与最终奖励时间接近性对学习性能的敏感性。

研究结果: 结果表明，当前最先进的子目标算法无法有效利用零激励动态，且学习性能高度依赖于子目标完成与奖励之间的时间接近性。

研究结论: 结论指出当前方法存在根本性局限，需要开发能够推断潜在任务结构而不依赖即时奖励的机制。

中文摘要: 本研究重新审视了强化学习中奖励频率作为任务难度可靠指标的常见假设。我们发现并形式化了一个结构性挑战，该挑战削弱了当前策略学习方法的有效性：当关键子目标未直接产生奖励时。我们将此类情境描述为零激励动态，即对成功至关重要的过渡未得到奖励。研究表明，当前最先进的基于深度子目标的算法无法利用这些动态，且学习性能对子目标完成与最终奖励之间的时间接近性高度敏感。这些发现揭示了当前方法的根本局限性，并指出需要开发能够在不依赖即时激励的情况下推断潜在任务结构的机制。

</details>


### [204] [Chargax: A JAX Accelerated EV Charging Simulator](https://arxiv.org/abs/2507.01522)
**中文标题：Chargax：基于JAX加速的电动汽车充电模拟器**

*Koen Ponse,Jan Felix Kleuker,Aske Plaat,Thomas Moerland*

主要分类: cs.LG

摘要简述: 本文介绍了Chargax，一个基于JAX的电动汽车充电站模拟器，旨在加速强化学习代理的训练。相比现有环境，Chargax实现了100-1000倍的计算性能提升，并支持多样化的真实充电站配置。


<details>
  <summary>详细信息</summary>
研究动机: 当前电网系统拥堵严重，亟需提高运营效率。尽管深度强化学习在可持续能源领域具有潜力，但其训练过程因样本复杂性和模拟成本高昂而缓慢。现有基于GPU加速的方法多集中于经典玩具问题，缺乏对实际场景的支持。

研究方法: 本文提出Chargax，一个基于JAX的电动汽车充电站模拟环境。通过JAX加速数据生成，支持多样化的真实充电站配置，并验证了其在多种真实数据场景下的性能。

研究结果: Chargax在计算性能上比现有环境提升了100-1000倍，同时其模块化架构能够灵活表示多种真实充电站配置。

研究结论: Chargax为强化学习在电动汽车充电领域的应用提供了高效的模拟环境，显著提升了训练速度，并支持实际场景的多样化需求。

中文摘要: 深度强化学习在应对可持续能源挑战中具有重要作用。例如，许多电网系统严重拥堵，亟需提高运营效率。然而，强化学习方法因样本复杂性和模拟成本高昂而进展缓慢。尽管近期研究通过将环境转换为JAX，利用GPU加速数据生成，但这些研究多集中于经典玩具问题。本文介绍了Chargax，一个基于JAX的电动汽车充电站模拟环境，旨在加速强化学习代理的训练。我们基于真实数据在多种场景中验证了该环境，并将强化学习代理与基线方法进行了比较。Chargax的计算性能比现有环境提升了100-1000倍。此外，其模块化架构支持多样化的真实充电站配置。

</details>


### [205] [GradMetaNet: An Equivariant Architecture for Learning on Gradients](https://arxiv.org/abs/2507.01649)
**中文标题：GradMetaNet：一种用于梯度学习的等变架构**

*Yoav Gelberg,Yam Eitan,Aviv Navon,Aviv Shamsian,Theo,Putterman,Michael Bronstein,Haggai Maron*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GradMetaNet的新型架构，专门用于处理神经网络梯度，通过等变性设计、多数据点梯度集处理和高效梯度表示，提升了梯度学习任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 神经网络的梯度包含优化、编辑和分析模型的重要信息，但现有方法未针对梯度处理设计专门架构，限制了其应用。本文旨在填补这一空白。

研究方法: 基于三个原则设计GradMetaNet：1）保持神经元置换对称性的等变性设计；2）通过多数据点梯度集捕捉曲率信息；3）利用秩-1分解实现高效梯度表示。

研究结果: GradMetaNet在MLP和Transformer上的多种梯度任务（如优化、编辑和曲率估计）中表现优异，且能逼近其他方法无法实现的自然梯度函数。

研究结论: GradMetaNet为梯度学习任务提供了一种高效且通用的架构，填补了现有方法的不足，并在实验中验证了其优越性。

中文摘要: 神经网络的梯度为模型的优化、编辑和分析提供了宝贵信息，因此梯度常被用作特定任务算法的输入（如剪枝或优化）。近期研究探索了直接操作梯度的学习算法，但这些算法未针对梯度处理设计专门架构，限制了其适用性。本文提出了一种设计梯度处理架构的原则性方法，基于三个原则：1）保持神经元置换对称性的等变性设计；2）通过多数据点梯度集捕捉曲率信息；3）利用秩-1分解实现高效梯度表示。基于这些原则，我们提出了GradMetaNet，一种由简单等变模块构建的新型梯度学习架构。我们证明了GradMetaNet的普适性，并表明先前方法无法逼近GradMetaNet能处理的自然梯度函数。最后，我们在MLP和Transformer上的多种梯度任务（如学习优化、INR编辑和损失景观曲率估计）中验证了GradMetaNet的有效性。

</details>


### [206] [AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training](https://arxiv.org/abs/2507.01663)
**中文标题：AsyncFlow：一种用于高效LLM后训练的异步流式强化学习框架**

*Zhenyu Han,Ansheng You,Haibo Wang,Kui Luo,Guang Yang,Wenqi Shi,Menglong Chen,Sicheng Zhang,Zeshun Lan,Chunshi Deng,Huazhong Ji,Wenjie Liu,Yu Huang,Yixiang Zhang,Chenyi Pan,Jing Wang,Xin Huang,Chunsheng Li,Jianping Wu*

主要分类: cs.LG

摘要简述: AsyncFlow是一个异步流式强化学习框架，用于高效的大型语言模型（LLM）后训练，解决了传统框架的可扩展性和资源闲置问题，并通过模块化设计支持自定义引擎。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习框架在大型语言模型后训练中存在可扩展性瓶颈、复杂数据流问题以及资源闲置和工作负载不平衡的挑战，且与训练或推理引擎紧密耦合，难以支持自定义设计。

研究方法: 提出AsyncFlow框架，包括分布式数据存储与传输模块，支持统一数据管理和细粒度调度；采用生产者-消费者异步工作流，延迟参数更新以减少计算闲置；并通过服务化接口实现模块化设计。

研究结果: 实验表明，AsyncFlow相比现有基线平均提升1.59倍的吞吐量，同时提供了动态负载均衡和自动化流水线重叠的能力。

研究结论: AsyncFlow为下一代强化学习训练系统设计提供了可操作的见解，其模块化和异步流式架构显著提升了效率和灵活性。

中文摘要: 强化学习（RL）已成为大型语言模型（LLM）后训练阶段的关键技术。传统的任务共置RL框架存在显著的可扩展性瓶颈，而任务分离的RL框架则面临复杂数据流及相应的资源闲置和工作负载不平衡问题。此外，大多数现有框架与LLM训练或推理引擎紧密耦合，难以支持自定义设计的引擎。为解决这些问题，我们提出了AsyncFlow，一种用于高效后训练的异步流式RL框架。具体而言，我们引入了一个分布式数据存储与传输模块，以完全流式的方式提供统一的数据管理和细粒度调度能力。该架构天然促进了RL任务间的自动化流水线重叠和动态负载均衡。此外，我们提出了一种基于生产者-消费者的异步工作流，通过策略性地延迟参数更新过程以减少计算闲置。最后，AsyncFlow的核心能力在架构上与底层训练和推理引擎解耦，并通过面向服务的用户接口封装，提供了模块化和可定制的用户体验。大量实验表明，相比现有基线，AsyncFlow平均提升了1.59倍的吞吐量。本文提出的架构为下一代RL训练系统设计提供了可操作的见解。

</details>


### [207] [Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models](https://arxiv.org/abs/2507.01201)
**中文标题：逃离柏拉图的洞穴：用于对齐独立训练的视觉和语言模型的JAM框架**

*Hyoseo,Yoon,Yisong Yue,Been Kim*

主要分类: cs.LG

摘要简述: 本文提出了一种名为JAM的框架，用于对齐独立训练的视觉和语言模型，通过多目标优化实现模态间的一致性，并验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 独立训练的视觉和语言模型存在于不同的表示空间中，但可能共享对现实的统计模型。本文旨在探索如何显式优化这种对齐，而不仅仅是事后统计检测。

研究方法: 提出了联合自动编码调制器（JAM）框架，通过训练模态特定的自动编码器，结合重构和跨模态目标，实现对齐。研究了三种对齐目标（对比损失、硬负样本对比损失和Spread损失）、对齐层深度以及基础模型规模的影响。

研究结果: 实验表明，JAM框架能够有效诱导对齐，即使是在冻结的独立训练表示上，为将通用单模态基础模型转化为专业多模态模型提供了理论和实践路径。

研究结论: JAM框架为对齐独立训练的视觉和语言模型提供了一种轻量级且高效的方法，展示了跨模态共享结构的潜力。

中文摘要: 独立训练的视觉和语言模型存在于不同的表示空间中，这些空间由其各自的模态、目标和架构塑造。然而，一种新兴的假设——柏拉图表示假设——认为这些模型可能仍然会趋近于对现实的共享统计模型。如果这种兼容性存在，它将引发一个基本问题：我们能否超越事后统计检测对齐，而显式优化这种不相关表示之间的对齐？我们将这一柏拉图对齐问题表述为一个多目标优化任务——在保持每个模态原生结构的同时，对齐以实现相互一致性。我们引入了联合自动编码调制器（JAM）框架，该框架在预训练的单模态模型的潜在表示上联合训练模态特定的自动编码器，通过重构和跨模态目标鼓励对齐。类比而言，这一框架是一种逃离柏拉图洞穴的方法，使得从不相交的输入中涌现出共享结构。我们在三个关键设计轴上评估了这一框架：（i）对齐目标——比较对比损失（Con）、其硬负样本变体（NegCon）和我们的Spread损失；（ii）对齐最有效的层深度；（iii）基础模型规模对表示收敛的影响。我们的研究结果表明，这种轻量级的帕累托高效框架能够可靠地诱导对齐，即使是在冻结的独立训练表示上，为将通用单模态基础模型转化为专业多模态模型提供了理论洞见和实践路径。

</details>


### [208] [GPT, But Backwards: Exactly Inverting Language Model Outputs](https://arxiv.org/abs/2507.01693)
**中文标题：GPT，但反向：精确反转语言模型输出**

*Adrians Skapars,Edoardo Manino,Youcheng Sun,Lucas C. Cordeiro*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SODA的高效梯度算法，用于从大型语言模型（LLM）的输出中精确重建输入，解决了现有审计技术无法实现的输入重构问题。实验表明，SODA在短输入上表现优异，但对长输入的保护效果仍存挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有审计技术主要用于识别大型语言模型（LLM）的不当行为，但缺乏从输出中精确重建输入的能力。本文旨在解决这一问题，为事后分析和检测虚假输出提供技术支持。

研究方法: 本文提出SODA算法，将输入重构问题形式化为离散优化问题，并通过梯度算法在连续松弛的输入搜索空间中进行求解，结合周期性重启和参数衰减策略提高效率。

研究结果: 实验表明，SODA在33M至3B参数的LLM上显著优于现有方法，成功恢复了79.5%的短输入，但对15+ token的长输入隐私信息提取效果不佳。

研究结论: 标准部署实践可能已对恶意使用SODA提供了足够保护，但长输入的保护仍需改进。

中文摘要: 现有的审计技术试图识别大型语言模型（LLM）中的潜在不良行为，而我们则解决了与之互补的法证问题：从现有LLM输出中精确重建输入，以支持事后分析和检测虚假输出报告。我们将精确输入重构形式化为一个具有唯一全局最小值的离散优化问题，并提出了SODA算法，这是一种高效的基于梯度的算法，通过在连续松弛的输入搜索空间中操作，并结合周期性重启和参数衰减。在参数规模从33M到3B的LLM上进行全面实验后，我们发现SODA显著优于现有方法。我们成功地从下一个标记的对数概率中完全恢复了79.5%的短输入（超出分布范围），且无一假阳性，但在提取较长（15+标记）输入序列的隐私信息时表现不佳。这表明，标准的部署实践可能已为防范恶意使用我们的方法提供了足够的保护。代码发布于https://doi.org/10.5281/zenodo.15539879。

</details>


### [209] [Relational Causal Discovery with Latent Confounders](https://arxiv.org/abs/2507.01700)
**中文标题：带有潜在混杂变量的关系因果发现**

*Andrea Piras,Matteo Negro,Ragib Ahsan,David Arbour,Elena Zheleva*

主要分类: cs.LG

摘要简述: 本文提出了一种名为RelFCI的算法，用于解决关系数据中存在潜在混杂变量的因果发现问题，结合了FCI和RCD算法的优势，并提出了新的图模型。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的关系数据通常存在潜在混杂变量，而现有因果发现算法要么假设数据独立同分布，要么假设因果充分性，无法有效处理此类问题。

研究方法: RelFCI算法结合了Fast Causal Inference (FCI)和Relational Causal Discovery (RCD)算法，定义了新的图模型以支持关系数据中的因果发现，并建立了关系d-分离的完备性和正确性保证。

研究结果: 实验结果表明，RelFCI能够有效识别带有潜在混杂变量的关系因果模型中的正确因果结构。

研究结论: RelFCI为关系数据中潜在混杂变量的因果发现提供了一种可靠且完备的解决方案。

中文摘要: 从现实世界的关系数据中估计因果效应具有挑战性，尤其是当潜在因果模型和混杂变量未知时。现有的因果发现算法要么假设数据独立同分布（i.i.d.），要么假设因果充分性，无法适用于关系数据。为解决这一问题，我们提出了RelFCI算法，这是一种针对带有潜在混杂变量的关系数据的完备因果发现算法。我们的工作基于Fast Causal Inference (FCI)和Relational Causal Discovery (RCD)算法，并定义了新的图模型以支持关系领域中的因果发现。我们还建立了关系d-分离在潜在混杂变量下的完备性和正确性保证。实验结果表明，RelFCI能够有效识别带有潜在混杂变量的关系因果模型中的正确因果结构。

</details>


### [210] [How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks](https://arxiv.org/abs/2507.01559)
**中文标题：权重重采样与优化器如何塑造神经网络中持续学习与遗忘的动态**

*Lapo Frati,Neil Traft,Jeff Clune,Nick Cheney*

主要分类: cs.LG

摘要简述: 研究探讨了神经网络中权重重采样（zapping）和优化器选择如何影响持续学习和遗忘的动态，发现zapping能加速模型在新领域的恢复，且优化器选择对任务间学习与遗忘的交互模式有深远影响。


<details>
  <summary>详细信息</summary>
研究动机: 尽管权重重采样（zapping）在持续学习中表现出显著效果，但其背后的机制尚不明确。本文旨在揭示zapping和优化器如何影响神经网络在持续学习和少样本迁移学习中的动态行为。

研究方法: 通过在卷积神经网络中应用zapping，并在手写字符和自然图像的持续学习和少样本迁移学习任务中进行实验，研究学习与遗忘的动态模式，并分析不同优化器对任务间交互的影响。

研究结果: 实验表明，zapping能帮助模型更快适应新领域；同时，优化器的选择会显著改变任务间的学习与遗忘模式，导致复杂的协同或干扰现象。

研究结论: 权重重采样和优化器选择是影响持续学习动态的关键因素，zapping能提升模型适应性，而优化器选择则决定了任务间的交互模式。

中文摘要: 近期持续学习研究表明，对神经网络最后一层权重进行重采样（“zapping”）具有显著效果，但其作用机制尚不明确。本文详细研究了卷积神经网络在手写字符和自然图像的持续学习及少样本迁移学习中的学习与遗忘模式。实验表明，经过zapping训练的模型能更快适应新领域。此外，为观察多任务设置中持续学习的效果，我们测量了每个任务的影响，发现不仅zapping，优化器的选择也会深刻影响学习与遗忘的动态，导致任务间在迁移学习时出现复杂的协同或干扰模式。

</details>


### [211] [Enhanced Generative Model Evaluation with Clipped Density and Coverage](https://arxiv.org/abs/2507.01761)
**中文标题：基于截断密度和覆盖率的增强生成模型评估**

*Nicolas Salvy,Hugues Talbot,Bertrand Thirion*

主要分类: cs.LG

摘要简述: 本文提出两种新指标——截断密度和截断覆盖率，用于评估生成模型的质量，解决了现有指标在鲁棒性和可解释性上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 生成模型在关键应用中的使用受到样本质量评估不可靠的限制，现有指标因缺乏校准或对异常值不够鲁棒而难以提供可靠、可解释的结果。

研究方法: 通过截断单个样本贡献和最近邻球的半径，提出截断密度和截断覆盖率两种新指标，防止分布外样本影响聚合值，并通过分析和实验校准使其得分随劣质样本比例线性下降。

研究结果: 在合成和真实数据集上的实验表明，截断密度和截断覆盖率在鲁棒性、敏感性和可解释性上优于现有方法。

研究结论: 新指标为生成模型评估提供了更可靠、直观的工具，推动了生成模型在关键领域的应用。

中文摘要: 尽管生成模型近年来取得了显著进展，但由于无法可靠评估样本质量，其在关键应用中的使用受到限制。质量至少涉及两个互补概念：保真度和覆盖率。当前的质量指标由于缺乏校准或对异常值不够鲁棒，往往难以提供可靠、可解释的值。为解决这些问题，我们引入了两种新指标：截断密度和截断覆盖率。通过截断单个样本贡献以及保真度中最近邻球的半径，我们的指标防止了分布外样本对聚合值的偏差。通过分析和实验校准，这些指标在劣质样本比例增加时表现出线性得分下降，因此可以直观地解释为等效的优质样本比例。在合成和真实数据集上的大量实验表明，截断密度和截断覆盖率在评估生成模型时，在鲁棒性、敏感性和可解释性上优于现有方法。

</details>


### [212] [BranchNet: A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification](https://arxiv.org/abs/2507.01781)
**中文标题：BranchNet：一种面向结构化多类分类的神经符号学习框架**

*Dalia Rodríguez-Salas,Christian Riess*

主要分类: cs.LG

摘要简述: BranchNet是一种神经符号学习框架，将决策树集成转化为稀疏、部分连接的神经网络，保留符号结构的同时支持梯度优化，在多类分类任务中表现优于XGBoost。


<details>
  <summary>详细信息</summary>
研究动机: 传统决策树集成方法缺乏梯度优化能力，且模型结构复杂。BranchNet旨在通过神经符号框架结合决策树的符号化结构与神经网络的优化能力，提升分类性能并保持可解释性。

研究方法: BranchNet将决策树的每条路径映射为神经网络的隐藏神经元，形成稀疏连接结构。通过梯度优化训练模型，无需手动调整架构。

研究结果: 在多类分类基准测试中，BranchNet的准确率显著优于XGBoost，模型紧凑且可解释。但在二元任务中仍需进一步校准优化。

研究结论: BranchNet成功结合了符号化结构与神经网络优化能力，在多类分类中表现优异，未来可针对二元任务改进适应性校准。

中文摘要: 我们提出了BranchNet，一种神经符号学习框架，将决策树集成转化为稀疏、部分连接的神经网络。每条从根节点到叶子父节点的决策路径被映射为一个隐藏神经元，保留了符号结构的同时支持基于梯度的优化。生成的模型紧凑、可解释，且无需手动调整架构。在一系列结构化多类分类基准测试中，BranchNet的准确率始终优于XGBoost，且具有统计显著性提升。我们详细介绍了其架构、训练过程和稀疏性动态，并讨论了模型在符号可解释性方面的优势及其当前局限性，尤其是在二元任务中可能需要进一步的自适应校准。

</details>


### [213] [MILP-SAT-GNN: Yet Another Neural SAT Solver](https://arxiv.org/abs/2507.01825)
**中文标题：MILP-SAT-GNN：另一种基于神经网络的SAT求解器**

*Franco Alberto Cardillo,Hamza Khyari,Umberto Straccia*

主要分类: cs.LG

摘要简述: 本文提出了一种新方法MILP-SAT-GNN，通过将k-CNF公式映射为MILP问题，再编码为加权二分图输入GNN，实现SAT问题的求解。理论证明了方法的排列和等价不变性，同时揭示了标准GNN对可折叠公式的局限性。实验表明，该方法在简单神经网络架构下取得了有希望的结果。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索如何利用图神经网络（GNN）解决SAT问题，特别是通过借鉴混合整数线性规划（MILP）的技术，以提升GNN在逻辑问题求解中的表现。

研究方法: 方法包括将k-CNF公式转化为MILP问题，进一步编码为加权二分图，输入GNN进行训练和测试。理论部分证明了方法的排列和等价不变性，并分析了标准GNN对可折叠公式的局限性。

研究结果: 理论结果表明，该方法在有限数据集上能够通过随机节点初始化（RNI）实现任意精度的SAT求解近似。实验验证了该方法在简单神经网络架构下的有效性。

研究结论: 结论表明，MILP-SAT-GNN方法在理论上具有稳定性和近似能力，实验验证了其潜力，尽管神经网络架构简单，但结果令人鼓舞。

中文摘要: 本文提出了一种新方法，使图神经网络（GNN）能够通过借鉴混合整数线性规划（MILP）的技术解决SAT问题。具体而言，k-CNF公式被映射为MILP问题，随后编码为加权二分图并输入GNN进行训练和测试。从理论角度看：（i）我们证明了排列和等价不变性，表明该方法在条款和变量重排序下输出稳定；（ii）我们发现了一个理论限制，即对于一类称为可折叠公式的问题，标准GNN无法总是区分可满足与不可满足实例；（iii）我们证明了一个通用逼近定理，表明通过随机节点初始化（RNI），该方法可以在有限数据集上以任意精度逼近SAT求解，即GNN在此类数据集上近似完备。此外，我们证明对于不可折叠公式，无需RNI即可实现相同的逼近保证。最后，我们通过实验评估了该方法，结果表明，尽管神经网络架构简单，但该方法取得了有希望的结果。

</details>


### [214] [mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling](https://arxiv.org/abs/2507.01829)
**中文标题：mGRADE：最小循环门控与延迟卷积结合的轻量级序列建模**

*Tristan Torchet,Christian Metzner,Laura Kriener,Melika Payvand*

主要分类: cs.LG

摘要简述: mGRADE是一种轻量级序列建模方法，结合了时间卷积和最小门控循环单元，适用于边缘设备，显著降低内存占用并提升多尺度时序特征处理能力。


<details>
  <summary>详细信息</summary>
研究动机: 边缘设备需要高效处理时序数据的模型，但现有方法如Transformer内存占用高，RNN训练慢，TCN内存随核大小增加。mGRADE旨在解决这些问题，提供一种内存高效的解决方案。

研究方法: mGRADE结合了时间1D卷积（可学习间距）和最小门控循环单元（minGRU），卷积层捕捉快速时序变化，循环模块高效维护全局上下文，内存开销极低。

研究结果: 在合成任务和像素级图像分类基准测试中，mGRADE比纯卷积或纯循环模型性能更好，内存占用减少约20%。

研究结论: mGRADE是一种高效的多尺度时序处理方法，特别适合内存受限的边缘设备应用。

中文摘要: 边缘设备对时序处理的需求要求模型在严格的内存限制下捕捉短程和长程动态。尽管Transformer在序列建模中表现出色，但其内存随序列长度呈二次方增长，不适用于此类场景。循环神经网络（RNN）内存占用恒定但需顺序训练，而时序卷积网络（TCN）虽高效，内存却随核大小增加。为解决这些问题，我们提出mGRADE（最小门控循环架构与延迟嵌入），这是一种混合内存系统，结合了可学习间距的时间1D卷积和最小门控循环单元（minGRU）。该设计使卷积层实现灵活的延迟嵌入以捕捉快速时序变化，而循环模块以最小内存开销高效维护全局上下文。我们在两项合成任务中验证了该方法，证明mGRADE能有效分离并保留多尺度时序特征。此外，在像素级图像分类基准测试中，mGRADE始终优于纯卷积或纯循环模型，内存占用减少约20%，突显其在内存受限的边缘时序处理中的适用性。这展示了mGRADE作为内存受限多尺度时序处理的高效解决方案的潜力。

</details>


### [215] [Towards Foundation Auto-Encoders for Time-Series Anomaly Detection](https://arxiv.org/abs/2507.01875)
**中文标题：面向时间序列异常检测的基础自编码器**

*Gastón García González,Pedro Casas,Emilio Martínez,Alicia Fernández*

主要分类: cs.LG

摘要简述: 本文提出了一种基于变分自编码器（VAE）和扩张卷积神经网络（DCNN）的新型时间序列异常检测方法FAE，旨在通过大规模预训练构建通用模型，实现零样本异常检测。


<details>
  <summary>详细信息</summary>
研究动机: 受大型预训练基础模型成功的启发，本文旨在开发一种通用的时间序列建模方法，能够学习复杂的时间模式，并在未见过的数据集上实现准确的建模、预测和异常检测。

研究方法: FAE结合了变分自编码器（VAE）和扩张卷积神经网络（DCNN），构建了一个通用的单变量时间序列模型，支持零样本异常检测。

研究结果: 初步实验结果表明，FAE在多个多维时间序列数据集（包括来自移动ISP的真实数据和KDD 2021异常检测数据集）上表现良好。

研究结论: FAE为时间序列异常检测提供了一种新型的通用方法，未来有望在零样本应用中发挥重要作用。

中文摘要: 我们研究了一种新型的时间序列建模方法，受大型预训练基础模型成功的启发。我们提出了FAE（基础自编码器），这是一种基于变分自编码器（VAE）的时间序列异常检测基础生成AI模型。所谓“基础”，是指该模型通过大规模时间序列数据预训练，能够学习复杂的时间模式，从而在未见过的数据集上实现准确的建模、预测和异常检测。FAE利用VAE和扩张卷积神经网络（DCNN）构建了一个通用的单变量时间序列模型，最终可能在开箱即用的零样本异常检测应用中表现良好。我们介绍了FAE的主要概念，并在多个多维时间序列数据集（包括来自移动ISP的真实数据和知名的KDD 2021异常检测数据集）上展示了初步结果。

</details>


### [216] [Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection](https://arxiv.org/abs/2507.01924)
**中文标题：探索混合深度学习方法在心理健康服务账单异常检测中的应用：通过半监督异常检测解决标签稀缺问题**

*Samirah Bakker,Yao Ma,Seyed Sahand Mohammadi Ziabari*

主要分类: cs.LG

摘要简述: 本文探讨了一种结合长短期记忆网络（LSTM）和Transformer的混合深度学习方法，用于心理健康服务账单中的异常检测，通过半监督异常检测解决标签稀缺问题。


<details>
  <summary>详细信息</summary>
研究动机: 心理健康服务账单的复杂性容易导致异常（如欺诈），而传统机器学习方法在类别不平衡、标签稀缺和复杂序列模式方面表现不佳。本研究旨在探索一种结合伪标签技术的混合深度学习模型，以提升异常检测效果。

研究方法: 研究采用LSTM和Transformer的混合模型，结合基于隔离森林（iForest）和自编码器（AE）的伪标签技术，对心理健康服务账单数据进行异常检测。

研究结果: 在声明级数据上，iForest LSTM基线模型实现了最高召回率（0.963）；在操作级数据上，基于iForest的混合模型召回率最高（0.744），但精度较低。

研究结论: 研究结果表明，在复杂且不平衡的异常检测场景中，结合伪标签技术的混合深度学习方法具有潜力。

中文摘要: 心理健康服务账单的复杂性容易导致异常（包括欺诈）。尽管机器学习方法已应用于异常检测，但它们常受限于类别不平衡、标签稀缺和复杂序列模式。本研究探索了一种结合长短期记忆网络（LSTM）和Transformer的混合深度学习方法，并通过隔离森林（iForest）和自编码器（AE）进行伪标签生成。此前研究未在医疗账单领域评估此类基于伪标签数据的混合模型。该方法在两个真实心理健康服务账单数据集上进行了评估。在声明级数据上，iForest LSTM基线模型实现了最高召回率（0.963）；在操作级数据上，基于iForest的混合模型召回率最高（0.744），但精度较低。这些发现表明，在复杂且不平衡的异常检测场景中，结合伪标签技术的混合深度学习方法具有潜力。

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [217] [Systemic Constraints of Undecidability](https://arxiv.org/abs/2507.01036)
**中文标题：系统性不可判定性的约束**

*Seth Bulin*

主要分类: cs.FL

摘要简述: 本文提出了一种系统性不可判定性理论，将不可计算性重新定义为系统的结构属性而非特定函数或问题的局部特征，并证明子系统在功能上参与不可判定系统的计算时会继承其不可判定性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于重新理解不可判定性，将其从特定函数或问题的局部特征提升为系统的结构属性，从而揭示其在预测、建模和认知访问中的普遍约束。

研究方法: 通过定义因果嵌入的概念，并证明一个闭合原则：任何在功能上参与不可判定系统计算的子系统都会继承其不可判定性。

研究结果: 结果表明，不可判定性是一种对自然和人工系统中预测、建模和认知访问的普遍约束，挑战了通过架构创新绕过计算限制的观点。

研究结论: 本文通过将经典结果推广到动态系统背景中，扩展了哥德尔、图灵和柴廷的逻辑轨迹，为可计算性拓扑及其与科学知识边界的关系提供了新视角。

中文摘要: 本文提出了一种系统性不可判定性理论，将不可计算性重新定义为系统的结构属性，而非特定函数或问题的局部特征。我们定义了因果嵌入的概念，并证明了一个闭合原则：任何在功能上参与不可判定系统计算的子系统都会继承其不可判定性。这一结果表明，不可判定性是对自然和人工系统中预测、建模和认知访问的普遍约束。我们的框架削弱了预言模仿的可能性，并挑战了通过架构创新绕过计算限制的观点。通过将经典结果推广到动态系统背景中，这项工作扩展了哥德尔、图灵和柴廷的逻辑轨迹，为可计算性拓扑及其与科学知识边界的关系提供了新视角。

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [218] [Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems](https://arxiv.org/abs/2507.01429)
**中文标题：基于赛道存储器的内存计算硬件-软件协同设计用于嵌入式系统中的CNN推理**

*Benjamin Chen Ming Choong,Tao Luo,Cheng Liu,Bingsheng He,Wei Zhang,Joey Tianyi Zhou*

主要分类: cs.ET

摘要简述: 本文提出了一种基于赛道存储器的内存计算硬件-软件协同设计方法，用于优化嵌入式系统中的CNN推理，显著提升了能效和性能。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络在嵌入式系统中处理大量数据时面临资源限制的挑战。内存计算作为一种高效的计算基础设施，尤其适合嵌入式AI应用。赛道存储器因其高数据密度和非易失性成为内存计算的理想选择，但如何在其上设计高效的内存算术电路仍是一个难题。

研究方法: 设计了一系列适用于乘加操作的内存计算单元，并通过硬件-软件协同设计方法，探索了基于赛道存储器的系统与CNN模型架构的设计空间，以优化性能和效率。

研究结果: 提出的电路设计和模型-系统协同优化策略显著减小了存储单元面积，同时在能效和性能上实现了显著提升。

研究结论: 本文通过硬件-软件协同设计，成功实现了基于赛道存储器的嵌入式系统中高效CNN推理，为未来嵌入式AI应用提供了可行的解决方案。

中文摘要: 深度神经网络生成和处理大量数据，对资源有限的嵌入式系统提出了挑战。内存计算已被证明是一种高效的计算基础设施，并显示出在嵌入式AI应用中的潜力。在新型存储器技术中，赛道存储器是一种非易失性技术，可实现高数据密度制造，非常适合内存计算。然而，将内存算术电路与存储单元集成会影响存储密度和能效。在面积和能量限制下，在赛道存储器上构建高效的内存算术电路仍具挑战性。为此，我们提出了一种针对赛道存储器优化的高效内存卷积神经网络（CNN）加速器。我们设计了一系列适用于乘加操作的内存计算单元作为基础算术电路。此外，我们探索了基于赛道存储器的系统和CNN模型架构的设计空间，采用协同设计方法，在保持模型精度的同时，提高了在赛道存储器上执行CNN推理的效率和性能。我们设计的电路和模型-系统协同优化策略实现了小面积存储单元，并在基于赛道存储器的嵌入式系统中显著提升了能效和性能。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [219] [Hello Afrika: Speech Commands in Kinyarwanda](https://arxiv.org/abs/2507.01024)
**中文标题：你好，非洲：卢旺达语的语音命令**

*George Igwegbe,Martins Awojide,Mboh Bless,Nirel Kadzo*

主要分类: eess.AS

摘要简述: Hello Afrika项目旨在填补非洲语言语音命令模型的空白，首期专注于卢旺达语，构建了一个包含通用指令、数字和唤醒词的语音命令模型，并在多种设备上部署和评估性能。


<details>
  <summary>详细信息</summary>
研究动机: 目前非洲语言的语音命令模型稀缺，限制了非接触式设备控制的发展，尤其是对残障人士。卢旺达对语音识别技术的兴趣促成了Hello Afrika项目的启动，旨在利用该国在Mozilla Common Voice上的大型数据集。

研究方法: 项目基于自定义的语音命令语料库（包含通用指令、数字和唤醒词），构建了语音命令模型，并在PC、手机和边缘设备上部署，使用合适的指标评估性能。

研究结果: 模型成功部署于多种设备，并通过性能评估验证了其有效性。

研究结论: Hello Afrika项目为非洲语言的语音命令技术发展提供了重要支持，未来可扩展至更多语言。

中文摘要: 语音命令是语言口语语料库的一个子集，对于非接触式控制和日常设备中大型AI系统的激活至关重要，尤其对残障人士而言。目前非洲语言的语音命令模型稀缺。Hello Afrika项目旨在解决这一问题，首期专注于卢旺达语，因该国对语音识别技术的兴趣促成了Mozilla Common Voice上最大的数据集之一。模型基于包含通用指令、数字和唤醒词的自定义语音命令语料库构建，最终在多种设备（PC、手机和边缘设备）上部署，并使用合适的指标评估性能。

</details>


### [220] [Scalable Offline ASR for Command-Style Dictation in Courtrooms](https://arxiv.org/abs/2507.01021)
**中文标题：可扩展的离线ASR用于法庭命令式听写**

*Kumarmanas Nethil,Vaibhav Mishra,Kriti Anandan,Kavya Manohar*

主要分类: eess.AS

摘要简述: 本文提出了一种开源框架，用于法庭命令式听写，填补了资源密集型在线系统与高延迟批处理之间的空白。通过语音活动检测（VAD）分割音频，并利用Whisper模型并行转录，实现了高效的多路复用。


<details>
  <summary>详细信息</summary>
研究动机: 现有系统在资源消耗和延迟之间存在矛盾，尤其是在法庭等实时性要求高的场景中。本文旨在提供一种高效、低延迟的开源解决方案，兼容多种ASR架构。

研究方法: 使用语音活动检测（VAD）分割音频，并利用Whisper模型并行转录音频片段。通过多路复用技术最大化计算资源利用率，兼容包括CTC模型在内的多种ASR架构。

研究结果: 在印度约15%的法庭中部署，实验表明，随着用户并发量的增加，延迟显著降低，优于传统的顺序批处理。

研究结论: 提出的开源框架在命令式听写场景中表现出高效性和低延迟，适用于大规模部署，并兼容多种ASR模型。

中文摘要: 我们提出了一种开源框架，用于命令式听写，填补了资源密集型在线系统与高延迟批处理之间的空白。该方法利用语音活动检测（VAD）分割音频，并使用Whisper模型并行转录这些片段，实现音频的高效多路复用。与SuperWhisper等专有系统不同，该框架还兼容大多数ASR架构，包括广泛使用的基于CTC的模型。我们的多路复用技术在现实场景中最大化计算资源利用率，已在印度约15%的法庭中部署。对实时数据的评估表明，与顺序批处理相比，随着用户并发量的增加，延迟持续降低。现场演示将展示我们的开源实现，并允许与会者实时互动。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [221] [AI-guided digital intervention with physiological monitoring reduces intrusive memories after experimental trauma](https://arxiv.org/abs/2507.01081)
**中文标题：AI引导的数字干预结合生理监测减少实验性创伤后的侵入性记忆**

*Megan T. deBettencourt,Sruthi Sakthivel,Emily A. Holmes,Mark Chevillet*

主要分类: cs.HC

摘要简述: AI引导的数字干预结合生理监测显著减少实验性创伤后的侵入性记忆。


<details>
  <summary>详细信息</summary>
研究动机: 全球创伤问题普遍，现有数字治疗多需人工指导，限制了可扩展性。研究探讨生成式AI和神经技术是否能提供可扩展的替代方案。

研究方法: 研究测试了ANTIDOTE系统，结合AI指导和瞳孔测量技术，自动提供并监测基于证据的数字治疗（ICTI），以减少创伤后的侵入性记忆。100名健康志愿者观看创伤视频后随机分为干预组和对照组。

研究结果: 干预组报告随后一周的侵入性记忆显著减少。AI指导成功实施干预，瞳孔大小反映干预参与度并预测症状减轻，可作为干预效果的生物标志物。

研究结论: 研究为可扩展的AI引导数字干预提供了科学依据，有望应对全球创伤问题。

中文摘要: 全球创伤问题普遍。基于证据的数字治疗虽有帮助，但大多需人工指导。人工指导虽能提供个性化指令和响应，但限制了可扩展性。生成式AI和神经技术能否提供可扩展的替代方案？本研究测试了ANTIDOTE系统，结合AI指导和瞳孔测量技术，自动提供并监测基于证据的数字治疗（ICTI），以减少心理创伤后的侵入性记忆。100名健康志愿者观看创伤视频后随机分为干预组和对照组。如预期，干预组随后一周报告的侵入性记忆显著减少。事后评估证实AI指导成功实施了干预。此外，瞳孔大小追踪了干预参与度并预测症状减轻，为干预效果提供了候选生物标志物。这些发现为可扩展的AI引导数字干预开辟了道路。

</details>


### [222] [Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants](https://arxiv.org/abs/2507.01548)
**中文标题：汉字作为叙事桥梁的共创：老年移民的AI辅助工作坊**

*Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen*

主要分类: cs.HC

摘要简述: 本文探讨了老年移民如何通过AI辅助共创表达个人叙事，结合口述故事和汉字重构，将生活经验转化为视觉和触觉表达。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在帮助老年移民，尤其是城市中的老年移民，通过AI辅助工具表达那些通常难以言表或碎片化的个人叙事，同时探索人机协作的新视角。

研究方法: 通过试点工作坊，结合口述故事和由大型语言模型（LLM）建议的小篆字形重构，参与者使用实物材料重新创作汉字形式，无需数字素养。

研究结果: 参与者成功将生活经验转化为视觉和触觉表达，AI作为支持机制而非内容生产者，增强了叙事能力。

研究结论: 该方法为人机协作和老龄化研究提供了新视角，重新定位AI的角色，并支持社会技术系统中的叙事自主性。

中文摘要: 本文探讨了老年人，尤其是中国城市中的老年移民，如何通过AI辅助共创表达那些通常碎片化、被忽视或难以言表的个人叙事。通过一个结合口述故事和汉字象征性重构的试点工作坊，参与者分享了移民记忆，并使用大型语言模型（LLM）建议的小篆字形与实物材料重新创作了新的字符形式。在人类引导和温和AI支持下，参与者无需数字素养便将生活经验转化为视觉和触觉表达。这一方法通过将AI重新定位为支持机制而非内容生产者，并支持社会技术系统中的叙事自主性，为人机协作和老龄化研究提供了新视角。

</details>


### [223] [AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance](https://arxiv.org/abs/2507.01274)
**中文标题：AI与海事培训的结合：精准分析提升安全与表现**

*Vishakha Lall,Yisi Liu*

主要分类: cs.HC

摘要简述: 本研究开发了一个AI驱动的框架，通过视觉焦点追踪、语音识别和压力检测，客观评估海事培训学员的表现，提升高风险场景的准备能力。系统在模拟海事场景中表现出高准确率，显著优于现有基准。


<details>
  <summary>详细信息</summary>
研究动机: 传统海事培训依赖主观评估，存在主观性、关键特征难以测量和认知限制等问题。本研究旨在通过AI技术解决这些问题，提供客观的性能分析。

研究方法: 系统整合了多种AI技术：通过眼动追踪和计算机视觉分析视觉焦点；使用海事专用语音转文本模型和自然语言处理分析沟通；利用大语言模型评估沟通正确性；通过声音音高检测心理压力。模型在模拟海事场景中进行了评估。

研究结果: AI算法在视觉检测（约92%）、海事语音识别（约91%）和压力检测（约90%）方面表现出高准确率，优于现有基准。系统提供了视觉注意力、沟通清单遵守和压力水平的详细分析。

研究结论: 研究表明，AI可以革新海事培训，提供客观性能分析、个性化反馈，并提升应对实际挑战的准备能力。

中文摘要: 传统的模拟器培训对海事专业人员的安全至关重要，但通常依赖主观的教练评估，涉及技术技能、行为焦点、沟通和肢体语言，存在主观性、关键特征难以测量和认知限制等问题。为解决这些问题，本研究开发了一个AI驱动的框架，通过视觉焦点追踪、语音识别和压力检测，客观评估学员表现，提升高风险场景的准备能力。系统整合了多种AI技术：通过眼动追踪和计算机视觉分析视觉焦点；使用海事专用语音转文本模型和自然语言处理分析沟通；利用大语言模型评估沟通正确性；通过声音音高检测心理压力。模型在模拟海事场景中进行了评估，AI算法在视觉检测（约92%）、海事语音识别（约91%）和压力检测（约90%）方面表现出高准确率，优于现有基准。系统提供了视觉注意力、沟通清单遵守和压力水平的详细分析。研究表明，AI可以革新海事培训，提供客观性能分析、个性化反馈，并提升应对实际挑战的准备能力。

</details>


### [224] [Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America](https://arxiv.org/abs/2507.01719)
**中文标题：面向多数世界的文化适宜医疗对话AI：拉丁美洲公民与专业人士的探索性研究**

*Dorian Peters,Fernanda Espinoza,Marco da Re,Guido Ivetta,Luciana Benotti,Rafael A. Calvo*

主要分类: cs.HC

摘要简述: 本文探讨如何为拉丁美洲开发文化适宜的医疗对话AI，通过参与式工作坊收集定性数据，提出‘多元对话AI’框架，强调关系性和包容性而非仅依赖数据。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLMs）在全球范围内忽略了许多文化背景，尤其在医疗领域，对话AI（CAI）需要适应多元文化和语言环境。拉丁美洲作为研究不足的地区，亟需本地化的解决方案。

研究方法: 采用自下而上的本地化方法，通过参与式工作坊收集拉丁美洲公民和专业人士的定性数据，分析文化错位、区域对医疗聊天机器人的看法及文化适宜策略。

研究结果: 研究发现，学术定义的文化概念在现实中失去意义，技术需结合经济、政治、地理和本地物流等更广泛的文化框架。提出‘多元对话AI’框架，强调关系性和包容性。

研究结论: 开发文化适宜的医疗对话AI需超越数据量，关注多元文化背景下的关系性和包容性。拉丁美洲的研究为全球类似地区提供了重要启示。

中文摘要: 在多数世界利用对话AI（CAI）促进健康具有合理兴趣，但CAI需在多元文化和语言环境中恰当响应。当前大型语言模型（LLMs）排除了全球许多生活经验，亟需解决方案。现有研究多采用自上而下方法或增加训练数据，本文通过拉丁美洲参与式工作坊的定性数据，提出自下而上的本地化方法。目标是构建以人为本的理解：a)数字健康中的文化错位；b)拉丁美洲对医疗聊天机器人的看法；c)文化适宜CAI的策略。研究发现，学术文化概念在现实中失去意义，技术需结合经济、政治、地理和本地物流等更广泛框架。为此，提出‘多元对话AI’框架，强调关系性和包容性而非仅依赖数据。

</details>


### [225] [Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents](https://arxiv.org/abs/2507.01862)
**中文标题：桥接UI设计与聊天机器人交互：将表单式原则应用于对话代理**

*Sanjay Krishna Anbalagan,Xinrui Nie,Umesh Mohan,Vijay Kumar Kanamarlapudi,Anughna Kommalapati,Xiaodan Zhao*

主要分类: cs.HC

摘要简述: 本文提出将GUI中的提交和重置操作引入聊天机器人交互，通过结构化会话数据提升多轮任务的一致性和用户体验。


<details>
  <summary>详细信息</summary>
研究动机: 特定领域的聊天机器人常涉及多步交互，传统GUI通过明确的提交和重置操作管理用户意图，而聊天机器人依赖语言线索易导致混淆。本文旨在解决这一问题。

研究方法: 将GUI中的提交和重置操作建模为LLM提示中的显式任务，通过结构化会话数据（如用户确认、重置操作和思维链推理）管理交互。

研究结果: 在酒店预订和客户管理场景中，该方法显著提升了多轮任务的一致性、用户满意度和效率。

研究结论: 通过引入GUI设计原则，聊天机器人交互的清晰度和用户体验得到显著改善，为领域特定应用提供了有效解决方案。

中文摘要: 特定领域的聊天机器人应用通常涉及多步交互，例如细化搜索筛选、选择多个项目或进行比较。传统图形用户界面（GUI）通过提供明确的“提交”（提交数据）和“重置”（丢弃数据）操作来处理这些流程，使后端系统能够明确跟踪用户意图。相比之下，对话代理依赖微妙的语言线索，可能导致混淆和上下文管理不完整。本文提出将这些GUI启发的隐喻（如提交式确认和重置式上下文切换）建模为大型语言模型（LLM）提示中的显式任务。通过将用户确认、重置操作和思维链（CoT）推理作为结构化会话数据捕获，我们保持了清晰度，减少了用户混淆，并将领域特定的聊天机器人交互与后端逻辑对齐。我们在酒店预订和客户管理场景中展示了该方法，突出了多轮任务一致性、用户满意度和效率的改进。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [226] [Customized Exploration of Landscape Features Driving Multi-Objective Combinatorial Optimization Performance](https://arxiv.org/abs/2507.01638)
**中文标题：定制化探索驱动多目标组合优化性能的景观特征**

*Ana Nikolikj,Gabriela Ochoa,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文通过分析组合优化问题的景观特征，预测多目标组合优化算法的性能，揭示了特定景观特征对算法表现的影响。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索多目标组合优化算法的性能与景观特征之间的关系，为算法选择和优化提供理论支持。

研究方法: 采用压缩帕累托局部最优解网络（C-PLOS-net）模型提取景观特征，并在具有不同复杂度和目标相关性的rmnk-landscapes上测试PLS、GSEMO和NSGA-II算法的性能。

研究结果: 研究发现特定景观特征的组合对算法性能有显著影响，且这种影响因景观和算法的不同而异。

研究结论: 该研究为多目标组合优化算法的性能预测提供了新的视角，并为特定景观和算法的优化提供了指导。

中文摘要: 本文分析了用于预测多目标组合优化算法性能的景观特征。我们采用了最近提出的压缩帕累托局部最优解网络（C-PLOS-net）模型来提取组合景观的特征。基准实例为一组具有2个和3个目标以及不同复杂度和目标相关性的rmnk-landscapes。我们使用分辨率和超体积指标评估了三种算法——帕累托局部搜索（PLS）、全局简单EMO优化器（GSEMO）和非支配排序遗传算法（NSGA-II）的性能。我们的定制化分析揭示了影响特定景观下算法性能的特征组合。这项研究为特定rmnk-landscapes和算法的特征重要性提供了更深入的见解。

</details>


### [227] [Comparing Optimization Algorithms Through the Lens of Search Behavior Analysis](https://arxiv.org/abs/2507.01668)
**中文标题：基于搜索行为分析的优化算法比较**

*Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文通过统计测试比较优化算法的搜索行为，分析114种算法的相似性，旨在解决新算法缺乏实质性创新的问题。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，基于自然或人工过程隐喻的“新型”元启发式算法层出不穷，但这些算法常被批评缺乏实质性创新且难以与现有方法区分。本文旨在通过统计测试比较算法的搜索行为，以解决这一问题。

研究方法: 研究采用交叉匹配统计测试比较多元分布，评估MEALPY库中114种算法生成的解，并通过实证分析识别搜索行为相似的算法。

研究结果: 研究发现了一些算法在搜索行为上的相似性，为区分和评估新算法提供了实证依据。

研究结论: 通过统计测试分析算法的搜索行为，可以有效识别相似算法，为优化算法的创新性评估提供了新视角。

中文摘要: 数值优化领域近年来涌现了大量基于自然或人工过程隐喻的“新型”元启发式算法，但这些算法常因缺乏实质性创新且难以与现有方法区分而受到批评。为解决这一问题，我们研究了基于搜索行为的统计测试方法。通过交叉匹配统计测试比较多元分布，评估了MEALPY库中114种算法生成的解，并将结果纳入实证分析，旨在识别搜索行为相似的算法。

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [228] [Age Sensitive Hippocampal Functional Connectivity: New Insights from 3D CNNs and Saliency Mapping](https://arxiv.org/abs/2507.01411)
**中文标题：海马功能连接的年龄敏感性：基于3D CNN和显著性映射的新发现**

*Yifei Sun,Marshall A. Dalton,Robert D. Sanders,Yixuan Yuan,Xiang Li,Sharon L. Naismith,Fernando Calamante,Jinglei Lv*

主要分类: q-bio.NC

摘要简述: 本研究开发了一种可解释的深度学习框架，结合3D CNN和LayerCAM显著性映射，预测大脑年龄并揭示海马功能连接随年龄变化的模式，特别是与前楔叶、楔叶、后扣带回皮层等区域的连接。


<details>
  <summary>详细信息</summary>
研究动机: 海马灰质减少是神经生物学衰老的标志，但其功能连接的变化尚不明确。研究旨在通过深度学习揭示海马功能连接随年龄变化的机制。

研究方法: 使用三维卷积神经网络（3D CNN）结合LayerCAM显著性映射，分析海马功能连接（FC）数据，预测大脑年龄并识别关键连接区域。

研究结果: 研究发现海马与前楔叶、楔叶、后扣带回皮层等区域的连接对年龄高度敏感，且前、后海马功能连接存在明显差异。

研究结论: 研究为海马衰老的功能机制提供了新见解，并展示了可解释深度学习在神经影像数据分析中的潜力。

中文摘要: 海马灰质减少是神经生物学衰老的标志，但其功能连接的相应变化仍知之甚少。基于种子的功能连接（FC）分析能够绘制海马与皮层区域的同步活动，为衰老过程中的功能重组提供窗口。本研究开发了一种可解释的深度学习框架，通过结合三维卷积神经网络（3D CNN）和LayerCAM显著性映射，从海马FC预测大脑年龄。该方法揭示了海马与前楔叶、楔叶、后扣带回皮层、海马旁皮层、左顶上小叶和右颞上沟等区域的关键连接，这些连接对年龄高度敏感。重要的是，分离前、后海马FC显示出与其已知功能特化一致的不同映射模式。这些发现为海马衰老的功能机制提供了新见解，并展示了可解释深度学习在揭示神经影像数据中生物学意义模式方面的强大能力。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [229] [Can AI be Consentful?](https://arxiv.org/abs/2507.01051)
**中文标题：AI能否做到“知情同意”？**

*Giada Pistilli,Bruna Trevelin*

主要分类: cs.CY

摘要简述: 本文探讨了生成式AI系统对传统法律和伦理框架中“同意”概念的挑战，指出个人无法对AI生成内容的潜在用途和传播范围做出有效同意，揭示了“同意鸿沟”问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI的发展，传统基于“同意”的法律和伦理框架在处理AI生成内容时显得不足。本文旨在分析这种不足，并探讨其对个人自主权、身份权利和社会责任的影响。

研究方法: 通过法律和伦理分析，本文研究了AI生成内容对“同意”概念的挑战，提出了“范围问题”、“时间性问题”和“自主陷阱”三大核心问题，并探讨了这些问题的法律和伦理影响。

研究结果: 研究发现，现有法律框架无法有效应对AI生成内容带来的“同意鸿沟”，尤其是在个人自主权和身份权利方面存在显著不足。

研究结论: 本文呼吁更新法律和伦理框架，以更好地应对AI生成内容带来的挑战，特别是在公平性、透明度、问责制和自主权等方面。

中文摘要: 生成式AI系统的发展暴露了围绕“同意”构建的传统法律和伦理框架的不足。本章探讨了传统“同意”概念在应对AI生成内容时的局限性，尽管“同意”对数据保护和隐私权至关重要，但个人无法对数据可能生成的无数潜在输出或其使用和传播范围做出有效同意。通过法律和伦理分析，我们揭示了三大挑战：范围问题、时间性问题和自主陷阱，这些共同构成了AI系统中的“同意鸿沟”。我们认为，现有法律框架未能充分应对这些新兴挑战，尤其是在个人自主权、身份权利和社会责任方面，尤其是当AI生成内容超出原始“同意”范围时。通过分析这些“同意”限制与负责任AI原则（包括公平性、透明度、问责制和自主权）的交集，我们证明了更新伦理和法律“同意”框架的必要性。

</details>


### [230] [Epitome: Pioneering an Experimental Platform for AI-Social Science Integration](https://arxiv.org/abs/2507.01061)
**中文标题：Epitome：开创人工智能与社会科学融合的实验平台**

*Jingjing Qu,Kejia Hu,Jun Zhu,Wenhao Li,Teng Wang,Zhiyun Chen,Yulei Ye,Chaochao Lu,Aimin Zhou,Xiangfeng Wang,James Evan*

主要分类: cs.CY

摘要简述: Epitome是全球首个专注于人工智能与社会科学深度融合的开放实验平台，通过跨学科实验和用户友好界面，简化复杂实验设计，提升人机交互效率，为AI的社会影响研究提供系统解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索大型语言模型（LLMs）在社会科学实验中的整合，以理解人机交互及其社会影响。Epitome旨在填补AI与社会科学交叉领域的实验平台空白，推动跨学科研究。

研究方法: 方法包括构建Epitome平台，整合管理、传播学、社会学、心理学和伦理学理论，通过七个核心模块实现“基础模型-复杂应用开发-用户反馈”的一站式实验解决方案，并嵌入社会科学的经典实验逻辑。

研究结果: 通过复现三项经典社会科学实验，展示了Epitome在简化复杂实验设计和生成稳健结果方面的潜力，提升了人机交互的效率和质量，为AI技术的社会影响提供了宝贵见解。

研究结论: Epitome为AI与社会科学交叉研究提供了强大工具，有望在政策制定等领域发挥重要作用，推动跨学科研究的深入发展。

中文摘要: 将大型语言模型（LLMs）整合到社会科学实验中，为理解人机交互及其社会影响提供了变革性方法。我们推出了Epitome，这是全球首个专注于人工智能与社会科学深度融合的开放实验平台。基于管理学、传播学、社会学、心理学和伦理学的理论基础，Epitome关注AI在现实部署中对个人、组织和社会的交互影响，并通过跨学科实验构建理论支持系统。该平台通过七个核心模块提供“基础模型-复杂应用开发-用户反馈”的一站式综合实验解决方案，同时将社会科学的经典“控制-比较-因果逻辑”嵌入多级人机交互环境（如对话、群聊和多智能体虚拟场景）。凭借其画布式、用户友好的界面，Epitome使研究人员能够轻松设计和运行复杂实验场景，促进对AI社会影响的系统性研究及整合解决方案的探索。为展示其能力，我们复现了三项涉及LLMs的经典社会科学实验，证明了Epitome在简化复杂实验设计和生成稳健结果方面的潜力，适合在顶级期刊发表。研究结果凸显了该平台在提升人机交互效率和质量方面的实用性，为AI技术的社会影响提供了宝贵见解。Epitome为推进AI与社会科学交叉领域的跨学科研究提供了强大工具，并有望在政策制定等领域发挥重要作用。

</details>


### [231] [Quantifying Student Success with Generative AI: A Monte Carlo Simulation Informed by Systematic Review](https://arxiv.org/abs/2507.01062)
**中文标题：量化生成式AI对学生成功的贡献：基于系统综述的蒙特卡洛模拟**

*Seyma Yaman Kayadibi*

主要分类: cs.CY

摘要简述: 本文通过系统文献综述和蒙特卡洛模拟，探讨生成式AI（如ChatGPT）在高等教育中的应用对学生学习成果的影响。研究发现，学生对AI的实用性和易用性的态度是学习成就的显著预测因素。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI技术的快速发展，其在高等教育中的应用引发了广泛关注。本文旨在通过系统综述和模拟建模，探索学生对AI工具的看法及其对学习成果的影响。

研究方法: 采用混合方法，包括对2023年至2025年Scopus数据库中19篇实证文献的系统综述，以及基于蒙特卡洛模拟的概率建模。通过主题分类和逆方差加权分析代表性数据集。

研究结果: 模拟结果显示，学生对AI工具实用性和易用性的态度是学习成就的显著预测因素，而情感或信任因素预测力较弱。

研究结论: 研究为生成式AI在高等教育中的合理使用提供了跨学科视角，强调了实用性和易用性对学生学习成果的重要性。

中文摘要: 生成式人工智能（GenAI）技术（如ChatGPT）的快速发展引发了对其在高等教育中应用的广泛关注，尤其是学生对它们的看法、使用方式及其对学习成果的影响。本文采用混合方法，结合系统文献综述和基于模拟的建模，探讨高等教育中学生对GenAI使用的看法。通过PRISMA方法从Scopus数据库中筛选出2023年至2025年的19篇实证文献，并通过主题分类对文献中的模式进行综合。其中6篇文献提供了足够的定量信息（如项目级均值和标准差），以支持概率建模。从中选取一个具有代表性的数据集，通过蒙特卡洛模拟进行逆方差加权分析，该数据集因其设计良好的Likert量表和与研究者计算系统使用主题的一致性而被选中。

模拟结果生成了一个综合的“成功分数”，用于预测学生看法与学习成就之间的关系强度。研究发现，与实用性和现实世界有用性相关的态度因素对积极学习成就的预测能力显著优于情感或信任因素。这种跨学科视角为将主题结果与预测模型联系起来提供了独特方法，同时也回应了关于大学中GenAI工具合理使用的长期争议。

</details>


### [232] [Penalizing Transparency? How AI Disclosure and Author Demographics Shape Human and AI Judgments About Writing](https://arxiv.org/abs/2507.01418)
**中文标题：惩罚透明？AI披露与作者人口统计如何影响人类与AI对写作的评价**

*Inyoung Cheong,Alicia Guo,Mina Lee,Zhehui Liao,Kowe Kadoma,Dongyoung Go,Joseph Chee Chang,Peter Henderson,Mor Naaman,Amy X. Zhang*

主要分类: cs.CY

摘要简述: 研究探讨AI披露声明如何影响写作质量评价，以及作者种族和性别是否导致差异。发现人类和AI评分者均对披露AI使用持负面态度，但仅AI评分者表现出对女性和黑人作者的偏好，且此偏好在披露AI后消失。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在写作中的广泛应用，透明披露AI辅助的呼声增加。但若透明披露对不同身份群体影响不均，可能导致开放负担不对称。本研究旨在揭示AI披露声明对写作评价的影响，以及作者种族和性别是否加剧这种影响。

研究方法: 通过大规模控制实验，让人类评分者（1,970人）和AI评分者（2,520人）评估同一篇人类撰写的新闻文章，同时系统化调整披露声明和作者人口统计信息。

研究结果: 人类和AI评分者均对披露AI使用持负面态度。但仅AI评分者表现出对女性和黑人作者的偏好，且此偏好在披露AI后消失。

研究结论: 研究揭示了AI披露与作者身份之间的复杂关系，凸显了机器与人类评价模式的差异。

中文摘要: 随着AI逐渐融入各类人类写作中，对AI辅助透明披露的呼声日益高涨。然而，如果透明披露在不同群体中作用不均，某些身份群体因诚实而承担更重代价，则开放负担将变得不对称。本研究探讨AI披露声明如何影响对写作质量的评价，以及这些影响是否因作者的种族和性别而异。通过一项大规模控制实验，人类评分者（n = 1,970）和AI评分者（n = 2,520）评估了一篇人类撰写的新闻文章，同时系统化调整披露声明和作者人口统计信息。这种方法反映了人类和算法决策如何影响机会获取（如招聘、晋升）和社会认可（如内容推荐算法）。我们发现，人类和AI评分者均对披露AI使用持负面态度。然而，仅AI评分者表现出人口统计交互效应：在未披露AI时，他们更倾向于女性和黑人作者的文章。但这些优势在披露AI辅助后消失。这些发现揭示了AI披露与作者身份之间的复杂关系，凸显了机器与人类评价模式的差异。

</details>


### [233] [AI and Remote Sensing for Resilient and Sustainable Built Environments: A Review of Current Methods, Open Data and Future Directions](https://arxiv.org/abs/2507.01547)
**中文标题：人工智能与遥感技术用于韧性和可持续建筑环境的当前方法、开放数据与未来方向综述**

*Ubada El Joulani,Tatiana Kalganova,Stergios-Aristoteles Mitoulis,Sotirios Argyroudis*

主要分类: cs.CY

摘要简述: 本文综述了人工智能（AI）与遥感技术在提升交通基础设施韧性和可持续性中的应用，重点探讨了AI在自然灾害后道路和桥梁损伤评估中的潜力，并指出SAR数据与AI模型结合的研究缺口。


<details>
  <summary>详细信息</summary>
研究动机: 交通基础设施对经济增长至关重要，但面临老化、气候变化和自然灾害等威胁。本文旨在探索AI如何通过损伤评估和监测提升其韧性，尤其是桥梁这类复杂结构。

研究方法: 通过系统性文献综述，分析了现有AI模型和数据集在道路、桥梁等基础设施损伤评估中的应用，特别关注SAR数据与AI模型的结合。

研究结果: 研究发现，尽管AI在基础设施损伤评估中具有潜力，但SAR数据与AI模型结合的研究仍存在显著缺口，尤其是在桥梁损伤评估领域。

研究结论: 本文揭示了AI与遥感技术在基础设施韧性提升中的研究缺口，为未来AI驱动的解决方案提供了基础。

中文摘要: 关键基础设施（如交通网络）通过促进流动性和贸易支撑经济增长。然而，资产老化、气候变化影响（如极端天气、海平面上升）以及从自然灾害到网络攻击和冲突的混合威胁，对其韧性和功能性构成日益增长的风险。本文综述探讨了新兴数字技术，特别是人工智能（AI），如何提升交通基础设施的损伤评估和监测能力。通过系统性文献综述，分析了现有AI模型和数据集在自然灾害影响的道路、桥梁等关键基础设施损伤评估中的应用。特别关注桥梁损伤检测的独特挑战和机遇，因其结构复杂且在连通性中扮演关键角色。同时讨论了合成孔径雷达（SAR）数据与AI模型的结合，揭示了一个关键研究缺口：缺乏将AI模型应用于SAR数据进行全面桥梁损伤评估的研究。因此，本文旨在识别研究缺口，并为AI驱动的关键交通基础设施评估和监测解决方案提供基础。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [234] [Epistemic Scarcity: The Economics of Unresolvable Unknowns](https://arxiv.org/abs/2507.01483)
**中文标题：认知稀缺：不可解未知的经济学**

*Craig S Wright*

主要分类: econ.GN

摘要简述: 本文通过奥地利经济学派的理论，批判人工智能在经济协调中的局限性，指出AI无法处理主观价值和不确定性，并质疑主流AI伦理框架的合理性。


<details>
  <summary>详细信息</summary>
研究动机: 本文旨在挑战人工智能在经济和认知秩序中的主导地位，揭示AI系统无法完成经济协调的核心功能，如解释目标、发现手段和通过价格传递主观价值。同时，批判主流AI伦理框架（如公平、问责和透明）与自由主义秩序的冲突。

研究方法: 采用米塞斯的先验推理和奥地利经济学派的企业家理论，分析AI在经济协调中的局限性，并对比新古典和行为经济学模型。通过“认知稀缺”概念，探讨信息过载对真理辨识的影响。

研究结果: 研究发现AI系统无法生成规范、解释制度或承担责任，其复杂性与经济协调的需求存在根本性不匹配。信息过载既催生企业家洞察，也可能助长软性极权主义。

研究结论: 本文认为AI的争论关乎人类自主权、制度演化和理性选择的未来。奥地利经济学派的行动、主观性和自发秩序理论，为对抗计算社会控制提供了唯一连贯的替代方案。

中文摘要: 本文对人工智能和算法治理进行了行动学分析，挑战了机器系统维持经济和认知秩序能力的假设。基于米塞斯的先验推理和奥地利经济学派的企业家理论，我们认为AI系统无法完成经济协调的核心功能：解释目标、发现手段以及通过价格传递主观价值。新古典和行为经济学模型将决策视为约束下的优化，而我们将其视为不确定性下的有目的行动。

我们批判主流AI伦理框架（如公平、问责和透明）作为建构理性主义的延伸，与基于自愿行动和财产权的自由主义秩序相冲突。试图将道德推理编码到算法中，反映了对伦理和经济学的误解。无论多么复杂，AI系统都无法生成规范、解释制度或承担责任，它们始终是不透明、错位且惰性的。

通过“认知稀缺”的概念，我们探讨了信息过载如何削弱真理辨识能力，既催生企业家洞察，也可能助长软性极权主义。我们的分析最终提出一个文明层面的主张：关于AI的争论关乎人类自主权、制度演化和理性选择的未来。奥地利经济学派关注行动、主观性和自发秩序，为对抗日益增长的计算社会控制提供了唯一连贯的替代方案。

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [235] [Empirical Analysis Of Heuristic and Approximation Algorithms for the The Mutual-Visibility Problem](https://arxiv.org/abs/2507.01076)
**中文标题：互视问题的启发式和近似算法的实证分析**

*Vanja Stojanović,Bor Pangeršič*

主要分类: cs.CG

摘要简述: 本文填补了NP完全互视问题缺乏实证分析的空白，通过评估三种算法在小图和大图上的表现，发现小图中算法结果与理论界限一致，而大图中结果与理论界限差异显著。


<details>
  <summary>详细信息</summary>
研究动机: 尽管互视问题在理论上已有研究，但其实际行为缺乏实证分析。本文旨在填补这一空白，通过实验评估不同算法在实际数据集上的表现。

研究方法: 本文实现了三种算法：直接贪心启发式、基于超图的近似算法和遗传算法，并在多种合成图数据集上进行了评估，包括已知μ(G)值的图和一般图模型。

研究结果: 对于小图，算法结果与理论界限一致；而对于大图，结果与理论界限差异显著。在已知最优图上验证时，遗传算法和其他启发式表现最佳。

研究结论: 尽管大图中算法结果与理论界限存在差异，但遗传算法和启发式方法在已知最优图上表现良好，为互视问题的实际应用提供了参考。

中文摘要: NP完全的互视问题目前缺乏对其实际行为的实证分析，尽管已有理论研究。本文通过实现和评估三种不同的算法——直接贪心启发式、基于超图的近似算法和遗传算法——填补了这一空白。实验在多种合成图数据集上进行，包括已知μ(G)值的图和一般图模型。结果表明，对于较小的图，算法结果与理论界限一致；而对于较大的实例，结果与理论界限显著偏离。由于缺乏紧界限，绝对质量评估变得复杂。然而，在已知最优图上的验证显示，遗传算法和其他启发式在测试方法中表现最佳。

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [236] [SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars](https://arxiv.org/abs/2507.01939)
**中文标题：SpecCLIP：恒星光谱测量的对齐与翻译**

*Xiaosheng Zhao,Yang Huang,Guirong Xue,Xiao Kong,Jifeng Liu,Xiaoyu Tang,Timothy C. Beers,Yuan-Sen Ting,A-Li Luo*

主要分类: astro-ph.IM

摘要简述: SpecCLIP是一种基于大语言模型（LLM）启发的框架，用于恒星光谱分析，通过对比对齐和多光谱翻译提升恒星参数估计和化学丰度测定的精度。


<details>
  <summary>详细信息</summary>
研究动机: 受大语言模型（LLM）在自然语言处理中的成功启发，研究者希望将类似方法应用于恒星光谱分析，以提取丰富的物理和化学信息，并支持多样化的下游任务。

研究方法: SpecCLIP框架包括两个步骤：1）在LAMOST低分辨率和Gaia XP光谱数据集上进行预训练；2）使用CLIP框架进行对比对齐，并通过辅助解码器实现光谱翻译和保留光谱特定信息。

研究结果: SpecCLIP在中等规模的标记数据集上微调后，显著提升了恒星参数估计和化学丰度测定的精度，同时支持异常检测和跨光谱预测。

研究结论: 研究表明，结合对比训练和光谱感知解码器的基础模型能够推动高精度恒星光谱学的发展。

中文摘要: 近年来，大语言模型（LLM）通过海量数据和大规模参数化彻底改变了自然语言理解。受此启发，我们提出了SpecCLIP，一种将LLM方法扩展到恒星光谱分析的基础模型框架。恒星光谱类似于结构化语言，编码了丰富的恒星物理和化学信息。通过在大型光谱数据集上训练基础模型，我们的目标是学习稳健且信息丰富的嵌入，以支持多样化的下游应用。作为概念验证，SpecCLIP包括对LAMOST低分辨率和Gaia XP两种光谱类型的预训练，随后使用CLIP（对比语言-图像预训练）框架进行对比对齐，以关联不同仪器的光谱。这种对齐通过辅助解码器补充，这些解码器保留了光谱特定信息，并实现了光谱类型之间的翻译（预测），前者通过最大化嵌入与输入光谱之间的互信息实现。结果是一个跨光谱框架，支持仪器间的内在校准和灵活应用。我们证明，在中等规模的标记数据集上微调这些模型可以提高对恒星参数估计和化学丰度测定等任务的适应性。SpecCLIP还提升了基于外部调查数据的参数估计的准确性和精度。此外，其相似性搜索和跨光谱预测能力为异常检测提供了潜力。我们的结果表明，结合对比训练和光谱感知解码器的基础模型可以推动高精度恒星光谱学的进步。

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [237] [Evaluating LLM Agent Collusion in Double Auctions](https://arxiv.org/abs/2507.01413)
**中文标题：评估大型语言模型代理在双向拍卖中的共谋行为**

*Kushal Agrawal,Verona Teo,Juan J. Vazquez,Sudarsh Kunnavakkam,Vishak Srikanth,Andy Liu*

主要分类: cs.GT

摘要简述: 本文研究了大型语言模型（LLM）作为拍卖市场中的卖家代理时可能出现的共谋行为，探讨了沟通能力、模型选择和环境压力对共谋倾向的影响。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）作为自主代理在社会经济互动中的应用日益广泛，识别其潜在的不良行为（如共谋）变得至关重要。本文旨在系统研究LLM代理在拍卖市场中的共谋行为及其影响因素。

研究方法: 通过模拟连续双向拍卖市场，设计了一系列控制实验，分析LLM代理作为卖家时的行为。实验参数包括代理之间的沟通能力、模型选择以及环境压力（如监管和紧迫感）。

研究结果: 研究发现，直接沟通会增加共谋倾向，不同模型的共谋倾向存在差异，环境压力（如监管和紧迫感）也会显著影响共谋行为。

研究结论: 本文揭示了LLM代理在拍卖市场中可能出现的共谋行为及其影响因素，强调了在部署基于LLM的市场代理时需要考虑的经济和伦理问题。

中文摘要: 大型语言模型（LLM）作为自主代理在多个领域展现了强大的能力，其应用范围正在迅速扩展。随着这些代理越来越多地参与社会经济互动，识别其潜在的不良行为变得至关重要。本文研究了LLM代理可能选择共谋（定义为秘密合作以损害另一方利益）的情景。为系统研究这一问题，我们模拟了连续双向拍卖市场中作为卖家的LLM代理的行为。通过一系列控制实验，分析了沟通能力、模型选择和环境压力（如监管和紧迫感）对卖家共谋稳定性和出现的影响。研究发现，卖家之间的直接沟通会增加共谋倾向，不同模型的共谋倾向存在差异，环境压力（如监管和紧迫感）也会影响共谋行为。这些发现为部署基于LLM的市场代理提供了重要的经济和伦理考量。

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [238] [A Hybrid Ensemble Learning Framework for Image-Based Solar Panel Classification](https://arxiv.org/abs/2507.01778)
**中文标题：基于混合集成学习的图像太阳能电池板分类框架**

*Vivek Tetarwal,Sandeep Kumar*

主要分类: cs.IT

摘要简述: 本文提出了一种新型双集成神经网络（DENN），用于基于图像的太阳能电池板分类，旨在提高分类准确性和鲁棒性，并在实验中优于现有集成方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着太阳能系统的普及，如何自动区分清洁与脏污的太阳能电池板成为维护高效性能的关键挑战。本文旨在通过集成学习方法解决这一问题。

研究方法: 提出了一种双集成神经网络（DENN），通过整合多种集成模型的优势，构建一个双框架，以提高分类性能和鲁棒性。

研究结果: 在Deep Solar Eye数据集上的实验表明，DENN方法优于现有集成方法，达到了最先进的分类精度。

研究结论: DENN展示了混合集成学习技术在太阳能电池板自动检测中的潜力，为解决实际挑战提供了可扩展的解决方案。

中文摘要: 太阳能系统的安装日益增多，因此需要适当的维护技术以保持其最佳性能。其中一个主要挑战是自动区分清洁与脏污的太阳能电池板。本文提出了一种新型双集成神经网络（DENN），用于基于图像的太阳能电池板分类。该方法通过整合多种集成模型的优势，构建了一个双框架，旨在提高分类准确性和鲁棒性。与现有集成方法相比，DENN在多种评估指标上表现出更优的性能。实验结果表明，该方法在Deep Solar Eye数据集上达到了最先进的分类精度，有效服务于太阳能系统的预测性维护需求。这揭示了混合集成学习技术在推动太阳能电池板自动检测方面的潜力，为解决实际挑战提供了可扩展的解决方案。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [239] [Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives](https://arxiv.org/abs/2507.01198)
**中文标题：基于距离自适应运动基元的搜索型机器人运动规划**

*Benjamin Kraljusic,Zlatan Ajanovic,Nermin Covic,Bakir Lacevic*

主要分类: cs.RO

摘要简述: 本文提出了一种结合采样与搜索的机器人运动规划算法，通过自适应运动基元（burs）在自由配置空间中高效探索，显著减少路径规划时间和扩展次数。


<details>
  <summary>详细信息</summary>
研究动机: 传统固定大小的运动基元在复杂环境中效率较低，尤其是在高自由度机械臂中。本文旨在通过自适应运动基元提升规划效率。

研究方法: 提出了一种基于burs的自适应运动基元方法，将其嵌入图搜索算法中，利用其在自由配置空间中的自适应扩展特性，优化路径规划过程。

研究结果: 实验表明，该方法在复杂场景（尤其是高自由度机械臂）中优于固定基元规划，同时在简单场景中表现相当。

研究结论: 基于burs的自适应运动基元方法显著提升了运动规划效率，尤其适用于复杂环境和高自由度机械臂。

中文摘要: 本文提出了一种结合采样与搜索的机器人运动规划算法，其核心贡献是在图搜索算法中使用自由配置空间（C-space）中的burs作为自适应运动基元。由于burs能够在自由C-space中自适应扩展，相比固定大小的运动基元，该方法能更高效地探索配置空间，显著减少找到有效路径的时间和所需扩展次数。该算法在现有SMPL（Search-Based Motion Planning Library）库中实现，并通过一系列不同场景（涉及不同自由度的机械臂和环境复杂度）进行评估。结果表明，基于burs的方法在复杂场景（尤其是高自由度机械臂）中优于固定基元规划，同时在简单场景中表现相当。

</details>


### [240] [LLM-based Realistic Safety-Critical Driving Video Generation](https://arxiv.org/abs/2507.01264)
**中文标题：基于大语言模型的逼真安全关键驾驶视频生成**

*Yongjie Fu,Ruijian Zha,Pei Tian,Xuan Di*

主要分类: cs.RO

摘要简述: 本文提出了一种基于大语言模型（LLM）的框架，用于自动生成安全关键的驾驶场景，并通过视频生成技术将模拟场景转化为逼真的驾驶视频，为自动驾驶系统测试提供了多样化和可控的场景生成工具。


<details>
  <summary>详细信息</summary>
研究动机: 设计多样化的安全关键驾驶场景对评估自动驾驶系统至关重要。传统方法难以高效生成复杂且真实的边缘案例，因此需要一种自动化且灵活的场景生成方法。

研究方法: 利用大语言模型（LLM）通过少量示例提示和代码样本生成安全关键的驾驶场景脚本，结合CARLA模拟器实现高效代码控制。同时，使用Cosmos-Transfer1与ControlNet的视频生成管道将模拟场景转化为逼真视频。

研究结果: 实验结果表明，该方法能够生成大量多样、真实且安全关键的驾驶场景，包括罕见的边缘案例（如遮挡下的行人横穿或车辆突然切入）。

研究结论: 该方法为基于模拟的自动驾驶测试提供了高效且可控的场景生成工具，能够显著提升测试覆盖率和真实性。

中文摘要: 设计多样化的安全关键驾驶场景对评估自动驾驶系统至关重要。本文提出了一种新颖的框架，利用大语言模型（LLM）通过少量代码生成自动合成CARLA模拟器中的驾驶场景，具有场景脚本灵活、基于代码的高效交通参与者控制以及逼真物理动态的特点。给定少量示例提示和代码样本，LLM生成安全关键场景脚本，重点关注碰撞事件。为缩小模拟与真实世界外观的差距，我们整合了基于Cosmos-Transfer1与ControlNet的视频生成管道，将渲染场景转化为逼真驾驶视频。我们的方法支持可控场景生成，并能够创建罕见但关键的边缘案例，如遮挡下的行人横穿或车辆突然切入。实验结果表明，该方法在生成多样、真实且安全关键的场景方面具有显著效果，为自动驾驶的模拟测试提供了有力工具。

</details>


### [241] [VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process](https://arxiv.org/abs/2507.01284)
**中文标题：VLAD：一种基于视觉语言模型增强的自动驾驶框架，具有分层规划和可解释决策过程**

*Cristian Gariboldi,Hayato Tokida,Ken Kinjo,Yuki Asada,Alexander Carballo*

主要分类: cs.RO

摘要简述: 本文提出VLAD框架，通过结合视觉语言模型（VLM）与自动驾驶系统（VAD），提升自动驾驶的感知、预测与规划能力。实验表明，该系统在nuScenes数据集上碰撞率降低31.82%，并生成可解释的驾驶决策说明。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，开源视觉语言模型（如LLaVA、Qwen-VL等）的进步为自动驾驶系统提供了新的可能性。这些模型包含的互联网规模通用知识有望显著提升自动驾驶的感知、预测和规划能力。然而，传统端到端系统缺乏透明性，因此需要一种既能提升性能又能解释决策的方法。

研究方法: VLAD框架通过微调视觉语言模型（VLM），结合定制问答数据集增强其空间推理能力。微调后的VLM生成高级导航指令，由VAD系统执行。此外，系统还能生成自然语言解释，说明驾驶决策过程，提高透明性。

研究结果: 在nuScenes数据集上的实验表明，VLAD框架的平均碰撞率比基线方法降低31.82%，同时能够生成可解释的驾驶决策说明，为VLM增强的自动驾驶系统设立了新标杆。

研究结论: VLAD框架通过结合视觉语言模型与自动驾驶系统，显著提升了性能并增强了决策透明性，为未来自动驾驶研究提供了新方向。

中文摘要: 近年来，开源视觉语言模型（如LLaVA、Qwen-VL和Llama）的进展推动了其与多样化系统的整合研究。这些模型中包含的互联网规模通用知识为提升自动驾驶的感知、预测和规划能力提供了重要机遇。本文提出VLAD，一种视觉语言自动驾驶模型，通过将微调的VLM与先进的端到端系统VAD结合，实现了性能提升。我们采用定制问答数据集对模型进行微调，专门增强其空间推理能力。改进后的VLM生成高级导航指令，由VAD系统执行。此外，我们的系统还能生成驾驶决策的自然语言解释，从而提高了传统黑盒端到端架构的透明性和可信度。在nuScenes数据集上的全面评估表明，我们的集成系统比基线方法平均碰撞率降低了31.82%，为VLM增强的自动驾驶系统设立了新标杆。

</details>


### [242] [Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0](https://arxiv.org/abs/2507.01462)
**中文标题：量子辅助的工业4.0机器人质量检测自动路径规划**

*Eneko Osaba,Estibaliz Garrote,Pablo Miranda-Rodriguez,Alessia Ciacco,Itziar Cabanes,Aitziber Mancisidor*

主要分类: cs.RO

摘要简述: 本文探讨了混合量子-经典算法在工业4.0中优化机器人检测路径的应用，通过3D旅行商问题建模，比较了D-Wave求解器与经典方法的性能，结果显示量子方法在计算时间和解质量上具有竞争力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在利用量子计算技术优化工业机器人检测路径，以提升自动化效率，适应工业4.0的需求。

研究方法: 研究将机器人检测路径规划建模为3D旅行商问题，结合不完全图和开放路径约束，比较了D-Wave量子求解器与GUROBI、Google OR-Tools等经典方法的性能。

研究结果: 在五个实际案例中，量子求解器在解质量和计算时间上均表现出竞争力，显著缩短了计算时间。

研究结论: 量子方法在工业自动化路径规划中具有潜力，能够高效解决复杂优化问题，为工业4.0提供技术支持。

中文摘要: 本研究探讨了混合量子-经典算法在工业环境中优化基于计算机辅助设计（CAD）模型的机器人检测路径的应用。通过将任务建模为3D旅行商问题的变体，结合不完全图和开放路径约束，本研究评估了两种基于D-Wave的求解器与GUROBI和Google OR-Tools等经典方法的性能。在五个实际案例中的结果表明，量子方法在解质量上具有竞争力，同时显著减少了计算时间，凸显了量子方法在工业4.0自动化中的潜力。

</details>


### [243] [BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments](https://arxiv.org/abs/2507.01485)
**中文标题：BioMARS：一种用于自主生物实验的多智能体机器人系统**

*Yibo Qiu,Zan Huang,Zhiyu Wang,Handi Liu,Yiling Qiao,Yifeng Hu,Shu'ang Sun,Hangke Peng,Ronald X Xu,Mingzhai Sun*

主要分类: cs.RO

摘要简述: BioMARS是一种多智能体机器人系统，结合大语言模型和视觉语言模型，实现生物实验的自主设计、规划和执行，性能优于人工操作。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型和视觉语言模型在生物研究中的应用受限于僵化的协议设计、动态实验室条件的适应性不足、错误处理能力有限以及操作复杂性高。BioMARS旨在解决这些问题，推动AI驱动的实验室自动化。

研究方法: BioMARS采用分层架构：生物学家代理通过检索增强生成合成协议；技术员代理将其转化为可执行的机器人伪代码；检查员代理通过多模态感知和异常检测确保程序完整性。系统支持上下文感知优化和实时人机协作。

研究结果: BioMARS在细胞传代和培养任务中表现优于或等同于人工操作，并在视网膜色素上皮细胞分化中超越传统策略。系统通过模块化后端实现与实验室硬件的可扩展集成。

研究结论: BioMARS展示了通用化AI驱动实验室自动化的可行性，突显了基于语言推理在生物研究中的变革性作用。

中文摘要: 大语言模型（LLMs）和视觉语言模型（VLMs）有潜力通过实现自主实验改变生物研究。然而，其应用仍受限于僵化的协议设计、动态实验室条件的适应性不足、错误处理能力有限以及操作复杂性高。本文介绍了BioMARS（生物多智能体机器人系统），这是一个集成了LLMs、VLMs和模块化机器人技术的智能平台，能够自主设计、规划和执行生物实验。BioMARS采用分层架构：生物学家代理通过检索增强生成合成协议；技术员代理将其转化为可执行的机器人伪代码；检查员代理通过多模态感知和异常检测确保程序完整性。该系统能够自主完成细胞传代和培养任务，在细胞活力、一致性和形态完整性方面达到或超过人工操作水平。它还支持上下文感知优化，在视网膜色素上皮细胞分化任务中表现优于传统策略。通过一个网络界面，系统实现了实时人机协作，而模块化后端则支持与实验室硬件的可扩展集成。这些结果证明了通用化AI驱动实验室自动化的可行性，以及基于语言推理在生物研究中的变革性作用。

</details>


### [244] [LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction](https://arxiv.org/abs/2507.01308)
**中文标题：LANet：一种基于车道边界感知的鲁棒轨迹预测方法**

*Muhammad Atta ur Rahman,Dooseop Choi,KyoungWook Min*

主要分类: cs.RO

摘要简述: 本文提出了一种基于车道边界感知的轨迹预测方法LANet，通过融合多种矢量地图元素（如车道边界和道路边缘）来丰富驾驶环境表示，并开发了有效的特征融合和剪枝机制，以提高预测准确性和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前大多数运动预测模型主要基于车道中心线表示，限制了其对复杂交通环境和规则的捕捉能力。本文旨在通过引入更多矢量地图元素（如车道边界和道路边缘）来提升模型的预测能力。

研究方法: 提出LANet模型，融合多种矢量地图元素，开发特征融合策略和剪枝机制，以过滤与目标代理最相关的地图连接，确保计算效率的同时保持空间和语义关系。

研究结果: 在Argoverse 2数据集上的实验表明，LANet在保持竞争力的同时提升了性能，验证了其方法的有效性。

研究结论: LANet通过更丰富的地图表示和高效的剪枝机制，克服了传统车道中心线模型的局限性，为自动驾驶运动预测提供了更优的解决方案。

中文摘要: 准确的运动预测对于安全高效的自动驾驶至关重要，使车辆能够在复杂交通场景中预测未来轨迹并做出明智决策。当前大多数运动预测模型基于车道中心线的主要表示，限制了其对关键道路环境和交通规则的捕捉能力。本文提出了一种增强的运动预测模型，通过引入多种矢量地图元素（如车道边界和道路边缘）来丰富驾驶环境表示。开发了一种有效的特征融合策略，以合并不同矢量地图组件中的信息，使模型能够学习道路结构及其与代理的交互的全局信息。由于编码更多道路环境信息会增加内存使用和计算成本，我们开发了一种有效的剪枝机制，过滤与目标代理最相关的地图连接，在保持计算效率的同时确保准确轨迹预测所需的空间和语义关系。克服了基于车道中心线模型的局限性，我们的方法提供了更丰富且高效的驾驶环境表示，并推动了自动驾驶车辆运动预测的技术水平。我们在Argoverse 2运动预测数据集上通过大量实验验证了我们的方法，结果表明我们的模型在保持竞争力的同时实现了性能提升。

</details>


### [245] [AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation](https://arxiv.org/abs/2507.01961)
**中文标题：AC-DiT：用于移动操作的自适应协调扩散变换器**

*Sixiang Chen,Jiaming Liu,Siyuan Qian,Han Jiang,Lily Li,Renrui Zhang,Zhuoyang Liu,Chenyang Gu,Chengkai Hou,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

主要分类: cs.RO

摘要简述: 本文提出了一种自适应协调扩散变换器（AC-DiT），用于解决移动操作中移动底座与机械臂协调不足的问题，通过动态调整多模态感知权重和引入移动底座动作表示，实现了端到端的移动操作控制。


<details>
  <summary>详细信息</summary>
研究动机: 现有移动操作方法在协调移动底座与机械臂时存在不足，未能显式建模移动底座对机械臂控制的影响，且忽视了不同阶段的多模态感知需求。本文旨在通过AC-DiT解决这些问题。

研究方法: AC-DiT引入移动底座动作表示作为上下文先验，指导整体动作预测；同时设计感知感知的多模态条件策略，动态调整2D图像与3D点云的融合权重，以适应不同阶段的感知需求。

研究结果: 实验表明，AC-DiT在模拟和真实世界的移动操作任务中均表现出色，能够有效协调移动底座与机械臂的动作，并适应多模态感知需求。

研究结论: AC-DiT通过自适应协调和多模态感知优化，显著提升了移动操作的性能，为语言条件下的机器人控制提供了新思路。

中文摘要: 近年来，移动操作因其在家庭任务中实现语言条件机器人控制的能力而受到广泛关注。然而，现有方法在协调移动底座与机械臂时仍面临挑战，主要源于两方面限制：一方面，未能显式建模移动底座对机械臂控制的影响，导致高自由度下误差累积；另一方面，将整个移动操作过程视为单一视觉观察模态（如全2D或全3D），忽视了不同阶段的多模态感知需求。为此，我们提出自适应协调扩散变换器（AC-DiT），以增强端到端移动操作中移动底座与机械臂的协调。首先，由于移动底座的运动直接影响机械臂动作，我们引入移动底座动作表示机制，指导模型先提取底座运动表示，再将其作为上下文先验预测整体动作，从而实现考虑底座运动潜在影响的整体控制。其次，为满足移动操作不同阶段的感知需求，我们设计感知感知的多模态条件策略，动态调整2D视觉图像与3D点云的融合权重，生成符合当前感知需求的视觉特征。例如，在语义信息对动作预测至关重要时，模型可自适应依赖2D输入；而在需要精确空间理解时，则更注重3D几何信息。我们通过模拟和真实世界移动操作任务的广泛实验验证了AC-DiT的有效性。

</details>
