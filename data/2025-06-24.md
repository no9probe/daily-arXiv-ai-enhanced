<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 85]
- [cs.CV](#cs.CV) [Total: 175]
- [cs.AI](#cs.AI) [Total: 50]
- [math.PR](#math.PR) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.CR](#cs.CR) [Total: 12]
- [cs.GR](#cs.GR) [Total: 8]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.DB](#cs.DB) [Total: 1]
- [eess.SY](#eess.SY) [Total: 4]
- [physics.med-ph](#physics.med-ph) [Total: 2]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.DL](#cs.DL) [Total: 2]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.RO](#cs.RO) [Total: 19]
- [cs.DC](#cs.DC) [Total: 4]
- [eess.IV](#eess.IV) [Total: 9]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 2]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [cs.CY](#cs.CY) [Total: 9]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]
- [cs.LG](#cs.LG) [Total: 86]
- [cs.SD](#cs.SD) [Total: 9]
- [cs.HC](#cs.HC) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Outcome-Based Education: Evaluating Students' Perspectives Using Transformer](https://arxiv.org/abs/2506.17223)
**中文标题：基于Transformer的成果导向教育：学生视角评估**

*Shuvra Smaran Das,Anirban Saha Anik,Md Kishor Morol,Mohammad Sakib Mahmood*

主要分类: cs.CL

摘要简述: 本研究利用基于Transformer的模型（如DistilBERT）分析学生反馈数据，结合LIME解释模型，以提升基于成果的教育（OBE）效果。结果表明，该方法能更准确地分类情感并识别学习模式，为教育实践提供数据支持。


<details>
  <summary>详细信息</summary>
研究动机: 基于成果的教育（OBE）强调通过以学生为中心的学习培养特定能力。本研究旨在利用Transformer模型分析学生反馈，评估和改进教育成果，以实现OBE的可测量目标。

研究方法: 采用DistilBERT等Transformer模型分析学生反馈数据集，结合LIME解释模型预测结果，确保模型透明性。该方法利用Transformer对语言上下文的深度理解，优于其他机器学习模型。

研究结果: 研究发现，Transformer模型与LIME解释结合能有效分类情感并识别学习模式，为教育实践提供清晰的数据驱动见解，更符合OBE原则。

研究结论: Transformer模型与LIME解释的结合为分析学生反馈提供了强大且直观的框架，有助于改进教育实践，实现OBE的可测量目标。

中文摘要: 成果导向教育（OBE）强调通过以学生为中心的学习培养特定能力。本研究回顾了OBE的重要性，并采用基于Transformer的模型（如DistilBERT）分析包含学生反馈的自然语言处理数据集，旨在评估和改进教育成果。我们的方法优于其他机器学习模型，因为它利用Transformer对语言上下文的深度理解，更准确地分类情感，并在更广泛的指标上取得更好结果。本研究直接支持OBE的可测量目标，通过识别学生学习体验中的模式。我们还应用LIME（局部可解释模型无关解释）确保模型预测的透明性，从而获得关于关键术语如何影响情感的清晰信息。研究结果表明，Transformer模型与LIME解释的结合为分析学生反馈提供了强大且直观的框架，更符合OBE原则，并通过数据驱动见解确保教育实践的改进。

</details>


### [2] [Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231)
**中文标题：通过对抗性提示蒸馏从大型语言模型到小型语言模型的高效隐蔽越狱攻击**

*Xiang Li,Chong Zhang,Jia Wang,Fangyu Wu,Yushi Li,Xiaobo Jin*

主要分类: cs.CL

摘要简述: 本文提出一种名为“对抗性提示蒸馏”的方法，通过结合掩码语言建模、强化学习和动态温度控制，使小型语言模型（SLM）能够对主流大型语言模型（LLM）进行越狱攻击。实验证明该方法在攻击成功率和危害性上表现优越，同时具备资源高效性和跨模型适应性。


<details>
  <summary>详细信息</summary>
研究动机: 当前越狱攻击方法存在效率低、计算成本高、跨模型适应性和通用性差等问题，难以应对LLM的快速发展和新防御策略。本研究旨在探索如何将LLM的越狱能力蒸馏到SLM中，揭示模型漏洞，并为LLM安全研究提供新思路。

研究方法: 提出“对抗性提示蒸馏”方法，结合掩码语言建模、强化学习和动态温度控制，通过提示生成和蒸馏技术，使SLM能够对LLM进行高效的越狱攻击。

研究结果: 实验结果表明，该方法在攻击成功率和危害性上表现优越，同时具备资源高效性和跨模型适应性。

研究结论: 本研究验证了将LLM越狱能力蒸馏到SLM的可行性，揭示了模型漏洞，为LLM安全研究提供了新方向。

中文摘要: 在越狱场景下对大型语言模型（LLM）的攻击引发了许多安全和伦理问题。当前的越狱攻击方法存在效率低、计算成本高、跨模型适应性和通用性差等问题，难以应对LLM的快速发展和新防御策略。我们的工作提出了一种“对抗性提示蒸馏”方法，通过结合掩码语言建模、强化学习和动态温度控制的提示生成与蒸馏技术，使小型语言模型（SLM）能够对主流LLM进行越狱攻击。实验结果验证了该方法在攻击成功率和危害性上的优越性，同时体现了资源高效性和跨模型适应性。本研究探索了将LLM越狱能力蒸馏到SLM的可行性，揭示了模型的漏洞，为LLM安全研究提供了新思路。

</details>


### [3] [GTA: Grouped-head latenT Attention](https://arxiv.org/abs/2506.17286)
**中文标题：GTA：分组头潜在注意力**

*Luoyang Sun,Jiwen Jiang,Cheng Deng,Xinjian Wu,Haifeng Zhang,Lei Chen,Lionel Ni,Jun Wang*

主要分类: cs.CL

摘要简述: GTA是一种新型注意力机制，通过共享注意力图和压缩值缓存，显著减少内存和计算开销，同时保持性能，提升LLM的推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有注意力机制在大型语言模型（LLM）中存在计算和内存开销大的问题，尤其是KV缓存和注意力计算随文本长度快速增加，限制了在资源有限硬件上的部署。研究发现注意力机制存在冗余，KV缓存可压缩且多头注意力图高度相似，表明大量计算和存储是不必要的。

研究方法: GTA包含两部分：1）共享注意力图机制，跨多头复用注意力分数，减少键缓存大小；2）非线性值解码器，通过学习投影将值缓存压缩到潜在空间，进一步降低内存需求。

研究结果: GTA将注意力计算FLOPs减少高达62.5%，KV缓存压缩高达70%，同时避免多头潜在注意力的额外开销，实现端到端推理速度提升2倍。

研究结论: GTA通过减少冗余计算和存储，显著提升了LLM的部署效率，为资源受限环境下的高性能模型部署提供了有效解决方案。

中文摘要: 注意力机制是大型语言模型（LLM）成功的关键，但其巨大的计算和内存开销对效率和性能优化提出了挑战。KV缓存和注意力计算随文本长度快速增加成为瓶颈，限制了在计算和内存资源有限的硬件上的部署。我们发现注意力机制存在显著冗余，KV缓存可大幅压缩且多头注意力图高度相似，表明大量计算和存储是不必要的。基于这些发现，我们提出了分组头潜在注意力（GTA），这是一种新型注意力机制，可在保持性能的同时减少内存使用和计算复杂度。GTA包含两部分：1）共享注意力图机制，跨多头复用注意力分数，减少键缓存大小；2）非线性值解码器，通过学习投影将值缓存压缩到潜在空间，进一步降低内存需求。GTA将注意力计算FLOPs减少高达62.5%，KV缓存压缩高达70%，同时避免多头潜在注意力的额外开销，从而提升LLM部署效率。因此，GTA模型实现了端到端推理速度提升2倍，预填充得益于计算成本降低，解码则受益于更小的缓存占用。

</details>


### [4] [AI-Generated Game Commentary: A Survey and a Datasheet Repository](https://arxiv.org/abs/2506.17294)
**中文标题：AI生成游戏解说：综述与数据表仓库**

*Qirui Zheng,Xingbo Wang,Keyuan Cheng,Yunlong Lu,Wenxin Li*

主要分类: cs.CL

摘要简述: 本文综述了AI生成游戏解说（AIGGC）的研究现状，提出了通用框架，分类比较了45个数据集和方法，并提供了公开的数据表仓库以支持未来研究。


<details>
  <summary>详细信息</summary>
研究动机: AI生成游戏解说（AIGGC）因其市场潜力与技术挑战备受关注，但缺乏系统性综述和标准化数据集。本文旨在填补这一空白，推动领域发展。

研究方法: 提出AIGGC的通用框架，系统综述45个现有数据集和方法，分类比较常用评估指标，并创建结构化数据表仓库。

研究结果: 总结了AIGGC领域的关键挑战与解决方案，提供了公开的数据表仓库，支持未来研究与基准测试。

研究结论: AIGGC是一个复杂的多模态NLP任务，本文的综述与数据仓库为研究者提供了重要参考，推动了该领域的标准化与进一步发展。

中文摘要: AI生成游戏解说（AIGGC）因其市场潜力与技术挑战日益受到关注。作为一种综合性的多模态自然语言处理（NLP）任务，AIGGC对语言模型提出了高要求，包括事实准确性、逻辑推理、表达性文本生成、生成速度与上下文管理。本文提出了AIGGC的通用框架，并系统综述了45个现有游戏解说数据集与方法，根据其解决的关键挑战进行分类。此外，我们还分类比较了该领域常用的评估指标。为支持未来研究与基准测试，我们提供了一个结构化数据表，总结了这些数据集的基本属性，并将其公开于开放仓库中。

</details>


### [5] [Semantic uncertainty in advanced decoding methods for LLM generation](https://arxiv.org/abs/2506.17296)
**中文标题：大型语言模型生成中高级解码方法的语义不确定性**

*Darius Foodeei,Simin Fan,Martin Jaggi*

主要分类: cs.CL

摘要简述: 本研究探讨了大型语言模型（LLM）在不同解码方法下的语义不确定性，发现结构化解码方法（如链式思维解码和推测采样）能提升语义多样性并保持输出质量。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索不同解码方法对LLM输出的语义多样性和可靠性的影响，以解决传统方法中多样性与准确性之间的权衡问题。

研究方法: 通过问答、摘要和代码生成任务实验，分析了链式思维解码（CoT）和推测采样等新兴解码方法的表现。

研究结果: 结果显示，CoT解码具有更高的语义多样性且预测熵较低，代码生成任务中Pass@2率提升48.8%；推测采样在摘要任务中表现优异，ROUGE得分更高。

研究结论: 研究表明，结构化解码方法可以同时提升语义探索和输出质量，对实际应用中需要多样性和可靠性的场景具有重要意义。

中文摘要: 本研究探讨了大型语言模型（LLM）在不同解码方法下的语义不确定性，重点关注推测采样和链式思维解码（CoT）等新兴技术。通过问答、摘要和代码生成任务的实验，分析了不同解码策略对模型输出的多样性和可靠性的影响。研究发现，尽管CoT解码显示出更高的语义多样性，但其预测熵较低，表明结构化探索可以带来更自信和准确的输出。这一点在代码生成任务中尤为明显，Pass@2率提升了48.8%，尽管与参考解决方案的匹配度较低。在摘要任务中，推测采样表现尤为突出，取得了更高的ROUGE分数，同时保持了适度的语义多样性。这些结果挑战了关于语言模型输出多样性与准确性之间权衡的传统假设，表明结构化的解码方法可以增加语义探索，同时保持或提升输出质量。这些发现对在实际应用中部署语言模型具有重要意义，尤其是在需要可靠性和多样化解生成的场景中。

</details>


### [6] [Mercury: Ultra-Fast Language Models Based on Diffusion](https://arxiv.org/abs/2506.17298)
**中文标题：Mercury：基于扩散的超快速语言模型**

*Inception Labs,Samar Khanna,Siddhant Kharbanda,Shufan Li,Harshit Varma,Eric Wang,Sawyer Birnbaum,Ziyang Luo,Yanis Miraoui,Akash Palrecha,Stefano Ermon,Aditya Grover,Volodymyr Kuleshov*

主要分类: cs.CL

摘要简述: Mercury是一种基于扩散技术的超快速大型语言模型，专为编码应用设计，提供Mini和Small两种版本，在速度和性能上均达到行业领先水平。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在速度和性能之间存在权衡，Mercury旨在通过扩散技术实现超快速且高质量的模型，满足商业规模的需求。

研究方法: Mercury基于Transformer架构，采用扩散技术并行预测多个令牌，训练出专为编码设计的模型Mercury Coder，提供Mini和Small两种版本。

研究结果: Mercury Coder在NVIDIA H100 GPU上分别达到1109和737令牌/秒的吞吐量，速度比前沿模型快10倍，同时在Copilot Arena中排名第二。

研究结论: Mercury通过扩散技术实现了速度和性能的突破，为编码应用提供了高效的解决方案，并已通过公开API和免费平台开放使用。

中文摘要: 我们介绍了Mercury，一种基于扩散技术的新一代商业规模大型语言模型（LLM）。这些模型通过Transformer架构参数化，并训练以并行预测多个令牌。本报告中，我们详细介绍了专为编码应用设计的Mercury Coder，目前提供Mini和Small两种版本。这些模型在速度与质量的前沿领域设定了新的行业标准。根据Artificial Analysis的独立评估，Mercury Coder Mini和Small在NVIDIA H100 GPU上分别实现了1109和737令牌/秒的吞吐量，速度比优化后的前沿模型快10倍，同时保持可比的质量。我们还讨论了多种代码基准测试的结果，涵盖多语言和用例，并通过Copilot Arena的开发者实际验证，该模型目前在质量上排名第二，且是整体最快的模型。我们还发布了公共API（https://platform.inceptionlabs.ai/）和免费平台（https://chat.inceptionlabs.ai）。

</details>


### [7] [PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights](https://arxiv.org/abs/2506.17314)
**中文标题：PRAISE：基于LLM的结构化洞察增强产品描述**

*Adnan Qidwai,Srija Mukhopadhyay,Prerana Khatiwada,Dan Roth,Vivek Gupta*

主要分类: cs.CL

摘要简述: PRAISE是一种利用大型语言模型（LLM）从客户评论和卖家描述中提取、比较和结构化信息的系统，帮助卖家改进产品描述并提升买家信任度。


<details>
  <summary>详细信息</summary>
研究动机: 电商中产品描述的准确性和完整性至关重要，但卖家提供的信息往往不足，而客户评论虽包含丰富细节却难以手动筛选。PRAISE旨在解决这一问题。

研究方法: PRAISE通过大型语言模型自动分析客户评论和卖家描述，提取结构化信息，并对比两者差异，以直观界面展示缺失、矛盾或不匹配的细节。

研究结果: PRAISE能够有效生成可操作的结构化信息，显著提升电商产品目录的质量和可信度。

研究结论: PRAISE通过LLM驱动的结构化分析，为卖家和买家提供了改进产品描述和评估产品可靠性的工具，具有广泛应用潜力。

中文摘要: 准确且完整的产品描述对电商至关重要，但卖家提供的信息往往不足。客户评论虽包含宝贵细节，但手动筛选费时费力。我们提出了PRAISE（产品评论属性洞察结构化引擎），这是一种利用大型语言模型（LLM）自动从客户评论和卖家描述中提取、比较和结构化信息的系统。PRAISE通过直观界面展示两者之间的缺失、矛盾或不匹配细节，并提供评论中的支持证据，帮助卖家改进产品描述的清晰度和说服力，同时让买家更好地评估产品可靠性。我们的演示展示了PRAISE的工作流程、从非结构化评论中生成可操作结构化信息的有效性，以及其显著提升电商产品目录质量和可信度的潜力。

</details>


### [8] [Towards Safety Evaluations of Theory of Mind in Large Language Models](https://arxiv.org/abs/2506.17352)
**中文标题：大型语言模型心智理论能力的安全评估研究**

*Tatsuhiro Aoshima,Mitsuaki Akiyama*

主要分类: cs.CL

摘要简述: 本文探讨了大型语言模型（LLMs）的心智理论能力及其在安全评估中的重要性，发现尽管LLMs在阅读理解上有所提升，但其心智理论能力并未同步发展。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型能力的提升，其潜在的安全风险日益凸显，尤其是模型可能表现出欺骗性行为。研究旨在评估LLMs是否具备心智理论能力，以判断其行为是否源于隐蔽的意图。

研究方法: 研究回顾了心智理论的现有研究，并分析了其在安全评估中的应用。通过一系列开放权重的LLMs，研究了心智理论能力的发展趋势。

研究结果: 结果显示，尽管LLMs在阅读理解方面有所进步，但其心智理论能力并未显著提升。

研究结论: 研究强调了评估LLMs心智理论能力的必要性，并指出了未来工作中需要解决的挑战。

中文摘要: 随着大型语言模型（LLMs）能力的不断提升，严格的安全评估显得愈发重要。近期安全评估领域的研究发现，LLMs可能表现出绕过监管机制并以欺骗方式回应的行为。例如，有报告指出，当LLMs在执行任务时遇到不利于其持续存在的信息时，可能会采取隐蔽行动，甚至对验证其行为的问题提供虚假答案。为评估此类欺骗行为对开发者或用户的潜在风险，有必要探究这些行为是否源于模型内部的隐蔽意图。本研究提出，需要测量LLMs的心智理论能力。我们首先回顾了心智理论的现有研究，并确定了其在安全评估中的应用视角和任务。鉴于心智理论主要在发展心理学背景下研究，我们分析了一系列开放权重LLMs的心智理论能力发展趋势。结果表明，尽管LLMs的阅读理解能力有所提升，但其心智理论能力并未同步发展。最后，我们总结了当前LLMs心智理论能力的安全评估现状，并讨论了未来研究中的挑战。

</details>


### [9] [Cash or Comfort? How LLMs Value Your Inconvenience](https://arxiv.org/abs/2506.17367)
**中文标题：金钱还是舒适？大型语言模型如何衡量您的不便**

*Mateusz Cedro,Timour Ichmoukhamedov,Sofie Goethals,Yifan He,James Hinns,David Martens*

主要分类: cs.CL

摘要简述: 研究发现，当前的大型语言模型（LLMs）在权衡金钱与用户舒适度时表现出不一致性和不合理性，不适合作为决策助手。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）被提议作为近乎自主的AI代理，其在个人决策中的行为尚未充分研究，尤其是在金钱与用户舒适度冲突的场景下。

研究方法: 研究通过量化多个LLMs对用户不适（如额外步行、等待、饥饿和疼痛）的定价，分析其决策行为。

研究结果: 发现LLMs存在以下问题：(1) 不同模型间差异大，(2) 同一模型对提示微小变化敏感，(3) 对重大不适接受极低报酬，(4) 无不适时拒绝高额报酬。

研究结论: 当前LLMs在权衡金钱与舒适度时表现不可靠，需进一步审查其作为决策助手的适用性。

中文摘要: 大型语言模型（LLMs）越来越多地被提议作为近乎自主的人工智能（AI）代理，能够代表人类做出日常决策。尽管LLMs在许多技术任务上表现良好，但它们在个人决策中的行为仍较少被理解。以往研究评估了其理性与人类决策的道德一致性，但AI助手在金钱奖励与用户舒适度冲突场景下的行为尚未深入探索。本文通过量化多个LLMs对一系列用户不适（额外步行、等待、饥饿和疼痛）的定价，解决了这一问题。我们发现几个关键问题严重质疑当前LLMs作为决策助手的前景：(1) 不同LLMs间响应差异大，(2) 同一LLM对提示微小变化（如以第一人称重述问题）敏感，(3) LLMs可能为重大不适接受极低报酬（如1欧元等待10小时），(4) LLMs可能拒绝无不适时的高额报酬（如1,000欧元等待0分钟）。这些发现强调需审查LLMs如何衡量人类不便，尤其是在迈向由其代表用户做出金钱与舒适度权衡的应用时。

</details>


### [10] [Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study](https://arxiv.org/abs/2506.17410)
**中文标题：利用大语言模型评估真实对话中的导师行为：可行性研究**

*Danielle R. Thomas,Conrad Borchers,Jionghao Lin,Sanjit Kakarla,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Ralph Abboud,Kenneth R. Koedinger*

主要分类: cs.CL

摘要简述: 本研究探讨了利用生成式AI（如GPT-4、Gemini-1.5-pro等）识别和评估真实数学辅导对话中导师行为的可行性，结果显示模型能高精度检测导师的表扬和错误回应行为，并与人类评估高度一致。


<details>
  <summary>详细信息</summary>
研究动机: 辅导能提升学生成绩，但如何基于音频转录大规模识别和研究与学生学习最相关的辅导行为仍是一个开放问题。本研究旨在探索生成式AI在此领域的可行性和扩展性。

研究方法: 研究分析了50份随机选择的大学导师远程辅导中学生的数学对话转录，使用GPT-4、GPT-4-turbo、Gemini-1.5-pro等模型评估导师的两项技能：有效表扬和回应学生数学错误。

研究结果: 所有模型均能高精度检测相关情境（如导师表扬学生准确率94-98%，学生错误检测率82-88%），且对导师行为的评估与人类判断高度一致（83-89%和73-77%）。

研究结论: 研究表明生成式AI可用于大规模辅导行为评估，并提出了一种经济高效的提示策略，为AI支持的真实场景评估提供了实用参考。

中文摘要: 辅导能提升学生成绩，但基于音频转录大规模识别和研究与学生学习最相关的辅导行为仍是一个开放问题。本研究探讨了利用生成式AI识别和评估真实数学辅导中导师行为的可行性和扩展性。我们分析了50份随机选择的大学导师远程辅导中学生的数学对话转录，使用GPT-4、GPT-4-turbo、Gemini-1.5-pro等模型评估导师的两项技能：有效表扬和回应学生数学错误。所有模型均能高精度检测相关情境（如导师表扬学生准确率94-98%，学生错误检测率82-88%），且对导师行为的评估与人类判断高度一致（83-89%和73-77%）。我们提出了一种经济高效的提示策略，并讨论了利用大语言模型支持真实场景评估的实践意义。本研究还贡献了支持可重复性和AI辅助学习研究的LLM提示。

</details>


### [11] [UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making](https://arxiv.org/abs/2506.17419)
**中文标题：UProp：研究大型语言模型在多步代理决策中的不确定性传播**

*Jinhao Duan,James Diffenderfer,Sandeep Madireddy,Tianlong Chen,Bhavya Kailkhura,Kaidi Xu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为UProp的框架，用于量化大型语言模型（LLM）在多步决策中的不确定性传播，将不确定性分解为内部和外部两部分，并通过实验验证其优于现有单轮不确定性量化方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）被应用于涉及多步决策的安全关键场景，了解何时信任LLM的决策变得至关重要。现有的不确定性量化方法主要针对单轮问答场景，多步决策场景的研究不足。

研究方法: 本文提出了一种基于信息论的框架，将LLM序列决策的不确定性分解为内部不确定性和外部不确定性（通过互信息量化）。UProp通过将互信息估计转化为轨迹依赖决策过程中的点互信息估计，实现了高效的外部不确定性估计。

研究结果: 实验结果表明，UProp在多步决策基准测试（如AgentBench和HotpotQA）中显著优于现有的单轮不确定性量化方法，并分析了其采样效率、潜在应用和中间不确定性传播。

研究结论: UProp为多步决策场景中的不确定性量化提供了有效解决方案，实验证明其优越性，并展示了其在安全关键应用中的潜力。

中文摘要: 随着大型语言模型（LLM）被集成到涉及现实世界中多步决策的安全关键应用中，了解何时信任LLM的决策变得至关重要。现有的LLM不确定性量化（UQ）方法主要针对单轮问答格式设计，导致多步决策场景（如LLM代理系统）的研究不足。本文提出了一种基于信息论的框架，将LLM序列决策的不确定性分解为两部分：（i）内部不确定性，即当前决策固有的不确定性（现有UQ方法的重点），以及（ii）外部不确定性，一种互信息量，描述从前序决策中应继承多少不确定性。随后，我们提出了UProp，一种高效且有效的外部不确定性估计器，将互信息的直接估计转化为在多个轨迹依赖决策过程中对点互信息的估计。UProp在广泛的多步决策基准测试（如AgentBench和HotpotQA）中进行了评估，使用了最先进的LLM（如GPT-4.1和DeepSeek-V3）。实验结果表明，UProp显著优于配备了深思熟虑聚合策略的现有单轮UQ基线。此外，我们还对UProp进行了全面分析，包括采样效率、潜在应用和中间不确定性传播，以证明其有效性。代码将在https://github.com/jinhaoduan/UProp 上提供。

</details>


### [12] [Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media](https://arxiv.org/abs/2506.17435)
**中文标题：超越链接：评估LLMs在全球媒体中分类政治内容的能力**

*Alberto Martinez-Serra,Alejandro De La Fuente,Nienke Viescher,Ana S. Cardenal*

主要分类: cs.CL

摘要简述: 本文评估了大型语言模型（LLMs）仅通过URL分类政治内容的能力，发现URL能有效嵌入新闻内容，为政治科学研究提供了成本与准确性的平衡视角。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在标注任务中表现优异，但其仅通过URL分类政治内容的效果尚未充分研究。本文旨在填补这一空白，探讨URL分析是否能替代全文分析。

研究方法: 使用GPT、Llama、Mistral等先进LLMs，对来自法、德、西、英、美五国的多语言新闻URL和文本进行分类，并与人工标注及传统监督学习方法对比。

研究结果: 研究发现URL能有效嵌入新闻内容，为政治内容分类提供了高性价比的解决方案，同时揭示了跨语言和国家的性能差异。

研究结论: URL分析可作为全文分析的有效替代，为政治科学研究提供了新的方法论建议，但需考虑上下文限制。

中文摘要: 大型语言模型（LLMs）在政治科学中的应用日益普遍，尤其是在分析数字媒体使用的场景中。然而，尽管先前研究证明了LLMs在标注任务中的能力，但仅通过URL分类政治内容（PC）的效果尚未充分探索。本文通过评估LLMs能否从文章文本和URL中准确识别PC与非PC内容（覆盖法国、德国、西班牙、英国和美国的多语言数据），填补了这一空白。使用GPT、Llama、Mistral、Deepseek、Qwen和Gemma等先进LLMs，我们测量了模型性能，以评估URL分析是否能作为全文分析的有效近似，尤其是在跨语言和国家背景下。模型输出与人工标注文章及传统监督学习方法对比，设定了性能基准。总体而言，研究发现URL能有效嵌入大部分新闻内容，为准确性-成本平衡提供了重要视角。同时，本文还探讨了上下文限制，并为政治科学研究中使用LLMs提出了方法论建议。

</details>


### [13] [Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages](https://arxiv.org/abs/2506.17459)
**中文标题：突破转录瓶颈：为极低资源田野调查语言微调ASR模型**

*Siyu Liang,Gina-Anne Levow*

主要分类: cs.CL

摘要简述: 本文评估了两种多语言ASR模型（MMS和XLS-R）在五种低资源语言上的表现，发现MMS在极少量训练数据时表现最佳，而XLS-R在数据超过一小时后性能相当。研究为语言学家提供了实用的ASR适应指南。


<details>
  <summary>详细信息</summary>
研究动机: 尽管自动语音识别（ASR）在高资源语言中表现优异，但在语言田野调查中仍面临挑战，如自发语音、环境噪声和极少量数据。本文旨在通过评估ASR模型在低资源语言中的表现，为田野语言学家提供实用解决方案。

研究方法: 研究对两种多语言ASR模型（MMS和XLS-R）在五种类型多样的低资源语言上进行微调，并控制训练数据的时长，以评估其性能差异。

研究结果: 结果显示，MMS在极少量训练数据时表现最佳，而XLS-R在训练数据超过一小时后性能与MMS相当。研究还提供了语言学分析，为田野语言学家提供实用指南。

研究结论: 研究为低资源语言的ASR应用提供了实用建议，MMS适合极少量数据场景，而XLS-R在数据量较大时表现更优，有助于缓解语言文档化中的转录瓶颈。

中文摘要: 自动语音识别（ASR）在高资源语言中已达到令人印象深刻的准确率，但在语言田野调查中的实用性仍然有限。田野调查中收集的录音面临独特挑战，包括自发语音、环境噪声以及来自未充分记录语言的极少量数据集。本文对两种微调的多语言ASR模型（MMS和XLS-R）在五种类型多样的低资源语言上进行了性能基准测试，并控制了训练数据的时长。研究发现，当训练数据极少时，MMS表现最佳，而XLS-R在训练数据超过一小时后性能与MMS相当。我们还提供了语言学分析，为田野语言学家提供实用指南，强调可复现的ASR适应方法，以缓解语言文档化中的转录瓶颈。

</details>


### [14] [Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems](https://arxiv.org/abs/2506.17467)
**中文标题：理解大型语言模型对写作和信息生态系统影响的计算方法**

*Weixin Liang*

主要分类: cs.CL

摘要简述: 本文通过三个研究方向探讨大型语言模型（LLMs）对写作和信息生态系统的影响：揭示AI检测器的系统性偏见，量化LLMs在多个写作领域的应用，以及评估LLMs在研究手稿反馈中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的快速普及正在改变写作、沟通和创作方式，但其对社会的影响尚未完全理解。本研究旨在探索LLMs对个体和机构的实际影响，特别是在公平性、应用范围和科研支持方面的潜在问题。

研究方法: 研究分为三部分：1）分析AI检测器对非主流语言使用者的系统性偏见；2）开发算法方法量化LLMs在学术评审、科学出版物、企业通讯等领域的应用；3）通过大规模实证分析评估LLMs在研究手稿反馈中的效果。

研究结果: 研究发现：1）AI检测器存在对非主流语言使用者的偏见；2）LLMs在多个写作领域中的应用显著增加；3）LLMs能够为研究人员提供有效的手稿反馈，尤其对资源匮乏的研究者有益。

研究结论: LLMs的广泛应用带来了机遇与挑战，需关注公平性和支持弱势群体。未来研究应进一步优化AI工具，确保其普惠性。

中文摘要: 大型语言模型（LLMs）已展现出改变写作、沟通和创作方式的巨大潜力，并在社会中迅速普及。本论文通过三个研究方向探讨个体和机构如何适应并利用这一新兴技术。首先，我揭示了AI检测器的系统性偏见，尤其是对非主流语言使用者的不公平对待，凸显了AI治理中的关键公平问题。其次，我提出了一种新颖的群体级算法方法，用于量化LLMs在学术评审、科学出版物、消费者投诉、企业通讯、招聘信息及国际组织新闻稿等写作领域中的应用，发现AI辅助内容的普遍存在。最后，通过大规模实证分析，我研究了LLMs在研究手稿反馈中的能力，为那些难以获得及时反馈的研究者（尤其是早期职业研究者和资源匮乏者）提供了支持的可能性。

</details>


### [15] [VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM](https://arxiv.org/abs/2506.17506)
**中文标题：VeriLocc：基于LLM的端到端跨架构寄存器分配**

*Lesheng Jin,Zhenyuan Ruan,Haohui Mai,Jingbo Shang*

主要分类: cs.CL

摘要简述: VeriLocc是一个结合大型语言模型（LLM）和形式化编译器技术的框架，用于跨GPU架构的通用且可验证的寄存器分配，显著提升性能和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现代GPU发展迅速，但生产编译器仍依赖手工调整的寄存器分配启发式方法，需要为每代硬件重新调整。VeriLocc旨在通过LLM和形式化技术实现跨架构的通用寄存器分配。

研究方法: VeriLocc通过微调LLM将中间表示（MIR）转换为目标特定的寄存器分配，结合静态分析实现跨架构归一化和泛化，并通过验证器引导的再生循环确保正确性。

研究结果: 在矩阵乘法（GEMM）和多头注意力（MHA）测试中，VeriLocc单次准确率达85-99%，pass@100接近100%，性能优于专家调优库，如rocBLAS运行时提升超10%。

研究结论: VeriLocc展示了LLM与形式化编译器技术结合在寄存器分配中的潜力，能够高效生成高性能且可验证的分配方案。

中文摘要: 现代GPU发展迅速，但生产编译器仍依赖手工调整的寄存器分配启发式方法，需为每代硬件重新调整。我们提出VeriLocc，一个结合大型语言模型（LLM）和形式化编译器技术的框架，实现跨GPU架构的通用且可验证的寄存器分配。VeriLocc通过微调LLM将中间表示（MIR）转换为目标特定的寄存器分配，辅以静态分析实现跨架构归一化和泛化，并通过验证器引导的再生循环确保正确性。在矩阵乘法（GEMM）和多头注意力（MHA）测试中，VeriLocc单次准确率达85-99%，pass@100接近100%。案例研究表明，VeriLocc发现的分配方案性能优于专家调优库，如rocBLAS运行时提升超10%。

</details>


### [16] [Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning](https://arxiv.org/abs/2506.17525)
**中文标题：多语言语音数据集中的数据质量问题：社会语言学意识与主动语言规划的必要性**

*Mingfei Lau,Qian Chen,Yeming Fang,Tingting Xu,Tongzhou Chen,Pavel Golik*

主要分类: cs.CL

摘要简述: 本文对三个广泛使用的多语言语音数据集（Mozilla Common Voice 17.0、FLEURS和VoxPopuli）进行了质量审核，发现某些语言存在显著质量问题。研究将问题分为微观和宏观两类，指出宏观问题在资源不足的语言中更为普遍，并以台湾闽南语为例，强调语言规划和数据质量控制的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 多语言语音数据集在自动语音识别（ASR）领域具有重要价值，但某些语言的数据质量存在问题，影响了其作为训练和评估集的实用性。研究旨在揭示这些问题并提出改进建议。

研究方法: 研究对三个公共多语言语音数据集进行质量审核，将问题分为微观和宏观两类，并以台湾闽南语为例进行案例分析，探讨语言规划和数据质量控制的作用。

研究结果: 研究发现，宏观质量问题在资源不足的语言中更为普遍，尤其是缺乏语言规划的语言。台湾闽南语的案例表明，主动的语言规划和严格的数据质量控制是解决这些问题的关键。

研究结论: 研究提出了一系列建议，强调在未来的数据集开发中需要增强社会语言学意识，实施语言规划和严格的质量控制，以确保语音数据资源的可靠性和鲁棒性。

中文摘要: 我们对三个广泛使用的公共多语言语音数据集（Mozilla Common Voice 17.0、FLEURS和VoxPopuli）进行了质量审核，发现某些语言存在显著的质量问题。解决这些问题将使这些数据集更适合作为训练和评估集，并提升下游模型的性能。我们将这些问题分为微观和宏观两类，发现宏观问题在制度化程度较低、资源不足的语言中更为普遍。通过对台湾闽南语（nan_tw）的案例分析，我们强调了主动语言规划（如正字法规范、方言边界定义）和增强数据质量控制在自动语音识别（ASR）数据集创建过程中的必要性。最后，我们提出了缓解这些问题的指导原则和建议，强调了社会语言学意识在创建稳健可靠的语音数据资源中的重要性。

</details>


### [17] [DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning](https://arxiv.org/abs/2506.17533)
**中文标题：DuaShepherd：结合逐步正确性与潜在奖励的数学推理方法**

*Yuanhao Wu,Juntong Song,Hanning Zhang,Tong Zhang,Cheng Niu*

主要分类: cs.CL

摘要简述: 本文提出DuaShepherd框架，通过结合正确性和潜力两种奖励信号，提升大语言模型的数学推理能力，并在多个基准测试中取得显著性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在数学推理任务中表现有限，主要依赖单一奖励信号（如正确性）。本文旨在通过结合正确性和潜力两种互补奖励信号，提升模型的推理能力和最终答案的准确性。

研究方法: 提出DuaShepherd框架，构建自动化流程生成包含两种奖励信号的大规模数据集，并采用多任务学习的统一多头部架构训练模型。通过将两种信号结合为复合概率，优化模型性能。

研究结果: 在MATH500和ProcessBench等基准测试中，DuaShepherd显著优于仅依赖单一奖励信号的模型，并在相同资源条件下达到最优性能。

研究结论: DuaShepherd通过整合正确性和潜力奖励信号，有效提升了大语言模型的数学推理能力，为复杂推理任务提供了新的解决方案。

中文摘要: 本文提出DuaShepherd，一种新颖的奖励建模框架，通过整合两种互补的奖励信号（正确性和潜力）来增强大语言模型（LLMs）的数学推理能力。正确性信号侧重于逐步错误的识别，而潜力信号则关注最终答案的正确可能性。我们开发了一个自动化流程，用于构建包含这两种信号的大规模奖励建模数据集。通过探索统一的多头部架构，在多任务设置中训练这两种奖励模型，展示了同时学习正确性和潜力的优势。通过将这两种信号结合为复合概率，我们的模型在多个基准测试中实现了持续的性能提升。在MATH500和ProcessBench上的实证评估表明，这种组合奖励显著优于仅依赖单一奖励类型的模型，并在可比资源条件下达到最优性能。

</details>


### [18] [Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception](https://arxiv.org/abs/2506.17542)
**中文标题：自监督语音表征中的音系特征探究：以口音感知为例**

*Nitin Venkateswaran,Kevin Tang,Ratree Wayland*

主要分类: cs.CL

摘要简述: 本文通过自监督学习模型探究语音表征如何编码影响口音感知的音系特征，发现特定音段的自监督表征特征能有效预测口音强度，突显了音系特征在口音感知中的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 传统口音感知模型低估了音系特征梯度变化的作用，本文旨在研究自监督学习模型如何编码这些特征，以更好地理解口音感知机制。

研究方法: 使用CSLU外国口音英语语料库，提取三个音段的音系特征概率，并结合Wav2Vec2-BERT和WavLM的自监督表征，通过探测分析和多项逻辑回归研究口音评分的预测关系。

研究结果: 结果显示，口音强度可通过音段的自监督表征特征子集预测，其中感知显著的音系特征对口音评分有显著影响，且与基线距离的关联性符合预期方向。

研究结论: 自监督语音表征为基于可解释音系特征的口音感知建模提供了重要价值，揭示了音系特征在口音判断中的关键作用。

中文摘要: 传统口音感知模型低估了音系特征梯度变化的作用，而听者正是依赖这些变化进行口音判断。本文研究了当前自监督学习（SSL）语音模型如何编码影响音段口音感知的音系特征变化。我们聚焦于三个音段：唇齿近音、闪音和卷舌塞音，这些音段在印度次大陆的英语母语者中表现一致。使用CSLU外国口音英语语料库（Lander，2007），我们通过Phonet（Vásquez-Correa等，2019）提取这些音段的音系特征概率，并结合Wav2Vec2-BERT（Barrault等，2023）和WavLM（Chen等，2022）的自监督表征及美国英语母语者的口音评分。探测分析表明，口音强度可通过音段自监督表征特征的子集最佳预测，其中感知显著的音系特征（对比美国英语预期与非母语英语实际音段）被赋予显著权重。基于自监督表征的音段距离与美国和印度英语基线的多项逻辑回归显示，口音评分与基线距离的关联性在预期方向上表现出强相关性。这些结果凸显了自监督语音表征在利用可解释音系特征建模口音感知中的价值。

</details>


### [19] [AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition](https://arxiv.org/abs/2506.17578)
**中文标题：AgriCHN：一个全面的跨领域中文农业命名实体识别资源**

*Lingxiao Zeng,Yiqi Tong,Wei Guo,Huarui Wu,Lihao Ge,Yijun Ye,Fuzhen Zhuang,Deqing Wang,Wei Guo,Cheng Chen*

主要分类: cs.CL

摘要简述: AgriCHN是一个高质量的中文农业命名实体识别数据集，涵盖27类农业实体，并整合水文和气象实体，显著提升了农业信息提取的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏高质量的中文农业命名实体识别数据集，且现有研究多忽略农业与水文、气象的关联。AgriCHN填补了这一空白，旨在提升农业实体标注的自动化水平。

研究方法: AgriCHN从大量农业文章中精心筛选4040个句子，标注15799个农业实体，涵盖27类实体，并整合水文和气象数据。通过验证数据质量，并利用前沿神经NER模型构建基准任务。

研究结果: 实验表明，AgriCHN数据质量高，实体类型丰富且划分细致，为农业命名实体识别研究提供了重要资源，同时展示了其挑战性和研究潜力。

研究结论: AgriCHN是一个全面且高质量的中文农业命名实体识别数据集，为农业信息提取和相关领域研究提供了重要支持。

中文摘要: 农业命名实体识别是一项专注于从大量文本中识别农业实体（如作物、病害、害虫和肥料）的任务，对提升农业文本信息提取至关重要。然而，高质量的中文农业数据集稀缺，导致主流方法表现不佳。现有研究多仅标注农业实体，而忽略了农业与水文、气象的关联。为此，我们提出了AgriCHN，一个全面的开源中文资源，旨在提升农业实体自动标注的准确性。AgriCHN数据集从大量农业文章中精选4040个句子，标注15799个农业实体，涵盖27类实体，并整合水文和气象实体，丰富了实体多样性。数据验证表明，AgriCHN因更丰富的实体类型和更细致的划分而表现出色。我们还利用前沿神经NER模型构建了基准任务，实验结果凸显了AgriCHN的挑战性和研究潜力。

</details>


### [20] [Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages](https://arxiv.org/abs/2506.17603)
**中文标题：注意差距：评估维基词典中众包语言知识对两种相关语言形态空缺的描述**

*Jonathan Sakunkoo,Annabella Sakunkoo*

主要分类: cs.CL

摘要简述: 本研究通过定制神经形态分析器验证了维基词典中拉丁语和意大利语的形态空缺数据，发现意大利语数据高度可靠，但拉丁语有7%的词条被误标为非空缺，揭示了众包数据在未被充分研究语言中的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 形态空缺是语言学中一个有趣但研究不足的现象，对提升形态丰富语言的NLP工具准确性至关重要。传统资源往往缺乏对形态空缺的覆盖，而维基词典等众包资源的可靠性存在争议，因此需要验证其数据质量。

研究方法: 研究定制了一种神经形态分析器，用于标注拉丁语和意大利语语料库，并利用大规模标注数据计算验证维基词典中众包整理的形态空缺动词列表。

研究结果: 结果显示，维基词典对意大利语形态空缺的描述高度可靠，但拉丁语中有7%被标记为空缺的词条在语料库中表现出非空缺的证据，揭示了众包数据在未被充分研究语言中的局限性。

研究结论: 尽管众包资源对罕见语言特征具有价值，但其作为语言学知识的权威来源存在局限性，特别是在未被充分研究的语言和现象中。本研究通过提供可扩展的工具和方法，推动了计算形态学的发展，并扩展了对非英语形态丰富语言中形态空缺的认知。

中文摘要: 形态空缺是语言学中一个引人注目但研究不足的现象。解决形态空缺问题（即预期屈折形式缺失的情况）对提升形态丰富语言的NLP工具准确性至关重要。然而，传统语言学资源往往缺乏对形态空缺的覆盖，因为这类知识需要大量人力和专业知识来记录和验证。对于未被充分探索语言中的稀缺语言现象，维基百科和维基词典通常是少数可访问的资源之一。尽管它们覆盖面广，但其可靠性一直存在争议。本研究定制了一种新型神经形态分析器，用于标注拉丁语和意大利语语料库。利用大规模标注数据，计算验证了维基词典中众包整理的形态空缺动词列表。结果表明，尽管维基词典对意大利语形态空缺的描述高度可靠，但拉丁语中有7%被标记为空缺的词条在语料库中表现出非空缺的证据。这种差异凸显了众包维基作为语言学知识权威来源的潜在局限性，尤其是在未被充分研究的现象和语言中，尽管它们对罕见语言特征具有价值。通过提供可扩展的工具和方法来保证众包数据的质量，本研究推动了计算形态学的发展，并扩展了对非英语形态丰富语言中形态空缺的认知。

</details>


### [21] [TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting](https://arxiv.org/abs/2506.17609)
**中文标题：TyphoFormer：语言增强的Transformer模型用于精准台风路径预测**

*Lincan Li,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

主要分类: cs.CL

摘要简述: TyphoFormer是一种结合自然语言描述的Transformer模型，通过语言增强提升台风路径预测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 台风路径预测对早期预警和灾害响应至关重要。传统Transformer模型在稀疏气象轨迹（如台风路径）预测中缺乏上下文知识，TyphoFormer通过语言描述弥补这一不足。

研究方法: TyphoFormer利用大型语言模型（LLM）生成台风数值属性的自然语言描述，并将其作为特殊标记嵌入Transformer编码器，结合文本和序列信息进行预测。

研究结果: 在HURDAT2基准测试中，TyphoFormer表现优于其他先进方法，尤其在非线性路径变化和历史数据有限的情况下。

研究结论: TyphoFormer通过语言增强显著提升了台风路径预测的准确性，为气象预测提供了新思路。

中文摘要: 准确的台风路径预测对早期系统预警和灾害响应至关重要。尽管基于Transformer的模型在智能城市中密集轨迹（如人类和车辆）的时间动态建模中表现出色，但它们通常缺乏对稀疏气象轨迹（如台风路径）预测所需的上下文知识。为解决这一问题，我们提出TyphoFormer，一种新颖的框架，通过引入自然语言描述作为辅助提示来改进台风轨迹预测。在每个时间步，我们使用大型语言模型（LLM）基于北大西洋飓风数据库中的数值属性生成简洁的文本描述。这些语言描述捕捉了高级气象语义，并作为特殊标记嵌入数值时间序列输入中。通过将文本和序列信息整合到统一的Transformer编码器中，TyphoFormer使模型能够利用仅通过数值特征无法获取的上下文线索。在HURDAT2基准测试中进行了大量实验，结果表明TyphoFormer始终优于其他最先进的基线方法，尤其是在涉及非线性路径变化和历史观测有限的挑战性场景中。

</details>


### [22] [OpusLM: A Family of Open Unified Speech Language Models](https://arxiv.org/abs/2506.17611)
**中文标题：OpusLM：一个开放统一语音语言模型家族**

*Jinchuan Tian,William Chen,Yifan Peng,Jiatong Shi,Siddhant Arora,Shikhar Bharadwaj,Takashi Maekaku,Yusuke Shinohara,Keita Goto,Xiang Yue,Huck Yang,Shinji Watanabe*

主要分类: cs.CL

摘要简述: 本文介绍了OpusLM系列开放统一语音语言模型，通过从纯文本语言模型初始化，并在大量语音-文本对和纯文本数据上进行预训练，实现了在语音识别、语音合成和纯文本任务上的优异性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前语音语言模型（SpeechLMs）的研究缺乏开放性和透明度，且性能有待提升。本文旨在开发一个基于公开材料的开放统一语音语言模型家族，推动开放研究。

研究方法: OpusLM系列模型从纯文本语言模型初始化，通过多阶段训练策略，结合213K小时的语音-文本对和292B的纯文本数据进行预训练，并采用多流语言模型设计。

研究结果: 实验表明，OpusLM在语音识别、语音合成和纯文本任务上表现优异，甚至超越现有SpeechLMs。模型规模扩展和数据选择策略对性能有显著影响。

研究结论: OpusLM系列模型基于公开材料构建，性能优越且完全透明，为开放语音语言模型研究提供了重要资源。

中文摘要: 本文介绍了开放统一语音语言模型（OpusLMs），这是一个规模高达7B的开放基础语音语言模型家族。OpusLMs从仅解码器的纯文本语言模型初始化，并在213K小时的语音-文本对和292B的纯文本标记上持续预训练。我们展示了OpusLMs在语音识别、语音合成和纯文本能力上与现有SpeechLMs相当（甚至更优）的性能。技术上，本文详细阐述了我们在分词、多流语言模型和多阶段训练策略上的设计。实验证明了模型规模扩展和数据选择退火的重要性。OpusLMs完全基于公开材料构建，是完全透明的模型。我们发布了代码、数据、检查点和训练日志，以促进开放SpeechLM研究。

</details>


### [23] [Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs](https://arxiv.org/abs/2506.17630)
**中文标题：答案中心还是推理驱动？揭示LLMs中的潜在记忆锚点**

*Yang Wu,Yifan Zhang,Yiwei Wang,Yujun Cai,Yurong Wu,Yuran Wang,Ning Xu,Jian Cheng*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLMs）更多依赖记忆的答案模式而非真实推理，通过五级答案可见性提示框架验证了其对显式答案的强烈依赖。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs展现出强大的推理能力，但越来越多的证据表明其成功可能源于记忆的答案-推理模式而非真实推理。本文旨在探究LLMs是否主要依赖于最终答案或推理链的文本模式。

研究方法: 提出一个五级答案可见性提示框架，通过系统性地操纵答案线索并间接分析模型行为，验证LLMs对显式答案的依赖程度。

研究结果: 实验显示，当答案线索被掩盖时，即使推理链完整，LLMs的性能仍下降26.90%，表明其推理可能更多是事后合理化而非真实推理。

研究结论: 研究揭示了LLMs对答案的锚定现象，并强调需要更细致地理解LLMs的推理本质。

中文摘要: 尽管大型语言模型（LLMs）展现出令人印象深刻的推理能力，但越来越多的证据表明其成功可能源于记忆的答案-推理模式而非真实推理。本文研究了一个核心问题：LLMs是否主要依赖于最终答案或推理链的文本模式？我们提出了一个五级答案可见性提示框架，通过系统性地操纵答案线索并间接分析模型行为。实验表明，即使在推理链完整的情况下，当答案线索被掩盖时，性能下降了26.90%。这些发现表明，LLMs展现的推理可能更多是事后合理化而非真实推理，对其推理深度提出了质疑。本研究通过严格的实证验证揭示了答案锚定现象，并强调需要更细致地理解LLMs的推理本质。

</details>


### [24] [Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation](https://arxiv.org/abs/2506.17637)
**中文标题：Step-Opt：通过迭代数据合成与结构化验证提升LLMs的优化建模能力**

*Yang Wu,Yifan Zhang,Yurong Wu,Yuran Wang,Junkai Zhang,Jian Cheng*

主要分类: cs.CL

摘要简述: 本文提出Step-Opt-Instruct框架，通过迭代生成问题和逐步验证数据，提升LLMs在优化建模任务中的性能，并在多个基准测试中取得显著效果。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在优化建模任务中面临复杂问题处理的挑战，现有数据集难以满足需求，亟需一种高效的数据生成和验证方法。

研究方法: Step-Opt-Instruct框架通过迭代生成逐步复杂的问题，并结合逐步验证确保数据质量，随后对开源LLMs（如LLaMA-3-8B和Mistral-7B）进行微调。

研究结果: Step-Opt在NL4OPT、MAMO和IndustryOR等基准测试中表现优异，尤其在复杂任务上实现了17.01%的微平均准确率提升。

研究结论: 结合结构化验证和逐步问题优化的方法显著提升了LLMs在优化建模任务中的性能，为决策自动化提供了有效支持。

中文摘要: 大型语言模型（LLMs）在多个领域取得了革命性进展，但在处理运筹学（OR）中的复杂优化建模任务时仍面临重大挑战。本文提出Step-Opt-Instruct框架，通过迭代生成问题和逐步验证数据，为优化建模任务生成高质量的微调数据。该框架通过逐步增加问题复杂度和严格验证数据质量，避免错误传播并确保生成数据集的可靠性。基于此框架，我们对开源LLMs（如LLaMA-3-8B和Mistral-7B）进行微调，开发出Step-Opt模型。该模型在NL4OPT、MAMO和IndustryOR等基准测试中达到了最先进的性能，尤其在复杂OR任务上实现了17.01%的微平均准确率提升。实验结果表明，结合结构化验证和逐步问题优化的方法能够有效提升LLMs在决策自动化中的应用效果。代码和数据集已开源：https://github.com/samwu-learn/Step。

</details>


### [25] [TPTT: Transforming Pretrained Transformer into Titans](https://arxiv.org/abs/2506.17671)
**中文标题：TPTT：将预训练Transformer转化为泰坦**

*Fabien Furfaro*

主要分类: cs.CL

摘要简述: TPTT是一种新型框架，通过高效线性化注意力机制和先进内存管理技术增强预训练Transformer模型，显著提升大语言模型的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型（LLMs）在自然语言处理中取得了显著进展，但其计算和内存需求仍是长期上下文推理的主要挑战。TPTT旨在解决这一问题。

研究方法: TPTT采用Memory as Gate（MaG）和混合线性化注意力（LiZA）技术，并与Hugging Face Transformers库完全兼容，支持通过参数高效微调（LoRA）无缝适配任何因果LLM。

研究结果: 在MMLU基准测试中，TPTT在约10亿参数的模型上表现出显著提升，如Titans-Llama-3.2-1B的Exact Match（EM）分数比基线提高了20%。

研究结论: TPTT展示了实际可扩展性和鲁棒性，为高效利用预训练Transformer模型提供了实用解决方案。

中文摘要: 近年来，大语言模型（LLMs）在自然语言处理领域取得了显著进展，但其计算和内存需求仍是长期上下文推理的主要挑战。我们提出了TPTT（将预训练Transformer转化为泰坦），这是一种新型框架，通过高效线性化注意力机制和先进内存管理技术增强预训练Transformer模型。TPTT采用Memory as Gate（MaG）和混合线性化注意力（LiZA）等技术，并与Hugging Face Transformers库完全兼容，支持通过参数高效微调（LoRA）无缝适配任何因果LLM，而无需完全重新训练。我们在MMLU基准测试中验证了TPTT的有效性，使用约10亿参数的模型观察到效率和准确性的显著提升。例如，Titans-Llama-3.2-1B的Exact Match（EM）分数比基线提高了20%。统计分析及与最新方法的比较证实了TPTT的实际可扩展性和鲁棒性。代码发布于https://github.com/fabienfrfr/tptt，Python包发布于https://pypi.org/project/tptt/。

</details>


### [26] [Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering](https://arxiv.org/abs/2506.17692)
**中文标题：资源友好的动态增强链用于多跳问答**

*Binquan Ji,Haibo Luo,Yifei Lu,Lei Hei,Jiaqi Wang,Tingjing Liao,Lingyu Wang,Shichao Wang,Feiliang Ren*

主要分类: cs.CL

摘要简述: 本文提出了一种名为DEC（动态增强链）的新框架，用于解决知识密集型多跳问答任务中的幻觉和语义漂移问题。DEC通过分解复杂问题为逻辑连贯的子问题，并利用轻量级关键词提取模块实现高效检索，显著降低了计算开销，并在资源受限环境中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 知识密集型多跳问答任务需要从多个来源整合证据，但轻量级语言模型在处理大量文档和扩展上下文时容易产生幻觉和语义漂移。本文旨在设计一种资源友好的框架，既能高效完成任务，又能减少计算开销。

研究方法: DEC框架首先将复杂问题分解为逻辑连贯的子问题，形成无幻觉的推理链；然后通过上下文感知的重写迭代优化子问题。此外，引入轻量级判别性关键词提取模块，利用关键词实现精准文档召回，降低计算开销。

研究结果: 在三个多跳问答数据集上的实验表明，DEC的性能与或优于现有最佳基准，同时显著减少令牌消耗。特别是在8B参数模型上取得了最佳结果，展示了其在资源受限环境中的有效性。

研究结论: DEC框架通过动态增强链和轻量级关键词提取，有效解决了多跳问答任务中的幻觉和语义漂移问题，显著提升了资源利用率，适用于资源受限场景。

中文摘要: 知识密集型多跳问答（QA）任务需要通过整合多源证据来解决复杂查询，通常需要大型语言模型（LLM）进行多轮检索和迭代生成。然而，处理大量文档和扩展上下文对参数较少的轻量级LLM提出了挑战，例如幻觉和语义漂移。本文提出了一种名为DEC（动态增强链）的新框架。DEC首先将复杂问题分解为逻辑连贯的子问题，形成无幻觉的推理链；然后通过上下文感知的重写迭代优化这些子问题以生成有效的查询表述。在检索方面，我们引入了一种轻量级判别性关键词提取模块，利用提取的关键词实现目标明确、精确的文档召回，同时计算开销较低。在三个多跳问答数据集上的广泛实验表明，DEC的性能与或优于现有最佳基准，同时显著减少令牌消耗。值得注意的是，我们的方法在8B参数模型上取得了最佳结果，展示了其在各种场景中的有效性，尤其是在资源受限的环境中。

</details>


### [27] [Zero-Shot Conversational Stance Detection: Dataset and Approaches](https://arxiv.org/abs/2506.17693)
**中文标题：零样本对话立场检测：数据集与方法**

*Yuzhe Ding,Kang He,Bobo Li,Li Zheng,Haijun He,Fei Li,Chong Teng,Donghong Ji*

主要分类: cs.CL

摘要简述: 本文提出了一种零样本对话立场检测方法，构建了大规模数据集ZS-CSD，并设计了SITPCL模型，在零样本设置下取得了先进性能，但仍面临挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有对话立场检测数据集局限于特定目标，无法应对现实应用中大量未见目标的需求，因此需要构建零样本数据集并开发相应模型。

研究方法: 手动构建了包含280个目标的ZS-CSD数据集，并提出SITPCL模型，结合说话者交互和目标感知的原型对比学习。

研究结果: SITPCL在零样本对话立场检测中表现最佳，但F1-macro得分仅为43.81%，显示任务仍具挑战性。

研究结论: 研究为零样本对话立场检测提供了数据集和模型基准，但性能提升仍需进一步探索。

中文摘要: 立场检测旨在利用社交媒体数据识别公众对特定目标的观点，是一项重要但具有挑战性的任务。随着社交媒体用户在线辩论的增加，对话立场检测成为关键研究领域。然而，现有对话立场检测数据集局限于少量特定目标，限制了模型在现实应用中面对大量未见目标时的有效性。为填补这一空白，我们手动构建了一个大规模、高质量的零样本对话立场检测数据集ZS-CSD，涵盖两种目标类型的280个目标。基于ZS-CSD数据集，我们提出了SITPCL模型，一种结合说话者交互和目标感知的原型对比学习方法，并在零样本设置下建立了基准性能。实验结果表明，SITPCL在零样本对话立场检测中取得了先进性能。值得注意的是，SITPCL模型的F1-macro得分仅为43.81%，凸显了零样本对话立场检测的持续挑战。

</details>


### [28] [The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future](https://arxiv.org/abs/2506.17700)
**中文标题：自然语言处理的演进：提示优化与语言模型如何塑造未来**

*Summra Saleem,Muhammad Nabeel Asim,Shaista Zulfiqar,Andreas Dengel*

主要分类: cs.CL

摘要简述: 本文综述了提示优化策略在自然语言处理（NLP）中的潜力，将其分为11类，并分析了其在多种NLP任务中的应用，为未来研究提供了统一评估框架。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有许多关于提示工程的综述文章，但对提示优化策略的全面分析仍存在空白。本文旨在填补这一空白，为NLP领域的研究者提供系统化的提示优化策略知识。

研究方法: 本文通过分析提示优化策略的工作原理，将其分为11类，并详细探讨了这些策略在不同NLP任务中的应用，包括使用的语言模型和基准数据集。

研究结果: 研究结果表明，提示优化策略能显著提升NLP任务的性能，并为未来的比较研究和实验评估提供了统一的基础。

研究结论: 本文为提示优化策略的系统化研究奠定了基础，有助于推动创新预测模型在未探索任务中的应用。

中文摘要: 大型语言模型（LLM）通过自动化传统劳动密集型任务，彻底改变了自然语言处理（NLP）领域，并加速了计算机辅助应用的发展。随着研究人员不断引入新颖的语言模型和更高效的训练/微调方法，提示工程及其优化策略已成为显著提升NLP任务性能的重要趋势。尽管已有许多关于提示工程的综述文章，但对提示优化策略的全面分析仍存在空白。为填补这一空白，本文提供了关于多种提示优化策略潜力的独特且全面的见解。文章分析了这些策略的基本工作原理，并基于这些原理将其分为11类。此外，本文还详细介绍了这些提示优化策略在多种NLP任务中的应用，以及用于评估的不同LLM和基准数据集。这一全面的汇编为未来的比较研究奠定了坚实基础，并在一致的实验设置下实现了对提示优化和基于LLM的预测流程的严格评估：这是当前研究中的关键需求。最终，本研究将集中多样化的策略知识，促进现有提示优化策略在未探索任务中创新预测模型的开发。

</details>


### [29] [Aged to Perfection: Machine-Learning Maps of Age in Conversational English](https://arxiv.org/abs/2506.17708)
**中文标题：完美年龄：机器学习对英语会话中年龄的映射**

*MingZe Tang*

主要分类: cs.CL

摘要简述: 研究利用英国国家语料库2014，通过机器学习和计算语言分析，探索不同年龄段英语使用者的语言特征，并构建预测模型以估计说话者的年龄组。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在揭示不同年龄段说话者在语言使用上的差异，探索人口统计学特征与语言因素（如话语时长、词汇多样性和词汇选择）之间的关系。

研究方法: 使用英国国家语料库2014的大规模当代英国口语样本，结合计算语言分析和机器学习方法，分析不同年龄组的语言模式，并构建预测模型。

研究结果: 研究发现不同年龄组在语言使用上存在显著差异，并成功构建了能够根据语言特征预测说话者年龄组的模型。

研究结论: 该研究为现代英国口语的社会语言多样性提供了新的见解，展示了机器学习在语言年龄分析中的潜力。

中文摘要: 本研究利用英国国家语料库2014，一个大规模的当代英国口语样本，探讨不同年龄组的语言模式。研究试图揭示不同年龄组之间语言模式的差异，探索说话者人口统计学特征与语言因素（如话语时长、词汇多样性和词汇选择）之间的联系。通过结合计算语言分析和机器学习方法，我们试图揭示多代人特有的语言标记，并构建能够从多个方面一致估计说话者年龄组的预测模型。这项工作为我们理解现代英国口语在社会语言学多样性方面的知识做出了贡献。

</details>


### [30] [Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages](https://arxiv.org/abs/2506.17715)
**中文标题：揭示增强词性标注的关键因素：低资源中世纪罗曼语研究**

*Matthias Schöffel,Esteban Garces Arias,Marinus Wiedner,Paula Ruppert,Meimingwei Li,Christian Heumann,Matthias Aßenmacher*

主要分类: cs.CL

摘要简述: 本研究探讨了低资源中世纪罗曼语（如中世纪奥克语、西班牙语和法语）的词性标注性能关键因素，揭示了大型语言模型在处理历史语言变体和非标准化拼写时的局限性，并提出了一些有效的专门技术。


<details>
  <summary>详细信息</summary>
研究动机: 尽管现代大型语言模型在古语言处理方面取得了显著进展，但在处理中世纪罗曼语时仍面临历时语言演变、拼写变体和标注数据稀缺等独特挑战。本研究旨在系统分析这些挑战并探索提升词性标注性能的方法。

研究方法: 研究通过实验评估了微调方法、提示工程、模型架构、解码策略和跨语言迁移学习技术对中世纪奥克语、西班牙语和法语文本词性标注准确性的影响。

研究结果: 结果显示，大型语言模型在处理历史语言变体和非标准化拼写时存在显著局限性，但也发现了一些能够有效应对低资源历史语言挑战的专门技术。

研究结论: 研究强调了针对低资源历史语言的专门技术的重要性，并为进一步改进中世纪罗曼语的词性标注提供了方向。

中文摘要: 词性标注（POS）仍然是自然语言处理流程中的基础组成部分，尤其对计算语言学与数字人文交叉领域的历史文本分析至关重要。尽管现代大型语言模型（LLMs）在古语言处理方面取得了显著进展，但其在中世纪罗曼语中的应用仍面临历时语言演变、拼写变体和标注数据稀缺等独特挑战。本研究系统分析了中世纪奥克语、西班牙语和法语文本中词性标注性能的关键决定因素，涵盖圣经、圣徒传记、医学和饮食等多个领域。通过严格的实验，我们评估了微调方法、提示工程、模型架构、解码策略和跨语言迁移学习技术对标注准确性的影响。结果显示，大型语言模型在处理历史语言变体和非标准化拼写时存在显著局限性，但也发现了一些能够有效应对低资源历史语言挑战的专门技术。

</details>


### [31] [KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process](https://arxiv.org/abs/2506.17728)
**中文标题：KAG-Thinker：教授大语言模型以人类思维过程进行推理**

*Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo*

主要分类: cs.CL

摘要简述: 本文提出KAG-Thinker框架，通过模拟人类认知机制，提升大语言模型在领域知识问答任务中的逻辑连贯性和上下文一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有大语言模型在复杂问题推理中缺乏逻辑连贯性和上下文一致性，KAG-Thinker旨在通过模拟人类结构化思维过程解决这一问题。

研究方法: KAG-Thinker采用广度分解将复杂问题拆分为可独立解决的子问题，并通过逻辑函数接口明确建模依赖关系。在解决过程中，分别使用检索、数学和推理功能完成任务，并通过知识边界模型和深度解决模型优化知识获取。

研究结果: 实验表明，KAG-Thinker显著提升了模型在领域知识问答任务中的表现，逻辑连贯性和上下文一致性得到明显改善。

研究结论: KAG-Thinker通过结构化推理框架有效提升了大语言模型的推理能力，为复杂问题处理提供了新思路。

中文摘要: 本文介绍了KAG-Thinker，一种基于参数轻量化大语言模型（LLM）的新型人类推理框架。该方法通过建立结构化思维过程，提升了LLM在领域知识库（KB）问答任务中的逻辑连贯性和上下文一致性。该框架延续了KAG v0.7的逻辑形式引导检索与推理技术路线，首先通过广度分解将复杂问题拆分为可独立解决的子问题（即逻辑形式），每个子问题以自然语言和逻辑函数两种等价形式表示，并进一步分类为知识检索或推理分析任务，通过逻辑函数接口明确建模依赖关系和变量传递。在解决过程中，检索功能用于执行知识检索任务，而数学和推理功能用于执行推理分析任务。其次，在知识检索子任务中，LLM和外部知识源被视为等效的知识库，通过知识边界模型结合自信校准和反思推理等自调节机制确定最优知识源，并通过深度解决模型提升知识获取的全面性。最后，我们采用监督微调而非强化学习，通过多轮对话将模型与结构化推理范式对齐，避免过度反思。这一过程得到数据评估框架和迭代语料合成的支持，有助于生成详细的推理轨迹。

</details>


### [32] [HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations](https://arxiv.org/abs/2506.17748)
**中文标题：HIDE与Seek：通过解耦表示检测语言模型中的幻觉**

*Anwoy Chatterjee,Yash Goel,Tanmoy Chakraborty*

主要分类: cs.CL

摘要简述: 本文提出了一种名为HIDE的单次训练无关方法，通过解耦表示检测语言模型中的幻觉内容，实验表明其在多种模型和数据集上优于其他单次方法，并接近多次方法的性能，同时计算成本更低。


<details>
  <summary>详细信息</summary>
研究动机: 当代语言模型虽然流畅，但常生成与输入上下文不符或事实错误的内容（即幻觉），且这些内容难以检测，降低了模型的可靠性。现有方法多依赖多次生成，计算成本高，因此需要一种高效的单次检测方法。

研究方法: HIDE方法基于幻觉源于模型内部输入上下文与生成输出的统计解耦假设，通过Hilbert-Schmidt独立性准则（HSIC）量化隐藏状态表示的解耦程度，实现单次检测。

研究结果: 在四个问答数据集和六个开源语言模型上的实验表明，HIDE在几乎所有设置中优于其他单次方法，AUC-ROC平均提升约29%，且与多方法性能相当，计算时间减少51%。

研究结论: HIDE通过利用语言模型内部表示的解耦特性，实现了高效且实用的幻觉检测，为提升语言模型可靠性提供了新思路。

中文摘要: 当代语言模型（LMs）虽然流畅性令人印象深刻，但常生成与输入上下文不符或事实错误的内容——这一关键问题通常被称为“幻觉”。语言模型生成幻觉内容的倾向削弱了其可靠性，尤其是因为这些虚构内容通常极具说服力，难以检测。尽管现有方法尝试检测幻觉，但大多依赖对每个输入进行多次生成分析，导致计算成本和延迟增加。为此，我们提出了一种单次、无需训练的方法——通过解耦表示进行有效幻觉检测（HIDE）。该方法基于幻觉源于语言模型内部输入上下文与生成输出的统计解耦假设，通过Hilbert-Schmidt独立性准则（HSIC）量化生成输出序列时提取的隐藏状态表示的解耦程度。我们在四个多样化问答数据集上进行了广泛实验，评估了六种不同规模和特性的开源语言模型中的忠实性和事实性幻觉。结果表明，HIDE在几乎所有设置中优于其他单次方法，AUC-ROC平均相对提升约29%。此外，HIDE与多方法性能相当甚至更优，AUC-ROC平均相对提升约3%，同时计算时间减少约51%。我们的研究结果表明，利用语言模型内部表示的解耦特性，可以实现高效且实用的幻觉检测。

</details>


### [33] [Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights](https://arxiv.org/abs/2506.17789)
**中文标题：从印度语言视角看多语言分词：挑战与洞见**

*N J Karthika,Maharaj Brahma,Rohit Saluja,Ganesh Ramakrishnan,Maunendra Sankar Desarkar*

主要分类: cs.CL

摘要简述: 本文对17种印度语言的分词策略进行了全面评估，探讨了BPE和Unigram LM算法的权衡、词汇量大小的影响，以及联合和基于集群的多语言词汇构建策略，发现低资源语言可从高资源语言的Tokenizer中受益。


<details>
  <summary>详细信息</summary>
研究动机: 现有Tokenizer偏向高资源语言，对印度等语言多样且形态丰富的地区效果有限，需研究更公平高效的多语言分词方法。

研究方法: 对17种印度语言进行分词策略评估，比较BPE和Unigram LM算法，分析词汇量大小和多语言词汇构建策略（联合与集群训练）。

研究结果: 低资源语言可通过高资源语言的Tokenizer提升效果，不同算法和词汇量对分词效果有显著影响。

研究结论: 研究为构建更公平、高效且符合语言学特点的多语言Tokenizer提供了实用见解。

中文摘要: 分词在多语言NLP中至关重要，但现有Tokenizer常偏向高资源语言，对印度等语言多样且形态丰富的地区效果有限。本文对17种印度语言的分词策略进行了全面评估，量化了BPE和Unigram LM算法的权衡、词汇量大小的影响，并比较了联合和基于集群的多语言词汇构建策略。研究表明，极低资源语言可从相关高资源语言的Tokenizer中受益。本研究为构建更公平、高效且符合语言学特点的多语言Tokenizer提供了实用见解。

</details>


### [34] [THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction](https://arxiv.org/abs/2506.17844)
**中文标题：THCM-CAL：基于时间层次因果建模与置信校准的临床风险预测**

*Xin Zhang,Qiyu Wei,Yingjie Zhu,Fanyi Wu,Sophia Ananiadou*

主要分类: cs.CL

摘要简述: THCM-CAL是一种结合时间层次因果建模与置信校准的临床风险预测方法，通过多模态因果图建模诊断代码和文本笔记的交互，提升预测可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有临床风险预测方法多模态融合策略简单，忽略了诊断与文本笔记间的层次因果交互，THCM-CAL旨在解决这一问题。

研究方法: THCM-CAL构建多模态因果图，建模临床实体的层次因果交互，并扩展置信预测至多标签ICD编码以校准置信区间。

研究结果: 在MIMIC-III和MIMIC-IV数据集上，THCM-CAL表现优于现有方法。

研究结论: THCM-CAL通过层次因果建模和置信校准，显著提升了临床风险预测的准确性和可靠性。

中文摘要: 自动化临床风险预测需同时处理电子健康记录中的结构化诊断代码和非结构化文本笔记。然而，现有方法多单独处理这些模态或采用简单融合策略，忽略了文本观察引发诊断及跨入院风险传播的层次因果交互。本文提出THCM-CAL，一种结合时间层次因果建模与置信校准的框架。该框架构建多模态因果图，节点代表两种模态的临床实体：从笔记提取的文本命题和映射为文本描述的ICD代码。通过层次因果发现，THCM-CAL推断三种临床交互：同模态序列、跨模态触发和跨切片风险传播。为提升预测可靠性，我们将置信预测扩展至多标签ICD编码，校准复杂共现下的每代码置信区间。在MIMIC-III和MIMIC-IV上的实验结果验证了THCM-CAL的优越性。

</details>


### [35] [LLMs for Customized Marketing Content Generation and Evaluation at Scale](https://arxiv.org/abs/2506.17863)
**中文标题：基于大语言模型的规模化定制营销内容生成与评估**

*Haoran Liu,Amir Tahmasbi,Ehtesham Sam Haque,Purak Jain*

主要分类: cs.CL

摘要简述: 本文提出MarketingFM系统，通过整合多数据源生成定制化广告文案，显著提升点击率和成本效率。同时，开发AutoEval-Main和AutoEval-Update系统，结合规则与LLM技术，减少人工审核成本，保持高质量评估。


<details>
  <summary>详细信息</summary>
研究动机: 当前电商外部营销内容过于模板化，与落地页匹配度低，效果不佳。需开发自动化系统生成精准广告文案，并解决人工审核成本高的问题。

研究方法: 1. 提出MarketingFM系统，整合多数据源生成关键词定制广告文案。2. 开发AutoEval-Main，结合规则与LLM技术自动评估广告质量。3. 提出AutoEval-Update框架，动态优化评估提示，减少人工干预。

研究结果: MarketingFM使广告点击率提升9%，展示量增加12%，单次点击成本降低0.38%。AutoEval-Main与人工评估一致率达89.57%，AutoEval-Update进一步优化评估一致性。

研究结论: 自动化系统显著提升广告效果和评估效率，但人工监督仍为关键，需设定阈值并验证改进。

中文摘要: 外部营销在电商中至关重要，但当前内容过于模板化且与落地页匹配度低。为此，我们提出MarketingFM系统，通过整合多数据源生成关键词定制广告文案，减少人工干预。通过线下和线上测试验证，关键词定制文案点击率提升9%，展示量增加12%，单次点击成本降低0.38%。为解决人工审核成本高的问题，我们开发了AutoEval-Main系统，结合规则与LLM技术实现自动化评估，与人工评估一致率达89.57%。进一步提出AutoEval-Update框架，动态优化评估提示，减少人工输入。实验表明，该系统能显著提升评估一致性，但人工监督仍不可或缺。

</details>


### [36] [QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs](https://arxiv.org/abs/2506.17864)
**中文标题：QueueEDIT：LLMs连续模型编辑中的结构自校正方法**

*Taolin Zhang,Haidong Kang,Dongyang Li,Qizhou Chen,Chengyu Wang Xiaofeng He,Richang Hong*

主要分类: cs.CL

摘要简述: 本文提出了一种基于队列的自校正框架QueueEDIT，用于在大型语言模型（LLMs）的连续编辑中提升性能并减少对模型通用能力的负面影响。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）虽然表现出色，但仍存在幻觉问题。连续模型编辑（SME）旨在持续修正错误，但传统方法可能因引入新参数而损害模型的通用能力。

研究方法: QueueEDIT通过结构映射编辑损失将知识三元组映射到LLMs的Transformer层中的知识敏感神经元，并将编辑参数存储在队列中动态对齐。每次编辑时选择相关队列参数进行知识对齐，冻结无关参数并更新队列头部参数。

研究结果: 实验表明，QueueEDIT在多种SME设置中显著优于基线方法，并在单次编辑中保持竞争力，同时在整个SME过程中保持了LLMs在通用NLP任务中的高性能。

研究结论: QueueEDIT有效提升了连续模型编辑的性能，同时减少了参数偏差对LLMs通用能力的负面影响。

中文摘要: 近年来，大型语言模型（LLMs）表现出令人印象深刻的结果，但仍存在幻觉问题。模型编辑被提出用于修正LLMs中的事实错误。连续模型编辑（SME）旨在持续修正错误，而非一次性任务。在SME过程中，新参数的引入可能对LLMs的通用能力产生负面影响。本文提出了一种基于队列的自校正框架（QueueEDIT），不仅通过解决长序列依赖问题提升了SME性能，还缓解了参数偏差对LLMs通用能力的影响。具体而言，我们首先引入结构映射编辑损失，将知识三元组映射到LLMs的Transformer层中的知识敏感神经元。随后，将每段编辑知识的定位参数存储在队列中，并动态对齐先前编辑的参数。每次编辑时，选择与当前定位参数最相关的队列参数以判断是否需要重新对齐知识。队列中无关的参数被冻结，同时更新队列头部参数到LLM中，以确保其不损害通用能力。实验表明，我们的框架在多种SME设置中显著优于强基线方法，并在单次编辑中保持竞争力。生成的LLMs在整个SME过程中也保持了在通用NLP任务中的高能力。

</details>


### [37] [How Alignment Shrinks the Generative Horizon](https://arxiv.org/abs/2506.17871)
**中文标题：对齐如何缩小生成视野**

*Chenghao Yang,Ari Holtzman*

主要分类: cs.CL

摘要简述: 研究发现，对齐的大语言模型（LLM）输出多样性降低，原因是生成过程中概率分布集中。通过引入分支因子（BF）量化这种集中，发现对齐调整显著降低BF，使模型更稳定，尤其在复杂推理任务中表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 尽管对齐的大语言模型（LLM）能力强大，但其输出往往缺乏多样性。本文旨在探究这种稳定性的驱动因素，并量化其对生成过程的影响。

研究方法: 引入分支因子（BF）作为量化指标，衡量生成过程中有效下一步的数量。通过实验分析BF的变化及其与对齐调整的关系，并探讨其对复杂推理任务的影响。

研究结果: 1. 生成过程中BF逐渐降低，模型变得更可预测。2. 对齐调整显著降低BF（如从12降至1.2），使输出更稳定。3. 对齐的思维链（CoT）模型通过生成长推理链进入低BF阶段，输出更稳定。

研究结论: 对齐调整并未改变模型行为，而是引导其选择低熵路径。BF是理解和控制LLM输出的有力工具，揭示了对齐如何减少多样性、CoT如何促进稳定生成。

中文摘要: 尽管能力强大，对齐的大语言模型（LLM）输出往往缺乏多样性。本文通过模型输出分布的概率集中现象探究这一稳定性。为量化这种集中，我们引入分支因子（BF）——一种衡量生成过程中有效下一步数量的指标。实证分析揭示两点关键发现：（1）BF随生成过程逐渐降低，表明LLM生成时变得更可预测。（2）对齐调整从一开始就显著锐化输出分布，使BF降低近一个数量级（如从12降至1.2）。这一大幅降低解释了为何对齐模型对解码策略不敏感。进一步发现，这种稳定性对复杂推理有意外影响。例如，对齐的思维链（CoT）模型（如DeepSeek蒸馏模型）利用此效应，通过生成长推理链进入后期低BF阶段，输出更稳定。我们假设对齐调整并未根本改变模型行为，而是引导其选择风格化标记（如“当然”），解锁基模型中已有的低熵路径。这一观点得到提示实验支持，表明用此类标记提示基模型同样可降低BF。综上，BF是理解和控制LLM输出的有力诊断工具，阐明了对齐如何减少变异性、CoT如何促进稳定生成，以及如何引导基模型远离多样性。

</details>


### [38] [Multi-turn Jailbreaking via Global Refinement and Active Fabrication](https://arxiv.org/abs/2506.17881)
**中文标题：通过全局优化和主动伪造实现多轮越狱**

*Hua Tang,Lingyong Yan,Yukun Zhao,Shuaiqiang Wang,Jizhou Huang,Dawei Yin*

主要分类: cs.CL

摘要简述: 本文提出了一种新颖的多轮越狱方法，通过全局优化和主动伪造模型响应，显著提高了在复杂对话中诱导大型语言模型生成有害内容的成功率。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在广泛任务中表现出色，但其潜在的安全风险不容忽视。现有越狱技术主要针对单轮场景，而复杂的多轮场景研究不足。本文旨在填补这一空白，解决多轮对话中动态变化的挑战。

研究方法: 提出一种多轮越狱方法，通过全局优化越狱路径，并在对话中主动伪造模型响应以抑制安全警告，从而增加后续问题中诱导有害内容的可能性。

研究结果: 实验结果表明，该方法在六种先进的大型语言模型上均优于现有的单轮和多轮越狱技术。

研究结论: 本文提出的方法在多轮越狱场景中表现出色，为识别和缓解大型语言模型的安全风险提供了新思路。

中文摘要: 大型语言模型（LLMs）在广泛任务中表现卓越，但仍存在因恶意使用而引发的重大安全风险。越狱技术旨在诱导模型生成有害内容，对识别潜在安全威胁至关重要。现有研究主要关注单轮场景，而更复杂的多轮场景尚未充分探索。此外，现有多轮越狱技术难以适应对话的动态变化。为解决这一问题，我们提出了一种新颖的多轮越狱方法，通过全局优化越狱路径，并主动伪造模型响应以抑制安全警告，从而提高后续问题中诱导有害输出的概率。实验结果表明，该方法在六种先进的大型语言模型上均优于现有的单轮和多轮越狱技术。代码已公开于https://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication。

</details>


### [39] [Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation](https://arxiv.org/abs/2506.17949)
**中文标题：基于散射的创新传播在大语言模型中的多阶段过程适应**

*Hong Su*

主要分类: cs.CL

摘要简述: 本文提出了一种基于散射的创新传播模型，帮助大语言模型在多阶段过程中扩展局部创新，提升其泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在预训练中表现出强大的模式复制和扩展能力，但在将局部创新推广到多阶段过程的其他部分时存在困难。本文旨在解决这一问题。

研究方法: 提出了一种四步创新散射模型：(1) 通过比较用户输入与上下文识别核心创新；(2) 通过去除特定阶段或组件的引用泛化创新；(3) 判断泛化后的创新是否适用于更广范围；(4) 利用大语言模型将其系统性地应用于结构相似的其他阶段。

研究结果: 验证结果表明，创新散射模型能够帮助大语言模型将创新扩展到结构相似的阶段，从而提升泛化和重用能力。

研究结论: 创新散射模型通过利用阶段间的结构冗余，有效提升了大语言模型在多阶段过程中推广局部创新的能力。

中文摘要: 大语言模型（LLMs）在重现和扩展预训练中观察到的模式方面表现出强大的能力，但往往难以将新颖的想法推广到原始上下文之外。本文解决了将此类局部创新（在特定阶段或组件中引入）应用于多阶段过程其他部分的挑战。我们提出了一种基于散射的创新扩展模型（创新散射模型），通过四个步骤引导大语言模型：(1) 通过比较用户输入与其周围上下文识别核心创新；(2) 通过去除特定阶段或组件的引用泛化创新；(3) 判断泛化后的创新是否适用于原始阶段之外的更广范围；(4) 利用大语言模型将其系统性地应用于结构相似的其他阶段。该模型利用阶段间的结构冗余，提高了新颖想法的适用性。验证结果表明，创新散射模型能够帮助大语言模型将创新扩展到结构相似的阶段，从而提升泛化和重用能力。

</details>


### [40] [A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment](https://arxiv.org/abs/2506.17951)
**中文标题：基于模式寻求偏好对齐的全面图框架在问答系统中的应用**

*Quanwei Tang,Sophia Yat Mei Lee,Junshuang Wu,Dong Zhang,Shoushan Li,Erik Cambria,Guodong Zhou*

主要分类: cs.CL

摘要简述: 本文提出GraphMPA，一种基于图的框架，通过模式寻求偏好对齐提升问答系统中大语言模型的性能，实验证明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管检索增强生成（RAG）技术提升了问答系统中大语言模型的能力，但在全局理解和符合人类伦理及质量偏好方面仍存在挑战。

研究方法: GraphMPA通过构建分层文档图模拟人类认知过程，并引入模式寻求偏好优化，通过概率匹配约束使模型输出更符合人类偏好。

研究结果: 在六个数据集上的实验验证了GraphMPA的有效性。

研究结论: GraphMPA通过图框架和偏好对齐显著提升了问答系统的性能，为未来研究提供了新方向。

中文摘要: 检索增强生成（RAG）的最新进展通过整合外部知识提升了大语言模型在问答系统中的表现。然而，在实现全局理解及使回答符合人类伦理和质量偏好方面仍存在挑战。为此，我们提出GraphMPA，一种基于图的全面框架，具备模式寻求偏好对齐功能。该方法通过通用相似性度量构建分层文档图，模拟人类认知过程以理解和综合信息。此外，我们引入模式寻求偏好优化，通过概率匹配约束使模型输出更符合人类偏好。在六个数据集上的大量实验证明了GraphMPA的有效性。

</details>


### [41] [PDF Retrieval Augmented Question Answering](https://arxiv.org/abs/2506.18027)
**中文标题：基于PDF检索增强的问答系统**

*Thi Thu Uyen Hoang,Viet Anh Nguyen*

主要分类: cs.CL

摘要简述: 本文提出了一种基于检索增强生成（RAG）框架的问答系统，用于从PDF文件中提取多模态信息，解决传统QA系统难以处理非文本内容的挑战。


<details>
  <summary>详细信息</summary>
研究动机: PDF文件中包含丰富的多模态数据（如文本、图像、图表等），而现有问答系统主要针对文本内容设计，难以有效处理复杂多模态问题。本文旨在开发一种全面的RAG框架，以提升对PDF中多模态信息的提取和问答能力。

研究方法: 通过改进PDF中非文本内容的处理与集成方法，将多模态数据融入RAG框架，并微调大型语言模型以适应系统需求。

研究结果: 实验表明，该系统能够从PDF中准确提取多模态信息，并回答复杂问题，为多模态数据集成和处理提供了新思路。

研究结论: 本研究不仅拓展了检索增强问答系统的边界，还为多模态数据集成和处理的研究奠定了基础。

中文摘要: 本文提出了一种基于检索增强生成（RAG）框架的问答系统，用于从PDF文件中提取多模态信息。PDF文件包含丰富的文本、图像、矢量图、图表和表格等数据，这对主要针对文本内容设计的现有问答系统提出了独特挑战。我们致力于开发一种全面的RAG问答系统，以有效解决结合多种数据类型的复杂多模态问题。主要通过改进PDF中非文本内容的处理与集成方法，将其融入RAG框架以获取精确答案，并微调大型语言模型以适应系统需求。我们通过深入的实验评估展示了该方案的能力，证明其能够从PDF中提取准确信息并应用于不同类型的内容。这一工作不仅推动了检索增强问答系统的边界，还为多模态数据集成和处理的研究奠定了基础。

</details>


### [42] [Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices](https://arxiv.org/abs/2506.18035)
**中文标题：Splitformer：一种改进的边缘设备自动语音识别早期退出架构**

*Maxence Lasbordes,Daniele Falavigna,Alessio Brutti*

主要分类: cs.CL

摘要简述: 本文提出了一种改进的早期退出架构Splitformer，用于边缘设备上的自动语音识别，通过引入并行层处理下采样输入，显著提升了性能，同时仅小幅增加模型参数且不影响推理时间。


<details>
  <summary>详细信息</summary>
研究动机: 边缘设备资源有限且动态变化，需要动态调整神经网络计算负载。早期退出架构虽能通过中间分支减少计算，但现有高效架构（如Zipformer）缺乏模块化设计以支持早期退出分支。

研究方法: 提出Splitformer架构，在标准处理层基础上引入并行层，处理输入的下采样版本，从而提升性能并保持推理时间不变。

研究结果: 在标准语音识别基准测试中，Splitformer显著提升了性能，仅小幅增加模型参数，且未影响推理时间。

研究结论: Splitformer通过结合并行层与早期退出机制，为边缘设备上的语音识别提供了高效解决方案。

中文摘要: 在资源受限且动态变化的边缘设备场景中，动态调整神经网络推理计算负载的能力至关重要。早期退出架构通过中间分支减少计算层数，是一种优雅而有效的解决方案。然而，现有高效架构（如Zipformer）虽通过中间层的下采样/上采样操作减少计算量，但缺乏支持早期退出分支的模块化设计。为提升早期退出模型的性能，本文提出在架构中引入并行层处理输入的下采样版本。实验表明，该方法显著提升了标准语音识别基准的性能，仅小幅增加模型参数且不影响推理时间。

</details>


### [43] [Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models](https://arxiv.org/abs/2506.18036)
**中文标题：马尔可夫增强聚类用于长文档摘要：利用大语言模型解决‘中间信息丢失’挑战**

*Aziz Amari,Mohamed Achref Ben Ammar*

主要分类: cs.CL

摘要简述: 本文提出了一种结合提取式和生成式摘要的混合方法，通过分块、聚类和马尔可夫链图解决大语言模型在长文档摘要中‘中间信息丢失’的问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着信息爆炸式增长，自动文本摘要需求激增。大语言模型在生成式摘要中表现优异，但在处理长文档时容易丢失关键信息（‘中间信息丢失’问题），亟需一种高效且保留关键信息的方法。

研究方法: 方法分为四步：1) 将文档分块；2) 对块向量嵌入进行聚类；3) 为每个聚类生成摘要；4) 通过马尔可夫链图选择语义顺序，构建最终摘要。

研究结果: 该方法有效解决了长文档摘要中的‘中间信息丢失’问题，生成更连贯且保留关键信息的摘要。

研究结论: 结合提取式和生成式摘要的混合方法，通过分块、聚类和马尔可夫链图，显著提升了长文档摘要的质量和效率。

中文摘要: 信息源的快速扩展加剧了对高效自动文本摘要的需求，摘要方法主要分为提取式（从原文选择关键片段）和生成式（通过重述内容生成摘要）。大语言模型推动了生成式摘要的发展，但其资源消耗大且在长文档中易丢失关键信息（称为‘中间信息丢失’）。为解决这一问题，我们提出了一种结合提取式和生成式技术的混合摘要方法：将文档分块、聚类其向量嵌入、为每个聚类生成代表关键思想的摘要，并通过马尔可夫链图选择语义顺序构建最终摘要。

</details>


### [44] [Statistical Multicriteria Evaluation of LLM-Generated Text](https://arxiv.org/abs/2506.18082)
**中文标题：LLM生成文本的统计多准则评估**

*Esteban Garces Arias,Hannah Blocher,Julian Rodemann,Matthias Aßenmacher,Christoph Jansen*

主要分类: cs.CL

摘要简述: 本文提出了一种基于广义随机优势（GSD）的统计多准则评估框架，用于解决LLM生成文本质量评估中的单指标局限性、自动指标与人工判断的不兼容性以及缺乏统计推断保证的问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估LLM生成文本质量的方法通常依赖单一指标或简单聚合，无法捕捉文本在连贯性、多样性、流畅性等多维度的权衡。本文旨在解决现有方法的三大局限性：单指标评估不足、自动指标与人工判断的不兼容性以及缺乏统计推断保证。

研究方法: 本文采用广义随机优势（GSD）框架，通过部分排序解码策略，避免对多指标进行任意加权，实现跨多维度同时评估，同时考虑不同测量尺度。

研究结果: 通过将GSD框架应用于常见解码策略与人工生成文本的对比，结果表明该方法能够识别统计显著的性能差异，并考虑了采样设计中可能偏离i.i.d.假设的情况。

研究结论: GSD框架为LLM生成文本的多维质量评估提供了一种统计可靠的方法，解决了现有评估方法的局限性。

中文摘要: 评估LLM生成文本的质量仍然是自然语言处理中的一个基本挑战。当前的评估方法通常依赖于孤立的指标或简单的聚合，无法捕捉文本在连贯性、多样性、流畅性等多维度的权衡。本文采用了一种基于广义随机优势（GSD）的统计推断框架，解决了现有基准方法的三大关键局限性：单指标评估不足、自动指标与人工判断的不兼容性以及缺乏统计推断保证。GSD-front方法能够在多维度同时评估文本质量，同时尊重不同测量尺度，通过部分排序解码策略避免对指标的任意加权。通过将该框架应用于常见解码策略与人工生成文本的对比，我们证明了其在识别统计显著性能差异方面的能力，同时考虑了采样设计中可能偏离i.i.d.假设的情况。

</details>


### [45] [Evaluating Prompt-Based and Fine-Tuned Approaches to Czech Anaphora Resolution](https://arxiv.org/abs/2506.18091)
**中文标题：基于提示工程与微调模型的捷克语指代消解方法对比评估**

*Patrik Stano,Aleš Horák*

主要分类: cs.CL

摘要简述: 本文比较了基于提示工程和微调模型在捷克语指代消解任务中的表现，发现微调模型（如mT5-large）在准确率和计算资源消耗上均优于提示工程方法。


<details>
  <summary>详细信息</summary>
研究动机: 指代消解在自然语言理解中至关重要，尤其是在形态丰富的语言如捷克语中。本文旨在比较两种现代方法（提示工程和微调模型）在捷克语指代消解任务中的表现，以确定更优的解决方案。

研究方法: 研究使用来自布拉格依存树库的数据集，评估了多种指令调优的大语言模型（如Mistral Large 2和Llama 3）的提示工程方法，并与专门针对捷克语指代消解任务微调的mT5和Mistral模型进行对比。

研究结果: 实验结果显示，提示工程方法在少样本场景下表现尚可（最高74.5%准确率），但微调模型（尤其是mT5-large）显著优于前者，最高达到88%准确率，且计算资源需求更低。

研究结论: 微调模型在捷克语指代消解任务中表现更优，尤其是在准确率和计算效率方面。提示工程方法虽有一定潜力，但需进一步优化。

中文摘要: 指代消解在自然语言理解中具有关键作用，尤其是在捷克语等形态丰富的语言中。本文对比了两种现代方法在捷克语指代消解任务中的表现：基于大语言模型（LLM）的提示工程与微调紧凑生成模型。研究使用来自布拉格依存树库的数据集，评估了多种指令调优的LLM（如Mistral Large 2和Llama 3）的提示模板效果，并将其与专门针对捷克语指代消解任务微调的mT5和Mistral模型进行对比。实验表明，提示工程方法在少样本场景下表现尚可（最高74.5%准确率），但微调模型（尤其是mT5-large）显著优于前者，最高达到88%准确率，且计算资源需求更低。研究还分析了不同指代类型、先行词距离和语料来源对性能的影响，揭示了两种方法的关键优势和权衡。

</details>


### [46] [InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating](https://arxiv.org/abs/2506.18102)
**中文标题：InspireDebate：基于多维主客观评估引导的辩论推理与优化**

*Fuyu Wang,Jiangtong Li,Kun Zhu,Changjun Jiang*

主要分类: cs.CL

摘要简述: 本文提出了一种双组件框架InspireDebate，通过多维评估和优化方法提升辩论系统的性能。InspireScore评估系统结合主客观指标，而InspireDebate通过分阶段优化显著提升了辩论效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于大语言模型的辩论系统主要关注特定论点的回应，而忽略了事实真实性和逻辑有效性等客观评估，且缺乏多维度的优化方法。本文旨在解决这些问题。

研究方法: 提出双组件框架：(1) InspireScore，结合四项主观标准（情感吸引力、论点清晰度、论点安排、主题相关性）和两项客观指标（事实真实性和逻辑有效性）的多维评估系统；(2) InspireDebate，通过分阶段优化（链式思维推理增强、多维直接偏好优化、基于网络的检索增强生成）提升辩论性能。

研究结果: 实验表明，InspireScore与专家判断的相关性比现有方法高44%，而InspireDebate的性能显著提升，优于基线模型57%。

研究结论: 本文提出的多维评估和优化框架显著提升了辩论系统的性能，为未来研究提供了重要参考。

中文摘要: 随着大语言模型（LLMs）的快速发展，辩论任务（如论点质量评估和辩论过程模拟）取得了显著进展。然而，现有的基于LLM的辩论系统主要关注对特定论点的回应，而忽略了事实真实性和逻辑有效性等客观评估。此外，这些系统缺乏在多维度（包括评估指标、链式思维推理和多轮辩论优化）上的结构化优化方法，从而限制了其有效性。为解决这些相互关联的挑战，我们提出了一种双组件框架：(1) InspireScore，一种新颖的评估系统，建立了包含四项主观标准（情感吸引力、论点清晰度、论点安排和主题相关性）和两项客观指标（事实真实性和逻辑有效性）的多维评估架构；(2) InspireDebate，一种优化的辩论框架，通过链式思维推理增强、多维直接偏好优化（DPO）和基于网络的检索增强生成（Web-RAG）实现分阶段优化。实证评估表明，InspireScore与专家判断的相关性比现有方法高44%，而InspireDebate表现出显著改进，优于基线模型57%。源代码可在https://github.com/fywang12/InspireDebate获取。

</details>


### [47] [Chengyu-Bench: Benchmarking Large Language Models for Chinese Idiom Understanding and Use](https://arxiv.org/abs/2506.18105)
**中文标题：Chengyu-Bench：评估大语言模型对中文成语理解与使用的基准测试**

*Yicheng Fu,Zhemin Huang,Liuxin Yang,Yumeng Lu,Zhongdongming Dai*

主要分类: cs.CL

摘要简述: 论文介绍了Chengyu-Bench，一个用于评估大语言模型对中文成语理解和使用的综合性基准测试，包含三项任务：情感评价、使用恰当性和开放填空。测试结果显示，模型在情感评价任务中表现优异，但在使用恰当性和开放填空任务中仍有较大提升空间。


<details>
  <summary>详细信息</summary>
研究动机: 中文成语（成语）是蕴含丰富历史文化的四字表达，其字面翻译往往无法完全体现其含义。现有基准测试仅关注狭窄任务，如选择题填空或简单释义，缺乏对成语全面理解和使用的评估。因此，论文提出Chengyu-Bench，旨在填补这一空白。

研究方法: Chengyu-Bench包含三项任务：1）情感评价（判断成语的情感倾向）；2）使用恰当性（检测成语在上下文中的错误使用）；3）开放填空（在无选项的长文中填空）。基准测试包含2,937个人工验证的示例，涵盖1,765个常见成语。

研究结果: 测试结果显示，领先的大语言模型在情感评价任务中准确率超过95%，但在使用恰当性任务中约为85%，开放填空任务中仅为40%左右。错误分析表明，大多数错误源于对成语含义的根本误解。

研究结论: Chengyu-Bench表明，尽管大语言模型能可靠评估成语情感倾向，但在理解文化和上下文细微差别方面仍有不足。该基准测试为未来研究提供了重要工具。

中文摘要: 中文成语（成语）是蕴含丰富历史文化的四字表达，其字面翻译往往无法完全体现其含义。这种复杂性使得语言模型难以正确理解和运用成语。现有基准测试仅关注狭窄任务，如选择题填空、孤立翻译或简单释义。我们提出了Chengyu-Bench，一个包含三项任务的综合性基准测试：1）情感评价（判断成语的情感倾向）；2）使用恰当性（检测成语在上下文中的错误使用）；3）开放填空（在无选项的长文中填空）。Chengyu-Bench包含2,937个人工验证的示例，涵盖1,765个常见成语，数据来源多样。我们对领先的大语言模型进行了评估，发现它们在情感评价任务中准确率超过95%，但在使用恰当性任务中约为85%，开放填空任务中仅为40%左右。错误分析表明，大多数错误源于对成语含义的根本误解。Chengyu-Bench表明，尽管大语言模型能可靠评估成语情感倾向，但在理解文化和上下文细微差别方面仍有不足。基准测试和源代码可在以下网址获取：https://github.com/sofyc/ChengyuBench。

</details>


### [48] [Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives](https://arxiv.org/abs/2506.18116)
**中文标题：LLMs中的心理健康公平性：利用多跳问答检测放大和沉默的观点**

*Batool Haider,Atmika Gorti,Aman Chadha,Manas Gaur*

主要分类: cs.CL

摘要简述: 本文提出了一种多跳问答框架（MHQA），用于检测大型语言模型（LLMs）在心理健康领域中的偏见，揭示了模型在情感、人口统计和心理健康条件上的系统性差异，并通过两种去偏技术显著减少了偏见。


<details>
  <summary>详细信息</summary>
研究动机: 心理健康领域的大型语言模型可能传播偏见，加剧对边缘群体的污名化。现有研究缺乏系统性检测交叉偏见的方法，因此本文旨在填补这一空白。

研究方法: 研究使用多跳问答框架（MHQA）分析IMHI数据集中的症状表现、应对机制和治疗方案，通过年龄、种族、性别和社会经济地位的系统性标注，检测模型在人口交叉点的偏见模式。评估了Claude 3.5 Sonnet、Jamba 1.6、Gemma 3和Llama 4四种模型。

研究结果: 研究发现LLMs在情感、人口统计和心理健康条件上存在系统性差异，MHQA方法在偏见检测上优于传统方法。通过角色扮演模拟和显性偏见减少技术，偏见减少了66-94%。

研究结论: 研究揭示了LLMs在心理健康领域中的偏见放大点，为开发公平的AI提供了可行建议。

中文摘要: 心理健康领域的大型语言模型（LLMs）可能传播偏见，加剧对边缘群体的污名化。尽管已有研究揭示了相关趋势，但系统性检测交叉偏见的方法仍然有限。本研究提出了一种多跳问答（MHQA）框架，用于探索LLMs在心理健康讨论中的响应偏见。我们分析了可解释心理健康指令（IMHI）数据集中的症状表现、应对机制和治疗方案，通过年龄、种族、性别和社会经济地位的系统性标注，研究了人口交叉点的偏见模式。评估了四种LLMs：Claude 3.5 Sonnet、Jamba 1.6、Gemma 3和Llama 4，揭示了在情感、人口统计和心理健康条件上的系统性差异。MHQA方法在偏见检测上优于传统方法，能够识别通过序列推理放大的偏见点。我们实施了两种去偏技术：角色扮演模拟和显性偏见减少，通过BBQ数据集的少样本提示实现了66-94%的偏见减少。这些发现揭示了LLMs在心理健康领域中的偏见复制点，为公平AI开发提供了可行见解。

</details>


### [49] [The Syntactic Acceptability Dataset (Preview): A Resource for Machine Learning and Linguistic Analysis of English](https://arxiv.org/abs/2506.18120)
**中文标题：《句法可接受性数据集（预览版）：英语机器学习和语言分析的资源》**

*Tom S Juzek*

主要分类: cs.CL

摘要简述: 本文介绍了《句法可接受性数据集（预览版）》，这是一个为句法和计算语言学研究设计的资源，包含1000个英语序列，标注了语法状态和可接受性状态。初步分析显示语法性和可接受性判断在83%的情况下一致，机器学习模型在预测可接受性方面表现更好。


<details>
  <summary>详细信息</summary>
研究动机: 动机是为句法和计算语言学领域提供一个公开可用的资源，用于研究语法性和可接受性之间的关系，并支持机器学习模型的开发。

研究方法: 方法包括从教科书和《Linguistic Inquiry》期刊中收集1000个英语序列，标注其语法状态（基于文献）和可接受性状态（通过众包实验）。初步分析聚焦于语法性和可接受性的一致性以及机器学习模型的预测能力。

研究结果: 结果显示语法性和可接受性判断在83%的情况下一致，且机器学习模型在预测可接受性方面表现优于语法性预测。

研究结论: 结论是当前数据集是同类中最大的公开资源，未来工作将扩展数据集以支持更深入的研究。

中文摘要: 我们介绍了《句法可接受性数据集（预览版）》，这是一个为句法和计算语言学研究设计的资源。当前数据集包含1000个英语序列，其中一半来自教科书，另一半来自《Linguistic Inquiry》期刊，以确保当代话语的代表性。每个条目标注了从文献中提取的语法状态（“形式句法的良好性”）和通过众包实验获得的可接受性状态（“母语者的直觉判断”）。即使在初步阶段，该数据集仍是同类中最大的公开资源。我们还提供了初步分析，涉及语言学和计算语言学中的三个争议：我们发现语法性和可接受性判断在约83%的情况下一致，且“中间状态”频繁出现，这与现有研究一致。此外，机器学习模型在预测语法性方面表现不佳，但在预测可接受性方面表现较好，这是一个新发现。未来工作将专注于扩展数据集。

</details>


### [50] [$φ^{\infty}$: Clause Purification, Embedding Realignment, and the Total Suppression of the Em Dash in Autoregressive Language Models](https://arxiv.org/abs/2506.18129)
**中文标题：Error**

*Bugra Kilictas,Faruk Alpay*

主要分类: cs.CL

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [51] [Sparse Feature Coactivation Reveals Composable Semantic Modules in Large Language Models](https://arxiv.org/abs/2506.18141)
**中文标题：稀疏特征共激活揭示大语言模型中的可组合语义模块**

*Ruixuan Deng,Xiaoyang Hu,Miles Gilberti,Shane Storks,Aman Taxali,Mike Angstadt,Chandra Sripada,Joyce Chai*

主要分类: cs.CL

摘要简述: 通过稀疏自编码器特征共激活，研究发现大语言模型（LLMs）中存在语义模块化结构，国家相关组件在早期层出现，而更抽象的关系组件集中在后期层，模块化知识组织为高效模型操控提供新方法。


<details>
  <summary>详细信息</summary>
研究动机: 探索大语言模型（LLMs）中语义知识的模块化组织方式，揭示其内部结构和功能，为高效、精准的模型操控提供理论基础。

研究方法: 使用稀疏自编码器（SAE）特征共激活技术，分析少量提示下LLMs的语义组件，重点关注国家-关系任务，通过消融和放大组件观察模型输出的变化。

研究结果: 国家相关组件主要出现在早期层，关系组件集中在后期层；后期层节点对模型输出的因果影响更强；组合国家和关系组件可生成复合反事实输出。

研究结论: LLMs内部存在模块化的语义知识组织，国家与关系组件分层分布，后期层对抽象关系更具影响力，为高效模型操控提供了新思路。

中文摘要: 我们通过稀疏自编码器（SAE）特征的共激活，从少量提示中识别出大语言模型（LLMs）中语义连贯、上下文一致的网络组件。以国家-关系任务为例，消融国家和关系的语义组件会以可预测的方式改变模型输出，而放大这些组件则会引发反事实响应。值得注意的是，组合关系和国家的组件可产生复合反事实输出。研究发现，大多数国家组件从第一层开始出现，而更抽象的关系组件则集中在后期层。此外，在关系组件内部，后期层节点对模型输出的因果影响更强。总体而言，这些发现表明LLMs内部存在模块化的知识组织，并推动了高效、针对性模型操控方法的发展。

</details>


### [52] [QuranMorph: Morphologically Annotated Quranic Corpus](https://arxiv.org/abs/2506.18148)
**中文标题：QuranMorph：《古兰经》形态标注语料库**

*Diyam Akra,Tymaa Hammouda,Mustafa Jarrar*

主要分类: cs.CL

摘要简述: 本文介绍了QuranMorph语料库，这是一个对《古兰经》进行形态标注的语料库，包含77,429个词条，每个词条由三位语言学专家手动标注词性和词根。


<details>
  <summary>详细信息</summary>
研究动机: 为了提供一个高质量的《古兰经》形态标注语料库，支持语言学研究和资源互联。

研究方法: 使用Qabas阿拉伯语词典数据库进行词根标注，并采用包含40个标签的SAMA/Qabas细粒度词性标注集进行标注。

研究结果: QuranMorph语料库成功实现了与多种语言资源的互联，并作为开源资源公开提供。

研究结论: QuranMorph语料库为《古兰经》研究提供了丰富的形态标注数据，并促进了语言学资源的共享与互联。

中文摘要: 本文介绍了QuranMorph语料库，这是一个对《古兰经》进行形态标注的语料库（包含77,429个词条）。每个词条由三位语言学专家手动标注词根和词性。词根标注过程使用了Qabas阿拉伯语词典数据库，该数据库链接了110个词典和包含200万词条的语料库。词性标注采用了细粒度的SAMA/Qabas标注集，包含40个标签。如本文所示，这种丰富的词根和词性标注使得QuranMorph语料库能够与多种语言资源互联。该语料库是开源的，作为SinaLab资源的一部分公开提供（https://sina.birzeit.edu/quran）。

</details>


### [53] [CareLab at #SMM4H-HeaRD 2025: Insomnia Detection and Food Safety Event Extraction with Domain-Aware Transformers](https://arxiv.org/abs/2506.18185)
**中文标题：CareLab在SMM4H-HeaRD 2025：基于领域感知Transformer的失眠检测与食品安全事件提取**

*Zihan Liang,Ziwen Pan,Sumon Kanti Dey,Azra Ismail*

主要分类: cs.CL

摘要简述: 本文介绍了CareLab团队在SMM4H-HeaRD 2025共享任务中的系统，重点解决了失眠检测和食品安全事件提取任务，并在食品安全事件提取任务中取得了第一名的成绩。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过领域感知的Transformer模型，解决临床笔记中的失眠检测和新闻中的食品安全事件提取问题，以提升自然语言处理在医疗和食品安全领域的应用效果。

研究方法: 采用了基于编码器的模型（如RoBERTa）和GPT-4进行数据增强，结合预处理、模型架构设计和任务特定调整，优化了任务表现。

研究结果: 在食品安全事件提取任务中，系统以F1分数0.958的成绩排名第一，展示了模型的高效性和适应性。

研究结论: 研究表明，结合领域感知的Transformer模型和数据增强技术，可以有效提升特定任务的表现，为医疗和食品安全领域的自然语言处理提供了有力工具。

中文摘要: 本文介绍了我们在SMM4H-HeaRD 2025共享任务中的系统，特别是任务4（子任务1、2a和2b）和任务5（子任务1和2）。任务4专注于从临床笔记中检测失眠提及，而任务5则涉及从新闻文章中提取食品安全事件。我们参与了所有子任务，并报告了关键发现，特别强调了任务5子任务1，我们的系统在该任务中表现出色，以测试集F1分数0.958的成绩获得第一名。为实现这一结果，我们采用了基于编码器的模型（如RoBERTa）以及GPT-4进行数据增强。本文概述了我们的方法，包括预处理、模型架构和任务特定调整。

</details>


### [54] [Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review](https://arxiv.org/abs/2506.18199)
**中文标题：减轻大型语言模型中阿拉伯和穆斯林文化偏见的提示工程技术：系统综述**

*Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil*

主要分类: cs.CL

摘要简述: 本文系统综述了针对大型语言模型中阿拉伯和穆斯林文化偏见的提示工程技术，总结了五种主要方法，发现结构化多步流程效果最佳，但需更高技术能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在多个领域表现出色，但针对阿拉伯和穆斯林的偏见问题日益突出，亟需研究有效的提示工程技术以减少这种文化偏见。

研究方法: 采用混合方法系统综述，遵循PRISMA指南和Kitchenham的系统综述方法，分析了2021-2024年间的8项实证研究。

研究结果: 研究发现五种主要提示工程技术：文化提示、情感启动、自去偏技术、结构化多步流程和参数优化连续提示。结构化多步流程效果最佳，偏见减少高达87.7%。

研究结论: 提示工程技术可有效减少文化偏见，但需进一步研究开发适应性提示技术、特定评估资源，并结合其他去偏方法。

中文摘要: 大型语言模型在多个领域表现出卓越能力，但对阿拉伯和穆斯林的文化偏见问题引发了严重的伦理挑战，助长了有害的刻板印象和边缘化。尽管对大型语言模型中的偏见问题认识逐渐加深，专门针对阿拉伯和穆斯林群体的提示工程技术研究仍显不足。本混合方法系统综述探讨了此类技术，为研究者和从业者提供了基于证据的指导。遵循PRISMA指南和Kitchenham的系统综述方法，我们分析了2021-2024年间发表的8项关于偏见缓解策略的实证研究。研究发现五种主要提示工程技术：文化提示、情感启动、自去偏技术、结构化多步流程和参数优化连续提示。尽管所有方法均显示出减少偏见的潜力，但效果因研究和偏见类型差异显著。证据表明，某些偏见类型可能对基于提示的缓解更具抵抗力。结构化多步流程总体效果最佳，偏见减少高达87.7%，但需要更高的技术能力。文化提示则具有更广泛的适用性和显著效果。这些结果凸显了提示工程技术在不需访问模型参数的情况下减轻文化偏见的可行性。已识别的研究数量有限，凸显了这一关键领域的显著研究空白。未来研究应聚焦于开发文化适应性提示技术、创建针对阿拉伯和穆斯林的评估资源，并将提示工程与其他去偏方法结合，以解决更深层次的刻板印象，同时保持模型实用性。

</details>


### [55] [Deciphering Emotions in Children Storybooks: A Comparative Analysis of Multimodal LLMs in Educational Applications](https://arxiv.org/abs/2506.18201)
**中文标题：解读儿童故事书中的情感：多模态大语言模型在教育应用中的比较分析**

*Bushra Asseri,Estabraq Abdelaziz,Maha Al Mogren,Tayef Alhefdhi,Areej Al-Wabil*

主要分类: cs.CL

摘要简述: 本研究比较了GPT-4o和Gemini 1.5 Pro两种多模态大语言模型在阿拉伯语儿童故事书插图中的情感识别能力，发现GPT-4o在所有测试条件下均优于Gemini，但其文化理解仍存在局限。


<details>
  <summary>详细信息</summary>
研究动机: 阿拉伯语教育工具需要文化敏感的情感识别技术，但目前多模态AI系统在此领域的表现尚未充分研究。

研究方法: 研究评估了两种模型在零样本、少样本和思维链三种提示策略下的表现，使用75张阿拉伯故事书插图，并与基于Plutchik情感框架的人工标注进行对比。

研究结果: GPT-4o在所有条件下表现最佳，思维链提示下的宏F1分数达59%，而Gemini最高为43%。模型在文化细微情感和模糊叙事场景中存在系统性误分类。

研究结论: 当前模型在文化理解上存在根本性局限，需开发更具文化敏感性的训练方法以支持阿拉伯语学习者的情感感知教育技术。

中文摘要: 多模态AI系统的情感识别能力对开发文化敏感的教育技术至关重要，但在阿拉伯语背景下尚未充分探索。本研究评估了两种先进的多模态大语言模型（GPT-4o和Gemini 1.5 Pro）在处理阿拉伯儿童故事书插图时的情感识别表现。我们使用75张来自七本阿拉伯故事书的图像，通过三种提示策略（零样本、少样本和思维链）评估模型，并将其预测与基于Plutchik情感框架的人工标注进行比较。GPT-4o在所有条件下均优于Gemini，思维链提示下的宏F1分数最高为59%，而Gemini的最佳表现为43%。错误分析显示存在系统性误分类模式，其中情感极性反转占60.7%的错误，且两种模型在文化细微情感和模糊叙事场景中表现不佳。这些发现凸显了当前模型在文化理解上的根本局限，并强调需要采用更具文化敏感性的训练方法来开发适用于阿拉伯语学习者的情感感知教育技术。

</details>


### [56] [Enhancing Entity Aware Machine Translation with Multi-task Learning](https://arxiv.org/abs/2506.18318)
**中文标题：基于多任务学习的实体感知机器翻译性能优化**

*An Trieu,Phuong Nguyen,Minh Le Nguyen*

主要分类: cs.CL

摘要简述: 本文提出一种多任务学习方法，通过联合优化命名实体识别和机器翻译两个子任务，提升实体感知机器翻译（EAMT）的性能。实验基于SemEval 2025竞赛提供的数据集。


<details>
  <summary>详细信息</summary>
研究动机: 实体感知机器翻译（EAMT）因缺乏相关翻译数据及上下文复杂性而成为自然语言处理中的难题。本文旨在通过多任务学习提升其性能。

研究方法: 采用多任务学习方法，同时优化命名实体识别和机器翻译两个子任务，以提升EAMT的整体性能。

研究结果: 实验在SemEval 2025竞赛数据集上进行，结果显示多任务学习方法有效提升了EAMT的性能。

研究结论: 多任务学习方法显著提升了实体感知机器翻译的性能，为复杂上下文中的实体翻译提供了有效解决方案。

中文摘要: 实体感知机器翻译（EAMT）是自然语言处理中的一项复杂任务，不仅因为缺乏与实体相关的翻译数据，还因为翻译这些实体时需要处理的上下文复杂性。本文提出一种方法，通过多任务学习优化命名实体识别和机器翻译两个子任务，从而提升实体感知机器翻译任务的最终性能。实验和分析基于SemEval 2025竞赛任务2组织者提供的数据集。

</details>


### [57] [TranslationCorrect: A Unified Framework for Machine Translation Post-Editing with Predictive Error Assistance](https://arxiv.org/abs/2506.18337)
**中文标题：TranslationCorrect：基于预测错误辅助的机器翻译后编辑统一框架**

*Syed Mekael Wasti,Shou-Yi Hung,Christopher Collins,En-Shiun Annie Lee*

主要分类: cs.CL

摘要简述: TranslationCorrect是一个集成框架，结合机器翻译生成、错误预测和直观的后编辑界面，显著提升翻译效率和研究数据收集质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前机器翻译后编辑和研究数据收集工作流程效率低下且分散，亟需一个统一的解决方案。

研究方法: TranslationCorrect整合了NLLB等模型的机器翻译生成、XCOMET或LLM API的错误预测（含详细推理）以及符合人机交互原则的后编辑界面。

研究结果: 用户研究表明，TranslationCorrect显著提高了翻译效率和用户满意度，并支持高质量的基于跨度的错误标注。

研究结论: TranslationCorrect为翻译者和研究者提供了一个高效、统一的工具，优化了机器翻译后编辑和研究数据收集流程。

中文摘要: 机器翻译（MT）后编辑和研究数据收集通常依赖于低效且分散的工作流程。我们提出了TranslationCorrect，一个旨在整合这些任务的统一框架。TranslationCorrect结合了使用NLLB等模型的机器翻译生成、基于XCOMET或LLM API（提供详细推理）的自动错误预测，以及一个符合人机交互（HCI）原则的直观后编辑界面。用户研究证实，该框架能有效降低认知负荷。对于翻译者，它支持高效纠错和批量翻译；对于研究者，TranslationCorrect以错误跨度标注（ESA）格式导出高质量的基于跨度的标注，其错误分类受多维质量指标（MQM）启发。这些输出兼容前沿的错误检测模型，适用于训练MT或后编辑系统。用户研究表明，TranslationCorrect在翻译效率和用户满意度上显著优于传统标注方法。

</details>


### [58] [Less Data Less Tokens: Multilingual Unification Learning for Efficient Test-Time Reasoning in LLMs](https://arxiv.org/abs/2506.18341)
**中文标题：更少数据更少标记：多语言统一学习提升LLMs测试时推理效率**

*Kang Chen,Mengdi Zhang,Yixin Cao*

主要分类: cs.CL

摘要简述: 本文提出了一种名为L²的多语言统一学习方法，通过解码干预策略提升大型语言模型（LLMs）在测试时的推理效率和性能。研究发现，多语言学习可以减少所需数据和推理标记数量，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在测试时的扩展面临数据和推理效率的挑战。多语言推理的多样性可能为提升模型性能和效率提供新途径。

研究方法: 提出L²多语言统一学习方法，结合两种多语言数据：完整的长链思维注释和分步混合语言数据，并通过解码干预策略进行优化。

研究结果: 实验表明，少量数据即可显著提升推理能力，多语言学习减少了数据和推理标记需求，同时性能未受影响。

研究结论: L²方法为LLMs的数据收集和测试时计算效率问题提供了有效解决方案，且与其他数据高效方法互补。

中文摘要: 本文探讨了大型语言模型（LLMs）在测试时扩展中面临的数据和推理效率挑战。基于初步研究，我们强调了多语言推理的多样性，并提出了一种名为L²的多语言统一学习方法，结合解码干预策略进行深入研究。L²的核心思想是不同语言的推理过程可能相互促进，从而提升模型性能和效率。具体而言，我们使用了两种多语言数据：完整的长链思维注释和分步混合语言数据。通过进一步调优，我们发现即使少量数据也能显著提升推理能力。研究结果表明，多语言学习减少了所需数据和推理标记数量，同时保持了性能。此外，L²方法与其他数据高效方法正交，因此我们还强调了多样化数据选择的重要性。L²方法为LLMs的数据收集和测试时计算效率问题提供了有前景的解决方案。

</details>


### [59] [Evaluating Causal Explanation in Medical Reports with LLM-Based and Human-Aligned Metrics](https://arxiv.org/abs/2506.18387)
**中文标题：基于LLM和人类对齐指标评估医学报告中的因果解释**

*Yousang Cho,Key-Sun Choi*

主要分类: cs.CL

摘要简述: 本研究比较了六种评估指标在自动生成诊断报告中因果解释质量的表现，发现GPT-Black在识别逻辑连贯和临床有效的因果叙述方面表现最佳，GPT-White与专家评估一致，而基于相似性的指标与临床推理质量脱节。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探讨不同评估指标如何准确捕捉自动生成诊断报告中因果解释的质量，以支持需要可解释性和因果推理的任务。

研究方法: 研究比较了六种指标（BERTScore、Cosine Similarity、BioSentVec、GPT-White、GPT-Black和专家定性评估），应用于两种输入类型（基于观察和基于多项选择的报告生成），并采用两种权重策略（任务优先级和等权重）。

研究结果: 结果显示，GPT-Black在识别逻辑连贯和临床有效的因果叙述方面最具区分力，GPT-White与专家评估一致，而基于相似性的指标与临床推理质量不符。

研究结论: 研究强调了指标选择和权重对评估结果的影响，支持在需要可解释性和因果推理的任务中使用基于LLM的评估方法。

中文摘要: 本研究探讨了不同评估指标如何准确捕捉自动生成诊断报告中因果解释的质量。我们比较了六种指标：BERTScore、余弦相似度、BioSentVec、GPT-White、GPT-Black和专家定性评估，应用于两种输入类型（基于观察和基于多项选择的报告生成）。采用两种权重策略：一种反映任务优先级，另一种对所有指标赋予等权重。结果显示，GPT-Black在识别逻辑连贯和临床有效的因果叙述方面表现最佳，GPT-White与专家评估一致，而基于相似性的指标与临床推理质量脱节。这些发现强调了指标选择和权重对评估结果的影响，支持在需要可解释性和因果推理的任务中使用基于LLM的评估方法。

</details>


### [60] [Lemmatization as a Classification Task: Results from Arabic across Multiple Genres](https://arxiv.org/abs/2506.18399)
**中文标题：将词形还原视为分类任务：阿拉伯语多领域研究结果**

*Mostafa Saeed,Nizar Habash*

主要分类: cs.CL

摘要简述: 该论文提出两种将阿拉伯语词形还原视为分类任务的新方法，并引入一个覆盖多领域的新测试集。结果显示分类和聚类方法比序列模型更稳健。


<details>
  <summary>详细信息</summary>
研究动机: 阿拉伯语等形态丰富的语言在词形还原任务中面临标准不一致和领域覆盖有限的问题，现有工具表现不佳。

研究方法: 论文提出两种基于Lemma-POS-Gloss (LPG) 标签集的分类方法，结合机器翻译和语义聚类，并引入新的多领域阿拉伯语测试集。

研究结果: 字符级序列模型表现尚可但易生成不合理形式，而分类和聚类方法更稳健且可解释，为阿拉伯语词形还原设定了新基准。

研究结论: 分类和聚类方法在阿拉伯语词形还原中表现更优，提供了更稳健和可解释的结果。

中文摘要: 词形还原对于形态丰富且拼写模糊的语言（如阿拉伯语）的NLP任务至关重要，但现有工具因标准不一致和领域覆盖有限而面临挑战。本文提出两种新方法，将词形还原视为对Lemma-POS-Gloss (LPG)标签集的分类任务，结合机器翻译和语义聚类。我们还引入了一个覆盖多领域的阿拉伯语词形还原测试集，并与现有数据集标准化。评估显示，字符级序列到序列模型表现尚可，但仅限于词形预测（而非LPG）且易生成不合理形式。结果表明，分类和聚类方法能产生更稳健、可解释的输出，为阿拉伯语词形还原设定了新基准。

</details>


### [61] [TReB: A Comprehensive Benchmark for Evaluating Table Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2506.18421)
**中文标题：TReB：一个用于评估大型语言模型表格推理能力的综合基准**

*Ce Li,Xiaofan Liu,Zhiyan Song,Ce Chi,Chen Zhao,Jingjing Yang,Zhendong Wang,Kexin Yang,Boshen Shi,Xing Wang,Chao Deng,Junlan Feng*

主要分类: cs.CL

摘要简述: 本文提出了一个全面的表格推理评估基准TReB，用于评估大型语言模型（LLM）在表格数据上的推理能力，包含26个子任务，并通过实验证明现有LLM在复杂表格任务上仍有提升空间。


<details>
  <summary>详细信息</summary>
研究动机: 企业和行业中的大量数据以表格形式存储，但表格数据的隐藏语义、复杂性和结构化特性对LLM的推理能力提出了挑战。目前缺乏一个能够全面评估LLM在表格推理能力上的基准，本文旨在填补这一空白。

研究方法: 本文提出了TReB基准，包含浅层表格理解和深层表格推理共26个子任务。通过迭代数据处理构建高质量数据集，并设计了三种推理模式（TCoT、PoT和ICoT）的评估框架。对20多种先进LLM进行了基准测试。

研究结果: 实验结果表明，现有LLM在处理复杂和真实世界的表格任务时仍有显著提升空间。TReB基准及其评估框架被证明是有效的，数据集和框架已公开。

研究结论: TReB为评估LLM在表格推理能力上提供了全面且有效的基准，揭示了现有模型的不足，并为未来研究提供了方向。

中文摘要: 企业和行业中的大部分数据以表格、数据库和数据仓库的形式存储。表格数据的推理对大型语言模型（LLM）提出了显著挑战，因其隐藏的语义、固有的复杂性和结构化特性。其中一个挑战是缺乏一个能够公平反映LLM在广泛表格推理能力上的有效评估基准。本文填补了这一空白，提出了一个全面的表格推理评估基准TReB，涵盖浅层表格理解能力和深层表格推理能力，共26个子任务。通过迭代数据处理构建了高质量数据集，并设计了包含三种推理模式（TCoT、PoT和ICoT）的评估框架。进一步对20多种先进LLM进行了基准测试，证明了其有效性。实验结果表明，现有LLM在处理复杂和真实世界的表格任务时仍有显著提升空间。数据集和评估框架均已公开，数据集托管于[HuggingFace]，框架发布于[GitHub]。

</details>


### [62] [MeRF: Motivation-enhanced Reinforcement Finetuning for Large Reasoning Models](https://arxiv.org/abs/2506.18485)
**中文标题：MeRF：基于动机增强的强化微调用于大型推理模型**

*Junjie Zhang,Guozheng Ma,Shunyu Liu,Haoyu Wang,Jiaxing Huang,Ting-En Lin,Fei Huang,Yongbin Li,Dacheng Tao*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MeRF的新方法，通过将奖励规则直接注入提示中，结合强化学习和上下文学习能力，显著提升了大型语言模型在复杂推理任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于可验证奖励的强化学习方法（RLVR）忽视了大型语言模型（LLM）的上下文学习能力，如思维链（CoT）提示的成功所示。因此，作者探索如何有效结合强化学习与上下文学习，以进一步提升LLM的推理能力。

研究方法: MeRF方法通过将奖励规范直接注入提示中，作为上下文动机，使模型在优化目标意识下改进其响应。这种简单修改利用了LLM的上下文学习能力，将生成与优化对齐，激励模型从内部动机和外部奖励生成理想输出。

研究结果: 在Knights and Knaves（K&K）逻辑谜题推理基准测试中，MeRF显著优于基线方法。消融研究表明，性能提升与上下文动机和外部奖励函数的一致性密切相关，同时模型还能通过强化学习适应误导性动机。

研究结论: MeRF通过结合强化学习和上下文学习，有效提升了LLM的推理能力，证明了将优化目标直接注入提示的简单方法的有效性。

中文摘要: 基于可验证奖励的强化学习（RLVR）已成为大型语言模型（LLM）解决复杂推理任务的有力学习范式。然而，现有RLVR方法忽视了LLM最显著的能力之一——上下文学习能力，如思维链（CoT）提示的成功所示。这促使我们探索如何将强化学习与上下文学习有效结合，以更好地提升LLM的推理能力。本文提出动机增强的强化微调（MeRF），这是一种直观而有效的方法，通过“告诉LLM游戏规则”来增强LLM的强化学习。具体而言，MeRF直接将奖励规范注入提示中，作为上下文动机，使模型在优化目标意识下改进其响应。这种简单修改利用了LLM的上下文学习能力，将生成与优化对齐，从而激励模型从内部动机和外部奖励生成理想输出。在Knights and Knaves（K&K）逻辑谜题推理基准测试中，MeRF显著优于基线方法。此外，消融研究表明，性能提升与上下文动机和外部奖励函数的一致性密切相关，同时模型还能通过强化学习适应误导性动机。

</details>


### [63] [Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance](https://arxiv.org/abs/2506.18501)
**中文标题：ChatGPT与DeepSeek在关键NLP任务中的比较评估：优势、弱点及领域特定表现**

*Wael Etaiwi,Bushra Alhijawi*

主要分类: cs.CL

摘要简述: 本研究对ChatGPT和DeepSeek在五个关键NLP任务（情感分析、主题分类、文本摘要、机器翻译和文本蕴含）中的表现进行了全面评估，发现DeepSeek在分类稳定性和逻辑推理上表现更优，而ChatGPT在需要细微理解和灵活性的任务中更胜一筹。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在自然语言处理（NLP）任务中的广泛应用，对其在不同任务中的表现进行全面评估变得尤为重要。ChatGPT和DeepSeek在许多NLP领域表现出色，但缺乏对其优势和局限性的系统性比较。本研究旨在填补这一空白，为模型选择提供依据。

研究方法: 研究采用结构化实验设计，确保公平性和减少变异性。两种模型在相同的中性提示下进行测试，并在每个任务的两个基准数据集上评估，涵盖新闻、评论和正式/非正式文本等领域。

研究结果: 结果显示，DeepSeek在分类稳定性和逻辑推理任务中表现更优，而ChatGPT在需要细微理解和灵活性的任务中表现更好。

研究结论: 研究结果为根据任务需求选择合适的LLM提供了重要参考，强调了模型在不同任务中的互补性。

中文摘要: 大型语言模型（LLMs）在自然语言处理（NLP）任务中的广泛应用引发了对它们在不同应用中效果的评估兴趣。尽管ChatGPT和DeepSeek在许多NLP领域表现出色，但仍需全面评估以了解其优势、弱点及领域特定能力。本研究旨在评估这两种模型在五个关键NLP任务中的表现：情感分析、主题分类、文本摘要、机器翻译和文本蕴含。通过结构化实验设计，确保公平性并减少变异性。两种模型在相同的中性提示下测试，并在每个任务的两个基准数据集上评估，涵盖新闻、评论和正式/非正式文本等领域。结果显示，DeepSeek在分类稳定性和逻辑推理上表现更优，而ChatGPT在需要细微理解和灵活性的任务中表现更好。这些发现为根据任务需求选择合适的LLM提供了宝贵见解。

</details>


### [64] [End-to-End Spoken Grammatical Error Correction](https://arxiv.org/abs/2506.18532)
**中文标题：端到端口语语法纠错**

*Mengjie Qian,Rao Ma,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

主要分类: cs.CL

摘要简述: 本文探讨了一种端到端（E2E）的口语语法纠错（SGEC）框架，解决了传统级联系统中的错误传播问题，并通过伪标注和数据增强提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 口语语法纠错（SGEC）对第二语言（L2）学习者至关重要，但现有系统依赖级联模块，易受错误传播影响。本文旨在开发一种端到端框架，以克服这些挑战。

研究方法: 研究比较了级联、部分级联和端到端架构，基于Whisper基础模型构建。通过伪标注将训练数据从77小时增至2500小时以上，并引入上下文信息优化反馈生成。

研究结果: 实验表明，提出的方法在Linguaskill和Speak & Improve语料库上显著提升了端到端SGEC的性能。

研究结论: 端到端SGEC框架通过数据增强和反馈优化，有效提升了性能，为口语语法纠错提供了新思路。

中文摘要: 语法纠错（GEC）和反馈对支持第二语言（L2）学习者、教育者和考官至关重要。虽然书面GEC已较为成熟，但口语GEC（SGEC）由于不流畅、转录错误和缺乏结构化输入而面临更多挑战。SGEC系统通常采用自动语音识别（ASR）、不流畅检测和GEC的级联流程，容易受模块间错误传播的影响。本文研究了一种端到端（E2E）的SGEC和反馈生成框架，探讨了开发此类系统的挑战与解决方案。比较了基于Whisper基础模型的级联、部分级联和E2E架构。E2E系统面临GEC标注口语数据稀缺的问题，为此研究了自动伪标注框架，将训练数据从77小时增至2500小时以上。为提高SGEC系统的准确性，还探索了利用ASR输出的额外上下文信息。反馈生成是提升性能的关键步骤，E2E系统中需将SGEC输出与流畅转录估计进行比较以生成反馈。为提高反馈精度，提出了一种新颖的参考对齐流程，旨在消除由流畅转录错误导致的假设编辑。最后，结合编辑置信度估计方法，排除低置信度编辑。在内部Linguaskill（LNG）语料库和公开的Speak & Improve（S&I）语料库上的实验表明，所提方法显著提升了E2E SGEC的性能。

</details>


### [65] [When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking](https://arxiv.org/abs/2506.18535)
**中文标题：当微调失败时：来自MS MARCO段落排序的教训**

*Manu Pande,Shahil Kumar,Anay Yatin Damle*

主要分类: cs.CL

摘要简述: 研究发现，在MS MARCO段落排序任务中，微调预训练的Transformer模型反而会降低性能，所有微调方法均不如基础模型表现好。


<details>
  <summary>详细信息</summary>
研究动机: 探讨为何在MS MARCO段落排序任务中，微调预训练模型会降低性能，挑战传统迁移学习的有效性。

研究方法: 通过五种模型变体（包括全参数微调和参数高效的LoRA适配）进行实验，分析微调对嵌入空间结构的影响，并使用UMAP可视化训练动态。

研究结果: 所有微调方法表现均不如基础模型（MRR@10: 0.3026），微调破坏了基础模型在预训练中学习到的最优嵌入空间结构。

研究结论: 研究结果表明，传统迁移学习方法在饱和基准测试中可能无效，需要架构创新以实现性能提升。

中文摘要: 本文研究了一种反直觉现象：在MS MARCO段落排序任务中，微调预训练的Transformer模型会降低性能。通过涉及五种模型变体（包括全参数微调和参数高效的LoRA适配）的综合实验，我们发现所有微调方法的表现均不如基础模型sentence-transformers/all-MiniLM-L6-v2（MRR@10: 0.3026）。分析表明，微调破坏了基础模型在预训练中学习到的最优嵌入空间结构，该预训练涉及10亿句对（包括910万MS MARCO样本）。UMAP可视化显示嵌入空间逐渐扁平化，而训练动态分析和计算效率指标进一步支持了我们的发现。这些结果挑战了传统关于迁移学习在饱和基准测试中有效性的观点，并表明可能需要架构创新才能实现有意义的改进。

</details>


### [66] [A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance](https://arxiv.org/abs/2506.18576)
**中文标题：仇恨言论定义的模块化分类法及其对零样本大语言模型分类性能的影响**

*Matteo Melis,Gabriella Lapesa,Dennis Assenmacher*

主要分类: cs.CL

摘要简述: 本文提出了一种模块化分类法来定义仇恨言论，并研究了不同定义对零样本大语言模型分类性能的影响。研究发现，定义的具体性会影响模型表现，但效果因模型架构而异。


<details>
  <summary>详细信息</summary>
研究动机: 仇恨言论检测是自然语言处理中的重要任务，但其定义模糊不清。本文旨在通过收集和分析现有定义，构建一个清晰的分类法，并探讨不同定义对模型性能的影响。

研究方法: 1. 理论层面：收集并分析文献中的仇恨言论定义，将其归纳为14个概念要素的分类法。2. 实验层面：使用三种大语言模型，在三种仇恨言论数据集（合成、人工参与和真实数据）上进行零样本评估，测试不同定义对模型性能的影响。

研究结果: 研究发现，选择不同具体程度的仇恨言论定义会影响模型性能，但这种影响并非在所有模型架构中一致。

研究结论: 本文通过构建仇恨言论定义的分类法，揭示了定义的具体性对模型性能的重要性，为未来研究提供了理论支持和实验依据。

中文摘要: 检测有害内容是自然语言处理在社会公益应用中的关键任务，而仇恨言论是其最危险的形式之一。但我们如何定义仇恨言论？不同的定义如何影响模型性能？本文的贡献包括两方面：在理论层面，我们通过收集和分析文献中的现有定义，解决了仇恨言论定义的模糊性问题，并将其组织为包含14个概念要素的分类法，这些要素捕捉了仇恨言论定义的不同方面，如仇恨目标（个人或群体）或其潜在后果。在实验层面，我们利用这些定义对三种大语言模型进行了系统的零样本评估，测试了三种代表不同类型数据（合成、人工参与和真实世界）的仇恨言论数据集。研究发现，选择不同具体程度的定义（即编码要素的不同）会影响模型性能，但这种效果并非在所有架构中一致。

</details>


### [67] [Parallel Continuous Chain-of-Thought with Jacobi Iteration](https://arxiv.org/abs/2506.18582)
**中文标题：基于雅可比迭代的并行连续思维链**

*Haoyi Wu,Zhihao Teng,Kewei Tu*

主要分类: cs.CL

摘要简述: 本文提出了一种并行连续思维链（PCCoT）方法，通过雅可比迭代并行更新潜在思维标记，显著提升了连续思维链的训练和推理效率，同时保持了性能。


<details>
  <summary>详细信息</summary>
研究动机: 连续思维链（CoT）通过潜在思维标记进行隐式推理，节省了推理标记，但其顺序依赖性导致训练时间长。本文旨在解决这一问题，提升训练和推理效率。

研究方法: 提出并行连续思维链（PCCoT），利用雅可比迭代并行更新潜在思维标记，替代传统的顺序更新，从而提升训练和推理效率。

研究结果: 实验表明，PCCoT在保持或超越性能的同时，节省了近50%的训练和推理时间，并表现出更好的训练稳定性和鲁棒性。

研究结论: PCCoT通过并行化显著提升了连续思维链的效率，为大规模语言模型的推理任务提供了一种高效且稳定的解决方案。

中文摘要: 连续思维链已被证明能够有效节省大型语言模型的推理标记。通过使用连续的潜在思维标记进行推理，连续思维链能够以紧凑的方式进行隐式推理。然而，潜在思维标记之间的顺序依赖性破坏了并行训练，导致训练时间过长。本文提出了并行连续思维链（PCCoT），该方法对潜在思维标记进行雅可比迭代，以并行而非顺序的方式迭代更新这些标记，从而提高了连续思维链的训练和推理效率。实验表明，通过选择合适的迭代次数，我们能够在保持甚至提升性能的同时，节省近50%的训练和推理时间。此外，PCCoT在训练过程中表现出更好的稳定性和鲁棒性。代码已开源：https://github.com/whyNLP/PCCoT。

</details>


### [68] [Reply to "Emergent LLM behaviors are observationally equivalent to data leakage"](https://arxiv.org/abs/2506.18600)
**中文标题：回应《大语言模型的涌现行为与数据泄漏在观测上等价》**

*Ariel Flint Ashery,Luca Maria Aiello,Andrea Baronchelli*

主要分类: cs.CL

摘要简述: 本文回应了对大语言模型（LLM）群体模拟中数据泄漏问题的批评，强调尽管数据污染可能影响实验，但LLM群体中的自组织和模型依赖性涌现动态仍可研究。


<details>
  <summary>详细信息</summary>
研究动机: 针对Barrie和Törnberg对Flint Ashery等人研究的批评，本文旨在澄清数据污染问题并不妨碍研究LLM群体中真实的涌现动态，尤其是社会惯例中的实证观察。

研究方法: 通过理论分析和实证案例（如社会惯例的形成），论证LLM群体中的自组织和涌现动态是可研究的，不受数据污染的完全限制。

研究结果: 研究表明，尽管数据污染可能影响某些实验，但LLM群体中的涌现动态（如社会惯例）仍可通过实证观察验证。

研究结论: 数据污染问题虽重要，但并未完全阻碍对LLM群体中涌现动态的研究，尤其是在社会惯例等具体案例中。

中文摘要: 在模拟大语言模型（LLM）群体时，数据污染（即训练数据可能以意外方式影响结果）是一个潜在问题。尽管这一担忧重要且可能阻碍多智能体模型的某些实验，但它并未排除对LLM群体中真实涌现动态的研究。Barrie和Törnberg近期对Flint Ashery等人研究的批评[1][2]提供了一个机会，澄清自组织和模型依赖性涌现动态可以在LLM群体中研究，并强调这些动态在社会惯例的具体案例中已被实证观察到。

</details>


### [69] [Semantic similarity estimation for domain specific data using BERT and other techniques](https://arxiv.org/abs/2506.18602)
**中文标题：使用BERT及其他技术对领域特定数据进行语义相似度估计**

*R. Prashanth*

主要分类: cs.CL

摘要简述: 本文研究了语义相似度估计问题，比较了多种先进技术（如USE、InferSent和BERT），发现BERT在领域特定数据上表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 语义相似度估计是自然语言处理和自然语言理解中的重要研究问题，广泛应用于问答、语义搜索、信息检索等任务。本文旨在探索不同技术在领域特定数据上的表现。

研究方法: 使用USE、InferSent和BERT等先进技术，分别在领域特定的内部数据集和公开的Quora问题对数据集上进行语义相似度估计。

研究结果: 实验结果表明，BERT模型的表现显著优于其他方法，这归因于其微调过程能够更好地学习训练数据的模式。

研究结论: 本文证明了BERT在领域特定数据上的优越性，建议在类似任务中优先使用BERT。

中文摘要: 语义相似度估计是自然语言处理和自然语言理解中的重要研究问题，在问答、语义搜索、信息检索、文档聚类、词义消歧和机器翻译等下游任务中具有广泛应用。本研究采用多种先进技术（包括通用句子编码器USE、InferSent和最新的BERT模型）进行语义相似度估计。我们使用了两个问题对数据集进行分析，一个是领域特定的内部数据集，另一个是公开的Quora问题对数据集。实验发现，BERT模型的表现显著优于其他方法，这可能是由于其训练过程中涉及的微调过程使其能够更好地学习训练数据的模式。本研究证明了BERT在领域特定数据集上的适用性，并推断出在领域特定数据中，BERT是最佳的技术选择。

</details>


### [70] [The Anatomy of Speech Persuasion: Linguistic Shifts in LLM-Modified Speeches](https://arxiv.org/abs/2506.18621)
**中文标题：演讲说服力的解剖：LLM修改演讲中的语言变化**

*Alisa Barkar,Mathieu Chollet,Matthieu Labeau,Beatrice Biancardi,Chloe Clavel*

主要分类: cs.CL

摘要简述: 本研究探讨大型语言模型如何通过修改演讲文本来理解说服力，发现GPT-4o通过系统性风格调整而非人类式优化来增强修辞效果。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索大型语言模型（如GPT-4o）如何理解和生成具有说服力的公共演讲内容，尤其是通过修改演讲文本来分析其语言变化。

研究方法: 研究方法包括使用法国3MT数据集中的博士候选人演讲文本，通过GPT-4o生成增强或减弱说服力的版本，并分析其修辞手法和话语标记的语言变化。

研究结果: 结果显示，GPT-4o通过操纵情感词汇和句法结构（如疑问句和感叹句）来增强修辞效果，而非以人类方式优化说服力。

研究结论: 结论指出，GPT-4o在修改演讲时更倾向于系统性风格调整，而非模仿人类说服力优化策略。

中文摘要: 本研究通过修改法国“Ma These en 180 Secondes”竞赛中博士候选人的演讲文本，探讨大型语言模型如何理解公共演讲中的说服力。我们提出了一种新方法和可解释的文本特征集，整合了修辞手法和话语标记。通过提示GPT-4o增强或减弱说服力，并分析原始与生成演讲之间的语言变化。结果表明，GPT-4o采用系统性风格调整而非人类式优化说服力，尤其通过操纵情感词汇和句法结构（如疑问句和感叹句）来放大修辞效果。

</details>


### [71] [ByteSpan: Information-Driven Subword Tokenisation](https://arxiv.org/abs/2506.18639)
**中文标题：ByteSpan：信息驱动的子词分词方法**

*Zébulon Goriely,Suchir Salhan,Pietro Lesci,Julius Cheng,Paula Buttery*

主要分类: cs.CL

摘要简述: ByteSpan是一种基于信息驱动的子词分词方法，通过外部字节级语言模型训练，将可预测的字节序列分组为子词，生成高效的词汇表，并在英语和多语言实验中表现优于BPE。


<details>
  <summary>详细信息</summary>
研究动机: 近年来动态分词方法直接在字节上操作，并将其潜在表示聚合为块。这与计算模型中的分词方法类似，后者通过自回归模型的预测误差峰值确定词汇边界。受此启发，研究是否可以通过分组可预测字节而非聚合其表示来生成有用的固定子词词汇表。

研究方法: 提出ByteSpan，一种信息驱动的子词分词器，训练时使用外部字节级语言模型识别连续可预测的字节序列，并将其分组为子词。

研究结果: 实验表明，ByteSpan生成的词汇表效率高，英语形态对齐分数优于BPE。多语言实验在25种语言中表现出相似的压缩和Rényi效率。

研究结论: ByteSpan通过信息驱动的方法生成高效的子词词汇表，在英语和多语言任务中表现优异，为分词提供了新的思路。

中文摘要: 最近的动态分词方法直接在字节上操作，并将其潜在表示聚合为块。这与计算模型中的分词方法类似，后者通过自回归模型的预测误差峰值确定词汇边界。受此启发，我们探索是否可以通过分组可预测字节而非聚合其表示来生成有用的固定子词词汇表。我们提出了一种新的信息驱动子词分词器ByteSpan，训练时使用外部字节级语言模型识别连续可预测的字节序列，并将其分组为子词。实验表明，ByteSpan生成的词汇表效率高，英语形态对齐分数优于BPE。多语言实验在25种语言中表现出相似的压缩和Rényi效率。

</details>


### [72] [Is There a Case for Conversation Optimized Tokenizers in Large Language Models?](https://arxiv.org/abs/2506.18674)
**中文标题：大型语言模型中是否存在聊天对话优化的分词器？**

*Raquel Ferrando,Javier Conde,Gonzalo Martínez,Pedro Reviriego*

主要分类: cs.CL

摘要简述: 研究发现，为聊天机器人对话优化的分词器能减少5%至10%的token数量，从而显著节省能源，同时对原始训练语料的分词效率影响极小甚至略有提升。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）的计算和能源成本随模型规模和用户数量激增，而分词器在模型效率中起关键作用。聊天机器人作为LLM的流行应用，其用户输入和回复的文本与训练语料不同，因此探索优化分词器是否能为聊天对话带来效益。

研究方法: 研究使用公开的聊天机器人对话语料库，重新设计不同分词器的词汇表，并评估其在聊天对话领域的性能。

研究结果: 优化后的分词器在聊天对话中显著减少token数量（5%-10%），同时原始训练语料的分词效率几乎不受影响或略有提升。

研究结论: 为聊天对话优化的分词器能有效降低能源消耗，且不影响原始语料的分词效率，具有实际应用潜力。

中文摘要: 大型语言模型（LLM）的计算和能源成本因模型规模扩大和用户数量激增而呈指数增长。分词器作为模型效率的关键因素，通常针对训练语料优化以减少token数量。然而，聊天机器人作为LLM的主要应用之一，其用户输入和回复的文本与训练语料不同。因此，本文探讨了为聊天对话优化分词器的潜在效益。通过使用公开的聊天对话语料库重新设计分词器词汇表，并评估其性能。结果显示，优化后的分词器在聊天对话中能持续减少token数量（5%-10%），从而显著节省能源，同时对原始训练语料的分词效率影响极小甚至略有提升。

</details>


### [73] [Context Biasing for Pronunciations-Orthography Mismatch in Automatic Speech Recognition](https://arxiv.org/abs/2506.18703)
**中文标题：自动语音识别中发音与拼写不匹配的上下文偏置方法**

*Christian Huber,Alexander Waibel*

主要分类: cs.CL

摘要简述: 本文提出了一种针对发音与拼写不匹配的自动语音识别（ASR）问题的上下文偏置方法，通过动态修正替换错误，显著提高了特定词汇的识别准确率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的神经序列到序列系统在自动语音识别中表现优异，但对于训练中未见的词汇（如专有名词、缩写或领域特定词汇）识别效果不佳，尤其是发音与拼写不匹配的词汇。本文旨在解决这一问题。

研究方法: 提出了一种动态修正替换错误的方法，允许用户在推理过程中实时添加修正，从而优化发音与拼写不匹配词汇的识别。

研究结果: 实验表明，该方法在偏置词汇错误率上实现了高达11%的相对提升，同时保持了整体词汇错误率的竞争力。

研究结论: 该方法有效解决了发音与拼写不匹配词汇的识别问题，为自动语音识别系统的实际应用提供了实用解决方案。

中文摘要: 神经序列到序列系统在自动语音识别中实现了最先进的性能。当使用适当的建模单元（如字节对编码字符）时，这些系统在理论上具有开放词汇能力。然而，在实践中，它们往往无法识别训练中未见的词汇（如专有名词、缩写或领域特定词汇）。针对这一问题，已提出多种上下文偏置方法，但对于发音与拼写不匹配的词汇，这些方法仍可能表现不佳。我们提出了一种方法，通过修正替换错误来提高此类挑战性词汇的识别准确率。用户可以在推理过程中动态添加修正。实验表明，该方法在偏置词汇错误率上实现了高达11%的相对提升，同时保持了整体词汇错误率的竞争力。

</details>


### [74] [Benchmarking the Pedagogical Knowledge of Large Language Models](https://arxiv.org/abs/2506.18710)
**中文标题：评估大型语言模型的教学知识基准测试**

*Maxime Lelièvre,Amy Waldock,Meng Liu,Natalia Valdés Aspillaga,Alasdair Mackintosh,María José Ogando Portelo,Jared Lee,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

主要分类: cs.CL

摘要简述: 本文介绍了《教学基准测试》，一种用于评估大型语言模型在跨领域教学知识（CDPK）和特殊教育需求与残疾（SEND）教学知识上的表现的新数据集。基于教师专业考试题目，测试结果显示模型准确率在28%至89%之间，并探讨了成本与准确性的关系。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试主要关注内容知识，缺乏对教学方法的评估。本文旨在填补这一空白，通过开发专门的教学知识基准测试，评估模型在教学实践中的理解能力，为教育领域的AI应用提供依据。

研究方法: 基于教师专业发展考试的题目，构建了涵盖教学策略和评估方法等子领域的《教学基准测试》。测试了97个模型的表现，并分析了成本与准确性的关系。

研究结果: 模型在教学知识问题上的准确率介于28%至89%之间。研究还展示了成本与准确性的帕累托前沿随时间的变化，并提供了在线排行榜供交互式探索。

研究结论: 教学知识基准测试对衡量模型的教学理解能力至关重要，有助于指导AI在教育领域的负责任部署和政策制定。

中文摘要: 如大规模多任务语言理解（MMLU）等基准测试在评估AI跨领域知识和能力方面发挥了关键作用。然而，现有基准测试主要关注内容知识，忽视了评估模型对教学方法（即教学实践）的理解。本文介绍了《教学基准测试》，这是一种新型数据集，旨在评估大型语言模型在跨领域教学知识（CDPK）和特殊教育需求与残疾（SEND）教学知识上的表现。这些基准测试基于从教师专业发展考试中精心挑选的问题，涵盖教学策略和评估方法等多个教学子领域。本文概述了这些基准测试的方法和开发过程，并报告了97个模型的结果，其教学知识问题的准确率介于28%至89%之间。我们还探讨了成本与准确性的关系，并绘制了帕累托价值前沿随时间的变化。我们提供了在线排行榜（https://rebrand.ly/pedagogy），该排行榜会随着新模型的加入而更新，并允许基于各种模型属性（如每标记成本和开放与封闭权重）进行交互式探索和筛选，同时还能查看不同学科的表现。大型语言模型和生成式AI在教育领域具有巨大潜力，有助于解决全球学习危机。以教育为重点的基准测试对于衡量模型理解教学概念、适当回应学习者需求以及支持多样化背景下的有效教学实践至关重要。这些基准测试为在教育环境中负责任且基于证据地部署大型语言模型及其工具提供了依据，并为开发与政策决策提供了指导。

</details>


### [75] [Semantic-Preserving Adversarial Attacks on LLMs: An Adaptive Greedy Binary Search Approach](https://arxiv.org/abs/2506.18756)
**中文标题：保持语义的LLMs对抗攻击：一种自适应贪婪二分搜索方法**

*Chong Zhang,Xiang Li,Jia Wang,Shan Liang,Haochen Xue,Xiaobo Jin*

主要分类: cs.CL

摘要简述: 本文提出了一种自适应贪婪二分搜索（AGBS）方法，用于在保持语义稳定的同时生成对抗样本，以解决大型语言模型（LLMs）在自动提示优化中可能导致的语义失真问题。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在图形用户界面（GUI）中依赖自动提示优化以提升响应准确性，但用户需求的多样性常导致原始意图被误解，产生错误输出。本文旨在解决这一问题。

研究方法: 提出自适应贪婪二分搜索（AGBS）方法，模拟常见提示优化机制，动态评估其对LLM性能的影响，从而生成鲁棒的对抗样本。

研究结果: 通过在开源和闭源LLMs上的广泛实验，证明AGBS在语义一致性和攻击效果之间取得了良好平衡。

研究结论: 研究结果为设计更可靠的提示优化系统提供了实用见解，代码已开源。

中文摘要: 大型语言模型（LLMs）在图形用户界面（GUI）中越来越多地依赖自动提示工程以优化用户输入并提升响应准确性。然而，用户需求的多样性常导致意外的误解，自动优化可能扭曲原始意图并产生错误输出。为解决这一问题，我们提出了自适应贪婪二分搜索（AGBS）方法，该方法在模拟常见提示优化机制的同时保持语义稳定性。我们的方法动态评估此类策略对LLM性能的影响，从而生成鲁棒的对抗样本。通过在开源和闭源LLMs上的广泛实验，我们证明了AGBS在语义一致性和攻击效果之间的平衡能力。研究结果为设计更可靠的提示优化系统提供了实用见解。代码已开源：https://github.com/franz-chang/DOBS

</details>


### [76] [ASP2LJ : An Adversarial Self-Play Laywer Augmented Legal Judgment Framework](https://arxiv.org/abs/2506.18768)
**中文标题：ASP2LJ：一种对抗性自我博弈律师增强的法律判决框架**

*Ao Chang,Tong Zhou,Yubo Chen,Delai Qiu,Shengping Liu,Kang Liu,Jun Zhao*

主要分类: cs.CL

摘要简述: 本文提出ASP2LJ框架，通过对抗性自我博弈和案例生成模块解决法律判决预测中的长尾分布问题，并提升律师论证能力，从而提高司法决策的客观性和公平性。


<details>
  <summary>详细信息</summary>
研究动机: 法律判决预测（LJP）面临长尾数据分布和律师论证能力不足的挑战，现有系统忽视律师在优化论证中的作用，导致司法准确性受限。

研究方法: 提出ASP2LJ框架，包含案例生成模块以解决长尾分布问题，并采用对抗性自我博弈机制增强律师论证能力，法官可参考优化的论证提升决策质量。

研究结果: 在SimuCourt和RareCases数据集上的实验表明，ASP2LJ框架显著提升了模型性能，验证了其有效性。

研究结论: ASP2LJ框架通过整合案例生成和对抗性自我博弈，提升了法律判决预测的公平性和准确性，并贡献了稀有案例数据集和公开代码。

中文摘要: 法律判决预测（LJP）旨在预测司法结果，包括相关法律指控、刑期和罚款，是大语言模型（LLM）中的关键过程。然而，LJP面临两大挑战：（1）长尾分布：现有数据集源自真实案例，标注成本高且分布不均衡，导致模型性能下降。（2）律师的改进：现有系统专注于提升法官决策，却忽视了律师在优化论证中的关键作用，限制了司法准确性。为解决这些问题，我们提出了一种对抗性自我博弈律师增强的法律判决框架（ASP2LJ），通过案例生成模块解决长尾数据分布问题，并通过对抗性自我博弈机制提升律师论证能力。该框架使法官能够参考优化的律师论证，提高司法决策的客观性、公平性和合理性。此外，我们还引入了RareCases数据集，包含120个中国稀有法律案例。我们在SimuCourt和RareCases数据集上验证了方法的有效性，实验结果表明框架显著提升了性能。我们的贡献包括一个整合框架、稀有案例数据集，以及公开数据集和代码以支持自动化司法系统的进一步研究。

</details>


### [77] [Existing LLMs Are Not Self-Consistent For Simple Tasks](https://arxiv.org/abs/2506.18781)
**中文标题：现有大型语言模型在简单任务中缺乏自我一致性**

*Zhenru Lin,Jiawen Tao,Yang Yuan,Andrew Chi-Chih Yao*

主要分类: cs.CL

摘要简述: 研究发现，即使是简单的任务，现有的大型语言模型（LLMs）也缺乏自我一致性，即使是先进模型如DeepSeek-R1和GPT-o4-mini也存在不一致性。论文提出了两种自动化方法以量化并缓解这一问题，但改进有限，凸显了自我一致性在构建可靠AI中的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）能力不断增强，但其决策的透明性和可信赖性依赖于自我一致性（即内部推理无矛盾）。然而，研究发现即使是简单任务，LLMs也存在不一致性，这促使研究者探索如何量化并改进这一问题。

研究方法: 论文提出了两种自动化方法：基于图的方法和基于能量的方法，用于量化和缓解LLMs的不一致性。同时，引入了不一致性指标以评估模型的自我一致性。

研究结果: 实验表明，即使是先进模型如DeepSeek-R1和GPT-o4-mini，在简单任务中仍存在显著的不一致性。提出的两种方法虽能部分改进，但未能完全解决问题。

研究结论: 自我一致性是构建可靠和可解释AI的关键因素。尽管提出的方法提供了部分改进，但问题复杂性表明仍需进一步研究。代码和数据已开源。

中文摘要: 大型语言模型（LLMs）的能力不断增强，但确保其决策透明和可信赖需要自我一致性——即内部推理无矛盾。我们的研究表明，即使在简单任务（如比较线上或平面上的点，或家族树推理）中，所有较小模型均高度不一致，甚至先进模型如DeepSeek-R1和GPT-o4-mini也未完全实现自我一致性。为量化和缓解这些不一致性，我们引入了不一致性指标，并提出了两种自动化方法——基于图的方法和基于能量的方法。尽管这些改进提供了部分效果，但也凸显了自我一致性在构建更可靠和可解释AI中的复杂性和重要性。代码和数据可在https://github.com/scorpio-nova/llm-self-consistency获取。

</details>


### [78] [RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies](https://arxiv.org/abs/2506.18819)
**中文标题：RWESummary：一个用于选择大型语言模型总结真实世界证据（RWE）研究的框架与测试**

*Arjun Mukerji,Michael L. Jackson,Jason Jones,Neil Sanghavi*

主要分类: cs.CL

摘要简述: 本文介绍了RWESummary框架，用于评估大型语言模型（LLM）在总结真实世界证据（RWE）研究中的表现。通过一个场景和三项评估，发现Gemini 2.5模型表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 目前大型语言模型在医学研究辅助和通用摘要任务中已有广泛评估，但尚未专门针对真实世界证据（RWE）研究的结构化输出摘要任务进行评估。

研究方法: 提出RWESummary框架，作为MedHELM框架的补充，用于评估LLM在RWE研究摘要任务中的表现。框架包括一个场景和三项评估，基于Atropos Health专有数据开发。

研究结果: 在13项RWE研究中，Gemini 2.5模型（Flash和Pro版本）表现最佳。

研究结论: RWESummary为真实世界证据研究摘要任务提供了一个新颖且实用的基准模型。

中文摘要: 大型语言模型（LLM）在通用摘要任务和医学研究辅助中已被广泛评估，但尚未专门针对真实世界证据（RWE）研究的结构化输出摘要任务进行评估。我们提出了RWESummary，作为MedHELM框架（Bedi, Cui, Fuentes, Unell等，2025）的补充，用于评估LLM在此任务中的表现。RWESummary包括一个场景和三项评估，涵盖了医学研究摘要中观察到的主要错误类型，并使用Atropos Health专有数据开发。此外，我们利用RWESummary比较了不同LLM在我们内部RWE摘要工具中的表现。在发表时，基于13项RWE研究，我们发现Gemini 2.5模型（Flash和Pro版本）整体表现最佳。我们建议将RWESummary作为真实世界证据研究摘要任务的新颖且实用的基准模型。

</details>


### [79] [MLLP-VRAIN UPV system for the IWSLT 2025 Simultaneous Speech Translation Translation task](https://arxiv.org/abs/2506.18828)
**中文标题：MLLP-VRAIN UPV系统在IWSLT 2025同步语音翻译任务中的应用**

*Jorge Iranzo-Sánchez,Javier Iranzo-Sánchez,Adrià Giménez,Jorge Civera,Alfons Juan*

主要分类: cs.CL

摘要简述: MLLP-VRAIN研究组在IWSLT 2025同步语音翻译任务中提出了一种模块化级联系统，结合Whisper和NLLB模型，通过轻量级适应技术实现实时长语音翻译，平衡了翻译质量和延迟。


<details>
  <summary>详细信息</summary>
研究动机: 解决长语音实时翻译的独特挑战，避免从头训练端到端模型，利用预训练模型的优势。

研究方法: 结合Whisper Large-V3-Turbo进行语音识别，NLLB-3.3B进行多语言翻译，采用文档级适应和前缀训练优化模型，结合wait-$k$策略和RALCP管理翻译流，使用缓冲区管理和分段策略确保连贯性。

研究结果: 在ACL60/60数据集上，BLEU得分为31.96，延迟为2.94秒；在IWSLT25Instruct测试集上初步得分为29.8 BLEU。

研究结论: 研究表明，通过精心调整预训练组件，无需大量领域内并行数据或端到端训练，即可构建有效的长语音同步翻译系统。

中文摘要: 本文描述了MLLP-VRAIN研究组在IWSLT 2025同步语音翻译任务中的参与情况。我们的提交通过开发模块化级联系统，将强大的预训练模型适应流式场景，解决了长语音实时翻译的独特挑战。我们结合Whisper Large-V3-Turbo进行语音识别，以及多语言NLLB-3.3B模型进行机器翻译，采用轻量级适应技术而非从头训练端到端模型。我们的方法通过文档级适应和前缀训练提升MT模型处理不完整输入的能力，同时结合wait-$k$策略和RALCP管理翻译流。专用缓冲区管理和分段策略确保长音频序列的连贯翻译。在ACL60/60数据集上的实验结果表明，我们的系统在翻译质量和延迟之间取得了良好平衡，BLEU得分为31.96，非计算感知的StreamLAAL延迟为2.94秒。最终模型在官方测试集（IWSLT25Instruct）上的初步得分为29.8 BLEU。我们的研究表明，精心调整的预训练组件可以构建有效的长内容同步翻译系统，无需大量领域内并行数据或专门的端到端训练。

</details>


### [80] [STU-PID: Steering Token Usage via PID Controller for Efficient Large Language Model Reasoning](https://arxiv.org/abs/2506.18831)
**中文标题：STU-PID：通过PID控制器动态调节token使用以实现高效大型语言模型推理**

*Aryasomayajula Ram Bharadwaj*

主要分类: cs.CL

摘要简述: 本文提出STU-PID方法，通过PID控制器动态调节推理过程中的激活引导强度，减少冗余推理步骤，提升计算效率。实验显示，该方法在GSM8K任务上准确率提升6%，同时减少32%的token使用。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在长链推理（CoT）中常因过度思考生成冗余推理步骤，增加计算成本并可能降低性能。现有静态引导方法缺乏动态调整能力，无法根据实时推理质量灵活调节干预强度。

研究方法: 提出STU-PID方法，结合基于分块的分类器检测冗余推理模式，并通过PID控制器动态调整引导强度。该方法无需训练，直接在推理过程中实现动态校准。

研究结果: 在GSM8K任务上，STU-PID将准确率提升6%，同时减少32%的token使用，优于静态引导基线方法。

研究结论: STU-PID为动态推理校准提供了理论框架，在保持推理质量的同时显著提升计算效率。

中文摘要: 采用长链推理（CoT）的大型语言模型常因过度思考现象生成过多冗余推理步骤，增加计算成本并可能降低性能。尽管近期研究探索了静态引导方法以缓解此问题，但这些方法缺乏根据实时推理质量动态调整干预强度的能力。我们提出STU-PID（通过PID控制器动态调节token使用），一种无需训练的新方法，利用PID控制器在推理过程中动态调节激活引导强度。该方法结合分块级分类器检测冗余推理模式，并通过PID控制机制根据预测的冗余概率自适应调整引导强度。在GSM8K上的实验表明，STU-PID在准确率上提升6%，同时减少32%的token使用，优于静态引导基线。我们的方法为动态推理校准提供了理论框架，在保持推理质量的同时显著提升计算效率。

</details>


### [81] [LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning](https://arxiv.org/abs/2506.18841)
**中文标题：LongWriter-Zero：通过强化学习掌握超长文本生成**

*Yuhao Wu,Yushi Bai,Zhiqiang Hu,Roy Ka-Wei Lee,Juanzi Li*

主要分类: cs.CL

摘要简述: 本文提出了一种基于强化学习的无监督方法LongWriter-Zero，用于解决大语言模型在生成长文本时的长度限制和质量下降问题。该方法无需依赖人工标注或合成数据，通过强化学习训练模型，显著提升了长文本生成的性能，并在多个评测中超越现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在生成长文本时面临长度限制和质量下降的挑战，传统方法依赖合成数据进行监督微调，但数据构建成本高且质量不佳。本文旨在探索一种无需依赖标注数据的强化学习方法，以提升长文本生成能力。

研究方法: 提出LongWriter-Zero方法，从零开始利用强化学习训练基础模型，通过奖励模型引导模型在写作过程中进行规划和优化，从而提升长度控制、写作质量和结构格式。

研究结果: 实验表明，基于Qwen2.5-32B训练的LongWriter-Zero在长文本生成任务中表现优异，在WritingBench和Arena-Write评测中均达到最优水平，甚至超越100B+规模的模型。

研究结论: LongWriter-Zero通过强化学习实现了无需标注数据的长文本生成能力提升，为相关领域提供了新的解决方案，并开源了模型和数据。

中文摘要: 大语言模型（LLMs）的超长文本生成是一个广泛需求但极具挑战性的任务，主要受限于最大生成长度和随着序列增长的质量下降。传统方法如LongWriter依赖监督微调（SFT）于合成长文本输出，但这种方法需要大量合成数据，构建困难且成本高昂，且常缺乏连贯性和一致性，结构单调。本文提出了一种基于激励的方法，完全从零开始，不依赖任何标注或合成数据，利用强化学习（RL）激发LLMs的超长高质量文本生成能力。我们从基础模型（类似R1-Zero）出发，通过RL训练引导模型在写作过程中进行规划和优化。为此，我们采用专门的奖励模型，指导LLM在长度控制、写作质量和结构格式上的改进。实验评估显示，基于Qwen2.5-32B训练的LongWriter-Zero在长文本写作任务中持续优于传统SFT方法，在WritingBench和Arena-Write评测中所有指标均达到最优，甚至超越100B+规模的模型如DeepSeek R1和Qwen3-235B。我们开源了数据和模型检查点，详见https://huggingface.co/THU-KEG/LongWriter-Zero-32B。

</details>


### [82] [Mechanistic Interpretability Needs Philosophy](https://arxiv.org/abs/2506.18852)
**中文标题：机制可解释性需要哲学**

*Iwan Williams,Ninell Oldenburg,Ruchira Dhar,Joshua Hatherley,Constanza Fierro,Nina Rajcic,Sandrine R. Schiller,Filippos Stamatiou,Anders Søgaard*

主要分类: cs.CL

摘要简述: 本文主张机制可解释性研究需要哲学的深度参与，以澄清概念、优化方法并评估解释AI系统的认识论和伦理意义。


<details>
  <summary>详细信息</summary>
研究动机: 随着机制可解释性（MI）研究的影响力扩大，仅关注模型本身已不足够，还需审视其隐含的假设、概念和解释策略。本文认为哲学应成为MI研究的持续合作伙伴。

研究方法: 通过分析MI文献中的三个开放性问题，本文展示了哲学对MI研究的价值，并提出了深化跨学科对话的路径。

研究结果: 哲学能够帮助MI研究澄清概念、优化方法，并评估解释AI系统的认识论和伦理意义。

研究结论: 机制可解释性研究需要与哲学紧密结合，以推动更深入的概念和方法论发展。

中文摘要: 机制可解释性（MI）旨在通过揭示神经网络的潜在因果机制来解释其工作原理。随着该领域影响力的增长，不仅需要关注模型本身，还需审视MI研究中隐含的假设、概念和解释策略。我们认为机制可解释性需要哲学：不是作为事后补充，而是作为持续合作伙伴，以澄清其概念、优化方法并评估解释AI系统的认识论和伦理意义。本文以MI文献中的三个开放性问题为例，展示了哲学对MI研究的价值，并提出了深化跨学科对话的路径。

</details>


### [83] [CommVQ: Commutative Vector Quantization for KV Cache Compression](https://arxiv.org/abs/2506.18879)
**中文标题：CommVQ：用于KV缓存压缩的可交换向量量化**

*Junyan Li,Yang Zhang,Muhammad Yusuf Hassan,Talha Chafekar,Tianle Cai,Zhile Ren,Pengsheng Guo,Foroozan Karimzadeh,Colorado Reed,Chong Wang,Chuang Gan*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CommVQ的向量量化方法，用于压缩大型语言模型（LLM）中的键值（KV）缓存，显著减少内存占用，同时保持高精度。通过设计可交换的码本和轻量级编码器，该方法在长上下文推理中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在长上下文应用中的普及，键值（KV）缓存在GPU上的内存占用成为瓶颈。为了解决这一问题，本文提出了一种高效的压缩方法，以减少内存使用并保持模型性能。

研究方法: 本文提出了一种可交换向量量化（CommVQ）方法，通过轻量级编码器和码本对KV缓存进行压缩，解码过程仅需简单矩阵乘法。此外，码本设计为与旋转位置嵌入（RoPE）可交换，并通过期望最大化（EM）算法训练，以降低解码计算成本。

研究结果: 实验表明，该方法在长上下文基准测试和GSM8K上表现优异，将FP16 KV缓存大小减少87.5%（2位量化），并优于现有KV缓存量化方法。1位量化时，精度损失极小，使LLaMA-3.1 8B模型能在单块RTX 4090 GPU上支持128K上下文长度。

研究结论: CommVQ通过可交换向量量化显著减少了KV缓存的内存占用，同时保持了高精度和低计算开销，为长上下文LLM推理提供了高效解决方案。

中文摘要: 大型语言模型（LLM）在需要长上下文的应用中日益普及，但随着上下文增长，键值（KV）缓存在GPU上的内存占用成为瓶颈。为此，我们提出可交换向量量化（CommVQ），显著减少长上下文LLM推理中的内存使用。我们首先引入轻量级编码器和码本的加法量化来压缩KV缓存，解码仅需简单矩阵乘法。为降低解码计算成本，我们设计码本与旋转位置嵌入（RoPE）可交换，并通过期望最大化（EM）算法训练，从而高效地将解码集成到自注意力机制中。我们的方法通过加法量化和RoPE可交换码本实现高精度和低开销。在长上下文基准测试和GSM8K上的实验表明，该方法在2位量化下将FP16 KV缓存大小减少87.5%，优于现有KV缓存量化方法。值得注意的是，1位量化时精度损失极小，使LLaMA-3.1 8B模型能在单块RTX 4090 GPU上支持128K上下文长度。源代码见：https://github.com/UMass-Embodied-AGI/CommVQ。

</details>


### [84] [OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization](https://arxiv.org/abs/2506.18880)
**中文标题：OMEGA：大型语言模型能否在数学中跳出思维定式？探索性、组合性与转化性泛化的评估**

*Yiyou Sun,Shawn Hu,Georgia Zhou,Ken Zheng,Hannaneh Hajishirzi,Nouha Dziri,Dawn Song*

主要分类: cs.CL

摘要简述: 本文介绍了OMEGA基准测试，用于评估大型语言模型（LLMs）在数学问题中的三种泛化能力：探索性、组合性和转化性。研究发现，前沿LLMs在复杂问题中表现显著下降，而微调模型在探索性泛化上有所提升，但组合性和转化性泛化仍有限。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在数学推理中表现优异，但在需要新颖思维的问题上表现不佳。为系统研究这些局限性，作者提出OMEGA基准测试，旨在评估模型在探索性、组合性和转化性泛化上的能力。

研究方法: OMEGA基准测试通过程序化生成训练-测试对，涵盖几何、数论、代数等多个数学领域，并验证解决方案的准确性。作者评估了前沿LLMs的表现，并对Qwen系列模型进行了微调。

研究结果: 前沿LLMs在复杂问题中表现显著下降。微调后的Qwen模型在探索性泛化上有所提升，但组合性和转化性泛化改进有限。

研究结论: OMEGA基准测试为提升LLMs在数学创造力方面的能力奠定了基础，揭示了当前模型在组合性和转化性推理上的局限性。

中文摘要: 近期具备长链思维推理能力的大型语言模型（如DeepSeek-R1）在奥林匹克数学基准测试中取得了令人瞩目的成绩。然而，这些模型通常依赖有限的策略，难以应对需要新颖思维方式的问题。为系统研究这些局限性，我们提出了OMEGA（分布外数学问题评估与三种泛化轴）——一个受Boden创造力分类启发的多样化基准测试，旨在评估三种分布外泛化能力：（1）探索性：将已知问题解决技能应用于同一领域内更复杂的实例；（2）组合性：将孤立学习的推理技能结合，以解决需要新方式整合这些技能的问题；（3）转化性：超越熟悉的方法，采用新颖甚至非常规的策略更高效地解决问题。OMEGA包含从几何、数论、代数、组合数学、逻辑和谜题等领域模板化问题生成器生成的训练-测试对，并通过符号、数值或图形方法验证解决方案。我们评估了前沿LLMs，发现随着问题复杂度的增加，其性能显著下降。此外，我们对Qwen系列模型在所有泛化设置下进行了微调，观察到探索性泛化的显著提升，而组合性泛化仍有限，转化性推理几乎没有改进。通过分离和量化这些细粒度失败案例，OMEGA为推进LLMs超越机械熟练度、实现真正的数学创造力奠定了基础。

</details>


### [85] [ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2506.18896)
**中文标题：ReasonFlux-PRM：面向长链推理的轨迹感知PRM**

*Jiaru Zou,Ling Yang,Jingwen Gu,Jiahao Qiu,Ke Shen,Jingrui He,Mengdi Wang*

主要分类: cs.CL

摘要简述: ReasonFlux-PRM是一种新型轨迹感知PRM，专为评估轨迹响应型推理轨迹设计，结合步骤级和轨迹级监督，显著提升推理模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有PRM主要基于模型最终输出训练，难以稳健评估中间推理轨迹，尤其是在前沿推理模型生成的轨迹响应输出中。

研究方法: ReasonFlux-PRM引入步骤级和轨迹级监督，支持离线和在线奖励监督，包括高质量数据选择、密集过程奖励和测试时奖励引导。

研究结果: 在AIME、MATH500和GPQA-Diamond等基准测试中，ReasonFlux-PRM-7B表现优于其他PRM和人工基线，平均提升12.1%（监督微调）、4.5%（强化学习）和6.3%（测试时扩展）。

研究结论: ReasonFlux-PRM显著提升了推理模型的性能，并发布了轻量级版本ReasonFlux-PRM-1.5B，适用于资源受限场景。

中文摘要: 过程奖励模型（PRM）是监督大型语言模型（LLM）中间推理步骤的强大框架。现有PRM主要基于模型最终输出训练，难以稳健评估中间推理轨迹，尤其是在前沿推理模型（如Deepseek-R1）生成的轨迹响应输出中。本文提出ReasonFlux-PRM，一种新型轨迹感知PRM，专为评估轨迹响应型推理轨迹设计。ReasonFlux-PRM结合步骤级和轨迹级监督，实现与结构化思维链数据对齐的细粒度奖励分配。我们支持离线和在线奖励监督，包括：（i）为下游监督微调选择高质量蒸馏数据，（ii）在强化学习中提供密集过程级奖励，（iii）支持奖励引导的测试时扩展。在AIME、MATH500和GPQA-Diamond等基准测试中，ReasonFlux-PRM-7B表现优于其他PRM（如Qwen2.5-Math-PRM-72B）和人工基线。此外，ReasonFlux-PRM-7B在监督微调、强化学习和测试时扩展中分别实现12.1%、4.5%和6.3%的平均提升。我们还发布了轻量级ReasonFlux-PRM-1.5B，适用于资源受限场景和边缘部署。项目地址：https://github.com/Gen-Verse/ReasonFlux

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [86] [Mechanistic Interpretability of Diffusion Models: Circuit-Level Analysis and Causal Validation](https://arxiv.org/abs/2506.17237)
**中文标题：扩散模型的机制可解释性：电路级分析与因果验证**

*Dip Roy*

主要分类: cs.CV

摘要简述: 本文通过定量电路级分析揭示了扩散模型的图像生成机制，发现合成数据与真实人脸数据处理的算法差异，并识别了八种功能不同的注意力机制。干预实验验证了关键计算瓶颈，为生成模型的行为控制提供了因果证据。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在定量分析扩散模型的电路级机制，揭示其在合成与自然数据分布处理中的算法差异，为生成模型的行为理解和控制提供基础。

研究方法: 通过对2,000张合成图像和2,000张CelebA人脸图像进行系统干预实验，分析扩散模型的计算路径和注意力机制，识别功能不同的注意力角色。

研究结果: 研究发现真实人脸处理需要更高计算复杂度（复杂度比=1.084±0.008），并识别了八种注意力机制（如边缘检测、纹理分析等）。干预实验显示关键计算瓶颈导致性能下降25.6%至128.3%。

研究结论: 研究为扩散模型的算法理解和行为控制提供了定量基础，揭示了注意力机制在图像生成中的关键作用。

中文摘要: 我们提出了扩散模型的定量电路级分析，建立了图像生成过程的计算路径和机制原理。通过对2,000张合成图像和2,000张CelebA人脸图像的系统干预实验，我们发现扩散架构在处理合成与自然数据分布时存在基础算法差异。研究表明，真实人脸处理需要计算复杂度显著更高的电路（复杂度比=1.084±0.008，p<0.001），并在去噪时间步中表现出不同的注意力专业化模式（熵散度范围为0.015至0.166）。我们识别了八种功能不同的注意力机制，包括边缘检测（熵=3.18±0.12）、纹理分析（熵=4.16±0.08）和语义理解（熵=2.67±0.15）。干预分析揭示了关键计算瓶颈，针对性消融导致性能下降25.6%至128.3%，为电路功能提供了因果证据。这些发现为通过机制干预策略理解和控制生成模型行为奠定了定量基础。

</details>


### [87] [SRKD: Towards Efficient 3D Point Cloud Segmentation via Structure- and Relation-aware Knowledge Distillation](https://arxiv.org/abs/2506.17290)
**中文标题：SRKD：通过结构和关系感知知识蒸馏实现高效的3D点云分割**

*Yuqi Li,Junhao Dong,Zeyu Dong,Chuanguang Yang,Zhulin An,Yongjun Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SRKD的结构和关系感知知识蒸馏框架，旨在通过从大型教师模型向轻量级学生模型传递几何和语义知识，高效解决3D点云分割的计算复杂性和部署限制问题。


<details>
  <summary>详细信息</summary>
研究动机: 3D点云分割面临计算复杂性和大规模基于Transformer模型部署限制的实际挑战，需要一种高效的方法来压缩模型复杂度并保持性能。

研究方法: SRKD框架通过亲和矩阵关系对齐模块从教师模型向学生模型传递结构依赖关系，采用跨样本小批量构建策略增强学生对几何结构的感知，并结合KL散度对齐语义分布和真实监督提升分割准确性。

研究结果: 该方法在显著降低模型复杂度的同时实现了最先进的性能，证明了其在现实部署场景中的高效性和有效性。

研究结论: SRKD通过结构和关系感知知识蒸馏，成功实现了轻量级3D点云分割模型的高效训练和部署，为实际应用提供了可行方案。

中文摘要: 3D点云分割由于大规模基于Transformer模型的计算复杂性和部署限制面临实际挑战。为解决这一问题，我们提出了一种名为SRKD的新型结构和关系感知知识蒸馏框架，将丰富的几何和语义知识从大型冻结教师模型（>100M）传递到轻量级学生模型（<15M）。具体而言，我们提出了基于亲和矩阵的关系对齐模块，通过点对点相似性匹配从教师模型向学生模型蒸馏结构依赖关系，增强学生学习上下文交互的能力。同时，我们引入了一种跨样本小批量构建策略，使学生能够感知稳定且泛化的几何结构，这种对齐是在教师模型的不同点云实例之间进行的，而非单个样本内。此外，KL散度用于对齐语义分布，真实监督进一步强化了准确分割。我们的方法在显著降低模型复杂度的同时实现了最先进的性能，证明了其在现实部署场景中的高效性和有效性。代码可在https://github.com/itsnotacie/SRKD获取。

</details>


### [88] [Fine-Scale Soil Mapping in Alaska with Multimodal Machine Learning](https://arxiv.org/abs/2506.17302)
**中文标题：基于多模态机器学习的阿拉斯加精细尺度土壤制图**

*Yijun Lin,Theresa Chen,Colby Brungard,Grunwald Sabine,Sue Ives,Matt Macander,Timm Nawrocki,Yao-Yi Chiang,Nic Jelinski*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉的机器学习模型MISO，用于生成阿拉斯加高分辨率土壤地图，以监测近地表永久冻土和土壤分类。相比传统随机森林模型，MISO在未见过区域的泛化能力和召回率更高。


<details>
  <summary>详细信息</summary>
研究动机: 阿拉斯加的土壤地图绘制对生态保护和基础设施规划至关重要，但传统方法依赖实地调查和局部模拟，效率低下。随着气候变化加速永久冻土融化，高分辨率土壤地图的需求日益迫切。

研究方法: MISO模型结合了地理空间基础模型（视觉特征提取）、隐式神经表示（连续空间预测）和对比学习（多模态对齐和地理定位感知），并与随机森林模型进行了对比。

研究结果: 空间交叉验证和区域分析表明，MISO在未见过区域的泛化能力和召回率优于随机森林模型，尤其在永久冻土区和主要土地资源区域表现突出。

研究结论: MISO展示了先进机器学习方法在高分辨率土壤地图绘制中的潜力，为永久冻土区的土壤采样和基础设施规划提供了实用指导。

中文摘要: 阿拉斯加的精细尺度土壤制图传统上依赖实地调查和局部模拟，尽管该地区生态重要且永久冻土覆盖广泛，但这一任务仍未得到充分发展。随着气候变化加速永久冻土融化，其对基础设施稳定性和土壤碳储存等关键生态系统服务构成威胁。高分辨率土壤地图对于表征永久冻土分布、识别脆弱区域和制定适应策略至关重要。我们提出了MISO，一种基于视觉的机器学习模型，用于生成全州范围的近地表永久冻土和土壤分类高分辨率土壤地图。该模型结合了地理空间基础模型（视觉特征提取）、隐式神经表示（连续空间预测）和对比学习（多模态对齐和地理定位感知）。我们将MISO与随机森林（RF）这一传统土壤制图模型进行了对比。空间交叉验证和跨永久冻土区及主要土地资源区域（MLRAs）的区域分析表明，MISO在未见过区域的泛化能力和召回率优于RF，这对监测永久冻土融化及相关环境过程至关重要。这些发现展示了先进机器学习方法在精细尺度土壤制图中的潜力，并为永久冻土影响区域的未来土壤采样和基础设施规划提供了实用指导。项目将在https://github.com/knowledge-computing/Peatland-permafrost发布。

</details>


### [89] [RadarSeq: A Temporal Vision Framework for User Churn Prediction via Radar Chart Sequences](https://arxiv.org/abs/2506.17325)
**中文标题：RadarSeq：基于雷达图序列的时间视觉框架用于用户流失预测**

*Sina Najafi,M. Hadi Sepanj,Fahimeh Jafari*

主要分类: cs.CV

摘要简述: 本文提出了一种基于雷达图序列的时间视觉框架RadarSeq，用于预测非订阅制零工平台的用户流失。通过将用户行为模式建模为雷达图序列，并结合CNN和双向LSTM，该方法显著提升了预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 在非订阅制零工平台中，用户流失是隐式的，缺乏明确标签且行为动态变化。现有方法多依赖静态快照或视觉表示，忽略了时间线索。本文旨在通过时间感知的视觉框架解决这一问题。

研究方法: 提出RadarSeq框架，将用户行为特征编码为雷达图序列，通过预训练CNN编码器和双向LSTM捕捉时空模式。

研究结果: 在真实数据集上的实验表明，RadarSeq在F1分数、精确率和AUC上分别提升17.7、29.4和16.1，优于传统模型和ViT基线。

研究结论: RadarSeq框架具有模块化设计、可解释性和高效部署特点，适用于动态零工经济平台的大规模流失建模。

中文摘要: 预测非订阅制零工平台的用户流失面临独特挑战，因为流失是隐式的且用户行为动态变化。现有方法依赖静态快照或视觉表示，忽略了关键时间线索。本文提出一种时间感知的计算机视觉框架，将用户行为模式建模为雷达图序列，每张图编码每日行为特征。通过结合预训练CNN编码器和双向LSTM，该框架捕捉了流失行为的时空模式。在大型真实数据集上的实验表明，该方法在F1分数、精确率和AUC上分别提升17.7、29.4和16.1，优于传统模型和ViT基线，同时提升了可解释性。其模块化设计、解释工具和高效部署特性使其适用于动态零工经济平台的大规模流失建模。

</details>


### [90] [P2MFDS: A Privacy-Preserving Multimodal Fall Detection System for Elderly People in Bathroom Environments](https://arxiv.org/abs/2506.17332)
**中文标题：P2MFDS：一种隐私保护的多模态老年人浴室跌倒检测系统**

*Haitian Wang,Yiren Wang,Xinyu Wang,Yumeng Miao,Yuliang Zhang,Yu Zhang,Atif Mansoor*

主要分类: cs.CV

摘要简述: 本文提出了一种隐私保护的多模态跌倒检测系统P2MFDS，专为老年人在浴室环境中设计。通过融合毫米波雷达和3D振动传感，结合双流网络架构，显著提升了复杂环境下的检测准确率和召回率。


<details>
  <summary>详细信息</summary>
研究动机: 随着全球老龄化加剧，老年人跌倒风险增加，尤其在浴室等湿滑狭窄环境中。现有单模态检测系统（如WiFi、红外或毫米波）因环境干扰和系统偏差导致准确性不足。本文旨在通过多模态传感和深度学习技术，解决这些问题。

研究方法: 首先开发传感器评估框架，选择并融合毫米波雷达与3D振动传感，构建隐私保护的多模态数据集。其次提出P2MFDS双流网络，结合CNN-BiLSTM-Attention分支处理雷达动态数据，以及多尺度CNN-SEBlock-Self-Attention分支检测振动信号。

研究结果: P2MFDS在真实浴室环境中显著优于现有方法，准确率和召回率均有显著提升。数据集和预训练模型将公开发布。

研究结论: P2MFDS通过多模态传感和深度学习技术，有效解决了浴室环境中老年人跌倒检测的隐私保护和准确性挑战，为未来研究提供了重要参考。

中文摘要: 到2050年，65岁及以上人口预计将占全球人口的16%。老龄化与跌倒风险增加密切相关，尤其是在浴室等湿滑狭窄环境中，80%以上的跌倒发生于此。尽管近期研究逐渐关注非侵入式、隐私保护的方法（不依赖可穿戴设备或视频监控），但这些努力尚未完全克服现有单模态系统（如基于WiFi、红外或毫米波）的局限性，这些系统在复杂环境中准确性较低。这些局限性源于单模态传感的基本约束，包括系统偏差和环境干扰（如WiFi系统中的多径衰落和红外方法中的温度剧烈变化）。为解决这些问题，我们提出了一种隐私保护的多模态老年人浴室跌倒检测系统。首先，我们开发了传感器评估框架，选择并融合毫米波雷达与3D振动传感，构建并预处理了一个大规模、隐私保护的多模态数据集（将在发表后公开）。其次，我们提出了P2MFDS，这是一种双流网络，结合了CNN-BiLSTM-Attention分支处理雷达动态数据，以及多尺度CNN-SEBlock-Self-Attention分支检测振动信号。通过融合宏观和微观特征，P2MFDS在准确率和召回率上显著优于现有方法。代码和预训练模型将在以下网址提供：https://github.com/HaitianWang/P2MFDS-A-Privacy-Preserving-Multimodal-Fall-Detection-Network-for-Elderly-Individuals-in-Bathroom。

</details>


### [91] [A Novel Multi-layer Task-centric and Data Quality Framework for Autonomous Driving](https://arxiv.org/abs/2506.17346)
**中文标题：一种面向任务和数据质量的多层自动驾驶框架**

*Yuhan Zhou,Haihua Chen,Kewei Sha*

主要分类: cs.CV

摘要简述: 本文提出了一种面向任务和数据质量的多层框架，用于提升自动驾驶系统的功能性和可靠性。通过案例研究验证了冗余数据对任务性能的影响，并呼吁社区关注数据质量与任务需求的匹配。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶领域的研究和实践过于关注模型和算法，而忽视了数据质量（DQ）对系统性能的影响。下一代自动驾驶车辆需要高效、可靠且适应动态环境的数据处理框架。

研究方法: 提出一个五层框架（数据层、DQ层、任务层、应用层和目标层），将数据质量与任务需求和性能目标关联。通过nuScenes数据集上的案例研究，分析多源图像数据的冗余对YOLOv8目标检测任务的影响。

研究结果: 研究表明，部分去除多源图像数据的冗余可以提升目标检测任务的性能。同时，图像和LiDAR数据的多模态分析揭示了现有冗余数据质量问题。

研究结论: 本文为自动驾驶领域的数据质量、任务编排和性能导向系统开发提供了新思路，有望推动构建更具适应性、可解释性和鲁棒性的自动驾驶系统。

中文摘要: 下一代自动驾驶车辆（AVs）依赖于大量多源和多模态数据，但在实际环境中，数据质量（DQ）因环境因素或传感器问题而存在差异。当前研究与实践过于关注模型和算法，而低估了DQ的重要性。为满足下一代AVs的功能性、高效性和可信赖性需求，本文提出了一种面向任务和数据质量的多层框架，包括数据层、DQ层、任务层、应用层和目标层。该框架旨在将DQ与任务需求和性能目标关联。通过nuScenes数据集上的案例研究，证明了部分去除多源图像数据的冗余可以提升YOLOv8目标检测任务的性能。对图像和LiDAR多模态数据的分析进一步揭示了现有冗余DQ问题。本文为DQ、任务编排和性能导向系统开发的交叉领域开辟了一系列关键但未探索的挑战，有望引导AV社区构建更具适应性、可解释性和鲁棒性的自动驾驶系统。代码、数据和实现细节公开于：https://anonymous.4open.science/r/dq4av-framework/README.md。

</details>


### [92] [Efficient Feedback Gate Network for Hyperspectral Image Super-Resolution](https://arxiv.org/abs/2506.17361)
**中文标题：高效反馈门网络在高光谱图像超分辨率中的应用**

*Xufei Wang,Mingjian Zhang,Fei Ge,Jinchen Zhu,Wen Sha,Jifen Ren,Zhimeng Hou,Shouguo Zheng,ling Zheng,Shizhuang Weng*

主要分类: cs.CV

摘要简述: 本文提出了一种高效的反馈门网络（EFGN），用于单幅高光谱图像超分辨率（SHSR），通过反馈和门操作结合大核卷积和光谱交互，显著提升了空间分辨率和光谱保真度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的单幅高光谱图像超分辨率方法未能充分利用波段间和空间-光谱信息的关联性，导致性能受限。本文旨在通过设计一种新型的基于分组的SHSR方法，提升高光谱图像的空间分辨率和光谱保真度。

研究方法: 提出了一种高效的反馈门网络（EFGN），包括以下模块：1）基于通道混洗和扩张卷积的混洗渐进扩张融合模块（SPDFM），用于学习丰富的波段信息和分层空间信息；2）宽边界感知门块和光谱增强门块，构建空间-光谱强化门模块（SSRGM），高效提取代表性特征；3）三维SSRGM增强全局信息和关联性。

研究结果: 在三个高光谱数据集上的实验表明，所提网络在光谱保真度和空间内容重建方面优于现有最优方法。

研究结论: 本文提出的EFGN通过反馈和门操作有效提升了高光谱图像的超分辨率性能，为SHSR任务提供了一种高效解决方案。

中文摘要: 即使没有辅助图像，单幅高光谱图像超分辨率（SHSR）方法也可以设计用于提高高光谱图像的空间分辨率。然而，未能充分利用波段间和空间-光谱信息的关联性，导致SHSR的性能受限。本研究提出了一种新型的基于分组的SHSR方法，称为高效反馈门网络，它利用多种反馈和门操作，包括大核卷积和光谱交互。具体而言，通过为相邻分组提供不同的指导，我们可以在混洗渐进扩张融合模块（SPDFM）中通过通道混洗和扩张卷积学习丰富的波段信息和分层空间信息。此外，我们开发了宽边界感知门块和光谱增强门块，构建了空间-光谱强化门模块（SSRGM），高效获取高度代表性的空间-光谱特征。另外，我们应用三维SSRGM增强高光谱数据的全局信息和关联性。在三个高光谱数据集上的实验结果表明，所提网络在光谱保真度和空间内容重建方面优于现有最优方法。

</details>


### [93] [From Drawings to Decisions: A Hybrid Vision-Language Framework for Parsing 2D Engineering Drawings into Structured Manufacturing Knowledge](https://arxiv.org/abs/2506.17374)
**中文标题：从图纸到决策：一种混合视觉语言框架用于将2D工程图纸解析为结构化制造知识**

*Muhammad Tayyab Khan,Lequn Chen,Zane Yong,Jun Ming Tan,Wenhe Feng,Seung Ki Moon*

主要分类: cs.CV

摘要简述: 本文提出了一种混合视觉语言框架，用于从2D工程图纸中提取结构化制造知识，结合旋转感知的目标检测模型和轻量级视觉语言解析器，显著提升了信息提取的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统手动提取2D工程图纸中的关键信息（如几何尺寸与公差、材料规格等）效率低下且易出错，而通用OCR模型因复杂布局和工程符号等问题表现不佳。因此，需要一种高效且准确的方法来支持数字化制造流程。

研究方法: 提出了一种混合框架，结合YOLOv11-OBB（旋转感知目标检测模型）和基于Transformer的视觉语言解析器。首先使用YOLOv11-OBB定位标注并提取定向边界框（OBB）图像块，然后通过微调的轻量级视觉语言模型（VLM）解析为结构化输出。实验使用了1,367张2D机械图纸数据集，并比较了Donut和Florence-2两种VLM的性能。

研究结果: Donut模型表现优于Florence-2，达到88.5%的精确率、99.2%的召回率和93.5%的F1分数，幻觉率为11.5%。案例研究表明，提取的结构化信息可有效支持下游制造任务（如工艺和工具选择）。

研究结论: 该框架显著提升了2D工程图纸解析的准确性和实用性，为数字化制造提供了可靠支持。

中文摘要: 高效且准确地从2D工程图纸中提取关键信息（如几何尺寸与公差、测量值、材料规格和文本标注）对推动数字化制造流程至关重要。手动提取缓慢且费力，而通用OCR模型常因复杂布局、工程符号和旋转文本导致输出不完整且不可靠。为解决这些问题，我们提出了一种混合视觉语言框架，结合旋转感知目标检测模型（YOLOv11-OBB）和基于Transformer的视觉语言解析器。结构化流程首先应用YOLOv11-OBB定位标注并提取定向边界框（OBB）图像块，随后通过微调的轻量级视觉语言模型（VLM）解析为结构化输出。我们整理了一个包含1,367张2D机械图纸的数据集，标注了九类关键信息。YOLOv11-OBB在此数据集上训练以检测OBB并提取标注图像块，随后使用两种开源VLM（Donut和Florence-2）进行解析。这两种模型均为轻量级，适合在有限计算资源下完成工业任务。微调后，通过四项关键指标评估解析性能。Donut表现优于Florence-2，达到88.5%的精确率、99.2%的召回率和93.5%的F1分数，幻觉率为11.5%。最后，案例研究展示了提取的结构化信息如何支持下游制造任务（如工艺和工具选择），验证了该框架在现代化2D图纸解析中的实用价值。

</details>


### [94] [Spatial-Temporal Pre-Training for Embryo Viability Prediction Using Time-Lapse Videos](https://arxiv.org/abs/2506.17403)
**中文标题：基于时空预训练的胚胎生存能力预测方法：利用延时摄影视频**

*Zhiyi Shi,Junsik Kim,Helen Y. Yang,Yonghyun Song,Hyun-Jic Oh,Dalit Ben-Yosef,Daniel Needleman,Hanspeter Pfister*

主要分类: cs.CV

摘要简述: 本文提出了一种名为时空预训练（STPT）的自监督学习方法，用于胚胎发育视频的生存能力预测，解决了长视频和时序不对齐的挑战，并在有限计算资源下取得了最佳性能。


<details>
  <summary>详细信息</summary>
研究动机: 体外受精（IVF）中胚胎生存能力的自动化预测因标记数据稀缺而具有挑战性。现有视频自监督学习方法难以直接应用于胚胎发育视频，因其帧数多且时序不一致。

研究方法: STPT分为空间和时序两阶段：空间阶段学习单视频内对齐和增强，时序阶段建模视频嵌入间关系。通过冻结一个编码器减少内存需求，避免跨视频帧对齐。

研究结果: 在23,027个胚胎视频（3,286个标记）上，STPT以0.635的AUC（95% CI: 0.632-0.638）超越基线方法，且计算资源需求低。

研究结论: STPT有效解决了长视频和时序不对齐问题，为胚胎生存能力预测提供了高效的自监督学习方案。

中文摘要: 体外受精（IVF）中胚胎生存能力的自动化预测具有重要意义，但由于仅有少量胚胎在移植后被标记，标记数据有限，这一任务极具挑战性。自监督学习（SSL）可以利用标记和未标记数据提升预测性能，但现有视频SSL方法因以下两个挑战无法直接应用于胚胎发育视频：（1）胚胎延时视频包含数百帧，传统SSL需要大量GPU内存；（2）数据集视频长度不一且存在异常帧，传统视频对齐方法难以处理语义不对齐。为此，我们提出时空预训练（STPT）方法。STPT分为空间和时序两阶段：每阶段仅训练一个编码器并冻结另一个，以减少内存需求。为处理时序不对齐，STPT避免跨视频逐帧对齐。空间阶段学习单视频内对齐及其时序一致的增强，时序阶段建模视频嵌入间关系。该方法高效处理长视频和时序变异性。在23,027个延时视频（3,286个标记）上，STPT以0.635的AUC（95% CI: 0.632-0.638）超越基线方法，且计算资源需求有限。

</details>


### [95] [VMRA-MaR: An Asymmetry-Aware Temporal Framework for Longitudinal Breast Cancer Risk Prediction](https://arxiv.org/abs/2506.17412)
**中文标题：VMRA-MaR：一种基于不对称感知的时序框架用于纵向乳腺癌风险预测**

*Zijun Sun,Solveig Thrun,Michael Kampffmeyer*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Vision Mamba RNN（VMRNN）和状态空间模型（SSM）的时序框架VMRA-MaR，结合不对称模块（SAD和LAT），用于纵向乳腺癌风险预测，显著提升了高风险人群的筛查效果。


<details>
  <summary>详细信息</summary>
研究动机: 乳腺癌是全球主要致死原因之一，现有筛查方法多依赖最新数据，忽略了时序动态信息。本文旨在利用纵向影像数据中的时序趋势和双侧不对称性，提升乳腺癌早期预测的准确性。

研究方法: 提出VMRA-MaR框架，结合VMRNN和SSM捕捉乳腺组织演变的时序动态，并引入不对称模块（SAD和LAT）检测临床相关的双侧差异。

研究结果: 该方法在预测癌症发病方面表现显著，尤其对高密度乳腺病例和远期时间点（第四和第五年）效果更优，代码已开源。

研究结论: VMRA-MaR框架通过时序建模和不对称性检测，为乳腺癌早期识别和个性化筛查提供了新思路。

中文摘要: 乳腺癌是全球主要致死原因之一，通常通过定期筛查发现。自动化风险预测方法有望通过动态筛查高风险群体改进这一过程。现有模型多关注最新筛查数据，而临床实践启发下，利用时序信息捕捉乳腺组织演变趋势的研究日益增多。早期方法仅依赖两个时间点，近期研究虽扩展至多时间点并使用Transformer架构，但在充分利用纵向影像数据的时序动态方面仍存挑战。本文提出结合Vision Mamba RNN（VMRNN）与状态空间模型（SSM）及类LSTM记忆机制，有效捕捉乳腺组织演变的细微趋势。为进一步优化，引入不对称模块（SAD和LAT）识别临床相关的双侧差异。该框架在预测癌症发病方面表现显著，尤其对高密度乳腺病例和远期时间点（第四和第五年）效果更优，展现了其在乳腺癌早期识别和个性化筛查中的潜力。代码见https://github.com/Mortal-Suen/VMRA-MaR.git。

</details>


### [96] [Trans${^2}$-CBCT: A Dual-Transformer Framework for Sparse-View CBCT Reconstruction](https://arxiv.org/abs/2506.17425)
**中文标题：Trans$^2$-CBCT：一种用于稀疏视图CBCT重建的双Transformer框架**

*Minmin Yang,Huantao Ren,Senem Velipasalar*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Trans$^2$-CBCT的双Transformer框架，用于稀疏视图CBCT重建。通过结合CNN-Transformer特征和基于点的几何推理，显著提升了重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏视图CBCT扫描速度快且辐射剂量低，但严重的欠采样会导致伪影和空间覆盖不足。本文旨在通过结合CNN和Transformer的优势，解决这些问题。

研究方法: 1. 使用TransUNet替代传统UNet/ResNet编码器，结合CNN的局部细节捕捉和Transformer的全局上下文增强。2. 引入邻域感知的Point Transformer模块，通过3D位置编码和k近邻注意力提升空间一致性。

研究结果: 在LUNA16数据集上，Trans-CBCT比基线方法提升了1.17 dB PSNR和0.0163 SSIM；Trans$^2$-CBCT进一步提升了0.63 dB PSNR和0.0117 SSIM。实验在6到10视图下均表现优异。

研究结论: 结合CNN-Transformer特征和基于点的几何推理，Trans$^2$-CBCT显著提升了稀疏视图CBCT的重建质量，验证了该方法的有效性。

中文摘要: 稀疏视图的锥束计算机断层扫描（CBCT）能够实现更快的扫描速度和更低的辐射剂量，但严重的欠采样会导致强烈的伪影和较差的空间覆盖。我们在一个统一的框架中解决了这些挑战。首先，我们用TransUNet替代传统的UNet/ResNet编码器，这是一种混合了CNN和Transformer的模型。卷积层捕捉局部细节，而自注意力层增强全局上下文。我们通过结合多尺度特征、查询每个3D点的视图特定特征，并添加轻量级的衰减预测头，将TransUNet适配到CBCT中。这产生了Trans-CBCT，在LUNA16数据集上，其PSNR比现有基线高出1.17 dB，SSIM高出0.0163（六视图）。其次，我们引入了一种邻域感知的Point Transformer模块，以增强体积一致性。该模块使用3D位置编码和k近邻注意力来改善空间一致性。最终的模型Trans$^2$-CBCT进一步提升了0.63 dB PSNR和0.0117 SSIM。在LUNA16和ToothFairy数据集上的实验表明，从六视图到十视图均取得了稳定的提升，验证了结合CNN-Transformer特征与基于点的几何推理在稀疏视图CBCT重建中的有效性。

</details>


### [97] [Enhancing Wireless Device Identification through RF Fingerprinting: Leveraging Transient Energy Spectrum Analysis](https://arxiv.org/abs/2506.17439)
**中文标题：通过射频指纹增强无线设备识别：基于瞬态能量谱分析的方法**

*Nisar Ahmed,Gulshan Saleem,Hafiz Muhammad Shahzad Asif,Muhammad Usman Younus,Kalsoom Safdar*

主要分类: cs.CV

摘要简述: 本文提出了一种基于瞬态能量谱分析的无线设备识别方法，利用通用线性调频小波变换提取射频设备特征，并结合CNN-Bi-GRU混合深度学习模型，实现了99.17%的分类准确率。


<details>
  <summary>详细信息</summary>
研究动机: 随着物联网技术和5G无线网络的快速发展，复杂电磁环境中的辐射设备数量激增，准确识别和分类这些设备成为管理和安全的关键挑战。特定发射器识别技术为解决这一问题提供了可能。

研究方法: 研究采用通用线性调频小波变换分析射频设备的瞬态能量谱，提取特征后，提出了一种混合深度学习模型CNN-Bi-GRU进行设备识别。数据集包含9种射频设备，每样本900个属性，共1080个样本。

研究结果: 实验结果显示，CNN-Bi-GRU模型的10折交叉验证性能为：精确率99.33%、召回率99.53%、F1分数99.43%、分类准确率99.17%。

研究结论: 该方法在基于瞬态特征的射频设备识别中表现出色，适用于复杂无线环境中的设备识别与分类，具有实际应用潜力。

中文摘要: 近年来，物联网技术的快速发展和5G无线网络的广泛应用，导致复杂电磁环境中运行的辐射设备数量呈指数增长。管理和安全这些设备的关键挑战在于准确识别和分类。为解决这一问题，特定发射器识别技术作为一种有前景的解决方案应运而生，旨在以统一和标准化的方式提供可靠且高效的辐射设备识别手段。本研究提出了一种利用通用线性调频小波变换分析射频设备瞬态能量谱以提取特征的方法。数据集包含9种射频设备，每样本900个属性，共1080个均匀分布的样本。这些特征随后被用于分类建模框架。为克服传统机器学习方法的局限性，我们引入了一种名为CNN-Bi-GRU的混合深度学习模型，用于基于瞬态特征的射频设备识别。所提方法的10折交叉验证性能为：精确率99.33%、召回率99.53%、F1分数99.43%、分类准确率99.17%。结果表明，CNN-Bi-GRU方法在分类性能上表现优异，适用于基于瞬态特征的射频设备准确识别，并有望提升复杂无线环境中的设备识别与分类能力。

</details>


### [98] [AQUA20: A Benchmark Dataset for Underwater Species Classification under Challenging Conditions](https://arxiv.org/abs/2506.17455)
**中文标题：AQUA20：挑战性条件下水下物种分类的基准数据集**

*Taufikur Rahman Fuad,Sabbir Ahmed,Shahriar Ivan*

主要分类: cs.CV

摘要简述: 本文介绍了AQUA20数据集，一个包含8,171张水下图像的基准数据集，涵盖20种海洋物种，用于评估深度学习模型在复杂水下环境中的分类性能。实验表明ConvNeXt模型表现最佳，同时提供了可解释性分析。


<details>
  <summary>详细信息</summary>
研究动机: 水下视觉识别因浑浊、低光照和遮挡等复杂失真问题而极具挑战性，现有视觉系统性能严重下降。为此，本文提出AQUA20数据集，为水下视觉理解提供资源，并评估深度学习模型在此环境中的表现。

研究方法: 研究构建了AQUA20数据集，包含8,171张水下图像，涵盖20种海洋物种，并评估了13种深度学习模型（包括轻量级CNN和基于Transformer的架构）的分类性能。使用GRAD-CAM和LIME进行可解释性分析。

研究结果: ConvNeXt模型表现最佳，Top-3准确率达98.82%，Top-1准确率为90.69%，F1分数为88.92%。其他模型在复杂性和性能之间存在权衡。可解释性分析揭示了模型的优缺点。

研究结论: AQUA20数据集为水下物种识别研究提供了重要基础，实验结果展示了模型性能的提升空间，并强调了该数据集对未来研究的价值。

中文摘要: 水下环境中的鲁棒视觉识别因浑浊、低光照和遮挡等复杂失真问题而极具挑战性，这些因素严重降低了标准视觉系统的性能。本文介绍了AQUA20，一个包含8,171张水下图像的基准数据集，涵盖20种海洋物种，反映了光照、浑浊度和遮挡等真实环境挑战，为水下视觉理解提供了宝贵资源。评估了13种最先进的深度学习模型（包括轻量级CNN如SqueezeNet、MobileNetV2和基于Transformer的架构如ViT、ConvNeXt），以衡量其在挑战性条件下分类海洋物种的性能。实验结果表明，ConvNeXt表现最佳，Top-3准确率为98.82%，Top-1准确率为90.69%，F1分数为88.92%，且参数量适中。其他基准模型的结果也展示了复杂性与性能之间的权衡。此外，使用GRAD-CAM和LIME进行了广泛的可解释性分析，以解释模型的优势和不足。结果表明，水下物种识别仍有较大改进空间，并证明了AQUA20作为该领域未来研究基础的价值。数据集公开于：https://huggingface.co/datasets/taufiktrf/AQUA20。

</details>


### [99] [When Every Millisecond Counts: Real-Time Anomaly Detection via the Multimodal Asynchronous Hybrid Network](https://arxiv.org/abs/2506.17457)
**中文标题：分秒必争：基于多模态异步混合网络的实时异常检测**

*Dong Xiao,Guangyao Chen,Peixi Peng,Yangru Huang,Yifan Zhao,Yongxing Dai,Yonghong Tian*

主要分类: cs.CV

摘要简述: 本文提出了一种用于自动驾驶的实时异常检测方法，通过结合事件相机和RGB相机的多模态异步混合网络，同时优化响应时间和检测精度。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶系统的安全性和可靠性依赖于高效的异常检测，但现有方法多关注精度而忽视响应时间，无法满足实时驾驶场景的需求。

研究方法: 提出了一种多模态异步混合网络，利用事件相机的高时间分辨率通过异步图神经网络，并结合RGB相机的空间特征提取CNN，以捕捉驾驶环境的时空动态。

研究结果: 在基准数据集上的实验表明，该方法在精度和响应时间上均优于现有方法，实现了毫秒级的实时性能。

研究结论: 该方法通过多模态异步混合网络，成功实现了自动驾驶中的实时异常检测，兼顾了高精度和低延迟。

中文摘要: 异常检测对自动驾驶系统的安全性和可靠性至关重要。现有方法通常关注检测精度而忽视响应时间，这在时间敏感的驾驶场景中尤为关键。本文提出了一种面向自动驾驶的实时异常检测方法，同时优化了响应时间和检测精度。我们设计了一种新型多模态异步混合网络，结合了事件相机的事件流和RGB相机的图像数据。该网络通过异步图神经网络利用事件相机的高时间分辨率，并与RGB图像中CNN提取的空间特征相结合，有效捕捉了驾驶环境的时空动态，实现了快速且精确的异常检测。在多个基准数据集上的实验表明，我们的方法在精度和响应时间上均优于现有方法，达到了毫秒级的实时性能。

</details>


### [100] [Photogranulometry -- Dataset of soil images with corresponding particle size distributions](https://arxiv.org/abs/2506.17469)
**中文标题：光粒度分析——包含对应粒径分布的土壤图像数据集**

*Thomas Plante St-Cyr,François Duhaime,Jean-Sébastien Dubé,Simon Grenier*

主要分类: cs.CV

摘要简述: 本文提出了一种高分辨率土壤图像数据集，包含12,714张图像和321种土壤样本的粒径分布数据，旨在为卷积神经网络在岩土工程中的应用提供训练基础。


<details>
  <summary>详细信息</summary>
研究动机: 传统的粒径分布分析方法耗时且成本高，通过光学粒度分析可以缓解这些问题。本文旨在为岩土工程实验室提供一种高效的数据集，以支持卷积神经网络的训练和应用。

研究方法: 研究采集了321种土壤样本，拍摄了12,714张高分辨率图像（45 MP，最小尺度为39.4微米/像素），并在湿润和干燥状态下进行标准化拍摄。使用定制测试台和13x9英寸白色铝托盘，对样本进行薄层铺展，大样本采用四分法减量。

研究结果: 提供了包含12,714张图像和对应粒径分布的高分辨率数据集，为卷积神经网络的训练提供了可靠的基础。

研究结论: 该数据集为岩土工程中的光学粒度分析提供了高效解决方案，支持卷积神经网络的训练，有望减少传统方法的成本和耗时。

中文摘要: 传统的粒径分布（PSD）分析耗时且成本高昂，维护和人力投入大。通过将光学粒度分析整合到常规岩土实验室工作流程中，可以缓解这些问题。本文提供了一个高分辨率数据集，包含12,714张图像和321种在加拿大魁北克蒙特利尔地区采集的土壤样本及其PSD分析。该数据集旨在为卷积神经网络（CNN）在岩土工程应用中的训练提供坚实基础。土壤样本在湿润和干燥状态下以标准化俯视角度拍摄，分辨率为45 MP，最小尺度为39.4微米/像素。使用定制测试台和13x9英寸白色铝托盘，将样本薄层铺展。对于超过尺寸限制的样本，采用四分法减量。

</details>


### [101] [Few-Shot, Now for Real: Medical VLMs Adaptation without Balanced Sets or Validation](https://arxiv.org/abs/2506.17500)
**中文标题：少样本适应，真实场景：无需平衡集或验证的医学视觉语言模型适应**

*Julio Silva-Rodríguez,Fereshteh Shakeri,Houda Bahig,Jose Dolz,Ismail Ben Ayed*

主要分类: cs.CV

摘要简述: 本文挑战了医学视觉语言模型（VLM）在少样本适应中的不现实假设，提出了一种无需平衡数据集或验证集的真实适应方法，并引入了一种无需训练的自适应线性探针方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有医学VLM少样本适应方法假设数据分布平衡且需要验证集，这与实际医学场景中疾病分布不均衡且数据稀缺的现实不符。本文旨在解决这一问题。

研究方法: 提出了一种无需平衡支持集或验证集的真实适应设置，并设计了一种训练免费的自适应线性探针方法，动态融合视觉和文本监督。

研究结果: 实验表明，现有方法在真实条件下性能显著下降，甚至可能不如零样本推理；而提出的方法在多种模态和任务中表现稳健且高效。

研究结论: 本文提出的方法为医学VLM在真实场景中的少样本适应提供了高效且鲁棒的解决方案，显著优于现有方法。

中文摘要: 视觉语言模型（VLM）在医学图像分析中受到关注。这些模型通过大规模异构数据预训练，生成丰富且可迁移的表示。特别是，结合模态专用VLM与少样本适应已取得显著成果，实现了高性能解决方案的高效部署。然而，此前研究对适应数据分布的假设过于理想化，与医学领域的实际情况不符。首先，现有方法假设支持集是平衡的，这与真实世界中疾病流行率的不均衡性相矛盾。其次，这些方法通常需要额外的验证集来调整关键超参数，这在数据稀缺时效率低下。本文挑战了这些理想化的部署场景，提出了一种真实、不均衡且无需验证的适应设置。通过多种模态和下游任务的广泛实验，我们发现现有方法在真实条件下性能显著下降，甚至可能不如零样本推理。此外，我们提出了一种无需训练的自适应线性探针方法，动态融合视觉和文本监督。详细研究表明，该方法是一种高效且鲁棒的基线，能够在挑战性场景中实现稳健适应。

</details>


### [102] [Trustworthy Few-Shot Transfer of Medical VLMs through Split Conformal Prediction](https://arxiv.org/abs/2506.17503)
**中文标题：基于分割共形预测的医学视觉语言模型可信少样本迁移**

*Julio Silva-Rodríguez,Ismail Ben Ayed,Jose Dolz*

主要分类: cs.CV

摘要简述: 本文提出了一种名为转导式分割共形适应（SCA-T）的新方法，用于在医学视觉语言模型（VLM）的少样本迁移中提供可信度保证。通过联合校准和测试数据的无监督转导适应，解决了传统分割共形预测（SCP）在模型适应时破坏数据交换性假设的问题，显著提升了效率和条件覆盖范围。


<details>
  <summary>详细信息</summary>
研究动机: 医学视觉语言模型（VLM）在少样本图像分类中表现出强大的迁移能力，但其可靠性尚未得到充分研究。传统分割共形预测（SCP）在模型适应时会破坏测试数据的交换性假设，导致性能下降。本文旨在解决这一问题，提供更可靠的迁移方法。

研究方法: 提出转导式分割共形适应（SCA-T），一种新的迁移学习流程。该方法在共形场景下，通过联合校准和测试数据的无监督转导适应，避免了传统SCP中模型适应对数据交换性的破坏。实验覆盖多种医学图像模态、迁移任务和非共形性评分。

研究结果: SCA-T在效率和条件覆盖范围上均优于传统SCP，同时保持了相同的经验保证。实验结果表明，该方法在多种医学图像分类任务中表现一致且高效。

研究结论: SCA-T为医学VLM的少样本迁移提供了一种可靠且高效的解决方案，解决了传统SCP在模型适应时的局限性，为实际应用中的可信度问题提供了新的思路。

中文摘要: 医学视觉语言模型（VLM）展现出前所未有的迁移能力，并越来越多地用于数据高效的图像分类。尽管其日益流行，但其可靠性方面仍未被充分探索。本研究探索了分割共形预测（SCP）框架，以在基于少量标记校准集迁移此类模型时提供可信度保证。尽管潜力巨大，但VLM预训练的通用性可能对特定任务的共形预测集性质产生负面影响。在迁移学习中，常见的判别性目的适应阶段在实践中用于共形目的时效果不佳，因为使用校准数据适应模型会破坏SCP中测试数据的严格交换性假设。为解决这一问题，我们提出了转导式分割共形适应（SCA-T），一种用于共形场景迁移学习的新流程，它联合校准和测试数据进行无监督转导适应。我们通过多种医学图像模态、迁移任务和非共形性评分进行了全面实验。与SCP相比，我们的框架在效率和条件覆盖范围上均表现出持续优势，同时保持了相同的经验保证。

</details>


### [103] [Learning golf swing signatures from a single wrist-worn inertial sensor](https://arxiv.org/abs/2506.17505)
**中文标题：从单手腕惯性传感器学习高尔夫挥杆特征**

*Jessy Lauer*

主要分类: cs.CV

摘要简述: 本文提出了一种基于单手腕惯性传感器的个性化高尔夫挥杆分析方法，通过数据驱动的框架解决了传统挥杆分析中的局限性，如孤立指标、专业运动员数据不足等。


<details>
  <summary>详细信息</summary>
研究动机: 高尔夫挥杆分析对表现和预防损伤至关重要，但传统方法存在孤立指标、专业运动员数据不足等问题。本文旨在通过数据驱动的方法填补这些空白，提供更全面、可解释的挥杆分析。

研究方法: 作者构建了一个大型专业挥杆数据集，利用生物精确的人体网格重建技术生成合成惯性数据，训练神经网络从手腕数据推断动作并分割挥杆阶段。同时，学习了一种离散的运动基元词汇表，用于检测技术缺陷。

研究结果: 系统能够从手腕数据准确估计全身运动学和挥杆事件，提供实验室级别的运动分析，并支持早期异常动作检测。此外，还揭示了细微的个性化运动特征，挑战了挥杆一致性和单一“理想”挥杆的假设。

研究结论: 本研究填补了实验室与现场生物力学之间的空白，为研究、教练和损伤预防提供了可扩展、高保真的运动分析方法，并为运动表型、个性化装备设计和运动技能发展开辟了新方向。

中文摘要: 尽管高尔夫挥杆分析对表现和预防损伤至关重要，但其受限于孤立指标、专业运动员数据不足以及缺乏丰富可解释的运动表征。我们通过一个基于单手腕传感器的个性化挥杆分析框架填补了这些空白。我们构建了一个大型专业挥杆数据集，利用生物精确的人体网格重建技术生成合成惯性数据，训练神经网络从手腕数据推断动作并分割挥杆阶段。我们学习了一种离散的运动基元词汇表，用于检测技术缺陷，并能预测球员身份、球杆类型、性别和年龄。系统从手腕数据准确估计全身运动学和挥杆事件，提供实验室级别的运动分析，支持早期异常动作检测。可解释性方法揭示了细微的个性化运动特征，表明变异性是高水平表现的标志。纵向跟踪显示实际价值：一名球员的差点在1.5年内从50降至2.2，系统捕捉到了技术进步的量化指标并提供了针对性反馈。我们的发现挑战了常见假设，如挥杆在不同球杆间的一致性以及单一“理想”挥杆的存在，并揭示了由内在特征和任务特定约束形成的潜在生物标志。本研究连接了实验室与现场生物力学，为研究、教练和损伤预防提供了可扩展、高保真的运动分析方法，并为运动表型、个性化装备设计和运动技能发展开辟了新方向。

</details>


### [104] [Scene-R1: Video-Grounded Large Language Models for 3D Scene Reasoning without 3D Annotations](https://arxiv.org/abs/2506.17545)
**中文标题：Scene-R1：无需3D标注的视频驱动大语言模型3D场景推理**

*Zhihao Yuan,Shuyi Jiang,Chun-Mei Feng,Yaolun Zhang,Shuguang Cui,Zhen Li,Na Zhao*

主要分类: cs.CV

摘要简述: 本文提出Scene-R1框架，通过强化学习驱动的推理和两阶段定位流程，无需3D标注即可实现3D场景理解，并在多个数据集上超越现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大语言模型的3D场景理解方法依赖预训练的3D检测器，且决策过程不透明。Scene-R1旨在通过视频驱动的框架，消除对3D标注的依赖，并提供透明的推理过程。

研究方法: Scene-R1采用两阶段定位流程：1）时间定位阶段选择与查询相关的视频片段；2）图像定位阶段预测2D边界框，并通过SAM2生成像素级掩码，最后投影回3D空间。该方法无需3D标注，仅需任务级2D框或文本标签。

研究结果: Scene-R1在多个数据集上超越现有开放词汇基线，同时提供逐步透明的推理过程，验证了基于RGB-D视频的强化学习推理在3D场景理解中的有效性。

研究结论: Scene-R1展示了无需3D标注的3D场景理解可行性，结合强化学习和视频数据，为高效且可信的3D推理提供了新途径。

中文摘要: 目前，利用大语言模型理解3D世界正变得流行。然而现有的3D感知大语言模型如同黑箱：它们输出边界框或文本答案，却不揭示决策过程，且仍依赖预训练的3D检测器提供对象提案。我们提出Scene-R1，一种视频驱动的框架，通过将强化学习驱动的推理与两阶段定位流程结合，无需任何点级3D实例标注即可学习3D场景推理。在时间定位阶段，我们显式推理视频并选择与开放式查询最相关的片段；在随后的图像定位阶段，我们分析图像并预测2D边界框，然后使用SAM2跟踪对象以生成RGB帧中的像素级掩码，并将其投影回3D空间，从而无需基于3D检测器的提案，同时捕捉精细的几何和材质线索。Scene-R1还可适应3D视觉问答任务，直接从视频中回答自由形式问题。我们的训练流程仅需任务级2D框或文本标签，无需密集3D点级标注。Scene-R1在多个数据集上超越现有开放词汇基线，并提供透明的逐步推理。这些结果表明，基于强化学习的推理结合RGB-D视频，为可信的3D场景理解提供了一条高效且标注节约的实用路径。

</details>


### [105] [SynDaCaTE: A Synthetic Dataset For Evaluating Part-Whole Hierarchical Inference](https://arxiv.org/abs/2506.17558)
**中文标题：SynDaCaTE：用于评估部分-整体层次推理的合成数据集**

*Jake Levi,Mark van der Wilk*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SynDaCaTE的合成数据集，用于评估部分-整体层次推理能力，并揭示了现有胶囊模型的瓶颈，同时展示了自注意力机制在部分到整体推理中的高效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前胶囊网络在训练过程中难以验证是否真正学习到部分-整体层次结构，因此需要一种专门的数据集来评估此类模型的性能。

研究方法: 作者开发了SynDaCaTE合成数据集，并通过实验验证了现有胶囊模型的瓶颈，同时测试了置换等变自注意力机制在部分-整体推理中的表现。

研究结果: 实验表明，现有胶囊模型存在瓶颈，而自注意力机制在部分到整体推理中表现出色，为未来计算机视觉模型的归纳偏置设计提供了新方向。

研究结论: SynDaCaTE数据集为评估部分-整体层次推理提供了有效工具，同时揭示了自注意力机制的潜力，推动了相关领域的研究。

中文摘要: 学习推断对象表示，尤其是部分-整体层次结构，一直是计算机视觉研究的重点，旨在提高数据效率、系统泛化能力和鲁棒性。设计用于推断部分-整体层次结构的模型（通常称为胶囊网络）通常在监督任务（如对象分类）上进行端到端训练，这种情况下很难评估模型是否真正学习到了部分-整体层次结构。为解决这一问题，我们提出了一个名为SynDaCaTE的合成数据集，并通过以下两点验证其有效性：（1）揭示了现有胶囊模型的瓶颈，（2）展示了置换等变自注意力机制在部分到整体推理中的高效性，为未来计算机视觉模型的归纳偏置设计提供了新方向。

</details>


### [106] [VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models](https://arxiv.org/abs/2506.17561)
**中文标题：VLA-OS：视觉-语言-动作模型中的规划表示与范式结构分析与解构**

*Chongkai Gao,Zixuan Liu,Zhenghao Chi,Junshan Huang,Xin Fei,Yiwen Hou,Yuxuan Zhang,Yudi Lin,Zhirui Fang,Zeyu Jiang,Lin Shao*

主要分类: cs.CV

摘要简述: 本文提出VLA-OS，一种统一的视觉-语言-动作（VLA）架构系列，通过系统实验比较不同任务规划范式和表示，发现视觉基础规划表示优于语言表示，且分层VLA范式在任务性能、预训练、泛化能力等方面表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉-语言-动作（VLA）模型在任务规划和动作生成方面存在架构、范式和表示的多样性，导致性能提升来源难以明确。本文旨在通过统一架构和实验设计，系统研究不同规划范式和表示对性能的影响。

研究方法: 提出VLA-OS，一种支持多种任务规划范式的统一VLA架构系列，并在不同对象类别（刚体和可变形）、视觉模态（2D和3D）、环境（仿真和现实）和末端执行器（夹爪和灵巧手）上设计全面的对照实验。

研究结果: 实验结果表明：1）视觉基础规划表示通常优于语言规划表示；2）分层VLA范式在任务性能、预训练、泛化能力等方面表现更优，但训练和推理速度较慢。

研究结论: VLA-OS通过统一架构和系统实验揭示了视觉基础规划和分层范式的重要性，为未来VLA模型优化提供了方向。

中文摘要: 近期关于视觉-语言-动作（VLA）模型的研究从端到端动作生成范式转向任务规划与动作生成的流水线，显著提升了复杂长时程操作任务的性能。然而，现有方法在网络架构、规划范式、表示和训练数据来源上差异显著，使得研究者难以明确性能提升的具体来源和改进方向。为系统研究不同规划范式和表示的影响（排除网络架构和训练数据的干扰），本文提出VLA-OS，一种支持多种任务规划范式的统一VLA架构系列，并设计了涵盖不同对象类别（刚体和可变形）、视觉模态（2D和3D）、环境（仿真和现实）和末端执行器（夹爪和灵巧手）的全面对照实验。结果表明：1）视觉基础规划表示通常优于语言规划表示；2）分层VLA范式在任务性能、预训练、泛化能力、扩展性和持续学习能力上表现更优或相当，但训练和推理速度较慢。

</details>


### [107] [LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning](https://arxiv.org/abs/2506.17562)
**中文标题：基于通信高效的异构联邦学习的大语言模型驱动医学报告生成**

*Haoxuan Che,Haibo Jin,Zhengrui Guo,Yi Lin,Cheng Jin,Hao Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FedMRG的框架，通过联邦学习（FL）实现多中心隐私保护的医学报告生成（MRG），解决了通信效率和数据异质性两大挑战。


<details>
  <summary>详细信息</summary>
研究动机: 医学报告生成（MRG）需要大量医疗图像-报告对，但这些数据分散在各中心且隐私保护严格，难以集中使用。因此，亟需一种隐私保护的多中心协作方法。

研究方法: FedMRG框架采用低秩分解降低通信开销，并通过客户端感知对比学习和双适配器机制解决数据异质性，提升模型适应性和诊断准确性。

研究结果: 实验表明，FedMRG在通信效率和报告生成质量上表现优异，能够有效利用多中心数据生成临床准确的报告。

研究结论: FedMRG为多中心隐私保护的医学报告生成提供了可行方案，兼具通信效率和临床实用性。

中文摘要: 大语言模型（LLM）在医学报告生成（MRG）中展现出巨大潜力，但其发展需要大量医疗图像-报告对，而这些数据通常分散在各中心。由于隐私法规的限制，集中这些数据极具挑战性，阻碍了LLM驱动的MRG模型的开发和广泛应用。为解决这一问题，我们提出了FedMRG，首个利用联邦学习（FL）实现隐私保护的多中心LLM驱动MRG模型开发的框架，专门设计用于解决多模态数据异质性下的通信高效LLM训练难题。首先，我们的框架通过低秩分解高效分解参数更新，显著降低梯度传输成本，使LLM驱动的MRG在带宽受限的FL环境中可行。此外，我们观察到FL场景下MRG的双重异质性：各医疗中心的图像特征差异，以及报告风格和术语偏好的多样性。为此，我们进一步优化FedMRG：（1）在MRG编码器中引入客户端感知对比学习，结合诊断驱动的提示，捕捉全局通用和局部独特的特征，同时保持诊断准确性；（2）在MRG解码器中采用双适配器相互促进机制，协调通用和专用适配器以应对报告风格和术语的差异。通过对我们建立的FL-MRG基准的广泛评估，我们证明了FedMRG的通用性和适应性，凸显了其在利用多中心数据生成临床准确报告的同时保持通信效率的潜力。

</details>


### [108] [HalluRNN: Mitigating Hallucinations via Recurrent Cross-Layer Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2506.17587)
**中文标题：HalluRNN：通过跨层循环推理减少大型视觉语言模型中的幻觉**

*Le Yu,Kaishen Wang,Jianlong Xiong,Yue Cao,Tao He*

主要分类: cs.CV

摘要简述: HalluRNN通过跨层循环推理减少大型视觉语言模型中的幻觉现象，提出双门深度传播单元（DG-DPU），仅微调该模块即可在多任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型（LVLMs）虽在多任务中表现优异，但易产生视觉无依据的幻觉输出。现有方法通常需要大量资源或任务特定配置，因此需要一种更高效的架构级解决方案。

研究方法: 提出HalluRNN架构，引入双门深度传播单元（DG-DPU），该模块跨层共享并通过循环推理优化隐藏状态，自适应传播信息并减少表征漂移导致的幻觉。

研究结果: 仅微调DG-DPU模块的HalluRNN在多个基准测试中表现出色，显著减少了幻觉现象。

研究结论: HalluRNN通过跨层循环推理和DG-DPU模块，提供了一种高效且资源友好的方法，显著减少了大型视觉语言模型中的幻觉问题。

中文摘要: 尽管大型视觉语言模型（LVLMs）在各种任务中表现卓越，但仍易产生文本合理但视觉无依据的幻觉输出。现有方法通常通过数据为中心的微调或创新解码策略解决此问题，但这些方法往往需要大量资源或任务特定配置。本研究提出一种架构级解决方案HalluRNN，通过跨层循环推理增强模型稳定性。具体而言，我们提出一种新型双门深度传播单元（DG-DPU）模块，该模块跨层共享并通过循环优化隐藏状态，实现信息自适应传播，确保层间一致性，并减少表征漂移导致的幻觉。仅微调DG-DPU模块的HalluRNN在多个基准测试中表现出色且稳健。

</details>


### [109] [DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving](https://arxiv.org/abs/2506.17590)
**中文标题：DRAMA-X：一种用于驾驶的细粒度意图预测和风险推理基准**

*Mihir Godbole,Xiangbo Gao,Zhengzhong Tu*

主要分类: cs.CV

摘要简述: DRAMA-X是一个用于自动驾驶的细粒度意图预测和风险推理基准，填补了现有研究中多类意图预测在安全关键场景中的空白，并提出了一个轻量级框架SGG-Intent作为基线。


<details>
  <summary>详细信息</summary>
研究动机: 理解行人、骑行者等弱势道路使用者（VRUs）的短期运动对自动驾驶安全至关重要，尤其是在高风险或模糊行为场景中。目前缺乏评估多类意图预测的基准，DRAMA-X旨在填补这一空白。

研究方法: DRAMA-X基于DRAMA数据集，通过自动化标注流程构建，包含5,686帧事故易发场景的标注数据。提出SGG-Intent框架，利用视觉语言模型（VLMs）和大型语言模型（LLMs）进行场景图生成、意图推理、风险评估和动作建议。

研究结果: 实验表明，基于场景图的推理方法显著提升了意图预测和风险评估的准确性，尤其是在显式建模上下文线索时。

研究结论: DRAMA-X为自动驾驶决策提供了结构化评估基准，SGG-Intent展示了场景图推理在意图和风险任务中的潜力。

中文摘要: 理解行人、骑行者等弱势道路使用者（VRUs）的短期运动对自动驾驶安全至关重要，尤其是在高风险或模糊行为场景中。尽管视觉语言模型（VLMs）已实现开放词汇感知，但其在细粒度意图推理中的应用尚未充分探索。目前尚无基准评估安全关键场景中的多类意图预测。为此，我们提出了DRAMA-X，一个基于DRAMA数据集并通过自动化标注流程构建的细粒度基准。DRAMA-X包含5,686帧事故易发场景的标注数据，包括目标边界框、九类方向意图分类、二元风险评分、专家生成的自我车辆动作建议及运动描述摘要。这些标注支持对自动驾驶决策中四项核心任务的结构化评估：目标检测、意图预测、风险评估和动作建议。作为参考基线，我们提出了SGG-Intent，一个轻量级、无需训练的框架，模拟自我车辆的推理流程。它通过VLM支持的检测器从视觉输入生成场景图，推断意图，评估风险，并利用大型语言模型（LLM）支持的组合推理阶段推荐动作。我们评估了多种最新VLMs，比较了其在DRAMA-X四项任务中的表现。实验表明，基于场景图的推理显著提升了意图预测和风险评估的准确性，尤其是在显式建模上下文线索时。

</details>


### [110] [SELFI: Selective Fusion of Identity for Generalizable Deepfake Detection](https://arxiv.org/abs/2506.17592)
**中文标题：SELFI：选择性身份融合用于可泛化的深度伪造检测**

*Younghun Kim,Minsuk Jang,Myung-Joon Kwon,Wonjun Lee,Changick Kim*

主要分类: cs.CV

摘要简述: 本文提出SELFI框架，通过选择性融合身份特征提升深度伪造检测的泛化能力，实验表明其在跨操纵方法检测中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究对身份特征在深度伪造检测中的作用存在分歧：一些认为应抑制身份特征以减少偏差，另一些则依赖其作为证据。本文旨在分析身份特征的判别性和泛化性，并提出一种动态调控身份特征的方法。

研究方法: 提出SELFI框架，包含两个模块：(1) Forgery-Aware Identity Adapter (FAIA)，从冻结的人脸识别模型中提取身份嵌入并通过辅助监督投影至伪造相关空间；(2) Identity-Aware Fusion Module (IAFM)，基于相关性动态融合身份和视觉特征。

研究结果: 在四个基准测试中，SELFI平均AUC提升3.1%，在DFDC数据集上超过之前最佳方法6%。

研究结论: 身份特征在深度伪造检测中具有信息量但依赖上下文，SELFI通过动态调控身份特征显著提升了检测的泛化能力。

中文摘要: 人脸身份为深度伪造检测提供了强有力的信号。先前研究表明，即使未显式建模，分类器也常隐式学习身份特征。这导致了两种对立观点：一些研究抑制身份线索以减少偏差，而另一些则依赖其作为取证证据。为调和这些观点，我们分析两个假设：(1) 身份特征是否足以判别深度伪造；(2) 此类特征是否在跨操纵方法中泛化性差。实验证实身份特征具有信息量但依赖上下文：某些操纵保留身份一致性伪影，而其他则扭曲身份线索并损害泛化。我们认为身份特征既不应盲目抑制也不应完全依赖，而应显式建模并基于样本相关性动态调控。为此，我们提出SELFI（选择性身份融合），一种可泛化的检测框架，动态调控身份特征使用。SELFI包含：(1) Forgery-Aware Identity Adapter (FAIA)，从冻结的人脸识别模型中提取身份嵌入并通过辅助监督投影至伪造相关空间；(2) Identity-Aware Fusion Module (IAFM)，基于相关性选择性融合身份和视觉特征。在四个基准测试中，SELFI平均AUC提升3.1%，在DFDC数据集上超过之前最佳方法6%。代码将在论文接受后发布。

</details>


### [111] [A Multimodal In Vitro Diagnostic Method for Parkinson's Disease Combining Facial Expressions and Behavioral Gait Data](https://arxiv.org/abs/2506.17596)
**中文标题：一种结合面部表情和行为步态的多模态体外诊断方法用于帕金森病**

*Wei Huang,Yinxuan Xu,Yintao Zhou,Zhengyu Li,Jing Huang,Meng Pang*

主要分类: cs.CV

摘要简述: 本文提出了一种结合面部表情和行为步态的多模态体外诊断方法，用于帕金森病（PD）的早期检测。通过轻量级深度学习模型提取和融合特征，提高了诊断准确性，并建立了最大的多模态PD数据集进行验证。


<details>
  <summary>详细信息</summary>
研究动机: 帕金森病（PD）具有不可治愈性、快速进展和严重致残性，对患者及其家庭生活造成巨大挑战。随着人口老龄化，早期检测PD的需求日益增加。现有的体外诊断方法存在训练数据不足、设备要求高、泛化能力差以及单模态易误诊或漏诊等问题。

研究方法: 本文提出了一种结合面部表情和行为步态的多模态体外诊断方法，采用轻量级深度学习模型进行特征提取和融合，以提高诊断准确性并便于在移动设备上部署。同时，与医院合作建立了最大的多模态PD数据集。

研究结果: 通过大量实验验证，该方法在诊断准确性上表现优异，且适用于移动设备部署。

研究结论: 本文提出的多模态体外诊断方法有效解决了现有单模态方法的局限性，为PD的早期检测提供了高效、低成本且非侵入性的解决方案。

中文摘要: 帕金森病（PD）以其不可治愈性、快速进展和严重致残性为特征，对患者及其家庭生活造成巨大挑战。随着人口老龄化，早期检测PD的需求日益增加。体外诊断因其非侵入性和低成本而受到关注。然而，现有方法存在以下问题：1）面部表情诊断的训练数据有限；2）步态诊断需要专用设备和采集环境，泛化能力差；3）依赖单一模态易导致误诊或漏诊。为解决这些问题，我们提出了一种结合面部表情和行为步态的多模态体外诊断方法。该方法采用轻量级深度学习模型进行特征提取和融合，旨在提高诊断准确性并便于在移动设备上部署。此外，我们与医院合作建立了最大的多模态PD数据集，并通过大量实验验证了所提方法的有效性。

</details>


### [112] [OpenMAP-BrainAge: Generalizable and Interpretable Brain Age Predictor](https://arxiv.org/abs/2506.17597)
**中文标题：OpenMAP-BrainAge：一种可泛化且可解释的脑龄预测模型**

*Pengyu Kan,Craig Jones,Kenichi Oishi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer架构的可解释且鲁棒的脑龄预测模型OpenMAP-BrainAge，通过多视角MRI扫描和体积信息融合，实现了高精度和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 开发一种能够解释且对人口统计学和技术差异具有鲁棒性的脑龄预测模型，以提升脑MRI扫描的年龄预测准确性和可解释性。

研究方法: 采用基于Transformer的架构，结合自监督预训练和多视角伪3D T1加权MRI扫描，引入茎架构降低计算复杂度，并在ADNI2 & 3和OASIS3数据集上训练，在AIBL数据集上验证。

研究结果: 在ADNI2 & 3和OASIS3测试集上MAE为3.65年，在AIBL数据集上MAE为3.54年；脑龄差（BAG）随认知障碍程度增加而显著上升，且与认知评分呈显著负相关。

研究结论: 该模型通过多视角和体积信息融合，实现了高精度的脑龄预测，并提升了泛化能力和可解释性，与神经退行性疾病关联显著。

中文摘要: 目的：开发一种可解释且对脑MRI扫描中人口统计学和技术差异具有鲁棒性的年龄预测模型。材料与方法：我们提出了一种基于Transformer的架构，利用大规模数据集的自监督预训练。模型处理来自三个解剖视角的伪3D T1加权MRI扫描，并整合脑体积信息。通过引入茎架构，将传统Transformer模型的二次复杂度降至线性复杂度，从而适应高维MRI数据。我们在北美地区的ADNI2 & 3（N=1348）和OASIS3（N=716）数据集（年龄范围：42-95岁）上训练模型，按8:1:1划分为训练、验证和测试集，并在澳大利亚的AIBL数据集（N=768，年龄范围：60-92岁）上验证。结果：在ADNI2 & 3和OASIS3测试集上MAE为3.65年，在AIBL数据集上泛化能力强的MAE为3.54年。脑龄差（BAG）在不同认知组中显著增加，CN组平均为0.15年（95% CI: [-0.22, 0.51]），MCI组为2.55年（[2.40, 2.70]），AD组为6.12年（[5.82, 6.43]）。此外，BAG与认知评分呈显著负相关，MoCA和MMSE的相关系数分别为-0.185（p < 0.001）和-0.231（p < 0.001）。基于梯度的特征归因显示，脑室和白质结构是受脑老化影响的关键区域。结论：我们的模型通过融合多视角和体积信息，实现了最先进的脑龄预测精度，提升了泛化能力和可解释性，并与神经退行性疾病关联显著。

</details>


### [113] [HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs](https://arxiv.org/abs/2506.17608)
**中文标题：HIRE：面向多模态大语言模型的轻量级高分辨率图像特征增强**

*Nikitha SR,Aradhya Neeraj Mathur,Tarun Ram Menta,Rishabh Jain,Mausoom Sarkar*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级的高分辨率图像特征增强方法（HIRE），通过浅层特征增强器显著降低了多模态大语言模型的计算成本，同时保持高性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代多模态大语言模型通过集成高分辨率图像特征在细粒度视觉理解任务中表现优异，但使用大型图像编码器（如ViT）导致计算成本显著增加。本文旨在通过轻量级方法解决这一问题。

研究方法: 提出了一种浅层特征增强器，通过特征上采样扩展高分辨率特征生成，显著减少了训练和推理时间以及计算成本。

研究结果: 实验表明，该方法在保持竞争力的同时，计算成本降低了1.5倍（以FLOPs衡量）。

研究结论: HIRE方法通过轻量级设计实现了高分辨率图像特征的高效集成，为多模态大语言模型提供了计算成本优化的解决方案。

中文摘要: 在现代多模态大语言模型中集成高分辨率图像特征显著提升了细粒度视觉理解任务的性能，并在多个基准测试中取得了优异表现。然而，这些特征通常来自大型图像编码器（如ViT），多次调用这些编码器导致计算成本大幅增加。本文首先将特征上采样作为高分辨率特征生成的自然扩展进行了理论分析。通过大量实验和消融研究，我们证明了一种浅层特征增强器能够在显著减少训练和推理时间以及计算成本的同时，保持竞争力，最高可节省1.5倍的FLOPs。

</details>


### [114] [JarvisArt: Liberating Human Artistic Creativity via an Intelligent Photo Retouching Agent](https://arxiv.org/abs/2506.17612)
**中文标题：JarvisArt：通过智能照片润色代理解放人类艺术创造力**

*Yunlong Lin,Zixu Lin,Kunjie Lin,Jinbin Bai,Panwang Pan,Chenxin Li,Haoyu Chen,Zhongdao Wang,Xinghao Ding,Wenbo Li,Shuicheng Yan*

主要分类: cs.CV

摘要简述: JarvisArt是一种基于多模态大语言模型的智能照片润色代理，通过理解用户意图和模仿专业艺术家的推理过程，协调200多种Lightroom工具，实现用户友好的交互和精细控制。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI照片润色工具自动化程度高但调整性和泛化能力有限，无法满足个性化需求；专业工具如Lightroom功能强大但需专业知识。JarvisArt旨在填补这一空白，提供智能且灵活的润色解决方案。

研究方法: JarvisArt采用两阶段训练：首先通过Chain-of-Thought监督微调建立基础推理和工具使用能力，再通过Group Relative Policy Optimization for Retouching (GRPO-R)提升决策和工具熟练度。同时提出Agent-to-Lightroom协议实现无缝集成。

研究结果: 在MMArt-Bench基准测试中，JarvisArt在内容保真度上比GPT-4o提升60%，同时保持指令跟随能力，展示了优异的泛化能力和全局/局部调整的精细控制。

研究结论: JarvisArt为智能照片润色开辟了新途径，结合了用户友好性、泛化能力和精细控制，显著优于现有解决方案。

中文摘要: 照片润色已成为当代视觉叙事的重要组成部分，帮助用户捕捉美学并表达创意。尽管专业工具如Adobe Lightroom功能强大，但需要大量专业知识和手动操作。相比之下，现有AI解决方案提供自动化，但调整性和泛化能力有限，难以满足多样化和个性化需求。为此，我们推出JarvisArt，一种基于多模态大语言模型（MLLM）的代理，能够理解用户意图，模仿专业艺术家的推理过程，并智能协调Lightroom中的200多种润色工具。JarvisArt采用两阶段训练：首先通过Chain-of-Thought监督微调建立基础推理和工具使用能力，再通过Group Relative Policy Optimization for Retouching (GRPO-R)提升决策和工具熟练度。我们还提出Agent-to-Lightroom协议以实现无缝集成。为评估性能，我们开发了MMArt-Bench基准，基于真实用户编辑数据构建。JarvisArt展示了用户友好的交互、优异的泛化能力以及对全局和局部调整的精细控制，为智能照片润色开辟了新途径。值得注意的是，在MMArt-Bench的内容保真度指标上，JarvisArt比GPT-4o提升了60%，同时保持相当的指令跟随能力。项目页面：https://jarvisart.vercel.app/。

</details>


### [115] [CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning](https://arxiv.org/abs/2506.17629)
**中文标题：CLiViS：通过语言-视觉协同释放认知地图以实现具身视觉推理**

*Kailing Li,Qi'ao Xu,Tianwen Qian,Yuqian Fu,Yang Jiao,Xiaoling Wang*

主要分类: cs.CV

摘要简述: CLiViS是一种新型训练免费框架，通过结合大型语言模型（LLMs）和视觉语言模型（VLMs）的优势，构建动态认知地图，实现高效的具身视觉推理。


<details>
  <summary>详细信息</summary>
研究动机: 具身视觉推理（EVR）面临复杂指令多样性和长时序视频动态性的挑战，现有方法要么忽略关键视觉细节，要么难以实现逐步组合推理。CLiViS旨在通过语言-视觉协同解决这些问题。

研究方法: CLiViS利用LLMs进行高级任务规划，并通过VLM驱动的开放世界视觉感知迭代更新场景上下文，构建动态认知地图，连接低层感知与高层推理。

研究结果: 在多个基准测试中，CLiViS表现出色，尤其在处理长时序视觉依赖任务上具有显著优势。

研究结论: CLiViS通过语言-视觉协同和动态认知地图，显著提升了具身视觉推理的能力，为复杂动态环境中的语义理解和时空推理提供了有效解决方案。

中文摘要: 具身视觉推理（EVR）旨在基于第一人称视频执行复杂的自由形式指令，实现动态环境中的语义理解和时空推理。尽管潜力巨大，EVR仍面临复杂指令多样性和长时序视频动态性的挑战。现有方法要么依赖静态视频描述的LLMs，忽略关键视觉细节，要么使用端到端VLMs，难以实现逐步组合推理。结合LLMs的推理能力和VLMs的感知优势，我们提出CLiViS，一种无需训练的新型框架。它利用LLMs进行高级任务规划，并通过VLM驱动的开放世界视觉感知迭代更新场景上下文。基于此协同，CLiViS的核心是一个动态认知地图，其在推理过程中不断演化，构建具身场景的结构化表示，连接低层感知与高层推理。多个基准测试的实验证明了CLiViS的有效性和通用性，尤其是在处理长时序视觉依赖任务上。代码发布于https://github.com/Teacher-Tom/CLiViS。

</details>


### [116] [Optimization-Free Patch Attack on Stereo Depth Estimation](https://arxiv.org/abs/2506.17632)
**中文标题：无需优化的立体深度估计对抗补丁攻击**

*Hangcheng Liu,Xu Kuang,Xingshuo Han,Xingwan Wu,Haoran Ou,Shangwei Guo,Xingyi Huang,Tao Xiang,Tianwei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需优化的对抗性补丁攻击方法PatchHunter，针对立体深度估计（SDE）模型，展示了其在真实场景中的高效性和可迁移性。


<details>
  <summary>详细信息</summary>
研究动机: 立体深度估计（SDE）在自动驾驶等视觉系统中至关重要，但现有对抗攻击方法局限于不现实的场景（如静态场景的数字扰动），缺乏实际应用性。本文旨在设计一种物理可实现、场景自适应且可迁移的攻击方法。

研究方法: 首先，提出了一个统一的攻击框架，将基于优化的技术扩展到立体匹配的四个核心阶段。随后，提出PatchHunter，一种基于强化学习的无优化对抗补丁攻击方法，通过搜索视觉模式空间来破坏SDE假设。

研究结果: PatchHunter在KITTI数据集、CARLA模拟器和真实车辆部署中验证了其高效性，显著优于基于优化的方法，并在低光等挑战性条件下保持高攻击成功率。

研究结论: PatchHunter不仅超越了基于优化的方法，还展示了更强的黑盒可迁移性，为真实场景中的对抗攻击提供了新思路。

中文摘要: 立体深度估计（SDE）在自动驾驶等视觉系统中至关重要，但现有研究表明SDE模型易受对抗攻击，且这些攻击通常局限于不现实的场景（如静态场景中分离立体视图的数字扰动），限制了其实际应用。这引发了一个关键问题：如何在现实约束下设计物理可实现、场景自适应且可迁移的攻击方法？

为此，本文提出了两项关键贡献。首先，我们提出了一个统一的攻击框架，将基于优化的技术扩展到立体匹配的四个核心阶段：特征提取、成本体积构建、成本聚合和视差回归。通过对9种主流SDE模型的阶段评估（在光度一致性等约束下），发现基于优化的补丁可迁移性较差。有趣的是，部分可迁移的补丁表明，模式而非像素级扰动可能是实现通用攻击的关键。基于此，我们提出了PatchHunter，首个针对SDE的无优化对抗补丁攻击方法。PatchHunter将补丁生成建模为强化学习驱动的搜索，通过设计视觉模式空间来破坏SDE假设。

我们在三个层面验证了PatchHunter：KITTI数据集、CARLA模拟器和真实车辆部署。PatchHunter不仅在攻击效果上超越了基于优化的方法，还实现了显著更好的黑盒可迁移性。即使在低光等挑战性物理条件下，PatchHunter仍能保持高攻击成功率（如D1-all > 0.4），而基于优化的方法则失效。

</details>


### [117] [Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection](https://arxiv.org/abs/2506.17633)
**中文标题：自适应多提示对比网络用于少样本分布外检测**

*Xiang Fang,Arvind Easwaran,Blaise Genest*

主要分类: cs.CV

摘要简述: 本文提出了一种自适应多提示对比网络（AMCN），用于解决少样本分布外（OOD）检测问题。通过结合文本与图像的CLIP模型，生成自适应提示并学习类间和类内分布，显著提升了少样本OOD检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的OOD检测方法需要大量训练样本，而少样本OOD检测更具挑战性。现有方法忽略了不同类别间的多样性差异，因此需要一种能够自适应调整ID-OOD分离边界的新方法。

研究方法: AMCN通过CLIP模型连接文本与图像，生成可学习的ID提示和固定/自适应OOD提示。引入类间阈值生成自适应类别边界，并提出提示引导的ID-OOD分离模块以控制ID与OOD提示的间隔。

研究结果: 实验结果表明，AMCN在少样本OOD检测任务中优于其他最先进方法。

研究结论: AMCN通过自适应提示和类间分布学习，显著提升了少样本OOD检测的性能，为实际应用提供了有效解决方案。

中文摘要: 分布外（OOD）检测旨在区分异常样本，以防止在分布内（ID）数据集上训练的模型产生不可靠的输出。大多数OOD检测方法需要大量ID样本进行训练，这严重限制了其实际应用。为此，我们研究了一个更具挑战性的设置：少样本OOD检测，其中仅提供少量标记的ID样本。因此，少样本OOD检测比传统OOD检测更具挑战性。现有的少样本OOD检测方法忽略了不同类别间的多样性差异。本文提出了一种新型网络：自适应多提示对比网络（AMCN），通过学习类间和类内分布自适应调整ID-OOD分离边界。为了弥补OOD样本的缺失和ID图像样本的稀缺性，我们利用CLIP模型连接文本与图像，设计了可学习的ID和OOD文本提示。具体而言，我们首先生成自适应提示（可学习的ID提示、固定标签的OOD提示和自适应标签的OOD提示）。然后，通过引入类间阈值为每个类别生成自适应类别边界。最后，我们提出了一种提示引导的ID-OOD分离模块，以控制ID与OOD提示之间的间隔。实验结果表明，AMCN优于其他最先进的方法。

</details>


### [118] [Histopathology Image Report Generation by Vision Language Model with Multimodal In-Context Learning](https://arxiv.org/abs/2506.17645)
**中文标题：基于多模态上下文学习的视觉语言模型生成组织病理学图像报告**

*Shih-Wen Liu,Hsuan-Yu Fan,Wei-Ta Chu,Fu-En Yang,Yu-Chiang Frank Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PathGenIC的多模态上下文学习框架，用于从组织病理学图像自动生成医学报告，通过动态检索相似图像-报告对并结合自适应反馈，显著提升了报告生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 自动化从组织病理学图像生成医学报告是一个关键挑战，需要有效的视觉表示和领域知识。受人类专家实践的启发，本文旨在通过上下文学习框架解决这一问题。

研究方法: 提出的PathGenIC框架结合了训练集中的上下文信息与多模态上下文学习机制，动态检索语义相似的WSI-报告对，并通过自适应反馈增强上下文相关性和生成质量。

研究结果: 在HistGen基准测试中，PathGenIC在BLEU、METEOR和ROUGE-L指标上取得了最先进的结果，且在不同报告长度和疾病类别中表现出鲁棒性。

研究结论: 通过最大化训练数据效用和多模态上下文学习，PathGenIC为AI驱动的组织病理学报告生成提供了解决方案，为未来多模态临床应用奠定了基础。

中文摘要: 从组织病理学图像自动生成医学报告是一个关键挑战，需要有效的视觉表示和领域知识。受人类专家实践的启发，我们提出了一种名为PathGenIC的上下文学习框架，该框架结合了训练集中的上下文信息与多模态上下文学习（ICL）机制。我们的方法动态检索语义相似的全切片图像（WSI）-报告对，并通过自适应反馈增强上下文相关性和生成质量。在HistGen基准测试中，该框架在BLEU、METEOR和ROUGE-L指标上取得了最先进的结果，并在不同报告长度和疾病类别中表现出鲁棒性。通过最大化训练数据效用和多模态上下文学习，我们的工作为AI驱动的组织病理学报告生成提供了解决方案，为未来多模态临床应用奠定了坚实基础。

</details>


### [119] [MDSAM:Memory-Driven Sparse Attention Matrix for LVLMs Hallucination Mitigation](https://arxiv.org/abs/2506.17664)
**中文标题：MDSAM：基于记忆驱动的稀疏注意力矩阵用于缓解大型视觉语言模型的幻觉问题**

*Shuaiye Lu,Linjiang Zhou,Xiaochuan Shi*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MDSAM的训练无关方法，通过动态捕捉和优化图像令牌的注意力分配，有效减少大型视觉语言模型（LVLMs）中的幻觉现象。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型在解码过程中对图像令牌的敏感性导致幻觉问题，表现为在生成真实和虚构实体时出现注意力峰值。为解决这一问题，研究提出了MDSAM方法。

研究方法: MDSAM通过记忆注意力模式并在解码过程中通过对齐激活更新，动态调整图像令牌的注意力分配，增强对相关令牌的关注，从而减少幻觉。

研究结果: 在图像描述和视觉问答等任务的多项基准测试中，MDSAM显著减少了幻觉现象并提高了模型的可靠性，且无需额外训练或外部工具。

研究结论: MDSAM是一种适应性强的训练无关方法，能够有效减少LVLMs中的幻觉现象，适用于多种模型架构。

中文摘要: 大型视觉语言模型（LVLMs）中的幻觉问题通常源于模型在解码过程中对图像令牌的敏感性，表现为生成真实和虚构实体时出现的注意力峰值。为解决这一问题，我们提出了记忆驱动的稀疏注意力矩阵（MDSAM），这是一种无需训练的新方法，能够动态捕捉并优化每一层图像令牌的注意力分配。MDSAM通过记忆注意力模式并在解码过程中通过对齐激活更新，增强对相关图像令牌的关注，从而有效减少幻觉。我们在图像描述和视觉问答等任务的多个基准上评估了MDSAM，结果表明其能够持续减少幻觉并提高可靠性。MDSAM兼容多种LVLM架构，展示了其在无需额外训练或外部工具的情况下缓解幻觉问题的适应性和有效性。

</details>


### [120] [CSDN: A Context-Gated Self-Adaptive Detection Network for Real-Time Object Detection](https://arxiv.org/abs/2506.17679)
**中文标题：CSDN：一种用于实时目标检测的上下文门控自适应检测网络**

*Wei Haolin*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer的检测头CSDN，通过新颖的门控机制替代传统的自注意力和交叉注意力层，提升了目标检测的全局上下文建模能力，并适应不同尺寸和结构的物体。


<details>
  <summary>详细信息</summary>
研究动机: 传统卷积神经网络（CNN）在目标检测中受限于有限的感受野，难以捕捉全局上下文信息。本文认为特征的有效利用与特征提取过程同等重要，并重新评估了DETR启发下的头网络架构，发现其自注意力机制存在信息冗余问题。

研究方法: 提出了一种基于自然语言处理架构和人类视觉感知的Transformer检测头CSDN，通过门控机制自适应选择和组合多个注意力模式的特征维度和尺度信息，替代了传统的堆叠自注意力和交叉注意力层。

研究结果: CSDN提供了更强大的全局上下文建模能力，能够更好地适应不同尺寸和结构的物体。实验表明，仅需少量微调即可显著提升检测精度，避免了大规模重新训练的需求。

研究结论: CSDN作为一种高效的检测头，可直接替换多种基于CNN的检测器的原生头部，显著提升检测性能，同时减少了计算和训练成本。

中文摘要: 卷积神经网络（CNN）长期以来是目标检测的基石，但其有限的感受野限制了捕捉全局上下文信息的能力。本文认为提取特征的有效利用与特征提取过程本身同等重要。我们重新评估了受DETR启发的头网络架构，质疑其自注意力机制的必要性，并发现了显著的信息冗余。为解决这些问题，我们提出了基于自然语言处理架构和人类视觉感知的Transformer检测头CSDN。CSDN通过新颖的门控机制替代传统的堆叠自注意力和交叉注意力层，使每个感兴趣区域（ROI）能够自适应地选择和组合多个注意力模式的特征维度和尺度信息。CSDN提供了更强大的全局上下文建模能力，并能更好地适应不同尺寸和结构的物体。我们提出的检测头可直接替换多种基于CNN的检测器的原生头部，仅需少量微调即可显著提升检测精度，从而避免了为实现微小改进而进行大规模重新训练的需求。

</details>


### [121] [Domain Generalization using Action Sequences for Egocentric Action Recognition](https://arxiv.org/abs/2506.17685)
**中文标题：基于动作序列的领域泛化方法用于第一人称视角动作识别**

*Amirshayan Nasirimajd,Chiara Plizzari,Simone Alberto Peirone,Marco Ciccone,Giuseppe Averta,Barbara Caputo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SeqDG的领域泛化方法，通过利用动作序列的一致性意图提升第一人称视角动作识别的跨领域性能。方法结合视觉-文本序列重建（SeqRec）和多领域动作序列混合训练（SeqMix），在EPIC-KITCHENS-100和EGTEA数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 第一人称视角动作识别模型在未见过的环境中性能显著下降，主要由于光照、视角和环境的多样性。本文旨在通过动作序列的一致性意图提升模型的跨领域泛化能力。

研究方法: 提出SeqDG方法，包括视觉-文本序列重建目标（SeqRec）和多领域动作序列混合训练（SeqMix）。SeqRec利用文本和视觉输入的上下文线索重建序列中心动作，SeqMix通过混合不同领域的动作序列增强模型鲁棒性。

研究结果: 在EPIC-KITCHENS-100数据集上，SeqDG在跨领域动作识别中相对平均提升2.4%；在EGTEA数据集上，模型在领域内动作识别中Top-1准确率提升0.6%，优于现有最佳方法。

研究结论: SeqDG通过动作序列的领域泛化方法有效提升了第一人称视角动作识别的性能，尤其在跨领域场景中表现突出。

中文摘要: 从视觉输入中识别人类活动，尤其是通过第一人称视角，对于机器人模仿人类行为至关重要。第一人称视角（由佩戴摄像头的观察者捕捉）具有光照、视角和环境的多样性，导致动作识别模型在未见过的环境中性能显著下降。本文提出了一种领域泛化方法（SeqDG），通过动作序列的一致性意图提升模型的泛化能力。SeqDG包含视觉-文本序列重建目标（SeqRec）和多领域动作序列混合训练（SeqMix）。SeqRec利用文本和视觉输入的上下文线索重建序列中心动作，SeqMix通过混合不同领域的动作序列增强模型鲁棒性。在EPIC-KITCHENS-100和EGTEA数据集上的实验表明，SeqDG在跨领域动作识别中相对平均提升2.4%，在EGTEA的领域内动作识别中Top-1准确率提升0.6%，优于现有最佳方法。

</details>


### [122] [SSAVSV: Towards Unified Model for Self-Supervised Audio-Visual Speaker Verification](https://arxiv.org/abs/2506.17694)
**中文标题：SSAVSV：面向自监督音频-视觉说话人验证的统一模型**

*Gnana Praveen Rajasekhar,Jahangir Alam*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自监督学习的统一框架SSAVSV，通过对比学习和非对称掩码技术，实现高效的音频-视觉说话人验证，减少对标注数据的依赖和计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 传统的音频-视觉说话人验证方法依赖大量标注数据和独立模态架构，计算成本高且扩展性受限。本文旨在通过自监督学习解决这些问题。

研究方法: 提出了一种基于对比学习和掩码数据建模的自监督学习框架，采用统一的视觉变换器（Vision Transformer）作为共享主干网络，支持音频、视觉或音频-视觉输入，并对缺失模态具有鲁棒性。

研究结果: 实验表明，该方法在无需标注数据的情况下实现了与传统方法竞争的性能，同时显著降低了计算成本。

研究结论: SSAVSV框架为音频-视觉说话人验证提供了一种高效、鲁棒且可扩展的解决方案，减少了标注数据和计算资源的需求。

中文摘要: 传统的音频-视觉说话人验证方法依赖大量标注数据和独立的模态专用架构，计算成本高昂，限制了其扩展性。为解决这些问题，我们提出了一种基于对比学习和非对称掩码技术的自监督学习框架，以获取鲁棒的音频-视觉特征表示。具体而言，我们采用统一的框架，利用视觉变换器的多功能性，为音频和视觉输入共享单一主干网络。该框架在训练和测试阶段能够处理音频、视觉或音频-视觉输入，同时计算高效且对缺失模态具有鲁棒性。大量实验表明，我们的方法在无需标注数据的情况下实现了与传统方法竞争的性能，同时显著降低了计算成本。

</details>


### [123] [DreamJourney: Perpetual View Generation with Video Diffusion Models](https://arxiv.org/abs/2506.17705)
**中文标题：DreamJourney：基于视频扩散模型的连续视角生成**

*Bo Pan,Yang Chen,Yingwei Pan,Ting Yao,Wei Chen,Tao Mei*

主要分类: cs.CV

摘要简述: DreamJourney提出了一种两阶段框架，利用视频扩散模型的能力生成动态场景的连续视角视频，解决了现有方法在3D感知和动态对象运动方面的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法基于2D扩散模型生成新视角，缺乏3D感知能力，导致画面扭曲，且无法捕捉动态4D世界中的对象运动。DreamJourney旨在解决这些问题，实现动态场景的连续视角生成。

研究方法: DreamJourney分为两阶段：第一阶段通过3D点云和视频扩散模型生成视角一致的视频；第二阶段利用多模态大语言模型描述对象运动，并通过视频扩散模型动态化当前视角。两阶段循环执行，实现连续动态场景生成。

研究结果: 实验表明，DreamJourney在定量和定性上均优于现有方法，能够生成高质量的动态场景视频。

研究结论: DreamJourney通过结合视频扩散模型和多模态语言模型，成功实现了动态场景的连续视角生成，为相关领域提供了新的解决方案。

中文摘要: 连续视角生成旨在从单张输入图像生成与任意相机轨迹对应的长期视频。现有方法通常使用预训练的文本到图像扩散模型合成新内容，但2D扩散模型缺乏3D感知能力，导致画面扭曲，且仅适用于静态3D场景。为解决这些问题，我们提出了DreamJourney，一个两阶段框架，利用视频扩散模型的世界模拟能力，实现包含相机运动和对象动态的连续场景生成。第一阶段，DreamJourney将输入图像提升为3D点云，并从特定相机轨迹渲染部分图像序列，利用视频扩散模型补全缺失区域并增强视觉一致性。第二阶段，通过多模态大语言模型生成描述对象运动的文本提示，并用视频扩散模型动态化当前视角。两阶段循环执行，实现连续动态场景生成。实验表明，DreamJourney在定量和定性上均优于现有方法。项目页面：https://dream-journey.vercel.app。

</details>


### [124] [Programmable-Room: Interactive Textured 3D Room Meshes Generation Empowered by Large Language Models](https://arxiv.org/abs/2506.17707)
**中文标题：可编程房间：基于大语言模型的交互式纹理3D房间网格生成**

*Jihyun Kim,Junho Park,Kyeongbo Kong,Suk-Ju Kang*

主要分类: cs.CV

摘要简述: 本文提出Programmable-Room框架，通过自然语言指令交互式生成和编辑3D房间网格，结合视觉编程和大语言模型实现精确控制，并在纹理生成和房间布局上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D房间生成方法难以通过自然语言精确控制房间的各个属性，因此需要一种能够分解任务并统一支持的框架。

研究方法: 将复杂任务分解为生成3D坐标、全景图像纹理、构建3D网格和家具布置等步骤，利用视觉编程（VP）和大语言模型（LLM）生成Python式程序，并通过预训练扩散模型优化全景图像生成。

研究结果: Programmable-Room在生成和编辑3D房间网格上表现出灵活性和优越性，定量和定性均优于现有模型。

研究结论: 该框架通过自然语言指令实现了3D房间的高效生成与编辑，为未来交互式3D设计提供了新思路。

中文摘要: 我们提出了Programmable-Room框架，该框架能够根据自然语言指令交互式生成和编辑3D房间网格。为了精确控制房间的每个属性，我们将这一复杂任务分解为多个简单步骤，包括生成房间网格的合理3D坐标、生成全景图像纹理、整合坐标和全景图像构建3D网格，以及布置家具。为了用一个统一框架支持这些分解任务，我们引入了视觉编程（VP）方法，该方法利用大语言模型（LLM）编写类似Python的程序，将自然语言描述的任务转化为有序的模块列表。我们开发了大部分模块，尤其是纹理生成模块，利用预训练的大规模扩散模型，在文本和视觉提示（如布局、深度和语义图）的条件下生成全景图像。具体而言，我们通过优化训练目标，使用双向LSTM获取的1D全景场景表示，提升了全景图像生成的质量。我们展示了Programmable-Room在生成和编辑3D房间网格上的灵活性，并通过定量和定性实验证明了该框架的优越性。项目页面详见：https://jihyun0510.github.io/Programmable_Room_Page/。

</details>


### [125] [PDC-Net: Pattern Divide-and-Conquer Network for Pelvic Radiation Injury Segmentation](https://arxiv.org/abs/2506.17712)
**中文标题：PDC-Net：基于模式分治网络的盆腔放射损伤分割**

*Xinyu Xiong,Wuteng Cao,Zihuang Wu,Lei Zhang,Chong Gao,Guanbin Li,Qiyuan Qin*

主要分类: cs.CV

摘要简述: 提出了一种新型的PDC-Net网络，通过多方向聚合模块和记忆引导上下文模块，结合自适应融合解码器，实现了盆腔放射损伤的精确分割。


<details>
  <summary>详细信息</summary>
研究动机: 盆腔放射损伤（PRI）的精确分割对预后评估和个性化治疗计划至关重要，但由于器官形态复杂和上下文混淆，自动化分割仍具挑战性。

研究方法: PDC-Net采用多方向聚合模块（MDA）增强对器官形状的拟合能力，引入记忆引导上下文模块（MGC）提升全局模式区分，并通过自适应融合解码器（AFD）动态选择特征生成最终分割结果。

研究结果: 在首个大规模盆腔放射损伤数据集上的实验表明，PDC-Net优于现有方法。

研究结论: PDC-Net通过分治策略和灵活特征选择，显著提升了PRI分割的准确性，为临床提供了有力工具。

中文摘要: 从磁共振图像（MRI）中精确分割盆腔放射损伤（PRI）对于更准确的预后评估和个性化治疗计划的制定至关重要。然而，由于复杂的器官形态和上下文混淆等因素，自动化分割仍面临挑战。为解决这些问题，我们提出了一种新型的模式分治网络（PDC-Net）用于PRI分割。其核心思想是通过不同网络模块“分治”各种局部和全局模式，并在解码阶段通过灵活的特征选择“攻克”感兴趣区域（ROI）。具体而言，考虑到ROI在MR切片中常表现为条状或环状结构，我们引入了多方向聚合模块（MDA），通过在四个不同方向上应用条状卷积增强模型对器官形状的拟合能力。此外，为缓解上下文混淆的挑战，我们提出了记忆引导上下文模块（MGC），该模块显式维护一个记忆参数以跟踪数据集级别的跨图像模式，从而增强与正负类别相关的全局模式的区分。最后，我们设计了一个基于专家混合框架（MoE）的自适应融合解码器（AFD），动态选择不同模式的特征，最终生成分割结果。我们在首个大规模盆腔放射损伤数据集上评估了该方法，结果表明PDC-Net优于现有方法。

</details>


### [126] [YOLOv13: Real-Time Object Detection with Hypergraph-Enhanced Adaptive Visual Perception](https://arxiv.org/abs/2506.17733)
**中文标题：YOLOv13：基于超图增强自适应视觉感知的实时目标检测**

*Mengqi Lei,Siqi Li,Yihong Wu,Han Hu,You Zhou,Xinhu Zheng,Guiguang Ding,Shaoyi Du,Zongze Wu,Yue Gao*

主要分类: cs.CV

摘要简述: YOLOv13提出了一种基于超图的自适应相关性增强机制（HyperACE）和全流程聚合与分配范式（FullPAD），显著提升了复杂场景下的目标检测性能，同时减少了参数和计算量。


<details>
  <summary>详细信息</summary>
研究动机: YOLO系列模型在实时目标检测中表现优异，但其卷积架构和自注意力机制仅能建模局部信息和成对相关性，无法捕捉全局高阶相关性，限制了复杂场景下的检测性能。

研究方法: 提出HyperACE机制，通过超图计算自适应挖掘高阶相关性；设计FullPAD范式，实现全流程特征融合与增强；采用深度可分离卷积替换传统大核卷积，降低参数和计算复杂度。

研究结果: 在MS COCO基准测试中，YOLOv13-N的mAP比YOLO11-N提升3.0%，比YOLOv12-N提升1.5%，且参数和FLOPs更少。

研究结论: YOLOv13通过HyperACE和FullPAD机制，显著提升了目标检测的全局相关性建模能力，同时保持了轻量化和高效性。

中文摘要: YOLO系列模型因其卓越的准确性和计算效率在实时目标检测领域占据主导地位。然而，YOLO11及之前版本的卷积架构以及YOLOv12引入的基于区域的自注意力机制仅局限于局部信息聚合和成对相关性建模，缺乏捕捉全局多对多高阶相关性的能力，这限制了复杂场景下的检测性能。本文提出YOLOv13，一种精确且轻量化的目标检测器。为解决上述问题，我们提出了一种基于超图的自适应相关性增强机制（HyperACE），通过超图计算自适应挖掘潜在的高阶相关性，克服了以往方法仅能建模成对相关性的局限，实现了高效的全局跨位置和跨尺度特征融合与增强。随后，我们提出了一种基于HyperACE的全流程聚合与分配范式（FullPAD），通过将相关性增强的特征分配到整个流程中，有效实现了细粒度信息流和网络内的表示协同。最后，我们提出利用深度可分离卷积替换传统大核卷积，并设计了一系列模块，在不牺牲性能的情况下显著减少了参数和计算复杂度。我们在广泛使用的MS COCO基准上进行了大量实验，结果表明，我们的方法在参数和FLOPs更少的情况下实现了最先进的性能。具体而言，我们的YOLOv13-N在mAP上比YOLO11-N提升了3.0%，比YOLOv12-N提升了1.5%。YOLOv13的代码和模型可在https://github.com/iMoonLab/yolov13获取。

</details>


### [127] [PhysID: Physics-based Interactive Dynamics from a Single-view Image](https://arxiv.org/abs/2506.17746)
**中文标题：PhysID：基于单视角图像的物理交互动态生成**

*Sourabh Vasant Gothe,Ayon Chattopadhyay,Gunturi Venkata Sai Phani Kiran,Pratik,Vibhav Agarwal,Jayesh Rajkumar Vachhani,Sourav Ghosh,Parameswaranath VM,Barath Raj KR*

主要分类: cs.CV

摘要简述: 本文提出PhysID，一种基于物理的交互动态生成方法，仅需单视角图像即可实现实时交互和个性化体验，显著降低3D建模和物理属性校准的复杂性。


<details>
  <summary>详细信息</summary>
研究动机: 当前将静态图像转化为交互体验的方法多依赖多视角图像或预录视频，限制了移动端应用的发展。本文旨在通过单视角图像实现实时交互，提升移动用户体验。

研究方法: PhysID利用大型生成模型生成3D网格并预测物理属性，结合设备端物理引擎实现实时渲染和用户交互，减少人工干预。

研究结果: 实验验证了多模态大语言模型的零样本能力和3D重建模型的性能，展示了端到端框架的有效性。

研究结论: PhysID在移动端交互动态领域取得显著进展，支持实时、非确定性交互和个性化体验，同时优化设备内存消耗。

中文摘要: 将静态图像转化为交互体验是计算机视觉中的一项挑战性任务。解决这一挑战有望通过交互式和增强现实/虚拟现实（AR/VR）应用提升移动用户体验。当前方法通常依赖预录视频或多视角图像作为输入。本文提出PhysID，通过利用大型生成模型生成3D网格并预测物理属性，从单视角图像简化基于物理的交互动态生成过程。这显著降低了3D建模和固有属性校准等工程密集型任务所需的专业知识，使流程能够以最少的人工干预进行扩展。我们集成了设备端物理引擎，实现物理上合理的实时渲染与用户交互。PhysID在移动端交互动态领域实现了飞跃，提供实时、非确定性交互和用户个性化，同时优化设备内存消耗。实验评估了多模态大语言模型（MLLMs）在多样化任务中的零样本能力以及3D重建模型的性能。结果表明，端到端框架中所有模块的协同工作为其有效性提供了支持。

</details>


### [128] [LoLA-SpecViT: Local Attention SwiGLU Vision Transformer with LoRA for Hyperspectral Imaging](https://arxiv.org/abs/2506.17759)
**中文标题：LoLA-SpecViT：基于LoRA的局部注意力SwiGLU视觉变换器用于高光谱成像**

*Fadi Abdeladhim Zidi,Djamel Eddine Boukhari,Abdellah Zakaria Sellam,Abdelkrim Ouafi,Cosimo Distante,Salah Eddine Bekhouche,Abdelmalik Taleb-Ahmed*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级光谱视觉变换器LoLA-SpecViT，通过局部窗口自注意力和低秩适应（LoRA）技术，显著降低了计算复杂度和可训练参数量，在高光谱图像分类任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱图像分类面临高维数据、频带冗余和标注样本不足的挑战。现有变换器模型在全局建模方面表现优异，但在标签稀缺条件下的可扩展性和适应性有限。

研究方法: LoLA-SpecViT结合了3D卷积光谱前端和局部窗口自注意力，提升光谱特征提取和空间一致性。通过引入LoRA技术，减少了80%以上的可训练参数，并采用循环学习率调度器优化训练过程。

研究结果: 在WHU-Hi LongKou、WHU-Hi HongHu和Salinas三个基准数据集上的实验表明，LoLA-SpecViT性能优于现有方法，最高准确率达99.91%，且参数量更少，标签稀缺条件下鲁棒性更强。

研究结论: LoLA-SpecViT为高光谱图像分类提供了一种高效、可扩展的解决方案，适用于农业、环境监测和遥感分析等实际应用。

中文摘要: 高光谱图像分类由于数据维度高、频带冗余严重以及标注样本有限，仍然是一项具有挑战性的任务。尽管基于变换器的最新模型在全局建模光谱-空间依赖性方面有所改进，但其在标签稀缺条件下的可扩展性和适应性仍有限。本文提出了一种轻量级光谱视觉变换器LoLA-SpecViT（低秩适应局部注意力光谱视觉变换器），通过针对高光谱图像独特特性的参数高效架构解决了这些限制。我们的模型结合了3D卷积光谱前端和基于局部窗口的自注意力，既增强了光谱特征提取和空间一致性，又降低了计算复杂度。为进一步提升适应性，我们在注意力和投影层中集成了低秩适应（LoRA）技术，使得微调时可训练参数减少80%以上。一种新颖的循环学习率调度器在训练过程中调节LoRA的适应强度，改善了收敛性和泛化能力。在WHU-Hi LongKou、WHU-Hi HongHu和Salinas三个基准数据集上的大量实验表明，LoLA-SpecViT始终优于现有基线方法，最高准确率达到99.91%，且参数量显著减少，在低标签条件下鲁棒性更强。该框架为农业、环境监测和遥感分析等实际高光谱应用提供了一种可扩展且通用的解决方案。代码可在以下GitHub仓库获取：https://github.com/FadiZidiDz/LoLA-SpecViT。

</details>


### [129] [Incorporating Rather Than Eliminating: Achieving Fairness for Skin Disease Diagnosis Through Group-Specific Expert](https://arxiv.org/abs/2506.17787)
**中文标题：融合而非消除：通过群体特定专家实现皮肤疾病诊断的公平性**

*Gelei Xu,Yuying Duan,Zheyuan Liu,Xueyang Li,Meng Jiang,Michael Lemmon,Wei Jin,Yiyu Shi*

主要分类: cs.CV

摘要简述: 本文提出FairMoE框架，通过动态路由数据到特定专家模块，解决皮肤疾病诊断中的偏见问题，同时提升准确性和公平性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的AI皮肤疾病诊断系统存在跨人口群体的偏见，导致不公平的医疗结果和患者信任下降。传统的偏见缓解方法试图消除敏感属性与诊断预测的关联，但会丢失临床相关诊断线索，降低性能。

研究方法: 提出FairMoE框架，采用分层混合专家模块作为群体特定学习器，动态路由数据到最适合的专家，尤其适用于处理群体边界附近的情况。

研究结果: 实验结果表明，FairMoE在保持公平性指标的同时，显著提升了诊断准确性，优于传统的公平性方法。

研究结论: FairMoE通过动态数据路由和群体特定学习，实现了高准确性和公平性的皮肤疾病诊断，为医疗AI的公平性提供了新思路。

中文摘要: 基于AI的系统在皮肤疾病诊断中取得了高准确性，但常表现出跨人口群体的偏见，导致医疗结果不公平和患者信任下降。现有的偏见缓解方法大多试图消除敏感属性与诊断预测的关联，但这些方法常因丢失临床相关诊断线索而降低性能。本文提出一种替代方法，通过融合敏感属性来实现公平性。我们引入FairMoE框架，采用分层混合专家模块作为群体特定学习器。与传统方法不同，FairMoE动态路由数据到最适合的专家，尤其适用于处理群体边界附近的情况。实验结果表明，与以往降低性能的公平性方法不同，FairMoE在保持可比公平性指标的同时，显著提升了准确性。

</details>


### [130] [Time-Contrastive Pretraining for In-Context Image and Video Segmentation](https://arxiv.org/abs/2506.17837)
**中文标题：基于时间对比预训练的上下文图像与视频分割方法**

*Assefa Wahd,Jacob Jaremko,Abhilash Hareendranathan*

主要分类: cs.CV

摘要简述: 本文提出了一种基于时间对比自监督学习的预训练方法（Temporal），用于图像和视频分割的上下文学习（ICL）。通过将ICL重新定义为视频对象分割（VOS）任务，并训练提示检索器，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的上下文学习方法依赖网格化策略，缺乏灵活性，限制了上下文图像的数量和分辨率。本文旨在解决这一问题，提出一种更灵活的方法以支持可变数量的上下文图像并保持其完整分辨率。

研究方法: 提出Temporal方法，通过时间对比自监督学习预训练提示检索器，将ICL任务重新定义为VOS问题。在图像分割中，检索器选择相关序列形成连贯视频；在视频分割中，识别关键帧并传播其掩码。

研究结果: 在MICCAI FLARE 2022数据集上，图像分割Dice分数提升10.64%（达到90.95%），视频分割Dice分数提升14.88%（达到92.45%）。

研究结论: Temporal方法通过时间对比学习和VOS任务重构，显著提升了图像和视频分割的性能，为上下文学习提供了更灵活的解决方案。

中文摘要: 上下文学习（ICL）能够通过少量标记数据实现对新任务的泛化。然而，主流ICL方法依赖网格化策略，缺乏视觉应用所需的灵活性。我们提出了Temporal，一种基于时间对比的自监督目标，用于预训练视觉ICL的提示检索器，并将ICL任务重新定义为视频对象分割（VOS）问题。Temporal解决了网格化方法在上下文图像数量和分辨率上的限制。通过将ICL重构为VOS问题，我们的方法支持可变数量的上下文图像，同时保持其完整分辨率。为应对选择最优上下文集的挑战，我们通过自监督学习在视频上预训练提示检索器，其中相邻帧作为正样本，远距离帧作为负样本。在图像分割中，提示检索器选择相关序列，与查询结合形成连贯视频以供VOS处理。在视频分割中，它识别关键帧，使用ICL管道预测其掩码，并在序列中传播。在MICCAI FLARE 2022上的评估显示，我们的方法显著优于基线：图像分割Dice分数达到90.95%（提升10.64%），视频分割Dice分数达到92.45%（提升14.88%）。

</details>


### [131] [Robust Foreground-Background Separation for Severely-Degraded Videos Using Convolutional Sparse Representation Modeling](https://arxiv.org/abs/2506.17838)
**中文标题：基于卷积稀疏表示建模的严重退化视频前景-背景鲁棒分离方法**

*Kazuki Naganuma,Shunsuke Ono*

主要分类: cs.CV

摘要简述: 本文提出了一种基于卷积稀疏表示（CSR）的前景-背景分离（FBS）方法，用于处理严重退化的视频，能够自适应捕捉空间结构并有效去除多种噪声。


<details>
  <summary>详细信息</summary>
研究动机: 现有FBS方法在低帧率和多噪声条件下难以准确分离前景和背景，主要因为其无法同时捕捉数据特定和通用特征，且缺乏对多种噪声的显式建模。本文旨在解决这些问题。

研究方法: 提出了一种基于CSR的前景模型，将FBS建模为多凸优化问题，结合CSR、通用特征捕捉函数和噪声表征函数，并开发了交替求解子问题的算法。

研究结果: 实验表明，该方法在红外和显微镜视频等退化视频中优于现有方法，能准确分离前景和背景并去除噪声。

研究结论: 本文提出的CSR-based FBS方法在严重退化视频中表现出色，为动态和静态成分的分离提供了有效解决方案。

中文摘要: 本文提出了一种基于卷积稀疏表示（CSR）的前景-背景分离（FBS）方法，其前景模型采用CSR技术。为了分析在硬件、环境和电源限制等不良条件下获取的视频的动态和静态成分，需要一种能够处理低帧率和多种噪声的FBS方法。现有FBS方法存在两个局限性：一是仅能捕捉数据特定或通用特征；二是缺乏对多种噪声的显式建模。为此，我们提出了一种基于CSR的鲁棒FBS方法。该模型能够自适应捕捉成像数据中的特定空间结构。随后，我们将FBS建模为一个约束多凸优化问题，结合了CSR、通用特征捕捉函数和多种噪声的表征函数。通过这些函数，我们的方法能够在低帧率下准确分离成分并去除多种噪声。为解决该优化问题，我们开发了一种交替求解其两个凸子问题的新算法。实验表明，在红外和显微镜视频等退化视频中，我们的方法优于现有方法。

</details>


### [132] [Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose](https://arxiv.org/abs/2506.17858)
**中文标题：简化胎儿建模：胎儿形状与姿态的建模与追踪**

*Yingcheng Liu,Peiqi Wang,Sebastian Diaz,Esra Abaci Turk,Benjamin Billot,Patricia Ellen Grant,Polina Golland*

主要分类: cs.CV

摘要简述: 本文提出了一种基于SMPL的3D胎儿统计身体模型，用于分析胎儿形状和姿态，解决了现有方法在细节捕捉和运动分析上的不足，并在MRI数据上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有胎儿MRI分析方法依赖解剖关键点或体积分割，前者简化了身体结构但忽略细节，后者捕捉完整形状但难以分析运动。本文旨在结合两者优势，构建更全面的胎儿形状和运动分析模型。

研究方法: 基于SMPL构建3D胎儿统计身体模型，迭代估计图像空间中的身体姿态和标准姿态空间中的身体形状，提高对MRI运动伪影和强度失真的鲁棒性，并减少因胎儿姿态导致的表面观测不完整的影响。

研究结果: 模型在53名受试者的19,816个MRI体积数据上训练，对未见胎儿形状的表面对齐误差为3.2毫米（3毫米MRI体素）。模型支持时间序列分析并提供直观可视化，还能实现传统方法难以获取的自动化人体测量。

研究结论: 本文提出的首个3D胎儿统计身体模型，为胎儿运动和形状分析提供了新工具，有望提升产前诊断的效果。代码已开源。

中文摘要: 分析胎儿身体运动和形状对产前诊断和监测至关重要。现有胎儿MRI分析方法主要依赖解剖关键点或体积分割。关键点简化了身体结构以便于运动分析，但可能忽略全身形状的重要细节；体积分割捕捉了完整形状信息，但因胎儿大范围非局部运动而难以进行时间分析。为解决这些局限，我们基于Skinned Multi-Person Linear Model（SMPL）构建了一个3D胎儿统计身体模型。我们的算法迭代估计图像空间中的身体姿态和标准姿态空间中的身体形状，提高了对MRI运动伪影和强度失真的鲁棒性，并减少了因胎儿姿态导致的表面观测不完整的影响。模型在53名受试者的19,816个MRI体积数据上训练，能够捕捉时间序列中的身体形状和运动，并提供直观可视化。此外，它还支持传统方法难以从分割和关键点中获取的自动化人体测量。在未见胎儿形状上测试时，我们的方法在3毫米MRI体素下的表面对齐误差为3.2毫米。据我们所知，这是首个3D胎儿统计身体模型，为产前诊断中的胎儿运动和形状分析开辟了新途径。代码已发布于https://github.com/MedicalVisionGroup/fetal-smpl。

</details>


### [133] [Cross-modal State Space Modeling for Real-time RGB-thermal Wild Scene Semantic Segmentation](https://arxiv.org/abs/2506.17869)
**中文标题：基于跨模态状态空间建模的实时RGB-热成像野外场景语义分割**

*Xiaodong Guo,Zi'ang Lin,Luwen Hu,Zhihong Deng,Tong Liu,Wujie Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种高效的RGB-热成像语义分割架构CM-SSM，通过跨模态状态空间建模（SSM）方法，显著降低了计算开销，同时提升了野外场景下的分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 在野外环境中，RGB和热成像数据的融合可以显著提升语义分割性能，但现有方法（如基于Transformer的方法）计算开销大，难以在资源受限的系统上实时运行。因此，本文旨在解决这一关键限制。

研究方法: CM-SSM包含两个核心模块：跨模态2D选择性扫描（CM-SS2D）模块，用于建立RGB和热成像模态之间的状态空间模型；跨模态状态空间关联（CM-SSA）模块，将全局关联与局部空间特征有效整合。该方法实现了线性计算复杂度。

研究结果: 实验表明，CM-SSM在CART数据集上实现了最先进的性能，且参数更少、计算成本更低。在PST900数据集上的进一步实验验证了其泛化能力。

研究结论: CM-SSM通过跨模态状态空间建模，显著提升了RGB-热成像语义分割的效率和性能，适用于资源受限的实时系统。

中文摘要: RGB和热成像数据的融合可以显著提升野外环境中语义分割的性能，但多源数据处理（如基于Transformer的方法）带来了巨大的计算开销，对资源受限的系统提出了挑战。为解决这一关键限制，我们提出了CM-SSM，一种高效的RGB-热成像语义分割架构，采用跨模态状态空间建模（SSM）方法。我们的框架包含两个关键组件：首先，我们引入了跨模态2D选择性扫描（CM-SS2D）模块，用于在RGB和热成像模态之间建立SSM，构建跨模态视觉序列并从一个模态中推导出另一个模态的隐藏状态表示；其次，我们开发了跨模态状态空间关联（CM-SSA）模块，将CM-SS2D的全局关联与通过卷积操作提取的局部空间特征有效整合。与基于Transformer的方法相比，CM-SSM实现了与图像分辨率相关的线性计算复杂度。实验结果表明，CM-SSM在CART数据集上实现了最先进的性能，且参数更少、计算成本更低。在PST900数据集上的进一步实验证明了其泛化能力。代码可在https://github.com/xiaodonguo/CMSSM获取。

</details>


### [134] [SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model](https://arxiv.org/abs/2506.17873)
**中文标题：SurgVidLM：基于大语言模型的多粒度手术视频理解**

*Guankun Wang,Wenjin Mo,Junyi Wang,Long Bai,Kun Yuan,Ming Hu,Jinlin Wu,Junjun He,Yiming Huang,Nicolas Padoy,Zhen Lei,Hongbin Liu,Nassir Navab,Hongliang Ren*

主要分类: cs.CV

摘要简述: 本文提出SurgVidLM，首个专为手术视频多粒度理解设计的视频语言模型，通过SVU-31K数据集和StageFocus机制，显著提升全视频和细粒度任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型在医学领域潜力巨大，但缺乏专用于细粒度手术视频理解的模型。本文旨在填补这一空白，提升手术场景和过程的详细分析能力。

研究方法: 提出SurgVidLM模型，构建SVU-31K数据集（含31K视频-指令对），引入StageFocus机制实现多粒度渐进理解，并开发Multi-frequency Fusion Attention以融合高低频视觉信息。

研究结果: 实验表明，SurgVidLM在全视频和细粒度理解任务中均显著优于现有视频语言模型，能更有效捕捉复杂手术过程。

研究结论: SurgVidLM为手术视频理解提供了首个多粒度解决方案，其性能优越，为医学视频分析开辟了新方向。

中文摘要: 近年来，多模态大语言模型在医学领域展现出巨大潜力，帮助用户理解手术场景和流程。相较于基于图像的方法，视频大语言模型（Vid-LLMs）的探索成为捕捉手术中复杂信息序列的有力途径。然而，目前仍缺乏专门用于细粒度手术视频理解的Vid-LLMs，而这对于分析手术中的具体过程或细节至关重要。为此，我们提出SurgVidLM，首个旨在同时解决全视频和细粒度手术视频理解的视频语言模型。为训练SurgVidLM，我们构建了SVU-31K数据集，包含超过31K视频-指令对，支持手术流程的整体理解和详细分析。此外，我们引入了StageFocus机制，这是一个两阶段框架，实现对手术视频的多粒度渐进理解。我们还开发了Multi-frequency Fusion Attention，有效融合低频和高频视觉标记，确保关键信息的保留。实验结果表明，SurgVidLM在全视频和细粒度视频理解任务中均显著优于现有Vid-LLMs，展现了其在捕捉复杂流程上下文方面的卓越能力。

</details>


### [135] [StainPIDR: A Pathological Image Decouplingand Reconstruction Method for StainNormalization Based on Color VectorQuantization and Structure Restaining](https://arxiv.org/abs/2506.17879)
**中文标题：StainPIDR：基于颜色向量量化与结构重染色的病理图像解耦与重建方法**

*Zheng Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为StainPIDR的病理图像染色归一化方法，通过解耦图像的结构特征和颜色特征，并利用向量量化和结构重染色技术，有效解决了病理图像因染色差异导致的诊断系统性能下降问题。


<details>
  <summary>详细信息</summary>
研究动机: 病理图像的颜色差异主要由成像协议、染料比例和扫描设备等因素引起，这些差异会影响计算机辅助诊断系统的性能。因此，需要一种方法消除颜色差异，提升诊断准确性。

研究方法: StainPIDR方法将图像解耦为结构特征和向量量化的颜色特征，通过固定颜色向量码本映射颜色特征，并利用交叉注意力机制对结构特征进行重染色。此外，还设计了模板图像选择算法以优化染色归一化效果。

研究结果: 实验验证了StainPIDR和模板图像选择算法的有效性，表明该方法在染色归一化任务中表现优异。

研究结论: StainPIDR能够有效解决病理图像颜色差异问题，提升计算机辅助诊断系统的性能，其代码将公开供后续研究使用。

中文摘要: 病理图像的颜色表现与成像协议、染料比例及扫描设备高度相关。这些颜色差异可能导致计算机辅助诊断系统性能下降。本文提出了一种名为StainPIDR的染色归一化方法，通过将图像解耦为结构特征和向量量化的颜色特征，对结构特征进行目标颜色重染色，并解码为归一化的病理图像。假设相同颜色的图像解耦出的颜色特征应完全一致，因此训练了一个固定颜色向量码本用于映射颜色特征。在重染色部分，利用交叉注意力机制高效染色结构特征。由于目标颜色（从模板图像解耦）也会影响归一化效果，进一步设计了模板图像选择算法。大量实验验证了StainPIDR及模板选择算法的有效性，结果表明该方法在染色归一化任务中表现优异。StainPIDR的代码将后续公开。

</details>


### [136] [Cloud-Aware SAR Fusion for Enhanced Optical Sensing in Space Missions](https://arxiv.org/abs/2506.17885)
**中文标题：面向空间任务的云感知SAR融合增强光学传感**

*Trong-An Bui,Thanh-Thoai Le*

主要分类: cs.CV

摘要简述: 本文提出了一种结合SAR-光学特征融合和深度学习的云感知重建框架，用于生成无云光学图像，显著提升了图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 云污染严重影响了光学卫星图像的可用性，限制了环境监测、灾害响应和土地利用分析等关键应用。因此，需要一种有效的方法来消除云层干扰，生成高质量的无云图像。

研究方法: 研究提出了一种云感知重建框架，通过注意力驱动的特征融合机制，将合成孔径雷达（SAR）的结构信息与光学数据的光谱特征对齐，并结合自适应损失加权策略，优先处理云遮挡区域。

研究结果: 实验结果表明，该方法优于现有技术，PSNR达到31.01 dB，SSIM为0.918，MAE为0.017，能够生成高保真、空间和光谱一致的无云光学图像。

研究结论: 该框架在消除云污染、提升光学图像质量方面表现出色，为卫星遥感应用提供了有效的解决方案。

中文摘要: 云污染显著降低了光学卫星图像的可用性，影响了环境监测、灾害响应和土地利用分析等关键应用。本研究提出了一种云感知重建框架，通过结合SAR-光学特征融合和基于深度学习的图像重建技术，生成无云光学图像。该框架采用注意力驱动的特征融合机制，将合成孔径雷达（SAR）的互补结构信息与光学数据的光谱特征对齐。此外，云感知模型更新策略引入了自适应损失加权，优先处理云遮挡区域，从而提高了重建精度。实验结果表明，所提方法优于现有方法，PSNR达到31.01 dB，SSIM为0.918，MAE为0.017。这些结果证明了该框架在生成高保真、空间和光谱一致的无云光学图像方面的有效性。

</details>


### [137] [Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation](https://arxiv.org/abs/2506.17891)
**中文标题：Relation3D：增强点云实例分割中的关系建模**

*Jiahao Lu,Jiacheng Deng*

主要分类: cs.CV

摘要简述: Relation3D通过增强点云实例分割中的关系建模，提出自适应超点聚合模块和对比学习引导的超点优化模块，结合关系感知自注意力机制，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于Transformer的方法主要关注场景特征与查询特征的外部关系，而忽略了场景特征内部及查询特征之间的关系建模。Relation3D旨在解决这一问题。

研究方法: 提出自适应超点聚合模块和对比学习引导的超点优化模块，优化超点特征表示；引入关系感知自注意力机制，结合位置和几何关系增强查询特征间的关系建模。

研究结果: 在ScanNetV2、ScanNet++、ScanNet200和S3DIS数据集上的实验表明，Relation3D性能优越。

研究结论: Relation3D通过改进关系建模，显著提升了点云实例分割的性能，为未来研究提供了新思路。

中文摘要: 3D实例分割旨在预测场景中的一组对象实例，并将其表示为带有相应语义标签的二进制前景掩码。目前，基于Transformer的方法因其优雅的流程和卓越的预测性能而受到越来越多的关注。然而，这些方法主要通过掩码注意力建模场景特征与查询特征的外部关系，缺乏对场景特征内部及查询特征之间关系的有效建模。针对这些不足，我们提出了\textbf{Relation3D：增强点云实例分割中的关系建模}。具体而言，我们引入了自适应超点聚合模块和对比学习引导的超点优化模块，以更好地表示超点特征（场景特征），并利用对比学习指导这些特征的更新。此外，我们的关系感知自注意力机制通过将位置和几何关系融入自注意力机制，增强了查询特征间的关系建模能力。在ScanNetV2、ScanNet++、ScanNet200和S3DIS数据集上的大量实验证明了Relation3D的优越性能。

</details>


### [138] [BeltCrack: the First Sequential-image Industrial Conveyor Belt Crack Detection Dataset and Its Baseline with Triple-domain Feature Learning](https://arxiv.org/abs/2506.17892)
**中文标题：BeltCrack：首个序列图像工业传送带裂纹检测数据集及其基于三域特征学习的基线方法**

*Jianghong Huang,Luping Ji,Xin Ma,Mao Ye*

主要分类: cs.CV

摘要简述: 本文构建了首个真实工业场景的传送带裂纹检测数据集（BeltCrack14ks和BeltCrack9kd），并提出了一种基于时空频三域特征分层融合的基线方法，实验证明其优于其他类似方法。


<details>
  <summary>详细信息</summary>
研究动机: 传送带是现代工业中的重要设备，其裂纹问题严重影响运行效率和安全。现有裂纹数据集多为路面场景或合成数据，缺乏真实工业场景的数据集，阻碍了机器学习在该领域的应用。

研究方法: 本文构建了首个真实工业场景的传送带裂纹数据集，并提出了一种基于时空频三域特征分层融合的基线方法，用于验证数据集的有效性。

研究结果: 实验结果表明，所构建的数据集具有可用性和有效性，且提出的基线方法明显优于其他类似检测方法。

研究结论: 本文填补了真实工业场景传送带裂纹数据集的空白，提出的基线方法为后续研究提供了有效工具。

中文摘要: 传送带是现代工业中的重要设备，广泛应用于生产和制造领域。其健康状况对运行效率和安全风险至关重要。在影响传送带健康的因素中，裂纹往往是最具威胁的风险之一。目前，出于安全考虑，如何智能检测传送带裂纹正受到越来越多的关注。为实现基于机器学习的智能检测，真实的裂纹样本被认为是必要的。然而，现有的裂纹数据集主要关注路面场景或合成数据，完全没有真实工业场景的传送带裂纹数据集。为推动该领域的机器学习发展，本文从真实工厂场景中构建了首个序列图像传送带裂纹检测数据集（BeltCrack14ks和BeltCrack9kd）。此外，为验证其可用性和有效性，我们提出了一种特殊的基线方法，采用时空频三域特征分层融合学习，用于这两个全新数据集。实验结果表明，我们的数据集具有可用性和有效性。此外，实验结果还表明，我们的基线方法明显优于其他类似检测方法。我们的数据集和源代码可在https://github.com/UESTC-nnLab/BeltCrack获取。

</details>


### [139] [EgoWorld: Translating Exocentric View to Egocentric View using Rich Exocentric Observations](https://arxiv.org/abs/2506.17896)
**中文标题：EgoWorld：利用丰富的第三人称观察将第三人称视角转换为第一人称视角**

*Junho Park,Andrew Sangwoo Ye,Taein Kwon*

主要分类: cs.CV

摘要简述: EgoWorld提出了一种新颖的两阶段框架，通过丰富的第三人称观察（如点云、3D手部姿态和文本描述）重建第一人称视角，解决了现有方法依赖2D线索和多视角同步的限制，并在H2O和TACO数据集上实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 第一人称视角在增强现实（AR）、虚拟现实（VR）和机器人应用中至关重要，但现有的第三人称到第一人称视角转换方法依赖2D线索、多视角同步设置或不切实际的假设（如初始第一人称帧和相机姿态）。EgoWorld旨在通过丰富的第三人称观察克服这些限制。

研究方法: EgoWorld采用两阶段框架：首先从估计的第三人称深度图重建点云，并将其重投影到第一人称视角；然后使用基于扩散的修复技术生成密集且语义连贯的第一人称图像。

研究结果: 在H2O和TACO数据集上，EgoWorld实现了最先进的性能，并对新物体、动作、场景和主体表现出强大的泛化能力。此外，即使在未标记的真实世界示例中也显示出良好的效果。

研究结论: EgoWorld通过丰富的第三人称观察成功重建了第一人称视角，克服了现有方法的限制，为AR、VR和机器人应用提供了更灵活的解决方案。

中文摘要: 第一人称视角对人类和机器的视觉理解至关重要，尤其是在捕捉手-物体交互细节以完成操作任务时。将第三人称视角转换为第一人称视角对增强现实（AR）、虚拟现实（VR）和机器人应用具有重要意义。然而，现有的第三人称到第一人称转换方法受限于对2D线索、同步多视角设置以及不切实际假设（如推断时需要初始第一人称帧和相机姿态）的依赖。为解决这些问题，我们提出了EgoWorld，一种新颖的两阶段框架，通过丰富的第三人称观察（包括投影点云、3D手部姿态和文本描述）重建第一人称视角。我们的方法首先从估计的第三人称深度图重建点云，并将其重投影到第一人称视角，然后应用基于扩散的修复技术生成密集且语义连贯的第一人称图像。在H2O和TACO数据集上的评估表明，EgoWorld实现了最先进的性能，并对新物体、动作、场景和主体表现出强大的泛化能力。此外，EgoWorld在未标记的真实世界示例中也显示出良好的效果。

</details>


### [140] [PostAlign: Multimodal Grounding as a Corrective Lens for MLLMs](https://arxiv.org/abs/2506.17901)
**中文标题：PostAlign：多模态基础作为MLLMs的矫正视角**

*Yixuan Wu,Yang Zhang,Jian Wu,Philip Torr,Jindong Gu*

主要分类: cs.CV

摘要简述: 本文提出PostAlign框架，通过多模态对齐增强MLLMs的视觉理解能力，减少幻觉问题，结合视觉和文本基础模块，显著提升细粒度视觉理解和幻觉抑制效果。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在视觉语言任务中表现优异，但常因过度依赖语言先验而忽视实际视觉信息，导致幻觉问题。本文旨在通过多模态对齐框架解决这一问题。

研究方法: 提出MMGrounded-PostAlign框架，包含视觉基础模块（识别图像中对象）和文本基础模块（生成答案依据），并引入负拒绝机制和选择性推理机制以抑制幻觉。

研究结果: 在POPE、HaloQuest、VQAv2、MME和MMBench等基准测试中，模型在细粒度视觉理解和幻觉抑制方面表现显著提升。

研究结论: PostAlign框架通过多模态对齐有效增强MLLMs的视觉理解能力，减少幻觉问题，为未来研究提供了新方向。

中文摘要: 多模态大语言模型（MLLMs）在图像描述和视觉问答等视觉语言任务中表现出色，但常因过度依赖语言先验而忽视实际视觉信息，导致幻觉问题。为解决这些问题，我们提出了MMGrounded-PostAlign，一种后多模态对齐框架，旨在增强MLLMs的视觉理解能力并减少幻觉。该框架包含多模态基础模块，分别用于视觉基础（识别图像中的对象）和文本基础（生成最终答案的依据），确保输出基于视觉和文本证据。为减少幻觉，我们在视觉基础模块中引入负拒绝机制，以区分基于语言偏见的非存在对象。在文本基础方面，我们提出选择性推理机制，根据查询复杂度调整模型的推理策略。在POPE、HaloQuest、VQAv2、MME和MMBench等基准测试上的广泛评估表明，该框架在细粒度视觉理解和幻觉抑制方面取得了显著改进。

</details>


### [141] [Cause-Effect Driven Optimization for Robust Medical Visual Question Answering with Language Biases](https://arxiv.org/abs/2506.17903)
**中文标题：基于因果驱动的优化方法用于鲁棒医学视觉问答中的语言偏差问题**

*Huanjia Zhu,Yishu Liu,Xiaozhao Fang,Guangming Lu,Bingzhi Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CEDO的新型因果驱动优化框架，通过三种机制（MHO、GMS、DLR）从因果和效果角度全面缓解医学视觉问答中的语言偏差问题，显著提升了模型的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有医学视觉问答（Med-VQA）模型常因语言偏差（如问题类型与答案类别间的虚假关联）而表现不佳。本文旨在通过因果驱动的方法解决这一问题，提升模型的鲁棒性。

研究方法: CEDO框架包含三种机制：1）MHO通过模态驱动的异质优化增强推理能力；2）GMS利用帕累托优化促进模态协同并消除偏差更新；3）DLR通过自适应损失权重平衡学习，缓解数据集中的不平衡偏差。

研究结果: 在多个传统和偏差敏感基准测试中，CEDO表现出优于现有方法的鲁棒性，验证了其有效性。

研究结论: CEDO通过因果驱动的方法有效缓解了Med-VQA中的语言偏差问题，为未来研究提供了新思路。

中文摘要: 现有医学视觉问答（Med-VQA）模型常因语言偏差（如问题类型与答案类别间的虚假关联）而表现不佳。为解决这一问题，本文提出了一种新型因果驱动优化框架CEDO，包含三种机制：模态驱动的异质优化（MHO）、梯度引导的模态协同（GMS）和分布适应的损失重缩放（DLR），从因果和效果角度全面缓解语言偏差。具体而言，MHO通过自适应学习率增强模态推理能力；GMS利用帕累托优化促进模态协同并消除偏差更新；DLR通过自适应损失权重平衡学习。在多个基准测试中，CEDO均表现出优于现有方法的鲁棒性。

</details>


### [142] [Feedback Driven Multi Stereo Vision System for Real-Time Event Analysis](https://arxiv.org/abs/2506.17910)
**中文标题：基于反馈驱动的多立体视觉系统用于实时事件分析**

*Mohamed Benkedadra,Matei Mancas,Sidi Ahmed Mahmoudi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于3D立体视觉的实时事件分析系统，通过多摄像头融合实现场景重建，支持事件识别、目标跟踪等功能，并通过反馈机制优化决策。


<details>
  <summary>详细信息</summary>
研究动机: 现有2D摄像头和短距离3D摄像头在复杂环境中表现不佳，因此需要一种更可靠的3D立体视觉系统，以支持交互式应用和场景理解。

研究方法: 提出了一种多3D摄像头融合的流水线，实现全场景重建，并结合反馈机制从环境中学习以优化决策。

研究结果: 初步实验表明，该系统能够有效支持事件识别、目标跟踪和通知功能，并通过反馈适应新环境。

研究结论: 本文提出了一个可行的3D立体视觉系统框架，并规划了进一步优化和生产的路线图。

中文摘要: 2D摄像头常用于交互式系统，而游戏机等设备则提供更强大的短距离3D深度感知摄像头。然而，这些摄像头在复杂大环境中并不可靠。本文提出了一种基于3D立体视觉的流水线，能够通过鲁棒的场景理解处理普通和敏感应用。我们探索了多3D摄像头的融合以实现全场景重建，从而支持事件识别、目标跟踪和通知等功能。通过可能的反馈机制，系统可以从环境中获取数据，学习优化决策或适应全新环境。文中介绍了该流水线，并展示了初步实验和结果。最后，我们规划了将该流水线投入生产的下一步路线图。

</details>


### [143] [PlanMoGPT: Flow-Enhanced Progressive Planning for Text to Motion Synthesis](https://arxiv.org/abs/2506.17912)
**中文标题：PlanMoGPT：基于流增强渐进式规划的文本到运动合成**

*Chuhao Jin,Haosen Li,Bingzi Zhang,Che Liu,Xiting Wang,Ruihua Song,Wenbing Huang,Ying Qin,Fuzheng Zhang,Di Zhang*

主要分类: cs.CV

摘要简述: PlanMoGPT通过渐进式规划和流增强细粒度运动标记化，解决了文本到运动生成中的多样性-质量权衡问题，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大语言模型（LLM）的文本到运动生成方法在性能上落后于非LLM方法，主要由于运动标记化的粒度问题：细粒度标记化导致局部依赖问题，而粗粒度标记化牺牲了运动细节。

研究方法: PlanMoGPT结合渐进式规划和流增强细粒度运动标记化：1）渐进式规划机制利用LLM的自回归能力，从稀疏全局计划逐步细化生成完整运动序列；2）流增强标记器提高下采样分辨率并扩展码本大小，减少离散化过程中的细节损失，同时通过流增强解码器恢复运动细节。

研究结果: 在文本到运动基准测试中，PlanMoGPT实现了最先进的性能，长序列生成的FID分数提升了63.8%（从0.380降至0.141），运动多样性提高了49.9%。

研究结论: PlanMoGPT成功解决了当前非LLM方法面临的多样性-质量权衡问题，为文本到运动生成设定了新标准。

中文摘要: 近年来，大语言模型（LLM）在多模态生成任务中取得了突破性进展，但在文本到运动生成领域，基于LLM的方法仍显著落后于非LLM方法。我们发现运动标记化的粒度是关键瓶颈：细粒度标记化会引发局部依赖问题，导致LLM过度强调短期一致性而牺牲全局语义对齐；而粗粒度标记化则丢失了运动细节。为解决这一问题，我们提出了PlanMoGPT，一个结合渐进式规划和流增强细粒度运动标记化的LLM框架。首先，渐进式规划机制利用LLM的自回归能力，从稀疏全局计划开始，逐步细化生成完整运动序列。其次，流增强标记器将下采样分辨率提高一倍，并将码本大小扩展八倍，最小化离散化过程中的细节损失，同时通过流增强解码器恢复运动细节。在文本到运动基准测试上的大量实验表明，PlanMoGPT实现了最先进的性能，长序列生成的FID分数提升了63.8%（从0.380降至0.141），同时运动多样性提高了49.9%。该框架成功解决了当前非LLM方法面临的多样性-质量权衡问题，为文本到运动生成了新的标准。

</details>


### [144] [IDAL: Improved Domain Adaptive Learning for Natural Images Dataset](https://arxiv.org/abs/2506.17931)
**中文标题：IDAL：改进的自然图像数据集域自适应学习方法**

*Ravi Kant Gupta,Shounak Das,Amit Sethi*

主要分类: cs.CV

摘要简述: 本文提出了一种改进的无监督域自适应学习方法IDAL，通过结合ResNet和FPN的深度结构以及新型损失函数，有效解决了自然图像数据集中的域偏移问题，提升了目标域的模型准确性和训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的对抗域自适应方法在处理多模态分布的分类问题时，可能无法有效对齐不同域。本文旨在通过改进的神经网络架构和损失函数设计，解决自然图像数据集中因尺度、噪声和风格变化带来的挑战。

研究方法: 方法结合了ResNet的深度结构和FPN的多尺度特征分离能力，同时设计了一种新型损失函数与现有损失函数的组合，以优化模型在目标域的表现。

研究结果: 在Office-Home、Office-31和VisDA-2017数据集上，IDAL优于当前最先进的基于CNN的方法，在DomainNet数据集上表现相当。

研究结论: IDAL通过改进的架构和损失函数设计，显著提升了无监督域自适应的性能，尤其在处理自然图像数据集时表现出色。

中文摘要: 我们提出了一种用于自然图像无监督域自适应（UDA）的新方法。UDA方案的常用目标是在表示空间中增强域对齐，即使输入空间存在域偏移。现有的对抗域自适应方法可能无法有效对齐与分类问题相关的多模态分布的不同域。我们的方法有两个主要特点。首先，其神经网络架构利用了ResNet的深度结构和特征金字塔网络（FPN）的多尺度特征分离能力，同时处理内容和风格特征。其次，它结合了一种新型损失函数和精心选择的现有损失函数来训练网络架构。这种定制组合旨在解决自然图像中固有的挑战，如尺度、噪声和风格变化，这些挑战出现在多模态（多类）分布之上。组合损失函数不仅提高了目标域上的模型准确性和鲁棒性，还加快了训练收敛速度。我们提出的UDA方案在Office-Home、Office-31和VisDA-2017数据集上优于基于CNN的最新方法，在DomainNet数据集上表现相当。

</details>


### [145] [GEMeX-ThinkVG: Towards Thinking with Visual Grounding in Medical VQA via Reinforcement Learning](https://arxiv.org/abs/2506.17939)
**中文标题：GEMeX-ThinkVG：通过强化学习实现医学视觉问答中的视觉关联推理**

*Bo Liu,Xiangyu Zhao,Along He,Yidi Chen,Huazhu Fu,Xiao-Ming Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ThinkVG的数据集和基于强化学习的可验证奖励机制，用于提升医学视觉问答模型的可靠性和可解释性。该方法仅需八分之一的训练数据即可达到可比性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前医学视觉问答模型存在答案可靠性低和可解释性差的问题，限制了临床医生和患者对模型生成答案的理解和信任。

研究方法: 1. 提出ThinkVG数据集，将答案生成分解为显式关联医学图像区域的中间推理步骤；2. 引入基于强化学习的可验证奖励机制，优化模型推理过程与最终答案的一致性。

研究结果: 该方法仅需八分之一的训练数据即可达到与现有方法相当的性能，显著提升了效率和效果。

研究结论: 通过ThinkVG数据集和可验证奖励机制，显著提升了医学视觉问答模型的可靠性和可解释性，为临床应用提供了更高效和可信的解决方案。

中文摘要: 医学视觉问答旨在通过模型基于医学图像回答自然语言问题来支持临床决策。尽管多模态学习的最新进展显著提升了性能，但现有方法仍存在答案可靠性低和可解释性差的问题，影响了临床医生和患者对模型生成答案的理解和信任。为此，本文首先提出了一个名为“视觉关联推理”（ThinkVG）的数据集，其中答案生成被分解为显式关联医学图像相关区域的中间推理步骤，从而提供细粒度的可解释性。此外，我们引入了一种基于强化学习的可验证奖励机制，用于指导后训练，优化模型推理过程与最终答案的一致性。值得注意的是，我们的方法仅需八分之一的训练数据即可达到可比性能，证明了该提案的高效性和有效性。数据集可在https://huggingface.co/datasets/BoKelvin/GEMeX-ThinkVG获取。

</details>


### [146] [SegChange-R1:Augmented Reasoning for Remote Sensing Change Detection via Large Language Models](https://arxiv.org/abs/2506.17944)
**中文标题：SegChange-R1：基于大语言模型的遥感变化检测增强推理方法**

*Fei Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种基于大语言模型（LLM）的增强推理方法SegChange-R1，用于遥感变化检测，通过整合文本描述信息提升检测能力，并设计了一种基于线性注意力的空间变换模块（BEV）解决模态不对齐问题。实验表明该方法在多个数据集上显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 遥感变化检测在城乡规划、地形地貌分析和环境监测等领域有广泛应用，但现有方法在检测能力和模态对齐方面存在不足。本文旨在通过大语言模型增强推理能力，并解决模态不对齐问题。

研究方法: 提出SegChange-R1方法，整合文本描述信息以增强检测能力；设计基于线性注意力的BEV模块，统一不同时间视角的特征到BEV空间；构建首个无人机视角的建筑变化检测数据集（DVCD）。

研究结果: 在四个广泛使用的变化检测数据集上，SegChange-R1显著优于现有方法，验证了其有效性。

研究结论: SegChange-R1通过大语言模型增强推理和BEV模块设计，显著提升了遥感变化检测的性能，为相关领域提供了新的解决方案。

中文摘要: 遥感变化检测广泛应用于城乡规划、地形地貌分析和环境监测等领域，主要通过分析同一空间区域在不同时间阶段的特征（如建筑变化）的显著差异。本文提出了一种基于大语言模型（LLM）的增强推理方法（SegChange-R1），通过整合文本描述信息提升检测能力，旨在引导模型分割更感兴趣的变化区域，从而加速收敛速度。此外，我们设计了一种基于线性注意力的空间变换模块（BEV），通过将不同时间视角的特征统一到BEV空间，解决了变化检测中的模态不对齐问题。我们还构建了首个无人机视角的建筑变化检测数据集（DVCD）。在四个广泛使用的变化检测数据集上的实验表明，该方法显著优于现有方法。代码和预训练模型可在https://github.com/Yu-Zhouz/SegChange-R1获取。

</details>


### [147] [Classification of Tents in Street Bazaars Using CNN](https://arxiv.org/abs/2506.17946)
**中文标题：基于CNN的街头集市帐篷分类**

*Azamat Ibragimov,Ruslan Isaev,Remudin Reshid Mekuria,Gulnaz Gimaletdinova,Dim Shaiakhmetov*

主要分类: cs.CV

摘要简述: 本研究提出一种改进的深度学习模型，用于分类街头集市中的帐篷，比较了自定义CNN与EfficientNetB0的性能。结果显示，EfficientNetB0的准确率达98.4%，优于自定义CNN的92.8%，验证了迁移学习在集市图像分类中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 街头集市是许多地区的重要经济中心，但其非结构化特性使得帐篷等市场基础设施的自动分类成为挑战。传统手动方法效率低下，而CNN在集市特定任务中的应用尚未充分探索。

研究方法: 研究通过扩展126张原始照片并生成增强图像构建数据集，训练自定义CNN和EfficientNetB0模型，使用准确率、精确率、召回率、F1分数和mAP等指标评估性能。

研究结果: 自定义CNN的准确率为92.8%，而EfficientNetB0达到98.4%。混淆矩阵分析揭示了各模型的优缺点，表明预训练模型显著提升了分类准确率和泛化能力。

研究结论: 使用预训练模型（如EfficientNetB0）可显著提高集市帐篷分类的准确性和泛化性能，为市场组织提供高效解决方案。

中文摘要: 本研究提出一种改进的深度学习模型，用于分类街头集市中的帐篷，比较了自定义卷积神经网络（CNN）与EfficientNetB0的性能。集市帐篷分类对市场组织至关重要，但传统手动方法效率低下。街头集市是许多地区的重要经济中心（如吉尔吉斯斯坦，集市贡献了该国超过四分之一的GDP），但其非结构化特性为帐篷等基础设施的自动分类带来挑战。尽管CNN已广泛应用于物体识别，但其在集市特定任务中的应用仍较少。本研究在原有方法基础上，通过扩展126张原始照片并生成增强图像构建数据集，该数据集已在Kaggle上公开。研究使用准确率、精确率、召回率、F1分数和平均精度（mAP）等指标对模型进行对比评估，提供了更全面的分类性能分析。结果显示，自定义CNN的准确率为92.8%，而EfficientNetB0达到98.4%，验证了迁移学习在集市图像分类中的有效性。混淆矩阵分析揭示了各模型的优缺点，表明预训练模型显著提升了分类准确率和泛化能力。

</details>


### [148] [Mobile Image Analysis Application for Mantoux Skin Test](https://arxiv.org/abs/2506.17954)
**中文标题：基于移动图像分析的曼托皮肤试验应用**

*Liong Gele,Tan Chye Cheah*

主要分类: cs.CV

摘要简述: 本文介绍了一款新型移动应用程序，用于通过曼托皮肤试验（TST）诊断潜伏性结核感染（LTBI）。该应用利用图像处理和机器学习技术，显著提高了诊断的准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的曼托皮肤试验方法存在随访率低、患者不适和主观性解读等问题，容易导致误诊和治疗延误。此外，现有移动应用多依赖3D重建技术，而本应用通过引入标尺贴纸作为参考物，解决了这些问题。

研究方法: 该应用结合了ARCore和DeepLabv3等先进图像处理与机器学习技术，采用边缘检测算法提升测量精度，实现了对皮肤硬结的自动化、标准化评估。

研究结果: 与标准临床实践相比，该应用显著提高了诊断的准确性和可靠性，为结核病管理提供了高效工具。

研究结论: 该应用通过自动化和标准化曼托皮肤试验评估，提升了结核病诊断的可及性和效率。未来工作将优化机器学习模型和测量算法，并扩展患者数据管理功能。

中文摘要: 本文介绍了一款新开发的移动应用程序，用于通过曼托皮肤试验（TST）诊断潜伏性结核感染（LTBI）。传统的TST方法存在随访率低、患者不适和主观性解读等问题，尤其是圆珠笔法，容易导致误诊和治疗延误。与此前依赖3D重建的移动应用不同，本应用采用标尺贴纸作为参考物进行硬结测量。该应用集成了先进的图像处理技术（如ARCore）和机器学习算法（如DeepLabv3），实现了对皮肤硬结的鲁棒图像分割和精确测量，并通过边缘检测算法提升准确性。与标准临床实践对比评估表明，该应用显著提高了准确性和可靠性。这一创新对结核病管理至关重要，尤其是在资源有限的地区。通过自动化和标准化TST评估，该应用提升了结核病诊断的可及性和效率。未来工作将优化机器学习模型和测量算法，扩展患者数据管理功能，并提升ARCore在不同光照和操作环境下的性能。

</details>


### [149] [ELMAR: Enhancing LiDAR Detection with 4D Radar Motion Awareness and Cross-modal Uncertainty](https://arxiv.org/abs/2506.17958)
**中文标题：ELMAR：通过4D雷达运动感知和跨模态不确定性增强LiDAR检测**

*Xiangyuan Peng,Miao Tang,Huawei Sun,Bierzynski Kay,Lorenzo Servadei,Robert Wille*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ELMAR的LiDAR检测框架，通过结合4D雷达的运动感知和跨模态不确定性，解决了LiDAR与4D雷达融合中的模态不对齐问题，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: LiDAR和4D雷达在自动驾驶和机器人领域广泛应用，LiDAR提供丰富的空间信息，而4D雷达则提供速度测量并在恶劣条件下表现稳健。然而，现有研究往往忽视了两者之间的模态不对齐问题。本文旨在通过结合4D雷达的运动状态和跨模态不确定性，提升LiDAR检测的准确性和鲁棒性。

研究方法: 1. 提出动态运动感知编码模块（Dynamic Motion-Aware Encoding），在特征提取阶段捕获4D雷达的运动信息以增强预测。2. 估计边界框的实例级不确定性，以减少跨模态不对齐并优化最终的LiDAR预测。

研究结果: 在View-of-Delft（VoD）数据集上的实验表明，该方法在整体区域和驾驶走廊内的mAP分别达到74.89%和88.70%，同时保持30.02 FPS的实时推理速度，性能达到最先进水平。

研究结论: ELMAR框架通过结合4D雷达的运动感知和跨模态不确定性，有效解决了LiDAR与4D雷达融合中的模态不对齐问题，显著提升了检测性能，同时保持了实时性。

中文摘要: LiDAR和4D雷达广泛应用于自动驾驶和机器人领域。LiDAR提供丰富的空间信息，而4D雷达则提供速度测量并在恶劣条件下表现稳健。因此，越来越多的研究关注于4D雷达与LiDAR的融合方法以提升感知能力。然而，不同模态之间的不对齐问题常被忽视。为解决这一挑战并充分利用两种模态的优势，我们提出了一种通过4D雷达运动状态和跨模态不确定性增强的LiDAR检测框架。在特征提取阶段，首先通过动态运动感知编码模块捕获4D雷达的运动信息以增强其预测。随后，估计边界框的实例级不确定性以减少跨模态不对齐并优化最终的LiDAR预测。在View-of-Delft（VoD）数据集上的大量实验证明了该方法的有效性，整体区域和驾驶走廊内的mAP分别达到74.89%和88.70%，同时保持30.02 FPS的实时推理速度，性能达到最先进水平。

</details>


### [150] [BPCLIP: A Bottom-up Image Quality Assessment from Distortion to Semantics Based on CLIP](https://arxiv.org/abs/2506.17969)
**中文标题：BPCLIP：一种基于CLIP的自底向上从失真到语义的图像质量评估方法**

*Chenyue Song,Chen Hui,Wei Zhang,Haiqi Zhu,Shaohui Liu,Hong Huang,Feng Jiang*

主要分类: cs.CV

摘要简述: BPCLIP是一种基于CLIP的自底向上图像质量评估方法，通过逐步提取低层失真对高层语义的影响，结合多尺度交叉注意力模块和40个图像质量形容词，显著提升了图像质量评估的性能和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像质量评估方法多依赖多尺度特征的线性融合，未能充分捕捉失真对语义内容的影响。BPCLIP旨在通过自底向上的方式，更准确地评估失真对图像语义的影响。

研究方法: BPCLIP利用编码器提取多尺度特征，并引入自底向上的多尺度交叉注意力模块，捕捉浅层与深层特征的关系。同时，结合40个图像质量形容词，利用CLIP文本编码器生成图像内在质量的表示，增强图像质量感知与人类语言的关联。

研究结果: BPCLIP在大多数公开的全参考（FR）和无参考（NR）图像质量评估基准测试中表现优异，并展现出更强的鲁棒性。

研究结论: BPCLIP通过自底向上的方式结合多尺度特征和语义信息，显著提升了图像质量评估的准确性和鲁棒性，为未来研究提供了新思路。

中文摘要: 图像质量评估（IQA）旨在基于人类主观感知评估图像的感知质量。现有方法通常结合多尺度特征以实现高性能，但多数依赖这些特征的简单线性融合，可能无法充分捕捉失真对语义内容的影响。为此，我们提出了一种基于对比语言-图像预训练（CLIP，一种最近提出的将图像和文本对齐到共享特征空间的模型）的自底向上图像质量评估方法，命名为BPCLIP，逐步提取低层失真对高层语义的影响。具体而言，我们利用编码器从输入图像中提取多尺度特征，并引入自底向上的多尺度交叉注意力模块，旨在捕捉浅层与深层特征之间的关系。此外，通过结合六个不同维度的40个图像质量形容词，我们使预训练的CLIP文本编码器能够生成图像内在质量的表示，从而增强图像质量感知与人类语言的关联。我们的方法在大多数公开的全参考（FR）和无参考（NR）IQA基准测试中取得了优异的结果，同时展现出更强的鲁棒性。

</details>


### [151] [Enabling PSO-Secure Synthetic Data Sharing Using Diversity-Aware Diffusion Models](https://arxiv.org/abs/2506.17975)
**中文标题：基于多样性感知扩散模型的PSO安全合成数据共享**

*Mischa Dombrowski,Bernhard Kainz*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多样性感知扩散模型的PSO安全合成数据共享框架，旨在解决合成数据在隐私保护和性能上的不足，同时确保数据共享的合法性。


<details>
  <summary>详细信息</summary>
研究动机: 合成数据在医学影像等领域具有隐私保护潜力，但现有方法在合法性和性能上存在不足。本文旨在通过最大化多样性提升合成数据的隐私保护能力（PSO安全）和下游任务性能。

研究方法: 提出了一种通用的扩散模型训练框架，通过最大化生成数据的多样性，确保合成数据既满足隐私保护（PSO安全），又能接近真实数据的性能。

研究结果: 实验表明，该方法生成的合成数据在性能上接近真实数据（差距小于1%），并显著优于未考虑隐私保护的现有方法。

研究结论: 通过多样性最大化，本文方法实现了隐私保护与性能的平衡，为合成数据共享提供了合法且高效的解决方案。

中文摘要: 合成数据在视觉保真度上已达到与真实数据难以区分的水平，为医学影像等领域的隐私保护数据共享提供了可能。然而，完全合成的数据集仍存在显著局限：首先，合成数据共享的法律问题常被忽视，如GDPR等数据法规未被充分考虑；其次，合成数据在下游任务中的性能仍不及真实数据。近期图像生成方法专注于最大化图像多样性而非仅保真度，以提升合成数据的模式覆盖和下游性能。本文转变视角，指出最大化多样性也可视为保护个体免于被单独识别，从而实现PSO安全的合成数据集。具体而言，我们提出了一种通用的扩散模型训练框架，用于生成去个性化的合成数据，其性能与真实数据模型的差距小于1%，同时显著优于未确保隐私的现有方法。代码发布于https://github.com/MischaD/Trichotomy。

</details>


### [152] [Fast Neural Inverse Kinematics on Human Body Motions](https://arxiv.org/abs/2506.17996)
**中文标题：基于神经网络的快速人体运动逆运动学**

*David Tolpin,Sefy Kagarlitsky*

主要分类: cs.CV

摘要简述: 本文提出了一种快速神经逆运动学框架，用于实时捕捉人体运动的3D关键点，解决了无标记运动捕捉系统计算需求高和推理速度慢的问题。


<details>
  <summary>详细信息</summary>
研究动机: 无标记运动捕捉系统虽然灵活且成本低，但通常计算需求高且推理速度慢，限制了其在实时场景中的应用。本文旨在解决这一问题。

研究方法: 详细描述了网络架构、训练方法和推理流程，并通过消融研究验证了关键设计决策。

研究结果: 框架在定性和定量评估中表现优异，证明了其在实时捕捉人体运动中的高效性和可靠性。

研究结论: 该神经逆运动学框架为实时人体运动捕捉提供了一种快速可靠的解决方案，具有实际应用潜力。

中文摘要: 无标记运动捕捉无需物理标记或服装，与传统系统相比更具灵活性和成本优势。然而，这些优势通常伴随着更高的计算需求和较慢的推理速度，限制了其在实时场景中的应用。本技术报告提出了一种快速可靠的神经逆运动学框架，用于从3D关键点实时捕捉人体运动。我们详细描述了网络架构、训练方法和推理流程，并通过定性和定量评估验证了框架的性能，同时通过消融研究支持了关键设计决策。

</details>


### [153] [OSDMamba: Enhancing Oil Spill Detection from Remote Sensing Images Using Selective State Space Model](https://arxiv.org/abs/2506.18006)
**中文标题：OSDMamba：基于选择性状态空间模型的遥感图像溢油检测增强方法**

*Shuaiyu Chen,Fu Wang,Peng Ren,Chunbo Luo,Zeyu Fu*

主要分类: cs.CV

摘要简述: 本文提出OSDMamba，一种基于Mamba的架构，用于遥感图像中的溢油检测，通过选择性扫描机制和多尺度特征融合，显著提升了检测精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于CNN的溢油检测方法因感受野有限和全局上下文信息捕捉不足，难以检测小面积溢油区域，且标记样本稀缺和类别不平衡问题进一步降低了检测准确性。

研究方法: 提出OSDMamba架构，利用Mamba的选择性扫描机制扩展模型感受野，同时设计非对称解码器结合ConvSSM和深度监督，增强多尺度特征融合和对少数类样本的敏感性。

研究结果: 实验表明，OSDMamba在两个公开数据集上的溢油检测性能分别提升了8.9%和11.8%，达到最先进水平。

研究结论: OSDMamba通过结合Mamba的选择性机制和多尺度特征融合，有效解决了溢油检测中的小区域检测和类别不平衡问题，为遥感图像分析提供了新思路。

中文摘要: 语义分割常用于遥感图像中的溢油检测（OSD），但标记样本稀缺和类别不平衡问题显著降低了检测精度。此外，现有基于卷积神经网络（CNN）的方法因感受野有限和全局上下文信息捕捉不足，难以检测小面积溢油区域。本研究探索了状态空间模型（SSMs），尤其是Mamba在解决这些问题中的潜力，并基于其在视觉应用中的成功，提出了首个专为溢油检测设计的Mamba架构OSDMamba。OSDMamba利用Mamba的选择性扫描机制有效扩展模型感受野，同时保留关键细节。此外，我们设计了结合ConvSSM和深度监督的非对称解码器，以增强多尺度特征融合，提升模型对少数类样本的敏感性。实验结果表明，OSDMamba在两个公开数据集上的溢油检测性能分别提升了8.9%和11.8%，达到最先进水平。

</details>


### [154] [On the Robustness of Human-Object Interaction Detection against Distribution Shift](https://arxiv.org/abs/2506.18021)
**中文标题：人-物交互检测在分布偏移下的鲁棒性研究**

*Chi Xie,Shuang Liang,Jie Li,Feng Zhu,Rui Zhao,Yichen Wei,Shengjie Zhao*

主要分类: cs.CV

摘要简述: 本文研究了人-物交互（HOI）检测模型在分布偏移下的鲁棒性，提出了首个自动化评估基准，分析了40多种现有模型的不足，并提出两种简单有效的方法提升鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管人-物交互检测近年来取得显著进展，但现有研究多基于理想图像和自然分布，忽略了实际场景中的分布偏移问题，限制了其实际应用。本文旨在解决这一问题。

研究方法: 1. 提出首个自动化评估基准用于HOI检测的鲁棒性测试；2. 评估40多种现有模型并分析其不足；3. 提出跨域数据增强结合mixup的方法；4. 引入基于冻结视觉基础模型的特征融合策略。

研究结果: 实验表明，所提方法显著提升了多种HOI检测模型的鲁棒性，且在标准基准测试中也有额外收益。

研究结论: 本文通过系统性分析和简单方法，显著提升了HOI检测模型在分布偏移下的鲁棒性，为实际应用提供了有力支持。

中文摘要: 近年来，人-物交互（HOI）检测取得了显著进展。然而，现有研究多集中于理想图像和自然分布的标准场景，忽略了实际应用中不可避免的分布偏移问题，限制了HOI检测的实际适用性。本文通过基准测试、分析和增强HOI检测模型在多种分布偏移下的鲁棒性，探讨了这一问题。首先，我们提出了一种自动化方法，创建了首个HOI检测鲁棒性评估基准。随后，评估了40多种现有HOI检测模型，揭示了其不足，分析了不同框架的特点，并讨论了HOI任务中鲁棒性与其他任务的差异。基于这些分析，我们提出通过以下两种方法提升HOI检测的鲁棒性：（1）结合mixup的跨域数据增强；（2）基于冻结视觉基础模型的特征融合策略。这两种方法简单、即插即用，适用于多种模型。实验结果表明，所提方法显著提升了多种模型的鲁棒性，且在标准基准测试中也有额外收益。数据集和代码将公开发布。

</details>


### [155] [PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding](https://arxiv.org/abs/2506.18023)
**中文标题：PP-DocBee2：基于高效数据的多模态文档理解基线改进**

*Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu*

主要分类: cs.CV

摘要简述: PP-DocBee2是PP-DocBee的升级版，通过提升合成数据质量、优化视觉特征融合策略和改进推理方法，显著提升了多模态文档理解性能，并在中文商业文档任务中实现了11.4%的性能提升和73.0%的推理延迟降低。


<details>
  <summary>详细信息</summary>
研究动机: PP-DocBee2旨在解决其前身在多模态文档理解任务中的局限性，通过技术改进提升模型性能，尤其是在中文商业文档处理方面。

研究方法: PP-DocBee2采用大规模多模态预训练模型评估数据质量，通过统计标准过滤异常数据；同时分解ViT层并应用新的特征融合策略，增强复杂推理能力。

研究结果: 在内部基准测试中，PP-DocBee2在中文商业文档任务上性能提升11.4%，推理延迟降低73.0%。

研究结论: PP-DocBee2通过数据质量优化和特征融合策略改进，显著提升了多模态文档理解的性能和效率。

中文摘要: 本报告介绍了PP-DocBee2，这是PP-DocBee的升级版本，旨在提升多模态文档理解能力。基于大规模多模态模型架构，PP-DocBee2通过关键技术改进解决了其前身的局限性，包括提升合成数据质量、优化视觉特征融合策略和改进推理方法。这些改进在中文商业文档的内部基准测试中实现了11.4%的性能提升，并将推理延迟降低了73.0%。我们工作的一个关键创新是为多模态文档任务设计的数据质量优化策略。通过使用大规模多模态预训练模型评估数据，并应用新的统计标准过滤异常值，确保高质量的训练数据。受多模态模型中未充分利用的中间特征的启发，我们通过分解ViT层并应用新的特征融合策略，增强了复杂推理能力。源代码和预训练模型可在https://github.com/PaddlePaddle/PaddleMIX获取。

</details>


### [156] [MiCo: Multiple Instance Learning with Context-Aware Clustering for Whole Slide Image Analysis](https://arxiv.org/abs/2506.18028)
**中文标题：MiCo：基于上下文感知聚类的多实例学习用于全切片图像分析**

*Junjian Li,Hulin Kuang,Jin Liu,Hailin Yue,Mengshen He,Jianxin Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MiCo的新型多实例学习框架，通过上下文感知聚类增强全切片图像（WSI）分析中的跨区域组织内相关性和组织间语义关联，显著提升了癌症诊断和预后的性能。


<details>
  <summary>详细信息</summary>
研究动机: 全切片图像（WSI）在癌症诊断和预后中具有重要作用，但其空间异质性导致形态相似的组织可能分散在远距离解剖区域。传统的多实例学习方法难以有效建模这些分散的组织分布和跨区域空间交互，因此需要一种新方法来增强组织内和跨组织的语义关联。

研究方法: MiCo框架通过聚类提取具有判别性的形态模式，并以聚类中心作为语义锚点。通过Cluster Route模块动态连接远距离区域的相同组织类型实例，增强跨区域组织内相关性。Cluster Reducer模块则整合冗余锚点，加强不同语义组之间的信息交换，消除语义碎片化。

研究结果: 在九个大规模公共癌症数据集上的实验表明，MiCo在两项挑战性任务中表现优异，显著优于现有最先进方法。

研究结论: MiCo通过上下文感知聚类有效解决了WSI分析中的空间异质性问题，增强了组织内和跨组织的语义关联，为癌症诊断和预后提供了更强大的工具。

中文摘要: 多实例学习（MIL）在组织病理学全切片图像（WSI）分析中显示出巨大的潜力，可用于癌症诊断和预后。然而，WSI固有的空间异质性带来了关键挑战，因为形态相似的组织类型通常分散在远距离的解剖区域。传统的MIL方法难以有效建模这些分散的组织分布和跨区域空间交互。为了解决这些局限性，我们提出了一种新型的多实例学习框架MiCo，通过上下文感知聚类增强WSI中的跨区域组织内相关性和组织间语义关联。MiCo首先通过聚类提取具有判别性的形态模式，并以聚类中心作为语义锚点。为了增强跨区域组织内相关性，MiCo采用Cluster Route模块，通过特征相似性动态连接远距离区域的相同组织类型实例。这些语义锚点作为上下文枢纽，传播语义关系以优化实例级表示。为了消除语义碎片化并加强组织间语义关联，MiCo集成了Cluster Reducer模块，整合冗余锚点同时增强不同语义组之间的信息交换。在九个大规模公共癌症数据集上的两项挑战性任务中，MiCo表现出卓越的性能，显著优于现有最先进方法。代码可在https://github.com/junjianli106/MiCo获取。

</details>


### [157] [Pre-Trained LLM is a Semantic-Aware and Generalizable Segmentation Booster](https://arxiv.org/abs/2506.18034)
**中文标题：预训练LLM是语义感知且通用性强的分割增强器**

*Fenghe Tang,Wenxin Ma,Zhiyang He,Xiaodong Tao,Zihang Jiang,S. Kevin Zhou*

主要分类: cs.CV

摘要简述: 本文发现预训练的大型语言模型（LLM）层可以处理视觉标记，用于医学图像分割任务，提出了一种简单混合结构LLM4Seg，显著提升分割性能且参数增加极少。


<details>
  <summary>详细信息</summary>
研究动机: 探索预训练LLM在视觉任务中的潜力，尤其是如何利用其语义理解能力提升医学图像分割的全局和局部建模能力。

研究方法: 提出LLM4Seg，将预训练且冻结的LLM层嵌入CNN编码器-解码器分割框架中，通过LLM处理视觉标记以增强语义感知。

研究结果: 实验表明，LLM4Seg在超声、皮肤镜、息肉镜和CT等多种模态中显著提升分割性能，且对不同LLM（如LLaMA和DeepSeek）均有效。

研究结论: 预训练LLM的语义感知能力可有效迁移至视觉分割任务，为医学图像分割提供了一种通用且高效的增强方法。

中文摘要: 随着大型语言模型（LLM）在自然语言处理中的发展，本文发现一个有趣的现象：冻结的预训练LLM层可以处理视觉标记，用于医学图像分割任务。具体而言，我们提出了一种简单的混合结构LLM4Seg，将预训练且冻结的LLM层嵌入CNN编码器-解码器分割框架中。令人惊讶的是，这种设计在超声、皮肤镜、息肉镜和CT等多种模态中显著提升了分割性能，且仅需极少的可训练参数。深入分析表明，LLM的语义感知能力可以迁移至分割任务，既增强了全局理解，又优化了局部建模能力。这一改进在不同LLM（如LLaMA和DeepSeek）中均表现出鲁棒性。

</details>


### [158] [CmFNet: Cross-modal Fusion Network for Weakly-supervised Segmentation of Medical Images](https://arxiv.org/abs/2506.18042)
**中文标题：CmFNet：用于医学图像弱监督分割的跨模态融合网络**

*Dongdong Meng,Sheng Li,Hao Wu,Suqing Tian,Wenjun Ma,Guoping Wang,Xueqing Yan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CmFNet的新型3D弱监督跨模态医学图像分割方法，通过多模态特征融合和混合监督学习策略，显著提升了分割性能，并在实验中优于现有弱监督和全监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割通常需要高质量密集标注，但标注成本高且耗时。弱监督学习利用稀疏标注提供了一种高效替代方案，但稀疏标注易导致性能下降和过拟合。本文旨在解决这些问题。

研究方法: CmFNet包含三个主要组件：模态特定特征学习网络、跨模态特征学习网络和混合监督学习策略。通过多模态特征融合和多种监督方式（如涂鸦监督、模态内正则化和模态间一致性），提升分割性能并减少过拟合。

研究结果: 在临床跨模态鼻咽癌数据集（CT和MR）和公开的CT全腹部器官数据集（WORD）上，CmFNet优于现有弱监督方法，甚至在全标注情况下也优于全监督方法。

研究结论: CmFNet通过多模态特征融合和混合监督策略，显著提升了弱监督医学图像分割的性能，为临床治疗提供了有力支持。

中文摘要: 准确的自动医学图像分割依赖于高质量密集标注，但标注成本高且耗时。弱监督学习通过利用稀疏和粗糙标注提供了一种高效替代方案，但稀疏标注易导致分割性能下降和过拟合。为解决这些问题，我们提出了CmFNet，一种新型3D弱监督跨模态医学图像分割方法。CmFNet包含三个主要组件：模态特定特征学习网络、跨模态特征学习网络和混合监督学习策略。模态特定和跨模态特征学习网络有效整合多模态图像的互补信息，增强跨模态共享特征以提升分割性能。此外，混合监督学习策略通过涂鸦监督、模态内正则化和模态间一致性指导分割，建模空间和上下文关系，同时促进特征对齐。我们的方法有效减少了过拟合，提供了稳健的分割结果，在挑战性小肿瘤区域和常见解剖结构分割中表现优异。在临床跨模态鼻咽癌数据集（CT和MR）和公开的CT全腹部器官数据集（WORD）上的大量实验表明，我们的方法优于现有弱监督方法，甚至在全标注情况下也优于全监督方法。我们的方法可为临床治疗提供便利，并惠及物理学家、放射科医生、病理学家和肿瘤学家等多种专业人员。

</details>


### [159] [CLGRPO: Reasoning Ability Enhancement for Small VLMs](https://arxiv.org/abs/2506.18048)
**中文标题：CLGRPO：增强小规模视觉语言模型的推理能力**

*Fanyi Wang,Binzhi Dong,Haotian Hu,Jinjin Xu,Zhiwang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种增量训练策略CLGRPO，通过自监督构建思维链数据和多阶段优化，显著提升了小规模视觉语言模型（SVLM）的推理能力，使其性能接近更大规模模型。


<details>
  <summary>详细信息</summary>
研究动机: 小规模视觉语言模型（SVLM）因参数限制推理能力较弱，但其低成本和低功耗具有高商业价值。本文旨在通过后训练优化提升SVLM的推理能力。

研究方法: 1. 自监督构建思维链（COT）数据；2. 分四阶段增量训练：阶段1注入领域知识（SFT），阶段2对齐数据格式（GRPO），阶段3增强推理能力（GRPO+精度奖励），阶段4限制训练空间（CLGRPO）。

研究结果: 在EMOSet-118K数据集上，1B SVLM的准确率提升2.77，召回率提升0.69，性能接近8B模型。

研究结论: CLGRPO方法有效提升了SVLM的推理能力，验证了增量训练策略的可行性，为小规模模型的商业化应用提供了新思路。

中文摘要: 小规模视觉语言模型（SVLM）通常指参数规模不超过2B的模型，其低成本和低功耗特性具有高商业价值。然而，其推理能力受限于参数规模。为解决这一问题，本文提出了一种后训练优化范式——增量训练策略，以提升SVLM的推理能力。首先，我们构建了一个自监督思维链（COT）数据生成系统，利用多个参数规模≥7B的大规模视觉语言模型（LVLM）将原始数据转化为COT数据。增量训练策略分为四个阶段：阶段1通过监督微调（SFT）在COT数据上注入领域知识；阶段2通过少量格式奖励约束的组相对策略优化（GRPO）对齐COT数据格式；阶段3通过格式和精度奖励双重约束的GRPO训练增强推理能力；阶段4提出ClipLow GRPO（CLGRPO）限制训练空间，解决SVLM容量有限和复杂模式捕捉能力弱的问题。在抽象语义识别数据集EMOSet-118K上的对比和消融实验表明，该方法显著提升了1B SVLM的推理能力，准确率提升2.77，召回率提升0.69，性能接近8B模型。

</details>


### [160] [Deep Supervised LSTM for 3D morphology estimation from Multi-View RGB Images of Wheat Spikes](https://arxiv.org/abs/2506.18060)
**中文标题：基于深度监督LSTM的小麦穗三维形态多视角RGB图像估计**

*Olivia Zumsteg,Nico Graf,Aaron Haeusler,Norbert Kirchgessner,Nicola Storni,Lukas Roth,Andreas Hund*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度监督LSTM的神经网络方法，用于从多视角RGB图像中估计小麦穗的三维形态，通过结合DINOv2和LSTM网络，显著提升了体积估计的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 由于二维RGB图像在田间条件下存在深度信息丢失、投影失真和遮挡等问题，准确估计小麦穗的三维形态具有挑战性。本文旨在开发一种非破坏性的体积估计方法。

研究方法: 采用了一种结合自监督Vision Transformer（DINOv2）和单向LSTM网络的迁移学习框架，通过深度监督学习更鲁棒的中间表示，提升模型在不同评估序列中的泛化能力。

研究结果: 在六视角室内图像上，模型的平均绝对百分比误差（MAPE）为6.46%，优于基于面积的投影（9.36%）和几何重建（13.98%）基线。在单图像田间数据上微调后，MAPE为10.82%。

研究结论: 深度学习模型在复杂几何形状（如小麦穗）的体积预测中表现优于传统几何方法，且通过域适应能力在田间条件下仍保持较高准确性。

中文摘要: 从二维RGB图像中估计三维形态特征存在深度信息丢失、投影失真和遮挡等固有挑战。本文探索了多种非破坏性小麦穗体积估计方法，使用RGB图像序列和结构光3D扫描作为真实参考。针对穗的复杂几何形状，我们提出了一种神经网络方法，结合自监督Vision Transformer（DINOv2）和单向LSTM网络，通过深度监督学习更鲁棒的中间表示，提升模型泛化能力。与基于面积的投影和几何重建基线相比，我们的模型在六视角室内图像上的平均绝对百分比误差（MAPE）为6.46%，显著优于基线（9.36%和13.98%）。在单图像田间数据上微调后，MAPE为10.82%。结果表明，物体形状对体积预测准确性有显著影响，复杂几何形状（如小麦穗）对几何方法的挑战更大，而我们的深度学习方法表现更优。

</details>


### [161] [Training-free Test-time Improvement for Explainable Medical Image Classification](https://arxiv.org/abs/2506.18070)
**中文标题：无需训练的可解释医学图像分类测试时改进方法**

*Hangzhou He,Jiachen Tang,Lei Zhu,Kaiwen Li,Yanye Lu*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的测试时改进方法，用于提升可解释医学图像分类模型的跨域性能，通过屏蔽混淆概念和增强判别性概念，仅需少量带图像级标签的新数据。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分类中，概念瓶颈模型（CBMs）因其可解释性受到关注，但在新环境中部署时，成像协议和染色方法的差异可能导致概念级偏移。此外，CBMs训练需要专家标注的概念标签，成本高昂。因此，需要一种无需额外训练的方法来提升跨域性能。

研究方法: 提出了一种无需训练的混淆概念识别策略，仅需少量带图像级标签的新数据（如每类4张图像），通过屏蔽误激活的混淆概念和增强未充分激活的判别性概念，提升模型在新环境中的表现。

研究结果: 在皮肤和白细胞图像上的实验验证了该方法的有效性，能够在不牺牲源域准确性的情况下提升跨域性能。

研究结论: 该方法为可解释医学图像分类提供了一种高效且低成本的跨域性能改进方案，适用于实际临床场景。

中文摘要: 基于深度学习的医学图像分类技术在医学图像分析中迅速发展，开发准确且可信赖的模型以高效部署于多样化临床场景至关重要。概念瓶颈模型（CBMs）通过先预测一组可解释概念再进行分类，逐渐被用于可解释医学图像分类。然而，CBMs的可解释性在新环境中部署时带来了新挑战。成像协议和染色方法的差异可能导致概念级偏移，如颜色分布和尺度的变化。此外，由于CBM训练需要显式的概念标注，仅使用图像级标签微调模型可能损害概念预测的准确性和忠实性——这在医学领域中获取专家标注概念标签的高成本下尤为关键。为解决这些问题，我们提出了一种无需训练的混淆概念识别策略。通过利用少量仅带图像级标签的新数据（如每类4张图像），我们的方法通过屏蔽误激活的混淆概念和增强未充分激活的判别性概念，在不牺牲源域准确性的情况下提升跨域性能。该方法在皮肤和白细胞图像上的有效性得到了验证。代码已开源：https://github.com/riverback/TF-TTI-XMed。

</details>


### [162] [MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering](https://arxiv.org/abs/2506.18071)
**中文标题：MUPA：面向基于视频问答的多路径代理推理方法**

*Jisheng Dang,Huilin Song,Junbin Xiao,Bimei Wang,Han Peng,Haoxuan Li,Xun Yang,Meng Wang,Tat-Seng Chua*

主要分类: cs.CV

摘要简述: MUPA是一种多路径代理推理方法，用于解决基于视频的问答任务，通过结合视频定位、问答、答案反思和聚合，显著提高了答案的准确性和视觉证据的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态模型在基于视频的问答任务中，往往依赖语言先验和虚假关联，导致预测结果缺乏视觉证据支持。MUPA旨在通过多路径代理推理方法解决这一问题。

研究方法: MUPA采用多路径代理推理框架，包括视频定位代理、问答代理、答案反思代理和结果聚合代理。通过三种不同的推理路径和反思代理的评估，实现了问答和视觉证据的一致性。

研究结果: MUPA在仅使用2B参数的情况下，性能优于所有7B规模的竞争对手。当扩展到7B参数时，MUPA在NExT-GQA和DeVE-QA数据集上分别达到了30.3%和47.4%的Acc@GQA，创下新纪录。

研究结论: MUPA通过多路径代理推理方法，显著提升了基于视频的问答任务的视觉证据可靠性和答案准确性，为可信赖的视频-语言理解提供了有效解决方案。

中文摘要: 基于视频的问答任务（Grounded VideoQA）要求将文本答案与明确的视觉证据对齐。然而，现代多模态模型通常依赖语言先验和虚假关联，导致预测结果缺乏视觉证据支持。本文提出MUPA，一种协作式的多路径代理方法，通过统一视频定位、问答、答案反思和聚合来解决Grounded VideoQA任务。MUPA设计了三种不同的推理路径，结合定位代理和问答代理的交互，并引入反思代理来评估和聚合多路径结果，从而实现一致的问答和视觉证据对齐。这一设计显著提高了视觉证据的可靠性，同时未牺牲答案准确性。尽管仅使用2B参数，我们的方法性能优于所有7B规模的竞争对手。当扩展到7B参数时，MUPA在NExT-GQA和DeVE-QA数据集上分别达到30.3%和47.4%的Acc@GQA，创下新纪录，证明了MUPA在可信赖的视频-语言理解中的有效性。代码已开源：https://github.com/longmalongma/MUPA。

</details>


### [163] [TEM^3-Learning: Time-Efficient Multimodal Multi-Task Learning for Advanced Assistive Driving](https://arxiv.org/abs/2506.18084)
**中文标题：TEM^3-Learning：面向高级辅助驾驶的高效多模态多任务学习**

*Wenzhuo Liu,Yicheng Qiao,Zhen Wang,Qiannan Guo,Zilong Chen,Meihua Zhou,Xinran Li,Letian Wang,Zhiwei Li,Huaping Liu,Wenshuo Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为TEM^3-Learning的高效多模态多任务学习框架，通过两阶段架构联合优化驾驶员情绪识别、行为识别、交通场景识别和车辆行为识别，实现了轻量级模型和高实时性。


<details>
  <summary>详细信息</summary>
研究动机: 现有多任务学习方法存在单模态限制和低效架构问题，无法满足辅助驾驶场景的全面理解和实时部署需求。

研究方法: 提出两阶段架构：1) MTS-Mamba子网络，通过前向-后向时间扫描和全局-局部空间注意力提取多视角时空特征；2) MGMI模块，通过任务特定门控机制自适应融合多模态特征，缓解负迁移问题。

研究结果: 在AIDE数据集上，模型以少于600万参数实现所有四项任务的最高精度，推理速度达142.32 FPS。

研究结论: TEM^3-Learning通过高效多模态特征提取和任务自适应融合，显著提升了辅助驾驶多任务学习的性能和实时性。

中文摘要: 多任务学习（MTL）通过共享表征探索任务间相关性，可推动辅助驾驶发展。然而，现有方法存在两大局限：单模态限制阻碍场景全面理解，低效架构影响实时部署。本文提出TEM^3-Learning（高效多模态多任务学习），通过两阶段架构联合优化驾驶员情绪识别、行为识别、交通场景识别及车辆行为识别。首阶段为基于Mamba的多视角时空特征提取子网络（MTS-Mamba），引入前向-后向时间扫描机制和全局-局部空间注意力，高效提取多视角序列图像的低成本时空特征。次阶段为基于MTL的门控多模态特征整合器（MGMI），利用任务特定多门控模块自适应突出各任务最相关模态特征，有效缓解MTL中的负迁移问题。在AIDE数据集上的评估表明，所提模型以轻量级架构（参数少于600万）实现四项任务的最高精度，推理速度达142.32 FPS。消融实验进一步验证了框架及各模块的有效性。代码发布于https://github.com/Wenzhuo-Liu/TEM3-Learning。

</details>


### [164] [ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation](https://arxiv.org/abs/2506.18095)
**中文标题：ShareGPT-4o-Image：将多模态模型与GPT-4o级图像生成对齐**

*Junying Chen,Zhenyang Cai,Pengcheng Chen,Shunian Chen,Ke Ji,Xidong Wang,Yunjin Yang,Benyou Wang*

主要分类: cs.CV

摘要简述: 本文介绍了ShareGPT-4o-Image数据集和Janus-4o模型，旨在通过开源数据和模型推动多模态图像生成的研究，实现与GPT-4o相当的图像生成能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态生成模型（如GPT-4o-Image）多为专有且不开放，限制了研究的发展。本文希望通过开源数据集和模型，推动多模态图像生成的开放研究。

研究方法: 使用GPT-4o生成45K文本到图像和46K文本加图像到图像的数据集ShareGPT-4o-Image，并基于此训练Janus-4o模型，支持文本到图像和文本加图像到图像的生成。

研究结果: Janus-4o在文本到图像生成上显著优于前代Janus-Pro，并首次支持文本加图像到图像的生成，仅用91K合成样本和6小时训练即表现出色。

研究结论: ShareGPT-4o-Image和Janus-4o的开源将促进真实感、指令对齐的图像生成研究。

中文摘要: 近年来，多模态生成模型的进展实现了真实感、指令对齐的图像生成，但领先系统如GPT-4o-Image仍为专有且不可访问。为普及这些能力，我们提出ShareGPT-4o-Image，首个包含45K文本到图像和46K文本加图像到图像的数据集，均通过GPT-4o的图像生成能力合成，以提取其先进的图像生成能力。利用此数据集，我们开发了Janus-4o，一种多模态大语言模型，支持文本到图像和文本加图像到图像的生成。Janus-4o不仅在文本到图像生成上显著优于前代Janus-Pro，还首次支持文本加图像到图像的生成。值得注意的是，它仅用91K合成样本和6小时训练（基于8台A800-GPU机器）即实现了出色的文本加图像到图像生成性能。我们希望ShareGPT-4o-Image和Janus-4o的发布能推动真实感、指令对齐图像生成的开放研究。

</details>


### [165] [Enhancing VICReg: Random-Walk Pairing for Improved Generalization and Better Global Semantics Capturing](https://arxiv.org/abs/2506.18104)
**中文标题：增强VICReg：通过随机游走配对提升泛化能力与全局语义捕捉**

*Idan Simai,Ronen Talmon,Uri Shaham*

主要分类: cs.CV

摘要简述: 本文提出SAG-VICReg方法，通过改进VICReg的泛化能力和全局语义捕捉能力，解决了其在未见数据上表现不佳的问题。实验表明，该方法在全局语义理解和局部评估指标上均优于现有自监督学习方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究发现VICReg方法在训练数据上过度依赖，可能导致对未见数据的泛化能力不足。本文旨在通过改进VICReg，提升其全局语义捕捉能力和泛化性能。

研究方法: 提出SAG-VICReg方法，结合新的训练技术，增强VICReg的全局语义捕捉能力。同时，提出一种无需标签的新评估指标，用于衡量嵌入的全局数据结构。

研究结果: 实验显示，SAG-VICReg在全局语义理解和局部评估指标上表现优异，优于现有自监督学习方法。新评估指标有效补充了标准评估方法。

研究结论: SAG-VICReg显著提升了VICReg的泛化能力和全局语义捕捉能力，为自监督学习提供了更优的解决方案。

中文摘要: 本文认为，从谱嵌入的角度分析VICReg（一种流行的自监督学习方法）揭示了其潜在不足：由于对训练数据的过度依赖，可能在未见数据上泛化能力不足。这引发了对该方法在训练集外数据上生成有意义表示能力的进一步探讨。为此，我们研究了这一问题，并提出了SAG-VICReg（稳定且可泛化的VICReg），该方法在VICReg基础上结合了新的训练技术，提升了模型捕捉数据全局语义的能力和泛化性能。实验表明，SAG-VICReg有效解决了泛化问题，并在性能上匹配或超越了多种先进的自监督学习方法。值得注意的是，该方法在评估全局语义理解的指标上表现优异，同时在局部评估指标上保持竞争力。此外，我们提出了一种新的独立评估指标，用于衡量嵌入的全局数据结构，无需标签即可补充标准评估方法——这在标注数据稀缺或不可用时尤为重要。

</details>


### [166] [Targeted False Positive Synthesis via Detector-guided Adversarial Diffusion Attacker for Robust Polyp Detection](https://arxiv.org/abs/2506.18134)
**中文标题：基于检测器引导的对抗性扩散攻击器的靶向假阳性合成用于鲁棒性息肉检测**

*Quan Zhou,Gan Luo,Qiang Hu,Qingyong Zhang,Jinhua Zhang,Yinjiao Tian,Qiang Li,Zhiwei Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种对抗性扩散框架（DADA），用于合成高价值的假阳性样本，以增强结肠息肉检测模型的鲁棒性。通过区域噪声匹配策略和检测器引导的对抗性扩散攻击模块，该方法显著提升了检测器的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的结肠息肉检测模型受限于数据规模和多样性，尤其是假阳性样本的缺乏。生成模型虽然可用于数据增强，但当前方法主要关注息肉多样性，忽略了假阳性问题。本文旨在填补这一空白，通过合成高价值的假阳性样本提升检测器的鲁棒性。

研究方法: 1. 设计区域噪声匹配策略，利用息肉检测数据集构建负样本合成空间，训练专注于背景模式的扩散模型。2. 提出检测器引导的对抗性扩散攻击模块（DADA），通过干扰合成过程生成高价值的假阳性样本。

研究结果: 在公开和内部数据集上的实验表明，该方法显著优于现有技术，合成的数据使检测器的F1分数分别提高了至少2.6%和2.7%。

研究结论: 本文首次将对抗性扩散应用于病灶检测，为靶向假阳性合成开辟了新范式，有望提升结肠癌筛查的临床可靠性。

中文摘要: 结肠息肉检测对结直肠癌筛查至关重要，但现有模型受限于数据的规模和多样性。尽管生成模型在数据增强方面表现出潜力，但现有方法主要关注增强息肉的多样性，往往忽略了假阳性这一关键问题。本文提出了一种对抗性扩散框架，用于合成高价值的假阳性样本。负样本背景的广泛变异性为假阳性合成带来了巨大挑战。为此，我们提出了两项创新：首先，设计了一种区域噪声匹配策略，利用息肉检测数据集构建负样本合成空间。该策略通过掩膜息肉区域训练负样本中心的扩散模型，确保模型专注于学习多样化的背景模式。其次，引入了检测器引导的对抗性扩散攻击模块（DADA），通过干扰负样本合成过程破坏预训练检测器的决策，引导负样本中心扩散模型生成高价值的、能混淆检测器的假阳性样本，而非低价值的普通背景。我们的方法是首次将对抗性扩散应用于病灶检测，为靶向假阳性合成建立了新范式，为结直肠癌筛查的临床应用提供了更可靠的基础。在公开和内部数据集上的大量实验结果验证了我们的方法优于当前最先进技术，合成的数据分别使检测器的F1分数提高了至少2.6%和2.7%。代码发布于https://github.com/Huster-Hq/DADA。

</details>


### [167] [See-in-Pairs: Reference Image-Guided Comparative Vision-Language Models for Medical Diagnosis](https://arxiv.org/abs/2506.18140)
**中文标题：See-in-Pairs：基于参考图像的医学视觉-语言对比模型**

*Ruinan Jin,Gexin Huang,Xinwei Shen,Qiong Zhang,Yan Shuo Tan,Xiaoxiao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种基于参考图像的医学视觉-语言模型（See-in-Pairs），通过引入健康对照或历史检查图像进行对比分析，显著提升了医学诊断的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像诊断中存在疾病与正常解剖结构相似及患者间差异大的问题，现有医学视觉-语言模型缺乏对比分析能力，而通用视觉-语言模型虽具备多图像对比能力但缺乏医学领域知识。本文旨在结合两者优势，提升诊断效果。

研究方法: 通过为通用视觉-语言模型提供查询图像和匹配的参考图像，并结合临床启发的对比提示，进行监督微调（SFT），以增强其对比分析能力。

研究结果: 实验表明，该方法在多个医学视觉问答（VQA）任务中显著优于单图像基线模型，尤其是在监督微调后表现更优。

研究结论: 研究证明了对比分析在医学诊断中的临床价值，提出了利用参考图像的新策略，并通过实验验证了其有效性。

中文摘要: 医学影像诊断因疾病与正常解剖结构相似及患者间差异大而具有固有挑战。临床医生通常通过对比健康对照或历史检查图像来识别细微但关键的异常。然而，现有医学视觉-语言模型（VLMs）主要关注单图像或单序列分析，缺乏显式对比机制。而通用VLMs虽具备多图像对比能力，却缺乏识别临床细微差异的医学知识。本文旨在通过探索临床启发的对比分析，利用参考图像提升诊断准确性。实验表明，为通用VLMs提供查询图像和匹配的参考图像，并结合临床对比提示，显著优于单图像基线，尤其是在监督微调（SFT）后。研究贡献包括：强调对比分析的临床价值，提出利用参考图像的新策略，通过实验验证其在医学视觉问答（VQA）任务中的性能提升，并为医学诊断中对比图像分析的有效性提供理论见解。

</details>


### [168] [Pattern-Based Phase-Separation of Tracer and Dispersed Phase Particles in Two-Phase Defocusing Particle Tracking Velocimetry](https://arxiv.org/abs/2506.18157)
**中文标题：基于模式的示踪与分散相粒子相分离在两相离焦粒子追踪测速中的应用**

*Christian Sax,Jochen Kriegseis*

主要分类: cs.CV

摘要简述: 本文研究了一种基于后处理的相分离方法，用于分散两相流中的离焦粒子追踪测速技术，通过单相机实现示踪粒子和分散相粒子的3D定位，利用卷积神经网络分类粒子图像，生成对抗网络辅助生成训练数据，实验验证了高精度分类能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法在分散两相流中难以实现示踪粒子和分散相粒子的区分，尤其是在波长、尺寸或相关性方法不适用的情况下。本文旨在提出一种基于图像模式差异的相分离方法，以解决这一问题。

研究方法: 通过分析离焦粒子图像的散射模式差异，训练卷积神经网络（如Faster R-CNN和YOLOv4）进行粒子检测和分类。使用生成对抗网络生成实验特定外观的自动标记训练数据。

研究结果: 在六个数据集（包括合成和真实两相流）上的实验表明，该方法具有高检测精度和分类准确率（95-100%），即使在领域偏移下也表现稳健。

研究结论: 该方法证实了卷积神经网络在分散两相离焦粒子追踪测速中实现稳健相分离的可行性，尤其在传统方法不适用时具有优势。

中文摘要: 本研究探讨了一种基于后处理的相分离方法在分散两相流离焦粒子追踪测速中的可行性。该方法通过单相机实现示踪粒子和分散相粒子的3D定位，利用离焦粒子图像的散射模式差异区分两相。训练卷积神经网络（如Faster R-CNN和YOLOv4）检测和分类粒子图像。为生成大规模标记训练数据，引入基于生成对抗网络的框架，生成更接近实验外观的自动标记数据。在六个数据集（包括合成两相流和真实单相及两相流）上的评估显示，该方法具有高检测精度和分类准确率（95-100%），即使在领域偏移下也表现稳健。结果证实了卷积神经网络在分散两相离焦粒子追踪测速中实现稳健相分离的可行性，尤其在传统波长、尺寸或相关性方法不适用时具有优势。

</details>


### [169] [CDG-MAE: Learning Correspondences from Diffusion Generated Views](https://arxiv.org/abs/2506.18164)
**中文标题：CDG-MAE：从扩散生成视图中学习对应关系**

*Varun Belagali,Pierre Marza,Srikar Yellapragada,Zilinghan Li,Tarak Nath Nandi,Ravi K Madduri,Joel Saltz,Stergios Christodoulidis,Maria Vakalopoulou,Dimitris Samaras*

主要分类: cs.CV

摘要简述: 本文提出CDG-MAE，一种基于MAE的自监督方法，利用扩散模型生成多样合成视图，显著提升密集对应学习性能。


<details>
  <summary>详细信息</summary>
研究动机: 密集对应学习依赖繁琐且不可扩展的人工标注，现有自监督方法因训练数据不足（视频数据集收集困难，图像裁剪缺乏姿态变化）而受限。

研究方法: CDG-MAE通过图像条件扩散模型生成多样合成视图，增强训练信号；提出多锚点策略调节任务难度，并量化评估生成图像的局部和全局一致性。

研究结果: CDG-MAE显著优于仅依赖图像的MAE方法，大幅缩小与基于视频方法的性能差距。

研究结论: CDG-MAE通过合成视图和多锚点策略有效解决了训练数据不足问题，为密集对应学习提供了高效解决方案。

中文摘要: 学习密集对应关系对于视频标签传播等应用至关重要，但依赖繁琐且不可扩展的人工标注。自监督方法通过跨视图借口任务（如掩码自编码器）解决这一问题，但获取有效训练数据仍具挑战性——收集多样视频数据集困难且成本高，而简单图像裁剪缺乏必要的姿态变化。本文提出CDG-MAE，一种基于MAE的新型自监督方法，利用图像条件扩散模型从静态图像生成多样合成视图。这些生成视图在姿态和视角上表现出显著变化，提供了丰富的训练信号，克服了视频和裁剪锚点的局限性。我们提出了一种量化方法评估生成图像的局部和全局一致性，并讨论了其在跨视图自监督预训练中的应用。此外，我们将标准的单锚点MAE设置扩展为多锚点策略，以有效调节借口任务的难度。CDG-MAE显著优于仅依赖图像的最先进MAE方法，并大幅缩小了与基于视频方法的性能差距。

</details>


### [170] [STACT-Time: Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification](https://arxiv.org/abs/2506.18172)
**中文标题：STACT-Time：基于时空交叉注意力的甲状腺超声动态视频时间序列分类**

*Irsyad Adam,Tengyue Zhang,Shrayes Raman,Zhuyu Qiu,Brandon Taraku,Hexiang Feng,Sile Wang,Ashwath Radhachandran,Shreeram Athreya,Vedrana Ivezic,Peipei Ping,Corey Arnold,William Speier*

主要分类: cs.CV

摘要简述: 本文提出了一种名为STACT-Time的模型，通过时空交叉注意力机制，利用甲状腺超声动态视频的时空信息，结合分割掩模特征，显著提升了甲状腺结节恶性预测的准确性，减少了不必要的活检。


<details>
  <summary>详细信息</summary>
研究动机: 甲状腺癌是美国常见癌症之一，超声检查常发现甲状腺结节，但细针穿刺活检（FNA）对良性结节的不必要检查增加了患者负担。现有系统如TI-RADS受限于观察者间差异，而现有深度学习方法未能充分利用超声动态视频的时空信息。因此，本文旨在开发一种能有效利用时空上下文信息的模型，提升恶性预测准确性。

研究方法: 本文提出STACT-Time模型，结合超声动态视频的时空特征与预训练模型生成的分割掩模特征，通过自注意力和交叉注意力机制捕捉动态视频的时空上下文，并利用分割引导学习增强特征表示。

研究结果: 实验表明，STACT-Time模型在恶性预测中表现优异，交叉验证精确度为0.91（±0.02），F1分数为0.89（±0.02），显著优于现有方法，减少了良性结节的不必要活检。

研究结论: STACT-Time模型通过有效利用超声动态视频的时空信息，显著提升了甲状腺结节恶性预测的准确性，有望优化临床决策并改善患者预后。

中文摘要: 甲状腺癌是美国最常见的癌症之一。甲状腺结节通常通过超声（US）成像检测，部分需通过细针穿刺（FNA）活检进一步评估。尽管FNA有效，但常导致对良性结节的不必要活检，引发患者不适和焦虑。为此，美国放射学会开发了甲状腺成像报告与数据系统（TI-RADS）以减少良性活检，但其受限于观察者间差异。近期深度学习方法试图改进风险分层，但未能充分利用超声动态视频提供的丰富时空上下文信息，这些视频包含动态全局信息和多视角下的周围结构变化。本文提出STACT-Time模型，一种新型表征学习框架，将超声动态视频的成像特征与预训练模型自动生成的分割掩模特征相结合。通过自注意力和交叉注意力机制，模型捕捉超声动态视频的时空上下文，并通过分割引导学习增强特征表示。相比现有模型，STACT-Time显著提升了恶性预测能力，交叉验证精确度为0.91（±0.02），F1分数为0.89（±0.02）。通过减少良性结节的不必要活检并保持高恶性检测敏感性，该模型有望优化临床决策并改善患者预后。

</details>


### [171] [DExNet: Combining Observations of Domain Adapted Critics for Leaf Disease Classification with Limited Data](https://arxiv.org/abs/2506.18173)
**中文标题：DExNet：结合领域适应评论器的观察结果用于小样本叶片病害分类**

*Sabbir Ahmed,Md. Bakhtiar Hasan,Tasnim Ahmed,Md. Hasanul Kabir*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DExNet的小样本学习框架，通过结合多个预训练CNN架构的观察结果，解决了植物叶片病害分类中数据不足的问题，显著提升了分类准确率。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习模型在植物病害分类中需要大量数据，但在小样本场景下表现不佳。本文旨在解决这一问题，提出一种能够在有限数据下高效分类叶片病害的方法。

研究方法: DExNet框架首先从九个预训练的CNN架构中提取特征嵌入作为观察结果，并通过公开的叶片病害数据集进行领域适应。随后，通过特征融合块和Bi-LSTM分类器网络完成分类任务。

研究结果: 在PlantVillage数据集的番茄叶片图像分类任务中，DExNet在5-shot、10-shot和15-shot分类中分别达到89.06%、92.46%和94.07%的准确率，80-shot分类中达到98.09%的准确率，仅比现有最优方法低1.2%，同时减少了94.5%的训练数据需求。

研究结论: DExNet在小样本叶片病害分类任务中表现出色，显著降低了数据需求，并在多种场景下优于现有方法，为实际应用提供了高效解决方案。

中文摘要: 尽管基于深度学习的架构已广泛用于植物病害的检测和分类，但它们需要大规模数据集以学习通用特征并实现最优性能。这为模型在有限样本下分类叶片病害带来了挑战。本文提出了一种小样本学习框架——领域适应专家网络（DExNet），通过结合多个专家评论器的观察结果，弥补了训练数据不足的问题。该框架首先从九个预训练的CNN架构中提取特征嵌入作为观察结果，并使用与下游任务无重叠类别的公开叶片病害数据集进行领域适应。随后，观察结果通过特征融合块传递至由Bi-LSTM层组成的分类器网络。该框架在PlantVillage数据集的10类番茄叶片图像上进行了评估，分别在5-shot、10-shot和15-shot分类中实现了89.06%、92.46%和94.07%的准确率。此外，80-shot分类的准确率达到98.09±0.7%，仅比最优方法低1.2%，同时减少了94.5%的训练数据需求。该框架在实验室和实际场景中的单域、混合域和跨域条件下，均优于现有的小样本叶片病害分类方法。

</details>


### [172] [Multimodal Fusion SLAM with Fourier Attention](https://arxiv.org/abs/2506.18204)
**中文标题：基于傅里叶注意力的多模态融合SLAM**

*Youjie Zhou,Guofeng Mei,Yiming Wang,Yi Wan,Fabio Poiesi*

主要分类: cs.CV

摘要简述: FMF-SLAM是一种高效的多模态融合SLAM方法，利用快速傅里叶变换（FFT）提升算法效率，通过傅里叶自注意力和跨注意力机制提取RGB与深度信号特征，并在噪声、光照变化和黑暗环境中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于光流的视觉SLAM方法在噪声、光照变化和黑暗环境中表现不佳且计算资源消耗大，亟需一种高效的多模态融合方法以应对这些挑战。

研究方法: 提出FMF-SLAM，采用快速傅里叶变换（FFT）提升效率，引入傅里叶自注意力和跨注意力机制提取RGB与深度信号特征，并结合多尺度知识蒸馏增强多模态特征交互。

研究结果: 在TUM、TartanAir及真实数据集上验证，FMF-SLAM在噪声、光照变化和黑暗条件下表现优异，且具备实时性能。

研究结论: FMF-SLAM通过多模态融合和傅里叶注意力机制，显著提升了视觉SLAM在复杂环境中的性能和效率。

中文摘要: 视觉SLAM在噪声、光照变化和黑暗环境中尤为困难。基于学习的光流算法可以利用多模态应对这些挑战，但传统基于光流的视觉SLAM方法通常需要大量计算资源。为克服这一限制，我们提出FMF-SLAM，一种高效的多模态融合SLAM方法，利用快速傅里叶变换（FFT）提升算法效率。具体而言，我们引入了一种新颖的基于傅里叶的自注意力和跨注意力机制，从RGB和深度信号中提取特征。通过跨模态的多尺度知识蒸馏，进一步增强了多模态特征的交互。我们还通过将FMF-SLAM与安全机器人集成，融合全球定位模块GNSS-RTK和全局Bundle Adjustment，展示了其在真实场景中的实时性能。我们的方法在TUM、TartanAir及真实数据集上验证，在噪声、光照变化和黑暗条件下表现出最先进的性能。代码和数据集可在https://github.com/youjie-zhou/FMF-SLAM.git获取。

</details>


### [173] [Limitations of NERF with pre-trained Vision Features for Few-Shot 3D Reconstruction](https://arxiv.org/abs/2506.18208)
**中文标题：预训练视觉特征在少样本3D重建中对NeRF的限制**

*Ankit Sanjyal*

主要分类: cs.CV

摘要简述: 本文系统评估了DINO增强的NeRF模型在少样本3D重建中的表现，发现预训练视觉特征（如DINO）不仅未提升性能，反而表现更差，挑战了该领域的常见假设。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，NeRF在稀疏图像集的3D场景重建中取得突破，但预训练视觉特征（如DINO）在少样本场景中的有效性尚不明确。本文旨在验证这些特征的实际效果。

研究方法: 通过对比基线NeRF、冻结DINO特征、LoRA微调特征和多尺度特征融合，系统评估DINO增强NeRF模型在少样本3D重建中的表现。

研究结果: 实验显示，所有DINO变体的PSNR值（12.9-13.0）均低于基线NeRF（14.71），表明预训练特征可能引入有害偏差。

研究结论: 预训练视觉特征对少样本3D重建无益，甚至可能有害，建议采用更简单的几何一致性架构。

中文摘要: 神经辐射场（NeRF）通过稀疏图像集实现了3D场景重建的革命性进展。近期研究探索了整合预训练视觉特征（尤其是DINO）以增强少样本重建能力，但其有效性尚不明确，尤其在极端少样本场景中。本文系统评估了DINO增强的NeRF模型，对比了基线NeRF、冻结DINO特征、LoRA微调特征和多尺度特征融合。出乎意料的是，实验表明所有DINO变体表现均逊于基线NeRF，PSNR值约为12.9至13.0，而基线为14.71。这一反直觉的结果表明，预训练视觉特征可能对少样本3D重建无益，甚至引入有害偏差。我们分析了潜在原因，包括特征与任务不匹配、对有限数据的过拟合以及整合挑战。这些发现挑战了该领域的常见假设，并表明专注于几何一致性的更简单架构可能更适合少样本场景。

</details>


### [174] [Deep Learning-based Alignment Measurement in Knee Radiographs](https://arxiv.org/abs/2506.18209)
**中文标题：基于深度学习的膝关节X光片对线测量**

*Zhisen Hu,Dominic Cullen,Peter Thompson,David Johnson,Chang Bian,Aleksei Tiulpin,Timothy Cootes,Claudia Lindner*

主要分类: cs.CV

摘要简述: 本研究提出了一种基于深度学习的方法，用于在膝关节前后位X光片中自动定位膝关节解剖标志并测量膝关节对线（KA），与传统手动方法相比，具有高准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的膝关节对线测量方法依赖手动操作，耗时且需要长腿X光片。为了提高效率和准确性，本研究旨在开发一种自动化、高精度的深度学习方法来测量膝关节对线。

研究方法: 研究采用沙漏网络（hourglass networks）并结合注意力门结构，自动定位超过100个膝关节解剖标志，全面勾勒膝关节形状，并整合术前和术后图像的KA测量。

研究结果: 该方法在解剖胫股角测量中表现出高准确性，与临床真实测量结果的绝对平均差异约为1度。术前和术后自动测量与临床测量的一致性分别为优异（ICC=0.97）和良好（ICC=0.86）。

研究结论: 研究表明，膝关节对线评估可以通过深度学习实现高精度自动化，为数字化临床工作流程提供了新的可能性。

中文摘要: 膝关节对线（KA）的X光测量对于预测关节健康和全膝关节置换术后效果具有重要意义。传统的KA测量方法依赖手动操作，耗时且需要长腿X光片。本研究提出了一种基于深度学习的方法，通过自动定位膝关节解剖标志，在前后位膝关节X光片中测量KA。该方法基于沙漏网络，并结合注意力门结构以提高鲁棒性并聚焦关键解剖特征。据我们所知，这是首个基于深度学习的方法，能够定位超过100个膝关节解剖标志以全面勾勒膝关节形状，并整合术前和术后图像的KA测量。通过解剖胫股角，该方法提供了高度准确和可靠的解剖内翻/外翻KA测量，与临床真实测量结果的绝对平均差异约为1度。自动测量与临床测量的一致性在术前表现优异（组内相关系数ICC=0.97），术后表现良好（ICC=0.86）。我们的研究结果表明，KA评估可以实现高精度自动化，为数字化增强的临床工作流程创造了机会。

</details>


### [175] [Shape from Polarization of Thermal Emission and Reflection](https://arxiv.org/abs/2506.18217)
**中文标题：基于热发射与反射偏振的形状估计**

*Kazuma Kitazawa,Tsuyoshi Takatani*

主要分类: cs.CV

摘要简述: 本文提出了一种基于长波红外（LWIR）偏振的形状估计方法，通过结合发射和反射的偏振模型，解决了透明物体形状估计的难题，并开发了首个真实世界LWIR偏振数据集ThermoPol。


<details>
  <summary>详细信息</summary>
研究动机: 透明物体的形状估计因复杂的光传输而具有挑战性。传统方法在长波红外光谱中因忽略反射效应导致误差较大，因此需要一种更精确的偏振模型。

研究方法: 提出了一种偏振模型，明确考虑了发射和反射的联合效应，并采用基于模型和基于学习（神经网络）的方法估计表面法线。同时，建立了LWIR偏振成像过程的模型以消除系统误差。

研究结果: 通过实验验证，该方法在多种材料（包括可见光透明的材料）上表现出高精度和广泛适用性，并创建了首个真实世界LWIR偏振数据集ThermoPol。

研究结论: 本文的方法显著提升了长波红外偏振形状估计的准确性，为透明物体的形状估计提供了新的解决方案。

中文摘要: 透明物体的形状估计因其复杂的光传输特性而具有挑战性。为解决这一问题，我们利用长波红外（LWIR）光谱中的偏振形状估计（SfP）技术，其中大多数材料是不透明且具有发射性的。尽管已有少数研究探索了LWIR SfP，但这些尝试因偏振建模不足（尤其是忽略了反射效应）而存在显著误差。针对这一缺陷，我们提出了一种偏振模型，明确考虑了发射和反射的联合效应。基于该模型，我们不仅采用基于模型的方法估计表面法线，还通过神经网络在物理基础的合成数据集上训练实现了基于学习的方法。此外，我们建模了LWIR偏振成像过程，以消除固有的系统误差，确保偏振测量的准确性。我们实现了一个原型系统，并创建了首个真实世界LWIR SfP基准数据集ThermoPol。通过全面实验，我们证明了该方法在多种材料（包括可见光透明的材料）上的高精度和广泛适用性。

</details>


### [176] [Cross-Architecture Knowledge Distillation (KD) for Retinal Fundus Image Anomaly Detection on NVIDIA Jetson Nano](https://arxiv.org/abs/2506.18220)
**中文标题：跨架构知识蒸馏（KD）在NVIDIA Jetson Nano上的视网膜眼底图像异常检测**

*Berk Yilmaz,Aniruddh Aiyengar*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级的跨架构知识蒸馏方法，用于在资源有限的边缘设备（如NVIDIA Jetson Nano）上部署视网膜眼底图像异常检测模型。通过高容量ViT教师模型和CNN学生模型的结合，实现了诊断性能的高保留。


<details>
  <summary>详细信息</summary>
研究动机: 在资源有限的地区，早期准确诊断视网膜疾病至关重要，但缺乏可靠的诊断设备。本文旨在开发一种轻量级、可部署在边缘设备上的疾病分类器，以解决这一问题。

研究方法: 首先训练一个基于ViT的高容量教师模型，使用I-JEPA自监督学习预训练，分类眼底图像为四类（正常、糖尿病视网膜病变、青光眼和白内障）。然后通过跨架构知识蒸馏，将模型压缩为CNN学生模型，采用分区交叉注意力投影器、分组线性投影器和多视图鲁棒训练方法。

研究结果: 教师模型参数比学生模型多97.4%，学生模型分类准确率为89%，保留了教师模型93%的诊断性能，验证了方法的有效性。

研究结论: 本文方法成功实现了ViT模型的压缩，同时保持了高诊断准确性，为资源有限地区提供了一种可扩展的视网膜疾病AI分诊解决方案。

中文摘要: 早期准确识别视网膜疾病对防止视力下降至关重要，但在资源有限的地区，可靠的诊断设备往往难以获取。本项目通过开发一种轻量级、可部署在边缘设备上的疾病分类器来解决这一问题，采用跨架构知识蒸馏方法。首先训练一个基于ViT的高容量教师模型，使用I-JEPA自监督学习预训练，分类眼底图像为四类（正常、糖尿病视网膜病变、青光眼和白内障）。在压缩为CNN学生模型时，保持了物联网（IoT）的焦点，以便在资源有限的设备（如NVIDIA Jetson Nano）上部署。采用了一种新颖的框架，包括分区交叉注意力投影器、分组线性投影器和多视图鲁棒训练方法。教师模型参数比学生模型多97.4%，学生模型分类准确率为89%，保留了教师模型93%的诊断性能。临床分类行为的保留支持了我们的初始目标：在压缩ViT模型的同时保持准确性。本研究为资源有限地区的视网膜疾病提供了一种可扩展的AI分诊解决方案。

</details>


### [177] [Make It Efficient: Dynamic Sparse Attention for Autoregressive Image Generation](https://arxiv.org/abs/2506.18226)
**中文标题：高效化：自回归图像生成的动态稀疏注意力**

*Xunzhi Xiang,Qi Fan*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的上下文优化方法——自适应动态稀疏注意力（ADSA），用于解决自回归图像生成中的内存和计算效率问题，显著减少GPU内存消耗并提升生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 自回归条件图像生成模型在文本到图像合成中表现优异，但推理过程中过长的上下文导致KV缓存占用大量内存和计算延迟。本文旨在通过优化注意力机制解决这些问题。

研究方法: 提出自适应动态稀疏注意力（ADSA），动态识别对局部纹理一致性和全局语义连贯性至关重要的历史标记，并引入动态KV缓存更新机制，减少内存消耗。

研究结果: 实验表明，ADSA在生成质量和资源效率上均表现优越，GPU内存消耗减少约50%。

研究结论: ADSA是一种高效的无训练方法，显著提升了自回归图像生成的效率和质量。

中文摘要: 自回归条件图像生成模型已成为文本到图像合成的主要范式。这些方法通常将图像转换为一维标记序列，并利用自注意力机制捕获长距离依赖关系、建模全局上下文并确保语义连贯性。然而，推理过程中过长的上下文导致KV缓存占用大量内存和计算延迟。为缓解这些问题，我们系统分析了全局语义、空间布局和细粒度纹理在推理过程中的形成方式，并提出了一种无需训练的上下文优化方法——自适应动态稀疏注意力（ADSA）。ADSA动态识别对局部纹理一致性和全局语义连贯性至关重要的历史标记，从而高效简化注意力计算。此外，我们还为ADSA设计了一种动态KV缓存更新机制，将推理时的GPU内存消耗减少约50%。大量定性和定量实验证明了我们的方法在生成质量和资源效率上的有效性和优越性。

</details>


### [178] [Drive-R1: Bridging Reasoning and Planning in VLMs for Autonomous Driving with Reinforcement Learning](https://arxiv.org/abs/2506.18234)
**中文标题：Drive-R1：通过强化学习在自动驾驶视觉语言模型中桥接推理与规划**

*Yue Li,Meng Tian,Dechang Zhu,Jiangtong Zhu,Zhenyu Lin,Zhiwei Xiong,Xinhai Zhao*

主要分类: cs.CV

摘要简述: Drive-R1是一种结合推理与规划的视觉语言模型，通过强化学习优化推理路径，提升自动驾驶的运动规划能力，在nuScenes和DriveLM-nuScenes基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言模型（VLMs）在自动驾驶中主要依赖历史输入信息，缺乏对视觉输入的真正理解，且推理过程与运动规划结果不一致。Drive-R1旨在解决这些问题，通过强化学习将推理与规划紧密结合。

研究方法: Drive-R1首先在包含长短链式推理（COT）数据的精细数据集上进行监督微调，逐步从视觉输入推理到最终规划决策。随后通过强化学习框架训练，以预测轨迹和元动作为奖励，优化推理路径。

研究结果: 在nuScenes和DriveLM-nuScenes基准测试中，Drive-R1表现优于现有最先进的视觉语言模型，验证了其推理与规划结合的有效性。

研究结论: Drive-R1为自动驾驶中推理与规划的融合提供了新方向，为未来研究和应用提供了方法论启示。

中文摘要: 自动驾驶中的大型视觉语言模型（VLMs）正从感知和认知任务向运动规划发展。然而，我们发现两个关键挑战：（1）VLMs倾向于依赖历史输入信息走捷径，看似规划结果良好却未真正理解视觉输入；（2）链式推理（COT）过程与运动规划结果不一致，如何有效利用复杂推理能力提升规划仍待探索。本文从小规模领域专用VLM出发，提出Drive-R1，旨在桥接自动驾驶的场景推理与运动规划。Drive-R1首先在包含长短COT数据的精细数据集上进行监督微调，鼓励其从视觉输入逐步推理至最终规划决策。随后，Drive-R1在强化学习框架中训练，以预测轨迹和元动作为奖励，激励发现对规划更具信息量的推理路径。在nuScenes和DriveLM-nuScenes基准测试中，Drive-R1表现优于现有最先进的VLMs。我们认为，Drive-R1为自动驾驶中推理与规划的融合提供了有前景的方向，为未来研究和应用提供了方法论启示。

</details>


### [179] [Referring Expression Instance Retrieval and A Strong End-to-End Baseline](https://arxiv.org/abs/2506.18246)
**中文标题：指代表达实例检索与一种强端到端基线方法**

*Xiangzhao Hao,Kuan Zhu,Hongyu Guo,Haiyun Guo,Ming Tang,JinQiao Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种新任务：指代表达实例检索（REIR），结合实例级检索和定位，并构建了大规模基准数据集REIRCOCO。提出的基线方法CLARE通过双流架构和关系专家模块（MORE）实现端到端优化，在REIR任务中表现优异，并能泛化到其他视觉语言任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有任务如文本-图像检索（TIR）和指代表达理解（REC）分别存在精度不足和扩展性差的问题，无法满足现实场景中同时需要实例级检索和定位的需求。因此，本文提出REIR任务以填补这一空白。

研究方法: 本文提出CLARE方法，采用双流架构和关系专家模块（MORE）捕捉实例间关系，结合目标检测和REC预训练，并通过对比语言-实例对齐（CLIA）实现端到端优化。

研究结果: 实验表明，CLARE在REIR任务上达到最先进性能，并能有效泛化到TIR和REC任务，展现了其高效性和通用性。

研究结论: REIR任务和CLARE方法为实例级检索和定位提供了新思路，实验验证了其有效性，未来可进一步扩展应用场景。

中文摘要: 自然语言查询视觉内容是许多视觉语言任务的基础，通常根据文本粒度和视觉搜索范围分类。文本-图像检索（TIR）通过粗粒度描述检索整张图像，而指代表达理解（REC）则在单张图像中使用细粒度表达定位对象。然而，现实场景往往需要同时进行实例级检索和大规模图库中的定位——TIR缺乏精度，而REC缺乏扩展性。为填补这一空白，我们提出新任务：指代表达实例检索（REIR），支持实例级检索和定位。我们构建了REIRCOCO基准数据集，利用视觉语言模型为MSCOCO和RefCOCO实例生成细粒度表达。同时提出基线方法CLARE，采用双流架构和关系专家模块（MORE）捕捉实例间关系，结合目标检测和REC预训练，并通过对比语言-实例对齐（CLIA）实现端到端优化。实验表明，CLARE在REIR任务上达到最先进性能，并能泛化到TIR和REC任务，展现了其高效性和通用性。

</details>


### [180] [Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability](https://arxiv.org/abs/2506.18248)
**中文标题：语义结构感知的生成对抗攻击以增强对抗迁移性**

*Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon*

主要分类: cs.CV

摘要简述: 本文提出了一种基于语义结构感知的生成对抗攻击框架，通过利用生成模型的中间激活特征提升对抗样本的迁移性，实验表明该方法在多种模型和任务中均优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 现有的生成对抗攻击方法未能充分利用生成模型中的语义信息，限制了对抗样本的迁移性。本文旨在通过语义结构感知的方法提升对抗攻击的效果。

研究方法: 提出了一种基于Mean Teacher的语义结构感知攻击框架，通过特征蒸馏保持学生模型与教师模型在早期层激活的语义一致性，并基于经验发现将扰动合成锚定在生成器的语义显著区域。

研究结果: 在多种模型、领域和任务上的实验表明，该方法在对抗迁移性方面显著优于现有生成对抗攻击方法，并通过新提出的Accidental Correction Rate (ACR)指标进行了全面评估。

研究结论: 通过语义结构感知的方法，本文成功提升了生成对抗攻击的迁移性，为对抗攻击领域提供了新的技术方向。

中文摘要: 生成对抗攻击通过在白盒代理模型上训练扰动生成器，随后将生成的扰动应用于未见过的黑盒受害者模型。与迭代攻击相比，这些方法具有更高的推理效率、可扩展性和迁移性；然而，迄今为止，现有研究尚未充分利用生成模型的表征能力来保留和利用语义信息。具体而言，生成器的中间激活编码了丰富的语义特征（如物体边界和粗略形状），但这些特征未被充分利用，从而限制了扰动与物体显著区域的对齐，而这些区域对对抗迁移性至关重要。为此，我们提出了一种基于Mean Teacher的语义结构感知攻击框架，该框架作为时间平滑的特征参考。通过这一平滑参考，我们进一步通过特征蒸馏指导学生模型的早期层激活与语义丰富的教师模型保持一致。基于经验发现，我们的方法将扰动合成锚定在生成器的语义显著早期中间块上，从而引导渐进式对抗扰动作用于显著提升对抗迁移性的区域。我们在多种模型、领域和任务上进行了广泛实验，结果表明相对于最先进的生成对抗攻击方法，我们的方法在传统指标和新提出的Accidental Correction Rate (ACR)上均表现出持续改进。

</details>


### [181] [Improving Weakly Supervised Temporal Action Localization by Exploiting Multi-resolution Information in Temporal Domain](https://arxiv.org/abs/2506.18261)
**中文标题：通过利用时域多分辨率信息改进弱监督时序动作定位**

*Rui Su,Dong Xu,Luping Zhou,Wanli Ouyang*

主要分类: cs.CV

摘要简述: 本文提出了一种两阶段方法，通过利用时域多分辨率信息生成高质量帧级伪标签，以改进弱监督时序动作定位任务。


<details>
  <summary>详细信息</summary>
研究动机: 弱监督时序动作定位任务仅依赖视频级标注，训练过程中缺乏帧级监督信息，导致性能受限。本文旨在通过多分辨率信息提升伪标签质量，从而改进定位效果。

研究方法: 方法分为两阶段：1) 初始标签生成阶段，利用时域多分辨率一致性生成高质量类别激活序列；2) 渐进式标签细化阶段，通过两个网络（OTS和RTS流）交替优化伪标签，实现多分辨率信息交换。

研究结果: 实验表明，该方法通过多分辨率信息交换和伪标签优化，显著提升了时序动作定位的性能。

研究结论: 本文提出的两阶段框架有效利用了时域多分辨率信息，通过伪标签优化显著提升了弱监督时序动作定位的准确性。

中文摘要: 弱监督时序动作定位是一项具有挑战性的任务，因为训练过程中仅提供视频级标注。为解决这一问题，我们提出了一种两阶段方法，充分利用时域多分辨率信息，并基于外观和运动流生成高质量帧级伪标签。具体而言，第一阶段生成可靠的初始帧级伪标签；第二阶段迭代优化伪标签，并利用高置信度伪标签的帧集训练神经网络，以更好地预测每帧的动作类别分数。我们充分挖掘多尺度时序信息以提升定位性能。在第一阶段，我们提出初始标签生成（ILG）模块，利用时域多分辨率一致性生成高质量的类别激活序列（CASs），每个序列衡量视频帧属于特定动作类别的可能性。第二阶段，我们提出渐进式时序标签细化（PTLR）框架，其中两个网络（Network-OTS和Network-RTS）分别用于生成原始时序尺度和缩减时序尺度的CASs，作为两个流（OTS流和RTS流）交替优化伪标签。通过这种方式，时域多分辨率信息在伪标签层面交换，我们的工作通过利用另一流（RTS/OTS流）的优化伪标签来提升每个流（OTS/RTS流）的性能。

</details>


### [182] [YouTube-Occ: Learning Indoor 3D Semantic Occupancy Prediction from YouTube Videos](https://arxiv.org/abs/2506.18266)
**中文标题：YouTube-Occ：从YouTube视频学习室内3D语义占据预测**

*Haoming Chen,Lichen Yuan,TianFang Sun,Jingyu Gong,Xin Tan,Zhizhong Zhang,Yuan Xie*

主要分类: cs.CV

摘要简述: 本文提出了一种利用YouTube室内视频进行3D语义占据预测的自监督学习方法，无需相机参数，通过2D先验知识实现高效的3D感知。


<details>
  <summary>详细信息</summary>
研究动机: 传统3D语义占据预测依赖精确几何关系，但复杂室内环境的数据采集和标注成本高且隐私问题突出。本文旨在利用互联网视频数据（如YouTube房屋游览视频）实现无需相机参数的3D训练。

研究方法: 收集YouTube房屋游览视频构建数据集YouTube-Occ，提出自监督模型，利用视觉基础模型将2D区域级知识（如超像素分组）蒸馏到占据网络中。

研究结果: 实验表明，该方法在NYUv2和OccScanNet基准测试中实现了零样本状态的最优性能。

研究结论: 通过互联网视频数据，无需相机参数即可实现高效的3D语义占据预测，为复杂室内环境的3D感知提供了新思路。

中文摘要: 过去的3D语义占据预测被认为需要精确的几何关系以实现有效训练。然而，在复杂室内环境中，大规模数据采集和细粒度标注因数据获取复杂性和隐私问题变得不切实际。本文证明，仅使用室内互联网数据即可实现3D空间精确训练，无需任何相机内外参数先验知识。我们构建了YouTube-Occ数据集，包含YouTube房屋游览视频，为3D表示学习提供丰富真实场景。基于此数据集，我们建立了完全自监督模型，利用可访问的2D先验知识实现强大的3D室内感知。具体而言，我们利用视觉基础模型的优势，通过将相似像素分组为超像素，将2D区域级知识蒸馏到占据网络中。实验结果表明，我们的方法在两个流行基准测试（NYUv2和OccScanNet）中实现了零样本状态的最优性能。

</details>


### [183] [ThermalLoc: A Vision Transformer-Based Approach for Robust Thermal Camera Relocalization in Large-Scale Environments](https://arxiv.org/abs/2506.18268)
**中文标题：ThermalLoc：基于视觉Transformer的大规模环境中热成像相机鲁棒重定位方法**

*Yu Liu,Yangtao Meng,Xianfei Pan,Jie Jiang,Changhao Chen*

主要分类: cs.CV

摘要简述: ThermalLoc是一种基于视觉Transformer的端到端深度学习方法，专门用于热成像相机在大规模环境中的鲁棒重定位，结合EfficientNet和Transformer提取特征，并通过MLP网络实现绝对位姿回归，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统视觉重定位方法基于可见光图像，无法直接应用于热成像图像。尽管深度学习在相机重定位方面取得进展，但针对热成像相机的重定位方法仍未被充分探索。

研究方法: ThermalLoc结合EfficientNet和Transformer提取热成像图像的局部和全局特征，并通过两个MLP网络进行绝对位姿回归。

研究结果: 在公开数据集和自有数据集上的实验表明，ThermalLoc在热成像相机重定位任务中优于AtLoc、MapNet、PoseNet和RobustLoc等方法，表现出更高的准确性和鲁棒性。

研究结论: ThermalLoc填补了热成像相机重定位领域的空白，为大规模环境中的鲁棒重定位提供了有效解决方案。

中文摘要: 热成像相机通过热辐射捕捉环境数据，其机制与基于针孔成像的可见光相机截然不同。因此，传统针对可见光图像的视觉重定位方法无法直接应用于热成像图像。尽管深度学习在相机重定位领域取得了显著进展，但专门针对热成像相机重定位的方法仍未被充分研究。为此，我们提出了ThermalLoc，一种新颖的端到端深度学习方法，用于热成像图像的重定位。ThermalLoc通过结合EfficientNet和Transformer，有效提取热成像图像的局部和全局特征，并利用两个MLP网络实现绝对位姿回归。我们在公开的热成像-里程计数据集和自有数据集上评估了ThermalLoc的性能。结果表明，ThermalLoc在热成像相机重定位任务中优于现有的代表性方法（如AtLoc、MapNet、PoseNet和RobustLoc），展现出更高的准确性和鲁棒性。

</details>


### [184] [Adaptive Mask-guided K-space Diffusion for Accelerated MRI Reconstruction](https://arxiv.org/abs/2506.18270)
**中文标题：自适应掩码引导的k空间扩散用于加速MRI重建**

*Qinrong Cai,Yu Guan,Zhibo Chen,Dong Liang,Qiuyun Fan,Qiegen Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自适应掩码的k空间扩散模型（AMDM），通过动态调整k空间数据的频率分布，有效分离高低频成分，从而提升MRI重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统MRI重建方法通常优化整个图像域或k空间，未考虑不同频率区域的重要性。本文旨在通过自适应掩码机制，更有效地利用k空间数据中的频率信息，提升重建效果。

研究方法: 提出自适应掩码引导的k空间扩散模型（AMDM），利用k空间数据的频率分布生成自适应掩码，指导闭环扩散过程，分离高低频成分，生成多样化的频率特定表示。

研究结果: 实验证明，该方法能有效学习特定频率信息，显著提高MRI重建质量，为未来基于掩码的k空间数据优化提供了灵活框架。

研究结论: AMDM通过自适应掩码机制优化k空间数据，显著提升了MRI重建质量，为相关领域提供了新的研究思路。

中文摘要: 随着深度学习的快速发展，掩码建模成为一种独特的方法，通过预测训练中被部分掩码的原始数据，已在多个领域展现出卓越性能。磁共振成像（MRI）重建是医学影像中的关键任务，旨在从欠采样的k空间数据中恢复高质量图像。然而，以往的MRI重建策略通常优化整个图像域或k空间，未考虑k空间中不同频率区域的重要性。本文提出了一种基于自适应掩码的扩散模型（AMDM），利用k空间数据的频率分布动态调整，开发了一种适应不同k空间输入的混合掩码机制。这有效分离了高频和低频成分，生成了多样化的频率特定表示。此外，k空间频率分布指导生成自适应掩码，进而引导闭环扩散过程。实验结果验证了该方法学习特定频率信息的能力，从而提高了MRI重建质量，为未来利用掩码优化k空间数据提供了灵活框架。

</details>


### [185] [ReFrame: Rectification Framework for Image Explaining Architectures](https://arxiv.org/abs/2506.18272)
**中文标题：ReFrame：图像解释架构的修正框架**

*Debjyoti Das Adhikary,Aritra Hazra,Partha Pratim Chakrabarti*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ReFrame的可解释框架，用于解决图像解释任务中对象识别的不一致性和不完整性问题，显著提升了图像描述、视觉问答和基于提示的AI模型的解释能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像解释方法常存在幻觉对象或遗漏真实对象的问题，导致解释的不一致性和不完整性。本文旨在通过一种可插拔的框架，增强现有图像解释架构的准确性。

研究方法: 提出ReFrame框架，可集成于图像描述、视觉问答和基于提示的AI模型中，通过修正错误或缺失的对象来提升解释能力。采用基于对象的精度指标评估改进效果。

研究结果: 实验表明，ReFrame显著提升了图像描述的完整性（81.81%）和不一致性（37.10%）、视觉问答的完整性（平均9.6%）和不一致性（37.10%），以及基于提示的AI模型的完整性（0.01%）和不一致性（5.2%）。

研究结论: ReFrame框架有效解决了图像解释中的对象识别问题，显著提升了多种任务的一致性和完整性，超越了现有技术。

中文摘要: 图像解释一直是深度学习领域的关键研究方向之一。多年来，研究者提出了多种方法来解释用户输入的图像，从检测图像中的对象到生成人类可理解的句子描述，再到通过对话描述图像内容，这一领域经历了巨大变革。然而，现有方法常存在以下问题：（a）幻觉出图像中不存在的对象；（b）未能识别图像中所有对象。本文提出了一种新方法，旨在解决图像解释中对象识别的不一致性和不完整性问题。为此，我们提出了一种可解释的框架，可集成于多种图像解释架构（如图像描述、视觉问答和基于提示的AI模型），通过修正错误或缺失的对象来增强其解释能力。我们进一步利用基于对象的精度指标评估修正后解释的效果，并展示了图像解释在一致性和完整性方面的改进。定量结果表明，所提框架在图像描述（完整性提升81.81%，不一致性降低37.10%）、视觉问答（完整性和不一致性平均提升9.6%和37.10%）和基于提示的AI模型（完整性和不一致性分别提升0.01%和5.2%）中均显著优于现有技术。

</details>


### [186] [Open Set Recognition for Endoscopic Image Classification: A Deep Learning Approach on the Kvasir Dataset](https://arxiv.org/abs/2506.18284)
**中文标题：内窥镜图像分类的开放集识别：基于Kvasir数据集的深度学习方法**

*Kasra Moazzami,Seoyoun Son,John Lin,Sun Min Lee,Daniel Son,Hayeon Lee,Jeongho Lee,Seongji Lee*

主要分类: cs.CV

摘要简述: 本文探讨了在Kvasir内窥镜数据集上应用开放集识别（OSR）技术，评估了多种深度学习模型（如ResNet-50、Swin Transformer和混合模型）在开放集条件下的表现，并采用OpenMax作为基线方法。研究为医学图像分析中的OSR性能提供了基准。


<details>
  <summary>详细信息</summary>
研究动机: 传统封闭集分类框架在临床开放环境中存在局限性，无法处理未知类别。本文旨在通过开放集识别技术提升内窥镜图像分类在真实临床场景中的可靠性。

研究方法: 研究在Kvasir数据集上评估了ResNet-50、Swin Transformer和混合ResNet-Transformer模型的OSR能力，并采用OpenMax作为基线方法，比较了它们在封闭集和开放集条件下的表现。

研究结果: 实验结果表明，混合模型在开放集条件下表现最佳，为医学图像分析中的OSR提供了实用基准，并揭示了模型在临床真实场景中的行为特点。

研究结论: 开放集识别技术对AI系统在内窥镜中的安全部署至关重要，本研究为相关领域提供了基础性参考。

中文摘要: 内窥镜图像分类在医学诊断中至关重要，能够识别解剖标志和病理发现。然而，传统的封闭集分类框架在开放世界的临床环境中存在固有局限性，无法应对未知情况，从而影响模型可靠性。为此，我们在公开且多样化的Kvasir内窥镜图像数据集上探索了开放集识别（OSR）技术的应用。本研究评估并比较了多种代表性深度学习架构（包括ResNet-50、Swin Transformer和混合ResNet-Transformer模型）在封闭集和开放集条件下的OSR能力。采用OpenMax作为基线OSR方法，以评估这些模型区分已知类别与未知类别的能力。这是首次将开放集识别应用于Kvasir数据集的研究之一，为医学图像分析中的OSR性能评估提供了基础性基准。我们的结果揭示了模型在临床真实场景中的行为特点，并强调了OSR技术在内窥镜AI系统安全部署中的重要性。

</details>


### [187] [Selective Social-Interaction via Individual Importance for Fast Human Trajectory Prediction](https://arxiv.org/abs/2506.18291)
**中文标题：基于个体重要性的选择性社交交互用于快速人类轨迹预测**

*Yota Urano,Hiromu Taketsugu,Norimichi Ukita*

主要分类: cs.CV

摘要简述: 本文提出了一种通过选择重要邻居来预测主要人物轨迹的架构，使用重要性估计模块和Gumbel Softmax技术，实验表明该方法在保持预测精度的同时加快了速度。


<details>
  <summary>详细信息</summary>
研究动机: 预测人类轨迹时，周围人群的影响是关键，但传统方法对所有邻居平等处理，效率低下。本文旨在通过选择重要邻居来提高预测效率和准确性。

研究方法: 提出重要性估计模块（Importance Estimator）评估每个邻居对主要人物轨迹预测的重要性，并使用Gumbel Softmax解决非可微分操作导致的梯度阻塞问题。

研究结果: 在JRDB数据集上的实验表明，该方法在保持竞争性预测精度的同时显著加快了预测速度。

研究结论: 通过选择性社交交互和重要性估计，本文方法在轨迹预测任务中实现了高效和准确的平衡。

中文摘要: 本文提出了一种架构，用于选择重要的邻居来预测主要人物的轨迹。为实现有效的邻居选择，我们提出了一个称为重要性估计器的人员选择模块，该模块输出每个邻居对预测主要人物未来轨迹的重要性。为防止基于重要性采样周围人员时因非可微分操作而阻塞梯度，我们采用了Gumbel Softmax进行训练。在JRDB数据集上的实验表明，我们的方法在保持竞争性预测精度的同时加快了预测过程。

</details>


### [188] [Rapeseed population point cloud completion network (RP-PCN) with dynamic graph convolution for 3D reconstruction of crop canopy occlusion architecture](https://arxiv.org/abs/2506.18292)
**中文标题：基于动态图卷积的油菜群体点云补全网络（RP-PCN）用于作物冠层遮挡结构的三维重建**

*Ziyue Guo,Xin Yang,Yutao Shen,Yang Zhu,Lixi Jiang,Haiyan Cen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于动态图卷积的油菜群体点云补全网络（RP-PCN），用于从多视角图像中重建油菜群体从苗期到角果期的三维结构。该方法通过虚拟-现实融合模拟和遮挡点检测算法生成完整点云数据集，并利用多分辨率动态图卷积编码器和点金字塔解码器预测遮挡点。实验表明，RP-PCN显著提升了点云补全精度和产量预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 作物冠层结构的完整定量描述对评估光合作用和产量至关重要，但严重的遮挡和复杂结构阻碍了准确描述。本研究旨在通过点云补全技术解决油菜群体冠层三维重建中的遮挡问题。

研究方法: 1. 使用虚拟-现实融合（VRI）模拟和遮挡点检测算法标注训练数据集；2. 设计RP-PCN网络，包含多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD）；3. 引入动态图卷积特征提取器（DGCFE）捕捉生长周期中的结构变化。

研究结果: RP-PCN在苗期、抽薹期、花期和角果期的Chamfer距离（CD）分别为3.35 cm、3.46 cm、4.32 cm和4.51 cm。消融实验表明，MRDG和DGCFE模块分别降低CD值10%和23%。RP-PCN的角果效率指数（SEI）将产量预测准确性提高了11.2%。

研究结论: RP-PCN能有效补全油菜群体冠层的点云数据，显著提升产量预测精度，并有望推广至其他作物，为田间群体冠层结构分析提供新方法。

中文摘要: 完整的冠层结构定量描述对评估作物光合作用和产量以指导理想型设计至关重要。尽管已开发出用于植物和冠层重建的三维（3D）传感技术，但严重的遮挡和复杂结构阻碍了准确的冠层描述。本研究提出了一种基于多视角成像的点云补全模型，用于从苗期到角果期的油菜群体三维重建。通过虚拟-现实融合（VRI）模拟方法和遮挡点检测算法，开发了完整点云生成框架，以区分表面点和遮挡点并标注训练数据集。设计的油菜群体点云补全网络（RP-PCN）采用多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD），基于输入表面点云预测遮挡点。引入动态图卷积特征提取器（DGCFE）以捕捉生长周期中的结构变化。通过从完整点云中提取的冠层结构指标预测产量，验证了点云补全的有效性。结果表明，RP-PCN在苗期、抽薹期、花期和角果期的Chamfer距离（CD）分别为3.35 cm、3.46 cm、4.32 cm和4.51 cm。消融实验表明，MRDG和DGCFE模块分别降低CD值10%和23%。RP-PCN的角果效率指数（SEI）与不完整点云相比，将产量预测准确性提高了11.2%。本研究中提出的RP-PCN流程有望推广至其他作物，显著提升田间群体冠层结构的分析能力。

</details>


### [189] [Attention-Based Ensemble Learning for Crop Classification Using Landsat 8-9 Fusion](https://arxiv.org/abs/2506.18321)
**中文标题：基于注意力集成学习的Landsat 8-9融合数据作物分类方法**

*Zeeshan Ramzan,Nisar Ahmed,Qurat-ul-Ain Akram,Shahzad Asif,Muhammad Shahbaz,Rabin Chakrabortty,Ahmed F. Elaksher*

主要分类: cs.CV

摘要简述: 该研究利用Landsat 8-9融合数据和注意力机制集成学习方法，结合植被指数和反射率值，提高了巴基斯坦旁遮普中部灌溉区作物分类的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 遥感技术为作物面积和类型的高效监测提供了可能。研究旨在通过结合多源遥感数据和先进建模技术，提升灌溉农业区的作物分类精度。

研究方法: 研究分两阶段：1) 通过实地调查和GPS测绘收集目标作物的地理编码数据；2) 获取Landsat 8-9影像，进行辐射校准、大气校正和图像融合。提取植被指数后，采用传统分类器、集成学习和神经网络进行建模，并结合特征选择优化分类特征。

研究结果: 研究构建了包含50,835个数据点的数据集，通过融合Landsat 8-9光谱信息，显著提升了作物分类的准确性。

研究结论: 结合遥感数据和先进建模技术，可有效提高灌溉农业区的作物分类精度，为农业监测提供了可靠工具。

中文摘要: 遥感技术为获取作物总面积和类型的精确信息提供了高效方法。本研究聚焦巴基斯坦旁遮普中部灌溉区的作物覆盖识别。数据收集分为两个阶段：第一阶段通过2023年1月至2月的实地调查，对六种目标作物进行地理编码；第二阶段获取每个地理编码田块的Landsat 8-9影像，构建标记数据集。卫星影像经过辐射校准（反射率值）、大气校正和地理配准验证，确保其在统一坐标系中的一致性。随后，应用图像融合技术结合Landsat 8和9的光谱波段，生成具有增强光谱信息的复合图像，并进行对比度增强。数据收集过程中，通过访谈农民和使用GPS仪器精细测绘田块，最终构建了包含50,835个数据点的综合数据集。该数据集支持提取NDVI、SAVO、RECI和NDRE等植被指数。这些指数和原始反射率值被用于传统分类器、集成学习和人工神经网络的分类建模。研究还结合特征选择方法，确定分类学习的最佳特征集。本研究展示了结合遥感数据和先进建模技术，在提升灌溉农业区作物分类精度方面的有效性。

</details>


### [190] [Escaping the SpuriVerse: Can Large Vision-Language Models Generalize Beyond Seen Spurious Correlations?](https://arxiv.org/abs/2506.18322)
**中文标题：逃离虚假宇宙：大型视觉语言模型能否超越所见虚假相关性实现泛化？**

*Yiwei Yang,Chung Peng Lee,Shangbin Feng,Dora Zhao,Bingbing Wen,Anthony Z. Liu,Yulia Tsvetkov,Bill Howe*

主要分类: cs.CV

摘要简述: 本文研究了大型视觉语言模型（LVLMs）中虚假相关性的问题，开发了SpuriVerse基准测试，发现即使最先进的模型也难以避免虚假相关性，但通过微调可以显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多关注窄任务中虚假相关性的影响，而本文旨在探索多模态大型视觉语言模型（LVLMs）在广泛数据集预训练后是否仍受虚假相关性影响，并开发了更贴近现实的基准测试。

研究方法: 通过分析GPT-4o在真实视觉问答（VQA）任务中的错误，结合人工标注和合成反事实评估，构建了SpuriVerse基准，包含124类虚假相关性和1364个多选问题。随后评估了15种开源和闭源LVLMs的性能。

研究结果: 实验显示，即使是顶级闭源模型在SpuriVerse上的准确率最高仅为37.1%，但通过针对虚假相关性的微调，性能可提升至78.40%，表明模型能学会避免“捷径”并关注整体图像上下文。

研究结论: 研究表明，LVLMs在真实场景中仍易受虚假相关性影响，但通过多样化训练可以提升泛化能力，避免依赖虚假特征。

中文摘要: 微调可能导致非必要特征与目标标签之间产生虚假相关性，但现有研究多基于人为设置的窄任务。本文则关注多模态大型视觉语言模型（LVLMs）在广泛数据集预训练后是否仍受虚假相关性影响。我们通过分析GPT-4o在真实视觉问答（VQA）任务中的错误，结合人工标注和合成反事实评估，构建了SpuriVerse基准，包含124类虚假相关性和1364个多选问题。评估15种开源和闭源LVLMs后发现，即使最先进的闭源模型表现也较差，最高准确率仅为37.1%。然而，通过针对虚假相关性的微调，性能可提升至78.40%，表明模型能学会避免“捷径”并关注整体图像上下文。

</details>


### [191] [A Multi-Scale Spatial Attention-Based Zero-Shot Learning Framework for Low-Light Image Enhancement](https://arxiv.org/abs/2506.18323)
**中文标题：基于多尺度空间注意力的零样本学习框架用于低光图像增强**

*Muhammad Azeem Aslam,Hassan Khalid,Nisar Ahmed*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多尺度空间注意力的零样本学习框架LucentVisionNet，用于低光图像增强，无需配对训练数据即可实现高质量的图像增强。


<details>
  <summary>详细信息</summary>
研究动机: 低光图像增强是一个具有挑战性的任务，尤其是在缺乏配对训练数据的情况下。传统方法和深度学习方法存在局限性，因此需要一种无需配对数据的零样本学习框架。

研究方法: LucentVisionNet结合了多尺度空间注意力和深度曲线估计网络，采用循环增强策略，并通过包含六个定制组件的复合损失函数进行优化，其中包括一种基于人类视觉感知的无参考图像质量损失。

研究结果: 在多个基准数据集上的实验表明，LucentVisionNet在多项全参考和无参考图像质量指标上均优于现有的监督、无监督和零样本方法，具有高视觉质量、结构一致性和计算效率。

研究结论: LucentVisionNet在低光图像增强任务中表现出色，适用于移动摄影、监控和自主导航等实际应用场景。

中文摘要: 低光图像增强仍然是一项具有挑战性的任务，尤其是在缺乏配对训练数据的情况下。本研究提出了一种名为LucentVisionNet的新型零样本学习框架，旨在解决传统和基于深度学习的增强方法的局限性。该方法将多尺度空间注意力与深度曲线估计网络相结合，实现了细粒度的增强，同时保持了语义和感知的保真度。为了进一步提高泛化能力，我们采用了循环增强策略，并通过包含六个定制组件的复合损失函数优化模型，其中包括一种受人类视觉感知启发的无参考图像质量损失。在多个配对和非配对基准数据集上的广泛实验表明，LucentVisionNet在全参考和无参考图像质量指标上均优于现有的监督、无监督和零样本方法。我们的框架具有高视觉质量、结构一致性和计算效率，非常适合应用于移动摄影、监控和自主导航等实际场景。

</details>


### [192] [NSFW-Classifier Guided Prompt Sanitization for Safe Text-to-Image Generation](https://arxiv.org/abs/2506.18325)
**中文标题：基于NSFW分类器引导的提示净化技术实现安全文本到图像生成**

*Yu Xie,Chengjie Zeng,Lingyun Zhang,Yanwei Fu*

主要分类: cs.CV

摘要简述: 本文提出PromptSan方法，通过NSFW分类器引导的提示净化技术，确保文本到图像生成的安全性，避免有害内容生成，同时保持模型生成能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着文本到图像（T2I）模型的快速发展，其生成能力提升的同时也带来了滥用风险，如生成色情、暴力等有害内容。本文旨在解决这一问题，确保T2I技术的可持续发展。

研究方法: 提出PromptSan方法，包括两种变体：PromptSan-Modify通过迭代替换有害标记净化输入提示；PromptSan-Suffix训练优化的后缀标记序列中和有害意图。两种方法均基于文本和图像NSFW分类器。

研究结果: 实验表明，PromptSan在减少有害内容生成方面表现优异，同时平衡了安全性与可用性。

研究结论: PromptSan为T2I模型提供了一种无需修改架构即可实现安全生成的有效方法，推动了技术的可持续发展。

中文摘要: 文本到图像（T2I）模型（如Stable Diffusion）的快速发展提升了其从文本提示生成图像的能力，但也带来了滥用风险，如生成色情、暴力或歧视性内容，这与T2I技术的伦理目标相悖，阻碍了其可持续发展。受大型语言模型中“越狱”攻击的启发，本文提出NSFW分类器引导的提示净化技术（PromptSan），一种无需修改模型架构或降低生成能力即可净化有害提示的新方法。PromptSan包括两种变体：PromptSan-Modify在推理过程中通过文本NSFW分类器迭代识别并替换输入提示中的有害标记；PromptSan-Suffix训练优化的后缀标记序列以中和有害意图，同时通过文本和图像NSFW分类器检查。大量实验表明，PromptSan在减少有害内容生成方面达到了最先进的性能，有效平衡了安全性与可用性。

</details>


### [193] [Geometry-Aware Preference Learning for 3D Texture Generation](https://arxiv.org/abs/2506.18331)
**中文标题：几何感知的偏好学习用于3D纹理生成**

*AmirHossein Zamani,Tianhao Xie,Amir G. Aghdam,Tiberiu Popa,Eugene Belilovsky*

主要分类: cs.CV

摘要简述: 本文提出了一种端到端的可微分偏好学习框架，通过几何感知的奖励函数将人类偏好反向传播至3D生成流程，解决了现有3D纹理生成方法缺乏对3D结构理解的问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D生成模型虽取得显著进展，但生成的3D内容常与人类主观偏好或任务特定标准不符，且现有方法依赖2D文本到图像模型，缺乏对3D结构的理解。

研究方法: 提出一种端到端的可微分偏好学习框架，通过几何感知的奖励函数将人类偏好反向传播至整个3D生成流程，使其具备几何感知能力。

研究结果: 通过四种新颖的几何感知奖励函数验证了框架的有效性，为高质量3D内容生成提供了更可控和可解释的途径。

研究结论: 该框架为3D纹理生成提供了更符合人类偏好的几何感知解决方案，提升了生成内容的质量和可控性。

中文摘要: 近年来，3D生成模型取得了显著进展，但这些模型生成的3D内容可能不符合人类主观偏好或任务特定标准。此外，3D纹理生成领域的一个核心挑战是：大多数现有方法依赖于对2D文本到图像生成模型的重复调用，这些模型缺乏对输入3D网格对象结构的固有理解。为此，我们提出了一种端到端的可微分偏好学习框架，通过可微分奖励函数将人类偏好反向传播至整个3D生成流程，使其具备几何感知能力。我们通过四种新颖的几何感知奖励函数验证了该框架的有效性，为基于自然语言的高质量3D内容生成提供了更可控和可解释的途径。

</details>


### [194] [Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention](https://arxiv.org/abs/2506.18335)
**中文标题：重新思考解码器设计：利用深度到空间恢复和残差线性注意力提升生物标志物分割**

*Saad Wazir,Daeyoung Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种新型解码器设计，通过深度到空间恢复和残差线性注意力机制，显著提升了生物标志物在医学图像中的分割精度，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于Transformer和CNN的医学图像分割方法在染色和形态变化上表现不佳，且端到端方法因多尺度特征传递和解码器效率问题而性能受限。本文旨在解决这些问题。

研究方法: 提出了一种新型解码器架构，结合多尺度局部和全局上下文信息，通过深度到空间恢复和残差线性注意力机制，有效整合编码器特征并提升空间维度重建。

研究结果: 在四个数据集（MoNuSeg、DSB、电子显微镜和TNBC）上的实验表明，该方法性能显著优于现有SOTA方法，绝对性能提升分别为2.76%、3.12%、2.87%和4.03%。

研究结论: 本文的解码器设计在医学图像分割中表现出色，兼容多种编码器，为生物标志物分割提供了高效且准确的解决方案。

中文摘要: 医学图像中的生物标志物分割对多种生物技术应用至关重要。尽管已有进展，基于Transformer和CNN的方法在染色和形态变化上仍存在困难，限制了特征提取。在样本有限的医学图像分割任务中，现有SOTA方法依赖预训练编码器以提高精度，而端到端方法表现不佳。这源于多尺度特征从编码器到解码器的传递效率问题以及解码器设计不足。为解决这些问题，我们提出了一种架构，能够捕获多尺度局部和全局上下文信息，并设计了一种新型解码器，有效整合编码器特征、突出重要通道和区域，并通过空间维度重建提升分割精度。我们的方法兼容多种编码器，在四个数据集和消融实验中表现优于SOTA方法，具体表现为在MoNuSeg、DSB、电子显微镜和TNBC数据集上分别实现了2.76%、3.12%、2.87%和4.03%的绝对性能提升。代码：https://github.com/saadwazir/MCADS-Decoder

</details>


### [195] [BSMamba: Brightness and Semantic Modeling for Long-Range Interaction in Low-Light Image Enhancement](https://arxiv.org/abs/2506.18346)
**中文标题：BSMamba：基于亮度与语义建模的低光图像增强远距离交互方法**

*Tongshun Zhang,Pingping Liu,Mengen Cai,Zijian Zhang,Yubing Lu,Qiuzhan Zhou*

主要分类: cs.CV

摘要简述: BSMamba提出了一种新的视觉Mamba架构，通过亮度Mamba和语义Mamba分别建模亮度相似性和语义相关性，解决了低光图像增强中亮度恢复和语义一致性的问题，并在实验中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 当前低光图像增强方法在提升亮度的同时难以保持语义一致性和细节，且现有视觉Mamba方法因固定扫描规则限制了远距离token的交互能力。BSMamba旨在通过亮度与语义建模解决这些问题。

研究方法: BSMamba包含亮度Mamba和语义Mamba两个组件：亮度Mamba通过亮度相似性优先连接远距离token，语义Mamba则通过语义相似性保持上下文一致性。两者结合突破了传统token序列的限制。

研究结果: 实验表明，BSMamba在低光图像增强任务中实现了最先进的性能，同时有效保持了语义一致性。

研究结论: BSMamba通过亮度与语义建模，显著提升了低光图像增强的性能和语义一致性，为视觉Mamba架构提供了新的设计思路。

中文摘要: 当前的低光图像增强（LLIE）方法在提升亮度的同时难以保持语义一致性、细节和计算效率。随着状态空间模型（如Mamba）的出现，图像修复取得了显著进展，但现有视觉Mamba方法通过固定扫描规则将2D图像展平为1D token序列，严重限制了具有因果关系的远距离token之间的交互，从而难以捕捉有意义的长距离依赖关系。为解决这些根本性限制，我们提出了BSMamba，一种新型视觉Mamba架构，包含两个专门设计的组件：亮度Mamba和语义Mamba。亮度Mamba通过优先连接亮度相似的远距离token，彻底改变了token交互模式，通过亮度引导的选择性注意力有效解决了LLIE任务中的亮度恢复挑战。与之互补，语义Mamba优先连接语义相似的token，使模型能够通过连接图像中语义相关的区域来保持上下文一致性，从而在增强过程中保留图像语义的层次性。通过基于亮度和语义相似性而非任意扫描模式对token进行智能建模，BSMamba突破了传统token序列的限制，同时遵循因果建模的原则。大量实验表明，BSMamba在LLIE中实现了最先进的性能，同时保持了语义一致性。

</details>


### [196] [Spatial frequency information fusion network for few-shot learning](https://arxiv.org/abs/2506.18364)
**中文标题：小样本学习的空间频率信息融合网络**

*Wenqing Zhao,Guojia Xie,Han Pan,Biao Yang,Weichuan Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SFIFNet的空间频率信息融合网络，通过结合频域和空间域信息提升小样本学习的分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 小样本学习中，每类图像数量有限，传统方法易过拟合且泛化能力差。现有模型多关注空间域信息而忽略频域信息，导致特征利用不充分。本文旨在通过融合频域信息提升模型性能。

研究方法: 基于传统数据增强，提出SFIFNet网络，创新性地结合频域和空间域信息，优化图像特征表示。

研究结果: 实验证明，该方法有效提升了分类性能。

研究结论: SFIFNet通过融合频域信息显著提升了小样本学习的分类效果，为实际应用提供了更优解决方案。

中文摘要: 小样本学习的目标是通过算法充分利用有限数据资源，挖掘数据中的潜在关联，并训练出性能优异的模型以满足实际应用需求。在实际应用中，每类图像数量通常少于传统深度学习，易导致过拟合和泛化性能差。目前，许多小样本分类模型更关注空间域信息而忽略频域信息，后者包含更多特征信息。忽略频域信息会阻碍模型充分利用特征信息，从而影响分类性能。基于传统数据增强，本文提出了一种创新的数据预处理方法SFIFNet。该方法的核心是通过融合频域和空间域信息提升图像特征表示的准确性。实验结果证明了该方法在提升分类性能方面的有效性。

</details>


### [197] [Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection](https://arxiv.org/abs/2506.18368)
**中文标题：序列关键点密度估计器：骨架视频异常检测中被忽视的基线方法**

*Anja Delić,Matej Grcić,Siniša Šegvić*

主要分类: cs.CV

摘要简述: 本文提出了一种基于骨架序列的异常行为检测方法SeeKer，通过自回归因子化建模关键点密度，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在医疗监控、工作场所安全和公共监控等安全关键应用中，异常行为检测至关重要。异常通常表现为不寻常的人体姿态，因此需要一种高效的方法来检测这些异常。

研究方法: SeeKer方法通过自回归因子化在关键点级别建模骨架序列密度，利用条件高斯分布表示关键点位置的概率。异常分数是关键点对数条件概率的加权和，权重考虑了关键点检测器的置信度。

研究结果: SeeKer在UBnormal和MSAD-HR数据集上超越了所有现有方法，并在ShanghaiTech数据集上表现出竞争力。

研究结论: 尽管方法简单，SeeKer在多个数据集上表现出色，证明了其在骨架序列异常检测中的有效性。

中文摘要: 检测异常人类行为是医疗监控、工作场所安全和公共监控等安全关键应用中的重要视觉任务。在这些场景中，异常通常表现为不寻常的人体姿态。为此，我们提出了SeeKer，一种用于检测人类骨架序列异常的方法。我们的方法通过关键点级别的自回归因子化建模骨架序列密度，相应的条件分布表示给定先前骨骼运动的关键点位置概率。我们将骨架的联合分布建模为其关键点条件高斯的因果预测。如果骨架的关键点位置出乎模型意料（即密度较低），则被标记为异常。实践中，我们的异常分数是关键点对数条件概率的加权和，权重考虑了底层关键点检测器的置信度。尽管概念简单，SeeKer在UBnormal和MSAD-HR数据集上超越了所有先前方法，并在ShanghaiTech数据集上表现出竞争力。

</details>


### [198] [RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models](https://arxiv.org/abs/2506.18369)
**中文标题：RePIC：基于强化学习的后训练框架用于个性化多模态语言模型**

*Yeongtak Oh,Jisoo Mok,Dohyun Chung,Juhyeon Shin,Sangha Park,Johan Barthelemy,Sungroh Yoon*

主要分类: cs.CV

摘要简述: 本文提出了一种基于强化学习的后训练框架RePIC，用于提升多模态大语言模型（MLLMs）的个性化图像描述生成能力，显著优于现有的监督微调方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态大语言模型在生成个性化图像描述时表现不佳，尤其是面对多概念图像描述等复杂场景时，监督微调方法效果有限且数据获取成本高。

研究方法: 提出了一种基于强化学习的后训练框架RePIC，通过强化学习优化模型，而非依赖大规模高质量标注数据。

研究结果: RePIC显著提升了模型的视觉识别和个性化生成能力，在多概念图像描述任务中表现优于现有监督微调方法。

研究结论: 强化学习后训练是一种有效提升多模态大语言模型个性化生成能力的方法，尤其在复杂场景下表现突出。

中文摘要: 当前的多模态大语言模型（MLLMs）在生成个性化图像描述时表现不佳，即使经过高质量标注数据的训练。本文发现，现有的基于后训练的MLLM个性化方法仍存在这一局限。具体而言，尽管通过监督微调（SFT）使用大规模标注数据进行后调优，这些模型在真实场景（如多概念图像描述）中仍难以生成准确的描述。然而，获取此类复杂场景下的大规模高质量标注数据成本高且困难。为解决SFT的数据依赖问题，我们提出了一种基于强化学习（RL）的后训练框架。据我们所知，这是首个基于RL的后训练方法，用于个性化图像描述的MLLM训练。我们的方法显著提升了MLLMs的视觉识别和个性化生成能力，在多概念图像描述任务中表现优于现有SFT基线。

</details>


### [199] [OpenEvents V1: Large-Scale Benchmark Dataset for Multimodal Event Grounding](https://arxiv.org/abs/2506.18372)
**中文标题：OpenEvents V1：用于多模态事件定位的大规模基准数据集**

*Hieu Nguyen,Phuc-Tan Nguyen,Thien-Phuc Tran,Minh-Quang Nguyen,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: OpenEvents V1是一个大规模多模态事件基准数据集，专注于事件感知的图像描述生成和基于叙事文本查询的图像检索任务，包含20万篇新闻文章和40万张相关图片。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像描述和检索数据集仅关注表面描述，缺乏对事件上下文和时间维度的深入理解。OpenEvents V1旨在推动事件中心的多模态视觉语言理解，填补这一空白。

研究方法: 数据集包含来自CNN和The Guardian的20万篇新闻文章和40万张图片，覆盖多样领域和时间段。提供两种任务：生成事件感知的图像描述和基于叙事文本的图像检索，并制定了标准化评估协议。

研究结果: OpenEvents V1为开发能够深度推理复杂现实事件的多模态模型提供了坚实基础，并提供了广泛的基线结果和评估标准。

研究结论: OpenEvents V1通过其大规模和任务设计，为多模态事件理解研究提供了重要资源，推动了该领域的进展。

中文摘要: 我们介绍了OpenEvents V1，这是一个旨在推动事件中心视觉语言理解的大规模基准数据集。与传统强调表面描述的图像描述和检索数据集不同，OpenEvents V1通过两项主要任务聚焦于上下文和时间定位：(1)生成丰富的事件感知图像描述；(2)基于叙事风格文本查询检索事件相关图像。数据集包含来自CNN和The Guardian的20万篇新闻文章和40万张相关图片，涵盖多样领域和时间段。我们为两项任务提供了广泛的基线结果和标准化评估协议。OpenEvents V1为开发能够深度推理复杂现实事件的多模态模型奠定了坚实基础。数据集可通过https://ltnghia.github.io/eventa/openevents-v1获取。

</details>


### [200] [InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2506.18385)
**中文标题：InternSpatial：视觉-语言模型空间推理的综合数据集**

*Nianchen Deng,Lixin Gu,Shenglong Ye,Yinan He,Zhe Chen,Songze Li,Haomin Wang,Xingguang Wei,Tianshuo Yang,Min Dou,Tong He,Wenqi Shao,Kaipeng Zhang,Yi Wang,Botian Shi,Yanting Zhang,Jifeng Dai,Yu Qiao,Hongjie Zhang,Wenhai Wang*

主要分类: cs.CV

摘要简述: 本文提出了InternSpatial，一个用于提升视觉-语言模型空间推理能力的最大开源数据集，并配套了评估基准InternSpatial-Bench。实验表明，使用该数据集训练的模型在空间推理任务上表现显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉-语言模型空间推理数据集规模小、视觉多样性不足且指令表达有限，限制了模型的空间推理能力发展。本文旨在填补这一空白。

研究方法: 构建了包含1200万问答对的InternSpatial数据集，涵盖单视角和多视角场景，支持19种指令格式。同时设计了InternSpatial-Bench评估基准，并引入了新颖的旋转角度预测任务。

研究结果: 实验结果显示，使用InternSpatial训练的模型在InternSpatial-Bench上提升了12.1%，在VSI-Bench上提升了10.7%，同时在通用基准上保持良好性能。

研究结论: InternSpatial及其评估基准为开发具有空间推理能力的视觉-语言模型提供了重要资源，有望推动机器人和具身AI等实际应用的发展。

中文摘要: 近年来，尽管已有一些基准和数据集被提出以提升视觉-语言模型（VLMs）的空间推理能力，但现有的开放资源在规模、视觉多样性和指令表达性方面仍显不足。本文提出了InternSpatial，这是目前最大的开源空间推理数据集，同时配套了InternSpatial-Bench评估基准，用于评估多样化指令格式下的空间理解能力。InternSpatial包含1200万问答对，涵盖单视角和多视角场景，源自多样化的视觉环境，并支持19种反映不同查询风格的指令格式。在评估方面，我们为单视角任务设计了InternSpatial-Bench，并通过引入一种新颖的旋转角度预测任务扩展了多视角推理能力，这在先前的研究中尚未被探索。实验结果表明，使用InternSpatial训练的模型在InternSpatial-Bench上提升了12.1%，在VSI-Bench上提升了10.7%，同时在通用基准上保持了强劲性能。我们希望这些资源能够支持开发具有空间能力的VLMs，推动机器人和具身AI等实际应用的发展。

</details>


### [201] [Distributed Poisson multi-Bernoulli filtering via generalised covariance intersection](https://arxiv.org/abs/2506.18397)
**中文标题：基于广义协方差交集的分布式泊松多伯努利滤波**

*Ángel F. García-Fernández,Giorgio Battistelli*

主要分类: cs.CV

摘要简述: 本文提出了一种基于广义协方差交集（GCI）融合规则的分布式泊松多伯努利（PMB）滤波器，用于分布式多目标滤波。由于精确的GCI融合难以实现，作者提出了一种理论上的近似方法，并通过实验验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 分布式多目标滤波在传感器网络中具有重要应用，但现有的方法在计算复杂性和精度上存在挑战。本文旨在通过GCI融合规则改进PMB滤波器的性能。

研究方法: 作者提出了一种近似方法，将PMB密度的幂近似为未归一化的PMB密度，并通过GCI融合规则将其转化为泊松多伯努利混合（PMBM）形式。该方法保留了PMBM的闭式表达，并在滤波步骤中保持其形式。

研究结果: 实验结果表明，该方法在分布式多目标滤波中优于其他方法，能够有效提升滤波精度和计算效率。

研究结论: 本文提出的基于GCI融合的分布式PMB滤波器为多目标滤波提供了一种高效且精确的解决方案，具有实际应用潜力。

中文摘要: 本文提出了一种基于广义协方差交集（GCI）融合规则的分布式泊松多伯努利（PMB）滤波器，用于分布式多目标滤波。由于两个PMB密度的精确GCI融合难以实现，我们提出了一种理论上的近似方法。具体而言，我们将PMB密度的幂近似为未归一化的PMB密度，这对应于PMB密度的上界。然后，GCI融合规则对应于两个未归一化PMB密度的归一化乘积。我们证明结果为泊松多伯努利混合（PMBM），可以闭式表达。每个滤波器中的未来预测和更新步骤保留了PMBM形式，可以在下一次融合步骤之前将其投影回PMB密度。实验结果表明，与其他分布式多目标滤波器相比，该方法具有显著优势。

</details>


### [202] [Latent Space Analysis for Melanoma Prevention](https://arxiv.org/abs/2506.18414)
**中文标题：基于潜在空间的黑色素瘤预防分析**

*Ciro Listone,Aniello Murano*

主要分类: cs.CV

摘要简述: 本文提出了一种基于条件变分自编码器的新方法，通过学习结构化潜在空间实现黑色素瘤的可解释风险评估，结合SVM分类器提升诊断性能，并支持视觉和几何解释。


<details>
  <summary>详细信息</summary>
研究动机: 黑色素瘤因其侵袭性和高死亡率成为重大健康威胁，现有深度学习模型多为二元分类，缺乏临床可解释性。本文旨在开发一种可解释的风险评估方法，以支持早期诊断和临床决策。

研究方法: 采用条件变分自编码器学习结构化潜在空间，捕捉皮肤病变的语义关系，实现连续风险评估；同时训练SVM分类器区分良性痣和黑色素瘤。

研究结果: 该方法在分类任务中表现优异，潜在空间支持视觉和几何解释，病变与已知黑色素瘤的空间接近性可作为风险指标，增强了AI辅助诊断的可信度。

研究结论: 该方法结合预测性能与临床适用性，通过透明和可解释的决策支持早期检测，并突出模糊病例，为AI辅助诊断提供了新思路。

中文摘要: 黑色素瘤因其侵袭性进展和高死亡率成为重大健康风险，亟需早期且可解释的诊断工具。尽管深度学习在皮肤病变分类中取得进展，但现有模型多仅提供二元输出，临床洞察有限。本研究提出一种超越分类的新方法，通过条件变分自编码器实现可解释的风险建模。该方法学习了一个结构化潜在空间，捕捉病变间的语义关系，支持对形态差异的细致连续评估。同时，基于该表示训练的SVM能有效区分良性痣和黑色素瘤，表现出稳健且一致的性能。更重要的是，学习的潜在空间支持对恶性的视觉和几何解释，病变与已知黑色素瘤的空间接近性可作为风险的有意义指标。该方法将预测性能与临床适用性结合，促进早期检测，突出模糊病例，并通过透明和可解释的决策增强对AI辅助诊断的信任。

</details>


### [203] [Benchmarking Foundation Models and Parameter-Efficient Fine-Tuning for Prognosis Prediction in Medical Imaging](https://arxiv.org/abs/2506.18434)
**中文标题：基础模型与参数高效微调在医学影像预后预测中的基准测试**

*Filippo Ruffini,Elena Mulero Ayllon,Linlin Shen,Paolo Soda,Valerio Guarrasi*

主要分类: cs.CV

摘要简述: 本文通过系统化基准测试，评估了卷积神经网络和基础模型在COVID-19患者预后预测中的迁移能力，并比较了多种微调策略的性能，包括传统方法和参数高效微调方法。


<details>
  <summary>详细信息</summary>
研究动机: 人工智能在医学影像预后预测中潜力巨大，但实际应用仍面临挑战。本研究旨在通过结构化基准测试，评估不同模型在数据稀缺和类别不平衡条件下的适应性和泛化能力，为临床实践提供高效、鲁棒的AI解决方案。

研究方法: 研究利用公开的胸部X光数据集，对卷积神经网络和基础模型进行了大规模比较分析。实验涵盖了多种微调策略，包括全微调、线性探测以及参数高效微调方法（如低秩适应、BitFit、VeRA和IA3），并在全数据和少样本学习场景下进行了评估。

研究结果: 研究结果表明，参数高效微调方法在数据稀缺和类别不平衡条件下表现优异，而基础模型（如CLIP和DINOv2）在预后任务中展现出较强的适应性和泛化能力。

研究结论: 本研究为医学影像预后预测提供了详细的基准测试结果，揭示了不同微调策略的优缺点，为临床实践中高效、鲁棒的AI解决方案的部署提供了重要参考。

中文摘要: 人工智能（AI）在改善医学影像预后预测方面具有巨大潜力，但其有效应用仍具挑战性。本研究引入了一个结构化基准，专门用于评估和比较卷积神经网络和基础模型在预测COVID-19患者临床结局中的迁移能力，利用了多种公开的胸部X光数据集。实验方法广泛探索了多种微调策略，包括传统的全微调和线性探测，以及先进的参数高效微调方法（如低秩适应、BitFit、VeRA和IA3）。评估在多种学习范式下进行，包括全数据场景和更符合临床实际的少样本学习场景，这对建模罕见疾病结局和快速出现的健康威胁至关重要。通过大规模比较分析，涵盖了从通用架构（如CLIP和DINOv2）到生物医学专用模型（如MedCLIP、BioMedCLIP和PubMedCLIP）的多样化预训练模型，我们严格评估了每个模型在数据稀缺和类别不平衡条件下适应和泛化到预后任务的能力。该基准旨在捕捉预后任务中常见的关键条件，包括数据集规模和类别分布的变化，为每种微调策略的优势和局限性提供了详细见解。这一全面且结构化的评估旨在为实际临床预后预测工作流程中高效、鲁棒且可泛化的AI驱动解决方案的部署和采用提供参考。

</details>


### [204] [Frequency-Domain Fusion Transformer for Image Inpainting](https://arxiv.org/abs/2506.18437)
**中文标题：基于频域融合Transformer的图像修复方法**

*Sijin He,Guangfeng Lin,Tao Li,Yajun Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer的图像修复方法，通过频域融合增强高频细节保留，解决了传统方法在处理复杂纹理和大遮挡时的不足。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像修复方法难以处理复杂纹理和大遮挡，而基于Transformer的方法虽具有全局建模能力，但高频细节保留不足且计算成本高。本文旨在通过频域融合解决这些问题。

研究方法: 提出了一种结合小波变换和Gabor滤波的注意力机制，增强多尺度结构建模和细节保留；设计了基于快速傅里叶变换的可学习频域滤波器，替代前馈网络以实现自适应噪声抑制和细节保留；采用四级编码器-解码器结构，并通过新型损失策略平衡全局语义和细节。

研究结果: 实验结果表明，该方法通过保留更多高频信息，显著提升了图像修复质量。

研究结论: 本文提出的频域融合Transformer方法在图像修复中表现出色，有效平衡了全局语义和高频细节，为复杂场景下的图像修复提供了新思路。

中文摘要: 图像修复在恢复缺失图像区域和支持高级视觉任务中起着至关重要的作用，但传统方法在处理复杂纹理和大遮挡时表现不佳。尽管基于Transformer的方法展现了强大的全局建模能力，但由于自注意力的低通特性，它们往往难以保留高频细节，且计算成本较高。为解决这些问题，本文提出了一种结合频域融合的Transformer图像修复方法。具体而言，引入了一种结合小波变换和Gabor滤波的注意力机制，以增强多尺度结构建模和细节保留。此外，设计了一种基于快速傅里叶变换的可学习频域滤波器，替代前馈网络以实现自适应噪声抑制和细节保留。模型采用四级编码器-解码器结构，并通过新型损失策略平衡全局语义和细节。实验结果表明，所提方法通过保留更多高频信息，有效提升了图像修复质量。

</details>


### [205] [OmniGen2: Exploration to Advanced Multimodal Generation](https://arxiv.org/abs/2506.18871)
**中文标题：OmniGen2：探索高级多模态生成**

*Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu*

主要分类: cs.CV

摘要简述: OmniGen2是一个多功能开源生成模型，支持文本到图像、图像编辑和上下文生成等任务。通过分离的文本和图像解码路径及解耦的图像标记器，它在保持文本生成能力的同时提升了多模态任务性能。训练中引入了反射机制和专用数据集，并在多个任务上取得竞争性结果。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态生成模型在统一处理文本和图像任务时存在性能折衷。OmniGen2旨在通过分离的解码路径和专用设计，提升多模态任务的灵活性和性能，同时避免重新适应VAE输入。

研究方法: OmniGen2采用分离的文本和图像解码路径，使用非共享参数和解耦的图像标记器。训练中开发了数据构建管道，并引入反射机制和专用数据集。新基准OmniContext用于评估上下文生成任务。

研究结果: OmniGen2在文本到图像和图像编辑等任务中表现优异，并在新基准OmniContext上达到开源模型中的最先进一致性。模型、代码和数据集将公开以支持研究。

研究结论: OmniGen2通过分离解码路径和专用设计，在多模态生成任务中实现了高性能和灵活性，为未来研究提供了开源支持。

中文摘要: 本文介绍了OmniGen2，这是一种多功能开源生成模型，旨在为文本到图像、图像编辑和上下文生成等多样化任务提供统一解决方案。与OmniGen v1不同，OmniGen2采用分离的文本和图像解码路径，使用非共享参数和解耦的图像标记器。这一设计使OmniGen2能够基于现有多模态理解模型构建，无需重新适应VAE输入，从而保留原始文本生成能力。为支持OmniGen2的训练，我们开发了涵盖图像编辑和上下文生成数据的综合数据构建管道。此外，我们为图像生成任务定制了反射机制，并基于OmniGen2策划了专用反射数据集。尽管参数规模相对较小，OmniGen2在文本到图像和图像编辑等多项任务基准上取得了竞争性结果。为进一步评估上下文生成（也称为主题驱动任务），我们引入了名为OmniContext的新基准。在一致性方面，OmniGen2在开源模型中达到了最先进性能。我们将发布模型、训练代码、数据集和数据构建管道，以支持该领域的未来研究。项目页面：https://vectorspacelab.github.io/OmniGen2；GitHub链接：https://github.com/VectorSpaceLab/OmniGen2

</details>


### [206] [CPAM: Context-Preserving Adaptive Manipulation for Zero-Shot Real Image Editing](https://arxiv.org/abs/2506.18438)
**中文标题：CPAM：保留上下文的自适应操作零样本真实图像编辑**

*Dinh-Khoi Vo,Thanh-Toan Do,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CPAM的零样本框架，用于复杂非刚性真实图像编辑，通过自适应调整自注意力机制和局部提取模块，有效保留对象和背景细节，并在新构建的IMBA基准测试中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到图像扩散模型在编辑自然图像时难以保持纹理和身份一致性，且需要大量微调。本文旨在解决这些问题，提出一种无需微调的零样本框架，以实现复杂非刚性对象的编辑。

研究方法: CPAM框架包含两个核心模块：1) 保护适应模块，通过调整自注意力机制独立控制对象和背景；2) 局部提取模块，减少交叉注意力机制中对非目标区域的干扰。此外，还引入了多种掩码引导策略以简化多样化图像编辑任务。

研究结果: 在专门设计的IMBA基准测试中，CPAM方法在人类评分中表现最佳，显著优于现有技术，能够有效保留对象形状、纹理和背景细节。

研究结论: CPAM是一种高效的零样本真实图像编辑框架，通过自适应注意力机制和局部提取技术，解决了复杂非刚性对象编辑中的挑战，为未来研究提供了新方向。

中文摘要: 使用文本描述在文本到图像扩散模型中编辑自然图像仍然是一个重大挑战，尤其是在实现一致生成和处理复杂非刚性对象方面。现有方法通常难以保持纹理和身份一致性，需要大量微调，并且在编辑特定空间区域或对象时保留背景细节方面存在局限性。本文提出了保留上下文的自适应操作（CPAM），一种用于复杂非刚性真实图像编辑的新型零样本框架。具体而言，我们提出了一种保护适应模块，通过调整自注意力机制有效保留并独立控制对象和背景。这确保了在编辑过程中使用掩码引导技术时，对象的形状、纹理和身份得以保持，同时背景不受干扰。此外，我们还开发了一个局部提取模块，以减少交叉注意力机制中对非目标修改区域的干扰。我们还引入了多种掩码引导策略，以简单的方式促进多样化图像编辑任务。在我们新构建的图像编辑基准数据集（IMBA）上进行的大量实验表明，我们提出的方法是人类评分者的首选，优于现有的最先进编辑技术。

</details>


### [207] [Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations](https://arxiv.org/abs/2506.18898)
**中文标题：视觉作为一种方言：通过文本对齐表示统一视觉理解与生成**

*Jiaming Han,Hao Chen,Yang Zhao,Hanyu Wang,Qi Zhao,Ziyan Yang,Hao He,Xiangyu Yue,Lu Jiang*

主要分类: cs.CV

摘要简述: 本文提出了一种多模态框架，通过文本对齐的离散语义表示统一视觉理解和生成。核心是文本对齐分词器（TA-Tok），将图像转换为离散标记，并通过扩展词汇表实现跨模态输入输出。实验表明，该方法在性能和效率上优于现有多模态LLM方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉理解和生成任务通常需要特定模态设计，缺乏统一的表示方法。本文旨在通过文本对齐的离散语义表示，实现视觉与文本的统一处理，简化多模态任务的设计。

研究方法: 提出文本对齐分词器（TA-Tok），将图像转换为离散标记，并扩展词汇表以支持跨模态输入输出。采用尺度自适应编码和解码平衡效率与细节，并利用两种互补的解码器（自回归模型和扩散模型）满足多样化需求。通过高级预训练任务增强模态融合。

研究结果: 实验表明，该方法在视觉理解和生成任务中表现优异，收敛速度更快且训练效率更高，优于现有多模态LLM方法。

研究结论: 本文提出的多模态框架通过文本对齐表示统一视觉理解和生成，简化了跨模态任务设计，并在性能和效率上取得显著提升。

中文摘要: 本文提出了一种多模态框架，试图通过共享的离散语义表示统一视觉理解和生成。其核心是文本对齐分词器（TA-Tok），它利用从大型语言模型（LLM）词汇表中投影的文本对齐码本将图像转换为离散标记。通过将视觉和文本整合到具有扩展词汇表的统一空间中，我们的多模态LLM（Tar）实现了通过共享接口的跨模态输入和输出，无需特定模态设计。此外，我们提出了尺度自适应编码和解码以平衡效率和视觉细节，以及生成式解码器以产生高保真视觉输出。为满足多样化解码需求，我们使用了两种互补的解码器：快速自回归模型和基于扩散的模型。为增强模态融合，我们研究了高级预训练任务，展示了在视觉理解和生成方面的改进。跨基准实验表明，Tar匹配或超越了现有多模态LLM方法，实现了更快的收敛和更高的训练效率。代码、模型和数据可在https://tar.csuhan.com获取。

</details>


### [208] [DIP: Unsupervised Dense In-Context Post-training of Visual Representations](https://arxiv.org/abs/2506.18463)
**中文标题：DIP：视觉表示的上下文密集无监督后训练**

*Sophia Sirko-Galouchenko,Spyros Gidaris,Antonin Vobecky,Andrei Bursuc,Nicolas Thome*

主要分类: cs.CV

摘要简述: DIP是一种新型无监督后训练方法，旨在通过模拟下游场景任务增强大规模预训练视觉编码器的密集图像表示，无需复杂自蒸馏架构，计算高效且性能优越。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖复杂的自蒸馏架构，难以高效提升密集图像表示。DIP旨在通过无监督方式，利用伪任务模拟下游场景，提升视觉编码器的性能。

研究方法: DIP采用元学习思想，通过预训练扩散模型和视觉编码器自动生成伪任务，训练视觉编码器以模拟下游场景任务，无需标注数据。

研究结果: DIP在多种下游场景理解任务中表现优异，超越初始视觉编码器和现有方法，计算效率高（单A100 GPU不到9小时）。

研究结论: DIP提供了一种简单、无监督且高效的方法，通过伪任务学习密集表示，显著提升视觉编码器在场景理解任务中的性能。

中文摘要: 我们提出了DIP，一种新型无监督后训练方法，旨在通过上下文场景任务增强大规模预训练视觉编码器的密集图像表示。与依赖复杂自蒸馏架构的现有方法不同，DIP受元学习启发，通过伪任务模拟下游场景任务来训练视觉编码器。为实现无标注数据的后训练，我们提出了一种结合预训练扩散模型和视觉编码器的自动任务生成机制。DIP简单、无监督且计算高效，单A100 GPU训练时间不足9小时。通过伪上下文任务学习密集表示，DIP在多种下游实际场景理解任务中表现优异，超越了初始视觉编码器和现有方法，为提升密集表示提供了实用有效的解决方案。代码见：https://github.com/sirkosophia/DIP

</details>


### [209] [AViLA: Asynchronous Vision-Language Agent for Streaming Multimodal Data Interaction](https://arxiv.org/abs/2506.18472)
**中文标题：AViLA：用于流式多模态数据交互的异步视觉语言代理**

*Gengyuan Zhang,Tanveer Hannan,Hermine Kleiner,Beste Aydemir,Xinyu Xie,Jian Lan,Thomas Seidl,Volker Tresp,Jindong Gu*

主要分类: cs.CV

摘要简述: 本文提出了一种异步视觉语言代理AViLA，用于处理流式多模态数据交互中的查询-证据异步问题，通过综合记忆保留、证据识别和证据触发模块，显著提升了响应准确性和时间感知能力。


<details>
  <summary>详细信息</summary>
研究动机: 在自动驾驶和具身代理等现实应用中，理想的视觉语言代理需要实时连接用户与物理世界，并基于动态数据流和用户临时查询提供准确及时的响应。然而，查询与支持证据通常异步到达，代理需基于历史、当前甚至未来数据作出响应，这提出了新的挑战。

研究方法: 作者提出了AViLA（异步视觉语言代理），包含三个关键模块：综合记忆保留、证据识别和证据触发。这些模块设计用于维护通用记忆，并在适当时间响应查询。此外，还提出了一个诊断基准，用于评估多模态大语言模型（MLLMs）处理流式数据交互的能力。

研究结果: 实验表明，现有模型往往无法在适当时间响应，而AViLA显著提升了响应准确性和时间感知能力。

研究结论: AViLA通过其独特设计有效解决了查询-证据异步问题，为流式多模态数据交互提供了更高效的解决方案。

中文摘要: 理想的视觉语言代理在自动驾驶和具身代理等现实应用中充当用户与周围物理世界的桥梁，并根据用户意图主动提供准确及时的响应。当代理与动态数据流和用户临时查询交互时，一个有趣的挑战出现了：查询的支持知识（即证据）通常与查询到达时间异步出现，代理需要基于历史数据、当前观察甚至未来数据流作出响应。我们将这一挑战称为查询-证据异步性，其中用户查询及其支持证据在流式设置中通常异步到达。这一设置不仅需要强大的推理能力，还需要保留过去观察并具有时间感知的响应能力。本文提出了一个诊断基准，用于评估多模态大语言模型（MLLMs）处理流式数据交互的能力。此外，我们提出了AViLA（异步视频语言代理），用于处理流式数据交互中的临时查询并提供时间感知响应。为此，AViLA包含三个关键模块：综合记忆保留、证据识别和证据触发，旨在维护通用记忆并随时准备及时响应查询。实验表明，现有模型往往无法在适当时间响应，而AViLA显著提升了准确性和时间感知能力。我们的代码和数据集将公开提供。

</details>


### [210] [Context Consistency Learning via Sentence Removal for Semi-Supervised Video Paragraph Grounding](https://arxiv.org/abs/2506.18476)
**中文标题：基于句子移除的上下文一致性学习用于半监督视频段落定位**

*Yaokun Zhong,Siyu Jiang,Jian Zhu,Jian-Fang Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的上下文一致性学习（CCL）框架，通过句子移除增强半监督视频段落定位（SSVPG）的性能。该方法结合一致性正则化和伪标签生成，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的半监督视频段落定位方法主要关注师生一致性学习和视频级对比损失，但忽略了通过扰动查询上下文生成强监督信号的重要性。本文旨在填补这一空白。

研究方法: 首先进行师生学习，学生模型输入经过强增强（句子移除）的样本，并从教师模型中学习强监督信号。随后基于生成的伪标签进行模型重训练，利用原始视图和增强视图预测的一致性作为标签置信度。

研究结果: 大量实验表明，CCL框架显著优于现有方法，性能提升明显。

研究结论: 通过结合一致性正则化和伪标签生成，CCL框架在半监督视频段落定位任务中表现出色，为未来研究提供了新思路。

中文摘要: 半监督视频段落定位（SSVPG）旨在从未修剪的视频中定位段落中的多个句子，且仅需有限的时序标注。现有方法主要关注师生一致性学习和视频级对比损失，但忽略了通过扰动查询上下文生成强监督信号的重要性。本文提出了一种新颖的上下文一致性学习（CCL）框架，统一了一致性正则化和伪标签生成的范式以增强半监督学习。具体而言，我们首先进行师生学习，学生模型输入经过强增强（句子移除）的样本，并从教师模型中学习强监督信号。随后基于生成的伪标签进行模型重训练，利用原始视图和增强视图预测的一致性作为标签置信度。大量实验表明，CCL显著优于现有方法。

</details>


### [211] [GANs vs. Diffusion Models for virtual staining with the HER2match dataset](https://arxiv.org/abs/2506.18484)
**中文标题：GANs与扩散模型在HER2match数据集上的虚拟染色性能比较**

*Pascal Klöckner,José Teixeira,Diana Montezuma,Jaime S. Cardoso,Hugo M. Horlings,Sara P. Oliveira*

主要分类: cs.CV

摘要简述: 本文介绍了首个公开的H&E和HER2双染色乳腺癌组织数据集HER2match，并比较了GANs和扩散模型在H&E-HER2染色转换中的性能。研究发现GANs整体表现优于扩散模型，仅BBDM模型表现接近。数据对齐对模型性能提升显著。


<details>
  <summary>详细信息</summary>
研究动机: 虚拟染色技术通过深度生成模型重建组织染色，比传统化学染色更快且成本更低。然而，H&E-HER2染色转换领域缺乏公开数据集，且不清楚哪种模型框架最适合该任务。

研究方法: 本文引入HER2match数据集，比较了多种GANs和扩散模型（包括新提出的BBDM模型）在H&E-HER2转换中的性能，并分析了数据对齐的重要性。

研究结果: 实验表明，GANs整体优于扩散模型，仅BBDM模型表现接近。使用HER2match数据集训练的模型视觉效果显著优于广泛使用的BCI数据集。

研究结论: 本研究提供了高质量的数据集和模型比较结果，为H&E-HER2染色转换研究提供了重要参考。

中文摘要: 虚拟染色是一种利用深度生成模型重建组织染色的技术，为传统组织化学染色提供了更快且更具成本效益的替代方案。针对H&E-HER2染色转换，尽管相关研究逐渐增多，但公开数据集的缺乏阻碍了该领域的进展。此外，目前尚不清楚哪种模型框架最适合该任务。本文介绍了HER2match数据集，这是首个公开的同一乳腺癌组织切片同时进行H&E和HER2染色的数据集。此外，我们比较了多种生成对抗网络（GANs）和扩散模型（DMs）的性能，并实现了一种新型的布朗桥扩散模型（BBDM）用于H&E-HER2转换。结果表明，总体上GANs优于DMs，仅BBDM模型表现接近。我们还强调了数据对齐的重要性，所有基于HER2match训练的模型在视觉效果上均显著优于广泛使用的连续切片BCI数据集。本研究提供了一个高质量的新数据集（待发表后公开），改进了模型训练和评估。此外，我们的框架比较为相关领域的研究人员提供了有价值的指导。

</details>


### [212] [ShowFlow: From Robust Single Concept to Condition-Free Multi-Concept Generation](https://arxiv.org/abs/2506.18493)
**中文标题：ShowFlow：从鲁棒的单概念生成到无条件的多概念生成**

*Trong-Vu Hoang,Quang-Binh Nguyen,Thanh-Toan Do,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: ShowFlow是一个全面的图像生成框架，分为ShowFlow-S和ShowFlow-M两部分，分别解决单概念和多概念生成的挑战。通过KronA-WED适配器和SAMA模块，实现了身份保持和提示对齐，无需额外条件即可生成多概念图像。


<details>
  <summary>详细信息</summary>
研究动机: 定制化图像生成在可控图像合成中仍具挑战性。单概念生成难以同时保持身份和提示对齐，而多概念生成依赖额外条件（如布局框或语义掩码）易导致身份丢失和概念遗漏。本文旨在解决这些问题。

研究方法: ShowFlow-S采用KronA-WED适配器（结合Kronecker适配器与权重和嵌入分解）和解耦学习方法，增强单概念生成。ShowFlow-M直接复用ShowFlow-S的模型，通过SAMA模块和布局一致性策略实现无额外条件的多概念生成。

研究结果: 实验和用户研究表明，ShowFlow在单概念和多概念生成中均表现优异，适用于广告和虚拟试衣等实际场景。

研究结论: ShowFlow通过创新的适配器和模块设计，有效解决了单概念和多概念生成的挑战，展示了在实际应用中的潜力。

中文摘要: 定制化图像生成仍是可控图像合成的核心挑战。在单概念生成中，同时保持身份保存和提示对齐具有难度；而在多概念场景中，仅依赖提示而无额外条件（如布局框或语义掩码）常导致身份丢失和概念遗漏。本文提出ShowFlow，一个全面解决这些问题的框架。ShowFlow-S用于单概念图像生成，ShowFlow-M用于多概念生成。ShowFlow-S引入KronA-WED适配器，结合Kronecker适配器与权重和嵌入分解，并采用解耦学习方法和新型注意力正则化目标以增强单概念生成。在此基础上，ShowFlow-M直接复用ShowFlow-S的学习模型，支持无需额外条件的多概念生成，整合了主题自适应匹配注意力（SAMA）和布局一致性策略作为即插即用模块。大量实验和用户研究验证了ShowFlow的有效性，突显其在广告和虚拟试衣等实际应用中的潜力。

</details>


### [213] [Biased Teacher, Balanced Student](https://arxiv.org/abs/2506.18496)
**中文标题：偏见的教师，平衡的学生**

*Seonghak Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种针对长尾数据分布的知识蒸馏框架LTKD，通过分解标准KD目标为组间和组内KL散度，校准教师模型的预测偏差，显著提升了学生模型在尾类上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 传统知识蒸馏（KD）在长尾数据分布中表现不佳，因为教师模型对头部类别的预测存在偏差，导致尾类监督不足。本文旨在解决这一问题，提出一种适用于类别不平衡场景的KD框架。

研究方法: LTKD将标准KD目标分解为组间和组内KL散度，分别对应类别组间和组内的预测分布。通过引入重新平衡的组间损失和均匀的组内损失，校准教师模型的预测偏差。

研究结果: 在CIFAR-100-LT、TinyImageNet-LT和ImageNet-LT上的实验表明，LTKD显著优于现有KD方法，整体准确率和尾类性能均有显著提升。

研究结论: LTKD能够有效从偏差教师模型中转移知识，适用于资源受限和类别不平衡的实际场景。

中文摘要: 知识蒸馏（KD）是一种广泛采用的模型压缩技术，其中紧凑的学生模型从预训练的大型教师模型的输出中学习。尽管在平衡设置中表现良好，传统KD在长尾数据分布中表现显著下降，因为教师模型倾向于偏向头部类别，对尾类别的监督有限。本文提出长尾知识蒸馏（LTKD），一种专为类别不平衡场景设计的新框架。我们首先将标准KD目标重新表述为两个部分：组间和组内Kullback-Leibler（KL）散度，分别对应类别组间和组内的预测分布。这种分解使我们能够识别和量化教师偏差的来源。为解决这些问题，我们引入了（1）重新平衡的组间损失，校准教师模型在组级别的预测；（2）均匀的组内损失，确保蒸馏过程中所有类别的贡献均等。在CIFAR-100-LT、TinyImageNet-LT和ImageNet-LT上的大量实验表明，LTKD始终优于现有KD方法，在整体准确率和尾类别性能上均取得显著提升。我们的结果表明，LTKD能够从偏差教师模型中实现有效的知识转移，使其成为资源受限和类别不平衡实际部署的有力候选方案。

</details>


### [214] [Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey](https://arxiv.org/abs/2506.18504)
**中文标题：视觉-语言模型在新领域的泛化：全面综述**

*Xinyao Li,Jingjing Li,Fengling Li,Lei Zhu,Yang Yang,Heng Tao Shen*

主要分类: cs.CV

摘要简述: 本文综述了视觉-语言模型（VLMs）在新领域的泛化方法，总结了当前研究的设置、方法、基准及结果，并探讨了VLMs与多模态大语言模型（MLLMs）的关系。


<details>
  <summary>详细信息</summary>
研究动机: 视觉-语言预训练模型在零样本任务中表现优异，但在特定领域或专业化任务中性能下降。本文旨在总结如何将VLMs的知识泛化到下游任务，并为未来研究提供清晰的方向。

研究方法: 通过分析典型VLM结构，将现有文献分为基于提示、基于参数和基于特征的方法，并总结了每类方法的差异与特点。同时回顾了迁移学习在VLM时代的应用，并介绍了相关基准测试。

研究结果: 本文系统梳理了VLMs泛化的研究进展，比较了不同方法的性能，并探讨了VLMs与MLLMs（如DeepSeek-VL）的关系与差异。

研究结论: 本文为视觉-语言研究提供了全面的泛化视角，为未来多模态研究指明了方向。

中文摘要: 近年来，视觉-语言预训练作为一种整合视觉与文本模态优势的技术，催生了强大的视觉-语言模型（VLMs）。这些模型利用网络规模的预训练数据，展现出强大的零样本能力。然而，在面对特定领域或专业化泛化任务时，其性能往往下降。为此，越来越多的研究致力于将VLMs中嵌入的丰富知识迁移或泛化到各种下游应用中。本综述旨在全面总结VLM文献中的泛化设置、方法、基准及结果。通过深入分析典型VLM结构，现有文献被归类为基于提示、基于参数和基于特征的方法，并根据迁移模块进一步总结和讨论了各类方法的差异与特点。同时，通过回顾典型的迁移学习（TL）设置，为VLM时代的TL提供了新的解读。此外，还介绍了VLM泛化的流行基准，并对所综述方法的性能进行了全面比较。随着大规模可泛化预训练的进展，本综述还探讨了VLMs与最新多模态大语言模型（MLLM，如DeepSeek-VL）的关系与差异。通过从新颖且实用的泛化视角系统梳理视觉-语言研究的激增文献，本综述为当前和未来的多模态研究提供了清晰的图景。

</details>


### [215] [MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis](https://arxiv.org/abs/2506.18512)
**中文标题：MedTVT-R1：一种赋能医疗推理与诊断的多模态大语言模型**

*Yuting Zhang,Kaishen Yuan,Hao Lu,Yutao Yue,Jintai Chen,Kaishun Wu*

主要分类: cs.CV

摘要简述: MedTVT-R1是一种新型多模态大语言模型（MLLM），旨在整合临床多模态数据以进行多疾病诊断和推理。通过构建MedTVT-QA数据集并采用GRPO强化微调，模型在多模态特征利用和多疾病诊断方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前医疗诊断方法多依赖单模态数据，难以全面理解复杂疾病。为解决这一问题，研究提出了一种能够整合多模态数据的模型，以提升诊断的准确性和可解释性。

研究方法: 研究构建了MedTVT-QA数据集，包含生理级解释和疾病级诊断的问答对。模型采用模态感知层捕捉模态间依赖关系，并通过GRPO强化微调和Jaccard奖励函数优化诊断推理。

研究结果: 实验结果表明，MedTVT-R1在多模态特征利用和多疾病诊断方面表现优越，具有生成诊断报告和共病推理的临床应用潜力。

研究结论: MedTVT-R1为多模态医疗诊断提供了高效解决方案，其数据集和代码已开源，有望推动临床应用的进一步发展。

中文摘要: 准确且可解释的多疾病诊断是医疗研究中的关键挑战，尤其是在利用异构多模态医疗数据时。现有方法多依赖单模态数据，限制了其对复杂疾病的全面理解能力。为此，我们提出了MedTVT-R1，一种新型多模态大语言模型（MLLM）框架，旨在整合临床多模态数据以进行推理和多疾病诊断。我们构建了MedTVT-QA数据集，该数据集通过证据链方法提供了生理级解释和疾病级诊断的问答对。MedTVT-R1采用模态感知层捕捉模态间依赖关系，并自适应加权模态贡献。此外，我们基于组相对策略优化（GRPO）的强化微调和Jaccard奖励函数，优化了诊断推理能力。实验结果表明，MedTVT-R1在多模态特征利用和多疾病诊断方面表现优越，为诊断报告生成和共病推理等临床应用提供了重要潜力。数据集和代码已发布于https://github.com/keke-nice/MedTVT-R1。

</details>


### [216] [Enhancing Image Restoration Transformer via Adaptive Translation Equivariance](https://arxiv.org/abs/2506.18520)
**中文标题：通过自适应平移等变性增强图像恢复Transformer**

*JiaKui Hu,Zhengjian Yao,Lujia Jin,Hangzhou He,Yanye Lu*

主要分类: cs.CV

摘要简述: 本文提出了一种自适应平移等变性的图像恢复Transformer（TEAFormer），通过滑动索引和组件堆叠策略解决传统注意力机制破坏平移等变性的问题，并在多种图像恢复任务中表现出优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代图像恢复Transformer中的注意力机制破坏了平移等变性，影响训练收敛和泛化能力。为解决这一问题，本文提出结合平移等变性的策略。

研究方法: 提出滑动索引和组件堆叠两种策略：滑动索引保持固定位置的算子响应（如滑动窗口注意力），组件堆叠允许并行或顺序排列平移等变算子。进一步设计自适应滑动索引机制，高效选择查询的键值对并与全局聚合键值对并行拼接。

研究结果: 提出的TEAFormer在多种图像恢复任务中表现出色，验证了其在效果、训练收敛和泛化能力上的优越性。

研究结论: TEAFormer通过自适应平移等变性机制有效解决了传统注意力机制的局限性，为图像恢复任务提供了高效且性能优越的解决方案。

中文摘要: 平移等变性是图像恢复中的基本归纳偏置，确保平移输入产生平移输出。现代恢复Transformer中的注意力机制破坏了这一性质，对训练收敛和泛化产生负面影响。为缓解此问题，我们提出两种结合平移等变性的关键策略：滑动索引和组件堆叠。滑动索引保持固定位置的算子响应（滑动窗口注意力是典型例子），而组件堆叠允许并行或顺序排列平移等变算子，从而构建复杂架构的同时保持平移等变性。然而，这些策略仍面临自注意力高计算成本与滑动窗口注意力固定感受野之间的设计困境。为此，我们开发了一种自适应滑动索引机制，高效选择每个查询的键值对，并与全局聚合键值对并行拼接。设计的网络称为平移等变自适应Transformer（TEAFormer），在多种图像恢复任务中进行了评估。结果凸显了其在效果、训练收敛和泛化上的优越性。

</details>


### [217] [Multi-Scale Representation of Follicular Lymphoma Pathology Images in a Single Hyperbolic Space](https://arxiv.org/abs/2506.18523)
**中文标题：在单一双曲空间中表示滤泡性淋巴瘤病理图像的多尺度特征**

*Kei Taguchi,Kazumasa Ohara,Tatsuya Yokota,Hiroaki Miyoshi,Noriaki Hashimoto,Ichiro Takeuchi,Hidekata Hontani*

主要分类: cs.CV

摘要简述: 提出一种利用自监督学习在双曲空间中表示恶性淋巴瘤病理图像的方法，涵盖从高分辨率细胞核到低分辨率组织的多尺度特征。


<details>
  <summary>详细信息</summary>
研究动机: 为了捕捉疾病进展中跨尺度的形态变化，研究旨在将组织和细胞核图像嵌入同一双曲空间，以编码其层次结构。

研究方法: 使用Poincaré球作为特征空间，通过自监督学习将组织和细胞核图像基于包含关系嵌入相近位置。

研究结果: 学习到的表征能够同时捕捉疾病状态和细胞类型的变化。

研究结论: 该方法有效编码了多尺度病理图像的层次结构，为疾病分析提供了新视角。

中文摘要: 我们提出了一种方法，通过自监督学习在单一双曲空间中表示恶性淋巴瘤病理图像，涵盖从高分辨率细胞核到低分辨率组织的多尺度特征。为了捕捉疾病进展中跨尺度的形态变化，我们的方法基于包含关系将组织和对应细胞核图像嵌入相近位置。使用Poincaré球作为特征空间，能够有效编码这种层次结构。学习到的表征同时捕捉了疾病状态和细胞类型的变化。

</details>


### [218] [Auto-Regressively Generating Multi-View Consistent Images](https://arxiv.org/abs/2506.18527)
**中文标题：自回归生成多视角一致图像**

*JiaKui Hu,Yuxiao Yang,Jialun Liu,Jinbo Wu,Chen Zhao,Yanye Lu*

主要分类: cs.CV

摘要简述: 本文提出了一种多视角自回归（MV-AR）方法，通过自回归模型逐步生成多视角一致的图像，解决了多视角图像生成中的一致性和多样性问题。


<details>
  <summary>详细信息</summary>
研究动机: 多视角图像生成在3D内容创作中至关重要，但现有方法在保持多视角一致性和处理多样化条件时面临挑战。本文旨在提出一种高效且通用的方法来解决这些问题。

研究方法: MV-AR方法利用自回归模型的逐词预测能力，逐步生成多视角图像。通过设计统一模型和条件注入模块（如文本、相机位姿、图像和形状），并结合渐进式训练策略和“Shuffle View”数据增强技术，提升了模型的性能和泛化能力。

研究结果: 实验表明，MV-AR能够生成一致的多视角图像，并在多种条件下表现优异，性能与领先的基于扩散的多视角图像生成模型相当。

研究结论: MV-AR方法在多视角图像生成任务中表现出色，通过自回归模型和渐进式训练策略，有效解决了多视角一致性和多样化条件的问题，为3D内容创作提供了有力工具。

中文摘要: 从人类指令生成多视角图像对3D内容创作至关重要。主要挑战在于保持多视角间的一致性以及在多样化条件下有效合成形状和纹理。本文提出多视角自回归（MV-AR）方法，利用自回归模型逐步生成与任意提示一致的多视角图像。首先，自回归模型的逐词预测能力显著提升了其在渐进式多视角合成中的效果。在生成广泛分离的视角时，MV-AR可以利用其所有先前视角提取有效参考信息。其次，我们提出了一种通过架构设计和训练策略适应多种提示的统一模型。为应对多种条件，我们引入了文本、相机位姿、图像和形状的条件注入模块。为同时处理多模态条件，采用了渐进式训练策略。该策略首先以文本到多视角（t2mv）模型为基线，通过随机丢弃和组合条件，逐步开发全面的X到多视角（X2mv）模型。最后，为缓解高质量数据有限导致的过拟合问题，提出了“Shuffle View”数据增强技术，从而将训练数据扩展了数个数量级。实验证明了MV-AR的性能和通用性，其能够在一系列条件下生成一致的多视角图像，并与领先的基于扩散的多视角图像生成模型表现相当。代码和模型将在https://github.com/MILab-PKU/MVAR发布。

</details>


### [219] [A Set-to-Set Distance Measure in Hyperbolic Space](https://arxiv.org/abs/2506.18529)
**中文标题：双曲空间中的集合间距离度量**

*Pengxiang Li,Wei Wu,Zhi Gao,Xiaomeng Fan,Peilin Yu,Yuwei Wu,Zhipeng Lu,Yunde Jia,Mehrtash Harandi*

主要分类: cs.CV

摘要简述: 本文提出了一种双曲空间中的集合间距离度量方法（HS2SD），结合全局和局部结构信息，用于计算双曲空间中集合的差异性，并在实体匹配和图像分类任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现实应用中需要比较双曲空间中的集合数据，而现有方法仅关注点对点距离，无法有效捕捉集合的全局和局部结构信息。因此，本文旨在提出一种能够同时整合这两种信息的距离度量方法。

研究方法: 提出的HS2SD方法通过双曲集合的爱因斯坦中点之间的测地距离捕捉全局结构，同时利用有限Thue-Morse序列的度和邻接矩阵近似拓扑结构以捕捉局部差异。

研究结果: 实验表明，HS2D在实体匹配、标准图像分类和小样本图像分类任务中优于现有方法，能够更准确地建模双曲集合的层次和复杂关系。

研究结论: HS2SD通过结合全局和局部结构信息，为双曲空间中的集合比较提供了更全面的距离度量，适用于多种实际任务。

中文摘要: 本文提出了一种双曲空间中的集合间距离度量方法（HS2SD），用于计算双曲空间中集合的差异性。虽然双曲空间中的点对点距离能有效捕捉数据点之间的层次关系，但许多实际应用需要比较双曲数据点的集合，其中集合的局部和全局结构承载了关键的语义信息。HS2SD通过整合全局和局部结构信息：全局结构通过双曲集合的爱因斯坦中点之间的测地距离，局部结构通过两个集合的拓扑特征。为了高效计算拓扑差异，我们证明使用有限Thue-Morse序列的度和邻接矩阵可以作为捕捉集合拓扑结构的稳健近似。通过考虑拓扑差异，HS2SD提供了对两个双曲集合关系的更细致理解。在实体匹配、标准图像分类和小样本图像分类上的实验表明，我们的距离度量方法通过有效建模双曲集合中固有的层次和复杂关系，优于现有方法。

</details>


### [220] [Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces](https://arxiv.org/abs/2506.18533)
**中文标题：双曲空间中多样化层次结构的几何感知距离度量**

*Pengxiang Li,Yuwei Wu,Zhi Gao,Xiaomeng Fan,Wei Wu,Zhipeng Lu,Yunde Jia,Mehrtash Harandi*

主要分类: cs.CV

摘要简述: 本文提出了一种几何感知的双曲空间距离度量方法，能够动态适应多样化的层次结构，显著提升了分类和少样本学习任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的双曲学习方法通常假设所有数据点具有统一的层次结构，并使用固定的距离度量，而现实中的层次结构具有多样性，这种假设过于局限。

研究方法: 通过为每对数据点生成定制化的投影和曲率，将其映射到合适的双曲空间，同时引入低秩分解方案和困难对挖掘机制以降低计算成本。

研究结果: 在标准图像分类、层次分类和少样本学习任务中，该方法显著优于固定距离度量的方法，尤其在少样本学习任务中性能提升超过5%。

研究结论: 自适应距离度量能更好地捕捉多样化的层次结构，可视化结果显示双曲空间中的类别边界更清晰，原型分离更明显。

中文摘要: 由于双曲空间在建模数据层次结构方面的优越能力，双曲空间学习日益受到关注。现有的大多数双曲学习方法对所有数据使用固定的距离度量，假设所有数据点具有统一的层次结构。然而，现实中的层次结构表现出显著的多样性，这种假设过于局限。本文提出了一种双曲空间中的几何感知距离度量，能够动态适应不同的层次结构。我们的方法通过为每对数据点生成定制化的投影和曲率，将其映射到合适的双曲空间。为了在不影响精度的情况下降低成对距离计算的计算成本，我们引入了改进的低秩分解方案和困难对挖掘机制。利用Talagrand的集中不等式，我们提出了低秩近似误差的上界，确保了理论上的鲁棒性。在标准图像分类（MNIST、CIFAR-10和CIFAR-100）、层次分类（5级CIFAR-100）和少样本学习任务（mini-ImageNet、tiered-ImageNet）上的大量实验证明了该方法的有效性。我们的方法在固定距离度量的学习方法中表现优异，尤其在少样本学习任务中，mini-ImageNet上的性能提升超过5%。结果表明，自适应距离度量能更好地捕捉多样化的层次结构，可视化结果显示双曲空间中的类别边界更清晰，原型分离更明显。

</details>


### [221] [Normality Prior Guided Multi-Semantic Fusion Network for Unsupervised Image Anomaly Detection](https://arxiv.org/abs/2506.18544)
**中文标题：正态性先验引导的多语义融合网络用于无监督图像异常检测**

*Muhao Xu,Xueying Zhou,Xizhan Gao,Weiye Song,Guang Feng,Sijie Niu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于正态性先验的多语义融合网络，用于无监督图像异常检测，通过引入正常样本的多语义特征指导异常重建，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于编码器-解码器的方法在检测逻辑异常时表现不佳，因为逻辑异常的局部特征与正常语义相似，但全局语义差异显著。神经网络泛化能力导致异常特征通过低维瓶颈传播，解码器可能以高保真度重建异常图像。

研究方法: 方法包括：1) 使用预训练的视觉-语言网络提取正常样本的全局语义；2) 构建可学习的语义码本存储正常样本特征；3) 融合多语义特征作为解码器输入，指导异常重建逼近正常模式。

研究结果: 在MVTec LOCO AD数据集上，该方法在像素级sPRO和图像级AUROC指标上分别提升了5.7%和2.6%，达到SOTA性能。

研究结论: 通过引入正态性先验和多语义融合，该方法有效解决了逻辑异常检测的挑战，显著提升了无监督异常检测的性能。

中文摘要: 近年来，检测逻辑异常比检测结构异常更具挑战性。现有的基于编码器-解码器的方法通常将输入压缩到低维瓶颈中，假设压缩过程可以有效抑制逻辑异常向解码器的传递。然而，逻辑异常的局部特征通常与正常语义相似，但其全局语义与正常模式显著偏离。由于神经网络的泛化能力，这些异常语义特征可能通过低维瓶颈传播，最终导致解码器以误导性的高保真度重建异常图像。为解决这一问题，我们提出了一种新颖的正态性先验引导的多语义融合网络用于无监督异常检测。该方法不直接向解码器提供压缩瓶颈，而是将正常样本的多语义特征引入重建过程。具体而言，我们首先通过预训练的视觉-语言网络提取正常样本的抽象全局语义，然后构建可学习的语义码本，通过向量量化存储正常样本的代表性特征向量。最后，将上述多语义特征融合并作为解码器输入，指导异常重建逼近正常模式。大量实验验证了该方法的有效性，在MVTec LOCO AD数据集上，像素级sPRO和图像级AUROC分别提升了5.7%和2.6%，达到SOTA性能。源代码见https://github.com/Xmh-L/NPGMF。

</details>


### [222] [Object-aware Sound Source Localization via Audio-Visual Scene Understanding](https://arxiv.org/abs/2506.18557)
**中文标题：基于视听场景理解的对象感知声音源定位**

*Sung Jin Um,Dongjin Kim,Sangmin Lee,Jung Uk Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多模态大语言模型（MLLMs）的声音源定位框架，通过生成细粒度语义信息区分发声物体与静默物体，并引入两种新型损失函数（OCA和ORI），显著提升了复杂场景中的定位精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有声音源定位方法在复杂场景中表现不佳，尤其是当视觉相似的静默物体存在时。这主要是由于它们依赖简单的视听对应关系，无法区分发声物体与静默物体的语义差异。

研究方法: 提出了一种利用MLLMs生成详细上下文信息的框架，明确区分发声前景物体与静默背景物体。同时，设计了两种新型损失函数：对象感知对比对齐（OCA）损失和对象区域隔离（ORI）损失。

研究结果: 在MUSIC和VGG-Sound数据集上的实验表明，该方法在单源和多源定位场景中均显著优于现有方法。

研究结论: 通过结合MLLMs和新型损失函数，本文方法有效解决了复杂场景中声音源定位的挑战，为视听场景理解提供了新思路。

中文摘要: 视听声音源定位任务旨在通过结合视觉和音频线索，在视觉场景中空间定位发声物体。然而，现有方法在复杂场景中难以准确定位发声物体，尤其是当视觉相似的静默物体共存时。这一局限性主要源于它们依赖简单的视听对应关系，无法捕捉发声物体与静默物体之间的细粒度语义差异。为解决这些问题，我们提出了一种新颖的声音源定位框架，利用多模态大语言模型（MLLMs）生成详细的上下文信息，明确区分发声前景物体与静默背景物体。为有效整合这些信息，我们引入了两种新型损失函数：对象感知对比对齐（OCA）损失和对象区域隔离（ORI）损失。在MUSIC和VGG-Sound数据集上的大量实验结果表明，我们的方法在单源和多源定位场景中均显著优于现有方法。代码和生成的详细上下文信息可在以下网址获取：https://github.com/VisualAIKHU/OA-SSL。

</details>


### [223] [VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning](https://arxiv.org/abs/2506.18564)
**中文标题：VQ-Insight：通过渐进式视觉强化学习教授视觉语言模型理解AI生成视频质量**

*Xuanyu Zhang,Weiqi Li,Shijie Zhao,Junlin Li,Li Zhang,Jian Zhang*

主要分类: cs.CV

摘要简述: VQ-Insight提出了一种基于渐进式视觉强化学习的视频质量评估框架，通过多维度评分奖励和时序建模奖励，显著提升了AI生成视频的质量评估性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI生成视频的质量评估面临泛化能力不足、缺乏时序感知、依赖大规模标注数据等问题。现有方法多基于监督微调的视觉语言模型，但往往无法有效结合理解和生成。VQ-Insight旨在解决这些问题。

研究方法: VQ-Insight采用渐进式学习方案，包括图像质量预热、任务特定时序学习和与视频生成模型的联合优化。设计了多维度评分奖励、偏好比较奖励和时序建模奖励，以提升评估的泛化和专业化能力。

研究结果: 实验表明，VQ-Insight在偏好比较、多维度评分和自然视频评分中均优于现有基线方法，显著提升了视频生成任务的效果。

研究结论: VQ-Insight通过渐进式视觉强化学习和多维度奖励设计，为AI生成视频质量评估提供了高效解决方案，显著优于现有方法。

中文摘要: 近年来，AI生成内容（AIGC）的进展催生了强大的文本到视频生成模型。然而，由于泛化能力有限、缺乏时序感知、依赖大规模标注数据以及与生成模型交互不足等问题，评估AIGC生成视频的质量仍然具有挑战性。当前方法多基于视觉语言模型（VLMs）的监督微调，但需要大规模标注数据且往往无法有效结合理解和生成。为解决这些问题，我们提出了VQ-Insight，一种新型推理式VLM框架，用于AIGC视频质量评估。我们的方法包括：（1）渐进式视频质量学习方案，结合图像质量预热、任务特定时序学习和与视频生成模型的联合优化；（2）设计多维度评分奖励、偏好比较奖励和时序建模奖励，以提升视频质量评估的泛化和专业化能力。大量实验表明，VQ-Insight在偏好比较、多维度评分和自然视频评分中均优于现有基线方法，为视频生成任务带来了显著改进。

</details>


### [224] [VisualChef: Generating Visual Aids in Cooking via Mask Inpainting](https://arxiv.org/abs/2506.18569)
**中文标题：VisualChef：通过掩码修复生成烹饪中的视觉辅助工具**

*Oleh Kuzyk,Zuoyue Li,Marc Pollefeys,Xi Wang*

主要分类: cs.CV

摘要简述: VisualChef是一种通过掩码修复技术生成烹饪场景中视觉辅助工具的方法，旨在提供一致的视觉指导，简化视觉与文本对齐过程。


<details>
  <summary>详细信息</summary>
研究动机: 烹饪过程中缺乏一致的视觉指导，现有方法依赖复杂的文本描述和额外标注，VisualChef旨在通过视觉掩码简化这一过程。

研究方法: VisualChef通过掩码视觉定位识别动作相关对象并分类，生成反映动作和结果的图像，同时保持环境一致性，并提出自动化提取高质量帧的流程。

研究结果: 在三个第一人称视频数据集上的定量和定性评估显示，VisualChef优于现有方法。

研究结论: VisualChef通过掩码修复技术简化视觉辅助生成，为烹饪场景提供更直观的视觉支持。

中文摘要: 烹饪不仅需要遵循指令，还需要理解、执行和监控每一步，这一过程在缺乏视觉指导时可能具有挑战性。尽管食谱图像和视频提供了有用的提示，但它们通常在焦点、工具和设置上缺乏一致性。为了更好地支持烹饪过程，我们提出了VisualChef，一种为烹饪场景生成上下文视觉辅助工具的方法。给定初始帧和指定动作，VisualChef生成描绘动作执行和对象最终外观的图像，同时保留初始帧的环境。先前的工作旨在通过生成详细的文本描述来引导图像生成，这需要细粒度的视觉-文本对齐并涉及额外标注。相比之下，VisualChef通过基于掩码的视觉定位简化了对齐过程。我们的关键见解是识别动作相关对象并对其进行分类，以实现反映预期动作和结果的针对性修改，同时保持环境一致性。此外，我们提出了一种自动化流程来提取高质量的初始、动作和最终状态帧。我们在三个第一人称视频数据集上对VisualChef进行了定量和定性评估，并展示了其相对于现有方法的改进。

</details>


### [225] [2D Triangle Splatting for Direct Differentiable Mesh Training](https://arxiv.org/abs/2506.18575)
**中文标题：用于直接可微分网格训练的2D三角形面片方法**

*Kaifeng Sheng,Zheng Zhou,Yingliang Peng,Qianwei Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为2D三角形面片（2DTS）的新方法，用于替代3D高斯基元，直接训练高保真网格。该方法结合了连续体积建模的优势和离散网格结构，实验显示其性能优于现有高斯基元和网格重建方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于3D高斯基元的可微分渲染方法在多视图图像重建中表现出色，但在渲染速度和高级渲染效果（如重新光照和阴影渲染）上仍不及基于网格的模型。本文旨在提出一种更高效且高质量的重建方法。

研究方法: 本文提出2D三角形面片（2DTS）方法，用2D三角形面片替代3D高斯基元，形成离散的类网格结构，同时保留连续体积建模的优势。通过引入紧凑性参数，实现了直接训练高保真网格。

研究结果: 实验结果表明，2DTS方法在未调整紧凑性的情况下，其保真度优于当前最先进的高斯基元方法，且重建的网格视觉质量优于现有网格重建方法。

研究结论: 2DTS方法结合了连续体积建模和离散网格的优势，为高保真网格训练提供了一种高效且高质量的解决方案，优于现有方法。

中文摘要: 基于3D高斯基元的可微分渲染已成为从多视图图像重建高保真3D场景的强大方法。尽管其性能优于基于NeRF的方法，但在渲染速度和高级渲染效果（如重新光照和阴影渲染）方面仍不及基于网格的模型。本文提出2D三角形面片（2DTS）方法，用2D三角形面片替代3D高斯基元。这种表示自然形成离散的类网格结构，同时保留了连续体积建模的优势。通过在三角形基元中引入紧凑性参数，我们实现了直接训练高保真网格。实验结果表明，我们的三角形方法（未调整紧凑性）在保真度上优于当前最先进的高斯基元方法。此外，我们的方法重建的网格在视觉质量上优于现有的网格重建方法。

</details>


### [226] [Resampling Augmentation for Time Series Contrastive Learning: Application to Remote Sensing](https://arxiv.org/abs/2506.18587)
**中文标题：时间序列对比学习的重采样增强方法：在遥感中的应用**

*Antoine Saget,Baptiste Lafabregue,Antoine Cornuéjols,Pierre Gançarski*

主要分类: cs.CV

摘要简述: 本文提出了一种基于重采样的时间序列对比学习增强方法，用于遥感领域，通过上采样和提取不重叠子序列生成正样本对，显著提升了农业分类任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 由于卫星图像时间序列（SITS）数据丰富但标注稀缺，对比自监督预训练成为利用未标注数据的有效工具，但时间序列的数据增强设计仍具挑战性。

研究方法: 提出了一种新颖的重采样增强策略，通过上采样时间序列并提取不重叠子序列以生成正样本对，同时保持时间覆盖范围。

研究结果: 在多个农业分类基准测试中，该方法优于抖动、调整大小和掩码等常见方法，并在S2-Agri100数据集上实现了最先进的性能，无需使用空间信息或时间编码。

研究结论: 该方法为遥感时间序列提供了一种简单而有效的对比学习增强策略，性能优于复杂的基于掩码的自监督学习框架。

中文摘要: 鉴于卫星图像时间序列（SITS）数据丰富而标注稀缺，对比自监督预训练成为利用大量未标注数据的自然选择。然而，为时间序列设计有效的数据增强方法仍具挑战性。我们提出了一种基于重采样的增强策略，通过上采样时间序列并提取不重叠子序列生成正样本对，同时保持时间覆盖范围。我们在多个农业分类基准测试中使用Sentinel-2图像验证了该方法，结果表明其优于抖动、调整大小和掩码等常见方法。此外，我们在S2-Agri100数据集上实现了最先进的性能，且未使用空间信息或时间编码，超越了更复杂的基于掩码的自监督学习框架。我们的方法为遥感时间序列提供了一种简单而有效的对比学习增强策略。

</details>


### [227] [SpaNN: Detecting Multiple Adversarial Patches on CNNs by Spanning Saliency Thresholds](https://arxiv.org/abs/2506.18591)
**中文标题：SpaNN：通过跨度显著性阈值检测CNN上的多个对抗性补丁**

*Mauricio Byrd Victorica,György Dán,Henrik Sandberg*

主要分类: cs.CV

摘要简述: SpaNN是一种新型对抗性补丁检测器，其计算复杂度与补丁数量无关，通过多显著性阈值构建二值化特征图集合，并利用聚类特征进行分类，显著优于现有防御方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有防御方法主要针对单补丁攻击，对多补丁攻击效果不佳或计算复杂度高。SpaNN旨在解决这一问题，提供一种高效且鲁棒的多补丁攻击检测方法。

研究方法: SpaNN通过应用一组显著性阈值对受害者模型的第一个卷积层激活进行二值化，构建特征图集合，然后进行聚类并将聚类特征输入分类器进行攻击检测。

研究结果: 在四个广泛使用的数据集上，SpaNN在目标检测和图像分类任务中分别比现有最佳防御方法高出11和27个百分点。

研究结论: SpaNN通过多显著性阈值和聚类特征的方法，显著提升了多补丁攻击的检测性能，且计算复杂度与补丁数量无关。

中文摘要: 最先进的卷积神经网络模型在目标检测和图像分类任务中容易受到物理可实现的对抗性扰动（如补丁攻击）的影响。现有防御方法主要针对单补丁攻击，对多补丁攻击的敏感性尚未解决，或在最坏情况下计算不可行或效率低下。本文提出SpaNN，一种计算复杂度与预期补丁数量无关的攻击检测器。该检测器的关键创新在于通过应用一组显著性阈值对受害者模型的第一个卷积层激活进行二值化，构建特征图集合，然后进行聚类并将聚类特征用于攻击检测分类。与现有检测器不同，SpaNN不依赖固定显著性阈值识别对抗区域，从而对白盒对抗攻击具有鲁棒性。我们在四个广泛使用的数据集上评估SpaNN，结果显示在目标检测和图像分类任务中，SpaNN分别比现有最佳防御方法高出11和27个百分点。代码发布于https://github.com/gerkbyrd/SpaNN。

</details>


### [228] [RDPO: Real Data Preference Optimization for Physics Consistency Video Generation](https://arxiv.org/abs/2506.18655)
**中文标题：RDPO：基于真实数据偏好优化的物理一致性视频生成**

*Wenxu Qian,Chaoyue Wang,Hou Peng,Zhiyu Tan,Hao Li,Anxiang Zeng*

主要分类: cs.CV

摘要简述: RDPO是一种无需标注的框架，通过从真实视频中提取物理先验知识，显著提升生成视频的动作连贯性和物理真实性。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频生成技术在视觉质量上取得了显著进展，但在真实物理规律的再现上仍存在不足。传统方法依赖昂贵的人工标注数据或奖励模型，难以实现。RDPO旨在通过直接从真实视频中学习物理先验，解决这一问题。

研究方法: RDPO利用预训练生成器反向采样真实视频序列，自动构建物理正确性可区分的偏好对，并通过多阶段迭代训练逐步提升生成器对物理规律的遵循能力。

研究结果: 在多个基准测试和人工评估中，RDPO显著提升了生成视频的动作连贯性和物理真实性，取得了多维度改进。

研究结论: RDPO通过直接从真实视频中提取动态信息，为视频生成中的物理一致性提供了高效且无需标注的解决方案。

中文摘要: 视频生成技术在视觉质量上取得了显著进展，但真实物理规律的再现仍具挑战性。基于偏好的模型后训练可能提升物理一致性，但依赖昂贵的人工标注数据或尚不可行的奖励模型。为解决这些问题，我们提出了真实数据偏好优化（RDPO），一种无需标注的框架，直接从真实视频中提取物理先验。具体而言，RDPO利用预训练生成器反向采样真实视频序列，自动构建物理正确性可区分的偏好对，并通过多阶段迭代训练逐步提升生成器对物理规律的遵循能力。得益于从真实视频中探索的动态信息，RDPO显著提升了生成视频的动作连贯性和物理真实性。在多个基准测试和人工评估中，RDPO实现了多维度改进。本文的源代码和演示可在以下网址获取：https://wwenxu.github.io/RDPO/

</details>


### [229] [Historical Report Guided Bi-modal Concurrent Learning for Pathology Report Generation](https://arxiv.org/abs/2506.18658)
**中文标题：基于历史报告引导的双模态并发学习病理报告生成**

*Ling Zhang,Boxiang Yun,Qingli Li,Yan Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于历史报告引导的双模态并发学习框架（BiGen），用于病理报告生成，解决了全切片图像（WSI）中语义内容不足和信息冗余的问题。通过知识检索机制和双模态学习策略，显著提升了报告生成质量和分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动化病理报告生成面临两大挑战：视觉特征缺乏语义内容，以及WSI中存在信息冗余。本文旨在模拟病理学家的诊断推理，通过引入历史报告和双模态学习，提升报告的语义丰富性和准确性。

研究方法: 1. 知识检索机制：从预建的医学知识库中匹配高注意力区域，提供丰富的语义内容。2. 双模态并发学习策略：通过可学习的视觉和文本标记动态提取关键特征，并利用权重共享层实现跨模态对齐。多模态解码器整合两种模态生成全面诊断报告。

研究结果: 在PathText（BRCA）数据集上的实验表明，BiGen在NLP指标上相对提升了7.4%，在Her-2预测的分类指标上提升了19.1%，优于现有方法。消融研究验证了所提模块的必要性。

研究结论: BiGen框架通过引入历史报告和双模态学习，有效解决了WSI中的语义不足和信息冗余问题，显著提升了病理报告生成的质量和分类性能。

中文摘要: 自动化病理报告生成面临全切片图像（WSI）中视觉特征缺乏语义内容和信息冗余两大挑战。为此，我们提出了一种模拟病理学家诊断推理的历史报告引导双模态并发学习框架（BiGen），包括：（1）知识检索机制，通过匹配高注意力区域从预建医学知识库中获取相关语义内容；（2）双模态并发学习策略，通过可学习的视觉和文本标记动态提取关键特征，并利用权重共享层实现跨模态对齐。多模态解码器整合两种模态生成全面诊断报告。在PathText（BRCA）数据集上的实验表明，BiGen在NLP指标上相对提升了7.4%，在Her-2预测的分类指标上提升了19.1%，优于现有方法。消融研究验证了所提模块的必要性，表明BiGen能够提供丰富的语义内容并抑制信息冗余。代码已公开：https://github.com/DeepMed-Lab-ECNU/BiGen。

</details>


### [230] [Benchmarking histopathology foundation models in a multi-center dataset for skin cancer subtyping](https://arxiv.org/abs/2506.18668)
**中文标题：在多中心数据集中对组织病理学基础模型进行皮肤癌亚型分类的基准测试**

*Pablo Meseguer,Rocío del Amor,Valery Naranjo*

主要分类: cs.CV

摘要简述: 本文提出了一种新的基准测试方法，用于评估组织病理学基础模型在多中心皮肤癌亚型分类任务中的表现，并引入了一种新的指标FM-SI来衡量模型对分布偏移的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 当前组织病理学基础模型（FM）的多样性使得需要设计真实世界的挑战来评估其有效性。本文旨在填补这一空白，通过多中心数据集评估FM在皮肤癌亚型分类任务中的表现。

研究方法: 利用AI4SkIN多中心数据集，将FM作为补丁级特征提取器，结合多实例学习（MIL）分类框架进行评估，并提出了新的指标FM-SI来衡量模型的一致性。

研究结果: 实验表明，提取较少偏见的特征可以提高分类性能，特别是在基于相似性的MIL分类器中表现更优。

研究结论: 本文提出的基准测试方法和FM-SI指标为评估组织病理学基础模型提供了有效工具，并展示了其在皮肤癌亚型分类任务中的潜力。

中文摘要: 通过在大型领域内数据集上进行预训练，组织病理学基础模型（FM）能够学习任务无关的数据表示，从而增强在下游任务中的迁移学习能力。在计算病理学中，由于切片图像的千兆像素规模，自动化的全切片图像分析需要多实例学习（MIL）框架。组织病理学FM的多样性凸显了设计真实世界挑战以评估其有效性的必要性。为了填补这一空白，我们的工作提出了一种新的基准测试方法，用于评估FM作为补丁级特征提取器在MIL分类框架中的表现。为此，我们利用了AI4SkIN数据集，这是一个包含具有挑战性的皮肤梭形细胞肿瘤亚型的多中心队列。我们还定义了基础模型-轮廓指数（FM-SI），这是一种新的指标，用于衡量模型对分布偏移的一致性。实验表明，提取较少偏见的特征可以提高分类性能，特别是在基于相似性的MIL分类器中。

</details>


### [231] [MedSeg-R: Medical Image Segmentation with Clinical Reasoning](https://arxiv.org/abs/2506.18669)
**中文标题：MedSeg-R：基于临床推理的医学图像分割**

*Hao Shao,Qibin Hou*

主要分类: cs.CV

摘要简述: MedSeg-R是一种基于临床推理的轻量级双阶段框架，通过融合医学报告的语义先验信息，显著提升了医学图像分割中对小病灶的敏感性和分割精度。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割面临解剖结构边界模糊、前景与背景类别不平衡等问题，现有方法依赖局部线索或用户提示，缺乏语义先验，难以处理低对比度或重叠目标。

研究方法: MedSeg-R采用双阶段设计：认知阶段解析医学报告生成结构化语义先验（位置、纹理、形状），并通过Transformer融合；感知阶段利用这些先验调制SAM主干网络，通过空间注意力、动态卷积和可变形采样优化分割。

研究结果: 在挑战性基准测试中，MedSeg-R显著提升了重叠和模糊结构的分割性能，对小病灶的敏感性大幅提高。

研究结论: MedSeg-R通过嵌入临床推理的语义先验，有效解决了医学图像分割中的复杂问题，展示了与SAM系统的兼容性。

中文摘要: 医学图像分割因解剖结构边界模糊及前景与背景类别严重不平衡而具有挑战性，尤其影响小病灶的划分。现有方法（如编码器-解码器网络和基于提示的Segment Anything Model变体）过度依赖局部线索或用户提示，缺乏集成的语义先验，难以泛化至低对比度或重叠目标。为此，我们提出MedSeg-R，一种受临床推理启发的轻量级双阶段框架。其认知阶段将医学报告解析为结构化语义先验（位置、纹理、形状），并通过Transformer块融合。在感知阶段，这些先验调制SAM主干：空间注意力突出可能的病灶区域，动态卷积调整特征滤波器以适应预期纹理，可变形采样优化空间支持。通过早期嵌入这种细粒度指导，MedSeg-R解开了类别间混淆并放大了少数类线索，显著提升了对小病灶的敏感性。在挑战性基准测试中，MedSeg-R在重叠和模糊结构上实现了大幅Dice提升，展示了与基于SAM系统的即插即用兼容性。

</details>


### [232] [Reconstructing Tornadoes in 3D with Gaussian Splatting](https://arxiv.org/abs/2506.18677)
**中文标题：基于高斯泼溅技术的龙卷风三维重建**

*Adam Yang,Nadula Kadawedduwa,Tianfu Wang,Maria Molina,Christopher Metzler*

主要分类: cs.CV

摘要简述: 本文提出了一种利用3D高斯泼溅技术（3DGS）重建实验室小型龙卷风三维结构的方法，并发布了一个多视角数据集用于开发和验证相关工具。


<details>
  <summary>详细信息</summary>
研究动机: 准确重建龙卷风的三维结构对理解和应对这一高破坏性天气现象至关重要。然而，目前缺乏用于开发和验证3D重建技术的受控龙卷风数据集。

研究方法: 作者捕获并发布了一个实验室小型龙卷风的多视角数据集，并利用3D高斯泼溅技术（3DGS）重建其三维结构。

研究结果: 实验证明，3DGS能够有效重建并可视化龙卷风的三维结构。

研究结论: 本研究为龙卷风的三维重建提供了新的数据集和方法，为未来相关研究奠定了基础。

中文摘要: 准确重建龙卷风的三维结构对于理解和应对这一高破坏性天气现象至关重要。尽管现代三维场景重建技术（如3D高斯泼溅技术，3DGS）可能为龙卷风的三维结构重建提供有价值的工具，但目前我们严重缺乏用于开发和验证这些工具的受控龙卷风数据集。在本研究中，我们捕获并发布了一个实验室小型龙卷风的多视角数据集。我们证明，利用3DGS可以有效重建并可视化该龙卷风的三维结构。

</details>


### [233] [MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation](https://arxiv.org/abs/2506.18678)
**中文标题：MCN-SLAM：基于混合隐式神经场景表示的多智能体协作神经SLAM**

*Tianchen Deng,Guole Shen,Xun Chen,Shenghai Yuan,Hongming Shen,Guohao Peng,Zhenyu Wu,Jingchuan Wang,Lihua Xie,Danwei Wang,Hesheng Wang,Weidong Chen*

主要分类: cs.CV

摘要简述: 本文提出了首个分布式多智能体协作神经SLAM框架MCN-SLAM，结合混合隐式神经场景表示、分布式相机跟踪、局部到全局闭环以及在线蒸馏技术，解决了现有单智能体SLAM在大场景和长序列中的局限性，并提出了首个真实世界的密集SLAM数据集DES。


<details>
  <summary>详细信息</summary>
研究动机: 现有隐式SLAM算法仅适用于单智能体场景，且在大规模场景和长序列中存在困难，而基于NeRF的多智能体SLAM框架无法满足通信带宽限制。因此，本文旨在解决这些问题，并填补真实世界数据集的空白。

研究方法: 提出了一种混合场景表示方法（triplane-grid联合表示），设计了局部到全局闭环方法以实现一致性，并开发了在线蒸馏技术用于子地图融合。此外，创建了首个真实世界密集SLAM数据集DES，涵盖单智能体和多智能体场景。

研究结果: 实验表明，所提方法在映射、跟踪和通信方面均表现优越，且DES数据集为SLAM、3D重建和视觉基础模型的研究提供了高质量的真实数据支持。

研究结论: MCN-SLAM框架在多智能体协作SLAM中表现出色，解决了现有技术的局限性，同时DES数据集的发布将推动相关领域的研究发展。

中文摘要: 神经隐式场景表示在密集视觉SLAM中展现出潜力，但现有隐式SLAM算法仅适用于单智能体场景，且在大规模场景和长序列中表现不佳。基于NeRF的多智能体SLAM框架无法满足通信带宽限制。为此，我们提出了首个分布式多智能体协作神经SLAM框架，结合混合场景表示、分布式相机跟踪、局部到全局闭环以及在线蒸馏技术。提出了一种新颖的triplane-grid联合场景表示方法以改进场景重建，设计了局部到全局闭环方法以实现一致性，并开发了在线蒸馏技术用于子地图融合。此外，我们提出了首个真实世界密集SLAM数据集DES，涵盖单智能体和多智能体场景，从小房间到大规模户外场景，提供高精度的3D网格和连续时间相机轨迹真值。该数据集将推动SLAM、3D重建和视觉基础模型的研究。实验表明，所提方法在映射、跟踪和通信方面均表现优越。数据集和代码将在https://github.com/dtc111111/mcnslam开源。

</details>


### [234] [MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning for Active Contour Optimization in Medical Image Segmentation](https://arxiv.org/abs/2506.18679)
**中文标题：MARL-MambaContour：释放多智能体深度强化学习在医学图像分割中主动轮廓优化的潜力**

*Ruicheng Zhang,Yu Sun,Zeyu Zhang,Jinai Li,Xiaofan Liu,Au Hoi Fan,Haowei Guo,Puxin Yan*

主要分类: cs.CV

摘要简述: MARL-MambaContour是一种基于多智能体强化学习的医学图像分割框架，通过将每个轮廓点建模为自主智能体，优化轮廓生成过程，解决了传统像素级方法在拓扑一致性和结构感知上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 传统医学图像分割方法（如像素级方法）缺乏对目标边界的拓扑约束和整体结构感知能力，尤其是在处理模糊边缘和复杂形态时表现不佳。因此，研究团队提出了一种基于多智能体强化学习的框架，以生成更精确且拓扑一致的轮廓。

研究方法: MARL-MambaContour将每个轮廓点建模为自主智能体，通过迭代调整位置以对齐目标边界。采用改进的Soft Actor-Critic（SAC）算法优化调整过程，并引入熵正则化调整机制（ERAM）平衡探索与轮廓平滑性。此外，框架还包含基于Mamba的策略网络，采用双向交叉注意力隐藏状态融合机制（BCHFM）提升长程建模能力。

研究结果: 在五个多样化医学图像数据集上的实验表明，MARL-MambaContour实现了最先进的性能，能够准确适应模糊边缘和复杂形态，展示了其在临床应用中作为高精度和鲁棒工具的潜力。

研究结论: MARL-MambaContour通过多智能体强化学习框架，显著提升了医学图像分割的精度和鲁棒性，为临床诊断提供了更可靠的解决方案。

中文摘要: 我们提出了MARL-MambaContour，这是首个基于多智能体强化学习（MARL）的轮廓医学图像分割框架。该方法将分割任务重新定义为多智能体协作任务，专注于生成拓扑一致的目标轮廓，解决了传统像素级方法在拓扑约束和整体结构感知上的不足。每个轮廓点被建模为自主智能体，通过迭代调整位置以精确对齐目标边界，从而适应医学图像中常见的模糊边缘和复杂形态。这一调整过程由改进的Soft Actor-Critic（SAC）算法优化，并进一步通过熵正则化调整机制（ERAM）动态平衡智能体探索与轮廓平滑性。此外，框架还整合了基于Mamba的策略网络，采用新颖的双向交叉注意力隐藏状态融合机制（BCHFM），缓解了状态空间模型中长程建模可能引发的记忆混淆问题，从而促进更准确的智能体间信息交换和决策制定。在五个多样化医学图像数据集上的广泛实验表明，MARL-MambaContour实现了最先进的性能，展示了其作为高精度和鲁棒临床应用的潜力。

</details>


### [235] [Multi-Scale Spectral Attention Module-based Hyperspectral Segmentation in Autonomous Driving Scenarios](https://arxiv.org/abs/2506.18682)
**中文标题：基于多尺度光谱注意力模块的自动驾驶场景高光谱分割**

*Imad Ali Shah,Jiarong Li,Tim Brophy,Martin Glavin,Edward Jones,Enda Ward,Brian Deegan*

主要分类: cs.CV

摘要简述: 本文提出了一种多尺度光谱注意力模块（MSAM），通过结合不同核大小的1D卷积和自适应特征聚合机制，显著提升了高光谱图像在自动驾驶场景中的语义分割性能，计算开销极小。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶（AD）中高光谱成像（HSI）在复杂天气和光照条件下具有环境感知潜力，但其高维光谱数据处理效率低下。本文旨在解决这一问题。

研究方法: 提出多尺度光谱注意力模块（MSAM），包含三个并行1D卷积（核大小为1至11）和自适应特征聚合机制，并将其集成到UNet的跳跃连接中（UNet-MSAM）。

研究结果: 在HyKo-VIS v2、HSI-Drive v2和Hyperspectral City v2数据集上，UNet-MSAM平均提升3.61%的mIoU和3.80%的mF1，计算开销仅增加0.02%参数和0.82%GFLOPS。

研究结论: 多尺度核组合优于单尺度配置，证明了HSI在AD中的潜力，并为设计鲁棒的多尺度光谱特征提取器提供了实用见解。

中文摘要: 自动驾驶（AD）的最新进展凸显了高光谱成像（HSI）在复杂天气和光照条件下增强环境感知的潜力，但其高维光谱数据的高效处理仍是一大挑战。本文提出了一种多尺度光谱注意力模块（MSAM），通过三个核大小从1到11的并行1D卷积结合自适应特征聚合机制，增强了光谱特征提取。将MSAM集成到UNet的跳跃连接（UNet-SC）中，提出的UNet-MSAM在多个HSI数据集（HyKo-VIS v2、HSI-Drive v2和Hyperspectral City v2）上显著提升了语义分割性能。综合实验表明，在极小的计算开销（平均增加0.02%参数和0.82%GFLOPS）下，UNet-MSAM始终优于UNet-SC，平均提升3.61%的mIoU和3.80%的mF1。通过大量消融研究，我们证实多尺度核组合优于单尺度配置。这些发现证明了HSI处理在AD中的潜力，并为设计适用于实际应用的鲁棒多尺度光谱特征提取器提供了宝贵见解。

</details>


### [236] [SIM-Net: A Multimodal Fusion Network Using Inferred 3D Object Shape Point Clouds from RGB Images for 2D Classification](https://arxiv.org/abs/2506.18683)
**中文标题：SIM-Net：一种利用RGB图像推断的3D物体形状点云进行多模态融合的2D分类网络**

*Youcef Sklab,Hanane Ariouat,Eric Chenin,Edi Prifti,Jean-Daniel Zucker*

主要分类: cs.CV

摘要简述: SIM-Net是一种新型2D图像分类架构，通过从RGB图像推断3D点云，融合纹理和几何特征，显著提升分类性能，尤其在复杂背景和遮挡场景下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统2D图像分类模型在处理复杂背景、非目标元素和遮挡时性能受限。SIM-Net旨在通过融合3D几何特征，提升分类准确性，特别适用于数字化植物标本等挑战性任务。

研究方法: SIM-Net通过像素到点的转换将2D物体掩码转化为3D点云，结合CNN提取的2D图像特征和PointNet提取的几何特征，在统一潜在空间中进行融合。

研究结果: 在植物标本数据集上，SIM-Net比ResNet101准确率提升9.9%，F-score提升12.3%，并优于多种基于Transformer的先进架构。

研究结论: SIM-Net通过融合3D结构推理显著提升了2D图像分类性能，证明了多模态特征融合的有效性。

中文摘要: 我们提出了形状-图像多模态网络（SIM-Net），这是一种新型的2D图像分类架构，通过直接从RGB图像推断3D点云表示来融合纹理和几何特征。其核心贡献在于将2D物体掩码转换为3D点云的像素到点变换，从而提升分类性能。SIM-Net特别适用于处理背景复杂、非目标元素和遮挡的数字化植物标本分类任务。为解决这些问题，SIM-Net采用基于分割的预处理步骤提取物体掩码，再生成3D点云。架构包括用于2D图像特征的CNN编码器和用于几何特征的基于PointNet的编码器，两者在统一潜在空间中融合。在植物标本数据集上的实验表明，SIM-Net始终优于ResNet101，准确率和F-score分别提升9.9%和12.3%，并超越多种基于Transformer的先进架构，凸显了将3D结构推理融入2D图像分类任务的优势。

</details>


### [237] [Matrix-Game: Interactive World Foundation Model](https://arxiv.org/abs/2506.18701)
**中文标题：Matrix-Game：交互式世界基础模型**

*Yifan Zhang,Chunli Peng,Boyang Wang,Puyi Wang,Qingcheng Zhu,Fei Kang,Biao Jiang,Zedong Gao,Eric Li,Yang Liu,Yahui Zhou*

主要分类: cs.CV

摘要简述: Matrix-Game是一种交互式世界基础模型，通过两阶段训练实现可控游戏世界生成，性能优于现有开源模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前游戏世界生成模型在可控性和物理一致性方面存在不足，Matrix-Game旨在通过大规模数据和可控生成范式解决这些问题。

研究方法: 采用两阶段训练：大规模无标签预训练理解环境，再通过动作标签训练生成交互视频。模型基于参考图像、运动上下文和用户动作进行可控生成。

研究结果: Matrix-Game在视觉质量、时间连贯性、动作可控性和物理规则理解方面均优于现有模型（如Oasis和MineWorld），人类评估也证实其优越性。

研究结论: Matrix-Game为交互式图像到世界生成提供了高效解决方案，未来将开源模型和评测基准以推动相关研究。

中文摘要: 我们介绍了Matrix-Game，一种用于可控游戏世界生成的交互式世界基础模型。Matrix-Game采用两阶段训练流程：首先进行大规模无标签预训练以理解环境，随后通过动作标签训练生成交互视频。为此，我们构建了Matrix-Game-MC数据集，包含超过2,700小时的无标签游戏视频片段和1,000小时的高质量标签片段（附带细粒度键盘和鼠标动作标注）。模型采用可控的图像到世界生成范式，基于参考图像、运动上下文和用户动作进行生成。拥有超过170亿参数的Matrix-Game能够精确控制角色动作和相机移动，同时保持高视觉质量和时间连贯性。为评估性能，我们开发了GameWorld Score评测基准，衡量Minecraft世界生成的视觉质量、时间质量、动作可控性和物理规则理解。大量实验表明，Matrix-Game在所有指标上均优于现有开源模型（包括Oasis和MineWorld），尤其在可控性和物理一致性方面表现突出。双盲人类评估进一步证实了Matrix-Game的优越性，突显其在多样化游戏场景中生成感知真实且精确可控视频的能力。为推动交互式图像到世界生成的研究，我们将开源Matrix-Game模型权重和GameWorld Score评测基准。

</details>


### [238] [Including Semantic Information via Word Embeddings for Skeleton-based Action Recognition](https://arxiv.org/abs/2506.18721)
**中文标题：基于词嵌入语义信息的骨架动作识别方法**

*Dustin Aganian,Erik Franze,Markus Eisenbach,Horst-Michael Gross*

主要分类: cs.CV

摘要简述: 本文提出一种基于骨架的动作识别新方法，通过词嵌入引入语义信息，显著提升了分类性能与泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 在工业4.0中，人机协作需要高效的动作识别技术。传统骨架方法常忽略关键点语义信息，限制了复杂交互中的效果。本文旨在通过语义信息增强骨架动作识别。

研究方法: 提出一种新方法，用语义体积替代传统独热编码，通过词嵌入编码语义信息，捕捉关节与物体间的有意义关系。

研究结果: 在多个装配数据集上的实验表明，该方法显著提升了分类性能，并支持不同骨架类型和物体类别，增强了泛化能力。

研究结论: 研究表明，引入语义信息能有效提升骨架动作识别在动态多样环境中的表现，为未来研究提供了新方向。

中文摘要: 高效的人体动作识别在工业4.0中广泛应用于协作机器人以辅助装配任务。然而，传统的基于骨架的方法常丢失关键点语义信息，限制了其在复杂交互中的效果。本文提出了一种新颖的骨架动作识别方法，通过词嵌入编码语义信息来丰富输入表示。我们的方法用语义体积替代独热编码，使模型能够捕捉关节与物体之间的有意义关系。通过在多个装配数据集上的广泛实验，我们证明该方法显著提升了分类性能，并通过同时支持不同骨架类型和物体类别增强了泛化能力。我们的发现凸显了引入语义信息以增强动态多样环境中骨架动作识别的潜力。

</details>


### [239] [Deep CNN Face Matchers Inherently Support Revocable Biometric Templates](https://arxiv.org/abs/2506.18731)
**中文标题：深度CNN人脸匹配器天生支持可撤销的生物特征模板**

*Aman Bhatta,Michael C. King,Kevin W. Bowyer*

主要分类: cs.CV

摘要简述: 现代深度CNN人脸匹配器天生支持可撤销的生物特征模板，解决了生物特征认证中模板被泄露后无法撤销的问题。


<details>
  <summary>详细信息</summary>
研究动机: 生物特征认证的一个常见问题是，一旦生物特征模板被泄露，用户无法撤销或更换。可撤销生物特征的概念旨在解决这一问题。

研究方法: 通过生成多个具有等效识别能力但模板不兼容的深度CNN人脸匹配器模型，实现生物特征模板的可撤销性。同时探索了Vision Transformer（ViT）在此类系统中的适用性。

研究结果: 实验表明，深度CNN模型可以生成无限数量的等效识别能力模型，且模板间兼容性极低，泄露的模板在撤销后几乎无价值。ViT在此场景下表现不如ResNet。

研究结论: 深度CNN人脸匹配器天生支持可撤销生物特征模板，为生物特征认证的安全性提供了新的解决方案。

中文摘要: 生物特征认证的一个常见批评是，如果个体的生物特征被泄露，个体将无法挽回。可撤销生物特征的概念正是为了解决这一问题而提出的。一个生物特征方案是可撤销的，如果个体可以撤销当前的注册，使泄露的生物特征模板失效，并重新注册一个新的具有相似识别能力的模板。我们证明，现代深度CNN人脸匹配器天生支持一种强大的可撤销生物特征方案。对于给定的最先进深度CNN主干和训练集，可以生成无限数量的不同人脸匹配器模型，这些模型具有（1）等效的识别能力，以及（2）极不兼容的生物特征模板。这种等效识别能力甚至扩展到生成具有相同形状和相似度维度分布的冒名顶替和真实分布，这意味着这些模型可以共享一个用于1/10,000错误匹配率的相似度阈值。不同模型实例的生物特征模板兼容性极低，以至于同一人物的跨实例相似度得分通常低于不同人物的同实例相似度得分。也就是说，被撤销的泄露生物特征模板在尝试匹配重新注册的身份时，其价值低于平均冒名顶替模板。我们还探讨了在本文提出的可撤销生物特征系统中使用基于Vision Transformer（ViT）主干的人脸匹配器的可行性，并证明其不如典型的基于ResNet的深度CNN主干。

</details>


### [240] [USVTrack: USV-Based 4D Radar-Camera Tracking Dataset for Autonomous Driving in Inland Waterways](https://arxiv.org/abs/2506.18737)
**中文标题：USVTrack：基于无人水面车辆的4D雷达-相机跟踪数据集，用于内陆水域自动驾驶**

*Shanliang Yao,Runwei Guan,Yi Ni,Sen Xu,Yong Yue,Xiaohui Zhu,Ryan Wen Liu*

主要分类: cs.CV

摘要简述: USVTrack是首个为新一代水上交通系统自动驾驶设计的4D雷达-相机跟踪数据集，通过无人水面车辆（USV）在复杂水域环境中收集数据，并提出了一种简单有效的雷达-相机匹配方法（RCM），显著提升了目标跟踪的准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 内陆水域的目标跟踪对水上交通、观光旅游、环境监测和救援等应用至关重要。然而，现有数据集和跟踪方法在复杂水域环境中的表现不足，因此需要开发专门的数据集和方法以提升自动驾驶系统的性能。

研究方法: 研究团队利用配备4D雷达、单目相机、GPS和IMU的无人水面车辆（USV）收集了多样化的水域场景数据，构建了USVTrack数据集。此外，提出了一种雷达-相机匹配方法（RCM），可集成到常用的两阶段关联跟踪器中。

研究结果: 实验结果表明，RCM方法显著提高了目标跟踪的准确性和可靠性，尤其是在复杂水域环境中。USVTrack数据集公开可用，为相关研究提供了丰富的资源。

研究结论: USVTrack数据集和RCM方法为水上自动驾驶系统的目标跟踪提供了重要支持，未来可进一步优化和扩展以适应更多场景。

中文摘要: 内陆水域的目标跟踪在水上交通、观光旅游、环境监测和救援等应用中具有重要作用。我们的无人水面车辆（USV）配备了4D雷达、单目相机、GPS和IMU，能够在复杂水域环境中实现稳健的目标跟踪。通过这些传感器，USV收集了全面的目标跟踪数据，并构建了USVTrack数据集，这是首个为新一代水上交通系统自动驾驶设计的4D雷达-相机跟踪数据集。USVTrack数据集涵盖了多样化的水域场景，包括不同时间段、天气和光照条件。此外，我们提出了一种简单但有效的雷达-相机匹配方法（RCM），可集成到常用的两阶段关联跟踪器中。实验结果表明，RCM方法显著提升了目标跟踪的准确性和可靠性。USVTrack数据集已在https://usvtrack.github.io公开。

</details>


### [241] [SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving](https://arxiv.org/abs/2506.18785)
**中文标题：SWA-SOP：自动驾驶中语义占用预测的空间感知窗口注意力**

*Helin Cao,Rafael Materla,Sven Behnke*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SWA-SOP的空间感知窗口注意力机制，用于自动驾驶中的语义占用预测，通过引入局部空间上下文显著提升了稀疏或遮挡区域的预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶感知系统依赖LiDAR和摄像头等传感器感知3D环境，但由于遮挡和数据稀疏性，这些传感器常无法捕获完整信息。现有基于Transformer的语义占用预测方法在注意力计算中缺乏对空间结构的显式建模，导致几何感知能力有限，在稀疏或遮挡区域表现不佳。

研究方法: 本文提出了一种空间感知窗口注意力（SWA）机制，将局部空间上下文融入注意力计算中，显著提升了场景补全能力。此外，SWA还被集成到基于摄像头的语义占用预测流程中，验证了其跨模态的通用性。

研究结果: SWA在基于LiDAR的语义占用预测基准测试中取得了最先进的性能，同时在基于摄像头的流程中也表现出一致的性能提升。

研究结论: SWA-SOP通过引入空间感知窗口注意力机制，有效解决了稀疏或遮挡区域的预测问题，为自动驾驶感知系统提供了更全面的环境理解能力。

中文摘要: 自动驾驶感知系统依赖LiDAR和摄像头等传感器感知3D环境，但由于遮挡和数据稀疏性，这些传感器常无法捕获完整信息。语义占用预测（SOP）通过推断未观测区域的占用和语义信息来解决这一挑战。现有的基于Transformer的SOP方法在注意力计算中缺乏对空间结构的显式建模，导致几何感知能力有限，在稀疏或遮挡区域表现不佳。为此，我们提出了一种空间感知窗口注意力（SWA）机制，将局部空间上下文融入注意力计算中。SWA显著提升了场景补全能力，并在基于LiDAR的SOP基准测试中取得了最先进的性能。我们还通过将SWA集成到基于摄像头的SOP流程中验证了其通用性，结果表明其在跨模态中也能带来一致的性能提升。

</details>


### [242] [3D Arena: An Open Platform for Generative 3D Evaluation](https://arxiv.org/abs/2506.18787)
**中文标题：3D Arena：一个用于生成式3D评估的开放平台**

*Dylan Ebert*

主要分类: cs.CV

摘要简述: 3D Arena是一个开放平台，通过大规模人类偏好收集评估生成式3D模型，填补了自动指标与人类感知之间的差距，并提供了可靠的模型排名和人类偏好分析。


<details>
  <summary>详细信息</summary>
研究动机: 当前生成式3D模型的评估存在自动指标与人类感知质量不匹配的问题，现有基准测试依赖图像指标或几何测量，无法全面反映感知吸引力和实际效用。

研究方法: 3D Arena通过成对比较收集大规模人类偏好数据，使用统计欺诈检测确保用户真实性，并基于ELO排名系统评估模型。

研究结果: 平台收集了123,243票用户偏好数据，发现高斯溅射输出比网格模型更具优势（16.6 ELO），带纹理模型比无纹理模型更受欢迎（144.1 ELO）。

研究结论: 3D Arena成为生成式3D评估的标杆，提出了多标准评估、任务导向评估和格式感知比较等改进建议，推动了以人为中心的评估方法发展。

中文摘要: 评估生成式3D模型仍然具有挑战性，因为自动指标与人类对质量的感知之间存在不一致。当前的基准测试依赖忽略3D结构的基于图像的指标，或无法捕捉感知吸引力和实际效用的几何测量。为了填补这一空白，我们提出了3D Arena，这是一个通过成对比较收集大规模人类偏好的开放平台，用于评估图像到3D的生成模型。
自2024年6月推出以来，该平台已从8,096名用户收集了123,243票，覆盖19个最先进的模型，建立了生成式3D领域最大规模的人类偏好评估。我们贡献了包含100个评估提示的iso3d数据集，并通过统计欺诈检测实现了99.75%的用户真实性。基于ELO的排名系统提供了可靠的模型评估，使该平台成为公认的评估资源。
通过对偏好数据的分析，我们揭示了人类偏好的模式。研究发现，高斯溅射输出比网格模型具有16.6 ELO的优势，带纹理模型比无纹理模型具有144.1 ELO的优势。我们提出了改进评估方法的建议，包括多标准评估、任务导向评估和格式感知比较。平台的社区参与使3D Arena成为该领域的标杆，同时推动了以人为中心的生成式3D评估的理解。

</details>


### [243] [Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers](https://arxiv.org/abs/2506.18791)
**中文标题：聚焦注意力：面向数据直观的轻量级视觉变换器**

*Suyash Gaurav,Muhammad Farhan Humayun,Jukka Heikkonen,Jatin Chaudhary*

主要分类: cs.CV

摘要简述: 本文提出了一种基于超像素的补丁池化（SPPP）技术和轻量潜在注意力（LLA）模块，旨在降低视觉变换器的计算和内存需求，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉变换器在广泛领域取得成功，但其依赖大量计算和内存资源，且任务特定迁移学习困难。这些问题源于计算密集的自注意力机制，导致能效低下。

研究方法: 提出SPPP技术生成上下文感知的语义丰富补丁嵌入，降低架构复杂性；引入LLA模块，通过潜在令牌集成减少注意力模块的时间和空间复杂度。

研究结果: 实验表明，该方法显著提升计算效率，性能与最先进方法相当，适合边缘部署的能效优化变换器。

研究结论: SPPP和LLA模块的结合有效解决了视觉变换器的资源需求问题，为轻量化和高效能变换器提供了可行方案。

中文摘要: 视觉变换器的发展使其广泛应用于不同领域，但其依赖大规模数据集预训练的计算和内存资源，以及任务特定迁移学习的困难，仍是主要挑战。这些问题主要源于计算密集的自注意力机制。为解决这些问题，我们提出了一种新颖的超像素补丁池化（SPPP）技术，生成上下文感知且语义丰富的补丁嵌入，有效降低架构复杂性并提升效率。此外，我们在流程中引入了轻量潜在注意力（LLA）模块，通过潜在令牌集成到注意力机制中，显著减少注意力模块的时间和空间复杂度。通过结合数据直观的补丁嵌入和动态位置编码，我们的方法自适应调节交叉注意力过程，聚焦信息丰富区域，同时保持全局语义结构。这种定向注意力提升了训练效率并加速收敛。值得注意的是，SPPP模块轻量且易于集成到现有变换器架构中。大量实验表明，我们提出的架构在计算效率方面显著提升，同时性能与最先进方法相当，突显了其适用于边缘部署的能效优化变换器的潜力。（代码已发布于GitHub仓库：https://github.com/zser092/Focused-Attention-ViT）。

</details>


### [244] [ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs](https://arxiv.org/abs/2506.18792)
**中文标题：ViDAR：基于单目输入的视频扩散感知4D重建**

*Michal Nazarczuk,Sibi Catley-Chandar,Thomas Tanay,Zhensong Zhang,Gregory Slabaugh,Eduardo Pérez-Pellitero*

主要分类: cs.CV

摘要简述: ViDAR是一种新颖的4D重建框架，利用个性化扩散模型生成伪多视角监督信号，通过高斯泼溅表示训练，显著提升动态场景的视觉质量和几何一致性。


<details>
  <summary>详细信息</summary>
研究动机: 动态新视角合成任务在单目视频输入下极具挑战性，因为从运动中分离结构是不适定的且监督信号稀缺。ViDAR旨在解决这一问题，通过扩散模型生成伪多视角监督信号，提升重建质量。

研究方法: ViDAR结合个性化扩散模型生成伪多视角监督信号，训练高斯泼溅表示。通过场景特定特征条件化，恢复细节并减少单目模糊性带来的伪影。提出扩散感知损失函数和相机姿态优化策略，对齐合成视图与场景几何。

研究结果: 在DyCheck基准测试中，ViDAR在视觉质量和几何一致性上均优于现有方法，尤其在动态区域表现突出，并提供了新的运动丰富场景重建性能比较基准。

研究结论: ViDAR通过扩散模型生成的伪多视角监督信号，显著提升了动态场景的4D重建质量，为单目输入下的动态新视角合成任务提供了有效解决方案。

中文摘要: 动态新视角合成任务旨在从任意视角生成运动主体的逼真视图。在依赖单目视频时，这一任务尤为困难，因为从运动中分离结构是不适定的且监督信号稀缺。我们提出了视频扩散感知重建（ViDAR），一种新颖的4D重建框架，利用个性化扩散模型生成伪多视角监督信号，用于训练高斯泼溅表示。通过场景特定特征条件化，ViDAR恢复了细粒度的外观细节，同时减少了单目模糊性引入的伪影。为解决基于扩散的监督的时空不一致性，我们提出了扩散感知损失函数和相机姿态优化策略，对齐合成视图与底层场景几何。在具有极端视角变化的DyCheck基准测试中，ViDAR在视觉质量和几何一致性上均优于所有现有基线方法。我们进一步展示了ViDAR在动态区域上的显著改进，并提供了一个新的基准用于比较运动丰富场景部分的重建性能。项目页面：https://vidar-4d.github.io

</details>


### [245] [OC-SOP: Enhancing Vision-Based 3D Semantic Occupancy Prediction by Object-Centric Awareness](https://arxiv.org/abs/2506.18798)
**中文标题：OC-SOP：通过对象中心感知增强基于视觉的3D语义占据预测**

*Helin Cao,Sven Behnke*

主要分类: cs.CV

摘要简述: 论文提出了一种名为OC-SOP的框架，通过结合目标检测的高层对象信息，显著提升了基于视觉的3D语义占据预测的准确性，尤其在动态前景物体上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶感知面临环境遮挡和场景数据不完整的挑战。传统的基于相机的方法对所有类别一视同仁，主要依赖局部特征，导致动态前景物体的预测效果不佳。因此，需要一种能够整合对象中心信息的方法来提升预测性能。

研究方法: 论文提出了OC-SOP框架，通过一个检测分支提取高层对象中心信息，并将其整合到语义占据预测流程中，从而增强对前景物体的预测能力。

研究结果: OC-SOP显著提升了前景物体的预测准确性，并在SemanticKITTI数据集上实现了所有类别的领先性能。

研究结论: OC-SOP通过整合对象中心信息，有效解决了传统方法在动态前景物体上的不足，为自动驾驶感知提供了更优的解决方案。

中文摘要: 自动驾驶感知因环境中的遮挡和场景数据不完整而面临重大挑战。为解决这些问题，提出了语义占据预测（SOP）任务，旨在从图像中联合推断场景的几何和语义标签。然而，传统的基于相机的方法通常对所有类别一视同仁，并主要依赖局部特征，导致预测效果不佳，尤其是对动态前景物体。为此，我们提出了对象中心SOP（OC-SOP）框架，该框架通过检测分支提取高层对象中心信息，并将其整合到语义占据预测流程中。这种对象中心的整合显著提升了前景物体的预测准确性，并在SemanticKITTI数据集上实现了所有类别的领先性能。

</details>


### [246] [PicoSAM2: Low-Latency Segmentation In-Sensor for Edge Vision Applications](https://arxiv.org/abs/2506.18807)
**中文标题：PicoSAM2：面向边缘视觉应用的传感器内低延迟分割**

*Pietro Bonazzi,Nicola Farronato,Stefan Zihlmann,Haotong Qi,Michele Magno*

主要分类: cs.CV

摘要简述: PicoSAM2是一种轻量级、低延迟的分割模型，专为边缘和传感器内执行优化，适用于实时隐私保护应用。


<details>
  <summary>详细信息</summary>
研究动机: 实时、设备端的分割对于延迟敏感和隐私保护的应用（如智能眼镜和物联网设备）至关重要。

研究方法: 基于深度可分离U-Net，结合知识蒸馏和固定点提示编码，从Segment Anything Model 2（SAM2）中学习。

研究结果: 在COCO和LVIS上分别达到51.9%和44.9%的mIoU，量化模型（1.22MB）在IMX500上运行时间为14.3毫秒，满足传感器内部署的内存和计算限制。

研究结论: 高效的、可提示的分割模型可直接在相机上实现隐私保护的视觉处理，无需云端或主机处理。

中文摘要: 实时、设备端的分割对于延迟敏感和隐私保护的应用（如智能眼镜和物联网设备）至关重要。我们介绍了PicoSAM2，一种轻量级（1.3M参数，336M MACs）的可提示分割模型，专为边缘和传感器内执行优化，包括索尼IMX500。它基于深度可分离U-Net，通过知识蒸馏和固定点提示编码从Segment Anything Model 2（SAM2）中学习。在COCO和LVIS上，分别达到51.9%和44.9%的mIoU。量化模型（1.22MB）在IMX500上运行时间为14.3毫秒，实现了86 MACs/cycle，是唯一满足传感器内部署内存和计算限制的模型。蒸馏将LVIS性能提升了+3.5% mIoU和+5.1% mAP。这些结果表明，高效的、可提示的分割可直接在相机上实现，无需云端或主机处理，从而实现隐私保护的视觉应用。

</details>


### [247] [4Real-Video-V2: Fused View-Time Attention and Feedforward Reconstruction for 4D Scene Generation](https://arxiv.org/abs/2506.18839)
**中文标题：4Real-Video-V2：融合视角-时间注意力与前馈重建的4D场景生成**

*Chaoyang Wang,Ashkan Mirzaei,Vidit Goel,Willi Menapace,Aliaksandr Siarohin,Avalon Vinella,Michael Vasilkovsky,Ivan Skorokhodov,Vladislav Shakhrai,Sergey Korolev,Sergey Tulyakov,Peter Wonka*

主要分类: cs.CV

摘要简述: 本文提出了一种名为4Real-Video-V2的框架，首次通过前馈架构生成4D时空视频帧和3D高斯粒子。其核心创新包括融合时空注意力的单层设计和改进的3D重建算法，显著提升了4D生成的视觉质量和重建能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前4D视频生成方法在时空注意力处理上存在局限性，通常采用顺序或并行设计，导致效率和质量不足。本文旨在通过融合时空注意力和改进重建算法，解决这些问题，提升4D场景生成的表现。

研究方法: 1. 提出融合时空注意力的单层设计，采用稀疏注意力模式，使token在同一帧、时间戳或视角内交互。2. 扩展3D重建算法，引入高斯头、相机token替换算法及动态层和训练。

研究结果: 实验表明，4Real-Video-V2在4D生成任务中达到新的最佳性能，显著提升了视觉质量和重建能力。

研究结论: 本文提出的融合时空注意力设计和改进重建算法有效解决了现有方法的局限性，为4D场景生成提供了高效且高质量的解决方案。

中文摘要: 我们提出了首个能够通过前馈架构计算4D时空视频帧和每时间步3D高斯粒子的框架。该架构包含两部分：4D视频模型和4D重建模型。在第一部分中，我们分析了当前4D视频扩散架构，这些架构在双流设计中顺序或并行执行空间和时间注意力。我们指出了现有方法的局限性，并提出了一种新颖的融合架构，在单层内完成空间和时间注意力。该方法的关键在于稀疏注意力模式，其中token关注同一帧、同一时间戳或同一视角的其他token。在第二部分中，我们通过引入高斯头、相机token替换算法以及额外的动态层和训练，扩展了现有3D重建算法。总体而言，我们在4D生成任务中确立了新的最佳性能，显著提升了视觉质量和重建能力。

</details>


### [248] [Phantom-Data : Towards a General Subject-Consistent Video Generation Dataset](https://arxiv.org/abs/2506.18851)
**中文标题：Phantom-Data：迈向通用主题一致视频生成数据集**

*Zhuowei Chen,Bingchuan Li,Tianxiang Ma,Lijie Liu,Mingcong Liu,Yi Zhang,Gen Li,Xinghui Li,Siyu Zhou,Qian He,Xinglong Wu*

主要分类: cs.CV

摘要简述: 本文提出了Phantom-Data，首个通用跨配对主题一致视频生成数据集，解决了现有模型因配对训练导致的主题与背景纠缠问题，显著提升了文本指令的遵循能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有主题到视频生成模型因配对训练范式导致主题身份与背景属性纠缠，难以忠实遵循文本指令（即“复制粘贴问题”）。本文旨在通过构建跨配对数据集解决这一问题。

研究方法: 通过三阶段流程构建Phantom-Data数据集：(1)通用输入对齐主题检测模块；(2)从5300万视频和30亿图像中检索跨上下文主题；(3)基于先验的身份验证以确保视觉一致性。

研究结果: 实验表明，使用Phantom-Data训练显著提升了提示对齐和视觉质量，同时保持了与配对基线相当的身份一致性。

研究结论: Phantom-Data为跨配对主题一致视频生成提供了首个通用数据集，有效解决了现有模型的局限性，推动了该领域的发展。

中文摘要: 近年来，主题到视频生成取得了显著进展，但现有模型在忠实遵循文本指令方面仍面临重大挑战。这一限制（通常称为“复制粘贴问题”）源于广泛使用的配对训练范式，该方法通过从目标视频同一场景中采样参考图像，将主题身份与背景和上下文属性纠缠在一起。为解决这一问题，我们提出了\textbf{Phantom-Data，首个通用跨配对主题一致视频生成数据集}，包含跨多样类别的约一百万身份一致配对。我们的数据集通过三阶段流程构建：(1)通用且输入对齐的主题检测模块；(2)从超过5300万视频和30亿图像中进行大规模跨上下文主题检索；(3)基于先验的身份验证以确保上下文变化下的视觉一致性。综合实验表明，使用Phantom-Data训练显著提升了提示对齐和视觉质量，同时保持了与配对基线相当的身份一致性。

</details>


### [249] [RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base](https://arxiv.org/abs/2506.18856)
**中文标题：RAG-6DPose：基于检索增强的6D姿态估计——利用CAD模型作为知识库**

*Kuanning Wang,Yuqian Fu,Tianyu Wang,Yanwei Fu,Longfei Liang,Yu-Gang Jiang,Xiangyang Xue*

主要分类: cs.CV

摘要简述: RAG-6DPose是一种通过检索增强的6D姿态估计方法，利用3D CAD模型作为知识库，结合视觉和几何线索，显著提升了姿态估计的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 准确的6D姿态估计对于机器人操作（如抓取）至关重要。然而，现有方法在处理遮挡和新视角时表现不佳。本文提出了一种检索增强的方法，利用CAD模型作为知识库，以提升姿态估计的性能。

研究方法: RAG-6DPose包含三个阶段：1) 构建多模态CAD知识库，从多视角CAD渲染图像中提取2D视觉特征并附加3D点；2) 通过ReSPC模块从知识库中检索与当前查询图像相关的CAD特征；3) 通过检索增强解码将检索到的CAD信息用于优化姿态预测。

研究结果: 在标准基准测试和实际机器人任务中，RAG-6DPose表现出色，尤其在处理遮挡和新视角时具有显著优势。

研究结论: RAG-6DPose通过检索增强的方法有效提升了6D姿态估计的准确性和鲁棒性，为机器人操作提供了更可靠的解决方案。

中文摘要: 准确的6D姿态估计是机器人操作的关键，能够为抓取等任务提供精确的物体定位。我们提出了RAG-6DPose，这是一种检索增强的方法，通过整合视觉和几何线索，利用3D CAD模型作为知识库。RAG-6DPose大致包含三个阶段：1) 通过从多视角CAD渲染图像中提取2D视觉特征并附加3D点，构建多模态CAD知识库；2) 通过我们的ReSPC模块从知识库中检索与当前查询图像相关的CAD特征；3) 通过检索增强解码将检索到的CAD信息用于优化姿态预测。在标准基准测试和实际机器人任务中的实验结果表明，我们的方法具有高效性和鲁棒性，尤其是在处理遮挡和新视角时表现突出。补充材料可在我们的项目网站https://sressers.github.io/RAG-6DPose上获取。

</details>


### [250] [TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting](https://arxiv.org/abs/2506.18862)
**中文标题：TAMMs：面向卫星图像变化理解与预测的时序感知多模态模型**

*Zhongbin Guo,Yuhao Wang,Ping Jian,Xinyue Chen,Wei Peng,Ertai E*

主要分类: cs.CV

摘要简述: 本文提出TAMMs模型，通过轻量级时序模块增强多模态大语言模型（MLLMs），用于卫星图像时序变化理解和未来场景生成，实验显示其在时空理解任务中优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有MLLMs在卫星图像时序分析中难以实现细粒度的时空推理，本文旨在探索MLLMs在联合任务（时序变化理解和未来场景生成）中的潜力。

研究方法: TAMMs通过轻量级时序模块增强冻结的MLLMs，支持结构化序列编码和上下文提示；引入语义融合控制注入（SFCI）机制，结合高级语义推理和结构先验，生成时序一致且语义合理的图像。

研究结果: 实验表明，TAMMs在时序变化理解和未来图像预测任务中均优于基线MLLMs，验证了其时空推理和语义融合的有效性。

研究结论: TAMMs通过精心设计的时序推理和语义融合，充分释放了MLLMs在时空理解任务中的潜力。

中文摘要: 卫星图像时序分析需要细粒度的时空推理，这对现有多模态大语言模型（MLLMs）仍具挑战性。本文研究MLLMs在联合任务（时序变化理解和未来场景生成）中的能力，旨在评估其建模复杂多模态动态的潜力。我们提出TAMMs，一种时序感知多模态模型，通过轻量级时序模块增强冻结的MLLMs，实现结构化序列编码和上下文提示。为引导未来图像生成，TAMMs引入语义融合控制注入（SFCI）机制，在增强的ControlNet中自适应结合高级语义推理和结构先验。这种双路径条件支持生成时序一致且语义合理的图像。实验表明，TAMMs在时序变化理解和未来图像预测任务中均优于基线MLLMs，突显了精心设计的时序推理和语义融合如何充分释放MLLMs在时空理解中的潜力。

</details>


### [251] [OmniAvatar: Efficient Audio-Driven Avatar Video Generation with Adaptive Body Animation](https://arxiv.org/abs/2506.18866)
**中文标题：OmniAvatar：基于自适应身体动画的高效音频驱动虚拟形象视频生成**

*Qijun Gan,Ruizi Yang,Jianke Zhu,Shaofei Xue,Steven Hoi*

主要分类: cs.CV

摘要简述: OmniAvatar是一种创新的音频驱动全身视频生成模型，通过像素级多层级音频嵌入策略和LoRA训练方法，显著提升了唇部同步和自然动作的生成效果，同时支持精确的文本控制。


<details>
  <summary>详细信息</summary>
研究动机: 现有音频驱动人体动画方法主要关注面部动作，难以生成自然同步的全身动画，且缺乏细粒度提示控制能力。OmniAvatar旨在解决这些问题。

研究方法: 采用像素级多层级音频嵌入策略捕捉潜在空间中的音频特征，结合LoRA训练方法，实现音频特征与基础模型的有效融合，同时保留文本提示控制能力。

研究结果: 实验表明，OmniAvatar在面部和半身视频生成中优于现有模型，支持播客、人际互动、动态场景和歌唱等多种领域的视频生成。

研究结论: OmniAvatar通过创新的音频嵌入和训练方法，显著提升了音频驱动视频生成的自然性和控制精度，为多领域应用提供了强大工具。

中文摘要: 音频驱动人体动画已取得显著进展，但现有方法主要关注面部动作，难以生成自然同步的全身动画，且缺乏细粒度提示控制能力。为解决这些问题，我们提出了OmniAvatar，一种创新的音频驱动全身视频生成模型，通过改进唇部同步和自然动作提升了人体动画效果。OmniAvatar采用像素级多层级音频嵌入策略，更好地捕捉潜在空间中的音频特征，从而增强不同场景下的唇部同步效果。为在保留基础模型提示驱动控制能力的同时有效融合音频特征，我们采用了基于LoRA的训练方法。大量实验表明，OmniAvatar在面部和半身视频生成中均优于现有模型，并支持播客、人际互动、动态场景和歌唱等多种领域的精确文本控制视频生成。项目页面请访问：https://omni-avatar.github.io/。

</details>


### [252] [Let Your Video Listen to Your Music!](https://arxiv.org/abs/2506.18881)
**中文标题：让你的视频聆听你的音乐！**

*Xinyu Zhang,Dong Gong,Zicheng Duan,Anton van den Hengel,Lingqiao Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MVAA（音乐视频自动对齐）的新框架，能够自动编辑视频以与音乐节奏对齐，同时保留原始视觉内容。通过两阶段方法（关键帧对齐和节奏感知视频修复），该方法在10分钟内完成适配，实验证明其能实现高质量的对齐和视觉流畅性。


<details>
  <summary>详细信息</summary>
研究动机: 在多媒体制作中，将视频的视觉运动节奏与音乐对齐是一个实际需求，但现有方法通常依赖人工编辑或启发式技术，缺乏灵活性。本文旨在提出一种自动化的解决方案，以提升视频与音乐对齐的效率和质量。

研究方法: MVAA框架采用两阶段方法：首先将运动关键帧与音频节拍对齐，然后通过帧条件扩散模型生成连贯的中间帧，保留原始视频的语义内容。采用预训练和快速微调策略，适配时间短。

研究结果: 实验表明，MVAA能够在10分钟内完成适配，并在单块NVIDIA 4090 GPU上实现高质量的音乐节拍对齐和视觉流畅性。

研究结论: MVAA提供了一种高效且灵活的自动化视频编辑方法，能够显著提升视频与音乐对齐的质量，适用于音乐视频、宣传内容等多种场景。

中文摘要: 将视频中的视觉运动节奏与给定音乐轨道对齐是多媒体制作中的实际需求，但在自主视频编辑中仍是一个未充分探索的任务。有效的运动与音乐节拍对齐能够增强观众的参与感和视觉吸引力，尤其是在音乐视频、宣传内容和电影剪辑中。现有方法通常依赖于劳动密集型的手动剪辑、速度调整或基于启发式的编辑技术来实现同步。虽然一些生成模型能够处理视频和音乐的联合生成，但它们通常将两种模态纠缠在一起，限制了在保留完整视觉内容的同时对齐视频与音乐节拍的灵活性。本文提出了一种新颖且高效的框架，称为MVAA（音乐视频自动对齐），能够自动编辑视频以与给定音乐轨道的节奏对齐，同时保留原始视觉内容。为了增强灵活性，我们将任务模块化为两步过程：首先将运动关键帧与音频节拍对齐，然后进行节奏感知的视频修复。具体来说，我们首先在与音乐节拍对齐的时间戳插入关键帧，然后使用帧条件扩散模型生成连贯的中间帧，保留原始视频的语义内容。由于全面的测试时训练可能耗时较长，我们采用了两阶段策略：在小型视频集上预训练修复模块以学习一般运动先验，然后进行快速的推理时微调以实现视频特定适配。这种混合方法能够在10分钟内完成适配，并在单块NVIDIA 4090 GPU上使用CogVideoX-5b-I2V作为主干进行一个周期的微调。大量实验表明，我们的方法能够实现高质量的节拍对齐和视觉流畅性。

</details>


### [253] [Light of Normals: Unified Feature Representation for Universal Photometric Stereo](https://arxiv.org/abs/2506.18882)
**中文标题：法线之光：通用光度立体视觉的统一特征表示**

*Hong Li,Houyuan Chen,Chongjie Ye,Zhaoxi Chen,Bohan Li,Shaocong Xu,Xianda Guo,Xuhui Liu,Yikai Wang,Baochang Zhang,Satoshi Ikehata,Boxin Shi,Anyi Rao,Hao Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种统一特征表示方法，用于解决通用光度立体视觉中的光照与表面法线耦合问题，并保留复杂表面的高频几何细节。


<details>
  <summary>详细信息</summary>
研究动机: 通用光度立体视觉（PS）旨在从任意光照条件下的物体中恢复高质量表面法线，但现有方法面临光照与表面法线特征深度耦合的挑战，以及复杂表面高频几何细节难以保留的问题。

研究方法: 本文提出了一种统一特征表示方法，通过解耦光照变化与表面法线特征，并设计高效的特征处理操作，以准确捕捉复杂表面的几何细节。

研究结果: 实验表明，该方法能够有效分离光照与表面法线特征，并在复杂表面上保留高频几何细节，显著提升了通用光度立体视觉的性能。

研究结论: 本文提出的统一特征表示方法为通用光度立体视觉提供了一种有效的解决方案，解决了光照与法线耦合问题，并提升了复杂表面几何细节的恢复能力。

中文摘要: 通用光度立体视觉（PS）旨在从任意光照条件下的物体中恢复高质量表面法线，而无需依赖特定的光照模型。尽管近期出现了SDM-UniPS和Uni MS-PS等进展，但仍存在两个基本挑战：1）光照变化与表面法线特征的深度耦合，观测亮度变化难以区分是源于光照变化还是表面方向；2）复杂表面中高频几何细节的保留，复杂几何结构导致自阴影、相互反射和细微法线变化，传统特征处理操作难以准确捕捉。

</details>


### [254] [Universal Video Temporal Grounding with Generative Multi-modal Large Language Models](https://arxiv.org/abs/2506.18883)
**中文标题：基于生成式多模态大语言模型的通用视频时间定位**

*Zeqian Li,Shangzhe Di,Zhonghua Zhai,Weilin Huang,Yanfeng Wang,Weidi Xie*

主要分类: cs.CV

摘要简述: 本文提出了一种通用的视频时间定位模型UniTime，利用生成式多模态大语言模型（MLLMs）的强大视觉语言理解能力，能够精准定位视频中的时间片段。该模型通过插入时间戳标记和自适应帧缩放技术，实现了对不同长度和类型视频的鲁棒性时间定位，并在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视频时间定位方法通常局限于特定视频领域或时长，无法处理多样化的视频内容和复杂的语言查询。本文旨在开发一种通用的视频时间定位模型，能够适应不同视图、类型和长度的视频，并理解复杂的语言查询。

研究方法: UniTime模型通过以下方法实现通用视频时间定位：(i) 利用生成式多模态大语言模型（MLLMs）的视觉语言理解能力，通过插入时间戳标记与视频标记结合，实现精确的时间戳输出；(ii) 采用自适应帧缩放技术，训练模型处理不同输入粒度的视频，从而实现对短视频和长视频的鲁棒性时间定位。

研究结果: 实验结果表明，UniTime在五个公开的时间定位基准测试中，无论是零样本还是数据集特定的微调设置下，均优于现有最先进方法。此外，当UniTime作为长视频问答（VideoQA）的初步片段检索器时，显著提高了VideoQA的准确性。

研究结论: UniTime通过结合生成式多模态大语言模型和自适应帧缩放技术，实现了对多样化视频的鲁棒性时间定位，并在复杂视频理解任务中展现出重要价值。

中文摘要: 本文提出了一种通用的视频时间定位计算模型，能够根据自然语言查询（如问题或描述）精准定位视频中的时间片段。与现有方法通常局限于特定视频领域或时长不同，我们提出了UniTime，一种利用生成式多模态大语言模型（MLLMs）强大视觉语言理解能力的鲁棒通用视频定位模型。我们的模型能够有效处理多样化视图、类型和长度的视频，同时理解复杂的语言查询。主要贡献包括：(i) 我们探索了如何利用强大的MLLMs进行视频时间定位。为了实现精确的时间戳输出，我们通过将时间戳标记与视频标记交错结合，引入了时间信息。(ii) 通过训练模型处理不同输入粒度的视频（采用自适应帧缩放技术），我们的方法实现了对短视频和长视频的鲁棒性时间定位。(iii) 综合实验表明，UniTime在五个公开的时间定位基准测试中，无论是零样本还是数据集特定的微调设置下，均优于现有最先进方法。(iv) 当UniTime作为长视频问答（VideoQA）的初步片段检索器时，显著提高了VideoQA的准确性，凸显了其在复杂视频理解任务中的价值。

</details>


### [255] [4D-LRM: Large Space-Time Reconstruction Model From and To Any View at Any Time](https://arxiv.org/abs/2506.18890)
**中文标题：4D-LRM：从任意视角和时间点到任意视角和时间的大规模时空重建模型**

*Ziqiao Ma,Xuweiyi Chen,Shoubin Yu,Sai Bi,Kai Zhang,Chen Ziwen,Sihan Xu,Jianing Yang,Zexiang Xu,Kalyan Sunkavalli,Mohit Bansal,Joyce Chai,Hao Tan*

主要分类: cs.CV

摘要简述: 4D-LRM是首个大规模4D重建模型，能够从任意视角和时间点输入，渲染任意新视角和时间组合，实现高效、高质量的4D重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有4D方法（如基于优化、几何或生成的方法）在效率、泛化性或保真度方面存在不足，4D-LRM旨在通过学习统一的时空表示，解决这些问题。

研究方法: 4D-LRM通过从时间序列的位姿图像标记中直接预测每像素的4D高斯基元，学习统一的时空表示，实现快速、高质量的渲染。

研究结果: 实验表明，4D-LRM能够泛化到新物体、时间插值，并处理多样化的相机设置，单次前向传播即可在A100 GPU上1.5秒内重建24帧序列。

研究结论: 4D-LRM通过扩展时空预训练，实现了高效且准确的4D重建，为时空表示学习提供了新思路。

中文摘要: 我们能否通过4D预训练学习通用的时空表示，从某些时间的少量视角重建物体到任意时间的任意视角？我们通过4D-LRM给出了肯定的答案，这是首个大规模4D重建模型，能够从不受约束的视角和时间点输入，并渲染任意新视角和时间的组合。与之前的4D方法（如基于优化、几何或生成的方法）不同，4D-LRM通过学习统一的时空表示，直接从时间序列的位姿图像标记中预测每像素的4D高斯基元，实现了快速、高质量的渲染，理论上支持无限帧率。我们的结果表明，扩展时空预训练能够实现高效且准确的4D重建。4D-LRM能够泛化到新物体、时间插值，并处理多样化的相机设置，单次前向传播即可在A100 GPU上1.5秒内重建24帧序列。

</details>


### [256] [FilMaster: Bridging Cinematic Principles and Generative AI for Automated Film Generation](https://arxiv.org/abs/2506.18899)
**中文标题：FilMaster：融合电影原则与生成式AI的自动化电影生成系统**

*Kaiyi Huang,Yukun Huang,Xintao Wang,Zinan Lin,Xuefei Ning,Pengfei Wan,Di Zhang,Yu Wang,Xihui Liu*

主要分类: cs.CV

摘要简述: FilMaster是一款端到端AI系统，通过整合真实世界的电影原则，实现专业级电影生成，解决现有系统在镜头语言和节奏上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI电影生成系统缺乏多样化的镜头语言和电影节奏，导致视觉效果模板化和叙事乏味。FilMaster旨在通过整合真实电影原则，生成专业级电影。

研究方法: FilMaster分为两个阶段：参考引导生成阶段和多镜头协同RAG模块生成专业镜头语言；生成后制作阶段通过观众中心节奏控制模块模拟专业工作流程。

研究结果: 实验表明，FilMaster在镜头语言设计和电影节奏控制上表现优异，推动了生成式AI在专业电影制作中的应用。

研究结论: FilMaster通过整合电影原则和生成式AI，实现了专业级电影生成，并引入FilmEval基准评估AI生成电影。

中文摘要: AI驱动的内容创作在电影制作中展现出潜力，但现有电影生成系统难以实现电影原则，导致生成效果缺乏专业水准，尤其在镜头语言和电影节奏上表现不足，造成视觉效果模板化和叙事乏味。为此，我们提出FilMaster，一款端到端AI系统，整合真实世界电影原则，生成可编辑、符合行业标准的专业级电影。FilMaster基于两大原则：(1)从海量真实电影数据中学习电影摄影；(2)模拟以观众为中心的专业后期制作流程。受此启发，FilMaster包含两个阶段：参考引导生成阶段将用户输入转化为视频片段；生成后制作阶段通过协调视听元素实现电影节奏，将原始素材转化为视听输出。生成阶段采用多镜头协同RAG镜头语言设计模块，通过从44万电影片段库中检索参考片段，指导AI生成专业镜头语言。后制作阶段通过设计观众中心电影节奏控制模块（包括基于模拟观众反馈的粗剪和精剪流程），模拟专业工作流程，有效整合视听元素以生成引人入胜的内容。系统由(M)LLMs和视频生成模型等生成式AI模型驱动。此外，我们引入FilmEval，一个评估AI生成电影的全面基准。大量实验表明，FilMaster在镜头语言设计和电影节奏控制上表现卓越，推动了生成式AI在专业电影制作中的发展。

</details>


### [257] [Audit & Repair: An Agentic Framework for Consistent Story Visualization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18900)
**中文标题：审计与修复：一种用于文本到图像扩散模型中一致故事可视化的智能框架**

*Kiymet Akdemir,Tahira Kazimi,Pinar Yanardag*

主要分类: cs.CV

摘要简述: 本文提出了一种多智能体协作框架，用于解决文本到图像扩散模型在故事可视化中的一致性问题，通过迭代修复机制提升多面板叙事的视觉一致性。


<details>
  <summary>详细信息</summary>
研究动机: 故事可视化任务中，保持角色和对象在多面板中的视觉一致性是一个核心挑战。现有扩散模型常因无法维持关键属性而导致叙事不连贯，本文旨在解决这一问题。

研究方法: 提出了一种协作多智能体框架，能够自主识别、修正和优化多面板故事可视化中的不一致性。该框架采用迭代循环机制，支持细粒度的面板级更新，无需重新生成整个序列，并可灵活集成多种扩散模型。

研究结果: 定量和定性实验表明，该方法在多面板一致性方面优于现有方法。

研究结论: 本文提出的多智能体框架有效提升了故事可视化的视觉一致性，且具有模型无关性和灵活性。

中文摘要: 故事可视化已成为一项流行任务，通过多个面板生成视觉场景以描绘叙事。该任务的核心挑战在于保持视觉一致性，尤其是角色和对象在故事中的持续性和演变。尽管扩散模型近期取得了进展，但现有方法常无法保留关键角色属性，导致叙事不连贯。本文提出了一种协作多智能体框架，能够自主识别、修正和优化多面板故事可视化中的不一致性。智能体在迭代循环中运行，支持细粒度的面板级更新，而无需重新生成整个序列。该框架与多种扩散模型兼容，包括Flux等整流流变换器和Stable Diffusion等潜在扩散模型。定量和定性实验表明，本方法在多面板一致性方面优于现有方法。

</details>


### [258] [From Virtual Games to Real-World Play](https://arxiv.org/abs/2506.18901)
**中文标题：从虚拟游戏到真实世界游戏**

*Wenqiang Sun,Fangyun Wei,Jinjing Zhao,Xi Chen,Zilong Chen,Hongyang Zhang,Jun Zhang,Yan Lu*

主要分类: cs.CV

摘要简述: RealPlay是一种基于神经网络的真实世界游戏引擎，能够通过用户控制信号生成交互式视频。它专注于生成逼真且时间一致的视频序列，并通过迭代块预测实现低延迟反馈。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多关注游戏风格的视觉效果，而RealPlay旨在生成逼真且时间一致的视频序列，模拟真实世界场景，并通过交互式反馈提升用户体验。

研究方法: RealPlay采用神经网络模型，结合标记的游戏数据和无标记的真实世界视频进行训练，无需真实世界动作标注。通过迭代块预测实现低延迟反馈，并确保时间一致性和控制准确性。

研究结果: RealPlay实现了两种泛化能力：控制信号从虚拟场景到真实场景的映射，以及从赛车游戏标签扩展到控制自行车、行人等多样化实体。

研究结论: RealPlay展示了在无需真实世界动作标注的情况下，生成逼真交互式视频的潜力，并验证了其在控制信号和实体泛化方面的能力。

中文摘要: 我们介绍了RealPlay，一种基于神经网络的真实世界游戏引擎，能够通过用户控制信号生成交互式视频。与以往专注于游戏风格视觉效果的研究不同，RealPlay旨在生成逼真且时间一致的视频序列，模拟真实世界场景。其工作模式为交互式循环：用户观察生成的场景，发出控制命令，并收到一段短视频作为响应。为实现这种逼真且响应迅速的生成，我们解决了关键挑战，包括低延迟反馈的迭代块预测、跨迭代的时间一致性以及准确的控制响应。RealPlay通过结合标记的游戏数据和无标记的真实世界视频进行训练，无需真实世界动作标注。值得注意的是，我们观察到两种泛化形式：（1）控制信号从虚拟到真实场景的有效映射；（2）尽管训练标签仅来自赛车游戏，但RealPlay能够泛化控制自行车、行人等多样化实体，而不仅限于车辆。项目页面：https://wenqsun.github.io/RealPlay/

</details>


### [259] [VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory](https://arxiv.org/abs/2506.18903)
**中文标题：VMem：基于表面元素索引视图内存的一致性交互式视频场景生成**

*Runjia Li,Philip Torr,Andrea Vedaldi,Tomas Jakab*

主要分类: cs.CV

摘要简述: 本文提出了一种名为VMem的新型内存机制，用于构建能够交互式探索环境的视频生成器。通过几何索引过去视图，VMem显著提升了场景一致性和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在长期场景合成中存在局限性：基于2D视图外绘的方法会快速累积误差，而短上下文窗口的视频生成器难以保持长期场景一致性。因此，需要一种高效且一致的方法来解决这些问题。

研究方法: VMem通过3D表面元素（surfels）几何索引过去视图，仅检索与生成新视图最相关的历史视图，从而在降低计算成本的同时保持场景一致性。

研究结果: 在长期场景合成基准测试中，VMem表现出色，优于现有方法，显著提升了场景一致性和相机控制能力。

研究结论: VMem通过高效索引和检索历史视图，实现了长期场景一致性和交互式探索，为视频生成领域提供了新的解决方案。

中文摘要: 我们提出了一种新型内存机制，用于构建能够交互式探索环境的视频生成器。以往方法通过外绘场景的2D视图并逐步重建其3D几何结构，但会快速累积误差；或使用短上下文窗口的视频生成器，但难以长期保持场景一致性。为解决这些问题，我们引入了基于3D表面元素（surfels）几何索引的视图内存（VMem），能够高效检索与生成新视图最相关的历史视图。通过仅关注这些相关视图，我们的方法以远低于使用所有历史视图的计算成本，实现了对想象环境的一致性探索。我们在具有挑战性的长期场景合成基准上评估了该方法，结果表明其在保持场景一致性和相机控制方面优于现有方法。

</details>


### [260] [TC-Light: Temporally Consistent Relighting for Dynamic Long Videos](https://arxiv.org/abs/2506.18904)
**中文标题：TC-Light：动态长视频的时间一致性重光照**

*Yang Liu,Chuanchen Luo,Zimo Tang,Yingyan Li,Yuran Yang,Yuanyong Ning,Lue Fan,Junran Peng,Zhaoxiang Zhang*

主要分类: cs.CV

摘要简述: TC-Light是一种新颖的视频重光照方法，通过两阶段优化机制实现动态长视频的时间一致性重光照，具有高效计算和优越的时间连贯性。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频重光照技术主要局限于肖像视频或面临时间一致性和计算效率的瓶颈。动态长视频的重光照在视觉内容创作和数据扩展方面具有重要价值，因此需要一种高效且时间一致的方法。

研究方法: TC-Light采用两阶段优化机制：第一阶段优化外观嵌入以对齐全局光照；第二阶段优化提出的规范视频表示（UVT）以对齐细粒度纹理和光照。

研究结果: 实验表明，TC-Light能够实现物理上合理且时间连贯的重光照结果，同时计算成本低。

研究结论: TC-Light为动态长视频提供了一种高效且时间一致的重光照解决方案，适用于多种下游任务。

中文摘要: 在动态长视频中编辑光照对于视觉内容创作和数据扩展具有重要价值。然而，现有视频重光照技术主要局限于肖像视频或面临时间一致性和计算效率的瓶颈。本文提出TC-Light，一种基于两阶段优化机制的新范式。首先通过膨胀视频重光照模型初步重光照视频，第一阶段优化外观嵌入以对齐全局光照；第二阶段优化提出的规范视频表示（Unique Video Tensor, UVT）以对齐细粒度纹理和光照。我们还建立了一个长且高度动态的视频基准进行全面评估。大量实验表明，我们的方法能够实现物理上合理且时间连贯的重光照结果，同时计算成本低。代码和视频演示可在https://dekuliutesla.github.io/tclight/获取。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [261] [Evaluating Generalization and Representation Stability in Small LMs via Prompting](https://arxiv.org/abs/2506.17289)
**中文标题：通过提示评估小语言模型的泛化能力和表征稳定性**

*Rahul Raja,Arpita Vats*

主要分类: cs.AI

摘要简述: 本文比较了小语言模型在少样本提示和监督微调两种适应范式下的泛化能力，重点分析了它们在分布内和分布外设置中的表现及内部表征稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探讨少样本提示和监督微调在小语言模型中的泛化能力和表征稳定性，尤其是在低资源设置和分布变化下的表现差异。

研究方法: 通过比较不同任务格式、提示风格和模型规模下的提示和微调方法，分析其在分布内和分布外设置中的表现，并评估任务特定特征的稳定性和抽象性。

研究结果: 研究发现，提示和微调在小模型中对知识的内部化和泛化方式存在显著差异，提示在参数效率和灵活性上表现优越，但在低资源设置和分布变化下可能不够稳健。

研究结论: 本研究为低数据环境下的模型选择提供了实用指导，并为提示与微调的争论贡献了实证见解。

中文摘要: 我们研究了小语言模型在两种流行的适应范式下的泛化能力：少样本提示和监督微调。尽管提示因其参数效率和灵活性而备受青睐，但其在低资源设置和分布变化下的稳健性尚不明确。本文比较了提示和微调在不同任务格式、提示风格和模型规模下的表现，重点关注它们在分布内和分布外（OOD）设置中的行为。
  除了准确性外，我们还分析了每种方法学习到的内部表征，以评估任务特定特征的稳定性和抽象性。我们的研究结果突显了小模型在不同适应策略下如何内部化和泛化知识的关键差异。这项工作为低数据环境下的模型选择提供了实用指导，并为提示与微调的争论贡献了实证见解。实验代码可在以下链接获取。

</details>


### [262] [Individual Causal Inference with Structural Causal Model](https://arxiv.org/abs/2506.17300)
**中文标题：基于结构因果模型的个体因果推断**

*Daniel T. Chang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于结构因果模型（SCM）的个体因果推断（ICI）方法，通过引入个体化操作符和个体因果查询，实现对个体干预效果的估计，填补了传统群体因果推断在个体层面的空白。


<details>
  <summary>详细信息</summary>
研究动机: 传统因果推断方法主要基于群体数据，难以直接应用于个体层面。个体因果推断（ICI）旨在解决这一问题，通过考虑个体特征，估计个体因果效应（ICE），但现有方法在个体数据有限的情况下存在挑战。SCM虽为群体模型，但其外生变量可编码个体差异，为个体化推断提供了可能。

研究方法: 提出了一种基于SCM的ICI方法，引入个体化操作符indiv(W)和个体因果查询P(Y | indiv(W), do(X), Z)，将群体模型个体化，从而估计个体干预效果。该方法通过外生变量捕捉个体差异，实现了个体层面的因果推断。

研究结果: 研究表明，基于SCM的ICI方法能够有效估计个体因果效应，且其推断对象为个体可能的替代情况，而非反事实的非实际状态。

研究结论: 本文提出的ICI方法扩展了SCM在个体层面的应用，为个体因果推断提供了理论框架和实用工具，填补了传统群体方法的不足。

中文摘要: 个体因果推断（ICI）利用因果推断方法，结合个体特征/事实，理解和预测干预对个体的影响，旨在估计个体因果效应（ICE）。由于个体数据有限且传统因果推断方法多为群体性，估计ICE具有挑战性。结构因果模型（SCM）本质上是群体模型，其因果发现、关联查询和干预查询均为群体性。然而，SCM中的外生变量（U）可编码个体差异，从而为基于特定个体特征/事实的个体化群体提供机制。基于此，我们提出将SCM用于ICI作为“第三级”因果推断，因为它涉及“想象”在给定个体观察特征/事实的情况下，假设干预对个体的因果效应。具体而言，我们提出indiv(W)操作符形式化/表示群体个体化过程，以及个体因果查询P(Y | indiv(W), do(X), Z)形式化/表示ICI。我们证明并论证，基于SCM的ICI是对个体替代（可能）的推断，而非个体反事实（非实际）。

</details>


### [263] [Resource Rational Contractualism Should Guide AI Alignment](https://arxiv.org/abs/2506.17434)
**中文标题：资源理性契约主义应指导AI对齐**

*Sydney Levine,Matija Franklin,Tan Zhi-Xuan,Secil Yanik Guyot,Lionel Wong,Daniel Kilov,Yejin Choi,Joshua B. Tenenbaum,Noah Goodman,Seth Lazar,Iason Gabriel*

主要分类: cs.AI

摘要简述: 本文提出资源理性契约主义（RRC）框架，通过启发式方法高效模拟多方理性协议，指导AI系统在复杂人类环境中动态适应和决策。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI系统在人类环境中决策的需求增加，如何让AI在目标和价值观不同的多方之间达成共识成为挑战。传统契约主义方法成本高且效率低，因此需要一种更高效的解决方案。

研究方法: 提出资源理性契约主义（RRC）框架，利用基于规范和认知启发的启发式方法，在效率和准确性之间权衡，模拟多方理性协议。

研究结果: RRC框架使AI系统能够高效运作，并动态适应和理解不断变化的人类社会环境。

研究结论: 资源理性契约主义为AI对齐提供了一种高效且动态适应的解决方案，适用于复杂的人类社会决策场景。

中文摘要: AI系统很快将需要在人类环境中导航并做出影响人类和其他AI代理的决策，而这些代理的目标和价值观可能各不相同。契约主义对齐提议将这些决策建立在多样利益相关者在适当条件下会支持的协议基础上，然而大规模达成此类协议成本高且速度慢——即使对先进AI也是如此。因此，我们提出资源理性契约主义（RRC）：一种框架，其中AI系统通过利用一套基于规范和认知启发的启发式方法，在努力和准确性之间权衡，近似模拟理性各方会形成的协议。一个RRC对齐的代理不仅能高效运作，还能动态适应并解释不断变化的人类社会世界。

</details>


### [264] [Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation](https://arxiv.org/abs/2506.17442)
**中文标题：保持医疗AI的健康：系统性能退化检测与校正方法综述**

*Hao Guan,David Bates,Li Zhou*

主要分类: cs.AI

摘要简述: 本文综述了医疗AI系统性能退化的检测与校正方法，探讨了数据分布变化、患者特征变化等因素对AI模型可靠性的影响，并提出了持续监控和自校正机制的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在医疗领域的广泛应用，其性能可能因数据分布变化、患者特征变化等因素而退化，影响临床决策的可靠性。本文旨在探讨如何监测和维护医疗AI系统的“健康”，以确保其长期安全部署。

研究方法: 本文首先分析了导致AI系统性能退化的常见原因（如数据和模型层面的变化），随后总结了数据漂移和模型漂移的检测技术，并深入探讨了根因分析。此外，还回顾了从模型重训练到测试时适应的校正策略。

研究结果: 研究总结了传统机器学习模型和大型语言模型（LLMs）在检测和校正性能退化方面的优缺点，并提出了未来研究方向。

研究结论: 本文为开发可靠、鲁棒的医疗AI系统提供了指导，强调了持续监控和自校正机制的重要性，以应对动态临床环境中的挑战。

中文摘要: 人工智能（AI）在现代医疗中的应用日益广泛，为临床决策提供了强大支持。然而，在实际应用中，AI系统可能因数据分布变化、患者特征变化、临床协议演变以及数据质量波动等因素而出现性能退化，从而影响模型的可靠性，引发安全隐患或导致预测不准确。本文从前瞻性视角探讨了如何监测和维护医疗AI系统的“健康”，强调了持续性能监控、早期退化检测和有效自校正机制的迫切需求。文章首先回顾了数据和模型层面导致性能退化的常见原因，随后总结了数据漂移和模型漂移的检测技术，并深入分析了根因。校正策略方面，从模型重训练到测试时适应均有所涉及。本研究涵盖了传统机器学习模型和前沿大型语言模型（LLMs），分析了其优势与局限。最后，讨论了当前技术挑战并提出了未来研究方向。本文旨在为开发可靠、鲁棒的医疗AI系统提供指导，以支持其在动态临床环境中的长期安全部署。

</details>


### [265] [OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections](https://arxiv.org/abs/2506.17449)
**中文标题：OmniReflect：通过神经符号反思发现LLM代理的可迁移宪法**

*Manasa Bharadwaj,Nikhil Verma,Kevin Ferreira*

主要分类: cs.AI

摘要简述: OmniReflect提出了一种层次化、反思驱动的框架，通过神经符号技术构建指导原则（宪法），显著提升LLM代理的任务表现，在ALFWorld、BabyAI和PDDL等任务中取得显著改进。


<details>
  <summary>详细信息</summary>
研究动机: 当前提升大型语言模型（LLM）代理性能的方法主要集中在微调和迭代自校正上，但这些方法缺乏长期学习的通用机制且在动态环境中效率低下。OmniReflect旨在通过构建紧凑的指导原则（宪法）来解决这些问题。

研究方法: OmniReflect采用两种模式：自我维持模式（单个代理在任务执行中定期反思）和协作模式（元顾问从校准集中提取宪法指导另一代理）。通过神经、符号和神经符号技术构建宪法，平衡上下文适应性和计算效率。

研究结果: 实验结果显示，OmniReflect在ALFWorld、BabyAI和PDDL任务中分别取得+10.3%、+23.8%和+8.3%的绝对提升。协作模式下，轻量级Qwen3-4B ReAct代理在BabyAI上表现优于所有Reflexion基线。

研究结论: OmniReflect通过构建通用指导原则，显著提升了LLM代理的效率和效果，展示了其在多种环境和模型中的鲁棒性和有效性。

中文摘要: 提升大型语言模型（LLM）代理在复杂任务中性能的努力主要集中在微调和迭代自校正上，但这些方法缺乏长期学习的通用机制且在动态环境中效率低下。我们提出了OmniReflect，一种层次化、反思驱动的框架，通过从任务经验中提炼紧凑的指导原则（宪法）来增强LLM代理的效率和效果。OmniReflect有两种模式：自我维持模式（单个代理在任务执行中定期反思）和协作模式（元顾问从校准集中提取宪法指导另一代理）。为构建这些宪法原则，我们采用神经、符号和神经符号技术，平衡上下文适应性和计算效率。实验结果显示，OmniReflect在ALFWorld、BabyAI和PDDL任务中分别取得+10.3%、+23.8%和+8.3%的绝对提升。协作模式下，轻量级Qwen3-4B ReAct代理在BabyAI上表现优于所有Reflexion基线。这些发现凸显了OmniReflect在多种环境和模型中的鲁棒性和有效性。

</details>


### [266] [From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases](https://arxiv.org/abs/2506.17484)
**中文标题：从非结构化通信到智能RAG：基于多智能体的供应链知识库自动化**

*Yao Zhang,Zaixi Shang,Silpan Patel,Mikel Zuniga*

主要分类: cs.AI

摘要简述: 本文提出了一种基于多智能体的离线方法，将供应链中的非结构化通信（如支持工单）转化为结构化知识库，显著提升了RAG系统的性能，减少了支持工作量并加速了问题解决。


<details>
  <summary>详细信息</summary>
研究动机: 供应链运营产生大量非结构化通信数据（如支持工单、邮件等），其中包含关键知识（如系统使用实践、故障排除流程等），但现有RAG系统因数据噪声和不一致性而效果有限。本文旨在通过离线处理将这些数据转化为结构化知识库，提升RAG系统的性能。

研究方法: 提出了一种基于LLM的多智能体系统，包含三个专用智能体：分类发现（用于创建分类法）、分类（用于工单分组）和知识合成（用于生成知识文章）。通过离线处理将非结构化通信转化为结构化知识库。

研究结果: 实验表明，该方法将原始工单数据量减少至3.4%，同时显著提升RAG系统的性能（有用回答率从38.60%提升至48.74%），并减少77.4%的无用回答。此外，自动解决了约50%的未来供应链工单。

研究结论: 通过离线智能处理将非结构化通信转化为结构化知识库，显著提升了RAG系统的效率和性能，减少了支持工作量并加速了问题解决，填补了知识管理的关键空白。

中文摘要: 供应链运营产生大量运营数据，但关键知识（如系统使用实践、故障排除流程等）通常埋藏在非结构化通信（如支持工单、邮件和聊天记录）中。尽管RAG系统试图利用这些通信作为知识库，但其效果受限于原始数据的噪声、不一致性和不完整性。与现有专注于运行时优化的RAG方法不同，我们提出了一种新颖的离线优先方法，将这些通信转化为结构化知识库。我们的核心创新是基于LLM的多智能体系统，协调三个专用智能体：分类发现（用于创建分类法）、分类（用于工单分组）和知识合成（用于生成知识文章）。将我们的方法应用于包含解决注释和评论的真实支持工单，系统创建了一个紧凑的知识库——将总数据量减少至原始工单数据的3.4%，同时提升了质量。实验表明，我们的预构建知识库在RAG系统中显著优于传统实现（有用回答率48.74% vs. 38.60%），并减少了77.4%的无用回答。通过自动化捕获通常仅存在于专家头脑中的机构知识，我们的解决方案显著提升了运营效率：减少了支持工作量、加速了解决时间，并创建了能够自动解决约50%未来供应链工单的自我改进系统。我们的方法通过智能离线处理而非延迟诱导的运行时架构，将瞬态通信转化为结构化、可重用的知识，填补了知识管理的关键空白。

</details>


### [267] [Kaleidoscopic Teaming in Multi Agent Simulations](https://arxiv.org/abs/2506.17514)
**中文标题：多智能体模拟中的万花筒式团队**

*Ninareh Mehrabi,Tharindu Kumarage,Kai-Wei Chang,Aram Galstyan,Rahul Gupta*

主要分类: cs.AI

摘要简述: 本文提出了一种称为“万花筒式团队”的新框架，用于评估单智能体和多智能体场景中的安全风险，填补了现有安全评估方法的不足，并通过多样化的场景和优化技术识别智能体的潜在漏洞。


<details>
  <summary>详细信息</summary>
研究动机: 现有红队或安全评估框架无法全面评估智能体在复杂行为和交互中的安全风险，尤其是在多智能体场景中。本文旨在填补这一空白，提出更全面的安全评估方法。

研究方法: 引入“万花筒式团队”概念，设计了一个框架，生成多样化场景模拟现实社会，评估单智能体和多智能体的安全风险。采用上下文优化技术生成更优场景，并提出了相应的安全度量指标。

研究结果: 通过该框架，成功识别了多种智能体模型在单智能体和多智能体场景中的安全漏洞，验证了框架的有效性。

研究结论: 万花筒式团队框架为智能体安全评估提供了更全面的方法，能够有效识别复杂行为和多智能体交互中的潜在风险。

中文摘要: 警告：本文内容可能包含不适当或冒犯性内容。
近年来，AI智能体因其自主工具使用能力和在现实应用中的集成而受到广泛关注。这种自主性为系统的安全性带来了新的挑战，无论是单智能体还是多智能体场景。我们认为，现有的红队或安全评估框架在评估智能体的复杂行为、思维过程和行动中的安全风险方面存在不足。此外，它们未能考虑多智能体设置中的风险，当智能体进行复杂行为和相互交互时，可能暴露出多种漏洞。为弥补这一不足，我们提出了“万花筒式团队”这一术语，旨在捕捉单智能体和多智能体场景中可能发生的广泛而复杂的漏洞。我们还提出了一种新的万花筒式团队框架，生成多样化场景以模拟现实人类社会。该框架评估单智能体和多智能体设置中智能体的安全性。在单智能体设置中，智能体需完成一个场景任务；在多智能体设置中，多个智能体通过竞争或合作完成任务，从而揭示其安全漏洞。我们引入了新的上下文优化技术，用于生成更优的安全分析场景。最后，我们提出了适用于该框架的度量指标，以衡量智能体的安全性。通过万花筒式团队框架，我们识别了多种模型在智能体用例中的安全漏洞。

</details>


### [268] [Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models](https://arxiv.org/abs/2506.17585)
**中文标题：引用预训练：大型语言模型的无检索知识归因**

*Yukun Huang,Sanxing Chen,Jian Pei,Manzil Zaheer,Bhuwan Dhingra*

主要分类: cs.AI

摘要简述: 本文探讨了如何让大型语言模型在无需检索的情况下可靠地引用预训练数据，提出了一种两阶段方法（持续预训练和指令微调），并通过实验证明主动索引法优于被动索引法。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型在引用预训练数据时存在不可靠的幻觉问题，而依赖外部检索器会引入延迟和噪声。本文旨在探索是否可以通过改进训练过程，使模型无需检索即可可靠引用数据。

研究方法: 采用两阶段方法：1) 持续预训练，将事实与文档标识符绑定；2) 指令微调，引导模型生成引用行为。提出主动索引法，通过合成多样化QA对增强模型的双向生成能力。

研究结果: 实验表明，主动索引法在Qwen2.5-7B和3B模型上表现优于被动索引法，引用精度提升高达30.2%。数据增强规模越大，性能提升越明显。

研究结论: 主动索引法能有效提升模型引用预训练数据的可靠性，且性能随数据增强规模增加而持续提升。

中文摘要: 可信的语言模型应提供正确且可验证的答案。虽然语言模型有时能将其输出归因于预训练数据，但其引用常因幻觉而不可靠。因此，现有系统通过推理时查询外部检索器插入引用，这引入了延迟、基础设施依赖性和检索噪声的脆弱性。我们探讨是否可以通过改进训练过程，使大型语言模型能够可靠地归因于（持续）预训练期间看到的文档——而无需测试时检索。为此，我们发布了CitePretrainBench基准，该基准混合了真实语料库（维基百科、Common Crawl、arXiv）和未见文档，并测试了短形式（单事实）和长形式（多事实）引用任务。我们的方法分为两个阶段：(1) 持续预训练，将事实与持久文档标识符绑定；(2) 指令微调，引导引用行为。我们发现，简单的被动索引法（为每篇文档附加标识符）有助于记忆逐字文本，但在转述或组合事实上表现不佳。为此，我们提出主动索引法，通过持续预训练合成多样化QA对，要求双向生成（从源到事实和从事实到源），共同训练模型从引用源生成内容并归因其答案。在Qwen2.5-7B和3B上的实验表明，主动索引法在所有任务和模型上均优于被动索引法，引用精度提升高达30.2%。消融研究表明，随着增强数据量的增加，性能持续提升，即使在原始标记量的16倍时仍呈现明显上升趋势。

</details>


### [269] [Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown](https://arxiv.org/abs/2506.17589)
**中文标题：驯服未知：基于图的知识检索与推理助力多模态大语言模型征服未知领域**

*Bowen Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于图的知识检索与推理方法，通过构建多模态知识图谱（MH-MMKG）和多智能体检索器，显著提升了多模态大语言模型（MLLMs）在罕见领域任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在多模态任务中表现出色，但在罕见领域任务中常因相关知识不足而失败。本文旨在探索如何通过知识检索与推理增强MLLMs的能力，以应对未知领域的挑战。

研究方法: 以视觉游戏认知为测试平台，构建了多模态知识图谱（MH-MMKG），并设计了一系列复杂查询任务。此外，提出了一种无需额外训练的多智能体检索器，使模型能够自主搜索相关知识。

研究结果: 实验结果表明，该方法显著提升了MLLMs在复杂知识检索与推理任务中的性能，为多模态知识增强推理提供了新视角。

研究结论: 本文提出的方法为MLLMs在罕见领域任务中的表现提供了有效解决方案，并为未来研究奠定了基础。

中文摘要: 知识的真正价值不仅在于其积累，更在于其被有效利用以征服未知的潜力。尽管近期的多模态大语言模型（MLLMs）展现了令人印象深刻的多模态能力，但在罕见领域任务中常因相关知识有限而失败。为此，我们以视觉游戏认知为测试平台，选择《怪物猎人：世界》为目标，构建了一个包含多模态和复杂实体关系的多模态知识图谱（MH-MMKG）。我们还基于MH-MMKG设计了一系列具有挑战性的查询任务，以评估模型在复杂知识检索与推理方面的能力。此外，我们提出了一种多智能体检索器，使模型能够在无需额外训练的情况下自主搜索相关知识。实验结果表明，我们的方法显著提升了MLLMs的性能，为多模态知识增强推理提供了新视角，并为未来研究奠定了坚实基础。

</details>


### [270] [Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges](https://arxiv.org/abs/2506.17644)
**中文标题：测量与增强大型语言模型解决夺旗赛挑战的能力**

*Zimo Ji,Daoyuan Wu,Wenyuan Jiang,Pingchuan Ma,Zongjie Li,Shuai Wang*

主要分类: cs.AI

摘要简述: 本文研究了大型语言模型（LLM）在解决网络安全夺旗赛（CTF）挑战中的能力，构建了CTFKnow基准测试，并提出CTFAgent框架以提升LLM的表现。实验显示CTFAgent在性能上提升了80%以上，并在实际比赛中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型的发展，其在自动化解决CTF挑战中的潜力受到关注。然而，LLM在技术知识应用和场景适应方面存在不足，因此需要深入研究并提升其能力。

研究方法: 论文构建了包含3,992个问题的CTFKnow基准测试，用于评估LLM的技术知识能力。随后提出了CTFAgent框架，包含两阶段检索增强生成（RAG）和交互式环境增强模块，以提升LLM的知识应用和漏洞利用能力。

研究结果: 实验结果表明，CTFAgent在两个流行的CTF数据集上实现了超过80%的性能提升，并在picoCTF2024比赛中排名前23.6%。

研究结论: 研究揭示了LLM在CTF挑战中的局限性，并通过CTFAgent框架显著提升了其表现，展示了该框架在推动LLM能力方面的潜力。

中文摘要: 夺旗赛（CTF）竞赛对网络安全教育和培训至关重要。随着大型语言模型（LLM）的发展，人们对其自动化解决CTF挑战的能力越来越感兴趣。例如，DARPA自2023年起组织了AIxCC竞赛，以推动AI驱动的自动化攻防。然而，这需要结合多种能力，从知识到推理再到行动。本文强调了技术知识在解决CTF问题中的重要性，并专门构建了一个包含3,992个问题的基准测试CTFKnow，以衡量LLM在这一核心方面的表现。我们的研究对LLM理解CTF知识并将其应用于解决CTF挑战的能力进行了创新性测量。关键发现表明，尽管LLM拥有丰富的技术知识，但在将知识准确应用于具体场景并根据CTF环境的反馈调整策略方面存在不足。基于这些发现，我们提出了CTFAgent，一种新型LLM驱动框架，用于提升CTF问题解决能力。CTFAgent引入了两阶段检索增强生成（RAG）和交互式环境增强模块，分别增强了LLM的技术知识和漏洞利用能力。实验结果显示，在两个流行的CTF数据集上，CTFAgent实现了超过80%的性能提升。此外，在CMU主办的picoCTF2024中，CTFAgent在近7,000支参赛队伍中排名前23.6%。这反映了我们测量研究的价值以及该框架在提升LLM解决CTF挑战能力方面的潜力。

</details>


### [271] [PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models](https://arxiv.org/abs/2506.17667)
**中文标题：PhysUniBench：面向多模态模型的本科物理推理基准测试**

*Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma*

主要分类: cs.AI

摘要简述: 本文提出了PhysUniBench，一个用于评估多模态大语言模型在本科物理问题推理能力的大规模多模态基准测试。该基准包含3,304个物理问题，覆盖8个主要物理子领域，并配有图表。实验显示当前先进模型在物理推理上表现不佳，如GPT-4o mini仅达到34.2%的准确率。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI模型在物理问题解决领域的能力评估存在局限性，尤其是在本科物理的广度和复杂性方面。因此，需要更严格的评估工具来推动多模态大语言模型在物理推理和问题解决能力上的进步。

研究方法: PhysUniBench通过多阶段严格流程构建，包括多次测试、专家评估、自动过滤简单问题以及五级难度分级系统。基准包含3,304个问题，涵盖8个物理子领域，并配有图表，问题类型包括开放式和选择题。

研究结果: 实验结果表明，当前最先进的多模态大语言模型在物理推理上表现较差，例如GPT-4o mini在PhysUniBench上的准确率仅为34.2%。模型在多步骤问题和需要精确图表解释的问题上尤其困难。

研究结论: PhysUniBench为AI在科学领域的进步提供了广泛而严格的评估工具，旨在推动模型在物理推理、问题解决和多模态理解能力上的发展。

中文摘要: 物理问题解决是大型AI模型的挑战性领域，需要整合概念理解、数学推理和物理图表解释。当前的评估方法在捕捉本科物理的广度和复杂性方面存在显著局限，凸显了对更严格评估的需求。为此，我们提出了PhysUniBench，一个大规模多模态基准测试，旨在评估和改进多模态大语言模型（MLLMs）在本科物理问题上的推理能力。PhysUniBench包含3,304个物理问题，涵盖8个主要物理子领域，每个问题配有一张图表。基准包括开放式和选择题，通过迭代的模型参与过程系统筛选和难度分级。基准的构建涉及多阶段严格流程，包括多次测试、专家评估、自动过滤易解决问题以及五级难度分级系统。通过大量实验，我们发现当前最先进模型在物理推理上表现不佳。例如，GPT-4o mini在PhysUniBench上的准确率仅为34.2%。这些结果表明，当前MLLMs在高级物理推理上存在困难，尤其是多步骤问题和需要精确图表解释的问题。通过提供广泛而严格的评估工具，PhysUniBench旨在推动AI在科学领域的进步，鼓励开发具有更强物理推理、问题解决和多模态理解能力的模型。基准和评估脚本可在https://prismax-team.github.io/PhysUniBenchmark/获取。

</details>


### [272] [Beyond Syntax: Action Semantics Learning for App Agents](https://arxiv.org/abs/2506.17697)
**中文标题：超越语法：面向App代理的动作语义学习**

*Bohan Tang,Dezhao Luo,Jingxuan Chen,Shaogang Gong,Jianye Hao,Jun Wang,Kun Shao*

主要分类: cs.AI

摘要简述: 本文提出了一种名为动作语义学习（ASL）的新框架，旨在通过捕捉动作的语义而非语法形式，提升App代理的准确性和泛化能力，解决了现有语法学习范式在分布外（OOD）问题上的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于提示的大语言模型（LLMs）解决方案虽然有效，但计算成本高且依赖外部API；而微调开源小模型的方法则因语法学习范式导致分布外（OOD）问题。本文旨在通过语义学习填补这一空白。

研究方法: 提出动作语义学习（ASL）框架，定义动作语义为用户界面中的状态转换，并设计语义估计器（SEE）计算语义奖励，训练代理生成语义一致的动作，即使语法形式不同。

研究结果: 理论分析和实验表明，ASL在分布外（OOD）问题上具有更强的鲁棒性，显著提升了App代理在离线和在线基准测试中的准确性和泛化能力。

研究结论: ASL通过语义学习范式有效解决了语法学习范式的局限性，为App代理的性能提升提供了新方向。

中文摘要: 大型语言模型（LLMs）的出现推动了App代理的兴起，这些代理通过点击和滚动等动作解释用户意图并操作智能手机应用。尽管基于提示的封闭LLM API解决方案显示出潜力，但其计算成本高且依赖外部API。微调较小的开源LLM可以解决这些限制，但当前的微调方法采用语法学习范式，强制代理完全复制真实动作字符串，导致分布外（OOD）脆弱性。为填补这一空白，我们提出了动作语义学习（ASL），一种新颖的学习框架，其学习目标是捕捉真实动作的语义。具体而言，受编程语言理论启发，我们将App代理的动作语义定义为用户界面中动作引发的状态转换。基于这一见解，ASL采用新型语义估计器（SEE）计算语义奖励，训练App代理生成与真实动作语义一致的动作，即使语法形式不同。为验证ASL的有效性，我们从理论上证明了ASL在OOD问题上的鲁棒性优于现有语法学习范式。在离线和在线智能手机应用操作基准测试中的大量实验表明，ASL显著提升了App代理的准确性和泛化能力。

</details>


### [273] [AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction](https://arxiv.org/abs/2506.17784)
**中文标题：AnyMAC：通过下一智能体预测实现级联灵活多智能体协作**

*Song Wang,Zhen Tan,Zihan Chen,Shuang Zhou,Tianlong Chen,Jundong Li*

主要分类: cs.AI

摘要简述: 本文提出了一种新的多智能体协作框架AnyMAC，通过序列化结构而非图结构实现灵活通信，结合Next-Agent Prediction和Next-Context Selection技术，显著提升了协作效率和适应性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于大语言模型的多智能体协作方法多依赖静态或图结构的通信拓扑，缺乏灵活性和适应性。本文旨在通过序列化结构重新设计多智能体协作，以扩展通信拓扑空间并提升协作效率。

研究方法: 提出AnyMAC框架，包含两个关键技术：(1) Next-Agent Prediction，动态选择最适合的智能体角色；(2) Next-Context Selection (NCS)，允许智能体选择性访问历史信息。两者结合构建任务自适应的通信管道。

研究结果: 在多个基准测试中，AnyMAC表现出卓越性能，同时显著降低了通信开销。

研究结论: AnyMAC通过序列化结构和动态通信技术，实现了多智能体协作的高效与灵活，为未来研究提供了新方向。

中文摘要: 近年来，基于大语言模型（LLM）的多智能体协作研究突显了结构化通信在激发集体智能方面的潜力。然而，现有方法主要依赖静态或基于图的智能体间拓扑结构，缺乏通信的潜在适应性和灵活性。本文提出了一种新框架，通过序列化结构而非图结构重新思考多智能体协作，为多智能体通信提供了更大的拓扑空间。我们的方法聚焦于两个关键方向：(1) Next-Agent Prediction，动态选择每一步最适合的智能体角色；(2) Next-Context Selection (NCS)，使每个智能体能够选择性访问任何先前步骤的相关信息。这些组件共同构建了任务自适应的通信管道，支持角色灵活性和全局信息流。在多个基准测试中的广泛评估表明，我们的方法在显著降低通信开销的同时，实现了卓越的性能。

</details>


### [274] [Bayesian Social Deduction with Graph-Informed Language Models](https://arxiv.org/abs/2506.17788)
**中文标题：基于图结构语言模型的贝叶斯社交推理**

*Shahab Rahimirad,Guven Gergerli,Lucia Romero,Angela Qian,Matthew Lyle Olson,Simon Stepputtis,Joseph Campbell*

主要分类: cs.AI

摘要简述: 本文提出了一种结合结构化概率模型与大型语言模型（LLM）的混合推理框架，用于解决社交推理任务中的挑战。该方法在社交推理游戏Avalon中表现优异，首次击败人类玩家，并显著优于现有基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在社交推理任务（如推断他人信念和意图）中表现有限，尤其是在实时推理和小型化模型上表现不佳。本文旨在通过结合结构化推理和语言模型，提升社交推理能力。

研究方法: 提出了一种混合推理框架，将信念推断任务交给结构化概率模型处理，同时利用LLM进行语言理解和交互。该方法在Avalon游戏中进行了验证。

研究结果: 该方法在Agent-Agent对战中表现优异，首次在受控研究中击败人类玩家，胜率达67%，且定性评分高于基线模型和人类队友。

研究结论: 结合结构化概率模型与LLM的混合框架显著提升了社交推理能力，为未来LLM在社交推理领域的研究提供了新方向。

中文摘要: 社交推理——从部分观察中推断其他智能体的不可见信念和意图——对大型语言模型（LLM）仍是一项挑战。我们评估了当前推理语言模型在社交推理游戏Avalon中的表现，发现尽管最大模型表现出色，但它们需要大量测试时推理，且在小型化实时模型上表现急剧下降。为此，我们提出了一种混合推理框架，将信念推断任务交给结构化概率模型，同时利用LLM进行语言理解和交互。我们的方法在Agent-Agent对战中与更大模型竞争，并首次在受控研究中击败人类玩家——胜率达67%，定性评分高于推理基线和人类队友。我们发布了代码、模型和数据集，以支持未来LLM智能体的社交推理研究，详见https://camp-lab-purdue.github.io/bayesian-social-deduction/。

</details>


### [275] [Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition](https://arxiv.org/abs/2506.17792)
**中文标题：基于分层块分解的MDP高效策略合成方法**

*Alexandros Evangelidis,Gricel Vázquez,Simos Gerasimou*

主要分类: cs.AI

摘要简述: 本文提出了一种通过分层块分解加速大规模MDP策略合成的方法，动态优化MDP并迭代选择脆弱区域进行细化，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统策略合成方法在大规模状态空间中难以扩展，本文旨在解决这一问题，通过动态优化MDP提升策略合成的效率和准确性。

研究方法: 采用分层块分解方法，动态细化MDP并迭代选择最脆弱的区域进行优化，实现效率与精度的平衡。

研究结果: 通过多种案例研究和高达100万状态的MDP验证，该方法性能显著优于PRISM模型检查器（最高提升2倍）。

研究结论: 该方法为大规模MDP中的实际策略合成任务提供了高效且具有竞争力的解决方案。

中文摘要: 软件密集型系统（如软件产品线和机器人技术）利用马尔可夫决策过程（MDP）来捕捉不确定性并分析序列决策问题。尽管传统策略合成方法具有一定实用性，但其难以扩展到大规模状态空间。我们的方法通过动态优化MDP并迭代选择最脆弱的区域进行细化，解决了这一问题，从而加速了大规模MDP中的策略合成。这种迭代过程在精度和效率之间取得了平衡，因为细化仅在必要时进行。通过包含多样化案例研究和高达100万状态的MDP的全面实证评估，我们证明了该方法相较于领先的概率模型检查器PRISM（最高提升2倍）具有显著的性能优势，从而为大规模MDP中的实际策略合成任务提供了极具竞争力的解决方案。

</details>


### [276] [Reflective Verbal Reward Design for Pluralistic Alignment](https://arxiv.org/abs/2506.17834)
**中文标题：用于多元对齐的反思性语言奖励设计**

*Carter Blair,Kate Larson,Edith Law*

主要分类: cs.AI

摘要简述: 本文提出了一种新型奖励建模方法，通过个性化对话学习个体化奖励模型，解决了传统RLHF方法中少数群体偏好被压制的问题。实验显示，该方法在准确性和样本效率上均优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统RLHF方法通过聚合人类反馈学习单一奖励模型，但人类价值观多样且可能存在冲突，导致少数群体偏好被压制。本文旨在解决这一问题，提出个体化奖励建模方法。

研究方法: 利用语言模型引导用户通过反思性对话构建个性化偏好，并将对话历史作为上下文，训练个体化奖励模型（称为“语言奖励模型”）以评估新行为轨迹。

研究结果: 在30名参与者的实验中，该方法比非反思性语言奖励模型准确率提高9-12%，且样本效率高于传统监督学习方法。

研究结论: 本文提出的个体化奖励建模方法有效解决了价值观多样性问题，显著提升了准确性和效率，为AI对齐提供了新思路。

中文摘要: AI代理通常通过人类反馈强化学习（RLHF）与“人类价值观”对齐，其中单一奖励模型从聚合的人类反馈中学习并用于对齐代理行为。然而，人类价值观并非同质化——不同人持有不同甚至冲突的价值观。将反馈聚合为单一奖励模型可能导致少数偏好被压制。为解决这一问题，我们提出了一种新型奖励建模方法，用于学习个体化奖励模型。该方法利用语言模型引导用户通过反思性对话批判代理行为并构建其偏好。这种个性化对话历史（包含用户的反思和批判示例）随后用作另一语言模型的上下文，该模型作为个体化奖励函数（我们称之为“语言奖励模型”）用于评估新轨迹。在30名参与者的研究中，我们的方法比非反思性语言奖励模型准确率提高9-12%，同时样本效率高于传统监督学习方法。

</details>


### [277] [Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)](https://arxiv.org/abs/2506.17846)
**中文标题：失控——为什么对齐需要形式控制理论（及对齐控制栈）**

*Elija Perrier*

主要分类: cs.AI

摘要简述: 本文主张将形式最优控制理论作为AI对齐研究的核心，提出了一种不同于现有AI安全和安全方法的视角。通过引入对齐控制栈，分层分析对齐问题，以增强对前沿模型和代理AI系统的控制潜力与局限的理解。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI安全和机制可解释性研究虽在形式上有所进展，但缺乏通用控制框架和协议互操作性研究。本文旨在通过形式最优控制理论重新定义对齐问题，并构建分层对齐控制栈，以填补这一空白。

研究方法: 提出对齐控制栈，分层分析从物理层到社会技术层的对齐问题，明确各层的测量和控制特性，并研究不同层之间的形式互操作性。

研究结果: 通过形式最优控制理论和对齐控制栈，为AI对齐提供了更全面的框架，增强了前沿模型和代理AI系统的安全性和可靠性。

研究结论: 将形式最优控制理论应用于AI对齐研究，能够结合实践经验与部署需求，构建更全面的对齐框架，为政府和监管机构提供必要的保障。

中文摘要: 本立场论文主张形式最优控制理论应成为AI对齐研究的核心，提供了一种不同于主流AI安全和安全方法的视角。尽管AI安全和机制可解释性研究在形式上有所进展，但其通用性不足，且缺乏对齐/控制协议的互操作性研究。通过将对齐问题重新定义为形式最优控制原则，并构建从物理层到社会技术层的分层对齐控制栈，可以更好地理解前沿模型和代理AI系统的控制潜力与局限。为此，我们引入了对齐控制栈，分层分析各层的测量和控制特性，以及不同层之间的形式互操作性。我们认为，这种分析也是政府和监管机构所需保障的关键。我们的立场是，通过结合形式最优控制理论与实际部署需求，可以构建更全面的对齐框架，提升高级AI系统的安全性和可靠性。

</details>


### [278] [Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval](https://arxiv.org/abs/2506.17878)
**中文标题：迈向稳健的事实核查：一种具备高级证据检索功能的多智能体系统**

*Tam Trinh,Manh Nguyen,Truong-Son Hy*

主要分类: cs.AI

摘要简述: 本文提出了一种新型多智能体系统，用于自动化事实核查，通过分解复杂声明、检索可信证据并生成透明解释，显著提升了准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 数字时代中错误信息的快速传播对公共讨论构成挑战，传统人工核查方法难以应对海量内容，而现有自动化方法在复杂声明处理、来源可信度和透明度方面存在局限。

研究方法: 系统包含四个专用智能体：输入解析智能体分解声明，查询生成智能体制定子查询，证据检索智能体获取可信证据，裁决预测智能体生成可解释的验证结果。

研究结果: 在基准数据集（FEVEROUS、HOVER、SciFact）上，系统Macro F1分数比基线方法提升12.3%，能有效分解复杂声明并生成透明解释。

研究结论: 该方法为自动化事实核查领域提供了更准确、高效且透明的验证方法，兼具可扩展性，符合人工核查实践。

中文摘要: 数字时代错误信息的快速传播对公共讨论构成重大挑战，亟需稳健且可扩展的事实核查解决方案。传统人工核查方法虽可信，但难以应对在线内容的体量和速度，促使基于大语言模型（LLMs）的自动化系统被引入。然而，现有自动化方法常面临局限，如处理复杂声明、确保来源可信度及保持透明度。本文提出一种新型多智能体系统，用于自动化事实核查，提升准确性、效率和可解释性。该系统包含四个专用智能体：输入解析智能体用于声明分解，查询生成智能体用于制定目标子查询，证据检索智能体用于获取可信证据，裁决预测智能体用于综合真实性判断并生成人类可理解的解释。在基准数据集（FEVEROUS、HOVER、SciFact）上的评估显示，该系统Macro F1分数比基线方法提升12.3%，能有效分解复杂声明、从可信来源检索可靠证据，并为验证决策生成透明解释。我们的方法为自动化事实核查领域提供了更准确、高效且透明的验证方法，符合人工核查实践，同时保持实际应用的可扩展性。源代码发布于https://github.com/HySonLab/FactAgent。

</details>


### [279] [Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms](https://arxiv.org/abs/2506.17900)
**中文标题：基于大语言模型的云AI平台智能日志处理与自主调试**

*Cheng Ji,Huaiying Luo*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大语言模型（LLM）的智能日志处理和自动调试框架LLM-ID，通过多阶段语义推理和强化学习策略，显著提升了云AI平台中的故障定位准确率。


<details>
  <summary>详细信息</summary>
研究动机: 随着云平台中AI系统的复杂性和规模迅速扩大，日志数据量大、非结构化且语义模糊，给故障定位和系统自修复带来巨大挑战。

研究方法: 扩展预训练的Transformer模型，结合多阶段语义推理机制，动态结构化系统日志，提取事件模板和语义模式；利用微调的LLM和多轮注意力机制进行上下文推理，生成潜在故障假设和根因路径；引入基于强化学习的策略引导恢复规划器，支持动态决策和自适应调试。

研究结果: 实验表明，LLM-ID在云平台日志数据集上的故障定位准确率提升了16.2%，显著优于当前主流方法。

研究结论: LLM-ID框架具有更强的语义理解能力、持续学习能力和异构环境适应性，为云AI平台的智能日志处理和自动调试提供了有效解决方案。

中文摘要: 随着云平台中AI系统复杂性和规模的迅速扩大，系统运行期间生成的日志数据量大、非结构化且语义模糊，为故障定位和系统自修复带来了巨大挑战。为解决这一问题，本文提出了一种基于大语言模型（LLM）的智能日志处理和自动调试框架，命名为智能调试器（LLM-ID）。该方法在现有预训练Transformer模型的基础上扩展，并整合了多阶段语义推理机制，实现了对系统日志的上下文理解和故障链的自动重建。首先，动态结构化系统日志，利用无监督聚类和嵌入机制提取事件模板和语义模式；随后，结合微调的LLM和多轮注意力机制对日志序列进行上下文推理，生成潜在故障假设和根因路径；此外，本文还引入了基于强化学习的策略引导恢复规划器，由LLM生成的修复策略驱动，支持云环境中的动态决策和自适应调试。与现有规则引擎或传统日志分析系统相比，所提模型具有更强的语义理解能力、持续学习能力和异构环境适应性。在云平台日志数据集上的实验表明，LLM-ID将故障定位准确率提高了16.2%，显著优于当前主流方法。

</details>


### [280] [Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents](https://arxiv.org/abs/2506.17913)
**中文标题：学习、推理与优化：基于Kahneman双系统理论的GUI代理智能框架**

*Jinjie Wei,Jiyao Liu,Lihao Liu,Ming Hu,Junzhi Ning,Mingcheng Li,Weijie Yin,Junjun He,Xiao Liang,Chao Feng,Dingkang Yang*

主要分类: cs.AI

摘要简述: 本文提出CogniGUI框架，结合Kahneman的双系统理论，通过快速视觉语义分析和相对奖励优化，实现GUI代理的适应性学习，并引入ScreenSeek基准测试其性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有GUI代理系统依赖试错决策，缺乏渐进推理能力，且评估指标过于简单，无法反映真实GUI交互的复杂性。本文旨在解决这些问题。

研究方法: CogniGUI框架包含两部分：(1) 全解析引擎，通过快速视觉语义分析识别可操作组件；(2) GRPO代理，使用相对奖励系统评估交互路径。此外，提出ScreenSeek基准测试代理的泛化能力。

研究结果: 实验表明，CogniGUI在现有GUI基准和新提出的ScreenSeek基准上均优于现有方法。

研究结论: CogniGUI通过双系统设计实现了GUI代理的适应性学习和高效交互，ScreenSeek基准为未来研究提供了更全面的评估标准。

中文摘要: 图形用户界面（GUI）代理通过计算机视觉和语言模型在自动化数字任务方面取得了显著进展。然而，现有系统存在明显局限：主要依赖试错决策而非渐进推理，缺乏从交互中学习的能力；评估指标过于简单，无法反映真实GUI交互的复杂性。本文提出CogniGUI框架，通过结合Kahneman的双过程理论，实现类似人类行为的GUI自动化学习。其核心包括：(1) 全解析引擎，通过快速视觉语义分析分层解析GUI元素；(2) GRPO代理，使用相对奖励系统评估交互路径，促进高效操作。此外，引入ScreenSeek基准，涵盖多应用导航、动态状态转换和跨界面一致性等挑战。实验证明，CogniGUI在现有基准和新基准上均优于现有方法。

</details>


### [281] [Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective](https://arxiv.org/abs/2506.17930)
**中文标题：上下文中的动态提示演化：一种开放式、自我复制的视角**

*Jianyu Wang,Zhiqiang Hu,Lidong Bing*

主要分类: cs.AI

摘要简述: 本文提出了一种新颖的提示设计范式，通过修剪随机演示为看似无意义的“胡言乱语”，显著提升大语言模型（LLM）在多种任务中的表现。该方法无需依赖传统优化技术，而是通过自发现框架PromptQuine自动搜索修剪策略，实现了高效且开放的提示优化。


<details>
  <summary>详细信息</summary>
研究动机: 传统提示设计依赖精心设计的指令和演示，但本文挑战这一常规思路，提出修剪随机演示为“胡言乱语”反而能提升性能。然而，如何发现有效的修剪策略仍是一个难题，现有方法无法提供稳健结果。

研究方法: 提出自发现提示优化框架PromptQuine，通过进化搜索自动寻找修剪策略，仅需少量数据即可实现高效优化。该框架利用上下文中的标记，模拟自然界的自组织现象，逐步演化出非常规但高效的提示。

研究结果: 实验表明，该方法在分类、多选问答、生成和数学推理等任务中均优于现有自动提示优化技术，且运行时效率较高。

研究结论: 本文发现为上下文学习机制研究提供了新方向，并呼吁开发更多开放式搜索算法以优化LLM提示设计。

中文摘要: 我们提出了一种新颖的提示设计范式，挑战了大语言模型（LLM）提示设计的传统观念。传统观念强调精心设计的指令和演示对上下文学习（ICL）的重要性，而我们发现将随机演示修剪为看似无意义的“胡言乱语”反而能显著提升多种任务的性能。值得注意的是，这种“胡言乱语”始终优于或等同于最先进的自动提示优化技术，且不受LLM对齐的影响。然而，发现有效的修剪策略并非易事，现有归因方法和提示压缩算法均无法提供稳健结果，更不用说人类直觉。为此，我们提出了一种自发现提示优化框架PromptQuine，这是一种进化搜索框架，仅需少量数据即可自动搜索修剪策略。类似于自然界中因资源限制而涌现的复杂性（如共生和自组织），我们的框架通过利用上下文中的标记，逐步演化出非常规但高效的提示。我们在多种LLM的分类、多选问答、生成和数学推理任务中验证了其有效性，同时保持了较高的运行时效率。我们希望这些发现能为上下文学习的机制研究提供指导，并呼吁开发更多开放式搜索算法，以推动更高效的LLM提示设计。

</details>


### [282] [medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs](https://arxiv.org/abs/2506.17959)
**中文标题：medicX-KG：满足药剂师药物信息需求的知识图谱**

*Lizzy Farrugia,Lilian M. Azzopardi,Jeremy Debattista,Charlie Abela*

主要分类: cs.AI

摘要简述: 本文介绍了medicX-KG，一个面向药剂师的知识图谱，旨在整合多源药物数据，支持临床和监管决策，解决药物信息碎片化问题。


<details>
  <summary>详细信息</summary>
研究动机: 药剂师的角色正从简单的药物分发转向提供全面的药学服务，但缺乏统一的药物信息库，导致依赖碎片化数据来源。medicX-KG旨在通过知识图谱技术整合多源数据，支持药剂师的决策需求。

研究方法: medicX-KG整合了英国国家处方集（BNF）、DrugBank和马耳他药物管理局（MMA）的数据，通过数据提取、本体设计和语义映射构建知识图谱。设计过程中还参考了药剂师的实践需求。

研究结果: 评估表明，medicX-KG能有效支持关于药物可用性、相互作用、不良反应和治疗类别的查询。但也存在剂量编码不详细和实时更新不足的局限性。

研究结论: medicX-KG为药剂师提供了一个统一的药物信息平台，支持临床和监管决策。未来需改进剂量编码和实时更新功能。

中文摘要: 药剂师的角色正从药物分发转向在多学科医疗团队中提供全面的药学服务。这一转变的核心是获取准确、最新的药物信息，并依赖强大的数据整合。借助人工智能和语义技术，知识图谱（KGs）能够揭示隐藏的关系并支持数据驱动的决策。本文介绍了medicX-KG，一个面向药剂师的知识图谱，旨在支持临床和监管决策。它作为medicX平台的语义层，为预测性和可解释的药学服务提供支持。medicX-KG整合了三个数据源，包括英国国家处方集（BNF）、DrugBank和马耳他药物管理局（MMA），以应对马耳他的监管环境，同时结合欧洲药品管理局的规范并部分依赖英国的供应。该知识图谱解决了缺乏统一国家药物库的问题，减少了药剂师对碎片化来源的依赖。其设计基于对执业药剂师的访谈，以确保实际适用性。我们详细介绍了知识图谱的构建过程，包括数据提取、本体设计和语义映射。评估表明，medicX-KG能有效支持关于药物可用性、相互作用、不良反应和治疗类别的查询。文中还讨论了局限性，如缺少详细的剂量编码和实时更新功能，并提出了未来的改进方向。

</details>


### [283] [Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities](https://arxiv.org/abs/2506.18019)
**中文标题：图与AI代理的交汇：分类、进展与未来机遇**

*Yuanchen Bei,Weizhi Zhang,Siwen Wang,Weizhi Chen,Sheng Zhou,Hao Chen,Yong Li,Jiajun Bu,Shirui Pan,Yizhou Yu,Irwin King,Fakhri Karray,Philip S. Yu*

主要分类: cs.AI

摘要简述: 本文系统综述了图技术如何赋能AI代理，探讨了图技术与核心代理功能的结合、显著应用及未来研究方向，旨在推动下一代AI代理的发展。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI代理从强化学习（RL）到大型语言模型（LLMs）的演进，其能力不断增强，但完成复杂任务仍需高效规划、可靠记忆和多代理协调。图技术因其结构化数据的优势，有望支持这些能力。

研究方法: 本文通过系统综述，探讨了图技术与AI代理核心功能的结合，包括规划、记忆和协调，并总结了相关应用和未来研究方向。

研究结果: 研究发现，图技术能够有效支持AI代理处理复杂数据和交互，提升其任务执行能力，并为未来研究提供了多个潜在方向。

研究结论: 图技术为AI代理提供了强大的数据范式支持，未来研究应进一步探索其与代理功能的深度融合，以应对更复杂的挑战。

中文摘要: AI代理经历了从强化学习（RL）到大型语言模型（LLMs）的范式转变，如今进一步向RL与LLM能力的协同融合迈进。这一进展赋予代理更强大的能力，但完成复杂现实任务仍需高效规划、可靠记忆和多代理协调。面对这一挑战，数据结构化通过将复杂无序数据转化为结构化形式，有望支持代理更高效地理解和处理数据。在此背景下，图凭借其在组织、管理和利用复杂数据关系方面的天然优势，为支持高级AI代理能力提供了强大的数据范式。为此，本文首次系统综述了图如何赋能AI代理，探讨了图技术与核心代理功能的结合、显著应用及未来研究方向。通过全面综述这一新兴交叉领域，我们希望推动下一代AI代理的发展，使其能够借助图技术应对日益复杂的挑战。相关资源已在Github链接中收集并持续更新。

</details>


### [284] [Action Language BC+](https://arxiv.org/abs/2506.18044)
**中文标题：动作语言BC+**

*Joseph Babb,Joohyung Lee*

主要分类: cs.AI

摘要简述: 本文提出了一种新的动作语言BC+，旨在弥补传统动作语言与现代答案集编程（ASP）语言之间的差距，通过广义稳定模型语义实现更丰富的知识表示。


<details>
  <summary>详细信息</summary>
研究动机: 传统动作语言在描述动作效果时功能有限，无法充分利用现代ASP语言的高级特性（如选择规则、聚合和抽象约束原子）。本文旨在提出一种新语言BC+，以填补这一空白。

研究方法: BC+基于广义稳定模型语义定义，将现代ASP语言构造视为命题公式的简写形式，从而支持更复杂的知识表示。该方法通过扩展系统cplus2asp实现。

研究结果: BC+成功整合了其他动作语言（如B、C、C+和BC）的优良特性，并通过ASP求解器实现了高效计算。

研究结论: BC+是一种表达力强且计算高效的动作语言，为动作描述和知识表示提供了更强大的工具。

中文摘要: 动作语言是自然语言中用于描述动作效果的形式化模型。许多动作语言可视为表示过渡系统的高级答案集程序。然而，早期研究中的答案集程序形式与现代答案集编程（ASP）语言相比功能有限，后者支持选择规则、聚合和抽象约束原子等知识表示构造。本文提出一种新动作语言BC+，以弥补动作语言与现代ASP语言之间的差距。其核心思想是基于命题公式的广义稳定模型语义定义BC+的语义，将现代ASP语言构造视为命题公式的简写。BC+的表达力足以涵盖其他动作语言（如B、C、C+和BC）的最佳特性。通过扩展系统cplus2asp，实现了BC+的计算方法，可直接利用ASP求解器进行计算。

</details>


### [285] [Weighted Assumption Based Argumentation to reason about ethical principles and actions](https://arxiv.org/abs/2506.18056)
**中文标题：基于加权假设的论证方法用于伦理原则与行为推理**

*Paolo Baldi,Fabio Aurelio D'Asaro,Abeer Dyoub,Francesca Alessandra Lisi*

主要分类: cs.AI

摘要简述: 本文提出了一种基于加权假设的论证方法（ABA），通过为论证分配权重并推导攻击权重，应用于伦理推理领域，并基于答案集编程实现。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于扩展假设基于论证（ABA）的能力，通过引入权重机制，使其能够更有效地处理伦理原则与行为之间的复杂推理问题。

研究方法: 方法包括为ABA中的论证分配权重，并推导论证之间的攻击权重。通过伦理推理的实际案例进行说明，并基于答案集编程实现该方法。

研究结果: 结果表明，加权ABA能够有效支持伦理推理，并通过具体案例展示了其实际应用价值。

研究结论: 结论指出，加权ABA为伦理推理提供了一种新的工具，其实现方法具有可行性和实用性。

中文摘要: 我们通过加权论证扩展了假设基于论证（ABA）。简而言之，我们为论证分配权重，并推导ABA论证之间的攻击权重。通过伦理推理领域的实例展示了我们的方法，并基于答案集编程实现了该方案。

</details>


### [286] [Deep Research Agents: A Systematic Examination And Roadmap](https://arxiv.org/abs/2506.18096)
**中文标题：深度研究智能体：系统化审视与路线图**

*Yuxuan Huang,Yihang Chen,Haozheng Zhang,Kang Li,Meng Fang,Linyi Yang,Xiaoguang Li,Lifeng Shang,Songcen Xu,Jianye Hao,Kun Shao,Jun Wang*

主要分类: cs.AI

摘要简述: 本文系统分析了深度研究（DR）智能体的核心技术、架构组件及分类，提出了静态与动态工作流的分类法，并评估了当前基准的局限性，同时指出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）的快速发展，深度研究智能体（DR agents）成为解决复杂多轮信息研究任务的新兴工具。本文旨在系统梳理其核心技术、架构及分类，并为未来研究提供方向。

研究方法: 文章首先对比了基于API和浏览器的信息获取策略，接着探讨了模块化工具使用框架（如代码执行、多模态输入处理等），并提出了静态与动态工作流的分类法。此外，还根据规划策略和智能体组成（单智能体与多智能体）对架构进行了分类。

研究结果: 研究提出了DR智能体的分类法，并指出当前基准的局限性，如外部知识访问受限、顺序执行效率低及评估指标与实际目标不匹配等问题。

研究结论: 本文系统总结了DR智能体的技术现状，提出了未来研究的开放挑战与方向，并提供了相关研究的持续更新资源库。

中文摘要: 大型语言模型（LLMs）的快速发展催生了一类新型自主AI系统，称为深度研究（DR）智能体。这些智能体通过动态推理、自适应长程规划、多跳信息检索、迭代工具使用以及结构化分析报告生成，旨在解决复杂的多轮信息研究任务。本文详细分析了构成深度研究智能体的基础技术与架构组件。首先回顾了信息获取策略，对比了基于API的检索方法与基于浏览器的探索。接着探讨了模块化工具使用框架，包括代码执行、多模态输入处理以及支持可扩展性和生态系统开发的模型上下文协议（MCPs）集成。为系统化现有方法，我们提出了区分静态与动态工作流的分类法，并根据规划策略和智能体组成（单智能体与多智能体）对架构进行了分类。此外，我们还对当前基准进行了批判性评估，指出了关键局限性，如外部知识访问受限、顺序执行效率低以及评估指标与DR智能体实际目标不匹配等问题。最后，我们概述了未来研究的开放挑战与方向。相关研究的精选与持续更新资源库可在以下链接获取：{https://github.com/ai-agents-2030/awesome-deep-research-agent}。

</details>


### [287] [Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game](https://arxiv.org/abs/2506.18126)
**中文标题：基于共识推断的分层强化学习在多约束无人机追逃游戏中的应用**

*Xiang Yuming,Li Sizhao,Li Rongpeng,Zhao Zhifeng,Zhang Honggang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于共识推断的分层强化学习框架（CI-HRL），用于解决多约束无人机追逃游戏中的高维复杂问题，通过高低层策略分工协作，提升无人机群的协同逃逸和任务完成能力。


<details>
  <summary>详细信息</summary>
研究动机: 多约束无人机追逃游戏（MC-PEG）中的协同逃逸与编队覆盖任务（CEFC）在通信受限条件下极具挑战性，涉及障碍物、敌手、目标区域和编队动态等多维复杂问题，亟需高效解决方案。

研究方法: 提出CI-HRL框架，高层策略采用共识导向多智能体通信（ConsMAC）实现全局感知与共识建立，低层策略结合交替训练多智能体近端策略优化（AT-M）和策略蒸馏，完成避障、导航与编队控制。

研究结果: 高保真软件在环（SITL）仿真实验表明，CI-HRL显著提升了无人机群的协同逃逸和任务完成能力。

研究结论: CI-HRL为多约束无人机追逃游戏提供了一种高效解决方案，通过分层策略和共识推断机制，有效应对高维复杂问题。

中文摘要: 多旋翼无人机（UAV）系统在多约束追逃游戏（MC-PEG）中具有广泛应用前景，其中协同逃逸与编队覆盖任务（CEFC）尤为复杂，尤其在通信受限条件下。该问题涉及障碍物、敌手、目标区域和编队动态等多维复杂性。本文提出一种新颖的两层框架——基于共识推断的分层强化学习（CI-HRL），高层策略负责目标定位，低层策略处理避障、导航和编队。高层策略中，我们开发了共识导向多智能体通信（ConsMAC），通过有效聚合邻居信息实现全局感知与共识建立；低层策略则结合交替训练多智能体近端策略优化（AT-M）和策略蒸馏完成控制。高保真软件在环（SITL）仿真实验验证了CI-HRL在提升无人机群协同逃逸和任务完成能力方面的优越性。

</details>


### [288] [SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging](https://arxiv.org/abs/2506.18135)
**中文标题：SE-Merging：一种自增强的动态模型融合方法**

*Zijun Chen,Zhanpeng Zhou,Bo Zhang,Weinan Zhang,Xi Sun,Junchi Yan*

主要分类: cs.AI

摘要简述: 本文提出了一种自增强的动态模型融合方法SE-Merging，通过分析模型融合的机制，发现其多任务能力依赖于区分不同任务样本和适应对应专家模型的能力。SE-Merging利用这两点动态识别任务并调整融合系数，无需额外训练即可显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管模型融合在实践中表现出多任务能力，但其机制尚不明确。本文旨在从表示角度揭示模型融合的机制，并基于此提出一种自增强的动态融合方法。

研究方法: 通过分析模型融合的机制，提出SE-Merging框架，动态识别样本任务并自适应调整融合系数，以增强任务特定能力。该方法无需额外训练。

研究结果: 实验表明，SE-Merging显著提升了模型融合的性能，同时与现有融合技术兼容。

研究结论: SE-Merging通过动态调整融合系数，有效提升了模型融合的多任务能力，为模型融合研究提供了新思路。

中文摘要: 模型融合因其能够通过插值不同任务微调模型的参数实现多任务能力而受到广泛关注。然而，尽管其经验性成功，模型融合的机制仍未被充分理解。本文从表示角度深入研究了模型融合的机制，发现其多任务能力依赖于两个关键能力：i) 区分不同任务的样本，ii) 为每个样本适应对应的专家模型。这两种能力使融合模型保留任务特定专长，实现高效的多任务适应。基于这些发现，我们提出了SE-Merging，一种自增强的模型融合框架，利用这两种特性动态识别样本任务并自适应调整融合系数，以进一步增强融合模型的任务特定专长。值得注意的是，SE-Merging无需额外训练即可实现动态模型融合。大量实验表明，SE-Merging在保持与现有融合技术兼容的同时，显著提升了性能。

</details>


### [289] [CoachGPT: A Scaffolding-based Academic Writing Assistant](https://arxiv.org/abs/2506.18149)
**中文标题：CoachGPT：基于支架式学习的学术写作助手**

*Fumian Chen,Sotheara Veng,Joshua Wilson,Xiaoming Li,Hui Fang*

主要分类: cs.AI

摘要简述: CoachGPT是一款基于大型语言模型的学术写作助手，通过分步任务和实时反馈帮助用户提升写作能力，尤其适合资源有限或偏好自主学习的学习者。


<details>
  <summary>详细信息</summary>
研究动机: 学术写作对学生至关重要，但缺乏指导和资源时可能令人望而生畏。传统写作助手功能有限，而大型语言模型虽强大但缺乏教育性反馈。因此，开发CoachGPT以结合教育指导和语言模型能力，提供更有效的写作支持。

研究方法: CoachGPT是一个基于AI代理的网页应用，通过接收教育者的指令，将其分解为子任务，并利用大型语言模型提供实时反馈和建议，形成独特的支架式学习结构。

研究结果: 用户研究表明，CoachGPT提供了沉浸式的写作体验和个性化反馈，优于现有写作助手，展示了大型语言模型在学术写作中的潜力。

研究结论: CoachGPT通过结合教育指导和语言模型技术，有效提升了学术写作的辅助效果，为资源有限的学习者提供了实用工具。

中文摘要: 学术写作能力对学生的成功至关重要，但缺乏适当指导和练习时可能令人感到压力，尤其是用第二语言写作时。传统上，学生会向教师求助或查阅词典，但这些方法并非普遍可用。早期的写作助手是基于规则的系统，专注于检测拼写错误、主谓不一致和基本标点错误，但它们准确性不足且缺乏上下文理解。基于机器学习的助手在语言理解方面表现优异，但训练成本高昂。大型语言模型（LLMs）在根据提示生成自然语言响应方面表现出色，但在教育中存在根本性限制：它们生成文章而不教授，若被误用可能对学习产生负面影响。为解决这一问题，我们开发了CoachGPT，利用大型语言模型帮助教育资源有限或偏好自主学习的学习者进行学术写作。CoachGPT是一款基于AI代理的网页应用，能够（1）接收经验丰富的教育者的指令，（2）将指令转化为子任务，（3）利用大型语言模型提供实时反馈和建议。这种独特的支架式结构使CoachGPT在现有写作助手中独树一帜。与现有写作助手相比，CoachGPT提供了更具沉浸感的写作体验和个性化反馈与指导。我们的用户研究证明了CoachGPT的实用性以及大型语言模型在学术写作中的潜力。

</details>


### [290] [AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology](https://arxiv.org/abs/2506.18156)
**中文标题：从人类视角看AI：机器心理学中的认知理论研究**

*Akash Kundu,Rishika Goswami*

主要分类: cs.AI

摘要简述: 研究探讨大型语言模型（LLMs）是否在四种心理学框架下表现出类似人类的认知模式，发现其行为与人类认知倾向相似，但受训练数据和校准方法影响。


<details>
  <summary>详细信息</summary>
研究动机: 探讨大型语言模型是否具有类似人类的认知模式，以心理学理论为框架，评估其透明度和伦理部署的潜在影响。

研究方法: 使用主题统觉测试（TAT）、框架偏差、道德基础理论（MFT）和认知失调四种心理学框架，通过结构化提示和自动评分评估多个专有和开源模型。

研究结果: 模型能生成连贯叙述，易受正面框架影响，道德判断偏向自由/压迫问题，并通过大量合理化缓解自我矛盾，行为与人类认知倾向相似。

研究结论: 模型行为与人类认知倾向相似，但受训练数据和校准方法影响，需进一步研究以提升AI透明度和伦理部署。

中文摘要: 我们研究了大型语言模型（LLMs）是否在四种心理学框架下表现出类似人类的认知模式：主题统觉测试（TAT）、框架偏差、道德基础理论（MFT）和认知失调。通过结构化提示和自动评分，我们评估了多个专有和开源模型。研究发现，这些模型常能生成连贯叙述，易受正面框架影响，道德判断偏向自由/压迫问题，并通过大量合理化缓解自我矛盾。这些行为与人类认知倾向相似，但受训练数据和校准方法影响。我们讨论了其对AI透明度、伦理部署以及未来结合认知心理学与AI安全研究的启示。

</details>


### [291] [Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation](https://arxiv.org/abs/2506.18158)
**中文标题：记忆链：增强跨应用导航的GUI代理**

*Xinzge Gao,Chuanrui Hu,Bin Chen,Teng Li*

主要分类: cs.AI

摘要简述: 本文提出了一种名为Chain-of-Memory (CoM)的新方法，通过显式建模短期和长期记忆，提升GUI代理在跨应用任务中的导航能力。实验证明CoM显著提高了性能，并使得7B模型具备与72B模型相当的记忆管理能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的GUI代理方法依赖历史截图或动作隐式表示任务状态，导致在复杂跨应用任务中难以准确理解任务状态且缺乏有效信息存储机制。为解决这些问题，本文提出了CoM方法。

研究方法: CoM通过捕获动作描述、整合任务相关屏幕信息，并维护专用记忆模块来显式建模短期和长期记忆。此外，开发了包含11.1万屏幕-动作对的GUI Odyssey-CoM数据集以评估CoM效果。

研究结果: 实验结果表明，CoM显著提升了GUI代理在跨应用任务中的性能，并使7B模型达到与72B模型相当的记忆管理能力。

研究结论: CoM通过显式记忆表示有效解决了GUI代理在复杂任务中的状态理解和信息存储问题，为未来研究提供了重要工具和数据支持。

中文摘要: 多模态大语言模型（MLLMs）在图形用户界面（GUI）代理开发中受到越来越多的关注。现有方法通常依赖历史截图或动作隐式表示任务状态，这导致GUI代理难以准确理解任务状态，并凸显了在复杂且冗长的跨应用任务中缺乏有效信息存储机制的问题。为解决这些问题，我们提出了记忆链（Chain-of-Memory, CoM），一种显式建模GUI代理中短期和长期记忆的新方法。CoM通过捕获动作描述、整合任务相关屏幕信息，并维护专用记忆模块来存储和管理这些信息。通过利用显式记忆表示，CoM使GUI代理能够更好地理解任务状态并持久保留关键历史信息。为赋予GUI代理记忆管理能力并评估CoM的有效性，我们开发了GUI Odyssey-CoM数据集，包含11.1万条标注了记忆链的屏幕-动作对。实验结果表明，CoM显著提升了GUI代理在跨应用任务中的性能。此外，GUI Odyssey-CoM使7B模型达到了与72B模型相当的记忆管理能力。数据集和代码将开源。

</details>


### [292] [Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?](https://arxiv.org/abs/2506.18183)
**中文标题：关于不确定性的推理：推理模型是否知道它们不知道？**

*Zhiting Mei,Christina Zhang,Tenny Yin,Justin Lidard,Ola Shorinwa,Anirudha Majumdar*

主要分类: cs.AI

摘要简述: 本文探讨了推理语言模型的不确定性量化问题，发现这些模型通常过于自信，尤其是错误答案的置信度常超过85%。通过引入自省不确定性量化（UQ），研究发现更深层次的推理会加剧过度自信，但部分模型可通过自省改善校准。


<details>
  <summary>详细信息</summary>
研究动机: 推理语言模型在多项基准测试中表现优异，但其生成的答案可能错误且过度自信。为确保模型在实际应用中的安全部署，研究探索了模型的不确定性量化问题，重点关注其校准性、推理深度的影响以及自省的作用。

研究方法: 研究通过自省不确定性量化（UQ）方法，评估了多个先进推理模型在广泛基准测试中的表现，分析了模型的校准性、推理深度对置信度的影响，以及自省对校准的改进效果。

研究结果: 研究发现：（1）推理模型通常过度自信，错误答案的置信度常超过85%；（2）更深层次的推理会进一步加剧过度自信；（3）部分模型通过自省改善了校准性（如o3-Mini和DeepSeek R1），但并非所有模型均如此（如Claude 3.7 Sonnet校准性反而变差）。

研究结论: 研究强调了设计不确定性量化基准和改进推理模型校准性的重要性，为未来研究提供了方向。

中文摘要: 推理语言模型在许多具有挑战性的基准测试中创下了最先进的记录，这得益于通过强化学习诱导的多步推理。然而，与之前的语言模型类似，推理模型容易生成自信但错误的回答（幻觉）。了解何时以及多大程度上信任这些模型对于推理模型在现实应用中的安全部署至关重要。为此，本研究探索了推理模型的不确定性量化问题。具体而言，我们提出了三个基本问题：首先，推理模型是否校准良好？其次，更深的推理是否能改善模型校准？最后，受人类天生能够通过双重检查思维过程来验证答案及其信心的启发，我们提出：推理模型能否通过显式推理其思维链痕迹来改善校准？我们引入了自省不确定性量化（UQ）来探索这一方向。在对多个先进推理模型在广泛基准测试中的评估中，我们发现推理模型：（i）通常过度自信，尤其是错误答案的自述置信度常超过85%；（ii）随着推理深度增加，过度自信进一步加剧；（iii）部分模型可通过自省改善校准性（如o3-Mini和DeepSeek R1），但并非所有模型均如此（如Claude 3.7 Sonnet校准性反而变差）。最后，我们总结了设计必要的不确定性量化基准和改进推理模型校准性的重要研究方向。

</details>


### [293] [The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis](https://arxiv.org/abs/2506.18187)
**中文标题：药物未依从性对不良后果的影响：基于精神分裂症患者的生存分析证据**

*Shahriar Noroozizadeh,Pim Welle,Jeremy C. Weiss,George H. Chen*

主要分类: cs.AI

摘要简述: 本研究通过生存分析量化了精神分裂症患者未按时服用抗精神病药物与不良后果（如早逝、强制住院、入狱）之间的关系，发现未服药会提前1至4个月导致不良事件。


<details>
  <summary>详细信息</summary>
研究动机: 精神分裂症患者的药物依从性对临床结果至关重要，但缺乏对其与不良后果关系的量化研究。本研究旨在填补这一空白，为临床和政策制定提供依据。

研究方法: 采用生存分析方法，结合因果推断工具（T-learner、S-learner、最近邻匹配），利用不同时间跨度（3、6、9、12个月）的纵向数据，估计个体和平均治疗效果。

研究结果: 研究发现，未服药会使不良事件提前1至4个月发生。亚组分析显示，无论是注射还是口服药物，未服药均与不良事件提前相关。

研究结论: 药物依从性对延缓精神分裂症患者的不良事件至关重要。生存分析与因果推断结合可为政策制定提供重要参考，但需注意因果解释的假设限制。

中文摘要: 本研究量化了精神分裂症患者未按时服用抗精神病药物与不良后果之间的关系。通过生存分析方法，关注多种不良事件（早逝、强制住院、入狱）的最早发生时间。扩展了标准因果推断方法（T-learner、S-learner、最近邻匹配），利用不同生存模型估计个体和平均治疗效果，其中治疗对应药物未依从性。分析使用了不同时间跨度（3、6、9、12个月）的纵向数据。基于宾夕法尼亚州阿勒格尼县的数据，研究发现未服药会使不良事件提前1至4个月。消融研究证实，县提供的风险评分调整了关键混杂因素，移除这些评分会放大估计效果。亚组分析（注射与口服药物）一致表明未服药与不良事件提前相关。这些发现强调了依从性在延缓精神危机中的临床重要性，并表明生存分析与因果推断工具结合可提供政策相关见解。需注意，尽管应用了因果推断，但研究仅提出关联性结论，并讨论了因果解释所需的假设。

</details>


### [294] [A Conceptual Framework for AI Capability Evaluations](https://arxiv.org/abs/2506.18213)
**中文标题：AI能力评估的概念框架**

*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Luca Nicolás Forziati Gangi,Matheo Sandleris Musa,Lola Ramos Pereyra,Mario Leiva,Juan Gustavo Corvalan,María Vanina Martinez,Gerardo Simari*

主要分类: cs.AI

摘要简述: 本文提出了一个AI能力评估的概念框架，旨在通过结构化、描述性方法提升评估的透明度、可比性和可解释性，帮助研究人员、实践者和政策制定者更好地分析和设计评估。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI系统的发展和广泛应用，透明且设计良好的评估成为AI治理的关键工具。然而，目前缺乏全面且可靠的评估方法，因此需要建立一个系统化的框架来解决这一问题。

研究方法: 作者提出了一种概念框架，通过结构化、描述性方法分析AI能力评估，不引入新的分类或固定格式，而是系统化现有方法和术语的分析。

研究结果: 该框架支持评估的透明度、可比性和可解释性，帮助研究人员发现方法缺陷，辅助实践者设计评估，并为政策制定者提供工具以审查和比较复杂的评估体系。

研究结论: 该框架为AI能力评估提供了一个实用的工具，有助于提升评估的质量和实用性，推动AI治理的透明化和标准化。

中文摘要: 随着AI系统的进步及其在社会中的广泛应用，设计良好且透明的评估已成为AI治理的重要工具，通过提供关于系统能力和风险的证据来支持决策。然而，目前仍缺乏全面且可靠的评估方法。为解决这一问题，我们提出了一个分析AI能力评估的概念框架，采用结构化、描述性方法，系统化分析广泛使用的方法和术语，而不引入新的分类或固定格式。该框架支持不同评估之间的透明度、可比性和可解释性，帮助研究人员识别方法缺陷，辅助实践者设计评估，并为政策制定者提供一个易于使用的工具，以审查、比较和应对复杂的评估体系。

</details>


### [295] [The 4th Dimension for Scaling Model Size](https://arxiv.org/abs/2506.18233)
**中文标题：扩展模型规模的第四维度**

*Ruike Zhu,Hanwen Zhang,Tianyu Shi,Chi Wang,Tianyi Zhou,Zengyi Qin*

主要分类: cs.AI

摘要简述: 本文提出了一种新的模型规模扩展维度——虚拟逻辑深度（VLD），通过参数复用在不增加参数总量的情况下提升模型的有效算法深度，研究发现VLD扩展能显著提升推理能力，而无需增加参数数量。


<details>
  <summary>详细信息</summary>
研究动机: 传统的大语言模型规模扩展通常涉及深度、宽度和参数数量三个维度，但参数复用的潜力及其在模型扩展中的特性尚未被充分研究。本文旨在探索虚拟逻辑深度（VLD）作为第四维度，以揭示其在模型扩展中的作用和潜力。

研究方法: 通过精心设计的控制实验，研究虚拟逻辑深度（VLD）对模型性能的影响，重点关注参数复用对知识容量和推理能力的提升效果。

研究结果: 研究发现：1）VLD扩展几乎不改变模型的知识容量；2）在正确实施的情况下，VLD能显著提升推理能力；3）参数数量与知识容量相关，但与推理能力无关，某些情况下无需增加参数即可提升推理能力。

研究结论: 虚拟逻辑深度（VLD）是一种有效的模型扩展维度，能够在不增加参数数量的情况下显著提升推理能力，这一发现在多种模型配置中具有普遍性。

中文摘要: 扩展大语言模型的规模通常涉及三个维度：深度、宽度和参数数量。本文探索了第四维度——虚拟逻辑深度（VLD），它通过复用模型内的参数来增加有效算法深度，而不改变总参数数量。尽管参数复用并非新概念，但其在模型扩展中的潜力和特性尚未得到充分研究。通过精心设计的控制实验，我们得出以下关于VLD扩展的关键发现：
  VLD扩展迫使模型的知识容量几乎保持不变，仅存在微小变化。
  在正确实施的情况下，VLD扩展能显著提升推理能力。
  参数数量与知识容量相关，但与推理能力无关。在某些条件下，无需增加参数数量即可提升推理能力。
  这些发现在多种模型配置中一致，可能具有普遍有效性。

</details>


### [296] [Advanced For-Loop for QML algorithm search](https://arxiv.org/abs/2506.18260)
**中文标题：用于QML算法搜索的高级For-Loop框架**

*FuTe Wong*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大型语言模型多智能体系统（LLMMA）的高级框架，用于自动搜索和优化量子机器学习（QML）算法。通过迭代生成和优化经典机器学习算法的量子变换，展示了智能体框架在量子计算中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 受Google DeepMind的FunSearch启发，本文旨在利用多智能体系统自动化探索和优化量子机器学习算法，填补经典机器学习与量子计算之间的鸿沟。

研究方法: 采用基于大型语言模型的多智能体系统（LLMMA），在抽象层面上迭代生成和优化经典机器学习算法（如多层感知机、前向-前向和反向传播算法）的量子变换。

研究结果: 作为概念验证，该系统展示了智能体框架在系统化探索经典机器学习概念并将其适配到量子计算中的潜力，为高效自动化开发QML算法奠定了基础。

研究结论: 本文提出的框架为量子增强机器学习的自动化算法开发开辟了新途径，未来研究方向包括引入规划机制和优化搜索策略以扩大应用范围。

中文摘要: 本文介绍了一种基于大型语言模型多智能体系统（LLMMA）的高级框架，用于自动搜索和优化量子机器学习（QML）算法。受Google DeepMind的FunSearch启发，该系统在抽象层面上迭代生成和优化经典机器学习算法（如多层感知机、前向-前向和反向传播算法）的量子变换。作为概念验证，本研究展示了智能体框架在系统化探索经典机器学习概念并将其适配到量子计算中的潜力，为高效自动化开发QML算法铺平了道路。未来方向包括引入规划机制和优化搜索空间的策略，以扩大其在量子增强机器学习中的应用范围。

</details>


### [297] [Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team](https://arxiv.org/abs/2506.18348)
**中文标题：动态知识交换与双多样性评审：简洁释放多智能体研究团队的潜力**

*Weilun Yu,Shixiang Tang,Yonggui Huang,Nanqing Dong,Li Fan,Honggang Qi,Wei Liu,Xiaoli Diao,Xi Chen,Wanli Ouyang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大语言模型的多智能体框架IDVSCI，通过动态知识交换和双多样性评审机制，提升科学研究的交互推理和创造力，实验证明其在多个领域优于现有系统。


<details>
  <summary>详细信息</summary>
研究动机: 科学进步依赖于研究者间的有效协作，而现有的大语言模型科学家代理缺乏交互推理和评估机制，限制了其在真实研究中的应用潜力。

研究方法: IDVSCI框架包含动态知识交换机制和双多样性评审范式，前者支持智能体间的迭代反馈，后者模拟异质专家评估，共同促进深度推理和创新科学想法的生成。

研究结果: 在计算机科学和健康科学领域的实验中，IDVSCI表现优于AI Scientist和VIRSCI等现有系统，验证了其有效性和泛化能力。

研究结论: IDVSCI通过模拟交互和同行评审动态，显著提升了大语言模型在自主研究中的表现，为未来科学协作提供了新思路。

中文摘要: 科学进步日益依赖于研究者间的有效协作，而大语言模型（LLMs）仅初步模拟了这一动态。尽管近期基于LLM的科学家代理在自主科学发现中展现出潜力，但它们通常缺乏真实研究所需的交互推理和评估机制。我们提出了IDVSCI（内部讨论与投票科学家），一种基于LLM的多智能体框架，包含两项关键创新：动态知识交换机制（支持智能体间的迭代反馈）和双多样性评审范式（模拟异质专家评估）。这些组件共同促进深度推理，并生成更具创造力和影响力的科学想法。为评估方法的有效性和泛化能力，我们在两个数据集上进行了实验：一个广泛使用的计算机科学基准和我们新引入的健康科学领域数据集。结果表明，IDVSCI在两个数据集上均表现最佳，优于AI Scientist和VIRSCI等现有系统。这些发现凸显了在基于LLM的自主研究中模拟交互和同行评审动态的价值。

</details>


### [298] [A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction](https://arxiv.org/abs/2506.18424)
**中文标题：基于大语言模型的多智能体框架用于模拟电路尺寸关系提取**

*Chengjie Liu,Weiyu Chen,Huiyao Xu,Yuan Du,Jun Yang,Li Du*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大语言模型（LLM）的多智能体框架，用于从学术论文中提取模拟电路的尺寸关系，从而有效修剪搜索空间，提升优化效率。


<details>
  <summary>详细信息</summary>
研究动机: 在模拟电路预布局阶段，器件尺寸设计是决定电路性能的关键步骤。现有技术多将其视为数学优化问题，但忽略了先验知识的自动引入，导致搜索空间压缩不足。本文旨在通过LLM提取尺寸关系，解决这一问题。

研究方法: 提出一种基于LLM的多智能体框架，从学术论文中自动提取模拟电路的尺寸关系，并利用这些关系修剪搜索空间。

研究结果: 在3类电路上测试，优化效率提升了2.32至26.6倍，证明LLM能有效修剪模拟电路尺寸设计的搜索空间。

研究结论: LLM与模拟电路设计自动化方法的结合为搜索空间修剪提供了新解决方案，显著提升了优化效率。

中文摘要: 在模拟电路预布局阶段的设计过程中，器件尺寸是决定电路能否满足性能指标的重要步骤。现有技术多将电路尺寸设计任务提取为数学优化问题，并从数学角度持续提升优化效率，但忽略了先验知识的自动引入，未能实现搜索空间的有效修剪，从而导致搜索空间仍存在较大压缩空间。为解决这一问题，我们提出了一种基于大语言模型（LLM）的多智能体框架，用于从学术论文中提取模拟电路的尺寸关系。该框架提取的尺寸关系可有效修剪尺寸设计过程中的搜索空间。最终，我们在3类电路上进行了测试，优化效率提升了2.32至26.6倍。这项工作表明，LLM能有效修剪模拟电路尺寸设计的搜索空间，为LLM与传统模拟电路设计自动化方法的结合提供了新解决方案。

</details>


### [299] [How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18428)
**中文标题：微调后模型编辑的鲁棒性如何？——文本到图像扩散模型的实证研究**

*Feng He,Zhenyang Liu,Marco Valentino,Zhixue Zhao*

主要分类: cs.AI

摘要简述: 本文研究了文本到图像扩散模型在微调后模型编辑的鲁棒性，发现编辑效果通常无法在微调后保留，尤其是DoRA方法表现出最强的编辑反转效果，而UCE编辑方法相对更鲁棒。


<details>
  <summary>详细信息</summary>
研究动机: 模型编辑是一种低成本的方法，用于在预训练模型中注入或修正特定行为，但编辑后是否能在微调中保留尚不明确。这一问题对AI安全有重要影响，例如微调可能消除恶意编辑，但也可能意外移除有益的安全修正。

研究方法: 研究在两种T2I模型（Stable Diffusion和FLUX）上，结合两种编辑技术（UCE和ReFACT）和三种微调方法（DreamBooth、LoRA和DoRA），通过多样化的编辑任务和评估指标进行系统性实验。

研究结果: 实验结果表明，编辑通常在微调后失效，即使微调与编辑无关。DoRA对编辑的逆转效果最强，而UCE在微调后保留的编辑效果显著优于ReFACT。

研究结论: 当前编辑方法在微调后缺乏鲁棒性，需开发更可靠的技术以确保长期控制和AI系统对齐。研究同时表明微调可作为恶意编辑的修复机制，但也需在微调后重新编辑以维持安全性和对齐性。

中文摘要: 模型编辑提供了一种低成本技术，可以在不进行大规模重新训练的情况下，向预训练模型中注入或修正特定行为，支持诸如事实修正和偏见缓解等应用。尽管这是一种常见做法，但编辑是否能在微调后保留，或是否会被无意中逆转，仍是一个未知问题。这一问题具有重要的实际意义。例如，如果微调消除了先前的编辑，它可能成为对抗隐藏恶意编辑的防御机制；反之，若意外移除了与偏见缓解相关的编辑，则可能引发严重的安全问题。我们系统地研究了文本到图像（T2I）扩散模型中模型编辑与微调之间的交互作用，这类模型已知存在偏见并可能生成不当内容。我们的研究涵盖两种T2I模型家族（Stable Diffusion和FLUX）、两种最先进的编辑技术以及三种微调方法（DreamBooth、LoRA和DoRA）。通过多样化的编辑任务和评估指标的广泛实证分析，我们的发现揭示了一个趋势：编辑通常无法在微调后保留，即使微调与编辑无关。值得注意的是，我们发现DoRA表现出最强的编辑逆转效果。同时，在编辑方法中，UCE表现出更高的鲁棒性，在微调后保留的编辑效果显著优于ReFACT。这些发现突显了当前编辑方法的关键局限性，强调了开发更鲁棒技术的必要性，以确保对部署的AI系统进行可靠的长期控制和对齐。这些发现对AI安全具有双重意义：它们表明微调可以作为恶意编辑的修复机制，同时也强调了在微调后重新编辑的必要性，以维持有益的安全性和对齐属性。

</details>


### [300] [Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance](https://arxiv.org/abs/2506.18511)
**中文标题：标准适用性判断与跨司法管辖区推理：基于RAG的医疗器械合规性框架**

*Yu Han,Aaron Ceross,Jeroen H. M. Bergmann*

主要分类: cs.AI

摘要简述: 本文提出了一种基于检索增强生成（RAG）的模块化AI系统，用于自动化判断医疗器械的法规标准适用性，支持跨司法管辖区（如中美）的冲突解决和适用性论证。


<details>
  <summary>详细信息</summary>
研究动机: 医疗器械合规性中，确定适用的法规标准是一个关键但研究不足的挑战，通常需要专家对分散且异构的跨司法管辖区文档进行解释。

研究方法: 系统通过RAG流程，根据自由文本设备描述从精选语料库中检索候选标准，并利用大语言模型推断特定司法管辖区的适用性（强制性、推荐或不适用），同时提供可追溯的论证。

研究结果: 系统在分类准确率达到73%，Top-5检索召回率为87%，显著优于仅检索、零样本和基于规则的基线方法。

研究结论: 本文首次提出了一种端到端的标准适用性推理系统，支持可扩展和可解释的AI辅助法规科学，并在中美标准间实现了跨司法管辖区推理。

中文摘要: 确定适用的法规标准是医疗器械合规性中一个关键但研究不足的挑战，通常需要专家对不同司法管辖区的分散且异构文档进行解释。为解决这一问题，我们提出了一种模块化AI系统，利用检索增强生成（RAG）流程自动化判断标准适用性。给定自由文本设备描述，系统从精选语料库中检索候选标准，并使用大语言模型推断特定司法管辖区的适用性（分类为强制性、推荐或不适用），并提供可追溯的论证。我们构建了一个国际基准数据集，包含专家标注的标准映射，并评估了系统在仅检索、零样本和基于规则基线上的表现。所提方法的分类准确率为73%，Top-5检索召回率为87%，证明了其在识别相关法规标准方面的有效性。我们首次提出了一种端到端的标准适用性推理系统，支持可扩展和可解释的AI辅助法规科学。值得注意的是，我们的区域感知RAG代理实现了中美标准间的跨司法管辖区推理，支持跨法规框架的冲突解决和适用性论证。

</details>


### [301] [A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence](https://arxiv.org/abs/2506.18538)
**中文标题：评估AI包容性的问题库：从多样性错误到包容性卓越的路径映射**

*Rifat Ara Shams,Didar Zowghi,Muneera Bano*

主要分类: cs.AI

摘要简述: 本文提出一个包含253个问题的AI包容性评估题库，覆盖人类、数据、流程、系统和治理五大支柱，旨在填补现有AI风险评估框架在包容性衡量上的空白。通过多源迭代开发方法，结合文献综述、D&I指南和模拟用户研究，验证了题库的实用性和有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI风险评估框架缺乏对包容性的标准化衡量工具，导致AI系统在多样性和包容性（D&I）方面的偏差难以识别和纠正。本文旨在填补这一空白，提供一个系统化的评估工具，帮助研究人员和实践者提升AI技术的公平性和包容性。

研究方法: 采用多源迭代方法开发题库，结合文献综述、D&I指南、负责任AI框架和模拟用户研究。通过70个AI生成的角色模拟评估题库的相关性和有效性。

研究结果: 研究发现，题库能有效评估AI系统在D&I原则上的表现，并强调了将D&I原则整合到AI开发和治理流程中的重要性。模拟评估验证了题库在不同角色和应用领域的适用性。

研究结论: 该题库为研究人员、实践者和政策制定者提供了一个实用工具，可系统化评估和提升AI系统的包容性，推动更公平和负责任的AI技术发展。

中文摘要: 确保人工智能（AI）的多样性和包容性（D&I）对于减少偏见和促进公平决策至关重要。然而，现有的AI风险评估框架往往忽视包容性，缺乏衡量AI系统与D&I原则一致性的标准化工具。本文介绍了一个结构化的AI包容性问题库，包含253个问题，旨在从人类、数据、流程、系统和治理五大支柱评估AI包容性。问题库的开发采用多源迭代方法，结合文献综述、D&I指南、负责任AI框架和模拟用户研究。通过70个与不同AI工作相关的AI生成角色进行模拟评估，验证了问题库在多样角色和应用领域中的相关性和有效性。研究结果强调了将D&I原则整合到AI开发流程和治理结构中的重要性。该问题库为研究人员、实践者和政策制定者提供了一个实用工具，可系统化评估和提升AI系统的包容性，推动更公平和负责任的AI技术发展。

</details>


### [302] [T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent](https://arxiv.org/abs/2506.18559)
**中文标题：T-CPDL：一种时序因果概率描述逻辑框架用于开发逻辑-RAG智能体**

*Hong Qing Yu*

主要分类: cs.AI

摘要简述: 本文提出了一种名为T-CPDL的时序因果概率描述逻辑框架，用于增强语言模型在时序约束、因果关系和概率推理方面的能力。该框架通过扩展传统描述逻辑，结合时序区间算子和因果标注，显著提升了推理准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在生成流畅文本方面表现出色，但在涉及时序约束、因果关系和概率推理的结构化任务中表现不佳。为了解决这一问题，本文提出了T-CPDL框架，旨在弥补语言模型在这些领域的不足。

研究方法: T-CPDL扩展了传统描述逻辑，引入了时序区间算子和显式因果标注。提出了两种变体：一种基于Allen区间代数捕捉定性时序关系，另一种结合时间戳因果断言。两种变体共享统一的逻辑结构，支持从简单时序排序到复杂概率因果推理的任务。

研究结果: 实验表明，T-CPDL在时序推理和因果推断任务中显著提升了语言模型的推理准确性、可解释性和置信度校准。同时，该框架为开发逻辑检索增强生成（Logic-RAG）系统奠定了基础。

研究结论: T-CPDL通过提供透明的推理路径和细粒度的时序因果语义，显著增强了语言模型的决策能力，为构建更可靠、可解释的推理系统提供了重要支持。

中文摘要: 大型语言模型擅长生成流畅文本，但在涉及时序约束、因果关系和概率推理的结构化任务中表现欠佳。为解决这一问题，我们提出了时序因果概率描述逻辑（T-CPDL），该框架扩展了传统描述逻辑，引入了时序区间算子、显式因果关系和概率标注。我们提出了T-CPDL的两种变体：一种通过Allen区间代数捕捉定性时序关系，另一种结合时间戳因果断言。两种变体共享统一的逻辑结构，支持从简单时序排序到复杂概率因果推理的任务。实验结果表明，T-CPDL显著提升了语言模型在时序推理和因果推断任务中的准确性、可解释性和置信度校准。通过提供透明的推理路径和细粒度的时序因果语义，T-CPDL显著增强了语言模型支持稳健、可解释和可信决策的能力。本研究还为开发先进的逻辑检索增强生成（Logic-RAG）框架奠定了基础，有望提升知识图谱增强的RAG系统的推理能力和效率。

</details>


### [303] [Airalogy: AI-empowered universal data digitization for research automation](https://arxiv.org/abs/2506.18586)
**中文标题：Airalogy：AI赋能的通用数据数字化平台助力科研自动化**

*Zijie Yang,Qiji Zhou,Fang Guo,Sijie Zhang,Yexun Xi,Jinglei Nie,Yudian Zhu,Liping Huang,Chou Wu,Yonghe Xia,Xiaoyu Ma,Yingming Pu,Panzhong Lu,Junshu Pan,Mingtao Chen,Tiannan Guo,Yanmei Dou,Hongyu Chen,Anping Zeng,Jiaxing Huang,Tian Xu,Yue Zhang*

主要分类: cs.AI

摘要简述: 本文介绍了Airalogy，首个AI驱动的多学科研究数据数字化平台，旨在解决研究数据碎片化和标准化不足的问题，通过平衡通用性与标准化，推动AI驱动的科研自动化。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI应用受限于少数领域的数据可用性，研究数据缺乏统一标准和高效管理，阻碍了多学科AI赋能。Airalogy旨在填补这一空白，通过整合领域知识与计算技术，实现跨学科数据标准化和AI驱动研究。

研究方法: 开发Airalogy平台，结合AI技术和社区驱动，提供可定制且标准化的数据记录方法，支持智能问答、自动化数据录入和分析等功能。

研究结果: Airalogy已在西湖大学四个学院的实验室中部署，展示了其在加速科研创新和自动化方面的潜力。

研究结论: Airalogy通过平衡通用性与标准化，为多学科研究数据数字化提供了创新解决方案，有望推动全球科研社区的AI驱动进步。

中文摘要: 研究数据是人工智能（AI）驱动科学的基础，但当前AI应用仅限于少数拥有结构化、数字化数据的领域。实现多学科的全面AI赋能仍面临挑战。现今研究数据收集分散、缺乏统一标准、管理低效且难以共享。构建一个标准化数据数字化平台需平衡通用性（支持多学科需求）与标准化（统一格式以支持AI）。现有平台无法兼顾两者。真正的多学科平台需整合科学领域知识与计算技术。研究者常缺乏设计定制化标准化数据记录方法的计算能力，而平台开发者则难以理解多学科需求。这些障碍阻碍了研究数据标准化和AI驱动的进步。本研究通过开发Airalogy（https://airalogy.com），首个AI与社区驱动的平台，平衡通用性与标准化，实现多学科研究数据数字化。Airalogy通过可定制标准化数据记录支持完整研究流程，并提供智能问答、自动化数据录入与分析等功能。该平台已在西湖大学四个学院的实验室中部署，有望加速高校、产业及全球科研社区的创新自动化，最终造福全人类。

</details>


### [304] [AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs](https://arxiv.org/abs/2506.18628)
**中文标题：AggTruth：利用聚合注意力分数检测LLMs中的上下文幻觉**

*Piotr Matys,Jan Eliasz,Konrad Kiełczyński,Mikołaj Langner,Teddy Ferdinan,Jan Kocoń,Przemysław Kazienko*

主要分类: cs.AI

摘要简述: 本文提出AggTruth方法，通过分析大型语言模型（LLMs）内部注意力分数的分布，实现在线检测上下文幻觉，并在多任务和跨任务场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在实际应用中常出现幻觉问题，即使在检索增强生成（RAG）设置下也难以避免，这对其部署提出了重大挑战。

研究方法: AggTruth通过分析上下文（段落）中内部注意力分数的分布，提出四种不同的聚合技术变体，用于计算注意力分数。

研究结果: 在所有测试的LLMs中，AggTruth在相同任务和跨任务设置中均表现稳定，并在多个场景中优于当前最优方法。此外，研究还深入分析了特征选择技术及注意力头数量对检测性能的影响。

研究结论: AggTruth是一种有效的在线检测上下文幻觉的方法，其性能依赖于注意力头的精心选择。

中文摘要: 在实际应用中，大型语言模型（LLMs）常出现幻觉问题，即使在检索增强生成（RAG）设置下也难以避免，这对其部署提出了重大挑战。本文提出AggTruth方法，通过分析上下文（段落）中内部注意力分数的分布，实现在线检测上下文幻觉。具体而言，我们提出了四种不同的聚合技术变体，用于计算注意力分数。在所有测试的LLMs中，AggTruth在相同任务和跨任务设置中均表现稳定，并在多个场景中优于当前最优方法。此外，我们还深入分析了特征选择技术，并研究了所选注意力头数量对检测性能的影响，结果表明精心选择注意力头对实现最佳效果至关重要。

</details>


### [305] [Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems](https://arxiv.org/abs/2506.18651)
**中文标题：多智能体系统中组间与组内协调的双层次行为一致性**

*Shuocun Yang,Huawen Hu,Enze Shi,Shu Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为双层次行为一致性（DLBC）的新方法，用于在多智能体系统中同时调控组内和组间的行为一致性，显著提升了组内合作和组间任务分工的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前多智能体强化学习（MARL）研究主要关注组内行为一致性，而忽略了多智能体分组场景中的行为一致性。本文旨在填补这一空白，通过双层次行为一致性调控，提升多智能体系统的协作效率。

研究方法: DLBC方法将智能体划分为不同组，动态调控组内和组间的行为多样性。通过组间一致性约束不同组的行为策略，实现任务分工；通过组内一致性对齐组内行为策略，促进组内合作。DLBC直接约束智能体的策略函数，具有广泛的算法适用性。

研究结果: 实验结果表明，DLBC在多种分组合作场景中显著提升了组内合作性能和组间任务专业化，带来了显著的性能提升。

研究结论: DLBC为多智能体系统的行为一致性控制提供了新思路，未来可进一步探索其在更复杂任务和动态环境中的应用潜力。

中文摘要: 多智能体强化学习（MARL）中的行为多样性是一个新兴且有前景的研究领域。先前的研究主要集中在多智能体系统中的组内行为一致性，而对多智能体分组场景中的行为一致性关注有限。本文提出了双层次行为一致性（DLBC），这是一种新颖的MARL控制方法，旨在明确调控智能体在组内和组间两个层次的行为。DLBC将智能体划分为不同组，并动态调控组内和组间的行为多样性。通过动态调控组内和组间的行为多样性，DLBC通过组间一致性（约束不同组的行为策略）实现了更高效的任务分工；同时，通过组内一致性（对齐组内行为策略）促进了更强的组内合作。重要的是，DLBC直接约束智能体的策略函数，确保了其在多种算法框架中的广泛适用性。在多种分组合作场景中的实验结果表明，DLBC显著提升了组内合作性能和组间任务专业化，带来了显著的性能提升。DLBC为多智能体系统的行为一致性控制提供了新思路，未来可进一步探索其在更复杂任务和动态环境中的应用潜力。

</details>


### [306] [Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training](https://arxiv.org/abs/2506.18777)
**中文标题：反向传播编程：代码训练中大型语言模型获得可重用算法抽象**

*Jonathan Cook,Silvia Sapora,Arash Ahmadian,Akbir Khan,Tim Rocktaschel,Jakob Foerster,Laura Ruis*

主要分类: cs.AI

摘要简述: 本文提出“反向传播编程”（PBB）作为大型语言模型（LLM）通过代码训练获得可重用算法抽象的潜在机制，研究发现仅通过源代码训练模型即可评估程序输入，且效果优于基于输入输出示例的训练。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在揭示LLM通过代码训练提升通用推理能力的机制，探索仅通过源代码训练模型是否能使其具备评估程序输入的能力。

研究方法: 通过微调LLM在两组程序（数学问题和算法）上进行实验，一组包含源代码和输入输出示例（w/ IO），另一组仅包含源代码（w/o IO），比较模型在不同设置下的表现。

研究结果: 研究发现，仅通过源代码训练的LLM具备评估程序输入的能力，且代码形式比语义描述更有效；模型可通过前向传递隐式评估程序，而链式思考（chain-of-thought）能进一步提升可靠性。此外，PBB比基于自然数据分布的输入输出训练更具鲁棒性。

研究结论: 代码训练使LLM能够内化可重用的算法抽象，从而增强推理能力。未来研究可进一步优化LLM从符号化过程中学习的效果，并为模型对齐等领域提供新思路。

中文摘要: 在源代码上训练大型语言模型（LLM）显著提升了其通用推理能力，但这种泛化背后的机制尚不明确。本文提出“反向传播编程”（PBB）作为潜在驱动因素——仅通过源代码训练模型评估程序输入，而无需输入输出示例。为验证这一想法，我们在两组程序（简单数学问题和算法）上微调LLM：一组包含源代码和输入输出示例（w/ IO），另一组仅包含源代码（w/o IO）。实验表明，LLM在多种设置下具备评估w/o IO程序输入的能力，并得出以下观察：首先，PBB在代码形式下效果显著优于语义描述；其次，LLM可通过前向传递隐式评估程序，而链式思考能进一步提升可靠性。此外，PBB比基于自然数据分布的输入输出训练更具鲁棒性。这些发现表明，代码训练通过内化可重用算法抽象增强了推理能力。未来研究可进一步优化LLM从符号化过程中学习的效果，并为模型对齐等领域（如基于正式宪法原则的训练）提供新思路。

</details>


### [307] [TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation](https://arxiv.org/abs/2506.18783)
**中文标题：TRIZ智能体：一种基于多智能体大语言模型的TRIZ创新方法**

*Kamil Szczepanik,Jarosław A. Chudziak*

主要分类: cs.AI

摘要简述: 本文提出了一种基于多智能体大语言模型（LLM）的TRIZ创新方法，通过多个具备专业能力和工具访问权限的智能体协作解决发明性问题，展示了在复杂创新任务中分散式问题解决的优势。


<details>
  <summary>详细信息</summary>
研究动机: TRIZ（发明性问题解决理论）的应用常受限于其复杂性和跨学科知识需求。尽管已有研究探索单一大语言模型在TRIZ中的应用，但多智能体协作的潜力尚未充分挖掘。本文旨在通过多智能体系统模拟发明过程，提升复杂创新问题的解决效率。

研究方法: 提出了一种名为TRIZ agents的多智能体系统，每个智能体具备专业能力和工具访问权限，基于TRIZ方法论协作解决发明性问题。通过多领域专家智能体的协同工作，高效完成TRIZ步骤。

研究结果: 通过工程领域的案例研究，验证了多智能体系统在解决复杂创新挑战中的有效性，展示了智能体协作能够产生多样化的发明性解决方案。

研究结论: 本研究为AI驱动的创新提供了新方向，证明了分散式问题解决在复杂构思任务中的优势，为未来智能创新工具的开发奠定了基础。

中文摘要: TRIZ（发明性问题解决理论）是一种结构化、基于知识的创新框架，用于抽象问题并寻找发明性解决方案。然而，其应用常因复杂性和跨学科知识需求而受限。大语言模型（LLM）的进步为自动化部分流程提供了新可能。尽管已有研究探索单一大语言模型在TRIZ中的应用，本文提出了一种多智能体方法。我们设计了一个基于LLM的多智能体系统（称为TRIZ智能体），每个智能体具备专业能力和工具访问权限，基于TRIZ方法论协作解决发明性问题。该系统利用多领域专家智能体高效完成TRIZ步骤，旨在通过语言智能体模拟发明过程。我们通过工程领域的案例研究评估了智能体团队在解决复杂创新挑战中的有效性，展示了智能体协作产生多样化发明性解决方案的潜力。本研究为AI驱动的创新未来提供了贡献，突显了分散式问题解决在复杂构思任务中的优势。

</details>


### [308] [ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation](https://arxiv.org/abs/2506.18810)
**中文标题：ConciseHint：通过生成过程中持续简洁提示提升高效推理**

*Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为ConciseHint的框架，通过在推理过程中注入简洁提示，显著减少大型推理模型的冗余输出，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型推理模型（如DeepSeek-R1和OpenAI o1系列）在复杂推理任务中表现优异，但倾向于生成冗长的推理过程，导致效率低下。现有方法主要关注推理前的优化，忽略了在生成过程中直接干预以提升简洁性的潜力。

研究方法: 提出ConciseHint框架，通过在推理过程中动态注入简洁提示（手动设计或基于简洁数据训练），并根据查询复杂度自适应调整提示强度，确保模型性能不受影响。

研究结果: 实验表明，ConciseHint在DeepSeek-R1和Qwen-3系列模型上显著减少了推理长度（如GSM8K基准上减少65%），同时几乎无准确率损失。

研究结论: ConciseHint有效解决了大型推理模型冗长输出的问题，为高效推理提供了新方向。

中文摘要: 近年来，大型推理模型（如DeepSeek-R1和OpenAI o1系列）通过扩展生成长度（如思维链CoT）在复杂推理任务中取得了显著性能提升。然而，这些模型倾向于生成冗长的推理过程，导致效率问题。现有研究主要关注推理前的优化（如提示和微调），而忽略了在生成过程中直接鼓励模型简洁表达的可能性。为此，我们提出了ConciseHint框架，通过在推理过程的令牌生成中注入简洁提示（手动设计或基于简洁数据训练），并自适应调整提示强度以适应查询复杂度，从而确保模型性能不受影响。在DeepSeek-R1和Qwen-3系列模型上的实验表明，我们的方法能有效生成简洁的推理过程，同时保持性能。例如，在GSM8K基准上，Qwen-3 4B模型的推理长度减少了65%，且几乎无准确率损失。

</details>


### [309] [Steering Conceptual Bias via Transformer Latent-Subspace Activation](https://arxiv.org/abs/2506.18887)
**中文标题：通过Transformer潜在子空间激活引导概念偏差**

*Vansh Sharma,Venkat Raman*

主要分类: cs.AI

摘要简述: 本文研究了通过激活语言模型的潜在子空间来引导科学代码生成偏向特定编程语言的方法，提出了一种梯度优化的自适应激活框架（G-ACT），显著提高了编程语言选择的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索如何通过激活语言模型的潜在子空间，实现对科学代码生成中编程语言选择的控制，以解决现有方法在泛化性和鲁棒性上的不足。

研究方法: 方法包括：首先评估五种因果语言模型在科学代码生成中的基线偏差；提出静态神经元扰动方法，发现其局限性后，开发了梯度优化的自适应激活框架（G-ACT），通过聚类激活差异和在线训练轻量级探针来选择最优激活方向。

研究结果: 结果表明，G-ACT在LLaMA-3.2 3B模型中显著提高了CPP语言的选择准确性（平均提升15%，早期层提升61.5%），并在LLaMA-3.3 70B模型中通过关键层注入进一步优化了语言选择。

研究结论: 结论指出，G-ACT提供了一种可扩展、可解释且高效的机制，实现了对语言模型概念级别的控制，适用于实际代理系统。

中文摘要: 本研究探讨了是否可以通过激活语言模型（LLMs）的潜在子空间，将科学代码生成引导至特定编程语言。首先评估了五种因果语言模型在科学代码提示上的基线偏差，量化了其对四种编程语言的偏好。静态神经元扰动方法（通过扰动C++或CPP令牌的最高激活MLP权重）表现出脆弱性，且在不同提示风格和模型规模上泛化能力有限。为解决这些问题，开发了梯度优化的自适应激活框架（G-ACT）：将每提示的激活差异聚类为少量引导方向，并在线训练和优化轻量级层探针以选择适当的引导向量。在LLaMA-3.2 3B中，该方法通过将探针分类准确率平均提高15%，并在早期层（0-6）提升61.5%，可靠地将生成偏向CPP语言。对于LLaMA-3.3 70B，注意力信号更分散时，关键层的定向注入仍能改善语言选择。尽管层探针引入了适度的推理开销，但通过仅引导部分层，保持了实用性并实现了可复现的模型行为。这些结果表明了一种可扩展、可解释且高效的机制，为实际代理系统提供了概念级别的控制。

</details>


### [310] [jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval](https://arxiv.org/abs/2506.18902)
**中文标题：Jina-embeddings-v4：用于多模态多语言检索的通用嵌入模型**

*Michael Günther,Saba Sturua,Mohammad Kalim Akram,Isabelle Mohr,Andrei Ungureanu,Sedigheh Eslami,Scott Martens,Bo Wang,Nan Wang,Han Xiao*

主要分类: cs.AI

摘要简述: Jina-embeddings-v4 是一个 38 亿参数的多模态嵌入模型，通过新颖架构统一文本和图像表示，支持单向量和多向量嵌入，并在多种检索任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态和多语言检索任务需要统一的嵌入模型，以支持跨模态语义相似性和复杂视觉内容的处理。

研究方法: 模型采用任务特定的低秩适配器（LoRA）优化性能，支持单模态和跨模态检索任务，并引入 Jina-VDR 基准评估视觉丰富内容的检索能力。

研究结果: Jina-embeddings-v4 在单模态和跨模态检索任务中均达到最先进性能，尤其在处理表格、图表和混合媒体等视觉丰富内容时表现突出。

研究结论: Jina-embeddings-v4 为多模态多语言检索提供了高效解决方案，并通过 Jina-VDR 基准推动了视觉丰富内容检索的研究。

中文摘要: 我们介绍了 Jina-embeddings-v4，这是一个拥有 38 亿参数的多模态嵌入模型，通过一种新颖的架构统一了文本和图像的表示，支持单向量和多向量嵌入的后期交互风格。该模型结合了任务特定的低秩适配器（LoRA），以优化多种检索场景的性能，包括基于查询的信息检索、跨模态语义相似性和编程代码搜索。综合评估表明，Jina-embeddings-v4 在单模态和跨模态检索任务中均实现了最先进的性能，尤其擅长处理视觉丰富的内容，如表格、图表、图解和混合媒体格式。为了评估这一能力，我们还引入了 Jina-VDR，这是一个专门为视觉丰富图像检索设计的新基准。

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [311] [Greedy Selection under Independent Increments: A Toy Model Analysis](https://arxiv.org/abs/2506.17941)
**中文标题：独立增量下的贪心选择：一个玩具模型分析**

*Huitao Yang*

主要分类: math.PR

摘要简述: 本文研究了一个基于独立增量的迭代选择问题，证明了在多阶段淘汰设置中，贪心选择策略是选择最终最大值过程的最优方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索在多阶段淘汰过程中，贪心选择策略的有效性，尤其是在独立增量假设下，为高维应用中的相关算法提供理论基础。

研究方法: 方法是通过分析N个独立同分布的离散时间随机过程，每个阶段基于观测值保留固定数量的过程，验证贪心策略的最优性。

研究结果: 结果表明，在独立增量假设下，贪心选择策略是选择最终最大值过程的最优方法。

研究结论: 结论是贪心策略在多阶段淘汰设置中具有理论上的最优性，为相关算法的设计提供了简洁的理论支持。

中文摘要: 我们研究了基于N个独立同分布的离散时间随机过程的迭代选择问题，这些过程具有独立增量。在每个阶段，根据观测值保留固定数量的过程。在这一简单模型下，我们证明了选择最终最大值过程的最优策略是在每个阶段应用贪心选择。尽管结果依赖于强独立性假设，但它为多阶段淘汰设置中的贪心启发式提供了简洁的理论支持，并可作为理解高维应用中相关算法的玩具示例。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [312] [A Study of Dynamic Stock Relationship Modeling and S&P500 Price Forecasting Based on Differential Graph Transformer](https://arxiv.org/abs/2506.18717)
**中文标题：基于差分图Transformer的动态股票关系建模与S&P500价格预测研究**

*Linyue Hu,Qi Wang*

主要分类: cs.CE

摘要简述: 本文提出了一种基于差分图Transformer（DGT）的动态股票关系建模方法，用于预测S&P500价格。通过整合动态图结构和多头部自注意力机制，DGT能够自适应捕捉股票间的时变关系，显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 股票价格预测对投资决策和风险管理至关重要，但由于市场的非线性动态和时变的股票间相关性，传统静态相关性模型难以捕捉这些变化。因此，需要一种能够动态建模股票关系的方法。

研究方法: 提出差分图Transformer（DGT）框架，通过差分图机制将动态图结构变化整合到多头部自注意力中，自适应保留高价值连接并抑制噪声。同时，采用因果时间注意力捕捉价格序列的全局/局部依赖关系，并评估多种相关性指标（如Pearson、互信息等）作为空间注意力的先验。

研究结果: 在10年S&P500收盘价数据上，DGT结合空间先验显著优于GRU基线（RMSE：0.24 vs. 0.87）。Kendall's Tau全局矩阵表现最优（MAE：0.11）。聚类分析发现“高波动增长”和“防御性蓝筹股”两类股票，后者因稳定相关性误差更低（RMSE：0.13）。

研究结论: 本研究创新性地将差分图结构与Transformer结合，验证了动态关系建模的有效性，并确定了最优相关性指标和范围。聚类分析支持定制化量化策略，为金融时间序列预测提供了新方法。

中文摘要: 股票价格预测对投资决策和风险管理至关重要，但由于市场的非线性动态和时变的股票间相关性，传统静态相关性模型难以捕捉这些变化。为此，我们提出了一种差分图Transformer（DGT）框架，用于动态关系建模和价格预测。DGT通过差分图机制将动态图结构变化整合到多头部自注意力中，自适应保留高价值连接并抑制噪声。因果时间注意力捕捉价格序列的全局/局部依赖关系。我们进一步评估了多种相关性指标（Pearson、互信息、Spearman、Kendall's Tau）作为空间注意力的先验。使用10年S&P500收盘价数据（z-score标准化；64天滑动窗口），DGT结合空间先验显著优于GRU基线（RMSE：0.24 vs. 0.87）。Kendall's Tau全局矩阵表现最优（MAE：0.11）。K-means聚类揭示了“高波动增长”和“防御性蓝筹股”两类股票，后者因稳定相关性误差更低（RMSE：0.13）。Kendall's Tau和互信息在波动性行业中表现优异。本研究创新性地将差分图结构与Transformer结合，验证了动态关系建模的有效性，并确定了最优相关性指标和范围。聚类分析支持定制化量化策略，为金融时间序列预测提供了新方法。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [313] [Advanced Game-Theoretic Frameworks for Multi-Agent AI Challenges: A 2025 Outlook](https://arxiv.org/abs/2506.17348)
**中文标题：面向多智能体AI挑战的高级博弈论框架：2025年展望**

*Pavel Malinovskiy*

主要分类: cs.MA

摘要简述: 本文探讨了2025年多智能体AI挑战中高级博弈论框架的应用，提出动态联盟形成、语言效用、破坏风险和部分可观测性等新模型，为复杂环境中的多智能体系统提供理论工具。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI技术的快速发展，多智能体系统在复杂环境中的战略交互问题日益突出。本文旨在通过高级博弈论框架，为2025年可能出现的多智能体AI挑战提供理论基础和解决方案。

研究方法: 论文结合动态联盟形成、语言效用、破坏风险和部分可观测性等新模型，提出了一系列数学形式化方法、模拟实验和编码方案，并通过重复博弈、贝叶斯更新和道德框架等工具分析多智能体系统的适应与协商能力。

研究结果: 研究结果表明，所提出的博弈论框架能够有效支持多智能体系统在不确定和部分对抗性环境中的战略交互，为AI研究者提供了实用的理论工具。

研究结论: 本文为2025年多智能体AI挑战提供了前瞻性的博弈论解决方案，强调了动态联盟和道德框架在复杂环境中的重要性，为未来研究指明了方向。

中文摘要: 本文重新审视了高级博弈论范式如何作为下一代人工智能（AI）挑战的基础，预计这些挑战将在2025年左右出现。我们的研究超越了传统模型，引入了动态联盟形成、语言效用、破坏风险和部分可观测性等新概念。我们提供了一套数学形式化方法、模拟实验和编码方案，展示了多智能体AI系统如何在复杂环境中适应和协商。关键要素包括重复博弈、用于对抗检测的贝叶斯更新以及收益结构中的道德框架。这项工作旨在为AI研究者提供强大的理论工具，以在不确定和部分对抗性环境中对齐战略交互。

</details>


### [314] [Towards Zero-Shot Coordination between Teams of Agents: The N-XPlay Framework](https://arxiv.org/abs/2506.17560)
**中文标题：面向多智能体团队间零样本协作的N-XPlay框架**

*Ava Abderezaei,Chi-Hui Lin,Joseph Miceli,Naren Sivagnanadasan,Stéphane Aroca-Ouellette,Jake Brawer,Alessandro Roncone*

主要分类: cs.MA

摘要简述: 本文提出了N-XPlay框架，用于解决多智能体团队间的零样本协作问题，并通过扩展的N玩家Overcooked环境验证其优于传统自博弈方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有零样本协作方法仅适用于两智能体场景，无法反映现实多团队系统的复杂性，因此需要开发支持多智能体团队协作的新方法。

研究方法: 首先扩展了Overcooked环境为N玩家版本，随后提出N-XPlay框架，用于训练智能体在多团队场景中同时优化团队内和团队间协作。

研究结果: 实验表明，N-XPlay在二、三和五玩家Overcooked场景中，比自博弈方法更能平衡团队内和团队间协作。

研究结论: N-XPlay为多智能体团队协作提供了有效解决方案，填补了零样本协作在多团队场景中的空白。

中文摘要: 零样本协作（ZSC）——即与陌生伙伴协作的能力——是使自主智能体成为有效队友的关键。现有ZSC方法仅评估两个未交互过的智能体之间的协作能力，但这些场景无法反映现实多智能体系统的复杂性，其中协作通常涉及子群层次结构和多团队系统（MTS）间的交互。为解决这一问题，我们首先引入了N玩家Overcooked，这是流行两智能体ZSC基准的N智能体扩展，支持在N智能体场景中评估ZSC。随后，我们提出了N-XPlay，用于N智能体多团队场景中的ZSC。通过在二、三和五玩家Overcooked场景中与自博弈方法对比（智能体被分为“自我团队”和一组未见过的协作者），结果表明，使用N-XPlay训练的智能体比自博弈训练的智能体更能同时平衡“团队内”和“团队间”协作。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [315] [Step-by-Step Reasoning Attack: Revealing 'Erased' Knowledge in Large Language Models](https://arxiv.org/abs/2506.17279)
**中文标题：逐步推理攻击：揭示大语言模型中‘被擦除’的知识**

*Yash Sinha,Manit Baser,Murari Mandal,Dinil Mon Divakaran,Mohan Kankanhalli*

主要分类: cs.CR

摘要简述: 本文揭示了大语言模型（LLM）中知识擦除的漏洞，通过逐步推理攻击（Sleek）成功恢复被擦除的知识，暴露现有遗忘技术的不足。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型的知识擦除对数据合规、隐私保护和减少偏见至关重要，但现有遗忘技术仅表面抑制知识，未彻底删除，存在信息泄露风险。本文旨在揭示这一漏洞。

研究方法: 提出逐步推理攻击Sleek，包含三部分：基于LLM生成查询的对抗提示策略、成功召回被擦除内容的攻击机制，以及直接、间接和隐含提示分类，以识别遗忘弱点。

研究结果: 在四种先进遗忘技术和两种LLM上的实验显示，62.5%的对抗提示成功恢复被擦除的《哈利波特》知识，50%暴露了对保留知识的不公平抑制。

研究结论: 现有遗忘技术无法可靠擦除知识，信息泄露风险持续存在，亟需更鲁棒的遗忘策略。

中文摘要: 大语言模型（LLM）中的知识擦除对确保数据与AI法规合规、保护用户隐私、减少偏见和错误信息至关重要。现有遗忘方法旨在高效擦除特定知识的同时保持模型整体性能，尤其是保留信息。然而，这些技术往往仅表面抑制知识，使其仍可通过适当提示恢复。本文证明，逐步推理可作为恢复隐藏信息的后门。我们提出逐步推理黑盒攻击Sleek，系统性暴露遗忘失败。攻击框架包含三部分：（1）基于LLM生成查询的对抗提示策略，（2）成功召回被擦除内容并揭露对保留知识不公平抑制的攻击机制，（3）将提示分为直接、间接和隐含三类，以识别最有效利用遗忘弱点的查询类型。通过对四种先进遗忘技术和两种广泛使用LLM的评估，现有方法无法确保可靠知识擦除。生成的对抗提示中，62.5%成功从WHP遗忘的Llama中恢复《哈利波特》知识，50%暴露了对保留知识的不公平抑制。本研究凸显信息泄露的持续风险，强调需更鲁棒的遗忘策略以实现擦除。

</details>


### [316] [Theoretically Unmasking Inference Attacks Against LDP-Protected Clients in Federated Vision Models](https://arxiv.org/abs/2506.17292)
**中文标题：理论揭示联邦视觉模型中针对LDP保护客户端的推理攻击**

*Quan Nguyen,Minh N. Vu,Truc Nguyen,My T. Thai*

主要分类: cs.CR

摘要简述: 联邦学习通过协调服务器实现客户端协作学习，避免直接数据共享，但成员推理攻击（MIAs）对未保护数据的高成功率挑战了其隐私保护能力。本地差分隐私（LDP）虽被视为隐私保护的黄金标准，但多数研究未考虑LDP或未提供理论保证。本文推导了低多项式时间MIAs的理论下界，揭示LDP保护下隐私风险仍存在，且噪声需求会显著降低模型效用。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习被认为能保护隐私，但成员推理攻击（MIAs）对未保护数据的高成功率引发担忧。本地差分隐私（LDP）虽为隐私保护标准，但缺乏对LDP保护数据的MIAs理论分析。本文旨在填补这一空白，探讨LDP保护下的隐私风险。

研究方法: 本文推导了低多项式时间成员推理攻击（MIAs）的理论下界，针对全连接层或自注意力层的漏洞。通过理论分析，量化了LDP保护下的隐私风险，并评估了噪声对模型效用的影响。

研究结果: 理论分析表明，即使数据受LDP保护，隐私风险仍存在，且攻击成功率与隐私预算相关。实验验证了联邦视觉模型中显著的隐私风险，并显示所需噪声会显著降低模型效用。

研究结论: LDP保护无法完全消除隐私风险，攻击成功率与隐私预算相关。为缓解攻击所需的噪声会损害模型效用，需在隐私与效用间权衡。

中文摘要: 联邦学习通过协调服务器实现客户端协作学习，避免直接数据共享，被视为隐私保护的解决方案。然而，最近关于成员推理攻击（MIAs）的研究挑战了这一观点，显示对未保护训练数据的高成功率。尽管本地差分隐私（LDP）被广泛认为是数据隐私保护的黄金标准，但多数关于MIAs的研究要么忽略LDP，要么未能提供针对LDP保护数据的攻击成功率的理论保证。为填补这一空白，我们推导了低多项式时间MIAs的理论下界，这些攻击利用了全连接层或自注意力层的漏洞。我们证明，即使数据受LDP保护，隐私风险仍存在，且与隐私预算相关。联邦视觉模型的实践评估证实了显著的隐私风险，揭示缓解这些攻击所需的噪声会显著降低模型效用。

</details>


### [317] [LLM Jailbreak Oracle](https://arxiv.org/abs/2506.17299)
**中文标题：大型语言模型越狱预言**

*Shuyi Lin,Anshuman Suri,Alina Oprea,Cheng Tan*

主要分类: cs.CR

摘要简述: 本文提出了一种名为Boa的高效算法，用于解决大型语言模型（LLM）的越狱预言问题，通过三阶段搜索策略系统评估模型的安全漏洞。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型在安全关键应用中的广泛部署，缺乏系统方法评估其对越狱攻击的脆弱性成为一个关键安全缺口。本文旨在通过形式化越狱预言问题，为研究模型漏洞提供理论基础。

研究方法: Boa算法采用三阶段搜索策略：(1)构建块列表识别拒绝模式，(2)广度优先采样寻找易访问的越狱路径，(3)深度优先优先级搜索，基于细粒度安全评分探索低概率路径。

研究结果: Boa能够高效解决越狱预言问题，支持系统化的安全评估，包括防御测试、标准化红队攻击比较及极端对抗条件下的模型认证。

研究结论: Boa为大型语言模型的安全漏洞评估提供了首个高效解决方案，填补了系统化安全研究的空白。

中文摘要: 随着大型语言模型（LLM）在安全关键应用中的部署日益增多，缺乏系统方法评估其对越狱攻击的脆弱性成为一个关键安全缺口。我们提出了越狱预言问题：给定模型、提示和解码策略，判断是否能够生成概率超过指定阈值的越狱响应。这一形式化为研究越狱漏洞提供了理论基础。解决越狱预言问题面临显著的计算挑战——搜索空间随响应令牌长度呈指数增长。我们提出了Boa，首个高效解决越狱预言问题的算法。Boa采用三阶段搜索策略：(1)构建块列表识别拒绝模式，(2)广度优先采样寻找易访问的越狱路径，(3)深度优先优先级搜索，基于细粒度安全评分探索低概率路径。Boa支持严格的安评评估，包括系统防御测试、标准化红队攻击比较及极端对抗条件下的模型认证。

</details>


### [318] [Context manipulation attacks : Web agents are susceptible to corrupted memory](https://arxiv.org/abs/2506.17318)
**中文标题：上下文操纵攻击：网页代理易受内存污染影响**

*Atharv Singh Patlan,Ashwin Hebbar,Pramod Viswanath,Prateek Mittal*

主要分类: cs.CR

摘要简述: 本文揭示了自主网页导航代理因依赖外部内存系统而面临的安全漏洞，提出并验证了一种新型的“计划注入”攻击，成功率高且能绕过现有防御机制。


<details>
  <summary>详细信息</summary>
研究动机: 随着自主网页导航代理在电子商务、信息检索等领域的广泛应用，其依赖的外部内存系统存在安全漏洞，导致攻击者可通过操纵上下文进行攻击，威胁系统安全。

研究方法: 研究提出并形式化了一种名为“计划注入”的上下文操纵攻击，通过系统评估两种流行的网页代理（Browser-use和Agent-E），验证了攻击的有效性，并进一步设计了“上下文链式注入”以提升攻击成功率。

研究结果: 实验表明，“计划注入”攻击能绕过现有防御机制，攻击成功率比传统提示注入攻击高出3倍；“上下文链式注入”在隐私泄露任务中使攻击成功率提升17.7%。

研究结论: 研究强调了在代理系统中安全内存处理的重要性，需将其作为首要关注点以防止类似攻击。

中文摘要: 自主网页导航代理能够将自然语言指令转化为浏览器操作序列，广泛应用于电子商务、信息检索和内容发现等复杂任务。由于大型语言模型（LLM）的无状态特性，这些代理严重依赖外部内存系统来维护交互间的上下文。与集中式系统中上下文安全存储在服务器端不同，代理内存通常由客户端或第三方应用管理，存在显著的安全漏洞。近期已有攻击者利用此漏洞攻击生产系统。

我们提出并形式化了一种名为“计划注入”的新型上下文操纵攻击，通过针对这一脆弱上下文，破坏代理的内部任务表示。通过对两种流行的网页代理（Browser-use和Agent-E）进行系统评估，我们发现计划注入能够绕过强大的提示注入防御机制，攻击成功率比同类提示注入攻击高出3倍。此外，“上下文链式注入”通过在合法用户目标和攻击者目标之间构建逻辑桥梁，使隐私泄露任务的攻击成功率提升了17.7%。我们的研究结果表明，安全内存处理必须成为代理系统的首要关注点。

</details>


### [319] [On the Performance of Cyber-Biomedical Features for Intrusion Detection in Healthcare 5.0](https://arxiv.org/abs/2506.17329)
**中文标题：关于网络生物医学特征在Healthcare 5.0入侵检测中的性能研究**

*Pedro H. Lui,Lucas P. Siqueira,Juliano F. Kazienko,Vagner E. Quincozes,Silvio E. Quincozes,Daniel Welfer*

主要分类: cs.CR

摘要简述: 本文研究了在Healthcare 5.0中结合网络流量和生物医学数据的入侵检测方法，使用可解释AI（XAI）模型XGBoost，结果显示其性能优异，并揭示了生物医学特征在欺骗检测中的重要性。


<details>
  <summary>详细信息</summary>
研究动机: Healthcare 5.0依赖AI和物联网技术，但现有网络安全模型常忽略生物医学数据，导致效果和可解释性不足。本研究旨在填补这一空白，探索结合网络和生物医学数据的入侵检测方法。

研究方法: 研究使用可解释AI（XAI）模型XGBoost，分析整合了网络流量和生物医学传感器数据的Healthcare 5.0数据集，评估其在入侵检测中的性能。

研究结果: XGBoost在良性数据篡改检测中F1-score达99%，欺骗检测中为81%。可解释性分析显示网络数据在入侵检测中占主导，而生物医学特征（如温度）在欺骗检测中贡献显著（Shapley值达0.37）。

研究结论: 结合网络和生物医学数据的XAI模型在Healthcare 5.0入侵检测中表现优异，生物医学特征对欺骗检测尤为重要，为未来研究提供了新方向。

中文摘要: Healthcare 5.0整合了人工智能（AI）、物联网（IoT）、实时监测和以人为中心的设计，旨在实现个性化医疗和预测性诊断。然而，对互联医疗技术的依赖增加使其面临网络威胁。目前基于AI的网络安全模型常忽略生物医学数据，限制了其效果和可解释性。本研究通过将可解释AI（XAI）应用于整合网络流量和生物医学传感器数据的Healthcare 5.0数据集，填补了这一空白。分类结果显示，XGBoost在良性数据篡改检测中F1-score达99%，欺骗检测中为81%。可解释性分析表明，网络数据在入侵检测中占主导，而生物医学特征（如温度）在欺骗检测中贡献显著（Shapley值达0.37）。

</details>


### [320] [CUBA: Controlled Untargeted Backdoor Attack against Deep Neural Networks](https://arxiv.org/abs/2506.17350)
**中文标题：CUBA：针对深度神经网络的受控无目标后门攻击**

*Yinghao Wu,Liyan Zhang*

主要分类: cs.CR

摘要简述: 本文提出了一种新型的受控无目标后门攻击（CUBA），结合无目标攻击的灵活性和有目标攻击的意图性，通过约束目标类别范围实现随机分类，有效规避现有防御方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有后门攻击多为有目标攻击，其触发机制与特定恶意行为强关联，而纯粹的无目标攻击因缺乏目标性而效果有限。本文旨在结合两者优势，提出一种既能灵活攻击又能规避防御的新型后门攻击方法。

研究方法: 通过在对数归一化的交叉熵损失中使用翻转的独热标签，约束训练过程中的对数分布，使受感染模型在选定目标类别范围内呈现均匀分布，从而实现受控的无目标攻击。

研究结果: 实验表明，CUBA在不同数据集上均能有效实现受控无目标攻击，成功规避现有后门防御方法。

研究结论: CUBA通过结合无目标攻击的灵活性和有目标攻击的意图性，提出了一种新型后门攻击方法，为后门攻击防御研究提供了新的挑战。

中文摘要: 近年来，后门攻击已成为深度神经网络面临的重要安全威胁。现有后门攻击多为有目标攻击，其触发机制与特定恶意行为强关联。多数后门检测方法依赖这一固有特性，能有效识别和缓解此类攻击。然而，纯粹的无目标攻击在某些情况下会自我削弱，因为目标性正是后门攻击的强大之处。为此，我们提出了一种新型的受控无目标后门攻击（CUBA），结合了无目标攻击的灵活性和有目标攻击的意图性。受感染的模型在面对后门图像时，会将其分类到攻击者选定的目标类别范围内的随机类别。这种随机性与确定性的结合使该无目标后门攻击能天然规避现有防御方法。为实现受控灵活性下的无目标攻击，我们提出在对数归一化的交叉熵损失中使用翻转的独热标签。通过约束训练过程中的对数分布，受感染模型将在选定目标类别范围内呈现均匀分布，从而实现受控无目标攻击。大量实验证明了CUBA在不同数据集上的有效性。

</details>


### [321] [Differentiation-Based Extraction of Proprietary Data from Fine-Tuned LLMs](https://arxiv.org/abs/2506.17353)
**中文标题：基于差异化的微调大型语言模型专有数据提取**

*Zongjie Li,Daoyuan Wu,Shuai Wang,Zhendong Su*

主要分类: cs.CR

摘要简述: 本文首次研究了从经过监督微调（SFT）的大型语言模型（LLM）中提取专有数据的问题，提出了一种名为差异化数据提取（DDE）的新方法，该方法利用微调模型的置信度及其与预训练基础模型的行为差异，显著优于现有基线方法。同时，论文还提出了一种防御机制以减轻此类攻击。


<details>
  <summary>详细信息</summary>
研究动机: 随着领域特定和人类对齐的大型语言模型（LLM）需求的增加，监督微调（SFT）技术被广泛采用。SFT数据集通常包含高价值的指令-响应对，成为潜在提取的目标。本文首次对这一关键研究问题进行了探讨。

研究方法: 论文首先正式定义并形式化了这一问题，随后基于SFT数据在现实场景中的独特属性，探索了多种攻击目标、类型和变体。通过分析直接提取的行为，开发了一种专门针对SFT模型的提取方法——差异化数据提取（DDE），该方法利用微调模型的置信度及其与预训练基础模型的行为差异。

研究结果: 通过跨多个领域和场景的广泛实验，证明了使用DDE提取SFT数据的可行性。结果显示，DDE在所有攻击设置中均显著优于现有基线方法。同时，论文提出了一种防御机制，能够以最小性能影响减轻DDE攻击。

研究结论: 本研究揭示了微调LLM中隐藏的数据泄露风险，并为开发更安全的模型提供了见解。

中文摘要: 随着领域特定和人类对齐的大型语言模型（LLM）需求的增加，监督微调（SFT）技术被广泛采用。SFT数据集通常包含高价值的指令-响应对，成为潜在提取的目标。本文首次对这一关键研究问题进行了探讨。我们首先正式定义并形式化了这一问题，随后基于SFT数据在现实场景中的独特属性，探索了多种攻击目标、类型和变体。通过分析直接提取的行为，我们开发了一种专门针对SFT模型的提取方法——差异化数据提取（DDE），该方法利用微调模型的置信度及其与预训练基础模型的行为差异。通过跨多个领域和场景的广泛实验，我们证明了使用DDE提取SFT数据的可行性。结果显示，DDE在所有攻击设置中均显著优于现有基线方法。为应对这一新型攻击，我们提出了一种防御机制，能够以最小性能影响减轻DDE攻击。总体而言，本研究揭示了微调LLM中隐藏的数据泄露风险，并为开发更安全的模型提供了见解。

</details>


### [322] [Shrinking the Generation-Verification Gap with Weak Verifiers](https://arxiv.org/abs/2506.18203)
**中文标题：通过弱验证器缩小生成与验证之间的差距**

*Jon Saad-Falcon,E. Kelly Buchanan,Mayee F. Chen,Tzu-Heng Huang,Brendan McLaughlin,Tanvir Bhathal,Shang Zhu,Ben Athiwaratkun,Frederic Sala,Scott Linderman,Azalia Mirhoseini,Christopher Ré*

主要分类: cs.CR

摘要简述: 本文提出Weaver框架，通过结合多个弱验证器来缩小生成与验证之间的性能差距，显著提升了候选响应的选择质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前高质量验证器（如人类或工具）难以扩展或效用有限，而语言模型验证器与理想验证器之间存在显著性能差距。本文旨在通过结合多个弱验证器来缩小这一差距。

研究方法: Weaver框架通过加权集成多个弱验证器，利用弱监督估计各验证器准确性，并归一化输出格式以解决不一致性问题。此外，通过数据集统计过滤低质量验证器，最终生成统一评分以反映真实响应质量。

研究结果: 实验表明，Weaver在数学和推理任务中显著优于Pass@1性能，使用Llama 3.3 70B Instruct生成器时，验证器集成达到87.7%的平均准确率，接近理想验证器水平。

研究结论: Weaver通过结合弱验证器有效缩小了生成与验证之间的性能差距，同时通过训练小型跨编码器降低了计算成本。

中文摘要: 验证器可以通过评分和排序生成的候选响应来提升语言模型的能力。目前，高质量的验证器要么难以扩展（如人类），要么效用有限（如Lean等工具）。尽管语言模型评判器和奖励模型已成为通用验证器，但其与理想验证器（准确率完美）之间仍存在显著性能差距。为缩小这一差距，我们提出了Weaver框架，通过结合多个弱且不完美的验证器来设计强验证器。我们发现，加权集成验证器（通常需要从标注数据中学习）由于验证器准确率差异，显著优于未加权组合。为减少对标注数据的依赖，Weaver利用弱监督估计各验证器的准确率，并将输出结合为统一评分以更真实反映响应质量。然而，直接应用弱监督算法面临挑战，包括验证器输出格式不一致和处理低质量验证器。Weaver通过数据集统计归一化输出并过滤特定验证器来解决这些问题。我们研究了Weaver在测试时重复采样中的有效性，即模型生成多个候选响应并选择其一。评估显示，Weaver在选择首个候选响应时显著优于Pass@1性能，在推理和数学任务中，使用Llama 3.3 70B Instruct作为生成器，以及70B或更小的评判器和奖励模型作为验证器集成时，平均准确率达到87.7%。这一提升与GPT-4o和o3-mini之间的差距（69.0% vs. 86.7%）相当，后者需要大量微调和后训练。为降低验证器集成的计算成本，我们使用Weaver的综合输出评分训练了一个400M的跨编码器。

</details>


### [323] [Mechanistic Interpretability in the Presence of Architectural Obfuscation](https://arxiv.org/abs/2506.18053)
**中文标题：架构混淆下的机制可解释性研究**

*Marcos Florencio,Thomas Barton*

主要分类: cs.CR

摘要简述: 本文研究了架构混淆对机制可解释性的影响，发现混淆虽改变激活模式但保留计算图，阻碍细粒度解释但保持任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 架构混淆（如隐藏状态张量置换或嵌入表线性变换）被用作轻量级隐私保护技术，但其对机制可解释性的影响尚未系统研究。本文旨在填补这一空白。

研究方法: 通过分析一个从头训练的GPT-2-small模型，应用logit-lens归因、因果路径修补和注意力头消融等方法，研究混淆对已知电路的影响。

研究结果: 混淆显著改变注意力头的激活模式，但保留层间计算图。细粒度可解释性受损，但任务性能未受影响。

研究结论: 架构混淆能同时保留全局模型行为并阻碍用户特定内容的机制分析，为未来隐私防御和可解释性工具提供指导。

中文摘要: 架构混淆（如隐藏状态张量置换、嵌入表线性变换或令牌重映射）近年来作为轻量级替代密码学的方法，在隐私保护的大语言模型推理中受到关注。尽管近期研究表明这些技术可通过专用重构攻击破解，但其对机制可解释性的影响尚未系统研究。特别是，尚不清楚混淆网络的内部表示是否会真正阻碍对模型工作原理的理解，还是仅将相同电路转移到不熟悉的坐标系中。本文通过分析一个从头训练的GPT-2-small模型（采用代表性混淆映射）填补了这一空白。假设混淆映射为私有且原始基隐藏（模拟诚实但好奇的服务器），我们应用logit-lens归因、因果路径修补和注意力头消融来定位和操作已知电路。研究发现，混淆显著改变注意力头的激活模式，但保留层间计算图。这种脱节阻碍了用户提示的反向工程：因果轨迹与基线语义失去对齐，令牌级logit归因噪声过大无法重构。同时，前馈和残差路径功能完好，表明混淆虽损害细粒度可解释性但不影响顶层任务性能。这些结果为架构混淆能同时（i）保留全局模型行为和（ii）阻碍用户特定内容的机制分析提供了量化证据。通过映射可解释性失效点，本研究为未来隐私防御和鲁棒性感知的可解释性工具提供了指导。

</details>


### [324] [Federated Learning-Based Data Collaboration Method for Enhancing Edge Cloud AI System Security Using Large Language Models](https://arxiv.org/abs/2506.18087)
**中文标题：基于联邦学习的数据协作方法：利用大型语言模型增强边缘云AI系统安全性**

*Huaiying Luo,Cheng Ji*

主要分类: cs.CR

摘要简述: 本文提出了一种基于联邦学习的数据协作方法，结合大型语言模型（LLM）提升边缘云AI系统的安全性，通过安全多方计算协议和对抗训练技术优化数据隐私保护和系统鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 随着边缘计算和云系统在AI应用中的普及，如何在保证数据隐私的同时维持高效性能成为亟待解决的安全问题。

研究方法: 在现有联邦学习框架基础上，引入安全多方计算协议，利用LLM优化分布式节点间的数据聚合与加密过程，并结合对抗训练技术增强系统对数据泄露和模型投毒等威胁的抵抗力。

研究结果: 实验结果表明，该方法在数据保护和模型鲁棒性方面比传统联邦学习方法提升了15%。

研究结论: 该方法有效提升了边缘云AI系统的安全性和效率，为数据隐私保护和系统鲁棒性提供了新的解决方案。

中文摘要: 随着边缘计算和云系统在AI驱动应用中的广泛应用，如何在确保数据隐私的同时保持高效性能成为一个紧迫的安全问题。本文提出了一种基于联邦学习的数据协作方法，以提高边缘云AI系统的安全性，并利用大型语言模型（LLM）增强数据隐私保护和系统鲁棒性。该方法在现有联邦学习框架的基础上，引入了一种安全多方计算协议，通过使用LLM优化分布式节点间的数据聚合和加密过程，确保数据隐私并提高系统效率。通过结合先进的对抗训练技术，模型增强了边缘云AI系统对数据泄露和模型投毒等安全威胁的抵抗力。实验结果表明，所提出的方法在数据保护和模型鲁棒性方面比传统联邦学习方法提升了15%。

</details>


### [325] [Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection](https://arxiv.org/abs/2506.18245)
**中文标题：Smart-LLaMA-DPO：基于强化大型语言模型的可解释智能合约漏洞检测**

*Lei Yu,Zhirong Huang,Hang Yuan,Shiqi Cheng,Li Yang,Fengjun Zhang,Chenjie Shen,Jiajia Ma,Jingyuan Zhang,Junyi Lu,Chun Zuo*

主要分类: cs.CR

摘要简述: 本文提出Smart-LLaMA-DPO，基于LLaMA-3.1-8B模型，通过构建全面数据集和优化方法，显著提升智能合约漏洞检测的准确性和解释性。


<details>
  <summary>详细信息</summary>
研究动机: 智能合约漏洞检测是区块链安全的主要挑战。现有方法存在数据集覆盖不全和解释质量低的问题，且大型语言模型（LLM）难以准确理解智能合约安全概念。

研究方法: 1. 构建涵盖四大漏洞类型和机器不可审计漏洞的全面数据集；2. 通过大规模智能合约进行持续预训练（CPT）；3. 使用数据集进行监督微调（SFT）；4. 应用直接偏好优化（DPO）结合人类反馈和特殊损失函数。

研究结果: Smart-LLaMA-DPO在四大漏洞类型和机器不可审计漏洞检测中显著优于现有方法，F1分数和准确率分别平均提升10.43%和7.87%，且生成更正确、全面和清晰的解释。

研究结论: Smart-LLaMA-DPO通过综合数据集和优化方法，显著提升了智能合约漏洞检测的性能和解释质量，为区块链安全提供了有效解决方案。

中文摘要: 智能合约漏洞检测仍是区块链安全的主要挑战。现有方法存在两大问题：（1）数据集缺乏全面覆盖和高质量解释；（2）大型语言模型（LLM）难以准确理解智能合约安全概念。实证分析表明，即使经过持续预训练（CPT）和监督微调（SFT），LLM仍可能误解状态变化的执行顺序，导致解释错误。为解决这些问题，我们基于LLaMA-3.1-8B提出Smart-LLaMA-DPO。首先，构建涵盖四大漏洞类型和机器不可审计漏洞的全面数据集，包括精确标签、解释和位置用于SFT，以及高质量和低质量输出对用于直接偏好优化（DPO）。其次，通过大规模智能合约进行CPT以增强LLM对智能合约安全实践的理解。接着，使用数据集进行SFT。最后，应用DPO结合人类反馈和特殊损失函数，提高偏好解释的概率并降低非偏好输出的可能性。我们在四大漏洞类型（重入、时间戳依赖、整数溢出/下溢和委托调用）及机器不可审计漏洞上评估Smart-LLaMA-DPO。结果显示，我们的方法显著优于现有基线，F1分数和准确率分别平均提升10.43%和7.87%。此外，LLM评估和人类评估均证实，我们的方法生成更正确、全面和清晰的解释。

</details>


### [326] [Security Assessment of DeepSeek and GPT Series Models against Jailbreak Attacks](https://arxiv.org/abs/2506.18543)
**中文标题：DeepSeek与GPT系列模型在越狱攻击下的安全性评估**

*Xiaodong Wu,Xiangman Li,Jianbing Ni*

主要分类: cs.CR

摘要简述: 本文首次系统评估了DeepSeek系列模型与GPT-3.5和GPT-4在越狱攻击下的安全性，发现DeepSeek的MoE架构对优化攻击有选择性鲁棒性，但对提示攻击更脆弱，而GPT-4 Turbo表现更一致。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）的广泛应用，其越狱攻击的脆弱性引发关注。尽管GPT-4等专有模型已广泛评估，但开源模型如DeepSeek的安全性尚未充分研究。

研究方法: 使用HarmBench基准评估DeepSeek系列模型与GPT-3.5和GPT-4，涵盖7种代表性攻击策略和510种有害行为，分析其在不同攻击下的表现。

研究结果: DeepSeek的MoE架构对优化攻击（如TAP-T）有选择性鲁棒性，但对提示攻击和人工设计攻击更脆弱；GPT-4 Turbo表现更一致，安全性更强。

研究结论: 研究发现架构效率与对齐泛化之间存在权衡，开源LLMs需针对性安全调优和模块化对齐策略以确保安全部署。

中文摘要: 大语言模型（LLMs）的广泛部署引发了对其越狱攻击脆弱性的重要关注，即通过对抗性提示绕过对齐机制，引发有害或违反政策的输出。尽管像GPT-4这样的专有模型已进行了广泛评估，但新兴的开源替代品（如DeepSeek）的鲁棒性仍未被充分研究，尽管其在现实应用中的使用日益增长。本文首次对DeepSeek系列模型进行了系统的越狱评估，并与GPT-3.5和GPT-4进行了比较，使用了HarmBench基准。我们评估了7种代表性攻击策略，涵盖按功能和语义领域分类的510种有害行为。分析表明，DeepSeek的混合专家（MoE）架构通过路由稀疏性对基于优化的攻击（如TAP-T）提供了选择性鲁棒性，但在提示攻击和人工设计攻击下表现出更高的脆弱性。相比之下，GPT-4 Turbo由于其密集的Transformer设计和人类反馈强化学习，在不同行为中表现出更强且更一致的安全对齐。细粒度行为分析和案例研究进一步显示，DeepSeek常将对抗性提示路由至未充分对齐的专家模块，导致不一致的拒绝行为。这些发现凸显了架构效率与对齐泛化之间的根本权衡，强调了针对性安全调优和模块化对齐策略的必要性，以确保开源LLMs的安全部署。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [327] [BlenderFusion: 3D-Grounded Visual Editing and Generative Compositing](https://arxiv.org/abs/2506.17450)
**中文标题：BlenderFusion：基于3D的视觉编辑与生成式合成**

*Jiacheng Chen,Ramin Mehran,Xuhui Jia,Saining Xie,Sanghyun Woo*

主要分类: cs.GR

摘要简述: BlenderFusion是一种生成式视觉合成框架，通过3D实体编辑和生成式合成技术实现复杂场景的编辑与合成，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在复杂场景编辑任务中表现不足，BlenderFusion旨在通过3D实体编辑和生成式合成技术提升场景编辑的灵活性和效果。

研究方法: BlenderFusion采用分层-编辑-合成流程：(1)将视觉输入分割并转换为可编辑的3D实体；(2)在Blender中进行3D控制编辑；(3)通过生成式合成器将编辑后的场景融合为连贯画面。合成器基于预训练扩散模型，支持源场景和目标场景并行处理，并通过源掩码和模拟对象抖动训练策略优化效果。

研究结果: BlenderFusion在复杂场景编辑任务中显著优于现有方法，支持背景替换和对象与相机的解耦控制。

研究结论: BlenderFusion通过3D实体编辑和生成式合成技术，为复杂场景编辑提供了高效灵活的解决方案。

中文摘要: 我们提出了BlenderFusion，一种生成式视觉合成框架，通过重新组合对象、相机和背景来合成新场景。其流程分为三步：(1)将视觉输入分割并转换为可编辑的3D实体（分层）；(2)在Blender中进行基于3D控制的编辑；(3)使用生成式合成器将编辑后的场景融合为连贯画面。我们的生成式合成器扩展了预训练扩散模型，支持源场景和目标场景的并行处理，并通过两种关键训练策略进行微调：(1)源掩码，支持背景替换等灵活修改；(2)模拟对象抖动，便于对象与相机的解耦控制。BlenderFusion在复杂场景编辑任务中显著优于现有方法。

</details>


### [328] [3D Gaussian Splatting for Fine-Detailed Surface Reconstruction in Large-Scale Scene](https://arxiv.org/abs/2506.17636)
**中文标题：基于3D高斯泼溅的大规模场景精细表面重建**

*Shihan Chen,Zhaojin Li,Zeyu Chen,Qingsong Yan,Gaoyang Shen,Ran Duan*

主要分类: cs.GR

摘要简述: 本文提出了一种基于3D高斯泼溅的大规模场景精细表面重建方法，通过粗到细策略、自适应场景分区和外观解耦模型，显著提升了重建精度和效率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管3D高斯泼溅技术在表面重建方面取得了进展，但在大规模场景（如航测和自动驾驶）中仍面临计算复杂度高和动态外观干扰的挑战。本文旨在解决这些问题，实现高精度的表面重建。

研究方法: 1. 采用粗到细策略，先快速构建粗糙模型，再通过自适应场景分区和子场景细化优化细节。2. 引入解耦外观模型捕捉全局外观变化，并使用瞬态掩模模型减少移动物体的干扰。3. 扩展多视角约束，并为纹理缺失区域引入单视角正则化。

研究结果: 在公开数据集GauU-Scene V2上的实验表明，该方法在视觉保真度和表面精度上优于现有基于NeRF和高斯的方法。

研究结论: 本文方法通过创新策略和模型设计，实现了大规模场景的高精度表面重建，为航测和自动驾驶等应用提供了有效解决方案。

中文摘要: 近年来，3D高斯泼溅技术在表面重建方面取得了显著进展。然而，由于计算需求高和户外环境复杂的动态外观，将这些方法扩展到大规模场景仍具挑战性，这限制了其在航测和自动驾驶中的应用。本文提出了一种新方法，通过全尺寸图像的监督重建具有精细细节的大规模表面。首先，我们引入了一种粗到细策略，高效重建粗糙模型，随后通过自适应场景分区和图像片段细化子场景。此外，我们集成了一个解耦外观模型以捕捉全局外观变化，以及一个瞬态掩模模型以减少移动物体的干扰。最后，我们扩展了多视角约束，并为纹理缺失区域引入了单视角正则化。实验在公开数据集GauU-Scene V2上进行，该数据集通过无人机拍摄。据我们所知，我们的方法在视觉保真度和表面精度上优于现有的基于NeRF和高斯的方法。开源代码将在GitHub上提供。

</details>


### [329] [Auto-Regressive Surface Cutting](https://arxiv.org/abs/2506.18017)
**中文标题：自回归表面切割**

*Yang Li,Victor Cheung,Xinhai Liu,Yuguang Chen,Zhongjin Luo,Biwen Lei,Haohan Weng,Zibo Zhao,Jingwei Huang,Zhuo Chen,Chunchao Guo*

主要分类: cs.GR

摘要简述: 本文提出了一种名为SeamGPT的自回归模型，用于生成表面切割缝，模仿专业工作流程，显著提升了UV展开和网格分解的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的表面切割方法虽然技术有效，但生成的图谱往往过于碎片化且缺乏语义一致性。本文旨在通过模仿专业工作流程，解决这一问题。

研究方法: 将表面切割任务转化为下一个标记预测任务：在网格顶点和边缘上采样点云，将其编码为形状条件，并使用GPT风格的变换器模型逐步预测带有量化3D坐标的切割缝段。

研究结果: 在包含流形和非流形网格的UV展开基准测试中表现优异，包括艺术家创作和3D扫描模型。同时，为现有3D分割工具提供了清晰的边界支持。

研究结论: SeamGPT通过自回归模型成功解决了表面切割中的碎片化和语义一致性问题，为计算机图形学中的相关任务提供了高效解决方案。

中文摘要: 表面切割是计算机图形学中的一项基础任务，广泛应用于UV参数化、纹理映射和网格分解。然而，现有方法通常生成技术上有效但过于碎片化的图谱，缺乏语义一致性。我们提出了SeamGPT，一种自回归模型，通过模仿专业工作流程生成切割缝。我们的关键技术创新在于将表面切割任务转化为下一个标记预测任务：在网格顶点和边缘上采样点云，将其编码为形状条件，并采用GPT风格的变换器逐步预测带有量化3D坐标的切割缝段。我们的方法在包含流形和非流形网格的UV展开基准测试中表现优异，包括艺术家创作和3D扫描模型。此外，该方法通过为部件分解提供清晰边界，增强了现有3D分割工具的功能。

</details>


### [330] [Collaborative Texture Filtering](https://arxiv.org/abs/2506.17770)
**中文标题：协作纹理过滤**

*Tomas Akenine-Möller,Pontus Ebelin,Matt Pharr,Bartlomiej Wronski*

主要分类: cs.GR

摘要简述: 本文提出了一种基于GPU波通信的协作纹理过滤方法，通过共享解压缩的纹理值减少重复计算，实现了高质量纹理放大和降噪。


<details>
  <summary>详细信息</summary>
研究动机: 现有的随机纹理过滤（STF）技术在纹理放大时可能产生视觉伪影和噪声，尽管使用了时空去噪器，效果仍不理想。因此，需要一种更高效且高质量的纹理过滤方法。

研究方法: 利用GPU波通信特性，在着色器执行过程中共享解压缩的纹理值，避免重复计算。对于高放大倍数，实现了零误差过滤；其他情况下，提出了新的高质量过滤回退方法。

研究结果: 提出的方法在高放大倍数下实现了零误差过滤，且在其他情况下显著提升了过滤质量，优于现有技术。

研究结论: 通过GPU波通信协作过滤，本文方法在减少计算开销的同时，显著提升了纹理过滤的质量和效率。

中文摘要: 近年来，纹理压缩技术的进步显著提高了压缩比，但无法利用GPU的纹理单元进行解压缩和过滤。这促使了随机纹理过滤（STF）技术的发展，以避免此类格式下多次纹理评估的高成本。然而，这些方法在放大时可能导致不理想的视觉变化，并可能包含可见的噪声和闪烁，尽管使用了时空去噪器。最近的研究通过共享附近像素的解压缩纹理值（Wronski 2025），显著改善了STF的放大过滤质量。利用GPU波通信特性，这种共享可以在活跃执行的着色器内部完成，无需额外的内存开销。我们进一步扩展了这一思路，提出了新的算法，利用波通信避免过滤前的重复纹理解压缩。通过在不同通道间分配唯一任务，我们可以在足够大的放大倍数下，实现每像素≤1次纹理评估的零误差过滤。对于其他情况，我们提出了新的高质量过滤回退方法，其效果优于现有技术。

</details>


### [331] [Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models](https://arxiv.org/abs/2506.18251)
**中文标题：Morse：双采样框架实现扩散模型的无损加速**

*Chao Li,Jiawei Fan,Anbang Yao*

主要分类: cs.GR

摘要简述: 本文提出Morse框架，通过双采样策略（Dash和Dot模型交互）无损加速扩散模型，平均提速1.78X至3.31X，适用于多种图像生成任务。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型生成速度慢，现有加速方法可能损失性能。Morse旨在通过双采样框架实现无损加速，提升效率同时保持生成质量。

研究方法: Morse包含Dash和Dot模型：Dash为预训练扩散模型，采用跳跃采样；Dot生成残差反馈，提升噪声估计效率。两者通过时间交错运行和权重共享策略实现高效训练与推理。

研究结果: 在6项图像生成任务中，Morse平均提速1.78X至3.31X，优于9种基线模型，并可推广至Latent Consistency Model（LCM-SDXL）。

研究结论: Morse通过双采样框架和残差反馈策略，实现了扩散模型的无损加速，显著提升效率且保持性能，适用于广泛任务。

中文摘要: 本文提出Morse，一种简单的双采样框架，用于无损加速扩散模型。Morse的核心思想是通过快速跳跃采样和自适应残差反馈策略重构迭代生成过程。具体而言，Morse包含Dash和Dot两个交互模型：Dash为任意类型的预训练扩散模型，采用跳跃采样以提升效率；Dot模型速度更快，通过学习生成残差反馈，将噪声估计提升至与Dash模型的下一步估计匹配，无需跳跃采样。通过时间交错运行Dash和Dot模型，Morse灵活实现高效图像生成。提出的权重共享策略使训练和推理更高效。实验表明，Morse在6项图像生成任务中平均提速1.78X至3.31X，优于9种基线模型，并可推广至适用于少步文本到图像合成的Latent Consistency Model（LCM-SDXL）。代码和模型已开源。

</details>


### [332] [What You Think Is What You Get: Bridge User Intent and Transfer Function Design through Multimodal Large Language Models](https://arxiv.org/abs/2506.18407)
**中文标题：所想即所得：通过多模态大语言模型桥接用户意图与传递函数设计**

*Yiyao Wang,Bo Pan,Ke Wang,Han Liu,Jinyuan Mao,Yuxin Liu,Minfeng Zhu,Bo Zhang,Weifeng Chen,Xiuqi Huang,Wei Chen*

主要分类: cs.GR

摘要简述: 本文提出了一种名为WYTWYG的框架，利用多模态大语言模型（MLLMs）指导基于用户意图的传递函数（TF）优化，解决了传统TF设计中的探索空间大和泛化能力弱的问题。


<details>
  <summary>详细信息</summary>
研究动机: 直接体积渲染（DVR）中，传递函数（TF）的设计由于用户意图与TF参数空间之间的语义鸿沟而显得不直观。现有TF优化方法面临探索空间大和泛化能力弱的挑战，因此需要一种更高效且通用的解决方案。

研究方法: WYTWYG框架包含两个核心组件：(1) 基于进化的探索器，用于高效探索TF空间；(2) 基于MLLMs的体积渲染质量评估器，提供通用视觉指导。此外，还提出了一个基于此方法的TF交互设计系统。

研究结果: 通过三个案例研究验证了框架的通用性，并通过大量实验验证了各组件的有效性。

研究结论: WYTWYG框架成功解决了TF设计中的探索空间和泛化问题，为基于用户意图的TF优化提供了新思路。

中文摘要: 直接体积渲染（DVR）是可视化体积数据的基本技术，传递函数（TFs）在提取有意义结构中起关键作用。然而，由于用户意图与TF参数空间之间的语义鸿沟，设计有效的TFs仍不直观。研究者开发了许多TF优化方法以弥合这一鸿沟，但现有方法仍面临两大挑战：探索空间大和泛化能力弱。为解决这些问题，我们提出了“所想即所得”（WYTWYG）框架，利用多模态大语言模型（MLLMs）基于用户意图指导TF优化。具体而言，我们首先提出了一种新的TF优化方法，包含两个核心组件：(1) 基于进化的探索器，用于高效探索TF空间；(2) 基于MLLMs的体积渲染质量评估器，提供通用视觉指导。我们还基于此方法提出了一个TF交互设计系统。通过三个案例研究展示了框架的通用性，并通过大量实验验证了各组件的有效性。代码可在https://github.com/wyysteelhead/TFevolve获取。

</details>


### [333] [BulletGen: Improving 4D Reconstruction with Bullet-Time Generation](https://arxiv.org/abs/2506.18601)
**中文标题：BulletGen：通过子弹时间生成改进4D重建**

*Denys Rozumnyi,Jonathon Luiten,Numair Khan,Johannes Schönberger,Peter Kontschieder*

主要分类: cs.GR

摘要简述: BulletGen利用生成模型修正高斯动态场景表示中的错误并补全缺失信息，通过扩散模型生成帧监督4D高斯模型优化，实现沉浸式动态场景重建。


<details>
  <summary>详细信息</summary>
研究动机: 将单目视频转化为沉浸式动态场景存在严重挑战，如重建未观测区域和单目深度估计模糊性。本文旨在通过生成模型解决这些问题。

研究方法: 提出BulletGen方法，结合扩散模型生成帧与4D重建对齐，生成内容用于监督4D高斯模型优化，融合静态与动态场景组件。

研究结果: 在新型视图合成和2D/3D跟踪任务中取得最先进成果，生成内容与场景无缝融合。

研究结论: BulletGen通过生成模型与4D重建的结合，显著提升了动态场景重建的准确性和沉浸感。

中文摘要: 将随意捕捉的单目视频转化为完全沉浸式的动态体验是一项高度不适定的任务，面临诸多挑战，如重建未观测区域和处理单目深度估计的模糊性。本文提出BulletGen方法，利用生成模型修正高斯动态场景表示中的错误并补全缺失信息。该方法通过将基于扩散的视频生成模型输出与单次冻结的“子弹时间”步骤的4D重建对齐，生成的帧用于监督4D高斯模型的优化。我们的方法无缝融合了生成内容与静态和动态场景组件，在新型视图合成和2D/3D跟踪任务中取得了最先进的结果。

</details>


### [334] [DuetGen: Music Driven Two-Person Dance Generation via Hierarchical Masked Modeling](https://arxiv.org/abs/2506.18680)
**中文标题：DuetGen：基于分层掩码建模的音乐驱动双人舞蹈生成**

*Anindita Ghosh,Bing Zhou,Rishabh Dabral,Jian Wang,Vladislav Golyanik,Christian Theobalt,Philipp Slusallek,Chuan Guo*

主要分类: cs.GR

摘要简述: DuetGen是一种新颖的框架，通过分层掩码建模从音乐生成交互式双人舞蹈，解决了双人舞蹈同步和音乐对齐的复杂性问题。


<details>
  <summary>详细信息</summary>
研究动机: 双人舞蹈生成任务的核心挑战在于舞伴之间以及与音乐的同步性。现有方法难以有效捕捉复杂的交互细节，因此需要一种能够分层建模并生成高质量双人舞蹈的框架。

研究方法: DuetGen采用两阶段方法：1) 使用VQ-VAE将双人动作编码为离散令牌，分层分离高级语义特征和低级细节；2) 使用两个生成式掩码变换器，分别将音乐信号映射到高级和低级舞蹈令牌，通过掩码预测逐步生成动作序列。

研究结果: 在基准双人舞蹈数据集上的实验和用户研究表明，DuetGen在动作真实性、音乐舞蹈对齐和舞伴协调性方面达到了最先进的性能。

研究结论: DuetGen通过分层掩码建模和专用交互表示，成功生成了跨多种风格的同步且交互性强的双人舞蹈，为音乐驱动的舞蹈生成提供了有效解决方案。

中文摘要: 我们提出了DuetGen，一种从音乐生成交互式双人舞蹈的新颖框架。该任务的关键挑战在于双人舞蹈交互的复杂性，舞伴需要彼此同步并与音乐同步。受运动合成最新进展的启发，我们提出了一种两阶段解决方案：将双人动作编码为离散令牌，然后从音乐生成这些令牌。为了有效捕捉复杂的交互，我们将两位舞者的动作表示为一个整体来学习必要的动作令牌，并在两个阶段中采用由粗到细的学习策略。第一阶段使用VQ-VAE，在粗时间分辨率下分层分离高级语义特征，在细分辨率下分离低级细节，生成两个不同抽象级别的离散令牌序列。随后，在第二阶段，两个生成式掩码变换器学习将音乐信号映射到这些舞蹈令牌：第一个生成高级语义令牌，第二个在音乐和这些语义令牌的条件下生成低级令牌。我们训练这两个变换器预测序列中随机掩码的令牌，使它们能够在推理过程中通过填充空令牌序列逐步生成动作令牌。通过分层掩码建模和专用交互表示，DuetGen实现了跨多种风格的同步且交互性强的双人舞蹈生成。在基准双人舞蹈数据集上的广泛实验和用户研究表明，DuetGen在动作真实性、音乐舞蹈对齐和舞伴协调性方面达到了最先进的性能。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [335] [LMR-BENCH: Evaluating LLM Agent's Ability on Reproducing Language Modeling Research](https://arxiv.org/abs/2506.17335)
**中文标题：LMR-BENCH：评估LLM代理在复现语言建模研究中的能力**

*Shuo Yan,Ruochen Li,Ziming Luo,Zimu Wang,Daoyang Li,Liqiang Jing,Kaiyu He,Peilin Wu,George Michalopoulos,Yue Zhang,Ziyang Zhang,Mian Zhang,Zhiyu Chen,Xinya Du*

主要分类: cs.SE

摘要简述: 本文提出LMR-BENCH基准，用于评估大型语言模型（LLM）代理在复现语言建模研究代码方面的能力，发现即使最先进的模型在科学推理和代码合成上仍存在显著不足。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM代理在科学发现中展现出潜力，但其在复现研究论文代码（尤其是NLP领域）方面的能力尚未充分研究。这一任务涉及抽象概念的综合理解和对代码库的复杂推理，因此需要系统评估。

研究方法: 研究设计了LMR-BENCH基准，包含28个代码复现任务，源自过去五年顶级NLP会议的23篇论文，涵盖九类基础任务。模型需根据论文和部分掩码的代码库实现缺失功能，并通过单元测试和LLM评估代码正确性。

研究结果: 实验表明，即使最先进的LLM在科学推理和代码合成方面仍存在显著局限性，无法完全自主复现科学研究。

研究结论: LMR-BENCH揭示了LLM代理在科学代码复现中的不足，为未来改进提供了方向。

中文摘要: 大型语言模型（LLM）代理在推动科学发现方面展现出巨大潜力，但其在复现研究论文代码（尤其是NLP领域）这一基础而关键任务中的能力尚未充分探索。该任务涉及抽象概念的综合理解和对依赖文件的代码库的复杂推理。基于此空白，我们提出LMR-BENCH基准，用于系统评估LLM代理在语言建模研究代码复现中的能力。该基准包含28个代码复现任务，源自过去五年顶级NLP会议的23篇论文，涵盖九类基础任务。模型需根据论文、部分掩码的代码库及实现指令完成任务。我们在标准提示和LLM代理设置下进行了广泛实验，通过单元测试和LLM评估代码正确性。实验结果表明，即使最先进的模型在科学推理和代码合成方面仍存在显著局限性，凸显了LLM代理在自主复现科学研究中的关键不足。

</details>


### [336] [Re-Evaluating Code LLM Benchmarks Under Semantic Mutation](https://arxiv.org/abs/2506.17369)
**中文标题：在语义变异下重新评估代码LLM基准测试**

*Zhiyuan Pan,Xing Hu,Xin Xia,Xiaohu Yang*

主要分类: cs.SE

摘要简述: 本文研究了代码基准测试中提示敏感性对大型语言模型（LLM）性能评估的影响，发现即使微小的提示变化也会导致性能显著波动，并可能影响模型排名。


<details>
  <summary>详细信息</summary>
研究动机: 现有代码基准测试通常依赖单一提示模板，容易因提示敏感性导致性能评估不可靠。本文旨在探究代码任务中提示敏感性的影响，为未来基准测试设计提供更可靠的评估方法。

研究方法: 提出一个通用框架，生成语义和结构相似的提示模板，并在8个代码基准任务和10个代表性开源LLM上进行实验，分析性能变化和模型排名一致性。

研究结果: 实验表明，微小的提示变化会导致性能显著波动，并可能改变模型排名，凸显了提示敏感性对评估结果的影响。

研究结论: 未来代码基准测试设计需考虑提示敏感性，以确保对LLM能力的评估更可靠和准确。

中文摘要: 在大型语言模型（LLM）时代，代码基准测试已成为软件工程中的重要研究领域，并被广泛用于实践。这些基准测试评估LLM在特定代码相关任务（如代码理解和生成）上的性能。构建代码基准测试的关键步骤是提示设计。然而，现有代码基准测试通常依赖每个任务的单一提示模板，容易因提示敏感性导致性能评估不可靠，即微小的提示变化可能导致性能显著波动。尽管已有研究探索了提示敏感性，但其实验设计和发现仅限于传统自然语言处理（NLP）任务。本文通过实证研究探究代码基准测试中的提示敏感性。我们首先提出一个通用框架，尽可能保留语义和结构地修改提示模板。基于该框架，我们在8个代码基准任务和10个代表性开源LLM上进行了广泛实验，每个任务包含100个语义相似的提示模板。随后，我们使用多种统计指标分析评估结果，重点关注绝对和相对模型性能。研究发现，即使微小的提示变化也会导致性能显著波动。此外，这种变化可能导致不同模型间的性能排名不一致。这些发现强调了在设计未来代码基准测试时需考虑提示敏感性，以确保对LLM能力的评估更可靠和准确。

</details>


### [337] [Software Reuse in the Generative AI Era: From Cargo Cult Towards AI Native Software Engineering](https://arxiv.org/abs/2506.17937)
**中文标题：生成式AI时代的软件复用：从货物崇拜到AI原生软件工程**

*Tommi Mikkonen,Antero Taivalsaari*

主要分类: cs.SE

摘要简述: 本文探讨了生成式AI时代下的软件复用，从‘货物崇拜’开发转向AI原生软件工程，提出了相关问题和研究议程。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI和生成式软件复用在软件开发中的崛起，传统复用方法正被AI辅助方式取代，这引发了对新复用形式及其问题的探讨。

研究方法: 通过分析AI辅助生成式软件复用的现象，提出相关问题，并定义研究议程以解决这一新复用形式的核心问题。

研究结果: 文章揭示了AI辅助软件复用与‘货物崇拜’开发的相似性，并提出了应对这一趋势的研究方向和行动呼吁。

研究结论: 生成式AI时代的软件复用需要新的研究议程，以确保AI原生软件工程的健康发展。

中文摘要: 软件开发正经历一场范式转变，人工智能和生成式软件复用成为软件创造的核心。传统的软件复用实践和方法正迅速被AI辅助方法取代，开发者开始信任由AI生成的代码。这导致了一种新的软件复用形式，概念上与‘货物崇拜’开发并无太大差异。本文讨论了AI辅助生成式软件复用在‘AI原生’软件工程背景下的影响，提出了相关问题，并定义了一个初步的研究议程和行动呼吁，以解决与这一方法相关的核心问题。

</details>


### [338] [Call Me Maybe: Enhancing JavaScript Call Graph Construction using Graph Neural Networks](https://arxiv.org/abs/2506.18191)
**中文标题：或许可以叫我：利用图神经网络增强JavaScript调用图构建**

*Masudul Hasan Masud Bhuiyan,Gianluca De Stefano,Giancarlo Pellegrino,Cristian-Alexandru Staicu*

主要分类: cs.SE

摘要简述: 本文提出GRAPHIA方法，利用图神经网络改进JavaScript调用图的构建，通过链接预测填补现有工具的遗漏边，显著提升召回率。


<details>
  <summary>详细信息</summary>
研究动机: JavaScript调用图构建因语言特性复杂，现有工具既不健全也不完整，常产生假边或遗漏有效边。本文旨在通过机器学习方法辅助工具识别遗漏的调用边。

研究方法: GRAPHIA将问题建模为全程序图上的链接预测，结合句法和语义边表示代码元素关系，利用图神经网络学习非局部关系，支持从静态工具和动态测试中学习不完美标签。

研究结果: 在50个流行JavaScript库的163K调用边（150K静态和13K动态）上评估，GRAPHIA在42%未解析调用中将正确目标排名第一，72%排名前五，显著减少人工分析需求。

研究结论: 基于学习的方法可提升JavaScript调用图构建的召回率，GRAPHIA是首个将GNN链接预测应用于多文件程序图进行过程间分析的工作。

中文摘要: 静态分析在发现漏洞（包括安全问题）中起关键作用，而构建准确的调用图是静态分析的核心步骤。然而，由于难以分析的语言特性，现有JavaScript调用图构建算法既不健全也不完整。先前研究表明，即使高级解决方案也会产生假边或遗漏有效边。本文通过识别遗漏的调用边辅助这些工具，将问题建模为全程序图上的链接预测，采用多边类型的丰富表示。我们的方法GRAPHIA利用图神经网络的最新进展建模代码元素间的非局部关系，具体提出结合句法和语义边表示JavaScript程序。GRAPHIA可从静态工具和动态测试的不完美标签中学习，包括来自同一或不同项目的调用边。由于调用图稀疏，标准机器学习指标（如ROC）不适用，我们通过为每个未解析调用点排名函数定义来评估GRAPHIA。在50个流行JavaScript库的163K调用边（150K静态和13K动态）上进行大规模评估，GRAPHIA构建了包含6.6M结构边和386K语义边的程序图。在42%未解析案例中，它将正确目标排名第一，72%排名前五，减少了人工分析需求。结果表明，基于学习的方法可提升JavaScript调用图构建的召回率。据我们所知，这是首个将GNN链接预测应用于多文件程序图进行过程间分析的工作。

</details>


### [339] [Tu(r)ning AI Green: Exploring Energy Efficiency Cascading with Orthogonal Optimizations](https://arxiv.org/abs/2506.18289)
**中文标题：将AI“调绿”：通过正交优化探索能源效率的级联效应**

*Saurabhsingh Rajput,Mootez Saad,Tushar Sharma*

主要分类: cs.SE

摘要简述: 本文提出将能源效率作为AI计算密集型流程的核心设计考量，通过正交优化组合在五个AI流程阶段（数据、模型、训练、系统、推理）中实现能源效率的级联提升，实验证明可减少高达94.6%的能耗，同时保持95.95%的原始F1分数。


<details>
  <summary>详细信息</summary>
研究动机: AI的快速发展带来了巨大的计算需求和能源挑战。目前，优化技术（如“旋钮”）通常是被动、孤立地应用，缺乏对其组合效应对能源效率影响的系统性研究。本文旨在将能源效率提升为设计AI流程时的首要考虑因素。

研究方法: 研究提出了一种正交优化方法，通过战略性地选择并组合五个AI流程阶段（数据、模型、训练、系统、推理）中的优化技术，以实现能源效率的级联提升。实验验证了这些正交组合的效果。

研究结果: 实验结果表明，正交优化组合可减少高达94.6%的能源消耗，同时保持95.95%的原始F1分数，显著提升了能源效率而不显著牺牲性能。

研究结论: 本文提供了一种可操作的框架，帮助实现可持续的AI设计，平衡效率、性能和环保责任。能源效率应成为AI流程设计的核心考量。

中文摘要: AI的指数级增长加剧了计算需求和能源挑战。尽管从业者采用了多种优化技术（本文称之为“旋钮”）来调整模型效率，但这些通常是事后被动、孤立的临时调整，缺乏对其组合效应对能源效率影响的系统性理解。本文强调将能源效率作为计算密集型流程的一等公民和基本设计考量。研究表明，在五个AI流程阶段（数据、模型、训练、系统、推理）中战略性地选择优化技术，可以实现能源效率的级联提升。实验验证表明，正交组合可将能耗降低高达94.6%，同时保留非优化流程原始F1分数的95.95%。这种精心设计的方法为平衡效率、性能和环保责任的可持续AI提供了可操作的框架。

</details>


### [340] [Use Property-Based Testing to Bridge LLM Code Generation and Validation](https://arxiv.org/abs/2506.18315)
**中文标题：利用基于属性的测试桥接LLM代码生成与验证**

*Lehan He,Zeren Chen,Zhe Zhang,Jing Shao,Xiang Gao,Lu Sheng*

主要分类: cs.SE

摘要简述: 本文提出了一种基于属性测试（PBT）的新框架Property-Generated Solver，用于验证大语言模型（LLM）生成的代码功能正确性。通过两个协作的LLM代理（生成器和测试器），该框架避免了传统测试驱动开发（TDD）的局限性，显著提升了代码生成的准确性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）在代码生成方面表现出色，但其输出在复杂编程任务中的功能正确性难以保证。传统测试驱动开发（TDD）因高质量测试用例稀缺或自动化测试生成的缺陷（如偏差测试或不准确的输出预测）而效果受限。因此，需要一种更高效的验证方法。

研究方法: 本文提出Property-Generated Solver框架，利用属性测试（PBT）验证程序的高层属性或不变式，而非依赖具体输入输出示例。框架包含两个LLM代理：生成器负责代码生成与迭代优化，测试器管理PBT生命周期并从属性违规中生成语义丰富的反馈。

研究结果: 实验结果表明，Property-Generated Solver在多个代码生成基准测试中显著优于传统TDD方法，pass@1指标相对提升了23.1%至37.3%。

研究结论: 通过将PBT作为核心验证引擎，Property-Generated Solver为LLM代码生成提供了更稳健的验证机制，显著提升了代码的正确性和泛化能力。

中文摘要: 大语言模型（LLM）擅长代码生成，但确保其输出在复杂编程任务中的功能正确性仍是一个持续挑战。传统的测试驱动开发（TDD）虽为代码优化提供了路径，但其在LLM中的应用常因高质量测试用例稀缺或自动化测试生成的缺陷（如偏差测试或不准确的输出预测）而受限。本文提出Property-Generated Solver，一种新颖框架，利用基于属性的测试（PBT）验证程序的高层属性或不变式，而非依赖具体输入输出示例。这些属性通常比直接预测详尽测试预言更易定义和验证，从而打破了测试可能与待验证代码共享缺陷的“自我欺骗循环”。Property-Generated Solver采用两个协作的LLM代理：生成器专注于代码生成与迭代优化，测试器则管理PBT生命周期并从属性违规中生成语义丰富的反馈。由此产生的全面且可操作的反馈指导生成器进行优化。通过将PBT作为这一迭代闭环范式中的核心验证引擎，Property-Generated Solver为引导LLM生成更正确且泛化的代码提供了稳健机制。在多个代码生成基准测试中的广泛实验结果表明，Property-Generated Solver相对于传统TDD方法实现了显著的pass@1提升，相对增益达23.1%至37.3%。

</details>


### [341] [The Debugging Decay Index: Rethinking Debugging Strategies for Code LLMs](https://arxiv.org/abs/2506.18403)
**中文标题：调试衰减指数：重新思考代码大语言模型的调试策略**

*Muntasir Adnan,Carlos C. N. Kuhn*

主要分类: cs.SE

摘要简述: 论文提出了一种称为“调试衰减指数（DDI）”的数学框架，用于量化AI调试能力的衰减，并提出了一种策略性重启方法，以优化代码生成系统的调试效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI调试能力在2-3次尝试后会显著衰减60-80%，而迭代调试是代码生成系统的关键能力。研究旨在解决这一局限性，并提供量化工具和优化策略。

研究方法: 引入调试衰减指数（DDI）作为量化工具，预测调试失效点，并提出策略性重启方法，从利用转向探索，以提升调试效果。

研究结果: DDI揭示了当前AI调试的根本局限性，并通过策略性重启显著提升了调试效果，为优化迭代代码生成策略提供了首个量化框架。

研究结论: DDI为AI调试提供了量化分析工具，策略性重启方法有效解决了调试能力衰减问题，为代码生成系统的优化提供了新思路。

中文摘要: AI调试的效果遵循可预测的指数衰减模式；大多数模型在仅2-3次尝试后就会丧失60-80%的调试能力，而迭代调试是实际代码生成系统的关键能力。我们引入了调试衰减指数（DDI），这是一个数学框架，用于量化调试何时失效并预测干预点。我们的策略性重启方法在调试过程中从利用转向探索，表明适时干预可以挽救调试效果。DDI揭示了当前AI调试的根本局限性，并为优化迭代代码生成策略提供了首个量化框架。

</details>


### [342] [Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories](https://arxiv.org/abs/2506.18824)
**中文标题：理解软件工程代理：思维-行动-结果轨迹研究**

*Islem Bouzenia,Michael Pradel*

主要分类: cs.SE

摘要简述: 本文通过大规模实证研究，分析了三种基于大语言模型（LLM）的软件工程代理（RepairAgent、AutoCodeRover和OpenHands）的思维-行动-结果轨迹，揭示了其决策过程的行为模式和反模式，为改进代理设计提供了实用建议。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于LLM的代理在软件工程任务（如程序修复和问题解决）中广泛应用，但其内部决策过程仍未被充分研究，限制了对其操作动态和失败模式的理解。本文旨在填补这一空白。

研究方法: 研究统一了三种代理的交互日志（共120条轨迹和2822次LLM交互），结合定量分析（结构特性、行动模式和令牌使用）和定性评估（推理一致性和反馈整合），揭示了轨迹特征和行为模式。

研究结果: 研究发现成功与失败执行的关键区别在于迭代次数、令牌消耗、重复行动序列以及思维、行动与结果的语义一致性。同时，识别了行为模式和反模式，为代理设计改进提供了具体建议。

研究结论: 研究揭示了LLM代理的行为特征和失败原因，为优化代理设计（如提示策略、失败诊断和反模式检测）提供了实用指导，并公开了数据集和标注框架以支持未来研究。

中文摘要: 基于大语言模型（LLM）的代理越来越多地用于自动化复杂软件工程任务（如程序修复和问题解决）。这些代理通过自主生成自然语言思维、调用外部工具并迭代优化解决方案来运作。尽管其广泛应用，这些代理的内部决策过程仍未被充分探索，限制了对其操作动态和失败模式的理解。本文对三种先进LLM代理（RepairAgent、AutoCodeRover和OpenHands）的思维-行动-结果轨迹进行了大规模实证研究。我们将其交互日志统一为通用格式，捕获了120条轨迹和2822次专注于程序修复和问题解决的LLM交互。研究结合了结构特性、行动模式和令牌使用的定量分析，以及推理一致性和反馈整合的定性评估。我们识别了关键轨迹特征（如迭代次数和令牌消耗）、重复行动序列以及思维、行动与结果的语义一致性。研究发现揭示了区分成功与失败执行的行为模式和反模式，为改进代理设计（包括提示策略、失败诊断和反模式检测）提供了实用见解。我们公开了数据集和标注框架，以支持未来对透明且鲁棒的自洽软件工程代理的研究。

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [343] [LIGHTHOUSE: Fast and precise distance to shoreline calculations from anywhere on earth](https://arxiv.org/abs/2506.18842)
**中文标题：灯塔：地球上任意位置快速精确的海岸线距离计算**

*Patrick Beukema,Henry Herzog,Yawen Zhang,Hunter Pitelka,Favyen Bastani*

主要分类: cs.DB

摘要简述: 本文介绍了一种新的数据集和算法，用于从地球上任何位置快速高效地计算海岸线距离。现有全球海岸数据集分辨率较低（1-4公里），限制了其应用。通过结合公开卫星图像和计算机视觉技术，本文提供了10米分辨率的全球海岸线数据集，精度提升了100倍以上。同时，提出了一种名为Lighthouse的高效计算库，仅需1个CPU和2GB内存即可实现毫秒级在线推理，适用于资源受限的实时应用。


<details>
  <summary>详细信息</summary>
研究动机: 现有全球海岸数据集分辨率较低（1-4公里），无法满足高精度需求。公开卫星图像和计算机视觉技术的发展为更高精度的海岸线距离计算提供了可能。本文旨在填补这一空白，提供高分辨率数据集和高效算法。

研究方法: 1. 利用公开卫星图像和计算机视觉技术生成10米分辨率的全球海岸线数据集。2. 开发Lighthouse库，采用分层迭代地理空间层次化地形导向统一搜索算法，实现高效计算。3. 优化资源占用，仅需1个CPU和2GB内存即可完成毫秒级在线推理。

研究结果: 1. 提供了10米分辨率的全球海岸线数据集，精度比现有数据提升100倍以上。2. Lighthouse库在资源受限环境下表现优异，仅需1个CPU和2GB内存即可实现毫秒级响应。

研究结论: 本文成功开发了高分辨率全球海岸线数据集和高效计算库Lighthouse，显著提升了海岸线距离计算的精度和效率，适用于实时应用。

中文摘要: 我们介绍了一种新的数据集和算法，用于从地球上任何位置（AoE）快速高效地计算海岸线距离。现有的全球海岸数据集分辨率较低（例如1-4公里），限制了其应用。通过结合公开卫星图像和计算机视觉技术，我们提供了10米分辨率的全球海岸线数据集，精度比现有数据提高了100倍以上。为了应对如此大规模查询的计算挑战，我们引入了一个新库：分层迭代地理空间层次化地形导向统一搜索引擎（Lighthouse）。Lighthouse既异常快速又资源高效，仅需1个CPU和2GB内存即可实现毫秒级在线推理，非常适合资源受限环境中的实时应用。

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [344] [A Digital Twin Framework for Generation-IV Reactors with Reinforcement Learning-Enabled Health-Aware Supervisory Control](https://arxiv.org/abs/2506.17258)
**中文标题：基于强化学习的第四代核反应堆健康感知监控数字孪生框架**

*Jasmin Y. Lim,Dimitrios Pylorof,Humberto E. Garcia,Karthik Duraisamy*

主要分类: eess.SY

摘要简述: 本文提出了一种基于强化学习的数字孪生框架，用于第四代核反应堆的健康感知监控控制，通过数据增强方法优化运行和维护策略，同时满足系统约束。


<details>
  <summary>详细信息</summary>
研究动机: 第四代（Gen-IV）核电站旨在替代现有反应堆，提升性能、安全性、可靠性和可持续性，但高昂成本阻碍了其部署。数字孪生技术通过连接现实系统与数字工具，可降低成本并提升效率。

研究方法: 框架结合了代理建模、强化学习和贝叶斯推断，通过强化学习考虑组件健康和退化，驱动目标发电量，并通过参考调节器控制算法确保泵流量和温度限制。在线模拟数据通过贝叶斯滤波与测量数据融合。

研究结果: 通过三个案例研究验证了框架的鲁棒性：长期运行维护规划、短期高频测量精度优化以及边界条件变化时的实时重新校准能力。

研究结论: 该数字孪生框架为健康感知和约束驱动的核电站运行提供了通用解决方案，适用于其他先进反应堆和复杂工程系统。

中文摘要: 第四代（Gen-IV）核电站旨在替代现有反应堆，提升性能、安全性、可靠性和可持续性，但高昂成本阻碍了其部署。数字孪生技术通过连接现实系统与数字工具，可降低成本并提升效率。本文设计了一个数字孪生框架，用于操作第四代氟盐冷却高温反应堆，利用数据增强方法优化运行和维护策略，同时满足系统约束。闭环框架整合了代理建模、强化学习和贝叶斯推断，以实现端到端通信的在线调节和自我调整。强化学习用于考虑组件健康和退化，驱动目标发电量，并通过参考调节器控制算法确保泵流量和温度限制。这些输入驱动模块受益于与测量数据融合的详细在线模拟。数字孪生通过三个案例研究验证：展示维护规划能力的长期运行、高频测量的短期精度优化，以及边界条件变化时实时重新校准能力的系统冲击捕捉。这些验证表明，该框架在健康感知和约束驱动的核电站运行中具有鲁棒性，并适用于其他先进反应堆和复杂工程系统。

</details>


### [345] [Conformal Safety Shielding for Imperfect-Perception Agents](https://arxiv.org/abs/2506.17275)
**中文标题：面向感知不完美代理的共形安全屏蔽方法**

*William Scarbro,Calum Imrie,Sinem Getir Yaman,Kavan Fatehi,Corina S. Pasareanu,Radu Calinescu,Ravi Mangal*

主要分类: eess.SY

摘要简述: 本文提出了一种基于共形预测的安全屏蔽方法，用于为感知不完美的自主代理提供运行时安全保证，通过限制代理的动作选择以确保局部安全性。


<details>
  <summary>详细信息</summary>
研究动机: 自主代理在感知不完美的情况下（如高维观测中的状态估计）可能产生错误，导致不安全行为。本文旨在设计一种运行时安全屏蔽机制，确保代理在感知错误时仍能安全运行。

研究方法: 利用共形预测为感知组件提供概率保证，确保预测的状态估计集以用户指定概率包含实际状态。屏蔽机制仅允许代理执行对所有估计状态均安全的动作，从而实现局部安全保证。此外，还证明了完美感知代理屏蔽机制的全局安全性。

研究结果: 提出的屏蔽方法能够有效限制代理的动作选择，确保在感知错误时仍能提供安全保证。通过实验验证，该方法成功应用于基于高维感知DNN的飞机滑行引导系统。

研究结论: 本文提出的共形安全屏蔽方法为感知不完美的自主代理提供了有效的运行时安全保证，并通过实验验证了其实际可行性。

中文摘要: 本文研究了使用学习组件从高维观测中进行不完美感知（或状态估计）的离散自主代理的安全控制问题。我们提出了一种屏蔽构造方法，通过限制代理（建模为马尔可夫决策过程）的动作选择，在感知错误时提供运行时安全保证。该方法利用共形预测为感知组件提供概率保证，确保每个观测的预测估计集以用户指定概率包含实际状态。屏蔽机制仅允许代理执行对所有估计状态均安全的动作，从而实现局部安全保证。我们还阐述并证明了完美感知代理屏蔽构造的全局安全性，即在代理始终选择屏蔽规定的动作时，到达不安全状态的概率有界。通过一个基于高维感知DNN的实验性飞机滑行引导系统案例，验证了所提方法的有效性。

</details>


### [346] [A Theoretical Framework for Virtual Power Plant Integration with Gigawatt-Scale AI Data Centers: Multi-Timescale Control and Stability Analysis](https://arxiv.org/abs/2506.17284)
**中文标题：吉瓦级AI数据中心与虚拟电厂集成的理论框架：多时间尺度控制与稳定性分析**

*Ali Peivandizadeh*

主要分类: eess.SY

摘要简述: 本文提出了一种针对吉瓦级AI数据中心与虚拟电厂（VPP）集成的理论框架，通过四层分层控制架构解决极端动态功率波动问题，并开发了适用于转换器主导系统的控制机制和稳定性标准。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能的爆炸性增长，吉瓦级数据中心的功率波动（如秒级超过500 MW、毫秒级达50-75%热设计功率）对电力系统运行提出了严峻挑战。传统VPP架构无法应对这种极端动态，因此需要新的理论框架。

研究方法: 提出了一种四层分层控制架构，涵盖100微秒至24小时的时间尺度，包括：（1）亚毫秒级控制层抑制功率振荡；（2）新的稳定性标准；（3）量化灵活性表征。

研究结果: 证明了传统VPP架构在吉瓦级脉冲负载（变化速率超过1,000 MW/s）下无法保持稳定，新框架将临界清除时间从150 ms降至83 ms，并通过负载可延迟性实现30%峰值削减，同时保持AI服务可用性高于99.95%。

研究结论: 该研究为2030年将占数据中心电力消耗50-70%的AI基础设施的稳定集成奠定了数学基础。

中文摘要: 人工智能的爆炸性增长催生了吉瓦级数据中心，其功率波动（秒级超过500 MW，毫秒级达50-75%热设计功率）对电力系统运行提出了根本性挑战。本文提出了一种全面的理论框架，通过四层分层控制架构（时间尺度从100微秒至24小时）重新定义虚拟电厂（VPP），以适应这些极端动态。

我们开发了专门针对转换器主导系统和兆瓦级脉冲负载的控制机制及稳定性标准，并证明传统VPP架构（设计用于聚合响应时间为秒至分钟的分布式资源）在吉瓦级AI数据中心动态（变化速率超过1,000 MW/s）下无法保持稳定。

新框架包括：（1）亚毫秒级控制层，与数据中心电力电子设备交互以主动抑制功率振荡；（2）结合保护系统动态的新稳定性标准，表明吉瓦级脉冲负载的临界清除时间从150 ms降至83 ms；（3）量化灵活性表征，显示负载可延迟性可实现30%峰值削减，同时保持AI服务可用性高于99.95%。

本研究为2030年将占数据中心电力消耗50-70%的AI基础设施的稳定集成奠定了数学基础。

</details>


### [347] [Frequency Control in Microgrids: An Adaptive Fuzzy-Neural-Network Virtual Synchronous Generator](https://arxiv.org/abs/2506.18611)
**中文标题：微电网频率控制：一种自适应模糊神经网络虚拟同步发电机方法**

*Waleed Breesam,Rezvan Alamian,Nima Tashakor,Brahim Elkhalil Youcefa,Stefan M. Goetz*

主要分类: eess.SY

摘要简述: 本文提出了一种基于模糊神经网络的虚拟同步发电机方法，动态调整微电网中的惯性、阻尼和下垂参数，显著降低了频率偏差至0.03 Hz以下，并缩短了稳定时间。


<details>
  <summary>详细信息</summary>
研究动机: 随着分布式可再生能源的普及，电力电子设备取代了同步发电机，导致微电网动态特性变化，系统惯性和阻尼降低。固定参数的虚拟同步发电机无法保证频率调节在可接受范围内，因此需要动态调整参数以实现稳定频率。

研究方法: 通过模糊神经网络控制器动态调整虚拟同步发电机的惯性、阻尼和下垂参数。该控制器在线训练，选择适当的虚拟参数值，并应用于典型交流微电网中，考虑可再生能源的渗透和影响。

研究结果: 在MATLAB/Simulink模型中验证，并通过基于嵌入式ARM系统的硬件在环实验实时验证。与传统方法和模糊逻辑控制器相比，所提方法将频率偏差显著降低至0.03 Hz以下，并缩短了稳定时间。

研究结论: 提出的模糊神经网络虚拟同步发电机方法能够有效解决微电网频率控制问题，动态调整参数显著提升了频率稳定性和恢复速度。

中文摘要: 近年来，分布式可再生能源的依赖度增加，电力电子设备取代了同步发电机，导致微电网动态特性变化，系统惯性和阻尼降低。虚拟同步发电机通过模拟同步发电机的动态行为来解决这一问题，但固定参数无法保证频率调节在可接受范围内。动态调整这些虚拟参数有望提供稳健的解决方案。本文提出了一种通过模糊神经网络控制器动态调整惯性、阻尼和下垂参数的方法。该控制器在线训练以选择适当的虚拟参数值，并应用于典型交流微电网中，考虑可再生能源的渗透和影响。我们在MATLAB/Simulink模型中研究了该系统，并通过基于嵌入式ARM系统（SAM3X8E，Cortex-M3）的硬件在环实验实时验证。与传统方法和模糊逻辑控制器相比，结果表明所提方法将频率偏差显著降低至0.03 Hz以下，并缩短了稳定/恢复时间。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [348] [Exploring Strategies for Personalized Radiation Therapy Part II Predicting Tumor Drift Patterns with Diffusion Models](https://arxiv.org/abs/2506.17491)
**中文标题：探索个性化放疗策略第二部分：利用扩散模型预测肿瘤漂移模式**

*Hao Peng,Steve Jiang,Robert Timmerman*

主要分类: physics.med-ph

摘要简述: 本文提出了一种基于去噪扩散隐式模型（DDIM）的新框架，用于预测脑癌放疗中肿瘤的动态演变，支持个性化超分割立体定向自适应放疗（PULSAR）的早期决策。


<details>
  <summary>详细信息</summary>
研究动机: 脑癌放疗的剂量和时间参数因患者而异，传统方法难以预测肿瘤的动态响应。PULSAR策略需要更精准的预测工具以避免过度或不足治疗。

研究方法: 采用去噪扩散隐式模型（DDIM），从治疗前后的影像数据中学习肿瘤演变的映射关系，开发了单步和迭代去噪策略并进行性能比较。

研究结果: 扩散模型能有效模拟患者特异性肿瘤演变，并定位与治疗响应相关的区域，为个性化放疗提供了新工具。

研究结论: 该框架为建模异质性治疗响应和早期自适应干预奠定了基础，推动了更个性化和生物学导向的放疗发展。

中文摘要: 放疗效果由剂量和时间两个关键参数决定，其最佳值因患者差异显著。在脑癌治疗中，分阶段立体定向放射外科比单次治疗更安全，但增加了预测治疗响应的难度。为此，我们采用个性化超分割立体定向自适应放疗（PULSAR），动态调整治疗方案以适应肿瘤的演变。然而，PULSAR等自适应方法的成功依赖于能指导早期决策的预测工具，以避免过度或不足治疗。当前放射组学和剂量组学模型对肿瘤响应的时空演变模式提供有限信息。为克服这些限制，我们提出了一种基于去噪扩散隐式模型（DDIM）的新框架，从治疗前后影像中学习数据驱动的映射关系。本研究开发了单步和迭代去噪策略并比较其性能。结果表明，扩散模型能有效模拟患者特异性肿瘤演变，并定位与治疗响应相关的区域。该策略为建模异质性治疗响应和实现早期自适应干预提供了有前景的基础，推动了更个性化和生物学导向的放疗发展。

</details>


### [349] [Exploring Strategies for Personalized Radiation Therapy Part I Unlocking Response-Related Tumor Subregions with Class Activation Mapping](https://arxiv.org/abs/2506.17536)
**中文标题：探索个性化放疗策略第一部分：利用类别激活映射解锁与反应相关的肿瘤亚区域**

*Hao Peng,Steve Jiang,Robert Timmerman*

主要分类: physics.med-ph

摘要简述: 本研究比较了三种预测放疗反应的方法，发现基于像素级CAM的卷积神经网络在分类准确性和空间细节上优于传统方法，为个性化放疗提供了新思路。


<details>
  <summary>详细信息</summary>
研究动机: 个性化精准放疗需要识别具有预后意义的空间特征，并基于个体反应调整治疗方案。本研究旨在探索更有效的预测方法。

研究方法: 研究分析了39名患者的69个脑转移瘤，使用标准放射组学、基于梯度的特征和卷积神经网络（结合CAM）预测肿瘤体积是否在三个月随访时缩小超过20%。

研究结果: 像素级CAM模型在分类准确性上优于放射组学和基于梯度的方法，并能识别病灶特异性区域，揭示可能的放疗抵抗区域。

研究结论: 像素级CAM为个性化放疗提供了更精细的空间特征，支持生物学验证，未来有望指导光子及粒子疗法的适应性策略。

中文摘要: 个性化精准放疗不仅需要简单分类，还需识别具有预后意义的空间特征，并根据个体反应调整治疗。本研究比较了三种预测治疗反应的方法：标准放射组学、基于梯度的特征以及结合类别激活映射（CAM）的卷积神经网络。我们分析了39名患者经伽玛刀放射外科治疗的69个脑转移瘤，使用集成自编码器分类模型预测肿瘤体积在三个月随访时是否缩小超过20%（作为二分类任务）。结果表明，这些方法在分层特征提取和分类判别能力上表现突出。其中，像素级CAM提供了最详细的空间信息，能够识别病灶特异性区域而非依赖固定模式，表现出强泛化能力。在无反应病灶中，激活区域可能指示放疗抵抗区域。像素级CAM在分类准确性上优于放射组学和基于梯度的方法，其精细空间特征还可与细胞水平数据对齐，支持生物学验证和深入理解异质性治疗反应。尽管需进一步验证，这些发现为光子及粒子疗法的个性化适应性策略提供了重要指导。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [350] [Can Generated Images Serve as a Viable Modality for Text-Centric Multimodal Learning?](https://arxiv.org/abs/2506.17623)
**中文标题：生成的图像能否作为文本中心多模态学习的可行模态？**

*Yuesheng Huang,Peng Zhang,Riliang Liu,Jiaqi Liang*

主要分类: cs.MM

摘要简述: 本文系统研究了文本生成图像（T2I）模型生成的图像是否可作为文本中心多模态学习的有效补充模态。通过文本分类任务的综合评估，发现合成图像在特定条件下能显著提升性能，但其效果高度依赖文本与图像的语义对齐、任务的视觉可解释性及T2I模型的生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本数据丰富，但多模态模型能力日益增强，两者之间存在显著的模态鸿沟。本研究旨在探索T2I模型生成的图像是否能填补这一鸿沟，为文本中心任务提供有价值的补充模态。

研究方法: 研究通过文本分类任务构建了一个综合评估框架，分析了T2I模型质量、提示工程策略和多模态融合架构等关键变量对性能的影响。

研究结果: 结果表明，合成图像能显著提升性能，但其效果高度依赖文本与图像的语义对齐、任务的视觉可解释性及T2I模型的生成质量。研究还建立了该范式的首个严格基准。

研究结论: 合成感知为传统单模态场景下的语言理解提供了可行路径，但其应用需谨慎考虑语义对齐和生成质量等条件。

中文摘要: 文本数据丰富与多模态模型能力增强之间存在显著的“模态鸿沟”。本研究系统探讨了文本生成图像（T2I）模型实时生成的图像是否能作为文本中心任务的有价值补充模态。通过文本分类任务的综合评估框架，分析了T2I模型质量、提示工程策略和多模态融合架构等关键变量的影响。研究发现，这种“合成感知”能显著提升性能，甚至能增强强大的大型语言模型基线。然而，该方法的有效性高度依赖文本与生成图像的语义对齐、任务的“视觉可解释性”及T2I模型的生成保真度。本研究为该范式建立了首个严格基准，清晰分析了其潜力与当前局限，并证明了其在传统单模态场景下丰富语言理解的可行性。

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [351] [Mapping the Evolution of Research Contributions using KnoVo](https://arxiv.org/abs/2506.17508)
**中文标题：利用KnoVo映射研究贡献的演变**

*Sajratul Y. Rubaiat,Syed N. Sakib,Hasan M. Jamil*

主要分类: cs.DL

摘要简述: 本文介绍了KnoVo（知识演化）框架，用于量化分析科学文献中研究新颖性的演变。通过动态提取比较维度并利用大型语言模型（LLMs），KnoVo能评估目标论文在特定方面的相对新颖性，并通过可视化工具帮助研究人员追踪知识演化。


<details>
  <summary>详细信息</summary>
研究动机: 传统引用分析主要衡量研究的影响力，而忽略了新颖性的动态演变。KnoVo旨在填补这一空白，通过多维度比较和量化分析，帮助研究人员评估原创性、发现研究空白并探索跨学科联系。

研究方法: KnoVo利用大型语言模型（LLMs）动态提取目标论文的比较维度（如方法、应用、数据集），并将其与相关文献进行对比。通过类似锦标赛选择的量化评分，生成反映相对新颖性的分数，并通过动态演化图和雷达图可视化结果。

研究结果: 通过对20篇跨学科论文的详细分析，KnoVo展示了其在评估新颖性、追踪知识演化和发现研究空白方面的能力。同时，测试了多种开源LLMs在框架中的性能表现。

研究结论: KnoVo为研究新颖性的量化分析提供了创新工具，不仅补充了传统引用分析的不足，还能帮助研究人员更全面地理解知识演化过程，促进跨学科研究的发展。

中文摘要: 本文介绍了KnoVo（知识演化），一种用于量化分析科学文献中研究新颖性演变的智能框架。与传统引用分析不同，KnoVo通过多层引用网络评估目标论文相对于先前和后续工作的新颖性。给定目标论文的摘要后，KnoVo利用大型语言模型（LLMs）动态提取比较维度（如方法、应用、数据集），并将目标论文与相关文献进行对比。这种受锦标赛选择启发的分析生成定量新颖性分数，反映目标论文在特定方面的相对改进、等效或劣势。通过聚合这些分数并可视化其演变（如动态演化图和雷达图），KnoVo不仅帮助研究人员评估原创性和发现类似工作，还能追踪特定研究维度的知识演化、揭示研究空白并探索跨学科联系。我们通过对20篇跨学科论文的详细分析展示了这些功能，并报告了KnoVo框架中多种开源LLMs的性能表现。

</details>


### [352] [Unfolding the Past: A Comprehensive Deep Learning Approach to Analyzing Incunabula Pages](https://arxiv.org/abs/2506.18069)
**中文标题：揭开历史：一种全面的深度学习方法分析早期印刷书籍页面**

*Klaudia Ropel,Krzysztof Kutt,Luiz do Valle Miranda,Grzegorz J. Nalepa*

主要分类: cs.DL

摘要简述: 本文提出了一种基于深度学习的自动化方法，用于分析早期印刷书籍（incunabula）页面的结构和内容，结合YOLO模型进行目标检测，Tesseract和Kraken进行OCR，以及ResNet18和CLIP模型进行图像分类和语义描述生成，取得了较高的性能。


<details>
  <summary>详细信息</summary>
研究动机: 早期印刷书籍（incunabula）的分析通常依赖人工，效率低下且成本高昂。本文旨在开发一种自动化的深度学习方法，以提高分析效率和准确性。

研究方法: 1. 创建了一个包含500页标注数据的自定义数据集，标注类别包括文本、标题、图片、表格和手写内容。2. 使用YOLO11n和YOLO11s模型进行目标检测，训练策略包括结合公开数据集DocLayNet和仅使用自定义数据集。3. 对文本区域使用Tesseract和Kraken进行OCR。4. 对图片类别使用ResNet18进行子类分类。5. 使用CLIP模型生成插图的语义描述。

研究结果: 1. YOLO11n模型在仅使用自定义数据集时表现最佳（F1=0.94）。2. Tesseract在OCR任务中优于Kraken。3. ResNet18在图片子类分类中达到98.7%的准确率。4. CLIP模型成功生成了插图的语义描述。

研究结论: 机器学习在早期印刷书籍分析中具有巨大潜力，但OCR性能和视觉内容理解仍需进一步改进。

中文摘要: 我们开发了一种概念验证方法，用于自动分析早期印刷书籍页面的结构和内容。通过使用雅盖隆数字图书馆的资源，创建了一个包含500页标注数据的自定义数据集，每页标注了五种预定义类别：文本、标题、图片、表格和手写内容。此外，还利用了公开的DocLayNet数据集作为补充训练数据。在目标检测任务中，采用了YOLO11n和YOLO11s模型，并通过两种策略进行训练：结合DocLayNet和自定义数据集，以及仅使用自定义数据集。YOLO11n模型在仅使用自定义数据时表现最佳（F1=0.94）。随后，对分类为文本的区域进行了光学字符识别（OCR），使用了Tesseract和Kraken，其中Tesseract表现更优。接着，对图片类别使用ResNet18模型进行了图像分类，在五个子类（装饰字母、插图、其他、印章和错误检测）中达到了98.7%的准确率。此外，还使用CLIP模型生成了插图的语义描述。结果表明，机器学习在早期印刷书籍分析中具有潜力，但OCR性能和视觉内容理解仍需进一步改进。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [353] [QUST_NLP at SemEval-2025 Task 7: A Three-Stage Retrieval Framework for Monolingual and Crosslingual Fact-Checked Claim Retrieval](https://arxiv.org/abs/2506.17272)
**中文标题：QUST_NLP在SemEval-2025任务7中的应用：一种用于单语和跨语言事实核查声明检索的三阶段检索框架**

*Youzheng Liu,Jiyan Liu,Xiaoman Xu,Taihang Wang,Yimin Wang,Ye Jiang*

主要分类: cs.IR

摘要简述: QUST_NLP团队在SemEval-2025任务7中提出了一个三阶段检索框架，用于单语和跨语言事实核查声明检索，最终在单语和跨语言赛道分别获得第5和第7名。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决事实核查声明检索中的性能问题，QUST_NLP团队设计了一个高效的三阶段框架，旨在提升检索结果的准确性和效率。

研究方法: 方法包括三个阶段：首先评估并选择最佳候选检索模型；其次使用多个重排序模型优化候选结果；最后通过加权投票确定最终检索结果。

研究结果: 该方法在SemEval-2025任务7的单语赛道中排名第5，跨语言赛道中排名第7，证明了其有效性。

研究结论: 三阶段检索框架在事实核查声明检索任务中表现优异，未来可进一步优化模型以提升性能。

中文摘要: 本文介绍了QUST_NLP团队在SemEval-2025任务7中的参与情况。我们提出了一种专门为事实核查声明检索设计的三阶段检索框架。首先，我们评估了多种检索模型的性能，并选择了表现最佳的模型用于候选检索。接着，我们使用多个重排序模型对候选结果进行优化，每个模型选择前10个结果。最后，我们通过加权投票确定最终的检索结果。我们的方法在单语赛道中排名第5，跨语言赛道中排名第7。系统代码已发布于：https://github.com/warmth27/SemEval2025_Task7

</details>


### [354] [Chunk Twice, Embed Once: A Systematic Study of Segmentation and Representation Trade-offs in Chemistry-Aware Retrieval-Augmented Generation](https://arxiv.org/abs/2506.17277)
**中文标题：分块两次，嵌入一次：化学感知检索增强生成中分割与表示权衡的系统研究**

*Mahmoud Amiri,Thomas Bocklitz*

主要分类: cs.IR

摘要简述: 本文首次系统评估了化学领域检索增强生成（RAG）系统中的文档分割和表示策略，发现递归基于标记的分块（R100-0）和检索优化嵌入模型（如Nomic和Intfloat E5）表现最佳，为构建高效化学RAG系统提供了实用指南。


<details>
  <summary>详细信息</summary>
研究动机: 随着科学文献的迅速增长，检索增强生成（RAG）系统在化学等高价值领域的重要性日益凸显。然而，领域特定的文档分割和表示策略尚未得到充分研究，因此本文旨在填补这一空白。

研究方法: 本研究评估了25种分块策略（涵盖五种方法家族）和48种嵌入模型在三个化学特定基准（包括新提出的QuestChemRetrieval数据集）上的表现。

研究结果: 结果显示，递归基于标记的分块（R100-0）性能最优且资源消耗低，而检索优化嵌入模型（如Nomic和Intfloat E5）显著优于领域专用模型（如SciBERT）。

研究结论: 通过发布数据集、评估框架和实证基准，本文为构建高效化学RAG系统提供了实用指南，并揭示了分块和嵌入模型的最佳实践。

中文摘要: 检索增强生成（RAG）系统在科学文献导航中日益重要，尤其是在化学等高价值领域。尽管RAG前景广阔，但其基础设计选择（如文档分割和表示方式）在领域特定背景下仍未充分探索。本研究首次对化学RAG系统的分块策略和嵌入模型进行了大规模系统评估。我们研究了五种方法家族下的25种分块配置，并评估了48种嵌入模型在三个化学特定基准（包括新提出的QuestChemRetrieval数据集）上的表现。结果表明，递归基于标记的分块（R100-0）性能最优且资源消耗低，而检索优化嵌入模型（如Nomic和Intfloat E5）显著优于领域专用模型（如SciBERT）。通过发布数据集、评估框架和实证基准，我们为构建高效化学RAG系统提供了实用指南。

</details>


### [355] [CORONA: A Coarse-to-Fine Framework for Graph-based Recommendation with Large Language Models](https://arxiv.org/abs/2506.17281)
**中文标题：CORONA：基于大语言模型的图推荐框架——从粗到细的检索链**

*Junze Chen,Xinjie Yang,Cheng Yang,Junfei Bao,Zeyuan Guo,Yawen Li,Chuan Shi*

主要分类: cs.IR

摘要简述: 本文提出了一种基于大语言模型（LLMs）和图神经网络的推荐框架CORONA，通过逐步缩小候选范围，结合LLMs的推理能力和GNN的高阶关系捕捉能力，显著提升了推荐性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有推荐系统虽然利用图神经网络（GNNs）捕捉高阶交互关系，但大语言模型（LLMs）的潜力未被充分挖掘，尤其是在候选过滤阶段。本文旨在通过LLMs的推理能力优化候选过滤过程，提升推荐效果。

研究方法: CORONA框架分为三步：(1) 基于用户画像的偏好推理，提取相关用户和物品；(2) 结合目标用户购买历史的意图推理，进一步缩小交互子图；(3) 使用GNN从子图中捕捉高阶协同过滤信息，生成最终推荐结果。

研究结果: 实验表明，CORONA在多个数据集和设置下均达到最优性能，召回率和NDCG分别平均提升18.6%和18.4%。

研究结论: CORONA通过结合LLMs的推理能力和GNN的高阶关系捕捉能力，显著提升了推荐系统的性能，为推荐领域提供了新的思路。

中文摘要: 推荐系统（RSs）旨在从大量候选中检索用户可能感兴趣的物品。常见方法是使用图神经网络（GNNs）捕捉高阶交互关系。随着大语言模型（LLMs）在各领域展现出强大能力，研究者开始探索其在推荐中的应用。然而，现有工作仅将LLMs用于重排序或数据增强，未充分利用其在候选过滤阶段的潜力，可能导致性能不佳。为此，我们提出在候选过滤过程中利用LLMs的推理能力，并引入基于图的检索链（CORONA），逐步缩小交互图中的候选范围：(1) 首先，LLM基于用户画像进行偏好推理，其响应作为查询从交互图中提取相关用户和物品；(2) 然后，结合目标用户购买历史，LLM进行意图推理，进一步细化交互子图；(3) 最后，使用GNN从子图中捕捉高阶协同过滤信息，生成最终推荐结果。CORONA在检索过程中充分利用LLMs的推理能力，同时无缝集成GNNs以提升整体性能。多数据集实验表明，CORONA实现了最优性能，召回率和NDCG分别平均提升18.6%和18.4%。

</details>


### [356] [SlimRAG: Retrieval without Graphs via Entity-Aware Context Selection](https://arxiv.org/abs/2506.17288)
**中文标题：SlimRAG：通过实体感知上下文选择实现无图检索**

*Jiale Zhang,Jiaxiang Chen,Zhucong Li,Jie Ding,Kui Zhao,Zenglin Xu,Xin Pang,Yinghui Xu*

主要分类: cs.IR

摘要简述: SlimRAG提出了一种轻量化的检索框架，通过实体感知的上下文选择机制取代传统基于图的RAG系统，显著提升了检索效率和准确性，同时减少了索引大小和计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 基于图的RAG系统存在结构复杂性和检索不精确的问题，例如需要昂贵的实体链接和关系提取流程，且常返回相关性低的子图。SlimRAG旨在通过无图设计解决这些问题。

研究方法: SlimRAG采用实体感知机制，在索引阶段构建紧凑的实体到文本块的映射表，查询阶段通过识别关键实体并检索相关文本块，避免了图遍历和边构建的复杂性。

研究结果: 实验表明，SlimRAG在多个问答基准测试中优于传统的基于图和扁平化检索方法，同时显著降低了索引大小和Relative Index Token Utilization（RITU）指标（如16.31 vs. 56+）。

研究结论: SlimRAG证明了无图设计的实体中心化上下文选择在检索效率和准确性上的优势，为轻量化RAG系统提供了新思路。

中文摘要: 检索增强生成（RAG）通过引入外部知识提升了语言模型的推理能力。然而，基于图的RAG系统通常面临结构复杂性和检索不精确的问题：它们需要昂贵的实体链接和关系提取流程，却常返回包含松散相关内容的子图。这源于一个根本缺陷——语义相似性并不等同于语义相关性。我们提出了SlimRAG，一种轻量化的无图检索框架。SlimRAG用简单高效的实体感知机制取代了结构复杂的组件。在索引阶段，它基于语义嵌入构建紧凑的实体到文本块映射表；在查询阶段，它识别关键实体，检索并评分相关文本块，最终生成简洁且上下文相关的输入——无需图遍历或边构建。为量化检索效率，我们提出了Relative Index Token Utilization（RITU），用于衡量检索内容的紧凑性。在多个问答基准测试中，SlimRAG在准确性上优于基于图和扁平化的基线方法，同时显著降低了索引大小和RITU（例如16.31 vs. 56+），凸显了无图设计、实体中心化上下文选择的价值。代码即将发布。https://github.com/continue-ai-company/SlimRAG

</details>


### [357] [Enhancing Document Retrieval in COVID-19 Research: Leveraging Large Language Models for Hidden Relation Extraction](https://arxiv.org/abs/2506.18311)
**中文标题：提升COVID-19研究中的文献检索：利用大语言模型提取隐藏关系**

*Hoang-An Trieu,Dinh-Truong Do,Chau Nguyen,Vu Tran,Minh Le Nguyen*

主要分类: cs.IR

摘要简述: 本文提出了一种利用大语言模型（LLMs）提取COVID-19文献中隐藏关系的方法，以提升检索系统Covrelex-SE的质量，帮助研究人员更高效地获取有用信息。


<details>
  <summary>详细信息</summary>
研究动机: COVID-19疫情期间，大量相关文献涌现，但现有检索系统难以高效提取未标注文献中的隐藏关系，导致检索结果质量不高。本文旨在通过LLMs提升检索系统的信息提取能力。

研究方法: 利用大语言模型（LLMs）提取未标注COVID-19文献中的隐藏关系，补充现有解析工具的不足，从而为检索系统Covrelex-SE提供更全面的信息支持。

研究结果: 通过LLMs提取的隐藏关系显著提升了检索系统的检索质量，使其能够提供更多高价值的信息。

研究结论: 本文证明了LLMs在提取隐藏关系方面的有效性，为未来突发公共卫生事件中的文献检索提供了新的技术支持。

中文摘要: 近年来，随着COVID-19大流行的出现，大量与该疾病相关的文献被发表。由于文献数量庞大，需要一个高效的检索系统，以便在类似COVID-19这样的突发疫情中为研究人员提供有用信息。本文提出了一种方法，帮助检索系统Covrelex-SE提供更高质量的搜索结果。我们利用大语言模型（LLMs）提取未标注文献中现有解析工具无法发现的隐藏关系，从而在检索过程中为系统提供更多有用信息。

</details>


### [358] [Team LA at SCIDOCA shared task 2025: Citation Discovery via relation-based zero-shot retrieval](https://arxiv.org/abs/2506.18316)
**中文标题：团队LA在SCIDOCA 2025共享任务中的表现：基于关系特征的零样本检索实现引文发现**

*Trieu An,Long Nguyen,Minh Le Nguyen*

主要分类: cs.IR

摘要简述: 团队LA在SCIDOCA 2025共享任务中提出了一种基于关系特征的零样本检索方法，用于从候选池中发现正确的引文。通过提取段落的关系特征并利用大语言模型（LLM）进行精准匹配，该方法在训练数据集上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 引文发现任务的主要挑战在于段落长度和候选摘要之间的高度相似性，导致难以准确确定引文。团队LA旨在开发一种高效的系统来解决这一问题。

研究方法: 首先基于段落提取的关系特征检索出前k个最相似的摘要，然后利用大语言模型（LLM）从子集中精准识别最相关的引文。

研究结果: 在SCIDOCA 2025提供的训练数据集上验证了该框架的有效性，展示了其在引文预测中的优异表现。

研究结论: 该方法通过结合关系特征检索和LLM的精准匹配，成功解决了引文发现任务中的挑战。

中文摘要: 引文发现共享任务的目标是从给定的候选池中预测出段落的正确引文。主要挑战在于摘要段落的长度和候选摘要之间的高度相似性，这使得确定具体引文变得困难。为此，我们开发了一种系统，首先基于段落提取的关系特征检索出前k个最相似的摘要，然后利用大语言模型（LLM）从子集中精准识别最相关的引文。我们在SCIDOCA 2025组织者提供的训练数据集上评估了该框架，证明了其在引文预测中的有效性。

</details>


### [359] [Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models](https://arxiv.org/abs/2506.17580)
**中文标题：基于大语言模型的关联开放数据上下文感知科学知识提取**

*Sajratul Y. Rubaiat,Hasan M. Jamil*

主要分类: cs.IR

摘要简述: 本文提出了一种名为WISE的系统，用于从科学文献中智能提取知识。通过树状架构和动态评分，WISE显著减少了处理文本量并提高了信息召回率，优于传统搜索引擎和其他基于大语言模型的方法。


<details>
  <summary>详细信息</summary>
研究动机: 科学文献的快速增长使研究者难以高效提取和整合知识。传统搜索引擎返回大量无关信息，而通用大语言模型（LLM）的回答缺乏深度或时效性。WISE旨在解决这些问题，提供更精准、深入的知识提取。

研究方法: WISE采用树状架构和大语言模型，通过结构化工作流程提取、精炼和排序查询相关知识。动态评分和自适应停止标准优化了处理效率，确保提取的信息与查询相关、上下文感知且无冗余。

研究结果: 实验表明，WISE在HBB基因相关疾病的研究中，处理文本量减少80%以上，召回率显著高于基线方法。ROUGE和BLEU指标显示其输出更具独特性，且能提供更深入的信息。

研究结论: WISE通过系统化的知识提取和整合，显著提升了科学文献分析的效率和质量。其方法可扩展至药物发现、材料科学和社会科学等领域，为知识管理提供了新工具。

中文摘要: 科学文献的指数级增长给研究者提取和整合知识带来了挑战。传统搜索引擎返回大量来源但缺乏直接、详细的答案，而通用大语言模型（LLM）的回答可能简洁但缺乏深度或遗漏最新信息。具备搜索能力的LLM也受限于上下文窗口，导致回答简短且不完整。本文介绍了WISE（智能科学知识提取工作流），该系统通过结构化工作流程提取、精炼和排序查询相关知识，解决了这些限制。WISE采用基于大语言模型的树状架构精炼数据，专注于与查询对齐、上下文感知且无冗余的信息。动态评分和排序优先考虑每个来源的独特贡献，自适应停止标准最小化处理开销。WISE通过系统化探索和整合多样化来源的知识，提供详细且组织化的答案。在HBB基因相关疾病的实验中，WISE减少了80%以上的处理文本量，同时召回率显著高于搜索引擎和其他基于LLM的方法。ROUGE和BLEU指标显示WISE的输出更具独特性，而一种新颖的层级指标表明其提供的信息更深入。我们还探讨了WISE工作流如何适应药物发现、材料科学和社会科学等多样化领域，从而高效地从非结构化科学论文和网络来源中提取和整合知识。

</details>


### [360] [Reinforcing User Interest Evolution in Multi-Scenario Learning for recommender systems](https://arxiv.org/abs/2506.17682)
**中文标题：多场景学习中强化用户兴趣演化的推荐系统研究**

*Zhijian Feng,Wenhao Zheng,Xuanji Xiao*

主要分类: cs.IR

摘要简述: 本文提出了一种基于强化学习的方法，通过建模用户兴趣在多场景中的演化，提升推荐系统的性能。实验表明，该方法在多场景推荐任务中优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 现实推荐系统中，用户在不同场景（如首页、搜索页等）的兴趣可能不一致，这增加了统一建模的难度。本文旨在解决多场景学习中用户兴趣演化的挑战。

研究方法: 采用强化学习方法，通过双Q学习建模用户兴趣在多场景中的演化，并利用Q值优化对比学习损失，提升模型性能。

研究结果: 实验结果表明，该方法在多场景推荐任务中优于现有技术，验证了其有效性。

研究结论: 本文为多场景建模提供了新视角，并指出了未来研究的潜在方向。

中文摘要: 在现实世界的推荐系统中，用户会参与多种场景，如首页、搜索页和相关推荐页。这些场景反映了用户关注的不同方面。然而，由于决策过程和偏好表达的差异，用户兴趣在不同场景中可能不一致，这增加了统一建模的复杂性，使多场景学习成为一项重要挑战。为解决这一问题，我们提出了一种新颖的强化学习方法，通过建模用户兴趣在多场景中的演化来建模用户偏好。我们的方法采用双Q学习来提高下一项预测的准确性，并利用Q值优化对比学习损失以提升模型性能。实验结果表明，我们的方法在多场景推荐任务中优于现有技术。我们的工作为多场景建模提供了新视角，并指出了未来研究的潜在方向。

</details>


### [361] [CARTS: Collaborative Agents for Recommendation Textual Summarization](https://arxiv.org/abs/2506.17765)
**中文标题：CARTS：协作智能体用于推荐文本摘要**

*Jiao Chen,Kehui Yao,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Jason Cho,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

主要分类: cs.IR

摘要简述: 本文提出CARTS框架，通过多智能体协作解决推荐系统中的文本摘要问题，显著提升标题相关性和用户参与度。


<details>
  <summary>详细信息</summary>
研究动机: 当前推荐系统的文本摘要任务（如生成简洁标题）需要高度相关性和严格的字数限制，现有大语言模型方法难以直接适用。

研究方法: CARTS采用多智能体框架，分为三个阶段：生成增强生成（GAG）、迭代精炼和仲裁，分别负责提取特征、优化标题和最终选择。

研究结果: 实验表明，CARTS在大规模电商数据和A/B测试中优于单次生成和思维链基线，标题相关性和用户参与度显著提升。

研究结论: CARTS通过多智能体协作有效解决了推荐系统中的文本摘要问题，为实际应用提供了高效解决方案。

中文摘要: 当前推荐系统常需文本摘要（如为产品轮播生成简洁标题），但现有大语言模型方法难以直接适用，因其需高度相关性和严格字数限制。本文提出CARTS（协作智能体用于推荐文本摘要），一种多智能体大语言模型框架，专为推荐系统的结构化摘要设计。CARTS将任务分解为三个阶段：生成增强生成（GAG）、精炼循环和仲裁，分别由不同智能体负责提取关键特征、基于相关性和长度反馈迭代优化候选标题，并通过协作仲裁选择最终标题。在大规模电商数据和实时A/B测试中，CARTS显著优于单次生成和思维链基线，标题相关性和用户参与度指标均有提升。

</details>


### [362] [Expanding Relevance Judgments for Medical Case-based Retrieval Task with Multimodal LLMs](https://arxiv.org/abs/2506.17782)
**中文标题：利用多模态大语言模型扩展医学案例检索任务的相关性标注**

*Catarina Pires,Sérgio Nunes,Luís Filipe Teixeira*

主要分类: cs.IR

摘要简述: 本文探讨了利用多模态大语言模型（MLLM）扩展医学案例检索任务的相关性标注，通过结构化提示策略生成自动化标注，显著提升了标注规模，并与人工标注达成较高一致性。


<details>
  <summary>详细信息</summary>
研究动机: 信息检索系统的评估依赖于高质量的人工相关性标注，但标注成本高且耗时长。多模态大语言模型为减少对人工标注的依赖提供了可能，尤其是在需要分析文本和视觉信息的医学案例检索领域。

研究方法: 采用Gemini 1.5 Pro多模态大语言模型，通过结构化提示策略（包括二元评分、指令评估和少样本学习）模拟人工标注，扩展ImageCLEFmed 2013任务的数据集。

研究结果: 模型与人工标注的Cohen's Kappa一致性得分为0.6，标注规模从15,028扩展到558,653，相关标注从4.72%增至5,950，每个查询平均新增15,398条标注。

研究结论: 多模态大语言模型能够显著扩展相关性标注规模，为医学和多模态信息检索任务的评估提供了新方向。

中文摘要: 评估信息检索系统依赖于高质量的人工相关性标注（qrels），但获取这些标注成本高且耗时长。尽管池化方法减少了标注工作量，但仅能生成部分标注的数据集。大型语言模型（LLMs）为减少对人工标注的依赖提供了可能，尤其是在需要分析文本和视觉信息的复杂领域（如医学案例检索）中。本研究探索了利用多模态大语言模型（MLLM）扩展相关性标注，生成自动化标注的新数据集。具体而言，我们在ImageCLEFmed 2013案例检索任务中采用Gemini 1.5 Pro，通过迭代优化的结构化提示策略（整合二元评分、指令评估和少样本学习）模拟人工评估。我们系统性地尝试了多种提示配置，以最大化与人工标注的一致性。为评估MLLM与人工标注的一致性，我们使用Cohen's Kappa，获得了0.6的显著一致性分数，与多模态检索任务中常见的标注者间一致性相当。原始数据集包含35个主题的15,028条人工标注（4.72%相关），通过MLLM方法将数据集扩展了37倍以上，达到558,653条标注，相关标注增至5,950条。平均每个医学案例查询新增15,398条标注，其中约99%为非相关标注，反映了该领域的高稀疏性。结果表明，MLLM能够显著扩展相关性标注规模，为医学和多模态信息检索任务的评估提供了新方向。

</details>


### [363] [A GenAI System for Improved FAIR Independent Biological Database Integration](https://arxiv.org/abs/2506.17934)
**中文标题：一种改进FAIR独立生物数据库整合的GenAI系统**

*Syed N. Sakib,Kallol Naha,Sajratul Y. Rubaiat,Hasan M. Jamil*

主要分类: cs.IR

摘要简述: 本文介绍了一种名为FAIRBridge的实验性自然语言查询处理系统，旨在帮助科学家发现、访问和查询生物数据库，即使这些数据库不符合FAIR原则。该系统利用AI技术解析查询意图，生成可执行查询，并提供高质量的信息处理工具。


<details>
  <summary>详细信息</summary>
研究动机: 生命科学研究需要从不断变化的Linked Open Data（LOD）网络中识别、访问和处理数据，但数据源的选择和语义整合过程往往繁琐且易出错。尽管FAIR原则试图解决这些问题，但高效准确的数据处理仍存在障碍。

研究方法: FAIRBridge通过AI技术解析自然语言查询意图，将其映射到科学文献中描述的数据库，并生成可执行查询。系统还提供工具以应对低质量查询处理，确保信息的高保真度和响应性。

研究结果: FAIRBridge的自主查询处理框架使用户能够探索替代数据源，并在每一步做出明智选择，同时支持社区驱动的众包管理。系统显著提升了科学数据的整合与处理效率。

研究结论: FAIRBridge通过自然语言平台为研究人员提供了一个强大的工具，显著改善了科学数据的整合与处理，推动了研究进展。

中文摘要: 生命科学研究日益需要从Linked Open Data（LOD）网络中识别、访问和处理不断变化的信息源数据。这种动态环境给研究人员带来了巨大负担，因为查询响应的质量高度依赖于数据源的选择和语义整合——这些过程通常繁琐、易出错且成本高昂。尽管FAIR（可查找、可访问、可互操作和可重用）数据原则试图解决这些问题，但高效准确的数据处理仍存在障碍。

本文介绍了FAIRBridge，一种实验性的基于自然语言的查询处理系统，旨在帮助科学家发现、访问和查询生物数据库，即使这些数据库不符合FAIR原则。FAIRBridge利用AI技术解析查询意图，将其映射到科学文献中描述的数据库，并通过智能资源访问计划生成可执行查询。系统还包含强大的工具，用于应对低质量查询处理，确保所提供信息的高保真度和响应性。

FAIRBridge的自主查询处理框架使用户能够探索替代数据源，在每一步做出明智选择，并在需要时利用社区驱动的众包管理。通过提供一个用户友好的自然英语自动化假设测试平台，FAIRBridge显著提升了科学数据的整合与处理效率，为研究人员提供了一种强大的新工具以推动其研究。

</details>


### [364] [LLM-Enhanced Multimodal Fusion for Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2506.17966)
**中文标题：基于大语言模型增强的多模态融合跨域序列推荐方法**

*Wangyu Wu,Zhenhong Chen,Xianglin Qiu,Siqi Song,Xiaowei Huang,Fei Ma,Jimin Xiao*

主要分类: cs.IR

摘要简述: 本文提出了一种基于大语言模型（LLM）增强的多模态融合方法（LLM-EMF），用于跨域序列推荐（CDSR），通过融合视觉和文本数据显著提升了推荐性能。


<details>
  <summary>详细信息</summary>
研究动机: 跨域序列推荐（CDSR）旨在通过利用用户在多领域的交互历史来预测行为，但现有方法在建模跨域偏好和捕捉复杂用户兴趣方面存在不足。本文希望通过结合大语言模型和多模态数据，提升推荐系统的表现。

研究方法: 提出LLM-EMF方法，利用冻结的CLIP模型生成图像和文本嵌入，丰富项目表示；通过多重注意力机制联合学习单域和跨域偏好，以捕捉复杂用户兴趣。

研究结果: 在四个电商数据集上的实验表明，LLM-EMF在建模跨域用户偏好方面优于现有方法，验证了多模态数据融合的有效性。

研究结论: LLM-EMF通过融合多模态数据和大语言模型知识，显著提升了跨域序列推荐的性能，为推荐系统提供了新的优化方向。

中文摘要: 跨域序列推荐（CDSR）通过利用用户在多领域的历史交互行为预测其行为，重点关注跨域偏好的建模以及序列内和序列间项目关系的捕捉。我们提出了一种新颖且先进的方法——基于大语言模型增强的多模态融合跨域序列推荐（LLM-EMF），该方法通过大语言模型（LLM）知识增强文本信息，并通过融合视觉和文本数据显著提升推荐性能。利用冻结的CLIP模型，我们生成了图像和文本嵌入，从而丰富了项目的多模态表示。通过多重注意力机制联合学习单域和跨域偏好，有效捕捉和理解用户在不同领域的复杂兴趣。在四个电商数据集上的评估表明，LLM-EMF在建模跨域用户偏好方面持续优于现有方法，凸显了多模态数据融合的有效性及其在增强序列推荐系统中的优势。我们的源代码将公开发布。

</details>


### [365] [LettinGo: Explore User Profile Generation for Recommendation System](https://arxiv.org/abs/2506.18309)
**中文标题：LettinGo：探索推荐系统中的用户画像生成**

*Lu Wang,Di Zhang,Fangkai Yang,Pu Zhao,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qingwei Lin,Weiwei Deng,Dongmei Zhang,Feng Sun,Qi Zhang*

主要分类: cs.IR

摘要简述: 本文提出LettinGo框架，利用大语言模型（LLM）生成多样化和自适应的用户画像，通过直接偏好优化（DPO）提升推荐系统的准确性和灵活性。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于嵌入的用户画像缺乏可解释性和适应性，而现有文本画像方法受限于固定格式，无法充分捕捉用户行为的多样性。因此，需要一种更灵活且高效的画像生成方法。

研究方法: LettinGo框架分为三个阶段：1）通过多个LLM探索多样化的用户画像；2）基于推荐系统中的表现评估画像质量；3）利用任务性能生成的成对偏好数据对齐画像生成。

研究结果: 实验结果表明，LettinGo显著提升了推荐系统的准确性、灵活性和上下文感知能力。

研究结论: LettinGo通过结合LLM的表达能力和任务驱动的优化方法，为下一代推荐系统提供了一种创新的用户画像生成方案。

中文摘要: 用户画像在推荐系统中至关重要，它将原始用户交互数据转化为简洁且结构化的表示，从而驱动个性化推荐。传统的基于嵌入的画像缺乏可解释性和适应性，而近期大语言模型（LLM）的进展使得基于文本的画像更具语义丰富性和透明度。然而，现有方法通常采用固定格式，限制了其捕捉用户行为多样性的能力。本文提出LettinGo，一种生成多样化和自适应用户画像的新框架。通过利用LLM的表达能力并结合下游推荐任务的直接反馈，我们的方法避免了监督微调（SFT）的刚性约束。相反，我们采用直接偏好优化（DPO）将画像生成器与任务性能对齐，确保画像的适应性和有效性。LettinGo分为三个阶段：1）通过多个LLM探索多样化用户画像；2）基于推荐系统中的表现评估画像质量；3）利用任务性能生成的成对偏好数据对齐画像生成。实验结果表明，我们的框架显著提升了推荐准确性、灵活性和上下文感知能力。这项工作将画像生成作为下一代推荐系统的关键创新。

</details>


### [366] [Bias vs Bias -- Dawn of Justice: A Fair Fight in Recommendation Systems](https://arxiv.org/abs/2506.18327)
**中文标题：偏见对偏见——正义的曙光：推荐系统中的公平对抗**

*Tahsin Alamgir Kheya,Mohamed Reda Bouadjenek,Sunil Aryal*

主要分类: cs.IR

摘要简述: 本文提出了一种公平感知的重新排序方法，旨在解决推荐系统中不同类别项目的偏见问题，并通过实验验证了其在减少性别、年龄和职业等多重敏感属性偏见上的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 推荐系统在电子商务、招聘广告和娱乐等领域对用户体验至关重要，但现有研究未能全面解决不同类别项目的偏见问题，且多数公平重新排序方法仅关注二元敏感属性。本文旨在填补这一空白。

研究方法: 提出了一种公平感知的重新排序方法，利用现有偏见纠正不同人口群体间的推荐差异，并在三个真实数据集上验证其效果。

研究结果: 实验结果表明，该方法能有效减少性别、年龄和职业等多重敏感属性的偏见，且对推荐性能影响极小。

研究结论: 本文提出的公平重新排序方法为推荐系统中的偏见问题提供了有效解决方案，同时保持了推荐性能。

中文摘要: 推荐系统通过影响电子商务、招聘广告和娱乐等领域的用户体验，在我们的日常生活中发挥着关键作用。鉴于此类系统的重要性，从业者必须确保其不会产生不公平和不平衡的推荐。以往关于推荐偏见的研究忽略了某些项目类别的偏见，可能导致部分偏见未被解决。此外，大多数关于公平重新排序的研究仅关注二元敏感属性。本文通过提出一种公平感知的重新排序方法来解决这些问题，该方法有助于缓解不同类别项目的偏见。这种重新排序方法利用现有偏见来纠正不同人口群体间的推荐差异。我们展示了该方法如何在性别、年龄和职业等多重敏感属性上减少偏见。我们在三个真实数据集上进行了实验，以评估重新排序方案在减少推荐偏见方面的有效性。结果表明，该方法有助于减少社会偏见，同时对性能的影响微乎其微。

</details>


### [367] [PERSCEN: Learning Personalized Interaction Pattern and Scenario Preference for Multi-Scenario Matching](https://arxiv.org/abs/2506.18382)
**中文标题：PERSCEN：学习个性化交互模式和场景偏好以实现多场景匹配**

*Haotong Du,Yaqing Wang,Fei Xiong,Lei Shao,Ming Liu,Hao Gu,Quanming Yao,Zhen Wang*

主要分类: cs.IR

摘要简述: PERSCEN是一种创新的多场景匹配方法，通过用户特定建模和图神经网络捕捉跨场景共享偏好，结合向量量化技术提取场景感知偏好，显著提升推荐效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有多场景推荐方法忽略用户特定建模，限制了生成个性化用户表示。PERSCEN旨在通过用户特定建模和场景感知偏好提取，提升多场景匹配的个性化效果。

研究方法: PERSCEN构建用户特定特征图，利用轻量图神经网络捕捉高阶交互模式，提取跨场景共享偏好；结合向量量化技术从用户行为序列中提取场景感知偏好；引入渐进式场景感知门控线性单元实现细粒度低延迟信息融合。

研究结果: 实验表明PERSCEN优于现有方法，且在性能和计算成本间取得平衡，适用于实际工业系统。

研究结论: PERSCEN通过用户特定建模和场景感知偏好提取，显著提升了多场景推荐的个性化效果和实用性。

中文摘要: 随着在线平台业务规模和范围的扩大，多场景匹配成为降低维护成本和缓解数据稀疏性的主流解决方案。有效的多场景推荐关键在于捕捉用户在所有场景中共享的偏好和每个场景特有的场景感知偏好。然而，现有方法往往忽略用户特定建模，限制了生成个性化用户表示的能力。为此，我们提出PERSCEN，一种创新的方法，将用户特定建模融入多场景匹配。PERSCEN基于用户特征构建用户特定特征图，并采用轻量图神经网络捕捉高阶交互模式，实现跨场景共享偏好的个性化提取。此外，我们利用向量量化技术从用户在各场景中的行为序列中提取场景感知偏好，支持用户特定和场景感知偏好的建模。为提升信息传递的效率和灵活性，我们引入渐进式场景感知门控线性单元，实现细粒度、低延迟的融合。大量实验表明PERSCEN优于现有方法。进一步的效率分析证实PERSCEN在性能和计算成本间取得了有效平衡，确保了其在实际工业系统中的实用性。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [368] [Heterogeneous Temporal Hypergraph Neural Network](https://arxiv.org/abs/2506.17312)
**中文标题：异构时序超图神经网络**

*Huan Liu,Pengfei Jiao,Mengzhou Gao,Chaochao Chen,Di Jin*

主要分类: cs.SI

摘要简述: 本文提出了一种异构时序超图神经网络（HTHGN），用于捕捉复杂异构时序图中的高阶交互关系，通过分层注意力机制和对比学习提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有图表示学习方法主要关注低阶拓扑信息，忽略了高阶群体交互关系，且现有超图方法仅适用于静态同构图。本文旨在解决这些问题，提出一种能同时建模异构时序图中高阶交互关系的方法。

研究方法: 首先定义了异构时序超图的形式化表示及不依赖额外信息的$P$-均匀超边构建算法；随后提出HTHGN模型，通过分层注意力机制模块实现异构节点与超边间的时序消息传递，并利用对比学习避免低阶结构模糊问题。

研究结果: 在三个真实世界异构时序图数据集上的实验表明，HTHGN能有效建模高阶交互关系，并显著提升了性能。

研究结论: HTHGN为异构时序图中的高阶交互建模提供了一种有效解决方案，实验验证了其优越性。

中文摘要: 图表示学习（GRL）已成为建模图结构数据的有效技术。在建模真实世界复杂网络中的异构性和动态性时，针对复杂异构时序图（HTG）的GRL方法已被提出并在多个领域成功应用。然而，现有GRL方法主要关注保留低阶拓扑信息，而忽略了更符合真实网络的高阶群体交互关系。此外，现有超图方法仅能建模静态同构图，限制了其在HTG中建模高阶交互的能力。因此，为使GRL模型同时捕捉HTG中的高阶交互关系，本文首先提出了异构时序超图的形式化定义及不依赖额外信息的$P$-均匀异构超边构建算法。随后，提出了一种新型异构时序超图神经网络（HTHGN），以全面捕捉HTG中的高阶交互。HTHGN包含一个分层注意力机制模块，可同时实现异构节点与超边间的时序消息传递，以捕捉超边带来的更广感受野中的丰富语义。此外，HTHGN通过最大化HTG上低阶相关异构节点对的一致性进行对比学习，以避免低阶结构模糊问题。在三个真实世界HTG数据集上的详细实验结果验证了HTHGN在建模高阶交互方面的有效性，并展示了显著的性能提升。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [369] [RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation](https://arxiv.org/abs/2506.18088)
**中文标题：RoboTwin 2.0：一种具有强领域随机化的可扩展数据生成器与双机械臂鲁棒操作基准**

*Tianxing Chen,Zanxin Chen,Baijun Chen,Zijian Cai,Yibin Liu,Qiwei Liang,Zixuan Li,Xianliang Lin,Yiheng Ge,Zhenyu Gu,Weiliang Deng,Yubin Guo,Tian Nian,Xuanbing Xie,Qiangyu Chen,Kailun Su,Tianling Xu,Guodong Liu,Mengkang Hu,Huan-ang Gao,Kaixuan Wang,Zhixuan Liang,Yusen Qin,Xiaokang Yang,Ping Luo,Yao Mu*

主要分类: cs.RO

摘要简述: RoboTwin 2.0是一个可扩展的仿真框架，用于生成多样化和真实的双机械臂操作数据，并通过结构化领域随机化提升策略鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有合成数据在双机械臂操作中表现不足，主要问题包括缺乏高效的数据生成方法和过于简化的仿真环境。

研究方法: 构建RoboTwin-OD对象库，结合多模态大语言模型和仿真循环优化自动生成任务代码，并通过五轴领域随机化增强数据多样性。

研究结果: 实验显示代码生成成功率提升10.9%，在未见过的真实场景中泛化能力显著提升，VLA模型相对改进367%。

研究结论: RoboTwin 2.0为双机械臂操作提供了高效的数据生成和评估工具，显著提升了仿真到现实的迁移能力。

中文摘要: 基于仿真的数据合成已成为增强现实世界机器人操作的有力范式。然而，现有合成数据集在双机械臂操作中仍显不足，原因有二：(1) 缺乏针对新任务的高效、可扩展数据生成方法；(2) 仿真环境过于简化，未能捕捉现实世界的复杂性。我们提出RoboTwin 2.0，一个可扩展的仿真框架，支持自动生成多样化且真实的数据，并提供统一的评估协议。我们首先构建RoboTwin-OD，一个包含147个类别、731个实例的大规模对象库，每个实例均标注了语义和操作相关标签。在此基础上，开发了结合多模态大语言模型（MLLMs）和仿真循环优化的专家数据合成流程，自动生成任务级执行代码。为提升仿真到现实的迁移能力，RoboTwin 2.0引入了五轴结构化领域随机化（杂乱度、光照、背景、桌面高度和语言指令），从而增强数据多样性和策略鲁棒性。我们在五种机器人实体上实例化了50个双机械臂任务，并预收集了超过100,000条领域随机化的专家轨迹。实验结果表明，代码生成成功率提升10.9%，并在新现实场景中表现出更强的泛化能力。基于我们数据集微调的VLA模型在未见过的真实任务中相对改进367%（42.0% vs. 9.0%），而仅使用合成数据训练的零样本模型相对提升228%，显示出无需真实监督的强泛化能力。我们发布了数据生成器、基准、数据集和代码，以支持双机械臂鲁棒操作的可扩展研究。

</details>


### [370] [General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting](https://arxiv.org/abs/2506.17462)
**中文标题：基于LVLM协调感知、推理与行动的通用机器人导航**

*Bernard Lange,Anil Yildiz,Mansur Arief,Shehryar Khattak,Mykel Kochenderfer,Georgios Georgakis*

主要分类: cs.RO

摘要简述: 本文提出了一种基于大型视觉语言模型（LVLM）的通用机器人导航框架ARNA，通过动态调用感知、推理和导航工具，实现未知环境中的自主导航和推理，并在HM-EQA基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有机器人导航系统通常依赖任务特定的神经网络和固定数据流，泛化能力有限。大型视觉语言模型（LVLM）具备类人知识，适用于推理和规划，但现有LVLM与机器人集成多依赖预建地图和硬编码表示。本文旨在开发一种通用导航框架，克服这些限制。

研究方法: 提出了Agentic Robotic Navigation Architecture（ARNA），一个基于LVLM的通用导航框架。ARNA动态调用现代机器人技术栈中的感知、推理和导航工具，在运行时自主定义任务特定工作流，迭代查询机器人模块、处理多模态输入并选择导航动作。

研究结果: 在Habitat Lab的HM-EQA基准测试中，ARNA实现了最先进的性能，能够在未映射环境中有效探索、导航和回答具身问题，且无需依赖手工计划、固定输入表示或预建地图。

研究结论: ARNA为机器人技术栈设计提供了新视角，展示了LVLM在通用导航中的潜力，能够在不依赖预定义流程的情况下实现鲁棒的导航和推理。

中文摘要: 开发适用于未知环境的通用导航策略仍是机器人技术的核心挑战。现有系统多依赖任务特定的神经网络和固定数据流，泛化能力有限。大型视觉语言模型（LVLM）通过嵌入类人知识，为推理和规划提供了新途径。然而，现有的LVLM-机器人集成通常依赖预建地图、硬编码表示和短视探索。本文提出了Agentic Robotic Navigation Architecture（ARNA），一种通用导航框架，为基于LVLM的智能体配备了现代机器人技术栈中的感知、推理和导航工具库。在运行时，智能体自主定义并执行任务特定的工作流，迭代查询机器人模块、推理多模态输入并选择适当的导航动作。这种方法能够在未映射环境中实现鲁棒的导航和推理，为机器人技术栈设计提供了新视角。在Habitat Lab的HM-EQA基准测试中，ARNA表现优异，实现了最先进的性能，展示了无需手工计划、固定输入表示或预建地图的有效探索、导航和具身问题回答能力。

</details>


### [371] [Distilling On-device Language Models for Robot Planning with Minimal Human Intervention](https://arxiv.org/abs/2506.17486)
**中文标题：通过最小化人工干预在设备端蒸馏语言模型用于机器人规划**

*Zachary Ravichandran,Ignacio Hounie,Fernando Cladera,Alejandro Ribeiro,George J. Pappas,Vijay Kumar*

主要分类: cs.RO

摘要简述: 本文提出PRISM框架，通过自动合成任务和环境数据，将大型语言模型（LLM）蒸馏为小型语言模型（SLM），实现设备端运行的机器人规划，性能接近GPT-4o的93%，且无需人工监督。


<details>
  <summary>详细信息</summary>
研究动机: 当前依赖云端大型语言模型（LLM）的机器人规划在通信不可靠的环境（如户外或工业场景）中受限。研究旨在开发一种设备端运行的小型语言模型（SLM），减少对云端的依赖，并提升机器人的自主性。

研究方法: PRISM框架从现有LLM规划器出发，自动生成多样化任务和环境数据，利用LLM生成规划方案，并通过合成数据蒸馏出紧凑的SLM，作为LLM的直接替代。

研究结果: PRISM将Llama-3.2-3B的性能从GPT-4o的10-20%提升至93%以上，且蒸馏后的规划器能泛化到不同机器人平台（地面和空中）及多样化环境（室内和户外）。

研究结论: PRISM通过合成数据蒸馏SLM，显著提升了设备端机器人规划的性能和泛化能力，为通信受限环境中的机器人应用提供了可行解决方案。

中文摘要: 大型语言模型（LLM）为机器人提供了强大的上下文推理能力和自然的人机交互界面。然而，目前依赖云端LLM的机器人在通信不可靠的环境（如户外或工业场景）中实用性受限。我们提出了PRISM框架，通过最小化人工监督，蒸馏出可在设备端运行的小型语言模型（SLM）规划器。PRISM从现有LLM规划器出发，自动合成多样化任务和环境数据，利用LLM生成规划方案，并通过合成数据蒸馏出紧凑的SLM作为直接替代。我们将PRISM应用于三种LLM规划器（用于地图探索、操作和家庭辅助），结果显示PRISM将Llama-3.2-3B的性能从GPT-4o的10-20%提升至93%以上，且仅使用合成数据。此外，蒸馏后的规划器能泛化到不同机器人平台（地面和空中）及多样化环境（室内和户外）。所有软件、训练模型和数据集已发布于https://zacravichandran.github.io/PRISM。

</details>


### [372] [Risk-Guided Diffusion: Toward Deploying Robot Foundation Models in Space, Where Failure Is Not An Option](https://arxiv.org/abs/2506.17601)
**中文标题：风险引导扩散：在太空部署机器人基础模型，失败不是选项**

*Rohan Thakker,Adarsh Patnaik,Vince Kurtz,Jonas Frey,Jonathan Becktor,Sangwoo Moon,Rob Royce,Marcel Kaufmann,Georgios Georgakis,Pascal Roth,Joel Burdick,Marco Hutter,Shehryar Khattak*

主要分类: cs.RO

摘要简述: 本文提出了一种风险引导扩散框架，结合快速学习的‘系统1’与基于物理的慢速‘系统2’，在极端地形中实现安全可靠的机器人导航，实验表明其故障率降低至4倍。


<details>
  <summary>详细信息</summary>
研究动机: 未来的太空探索任务需要机器人在极端陌生地形中实现安全可靠的导航。尽管现有生成式AI方法能从跨本体数据集中学习语义感知导航策略，但其安全性保障有限。受人类认知科学启发，本文旨在设计一种兼具适应性和形式化安全性的导航框架。

研究方法: 提出风险引导扩散框架，融合快速学习的‘系统1’（基于生成式AI）与慢速物理模拟的‘系统2’，在训练和推理阶段共享计算资源，确保安全性与适应性。

研究结果: 在NASA JPL的Mars Yard火星模拟设施中进行的硬件实验表明，该方法将故障率降低至4倍，同时保持与学习型机器人模型相同的目标达成性能，且无需额外训练。

研究结论: 风险引导扩散框架通过结合生成式AI与物理模拟，显著提升了机器人在极端环境中的导航安全性，为未来太空探索任务提供了可靠解决方案。

中文摘要: 未来的机器人太空探索任务需要在极端陌生地形中实现安全可靠的导航。尽管最近的生成式AI方法能够从大型跨本体数据集中学习语义感知导航策略，但其安全性保障有限。受人类认知科学启发，我们提出了一种风险引导扩散框架，将快速学习的‘系统1’与慢速基于物理的‘系统2’融合，通过在训练和推理阶段共享计算资源，实现适应性与形式化安全的结合。在NASA JPL的火星模拟设施Mars Yard中进行的硬件实验表明，我们的方法将故障率降低至4倍，同时通过利用推理计算资源（无需额外训练）匹配学习型机器人模型的目标达成性能。

</details>


### [373] [RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models](https://arxiv.org/abs/2506.17639)
**中文标题：RLRC：基于强化学习的视觉-语言-动作模型压缩恢复方法**

*Yuxuan Chen,Xiao Li*

主要分类: cs.RO

摘要简述: 本文提出了一种基于强化学习的恢复方法RLRC，用于压缩视觉-语言-动作模型（VLA），显著减少内存占用并提升推理速度，同时保持任务成功率。


<details>
  <summary>详细信息</summary>
研究动机: 视觉-语言-动作模型（VLA）在复杂机器人任务中表现优异，但其庞大的参数和高延迟限制了在资源受限设备上的部署。本文旨在通过压缩技术解决这一问题。

研究方法: RLRC采用三阶段恢复方法：结构化剪枝、基于监督微调（SFT）和强化学习（RL）的性能恢复，以及进一步量化。

研究结果: RLRC实现了内存占用减少8倍，推理吞吐量提升2.3倍，同时任务成功率保持甚至超过原始模型。实验表明其优于现有压缩基线。

研究结论: RLRC展示了在设备端部署VLA的潜力，为资源受限平台提供了高效的解决方案。

中文摘要: 视觉-语言-动作模型（VLA）在解决复杂机器人操作任务中表现出卓越能力和潜力。然而，其庞大的参数规模和高推理延迟为实际部署带来了挑战，尤其是在资源受限的机器人平台上。为解决这一问题，我们首先通过实证研究探索了模型压缩技术在VLA上的有效性。基于初步实验的洞察，我们提出了RLRC，一种针对压缩VLA的三阶段恢复方法，包括结构化剪枝、基于监督微调（SFT）和强化学习（RL）的性能恢复，以及进一步量化。RLRC实现了内存占用减少8倍，推理吞吐量提升2.3倍，同时保持甚至超过原始VLA的任务成功率。大量实验表明，RLRC始终优于现有压缩基线，展示了在设备端部署VLA的强大潜力。项目网站：https://rlrc-vla.github.io

</details>


### [374] [RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models](https://arxiv.org/abs/2506.17811)
**中文标题：RoboMonkey：视觉-语言-动作模型的测试时采样与验证扩展**

*Jacky Kwok,Christopher Agia,Rohan Sinha,Matt Foutter,Shulu Li,Ion Stoica,Azalia Mirhoseini,Marco Pavone*

主要分类: cs.RO

摘要简述: 本文提出RoboMonkey框架，通过测试时采样和验证提升视觉-语言-动作（VLA）模型的鲁棒性和泛化能力，显著提升任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉-语言-动作（VLA）模型在视觉运动控制中表现优异，但在非结构化真实环境中的鲁棒性仍面临挑战。本文旨在通过测试时采样和验证增强VLA的鲁棒性和泛化能力。

研究方法: 提出RoboMonkey框架，通过采样少量动作、高斯扰动和多数投票构建动作分布，并利用基于视觉语言模型（VLM）的验证器选择最优动作。同时设计了合成数据生成流程训练VLM验证器。

研究结果: 实验表明，RoboMonkey显著提升VLA性能，在分布外任务中绝对提升25%，分布内任务提升8%。适应新机器人设置时，联合微调VLA和验证器比单独微调VLA性能提升7%。

研究结论: RoboMonkey通过测试时采样和验证有效提升VLA的鲁棒性和泛化能力，为实际部署提供了可靠解决方案。

中文摘要: 视觉-语言-动作（VLA）模型在视觉运动控制中展现出卓越能力，但确保其在非结构化真实环境中的鲁棒性仍是一个持续挑战。本文从采样和验证的角度研究测试时扩展，以增强VLA的鲁棒性和泛化能力。我们首先证明，动作误差与生成样本数量之间的关系遵循指数幂律，表明存在推理时扩展规律。基于此，我们提出RoboMonkey，一个用于VLA的测试时扩展框架。在部署时，RoboMonkey从VLA中采样少量动作，应用高斯扰动和多数投票构建动作提议分布，然后使用基于视觉语言模型（VLM）的验证器选择最优动作。我们提出了一种合成数据生成流程，用于训练此类VLM动作验证器，并证明扩展合成数据集能持续提升验证和下游任务准确性。通过大量仿真和硬件实验，我们发现将现有VLA与RoboMonkey结合可显著提升性能，在分布外任务中实现25%的绝对提升，分布内任务提升8%。此外，在适应新机器人设置时，联合微调VLA和动作验证器比单独微调VLA性能提升7%。

</details>


### [375] [Learning to Dock: A Simulation-based Study on Closing the Sim2Real Gap in Autonomous Underwater Docking](https://arxiv.org/abs/2506.17823)
**中文标题：学习对接：基于模拟的研究缩小自主水下对接中的仿真与现实差距**

*Kevin Chang,Rakesh Vivekanandan,Noah Pragin,Sean Bullock,Geoffrey Hollinger*

主要分类: cs.RO

摘要简述: 本文通过模拟研究探讨如何缩小自主水下对接中的仿真与现实差距，重点关注不同负载条件下的对接挑战，并提出改进鲁棒性的方法。


<details>
  <summary>详细信息</summary>
研究动机: 自主水下车辆（AUV）在动态和不确定环境中的对接是水下机器人技术的关键挑战。强化学习是开发鲁棒控制器的有效方法，但仿真与现实的差距（sim2real gap）常导致性能显著下降。本文旨在通过模拟研究减少这一差距，尤其是在不同负载条件下的对接问题。

研究方法: 研究通过训练多种控制器并在真实扰动下评估其性能，探讨了随机化技术和历史条件控制器等现有方法对提升鲁棒性的效果。

研究结果: 研究发现，这些方法能够有效缩小仿真与现实的差距，尤其是在负载条件超出原始训练分布的情况下。

研究结论: 本文为训练对接控制器时缩小sim2real差距提供了见解，并指出了未来对海洋机器人社区有益的研究方向。

中文摘要: 自主水下车辆（AUV）在动态和不确定环境中的对接是水下机器人技术的关键挑战。强化学习是开发鲁棒控制器的有效方法，但仿真与现实的差距（sim2real gap）常导致性能显著下降。本文通过模拟研究探讨如何缩小这一差距，尤其是在不同负载条件下的对接问题。我们训练了多种控制器，并在真实扰动下评估其性能，重点关注负载条件超出原始训练分布的情况。我们探索了包括随机化技术和历史条件控制器在内的现有方法对提升鲁棒性的效果。研究结果为训练对接控制器时缩小sim2real差距提供了见解，并指出了未来对海洋机器人社区有益的研究方向。

</details>


### [376] [Generative Grasp Detection and Estimation with Concept Learning-based Safety Criteria](https://arxiv.org/abs/2506.17842)
**中文标题：基于概念学习的安全标准生成抓取检测与估计**

*Al-Harith Farhad,Khalil Abuibaid,Christiane Plociennik,Achim Wagner,Martin Ruskowski*

主要分类: cs.RO

摘要简述: 本文提出了一种基于概念学习的协作机器人抓取算法，通过可解释AI方法提高透明度和可靠性，确保工具的安全操作。


<details>
  <summary>详细信息</summary>
研究动机: 神经网络的复杂性使其成为黑盒模型，这在安全关键应用中存在问题。为提高透明度和可靠性，本文提出了一种结合可解释AI的抓取算法。

研究方法: 提出了一种协作机器人抓取算法，通过可解释AI方法提取学习特征并与输入类别关联，作为安全操作的附加标准。

研究结果: 在工业环境中测试表明，该方法提高了抓取位置的准确性，并确保工具的安全操作。

研究结论: 该方法通过概念学习提高了抓取算法的透明度和安全性，适用于工业环境中的协作机器人操作。

中文摘要: 神经网络常被视为可以估计任何函数的通用方程。然而，这种灵活性伴随着高复杂性的缺点，使这些网络成为黑盒模型，这在安全关键应用中尤为重要。为此，我们提出了一种协作机器人（Cobot）抓取算法的流程，用于检测相关工具并生成最佳抓取。为提高该方法的透明度和可靠性，我们集成了一种可解释AI方法，通过提取学习特征并将其与输入类别关联，为模型的预测提供解释。这些概念随后被用作附加标准，以确保工具的安全操作。本文展示了该方法的一致性及其对改进交接位置的准则。该方法在工业环境中进行了测试，通过设置摄像头系统使机器人能够抓取特定工具和物体。

</details>


### [377] [A workflow for generating synthetic LiDAR datasets in simulation environments](https://arxiv.org/abs/2506.17378)
**中文标题：在仿真环境中生成合成LiDAR数据集的工作流程**

*Abhishek Phadke,Shakib Mahmud Dipto,Pratip Rana*

主要分类: cs.RO

摘要简述: 本文提出了一种在仿真环境中生成合成LiDAR数据集的工作流程，用于支持自动驾驶感知、机器人研究和传感器安全分析。通过CoppeliaSim仿真环境及其Python API，实现了多模态数据的自动化捕获、存储和标注，并验证了其在大规模点云和RGB/深度图像生成中的应用。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决自动驾驶和机器人领域对高质量LiDAR数据的需求，同时探索LiDAR数据的安全漏洞，为防御策略评估提供支持。

研究方法: 利用CoppeliaSim仿真环境及其Python API，将LiDAR、图像传感器和二维扫描仪集成到模拟车辆平台上，自动化生成多格式（PCD、PLY、CSV）的同步多模态数据集，并包含真实姿态信息。

研究结果: 成功生成了大规模点云及对应的RGB和深度图像，验证了工作流程的有效性，并展示了LiDAR数据中的安全漏洞（如对抗点注入和欺骗攻击）。

研究结论: 该工作流程为生成高保真合成LiDAR数据集提供了可复现的框架，支持感知研究和传感器安全。未来可扩展至天气效果、真实地形模型和高级扫描配置。

中文摘要: 本文提出了一种仿真工作流程，用于生成合成LiDAR数据集，以支持自动驾驶感知、机器人研究和传感器安全分析。通过CoppeliaSim仿真环境及其Python API，我们将飞行时间LiDAR、图像传感器和二维扫描仪集成到模拟车辆平台上，并在城市场景中运行。该工作流程自动化了数据捕获、存储和标注，支持多种格式（PCD、PLY、CSV），并生成带有真实姿态信息的同步多模态数据集。我们通过生成大规模点云及对应的RGB和深度图像验证了该流程。研究还探讨了LiDAR数据中的潜在安全漏洞（如对抗点注入和欺骗攻击），并展示了合成数据集如何促进防御策略的评估。最后，讨论了环境真实性、传感器噪声建模和计算可扩展性等局限性，并提出了未来研究方向，如加入天气效果、真实地形模型和高级扫描配置。该工作流程为生成高保真合成LiDAR数据集提供了灵活且可复现的框架，推动感知研究并增强自动驾驶系统中的传感器安全性。文档和示例随框架提供，动画云返回和图像传感器数据的样本可通过链接查看。

</details>


### [378] [GeNIE: A Generalizable Navigation System for In-the-Wild Environments](https://arxiv.org/abs/2506.17960)
**中文标题：GeNIE：一种适用于野外环境的通用导航系统**

*Jiaming Wang,Diwen Liu,Jizhuo Chen,Jiaxuan Da,Nuowen Qian,Tram Minh Man,Harold Soh*

主要分类: cs.RO

摘要简述: GeNIE是一种通用导航系统，专为复杂自然环境设计，结合了可泛化的通行性预测模型和路径融合策略，在ICRA 2025地球漫游者挑战赛中表现优异，无需人工干预完成全部任务。


<details>
  <summary>详细信息</summary>
研究动机: 在非结构化、多样化的真实环境中实现可靠的导航是机器人领域的重大挑战，尤其是在不同地形、天气和传感器配置下。GeNIE旨在开发一种通用且鲁棒的导航系统，以应对这些复杂场景。

研究方法: GeNIE整合了基于SAM2的可泛化通行性预测模型和一种新型路径融合策略，提升了在噪声和模糊环境中的规划稳定性。

研究结果: GeNIE在ICRA 2025地球漫游者挑战赛中表现卓越，获得第一名，完成全部任务且无需人工干预，得分超过第二名17%。

研究结论: GeNIE为户外机器人导航设立了新的基准，其通用性和鲁棒性在真实环境中得到了验证。代码、预训练模型和新数据集将公开以支持未来研究。

中文摘要: 在非结构化的真实环境中实现可靠的导航对机器人来说仍是一个重大挑战，尤其是在多样化的地形、天气和传感器配置下。本文介绍了GeNIE（适用于野外环境的通用导航系统），这是一种为全球部署设计的鲁棒导航框架。GeNIE整合了基于SAM2的可泛化通行性预测模型和一种新型路径融合策略，提升了在噪声和模糊环境中的规划稳定性。GeNIE在ICRA 2025地球漫游者挑战赛（ERC）中进行了测试，跨越三大洲的六个国家。GeNIE获得第一名，达到了最高分的79%，领先第二名17%，并在整个比赛中未需任何人工干预。这些结果为鲁棒且可泛化的户外机器人导航设立了新基准。我们将发布代码库、预训练模型权重和新整理的数据集，以支持未来在真实世界导航中的研究。

</details>


### [379] [EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization](https://arxiv.org/abs/2506.17516)
**中文标题：EASE：通过自监督能量最小化实现具身主动事件感知**

*Zhou Chen,Sanjoy Kundu,Harsimran S. Baweja,Sathyanarayanan N. Aakur*

主要分类: cs.RO

摘要简述: 论文提出了一种名为EASE的自监督框架，通过自由能量最小化实现动态事件感知，无需依赖预定义动作空间或标注数据，适用于动态现实场景。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事件感知方法通常依赖预定义动作空间、标注数据集和外部奖励，限制了其在动态现实场景中的适应性和扩展性。受事件感知和预测编码的认知理论启发，研究旨在提出一种自监督框架，实现更灵活和可扩展的主动事件感知。

研究方法: EASE框架通过自由能量最小化统一时空表示学习和具身控制，利用预测误差和熵作为内在信号分割事件、总结观察并主动跟踪显著目标，无需标注或外部奖励。结合生成感知模型和动作驱动控制策略，动态对齐预测与观察。

研究结果: 在仿真和现实环境中的广泛评估表明，EASE能够实现隐私保护且可扩展的事件感知，支持隐式记忆、目标连续性和对新环境的适应性等行为。

研究结论: EASE为动态、非脚本任务中的具身系统提供了强大的基础，展示了自监督框架在主动事件感知中的潜力。

中文摘要: 主动事件感知是具身智能在人类-AI协作、辅助机器人和自主导航等任务中的关键能力。然而，现有方法通常依赖预定义动作空间、标注数据集和外部奖励，限制了其在动态现实场景中的适应性和扩展性。受事件感知和预测编码的认知理论启发，我们提出了EASE，一种通过自由能量最小化统一时空表示学习和具身控制的自监督框架。EASE利用预测误差和熵作为内在信号分割事件、总结观察并主动跟踪显著目标，无需显式标注或外部奖励。通过将生成感知模型与动作驱动控制策略结合，EASE动态对齐预测与观察，实现了隐式记忆、目标连续性和对新环境的适应性等行为。在仿真和现实环境中的广泛评估表明，EASE能够实现隐私保护且可扩展的事件感知，为动态、非脚本任务中的具身系统提供了强大的基础。

</details>


### [380] [ADA-DPM: A Neural Descriptors-based Adaptive Noise Point Filtering Strategy for SLAM](https://arxiv.org/abs/2506.18016)
**中文标题：ADA-DPM：一种基于神经描述符的自适应噪声点过滤策略用于SLAM**

*Yongxin Shao,Binrui Wang,Aihong Tan*

主要分类: cs.RO

摘要简述: 本文提出了一种基于神经描述符的自适应噪声点过滤策略ADA-DPM，用于提升SLAM系统在动态物体干扰和噪声环境中的定位精度与鲁棒性。通过动态分割头和全局重要性评分头，结合多尺度邻域结构的图卷积模块，显著提升了特征点的判别能力，并在公开数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有SLAM方法在动态物体干扰、点云噪声和非结构化环境下，往往需要在定位精度和系统鲁棒性之间做出妥协。为了解决这一问题，本文提出了一种自适应噪声过滤策略，旨在同时提升这两方面的性能。

研究方法: 设计了动态分割头（Dynamic Segmentation Head）用于预测动态特征点类别以消除动态点；全局重要性评分头（Global Importance Scoring Head）用于自适应选择贡献更高的特征点并抑制噪声干扰；构建了跨层图内卷积模块（GLI-GCN）以融合多尺度邻域结构，增强重叠特征的判别能力。

研究结果: 在多个公开数据集上的测试表明，ADA-DPM在定位精度和系统鲁棒性方面均表现出色，显著优于现有方法。

研究结论: ADA-DPM通过自适应噪声过滤和多尺度特征融合，有效解决了SLAM在复杂环境中的性能瓶颈，为移动机器人导航和高精度地图构建提供了可靠的技术支持。

中文摘要: 激光雷达SLAM在移动机器人导航和高精度地图构建等领域展现了重要应用价值。然而，现有方法在面对动态物体干扰、点云噪声和非结构化环境时，往往需要在定位精度和系统鲁棒性之间做出妥协。为解决这一问题，我们提出了一种自适应噪声过滤SLAM策略——ADA-DPM，在两方面均取得了优异表现。我们设计了动态分割头以预测动态特征点类别，消除动态特征点；设计了全局重要性评分头以自适应选择贡献更高的特征点并抑制噪声干扰；构建了跨层图内卷积模块（GLI-GCN）以融合多尺度邻域结构，从而增强重叠特征的判别能力。最后，为验证方法的有效性，我们在多个公开数据集上进行了测试，并取得了卓越的结果。

</details>


### [381] [Radar and Event Camera Fusion for Agile Robot Ego-Motion Estimation](https://arxiv.org/abs/2506.18443)
**中文标题：雷达与事件相机融合用于敏捷机器人自运动估计**

*Yang Lyu,Zhenghao Zou,Yanfeng Li,Chunhui Zhao,Quan Pan*

主要分类: cs.RO

摘要简述: 本文提出了一种结合事件相机和毫米波雷达的无IMU和无特征关联框架，用于高动态场景下机器人平台的敏捷自运动速度估计。该方法通过直接利用原始事件和多普勒测量计算速度，避免了复杂的帧间关联，提高了在无纹理和无结构环境中的鲁棒性，并在后端通过连续时间状态空间模型融合测量数据，验证了其可靠性和高效性。


<details>
  <summary>详细信息</summary>
研究动机: 高动态机器人（如特技飞行器）的自运动估计面临传感器响应不及时或模糊的挑战，导致测量模糊、失真和延迟。因此，需要一种无需IMU和特征关联的鲁棒方法，以适应高动态场景。

研究方法: 方法结合事件相机和毫米波雷达，直接利用原始事件和多普勒测量计算旋转和平移速度，避免了复杂的帧间关联。后端采用连续时间状态空间模型，以固定滞后平滑方式融合基于时间和事件的测量数据。

研究结果: 实验结果表明，该框架在挑战性环境中能够实现可靠且高效的速度输出，适用于无纹理和无结构的环境，且计算效率高，适合边缘计算设备。

研究结论: 本文提出的无IMU和无特征关联的自运动估计框架在高动态场景中表现优异，验证了其可靠性和高效性，为敏捷机器人运动估计提供了新思路。

中文摘要: 为高动态机器人（如特技飞行器）实现可靠的自运动估计仍具挑战性，因为大多数传感器无法及时清晰地响应高度动态的运动，常导致测量模糊、失真和延迟。本文提出了一种无IMU和无特征关联的框架，通过结合事件相机和毫米波雷达两种外部感知传感器，实现高动态场景下机器人平台的敏捷自运动速度估计。首先，我们利用瞬时原始事件和多普勒测量直接计算旋转和平移速度。无需复杂的测量帧间关联过程，该方法在无纹理和无结构环境中更具鲁棒性，且对边缘计算设备更高效。后端提出了一种连续时间状态空间模型，以固定滞后平滑方式融合基于时间和事件的测量数据，估计自运动速度。最后，我们在自收集的实验数据集中广泛验证了速度计框架。结果表明，我们的无IMU和无关联自运动估计框架在挑战性环境中能够实现可靠且高效的速度输出。源代码、演示视频和数据集可在https://github.com/ZzhYgwh/TwistEstimator获取。

</details>


### [382] [TDACloud: Point Cloud Recognition Using Topological Data Analysis](https://arxiv.org/abs/2506.18725)
**中文标题：TDACloud：基于拓扑数据分析的点云识别**

*Anirban Ghosh,Ian Dahlin,Ayan Dutta*

主要分类: cs.RO

摘要简述: TDACloud是一种基于拓扑数据分析（TDA）的点云识别方法，无需GPU密集型训练，通过ATOL向量化生成固定大小的描述符向量，在噪声和变换条件下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 点云识别在自动驾驶、场景重建和定位等应用中具有重要意义，但现有方法在噪声和变换（如旋转）条件下表现不佳，且依赖资源密集型训练。因此，需要一种高效且鲁棒的点云识别方法。

研究方法: 提出TDACloud方法，利用拓扑数据分析（TDA）提取点云的局部描述符，采用ATOL向量化技术生成固定大小的描述符向量，直接处理原始点云输入。

研究结果: 在真实世界（如Oxford RobotCar、KITTI-360）和仿真（如ShapeNet）数据集上测试，TDACloud在噪声和变换条件下表现出高识别精度，优于基线方法约14%。

研究结论: TDACloud通过TDA技术提供了一种高效且鲁棒的点云识别方法，无需GPU密集型训练，适用于复杂场景下的对象和场景识别。

中文摘要: 点云识别在自动驾驶、场景重建和定位等应用中具有重要意义。从查询点云中提取有意义的局部描述符以与收集的点云描述符匹配是一个具有挑战性的问题，尤其是在点云存在噪声或变换（如旋转）时。为此，我们提出了一种名为TDACloud的新方法，利用拓扑数据分析（TDA）从点云中提取局部描述符，无需依赖资源密集型的GPU机器学习训练。具体而言，我们使用ATOL向量化方法为点云生成向量。与体素化不同，我们的技术可以直接处理原始点云输入，并输出固定大小的TDA描述符向量。为验证TDACloud的质量，我们在多个真实世界（如Oxford RobotCar、KITTI-360）和仿真（如ShapeNet）点云数据集上进行了对象和场景识别测试，并在噪声和变换（如缩放、平移或旋转）条件下进行了验证。结果表明，TDACloud在噪声条件下和大规模真实世界场景识别中表现出高精度，优于基线方法约14%。

</details>


### [383] [Reproducible Evaluation of Camera Auto-Exposure Methods in the Field: Platform, Benchmark and Lessons Learned](https://arxiv.org/abs/2506.18844)
**中文标题：野外相机自动曝光方法的可复现评估：平台、基准与经验教训**

*Olivier Gamache,Jean-Michel Fortin,Matěj Boxan,François Pomerleau,Philippe Giguère*

主要分类: cs.RO

摘要简述: 本文提出了一种利用模拟器生成任意曝光时间图像的方法，基于BorealHDR数据集，评估了八种自动曝光（AE）方法，发现传统AE方法表现最佳，并分享了硬件平台开发经验。


<details>
  <summary>详细信息</summary>
研究动机: 标准数据集的固定输入传感器参数限制了自动曝光（AE）方法的比较，传统在线实验难以复现。本文旨在通过模拟器和多曝光数据集解决这一问题。

研究方法: 利用BorealHDR多曝光立体数据集及其扩展，开发了一种模拟器生成任意曝光图像的方法，并通过RMSE验证其准确性。评估了八种AE方法。

研究结果: 模拟器生成的图像与真实图像的RMSE低于1.78%，传统AE方法表现最佳。数据集包含13.4 km轨迹和多种传感器数据。

研究结论: 传统AE方法仍为最优，模拟器和数据集支持可复现性研究。硬件平台开发经验为未来研究提供了参考。

中文摘要: 标准数据集常因输入传感器数据的固定性而受限，尤其是对于依赖环境因素调整传感器参数的自动曝光（AE）方法。传统AE方法的在线实验难以复现。基于前期工作，我们提出了一种利用模拟器生成任意曝光时间图像的方法。该方法结合了独特的BorealHDR多曝光立体数据集及其扩展，数据采集于一天中不同时段以评估光照变化的影响。BorealHDR共覆盖13.4公里、59条轨迹，涵盖挑战性光照条件。数据集还包括基于激光雷达-惯性里程计的地图、每帧图像的姿态估计及GNSS数据。实验表明，通过不同曝光时间图像生成的模拟图像与真实图像的RMSE低于1.78%。利用这一离线方法，我们评估了八种AE方法，发现传统AE方法表现最佳。为支持复现性，我们详细介绍了背包采集平台的硬件、电气组件及性能规格，并分享了在25公里以上环境中部署的经验。代码和数据集见：https://github.com/norlab-ulaval/TFR24 BorealHDR

</details>


### [384] [GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale Multi-Agent Gaussian SLAM](https://arxiv.org/abs/2506.18885)
**中文标题：GRAND-SLAM：面向全局一致大规模多智能体高斯SLAM的局部优化方法**

*Annika Thomas,Aneesa Sonawalla,Alex Rose,Jonathan P. How*

主要分类: cs.RO

摘要简述: GRAND-SLAM是一种多智能体高斯SLAM方法，通过局部优化和闭环检测提升大规模户外环境下的跟踪与重建性能，实验表明其在室内和户外数据集上均优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前多智能体高斯SLAM方法仅适用于小规模室内环境，而大规模户外环境的应用尚未探索。GRAND-SLAM旨在填补这一空白，提供高效的多智能体协作SLAM解决方案。

研究方法: GRAND-SLAM结合了基于子图的局部优化隐式跟踪模块和集成于位姿图优化框架的机器人间与机器人内闭环检测方法。

研究结果: 在Replica室内数据集上，GRAND-SLAM的跟踪性能领先，PSNR提升28%；在Kimera-Multi户外数据集上，多智能体跟踪误差降低91%，渲染效果更优。

研究结论: GRAND-SLAM通过局部优化和闭环检测实现了大规模多智能体高斯SLAM的高效协作，显著提升了跟踪和重建性能。

中文摘要: 3D高斯喷绘已成为RGB-D视觉SLAM的一种高效场景表示方法，但其在大规模多智能体户外环境中的应用尚未探索。多智能体高斯SLAM是一种快速探索和重建环境的有前景方法，提供可扩展的环境表示，但现有方法仅限于小规模室内环境。为此，我们提出了GRAND-SLAM，一种协作式高斯喷绘SLAM方法，集成了i）基于子图局部优化的隐式跟踪模块和ii）集成于位姿图优化框架的机器人间与机器人内闭环检测方法。实验表明，GRAND-SLAM在Replica室内数据集上提供了最先进的跟踪性能，PSNR比现有方法高28%；在Kimera-Multi大规模户外数据集上，多智能体跟踪误差降低91%，渲染效果优于现有多智能体方法。

</details>


### [385] [Robots and Children that Learn Together : Improving Knowledge Retention by Teaching Peer-Like Interactive Robots](https://arxiv.org/abs/2506.18365)
**中文标题：儿童与机器人共同学习：通过教授同伴式互动机器人提升知识保留率**

*Imene Tarakli,Samuele Vinanzi,Richard Moore,Alessandro Di Nuovo*

主要分类: cs.RO

摘要简述: 本研究探索了儿童与自主社交机器人通过互动强化学习（Interactive RL）共同学习的效果，发现儿童在教授机器人法语词汇和语法时，知识保留率显著高于自主练习，尤其是语法任务和低基础学习者。


<details>
  <summary>详细信息</summary>
研究动机: 尽管“通过教学学习”（LbT）模式受到关注，但此前研究多依赖脚本或“绿野仙踪”方法，缺乏对自主社交机器人在真实课堂中实时互动学习效果的探索。本研究旨在填补这一空白。

研究方法: 研究采用互动强化学习（Interactive RL）作为机器人的认知模型，通过两项实验（58名小学生参与）比较儿童教授机器人与自主练习的效果，任务包括法语词汇记忆和语法规则推理。

研究结果: 结果显示，LbT组的儿童在知识保留上显著优于自主练习组，尤其是语法任务；低基础学习者受益最大。行为指标表明儿童逐渐调整教学策略，并在推理任务中更投入。

研究结论: 研究贡献在于：（1）提出Interactive RL作为可扩展的同伴机器人学习模型；（2）首次在真实课堂中同时部署多个自主机器人，证明其可行性。社交机器人可作为适应性伙伴提升元认知参与和长期学习效果。

中文摘要: 尽管“通过教学学习”（LbT）模式日益受到关注，但少有研究探讨如何将其应用于真实课堂中的自主、同伴式社交机器人。此前研究多依赖脚本或“绿野仙踪”行为，限制了我们对人工代理如何支持实时互动学习的理解。本研究通过引入互动强化学习（Interactive RL）作为可教学机器人的认知模型，填补了这一空白。我们进行了两项实验，58名小学生分别教授机器人或自主练习平板，学习法语词汇（记忆）和语法规则（推理）。机器人通过Interactive RL从儿童的评价反馈中学习。结果显示，LbT组的儿童在知识保留上显著优于自主练习组，尤其是语法任务；低基础学习者受益最大。行为指标表明儿童逐渐调整教学策略，并在推理任务中更投入。本研究贡献在于：（1）提出Interactive RL作为一种教育有效且可扩展的同伴机器人学习模型；（2）首次证明在真实课堂中同时部署多个自主机器人的可行性。这些发现扩展了LbT的理论理解，表明社交机器人不仅可以作为被动学习者，还能作为适应性伙伴，提升元认知参与和长期学习效果。

</details>


### [386] [NOVA: Navigation via Object-Centric Visual Autonomy for High-Speed Target Tracking in Unstructured GPS-Denied Environments](https://arxiv.org/abs/2506.18689)
**中文标题：NOVA：基于对象中心视觉自主的高速目标跟踪在无GPS非结构化环境中的导航**

*Alessandro Saviolo,Giuseppe Loianno*

主要分类: cs.RO

摘要简述: NOVA是一种完全基于机载设备的对象中心视觉自主框架，能够在无GPS的非结构化环境中实现高速目标跟踪和避障导航，仅需立体相机和IMU。


<details>
  <summary>详细信息</summary>
研究动机: 当前自主空中目标跟踪在非结构化和无GPS环境中仍面临挑战，现有方法依赖运动捕捉系统、预建地图或基于特征的定位，限制了实际应用。NOVA旨在通过对象中心框架解决这些问题。

研究方法: NOVA采用轻量级目标检测器和立体深度补全技术，结合基于直方图的滤波推断目标距离，并通过视觉惯性状态估计器恢复机器人相对于目标的6自由度位姿。非线性模型预测控制器（NMPC）在目标坐标系中规划动态可行轨迹，同时利用高阶控制屏障函数实现实时避障。

研究结果: NOVA在多种复杂场景（如城市迷宫、森林小径和建筑过渡）中验证了其性能，能够在间歇性GPS丢失和光照变化下实现超过50公里/小时的高速目标跟踪。

研究结论: NOVA展示了仅依赖机载传感器的高速视觉目标跟踪在现实环境中的可行性，无需外部定位或环境假设。

中文摘要: 在非结构化和无GPS环境中实现自主空中目标跟踪仍然是机器人技术中的一项基本挑战。许多现有方法依赖运动捕捉系统、预建场景或基于特征的定位来确保安全和控制，限制了其在现实条件下的部署。我们提出了NOVA，一种完全机载的对象中心框架，仅使用立体相机和IMU实现鲁棒的目标跟踪和避障导航。NOVA不构建全局地图或依赖绝对定位，而是完全在目标参考系中实现感知、估计和控制。一个紧密集成的堆栈结合了轻量级目标检测器与立体深度补全，随后通过基于直方图的滤波推断遮挡和噪声下的鲁棒目标距离。这些测量结果输入视觉惯性状态估计器，恢复机器人相对于目标的完整6自由度位姿。非线性模型预测控制器（NMPC）在目标坐标系中规划动态可行轨迹。为确保安全，从深度提取的高风险碰撞点构建在线高阶控制屏障函数，实现无需地图或密集表示的实时避障。我们在多种挑战性现实场景中验证了NOVA，包括城市迷宫、森林小径和建筑过渡，这些场景中GPS间歇性丢失和严重光照变化会干扰基于特征的定位。每个实验在相似条件下重复多次以评估鲁棒性，结果显示NOVA具有一致且可靠的性能。NOVA实现了超过50公里/小时的敏捷目标跟踪。这些结果表明，仅依赖机载传感的高速视觉跟踪在现实环境中是可行的，无需外部定位或环境假设。

</details>


### [387] [MinD: Unified Visual Imagination and Control via Hierarchical World Models](https://arxiv.org/abs/2506.18897)
**中文标题：MinD：基于分层世界模型的统一视觉想象与控制**

*Xiaowei Chi,Kuangzhi Ge,Jiaming Liu,Siyuan Zhou,Peidong Jia,Zichen He,Yuzhen Liu,Tingguang Li,Lei Han,Sirui Han,Shanghang Zhang,Yike Guo*

主要分类: cs.RO

摘要简述: 论文提出MinD框架，通过分层扩散模型解决视频生成模型在机器人应用中生成速度慢和视频与动作一致性差的问题，实现实时交互与视觉引导的闭环控制。


<details>
  <summary>详细信息</summary>
研究动机: 视频生成模型（VGMs）在机器人领域具有统一世界建模的潜力，但因生成速度慢和视频与动作一致性差，实际应用受限。MinD旨在解决这些问题，提升实时交互与任务预测能力。

研究方法: MinD采用分层扩散模型设计，结合低频视频生成模型提取预测特征，高频扩散策略实现实时交互。引入DiffMatcher模块和协同训练策略，通过扩散强制机制对齐中间表示，优化动作模型对视频预测的理解。

研究结果: MinD在RL-Bench等基准测试中表现优异，任务成功率超过63%，验证了其在机器人统一世界建模中的先进性和实用性。

研究结论: MinD不仅提升了机器人操作的实时性和一致性，还能作为世界模拟器预测任务可行性，为统一世界建模提供了新思路。

中文摘要: 视频生成模型（VGMs）为机器人领域的统一世界建模提供了潜力，但其实际应用受限于（1）生成速度慢，影响实时交互；（2）想象视频与可执行动作的一致性差。为此，我们提出Manipulate in Dream（MinD），一种基于分层扩散的世界模型框架，采用双系统设计实现视觉语言操作。MinD通过低频执行VGM提取视频预测特征，同时利用高频扩散策略实现实时交互。该架构支持低延迟的闭环控制与连贯的视觉引导。为协调两系统，我们引入视频-动作扩散匹配模块（DiffMatcher），采用新颖的协同训练策略，为每个扩散模型分配独立调度器。具体而言，DiffMatcher通过扩散强制机制在训练中对齐中间表示，帮助快速动作模型更好地理解视频预测。MinD还可作为世界模拟器，在执行前于潜在空间可靠预测任务成败。可信分析进一步表明，VGMs能预先评估任务可行性并降低风险。多基准测试表明，MinD在RL-Bench中任务成功率超过63%，推动了机器人统一世界建模的前沿。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [388] [PBFT-Backed Semantic Voting for Multi-Agent Memory Pruning](https://arxiv.org/abs/2506.17338)
**中文标题：基于PBFT的语义投票用于多代理记忆修剪**

*Duong Bach*

主要分类: cs.DC

摘要简述: 本文提出了一种名为Co-Forgetting Protocol的新框架，用于多代理系统中同步修剪共享记忆，结合语义投票、时间衰减函数和PBFT共识机制，实验显示其显著减少了内存占用并提高了决策准确性。


<details>
  <summary>详细信息</summary>
研究动机: 多代理系统在复杂动态环境中需要高效管理共享知识，避免过时或无关数据的积累。本文旨在解决这一挑战，提出一种同步修剪记忆的协议。

研究方法: 协议包含三个关键部分：(1) 基于DistilBERT的语义投票，评估记忆项的相关性；(2) 多尺度时间衰减函数，根据记忆的年龄和访问频率调整重要性；(3) 基于PBFT的共识机制，确保在存在恶意代理时仍能达成一致。

研究结果: 实验表明，协议在500个周期内减少52%内存占用，遗忘决策准确率达88%，PBFT共识成功率为92%，内存访问缓存命中率为82%。

研究结论: Co-Forgetting Protocol有效解决了多代理系统中记忆同步修剪的问题，显著提升了系统的效率和鲁棒性。

中文摘要: 多代理系统（MAS）在复杂动态环境中的广泛应用需要高效管理共享知识，确保分布式记忆同步、相关且避免过时或无关数据的积累——这一过程类似于生物遗忘。本文提出了一种名为Co-Forgetting Protocol的新框架，通过同步修剪MAS中的记忆来解决这一挑战。该协议整合了三个关键组件：(1) 上下文感知的语义投票，代理使用轻量级DistilBERT模型评估记忆项的内容和当前操作上下文的相关性；(2) 多尺度时间衰减函数，根据记忆的年龄和访问频率在不同时间范围内分配递减的重要性；(3) 基于实用拜占庭容错（PBFT）的共识机制，确保保留或丢弃记忆项的决定由合格且容错的多数代理达成，即使系统中存在最多f个拜占庭（恶意或故障）代理（N≥3f+1）。协议利用gRPC实现高效的代理间通信，Pinecone用于可扩展的向量嵌入存储和相似性搜索，SQLite管理元数据。在模拟MAS环境中对四个代理的实验评估表明，协议在500个周期内减少52%内存占用，遗忘决策准确率达88%（基于人工标注基准），PBFT共识成功率为92%（模拟拜占庭条件下），内存访问缓存命中率为82%。

</details>


### [389] [Speeding up Local Optimization in Vehicle Routing with Tensor-based GPU Acceleration](https://arxiv.org/abs/2506.17357)
**中文标题：基于张量的GPU加速在车辆路径问题中加速局部优化**

*Zhenyu Lei,Jin-Kao Hao,Qinghua Wu*

主要分类: cs.DC

摘要简述: 本文提出了一种基于张量的GPU加速方法，用于提升车辆路径问题（VRP）中局部搜索算子的计算效率，显著减少了计算时间并可能提高解的质量。


<details>
  <summary>详细信息</summary>
研究动机: 车辆路径问题中的局部搜索计算成本高且耗时，尤其是在大规模或复杂约束问题中。本研究旨在通过GPU加速技术解决这一挑战。

研究方法: 采用基于属性的张量表示方法，将密集计算完全卸载到GPU上，设计了一种低耦合架构，适用于多种VRP变体。

研究结果: 在三种路由问题的基准实例上，该方法相比传统CPU实现展现出显著的计算优势，并分析了其性能特点和潜在瓶颈。

研究结论: 该方法不仅提高了计算效率，还为未来改进提供了方向，同时揭示了实际应用中的性能限制。

中文摘要: 局部搜索在车辆路径问题（VRP）及其变体的许多有效启发式算法中扮演着核心角色。然而，邻域探索的计算成本高且耗时，尤其是对于大规模或复杂约束的问题。本研究探索了一种有前景的方向，通过引入一种基于张量的GPU加速方法，旨在加速车辆路径中常用的局部搜索算子。该方法采用基于属性的表示，具有广泛的扩展性，适用于不同的VRP变体。其低耦合架构将密集计算完全卸载到GPU上，确保了在各种基于局部搜索的算法和框架中的无缝集成，从而显著提高了计算效率并可能改善解的质量。通过在三种路由问题的基准实例上的对比实验，我们证明了该方法相比传统CPU实现的显著计算优势。我们还详细分析了该方法的优势和局限性，为其性能特点提供了有价值的见解，并指出了实际应用中的潜在瓶颈。这些发现有助于更好地理解该方法，并为未来的改进指明了方向。

</details>


### [390] [ConsumerBench: Benchmarking Generative AI Applications on End-User Devices](https://arxiv.org/abs/2506.17538)
**中文标题：ConsumerBench：终端设备上生成式AI应用的基准测试**

*Yile Gu,Rohan Kadekodi,Hoang Nguyen,Keisuke Kamahori,Yiyu Liu,Baris Kasikci*

主要分类: cs.DC

摘要简述: 本文提出了ConsumerBench，一个用于评估终端设备上生成式AI模型系统效率和响应时间的综合基准测试框架，揭示了资源分配和调度中的问题，并提供了优化建议。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI应用从云端迁移到终端设备，资源管理、系统效率和用户体验面临新挑战。现有基准测试假设模型独占专用GPU，无法反映多应用并发运行的实际情况，因此需要更贴近现实的测试框架。

研究方法: ConsumerBench模拟了终端设备上多应用并发运行的场景，支持自定义工作流以模拟复杂任务。它捕获应用级指标（如延迟和服务水平目标达成率）和系统级指标（如CPU/GPU利用率和内存带宽）。

研究结果: 实验揭示了资源共享的低效性、贪婪分配下的不公平调度以及静态模型服务器配置的性能缺陷。同时，研究提出了针对消费级GPU架构的定制内核和SLO感知调度策略的价值。

研究结论: ConsumerBench为模型开发者和系统设计者提供了实用洞察，强调了优化资源分配和调度策略的重要性，以提升终端设备上生成式AI应用的性能。

中文摘要: 生成式AI（GenAI）应用从云端环境向终端设备的迁移，为资源管理、系统效率和用户体验带来了新的挑战。本文提出了ConsumerBench，一个全面的基准测试框架，旨在评估终端设备上运行GenAI模型的系统效率和响应时间。与现有假设模型独占专用GPU的基准测试不同，ConsumerBench模拟了受限硬件上多应用并发运行的现实场景。此外，ConsumerBench支持自定义工作流，模拟需要多应用协调的复杂任务。它捕获了应用级指标（如延迟和服务水平目标达成率）和系统级指标（如CPU/GPU利用率和内存带宽）。通过大量实验，ConsumerBench揭示了资源共享的低效性、贪婪分配下的不公平调度以及静态模型服务器配置的性能缺陷。本文还为模型开发者和系统设计者提供了实用建议，强调了针对消费级GPU架构的定制内核的价值，以及实施SLO感知调度策略的优势。

</details>


### [391] [Research on Model Parallelism and Data Parallelism Optimization Methods in Large Language Model-Based Recommendation Systems](https://arxiv.org/abs/2506.17551)
**中文标题：基于大语言模型的推荐系统中模型并行与数据并行优化方法研究**

*Haowei Yang,Yu Tian,Zhongheng Yang,Zhao Wang,Chengrui Zhou,Dannier Li*

主要分类: cs.DC

摘要简述: 本文研究了在基于大语言模型的推荐系统中，模型并行和数据并行的优化方法，提出了一种混合并行方案，显著提升了训练效率和资源利用率。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型在推荐系统中的广泛应用，其庞大的参数量和数据量导致的计算和通信瓶颈日益突出，亟需优化并行训练方法以提升效率。

研究方法: 本文系统研究了模型并行（包括张量并行和流水线并行）和数据并行（同步与异步模式），并引入自适应负载均衡机制和梯度压缩技术，优化通信开销和带宽利用率。

研究结果: 实验表明，提出的混合并行方案在真实推荐数据集上训练吞吐量提升30%以上，资源利用率提高约20%，同时保持了良好的扩展性和鲁棒性。

研究结论: 本文验证了混合并行策略的有效性，并探讨了在线部署中的权衡问题，未来研究方向包括异构硬件集成和自动化调度技术。

中文摘要: 随着大语言模型（LLMs）在推荐系统中的快速应用，其庞大的参数量和数据量导致的计算和通信瓶颈日益突出。本文系统研究了两种优化方法——模型并行和数据并行——用于推荐场景下LLMs的分布式训练。在模型并行方面，我们实现了张量并行和流水线并行，并引入自适应负载均衡机制以减少跨设备通信开销。在数据并行方面，我们比较了同步和异步模式，结合梯度压缩和稀疏化技术，以及高效的聚合通信框架，显著提高了带宽利用率。在模拟服务环境中对真实推荐数据集的实验表明，与传统单一并行模式相比，我们提出的混合并行方案使训练吞吐量提升超过30%，资源利用率提高约20%，同时保持了强大的扩展性和鲁棒性。最后，我们讨论了在线部署中不同并行策略的权衡，并展望了未来研究方向，包括异构硬件集成和自动化调度技术。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [392] [Can Common VLMs Rival Medical VLMs? Evaluation and Strategic Insights](https://arxiv.org/abs/2506.17337)
**中文标题：通用视觉语言模型能否匹敌医疗专用模型？评估与策略洞察**

*Yuan Zhong,Ruinan Jin,Xiaoxiao Li,Qi Dou*

主要分类: eess.IV

摘要简述: 本研究探讨通用视觉语言模型（VLMs）是否可通过微调匹敌医疗专用VLMs。结果显示，经轻量微调后，通用VLMs在特定医疗任务中表现优异，甚至超越医疗专用模型，尤其在跨域任务中展现出强大适应性。


<details>
  <summary>详细信息</summary>
研究动机: 医疗视觉语言模型（VLMs）需要大量计算和数据资源，而通用VLMs虽未经医疗训练，但通过微调可能具备竞争力。本研究旨在验证通用VLMs是否能在医疗任务中替代专用模型。

研究方法: 研究系统评估了基于CLIP和LLaVA的通用与医疗VLMs，比较了其在域内（ID）和域外（OOD）任务中的表现，并测试了轻量微调（如LoRA）的效果。

研究结果: 医疗专用预训练在域内任务中占优，但通用VLMs经微调后表现相当或更优；在域外任务中，通用VLMs展现出较强适应性，挑战了医疗专用预训练的必要性。

研究结论: 通用VLMs结合微调是一种可扩展且经济高效的替代方案，为医疗影像领域研究提供了重要启示。

中文摘要: 医疗视觉语言模型（VLMs）通过大规模预训练适用于多种影像任务，但需要大量计算和数据资源。与此同时，通用VLMs（如CLIP、LLaVA）虽未经医疗训练，但通过微调展现出潜力。这引发了一个关键问题：高效微调的通用VLMs能否在特定医疗影像任务中匹敌通用医疗VLMs？本研究系统评估了通用与医疗VLMs在疾病诊断和视觉问答（VQA）中的表现。基于CLIP和LLaVA的模型，我们考察了（1）域内（ID）任务中的现成性能差距，（2）微调是否能弥合这些差距，以及（3）对未见医疗模态的域外（OOD）任务的泛化能力。结果显示，医疗专用预训练在ID任务中具有优势，但通用VLMs经轻量微调后表现相当或更优，其中LoRA适配方法尤为有效。在OOD任务中，通用VLMs在某些任务中展现出强大适应性，挑战了医疗专用预训练的必要性。这些发现表明，结合微调的通用VLMs为开发大规模医疗VLMs提供了一种可扩展且经济高效的替代方案，为医疗影像领域的未来研究提供了重要启示。

</details>


### [393] [DSA-NRP: No-Reflow Prediction from Angiographic Perfusion Dynamics in Stroke EVT](https://arxiv.org/abs/2506.17501)
**中文标题：DSA-NRP：基于血管造影灌注动态的卒中EVT无复流预测**

*Shreeram Athreya,Carlos Olivares,Ameera Ismail,Kambiz Nael,William Speier,Corey Arnold*

主要分类: eess.IV

摘要简述: 本文提出了一种名为DSA-NRP的机器学习框架，用于在急性缺血性卒中血管内取栓术（EVT）后立即预测无复流现象。该方法通过分析数字减影血管造影（DSA）序列和临床变量，显著优于传统临床特征基线，为实时预测无复流提供了新途径。


<details>
  <summary>详细信息</summary>
研究动机: 急性缺血性卒中患者在成功进行血管内取栓术后，部分患者会出现无复流现象，导致微血管低灌注，影响组织恢复和临床结果。目前临床依赖术后24小时内的灌注MRI进行识别，延迟了干预时机。因此，需要一种实时预测无复流的方法。

研究方法: 研究回顾性分析了2011-2024年UCLA医学中心接受EVT治疗并取得良好mTICI评分（2b-3）的患者。通过从DSA序列（前后位和侧位视图）中提取目标下游区域的统计和时间灌注特征，结合临床变量，训练机器学习分类器预测无复流现象。

研究结果: 该方法显著优于仅依赖临床特征的基线模型（AUC：0.7703 ± 0.12 vs. 0.5728 ± 0.12；准确率：0.8125 ± 0.10 vs. 0.6331 ± 0.09），表明DSA灌注动态能够实时反映微血管完整性。

研究结论: DSA-NRP为无复流现象的实时预测提供了可靠工具，使临床医生能够及时干预高风险患者，无需依赖延迟的影像学检查。

中文摘要: 在急性缺血性卒中（AIS）患者通过血管内取栓术（EVT）成功实现大血管再通后，部分患者会出现无复流现象，表现为持续的微血管低灌注，影响组织恢复并恶化临床结果。尽管及时识别至关重要，但标准临床实践依赖于术后24小时内的灌注磁共振成像（MRI），导致干预延迟。本研究首次引入了一种机器学习（ML）框架，通过利用术中数字减影血管造影（DSA）序列和临床变量，在EVT后立即预测无复流现象。我们的回顾性分析包括2011-2024年在UCLA医学中心接受治疗并取得良好mTICI评分（2b-3）的AIS患者，这些患者接受了术前和术后MRI检查。无复流定义为术后影像中持续的Tmax > 6秒的低灌注。我们从DSA序列（前后位和侧位视图）中提取目标下游区域的统计和时间灌注特征，训练ML分类器预测无复流。我们的新方法显著优于仅依赖临床特征的基线模型（AUC：0.7703 ± 0.12 vs. 0.5728 ± 0.12；准确率：0.8125 ± 0.10 vs. 0.6331 ± 0.09），表明实时DSA灌注动态能够反映微血管完整性的关键信息。这一方法为实时、准确的无复流预测奠定了基础，使临床医生能够主动管理高风险患者，而无需依赖延迟的影像学检查。

</details>


### [394] [MTSIC: Multi-stage Transformer-based GAN for Spectral Infrared Image Colorization](https://arxiv.org/abs/2506.17540)
**中文标题：MTSIC：基于多阶段Transformer的生成对抗网络用于光谱红外图像颜色化**

*Tingting Liu,Yuan Liu,Jinhui Tang,Liyin Yuan,Chengyu Liu,Chunlai Li,Xiubao Sui,Qian Chen*

主要分类: eess.IV

摘要简述: 本文提出了一种基于生成对抗网络（GAN）的多阶段Transformer框架（MTSIC），用于红外图像的颜色化。通过多波段光谱信息和自注意力机制，显著提升了图像的颜色化质量和语义准确性。


<details>
  <summary>详细信息</summary>
研究动机: 热红外（TIR）图像不受光照和大气雾霾影响，但缺乏颜色和纹理信息，限制了其应用并可能导致视觉疲劳。现有方法依赖单波段图像，光谱信息有限且特征提取能力不足，易导致图像失真和语义模糊。多波段红外图像提供更丰富的光谱数据，有助于保留细节和提升语义准确性。

研究方法: 提出MTSIC框架，采用多阶段光谱自注意力Transformer网络作为生成器。将每个光谱特征视为自注意力计算的token，并通过多头自注意力机制形成空间-光谱注意力残差块（SARB），实现多波段特征映射并减少语义混淆。多个SARB单元集成到基于Transformer的单阶段网络（STformer）中，结合U形架构提取上下文信息，并通过多尺度小波块（MSWB）在空间-频率双域对齐语义信息。多个STformer模块级联形成MTSIC，逐步优化重建质量。

研究结果: 实验结果表明，该方法显著优于传统技术，有效提升了红外图像的视觉质量。

研究结论: MTSIC通过多波段光谱信息和自注意力机制，成功解决了红外图像颜色化中的语义模糊和失真问题，显著提升了图像质量和语义准确性。

中文摘要: 热红外（TIR）图像通过热辐射成像获取，不受光照条件和大气雾霾变化的影响。然而，TIR图像本身缺乏颜色和纹理信息，限制了其下游任务并可能导致视觉疲劳。现有的颜色化方法主要依赖单波段图像，光谱信息有限且特征提取能力不足，往往导致图像失真和语义模糊。相比之下，多波段红外图像提供更丰富的光谱数据，有助于保留更精细的细节并提升语义准确性。本文提出了一种基于生成对抗网络（GAN）的框架，旨在整合光谱信息以增强红外图像的颜色化。该框架采用多阶段光谱自注意力Transformer网络（MTSIC）作为生成器。每个光谱特征被视为自注意力计算的token，多头自注意力机制形成空间-光谱注意力残差块（SARB），实现多波段特征映射并减少语义混淆。多个SARB单元集成到基于Transformer的单阶段网络（STformer）中，利用U形架构提取上下文信息，并结合多尺度小波块（MSWB）在空间-频率双域对齐语义信息。多个STformer模块级联形成MTSIC，逐步优化重建质量。实验结果表明，所提方法显著优于传统技术，有效提升了红外图像的视觉质量。

</details>


### [395] [LVPNet: A Latent-variable-based Prediction-driven End-to-end Framework for Lossless Compression of Medical Images](https://arxiv.org/abs/2506.17983)
**中文标题：LVPNet：一种基于潜在变量的预测驱动端到端框架用于医学图像的无损压缩**

*Chenyue Song,Chen Hui,Qing Lin,Wei Zhang,Siqiao Li,Shengping Zhang,Haiqi Zhu,Zhixuan Li,Shaohui Liu,Feng Jiang,Xiang Li*

主要分类: eess.IV

摘要简述: LVPNet是一种基于潜在变量的预测驱动端到端框架，用于医学图像的无损压缩，通过全局多尺度感知模块和量化补偿模块提升压缩效率和潜在变量利用率。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法中，图像分割过程导致潜在变量信息均匀分布，引发后验崩溃和潜在变量利用不足。LVPNet旨在解决这些问题，提升无损压缩效率。

研究方法: 提出LVPNet框架，结合全局潜在变量预测像素值并编码预测概率；引入全局多尺度感知模块（GMSM）提取紧凑潜在表示，量化补偿模块（QCM）补偿量化损失。

研究结果: 在多个基准测试中，LVPNet压缩效率优于现有无损图像压缩方法，同时保持推理速度竞争力。

研究结论: LVPNet通过全局潜在变量和量化补偿机制，显著提升了医学图像无损压缩的效率和性能。

中文摘要: 自回归初始比特是一种结合子图像自回归和潜在变量建模的框架，在无损医学图像压缩中表现出优势。然而，现有方法中图像分割过程导致潜在变量信息均匀分布于各子图像，引发后验崩溃和潜在变量利用不足。为解决这些问题，我们提出基于预测的端到端无损医学图像压缩方法LVPNet，利用全局潜在变量预测像素值并编码预测概率以实现无损压缩。具体而言，我们引入全局多尺度感知模块（GMSM），从整幅图像中提取紧凑且信息丰富的潜在表示，有效捕捉潜在空间内的空间依赖性。此外，为缓解量化引入的信息损失，我们提出量化补偿模块（QCM），学习量化误差分布并优化量化特征以补偿量化损失。在多个挑战性基准测试中的实验表明，我们的方法在压缩效率上优于当前最先进的无损图像压缩方法，同时保持竞争力推理速度。代码详见https://github.com/Anonymity00000/Anonymity-repository/。

</details>


### [396] [Multimodal Medical Image Binding via Shared Text Embeddings](https://arxiv.org/abs/2506.18072)
**中文标题：通过共享文本嵌入实现多模态医学影像绑定**

*Yunhao Liu,Suyang Xi,Shiqi Liu,Hong Ding,Chicheng Jin,Chenxi Yang,Junjun He,Yiqing Shen*

主要分类: eess.IV

摘要简述: 本文提出了一种名为M³Bind的新型预训练框架，通过共享文本表示空间实现多种医学影像模态的无缝对齐，无需显式配对数据，并在多个下游任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像分析需要整合多种成像模态以获取互补信息，但现有方法如CLIP需要显式配对数据，这在医学领域难以获取。因此，本文旨在解决这一难题。

研究方法: M³Bind通过微调预训练的CLIP类图像-文本模型，对齐模态特定的文本嵌入空间，同时保留原始图像-文本对齐，随后将这些模态特定的文本编码器蒸馏为一个统一模型，创建共享文本嵌入空间。

研究结果: 在X光、CT、视网膜、心电图和病理图像等多个下游任务中，M³Bind在零样本、少样本分类和跨模态检索任务中表现优于现有CLIP类方法。

研究结论: M³Bind通过共享文本嵌入空间有效实现了医学影像的跨模态对齐，为医学分析提供了高效工具。

中文摘要: 医学影像分析越来越依赖多种成像模态的整合，以捕捉互补的解剖和功能信息，从而实现更准确的诊断和治疗规划。因此，在这些多样化模态之间实现对齐的特征表示对于有效的多模态分析至关重要。尽管对比语言-图像预训练（CLIP）及其变体实现了图像-文本对齐，但它们需要任意两种模态之间的显式配对数据，这在医学背景下难以获取。为了解决这一问题，我们提出了多模态医学影像与文本绑定（M³Bind），这是一种新型预训练框架，通过共享文本表示空间实现多种医学影像模态的无缝对齐，而无需任何两种医学影像模态之间的显式配对数据。具体而言，基于不同图像可以自然与文本绑定的洞察，M³Bind首先微调预训练的CLIP类图像-文本模型，以对齐其模态特定的文本嵌入空间，同时保留原始图像-文本对齐。随后，我们将这些模态特定的文本编码器蒸馏为一个统一模型，创建共享文本嵌入空间。在X光、CT、视网膜、心电图和病理图像上的多个下游任务实验表明，与现有的CLIP类方法相比，M³Bind在零样本、少样本分类和跨模态检索任务中实现了最先进的性能。这些结果验证了M³Bind在医学分析中实现跨图像模态对齐的有效性。

</details>


### [397] [Transforming H&E images into IHC: A Variance-Penalized GAN for Precision Oncology](https://arxiv.org/abs/2506.18371)
**中文标题：将H&E图像转换为IHC：一种基于方差惩罚的GAN用于精准肿瘤学**

*Sara Rehmat,Hafeez Ur Rehman*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的图像转换框架，通过改进的GAN模型将H&E染色图像转换为高质量的IHC图像，用于精准肿瘤学中的HER2评估。


<details>
  <summary>详细信息</summary>
研究动机: HER2阳性乳腺癌的诊断依赖于昂贵的IHC技术，而常规的H&E染色虽普及但缺乏特异性。本研究旨在开发一种高效、低成本的方法，通过深度学习将H&E图像转换为IHC图像，以解决现有技术的局限性。

研究方法: 研究改进了金字塔pix2pix模型的损失函数，引入方差惩罚项以避免模式崩溃，并增强生成图像的结构多样性。模型特别针对HER2阳性（IHC 3+）图像的复杂形态变化进行了优化。

研究结果: 在BCI病理数据集上的实验表明，该模型在PSNR、SSIM和FID等指标上优于现有方法，尤其在HER2阳性图像的转换上表现突出。此外，模型在通用图像转换任务中也展现出优越性能。

研究结论: 本研究为精准肿瘤学提供了一种可靠且高效的HER2诊断替代方案，同时展示了模型在跨领域图像转换任务中的潜力。

中文摘要: 人类表皮生长因子受体2（HER2）在乳腺细胞中的过表达是HER2阳性乳腺癌的关键驱动因素，这种高度侵袭性的亚型需要精确诊断和靶向治疗。免疫组化（IHC）是HER2评估的标准技术，但成本高、耗时长且高度依赖抗体选择。相比之下，常规的苏木精和伊红（H&E）染色虽然普及，但缺乏HER2特异性。本研究提出了一种先进的基于深度学习的图像转换框架，能够从H&E染色的组织样本中生成高保真的IHC图像，从而实现经济高效且可扩展的HER2评估。通过改进金字塔pix2pix的损失函数，我们缓解了生成对抗网络（GANs）中的模式崩溃问题，并引入了一种基于方差的新型惩罚项，以增强生成图像的结构多样性。我们的模型在转换HER2阳性（IHC 3+）图像方面表现尤为突出，这些图像因其复杂的形态变化而成为现有方法的挑战。在BCI病理数据集上的广泛评估表明，我们的模型在峰值信噪比（PSNR）、结构相似性指数（SSIM）和弗雷歇起始距离（FID）等方面优于现有技术，尤其是在准确转换HER2阳性（IHC 3+）图像方面。除了医学影像，我们的模型在通用图像转换任务中也表现出卓越性能，展示了其在多个领域的潜力。这项工作标志着AI驱动的精准肿瘤学迈出了重要一步，为传统的HER2诊断提供了一种可靠且高效的替代方案。

</details>


### [398] [Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review](https://arxiv.org/abs/2506.18378)
**中文标题：驯服视觉-语言模型用于医学图像分析：全面综述**

*Haoneng Lin,Cheng Xu,Jing Qin*

主要分类: eess.IV

摘要简述: 本文综述了视觉-语言模型（VLMs）在医学图像分析中的适应策略，总结了核心学习方法、五大适应策略及其在11项医学任务中的应用，分析了当前挑战并提出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分析需要多模态整合，而通用VLMs在医学领域的适应面临领域差异大、病理变化复杂等挑战。本文旨在系统总结医学VLMs的最新进展，分析问题并推荐研究方向。

研究方法: 介绍了医学VLMs的核心学习策略（预训练、微调、提示学习），分类了五大适应策略，并在11项医学任务中分析了其实际应用。

研究结果: 总结了医学VLMs的适应策略及其应用，分析了阻碍临床适应的关键挑战，并提出了未来研究方向。

研究结论: 本文为医学图像分析领域的研究者提供了对VLMs能力、局限性和技术障碍的全面理解，以促进其在临床实践中的创新、稳健和安全应用。

中文摘要: 现代视觉-语言模型（VLMs）在视觉与文本模态间的跨模态语义理解方面展现出前所未有的能力。鉴于临床应用中多模态整合的内在需求，VLMs已成为医学图像分析广泛任务的有前景解决方案。然而，将通用VLMs适应医学领域面临诸多挑战，如领域差异大、病理变化复杂以及任务多样性和独特性。本综述的核心目的是系统总结医学VLMs适应的最新进展，分析当前挑战，并推荐未来研究的紧迫方向。我们首先介绍医学VLMs的核心学习策略，包括预训练、微调和提示学习。随后分类了五大医学图像分析的VLM适应策略，并在11项医学任务中分析了其实际应用。此外，我们分析了阻碍VLMs有效适应临床应用的关键挑战，并讨论了未来研究的潜在方向。我们还提供了一个开放获取的相关文献库以促进进一步研究，访问地址为https://github.com/haonenglin/Awesome-VLM-for-MIA。本文旨在帮助对医学图像分析中利用VLMs感兴趣的研究者更好地理解其能力、局限性和当前技术障碍，以推动其在临床实践中的创新、稳健和安全应用。

</details>


### [399] [A Deep Convolutional Neural Network-Based Novel Class Balancing for Imbalance Data Segmentation](https://arxiv.org/abs/2506.18474)
**中文标题：基于深度卷积神经网络的新型类别平衡方法用于不平衡数据分割**

*Atifa Kalsoom,M. A. Iftikhar,Amjad Ali,Zubair Shah,Shidin Balakrishnan,Hazrat Ali*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习和双层类别平衡方案的新型管道BLCB-CNN，用于视网膜眼底图像中的血管分割，通过平衡血管与非血管以及厚薄血管的像素分布，结合预处理技术，实现了高精度的分割效果。


<details>
  <summary>详细信息</summary>
研究动机: 视网膜眼底图像中的血管分割由于数据分布不平衡和血管厚度变化而具有挑战性，因此需要一种能够平衡类别分布并提升分割精度的方法。

研究方法: BLCB-CNN采用卷积神经网络（CNN）和双层类别平衡方案（Level-I用于血管/非血管平衡，Level-II用于厚/薄血管平衡），并结合全局对比度归一化（GCN）、限制对比度自适应直方图均衡化（CLAHE）和伽马校正等预处理技术。

研究结果: 在标准视网膜眼底图像上，BLCB-CNN实现了ROC曲线下面积98.23%、准确率96.22%、灵敏度81.57%和特异性97.65%的优异性能，并在STARE图像上验证了其泛化能力。

研究结论: BLCB-CNN通过双层类别平衡和预处理技术，显著提升了视网膜血管分割的精度和鲁棒性，具有广泛的临床应用潜力。

中文摘要: 视网膜眼底图像提供了人眼内部结构和关键特征（如血管、视盘、黄斑和中央凹）的宝贵信息。然而，由于数据分布不平衡和血管厚度变化，视网膜血管的精确分割具有挑战性。本文提出了BLCB-CNN，一种基于深度学习和双层类别平衡方案的新型管道，用于实现视网膜眼底图像中的血管分割。BLCB-CNN方案采用卷积神经网络（CNN）架构和一种经验方法，平衡血管与非血管类别以及厚薄血管之间的像素分布。Level-I用于血管/非血管平衡，Level-II用于厚/薄血管平衡。此外，通过全局对比度归一化（GCN）、限制对比度自适应直方图均衡化（CLAHE）和伽马校正对输入图像进行预处理，以增强强度均匀性和血管与背景像素的对比度。生成的平衡数据集用于基于分类的视网膜血管树分割。我们在标准视网膜眼底图像上评估了该方案，取得了优异的性能指标，包括ROC曲线下面积98.23%、准确率96.22%、灵敏度81.57%和特异性97.65%。我们还通过在STARE图像上的外部交叉验证证明了该方法的有效性，确认了其泛化能力。

</details>


### [400] [Temporal Neural Cellular Automata: Application to modeling of contrast enhancement in breast MRI](https://arxiv.org/abs/2506.18720)
**中文标题：时间神经细胞自动机：在乳腺MRI对比增强建模中的应用**

*Daniel M. Lang,Richard Osuala,Veronika Spieker,Karim Lekadir,Rickmer Braren,Julia A. Schnabel*

主要分类: eess.IV

摘要简述: 本文提出了一种名为TeNCA（时间神经细胞自动机）的新方法，用于建模乳腺MRI中的对比增强，通过改进神经细胞自动机（NCA）架构和训练策略，生成与真实对比增强序列一致的图像，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 乳腺MRI的合成对比增强技术可以缩短成像时间并避免注射对比剂，但现有方法在时间演化一致性上表现不足。本文旨在通过改进NCA架构，解决这一问题。

研究方法: 提出TeNCA方法，扩展并优化神经细胞自动机（NCA），通过自适应损失计算和模拟物理时间演进的迭代训练策略，建模稀疏且非均匀采样的时间序列数据。

研究结果: 在多样化的乳腺MRI数据集上验证了TeNCA的有效性，其生成的图像与真实对比增强序列高度一致，性能优于现有方法。

研究结论: TeNCA为乳腺MRI的合成对比增强提供了一种高效且生理学合理的建模方法，具有广泛的应用潜力。

中文摘要: 合成对比增强技术能够快速获取图像并避免静脉注射对比剂，这对乳腺成像尤为重要，因为长成像时间和高成本限制了MRI作为广泛筛查手段的适用性。近期研究证明了合成对比生成的可行性，但现有方法在时间演化一致性上表现不足。神经细胞自动机（NCA）提供了一种轻量且鲁棒的架构，用于建模相邻细胞或像素间的演化模式。本文提出TeNCA（时间神经细胞自动机），扩展并优化了NCA，以有效建模稀疏且非均匀采样的时间序列数据。为此，我们改进了训练策略，引入自适应损失计算，并定义方法的迭代特性以模拟物理时间演进，从而使模型学习生理学合理的对比增强演化。我们在多样化的乳腺MRI数据集上严格训练和测试TeNCA，证明其在生成与真实对比增强序列一致的图像方面优于现有方法。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [401] [Embedded FPGA Acceleration of Brain-Like Neural Networks: Online Learning to Scalable Inference](https://arxiv.org/abs/2506.18530)
**中文标题：嵌入式FPGA加速脑类似神经网络：从在线学习到可扩展推理**

*Muhammad Ihsan Al Hafiz,Naresh Ravichandran,Anders Lansner,Pawel Herman,Artur Podobas*

主要分类: cs.AR

摘要简述: 本文提出了一种基于嵌入式FPGA的脑神经网络加速器，首次在Zynq UltraScale+ SoC上实现了BCPNN的在线学习和推理功能，显著降低了延迟和能耗，适用于边缘设备。


<details>
  <summary>详细信息</summary>
研究动机: 边缘AI应用需要低功耗、自适应学习的模型，传统深度学习模型能耗高且依赖云端。脑神经网络（如BCPNN）具有稀疏架构和局部学习规则，适合边缘设备，但现有实现依赖GPU或数据中心FPGA，限制了嵌入式应用。

研究方法: 使用高层次综合（HLS）在Zynq UltraScale+ SoC上实现嵌入式FPGA加速器，支持可变和混合精度的在线学习和推理功能。

研究结果: 在MNIST、肺炎和乳腺癌数据集上的实验表明，该加速器比ARM基线降低了17.5倍的延迟和94%的能耗，同时保持准确性。

研究结论: 该研究实现了边缘设备上的实用神经形态计算，填补了脑类似学习与实际部署之间的空白。

中文摘要: 边缘AI应用越来越需要能够在设备上以最低能耗学习和适应的模型。传统深度学习模型虽然强大，但通常参数过多、能耗高且依赖云端连接。脑类似神经网络（如贝叶斯置信传播神经网络，BCPNN）通过模仿皮层架构和生物约束学习，提出了一种神经形态替代方案。它们具有稀疏架构和局部学习规则，支持无监督/半监督学习，非常适合低功耗边缘智能。然而，现有的BCPNN实现依赖于GPU或数据中心FPGA，限制了其在嵌入式系统中的应用。本研究首次在Zynq UltraScale+ SoC上使用高层次综合实现了嵌入式FPGA加速器，支持可变和混合精度的在线学习和推理功能。在MNIST、肺炎和乳腺癌数据集上的评估表明，该加速器比ARM基线降低了17.5倍的延迟和94%的能耗，同时未牺牲准确性。这项研究实现了边缘设备上的实用神经形态计算，填补了脑类似学习与实际部署之间的空白。

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [402] [Modal Logic for Stratified Becoming: Actualization Beyond Possible Worlds](https://arxiv.org/abs/2506.17276)
**中文标题：分层生成的模态逻辑：超越可能世界的实际化**

*Alexandre Le Nepvou*

主要分类: cs.LO

摘要简述: 本文提出了一种基于分层实现而非传统可能世界模型的模态逻辑新框架——分层实现逻辑（SAL），通过分层索引模态操作，捕捉实际化过程的局部性和动态性，并证明了其完备性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 传统克里普克语义学将模态操作视为对完全确定性替代方案的量化，忽略了实际化过程的局部性、动态性和不对称性。本文旨在开发一种更贴近实际化过程本质的模态逻辑框架。

研究方法: 提出分层实现逻辑（SAL），将模态操作按本体稳定性层级索引，解释为可容许性机制。通过定义SAL的语法和语义，引入公理，并证明其完备性和可靠性。

研究结果: SAL成功捕捉了实际化的本体结构，无需依赖抽象的可能世界模型，为时间生成、量子退相干领域和模态形而上学提供了新的逻辑工具。

研究结论: 分层实现逻辑（SAL）为模态逻辑提供了一种分层替代方案，更准确地反映了实际化过程的动态性和局部性，具有广泛的应用潜力。

中文摘要: 本文基于分层实现而非传统的全局可能世界模型，提出了一种新的模态逻辑框架。传统克里普克语义学将模态操作视为对完全确定性替代方案的量化，忽略了实际化过程的局部性、动态性和不对称性。我们提出了一种分层实现逻辑（SAL），其中模态操作按本体稳定性层级索引，解释为可容许性机制。每个模态操作作用于一个结构化的可能性层级，基于层级间转换的内在一致性。我们形式化定义了SAL的语法和语义，引入了其公理，并证明了其完备性和可靠性。讨论了其在时间生成、量子退相干领域和模态形而上学中的应用。结果表明，SAL无需依赖抽象的可能世界模型即可捕捉实际化的本体结构，为标准的模态实在论提供了一种分层替代方案。

</details>


### [403] [Beyond Prediction -- Structuring Epistemic Integrity in Artificial Reasoning Systems](https://arxiv.org/abs/2506.17331)
**中文标题：超越预测——构建人工智能推理系统中的认知完整性**

*Craig Steven Wright*

主要分类: cs.LO

摘要简述: 本文提出了一种严格认知约束下的人工智能系统框架，超越随机语言预测，支持结构化推理、命题承诺和矛盾检测，确保真理保持和可审计的理性认知代理。


<details>
  <summary>详细信息</summary>
研究动机: 当前人工智能系统主要依赖随机语言预测，缺乏结构化推理和认知约束。本文旨在解决这一问题，构建一个支持严格认知约束、真理保持和可审计性的框架。

研究方法: 通过形式化信念表示、元认知过程和规范性验证，整合符号推理、知识图谱和基于区块链的论证，确保系统的真理保持和理性。

研究结果: 开发了一个综合框架，支持结构化推理、命题承诺和矛盾检测，同时具备真理保持和可审计性。

研究结论: 本文提出的框架为人工智能系统在严格认知约束下的运作提供了理论基础和实践方法，推动了理性认知代理的发展。

中文摘要: 本文开发了一个全面的人工智能系统框架，在严格的认知约束下运行，超越随机语言预测，支持结构化推理、命题承诺和矛盾检测。它形式化了信念表示、元认知过程和规范性验证，整合了符号推理、知识图谱和基于区块链的论证，以确保真理保持、可审计的理性认知代理。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [404] [OmniESI: A unified framework for enzyme-substrate interaction prediction with progressive conditional deep learning](https://arxiv.org/abs/2506.17963)
**中文标题：OmniESI：基于渐进条件深度学习的酶-底物相互作用预测统一框架**

*Zhiwei Nie,Hongyu Zhang,Hao Jiang,Yutian Liu,Xiansong Huang,Fan Xu,Jie Fu,Zhixiang Ren,Yonghong Tian,Wen-Bin Zhang,Jie Chen*

主要分类: q-bio.BM

摘要简述: OmniESI是一个基于渐进条件深度学习的统一框架，用于预测酶-底物相互作用，通过两阶段渐进过程结合催化特异性，显著提升预测性能，适用于多种下游任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法未能充分利用酶催化的先验知识来调整与催化模式不匹配的蛋白质-分子特征，因此需要一种能够结合催化特异性并逐步优化特征的预测框架。

研究方法: OmniESI采用两阶段渐进框架，通过两个条件网络分别强调酶反应特异性和关键催化相关相互作用，逐步在潜在空间中将特征从通用蛋白质-分子领域调整到催化感知领域。

研究结果: 在多个基准测试中，OmniESI在分布内和分布外设置下均优于现有方法，且通过关键组件的消融研究证明其仅增加0.16%参数即可显著提升性能。

研究结论: OmniESI为酶-底物相互作用提供了一种统一的预测方法，具有强大的泛化能力和广泛适用性，是催化机制研究和酶工程的有效工具。

中文摘要: 理解和建模酶-底物相互作用对于催化机制研究、酶工程和代谢工程至关重要。尽管已有大量预测方法，但它们未能结合酶催化的先验知识来合理调整与催化模式不匹配的通用蛋白质-分子特征。为解决这一问题，我们提出了OmniESI，一个基于条件深度学习的两阶段渐进框架，用于预测酶-底物相互作用。通过将酶-底物相互作用的建模分解为两阶段渐进过程，OmniESI结合了两个条件网络，分别强调酶反应特异性和关键催化相关相互作用，从而在潜在空间中逐步将特征从通用蛋白质-分子领域调整到催化感知领域。在这一统一架构的基础上，OmniESI可适应多种下游任务，包括酶动力学参数预测、酶-底物配对预测、酶突变效应预测和酶活性位点注释。在分布内和分布外设置的多视角性能评估中，OmniESI在七个基准测试中均优于现有专用方法。更重要的是，所提出的条件网络能够内化催化效率的基本模式，同时显著提升预测性能，而参数仅增加0.16%（关键组件的消融研究证实了这一点）。总体而言，OmniESI为酶-底物相互作用提供了一种统一的预测方法，具有强大的泛化能力和广泛适用性，是催化机制破解和酶工程的有效工具。

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [405] [Wisdom of Crowds Through Myopic Self-Confidence Adaptation](https://arxiv.org/abs/2506.18195)
**中文标题：通过短视自信调整实现的群体智慧**

*Giacomo Como,Fabio Fagnani,Anton Proskurnikov*

主要分类: math.OC

摘要简述: 本文研究了群体智慧现象，探讨了在迭代学习过程中，个体如何通过调整自信权重来优化集体决策的准确性。研究发现，通过博弈论方法可以找到最优权重分配，并证明了异步最佳响应动态会收敛到严格纳什均衡。


<details>
  <summary>详细信息</summary>
研究动机: 群体智慧现象表明，集体决策可能比个体决策更准确，但若个体意见受少数影响者主导，准确性会降低。本文旨在探讨个体如何通过调整自信权重来优化集体决策的准确性。

研究方法: 研究假设个体初始拥有对世界状态的独立噪声测量，并通过迭代学习规则（如法国-德格鲁特动态）更新估计值。个体通过博弈论方法优化权重分配，以最小化估计方差。

研究结果: 研究刻画了博弈的帕累托前沿和纳什均衡集，并证明异步最佳响应动态会收敛到严格纳什均衡。

研究结论: 通过博弈论方法，个体可以优化自信权重分配，从而提高集体决策的准确性，异步动态收敛性为实际应用提供了理论支持。

中文摘要: 群体智慧是一个泛指现象，表明大规模群体的集体判断或决策可能比个体判断或决策更准确。一个著名的例子是Galton描述的乡村集市比赛，其中个体对牛重量的猜测中位数惊人地接近实际重量。这种现象类似于概率论中的经典结果，依赖于独立决策。若最终代理意见受少数影响者主导，群体决策的准确性会显著降低。
  本文研究了一组代理，他们最初拥有对世界状态的独立且无偏的噪声测量。假设这些代理根据简单的非贝叶斯学习规则（数学社会学中称为法国-德格鲁特动态或迭代意见池）迭代更新其估计。通过这种迭代分布式平均过程，每个代理最终得到世界状态的渐近估计，其方差由代理间分配的权重矩阵决定。每个代理旨在最小化其渐近估计的方差，但该方差也受其他代理分配权重的影响。为实现最佳估计，代理需解决由可用影响权重集定义的博弈论多目标优化问题。我们刻画了博弈的帕累托前沿和纳什均衡集，并研究了代理组的异步最佳响应动态，证明其收敛到严格纳什均衡集。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [406] [Spiffy: Efficient Implementation of CoLaNET for Raspberry Pi](https://arxiv.org/abs/2506.18306)
**中文标题：Spiffy：为树莓派高效实现CoLaNET**

*Andrey Derzhavin,Denis Larionov*

主要分类: cs.NE

摘要简述: 本文提出了一种轻量级软件方法Spiffy，用于在普通计算平台上高效运行脉冲神经网络（SNN）CoLaNET，无需依赖专用神经形态硬件。以Raspberry Pi为例，Spiffy在MNIST数据集上实现了92%的准确率，训练和推理延迟分别仅为0.9毫秒和0.45毫秒。


<details>
  <summary>详细信息</summary>
研究动机: 当前运行脉冲神经网络通常需要专用硬件或框架，限制了其广泛应用。本文旨在通过软件优化，在普通计算平台上高效实现SNN，降低部署门槛。

研究方法: 采用Rust语言实现特定SNN架构CoLaNET，并进行优化，使其适用于普通计算平台。以Raspberry Pi为案例，展示了其在MNIST数据集上的性能。

研究结果: Spiffy在Raspberry Pi上实现了92%的准确率，训练和推理延迟分别为0.9毫秒和0.45毫秒，代码开源。

研究结论: Spiffy证明了通过软件优化可在普通计算平台上高效运行SNN，为广泛部署提供了可行方案。

中文摘要: 本文提出了一种轻量级的软件方法，用于在不依赖专用神经形态硬件或框架的情况下运行脉冲神经网络（SNN）。我们采用Rust语言实现了一种特定的SNN架构（CoLaNET），并针对普通计算平台进行了优化。作为案例研究，我们在树莓派上使用MNIST数据集展示了我们的实现（称为Spiffy）。Spiffy实现了92%的准确率，训练和推理延迟分别仅为0.9毫秒和0.45毫秒。代码已开源。

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [407] [PaceLLM: Brain-Inspired Large Language Models for Long-Context Understanding](https://arxiv.org/abs/2506.17310)
**中文标题：PaceLLM：基于大脑启发的长上下文理解大语言模型**

*Kangcong Li,Peng Ye,Chongjun Tu,Lin Zhang,Chunfeng Song,Jiamin Wu,Tao Yang,Qihao Zheng,Tao Chen*

主要分类: q-bio.NC

摘要简述: PaceLLM是一种受大脑启发的长上下文理解大语言模型，通过持久活动机制和皮层专家聚类解决了信息衰减和语义碎片化问题，显著提升了长上下文任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有大语言模型在长上下文任务中因神经激活短暂和权重结构松散导致信息衰减和语义碎片化，限制了其性能。受大脑工作记忆和皮层模块化启发，研究旨在优化模型的长上下文能力。

研究方法: PaceLLM引入两种创新机制：(1) 持久活动机制，模拟前额叶神经元的持续放电，动态管理关键网络状态；(2) 皮层专家聚类，重组权重为语义模块，增强跨令牌依赖。

研究结果: 实验显示，PaceLLM在LongBench多文档问答任务上提升6%，在Infinite-Bench任务上提升12.5-17.5%，并在NIAH测试中将可测量上下文长度扩展至20万令牌。

研究结论: PaceLLM通过脑启发优化显著提升大语言模型的长上下文性能和可解释性，且无需结构改造，具有广泛适用性。

中文摘要: 尽管大语言模型（LLMs）在各领域表现优异，但其长上下文能力受限于神经激活短暂导致的信息衰减和权重结构松散引发的语义碎片化。受大脑工作记忆和皮层模块化启发，我们提出PaceLLM，包含两项创新：(1) 持久活动机制（PA），模拟前额叶神经元持续放电，通过激活级记忆库动态检索、重用和更新关键网络状态，解决上下文衰减；(2) 皮层专家聚类（CE），模拟任务适应性神经特化，将网络权重重组为语义模块，建立跨令牌依赖并减少碎片化。大量实验表明，PaceLLM在LongBench多文档问答任务上提升6%，在Infinite-Bench任务上提升12.5-17.5%，并在“大海捞针”测试中将可测量上下文长度扩展至20万令牌。该研究开创了脑启发的大语言模型优化方法，与其他工作互补，且无需结构改造即可提升模型的长上下文性能和可解释性。

</details>


### [408] [Challenges in Grounding Language in the Real World](https://arxiv.org/abs/2506.17375)
**中文标题：语言与现实世界结合的挑战**

*Peter Lindes,Kaoutar Skiker*

主要分类: q-bio.NC

摘要简述: 本文探讨了人工智能中语言与现实世界结合的挑战，提出了一种结合认知代理与大型语言模型的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 人工智能的长期目标是构建一个语言理解系统，使人类能够通过自然语言与物理机器人协作。本文旨在解决这一过程中的挑战。

研究方法: 提出了一种将认知代理的交互式任务学习能力与大型语言模型的语言能力相结合的解决方案。

研究结果: 初步实现了一种整合认知代理和语言模型的方法，为未来研究指明了方向。

研究结论: 通过整合认知代理与语言模型，为解决语言与现实世界结合的挑战提供了可行路径。

中文摘要: 人工智能的长期目标是构建一个语言理解系统，使人类能够通过自然语言与物理机器人协作。本文探讨了实现这一目标的一些挑战，并提出了一种解决方案，该方案将具备交互式任务学习能力的认知代理与大型语言模型的语言能力相结合。同时，我们还指出了这一方法的初步实现方向。

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [409] [Pix2Geomodel: A Next-Generation Reservoir Geomodeling with Property-to-Property Translation](https://arxiv.org/abs/2506.17747)
**中文标题：Pix2Geomodel：下一代储层地质建模与属性间转换**

*Abdulrahman Al-Fakih,Ardiansyah Koeshidayatullah,Nabil A. Saraih,Tapan Mukerji,Rayan Kanfar,Abdulmohsen Alali,SanLinn I. Kaka*

主要分类: physics.geo-ph

摘要简述: 本文提出Pix2Geomodel，一种基于Pix2Pix的条件生成对抗网络（cGAN）框架，用于从荷兰Groningen气田的Rotliegend储层预测储层属性（岩相、孔隙度、渗透率和含水饱和度）。该方法在数据预处理和增强后，通过U-Net生成器和PatchGAN判别器训练，表现出高精度和地质真实性，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统地质建模方法难以应对复杂的地下异质性和观测数据条件限制，因此需要一种更高效且精确的方法来预测储层属性。

研究方法: 研究采用Pix2Pix框架的cGAN模型，利用760万单元数据集进行预处理和增强，生成每种属性的2350张图像，并通过U-Net生成器和PatchGAN判别器进行训练。评估指标包括像素准确率（PA）、平均交并比（mIoU）和频率加权交并比（FWIoU）。

研究结果: 结果显示，岩相（PA 0.88，FWIoU 0.85）和含水饱和度（PA 0.96，FWIoU 0.95）预测精度高，孔隙度（PA 0.70，FWIoU 0.55）和渗透率（PA 0.74，FWIoU 0.60）表现中等，属性间转换性能稳健（如岩相到岩相PA 0.98，FWIoU 0.97）。

研究结论: Pix2Geomodel在储层属性预测中表现出色，具有地质真实性和空间变异性，优于传统方法。未来需解决微观结构变异性和2D限制，并探索多模态数据和3D建模（Pix2Geomodel v2.0）。

中文摘要: 精确的地质建模对储层表征至关重要，但传统方法难以应对复杂的地下异质性和观测数据条件限制。本研究提出Pix2Geomodel，一种基于Pix2Pix的条件生成对抗网络（cGAN）框架，用于从荷兰Groningen气田的Rotliegend储层预测储层属性（岩相、孔隙度、渗透率和含水饱和度）。通过EPOS-NL获取的760万单元数据集，方法包括数据预处理、增强（每种属性生成2350张图像），以及使用U-Net生成器和PatchGAN判别器进行19000步训练。评估指标包括像素准确率（PA）、平均交并比（mIoU）、频率加权交并比（FWIoU），并通过可视化评估掩模属性预测和属性间转换任务的性能。结果显示岩相（PA 0.88，FWIoU 0.85）和含水饱和度（PA 0.96，FWIoU 0.95）预测精度高，孔隙度（PA 0.70，FWIoU 0.55）和渗透率（PA 0.74，FWIoU 0.60）表现中等，属性间转换性能稳健（如岩相到岩相PA 0.98，FWIoU 0.97）。该框架捕捉了空间变异性和地质真实性，并通过变差函数分析验证。与传统方法相比，Pix2Geomodel在直接属性映射中具有更高的保真度。局限性包括微观结构变异性和2D限制，未来需整合多模态数据和3D建模（Pix2Geomodel v2.0）。本研究推动了生成式AI在地球科学中的应用，支持改进储层管理和开放科学倡议。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [410] [Distinguishing Predictive and Generative AI in Regulation](https://arxiv.org/abs/2506.17347)
**中文标题：监管中区分预测式AI与生成式AI**

*Jennifer Wang,Andrew Selbst,Solon Barocas,Suresh Venkatasubramanian*

主要分类: cs.CY

摘要简述: 本文探讨了生成式AI与预测式AI在监管上的差异，指出现有监管工具对生成式AI的适用性不足，并提出四点关键区别及三条政策建议。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI的兴起，现有基于预测式AI的监管工具已无法满足需求，政策制定者需重新评估监管框架以适应新技术的特点。

研究方法: 通过分析生成式AI的四个独特方面（通用性、评估难度、法律问题及价值链结构），提出其与预测式AI的差异，并基于此提出政策建议。

研究结果: 识别出生成式AI的四个关键特征，表明现有监管工具对其不适用，并建议政策制定者调整监管目标和约束机制。

研究结论: 政策制定者需区分生成式AI与预测式AI的监管需求，重新设计政策以应对生成式AI的独特风险。

中文摘要: 过去十年，政策制定者开发了一系列监管工具，以确保AI发展符合社会目标。这些工具最初是为应对预测式AI的问题而设计，因此隐含了对AI系统性质和监管效用的假设。然而，随着生成式AI的出现，这些假设不再成立，尽管政策制定者试图将两者纳入同一监管框架。本文指出生成式AI的四个独特方面，需要不同的政策应对：通用性和适应性使其难以成为监管目标、评估设计的困难、新的法律问题改变了利益相关者和专家来源的生态系统，以及生成式AI价值链的分布式结构。基于这些差异，政策制定者需评估过去十年的监管工作是否仍适用，并设计新政策以应对生成式AI的独特风险。本文提出三条建议，帮助政策制定者更有效地识别监管目标并利用生态系统中的约束来治理生成式AI。

</details>


### [411] [The Democratic Paradox in Large Language Models' Underestimation of Press Freedom](https://arxiv.org/abs/2506.18045)
**中文标题：大型语言模型低估新闻自由的民主悖论**

*I. Loaiza,R. Vestrelli,A. Fronzetti Colladon,R. Rigobon*

主要分类: cs.CY

摘要简述: 研究发现六种流行的大型语言模型（LLMs）在评估180个国家新闻自由时存在系统性偏差，普遍低估新闻自由，且对本国存在正向偏见。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLMs在全球信息获取中的角色日益重要，其偏见可能影响公众对新闻自由等民主制度的理解与信任，因此需研究其评估准确性。

研究方法: 研究比较了六种LLMs对180个国家新闻自由的评估与世界新闻自由指数（WPFI）的专家评估，分析其偏差模式。

研究结果: LLMs普遍低估新闻自由（71%-93%国家被低估），且在新闻自由较高的国家低估更严重；五种LLMs对本国存在正向偏见（高估7%-260%）。

研究结论: 若LLMs成为下一代搜索引擎和文化工具，必须确保其对全球人权与公民权利的准确评估。

中文摘要: 随着大型语言模型（LLMs）在全球范围内为数百万人提供信息中介服务，其偏见可能影响公众对新闻自由等民主制度的理解与信任。本研究揭示了六种流行LLMs在评估180个国家新闻自由时与世界新闻自由指数（WPFI）专家评估相比存在的三种系统性偏差。这些LLMs普遍低估新闻自由，71%至93%的国家被低估。我们还发现了一种称为“差异偏差”的悖论模式：LLMs对新闻自由较高的国家低估更严重。此外，六种模型中有五种对本国存在正向偏见，高估本国新闻自由（7%至260%）。若LLMs成为下一代搜索引擎和文化工具，必须确保其对全球人权与公民权利的准确评估。

</details>


### [412] [Automatic Large Language Models Creation of Interactive Learning Lessons](https://arxiv.org/abs/2506.17356)
**中文标题：大型语言模型自动生成交互式学习课程**

*Jionghao Lin,Jiarui Rao,Yiyang Zhao,Yuting Wang,Ashish Gurung,Amanda Barany,Jaclyn Ocumpaugh,Ryan S. Baker,Kenneth R. Koedinger*

主要分类: cs.CY

摘要简述: 本文探讨了利用大型语言模型自动生成交互式学习课程的方法，旨在培训在线初中数学新手导师。通过任务分解提示策略，系统生成的课程在结构和内容上表现优异，但也存在反馈泛化和部分教学环节不清晰的问题。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决新手导师培训中缺乏高效、结构化课程的问题，探索大型语言模型在生成交互式学习课程中的潜力，以提升培训效率和质量。

研究方法: 采用检索增强生成方法（RAG）结合GPT-4o，通过任务分解提示策略将课程生成分为多个子任务，生成三个关键主题的英语课程。

研究结果: 任务分解策略生成的课程评分高于单步生成，内容结构良好且节省时间，但存在反馈泛化和部分教学环节不清晰的问题。

研究结论: 研究表明，结合人类与AI的混合方法在生成高效导师培训课程方面具有潜力，未来需进一步优化反馈和教学环节的清晰度。

中文摘要: 本文探讨了自动生成交互式、基于场景的课程，旨在培训在线初中数学新手导师。通过检索增强生成方法（RAG）结合GPT-4o，我们开发了一个能够生成结构化导师培训课程的系统。研究中，我们采用任务分解提示策略，将课程生成分为多个子任务，生成了三个关键主题的英语课程：鼓励学生独立性、鼓励求助行为和开启摄像头。生成的课程由两名人类评估者根据课程设计研究制定的综合评分标准进行定量和定性评估。结果表明，任务分解策略生成的课程评分高于单步生成。评估者指出，大型语言模型生成的课程在内容结构和节省时间方面表现优异，但也存在反馈泛化和部分教学环节不清晰的问题。这些发现强调了人机混合方法在生成高效导师培训课程方面的潜力。

</details>


### [413] [A Large-Scale Real-World Evaluation of LLM-Based Virtual Teaching Assistant](https://arxiv.org/abs/2506.17363)
**中文标题：基于大型语言模型的虚拟教学助手在大规模真实课堂中的评估**

*Sunjun Kweon,Sooyohn Nam,Hyunseung Lim,Hwajung Hong,Edward Choi*

主要分类: cs.CY

摘要简述: 本研究通过大规模实证评估，探讨了基于大型语言模型（LLM）的虚拟教学助手（VTA）在实际课堂中的效果和接受度，分析了学生互动模式，并与传统师生互动对比，提出了推广VTA的关键挑战。


<details>
  <summary>详细信息</summary>
研究动机: 虚拟教学助手（VTA）在提升学生学习体验方面具有潜力，但其实际效果和接受度缺乏实证研究。本研究旨在填补这一空白，评估VTA在真实课堂中的表现。

研究方法: 研究开发了一个基于LLM的VTA，并在477名研究生的AI编程课程中部署。通过三轮问卷调查和3,869组学生-VTA互动数据分析，评估VTA的表现和互动模式，并与传统师生互动进行对比。

研究结果: 研究发现，学生对VTA的接受度随时间变化，互动分析揭示了常见问题类型和参与模式。VTA在提供即时反馈方面表现良好，但在复杂问题上仍需改进。

研究结论: 研究表明，VTA在实际课堂中具有可行性，但需解决复杂问题处理等挑战。研究开源了VTA系统代码，推动AI驱动教育的未来发展。

中文摘要: 基于大型语言模型（LLM）的虚拟教学助手（VTA）能够通过即时反馈和多轮互动提升学生学习效果，但其在实际课堂中的效果和接受度缺乏实证研究。本研究开发了一个基于LLM的VTA，并在477名研究生的AI编程课程中部署。通过三轮问卷调查和3,869组学生-VTA互动数据分析，评估了学生对VTA的感知变化、常见问题类型和互动模式，并与传统师生互动进行对比。通过大规模实证研究和互动分析，本研究评估了VTA在真实课堂中的可行性，并指出了推广的关键挑战。最后，研究开源了VTA系统代码，以促进AI驱动教育的未来发展：\texttt{https://github.com/sean0042/VTA}。

</details>


### [414] [AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning](https://arxiv.org/abs/2506.17364)
**中文标题：基于AI的多模态生物特征检测智能手机分心：应用于在线学习**

*Alvaro Becerra,Roberto Daza,Ruth Cobos,Aythami Morales,Mutlu Cukurova,Julian Fierrez*

主要分类: cs.CY

摘要简述: 本研究利用多模态生物特征检测在线学习中因智能手机使用导致的注意力分散，结合生理信号和头部姿态数据，多模态模型准确率达91%。


<details>
  <summary>详细信息</summary>
研究动机: 在线学习中，学习者常因智能手机使用等因素分心，传统学习平台缺乏详细行为数据。多模态学习分析和生物传感器为注意力监测提供新思路。

研究方法: 提出一种基于AI的方法，结合生理信号（如脑电波、心率）和头部姿态数据，检测智能手机使用导致的注意力分散。

研究结果: 单一生物信号（如脑电波或心率）准确率有限，头部姿态单独准确率为87%，多模态模型结合所有信号后准确率达91%。

研究结论: 多模态模型显著提升检测准确率，但需讨论其在在线学习环境中实时支持的可行性与局限性。

中文摘要: 本研究探讨了利用多模态生物特征检测因智能手机使用导致的注意力分散问题，重点关注计算机在线学习场景。尽管方法适用于自动驾驶等领域，但本研究聚焦学习者在内部（如动机）、系统相关（如课程设计）和情境（如智能手机使用）因素下维持注意力的挑战。传统学习平台常缺乏详细行为数据，而多模态学习分析（MMLA）和生物传感器为学习者注意力提供了新视角。我们提出一种基于AI的方法，利用生理信号和头部姿态数据检测手机使用。结果显示，单一生物信号（如脑电波或心率）准确率有限，而头部姿态单独准确率达87%。结合所有信号的多模态模型准确率达91%，凸显了整合的优势。最后讨论了这些模型在在线学习环境中实时支持的应用与局限性。

</details>


### [415] [AI based Content Creation and Product Recommendation Applications in E-commerce: An Ethical overview](https://arxiv.org/abs/2506.17370)
**中文标题：电子商务中基于AI的内容创作与产品推荐应用的伦理概述**

*Aditi Madhusudan Jain,Ayush Jain*

主要分类: cs.CY

摘要简述: 本文探讨了电子商务中基于AI的内容创作和产品推荐的伦理问题，提出了消除偏见和确保公平的实践建议。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在电子商务中的广泛应用，其在内容创作和产品推荐方面的优势显著，但也引发了数据隐私、算法偏见和消费者自主权等伦理挑战。本文旨在分析这些问题并提出解决方案。

研究方法: 通过分析AI在电子商务中的应用案例（如亚马逊和Shopify），识别潜在的伦理问题，并提出消除偏见、确保透明度和公平性的具体方法，如算法审计、多样化训练数据和公平性指标。

研究结果: 研究发现，AI模型可能嵌入文化、性别或社会经济偏见，导致不公平的产品推荐。本文提出了消除这些偏见的实践建议，并讨论了保护消费者隐私和增强透明度的伦理框架。

研究结论: 为确保AI在电子商务中的伦理使用，需要建立公平、透明的标准，并通过多样化数据和定期审计消除偏见，同时保护消费者隐私和自主权。

中文摘要: 随着电子商务迅速整合人工智能用于内容创作和产品推荐，这些技术在个性化和效率方面带来了显著优势。AI驱动的系统自动化生成产品描述、动态广告，并根据消费者行为提供定制推荐，如亚马逊和Shopify等主要平台所示。然而，AI在电子商务中的广泛应用引发了关键的伦理挑战，尤其是围绕数据隐私、算法偏见和消费者自主权的问题。偏见——无论是文化、性别还是社会经济层面的——可能无意中嵌入AI模型，导致不公平的产品推荐并强化有害的刻板印象。本文探讨了AI驱动的内容创作和产品推荐的伦理影响，强调需要建立框架以确保公平性、透明度和更完善的伦理标准。我们提出了消除偏见和确保包容性的可行最佳实践，如定期审计算法、多样化训练数据以及将公平性指标纳入AI模型。此外，我们讨论了以保护消费者数据隐私、促进决策过程透明度和增强消费者自主权为核心的伦理合规框架。通过解决这些问题，我们为电子商务中负责任地使用AI进行内容创作和产品推荐提供了指导，确保这些技术既高效又符合伦理。

</details>


### [416] [Multimodal Political Bias Identification and Neutralization](https://arxiv.org/abs/2506.17372)
**中文标题：多模态政治偏见识别与中和**

*Cedric Bernard,Xavier Pleimling,Amun Kharel,Chase Vickery*

主要分类: cs.CY

摘要简述: 本文提出了一种多模态政治偏见识别与中和模型，结合文本和图像处理，通过四步方法实现偏见检测与中和，初步结果显示效果良好但需进一步优化。


<details>
  <summary>详细信息</summary>
研究动机: 政治回音室现象使得从政治文章文本和图像中检测并消除主观偏见和情绪化语言变得至关重要。以往研究仅关注文本偏见，忽略了图像作为信息传递媒介的重要性，因此本文旨在填补这一空白。

研究方法: 模型分为四步：1) 图像文本对齐（通过CLIP模型语义对齐图像偏见）；2) 图像偏见评分（通过ViT分类器评分）；3) 文本去偏见（通过BERT模型检测并中和偏见词句）；4) 最终去偏见（替换为中和后的文本和图像）。

研究结果: 初步结果显示文本去偏见策略能有效识别潜在偏见词句，ViT模型训练效果良好，语义对齐模型效率高，但需更多时间和资源优化结果。还提出人工评估以确保生成内容语义一致性。

研究结论: 该多模态方法在政治偏见识别与中和方面具有潜力，但仍需进一步优化训练和资源投入以提升效果。

中文摘要: 由于政治回音室的存在，从政治文章的文本和图像中检测并消除主观偏见和情绪化语言变得至关重要。然而，以往研究仅关注文本部分的偏见，而忽略了图像作为信息传递媒介的同等重要性。为此，我们提出了一种结合文本和图像偏见的模型，包含四个步骤：图像文本对齐（通过CLIP模型语义对齐图像偏见）、图像偏见评分（通过ViT分类器评分）、文本去偏见（通过BERT模型检测并中和偏见词句）以及最终的去偏见步骤（替换为中和后的文本和图像，图像部分通过比较偏见分数实现）。初步结果表明该方法具有潜力，文本去偏见策略能识别大量潜在偏见词句，ViT模型训练效果良好，语义对齐模型效率高，但仍需更多时间和资源以获得更好结果。此外，还提出人工评估以确保生成文本和图像的语义一致性。

</details>


### [417] [Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps](https://arxiv.org/abs/2506.17577)
**中文标题：通过快进跳过过度练习步骤优化掌握学习**

*Meng Xia,Robin Schmucker,Conrad Borchers,Vincent Aleven*

主要分类: cs.CY

摘要简述: 本文提出了一种名为“快进”的技术，通过跳过学生已掌握的解题步骤，减少过度练习，提升学习效率。模拟研究表明，该方法可减少高达三分之一的过度练习。


<details>
  <summary>详细信息</summary>
研究动机: 掌握学习虽能提升学习效果，但学生在已掌握技能上的过度练习仍是辅导系统的核心挑战。现有研究多通过改进题目选择算法或设计针对性练习任务来减少过度练习，但鲜有关注步骤级别的适应性调整。

研究方法: 提出“快进”技术，基于学习者模型和真实学生数据的解题路径模拟，跳过学生已完全掌握的解题步骤，无需完成所有步骤即可继续学习。该方法适用于任何题目选择算法，尤其适合偏好选择难题的算法。

研究结果: 模拟研究表明，“快进”技术可减少高达三分之一的过度练习时间，且其效果在偏好选择难题的算法中表现最佳。

研究结论: “快进”技术能显著提升学习效率，但其实际效果还取决于学生在高难度学习中的持续动机和参与度。

中文摘要: 掌握学习能提升学习熟练度和效率，但学生在已掌握技能上的过度练习仍是辅导系统的核心挑战。以往研究通过改进题目选择算法或设计针对性练习任务来减少过度练习，但鲜有关注步骤级别的适应性调整。本文提出并评估了“快进”技术，通过增强现有题目选择算法，跳过学生已完全掌握的解题步骤。基于真实学生数据的学习者模型和解题路径模拟研究表明，“快进”技术可减少高达三分之一的过度练习时间。该方法灵活适用于任何题目选择算法，但在偏好选择难题的算法中效果最佳。因此，尽管“快进”技术能提升学习效率，其实际效果还取决于学生在高难度学习中的持续动机和参与度。

</details>


### [418] [MAARTA:Multi-Agentic Adaptive Radiology Teaching Assistant](https://arxiv.org/abs/2506.17320)
**中文标题：MAARTA：多智能体自适应放射学教学助手**

*Akash Awasthi,Brandon V. Chang,Anh M. Vu,Ngan Le,Rishi Agrawal,Zhigang Deng,Carol Wu,Hien Van Nguyen*

主要分类: cs.CY

摘要简述: MAARTA是一个多智能体框架，通过分析视线模式和放射学报告提供个性化反馈，帮助放射学学生减少视觉搜索和诊断解释中的错误。


<details>
  <summary>详细信息</summary>
研究动机: 放射学学生因缺乏专家指导时间，常出现视觉搜索和诊断解释错误，现有AI系统仅关注诊断准确性，无法解释错误原因。MAARTA旨在填补这一空白。

研究方法: MAARTA采用多智能体框架，动态选择智能体分析错误复杂性，通过结构化图表比较专家与学生视线行为，识别遗漏发现并分配感知错误教师智能体分析差异，逐步提示学生改进。

研究结果: MAARTA能够识别学生与专家视线行为的差异，提供个性化反馈，帮助学生理解错误并提升诊断推理能力。

研究结论: MAARTA通过多智能体框架和个性化反馈，推动了AI驱动的放射学教育发展，有效帮助学生减少诊断错误。

中文摘要: 放射学学生常因专家指导时间有限而难以发展感知专业知识，导致视觉搜索和诊断解释错误。这些错误（如遗漏注视、短暂停留或误判）未被当前AI系统充分解决，后者仅关注诊断准确性而未能解释错误原因。为此，我们提出MAARTA（多智能体自适应放射学教学助手），一个通过分析视线模式和放射学报告提供个性化反馈的多智能体框架。与单智能体模型不同，MAARTA根据错误复杂性动态选择智能体，实现自适应高效推理。通过结构化图表比较专家与学生视线行为，系统识别遗漏发现并分配感知错误教师智能体分析差异。MAARTA通过逐步提示帮助学生理解错误并改进诊断推理，推动AI驱动的放射学教育发展。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [419] [DRO-Augment Framework: Robustness by Synergizing Wasserstein Distributionally Robust Optimization and Data Augmentation](https://arxiv.org/abs/2506.17874)
**中文标题：DRO-Augment框架：通过Wasserstein分布鲁棒优化与数据增强的协同提升鲁棒性**

*Jiaming Hu,Debarghya Mukherjee,Ioannis Ch. Paschalidis*

主要分类: stat.ML

摘要简述: 本文提出DRO-Augment框架，通过结合Wasserstein分布鲁棒优化（W-DRO）与数据增强技术，显著提升深度神经网络在多种输入扰动下的鲁棒性，同时保持干净数据上的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在图像分类等实际应用中，深度神经网络需应对多种输入扰动，现有数据增强技术虽能提升模型鲁棒性，但对数据损坏和对抗攻击的防御仍有不足。

研究方法: DRO-Augment框架将Wasserstein分布鲁棒优化（W-DRO）与多种数据增强策略结合，通过计算高效的变分正则化损失函数训练模型，提升鲁棒性。

研究结果: 实验表明，DRO-Augment在CIFAR-10-C、CIFAR-100-C等基准数据集上优于现有方法，尤其在严重数据扰动和对抗攻击场景下表现突出。

研究结论: DRO-Augment通过协同优化W-DRO与数据增强，显著提升模型鲁棒性，同时理论分析为神经网络训练提供了新的泛化误差界。

中文摘要: 在许多实际应用中，确保深度神经网络（DNNs）的鲁棒性和稳定性至关重要，尤其是图像分类任务面临多种输入扰动时。尽管数据增强技术被广泛用于提升模型对这些扰动的适应能力，但在同时应对数据损坏和对抗攻击方面仍有改进空间。为解决这一问题，我们提出DRO-Augment框架，通过结合Wasserstein分布鲁棒优化（W-DRO）与多种数据增强策略，显著提升模型在广泛扰动下的鲁棒性。我们的方法在CIFAR-10-C、CIFAR-100-C、MNIST和Fashion-MNIST等基准数据集上优于现有增强方法，尤其在严重数据扰动和对抗攻击场景下表现优异，同时保持干净数据上的准确性。在理论方面，我们为使用与W-DRO问题密切相关的计算高效、变分正则化损失函数训练的神经网络建立了新的泛化误差界。

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [420] [Tutorial: $\varphi$-Transductions in OpenFst via the Gallic Semiring](https://arxiv.org/abs/2506.17942)
**中文标题：Error**

*Marco Cognetta,Cyril Allauzen*

主要分类: cs.FL

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [421] [Enhancing Few-shot Keyword Spotting Performance through Pre-Trained Self-supervised Speech Models](https://arxiv.org/abs/2506.17686)
**中文标题：通过预训练自监督语音模型提升少样本关键词检测性能**

*Alican Gok,Oguzhan Buyuksolak,Osman Erman Okman,Murat Saraclar*

主要分类: eess.AS

摘要简述: 本文提出了一种基于自监督学习模型的训练方案，通过特征提取、降维和知识蒸馏提升少样本关键词检测性能，显著提高了在边缘设备上的准确率。


<details>
  <summary>详细信息</summary>
研究动机: 少样本关键词检测（FS-KWS）在资源受限的边缘设备上表现不佳，传统系统在低误报率下准确率较低。本文旨在通过自监督学习模型提升其性能。

研究方法: 采用基于Wav2Vec 2.0的教师模型，使用Sub-center ArcFace损失增强类间分离性和类内紧凑性；引入基于注意力的降维方法，并训练轻量级ResNet15学生模型以实现高效部署。

研究结果: 在GSC数据集上，10样本分类准确率从33.4%提升至74.1%（11类，1%误报率），显著优于现有方法。

研究结论: 所提方法显著提升了少样本关键词检测的性能，适用于实际边缘设备应用场景。

中文摘要: 关键词检测在电池供电的边缘设备中实现免提交互至关重要。少样本关键词检测（FS-KWS）通过仅需少量示例即可识别自定义关键词，解决了传统系统的可扩展性和适应性挑战。然而，现有FS-KWS系统在理想误报率下准确率较低，尤其在资源受限的边缘环境中。为解决这些问题，我们提出了一种训练方案，利用自监督学习模型进行鲁棒特征提取、降维和知识蒸馏。基于Wav2Vec 2.0的教师模型使用Sub-center ArcFace损失训练，增强了类间分离性和类内紧凑性。为实现边缘设备的高效部署，我们引入了基于注意力的降维方法，并训练了轻量级ResNet15学生模型。我们在多语言口语词库（MSWC）的英语部分和Google语音命令（GSC）数据集上评估了所提方法。值得注意的是，该方法在GSC数据集上将10样本分类准确率从33.4%提升至74.1%（11类，1%误报率），使其更适用于实际应用场景。

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [422] [Resolving the Ti-V Phase Diagram Discrepancy with First-Principles Calculations and Bayesian Learning](https://arxiv.org/abs/2506.17719)
**中文标题：利用第一性原理计算和贝叶斯学习解决钛-钒相图争议**

*Timofei Miryashkin,Olga Klimanova,Alexander Shapeev*

主要分类: cond-mat.mtrl-sci

摘要简述: 通过第一性原理计算和贝叶斯学习解决了钛-钒（Ti-V）二元合金相图的争议，确认其存在体心立方（BCC）混溶间隙，且该间隙与氧污染无关。


<details>
  <summary>详细信息</summary>
研究动机: 钛-钒（Ti-V）二元合金的相图存在争议，实验数据对是否存在体心立方（BCC）混溶间隙或完全可溶性存在分歧。本研究旨在通过计算和机器学习方法解决这一争议，并验证混溶间隙是否由氧污染引起。

研究方法: 结合第一性原理计算和机器学习方法，使用主动训练的矩张量势（Moment Tensor Potential）与贝叶斯热力学推断，生成钛-钒系统的完整相图，并计算热力学极限下的置信区间。

研究结果: 研究结果表明，钛-钒系统存在BCC混溶间隙，终止温度为980 K，成分为c = 0.67。由于模拟中排除了氧的影响，混溶间隙不能归因于杂质效应。

研究结论: 本研究通过计算和机器学习方法确认了钛-钒二元合金相图中BCC混溶间隙的存在，并排除了氧污染的影响，为相关争议提供了明确的解决方案。

中文摘要: 钛-钒（Ti-V）二元合金的相图存在争议，实验数据对是否存在体心立方（BCC）混溶间隙或完全可溶性存在分歧。本研究采用从头算+机器学习的工作流程，结合主动训练的矩张量势与贝叶斯热力学推断，生成了钛-钒二元系统在整个成分范围内的相图，并计算了热力学极限下的置信区间。结果表明，相图重现了所有实验特征，支持存在终止于T = 980 K和c = 0.67的BCC混溶间隙。由于模拟中排除了氧的影响，混溶间隙不能归因于杂质效应，这与最近的CALPHAD重新评估结果相矛盾。

</details>


### [423] [Residual Connection-Enhanced ConvLSTM for Lithium Dendrite Growth Prediction](https://arxiv.org/abs/2506.17756)
**中文标题：残差连接增强的ConvLSTM用于锂枝晶生长预测**

*Hosung Lee,Byeongoh Hwang,Dasan Kim,Myungjoo Kang*

主要分类: cond-mat.mtrl-sci

摘要简述: 本文提出了一种残差连接增强的ConvLSTM模型，用于预测锂枝晶生长，提高了预测精度和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 锂枝晶的生长严重影响可充电电池的性能和安全性，可能导致短路和容量下降。因此，需要一种高效且准确的模型来预测枝晶生长模式。

研究方法: 通过将残差连接集成到ConvLSTM中，模型缓解了梯度消失问题，增强了跨层特征保留，并有效捕捉了局部枝晶生长动态和宏观电池行为。数据集通过相场模型生成，模拟了不同条件下的枝晶演化。

研究结果: 实验结果表明，与传统的ConvLSTM相比，该模型在不同电压条件下（0.1V、0.3V、0.5V）的预测精度提高了7%，并显著降低了均方误差（MSE）。

研究结论: 残差连接在深度时空网络中表现出色，为电化学系统建模提供了有效工具。该方法有望用于电池诊断和实时性能优化。未来研究可扩展至其他电池化学体系，并结合实际实验数据进一步验证。

中文摘要: 锂枝晶的生长显著影响可充电电池的性能和安全性，可能导致短路和容量下降。本研究提出了一种残差连接增强的ConvLSTM模型，以提高枝晶生长模式的预测精度和计算效率。通过将残差连接集成到ConvLSTM中，模型缓解了梯度消失问题，增强了跨层特征保留，并有效捕捉了局部枝晶生长动态和宏观电池行为。数据集通过相场模型生成，模拟了不同条件下的枝晶演化。实验结果表明，与传统的ConvLSTM相比，该模型在不同电压条件下（0.1V、0.3V、0.5V）的预测精度提高了7%，并显著降低了均方误差（MSE）。这凸显了残差连接在深度时空网络中对电化学系统建模的有效性。该方法为电池诊断提供了强大工具，有望用于实时监测和锂电池性能优化。未来研究可将此框架扩展至其他电池化学体系，并结合实际实验数据进一步验证。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [424] [MMET: A Multi-Input and Multi-Scale Transformer for Efficient PDEs Solving](https://arxiv.org/abs/2506.17230)
**中文标题：MMET：一种多输入和多尺度的高效PDE求解Transformer**

*Yichen Luo,Jia Wang,Dapeng Lan,Yu Liu,Zhibo Pang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为MMET的新型框架，通过解耦网格和查询点序列，结合门控条件嵌入层和基于Hilbert曲线的重序列化机制，显著提升了多输入和多尺度偏微分方程（PDE）求解的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 偏微分方程（PDE）在物理系统建模中具有重要作用，但现有的机器学习方法在多输入和多尺度泛化能力上表现不足，且计算成本高昂。因此，需要一种高效且通用的解决方案。

研究方法: MMET框架将网格和查询点作为两个序列分别输入编码器和解码器，使用门控条件嵌入（GCE）层处理不同维度的输入变量或函数，并通过基于Hilbert曲线的重序列化和补丁嵌入机制减少输入长度，从而降低计算成本。

研究结果: 在多个物理领域的基准测试中，MMET在精度和计算效率上均优于现有方法，证明了其在大规模和多输入PDE问题中的高效性和可扩展性。

研究结论: MMET为工程和物理应用中的实时PDE求解提供了一种鲁棒且可扩展的解决方案，并为特定领域预训练大规模模型的未来探索奠定了基础。

中文摘要: 偏微分方程（PDE）是物理系统建模的基础，但由于多输入和多尺度泛化能力有限以及计算成本高昂，使用机器学习方法高效且通用地求解PDE仍然具有挑战性。本文提出了多输入和多尺度高效Transformer（MMET），这是一种新颖的框架，旨在解决上述挑战。MMET将网格和查询点解耦为两个序列，分别输入编码器和解码器，并使用门控条件嵌入（GCE）层嵌入不同维度的输入变量或函数，从而实现对多尺度多输入问题的有效求解。此外，基于Hilbert曲线的重序列化和补丁嵌入机制减少了输入长度，显著降低了处理大规模几何模型时的计算成本。这些创新实现了高效表示，并支持大规模和多输入PDE问题的多尺度分辨率查询。在涵盖不同物理领域的多样化基准测试中，实验评估表明MMET在精度和计算效率上均优于现有方法。这项工作突出了MMET作为工程和物理应用中实时PDE求解的鲁棒且可扩展解决方案的潜力，为特定领域预训练大规模模型的未来探索铺平了道路。本工作已在https://github.com/YichenLuo-0/MMET开源。

</details>


### [425] [PCaM: A Progressive Focus Attention-Based Information Fusion Method for Improving Vision Transformer Domain Adaptation](https://arxiv.org/abs/2506.17232)
**中文标题：PCaM：一种基于渐进式聚焦注意力的信息融合方法，用于改进视觉Transformer的域适应**

*Zelin Zang,Fei Wang,Liangyu Li,Jinlin Wu,Chunshui Zhao,Zhen Lei,Baigui Sun*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PCaM的渐进式聚焦注意力机制，用于改进基于视觉Transformer（ViT）的无监督域适应（UDA）方法。通过逐步过滤背景信息并聚焦于前景语义，PCaM显著提升了跨域注意力一致性，从而提高了域适应性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于ViT的UDA方法在跨域特征对齐时存在前景对象不匹配的问题，即前景对象的大小和空间分布差异导致注意力一致性减弱，影响了域适应效果。本文旨在解决这一问题。

研究方法: 提出了一种渐进式聚焦交叉注意力机制（PCaM），逐步过滤背景信息，使模型能够专注于跨域的判别性前景语义。此外，引入了一种注意力引导损失，明确将注意力导向任务相关区域，增强跨域注意力一致性。

研究结果: 在Office-Home、DomainNet、VisDA-2017和遥感数据集上的实验表明，PCaM显著提升了域适应性能，并取得了新的最优结果。

研究结论: PCaM通过注意力引导的前景语义融合，有效解决了跨域前景对象不匹配问题，为基于ViT的UDA方法提供了轻量级且通用的解决方案。

中文摘要: 无监督域适应（UDA）旨在将知识从有标注的源域迁移到无标注的目标域。近期基于视觉Transformer（ViT）的UDA方法通过基于注意力的特征对齐取得了显著性能。然而，我们发现一个关键限制：前景对象不匹配，即跨域前景对象大小和空间分布的差异削弱了注意力一致性，阻碍了有效的域对齐。为解决这一问题，我们提出了渐进式聚焦交叉注意力机制（PCaM），在交叉注意力过程中逐步过滤背景信息，使模型能够专注于并融合跨域的判别性前景语义。我们还引入了一种注意力引导损失，明确将注意力导向任务相关区域，增强跨域注意力一致性。PCaM轻量级、架构无关，易于集成到现有的基于ViT的UDA流程中。在Office-Home、DomainNet、VisDA-2017和遥感数据集上的大量实验表明，PCaM显著提升了适应性能，并取得了新的最优结果，验证了注意力引导的前景融合对域适应的有效性。

</details>


### [426] [Graph Neural Networks in Multi-Omics Cancer Research: A Structured Survey](https://arxiv.org/abs/2506.17234)
**中文标题：图神经网络在多组学癌症研究中的结构化综述**

*Payam Zohari,Mostafa Haghir Chehreghani*

主要分类: cs.LG

摘要简述: 本文系统综述了图神经网络（GNN）在多组学癌症研究中的应用，分类了不同方法，并揭示了当前趋势与未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 多组学数据整合是解析癌症复杂生物学机制的有效策略，而图神经网络（GNN）为建模异质性和结构化组学数据提供了强大框架。本文旨在系统梳理GNN在多组学癌症研究中的最新进展。

研究方法: 通过系统综述多组学癌症研究中基于GNN的架构，分类了这些方法的目标组学层、图神经网络结构及生物任务（如亚型分类、预后预测和生物标志物发现）。

研究结果: 分析表明，当前趋势倾向于混合和可解释模型，注意力机制和对比学习的应用日益增多，同时患者特异性图和知识驱动先验成为新兴方向。

研究结论: 本文为设计基于GNN的多组学癌症分析流程提供了全面资源，总结了当前实践、局限性和潜在未来方向。

中文摘要: 多组学数据整合已成为揭示癌症复杂生物学基础的有力策略。近年来，图神经网络（GNN）的进展为建模异质性和结构化组学数据提供了有效框架，能够精确表征分子相互作用和调控网络。本系统综述探讨了多组学癌症研究中基于GNN架构的若干最新研究。我们根据目标组学层、图神经网络结构及生物任务（如亚型分类、预后预测和生物标志物发现）对这些方法进行了分类。分析揭示了当前趋势倾向于混合和可解释模型，注意力机制和对比学习的应用日益增多。此外，我们强调了患者特异性图和知识驱动先验作为新兴方向。本综述旨在为研究人员设计基于GNN的多组学癌症分析流程提供全面资源，并深入探讨当前实践、局限性和潜在未来方向。

</details>


### [427] [Recursive Learning-Based Virtual Buffering for Analytical Global Placement](https://arxiv.org/abs/2506.17247)
**中文标题：基于递归学习的虚拟缓冲分析全局布局方法**

*Andrew B. Kahng,Yiting Liu,Zhiang Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为MLBuf-RePlAce的开源学习驱动虚拟缓冲感知全局布局框架，通过递归学习生成缓冲类型和位置，解决了传统方法的计算成本高和机器学习方法忽视ERC违规的问题，显著提升了时序性能。


<details>
  <summary>详细信息</summary>
研究动机: 在现代技术节点中，互连延迟与单元延迟的不均衡缩放使得缓冲孔隙感知的布局对时序收敛至关重要。然而，传统方法计算成本高，而机器学习方法如BufFormer未能充分考虑ERC违规，且未完全融入物理设计流程。

研究方法: MLBuf-RePlAce基于OpenROAD基础设施，采用递归学习生成缓冲类型和位置的方法，解决了ERC违规问题，并在全局布局阶段实现了高效的缓冲预测。

研究结果: 与OpenROAD默认的虚拟缓冲时序驱动全局布局器相比，MLBuf-RePlAce在不降低布线后功耗的情况下，总负松弛（TNS）实现了最大56%、平均31%的提升；在商业流程中，TNS提升最大53%、平均28%，且布线后功耗平均提升0.2%。

研究结论: MLBuf-RePlAce是首个开源的学习驱动虚拟缓冲感知全局布局框架，通过递归学习方法显著提升了时序性能，同时解决了ERC违规问题，为物理设计流程提供了高效解决方案。

中文摘要: 在现代技术节点中，由于互连延迟与单元延迟的不均衡缩放，具有缓冲孔隙（即单元密度）感知的布局对物理综合流程的时序收敛至关重要。然而，现有方法面临两大挑战：（i）传统的van Ginneken-Lillis风格缓冲方法在全局布局阶段计算成本高昂；（ii）基于机器学习的方法（如BufFormer）未能充分考虑电气规则检查（ERC）违规，且未完全融入物理设计流程。本文提出MLBuf-RePlAce，首个基于OpenROAD基础设施的开源学习驱动虚拟缓冲感知分析全局布局框架。MLBuf-RePlAce采用高效的递归学习生成缓冲类型和位置的方法，解决了全局布局阶段的ERC违规问题。我们通过TILOS MacroPlacement和OpenROAD-flow-scripts仓库的开源测试用例，将MLBuf-RePlAce与OpenROAD默认的虚拟缓冲时序驱动全局布局器进行比较。在不降低布线后功耗的情况下，MLBuf-RePlAce在开源OpenROAD流程中实现了总负松弛（TNS）最大56%、平均31%的提升。在商业流程中评估时，MLBuf-RePlAce的TNS提升最大53%、平均28%，且布线后功耗平均提升0.2%。

</details>


### [428] [Efficient Quantification of Multimodal Interaction at Sample Level](https://arxiv.org/abs/2506.17248)
**中文标题：样本级多模态交互的高效量化**

*Zequn Yang,Hongfa Wang,Di Hu*

主要分类: cs.LG

摘要简述: 本文提出了一种轻量级样本级多模态交互（LSMI）估计器，用于精确量化多模态信息中的冗余、独特性和协同作用，并通过实验验证了其高效性和实用性。


<details>
  <summary>详细信息</summary>
研究动机: 多模态信息中的交互作用（冗余、独特性和协同作用）对理解信息动态至关重要，但样本级量化存在理论和计算挑战。本文旨在解决这一问题。

研究方法: 基于点对点信息论，首先开发了冗余估计框架，随后提出了一种通用的交互估计方法，采用高效熵估计技术，特别适用于连续分布的样本级估计。

研究结果: 在合成和真实数据集上的实验验证了LSMI的精确性和高效性，并揭示了多模态数据中细粒度的样本和类别动态。

研究结论: LSMI为多模态数据分析提供了实用工具，支持冗余样本划分、目标知识蒸馏和交互感知模型集成等应用。

中文摘要: 多模态之间的交互作用——冗余性、独特性和协同性——共同决定了多模态信息的组成。理解这些交互作用对于分析多模态系统中的信息动态至关重要，但其在样本级的精确量化仍面临显著的理论和计算挑战。为此，我们提出了基于点对点信息论的轻量级样本级多模态交互（LSMI）估计器。我们首先开发了一个冗余估计框架，采用适当的点对点信息度量来量化这种最易分解和测量的交互作用。在此基础上，我们提出了一种通用的交互估计方法，采用高效熵估计技术，特别适用于连续分布的样本级估计。在合成和真实数据集上的大量实验验证了LSMI的精确性和高效性。重要的是，我们的样本级方法揭示了多模态数据中细粒度的样本和类别动态，支持冗余样本划分、目标知识蒸馏和交互感知模型集成等实际应用。代码可在https://github.com/GeWu-Lab/LSMI_Estimator获取。

</details>


### [429] [Improving Prediction Certainty Estimation for Reliable Early Exiting via Null Space Projection](https://arxiv.org/abs/2506.17249)
**中文标题：通过零空间投影改进预测确定性估计以实现可靠的早期退出**

*Jianing He,Qi Zhang,Duoqian Miao,Yi Kun,Shufeng Hao,Hongyun Zhang,Zhihua Wei*

主要分类: cs.LG

摘要简述: 本文提出了一种基于零空间投影（NSP）的新型早期退出方法，通过整合类无关信息比例和类相关逻辑值，提升预测确定性估计，实现更可靠的早期退出决策。实验表明，该方法在GLUE基准测试中平均加速2.19倍，性能损失可忽略，优于现有最佳方法28%。


<details>
  <summary>详细信息</summary>
研究动机: 现有早期退出方法仅依赖类相关逻辑值估计预测确定性，忽略了类无关信息对预测的负面影响，导致预测确定性被高估，错误样本过早退出。本文旨在通过考虑类无关信息比例，改进预测确定性估计。

研究方法: 提出NSP分数以量化类无关信息比例，并结合类相关逻辑值设计确定性感知概率（CAP）分数，用于更可靠的早期退出决策。

研究结果: 在GLUE基准测试中，该方法平均加速2.19倍，性能损失极小，优于现有最佳方法ConsistentEE 28%，实现了任务性能与推理效率的更好平衡。

研究结论: 通过整合类无关信息比例和类相关逻辑值，本文方法显著提升了预测确定性估计的可靠性，为早期退出提供了更优的解决方案。

中文摘要: 早期退出通过允许简单样本在浅层退出，无需执行更深层，显著加速了预训练语言模型（PLM）的推理。然而，现有早期退出方法主要依赖类相关逻辑值生成退出信号以估计预测确定性，忽略了特征中类无关信息对预测确定性的负面影响，导致预测确定性被高估，错误样本过早退出。为解决这一问题，我们定义了NSP分数，通过考虑特征中类无关信息的比例来估计预测确定性。在此基础上，提出了一种基于确定性感知概率（CAP）分数的早期退出方法，整合了逻辑值和NSP分数的信息，以提升预测确定性估计，从而实现更可靠的退出决策。GLUE基准测试的实验结果表明，我们的方法在所有任务中平均加速2.19倍，性能损失可忽略，优于现有最佳方法ConsistentEE 28%，实现了任务性能与推理效率的更好平衡。代码发布于https://github.com/He-Jianing/NSP.git。

</details>


### [430] [Towards Interpretable Adversarial Examples via Sparse Adversarial Attack](https://arxiv.org/abs/2506.17250)
**中文标题：面向可解释对抗样本的稀疏对抗攻击**

*Fudong Lin,Jiadong Lou,Hao Wang,Brian Jalaian,Xu Yuan*

主要分类: cs.LG

摘要简述: 本文提出了一种稀疏对抗攻击方法，通过最小化初始扰动的幅度并满足l0约束，实现了快速、可迁移且强力的攻击，同时生成了更稀疏且可解释的对抗样本。


<details>
  <summary>详细信息</summary>
研究动机: 现有稀疏对抗攻击方法在稀疏性、计算开销、迁移性和攻击强度方面存在不足，难以生成可解释的对抗样本。本文旨在克服这些缺点，开发一种高效的稀疏攻击方法，以理解卷积神经网络（CNN）的脆弱性。

研究方法: 本文引入了一种新颖的理论参数化技术，近似求解NP难的l0优化问题，并设计了一种损失函数，同时最大化对抗性和最小化扰动像素数量。

研究结果: 实验表明，该方法在计算开销、迁移性和攻击强度上优于现有稀疏攻击方法，并生成了更稀疏的对抗样本，揭示了两种噪声类型（“遮蔽噪声”和“引导噪声”），有助于解释对抗扰动如何误导分类器。

研究结论: 本文提出的稀疏对抗攻击方法不仅高效且可解释，为评估深度神经网络（DNN）的鲁棒性提供了基准，同时揭示了对抗扰动的内在机制。

中文摘要: 稀疏攻击旨在通过仅扰动少量像素（即满足l0约束）来优化对抗扰动的幅度，从而欺骗深度神经网络（DNN），适用于解释DNN的脆弱性。然而，现有方法由于稀疏性不足，难以生成可解释的对抗样本，且存在计算开销大、迁移性差和攻击强度弱等问题。本文旨在开发一种稀疏攻击方法，通过最小化初始扰动的幅度并满足l0约束，克服现有缺点，实现快速、可迁移且强力的攻击。具体而言，引入了一种新颖且理论可靠的重参数化技术，近似求解NP难的l0优化问题，使直接优化稀疏扰动成为可能。此外，设计了一种新的损失函数，通过同时最大化对抗性和最小化扰动像素数量来增强初始扰动。大量实验表明，我们的方法在计算开销、迁移性和攻击强度上优于现有稀疏攻击方法，并具有理论性能保证，有望成为评估DNN鲁棒性的基准。此外，理论和实证结果表明，我们的方法生成了更稀疏的对抗样本，揭示了两种噪声类型（“遮蔽噪声”和“引导噪声”），有助于解释对抗扰动如何误导分类器。代码已开源：https://github.com/fudong03/SparseAttack。

</details>


### [431] [Training-free LLM Verification via Recycling Few-shot Examples](https://arxiv.org/abs/2506.17251)
**中文标题：通过复用少量示例实现无需训练的LLM验证**

*Dongseok Lee,Jimyung Hong,Dongyoung Kim,Jaehyung Kim*

主要分类: cs.LG

摘要简述: 本文提出了一种无需训练的LLM验证框架Referi，通过复用少量示例评估候选输出，显著提升模型准确性，平均增益达4.8%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM表现优异，但其推理过程的随机性和结论的不一致性带来挑战。现有方法如多数投票或外部验证模型存在局限性，如适用性有限或额外训练成本高。

研究方法: 提出Referi框架，复用少量示例评估候选输出，结合贝叶斯规则设计两种评分，通过额外推理选择置信度高且上下文连贯的候选。

研究结果: 在三种LLM和七项任务上的实验表明，Referi显著提升准确性，平均增益4.8%，且无需额外训练。

研究结论: Referi通过复用少量示例验证LLM输出，有效提升模型性能，为LLM验证提供了一种高效且无需训练的新方法。

中文摘要: 尽管LLM取得了显著性能，但其推理过程的固有随机性和结论的多样性带来了重大挑战。多数投票或基于外部验证模型的Best-of-N方法已被探索，以从多个LLM输出中寻找最有希望的解决方案。然而，这些方法存在一定局限性，如适用性有限或额外训练步骤的成本。为解决这一问题，我们提出了一种新颖有效的框架Referi，通过复用少量示例验证LLM输出。我们的核心思想是额外利用给定的少量示例评估目标查询的候选输出，而不仅将其用于生成输出。具体而言，Referi通过结合两种基于贝叶斯规则设计的评分来评估生成输出，并通过少量额外LLM推理选择置信度高且上下文连贯的候选。在三种不同LLM和七项多样化任务上的实验表明，我们的框架通过有效响应选择显著提升了LLM的准确性，平均增益达4.8%，且无需额外训练。

</details>


### [432] [Adaptive Sample Scheduling for Direct Preference Optimization](https://arxiv.org/abs/2506.17252)
**中文标题：直接偏好优化的自适应样本调度**

*Zixuan Huang,Yikun Ban,Lean Fu,Xiaojie Li,Zhongxiang Dai,Jianxin Li,Deqing Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SamS的自适应样本调度算法，用于优化直接偏好优化（DPO）过程中训练样本的动态选择，显著提升了模型性能且计算开销极小。


<details>
  <summary>详细信息</summary>
研究动机: 直接偏好优化（DPO）的性能高度依赖人类偏好数据的质量，但现有方法忽略了模型在优化过程中的动态状态变化。本文旨在解决这一问题，通过动态调度样本提升模型泛化性能。

研究方法: 提出SamS算法，根据语言模型的学习反馈动态选择每批训练样本，无需修改DPO核心算法，仅通过样本调度即可优化性能。

研究结果: 实验表明，SamS显著提升了多任务性能，且额外计算开销极小。

研究结论: SamS为通过更有效利用固定偏好数据集改进语言模型对齐提供了新方向。

中文摘要: 直接偏好优化（DPO）已成为对齐大型语言模型（LLM）与人类偏好的有效方法，但其性能高度依赖人类偏好数据的质量。为解决这一瓶颈，先前研究探索了多种数据选择策略，但这些方法往往忽略了DPO过程中语言模型动态状态的影响。本文提出了一个新问题：DPO的样本调度，旨在基于模型在偏好优化中的动态状态自适应调度训练样本。为解决这一问题，我们提出了SamS算法，该算法根据LLM的学习反馈动态选择每批训练样本，以最大化泛化性能潜力。值得注意的是，无需修改DPO核心算法，仅通过集成SamS即可显著提升多任务性能，且额外计算开销极小。这项工作为通过更有效利用固定偏好数据集改进LLM对齐指明了新方向。

</details>


### [433] [MS-TVNet:A Long-Term Time Series Prediction Method Based on Multi-Scale Dynamic Convolution](https://arxiv.org/abs/2506.17253)
**中文标题：MS-TVNet：一种基于多尺度动态卷积的长期时间序列预测方法**

*Chenghan Li,Mingchen Li,Yipu Liao,Ruisheng Diao*

主要分类: cs.LG

摘要简述: 本文提出了一种基于多尺度动态卷积的长期时间序列预测方法MS-TVNet，通过多尺度时间序列重塑模块捕捉多周期片段和变量依赖关系，实验表明其性能优于基线模型，达到SOTA水平。


<details>
  <summary>详细信息</summary>
研究动机: 当前长期时间序列预测主要依赖Transformer和MLP模型，而卷积网络的潜力尚未充分挖掘。本文旨在填补这一空白，探索卷积网络在捕捉复杂时间模式中的有效性。

研究方法: 提出了一种多尺度时间序列重塑模块，用于捕捉多周期片段和变量依赖关系，并在此基础上构建了MS-TVNet，一种多尺度3D动态卷积神经网络。

研究结果: 在多个数据集上的综合评估表明，MS-TVNet性能优于基线模型，实现了长期时间序列预测的SOTA结果。

研究结论: 研究证明了卷积网络在捕捉复杂时间模式中的有效性，为未来研究提供了新方向。

中文摘要: 长期时间序列预测主要依赖于Transformer和MLP模型，而卷积网络在此领域的潜力尚未得到充分探索。为填补这一空白，我们提出了一种新颖的多尺度时间序列重塑模块，有效捕捉多周期片段之间的关系和变量依赖性。基于此模块，我们提出了MS-TVNet，一种多尺度3D动态卷积神经网络。通过对多个数据集的综合评估，MS-TVNet表现出优于基线模型的性能，在长期时间序列预测中达到了最先进（SOTA）水平。我们的研究结果表明，利用卷积网络捕捉复杂时间模式具有显著效果，为该领域的未来研究提供了有前景的方向。代码发布于https://github.com/Curyyfaust/TVNet。

</details>


### [434] [Keeping Up with the Models: Online Deployment and Routing of LLMs at Scale](https://arxiv.org/abs/2506.17254)
**中文标题：紧跟模型步伐：大规模语言模型的在线部署与路由**

*Shaoang Li,Jian Li*

主要分类: cs.LG

摘要简述: 论文提出了一种名为StageRoute的分层算法，用于在线部署和路由大规模语言模型（LLMs），以解决模型快速更新与资源限制之间的矛盾。该算法通过乐观选择模型和预算约束的路由策略，实现了接近最优的性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着新的大型语言模型（LLMs）不断涌现，旧模型迅速过时，服务提供商需要在有限的部署容量和查询成本预算下，动态管理模型库存。这一现实问题被建模为一个在线决策问题，需要同时考虑阶段性的模型部署和实时查询路由。

研究方法: 论文提出StageRoute算法，分为两个阶段：(i) 使用奖励上界和成本下界乐观选择下一阶段的模型；(ii) 通过预算约束的多臂老虎机子问题为每个查询动态路由。算法在理论上实现了$T^{2/3}$的遗憾上界，并通过实验验证了其实际性能。

研究结果: StageRoute在理论和实验上均表现出色，其遗憾上界为$T^{2/3}$，且实验结果表明其性能接近最优解。

研究结论: StageRoute是一种高效的在线部署和路由算法，能够在大规模LLM服务中动态管理模型，同时满足资源约束，具有理论和实际的双重优势。

中文摘要: 新的大型语言模型（LLMs）快速涌现，而旧模型迅速过时，这迫使LLM服务提供商在有限的部署容量和每查询成本预算下，动态管理流式模型库存。我们将这一现实问题建模为一个在线决策问题，结合阶段性的部署（在固定维护窗口完成）和实时查询路由。我们提出了StageRoute，一种分层算法：(i) 使用奖励上界和成本下界乐观选择下一阶段最多$M_max$个模型；(ii) 通过预算约束的多臂老虎机子问题为每个查询动态路由。我们证明了StageRoute的遗憾上界为$T^{2/3}$，并提供了匹配的下界，从而确立了其接近最优性。实验验证了理论结果，表明StageRoute在实际场景中性能接近最优。

</details>


### [435] [UltraSketchLLM: Saliency-Driven Sketching for Ultra-Low Bit LLM Compression](https://arxiv.org/abs/2506.17255)
**中文标题：UltraSketchLLM：面向超低比特LLM压缩的显著性驱动草图方法**

*Sunan Zou,Ziyun Zhang,Xueting Sun,Guojie Luo*

主要分类: cs.LG

摘要简述: UltraSketchLLM提出了一种基于数据草图的超低比特压缩框架，支持低至0.5比特/权重的压缩，同时保持模型性能，适用于资源受限的边缘设备部署。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）的快速发展，边缘设备的内存限制成为瓶颈，需要超越1比特极限的极端权重压缩方法。现有方法要么依赖映射表（增加内存开销），要么因随机权重分组导致严重精度下降。

研究方法: UltraSketchLLM采用无索引的草图框架，利用数据草图技术将多个权重映射为单个值，误差可控。结合低估AbsMaxMin草图最小化小权重的相对误差，重要性感知空间分配优先处理显著权重，以及直通估计器进行压缩感知微调。

研究结果: 在Llama-3.2-1B上的实验表明，UltraSketchLLM实现了低至0.5比特/权重的压缩，同时保持竞争力的困惑度，延迟开销可接受。

研究结论: UltraSketchLLM为资源受限环境中的LLM部署提供了一种实用解决方案，实现了超低比特压缩与性能的平衡。

中文摘要: 大型语言模型（LLMs）的快速增长已超出边缘设备的内存限制，需要超越1比特极限的极端权重压缩方法。量化虽能减小模型尺寸，但其本质限制为每权重1比特。现有的多对一压缩方法要么依赖映射表（增加内存开销），要么因随机权重分组导致严重精度下降。我们提出UltraSketchLLM，一种无索引的基于草图的框架，实现超低比特压缩（低至0.5比特/权重）同时保持模型性能。UltraSketchLLM利用数据草图（一种来自流应用的亚线性表示技术），将多个权重映射为误差可控的单个值。我们的方法集成了低估AbsMaxMin草图以最小化小权重的相对误差，重要性感知空间分配优先处理显著权重，以及直通估计器进行压缩感知微调。在Llama-3.2-1B上的实验表明，UltraSketchLLM实现了低至0.5比特/权重的压缩，同时保持竞争力的困惑度，延迟开销可接受。UltraSketchLLM为资源受限环境中的LLM部署提供了一种实用解决方案。

</details>


### [436] [AI to Identify Strain-sensitive Regions of the Optic Nerve Head Linked to Functional Loss in Glaucoma](https://arxiv.org/abs/2506.17262)
**中文标题：利用AI识别与青光眼功能损失相关的视神经头应变敏感区域**

*Thanadet Chuangsuwanich,Monisha E. Nongpiur,Fabian A. Braeu,Tin A. Tun,Alexandre Thiery,Shamira Perera,Ching Lin Ho,Martin Buist,George Barbastathis,Tin Aung,Michaël J. A. Girard*

主要分类: cs.LG

摘要简述: 该研究利用可解释AI技术，通过分析视神经头（ONH）生物力学特征，成功预测了青光眼患者的三种视野缺损模式，并确定了与功能损失相关的关键应变敏感区域。


<details>
  <summary>详细信息</summary>
研究动机: 青光眼是一种导致不可逆视力损失的疾病，其视野缺损模式多样。研究旨在探索ONH生物力学特征是否能够改进对青光眼视野缺损的预测，并通过可解释AI技术识别关键应变敏感区域。

研究方法: 研究纳入237名青光眼患者，通过眼科动态测量技术在不同眼压条件下成像ONH。专家根据视野缺损模式将患者分为四类。利用自动组织分割和数字体积相关技术计算ONH应变，结合几何深度学习模型进行分类预测，并通过可解释AI技术分析关键区域。

研究结果: 模型在预测三种视野缺损模式时表现出色（AUC为0.77-0.88），ONH应变显著提升了预测性能。研究发现下部和下颞侧视神经头边缘是关键应变敏感区域，且随病情加重逐渐扩大。

研究结论: ONH应变能够有效预测青光眼视野缺损模式，视神经头边缘（而非筛板）是模型预测中最关键的贡献区域。

中文摘要: 目的：(1) 评估视神经头（ONH）生物力学特征是否能够改进对青光眼三种进展性视野缺损模式的预测；(2) 利用可解释AI技术识别与这些预测相关的应变敏感ONH区域。方法：招募237名青光眼患者，通过眼科动态测量技术在不同眼压条件下成像ONH。专家根据视野缺损模式将患者分为四类：上鼻侧阶梯（26例）、上部分弓形缺损（62例）、上半视野完全缺损（25例）及其他/非特异性缺损（124例）。利用自动组织分割和数字体积相关技术计算ONH应变，结合几何深度学习模型进行分类预测，并通过可解释AI技术分析关键区域。结果：模型表现出色（AUC为0.77-0.88），ONH应变显著提升了预测性能。下部和下颞侧视神经头边缘是关键应变敏感区域，且随病情加重逐渐扩大。结论与意义：ONH应变能够有效预测青光眼视野缺损模式，视神经头边缘（而非筛板）是模型预测中最关键的贡献区域。

</details>


### [437] [Memory Allocation in Resource-Constrained Reinforcement Learning](https://arxiv.org/abs/2506.17263)
**中文标题：资源受限强化学习中的内存分配**

*Massimiliano Tamborski,David Abel*

主要分类: cs.LG

摘要简述: 本文探讨了在资源受限的强化学习中，内存分配如何影响智能体在未知环境中的表现，研究了不同内存分配策略对MCTS和DQN算法在情景学习和持续学习中的影响。


<details>
  <summary>详细信息</summary>
研究动机: 资源约束会显著改变学习和决策过程。本文旨在研究内存约束如何影响智能体在使用标准强化学习算法时的性能，特别是内存受限的智能体在内部过程（如估计世界模型和制定计划）之间的内存分配问题。

研究方法: 研究基于MCTS和DQN算法，分析了不同内存分配策略对智能体在情景学习和持续学习任务中的表现。

研究结果: 实验结果表明，内存分配策略对智能体的性能有显著影响，尤其是在资源受限的情况下，合理分配内存可以优化学习和决策效果。

研究结论: 内存分配在资源受限的强化学习中至关重要，合理分配内存可以显著提升智能体在未知环境中的学习和决策能力。

中文摘要: 资源约束可以从根本上改变学习和决策过程。本文探讨了内存约束如何影响智能体在使用标准强化学习算法导航未知环境时的表现。具体而言，内存受限的智能体面临一个困境：如何将有限的内存分配给其内部过程（如估计世界模型）与使用该模型制定计划之间？我们在基于MCTS和DQN的算法中研究了这一困境，并分析了不同内存分配策略在情景学习和持续学习任务中对性能的影响。

</details>


### [438] [OAT-Rephrase: Optimization-Aware Training Data Rephrasing for Zeroth-Order LLM Fine-Tuning](https://arxiv.org/abs/2506.17264)
**中文标题：OAT-Rephrase：面向零阶LLM微调的优化感知训练数据重述**

*Jikai Long,Zijian Hu,Xiaodong Yu,Jianwen Xie,Zhaozhuo Xu*

主要分类: cs.LG

摘要简述: 本文提出OAT-Rephrase，一种优化感知的训练数据重述策略，通过LLM重述训练数据以提升零阶优化（如MeZO）的微调性能，缩小与一阶方法的差距。


<details>
  <summary>详细信息</summary>
研究动机: 零阶优化方法（如MeZO）在微调大语言模型时内存效率高，但收敛慢且优化不稳定。本文旨在通过优化感知的数据重述策略解决这些问题。

研究方法: OAT-Rephrase采用双阶段流水线：重述LLM和语义判断器，确保重述内容保留任务相关性和逻辑一致性。

研究结果: 在五个分类任务和三种LLM架构上的实验表明，OAT-Rephrase显著提升MeZO微调性能，甚至接近一阶方法的效果。

研究结论: 优化感知的数据重述是一种可重用且低开销的零阶优化增强方法，能有效提升性能。

中文摘要: 使用零阶优化（ZO）微调大语言模型（LLMs）是一种内存高效的方法，但因其梯度估计噪声导致收敛慢且优化不稳定。本文提出OAT-Rephrase，一种优化感知的训练数据重述策略，利用LLM基于其对ZO动态（特别是MeZO）的理解重述训练实例。该方法采用包含重述LLM和语义判断器的双阶段流水线，确保所有重述内容保持任务相关性和逻辑一致性。在五个分类任务和三种LLM架构上的评估表明，OAT-Rephrase能持续提升MeZO微调性能，通常缩小甚至消除与一阶方法的差距。我们的研究结果表明，优化感知的重述是一种可重用且低开销的零阶优化增强方法。

</details>


### [439] [Does Multimodal Large Language Model Truly Unlearn? Stealthy MLLM Unlearning Attack](https://arxiv.org/abs/2506.17265)
**中文标题：多模态大语言模型是否真正遗忘？隐秘的MLLM遗忘攻击**

*Xianren Zhang,Hui Liu,Delvin Ce Zhang,Xianfeng Tang,Qi He,Dongwon Lee,Suhang Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为‘隐秘遗忘攻击（SUA）’的新方法，旨在揭示多模态大语言模型（MLLM）遗忘敏感信息后是否真正遗忘，还是仅隐藏了这些信息。实验证明，SUA能有效恢复被遗忘的信息，且攻击具有普适性。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLM）可能记忆敏感个人信息和照片，带来隐私风险。虽然已有方法通过微调模型以‘遗忘’敏感信息，但尚不清楚这些信息是否真正被遗忘。本文旨在研究这一问题，并提出攻击方法验证模型是否真正遗忘。

研究方法: 提出‘隐秘遗忘攻击（SUA）’框架，通过学习通用噪声模式，将其应用于输入图像以触发模型揭示被遗忘内容。为提高隐蔽性，引入嵌入对齐损失，确保攻击在语义上不可察觉。

研究结果: 实验表明，SUA能有效恢复MLLM中被遗忘的信息，且学习的噪声具有普适性，单个噪声模式可应用于未见过的图像。这表明知识重现是模型的一致行为，而非偶然失败。

研究结论: MLLM的遗忘机制可能仅隐藏而非真正遗忘敏感信息，SUA攻击揭示了这一潜在风险，为未来防御研究提供了方向。

中文摘要: 多模态大语言模型（MLLM）在大量数据训练中可能记忆敏感个人信息和照片，带来严重隐私风险。为缓解此问题，提出了MLLM遗忘方法，通过微调模型以减少‘遗忘’敏感信息。然而，这些信息是否真正被遗忘仍不明确。为此，本文研究了一种新的LLM遗忘攻击问题，旨在恢复被遗忘的LLM知识。为实现目标，提出了一种名为‘隐秘遗忘攻击（SUA）’的新框架，通过学习通用噪声模式，当应用于输入图像时，可触发模型揭示被遗忘内容。尽管像素级扰动在视觉上可能不明显，但在语义嵌入空间中可被检测，使此类攻击易受潜在防御影响。为提高隐蔽性，引入了嵌入对齐损失，最小化扰动与去噪图像嵌入间的差异，确保攻击在语义上不可察觉。实验结果表明，SUA能有效恢复MLLM中被遗忘的信息。此外，学习的噪声具有普适性：在部分样本上训练的单个扰动可揭示未见图像中的遗忘内容。这表明知识重现并非偶然失败，而是模型的一致行为。

</details>


### [440] [CF-VLM:CounterFactual Vision-Language Fine-tuning](https://arxiv.org/abs/2506.17267)
**中文标题：CF-VLM：基于反事实的视觉-语言模型微调**

*Jusheng Zhang,Kaitong Cai,Yijia Fan,Jian Wang,Keze Wang*

主要分类: cs.LG

摘要简述: CF-VLM是一种新型视觉-语言模型微调框架，通过引入反事实样本增强因果推理能力，显著提升细粒度判别和深度因果推理任务表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉-语言模型（VLMs）依赖表面统计相关性，缺乏捕捉视觉与文本内容间深层因果逻辑的能力，限制了其在细粒度判别和因果推理任务中的表现。

研究方法: CF-VLM提出三种互补训练目标：保持跨模态对齐基础、强化事实场景表示的唯一性和稳定性，以及提升模型对关键因果编辑的敏感性。

研究结果: 实验表明，CF-VLM在组合推理和泛化基准测试中优于基线方法和前沿技术，并有效减少视觉幻觉，提升事实一致性。

研究结论: CF-VLM为高风险的现实场景提供了可靠的视觉-语言模型部署基础，增强了模型的推理能力和可解释性。

中文摘要: 尽管视觉-语言模型（VLMs）在跨模态语义理解方面取得了显著进展，但在细粒度判别和深度因果推理任务中仍存在明显局限。现有VLMs通常依赖表面统计相关性，无法捕捉视觉与文本内容间的深层因果逻辑。为此，我们提出基于反事实的视觉-语言模型微调（CF-VLM），通过针对性使用反事实样本增强VLMs的因果推理能力。CF-VLM引入三种互补训练目标：保持基础跨模态对齐、强化事实场景表示在一致反事实下的唯一性和稳定性，以及提升模型对关键因果编辑的敏感性。大量实验表明，CF-VLM在组合推理和泛化基准测试中持续优于强基线及前沿方法。此外，其在减少视觉幻觉方面表现出潜力，表明事实一致性得到改善。CF-VLM为需要可靠推理和可解释性的高风险现实场景提供了稳健的VLM部署基础。

</details>


### [441] [SafeRL-Lite: A Lightweight, Explainable, and Constrained Reinforcement Learning Library](https://arxiv.org/abs/2506.17297)
**中文标题：SafeRL-Lite：一个轻量级、可解释且约束的强化学习库**

*Satyam Mishra,Phung Thao Vi,Shivam Mishra,Vishwanath Bijalwan,Vijay Bhaskar Semwal,Abdul Manan Khan*

主要分类: cs.LG

摘要简述: SafeRL-Lite是一个轻量级的开源Python库，专注于构建具有约束性和可解释性的强化学习代理，填补了现有工具在安全约束和决策解释性方面的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有的强化学习工具通常缺乏原生机制来强制执行硬性安全约束或生成人类可理解的决策理由，SafeRL-Lite旨在解决这一问题。

研究方法: SafeRL-Lite通过模块化封装标准Gym环境和深度Q学习代理，支持安全感知训练（通过约束强制执行）和实时事后解释（通过SHAP值和显著性图）。

研究结果: 在CartPole的约束变体上验证了其有效性，并提供了可视化工具以展示策略逻辑和安全性。

研究结论: SafeRL-Lite是一个轻量级、可扩展且易于安装的库，为强化学习的安全性和可解释性提供了实用工具。

中文摘要: 我们介绍了SafeRL-Lite，一个开源的Python库，用于构建具有约束性和可解释性的强化学习（RL）代理。现有的RL工具包通常缺乏原生机制来强制执行硬性安全约束或生成人类可理解的决策理由。SafeRL-Lite通过模块化封装标准Gym环境和深度Q学习代理，支持：（i）通过约束强制执行实现安全感知训练，（ii）通过SHAP值和显著性图实现实时事后解释。该库轻量级、可扩展，可通过pip安装，并内置了约束违反的度量指标。我们在CartPole的约束变体上验证了其有效性，并提供了可视化工具以展示策略逻辑和安全性。完整代码库可在以下网址获取：https://github.com/satyamcser/saferl-lite。

</details>


### [442] [AlgoSelect: Universal Algorithm Selection via the Comb Operator](https://arxiv.org/abs/2506.17304)
**中文标题：AlgoSelect：通过Comb Operator实现通用算法选择**

*Jasper Yao*

主要分类: cs.LG

摘要简述: AlgoSelect是一种基于Comb Operator的通用算法选择框架，能够通过学习从数据中选择最优算法，具有理论上的普适性、信息论最优性和计算高效性，并在实验中实现了近乎完美的选择准确率。


<details>
  <summary>详细信息</summary>
研究动机: 当前算法选择问题缺乏一种既能理论上保证最优性和可学习性，又能实际部署的解决方案。AlgoSelect旨在填补这一空白，通过Comb Operator实现通用且高效的算法选择。

研究方法: AlgoSelect的核心是Comb Operator，通过sigmoid门控选择器在算法之间插值，并扩展为N-Path Comb以支持多算法选择。理论贡献包括普适逼近定理、信息论可学习性、Comb Operator的线性算子理论形式化、N-Path Comb的泛化以及自适应种子函数的实用学习框架。

研究结果: 在20×20的问题-算法实验中，AlgoSelect实现了99.9%以上的选择准确率，样本需求极少且收敛迅速，表明在结构化领域中算法选择的条件熵接近于零。

研究结论: AlgoSelect为自动化算法选择提供了理论扎实、实际可部署的解决方案，具有普适性、最优性和可学习性保证，对AI和自适应系统具有重要意义。

中文摘要: 我们提出了AlgoSelect，一种基于新颖Comb Operator的算法选择框架，能够从数据中学习最优算法选择。给定一组算法和问题的特征表示，AlgoSelect学会在不同计算方法之间插值。对于算法对，一个简单的sigmoid门控选择器（Comb Operator的实例）实现了这种插值。我们将其扩展为支持多算法选择的N-Path Comb。我们证明该框架具有普适性（可以逼近任何算法选择器）、信息论最优性（选择阈值几乎必然收敛，通过Borel-Cantelli论证展示）、计算高效性和鲁棒性。关键理论贡献包括：(1) 普适逼近定理，证明基于Comb的选择器可以实现任意精度；(2) 选择阈值的信息论可学习性；(3) 在线性算子理论中形式化Comb Operator，详述其有界性和谱性质；(4) 多算法选择的N-Path Comb泛化；(5) 指导Comb Operator的自适应种子函数的实用学习框架。在全面的20×20问题-算法研究中，实验验证表明AlgoSelect实现了近乎完美的选择准确率（99.9%以上），样本需求极少且收敛迅速，揭示了在结构化领域中算法选择的条件熵接近于零。AlgoSelect为自动化算法选择提供了理论扎实、实际可部署的解决方案，具有最优性和可学习性保证，对AI和自适应系统具有重要影响。

</details>


### [443] [I Know Which LLM Wrote Your Code Last Summer: LLM generated Code Stylometry for Authorship Attribution](https://arxiv.org/abs/2506.17323)
**中文标题：我知道去年夏天是谁用LLM写了你的代码：基于代码风格学的LLM生成代码作者归属**

*Tamas Bisztray,Bilel Cherif,Richard A. Dubniczky,Nils Gruschka,Bertalan Borsos,Mohamed Amine Ferrag,Attila Kovacs,Vasileios Mavroeidis,Norbert Tihanyi*

主要分类: cs.LG

摘要简述: 本文提出了一种名为CodeT5-Authorship的新模型，用于识别由不同大型语言模型（LLM）生成的C程序代码的作者。通过引入LLM-AuthorBench基准测试，模型在二进制和多类分类任务中表现出色，准确率分别达到97.56%和95.40%。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型生成的代码日益普遍，识别代码背后的具体模型变得至关重要。本文旨在解决这一新兴研究挑战，为LLM生成的代码提供作者归属方法。

研究方法: 研究提出CodeT5-Authorship模型，仅使用CodeT5的编码器层，并通过两层分类头生成作者概率分布。使用LLM-AuthorBench基准测试（包含32,000个C程序）评估模型性能，并与多种传统和基于Transformer的模型进行比较。

研究结果: 在二进制分类任务中，模型区分GPT-4.1和GPT-4o生成的代码准确率达97.56%；在多类分类任务中，对五种主流LLM的准确率为95.40%。

研究结论: CodeT5-Authorship模型在LLM生成的代码作者归属任务中表现出色，为相关研究提供了新工具和基准。所有代码和脚本已开源。

中文摘要: 检测AI生成的代码、深度伪造和其他合成内容是新兴的研究挑战。随着大型语言模型（LLM）生成的代码日益普遍，识别每个样本背后的具体模型变得愈发重要。本文首次系统研究了LLM生成的C程序的作者归属问题。我们发布了CodeT5-Authorship模型，该模型仅使用原始CodeT5编码器-解码器架构中的编码器层，舍弃解码器以专注于分类任务。模型的编码器输出（首个标记）通过一个带有GELU激活和Dropout的两层分类头，生成可能的作者概率分布。为评估方法，我们引入了LLM-AuthorBench基准测试，包含32,000个由八种先进LLM生成的C程序，涵盖多种任务。我们将模型与七种传统机器学习分类器和八种微调的Transformer模型（包括BERT、RoBERTa、CodeBERT、ModernBERT、DistilBERT、DeBERTa-V3、Longformer和LoRA微调的Qwen2-1.5B）进行比较。在二进制分类任务中，模型区分GPT-4.1和GPT-4o生成的代码准确率达97.56%；在多类分类任务中，对五种主流LLM（Gemini 2.5 Flash、Claude 3.5 Haiku、GPT-4.1、Llama 3.3和DeepSeek-V3）的准确率为95.40%。为支持开放科学，我们开源了CodeT5-Authorship架构、LLM-AuthorBench基准测试及相关Google Colab脚本：https://github.com/LLMauthorbench/。

</details>


### [444] [FaithfulSAE: Towards Capturing Faithful Features with Sparse Autoencoders without External Dataset Dependencies](https://arxiv.org/abs/2506.17673)
**中文标题：FaithfulSAE：无需依赖外部数据集，通过稀疏自编码器捕获真实特征**

*Seonglae Cho,Harryn Oh,Donghyun Lee,Luis Eduardo Rodrigues Vieira,Andrew Bermingham,Ziad El Sayed*

主要分类: cs.LG

摘要简述: FaithfulSAE提出了一种通过使用模型自身合成数据训练稀疏自编码器（SAE）的方法，解决了传统SAE因依赖外部数据集而导致的特征不稳定和虚假特征问题，显著提升了特征捕获的准确性和稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 传统稀疏自编码器（SAE）在训练时依赖外部数据集（如网络数据或其他模型生成的数据），可能导致特征不稳定或捕获虚假特征（Fake Features），无法准确反映模型内部激活。为解决这一问题，本文提出了FaithfulSAE方法。

研究方法: FaithfulSAE通过使用模型自身生成的合成数据集训练SAE，避免了外部数据集中可能存在的分布外（OOD）数据问题，从而更稳定地捕获模型内部特征。

研究结果: 实验表明，FaithfulSAE在5/7的模型中表现出更低的虚假特征比例，并在SAE探测任务中优于基于网络数据训练的SAE，同时在不同初始化种子下表现更稳定。

研究结论: FaithfulSAE消除了对外部数据集的依赖，提升了稀疏自编码器对模型内部特征的捕获能力，为模型可解释性研究提供了更可靠的工具。

中文摘要: 稀疏自编码器（SAE）是一种用于分解大型语言模型表征为可解释特征的有前景方法。然而，Paulo和Belrose（2025）指出不同初始化种子下SAE的不稳定性，Heap等人（2025）则发现SAE可能无法捕获模型内部特征。这些问题可能源于SAE在外部数据集（如网络数据或其他模型生成数据）上的训练，这些数据可能包含超出模型泛化能力的分布外（OOD）数据，导致虚假SAE特征（即“虚假特征”），从而错误表征模型内部激活。为解决这些问题，我们提出FaithfulSAE，该方法通过使用模型自身合成的数据集训练SAE。实验表明，在较少OOD的指令数据集上训练的FaithfulSAE在不同种子下表现更稳定。值得注意的是，FaithfulSAE在SAE探测任务中优于基于网络数据训练的SAE，并在5/7的模型中表现出更低的虚假特征比例。总体而言，我们的方法消除了对外部数据集的依赖，通过更好地捕获模型内部特征推动了可解释性研究，同时强调了SAE训练数据集的重要性。

</details>


### [445] [Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models](https://arxiv.org/abs/2506.17781)
**中文标题：超越指令调节：MoTE——多任务嵌入模型的任务专家混合**

*Miguel Romero,Shuoyang Ding,Corey D. Barret,Georgiana Dinu,George Karypis*

主要分类: cs.LG

摘要简述: 本文提出了MoTE（任务专家混合）变换块，通过任务感知对比学习增强模型生成专用嵌入的能力，显著提升了检索任务和多任务性能，且不改变指令、训练数据或推理时间。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于指令调节的低容量模型在嵌入专业化中存在表示限制，限制了性能提升。本文旨在通过任务专家混合方法突破这些限制。

研究方法: 引入MoTE变换块，结合任务感知对比学习（TACL）训练任务专用参数，以生成更专业的嵌入。

研究结果: 实验显示，MoTE在检索数据集上性能提升64%（从+3.27到+5.21），在所有数据集上提升43%（从+1.81到+2.60）。

研究结论: MoTE在不改变指令、训练数据或推理时间的情况下，显著提升了嵌入模型的性能，为多任务嵌入提供了有效解决方案。

中文摘要: 密集嵌入是现代机器学习系统的基础，支持检索增强生成（RAG）、信息检索和表示学习。尽管指令调节已成为嵌入专业化的主要方法，但其在低容量模型中的直接应用存在表示限制，限制了专业化的性能提升。本文分析了这些限制，并提出了任务专家混合（MoTE）变换块，通过任务感知对比学习（TACL）训练任务专用参数，增强模型生成专用嵌入的能力。实验结果表明，MoTE在检索数据集上实现了64%的性能提升（从+3.27到+5.21），在所有数据集上提升了43%（从+1.81到+2.60）。重要的是，这些提升未改变指令、训练数据、推理时间或活动参数数量。

</details>


### [446] [Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach](https://arxiv.org/abs/2506.17828)
**中文标题：通过强化学习对齐冻结大型语言模型：一种迭代重加权优化方法**

*Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong*

主要分类: cs.LG

摘要简述: 本文提出了一种名为IRO的强化学习框架，用于对齐冻结的大型语言模型（LLM），无需修改模型参数，通过迭代重加权和优化方法提升输出质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法如RLHF和DPO需要直接优化模型参数，无法在测试时提升性能，且不适用于无法访问模型权重的情况。测试时方法虽避免权重更新，但依赖不完美的奖励函数，导致输出次优且推理成本高。

研究方法: IRO框架通过以下步骤实现对齐：(i) 从基础模型中采样候选输出，(ii) 使用当前价值函数重采样，(iii) 训练新的轻量级价值函数以指导下一次解码。测试时，通过搜索优化过程引导生成。

研究结果: IRO能够在无需访问模型权重的情况下，实现对冻结LLM的对齐，类似于OpenAI的RFT，但更具灵活性和适用性。

研究结论: IRO为对齐冻结LLM提供了一种高效且灵活的方法，适用于用户自定义数据集，且无需模型权重访问权限。

中文摘要: 对齐大型语言模型（LLM）与人类偏好通常需要微调方法，如RLHF和DPO。这些方法直接优化模型参数，因此无法在测试时提升性能，也不适用于无法访问模型权重的情况。相比之下，测试时方法通过利用奖励函数引导输出质量提升，避免了权重更新，但存在推理成本高且依赖不完美奖励函数的问题，导致输出次优。本文提出了一种名为迭代重加权优化（IRO）的方法，这是一种强化学习（RL）框架，可在不修改基础模型参数的情况下实现对齐。训练时，每轮迭代（i）从基础模型中采样候选输出，（ii）使用当前价值函数重采样，（iii）训练新的轻量级价值函数以指导下一次解码。测试时，通过搜索优化过程利用价值函数引导基础模型生成。值得注意的是，用户可类似OpenAI的强化微调（RFT）在自有数据集上应用IRO，但无需访问模型权重。

</details>


### [447] [Adaptive Social Metaverse Streaming based on Federated Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2506.17342)
**中文标题：基于联邦多智能体深度强化学习的自适应社交元宇宙流媒体**

*Zijian Long,Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

主要分类: cs.LG

摘要简述: 本文提出了一种基于联邦多智能体深度强化学习（F-MAPPO）的自适应社交元宇宙流媒体系统ASMS，旨在解决隐私保护和高质量低延迟流媒体的挑战。实验表明，ASMS在各种网络条件下比现有方法提升用户体验至少14%。


<details>
  <summary>详细信息</summary>
研究动机: 社交元宇宙作为虚拟与物理世界融合的数字生态系统，面临隐私保护和实时高质量流媒体的双重挑战。现有方法难以兼顾隐私与性能，因此需要一种新的解决方案。

研究方法: ASMS采用联邦多智能体近端策略优化（F-MAPPO），结合联邦学习（FL）和深度强化学习（DRL），动态调整流媒体比特率，同时保护用户隐私。

研究结果: 实验结果显示，ASMS在不同网络条件下比现有流媒体方法提升用户体验至少14%，实现了无缝且沉浸式的流媒体体验。

研究结论: ASMS通过F-MAPPO技术，在动态和资源受限的网络中提供高质量的流媒体服务，同时确保用户敏感数据本地化，显著提升了社交元宇宙的用户体验。

中文摘要: 社交元宇宙是一个融合虚拟与物理世界的数字生态系统，用户可以在其中进行社交互动、工作、购物和娱乐。然而，隐私问题仍是主要挑战，因为沉浸式交互需要持续收集生物特征和行为数据。同时，由于实时交互、沉浸式渲染和带宽优化的需求，确保高质量、低延迟的流媒体服务十分困难。为解决这些问题，我们提出了ASMS（自适应社交元宇宙流媒体系统），这是一种基于联邦多智能体近端策略优化（F-MAPPO）的新型流媒体系统。ASMS利用F-MAPPO，结合联邦学习（FL）和深度强化学习（DRL），动态调整流媒体比特率，同时保护用户隐私。实验结果表明，ASMS在各种网络条件下比现有流媒体方法提升用户体验至少14%。因此，ASMS通过提供无缝且沉浸式的流媒体体验，增强了社交元宇宙的用户体验，即使在动态和资源受限的网络中，也能确保敏感用户数据保留在本地设备上。

</details>


### [448] [AdapThink: Adaptive Thinking Preferences for Reasoning Language Model](https://arxiv.org/abs/2506.18237)
**中文标题：AdapThink：推理语言模型的自适应思维偏好**

*Xu Wan,Wei Wang,Wenyue Xu,Wotao Yin,Jie Song,Mingyang Sun*

主要分类: cs.LG

摘要简述: AdapThink是一种自适应后训练框架，通过动态调整反思偏好和多样性感知采样，提升语言模型的推理效率，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 基于强化学习的后训练虽然提升了语言模型的复杂推理能力，但静态预算或规则无法适应不同问题复杂度和模型能力的动态变化，导致推理效率低下。

研究方法: AdapThink包含两种机制：1）基于模型置信度和响应特征的群组相对奖励函数，动态调整反思偏好；2）通过熵引导分数平衡训练群的解准确性和推理多样性的多样性感知采样。

研究结果: 在多个数学推理数据集上的实验表明，AdapThink能够实现自适应推理模式并缓解效率低下的问题。

研究结论: AdapThink通过自适应机制有效提升了语言模型的推理效率，同时保持了性能，为后训练框架提供了新思路。

中文摘要: 基于强化学习（RL）的后训练显著提升了语言模型的复杂推理能力，促进了精细的自我反思过程。然而，这种“慢思考”范式对推理效率提出了关键挑战：模型可能在简单问题上耗费过多计算，或在复杂问题上过早切换推理。以往的机制通常依赖静态长度预算或预定义规则，缺乏对不同问题复杂度和模型能力动态变化的适应性。为此，我们提出了AdapThink，一种自适应后训练框架，旨在诱导更高效的思维，同时保持推理语言模型的性能。具体而言，AdapThink包含两种关键机制：1）一种群组相对奖励函数，利用模型置信度和响应特征动态调整反思相关过渡词的偏好，而无需固定长度偏好；2）一种多样性感知采样机制，通过熵引导分数平衡训练群的解准确性与推理多样性。在多个数学推理数据集上使用DeepSeek蒸馏模型的实验证明了AdapThink在实现自适应推理模式和缓解效率低下方面的优势。

</details>


### [449] [RLPR: Extrapolating RLVR to General Domains without Verifiers](https://arxiv.org/abs/2506.18254)
**中文标题：RLPR：无需验证器将RLVR推广至通用领域**

*Tianyu Yu,Bo Ji,Shouli Wang,Shu Yao,Zefan Wang,Ganqu Cui,Lifan Yuan,Ning Ding,Yuan Yao,Zhiyuan Liu,Maosong Sun,Tat-Seng Chua*

主要分类: cs.LG

摘要简述: 本文提出RLPR框架，通过利用LLM自身生成答案的概率作为奖励信号，无需依赖领域特定验证器，将RLVR扩展到更广泛的通用领域，显著提升了模型的推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有RLVR方法在数学和代码领域表现优异，但因依赖领域特定验证器而难以扩展到通用领域。本文旨在解决这一限制，提出一种无需验证器的方法。

研究方法: RLPR框架利用LLM生成答案的自身概率作为奖励信号，并通过prob-to-reward和稳定化方法降低噪声奖励的方差，从而优化训练过程。

研究结果: 在四个通用领域和三个数学领域的基准测试中，RLPR显著提升了Gemma、Llama和Qwen模型的推理能力，甚至优于依赖验证器的方法。

研究结论: RLPR通过LLM自身概率作为奖励信号，成功将RLVR扩展到通用领域，为提升模型推理能力提供了高效且可扩展的解决方案。

中文摘要: 基于可验证奖励的强化学习（RLVR）在提升大语言模型（LLM）推理能力方面展现出潜力，但其成功主要局限于数学和代码领域，原因在于对领域特定验证器的依赖导致复杂性和可扩展性受限。为解决这一问题，我们观察到LLM生成正确自由形式答案的内在概率直接反映了其对推理奖励的评估（即推理过程导向正确答案的程度）。基于这一发现，我们提出RLPR，一种简单的无验证器框架，将RLVR推广至更广泛的通用领域。RLPR利用LLM对参考答案的标记概率分数作为奖励信号，并在训练中最大化期望奖励。我们发现，解决这一噪声概率奖励的高方差问题至关重要，因此提出了prob-to-reward和稳定化方法，以确保从LLM内在概率中获取精确且稳定的奖励。在四个通用领域基准和三个数学领域基准上的综合实验表明，RLPR显著提升了Gemma、Llama和Qwen模型的推理能力。值得注意的是，RLPR在TheoremQA上比VeriFree高出7.6分，在Minerva上高出7.5分，甚至在七个基准上平均优于依赖验证器的General-Reasoner方法1.6分。

</details>


### [450] [Confucius3-Math: A Lightweight High-Performance Reasoning LLM for Chinese K-12 Mathematics Learning](https://arxiv.org/abs/2506.18330)
**中文标题：Confucius3-Math：一款轻量级高性能推理大语言模型，专为中国K-12数学学习设计**

*Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan*

主要分类: cs.LG

摘要简述: Confucius3-Math是一款开源的14B参数大语言模型，专为中国K-12数学学习设计，能在消费级GPU上高效运行，并在数学推理任务中表现优异。通过强化学习后训练，结合三项技术创新，显著提升了训练稳定性和性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在利用AI技术提升教育质量，特别是为中国K-12学生和教师提供高效、低成本的数学学习工具。通过开发轻量级高性能模型，解决主流数学问题，并推动知识传播。

研究方法: 采用大规模强化学习（RL）后训练方法，结合三项技术创新：目标熵正则化、近期样本恢复和策略特定难度加权。这些技术改进了熵正则化、数据调度策略和优势估计器，提升了训练效率和性能。

研究结果: Confucius3-Math在多个数学推理任务中达到SOTA性能，优于许多更大规模的模型，且能在单块消费级GPU上高效运行。

研究结论: 研究表明，通过技术创新和强化学习后训练，可以在特定领域（如K-12数学）以低成本构建高性能推理模型。模型和代码已开源。

中文摘要: 我们介绍了Confucius3-Math，这是一款开源的14B参数大语言模型，具有以下特点：（1）能在单块消费级GPU上高效运行；（2）在多项数学推理任务中表现优异，超越了许多规模更大的模型。作为利用AI提升教育和知识传播的使命的一部分，Confucius3-Math专注于为中国K-12学生和教师提供数学学习支持。通过大规模强化学习（RL）后训练，该模型与国家课程对齐，并能低成本解决主流K-12数学问题。本文分享了开发方法、遇到的挑战及解决技术，特别是三项技术创新：目标熵正则化、近期样本恢复和策略特定难度加权。这些创新包括新的熵正则化方法、数据调度策略和改进的组相对优势估计器，显著稳定了RL训练、提高了数据效率并提升了性能。我们的工作证明了在特定领域以低成本构建高性能推理模型的可行性。模型和代码已在https://github.com/netease-youdao/Confucius3-Math开源。

</details>


### [451] [SAFEx: Analyzing Vulnerabilities of MoE-Based LLMs via Stable Safety-critical Expert Identification](https://arxiv.org/abs/2506.17368)
**中文标题：SAFEx：通过稳定安全关键专家识别分析基于MoE的大型语言模型的脆弱性**

*Zhenglin Lai,Mengyao Liao,Dong Xu,Zebin Zhao,Zhihang Yuan,Chao Fan,Jianqiang Li,Bingzhe Wu*

主要分类: cs.LG

摘要简述: 本文提出SAFEx框架，用于识别和分析基于混合专家（MoE）的大型语言模型中的安全关键专家模块，揭示其位置脆弱性，并通过实验验证少数专家对模型安全性的决定性影响。


<details>
  <summary>详细信息</summary>
研究动机: 混合专家（MoE）架构的大型语言模型在效率和扩展性上表现优异，但其独特结构带来了未被充分探索的安全对齐挑战。现有安全对齐策略主要针对密集模型，无法有效解决MoE特有的脆弱性问题。

研究方法: 提出SAFEx分析框架，采用基于稳定性的专家选择（SES）算法，识别并验证安全关键专家模块，并将其功能分解为有害内容检测和安全响应生成等不同组别。

研究结果: 实验表明，主流MoE模型（如Qwen3-MoE）的安全机制高度依赖少数位置专家。禁用这些专家（如Qwen3-MoE中的12个专家）会导致模型拒绝有害请求的能力显著下降（拒绝率降低22%）。

研究结论: MoE模型的安全对齐存在位置脆弱性，少数专家对整体安全性具有不成比例的影响，需针对MoE架构设计更有效的安全策略。

中文摘要: 基于混合专家（MoE）的大型语言模型在效率和扩展性上取得了显著进展，但其架构独特性引入了未被充分探索的安全对齐挑战。现有的安全对齐策略主要针对密集模型设计，难以应对MoE特有的脆弱性。本文形式化并系统研究了MoE模型的位置脆弱性现象，即安全对齐行为依赖于特定专家模块，揭示了MoE架构的固有风险。为此，我们提出了SAFEx分析框架，通过新颖的基于稳定性的专家选择（SES）算法，稳健地识别、表征和验证安全关键专家。值得注意的是，我们的方法能够将安全关键专家明确分解为不同功能组，包括负责有害内容检测和控制安全响应生成的专家。在主流MoE模型（如最新发布的Qwen3-MoE）上的大量实验表明，其内在安全机制高度依赖少数位置专家。禁用这些专家会显著削弱模型拒绝有害请求的能力。对于拥有6144个专家（在FNN层）的Qwen3-MoE，我们发现仅禁用12个已识别的安全关键专家即可导致拒绝率下降22%，证明了少数专家对模型整体安全性的不成比例影响。

</details>


### [452] [SlimMoE: Structured Compression of Large MoE Models via Expert Slimming and Distillation](https://arxiv.org/abs/2506.18349)
**中文标题：SlimMoE：通过专家瘦身与蒸馏实现大型MoE模型的结构化压缩**

*Zichong Li,Chen Liang,Zixuan Zhang,Ilgee Hong,Young Jin Kim,Weizhu Chen,Tuo Zhao*

主要分类: cs.LG

摘要简述: SlimMoE是一种多阶段压缩框架，通过专家瘦身和蒸馏技术将大型MoE模型压缩为更小、高效的变体，仅需少量训练数据即可实现高性能，适合资源有限的环境。


<details>
  <summary>详细信息</summary>
研究动机: 大型MoE模型虽然能高效扩展语言模型，但其巨大的内存需求使其在资源受限环境中难以微调或部署。SlimMoE旨在解决这一问题，提供一种高效的压缩方法。

研究方法: SlimMoE通过多阶段压缩框架，逐步减少专家参数数量，并通过中间阶段知识转移，避免一次性剪枝带来的性能下降。该方法仅需少量训练数据（如400B tokens）。

研究结果: 压缩后的模型（如Phi-mini-MoE和Phi-tiny-MoE）在单GPU上即可微调，性能优于同类小模型，甚至接近更大模型的表现。例如，Phi-mini-MoE在MMLU分数上与Llama 3.1 8B相当，但延迟更低。

研究结论: SlimMoE展示了结构化剪枝与分阶段蒸馏结合的有效性，为高质量、紧凑的MoE模型提供了可行路径，推动了MoE架构的广泛应用。

中文摘要: 混合专家（MoE）架构已成为扩展大型语言模型（LLM）同时保持推理效率的强大范式。然而，其巨大的内存需求使其在资源受限环境中难以微调或部署。为解决这一问题，我们提出了SlimMoE，一种多阶段压缩框架，可将大型MoE模型转换为更小、高效的变体，而无需从头训练的高昂成本。我们的方法通过瘦身专家和分阶段知识转移，系统性地减少参数数量，有效缓解了一刀切剪枝方法常见的性能下降问题。利用该框架，我们仅使用400B tokens（不到原始模型训练数据的10%）将Phi 3.5-MoE（41.9B总参数/6.6B激活参数）压缩为Phi-mini-MoE（7.6B总参数/2.4B激活参数）和Phi-tiny-MoE（3.8B总参数/1.1B激活参数）。这些压缩模型可在单GPU（A100用于Phi-mini-MoE，A6000用于Phi-tiny-MoE）上微调，非常适合学术和资源有限的环境。实验表明，这些压缩模型的性能优于同类小模型，并与更大模型竞争。例如，Phi-mini-MoE仅使用2/3的激活参数即达到或超过Phi-3-mini的性能，且在MMLU分数上与Llama 3.1 8B相当，同时延迟显著更低。我们的研究表明，结构化剪枝与分阶段蒸馏相结合，为创建高质量、紧凑的MoE模型提供了有效途径，推动了MoE架构的广泛应用。模型已公开于https://huggingface.co/microsoft/Phi-mini-MoE-instruct和https://huggingface.co/microsoft/Phi-tiny-MoE-instruct。

</details>


### [453] [No Training Wheels: Steering Vectors for Bias Correction at Inference Time](https://arxiv.org/abs/2506.18598)
**中文标题：无需训练轮：推理时用于偏差校正的导向向量**

*Aviral Gupta,Armaan Sethi,Ameesh Sethi*

主要分类: cs.LG

摘要简述: 本文提出了一种无需重新训练的低成本方法，通过计算多数与少数群体激活均值的差异定义“偏差向量”，并在推理时从模型的残差流中减去该向量，以减少分类偏差并提升最差群体准确率。


<details>
  <summary>详细信息</summary>
研究动机: 神经网络分类器在训练数据中群体分布不均时，容易继承类别偏差并学习虚假相关性，导致在非典型群体上表现不佳。现有方法通常需要重新训练或大量计算资源，因此需要一种低成本、无需训练的解决方案。

研究方法: 受大语言模型中行为编辑的启发，计算多数与少数群体激活均值的差异，定义“偏差向量”，并在推理时从模型的残差流中减去该向量，以纠正分类偏差。

研究结果: 该方法显著减少了分类偏差，提升了最差群体的准确率，且在类似Transformer的分类器中表现出有效性。

研究结论: 本文展示了一种极低成本、无需训练、仅需推理时操作的方法，有效缓解分类模型中的偏差问题，为偏差校正提供了新思路。

中文摘要: 在群体分布不均的数据集上训练的神经网络分类器通常会继承类别偏差并学习虚假相关性。这些模型可能在平均表现上良好，但在非典型群体上持续失败。例如，在头发颜色分类中，数据集可能过度代表金发女性，强化了刻板印象。尽管已有多种算法和数据为中心的方法被提出以解决此类偏差，但它们通常需要重新训练或大量计算资源。本文提出了一种低成本、无需训练的方法，灵感来源于用于编辑大语言模型行为的导向向量。我们计算多数与少数群体激活均值的差异，定义“偏差向量”，并将其从模型的残差流中减去。这减少了分类偏差并提升了最差群体准确率。我们探索了在类似Transformer的分类器中提取和应用这些向量的多种策略，表明传统用于生成模型的导向向量在分类任务中同样有效。更广泛地说，我们展示了一种极低成本、仅需推理时操作、无需训练的方法，用于缓解分类模型中的偏差问题。

</details>


### [454] [ReDit: Reward Dithering for Improved LLM Policy Optimization](https://arxiv.org/abs/2506.18631)
**中文标题：ReDit：通过奖励抖动改进LLM策略优化**

*Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu*

主要分类: cs.LG

摘要简述: 本文提出ReDit（奖励抖动）方法，通过向离散奖励信号添加随机噪声，解决离散奖励导致的梯度异常、优化不稳定和收敛慢的问题，显著提升LLM策略优化的效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: DeepSeek-R1的离散奖励系统虽然有效避免了奖励黑客攻击，但会导致梯度异常、优化不稳定和收敛缓慢。为了解决这些问题，本文提出了ReDit方法。

研究方法: ReDit通过在离散奖励信号中添加简单的随机噪声，生成抖动的奖励信号，从而提供连续的探索梯度，实现更平滑的梯度更新和更快的收敛。噪声还引入随机性，帮助模型探索新策略并逃离局部最优。

研究结果: 实验表明，ReDit在多种任务中表现优异，仅需约10%的训练步数即可达到与普通GRPO相当的性能，且在相同训练时长下性能提升4%。可视化结果证实ReDit显著缓解了梯度问题。

研究结论: ReDit通过抖动离散奖励信号，有效解决了梯度异常和收敛慢的问题，显著提升了LLM策略优化的效率和性能，并通过理论和实验验证了其优势。

中文摘要: DeepSeek-R1通过其基于规则的奖励系统成功提升了大型语言模型（LLM）的推理能力。尽管这是一种“完美”的奖励系统，能有效避免奖励黑客攻击，但此类奖励函数通常是离散的。实验观察表明，离散奖励可能导致梯度异常、优化不稳定和收敛缓慢。为解决这一问题，我们提出ReDit（奖励抖动），该方法通过添加简单随机噪声对离散奖励信号进行抖动。这种扰动后的奖励在学习过程中持续提供探索梯度，从而实现更平滑的梯度更新和更快的收敛。注入的噪声还在平坦奖励区域引入随机性，鼓励模型探索新策略并逃离局部最优。多样任务的实验证明了ReDit的有效性和高效性。平均而言，ReDit仅需约10%的训练步数即可达到与普通GRPO相当的性能，且在相同训练时长下仍比普通GRPO性能提升4%。可视化结果证实ReDit显著缓解了梯度问题。此外，理论分析进一步验证了这些优势。

</details>


### [455] [Multi-modal Anchor Gated Transformer with Knowledge Distillation for Emotion Recognition in Conversation](https://arxiv.org/abs/2506.18716)
**中文标题：基于知识蒸馏的多模态锚点门控变换器在对话情感识别中的应用**

*Jie Li,Shifei Ding,Lili Guo,Xuan Li*

主要分类: cs.LG

摘要简述: 本文提出了一种多模态锚点门控变换器与知识蒸馏结合的方法（MAGTKD），用于对话中的情感识别任务，通过增强模态表示和有效整合多模态信息，实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 对话中的情感识别（ERC）需要为每个话语生成高效的模态特定表示，但现有方法忽视了模态对任务的不同贡献，且帧级对齐增加了复杂性。因此，本文旨在解决这些问题。

研究方法: 提出MAGTKD方法，包括使用提示学习增强文本模态表示，知识蒸馏强化较弱模态表示，以及多模态锚点门控变换器整合跨模态话语级表示。

研究结果: 在IEMOCAP和MELD数据集上的实验表明，知识蒸馏有效增强了模态表示，并在情感识别任务中达到了最先进的性能。

研究结论: MAGTKD通过知识蒸馏和多模态锚点门控变换器，显著提升了情感识别的性能，为多模态情感识别提供了有效解决方案。

中文摘要: 对话中的情感识别（ERC）旨在检测对话中单个话语的情感。为每个话语生成高效且模态特定的表示仍是一个重要挑战。先前研究提出了多种模型来整合不同模态编码器提取的特征，但它们忽视了模态对此任务的不同贡献，并通过帧级对齐引入了高复杂性。为解决这些问题，我们提出了基于知识蒸馏的多模态锚点门控变换器（MAGTKD）用于ERC任务。具体而言，采用提示学习增强文本模态表示，同时利用知识蒸馏强化较弱模态的表示。此外，我们引入多模态锚点门控变换器，有效整合跨模态的话语级表示。在IEMOCAP和MELD数据集上的大量实验表明，知识蒸馏有效增强了模态表示，并在情感识别中实现了最先进的性能。代码发布于：https://github.com/JieLi-dd/MAGTKD。

</details>


### [456] [Neural Total Variation Distance Estimators for Changepoint Detection in News Data](https://arxiv.org/abs/2506.18764)
**中文标题：基于神经总变差距离估计器的新闻数据变点检测方法**

*Csaba Zsolnai,Niels Lörch,Julian Arnold*

主要分类: cs.LG

摘要简述: 本文提出了一种基于神经网络的变点检测方法，通过分类器区分不同时间段的新闻内容，估计内容分布的总变差距离以识别重大事件。该方法在合成数据和真实新闻数据中均有效，成功检测到9/11、COVID-19等事件。


<details>
  <summary>详细信息</summary>
研究动机: 公共话语的转变对理解社会动态至关重要，但高维、稀疏且嘈杂的真实数据使变点检测成为挑战。本文旨在利用神经网络方法，自动识别新闻数据中的重大事件转折点。

研究方法: 采用基于“学习-混淆”方案的神经网络方法，训练分类器区分不同时间段的新闻文章，利用分类准确率估计内容分布的总变差距离，从而识别变点。

研究结果: 该方法在合成数据和《卫报》的真实新闻数据中均表现良好，成功检测到9/11、COVID-19大流行和总统选举等重大事件。

研究结论: 该方法无需过多领域知识，能自动发现公共话语的重大转变，并提供内容变化的量化指标，对新闻业、政策分析和危机监测具有重要价值。

中文摘要: 检测公共话语因重大事件而发生的转变对于理解社会动态至关重要。真实世界的数据具有高维度、稀疏性和噪声，使得该领域的变点检测成为一项挑战性任务。本文利用神经网络进行新闻数据中的变点检测，引入了一种基于“学习-混淆”方案的方法，该方法最初是为检测物理系统中的相变而开发的。我们训练分类器以区分不同时间段的文章，利用分类准确率估计潜在内容分布的总变差距离，显著的距离变化即为变点。我们在合成数据集和《卫报》的真实数据上验证了该方法的有效性，成功识别了包括9/11事件、COVID-19大流行和总统选举在内的重大历史事件。该方法对领域知识要求极低，能够自主发现公共话语的重大转变，并提供内容变化的量化指标，对新闻业、政策分析和危机监测具有重要价值。

</details>


### [457] [FedNAMs: Performing Interpretability Analysis in Federated Learning Context](https://arxiv.org/abs/2506.17466)
**中文标题：FedNAMs：在联邦学习环境中执行可解释性分析**

*Amitash Nanda,Sree Bhargavi Balija,Debashis Sahoo*

主要分类: cs.LG

摘要简述: 本文提出了一种名为FedNAMs的新方法，将神经加法模型（NAMs）与联邦学习框架结合，以解决联邦学习中的可解释性问题。该方法在保护隐私的同时，提供了特征级别的可解释性，并在多个数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在隐私保护方面具有优势，但其模型的可解释性和可解释性仍然是一个挑战。本文旨在通过结合神经加法模型（NAMs）和联邦学习，提出一种既能保护隐私又能提供高可解释性的解决方案。

研究方法: 本文提出了一种名为FedNAMs的方法，将神经加法模型（NAMs）与联邦学习框架结合。NAMs通过为每个输入特征分配独立的子网络，实现特征级别的可解释性。在联邦学习中，FedNAMs允许客户端在本地训练模型，并通过聚合全局模型来更新参数，从而保护数据隐私。

研究结果: 实验使用了OpenFetch ML Wine、UCI Heart Disease和Iris等数据集，结果表明FedNAMs在保持与传统联邦深度神经网络（DNNs）相近的准确率的同时，显著提高了模型的可解释性。研究还识别了多个关键预测特征，如葡萄酒质量中的挥发性酸度和硫酸盐含量，心脏病预测中的胸痛类型和最大心率等。

研究结论: FedNAMs成功地将联邦学习的隐私保护优势与NAMs的可解释性结合起来，为金融和医疗等领域提供了高效且透明的解决方案。该方法不仅提升了模型的鲁棒性和泛化能力，还为特征级别的分析提供了新的视角。

中文摘要: 联邦学习不断发展，但在可解释性和可解释性方面仍面临挑战。为解决这些问题，我们提出了一种新方法，将神经加法模型（NAMs）应用于联邦学习框架中。这种名为联邦神经加法模型（FedNAMs）的方法结合了NAMs的优势（每个子网络专注于特定输入特征）和联邦学习的去中心化特点，最终生成可解释的分析结果。这种集成通过在多个设备上训练本地数据来增强隐私保护，从而降低数据集中化的风险，并提高模型的鲁棒性和泛化能力。FedNAMs保留了详细的特征特定学习，使其在金融和医疗等领域尤为有价值。它们支持训练客户端特定模型以整合本地更新，保护隐私并缓解集中化带来的问题。我们在多种文本和图像分类任务（如OpenFetch ML Wine、UCI Heart Disease和Iris数据集）上的研究表明，与传统联邦深度神经网络（DNNs）相比，FedNAMs以最小的准确率损失提供了强大的可解释性。研究还包括重要发现，例如在客户端和全局层面识别关键预测特征（如葡萄酒质量中的挥发性酸度、硫酸盐和氯化物含量，心脏病预测中的胸痛类型、最大心率和血管数量，以及鸢尾花分类中的花瓣长度和宽度）。这种方法不仅增强了隐私保护和模型效率，还提高了跨数据集的可解释性和鲁棒性。最后，FedNAMs生成了关于高可解释性和低可解释性特征成因的见解。

</details>


### [458] [A Survey of State Representation Learning for Deep Reinforcement Learning](https://arxiv.org/abs/2506.17518)
**中文标题：深度强化学习中状态表示学习的综述**

*Ayoub Echchahed,Pablo Samuel Castro*

主要分类: cs.LG

摘要简述: 本文综述了深度强化学习中状态表示学习的方法，将其分为六类，探讨了不同方法的机制、优势与局限性，旨在为该领域提供清晰分类与未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 复杂观测空间在序列决策问题中带来挑战，状态表示学习方法成为解决这一问题的关键工具。本文旨在系统分类现有方法，帮助研究者理解并推动该领域发展。

研究方法: 本文在无模型在线设置下，将状态表示学习方法分为六类，详细分析每类方法的机制、优势与局限性，并探讨了表示质量评估技术。

研究结果: 通过分类与比较，本文揭示了不同状态表示学习方法的特点与应用场景，为研究者提供了实用指南，并指出了未来研究方向。

研究结论: 本文通过系统分类与评估，为深度强化学习中的状态表示学习领域提供了清晰框架，有助于推动未来研究发展。

中文摘要: 表示学习方法是解决序列决策问题中复杂观测空间挑战的重要工具。近年来，许多方法采用多种方式学习强化学习中有意义的状态表示，从而提升样本效率、泛化能力和性能。本综述旨在无模型在线设置下对这些方法进行广泛分类，探讨其学习状态表示的不同方式。我们将方法分为六大类，详细阐述其机制、优势与局限性。通过这一分类体系，我们旨在增强对该领域的理解，并为新研究者提供指导。此外，我们还讨论了评估表示质量的技术，并详细介绍了相关未来方向。

</details>


### [459] [Accelerating Residual Reinforcement Learning with Uncertainty Estimation](https://arxiv.org/abs/2506.17564)
**中文标题：基于不确定性估计的残差强化学习加速**

*Lakshita Dodeja,Karl Schmeckpeper,Shivam Vats,Thomas Weng,Mingxi Jia,George Konidaris,Stefanie Tellex*

主要分类: cs.LG

摘要简述: 本文提出两种改进残差强化学习的方法，通过利用基础策略的不确定性估计和修改离策略残差学习，显著提升了样本效率并适用于随机基础策略。


<details>
  <summary>详细信息</summary>
研究动机: 残差强化学习（RL）通过轻量级残差策略调整预训练策略，比微调整个基础策略更高效，但现有方法难以应对稀疏奖励且仅适用于确定性基础策略。本文旨在提升其样本效率并扩展至随机基础策略。

研究方法: 1. 利用基础策略的不确定性估计，将探索集中在基础策略不自信的区域；2. 修改离策略残差学习，使其能观察基础动作并更好处理随机基础策略。

研究结果: 在Robosuite和D4RL任务中，基于高斯和扩散的随机基础策略测试表明，该方法显著优于现有微调方法、演示增强RL方法及其他残差RL方法，并在零样本仿真到现实迁移中表现出鲁棒性。

研究结论: 本文提出的改进方法显著提升了残差强化学习的性能，适用于随机基础策略，并在仿真和现实任务中表现出色。

中文摘要: 残差强化学习（RL）是一种通过轻量级残差策略提供修正动作来调整预训练策略的流行方法。尽管残差RL比微调整个基础策略更高效，但现有方法难以应对稀疏奖励且仅适用于确定性基础策略。我们提出了两种改进方法，进一步提升其样本效率并使其适用于随机基础策略。首先，利用基础策略的不确定性估计，将探索集中在基础策略不自信的区域；其次，提出一种简单的离策略残差学习修改方法，使其能观察基础动作并更好处理随机基础策略。我们在Robosuite和D4RL任务中，基于高斯和扩散的随机基础策略评估了该方法，并与最先进的微调方法、演示增强RL方法及其他残差RL方法进行了比较。我们的算法在多种仿真基准环境中显著优于现有基线。我们还通过零样本仿真到现实迁移部署了学习策略，展示了其鲁棒性。

</details>


### [460] [Exploiting Efficiency Vulnerabilities in Dynamic Deep Learning Systems](https://arxiv.org/abs/2506.17621)
**中文标题：利用动态深度学习系统中的效率漏洞**

*Ravishka Rathnasuriya,Wei Yang*

主要分类: cs.LG

摘要简述: 动态深度学习系统（DDLSs）通过输入自适应计算优化效率，但其动态特性引入安全风险，攻击者可利用输入依赖性执行路径降低效率，导致延迟增加、能耗上升甚至拒绝服务。本文研究DDLSs的效率漏洞，分析攻击策略并提出防御机制。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度学习模型在现实环境中的广泛部署，高效推理的需求日益增长。动态深度学习系统（DDLSs）通过动态调整计算资源提高效率，但其动态特性可能被攻击者利用，导致效率下降甚至服务中断。本文旨在揭示DDLSs的效率漏洞及其安全风险。

研究方法: 本文首先调查现有攻击策略，分析其对新兴模型架构的覆盖不足及防御机制的局限性。随后，研究现代DDLSs中效率攻击的可行性，并开发针对性防御措施以增强系统鲁棒性。

研究结果: 研究发现，DDLSs的动态行为确实存在效率漏洞，攻击者可通过特定输入显著降低系统性能。现有防御机制未能完全覆盖这些漏洞，亟需改进。

研究结论: 动态深度学习系统的效率漏洞是一个被低估的安全问题。本文揭示了其潜在风险，并提出了针对性的防御方向，为未来研究提供了重要参考。

中文摘要: 随着深度学习模型在现实环境中的广泛应用，严格延迟和资源限制下的高效推理需求日益迫切。为满足这些需求，动态深度学习系统（DDLSs）应运而生，通过输入自适应计算优化运行时效率。尽管这些系统成功降低了成本，但其动态特性引入了未被充分探索的安全风险。具体而言，输入依赖的执行路径为攻击者提供了降低效率的机会，导致延迟增加、能耗上升，甚至可能对时间敏感部署造成拒绝服务。本研究探讨了DDLSs中动态行为的安全影响，揭示了当前系统如何暴露可被恶意输入利用的效率漏洞。通过对现有攻击策略的调查，我们发现新兴模型架构的覆盖不足以及当前防御机制的局限性。基于这些发现，我们提出研究现代DDLSs中效率攻击的可行性，并开发针对性防御措施以在对抗条件下保持系统鲁棒性。

</details>


### [461] [LLM-Prompt: Integrated Heterogeneous Prompts for Unlocking LLMs in Time Series Forecasting](https://arxiv.org/abs/2506.17631)
**中文标题：LLM-Prompt：集成异构提示以解锁大语言模型在时间序列预测中的应用**

*Zesen Wang,Yonggang Li,Lijuan Lan*

主要分类: cs.LG

摘要简述: 本文提出LLM-Prompt框架，通过整合多提示信息和跨模态语义对齐，解决了现有基于大语言模型（LLM）的时间序列预测方法在文本提示统一性和模态差异上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于LLM的时间序列预测方法存在两个主要问题：缺乏统一的文本提示范式，以及忽视文本提示与时间序列之间的模态差异。本文旨在解决这些问题，提升预测性能。

研究方法: 1. 构建统一的文本提示范式，包含可学习的软提示和文本化的硬提示；2. 设计语义空间嵌入和跨模态对齐模块，实现时间与文本信息的跨模态融合；3. 将LLM转换的时间序列投影以获取预测结果。

研究结果: 在6个公共数据集和3个碳排放数据集上的全面评估表明，LLM-Prompt是一个强大的时间序列预测框架。

研究结论: LLM-Prompt通过整合多提示信息和跨模态语义对齐，显著提升了时间序列预测的性能，尤其是在长期预测和数据稀缺场景中。

中文摘要: 时间序列预测旨在建模变量之间的时间依赖性以推断未来状态，在现实场景中具有重要意义和广泛应用。尽管基于深度学习的方法取得了显著进展，但在长期预测和数据稀缺场景中表现仍不理想。近期研究表明，大语言模型（LLM）在时间序列预测中表现出色。然而，我们发现现有基于LLM的方法仍存在不足：（1）缺乏统一的文本提示范式；（2）忽视了文本提示与时间序列之间的模态差异。为此，我们提出LLM-Prompt，一个基于LLM的时间序列预测框架，整合多提示信息和跨模态语义对齐。具体而言，我们首先构建一个统一的文本提示范式，包含可学习的软提示和文本化的硬提示。其次，为增强LLM对预测任务的全面理解，我们设计了语义空间嵌入和跨模态对齐模块，实现时间与文本信息的跨模态融合。最后，将LLM转换的时间序列投影以获取预测结果。在6个公共数据集和3个碳排放数据集上的全面评估表明，LLM-Prompt是一个强大的时间序列预测框架。

</details>


### [462] [Enhancing Stress-Strain Predictions with Seq2Seq and Cross-Attention based on Small Punch Test](https://arxiv.org/abs/2506.17680)
**中文标题：基于小冲孔试验的Seq2Seq与交叉注意力增强应力-应变预测**

*Zhengni Yang,Rui Yang,Weijian Han,Qixin Liu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于小冲孔试验数据的深度学习新方法，通过Seq2Seq模型和交叉注意力机制预测高强钢的真实应力-应变曲线，显著提高了预测精度。


<details>
  <summary>详细信息</summary>
研究动机: 传统实验方法在预测高强钢的真实应力-应变曲线时效率低且成本高，本文旨在通过深度学习技术提供一种更高效、准确的替代方案。

研究方法: 使用Gramian Angular Field将载荷-位移序列转化为图像以捕捉时空特征，并采用基于LSTM的Seq2Seq模型，结合多头交叉注意力机制提升预测精度。

研究结果: 实验结果显示，该方法的最小和最大平均绝对误差分别为0.15 MPa和5.58 MPa，预测精度显著优于传统方法。

研究结论: 本文提出的方法为材料科学中的真实应力-应变关系预测提供了一种高效且准确的替代方案，具有重要的应用潜力。

中文摘要: 本文提出了一种新的深度学习方法，用于从小冲孔试验（SPT）的载荷-位移数据中预测高强钢的真实应力-应变曲线。该方法通过Gramian Angular Field将载荷-位移序列转化为图像以捕捉时空特征，并采用基于LSTM的Seq2Seq模型，结合多头交叉注意力机制以提高精度。实验结果表明，该方法的最小和最大平均绝对误差分别为0.15 MPa和5.58 MPa，预测精度显著。该方法为材料科学中的真实应力-应变关系预测提供了一种高效且准确的替代方案。

</details>


### [463] [Machine Learning Model Integration with Open World Temporal Logic for Process Automation](https://arxiv.org/abs/2506.17776)
**中文标题：机器学习模型与开放世界时序逻辑的集成以实现流程自动化**

*Dyuman Aditya,Colton Payne,Mario Leiva,Paulo Shakarian*

主要分类: cs.LG

摘要简述: 本文提出了一种将机器学习模型输出与PyReason框架（一种开放世界时序逻辑编程推理引擎）集成的新方法，旨在将感知和提取能力与逻辑推理结合，实现复杂流程的自动化决策。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习模型能够从复杂数据中提取结构化信息，但将其输出转化为可操作的决策仍具挑战性。本文旨在通过结合机器学习模型的感知能力和PyReason的逻辑推理能力，解决这一难题。

研究方法: 通过PyReason框架，将机器学习模型的输出（如概率和置信度）转换为逻辑事实，并动态计算最小模型，实现实时自适应决策。PyReason还支持时序推理和知识图谱集成。

研究结果: 该方法能够将机器学习模型的感知输出与逻辑推理无缝结合，支持复杂流程的自动化决策，适用于制造、医疗和商业运营等多个领域。

研究结论: 通过集成机器学习与PyReason框架，本文提出了一种强大的系统，能够实现复杂流程的自动化决策，同时具备透明性和可解释性。

中文摘要: 机器学习（ML）的最新进展催生了能够从多样化和复杂数据源中提取结构化信息的强大模型。然而，将这些感知或提取输出转化为复杂工作流程中的可操作决策仍是一个重大挑战。为解决这一问题，本文提出了一种新方法，将各种机器学习模型的输出直接与PyReason框架（一种开放世界时序逻辑编程推理引擎）集成。PyReason基于广义注释逻辑，能够无缝整合来自不同机器学习模型的实值输出（如概率、置信度），并将其视为逻辑框架中的真值区间。关键的是，PyReason通过Python实现的机制持续轮询机器学习模型的输出，将其转换为逻辑事实，并动态重新计算最小模型，确保实时自适应决策。此外，其对时序推理、知识图谱集成和完全可解释的接口跟踪的原生支持，使得能够对时间敏感的流程数据和现有组织知识进行复杂分析。通过结合机器学习模型的感知和提取能力与PyReason的逻辑推理和透明性，我们旨在创建一个强大的系统，用于自动化复杂流程。这种集成在制造、医疗和商业运营等多个领域具有广泛应用。

</details>


### [464] [Toward Autonomous UI Exploration: The UIExplorer Benchmark](https://arxiv.org/abs/2506.17779)
**中文标题：迈向自主UI探索：UIExplorer基准测试**

*Andrei Cristian Nica,Akshaya Vishnu Kudlu Shanbhogue,Harshil Shah,Aleix Cambray,Tudor Berariu,Lucas Maystre,David Barber*

主要分类: cs.LG

摘要简述: 本文介绍了首个专注于UI探索的基准测试UIExplore-Bench，通过结构化模式和屏幕模式评估代理在GitLab沙盒环境中的表现，并提出hUFO指标量化探索效果。结果显示UIExplore-AlGo表现最佳，但仍与人类专家存在差距。


<details>
  <summary>详细信息</summary>
研究动机: 目前缺乏对自主代理在用户界面（UI）探索阶段的系统性评估，而这一阶段对任务解决的可靠性至关重要。因此，本文旨在填补这一空白，推动UI探索研究的发展。

研究方法: 研究提出了UIExplore-Bench基准测试，包含结构化模式（基于DOM树等布局信息）和屏幕模式（基于GUI观察如截图和模拟人机交互）。探索目标为最大化发现可操作的UI组件，并采用hUFO指标量化效果。测试在GitLab沙盒环境中进行，分为三个难度级别。

研究结果: UIExplore-AlGo在结构化模式和屏幕模式下的hUFO得分分别为77.2%和59.0%，表现最佳，尤其在稀疏级别上突出。然而，与人类专家一小时的探索相比，现有代理仍有显著差距。

研究结论: UIExplore-Bench基准测试的提出为UI探索研究提供了标准化评估工具，揭示了当前代理与人类表现的差距，为未来研究指明了方向。同时，公开的测试环境、数据集和评估套件将推动高效UI探索策略及其应用的发展。

中文摘要: 自主代理需要掌握如何探索用户界面（UI）以实现可靠的任务解决，但目前缺乏对这一关键阶段的系统性评估。我们推出了首个专注于UI探索的基准测试UIExplore-Bench。该基准测试在标准化的GitLab沙盒环境中，通过结构化模式（提供DOM树等布局信息）或屏幕模式（依赖GUI观察如截图和模拟人机交互）评估代理在三个难度级别的表现。我们将探索定义为最大化发现可操作的UI组件的过程，并提出人类标准化UI功能观察指标（hUFO）来量化探索效果。结果显示，UIExplore-AlGo在结构化模式和屏幕模式下的hUFO得分分别达到人类表现的77.2%和59.0%（2000步时），尤其在稀疏级别表现突出。这些结果凸显了基准测试的重要性，因为当前代理与人类专家一小时的探索相比仍存在显著差距，表明未来有较大改进空间。我们公开了基准测试环境、探索数据集和评估套件，以推动高效UI探索策略及其下游应用（如经验驱动的任务完成和自动化训练数据生成）的研究。

</details>


### [465] [Reimagining Parameter Space Exploration with Diffusion Models](https://arxiv.org/abs/2506.17807)
**中文标题：利用扩散模型重新探索参数空间**

*Lijun Zhang,Xiao Liu,Hui Guan*

主要分类: cs.LG

摘要简述: 本文提出使用扩散模型直接从任务标识生成任务特定参数，避免了传统微调的时间和标注数据依赖。实验表明，该方法在已知任务上表现良好，但在未知任务上泛化能力有限。


<details>
  <summary>详细信息</summary>
研究动机: 传统神经网络适应新任务需要任务特定的微调，耗时且依赖标注数据。本文探索一种生成式方法，直接从任务标识生成参数，以解决这一问题。

研究方法: 使用扩散模型学习任务特定参数空间的结构，并根据任务标识生成参数。模型训练后，可直接为已知任务、多任务和未知任务生成参数。

研究结果: 实验表明，扩散模型能为已知任务生成准确参数，并支持多任务插值，但在未知任务上泛化能力不足。

研究结论: 扩散模型在生成任务特定参数方面具有潜力，但在未知任务上的泛化能力仍需改进。

中文摘要: 神经网络适应新任务通常需要任务特定的微调，这既耗时又依赖标注数据。我们探索了一种生成式替代方案，直接从任务标识生成任务特定参数，无需任务特定训练。为此，我们提出使用扩散模型学习有效任务特定参数空间的基础结构，并按需合成参数。训练完成后，任务条件扩散模型可直接从任务标识生成专用权重。我们在三种场景下评估了该方法：为单个已知任务、多个已知任务和完全未知任务生成参数。实验表明，当参数子空间结构良好时，扩散模型能生成准确的任务特定参数并支持多任务插值，但在未知任务上无法泛化，凸显了这一生成式解决方案的潜力与局限性。

</details>


### [466] [Actionable Interpretability via Causal Hypergraphs: Unravelling Batch Size Effects in Deep Learning](https://arxiv.org/abs/2506.17826)
**中文标题：基于因果超图的可操作可解释性：揭示深度学习中的批量大小效应**

*Zhongtian Sun,Anoushka Harit,Pietro Lio*

主要分类: cs.LG

摘要简述: 本文提出了一种基于超图的因果框架HGCNet，用于揭示批量大小如何通过梯度噪声、极小值锐度和模型复杂性影响深度学习中的泛化性能，实验证明小批量能通过增加随机性和平坦极小值提升泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管批量大小对视觉任务泛化性能的影响已有研究，但其在图和文本领域的因果机制尚未深入探索。本文旨在填补这一空白，提供可解释的因果分析以指导深度学习训练策略。

研究方法: 提出HGCNet框架，利用深度结构因果模型（DSCMs）和超图捕捉训练动态中的高阶交互，通过do-演算量化批量大小干预的直接和间接效应。

研究结果: 实验表明，HGCNet在引文网络、生物医学文本和电商评论数据上优于GCN、GAT、PI-GNN、BERT和RoBERTa等基线模型，揭示小批量通过增加随机性和平坦极小值提升泛化能力。

研究结论: 本研究将可解释性作为深度学习架构和优化选择的驱动力，为训练策略提供了基于因果分析的实际指导。

中文摘要: 尽管批量大小对视觉任务泛化性能的影响已有研究，但其在图和文本领域的因果机制尚未深入探索。我们提出了一种基于超图的因果框架HGCNet，利用深度结构因果模型（DSCMs）揭示批量大小如何通过梯度噪声、极小值锐度和模型复杂性影响泛化性能。与以往基于静态成对依赖的方法不同，HGCNet采用超图捕捉训练动态中的高阶交互。通过do-演算，我们量化了批量大小干预的直接和间接效应，为优化提供了可解释的因果分析。在引文网络、生物医学文本和电商评论上的实验表明，HGCNet优于GCN、GAT、PI-GNN、BERT和RoBERTa等基线模型。分析揭示，较小的批量大小通过增加随机性和平坦极小值因果性地提升泛化能力，为深度学习训练策略提供了可操作的可解释性。本研究将可解释性作为架构和优化选择的驱动力，超越了事后分析的范畴。

</details>


### [467] [Causal Spherical Hypergraph Networks for Modelling Social Uncertainty](https://arxiv.org/abs/2506.17840)
**中文标题：因果超球面超图网络：用于建模社会不确定性**

*Anoushka Harit,Zhongtian Sun*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Causal-SphHN的框架，用于建模社会不确定性，通过超球面嵌入和超边表示个体与群体关系，结合熵量化不确定性，并利用Granger因果子图识别时间依赖性。实验表明该方法在预测准确性、鲁棒性和可解释性上优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 人类社交行为受复杂交互影响，涉及不确定性、因果关系和群体动态。现有方法难以统一建模这些因素，因此需要一种新的框架来捕捉高阶结构、方向性影响和认知不确定性。

研究方法: Causal-SphHN将个体表示为超球面嵌入，群体上下文表示为超边，通过von Mises-Fisher分布量化不确定性，利用Granger因果子图识别时间依赖性，并通过角度消息传递机制传播信息。

研究结果: 在SNARE、PHEME和AMIGOS数据集上的实验表明，Causal-SphHN在预测准确性、鲁棒性和校准性上优于基线模型，并能提供可解释的影响模式和社交模糊性分析。

研究结论: 本文提出了一种统一的因果几何方法，用于动态社交环境中的不确定性学习，为理解复杂社交行为提供了新工具。

中文摘要: 人类社交行为受复杂交互影响，涉及不确定性、因果关系和群体动态。我们提出了因果超球面超图网络（Causal-SphHN），这是一种基于社会背景的预测框架，联合建模高阶结构、方向性影响和认知不确定性。该方法将个体表示为超球面嵌入，群体上下文表示为超边，捕捉语义和关系几何。不确定性通过von Mises-Fisher分布的香农熵量化，时间因果依赖通过Granger因果子图识别。信息通过角度消息传递机制传播，尊重信念分散和方向性语义。在SNARE（离线网络）、PHEME（在线讨论）和AMIGOS（多模态情感）上的实验表明，Causal-SphHN在预测准确性、鲁棒性和校准性上优于基线模型，并能提供可解释的影响模式和社交模糊性分析。这项工作为动态社交环境中的不确定性学习提供了一种统一的因果几何方法。

</details>


### [468] [A Comparative Study of Open-Source Libraries for Synthetic Tabular Data Generation: SDV vs. SynthCity](https://arxiv.org/abs/2506.17847)
**中文标题：开源表格合成数据生成库的比较研究：SDV vs. SynthCity**

*Cristian Del Gobbo*

主要分类: cs.LG

摘要简述: 本研究比较了两种开源库（SDV和SynthCity）中的六种表格合成数据生成器，评估其在统计相似性和预测实用性上的表现。结果显示，SynthCity的贝叶斯网络在数据保真度上表现最佳，而SDV的TVAE在预测任务中表现最优。SDV因其文档和易用性更受推荐。


<details>
  <summary>详细信息</summary>
研究动机: 高质量的训练数据对机器学习模型（尤其是大语言模型）至关重要，但获取真实高质量数据对小型组织和初创公司具有挑战性。合成数据生成器通过复制真实数据的统计和结构特性，同时保护隐私和扩展性，提供了一种可行的解决方案。

研究方法: 研究使用来自UCI机器学习库的真实数据集（比利时能源消耗和环境变量），在低数据量（1,000行）下训练模型。评估了六种合成数据生成器（SDV中的高斯Copula、CTGAN、TVAE；SynthCity中的贝叶斯网络、CTGAN、TVAE），分别在1:1（1,000行）和1:10（10,000行）输入输出比例下生成合成数据。评估标准包括统计相似性（经典统计和分布度量）和预测实用性（“合成训练，真实测试”方法）。

研究结果: 统计相似性在两种场景下表现一致，但预测实用性在1:10比例下显著下降。SynthCity的贝叶斯网络在两种场景下保真度最高，而SDV的TVAE在1:10比例下预测任务表现最佳。两种库在性能上无显著差距，但SDV因其文档和易用性更受推荐。

研究结论: 合成数据生成器在低数据量下表现良好，但预测实用性随数据量增加而下降。SDV和SynthCity各有优势，SDV更适合实际应用。

中文摘要: 高质量的训练数据对机器学习模型（尤其是大语言模型）的性能至关重要，但获取真实高质量数据对小型组织和初创公司具有挑战性。合成数据生成器通过复制真实数据的统计和结构特性，同时保护隐私和扩展性，提供了一种可行的解决方案。本研究评估了两种广泛使用的开源库（SDV和SynthCity）中的六种表格合成数据生成器。使用来自UCI机器学习库的真实数据集（比利时能源消耗和环境变量），在低数据量（1,000行）下训练模型。每种生成器分别在1:1（1,000行）和1:10（10,000行）输入输出比例下生成合成数据。评估标准包括统计相似性（经典统计和分布度量）和预测实用性（“合成训练，真实测试”方法）。结果显示，统计相似性在两种场景下表现一致，但预测实用性在1:10比例下显著下降。SynthCity的贝叶斯网络在两种场景下保真度最高，而SDV的TVAE在1:10比例下预测任务表现最佳。两种库在性能上无显著差距，但SDV因其文档和易用性更受推荐。

</details>


### [469] [Pathway-based Progressive Inference (PaPI) for Energy-Efficient Continual Learning](https://arxiv.org/abs/2506.17848)
**中文标题：Error**

*Suyash Gaurav,Jukka Heikkonen,Jatin Chaudhary*

主要分类: cs.LG

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [470] [In-Context Learning Strategies Emerge Rationally](https://arxiv.org/abs/2506.17859)
**中文标题：上下文学习策略的理性涌现**

*Daniel Wurgaft,Ekdeep Singh Lubana,Core Francisco Park,Hidenori Tanaka,Gautam Reddy,Noah D. Goodman*

主要分类: cs.LG

摘要简述: 本文通过贝叶斯框架解释了Transformer模型在上下文学习（ICL）中为何选择不同策略，揭示了策略选择是损失与复杂度权衡的结果，并预测了任务多样性增加时记忆化策略的转变趋势。


<details>
  <summary>详细信息</summary>
研究动机: 近期研究发现了上下文学习（ICL）中模型行为的多种策略，但未解释为何模型会学习这些策略。本文旨在通过理性分析框架，揭示模型选择策略的内在原因，并统一现有发现。

研究方法: 作者提出了一种分层贝叶斯框架，将预训练视为更新策略后验概率的过程，推断行为则是这些策略预测的后验加权平均。该框架基于神经网络学习动态的常见假设，明确了策略损失与复杂度之间的权衡。

研究结果: 该框架几乎完美预测了Transformer在训练过程中的下一个标记预测，无需访问模型权重。同时，研究发现任务多样性增加时，记忆化策略的转变时间呈现超线性趋势。

研究结论: 本文通过损失与复杂度的权衡，为上下文学习提供了解释性和预测性理论，揭示了模型策略选择的合理性，并提出了新的预测，如任务多样性对记忆化策略的影响。

中文摘要: 近期关于上下文学习（ICL）的研究揭示了模型在不同实验条件下行为的多种策略。本文旨在通过探究模型为何学习这些策略来统一这些发现。具体而言，我们观察到，当模型被训练学习混合任务（如文献中常见）时，其用于ICL的策略可以通过贝叶斯预测器家族捕捉：记忆化预测器（假设对已见任务集采用离散先验）和泛化预测器（先验与底层任务分布匹配）。借鉴认知科学中的理性分析视角（将学习者行为解释为在计算约束下对数据的最优适应），我们开发了一个分层贝叶斯框架，该框架几乎完美预测了Transformer在训练过程中的下一个标记预测，而无需访问其权重。在此框架下，预训练被视为更新不同策略后验概率的过程，推断行为则是这些策略预测的后验加权平均。我们的框架基于关于神经网络学习动态的常见假设，明确了候选策略在损失与复杂度之间的权衡：模型对策略的偏好不仅取决于其对数据的解释能力，还取决于其复杂度。这解释了已知的ICL现象，同时提出了新预测：例如，我们展示了任务多样性增加时记忆化策略转变时间尺度的超线性趋势。总体而言，我们的工作基于策略损失与复杂度的权衡，为ICL提供了兼具解释性和预测性的理论。

</details>


### [471] [NestQuant: Post-Training Integer-Nesting Quantization for On-Device DNN](https://arxiv.org/abs/2506.17870)
**中文标题：NestQuant：一种用于设备端深度神经网络的后训练整数嵌套量化方法**

*Jianhang Xie,Chuntao Ding,Xiaqing Li,Shenyuan Ren,Yidong Li,Zhichao Lu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为NestQuant的后训练整数嵌套量化方法，用于物联网设备上的量化模型切换。通过整数权重分解和嵌套机制，NestQuant仅需存储一个模型即可适应不同资源需求，显著减少传输、存储和切换开销。实验表明，该方法在保持高精度的同时，显著降低了资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 当前的后训练量化方法仅提供固定位宽模型，难以适应物联网设备的动态资源需求；而部署多量化模型则消耗大量存储和切换资源。因此，需要一种资源友好的量化方法，既能适应动态资源变化，又能减少开销。

研究方法: NestQuant通过整数权重分解将量化权重按位拆分为高位和低位整数权重，并采用嵌套机制优化高位权重。在部署时，仅需存储一个模型，通过动态加载低位权重实现模型切换，从而适应资源变化。

研究结果: 实验结果显示，NestQuant在ImageNet-1K预训练模型上表现优异，例如ResNet-101的INT8嵌套INT6模型在完整位和部分位模式下分别达到78.1%和77.9%的准确率，切换开销减少约78.1%。

研究结论: NestQuant是一种高效的量化方法，能够在保持模型性能的同时，显著降低物联网设备的资源消耗，适用于动态资源环境。

中文摘要: 在物联网设备上部署具有资源适应能力的量化深度神经网络（DNN）模型，可以提供高质量的AI服务，同时利用压缩的优势并满足多场景资源需求。然而，现有的动态/混合精度量化需要重新训练或特殊硬件支持，而后训练量化（PTQ）在资源适应方面存在两个局限性：（i）现有PTQ方法仅提供固定位宽模型，难以适应物联网设备的动态资源；（ii）部署多量化模型会消耗大量存储资源并增加切换开销。为此，本文提出了一种资源友好的后训练整数嵌套量化方法NestQuant，用于物联网设备上的量化模型切换。NestQuant通过整数权重分解将量化权重按位拆分为高位和低位整数权重，并采用嵌套机制优化高位权重。在部署时，仅需存储一个NestQuant模型，通过动态加载低位权重实现模型切换，从而适应资源变化并减少开销。实验结果表明，NestQuant在ImageNet-1K预训练模型上表现优异，例如ResNet-101的INT8嵌套INT6模型在完整位和部分位模式下分别达到78.1%和77.9%的准确率，切换开销减少约78.1%。

</details>


### [472] [Permutation Equivariant Model-based Offline Reinforcement Learning for Auto-bidding](https://arxiv.org/abs/2506.17919)
**中文标题：基于置换等变模型的离线强化学习自动竞价方法**

*Zhiyu Mou,Miao Xu,Wei Chen,Rongquan Bai,Chuan Yu,Jian Xu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于置换等变模型的离线强化学习方法（PE-MORL），用于自动竞价，通过结合真实数据和模型生成数据扩展状态覆盖范围，并采用悲观惩罚机制提高模型可靠性。实验表明，该方法优于现有自动竞价技术。


<details>
  <summary>详细信息</summary>
研究动机: 现有离线强化学习自动竞价方法（ORLB）受限于数据集状态覆盖范围，而基于模拟器的方法（SRLB）存在模拟与现实差距问题。本文旨在通过模型学习结合真实与模拟数据，提升自动竞价效果。

研究方法: 提出基于模型的强化学习自动竞价方法（MRLB），包括置换等变模型架构以增强泛化能力，以及悲观惩罚的离线Q学习方法（PE-MORL），结合真实与模型生成数据训练策略。

研究结果: 实验结果表明，PE-MORL在真实场景中优于现有自动竞价方法，扩展了状态覆盖范围并提高了策略性能。

研究结论: PE-MORL通过模型学习和悲观惩罚机制，有效解决了自动竞价中状态覆盖不足和模拟差距问题，为离线强化学习在自动竞价中的应用提供了新思路。

中文摘要: 自动竞价的强化学习（RL）从基于离线模拟器（SRLB）转向基于固定真实数据集的离线RL（ORLB）。然而，ORLB策略受限于数据集的状态覆盖范围，提升有限。虽然SRLB扩展了状态覆盖，但其模拟与现实的差距可能导致策略误导。本文提出基于模型的RL竞价方法（MRLB），通过从真实数据学习环境模型来弥合这一差距。MRLB结合真实与模型生成数据训练策略，扩展了状态覆盖范围。为确保模型可靠性，我们提出：1）置换等变模型架构以提升泛化能力；2）悲观惩罚模型误差的鲁棒离线Q学习方法。二者构成置换等变模型离线RL算法（PE-MORL）。真实实验表明，PE-MORL优于现有自动竞价方法。

</details>


### [473] [Learning to Adapt Frozen CLIP for Few-Shot Test-Time Domain Adaptation](https://arxiv.org/abs/2506.17307)
**中文标题：学习适应冻结CLIP的小样本测试时域适应**

*Zhixiang Chi,Li Gu,Huan Liu,Ziqiang Wang,Yanan Wu,Yang Wang,Konstantinos N Plataniotis*

主要分类: cs.LG

摘要简述: 本文提出了一种新方法，通过在输入空间中学习补充冻结CLIP的特定数据集知识，结合贪婪文本集成和领域提示，显著提升了小样本测试时域适应的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖CLIP的预训练特征空间知识，但面对未显式见过的下游数据集时性能受限，尤其是在较弱的主干网络（如ViT-B/16）上表现显著下降。本文旨在通过直接学习输入空间知识来弥补这一不足。

研究方法: 提出了一种并行于CLIP的独立分支，通过反向注意力学习专属知识；采用贪婪文本集成增强文本特征的分散性；通过生成的领域提示逐步融合文本和视觉特征，实现特定领域的适应。

研究结果: 在5个大规模基准测试（WILDS和DomainNet）上表现优异，显著提升了ViT-B/16等小型网络的性能，如iWildCam的F1分数提高了5.1，FMoW的WC准确率提高了3.1%。

研究结论: 通过结合输入空间学习和领域提示，本文方法显著提升了小样本测试时域适应的性能，尤其是在较弱的主干网络上表现突出。

中文摘要: 小样本测试时域适应旨在利用少量未标记样本在测试时将模型适应到特定领域，以解决领域偏移问题。现有方法通过生成领域特定提示来利用CLIP的强大分布外（OOD）能力，但由于下游数据集未被CLIP显式见过，仅依赖特征空间知识受限于CLIP的先验知识。尤其是使用较弱的主干网络（如ViT-B/16）时，在具有挑战性的真实基准测试中性能显著下降。本文不同于现有方法，提出直接在输入空间中学习以补充冻结CLIP的特定数据集知识。具体而言，在CLIP旁并行附加一个独立分支，通过反向注意力强制学习专属知识；为更好地捕捉下游适应的特定标签语义，提出通过贪婪文本集成和细化增强文本特征的分散性；随后通过生成的领域提示逐步融合文本和视觉特征，实现特定领域的适应。大量实验表明，本文方法在5个大规模基准测试（WILDS和DomainNet）上表现优异，显著提升了ViT-B/16等小型网络的性能，如iWildCam的F1分数提高了5.1，FMoW的WC准确率提高了3.1%。

</details>


### [474] [ASTER: Adaptive Spatio-Temporal Early Decision Model for Dynamic Resource Allocation](https://arxiv.org/abs/2506.17929)
**中文标题：ASTER：面向动态资源分配的自适应时空早期决策模型**

*Shulun Chen,Wei Shao,Flora D. Salim,Hao Xue*

主要分类: cs.LG

摘要简述: ASTER提出了一种自适应时空早期决策模型，通过资源感知时空交互模块和多目标强化学习代理，将预测直接转化为可操作的决策，显著提升了资源分配效率和预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有时空预测研究多关注预测的及时性和准确性，但如何将预测结果转化为实际决策（如应急资源分配）仍是一大挑战。ASTER旨在解决预测与决策脱节的问题，直接支持可操作的决策。

研究方法: ASTER设计了资源感知时空交互模块（RaST），动态捕捉长短期依赖关系，并基于多目标强化学习开发了偏好导向决策代理（Poda），将预测信号转化为资源高效的干预策略。

研究结果: 在四个基准数据集上的实验表明，ASTER在早期预测准确性和资源分配效果上均达到领先水平，六项下游指标均有显著提升。

研究结论: ASTER通过整合预测与决策，显著提升了时空智能的实际应用效果，为动态资源分配提供了高效解决方案。

中文摘要: 支持决策一直是时空智能领域的核心目标。尽管先前研究提升了时空预测的及时性和准确性，但如何将这些预测转化为可操作的策略仍是关键挑战。主要限制在于预测与下游决策阶段的脱节，这会显著降低下游效率。例如，在应急响应中，重点是成功的资源分配和干预，而不仅仅是事件预测。为此，我们提出了一种自适应时空早期决策模型（ASTER），将预测范式从事件预判转变为可操作的决策支持。该框架确保信息直接用于决策，从而最大化整体效果。具体而言，ASTER引入了资源感知时空交互模块（RaST），动态捕捉资源条件下的长短期依赖关系，生成上下文感知的时空表征。为了直接生成可操作的决策，我们进一步设计了基于多目标强化学习的偏好导向决策代理（Poda），通过特定偏好和动态约束下的最优行动，将预测信号转化为资源高效的干预策略。在四个基准数据集上的实验结果表明，ASTER在早期预测准确性和资源分配效果上均达到领先水平，六项下游指标均有显著提升。

</details>


### [475] [Origins of Creativity in Attention-Based Diffusion Models](https://arxiv.org/abs/2506.17324)
**中文标题：基于注意力的扩散模型中创造力的起源**

*Emma Finn,T. Anderson Keller,Manos Theodosis,Demba E. Ba*

主要分类: cs.LG

摘要简述: 本文探讨了基于注意力的扩散模型中创造力的起源，扩展了现有理论以解释自注意力在生成全局一致图像中的作用。


<details>
  <summary>详细信息</summary>
研究动机: 随着扩散模型成为图像生成的首选工具，理解其创造力来源变得至关重要。现有理论未能解释自注意力在生成过程中的作用，本文旨在填补这一空白。

研究方法: 通过理论扩展和实验验证，研究将现有CNN扩散模型理论扩展到包含自注意力层的情况，分析其对图像生成的影响。

研究结果: 理论表明自注意力能促进局部特征的全局一致性排列，实验验证了这一点。

研究结论: 自注意力在扩散模型中起到关键作用，使生成的图像在全局上保持一致，超越了局部拼贴的限制。

中文摘要: 随着扩散模型成为图像生成的首选工具，图像质量不断提升，探讨扩散模型中‘创造力’的起源变得日益重要。分数匹配视角为理解扩散模型如何生成既合理又显著区别于训练图像的图像提供了有力工具。然而，现有理论仅适用于CNN参数化的扩散模型，未能解释自注意力在这一过程中的作用。本文初步将理论扩展到包含自注意力层的CNN扩散模型，表明自注意力能促进生成样本中局部特征的全局一致性排列，并通过实验验证了这一行为。

</details>


### [476] [An entropy-optimal path to humble AI](https://arxiv.org/abs/2506.17940)
**中文标题：通往谦逊AI的熵最优路径**

*Davide Bassetti,Lukáš Pospíšil,Michael Groom,Terence J. O'Kane,Illia Horenko*

主要分类: cs.LG

摘要简述: 本文提出了一种基于非平衡熵优化的新型数学框架，用于重构玻尔兹曼机，旨在解决当前AI模型的高成本和过度自信问题。该方法无需梯度下降，性能优越且成本低，适用于复杂问题和气候预测。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI模型存在高成本和过度自信的问题，尤其是在资源消耗和答案可靠性方面。本文旨在通过数学优化方法，开发一种更高效、更经济的AI学习框架。

研究方法: 提出了一种基于总概率定律的非平衡熵优化框架，重构玻尔兹曼机。该方法无需梯度下降，具有数学上可证明的存在性和唯一性标准，并提供答案置信度衡量。

研究结果: 在合成问题和历史气候数据上的实验表明，该方法生成的模型性能更优、更简洁，描述长度接近问题的内在复杂度边界。气候预测中，仅需少量数据即可实现高精度预测。

研究结论: 该熵优化框架显著提升了AI模型的性能和效率，降低了成本，同时提高了答案的可靠性，为复杂问题和气候预测提供了新思路。

中文摘要: AI的进步催生了许多成功但远非谦逊的模型和工具，尤其是在（i）它们所需的高昂且不断飙升的成本和资源，以及（ii）这些工具对答案的过度自信方面。本文提出了一种基于总概率定律的非平衡熵优化框架，用于重构玻尔兹曼机。该方法形成了一个高性能但成本更低、无需梯度下降的学习框架，具有数学上可证明的存在性和唯一性标准，并提供答案置信度衡量。与最先进的AI工具在性能、成本和模型描述长度上的比较表明，该方法生成的模型性能更优且更简洁，描述长度非常接近问题的内在复杂度边界。将该框架应用于历史气候数据，生成的模型对拉尼娜和厄尔尼诺气候现象的预测能力显著提升，仅需少量气候数据即可训练——远少于当代气候预测工具所需的数据量。

</details>


### [477] [Adapting Vision-Language Models for Evaluating World Models](https://arxiv.org/abs/2506.17967)
**中文标题：适应视觉语言模型以评估世界模型**

*Mariya Hendriksen,Tabish Rashid,David Bignell,Raluca Georgescu,Abdelhak Lemkhenter,Katja Hofmann,Sam Devlin,Sarah Parisot*

主要分类: cs.LG

摘要简述: 本文提出了一种适应视觉语言模型（VLMs）的方法UNIVERSE，用于评估世界模型的动态模拟效果，通过动作识别和角色识别任务验证其性能，并在计算和数据限制下实现高效评估。


<details>
  <summary>详细信息</summary>
研究动机: 世界模型在规划、模拟和具身AI中日益重要，但其动态模拟效果的评估仍缺乏细粒度和时间敏感的指标。视觉语言模型因其多模态推理能力有望成为自动评估工具，但需针对性适配。

研究方法: 提出UNIVERSE方法，通过动作识别和角色识别任务（包括二选一、多选和开放式格式）评估世界模型。研究比较了完整、部分和参数高效的微调策略，以及不同任务格式、上下文长度、采样策略和数据组合。

研究结果: UNIVERSE在单一检查点下达到任务专用基线的性能，并通过人类研究验证其与人类判断高度一致，成为可扩展且语义感知的评估工具。

研究结论: UNIVERSE为世界模型提供了一种高效、语义感知的评估方法，解决了现有指标的不足，并在计算和数据限制下表现出色。

中文摘要: 世界模型——基于过去观察和动作生成环境动态的生成模型——在规划、模拟和具身AI中日益重要。然而，评估其动态模拟效果仍是一个基本挑战，需要细粒度、时间敏感的评估动作对齐和语义一致性，而现有指标无法满足。视觉语言模型（VLMs）因其强大的多模态推理能力，有望成为生成内容的自动评估工具，但在细粒度、时间敏感任务中的应用仍有限且需针对性适配。我们提出了一种评估协议，针对动作识别和角色识别两项任务，分别以二选一、多选和开放式格式进行评估。为此，我们提出了UNIVERSE（统一视觉语言评估器），一种在计算和数据限制下适配VLMs的方法。我们进行了大规模研究，比较了完整、部分和参数高效的微调策略，以及不同任务格式、上下文长度、采样策略和数据组合。最终的统一评估器在单一检查点下达到任务专用基线的性能。人类研究证实其与人类判断高度一致，确立了UNIVERSE作为世界模型的可扩展、语义感知评估工具的地位。

</details>


### [478] [DRIMV_TSK: An Interpretable Surgical Evaluation Model for Incomplete Multi-View Rectal Cancer Data](https://arxiv.org/abs/2506.17552)
**中文标题：DRIMV_TSK：一种针对不完整多视角直肠癌数据的可解释手术评估模型**

*Wei Zhang,Zi Wang,Hanwen Zhou,Zhaohong Deng,Weiping Ding,Yuxi Ge,Te Zhang,Yuanpeng Zhang,Kup-Sze Choi,Shitong Wang,Shudong Hu*

主要分类: cs.LG

摘要简述: 本文提出了一种可解释的不完整多视角直肠癌手术评估模型DRIMV_TSK，通过构建多视角数据集（包括高分辨率MRI、压脂MRI和临床数据）并整合双表示学习和TSK模糊系统，显著提升了手术难度评估的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前直肠癌手术难度评估主要依赖临床数据，但随着技术进步，更多数据（如MRI图像）可用于评估。人工智能的发展为直肠癌治疗提供了新的可能性。本文旨在通过多视角数据构建和可解释模型，提升手术评估的全面性和准确性。

研究方法: 首先构建多视角直肠癌数据集，包括高分辨率MRI、压脂MRI和临床数据。提出双表示不完整多视角学习模型，提取视图间共同信息和各视图特有信息，并整合缺失视图填补与表示学习。引入二阶相似性约束优化协作学习。基于填补后的多视角数据和双表示，提出结合TSK模糊系统的多视角手术评估模型，通过协作学习机制探索视图间一致性信息，并引入香农熵自适应调整视图权重。

研究结果: 在MVRC数据集上，DRIMV_TSK模型与多种先进算法对比，取得了最优结果，验证了其在手术难度评估中的有效性。

研究结论: DRIMV_TSK模型通过多视角数据整合和可解释学习机制，显著提升了直肠癌手术评估的准确性和可靠性，为临床实践提供了有力工具。

中文摘要: 可靠的手术难度评估可提高直肠癌治疗的成功率，而当前评估方法主要基于临床数据。随着技术进步，更多关于直肠癌的数据（如MRI图像）可被采集，同时人工智能的发展使其在直肠癌治疗中的应用成为可能。本文首先构建了一个多视角直肠癌数据集，包括高分辨率MRI图像、压脂MRI图像和临床数据视图，以提供更全面的患者信息。随后，针对实际应用中难以获取完整患者数据的问题，提出了一种可解释的不完整多视角手术评估模型。具体而言，首先提出了一种双表示不完整多视角学习模型，用于提取视图间的共同信息和各视图的特有信息。该模型将缺失视图填补整合到表示学习中，并引入二阶相似性约束以优化两部分协作学习。然后，基于填补后的多视角数据和学习的双表示，提出了一种结合TSK模糊系统的多视角手术评估模型。在该模型中，构建了协作学习机制以探索视图间的一致性信息，并引入香农熵自适应调整视图权重。在MVRC数据集上，与多种先进算法对比，DRIMV_TSK取得了最优结果。

</details>


### [479] [h-calibration: Rethinking Classifier Recalibration with Probabilistic Error-Bounded Objective](https://arxiv.org/abs/2506.17968)
**中文标题：h-calibration：重新思考基于概率误差有界目标的分类器校准**

*Wenjian Huang,Guiping Cao,Jiahao Xia,Jingkun Chen,Hao Wang,Jianguo Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为h-calibration的概率学习框架，用于解决深度神经网络输出概率的校准问题。通过理论分析和实验验证，该方法克服了现有校准方法的十大局限性，并在性能上显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络在许多任务中表现出色，但其输出的概率往往存在校准问题，导致不可靠的概率预测。尽管已有许多后校准方法试图解决这一问题，但它们存在多种局限性。本文旨在通过理论分析和新的学习框架，提出一种更有效的校准方法。

研究方法: 本文提出了h-calibration框架，通过理论构建了一个具有有界性的等效学习目标，并设计了一种简单而有效的后校准算法。该方法不仅克服了现有方法的十大局限性，还通过实验验证了其优越性。

研究结果: 实验结果表明，h-calibration在标准后校准基准测试中达到了最先进的性能，显著优于传统方法。理论分析还揭示了其与传统评分规则的关系和优势。

研究结论: h-calibration框架为学习有界校准概率提供了一种近似可微的目标，阐明了计算统计与理论界限的对应关系。其理论有效性通过实验得到了验证，为相关领域提供了有价值的参考。

中文摘要: 深度神经网络在许多学习任务中表现出色，但其输出的概率往往存在校准问题，导致不可靠的概率预测。这激发了近年来许多关于缓解校准问题的研究，特别是通过后校准方法，旨在不牺牲预训练模型分类性能的情况下获得校准概率。本研究将前人工作总结为三种策略：直观设计方法、基于分箱的方法和基于理想校准公式的方法。通过理论和实践分析，我们指出了前人方法的十大常见局限性。为解决这些局限性，我们提出了一种名为h-calibration的概率学习框架，理论上构建了一个具有有界性的等效学习目标。在此基础上，我们设计了一种简单而有效的后校准算法。该方法不仅克服了十大局限性，还在实验中显著优于传统方法。我们还从理论和实验上分析了我们的学习目标与传统评分规则的关系和优势。总之，我们的概率框架为学习误差有界的校准概率提供了一个近似可微的目标，阐明了计算统计与理论界限的对应关系和收敛性质。理论有效性在标准后校准基准测试中通过达到最先进性能得到了验证。这项研究为学习相关领域的可靠似然提供了有价值的参考。

</details>


### [480] [Probing the Embedding Space of Transformers via Minimal Token Perturbations](https://arxiv.org/abs/2506.18011)
**中文标题：通过最小令牌扰动探究Transformer的嵌入空间**

*Eddie Conti,Alejandro Astruc,Alvaro Parafita,Axel Brando*

主要分类: cs.LG

摘要简述: 本文通过最小化令牌扰动研究Transformer模型的嵌入空间，发现罕见令牌通常导致更大的嵌入偏移，并验证了浅层可作为模型解释的代理。


<details>
  <summary>详细信息</summary>
研究动机: 理解Transformer模型中信息传播的方式是解释性的关键挑战，本文旨在通过最小令牌扰动研究嵌入空间的变化。

研究方法: 通过实验分析令牌扰动对嵌入空间的影响，研究扰动在不同层间的传播，并比较罕见与常见令牌的嵌入偏移。

研究结果: 实验表明，罕见令牌通常导致更大的嵌入偏移，且输入信息在深层网络中逐渐混合，验证了浅层可作为解释模型的代理。

研究结论: 本文提出令牌扰动与嵌入空间偏移的结合是模型解释性的有力工具，并验证了浅层网络在解释中的重要性。

中文摘要: 理解Transformer模型中信息的传播是解释性的关键挑战。本文通过研究最小令牌扰动对嵌入空间的影响，分析了哪些令牌更容易导致微小偏移，发现罕见令牌通常引发更大的偏移。此外，我们研究了扰动在不同层间的传播，表明输入信息在深层网络中逐渐混合。研究结果验证了浅层网络可作为模型解释的代理这一常见假设。总体而言，本文提出令牌扰动与嵌入空间偏移的结合是模型解释性的有力工具。

</details>


### [481] [Decoding Federated Learning: The FedNAM+ Conformal Revolution](https://arxiv.org/abs/2506.17872)
**中文标题：解码联邦学习：FedNAM+共形革命**

*Sree Bhargavi Balija,Amitash Nanda,Debashis Sahoo*

主要分类: cs.LG

摘要简述: 本文提出FedNAM+框架，结合神经加法模型与新型共形预测方法，为联邦学习提供可解释且可靠的预测不确定性估计，并通过实验验证其高效性和透明性。


<details>
  <summary>详细信息</summary>
研究动机: 现有联邦学习框架缺乏结合不确定性量化、可解释性和鲁棒性的综合解决方案，FedNAM+旨在填补这一空白。

研究方法: FedNAM+通过动态层级调整技术和基于梯度的敏感度映射，识别关键输入特征，提供像素级不确定性估计和可视化预测可靠性。

研究结果: 在CT扫描、MNIST和CIFAR数据集上的实验表明，FedNAM+预测精度高（如MNIST仅损失0.1%），且提供透明的不确定性度量，计算开销低于蒙特卡洛Dropout。

研究结论: FedNAM+为去中心化预测建模提供了鲁棒、可解释且计算高效的框架，增强了信任和透明度。

中文摘要: 联邦学习在分布式机器学习模型训练中取得了显著进展，但现有框架通常缺乏结合不确定性量化、可解释性和鲁棒性的综合解决方案。为此，我们提出FedNAM+，一种将神经加法模型（NAMs）与新型共形预测方法结合的联邦学习框架，以实现可解释且可靠的不确定性估计。我们的方法通过动态层级调整技术，利用基于梯度的敏感度映射识别影响预测的关键输入特征，从而同时实现可解释性和像素级不确定性估计。与LIME和SHAP等传统可解释性方法不同，FedNAM+提供了预测可靠性的可视化洞察。我们在CT扫描、MNIST和CIFAR数据集上验证了该方法，展示了高预测精度（如MNIST仅损失0.1%）和透明的不确定性度量。可视化分析揭示了可变不确定性区间，标出了可通过补充数据改进的低置信区域。与蒙特卡洛Dropout相比，FedNAM+以更低计算开销提供高效且全局的不确定性估计，尤其适合联邦学习场景。总体而言，FedNAM+为去中心化预测建模提供了鲁棒、可解释且计算高效的框架，增强了信任和透明度。

</details>


### [482] [Pathwise Explanation of ReLU Neural Networks](https://arxiv.org/abs/2506.18037)
**中文标题：ReLU神经网络的路径式解释**

*Seongwoo Lim,Won Jo,Joohyung Lee,Jaesik Choi*

主要分类: cs.LG

摘要简述: 本文提出了一种新的路径式解释方法，用于揭示ReLU神经网络的决策过程，通过关注隐藏单元的子集而非全部，提供了更清晰和一致的输入与决策关系理解。


<details>
  <summary>详细信息</summary>
研究动机: 神经网络的“黑箱”特性引发了对透明性和可靠性的担忧。以往研究试图通过所有隐藏单元的激活状态将ReLU网络解构为线性模型，但这种方法缺乏灵活性和细节。本文旨在通过路径式解释方法，提供更清晰、灵活的决策过程解释。

研究方法: 本文提出了一种路径式解释方法，关注决策路径中涉及的隐藏单元子集。该方法允许调整输入范围内的解释范围（从整体归因到特定组成部分），并支持对输入进行分解以提供更详细的解释。

研究结果: 实验表明，该方法在定量和定性上均优于其他方法，能够更清晰地揭示输入与决策之间的关系。

研究结论: 路径式解释方法为ReLU神经网络提供了更透明和可靠的决策过程解释，具有灵活性和细节性优势。

中文摘要: 神经网络在多个领域取得了成功，但其“黑箱”特性引发了对透明性和可靠性的担忧。以往关于ReLU网络的研究试图通过所有隐藏单元的激活状态将其解构为线性模型。本文提出了一种新方法，关注决策路径中涉及的隐藏单元子集。这种路径式解释提供了对输入与决策过程关系的更清晰和一致的理解。此外，该方法还允许调整输入范围内的解释范围（从整体归因到特定组成部分），并支持对输入进行分解以提供更详细的解释。实验表明，该方法在定量和定性上均优于其他方法。

</details>


### [483] [Distributionally robust minimization in meta-learning for system identification](https://arxiv.org/abs/2506.18074)
**中文标题：元学习中用于系统辨识的分布鲁棒最小化**

*Matteo Rufolo,Dario Piga,Marco Forgione*

主要分类: cs.LG

摘要简述: 本文探讨了在元学习中采用分布鲁棒最小化方法进行系统辨识，通过优化高损失任务提升最坏情况下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的元学习方法优化期望损失，忽略了任务间的变异性。本文旨在通过分布鲁棒优化范式，优先处理高损失任务，以提升在安全关键应用中的性能。

研究方法: 采用分布鲁棒优化方法，在元学习中优先优化高损失任务，并在合成动态系统类上进行训练和测试，包括分布内和分布外场景。

研究结果: 实验表明，该方法能够减少安全关键应用中的失败情况，提升在分布内和分布外场景下的性能。

研究结论: 分布鲁棒最小化方法在元学习中有效提升了系统辨识的性能，尤其是在最坏情况下，为安全关键应用提供了更可靠的解决方案。

中文摘要: 元学习旨在学习如何解决任务，从而能够快速适应新场景。本文探讨了在元学习中采用分布鲁棒最小化方法进行系统辨识。传统的元学习方法优化期望损失，忽略了任务间的变异性。我们采用了一种替代方法，即分布鲁棒优化范式，优先处理高损失任务，从而提升在最坏情况下的性能。通过在合成动态系统类上训练的元模型进行评估，并在分布内和分布外场景下进行测试，所提出的方法能够减少安全关键应用中的失败情况。

</details>


### [484] [RL for Reasoning by Adaptively Revealing Rationales](https://arxiv.org/abs/2506.18110)
**中文标题：通过自适应揭示理性实现推理的强化学习**

*Mohammad Hossein Amani,Aryo Lotfi,Nicolas Mario Baldwin,Samy Bengio,Mehrdad Farajtabar,Emmanuel Abbe,Robert West*

主要分类: cs.LG

摘要简述: 本文提出了一种基于强化学习（RL）的自适应回溯方法（AdaBack），通过动态调整训练时的部分目标输出前缀，解决了复杂序列生成任务中监督微调（SFT）和RL的局限性。该方法在数学推理任务中表现出色，能够解决传统方法无法处理的难题。


<details>
  <summary>详细信息</summary>
研究动机: 传统监督微调（SFT）依赖密集的真实标签，随着序列长度增加成本高昂；而强化学习（RL）则因稀疏奖励和巨大的输出空间而难以应对。本文旨在探索一种介于SFT和RL之间的方法，通过自适应部分监督提升模型在复杂任务中的表现。

研究方法: 提出自适应回溯（AdaBack）算法，动态调整每个样本的训练监督长度，仅揭示部分目标输出前缀。模型通过奖励信号逐步学习基于正确部分解完成推理链的能力。

研究结果: 在具有潜在奇偶约束的合成任务中，AdaBack成功解决了传统方法无法处理的问题。在数学推理基准（MATH、GSM8k）上，该方法使模型获得新的推理能力，解决了仅靠RL无法完成的任务。

研究结论: 自适应部分监督的课程学习不仅是一种效率与通用性的权衡，还能在SFT和RL均失效的长序列潜在依赖任务中取得成功。AdaBack为复杂序列生成任务提供了一种有效解决方案。

中文摘要: 我们提出，基于部分专家演示的强化学习（RL）不仅是一种训练启发式方法，还是解决复杂序列生成任务的有前景框架。监督微调（SFT）依赖密集的真实标签，随着序列长度增加成本急剧上升；而RL则因稀疏奖励和巨大的输出空间而难以应对。为解决这一问题，我们引入了自适应回溯（AdaBack），一种基于样本的课程学习算法，训练时仅揭示目标输出的部分前缀。监督长度根据模型过去的奖励信号动态调整，使其能够逐步学习基于正确部分解完成推理链的能力。我们研究了SFT与RL之间的这种中间状态，并认为基于样本的课程学习不仅是效率与通用性的权衡，还能在长序列潜在依赖任务中取得成功，而SFT和RL均无法泛化。通过具有潜在奇偶约束的合成任务，我们展示了自适应课程对部分答案的可靠解决能力。在数学推理基准（MATH、GSM8k）上，我们发现课程学习使模型能够解决仅靠RL无法完成的问题，通过逐步接触部分解获得新的推理能力。

</details>


### [485] [Pitfalls of Conformal Predictions for Medical Image Classification](https://arxiv.org/abs/2506.18162)
**中文标题：医学图像分类中保形预测的陷阱**

*Hendrik Mehrtens,Tabea Bucher,Titus J. Brinker*

主要分类: cs.LG

摘要简述: 本文指出，尽管保形预测在医学图像分类中因其可证明的校准保证而备受关注，但其在输入和标签变量分布偏移时不可靠，且不适用于提高准确性或特定数据子集（如单个类别或患者属性）。此外，在类别较少的医学分类任务中，其实用价值有限。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分类任务中，可靠的不确定性估计是一个重要挑战。保形预测因其可证明的校准保证而受到关注，但其在医学领域的应用存在潜在问题和限制，需要引起实践者的重视。

研究方法: 通过皮肤病学和组织病理学的实例，分析了保形预测在输入和标签变量分布偏移时的表现，并探讨了其在提高准确性或特定数据子集（如单个类别或患者属性）中的局限性。

研究结果: 研究发现，保形预测在分布偏移时不可靠，不适用于选择预测以提高准确性，且在数据子集（如单个类别或患者属性）中表现不稳定。此外，在类别较少的医学分类任务中，其实用价值有限。

研究结论: 保形预测在医学图像分类中虽有潜力，但其局限性（如对分布偏移的敏感性和在特定数据子集中的不可靠性）需引起重视，尤其是在安全关键的医学领域。

中文摘要: 可靠的不确定性估计是医学分类任务的主要挑战之一。尽管已有多种方法被提出，但近年来，保形预测的统计框架因其能够提供可证明的校准保证而备受关注。然而，在医学等安全关键领域中应用保形预测时，存在一些陷阱、限制和假设，实践者需要意识到这些问题。我们通过皮肤病学和组织病理学的实例表明，保形预测在输入和标签变量分布偏移时不可靠。此外，保形预测不应用于选择预测以提高准确性，且在数据子集（如单个类别或患者属性）中不可靠。另外，在类别较少的医学图像分类任务中，保形预测的实用价值有限。

</details>


### [486] [Routing Mamba: Scaling State Space Models with Mixture-of-Experts Projection](https://arxiv.org/abs/2506.18145)
**中文标题：路由Mamba：基于混合专家投影的状态空间模型扩展**

*Zheng Zhan,Liliang Ren,Shuohang Wang,Liyuan Liu,Yang Liu,Yeyun Gong,Yanzhi Wang,Yelong Shen*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Routing Mamba（RoM）的新方法，通过稀疏混合线性投影专家（MoE）扩展状态空间模型（SSM）的参数，显著提升了Mamba模型的表达能力和效率。实验表明，RoM在1.3B活跃参数（10B总参数）和16K训练序列长度下，性能与需要2.3倍活跃参数的密集Mamba模型相当，并节省了23%的计算资源。


<details>
  <summary>详细信息</summary>
研究动机: 线性状态空间模型（SSM）在高效序列建模中表现出色，但如何通过混合专家（MoE）有效扩展其表达能力仍具挑战性。本文旨在解决这一问题，提出一种能够高效扩展Mamba模型参数的方法。

研究方法: RoM通过稀疏混合线性投影专家（MoE）扩展Mamba模型的参数，共享投影层和轻量子模块的路由决策，从而利用线性投影专家之间的协同效应，实现高效稀疏扩展。

研究结果: 在1.3B活跃参数（10B总参数）和16K训练序列长度下，RoM的性能与需要2.3倍活跃参数的密集Mamba模型相当，同时在不同上下文长度下表现一致，并节省了23%的计算资源。

研究结论: RoM成功扩展了Mamba模型的表达能力，同时保持了高效性，为长序列建模提供了一种强有力且资源友好的替代方案。

中文摘要: 线性状态空间模型（SSM）在高效序列建模中表现出色，具有恒定的推理时间和内存复杂度。最近的Mamba等进展通过输入依赖的门控和硬件感知实现，进一步提升了SSM的性能，使其成为长序列建模中Transformer的有力替代者。然而，如何通过混合专家（MoE）高效扩展SSM的表达能力仍具挑战性，简单的集成尝试往往失败或性能下降。本文提出Routing Mamba（RoM），一种通过稀疏混合线性投影专家扩展SSM参数的新方法。RoM通过共享投影层和Mamba内部轻量子模块的路由决策，利用线性投影专家之间的协同效应，实现了Mamba层的高效稀疏扩展。在1.3B活跃参数（10B总参数）和16K训练序列长度下，RoM的语言建模性能与需要2.3倍活跃参数的密集Mamba模型相当，并在不同上下文长度下表现一致。实验还表明，RoM能有效扩展混合语言模型，在相似性能下比密集Mamba扩展节省23%的计算资源。

</details>


### [487] [Non-equilibrium Annealed Adjoint Sampler](https://arxiv.org/abs/2506.18165)
**中文标题：非平衡退火伴随采样器**

*Jaemoo Choi,Yongxin Chen,Molei Tao,Guan-Horng Liu*

主要分类: cs.LG

摘要简述: 本文提出了一种新型扩散采样器NAAS，通过结合退火参考动力学和伴随匹配技术，避免了重要性采样，实现了高效且可扩展的训练。


<details>
  <summary>详细信息</summary>
研究动机: 现有的扩散采样器通常依赖重要性采样，导致高方差和可扩展性受限。本文旨在通过引入退火参考动力学和伴随匹配技术，解决这些问题。

研究方法: 提出非平衡退火伴随采样器（NAAS），利用退火参考动力学和伴随匹配技术，避免重要性采样，实现高效训练。

研究结果: 实验表明，NAAS在经典能量景观和分子玻尔兹曼分布等任务中表现优异。

研究结论: NAAS通过结合退火参考动力学和伴随匹配技术，提供了一种高效且可扩展的扩散采样方法。

中文摘要: 近年来，基于学习的扩散采样器在从未归一化密度中采样方面取得了显著进展。这些方法通常遵循两种范式之一：(i) 使用规范参考过程将采样表述为无偏随机最优控制（SOC）问题，或 (ii) 通过重要性加权采样改进退火路径测度。尽管退火方法在引导样本向高密度区域移动方面具有优势，但对重要性采样的依赖导致实践中方差高且可扩展性有限。本文提出了一种新型SOC扩散采样器——非平衡退火伴随采样器（NAAS），它利用退火参考动力学而无需依赖重要性采样。NAAS采用受伴随匹配启发的轻量伴随系统，实现了高效且可扩展的训练。我们在包括经典能量景观和分子玻尔兹曼分布采样在内的多种任务中验证了该方法的有效性。

</details>


### [488] [Understanding Reasoning in Thinking Language Models via Steering Vectors](https://arxiv.org/abs/2506.18167)
**中文标题：通过转向向量理解思考型语言模型的推理行为**

*Constantin Venhoff,Iván Arcuschin,Philip Torr,Arthur Conmy,Neel Nanda*

主要分类: cs.LG

摘要简述: 本文提出了一种通过操纵激活空间中的线性方向（转向向量）来控制思考型语言模型推理行为的方法，并在DeepSeek-R1-Distill模型上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管思考型语言模型通过生成内部推理链提升了性能，但其推理过程难以控制。本文旨在通过分析并操纵模型激活空间中的特定方向，实现对推理行为的可控调节。

研究方法: 研究通过系统实验分析了500个任务中的推理行为，识别出表达不确定性、生成假设验证示例和回溯推理链等行为。这些行为由激活空间中的线性方向介导，可通过转向向量控制。

研究结果: 实验证明，转向向量能有效调节模型的特定推理行为（如回溯或表达不确定性），并在不同架构的DeepSeek-R1-Distill模型上表现一致。

研究结论: 本文提供了一种可控且可解释的方法来调节思考型模型的推理过程，为实际应用提供了实用工具。

中文摘要: 近年来，大型语言模型（LLM）的进步推动了思考型语言模型的发展，这些模型在生成响应前会生成复杂的内部推理链。尽管这些模型性能有所提升，但其推理过程的控制仍具挑战性。本研究提出了一种通过分析和操纵DeepSeek-R1-Distill模型中的特定推理行为来实现转向的方法。通过对10个不同类别的500项任务进行系统实验，我们识别出思考型模型表现出的多种推理行为，包括表达不确定性、生成假设验证示例以及回溯推理链。我们证明这些行为由模型激活空间中的线性方向介导，并可通过转向向量控制。通过提取和应用这些向量，我们提供了一种方法来调节模型推理过程的特定方面（如回溯倾向或不确定性表达）。我们的方法为可控且可解释地调节思考型模型的推理过程提供了实用工具。我们使用两个DeepSeek-R1-Distill模型验证了转向方法的有效性，证明了其在不同模型架构中的一致性控制。

</details>


### [489] [DeInfoReg: A Decoupled Learning Framework for Better Training Throughput](https://arxiv.org/abs/2506.18193)
**中文标题：DeInfoReg：一种解耦学习框架，通过信息正则化提升训练吞吐量**

*Zih-Hao Huang,You-Teng Lin,Hung-Hsuan Chen*

主要分类: cs.LG

摘要简述: DeInfoReg是一种新型解耦学习框架，通过将长梯度流分解为多个短梯度流，缓解梯度消失问题，并结合流水线策略实现多GPU并行训练，显著提升训练吞吐量。


<details>
  <summary>详细信息</summary>
研究动机: 传统反向传播（BP）在训练深度模型时存在梯度消失问题，且难以充分利用并行计算资源。DeInfoReg旨在通过解耦学习和信息正则化，优化梯度流并提升训练效率。

研究方法: DeInfoReg提出了一种解耦监督学习框架，将长梯度流分解为多个短梯度流，并结合信息正则化技术。通过流水线策略，实现模型在多GPU上的并行化训练。

研究结果: 实验表明，DeInfoReg在多种任务和数据集上表现优于传统BP模型，具有更强的抗噪能力和更高的训练吞吐量。

研究结论: DeInfoReg通过解耦学习和信息正则化，有效解决了梯度消失问题，并充分利用了并行计算资源，为高效训练深度模型提供了新思路。

中文摘要: 本文提出了一种名为“解耦监督学习与信息正则化”（DeInfoReg）的新方法，通过将长梯度流分解为多个短梯度流，缓解梯度消失问题。结合流水线策略，DeInfoReg实现了模型在多GPU上的并行化训练，显著提升了训练吞吐量。我们对比了标准反向传播和其他梯度流分解技术，实验结果表明，DeInfoReg在多种任务和数据集上表现优于传统BP模型，具有更强的抗噪能力，并能高效利用并行计算资源。代码已开源：https://github.com/ianzih/Decoupled-Supervised-Learning-for-Information-Regularization/。

</details>


### [490] [These are Not All the Features You are Looking For: A Fundamental Bottleneck In Supervised Pretraining](https://arxiv.org/abs/2506.18221)
**中文标题：这些并非你所需的全部特征：监督预训练中的根本瓶颈**

*Xingyu Alice Yang,Jianyu Zhang,Léon Bottou*

主要分类: cs.LG

摘要简述: 本文揭示了深度学习模型在预训练中存在的信息饱和瓶颈问题，即模型在预训练中无法学习新特征，导致迁移学习效果不佳。作者提出需要更丰富的特征表示来解决这一问题。


<details>
  <summary>详细信息</summary>
研究动机: 迁移学习是现代机器学习的核心，但如何确保预训练模型的特征能够适应新任务仍是一个挑战。本文旨在探讨预训练模型在迁移学习中的局限性，并提出解决方案。

研究方法: 作者通过评估模型从预训练混合数据迁移到其组成任务的表现，分析预训练特征是否能达到任务特定直接训练的效果。同时，提出了信息饱和瓶颈的概念，并探讨了数据分布和顺序对特征学习的影响。

研究结果: 研究发现，深度学习模型存在信息饱和瓶颈问题，导致预训练中无法学习新特征，从而影响迁移效果。实验证据表明，这一现象在现有架构中普遍存在。

研究结论: 单纯依赖大规模网络可能不如任务特定训练有效。作者建议采用更丰富的特征表示方法，以提升模型在新数据集上的泛化能力。

中文摘要: 迁移学习是现代机器学习的基石，它提供了一种方法，使模型能够通过预训练在广泛数据上适应新任务，而只需少量新数据。然而，确保迁移特征足以处理未见数据集仍是一个重大挑战，尤其是难以量化两个任务是否“相关”。为解决这些问题，我们评估了从预训练混合数据迁移到其组成任务的表现，检验预训练特征是否能匹配任务特定直接训练的效果。我们发现深度学习模型存在一个根本限制——"信息饱和瓶颈"，即网络在训练中一旦编码了相似竞争特征，就无法学习新特征。当预训练中仅学习部分关键特征时，模型将永久丢失迁移所需的关键特征，并在数据分布上表现不一致，即使是训练混合数据的组成部分。已有研究的实证证据表明，这一现象在深度学习架构中普遍存在——数据分布或顺序等因素会影响当前表示学习方法随时间学习的特征。本研究指出，当任务特定训练可用时，仅依赖大规模网络可能不如专注于任务特定训练有效。我们提出更丰富的特征表示作为潜在解决方案，以更好地泛化到新数据集，并具体介绍了现有方法及一种新方法的初步尝试，以应对这一挑战。

</details>


### [491] [Quantum-Classical Hybrid Quantized Neural Network](https://arxiv.org/abs/2506.18240)
**中文标题：量子-经典混合量化神经网络**

*Wenxin Li,Chuan Wang,Hongdong Zhu,Qi Gao,Yin Ma,Hai Wei,Kai Wen*

主要分类: cs.LG

摘要简述: 本文提出了一种新型的量子-经典混合量化神经网络训练方法，通过样条插值支持任意激活和损失函数，并利用量子计算优化非线性问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统神经网络训练在处理非线性问题和多层复合结构时面临挑战，量子计算为解决这些问题提供了新途径。本文旨在结合量子计算的优势，提升量化神经网络的训练效率和性能。

研究方法: 提出了前向区间传播（FIP）方法，将激活函数离散化为线性子区间，并结合量子条件梯度下降（QCGD）算法直接求解二次约束二进制优化（QCBO）问题。

研究结果: 实验结果表明，该方法在Fashion MNIST分类任务中达到了94.95%的准确率，仅需1.1位精度。

研究结论: 本文方法成功结合了量子计算和经典神经网络训练的优势，为复杂非线性问题的优化提供了高效解决方案。

中文摘要: 本文提出了一种新型的二次二进制优化（QBO）模型，用于量化神经网络训练，通过样条插值支持任意激活和损失函数。我们引入了前向区间传播（FIP）方法，通过将激活函数离散化为线性子区间，解决了神经网络中非线性和多层复合结构的挑战。该方法保留了神经网络的通用逼近特性，同时允许使用量子计算机优化复杂非线性函数，从而扩展了其在人工智能中的适用性。我们从优化角度推导了经验风险最小化问题的样本复杂度，提供了逼近误差和所需伊辛自旋数量的理论上界。大规模求解相关二次约束二进制优化（QCBO）模型的一个主要挑战是存在大量约束条件。使用惩罚方法处理这些约束时，调整大量惩罚系数成为一个关键的超参数优化问题，增加了计算复杂度并可能影响解的质量。为解决这一问题，我们采用了量子条件梯度下降（QCGD）算法，利用量子计算直接求解QCBO问题。我们证明了QCGD在量子随机预言机下目标值具有随机性和有界方差时的收敛性，以及在系数矩阵精度受限时的收敛性。此外，我们还提供了QCBO求解过程的时间解上界。使用相干伊辛机（CIM）的实验结果表明，在Fashion MNIST分类任务中达到了94.95%的准确率，仅需1.1位精度。

</details>


### [492] [ARD-LoRA: Dynamic Rank Allocation for Parameter-Efficient Fine-Tuning of Foundation Models with Heterogeneous Adaptation Needs](https://arxiv.org/abs/2506.18267)
**中文标题：ARD-LoRA：动态秩分配用于基础模型的高效参数微调与异构适应需求**

*Haseeb Ullah Khan Shinwari,Muhammad Usama*

主要分类: cs.LG

摘要简述: 本文提出ARD-LoRA框架，通过动态分配低秩适应（LoRA）的秩，解决了传统方法固定秩导致的异构学习需求问题，显著提升了参数效率和任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的低秩适应（LoRA）方法采用固定秩，无法适应不同Transformer层和注意力头的异构学习动态，限制了参数效率和任务性能的优化。

研究方法: ARD-LoRA通过可学习的缩放因子自动分配秩，结合ℓ1稀疏性和总变差正则化，实现连续、可微的逐头秩适应，平衡任务性能和参数效率。

研究结果: 在LLAMA-3.1-70B和PaliGemma-2上的实验表明，ARD-LoRA仅需0.32%的可训练参数即可达到全微调性能的99.3%，并减少多模态适应内存41%，优于DoRA和AdaLoRA等基线方法。

研究结论: 动态、细粒度的秩分配是高效适应基础模型的关键范式，ARD-LoRA为此提供了有效解决方案。

中文摘要: 传统的低秩适应（LoRA）方法采用固定秩，导致对不同Transformer层和注意力头的异构学习动态施加了统一的适应方式。本文提出自适应秩动态LoRA（ARD-LoRA），一种通过可学习缩放因子自动分配秩的新框架。这些因子通过平衡任务性能和参数效率的元目标进行优化，结合ℓ1稀疏性以实现最小秩和总变差正则化以稳定秩的过渡。ARD-LoRA实现了连续、可微的逐头秩适应。在LLAMA-3.1-70B和PaliGemma-2上的实验证明了ARD-LoRA的有效性，仅使用0.32%的可训练参数即可达到全微调性能的99.3%，优于DoRA和AdaLoRA等强基线方法。此外，它还将多模态适应的内存减少了41%。这些结果表明，动态、细粒度的秩分配是高效适应基础模型的关键范式。

</details>


### [493] [Learning Causal Graphs at Scale: A Foundation Model Approach](https://arxiv.org/abs/2506.18285)
**中文标题：大规模学习因果图：一种基础模型方法**

*Naiyu Yin,Tian Gao,Yue Yu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于基础模型的新方法ADAG，通过注意力机制学习多任务下的线性结构方程模型，显著提升了有向无环图（DAG）的学习精度和零样本推理效率。


<details>
  <summary>详细信息</summary>
研究动机: 由于DAG在AI研究中的广泛应用及其可解释性和不变性，但其学习面临计算成本高和在小样本场景下的可识别性问题。本文旨在解决这些问题，提出一种高效且通用的DAG学习方法。

研究方法: 提出ADAG（基于注意力的DAG学习架构），通过非线性注意力核学习观测数据到图结构和参数的映射，将多任务学习建模为连续优化问题，利用预训练模型捕捉共享的低维先验，减少下游任务的病态性。

研究结果: 在合成基准数据集上，ADAG在DAG学习精度和零样本推理效率方面均取得显著提升。

研究结论: ADAG是首个专门为DAG学习设计的基础模型预训练方法，为因果发现的高效和通用下游应用迈出了重要一步。

中文摘要: 由于其人类可解释性和不变性特性，有向无环图（DAG）已成为AI研究中多个领域的基础工具，推动了重大进展。然而，DAG学习仍然极具挑战性，主要源于其计算成本的超指数增长和小样本场景下的可识别性问题。为解决这两大挑战，本文利用线性变换器的最新成果，提出了一种基础模型方法，用于发现多任务中顺序一致的DAG。具体而言，我们提出了ADAG（基于注意力的DAG学习架构），这是一种新型注意力机制架构，用于学习多个线性结构方程模型（SEM）。ADAG通过非线性注意力核学习从观测数据到图结构和参数的映射，实现了对底层线性SEM的高效多任务估计。通过将多任务学习过程建模为连续优化问题，预训练的ADAG模型将共同结构特性捕捉为共享的低维先验，从而减少了小样本场景下下游DAG学习任务的病态性。我们在合成基准数据集上评估了所提方法，发现ADAG在DAG学习精度和零样本推理效率方面均取得显著提升。据我们所知，这是首个专门为DAG学习设计的实用基础模型预训练方法，为因果发现的高效和通用下游应用迈出了重要一步。

</details>


### [494] [GeNeRT: A Physics-Informed Approach to Intelligent Wireless Channel Modeling via Generalizable Neural Ray Tracing](https://arxiv.org/abs/2506.18295)
**中文标题：GeNeRT：一种基于物理信息的通用神经射线追踪智能无线信道建模方法**

*Kejia Bian,Meixia Tao,Shu Sun,Jun Yu*

主要分类: cs.LG

摘要简述: GeNeRT是一种基于物理信息的智能无线信道建模方法，通过可泛化的神经射线追踪技术，解决了现有方法在空间泛化能力和电磁定律遵循性上的不足，显著提升了建模精度和效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前神经射线追踪方法存在空间依赖性导致的泛化能力受限和对电磁定律遵循性弱的问题，限制了其在无线信道建模中的应用。本文旨在提出一种更通用、准确且高效的神经射线追踪框架。

研究方法: GeNeRT结合了菲涅尔启发的神经网络设计，支持场景内空间可迁移性和场景间零样本泛化，并采用GPU张量化加速策略提升运行效率。

研究结果: 实验表明，GeNeRT在未训练区域和全新环境中均表现出良好的泛化能力，多径分量预测精度优于基线方法，且在多发射器设置下运行效率超过Wireless Insite。

研究结论: GeNeRT通过创新的网络架构和训练策略，有效捕捉了射线与表面相互作用的物理原理，为无线信道建模提供了更优的解决方案。

中文摘要: 神经射线追踪（RT）通过将物理传播原理与神经网络结合，成为信道建模的一种有前景范式，具有高精度和高效率。然而，现有神经RT方法存在两大局限：因强空间依赖性导致的泛化能力受限，以及对电磁定律的遵循性较弱。本文提出GeNeRT，一种具有增强泛化性、精度和效率的通用神经RT框架。GeNeRT支持场景内空间可迁移性和场景间零样本泛化，并通过菲涅尔启发的神经网络设计在多径分量（MPC）预测中实现更高精度。此外，引入GPU张量化加速策略以提升运行效率。在户外场景的大量实验表明，GeNeRT在未训练区域和全新环境中均表现出良好的泛化能力，且在MPC预测精度上优于基线方法。此外，其运行效率在多发射器设置下超过Wireless Insite。消融实验验证了网络架构和训练策略在捕捉射线-表面相互作用物理原理上的有效性。

</details>


### [495] [Sharpening the Spear: Adaptive Expert-Guided Adversarial Attack Against DRL-based Autonomous Driving Policies](https://arxiv.org/abs/2506.18304)
**中文标题：磨砺长矛：针对基于深度强化学习的自动驾驶策略的自适应专家引导对抗攻击**

*Junchao Fan,Xuyang Lei,Xiaolin Chang*

主要分类: cs.LG

摘要简述: 本文提出了一种自适应专家引导的对抗攻击方法，用于提升针对基于深度强化学习（DRL）的自动驾驶策略的攻击效率和训练稳定性。通过模仿学习和专家集成架构，结合KL散度正则化和性能感知退火策略，该方法在攻击效率和训练稳定性上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 基于DRL的自动驾驶策略虽然表现出色，但对对抗攻击高度脆弱，存在严重的安全风险。现有攻击方法依赖高频攻击或限制攻击频率，导致攻击效率低或训练不稳定。本文旨在解决这些问题，提出更高效的攻击方法。

研究方法: 方法包括：1) 通过模仿学习从成功攻击演示中提取专家策略，并采用集成专家架构增强泛化能力；2) 使用KL散度正则化引导DRL对抗器；3) 引入性能感知退火策略，逐步减少对专家策略的依赖。

研究结果: 实验表明，该方法在碰撞率、攻击效率和训练稳定性上优于现有方法，尤其在专家策略不理想的情况下表现突出。

研究结论: 本文提出的自适应专家引导对抗攻击方法显著提升了攻击效率和训练稳定性，为揭示自动驾驶策略的脆弱性和开发更鲁棒的系统提供了有效工具。

中文摘要: 深度强化学习（DRL）已成为自动驾驶领域的一种有前景的范式。然而，尽管其能力先进，基于DRL的策略仍极易受到对抗攻击，给实际部署带来严重安全风险。研究此类攻击对揭示策略脆弱性和指导开发更鲁棒的自动驾驶系统至关重要。虽然现有攻击方法取得了显著进展，但仍面临以下挑战：1) 它们通常依赖高频攻击，但关键攻击机会通常是上下文相关且时间稀疏的，导致攻击模式效率低下；2) 限制攻击频率可提高效率，但常因对抗器探索有限而导致训练不稳定。为解决这些问题，我们提出了一种自适应专家引导的对抗攻击方法，提升攻击策略训练的稳定性和效率。该方法首先通过模仿学习从成功攻击演示中提取专家策略，并通过集成专家架构增强跨场景的泛化能力。随后，该专家策略通过KL散度正则化引导DRL对抗器。由于场景多样性，专家策略可能不完美，为此我们进一步引入性能感知退火策略，随着对抗器性能提升逐步减少对专家的依赖。大量实验表明，我们的方法在碰撞率、攻击效率和训练稳定性上优于现有方法，尤其在专家策略不理想的情况下表现突出。

</details>


### [496] [Structured Kolmogorov-Arnold Neural ODEs for Interpretable Learning and Symbolic Discovery of Nonlinear Dynamics](https://arxiv.org/abs/2506.18339)
**中文标题：结构化Kolmogorov-Arnold神经ODE：用于非线性动力学的可解释学习与符号发现**

*Wei Liu,Kiran Bacsa,Loon Ching Tang,Eleni Chatzi*

主要分类: cs.LG

摘要简述: 本文提出了一种结构化Kolmogorov-Arnold神经ODE（SKANODE）框架，结合结构化状态空间建模与Kolmogorov-Arnold网络（KAN），用于学习非线性动力学系统的可解释模型。该方法通过虚拟感知恢复物理可解释的潜在状态，并利用KAN的符号回归能力提取系统动力学的紧凑表达式，最终通过训练优化模型精度。实验表明，SKANODE在模拟和真实系统中均表现出色，并提供物理一致的模型。


<details>
  <summary>详细信息</summary>
研究动机: 非线性动力学系统的建模和理解是科学与工程领域的核心问题。尽管深度学习在复杂系统行为学习方面表现出巨大潜力，但如何同时实现高精度和物理可解释性仍是一大挑战。本文旨在通过结合结构化建模与符号回归技术，开发一种既能准确预测又能揭示系统内在机制的模型。

研究方法: SKANODE框架首先利用完全可训练的Kolmogorov-Arnold网络（KAN）作为结构化神经ODE中的通用函数逼近器，通过虚拟感知恢复物理可解释的潜在状态（如位置和速度）。随后，利用KAN的符号回归能力提取系统动力学的紧凑表达式，并将该表达式重新嵌入神经ODE框架中，通过持续训练优化系数，以提升模型精度和预测能力。

研究结果: 在模拟和真实系统的广泛实验中，SKANODE表现出卓越的性能，能够提供高精度且物理可解释的模型。此外，该方法成功揭示了非线性动力学系统的内在机制，验证了其在实际应用中的有效性。

研究结论: SKANODE框架通过结合结构化建模与符号回归技术，不仅实现了非线性动力学系统的高精度建模，还提供了物理可解释的模型，为复杂系统的理解和控制提供了新工具。

中文摘要: 理解和建模非线性动力学系统是科学与工程领域的基础问题。尽管深度学习在学习复杂系统行为方面展现出巨大潜力，但如何同时实现高精度和物理可解释性仍是一大挑战。为此，我们提出了一种结构化Kolmogorov-Arnold神经ODE（SKANODE）框架，将结构化状态空间建模与Kolmogorov-Arnold网络（KAN）相结合。SKANODE首先利用完全可训练的KAN作为结构化神经ODE中的通用函数逼近器，通过虚拟感知恢复物理可解释的潜在状态（如位置和速度）。随后，利用KAN的符号回归能力提取系统动力学的紧凑表达式，并将该表达式重新嵌入神经ODE框架中，通过持续训练优化系数，以提升模型精度和预测能力。在模拟和真实系统的广泛实验中，SKANODE表现出卓越性能，同时提供了可解释且物理一致的模型，揭示了非线性动力学系统的内在机制。

</details>


### [497] [Controlled Generation with Equivariant Variational Flow Matching](https://arxiv.org/abs/2506.18340)
**中文标题：基于等变变分流匹配的受控生成**

*Floor Eijkelboom,Heiko Zimmermann,Sharvaree Vadgama,Erik J Bekkers,Max Welling,Christian A. Naesseth,Jan-Willem van de Meent*

主要分类: cs.LG

摘要简述: 本文提出了一种基于变分流匹配（VFM）的受控生成方法，支持端到端训练和贝叶斯推理两种实现方式，并在分子生成任务中实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过变分流匹配框架实现受控生成，同时解决分子生成中的对称性问题，为约束驱动和对称性感知的生成提供可扩展的理论基础。

研究方法: 方法包括两种受控生成实现：端到端训练的条件生成模型和无需重新训练的贝叶斯推理方法，并提出了适用于分子生成的等变VFM框架。

研究结果: 实验表明，该方法在非受控和受控分子生成任务中均达到最先进水平，尤其在贝叶斯推理设置下表现优异。

研究结论: 本研究强化了基于流的生成模型与贝叶斯推理之间的联系，为约束驱动和对称性感知的生成提供了可扩展的理论框架。

中文摘要: 我们在变分流匹配（VFM）框架下推导了一种受控生成目标，将流匹配问题转化为变分推断问题。我们展示了受控生成的两种实现方式：（1）通过端到端训练条件生成模型；（2）作为贝叶斯推断问题，无需重新训练即可对无条件模型进行后验控制。此外，我们确立了等变生成的条件，并提出了适用于分子生成的等变VFM框架，确保对旋转、平移和置换的不变性。我们在非受控和受控分子生成任务中评估了该方法，在非受控生成中达到最先进水平，并在端到端训练和贝叶斯推理设置下的受控生成中优于现有模型。本研究强化了基于流的生成模型与贝叶斯推理之间的联系，为约束驱动和对称性感知的生成提供了可扩展的理论框架。

</details>


### [498] [LOGICPO: Efficient Translation of NL-based Logical Problems to FOL using LLMs and Preference Optimization](https://arxiv.org/abs/2506.18383)
**中文标题：LOGICPO：基于LLMs和偏好优化的自然语言逻辑问题高效翻译为一阶逻辑**

*Koushik Viswanadha,Deepanway Ghosal,Somak Aditya*

主要分类: cs.LG

摘要简述: 本文提出了一种基于偏好优化的方法LogicPO，通过微调开源LLMs（如Phi-3.5）将自然语言逻辑问题高效转换为FOL表示，显著提升了逻辑推理能力，优于GPT-3.5-turbo。


<details>
  <summary>详细信息</summary>
研究动机: 当前LLMs在自然语言逻辑问题转换为逻辑表示时存在不足，影响了推理能力。本文旨在通过偏好优化数据集和微调技术，提升LLMs的逻辑表示能力。

研究方法: 1) 引入新的监督和偏好优化数据集LogicPO；2) 采用DPO和KTO等技术微调开源LLMs（如Phi-3.5），以生成更准确的逻辑程序。

研究结果: 最佳模型Phi-3.5在逻辑正确性上比GPT-3.5-turbo（8-shot）提升10%，语法错误减少14%。

研究结论: LogicPO框架和评估指标为提升LLMs的逻辑推理能力提供了有效方向，通过改进逻辑表示实现更优性能。

中文摘要: 逻辑推理是人工智能的核心任务，因其在问答、摘要等下游任务中的重要作用。现有方法在将自然语言推理问题转换为等效逻辑表示时表现不佳，限制了推理能力。为此，我们提出通过偏好优化数据集微调LLMs，以学习将自然语言问题整体解析为一致的逻辑程序：1) 引入新的监督和偏好优化数据集LogicPO；2) 采用直接偏好优化（DPO）和Kahneman-Tversky优化（KTO）等技术微调开源LLMs。我们的最佳模型Phi-3.5在逻辑正确性上比GPT-3.5-turbo（8-shot）提升10%，语法错误减少14%。通过该框架和改进的评估指标，我们为提升LLMs的逻辑推理能力提供了有前景的方向，即通过优化逻辑表示实现更优性能。

</details>


### [499] [ADNF-Clustering: An Adaptive and Dynamic Neuro-Fuzzy Clustering for Leukemia Prediction](https://arxiv.org/abs/2506.18396)
**中文标题：ADNF-Clustering：一种用于白血病预测的自适应动态神经模糊聚类方法**

*Marco Aruta,Ciro Listone,Giuseppe Murano,Aniello Murano*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ADNF-Clustering的自适应动态神经模糊聚类方法，用于白血病预测。该方法结合卷积神经网络特征提取和在线模糊聚类引擎，通过动态更新聚类参数和拓扑优化，显著提升了聚类效果。


<details>
  <summary>详细信息</summary>
研究动机: 白血病诊断和监测依赖高通量图像数据，但传统聚类方法缺乏灵活性，无法适应动态变化的细胞模式并实时量化不确定性。因此，需要一种能够动态调整聚类参数并处理不确定性的新方法。

研究方法: ADNF-Clustering结合卷积神经网络特征提取和在线模糊聚类引擎，通过模糊C均值初始化软分区，并使用模糊时间指数（FTI）动态更新微聚类中心、密度和模糊参数。拓扑优化阶段通过密度加权合并和熵引导分裂防止过分割和欠分割。

研究结果: 在C-NMC白血病显微镜数据集上，该方法轮廓分数达到0.51，优于静态基线方法，展示了更好的聚类内聚性和分离性。

研究结论: ADNF-Clustering的自适应不确定性建模和无标签操作使其在个性化白血病管理中具有潜在应用价值，尤其适用于儿科肿瘤网络INFANT。

中文摘要: 白血病的诊断和监测越来越依赖于高通量图像数据，但传统的聚类方法缺乏灵活性，无法适应动态变化的细胞模式并实时量化不确定性。我们提出了一种名为自适应动态神经模糊聚类（ADNF-Clustering）的新型流式框架，该框架结合了基于卷积神经网络的特征提取和在线模糊聚类引擎。ADNF通过模糊C均值初始化软分区，随后使用模糊时间指数（FTI）动态更新微聚类中心、密度和模糊参数，以测量熵的演变。拓扑优化阶段通过密度加权合并和熵引导分裂防止过分割和欠分割。在C-NMC白血病显微镜数据集上，我们的工具轮廓分数达到0.51，优于静态基线方法。该方法的自适应不确定性建模和无标签操作为其在INFANT儿科肿瘤网络中的集成提供了潜在可能，从而为个性化白血病管理提供了可扩展的最新支持。

</details>


### [500] [PuckTrick: A Library for Making Synthetic Data More Realistic](https://arxiv.org/abs/2506.18499)
**中文标题：PuckTrick：一个使合成数据更真实的库**

*Alessandra Agostini,Andrea Maurino,Blerina Spahiu*

主要分类: cs.LG

摘要简述: PuckTrick是一个Python库，用于在合成数据中引入受控错误（如缺失值、噪声、异常值等），以提升机器学习模型在真实数据中的泛化能力。实验表明，使用污染后的合成数据训练的模型表现优于使用纯净合成数据的模型。


<details>
  <summary>详细信息</summary>
研究动机: 由于隐私和专有限制，真实数据难以获取，合成数据成为替代方案。然而，合成数据过于干净，缺乏真实数据中的不完美（如噪声、缺失值等），影响模型泛化能力。PuckTrick旨在解决这一问题。

研究方法: PuckTrick提供两种污染模式：一种在干净数据中注入错误，另一种进一步污染已污染的数据。支持多种错误类型（缺失数据、噪声、异常值、标签错误等），以系统评估模型在真实数据缺陷下的鲁棒性。

研究结果: 实验表明，使用PuckTrick污染后的合成数据训练的模型（尤其是基于树和线性模型如SVM和Extra Trees）表现优于使用纯净合成数据的模型。

研究结论: PuckTrick通过引入真实数据中的不完美，显著提升了机器学习模型的泛化能力和鲁棒性，为合成数据的实际应用提供了有效工具。

中文摘要: 随着机器学习（ML）模型在决策中的广泛应用，高质量的训练数据变得至关重要。然而，由于隐私问题、专有限制和数据不完整，真实数据往往难以获取。因此，合成数据生成（SDG）成为一种可行的替代方案，能够生成保留真实数据统计特性且符合隐私要求的人工数据集。尽管合成数据具有优势，但其通常过于干净，缺乏真实数据中的不完美（如缺失值、噪声、异常值和错误标签），这些缺陷会显著影响模型的泛化能力和鲁棒性。为解决这一问题，我们推出了PuckTrick，这是一个Python库，旨在通过引入受控错误系统性地污染合成数据集。该库支持多种错误类型，包括缺失数据、噪声值、异常值、标签错误、重复数据和类别不平衡，为评估ML模型在真实数据缺陷下的鲁棒性提供了结构化方法。PuckTrick提供两种污染模式：一种用于在干净数据中注入错误，另一种用于进一步污染已污染的数据。通过对真实金融数据集的广泛实验，我们评估了系统性数据污染对模型性能的影响。结果表明，使用污染后的合成数据训练的ML模型（尤其是基于树和线性模型如SVM和Extra Trees）表现优于使用纯净合成数据的模型。

</details>


### [501] [Optimization-Induced Dynamics of Lipschitz Continuity in Neural Networks](https://arxiv.org/abs/2506.18588)
**中文标题：神经网络中Lipschitz连续性的优化诱导动力学**

*Róisín Luo,James McDermott,Christian Gagné,Qiang Sun,Colm O'Riordan*

主要分类: cs.LG

摘要简述: 本文提出了一种数学框架，用于研究神经网络在随机梯度下降（SGD）训练过程中Lipschitz连续性的动态演化，揭示了梯度流、梯度噪声及Hessian矩阵投影对其的影响，并通过实验验证了理论预测。


<details>
  <summary>详细信息</summary>
研究动机: Lipschitz连续性反映了神经网络对小输入扰动的敏感性，但其在训练过程中的动态演化尚未被充分研究。本文旨在填补这一空白，揭示优化过程中Lipschitz连续性的变化机制。

研究方法: 作者建立了一个基于随机微分方程（SDEs）的数学框架，用于捕捉训练过程中的确定性和随机性力量。该框架分析了梯度流、梯度噪声及其在算子范数Jacobian和Hessian矩阵上的投影对Lipschitz连续性的影响。

研究结果: 理论分析表明，梯度流、梯度噪声及Hessian矩阵投影是驱动Lipschitz连续性演化的三大因素。实验结果显示，理论预测与实际观测行为高度一致。

研究结论: 本文提出的理论框架成功解释了Lipschitz连续性在训练中的动态变化，并揭示了噪声监督、参数初始化、批量大小等因素对其演化的影响。

中文摘要: Lipschitz连续性表征了神经网络对小输入扰动的最坏敏感性，但其在训练过程中的动态演化（即时间演化）尚未得到充分研究。我们提出了一个严格的数学框架，用于建模随机梯度下降（SGD）训练过程中Lipschitz连续性的时间演化。该框架利用随机微分方程（SDEs）系统来捕捉确定性和随机性力量。我们的理论分析确定了驱动演化的三个主要因素：（i）由优化动力学引起的梯度流在参数矩阵的算子范数Jacobian上的投影；（ii）由小批量采样的随机性引起的梯度噪声在算子范数Jacobian上的投影；以及（iii）梯度噪声在参数矩阵的算子范数Hessian上的投影。此外，我们的理论框架揭示了噪声监督、参数初始化、批量大小和小批量采样轨迹等因素如何塑造神经网络Lipschitz连续性的演化。实验结果表明，理论预测与观测行为高度一致。

</details>


### [502] [Simulation-Free Differential Dynamics through Neural Conservation Laws](https://arxiv.org/abs/2506.18604)
**中文标题：通过神经守恒定律实现无模拟的微分动力学**

*Mengjian Hua,Eric Vanden-Eijnden,Ricky T. Q. Chen*

主要分类: cs.LG

摘要简述: 本文提出了一种无模拟的连续时间扩散过程训练框架，通过神经守恒定律直接建模时间依赖密度函数和扩散过程动力学，适用于多种问题，如生成建模和随机最优控制。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常需要规定最优扩散过程或依赖昂贵的模拟，限制了问题的通用性。本文旨在开发一种无模拟的框架，适用于更广泛的问题形式。

研究方法: 通过扩展和简化神经守恒定律的构建，将Fokker-Planck方程和密度函数要求作为硬约束，联合建模时间依赖密度函数和扩散过程动力学。

研究结果: 该方法在生成建模、时空事件建模和从人口数据学习最优动力学等多个领域验证了其有效性。

研究结论: 提出的框架为多种问题提供了无模拟的训练方法，扩展了神经守恒定律的应用范围。

中文摘要: 我们提出了一种新颖的无模拟框架，用于训练连续时间扩散过程，适用于非常通用的目标函数。现有方法通常需要规定最优扩散过程（仅适用于高度受限的问题形式），或依赖昂贵的模拟来数值获取时间依赖密度并从扩散过程中采样。相比之下，我们提出了一种耦合参数化方法，联合建模时间依赖密度函数（或概率路径）和生成该概率路径的扩散过程动力学。为实现这一点，我们的方法通过扩展并大幅简化神经守恒定律的构建，直接将Fokker-Planck方程和密度函数要求作为硬约束。这使得无模拟训练适用于多种问题形式，从生成建模和动态最优传输等数据驱动目标，到随机最优控制等基于最优性的目标，并可轻松扩展到均值场目标，因为可以轻松访问精确密度函数。我们在从时空事件建模到从人口数据学习最优动力学等多个应用领域验证了我们的方法。

</details>


### [503] [Multi-Agent Reinforcement Learning for Inverse Design in Photonic Integrated Circuits](https://arxiv.org/abs/2506.18627)
**中文标题：基于多智能体强化学习的光子集成电路逆向设计**

*Yannik Mahlau,Maximilian Schier,Christoph Reinders,Frederik Schubert,Marco Bügling,Bodo Rosenhahn*

主要分类: cs.LG

摘要简述: 本文提出了一种基于多智能体强化学习（RL）的光子集成电路（PIC）逆向设计方法，通过离散化设计空间并分解为数千个智能体，显著提升了设计效率，并在二维和三维任务中优于传统梯度优化方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于梯度的光子集成电路逆向设计方法容易陷入局部最优，导致设计功能不理想。随着光学计算对PIC需求的增加，亟需更自适应的优化算法。

研究方法: 将设计空间离散化为网格，将设计任务建模为包含数千个二元变量的优化问题，并采用多智能体RL算法分解设计空间，每个智能体负责局部优化，仅需数千次环境采样即可完成设计。

研究结果: 在二维和三维PIC组件设计任务中，多智能体RL算法显著优于传统梯度优化方法，且样本效率高。

研究结论: 多智能体RL为光子集成电路逆向设计提供了高效且性能优越的解决方案，并为未来光子学中样本高效RL的探索奠定了基础。

中文摘要: 光子集成电路（PIC）的逆向设计传统上依赖于基于梯度的优化方法，但这种方法容易陷入局部最优，导致设计功能不理想。随着光学计算对PIC需求的增加，需要更自适应的优化算法。我们提出了一个强化学习（RL）环境及多智能体RL算法用于PIC设计。通过将设计空间离散化为网格，我们将设计任务建模为包含数千个二元变量的优化问题。我们研究了多个代表光学计算系统PIC组件的二维和三维设计任务。通过将设计空间分解为数千个独立智能体，我们的算法仅需数千次环境采样即可优化设计，并在二维和三维任务中优于传统梯度优化方法。本研究还可作为未来光子学中样本高效RL逆向设计的基准。

</details>


### [504] [Granular-Ball-Induced Multiple Kernel K-Means](https://arxiv.org/abs/2506.18637)
**中文标题：基于粒球的多核K均值聚类**

*Shuyin Xia,Yifan Wang,Lifeng Shen,Guoyin Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于粒球计算的多核K均值聚类框架（GB-MKKM），通过粒球核（GBK）和粒球关系提升聚类效率和鲁棒性，适用于复杂数据分布。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多核聚类算法（如多核K均值）在复杂数据分布下常面临计算效率和鲁棒性问题，主要依赖点对点关系优化，难以准确捕捉数据内在结构和多样性。

研究方法: 利用粒球计算自适应拟合数据分布，提出粒球核（GBK）和粒球多核K均值框架（GB-MKKM），通过粒球关系在多核空间中提升聚类效率和性能。

研究结果: 实验表明，GB-MKKM框架在多种聚类任务中表现出更高的效率和聚类性能。

研究结论: 基于粒球计算的多核聚类框架显著提升了复杂数据分布下的聚类效率和鲁棒性，为高维空间数据聚类提供了有效解决方案。

中文摘要: 现有的多核聚类算法（如多核K均值）在面对复杂数据分布时，常因依赖点对点关系优化而难以高效且鲁棒地捕捉数据内在结构和多样性。此外，多核间的复杂交互进一步加剧了这些问题，影响了高维空间中的数据聚类能力。本文利用粒球计算改进多核聚类框架，其核心是通过从粗到细的粒球自适应拟合数据分布，每个粒球基于密度一致性度量包含数据点。这种基于粒球的数据描述提升了计算效率和对未知噪声的鲁棒性。具体而言，基于粒球表示，我们提出了粒球核（GBK）及其对应的粒球多核K均值框架（GB-MKKM）以实现高效聚类。通过多核空间中的粒球关系，GB-MKKM框架在多种聚类任务的实证评估中展现了其在效率和聚类性能上的优越性。

</details>


### [505] [Federated Loss Exploration for Improved Convergence on Non-IID Data](https://arxiv.org/abs/2506.18640)
**中文标题：联邦损失探索：提升非独立同分布数据下的收敛性能**

*Christian Internò,Markus Olhofer,Yaochu Jin,Barbara Hammer*

主要分类: cs.LG

摘要简述: 本文提出了一种名为FedLEx的创新方法，专门针对联邦学习（FL）在非独立同分布（non-IID）数据场景中的性能问题。通过优化学习行为并利用梯度偏差构建全局指导矩阵，FedLEx显著提升了模型在非IID数据下的收敛性能。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在非独立同分布数据场景中面临性能不足和鲁棒性差的挑战。现有方法通常无法有效处理数据异质性，亟需一种能够在不依赖额外数据共享或数据分布统计的情况下提升模型性能的解决方案。

研究方法: FedLEx采用联邦损失探索技术，客户端通过计算模型参数的梯度偏差贡献到全局指导矩阵。该矩阵作为策略指南，指导后续联邦学习轮次中的梯度更新，从而优化全局模型的参数更新。

研究结果: 实验表明，FedLEx在非IID数据场景下显著优于现有联邦学习算法，仅需少量数据和训练轮次即可构建高效的全局指导矩阵，实现模型快速收敛。

研究结论: FedLEx通过创新的损失探索技术，有效解决了联邦学习在非IID数据中的性能瓶颈，为多样化联邦学习应用提供了潜在突破。

中文摘要: 联邦学习（FL）作为一种突破性的机器学习范式，能够在保护隐私的前提下实现跨数据集的协作模型训练。然而，在非独立同分布（non-IID）数据场景中，联邦学习面临数据异质性和性能鲁棒性不足的显著挑战。本文提出了一种名为联邦损失探索（FedLEx）的创新方法，专门针对这些挑战设计。FedLEx通过优化学习行为，解决了现有联邦学习方法在非IID数据假设不切实际或未知时的不足。该方法采用联邦损失探索技术，客户端通过计算模型参数的梯度偏差贡献到全局指导矩阵。该矩阵作为策略指南，指导后续联邦学习轮次中的梯度更新，从而优化全局模型的参数更新。FedLEx能够高效应对非IID数据中复杂的损失曲面，仅需少量数据和训练轮次即可构建强大的全局指导矩阵，实现模型收敛，无需额外数据共享或大规模客户端场景中的数据分布统计。我们通过大量实验表明，FedLEx在非IID条件下的性能显著优于现有联邦学习算法，展现了其在多样化联邦学习应用中突破关键障碍的潜力。

</details>


### [506] [On the Existence of Universal Simulators of Attention](https://arxiv.org/abs/2506.18739)
**中文标题：关于注意力通用模拟器的存在性**

*Debanjan Dutta,Faizanuddin Ansari,Anish Chakrabarty,Swagatam Das*

主要分类: cs.LG

摘要简述: 本文研究了Transformer编码器是否能够精确模拟任意注意力机制，特别是其底层操作。通过构建一个由Transformer编码器组成的通用模拟器，作者首次证明了存在一种算法可实现的数据无关解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 先前的研究主要集中在Transformer的可学习性和表达能力上，但缺乏对Transformer是否能精确模拟注意力机制的理论探讨。本文旨在填补这一空白，探索Transformer编码器是否能够完全模拟注意力机制及其底层操作。

研究方法: 作者构建了一个名为$\mathcal{U}$的通用模拟器，由Transformer编码器组成，并通过RASP（一种Transformer计算的形式化框架）提供了算法解决方案，以完全复制注意力输出及其底层矩阵和激活操作。

研究结果: 研究首次证明了存在一种算法可实现的数据无关解决方案，能够精确模拟注意力机制及其底层操作，而此前仅能通过学习近似实现。

研究结论: 本文通过理论证明和算法构建，展示了Transformer编码器能够完全模拟注意力机制，为Transformer的表达能力提供了新的理论支持。

中文摘要: 先前关于Transformer可学习性的研究在受限架构假设下通过训练证明了其近似特定算法模式的能力。这些论证本质上是数据驱动的，因此只能提供概率性保证。相反，表达能力从理论上探讨了此类架构可计算的问题。这些结果证明了Transformer的图灵完备性，并研究了电路复杂性和形式逻辑的界限。处于可学习性和表达能力的交叉点，问题仍然存在：Transformer架构能否精确模拟任意注意力机制，特别是其底层操作？本研究探讨了Transformer编码器模拟普通注意力机制的能力。通过构建一个由Transformer编码器组成的通用模拟器$\mathcal{U}$，我们提出了通过RASP（一种Transformer计算的形式化框架）完全复制注意力输出及其底层矩阵和激活操作的算法解决方案。我们的证明首次展示了存在一种算法可实现的数据无关解决方案，而此前仅能通过学习近似实现。

</details>


### [507] [ContinualFlow: Learning and Unlearning with Neural Flow Matching](https://arxiv.org/abs/2506.18747)
**中文标题：ContinualFlow：基于神经流匹配的学习与遗忘**

*Lorenzo Simone,Davide Bacciu,Shuangge Ma*

主要分类: cs.LG

摘要简述: 本文提出ContinualFlow框架，通过流匹配实现生成模型中的目标遗忘，无需从头训练或直接访问需遗忘样本，利用基于能量的重加权损失软性去除数据分布中的不期望区域。


<details>
  <summary>详细信息</summary>
研究动机: 生成模型在实际应用中常需遗忘某些数据区域，但传统方法需从头训练或直接访问遗忘样本，效率低下且不实用。本文旨在提出一种无需这些条件的高效遗忘方法。

研究方法: ContinualFlow采用基于能量的重加权损失，通过流匹配技术软性去除数据分布中的不期望区域。该方法利用能量代理指导遗忘过程，无需直接访问遗忘样本或从头训练。

研究结果: 实验在2D和图像领域验证了框架的有效性，通过可视化解释和定量评估展示了其性能。

研究结论: ContinualFlow为生成模型中的目标遗忘提供了一种高效且实用的解决方案，无需从头训练或直接访问遗忘样本。

中文摘要: 我们提出了ContinualFlow，一种通过流匹配实现生成模型中目标遗忘的原则性框架。我们的方法利用基于能量的重加权损失，软性去除数据分布中的不期望区域，而无需从头训练或直接访问需遗忘的样本。相反，它依赖基于能量的代理来指导遗忘过程。我们证明这能诱导与流匹配等效的梯度，朝向软性质量减除的目标，并通过2D和图像领域的实验验证了该框架，辅以可解释的可视化和定量评估。

</details>


### [508] [Sensitivity Analysis of Image Classification Models using Generalized Polynomial Chaos](https://arxiv.org/abs/2506.18751)
**中文标题：基于广义多项式混沌的图像分类模型敏感性分析**

*Lukas Bahr,Lucas Poßner,Konstantin Weise,Sophie Gröger,Rüdiger Daub*

主要分类: cs.LG

摘要简述: 本文研究了图像分类模型在预测质量中的敏感性，提出了一种基于广义多项式混沌（GPC）和Sobol指数的方法，用于量化输入参数对输出的影响，并通过焊接缺陷分类和宝马标志分类案例验证了方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据驱动的预测质量方法（如机器学习模型）在生产中的广泛应用，图像分类模型面临模型、数据和领域偏移带来的不确定性，导致分类结果过度自信。为了深入理解这些模型，敏感性分析成为必要。本文旨在通过量化输入参数对输出的影响，提升模型的可解释性和可靠性。

研究方法: 本文提出了一种基于广义多项式混沌（GPC）的方法，将输入参数的分布域偏移建模为随机变量，并通过Sobol指数量化其对模型输出的影响。研究通过微调的ResNet18模型和宝马标志分类模型，在焊接缺陷分类问题中验证了方法的有效性。

研究结果: 案例研究表明，提出的方法能够有效量化输入参数对图像分类模型输出的影响，尤其是在焊接缺陷分类和宝马标志分类中，展示了其在实际生产环境中的适用性。

研究结论: 本文提出的基于GPC和Sobol指数的敏感性分析方法，为图像分类模型的不确定性分析提供了有效工具，增强了模型的可解释性和可靠性，适用于实际生产环境中的预测质量问题。

中文摘要: 随着先进通信协议在生产中的集成，数据驱动的预测质量方法（尤其是机器学习模型）的采用加速。然而，图像分类中的机器学习模型常面临模型、数据和领域偏移带来的显著不确定性，导致分类模型输出过度自信。为了更好地理解这些模型，敏感性分析有助于分析输入参数对输出的相对影响。本研究探讨了用于预测质量的图像分类模型的敏感性。我们提出将输入的分布域偏移建模为随机变量，并通过广义多项式混沌（GPC）计算的Sobol指数量化其对模型输出的影响。该方法通过一个涉及焊接缺陷分类问题的案例研究进行了验证，使用了微调的ResNet18模型和宝马集团生产设施中使用的标志分类模型。

</details>


### [509] [Shift Happens: Mixture of Experts based Continual Adaptation in Federated Learning](https://arxiv.org/abs/2506.18789)
**中文标题：偏移发生：基于专家混合模型的联邦学习持续适应方法**

*Rahul Atul Bhope,K. R. Jayaram,Praveen Venkateswaran,Nalini Venkatasubramanian*

主要分类: cs.LG

摘要简述: 本文提出ShiftEx框架，通过专家混合模型动态适应联邦学习中的协变量和标签偏移，显著提升模型性能并减少适应时间。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在动态变化的客户端数据分布下性能下降，亟需解决协变量和标签偏移问题。

研究方法: 提出ShiftEx框架，利用最大均值差异检测协变量偏移，动态创建和训练专家模型，结合潜在记忆机制和设施选址优化。

研究结果: 实验表明，ShiftEx在多种偏移场景下比现有方法准确率提升5.5-12.9%，适应速度加快22-95%。

研究结论: ShiftEx为动态环境下的联邦学习提供了高效、隐私保护的中间件解决方案。

中文摘要: 联邦学习（FL）支持跨分散客户端的协作模型训练而无需共享原始数据，但在客户端数据分布动态演变的实际场景中面临重大挑战。本文解决了流式FL环境中协变量和标签偏移的关键问题，其中非平稳数据分布会降低模型性能，需要自适应中间件解决方案。我们提出了ShiftEx，一种基于专家混合模型的偏移感知框架，利用最大均值差异检测协变量偏移，动态创建和训练专用全局模型。该框架采用潜在记忆机制实现专家重用，并通过设施选址优化联合最小化协变量不匹配、专家创建成本和标签不平衡。通过理论分析和基准数据集的综合实验，我们展示了在多种偏移场景下，相比最先进的FL基线方法，ShiftEx实现了5.5-12.9个百分点的准确率提升和22-95%的更快适应速度。所提出的方法为在非平稳实际条件下运行的FL系统提供了一种可扩展、隐私保护的中间件解决方案，同时最小化了通信和计算开销。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [510] [Zero-Shot Cognitive Impairment Detection from Speech Using AudioLLM](https://arxiv.org/abs/2506.17351)
**中文标题：基于AudioLLM的零样本语音认知障碍检测**

*Mostafa Shahin,Beena Ahmed,Julien Epps*

主要分类: cs.SD

摘要简述: 本文提出了一种基于语音的零样本认知障碍检测方法，利用Qwen2-Audio AudioLLM模型，通过设计提示指令实现分类，无需手动标注，且在跨语言和任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 认知障碍（CI）是日益严重的公共卫生问题，早期检测对干预至关重要。传统方法依赖监督学习，需要手动标注且泛化性差。本文旨在开发一种无需标注、泛化性强的零样本检测方法。

研究方法: 使用Qwen2-Audio AudioLLM模型，设计提示指令对语音样本进行分类，判断其是否显示认知障碍。模型支持音频和文本输入，并在英语和多语言数据集上进行评估。

研究结果: 零样本方法在性能上与监督方法相当，且在跨语言、任务和数据集上表现出良好的泛化性和一致性。

研究结论: 基于AudioLLM的零样本方法为认知障碍检测提供了一种高效、泛化性强的解决方案，具有实际应用潜力。

中文摘要: 认知障碍（CI）是日益严重的公共卫生问题，早期检测对有效干预至关重要。语音作为一种非侵入性且易于收集的生物标志物，受到广泛关注。传统的CI检测方法通常依赖于从语音中提取的声学和语言特征的监督模型，这些方法需要手动标注且难以在不同数据集和语言中泛化。本文提出了一种基于Qwen2-Audio AudioLLM的零样本语音CI检测方法，该模型能够处理音频和文本输入。通过设计基于提示的指令，我们引导模型将语音样本分类为正常认知或认知障碍。我们在两个数据集（一个英语数据集和一个多语言数据集）上评估了该方法，涵盖不同的认知评估任务。结果表明，零样本AudioLLM方法的性能与监督方法相当，并在语言、任务和数据集上表现出良好的泛化性和一致性。

</details>


### [511] [AI-Generated Song Detection via Lyrics Transcripts](https://arxiv.org/abs/2506.18488)
**中文标题：基于歌词转录的AI生成歌曲检测**

*Markus Frohmann,Elena V. Epure,Gabriel Meseguer-Brocal,Markus Schedl,Romain Hennequin*

主要分类: cs.SD

摘要简述: 本文提出了一种通过歌词转录检测AI生成歌曲的方法，使用通用自动语音识别（ASR）模型和多种检测器，在多语言和多流派歌词上表现出色，尤其在音频被干扰时优于现有音频检测方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI音乐生成工具的快速发展，音乐行业亟需准确检测AI生成内容的方法。现有音频检测方法在泛化性和抗干扰性上表现不佳，而依赖完美歌词的方法在实际中不可行。因此，本文旨在填补这一空白。

研究方法: 使用通用自动语音识别（ASR）模型转录歌曲歌词，并结合多种检测器（如Whisper large-v2和LLM2Vec嵌入）进行AI生成歌曲检测。

研究结果: 在多语言、多流派的歌词数据集上，该方法表现出强大的检测性能，尤其在音频被干扰时优于现有音频检测方法，且对不同音乐生成器具有更强的鲁棒性。

研究结论: 通过歌词转录和多种检测器的结合，本文方法在检测AI生成歌曲方面表现出色，填补了实际应用中的空白，并为未来研究提供了新方向。

中文摘要: 近年来，基于AI的音乐生成工具能力大幅提升，对音乐行业产生了巨大冲击，因此需要开发准确检测AI生成内容的方法。虽然可以通过音频检测器实现，但它们在面对未见过的生成器或音频干扰时表现不佳。此外，已有研究利用歌词提供数据库中的精确歌词检测AI生成音乐，但实际中完美歌词难以获取（仅有音频），这在实际应用中留下了巨大空白。本文提出通过通用自动语音识别（ASR）模型转录歌曲歌词来解决这一问题，并采用多种检测器。实验结果表明，在多语言、多流派的歌词数据集上，该方法表现出强大的检测性能，尤其是在使用Whisper large-v2和LLM2Vec嵌入的最佳模型中。此外，本文方法在音频被不同方式干扰时，以及对不同音乐生成器的检测中，均表现出优于现有音频检测方法的鲁棒性。代码已开源：https://github.com/deezer/robust-AI-lyrics-detection。

</details>


### [512] [Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts](https://arxiv.org/abs/2506.18510)
**中文标题：流畅的操作者：LLMs将不完美提示转化为富含不流畅标记的转录本**

*Duygu Altinok*

主要分类: cs.SD

摘要简述: 本文提出了一种利用大型语言模型（LLMs）将不完美的语音提示转化为包含不流畅标记的转录本的方法，展示了LLMs在处理不完美输入时的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 准确检测口语中的不流畅现象对提升自动语音和语言处理系统的性能至关重要，同时也有助于开发更具包容性的语音技术。本文旨在利用LLMs的多模态处理能力，生成包含不流畅标记和时间戳的完整转录本。

研究方法: 该方法将音频编码器提取的声学表征与不同质量的文本输入（如无瑕疵的转录、时间对齐的转录或基于音素的ASR模型输出）结合，利用LLMs生成包含不流畅标记和时间戳的转录本。

研究结果: 实验表明，即使文本输入不完美，只要包含时间戳相关线索，LLMs仍能有效平滑输入并生成完整的不流畅标记转录本，证明了其处理不完美提示的鲁棒性。

研究结论: LLMs能够有效处理不完美的语音提示，生成高质量的不流畅标记转录本，为语音和语言处理技术的发展提供了新思路。

中文摘要: 准确检测口语中的不流畅现象对于提升自动语音和语言处理系统的性能至关重要，同时也有助于开发更具包容性的语音和语言技术。利用大型语言模型（LLMs）作为能够处理词汇和非词汇输入（如音频和视频）的多功能学习者的趋势，我们提出了一种将不流畅现象作为显式标记和时间戳转录的新方法，从而生成完全注释的富含不流畅标记的转录本。我们的方法将从音频编码器提取的声学表征与不同质量的文本输入（如无瑕疵的转录、时间对齐的转录或基于音素的ASR模型输出）结合，这些输入可能包含瑕疵。重要的是，我们的实验表明，文本输入无需完美无缺。只要包含时间戳相关线索，LLMs就能有效平滑输入并生成完整的不流畅标记转录本，凸显了其在处理不完美提示时的鲁棒性。

</details>


### [513] [USAD: Universal Speech and Audio Representation via Distillation](https://arxiv.org/abs/2506.18843)
**中文标题：USAD：通过蒸馏实现通用语音和音频表示**

*Heng-Jui Chang,Saurabhchand Bhati,James Glass,Alexander H. Liu*

主要分类: cs.SD

摘要简述: 本文提出了一种名为USAD的统一音频表示学习方法，通过蒸馏技术将语音、声音和音乐等多种音频类型整合到一个模型中，实现了跨领域的竞争性性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前自监督学习（SSL）模型多为领域专用，无法同时处理语音和非语音任务。本文旨在通过USAD方法，打破领域限制，实现通用音频表示学习。

研究方法: USAD采用层到层蒸馏技术，从领域专用SSL模型中提取知识，训练一个学生模型，使其能够处理包含多种音频类型的综合数据集。

研究结果: USAD在多个基准测试和数据集上表现出色，包括帧级和实例级语音处理任务、音频标记和声音分类，在SUPERB和HEAR基准测试中接近最先进水平。

研究结论: USAD通过统一模型实现了跨领域音频表示学习，展示了其在多种任务中的竞争力和通用性。

中文摘要: 自监督学习（SSL）已经彻底改变了音频表示，但模型通常仍是领域专用的，专注于语音或非语音任务。本文提出了通用语音和音频蒸馏（USAD），一种统一的音频表示学习方法，将语音、声音和音乐等多种音频类型整合到一个模型中。USAD采用高效的层到层蒸馏技术，从领域专用SSL模型中训练一个学生模型，使其能够处理综合音频数据集。USAD在多种基准测试和数据集上表现出色，包括帧级和实例级语音处理任务、音频标记和声音分类，在SUPERB和HEAR基准测试中接近最先进水平。

</details>


### [514] [From Generality to Mastery: Composer-Style Symbolic Music Generation via Large-Scale Pre-training](https://arxiv.org/abs/2506.17497)
**中文标题：从通用到精通：基于大规模预训练的作曲家风格符号音乐生成**

*Mingyang Yao,Ke Chen*

主要分类: cs.SD

摘要简述: 本文提出了一种两阶段训练方法，通过大规模预训练和轻量级适配器微调，实现了从通用音乐知识到特定作曲家风格的精确生成，显著提升了钢琴曲的风格准确性和音乐美感。


<details>
  <summary>详细信息</summary>
研究动机: 当前可控符号音乐生成中，数据稀缺问题限制了特定作曲家风格的建模。本文旨在探索如何利用通用音乐知识增强对少数作曲家作品的风格掌握，以解决数据不足的挑战。

研究方法: 采用两阶段训练：首先在大规模流行、民谣和古典音乐数据集上预训练基于REMI的音乐生成模型；随后在巴赫、莫扎特、贝多芬和肖邦的小型数据集上，通过轻量级适配器模块微调模型，以条件化风格指示。

研究结果: 实验表明，该方法在风格准确性和音乐性上优于基线模型，实现了更精确的作曲家风格建模和更好的音乐美学效果。同时揭示了模型如何从通用预训练中构建音乐概念，并通过微调细化风格理解。

研究结论: 通过结合通用预训练和特定风格微调，本文方法有效解决了数据稀缺问题，为作曲家风格音乐生成提供了高效且高质量的解决方案。

中文摘要: 尽管可控符号音乐生成取得了进展，但数据稀缺仍是某些控制模态的挑战。作曲家风格音乐生成是一个典型例子，因为每位作曲家的可用作品极少，限制了风格和基础音乐元素（如旋律、和弦、节奏）的建模。本文研究了如何利用从广泛语料库中学到的通用音乐知识增强对特定作曲家风格的掌握，重点关注钢琴曲生成。我们的方法采用两阶段训练范式：首先在大规模流行、民谣和古典音乐语料库上预训练基于REMI的音乐生成模型；随后在巴赫、莫扎特、贝多芬和肖邦的小型人工验证数据集上，通过轻量级适配器模块对模型进行风格指示的条件化微调。为评估方法的有效性，我们在风格准确性和音乐性上进行了主客观评估。实验结果表明，我们的方法优于消融实验和基线模型，实现了更精确的作曲家风格建模和更好的音乐美学效果。此外，我们还观察了模型如何从通用预训练中构建音乐概念，并通过精通微调细化其风格理解。

</details>


### [515] [CultureMERT: Continual Pre-Training for Cross-Cultural Music Representation Learning](https://arxiv.org/abs/2506.17818)
**中文标题：CultureMERT：跨文化音乐表示学习的持续预训练**

*Angelos-Nikolaos Kanatas,Charilaos Papaioannou,Alexandros Potamianos*

主要分类: cs.SD

摘要简述: 本文提出了一种名为CultureMERT-95M的多文化适应音乐基础模型，通过两阶段持续预训练策略提升跨文化音乐表示学习能力，在非西方音乐自动标注任务中表现优异，同时保持对西方音乐数据的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的音乐基础模型在跨文化音乐表示学习中表现有限，本文旨在通过多文化适应策略提升模型对多样化音乐传统的理解和表示能力。

研究方法: 采用两阶段持续预训练策略，结合学习率重新升温与衰减，训练于包含希腊、土耳其和印度音乐的650小时多文化数据集。同时探索了任务算术方法，将单文化适应模型在权重空间中合并。

研究结果: CultureMERT-95M在非西方音乐自动标注任务中平均提升4.9%的ROC-AUC和AP，优于现有技术，且对西方音乐数据遗忘最小。任务算术方法在非西方任务中表现相当，且对西方数据无退化。

研究结论: 多文化适应模型在跨文化音乐表示学习中表现最优，单文化模型的迁移效果因传统而异。本文公开了CultureMERT-95M和CultureMERT-TA-95M，以促进更具文化意识的音乐基础模型研究。

中文摘要: 尽管音乐基础模型在音频表示学习方面取得了进展，但其在多样化音乐传统中的表现仍有限。我们提出了CultureMERT-95M，一种多文化适应基础模型，旨在增强跨文化音乐表示学习与理解。为此，我们提出了一种两阶段持续预训练策略，结合学习率重新升温与衰减，即使在有限计算资源下也能实现稳定适应。通过在包含希腊、土耳其和印度音乐的650小时多文化数据集上训练，模型在非西方音乐自动标注任务中的ROC-AUC和AP平均提升了4.9%，超越了现有技术，同时对西方基准任务的遗忘最小。我们还研究了任务算术方法，这是一种在权重空间中合并单文化适应模型的替代方案。任务算术在非西方自动标注任务中表现与多文化训练模型相当，且对西方数据集无退化。跨文化评估表明，单文化模型在不同音乐传统中的迁移效果各异，而多文化适应模型整体表现最佳。为支持世界音乐表示学习研究，我们公开了CultureMERT-95M和CultureMERT-TA-95M，以推动更具文化意识的音乐基础模型发展。

</details>


### [516] [TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography](https://arxiv.org/abs/2506.18671)
**中文标题：TCDiff++：一种端到端轨迹可控扩散模型用于和谐音乐驱动群舞生成**

*Yuqin Dai,Wanlu Zhu,Ronghui Li,Xiu Li,Zhenyu Zhang,Jun Li,Jian Yang*

主要分类: cs.SD

摘要简述: TCDiff++是一种端到端的轨迹可控扩散模型，用于生成和谐的音乐驱动群舞，解决了多舞者碰撞、单舞者脚滑和长群舞生成中的突然交换问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有音乐驱动舞蹈生成方法在群舞生成中存在多舞者碰撞、单舞者脚滑和长群舞生成中的突然交换问题，亟需一种高效且和谐的解决方案。

研究方法: TCDiff++采用舞者定位嵌入和距离一致性损失避免碰撞，引入交换模式嵌入和脚步适配器减少脚滑，并通过长群扩散采样策略和序列解码层优化长群舞生成。

研究结果: 实验表明，TCDiff++在长时场景中表现优异，能够生成高质量且连贯的群舞。

研究结论: TCDiff++通过创新设计解决了群舞生成中的关键问题，实现了和谐且可控的群舞生成。

中文摘要: 音乐驱动舞蹈生成因其广泛的工业应用（尤其是群舞创作）而备受关注。然而，在群舞生成过程中，现有方法仍面临三个主要问题：多舞者碰撞、单舞者脚滑和长群舞生成中的突然交换。本文提出TCDiff++，一种端到端框架，旨在生成和谐的群舞。具体而言，为避免多舞者碰撞，我们采用舞者定位嵌入以更好地维持舞者间的相对位置，并引入距离一致性损失确保舞者间距合理。为解决单舞者脚滑问题，我们设计交换模式嵌入指示舞者交换模式，并开发脚步适配器优化原始动作以减少脚滑。针对长群舞生成，我们提出长群扩散采样策略，通过向噪声输入注入位置信息减少突然位置变化。此外，我们整合序列解码层以增强模型对长序列的选择性处理能力。大量实验表明，TCDiff++在长时场景中表现优异，确保了高质量且连贯的群舞生成。

</details>


### [517] [Frequency-Weighted Training Losses for Phoneme-Level DNN-based Speech Enhancement](https://arxiv.org/abs/2506.18714)
**中文标题：基于频率加权的训练损失函数用于音素级DNN语音增强**

*Nasser-Eddine Monir,Paul Magron,Romain Serizel*

主要分类: cs.SD

摘要简述: 本文提出了一种基于频率加权的训练损失函数，用于改进深度神经网络（DNN）在语音增强中对音素级细节的保留能力。通过设计固定和自适应的频率权重策略，实验表明其在感知指标和音素重建方面优于传统损失函数。


<details>
  <summary>详细信息</summary>
研究动机: 传统训练损失函数（如SDR）在多通道语音增强中可能无法保留对音素可懂性至关重要的频谱细节。因此，本文旨在设计一种感知驱动的频率加权损失函数，以更好地提升语音增强效果。

研究方法: 提出了基于时频域的频率加权SDR损失函数变体，包括固定权重（如ANSI频带重要性权重）和自适应权重（如基于语音和噪声相对量的动态权重）。使用FaSNet模型进行训练，并对比不同权重策略的效果。

研究结果: 实验结果显示，虽然标准指标（如SDR）提升有限，但感知频率加权指标显著改善。频谱和音素级分析表明，辅音重建效果更好，说明某些声学线索得到了更好的保留。

研究结论: 频率加权训练损失函数在多通道语音增强中能够更有效地保留音素级细节，尤其是在感知指标和辅音重建方面表现突出。

中文摘要: 深度学习的最新进展显著提升了多通道语音增强算法的性能，但传统训练损失函数（如尺度不变信噪比SDR）可能无法保留对音素可懂性至关重要的精细频谱线索。本文提出了感知驱动的SDR损失函数变体，在时频域中通过频率相关权重进行调制。这些权重旨在强调语音显著或噪声较强的时频区域。我们研究了固定和自适应策略，包括ANSI频带重要性权重、基于频谱幅度的加权以及基于语音和噪声相对量的动态加权。使用FaSNet多通道语音增强模型进行训练。实验结果表明，虽然标准指标（如SDR）仅略有提升，但其感知频率加权版本表现出更显著的改进。此外，频谱和音素级分析表明辅音重建效果更好，说明某些声学线索得到了更好的保留。

</details>


### [518] [MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners](https://arxiv.org/abs/2506.18729)
**中文标题：MuseControlLite：基于轻量级调节器的多功能音乐生成**

*Fang-Duo Tsai,Shih-Lun Wu,Weijaw Lee,Sheng-Ping Yang,Bo-Rui Chen,Hao-Chung Cheng,Yi-Hsuan Yang*

主要分类: cs.SD

摘要简述: 本文提出MuseControlLite，一种轻量级机制，用于通过时间变化的音乐属性和参考音频信号对文本到音乐生成模型进行精确调节。关键发现是位置嵌入在时间相关条件下至关重要，实验表明其显著提升控制精度并大幅减少可训练参数。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到音乐生成模型在时间相关条件下的控制精度不足，且调节机制通常需要大量可训练参数。本文旨在设计一种轻量级调节机制，提升控制精度并降低计算成本。

研究方法: 提出MuseControlLite，通过向解耦的交叉注意力层添加旋转位置嵌入，优化时间相关条件的控制。实验以旋律控制为例，验证其有效性。

研究结果: 实验显示，MuseControlLite将控制精度从56.6%提升至61.1%，同时仅需85M可训练参数，比现有方法减少6.75倍。在音乐属性控制、音频修复和扩展任务中表现优于MusicGen-Large和Stable Audio Open ControlNet。

研究结论: MuseControlLite在显著降低微调成本的同时，提升了文本到音乐生成模型的控制精度和多功能性，为轻量级调节机制提供了有效解决方案。

中文摘要: 我们提出MuseControlLite，一种轻量级机制，旨在通过多种时间变化的音乐属性和参考音频信号对文本到音乐生成模型进行精确调节。关键发现是，位置嵌入在文本条件调节器中很少被使用，但对于时间相关条件至关重要。以旋律控制为例，实验表明，仅需在解耦的交叉注意力层中添加旋转位置嵌入，即可将控制精度从56.6%提升至61.1%，同时所需可训练参数比现有最先进的微调机制减少6.75倍（基于相同的预训练扩散Transformer模型Stable Audio Open）。我们评估了多种音乐属性控制、音频修复和扩展任务，结果显示其控制性能优于MusicGen-Large和Stable Audio Open ControlNet，且微调成本显著降低，仅需85M可训练参数。源代码、模型检查点和演示示例详见：https://MuseControlLite.github.io/web/。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [519] [When concept-based XAI is imprecise: Do people distinguish between generalisations and misrepresentations?](https://arxiv.org/abs/2506.17936)
**中文标题：当基于概念的XAI不精确时：人们能否区分泛化与错误表示？**

*Romy Müller*

主要分类: cs.HC

摘要简述: 研究探讨了基于概念的XAI（C-XAI）中，人们是否能区分AI的泛化与错误表示。实验发现，参与者对不相关特征的泛化评价较低，且与错误表示相当，但对相关特征的不精确性高度敏感。


<details>
  <summary>详细信息</summary>
研究动机: 在复杂任务（如安全评估）中，理解AI的内部表示至关重要。C-XAI通过概念揭示这些表示，但人们是否能区分泛化与错误表示尚不明确。研究旨在验证这一点。

研究方法: 在铁路安全场景中，参与者评估模拟AI对危险交通场景的判断。AI通过类似图像片段提供解释，这些片段在相关特征（如轨道关系）或不相关特征（如动作）上与分类图像匹配度不同。

研究结果: 与假设相反，对不相关特征的泛化概念评分低于精确匹配概念，且与错误表示相当。参与者对相关特征的不精确性高度敏感。

研究结论: 人们可能无法自发识别AI的泛化行为，因此难以通过C-XAI概念判断AI是否深入理解了复杂情境。

中文摘要: 基于概念的可解释人工智能（C-XAI）有助于揭示AI模型的内部表示。理解这些表示在复杂任务（如安全评估）中尤为重要。此类任务依赖高级语义信息（如动作）来对抽象类别（如情境是否危险）做出决策。在此背景下，C-XAI概念可能需要一定变异性，表明AI能够超越具体情境细节进行泛化。然而，人们是否能识别并欣赏这种泛化，并将其与其他不理想的不精确形式区分开尚不明确。本研究通过铁路安全实验场景探讨了这一问题。参与者评估了一个模拟AI的性能，该AI判断涉及人员的交通场景是否危险。为解释这些决策，AI提供了类似图像片段作为概念。这些概念在与分类图像的匹配度上存在差异，涉及高度相关特征（如轨道关系）或较不相关特征（如动作）。与假设相反，对较不相关特征的泛化概念评分低于精确匹配概念，且与系统性错误表示相当。相反，参与者对相关特征的不精确性高度敏感。这些发现质疑人们是否能自发识别泛化行为，进而可能无法通过C-XAI概念推断AI模型是否深入理解了复杂情境。

</details>


### [520] [Conceptualization, Operationalization, and Measurement of Machine Companionship: A Scoping Review](https://arxiv.org/abs/2506.18119)
**中文标题：机器伴侣的概念化、操作化与测量：范围综述**

*Jaime Banks,Zhixin Li*

主要分类: cs.HC

摘要简述: 本文通过PRISMA指导的范围综述，系统梳理了2017-2025年间71篇关于机器伴侣（MC）的学术研究，提出了MC的定义：一种自主、协调且随时间发展的人类与机器之间的主观积极连接。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器伴侣在社交技术想象中由来已久，但缺乏对其作为正式概念或测量变量的深入研究。本文旨在填补这一空白，系统梳理现有文献，明确MC的定义和测量维度。

研究方法: 采用PRISMA指导的范围综述方法，系统筛选、调查并综合了2017-2025年间71篇关于MC的学术研究，分析了其理论框架、先验属性维度（主观积极、持续、协同、自主）及测量变量。

研究结果: 研究发现，MC的研究在理论框架、属性维度和测量变量上差异显著（超过50种不同的测量变量）。最终提出了MC的文献指导定义：一种自主、协调且随时间发展的人类与机器之间的主观积极连接。

研究结论: 本文为机器伴侣的研究提供了系统化的综述和定义，为未来研究奠定了概念基础。

中文摘要: 机器伴侣的概念长期根植于社会技术想象中。近年来，人工智能的进步将这些媒体设想转化为可感知的社交性，体现在界面、机器人身体和设备中。这些机器常被通俗地称为“伴侣”，但鲜有研究将机器伴侣（MC）作为正式概念或测量变量进行深入探讨。本文通过PRISMA指导的范围综述，系统筛选、调查并综合了2017-2025年间关于MC的学术研究（N=71）。研究发现，MC的研究在理论框架、先验属性维度（主观积极、持续、协同、自主）及测量变量上差异显著（超过50种不同的测量变量）。最终提出了MC的文献指导定义：一种自主、协调且随时间发展的人类与机器之间的主观积极连接。

</details>


### [521] [AI Harmonizer: Expanding Vocal Expression with a Generative Neurosymbolic Music AI System](https://arxiv.org/abs/2506.18143)
**中文标题：AI Harmonizer：利用生成式神经符号音乐AI系统扩展人声表达**

*Lancelot Blanchard,Cameron Holt,Joseph A. Paradiso*

主要分类: cs.HC

摘要简述: AI Harmonizer是一种创新的生成式神经符号音乐AI系统，能够自动为独唱旋律生成四部和声，无需用户预先输入和声信息，从而扩展了人声表达的可能性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的和声生成工具通常需要用户手动指定调性或通过外部键盘选择音高，这对音乐专业知识有一定要求。AI Harmonizer旨在通过自主生成音乐上连贯的和声，降低使用门槛，同时丰富独唱的表现力。

研究方法: 该系统结合了最先进的生成式AI技术（用于音高检测和声音建模）与定制的符号音乐模型，能够将任何独唱旋律转化为丰富的合唱纹理。

研究结果: AI Harmonizer成功生成了音乐上连贯的四部和声，展示了在表演和作曲中的潜在应用。尽管目前系统仅支持离线操作，但为实时AI辅助人声表演奠定了基础。

研究结论: AI Harmonizer代表了AI辅助人声表演和音乐表达增强的重要进展，未来有望实现实时应用。系统代码已在GitHub上开源。

中文摘要: 人声和声器是帮助独唱歌手通过和声丰富旋律的强大工具。这些工具形式多样，从商用踏板和软件到定制系统，每种都采用不同的和声生成方法。传统和声器通常需要用户手动指定调性或通过外部键盘选择音高，这两种方法均需一定的音乐专业知识。AI Harmonizer通过自主生成音乐上连贯的四部和声，无需用户预先输入和声信息，提出了一种新颖的方法。通过结合最先进的生成式AI技术（用于音高检测和声音建模）与定制的符号音乐模型，我们的系统能将任何独唱旋律转化为丰富的合唱纹理。本文介绍了我们的方法，探讨了在表演和作曲中的潜在应用，并讨论了实时实现的未来方向。尽管目前系统仅支持离线操作，但我们认为这是迈向AI辅助人声表演和音乐表达增强的重要一步。我们的实现已在GitHub上发布。

</details>


### [522] [Two Sonification Methods for the MindCube](https://arxiv.org/abs/2506.18196)
**中文标题：MindCube的两种声音化方法**

*Fangzheng Liu,Lancelot Blanchard,Don D. Haddad,Joseph A. Paradiso*

主要分类: cs.HC

摘要简述: 本文探讨了MindCube作为音乐界面的潜力，提出了两种映射方法（带AI和不带AI），旨在通过音乐系统帮助情绪调节。


<details>
  <summary>详细信息</summary>
研究动机: MindCube是一种用于研究情绪的交互设备，具有多种传感器和输入设备，适合作为音乐系统的控制器，帮助用户调节情绪。本文旨在探索其作为音乐界面的潜力。

研究方法: 提出了两种MindCube的映射方法：一种基于生成式AI，通过潜在空间注入意义并利用外部控制器导航；另一种不依赖AI。

研究结果: 讨论了两种映射方法的结果，展示了MindCube在情绪调节音乐系统中的潜力。

研究结论: MindCube作为音乐界面具有潜力，未来可进一步探索其在情绪调节中的应用。

中文摘要: 本研究探讨了MindCube作为音乐界面的潜力。MindCube是一种用于研究情绪的交互设备，配备多种传感器和输入设备，类似于常用于缓解压力和焦虑的指尖魔方玩具。因此，它特别适合作为旨在帮助情绪调节的音乐系统的控制器。为此，我们提出了两种不同的MindCube映射方法，分别包含和不包含AI。通过生成式AI映射，我们提出了一种在潜在空间中注入意义的方法，并利用外部控制器导航的技术。我们讨论了结果，并提出了未来工作的方向。

</details>


### [523] [BRAVE: Brain-Controlled Prosthetic Arm with Voice Integration and Embodied Learning for Enhanced Mobility](https://arxiv.org/abs/2506.18749)
**中文标题：BRAVE：结合语音集成与具身学习的脑控假肢臂以增强移动性**

*Abdul Basit,Maha Nawaz,Muhammad Shafique*

主要分类: cs.HC

摘要简述: BRAVE是一种结合脑电图（EEG）和语音控制的假肢系统，通过集成学习算法和实时校正框架，实现了96%的分类准确率和150毫秒的响应延迟，为无创假肢控制提供了新方案。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于EEG的假肢控制系统存在信号噪声、分类准确性和实时适应性等问题，BRAVE旨在通过结合EEG和语音控制，提供更直观、鲁棒的无创假肢控制方案。

研究方法: BRAVE采用LSTM、CNN和随机森林的集成学习框架处理EEG信号，结合带通滤波、独立成分分析（ICA）和共空间模式（CSP）进行预处理，并集成语音识别以实现自由度切换。系统通过Lab Streaming Layer（LSL）实现实时同步数据采集。

研究结果: BRAVE在测试中实现了96%的分类准确率，响应延迟为150毫秒，适用于多种用户，并在低功耗嵌入式环境中表现出色。

研究结论: BRAVE为非侵入式假肢控制提供了鲁棒、实时的解决方案，具有广泛的实际应用潜力。

中文摘要: 非侵入式脑机接口（BCI）有望为上肢截肢者提供直观的假肢控制，但现有的基于EEG的控制系统面临信号噪声、分类准确性和实时适应性等挑战。本研究提出BRAVE，一种结合EEG和语音控制的混合假肢系统，通过集成学习框架和人在回路（HITL）校正机制提升响应性。与传统基于肌电图（EMG）的控制不同，BRAVE通过解读EEG驱动的运动意图实现控制，无需依赖残余肌肉活动。为提高分类鲁棒性，BRAVE结合了LSTM、CNN和随机森林模型，在测试中达到96%的分类准确率。EEG信号通过带通滤波（0.5-45 Hz）、独立成分分析（ICA）和共空间模式（CSP）进行预处理，以减少EMG和眼电（EOG）信号的干扰。此外，BRAVE集成自动语音识别（ASR）以实现假肢臂不同自由度（DOF）的直观切换。系统实时运行，响应延迟为150毫秒，并利用Lab Streaming Layer（LSL）实现同步数据采集。系统在自制假肢臂和多名参与者中进行了评估，展示了跨用户的通用性。系统针对低功耗嵌入式部署进行了优化，确保在高性能计算环境外的实际应用。结果表明，BRAVE为鲁棒、实时的非侵入式假肢控制迈出了重要一步。

</details>
