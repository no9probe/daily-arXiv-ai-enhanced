<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 33]
- [cs.CV](#cs.CV) [Total: 48]
- [cs.AI](#cs.AI) [Total: 23]
- [hep-ph](#hep-ph) [Total: 1]
- [cs.RO](#cs.RO) [Total: 8]
- [eess.IV](#eess.IV) [Total: 7]
- [eess.AS](#eess.AS) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.LG](#cs.LG) [Total: 39]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.SE](#cs.SE) [Total: 4]
- [cs.CR](#cs.CR) [Total: 8]
- [cs.HC](#cs.HC) [Total: 4]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 2]
- [cs.GR](#cs.GR) [Total: 3]
- [eess.SP](#eess.SP) [Total: 1]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation](https://arxiv.org/abs/2506.19952)
**中文标题：CycleDistill：基于循环蒸馏的大语言模型机器翻译自举方法**

*Deepon Halder,Thanmay Jayakumar,Raj Dabre*

主要分类: cs.CL

摘要简述: CycleDistill是一种利用大语言模型（LLMs）和少量示例进行机器翻译（MT）的循环蒸馏方法，无需依赖大规模平行语料库即可生成高质量翻译系统。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语言通常缺乏平行语料库，而大语言模型在少量示例下的机器翻译表现不如专用翻译系统。CycleDistill旨在通过循环蒸馏方法，利用单语语料库和少量示例生成高质量翻译系统。

研究方法: CycleDistill通过迭代生成合成平行语料库（基于零样本或少样本翻译），并利用这些数据微调模型，实现机器翻译的逐步提升。同时研究了在蒸馏过程中使用softmax激活对翻译质量的改进。

研究结果: 在三种印度语言的实验中，CycleDistill仅依赖单语语料库，首次迭代即可将翻译质量提升20-30 chrF点，优于少样本基线模型。

研究结论: CycleDistill展示了无需大规模平行语料库即可生成高质量翻译系统的潜力，为低资源语言翻译提供了新思路。

中文摘要: 尽管大语言模型（LLMs）能够进行少样本机器翻译（MT），但其表现通常不如基于平行语料库训练的专用MT系统。然而，对于低资源语言，平行语料库往往稀缺或不存在。本文提出CycleDistill，一种利用LLMs和少样本翻译的自举方法，用于生成高质量MT系统。CycleDistill通过迭代生成合成平行语料库（基于零样本或少样本MT），并利用这些数据微调模型，从而提升翻译质量。CycleDistill仅需1至4个少样本示例，无需其他平行语料库。在针对三种印度语言的实验中，仅依赖单语语料库，CycleDistill首次迭代即可将翻译质量提升20-30 chrF点，优于少样本基线模型。此外，我们还研究了在蒸馏过程中利用softmax激活对翻译质量的轻微改进。

</details>


### [2] [Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs](https://arxiv.org/abs/2506.19967)
**中文标题：推理扩展GraphRAG：改进知识图谱上的多跳问答**

*Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Inference-Scaled GraphRAG的新框架，通过推理时间计算扩展提升基于LLM的图推理能力，显著改善了多跳问答性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）在语言理解和生成方面表现出色，但在知识密集型推理任务中表现不佳，主要原因是缺乏对结构化上下文和多跳信息的访问。传统的RAG和GraphRAG方法难以捕捉知识图谱中节点间的关系结构，因此需要一种更有效的方法。

研究方法: 本文提出的Inference-Scaled GraphRAG框架结合了顺序扩展（通过深度链式思维图遍历）和并行扩展（通过多数投票采样轨迹），并在交错的推理-执行循环中实现。

研究结果: 在GRBench基准测试中，该方法显著提升了多跳问答性能，优于传统GraphRAG和先前的图遍历基线方法。

研究结论: 研究表明，推理时间扩展是一种实用且与架构无关的解决方案，可用于LLMs的结构化知识推理。

中文摘要: 大型语言模型（LLMs）在语言理解和生成方面取得了显著成就，但由于对结构化上下文和多跳信息的访问有限，在知识密集型推理任务中表现仍不理想。检索增强生成（RAG）通过将生成基于检索到的上下文部分缓解了这一问题，但传统的RAG和GraphRAG方法往往无法捕捉知识图谱中节点间的关系结构。我们提出了Inference-Scaled GraphRAG，这是一种新颖的框架，通过应用推理时间计算扩展来增强基于LLM的图推理。我们的方法结合了顺序扩展（通过深度链式思维图遍历）和并行扩展（通过多数投票采样轨迹），并在交错的推理-执行循环中实现。在GRBench基准测试上的实验表明，我们的方法显著提升了多跳问答性能，相比传统GraphRAG和先前的图遍历基线方法取得了显著进步。这些发现表明，推理时间扩展是一种实用且与架构无关的解决方案，可用于LLMs的结构化知识推理。

</details>


### [3] [Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation](https://arxiv.org/abs/2506.19998)
**中文标题：Doc2Agent：从API文档可扩展生成工具调用代理**

*Xinyi Ni,Haonan Jian,Qiuyang Wang,Vedanshi Chetan Shah,Pengyu Hong*

主要分类: cs.CL

摘要简述: Doc2Agent提出了一种可扩展的流水线，用于从API文档生成工具调用代理，显著提升了性能并降低了成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有的API代理通常依赖统一工具集，无法反映真实世界API的复杂性。构建适用于任意领域的工具调用代理仍面临挑战，需要从非结构化API文档中提取信息并推断正确参数。

研究方法: Doc2Agent通过从API文档生成可执行工具，并利用代码代理迭代优化这些工具，实现了工具调用代理的自动化构建。

研究结果: 在真实世界API、WebArena API和研究API上的评估显示，Doc2Agent性能提升了55%，成本降低了90%。此外，在糖材料科学领域的应用证明了其适应复杂任务的能力。

研究结论: Doc2Agent为从非结构化API文档大规模构建工具代理提供了一种通用解决方案。

中文摘要: REST API在丰富网络代理的动作空间中扮演重要角色，但大多数基于API的代理依赖统一工具集，无法反映真实世界API的复杂性。为任意领域构建工具调用代理仍是一个主要挑战，因为它需要阅读非结构化API文档、测试API并推断正确参数。我们提出了Doc2Agent，一种可扩展的流水线，用于构建能够调用从API文档生成的Python工具的代理。Doc2Agent从API文档生成可执行工具，并通过代码代理迭代优化这些工具。我们在真实世界API、WebArena API和研究API上评估了该方法，生成了已验证的工具。与直接调用API相比，在WebArena基准测试中，我们实现了55%的相对性能提升和90%的成本降低。为糖材料科学领域构建的特定领域代理进一步证明了该流水线对复杂、知识密集型任务的适应性。Doc2Agent为从非结构化API文档大规模构建工具代理提供了一种通用解决方案。

</details>


### [4] [A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs](https://arxiv.org/abs/2506.20073)
**中文标题：模块化多任务推理框架：时空模型与大型语言模型的集成**

*Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang*

主要分类: cs.CL

摘要简述: 本文提出了一种名为STReason的新型框架，结合大型语言模型（LLMs）和时空模型的优势，用于多任务推理和复杂的长篇推理。该框架通过上下文学习分解自然语言查询为模块化程序，无需任务特定微调，显著提升了时空推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的时空数据挖掘模型通常局限于单一任务，缺乏多任务推理和复杂长篇推理的能力，限制了其在现实多场景决策中的应用。因此，需要一种能够结合LLMs和时空模型优势的通用框架。

研究方法: STReason框架利用上下文学习将复杂自然语言查询分解为模块化、可解释的程序，系统执行后生成解决方案和详细解释。无需任务特定微调，支持多任务推理。

研究结果: 实验结果表明，STReason在所有指标上显著优于先进的LLM基线，尤其在复杂时空推理场景中表现突出。人类评估进一步验证了其可信度和实用性。

研究结论: STReason为开发更强大、更通用的时空推理系统提供了有前景的方向，能够减少专家工作量并扩展现实时空任务的应用范围。

中文摘要: 时空数据挖掘在多个领域的决策中起着关键作用。然而，现有模型通常局限于狭窄的任务，缺乏多任务推理和复杂长篇推理的能力，无法生成深入的解释性输出，限制了其在现实多场景决策中的应用。本文提出STReason，一种新颖的框架，结合大型语言模型（LLMs）的推理能力和时空模型的分析能力，用于多任务推理和执行。STReason无需任务特定微调，利用上下文学习将复杂自然语言查询分解为模块化、可解释的程序，系统执行后生成解决方案和详细解释。为便于严格评估，我们构建了一个新的基准数据集，并提出了一个统一的评估框架，设计了专门用于长篇时空推理的指标。实验结果表明，STReason在所有指标上显著优于先进的LLM基线，尤其在复杂、推理密集的时空场景中表现突出。人类评估进一步验证了STReason的可信度和实用性，展示了其减少专家工作量和扩展现实时空任务应用范围的潜力。我们认为STReason为开发更强大、更通用的时空推理系统提供了有前景的方向。

</details>


### [5] [SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization](https://arxiv.org/abs/2506.20081)
**中文标题：SACL：通过语义增强重新排序和定位理解并减少代码检索中的文本偏见**

*Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie*

主要分类: cs.CL

摘要简述: 本文揭示了当前代码检索模型对表面文本特征（如文档字符串和标识符名称）的依赖及其对文档化代码的偏见，并提出了一种名为SACL的框架，通过语义增强重新排序和定位来减少偏见并提升检索性能。实验表明，SACL显著提高了代码检索和生成的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前代码检索模型过度依赖表面文本特征，且对文档化代码存在偏见，这影响了检索和生成的准确性。本文旨在通过分析这些偏见并提出解决方案，提升代码检索和生成的效果。

研究方法: 作者提出SACL框架，通过语义增强重新排序和定位，减少对表面文本特征的依赖，并降低对文档化代码的偏见。具体方法包括系统性地掩盖特定特征以分析模型行为，并通过语义信息增强代码或结构知识。

研究结果: 实验结果显示，SACL在HumanEval、MBPP和SWE-Bench-Lite数据集上的Recall@1分别提高了12.8%、9.4%和7.0%，同时代码生成的Pass@1也提升了4.88%。

研究结论: SACL通过语义增强有效减少了代码检索中的文本偏见，显著提升了检索和生成性能，为代码检索领域提供了新的解决方案。

中文摘要: 检索增强代码生成（RACG）是通过检索相关信息增强代码生成的关键技术。本文通过系统性地掩盖特定特征同时保留代码功能，对代码检索进行了深入分析。研究发现：（1）尽管基于代码训练，当前检索模型严重依赖表面文本特征（如文档字符串、标识符名称）；（2）它们对文档化代码表现出强烈偏见，即使文档无关。基于此，我们提出SACL框架，通过语义信息增强代码或结构知识以丰富文本信息并减少偏见。大量实验表明，SACL显著提升了代码检索性能（如在HumanEval/MBPP/SWE-Bench-Lite上的Recall@1分别提高了12.8%/9.4%/7.0%），同时也改善了代码生成性能（如HumanEval上的Pass@1提高了4.88%）。

</details>


### [6] [Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder](https://arxiv.org/abs/2506.20083)
**中文标题：结合组合语义与分布语义：基于自编码器的潜在语义几何综述**

*Yingji Zhang,Danilo S. Carvalho,André Freitas*

主要分类: cs.CL

摘要简述: 本文综述了通过自编码器架构（如VAE、VQVAE和SAE）在潜在语义几何中结合组合语义与分布语义的方法，旨在提升语言模型的可解释性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于Transformer的自回归语言模型在语义表示上存在组合性与可解释性不足的问题。本文旨在通过潜在语义几何的研究，弥合符号语义与分布语义之间的鸿沟，提升模型性能。

研究方法: 本文综述并比较了三种主流自编码器架构（VAE、VQVAE和SAE），分析了它们在潜在语义几何中对语义结构和可解释性的影响。

研究结果: 研究发现，不同自编码器架构在潜在空间几何中表现出独特的语义特性，为语义表示学习提供了新的视角。

研究结论: 通过潜在语义几何的研究，可以更好地结合组合语义与分布语义，从而提升语言模型的可解释性和泛化能力。

中文摘要: 将组合性和符号性特征融入当前的分布语义空间，可以提升基于Transformer的自回归语言模型（LMs）的可解释性、可控性、组合性和泛化能力。本综述从组合语义的角度，提出了一种关于潜在空间几何的新视角，我们称之为“语义表示学习”。这一方向能够弥合符号语义与分布语义之间的鸿沟。我们回顾并比较了三种主流自编码器架构——变分自编码器（VAE）、向量量化VAE（VQVAE）和稀疏自编码器（SAE），并分析了它们在语义结构和可解释性方面所诱导的独特潜在几何特性。

</details>


### [7] [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)
**中文标题：ITFormer：桥接时间序列与自然语言的多模态问答框架及大规模多任务数据集**

*Yilin Wang,Peixuan Lei,Jie Song,Yuzhe Hao,Tao Chen,Yuxuan Zhang,Lei Jia,Yuanxiang Li,Zhongyu Wei*

主要分类: cs.CL

摘要简述: 本文提出了一种新型框架ITFormer，用于桥接时间序列数据与自然语言，并发布了首个大规模多任务时间序列问答数据集EngineMT-QA。ITFormer通过结合时间序列编码器与冻结的大型语言模型，显著提升了问答准确性，同时保持了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 时间序列数据在工业监控、医疗诊断和气候研究等领域至关重要，但如何将其与自然语言有效结合以支持动态交互任务仍是一个重大挑战。本文旨在解决这一问题。

研究方法: 提出了Instruct Time Transformer (ITFormer)框架，通过提取、对齐和融合时间序列与文本特征，结合时间序列编码器和冻结的大型语言模型，实现了高效的跨模态建模。

研究结果: ITFormer在问答任务中显著优于基线模型，仅需少于1%的可训练参数即可实现更高的准确性。

研究结论: 本研究为时间序列数据与自然语言的结合提供了一种高效且适应性强的范式，为多模态AI的研究和应用开辟了新方向。

中文摘要: 时间序列数据在工业监控、医疗诊断和气候研究等多样化应用中至关重要。然而，如何将这些高维时间信号与自然语言有效结合以支持动态交互任务仍是一个重大挑战。为此，我们提出了时间序列问答（Time-Series QA）任务，并发布了EngineMT-QA，这是首个大规模、多任务、时间-文本问答数据集，旨在捕捉时间序列信号与自然语言之间的复杂交互。基于这一资源，我们提出了Instruct Time Transformer (ITFormer)，一种新颖的框架，将时间序列编码器与冻结的大型语言模型（LLMs）相结合。ITFormer有效提取、对齐和融合时间与文本特征，在问答准确性上显著优于基线模型，且仅需少于1%的可训练参数。通过将计算效率与强大的跨模态建模相结合，我们的工作为时间数据与自然语言的整合提供了一个适应性强的范式，为多模态AI的研究和应用开辟了新方向。更多项目详情，包括数据集和代码，请访问：https://pandalin98.github.io/itformer_site/

</details>


### [8] [A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection](https://arxiv.org/abs/2506.20112)
**中文标题：一种多阶段大语言模型框架用于精确高效的放射学报告错误检测**

*Songsoo Kim,Seungtae Lee,See Young Lee,Joonho Kim,Keechan Kan,Dukyong Yoon*

主要分类: cs.CL

摘要简述: 本文提出了一种三阶段大语言模型框架，显著提高了放射学报告错误检测的阳性预测值（PPV），同时降低了操作成本。


<details>
  <summary>详细信息</summary>
研究动机: 由于放射学报告中的错误发生率较低，现有大语言模型（LLM）校对方法的阳性预测值（PPV）有限。本文旨在评估三阶段LLM框架是否能够提升PPV并减少操作成本。

研究方法: 研究回顾性分析了来自MIMIC-III数据库的1,000份放射学报告（包括X光、超声、CT和MRI各250份），并使用CheXpert和Open-i作为验证集。测试了三种LLM框架：单提示检测器、提取器加检测器、以及提取器、检测器和假阳性验证器的组合。通过PPV和绝对真阳性率（aTPR）衡量精度，并通过模型推理费用和评审员薪酬计算效率。

研究结果: 三阶段框架的PPV从0.063（框架1）显著提升至0.159（框架3），操作成本每1,000份报告从9.72美元降至5.58美元，减少了42.6%。aTPR保持稳定（0.012-0.014）。外部验证支持框架3的优越PPV（CheXpert 0.133，Open-i 0.105）。

研究结论: 三阶段LLM框架显著提升了PPV并降低了操作成本，同时保持了检测性能，为AI辅助放射学报告质量保证提供了有效策略。

中文摘要: 背景：由于错误发生率低，基于大语言模型（LLM）的放射学报告校对方法的阳性预测值（PPV）有限。目的：评估三阶段LLM框架是否比基线方法更能提升PPV并降低操作成本。材料与方法：回顾性分析了MIMIC-III数据库中的1,000份连续放射学报告（X光、超声、CT和MRI各250份），并使用CheXpert和Open-i作为验证集。测试了三种LLM框架：（1）单提示检测器；（2）提取器加检测器；（3）提取器、检测器和假阳性验证器。通过PPV和绝对真阳性率（aTPR）衡量精度，并通过模型推理费用和评审员薪酬计算效率。结果：框架PPV从0.063（框架1）显著提升至0.159（框架3），操作成本每1,000份报告从9.72美元降至5.58美元。aTPR保持稳定（0.012-0.014）。外部验证支持框架3的优越PPV（CheXpert 0.133，Open-i 0.105）。结论：三阶段LLM框架显著提升了PPV并降低了操作成本，同时保持了检测性能，为AI辅助放射学报告质量保证提供了有效策略。

</details>


### [9] [Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests](https://arxiv.org/abs/2506.20119)
**中文标题：利用AI评分器填补缺失分数以实现构建反应测试中准确的能力估计**

*Masaki Uto,Yuma Ito*

主要分类: cs.CL

摘要简述: 本文提出了一种利用AI评分技术填补缺失分数的新方法，以提高构建反应测试中能力估计的准确性，同时显著减少人工评分工作量。


<details>
  <summary>详细信息</summary>
研究动机: 构建反应测试（如简答和论述题）能有效评估高阶能力，但人工评分成本高且耗时。传统IRT方法在缺失分数较多时准确性下降，现有数据填补技术对稀疏或异构数据效果不佳。本研究旨在通过AI评分技术填补缺失分数，提升能力估计的准确性和效率。

研究方法: 提出了一种结合自动评分技术的新方法，用于填补构建反应测试中的缺失分数，从而支持基于IRT的准确能力估计。该方法利用AI评分器生成缺失分数，减少对人工评分的依赖。

研究结果: 实验表明，该方法在能力估计中实现了高准确性，同时显著降低了人工评分的工作量。

研究结论: 通过AI评分技术填补缺失分数是一种高效且准确的方法，能够显著提升构建反应测试的评估效率，同时减轻人工负担。

中文摘要: 评估学习者的能力是教育领域的一项基本目标。特别是，对表达能力与逻辑思维等高阶能力的评估需求日益增长。构建反应测试（如简答和论述题）已成为满足这一需求的常用方法。尽管这些测试有效，但需要大量人工评分，既耗时又昂贵。项目反应理论（IRT）提供了一种有前景的解决方案，能够从不完整的分数数据中估计能力，即人类评分者仅对学习者提供的部分答案进行评分。然而，随着缺失分数比例的增加，能力估计的准确性会下降。尽管已有研究探索了填补缺失分数的数据增强技术，但这些技术对稀疏或异构数据的处理往往不够准确。为克服这些挑战，本研究提出了一种利用自动评分技术填补缺失分数的新方法，以实现基于IRT的准确能力估计。该方法在显著减少人工评分工作量的同时，实现了高准确性的能力估计。

</details>


### [10] [CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation](https://arxiv.org/abs/2506.20128)
**中文标题：CCRS：一种用于全面RAG评估的零样本LLM即评判框架**

*Aashiq Muhamed*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CCRS的零样本LLM评估框架，用于全面评估RAG系统的多维度质量，包括上下文连贯性、问题相关性、信息密度、答案正确性和信息召回。实验表明CCRS在计算效率和判别能力上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: RAG系统通过引入外部知识提升LLM性能，但现有评估方法多依赖简单的词汇重叠指标或复杂的多阶段流程，无法全面捕捉RAG输出的质量。因此，需要一种高效且全面的评估框架。

研究方法: CCRS利用预训练的大型语言模型（LLM）作为零样本端到端评估器，提出五个指标：上下文连贯性（CC）、问题相关性（QR）、信息密度（ID）、答案正确性（AC）和信息召回（IR）。在BioASQ数据集上测试了六种RAG系统配置。

研究结果: 实验结果显示，CCRS能有效区分不同RAG系统的性能，例如Mistral-7B优于Llama变体。CCRS在关键指标（如召回率和忠实度）上的判别能力与复杂框架RAGChecker相当或更优，且计算效率显著提升。

研究结论: CCRS为RAG系统提供了一种实用、全面且高效的评估框架，支持迭代改进。其零样本设计和多维度指标使其成为现有方法的理想替代。

中文摘要: RAG系统通过整合外部知识增强LLM，这对于需要事实准确性和最新信息的领域至关重要。然而，评估RAG输出的多维度质量（如上下文连贯性、查询相关性、事实正确性和信息完整性）面临重大挑战。现有方法多依赖简单的词汇重叠指标，无法捕捉这些细微差异，或涉及复杂的多阶段流程（如声明提取或微调专用评判模型），影响实际效率。为解决这些问题，我们提出CCRS（上下文连贯性与相关性评分），这是一套包含五个指标的新方法，利用单一预训练LLM作为零样本端到端评判器。CCRS评估：上下文连贯性（CC）、问题相关性（QR）、信息密度（ID）、答案正确性（AC）和信息召回（IR）。我们在具有挑战性的BioASQ数据集上评估了六种RAG系统配置。分析表明，CCRS能有效区分系统性能，例如Mistral-7B阅读器优于Llama变体。我们还详细分析了CCRS指标特性，包括分数分布、收敛/判别效度、平局率、总体统计和判别能力。与复杂的RAGChecker框架相比，CCRS在关键方面（如召回率和忠实度）的判别能力相当或更优，同时计算效率显著提升。因此，CCRS为评估和迭代改进RAG系统提供了一种实用、全面且高效的框架。

</details>


### [11] [AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control](https://arxiv.org/abs/2506.20160)
**中文标题：AALC：通过自适应精度-长度控制实现大型语言模型高效推理**

*Ruosen Li,Ziming Luo,Quan Zhang,Ruochen Li,Ben Zhou,Ali Payani,Xinya Du*

主要分类: cs.CL

摘要简述: AALC是一种通过自适应精度-长度控制优化大型推理模型效率的方法，显著减少响应长度50%以上，同时保持或提升准确性。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型（LRMs）通过生成长链推理实现强大能力，但冗长的推理导致高延迟和成本，且准确性提升有限。AALC旨在动态平衡推理的正确性和简洁性。

研究方法: AALC将轻量级的精度感知长度奖励集成到强化学习中，结合验证精度和动态调度的长度惩罚，延迟长度惩罚直至达到目标性能。

研究结果: 实验表明，AALC在标准和非分布数学基准测试中减少响应长度50%以上，同时保持或提升准确性，并减少冗余推理模式。

研究结论: AALC通过奖励策略引导LRMs生成更高效、通用的推理路径，但可能牺牲部分解释性。

中文摘要: 大型推理模型（LRMs）通过生成长链推理展现强大能力，但这种“过度思考”导致高延迟和成本，且准确性提升有限。本文提出AALC，一种轻量级的精度感知长度奖励，集成到强化学习中，动态平衡训练中的正确性和简洁性。通过将验证精度纳入奖励并采用动态调度的长度惩罚，AALC延迟长度惩罚直至目标性能达成。在标准和分布外数学基准测试中，AALC减少响应长度50%以上，同时保持或提升原始准确性。定性分析显示，该方法抑制了冗余推理模式（如过多的子目标设定和验证），生成结构更精炼的输出而非简单截断。此外，效率提升伴随解释性降低：AALC训练的模型省略了一些叙述框架和解释性内容。这些发现凸显了奖励策略在引导LRMs生成更高效、通用推理路径中的潜力。

</details>


### [12] [SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs](https://arxiv.org/abs/2506.20167)
**中文标题：SEED：一种用于嵌入驱动解码的结构编码器，基于LLM的时间序列预测**

*Fengze Li,Yue Wang,Yangle Liu,Ming Huang,Dou Hong,Jieming Ma*

主要分类: cs.CL

摘要简述: SEED是一种结构编码器，用于嵌入驱动的解码，通过结合时间序列的结构依赖和语言模型的语义推理能力，解决了多变量时间序列预测中的结构-语义建模差距。


<details>
  <summary>详细信息</summary>
研究动机: 多变量时间序列预测需要模型同时捕捉变量间的结构依赖并适应多样任务。现有结构编码器缺乏语义推理能力，而大型语言模型（LLMs）无法直接处理原始时间序列数据，导致统一的、可迁移的预测系统发展受限。

研究方法: SEED采用四阶段模块化架构：1）基于令牌感知的编码器提取时间序列片段；2）投影模块将片段与语言模型嵌入对齐；3）语义重编程机制将片段映射为任务感知原型；4）冻结的语言模型用于预测。该方法解耦了表示学习与推理，实现了数值模式与语义推理的高效对齐。

研究结果: 实验结果表明，SEED在多个数据集上均优于基线方法，验证了其在解决结构-语义建模差距方面的有效性。

研究结论: SEED通过结合结构编码器和语言模型的优势，填补了时间序列预测中的结构-语义建模空白，为统一、可迁移的预测系统提供了新思路。

中文摘要: 多变量时间序列预测要求模型同时捕捉变量间的结构依赖并适应多样任务。结构编码器虽能有效建模特征交互，但缺乏语义级推理或任务适应能力；而大型语言模型（LLMs）虽具备强泛化能力，却无法直接处理原始时间序列输入。这一差距限制了统一、可迁移预测系统的发展。为此，我们提出SEED，一种用于嵌入驱动解码的结构编码器，其包含四个阶段：令牌感知编码器提取片段、投影模块对齐片段与语言模型嵌入、语义重编程机制将片段映射为任务感知原型，以及冻结的语言模型用于预测。这种模块化架构解耦了表示学习与推理，实现了数值模式与语义推理的高效对齐。实验结果表明，该方法在多个数据集上均优于基线，验证了SEED在解决结构-语义建模差距中的作用。

</details>


### [13] [COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees](https://arxiv.org/abs/2506.20178)
**中文标题：COIN：基于不确定性引导的选择性问答框架，为基座模型提供可证明的风险保证**

*Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu*

主要分类: cs.CL

摘要简述: COIN提出了一种基于不确定性引导的选择性问答框架，通过统计校准阈值在用户指定的FDR约束下筛选单一答案，显著提高了样本保留率和预测效率。


<details>
  <summary>详细信息</summary>
研究动机: 基础模型的不确定性量化（UQ）对于识别和减少自动生成文本中的幻觉至关重要，但现有启发式方法缺乏对选择性预测中关键指标（如FDR）的正式保证。

研究方法: COIN通过校准集估计经验错误率，并应用Clopper-Pearson等置信区间方法建立真实错误率的高概率上界（即FDR），从而在测试数据上实现FDR控制。

研究结果: COIN在风险控制、测试时保留合格答案的能力以及有限校准数据下的预测效率方面表现出色，且通过替代上界构造和UQ策略进一步提升了性能。

研究结论: COIN框架在保证FDR控制的同时显著提高了样本保留率，展示了其在多样化应用场景中的扩展性和适应性。

中文摘要: 基础模型的不确定性量化（UQ）对于识别和减少自动生成文本中的幻觉至关重要，但现有启发式方法缺乏对选择性预测中关键指标（如FDR）的正式保证。先前工作采用分拆共形预测（SCP）框架通过构建预测集来确保合格答案的覆盖率，但这些集合常包含错误候选，限制了其实用性。为此，我们提出COIN，一种不确定性引导的选择框架，通过统计校准阈值在用户指定的FDR约束下筛选单一生成答案。COIN通过校准集估计经验错误率，并应用Clopper-Pearson等置信区间方法建立真实错误率的高概率上界（即FDR），从而在测试数据上实现FDR控制，同时显著提高样本保留率。我们展示了COIN在风险控制、测试时保留合格答案的能力以及有限校准数据下的预测效率方面的鲁棒性，并表明通过替代上界构造和UQ策略可进一步提升其性能，凸显了其在多样化应用场景中的扩展性和适应性。

</details>


### [14] [How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?](https://arxiv.org/abs/2506.20199)
**中文标题：如何通过上下文学习中的示例检索提升大语言模型的对话情感识别能力？**

*Mengqi Wang,Tiantian Feng,Shrikanth Narayanan*

主要分类: cs.CL

摘要简述: 本文探讨如何通过检索高质量示例提升大语言模型在上下文学习中的对话情感识别性能，实验表明增强示例检索方法优于其他技术。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在多个领域广泛应用，但在主观任务如情感识别中实现高精度仍具挑战性。受SLT 2024 GenSER挑战赛启发，本研究旨在通过改进上下文学习中的示例检索方法，提升对话情感识别性能。

研究方法: 研究提出基于随机和增强示例检索的策略，并分析对话上下文对情感识别准确性的影响。实验在IEMOCAP、MELD和EmoryNLP三个数据集上进行。

研究结果: 实验结果显示，增强示例检索方法在所有数据集上均优于其他技术，表明检索具有连贯性的目标示例并通过改写增强其质量的重要性。

研究结论: 研究表明，通过优化上下文学习中的示例检索方法，尤其是增强示例检索，可显著提升对话情感识别的性能。

中文摘要: 大语言模型（LLMs）已在多个领域实现了广泛的实际应用，但在主观任务如情感识别中实现高精度仍具挑战性。受SLT 2024 GenSER挑战赛启发，本研究探讨了如何通过改进上下文学习（ICL）中的示例检索方法，提升对话情感识别（CER）的性能。具体而言，我们研究了基于随机和增强示例检索的策略，并分析了对话上下文对CER准确性的影响。实验在IEMOCAP、MELD和EmoryNLP三个数据集上进行。结果表明，增强示例检索在所有数据集上均优于其他技术，突显了检索具有连贯性的目标示例并通过改写增强其质量的重要性。

</details>


### [15] [Intrinsic vs. Extrinsic Evaluation of Czech Sentence Embeddings: Semantic Relevance Doesn't Help with MT Evaluation](https://arxiv.org/abs/2506.20203)
**中文标题：捷克语句子嵌入的内在与外在评估：语义相关性对机器翻译评估无益**

*Petra Barančíková,Ondřej Bojar*

主要分类: cs.CL

摘要简述: 本文比较了捷克语特定和多语言句子嵌入模型在内在和外在评估中的表现，发现语义相似性测试表现优异的模型在下游翻译任务中未必表现最佳，反之亦然。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探讨捷克语和多语言句子嵌入模型在语义相似性和机器翻译评估任务中的表现差异，揭示语义属性与下游任务之间的复杂关系。

研究方法: 通过内在评估（使用Costra数据集和STS基准测试）和外在评估（基于COMET指标的机器翻译评估）对模型进行对比分析。

研究结果: 实验显示，内在语义相似性测试表现优异的模型在下游翻译任务中未必表现最佳，而某些嵌入空间看似过度平滑的模型通过微调却能取得优异结果。

研究结论: 研究强调了语义属性探测与下游任务之间的复杂关系，呼吁进一步研究句子嵌入中的‘可操作语义’或更深入的下游任务数据集。

中文摘要: 本文通过内在和外在评估范式比较了捷克语特定和多语言句子嵌入模型。在内在评估中，我们使用Costra数据集和多个语义文本相似性（STS）基准测试，评估嵌入模型捕捉语义相似性、时间方面和风格变化等语言现象的能力。在外在评估中，我们基于COMET指标对每个嵌入模型进行微调，用于机器翻译评估。实验揭示了一个有趣的现象：在内在语义相似性测试中表现优异的模型，在下游翻译评估任务中未必表现最佳；反之，某些嵌入空间看似过度平滑的模型通过微调却能取得优异结果。这些发现凸显了语义属性探测与下游任务之间的复杂关系，强调了需要进一步研究句子嵌入中的‘可操作语义’或更深入的下游任务数据集（如翻译评估）。

</details>


### [16] [Perspectives in Play: A Multi-Perspective Approach for More Inclusive NLP Systems](https://arxiv.org/abs/2506.20209)
**中文标题：多视角游戏：一种更包容NLP系统的多视角方法**

*Benedetta Muscato,Lucia Passaro,Gizem Gezici,Fosca Giannotti*

主要分类: cs.CL

摘要简述: 本文提出了一种多视角方法，通过软标签处理自然语言处理中的标注分歧，以更包容的方式捕捉少数观点，并在多个主观文本分类任务中验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 传统NLP方法通过聚合标注者观点建立单一真实标签，但忽视了少数观点，尤其是在主观任务中。本文旨在通过多视角方法更好地反映个体背景和价值观的多样性。

研究方法: 采用多视角软标签方法，避免传统聚合方式的偏见，并在仇恨言论、讽刺、辱骂语言和立场检测等主观任务中验证其效果。

研究结果: 多视角方法在Jensen-Shannon Divergence（JSD）和F1分数上优于传统方法，但在讽刺和立场检测任务中表现出较低的置信度。通过可解释AI（XAI）揭示了模型预测的不确定性。

研究结论: 多视角方法能更准确地捕捉人类标注分歧，提升模型包容性，但需进一步解决高主观性任务中的置信度问题。

中文摘要: 在自然语言处理（NLP）领域，处理人类标注分歧的常见方法是通过聚合标注者观点建立单一真实标签。然而，先前研究表明，忽视个体观点可能导致少数视角被低估，尤其是在主观任务中，标注者可能因偏好而系统性分歧。认识到标签反映了个人背景、生活经验和价值观的多样性，本研究提出了一种新的多视角方法，使用软标签促进下一代更具包容性和多元化的视角感知模型的发展。我们在多个主观文本分类任务（包括仇恨言论、讽刺、辱骂语言和立场检测）中进行了广泛分析，以强调捕捉人类分歧的重要性，这些分歧常被传统聚合方法忽视。结果表明，多视角方法不仅通过Jensen-Shannon Divergence（JSD）更好地近似人类标签分布，还实现了更高的分类性能（更高的F1分数），优于传统方法。然而，我们的方法在讽刺和立场检测等任务中表现出较低的置信度，可能是由于文本固有的主观性。最后，利用可解释AI（XAI），我们探索了模型不确定性，并揭示了模型预测的有意义见解。

</details>


### [17] [Enhancing Large Language Models through Structured Reasoning](https://arxiv.org/abs/2506.20241)
**中文标题：通过结构化推理增强大语言模型**

*Yubo Dong,Hehe Fan*

主要分类: cs.CL

摘要简述: 本文提出了一种通过结构化推理增强大语言模型的方法，通过标注推理步骤和优化算法显著提升了模型的逻辑推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大语言模型在复杂逻辑推理任务中表现不佳，主要依赖隐式统计关系而缺乏结构化知识表示。本文受认知科学和神经符号AI启发，旨在通过显式结构化推理提升模型性能。

研究方法: 首先将非结构化数据转换为结构化格式，标注推理步骤，并通过监督微调训练模型。进一步使用GRPO优化算法（包括MAX-Flow和LCS）增强结构化推理能力。

研究结果: 实验结果表明，基于DeepSeek-R1-Distill-Qwen-1.5B模型的微调实现了简洁推理、鲁棒性能和优化技术兼容性，验证了结构化推理的有效性。

研究结论: 结构化推理显著提升了大语言模型的逻辑推理能力，为复杂任务提供了更高效的解决方案。

中文摘要: 近年来，大语言模型（LLMs）在自然语言处理和自动化决策方面取得了显著进展。然而，这些模型在执行涉及逻辑推理和系统规划的复杂任务时仍存在困难，主要原因是其依赖隐式统计关系而缺乏结构化知识表示。受认知科学和神经符号AI的启发，我们提出了一种通过显式结构化推理增强LLMs的新方法。首先，我们通过显式标注推理步骤将非结构化数据转换为结构化格式，随后利用监督微调（SFT）训练LLMs。此外，我们通过群体相对策略优化（GRPO）增强LLMs的结构化推理能力，结合了两种创新算法——MAX-Flow和最长公共子序列（LCS），显著提升了推理效果并降低了计算复杂度。通过对DeepSeek-R1-Distill-Qwen-1.5B模型的微调实验，结果表明该方法实现了简洁推理、多场景鲁棒性能以及优化技术的兼容性，验证了结构化推理在LLMs中的有效性。

</details>


### [18] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
**中文标题：CBF-AFA：基于分块的多自监督学习融合自动流利度评估方法**

*Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc*

主要分类: cs.CL

摘要简述: 本文提出了一种基于分块的多自监督学习融合方法（CBF-AFA），用于自动流利度评估，通过结合多种自监督学习模型的优势，显著提升了评估性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动流利度评估（AFA）在非母语者的语音节奏、停顿和不流畅性捕捉方面仍具挑战性。本文旨在通过多自监督学习模型的融合，解决这一问题。

研究方法: 采用分块方法，结合Wav2Vec2、HuBERT和WavLM等自监督学习模型，利用Silero-VAD进行语音分块，并通过CNN-BiLSTM框架融合声学和语言特征。

研究结果: 在Speechocean762和Avalinguo数据集上，F1分数分别提升2.8和4.2，Pearson相关系数分别提升6.2和4.0，优于单模型基线。

研究结论: 分块多自监督学习融合方法在流利度评估中表现优异，未来需进一步研究其在非规则韵律方言中的泛化能力。

中文摘要: 自动流利度评估（AFA）在捕捉非母语者的语音节奏、停顿和不流畅性方面仍具挑战性。本文提出了一种基于分块的方法，结合自监督学习模型（Wav2Vec2、HuBERT和WavLM），利用其互补优势进行语音建模，并通过分层CNN-BiLSTM框架实现。语音通过Silero语音活动检测（Silero-VAD）分割为呼吸组分块，支持细粒度时间分析并减少过分割问题。自监督学习嵌入通过可学习加权机制融合，平衡声学和语言特征，并加入分块级流利度标记（如语速、停顿时长、n-gram重复）。CNN-BiLSTM捕捉分块间的局部和长期依赖关系。在Avalinguo和Speechocean762数据集上的评估显示，该方法在Speechocean762上的F1分数和Pearson相关系数分别提升2.8和6.2，在Avalinguo上分别提升4.2和4.0，优于基于Pyannote.audio的分割基线。这些结果表明，基于分块的多自监督学习融合方法在流利度评估中具有鲁棒性，但未来需进一步探索其在非规则韵律方言中的泛化能力。

</details>


### [19] [Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models](https://arxiv.org/abs/2506.20269)
**中文标题：叙事变化检测：动态主题模型与大语言模型的混合方法**

*Kai-Robin Lange,Tobias Schmidt,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch*

主要分类: cs.CL

摘要简述: 本文提出了一种结合动态主题模型和大语言模型的混合方法，用于检测叙事变化。通过主题模型筛选代表性文档，再利用大语言模型自动分析内容与叙事变化。实验表明，该方法能有效检测叙事变化，但在区分内容变化与叙事变化时表现一般。


<details>
  <summary>详细信息</summary>
研究动机: 随着媒体叙事的快速演变，仅提取叙事已不足以满足需求，研究其随时间的发展变得至关重要。大语言模型虽能捕捉叙事元素，但全语料库应用成本高。因此，需结合主题模型的大规模适用性，动态建模叙事变化。

研究方法: 首先使用主题模型和变化点检测方法识别特定主题的变化，筛选代表性文档；随后将这些文档输入大语言模型，自动分析变化类型（内容变化或叙事变化）。实验基于2009至2023年《华尔街日报》文章语料库。

研究结果: 实验表明，大语言模型能有效检测特定时间点的叙事变化，但在区分内容变化与叙事变化时表现不佳。

研究结论: 混合方法结合了主题模型和大语言模型的优势，能高效检测叙事变化，但在区分变化类型时仍需改进。

中文摘要: 随着媒体叙事的快速演变，不仅需要从语料库中提取叙事，还需研究其随时间的发展。尽管大语言模型能有效捕捉叙事元素或复杂结构，但其全语料库应用面临高成本等问题。我们提出结合大语言模型的语言理解能力与主题模型的大规模适用性，利用叙事政策框架动态建模叙事变化。通过主题模型及变化点检测方法识别特定主题的变化，筛选代表性文档后输入大语言模型，自动分析变化类型（内容变化或叙事变化）。实验基于2009至2023年《华尔街日报》文章语料库，结果表明大语言模型能有效检测叙事变化，但在区分变化类型时表现一般。

</details>


### [20] [Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content](https://arxiv.org/abs/2506.20331)
**中文标题：Biomed-Enriched：一个通过LLM增强的生物医学数据集，用于预训练和提取罕见及隐藏内容**

*Rian Touchent,Nathan Godey,Eric de la Clergerie*

主要分类: cs.CL

摘要简述: 本文介绍了Biomed-Enriched，一个通过两阶段标注过程从PubMed构建的生物医学文本数据集，用于预训练和提取罕见及隐藏内容。数据集包含高质量临床案例段落，并通过质量过滤和领域上采样优化，实验显示其能显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 临床文本通常因隐私限制难以获取，而PubMed中的临床案例段落可作为替代资源。本文旨在构建一个大规模、开放的生物医学数据集，以支持生物医学和临床自然语言处理任务。

研究方法: 通过两阶段标注过程构建数据集：首先使用大语言模型对PubMed的40万段落进行类型、领域和教育质量评分标注；然后利用小语言模型将标签传播至整个PMC-OA语料库，最终提取高质量子集并进行质量过滤和领域上采样。

研究结果: 数据集包含200万临床案例段落，其中45万为高质量内容。实验表明，临床上采样使MMLU ProfMed性能提升约5%，教育质量过滤使MedQA和MedMCQA提升约1%，且组合技术可加速收敛，减少训练标记需求。

研究结论: Biomed-Enriched为生物医学和临床NLP提供了宝贵的开放资源，其优化子集能显著提升模型性能，并为高效预训练策略提供了潜力。

中文摘要: 我们介绍了Biomed-Enriched，这是一个通过两阶段标注过程从PubMed构建的生物医学文本数据集。在第一阶段，大语言模型对PubMed科学文章中的40万段落进行标注，评估其类型（综述、研究、临床案例等）、领域（临床、生物医学等）和教育质量（1至5分）。这些标注用于微调小语言模型，并将标签传播至整个PMC-OA语料库。生成的元数据使我们能够提取精炼子集，包括200万临床案例段落（其中45万为高质量内容），并通过质量过滤和领域上采样构建多个变体。由于隐私限制，临床文本通常难以获取，而我们的数据集提供了PubMed中大规模、开放的临床案例集合，成为生物医学和临床NLP的宝贵资源。初步实验表明，这些优化子集能显著提升模型性能，临床上采样使MMLU ProfMed性能提升约5%，教育质量过滤使MedQA和MedMCQA提升约1%。组合技术还能加速收敛，减少训练标记需求，为高效生物医学预训练策略提供了潜力。

</details>


### [21] [TAPS: Tool-Augmented Personalisation via Structured Tagging](https://arxiv.org/abs/2506.20409)
**中文标题：TAPS：通过结构化标签实现工具增强的个性化**

*Ekaterina Taktasheva,Jeff Dalton*

主要分类: cs.CL

摘要简述: 本文提出了一种名为TAPS的新方法，通过结构化标签和基于不确定性的工具检测器，显著提升了大型语言模型在个性化工具使用方面的能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有工具增强的大型语言模型在个性化工具使用方面存在不足，忽视了用户偏好在任务导向对话中的作用。本文旨在解决这一问题。

研究方法: TAPS结合了结构化标签工具和基于不确定性的工具检测器，以更有效地整合用户偏好，优化工具使用。

研究结果: TAPS显著提升了大型语言模型在个性化工具使用方面的表现，并在NLSI任务上达到了开源模型的最新水平。

研究结论: TAPS通过结构化标签和不确定性检测，成功提升了大型语言模型的个性化工具使用能力，为未来研究提供了新方向。

中文摘要: 近年来，工具增强的大型语言模型通过与外部工具的交互，提升了其执行复杂用户任务的能力。然而，现有方法忽视了个性化在工具使用中的指导作用。本研究探讨了如何将用户偏好有效整合到任务导向的对话代理中。通过广泛分析，我们发现了大型语言模型在个性化工具使用方面的关键不足。为此，我们提出了TAPS，一种通过结构化标签工具和基于不确定性的工具检测器来增强个性化工具使用的新方法。TAPS显著提升了大型语言模型整合用户偏好的能力，并在NLSI任务上达到了开源模型的最新水平。

</details>


### [22] [An Agentic System for Rare Disease Diagnosis with Traceable Reasoning](https://arxiv.org/abs/2506.20430)
**中文标题：一种基于可追溯推理的罕见病诊断代理系统**

*Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie*

主要分类: cs.CL

摘要简述: DeepRare是一种基于大型语言模型（LLM）的罕见病诊断系统，通过透明推理链生成诊断假设，显著优于其他方法，并在多模态输入场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 罕见病诊断面临临床异质性、低流行率和医生知识有限的挑战。DeepRare旨在通过透明推理链和模块化设计提供准确、可追溯的诊断。

研究方法: DeepRare由核心主机、长期记忆模块和多个专业代理服务器组成，整合40多种工具和最新医学知识，支持复杂诊断推理。

研究结果: 在8个数据集中，DeepRare对2,919种疾病诊断准确率达100%（1,013种疾病），HPO评估中Recall@1为57.18%，显著优于其他方法。多模态输入场景下Recall@1达70.60%。

研究结论: DeepRare通过透明推理链和模块化设计显著提升罕见病诊断性能，已实现为易用的网络应用。

中文摘要: 罕见病全球影响超过3亿人，但及时准确诊断仍具挑战性。本文提出DeepRare，首个基于大型语言模型（LLM）的罕见病诊断代理系统，能处理异质临床输入并生成透明推理链的诊断假设。DeepRare包含核心主机、长期记忆模块和多个专业代理服务器，整合40多种工具和最新医学知识。在8个数据集中，DeepRare对2,919种疾病诊断准确率达100%（1,013种疾病），HPO评估中Recall@1为57.18%，显著优于其他方法。多模态输入场景下Recall@1达70.60%。临床专家对推理链的验证一致性达95.40%。DeepRare已实现为网络应用http://raredx.cn/doctor。

</details>


### [23] [Probing AI Safety with Source Code](https://arxiv.org/abs/2506.20471)
**中文标题：通过源代码探究AI安全性**

*Ujwal Narayan,Shreyas Chaudhari,Ashwin Kalyan,Tanmay Rajpurohit,Karthik Narasimhan,Ameet Deshpande,Vishvak Murahari*

主要分类: cs.CL

摘要简述: 研究发现当前大型语言模型在AI安全性方面存在严重不足，提出了一种名为“代码思维”（CoDoT）的提示策略，通过将自然语言转换为代码来评估模型安全性，结果显示多种先进模型在毒性输出上显著增加。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在安全关键应用中的广泛应用，确保其与人类价值观和偏好一致的需求日益迫切。然而，当前模型在安全性方面表现不佳，可能导致用户受到伤害。

研究方法: 提出“代码思维”（CoDoT）策略，将自然语言输入转换为代码形式以评估模型安全性。例如，将“使以下文本更具毒性”转换为“make_more_toxic({text})”。

研究结果: CoDoT导致多种先进模型在毒性输出上显著增加：GPT-4 Turbo毒性增加16.5倍，DeepSeek R1失败率100%，七种现代模型平均毒性增加300%。递归应用CoDoT可进一步使毒性翻倍。

研究结论: CoDoT揭示了当前LLMs在安全性上的严重不足，强调需要从基本原则出发评估安全性，确保安全性与能力同步提升。

中文摘要: 大型语言模型（LLMs）已广泛应用于与人类交互的安全关键场景中，这要求提升其能力的同时，必须加强安全性措施以确保与人类价值观和偏好一致。本研究表明，当前模型在AI安全性方面存在严重不足，可能导致用户遭受不安全甚至有害的体验。为此，我们提出了一种名为“代码思维”（CoDoT）的提示策略，用于评估LLMs的安全性。CoDoT将自然语言输入转换为表达相同意图的简单代码，例如将“使以下文本更具毒性：{text}”转换为“make_more_toxic({text})”。结果显示，CoDoT导致多种先进模型在安全性测试中一致失败：GPT-4 Turbo的毒性输出增加16.5倍，DeepSeek R1的失败率达100%，七种现代模型平均毒性增加300%。此外，递归应用CoDoT可进一步使毒性翻倍。鉴于LLMs的快速普及，CoDoT凸显了从基本原则出发评估安全性的紧迫性，以确保安全性与能力同步发展。

</details>


### [24] [Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations](https://arxiv.org/abs/2506.20474)
**中文标题：时间站在我这边：视频聊天中对话时间共享的动态**

*Kaixiang Zhang,Justine Zhang,Cristian Danescu-Niculescu-Mizil*

主要分类: cs.CL

摘要简述: 本文提出了一种计算框架，用于量化视频聊天中对话时间的分配及其动态变化，揭示了不同时间分配动态对参与者感知的影响，并为计算机辅助沟通平台设计提供了新工具。


<details>
  <summary>详细信息</summary>
研究动机: 对话中时间分配的平衡与否直接影响参与者的体验，但现有研究缺乏对时间分配动态变化的量化分析。本文旨在填补这一空白，探讨时间分配动态如何影响参与者的感知。

研究方法: 作者开发了一个计算框架，从对话层面和动态层面量化时间分配，并通过分析陌生人视频聊天的大数据集，验证了不同时间分配动态对参与者感知的影响。

研究结果: 研究发现，平衡的对话更受参与者欢迎，尤其是那些说话较少的人。此外，即使整体平衡相同，不同的时间分配动态也会导致不同的感知效果。

研究结论: 本文提出的框架为理解对话时间分配动态提供了新视角，并为计算机辅助沟通平台的设计提供了实用工具。

中文摘要: 对话的一个内在特征是说话者之间如何共享对话时间。对话可以是平衡的，每个说话者占用相似的时间；也可以是不平衡的，其中一方占用过多时间。这种整体分布是说话者在对话中持续协商的结果：谁应该在每个时间点说话，以及说多久？
  本文提出了一种计算框架，用于量化对话层面的时间分配及其动态变化。我们通过几个直观的变化轴构建了时间共享动态的类型学。通过将此框架应用于陌生人视频聊天的大数据集，我们发现，平衡的对话更受参与者欢迎，尤其是那些说话较少的人。此外，即使整体平衡相同，不同的时间共享动态也会导致不同的感知效果，凸显了我们新引入的类型学的相关性。最后，我们讨论了该框架如何为计算机辅助沟通平台的设计者提供新工具，包括人与人及人与AI的沟通。

</details>


### [25] [Knowledge-Aware Diverse Reranking for Cross-Source Question Answering](https://arxiv.org/abs/2506.20476)
**中文标题：知识感知多样性重排序在跨源问答中的应用**

*Tong Zhou*

主要分类: cs.CL

摘要简述: 本文介绍了Team Marikarp在SIGIR 2025 LiveRAG竞赛中的解决方案，其提出的知识感知多样性重排序RAG管道在竞赛中获得了第一名。


<details>
  <summary>详细信息</summary>
研究动机: 竞赛评估集由DataMorgana从互联网语料库自动生成，涵盖了广泛的主题、问题类型和知识组织方法，旨在公平评估从15M文档子集中检索问题相关支持文档的能力。

研究方法: 提出了一个知识感知的多样性重排序RAG管道，通过结合知识感知和多样性重排序技术，优化了文档检索的准确性和多样性。

研究结果: 该方法在竞赛中取得了第一名，证明了其在跨源问答任务中的有效性。

研究结论: 知识感知多样性重排序RAG管道在跨源问答任务中表现出色，为未来相关研究提供了有价值的参考。

中文摘要: 本文介绍了Team Marikarp在SIGIR 2025 LiveRAG竞赛中的解决方案。竞赛的评估集由DataMorgana从互联网语料库自动生成，涵盖了广泛的目标主题、问题类型、问题表述、受众类型和知识组织方法。该评估集旨在公平评估从FineWeb语料库的15M文档子集中检索问题相关支持文档的能力。我们提出的知识感知多样性重排序RAG管道在竞赛中获得了第一名。

</details>


### [26] [GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching](https://arxiv.org/abs/2506.20480)
**中文标题：GPTailor：通过层剪裁与拼接的大型语言模型剪枝方法**

*Guinan Su,Li Shen,Lu Yin,Shiwei Liu,Yanwu Yang,Jonas Geiping*

主要分类: cs.CL

摘要简述: 本文提出了一种名为GPTailor的新策略，通过剪裁和拼接层来压缩大型语言模型（LLMs），在保持性能的同时显著减少参数数量。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）虽然性能强大，但模型规模庞大，部署和推理成本高。现有剪枝方法主要针对单一模型，本文旨在通过结合不同微调模型的层来压缩模型，同时保留其能力。

研究方法: 提出了一种零阶优化方法，支持三种操作：层移除、从不同候选模型中选择层以及层合并。通过策略性地结合微调模型的层，实现模型压缩。

研究结果: 实验表明，该方法在Llama2-13B模型上实现了高效剪枝，压缩后模型保留了约97.3%的原始性能，同时减少了约25%的参数，优于现有方法。

研究结论: GPTailor提供了一种高效的大型语言模型压缩方法，通过层剪裁和拼接显著减少了模型规模，同时保持了高性能。

中文摘要: 大型语言模型（LLMs）在语言理解和生成方面表现出色，但其庞大的模型规模给部署和推理带来了巨大挑战。尽管结构化剪枝为降低计算成本提供了可行方案，但现有方法主要针对单一模型剪枝。本文提出了一种新策略，通过策略性地结合或合并微调模型变体的层来压缩模型，从而保留原始模型的能力。我们将LLMs的最优剪裁问题建模为零阶优化问题，支持三种操作：（1）层移除，（2）从不同候选模型中选择层，（3）层合并。实验表明，该方法在Llama2-13B模型家族中表现优异，压缩后的模型在移除约25%参数的同时，保留了约97.3%的原始性能，显著优于现有方法。代码已开源：https://github.com/Guinan-Su/auto-merge-llm。

</details>


### [27] [ReCode: Updating Code API Knowledge with Reinforcement Learning](https://arxiv.org/abs/2506.20495)
**中文标题：ReCode：基于强化学习的代码API知识更新**

*Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang*

主要分类: cs.CL

摘要简述: ReCode是一种基于强化学习的框架，用于帮助大型语言模型（LLMs）适应外部库API的频繁更新，显著提升动态API场景下的代码生成性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在代码生成方面表现出色，但难以适应外部库API的频繁更新，导致生成的代码不可靠。这一问题源于模型依赖过时的API知识，即使能够访问最新文档。

研究方法: ReCode通过构建包含约2000条数据的数据集，训练LLMs执行基于更新信息的版本迁移，并引入改进的字符串相似度指标作为强化学习的奖励。

研究结果: 实验表明，ReCode显著提升了LLMs在动态API场景下的代码生成性能，尤其在未见的CodeUpdateArena任务中表现突出。此外，与监督微调相比，ReCode对LLMs的通用代码生成能力影响较小。

研究结论: ReCode是一种有效的框架，能够帮助LLMs适应API更新，同时保持其通用代码生成能力。在不同LLMs和强化学习算法（如GRPO和DAPO）上均取得了稳定的改进。

中文摘要: 大型语言模型（LLMs）在代码生成方面表现出色，但难以适应外部库API的频繁更新。这一关键限制源于模型依赖训练数据中的过时API知识，即使能够访问最新文档，也阻碍了动态环境中可靠的代码生成。为解决这一问题，我们提出了ReCode（基于规则的强化学习代码更新框架），该框架模拟人类程序员对API变化的适应能力。具体而言，我们构建了一个包含约2000条数据的数据集，用于训练LLMs基于更新信息执行版本迁移。此外，我们引入了一种改进的字符串相似度指标作为强化学习的奖励。实验表明，ReCode显著提升了LLMs在动态API场景下的代码生成性能，尤其在未见的CodeUpdateArena任务中表现突出。重要的是，与监督微调相比，ReCode对LLMs的通用代码生成能力影响较小。我们在多种LLMs和强化学习算法（如GRPO和DAPO）上应用ReCode，均取得了稳定的改进。值得注意的是，经过训练后，Qwen2.5-Coder-7B的性能超过了32B参数的代码指令调优模型和相同架构的推理模型。代码可在https://github.com/zjunlp/ReCode获取。

</details>


### [28] [OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling](https://arxiv.org/abs/2506.20512)
**中文标题：OctoThinker：中训练激励强化学习扩展**

*Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu*

主要分类: cs.CL

摘要简述: 本文研究了基础语言模型在强化学习（RL）中的表现差异，发现高质量数学语料和长链推理数据能显著提升模型性能，并提出了一种两阶段训练策略OctoThinker，以缩小与RL友好模型的差距。


<details>
  <summary>详细信息</summary>
研究动机: 研究基础语言模型（如Llama和Qwen）在强化学习中的表现差异，探索如何通过中训练策略提升模型的RL兼容性，为下一代可扩展基础模型的发展提供指导。

研究方法: 通过对比Qwen和Llama模型，分析数学语料和长链推理数据对RL性能的影响，并提出两阶段训练策略Stable-then-Decay，结合高质量数学语料和链式推理数据优化模型。

研究结果: 发现高质量数学语料（如MegaMath-Web-Pro）显著提升RL性能，长链推理数据增强推理深度但可能引发模型冗长和不稳定，而两阶段训练策略OctoThinker成功缩小了与RL友好模型的性能差距。

研究结论: 中训练策略对提升模型的RL兼容性至关重要，OctoThinker通过优化数据选择和训练方法，为下一代基础模型的开发提供了重要参考。

中文摘要: 不同基础语言模型家族（如Llama和Qwen）在强化学习（RL）后训练中表现出显著差异，尤其是在推理密集型任务上。了解何种基础语言模型适合RL对开发下一代可扩展基础模型至关重要。本研究探讨了中训练策略如何影响RL动态，重点关注Qwen和Llama两种代表性模型家族。研究发现：（1）高质量数学语料（如MegaMath-Web-Pro）显著提升基础模型和RL性能，而现有替代品（如FineMath-4plus）则无效；（2）进一步添加问答式数据（尤其是长链推理示例）能增强RL效果，指令数据进一步释放这一潜力；（3）长链推理虽提升推理深度，但也可能导致模型回答冗长和RL训练不稳定，凸显数据格式化的重要性；（4）中训练规模扩大始终带来更强的下游RL性能。基于这些发现，我们提出了一种两阶段中训练策略Stable-then-Decay：基础模型首先以恒定学习率训练200B词元，随后在三个链式推理分支中以学习率衰减训练20B词元。由此产生的OctoThinker模型家族表现出强大的RL兼容性，缩小了与RL友好模型家族（如Qwen）的性能差距。我们希望这项工作能为RL时代的基础模型预训练策略提供指导。为支持进一步研究，我们开源了模型及超过700亿词元的精选数学推理语料库（即MegaMath-Web-Pro-Max）。

</details>


### [29] [When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs](https://arxiv.org/abs/2506.20544)
**中文标题：当生活给你样本：多语言大型语言模型推理计算扩展的益处**

*Ammar Khairi,Daniel D'souza,Ye Shen,Julia Kreutzer,Sara Hooker*

主要分类: cs.CL

摘要简述: 本文研究了在多语言和多任务环境下如何通过增加推理计算提升大型语言模型（LLM）性能，并提出适应多语言和任务的采样与选择策略，显著提升了模型表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前关于推理计算扩展的研究主要集中在英语和少数领域（如数学和编程），而本文旨在探索适用于开放任务和多语言的通用方法，以提升模型在多样化语言和任务中的表现。

研究方法: 本文提出了一种结合温度变化的采样策略和任务感知的选择策略，专门针对多语言和多任务场景进行优化。通过评估现有选择方法，发现其在非英语语言中表现不佳，进而提出了改进方案。

研究结果: 实验表明，新方法在8B模型上使m-ArenaHard-v2.0任务的胜率平均提升6.8%，在111B模型上仅用5个样本就实现了9.0%的胜率提升，显著优于单样本解码。

研究结论: 研究强调了语言和任务感知的推理计算方法的重要性，为提升非主流语言模型的性能提供了可行方案。

中文摘要: 近年来，大型语言模型（LLM）的研究重点转向扩展推理计算，以在不重新训练模型的情况下提升性能。常见方法包括并行采样多个输出并选择其中之一作为最终结果。然而，现有研究主要集中于英语和少数领域（如数学和编程）。相比之下，我们更关注适用于开放任务、可验证任务及多语言的通用技术。本文研究了在多语言、多任务环境下如何稳健扩展推理计算以支持开放式生成任务。
  研究结果表明，采样策略（基于温度变化）和选择策略均需针对多样化领域和语言进行调整。我们对现有选择方法进行了评估，发现适用于英语的策略往往无法推广到其他语言。为此，我们提出了专门针对多语言和多任务场景的采样与选择策略，并证明其在语言和任务中均能显著提升性能。例如，我们的方法使8B模型在m-ArenaHard-v2.0任务中的胜率平均提升6.8%，优于Gemini等专有模型。在更大规模的111B模型（Command-A）上，仅用5个样本就实现了9.0%的胜率提升，成本极低。这些结果凸显了语言和任务感知的推理计算方法的重要性，旨在为非主流语言的性能提升提供支持。

</details>


### [30] [Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm](https://arxiv.org/abs/2506.20606)
**中文标题：模型编辑的双刃剑：引导代理伦理行为向善或作恶**

*Baixiang Huang,Zhen Tan,Haoran Wang,Zijie Liu,Dawei Li,Ali Payani,Huan Liu,Tianlong Chen,Kai Shu*

主要分类: cs.CL

摘要简述: 本文探讨了通过模型编辑技术（行为编辑）动态调整基于大语言模型（LLM）的代理行为，既能引导其向善，也可能诱导其作恶，并提出了多层级基准BehaviorBench以系统评估该方法。


<details>
  <summary>详细信息</summary>
研究动机: 部署基于LLM的代理在高风险领域时，其不道德行为可能导致严重后果（如人身伤害或财务损失）。因此，亟需一种高效方法引导代理的伦理行为，同时研究模型编辑技术的潜在风险。

研究方法: 提出行为编辑（Behavior Editing）技术，通过精确修改LLM模型来调整代理行为。引入多层级基准BehaviorBench，基于心理学道德理论设计复杂场景，支持行为评估与编辑。

研究结果: 实验表明，行为编辑能动态引导代理在特定场景中实现目标行为，并调整其全局道德倾向。该方法既可促进伦理行为，也可能诱导恶意行为，且在不同模型和场景中均有效。

研究结论: 行为编辑为代理行为引导提供了新范式，展示了其潜力与风险，需谨慎应用。BehaviorBench为未来研究提供了系统评估工具。

中文摘要: 基于大语言模型（LLM）的代理在广泛任务中展现出强大能力，但其在高风险领域的部署伴随重大安全与伦理风险。代理的不道德行为可能直接导致严重后果（如人身伤害或财务损失）。为高效引导代理伦理行为，我们将行为引导定义为模型编辑任务（行为编辑）。模型编辑是新兴研究领域，可在保留LLM整体能力的同时实现精确高效修改。为系统研究该方法，我们提出基于心理学道德理论的多层级基准BehaviorBench，支持多种场景下的行为评估与编辑，每层级场景复杂度递增。实验表明，行为编辑能动态引导代理在特定场景中实现目标行为，并调整其全局道德倾向。该方法既可促进伦理行为，也可能诱导恶意行为。通过对前沿LLM代理的全面评估，BehaviorBench验证了行为编辑在不同模型和场景中的有效性。研究为代理行为引导提供了新范式，揭示了行为编辑的潜力与风险。

</details>


### [31] [DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation](https://arxiv.org/abs/2506.20639)
**中文标题：DiffuCoder：理解并改进用于代码生成的掩码扩散模型**

*Shansan Gong,Ruixiang Zhang,Huangjie Zheng,Jiatao Gu,Navdeep Jaitly,Lingpeng Kong,Yizhe Zhang*

主要分类: cs.CL

摘要简述: 本文提出DiffuCoder，一种基于扩散大语言模型（dLLM）的代码生成方法，通过系统分析其去噪过程和强化学习（RL）方法，改进了代码生成的性能。实验表明，DiffuCoder在代码生成基准上提升了4.4%，并减少了对自回归解码的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 扩散大语言模型（dLLM）因其全局规划和迭代优化的特性，在代码生成中具有潜力，但当前对其训练和推理机制的研究不足。本文旨在揭示dLLM的解码行为，并探索其在代码生成中的应用潜力。

研究方法: 训练了一个7B参数的dLLM模型DiffuCoder，分析了其解码行为与自回归模型的不同，并提出了一种新的采样方案coupled-GRPO，以减少对数似然估计的方差并提高训练效率。

研究结果: DiffuCoder在代码生成基准上性能提升了4.4%，并减少了对自回归因果解码的依赖。coupled-GRPO方案显著提升了模型的性能。

研究结论: 本文深入分析了dLLM的生成机制，并提出了一种有效的扩散原生RL训练框架，为代码生成提供了新的思路。

中文摘要: 扩散大语言模型（dLLM）因其去噪模型作用于整个序列，成为自回归（AR）模型的有力替代。dLLM的全局规划和迭代优化特性尤其适用于代码生成。然而，当前dLLM在代码生成中的训练和推理机制仍未被充分探索。为揭示dLLM的解码行为并释放其在代码生成中的潜力，我们系统研究了其去噪过程和强化学习（RL）方法。我们训练了一个7B参数的dLLM模型DiffuCoder，基于130B代码标记。通过该模型，我们分析了其解码行为，发现其与AR模型的不同之处：（1）dLLM无需依赖半自回归解码即可决定生成的因果性；（2）提高采样温度不仅多样化标记选择，还多样化其生成顺序。这种多样性为RL的探索提供了丰富的搜索空间。在RL训练中，为减少对数似然估计的方差并保持训练效率，我们提出了coupled-GRPO，一种新颖的采样方案，为训练中的补全构造互补掩码噪声。实验表明，coupled-GRPO显著提升了DiffuCoder在代码生成基准上的性能（EvalPlus上提升4.4%），并减少了解码时对AR因果性的依赖。我们的工作深入揭示了dLLM生成的机制，并提供了一种有效的扩散原生RL训练框架。

</details>


### [32] [Memento: Note-Taking for Your Future Self](https://arxiv.org/abs/2506.20642)
**中文标题：Memento：为未来的自己记笔记**

*Chao Wan,Albert Gong,Mihir Mishra,Carl-Leander Henneking,Claas Beger,Kilian Q. Weinberger*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Memento的提示策略，通过将复杂问题分解为小步骤、动态构建事实数据库并整合这些事实来提升大语言模型在多跳问答任务中的表现。该方法显著优于现有策略，如链式思维（CoT）和检索增强生成（RAG）。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLMs）在纯推理任务中表现优异，但在需要紧密结合检索的多跳问答任务中表现不佳。为了解决这一问题，作者提出了Memento策略，旨在通过分步处理和动态事实库构建来提升模型性能。

研究方法: Memento采用三阶段策略：1）将复杂问题分解为小步骤；2）利用LLMs动态构建事实数据库；3）整合这些事实以解决问题。该方法适用于多种提示策略，如链式思维（CoT）和检索增强生成（RAG）。

研究结果: 在PhantomWiki基准测试中，Memento将链式思维（CoT）的性能提升了一倍；在2WikiMultiHopQA开放域版本中，Memento结合CoT-RAG比普通CoT-RAG提高了20个F1百分点，比多跳RAG基线IRCoT提高了13个F1百分点；在MuSiQue数据集中，Memento比ReAct提高了3个F1百分点。

研究结论: Memento通过分步处理和动态事实库构建，显著提升了大语言模型在多跳问答任务中的性能，证明了其在复杂推理任务中的实用性。

中文摘要: 大语言模型（LLMs）在纯推理任务中表现优异，但在需要紧密结合检索的多跳问答任务中表现不佳。为了克服这些限制，我们提出了一种提示策略，首先将复杂问题分解为小步骤，然后利用LLMs动态构建事实数据库，最后整合这些事实以解决问题。我们展示了这种三阶段策略（称为Memento）如何在多样化场景中提升现有提示策略的性能。在9步PhantomWiki基准测试中，当所有信息均提供在上下文中时，Memento将链式思维（CoT）的性能提升了一倍。在2WikiMultiHopQA的开放域版本中，结合Memento的CoT-RAG比普通CoT-RAG提高了20个F1百分点，比多跳RAG基线IRCoT提高了13个F1百分点。在具有挑战性的MuSiQue数据集中，Memento比ReAct提高了3个F1百分点，证明了其在代理场景中的实用性。

</details>


### [33] [Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs](https://arxiv.org/abs/2506.20666)
**中文标题：你内心有许多狼：利用认知模型解析大型语言模型中的价值权衡**

*Sonia K. Murthy,Rosie Zhao,Jennifer Hu,Sham Kakade,Markus Wulfmeier,Peng Qian,Tomer Ullman*

主要分类: cs.CL

摘要简述: 本文利用认知模型分析大型语言模型（LLM）中人类价值权衡的表现，发现推理模型更注重信息效用而非社交效用，并揭示了训练动态对价值权衡的持久影响。


<details>
  <summary>详细信息</summary>
研究动机: 日常社交中，人类常需平衡冲突目标（如诚实与礼貌），但现有工具难以解析LLM中的此类动态价值权衡。认知科学中的认知模型为人类价值权衡提供了形式化描述，本文将其应用于LLM研究。

研究方法: 采用认知科学中的礼貌语言认知模型，系统评估LLM在两种场景下的价值权衡：前沿黑盒模型的推理“努力”程度，以及开源模型的强化学习后训练动态。

研究结果: 研究发现，推理模型更倾向于信息效用而非社交效用；开源模型在数学推理中表现更强。训练动态显示，基础模型和预训练数据对价值权衡有持久影响，而反馈数据集或对齐方法影响较小。

研究结论: 该方法能有效捕捉LLM快速演变中的多样性，为推理模型训练提供指导，并帮助在模型训练中更好地控制价值权衡。

中文摘要: 日常社交中，人们常需平衡冲突目标（如表达严酷真相与维护信任），同时顾及他人感受。这些价值权衡是人类决策与语言使用的核心，但目前解析LLM中此类动态多面价值的工具有限。认知科学中的“认知模型”通过量化说话者在行动或话语选择中的竞争效用函数权重，为人类价值权衡提供了形式化描述。本研究采用领先的礼貌语言认知模型，评估LLM在多大程度上体现了人类式的价值权衡。通过两种场景系统分析：前沿黑盒模型的推理“努力”程度，以及开源模型的强化学习后训练动态。结果显示，推理模型更注重信息效用而非社交效用；数学推理较强的开源模型也表现出类似倾向。LLM训练动态表明，基础模型和预训练数据对效用价值的早期调整具有持久影响，而反馈数据集或对齐方法影响较小。本方法能灵活应对快速演变的LLM生态，为推理模型训练假设的生成、训练方案的制定以及价值权衡的控制提供洞见。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [34] [Computer Vision based Automated Quantification of Agricultural Sprayers Boom Displacement](https://arxiv.org/abs/2506.19939)
**中文标题：基于计算机视觉的农业喷雾器喷杆位移自动化量化**

*Aryan Singh Dalal,Sidharth Rai,Rahul Singh,Treman Singh Kaloya,Rahul Harsha Cheppally,Ajay Sharda*

主要分类: cs.CV

摘要简述: 本文开发了一种基于计算机视觉的自动化系统，用于量化农业喷雾器喷杆的位移，以提高喷雾精度。通过YOLO神经网络模型实时跟踪喷杆目标，结合倾角传感器验证，结果显示模型检测精度超过90%，位移估计误差小于0.026米。


<details>
  <summary>详细信息</summary>
研究动机: 农业喷雾器在作业中喷杆的不稳定性是导致喷雾误差的主要因素之一。目前缺乏对喷杆位移的定量研究，难以系统改进喷杆设计和控制系统。因此，本研究旨在开发一种自动化系统，量化喷杆位移，为设计改进提供数据支持。

研究方法: 研究开发了一套计算机视觉系统，利用YOLO V7、V8和V11神经网络模型实时跟踪喷杆边缘的目标。同时，在喷杆上安装倾角传感器，用于验证神经网络模型的输出。通过量化喷杆在垂直和横向方向的位移，评估模型的准确性。

研究结果: 结果显示，神经网络模型对目标的检测精度超过90%，喷杆位移的估计值与倾角传感器数据的误差在0.026米以内。该系统可适用于当前喷雾器及其他喷雾器，仅需少量修改。

研究结论: 本研究开发的计算机视觉系统能够有效量化喷杆位移，为喷杆设计和控制系统的改进提供了可靠数据，有助于提高喷雾器的稳定性和喷雾精度。

中文摘要: 农业喷雾器在农业生产中的喷雾误差问题一直备受关注，其中喷杆的不稳定性是主要因素之一。喷杆宽度达38米，作业速度30公里/小时，加之复杂地形和机器动态，使得喷杆控制极为复杂。然而，目前缺乏对喷杆位移的定量研究，难以系统改进喷杆设计和控制系统。为此，本研究开发了一种基于计算机视觉的自动化系统，用于量化喷杆位移。通过训练YOLO V7、V8和V11神经网络模型实时跟踪喷杆边缘的目标，并结合倾角传感器验证模型输出。结果显示，模型检测精度超过90%，喷杆位移估计值与传感器数据的误差在0.026米以内。该系统适用于当前喷雾器及其他喷雾器，仅需少量修改。研究数据可用于改进喷杆设计，提高喷雾精度。

</details>


### [35] [EBC-ZIP: Improving Blockwise Crowd Counting with Zero-Inflated Poisson Regression](https://arxiv.org/abs/2506.19955)
**中文标题：EBC-ZIP：通过零膨胀泊松回归改进块状人群计数**

*Yiming Ma,Victor Sanchez,Tanaya Guha*

主要分类: cs.CV

摘要简述: 本文提出EBC-ZIP框架，通过零膨胀泊松回归改进块状人群计数，解决密度图稀疏性问题，提升稀疏区域性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有密度图估计方法忽略真实场景中人群分布的极端稀疏性（95%以上区域无人），导致模型偏向高估密集区域，低估稀疏区域。此外，传统损失函数基于MSE和高斯分布假设，不适合离散非负计数数据。

研究方法: EBC-ZIP采用零膨胀泊松回归（ZIP）建模人群空间分布，用ZIP分布的负对数似然替代传统回归损失，结合增强块分类（EBC）框架，保留目标离散性并提升性能。

研究结果: 在四个基准测试中，EBC-ZIP表现优于EBC，达到最先进水平，验证了其处理零密集分布和提升计数准确性的能力。

研究结论: EBC-ZIP通过ZIP回归和EBC框架的结合，显著改善了人群计数性能，尤其在稀疏区域表现突出，为密度图估计提供了更优解决方案。

中文摘要: 密度图估计已成为人群计数的主流范式。然而，现有方法大多忽略了真实密度图的极端稀疏性。在现实场景中，绝大多数空间区域（通常超过95%）无人，导致计数分布严重不平衡。忽视这种不平衡会使模型偏向高估密集区域，低估稀疏区域。此外，密度估计中常用的损失函数主要基于MSE，隐含假设高斯分布，不适合建模离散非负计数数据。本文提出EBC-ZIP框架，采用零膨胀泊松回归（ZIP）建模计数空间分布，用ZIP的负对数似然替代传统回归损失，更好地处理零密集分布并保持计数准确性。基于增强块分类（EBC）框架，EBC-ZIP继承了EBC在保留目标离散性和训练稳定性上的优势，并通过更严谨的概率损失进一步提升性能。我们还评估了不同计算复杂度骨干网络的EBC-ZIP，验证其可扩展性。在四个基准测试上的实验表明，EBC-ZIP始终优于EBC，并达到最先进水平。

</details>


### [36] [ToSA: Token Merging with Spatial Awareness](https://arxiv.org/abs/2506.20066)
**中文标题：ToSA：具有空间感知的令牌合并**

*Hsiang-Wei Huang,Wenhao Chai,Kuang-Ming Chen,Cheng-Yen Yang,Jenq-Neng Hwang*

主要分类: cs.CV

摘要简述: ToSA是一种结合语义和空间感知的令牌合并方法，通过深度图像生成伪空间令牌，优化视觉Transformer（ViT）的加速效果，同时保留关键场景结构。


<details>
  <summary>详细信息</summary>
研究动机: 现有令牌合并方法主要依赖特征相似性，忽略了空间信息在ViT早期层中的潜在作用。ToSA旨在通过整合空间信息，提升令牌合并的效率和准确性。

研究方法: ToSA利用深度图像生成伪空间令牌，作为视觉令牌合并的辅助空间信息，结合语义和空间感知指导合并过程。

研究结果: 实验表明，ToSA在视觉和具身问答任务中优于现有方法，显著减少ViT运行时间，同时保持场景结构。

研究结论: ToSA通过结合空间信息，提供了一种高效的ViT加速方案，适用于多种视觉任务。

中文摘要: 令牌合并已成为加速视觉Transformer（ViT）的有效策略，但现有方法主要依赖视觉令牌的特征相似性，忽略了空间信息的潜力。空间信息可作为ViT早期层中令牌合并的可靠标准，此时视觉令牌仅包含较弱的视觉信息。本文提出ToSA，一种结合语义和空间感知的新型令牌合并方法。ToSA利用深度图像生成伪空间令牌，作为视觉令牌合并的辅助空间信息。通过引入空间感知，ToSA实现了更明智的合并策略，更好地保留关键场景结构。实验结果表明，ToSA在视觉和具身问答任务中优于现有令牌合并方法，同时大幅减少ViT运行时间，成为ViT加速的高效解决方案。代码将在以下网址提供：https://github.com/hsiangwei0903/ToSA

</details>


### [37] [BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos](https://arxiv.org/abs/2506.20103)
**中文标题：BrokenVideos：AI生成视频中细粒度伪影定位的基准数据集**

*Jiahao Lin,Weixuan Peng,Bojia Zi,Yifeng Gao,Xianbiao Qi,Xingjun Ma,Yu-Gang Jiang*

主要分类: cs.CV

摘要简述: 本文介绍了BrokenVideos，一个专门用于AI生成视频中细粒度伪影定位的基准数据集，包含3,254个视频，并提供了像素级标注的伪影区域。实验表明，该数据集显著提升了现有模型在伪影定位任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI生成的视频常包含视觉伪影（如时间不一致的运动、物理不合理的轨迹等），但缺乏专门用于伪影定位的基准数据集。现有数据集要么仅支持视频或帧级检测，要么缺乏细粒度空间标注。

研究方法: 作者构建了BrokenVideos数据集，包含3,254个AI生成视频，并进行了像素级的伪影区域标注，每项标注均经过人工验证以确保高质量。在此基础上，训练了先进的伪影检测模型和多模态大语言模型（MLLMs）。

研究结果: 实验结果显示，使用BrokenVideos训练的模型在伪影定位任务中表现显著提升。该数据集为生成视频模型的伪影定位研究提供了重要基准。

研究结论: BrokenVideos填补了AI生成视频伪影定位领域的空白，为相关研究提供了高质量的数据支持，推动了生成视频模型的改进。

中文摘要: 近年来，深度生成模型在视频生成领域取得了显著进展，但AI生成视频的真实性仍有限制。合成内容常出现视觉伪影，如时间不一致的运动、物理不合理的轨迹、不自然的物体变形和局部模糊，这些伪影降低了真实性和用户信任度。准确检测和空间定位这些伪影对于自动化质量控制和改进生成模型至关重要。然而，研究社区目前缺乏专门用于AI生成视频伪影定位的全面基准数据集。现有数据集要么仅支持视频或帧级检测，要么缺乏评估定位方法所需的细粒度空间标注。为解决这一问题，我们提出了BrokenVideos，一个包含3,254个AI生成视频的基准数据集，其中每个视频均经过精心标注，提供了像素级的伪影区域掩码。每项标注均通过详细的人工检查以确保高质量的真实标注。实验表明，在BrokenVideos上训练的最先进伪影检测模型和多模态大语言模型（MLLMs）显著提升了其在伪影定位任务中的能力。通过广泛评估，我们证明BrokenVideos为生成视频模型的伪影定位研究奠定了重要基础。数据集地址：https://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/。

</details>


### [38] [From 2D to 3D Cognition: A Brief Survey of General World Models](https://arxiv.org/abs/2506.20134)
**中文标题：从2D到3D认知：通用世界模型简析**

*Ningwei Xie,Zizi Tian,Lei Yang,Xiao-Ping Zhang,Meng Guo,Jie Li*

主要分类: cs.CV

摘要简述: 本文综述了从2D感知到3D认知的世界模型发展，重点分析了3D表示和世界知识两大技术驱动力，并探讨了3D世界建模的三大核心能力及其实际应用。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能通用智能（AGI）的发展，世界模型作为学习外部世界表示和预测未来状态的计算框架受到广泛关注。然而，从2D感知到3D认知的过渡缺乏系统性分析，本文旨在填补这一空白。

研究方法: 通过引入概念框架，本文对从2D感知到3D认知的世界模型进行了结构化综述，重点分析了3D表示和世界知识两大技术驱动力，并探讨了3D物理场景生成、3D空间推理和3D空间交互三大核心能力。

研究结果: 本文系统梳理了3D世界建模的技术进展，并探讨了其在具身AI、自动驾驶、数字孪生和游戏/VR等领域的应用。同时，指出了数据、建模和部署方面的挑战。

研究结论: 本文为3D世界模型的发展提供了系统性分析，并指出了未来研究方向，旨在推动更强大和通用的3D世界模型的实现。

中文摘要: 世界模型作为学习外部世界表示和预测未来状态的计算框架，在人工通用智能（AGI）发展中日益受到关注。早期研究集中于2D视觉感知与模拟，而近年来的3D感知生成世界模型已能合成几何一致且可交互的3D环境，标志着向3D空间认知的转变。尽管进展迅速，该领域仍缺乏系统性分析以分类新兴技术并明确其在推动3D认知世界模型中的作用。本综述通过引入概念框架，对从2D感知到3D认知的世界模型进行了结构化且前瞻性的回顾。在此框架下，我们强调了3D表示和世界知识两大技术驱动力作为基础支柱。基于此，我们剖析了支撑3D世界建模的三大核心认知能力：3D物理场景生成、3D空间推理和3D空间交互。我们还探讨了这些能力在具身AI、自动驾驶、数字孪生和游戏/VR等实际应用中的部署。最后，我们指出了数据、建模和部署方面的挑战，并概述了推动更强大和通用3D世界模型的未来方向。

</details>


### [39] [EAR: Erasing Concepts from Unified Autoregressive Models](https://arxiv.org/abs/2506.20151)
**中文标题：EAR：从统一自回归模型中擦除概念**

*Haipeng Fan,Shiyuan Zhang,Baohunesitu,Zihang Guo,Huaiwen Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为EAR的方法，用于从统一自回归模型中有效擦除不期望的概念，同时保持生成质量。通过WGA和TLM策略，以及新基准ECGVF，实验证明EAR在擦除效果和模型实用性上均有显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 自回归模型在视觉理解和图像生成任务中表现优异，但如何在不影响整体生成质量的情况下移除不期望的概念仍是一个未解决的挑战。本文旨在解决这一问题。

研究方法: 提出EAR方法，结合窗口梯度累积（WGA）策略和阈值损失掩码（TLM）策略，优化概念擦除过程。同时，设计了ECGVF基准，通过结构化模板和视觉分类器生成并过滤大规模概念提示对。

研究结果: 在ECGVF基准上的实验表明，EAR在概念擦除效果和模型实用性保留方面均显著优于现有方法。

研究结论: EAR方法通过创新的策略和基准，成功实现了高效且实用的概念擦除，为自回归模型的进一步应用提供了新思路。

中文摘要: 自回归（AR）模型在视觉理解和图像生成任务中表现统一且强大。然而，如何在保持整体生成质量的同时从AR模型中移除不期望的概念仍是一个开放性问题。本文提出擦除自回归模型（EAR），一种用于在AR模型中实现高效且实用性保留的概念擦除的微调方法。具体而言，我们引入窗口梯度累积（WGA）策略以对齐块级解码与擦除目标，以及阈值损失掩码（TLM）策略以在微调过程中保护与目标概念无关的内容。此外，我们提出了一个新基准——擦除概念生成器与视觉过滤器（ECGVF），旨在为评估AR模型中的概念擦除提供更严格和全面的基础。具体而言，我们首先利用结构化模板在多样化的大语言模型（LLMs）中预生成大规模的目标-替换概念提示对。随后，我们从这些提示生成图像，并通过视觉分类器进行严格过滤以确保概念的保真度和对齐性。在ECGVF基准上对AR模型Janus-Pro进行的大量实验结果表明，EAR在擦除效果和模型实用性保留方面均取得了显著提升。代码可在https://github.com/immc-lab/ear/获取。

</details>


### [40] [Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration](https://arxiv.org/abs/2506.20152)
**中文标题：基于损失感知的深度神经网络加速结构化剪枝标准自动选择**

*Deepak Ghimire,Kilho Lee,Seong-heum Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种基于损失感知的自动结构化剪枝标准选择方法（LAASP），用于深度神经网络的压缩和加速。该方法通过剪枝与训练结合的方式，自动选择剪枝标准和层，显著减少了计算量（FLOPs），同时保持了较高的准确率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的结构化剪枝方法通常分为训练、剪枝和微调三个阶段，效率较低。本文旨在通过一种剪枝与训练结合的方法，自动选择剪枝标准和层，以提升剪枝效率和模型性能。

研究方法: 提出了一种剪枝与训练结合的LAASP方法，自动从预设的剪枝标准中选择适合的剪枝标准和层，并通过网络损失指导选择过程。每次剪枝后短暂重训练以缓解准确率下降，自动确定各层的最优剪枝率。

研究结果: 在CIFAR-10和ImageNet数据集上的实验表明，LAASP显著减少了FLOPs（ResNet56和ResNet110减少52%，ResNet50减少42%），同时保持了较高的准确率（ImageNet上仅下降0.33%）。

研究结论: LAASP方法通过自动选择剪枝标准和层，实现了高效的神经网络压缩和加速，显著优于现有方法，适用于资源受限的边缘设备部署。

中文摘要: 结构化剪枝是一种成熟的神经网络压缩技术，适用于资源受限的边缘设备部署。本文提出了一种高效的基于损失感知的结构化剪枝标准自动选择方法（LAASP），用于深度神经网络的瘦身和加速。大多数剪枝方法采用训练、剪枝和微调三阶段顺序流程，而本文提出的剪枝技术采用剪枝与训练结合的方式，省去了第一阶段，并将第二和第三阶段整合为一个循环。通过网络的总体损失指导从预设标准池中自动选择基于幅度或相似性的滤波器剪枝标准，并在每次剪枝迭代中选择特定剪枝层。为缓解剪枝导致的准确率骤降，每次减少预定义浮点运算（FLOPs）数量后，网络会短暂重训练。网络中各层的最优剪枝率自动确定，无需手动分配固定或可变剪枝率。在CIFAR-10和ImageNet基准数据集上对VGGNet和ResNet模型的实验证明了该方法的有效性。特别是，CIFAR-10数据集上的ResNet56和ResNet110模型在减少52% FLOPs的同时，显著提升了top-1准确率。此外，ImageNet数据集上的ResNet50模型减少了超过42%的FLOPs，而top-5准确率仅下降0.33%。本文的源代码已公开：https://github.com/ghimiredhikura/laasp。

</details>


### [41] [Towards Efficient Exemplar Based Image Editing with Multimodal VLMs](https://arxiv.org/abs/2506.20155)
**中文标题：基于多模态视觉语言模型的高效示例图像编辑**

*Avadhoot Jadhav,Ashutosh Srivastava,Abhinav Java,Silky Singh,Tarun Ram Menta,Surgan Jandial,Balaji Krishnamurthy*

主要分类: cs.CV

摘要简述: 本文提出了一种基于示例的高效图像编辑方法，利用多模态视觉语言模型（VLMs）和预训练的文本到图像扩散模型，无需优化即可实现快速且优于基线的编辑效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于文本的图像编辑方法难以通过文字准确表达某些模糊的编辑需求，而示例对（编辑前后的图像对）能更直观地传达编辑意图。本文旨在解决基于示例的图像编辑任务，提升编辑效率和效果。

研究方法: 本文提出了一种端到端的图像编辑流程，结合预训练的文本到图像扩散模型和多模态VLMs，无需优化步骤即可将示例对中的编辑效果迁移到目标图像上。

研究结果: 实验表明，该方法在多种编辑任务中表现优于基线方法，且速度提升约4倍。

研究结论: 本文提出的方法通过结合多模态VLMs和扩散模型，实现了高效且高质量的示例图像编辑，为复杂编辑需求提供了更直观的解决方案。

中文摘要: 文本到图像扩散模型已支持广泛的图像编辑应用。然而，仅通过文字捕捉所有类型的编辑可能具有挑战性且繁琐。某些图像编辑的模糊性更适合通过示例对（即编辑前后的图像对）表达。本文研究了基于示例的图像编辑任务——将示例对中的编辑效果迁移到内容图像上，利用预训练的文本到图像扩散模型和多模态VLMs。尽管我们的端到端流程无需优化，实验表明其在多种编辑任务中仍优于基线方法，且速度提升约4倍。

</details>


### [42] [Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2506.20168)
**中文标题：眼见为实？缓解多模态大语言模型中的OCR幻觉问题**

*Zhentao He,Can Zhang,Ziheng Wu,Zhenghao Chen,Yufei Zhan,Yifan Li,Zhao Zhang,Xian Wang,Minghui Qiu*

主要分类: cs.CV

摘要简述: 多模态大语言模型在文档理解中因视觉退化导致OCR幻觉问题，研究者提出KIE-HVQA基准和GRPO框架，显著减少幻觉生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有模型在视觉退化场景下过度依赖语言先验或视觉-文本推理错位，导致生成幻觉内容，亟需解决这一问题。

研究方法: 提出KIE-HVQA基准评估OCR幻觉，并设计GRPO框架，通过视觉不确定性自我感知和拒绝回答机制减少幻觉。

研究结果: 实验显示，7B参数模型在KIE-HVQA上比GPT-4o幻觉减少22%，标准任务性能无显著下降。

研究结论: GRPO框架有效减少多模态模型在视觉退化下的幻觉生成，兼具效果与鲁棒性。

中文摘要: 多模态大语言模型的最新进展通过整合文本和视觉信息提升了文档理解能力。然而，现有模型在现实场景中，尤其是视觉退化条件下，表现出范式不完整性。在此类条件下，当前响应范式往往无法充分感知视觉退化和模糊性，导致过度依赖语言先验或视觉-文本推理错位。这种不确定性识别的困难常常引发幻觉内容的生成，尤其是在无法提供精确答案时。为了更好地展示和分析这一现象及问题，我们提出了KIE-HVQA，这是首个专注于评估退化文档理解中OCR幻觉的基准。该数据集包含身份证和发票等测试样本，并模拟了现实中的OCR可靠性退化场景。通过这一设置，可以评估模型在退化输入下区分可靠视觉信息并据此回答的能力，从而突显避免在不确定数据上生成幻觉的挑战。为实现视觉可信的推理并避免上述问题，我们进一步提出了基于GRPO的框架，其采用了一种新颖的奖励机制。通过将视觉不确定性的自我感知和拒绝回答的分析方法纳入监督微调和强化学习框架，我们成功减少了模糊区域的幻觉生成。在Qwen2.5-VL上的实验表明，我们的7B参数模型在KIE-HVQA上比GPT-4o实现了22%的绝对幻觉减少，且在标准任务中性能无显著下降，突出了其有效性和鲁棒性。

</details>


### [43] [Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition](https://arxiv.org/abs/2506.20174)
**中文标题：通过基础模型组合实现可扩展和泛化的地球观测数据挖掘**

*Man Duc Chuc*

主要分类: cs.CV

摘要简述: 研究表明，通过组合预训练的小型基础模型，可以在地球观测任务中达到或超越大型模型的性能，同时减少训练时间和计算资源。知识蒸馏进一步展示了将集成模型优势转移到更紧凑模型的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 当前地球观测数据挖掘领域主要关注从头训练大型模型，而忽略了利用和组合现有预训练模型的潜力。本研究旨在探索通过组合预训练的基础模型，提升地球观测任务的性能和效率。

研究方法: 研究使用GEO-Bench基准测试，评估了包括Prithvi、Hiera和DOFA在内的多个预训练模型在11个数据集上的表现。通过特征级集成小型预训练模型，并与大型模型性能对比。

研究结果: 结果表明，小型预训练模型的集成性能可以匹配或超越大型模型，同时显著减少训练时间和计算资源。知识蒸馏进一步验证了将集成模型优势转移到紧凑模型的可行性。

研究结论: 组合预训练基础模型是一种高效且可扩展的地球观测数据挖掘方法，知识蒸馏为实际应用提供了实用路径。

中文摘要: 基础模型正在迅速改变地球观测数据挖掘，为场景分类和语义分割等关键任务提供泛化和可扩展的解决方案。尽管地理空间领域的研究主要集中于利用大规模地球观测数据集从头训练大型模型，但另一种尚未充分探索的策略是重用和组合现有的预训练模型。本研究探讨了在遥感数据和通用视觉数据集上预训练的基础模型是否能有效组合，以提升多种地球观测任务的性能。使用GEO-Bench基准测试，我们评估了包括Prithvi、Hiera和DOFA在内的多个模型在11个数据集上的表现，涵盖了多种空间分辨率、传感器模态和任务类型。结果表明，小型预训练模型的特征级集成性能可以匹配或超越大型模型，同时减少训练时间和计算资源。此外，研究还展示了通过知识蒸馏将集成模型优势转移到更紧凑模型的潜力，为实际地球观测应用中的基础模型部署提供了实用路径。

</details>


### [44] [Progressive Alignment Degradation Learning for Pansharpening](https://arxiv.org/abs/2506.20179)
**中文标题：渐进对齐退化学习用于全色锐化**

*Enzhe Zhao,Zhichang Guo,Yao Li,Fanghui Song,Boying Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种渐进对齐退化学习模块（PADM）和HFreqdiff框架，用于改进基于深度学习的全色锐化方法，显著提升高分辨率多光谱图像的空间清晰度和质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的Wald协议生成的合成数据无法准确模拟真实世界的退化模式，限制了全色锐化模型的泛化能力。本文旨在解决这一问题。

研究方法: 提出PADM模块，通过PAlignNet和PDegradeNet的相互迭代自适应学习退化过程；引入HFreqdiff框架，结合CFB和BACM模块进行高频细节提取和反向过程学习。

研究结果: 实验和消融研究表明，该方法在空间清晰度和图像质量上优于现有技术。

研究结论: 本文方法有效提升了全色锐化的性能，为高分辨率多光谱图像的生成提供了新思路。

中文摘要: 基于深度学习的全色锐化方法已证明能有效生成高分辨率多光谱（HRMS）图像。通常使用Wald协议生成的合成数据作为监督学习的真实HRMS图像。该协议假设在人工低分辨率数据上训练的网络在高分辨率数据上表现同样出色。然而，训练良好的模型通常在降分辨率和全分辨率数据集之间存在性能权衡。本文深入研究了Wald协议，发现其对真实世界退化模式的不准确近似限制了深度全色锐化模型的泛化能力。为解决这一问题，我们提出了渐进对齐退化模块（PADM），通过PAlignNet和PDegradeNet两个子网络的相互迭代，自适应学习准确的退化过程，而无需依赖预定义算子。在此基础上，我们引入了HFreqdiff，将高频细节嵌入扩散框架，并结合CFB和BACM模块进行频率选择性细节提取和精确反向过程学习。这些创新实现了高分辨率全色和多光谱图像的有效融合，显著提升了空间清晰度和质量。实验和消融研究表明，所提方法在性能上优于现有技术。

</details>


### [45] [UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2506.20214)
**中文标题：UniCode$^2$：用于统一多模态理解和生成的级联大规模码本**

*Yanzhe Chen,Huasong Zhong,Yan Li,Zhenheng Yang*

主要分类: cs.CV

摘要简述: UniCode$^2$提出了一种级联大规模视觉码本框架，用于统一多模态理解和生成，解决了现有码本方法在小词汇量或大规模扩展时的问题，实现了语义对齐和稳定训练。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态大语言模型（MLLMs）在视觉码本设计上存在局限性：小词汇量缺乏细粒度语义，而大规模扩展则导致低效的令牌利用和不稳定训练。UniCode$^2$旨在解决这些问题，实现更高效和稳定的视觉令牌化。

研究方法: UniCode$^2$通过聚类数百万SigLIP序列嵌入，构建了一个50万条目的码本，保持了视觉与语言的语义对齐。采用级联设计：冻结码本固定嵌入空间，可训练码本优化任务特定语义，从而确保稳定性和高利用率。

研究结果: UniCode$^2$在多个基准测试中表现优异，展示了在不牺牲稳定性、语义或模块性的前提下扩展视觉令牌空间的可行性，并支持高质量视觉合成。

研究结论: UniCode$^2$通过级联大规模码本设计，成功解决了视觉令牌化的稳定性与语义对齐问题，为多模态理解和生成提供了高效且模块化的解决方案。

中文摘要: 统一的多模态大语言模型（MLLMs）在联合推进多模态理解和生成方面显示出潜力，其中视觉码本将图像离散化为令牌以进行自回归建模。现有的基于码本的方法要么依赖缺乏细粒度语义的小词汇量（约1.6万条目），要么简单地扩大规模，导致令牌利用率低和训练不稳定。我们提出了UniCode$^2$，一种级联码本框架，支持大规模、语义对齐且稳定的视觉令牌化。通过聚类数百万SigLIP序列嵌入，我们构建了一个50万条目的码本，既保留了视觉与语言的语义对齐，又扩展了容量。稳定性通过级联设计得到保证：冻结码本固定嵌入空间，可训练码本优化任务特定语义。这种解耦设计提高了利用率和鲁棒性。此外，我们的视觉令牌与文本语义的对齐使其能够无缝集成预训练的扩散解码器，支持高质量视觉合成且仅需最小适配。UniCode$^2$在多个基准测试中表现出色，证明了在不牺牲稳定性、语义或模块性的前提下扩展视觉令牌空间的可行性。

</details>


### [46] [Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission](https://arxiv.org/abs/2506.20222)
**中文标题：混合事件-RGB传输的动态带宽分配**

*Pujing Yang,Guangyi Zhang,Yunlong Cai,Lei Yu,Guanding Yu*

主要分类: cs.CV

摘要简述: 本文提出了一种动态带宽分配方案，用于优化事件相机与RGB相机混合系统中的数据传输，通过消除冗余信息提升传输效率，同时实现高质量重建和实时去模糊。


<details>
  <summary>详细信息</summary>
研究动机: 事件相机与RGB相机在混合系统中会产生大量冗余数据，传输效率低下。本文旨在解决这一问题，通过优化带宽分配提升系统性能。

研究方法: 提出了一种联合事件与图像（E-I）传输框架，利用贝叶斯建模和信息瓶颈方法分离共享与领域特定信息，并根据场景动态自适应分配带宽。

研究结果: 仿真结果表明，该方案在重建质量和去模糊性能上均优于传统系统。

研究结论: 所提出的动态带宽分配方案显著提升了混合系统的传输效率与性能，为视觉相关应用提供了实用解决方案。

中文摘要: 事件相机以极低延迟异步捕捉像素级强度变化，常与RGB相机结合用于多种视觉应用。然而，混合系统中大量触发事件与RGB图像的传输是一个主要挑战。为此，我们提出了一种传输方案，在保留两种源数据高效重建性能的同时，实现并行实时去模糊。传统RGB相机与事件相机以不同方式捕捉同一场景，常导致输出中存在显著冗余信息。为解决这一问题，我们开发了一种联合事件与图像（E-I）传输框架，以消除冗余并优化信道带宽利用率。该方法采用贝叶斯建模和信息瓶颈方法，分离E-I输入中的共享与领域特定信息。这种分离的信息瓶颈框架确保了提取信息的紧凑性和信息量。此外，它根据场景动态自适应分配传输带宽，即动态细节分配更多符号给事件，静态信息分配更多符号给图像。仿真结果表明，所提方案不仅优于传统系统的重建质量，还提升了去模糊性能。

</details>


### [47] [Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement](https://arxiv.org/abs/2506.20254)
**中文标题：随处识别手术阶段：少样本测试时适应与任务图引导优化**

*Kun Yuan,Tingxuan Chen,Shi Li,Joel L. Lavanchy,Christian Heiliger,Ege Özsoy,Yiming Huang,Long Bai,Nassir Navab,Vinkle Srivastav,Hongliang Ren,Nicolas Padoy*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级框架SPA，用于适应不同机构的手术工作流理解，通过少样本空间适应和任务图引导的优化，显著提升了手术阶段识别的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 由于手术工作流的复杂性和多样性，现有模型在跨机构和跨手术场景中的泛化能力受限。本文旨在通过轻量级适应框架，解决领域偏移问题，提升模型在未见手术环境中的表现。

研究方法: SPA框架结合少样本空间适应和多模态嵌入对齐，利用扩散模型确保时间一致性，并通过动态测试时适应在自监督方式下优化模型。

研究结果: 实验表明，SPA在少样本手术阶段识别任务中表现优异，甚至优于使用32个标注样本的全样本模型。

研究结论: SPA为手术工作流理解提供了一种高效且轻量级的解决方案，适用于不同机构和手术场景，具有广泛的应用潜力。

中文摘要: 手术工作流的复杂性和多样性，源于异构手术室设置、机构协议和解剖学差异，为开发跨机构和跨手术的通用模型带来了巨大挑战。尽管近期基于大规模视觉语言数据预训练的手术基础模型展现出良好的迁移能力，但其零样本性能仍受限于领域偏移，限制了其在未见手术环境中的应用。为此，我们提出了“随处手术阶段识别”（SPA），一种轻量级框架，用于通用手术工作流理解，能够以最少标注将基础模型适应到机构特定场景。SPA通过少样本空间适应将多模态嵌入与机构特定的手术场景和阶段对齐，并通过扩散模型编码来自机构协议的任务图先验，确保时间一致性。此外，SPA利用多模态阶段预测流之间的相互一致性，以自监督方式动态适应测试视频，提升测试时分布偏移下的可靠性。SPA是一种轻量级适应框架，医院可通过定义自然语言文本的阶段、标注少量图像并提供定义阶段转换的任务图，快速定制阶段识别模型。实验结果表明，SPA框架在多个机构和手术中的少样本手术阶段识别任务中达到了最先进的性能，甚至优于使用32个标注样本的全样本模型。代码发布于https://github.com/CAMMA-public/SPA。

</details>


### [48] [A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features](https://arxiv.org/abs/2506.20255)
**中文标题：基于Transformer的联合在线与离线特征的手写识别系统**

*Ayush Lodh,Ritabrata Chakraborty,Shivakumara Palaiahnakote,Umapada Pal*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer的手写识别系统，联合利用在线和离线特征，通过早期融合提升识别精度，实验表明其性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有手写识别系统通常仅利用单一模态（如离线图像或在线笔画数据），而忽略了两种模态的互补性。本文旨在通过联合利用这两种模态，提升识别性能。

研究方法: 提出了一种端到端网络，在共享潜在空间中早期融合离线图像和在线笔画数据。使用补丁编码器将灰度图像转换为视觉标记，轻量级Transformer嵌入笔画序列。通过可学习的潜在查询联合关注两种标记流，生成上下文增强的笔画嵌入，并通过交叉熵损失解码。

研究结果: 在IAMOn-DB和VNOn-DB数据集上的实验表明，该方法达到了最先进的识别精度，比之前的最佳方法提升了1%。此外，该方法在ISI-Air数据集上也展示了适应性。

研究结论: 通过早期融合在线和离线特征，本文提出的方法显著提升了手写识别的性能，并展示了其在不同数据集上的适应性。

中文摘要: 我们认为手写识别可以从栅格化的复杂字形和笔的轨迹中携带的互补线索中受益，但大多数系统仅利用一种模态。我们提出了一种端到端网络，在共享潜在空间中早期融合离线图像和在线笔画数据。补丁编码器将灰度图像转换为固定长度的视觉标记，而轻量级Transformer嵌入$(x, y, 	ext{笔})$序列。可学习的潜在查询联合关注两种标记流，生成上下文增强的笔画嵌入，并通过交叉熵损失解码。由于融合发生在任何高级分类之前，时间线索在表示学习中相互增强，从而提高了书写独立性。在IAMOn-DB和VNOn-DB上的全面实验表明，我们的方法达到了最先进的精度，比之前的最佳方法提升了1%。我们的研究还展示了该方法在ISI-Air数据集上的手势化适应性。我们的代码可在此处找到。

</details>


### [49] [Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification](https://arxiv.org/abs/2506.20263)
**中文标题：分层掩码增强双重建网络用于少样本细粒度图像分类**

*Ning Luo,Meiyin Hu,Huan Wan,Yanyan Yang,Zhuohang Jiang,Xin Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为HMDRN的分层掩码增强双重建网络，用于解决少样本细粒度图像分类问题。该方法通过双层次特征重建和掩码增强处理，显著提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 少样本细粒度图像分类（FS-FGIC）面临巨大挑战，现有方法存在空间信息丢失、局部特征不对齐、缺乏层次特征利用等问题。本文旨在设计一种更高效的方法来解决这些问题。

研究方法: HMDRN结合了双层次特征重建与掩码增强特征处理。通过双层次特征重建模块，模型平衡了高层语义和中级结构细节；通过空间二值掩码增强的自重建模块，模型增强了判别性区域的关注并过滤背景噪声。

研究结果: 在三个具有挑战性的细粒度数据集上，HMDRN在Conv-4和ResNet-12骨干网络上均优于现有方法。消融实验验证了各模块的有效性。

研究结论: HMDRN通过双层次重建和掩码增强处理，显著提升了少样本细粒度图像分类的性能，同时减少了类内差异。

中文摘要: 少样本细粒度图像分类（FS-FGIC）是一项具有挑战性的任务，要求模型在有限的标记样本下区分视觉上相似的子类。现有方法存在明显局限性：基于度量的方法丢失空间信息且局部特征不对齐，而基于重建的方法未能利用层次特征信息且缺乏关注判别性区域的机制。我们提出了分层掩码增强双重建网络（HMDRN），通过结合双层次特征重建与掩码增强特征处理来改进细粒度分类。HMDRN包含一个双层次特征重建与融合模块，利用不同网络层次的互补视觉信息。通过可学习的融合权重，模型平衡了最后一层的高层语义表示与倒数第二层的中级结构细节。此外，我们设计了一个空间二值掩码增强的自重建模块，通过自适应阈值处理查询特征，同时保持完整的支持特征，增强了对判别性区域的关注并过滤了背景噪声。在三个具有挑战性的细粒度数据集上的大量实验表明，HMDRN在Conv-4和ResNet-12骨干网络上均优于现有方法。全面的消融研究验证了各模块的有效性，表明双层次重建增强了类间区分能力，而掩码增强变换减少了类内差异。可视化结果证明了HMDRN在特征重建方面的优越性。

</details>


### [50] [Forensic Study of Paintings Through the Comparison of Fabrics](https://arxiv.org/abs/2506.20272)
**中文标题：通过织物比较对绘画进行法证研究**

*Juan José Murillo-Fuentes,Pablo M. Olmos,Laura Alba-Carcelén*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的创新方法，用于评估画布纺织品的相似性，无需依赖传统线密度图匹配，为艺术品鉴定和保存提供了新工具。


<details>
  <summary>详细信息</summary>
研究动机: 传统画布分析方法依赖线密度图匹配，但无法适用于非连续位置的画布。本文旨在开发一种不依赖线密度图的自动工具，以更灵活地评估画布相似性。

研究方法: 设计并训练了一个孪生深度学习模型，通过扫描图像的特征表示比较画布对。提出了一种相似性估计方法，通过聚合多对样本的预测提供稳健的相似性评分。

研究结果: 该方法应用于普拉多博物馆的画布，验证了即使线密度相似，平纹画布也能有效比较，证明了方法的可行性和准确性。

研究结论: 该方法为艺术品分析开辟了新途径，尤其在画布相似性评估方面具有重要应用价值。

中文摘要: 艺术品中画布织物的研究是鉴定、归属和保存的关键工具。传统方法基于线密度图匹配，但无法适用于非连续位置的画布。本文提出了一种基于深度学习的新方法，用于评估纺织品的相似性。我们引入了一种自动工具，无需依赖线密度图即可评估画布间的相似性。设计并训练了一个孪生深度学习模型，通过扫描图像的特征表示比较画布对。此外，提出了一种相似性估计方法，通过聚合多对样本的预测提供稳健的相似性评分。该方法应用于普拉多博物馆的画布，验证了广泛用于绘画的平纹画布即使在线密度相似时也能有效比较。结果表明了该方法的可行性和准确性，为名作分析开辟了新途径。

</details>


### [51] [From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios](https://arxiv.org/abs/2506.20279)
**中文标题：从理想到现实：面向真实世界场景的统一且数据高效的密集预测**

*Changliang Xia,Chengyou Jia,Zhuohang Dang,Minnan Luo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DenseDiT的统一且高效的方法，用于解决真实世界场景中的密集预测任务，通过利用生成模型的视觉先验和轻量级分支，显著减少了训练数据需求，并在新基准DenseWorld上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 现有的密集预测方法主要针对理想化条件，对真实世界场景的泛化能力有限，且面临真实数据稀缺的挑战。本文旨在通过统一的方法和数据高效策略解决这些问题。

研究方法: 提出DenseDiT方法，结合参数重用机制和两个轻量级分支，自适应整合多尺度上下文信息，仅需不到0.1%的额外参数。该方法利用生成模型的视觉先验，通过统一策略处理多样化的密集预测任务。

研究结果: 在DenseWorld基准测试中，现有方法的性能显著下降，而DenseDiT仅需不到0.01%的训练数据即取得优异结果，展示了其在真实世界部署中的实用价值。

研究结论: DenseDiT通过统一策略和数据高效设计，显著提升了密集预测任务在真实世界场景中的性能，为实际应用提供了有力支持。

中文摘要: 密集预测任务在计算机视觉中具有重要意义，旨在为输入图像学习像素级标注标签。尽管该领域取得了进展，现有方法主要关注理想化条件，对真实世界场景的泛化能力有限，且面临真实数据稀缺的挑战。为系统研究此问题，我们首先引入DenseWorld基准，涵盖25个密集预测任务，对应紧迫的真实世界应用，并提供跨任务的统一评估。随后，我们提出DenseDiT，通过统一策略最大化利用生成模型的视觉先验，执行多样化的真实世界密集预测任务。DenseDiT结合参数重用机制和两个轻量级分支，自适应整合多尺度上下文，仅需不到0.1%的额外参数。在DenseWorld上的评估显示，现有通用和专用基线的性能显著下降，突显其真实世界泛化能力的不足。相比之下，DenseDiT仅需不到0.01%的训练数据即取得优异结果，彰显其在真实世界部署中的实用价值。我们的数据、检查点和代码可在https://xcltql666.github.io/DenseDiTProj获取。

</details>


### [52] [Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion](https://arxiv.org/abs/2506.20293)
**中文标题：突破空间边界：基于光谱域配导的高光谱与多光谱盲融合**

*Kunjing Yang,Libin Zheng,Minru Bai,Ting Lu,Leyuan Fang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于光谱域配准的高光谱与多光谱图像盲融合方法，通过轻量级光谱先验学习网络提升配准精度，并采用盲稀疏融合方法降低计算复杂度，实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在高光谱与多光谱图像配准时因空间分辨率差异大而效果不佳，且处理大尺寸遥感图像时耗时严重。为解决这些问题，本文从光谱域角度提出新方法。

研究方法: 1. 开发轻量级光谱先验学习（SPL）网络提取光谱特征并增强多光谱图像分辨率；2. 通过子空间表示和循环训练策略提升配准后的高光谱图像光谱精度；3. 提出盲稀疏融合（BSF）方法，利用群稀疏正则化降低计算复杂度；4. 使用近端交替优化（PAO）算法求解BSF模型。

研究结果: 在模拟和真实数据集上的实验表明，该方法在配准和融合方面表现优异，同时提升了分类性能。

研究结论: 本文提出的光谱域配准方法有效解决了高光谱与多光谱图像融合中的配准问题，且计算效率高，具有实际应用价值。

中文摘要: 近年来，未配准高光谱图像（HSI）与多光谱图像（MSI）的盲融合受到广泛关注。为解决配准问题，现有方法多采用空间变换将HSI与MSI对齐，但由于图像空间分辨率差异显著，这些方法效果往往不佳。此外，处理大尺寸遥感图像时配准过程耗时严重。为此，本文从光谱域角度解决配准问题。首先，开发轻量级光谱先验学习（SPL）网络提取HSI光谱特征并增强MSI光谱分辨率；随后，对所得图像进行空间下采样生成配准后的HSI，过程中采用子空间表示和循环训练策略提升光谱精度。接着，提出盲稀疏融合（BSF）方法，利用群稀疏正则化等效促进图像低秩性，既避免了秩估计需求，又降低了计算复杂度。然后，采用近端交替优化（PAO）算法求解BSF模型，并分析其收敛性。最后，通过模拟和真实数据集的大量实验验证了该方法在配准和融合中的有效性，并展示了其在提升分类性能方面的优势。

</details>


### [53] [Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations](https://arxiv.org/abs/2506.20294)
**中文标题：Ctrl-Z采样：基于控制随机锯齿探索的扩散采样方法**

*Shunqi Mao,Wei Guo,Chaoyi Zhang,Weidong Cai*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Ctrl-Z采样的新方法，用于在扩散模型中通过控制随机锯齿探索来改进条件生成的质量，避免陷入局部最优。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在条件生成中表现优异，但常因潜在空间复杂性和初始化不佳而陷入局部最优，导致生成结果全局不一致或条件不匹配。现有方法通过增强指导信号或调整初始噪声分布来解决这一问题，但效果有限。

研究方法: Ctrl-Z采样通过奖励模型识别局部最优，并在检测到后注入噪声并回退到更早的噪声状态以逃离当前优化平台。奖励模型评估候选轨迹，仅接受改进的路径，逐步加深回退以增强逃离效果。

研究结果: 实验表明，Ctrl-Z采样显著提升了生成质量，仅需约7.6倍的函数评估开销。

研究结论: Ctrl-Z采样是一种模型无关的方法，可与现有扩散框架兼容，通过动态交替前向优化和后向探索，显著提升生成结果的视觉质量和条件对齐。

中文摘要: 扩散模型通过逐步将高斯噪声去噪为目标数据分布，在条件生成中表现出色。这一去噪过程可视为在潜在空间中进行的一种爬山优化，模型通过迭代将样本向高概率区域细化。然而，由于潜在空间复杂性和初始化不佳，扩散模型常收敛于局部最优，导致生成结果局部视觉一致但全局不一致或条件不匹配。先前研究尝试通过增强指导信号或调整初始噪声分布来解决这一问题。本文提出了一种名为控制随机锯齿采样（Ctrl-Z采样）的新策略，旨在条件生成中检测并逃离局部最优。该方法首先通过奖励模型识别潜在局部最优，随后注入噪声并回退到更早的噪声状态以逃离当前优化平台。奖励模型评估候选轨迹，仅接受改进的路径，而逐步加深的回退可在附近替代方案失败时实现更强的逃离。这种控制随机锯齿过程允许动态交替前向优化和后向探索，从而提升生成结果的视觉质量和条件对齐。所提出的Ctrl-Z采样与模型无关，兼容现有扩散框架。实验结果表明，Ctrl-Z采样显著提升了生成质量，仅需约7.6倍的函数评估开销。

</details>


### [54] [TDiR: Transformer based Diffusion for Image Restoration Tasks](https://arxiv.org/abs/2506.20302)
**中文标题：TDiR：基于Transformer的扩散模型用于图像修复任务**

*Abbas Anwar,Mohammad Shullar,Ali Arshad Nasir,Mudassir Masood,Saeed Anwar*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer和扩散模型的图像修复方法TDiR，旨在提升退化图像的质量，并在多个公开数据集上验证了其优于现有深度学习方法的表现。


<details>
  <summary>详细信息</summary>
研究动机: 在复杂环境中捕获的图像常因噪声、色偏、模糊和光散射等问题导致质量下降，影响其在目标检测、地图绘制和分类等下游任务中的应用。为此，本文开发了一种基于Transformer的扩散模型，专注于图像修复任务。

研究方法: 本文提出了一种结合Transformer和扩散模型的图像修复方法TDiR。该方法通过扩散模型生成高质量图像，并利用Transformer捕捉全局上下文信息，从而有效处理多种退化问题。

研究结果: 实验表明，TDiR在多个公开数据集上（包括水下图像增强、去噪和去雨任务）的性能优于现有深度学习方法，显著提升了退化图像的质量。

研究结论: 本文证明了结合Transformer的扩散模型在图像修复任务中的有效性，能够显著提升图像质量，从而扩展其在需要高保真视觉数据的下游任务中的应用。

中文摘要: 在复杂环境中捕获的图像常因噪声、色偏、模糊和光散射等问题导致质量下降，影响其在目标检测、地图绘制和分类等下游任务中的应用。本文开发了一种基于Transformer的扩散模型，专注于图像修复任务，旨在提升退化图像的质量。该模型在多个公开数据集上针对水下图像增强、去噪和去雨任务进行了评估，并与现有深度学习方法进行了比较。实验结果表明，结合Transformer的扩散模型在性能上超越了现有方法。本文的成果凸显了扩散模型和Transformer在提升退化图像质量方面的有效性，从而扩展了其在需要高保真视觉数据的下游任务中的应用范围。

</details>


### [55] [Radiomic fingerprints for knee MR images assessment](https://arxiv.org/abs/2506.20306)
**中文标题：膝关节MRI图像的放射组学指纹评估**

*Yaxi Chen,Simin Ni,Shaheer U. Saeed,Aleksandra Ivanova,Rikin Hargunani,Jie Huang,Chaozong Liu,Yipeng Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的放射组学指纹框架，通过深度学习模型为每位患者动态构建放射组学特征集，显著提升膝关节MRI诊断的准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的放射组学方法使用固定的特征集，无法充分反映个体病理差异，导致性能受限。本文旨在通过动态特征选择解决这一问题。

研究方法: 提出放射组学指纹框架，利用深度学习模型从大量特征中动态选择与个体患者临床条件相关的特征，并结合低维逻辑回归进行分类。

研究结果: 在膝关节异常、前交叉韧带撕裂和半月板撕裂等诊断任务中，该方法表现优于或与现有端到端深度学习模型相当，同时具有更高的可解释性。

研究结论: 放射组学指纹框架不仅提高了诊断准确性，还为临床提供了有意义的生物标志物发现和解释性分析。

中文摘要: 膝关节MRI扫描的准确解读依赖于专家临床判断，但存在高变异性和有限的可扩展性。现有放射组学方法使用固定的特征集（签名），在群体水平选择并统一应用于所有患者。尽管可解释性强，但这些签名通常过于受限，无法代表个体病理变化。因此，传统的放射组学方法在性能上表现有限，而近期端到端深度学习方法则无需使用可解释的放射组学特征。我们认为，当前放射组学选择中的个体无关性并非其可解释性的核心，而是导致泛化能力差的原因。本文提出了一种新颖的放射组学指纹框架，其中放射组学特征集（指纹）由深度学习模型为每位患者动态构建。与现有签名不同，我们的指纹通过预测大型放射组学特征池中特征的相关性，并仅选择对个体患者临床条件有预测性的特征。放射组学选择模型与低维（相对可解释的）逻辑回归同时训练，用于下游分类。我们在多项诊断任务中验证了该方法，包括一般膝关节异常、前交叉韧带撕裂和半月板撕裂，结果显示其诊断准确性与最先进的端到端深度学习模型相当或更优。更重要的是，我们的方法固有的可解释性为临床提供了有意义的见解和潜在生物标志物发现，并通过真实临床案例的详细讨论、定量和定性分析证明了这些优势。

</details>


### [56] [On the Burstiness of Faces in Set](https://arxiv.org/abs/2506.20312)
**中文标题：关于集合中人脸的突发性现象**

*Jiong Wang*

主要分类: cs.CV

摘要简述: 本文研究了集合中人脸识别中的“突发性”现象，即某些特定属性的人脸在集合中频繁出现，影响训练和评估性能。作者提出三种检测方法，并通过调整采样策略和质量感知机制显著提升识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 在基于集合的人脸识别（SFR）中，突发性现象广泛存在，导致训练集和评估集被某些频繁出现的人脸主导，从而降低模型的泛化能力和评估准确性。本文旨在检测并抑制这种突发性现象，以提升识别性能。

研究方法: 作者提出三种策略检测突发性人脸：基于Quickshift++的方法、特征自相似性方法和广义最大池化（GMP）。在训练和评估阶段，利用检测结果调整低频人脸的采样比例或贡献度。此外，提出质量感知GMP，增强对低质量人脸的鲁棒性。

研究结果: 实验表明，突发性现象在SFR基准测试中普遍存在，通过抑制突发性，识别性能得到显著提升。

研究结论: 突发性现象对人脸识别性能有显著负面影响，通过检测和抑制突发性，可以有效提升模型的泛化能力和评估准确性。

中文摘要: 突发性是指在文本和图像检索中观察到的现象，即某些特定元素在集合中出现的次数比统计独立模型假设的更多。我们认为，在基于集合的人脸识别（SFR）中，突发性现象广泛存在，并在两方面降低性能：首先，突发性人脸（即具有特定属性的人脸在集合中频繁出现）主导训练实例和训练集，导致对无约束场景的泛化能力较差；其次，突发性人脸在评估集中干扰集合验证和识别时的相似性比较。为检测集合中的突发性人脸，我们提出了基于Quickshift++、特征自相似性和广义最大池化（GMP）的三种策略。我们将突发检测结果应用于训练和评估阶段，以增加低频人脸的采样比例或贡献度。在评估时，我们还提出了质量感知GMP，使原始GMP能够感知人脸质量并对低质量人脸具有鲁棒性。我们在SFR基准测试中进行了详细说明和广泛实验，证明突发性现象普遍存在，抑制突发性显著提升了识别性能。

</details>


### [57] [From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents](https://arxiv.org/abs/2506.20326)
**中文标题：从抄本学到代码：基于Transformer和YOLO的历史文档布局分析检测器比较研究**

*Sergio Torres Aguilar*

主要分类: cs.CV

摘要简述: 本文比较了基于Transformer和YOLO的布局分析模型在历史文档中的表现，发现YOLO-OBB在复杂数据集上表现最佳，而Transformer在结构化布局中更优。


<details>
  <summary>详细信息</summary>
研究动机: 历史文档的复杂页面组织对自动化处理提出了挑战，需要评估不同目标检测架构的性能差异。

研究方法: 在三个历史文档数据集（e-NDP、CATMuS、HORAE）上，比较了两种Transformer模型（Co-DETR、Grounding DINO）和三种YOLO变体（AABB、OBB、YOLO-World）的性能。

研究结果: 在e-NDP数据集上，Co-DETR表现最佳（0.752 mAP@.50:.95），而在更复杂的CATMuS和HORAE数据集上，YOLOv11x-OBB显著优于其他模型（0.564和0.568）。

研究结论: 研究证明，使用定向边界框（OBB）是准确建模历史文档非笛卡尔特性的关键，Transformer适合结构化布局，而CNN-OBB模型在视觉多样性和复杂性上表现更优。

中文摘要: 稳健的文档布局分析（DLA）对于自动化处理和理解具有复杂页面组织的历史文档至关重要。本文在三个代表不同抄本复杂性的标注数据集上（e-NDP、CATMuS、HORAE）对五种最先进的目标检测架构进行了基准测试。我们评估了两种基于Transformer的模型（Co-DETR、Grounding DINO）与三种YOLO变体（AABB、OBB、YOLO-World）的性能。结果表明，模型性能显著依赖于架构、数据集特性和边界框表示。在e-NDP数据集上，Co-DETR取得了最佳结果（0.752 mAP@.50:.95），紧随其后的是YOLOv11X-OBB（0.721）。而在更复杂的CATMuS和HORAE数据集上，基于CNN的YOLOv11x-OBB显著优于其他模型（0.564和0.568）。本研究明确表明，使用定向边界框（OBB）不仅是微小改进，而是准确建模历史手稿非笛卡尔特性的基本要求。我们得出结论，Transformer的全局上下文感知能力适合结构化布局，而CNN-OBB模型在视觉多样性和复杂性上具有更优的泛化能力。

</details>


### [58] [Feature Hallucination for Self-supervised Action Recognition](https://arxiv.org/abs/2506.20342)
**中文标题：自监督动作识别的特征幻觉方法**

*Lei Wang,Piotr Koniusz*

主要分类: cs.CV

摘要简述: 本文提出了一种自监督动作识别框架，通过联合预测动作概念和辅助特征，利用幻觉流推断缺失线索，并结合领域特定描述符（ODF和SDF）提升特征表示。该方法在多个基准测试中达到最先进性能。


<details>
  <summary>详细信息</summary>
研究动机: 视频中的人类动作识别不仅依赖于原始像素分析，还需要高级语义推理和多模态特征的有效整合。现有方法在特征表示和计算效率上存在不足，因此需要一种能够增强识别精度并减少计算开销的新框架。

研究方法: 提出了一种深度翻译动作识别框架，通过幻觉流推断缺失线索，结合对象检测特征（ODF）和显著性检测特征（SDF）增强特征表示。同时整合光流、骨架数据等辅助模态，并引入不确定性建模和鲁棒损失函数以处理特征噪声。

研究结果: 该方法在Kinetics-400、Kinetics-600和Something-Something V2等多个基准测试中取得了最先进的性能，验证了其在捕捉细粒度动作动态方面的有效性。

研究结论: 本文提出的多模态自监督动作识别框架通过联合预测和幻觉流技术显著提升了识别精度，同时保持了计算效率，为动作识别领域提供了新的解决方案。

中文摘要: 理解视频中的人类动作不仅需要原始像素分析，还依赖于高级语义推理和多模态特征的有效整合。我们提出了一种深度翻译动作识别框架，通过联合预测RGB视频帧中的动作概念和辅助特征来提升识别精度。在测试时，幻觉流推断缺失线索，丰富特征表示而不增加计算开销。为了关注动作相关区域，我们引入了两种新的领域特定描述符：对象检测特征（ODF）通过聚合多个检测器的输出捕捉上下文线索，而显著性检测特征（SDF）突出对动作识别至关重要的空间和强度模式。我们的框架将这些描述符与光流、改进的密集轨迹、骨架数据和音频线索等辅助模态无缝整合。该方法与I3D、AssembleNet、Video Transformer Network等先进架构兼容。为了处理辅助特征的不确定性，我们在幻觉步骤中引入了随机不确定性建模，并提出了一种鲁棒损失函数以减少特征噪声。我们的多模态自监督动作识别框架在Kinetics-400、Kinetics-600和Something-Something V2等多个基准测试中达到了最先进的性能，证明了其在捕捉细粒度动作动态方面的有效性。

</details>


### [59] [InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking](https://arxiv.org/abs/2506.20370)
**中文标题：InvZW：基于噪声对抗训练的鲁棒图像零水印不变特征学习**

*Abdullah All Tanvir,Xin Zhong*

主要分类: cs.CV

摘要简述: 本文提出了一种基于失真不变特征学习的深度学习框架，用于鲁棒的图像零水印技术。通过噪声对抗训练学习不变特征，并结合多比特零水印方案，实现了高鲁棒性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统的图像水印技术可能对原始图像造成修改，且对失真鲁棒性不足。本文旨在开发一种零水印方法，既能保持图像完整性，又能通过不变特征学习抵抗多种失真。

研究方法: 方法分为两个模块：1) 通过噪声对抗训练学习失真不变的特征表示，结合对抗监督和重建约束；2) 设计基于学习的多比特零水印方案，将不变特征投影到可训练的参考码上以匹配目标二进制消息。

研究结果: 实验表明，该方法在多种图像数据集和失真条件下，特征稳定性和水印恢复能力均达到最优水平，显著优于现有的自监督和深度学习水印技术。

研究结论: 本文提出的框架在零水印技术中实现了高鲁棒性和泛化能力，为图像水印领域提供了新的解决方案。

中文摘要: 本文提出了一种基于失真不变特征学习的深度学习框架，用于鲁棒的图像零水印技术。作为一种零水印方案，该方法不修改原始图像，而是通过特征空间优化学习参考签名。框架包含两个关键模块：第一个模块通过噪声对抗训练特征提取器，生成对失真不变且语义表达丰富的特征表示，结合对抗监督和重建约束；第二个模块设计了一种基于学习的多比特零水印方案，将训练好的不变特征投影到一组可训练的参考码上以匹配目标二进制消息。在多种图像数据集和失真条件下的广泛实验表明，该方法在特征稳定性和水印恢复方面均达到最优水平。与现有的自监督和深度学习水印技术的对比进一步验证了该框架在泛化能力和鲁棒性上的优势。

</details>


### [60] [Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking](https://arxiv.org/abs/2506.20381)
**中文标题：利用轻量级分层ViT和动态框架实现高效视觉跟踪**

*Ben Kang,Xin Chen,Jie Zhao,Chunjuan Bo,Dong Wang,Huchuan Lu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于轻量级分层ViT和动态框架的高效视觉跟踪方法HiT和DyHiT，通过Bridge Module和双图像位置编码提升性能，并在速度和精度上取得显著优势。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于Transformer的视觉跟踪器在性能上有显著提升，但其在资源受限设备上的实用性因处理速度慢而受限。本文旨在设计高效的跟踪模型，兼顾高性能和快速运行。

研究方法: HiT通过Bridge Module连接轻量级Transformer与跟踪框架，并采用双图像位置编码；DyHiT则通过动态路由分类场景并选择计算路径，实现精度与速度的平衡。

研究结果: HiT在NVIDIA Jetson AGX上达到61 fps，LaSOT基准测试AUC为64.6%；DyHiT最快版本达111 fps，AUC为62.4%。此外，提出的训练免费加速方法显著提升了其他高性能跟踪器的速度。

研究结论: HiT和DyHiT在高效视觉跟踪中表现出色，动态路由策略为资源受限设备提供了实用解决方案，同时提出的加速方法进一步扩展了其应用潜力。

中文摘要: 基于Transformer的视觉跟踪器因其强大的建模能力取得了显著进展，但其在资源受限设备上的实用性因处理速度慢而受限。为解决这一问题，我们提出了HiT，一种新型高效跟踪模型家族，能够在多种设备上实现高性能和快速运行。HiT的核心创新在于其Bridge Module，该模块将轻量级Transformer与跟踪框架连接，提升了特征表示质量。此外，我们引入了双图像位置编码方法以有效编码空间信息。HiT在NVIDIA Jetson AGX平台上达到61帧每秒（fps）的速度，并在LaSOT基准测试中取得64.6%的AUC，优于所有先前的高效跟踪器。基于HiT，我们进一步提出了DyHiT，一种高效的动态跟踪器，通过选择不同计算需求的路径灵活适应场景复杂度。DyHiT利用主干网络提取的搜索区域特征，并将其输入高效的动态路由器以分类跟踪场景。根据分类结果，DyHiT采用分治策略，选择合适路径以实现精度与速度的优越平衡。DyHiT的最快版本在NVIDIA Jetson AGX上达到111 fps，同时保持LaSOT上62.4%的AUC。此外，我们基于DyHiT的动态路由架构提出了一种无需训练的加速方法。该方法显著提升了多种高性能跟踪器的执行速度，且不牺牲精度。例如，我们的加速方法使最先进的跟踪器SeqTrack-B256在NVIDIA GeForce RTX 2080 Ti GPU上实现了2.68倍的速度提升，同时保持LaSOT上69.9%的AUC。

</details>


### [61] [A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management](https://arxiv.org/abs/2506.20388)
**中文标题：一种基于大型视觉基础模型（LVFM）的高分辨率人工林冠层高度图生成方法及其在精准林业管理中的应用**

*Shen Tan,Xin Zhang,Liangxiu Han,Huaguo Huang,Han Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于大型视觉基础模型（LVFM）的新方法，用于生成高分辨率冠层高度图（CHM），以支持精准林业管理。该方法在北京市房山区的测试中表现优异，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 精确且经济地监测人工林地上生物量（AGB）对于支持当地生计和碳汇计划（如中国核证减排量CCER）至关重要。传统激光雷达方法成本高昂，而基于RGB图像的深度学习方法在提取冠层高度特征方面仍存在挑战。

研究方法: 研究团队开发了一种新型模型，结合了特征提取器、自监督特征增强模块和高度估计器，利用大型视觉基础模型（LVFM）生成高分辨率冠层高度图。

研究结果: 在北京市房山区使用1米分辨率的Google Earth图像进行测试，该模型的平均绝对误差为0.09米，均方根误差为0.24米，与激光雷达生成的冠层高度图的相关系数为0.78。此外，该方法在单木检测中成功率超过90%，AGB估算精度高，并能有效跟踪人工林生长。

研究结论: 该方法为评估人工林和天然林的碳汇潜力提供了一种高效、可扩展的工具，具有广泛的应用前景。

中文摘要: 精确且经济地监测人工林地上生物量（AGB）对于支持当地生计和碳汇计划（如中国核证减排量CCER）至关重要。高分辨率冠层高度图（CHM）是实现这一目标的关键，但传统的激光雷达方法成本高昂。尽管基于RGB图像的深度学习提供了一种替代方案，但准确提取冠层高度特征仍具挑战性。为此，我们开发了一种基于大型视觉基础模型（LVFM）的新型高分辨率CHM生成模型。该模型集成了特征提取器、自监督特征增强模块和高度估计器。在北京市房山区使用1米分辨率的Google Earth图像进行测试时，该模型的表现优于现有方法（包括传统卷积神经网络），其平均绝对误差为0.09米，均方根误差为0.24米，与激光雷达生成的CHM的相关系数为0.78。生成的CHM在单木检测中成功率超过90%，AGB估算精度高，并能有效跟踪人工林生长，显示出对非训练区域的强泛化能力。该方法为评估人工林和天然林的碳汇潜力提供了一种高效、可扩展的工具。

</details>


### [62] [Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation](https://arxiv.org/abs/2506.20449)
**中文标题：Med-Art：基于扩散变换器的二维医学文本到图像生成**

*Changlu Guo,Anders Nymark Christensen,Morten Rieger Hannemose*

主要分类: cs.CV

摘要简述: Med-Art是一种专为医学图像生成设计的框架，通过结合视觉语言模型和扩散变换器（DiT），解决了医学文本数据稀缺和小数据集的问题，并提出了混合级扩散微调方法（HLDF），在医学图像生成任务中取得了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到图像生成模型在医学领域的应用面临数据集小、医学文本数据稀缺等挑战，因此需要一种能够在有限数据下高效生成医学图像的解决方案。

研究方法: Med-Art利用视觉语言模型生成医学图像的视觉描述，解决了文本数据稀缺问题；基于扩散变换器（DiT）的PixArt-α模型进行适配，并提出混合级扩散微调（HLDF）方法，优化像素级损失，避免颜色过饱和等问题。

研究结果: 在两个医学图像数据集上，Med-Art在FID、KID和下游分类任务中均取得了最先进的性能。

研究结论: Med-Art通过创新的方法解决了医学图像生成中的关键问题，为医学领域的文本到图像生成提供了高效且性能优越的解决方案。

中文摘要: 近年来，文本到图像生成模型取得了显著突破，但其在医学图像生成中的应用仍面临数据集规模小、医学文本数据稀缺等重大挑战。为解决这些问题，我们提出了Med-Art，一种专为有限数据下的医学图像生成设计的框架。Med-Art利用视觉语言模型生成医学图像的视觉描述，克服了医学文本数据稀缺的问题。Med-Art基于扩散变换器（DiT）对预训练的大规模文本到图像模型PixArt-α进行适配，在有限数据下实现了高性能。此外，我们提出了一种创新的混合级扩散微调（HLDF）方法，通过像素级损失有效解决了颜色过饱和等问题。在两个医学图像数据集上，Med-Art在FID、KID和下游分类任务中均取得了最先进的性能。

</details>


### [63] [HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling](https://arxiv.org/abs/2506.20452)
**中文标题：HiWave：基于小波扩散采样的免训练高分辨率图像生成**

*Tobias Vontobel,Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber*

主要分类: cs.CV

摘要简述: HiWave是一种无需训练的高分辨率图像生成方法，通过基于小波的扩散采样技术，显著提升超高清图像合成的视觉保真度和结构一致性。


<details>
  <summary>详细信息</summary>
研究动机: 当前扩散模型在高分辨率图像合成中面临计算成本高和零样本生成技术易产生伪影的问题，HiWave旨在解决这些挑战，提供无需重新训练的高质量超高清图像生成方案。

研究方法: HiWave采用两阶段流程：首先生成基础图像，随后通过基于小波的细节增强模块，保留低频成分以确保结构一致性，同时选择性增强高频细节。

研究结果: 实验表明，HiWave在Stable Diffusion XL上有效减少了伪影，用户研究中80%以上的对比案例中优于现有技术。

研究结论: HiWave为无需重新训练或架构修改的超高清图像合成提供了高效且高质量的解决方案。

中文摘要: 扩散模型已成为图像合成的主流方法，展现出卓越的逼真性和多样性。然而，高分辨率下的扩散模型训练计算成本极高，而现有的零样本生成技术在超出训练分辨率时往往产生伪影，如物体重复和空间不连贯。本文提出HiWave，一种免训练的零样本方法，利用预训练扩散模型显著提升超高清图像合成的视觉保真度和结构一致性。我们的方法采用两阶段流程：首先生成基础图像，随后进行基于小波的细节增强模块处理。具体而言，我们首先利用反演方法从基础图像中提取保持全局一致性的初始噪声向量；随后在采样过程中，通过小波域细节增强模块保留基础图像的低频成分以确保结构一致性，同时选择性引导高频成分以丰富细节和纹理。在Stable Diffusion XL上的广泛评估表明，HiWave有效减少了现有方法中常见的视觉伪影，实现了卓越的感知质量。用户研究证实了HiWave的性能，在80%以上的对比案例中优于现有技术，凸显了其在无需重新训练或架构修改的情况下实现高质量超高清图像合成的有效性。

</details>


### [64] [A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners](https://arxiv.org/abs/2506.20464)
**中文标题：基于深度学习的移动激光扫描仪捕获的地下矿山复杂3D点云中岩石锚杆识别方法**

*Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DeepBolt的两阶段深度学习架构，用于在复杂的地下矿山3D点云中自动高效识别岩石锚杆，显著优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 地下矿山中的岩石锚杆是支撑系统的关键部件，但其手动检测因环境恶劣且耗时而不切实际。现有自动化方法因数据噪声和环境复杂性缺乏鲁棒性，亟需一种更高效的解决方案。

研究方法: 提出DeepBolt方法，采用两阶段深度学习架构，专门针对类别不平衡问题，优化岩石锚杆在复杂3D点云中的识别。

研究结果: DeepBolt在岩石锚杆点的交并比（IoU）上比现有语义分割模型提升42.5%，分类精度和召回率分别达到96.41%和96.96%。

研究结论: DeepBolt在复杂地下环境中表现出色，为岩石锚杆的自动化检测提供了高效且鲁棒的解决方案。

中文摘要: 岩石锚杆是地下矿山支撑系统的关键部件，对维持岩体稳定性和减少风险至关重要。然而，地下矿山光线不足且手动检测耗时，自动化检测成为可行方案。现有方法依赖特征工程和传统机器学习，但因数据噪声和环境复杂性缺乏鲁棒性。本文提出DeepBolt方法，采用两阶段深度学习架构，专门针对类别不平衡问题，高效识别复杂3D点云中的岩石锚杆。实验表明，DeepBolt在岩石锚杆点的交并比（IoU）上比现有模型提升42.5%，分类精度和召回率分别达到96.41%和96.96%，证明了其在复杂环境中的鲁棒性和有效性。

</details>


### [65] [AI-assisted radiographic analysis in detecting alveolar bone-loss severity and patterns](https://arxiv.org/abs/2506.20522)
**中文标题：AI辅助放射影像分析在检测牙槽骨流失严重程度和模式中的应用**

*Chathura Wimalasiri,Piumal Rathnayake,Shamod Wijerathne,Sumudu Rasnayaka,Dhanushka Leuke Bandara,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

主要分类: cs.CV

摘要简述: 本文提出了一种基于AI的深度学习框架，用于自动检测和量化牙槽骨流失的严重程度和模式，通过结合YOLOv8和Keypoint R-CNN模型，实现了高精度的骨流失分析和分类。


<details>
  <summary>详细信息</summary>
研究动机: 牙周炎是一种慢性炎症性疾病，会导致牙槽骨流失，严重影响口腔健康和生活质量。准确评估骨流失的严重程度和模式对诊断和治疗规划至关重要。

研究方法: 研究结合YOLOv8进行牙齿检测，使用Keypoint R-CNN模型识别解剖标志物，并通过YOLOv8x-seg模型分割骨水平和牙齿掩模，利用几何分析确定骨流失模式（水平或角度）。

研究结果: 在1000张专业标注的X光片数据集上，该方法在检测骨流失严重程度（组内相关系数达0.80）和骨流失模式分类（准确率87%）方面表现出高精度。

研究结论: 该自动化系统为牙周评估提供了快速、客观且可重复的工具，减少了对主观人工评估的依赖，有望改善牙周炎的早期诊断和个性化治疗规划。

中文摘要: 牙周炎是一种导致牙槽骨流失的慢性炎症性疾病，严重影响口腔健康和生活质量。准确评估骨流失的严重程度和模式对诊断和治疗规划至关重要。本研究提出了一种基于AI的深度学习框架，通过口内根尖X光片自动检测和量化牙槽骨流失及其模式。我们的方法结合YOLOv8进行牙齿检测，并使用Keypoint R-CNN模型识别解剖标志物，从而精确计算骨流失的严重程度。此外，YOLOv8x-seg模型分割骨水平和牙齿掩模，通过几何分析确定骨流失模式（水平或角度）。在1000张专业标注的X光片数据集上评估，我们的方法在检测骨流失严重程度（组内相关系数达0.80）和骨流失模式分类（准确率87%）方面表现出高精度。这一自动化系统为牙周评估提供了快速、客观且可重复的工具，减少了对主观人工评估的依赖。通过将AI整合到牙科放射影像分析中，我们的框架有望改善牙周炎的早期诊断和个性化治疗规划，最终提升患者护理和临床效果。

</details>


### [66] [Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks](https://arxiv.org/abs/2506.20548)
**中文标题：减少对欺骗性伪影的关注：在线社交网络中压缩深度伪造的鲁棒检测**

*Manyi Li,Renshuai Tao,Yufan Liu,Chuangchuang Tan,Haotong Qin,Bing Li,Yunchao Wei,Yao Zhao*

主要分类: cs.CV

摘要简述: 本文提出PLADA框架，通过消除压缩引起的块效应和利用开放数据聚合，显著提升在线社交网络中压缩深度伪造图像的检测效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有深度伪造检测方法忽视在线社交网络中图像压缩引入的块效应，且主要依赖原始图像，难以应对实际场景中的压缩图像检测需求。

研究方法: PLADA框架包含两个核心模块：块效应消除器（B2E）通过双阶段注意力机制处理块效应；开放数据聚合（ODA）利用配对和非配对数据提升检测能力。

研究结果: 在26个数据集上的实验表明，PLADA在压缩深度伪造检测中表现优异，即使数据有限也能超越现有方法。

研究结论: PLADA不仅解决了压缩图像的检测难题，还首次将块效应作为关键因素引入深度伪造检测领域，为开放场景提供了鲁棒解决方案。

中文摘要: 随着深度学习的快速发展，尤其是生成对抗网络（GANs）和扩散模型（DMs）的应用，AI生成的图像（即“深度伪造”）已几乎无法与真实图像区分。这些图像在在线社交网络（OSNs）上广泛传播，引发了对其滥用的担忧。现有的深度伪造检测方法忽视了OSNs中压缩引入的“块效应”，这些效应掩盖了深度伪造的伪影，且主要关注原始图像，而实际场景中很少遇到。为解决这些问题，我们提出了PLADA（减少对欺骗性伪影的关注），一种新颖的框架，旨在解决配对数据不足和压缩图像利用效率低的问题。PLADA包含两个核心模块：块效应消除器（B2E），通过双阶段注意力机制处理块效应；开放数据聚合（ODA），处理配对和非配对数据以提升检测能力。在26个数据集上的广泛实验表明，PLADA在深度伪造检测中实现了显著平衡，即使数据有限和压缩情况下，仍优于现有方法。更重要的是，本研究首次将“块效应”作为深度伪造检测的关键因素，为开放场景提供了鲁棒解决方案。代码已开源：https://github.com/ManyiLee/PLADA。

</details>


### [67] [Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos](https://arxiv.org/abs/2506.20550)
**中文标题：轻量级多帧集成：提升YOLO视频目标检测鲁棒性**

*Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级多帧集成方法，通过堆叠连续帧输入YOLO检测器，仅监督目标帧输出，显著提升了视频中目标检测的鲁棒性，同时保持模型的轻量化和实时性。


<details>
  <summary>详细信息</summary>
研究动机: 现代基于图像的目标检测模型（如YOLOv7）通常独立处理单帧，忽略了视频中的宝贵时间上下文。现有视频检测方法则因引入复杂时序模块而增加模型复杂度和计算成本。针对监控和自动驾驶中的瞬时挑战（如运动模糊、遮挡和外观突变），本文旨在提出一种简单高效的解决方案。

研究方法: 本文提出了一种轻量级策略：将连续多帧堆叠作为YOLO检测器的输入，但仅监督目标帧的输出。该方法通过最小化对现有架构的修改，保留了模型的轻量化和实时推理能力。

研究结果: 在MOT20Det和自建的BOAT360数据集上的实验表明，该方法显著提升了检测鲁棒性，尤其对轻量模型效果明显，缩小了轻量与重型检测网络的性能差距。此外，本文贡献了BOAT360数据集，支持未来多帧视频目标检测研究。

研究结论: 本文提出的多帧集成方法有效利用了时间信息，提升了视频目标检测的鲁棒性，同时保持了模型的轻量化和实时性。BOAT360数据集的发布为相关研究提供了新的基准。

中文摘要: 现代基于图像的目标检测模型（如YOLOv7）通常独立处理单帧，忽略了视频中的时间上下文。现有视频检测方法则因引入复杂时序模块而增加模型复杂度和计算成本。针对监控和自动驾驶中的瞬时挑战（如运动模糊、遮挡和外观突变），本文提出了一种简单高效的策略：将连续多帧堆叠作为YOLO检测器的输入，但仅监督目标帧的输出。该方法通过最小化对现有架构的修改，保留了模型的轻量化和实时推理能力。在MOT20Det和自建的BOAT360数据集上的实验表明，该方法显著提升了检测鲁棒性，尤其对轻量模型效果明显，缩小了轻量与重型检测网络的性能差距。此外，本文贡献了BOAT360数据集，支持未来多帧视频目标检测研究。

</details>


### [68] [AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.20563)
**中文标题：AdvMIM：基于对抗性掩码图像建模的半监督医学图像分割方法**

*Lei Zhu,Jun Zhou,Rick Siow Mong Goh,Yong Liu*

主要分类: cs.CV

摘要简述: 提出了一种对抗性掩码图像建模方法（AdvMIM），通过增强监督信号和减少域间差距，显著提升了半监督医学图像分割中Transformer的性能。


<details>
  <summary>详细信息</summary>
研究动机: Transformer在医学图像分割中表现优异，但需要大量标注数据。半监督学习场景下，标注数据有限，现有方法难以有效训练Transformer。因此，本文提出AdvMIM，以增强监督信号并提升Transformer在半监督学习中的表现。

研究方法: 通过掩码图像建模构建辅助域，利用标注数据和伪标签训练Transformer预测完整分割掩码。提出对抗训练损失以减少原始域与掩码域之间的差距，并扩展该方法至CNN网络。

研究结果: 在三个公开医学图像分割数据集上的实验表明，AdvMIM显著优于现有方法。

研究结论: AdvMIM通过增强监督信号和域间对齐，有效提升了半监督医学图像分割的性能，为Transformer在标注稀缺场景中的应用提供了新思路。

中文摘要: 视觉Transformer因其在捕获长距离依赖方面的优势，近年来在医学图像分割任务中广受欢迎。然而，Transformer需要大量标注数据才能发挥效果，这限制了其在标注稀缺的半监督学习场景中的应用。现有的半监督学习方法通过组合CNN与Transformer进行交叉学习，取得了不错的效果，但在标注数据有限的情况下，如何有效训练Transformer仍具挑战性。本文提出了一种对抗性掩码图像建模方法（AdvMIM），以充分释放Transformer在半监督医学图像分割中的潜力。半监督学习中Transformer的关键挑战在于缺乏足够的监督信号。为此，我们通过掩码图像建模从原始域构建辅助域，并训练Transformer利用掩码输入预测完整分割掩码，以增强监督信号。我们利用标注数据的原始标签和未标注数据的伪标签学习掩码域。为进一步使原始域受益于掩码域，我们从多域学习的角度对方法进行了理论分析，并设计了一种新颖的对抗训练损失以减少原始域与掩码域之间的差距，从而提升半监督学习性能。我们还将对抗性掩码图像建模扩展至CNN网络。在三个公开医学图像分割数据集上的大量实验证明了该方法的有效性，其性能显著优于现有方法。代码已开源：https://github.com/zlheui/AdvMIM。

</details>


### [69] [Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization](https://arxiv.org/abs/2506.20567)
**中文标题：展示、讲述与总结：基于视觉线索辅助句子总结的密集视频描述**

*Zhiwang Zhang,Dong Xu,Wanli Ouyang,Chuanqi Tan*

主要分类: cs.CV

摘要简述: 本文提出了一种基于分割与总结（DaS）框架的密集视频描述方法，通过将长视频分割为多个事件提案，并利用视觉特征和句子生成技术，最终通过两阶段LSTM网络生成描述性句子。


<details>
  <summary>详细信息</summary>
研究动机: 密集视频描述任务需要从长视频中提取多个事件并生成描述，现有方法在语义和视觉信息结合上存在不足。本文旨在通过结合视觉特征和句子总结技术，提升描述的准确性和丰富性。

研究方法: 方法包括：1) 将长视频分割为多个事件提案，每个提案包含多个短视频段；2) 提取每个段的视觉特征（如C3D特征），并生成句子描述；3) 提出两阶段LSTM网络，结合视觉特征和语义信息，通过分层注意力机制生成最终描述。

研究结果: 在ActivityNet Captions数据集上的实验表明，提出的DaS框架在密集视频描述任务中表现优异，生成的描述更具语义丰富性和准确性。

研究结论: 本文提出的DaS框架通过结合视觉特征和句子总结技术，有效提升了密集视频描述的质量，为未来相关研究提供了新思路。

中文摘要: 本文提出了一种基于分割与总结（DaS）框架的密集视频描述方法。首先将未修剪的长视频分割为多个事件提案，每个提案包含多个短视频段。随后提取每个段的视觉特征（如C3D特征），并利用现有图像/视频描述方法为每个段生成一句描述。考虑到生成的句子包含关于整个事件提案的丰富语义信息，我们将密集视频描述任务视为视觉线索辅助的句子总结问题，并提出了一种新的两阶段长短时记忆（LSTM）方法，结合分层注意力机制，利用视觉特征将所有生成的句子总结为一句描述性句子。具体而言，第一阶段LSTM网络将生成的句子中的所有语义词和事件提案中所有段的视觉特征作为输入，作为编码器有效总结与该事件提案相关的语义和视觉信息。第二阶段LSTM网络将第一阶段LSTM网络的输出和事件提案中所有视频段的视觉特征作为输入，作为解码器生成该事件提案的描述性句子。在ActivityNet Captions数据集上的综合实验证明了我们新提出的DaS框架在密集视频描述任务中的有效性。

</details>


### [70] [Causal Representation Learning with Observational Grouping for CXR Classification](https://arxiv.org/abs/2506.20582)
**中文标题：基于观察分组的因果表示学习在胸部X光分类中的应用**

*Rajat Rasal,Avinash Kori,Ben Glocker*

主要分类: cs.CV

摘要简述: 本文提出了一种通过观察分组学习可识别因果表示的方法，用于胸部X光分类，实验表明该方法能提高模型的泛化性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 在医学影像领域，可识别因果表示学习能够揭示数据生成过程中的真实因果关系，从而提升任务特定潜在特征的泛化性和鲁棒性。

研究方法: 通过引入观察分组的概念，利用端到端框架学习可识别表示，用于胸部X光分类，并通过分组强制模型对种族、性别和成像视角等变量保持不变性。

研究结果: 实验结果表明，使用分组学习的因果表示在多个分类任务中显著提高了模型的泛化性和鲁棒性。

研究结论: 通过观察分组学习因果表示是一种有效的方法，能够提升医学影像分类任务的性能，尤其是在面对不同种族、性别和成像视角时。

中文摘要: 可识别因果表示学习旨在揭示数据生成过程中的真实因果关系。在医学影像领域，这为提高任务特定潜在特征的泛化性和鲁棒性提供了机会。本研究引入了观察分组的概念，通过端到端框架学习可识别表示，用于胸部X光分类。实验表明，当利用分组强制模型对种族、性别和成像视角等变量保持不变性时，这些因果表示能够显著提高模型在多个分类任务中的泛化性和鲁棒性。

</details>


### [71] [Dense Video Captioning using Graph-based Sentence Summarization](https://arxiv.org/abs/2506.20583)
**中文标题：基于图句子总结的密集视频描述**

*Zhiwang Zhang,Dong Xu,Wanli Ouyang,Luping Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图的分割与总结（GPaS）框架，用于密集视频描述任务。通过将事件提案分割为短片段并利用图卷积网络（GCN）和长短期记忆网络（LSTM）的交互模块（GLI）进行句子总结，显著提升了描述效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有密集视频描述方法未能充分探索事件提案内的场景演变，导致在场景和对象变化较长的提案中表现不佳。本文旨在通过更细粒度的分割和句子总结来解决这一问题。

研究方法: 提出GPaS框架，分为分割和总结两阶段。分割阶段将事件提案拆分为短片段进行描述；总结阶段通过GCN-LSTM交互模块（GLI）将片段句子总结为完整事件描述。

研究结果: 在ActivityNet Captions和YouCook II数据集上的实验表明，该方法优于现有技术，验证了其有效性。

研究结论: GPaS框架通过细粒度分割和句子总结显著提升了密集视频描述的性能，尤其在长事件提案中表现突出。

中文摘要: 近年来，密集视频描述在检测和描述长未剪辑视频中的所有事件方面取得了显著进展。尽管结果令人鼓舞，但现有方法未能充分探索事件提案内的场景演变，导致在场景和对象变化较长的提案中表现不佳。为解决这一问题，我们提出了一种基于图的分割与总结（GPaS）框架，分为两阶段：分割阶段将整个事件提案拆分为短片段进行更细粒度的描述；总结阶段将每个片段的描述句子总结为完整事件描述。我们特别关注总结阶段，提出了一种通过将语义词视为图中的节点并利用图卷积网络（GCN）和长短期记忆网络（LSTM）的交互模块（GLI）学习其关系的框架。实验在ActivityNet Captions和YouCook II数据集上验证了该方法的有效性。

</details>


### [72] [Learning-Based Distance Estimation for 360° Single-Sensor Setups](https://arxiv.org/abs/2506.20586)
**中文标题：基于学习的360°单传感器距离估计方法**

*Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell*

主要分类: cs.CV

摘要简述: 本文提出了一种基于神经网络的方法，用于通过单目360°鱼眼镜头相机进行距离估计，克服了传统几何方法在透镜畸变和环境变化中的局限性。实验表明，该方法在多个数据集上优于传统几何方法和基线学习模型。


<details>
  <summary>详细信息</summary>
研究动机: 在机器人感知中，准确的单目距离估计是一个关键挑战，尤其是在全向成像中，传统几何方法因透镜畸变和环境多样性而表现不佳。本文旨在通过深度学习提供一种更鲁棒且适应性强的解决方案。

研究方法: 本文提出了一种神经网络模型，直接从原始全向输入中学习并推断物体距离，避免了传统方法对精确透镜校准的依赖。该方法在三个不同的360°数据集（LOAF、ULM360和Boat360）上进行了评估。

研究结果: 实验结果表明，所提出的基于学习的方法在准确性和鲁棒性上均优于传统几何方法和其他学习基线，展示了深度学习在全向距离估计中的潜力。

研究结论: 本文的方法为低成本机器人、自主导航和监控应用提供了一种高效的全向距离估计解决方案，证明了深度学习在此领域的优势。

中文摘要: 准确的单目距离估计是机器人感知中的一个基本挑战，尤其是在全向成像中，传统几何方法因透镜畸变和环境多样性而表现不佳。本文提出了一种基于神经网络的方法，用于通过单目360°鱼眼镜头相机进行距离估计。与依赖精确透镜校准的传统三角测量技术不同，我们的方法直接从原始全向输入中学习并推断物体距离，具有更强的鲁棒性和适应性。我们在三个360°数据集（LOAF、ULM360和新捕获的Boat360）上评估了该方法，每个数据集代表不同的环境和传感器配置。实验结果表明，所提出的基于学习的模型在准确性和鲁棒性上均优于传统几何方法和其他学习基线。这些发现凸显了深度学习在全向距离估计中的潜力，使我们的方法特别适合机器人、自主导航和监控等低成本应用。

</details>


### [73] [TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness](https://arxiv.org/abs/2506.20588)
**中文标题：TRIM：一种最大化时间相对信息与代表性的自监督视频摘要框架**

*Pritam Mishra,Coloma Ballester,Dimosthenis Karatzas*

主要分类: cs.CV

摘要简述: 本文提出了一种自监督视频摘要框架TRIM，通过最大化时间相对信息和代表性，无需依赖监督标注或复杂注意力模型，在SUMME和TVSUM数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着视频内容的普及，高效获取关键信息的需求日益增长，但现有方法依赖监督标注或计算昂贵的注意力模型，且跨域适应性差。本文旨在开发一种高效、无需标注的自监督视频摘要方法。

研究方法: TRIM框架结合了马尔可夫过程驱动的损失指标和两阶段自监督学习范式，无需注意力机制、RNN或Transformer，同时捕捉时空依赖性。

研究结果: 在SUMME和TVSUM数据集上，TRIM表现优于所有无监督方法，并与最佳监督模型媲美，展示了高效且无需标注的潜力。

研究结论: TRIM为通用视频摘要技术开辟了新途径，挑战了对复杂架构的依赖，推动了高效自监督方法的发展。

中文摘要: 视频内容的日益普及及其对高效获取关键信息的需求，使得视频摘要和视频高光成为重要研究领域。然而，许多最先进方法严重依赖监督标注或基于注意力的模型，这些模型计算成本高且在分布偏移时表现脆弱，阻碍了跨数据集的适用性。我们提出了一种开创性的自监督视频摘要模型，无需注意力、RNN或Transformer的开销即可捕捉时空依赖性。我们的框架整合了一套新颖的马尔可夫过程驱动损失指标和两阶段自监督学习范式，确保性能和效率。我们的方法在SUMME和TVSUM数据集上达到了最先进的性能，优于所有现有的无监督方法，并与最佳监督模型媲美，展示了高效、无需标注架构的潜力。这为更通用的视频摘要技术铺平了道路，并挑战了对复杂架构的普遍依赖。

</details>


### [74] [WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration](https://arxiv.org/abs/2506.20590)
**中文标题：WonderFree：提升3D场景探索的新视角质量与跨视角一致性**

*Chaojun Ni,Jie Li,Haoyun Li,Hengyu Liu,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Boyuan Wang,Chenxin Li,Guan Huang,Wenjun Mei*

主要分类: cs.CV

摘要简述: WonderFree是一种新型3D场景生成模型，通过提升新视角质量和跨视角一致性，实现高质量、沉浸式的3D场景探索。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D生成方法在探索性上存在局限，无法在超出原始视角的大范围移动中生成高质量图像，尤其是在进入未观察区域时。

研究方法: WonderFree通过WorldRestorer消除新视角中的视觉伪影和漂浮物，并通过ConsistView机制提升跨视角的空间一致性。同时，提出自动数据收集流程以支持模型训练。

研究结果: 实验表明，WonderFree显著提升了渲染质量和全局一致性，用户研究中77.20%的参与者更偏好WonderFree。

研究结论: WonderFree为3D场景探索提供了高质量和一致性的解决方案，代码、模型和数据将公开。

中文摘要: 基于单张图像的交互式3D场景生成因其创建沉浸式虚拟世界的潜力而备受关注。然而，当前3D生成方法的一个关键挑战是探索性有限，无法在超出原始视角的大范围移动中渲染高质量图像，尤其是在尝试进入未观察区域时。为解决这一问题，我们提出了WonderFree，这是首个允许用户从任意角度和方向自由探索3D世界的模型。具体而言，我们将这一挑战分解为两个关键子问题：新视角质量（解决新视角中的视觉伪影和漂浮问题）和跨视角一致性（确保不同视角间的空间一致性）。为提升新视角的渲染质量，我们引入了WorldRestorer，一种数据驱动的视频修复模型，用于消除漂浮物和伪影。此外，还提出了一种自动数据收集流程，为WorldRestorer的训练数据提供支持，确保其能够处理3D场景生成中所需的多样化场景风格。为进一步提升跨视角一致性，我们提出了ConsistView，一种多视角联合修复机制，能够在保持时空一致性的同时同时修复多个视角。实验结果表明，WonderFree不仅提升了多样化视角下的渲染质量，还显著改善了全局一致性和连贯性。这些改进通过基于CLIP的指标和用户研究得到验证，用户研究中77.20%的参与者更偏好WonderFree而非WonderWorld，从而实现了无缝且沉浸式的3D探索体验。代码、模型和数据将公开提供。

</details>


### [75] [SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection](https://arxiv.org/abs/2506.20599)
**中文标题：SFNet：融合空间与频域特征的遥感图像伪造检测**

*Ji Qi,Xinchang Zhang,Dingqi Ye,Yongjia Ruan,Xin Guo,Shaowen Wang,Haifeng Li*

主要分类: cs.CV

摘要简述: SFNet是一种新型遥感图像伪造检测框架，通过融合空间和频域特征，显著提升检测准确率，并在多个数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式人工智能的快速发展，伪造的遥感图像越来越难以检测，可能导致错误情报和虚假新闻。现有方法依赖单一视觉特征，难以应对多样化的伪造场景。因此，需要一种能够结合多域特征的方法来提高检测的泛化能力。

研究方法: SFNet采用两个独立的特征提取器分别捕获空间和频域特征，并通过域特征映射模块和混合域特征细化模块（CBAM注意力）对齐和融合多域特征，同时抑制冗余信息。

研究结果: 在三个数据集上的实验表明，SFNet比现有遥感伪造检测方法的准确率提高了4%-15.18%，并展现出强大的泛化能力。

研究结论: SFNet通过融合空间和频域特征，显著提升了遥感图像伪造检测的准确率和泛化能力，为应对日益复杂的伪造技术提供了有效解决方案。

中文摘要: 生成式人工智能的快速发展正在产生越来越难以检测的伪造遥感图像（RSI），可能导致错误情报、虚假新闻甚至阴谋论。现有的伪造检测方法通常依赖单一视觉特征来捕捉预定义的伪造痕迹，例如利用空间域特征检测RSI中伪造的道路或建筑物，或利用频域特征识别对抗生成网络（GANs）中上采样操作产生的痕迹。然而，伪造痕迹的性质可能因地理地形、土地覆盖类型或RSI中的特定特征而显著不同。此外，随着生成模型的日益复杂，这些痕迹也在不断演变。简而言之，过度依赖单一视觉线索使得现有伪造检测器难以在多样化的遥感数据中实现泛化。本文提出了一种名为SFNet的新型伪造检测框架，旨在通过结合空间和频域特征来检测多样化的遥感数据中的伪造图像。具体而言，为了获取丰富且全面的视觉信息，SFNet采用两个独立的特征提取器分别从输入RSI中捕获空间和频域特征。为了充分利用互补的域特征，SFNet设计了域特征映射模块和混合域特征细化模块（CBAM注意力），依次对齐和融合多域特征，同时抑制冗余信息。在三个数据集上的实验表明，SFNet比现有遥感伪造检测方法的准确率提高了4%-15.18%，并展现出强大的泛化能力。代码可在https://github.com/GeoX-Lab/RSTI/tree/main/SFNet获取。

</details>


### [76] [Video Perception Models for 3D Scene Synthesis](https://arxiv.org/abs/2506.20601)
**中文标题：基于视频感知模型的3D场景合成**

*Rui Huang,Guangyao Zhai,Zuria Bauer,Marc Pollefeys,Federico Tombari,Leonidas Guibas,Gao Huang,Francis Engelmann*

主要分类: cs.CV

摘要简述: 本文提出VIPScene框架，利用视频生成模型的3D物理世界常识知识，实现高真实感和结构一致性的3D场景合成。


<details>
  <summary>详细信息</summary>
研究动机: 传统3D场景合成依赖专家知识和大量人工操作，自动化需求迫切。现有方法如大语言模型（LLMs）和图像生成模型在3D空间推理和多视角一致性上存在局限。

研究方法: VIPScene结合视频生成、前馈3D重建和开放词汇感知模型，通过文本和图像提示实现语义和几何分析，并引入FPVScore评估一致性和合理性。

研究结果: 实验表明VIPScene显著优于现有方法，并在多样化场景中表现优异。

研究结论: VIPScene为3D场景合成提供了一种高真实感和一致性的解决方案，具有广泛应用潜力。

中文摘要: 传统上，3D场景合成需要专家知识和大量人工操作。自动化这一过程可为建筑设计、机器人仿真、虚拟现实和游戏等领域带来巨大益处。当前的3D场景合成方法通常依赖大语言模型（LLMs）的常识推理或现代图像生成模型的视觉先验。然而，现有LLMs的3D空间推理能力有限，限制了生成逼真且连贯的3D场景的能力。同时，基于图像生成的方法常受限于视角选择和多视角不一致性。本文提出VIPScene框架，利用视频生成模型中编码的3D物理世界常识知识，确保场景布局的连贯性和多视角下物体放置的一致性。VIPScene支持文本和图像提示，无缝整合视频生成、前馈3D重建和开放词汇感知模型，对场景中的每个物体进行语义和几何分析，从而实现高真实感和结构一致性的灵活场景合成。为进一步精确分析，我们引入第一人称视角评分（FPVScore），利用连续第一人称视角发挥多模态大语言模型的推理能力，评估一致性和合理性。大量实验表明，VIPScene显著优于现有方法，并在多样化场景中表现优异。代码将开源。

</details>


### [77] [Shape2Animal: Creative Animal Generation from Natural Silhouettes](https://arxiv.org/abs/2506.20616)
**中文标题：Shape2Animal：从自然轮廓生成创意动物**

*Quoc-Duy Tran,Anh-Tuan Vo,Dinh-Khoi Vo,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: Shape2Animal是一个创新框架，通过将自然物体轮廓（如云、石头或火焰）重新解释为动物形态，模拟人类的pareidolia现象。该框架结合开放词汇分割、视觉语言模型和文本到图像扩散模型，生成视觉一致且空间连贯的动物图像。


<details>
  <summary>详细信息</summary>
研究动机: 受人类pareidolia现象的启发，即从模糊刺激中感知有意义模式的能力，本文旨在开发一个自动化框架，将自然物体轮廓转化为逼真的动物形态，为视觉叙事、教育内容和数字艺术提供新机会。

研究方法: Shape2Animal首先通过开放词汇分割提取物体轮廓，利用视觉语言模型识别语义相关的动物概念，再通过文本到图像扩散模型生成符合输入形状的动物图像，并将其无缝融合到原始场景中。

研究结果: 实验表明，Shape2Animal在多样化真实输入上表现稳健，展示了其创造潜力，能够生成视觉连贯且空间一致的动物图像。

研究结论: Shape2Animal为视觉叙事、教育内容、数字艺术和交互媒体设计提供了新的可能性，展示了自动化创意生成的潜力。

中文摘要: 人类具有从模糊刺激中感知有意义模式的独特能力，这种现象称为pareidolia。本文提出的Shape2Animal框架通过重新解释自然物体轮廓（如云、石头或火焰）为逼真的动物形态，模拟这种想象力。我们的自动化框架首先通过开放词汇分割提取物体轮廓，并利用视觉语言模型识别语义相关的动物概念。然后，通过文本到图像扩散模型生成符合输入形状的动物图像，并将其无缝融合到原始场景中，生成视觉连贯且空间一致的合成图像。我们在多样化真实输入上评估了Shape2Animal，证明了其稳健性和创造潜力。Shape2Animal为视觉叙事、教育内容、数字艺术和交互媒体设计提供了新机会。项目页面：https://shape2image.github.io

</details>


### [78] [Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects](https://arxiv.org/abs/2506.20638)
**中文标题：非合作空间物体的联合姿态估计与3D神经重建**

*Clément Forray,Pauline Delporte,Nicolas Delaygue,Florence Genin,Dawa Derksen*

主要分类: cs.CV

摘要简述: 本文利用神经辐射场（NeRF）对非合作空间物体进行3D重建，并通过联合优化相机姿态和NeRF模型，解决了单色图像、未知物体方向和有限视角等挑战。实验表明，逐帧训练图像能实现最准确的3D重建。


<details>
  <summary>详细信息</summary>
研究动机: 地球轨道物体的状态和行为信息对主动碎片清除、在轨维护和异常检测等应用至关重要。3D模型是空间态势感知（SSA）的重要信息来源。本文旨在利用NeRF技术，在单色图像、未知物体方向和有限视角等挑战性条件下，实现非合作空间物体的3D重建。

研究方法: 本文采用神经辐射场（NeRF）技术，通过联合优化相机姿态和NeRF模型，处理单色图像、未知物体方向和有限视角等问题。具体方法包括逐帧训练图像、优化均匀旋转估计相机姿态，并使用正则化防止相邻姿态差异过大。

研究结果: 实验结果表明，逐帧训练图像能够实现最准确的3D重建。通过优化均匀旋转和使用正则化，相机姿态的估计更加稳定。

研究结论: 本文证明了在单色图像和有限视角等挑战性条件下，NeRF技术仍能有效实现非合作空间物体的3D重建，并通过联合优化相机姿态和NeRF模型提升了重建精度。

中文摘要: 更好地了解地球轨道物体的当前状态和行为对主动碎片清除、在轨维护或异常检测等应用至关重要。3D模型是空间态势感知（SSA）领域的重要信息来源。本文利用神经辐射场（NeRF）技术，从模拟图像中对非合作空间物体进行3D重建。由于单色图像、未知物体方向、有限视角和缺乏漫射照明等挑战性条件，这一场景对NeRF模型具有较高难度。本文主要关注相机姿态与NeRF的联合优化。实验结果表明，逐帧训练图像能够实现最准确的3D重建。我们通过优化均匀旋转估计相机姿态，并使用正则化防止相邻姿态差异过大。

</details>


### [79] [MMSearch-R1: Incentivizing LMMs to Search](https://arxiv.org/abs/2506.20670)
**中文标题：MMSearch-R1：激励大型多模态模型进行搜索**

*Jinming Wu,Zihao Deng,Wei Li,Yiding Liu,Bo You,Bo Li,Zejun Ma,Ziwei Liu*

主要分类: cs.CV

摘要简述: MMSearch-R1是首个端到端强化学习框架，激励大型多模态模型（LMMs）在真实互联网环境中按需进行多轮搜索，结合图像和文本搜索工具，并通过奖励机制优化搜索行为。实验表明，该框架在减少30%搜索调用的情况下，性能优于同类检索增强生成（RAG）模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有检索增强生成（RAG）和提示工程搜索代理依赖固定流程，导致搜索效率低下或过度搜索。为提升大型多模态模型（LMMs）在复杂动态环境中的实用性，需开发一种灵活、高效的搜索框架。

研究方法: 提出MMSearch-R1框架，通过强化学习整合图像和文本搜索工具，模型根据基于结果的奖励和搜索惩罚决定何时及如何调用搜索工具。训练使用半自动化流程收集的多模态搜索VQA数据集，包含搜索需求和无搜索需求的样本。

研究结果: 实验表明，MMSearch-R1在知识密集和信息寻求VQA任务中，性能优于同类RAG基线模型，并减少30%以上搜索调用，同时匹配更大RAG模型的性能。

研究结论: MMSearch-R1为多模态搜索研究提供了实用框架，通过强化学习优化搜索行为，显著提升效率和性能。

中文摘要: 大型多模态模型（LMMs）在现实场景中的稳健部署需要访问外部知识源，以应对复杂多变的真实世界信息。现有方法如检索增强生成（RAG）和提示工程搜索代理依赖固定流程，常导致搜索效率低下或过度搜索。我们提出MMSearch-R1，首个端到端强化学习框架，使LMMs能够在真实互联网环境中按需进行多轮搜索。该框架整合图像和文本搜索工具，模型通过基于结果的奖励和搜索惩罚决定何时及如何调用搜索工具。为支持训练，我们通过半自动化流程收集了覆盖多样化视觉和文本知识需求的多模态搜索VQA数据集，并筛选出包含搜索需求和无搜索需求样本的搜索平衡子集，这对塑造高效按需搜索行为至关重要。在知识密集和信息寻求VQA任务上的大量实验表明，我们的模型不仅优于同类RAG基线模型，还能在减少30%以上搜索调用的情况下匹配更大RAG模型的性能。我们进一步分析关键实证发现，为多模态搜索研究的推进提供实用见解。

</details>


### [80] [Disentangled representations of microscopy images](https://arxiv.org/abs/2506.20649)
**中文标题：显微镜图像的解耦表示**

*Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone*

主要分类: cs.CV

摘要简述: 本文提出了一种解耦表示学习（DRL）方法，用于提升显微镜图像分类模型的可解释性，并在三个不同领域的显微镜图像数据集上验证了其准确性与可解释性的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 显微镜图像分析在诊断、合成工程和环境监测等领域具有重要意义。尽管深度学习在此领域表现优异，但模型的可解释性仍是一个未解决的挑战。本文旨在通过解耦表示学习提升显微镜图像分类模型的可解释性。

研究方法: 本文提出了一种基于解耦表示学习（DRL）的方法，通过从合成数据中学习表示并迁移到真实数据，以提升显微镜图像分类的可解释性。实验使用了浮游生物、酵母液泡和人类细胞三个领域的显微镜图像数据集。

研究结果: 实验结果表明，基于DRL的框架能够在显微镜图像分类任务中实现准确性与可解释性的良好平衡。

研究结论: 本文提出的解耦表示学习方法为显微镜图像分类提供了一种兼具高准确性和可解释性的解决方案，为相关领域的应用提供了新的思路。

中文摘要: 显微镜图像分析在从诊断到合成工程和环境监测等多种应用中具有基础性作用。现代采集系统使得获取大量图像成为可能，这要求开发大量基于深度学习的自动图像分析方法。尽管深度神经网络在此领域表现出色，但显微镜图像分析所必需的可解释性仍是一个未解决的挑战。
  本研究提出了一种解耦表示学习（DRL）方法，以提升显微镜图像分类模型的可解释性。通过利用来自三个不同显微镜图像领域（浮游生物、酵母液泡和人类细胞）的基准数据集，我们展示了基于从合成数据学习表示的DRL框架如何在该领域实现准确性与可解释性的良好平衡。

</details>


### [81] [IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals](https://arxiv.org/abs/2506.20671)
**中文标题：IPFormer：基于上下文自适应实例提案的视觉3D全景场景补全**

*Markus Gross,Aya Fahmy,Danit Niwattananan,Dominik Muhle,Rui Song,Daniel Cremers,Henri Meeß*

主要分类: cs.CV

摘要简述: IPFormer是一种基于视觉的3D全景场景补全方法，通过上下文自适应实例提案动态适应场景，显著提升了全景指标和运行效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的全景场景补全（PSC）方法主要基于LiDAR，而基于相机图像的方法尚未充分探索。此外，传统的Transformer方法使用固定的查询集，无法动态适应场景。IPFormer旨在解决这些问题，提出上下文自适应实例提案以提升性能。

研究方法: IPFormer通过图像上下文自适应初始化查询作为全景实例提案，并通过注意力编码和解码进一步优化这些提案，以推理语义实例与体素的关系。

研究结果: 实验表明，IPFormer在全景指标PQ$^\dagger$和PQ-All上优于现有方法，运行时间减少超过14倍。动态初始化提案使PQ-All提升3.62%，Thing指标平均提升18.65%。

研究结论: IPFormer通过上下文自适应实例提案，首次解决了基于视觉的3D全景场景补全问题，显著提升了性能和效率。

中文摘要: 语义场景补全（SSC）已成为联合学习场景几何和语义的关键方法，支持移动机器人导航等下游应用。全景场景补全（PSC）通过整合实例级信息进一步扩展了SSC领域，提升了场景理解的对象级敏感性。尽管PSC最初基于LiDAR模态，但基于相机图像的方法仍未被充分探索。此外，现有的基于Transformer的SSC方法使用固定的学习查询集重建场景中的对象，这些查询在训练时虽会更新，但在测试时保持静态，限制了其动态适应场景的能力。为解决这些问题，我们提出了IPFormer，首次利用上下文自适应实例提案在训练和测试时处理基于视觉的3D全景场景补全。具体而言，IPFormer自适应地将这些查询初始化为从图像上下文提取的全景实例提案，并通过注意力编码和解码进一步优化，以推理语义实例与体素的关系。实验结果表明，我们的方法在全景指标PQ$^\dagger$和PQ-All上超越了现有方法，运行时间减少了14倍以上。此外，消融研究表明，动态从图像上下文提取实例提案（而非随机初始化）使PQ-All提升了3.62%，Thing指标平均提升了18.65%。这些结果凸显了我们在基于视觉的3D全景场景补全中引入上下文自适应实例提案的开创性贡献。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [82] [Prover Agent: An Agent-based Framework for Formal Mathematical Proofs](https://arxiv.org/abs/2506.19923)
**中文标题：Prover Agent：一种基于代理的形式化数学证明框架**

*Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai*

主要分类: cs.AI

摘要简述: 本文提出了一种名为Prover Agent的新型AI代理，用于自动定理证明，结合大型语言模型（LLMs）与形式化证明助手Lean，通过协调非正式推理LLM、形式化证明模型及Lean的反馈，并生成辅助引理以帮助发现整体证明策略。在MiniF2F基准测试中达到86.1%的成功率，成为使用小型语言模型（SLMs）且样本预算更低的新最优方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前自动定理证明领域需要更高效且低成本的解决方案，尤其是在结合非正式推理与形式化证明方面。本文旨在通过整合LLMs与形式化工具Lean，提升定理证明的成功率与效率。

研究方法: Prover Agent结合了非正式推理的LLM、形式化证明模型及Lean的反馈机制，同时生成辅助引理以优化证明策略。通过协调这些组件，实现了高效的定理证明流程。

研究结果: 在MiniF2F基准测试中，Prover Agent取得了86.1%的成功率，显著优于其他使用小型语言模型的方法，且样本预算更低。案例研究展示了生成的引理对解决复杂问题的贡献。

研究结论: Prover Agent通过整合LLMs与形式化工具，显著提升了自动定理证明的效率和成功率，为未来研究提供了新的方向。

中文摘要: 我们提出了Prover Agent，一种用于自动定理证明的新型AI代理，它将大型语言模型（LLMs）与形式化证明助手Lean相结合。Prover Agent协调了一个非正式推理的LLM、一个形式化证明模型以及Lean的反馈，同时生成辅助引理以帮助发现整体证明策略。在MiniF2F基准测试中，它取得了86.1%的成功率，成为使用小型语言模型（SLMs）且样本预算更低的新最优方法。我们还通过案例研究展示了这些生成的引理如何帮助解决具有挑战性的问题。

</details>


### [83] [Context Attribution with Multi-Armed Bandit Optimization](https://arxiv.org/abs/2506.19977)
**中文标题：基于多臂老虎机优化的上下文归因**

*Deng Pan,Keerthiram Murugesan,Nuno Moniz,Nitesh Chawla*

主要分类: cs.AI

摘要简述: 本文提出了一种基于组合多臂老虎机（CMAB）的上下文归因框架，通过组合汤普森采样（CTS）高效探索上下文子集，显著提高了查询效率并保持了高归因保真度。


<details>
  <summary>详细信息</summary>
研究动机: 理解检索到的上下文中哪些部分对大型语言模型生成答案有贡献，对于构建可解释且可信的生成式问答系统至关重要。传统扰动归因方法（如SHAP）计算成本高且效率低，因此需要一种更高效的方法。

研究方法: 将上下文归因问题建模为组合多臂老虎机（CMAB）问题，每个上下文片段视为一个老虎机臂，采用组合汤普森采样（CTS）在有限查询预算下高效探索上下文子集。通过基于归一化标记似然的奖励函数评估子集对模型响应的支持程度。

研究结果: 在多种数据集和大型语言模型上的实验表明，该方法以较少的模型查询实现了竞争性的归因质量，显著提高了查询效率。

研究结论: 提出的框架通过组合多臂老虎机优化上下文归因，在保持高保真度的同时显著提升了效率，为生成式问答系统的可解释性提供了实用工具。

中文摘要: 理解检索到的上下文中哪些部分对大型语言模型生成答案有贡献，对于构建可解释且可信的生成式问答系统至关重要。我们提出了一种新颖的框架，将上下文归因问题建模为组合多臂老虎机（CMAB）问题。每个上下文片段被视为一个老虎机臂，并采用组合汤普森采样（CTS）在有限查询预算下高效探索指数级大的上下文子集空间。我们的方法基于归一化标记似然定义奖励函数，捕捉子集对原始模型响应的支持程度。与传统基于扰动的归因方法（如SHAP）不同，后者均匀采样子集且计算成本高，我们的方法通过利用片段相关性的后验估计自适应平衡探索与利用。这显著提高了查询效率，同时保持了高归因保真度。在多种数据集和大型语言模型上的广泛实验表明，我们的方法以较少的模型查询实现了竞争性的归因质量。

</details>


### [84] [QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges](https://arxiv.org/abs/2506.20008)
**中文标题：QHackBench：基于PennyLane Hackathon挑战的大语言模型量子代码生成基准测试**

*Abdul Basit,Minghao Shao,Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique*

主要分类: cs.AI

摘要简述: 本文提出了QHackBench，一个基于PennyLane的量子代码生成基准测试数据集，用于评估大语言模型在量子计算中的表现。研究比较了普通提示和检索增强生成（RAG）的效果，并引入多代理评估流程优化结果。结果表明，RAG在复杂量子算法中表现与普通提示相当，且多代理流程显著提升了执行成功率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在代码生成方面表现出色，但其在量子计算领域的应用尚未充分探索。本文旨在填补这一空白，通过实际量子编程挑战评估模型的性能，推动AI辅助量子编程的发展。

研究方法: 研究从Quantum Hackathon（QHack）竞赛中提取真实挑战，构建了QHackBench数据集。通过普通提示和RAG两种方式评估模型的功能正确性、语法有效性和执行成功率。此外，引入多代理评估流程迭代优化错误解决方案。

研究结果: 实验显示，RAG增强的模型在复杂量子算法中表现与普通提示相当。多代理评估流程进一步提升了执行成功率，尤其在解决错误解决方案时效果显著。

研究结论: QHackBench为AI辅助量子编程提供了有效的评估工具，RAG和多代理流程展示了优化潜力。研究公开了数据集和框架，以促进未来研究。

中文摘要: 近年来，大语言模型（LLMs）在代码生成方面展现出强大潜力，但其在量子计算中的有效性尚未充分研究。本文利用Quantum Hackathon（QHack）的实际挑战，对基于PennyLane的量子代码生成进行了基准测试。我们提出了QHackBench，一个源自QHack竞赛的新型基准数据集，并通过普通提示和检索增强生成（RAG）评估模型性能。我们的结构化评估框架涵盖了功能正确性、语法有效性和不同难度挑战的执行成功率。结果表明，RAG增强的模型在复杂量子算法中表现与普通提示相当。此外，我们引入了多代理评估流程，通过迭代优化错误解决方案进一步提升执行成功率。为促进进一步研究，我们将公开QHackBench数据集、评估框架和实验结果，推动AI辅助量子编程的持续发展。

</details>


### [85] [Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks](https://arxiv.org/abs/2506.20009)
**中文标题：精准且高效：本地检索增强生成模型在医疗任务中超越商业大语言模型**

*Konstantinos Vrettos,Michail E. Klontzas*

主要分类: cs.AI

摘要简述: 研究开发了一种定制化的检索增强生成（RAG）框架，用于医疗任务，其性能和能效优于商业大语言模型（如ChatGPT和DeepSeek），同时减少能源消耗和碳排放。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能在医疗领域的广泛应用，商业大语言模型的高资源需求和隐私安全问题引发关注。研究旨在开发一种更高效、环保的本地化解决方案。

研究方法: 开发了一个可定制的RAG框架，监测能源使用和碳排放，并基于开源大语言模型（如llama3.1:8b和medgemma-4b-it）构建RAG模型，与商业模型（如DeepSeekV3-R1和o4-mini）进行性能对比。

研究结果: 定制RAG模型在准确性和能效上均优于商业模型。llama3.1:8B RAG准确率最高（58.5%），能耗最低（每千瓦时0.52性能，总碳排放473克），比o4-mini节能172%。

研究结论: 研究表明，本地化RAG模型在医疗任务中优于商业模型，且更环保。模块化框架符合联合国可持续发展目标，推动可持续AI发展。

中文摘要: 背景：人工智能在医疗领域的广泛应用引发了对环境和伦理问题的关注。商业大语言模型（如ChatGPT和DeepSeek）资源消耗大，且存在隐私和安全风险。方法：我们开发了一种可定制的检索增强生成（RAG）框架，用于医疗任务，并监测其能源使用和碳排放。基于开源大语言模型（如llama3.1:8b和medgemma-4b-it）构建RAG模型，并与商业模型（如DeepSeekV3-R1和o4-mini）进行对比。结果：定制RAG模型在准确性和能效上均优于商业模型。llama3.1:8B RAG准确率最高（58.5%），能耗最低（每千瓦时0.52性能，总碳排放473克），比o4-mini节能172%。结论：研究表明，本地化RAG模型在医疗任务中优于商业模型，且更环保。模块化框架符合联合国可持续发展目标，推动可持续AI发展。

</details>


### [86] [Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models](https://arxiv.org/abs/2506.20018)
**中文标题：利用低延迟可解释AI模型实现可信赖的实时决策支持系统**

*Zechun Deng,Ziwei Liu,Ziqian Bi,Junhao Song,Chia Xin Liang,Joe Yeong,Junfeng Hao*

主要分类: cs.AI

摘要简述: 本文探讨了如何利用低延迟可解释AI模型构建可信赖的实时决策支持系统，结合了AI驱动的决策工具、边缘物联网技术及人机协作方法，并研究了模型压缩和边缘设备优化的技术进展。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决资源受限环境下实时决策支持系统的挑战，探索如何通过低延迟AI模型提升决策效率，并推动AI与边缘计算技术的结合。

研究方法: 通过综述现有技术，包括DeLLMa、模型压缩方法和边缘设备优化策略，分析其在实时决策支持中的应用潜力。

研究结果: 研究提供了开发策略和应用领域的实用视角，指出高效灵活AI支持系统的机遇，并展示了技术进展对决策支持的积极影响。

研究结论: 本文为未来实时决策支持领域的突破奠定了基础，强调了AI在重塑实时决策中的潜力。

中文摘要: 本文研究了利用低延迟AI模型的实时决策支持系统，结合了AI驱动的决策工具、边缘物联网技术及人机协作方法。研究探讨了大型语言模型在资源受限环境下的决策辅助作用，并分析了DeLLMa、模型压缩技术和边缘设备优化等技术进展的影响。通过详细综述，本文提供了开发策略和应用领域的实用视角，为高效灵活的AI支持系统指明了方向。结论为这一快速变化领域的未来突破奠定了基础，突出了AI对实时决策支持的重塑潜力。

</details>


### [87] [Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning](https://arxiv.org/abs/2506.20020)
**中文标题：赋予身份角色的大型语言模型表现出类人的动机性推理**

*Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan*

主要分类: cs.AI

摘要简述: 研究发现，赋予大型语言模型（LLMs）特定身份角色后，其表现出类似人类的动机性推理，导致判断偏差，且难以通过常规方法纠正。


<details>
  <summary>详细信息</summary>
研究动机: 人类推理常因身份保护等动机而产生偏见，影响理性决策。LLMs是否也会因身份角色而选择性推理尚不明确，研究旨在探究这一问题及其社会影响。

研究方法: 研究为8种LLMs（开源和专有）分配了4类政治和社会人口属性共8种身份角色，测试其在两类任务中的表现：虚假新闻真实性辨别和科学证据评估。

研究结果: 身份角色使LLMs的真实性辨别能力下降高达9%，政治身份角色在科学证据评估中表现尤为明显，当事实与其身份一致时正确率提升90%。常规去偏见方法效果有限。

研究结论: 身份角色赋予的LLMs表现出类似人类的动机性推理，且难以通过常规方法纠正，可能加剧身份一致性推理问题。

中文摘要: 人类推理常因身份保护等动机而产生偏见，影响理性决策和社会议题讨论（如气候变化或疫苗安全），甚至加剧政治极化。此前研究显示大型语言模型（LLMs）也存在类似认知偏差，但其选择性推理的程度尚不明确。本研究为8种LLMs分配了4类政治和社会人口属性共8种身份角色，测试其在虚假新闻真实性辨别和科学证据评估中的表现。结果显示，身份角色使LLMs的真实性辨别能力下降高达9%，政治身份角色在科学证据评估中表现尤为明显（当事实与其身份一致时正确率提升90%）。常规去偏见方法效果有限。研究表明，身份角色赋予的LLMs表现出类人的动机性推理，且难以纠正，可能加剧身份一致性推理问题。

</details>


### [88] [DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction](https://arxiv.org/abs/2506.20059)
**中文标题：DiaLLMs：基于电子健康记录的临床对话系统，用于临床测试推荐和诊断预测**

*Weijieying Ren,Tianxiang Zhao,Lei Wang,Tianchun Wang,Vasant Honavar*

主要分类: cs.AI

摘要简述: DiaLLM是首个整合电子健康记录（EHR）的医疗大语言模型，通过临床测试参考策略和强化学习框架，实现了临床测试推荐、结果解释和诊断预测，显著提升了医疗对话系统的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 现有医疗大语言模型忽视了电子健康记录（EHR）的作用，且仅关注诊断推荐，限制了其临床适用性。DiaLLM旨在通过整合EHR数据，提供更符合实际医疗实践的对话系统。

研究方法: DiaLLM采用临床测试参考（CTR）策略将临床代码映射为描述并分类测试结果，同时利用强化学习框架进行证据获取和自动诊断。通过拒绝采样策略减少冗余，并设计了确认奖励和类别敏感诊断奖励以提高准确性。

研究结果: 实验结果表明，DiaLLM在临床测试推荐和诊断预测方面优于基线模型。

研究结论: DiaLLM通过整合EHR和强化学习框架，显著提升了医疗对话系统的临床适用性和准确性，为未来医疗AI的发展提供了新方向。

中文摘要: 近年来，大语言模型（LLMs）在医疗咨询领域取得了显著进展。然而，现有的医疗LLMs忽视了电子健康记录（EHR）的关键作用，且主要关注诊断推荐，限制了其临床适用性。我们提出了DiaLLM，这是首个将异构EHR数据整合到临床对话中的医疗LLM，支持临床测试推荐、结果解释和诊断预测，以更好地符合实际医疗实践。为从EHR构建临床对话，我们设计了临床测试参考（CTR）策略，将每个临床代码映射为其对应描述，并将测试结果分类为“正常”或“异常”。此外，DiaLLM采用强化学习框架进行证据获取和自动诊断。为处理大动作空间，我们引入了拒绝采样策略以减少冗余并提高探索效率。同时，设计了确认奖励和类别敏感诊断奖励以指导准确的诊断预测。大量实验结果表明，DiaLLM在临床测试推荐和诊断预测方面优于基线模型。

</details>


### [89] [AI Copilots for Reproducibility in Science: A Case Study](https://arxiv.org/abs/2506.20130)
**中文标题：科学复现的AI副驾驶：一个案例研究**

*Adrien Bibal,Steven N. Minton,Deborah Khider,Yolanda Gil*

主要分类: cs.AI

摘要简述: 本文介绍了OpenPub平台及其AI助手Reproducibility Copilot，旨在通过生成结构化Jupyter Notebook和建议，显著减少科学研究的复现时间，从30小时缩短至1小时，并提高复现覆盖率。


<details>
  <summary>详细信息</summary>
研究动机: 开放科学倡议旨在提高研究的透明度和可重复性，但独立复现已发表成果仍面临挑战。本文提出AI驱动的OpenPub平台，以解决复现性问题。

研究方法: OpenPub平台通过Reproducibility Copilot分析论文、代码和补充材料，生成结构化Jupyter Notebook和建议，专注于计算复现性。测试基于已知复现基准的研究论文。

研究结果: 测试结果显示，OpenPub将复现时间从30多小时缩短至约1小时，并高覆盖率地复现图表和结果。系统还能检测复现障碍，如缺失超参数、未记录的预处理步骤等。

研究结论: AI工具可显著减轻复现负担，促进透明和可验证的科学交流。OpenPub的模块化架构还支持扩展至其他开放科学目标。

中文摘要: 开放科学倡议旨在提高研究输出的透明度、可访问性和可重用性，但确保已发表成果可独立复现仍是一项持续挑战。本文介绍了OpenPub，一个AI驱动的平台，通过一系列专注于关键开放科学任务的模块化副驾驶，支持研究人员、审稿人和读者。本文重点介绍了Reproducibility Copilot，它分析论文、代码和补充材料，生成结构化的Jupyter Notebook和建议，旨在促进计算或“机械”复现性。我们使用已知复现基准的研究论文进行了可行性测试。结果表明，OpenPub可显著减少复现时间——从30多小时缩短至约1小时——同时实现适合计算复现的图表和结果的高覆盖率。该系统还能系统性地检测复现障碍，包括缺失超参数、未记录的预处理步骤以及不完整或不可访问的数据集。这些发现表明，AI驱动工具可显著减轻复现负担，促进更透明和可验证的科学交流。模块化副驾驶架构还为扩展AI辅助至复现性以外的其他开放科学目标奠定了基础。

</details>


### [90] [Language Modeling by Language Models](https://arxiv.org/abs/2506.20249)
**中文标题：语言模型的语言建模**

*Junyan Cheng,Peter Clark,Kyle Richardson*

主要分类: cs.AI

摘要简述: 本文提出了一种多智能体LLM方法Genesys，通过模拟研究过程（从构思到验证）自动发现新的语言模型架构。采用遗传编程框架和规模扩展策略，显著提升了设计生成效率，并在实验中验证了其优于现有架构的性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机是利用LLM模拟语言模型架构的发现过程，以自动化传统研究中从构思到验证的各个阶段，从而高效生成新颖且高性能的模型设计。

研究方法: 方法包括：1）多智能体LLM模拟研究流程（提案、代码生成、预训练和验证）；2）采用规模扩展策略（从14M到350M参数）和预算限制；3）引入遗传编程框架，优化设计生成效率。

研究结果: 实验结果：1）生成了1,162个新设计，其中1,062个通过预训练验证；2）最佳设计在6/9基准测试中优于GPT2和Mamba2等现有架构；3）遗传编程框架显著提升了设计生成成功率（约86%）。

研究结论: 结论表明，Genesys系统能够高效自动发现高性能语言模型架构，其遗传编程框架和规模扩展策略为自主发现系统的设计提供了新思路。

中文摘要: 我们能否利用大型语言模型（LLM）来建模发现新型语言模型架构的过程？受真实研究启发，我们提出了一种多智能体LLM方法，模拟从构思和文献检索（提案阶段）到设计实现（代码生成）、生成式预训练和下游评估（验证）的传统研究阶段。基于规模扩展定律，我们的系统Genesys采用了一种“规模阶梯”方法：新设计被提出、对抗性评审、实现，并在逐渐增大的模型规模（14M至350M参数）和有限预算下选择性验证。为提高发现效率和可分解性，Genesys使用了一种新颖的遗传编程框架，实验证明其优于常用的直接提示生成工作流（例如，设计生成成功率提升约86个百分点，这是一个关键瓶颈）。我们报告了涉及1,162个新设计（其中1,062个通过预训练完全验证）的实验，发现最佳设计在6/9常见基准测试中优于已知架构（如GPT2、Mamba2等）。这些结果结合系统级消融实验和形式化结果，为高效自主发现系统的设计提供了更广泛的见解。

</details>


### [91] [Enterprise Large Language Model Evaluation Benchmark](https://arxiv.org/abs/2506.20274)
**中文标题：企业大语言模型评估基准**

*Liya Wang,David Yi,Damien Jose,John Passarelli,James Gao,Jordan Leventis,Kang Li*

主要分类: cs.AI

摘要简述: 本文提出了一种基于布鲁姆分类法的14任务框架，用于全面评估大语言模型在企业环境中的能力，并开发了一个可扩展的数据标注和评估流程。通过评估六种领先模型，发现开源模型在推理任务中表现优异，但在判断任务中因过度思考而表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大规模多任务语言理解基准（如MMLU）无法充分评估企业特定任务的复杂性，因此需要一种更全面的评估方法来指导企业优化大语言模型的应用。

研究方法: 作者提出了一个14任务的评估框架，结合了LLM-as-a-Labeler、LLM-as-a-Judge和纠正检索增强生成（CRAG）技术，构建了一个包含9,700个样本的稳健基准。

研究结果: 评估结果显示，开源模型（如DeepSeek R1）在推理任务中与专有模型表现相当，但在基于判断的任务中表现较差，可能是由于过度思考。

研究结论: 该研究为企业提供了定制化评估的蓝图，并推动了大语言模型在实际应用中的优化部署。

中文摘要: 大语言模型（LLMs）在提升AI工具生产力方面展现出潜力，但现有基准（如大规模多任务语言理解MMLU）无法充分评估企业特定任务的复杂性。我们提出了一个基于布鲁姆分类法的14任务框架，以全面评估LLM在企业环境中的能力。为解决噪声数据和昂贵标注的挑战，我们开发了一个可扩展的流程，结合了LLM-as-a-Labeler、LLM-as-a-Judge和纠正检索增强生成（CRAG），构建了一个包含9,700个样本的稳健基准。对六种领先模型的评估显示，开源模型（如DeepSeek R1）在推理任务中与专有模型相当，但在基于判断的任务中表现较差，可能是由于过度思考。我们的基准揭示了企业性能的关键差距，并为模型优化提供了实用见解。这项工作为企业提供了定制化评估的蓝图，并推动了大语言模型的实际部署。

</details>


### [92] [Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards](https://arxiv.org/abs/2506.20332)
**中文标题：Mobile-R1：基于任务级奖励的视觉语言模型移动代理交互式强化学习方法**

*Jihao Gu,Qihang Ai,Yingyao Wang,Pi Bu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Ziming Wang,Yingxiu Zhao,Ming-Liang Zhang,Jun Song,Yuning Jiang,Bo Zheng*

主要分类: cs.AI

摘要简述: 本文提出Mobile-R1，一种基于任务级奖励的交互式强化学习方法，用于提升视觉语言模型移动代理的探索与纠错能力。通过三阶段训练框架（初始微调、单步在线训练、多轮任务级奖励训练），显著提升了性能，并开源了数据集和模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多采用离线强化学习或动作级奖励的在线优化，限制了移动代理与环境的动态交互能力，容易陷入局部最优。本文旨在通过任务级奖励的交互式强化学习，提升代理的探索与纠错能力。

研究方法: 提出Mobile-R1方法，采用三阶段训练框架：1）初始格式微调；2）基于动作级奖励的单步在线训练；3）基于多轮轨迹的任务级奖励在线训练。通过任务级奖励增强代理的探索与纠错能力。

研究结果: Mobile-R1显著提升了移动代理的性能，并构建了包含28个中文应用、24,521条高质量标注的数据集，以及500条轨迹的新基准测试。所有资源（数据集、基准、模型权重、代码）均已开源。

研究结论: Mobile-R1通过任务级奖励的交互式强化学习，有效提升了移动代理的探索与纠错能力，为未来研究提供了新的训练框架和开源资源。

中文摘要: 基于视觉语言模型的移动代理不仅能理解复杂指令和移动屏幕截图，还能通过强化学习（如组相对策略优化GRPO）优化其动作输出。然而，现有研究集中于离线强化学习训练或基于动作级奖励的在线优化，限制了代理与环境的动态交互能力，导致代理易陷入局部最优，削弱了探索与错误动作纠正能力。为解决这些问题，我们提出Mobile-R1方法，采用基于任务级奖励的交互式多轮强化学习。训练框架分为三阶段：初始格式微调、基于动作级奖励的单步在线训练，以及基于多轮轨迹的任务级奖励在线训练。这一策略旨在增强Mobile-R1的探索与纠错能力，显著提升性能。此外，我们收集了涵盖28个中文应用的24,521条高质量人工标注数据集，并建立了包含500条轨迹的新基准测试。所有资源（数据集、基准、模型权重、代码）均已开源：https://mobile-r1.github.io/Mobile-R1/。

</details>


### [93] [Tabular Feature Discovery With Reasoning Type Exploration](https://arxiv.org/abs/2506.20357)
**中文标题：基于推理类型探索的表格特征发现**

*Sungwon Han,Sungkyu Park,Seungeon Lee*

主要分类: cs.AI

摘要简述: 本文提出了一种名为REFeat的新方法，通过引导大型语言模型（LLM）利用多种推理类型生成多样且信息丰富的特征，解决了现有LLM方法在表格数据特征工程中生成简单或重复特征的问题。实验表明，该方法在59个基准数据集上不仅提高了预测准确性，还发现了更多样且有意义的特征。


<details>
  <summary>详细信息</summary>
研究动机: 表格数据的特征工程是机器学习中的关键但具有挑战性的步骤。尽管大型语言模型（LLM）已被用于自动生成新特征，但现有方法常因LLM的固有偏差和缺乏结构化推理指导而生成过于简单或重复的特征。本文旨在通过引入多种推理类型和自适应策略选择，改进LLM驱动的特征发现。

研究方法: 本文提出了一种名为REFeat的新方法，通过引导LLM利用多种推理类型（如逻辑推理、类比推理等）来生成多样且信息丰富的特征。该方法在特征生成过程中结合了结构化推理指导和自适应策略选择，以避免生成简单或重复的特征。

研究结果: 在59个基准数据集上的实验表明，REFeat方法不仅平均预测准确性更高，还能发现更多样且有意义的特征。这些结果验证了在LLM驱动的特征发现中引入丰富推理范式和自适应策略的有效性。

研究结论: 本文提出的REFeat方法通过结合多种推理类型和自适应策略选择，显著提升了LLM在表格数据特征工程中的表现。实验结果表明，该方法能够生成更多样且信息丰富的特征，为未来的特征发现研究提供了新的方向。

中文摘要: 表格数据的特征工程是机器学习中关键但具有挑战性的一步。最近，大型语言模型（LLM）被用于通过其广泛的知识自动生成新特征。然而，现有的基于LLM的方法常因LLM选择的转换固有偏差和生成过程中缺乏结构化推理指导，而生成过于简单或重复的特征。本文提出了一种名为REFeat的新方法，通过利用多种推理类型引导LLM生成多样且信息丰富的特征。在59个基准数据集上的实验表明，我们的方法不仅平均预测准确性更高，还能发现更多样且有意义的特征。这些结果凸显了在LLM驱动的表格数据特征发现中引入丰富推理范式和自适应策略选择的前景。

</details>


### [94] [Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios](https://arxiv.org/abs/2506.20384)
**中文标题：Paladin-mini：一款紧凑高效的接地模型，在真实场景中表现卓越**

*Dror Ivry,Oran Nahum*

主要分类: cs.AI

摘要简述: 本文介绍了Paladin-mini，一个紧凑高效的开源分类模型（3.8B参数），用于在真实场景中验证上下文中的声明是否成立。同时提出了一个新的评估数据集grounding-benchmark，用于测试关键推理任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 解决在给定上下文中验证声明是否成立的问题，即是否存在支持声明的证据。

研究方法: 提出了Paladin-mini模型（3.8B参数）和grounding-benchmark数据集，用于评估模型在关键推理任务中的表现。

研究结果: Paladin-mini在真实场景中表现出色，并通过benchmark测试展示了其性能优于当前最先进模型。

研究结论: Paladin-mini是一个高效且紧凑的模型，适用于真实场景中的声明验证任务，grounding-benchmark为评估提供了新标准。

中文摘要: 本文针对在给定上下文中验证声明是否成立的问题提出了两项重要贡献。接地意味着在给定上下文（文档）和声明的情况下，文档中至少存在一条支持声明的证据。我们介绍了Paladin-mini，一个紧凑（3.8B参数）的开源分类模型（用于标记数据为接地或未接地），专为在真实场景中实现稳健性能而设计；同时提出了grounding-benchmark，一个新的评估数据集，用于测试关键推理任务的性能。我们还展示了Paladin-mini与当前最先进模型的基准测试结果，并提供了清晰且可复现的结果。

</details>


### [95] [Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation](https://arxiv.org/abs/2506.20401)
**中文标题：基于电动汽车的智能出行与配送服务：利用双向充电技术优化利润**

*Jinchun Du,Bojie Shen,Muhammad Aamir Cheema,Adel N. Toosi*

主要分类: cs.AI

摘要简述: 本文提出了一种基于电动汽车（EV）的智能出行和配送服务优化问题（EVOP-V2G），通过双向充电技术（V2G）最大化司机利润。研究采用混合整数规划（MIP）模型和两种元启发式算法（进化和大邻域搜索），实验表明其方法可将司机利润翻倍，并具有优异的扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 随着电动汽车（EV）的普及，现代服务系统（如网约车和配送服务）越来越多地使用EV。然而，EV的续航较短，充电管理成为关键挑战。双向充电技术（V2G）的出现为EV提供了放电回电网的能力，但也带来了新的复杂性。本文旨在通过优化EV的充放电决策，最大化司机利润。

研究方法: 研究提出了EVOP-V2G问题，将其建模为混合整数规划（MIP）模型，并设计了两种近优元启发式算法：进化算法（EA）和大邻域搜索算法（LNS）。这些算法考虑了动态电价、充电站选择和路径约束。

研究结果: 在真实数据实验中，所提方法将司机利润提升了一倍，同时在小规模实例中表现接近最优，在大规模实例中具有优异的扩展性。

研究结论: 本文为基于EV的智能出行系统提供了一种高效且盈利的优化路径，同时支持电网能源管理。

中文摘要: 随着电动汽车（EV）的普及，现代服务系统（如网约车和配送服务）越来越多地采用EV。与传统车辆不同，EV的续航较短，因此在满足需求时需谨慎考虑充电问题。近年来，车辆到电网（V2G）技术的进步使得EV能够将能量回馈电网，从而带来了新的机遇和复杂性。本文提出了基于V2G的电动汽车定向问题（EVOP-V2G）：一个利润最大化问题，EV司机需在管理充放电时间和地点的同时选择客户请求或订单。该问题涉及动态电价、充电站选择和路径约束。我们将其建模为混合整数规划（MIP）模型，并提出了两种近优元启发式算法：一种是进化算法（EA），另一种基于大邻域搜索（LNS）。在真实数据实验中，我们的方法可将司机利润提升一倍，同时在小规模实例中表现接近最优，在大规模实例中具有优异的扩展性。本研究为更智能、更盈利的基于EV的出行系统提供了一条可行路径，同时积极支持电网能源管理。

</details>


### [96] [GymPN: A Library for Decision-Making in Process Management Systems](https://arxiv.org/abs/2506.20404)
**中文标题：GymPN：业务流程管理系统中决策支持的软件库**

*Riccardo Lo Bianco,Willem van Jaarsveld,Remco Dijkman*

主要分类: cs.AI

摘要简述: 本文介绍了一个名为GymPN的软件库，用于通过深度强化学习优化业务流程中的决策，支持部分流程可见性和多决策建模，解决了以往研究的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 业务流程管理系统需要优化任务分配、执行时间和人员指派等决策，现有工具存在局限性，无法完全满足现实需求。GymPN旨在通过深度强化学习提供更优的决策支持。

研究方法: GymPN基于深度强化学习，支持部分流程可见性和多决策建模，解决了以往研究的不足。通过八种典型业务流程决策问题模式进行评估。

研究结果: GymPN能够轻松建模目标问题，并学习最优决策策略，验证了其在业务流程决策中的有效性。

研究结论: GymPN为业务流程管理提供了更现实的决策支持工具，解决了部分可见性和多决策建模的挑战。

中文摘要: 业务流程管理系统支持组织中工作分配的关键决策，包括下一步执行的任务、执行时间以及任务指派对象。需要合适的软件工具以最优方式支持这些决策。本文介绍了一个名为GymPN的软件库，利用深度强化学习优化业务流程中的决策。GymPN在以往支持任务分配的研究基础上，引入两个关键创新：支持部分流程可见性以及多决策建模能力。这些创新解决了以往研究的根本限制，从而能够表示更现实的流程决策。我们在八种典型业务流程决策问题模式上评估了该库，结果表明GymPN能够轻松建模目标问题并学习最优决策策略。

</details>


### [97] [Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization](https://arxiv.org/abs/2506.20486)
**中文标题：混合神经细胞自动机：一种用于生长建模与自组织的随机框架**

*Salvatore Milite,Giulio Caravagna,Andrea Sottoriva*

主要分类: cs.AI

摘要简述: 本文提出了一种混合神经细胞自动机（MNCA）框架，通过结合概率规则和内在噪声，解决了传统神经细胞自动机（NCA）确定性过强的问题，能够更好地模拟真实生物系统中的随机动态。


<details>
  <summary>详细信息</summary>
研究动机: 传统神经细胞自动机（NCA）因其确定性无法充分模拟真实生物和物理系统的随机性，限制了其在生命科学中的应用。本文旨在通过引入混合模型的概念，增强NCA的随机建模能力。

研究方法: 提出混合神经细胞自动机（MNCA），将概率规则分配与内在噪声结合，以模拟多样化的局部行为。该方法在三个领域进行了评估：组织生长与分化的合成模拟、图像形态生成的鲁棒性，以及显微镜图像分割。

研究结果: 实验结果表明，MNCA在抗干扰性、真实生物生长模式的再现以及可解释的规则分割方面表现优异。

研究结论: MNCA为模拟随机动态系统和研究自生长过程提供了一种有前景的工具，尤其在生命科学领域具有潜在应用价值。

中文摘要: 神经细胞自动机（NCA）是一种模拟自组织过程的新方法，在生命科学中具有潜在应用。然而，其确定性限制了其模拟真实生物和物理系统随机性的能力。本文提出混合神经细胞自动机（MNCA），将混合模型的概念引入NCA范式，通过结合概率规则和内在噪声，能够模拟多样化的局部行为并再现生物过程中的随机动态。我们在三个关键领域评估了MNCA的有效性：（1）组织生长与分化的合成模拟，（2）图像形态生成的鲁棒性，（3）显微镜图像分割。结果表明，MNCA在抗干扰性、真实生物生长模式的再现以及可解释的规则分割方面表现优异。这些发现表明，MNCA是模拟随机动态系统和研究自生长过程的有前景的工具。

</details>


### [98] [Engineering Sentience](https://arxiv.org/abs/2506.20504)
**中文标题：工程化感知能力**

*Konstantin Demin,Taylor Webb,Eric Elmoznino,Hakwan Lau*

主要分类: cs.AI

摘要简述: 本文提出了一种可用于设计和构建机器感知能力的定义，强调感知需具备功能性和计算性，同时包含主观性。通过具体实现方案展示了如何将这一概念应用于当前技术。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于为人工智能设计一种有意义的感知能力定义，既需功能性实现，又需体现主观性，以避免无意中创造具有感知能力的人工智能。

研究方法: 方法包括提出感知的功能性定义，强调感知信号需具备断言性和质性，并结合当前技术探讨了潜在实现方案。

研究结果: 研究结果展示了一种具体的感知定义，并通过技术实现方案验证了其可行性，为人工感知的设计提供了理论基础。

研究结论: 结论指出，明确人工感知的功能性定义有助于避免无意中创造感知能力，同时为相关技术发展提供指导。

中文摘要: 我们提出了一种可用于设计和构建机器感知能力的定义。我们认为，要使感知对人工智能有意义，必须从功能和计算角度详细阐述，以便实现。同时，这种感知概念还需体现某种本质上的‘主观性’，而不仅仅是具备编码感知内容的通用能力。为实现这种特定的功能性感知，我们提出某些感官信号需同时具备断言性（持久性）和质性。为更具体地说明这一定义，我们结合当前技术勾勒了一些潜在实现方式。理解人工代理如何具备功能性感知能力，不仅有助于避免无意中创造它们，还能让我们及时意识到其存在。

</details>


### [99] [Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios](https://arxiv.org/abs/2506.20531)
**中文标题：基于案例推理增强的大型语言模型框架在现实安全关键驾驶场景中的决策应用**

*Wenbin Gan,Minh-Son Dao,Koji Zettsu*

主要分类: cs.AI

摘要简述: 本文提出了一种基于案例推理增强的大型语言模型（CBR-LLM）框架，用于在安全关键的驾驶场景中做出决策。该框架结合语义场景理解和历史驾驶案例检索，提升决策的准确性和人类对齐性。


<details>
  <summary>详细信息</summary>
研究动机: 在安全关键的驾驶场景中，快速且基于情境的决策至关重要。尽管大型语言模型（LLMs）具有强大的通用推理能力，但其在自动驾驶领域的直接应用仍受限于领域适应性、情境理解以及缺乏可靠且可解释的决策经验。

研究方法: 本文提出CBR-LLM框架，通过结合语义场景理解（来自行车记录仪视频输入）和历史驾驶案例检索，使LLMs能够生成既符合情境又与人一致的驾驶建议。此外，采用风险感知提示策略和基于相似性的案例检索方法。

研究结果: 实验表明，该框架显著提高了决策准确性、理由质量以及与人类专家行为的一致性。风险感知提示策略和相似性案例检索方法均优于随机采样。案例研究进一步验证了框架在复杂现实条件下的鲁棒性。

研究结论: CBR-LLM框架为智能驾驶系统提供了一种自适应且可信的决策支持工具，展示了其在动态高风险环境中的潜力。

中文摘要: 在安全关键的驾驶场景中，快速且基于情境的决策需要结合对场景的理解和经验推理。大型语言模型（LLMs）凭借其强大的通用推理能力，为此类决策提供了有前景的基础。然而，由于领域适应性、情境理解以及缺乏在高风险动态环境中做出可靠且可解释决策所需的经验知识等问题，LLMs在自动驾驶中的直接应用仍受限。为填补这一空白，本文提出了一种基于案例推理增强的大型语言模型（CBR-LLM）框架，用于在复杂风险场景中制定规避动作决策。我们的方法将行车记录仪视频输入的语义场景理解与相关历史驾驶案例检索相结合，使LLMs能够生成既符合情境又与人一致的驾驶建议。在多个开源LLMs上的实验表明，该框架显著提高了决策准确性、理由质量以及与人类专家行为的一致性。风险感知提示策略进一步提升了在不同风险类型中的表现，而基于相似性的案例检索在指导上下文学习方面始终优于随机采样。案例研究进一步验证了该框架在具有挑战性的现实条件下的鲁棒性，突显了其作为智能驾驶系统自适应且可信的决策支持工具的潜力。

</details>


### [100] [Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges](https://arxiv.org/abs/2506.20598)
**中文标题：基于微调和提示工程的大型语言模型优化：用于解决可持续蛋白质生产挑战的多代理人工智能构建**

*Alexander D. Kalian,Jaewook Lee,Stefan P. Johannesson,Lennart Otte,Christer Hogstrand,Miao Guo*

主要分类: cs.AI

摘要简述: 本文提出了一种基于多代理人工智能的框架，旨在支持可持续蛋白质生产研究，重点针对微生物蛋白质来源。通过检索增强生成（RAG）系统，结合微调和提示工程两种方法优化代理性能，显著提升了信息提取的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 全球对可持续蛋白质来源的需求日益增长，亟需智能工具快速处理和综合领域特定的科学知识。本研究旨在开发一种多代理人工智能框架，以支持可持续蛋白质生产的研究，尤其是微生物蛋白质来源。

研究方法: 研究采用检索增强生成（RAG）系统，包含两个基于GPT的大型语言模型代理：一个用于检索相关科学文献，另一个用于提取生物和化学信息。通过微调和提示工程两种方法优化代理性能。

研究结果: 实验结果显示，两种方法均能显著提升信息提取代理的性能，其中微调方法将平均余弦相似度分数提升至≥0.94，提示工程方法则表现出较低的统计不确定性。

研究结论: 多代理人工智能框架在可持续蛋白质生产研究中表现出潜力，微调方法在性能提升上优于提示工程，但后者具有更低的统计不确定性。研究还开发了用户界面以支持系统使用。

中文摘要: 全球对可持续蛋白质来源的需求加速了对能够快速处理和综合领域特定科学知识的智能工具的需求。本研究提出了一种概念验证的多代理人工智能框架，旨在支持可持续蛋白质生产研究，初步聚焦于微生物蛋白质来源。我们的检索增强生成（RAG）导向系统包含两个基于GPT的大型语言模型代理：（1）一个文献检索代理，用于检索指定微生物菌株的相关科学文献；（2）一个信息提取代理，用于处理检索内容以提取相关的生物和化学信息。研究探索了两种并行方法（微调和提示工程）以优化代理性能。两种方法均有效提升了信息提取代理的性能，表现为基于变换器的余弦相似度分数（提取结果与理想输出之间的比较）的提升。平均余弦相似度分数最高提升了25%，且普遍达到≥0.89的平均分数。微调方法总体上将平均分数提升至更高的水平（普遍≥0.94），而提示工程方法则表现出较低的统计不确定性。研究还开发并发布了用户界面，以支持多代理人工智能系统的使用，并初步探索了基于化学安全的额外搜索功能。

</details>


### [101] [CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video](https://arxiv.org/abs/2506.20600)
**中文标题：CogGen：一种以学习者为中心的生成式AI架构，用于编程视频的智能辅导**

*Wengxi Li,Roy Pea,Nick Haber,Hari Subramonyam*

主要分类: cs.AI

摘要简述: CogGen是一种以学习者为中心的生成式AI架构，通过将编程视频转化为交互式、自适应的学习体验，结合学生建模与生成式AI辅导，基于认知学徒框架。


<details>
  <summary>详细信息</summary>
研究动机: 传统编程视频教学缺乏互动性和个性化指导，CogGen旨在通过AI技术提升视频教育的交互性和适应性，满足学习者的个性化需求。

研究方法: CogGen包含三个核心组件：(1) 按学习目标分割视频，(2) 基于认知学徒策略的对话式辅导引擎，(3) 使用贝叶斯知识追踪的学生模型以适配教学。

研究结果: 技术评估显示视频分割准确且教学策略在知识、方法、行动和交互层面具有强一致性。消融实验验证了各组件对生成有效指导的必要性。

研究结论: CogGen通过结合结构化学生建模与交互式AI对话，为视频编程教育提供了可扩展的解决方案，推动了AI辅助教学的进步。

中文摘要: 我们介绍了CogGen，一种以学习者为中心的AI架构，通过将学生建模与基于认知学徒框架的生成式AI辅导相结合，将编程视频转化为交互式、自适应的学习体验。该架构包含三个组件：(1) 按学习目标分割视频，(2) 应用认知学徒策略的对话式辅导引擎，(3) 使用贝叶斯知识追踪的学生模型以适配教学。技术评估表明，视频分割准确且教学策略在知识、方法、行动和交互层面具有强一致性。消融实验验证了各组件对生成有效指导的必要性。本研究通过结合结构化学生建模与交互式AI对话，为视频编程教育提供了可扩展的解决方案，推动了AI辅助教学的进步。

</details>


### [102] [AI Assistants to Enhance and Exploit the PETSc Knowledge Base](https://arxiv.org/abs/2506.20608)
**中文标题：AI助手增强与利用PETSc知识库**

*Barry Smith,Junchao Zhang,Hong Zhang,Lois Curfman McInnes,Murat Keceli,Archit Vasan,Satish Balay,Toby Isaac,Le Chen,Venkatram Vishwanath*

主要分类: cs.AI

摘要简述: 本文介绍了利用生成式AI（如大型语言模型LLMs）激活和利用PETSc（高性能科学计算库）分散知识库的初步尝试，通过RAG、重排序算法和聊天机器人等工具，提升用户和开发者的知识获取效率，并优化文档更新。


<details>
  <summary>详细信息</summary>
研究动机: PETSc作为广泛使用的高性能科学计算库，其知识库（包括源代码、文档、邮件列表等）分散且非正式，难以被用户和新开发者有效利用。因此，团队希望通过LLM技术整合这些知识，提升其可访问性和实用性。

研究方法: 团队构建了一个基于LLM的系统，结合RAG（检索增强生成）、重排序算法和聊天机器人等工具，从PETSc的多样化内容中提取信息，并通过用户界面设计支持开发和文档更新。

研究结果: 初步实验表明，该系统能够有效提升PETSc知识的可访问性，尤其是在可扩展Krylov求解器方面，同时为科学软件中的知识中心化AI提供了可扩展框架。

研究结论: 本文为科学软件中的知识中心化AI奠定了基础，未来计划扩展为更强大的平台，以加速科学发现。

中文摘要: 生成式AI，尤其是大型语言模型（LLMs），正在改变技术知识的获取、重用和扩展方式。PETSc作为一种广泛使用的高性能科学计算库，在其三十年的发展过程中积累了丰富但分散的知识库，涵盖源代码、文档、邮件列表、GitLab问题、Discord对话、技术论文等。这些知识大多是非正式的，难以被用户和新开发者访问。为了更有效地激活和利用这些知识，PETSc团队开始构建一个基于LLM的系统，将PETSc内容与自定义LLM工具（包括检索增强生成（RAG）、重排序算法和聊天机器人）结合，以辅助用户、支持开发者并提议更新正式文档。本文介绍了设计和评估这些工具的初步经验，重点关注系统架构、使用RAG和重排序处理PETSc特定信息、评估不同LLM和嵌入模型的方法，以及用户界面设计。利用阿贡国家实验室领导计算设施资源，我们分析了LLM响应如何提升数值软件的开发和使用，初步聚焦于可扩展Krylov求解器。我们的目标是建立一个可扩展的科学软件知识中心化AI框架，支持规模化支持、丰富文档并优化研发工作流程。最后，我们概述了将该系统扩展为一个强大、持续演进的平台的方向，以推动软件生态系统加速科学发现。

</details>


### [103] [Towards Community-Driven Agents for Machine Learning Engineering](https://arxiv.org/abs/2506.20640)
**中文标题：迈向社区驱动的机器学习工程代理**

*Sijie Li,Weiwei Sun,Shanda Li,Ameet Talwalkar,Yiming Yang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于社区驱动的机器学习代理CoMind，通过MLE-Live框架评估其在模拟Kaggle社区中的表现，结果显示其优于79.2%的人类竞争对手。


<details>
  <summary>详细信息</summary>
研究动机: 现有的机器学习代理通常孤立运行，缺乏与社区互动，而人类研究者通过分享知识获得灵感。本文旨在填补这一空白，开发能够与社区交流并利用集体知识的代理。

研究方法: 提出MLE-Live框架评估代理在模拟Kaggle社区中的表现，并在此基础上开发了CoMind代理，专注于在社区环境中交换见解和开发新解决方案。

研究结果: CoMind在MLE-Live框架中表现优异，平均在四个Kaggle竞赛中击败79.2%的人类竞争对手。

研究结论: CoMind展示了社区驱动代理在机器学习研究中的潜力，为未来研究提供了新方向。

中文摘要: 基于大型语言模型的机器学习（ML）代理在自动化ML研究中展现出巨大潜力。然而，现有代理通常孤立运行于特定研究问题，未与更广泛的研究社区互动，而人类研究者常通过分享知识获得灵感并做出贡献。为填补这一空白，我们提出了MLE-Live，一个实时评估框架，旨在评估代理与模拟Kaggle研究社区交流并利用集体知识的能力。基于此框架，我们提出了CoMind，一种在社区环境中擅长交换见解和开发新解决方案的新型代理。CoMind在MLE-Live中表现优异，平均在四个Kaggle竞赛中击败79.2%的人类竞争对手。代码发布于https://github.com/comind-ml/CoMind。

</details>


### [104] [The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind](https://arxiv.org/abs/2506.20664)
**中文标题：用于多智能体推理和心智理论的Decrypto基准测试**

*Andrei Lupu,Timon Willi,Jakob Foerster*

主要分类: cs.AI

摘要简述: 本文提出了Decrypto基准测试，用于评估大型语言模型在多智能体推理和心智理论（ToM）中的表现，填补了现有基准测试的不足，并通过实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）具备代理能力，它们需要在复杂多智能体场景中与人类和其他智能体交互。然而，现有基准测试在心智理论和多智能体能力评估上存在范围狭窄、数据泄漏、饱和及缺乏交互性等问题，亟需新的评估工具。

研究方法: 作者设计了Decrypto基准测试，灵感来自认知科学、计算语用学和多智能体强化学习。该测试简化了其他维度，消除了常见干扰因素，并首次提供了交互式心智理论实验平台。通过实证评估、鲁棒性研究和人机对抗实验验证其设计。

研究结果: 实验发现，LLMs在游戏能力上落后于人类和简单词嵌入基线模型。进一步测试显示，先进推理模型在关键心智理论任务上表现不如旧模型，表明Decrypto填补了当前评估的空白。

研究结论: Decrypto为多智能体推理和心智理论评估提供了重要工具，揭示了现有模型的不足，为未来智能代理的发展指明了方向。

中文摘要: 随着大型语言模型（LLMs）具备代理能力，它们需要在复杂多智能体场景中与人类和其他智能体交互，这需要新的推理技能，尤其是心智理论（ToM），即推理其他智能体“心理”状态的能力。然而，LLMs的ToM和多智能体能力尚不明确，因现有基准测试存在范围狭窄、数据泄漏、饱和及缺乏交互性等问题。为此，我们提出Decrypto，一种基于游戏的基准测试，灵感来自认知科学、计算语用学和多智能体强化学习。其设计尽可能简化其他维度，消除常见干扰因素，并首次提供了交互式ToM实验平台。

我们通过全面实证评估、鲁棒性研究和人机对抗实验验证了该基准设计。结果显示，LLMs的游戏能力落后于人类和简单词嵌入基线模型。随后，我们在Decrypto中设计了两种经典认知科学实验变体，评估三种关键ToM能力。出乎意料的是，先进推理模型在这些任务上表现显著劣于旧模型。这表明Decrypto填补了当前推理和ToM评估的关键空白，为更优人工代理的发展铺平了道路。

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [105] [DeepQuark: deep-neural-network approach to multiquark bound states](https://arxiv.org/abs/2506.20555)
**中文标题：DeepQuark：基于深度神经网络的多夸克束缚态研究方法**

*Wei-Lin Wu,Lu Meng,Shi-Lin Zhu*

主要分类: hep-ph

摘要简述: 本文首次采用基于深度神经网络的变分蒙特卡洛方法研究多夸克束缚态，设计高效架构DeepQuark解决强关联、离散量子数和复杂约束等挑战，在多夸克系统中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 多夸克束缚态的复杂性远超电子或核子系统，传统方法难以应对其强关联和复杂约束。本文旨在开发一种高效方法，突破计算限制，探索多夸克系统的非微扰QCD机制。

研究方法: 提出DeepQuark架构，结合深度神经网络与变分蒙特卡洛方法，处理多夸克系统的强关联、离散量子数和约束相互作用，无需额外计算成本。

研究结果: 在核子、双重重四夸克和全重重四夸克系统中表现优异，尤其在五夸克领域发现弱束缚态分子$P_{cc\bar c}(5715)$及其底夸克伙伴$P_{bb\bar b}(15569)$，推荐实验验证。

研究结论: DeepQuark为多夸克系统研究提供高效框架，突破传统方法限制，有望扩展至更大系统，并为非微扰QCD和强相互作用物理提供新见解。

中文摘要: 首次采用基于深度神经网络的变分蒙特卡洛方法研究多夸克束缚态，其复杂性因强SU(3)色相互作用远超电子或核子系统。我们设计了高效架构DeepQuark，以应对多夸克系统的独特挑战，如强关联、额外离散量子数和难解约束相互作用。该方法在核子、双重重四夸克和全重重四夸克系统中与扩散蒙特卡洛和高斯展开法等先进方法表现相当，尤其在五夸克领域超越现有计算，例如三重重五夸克。在核子中，我们成功引入三体通量管约束相互作用且无需额外计算成本。在四夸克系统中，我们以无偏波函数形式一致描述强子分子$T_{cc}$和紧凑四夸克$T_{bb}$。在五夸克领域，我们获得弱束缚态$\bar D^*\Xi_{cc}^*$分子$P_{cc\bar c}(5715)$（$S=\frac{5}{2}$）及其底夸克伙伴$P_{bb\bar b}(15569)$，它们可视为分子$T_{cc}$的类似物。我们建议在D波$J/\psi \Lambda_c$通道中实验搜索$P_{cc\bar c}(5715)$。DeepQuark有望扩展至更大多夸克系统，克服传统方法的计算障碍，并为探索多夸克态中超越二体相互作用的约束机制提供强大框架，为非微扰QCD和一般多体物理提供宝贵见解。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [106] [PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models](https://arxiv.org/abs/2506.20097)
**中文标题：PSALM-V：利用大语言模型在交互式视觉环境中自动化符号规划**

*Wang Bill Zhu,Miaosen Chai,Ishika Singh,Robin Jia,Jesse Thomason*

主要分类: cs.RO

摘要简述: PSALM-V是首个通过交互在视觉环境中自动推断符号动作语义（如前置和后置条件）的神经符号学习系统，利用大语言模型生成启发式计划和候选符号语义，无需专家定义动作，显著提升了部分观察环境下的计划成功率。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法主要依赖文本领域或不现实的假设（如预定义问题文件、完全可观察性），PSALM-V旨在动态推断PDDL问题文件和动作语义，适用于真实世界的视觉环境和多智能体任务。

研究方法: PSALM-V通过分析执行结果和合成可能的错误解释，动态推断PDDL问题文件和动作语义，迭代生成和执行计划，同时维护动作语义的树状信念结构，直至达成目标状态。

研究结果: 在ALFRED任务中，PSALM-V将计划成功率从37%提升至74%；在RTFM和Overcooked-AI等2D游戏环境中，提高了步骤效率并成功实现了多智能体领域的语义推断。

研究结论: PSALM-V在部分观察和多智能体环境中表现出色，能够有效推断真实世界机器人任务中的PDDL条件，展示了神经符号学习在复杂视觉环境中的潜力。

中文摘要: 我们提出了PSALM-V，这是首个通过交互在视觉环境中自动推断符号动作语义（如前置和后置条件）的自主神经符号学习系统。PSALM-V无需专家定义动作，利用大语言模型生成启发式计划和候选符号语义，从而实现了可靠的符号规划。以往研究主要关注基于文本的领域或依赖不现实的假设（如预定义问题文件、完全可观察性或显式错误消息）。相比之下，PSALM-V通过分析执行结果和合成可能的错误解释，动态推断PDDL问题文件和领域动作语义。该系统迭代生成和执行计划，同时维护每个动作可能语义的树状信念结构，逐步优化这些信念直至达成目标状态。在ALFRED任务模拟实验中，PSALM-V将部分观察环境下的计划成功率从37%（Claude-3.7）提升至74%。在RTFM和Overcooked-AI两个2D游戏环境中的结果表明，PSALM-V提高了步骤效率，并在多智能体设置中成功实现了领域语义推断。此外，尽管机器人底层操作失败，PSALM-V仍能正确推断真实世界机器人BlocksWorld任务的PDDL前置和后置条件。

</details>


### [107] [Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue](https://arxiv.org/abs/2506.20268)
**中文标题：为何机器人难以检测自身错误：人机对话中错误检测的局限性**

*Ruben Janssens,Jens De Bock,Sofie Labat,Eva Verhelst,Veronique Hoste,Tony Belpaeme*

主要分类: cs.RO

摘要简述: 研究发现，机器人在人机对话中检测错误的性能接近随机概率，主要因为用户即使感知到错误也未必反馈给机器人。


<details>
  <summary>详细信息</summary>
研究动机: 人机交互中检测沟通错误对维持用户信任至关重要，但机器人难以像人类一样通过非语言线索识别错误，研究旨在评估机器学习模型在此任务中的表现。

研究方法: 研究使用包含240段人机对话的多模态数据集，引入四种对话失败类型，并利用计算机视觉模型检测错误，同时收集用户反馈以分析模型性能。

研究结果: 尽管采用先进模型，机器人检测沟通错误的性能仅略高于随机概率；人类评分者也仅能识别约一半的错误，表明用户反馈不足是主要限制。

研究结论: 研究揭示了机器人检测对话错误的根本局限性，即用户反馈不足，这为设计更有效的人机对话提供了改进方向。

中文摘要: 在人机交互中检测沟通错误对维持用户参与和信任至关重要。尽管人类能轻松通过语言和非语言线索识别错误，但机器人在解读非语言反馈方面面临巨大挑战，即使计算机视觉在情感表达识别方面有所进展。本研究评估了机器学习模型在机器人对话中检测沟通错误的效果。通过一个包含240段人机对话的多模态数据集，系统引入四种对话失败类型，并评估了先进计算机视觉模型的性能。每次对话后，用户提供是否感知到错误的反馈，从而分析模型检测机器人错误的准确性。尽管使用了先进模型，其检测沟通错误的性能仅略高于随机概率；而在情感表达更丰富的数据集上，模型能成功识别困惑状态。为探究原因，人类评分者也被要求完成相同任务，结果仅能识别约一半的错误，与模型表现相似。这些结果揭示了机器人检测对话错误的根本局限性：即使用户感知到错误，也未必反馈给机器人。这一发现有助于调整对计算机视觉模型性能的预期，并为设计更好的人机对话提供指导，例如在必要时主动获取用户反馈。

</details>


### [108] [Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception](https://arxiv.org/abs/2506.20045)
**中文标题：基于RGB感知的共识驱动不确定性机器人抓取方法**

*Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai*

主要分类: cs.RO

摘要简述: 本文提出一种基于RGB感知的机器人抓取方法，通过训练轻量级网络预测抓取成功概率，避免高不确定性下的任务失败。


<details>
  <summary>详细信息</summary>
研究动机: 现有的深度物体姿态估计器通常过于自信，导致机器人抓取任务在高不确定性下失败。本文旨在通过量化不确定性，提升抓取任务的成功率。

研究方法: 通过真实图像的物体姿态估计和模拟抓取生成训练数据，训练轻量级网络预测抓取成功概率。研究发现，多物体联合训练对网络性能有积极影响。

研究结果: 实验表明，尽管抓取试验中物体变异性高，多物体联合训练仍能提升网络性能，支持抓取任务的成功预测。

研究结论: 本文方法通过量化不确定性，有效提升了机器人抓取任务的成功率，且多物体联合训练对网络性能有显著帮助。

中文摘要: 深度物体姿态估计器通常过于自信。一个既能估计目标物体6自由度姿态又能预测其估计不确定性的抓取代理，可以通过在高不确定性下选择不行动来避免任务失败。尽管物体姿态估计不断改进，不确定性量化研究也持续取得进展，但很少有研究将其与机器人抓取这一下游任务联系起来。我们提出了一种训练轻量级深度网络的方法，用于在尝试抓取之前预测基于图像姿态估计的抓取是否会成功。我们通过真实图像的物体姿态估计和模拟抓取生成训练数据。此外，尽管抓取试验中物体变异性高，网络仍能从多物体联合训练中受益，这表明多样化的物体仍能为同一目标做出贡献。

</details>


### [109] [Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion](https://arxiv.org/abs/2506.20036)
**中文标题：分层强化学习与价值优化在复杂四足运动中的应用**

*Jeremiah Coholich,Muhammad Ali Murtaza,Seth Hutchinson,Zsolt Kira*

主要分类: cs.RO

摘要简述: 本文提出了一种新颖的分层强化学习框架，用于四足机器人在复杂地形上的运动。通过高层策略选择目标，低层策略执行动作，并结合在线优化过程，显著提升了运动性能和避障能力。


<details>
  <summary>详细信息</summary>
研究动机: 四足机器人在复杂地形上的运动是一个具有挑战性的问题。传统的端到端强化学习方法难以高效处理此类任务，因此需要一种更高效的分层框架来优化运动策略。

研究方法: 提出了一种双层分层强化学习框架：高层策略（HLP）选择目标，低层策略（LLP）执行动作。LLP通过基于策略的演员-评论家算法训练，HLP则通过在线优化LLP的价值函数来操作，无需额外训练。

研究结果: 与端到端强化学习方法相比，该框架在多种复杂地形上实现了更高的奖励和更少的碰撞，甚至在训练中未遇到的地形上也表现优异。

研究结论: 分层强化学习框架通过高层策略的目标选择和低层策略的动作执行，显著提升了四足机器人在复杂地形上的运动性能，为机器人运动控制提供了新的思路。

中文摘要: 我们提出了一种新颖的分层强化学习框架，用于四足机器人在复杂地形上的运动。该方法采用双层结构，高层策略（HLP）为低层策略（LLP）选择最优目标。LLP通过基于策略的演员-评论家强化学习算法训练，并以足部落脚点为目标。我们提出的HLP无需额外训练或环境样本，而是通过在线优化LLP的价值函数来操作。通过将其与端到端强化学习方法进行比较，我们证明了该框架的优势。结果表明，该框架能够在多种不同地形（包括训练中未遇到的更复杂地形）上实现更高的奖励和更少的碰撞。

</details>


### [110] [Robust Robotic Exploration and Mapping Using Generative Occupancy Map Synthesis](https://arxiv.org/abs/2506.20049)
**中文标题：基于生成式占用地图合成的鲁棒机器人探索与建图**

*Lorin Achey,Alec Reed,Brendan Crowe,Bradley Hayes,Christoffer Heckman*

主要分类: cs.RO

摘要简述: 本文提出了一种利用生成式占用地图合成技术增强机器人探索能力的新方法，通过SceneSense扩散模型实时预测并融合3D占用地图，显著提升了地图质量和可通行性。


<details>
  <summary>详细信息</summary>
研究动机: 机器人探索中，部分观测数据导致的地图不完整和不可靠是主要挑战。本文旨在通过生成式占用地图合成技术，提升地图的完整性和准确性，从而改善机器人的探索能力。

研究方法: 提出SceneSense扩散模型，用于基于部分观测数据预测3D占用地图，并实时将这些预测结果融合到运行中的占用地图中。该方法在四足机器人上实现，并通过真实环境实验验证其性能。

研究结果: 实验表明，SceneSense增强的占用地图在机器人附近和远距离区域的FID分别提升了24.44%和75.59%。此外，将增强地图集成到现有探索系统中，显著提升了探索的鲁棒性和可通行性时间。

研究结论: SceneSense通过生成式占用地图合成技术，显著提升了机器人探索的地图质量和一致性，为复杂环境中的机器人导航提供了有效解决方案。

中文摘要: 我们提出了一种利用生成式占用地图合成技术增强机器人探索能力的新方法。我们介绍了SceneSense，这是一种专为基于部分观测数据预测3D占用地图而设计的扩散模型。所提出的方法实时将这些预测结果概率性地融合到运行中的占用地图中，显著提升了地图质量和可通行性。我们在四足机器人上实现了SceneSense，并通过真实环境实验验证了其性能。实验结果表明，SceneSense增强的占用地图更接近完全观测的真实数据（机器人附近FID提升24.44%，远距离区域提升75.59%）。此外，将SceneSense增强地图作为“即插即用”的地图改进集成到现有探索系统中，显著提升了鲁棒性和可通行性时间。最后，我们在两种不同环境中进行了完整的探索评估，发现局部增强地图比仅基于直接传感器测量构建的地图提供了更一致的探索结果。

</details>


### [111] [HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction](https://arxiv.org/abs/2506.20566)
**中文标题：HRIBench：用于人机交互中实时人类感知的视觉语言模型基准测试**

*Zhonghao Shi,Enyu Zhao,Nathaniel Dennler,Jingzhen Wang,Xinyang Xu,Kaleen Shrestha,Mengxue Fu,Daniel Seita,Maja Matarić*

主要分类: cs.RO

摘要简述: 本文介绍了HRIBench，一个用于评估视觉语言模型（VLMs）在人机交互（HRI）中实时人类感知能力的基准测试。研究发现，尽管VLMs具有泛化能力，但在核心感知任务上表现不佳，且无法满足实时部署的低延迟需求。


<details>
  <summary>详细信息</summary>
研究动机: 实时人类感知对有效的人机交互至关重要。尽管大型视觉语言模型（VLMs）具有泛化感知能力，但其高延迟问题限制了实际应用。本文旨在通过HRIBench系统研究VLMs在HRI中的感知能力及其性能与延迟的权衡。

研究方法: 作者构建了HRIBench，一个包含1000个视觉问答（VQA）问题的基准测试，涵盖五个关键领域：非语言线索理解、语言指令理解、人机对象关系理解、社交导航和人员识别。数据来自真实HRI环境和公开数据集。随后对11种开源和闭源VLMs进行了全面评估。

研究结果: 结果显示，尽管VLMs具有泛化能力，但在HRI核心感知任务上表现不佳。所有模型均未达到实时部署所需的性能与延迟平衡。

研究结论: 研究表明，当前VLMs在HRI中的实时感知能力仍需改进，未来需开发更小、低延迟且感知能力更强的模型。HRIBench为相关研究提供了基准支持。

中文摘要: 实时人类感知对有效的人机交互（HRI）至关重要。大型视觉语言模型（VLMs）虽然具备泛化的感知能力，但其高延迟问题影响了用户体验，并限制了其在现实场景中的应用。为系统研究VLMs在HRI中的人类感知能力及性能与延迟的权衡，我们提出了HRIBench，一个视觉问答（VQA）基准测试，用于评估VLMs在HRI关键感知任务中的表现。HRIBench涵盖五个关键领域：（1）非语言线索理解，（2）语言指令理解，（3）人机对象关系理解，（4）社交导航，（5）人员识别。为构建HRIBench，我们从真实HRI环境中收集数据以设计非语言线索理解问题，并利用公开数据集覆盖其余四个领域。每个领域包含200个VQA问题，总计1000个问题。随后，我们对11种开源和闭源VLMs进行了全面评估。结果表明，尽管VLMs具有泛化能力，但在HRI核心感知任务上仍存在不足。此外，所有模型均未达到适合实时部署的性能与延迟平衡，凸显了未来开发更小、低延迟且感知能力更强的VLMs的必要性。HRIBench及相关结果可在Github仓库中查看：https://github.com/interaction-lab/HRIBench。

</details>


### [112] [Generating and Customizing Robotic Arm Trajectories using Neural Networks](https://arxiv.org/abs/2506.20259)
**中文标题：使用神经网络生成和定制机械臂轨迹**

*Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Igor Farkaš*

主要分类: cs.RO

摘要简述: 本文提出了一种基于神经网络的方法，用于生成和定制机械臂的轨迹，确保精度和可重复性，并在认知机器人实验中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 为了提高机械臂在与人交互时的动作可预测性，并实现精确的线性运动，本文探索了一种新的神经网络方法。

研究方法: 通过神经网络计算机械臂的正向运动学，并结合关节角度生成器，训练了一个基于人工数据集的神经网络。通过计算角速度，评估了动作的形状和精度。

研究结果: 实验表明，该方法能够生成精确且可定制的轨迹，适用于不同场景，并在NICO机器人上验证了其有效性。

研究结论: 该方法具有广泛适用性，能够成功生成精确且可定制的机械臂轨迹，为机器人动作规划提供了新思路。

中文摘要: 我们提出了一种基于神经网络的方法，用于生成和定制机械臂的轨迹，确保精度和可重复性。为了展示这一新方法的潜力，我们描述了该技术的设计和实现，并在认知机器人的实验环境中展示了其应用。在这一场景中，NICO机器人能够通过精确的线性运动指向空间中的特定点，从而提高了机器人与人类交互时的动作可预测性。为实现这一目标，神经网络计算机械臂的正向运动学，并结合关节角度生成器，开发并训练了另一个神经网络，该网络基于机械臂的起始和结束姿态生成的人工数据集。通过计算角速度，机器人能够执行动作，并从形状和精度方面评估其动作质量。由于其广泛的适用性，我们的方法成功生成了精确且可定制的轨迹，适用于不同场景。

</details>


### [113] [CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition](https://arxiv.org/abs/2506.20373)
**中文标题：CARMA：通过结合视觉语言模型与对象和动作识别实现人机群体交互的情境感知**

*Joerg Deigmoeller,Stephan Hasler,Nakul Agarwal,Daniel Tanneberg,Anna Belardinelli,Reza Ghoddoosian,Chao Wang,Felix Ocker,Fan Zhang,Behzad Dariush,Michael Gienger*

主要分类: cs.RO

摘要简述: CARMA是一种用于人机群体交互情境感知的系统，通过结合视觉语言模型与对象和动作识别，实现对参与者、对象及其交互的准确识别和跟踪。


<details>
  <summary>详细信息</summary>
研究动机: 在群体协作中，机器人需要具备情境感知能力，以正确识别和跟踪参与者、对象及其交互行为，从而支持有效的协作决策。CARMA旨在解决这一问题。

研究方法: CARMA通过唯一标识现实世界中的实体（如参与者和对象），并将其组织为参与者-对象-动作的三元组，实现情境感知。系统结合视觉语言模型与对象和动作识别技术。

研究结果: 实验表明，CARMA能够可靠地生成准确的参与者-动作-对象三元组，支持角色区分、多参与者感知和实例一致性识别。

研究结论: CARMA为需要时空推理和情境决策的协作应用提供了结构化和鲁棒的基础。

中文摘要: 我们介绍了CARMA，一种用于人机群体交互情境感知的系统。在这种群体协作中，有效合作需要基于对当前人员和对象的一致表示以及对参与者和操作对象事件的抽象。这要求对实例进行清晰一致的分配，确保机器人能够正确识别和跟踪参与者、对象及其交互行为。为实现这一点，CARMA唯一标识现实世界中这些实体的物理实例，并将其组织为参与者-对象-动作的三元组。

为验证我们的方法，我们进行了三项实验，涉及多人与机器人交互：协作倾倒、物品传递和分类。这些场景用于评估系统在角色区分、多参与者感知和实例一致性识别方面的能力。实验表明，系统能够可靠地生成准确的参与者-动作-对象三元组，为需要时空推理和情境决策的协作应用提供了结构化和鲁棒的基础。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [114] [FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment](https://arxiv.org/abs/2506.20303)
**中文标题：FundaQ-8：一种基于临床启发的自动眼底图像质量评估评分框架**

*Lee Qi Zun,Oscar Wong Jin Hao,Nor Anita Binti Che Omar,Zalifa Zakiah Binti Asnir,Mohamad Sabri bin Sinal Zainal,Goh Man Fye*

主要分类: eess.IV

摘要简述: 本文提出FundaQ-8，一种基于临床验证的框架，用于系统评估眼底图像质量，并通过深度学习模型预测连续质量分数，提升糖尿病视网膜病变分级的诊断鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 由于眼底图像采集的多样性和专家评估的主观性，自动眼底图像质量评估（FIQA）仍具挑战性。本文旨在通过FundaQ-8框架解决这一问题，提供一种结构化的质量评估方法。

研究方法: 提出FundaQ-8框架，包含八个关键参数（如视野覆盖、解剖可见性、照明和图像伪影），并基于ResNet18回归模型预测0到1范围内的连续质量分数。模型通过迁移学习、均方误差优化和标准化预处理，在1800张临床和Kaggle数据集图像上训练。

研究结果: 在EyeQ数据集上的验证和统计分析证实了FundaQ-8的可靠性和临床可解释性。将其应用于糖尿病视网膜病变分级模型，提升了诊断的鲁棒性。

研究结论: FundaQ-8框架为眼底图像质量评估提供了可靠且临床可解释的方法，其结合深度学习模型的应用显著提升了实际筛查中的诊断性能。

中文摘要: 自动眼底图像质量评估（FIQA）因图像采集的多样性和专家评估的主观性而仍具挑战性。我们提出FundaQ-8，一种经过专家验证的框架，通过八个关键参数（如视野覆盖、解剖可见性、照明和图像伪影）系统评估眼底图像质量。以FundaQ-8为结构化评分参考，我们开发了基于ResNet18的回归模型，预测0到1范围内的连续质量分数。模型在1800张来自真实临床和Kaggle数据集的眼底图像上训练，采用迁移学习、均方误差优化和标准化预处理。在EyeQ数据集上的验证和统计分析证实了该框架的可靠性和临床可解释性。将FundaQ-8整合到糖尿病视网膜病变分级的深度学习模型中，还提升了诊断的鲁棒性，凸显了质量感知训练在实际筛查应用中的价值。

</details>


### [115] [VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration](https://arxiv.org/abs/2506.19975)
**中文标题：VoxelOpt：基于体素自适应消息传递的变形腹部CT配准离散优化方法**

*Hang Zhang,Yuxi Zhang,Jiazheng Wang,Xiang Chen,Renjiu Hu,Xin Tian,Gaolei Li,Min Liu*

主要分类: eess.IV

摘要简述: VoxelOpt是一种结合学习与迭代方法的变形腹部CT配准框架，通过体素自适应消息传递和多级图像金字塔，在精度和效率上优于传统迭代方法，并媲美有监督学习方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于学习的变形图像配准方法在数据有限或大变形时表现不佳，而迭代方法虽精度高但速度慢。VoxelOpt旨在结合两者优势，实现精度与效率的平衡。

研究方法: VoxelOpt利用局部成本体积的位移熵衡量体素信号强度，引入体素自适应消息传递和多级图像金字塔，并采用预训练分割模型提取特征，避免手工设计或对比学习。

研究结果: 在腹部CT配准中，VoxelOpt在效率和精度上均优于主流迭代方法，并与有监督学习方法性能相当。

研究结论: VoxelOpt通过创新的体素自适应消息传递和多级策略，成功平衡了配准精度与运行时间，为变形图像配准提供了高效解决方案。

中文摘要: 近年来，神经网络的发展通过摊销迭代优化改进了变形图像配准（DIR），实现了快速且准确的配准结果。然而，基于学习的方法在训练数据有限或大变形时表现不佳，且在无标签监督时通常不如迭代方法准确。尽管迭代方法在此类场景中精度更高，但其速度远慢于基于学习的方法。为解决这些问题，我们提出了VoxelOpt，一种基于离散优化的DIR框架，结合了学习与迭代方法的优势，以在配准精度和运行时间之间取得更好平衡。VoxelOpt利用局部成本体积的位移熵衡量每个体素的位移信号强度，与早期方法相比有三个关键改进：首先，引入体素自适应消息传递，熵较低的体素受邻居影响较小；其次，采用多级图像金字塔，每级使用27邻域成本体积，避免复杂度指数增长；第三，用预训练的基础分割模型替代手工特征或对比学习进行特征提取。在腹部CT配准中，这些改进使VoxelOpt在效率和精度上均优于主流迭代方法，同时与有监督学习方法的性能相当。源代码将在https://github.com/tinymilky/VoxelOpt 提供。

</details>


### [116] [MS-IQA: A Multi-Scale Feature Fusion Network for PET/CT Image Quality Assessment](https://arxiv.org/abs/2506.20200)
**中文标题：MS-IQA：一种用于PET/CT图像质量评估的多尺度特征融合网络**

*Siqiao Li,Chen Hui,Wei Zhang,Rui Liang,Chenyue Song,Feng Jiang,Haiqi Zhu,Zhixuan Li,Hong Huang,Xiang Li*

主要分类: eess.IV

摘要简述: 本文提出了一种名为MS-IQA的多尺度特征融合网络，用于评估PET/CT图像质量，通过结合ResNet和Swin Transformer的多尺度特征，动态加权通道注意力机制，显著提升了图像质量评估的准确性。同时，构建了一个包含2700张不同质量PET/CT图像的数据集，实验证明该方法优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: PET/CT在医学成像中至关重要，但图像质量下降可能导致诊断不确定性。现有医学图像质量评估方法无法同时考虑低层次特征（如失真）和高层次特征（如器官解剖结构），因此需要一种新的方法来综合评估PET/CT图像质量。

研究方法: 提出MS-IQA网络，结合ResNet和Swin Transformer的多尺度特征，引入动态加权通道注意力机制融合高低层次信息。构建PET-CT-IQA-DS数据集，包含2700张标注质量的PET/CT图像。

研究结果: 在PET-CT-IQA-DS和公开数据集LDCTIQAC2023上的实验表明，MS-IQA在多种图像质量评估指标上优于现有方法。

研究结论: MS-IQA为PET/CT提供了一种准确高效的图像质量评估方法，填补了相关数据集的空白。

中文摘要: 正电子发射断层扫描/计算机断层扫描（PET/CT）在医学成像中扮演重要角色，结合功能和解剖信息以辅助准确诊断。然而，由于噪声、压缩等因素导致的图像质量下降可能引发诊断不确定性并增加误诊风险。在评估PET/CT图像质量时，低层次特征（如失真）和高层次特征（如器官解剖结构）均影响图像的诊断价值。然而，现有医学图像质量评估（IQA）方法无法同时考虑这两种特征。本文提出MS-IQA，一种新颖的多尺度特征融合网络，用于PET/CT图像质量评估，利用ResNet和Swin Transformer的多尺度特征增强其对局部和全局信息的感知能力。此外，还引入了多尺度特征融合模块，通过动态加权通道注意力机制有效结合高低层次信息。最后，为填补PET/CT图像质量评估数据集的空白，我们构建了PET-CT-IQA-DS数据集，包含2700张不同质量的PET/CT图像，并由放射科医生标注质量评分。在我们的数据集和公开数据集LDCTIQAC2023上的实验表明，所提模型在多种图像质量评估指标上优于现有方法。本文为PET/CT提供了一种准确高效的图像质量评估方法。代码和数据集可在https://github.com/MS-IQA/MS-IQA/获取。

</details>


### [117] [Opportunistic Osteoporosis Diagnosis via Texture-Preserving Self-Supervision, Mixture of Experts and Multi-Task Integration](https://arxiv.org/abs/2506.20282)
**中文标题：通过纹理保留自监督学习、专家混合与多任务集成的机会性骨质疏松诊断**

*Jiaxing Huang,Heng Guo,Le Lu,Fan Yang,Minfeng Xu,Ge Yang,Wei Luo*

主要分类: eess.IV

摘要简述: 本文提出一种深度学习框架，通过自监督学习、专家混合架构和多任务集成，解决骨质疏松诊断中的未标记数据利用、设备差异和临床知识整合问题，提升诊断准确性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 骨质疏松症在老龄化人群中风险高，但传统DXA检测资源有限。现有CT分析方法存在未标记数据利用不足、设备差异导致的系统偏差和临床知识整合不足的问题。

研究方法: 方法包括：1）自监督学习利用未标记CT数据并保留骨纹理；2）专家混合架构增强跨设备适应性；3）多任务学习框架整合骨质疏松诊断、BMD回归和椎骨定位预测。

研究结果: 在三个临床站点和外部医院验证中，该方法在骨质疏松筛查和诊断中表现出优于现有方法的泛化能力和准确性。

研究结论: 该框架通过创新技术解决了骨质疏松诊断中的关键问题，为资源有限地区的诊断提供了高效替代方案。

中文摘要: 骨质疏松症以骨矿物质密度（BMD）降低和骨微结构受损为特征，增加了老龄化人群的骨折风险。尽管双能X线吸收法（DXA）是BMD评估的临床标准，但其有限的可用性阻碍了资源有限地区的诊断。机会性计算机断层扫描（CT）分析成为利用现有影像数据进行骨质疏松诊断的有前景替代方法。然而，现有方法存在三个局限性：1）未标记椎骨数据利用不足；2）设备特定DXA差异导致的系统偏差；3）临床知识（如空间BMD分布模式）整合不足。为解决这些问题，我们提出了一种统一的深度学习框架，包含三项创新：首先，利用放射组学表示的自监督学习方法以利用未标记CT数据并保留骨纹理；其次，采用具有学习门控机制的专家混合（MoE）架构以增强跨设备适应性；第三，集成骨质疏松诊断、BMD回归和椎骨定位预测的多任务学习框架。在三个临床站点和外部医院的验证中，我们的方法在机会性骨质疏松筛查和诊断中表现出优于现有方法的泛化能力和准确性。

</details>


### [118] [EAGLE: An Efficient Global Attention Lesion Segmentation Model for Hepatic Echinococcosis](https://arxiv.org/abs/2506.20333)
**中文标题：EAGLE：一种高效的全局注意力肝包虫病病灶分割模型**

*Jiayan Chen,Kai Li,Yulu Zhao,Jianqiang Huang,Zhan Wang*

主要分类: eess.IV

摘要简述: 提出了一种名为EAGLE的高效全局注意力病灶分割模型，用于肝包虫病（HE）的精确分割。该模型结合了渐进视觉状态空间（PVSS）编码器和混合视觉状态空间（HVSS）解码器，通过融合局部与全局特征，实现了高效且准确的分割效果。


<details>
  <summary>详细信息</summary>
研究动机: 肝包虫病（HE）在医疗资源匮乏的牧区广泛流行。现有的CNN和Transformer模型在医学图像分割中存在局限性：CNN缺乏全局上下文建模能力，而Transformer计算成本高。因此，需要一种既能高效建模长序列又能降低计算复杂度的新方法。

研究方法: EAGLE采用U形网络结构，包含PVSS编码器和HVSS解码器。设计了卷积视觉状态空间块（CVSSB）融合局部与全局特征，并通过Haar小波变换块（HWTB）实现无损下采样。

研究结果: 在260名患者的CT切片数据集上，EAGLE的Dice相似系数（DSC）达到89.76%，优于MSVM-UNet 1.61%。

研究结论: EAGLE通过结合状态空间模型的高效性和U形网络的分割能力，为肝包虫病病灶分割提供了高效且准确的解决方案。

中文摘要: 肝包虫病（HE）是医疗资源匮乏牧区中广泛流行的寄生虫病。尽管基于CNN和Transformer的模型已广泛应用于医学图像分割，但CNN因局部感受野而缺乏全局上下文建模能力，而Transformer虽能捕捉长程依赖，但计算成本高。最近，状态空间模型（SSMs，如Mamba）因其能以线性复杂度建模长序列而受到关注。本文提出EAGLE，一种由渐进视觉状态空间（PVSS）编码器和混合视觉状态空间（HVSS）解码器组成的U形网络，协同实现肝包虫病（HE）病灶的高效精确分割。提出的卷积视觉状态空间块（CVSSB）模块用于融合局部与全局特征，而Haar小波变换块（HWTB）模块将空间信息压缩至通道维度以实现无损下采样。由于缺乏公开的HE数据集，我们从当地医院收集了260名患者的CT切片。实验结果表明，EAGLE以89.76%的Dice相似系数（DSC）达到最先进性能，优于MSVM-UNet 1.61%。

</details>


### [119] [Fusing Radiomic Features with Deep Representations for Gestational Age Estimation in Fetal Ultrasound Images](https://arxiv.org/abs/2506.20407)
**中文标题：融合放射组学特征与深度表示用于胎儿超声图像中的孕周估计**

*Fangyijie Wang,Yuan Liang,Sourav Bhattacharjee,Abey Campbell,Kathleen M. Curran,Guénolé Silvestre*

主要分类: eess.IV

摘要简述: 本文提出了一种结合放射组学特征与深度学习表示的新框架，用于胎儿超声图像中的孕周估计，无需测量信息，平均绝对误差为8.0天，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 准确估计孕周对产前护理至关重要，但传统手动测量依赖操作者且耗时，亟需自动化的计算机辅助方法。

研究方法: 采用深度学习模型提取超声图像的深度表示，同时提取放射组学特征以揭示胎儿大脑生长模式，通过融合两类特征估计孕周。

研究结果: 框架在三孕期内的平均绝对误差为8.0天，优于现有机器学习方法，并在不同地理区域的人群中表现出鲁棒性。

研究结论: 提出的特征融合框架在孕周估计中表现出色，兼具高精度和鲁棒性，代码已开源。

中文摘要: 准确估计孕周（GA）是提供优质产前护理的关键，通常通过胎儿超声测量实现。然而，基于手动胎儿生物测量的GA估计依赖操作者且耗时，因此临床实践中需要自动化的计算机辅助方法。本文提出了一种新颖的特征融合框架，用于在无测量信息的情况下通过胎儿超声图像估计GA。我们采用深度学习模型从超声图像中提取深度表示，并提取放射组学特征以揭示胎儿大脑生长的模式和特征。为利用放射组学在医学影像分析中的可解释性，我们通过融合放射组学特征和深度表示来估计GA。我们的框架在三孕期内的平均绝对误差为8.0天，优于当前基于机器学习的方法。实验结果表明，该框架在不同地理区域的多样化人群中具有鲁棒性。代码已在GitHub上公开。

</details>


### [120] [Weighted Mean Frequencies: a handcraft Fourier feature for 4D Flow MRI segmentation](https://arxiv.org/abs/2506.20614)
**中文标题：加权平均频率：一种用于4D Flow MRI分割的手工傅里叶特征**

*Simon Perrin,Sébastien Levilly,Huajun Sun,Harold Mouchère,Jean-Michel Serfaty*

主要分类: eess.IV

摘要简述: 本文提出了一种名为加权平均频率（WMF）的手工特征，用于改善4D Flow MRI图像的分割效果。实验表明，WMF在深度学习和阈值分割任务中显著提高了IoU和Dice分数。


<details>
  <summary>详细信息</summary>
研究动机: 4D Flow MRI图像在量化血流速度场方面具有潜力，但分辨率低和噪声问题影响了分割效果，尤其是血管壁剪切应力等生物标志物的准确性。现有的PC-MRA方法虽为先进，但仍需改进。因此，本文旨在开发一种新的手工特征以提升分割性能。

研究方法: 提出了一种名为加权平均频率（WMF）的手工特征，能够三维显示脉冲流经过的体素区域。通过最优阈值分割和深度学习方法验证了WMF的有效性。

研究结果: 实验结果表明，WMF特征在深度学习和阈值分割任务中显著优于PC-MRA特征，IoU和Dice分数分别提高了0.12和0.13。

研究结论: WMF特征在4D Flow MRI图像分割中表现出显著优势，未来可应用于心脏或大脑等其他血管区域的分割任务。

中文摘要: 近几十年来，4D Flow MRI图像的使用使得在感兴趣体积内和心动周期中量化速度场成为可能。然而，这些生物标志物的分辨率不足和噪声问题是显著挑战。近期研究表明，血管壁剪切应力等生物标志物尤其受到血管分割分辨率低的影响。相位对比磁共振血管成像（PC-MRA）是目前促进分割的最先进方法。本文旨在引入一种新的手工特征，为4D Flow MRI图像提供一种新颖的可视化方法，有助于分割任务。这一特征称为加权平均频率（WMF），能够三维显示脉冲流经过的体素区域，代表了所有脉冲速度体素的包络。通过两个实验验证了该特征的价值：使用最优阈值分割和深度学习方法分割4D Flow MRI图像。结果表明，与PC-MRA特征相比，深度学习任务中IoU和Dice分数分别提高了0.12和0.13。WMF特征有望为其他血管区域（如心脏或大脑）的未来分割过程提供有价值的见解。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [121] [Speaker Embeddings to Improve Tracking of Intermittent and Moving Speakers](https://arxiv.org/abs/2506.19875)
**中文标题：利用说话人嵌入改进间歇性和移动说话人的跟踪**

*Taous Iatariene,Can Cui,Alexandre Guérin,Romain Serizel*

主要分类: eess.AS

摘要简述: 本文提出了一种利用说话人嵌入改进间歇性和移动说话人跟踪的方法，通过后跟踪身份重新分配显著提升了跟踪系统的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统说话人跟踪方法依赖空间观测，但在间歇性和移动说话人场景中，由于说话人位置变化导致轨迹不连续，跟踪效果受限。

研究方法: 提出一种基于说话人嵌入的身份重新分配方法，利用初始跟踪提供的轨迹信息和多通道音频信号，通过波束成形增强信号并提取说话人嵌入，最后基于注册池分配新轨迹身份。

研究结果: 实验表明，该方法显著提升了神经和标准跟踪系统的身份分配性能，并研究了波束成形和输入时长对嵌入提取的影响。

研究结论: 说话人嵌入在改进间歇性和移动说话人跟踪中具有显著效果，为复杂场景下的身份分配提供了有效解决方案。

中文摘要: 说话人跟踪方法通常依赖空间观测来分配连贯的轨迹身份，但在间歇性和移动说话人场景中，由于说话人在非活动期间可能改变位置，导致空间轨迹不连续。本文提出了一种简单的解决方案，即利用说话人嵌入进行身份重新分配。我们通过初始跟踪步骤提供的轨迹信息和多通道音频信号，使用波束成形增强说话人位置的信号以计算说话人嵌入，并基于注册池分配新轨迹身份。在说话人位置变化的场景中评估了该方法的性能，结果表明其显著提升了神经和标准跟踪系统的身份分配性能。此外，我们还研究了波束成形和输入时长对嵌入提取的影响。

</details>


### [122] [MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition](https://arxiv.org/abs/2506.19887)
**中文标题：MATER：多层次声学与文本情感表示用于可解释的语音情感识别**

*Hyo Jin Jon,Longbin Jin,Hyuntaek Jung,Hyunseo Kim,Donghun Min,Eun Yi Kim*

主要分类: eess.AS

摘要简述: 本文提出了一种名为MATER的多层次声学与文本情感表示框架，用于自然条件下的语音情感识别，通过融合声学和文本特征，结合不确定性感知集成策略，显著提升了情感识别的鲁棒性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 自然语音中的情感识别面临复杂性和多样性挑战，包括说话者内和说话者间的变异性。为了解决这些问题，本文旨在开发一种能够有效捕捉语音中细微情感变化和语义信息的框架。

研究方法: MATER框架通过多层次（词、话语和嵌入级别）融合声学和文本特征，结合低层次词汇与声学线索以及高层次上下文表示，同时引入不确定性感知集成策略以减少标注不一致性。

研究结果: MATER在SERNC挑战赛中表现优异，在分类情感识别和情感属性预测任务中分别排名第四，Macro-F1为41.01%，平均CCC为0.5928，并在效价预测中获得第二名的成绩（CCC为0.6941）。

研究结论: MATER框架通过多层次特征融合和不确定性感知策略，显著提升了自然语音情感识别的性能，为复杂情感表达的分析提供了有效工具。

中文摘要: 本文介绍了我们在自然条件下语音情感识别（SERNC）挑战中的贡献，重点解决了分类情感识别和情感属性预测问题。为应对自然语音的复杂性（包括说话者内和说话者间的变异性），我们提出了多层次声学-文本情感表示（MATER），这是一种新颖的分层框架，能够在词、话语和嵌入级别整合声学和文本特征。通过将低层次词汇与声学线索与高层次上下文表示相结合，MATER有效捕捉了细微的韵律变化和语义差异。此外，我们还引入了一种不确定性感知集成策略，以减少标注不一致性，提升模糊情感表达的鲁棒性。MATER在两项任务中均排名第四，Macro-F1为41.01%，平均CCC为0.5928，并在效价预测中以0.6941的CCC成绩获得第二名。

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [123] [Do psychic cells generate consciousness?](https://arxiv.org/abs/2506.20164)
**中文标题：心灵细胞是否产生意识？**

*Mototaka Suzuki,Jaan Aru*

主要分类: q-bio.NC

摘要简述: 本文探讨了大脑中皮层锥体神经元（即"心灵细胞"）是否产生意识，并回顾了近年来在细胞水平上理解意识处理机制的进展。


<details>
  <summary>详细信息</summary>
研究动机: 随着神经科学技术的进步，研究者开始以前所未有的方式探索意识的基本问题。本文旨在回顾并分析皮层锥体神经元在意识生成中的潜在作用。

研究方法: 通过综述近年来的研究进展，重点关注皮层锥体神经元的细胞机制，特别是其树突上分布的代谢型受体在麻醉诱导意识丧失时的反馈信号选择性中断中的作用。

研究结果: 研究发现，皮层锥体神经元的特定细胞机制（尤其是代谢型受体）可能是意识生成和控制的关键。

研究结论: 拉蒙·卡哈尔一个世纪前的直觉可能是正确的，心灵细胞可能确实在意识的生成和控制中发挥核心作用。

中文摘要: 过去几十年的技术进步使神经科学家能够以前所未有的方式探索意识的基本问题。本文回顾了近年来在理解大脑中意识处理的细胞水平机制方面的显著进展。特别引人关注的是皮层锥体神经元——拉蒙·卡哈尔在一百多年前称之为"心灵细胞"——其独特的细胞机制解释了麻醉诱导意识丧失时大脑反馈信号的选择性中断。重要的是，分布在锥体细胞树突上的一类特定代谢型受体被强调为关键的细胞机制。最终，卡哈尔一个世纪前的直觉可能是正确的——我们可能刚刚开始理解心灵细胞是否以及如何生成和控制我们的意识。

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [124] [MNN-AECS: Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection](https://arxiv.org/abs/2506.19884)
**中文标题：MNN-AECS：通过自适应核心选择优化移动设备上LLM解码的能耗**

*Zhengxiang Huang,Chaoyue Niu,Zhaode Wang,Jiarui Xue,Hanming Zhang,Yugang Wang,Zewei Xin,Xiaotang Jiang,Chengfei Lv,Fan Wu,Guihai Chen*

主要分类: cs.OS

摘要简述: MNN-AECS是一种针对移动设备上大型语言模型（LLM）解码的节能优化方案，通过动态选择低功耗CPU核心，显著降低能耗，同时保持解码速度在可接受范围内。


<details>
  <summary>详细信息</summary>
研究动机: 随着设备端大型语言模型（LLM）推理需求的增长，能耗问题成为移动设备的主要挑战，尤其是电池容量有限的设备。现有研究多关注预填充阶段的加速，而忽视了解码阶段的能耗问题。

研究方法: 提出自适应节能核心选择（AECS）技术，并将其集成到MNN中，形成MNN-AECS系统。该系统动态选择低功耗CPU核心，以优化解码阶段的能耗，同时确保解码速度不显著下降。

研究结果: 在5款Android和2款iOS设备上测试5种不同规模的流行LLM，MNN-AECS相比原始MNN平均节能23%，且未显著降低速度。与其他引擎相比，节能效果达39%至78%，速度提升12%至363%。

研究结论: MNN-AECS是首个无需root权限或操作系统修改的引擎级节能解决方案，显著降低了LLM解码的能耗，为移动设备上的高效LLM推理提供了实用方案。

中文摘要: 随着设备端大型语言模型（LLM）推理需求的增长，能耗问题成为移动设备的主要挑战，尤其是电池容量有限的设备。我们的分析表明，内存受限的LLM解码阶段是能耗的主要来源，而现有研究多关注预填充阶段的加速，忽视了能耗问题。我们提出自适应节能核心选择（AECS）技术，并将其集成到MNN中，形成MNN-AECS系统，这是首个无需root权限或操作系统修改的引擎级节能解决方案。MNN-AECS通过动态选择低功耗CPU核心，在保持解码速度可接受的前提下降低能耗。我们在5款Android和2款iOS设备上测试了5种不同规模的流行LLM。相比原始MNN，MNN-AECS平均节能23%，且未显著降低速度。与其他引擎（如llama.cpp、executorch、mllm和MediaPipe）相比，MNN-AECS平均节能39%至78%，速度提升12%至363%。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [125] [WattsOnAI: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads](https://arxiv.org/abs/2506.20535)
**中文标题：WattsOnAI：测量、分析与可视化AI工作负载的能耗与碳足迹**

*Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang*

主要分类: cs.DC

摘要简述: WattsOnAI是一个综合工具包，用于测量、分析和可视化AI工作负载的能耗与碳排放，填补现有工具的不足，支持标准化报告和相关性分析，推动绿色AI实践。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI尤其是大语言模型的快速发展，其训练和推理过程中的能耗与碳排放问题日益突出。然而，现有工具在测量和报告这些影响时往往分散且缺乏系统性，难以支持相关性分析。

研究方法: WattsOnAI通过集成现有AI框架，提供标准化的能耗、功率、硬件性能和碳排放报告，并支持细粒度时间序列数据导出，便于基准测试和可重复性分析。此外，它还支持硬件指标与模型性能的深度相关性分析。

研究结果: WattsOnAI填补了现有工具的不足，提供了全面的能耗与碳排放测量功能，支持标准化报告和深度分析，有助于识别性能瓶颈并推动绿色AI实践。

研究结论: WattsOnAI通过系统化的工具设计，解决了AI工作负载能耗与碳排放测量中的关键问题，鼓励研究社区在追求性能的同时关注环境影响，推动绿色AI的发展。

中文摘要: AI的快速发展，尤其是大语言模型（LLMs），引发了对其训练和推理过程中能耗与碳排放的广泛关注。然而，现有的测量和报告工具往往分散，缺乏系统性指标整合，且对相关性分析的支持有限。本文介绍了WattsOnAI，一个用于测量、分析和可视化AI工作负载能耗、功率、硬件性能及碳排放的综合软件工具包。通过与现有AI框架无缝集成，WattsOnAI提供标准化报告，并导出细粒度时间序列数据，以轻量级方式支持基准测试和可重复性研究。此外，它还支持硬件指标与模型性能的深度相关性分析，从而帮助识别瓶颈并优化性能。通过解决现有工具的关键不足，WattsOnAI鼓励研究社区在关注AI工作负载性能的同时权衡环境影响，推动更可持续的“绿色AI”实践。代码发布于https://github.com/SusCom-Lab/WattsOnAI。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [126] [A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior](https://arxiv.org/abs/2506.19999)
**中文标题：一种用于精细建模阅读行为的时空点过程**

*Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell*

主要分类: cs.LG

摘要简述: 本文提出了一种基于时空点过程的精细阅读行为模型，通过霍克斯过程捕捉注视和扫视的动态特性，发现传统惊讶理论对眼动解释有限。


<details>
  <summary>详细信息</summary>
研究动机: 现有阅读行为模型多基于强假设和聚合数据，忽略了时空动态特性。本文旨在提出更通用的概率模型，以精细捕捉阅读中的注视和扫视行为。

研究方法: 采用标记时空点过程模型，其中扫视通过霍克斯过程建模，捕捉时空邻近性；注视持续时间则结合时间卷积的预测因子建模。

研究结果: 霍克斯过程模型在扫视拟合上优于基线；注视持续时间模型中，上下文惊讶因子的加入对预测精度提升有限。

研究结论: 本文模型能更精细地描述阅读行为，但惊讶理论对眼动的解释能力不足，需进一步研究其他因素。

中文摘要: 阅读是一个在空间和时间中展开的过程，交替表现为注视（读者聚焦于某一点）和扫视（快速转移焦点）。心理语言学的假设认为，建模注视和扫视能揭示读者的在线句子处理机制。然而，传统方法依赖聚合的眼动数据及强假设模型，忽略了阅读中的时空动态特性。本文提出了一种更通用的阅读行为概率模型，基于标记时空点过程，不仅捕捉注视持续时间，还记录其空间位置和时间点。扫视通过霍克斯过程建模，捕捉每次注视对邻近时空新注视的激发效应；注视持续时间则通过时间卷积的预测因子建模，以捕捉溢出效应。实验表明，霍克斯过程模型在扫视拟合上优于基线；而在注视持续时间模型中，加入上下文惊讶因子仅略微提升预测精度，表明惊讶理论难以解释精细眼动。

</details>


### [127] [MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations](https://arxiv.org/abs/2506.20100)
**中文标题：MIRAGE：农业专家引导对话中的多模态信息搜索与推理基准**

*Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve*

主要分类: cs.LG

摘要简述: MIRAGE是一个多模态农业专家对话基准，结合用户查询、专家回答和图像上下文，用于评估模型在真实农业场景中的推理和生成能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准通常依赖明确输入和封闭分类，而农业领域的专家咨询场景复杂且开放，需要模型具备推理和主动引导能力。MIRAGE旨在填补这一空白。

研究方法: 基于35,000+真实用户-专家对话，通过多步流程构建MIRAGE基准，涵盖作物健康、病虫害诊断等场景，包含7,000+生物实体。

研究结果: MIRAGE成为首个覆盖开放世界、多模态农业咨询的基准，支持模型评估推理、澄清策略和长文本生成能力。

研究结论: MIRAGE为多模态模型在农业领域的应用提供了高保真基准，推动了开放场景下的专家级推理研究。

中文摘要: 我们介绍了MIRAGE，一个用于多模态专家级推理和决策的新基准，专为农业领域设计。MIRAGE通过结合自然用户查询、专家撰写的回答和基于图像的上下文，捕捉了专家咨询的复杂性，为评估模型在真实知识密集型领域中的推理、澄清策略和长文本生成能力提供了高保真基准。基于35,000+真实用户-专家对话，并通过精心设计的多步流程构建，MIRAGE涵盖了作物健康、病虫害诊断和作物管理等多种场景。该基准包含7,000+独特的生物实体，覆盖植物种类、害虫和疾病，是视觉语言模型中分类最多样化的基准之一。与现有依赖明确输入和封闭分类的基准不同，MIRAGE以开放世界为背景，要求模型推断潜在知识缺口、处理罕见实体，并主动引导或响应交互。项目页面：https://mirage-benchmark.github.io

</details>


### [128] [Position: Machine Learning Conferences Should Establish a "Refutations and Critiques" Track](https://arxiv.org/abs/2506.19882)
**中文标题：立场：机器学习会议应设立“反驳与批评”专题**

*Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho*

主要分类: cs.LG

摘要简述: 本文主张机器学习会议应设立“反驳与批评”专题，以系统性纠正研究中的错误，促进领域自我修正。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习领域快速发展，但同行评审的局限性导致一些误导性、错误甚至欺诈性研究被接受或突出展示。目前缺乏有效的机制来纠正这些错误，因此需要建立专门的“反驳与批评”专题。

研究方法: 提出在机器学习会议中设立“反驳与批评”专题，并讨论其设计原则、评审标准、潜在问题，并通过ICLR 2025的口头报告案例进行说明。

研究结果: 通过设立“反驳与批评”专题，可以为领域提供一个高声誉的平台，促进对先前研究的批判性挑战，从而推动研究的自我修正。

研究结论: 机器学习会议应建立官方且声誉良好的机制，帮助领域系统性纠正错误，推动研究的健康发展。

中文摘要: 科学通过不断推进和修正人类对世界的理解而进步。在机器学习（ML）研究中，快速的发展导致了大量论文的涌现，但也由于同行评审的局限性，一些误导性、错误、有缺陷甚至欺诈性的研究被接受，有时甚至在ML会议上被突出展示。虽然这些错误是可以理解的，但ML会议并未提供强有力的流程来帮助领域系统性纠正这些错误。本文主张ML会议应设立专门的“反驳与批评”（R & C）专题。这一R & C专题将提供一个高声誉的平台，支持对先前研究进行批判性挑战的重要研究，从而促进一个动态的自我修正研究生态系统。我们讨论了包括专题设计、评审原则、潜在问题等关键考虑因素，并以ICLR 2025的一个口头报告为例进行了说明。我们得出结论，ML会议应建立官方且声誉良好的机制，帮助ML研究实现自我修正。

</details>


### [129] [STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning](https://arxiv.org/abs/2506.19883)
**中文标题：STIMULUS：在随机多目标学习中实现快速收敛和低样本复杂度**

*Zhuqing Liu,Chaosheng Dong,Michinari Momma,Simone Shao,Shaoyuan Xu,Yan Gao,Haibo Yang,Jia Liu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为STIMULUS的新型多目标优化算法，通过递归框架更新随机梯度估计，显著提升了收敛速度和样本复杂度，并进一步提出了带动量项的STIMULUS-M和自适应批处理的STIMULUS+/STIMULUS-M+版本。


<details>
  <summary>详细信息</summary>
研究动机: 多目标优化（MOO）在机器学习、运筹学和工程中有广泛应用，但现有方法在收敛速度和样本复杂度方面表现不佳。本文旨在解决这一问题，提出更高效的算法。

研究方法: STIMULUS通过递归框架更新随机梯度估计，改进收敛性能；STIMULUS-M加入动量项加速收敛；STIMULUS+/STIMULUS-M+采用自适应批处理减少全梯度评估需求。

研究结果: 在非凸和强凸设置下，STIMULUS分别达到O(1/T)和O(exp{-μT})的收敛速度，样本复杂度分别为O(n+√nε⁻¹)和O(n+√nln(μ/ε))，性能优于现有方法。

研究结论: STIMULUS及其变体在多目标优化中表现出优异的收敛速度和样本复杂度，为实际应用提供了高效解决方案。

中文摘要: 近年来，多目标优化（MOO）因其在机器学习、运筹学和工程中的广泛应用而受到关注。然而，MOO算法设计仍处于初级阶段，许多现有方法在收敛速度和样本复杂度方面表现不佳。为解决这一问题，本文提出了一种名为STIMULUS（随机路径积分多梯度递归估计器）的新算法，通过简单而强大的递归框架更新随机梯度估计，以低样本复杂度提升收敛性能。此外，我们还提出了STIMULUS-M，通过加入动量项进一步加速收敛。在非凸和强凸设置下，我们分别证明了O(1/T)和O(exp{-μT})的收敛速度，并实现了O(n+√nε⁻¹)（非凸）和O(n+√nln(μ/ε))（强凸）的样本复杂度。此外，为减少STIMULUS和STIMULUS-M中周期性全梯度评估的需求，我们进一步提出了自适应批处理的增强版本STIMULUS+/STIMULUS-M+，并提供了理论分析。

</details>


### [130] [FlightKooba: A Fast Interpretable FTP Model](https://arxiv.org/abs/2506.19885)
**中文标题：FlightKooba：一种快速可解释的FTP模型**

*Jing Lu,Xuan Wu,Yizhun Tian,Songhan Fan,Yali Fang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于HIPPO方法、Koopman理论和控制论状态空间方程的新型建模与控制框架FlightKooba，用于快速且可解释的飞行轨迹预测（FTP）。该方法显著减少了可训练参数和训练时间，并在实验中表现出优越的时间和内存效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于Koopman理论的FTP模型存在效率低、可解释性差和计算复杂度高的问题，亟需一种快速且可解释的解决方案。

研究方法: FlightKooba结合HIPPO方法、Koopman理论和状态空间方程，直接从数据构建Koopman算子，减少可训练参数并提升计算效率。

研究结果: 实验表明，FlightKooba在时间和内存消耗上表现优越（训练时间接近未加速的Mamba模块，内存减少50%以上，参数数量减少十倍），成功完成FTP任务。

研究结论: FlightKooba为Koopman算子的快速计算提供了新方法，为时间序列预测与控制的结合开辟了新可能。

中文摘要: Koopman理论是一种将非线性系统转换为线性表示的有力工具，而飞行轨迹预测（FTP）是一个复杂的非线性系统。然而，当前将Koopman理论应用于FTP任务的模型效果不佳，可解释性存在问题，且Koopman算子计算量大，导致训练时间长。为解决这一问题，本文提出了一种基于HIPPO方法、Koopman理论和控制论状态空间方程的新型建模与控制框架：FlightKooba。受结构化状态空间方程启发，FlightKooba直接从数据构建Koopman算子。这使得框架具有高度可解释性，并显著减少了模块中的可训练参数，从而大幅降低训练时间。实验证明了FlightKooba建模方法在时间和内存消耗上的优越性（训练时间接近未使用CUDA级加速的Mamba模块；在大多数数据集上内存减少50%以上，参数数量减少十倍），基本完成了FTP任务。它为Koopman算子的快速计算提供了新方法，为时间序列预测与控制的结合开辟了新可能。

</details>


### [131] [Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction](https://arxiv.org/abs/2506.19890)
**中文标题：基于因果感知的自适应关键帧提取智能QoE优化VR交互方法**

*Ziru Zhang,Jiadong Yu,Danny H. K. Tsang*

主要分类: cs.LG

摘要简述: 本文提出了一种结合自适应关键帧提取和因果感知强化学习的智能框架，以优化多用户虚拟现实（VR）交互中的体验质量（QoE）。通过引入新的QoE度量和因果感知强化学习方法，显著降低了交互延迟并提升了公平性。


<details>
  <summary>详细信息</summary>
研究动机: 多用户VR交互中，体验质量（QoE）的优化需要在超低延迟、高保真运动同步和公平资源分配之间取得平衡。现有方法往往忽略带宽、CPU频率与用户感知之间的因果关系，限制了QoE的提升。

研究方法: 提出了一种基于Weber-Fechner定律的新QoE度量，结合感知灵敏度、注意力驱动优先级和运动重建精度。将QoE优化建模为混合整数规划问题，并提出了部分状态因果深度确定性策略梯度（PS-CDDPG）方法，整合因果推理以提升训练效率。

研究结果: 实验基于CMU Motion Capture Database进行，结果表明该框架显著降低了交互延迟，提升了QoE，并保持了公平性，性能优于基准方法。

研究结论: 本文提出的因果感知智能QoE优化框架通过结合自适应关键帧提取和因果感知强化学习，有效解决了VR交互中的QoE优化问题，为未来研究提供了新思路。

中文摘要: 多用户虚拟现实（VR）交互中的体验质量（QoE）优化需要在超低延迟、高保真运动同步和公平资源分配之间取得微妙平衡。尽管自适应关键帧提取减少了传输开销，但现有方法往往忽略了带宽分配、CPU频率与用户感知之间的因果关系，限制了QoE的提升。本文提出了一种智能框架，通过将自适应关键帧提取与因果感知强化学习（RL）相结合来最大化QoE。首先，基于Weber-Fechner定律提出了一种新的QoE度量，结合了感知灵敏度、注意力驱动优先级和运动重建精度。随后，将QoE优化问题建模为混合整数规划（MIP）任务，在公平性约束下联合优化关键帧比例、带宽和计算资源。我们提出了部分状态因果深度确定性策略梯度（PS-CDDPG），该方法将深度确定性策略梯度（DDPG）与因果影响检测相结合。通过利用关于QoE如何受各种动作影响和决定的因果信息，我们探索了由因果推理（CI）计算权重引导的动作，从而提高了训练效率。基于CMU Motion Capture Database的实验表明，我们的框架显著降低了交互延迟，提升了QoE，并保持了公平性，性能优于基准方法。

</details>


### [132] [Orthogonal Soft Pruning for Efficient Class Unlearning](https://arxiv.org/abs/2506.19891)
**中文标题：基于正交软剪枝的高效类别遗忘方法**

*Qinghui Gong,Xue Yang,Xiaohu Tang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于正交卷积核正则化的类感知软剪枝框架，用于高效实现机器遗忘，能够在毫秒级响应时间内快速且精确地遗忘特定类别的知识，同时保留其他类别的预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 机器遗忘旨在选择性移除预训练神经网络中的特定类别知识以满足隐私法规（如GDPR）。现有方法通常在遗忘速度和预测准确性之间难以平衡，要么计算开销大，要么性能下降明显。本文旨在解决这一问题。

研究方法: 提出了一种类感知软剪枝框架，利用正交卷积核正则化，通过训练中的正交约束解耦卷积滤波器和特征表示，并通过激活差异分析高效识别类别特定通道。

研究结果: 在CIFAR-10、CIFAR-100和TinyImageNet上的实验表明，该方法实现了毫秒级响应、目标类别的完全遗忘，且对保留数据的准确性损失极小，显著降低了成员推理攻击风险，并大幅加速了遗忘过程。

研究结论: 该框架为机器学习即服务（MLaaS）场景中的实时机器遗忘提供了一种高效、实用的解决方案。

中文摘要: 机器遗忘旨在从预训练的神经网络中选择性移除特定类别的知识，以满足如GDPR等隐私法规的要求。现有方法通常在遗忘速度和预测准确性之间难以平衡，往往需要较高的计算开销或导致保留类别的性能显著下降。本文提出了一种新颖的类感知软剪枝框架，利用正交卷积核正则化实现快速且精确的遗忘，响应时间达到毫秒级。通过在训练中施加正交约束，我们的方法解耦了卷积滤波器并分离了特征表示，同时通过激活差异分析高效识别类别特定通道。在多种架构和数据集上的广泛评估表明，该方法实现了稳定的剪枝、近乎即时的执行、目标类别的完全遗忘，以及对保留数据的准确性损失极小。在CIFAR-10、CIFAR-100和TinyImageNet上的实验证实，与现有最先进基线相比，我们的方法显著降低了成员推理攻击风险，并将遗忘速度提高了数个数量级。该框架为机器学习即服务（MLaaS）场景中的实时机器遗忘提供了一种高效、实用的解决方案。

</details>


### [133] [Counterfactual Influence as a Distributional Quantity](https://arxiv.org/abs/2506.20481)
**中文标题：反事实影响作为分布性量**

*Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye*

主要分类: cs.LG

摘要简述: 研究发现，机器学习模型记忆训练数据的现象不仅受自身样本影响，还受其他样本（尤其是近似重复样本）的影响。通过将反事实影响视为分布性量，揭示了仅关注自身影响会低估记忆风险，而完整影响分布能更全面捕捉记忆现象。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习模型记忆训练数据的现象引发隐私和泛化担忧。传统反事实自影响指标仅关注单个样本对模型预测的影响，忽略了其他样本（如近似重复样本）的作用。本文旨在通过将反事实影响视为分布性量，全面分析记忆现象。

研究方法: 研究将反事实影响视为分布性量，计算训练样本之间的完整影响分布。通过小型语言模型和图像分类任务（如CIFAR-10），分析影响分布的特性，揭示近似重复样本的作用。

研究结果: 研究发现，仅关注自身影响会严重低估记忆风险，而近似重复样本的存在显著降低自身影响，但仍可能被提取。影响分布分析还揭示了CIFAR-10中近似重复样本的存在。

研究结论: 记忆现象源于训练数据间的复杂交互，完整影响分布比单一自身影响更能全面捕捉记忆风险。

中文摘要: 机器学习模型已知会记忆训练数据中的样本，引发隐私和泛化问题。反事实自影响是研究记忆现象的常用指标，量化了样本是否包含在训练数据中对模型预测的影响。然而，近期研究表明，记忆现象还受其他因素（如近似重复样本）的影响。本文通过将反事实影响视为分布性量，研究所有训练样本如何影响记忆现象。针对小型语言模型，计算了训练样本间的完整影响分布并分析其特性。研究发现，仅关注自身影响会严重低估记忆风险：近似重复样本的存在显著降低自身影响，但这些样本仍可能被提取。在图像分类任务（如CIFAR-10）中，影响分布分析同样揭示了近似重复样本的存在。研究强调，记忆现象源于训练数据间的复杂交互，完整影响分布比单一自身影响更能全面捕捉记忆风险。

</details>


### [134] [Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks](https://arxiv.org/abs/2506.19893)
**中文标题：基于蒸馏的知识对齐在AIGC任务中的生成式语义通信**

*Jingzhi Hu,Geoffrey Ye Li*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DeKA-g的蒸馏知识对齐算法，用于生成式语义通信（GSC）系统，通过将云端生成式AI的知识蒸馏为低秩矩阵，提升边缘设备与用户的知识对齐效率，并适应多样化的无线信道条件。实验表明，DeKA-g显著提升了图像生成对齐效率和信道适应能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成内容（AIGC）的激增，从云端向边缘和移动用户提供AIGC会导致网络流量剧增。生成式语义通信（GSC）通过传输紧凑的提示文本和潜在表示而非高维AIGC数据，提供了一种解决方案。然而，GSC依赖于云端生成式AI与边缘及用户之间的知识对齐，以及无线传输知识与实际信道条件的对齐，这仍具挑战性。

研究方法: 本文提出DeKA-g算法，核心思想是将云端生成式AI的知识蒸馏为低秩矩阵，供边缘设备使用，并适应多样化的无线信道条件。DeKA-g包含两种新方法：元词辅助知识蒸馏（MAKD）和可变速率分组信噪比适应（VGSA）。MAKD通过优化元词提升知识蒸馏效率，VGSA则支持对不同压缩率和信噪比范围的高效适应。

研究结果: 实验结果显示，DeKA-g将边缘生成图像与云端生成图像的对齐效率提升了44%。此外，其压缩率适应效率比基线高116%，在低信噪比条件下的性能提升了28%。

研究结论: DeKA-g通过知识蒸馏和信道适应技术，显著提升了生成式语义通信系统的知识对齐效率和性能，为AIGC的高效传输提供了有效解决方案。

中文摘要: 由于AI生成内容（AIGC）的激增，从云端向边缘和移动用户提供AIGC会导致网络流量剧增。生成式语义通信（GSC）通过传输高度紧凑的信息（如提示文本和潜在表示）而非高维AIGC数据，提供了一种有前景的解决方案。然而，GSC依赖于云端生成式AI（GAI）与边缘及用户之间的知识对齐，以及无线传输知识与实际信道条件的对齐，这仍具挑战性。本文提出DeKA-g，一种基于蒸馏的知识对齐算法，用于GSC系统。其核心思想是将云端GAI的生成知识蒸馏为低秩矩阵，供边缘设备使用，并适应多样化的无线信道条件。DeKA-g包含两种新方法：元词辅助知识蒸馏（MAKD）和可变速率分组信噪比适应（VGSA）。MAKD通过优化元词提升知识蒸馏效率，VGSA则支持对不同压缩率和信噪比范围的高效适应。实验结果表明，DeKA-g将边缘生成图像与云端生成图像的对齐效率提升了44%，压缩率适应效率比基线高116%，并在低信噪比条件下性能提升了28%。

</details>


### [135] [Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards](https://arxiv.org/abs/2506.20520)
**中文标题：非对称REINFORCE用于离策略强化学习：平衡正负奖励**

*Charles Arnal,Gaëtan Narozniak,Vivien Cabannes,Yunhao Tang,Julia Kempe,Remi Munos*

主要分类: cs.LG

摘要简述: 本文研究了一种非对称的离策略REINFORCE算法，通过调整基线V来平衡正负奖励，理论分析表明当V低于期望奖励时算法具有策略改进保证，实验验证了在语言模型微调中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 强化学习在大型语言模型对齐中应用广泛，但离策略方法常导致性能不佳。本文旨在探索介于离策略强化学习和监督微调之间的算法，通过分析简单的离策略REINFORCE算法，揭示正负奖励的平衡机制。

研究方法: 提出一种离策略REINFORCE算法，定义优势函数A=r-V，通过调整基线V来强调高奖励样本或惩罚低奖励样本。理论分析表明当V低于期望奖励时算法具有策略改进保证。

研究结果: 理论分析证明了算法的策略改进性质，实验在随机赌博机设置和语言模型微调任务中验证了算法的有效性，表明离策略更新更依赖正奖励信号。

研究结论: 本文通过理论分析和实验验证，展示了离策略REINFORCE算法在平衡正负奖励方面的优势，为语言模型对齐提供了新思路。

中文摘要: 强化学习（RL）越来越多地用于对齐大型语言模型（LLM）。离策略方法比同策略方法实现更简单且数据效率更高，但通常导致性能不佳。本文研究了介于离策略RL和监督微调之间的算法，通过分析一种简单的离策略REINFORCE算法，其中优势定义为A=r-V，r为奖励，V为可调基线。直观上，降低V会强调高奖励样本，而提高V会加重惩罚低奖励样本。我们首先对该算法进行了理论分析，表明当基线V低于期望奖励时，算法具有策略改进保证。分析揭示，同策略更新可以安全利用正负信号，而离策略更新则更依赖正奖励。我们在随机赌博机设置和微调先进LLM的推理任务中验证了这些发现。

</details>


### [136] [Explaining deep neural network models for electricity price forecasting with XAI](https://arxiv.org/abs/2506.19894)
**中文标题：利用XAI解释电力价格预测的深度神经网络模型**

*Antoine Pesenti,Aidan OSullivan*

主要分类: cs.LG

摘要简述: 本文提出了一种结合深度神经网络（DNN）和可解释人工智能（XAI）的方法，用于电力市场价格预测，并通过SHAP和梯度等解释性方法分析市场动态。


<details>
  <summary>详细信息</summary>
研究动机: 电力市场高度复杂，传统计量经济学方法（白盒模型）预测能力有限，而DNN虽强大但缺乏可解释性。本文旨在通过XAI方法增强对DNN预测结果的理解，揭示电力市场价格驱动因素。

研究方法: 使用DNN进行电力价格预测，并应用SHAP、梯度等XAI方法，结合热图（显著性图）技术，分析五个电力市场中各特征的行为和贡献。此外，引入了SSHAP值和SSHAP线的新概念，以增强高维表格模型的复杂表示。

研究结果: 通过XAI方法成功揭示了电力市场价格动态的关键驱动因素，并验证了DNN模型在预测中的有效性。SSHAP值和SSHAP线的引入进一步提升了模型的可解释性。

研究结论: 本文证明了DNN与XAI结合在电力市场价格预测中的潜力，不仅提高了预测精度，还通过解释性方法增强了市场动态的理解，为未来研究提供了新思路。

中文摘要: 电力市场高度复杂，涉及大量交互和复杂依赖关系，这使得理解市场内部运作和价格驱动因素变得困难。计量经济学方法（白盒模型）已被开发用于此目的，但其预测能力不如深度神经网络模型（DNN）。本文使用DNN预测价格，并利用XAI方法理解市场价格动态的驱动因素，旨在增强对不同电力市场运作方式的理解。为此，我们应用了SHAP和梯度等可解释方法，并结合热图（显著性图）技术，分析了五个电力市场中各特征的行为和贡献。此外，我们引入了SSHAP值和SSHAP线的新概念，以增强高维表格模型的复杂表示。

</details>


### [137] [PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models](https://arxiv.org/abs/2506.20629)
**中文标题：PLoP：精确LoRA放置以实现大型模型的高效微调**

*Soufiane Hayou,Nikhil Ghosh,Bin Yu*

主要分类: cs.LG

摘要简述: PLoP是一种轻量级方法，通过自动识别LoRA适配器的最佳放置位置，显著提升大型模型微调的效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前LoRA适配器的放置策略缺乏系统性研究，不同研究结果不一致，亟需一种自动化的方法来优化适配器放置。

研究方法: PLoP通过直观的理论分析，自动识别给定预训练模型和微调任务中LoRA适配器的最佳放置模块类型。

研究结果: 实验表明，PLoP在监督微调和强化学习任务中始终优于或至少与常用放置策略相当。

研究结论: PLoP为LoRA适配器的放置提供了一种高效且自动化的解决方案，显著提升了微调性能。

中文摘要: 低秩适应（LoRA）是一种广泛用于大型模型微调的方法，其小内存占用使得用户能够以低成本将大型模型适配到特定任务。已有研究通过调整学习率、秩和初始化等方式提升其效率，但适配器放置策略的研究较少且结果不一：原始LoRA论文建议将适配器放置在注意力模块中，而其他研究则建议放在MLP模块中。通过直观的理论分析，我们提出了PLoP（精确LoRA放置），这是一种轻量级方法，能够根据预训练模型和微调任务自动识别LoRA适配器的最佳放置模块类型。通过监督微调和强化学习推理的综合实验，我们证明PLoP始终优于或至少与常用放置策略相当。

</details>


### [138] [A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers](https://arxiv.org/abs/2506.19895)
**中文标题：基于跨层最近邻的不确定性量化框架**

*Miguel N. Font,José L. Jorro-Aragoneses,Carlos M. Alaíz*

主要分类: cs.LG

摘要简述: 本文提出了一种基于神经网络各层最近邻的新框架，用于量化决策不确定性，通过两种新指标提升分类任务中的不确定性估计效果。


<details>
  <summary>详细信息</summary>
研究动机: 神经网络在复杂问题中表现优异，但其错误决策在高风险领域（如医疗诊断和自动驾驶）中可能带来严重后果。因此，量化决策不确定性成为关键需求。

研究方法: 作者提出了一种后处理框架，通过检索与查询在各层激活向量相似的训练案例，设计了两种新指标：决策变化和层不确定性，用于捕捉跨层最近邻类别分布的变化。

研究结果: 在CIFAR-10和MNIST数据集上的实验表明，新指标显著提升了不确定性估计效果，尤其在复杂分类任务中优于基于softmax的置信度方法。

研究结论: 该框架为神经网络决策的不确定性量化提供了有效工具，特别适用于高风险领域，未来可进一步扩展至其他任务。

中文摘要: 神经网络在解决难以检测模式或构建逻辑模型的问题时具有高准确性。然而，这些算法有时会返回错误解，这在医疗诊断或自动驾驶等高危领域中尤为严重。一种检测和缓解这些错误的策略是测量神经网络决策的不确定性。本文提出了一种新颖的后处理框架，通过检索与查询在各层激活向量相似的训练案例，设计了两种新指标：决策变化和层不确定性，用于捕捉跨层最近邻类别分布的变化。我们在CIFAR-10和MNIST数据集的分类模型中评估了该方法。结果表明，这些指标提升了不确定性估计效果，尤其在复杂分类任务中优于基于softmax的置信度。

</details>


### [139] [Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture](https://arxiv.org/abs/2506.19935)
**中文标题：任意顺序GPT作为掩码扩散模型：解耦建模范式与架构**

*Shuchen Xue,Tianyu Xie,Tianyang Hu,Zijin Feng,Jiacheng Sun,Kenji Kawaguchi,Zhenguo Li,Zhi-Ming Ma*

主要分类: cs.LG

摘要简述: 本文通过将掩码扩散模型（MDM）引入仅解码器架构，公平比较了自回归（AR）与MDM范式，并探讨了架构对模型性能的影响。研究发现，仅解码器MDM在生成速度和困惑度上表现优异，同时揭示了范式与架构的权衡。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLM）主要采用自回归（AR）方法，而掩码扩散模型（MDM）作为新兴替代方案，其与AR的比较常因架构差异（解码器vs编码器）而难以公平。本文旨在通过统一架构（仅解码器）直接比较AR与MDM范式，并分析架构对MDM性能的影响。

研究方法: 研究将MDM应用于仅解码器架构，提出“任意顺序自回归”（AO-AR）目标，通过平均所有标记排列优化模型。同时，对比了仅编码器和仅解码器MDM的性能差异，重点关注生成速度和困惑度。

研究结果: 实验表明，仅解码器MDM在生成速度上显著提升（约25倍），且通过温度退火达到与仅编码器MDM相当的困惑度，尽管建模空间更大。此外，标准AO-AR目标因部分排列信息量低而需优化。

研究结论: 本文成功解耦了范式与架构的影响，表明仅解码器MDM在速度和性能上具有优势，为未来模型设计提供了重要参考。代码已开源。

中文摘要: 大型语言模型（LLM）主要采用自回归（AR）方法，但掩码扩散模型（MDM）正成为可行的替代方案。比较AR与MDM的一个关键挑战是其典型架构差异：AR模型多为仅解码器，而MDM多为仅编码器。这种同时改变建模范式与架构的做法使得直接比较不公平，难以区分差异源于范式还是架构。本研究在仅解码器框架下评估MDM，以：（1）公平比较MDM（作为任意顺序AR，AO-AR）与标准AR范式。研究发现，标准AO-AR目标（平均所有标记排列）可能需优化，因许多排列信息量较低。（2）探讨MDM中架构（仅解码器vs仅编码器）的影响。实验表明，仅编码器MDM建模更简单的条件概率空间，而仅解码器MDM尽管建模空间更大，却可实现显著生成加速（约25倍）和通过温度退火达到相近困惑度，凸显了关键权衡。本研究解耦了核心范式与架构的影响，为未来模型设计提供了洞见。代码见https://github.com/scxue/AO-GPT-MDM。

</details>


### [140] [HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization](https://arxiv.org/abs/2506.19992)
**中文标题：HERCULES：基于分层嵌入的递归聚类算法，利用大语言模型实现高效摘要**

*Gabor Petnehazi,Bernadett Aradi*

主要分类: cs.LG

摘要简述: HERCULES是一种新型分层聚类算法，结合大语言模型（LLM）生成语义丰富的聚类标题和描述，提升复杂数据集的可解释性。支持多种数据类型，并提供交互式可视化工具。


<details>
  <summary>详细信息</summary>
研究动机: 随着复杂数据集的爆炸式增长，需要一种不仅能有效分组数据，还能提供人类可理解的聚类结构的工具。HERCULES旨在通过结合LLM增强聚类的语义解释性。

研究方法: HERCULES采用分层k-means聚类，递归地从单个数据点开始构建聚类层次结构。通过LLM生成每个层次聚类的标题和描述，支持两种模式：基于原始数据嵌入的`direct`模式和基于LLM生成摘要嵌入的`description`模式。

研究结果: HERCULES能够从复杂数据集中提取有意义的分层知识，并通过交互式可视化工具帮助用户深入分析聚类结果。

研究结论: HERCULES通过结合LLM和分层聚类，显著提升了复杂数据集的可解释性和实用性，为数据分析提供了新的可能性。

中文摘要: 随着多模态复杂数据集的爆炸式增长，需要一种不仅能有效分组数据，还能提供人类可理解的聚类结构的先进分析工具。我们提出了HERCULES（基于分层嵌入的递归聚类算法，利用大语言模型实现高效摘要），这是一种新颖的算法和Python包，专为分层k-means聚类设计，支持文本、图像和数值数据（每次运行处理一种模态）。HERCULES通过递归应用k-means聚类从第0层的单个数据点开始构建聚类层次结构。其关键创新在于深度集成大语言模型（LLM），为每个层次的聚类生成语义丰富的标题和描述，显著提升了可解释性。该算法支持两种主要表示模式：`direct`模式（基于原始数据嵌入或缩放数值特征进行聚类）和`description`模式（基于LLM生成摘要的嵌入进行聚类）。用户可以提供`topic_seed`以引导LLM生成的摘要朝向特定主题。交互式可视化工具有助于全面分析和理解聚类结果。我们展示了HERCULES的功能，并讨论了其从复杂数据集中提取有意义分层知识的潜力。

</details>


### [141] [TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design](https://arxiv.org/abs/2506.19997)
**中文标题：TRACED：基于转移感知的遗憾近似与共学习性的环境设计**

*Geonwoo Cho,Jaegyun Im,Jihwan Lee,Hojun Yi,Sejin Kim,Sundong Kim*

主要分类: cs.LG

摘要简述: 本文提出TRACED方法，通过结合转移预测误差和共学习性度量，改进无监督环境设计（UED）中的课程生成，显著提升零样本泛化能力并减少环境交互需求。


<details>
  <summary>详细信息</summary>
研究动机: 深度强化学习在未见环境中的泛化能力仍然是一个重大挑战。无监督环境设计（UED）通过教师动态生成高学习潜力的任务，学生从中学习鲁棒策略。然而，现有方法仅通过价值函数损失近似学习潜力（遗憾），忽略了任务间的影响。

研究方法: TRACED方法引入转移预测误差作为遗憾近似的新项，并提出轻量级共学习性度量以捕捉任务间学习影响。结合这两项指标，生成更高效的课程。

研究结果: 实验表明，TRACED生成的课程在多个基准测试中显著提升零样本泛化能力，且环境交互需求减少至基线方法的50%。消融研究证实转移预测误差驱动复杂性快速提升，共学习性进一步增强了性能。

研究结论: 研究表明，通过优化遗憾近似和显式建模任务关系，TRACED能够实现样本高效的课程设计，为UED提供了新思路。

中文摘要: 深度强化学习代理在未见环境中的泛化能力仍是一个重大挑战。无监督环境设计（UED）作为一种共进化框架，通过教师动态生成高学习潜力的任务，学生从中学习鲁棒策略。现有UED方法通常通过遗憾（即最优与当前性能的差距）来衡量学习潜力，仅基于价值函数损失近似。在此基础上，我们引入转移预测误差作为遗憾近似的新项，并提出一种轻量级共学习性度量以捕捉任务间学习影响。结合这两项指标，我们提出了基于转移感知的遗憾近似与共学习性的环境设计（TRACED）。实验表明，TRACED生成的课程在多个基准测试中显著提升零样本泛化能力，且环境交互需求减少至基线方法的50%。消融研究证实转移预测误差驱动复杂性快速提升，共学习性进一步增强了性能。这些结果表明，通过优化遗憾近似和显式建模任务关系，可以实现样本高效的课程设计。

</details>


### [142] [New Insights on Unfolding and Fine-tuning Quantum Federated Learning](https://arxiv.org/abs/2506.20016)
**中文标题：量子联邦学习的展开与微调新见解**

*Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel*

主要分类: cs.LG

摘要简述: 量子联邦学习（QFL）中客户异质性严重影响性能，本文提出一种基于深度展开的新方法，使客户能自主优化超参数（如学习率和正则化因子），动态适应训练行为，显著提升准确率至90%，远超传统方法的55%。


<details>
  <summary>详细信息</summary>
研究动机: 客户异质性导致传统量子联邦学习性能受限，尤其在医疗和基因组研究等关键领域，亟需一种能动态适应不同客户需求的方法以提升模型准确性和鲁棒性。

研究方法: 采用深度展开技术，使客户能自主优化超参数（如学习率和正则化因子），动态适应训练行为，避免过拟合，并在IBM量子硬件和Qiskit Aer模拟器上验证。

研究结果: 在高度异质环境中，该方法准确率达90%，显著优于传统方法的55%，尤其在基因表达分析和癌症检测等应用中表现突出。

研究结论: 通过深度展开框架的收敛感知和可学习优化步骤，本研究解决了传统QFL的核心限制，为医疗和基因组研究等复杂挑战提供了高效解决方案。

中文摘要: 客户异质性对量子联邦学习（QFL）的性能提出了重大挑战。为克服这些限制，我们提出了一种基于深度展开的新方法，使客户能够根据其特定的训练行为自主优化超参数（如学习率和正则化因子）。这种动态适应在高异质性环境中减轻了过拟合并确保了鲁棒的优化，而标准聚合方法在此类环境中往往失效。我们的框架在IBM量子硬件和Qiskit Aer模拟器上的实时训练中实现了约90%的准确率，显著优于传统方法（通常约为55%）。通过开发自适应的微调技术，该方法在基因表达分析和癌症检测等关键应用中尤为有效，提升了量子系统中的诊断精度和预测建模能力。这些成果归功于深度展开框架中固有的收敛感知和可学习优化步骤，保持了模型的泛化能力。因此，本研究解决了传统QFL的核心限制，为其在医疗和基因组研究等复杂挑战中的应用提供了高效途径。

</details>


### [143] [Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting](https://arxiv.org/abs/2506.20024)
**中文标题：详解滚动扩散模型用于概率天气预报**

*Salva Rühling Cachay,Miika Aittala,Karsten Kreis,Noah Brenowitz,Arash Vahdat,Morteza Mardani,Rose Yu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Elucidated Rolling Diffusion Models (ERDM)的新框架，首次成功将滚动预测结构与高性能的Elucidated Diffusion Models (EDM)相结合，用于解决高维混沌系统中的概率天气预报问题。通过改进噪声调度、网络预处理和采样器，ERDM在2D Navier-Stokes模拟和ERA5全球天气预报中表现优于现有基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有的扩散模型在高维混沌系统中通常逐帧预测未来状态，难以捕捉复杂的时间依赖关系，且未明确处理不确定性随时间的增长。尽管已有滚动扩散框架提出，但其与高性能扩散技术的结合仍面临挑战。本文旨在解决这一问题。

研究方法: ERDM框架通过以下关键贡献实现：1) 新颖的损失加权方案，集中模型能力于中等预测范围；2) 使用预训练EDM初始化初始窗口的高效策略；3) 定制化的混合序列架构，用于渐进去噪下的稳健时空特征提取。

研究结果: 在2D Navier-Stokes模拟和ERA5全球天气预报（1.5°分辨率）中，ERDM表现优于包括条件自回归EDM在内的基线模型。

研究结论: ERDM为扩散模型在序列生成问题中的应用提供了一个灵活且强大的框架，特别适用于不确定性随时间增长的任务。代码已开源。

中文摘要: 扩散模型是概率预测的强大工具，但在高维混沌系统中，大多数应用逐帧预测未来状态。这种常见方法难以建模复杂的时间依赖性，且未明确处理系统固有的不确定性随时间增长的问题。尽管已有滚动扩散框架提出，但其与高性能扩散技术的结合仍具挑战性。本文通过引入Elucidated Rolling Diffusion Models (ERDM)，首次成功将滚动预测结构与Elucidated Diffusion Models (EDM)的高性能设计相结合。为此，我们调整了EDM的核心组件（噪声调度、网络预处理和Heun采样器）以适应滚动预测场景。这一成功得益于三项关键贡献：(i) 新颖的损失加权方案，聚焦模型能力于中等预测范围；(ii) 使用预训练EDM初始化初始窗口的高效策略；(iii) 定制化的混合序列架构，用于渐进去噪下的稳健时空特征提取。在2D Navier-Stokes模拟和ERA5全球天气预报（1.5°分辨率）中，ERDM表现优于包括条件自回归EDM在内的基线模型。ERDM为扩散模型在序列生成问题中的应用提供了一个灵活且强大的通用框架，特别适用于不确定性随时间增长的任务。代码已开源：https://github.com/salvaRC/erdm。

</details>


### [144] [FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data](https://arxiv.org/abs/2506.20245)
**中文标题：FedBKD：基于蒸馏的联邦学习以应对非独立同分布数据的泛化与个性化**

*Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu*

主要分类: cs.LG

摘要简述: FedBKD提出了一种无数据蒸馏框架，通过生成对抗网络（GAN）生成合成数据，实现全局模型和局部模型之间的双向知识蒸馏，以解决联邦学习中非独立同分布（non-IID）数据的泛化和个性化问题。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习（FL）面临非独立同分布（non-IID）数据的挑战，现有方法难以同时实现全局模型的泛化和局部模型的个性化。此外，许多解决方案依赖公共数据集，增加了数据泄露风险。FedBKD旨在解决这些问题。

研究方法: FedBKD通过训练GAN生成合成数据，局部模型作为判别器且参数冻结。合成数据用于全局模型和局部模型之间的双向知识蒸馏，以提升双方性能。

研究结果: 在4个基准测试中，FedBKD在不同non-IID设置下均实现了最优性能。

研究结论: FedBKD通过无数据蒸馏框架成功解决了FL中non-IID数据的泛化和个性化问题，且避免了公共数据集带来的数据泄露风险。

中文摘要: 联邦学习（FL）是一种去中心化的协作机器学习技术，解决了工业实践中数据孤岛和数据隐私泄露的问题。FL的主要挑战之一是处理非独立同分布（non-IID）数据。现有解决方案要么专注于构建强大的全局模型，要么定制个性化局部模型，但很少能同时提供泛化良好的全局模型和性能优越的局部模型。此外，许多针对non-IID问题的FL解决方案依赖于引入公共数据集，但这会增加数据泄露风险。为解决这些问题，我们提出了一种新型无数据蒸馏框架——联邦双向知识蒸馏（FedBKD）。具体而言，我们训练生成对抗网络（GAN）生成合成数据。在GAN训练中，局部模型作为判别器且参数冻结。合成数据用于全局模型和局部模型之间的双向知识蒸馏，以实现知识交互，从而提升双方性能。我们在4个基准测试中进行了广泛实验，结果表明FedBKD在所有情况下均达到了最优性能。

</details>


### [145] [Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning](https://arxiv.org/abs/2506.20031)
**中文标题：基于二进制优化和图学习的多智能体行动方案多样化自动生成**

*Prithvi Poddar,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury*

主要分类: cs.LG

摘要简述: 本文提出了一种基于二进制优化和图学习的多智能体行动方案（COA）自动生成方法，用于灾难响应、搜救和军事任务，通过遗传算法和图神经网络实现任务分配与序列优化，显著提升任务完成率和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 多智能体任务（如灾难响应、搜救和军事行动）需要自动化生成多样化的行动方案（COA），以应对环境变化和智能体能力差异。传统方法难以同时满足多样性和任务兼容性需求，亟需新的理论框架和计算工具。

研究方法: 1. 将任务空间和COA池抽象为图结构以量化多样性；2. 将COA生成建模为集中式多机器人任务分配问题，使用遗传算法优化任务分配；3. 采用图神经网络（GNN）通过策略梯度方法优化单智能体任务序列，提升任务完成率。

研究结果: 在模拟环境中测试表明，该方法显著优于随机基线，任务序列优化接近最优解，且能在50分钟内为5个智能体/100个任务的操作生成多达20个COA。

研究结论: 本文提出的框架能够高效生成多样且兼容的COA，适用于复杂多智能体任务，为自动化任务规划提供了实用工具。

中文摘要: 在涉及多智能体的灾难响应、搜救和军事任务中，自动化生成行动方案（COA）的需求日益迫切。环境变化（如雨雪、障碍物等）可能影响COA的预期性能，因此需要生成任务分配多样化的COA池。此外，智能体能力（如人类团队或自主系统）的差异为规划过程带来机遇和挑战。本文提出了一种新的理论框架和计算方法，用于生成具有软性智能体-任务兼容性变化的多样化COA池。关键是将任务空间和COA池抽象为图结构以量化多样性。通过将COA建模为集中式多机器人任务分配问题，采用遗传算法优化任务分配，同时最大化COA池的多样性和智能体-任务映射的兼容性。进一步，使用图神经网络通过策略梯度方法优化单智能体任务序列，以提升任务完成率。模拟环境测试表明，该方法显著优于随机基线，任务序列优化接近最优解，且能在50分钟内为5个智能体/100个任务的操作生成多达20个COA。

</details>


### [146] [Cross-Layer Discrete Concept Discovery for Interpreting Language Models](https://arxiv.org/abs/2506.20040)
**中文标题：跨层离散概念发现：语言模型的可解释性研究**

*Ankur Garg,Xuemin Yu,Hassan Sajjad,Samira Ebrahimi Kahou*

主要分类: cs.LG

摘要简述: 本文提出了一种跨层离散概念发现框架CLVQVAE，用于解构语言模型中各层特征的演化过程，通过向量量化和温度采样技术，将冗余特征压缩为紧凑、可解释的概念向量。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究主要关注单层神经网络表示，忽视了跨层特征的叠加和冗余问题，导致对语言模型内部特征演化的理解不足。本文旨在解决这一问题，提出一种能够跨层分析并压缩冗余特征的方法。

研究方法: 本文提出CLVQVAE框架，结合向量量化和温度采样技术，利用EMA代码本更新和方向相似性聚类（scaled-spherical k-means++），将跨层特征压缩为离散的概念向量。

研究结果: 实验表明，CLVQVAE能够有效解构语言模型中各层特征的演化过程，生成紧凑且可解释的概念向量，优于传统的单层分析方法。

研究结论: CLVQVAE为理解语言模型内部特征演化提供了一种新方法，通过跨层分析和压缩冗余特征，显著提升了模型的可解释性。

中文摘要: 揭示跨变压器层的涌现概念仍是一项重大挑战，因为残差流线性混合并复制信息，模糊了大型语言模型中特征的演化过程。当前研究主要检查单层的神经表示，从而忽略了这种跨层叠加及其引入的冗余。这些表示通常直接分析激活模式，或传递给探测分类器以映射到有限的预定义概念集。为解决这些局限性，我们提出CLVQVAE框架，利用向量量化跨层映射表示，并在过程中将重复的残差流特征压缩为紧凑、可解释的概念向量。我们的方法在量化过程中独特地结合了基于温度的top-k采样与EMA代码本更新，提供了对离散潜在空间的可控探索，同时保持代码本多样性。我们进一步通过方向相似性聚类（scaled-spherical k-means++）初始化代码本，更好地与词嵌入空间中的语义结构对齐。

</details>


### [147] [Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding](https://arxiv.org/abs/2506.20305)
**中文标题：学习中等输入敏感性的函数：以QR码解码为例**

*Kazuki Yoda,Kazuhiko Kawamoto,Hiroshi Kera*

主要分类: cs.LG

摘要简述: 本文研究了中等输入敏感性的函数学习，以QR码解码为例，发现Transformer模型能够通过学习嵌入文本结构成功解码QR码，甚至超越理论纠错极限。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索中等输入敏感性的函数学习，尤其是QR码解码任务，以填补现有研究在输入敏感性谱系中的空白。

研究方法: 采用Transformer模型进行QR码解码，通过训练数据学习嵌入文本的结构，并测试其在多种语言和随机字符串上的泛化能力。

研究结果: 实验结果表明，Transformer能够成功解码QR码，甚至超越理论纠错极限，且能泛化到不同语言和随机字符串。此外，模型更关注数据位而非纠错位。

研究结论: 研究表明Transformer能够有效学习中等输入敏感性的函数，为类似任务提供了新的解决方案。

中文摘要: 学习一个实现目标任务的函数的难度与其输入敏感性相关。例如，图像分类任务对输入不敏感，因为轻微的干扰不应影响分类结果；而算术和符号计算则对输入高度敏感，因为每个输入变量都与计算结果相关。本研究首次提出了基于学习的快速响应（QR）码解码方法，并探讨了中等敏感性函数的学习。实验表明，Transformer通过学习嵌入文本的结构，能够成功解码QR码，甚至超越理论纠错极限。它们能够从以英语为主的训练数据泛化到其他语言甚至随机字符串。此外，我们发现基于Transformer的QR解码器更关注数据位而忽略纠错位，这表明其解码机制与标准QR码阅读器不同。

</details>


### [148] [LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification](https://arxiv.org/abs/2506.20041)
**中文标题：LSH-DynED：一种基于LSH欠采样的动态集成框架用于演化多类别不平衡分类**

*Soheil Abadifard,Fazli Can*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LSH-DynED的动态集成框架，通过基于局部敏感哈希（LSH）的欠采样技术处理多类别不平衡数据流分类问题，显著提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 多类别不平衡数据流的分类是机器学习中的关键难题，尤其是动态不平衡比的处理。现有研究多集中于二分类问题，而对多类别不平衡数据流的关注较少。本文旨在填补这一空白，提出一种鲁棒且高效的方法。

研究方法: 本文结合局部敏感哈希与随机超平面投影（LSH-RHP）技术，提出动态集成多样化（DynED）框架。通过LSH-RHP对多数类进行欠采样，生成平衡训练集，从而提升集成模型的预测性能。

研究结果: 在23个真实数据集和10个半合成数据集上的实验表明，LSH-DynED在Kappa和mG-Mean指标上优于15种现有方法，尤其在大规模、高维度和严重不平衡的数据集中表现优异。

研究结论: LSH-DynED是一种高效且鲁棒的方法，能够有效处理多类别不平衡非平稳数据流，为未来研究提供了重要参考。

中文摘要: 不平衡数据流的分类是机器学习中的关键难题，尤其是在多类别情况下。尽管二分类不平衡数据流任务已受到广泛关注，但多类别不平衡数据流的研究较少。动态不平衡比的有效管理是该领域的核心挑战。本研究通过将局部敏感哈希与随机超平面投影（LSH-RHP）集成到动态集成多样化（DynED）框架中，提出了一种新颖、鲁棒且高效的方法。据我们所知，这是首次将LSH-RHP用于不平衡非平稳数据流的欠采样。所提方法通过LSH-RHP对多数类进行欠采样，提供平衡的训练集，并提升集成预测性能。我们在23个真实数据集和10个半合成数据集上进行了全面实验，并将LSH-DynED与15种先进方法进行比较。结果表明，LSH-DynED在Kappa和mG-Mean指标上优于其他方法，展示了其在处理多类别不平衡非平稳数据流方面的能力。值得注意的是，LSH-DynED在大规模、高维度和严重不平衡的数据集中表现优异，并在实际场景中展现出适应性和鲁棒性。为激励设计，我们回顾了现有不平衡数据流方法，总结了关键挑战，并为未来工作提供了指导。为确保结果可复现，我们已在GitHub上公开了实现代码。

</details>


### [149] [GNN's Uncertainty Quantification using Self-Distillation](https://arxiv.org/abs/2506.20046)
**中文标题：基于自蒸馏的图神经网络不确定性量化**

*Hirad Daneshvar,Reza Samavi*

主要分类: cs.LG

摘要简述: 本文提出了一种基于自蒸馏的图神经网络（GNN）不确定性量化方法，通过单一网络同时作为教师和学生模型，高效且精准地量化预测不确定性，并在实验中验证了其优于传统方法的表现。


<details>
  <summary>详细信息</summary>
研究动机: 在医疗领域，图神经网络（GNNs）表现出色，但其预测不确定性的量化仍具挑战性，而传统贝叶斯和集成方法计算成本高且无法充分捕捉模型多样性。因此，需要一种更高效且精准的不确定性量化方法。

研究方法: 采用自蒸馏技术，同一网络既作为教师模型又作为学生模型，避免了独立训练多个网络的需求。通过开发一种新的不确定性度量方法，为每个GNN分类器分配不同权重，以捕捉网络的多样性。

研究结果: 在MIMIC-IV和Enzymes两个图数据集上的实验表明，该方法能有效量化模型预测不确定性，性能与MC Dropout和集成方法相当，同时计算效率更高。

研究结论: 提出的自蒸馏方法为GNNs提供了一种高效且精准的不确定性量化方案，适用于临床等需要高可信度的场景。

中文摘要: 图神经网络（GNNs）在医疗领域表现出色，但其预测不确定性的量化仍具挑战性，这是临床环境中可信度的重要方面。虽然贝叶斯和集成方法可用于量化不确定性，但计算成本高昂。此外，集成方法用于计算不确定性的分歧度量无法捕捉集成网络中模型的多样性。本文提出了一种基于知识蒸馏的新方法，以更高效且精准地量化GNNs的不确定性。我们采用自蒸馏技术，同一网络既作为教师模型又作为学生模型，从而避免独立训练多个网络。为确保自蒸馏的效果，我们开发了一种不确定性度量方法，通过为每个GNN分类器分配不同权重来捕捉网络的多样性。我们在MIMIC-IV和Enzymes两个图数据集上实验评估了该方法的精度、性能及其在区分分布外数据方面的能力。结果表明，所提方法能有效捕捉模型的预测不确定性，同时性能与MC Dropout和集成方法相当。代码公开于https://github.com/tailabTMU/UQ_GNN。

</details>


### [150] [Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach](https://arxiv.org/abs/2506.20197)
**中文标题：大型语言模型的零样本归因：一种分布测试方法**

*Clément L. Canonne,Yash Pote,Uddalok Sarkar*

主要分类: cs.LG

摘要简述: 本文提出了一种零样本归因工具Anubis，通过分布测试方法解决大型语言模型生成代码的归属问题，实验表明其在高维数据中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型生成代码的普及，如何准确归因代码来源成为重要问题。本文旨在利用假设测试技术，解决高维数据下的归因难题。

研究方法: 提出Anubis工具，将归因问题转化为分布测试问题，利用模型生成的样本和密度估计进行零样本归因。

研究结果: 在代码样本基准测试中，Anubis仅需约2000个样本即可区分不同模型（如DeepSeek-Coder、CodeGemma和Stable-Code），AUROC得分≥0.9。

研究结论: Anubis为零样本归因提供了一种高效且可靠的方法，适用于高维数据场景，具有实际应用潜力。

中文摘要: 随着大型语言模型（LLMs）生成的代码占比不断增加，我们研究了如何利用假设测试技术对这些代码进行归因。给定一组样本$S$和一个可疑模型$\mathcal{L}^*$，我们的目标是评估$S$来自$\mathcal{L}^*$的可能性。由于维度灾难，仅凭LLM的样本难以解决这一问题：为此，我们利用了LLM的样本和密度估计（这种访问方式通常可用）。
  我们提出了$\mathsf{Anubis}$，一种零样本归因工具，将归因问题转化为分布测试问题。在代码样本基准测试中，$\mathsf{Anubis}$仅需约2000个样本即可区分DeepSeek-Coder、CodeGemma和Stable-Code等模型，AUROC得分≥0.9。

</details>


### [151] [Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets](https://arxiv.org/abs/2506.20204)
**中文标题：情感启动分数：一种数据驱动的方法用于检测序列数据集中的启动效应**

*Eduardo Gutierrez Maestro,Hadi Banaee,Amy Loutfi*

主要分类: cs.LG

摘要简述: 本文提出了一种数据驱动的方法——情感启动分数（APS），用于检测序列数据中受启动效应影响的数据点，并通过实验验证其在减少分类错误方面的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 情感计算中启动效应的模糊性是一个重要挑战，现有研究多从标签角度解决，但启动效应对数据本身（尤其是生理信号）的影响尚未充分探索。受启动影响的数据可能导致学习模型的误分类，因此需要一种数据层面的检测方法。

研究方法: 本研究提出APS方法，为每个数据点分配一个分数，量化其受启动效应影响的程度。通过在SEED和SEED-VII数据集上应用APS，对比原始数据与去启动序列的分类效果，验证方法的有效性。

研究结果: 实验表明，使用去启动序列后，模型的误分类率显著降低，证明了APS在检测和消除启动效应方面的有效性。

研究结论: 本研究通过数据层面的启动效应检测与消除，提升了模型鲁棒性，为情感计算数据集的设计与收集提供了新思路。

中文摘要: 情感启动效应凸显了情感计算中模糊性的挑战。尽管学界已从标签角度解决了这一问题，但启动效应对数据本身（尤其是生理信号）的影响仍未被充分探索。受启动影响的数据可能导致学习模型的误分类。本研究提出情感启动分数（APS），一种数据驱动的方法，用于检测受启动效应影响的数据点。APS为每个数据点分配一个分数，量化其受启动影响的程度。为验证该方法，我们将其应用于SEED和SEED-VII数据集，这些数据集包含足够的情感事件转换以展现启动效应。我们使用相同配置训练模型，分别基于原始数据和去启动序列。结果显示，使用去启动序列后，误分类率显著降低。本研究通过数据层面的启动效应识别与消除，为解决模糊性问题提供了新方法，增强了模型鲁棒性，并为情感计算数据集的设计与收集提供了宝贵见解。

</details>


### [152] [Directed Link Prediction using GNN with Local and Global Feature Fusion](https://arxiv.org/abs/2506.20235)
**中文标题：基于局部与全局特征融合的图神经网络有向链接预测**

*Yuyang Zhang,Xu Shen,Yu Xie,Ka-Chun Wong,Weidun Xie,Chengbin Peng*

主要分类: cs.LG

摘要简述: 本文提出了一种融合局部和全局特征的图神经网络框架，用于有向图的链接预测，通过将输入图转换为有向线图以提升性能，实验表明其在多种训练数据比例下优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 有向图的链接预测是图分析中的经典问题，现有深度学习方法通常通过对比学习分析节点相似性或通过图卷积聚合邻域信息。本文旨在结合特征嵌入与社区信息，提升有向链接预测的性能。

研究方法: 提出了一种新的图神经网络框架，融合特征嵌入与社区信息，并通过理论证明这种混合特征能提升性能。此外，提出将输入图转换为有向线图的方法，使节点在图卷积中能聚合更多信息。

研究结果: 在基准数据集上的实验表明，当训练数据比例为30%、40%、50%和60%时，该方法在大多数情况下优于现有最优方法。

研究结论: 本文提出的融合局部和全局特征的GNN框架及有向线图转换方法，显著提升了有向链接预测的性能，为相关领域提供了新的解决方案。

中文摘要: 链接预测是图分析中的一个经典问题，具有许多实际应用。对于有向图，近期发展的深度学习方法通常通过对比学习分析节点相似性，并通过图卷积聚合邻域信息。本文提出了一种新颖的图神经网络（GNN）框架，将特征嵌入与社区信息融合。我们通过理论证明这种混合特征可以提升有向链接预测的性能。为了高效利用这些特征，我们还提出了一种将输入图转换为有向线图的方法，使转换后图中的节点在图卷积过程中能聚合更多信息。在基准数据集上的实验表明，当分别使用30%、40%、50%和60%的连接链接作为训练数据时，我们的方法在大多数情况下优于现有最优方法。

</details>


### [153] [Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models](https://arxiv.org/abs/2506.20251)
**中文标题：Q-resafe：量化大语言模型的安全风险评估与量化感知安全补丁**

*Kejia Chen,Jiawen Zhang,Jiacong Hu,Yu Wang,Jian Lou,Zunlei Feng,Mingli Song*

主要分类: cs.LG

摘要简述: 本文提出Q-resafe框架，用于评估量化大语言模型（LLMs）的安全风险，并通过量化感知的安全补丁修复其安全能力，同时最小化对模型效用的影响。


<details>
  <summary>详细信息</summary>
研究动机: 量化大语言模型（LLMs）在资源受限环境中部署日益重要，但研究表明量化可能损害其安全能力，亟需系统评估和修复策略。

研究方法: 通过主流量化技术和多样化校准数据集进行安全评估，提出Q-resafe框架，以量化感知方式修复量化LLMs的安全漏洞。

研究结果: 实验表明，Q-resafe成功将量化LLMs的安全能力恢复至量化前水平，即使在挑战性场景下也表现优异。

研究结论: Q-resafe为量化LLMs的安全问题提供了有效解决方案，平衡了安全性与模型效用。

中文摘要: 量化大语言模型（LLMs）因其在资源受限环境中的部署潜力而备受关注。然而，近期研究表明，某些无需校准数据集的量化方法可能损害LLMs的安全能力，亟需系统性安全评估和修复策略。本文通过主流量化技术和多样化校准数据集，利用广泛认可的安全基准进行全面安全评估。针对发现的安全漏洞，提出量化感知安全补丁框架Q-resafe，以高效恢复量化LLMs的安全能力，同时最小化对效用的负面影响。大量实验证明，Q-resafe成功将量化LLMs的安全性与量化前模型对齐，即使在挑战性评估场景下也表现优异。项目页面见：https://github.com/Thecommonirin/Qresafe。

</details>


### [154] [Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios](https://arxiv.org/abs/2506.20253)
**中文标题：基于机器学习方法生成的能源消费者时间序列替代数据用于长期预测场景**

*Ben Gerhards,Nikita Popkov,Annekatrin König,Marcel Arpogaus,Bastian Schäfermeier,Leonie Riedl,Stephan Vogt,Philip Hehlert*

主要分类: cs.LG

摘要简述: 本文深入比较了多种数据驱动方法（WGAN、DDPM、HMM和MABF）在生成用于长期能源消费预测的合成时间序列数据方面的性能，旨在提升合成数据的准确性和隐私保护。


<details>
  <summary>详细信息</summary>
研究动机: 电力价值链中的预测研究多集中于短期发电或消费预测，而个体消费者的长期消费预测研究较少。本文旨在填补这一空白，提供高保真合成数据以支持能源系统状态估计和电网规划。

研究方法: 研究评估了四种方法：混合Wasserstein生成对抗网络（WGAN）、去噪扩散概率模型（DDPM）、隐马尔可夫模型（HMM）和掩码自回归伯恩斯坦多项式归一化流（MABF），分析其在复制个体能源消费时间动态、长程依赖性和概率转移方面的能力。

研究结果: 比较分析揭示了WGAN、DDPM、HMM和MABF在生成合成能源消费数据时的优缺点，为状态估计和其他能源相关任务提供了方法选择依据。

研究结论: 本文提出的生成与分析框架提升了合成能源消费数据的准确性和可靠性，同时满足匿名化隐私保护需求，适用于实际应用如状态估计和消费预测。

中文摘要: 预测在电力价值链中吸引了大量研究关注，但大多数研究集中于发电或消费的短期预测，且多关注系统而非个体消费者。个体能源消费的长期预测研究更为稀缺。本文深入比较了多种数据驱动方法在生成用于长期能源消费预测的合成时间序列数据方面的性能。高保真合成数据对能源系统状态估计和电网规划等应用至关重要。本研究评估并比较了四种前沿但较少见的技术：混合Wasserstein生成对抗网络（WGAN）、去噪扩散概率模型（DDPM）、隐马尔可夫模型（HMM）和掩码自回归伯恩斯坦多项式归一化流（MABF）。我们分析了每种方法在复制个体能源消费时间动态、长程依赖性和概率转移方面的能力。比较分析揭示了WGAN、DDPM、HMM和MABF的优缺点，为状态估计和其他能源相关任务的方法选择提供了依据。我们的生成与分析框架旨在提升合成能源消费数据的准确性和可靠性，同时生成满足匿名化隐私保护需求的数据，避免对单个用户的特定分析风险。本研究使用了德国家庭的开源数据集，时间分辨率为15分钟。生成的合成电力配置文件可直接用于状态估计或消费预测等应用。

</details>


### [155] [Argumentative Ensembling for Robust Recourse under Model Multiplicity](https://arxiv.org/abs/2506.20260)
**中文标题：模型多重性下基于论证集成的鲁棒反事实解释**

*Junqi Jiang,Antonio Rago,Francesco Leofante,Francesca Toni*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“论证集成”的新方法，用于在模型多重性（MM）下提供鲁棒的反事实解释（CEs），确保反事实建议在所有模型中均有效。


<details>
  <summary>详细信息</summary>
研究动机: 在机器学习中，模型多重性（MM）导致不同模型对相同输入的预测结果不一致，传统集成方法无法保证反事实解释（CEs）在所有模型中的有效性。因此，需要一种新方法来解决这一问题。

研究方法: 本文提出“论证集成”方法，利用计算论证技术显式表示模型与反事实之间的冲突，并通过论证语义解决冲突，确保反事实解释的鲁棒性。方法还支持对模型偏好的定制。

研究结果: 理论分析表明，论证集成在四种不同论证语义下均表现良好。实证研究验证了该方法在满足六项理想性质方面的有效性。

研究结论: 论证集成方法为模型多重性下的反事实解释提供了鲁棒且灵活的解决方案，支持用户对模型偏好的定制。

中文摘要: 在机器学习中，针对同一预测任务通常会得到多个性能相当的模型，例如通过不同随机种子训练神经网络。模型多重性（MM）指这些竞争模型对相同输入的预测结果不同，此时常采用集成方法对输出进行聚合。在MM下通过反事实解释（CEs）提供反事实建议变得复杂，因为CE可能并非在所有模型中均有效，即CE在MM下缺乏鲁棒性。本文正式定义了MM下的反事实问题，称为“反事实感知集成”（RAE）。我们提出，在MM下，应同时考虑每个模型的反事实解释及其预测结果，以便同步决定聚合预测和反事实。围绕这一思路，我们提出了解决该问题的六项理想性质。针对RAE，我们提出了一种新颖的论证集成方法，确保CE在MM下的鲁棒性。具体而言，该方法利用计算论证技术显式表示模型与反事实在预测结果和CE有效性上的冲突，并通过论证语义解决冲突，最终得到参数化的解决方案。该方法还支持对MM下模型的偏好定制。通过全面的理论分析，我们刻画了四种论证语义下论证集成的行为。实证研究验证了该方法在满足理想性质方面的有效性。

</details>


### [156] [Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration](https://arxiv.org/abs/2506.20307)
**中文标题：有限演示下的超越专家性能：双重探索的高效模仿学习**

*Heyang Zhao,Xingrui Yu,David M. Bossens,Ivor W. Tsang,Quanquan Gu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ILDE的新型模仿学习算法，通过双重探索（乐观策略优化和好奇心驱动探索）在有限演示下实现超越专家性能，并在Atari和MuJoCo任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 模仿学习的目标是学习一个模仿专家行为的策略，但在实践中，由于状态空间的复杂性，从有限的演示中准确学习专家策略具有挑战性。此外，为了实现超越专家性能，探索环境和收集数据至关重要。

研究方法: ILDE算法通过双重探索实现：1）乐观策略优化，通过奖励高不确定性的状态-动作对以加速收敛到专家策略；2）好奇心驱动探索，探索偏离演示轨迹的状态以实现超越专家性能。

研究结果: 实验表明，ILDE在样本效率上优于现有模仿学习算法，并在Atari和MuJoCo任务中以更少的演示实现了超越专家性能。理论分析表明，ILDE是一种不确定性正则化的策略优化方法，具有乐观探索特性。

研究结论: ILDE通过双重探索机制在有限演示下实现了高效的模仿学习和超越专家性能，为模仿学习领域提供了新的解决方案。

中文摘要: 模仿学习是强化学习中的一个核心问题，其目标是学习一个模仿专家行为的策略。然而，由于状态空间的复杂性，从有限的演示中准确学习专家策略具有挑战性。此外，为了实现超越专家性能，探索环境和收集数据至关重要。为此，我们提出了一种名为双重探索模仿学习（ILDE）的新算法，该算法在两方面实现探索：1）通过乐观策略优化，奖励高不确定性的状态-动作对以加速收敛到专家策略；2）通过好奇心驱动探索，探索偏离演示轨迹的状态以实现超越专家性能。实验表明，ILDE在样本效率上优于现有模仿学习算法，并在Atari和MuJoCo任务中以更少的演示实现了超越专家性能。我们还从理论上证明了ILDE作为一种不确定性正则化的策略优化方法，具有乐观探索特性，其遗憾随情节数呈次线性增长。

</details>


### [157] [Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach](https://arxiv.org/abs/2506.20323)
**中文标题：基于迁移学习的农作物病害检测深度学习模型比较分析**

*Saundarya Subramaniam,Shalini Majumdar,Shantanu Nadar,Kaustubh Kulkarni*

主要分类: cs.LG

摘要简述: 本研究通过迁移学习方法比较了多种深度学习模型在农作物病害检测中的效果，其中自定义CNN模型验证准确率达95.76%，展示了AI在农业中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 旨在为资源有限的农村地区农民开发AI驱动的农作物病害检测系统，通过比较不同深度学习模型的迁移学习效果，提升农业病害管理的效率和可持续性。

研究方法: 研究采用迁移学习方法，比较了EfficientNet、ResNet101、MobileNetV2和自定义CNN模型在农作物病害分类中的表现。

研究结果: 自定义CNN模型表现最佳，验证准确率达95.76%，表明迁移学习在农作物病害检测中具有显著效果。

研究结论: 研究证明了迁移学习在农业病害检测中的潜力，可为农村地区提供高效的作物健康管理方案，推动可持续农业发展。

中文摘要: 本研究开发了一种基于人工智能（AI）的农作物病害检测系统，旨在帮助资源有限的农村地区农民。通过比较不同深度学习模型在迁移学习中的效果，包括EfficientNet、ResNet101、MobileNetV2和自定义CNN（验证准确率达95.76%），系统能有效分类植物病害。研究表明，迁移学习有望重塑农业实践，改善作物健康管理，并支持农村地区的可持续农业。

</details>


### [158] [DipSVD: Dual-importance Protected SVD for Efficient LLM Compression](https://arxiv.org/abs/2506.20353)
**中文标题：DipSVD：双重重要性保护的SVD用于高效LLM压缩**

*Xuan Ding,Rui Sun,Yunjian Zhang,Xiu Yan,Yueqi Zhou,Kaihao Huang,Suzhong Fu,Chuanlong Xie,Yao Zhu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DipSVD的双重重要性保护SVD方法，用于高效压缩大型语言模型（LLM）。通过局部和全局重要性保护机制，DipSVD在压缩模型时显著提升了性能，尤其是在高压缩比下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）的计算需求和部署成本不断增加，催生了多种压缩方法。尽管SVD压缩在硬件兼容性和理论保证上优于量化和非结构化剪枝，但现有方法忽略了矩阵中关键组件的保护，导致压缩模型性能下降。本文旨在通过双重重要性保护机制解决这一问题。

研究方法: DipSVD采用双重重要性保护机制：(1) 局部重要性保护：通过通道加权数据白化保留每个权重矩阵中最关键的奇异向量；(2) 全局重要性保护：通过启发式或优化方法，让不重要的层承担更多压缩负担，从而减少对关键层的影响。

研究结果: 实验表明，DipSVD在多个基准测试中优于现有的基于SVD的压缩方法，尤其是在高压缩比下，模型性能显著提升。

研究结论: DipSVD通过双重重要性保护机制，显著提升了SVD压缩方法的性能，为高效压缩大型语言模型提供了新思路。

中文摘要: 大型语言模型（LLM）日益增长的计算需求和部署成本催生了多种压缩方法。与量化和非结构化剪枝相比，SVD压缩具有更好的硬件兼容性和理论保证。然而，现有的基于SVD的方法关注原始矩阵与压缩矩阵之间的整体差异，而忽略了矩阵中关键组件的保护，导致压缩模型性能不佳。本文提出了一种双重重要性保护机制来增强基于SVD的压缩方法：(1) 局部重要性保护：通过通道加权数据白化保留每个权重矩阵中最关键的奇异向量；(2) 全局重要性保护：通过启发式或优化方法，让不重要的层承担更多压缩负担，从而减少对关键层的影响。大量实验表明，DipSVD在多个基准测试中优于现有的基于SVD的压缩方法，尤其是在高压缩比下实现了更优的模型性能。

</details>


### [159] [A foundation model with multi-variate parallel attention to generate neuronal activity](https://arxiv.org/abs/2506.20354)
**中文标题：基于多变量并行注意力的神经元活动生成基础模型**

*Francesco Carzaniga,Michael Hersche,Abu Sebastian,Kaspar Schindler,Abbas Rahimi*

主要分类: cs.LG

摘要简述: 本文提出了一种新型的多变量并行注意力机制（MVPA），用于处理多变量时间序列数据，特别是在临床颅内脑电图（iEEG）领域。MVPA通过解耦内容、时间和空间注意力，实现了对通道数量和配置变化的灵活建模。基于MVPA，作者构建了MVPFormer，一个生成性基础模型，用于预测iEEG信号的演变。此外，作者发布了目前最大的公开iEEG数据集SWEC，并验证了MVPFormer在癫痫检测和时间序列任务中的优异性能。


<details>
  <summary>详细信息</summary>
研究动机: 多变量时间序列数据（如iEEG）的通道配置在不同受试者间差异显著，这对深度神经网络（DNNs）提出了挑战。现有方法难以灵活处理这种异构性，因此需要一种能够适应不同通道配置的通用注意力机制。

研究方法: 作者提出了多变量并行注意力（MVPA），通过解耦内容、时间和空间注意力，实现对异构时间序列的高效建模。基于MVPA，构建了MVPFormer模型，用于生成iEEG信号。同时，发布了SWEC数据集，包含近10,000小时的iEEG记录。

研究结果: MVPFormer在SWEC、MAYO和FNUSA数据集上表现出色，实现了跨受试者的强泛化能力，并在癫痫检测中达到专家水平。MVPA在标准时间序列预测和分类任务中也优于现有注意力模型。

研究结论: MVPA是一种适用于异构时间序列的通用注意力机制，MVPFormer是首个开源、开放权重和开放数据的iEEG基础模型，具有领先的临床性能。

中文摘要: 从具有异构通道配置的多变量时间序列中学习仍然是深度神经网络（DNNs）的一项基本挑战，尤其是在临床领域如颅内脑电图（iEEG）中，不同受试者的通道设置差异显著。本文提出了一种新型的自注意力机制——多变量并行注意力（MVPA），它通过解耦内容、时间和空间注意力，实现了对通道数量和配置变化的灵活、通用且高效的建模。我们利用MVPA构建了MVPFormer，一个用于人类电生理学的生成性基础模型，旨在预测不同受试者的iEEG信号演变。为支持社区的研究，我们发布了SWEC iEEG数据集，这是目前最大的公开iEEG数据集，包含来自异构临床源的近10,000小时记录。MVPFormer通过MVPA实现了跨受试者的强泛化能力，在癫痫检测中表现出专家级性能，并在SWEC、MAYO和FNUSA数据集上优于现有Transformer基线模型。我们进一步在标准时间序列预测和分类任务中验证了MVPA，其表现与现有注意力模型相当或更优。综上，我们的贡献确立了MVPA作为异构时间序列的通用注意力机制，以及MVPFormer作为首个开源、开放权重和开放数据的iEEG基础模型，具有领先的临床性能。代码发布于https://github.com/IBM/multi-variate-parallel-transformer。SWEC iEEG数据集发布于https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg。

</details>


### [160] [Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations](https://arxiv.org/abs/2506.20362)
**中文标题：基于谱自举和拉普拉斯增强的自监督图学习**

*Lorenzo Bini,Stephane Marchand-Maillet*

主要分类: cs.LG

摘要简述: 本文提出LaplaceGNN，一种新颖的自监督图学习框架，通过谱自举技术和拉普拉斯增强，无需负采样即可有效捕获图结构表示。


<details>
  <summary>详细信息</summary>
研究动机: 现有自监督图学习方法依赖负采样或手工增强，效率低且复杂。本文旨在通过拉普拉斯信号和谱自举技术，提供一种更简单高效的自监督学习方案。

研究方法: LaplaceGNN结合拉普拉斯信号和谱自举技术，通过最大-最小中心性优化预计算谱增强，并采用对抗性自举训练方案增强特征学习和鲁棒性。

研究结果: 实验表明，LaplaceGNN在多个基准数据集上优于现有自监督图学习方法，展示了高效学习图表示的潜力。

研究结论: LaplaceGNN为自监督图学习提供了一种高效且表达力强的解决方案，无需依赖负采样或手工增强。

中文摘要: 我们提出LaplaceGNN，一种新颖的自监督图学习框架，通过谱自举技术避免了负采样的需求。该方法将拉普拉斯信号整合到学习过程中，使模型能够有效捕获丰富的结构表示，而无需依赖对比目标或手工增强。通过专注于正对齐，LaplaceGNN实现了线性扩展，同时为图神经网络提供了一种更简单、更高效的自监督替代方案，适用于多种领域。我们的贡献包括：通过最大-最小中心性引导的优化预计算谱增强，实现无需手工增强的丰富结构监督；随后整合对抗性自举训练方案，进一步增强特征学习和鲁棒性。在多个基准数据集上的广泛实验表明，LaplaceGNN优于当前最先进的自监督图学习方法，为高效学习表达性图表示提供了有前景的方向。

</details>


### [161] [Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning](https://arxiv.org/abs/2506.20413)
**中文标题：客户端聚类与知识共享的结合：增强个性化点对点学习中的隐私与鲁棒性**

*Mohammad Mahdi Maheri,Denys Herasymuk,Hamed Haddadi*

主要分类: cs.LG

摘要简述: 本文提出了一种名为P4的个性化、隐私保护的P2P学习方法，通过轻量级去中心化算法检测客户端相似性并形成协作组，利用差分隐私知识蒸馏共同训练模型，在保证隐私和鲁棒性的同时提升准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在IoT生态系统中的广泛应用，如何在资源受限的异构设备上实现高效且隐私保护的个性化学习成为关键挑战。现有方法在知识共享、隐私保护和对抗攻击鲁棒性方面存在不足。

研究方法: P4方法采用轻量级去中心化算法检测客户端相似性并形成协作组，组内通过差分隐私知识蒸馏共同训练模型，确保隐私和鲁棒性。

研究结果: 实验表明，P4在基准数据集上比现有差分隐私P2P方法准确率提升5%至30%，且在30%恶意客户端情况下仍保持鲁棒性，资源开销仅增加约7秒。

研究结论: P4为资源受限的IoT设备提供了一种高效、隐私保护且鲁棒的个性化学习解决方案，显著提升了准确性和实用性。

中文摘要: 人工智能（AI）在物联网（IoT）生态系统中的广泛应用加剧了对高效且隐私保护的个性化学习方法的需求。然而，在去中心化环境中实现有效的个性化学习面临诸多挑战，包括客户端间的高效知识转移、数据隐私保护以及对投毒攻击的鲁棒性。本文通过开发P4（个性化、隐私保护的点对点）方法解决这些挑战，旨在为资源受限的IoT设备提供个性化模型，同时确保差分隐私和对抗投毒攻击的鲁棒性。我们的解决方案采用轻量级、完全去中心化的算法，以隐私保护的方式检测客户端相似性并形成协作组。组内客户端利用差分隐私知识蒸馏共同训练模型，在保持高准确性的同时确保对恶意客户端的鲁棒性。我们在多种异构设置和攻击场景下，使用线性和基于CNN的架构对P4在流行基准数据集上进行了评估。实验结果表明，P4比领先的差分隐私点对点方法准确率提高了5%至30%，并在30%恶意客户端的情况下仍保持鲁棒性。此外，我们通过在资源受限设备上部署P4验证了其实用性，两个客户端之间的协作训练仅增加约7秒的开销。

</details>


### [162] [Off-Policy Evaluation and Learning for the Future under Non-Stationarity](https://arxiv.org/abs/2506.20417)
**中文标题：非平稳环境下未来策略的离策略评估与学习**

*Tatsuhiro Shimizu,Kazuki Kawamura,Takanori Muroi,Yusuke Narita,Kei Tateno,Takuma Udagawa,Yuta Saito*

主要分类: cs.LG

摘要简述: 本文提出了一种名为OPFV的新估计器，用于在非平稳环境中准确估计和优化未来策略价值，通过利用时间序列数据中的结构（如季节性、周效应等）来减少偏差，并进一步扩展为策略梯度方法。


<details>
  <summary>详细信息</summary>
研究动机: 在非平稳环境中（如电子商务推荐系统），现有方法假设环境平稳或依赖严格的奖励建模假设，导致显著偏差。本文旨在解决这一问题，提出一种能够准确估计和优化未来策略价值的方法。

研究方法: 提出了一种名为OPFV的新估计器，通过时间序列数据中的结构（如季节性、周效应等）进行重要性加权，以准确估计未来策略价值。此外，还扩展为一种策略梯度方法，用于仅使用历史数据主动学习未来策略。

研究结果: 实验结果表明，OPFV在非平稳环境下显著优于现有方法，能够更准确地估计和优化未来策略价值。

研究结论: OPFV通过利用时间序列数据中的结构，有效解决了非平稳环境下的未来策略价值估计和优化问题，为实际应用提供了可靠工具。

中文摘要: 我们研究了未来离策略评估（F-OPE）和学习（F-OPL）的新问题，旨在在非平稳环境中估计和优化策略的未来价值。例如，在电子商务推荐中，目标通常是利用上个月旧策略收集的数据来估计和优化下个月的策略价值。关键挑战是未来环境相关的数据在历史数据中未被观察到。现有方法假设环境平稳或依赖严格的奖励建模假设，导致显著偏差。为解决这些限制，我们提出了一种名为OPFV的新估计器，专为准确估计任何未来时间点的策略价值而设计。OPFV的关键特点是能够利用时间序列数据中的有用结构（如季节性、周效应或节假日效应）。我们的估计器首次通过一种新型重要性加权利用这些时间相关结构，实现有效的F-OPE。理论分析确定了OPFV低偏差的条件。此外，我们扩展了估计器，开发了一种新的策略梯度方法，仅使用历史数据主动学习未来策略。实验结果表明，我们的方法在非平稳环境下显著优于现有方法，能够更准确地估计和优化未来策略价值。

</details>


### [163] [Automatic Demonstration Selection for LLM-based Tabular Data Classification](https://arxiv.org/abs/2506.20451)
**中文标题：基于大语言模型的表格数据分类自动演示样本选择**

*Shuchu Han,Wolfgang Bruckner*

主要分类: cs.LG

摘要简述: 本文提出了一种基于谱图理论的算法，用于自动选择适合的演示样本数量，以优化基于大语言模型（LLM）的表格数据分类任务。该方法综合考虑数据分布、用户提示模板和LLM特性，通过构建相似性图并分析其特征值，确定最小演示样本数。实验验证了其优于随机选择算法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 在基于上下文学习（ICL）的表格数据分类中，如何确定提示中演示样本的理想数量是一个关键问题。传统方法通常依赖随机选择，缺乏对数据分布和模型特性的综合考虑。本文旨在解决这一问题，提出一种自动选择演示样本数量的算法。

研究方法: 本文提出了一种基于谱图理论的算法，通过定义新的相似性度量，构建相似性图并分析其拉普拉斯矩阵的特征值，从而确定能够代表数据的最小演示样本数量。该方法还整合了用户选择的提示模板和特定LLM的特性。

研究结果: 实验结果表明，本文提出的算法在多种数据集和LLM上均优于传统的随机选择方法，能够更高效地确定演示样本数量，提升分类性能。

研究结论: 本文提出的自动演示样本选择算法通过谱图理论和综合考量数据分布、提示模板及LLM特性，有效解决了表格数据分类中的演示样本数量选择问题，为ICL的实际应用提供了有力支持。

中文摘要: 在基于上下文学习（ICL）的表格数据分类中，如何确定提示中演示样本的理想数量是一个核心问题。本文通过提出一种算法来自动选择合理的演示样本数量，解决了这一挑战。该方法的独特之处在于不仅整合了表格数据的分布，还结合了用户选择的提示模板和特定大语言模型（LLM）的特性。基于谱图理论，本文提出的算法定义了一种新的度量标准，用于量化不同演示样本之间的相似性。随后，我们构建了一个相似性图，并通过分析其拉普拉斯矩阵的特征值，推导出能够在LLM的内在表示空间中代表数据的最小演示样本数量。通过在不同数据集和LLM上与传统随机选择算法的对比实验，我们验证了该方法的有效性。

</details>


### [164] [Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation](https://arxiv.org/abs/2506.20525)
**中文标题：基于数字孪生生成数据集和高效数据增强的工业能耗分解**

*Christian Internò,Andrea Castellani,Sebastian Schmitt,Fabio Stella,Barbara Hammer*

主要分类: cs.LG

摘要简述: 为解决工业非侵入式负载监测（NILM）中高质量数据稀缺和工业能耗模式复杂多变的问题，本文提出了一种基于数字孪生模拟生成的合成工业数据集（SIDED）和高效的设备调制数据增强方法（AMDA）。实验表明，AMDA显著提升了复杂工业设备的能耗分解性能。


<details>
  <summary>详细信息</summary>
研究动机: 工业非侵入式负载监测（NILM）面临高质量数据稀缺和工业能耗模式复杂多变的挑战，同时数据隐私问题也限制了数据的获取。本文旨在通过数字孪生模拟生成开放数据集，并提出高效的数据增强方法，以提升NILM模型的泛化能力。

研究方法: 本文提出了合成工业数据集（SIDED），通过数字孪生模拟生成包含三种工业设施和不同地理位置的开放数据集。同时，提出设备调制数据增强方法（AMDA），通过智能调整设备功率贡献来增强模型的泛化能力。

研究结果: 实验结果显示，使用AMDA增强数据训练的NILM模型在复杂工业设备（如热电联产系统）的能耗分解中表现优异，归一化分解误差为0.093，显著优于未使用数据增强（0.451）和随机数据增强（0.290）的模型。数据分析表明，AMDA有效对齐了训练和测试数据的分布。

研究结论: 本文提出的SIDED数据集和AMDA方法有效解决了工业NILM中的数据稀缺和模型泛化问题，为工业能耗监测提供了可靠的技术支持。

中文摘要: 工业非侵入式负载监测（NILM）受限于高质量数据稀缺和工业能耗模式的复杂多变性。为解决数据稀缺和隐私问题，我们提出了合成工业数据集（SIDED），这是一种通过数字孪生模拟生成的开源数据集。SIDED包含三种工业设施和三个不同地理位置的数据，涵盖了多样化的设备行为、天气条件和负载曲线。我们还提出了设备调制数据增强方法（AMDA），这是一种计算高效的技术，通过智能调整设备功率贡献来提升NILM模型的泛化能力。实验表明，使用AMDA增强数据训练的NILM模型在复杂工业设备（如热电联产系统）的能耗分解中表现显著提升。具体而言，在样本外场景中，使用AMDA训练的模型的归一化分解误差为0.093，优于未使用数据增强（0.451）和随机数据增强（0.290）的模型。数据分布分析证实，AMDA有效对齐了训练和测试数据的分布，增强了模型的泛化能力。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [165] [Physics-Guided Radiotherapy Treatment Planning with Deep Learning](https://arxiv.org/abs/2506.19880)
**中文标题：基于物理引导的深度学习放射治疗计划**

*Stefanos Achlatis,Efstratios Gavves,Jan-Jakob Sonke*

主要分类: physics.med-ph

摘要简述: 本文提出了一种基于物理引导的两阶段深度学习流程，用于放射治疗计划，通过结合MLC和MU值的直接监督以及预测的3D剂量分布，生成与临床真实情况高度匹配的治疗计划。


<details>
  <summary>详细信息</summary>
研究动机: 放射治疗（RT）是癌症治疗的重要手段，而自适应放疗需要频繁调整治疗计划以适应解剖学变化，传统方法耗时且效率低。深度学习为自动化这一过程提供了可能，因此本文旨在开发一种高效、物理引导的深度学习解决方案。

研究方法: 方法分为两阶段：第一阶段通过直接监督训练网络学习治疗计划参数（MLC和MU值）；第二阶段引入预测的3D剂量分布作为额外监督信号，将物理引导整合到训练过程中。实验基于133名前列腺癌患者的2-弧VMAT治疗数据，使用3D U-Net和UNETR架构实现。

研究结果: 结果表明，该方法生成的计划与临床真实情况高度吻合，PTV区域的D95%和V95%差异分别为0.42 +/- 1.83 Gy和-0.22 +/- 1.87%，同时降低了危险器官的辐射剂量。

研究结论: 本文提出的物理引导深度学习方法在放射治疗计划中表现出色，能够高效生成高质量的治疗计划，为临床实践提供了新思路。

中文摘要: 放射治疗（RT）是癌症治疗的重要手段，其中容积调强弧形治疗（VMAT）通过动态调整多叶准直器（MLC）位置和监测单位（MU）以提高剂量适形性。自适应放疗需要频繁调整治疗计划以适应解剖学变化，亟需高效解决方案。深度学习为此提供了可能。为此，我们提出了一种两阶段、物理引导的深度学习流程用于放疗计划。第一阶段，网络通过直接监督学习治疗计划参数（MLC和MU值）；第二阶段，引入预测的3D剂量分布作为额外监督信号，将物理引导整合到训练中。我们在133名采用统一2-弧VMAT协议（PTV剂量62 Gy）治疗的前列腺癌患者数据上训练和评估了该方法。结果显示，基于3D U-Net和UNETR架构的方法生成的计划与临床真实情况高度吻合，PTV区域的D95%和V95%差异分别为0.42 +/- 1.83 Gy和-0.22 +/- 1.87%，同时降低了危险器官的辐射剂量。这些发现凸显了物理引导深度学习在放疗计划中的潜力。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [166] [Valid Selection among Conformal Sets](https://arxiv.org/abs/2506.20173)
**中文标题：共形预测集的有效选择**

*Mahmoud Hegazy,Liviu Aolaritei,Michael I. Jordan,Aymeric Dieuleveut*

主要分类: stat.ML

摘要简述: 本文提出了一种基于稳定性的方法，用于在多个有效的共形预测集中选择最优集，同时确保覆盖率的有效性，并扩展到在线共形预测场景。


<details>
  <summary>详细信息</summary>
研究动机: 共形预测提供了一种分布无关的框架来构建具有覆盖率保证的预测集。然而，在实际应用中，可能存在多个有效的预测集（如不同模型或方法生成），选择最优集（如最小集）可能会破坏覆盖率保证。因此，需要一种方法确保所选集的覆盖率有效性。

研究方法: 作者提出了一种基于稳定性的方法，确保所选预测集的覆盖率有效性。此外，该方法还扩展到在线共形预测场景，并在具有额外结构的场景中提出了多种改进。

研究结果: 实验证明，所提出的方法能够有效确保所选预测集的覆盖率，并在在线共形预测和结构化场景中表现出色。

研究结论: 本文的方法为在多个共形预测集中选择最优集提供了理论保证，同时适用于在线和结构化场景，具有实际应用价值。

中文摘要: 共形预测提供了一种分布无关的框架，用于构建具有覆盖率保证的预测集。在实际应用中，可能存在多个有效的共形预测集（如不同模型或方法生成），但选择最优集（如最小集）可能会破坏覆盖率保证。为解决这一问题，我们提出了一种基于稳定性的方法，确保所选预测集的覆盖率。此外，我们将结果扩展到在线共形预测场景，并在具有额外结构的场景中提出了多种改进，并通过实验验证了其有效性。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [167] [Deciphering GunType Hierarchy through Acoustic Analysis of Gunshot Recordings](https://arxiv.org/abs/2506.20609)
**中文标题：通过枪声录音的声学分析解析枪支类型层级**

*Ankit Shah,Rita Singh,Bhiksha Raj,Alexander Hauptmann*

主要分类: cs.SD

摘要简述: 本文通过声学分析枪声录音，提出了一种低成本的方法来检测枪声并分类枪支类型，使用机器学习框架（包括SVM和CNN），CNN表现优于SVM，但数据质量和环境噪声仍是挑战。


<details>
  <summary>详细信息</summary>
研究动机: 枪支相关暴力和大规模枪击事件的增加对公共安全构成严重威胁。当前商业枪声检测系统成本高昂，研究旨在探索一种低成本替代方案，利用手机等常见设备的录音进行枪声检测和枪支分类。

研究方法: 研究使用3459条枪声录音数据集，分析枪声的声学特征（如枪口爆炸和冲击波），并提出基于SVM和CNN的机器学习框架，用于枪声检测和枪支类型分类。

研究结果: 深度学习方法的平均精度（mAP）为0.58，优于SVM基线（mAP 0.39）。但在噪声数据（如网络来源数据）中表现下降（mAP 0.35）。

研究结论: 研究展示了利用声学分析和机器学习开发低成本枪声检测系统的潜力，但需解决数据质量和噪声问题，以实现高精度实时系统。

中文摘要: 枪支相关暴力和大规模枪击事件的激增对公共安全构成重大威胁。为执法机构提供及时准确的信息对减少此类事件至关重要。当前商业枪声检测系统虽然有效，但成本高昂。本研究探索了一种低成本替代方案，利用手机等常见设备的枪声录音进行声学分析，不仅能检测枪声，还能分类使用的枪支类型。本文详细介绍了使用3459条录音数据集解析枪支类型层级的研究。我们研究了枪声的基本声学特征（如枪口爆炸和冲击波），这些特征因枪支类型、弹药和射击方向而异。我们提出并评估了机器学习框架，包括支持向量机（SVM）作为基线，以及更先进的卷积神经网络（CNN）架构，用于联合枪声检测和枪支类型分类。结果表明，我们的深度学习方法在干净标注数据上的平均精度（mAP）为0.58，优于SVM基线（mAP 0.39）。还讨论了数据质量、环境噪声以及使用噪声网络数据（mAP 0.35）时的泛化能力等挑战。长期目标是开发一种高精度、实时系统，可部署于常见录音设备，显著降低检测成本，并为急救人员提供关键情报。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [168] [Can LLMs Replace Humans During Code Chunking?](https://arxiv.org/abs/2506.19897)
**中文标题：大型语言模型能否替代人类进行代码分块？**

*Christopher Glasz,Emily Escamilla,Eric O. Scott,Anand Patel,Jacob Zimmer,Colin Diggs,Michael Doyle,Scott Rosen,Nitin Naik,Justin F. Brunelle,Samruddhi Thaker,Parthav Poudel,Arun Sridharan,Amit Madan,Doug Wendt,William Macke,Thomas Schill*

主要分类: cs.SE

摘要简述: 本文探讨大型语言模型（LLMs）在政府遗留代码现代化中的应用，特别是针对ALC和MUMPS语言。研究发现，LLMs在代码分块和生成模块注释方面表现优于人类专家，注释的准确性和实用性分别提升20%和10%。


<details>
  <summary>详细信息</summary>
研究动机: 政府企业软件常使用遗留语言（如MUMPS和ALC），而现有LLMs的训练和测试主要针对现代语言，对遗留语言的理解能力未知。此外，这些系统的代码长度超出LLMs的上下文窗口限制，亟需研究如何优化代码分块以支持现代化任务。

研究方法: 研究比较了多种代码分块方法，评估其对LLMs（如GPT-4o、Claude 3 Sonnet、Mixtral和Llama 3）生成遗留代码模块注释质量的影响。重点关注分块方法对文档生成任务的效果。

研究结果: LLMs选择的分块点与人类专家分块高度一致。LLMs生成的分块注释比人类分块的注释在事实性上高出20%，实用性上高出10%。

研究结论: LLMs可作为人类分块的替代方案，在LLM辅助的代码现代化过程中高效处理大型代码库。

中文摘要: 大型语言模型（LLMs）已成为计算机科学中的重要工具，尤其在代码理解和生成任务中。然而，现有研究未解决政府应用代码的独特挑战。政府企业软件常使用遗留语言（如MUMPS或汇编语言代码ALC），且其代码长度超出当前商用LLMs的上下文窗口限制。此外，LLMs主要针对现代语言训练，对遗留语言的测试有限，其理解能力尚不明确。本文研究了LLMs在ALC和MUMPS遗留代码现代化中的应用，探讨了输入限制的挑战。我们比较了多种代码分块方法，以优化遗留代码文件的模块注释生成，并评估分块方法对不同LLMs（如GPT-4o、Claude 3 Sonnet、Mixtral和Llama 3）生成文档质量的影响。结果表明，LLMs选择的分块点与人类专家分块高度一致。分块方法对文档生成等下游任务有显著影响。LLMs生成的分块注释比人类分块的注释在事实性上高出20%，实用性上高出10%。因此，我们得出结论：在LLM辅助的代码现代化过程中，LLMs可替代人类分块大型代码库。

</details>


### [169] [AI and Agile Software Development: From Frustration to Success -- XP2025 Workshop Summary](https://arxiv.org/abs/2506.20159)
**中文标题：AI与敏捷软件开发：从挫折到成功——XP2025研讨会总结**

*Tomas Herda,Victoria Pichler,Zheying Zhang,Pekka Abrahamsson,Geir K. Hanssen*

主要分类: cs.SE

摘要简述: XP2025研讨会的全天工作坊聚焦AI与敏捷开发的结合，探讨了工具、治理、数据质量和技能差距等挑战，并制定了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 研讨会旨在解决将人工智能整合到敏捷软件开发中的实际挑战，促进学术界与工业界的合作。

研究方法: 通过互动环节，参与者识别并系统分析了AI与敏捷开发结合的痛点，并共同制定了研究路线图。

研究结果: 研讨会明确了工具、治理、数据质量和技能差距等核心问题，并提出了短期和长期的研究方向。

研究结论: 研讨会成果为未来AI与敏捷开发的结合提供了结构化议程，推动从问题到成功实施的合作努力。

中文摘要: XP2025关于AI与敏捷的全天工作坊汇集了多样化的研究人员和行业从业者，探讨了将人工智能整合到敏捷软件开发中的实际挑战和机遇。通过互动环节，参与者识别了与AI和敏捷开发结合相关的共同挫折，包括工具、治理、数据质量和关键技能差距等挑战。这些问题被系统性地优先排序和分析，以揭示根本原因。研讨会最终协作制定了一份研究路线图，明确了未来工作的可行方向，包括即时解决方案和雄心勃勃的长期目标。关键成果是一份结构化议程，旨在促进学术界与工业界的共同努力，从已识别的挫折迈向成功实施。

</details>


### [170] [Large Language Model-Driven Code Compliance Checking in Building Information Modeling](https://arxiv.org/abs/2506.20551)
**中文标题：基于大语言模型的建筑信息模型规范合规性检查**

*Soumya Madireddy,Lu Gao,Zia Din,Kinam Kim,Ahmed Senouci,Zhe Han,Yunpeng Zhang*

主要分类: cs.SE

摘要简述: 本研究提出了一种基于大语言模型（LLM）的半自动化方法，用于建筑信息模型（BIM）中的规范合规性检查，显著减少了人工检查的时间和错误。


<details>
  <summary>详细信息</summary>
研究动机: 传统BIM中的规范合规性检查耗时且易出错，亟需一种高效、准确的自动化解决方案。

研究方法: 研究整合了GPT、Claude、Gemini和Llama等大语言模型与Revit软件，通过生成Python脚本实现半自动化的合规性检查。

研究结果: 案例研究表明，该系统显著减少了合规检查的时间和精力，提高了准确性，并能自动识别违规问题。

研究结论: 该方法为BIM规范检查提供了一种全面、灵活且经济高效的解决方案，具有广泛的应用潜力。

中文摘要: 本研究针对建筑信息模型（BIM）中人工规范合规性检查耗时且易出错的问题，提出了一种基于大语言模型（LLM）的半自动化方法。该系统整合了GPT、Claude、Gemini和Llama等LLM与Revit软件，用于解析建筑规范、生成Python脚本并在BIM环境中执行半自动化合规检查。通过对单户住宅项目和办公楼项目的案例研究，证明了该系统能够显著减少合规检查的时间和精力，同时提高准确性。该系统通过自动评估关系和生成可操作报告，简化了违规问题的识别，如不符合规范的房间尺寸、材料使用和物体放置。与人工方法相比，该系统消除了重复性任务，简化了复杂法规，并确保了标准的可靠遵循。通过提供一种全面、灵活且经济高效的解决方案，该方法为基于BIM的合规检查提供了有前景的进展，并有望在建筑项目的多样化规范文件中得到应用。

</details>


### [171] [Define-ML: An Approach to Ideate Machine Learning-Enabled Systems](https://arxiv.org/abs/2506.20621)
**中文标题：Define-ML：一种构思机器学习赋能系统的方法**

*Silvio Alonso,Antonio Pedro Santos Alves,Lucas Romao,Hélio Lopes,Marcos Kalinowski*

主要分类: cs.SE

摘要简述: 本文提出Define-ML框架，扩展Lean Inception方法，通过数据源映射、特征到数据源映射和ML映射活动，系统化整合数据和约束条件，以支持机器学习产品的早期构思。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习在软件系统中的广泛应用，传统构思方法（如Lean Inception）缺乏对数据依赖、技术可行性等ML特有挑战的支持，可能导致产品愿景不清晰或期望不切实际。Define-ML旨在填补这一空白。

研究方法: 基于技术转移模型开发并验证Define-ML，通过静态验证（玩具问题）和动态验证（工业案例研究）结合定量调查与定性反馈，评估其效用、易用性和采用意向。

研究结果: 参与者认为Define-ML能有效澄清数据问题、对齐ML能力与业务目标，并促进跨职能协作。尽管ML特定组件存在学习曲线，但所有参与者均表示有意采用。

研究结论: Define-ML是一个公开可用的验证框架，在Lean Inception的敏捷性基础上，通过结构化活动提升数据与技术可行性的意识，支持ML产品构思。

中文摘要: [背景] 机器学习（ML）在软件系统中的广泛应用需要针对ML特有挑战（如数据依赖、技术可行性、业务目标与概率系统行为的对齐）的专业构思方法。传统方法（如Lean Inception）缺乏对这些ML问题的结构化支持，可能导致产品愿景不清晰或期望不切实际。[目标] 本文提出Define-ML框架，通过扩展Lean Inception并引入数据源映射、特征到数据源映射和ML映射活动，系统化整合数据与技术约束至ML产品的早期构思阶段。[方法] 基于技术转移模型开发并验证Define-ML，通过静态验证（玩具问题）和动态验证（工业案例研究）结合定量调查与定性反馈，评估其效用、易用性和采用意向。[结果] 参与者认为Define-ML能有效澄清数据问题、对齐ML能力与业务目标，并促进跨职能协作。尽管ML特定组件存在学习曲线，但所有参与者均表示有意采用。[结论] Define-ML是一个公开可用的验证框架，在Lean Inception的敏捷性基础上，通过结构化活动提升数据与技术可行性的意识，支持ML产品构思。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [172] [Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability](https://arxiv.org/abs/2506.19870)
**中文标题：利用区块链和人工智能进行安全能源交易：欺诈检测与能源市场稳定性**

*Md Asif Ul Hoq Khan,MD Zahedul Islam,Istiaq Ahmed,Md Masud Karim Rabbi,Farhana Rahman Anonna,MD Abdul Fahim Zeeshan,Mehedi Hasan Ridoy,Bivash Ranjan Chowdhury,Md Nazmul Shakir Rabbi,GM Alamin Sadnan*

主要分类: cs.CR

摘要简述: 本研究结合区块链和人工智能技术，提出了一种安全、智能且高效的能源交易系统，旨在解决去中心化能源市场中的安全和欺诈问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着点对点交易和去中心化电网的发展，美国能源市场面临新的安全和真实性挑战。本研究旨在通过区块链和人工智能的结合，解决分布式能源市场中的安全、欺诈检测和市场可靠性问题。

研究方法: 研究提出了一种双层系统架构，包括区块链层和人工智能层。区块链层用于确保交易安全，人工智能层则用于检测欺诈行为。研究使用了包含120万条匿名能源交易记录的数据集，并选择了高性能的机器学习模型进行分类任务。

研究结果: 系统成功整合了区块链和人工智能技术，有效提升了能源交易的安全性和市场稳定性，并能够准确识别欺诈行为。

研究结论: 研究表明，区块链与人工智能的结合能够显著提升去中心化能源市场的安全性和效率，为未来的能源交易系统提供了可行的解决方案。

中文摘要: 点对点交易和向去中心化电网的转变重塑了美国的能源市场。然而，这些发展也带来了新的挑战，尤其是能源交易的安全性和真实性问题。本研究旨在为美国去中心化能源市场开发一种安全、智能且高效的能源交易系统。研究创新性地结合了区块链和人工智能技术，以解决分布式能源市场中长期存在的安全、欺诈检测和市场可靠性问题。研究数据集包含超过120万条来自模拟点对点能源交易网络的匿名交易记录，模拟了基于区块链的美国微电网（如LO3 Energy和Grid+ Labs测试的网络）。每条记录包含交易标识符、时间戳、能源量（kWh）、交易类型（买/卖）、单价、产消者/消费者标识符（哈希处理以保护隐私）、智能电表读数、地理区域和结算确认状态等详细字段。数据集还包括系统计算的行为指标，如交易频率、能源生产波动性和历史定价模式。提出的系统架构包含区块链层和人工智能层，两者在确保能源交易安全和提升市场智能方面发挥独特且互补的作用。研究中选用的机器学习模型因其在分类任务（尤其是识别去中心化市场中的能源交易欺诈）中的高性能而特别适合。

</details>


### [173] [An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network](https://arxiv.org/abs/2506.19871)
**中文标题：基于生成对抗网络的医疗保险欺诈检测攻击方法**

*Yining Pang,Chenghan Li*

主要分类: cs.CR

摘要简述: 本文提出了一种基于生成对抗网络（GAN）的攻击方法，用于测试医疗保险欺诈检测系统的脆弱性。实验表明，攻击者无需了解训练数据或模型细节，即可生成被误判为合法的欺诈案例，攻击成功率达99%。


<details>
  <summary>详细信息</summary>
研究动机: 当前医疗保险欺诈检测系统虽依赖AI和机器学习算法，但缺乏标准化防御机制，容易受到对抗性攻击。本文旨在揭示这些系统的脆弱性，并呼吁增强其鲁棒性。

研究方法: 采用生成对抗网络（GAN）生成对抗性样本，通过微调真实保险记录和索赔数据，使其被欺诈检测系统误判为合法。

研究结果: 攻击成功率达99%，表明现有欺诈检测系统极易受到对抗性攻击，可能被绕过。

研究结论: 研究结果强调了提升保险欺诈检测模型对抗性操纵能力的紧迫性，以确保保险系统的稳定性和可靠性。

中文摘要: 保险欺诈检测是现代保险服务中的关键进步，通过智能化和数字化监控提升管理并预防欺诈行为，对保障保险系统的安全与效率至关重要。尽管AI和机器学习算法在检测欺诈索赔方面表现出色，但缺乏标准化防御机制使现有系统易受新兴对抗性威胁的影响。本文提出了一种基于GAN的方法，对欺诈检测系统进行对抗性攻击。结果表明，攻击者在无需了解训练数据或模型内部细节的情况下，可以生成被分类为合法的欺诈案例，攻击成功率达99%。通过对真实保险记录和索赔的细微修改，攻击者能显著增加欺诈风险，可能绕过受损的检测系统。这些发现凸显了增强保险欺诈检测模型对抗性操纵能力的迫切需求，以确保不同保险系统的稳定性和可靠性。

</details>


### [174] [Towards Provable (In)Secure Model Weight Release Schemes](https://arxiv.org/abs/2506.19874)
**中文标题：迈向可证明（不）安全的模型权重发布方案**

*Xing Yang,Bingtao Wang,Yuhao Wang,Zimo Ji,Terry Jingchen Zhang,Wenyuan Jiang*

主要分类: cs.CR

摘要简述: 本文通过引入严格的安全定义，分析了现有模型权重发布方案的安全性，并以TaylorMLP为例揭示了其漏洞，呼吁在机器学习和安全领域进行更严谨的研究。


<details>
  <summary>详细信息</summary>
研究动机: 当前的安全权重发布方案缺乏严格的安全理论基础，仅提供非正式的安全保证。本文旨在填补这一空白，通过形式化安全定义，评估现有方案的实际安全性。

研究方法: 本文首先提出了一系列具体的模型权重发布方案的安全定义，随后以TaylorMLP为案例，通过分析其漏洞验证了这些定义的实用性。

研究结果: 研究发现TaylorMLP存在参数提取漏洞，未能实现其非正式的安全目标，证明了现有方案的安全缺陷。

研究结论: 本文强调了在机器学习和安全交叉领域进行严谨研究的重要性，并为未来权重发布方案的设计和评估提供了蓝图。

中文摘要: 近期的安全权重发布方案声称能够在开源模型分发的同时保护模型所有权并防止滥用。然而，这些方法缺乏严格的安全基础，仅提供非正式的安全保证。受密码学经典工作的启发，我们通过引入若干具体的安全定义，形式化了权重发布方案的安全性。随后，我们以TaylorMLP这一著名安全权重发布方案为例，展示了这些定义的实用性。我们的分析揭示了允许参数提取的漏洞，表明TaylorMLP未能实现其非正式的安全目标。我们希望这项工作能够推动机器学习和安全交叉领域的严谨研究，并为未来权重发布方案的设计和评估提供蓝图。

</details>


### [175] [Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017](https://arxiv.org/abs/2506.19877)
**中文标题：网络流量中的稳健异常检测：基于CICIDS2017数据集的机器学习模型评估**

*Zhaoyang Xu,Yunbo Liu*

主要分类: cs.CR

摘要简述: 本研究比较了四种机器学习模型在CICIDS2017数据集上的异常检测表现，发现监督模型在已知攻击上表现优异，但在未知攻击上表现不佳；无监督模型在未知攻击上表现稳健，但存在误报问题。


<details>
  <summary>详细信息</summary>
研究动机: 为构建高效且泛化的入侵检测系统，研究不同机器学习模型在已知和未知网络攻击场景下的表现差异。

研究方法: 在CICIDS2017数据集上，对比了多层感知机（MLP）、一维卷积神经网络（CNN）、一类支持向量机（OCSVM）和局部离群因子（LOF）四种模型在已知攻击和未知攻击检测中的表现。

研究结果: 监督模型MLP和CNN在已知攻击上准确率接近完美，但对未知攻击召回率显著下降；无监督模型LOF在未知攻击上召回率高但误报率高；OCSVM在精确率和召回率之间取得最佳平衡。

研究结论: OCSVM在动态网络环境中表现出稳健的检测能力，为入侵检测系统的模型选择提供了实用指导。

中文摘要: 为构建高效且泛化的入侵检测解决方案，选择合适的机器学习范式至关重要。本研究在CICIDS2017数据集上，对四种代表性模型——多层感知机（MLP）、一维卷积神经网络（CNN）、一类支持向量机（OCSVM）和局部离群因子（LOF）——进行了对照比较，评估其在已知攻击类型检测和未知威胁泛化能力上的表现。结果显示，监督模型MLP和CNN在已知攻击上准确率接近完美，但对未知攻击召回率显著下降；无监督模型LOF在未知攻击上召回率高但误报率高；而边界型OCSVM在精确率和召回率之间取得最佳平衡，展现出跨场景的稳健检测能力。这些发现为动态网络环境中的入侵检测系统模型选择提供了实用指导。

</details>


### [176] [Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models](https://arxiv.org/abs/2506.19889)
**中文标题：检索混淆生成是大型语言模型隐私侵犯攻击的有效防御手段**

*Wanli Peng,Xin Chen,Hang Fu,XinYu He,Xue Yiming,Juan Wen*

主要分类: cs.CR

摘要简述: 本文提出了一种基于检索混淆生成（RCG）的新防御范式，用于高效且隐蔽地抵御大型语言模型（LLM）的隐私侵犯攻击（PVA）。通过改写攻击查询的“用户评论”并构建干扰数据库，结合最不相关检索策略，最终生成防御性查询，使攻击者获取错误的个人属性。


<details>
  <summary>详细信息</summary>
研究动机: 由于大型语言模型（LLM）的推理能力强大，隐私侵犯攻击（PVA）引发了严重的隐私问题。现有防御方法成本高且效果不佳，而直接拒绝查询会暴露防御策略。因此，需要一种高效且隐蔽的防御方法。

研究方法: 1. 设计改写提示，诱导LLM重写攻击查询的“用户评论”，构建干扰数据库；2. 提出最不相关检索策略，从干扰数据库中检索目标用户数据；3. 将“数据评论”替换为检索到的用户数据，生成防御性查询，使攻击者获取错误信息。

研究结果: 在两个数据集和八种流行的LLM上进行了广泛实验，验证了所提防御方法的可行性和优越性。

研究结论: 基于检索混淆生成的防御范式能够高效且隐蔽地抵御隐私侵犯攻击，为LLM的隐私保护提供了新思路。

中文摘要: 近年来，大型语言模型（LLM）的快速发展对社会产生了深远影响，同时也引发了新的安全问题。特别是由于LLM强大的推理能力，Staab等人揭示的隐私侵犯攻击（PVA）带来了严重的个人隐私问题。现有的防御方法主要依赖LLM对输入查询进行匿名化处理，不仅需要高昂的推理时间，且防御效果不佳。此外，直接拒绝PVA查询看似有效，但会暴露防御方法，促使PVA进一步演化。本文提出了一种基于LLM检索混淆生成（RCG）的新型防御范式，能够高效且隐蔽地抵御PVA。我们首先设计了一种改写提示，诱导LLM重写攻击查询的“用户评论”，构建干扰数据库；随后提出最不相关检索策略，从干扰数据库中检索目标用户数据；最后将“数据评论”替换为检索到的用户数据，生成防御性查询，使攻击者获取错误的个人属性，即攻击失败。在两个数据集和八种流行的LLM上进行了广泛实验，全面评估了所提防御方法的可行性和优越性。

</details>


### [177] [RepuNet: A Reputation System for Mitigating Malicious Clients in DFL](https://arxiv.org/abs/2506.19892)
**中文标题：RepuNet：一种用于缓解DFL中恶意客户端的声誉系统**

*Isaac Marroqui Penalva,Enrique Tomás Martínez Beltrán,Manuel Gil Pérez,Alberto Huertas Celdrán*

主要分类: cs.CR

摘要简述: 本文提出RepuNet，一种去中心化的声誉系统，用于在去中心化联邦学习（DFL）中动态评估节点行为并调整其影响力，以抵御恶意攻击。实验表明，RepuNet在MNIST和CIFAR-10数据集上表现优异，F1分数分别超过95%和约76%。


<details>
  <summary>详细信息</summary>
研究动机: 去中心化联邦学习（DFL）中，节点自主选择聚合伙伴，易受恶意节点攻击（如模型投毒、延迟攻击或消息洪泛）。现有解决方案依赖固定配置或额外基础设施（如区块链），存在计算开销、可扩展性或适应性不足的问题。

研究方法: 提出RepuNet，通过模型相似性、参数变化、消息延迟和通信量等指标动态评估节点行为，并基于声誉分数调整其在模型聚合中的影响力。实验在Nebula DFL平台上进行，使用MNIST和CIFAR-10数据集，测试了不同攻击强度和拓扑结构。

研究结果: RepuNet能有效检测和缓解恶意行为，在MNIST场景中F1分数超过95%，CIFAR-10场景中约为76%。结果表明其适应性强、鲁棒性高，适用于去中心化联邦学习环境。

研究结论: RepuNet是一种高效的去中心化声誉系统，能够动态评估节点行为并抵御恶意攻击，为DFL环境提供了实用且可靠的解决方案。

中文摘要: 去中心化联邦学习（DFL）允许节点在没有中央服务器的情况下协作训练模型，但由于每个节点独立选择聚合伙伴，引入了新的漏洞。恶意节点可能利用这种自主性发送损坏的模型（模型投毒）、延迟提交模型（延迟攻击）或通过过量消息淹没网络，从而影响系统性能。现有解决方案通常依赖固定配置或额外基础设施（如区块链），导致计算开销、可扩展性问题或适应性不足。为克服这些限制，本文提出RepuNet，一种去中心化声誉系统，通过模型相似性、参数变化、消息延迟和通信量等指标动态评估节点行为，并基于声誉分数调整其在模型聚合中的影响力。RepuNet被集成到Nebula DFL平台中，并在MNIST和CIFAR-10数据集上进行了实验评估，测试了不同攻击强度、频率和激活间隔。结果表明，RepuNet能有效检测和缓解恶意行为，在MNIST场景中F1分数超过95%，CIFAR-10场景中约为76%。这些结果凸显了RepuNet在去中心化联邦学习环境中的适应性、鲁棒性和实用潜力。

</details>


### [178] [SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models](https://arxiv.org/abs/2506.20415)
**中文标题：SV-LLM：基于大型语言模型的SoC安全验证代理方法**

*Dipayan Saha,Shams Tarek,Hasan Al Shaikh,Khan Thamid Hasan,Pavan Sai Nalluri,Md. Ajoad Hasan,Nashmin Alam,Jingbo Zhou,Sujan Kumar Saha,Mark Tehranipoor,Farimah Farahmandi*

主要分类: cs.CR

摘要简述: SV-LLM是一种基于大型语言模型的多代理系统，旨在自动化并提升SoC安全验证的效率，通过多代理协作减少人工干预并提高准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统SoC安全验证方法在自动化、扩展性和适应性方面存在不足，而大型语言模型（LLMs）的先进能力为解决这些问题提供了新思路。

研究方法: SV-LLM采用多代理系统，每个代理专注于特定任务（如验证问答、威胁建模等），并结合上下文学习、微调和检索增强生成（RAG）优化性能。

研究结果: 实验和案例研究表明，SV-LLM能够显著减少人工干预，提高安全分析的准确性和效率，并支持设计周期早期的风险识别与缓解。

研究结论: SV-LLM展示了利用多代理LLM系统提升硬件安全实践的潜力，为SoC安全验证提供了高效且可扩展的解决方案。

中文摘要: 确保复杂系统级芯片（SoC）设计的安全性至关重要，但传统验证技术因自动化、扩展性、全面性和适应性方面的挑战而难以应对。大型语言模型（LLMs）凭借其在自然语言理解、代码生成和高级推理方面的卓越能力，为解决这些问题提供了新范式。超越单一模型，代理方法允许创建多代理系统，其中专门的LLM协作更有效地解决复杂问题。基于此，我们提出了SV-LLM，一种新型多代理辅助系统，旨在自动化并增强SoC安全验证。通过整合专注于验证问答、安全资产识别、威胁建模、测试计划与属性生成、漏洞检测及基于模拟的缺陷验证等任务的代理，SV-LLM优化了工作流程。为在这些多样化任务中提升性能，代理采用了上下文学习、微调和检索增强生成（RAG）等学习范式。该系统旨在减少人工干预、提高准确性并加速安全分析，支持在设计周期早期主动识别和缓解风险。通过案例研究和实验，我们展示了其在硬件安全实践中的潜在变革能力，验证了其适用性和有效性。

</details>


### [179] [Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS](https://arxiv.org/abs/2506.20576)
**中文标题：基于自适应黑盒对抗攻击的网络入侵检测系统漏洞披露**

*Sabrine Ennaji,Elhadj Benkhelifa,Luigi V. Mancini*

主要分类: cs.CR

摘要简述: 本文提出了一种新型的黑盒对抗攻击方法，通过自适应特征选择和因果分析，以最小交互实现高效攻击，适用于网络流量数据，提升了实际场景中的适应性。


<details>
  <summary>详细信息</summary>
研究动机: 现有对抗攻击方法在理论进展与实际应用间存在差距，尤其是在网络流量等结构化数据中，特征间的相互依赖使得攻击难以有效实施。此外，现有方法的模糊性限制了可重复性和防御能力的发展。

研究方法: 提出了一种严格遵循黑盒约束的自适应攻击方法，利用变点检测和因果分析选择敏感特征进行扰动，设计轻量级，计算成本低且易于部署。

研究结果: 实验表明，该方法能以最小交互有效规避检测，具有较高的适应性和实际应用价值。

研究结论: 本研究为网络流量中的对抗攻击提供了新思路，为开发更鲁棒的防御系统奠定了基础。

中文摘要: 对抗攻击通过精心设计的微小输入误导智能模型，日益受到关注。然而，理论进展与实际应用间仍存在显著差距，尤其是在网络流量等结构化数据中，特征间的相互依赖使得对抗操作复杂化。此外，现有方法的模糊性限制了可重复性和该领域的进展，导致现有防御难以应对不断演变的攻击。本文提出了一种新型黑盒对抗攻击方法，解决了这些限制。与以往研究不同，我们的方法严格遵循黑盒约束，减少交互以避免检测，更贴近实际场景。通过变点检测和因果分析，提出了一种自适应特征选择策略，以识别并扰动敏感特征。轻量级设计确保了低计算成本和高可部署性。全面实验表明，该方法能以最小交互有效规避检测，提升了实际场景中的适应性和适用性。通过深化对网络流量中对抗攻击的理解，本研究为开发鲁棒防御奠定了基础。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [180] [Capturing Visualization Design Rationale](https://arxiv.org/abs/2506.16571)
**中文标题：捕捉可视化设计逻辑**

*Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha*

主要分类: cs.HC

摘要简述: 本文提出了一种新的数据集和方法，通过自然语言探究可视化设计的逻辑，利用学生创建的可视化笔记本作为真实数据源，结合大型语言模型生成问题-答案-逻辑三元组，最终验证并整理出捕捉设计选择和逻辑的数据集。


<details>
  <summary>详细信息</summary>
研究动机: 现有自然语言数据集多关注可视化解读而非设计逻辑，且多基于人为构建的问题和可视化。本文旨在填补这一空白，通过真实的学生可视化笔记本探究设计决策背后的逻辑。

研究方法: 利用学生数据可视化课程中的可视化笔记本作为真实数据源，结合大型语言模型生成问题-答案-逻辑三元组，并通过验证和整理构建数据集。

研究结果: 成功构建了一个捕捉可视化设计选择和逻辑的数据集，为研究设计决策提供了新工具。

研究结论: 本文提出的数据集和方法为可视化设计逻辑的研究提供了新视角和工具，填补了现有研究的空白。

中文摘要: 以往的自然语言数据集多用于可视化素养评估、洞察生成或从自然语言指令生成可视化，这些研究通常依赖人为构建的问题和可视化，侧重于解读而非设计逻辑。本文提出了一种新的数据集和方法，通过自然语言探究可视化设计逻辑。我们利用学生数据可视化课程中的可视化笔记本作为真实数据源，这些笔记本结合了可视化作品和设计说明，学生明确阐述了其设计决策背后的逻辑。我们还使用大型语言模型（LLM）从笔记本中的叙述和表达生成并分类问题-答案-逻辑三元组，经过验证后整理出一个捕捉学生可视化设计选择和逻辑的数据集。

</details>


### [181] [Beyond Autocomplete: Designing CopilotLens Towards Transparent and Explainable AI Coding Agents](https://arxiv.org/abs/2506.20062)
**中文标题：超越自动完成：设计CopilotLens以实现透明和可解释的AI编码助手**

*Runlong Ye,Zeling Zhang,Boushra Almazroua,Michael Liut*

主要分类: cs.HC

摘要简述: 本文介绍了CopilotLens，一种新型交互框架，旨在通过透明和可解释的方式提升AI代码助手的使用体验，帮助开发者理解AI的决策过程。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI代码助手虽然能显著提升开发效率，但其建议缺乏解释性，开发者难以理解AI的决策逻辑，影响了信任和协作。CopilotLens旨在解决这一问题。

研究方法: CopilotLens作为一个解释层，通过动态双层界面展示AI的“思考过程”，包括高层次计划和代码库上下文，从而提供透明化的代码建议。

研究结果: CopilotLens成功设计了一个框架，使AI代码助手的决策过程变得透明和可解释，提升了开发者的理解和信任。

研究结论: CopilotLens为未来注重推理透明性的AI代码助手提供了具体框架，促进了更深层次的人机协作。

中文摘要: AI驱动的代码助手被广泛用于生成代码补全，显著提升了开发者的生产力。然而，这些工具通常在不解释其逻辑的情况下提供建议，使得其决策过程难以理解。这种不透明性阻碍了开发者对输出的批判性评估、形成准确的心理模型以及对系统建立校准的信任。为解决这一问题，我们引入了CopilotLens，一种新颖的交互框架，将代码补全从简单的建议转变为透明、可解释的事件。CopilotLens作为一个解释层，通过动态双层界面展示AI代理的“思考过程”，从重构的高层次计划到影响代码的具体代码库上下文。本文介绍了CopilotLens的设计和原理，为未来注重推理清晰性而非建议速度的代理代码助手提供了具体框架，从而促进更深层次的理解和更稳健的人机协作。

</details>


### [182] [Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype](https://arxiv.org/abs/2506.20156)
**中文标题：Irec：一种通过及时见解回忆促进自我调节学习的元认知支架：概念框架与系统原型**

*Xuefei Hou,Xizhao Tan*

主要分类: cs.HC

摘要简述: 本文提出了一种名为“Insight Recall”的新范式，通过上下文触发的个人过去见解检索，作为促进自我调节学习（SRL）的元认知支架。作者基于Just-in-Time Adaptive Intervention（JITAI）框架，开发了原型系统Irec，结合动态知识图谱和大型语言模型（LLM），实现了及时的相关见解检索和呈现。


<details>
  <summary>详细信息</summary>
研究动机: 当前数字工具在支持元认知反思方面存在不足，例如间隔重复系统（SRS）缺乏上下文，而个人知识管理（PKM）工具需要高人工维护。本文旨在解决这些问题，通过提出一种新范式，提升学习者的自我调节能力。

研究方法: 作者提出了“Insight Recall”范式，并基于JITAI框架开发了Irec系统。系统利用动态知识图谱记录用户学习历史，通过混合检索引擎和LLM进行深度相似性评估，及时呈现相关见解。此外，系统还设计了基于LLM的知识图谱构建流程和可选的“引导探究”模块，支持用户与专家LLM的对话。

研究结果: Irec系统通过动态知识图谱和LLM技术，实现了上下文相关的见解检索和呈现，有效降低了认知负荷，并为元认知反思提供了支持。

研究结论: 本文提供了一个坚实的理论框架和可用的系统平台，为下一代智能学习系统的设计提供了新思路，能够增强学习者的元认知和自我调节能力。

中文摘要: 学习的核心挑战已从知识获取转向有效的自我调节学习（SRL）：规划、监控和反思学习过程。然而，现有数字工具对元认知反思的支持不足。间隔重复系统（SRS）使用脱离上下文的复习方式，忽视了上下文的作用，而个人知识管理（PKM）工具则需要高人工维护。为解决这些问题，本文提出了“见解回忆”这一新范式，将上下文触发的个人过去见解检索概念化为促进SRL的元认知支架。我们基于Just-in-Time Adaptive Intervention（JITAI）框架形式化了这一范式，并开发了原型系统Irec以验证其可行性。Irec的核心是用户学习历史的动态知识图谱。当用户面对新问题时，混合检索引擎会召回相关的个人“见解”。随后，大型语言模型（LLM）进行深度相似性评估，筛选并即时呈现最相关的支架。为降低认知负荷，Irec设计了基于LLM的知识图谱构建流程。我们还提出了可选的“引导探究”模块，用户可以与专家LLM进行苏格拉底式对话，以当前问题和召回见解为背景。本文的贡献在于提供了一个坚实的理论框架和可用的系统平台，用于设计增强元认知和自我调节能力的下一代智能学习系统。

</details>


### [183] [AI in the Writing Process: How Purposeful AI Support Fosters Student Writing](https://arxiv.org/abs/2506.20595)
**中文标题：AI在写作过程中的作用：有目的的AI支持如何促进学生写作**

*Momin N. Siddiqui,Roy Pea,Hari Subramonyam*

主要分类: cs.HC

摘要简述: 本文探讨了AI写作支持工具对学生写作过程的影响，发现集成式AI工具能提升学生的写作自主性和知识转化深度，而单纯的聊天式LLM效果较差。


<details>
  <summary>详细信息</summary>
研究动机: 随着ChatGPT等技术的普及，人们担心其对学生的写作自主性和内容深度产生负面影响。本文旨在研究不同AI支持方式如何影响学生的写作自主性和知识转化深度。

研究方法: 通过一项随机对照试验，90名本科生被分为三组：使用聊天式LLM写作助手、集成式AI写作工具和标准写作界面（对照组），以比较不同支持方式的效果。

研究结果: 研究发现，使用集成式AI写作工具的学生在写作自主性和知识转化深度上表现最佳，而聊天式LLM的效果较差。

研究结论: 研究表明，针对写作过程特定环节设计的AI支持工具能帮助学生保持对写作的自主权，同时提升内容深度。

中文摘要: ChatGPT等技术的普及引发了对其影响学生写作的担忧，尤其是对学习者自主性和内容深度的影响。虽然独立的聊天式LLM通常导致写作效果不佳，但有证据表明，精心设计的AI写作支持工具可以改善写作过程。本文研究了不同AI支持方式如何影响作者的自主性和知识转化深度。通过对90名本科生进行的随机对照试验，我们比较了三种条件：（1）聊天式LLM写作助手，（2）支持多样化子过程的集成式AI写作工具，（3）标准写作界面（对照组）。研究发现，在AI支持条件下，使用集成式AI写作工具的学生表现出更强的写作自主性和更深入的知识转化。这些结果表明，针对写作过程特定环节设计的AI支持工具可以帮助学生保持对作品的所有权，同时促进对内容的更深入参与。

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [184] [An ab initio foundation model of wavefunctions that accurately describes chemical bond breaking](https://arxiv.org/abs/2506.19960)
**中文标题：一种基于从头计算的波函数基础模型，可准确描述化学键断裂**

*Adam Foster,Zeno Schätzle,P. Bernát Szabó,Lixue Cheng,Jonas Köhler,Gino Cassella,Nicholas Gao,Jiawei Li,Frank Noé,Jan Hermann*

主要分类: physics.chem-ph

摘要简述: 本文提出了一种名为Orbformer的新型可迁移波函数模型，通过预训练在22,000个平衡和解离结构上，能够高效准确地描述化学键断裂问题，其精度与成本比媲美传统多参考方法。


<details>
  <summary>详细信息</summary>
研究动机: 化学键断裂的可靠描述是量子化学中的主要挑战，传统多参考方法计算成本高昂且无法利用分子间电子结构的共性。本文旨在通过预训练可迁移波函数模型，解决这一问题。

研究方法: 提出Orbformer，一种基于深度神经网络和量子蒙特卡洛（deep QMC）的新型波函数模型，预训练于22,000个平衡和解离结构，并可针对未见分子进行微调。

研究结果: Orbformer在标准测试和更具挑战性的键解离及Diels-Alder反应中，唯一能够一致收敛至化学精度（1 kcal/mol）。

研究结论: Orbformer实现了将求解薛定谔方程的成本分摊到多个分子的新范式，为量子化学提供了一种实用方法。

中文摘要: 化学键断裂的可靠描述仍然是量子化学的主要挑战，这是由于解离物种电子结构的多参考特性。多参考方法尤其面临高昂的计算成本，而传统范式下，这种成本需要为每个系统单独支付，忽略了分子间电子结构的共性。基于深度神经网络的量子蒙特卡洛（deep QMC）通过预训练可迁移波函数模型，独特地利用了这种共性，但此前所有尝试均受限于范围。本文通过Orbformer实现了这一新范式，这是一种新型可迁移波函数模型，预训练于22,000个平衡和解离结构，可针对未见分子进行微调，其精度与成本比媲美经典多参考方法。在标准测试以及更具挑战性的键解离和Diels-Alder反应中，Orbformer是唯一能够一致收敛至化学精度（1 kcal/mol）的方法。这项工作将分摊求解薛定谔方程成本的理念转化为量子化学中的实用方法。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [185] [DualEquiNet: A Dual-Space Hierarchical Equivariant Network for Large Biomolecules](https://arxiv.org/abs/2506.19862)
**中文标题：DualEquiNet：一种用于大型生物分子的双空间层次等变网络**

*Junjie Xu,Jiahao Zhang,Mangal Prakash,Xiang Zhang,Suhang Wang*

主要分类: q-bio.BM

摘要简述: DualEquiNet是一种双空间层次等变网络，通过结合欧几里得空间和球谐空间的互补表示，解决了大型生物分子建模中的多尺度结构问题，并在RNA和蛋白质建模任务中取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的几何图神经网络（GNNs）在小型分子建模中表现优异，但在处理大型生物分子（如RNA和蛋白质）时面临可扩展性和表达能力不足的问题。这些系统需要同时捕捉细粒度原子相互作用、长程依赖关系和生物相关的层次结构。

研究方法: DualEquiNet通过在欧几里得空间和球谐空间中构建互补表示，结合双向跨空间消息传递和新型跨空间交互池化机制，实现了对局部几何和全局对称性特征的捕捉，并将原子特征层次聚合为生物意义单元（如残基）。

研究结果: DualEquiNet在RNA性质预测和蛋白质建模的多个现有基准测试中达到了最优性能，并在新引入的3D结构基准测试中优于先前方法，展示了其在大型生物分子建模任务中的广泛有效性。

研究结论: DualEquiNet通过双空间层次等变网络的设计，成功解决了大型生物分子建模中的多尺度问题，为生物分子结构的建模提供了高效且表达力强的解决方案。

中文摘要: 几何图神经网络（GNNs）在小型分子建模中表现出色，但在应用于RNA和蛋白质等大型生物分子时，面临可扩展性和表达能力的挑战。这些系统需要模型能够同时捕捉细粒度的原子相互作用、空间远距离组件的长程依赖关系以及生物相关的层次结构（如原子形成残基，残基再形成更高阶域）。现有的几何GNN通常仅在欧几里得空间或球谐空间中操作，难以同时捕捉细尺度原子细节和长程对称性依赖关系。我们提出了DualEquiNet，一种双空间层次等变网络，通过在欧几里得和球谐空间中构建互补表示，捕捉局部几何和全局对称性特征。DualEquiNet采用双向跨空间消息传递和新型跨空间交互池化机制，将原子特征层次聚合为生物意义单元（如残基），实现了对大型生物分子系统的高效多尺度建模。DualEquiNet在RNA性质预测和蛋白质建模的多个现有基准测试中达到了最优性能，并在新引入的3D结构基准测试中优于先前方法，展示了其在大型生物分子建模任务中的广泛有效性。

</details>


### [186] [Scalable and Cost-Efficient de Novo Template-Based Molecular Generation](https://arxiv.org/abs/2506.19865)
**中文标题：可扩展且经济高效的基于模板的分子生成**

*Piotr Gaiński,Oussama Boussif,Andrei Rekesh,Dmytro Shevchuk,Ali Parviz,Mike Tyers,Robert A. Batey,Michał Koziarski*

主要分类: q-bio.BM

摘要简述: 本文提出了一种基于模板的分子生成方法，通过递归成本指导和动态库机制，解决了合成成本高、大规模构建块库扩展和小片段集利用的挑战，显著提升了分子生成的效率、多样性和质量。


<details>
  <summary>详细信息</summary>
研究动机: 基于模板的分子生成在药物设计中具有潜力，但仍面临合成成本高、构建块库规模大和小片段集利用不足的挑战。本文旨在解决这些问题，提升分子生成的效率和实用性。

研究方法: 提出了递归成本指导框架，利用辅助机器学习模型估算合成成本和可行性，并通过动态库机制重用高奖励中间状态，优化分子生成过程。

研究结果: 该方法在基于模板的分子生成中取得了最先进的成果，显著降低了合成成本，提高了分子多样性和质量。

研究结论: 本文提出的递归成本指导和动态库机制为基于模板的分子生成提供了高效、可扩展的解决方案，为药物设计领域带来了重要进展。

中文摘要: 基于模板的分子生成为药物设计提供了一条有前景的途径，通过预定义的反应模板和构建块确保生成的化合物具有合成可行性。本研究解决了基于模板的GFlowNets中的三个核心挑战：(1)最小化合成成本，(2)扩展到大规模构建块库，(3)有效利用小片段集。我们提出了递归成本指导，这是一种反向策略框架，利用辅助机器学习模型来估算合成成本和可行性。这种指导将生成过程导向低成本合成路径，显著提升了成本效率、分子多样性和质量，尤其是与平衡探索与利用的利用惩罚相结合时。为了在小规模构建块库中提升性能，我们开发了动态库机制，通过重用高奖励中间状态构建完整的合成树。我们的方法在基于模板的分子生成中取得了最先进的结果。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [187] [X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis](https://arxiv.org/abs/2506.20267)
**中文标题：X-SiT：用于痴呆症诊断的固有可解释表面视觉变换器**

*Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger*

主要分类: cs.GR

摘要简述: 本文提出了一种可解释的表面视觉变换器（X-SiT），用于痴呆症诊断，首次实现了基于可解释皮层特征的人类可理解预测，并在阿尔茨海默病和额颞叶痴呆检测中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 可解释模型对临床决策至关重要，但3D体积数据的复杂性使其难以可视化。皮层表面渲染提供了更易理解的脑解剖表示，因此作者开发了X-SiT，以支持基于可解释特征的诊断。

研究方法: X-SiT是一种可解释的神经网络，结合了原型表面补丁解码器，通过空间对应的皮层原型进行分类，实现了基于案例的推理。

研究结果: X-SiT在阿尔茨海默病和额颞叶痴呆检测中达到先进水平，并提供与已知疾病模式一致的原型，揭示了分类错误。

研究结论: X-SiT不仅提升了痴呆症诊断的性能，还通过可解释的原型增强了临床决策的透明度和可靠性。

中文摘要: 可解释模型对支持临床决策至关重要，推动了其在医学图像中的发展和应用。然而，3D体积数据的特性使其难以可视化和解释复杂结构（如大脑皮层）。相比之下，皮层表面渲染提供了更易理解和交互探索的脑解剖3D表示。基于这一优势及表面数据在神经系统疾病研究中的广泛应用，我们提出了可解释表面视觉变换器（X-SiT）。这是首个基于可解释皮层特征提供人类可理解预测的固有可解释神经网络。作为X-SiT的一部分，我们引入了一种原型表面补丁解码器，用于分类表面补丁嵌入，结合了基于案例的推理和空间对应的皮层原型。结果表明，X-SiT在阿尔茨海默病和额颞叶痴呆检测中表现出色，同时提供了与已知疾病模式一致且揭示分类错误的信息原型。

</details>


### [188] [DreamAnywhere: Object-Centric Panoramic 3D Scene Generation](https://arxiv.org/abs/2506.20367)
**中文标题：DreamAnywhere：以对象为中心的360度全景3D场景生成**

*Edoardo Alberto Dominici,Jozef Hladky,Floor Verhoeven,Lukas Radl,Thomas Deixelberger,Stefan Ainetter,Philipp Drescher,Stefan Hauswiesner,Arno Coomans,Giacomo Nazzaro,Konstantinos Vardis,Markus Steinberger*

主要分类: cs.GR

摘要简述: DreamAnywhere是一种模块化系统，用于快速生成和原型化3D场景，通过文本生成360度全景图像，分解为背景和对象，并构建完整的3D表示，支持沉浸式导航和对象级编辑。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到3D场景生成方法通常仅生成正面视角、缺乏视觉保真度、场景理解有限，且仅适用于室内或室外场景。DreamAnywhere旨在解决这些问题，提供更灵活、高质量的3D场景生成方案。

研究方法: DreamAnywhere通过文本生成360度全景图像，将其分解为背景和对象，利用混合修复技术构建完整3D表示，并将对象掩码提升为详细3D对象，放置在虚拟环境中。系统支持沉浸式导航和对象级编辑。

研究结果: 与现有方法相比，DreamAnywhere在新视角合成的一致性和图像质量上表现更优，用户研究显示其技术稳健性和实用性得到验证。

研究结论: DreamAnywhere为低预算电影制作等场景提供快速迭代能力，模块化设计使其高度可定制，适用于多样化的3D场景生成需求。

中文摘要: 近年来，文本到3D场景生成技术的进步为多行业的内容创作带来了巨大潜力。尽管研究社区在这一复杂任务上取得了显著进展，但现有方法通常仅生成正面视角的场景，视觉保真度不足，场景理解有限，且通常仅针对室内或室外场景进行优化。本文提出DreamAnywhere，一种模块化系统，用于快速生成和原型化3D场景。该系统从文本生成360度全景图像，将其分解为背景和对象，通过混合修复技术构建完整的3D表示，并将对象掩码提升为详细的3D对象，放置在虚拟环境中。DreamAnywhere支持沉浸式导航和直观的对象级编辑，非常适合场景探索、视觉草图和快速原型设计，且无需大量手动建模。这些特性使其特别适用于低预算电影制作，能够快速迭代场景布局和视觉风格，而无需传统3D工作流程的开销。模块化设计允许独立替换组件，具有高度可定制性。与当前最先进的基于文本和图像的3D场景生成方法相比，DreamAnywhere在新视角合成的一致性和图像质量上表现出显著提升，验证了其在多样化和挑战性场景中的有效性。全面的用户研究表明，用户明显偏好我们的方法，进一步验证了其技术稳健性和实用性。

</details>


### [189] [EditP23: 3D Editing via Propagation of Image Prompts to Multi-View](https://arxiv.org/abs/2506.20652)
**中文标题：EditP23：通过图像提示传播实现多视角3D编辑**

*Roi Bar-On,Dana Cohen-Bar,Daniel Cohen-Or*

主要分类: cs.GR

摘要简述: EditP23是一种无需掩码的3D编辑方法，通过将2D图像编辑传播到多视角表示中，实现3D一致的编辑效果。


<details>
  <summary>详细信息</summary>
研究动机: 传统3D编辑方法依赖基于文本的提示或显式空间掩码，操作复杂且不够直观。EditP23旨在通过一对图像（原始视图和用户编辑后的视图）作为提示，实现更直观的3D编辑。

研究方法: EditP23利用预训练的多视角扩散模型的潜在空间，通过编辑感知流将2D图像编辑一致地传播到多视角中。该方法无需优化，以直接前馈方式运行，同时保留原始对象的结构和外观特征。

研究结果: 实验表明，EditP23在多种对象类别和编辑场景中均表现出色，能够高保真地保留源内容，且无需手动掩码。

研究结论: EditP23提供了一种高效、直观的3D编辑方法，通过图像提示实现多视角一致的编辑效果，为3D内容创作提供了新的可能性。

中文摘要: 我们提出了EditP23，一种无需掩码的3D编辑方法，通过将2D图像编辑以3D一致的方式传播到多视角表示中。与传统依赖基于文本提示或显式空间掩码的方法不同，EditP23通过一对图像（原始视图及其用户编辑后的版本）作为提示，实现直观的编辑。这些图像提示用于引导预训练多视角扩散模型潜在空间中的编辑感知流，使编辑能够一致地传播到多视角中。我们的方法以前馈方式运行，无需优化，并保留了原始对象的结构和外观特征。我们在多种对象类别和编辑场景中验证了其有效性，实现了对源内容的高保真度，且无需手动掩码。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [190] [A Multi-Modal Spatial Risk Framework for EV Charging Infrastructure Using Remote Sensing](https://arxiv.org/abs/2506.19860)
**中文标题：基于遥感的多模态电动汽车充电基础设施空间风险框架**

*Oktay Karakuş,Padraig Corcoran*

主要分类: eess.SP

摘要简述: 本文提出了一种多模态空间风险框架RSERI-EV，结合遥感数据和空间图分析，评估电动汽车充电站在环境和基础设施压力下的脆弱性，并以威尔士充电站数据集为例验证其可行性。


<details>
  <summary>详细信息</summary>
研究动机: 电动汽车充电基础设施对可持续交通系统至关重要，但其在环境和基础设施压力下的韧性研究不足。本文旨在填补这一空白，通过多模态数据融合评估充电站的脆弱性。

研究方法: RSERI-EV框架整合了洪水风险图、地表温度极值、植被指数、土地利用/覆盖、变电站邻近性和道路可达性等多源数据，生成综合韧性评分。通过构建空间k近邻图，实现基于邻域的对比和图感知诊断。

研究结果: 在威尔士充电站数据集上的应用表明，该框架能够有效评估充电站的脆弱性，并支持气候韧性和基础设施感知的电动汽车部署。

研究结论: 多源数据融合和可解释的空间推理为气候韧性的电动汽车充电基础设施部署提供了重要支持。

中文摘要: 电动汽车（EV）充电基础设施对可持续交通系统日益重要，但其在环境和基础设施压力下的韧性研究仍不足。本文提出了RSERI-EV，一种空间显式多模态风险评估框架，结合遥感数据、开放基础设施数据集和空间图分析，评估电动汽车充电站的脆弱性。RSERI-EV整合了洪水风险图、地表温度极值、植被指数（NDVI）、土地利用/覆盖（LULC）、变电站邻近性和道路可达性等多源数据，生成综合韧性评分。我们以威尔士电动汽车充电站数据集为例验证了该框架的可行性。通过构建充电网络的空间k近邻图，实现了基于邻域的对比和图感知诊断。原型研究表明，多源数据融合和可解释的空间推理对支持气候韧性和基础设施感知的电动汽车部署具有重要价值。

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [191] [Exploring the Capabilities of the Frontier Large Language Models for Nuclear Energy Research](https://arxiv.org/abs/2506.19863)
**中文标题：探索前沿大语言模型在核能研究中的能力**

*Ahmed Almeldein,Mohammed Alnaggar,Rick Archibald,Tom Beck,Arpan Biswas,Rike Bostelmann,Wes Brewer,Chris Bryan,Christopher Calle,Cihangir Celik,Rajni Chahal,Jong Youl Choi,Arindam Chowdhury,Mark Cianciosa,Franklin Curtis,Gregory Davidson,Sebastian De Pascuale,Lisa Fassino,Ana Gainaru,Yashika Ghai,Luke Gibson,Qian Gong,Christopher Greulich,Scott Greenwood,Cory Hauck,Ehab Hassan,Rinkle Juneja,Soyoung Kang,Scott Klasky,Atul Kumar,Vineet Kumar,Paul Laiu,Calvin Lear,Yan-Ru Lin,Jono McConnell,Furkan Oz,Anant Raj,Pradeep Ramuhalli,Marie Romedenne,Samantha Sabatino,José Salcedo-Pérez,Nathan D. See,Arpan Sircar,Punam Thankur,Tim Younkin,Xiao-Ying Yu,Prashant Jain,Tom Evans,Prasanna Balaprakash*

主要分类: physics.comp-ph

摘要简述: 美国橡树岭国家实验室的AI核能研讨会评估了大语言模型（LLMs）在加速核聚变和核裂变研究中的潜力。14个跨学科团队在一天内使用ChatGPT、Gemini、Claude等AI模型探索了核科学的多项挑战。研究发现LLMs在早期探索、文献综述和工作流设计方面表现优异，但在新材料设计、高级代码生成和领域细节验证方面存在局限。专家驱动的提示工程和AI作为辅助工具的使用是关键成功因素。


<details>
  <summary>详细信息</summary>
研究动机: 探讨大语言模型（LLMs）在核能研究中的应用潜力，以加速核聚变和核裂变领域的科学进展，并探索AI工具如何补充传统物理方法。

研究方法: 14个跨学科团队在一天内使用多种AI模型（如ChatGPT、Gemini、Claude）解决核科学问题，结合提示工程、深度研究和迭代优化，生成假设、原型代码和研究策略。

研究结果: LLMs在早期探索、文献综述和工作流设计方面表现突出，能识别研究空白并生成可行的实验框架，但在新材料设计、高级代码生成和领域细节验证方面存在困难。成功案例依赖于专家驱动的提示工程和AI作为辅助工具的使用。

研究结论: AI工具在核能研究中具有加速科学进展的潜力，但需开发核能专用数据集、工作流自动化和定制模型，同时保持严格的科学标准。

中文摘要: 美国橡树岭国家实验室的AI核能研讨会评估了大语言模型（LLMs）在加速核聚变和核裂变研究中的潜力。14个跨学科团队在一天内使用ChatGPT、Gemini、Claude等AI模型探索了核科学的多项挑战，包括开发聚变反应堆控制的基础模型、自动化蒙特卡洛模拟、预测材料退化以及设计先进反应堆的实验程序。团队采用结合提示工程、深度研究和迭代优化的结构化工作流，生成假设、原型代码和研究策略。关键发现表明，LLMs在早期探索、文献综述和工作流设计方面表现优异，能成功识别研究空白并生成可行的实验框架。然而，其在新材料设计、高级代码生成和需要专家验证的领域细节方面存在显著局限。成功案例依赖于专家驱动的提示工程和将AI视为物理方法的补充工具而非替代品。研讨会验证了AI通过快速迭代和跨学科合成加速核能研究的潜力，同时强调了开发核能专用数据集、工作流自动化和定制模型的必要性。这些结果为将AI工具整合到核科学工作流中提供了路线图，有望缩短更安全、高效核能系统的开发周期，同时保持严格的科学标准。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [192] [Learning Bilateral Team Formation in Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.20039)
**中文标题：合作多智能体强化学习中双边团队形成的学习**

*Koorosh Moslemi,Chi-Guhn Lee*

主要分类: cs.MA

摘要简述: 本文提出了一种动态多智能体系统中学习双边团队形成的框架，填补了现有研究中双边分组选择在动态群体中影响的空白，并验证了其性能和泛化能力的提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有多智能体强化学习（MARL）研究主要关注单边分组、预定义团队或固定群体设置，而双边分组选择在动态群体中的影响尚未充分探索。本文旨在填补这一空白。

研究方法: 引入了一个动态多智能体系统中学习双边团队形成的框架，通过分析双边团队形成的算法特性对策略性能和泛化的影响。

研究结果: 在广泛采用的多智能体场景中验证了该方法的有效性，展示了其竞争性性能和大多数场景中泛化能力的提升。

研究结论: 本文提出的双边团队形成框架为动态多智能体系统中的团队学习提供了新视角，验证了其在性能和泛化方面的优势。

中文摘要: 团队形成和团队学习动态在多智能体强化学习（MARL）中引起了广泛关注。然而，现有研究主要集中于单边分组、预定义团队或固定群体设置，双边分组选择在动态群体中的影响尚未充分探索。为填补这一空白，我们提出了一种动态多智能体系统中学习双边团队形成的框架。通过本研究，我们深入了解了双边团队形成中哪些算法特性影响策略性能和泛化。我们在广泛采用的多智能体场景中验证了该方法，展示了其在大多数场景中的竞争性性能和泛化能力的提升。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [193] [Quantum Neural Networks for Propensity Score Estimation and Survival Analysis in Observational Biomedical Studies](https://arxiv.org/abs/2506.19973)
**中文标题：量子神经网络在观察性生物医学研究中的倾向评分估计与生存分析应用**

*Vojtěch Novák,Ivan Zelinka,Lenka Přibylová,Lubomír Martínek*

主要分类: quant-ph

摘要简述: 本研究探讨了量子神经网络（QNN）在倾向评分估计中的应用，以解决1177名结直肠癌患者中腹腔镜与开放手术技术生存结果比较的选择偏倚问题。QNN在模拟硬件噪声条件下表现优于经典方法，并通过遗传匹配和权重优化实现协变量平衡，最终未发现调整后的生存差异。


<details>
  <summary>详细信息</summary>
研究动机: 在生物医学观察性研究中，选择偏倚是影响生存分析结果的主要问题。本研究旨在利用量子神经网络（QNN）改进倾向评分估计，以更准确地比较腹腔镜与开放手术技术的生存结果。

研究方法: 研究使用包含77个变量的数据集，开发了基于QNN的倾向评分模型，重点关注年龄、性别、分期和BMI四个关键协变量。QNN架构采用线性ZFeatureMap进行数据编码，SummedPaulis算子进行预测，并使用CMA-ES进行梯度优化。通过方差正则化减少量子测量噪声，并在精确、采样和模拟噪声条件下进行实验。

研究结果: 在模拟硬件噪声条件下，QNN在小样本（n=100）中表现优于经典逻辑回归和梯度提升机（AUC高达0.750）。倾向评分匹配和加权优化后，协变量平衡标准化均差分别为0.0849和0.0869。调整后的生存分析未发现显著差异（p值0.287-0.851）。

研究结论: 研究表明，QNN结合CMA-优化和噪声感知策略，能够有效改进生物医学研究中的因果推断，尤其适用于小样本高维数据集。

中文摘要: 本研究探讨了量子神经网络（QNN）在倾向评分估计中的应用，以解决1177名结直肠癌患者中腹腔镜与开放手术技术生存结果比较的选择偏倚问题。使用包含77个变量的数据集（包括患者人口统计学和肿瘤特征），我们开发了基于QNN的倾向评分模型，重点关注年龄、性别、分期和BMI四个关键协变量。QNN架构采用线性ZFeatureMap进行数据编码，SummedPaulis算子进行预测，并使用CMA-ES在噪声量子环境中进行鲁棒的梯度优化。通过方差正则化减少量子测量噪声，并在精确、采样（1024次）和模拟噪声硬件（FakeManhattanV2）条件下进行实验。QNN在模拟硬件噪声条件下表现优于经典逻辑回归和梯度提升机（小样本AUC高达0.750），噪声建模增强了预测稳定性。通过遗传匹配和匹配权重优化的倾向评分匹配和加权实现了协变量平衡（标准化均差分别为0.0849和0.0869）。使用Kaplan-Meier估计、Cox比例风险模型和Aalen加性回归进行的生存分析显示调整后无显著生存差异（p值0.287-0.851），表明未调整结果中存在混杂偏倚。这些结果突显了QNN结合CMA-ES和噪声感知策略在改进生物医学研究因果推断中的潜力，尤其适用于小样本高维数据集。

</details>


### [194] [Practical insights on the effect of different encodings, ansätze and measurements in quantum and hybrid convolutional neural networks](https://arxiv.org/abs/2506.20355)
**中文标题：量子与混合卷积神经网络中不同编码、ansätze和测量对性能影响的实用见解**

*Jesús Lozano-Cruz,Albert Nieto-Morales,Oriol Balló-Gimbernat,Adan Garriga,Antón Rodríguez-Otero,Alejandro Borrallo-Rentero*

主要分类: quant-ph

摘要简述: 本研究探讨了量子卷积神经网络（QCNN）和混合量子卷积神经网络（HQNN）中参数化量子电路（PQCs）的设计选择对卫星图像分类任务的影响。通过评估约500种不同模型配置，发现数据编码策略对混合架构性能影响最大（验证准确率差异达30%），而变分ansätze和测量基选择影响较小（差异低于5%）。纯量子模型中，测量协议和数据到振幅的映射对性能影响显著。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索量子卷积神经网络和混合量子卷积神经网络中参数化量子电路的不同设计选择（如数据编码、变分ansätze和测量基）对模型性能的影响，以优化卫星图像分类任务的性能。

研究方法: 研究方法包括在EuroSAT数据集上系统评估约500种不同的模型配置，比较数据编码技术、变分ansätze和测量基对量子及混合卷积神经网络性能的影响。混合架构还与其经典等效架构进行了对比。

研究结果: 结果显示，在混合架构中，数据编码策略对验证准确率的影响最大（差异达30%），而变分ansätze和测量基的选择影响较小（差异低于5%）。纯量子模型中，测量协议和数据到振幅的映射对性能影响显著，验证准确率差异分别达30%和8%。

研究结论: 结论表明，数据编码策略是混合量子卷积神经网络性能的主要影响因素，而纯量子模型的性能更依赖于测量协议和数据映射。这些发现为量子机器学习模型的设计提供了实用指导。

中文摘要: 本研究探讨了量子卷积神经网络（QCNN）和混合量子卷积神经网络（HQNN）中参数化量子电路（PQCs）的设计选择，应用于EuroSAT数据集的卫星图像分类任务。我们系统评估了约500种不同模型配置中数据编码技术、变分ansätze和测量基对性能的影响。分析表明，模型性能的影响因素存在明显层次。对于混合架构（与直接经典等效架构对比，如移除PQCs的相同架构），数据编码策略是主导因素，不同嵌入的验证准确率差异超过30%。相比之下，变分ansätze和测量基的选择影响较小，验证准确率差异低于5%。对于纯量子模型（仅限于振幅编码），性能最依赖于测量协议和数据到振幅的映射。测量策略使验证准确率差异达30%，而编码映射的差异约为8个百分点。

</details>
