<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 57]
- [cs.CV](#cs.CV) [Total: 81]
- [cs.AI](#cs.AI) [Total: 41]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CY](#cs.CY) [Total: 10]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.HC](#cs.HC) [Total: 3]
- [stat.ML](#stat.ML) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 2]
- [cs.SD](#cs.SD) [Total: 3]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.RO](#cs.RO) [Total: 9]
- [cs.IR](#cs.IR) [Total: 9]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [eess.IV](#eess.IV) [Total: 10]
- [cs.CC](#cs.CC) [Total: 1]
- [cs.CR](#cs.CR) [Total: 10]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 33]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.SE](#cs.SE) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TokenShapley: Token Level Context Attribution with Shapley Value](https://arxiv.org/abs/2507.05261)
**中文标题：TokenShapley：基于Shapley值的令牌级上下文归因**

*Yingtai Xiao,Yuqing Zhu,Sirat Samyoun,Wanrong Zhang,Jiachen T. Wang,Jian Du*

主要分类: cs.CL

摘要简述: TokenShapley是一种新颖的基于Shapley值的令牌级上下文归因方法，通过结合KNN检索技术，显著提升了令牌级归因的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在上下文学习中表现出色，但验证其生成响应的正确性仍具挑战性。现有方法仅支持句子级归因，无法满足用户对特定关键词（如数字、年份或名称）的归因需求。

研究方法: TokenShapley结合了基于Shapley值的数据归因和KNN检索技术，利用预计算的数据存储进行上下文检索，并通过Shapley值量化令牌重要性，实现细粒度的数据归因。

研究结果: 在四个基准测试上的广泛评估表明，TokenShapley在令牌级归因任务中优于现有基线方法，准确率提升了11-23%。

研究结论: TokenShapley为令牌级上下文归因提供了高效且准确的解决方案，填补了现有方法的不足。

中文摘要: 大型语言模型（LLMs）在上下文学习中表现出强大的能力，但验证其生成响应的正确性仍是一个挑战。先前的研究探索了句子级的归因方法，但这些方法无法满足用户对响应中特定关键词（如数字、年份或名称）的归因需求。为解决这一局限性，我们提出了TokenShapley，这是一种新颖的令牌级归因方法，结合了基于Shapley值的数据归因和受KNN增强LLMs启发的KNN检索技术。通过利用预计算的数据存储进行上下文检索，并计算Shapley值以量化令牌重要性，TokenShapley提供了一种细粒度的数据归因方法。在四个基准测试上的广泛评估表明，TokenShapley在令牌级归因任务中优于现有基线方法，准确率提升了11-23%。

</details>


### [2] [User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs](https://arxiv.org/abs/2507.05266)
**中文标题：用户行为预测作为一种通用、稳健、可扩展且低成本的评估策略，用于估计大型语言模型的泛化能力**

*Sougata Saha,Monojit Choudhury*

主要分类: cs.CL

摘要简述: 本文提出用户行为预测作为衡量大型语言模型（LLMs）泛化能力的新方法，避免了数据污染问题，并在电影和音乐推荐数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 由于数据污染问题，传统方法难以准确衡量LLMs的泛化能力。本文认为知识检索和推理任务不适合评估泛化，因此提出用户行为预测作为更可靠、可扩展的替代方案。

研究方法: 作者设计了一个用户行为预测框架，并在GPT-4o、GPT-4o-mini和Llama-3.1-8B-Instruct模型上进行了测试，使用了电影和音乐推荐数据集。

研究结果: 结果显示，GPT-4o表现优于GPT-4o-mini和Llama，但所有模型仍有改进空间，尤其是Llama。

研究结论: 用户行为预测是一种理论可靠、可扩展且稳健的评估方法，适用于衡量LLMs的泛化能力。

中文摘要: 由于数据污染问题，衡量大型语言模型（LLMs）的泛化能力具有挑战性。随着模型规模扩大和计算成本降低，确保训练阶段未见过任务和测试用例几乎不可能。我们认为知识检索和推理任务不适合衡量泛化，因为LLMs并非为特定任务训练。相反，我们提出用户行为预测（也是个性化的关键方面）作为一种理论可靠、可扩展且稳健的替代方案。我们为此引入了一个新框架，并在电影和音乐推荐数据集上对GPT-4o、GPT-4o-mini和Llama-3.1-8B-Instruct进行了测试。结果与框架预测一致，显示GPT-4o优于GPT-4o-mini和Llama，但所有模型仍有较大改进空间，尤其是Llama。

</details>


### [3] [An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks](https://arxiv.org/abs/2507.05271)
**中文标题：一种用于数字社交网络中隐性性别歧视检测的自适应监督对比学习框架**

*Mohammad Zia Ur Rehman,Aditya Shah,Nagendra Kumar*

主要分类: cs.CL

摘要简述: 本文提出了一种自适应监督对比学习框架（ASCEND），用于检测数字社交网络中的隐性性别歧视。通过阈值对比学习机制，优化嵌入空间，显著提升检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体中隐性性别歧视内容广泛传播，但传统检测方法往往难以捕捉其微妙特征。本文旨在开发一种更有效的方法来识别此类内容。

研究方法: 采用自适应监督对比学习框架（ASCEND），结合阈值对比学习机制，通过计算嵌入间的余弦相似度，选择性处理样本对。同时，通过联合优化对比损失和交叉熵损失，增强文本特征，并引入情感、情绪和毒性特征。

研究结果: 在EXIST2021和MLSC数据集上的实验表明，ASCEND显著优于现有方法，平均Macro F1分数分别提高了9.86%、29.63%和32.51%。

研究结论: ASCEND框架通过优化嵌入空间和联合损失函数，有效捕捉隐性性别歧视的细微特征，为社交媒体内容检测提供了新思路。

中文摘要: 社交媒体的全球影响力加剧了仇恨内容的传播，其中包括常被传统检测方法忽视的隐性性别歧视。本文提出了一种自适应监督对比学习框架（ASCEND），用于隐性性别歧视检测。该方法的核心创新是引入基于阈值的对比学习：通过计算嵌入间的余弦相似度，仅选择相似度超过可学习阈值的样本对作为正例。这一机制通过将语义相似的文本表示拉近、不相似的推远，优化了嵌入空间，从而减少误报和漏报。最终分类通过联合优化对比损失和交叉熵损失实现。文本特征通过词级注意力模块增强，并引入情感、情绪和毒性特征。在EXIST2021和MLSC数据集上的评估表明，ASCEND显著优于现有方法，平均Macro F1分数分别提高了9.86%、29.63%和32.51%，凸显了其在捕捉隐性性别歧视语言细微线索方面的有效性。

</details>


### [4] [Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion](https://arxiv.org/abs/2507.05285)
**中文标题：超越经典与当代模型：基于RAG、提示工程和跨模态融合的远程教育学生辍学预测变革性AI框架**

*Miloud Mihoubi,Meriem Zerkouk,Belkacem Chikhaoui*

主要分类: cs.CL

摘要简述: 本文提出了一种创新的AI框架，结合RAG、提示工程和跨模态融合技术，显著提升了远程教育中学生辍学预测的准确性和可操作性。


<details>
  <summary>详细信息</summary>
研究动机: 远程教育中的学生辍学问题对社会和经济影响深远，传统机器学习模型难以捕捉学生非结构化互动中的情感和情境因素，因此需要一种更全面的预测方法。

研究方法: 通过RAG增强的BERT模型进行领域特定情感分析，结合提示工程解码学业压力信号，并利用跨模态注意力融合技术动态整合文本、行为和社会人口学数据。

研究结果: 在4,423名学生的纵向数据集上，该框架实现了89%的准确率和0.88的F1分数，比传统模型高出7%，并将假阴性减少了21%。

研究结论: 该研究不仅提升了预测性能，还生成了可解释的干预措施，为全球教育系统提供了一种可扩展的辍学风险缓解方案。

中文摘要: 远程教育中的学生辍学问题是一个具有深远社会和经济效益的关键挑战。尽管经典机器学习模型利用结构化的社会人口和行为数据，但往往无法捕捉非结构化学生互动中蕴含的微妙情感和情境因素。本文提出了一种变革性AI框架，通过三项协同创新重新定义辍学预测：基于检索增强生成（RAG）的领域特定情感分析、解码学业压力的提示工程，以及动态对齐文本、行为和社会人口学洞察的跨模态注意力融合。通过将情感分析建立在精选的教学内容知识库上，我们的RAG增强BERT模型以前所未有的情境相关性解读学生评论，而优化的提示则隔离了学业压力指标（如“孤立感”、“学业负担焦虑”）。跨模态注意力层随后将这些洞察与时序参与模式融合，形成全面的风险画像。在4,423名学生的纵向数据集上评估，该框架实现了89%的准确率和0.88的F1分数，比传统模型高出7%，并将假阴性减少了21%。除了预测，系统还通过检索情境对齐的策略（如为孤立学习者提供导师计划）生成可解释的干预措施。这项工作弥合了预测分析与可操作教学法之间的差距，为全球教育系统提供了一种可扩展的辍学风险缓解方案。

</details>


### [5] [LCDS: A Logic-Controlled Discharge Summary Generation System Supporting Source Attribution and Expert Review](https://arxiv.org/abs/2507.05319)
**中文标题：LCDS：一种支持内容溯源和专家审核的逻辑控制出院摘要生成系统**

*Cheng Yuan,Xinkai Rui,Yongqi Fan,Yawei Fan,Boyang Zhong,Jiacheng Wang,Weiyan Zhang,Tong Ruan*

主要分类: cs.CL

摘要简述: LCDS是一种逻辑控制的出院摘要生成系统，通过构建源映射表和逻辑规则，解决大型语言模型在生成出院摘要时的幻觉问题，并支持内容溯源和专家审核。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在自动生成出院摘要时存在幻觉问题，如生成不准确内容或虚构信息，且难以将生成内容与电子病历的长文本数据关联。LCDS旨在解决这些问题，提升摘要的可靠性和可追溯性。

研究方法: LCDS通过计算电子病历与出院摘要的文本相似性构建源映射表，限制摘要内容的范围，并结合逻辑规则生成可靠的银标准出院摘要。系统支持内容溯源，便于专家审核和修正错误。

研究结果: LCDS能够生成更可靠的出院摘要，支持内容溯源和专家审核，生成的黄金标准摘要可用于逐步微调大型语言模型。

研究结论: LCDS通过逻辑控制和源映射表有效解决了大型语言模型在出院摘要生成中的幻觉问题，提升了内容的可靠性和可追溯性，为临床领域提供了实用工具。

中文摘要: 尽管大型语言模型（LLMs）在自动生成出院摘要方面表现出色，但仍存在幻觉问题，例如生成不准确内容或虚构无来源的信息。此外，电子病历（EMRs）通常为长文本数据，使得LLMs难以将生成内容与来源关联。为解决这些问题，我们提出了LCDS，一种逻辑控制的出院摘要生成系统。LCDS通过计算电子病历与出院摘要的文本相似性构建源映射表，以限制摘要内容的范围。此外，LCDS结合了一套全面的逻辑规则，能够生成针对不同临床领域更可靠的银标准出院摘要。同时，LCDS支持生成内容的溯源，便于专家高效审核、提供反馈和修正错误。生成的黄金标准出院摘要随后被记录用于逐步微调LLMs。我们的项目和演示视频可在GitHub仓库https://github.com/ycycyc02/LCDS中查看。

</details>


### [6] [MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents](https://arxiv.org/abs/2507.05330)
**中文标题：MindFlow：基于多模态大语言模型代理的电子商务客户支持革命**

*Ming Gong,Xucheng Huang,Chenghan Yang,Xianhan Peng,Haoxin Wang,Yang Liu,Ling Jiang*

主要分类: cs.CL

摘要简述: MindFlow是一种开源的多模态大语言模型代理，专为电子商务客户服务设计，通过整合记忆、决策和行动模块，显著提升了复杂查询处理能力和用户满意度。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在电子商务客户服务中的多模态复杂场景中表现受限，MindFlow旨在填补这一空白，提供更高效的解决方案。

研究方法: 基于CoALA框架，MindFlow采用模块化设计，结合记忆、决策和行动模块，并利用“MLLM-as-Tool”策略进行视觉-文本推理。

研究结果: 通过在线A/B测试和模拟消融实验，MindFlow在复杂查询处理、用户满意度和运营成本降低方面表现优异，实际部署中相对提升达93.53%。

研究结论: MindFlow为电子商务客户服务提供了一种高效的多模态解决方案，显著提升了服务质量和效率。

中文摘要: 近年来，大语言模型（LLM）的进展为电子商务客户服务带来了新的应用可能，但其在复杂的多模态场景中仍存在局限性。我们提出了MindFlow，首个专为电子商务设计的开源多模态LLM代理。基于CoALA框架，它整合了记忆、决策和行动模块，并采用模块化的“MLLM-as-Tool”策略进行高效的视觉-文本推理。通过在线A/B测试和模拟消融实验评估，MindFlow在处理复杂查询、提升用户满意度和降低运营成本方面表现出显著优势，实际部署中相对提升达93.53%。

</details>


### [7] [LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks](https://arxiv.org/abs/2507.05346)
**中文标题：LoRA增强生成（LAG）用于知识密集型语言任务**

*William Fleshman,Benjamin Van Durme*

主要分类: cs.CL

摘要简述: 提出了一种名为LoRA增强生成（LAG）的方法，用于高效选择和组合任务特定的LoRA适配器，无需额外训练或数据访问，在知识密集型任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着针对特定任务和领域的微调语言模型专家增多，亟需高效的选择和组合方法。LAG旨在利用大量知识和任务特定的LoRA适配器，解决这一问题。

研究方法: LAG通过无需额外训练或数据访问的方式，高效地过滤、检索和应用专家，基于每个token和层进行操作。

研究结果: 在多种知识密集型任务中，LAG表现优于现有无需数据的方法，并在有额外数据时展示了与检索增强生成（RAG）等替代方案的兼容性。

研究结论: LAG为知识密集型任务提供了一种高效且灵活的解决方案，能够无缝结合其他技术如RAG。

中文摘要: 随着针对特定任务和领域的微调语言模型专家的增多，亟需高效的选择和组合方法。我们提出了LoRA增强生成（LAG），用于利用大量知识和任务特定的LoRA适配器。LAG无需额外训练或数据访问，能够高效地过滤、检索和应用专家，基于每个token和层进行操作。我们在多种知识密集型任务中评估了LAG，其表现优于现有无需数据的方法。我们还探讨了在有额外数据时的场景，展示了LAG与检索增强生成（RAG）等替代方案的兼容性。

</details>


### [8] [On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study](https://arxiv.org/abs/2507.05362)
**中文标题：关于下一词预测器对系统性低效推理的偏向：以最短路径任务为例**

*Riccardo Alberghi,Elizaveta Demyanenko,Luca Biggio,Luca Saglietti*

主要分类: cs.CL

摘要简述: 研究发现，在最短路径任务中，训练语言模型时使用低效但连贯的推理轨迹比使用最优轨迹更能提升模型的泛化能力，这与模型对下一词预测的置信度相关。


<details>
  <summary>详细信息</summary>
研究动机: 探讨如何通过优化推理轨迹（如系统性和增量性）提升大型语言模型的推理能力，尤其是在计算资源分配和冗余推理轨迹的影响下。

研究方法: 在分层图的最短路径任务中，训练解码器专用Transformer模型，比较使用最优动态规划轨迹和低效回溯轨迹的训练效果，并分析冗余推理轨迹的影响。

研究结果: 使用低效但连贯的推理轨迹训练的模型在未见图上表现更好，其泛化能力与模型对下一词预测的置信度相关，而单纯增加冗余则无益甚至有害。

研究结论: 长且连贯的推理轨迹能优化训练信号，提升模型泛化能力，而非单纯的计算冗余或最优轨迹。

中文摘要: 自然语言处理的最新进展表明，提升大型语言模型（LLMs）推理能力的关键因素包括：（i）分配更多测试时计算资源通常对解决更难问题有帮助，但常导致推理轨迹冗余；（ii）计算资源最有效时，推理是系统且增量的，形成类似人类问题解决的结构化思维链（CoTs）。为单独研究这些因素，我们引入基于分层图最短路径任务的受控实验。通过自定义分词器训练解码器专用Transformer模型，比较使用最优自底向上动态规划轨迹和较长但有效的回溯轨迹训练的模型。出乎意料的是，在相同训练词数预算下，使用低效轨迹训练的模型在未见图上泛化能力更强。这种优势并非仅因长度——在推理轨迹中注入任意冗余无益甚至有害。相反，我们发现泛化能力与模型对下一词预测的置信度相关，表明长、连贯且局部增量的轨迹使训练信号更易优化。

</details>


### [9] [EduCoder: An Open-Source Annotation System for Education Transcript Data](https://arxiv.org/abs/2507.05385)
**中文标题：EduCoder：一个面向教育转录数据的开源标注系统**

*Guanzhong Pan,Mei Tan,Hyunji Nam,Lucía Langlois,James Malamut,Liliana Deonizio,Dorottya Demszky*

主要分类: cs.CL

摘要简述: EduCoder是一个专为教育对话数据标注设计的开源工具，支持复杂教学特征的编码，提供分类和开放式标注功能，并支持多标注者结果的对比与校准。


<details>
  <summary>详细信息</summary>
研究动机: 现有通用文本标注工具难以满足教育对话转录数据的复杂需求，如定义教学特征代码本、支持多种标注类型及上下文关联。EduCoder旨在解决这些问题。

研究方法: EduCoder提供协作定义复杂代码本的平台，支持分类和开放式标注，整合上下文材料，并提供多标注者结果的对比功能以提高数据可靠性。

研究结果: EduCoder成功实现了教育对话数据的复杂标注需求，支持研究者与领域专家协作，提升标注效率和可靠性。

研究结论: EduCoder为教育对话数据标注提供了高效、灵活的开源解决方案，填补了现有工具的空白。

中文摘要: 我们介绍了EduCoder，这是一个专为教育对话的语句级标注设计的领域专用工具。尽管通用文本标注工具在自然语言处理和定性研究中广泛应用，但很少有工具能够应对教育对话转录数据的复杂性——包括多样化的师生和同伴互动。常见挑战包括为复杂的教学特征定义代码本、支持开放性和分类性编码，以及将语句与外部特征（如课程目标和教学价值）关联起来。EduCoder旨在通过提供一个平台，让研究者和领域专家能够基于观察数据协作定义复杂代码本，从而解决这些挑战。它整合了分类性和开放性标注类型以及上下文材料。此外，它还支持多标注者结果的并列对比，允许通过与他人的标注进行比较和校准来提高数据可靠性。该系统为开源项目，提供演示视频。

</details>


### [10] [The Generalization Ridge: Information Flow in Natural Language Generation](https://arxiv.org/abs/2507.05387)
**中文标题：泛化岭：自然语言生成中的信息流动**

*Ruidi Chang,Chunyuan Deng,Hanjie Chen*

主要分类: cs.CL

摘要简述: 本文提出InfoRidge框架，通过信息论方法研究Transformer模型在训练过程中任务相关信息如何在不同层间流动，发现预测信息在中间层形成‘泛化岭’，揭示了中间层对泛化能力的关键作用。


<details>
  <summary>详细信息</summary>
研究动机: 尽管Transformer模型在自然语言生成任务中表现优异，但其内部如何合成任务相关信息的机制尚不明确。研究旨在揭示模型训练过程中信息流动的规律，尤其是中间层对泛化能力的影响。

研究方法: 提出InfoRidge框架，通过计算隐藏表示与目标输出之间的互信息，追踪任务相关信息在模型各层的流动。引入残差缩放系数作为功能探针，评估各层在分布偏移下的重要性。

研究结果: 实验发现预测信息在中间层达到峰值（形成‘泛化岭’），随后在最终层下降，表明模型从泛化转向记忆。残差缩放系数显示，在分布偏移下，模型更依赖中间层。

研究结论: 中间层在Transformer模型中扮演泛化关键角色，InfoRidge框架为理解模型内部机制提供了新视角。

中文摘要: 基于Transformer的语言模型在自然语言生成（NLG）任务中取得了最先进的性能，但其合成任务相关信息的内部机制仍未被充分理解。尽管先前研究表明中间层通常比最终层产生更具泛化性的表示，但这种泛化能力在训练过程中如何形成并跨层传播尚不清楚。为填补这一空白，我们提出InfoRidge，一种信息论框架，用于描述预测信息（隐藏表示与目标输出之间的互信息）如何随深度变化。通过估计这一量，我们能够追踪训练过程中任务相关信息在模型中的流动。我们在多种模型和数据集上的实验揭示了一致的非单调趋势：预测信息在上中层达到峰值（形成‘泛化岭’），随后在最终层下降，反映了从泛化到记忆的过渡。为进一步研究这一现象，我们引入了残差缩放系数（可训练的标量参数，应用于每个残差块），作为评估各Transformer层相对重要性的功能探针。这些系数表明，在分布偏移下，模型会降低最终层的权重并更依赖‘泛化岭’层，凸显了后者在泛化中的作用。这些发现为Transformer的内部机制提供了新见解，并强调了中间层在支持泛化中的关键作用。

</details>


### [11] [Controlling What You Share: Assessing Language Model Adherence to Privacy Preferences](https://arxiv.org/abs/2507.05391)
**中文标题：控制你的分享内容：评估语言模型对隐私偏好的遵循程度**

*Guillem Ramírez,Alexandra Birch,Ivan Titov*

主要分类: cs.CL

摘要简述: 本文探讨了如何通过隐私配置文件（自然语言指令）让用户控制数据隐私，提出了一种本地模型框架，用于在查询外部模型前隐藏敏感信息，并引入了多语言数据集PEEP。实验表明，轻量级语言模型能部分遵循指令，但仍需改进以更好地满足用户隐私需求。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）通常通过商业API访问，但用户需向服务提供商暴露数据。本文旨在让用户通过隐私配置文件控制数据隐私，平衡隐私与性能。

研究方法: 提出一个框架，本地模型根据用户的隐私配置文件（自然语言指令）重写查询，隐藏敏感信息后再发送给外部模型。引入了多语言数据集PEEP，包含真实用户查询和合成隐私配置文件。

研究结果: 实验表明，轻量级LLMs能部分遵循隐私指令，但仍存在挑战，需改进模型以更好地理解和遵守用户隐私偏好。

研究结论: 隐私配置文件是一种有效的数据控制方法，但需进一步优化模型以完全满足用户隐私需求。

中文摘要: 大型语言模型（LLMs）主要通过商业API访问，但用户通常需要向服务提供商暴露数据。本文探讨了如何通过隐私配置文件（简单的自然语言指令）让用户控制数据隐私。我们构建了一个框架，本地模型根据这些指令重写查询，仅隐藏用户认为敏感的内容，再发送给外部模型，从而平衡隐私与性能。为支持研究，我们引入了PEEP，一个多语言数据集，包含标记隐私内容的真实用户查询和合成隐私配置文件。实验表明，轻量级LLMs能部分遵循这些指令，但也面临持续挑战，突显了需要更好地理解和遵守用户隐私偏好的模型。

</details>


### [12] [Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning](https://arxiv.org/abs/2507.05418)
**中文标题：全球学习，本地表达：弥合多语言推理的鸿沟**

*Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang*

主要分类: cs.CL

摘要简述: 本文提出GeoFact-X基准和BRIDGE方法，旨在提升大语言模型在低资源语言中的多语言推理能力，通过语言一致性奖励和自动评估协议显著改善推理准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在多语言推理任务中表现不佳，尤其是低资源语言（如斯瓦希里语或泰语），常因偏向高资源语言（如英语）而影响事实准确性和可解释性。现有基准仅关注最终答案，忽略了模型是否真正用目标语言推理。

研究方法: 提出GeoFact-X基准，包含五种语言（英语、印地语、日语、斯瓦希里语、泰语）的地理事实推理任务及标注推理轨迹；设计BRIDGE训练方法，结合监督微调和测试时强化学习，通过语言一致性奖励对齐推理与输入语言；开发基于LLM的自动评估协议，分析答案正确性及推理轨迹的语言一致性。

研究结果: BRIDGE显著提升了多语言推理的准确性，证明了推理感知的多语言强化学习对跨语言泛化的重要性。

研究结论: 通过GeoFact-X基准和BRIDGE方法，研究展示了语言一致性在多语言推理中的关键作用，为未来模型优化提供了新方向。

中文摘要: 大语言模型（LLMs）在数学、事实问答和代码生成等领域表现优异，但其在这些任务中的多语言推理能力仍显不足。尤其是对于斯瓦希里语或泰语等低资源语言，LLMs常误解提示或默认用英语推理。这种对高资源语言的隐性偏见损害了事实准确性、可解释性和信任度。当前的多语言基准仅关注最终答案，忽视了模型是否真正用目标语言推理。为解决这一问题，我们引入GeoFact-X，一个基于地理的多语言事实推理基准，包含英语、印地语、日语、斯瓦希里语和泰语的标注推理轨迹。我们进一步提出BRIDGE，一种新颖的训练方法，通过语言一致性奖励指导监督微调和测试时强化学习，以对齐推理与输入语言。最后，我们开发了一种基于LLM的自动评估协议，用于评估答案正确性及推理轨迹的质量和语言一致性，实现了超越表面指标的细致且可扩展的分析。结果表明，BRIDGE显著提升了多语言推理的保真度，证明了推理感知的多语言强化学习对稳健跨语言泛化的重要性。

</details>


### [13] ["Lost-in-the-Later": Framework for Quantifying Contextual Grounding in Large Language Models](https://arxiv.org/abs/2507.05424)
**中文标题：‘后期丢失’：量化大语言模型中上下文基础性的框架**

*Yufei Tao,Adam Hiatt,Rahul Seetharaman,Ameeta Agrawal*

主要分类: cs.CL

摘要简述: 论文提出CoPE框架，用于量化大语言模型中的上下文知识（CK）和参数知识（PK），发现模型存在‘后期丢失’现象，即忽略上下文后期信息，并提出基于提示的方法改善上下文利用。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型能够利用上下文和参数知识，但其如何优先整合这些知识尚不明确。研究旨在系统量化模型在不同语言中的知识利用情况，揭示其潜在偏差。

研究方法: 通过MultiWikiAtomic数据集（英语、西班牙语、丹麦语），分析模型在开放式问答中整合上下文、优先信息和利用PK的方式。提出CoPE框架，并设计提示方法优化上下文利用。

研究结果: 发现‘后期丢失’现象，模型倾向于忽略上下文后期信息；推理模型和链式思维（CoT）提示的模型对上下文利用更差。提示方法可改善事实基础和减少幻觉。

研究结论: CoPE框架揭示了模型在上下文利用中的偏差，提示方法能有效提升模型表现，为未来研究提供了改进方向。

中文摘要: 大语言模型能够利用上下文和参数知识，但其如何优先整合这些知识尚不明确。我们提出CoPE框架，系统测量模型在不同语言中的上下文知识（CK）和参数知识（PK）。通过英语、西班牙语和丹麦语的MultiWikiAtomic数据集，分析模型在开放式问答中整合上下文、优先信息和利用PK的方式。研究发现‘后期丢失’现象，即模型倾向于忽略或降低上下文后期信息的优先级，显示出影响上下文基础性的强烈位置偏差。进一步发现，推理模型及使用链式思维（CoT）提示的非推理模型对上下文利用更差，且未能缓解‘后期丢失’效应。CoT提示尤其导致召回率降低和回答缩短，削弱了上下文基础性。基于这些发现，我们设计了基于提示的方法以有效利用输入上下文。通过CoPE在摘要任务中的应用案例，表明CK提示能改善事实基础并减少幻觉。

</details>


### [14] [Gendered Divides in Online Discussions about Reproductive Rights](https://arxiv.org/abs/2507.05443)
**中文标题：关于生殖权利的在线讨论中的性别差异**

*Ashwin Rao,Sze Yuh Nina Wang,Kristina Lerman*

主要分类: cs.CL

摘要简述: 美国最高法院2022年对Dobbs诉Jackson妇女健康组织案的裁决成为生殖权利全国辩论的转折点。研究发现，性别和地区政治背景显著影响公众对堕胎的态度和情感表达，尤其在保守地区，性别差异更为明显。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探讨性别和地区政治背景如何影响公众对生殖权利的讨论，特别是在意识形态分歧明显的堕胎议题上。

研究方法: 研究分析了近1000万条来自X（原Twitter）的堕胎相关帖子，通过推断用户的性别、意识形态和地理位置，探究性别对堕胎态度和情感表达的影响。

研究结果: 研究发现，性别显著调节了堕胎态度和情感表达，尤其在保守地区，性别差异更为明显。Dobbs案草案泄露后，支持堕胎的女性在受威胁地区的在线参与度显著增加。

研究结论: 堕胎讨论不仅受意识形态极化影响，还深刻受到性别和地区的结构化影响，突显了身份认同在制度动荡时期政治表达中的核心作用。

中文摘要: 美国最高法院2022年对Dobbs诉Jackson妇女健康组织案的裁决成为生殖权利全国辩论的转折点。尽管关于堕胎的意识形态分歧已有充分记录，但性别和地方社会政治背景如何共同塑造公众讨论尚不明确。通过分析近1000万条来自X（原Twitter）的堕胎相关帖子（用户性别、意识形态和地理位置已推断），我们发现性别显著调节了堕胎态度和情感表达，尤其在保守地区，且独立于意识形态。这导致堕胎态度中的性别差异在保守地区更为明显。Dobbs案草案泄露进一步加剧了在线参与，尤其是在堕胎权利受威胁地区，支持堕胎的女性被不成比例地动员起来。这些发现表明，堕胎讨论不仅受意识形态极化影响，还深刻受到性别和地区的结构化影响，突显了身份认同在制度动荡时期政治表达中的核心作用。

</details>


### [15] [PhoniTale: Phonologically Grounded Mnemonic Generation for Typologically Distant Language Pairs](https://arxiv.org/abs/2507.05444)
**中文标题：PhoniTale：基于语音学的助记符生成系统用于类型差异大的语言对**

*Sana Kang,Myeongseok Gwon,Su Young Kwon,Jaewook Lee,Andrew Lan,Bhiksha Raj,Rita Singh*

主要分类: cs.CL

摘要简述: 本文提出PhoniTale系统，通过语音相似性检索L1关键词序列并利用大语言模型生成助记符，帮助学习类型差异大的语言对（如英语和韩语）。实验表明其效果接近人工助记符，并指出了未来改进方向。


<details>
  <summary>详细信息</summary>
研究动机: 学习类型差异大的语言对（如英语和韩语）时，词汇习得因语音和结构不匹配而困难。现有研究多关注英语母语者学习其他语言，而忽略了反向情况。本文旨在填补这一空白，提出基于语音相似性的助记符生成系统。

研究方法: PhoniTale系统通过语音相似性检索学习者的母语（L1）关键词序列，并利用大语言模型生成助记符。通过自动化指标和人工评估对比其与人工及现有自动化方法的输出，并进行短期记忆测试验证实用性。

研究结果: 实验结果显示，PhoniTale生成的助记符效果与人工助记符相当。同时，研究指出了助记符质量和生成方法上的改进空间。

研究结论: PhoniTale为类型差异大的语言对提供了一种有效的助记符生成方法，未来需进一步优化助记符质量和生成技术。

中文摘要: 词汇习得对第二语言（L2）学习者而言是一大挑战，尤其是学习类型差异大的语言（如英语和韩语）时，语音和结构的不匹配增加了学习难度。近年来，大语言模型（LLMs）被用于通过利用学习者母语（L1）中的相似关键词生成助记符，以辅助L2词汇学习。然而，这类研究多聚焦于英语母语者学习其他语言，而非反向情况。本文提出PhoniTale，一种新颖的跨语言助记符生成系统，通过语音相似性检索L1关键词序列，并利用LLMs生成助记符。我们通过自动化指标和人工评估对比其输出与人工及现有自动化方法生成的助记符，同时进行短期记忆测试以评估实际效果。结果表明，PhoniTale的表现与人工助记符相当。我们还指出了助记符质量和方法上的未来改进方向。

</details>


### [16] [On the Semantics of Large Language Models](https://arxiv.org/abs/2507.05448)
**中文标题：论大型语言模型的语义学**

*Martin Schuele*

主要分类: cs.CL

摘要简述: 本文探讨大型语言模型（如ChatGPT）是否真正理解语言，通过分析其内部机制和语言表征，结合Frege和Russell的经典语义理论，揭示其语义能力的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）如ChatGPT展现了强大的语言生成和对话能力，但其是否真正理解语言仍存在争议。本文旨在通过语义学视角，探讨LLMs在词句层面的语义能力。

研究方法: 通过分析LLMs的内部工作机制及其生成的语言表征，并结合Frege和Russell的经典语义理论，对LLMs的语义能力进行深入评估。

研究结果: 研究发现，LLMs在词句层面的语义能力存在局限性，其语言生成更多依赖于统计模式而非真正的语义理解。

研究结论: 尽管LLMs在语言任务上表现优异，但其语义理解能力仍有限，未来的研究需进一步探索如何提升其真正的语言理解能力。

中文摘要: 大型语言模型（如ChatGPT）展现了通过技术复制人类语言能力的潜力，涵盖从文本生成到对话的多种任务。然而，这些系统是否真正理解语言仍存在争议。本文通过将问题缩小到词句层面的语义学，结合Frege和Russell的经典语义理论，分析LLMs的内部工作机制及其语言表征，从而更细致地评估LLMs的潜在语义能力。

</details>


### [17] [ModelCitizens:Representing Community Voices in Online Safety](https://arxiv.org/abs/2507.05455)
**中文标题：模范公民：在在线安全中代表社区声音**

*Ashima Suvarna,Christina Chance,Hamid Palangi,Sophie Hao,Thomas Hartvigsen,Saadia Gabriel*

主要分类: cs.CL

摘要简述: 论文提出MODELCITIZENS数据集，包含6.8K社交媒体帖子和40K毒性标注，强调社区多样性对毒性语言检测的重要性。现有模型表现不佳，而基于LLaMA和Gemma的新模型在评估中优于GPT-o4-mini。


<details>
  <summary>详细信息</summary>
研究动机: 现有毒性语言检测模型忽视了社区多样性和语境对毒性判断的影响，导致检测结果不够包容和准确。

研究方法: 构建MODELCITIZENS数据集，包含多样身份群体的标注数据，并通过LLM生成对话场景增强语境。训练了LLAMACITIZEN-8B和GEMMACITIZEN-12B模型。

研究结果: 现有毒性检测工具在MODELCITIZENS上表现不佳，而新模型在分布内评估中优于GPT-o4-mini 5.5%。

研究结论: 社区参与的标注和建模对包容性内容审核至关重要，MODELCITIZENS和新模型为毒性检测提供了更全面的解决方案。

中文摘要: 自动毒性语言检测对于创建安全、包容的在线空间至关重要。然而，这是一项高度主观的任务，对毒性语言的感知受到社区规范和生活经验的影响。现有的毒性检测模型通常基于将多样标注者观点合并为单一真实值的标注数据，忽略了如回收语言等重要的语境特定毒性概念。为解决这一问题，我们引入了MODELCITIZENS数据集，包含6.8K社交媒体帖子和40K来自多样身份群体的毒性标注。为捕捉社交媒体帖子中常见的对话语境对毒性的影响，我们使用LLM生成的对话场景增强MODELCITIZENS帖子。现有毒性检测工具（如OpenAI Moderation API、GPT-o4-mini）在MODELCITIZENS上表现不佳，而在语境增强的帖子上表现更差。最后，我们发布了基于LLaMA和Gemma的LLAMACITIZEN-8B和GEMMACITIZEN-12B模型，在分布内评估中优于GPT-o4-mini 5.5%。我们的研究强调了社区参与的标注和建模对包容性内容审核的重要性。

</details>


### [18] [Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications](https://arxiv.org/abs/2507.05517)
**中文标题：赋能医疗从业者：语言模型在两种真实临床应用中结构化语音转录**

*Jean-Philippe Corbeil,Asma Ben Abacha,George Michalopoulos,Phillip Swazinna,Miguel Del-Agua,Jerome Tremblay,Akila Jeeson Daniel,Cari Bader,Kevin Cho,Pooja Krishnan,Nathan Bodenstab,Thomas Lin,Wenxuan Teng,Francois Beaulieu,Paul Vozila*

主要分类: cs.CL

摘要简述: 本文探讨了使用大型语言模型（LLMs）解决临床自然语言处理中的两个高影响力任务：护士口述的结构化表格报告和医患咨询中的医嘱提取。通过私有和开源数据集评估了不同LLMs的性能，并提出了一种生成非敏感护士口述数据的代理流程。同时，发布了首个开源数据集SYNUR和SIMORD以支持进一步研究。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型在临床自然语言处理任务中表现优异，但护士口述的结构化报告和医嘱提取任务因数据稀缺和敏感性而研究不足。解决这些任务可以显著减轻医疗工作者的文档负担，使其更专注于患者护理。

研究方法: 研究使用私有和开源临床数据集，评估了开放和封闭权重的大型语言模型在护士口述结构化报告和医嘱提取任务中的性能。提出了一种代理流程，用于生成非敏感的护士口述数据以支持结构化提取。

研究结果: 研究发现不同LLMs在两项任务中各有优劣，并成功生成了可用于研究的非敏感护士口述数据。同时，发布了首个开源数据集SYNUR和SIMORD。

研究结论: 本研究为临床自然语言处理中的高影响力任务提供了实用解决方案，并通过开源数据集推动了进一步研究。

中文摘要: 大型语言模型（LLMs）如GPT-4o和o1在多个医学基准测试中表现出色，但护士口述的结构化表格报告和医患咨询中的医嘱提取这两项高影响力自然语言处理任务因数据稀缺和敏感性而研究不足。解决这些真实临床任务可显著减轻医疗工作者的文档负担，使其更专注于患者护理。本文通过私有和开源临床数据集评估了开放和封闭权重LLMs的性能，分析了其优缺点。此外，提出了一种代理流程，用于生成非敏感的护士口述数据以支持结构化提取。为支持这两项任务的进一步研究，我们发布了首个开源数据集SYNUR和SIMORD，分别用于护士观察提取和医嘱提取。

</details>


### [19] [Enhancing Test-Time Scaling of Large Language Models with Hierarchical Retrieval-Augmented MCTS](https://arxiv.org/abs/2507.05557)
**中文标题：基于分层检索增强蒙特卡洛树搜索的大型语言模型测试时扩展优化**

*Alex ZH Dou,Zhongwei Wan,Dongfei Cui,Xin Wang,Jing Xiong,Haokun Lin,Chaofan Tao,Shen Yan,Mi Zhang*

主要分类: cs.CL

摘要简述: 本文提出了一种名为R2-LLMs的分层检索增强推理框架，通过双级检索上下文学习和蒙特卡洛树搜索（MCTS）提升大型语言模型（LLMs）在推理时的性能，无需依赖高级模型的蒸馏数据。实验表明，该方法在复杂推理任务中显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 测试时扩展（test-time scaling）是一种利用额外计算资源提升语言模型推理性能的范式。然而，现有方法通常需要依赖高级模型的蒸馏数据来生成思维链（CoT）训练数据。本文旨在开发一种无需依赖高级模型蒸馏的通用框架，以提升LLMs在复杂推理任务中的性能。

研究方法: R2-LLMs采用分层检索增强推理框架：（1）粗粒度层面，从复杂推理问题中提取抽象模板并检索相似的问题-答案对，实现高层级上下文学习；（2）细粒度层面，在蒙特卡洛树搜索（MCTS）过程中，从数学问题数据集中检索类似中间解决步骤，并结合过程奖励模型（PRM）优化逐步推理。该方法通过PRM改进候选生成和决策，提升推理准确性。

研究结果: 在MATH500、GSM8K和OlympiadBench-TO数据集上的实验表明，使用LLaMA-3.1-8B模型的R2-LLMs相比基线方法实现了高达16%的相对性能提升，验证了其在复杂推理任务中的有效性。

研究结论: R2-LLMs是一种无需依赖高级模型蒸馏的分层检索增强推理框架，通过双级检索和MCTS显著提升了LLMs在复杂推理任务中的性能，为测试时扩展提供了新的解决方案。

中文摘要: 测试时扩展已成为语言建模中一种有前景的范式，通过利用推理时的额外计算资源提升模型性能。本文提出了一种新颖且通用的分层检索增强推理框架R2-LLMs，旨在无需依赖高级模型的蒸馏数据生成思维链（CoT）训练数据的情况下，提升大型语言模型（LLMs）的测试时扩展性能。R2-LLMs通过集成双级检索上下文学习增强推理时的泛化能力：（1）在粗粒度层面，该方法从复杂推理问题中提取抽象模板并检索相似的问题-答案对，以支持高层级上下文学习；（2）在细粒度层面，通过蒙特卡洛树搜索（MCTS）从参考数学问题数据集中高效检索类似中间解决步骤，并借助过程奖励模型（PRM）优化逐步推理。R2-LLMs是一种鲁棒的分层推理增强方法，既提升了上下文级推理能力，又无缝集成了步骤级树搜索方法。通过PRM，该方法改进了候选生成和决策，从而提高了推理准确性。在MATH500、GSM8K和OlympiadBench-TO数据集上的实验表明，使用LLaMA-3.1-8B模型的R2-LLMs相比基线方法实现了高达16%的相对性能提升，验证了其在复杂推理任务中的有效性。

</details>


### [20] [Self-Review Framework for Enhancing Instruction Following Capability of LLM](https://arxiv.org/abs/2507.05598)
**中文标题：增强LLM指令遵循能力的自评估框架**

*Sihyun Park*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Re5的自评估与修订框架，旨在提升大型语言模型（LLM）遵循指令的能力，同时保持生成内容的质量。通过任务和约束组件的提取、结构化评估和选择性修订，Re5在少量数据下实现了与高性能模型相当的指令遵循性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前提升LLM遵循指令能力的方法存在成本高或输出质量下降的问题。为解决这些挑战，本文提出了一种资源高效的自我评估与修订框架Re5，旨在在不增加成本的情况下提升指令遵循性能。

研究方法: Re5框架通过提取用户指令中的任务和约束组件，进行结构化评估以防止错误累积，并应用细粒度的约束特定内容评估和选择性修订，确保精确且质量保持的改进。最终高质量输出用于对齐调优，实现长期对齐改进。

研究结果: 实验结果表明，Re5在少量数据下实现了与GPT-4o-mini生成数据训练的模型相当的指令遵循性能，且未修订初始响应的胜率为64.24%，验证了其高效性和有效性。

研究结论: Re5作为一种高效且资源节约的解决方案，能够显著提升LLM的指令遵循能力，同时保持生成内容的质量，适用于需要最小外部监督的场景。

中文摘要: 为提高大型语言模型（LLM）对格式和指令约束的遵循能力，已有多种技术被提出。其中最有效的方法之一是使用高性能模型生成的高质量数据。然而，这些模型往往无法在单次生成中完全遵循复杂指令。为解决这一限制，迭代修订方法被引入。但随着数据点和修订次数的增加，相关成本显著上升。作为一种资源高效的替代方案，已有方法利用高性能评估工具弥补开源LLM自我评估能力的不足。但这些方法常因过度修订导致输出质量下降。为克服这些挑战，我们提出Re5，一种自评估与修订框架，旨在提升指令遵循性能的同时保持生成内容的质量。Re5从用户指令中提取任务和约束组件，进行结构化评估以防止错误累积，并应用细粒度的约束特定内容评估和选择性修订，确保精确且质量保持的改进。最终高质量输出用于对齐调优，通过数据中心的迭代优化循环实现长期对齐改进。实验结果表明，Re5在少量数据下实现了与GPT-4o-mini生成数据训练的模型相当的指令遵循性能，且未修订初始响应的胜率为64.24%。这些结果验证了Re5作为一种高效且有效的解决方案，能够以最小外部监督提升指令遵循能力。

</details>


### [21] [Flipping Knowledge Distillation: Leveraging Small Models' Expertise to Enhance LLMs in Text Matching](https://arxiv.org/abs/2507.05617)
**中文标题：翻转知识蒸馏：利用小模型专长提升大语言模型在文本匹配中的表现**

*Mingzhe Li,Jing Xiang,Qishen Zhang,Kaiyang Wan,Xiuying Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种翻转知识蒸馏方法，利用小模型的专长提升大语言模型在文本匹配任务中的表现，通过LoRA重新解释大模型为编码器-解码器结构，并结合Margin-aware对比学习实现性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 传统知识蒸馏通常将大模型知识迁移至小模型，但在文本匹配任务中，小模型往往能提供更有效的领域特定表示。本文旨在结合小模型的专长和大模型的语义理解能力，提出翻转知识蒸馏方法。

研究方法: 通过LoRA将解码器结构的大模型重新解释为编码器-解码器形式，编码器生成压缩表示，解码器映射到输出空间。训练时，采用Margin-aware对比学习（MCL）对齐教师模型生成的相似性分数，确保正负样本对的准确相似性。

研究结果: 在金融和医疗领域的基准测试及实际应用中，该方法显著提升了大模型的性能，并已成功部署到在线环境中。

研究结论: 翻转知识蒸馏方法有效结合了小模型的专长和大模型的语义理解能力，为大模型在文本匹配任务中的性能提升提供了新思路。

中文摘要: 知识蒸馏通常涉及将大语言模型（LLM）的知识迁移至小语言模型（SLM）。然而，在文本匹配等任务中，经过微调的小模型往往能提供更有效的领域特定表示，因为它们专注于优化输入对的相似性。为了结合小模型的专长和大模型的丰富语义理解能力，我们提出了一种翻转知识蒸馏范式，即大模型从小模型学习。具体而言，我们通过LoRA将仅解码器结构的大模型重新解释为编码器-解码器形式，编码器生成压缩表示，解码器将其映射到输出空间。训练过程中，编码器生成表示及其相似性，并通过我们提出的Margin-aware对比学习（MCL）方法与教师模型的相似性分数对齐。MCL确保正负样本对的准确相似性，并自适应处理正负样本的内部差异。我们的范式仅需一个性能合理的小模型，即可帮助大模型实现性能提升。在金融和医疗领域的基准测试及实际应用中的实验证实了其有效性，且该模型已完全部署到在线环境中。

</details>


### [22] [SARA: Selective and Adaptive Retrieval-augmented Generation with Context Compression](https://arxiv.org/abs/2507.05633)
**中文标题：SARA：基于选择性自适应检索增强生成与上下文压缩**

*Yiqiao Jin,Kartik Sharma,Vineeth Rakesh,Yingtong Dou,Menghai Pan,Mahashweta Das,Srijan Kumar*

主要分类: cs.CL

摘要简述: SARA是一个统一的检索增强生成（RAG）框架，通过结合自然语言文本片段和语义压缩向量，解决了上下文长度限制和检索文档冗余问题，显著提升了答案相关性和正确性。


<details>
  <summary>详细信息</summary>
研究动机: 检索增强生成（RAG）虽然通过外部知识扩展了大型语言模型（LLM）的能力，但面临上下文长度受限和检索文档冗余的挑战。纯压缩方法虽减小输入规模，却可能丢失关键细节。SARA旨在平衡局部精度和全局知识覆盖，提升上下文效率和答案准确性。

研究方法: SARA采用两层次上下文表示：1）保留关键实体和数值的细粒度自然语言片段；2）总结高层语义的紧凑可解释向量。通过迭代证据选择模块动态重排上下文，结合文本和压缩表示优化检索效果。

研究结果: 在9个数据集和5个开源LLM（涵盖Mistral、Llama和Gemma）上，SARA显著提升了答案相关性（+17.71）、答案正确性（+13.72）和语义相似性（+15.53）。

研究结论: SARA通过整合文本和压缩表示，证明了其在上下文高效RAG中的重要性，为检索增强生成提供了更稳健的解决方案。

中文摘要: 检索增强生成（RAG）通过外部知识扩展了大型语言模型（LLM），但面临关键挑战：有效上下文长度受限和检索文档冗余。纯压缩方法虽减小输入规模，却常丢失对事实准确性至关重要的细粒度细节。我们提出SARA，一种统一的RAG框架，在严格上下文预算下平衡局部精度和全局知识覆盖。SARA结合自然语言文本片段和语义压缩向量，共同提升上下文效率和答案正确性。它以两个互补层次表示上下文：1）保留关键实体和数值的细粒度自然语言片段；2）总结高层语义的紧凑可解释向量。迭代证据选择模块利用压缩向量动态重排上下文。在涵盖3个模型家族（Mistral、Llama和Gemma）的9个数据集和5个开源LLM上，SARA显著提升了答案相关性（+17.71）、答案正确性（+13.72）和语义相似性（+15.53），证明了整合文本和压缩表示对稳健、上下文高效RAG的重要性。

</details>


### [23] [ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support Issues?](https://arxiv.org/abs/2507.05639)
**中文标题：ECom-Bench：LLM代理能否解决现实世界中的电商客服问题？**

*Haoxin Wang,Xianhan Peng,Xucheng Huang,Yizhe Huang,Ming Gong,Chenghan Yang,Yang Liu,Ling Jiang*

主要分类: cs.CL

摘要简述: 本文介绍了ECom-Bench，首个用于评估具备多模态能力的LLM代理在电商客服领域表现的基准框架，包含基于真实用户互动的动态模拟任务，挑战性极高。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏针对电商客服领域的多模态LLM代理评估标准，亟需一个能够反映真实复杂场景的基准框架，以推动相关研究和模型优化。

研究方法: ECom-Bench基于真实电商对话数据构建任务集，通过动态用户模拟（基于真实用户画像）生成多样化场景，覆盖广泛的业务需求。

研究结果: 实验显示，即使是GPT-4o等先进模型，在ECom-Bench中的通过率仅为10-20%，表明电商复杂场景对LLM代理的挑战性极高。

研究结论: ECom-Bench为电商客服领域的LLM代理研究提供了首个高标准基准，其开源将促进该领域的进一步发展。

中文摘要: 本文介绍了ECom-Bench，首个用于评估具备多模态能力的LLM代理在电商客服领域表现的基准框架。ECom-Bench通过基于真实电商用户互动的动态用户模拟和真实对话数据集构建任务，覆盖多样化的业务场景，具有高度挑战性。例如，即使是GPT-4o等先进模型，在我们的基准测试中通过率仅为10-20%，凸显了复杂电商场景的难度。代码和数据将开源，以推动该领域的进一步研究与发展。

</details>


### [24] [Smoothie-Qwen: Post-Hoc Smoothing to Reduce Language Bias in Multilingual LLMs](https://arxiv.org/abs/2507.05686)
**中文标题：Smoothie-Qwen：一种后处理平滑方法以减少多语言大模型中的语言偏见**

*SeungWon Ji,Jungyup Lee,Jemin Kim,Sang Park,SeungJae Lee*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Smoothie-Qwen的轻量级后处理方法，用于减少多语言大模型中的语言偏见，无需重新训练即可显著降低非目标语言的生成概率。


<details>
  <summary>详细信息</summary>
研究动机: 多语言大模型（LLMs）常出现语言混淆问题，即无论输入提示的语言如何，模型倾向于以主导语言生成响应。这限制了模型的全球适用性。

研究方法: Smoothie-Qwen通过选择性调整标记级输出概率，有效抑制非目标语言的生成。该方法无需重新训练模型，直接应用于现有模型（如Qwen）。

研究结果: 在Qwen模型上应用该方法后，非目标中文输出的减少超过95%，同时保持了多语言基准测试的任务准确性。

研究结论: Smoothie-Qwen提供了一种高效实用的解决方案，显著提升了多语言大模型的语言可控性，使其更适合全球应用。

中文摘要: 多语言大语言模型（LLMs）常表现出语言混淆现象，即无论输入提示的语言如何，模型倾向于以主导语言生成响应。为解决这一问题，我们提出了Smoothie-Qwen，一种轻量级的后处理方法，无需重新训练即可减轻语言偏见。该技术通过选择性调整标记级输出概率，有效抑制非目标语言的生成。在Qwen模型上应用该方法后，非目标中文输出的减少超过95%，同时保持了多语言基准测试的任务准确性。这项工作为提升大语言模型的语言可控性提供了一种实用且高效的解决方案，使其更适合全球应用。

</details>


### [25] [Agentic-R1: Distilled Dual-Strategy Reasoning](https://arxiv.org/abs/2507.05707)
**中文标题：Agentic-R1：蒸馏双策略推理**

*Weihua Du,Pranjal Aggarwal,Sean Welleck,Yiming Yang*

主要分类: cs.CL

摘要简述: 本文提出了一种名为DualDistill的微调框架，通过从多个教师模型中提取互补的推理策略，训练出统一的学生模型Agentic-R1。该模型能动态选择最优策略，在处理算术和算法问题时调用工具，而在抽象问题上采用文本推理，显著提升了多种任务的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前的长链思维模型（long-CoT）在数学推理上表现优异，但依赖缓慢且易出错的自然语言追踪；而工具增强的代理在处理算术问题时表现良好，但在复杂逻辑任务上表现不佳。因此，需要一种能够结合两者优势的方法。

研究方法: 作者提出了DualDistill框架，通过从多个教师模型中提取互补的推理策略，训练出一个统一的学生模型Agentic-R1。该模型能够动态选择最优策略，在处理算术和算法问题时调用工具，而在抽象问题上采用文本推理。

研究结果: 实验表明，Agentic-R1在计算密集型任务和标准基准测试中均表现出更高的准确性，证明了多策略蒸馏在实现鲁棒和高效推理方面的有效性。

研究结论: 通过DualDistill框架训练的Agentic-R1模型，能够动态结合工具调用和文本推理的优势，显著提升了复杂任务的推理能力，为多策略推理提供了新的解决方案。

中文摘要: 当前的长链思维模型（long-CoT）在数学推理上表现出色，但依赖缓慢且易出错的自然语言追踪。工具增强的代理通过代码执行处理算术问题，但在复杂逻辑任务上表现不佳。我们提出了一种名为DualDistill的微调框架，通过从多个教师模型中提取互补的推理策略，训练出一个统一的学生模型Agentic-R1。该模型能够动态选择最优策略，在处理算术和算法问题时调用工具，而在抽象问题上采用文本推理。我们的方法在多种任务上提升了准确性，包括计算密集型任务和标准基准测试，证明了多策略蒸馏在实现鲁棒和高效推理方面的有效性。项目地址：https://github.com/StigLidu/DualDistill

</details>


### [26] [DRAGON: Dynamic RAG Benchmark On News](https://arxiv.org/abs/2507.05713)
**中文标题：DRAGON：新闻动态RAG基准**

*Fedor Chernogorskii,Sergei Averkiev,Liliya Kudraleeva,Zaven Martirosian,Maria Tikhonova,Valentin Malykh,Alena Fenogenova*

主要分类: cs.CL

摘要简述: 本文介绍了DRAGON（动态RAG新闻基准），这是首个针对俄语的动态RAG系统评估基准，基于不断更新的俄语新闻和公共文档，支持对检索器和生成器的全面评估。


<details>
  <summary>详细信息</summary>
研究动机: 现有的RAG基准主要集中在英语，其他语言（如俄语）的评估资源稀缺且静态，无法反映实际部署中的动态变化。因此，需要一种动态基准来填补这一空白。

研究方法: DRAGON基于定期更新的俄语新闻和公共文档构建，通过知识图谱自动生成问题，支持四种核心问题类型。提供了完整的评估框架，包括问题生成管道、评估脚本和基准数据。

研究结果: DRAGON发布了完整的评估框架和公开排行榜，支持社区参与和系统比较，其方法可扩展至其他语言和多语言场景。

研究结论: DRAGON填补了俄语动态RAG评估的空白，为研究社区提供了实用的工具和资源，推动了RAG系统在多语言环境中的发展。

中文摘要: 检索增强生成（RAG）是一种广泛采用的方法，通过在推理时引入外部知识来提高大型语言模型（LLM）的事实性。尽管存在多个英语RAG基准，但其他语言（包括俄语）的评估资源稀缺且静态，无法反映实际部署中的动态变化。
本文提出了DRAGON（新闻动态RAG基准），这是首个针对俄语的动态RAG评估基准，基于不断更新的俄语新闻和公共文档，支持对检索器和生成器的全面评估。问题生成通过基于知识图谱的自动化方法实现，可提取四种核心问题类型。我们发布了完整的评估框架，包括问题生成管道、评估脚本（可扩展至其他语言和多语言场景）和基准数据。同时，我们还推出了公开排行榜，以鼓励社区参与和比较。

</details>


### [27] [HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation](https://arxiv.org/abs/2507.05714)
**中文标题：HIRAG：基于分层思维的检索增强生成指令微调**

*YiHan Jiao,ZheHao Tan,Dan Yang,DuoLin Sun,Jie Feng,Jian Wang,Peng Wei*

主要分类: cs.CL

摘要简述: 本文提出了一种新的检索增强生成（RAG）指令微调方法HIRAG，通过分层思维策略提升模型在开放书考试中的能力，显著改善了多个数据集的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统RAG系统依赖大型语言模型的上下文学习能力，但对RAG生成模型的具体能力研究不足，导致文档质量不一致和检索系统缺陷。现有研究也缺乏对RAG任务的细粒度关注或对思维链的深度利用。

研究方法: HIRAG方法通过分层思维指令微调，要求模型具备三种渐进能力：信息过滤、跨段落语义信息组合以及利用内部知识处理外部知识的RAG特定推理能力。

研究结果: 实验表明，HIRAG训练策略在RGB、PopQA、MuSiQue、HotpotQA和PubmedQA等数据集上显著提升了模型性能。

研究结论: HIRAG通过分层思维策略有效增强了RAG模型的开放书考试能力，为RAG系统的优化提供了新思路。

中文摘要: 检索增强生成（RAG）已成为解决大型语言模型处理实时信息和领域特定问题挑战的基本范式。传统RAG系统主要依赖大型语言模型本身的上下文学习能力，但对RAG生成模型所需的具体能力缺乏深入研究，导致文档质量不一致和检索系统缺陷的问题。即使有限的研究对RAG生成模型进行微调，也往往缺乏对RAG任务的细粒度关注或对思维链过程的深度利用。为此，我们提出RAG模型应具备三种渐进的分层能力：（1）过滤：选择相关信息的能力；（2）组合：跨段落语义信息组合的能力；（3）RAG特定推理：利用内部知识进一步处理外部知识的能力。因此，我们引入了新的RAG指令微调方法——基于分层思维的检索增强生成指令微调（HIRAG），该方法采用“先思考后回答”策略，通过多级渐进思维链增强模型的开放书考试能力。实验表明，HIRAG训练策略在RGB、PopQA、MuSiQue、HotpotQA和PubmedQA等数据集上显著提升了模型性能。

</details>


### [28] [Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition](https://arxiv.org/abs/2507.05724)
**中文标题：Omni-Router：在稀疏专家混合模型中共享路由决策以提升语音识别**

*Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Omni-router Transformer的模型，通过在不同MoE层共享路由器，增强了专家之间的协作与专业化，显著提升了语音识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统MoE方法（如Switch Transformer）在各层独立路由专家，导致专家选择缺乏相关性。本文旨在通过共享路由器增强不同层专家间的协作与专业化。

研究方法: 提出Omni-router Transformer模型，在不同MoE层共享路由器，以增强专家协作与专业化。

研究结果: 实验表明，Omni-router Transformer在训练损失和性能上优于密集模型和Switch Transformer，平均词错误率分别降低11.2%和8.2%，且专家使用更具结构化。

研究结论: Omni-router Transformer通过共享路由器显著提升了语音识别性能，同时增强了专家协作与数据鲁棒性。

中文摘要: 专家混合（MoE）架构已从语言建模扩展到自动语音识别（ASR）。传统MoE方法（如Switch Transformer）在各层独立路由专家。我们的分析表明，大多数层的路由器专家选择与其他层相关性较弱。为增强不同层专家间的协作与专业化，我们在不同MoE层共享路由器，提出Omni-router Transformer模型。在大规模伪标签数据集和10个多样化、跨领域ASR基准测试中，Omni-router Transformer实现了更低的训练损失，并一致优于密集模型和Switch Transformer，平均词错误率分别降低11.2%和8.2%，同时提供结构化的专家使用和更强的数据鲁棒性。

</details>


### [29] [GPTKB v1.5: A Massive Knowledge Base for Exploring Factual LLM Knowledge](https://arxiv.org/abs/2507.05740)
**中文标题：GPTKB v1.5：用于探索事实性LLM知识的大规模知识库**

*Yujia Hu,Tuan-Phong Nguyen,Shrestha Ghosh,Moritz Müller,Simon Razniewski*

主要分类: cs.CL

摘要简述: GPTKB v1.5是一个包含1亿条三元组的知识库，通过GPT-4.1构建，用于探索和分析语言模型的事实知识。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型虽然强大，但其事实知识仍未被充分理解，且缺乏可浏览和统计分析的途径。GPTKB v1.5旨在填补这一空白。

研究方法: 采用GPTKB方法，通过大规模递归的LLM知识物化技术，以1.4万美元的成本从GPT-4.1构建了密集互联的知识库。

研究结果: 构建了一个包含1亿条三元组的知识库，支持基于链接遍历的知识探索、SPARQL查询以及LLM知识的比较分析。

研究结论: 大规模递归的LLM知识物化为系统分析LLM知识和自动化知识库构建提供了突破性机会。

中文摘要: 语言模型是强大的工具，但其事实知识仍未被充分理解，且缺乏即席浏览和可扩展的统计分析途径。本文介绍了GPTKB v1.5，这是一个通过GPT-4.1以1.4万美元成本构建的密集互联的1亿条三元组知识库（KB），采用了GPTKB方法进行大规模递归的LLM知识物化（Hu等人，ACL 2025）。演示体验聚焦于三个用例：（1）基于链接遍历的LLM知识探索，（2）基于SPARQL的结构化LLM知识查询，（3）LLM知识优缺点的比较探索。大规模递归的LLM知识物化为系统分析LLM知识的研究领域以及自动化知识库构建提供了突破性机会。GPTKB演示器可通过https://gptkb.org访问。

</details>


### [30] [DocTalk: Scalable Graph-based Dialogue Synthesis for Enhancing LLM Conversational Capabilities](https://arxiv.org/abs/2507.05750)
**中文标题：DocTalk：基于图的可扩展对话合成方法用于增强大型语言模型的对话能力**

*Jing Yang Lee,Hamed Bonab,Nasser Zalmout,Ming Zeng,Sanket Lokegaonkar,Colin Lockard,Binxuan Huang,Ritesh Sarkhel,Haodong Wang*

主要分类: cs.CL

摘要简述: 本文提出了一种名为DocTalk的新方法，通过将多篇相关文档转化为多轮、多主题的信息寻求对话，生成大规模对话数据，以增强大型语言模型（LLMs）的多轮对话能力。实验表明，使用DocTalk进行预训练可显著提升模型的上下文记忆和理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在多轮对话任务中表现优异，但其预训练数据主要为连续文本，与对话任务的需求存在不匹配。为了解决这一问题，本文提出通过合成对话数据来增强LLMs的多轮对话能力。

研究方法: 本文提出了一种流水线方法，将多篇相关文档转化为多轮、多主题的信息寻求对话。具体而言，通过处理维基百科文章，生成了包含超过73万条长对话的DocTalk数据集。

研究结果: 实验结果表明，使用DocTalk进行预训练可使LLMs的上下文记忆和理解能力提升高达40%，且不影响其基础性能。

研究结论: DocTalk作为一种合成对话数据的方法，有效提升了LLMs在多轮对话任务中的表现，为增强模型对话能力提供了新思路。

中文摘要: 大型语言模型（LLMs）越来越多地用于多轮对话任务，但其预训练数据主要为连续文本，导致所需能力与训练范式之间存在潜在不匹配。为解决这一问题，我们提出了一种从现有文本语料库中合成对话数据的新方法。我们介绍了一种流水线，可将多篇相关文档转化为扩展的多轮、多主题信息寻求对话。通过将此流水线应用于维基百科文章，我们构建了DocTalk，一个包含超过73万条长对话的多轮预训练对话语料库。我们假设在预训练中接触此类合成的对话结构可以增强LLMs的基本多轮能力，如上下文记忆和理解。实验表明，在预训练中引入DocTalk可使上下文记忆和理解能力提升高达40%，且不影响基础性能。DocTalk可在https://huggingface.co/datasets/AmazonScience/DocTalk获取。

</details>


### [31] [Flippi: End To End GenAI Assistant for E-Commerce](https://arxiv.org/abs/2507.05788)
**中文标题：Flippi：面向电商的端到端生成式AI助手**

*Anand A. Rajasekar,Praveen Tangarajan,Anjali Nainani,Amogh Batwal,Vinay Rao Dandin,Anusua Trivedi,Ozan Ersoy*

主要分类: cs.CL

摘要简述: 本文介绍了Flippi，一款基于大语言模型（LLM）的端到端对话助手，专为电商领域设计，通过自然语言对话帮助用户高效发现产品，提供个性化购物体验。


<details>
  <summary>详细信息</summary>
研究动机: 电商平台产品信息庞杂，用户难以高效筛选。Flippi旨在通过自然语言交互解决这一问题，提升用户购物体验。

研究方法: Flippi结合查询重构、意图检测、检索增强生成（RAG）、命名实体识别（NER）和上下文缩减等NLP技术，精准解析用户需求并提供个性化推荐。

研究结果: Flippi显著提升了用户购物效率和满意度，支持比价和产品对比功能，增强了用户决策能力，同时提高了电商平台的转化率。

研究结论: Flippi通过自然语言交互和个性化推荐，为电商领域设定了新的客户满意度和参与度标准。

中文摘要: 对话助手的出现从根本上改变了用户与数字平台的互动方式。本文介绍了Flippi——一款基于大语言模型（LLM）的端到端对话助手，专为电商领域设计。Flippi解决了产品信息庞杂带来的挑战，通过自然语言对话帮助用户更高效地发现产品。通过满足用户的主客观需求，Flippi提供了超越传统搜索方法的个性化购物体验。本文详细描述了Flippi如何解析用户查询以提供精准产品信息，并利用查询重构、意图检测、检索增强生成（RAG）、命名实体识别（NER）和上下文缩减等先进NLP技术。Flippi还能识别并展示电商平台上最具吸引力的优惠，帮助用户做出经济实惠的决策。此外，本文探讨了Flippi的对比分析功能，通过对比产品特性、价格等属性，帮助用户做出明智选择。系统架构设计灵活，支持跨平台集成，并详细介绍了其技术选型以确保性能和准确性。最后，本文提出了全面的评估框架，涵盖性能指标、用户满意度以及对客户参与度和转化率的影响。Flippi将线上购物的便利性与传统实体店的个性化服务相结合，为数字市场的客户满意度和参与度设定了新标准。

</details>


### [32] [Bridging Perception and Language: A Systematic Benchmark for LVLMs' Understanding of Amodal Completion Reports](https://arxiv.org/abs/2507.05799)
**中文标题：连接感知与语言：系统评估LVLMs对模态补全报告的理解能力**

*Amane Watahiki,Tomoki Doi,Taiga Shinozaki,Satoshi Nishida,Takuya Niikawa,Katsunori Miyahara,Hitomi Yanaka*

主要分类: cs.CL

摘要简述: 本文构建了一个基于基本形式本体的基准测试，系统评估大型视觉语言模型（LVLMs）在理解模态补全文本方面的能力，发现部分模型在特定对象类别上表现不佳，且日语提示下存在语言能力缺陷。


<details>
  <summary>详细信息</summary>
研究动机: 研究大型视觉语言模型（LVLMs）在理解模态补全（即感知被遮挡物体）相关文本方面的能力，填补现有研究空白。

研究方法: 基于基本形式本体构建系统分类的模态补全基准测试，评估多种LVLMs在不同对象类别和语言提示（如日语）下的表现。

研究结果: 多数LVLMs整体表现接近人类水平，但在某些对象类别上准确性显著下降，且部分模型在日语提示下表现更差。

研究结论: LVLMs在模态补全文本理解上仍有改进空间，尤其是针对特定对象类别和语言能力。

中文摘要: 开发大型视觉语言模型（LVLMs）的主要目标之一是设计能够协助人类完成多模态任务的系统，包括解释感知体验的描述。在这一背景下，模态补全是一个核心现象，即人们即使物体部分被遮挡也能感知其存在。尽管已有大量研究评估计算机视觉算法能否检测或重建遮挡区域，但LVLMs在模态补全相关文本上的推理能力尚未被探索。为填补这一空白，我们基于基本形式本体构建了一个基准测试，以实现对模态补全的系统分类。结果表明，虽然许多LVLMs整体表现接近人类水平，但在某些被补全对象类别上准确性存在差异。值得注意的是，在某些类别中，部分LLaVA-NeXT变体和Claude 3.5 Sonnet在原始图像上的准确性低于缺乏视觉内容的空白刺激。有趣的是，这种差异仅在日语提示下出现，表明这些模型在日语语言能力上存在不足。

</details>


### [33] [How to Evaluate Automatic Speech Recognition: Comparing Different Performance and Bias Measures](https://arxiv.org/abs/2507.05885)
**中文标题：如何评估自动语音识别：比较不同的性能与偏差度量方法**

*Tanvina Patel,Wiebke Hutiri,Aaron Yi Ding,Odette Scharenborg*

主要分类: cs.CL

摘要简述: 本文比较了不同的性能和偏差度量方法，评估荷兰语端到端自动语音识别（ASR）系统，发现平均错误率不足以全面衡量系统性能，需结合其他指标。


<details>
  <summary>详细信息</summary>
研究动机: 越来越多的证据表明，自动语音识别（ASR）系统对不同说话者或群体（如性别、年龄或口音）存在偏见。目前研究主要集中在检测、量化偏见及缓解方法，但如何衡量系统性能和偏见仍是未解决的问题。

研究方法: 本研究比较了文献中和提出的不同性能与偏差度量方法，用于评估荷兰语端到端ASR系统，并采用多种偏差缓解策略。

研究结果: 实验表明，仅依赖平均错误率（ASR研究中的标准指标）不足以全面评估系统性能，需补充其他指标。

研究结论: 论文建议在报告ASR性能和偏差时，采用更多元化的指标，以更全面地反映系统对不同说话者群体的表现及整体偏差。

中文摘要: 越来越多的证据表明，自动语音识别（ASR）系统对不同说话者或群体（如性别、年龄或口音）存在偏见。目前关于ASR偏见的研究主要集中在检测和量化偏见，以及开发缓解方法。尽管已有进展，但如何衡量系统性能和偏见仍是未解决的问题。本研究比较了文献中和提出的不同性能与偏差度量方法，用于评估荷兰语端到端ASR系统。实验采用多种偏差缓解策略以应对不同说话者群体的偏见。结果表明，仅依赖平均错误率（ASR研究中的标准指标）是不够的，需补充其他指标。论文最后提出了报告ASR性能和偏差的建议，以更全面地反映系统对不同说话者群体的表现及整体偏差。

</details>


### [34] [Psychometric Item Validation Using Virtual Respondents with Trait-Response Mediators](https://arxiv.org/abs/2507.05890)
**中文标题：基于特质-反应中介的虚拟受访者心理测量项目验证**

*Sungjib Lim,Woojung Song,Eun-Ju Lee,Yohan Jo*

主要分类: cs.CL

摘要简述: 本文提出了一种利用大语言模型（LLMs）模拟虚拟受访者的框架，通过考虑中介变量（影响特质与回答之间关系的因素）来高效验证心理测量量表的项目有效性。实验表明，该方法能有效识别高有效性项目，并为低成本量表开发提供了新方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着心理测量量表越来越多地用于评估大语言模型（LLMs）的特质，如何高效生成适合LLMs的量表项目并确保其构念效度成为关键挑战。传统方法依赖大规模人类数据收集，成本高昂。本文旨在通过LLMs模拟虚拟受访者，解决这一问题。

研究方法: 本文提出了一种虚拟受访者模拟框架，通过生成多样化的中介变量（即影响特质与回答之间关系的因素），模拟受访者行为以验证量表项目的有效性。实验基于三种心理特质理论（Big5、Schwartz、VIA），验证了中介生成方法和模拟框架的有效性。

研究结果: 实验结果表明，LLMs能够从特质定义中生成合理的中介变量，并模拟受访者行为以验证项目有效性。该方法成功识别了高有效性项目，为低成本量表开发提供了新工具。

研究结论: 本文提出的框架为心理测量量表的低成本高效开发开辟了新方向，同时深化了对LLMs如何模拟人类行为的理解。数据集和代码将公开以支持未来研究。

中文摘要: 随着心理测量量表越来越多地用于评估大语言模型（LLMs）的特质，适合LLMs的可扩展量表项目生成需求也日益增长。此处的关键挑战是确保生成项目的构念效度，即它们是否真正测量了目标特质。传统方法需要昂贵的大规模人类数据收集。为提高效率，我们提出了一种利用LLMs模拟虚拟受访者的框架。我们的核心思想是考虑中介变量：即特质通过其影响对量表项目回答的多样化因素。通过模拟具有多样化中介变量的受访者，我们识别出能够稳健测量目标特质的量表项目。基于三种心理特质理论（Big5、Schwartz、VIA）的实验表明，我们的中介生成方法和模拟框架能有效识别高有效性项目。LLMs展示了从特质定义生成合理中介变量并模拟受访者行为以验证项目有效性的能力。我们的问题定义、指标、方法和数据集为低成本量表开发和深入理解LLMs如何模拟人类行为开辟了新方向。我们将公开数据集和代码以支持未来研究。

</details>


### [35] [Few-shot text-based emotion detection](https://arxiv.org/abs/2507.05918)
**中文标题：基于少样本文本的情感检测**

*Teodor-George Marchitan,Claudiu Creanga,Liviu P. Dinu*

主要分类: cs.CL

摘要简述: 本文介绍了Unibuc-NLP团队在SemEval 2025 Workshop Task 11中的方法，主要使用大语言模型（Gemini、Qwen、DeepSeek）进行少样本提示或微调，在多标签情感检测任务中取得了不同语言子集的显著成绩。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决SemEval 2025 Workshop Task 11中的文本情感检测问题，特别是在少样本条件下提升多语言情感检测的性能。

研究方法: 团队采用大语言模型（Gemini、Qwen、DeepSeek），结合少样本提示或微调方法，针对多标签情感检测任务进行实验。

研究结果: 在英语子集中，F1-macro得分为0.7546（排名26/96）；葡萄牙语（莫桑比克）子集得分为0.1727（排名35/36）；Emakhuwa子集得分为0.325（排名1/31）。

研究结论: 研究表明，大语言模型在少样本条件下能够有效提升多语言情感检测的性能，尤其在低资源语言中表现突出。

中文摘要: 本文介绍了Unibuc-NLP团队在SemEval 2025 Workshop Task 11中的方法，主要关注使用大语言模型（Gemini、Qwen、DeepSeek）进行少样本提示或微调的实验。最终系统在多标签情感检测任务（Track A）中，英语子集的F1-macro得分为0.7546（排名26/96），葡萄牙语（莫桑比克）子集得分为0.1727（排名35/36），Emakhuwa子集得分为0.325（排名1/31）。

</details>


### [36] [Towards a Principled Evaluation of Knowledge Editors](https://arxiv.org/abs/2507.05937)
**中文标题：迈向知识编辑器的原则性评估**

*Sebastian Pohl,Max Ploner,Alan Akbik*

主要分类: cs.CL

摘要简述: 本文探讨知识编辑器的评估方法，指出当前评估指标和方法的不一致性及其对编辑器排名的影响，同时揭示了基于字符串匹配的评估方法容易产生假阳性匹配的问题。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，知识编辑器的研究受到广泛关注，但评估方法的不一致性和潜在的偏见尚未得到充分研究。本文旨在揭示不同评估指标和方法对编辑器排名的影响，并探讨其对模型整体能力的潜在破坏性影响。

研究方法: 通过分析不同评估指标和方法对知识编辑器排名的影响，并结合语言理解任务的评估，验证评估方法的稳健性。此外，对基于字符串匹配的评估方法进行人工评估，揭示其假阳性匹配的倾向。

研究结果: 研究发现，选择不同的评估指标、方法以及编辑批量大小会导致知识编辑器的排名发生变化。同时，基于字符串匹配的评估方法容易产生假阳性匹配，影响评估的准确性。

研究结论: 本文强调了知识编辑器评估方法的一致性和稳健性的重要性，并呼吁开发更可靠的评估标准以避免偏见和误导性结果。

中文摘要: 近年来，模型编辑受到越来越多的关注。特别是在知识编辑领域，近期发布了更具挑战性的评估数据集，这些数据集使用不同的方法来评分编辑器的成功与否。然而，这些方法的稳健性及其是否不公平地偏向某些编辑器仍未得到充分研究。此外，这些编辑器对模型整体能力的破坏性影响仍是一个盲点。

我们解决了这两个问题，并表明选择不同的指标、评估方法以及编辑批量大小会导致知识编辑器的排名不同。重要的是，我们在知识编辑任务之外的语言理解任务中也验证了这一效应。此外，我们对近期发布的数据集偏爱的基于字符串匹配的评估方法进行了人工评估，揭示了其容易产生假阳性匹配的倾向。

</details>


### [37] [Remember Past, Anticipate Future: Learning Continual Multimodal Misinformation Detectors](https://arxiv.org/abs/2507.05939)
**中文标题：记住过去，预测未来：学习持续多模态虚假信息检测器**

*Bing Wang,Ximing Li,Mengzhe Ye,Changchun Li,Bo Fu,Jianfeng Qu,Lin Yuanbo Wu*

主要分类: cs.CL

摘要简述: 本文提出了一种新的持续多模态虚假信息检测方法DAEDCMD，通过隔离事件特定参数干扰和学习连续时间动态模型，解决过去知识遗忘和未来环境适应问题，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 多模态虚假信息在社交媒体上广泛传播，带来严重负面影响。现有检测方法依赖离线数据，无法适应新事件的持续涌现，导致模型过时且无效。因此，研究在在线数据流下持续学习的多模态虚假信息检测方法成为迫切需求。

研究方法: 提出DAEDCMD方法：1) 使用基于Dirichlet过程的混合专家结构隔离事件特定参数干扰，避免过去知识遗忘；2) 学习连续时间动态模型，预测未来环境分布，提升泛化能力。

研究结果: 实验表明，DAEDCMD在持续多模态虚假信息检测任务中显著优于六种多模态虚假信息检测基线和三种持续学习方法，表现出更强的适应性和稳定性。

研究结论: DAEDCMD通过结合隔离干扰和动态建模，有效解决了持续学习中的知识遗忘和环境适应问题，为多模态虚假信息检测提供了新思路。

中文摘要: 如今，虚假信息文章，尤其是多模态形式，在社交媒体平台上广泛传播并造成严重的负面影响。为控制其传播，多模态虚假信息检测（MMD）成为社区中自动识别虚假信息的活跃课题。以往的MMD方法主要通过收集离线数据监督检测器。然而，在现实场景中，新事件不断涌现，导致基于离线数据训练的MMD模型逐渐过时且无效。为解决这一问题，在在线数据流下训练MMD模型成为一种替代方案，催生了持续MMD这一新兴任务。遗憾的是，该任务面临两大挑战：一是对新数据的训练会持续降低对过去数据的检测性能，称为过去知识遗忘；二是社会环境随时间不断演变，影响对未来数据的泛化能力。为缓解这些挑战，我们提出通过基于Dirichlet过程的混合专家结构隔离事件特定参数的干扰以记住过去知识，并通过学习连续时间动态模型预测未来环境分布。据此，我们提出了一种新的持续MMD方法DAEDCMD。大量实验表明，DAEDCMD能够持续且显著地优于包括六种MMD基线和三种持续学习方法在内的对比方法。

</details>


### [38] [Chat-Ghosting: A Comparative Study of Methods for Auto-Completion in Dialog Systems](https://arxiv.org/abs/2507.05940)
**中文标题：Chat-Ghosting：对话系统中自动补全方法的对比研究**

*Sandeep Mishra,Anubhab Mandal,Bishal Santra,Tushar Abhishek,Pawan Goyal,Manish Gupta*

主要分类: cs.CL

摘要简述: 本文研究了对话系统中的自动补全技术（Chat-Ghosting），比较了深度学习和非深度学习方法的性能，并提出了基于熵的动态早停策略。研究发现，统计n-gram模型和trie结构在已知前缀上表现更优，而神经模型如T5和Phi-2在未知查询上表现更好。对话上下文显著提升了补全质量。


<details>
  <summary>详细信息</summary>
研究动机: 随着ChatGPT等聊天系统的普及，自动补全技术（Ghosting）对提升用户体验至关重要，但相关研究较少，缺乏标准化基准和方法比较。本文旨在填补这一空白，通过公开数据集和多种方法对比，推动该领域的研究。

研究方法: 研究使用了四个公开对话数据集（包括人-人和人-机对话），比较了trie结构、n-gram方法和深度学习方法（如T5和Phi-2）的性能，并提出了一种基于熵的动态早停策略。实验考虑了有无对话上下文的情况。

研究结果: 结果显示，统计n-gram模型和trie结构在已知前缀上表现更优且推理效率更高；神经模型在未知查询上表现更好。对话上下文显著提升了补全质量，尤其在Open-Assistant和ShareGPT数据集上。

研究结论: 本文为Chat-Ghosting提供了全面的性能分析，表明传统方法在已知前缀上更高效，而神经模型在未知查询上更具优势。对话上下文是提升补全质量的关键因素。研究代码和数据已公开。

中文摘要: 自动补全（Ghosting）是现代搜索引擎和聊天界面的重要功能，能够预测用户输入的意图，显著提升用户体验。它尤其适用于打字速度慢、有语言障碍或语言能力有限的用户。尽管聊天系统（如ChatGPT、Copilot等）普遍采用自动补全技术，但相关研究仍较少，缺乏标准化基准和深度学习方法与非深度学习方法的性能对比。为此，我们使用四个公开对话数据集（包括人-人和人-机对话）进行了全面研究，比较了trie结构、n-gram方法和深度学习方法（如T5和Phi-2）的性能，并提出了一种基于熵的动态早停策略。实验发现，统计n-gram模型和trie结构在已知前缀上表现更优且推理效率更高；神经模型在未知查询上表现更好。添加对话上下文显著提升了补全质量，尤其在Open-Assistant和ShareGPT数据集上。研究代码和数据已公开。

</details>


### [39] [OpenFActScore: Open-Source Atomic Evaluation of Factuality in Text Generation](https://arxiv.org/abs/2507.05965)
**中文标题：OpenFActScore：文本生成中事实性的开源原子评估**

*Lucas Fonseca Lage,Simon Ostermann*

主要分类: cs.CL

摘要简述: OpenFActScore是一个开源工具，用于评估大语言模型生成文本的事实性。它通过原子事实生成和验证，支持开源模型，并实现了与闭源系统相近的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的FActScore框架依赖闭源商业模型（如InstructGPT和ChatGPT），限制了透明性和可复现性。OpenFActScore旨在提供一个开源替代方案，支持任何Hugging Face兼容的模型，以促进更开放和低成本的事实性评估。

研究方法: OpenFActScore采用原子事实生成（AFG）提取文本中的独立事实声明，并通过原子事实验证（AFV）利用可信知识源验证这些声明。工具支持开源模型，并优化设计以适配开放模型。

研究结果: 实验表明，开源模型（如Gemma）在AFG和AFV任务上表现接近闭源系统，BERTScore-F1和错误率与人工标注结果高度一致（Pearson相关系数达0.99）。

研究结论: OpenFActScore为文本生成的事实性评估提供了透明、可复现且低成本的解决方案，推动了开源模型在事实性验证领域的应用。

中文摘要: 我们介绍了OpenFActScore，这是FActScore框架的开源实现，用于评估大语言模型（LLM）生成文本的事实性。FActScore通过原子事实生成（AFG）提取独立事实声明，并利用原子事实验证（AFV）基于可信知识源验证每个声明。原版FActScore依赖闭源商业模型（如InstructGPT和ChatGPT），而OpenFActScore支持任何Hugging Face兼容的模型用于AFG和AFV。我们详细介绍了实现的技术细节，包括为支持开源模型所做的设计和修改。我们在原始FActScore基准上评估了多个开源LLM的AFG和AFV性能，报告了AFG的BERTScore-F1和AFV相对于人工标注的错误率。结果显示，开源模型能接近闭源系统的性能，其中Gemma表现最佳，最终配置与原版FActScore实验的Pearson相关系数达0.99。OpenFActScore提升了透明性、可复现性和低成本评估，项目地址：https://github.com/lflage/OpenFActScore。

</details>


### [40] [We Should Evaluate Real-World Impact](https://arxiv.org/abs/2507.05973)
**中文标题：我们应评估现实世界的影响**

*Ehud Reiter*

主要分类: cs.CL

摘要简述: ACL社区对评估NLP系统在现实世界中的影响兴趣寥寥，仅有0.1%的论文涉及此类评估，且多数评估内容简略，更关注指标评估。


<details>
  <summary>详细信息</summary>
研究动机: 本文旨在指出ACL社区对NLP系统在现实世界中影响的评估不足，强调此类评估的重要性以促进技术应用。

研究方法: 通过对ACL Anthology的结构化调查，分析论文中关于现实世界影响评估的内容及其呈现方式。

研究结果: 调查显示，仅有约0.1%的论文包含现实世界影响评估，且多数评估内容简略，重点仍为指标评估。

研究结论: NLP技术若想更具实用性并加速采用，需重视并深入评估其在现实世界中的实际影响。

中文摘要: ACL社区对评估NLP系统在现实世界中的影响兴趣甚微。对ACL Anthology的结构化调查显示，仅有约0.1%的论文包含此类评估；此外，大多数包含影响评估的论文仅以简略方式呈现，而更关注指标评估。如果我们认真尝试理解并评估NLP技术的现实世界影响，它将更具实用性并更快被采用。

</details>


### [41] [RabakBench: Scaling Human Annotations to Construct Localized Multilingual Safety Benchmarks for Low-Resource Languages](https://arxiv.org/abs/2507.05980)
**中文标题：RabakBench：扩展人工标注以构建低资源语言的本地化多语言安全基准测试**

*Gabriel Chua,Leanne Tan,Ziyu Ge,Roy Ka-Wei Lee*

主要分类: cs.CL

摘要简述: 本文介绍了RabakBench，一个针对新加坡多语言环境（包括Singlish、中文、马来语和泰米尔语）构建的多语言安全基准测试。通过可扩展的三阶段流程生成对抗性示例、半自动化标注和高保真翻译，最终数据集包含5000多个安全标注示例。评估显示现有安全分类器性能显著下降，为低资源语言环境提供了本地化安全数据集的构建框架。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）及其安全分类器在低资源语言上表现不佳，主要由于缺乏训练数据和评估基准。本文旨在通过构建本地化的多语言安全基准测试RabakBench，填补这一空白，并支持东南亚多语言环境的安全评估。

研究方法: RabakBench通过三阶段流程构建：(i) 生成：通过LLM驱动的对抗性示例生成增强真实Singlish网络内容；(ii) 标注：使用多数投票的LLM标注器进行半自动化多标签安全标注，并与人类判断对齐；(iii) 翻译：高保真翻译保留语言细微差别和毒性。最终数据集覆盖四种语言和六个细粒度安全类别。

研究结果: RabakBench包含5000多个安全标注示例，覆盖四种语言和六个安全类别。对11种流行的开源和闭源安全分类器的评估显示性能显著下降。数据集和评估代码已公开。

研究结论: RabakBench不仅为东南亚多语言环境提供了强大的安全评估工具，还为低资源语言环境构建本地化安全数据集提供了可复现的框架。

中文摘要: 大型语言模型（LLMs）及其安全分类器在低资源语言上表现不佳，主要由于缺乏训练数据和评估基准。本文介绍了RabakBench，一个针对新加坡独特语言环境（包括Singlish、中文、马来语和泰米尔语）的多语言安全基准测试。RabakBench通过可扩展的三阶段流程构建：(i) 生成：通过LLM驱动的对抗性示例生成增强真实Singlish网络内容；(ii) 标注：使用多数投票的LLM标注器进行半自动化多标签安全标注，并与人类判断对齐；(iii) 翻译：高保真翻译保留语言细微差别和毒性。最终数据集包含5000多个安全标注示例，覆盖四种语言和六个细粒度安全类别及严重程度。对11种流行的开源和闭源安全分类器的评估显示性能显著下降。RabakBench不仅支持东南亚多语言环境的安全评估，还为低资源语言环境构建本地化安全数据集提供了可复现的框架。基准测试数据集（包括人工验证的翻译）和评估代码已公开。

</details>


### [42] [Evolution without Large Models: Training Language Model with Task Principles](https://arxiv.org/abs/2507.05991)
**中文标题：无需大规模模型的语言模型进化：基于任务原则的训练方法**

*Minghang Zhu,Shen Gao,Zhengliang Shi,Jiabao Fang,Pengjie Ren,Zhaochun Ren,Zhumin Chen,Shuo Shang*

主要分类: cs.CL

摘要简述: 本文提出了一种语言模型的自进化方法，通过多级原则生成和基于原则的实例生成，显著降低了训练成本与碳排放，同时提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法依赖大规模语言模型扩展数据集，虽减少人工标注成本，但存在高碳排放和数据泄露风险。本文旨在解决这些问题。

研究方法: 1. 多级原则生成：利用大规模模型从小量任务数据中总结任务完成原则；2. 基于原则的实例生成：小规模模型根据原则生成大量数据用于训练。

研究结果: 实验表明，该方法比直接用小规模模型生成数据显著提升了模型性能，同时大幅减少了碳排放。

研究结论: 提出的自进化方法有效解决了传统训练中的碳排放和数据泄露问题，同时提升了模型性能。

中文摘要: 传统的语言模型训练方法通常利用大规模语言模型扩展人工提供的数据集，从而降低人工标注成本。然而，这种方法在数据增强过程中会产生高碳排放，且使用闭源大规模语言模型时存在数据泄露风险。为解决这些问题，我们提出了一种语言模型的自进化方法。首先，我们引入了多级原则生成，使大规模模型能够基于少量任务数据总结任务完成原则。随后，我们提出了基于原则的实例生成，其中小规模语言模型利用这些原则生成大量数据用于模型训练。实验结果表明，与直接使用小规模模型生成数据相比，我们的方法显著提升了模型性能。此外，由于我们仅使用大规模模型生成任务完成原则，训练过程中的碳排放大幅减少。

</details>


### [43] [DocIE@XLLM25: In-Context Learning for Information Extraction using Fully Synthetic Demonstrations](https://arxiv.org/abs/2507.05997)
**中文标题：DocIE@XLLM25：使用完全合成演示的上下文学习进行信息提取**

*Nicholas Popovič,Ashish Kangen,Tim Schopf,Michael Färber*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大型语言模型（LLM）的完全自动化流程，用于生成合成数据并通过上下文学习进行文档级实体和关系提取，避免了手动标注的需求。


<details>
  <summary>详细信息</summary>
研究动机: 在零样本或少样本设置下，文档级实体和关系提取任务缺乏高质量标注数据，现有方法依赖手动标注或直接零样本推理，限制了其可扩展性和性能。

研究方法: 结合合成数据生成与基于检索的上下文学习，使用推理优化的语言模型构建高质量演示数据库，并在推理时动态检索相关示例。

研究结果: 生成了一个包含5k+维基百科摘要、59k+实体和30k+关系三元组的合成数据集，并在DocIE共享任务中评估了零样本上下文学习性能。

研究结论: 文档级实体和关系的联合提取任务对当前最先进的大型语言模型仍具挑战性，但合成数据与上下文学习的结合为未来研究提供了方向。

中文摘要: 在零样本或少样本设置下，文档级实体和关系提取任务的高质量标注语料仍然稀缺。本文提出了一种完全自动化、基于大型语言模型（LLM）的流程，用于合成数据生成和上下文学习，以完成文档级实体和关系提取任务。与依赖手动标注演示或直接零样本推理的现有方法不同，我们的方法结合了合成数据生成与基于检索的上下文学习，并使用推理优化的语言模型。这使得我们能够无需手动标注即可构建高质量的演示数据库，并在推理时动态检索相关示例。基于此方法，我们生成了一个包含5k+维基百科摘要、59k+实体和30k+关系三元组的合成数据集。最后，我们在DocIE共享任务中评估了零样本上下文学习的性能，从长文档中提取实体和关系。我们发现，即使对于当前最先进的大型语言模型，文档级实体和关系的联合提取任务仍具挑战性。

</details>


### [44] [Conditional Multi-Stage Failure Recovery for Embodied Agents](https://arxiv.org/abs/2507.06016)
**中文标题：具身智能体的条件多阶段失败恢复框架**

*Youmna Farag,Svetlana Stoyanchev,Mohan Li,Simon Keizer,Rama Doddipatla*

主要分类: cs.CL

摘要简述: 本文提出了一种条件多阶段失败恢复框架，用于提升具身智能体在执行复杂任务时的容错能力。通过零样本链式提示和四阶段错误处理机制，该方法在TEACH数据集的TfD基准上取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 具身智能体在执行复杂任务时容易发生执行失败，因此需要高效的失败恢复机制来提升其任务完成能力。

研究方法: 提出了一种条件多阶段失败恢复框架，包含四个错误处理阶段：三个在任务执行中运行，一个作为执行后的反思阶段。该方法利用大语言模型的推理能力，分析环境中的执行挑战并制定策略性解决方案。

研究结果: 在TEACH数据集的TfD基准上，该方法实现了最优性能，比无错误恢复的基线提升了11.5%，并比现有最强模型高出19%。

研究结论: 该条件多阶段失败恢复框架显著提升了具身智能体的任务执行能力，证明了其在复杂任务中的有效性。

中文摘要: 具身智能体在执行复杂任务时容易发生执行失败，因此需要高效的失败恢复机制。本文提出了一种条件多阶段失败恢复框架，采用零样本链式提示技术。该框架分为四个错误处理阶段，其中三个阶段在任务执行中运行，一个阶段作为执行后的反思阶段。我们的方法利用大语言模型的推理能力，分析环境中的执行挑战并制定策略性解决方案。我们在TEACH数据集的TfD基准上评估了该方法，并取得了最优性能，比无错误恢复的基线提升了11.5%，比现有最强模型高出19%。

</details>


### [45] [Entropy-Memorization Law: Evaluating Memorization Difficulty of Data in LLMs](https://arxiv.org/abs/2507.06056)
**中文标题：熵-记忆定律：评估大语言模型中数据的记忆难度**

*Yizhan Huang,Zhe Yang,Meifang Chen,Jianping Zhang,Michael R. Lyu*

主要分类: cs.CL

摘要简述: 本文提出熵-记忆定律，揭示数据熵与LLMs记忆分数之间的线性关系，并通过实验验证其在区分训练与测试数据中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 研究大语言模型（LLMs）记忆训练数据的机制，探索如何量化数据的记忆难度，为理解和优化模型记忆行为提供理论基础。

研究方法: 通过OLMo系列开源模型的实证实验，提出熵-记忆定律，分析数据熵与记忆分数的关系，并以随机字符串为例验证其有效性。

研究结果: 发现数据熵与记忆分数呈线性相关，随机字符串的熵低于预期，基于此定律可有效区分训练与测试数据。

研究结论: 熵-记忆定律为量化LLMs记忆难度提供了新视角，并支持数据集推断（DI）的实际应用。

中文摘要: 大语言模型（LLMs）已知会记忆部分训练数据，有时在适当提示下逐字复现内容。本研究探讨了记忆领域一个基础但未充分研究的问题：如何量化LLMs中训练数据的记忆难度？通过对开源模型OLMo系列的实证实验，我们提出了熵-记忆定律，表明数据熵与记忆分数呈线性相关。此外，在以高度随机字符串（“无意义序列”）为例的案例研究中，我们发现这些序列尽管看似随机，但其经验熵却意外低于整体训练语料。基于熵-记忆定律的相同策略，我们提出了一种简单有效的方法来区分训练与测试数据，实现了数据集推断（DI）。

</details>


### [46] [A Survey on Prompt Tuning](https://arxiv.org/abs/2507.06085)
**中文标题：提示调优综述**

*Zongqian Li,Yixuan Su,Nigel Collier*

主要分类: cs.CL

摘要简述: 本文综述了提示调优（prompt tuning）这一参数高效的方法，通过添加可训练的连续向量来适配语言模型，同时保持模型冻结。将现有方法分为直接提示学习和迁移学习两类，分析了各类方法的设计、创新、优缺点，并探讨了计算效率和训练稳定性等挑战及未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型的普及，如何高效适配这些模型成为研究热点。提示调优作为一种参数高效的方法，能够在不改变模型参数的情况下提升性能，因此值得系统梳理和总结。

研究方法: 将现有提示调优方法分为直接提示学习和迁移学习两大类。直接提示学习包括通用优化方法、基于编码器的方法、分解策略和专家混合框架；迁移学习包括通用迁移方法、基于编码器的方法和分解策略。通过可视化对比分析各类方法的设计和创新。

研究结果: 总结了各类提示调优方法的优缺点，揭示了计算效率和训练稳定性方面的挑战，并提出了未来改进训练鲁棒性和扩展应用范围的潜在方向。

研究结论: 提示调优是一种高效的适配方法，但仍需解决计算效率和训练稳定性问题。未来研究应关注提升鲁棒性和扩展应用场景。

中文摘要: 本文综述了提示调优，这是一种通过添加可训练的连续向量来适配语言模型的高效方法，同时保持模型冻结。我们将现有方法分为两类：直接提示学习和迁移学习。直接提示学习方法包括：通用优化方法、基于编码器的方法、分解策略和专家混合框架。迁移学习方法包括：通用迁移方法、基于编码器的方法和分解策略。针对每种方法，我们分析了其设计、创新、见解、优缺点，并通过可视化比较了不同框架。我们指出了计算效率和训练稳定性方面的挑战，并探讨了未来在提升训练鲁棒性和扩展应用范围方面的方向。

</details>


### [47] [NeoBabel: A Multilingual Open Tower for Visual Generation](https://arxiv.org/abs/2507.06137)
**中文标题：NeoBabel：一种多语言开放的视觉生成塔**

*Mohammad Mahdi Derakhshani,Dheeraj Varghese,Marzieh Fadaee,Cees G. M. Snoek*

主要分类: cs.CL

摘要简述: NeoBabel是一种新型多语言图像生成框架，支持六种语言，通过多语言预训练和高分辨率指令调优，在多语言基准测试中表现优异，同时保持高效的性能和小型化设计。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到图像生成技术以英语为中心，导致非英语用户面临障碍和数字不平等。现有系统依赖翻译流程，但会引入语义漂移、计算开销和文化偏差。NeoBabel旨在解决这些问题，提供高效、包容的多语言图像生成方案。

研究方法: NeoBabel结合大规模多语言预训练和高分辨率指令调优进行训练。扩展了两个英语基准测试为多语言版本（m-GenEval和m-DPG），并引入新指标评估多语言对齐和代码混合提示的鲁棒性。

研究结果: NeoBabel在多语言基准测试中表现优异（m-GenEval得分0.75，m-DPG得分0.68），优于其他多语言基础模型，同时模型体积小2-4倍。

研究结论: NeoBabel证明多语言能力不是性能的妥协，而是提升生成AI鲁棒性、效率和文化保真度的催化剂。研究团队开源了工具包，推动包容性AI研究。

中文摘要: 文本到图像生成的进展主要以英语为中心，为非英语用户设置了障碍并加剧了数字不平等。现有系统依赖翻译流程，但会引入语义漂移、计算开销和文化偏差。我们提出了NeoBabel，一种新型多语言图像生成框架，支持六种语言（英语、中文、荷兰语、法语、印地语和波斯语），在性能、效率和包容性上设定了新的帕累托前沿。模型通过大规模多语言预训练和高分辨率指令调优训练。为评估其能力，我们将两个英语基准测试扩展为多语言版本：m-GenEval和m-DPG。NeoBabel在多语言任务中表现优异（m-GenEval得分0.75，m-DPG得分0.68），同时保持强大的英语能力。值得注意的是，它在英语任务中与领先模型表现相当，而在多语言基准测试中优于它们（分别提升0.11和0.09），尽管这些模型基于多语言基础LLM。这证明了我们针对性对齐训练在保持和扩展跨语言泛化方面的有效性。我们还引入了两个新指标，严格评估多语言对齐和对代码混合提示的鲁棒性。NeoBabel与仅支持英语的模型表现相当或更优，同时体积小2-4倍。我们开源了工具包，包括所有代码、模型检查点、124M多语言文本-图像对数据集和标准化多语言评估协议，以推动包容性AI研究。我们的工作表明，多语言能力不是妥协，而是提升生成AI鲁棒性、效率和文化保真度的催化剂。

</details>


### [48] [Coding Triangle: How Does Large Language Model Understand Code?](https://arxiv.org/abs/2507.06138)
**中文标题：代码三角：大语言模型如何理解代码？**

*Taolin Zhang,Zihan Ma,Maosong Cao,Junnan Liu,Songyang Zhang,Kai Chen*

主要分类: cs.CL

摘要简述: 本文提出Code Triangle框架，系统评估大语言模型（LLMs）在代码生成中的表现，发现其虽能形成自洽系统，但缺乏人类程序员的多样性和鲁棒性。通过结合人类生成的内容和模型混合，可显著提升LLMs的性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在代码生成方面取得显著进展，但其真实的编程能力仍未充分探索。本文旨在通过系统评估，揭示LLMs在代码理解上的局限性和改进方向。

研究方法: 提出Code Triangle框架，从编辑分析、代码实现和测试用例生成三个维度评估LLMs。在竞争性编程基准上进行广泛实验，分析模型的表现和错误模式。

研究结果: 实验表明，LLMs能形成自洽系统，但解决方案缺乏多样性和鲁棒性。模型错误因训练数据偏差和推理迁移受限而集中。结合人类生成内容和模型混合可显著提升性能。

研究结论: LLMs在代码理解上存在一致性与不一致性，为自我反思和改进提供方向。结合人类输入和模型混合是提升LLMs编程能力的有效途径。

中文摘要: 大语言模型（LLMs）在代码生成方面取得了显著进展，但其真实的编程能力仍未被充分探索。我们提出了Code Triangle框架，从编辑分析、代码实现和测试用例生成三个维度系统评估LLMs。通过在竞争性编程基准上的广泛实验，我们发现LLMs能在这三个维度上形成自洽系统，但其解决方案往往缺乏人类程序员的多样性和鲁棒性。我们揭示了模型认知与人类专业知识之间的显著分布偏移，模型错误因训练数据偏差和有限的推理迁移而集中。研究表明，结合人类生成的编辑内容、解决方案和多样化测试用例，以及利用模型混合，可显著提升LLMs的性能和鲁棒性。此外，我们揭示了LLMs认知中的一致性与不一致性，这可能促进自我反思和改进，为开发更强大的代码模型提供了潜在方向。

</details>


### [49] [Skywork-R1V3 Technical Report](https://arxiv.org/abs/2507.06167)
**中文标题：Skywork-R1V3技术报告**

*Wei Shen,Jiangbo Pei,Yi Peng,Xuchen Song,Yang Liu,Jian Peng,Haofeng Sun,Yunzhuo Hao,Peiyu Wang,Yahui Zhou*

主要分类: cs.CL

摘要简述: Skywork-R1V3是一种先进的、开源的视觉语言模型（VLM），通过创新的后训练强化学习框架，成功将纯文本大型语言模型（LLM）的推理能力迁移到视觉任务中，显著提升了多模态推理性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索如何将纯文本大型语言模型的推理能力有效迁移到视觉任务中，以提升多模态推理模型的性能，并推动开源视觉语言模型的发展。

研究方法: 采用后训练强化学习框架，激活和增强模型的推理能力，无需额外的预训练；提出关键推理标记的熵作为推理能力的指标，用于强化学习训练中的检查点选择；分析课程学习和强化微调策略。

研究结果: Skywork-R1V3在MMMU基准测试中取得76.0%的准确率，显著优于之前的64.3%，达到人类入门水平；38B参数模型性能媲美顶级闭源VLM；成功将数学推理能力迁移到其他学科推理任务。

研究结论: Skywork-R1V3在多模态推理领域取得重大突破，展示了强化学习在提升开源视觉语言模型能力方面的强大潜力。

中文摘要: 我们介绍了Skywork-R1V3，一种先进的、开源的视觉语言模型（VLM），开创了视觉推理的新方法。其核心创新在于将纯文本大型语言模型（LLM）的推理能力有效迁移到视觉任务中。Skywork-R1V3的卓越性能主要源于我们精心设计的后训练强化学习框架，该框架无需额外的持续预训练即可激活和增强模型的推理能力。通过这一框架，我们进一步揭示了连接器模块在多模态推理模型中实现稳健跨模态对齐的基础作用。此外，我们提出了一种独特的推理能力指标——关键推理标记的熵，该指标在强化学习训练中的检查点选择中表现出色。Skywork-R1V3在MMMU基准测试中取得了76.0%的准确率，显著优于之前的64.3%，达到了人类入门水平。值得注意的是，我们的强化学习后训练方法甚至使38B参数模型能够媲美顶级闭源VLM。该实现成功将数学推理能力迁移到其他学科相关的推理任务中。我们还分析了课程学习和强化微调策略，并对多模态推理进行了更广泛的讨论。Skywork-R1V3代表了多模态推理领域的重大飞跃，展示了强化学习作为推动开源VLM能力发展的强大引擎。

</details>


### [50] [CriticLean: Critic-Guided Reinforcement Learning for Mathematical Formalization](https://arxiv.org/abs/2507.06181)
**中文标题：CriticLean：基于批评者引导的强化学习数学形式化方法**

*Zhongyuan Peng,Yifan Yao,Kaijing Ma,Shuyue Guo,Yizhe Li,Yichi Zhang,Chenchen Zhang,Yifan Zhang,Zhouliang Yu,Luming Li,Minghao Liu,Yihang Xia,Jiawei Shen,Yuchen Wu,Yixin Cao,Zhaoxiang Zhang,Wenhao Huang,Jiaheng Liu,Ge Zhang*

主要分类: cs.CL

摘要简述: 本文提出CriticLean框架，通过强化学习将批评者从被动验证者提升为主动学习组件，显著提升数学形式化的语义准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多关注数学陈述的形式化生成和编译，而忽略了批评阶段对语义意图的验证。本文旨在优化批评阶段，确保生成的形式化代码准确反映原始问题的语义。

研究方法: 提出CriticLean框架，包括CriticLeanGPT（通过监督微调和强化学习训练）和CriticLeanBench（用于评估模型区分语义正确性的能力）。构建FineLeanCorpus数据集，包含28.5万问题，涵盖多样领域和难度。

研究结果: CriticLeanGPT在语义准确性上显著优于开源和闭源基线模型，FineLeanCorpus数据集通过人工评估验证了高质量和多样性。

研究结论: 优化批评阶段对生成可靠的形式化至关重要，CriticLean为形式化数学推理的未来发展提供了重要见解。

中文摘要: 将自然语言数学陈述转化为可执行的形式化代码是自动定理证明中的核心挑战。以往研究多关注生成和编译的成功，而忽略了批评阶段——即评估生成的形式化是否真正捕捉了原始问题的语义意图。本文提出CriticLean，一种新颖的批评者引导强化学习框架，将批评者从被动验证者提升为主动学习组件。具体而言，首先提出CriticLeanGPT，通过监督微调和强化学习训练，严格评估Lean 4形式化的语义保真度。其次，引入CriticLeanBench基准，用于衡量模型区分语义正确与错误形式化的能力，并证明训练的CriticLeanGPT模型显著优于开源和闭源基线。基于CriticLean框架，构建FineLeanCorpus数据集，包含超过28.5万问题，涵盖丰富领域多样性、广泛难度范围，并通过人工评估验证其高正确性。总体而言，研究结果表明优化批评阶段对生成可靠形式化至关重要，CriticLean将为形式化数学推理的未来发展提供宝贵见解。

</details>


### [51] [DS@GT at CheckThat! 2025: Detecting Subjectivity via Transfer-Learning and Corrective Data Augmentation](https://arxiv.org/abs/2507.06189)
**中文标题：DS@GT在CheckThat! 2025：通过迁移学习和校正数据增强检测主观性**

*Maximilian Heil,Dionne Bang*

主要分类: cs.CL

摘要简述: 本文介绍了在CLEF 2025的CheckThat!实验室任务1（主观性检测）中的提交成果，研究了迁移学习和风格数据增强在英语新闻文本中主观与客观句子分类中的效果。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索如何通过迁移学习和数据增强技术提升英语新闻文本中主观性检测的准确性，尤其是在预训练模型和生成式数据增强的结合方面。

研究方法: 方法包括对比预训练编码器的微调与迁移学习，以及使用GPT-4o生成特定主观性风格的改写样本，并通过同一模型校正以确保标签和风格一致性。

研究结果: 结果表明，特定编码器的迁移学习优于通用编码器的微调，且经过精心设计的数据增强显著提升了模型鲁棒性，尤其是在主观内容检测方面。官方提交结果在24名参与者中排名第16。

研究结论: 研究强调了结合编码器专业化和标签一致性数据增强对提升主观性检测效果的价值，并公开了代码。

中文摘要: 本文介绍了我们在CLEF 2025的CheckThat!实验室任务1（主观性检测）中的提交成果。我们研究了迁移学习和风格数据增强在英语新闻文本中主观与客观句子分类中的效果。我们的方法对比了预训练编码器的微调与迁移学习，并引入了一个使用GPT-4o生成特定主观性风格改写的控制增强流程。为确保标签和风格一致性，我们使用同一模型对生成的样本进行校正和优化。结果显示，特定编码器的迁移学习优于通用编码器的微调，且经过精心设计的数据增强显著提升了模型鲁棒性，尤其是在主观内容检测方面。我们的官方提交在24名参与者中排名第16。总体而言，研究结果强调了结合编码器专业化和标签一致性数据增强对提升主观性检测效果的价值。代码已公开：https://github.com/dsgt-arc/checkthat-2025-subject。

</details>


### [52] [DS@GT at CheckThat! 2025: Evaluating Context and Tokenization Strategies for Numerical Fact Verification](https://arxiv.org/abs/2507.06195)
**中文标题：DS@GT在CheckThat! 2025：评估数值事实验证中的上下文和分词策略**

*Maximilian Heil,Aleksandar Pramov*

主要分类: cs.CL

摘要简述: 本文研究了数值事实验证中的上下文和分词策略，发现右到左分词和长上下文窗口对性能提升有限，证据质量是关键瓶颈。最佳系统在CheckThat! 2025任务3中排名前四。


<details>
  <summary>详细信息</summary>
研究动机: 数值声明（如数量、比较和时间引用）对自动化事实核查系统提出了独特挑战。本研究旨在评估此类声明的真实性预测策略，重点关注上下文和分词方法的影响。

研究方法: 使用QuanTemp数据集和自建证据检索管道，评估了三种策略：(1) 长上下文窗口对ModernBERT的影响，(2) 右到左分词的效果，(3) 两者的组合对分类性能的影响。

研究结果: 右到左分词未提升自然语言推理性能，长上下文窗口也未显著改善真实性预测。最佳系统在任务3中取得0.57的宏平均F1分数，位列前四。

研究结论: 证据质量是数值事实验证的主要瓶颈，右到左分词和长上下文窗口效果有限。未来研究需聚焦证据质量优化。

中文摘要: 数值声明（涉及数量、比较和时间引用）对自动化事实核查系统提出了独特挑战。本研究使用QuanTemp数据集和自建证据检索管道，评估了此类声明的真实性预测策略。我们研究了三个关键因素：(1) 使用ModernBERT时更长输入上下文窗口的影响，(2) 右到左分词的效果，(3) 两者对分类性能的综合影响。与算术推理任务中的先前发现相反，右到左分词未提升自然语言推理性能，长上下文窗口也未改善真实性预测，表明证据质量是主要瓶颈。我们的最佳系统在CheckThat! 2025任务3中取得0.57的宏平均F1分数，位列前四。代码发布于https://github.com/dsgt-arc/checkthat-2025-numerical。

</details>


### [53] [UQLM: A Python Package for Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2507.06196)
**中文标题：UQLM：用于大语言模型不确定性量化的Python工具包**

*Dylan Bouchard,Mohit Singh Chauhan,David Skarbrevik,Ho-Kyeong Ra,Viren Bajaj,Zeya Ahmad*

主要分类: cs.CL

摘要简述: UQLM是一个Python工具包，用于检测大语言模型（LLM）的幻觉问题，通过先进的量化不确定性技术提供置信度评分，提升模型输出的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）生成的虚假或误导性内容（即幻觉）对下游应用的安全性和可信度构成挑战，亟需一种高效检测方法。

研究方法: UQLM采用量化不确定性（UQ）技术，提供一套基于UQ的评分器，计算0到1的响应级置信度分数，实现即插即用的幻觉检测。

研究结果: UQLM成功开发为一个可直接使用的工具包，能够量化LLM输出的不确定性，帮助用户识别并减少幻觉问题。

研究结论: UQLM为LLM幻觉检测提供了实用且高效的解决方案，显著提升了模型输出的可信度和安全性。

中文摘要: 幻觉（即大语言模型生成虚假或误导性内容）对下游应用的安全性和信任构成重大挑战。我们推出UQLM，一个基于先进量化不确定性（UQ）技术的Python工具包，用于检测LLM幻觉。该工具包提供一套基于UQ的评分器，可计算0到1的响应级置信度分数，为UQ-based幻觉检测提供即用解决方案，轻松集成以提升LLM输出的可靠性。

</details>


### [54] [A Survey on Latent Reasoning](https://arxiv.org/abs/2507.06203)
**中文标题：潜在推理研究综述**

*Rui-Jie Zhu,Tianhao Peng,Tianhao Cheng,Xingwei Qu,Jinfa Huang,Dawei Zhu,Hao Wang,Kaiwen Xue,Xuanliang Zhang,Yong Shan,Tianle Cai,Taylor Kergan,Assel Kembay,Andrew Smith,Chenghua Lin,Binh Nguyen,Yuqi Pan,Yuhong Chou,Zefan Cai,Zhenhe Wu,Yongchi Zhao,Tianyu Liu,Jian Yang,Wangchunshu Zhou,Chujie Zheng,Chongxuan Li,Yuyin Zhou,Zhoujun Li,Zhaoxiang Zhang,Jiaheng Liu,Ge Zhang,Wenhao Huang,Jason Eshraghian*

主要分类: cs.CL

摘要简述: 本文综述了潜在推理领域的研究进展，探讨了大型语言模型（LLMs）通过隐藏状态进行多步推理的方法，提出了多种潜在推理技术，并展望了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 尽管显式思维链（CoT）推理提升了大型语言模型的可解释性和准确性，但其依赖自然语言的特性限制了模型的表达能力。潜在推理通过隐藏状态进行多步推理，解决了这一瓶颈，推动了更高效的推理方法研究。

研究方法: 本文首先分析了神经网络层作为推理计算基础的作用，探讨了层次化表示如何支持复杂转换。随后，综述了多种潜在推理方法，包括基于激活的递归、隐藏状态传播以及通过微调策略压缩或内化显式推理轨迹。最后，讨论了高级范式，如通过掩码扩散模型实现无限深度潜在推理。

研究结果: 本文系统梳理了潜在推理的研究现状，提出了多种技术方法，并展示了其在提升推理效率和一致性方面的潜力。

研究结论: 通过整合潜在推理的多种视角，本文明确了该领域的概念框架，并为未来大型语言模型认知研究指明了方向。

中文摘要: 大型语言模型（LLMs）展现了强大的推理能力，尤其是在显式思维链（CoT）推理的引导下，通过语言化中间步骤显著提升了可解释性和准确性。然而，CoT依赖自然语言推理的特性限制了模型的表达带宽。潜在推理通过完全在模型的连续隐藏状态中进行多步推理，消除了对词级监督的依赖，从而解决了这一瓶颈。为推进潜在推理研究，本文对这一新兴领域进行了全面综述。首先探讨了神经网络层作为推理计算基础的作用，强调了层次化表示如何支持复杂转换。接着，研究了多种潜在推理方法，包括基于激活的递归、隐藏状态传播以及通过微调策略压缩或内化显式推理轨迹。最后，讨论了高级范式，如通过掩码扩散模型实现无限深度潜在推理，从而实现全局一致且可逆的推理过程。通过整合这些视角，本文旨在澄清潜在推理的概念框架，并为LLM认知前沿研究指明未来方向。相关GitHub仓库收集了最新论文和代码资源，地址为：https://github.com/multimodal-art-projection/LatentCoT-Horizon/。

</details>


### [55] [DS@GT at CheckThat! 2025: Ensemble Methods for Detection of Scientific Discourse on Social Media](https://arxiv.org/abs/2507.06205)
**中文标题：DS@GT在CheckThat! 2025：社交媒体科学话语检测的集成方法**

*Ayush Parikh,Hoang Thanh Thanh Truong,Jeanette Schofield,Maximilian Heil*

主要分类: cs.CL

摘要简述: 本文介绍了DS@GT团队在CLEF 2025 CheckThat!任务4a中探索的科学社交媒体内容检测方法，通过三种建模方法（Transformer微调、LLM少样本提示和集成模型）提升分类性能，最终在比赛中排名第七。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决社交媒体中科学内容（如科学主张、研究引用或科学实体提及）的多类别分类问题，以提升科学信息的识别准确性。

研究方法: 采用了三种方法：1. Transformer模型的微调；2. 大型语言模型（LLM）的少样本提示；3. 基于实验结果的集成模型设计。

研究结果: 团队在比赛中排名第七，宏平均F1得分为0.8611，优于DeBERTaV3基线的0.8375。

研究结论: 集成模型在科学社交媒体内容检测任务中表现优异，未来可进一步优化模型设计以提升性能。

中文摘要: 本文介绍了DS@GT团队在CLEF 2025 CheckThat!任务4a（科学网络话语检测）中探索的方法。该任务是一个多类别分类问题，旨在判断推文是否包含科学主张、科学研究或出版物的引用，以及科学实体（如大学或科学家）的提及。我们提出了三种建模方法：Transformer微调、LLM的少样本提示，以及基于早期实验设计的集成模型。团队在比赛中排名第七，宏平均F1得分为0.8611，优于DeBERTaV3基线的0.8375。代码已开源在Github：https://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4a。

</details>


### [56] [Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers](https://arxiv.org/abs/2507.06223)
**中文标题：基于大语言模型的重新排序器的效率-效果权衡FLOPs评估**

*Zhiyuan Peng,Ting-ruen Wei,Tingyu Song,Yilun Zhao,Yi Fang*

主要分类: cs.CL

摘要简述: 本文提出E²R-FLOPs指标，用于评估基于大语言模型（LLM）的重新排序器的效率与效果权衡，并设计了一个可解释的FLOPs估算器，无需实验即可估算计算量。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究使用延迟、前向传递次数等代理指标评估LLM重新排序器的效率，但这些指标依赖硬件和运行时选择，难以反映模型规模，导致效率与效果权衡评估不清晰。

研究方法: 提出E²R-FLOPs指标：RPP（每PetaFLOP的排序指标）衡量相关性计算效率，QPP（每PetaFLOP的查询数）衡量硬件无关吞吐量，并设计FLOPs估算器。

研究结果: 通过实验评估多种架构的LLM重新排序器，揭示了效率与效果的权衡关系，为研究社区提供了新的评估视角。

研究结论: E²R-FLOPs为LLM重新排序器的效率与效果评估提供了标准化指标，有助于推动该领域的进一步发展。

中文摘要: 大语言模型（LLM）最近被应用于信息检索的重新排序任务，表现出色。然而，其高计算需求常阻碍实际部署。现有研究使用延迟、前向传递次数、输入输出令牌数等代理指标评估LLM重新排序器的效率，但这些指标依赖硬件和运行时选择（如是否并行、批量大小等），且未考虑模型规模，导致评估难以解释且效率与效果权衡不明确。为解决此问题，我们提出E²R-FLOPs指标：RPP（每PetaFLOP的排序指标）衡量相关性计算效率，QPP（每PetaFLOP的查询数）衡量硬件无关吞吐量。同时，设计了一个可解释的FLOPs估算器，无需实验即可估算LLM重新排序器的计算量。基于新指标，我们通过实验评估多种架构的LLM重新排序器，研究效率与效果权衡，并将此问题引入研究社区的视野。

</details>


### [57] [Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving](https://arxiv.org/abs/2507.06229)
**中文标题：Agent KB：利用跨领域经验实现代理化问题解决**

*Xiangru Tang,Tianrui Qin,Tianhao Peng,Ziyang Zhou,Daniel Shao,Tingting Du,Xinming Wei,Peng Xia,Fang Wu,He Zhu,Ge Zhang,Jiaheng Liu,Xingyao Wang,Sirui Hong,Chenglin Wu,Hao Cheng,Chi Wang,Wangchunshu Zhou*

主要分类: cs.CL

摘要简述: Agent KB 是一个分层经验框架，通过“推理-检索-优化”流程解决跨领域任务中的错误修正和经验复用问题，显著提升了语言代理的复杂问题解决能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言代理在复杂任务中难以有效修正错误并跨领域复用经验，Agent KB 旨在解决这一核心限制，使代理能够从彼此的经验中学习。

研究方法: Agent KB 采用分层经验框架，通过“推理-检索-优化”流程捕获高层策略和详细执行日志，构建共享知识库以实现跨代理知识迁移。

研究结果: 在 GAIA 基准测试中，Agent KB 将成功率提升高达 16.28 个百分点。Claude-3 和 GPT-4 在最具挑战性任务中分别从 38.46% 提升至 57.69% 和从 53.49% 提升至 73.26%。在 SWE-bench 代码修复任务中，Claude-3 从 41.33% 提升至 53.33%。

研究结论: Agent KB 提供了一个模块化、框架无关的基础设施，使代理能够从历史经验中学习，并将成功策略泛化至新任务。

中文摘要: 随着语言代理处理的任务日益复杂，它们在跨领域错误修正和经验复用方面面临挑战。我们提出了 Agent KB，一种分层经验框架，通过新颖的“推理-检索-优化”流程实现复杂代理化问题解决。Agent KB 解决了一个核心限制：传统代理无法从彼此的经验中学习。通过捕获高层策略和详细执行日志，Agent KB 构建了一个共享知识库，支持跨代理知识迁移。在 GAIA 基准测试中，Agent KB 将成功率提升高达 16.28 个百分点。在最具挑战性任务中，Claude-3 从 38.46% 提升至 57.69%，而 GPT-4 在中等难度任务中从 53.49% 提升至 73.26%。在 SWE-bench 代码修复任务中，Agent KB 使 Claude-3 从 41.33% 提升至 53.33%。结果表明，Agent KB 提供了一个模块化、框架无关的基础设施，使代理能够从历史经验中学习，并将成功策略泛化至新任务。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [58] [Structured Captions Improve Prompt Adherence in Text-to-Image Models (Re-LAION-Caption 19M)](https://arxiv.org/abs/2507.05300)
**中文标题：结构化标注提升文本到图像模型的提示遵循能力（Re-LAION-Caption 19M）**

*Nicholas Merchant,Haitz Sáez de Ocáriz Borde,Andrei Cristian Popescu,Carlos Garcia Jurado Suarez*

主要分类: cs.CV

摘要简述: 本文提出结构化标注（Re-LAION-Caption 19M）可显著提升文本到图像模型的提示遵循能力，通过四部分模板（主题、场景、美学、相机细节）生成高质量标注，实验证明结构化标注能提高文本-图像对齐分数。


<details>
  <summary>详细信息</summary>
研究动机: 生成式文本到图像模型常因大规模数据集（如LAION-5B）的噪声和非结构化问题导致提示遵循能力差，用户需依赖复杂的提示工程。本文旨在通过结构化标注提升模型的可控性和对齐性。

研究方法: 从Re-LAION-5B中提取19M张1024x1024图像，使用Mistral 7B Instruct-based LLaVA-Next模型生成四部分结构化标注（主题、场景、美学、相机细节）。对PixArt-Σ和Stable Diffusion 2进行微调，对比结构化与随机打乱标注的效果。

研究结果: 实验表明，结构化标注版本在视觉问答（VQA）模型中始终获得更高的文本-图像对齐分数，验证了结构化标注的有效性。

研究结论: 结构化标注能显著提升文本到图像模型的提示遵循能力，为模型训练提供了一种高效的数据优化方法。

中文摘要: 本文指出，生成式文本到图像模型常因LAION-5B等大规模数据集的噪声和非结构化问题而难以遵循提示，用户需依赖复杂的提示工程。为此，我们提出在训练中强制使用一致的标注结构可显著提升模型的可控性和对齐性。我们发布了Re-LAION-Caption 19M，这是Re-LAION-5B的高质量子集，包含19M张1024x1024图像，其标注由基于Mistral 7B Instruct的LLaVA-Next模型生成，每一条标注均遵循四部分模板：主题、场景、美学和相机细节。我们使用结构化和随机打乱的标注分别微调PixArt-Σ和Stable Diffusion 2，结果显示结构化标注版本在视觉问答（VQA）模型中始终获得更高的文本-图像对齐分数。数据集已公开于https://huggingface.co/datasets/supermodelresearch/Re-LAION-Caption19M。

</details>


### [59] [CorrDetail: Visual Detail Enhanced Self-Correction for Face Forgery Detection](https://arxiv.org/abs/2507.05302)
**中文标题：CorrDetail：用于人脸伪造检测的视觉细节增强自校正框架**

*Binjia Zhou,Hengrui Lou,Lizhe Chen,Haoyuan Li,Dawei Luo,Shuai Chen,Jie Lei,Zunlei Feng,Yijun Bei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CorrDetail的视觉细节增强自校正框架，用于可解释的人脸伪造检测，通过错误引导问题和视觉细粒度细节增强模块，显著提升了伪造细节的识别能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着图像生成技术的快速发展，人脸深度伪造的广泛出现对安全领域提出了重大挑战。现有的伪造检测方法存在细节解释不清或易产生幻觉的问题，亟需一种更可靠且可解释的检测框架。

研究方法: CorrDetail框架通过错误引导问题校正真实的伪造细节，并引入视觉细粒度细节增强模块提供更精确的伪造细节。此外，设计了融合决策策略，结合视觉信息补偿和模型偏差减少，进一步提升模型的判别能力。

研究结果: 实验结果表明，CorrDetail在性能上优于最新方法，能够准确识别伪造细节，并展现出强大的泛化能力。

研究结论: CorrDetail不仅实现了最先进的性能，还通过增强视觉细节和自校正机制，显著提升了伪造检测的可解释性和可靠性。

中文摘要: 随着图像生成技术的快速发展，人脸深度伪造的广泛出现对安全领域提出了重大挑战，因此迫切需要有效的伪造检测方法。现有的人脸伪造检测技术主要分为两类：基于视觉的方法和多模态方法。前者通常缺乏对伪造细节的清晰解释，而后者结合了视觉和语言模态，更容易出现幻觉问题。为解决这些不足，我们提出了一种视觉细节增强的自校正框架CorrDetail，用于可解释的人脸伪造检测。CorrDetail通过错误引导问题校正真实的伪造细节，旨在培养揭示伪造细节的能力而非产生幻觉响应。此外，为增强其结果的可靠性，引入了视觉细粒度细节增强模块，为CorrDetail提供更精确的视觉伪造细节。最终，设计了融合决策策略，通过结合视觉信息补偿和模型偏差减少，进一步提升模型在处理极端样本时的判别能力。实验结果表明，CorrDetail不仅在与最新方法的比较中实现了最先进的性能，还在准确识别伪造细节方面表现出色，同时展现出强大的泛化能力。

</details>


### [60] [YOLO-APD: Enhancing YOLOv8 for Robust Pedestrian Detection on Complex Road Geometries](https://arxiv.org/abs/2507.05376)
**中文标题：YOLO-APD：增强YOLOv8在复杂道路几何上的鲁棒行人检测**

*Aquino Joctum,John Kandiri*

主要分类: cs.CV

摘要简述: 本文提出YOLO-APD，一种改进YOLOv8的深度学习架构，专注于复杂几何道路上的行人检测，通过多种创新模块显著提升了检测精度和实时性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶感知系统在复杂几何道路（如S型弯道）上行人检测存在局限性，需要一种更鲁棒的解决方案。

研究方法: YOLO-APD结合了无参数SimAM注意力机制、高效C3Ghost模块、新型SimSPPF多尺度特征池化模块、Mish激活函数和智能特征融合模块IGD，并利用车辆转向动态进行自适应感兴趣区域处理。

研究结果: 在自定义CARLA数据集上，YOLO-APD达到77.7%的mAP@0.5:0.95和96%以上的行人召回率，实时处理速度为100 FPS，显著优于YOLOv8等基线模型。

研究结论: YOLO-APD为复杂驾驶环境提供了一种高精度、高效且适应性强的感知系统，推动了低成本传感器在自动驾驶中的应用。

中文摘要: 自动驾驶感知系统需要鲁棒的行人检测，尤其是在几何复杂的道路（如S型曲面）上，传统的基于RGB摄像头的方法存在局限性。本文提出YOLO-APD，一种改进YOLOv8框架的新型深度学习架构，专门针对这一挑战。YOLO-APD集成了多项关键架构改进：无参数SimAM注意力机制、计算高效的C3Ghost模块、新型SimSPPF模块以增强多尺度特征池化、Mish激活函数以优化性能，以及智能特征融合模块IGD。此外，还提出了利用车辆转向动态进行自适应感兴趣区域处理的概念。在模拟复杂场景的自定义CARLA数据集上的综合评估表明，YOLO-APD达到了最先进的检测精度，mAP@0.5:0.95为77.7%，行人召回率超过96%，显著优于包括YOLOv8在内的基线模型。同时，它保持了100 FPS的实时处理能力，展现了精度与效率的卓越平衡。消融研究验证了各集成模块的协同贡献。在KITTI数据集上的评估进一步证实了该架构的潜力，同时指出了领域适应的必要性。本研究推动了基于低成本传感器的高精度、高效且适应性强的感知系统的发展，为复杂、非结构化驾驶环境中的自动驾驶提供了更高的安全性和可靠性。

</details>


### [61] [Foreground-aware Virtual Staining for Accurate 3D Cell Morphological Profiling](https://arxiv.org/abs/2507.05383)
**中文标题：面向前景感知的虚拟染色技术：实现精确的3D细胞形态分析**

*Alexandr A. Kalinin,Paula Llanos,Theresa Maria Sommer,Giovanni Sestini,Xinhai Hou,Jonathan Z. Sexton,Xiang Wan,Ivo D. Dinov,Brian D. Athey,Nicolas Rivron,Anne E. Carpenter,Beth Cimini,Shantanu Singh,Matthew J. O'Meara*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Spotlight的虚拟染色方法，通过聚焦于细胞结构而非背景噪声，提升了3D细胞形态分析的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有虚拟染色方法在训练时对所有像素一视同仁，导致背景噪声和伪影被复制，而非聚焦于有生物学意义的信号。本文旨在解决这一问题。

研究方法: Spotlight利用基于直方图的前景估计来掩蔽像素级损失，并通过软阈值预测计算Dice损失，实现形状感知学习。

研究结果: 在3D基准数据集上，Spotlight改善了形态学表示，同时保持了像素级准确性，生成的虚拟染色更适合分割和分析等下游任务。

研究结论: Spotlight方法通过聚焦于细胞结构，显著提升了虚拟染色的质量，为下游任务提供了更可靠的数据。

中文摘要: 显微镜技术能够直接观察3D细胞形态，其中透射光方法提供低成本、微创成像，而荧光显微镜则提供特异性和对比度。虚拟染色结合了这些优势，通过机器学习从无标记输入预测荧光图像。然而，现有方法的训练通常依赖于对所有像素一视同仁的损失函数，从而复制背景噪声和伪影，而非聚焦于有生物学意义的信号。我们提出了Spotlight，一种简单而强大的虚拟染色方法，引导模型关注相关细胞结构。Spotlight利用基于直方图的前景估计来掩蔽像素级损失，并通过软阈值预测计算Dice损失以实现形状感知学习。在3D基准数据集上的应用表明，Spotlight改善了形态学表示，同时保持了像素级准确性，生成的虚拟染色更适合分割和分析等下游任务。

</details>


### [62] [From General to Specialized: The Need for Foundational Models in Agriculture](https://arxiv.org/abs/2507.05390)
**中文标题：从通用到专用：农业领域对基础模型的需求**

*Vishal Nedungadi,Xingguo Xiong,Aike Potze,Ron Van Bree,Tao Lin,Marc Rußwurm,Ioannis N. Athanasiadis*

主要分类: cs.CV

摘要简述: 本文探讨了基础模型在农业领域的应用潜力，评估了现有通用模型在农业任务中的表现，并提出了针对农业的专用基础模型（CropFM）的需求。


<details>
  <summary>详细信息</summary>
研究动机: 随着人口增长和气候变化加剧，粮食安全成为全球关注的问题，亟需创新解决方案提升农业可持续生产力。基础模型在遥感和气候科学中表现出色，但在农业任务中的应用尚未充分探索。

研究方法: 作者定量评估了现有基础模型在农业任务中的有效性，提出了农业基础模型（CropFM）的需求框架，并比较了通用模型在该框架下的表现，同时实证评估了两种模型在三个代表性农业任务中的表现。

研究结果: 研究发现，现有通用基础模型在农业任务中表现有限，亟需开发专门针对农业的基础模型以满足领域需求。

研究结论: 本文强调了开发农业专用基础模型的重要性，为未来研究提供了方向。

中文摘要: 随着人口增长和气候变化加剧，粮食安全成为全球关注的问题，亟需创新解决方案提升农业可持续生产力。近年来，基础模型在遥感和气候科学中表现出色，为农业监测提供了新机遇。然而，其在农业相关挑战（如作物类型映射、作物物候估计和作物产量估计）中的应用仍未被充分探索。本研究定量评估了现有基础模型在一组代表性农业任务中的有效性。从农业领域视角出发，我们描述了理想农业基础模型（CropFM）的需求框架，并在此框架下比较了现有通用基础模型，同时实证评估了其中两种模型在三个代表性农业任务中的表现。最后，我们强调了开发专门针对农业的基础模型的必要性。

</details>


### [63] [Enhancing Underwater Images Using Deep Learning with Subjective Image Quality Integration](https://arxiv.org/abs/2507.05393)
**中文标题：基于深度学习与主观图像质量整合的水下图像增强**

*Jose M. Montero,Jose-Luis Lisani*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的算法，通过整合人类主观评估来提升水下图像质量，结合分类器和生成对抗网络（GANs）优化低质量图像，显著提高了感知和量化指标。


<details>
  <summary>详细信息</summary>
研究动机: 近年来深度学习在图像增强领域取得显著进展，但水下图像的自动增强仍面临挑战。本文旨在通过结合人类主观评估，提升水下图像的质量。

研究方法: 首先训练分类器网络区分高质量和低质量水下图像，随后利用生成对抗网络（GANs）基于多种增强标准优化低质量图像，并通过PSNR、SSIM和UIQM等指标评估性能。

研究结果: 实验表明，结合色彩保真度和图像清晰度等标准的模型在感知和量化图像质量上均取得显著提升。

研究结论: 本文提出的方法通过整合主观评估和深度学习技术，有效提升了水下图像的质量，为相关领域提供了新的解决方案。

中文摘要: 近年来，深度学习尤其是神经网络的进步对多个领域产生了深远影响，包括水下图像的自动增强。本文提出了一种基于深度学习的方法，通过将人类主观评估整合到训练过程中来提升水下图像质量。为此，我们利用公开数据集中的水下图像，这些图像由专家标记为高质量或低质量。我们的方法首先训练分类器网络区分高、低质量图像，随后使用生成对抗网络（GANs）基于多种增强标准优化低质量图像。通过PSNR、SSIM和UIQM等量化指标及定性分析评估GAN模型的性能。结果表明，所提出的模型——尤其是结合色彩保真度和图像清晰度等标准时——在感知和量化图像质量上均取得了显著提升。

</details>


### [64] [pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models](https://arxiv.org/abs/2507.05394)
**中文标题：pFedMMA：基于多模态适配器的视觉-语言模型个性化联邦微调**

*Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani*

主要分类: cs.CV

摘要简述: 本文提出pFedMMA，一种基于多模态适配器的个性化联邦学习框架，用于视觉-语言模型的微调，旨在解决现有方法在个性化和泛化性之间的权衡问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉-语言模型（如CLIP）在零样本和少样本任务中表现优异，但在分布式异构数据上的高效适应仍具挑战性。现有个性化联邦学习方法往往牺牲泛化性以换取个性化，尤其在未见类别或领域上表现不佳。

研究方法: pFedMMA采用多模态适配器，包含模态特定的上下投影层和全局共享的跨模态特征对齐投影层。通过非对称优化策略，客户端可本地适应个性化数据分布，同时协作训练共享投影层以提升全局泛化性。该设计通信高效，仅需在轮次间交换共享组件。

研究结果: 在11个数据集（包括领域和标签偏移场景）上的实验表明，pFedMMA在个性化和泛化性之间实现了最优权衡，优于现有联邦提示调优方法。

研究结论: pFedMMA为视觉-语言任务提供了一种高效且通信友好的个性化联邦学习框架，显著提升了模型在异构数据上的适应能力。

中文摘要: 视觉-语言模型（如CLIP）在零样本和少样本任务中表现出色，但在分布式异构数据上的高效适应仍具挑战性。尽管提示调优已成为个性化联邦学习中一种流行的参数高效方法，但现有方法往往以牺牲泛化性为代价实现个性化，尤其在未见类别或领域上表现不佳。本文提出pFedMMA，首个利用多模态适配器的个性化联邦学习框架，用于视觉-语言任务。每个适配器包含模态特定的上下投影层和全局共享的跨模态特征对齐投影层。通过非对称优化策略，客户端可本地适应个性化数据分布，同时协作训练共享投影层以提升全局泛化性。该设计通信高效，仅需在轮次间交换共享组件。在11个数据集（包括领域和标签偏移场景）上的实验表明，pFedMMA在个性化和泛化性之间实现了最优权衡，优于现有联邦提示调优方法。代码已开源：https://github.com/sajjad-ucsb/pFedMMA。

</details>


### [65] [Neural-Driven Image Editing](https://arxiv.org/abs/2507.05397)
**中文标题：神经驱动的图像编辑**

*Pengfei Zhou,Jie Xia,Xiaopeng Peng,Wangbo Zhao,Zilong Ye,Zekai Li,Suorong Yang,Jiadong Pan,Yuanxiang Chen,Ziqiao Wang,Kai Wang,Qian Zheng,Xiaojun Chang,Gang Pan,Shurong Dong,Kaipeng Zhang,Yang You*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LoongX的无手图像编辑方法，通过多模态神经生理信号驱动，结合先进的扩散模型和脑机接口技术，实现了与传统文本驱动方法相媲美的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像编辑依赖人工提示，耗时且对运动或语言能力受限的用户不友好。本文旨在利用脑机接口和生成模型，开发一种基于神经信号的图像编辑方法，提升可访问性和直观性。

研究方法: LoongX结合了多模态神经信号（如EEG、fNIRS、PPG和头部运动信号），通过跨尺度状态空间（CS3）模块编码特征，动态门控融合（DGF）模块统一特征空间，并利用扩散变换器（DiT）对齐编辑语义。此外，通过对比学习预训练编码器，将认知状态与语义意图对齐。

研究结果: 实验表明，LoongX在性能上接近文本驱动方法（CLIP-I: 0.6605 vs. 0.6558; DINO: 0.4812 vs. 0.4636），且在神经信号与语音结合时表现更优（CLIP-T: 0.2588 vs. 0.2549）。

研究结论: LoongX展示了神经驱动生成模型在图像编辑中的潜力，为认知驱动的创意技术开辟了新方向。数据集和代码将公开以支持未来研究。

中文摘要: 传统图像编辑通常依赖人工提示，耗时且对运动或语言能力受限的用户不友好。借助脑机接口（BCIs）和生成模型的最新进展，我们提出了LoongX，一种基于多模态神经生理信号的无手图像编辑方法。LoongX利用先进的扩散模型，训练于包含23,928个图像编辑对的数据集，每个编辑对均配有同步的脑电图（EEG）、功能性近红外光谱（fNIRS）、光电容积描记（PPG）和头部运动信号，以捕捉用户意图。为解决这些信号的异质性，LoongX集成了两个关键模块：跨尺度状态空间（CS3）模块编码模态特定特征，动态门控融合（DGF）模块将这些特征聚合到统一潜在空间，并通过扩散变换器（DiT）与编辑语义对齐。此外，我们通过对比学习预训练编码器，将认知状态与自然语言嵌入的语义意图对齐。大量实验表明，LoongX性能接近文本驱动方法（CLIP-I: 0.6605 vs. 0.6558; DINO: 0.4812 vs. 0.4636），且在神经信号与语音结合时表现更优（CLIP-T: 0.2588 vs. 0.2549）。这些结果凸显了神经驱动生成模型在实现可访问、直观图像编辑中的潜力，并为认知驱动的创意技术开辟了新方向。数据集和代码将公开以支持未来研究。

</details>


### [66] [Motion Generation: A Survey of Generative Approaches and Benchmarks](https://arxiv.org/abs/2507.05419)
**中文标题：运动生成：生成方法及基准综述**

*Aliasghar Khani,Arianna Rampini,Bruno Roy,Larasika Nadela,Noa Kaplan,Evan Atherton,Derek Cheung,Jacky Bibliowicz*

主要分类: cs.CV

摘要简述: 本文综述了运动生成领域的最新进展，重点分析了生成方法（如GANs、自编码器、自回归模型和扩散技术）的分类、架构原则和评估指标，旨在为研究者提供清晰的比较和开放挑战的参考。


<details>
  <summary>详细信息</summary>
研究动机: 运动生成在计算机视觉、图形学和机器人学中具有广泛应用，但生成方法的多样性和快速发展使得需要一篇全面且结构化的综述，以帮助研究者理解最新进展和挑战。

研究方法: 本文对2023年以来顶级会议发表的论文进行了深入分类，基于生成策略（如GANs、自编码器等）分析运动生成方法，并总结了架构原则、条件机制、生成设置以及评估指标和数据集。

研究结果: 综述提供了运动生成方法的详细分类和比较，明确了不同生成技术的优缺点，并整理了常用的评估指标和数据集，为研究者提供了清晰的参考框架。

研究结论: 本文为运动生成领域的研究者和实践者提供了全面的综述，指出了开放挑战，并为进一步研究提供了基础参考。

中文摘要: 运动生成任务是从多种条件输入中合成逼真运动序列，已成为计算机视觉、计算机图形学和机器人学的核心问题，应用涵盖动画、虚拟代理和人机交互等领域。随着GANs、自编码器、自回归模型和扩散技术等多种建模范式的引入，该领域迅速发展，每种方法均有其优势和局限。这种多样性催生了对生成方法视角下最新进展的全面结构化综述的需求。

本综述基于生成策略对运动生成方法进行了深入分类，重点关注2023年以来顶级会议发表的论文，反映了该领域的最新进展。此外，我们分析了架构原则、条件机制和生成设置，并整理了文献中使用的评估指标和数据集的详细概述。我们的目标是通过更清晰的比较和识别开放挑战，为研究者和实践者提供及时且基础的参考，助力他们应对快速发展的运动生成领域。

</details>


### [67] [Mastering Regional 3DGS: Locating, Initializing, and Editing with Diverse 2D Priors](https://arxiv.org/abs/2507.05426)
**中文标题：掌握区域3D高斯泼溅：基于多样2D先验的定位、初始化与编辑**

*Lanqing Guo,Yufei Wang,Hezhen Hu,Yan Zheng,Yeying Jin,Siyu Huang,Zhangyang Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于2D先验的区域3D高斯泼溅（3DGS）编辑方法，通过2D扩散编辑和逆渲染实现精准区域定位与初始化，支持迭代式视角一致编辑，实验表明其性能优越且速度提升4倍。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D场景编辑多关注全局修改，而区域编辑因3D语义解析性能不足难以精准定位和操作。本文旨在利用2D先验技术解决这一问题，提升区域编辑的精确性和效率。

研究方法: 方法包括：1）利用2D扩散编辑识别修改区域；2）通过逆渲染实现3D定位；3）基于2D深度图初始化粗粒度3DGS；4）迭代优化视角一致的结构和纹理细节。

研究结果: 实验结果表明，该方法在性能上达到最优，同时编辑速度提升高达4倍，显著提升了区域3D编辑的效率和效果。

研究结论: 本文提出的方法通过结合2D先验和迭代优化，实现了高效且精准的区域3DGS编辑，为3D场景局部修改提供了新思路。

中文摘要: 许多3D场景编辑任务专注于局部区域的修改，而非整个场景。在3D高斯泼溅（3DGS）中，场景由一系列高斯分布表示，这种结构允许对特定区域进行精确编辑。然而，3D语义解析的性能通常不如2D，导致3D空间中的目标操作更加困难，限制了编辑的保真度。为此，我们利用2D扩散编辑准确识别每视角的修改区域，并通过逆渲染实现3D定位，随后基于2D基础模型预测的深度图优化前视图并初始化粗粒度3DGS，支持迭代式视角一致的编辑过程，逐步增强结构和纹理细节以确保多视角一致性。实验表明，我们的方法在性能上达到最优，同时速度提升高达4倍，为3D场景局部编辑提供了更高效和有效的解决方案。

</details>


### [68] [OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts](https://arxiv.org/abs/2507.05427)
**中文标题：OpenWorldSAM：通过语言提示扩展SAM2以实现通用图像分割**

*Shiting Xiao,Rishabh Kabra,Yuhang Li,Donghyun Lee,Joao Carreira,Priyadarshini Panda*

主要分类: cs.CV

摘要简述: OpenWorldSAM扩展了SAM2模型，通过集成轻量级视觉语言模型的多模态嵌入，实现了基于开放词汇语言提示的通用图像分割，支持多样化提示、高效训练、实例感知和强泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于开放词汇语言提示的图像分割仍面临挑战，需要将文本语义精确映射到空间掩码，并处理多样化和未见过的类别。OpenWorldSAM旨在解决这一问题，扩展SAM2模型以支持开放词汇场景。

研究方法: OpenWorldSAM通过冻结SAM2和视觉语言模型的预训练组件，仅训练450万参数，集成多模态嵌入，并引入位置决胜嵌入和交叉注意力层，提升空间理解和实例分割能力。

研究结果: OpenWorldSAM在多个基准测试（如ADE20k、PASCAL、ScanNet和SUN-RGBD）中实现了开放词汇语义、实例和全景分割的先进性能，展现了强大的零样本泛化能力。

研究结论: OpenWorldSAM通过统一提示、高效训练和实例感知设计，显著提升了开放词汇图像分割的性能和泛化能力，为通用分割任务提供了灵活高效的解决方案。

中文摘要: 基于开放词汇语言提示分割对象的能力仍是一个关键挑战，需要模型将文本语义精确映射到空间掩码，并处理多样化和未见过的类别。我们提出了OpenWorldSAM，该框架通过集成轻量级视觉语言模型（VLM）提取的多模态嵌入，扩展了提示驱动的Segment Anything Model v2（SAM2）以支持开放词汇场景。我们的方法遵循四个关键原则：i）统一提示：OpenWorldSAM支持多样化的提示，包括类别级和句子级语言描述，为各种分割任务提供灵活接口。ii）高效性：通过冻结SAM2和VLM的预训练组件，我们仅在COCO-stuff数据集上训练450万参数，实现了显著的资源效率。iii）实例感知：通过新颖的位置决胜嵌入和交叉注意力层增强模型的空间理解，有效分割多个实例。iv）泛化能力：OpenWorldSAM展现出强大的零样本能力，无需额外训练即可在未见过的类别和开放词汇概念上表现优异。大量实验表明，OpenWorldSAM在ADE20k、PASCAL、ScanNet和SUN-RGBD等多个基准测试中实现了开放词汇语义、实例和全景分割的先进性能。

</details>


### [69] [Robotic System with AI for Real Time Weed Detection, Canopy Aware Spraying, and Droplet Pattern Evaluation](https://arxiv.org/abs/2507.05432)
**中文标题：基于AI的实时杂草检测、冠层感知喷洒及液滴模式评估的机器人系统**

*Inayat Rasool,Pappu Kumar Yadav,Amee Parmar,Hasan Mirzakhaninafchi,Rikesh Budhathoki,Zain Ul Abideen Usmani,Supriya Paudel,Ivan Perez Olivera,Eric Jone*

主要分类: cs.CV

摘要简述: 开发了一种基于AI的实时杂草检测与智能喷洒系统，通过深度学习模型动态调整喷洒量，减少除草剂浪费和环境污染。


<details>
  <summary>详细信息</summary>
研究动机: 现代农业中除草剂的均匀和过量使用导致成本增加、环境污染及杂草抗药性问题，亟需智能解决方案。

研究方法: 系统整合了轻量级YOLO11n和YOLO11n-seg深度学习模型，部署于NVIDIA Jetson Orin Nano硬件，通过Arduino控制喷嘴，根据杂草冠层大小实时调整喷洒。

研究结果: YOLO11n模型mAP@50达0.98，YOLO11n-seg模型mAP@50为0.48；喷洒覆盖率随冠层大小动态调整，小冠层16.22%，中大冠层21.46%和21.65%。

研究结论: 结合实时深度学习与低成本硬件，系统展示了选择性喷洒的潜力，未来将扩展检测能力并验证于田间试验。

中文摘要: 现代农业中除草剂的均匀和过量使用增加了成本、污染环境并导致杂草抗药性。为解决这些问题，我们开发了一种基于视觉引导和AI的变量喷洒系统，能够实时检测杂草、估计冠层大小并动态调整喷嘴激活。该系统集成了轻量级YOLO11n和YOLO11n-seg深度学习模型，部署于NVIDIA Jetson Orin Nano进行本地推理，并通过Arduino Uno继电器接口控制喷嘴。室内试验使用15株不同冠层大小的木槿模拟杂草场景，YOLO11n模型的平均精度（mAP@50）为0.98，精确度0.99，召回率接近1.0；YOLO11n-seg分割模型的mAP@50为0.48，精确度0.55，召回率0.52。通过水敏纸验证，系统在冠层区域的喷洒覆盖率为24.22%，且喷洒量随冠层大小动态调整（小冠层16.22%，中冠层21.46%，大冠层21.65%）。结果表明，实时深度学习与低成本硬件的结合在选择性除草剂喷洒中具有潜力。未来工作将扩展检测能力至南达科他州三种常见杂草，并在大豆和玉米田间试验中进一步验证。

</details>


### [70] [Driving as a Diagnostic Tool: Scenario-based Cognitive Assessment in Older Drivers From Driving Video](https://arxiv.org/abs/2507.05463)
**中文标题：驾驶作为诊断工具：基于驾驶视频的老年驾驶员场景化认知评估**

*Md Zahid Hasan,Guillermo Basulto-Elias,Jun Ha Chang,Sahuna Hallmark,Matthew Rizzo,Anuj Sharma,Soumik Sarkar*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自然驾驶视频和大规模视觉模型的老年驾驶员认知状态识别方法，通过分析驾驶行为早期发现认知衰退，如阿尔茨海默病和轻度认知障碍。


<details>
  <summary>详细信息</summary>
研究动机: 当前认知衰退的诊断方法耗时且昂贵，导致阿尔茨海默病和轻度认知障碍常被漏诊。研究旨在利用驾驶行为作为认知状态的观察指标，开发一种非侵入性、可扩展的早期检测系统。

研究方法: 研究提出了一种框架，利用大规模视觉模型分析自然驾驶视频，提取驾驶行为的“数字指纹”，并与认知衰退的临床特征关联，从而分类认知状态并预测疾病进展。

研究结果: 该方法能够识别功能损害的早期预警信号，为主动干预策略提供支持，并有助于开发可扩展的监测系统。

研究结论: 通过驾驶行为分析，研究为认知衰退的早期检测提供了新工具，有望减轻老龄化社会中认知衰退带来的社会和经济负担。

中文摘要: 我们提出了一种基于自然驾驶视频和大规模视觉模型的老年驾驶员认知状态识别方法。近年来，由于现有诊断方法耗时且成本高昂，包括阿尔茨海默病（AD）和轻度认知障碍（MCI）在内的认知衰退常被漏诊。通过分析车载系统捕捉的真实驾驶行为，本研究旨在提取与功能衰退及MCI和AD临床特征相关的“数字指纹”。此外，现代大规模视觉模型可以从老年患者的日常驾驶模式中提取有意义的见解，以早期发现认知衰退。我们提出了一种框架，利用大规模视觉模型和自然驾驶视频分析驾驶员行为，分类认知状态并预测疾病进展。我们利用驾驶行为作为驾驶员当前认知状态的观察指标，将车辆视为“诊断工具”。我们的方法识别了功能损害的早期预警信号，有助于制定主动干预策略。这项工作推动了早期检测，并支持开发可扩展、非侵入性的监测系统，以减轻老龄化社会中认知衰退带来的日益增长的社会和经济负担。

</details>


### [71] [Cloud Diffusion Part 1: Theory and Motivation](https://arxiv.org/abs/2507.05496)
**中文标题：云扩散第一部分：理论与动机**

*Andrew Randono*

主要分类: cs.CV

摘要简述: 本文提出了一种新的扩散模型——云扩散模型，通过使用尺度不变噪声替代传统白噪声，旨在提升图像生成的速度、高频细节和可控性。


<details>
  <summary>详细信息</summary>
研究动机: 传统扩散模型使用白噪声生成图像，但自然图像的统计特性具有尺度不变性。作者认为，采用尺度不变噪声可以更接近自然图像的统计特性，从而优化模型性能。

研究方法: 提出云扩散模型，用尺度不变噪声替代白噪声，强调大尺度相关性并弱化小尺度相关性。

研究结果: 云扩散模型有望实现更快的推理速度、更优的高频细节和更高的可控性。

研究结论: 云扩散模型为图像生成提供了一种新思路，后续研究将构建并训练该模型以验证其优势。

中文摘要: 扩散模型通过逐步向图像集添加噪声并训练模型分离信号与噪声来生成图像。这些模型使用的噪声为白噪声，即基于独立正态分布的噪声，其均值和方差与尺度无关。相比之下，大多数自然图像集的低阶统计特性表现出一种尺度不变性，其特征为幂律缩放。因此，自然图像更接近一种强调大尺度相关性并弱化小尺度相关性的概率分布。这种尺度不变噪声可以替代白噪声，形成所谓的“云扩散模型”。我们认为，这些模型可以实现更快的推理、更优的高频细节和更高的可控性。在后续论文中，我们将构建并训练一种在基础层面利用尺度不变性的云扩散模型，并将其与经典的白噪声扩散模型进行比较。

</details>


### [72] [LoomNet: Enhancing Multi-View Image Generation via Latent Space Weaving](https://arxiv.org/abs/2507.05499)
**中文标题：LoomNet：通过潜在空间编织增强多视图图像生成**

*Giulio Federico,Fabio Carrara,Claudio Gennaro,Giuseppe Amato,Marco Di Benedetto*

主要分类: cs.CV

摘要简述: LoomNet提出了一种新颖的多视图扩散架构，通过并行应用同一扩散模型构建共享潜在空间，生成高质量且一致的多视图图像，显著提升了3D重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前从单张图像生成一致的多视图图像仍具挑战性，缺乏空间一致性会降低3D网格重建质量。LoomNet旨在通过共享潜在空间解决这一问题。

研究方法: LoomNet采用多视图扩散架构，并行运行同一扩散模型，将各视图的编码投影到三个正交平面并融合，通过信息传播和缺失区域插值生成统一的潜在空间，最终渲染一致的多视图图像。

研究结果: LoomNet在15秒内生成16张高质量且一致的多视图图像，在图像质量和重建指标上均优于现有方法，并能从同一输入生成多样且合理的新视图。

研究结论: LoomNet通过共享潜在空间和多视图协作，显著提升了多视图图像生成的一致性和质量，为3D重建任务提供了高效解决方案。

中文摘要: 从单张图像生成一致的多视图图像仍具挑战性，缺乏空间一致性常导致3D网格重建质量下降。为此，我们提出LoomNet，一种新颖的多视图扩散架构，通过并行应用同一扩散模型构建共享潜在空间以保持视图一致性。每个视图的推理生成其假设的新视图编码，并投影到三个正交平面。所有视图的编码在每个平面上融合为单一聚合平面，随后通过信息传播和缺失区域插值，将假设统一为连贯的解释。最终利用该潜在空间渲染一致的多视图图像。LoomNet仅需15秒即可生成16张高质量且一致的多视图图像。实验表明，LoomNet在图像质量和重建指标上均优于现有方法，并能从同一输入生成多样且合理的新视图。

</details>


### [73] [Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model](https://arxiv.org/abs/2507.05513)
**中文标题：Llama Nemoretriever Colembed：高性能文本-图像检索模型**

*Mengyao Xu,Gabriel Moreira,Ronay Ak,Radek Osmulski,Yauhen Babakhin,Zhiding Yu,Benedikt Schifferer,Even Oldridge*

主要分类: cs.CV

摘要简述: Llama Nemoretriever Colembed是一种高性能的文本-图像检索模型，通过改进架构和引入ColBERT式交互机制，在多个基准测试中达到领先水平。


<details>
  <summary>详细信息</summary>
研究动机: 随着跨模态检索系统需求的增长，研究团队开发了一种统一的文本-图像检索模型，旨在提供最先进的性能。

研究方法: 模型基于NVIDIA Eagle2视觉语言模型，通过替换因果注意力为双向注意力，并集成ColBERT式后期交互机制，实现细粒度多模态检索。采用两阶段训练策略提升检索能力。

研究结果: 3B模型在ViDoRe V1和V2上分别取得NDCG@5 91.0和63.5的分数，位居排行榜首位。

研究结论: 该模型在检索精度上表现优异，但在存储和效率方面存在权衡，研究提供了全面的分析。

中文摘要: 随着跨模态检索系统需求的增长，我们推出了llama-nemoretriever-colembed，这是一种统一的文本-图像检索模型，在多个基准测试中表现卓越。我们发布了1B和3B两种模型变体，其中3B模型在ViDoRe V1和V2上分别取得NDCG@5 91.0和63.5的分数，截至2025年6月27日位居榜首。我们的方法基于NVIDIA Eagle2视觉语言模型（VLM），通过替换因果注意力为双向注意力，并集成ColBERT式后期交互机制，实现了共享嵌入空间中的细粒度多模态检索。尽管该机制提升了检索精度，但也带来了存储和效率方面的权衡。我们对此进行了全面分析，并采用两阶段训练策略以增强模型的检索能力。

</details>


### [74] [Simulating Refractive Distortions and Weather-Induced Artifacts for Resource-Constrained Autonomous Perception](https://arxiv.org/abs/2507.05536)
**中文标题：为资源受限的自动驾驶感知模拟折射畸变和天气干扰**

*Moseli Mots'oehli,Feimei Chen,Hok Wai Chan,Itumeleng Tlali,Thulani Babeli,Kyungim Baek,Huaijin Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种增强低成本单目行车记录仪数据的流程，模拟非洲复杂驾驶场景中的折射畸变和天气干扰，并发布了相关工具包和数据集，以支持资源受限地区的自动驾驶感知研究。


<details>
  <summary>详细信息</summary>
研究动机: 由于非洲等发展中地区缺乏多样化的自动驾驶数据集，特别是在城市、乡村和未铺装道路上，这限制了自动驾驶感知系统在资源受限环境中的鲁棒性。本文旨在通过模拟真实场景中的折射畸变和天气干扰，填补这一数据空白。

研究方法: 研究提出了一种流程化的数据增强方法，包括折射模块和天气模块。折射模块模拟低质量镜头和空气湍流引起的光学效应（如镜头畸变、Perlin噪声、薄板样条变形等），天气模块则添加均匀雾、非均匀雾和镜头眩光。此外，还提供了三种图像恢复模型的基准性能。

研究结果: 研究发布了包含模拟畸变和天气干扰的工具包、增强数据集和基准结果，为非洲等资源受限地区的自动驾驶感知研究提供了低成本的数据支持。

研究结论: 通过模拟真实场景中的折射畸变和天气干扰，本文为资源受限地区的自动驾驶感知研究提供了实用的数据增强工具和基准，避免了昂贵的数据采集和标注成本。

中文摘要: 发展中地区（尤其是非洲多样化的城市、乡村和未铺装道路）自动驾驶数据集的稀缺性，是资源受限环境下鲁棒感知的主要障碍。我们提出了一种流程化的数据增强方法，通过模拟非洲复杂驾驶场景中的折射畸变和天气干扰，增强低成本单目行车记录仪数据。折射模块模拟低质量镜头和空气湍流引起的光学效应，包括镜头畸变、Perlin噪声、薄板样条（TPS）变形和无散度（不可压缩）扭曲。天气模块添加均匀雾、非均匀雾和镜头眩光。为建立基准，我们提供了三种图像恢复模型的性能基线。为支持非洲等代表性不足地区的感知研究，避免昂贵的数据采集、标注或仿真成本，我们发布了畸变工具包、增强数据集和基准结果。

</details>


### [75] [ReLayout: Integrating Relation Reasoning for Content-aware Layout Generation with Multi-modal Large Language Models](https://arxiv.org/abs/2507.05568)
**中文标题：ReLayout：基于多模态大语言模型的关系推理内容感知布局生成**

*Jiaxu Tian,Xuehui Yu,Yaoxing Wang,Pan Wang,Guangqian Guo,Shan Gao*

主要分类: cs.CV

摘要简述: ReLayout通过关系推理和多模态大语言模型，提出了一种内容感知布局生成方法，解决了现有方法在空间关系理解和多样性上的不足，生成了更结构化和美观的布局。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于大语言模型的布局生成方法未能充分理解视觉主题与设计元素之间的空间关系，导致生成结果在结构和多样性上存在问题。ReLayout旨在通过关系推理解决这些问题。

研究方法: ReLayout引入关系链式思维（relation-CoT），通过显式定义元素间的关系（如区域、显著性和边距），将布局分解为更小的结构化子布局。此外，提出布局原型再平衡采样器，量化不同布局风格，解决数据偏差导致的生成均匀性问题。

研究结果: 实验表明，ReLayout在生成结构化和多样化的布局上优于基线方法，更符合人类审美且更具可解释性。

研究结论: ReLayout通过关系推理和布局原型再平衡，显著提升了内容感知布局生成的质量和多样性，为设计自动化提供了新思路。

中文摘要: 内容感知布局旨在在给定画布上合理排列设计元素以有效传达信息。近年来，利用大语言模型（LLMs）自动生成布局成为趋势，并取得了显著成果。然而，现有基于LLM的方法未能充分理解视觉主题与设计元素之间的空间关系，导致布局生成中存在结构和多样性问题。为解决这一问题，我们提出了ReLayout，一种新颖的方法，通过关系链式思维（relation-CoT）从设计概念出发生成更合理且美观的布局。具体而言，我们通过引入显式关系定义（如区域、显著性和元素间边距）增强布局标注，将布局分解为更小、结构化且递归的子布局，从而实现更结构化的布局生成。此外，基于这些定义的关系，我们引入了一种布局原型再平衡采样器，从三个维度定义布局原型特征并量化不同布局风格。该采样器解决了原型分布平衡过程中数据偏差导致的生成均匀性问题。大量实验结果验证了ReLayout优于基线方法，能够生成更符合人类审美且更具可解释性的结构化和多样化布局。

</details>


### [76] [Multi-Modal Face Anti-Spoofing via Cross-Modal Feature Transitions](https://arxiv.org/abs/2507.05575)
**中文标题：基于跨模态特征转换的多模态人脸防伪**

*Jun-Xiong Chong,Fang-Yu Hsu,Ming-Tsung Hsu,Yi-Ting Lin,Kai-Heng Chien,Chiou-Ting Hsu,Pei-Kai Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种跨模态特征转换引导网络（CTNet），用于解决多模态人脸防伪（FAS）任务中的分布差异和模态缺失问题。通过利用活体样本的跨模态特征一致性和欺骗样本的不一致性，CTNet显著提升了多模态FAS的性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态FAS因不同模态数据分布差异大且测试时可能缺失某些模态而面临挑战。本文基于活体样本跨模态特征转换更一致的观察，提出利用这一特性构建鲁棒的特征空间。

研究方法: 提出CTNet，通过学习活体样本的跨模态特征一致性构建泛化特征空间，并利用活体与欺骗样本的特征不一致性检测异常攻击。此外，通过RGB模态学习补充IR和深度特征以应对模态缺失。

研究结果: 实验表明，CTNet在多数协议下优于现有的多模态FAS方法，显著提升了防伪性能。

研究结论: CTNet通过跨模态特征转换的一致性学习和模态补充策略，有效解决了多模态FAS的分布差异和模态缺失问题，为生物识别系统提供了更鲁棒的防伪方案。

中文摘要: 多模态人脸防伪（FAS）旨在通过从RGB、红外（IR）和深度图像等多模态中提取判别性活体特征，增强生物识别系统的鲁棒性。然而，由于不同模态数据通常由不同传感器采集且环境条件各异，多模态FAS的训练与测试域分布差异显著大于单模态FAS。此外，在推理阶段，当某些模态不可用时，多模态FAS面临更大挑战。本文提出了一种新颖的跨模态转换引导网络（CTNet）以解决这些问题。我们的动机源于活体样本在单一模态内的视觉差异通常远小于欺骗样本，且活体类别的跨模态特征转换更一致。基于此，我们首先提出学习活体样本的跨模态特征一致性以构建泛化特征空间，随后学习活体与欺骗样本的不一致性以有效检测异常攻击。为应对模态缺失问题，我们还提出从RGB模态学习补充IR和深度特征作为辅助模态。大量实验表明，CTNet在多数协议下优于现有的多模态FAS方法。

</details>


### [77] [Semi-Supervised Defect Detection via Conditional Diffusion and CLIP-Guided Noise Filtering](https://arxiv.org/abs/2507.05588)
**中文标题：基于条件扩散和CLIP引导噪声过滤的半监督缺陷检测**

*Shuai Li,Shihan Chen,Wanru Geng,Zhaohua Xu,Xiaolu Liu,Can Dong,Zhen Tian,Changlin Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于条件扩散和CLIP引导噪声过滤的半监督缺陷检测框架（DSYM），显著提高了工业质量检测中的数据效率和检测精度。


<details>
  <summary>详细信息</summary>
研究动机: 工业质量检测中的缺陷检测对高精度和安全关键领域至关重要，但传统方法效率低、成本高且鲁棒性差。本文旨在通过半监督学习减少对标记数据的依赖，同时提升检测性能。

研究方法: 采用两阶段协作训练机制和分阶段联合优化策略，利用标记数据进行初始训练，并通过生成伪标签引入未标记数据。条件扩散模型生成多尺度伪缺陷样本，CLIP跨模态特征噪声过滤机制减少标签污染。

研究结果: 在NEU-DET数据集上，与传统监督方法相比，使用相同标记数据时mAP@0.5达到78.4%，仅需40%标记数据时达到75.1%，数据效率显著提升。

研究结论: 本研究为工业质量检测提供了一种高精度、低标记依赖的缺陷检测解决方案，具有实际应用价值。

中文摘要: 在工业质量检测领域，缺陷检测是关键环节，尤其在高精度和安全关键领域如汽车零部件、航空航天和医疗设备中。传统方法依赖人工检测或早期图像处理算法，存在效率低、成本高和鲁棒性差的问题。本文提出了一种基于条件扩散（DSYM）的半监督缺陷检测框架，采用两阶段协作训练机制和分阶段联合优化策略。框架利用标记数据进行初始训练，并通过生成伪标签引入未标记数据。条件扩散模型合成多尺度伪缺陷样本，而基于CLIP跨模态特征的噪声过滤机制减少标签污染。在NEU-DET数据集上的实验结果显示，与传统监督方法使用相同标记数据时mAP@0.5达到78.4%，仅需40%标记数据时达到75.1%，数据效率显著提升。本研究为工业质量检测场景提供了一种高精度、低标记依赖的缺陷检测解决方案。本文工作已开源：https://github.com/cLin-c/Semisupervised-DSYM。

</details>


### [78] [GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field](https://arxiv.org/abs/2507.05594)
**中文标题：GSVR：基于2D高斯的视频表示方法，支持800+ FPS解码速度与混合变形场**

*Zhizhuo Pang,Zhihui Ke,Xiaobo Zhou,Tie Qiu*

主要分类: cs.CV

摘要简述: GSVR是一种基于2D高斯分布的视频表示方法，通过混合变形场和动态感知时间切片策略，实现了800+ FPS的解码速度和35+ PSNR的画质，训练时间仅需每帧2秒。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于卷积网络的视频表示方法解码速度慢且训练时间长，GSVR旨在解决这些问题，提供高效的视频表示方案。

研究方法: GSVR提出混合变形场结合三平面运动和多项式运动，动态感知时间切片策略自适应划分视频，并通过量化感知微调优化压缩性能。

研究结果: 在Bunny和UVG数据集上，GSVR解码速度比其他方法快10倍，训练时间大幅缩短，视频插值和压缩性能优于现有方法。

研究结论: GSVR在解码速度、训练时间和视频质量上均显著优于现有方法，为高效视频表示提供了新思路。

中文摘要: 隐式神经表示作为一种新颖的视频表示形式备受关注。现有研究多关注重建质量，而忽视了解码速度。然而，现有方法中卷积网络的高计算量导致解码速度低下，且训练时间较长（如Bunny数据集上每帧需14秒以达到35+ PSNR）。为解决这些问题，我们提出GSVR，一种基于2D高斯的视频表示方法，在Bunny数据集上实现800+ FPS和35+ PSNR，训练时间仅需每帧2秒。具体而言，我们提出混合变形场，结合三平面运动和多项式运动，以处理视频中相机运动与物体运动的耦合。此外，我们提出动态感知时间切片策略，根据视频动态水平自适应划分视频组（GOP），以处理大幅相机运动和非刚性运动。最后，我们通过量化感知微调避免量化后性能下降，并利用图像编解码器压缩高斯分布以实现紧凑表示。在Bunny和UVG数据集上的实验表明，我们的方法收敛速度远超现有方法，解码速度快10倍，视频插值性能与SOTA相当，压缩性能优于NeRV。

</details>


### [79] [PaddleOCR 3.0 Technical Report](https://arxiv.org/abs/2507.05595)
**中文标题：PaddleOCR 3.0 技术报告**

*Cheng Cui,Ting Sun,Manhui Lin,Tingquan Gao,Yubo Zhang,Jiaxuan Liu,Xueqing Wang,Zelun Zhang,Changda Zhou,Hongen Liu,Yue Zhang,Wenyu Lv,Kui Huang,Yichao Zhang,Jing Zhang,Jun Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

主要分类: cs.CV

摘要简述: PaddleOCR 3.0 是一个开源的OCR工具包，提供多语言文本识别、结构化文档解析和关键信息提取功能，参数少于1亿但性能媲美主流视觉语言模型。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型时代对文档理解需求的增长，PaddleOCR 3.0 旨在提供一个高效、轻量且功能强大的OCR工具包，满足开发者需求。

研究方法: PaddleOCR 3.0 包含三个主要解决方案：(1) PP-OCRv5 用于多语言文本识别，(2) PP-StructureV3 用于分层文档解析，(3) PP-ChatOCRv4 用于关键信息提取。

研究结果: 这些模型参数少于1亿，但在准确性和效率上媲美主流视觉语言模型，同时提供训练、推理和部署工具，支持异构硬件加速。

研究结论: PaddleOCR 3.0 为开发者提供了高质量的OCR模型库和高效工具，便于构建智能文档应用。

中文摘要: 本技术报告介绍了PaddleOCR 3.0，这是一个Apache许可的开源工具包，用于OCR和文档解析。为满足大语言模型时代对文档理解的需求，PaddleOCR 3.0提供了三大解决方案：(1) PP-OCRv5用于多语言文本识别，(2) PP-StructureV3用于分层文档解析，(3) PP-ChatOCRv4用于关键信息提取。与主流视觉语言模型(VLMs)相比，这些模型参数少于1亿，但在准确性和效率上具有竞争力，媲美数十亿参数的VLMs。除了提供高质量的OCR模型库外，PaddleOCR 3.0还提供高效的训练、推理和部署工具，支持异构硬件加速，使开发者能够轻松构建智能文档应用。

</details>


### [80] [Rethinking Layered Graphic Design Generation with a Top-Down Approach](https://arxiv.org/abs/2507.05601)
**中文标题：采用自上而下方法重新思考分层图形设计生成**

*Jingye Chen,Zhaowen Wang,Nanxuan Zhao,Li Zhang,Difan Liu,Jimei Yang,Qifeng Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Accordion的图形设计生成框架，首次尝试将AI生成的设计转换为可编辑的分层设计，并通过用户提示优化无意义的AI生成文本。该方法采用自上而下的方式，利用视觉语言模型（VLM）和多个视觉专家工具（如SAM和元素移除模型）分解图层，生成高质量的可编辑设计。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI生成的图形设计虽然质量高，但缺乏可编辑性，而分层设计对设计师至关重要。受非分层设计对设计师的启发，本文旨在将AI生成的设计转换为可编辑的分层设计，同时优化文本内容。

研究方法: Accordion框架基于视觉语言模型（VLM），分为三个阶段，每个阶段通过定制提示指导VLM执行不同任务。与自下而上的方法不同，该方法采用自上而下的方式，利用参考图像全局指导图层分解，并借助SAM和元素移除模型等工具辅助生成分层设计。

研究结果: 实验和用户研究表明，Accordion在DesignIntention基准测试中表现优异，包括文本到模板、背景添加文本和文本去渲染等任务，同时在设计变体生成方面也表现出色。

研究结论: Accordion成功实现了将AI生成设计转换为可编辑分层设计的目标，并通过用户提示优化文本内容，为设计师提供了高效的工具。

中文摘要: 图形设计对于传达思想和信息至关重要。设计师通常将其工作组织为对象、背景和矢量化文本图层以简化编辑，但这一流程需要大量专业知识。随着生成式AI方法的兴起，高质量的像素格式图形设计变得更容易获取，但这些设计通常缺乏可编辑性。尽管如此，非分层设计仍能启发设计师，影响其布局和文本风格选择，最终指导分层设计的创建。基于此观察，我们提出Accordion，一个首次尝试将AI生成设计转换为可编辑分层设计的图形设计生成框架，同时通过用户提示优化无意义的AI生成文本。该框架围绕视觉语言模型（VLM）构建，在三个定制阶段中扮演不同角色。每个阶段通过设计提示指导VLM执行不同任务。与现有的自下而上方法（如COLE和Open-COLE）不同，我们的方法采用自上而下的方式，利用视觉和谐的参考图像作为全局指导分解图层，并借助SAM和元素移除模型等视觉专家工具辅助生成图形图层。我们使用内部图形设计数据集Design39K训练方法，并辅以AI生成的设计图像和定制修复模型生成的优化标注。实验和设计师的用户研究表明，Accordion在DesignIntention基准测试中表现出色，包括文本到模板、背景添加文本和文本去渲染等任务，同时在设计变体生成方面也表现优异。

</details>


### [81] [Kernel Density Steering: Inference-Time Scaling via Mode Seeking for Image Restoration](https://arxiv.org/abs/2507.05604)
**中文标题：核密度引导：通过模式搜索实现图像恢复的推理时间缩放**

*Yuyang Hu,Kangfu Mei,Mojtaba Sahraee-Ardakan,Ulugbek S. Kamilov,Peyman Milanfar,Mauricio Delbracio*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Kernel Density Steering（KDS）的新型推理时间框架，通过显式局部模式搜索提升图像恢复的鲁棒性和高保真度。KDS利用多粒子扩散样本集合，通过核密度估计梯度引导样本远离伪模式，显著改善了超分辨率和图像修复任务的效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的扩散模型在图像恢复任务中常面临保真度不一致和伪影问题。为了解决这些问题，本文提出KDS框架，旨在通过集体局部模式搜索机制生成更鲁棒、高质量的图像恢复结果。

研究方法: KDS采用N粒子扩散样本集合，计算其输出的局部核密度估计梯度，引导每个粒子的局部区域向集合中识别出的高密度区域移动。这种集体模式搜索机制避免了独立采样或模型缺陷导致的伪模式，提升了样本质量。

研究结果: 实验表明，KDS在真实世界的超分辨率和图像修复任务中显著提升了定量和定性性能，生成了更高质量的图像样本。

研究结论: KDS作为一种即插即用框架，无需重新训练或外部验证器，能够无缝集成到多种扩散采样器中，为图像恢复任务提供了更鲁棒和高效的解决方案。

中文摘要: 扩散模型在图像恢复中展现出潜力，但现有方法常因保真度不一致和伪影问题而受限。为此，我们提出核密度引导（KDS），一种新型推理时间框架，通过显式局部模式搜索生成鲁棒、高保真的输出。KDS采用N粒子扩散样本集合，从其集体输出中计算局部核密度估计梯度，引导每个粒子的局部区域向集合中识别出的高密度区域移动。这种集体局部模式搜索机制作为“集体智慧”，将样本从独立采样或模型缺陷导致的伪模式中引导出来，转向更鲁棒、高保真的结构。通过同时采样多个粒子，我们以更高的计算成本获得了更高质量的样本。作为一种即插即用框架，KDS无需重新训练或外部验证器，可无缝集成到多种扩散采样器中。大量数值验证表明，KDS在真实世界的超分辨率和图像修复任务中显著提升了定量和定性性能。

</details>


### [82] [Generative Head-Mounted Camera Captures for Photorealistic Avatars](https://arxiv.org/abs/2507.05620)
**中文标题：生成式头戴式摄像头捕捉技术用于逼真虚拟角色**

*Shaojie Bai,Seunghyeon Seo,Yida Wang,Chenghui Li,Owen Wang,Te-Li Wang,Tianyang Ma,Jason Saragih,Shih-En Wei,Nojun Kwak,Hyung Jun Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为GenHMC的生成方法，利用大量未配对的头戴式摄像头（HMC）数据生成高质量合成图像，解决了传统方法依赖配对数据的问题，并实现了更准确的地面真实数据生成。


<details>
  <summary>详细信息</summary>
研究动机: 在虚拟和增强现实（VR/AR）中，实现逼真的虚拟角色动画面临挑战，主要因为难以获取面部的真实状态数据。传统方法依赖配对的HMC和穹顶摄像头数据，成本高且不可复用。本文旨在通过生成方法解决这些问题。

研究方法: 提出Generative HMC（GenHMC）方法，利用大量未配对的HMC数据，直接生成高质量的合成HMC图像。该方法能够分离输入条件信号（如表情和视角）与面部外观，从而生成更准确的地面真实数据。

研究结果: 实验表明，GenHMC能够生成高质量的合成HMC图像，并支持未见过的身份泛化。基于这些新数据训练的通用面部编码器表现出更高的数据效率和最先进的准确性。

研究结论: GenHMC通过生成方法显著降低了数据收集成本，同时提高了地面真实数据的准确性，为虚拟角色动画提供了更高效的解决方案。

中文摘要: 在虚拟和增强现实（VR/AR）中实现逼真的虚拟角色动画一直具有挑战性，因为难以获取面部的真实状态数据。由于物理限制，无法同步获取头戴式摄像头（HMC）的红外部分观测数据和穹顶摄像头的完整观测数据。传统基于分析-合成的方法虽然能生成准确的地面真实数据，但在个性化训练中难以完全分离表情和风格。依赖同一主题的配对数据（HMC和穹顶）使得大规模数据集收集成本高昂，且无法复用。本文提出了一种新颖的生成方法Generative HMC（GenHMC），利用大量未配对的HMC数据直接生成高质量的合成HMC图像。该方法能够正确分离输入条件信号（如表情和视角）与面部外观，从而生成更准确的地面真实数据。此外，该方法还能泛化至未见过的身份，减少对配对数据的依赖。通过评估合成HMC图像和基于这些新数据训练的通用面部编码器，我们证明了该方法在数据效率和准确性上的突破。

</details>


### [83] [AdaptaGen: Domain-Specific Image Generation through Hierarchical Semantic Optimization Framework](https://arxiv.org/abs/2507.05621)
**中文标题：AdaptaGen：基于分层语义优化框架的领域特定图像生成**

*Suoxiang Zhang,Xiaxi Li,Hongrui Chang,Zhuoyan Hou,Guoxin Wu,Ronghua Ji*

主要分类: cs.CV

摘要简述: AdaptaGen提出了一种分层语义优化框架，通过矩阵提示优化和多视角理解，结合跨模态适应机制和两阶段标题语义转换，显著提升了领域特定图像生成的语义准确性和视觉多样性。


<details>
  <summary>详细信息</summary>
研究动机: 现有领域特定图像生成方法存在语义理解与视觉表示分离、领域约束融入不足的问题，导致生成结果出现幻觉和语义偏差。AdaptaGen旨在解决这些问题。

研究方法: AdaptaGen采用分层语义优化框架，结合矩阵提示优化、多视角语义理解、跨模态适应机制和两阶段标题语义转换，确保生成图像的语义一致性和多样性。

研究结果: 实验结果表明，AdaptaGen在40个类别上仅需每类16张图像即可显著提升图像质量、多样性和语义一致性。

研究结论: AdaptaGen通过分层语义优化和跨模态适应机制，有效解决了领域特定图像生成的语义偏差和幻觉问题，为高质量图像生成提供了新思路。

中文摘要: 领域特定图像生成旨在为专业领域生成高质量视觉内容，同时确保语义准确性和细节保真度。然而，现有方法存在两大关键局限：一是当前方法将提示工程和模型适应分开处理，忽视了专业领域中语义理解与视觉表示的内在依赖关系；二是这些技术在内容合成中未能充分融入领域特定语义约束，导致生成结果出现幻觉和语义偏差。为解决这些问题，我们提出AdaptaGen，一种分层语义优化框架，将基于矩阵的提示优化与多视角理解相结合，从全局和局部视角捕捉全面的语义关系。为减少专业领域中的幻觉，我们设计了跨模态适应机制，结合智能内容合成，既能保留核心主题元素，又能融入多样化的图像细节。此外，我们在生成阶段引入两阶段标题语义转换，确保语义连贯性的同时增强视觉多样性，使生成图像符合领域特定约束。实验结果证实了该方法的有效性，我们的框架在40个类别上仅需每类16张图像即可实现卓越性能，显著提升了图像质量、多样性和语义一致性。

</details>


### [84] [OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval](https://arxiv.org/abs/2507.05631)
**中文标题：OFFSET：基于分割的焦点偏移修正网络用于组合图像检索**

*Zhiwei Chen,Yupeng Hu,Zixu Li,Zhiheng Fu,Xuemeng Song,Liqiang Nie*

主要分类: cs.CV

摘要简述: 本文提出了一种基于分割的焦点偏移修正网络（OFFSET），用于解决组合图像检索（CIR）中的视觉特征退化和焦点偏差问题。通过主导部分分割和双重焦点映射模块，结合文本引导的焦点修正，显著提升了检索性能。


<details>
  <summary>详细信息</summary>
研究动机: 组合图像检索（CIR）虽然能灵活表达用户需求，但仍存在两个主要问题：1）视觉数据中主导部分与噪声部分的不均匀性被忽略，导致查询特征退化；2）文本数据在图像修改过程中的优先级被忽视，导致视觉焦点偏差。本文旨在解决这些问题。

研究方法: 方法包括两个模块：1）主导部分分割和双重焦点映射模块，用于识别图像中的显著部分并提取视觉和文本特征；2）文本引导的焦点修正模块，利用文本中的修改需求对参考图像进行自适应焦点修正。这些模块共同构成了OFFSET网络。

研究结果: 在四个基准数据集上的实验表明，OFFSET显著优于现有方法，验证了其在减少噪声干扰和修正视觉焦点偏差方面的有效性。

研究结论: OFFSET通过结合主导部分分割和文本引导的焦点修正，有效解决了CIR中的特征退化和焦点偏差问题，为组合图像检索提供了新的解决方案。

中文摘要: 组合图像检索（CIR）是一种能够灵活表达用户复杂检索需求的新型检索范式。它允许用户提交包含参考图像和修改文本的多模态查询，并检索目标图像。尽管现有方法取得了显著进展，但CIR仍处于早期阶段，存在两个局限性：1）视觉数据中主导部分与噪声部分的不均匀性被忽略，导致查询特征退化；2）文本数据在图像修改过程中的优先级被忽视，导致视觉焦点偏差。为解决这些问题，本文提出了一种基于焦点映射的特征提取器，包含主导部分分割和双重焦点映射两个模块，旨在识别图像中的显著主导部分并提取视觉和文本特征，从而减少噪声干扰。此外，我们还提出了一个文本引导的焦点修正模块，能够利用文本中的修改需求对参考图像进行自适应焦点修正，增强对组合特征中修改焦点的感知。上述模块共同构成了基于分割的焦点偏移修正网络（OFFSET）。在四个基准数据集上的全面实验验证了所提方法的优越性。代码和数据可在https://zivchen-ty.github.io/OFFSET.github.io/获取。

</details>


### [85] [Knowledge-guided Complex Diffusion Model for PolSAR Image Classification in Contourlet Domain](https://arxiv.org/abs/2507.05666)
**中文标题：基于Contourlet域知识引导的复杂扩散模型用于PolSAR图像分类**

*Junfei Shi,Yu Cheng,Haiyan Jin,Junhuai Li,Zhaolin Xiao,Maoguo Gong,Weisi Lin*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Contourlet变换的知识引导复杂扩散模型，用于PolSAR图像分类，解决了传统扩散模型在捕获复杂相位信息和保留精细结构细节方面的不足。


<details>
  <summary>详细信息</summary>
研究动机: 传统实值扩散模型在处理PolSAR数据时难以捕捉复杂相位信息，且无法保留精细结构细节。为此，本文利用Contourlet变换的多尺度多方向表示能力，提出了一种改进方法。

研究方法: 首先对PolSAR数据进行复杂Contourlet变换，分解为低频和高频子带；设计知识引导的复杂扩散网络建模低频统计特性，同时利用高频系数结构信息指导扩散过程，提升边缘保留能力；联合学习多尺度多方向高频特征以提高分类精度。

研究结果: 在三个真实PolSAR数据集上的实验表明，该方法在边缘细节保留和复杂地形区域同质性方面优于现有技术。

研究结论: 本文提出的知识引导复杂扩散模型在PolSAR图像分类中表现出色，尤其在保留边缘细节和区域同质性方面具有显著优势。

中文摘要: 扩散模型因其能够建模和生成复杂数据分布而在多个领域表现出色。然而，传统实值扩散模型应用于PolSAR数据时，难以捕捉复杂相位信息，且往往无法保留精细结构细节。为解决这些问题，我们利用Contourlet变换提供的多尺度多方向表示能力，提出了一种基于Contourlet域的结构知识引导复杂扩散模型用于PolSAR图像分类。具体而言，首先通过复杂Contourlet变换将数据分解为低频和高频子带，提取统计和边界特征；随后设计知识引导的复杂扩散网络建模低频统计特性，并利用高频系数结构信息指导扩散过程以提升边缘保留能力；同时联合学习多尺度多方向高频特征以进一步提高分类精度。在三个真实PolSAR数据集上的实验结果表明，该方法在边缘细节保留和复杂地形区域同质性方面优于现有技术。

</details>


### [86] [Dynamic Rank Adaptation for Vision-Language Models](https://arxiv.org/abs/2507.05668)
**中文标题：视觉语言模型的动态秩适应**

*Jiahui Wang,Qin Xu,Bo Jiang,Bin Luo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为动态秩适应（DRA）的新方法，通过动态调整特征的重要性排名来增强视觉语言模型对新类别的泛化能力，实验证明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于提示和适配器的方法在微调视觉语言模型时，对所有图像和文本编码器的标记一视同仁，容易导致对非信息性特征的过拟合，从而降低对新概念的识别能力。本文旨在解决这一问题。

研究方法: DRA通过动态分配适应秩来保留通用知识，首先使用序列注意力对标记进行重要性分组，然后根据重要性动态调整每个组的特征秩，并设计了一种新的通道响应机制以优先保留信息量最大的特征通道。此外，引入了L1正则化项以稳定训练。

研究结果: 大量实验表明，DRA在多个基准测试中显著提升了新类别的性能，包括基础-新类别、跨数据集评估和领域泛化任务。

研究结论: DRA通过动态调整特征重要性排名，有效提升了视觉语言模型对新类别的泛化能力，优于现有方法。

中文摘要: 预训练的大型视觉语言模型（如CLIP）展现出强大的泛化能力。现有的基于提示和适配器的方法在微调视觉语言模型方面取得了显著进展，但仍面临保持强大泛化能力的挑战，尤其是对未见新类别的识别。这一限制部分源于这些方法对所有图像和文本编码器的标记一视同仁，可能导致对非信息性特征（如背景噪声、模板词）的过拟合，并削弱对新概念识别至关重要的通用表示。为解决这一问题，我们提出了动态秩适应（DRA），这是一种专为增强新类别泛化能力而设计的新型适配器变体方法。DRA根据训练过程中特征的重要性动态分配适应秩以保留通用知识。DRA首先采用标记重要性分组，利用序列注意力评估并按重要性对标记分组；然后根据每组标记的重要性动态调整特征秩，为更重要的标记分配更高的特征秩。此外，我们设计了一种新的通道响应机制，优先保留和调整对每个实例最具信息量的特征通道。同时，引入了L1正则化项以稳定训练。大量实验证明了DRA的有效性和优越性，尤其是在提升新类别性能方面，包括基础-新类别、跨数据集评估和领域泛化任务。源代码将在论文接收后发布。

</details>


### [87] [Modeling and Reversing Brain Lesions Using Diffusion Models](https://arxiv.org/abs/2507.05670)
**中文标题：基于扩散模型的脑部病变建模与逆转**

*Omar Zamzam,Haleh Akrami,Anand Joshi,Richard Leahy*

主要分类: cs.CV

摘要简述: 本文提出了一种基于扩散模型的框架，用于分析和逆转脑部病变过程，通过分割异常区域、估计并逆转组织变形，最终修复核心病变区域，从而估计病变前的健康大脑状态。该方法在病变分割和表征方面优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的脑部病变分割方法未能区分受损组织和变形组织，将其统一标记为异常。本文旨在通过扩散模型区分并逆转病变过程，为临床和研究提供更精确的工具。

研究方法: 首先分割脑部异常区域，随后估计并逆转组织变形，恢复组织至原始位置，隔离核心病变区域。最后通过修复核心病变区域，估计病变前的健康大脑状态。

研究结果: 与传统方法相比，该方法在病变分割、表征和脑部标记方面表现出更高的准确性，为脑部病变分析提供了可靠工具。

研究结论: 基于扩散模型的框架能够有效逆转脑部病变过程，区分受损与变形组织，为临床和研究应用提供了新的解决方案。

中文摘要: 脑部病变是脑组织中的异常或损伤，通常可通过磁共振成像（MRI）检测到，显示受影响区域的结构变化。脑部病变的广义定义包括不可逆损伤区域以及因病变生长或肿胀而变形的脑组织区域。尽管区分受损组织和变形组织具有重要意义，但现有的病变分割方法忽视了这一区别，将两者统一标记为单一异常。本研究提出了一种基于扩散模型的框架，用于分析和逆转脑部病变过程。我们的流程首先分割脑部异常区域，随后估计并逆转组织变形，将位移组织恢复至原始位置，隔离代表初始损伤的核心病变区域。最后，通过修复核心病变区域，估计病变前的健康大脑状态。该框架逆转了生物力学研究中用于建模脑部病变的前向病变生长过程模型。与传统方法相比，我们的结果在病变分割、表征和脑部标记方面表现出更高的准确性，为脑部病变分析提供了可靠的临床和研究工具。由于公共数据集中缺乏异常大脑病变前的健康版本用于验证逆向过程，我们通过模拟前向模型合成了多张病变脑部图像。

</details>


### [88] [R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding](https://arxiv.org/abs/2507.05673)
**中文标题：R-VLM：基于区域感知的视觉语言模型用于精确GUI元素定位**

*Joonhyung Park,Peng Tang,Sagnik Das,Srikar Appalaraju,Kunwar Yashraj Singh,R. Manmatha,Shabnam Ghadar*

主要分类: cs.CV

摘要简述: R-VLM是一种新型的GUI元素定位方法，通过放大区域提案和IoU感知目标函数，显著提升了GUI元素定位的精确度，并在多个基准测试中取得领先性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于视觉的GUI自动化代理在处理复杂屏幕截图时，由于需要处理大量无关信息，导致定位精度不足。此外，传统的交叉熵损失函数无法有效衡量定位质量。因此，需要一种更精确的GUI元素定位方法。

研究方法: R-VLM提出了一种基于放大区域提案的GUI元素定位方法，并结合IoU感知的目标函数，以优化模型对高IoU预测的收敛性。

研究结果: R-VLM在ScreenSpot和AgentStudio基准测试中将GUI元素定位精度提升了13%，在AITW和Mind2Web的GUI导航任务中实现了3.2-9.7%的绝对精度提升。

研究结论: R-VLM通过结合视觉语言模型与传统目标检测技术，显著提升了GUI元素定位的精确度，为GUI自动化任务提供了更高效的解决方案。

中文摘要: 基于视觉语言模型（VLMs）的图形用户界面（GUI）自动化代理已成为一个重要的研究方向。然而，GUI自动化的关键挑战在于跨平台界面元素的精确定位。现有的纯视觉GUI代理直接从复杂的大尺寸截图中定位元素，需要处理大量无关信息，从而影响其准确性。此外，这些方法通常使用基本的交叉熵损失函数学习定位目标，无法有效衡量定位质量（如交并比IoU）。为解决这些问题，我们提出了R-VLM，一种新型的GUI元素定位方法，利用放大区域提案实现精确定位，并提出了一种IoU感知的目标函数，以促进模型向高IoU预测收敛。我们的方法填补了VLMs与传统目标检测技术之间的空白，在ScreenSpot和AgentStudio基准测试中将GUI元素定位精度提升了13%。此外，R-VLM在AITW和Mind2Web的GUI导航任务中实现了3.2-9.7%的绝对精度提升。

</details>


### [89] [MedGen: Unlocking Medical Video Generation by Scaling Granularly-annotated Medical Videos](https://arxiv.org/abs/2507.05675)
**中文标题：MedGen：通过细粒度标注医疗视频解锁医疗视频生成**

*Rongsheng Wang,Junying Chen,Ke Ji,Zhenyang Cai,Shunian Chen,Yunjin Yang,Benyou Wang*

主要分类: cs.CV

摘要简述: 论文介绍了MedVideoCap-55K数据集和MedGen模型，旨在解决医疗视频生成领域缺乏高质量数据的问题，并在视觉质量和医学准确性上达到领先水平。


<details>
  <summary>详细信息</summary>
研究动机: 医疗视频生成在临床培训和教育中至关重要，但现有模型因缺乏高质量医疗数据集而难以生成准确内容。论文旨在填补这一空白。

研究方法: 论文构建了首个大规模、多样化的医疗视频数据集MedVideoCap-55K，并基于此开发了MedGen模型，专注于提升医疗视频生成的视觉质量和医学准确性。

研究结果: MedGen在多个基准测试中表现优异，视觉质量和医学准确性均达到开源模型领先水平，甚至媲美商业系统。

研究结论: 论文提出的数据集和模型为医疗视频生成领域提供了宝贵资源，有望推动进一步研究。

中文摘要: 近年来，视频生成技术在开放领域取得了显著进展，但医疗视频生成仍鲜有研究。医疗视频在临床培训、教育和模拟等应用中至关重要，不仅需要高视觉保真度，还需严格的医学准确性。然而，当前模型在应用于医疗提示时，常生成不真实或错误的内容，主要原因是缺乏针对医疗领域的大规模高质量数据集。为解决这一问题，我们推出了MedVideoCap-55K，这是首个大规模、多样化且标注丰富的医疗视频生成数据集。它包含超过55,000个经过筛选的真实医疗场景片段，为训练通用医疗视频生成模型提供了坚实基础。基于此数据集，我们开发了MedGen，其在视觉质量和医学准确性上均达到开源模型领先水平，并在多个基准测试中媲美商业系统。我们希望这一数据集和模型能成为宝贵资源，推动医疗视频生成领域的进一步研究。代码和数据可在https://github.com/FreedomIntelligence/MedGen获取。

</details>


### [90] [Integrated Structural Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2507.05677)
**中文标题：视觉语言模型的集成结构化提示学习**

*Jiahui Wang,Qin Xu,Bo Jiang,Bin Luo*

主要分类: cs.CV

摘要简述: 本文提出了一种集成结构化提示（ISP）方法，用于增强视觉语言模型（VLMs）中文本和图像分支的信息交互，通过自结构和跨结构提示模块建模可学习提示与冻结令牌之间的关系，并引入样本探测模块动态调整损失系数，显著提升了模型在新类别上的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的提示学习方法大多忽略了可学习提示与模态内及模态间令牌的结构关系，且难以平衡基础类别和新类别的性能。本文旨在通过结构化提示和动态损失调整解决这些问题。

研究方法: 提出集成结构化提示（ISP），包含自结构和跨结构提示模块，建模可学习提示与冻结令牌的结构关系；引入样本探测模块，根据样本难度动态调整损失系数，防止模型过拟合简单样本。

研究结果: 在基础到新类别泛化、跨数据集评估和领域泛化三个广泛使用的设置中，ISP表现出色，性能优于现有最先进方法。

研究结论: ISP通过结构化提示和动态损失调整，显著提升了视觉语言模型的信息交互能力和泛化性能，为下游任务提供了更强大的迁移能力。

中文摘要: 提示学习方法显著扩展了预训练视觉语言模型（如CLIP）在下游任务中的可迁移性。这些方法通过手工模板或可学习向量为微调VLMs提供文本或图像指令。然而，现有工作大多忽略了可学习提示与模态内及模态间令牌的结构关系，且平衡基础类别和新类别的性能仍是一个重大挑战。本文提出了一种集成结构化提示（ISP），用于增强VLMs中文本和图像分支的信息表示交互。ISP引入了自结构和跨结构提示模块，建模可学习提示与冻结令牌在模态内及跨模态间的结构关系，从而实现高效信息传递并保持特征稳定性。此外，我们还提出了一种样本探测模块，根据样本难度动态调整损失系数，防止模型过拟合简单样本，并提升对新类别的泛化能力。在基础到新类别泛化、跨数据集评估和领域泛化三个广泛使用的设置中，实验表明ISP的性能优于现有最先进方法。

</details>


### [91] [LiON-LoRA: Rethinking LoRA Fusion to Unify Controllable Spatial and Temporal Generation for Video Diffusion](https://arxiv.org/abs/2507.05678)
**中文标题：LiON-LoRA：重新思考LoRA融合以实现视频扩散中可控空间和时间生成的统一**

*Yisu Zhang,Chenjie Cao,Chaohui Yu,Jianke Zhu*

主要分类: cs.CV

摘要简述: LiON-LoRA提出了一种新颖的框架，通过线性可扩展性、正交性和范数一致性重新设计LoRA融合，实现了视频扩散模型中空间和时间生成的可控性统一。


<details>
  <summary>详细信息</summary>
研究动机: 尽管低秩适应（LoRA）可以在有限数据下驱动视频扩散模型学习特定空间或时间运动，但由于融合不稳定和非线性可扩展性，精确控制相机轨迹和物体运动仍具挑战性。

研究方法: LiON-LoRA通过分析浅层LoRA特征的正交性实现低层解耦控制，强制层间范数一致性以稳定复杂相机运动组合的融合，并引入可控令牌到扩散变换器（DiT）中，通过改进的自注意力机制线性调整运动和物体幅度。

研究结果: 实验表明，LiON-LoRA在轨迹控制精度和运动强度调整上优于现有方法，仅需少量训练数据即可实现卓越的泛化能力。

研究结论: LiON-LoRA通过重新设计LoRA融合，成功统一了视频扩散模型中空间和时间生成的可控性，为复杂运动控制提供了高效解决方案。

中文摘要: 视频扩散模型（VDMs）通过学习大规模数据展现了合成逼真视频的卓越能力。尽管普通低秩适应（LoRA）可以在有限数据下驱动VDMs学习特定空间或时间运动，但由于融合不稳定和非线性可扩展性，精确控制相机轨迹和物体运动仍具挑战性。为解决这些问题，我们提出了LiON-LoRA，一种通过线性可扩展性、正交性和范数一致性重新设计LoRA融合的新框架。首先，我们分析了浅层VDM中LoRA特征的正交性，实现了解耦的低层可控性。其次，强制层间范数一致性以稳定复杂相机运动组合的融合。第三，将可控令牌集成到扩散变换器（DiT）中，通过改进的自注意力机制线性调整相机和物体的运动幅度，确保解耦控制。此外，我们利用静态相机视频将LiON-LoRA扩展到时间生成，统一了空间和时间可控性。实验表明，LiON-LoRA在轨迹控制精度和运动强度调整上优于现有方法，仅需少量训练数据即可实现卓越的泛化能力。项目页面：https://fuchengsu.github.io/lionlora.github.io/

</details>


### [92] [Event-RGB Fusion for Spacecraft Pose Estimation Under Harsh Lighting](https://arxiv.org/abs/2507.05698)
**中文标题：极端光照条件下基于事件-RGB融合的航天器姿态估计**

*Mohsi Jawaid,Marcus Märtens,Tat-Jun Chin*

主要分类: cs.CV

摘要简述: 本文提出了一种结合RGB和事件传感器的融合方法，用于在极端光照条件下进行航天器姿态估计，通过光束分离棱镜实现精确对齐，并开发了RANSAC技术融合两种传感器数据，实验结果表明该方法有效。


<details>
  <summary>详细信息</summary>
研究动机: 航天器姿态估计对自主空间操作至关重要，但传统RGB传感器在极端光照条件下表现不佳，而事件传感器虽动态范围高，但空间分辨率低且低运动时信噪比差。因此，需要一种融合方法结合两者的优势。

研究方法: 使用光束分离棱镜实现RGB和事件传感器的光学和时间对齐，开发基于RANSAC的技术融合两种传感器数据，并通过dropout不确定性估计检测极端条件。

研究结果: 在实验室收集的多样化光照条件下数据集上测试，结果表明事件-RGB融合方法有效，支持事件传感器在航天器姿态估计中的应用。

研究结论: 事件-RGB融合方法在极端光照条件下显著提升了姿态估计性能，为相关研究提供了公开数据集。

中文摘要: 航天器姿态估计对于自主空间操作（如交会、对接和在轨服务）至关重要。基于视觉的姿态估计方法通常使用RGB成像传感器，但在极端光照条件下（如眩光、过曝、光晕和镜头光斑）表现不佳。由于动态范围更高，神经形态或事件传感器对极端光照条件更具鲁棒性，但其空间分辨率较低且在低相对运动时信噪比下降。本研究通过结合RGB和事件传感器的融合方法解决了这些局限性。使用光束分离棱镜实现精确的光学和时间对齐，并开发了基于RANSAC的技术融合两种传感器的数据，同时通过dropout不确定性估计检测极端条件。为验证方法的性能，我们在实验室中收集了多种挑战性光照条件下的RGB和事件数据集。实验结果证明了事件-RGB融合方法的有效性，并进一步支持事件传感器在航天器姿态估计中的应用。相关数据集将公开以支持社区研究。

</details>


### [93] [Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study](https://arxiv.org/abs/2507.05730)
**中文标题：高光谱异常检测方法综述与比较研究**

*Aayushma Pant,Arbind Agrahari Baniya,Tsz-Kwan Lee,Sunil Aryal*

主要分类: cs.CV

摘要简述: 本文综述并比较了高光谱异常检测（HAD）方法，分析了统计模型、表示方法、经典机器学习和深度学习模型的性能，发现深度学习精度最高，统计模型速度最快，并指出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱异常检测技术在农业、军事等领域应用广泛，但现有方法面临计算复杂度高、噪声敏感和泛化能力不足等问题。本文旨在通过全面比较各类方法，为研究者和实践者提供有价值的参考。

研究方法: 研究对统计模型、表示方法、经典机器学习和深度学习模型进行了分类比较，并在17个基准数据集上使用ROC、AUC等指标评估了检测精度和计算效率。

研究结果: 结果表明，深度学习模型检测精度最高，统计模型在所有数据集中速度最快。同时，研究总结了各类方法的优缺点。

研究结论: 本文为高光谱异常检测领域的研究者和实践者提供了重要参考，并指出了未来研究方向，如提升泛化能力和计算效率。

中文摘要: 高光谱图像是由数百个连续光谱波段组成的高维数据集，能够进行详细的材料和表面分析。高光谱异常检测（HAD）技术旨在无需先验信息的情况下识别和定位此类数据中的异常目标。近年来，该技术在农业、国防、军事监视和环境监测等领域快速发展。然而，现有HAD方法仍面临计算复杂度高、噪声敏感以及泛化能力有限等挑战。本研究对统计模型、表示方法、经典机器学习和深度学习模型进行了全面比较，并在17个基准数据集上使用ROC、AUC和分离图等性能指标评估了检测精度和计算效率。结果表明，深度学习模型的检测精度最高，而统计模型在所有数据集中速度最快。本研究旨在为高光谱异常检测领域的研究者和实践者提供有价值的参考，并指出未来研究方向。

</details>


### [94] [SenseShift6D: Multimodal RGB-D Benchmarking for Robust 6D Pose Estimation across Environment and Sensor Variations](https://arxiv.org/abs/2507.05751)
**中文标题：SenseShift6D：面向环境与传感器变化的鲁棒6D姿态估计多模态RGB-D基准**

*Yegyu Han,Taegyoon Yoon,Dayeon Woo,Sojeong Kim,Hyung-Sin Kim*

主要分类: cs.CV

摘要简述: SenseShift6D是首个多模态RGB-D数据集，通过物理调整RGB曝光、增益、深度模式和光照水平，探索6D姿态估计在真实环境变化中的鲁棒性。实验表明，测试时传感器控制优于数据增强，联合调整RGB-D配置效果最佳。


<details>
  <summary>详细信息</summary>
研究动机: 现有6D姿态估计数据集（如LM-O、YCB-V和T-Less）在固定光照和相机设置下采集，未考虑真实环境中的变化（如光照、曝光、增益和深度模式）。为填补这一空白，研究团队提出SenseShift6D，探索传感器控制对鲁棒性的影响。

研究方法: SenseShift6D数据集通过物理调整13种RGB曝光、9种RGB增益、自动曝光、4种深度模式和5种光照水平，采集了101.9k RGB和10k深度图像，覆盖1,380种传感器-光照组合。实验对比了传感器控制与数据增强的效果。

研究结果: 实验表明，测试时传感器控制比数据增强更能提升性能，且联合调整RGB-D配置效果优于单独调整RGB或深度传感器。性能提升可与增加训练数据量和多样性相媲美。

研究结论: SenseShift6D将6D姿态评估从数据为中心扩展到传感器感知的鲁棒性，为自适应感知系统在不确定环境中的鲁棒运行奠定基础。

中文摘要: 近年来，6D物体姿态估计在代表性基准（如LM-O、YCB-V和T-Less）上取得了高性能。然而，这些数据集在固定光照和相机设置下采集，未充分探索真实环境中光照、曝光、增益或深度模式变化的影响，以及测试时传感器控制的潜力。为填补这一空白，我们提出了SenseShift6D，首个通过物理调整13种RGB曝光、9种RGB增益、自动曝光、4种深度模式和5种光照水平的RGB-D数据集。针对三种常见家用物品（喷雾罐、薯片罐和锡盒），我们采集了101.9k RGB和10k深度图像，每种物体姿态可提供1,380种独特的传感器-光照组合。在数据集上的实验表明，测试时传感器控制比数字数据增强更能提升性能，效果可与增加真实世界训练数据量和多样性相媲美。单独调整RGB或深度传感器均有效，而联合调整多模态RGB-D配置效果更佳。SenseShift6D将6D姿态评估范式从数据为中心扩展到传感器感知的鲁棒性，为自适应、自调节感知系统在不确定真实环境中的鲁棒运行奠定基础。数据集和脚本分别发布于huggingface.co/datasets/Yegyu/SenseShift6D和github.com/yegyu-han/SenseShift6D。

</details>


### [95] [Normal Patch Retinex Robust Alghoritm for White Balancing in Digital Microscopy](https://arxiv.org/abs/2507.05757)
**中文标题：用于数字显微镜白平衡的Normal Patch Retinex鲁棒算法**

*Radoslaw Roszczyk,Artur Krupa,Izabella Antoniuk*

主要分类: cs.CV

摘要简述: 本文提出了一种全自动的白平衡算法，用于校正显微镜图像的色彩，实验证明其在病理学和免疫组化染色图像中优于传统算法。


<details>
  <summary>详细信息</summary>
研究动机: 显微镜操作中获取色彩准确的图像具有挑战性，传统白平衡算法在显微镜图像中效果不佳，因此需要一种更有效的自动校正方法。

研究方法: 提出了一种基于Normal Patch Retinex的自动白平衡算法，通过实验验证其在200张显微镜图像上的表现，并与传统算法进行对比。

研究结果: 实验结果表明，该算法在染色为hematoxylin-phloxine-saffron的显微镜图像和免疫组化染色图像中，效果优于传统白平衡算法。

研究结论: 该自动白平衡算法在显微镜图像中表现出色，尤其适用于病理学和免疫组化领域，为色彩校正提供了更优解决方案。

中文摘要: 在光学显微镜中获取色彩准确且平衡的图像即使对经验丰富的操作者也是一项挑战。本文提出了一种全自动的白平衡机制，能够有效校正显微镜彩色图像。该算法在200张显微镜图像上进行了实验验证，这些图像包含三种常用于病理形态学的标本扫描结果。同时，与其他常用于数字摄影的白平衡算法进行了对比。实验表明，该算法在染色为hematoxylin-phloxine-saffron的显微镜图像和免疫组化染色图像中，效果优于传统色彩摄影算法。

</details>


### [96] [DreamArt: Generating Interactable Articulated Objects from a Single Image](https://arxiv.org/abs/2507.05763)
**中文标题：DreamArt：从单张图像生成可交互的铰接物体**

*Ruijie Lu,Yu Liu,Jiaxiang Tang,Junfeng Ni,Yuxiang Wang,Diwen Wan,Gang Zeng,Yixin Chen,Siyuan Huang*

主要分类: cs.CV

摘要简述: DreamArt提出了一种从单张图像生成可交互的铰接物体的新框架，通过三阶段流程实现高质量、可交互的3D资产生成。


<details>
  <summary>详细信息</summary>
研究动机: 当前图像到3D的方法主要关注表面几何和纹理，忽略了部件分解和铰接建模。而神经重建方法依赖密集多视图或交互数据，限制了其扩展性。DreamArt旨在解决这些问题，提供一种从单视图图像生成高质量铰接物体的方法。

研究方法: DreamArt采用三阶段流程：1) 通过图像到3D生成、掩码提示的3D分割和部件补全重建部件分割的完整3D网格；2) 微调视频扩散模型以捕捉部件级铰接先验，利用可移动部件掩码和遮挡补全图像减少歧义；3) 优化双四元数表示的铰接运动，并进行全局纹理优化和重绘以确保纹理一致性。

研究结果: 实验结果表明，DreamArt能够生成高质量的铰接物体，具有准确的部件形状、高保真外观和合理的铰接效果，为铰接资产生成提供了可扩展的解决方案。

研究结论: DreamArt通过创新的三阶段流程，成功实现了从单张图像生成高质量、可交互的铰接物体，为AR/VR和具身AI应用提供了重要工具。

中文摘要: 生成铰接物体（如笔记本电脑和微波炉）是具身AI和AR/VR中一项关键但具有挑战性的任务。当前的图像到3D方法主要关注表面几何和纹理，忽略了部件分解和铰接建模。同时，神经重建方法（如NeRF或高斯泼溅）依赖密集的多视图或交互数据，限制了其扩展性。本文提出DreamArt，一种从单视图图像生成高保真、可交互铰接资产的新框架。DreamArt采用三阶段流程：首先，通过图像到3D生成、掩码提示的3D分割和部件补全重建部件分割的完整3D网格；其次，微调视频扩散模型以捕捉部件级铰接先验，利用可移动部件掩码和遮挡补全图像减少歧义；最后，优化双四元数表示的铰接运动，并进行全局纹理优化和重绘以确保纹理一致性。实验结果表明，DreamArt能够生成高质量的铰接物体，具有准确的部件形状、高保真外观和合理的铰接效果，为铰接资产生成提供了可扩展的解决方案。项目页面见https://dream-art-0.github.io/DreamArt/。

</details>


### [97] [TalkFashion: Intelligent Virtual Try-On Assistant Based on Multimodal Large Language Model](https://arxiv.org/abs/2507.05790)
**中文标题：TalkFashion：基于多模态大语言模型的智能虚拟试穿助手**

*Yujie Hu,Xuanyu Zhang,Weiqi Li,Jian Zhang*

主要分类: cs.CV

摘要简述: 本文提出TalkFashion，一种基于多模态大语言模型的智能虚拟试穿助手，通过文本指令实现多功能虚拟试穿，包括全身换装和局部编辑，提升了灵活性和自动化程度。


<details>
  <summary>详细信息</summary>
研究动机: 现有虚拟试穿方法多依赖端到端网络，功能单一且缺乏灵活性。本文旨在通过大语言模型的多模态理解能力，实现基于文本指令的多功能虚拟试穿，提升用户体验。

研究方法: TalkFashion利用大语言模型分析用户指令，确定执行任务并激活相应处理流程。同时，提出基于指令的局部重绘模型，无需用户手动提供掩码，实现全自动局部编辑。

研究结果: 实验结果表明，TalkFashion在语义一致性和视觉质量上优于现有方法，验证了其多功能性和灵活性。

研究结论: TalkFashion通过结合多模态大语言模型和指令驱动的局部编辑，显著提升了虚拟试穿的灵活性和自动化水平，为未来研究提供了新方向。

中文摘要: 近年来，虚拟试穿技术取得了显著进展。本文探讨了如何仅通过文本指令实现多功能虚拟试穿，包括全身换装和局部编辑。现有方法主要依赖端到端网络执行单一试穿任务，缺乏多功能性和灵活性。我们提出了TalkFashion，一种智能试穿助手，利用大语言模型的强大理解能力分析用户指令并确定执行任务，从而激活不同的处理流程。此外，我们引入了一种基于指令的局部重绘模型，无需用户手动提供掩码。借助多模态模型，该方法实现了全自动局部编辑，提升了编辑任务的灵活性。实验结果表明，与现有方法相比，TalkFashion在语义一致性和视觉质量上表现更优。

</details>


### [98] [SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning](https://arxiv.org/abs/2507.05798)
**中文标题：SPADE：基于长程与局部上下文推理的空间感知去噪网络用于开放词汇全景场景图生成**

*Xin Hu,Ke Qin,Guiduo Duan,Ming Li,Yuan-Fang Li,Tao He*

主要分类: cs.CV

摘要简述: SPADE是一种新型空间感知去噪网络，通过逆扩散模型和空间感知上下文推理，显著提升了开放词汇全景场景图生成（PSG）的性能，特别是在空间关系预测方面。


<details>
  <summary>详细信息</summary>
研究动机: 现有的开放词汇全景场景图生成方法依赖预训练视觉语言模型（VLMs），但VLMs在空间关系推理方面存在固有局限性，如难以区分物体相对位置，导致关系预测效果不佳。

研究方法: SPADE框架包含两个关键步骤：(1) 通过逆扩散模型的交叉注意力图校准UNet，采用轻量级LoRA微调策略；(2) 设计空间感知关系图变换器，捕获局部和长程上下文信息，生成高质量关系查询。

研究结果: 在PSG和Visual Genome基准数据集上的实验表明，SPADE在封闭和开放场景中均优于现有方法，尤其在空间关系预测方面表现突出。

研究结论: SPADE通过结合逆扩散模型和空间感知推理，显著提升了开放词汇PSG的性能，为复杂场景中的空间关系理解提供了新思路。

中文摘要: 全景场景图生成（PSG）通过结合实例分割和关系理解，捕捉复杂场景中的像素级结构关系。尽管近期基于预训练视觉语言模型（VLMs）的方法在开放词汇设置中显著提升了性能，但它们普遍忽略了VLMs在空间关系推理中的固有局限性，例如难以区分物体相对位置，导致关系预测效果不佳。受去噪扩散模型逆过程在保留输入图像空间结构方面的启发，我们提出了SPADE（空间感知去噪网络）框架——一种用于开放词汇PSG的新方法。SPADE包含两个关键步骤：(1) 通过逆过程生成的交叉注意力图校准UNet，采用轻量级LoRA微调策略；(2) 设计空间感知关系图变换器，捕获局部和长程上下文信息，生成高质量关系查询。在PSG和Visual Genome基准数据集上的大量实验表明，SPADE在封闭和开放场景中均优于现有方法，尤其在空间关系预测方面表现突出。

</details>


### [99] [DREAM: Document Reconstruction via End-to-end Autoregressive Model](https://arxiv.org/abs/2507.05805)
**中文标题：DREAM：基于端到端自回归模型的文档重建**

*Xin Li,Mingming Gong,Yunfei Wu,Jianxin Dai,Antai Guo,Xinghua Jiang,Haoyu Cao,Yinsong Liu,Deqiang Jiang,Xing Sun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DREAM的自回归模型，用于端到端的文档重建，解决了传统多阶段方法中的错误传播问题，并保留了文档元素的布局信息。实验证明该方法在文档重建及相关子任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前文档重建方法多为多阶段模型，存在错误传播问题；而现有端到端生成模型虽能提取文本逻辑顺序，但忽略了布局信息。本文旨在解决这些问题，提出一种更全面的端到端文档重建方法。

研究方法: 提出DREAM模型，通过自回归方式将文本图像转换为文档重建序列，涵盖更广泛的文档元素信息。同时定义了文档重建任务的标准，并引入了新的评估指标DSM和数据集DocRec1K。

研究结果: 实验结果表明，DREAM在文档重建任务中表现卓越，同时在文档布局分析、文本识别、表格结构识别、公式识别和阅读顺序检测等子任务中具有竞争力。

研究结论: DREAM模型通过端到端自回归方法有效解决了文档重建中的错误传播和布局信息缺失问题，为文档分析领域提供了新的解决方案。

中文摘要: 文档重建是文档分析与识别领域的重要研究方向，近年来受到学术界广泛关注。许多研究使用多阶段模型对子任务进行预测，并通过启发式规则整合结果，但这种方法存在错误传播问题，性能不佳。此外，现有端到端生成模型虽能提取文本、表格和数学表达式的逻辑顺序，却忽略了布局信息。为此，本文提出了一种创新的自回归模型DREAM，通过端到端方式将文本图像转换为文档重建序列，全面保留文档元素信息。同时，我们定义了文档重建任务的标准，并引入了新的文档相似性度量（DSM）和数据集DocRec1K。实验证明，DREAM在文档重建任务中表现卓越，且在文档布局分析、文本识别、表格结构识别、公式识别和阅读顺序检测等子任务中具有竞争力。

</details>


### [100] [Towards Solar Altitude Guided Scene Illumination](https://arxiv.org/abs/2507.05812)
**中文标题：基于太阳高度的场景光照引导方法**

*Samed Doğan,Maximilian Hoh,Nico Leuze,Nicolas R. -Peña,Alfred Schöttl*

主要分类: cs.CV

摘要简述: 本文提出了一种基于太阳高度的全局条件变量方法，用于合成自动驾驶相机传感器数据，解决了白天光照变化标注稀缺的问题，并通过定制归一化方法准确捕捉光照特性和噪声。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶功能的开发依赖高质量传感器数据，但真实数据采集成本高且受限。现有研究缺乏对白天光照变化的关注，主要因标注稀缺。本文旨在填补这一空白，提出太阳高度作为全局条件变量，避免人工标注需求。

研究方法: 利用经纬度和当地时间计算太阳高度作为全局条件变量，结合定制归一化方法处理光照对微小高度变化的敏感性，应用于扩散模型中以生成合成数据。

研究结果: 实验表明，该方法能准确捕捉光照特性和图像噪声，尤其在扩散模型中表现优异。

研究结论: 太阳高度作为全局条件变量有效解决了白天光照变化标注稀缺问题，结合归一化方法显著提升了合成数据的质量。

中文摘要: 安全可靠的自动驾驶功能开发高度依赖大规模高质量传感器数据。然而，真实数据采集需要大量人力，且受标注成本、驾驶员安全协议和多样化场景覆盖等因素限制。因此，多项研究聚焦于条件生成合成相机传感器数据。我们发现白天光照变化的研究存在显著空白，可能因可用标注稀缺所致。为此，我们提出太阳高度作为全局条件变量，可直接通过经纬度坐标和当地时间计算，无需大量人工标注。我们还提出一种定制归一化方法，针对光照对太阳高度微小数值变化的敏感性。实验证明，该方法在扩散模型中能准确捕捉光照特性和依赖光照的图像噪声。

</details>


### [101] [Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework](https://arxiv.org/abs/2507.05814)
**中文标题：通过统一合成框架弥合数据鸿沟，赋能桥梁数字孪生**

*Wang Wang,Mingyu Shi,Jun Jiang,Wenqian Ma,Chong Liu,Yasutaka Narazaki,Xuguang Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种系统性框架，用于生成带有组件级实例标注、高保真色彩和精确法向量的完整3D桥梁点云数据，并扩展模拟多样化且物理真实的缺失点云，以支持分割和补全网络的训练。实验证明，合成数据训练的模型在真实桥梁语义分割和组件补全任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 桥梁作为关键交通基础设施，面临老化和损坏的挑战，传统人工检测效率低下。尽管3D点云技术提供了新范式，但实际数据的不完整性（如缺失标签和扫描遮挡）限制了其应用潜力。现有合成数据方法泛化能力不足，亟需突破。

研究方法: 提出一个系统性框架，自动生成完整的3D桥梁点云数据，包含组件级实例标注、高保真色彩和精确法向量。进一步扩展以模拟多样化且物理真实的缺失点云，用于支持分割和补全网络的训练。

研究结果: 实验表明，使用合成数据训练的PointNet++模型在真实桥梁语义分割任务中达到84.2%的平均交并比（mIoU）。同时，微调的KT-Net在组件补全任务中表现更优。

研究结论: 本研究为桥梁结构的3D视觉分析提供了创新方法和基础数据集，对推进基础设施的自动化管理和维护具有重要意义。

中文摘要: 作为关键交通基础设施，桥梁面临老化和损坏的日益严峻挑战，而传统人工检测方法效率低下。尽管3D点云技术提供了新的数据驱动范式，但其应用潜力常因实际数据的不完整性（如缺失标签和扫描遮挡）而受限。为克服现有合成数据方法泛化能力不足的瓶颈，本文提出了一种生成3D桥梁数据的系统性框架。该框架可自动生成带有组件级实例标注、高保真色彩和精确法向量的完整点云，并可进一步扩展以模拟多样化且物理真实的缺失点云，分别用于支持分割和补全网络的训练。实验表明，使用合成数据训练的PointNet++模型在真实桥梁语义分割任务中达到84.2%的平均交并比（mIoU）。同时，微调的KT-Net在组件补全任务中表现出更优性能。本研究为桥梁结构的3D视觉分析提供了创新方法和基础数据集，对推进基础设施的自动化管理和维护具有重要意义。

</details>


### [102] [2D Instance Editing in 3D Space](https://arxiv.org/abs/2507.05819)
**中文标题：3D空间中的2D实例编辑**

*Yuhuan Xie,Aoxuan Pan,Ming-Xian Lin,Wei Huang,Yi-Hua Huang,Xiaojuan Qi*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的“2D-3D-2D”框架，通过将2D对象提升为3D表示，在3D环境中进行编辑后再投影回2D图像，显著提升了编辑的一致性和对象身份保持能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的2D图像生成模型在编辑时难以保持一致性和对象身份，主要因其基于像素操作的本质。为了解决这一问题，本文提出了一种结合3D空间编辑的方法。

研究方法: 方法包括将2D对象提升为3D表示，在3D环境中进行物理合理且刚性约束的编辑，然后将编辑后的3D对象重新投影并无缝修复回原始2D图像。

研究结果: 实验表明，该方法在整体性能上优于现有2D编辑方法（如DragGAN和DragDiffusion），能够实现高度一致的编辑并稳健地保持对象身份。

研究结论: 本文提出的“2D-3D-2D”框架通过3D空间编辑显著提升了2D图像编辑的一致性和对象身份保持能力，为未来研究提供了新方向。

中文摘要: 生成模型在2D图像编辑方面取得了显著进展，表现出极高的精度和真实感。然而，由于其固有的像素操作特性，这些模型在一致性和对象身份保持方面往往表现不佳。为了解决这一局限性，我们提出了一种新颖的“2D-3D-2D”框架。我们的方法首先将2D对象提升为3D表示，使其能够在物理合理且刚性约束的3D环境中进行编辑。编辑后的3D对象随后被重新投影并无缝修复回原始2D图像。与现有的2D编辑方法（如DragGAN和DragDiffusion）相比，我们的方法直接在3D环境中操作对象。大量实验表明，我们的框架在整体性能上超越了以往方法，能够实现高度一致的编辑并稳健地保持对象身份。

</details>


### [103] [Video Event Reasoning and Prediction by Fusing World Knowledge from LLMs with Vision Foundation Models](https://arxiv.org/abs/2507.05822)
**中文标题：通过融合大型语言模型的世界知识与视觉基础模型实现视频事件推理与预测**

*L'ea Dubois,Klaus Schmidt,Chengyu Wang,Ji-Hoon Park,Lin Wang,Santiago Munoz*

主要分类: cs.CV

摘要简述: 本文提出了一种融合视觉基础模型（VFM）和大型语言模型（LLM）的新框架，通过知识驱动的推理模块提升视频事件的高层次认知任务（如因果推理和未来预测）能力。实验证明该模型在多个基准测试中表现优异，并具备零样本泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频理解模型在识别“发生了什么”方面表现优异，但在高层次认知任务（如因果推理和未来预测）上表现不足，主要原因是缺乏常识性世界知识。本文旨在通过融合视觉和语言模型来弥补这一认知差距。

研究方法: 提出了一种新颖的框架，通过Q-Former架构启发的融合模块，将复杂的时空和对象中心视觉特征转化为简洁的语言对齐表示。采用两阶段训练策略：先在大规模视频-文本数据上进行对齐预训练，再在专门设计的指令微调数据集上进行针对性训练。

研究结果: 模型在多个挑战性基准测试中达到最先进性能，并展现出对未见推理任务的零样本泛化能力。消融研究验证了各架构组件的关键贡献。

研究结论: 该工作将机器感知从简单识别推向真正的认知理解，为机器人、人机交互等领域更智能的AI系统奠定了基础。

中文摘要: 当前的视频理解模型在识别“发生了什么”方面表现出色，但在因果推理和未来预测等高层次认知任务上表现不足，这源于其缺乏常识性世界知识。为弥补这一认知差距，我们提出了一种新颖框架，将强大的视觉基础模型（VFM）用于深度视觉感知，与作为知识驱动推理核心的大型语言模型（LLM）协同融合。我们的关键技术创新是一个受Q-Former架构启发的复杂融合模块，它将复杂的时空和对象中心视觉特征提炼为简洁的语言对齐表示，使LLM能够有效地将其推理过程基于直接视觉证据。模型通过两阶段策略训练：首先在大规模视频-文本数据上进行对齐预训练，随后在专门设计的用于激发高级推理和预测能力的数据集上进行针对性指令微调。大量实验表明，我们的模型在多个挑战性基准测试中达到了最先进性能。值得注意的是，它展现出对未见推理任务的显著零样本泛化能力，而深入的消融研究验证了各架构组件的关键贡献。这项工作将机器感知的边界从简单识别推向真正的认知理解，为机器人、人机交互等领域更智能和强大的AI系统铺平了道路。

</details>


### [104] [I$^2$R: Inter and Intra-image Refinement in Few Shot Segmentation](https://arxiv.org/abs/2507.05838)
**中文标题：I²R：少样本分割中的图像间与图像内优化**

*Ourui Fu,Hangzhou He,Xinliang Zhang,Lei Zhu,Shuang Zeng,ZhaoHeng Xie,Yanye Lu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为I²R的新方法，通过聚合支持图像和查询图像的全局语义线索，以及采用方向性掩码策略，显著提升了少样本分割的性能。


<details>
  <summary>详细信息</summary>
研究动机: 少样本分割旨在通过少量样本快速泛化到新类别，但现有方法因支持图像与查询图像之间的语义差距以及图像内相似但语义不同的区域导致性能受限。本文旨在解决这些问题。

研究方法: 1) 使用类别特定的高层表示聚合支持图像和查询图像的全局语义线索，以更精确地定位跨图像区域；2) 采用方向性掩码策略抑制不一致的支持-查询像素对。

研究结果: 实验表明，I²R在PASCAL-5ⁱ和COCO-20ⁱ基准测试中，1-shot设置下的mIoU分别提升了1.9%和2.1%，优于现有方法。

研究结论: I²R通过解决跨图像和图像内的语义不一致问题，显著提升了少样本分割的性能，为相关领域提供了新的思路。

中文摘要: 语义分割中的标注瓶颈推动了少样本分割的广泛研究，其目标是通过少量样本快速泛化到新类别。传统训练范式通常从支持图像提取掩码区域特征生成查询先验图，并基于此进行预测。然而，现有方法仍受限于两个关键问题：1) 支持图像与查询图像间的语义差距导致特征不匹配和先验图不准确；2) 支持或查询图像中视觉相似但语义不同的区域导致误判。本文提出了一种名为I²R的新方法：1) 使用类别特定的高层表示聚合全局语义线索，以更精确地定位跨图像区域；2) 采用方向性掩码策略抑制不一致的支持-查询像素对。实验表明，I²R在PASCAL-5ⁱ和COCO-20ⁱ基准测试中，1-shot设置下的mIoU分别提升了1.9%和2.1%。

</details>


### [105] [USIGAN: Unbalanced Self-Information Feature Transport for Weakly Paired Image IHC Virtual Staining](https://arxiv.org/abs/2507.05843)
**中文标题：USIGAN：用于弱配对图像IHC虚拟染色的不平衡自信息特征传输**

*Yue Peng,Bing Xiong,Fuqiang Chen,De Eybo,RanRan Zhang,Wanming Hu,Jing Cai,Wenjian Qin*

主要分类: cs.CV

摘要简述: 本文提出了一种名为USIGAN的新方法，用于解决弱配对条件下IHC虚拟染色中的空间异质性问题，通过不平衡自信息特征传输技术提升生成结果的病理语义一致性。


<details>
  <summary>详细信息</summary>
研究动机: 在弱配对条件下，相邻切片间的空间异质性导致IHC虚拟染色任务中生成结果与病理语义不一致，亟需一种无需依赖位置对应的方法来提取全局形态语义。

研究方法: USIGAN通过去除联合边缘分布中的弱配对项，设计了不平衡最优传输一致性（UOT-CTM）机制和病理自对应（PC-SCM）机制，分别在图像级和组内级构建H&E与生成IHC之间的相关性矩阵。

研究结果: 在两个公开数据集上的实验表明，USIGAN在IoD和Pearson-R相关性等临床指标上表现优异，显著提升了生成结果的临床相关性。

研究结论: USIGAN通过不平衡自信息特征传输技术，有效解决了弱配对条件下的IHC虚拟染色问题，为病理分析提供了高效且经济的方法。

中文摘要: 免疫组织化学（IHC）虚拟染色是一项从H&E图像生成虚拟IHC图像的任务，同时保持与相邻切片的病理语义一致性。该任务旨在通过生成模型实现形态结构与染色模式之间的跨域映射，为病理分析提供高效且经济的解决方案。然而，在弱配对条件下，相邻切片间的空间异质性带来了显著挑战，可能导致不准确的一对多映射，并生成与相邻切片病理语义不一致的结果。为解决这一问题，我们提出了一种名为USIGAN的不平衡自信息特征传输方法，用于IHC虚拟染色。该方法无需依赖位置对应即可提取全局形态语义。通过去除联合边缘分布中的弱配对项，我们有效减轻了弱配对对联合分布的影响，从而显著提升了生成结果的内容一致性和病理语义一致性。此外，我们设计了不平衡最优传输一致性（UOT-CTM）机制和病理自对应（PC-SCM）机制，分别在图像级和组内级构建H&E与生成IHC之间的相关性矩阵。在两个公开数据集上的实验表明，我们的方法在IoD和Pearson-R相关性等临床指标上表现优异，具有更好的临床相关性。

</details>


### [106] [DFYP: A Dynamic Fusion Framework with Spectral Channel Attention and Adaptive Operator learning for Crop Yield Prediction](https://arxiv.org/abs/2507.05849)
**中文标题：DFYP：一种基于光谱通道注意力与自适应算子学习的动态融合框架用于作物产量预测**

*Juli Zhang,Zeyu Yan,Jing Zhang,Qiguang Miao,Quan Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DFYP的动态融合框架，结合光谱通道注意力和自适应算子学习，用于提高作物产量预测的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 由于复杂的空间模式、异质的光谱特性和动态的农业条件，基于遥感的作物产量预测仍是一项具有挑战性的任务。现有方法在空间建模能力和跨作物类型及年份的泛化性上表现不足。

研究方法: DFYP框架包含三个关键组件：(1) 分辨率感知通道注意力模块（RCA），通过基于分辨率特性的通道重加权增强光谱表示；(2) 自适应算子学习网络（AOL-Net），动态选择卷积核算子以提升边缘敏感的空间特征提取；(3) 双分支架构与可学习融合机制，联合建模局部空间细节和全局上下文信息。

研究结果: 在MODIS和Sentinel-2数据集上的实验表明，DFYP在不同空间分辨率、作物类型和时间段上均优于现有基线方法，RMSE、MAE和R2指标表现优异。

研究结论: DFYP框架通过动态融合光谱和空间特征，显著提升了作物产量预测的鲁棒性和泛化能力，适用于实际农业监测场景。

中文摘要: 基于遥感的作物产量预测由于复杂的空间模式、异质的光谱特性和动态的农业条件，仍是一项具有挑战性的任务。现有方法在空间建模能力和跨作物类型及年份的泛化性上表现不足。为解决这些问题，我们提出了DFYP，一种新颖的动态融合框架，结合光谱通道注意力、边缘自适应空间建模和可学习融合机制，以提高不同农业场景下的鲁棒性。具体而言，DFYP包含三个关键组件：(1) 分辨率感知通道注意力模块（RCA），通过基于分辨率特性的通道重加权增强光谱表示；(2) 自适应算子学习网络（AOL-Net），动态选择卷积核算子以提升边缘敏感的空间特征提取；(3) 双分支架构与可学习融合机制，联合建模局部空间细节和全局上下文信息，支持跨分辨率和跨作物的泛化。在MODIS和Sentinel-2数据集上的大量实验表明，DFYP在不同空间分辨率、作物类型和时间段上均优于现有基线方法，展示了其在真实农业监测中的有效性和鲁棒性。

</details>


### [107] [D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for Free-Viewpoint Videos](https://arxiv.org/abs/2507.05859)
**中文标题：D-FCGS：动态高斯泼溅的前馈压缩用于自由视点视频**

*Wenkang Zhang,Yan Zhao,Qiang Wang,Li Song,Zhengxue Cheng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为D-FCGS的前馈压缩框架，用于动态高斯点云序列的高效压缩，通过引入GoF结构和I-P帧编码，结合双先验熵模型，实现了高压缩率和视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 自由视点视频（FVV）需要高效的动态3D表示压缩方法，但现有方法通常依赖于场景重建与优化编码的耦合，限制了泛化能力。本文旨在解决这一问题。

研究方法: 提出D-FCGS框架，采用GoF结构和I-P帧编码，通过稀疏控制点提取帧间运动，并利用双先验熵模型压缩运动张量。重建时采用控制点引导的运动补偿和细化网络。

研究结果: 实验表明，D-FCGS在保持多视角视觉质量的同时，实现了超过40倍的压缩率，且在2秒内完成，性能与基于优化的方法相当。

研究结论: D-FCGS为动态3DGS的前馈压缩提供了新思路，推动了FVV在沉浸式应用中的可扩展传输与存储。

中文摘要: 自由视点视频（FVV）提供了沉浸式的3D体验，但动态3D表示的高效压缩仍是一个主要挑战。近年来，3D高斯泼溅（3DGS）及其动态扩展实现了高保真场景建模，但现有方法通常将场景重建与依赖优化的编码耦合，限制了泛化性。本文提出动态高斯泼溅的前馈压缩（D-FCGS），一种用于压缩时间相关高斯点云序列的新框架。该方法引入了帧组（GoF）结构和I-P帧编码，通过稀疏控制点提取帧间运动，并利用结合超先验和时空先验的双先验熵模型压缩运动张量。重建时采用控制点引导的运动补偿和细化网络提升视角一致性保真度。D-FCGS基于多视角视频衍生的高斯帧训练，无需逐场景优化即可泛化。实验表明，其性能与基于优化的方法相当，在2秒内实现超过40倍的压缩率，同时保持多视角视觉质量。这项工作推动了动态3DGS的前馈压缩，为沉浸式应用中的可扩展FVV传输与存储铺平了道路。

</details>


### [108] [GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing](https://arxiv.org/abs/2507.05887)
**中文标题：GeoMag：一种用于像素级细粒度遥感图像解析的视觉语言模型**

*Xianzhi Ma,Jianhui Li,Changhua Pei,Hao Liu*

主要分类: cs.CV

摘要简述: GeoMag是一种端到端的通用大型模型框架，用于遥感图像解析，通过动态调整注意力范围和语义裁剪，显著提升了像素级任务的性能并降低了计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有遥感视觉语言模型（RS-VLMs）主要局限于图像级和区域级任务，无法有效处理像素级任务，且在识别小物体时表现不佳，同时高分辨率遥感图像处理消耗大量计算资源。

研究方法: GeoMag引入了任务驱动的多粒度分辨率调整（TMRA）和提示引导的语义感知裁剪（PSC），动态优化任务相关区域的视觉表示，同时降低无关区域的分辨率。

研究结果: 在10个基准测试中，GeoMag不仅显著提升了像素级任务的性能，还在其他粒度任务中保持了竞争力，同时降低了计算成本。

研究结论: GeoMag通过动态注意力机制和语义裁剪，为遥感图像解析提供了一种高效且通用的解决方案，显著提升了模型性能并降低了资源消耗。

中文摘要: 视觉语言模型（VLMs）在遥感（RS）图像理解中的应用取得了显著进展，展示了识别和描述地理实体的基本能力。然而，现有的RS-VLMs大多局限于图像级和区域级任务，缺乏处理像素级任务的能力，且在小物体识别场景中表现不佳。此外，RS-VLMs在处理高分辨率RS图像时消耗大量计算资源，进一步限制了其实际应用。为此，我们提出了GeoMag（地理放大镜），一种端到端的通用大型模型框架，用于RS图像解析。GeoMag根据提示语义动态调整注意力范围，以有效执行多粒度遥感图像解析。该方法引入了任务驱动的多粒度分辨率调整（TMRA）和提示引导的语义感知裁剪（PSC），自适应地降低任务无关区域的空间分辨率，同时增强任务相关区域的视觉表示。这一方法提升了模型对关键目标区域的感知能力，抑制了背景冗余，并降低了高分辨率RS图像解析的计算成本。在10个基准测试上的广泛对比实验表明，GeoMag不仅在处理像素级任务时表现出色，还在其他粒度任务中保持了与现有RS-VLMs的竞争力。

</details>


### [109] [What You Have is What You Track: Adaptive and Robust Multimodal Tracking](https://arxiv.org/abs/2507.05899)
**中文标题：你所拥有即你所追踪：自适应且鲁棒的多模态跟踪**

*Yuedong Tan,Jiawei Shao,Eduard Zamfir,Ruanjun Li,Zhaochong An,Chao Ma,Danda Paudel,Luc Van Gool,Radu Timofte,Zongwei Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种自适应且鲁棒的多模态跟踪框架，通过动态激活计算单元应对数据缺失问题，显著提升了跟踪性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态数据虽能提升视觉跟踪的鲁棒性，但传感器同步问题常导致数据缺失，现有跟踪器因架构僵化无法适应此类情况，亟需灵活解决方案。

研究方法: 提出了一种基于异构专家混合融合机制的自适应框架，结合视频级掩码策略，动态调整计算单元以应对数据缺失率和场景复杂度。

研究结果: 在9个基准测试中取得最优性能，无论是完整数据还是缺失数据场景均表现卓越。

研究结论: 该框架不仅适应数据缺失，还能根据场景复杂度动态调整，为多模态跟踪提供了高效解决方案。

中文摘要: 多模态数据通过提升对外观变化的鲁棒性，被认为对视觉跟踪有益。然而，传感器同步问题常导致数据可用性受限，尤其是在视频场景中可能出现临时性短缺。尽管这一问题至关重要，但相关研究仍显不足。本文首次全面研究了在时间不完整多模态数据下的跟踪器性能。不出所料，现有跟踪器在此情况下表现显著下降，因其僵化架构缺乏应对缺失模态所需的适应性。为解决这些限制，我们提出了一种灵活的鲁棒多模态跟踪框架。我们认为跟踪器应根据数据缺失率动态激活计算单元。这通过一种新颖的异构专家混合融合机制实现，该机制具有自适应复杂性，并结合了视频级掩码策略，确保时间一致性和空间完整性，这对有效视频跟踪至关重要。令人惊讶的是，我们的模型不仅能适应不同缺失率，还能根据场景复杂度调整。大量实验表明，我们的模型在9个基准测试中均达到最优性能，无论是传统完整数据还是缺失模态场景均表现出色。代码和基准测试将公开于https://github.com/supertyd/FlexTrack/tree/main。

</details>


### [110] [On the Effectiveness of Methods and Metrics for Explainable AI in Remote Sensing Image Scene Classification](https://arxiv.org/abs/2507.05916)
**中文标题：遥感图像场景分类中可解释AI方法及评价指标的有效性研究**

*Jonas Klotz,Tom Burgert,Begüm Demir*

主要分类: cs.CV

摘要简述: 本文研究了遥感图像场景分类中可解释AI方法的有效性，分析了五种特征归因方法和十种评价指标，发现其局限性，并提供了选择方法和指标的指南。


<details>
  <summary>详细信息</summary>
研究动机: 遥感图像场景分类中的可解释AI方法多源自计算机视觉领域，直接应用于遥感场景可能不适用。本文旨在评估这些方法和指标在遥感领域的有效性。

研究方法: 通过方法论和实验分析，研究了五种特征归因方法（Occlusion、LIME、GradCAM、LRP和DeepLIFT）和十种评价指标（涵盖忠实性、鲁棒性、定位性、复杂性和随机性）在三个遥感数据集上的表现。

研究结果: 研究发现，基于扰动的方法（如Occlusion和LIME）受基线扰动和场景空间特征影响大；梯度方法（如GradCAM）在多标签图像中表现不佳；评价指标中，忠实性和定位性指标对大面积类别不可靠，而鲁棒性和随机性指标更稳定。

研究结论: 本文揭示了遥感场景分类中可解释AI方法和指标的局限性，并提供了选择方法和指标的实用指南。

中文摘要: 可解释人工智能（xAI）方法在遥感（RS）图像场景分类问题中的发展引起了广泛关注。大多数xAI方法及相关评价指标最初是为计算机视觉（CV）中的自然图像设计的，直接应用于RS可能并不合适。为解决这一问题，本文研究了遥感图像场景分类中解释方法和指标的有效性。具体而言，我们从方法论和实验上分析了十种评价指标（涵盖忠实性、鲁棒性、定位性、复杂性和随机性），并将其应用于五种特征归因方法（Occlusion、LIME、GradCAM、LRP和DeepLIFT）在三个RS数据集上的表现。方法论分析揭示了解释方法和指标的关键局限性。基于扰动的方法（如Occlusion和LIME）的性能高度依赖于扰动基线和RS场景的空间特征；梯度方法（如GradCAM）在多标签图像中表现不佳；而某些相关性传播方法（如LRP）可能将相关性分布与类别的空间范围不成比例。类似地，我们发现评价指标也存在局限性。忠实性指标与基于扰动的方法存在相同问题；定位性和复杂性指标对大面积类别不可靠；相比之下，鲁棒性和随机性指标表现出更高的稳定性。实验结果支持了这些方法论发现。基于分析，我们提供了在RS图像场景分类中选择解释方法、指标和超参数的指南。

</details>


### [111] [High-Resolution Visual Reasoning via Multi-Turn Grounding-Based Reinforcement Learning](https://arxiv.org/abs/2507.05920)
**中文标题：基于多轮定位强化学习的高分辨率视觉推理**

*Xinyu Huang,Yuhao Dong,Weiwei Tian,Bo Li,Rui Feng,Ziwei Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多轮对话的强化学习框架MGPO，通过自动裁剪关键视觉区域，提升大型多模态模型在高分辨率图像处理中的性能，无需额外标注数据。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型多模态模型在处理高分辨率图像时面临视觉令牌过多且无关的问题，而监督微调需要昂贵的标注数据。本文旨在通过强化学习自动聚焦关键区域，减少数据依赖。

研究方法: 提出多轮基于定位的策略优化（MGPO），通过强化学习框架迭代裁剪关键视觉区域，利用多轮对话模板解决冷启动问题，仅需二元奖励函数。

研究结果: 实验表明，MGPO在标准视觉问答数据上表现优异，无需标注数据即可提升定位能力，在MME-Realworld和V* Bench上分别提升5.4%和5.2%，并超越OpenAI的o1和GPT-4o模型。

研究结论: MGPO通过强化学习有效提升了大型多模态模型的视觉定位能力，为高分辨率图像处理提供了一种高效且无需标注的解决方案。

中文摘要: 当前最先进的大型多模态模型（LMMs）在处理高分辨率图像时面临挑战，因为这些输入被转换为大量视觉令牌，其中许多与下游任务无关。本文提出多轮基于定位的策略优化（MGPO），一种端到端的强化学习框架，使LMMs能够通过自动裁剪子图像，在多轮对话框架中基于模型预测的定位坐标迭代聚焦关键视觉区域。与需要昂贵额外定位标注的监督微调（SFT）相比，我们的方法表明LMMs可以在强化学习训练过程中涌现出稳健的定位能力，仅利用最终答案正确性衍生的二元奖励函数。此外，我们发现LMMs在展开过程中难以自主触发视觉定位。为解决这一冷启动问题，我们设计了一个多轮对话模板，并将策略损失计算限制在多个对话轮次生成的模型输出上，从而促进稳定优化。大量实验表明，在无需定位标注的标准视觉问答数据上训练时，MGPO相比GRPO能有效激发更强的定位能力，在分布内MME-Realworld和具有挑战性的分布外（OOD）V* Bench上分别提升5.4%和5.2%。值得注意的是，MGPO在Qwen2.5-VL-7B上使用21K样本进行后训练后，在OOD V* Bench上超越了OpenAI的o1和GPT-4o模型。代码发布于https://github.com/EvolvingLMMs-Lab/MGPO。

</details>


### [112] [Beyond Appearance: Geometric Cues for Robust Video Instance Segmentation](https://arxiv.org/abs/2507.05948)
**中文标题：超越外观：基于几何线索的鲁棒视频实例分割**

*Quanzhu Niu,Yikang Zhou,Shihao Chen,Tao Zhang,Shunping Ji*

主要分类: cs.CV

摘要简述: 本文提出通过引入几何感知（如单目深度估计）来增强视频实例分割（VIS）的鲁棒性，解决了遮挡、运动模糊和外观变化等挑战。通过三种集成方法（EDC、SV、DS）验证，EDC和SV显著提升了性能，其中EDC在OVIS基准上达到56.2 AP，创下新纪录。


<details>
  <summary>详细信息</summary>
研究动机: 视频实例分割（VIS）面临遮挡、运动模糊和外观变化等挑战，导致时间关联困难。本文旨在通过几何感知（如深度信息）提升VIS的鲁棒性。

研究方法: 研究了三种深度信息集成方法：1）EDC：将深度图作为输入通道与分割网络结合；2）SV：设计共享ViT主干，用于深度估计和分割；3）DS：将深度预测作为特征学习的辅助训练指导。

研究结果: 实验表明，EDC和SV显著提升了VIS的鲁棒性，其中EDC方法在Swin-L主干下达到56.2 AP，创下OVIS基准的新纪录。DS方法效果有限。

研究结论: 深度信息是提升视频理解鲁棒性的关键因素，EDC和SV方法验证了其有效性，为未来研究提供了方向。

中文摘要: 视频实例分割（VIS）在时间关联中面临遮挡、运动模糊和外观变化等挑战。为克服这些限制，本文引入几何感知（如单目深度估计）以增强VIS的鲁棒性。系统研究了三种集成范式：EDC方法将深度图作为输入通道与分割网络结合；SV方法设计共享ViT主干；DS方法利用深度预测作为特征学习的辅助训练指导。尽管DS效果有限，基准测试表明EDC和SV显著提升了VIS的鲁棒性。使用Swin-L主干时，EDC方法在OVIS基准上达到56.2 AP，创下新纪录。本文确立了深度信息对鲁棒视频理解的关键作用。

</details>


### [113] [High-Fidelity and Generalizable Neural Surface Reconstruction with Sparse Feature Volumes](https://arxiv.org/abs/2507.05952)
**中文标题：基于稀疏特征体积的高保真且可泛化的神经表面重建**

*Aoxiang Fan,Corentin Dumery,Nicolas Talabot,Hieu Le,Pascal Fua*

主要分类: cs.CV

摘要简述: 本文提出了一种基于稀疏特征体积的高保真且可泛化的神经表面重建方法，通过两阶段策略显著提升重建分辨率并减少存储需求。


<details>
  <summary>详细信息</summary>
研究动机: 当前通用的神经表面重建方法依赖密集3D特征体积，但随着体素分辨率提高，存储需求急剧增加，限制了重建质量。本文旨在解决这一问题。

研究方法: 采用两阶段方法：首先训练网络从姿态图像和深度图预测体素占用率，然后在占用率高的体素中计算特征并进行体积渲染。开发了定制算法以支持稀疏体积的高效采样和查询。

研究结果: 实验表明，该方法在公共数据集上存储需求降低50倍以上，支持512³分辨率重建（传统方法为128³），且重建精度优于现有技术。

研究结论: 稀疏特征体积方法显著提升了神经表面重建的分辨率和效率，为高保真重建提供了可行方案。

中文摘要: 可泛化的神经表面重建技术已成为一种从少量图像中无需逐场景优化即可重建的引人注目的方法，其中密集3D特征体积已被证明是场景的全局有效表示。然而，密集表示在体素分辨率增加时扩展性不佳，严重限制了重建质量。因此，我们提出了一种稀疏表示方法，最大化内存效率，并在标准硬件上实现显著更高分辨率的重建。我们通过两阶段方法实现：首先训练网络从姿态图像和关联深度图预测体素占用率，然后在占用率足够高的体素中计算特征并进行体积渲染。为支持这种稀疏表示，我们开发了定制算法，用于从稀疏体积中高效采样、特征聚合和查询，克服了现有工作中对密集体积的固有假设。在公共数据集上的实验表明，我们的方法在不降低性能的情况下将存储需求减少了50倍以上，支持512³分辨率重建（传统方法为128³），并在重建精度上优于当前最先进方法。

</details>


### [114] [Tora2: Motion and Appearance Customized Diffusion Transformer for Multi-Entity Video Generation](https://arxiv.org/abs/2507.05963)
**中文标题：Tora2：基于扩散变换器的多实体视频生成中的运动和外观定制**

*Zhenghao Zhang,Junchao Liao,Xiangyu Meng,Long Qin,Weizhi Wang*

主要分类: cs.CV

摘要简述: Tora2是Tora的增强版，通过解耦个性化提取器和门控自注意力机制，实现了多实体视频生成中的外观和运动定制，显著提升了多模态条件对齐和细粒度细节保留。


<details>
  <summary>详细信息</summary>
研究动机: 现有的扩散变换器模型（如Tora）在运动引导视频生成方面取得了进展，但在多实体外观和运动定制方面仍有不足。Tora2旨在通过改进设计，扩展其在多实体定制中的能力。

研究方法: Tora2引入了解耦的个性化提取器，生成多实体的全面个性化嵌入；设计了门控自注意力机制，整合轨迹、文本描述和视觉信息；并提出了对比损失，联合优化轨迹动态和实体一致性。

研究结果: 实验表明，Tora2在多实体外观和运动定制方面表现优异，与现有定制方法相比具有竞争力，同时提供了先进的运动控制能力。

研究结论: Tora2是首个实现多实体外观和运动同时定制的视频生成方法，标志着多条件视频生成领域的重要进展。

中文摘要: 近年来，扩散变换器模型（如Tora）在运动引导视频生成方面取得了显著进展。本文提出了Tora2，这是Tora的增强版本，通过多项设计改进扩展了其在外观和运动定制方面的能力。具体而言，我们引入了一种解耦的个性化提取器，为多个开放集实体生成全面的个性化嵌入，相比之前的方法更好地保留了细粒度的视觉细节。在此基础上，我们设计了一种门控自注意力机制，为每个实体整合轨迹、文本描述和视觉信息。这一创新显著减少了训练中多模态条件的错位。此外，我们提出了一种对比损失，通过运动与个性化嵌入之间的显式映射，联合优化轨迹动态和实体一致性。据我们所知，Tora2是首个实现多实体外观和运动同时定制的视频生成方法。实验结果表明，Tora2在定制性能上与最先进的方法竞争，同时提供了先进的运动控制能力，标志着多条件视频生成领域的关键进展。项目页面：https://github.com/alibaba/Tora。

</details>


### [115] [T-LoRA: Single Image Diffusion Model Customization Without Overfitting](https://arxiv.org/abs/2507.05964)
**中文标题：T-LoRA：无需过拟合的单图像扩散模型定制**

*Vera Soboleva,Aibek Alanov,Andrey Kuznetsov,Konstantin Sobolev*

主要分类: cs.CV

摘要简述: T-LoRA提出了一种基于时间步依赖的低秩适应框架，用于单图像扩散模型定制，解决了有限训练样本导致的过拟合问题，并在概念保真度和文本对齐之间取得了更好的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型微调在定制预训练模型以生成特定对象时，常因训练样本有限而出现过拟合，影响泛化能力和输出多样性。本文旨在解决仅使用单张图像进行模型定制的挑战，因其具有最大的实际潜力。

研究方法: T-LoRA是一种时间步依赖的低秩适应框架，包含两项创新：1）基于扩散时间步动态调整秩约束更新的微调策略；2）通过正交初始化确保适配器组件独立性的权重参数化技术。

研究结果: 实验表明，T-LoRA及其组件在概念保真度和文本对齐方面优于标准LoRA和其他扩散模型定制技术，适用于数据有限和资源受限的场景。

研究结论: T-LoRA在单图像扩散模型定制中表现出色，有效解决了过拟合问题，为数据受限场景提供了实用解决方案。

中文摘要: 尽管扩散模型微调为定制预训练模型以生成特定对象提供了强大方法，但在训练样本有限时常常出现过拟合，影响泛化能力和输出多样性。本文致力于解决仅使用单张概念图像进行扩散模型适配的挑战，因其具有最大的实际潜力。我们提出了T-LoRA，一种专为扩散模型个性化设计的时间步依赖低秩适应框架。研究表明，较高的扩散时间步比较低的时间步更容易过拟合，因此需要一种时间步敏感的微调策略。T-LoRA包含两项关键创新：1）基于扩散时间步动态调整秩约束更新的微调策略；2）通过正交初始化确保适配器组件独立性的权重参数化技术。大量实验表明，T-LoRA及其组件在概念保真度和文本对齐方面优于标准LoRA和其他扩散模型定制技术，展现了T-LoRA在数据有限和资源受限场景中的潜力。代码发布于https://github.com/ControlGenAI/T-LoRA。

</details>


### [116] [Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval](https://arxiv.org/abs/2507.05970)
**中文标题：高质量组合图像检索三元组数据的自动合成**

*Haiwen Li,Delong Liu,Zhaohui Hou,Zhicheng Zhao,Fei Su*

主要分类: cs.CV

摘要简述: 本文提出了一种自动生成高质量三元组数据的管道，并构建了完全合成的数据集CIRHS，用于提升组合图像检索（CIR）任务。通过结合大语言模型（LLM）和文本到图像生成模型，生成多样化的图像对，并引入新的检索框架CoAlign，实现了零样本和监督训练下的优异性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的组合图像检索方法依赖于昂贵的人工标注三元组数据，限制了其扩展性和零样本能力。为了解决这一问题，本文旨在开发一种自动生成高质量三元组数据的方案，并验证其在CIR任务中的有效性。

研究方法: 1. 提出自动生成三元组数据的管道，利用大语言模型生成多样化提示，控制文本到图像生成模型生成图像对；2. 构建完全合成的数据集CIRHS；3. 提出新的检索框架CoAlign，结合全局对齐和局部推理，提升模型表示能力。

研究结果: 1. 在零样本设置下，CoAlign在三个常用基准测试中表现优异；2. 在监督训练下，CoAlign超越了所有现有方法；3. 首次验证了完全合成数据集在CIR任务中的可行性。

研究结论: 本文提出的自动三元组生成管道和CoAlign框架显著提升了组合图像检索的性能，证明了合成数据在CIR任务中的潜力，为未来研究提供了新的方向。

中文摘要: 组合图像检索（CIR）是一项具有挑战性的视觉-语言任务，旨在通过多模态（图像+文本）查询检索目标图像。尽管现有许多CIR方法取得了显著性能，但其对昂贵人工标注三元组数据的依赖限制了扩展性和零样本能力。为解决这一问题，我们提出了一种自动生成三元组数据的可扩展管道，并构建了名为CIRHS的完全合成数据集。该管道利用大语言模型生成多样化提示，控制文本到图像生成模型生成具有相同元素的图像对，随后通过过滤和重组形成CIRHS数据集。此外，我们提出了混合上下文对齐（CoAlign）框架，能够在更广泛的上下文中实现全局对齐和局部推理，从而学习更鲁棒且信息丰富的表示。通过使用CIRHS数据集，CoAlign在三个常用基准测试中实现了优异的零样本性能，首次证明了完全合成数据集训练CIR模型的可行性。在监督训练下，我们的方法超越了所有现有方法，验证了检索框架的有效性。代码和CIRHS数据集将很快发布。

</details>


### [117] [Exploring Partial Multi-Label Learning via Integrating Semantic Co-occurrence Knowledge](https://arxiv.org/abs/2507.05992)
**中文标题：通过整合语义共现知识探索部分多标签学习**

*Xin Wu,Fei Teng,Yue Feng,Kaibo Shi,Zhuosheng Lin,Ji Zhang,James Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SCINet的新框架，用于解决部分多标签学习中的标签模糊性问题，通过语义共现知识和跨模态融合提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 部分多标签学习面临的核心挑战是如何准确识别标签与实例之间的模糊关系。本文强调，匹配标签与实例的共现模式是解决这一问题的关键。

研究方法: SCINet框架包含双主导提示模块，利用现成的多模态模型捕捉文本-图像相关性并增强语义对齐；跨模态融合模块联合建模标签间相关性、实例间关系及实例-标签分配的共现模式；此外，提出了一种内在语义增强策略，通过多样化的图像变换增强模型对数据语义的理解。

研究结果: 在四个广泛使用的基准数据集上的实验表明，SCINet优于现有最先进方法。

研究结论: SCINet通过整合语义共现知识和跨模态融合，有效解决了部分多标签学习中的标签模糊性问题，显著提升了模型性能。

中文摘要: 部分多标签学习旨在从不完全标注的数据中提取知识，这些数据包括已知正确标签、已知错误标签和未知标签。核心挑战在于准确识别标签与实例之间的模糊关系。本文强调，匹配标签与实例的共现模式是解决这一问题的关键。为此，我们提出了语义共现洞察网络（SCINet），这是一种新颖且有效的部分多标签学习框架。具体而言，SCINet引入了双主导提示模块，利用现成的多模态模型捕捉文本-图像相关性并增强语义对齐。为了强化实例与标签的相互依赖关系，我们开发了一个跨模态融合模块，联合建模标签间相关性、实例间关系以及实例-标签分配的共现模式。此外，我们提出了一种内在语义增强策略，通过应用多样化的图像变换增强模型对数据内在语义的理解，从而促进标签置信度与样本难度之间的协同关系。在四个广泛使用的基准数据集上的大量实验表明，SCINet超越了现有最先进方法。

</details>


### [118] [Ensemble-Based Deepfake Detection using State-of-the-Art Models with Robust Cross-Dataset Generalisation](https://arxiv.org/abs/2507.05996)
**中文标题：基于集成学习的Deepfake检测：利用先进模型实现鲁棒的跨数据集泛化**

*Haroon Wahab,Hassan Ugail,Lujain Jaleel*

主要分类: cs.CV

摘要简述: 本文提出了一种基于集成学习的方法，通过结合多个先进模型的预测概率，显著提升了Deepfake检测在不同数据集上的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于机器学习的Deepfake检测模型在基准数据集上表现优异，但在分布外数据上性能显著下降。本文旨在通过集成学习方法解决这一问题，提升模型的泛化性和稳定性。

研究方法: 研究基于开源基准，结合多个顶级会议提出的非对称模型的预测概率，构建集成模型。实验覆盖了两个不同的分布外数据集，验证了集成方法的有效性。

研究结果: 实验表明，单一模型在不同场景下表现不一致，而集成方法在所有场景中均提供了更稳定和可靠的性能。

研究结论: 非对称集成方法为现实世界中的Deepfake检测提供了一种鲁棒且可扩展的解决方案，尤其是在缺乏伪造类型或质量先验知识的情况下。

中文摘要: 基于机器学习的Deepfake检测模型在基准数据集上取得了显著成果，但其性能在分布外数据上往往大幅下降。本研究探讨了一种基于集成学习的方法，以提升Deepfake检测系统在不同数据集上的泛化能力。基于近期的一个开源基准，我们结合了多个顶级会议提出的非对称模型的预测概率。实验覆盖了两个不同的分布外数据集，结果表明，没有单一模型在所有场景中表现一致优于其他模型。相比之下，集成预测在所有场景中均提供了更稳定和可靠的性能。我们的结果表明，非对称集成方法为现实世界中的Deepfake检测提供了一种鲁棒且可扩展的解决方案，尤其是在缺乏伪造类型或质量先验知识的情况下。

</details>


### [119] [Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS](https://arxiv.org/abs/2507.05999)
**中文标题：无需GNSS的LiDAR点云与卫星图像地理配准**

*Xinyu Wang,Muhammad Ibrahim,Atif Mansoor,Ajmal Mian*

主要分类: cs.CV

摘要简述: 提出一种无需GNSS的LiDAR点云与卫星图像地理配准方法，通过道路骨架和交点对齐，结合RBF插值和地形校正，显著提升配准精度。


<details>
  <summary>详细信息</summary>
研究动机: 在GNSS信号受限的密集城市区域，现有依赖GNSS和IMU的方法常因定位不稳定而失效，亟需一种不依赖先验定位的配准方法。

研究方法: 使用预训练Point Transformer分割道路点，提取道路骨架和交点进行全局刚性对齐，再通过RBF插值局部优化，并基于SRTM地形数据校正高程。

研究结果: 在KITTI数据集上，平面配准标准差提升55.3%；在无GNSS的Perth数据集上，标准差提升77.4%，高程相关性分别提升30.5%和50.4%。

研究结论: 该方法有效解决了无GNSS环境下的LiDAR点云配准问题，显著提升了配准精度和高程一致性，适用于城市规模3D地图重建。

中文摘要: 在GNSS信号受限的高层建筑和桥梁密集城市区域，LiDAR点云的精确地理配准面临重大挑战。现有方法通常依赖实时GNSS和IMU数据，需预校准并假设数据采集期间定位稳定，但这一假设在密集城区常失效，导致定位误差。为此，我们提出一种结构化地理配准与空间校正方法，将3D点云与卫星图像对齐，无需依赖先验定位即可恢复GNSS信息并重建城市规模3D地图。该方法利用预训练Point Transformer模型分割道路点，从点云和目标地图中提取道路骨架和交点进行对齐。通过交点进行全局刚性对齐，再使用径向基函数（RBF）插值局部优化，并基于SRTM地形数据校正高程以解决垂直差异。在KITTI基准和本地采集的珀斯（西澳大利亚）CBD数据集上测试表明，在KITTI数据集上，平面配准标准差平均为0.84米（提升55.3%）；在无GNSS的珀斯数据集上，与Google Maps API提取的GPS数据相比，标准差为0.96米（提升77.4%）。高程相关性在KITTI和珀斯数据集上分别提升30.5%和50.4%。

</details>


### [120] [TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-Guided Supervision](https://arxiv.org/abs/2507.06033)
**中文标题：TextPixs：基于字形条件扩散的字符感知注意力与OCR引导监督**

*Syeda Anshrah Gillani,Mirza Samad Ahmed Baig,Osama Ahmed Khan,Shahid Munir Shah,Umema Mujeeb,Maheen Ali*

主要分类: cs.CV

摘要简述: 本文提出了一种名为GCDA的新框架，通过字符感知注意力和OCR引导监督，显著提升了文本到图像扩散模型中生成可读文本的能力。实验表明，GCDA在文本渲染和图像合成质量上均达到新的最优水平。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到图像扩散模型虽然能生成高质量图像，但无法生成可读且拼写正确的文本，限制了其在广告、教育和创意设计等领域的应用。本文旨在解决这一问题。

研究方法: GCDA框架包含三个模块：1) 双流文本编码器，同时编码语义和字形信息；2) 字符感知注意力机制，通过注意力分离损失避免字符变形；3) OCR引导的微调阶段，直接优化文本可读性和拼写准确性。

研究结果: 在MARIO-10M和T2I-CompBench等数据集上的实验表明，GCDA在字符错误率（0.08 vs 0.21）、单词错误率（0.15 vs 0.25）和人类感知评估上均优于现有方法，同时保持高保真图像合成质量（FID: 14.3）。

研究结论: GCDA通过结合字符感知注意力和OCR监督，显著提升了文本到图像模型中生成可读文本的能力，为实际应用提供了新的解决方案。

中文摘要: 现代文本到图像扩散模型的兴起为数字内容生产开辟了新纪元，其能够根据自然语言描述的语义生成逼真且风格多样的图像。然而，这些模型的共同缺陷是无法在生成的图像中生成可读、有意义且拼写正确的文本，这极大地限制了其在广告、学习和创意设计等实际用途中的应用。本文提出了一种新框架，即基于字形条件扩散的字符感知注意力（GCDA），通过三个精心设计的模块扩展了典型的扩散模型主干。首先，该模型采用双流文本编码器，同时编码语义上下文信息和显式字形表示，从而生成丰富的字符感知文本表示。其次，提出了一种字符感知注意力机制，并引入新的注意力分离损失，旨在独立限制每个字符的注意力分布以避免变形伪影。最后，GCDA包含一个OCR循环微调阶段，通过全文本感知损失直接优化模型的可读性和拼写准确性。在MARIO-10M和T2I-CompBench等基准数据集上的大规模实验表明，GCDA在所有指标上均达到了新的最优水平，包括文本渲染的字符级指标（字符错误率：0.08 vs 0.21；单词错误率：0.15 vs 0.25）、人类感知评估以及高保真图像合成质量（FID: 14.3）。

</details>


### [121] [VisualSpeaker: Visually-Guided 3D Avatar Lip Synthesis](https://arxiv.org/abs/2507.06060)
**中文标题：VisualSpeaker：视觉引导的3D虚拟形象唇部合成**

*Alexandre Symeonidis-Herzig,Özge Mercanoğlu Sincan,Richard Bowden*

主要分类: cs.CV

摘要简述: 本文提出VisualSpeaker，一种通过视觉语音识别监督的光真实感可微分渲染方法，显著提升3D面部动画的唇部合成质量，降低Lip Vertex Error指标56.1%。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D面部动画方法依赖网格域，难以充分利用2D计算机视觉和图形学的快速视觉创新。本文旨在通过光真实感渲染和视觉语音识别监督，提升3D面部动画的逼真度和表现力。

研究方法: 提出VisualSpeaker方法，利用光真实感3D高斯泼溅渲染技术生成虚拟形象，并通过预训练的视觉自动语音识别模型（VASR）计算感知唇读损失，优化3D面部动画。

研究结果: 在MEAD数据集上，VisualSpeaker将Lip Vertex Error指标降低56.1%，同时提升生成动画的感知质量，并保持网格驱动动画的可控性。

研究结论: VisualSpeaker通过视觉语音识别监督的光真实感渲染，显著提升了3D面部动画的唇部合成质量，尤其适用于需要精确口型的场景（如手语虚拟形象）。

中文摘要: 逼真且高保真的3D面部动画对于人机交互和可访问性中的表达性虚拟形象系统至关重要。尽管现有方法显示出良好的质量，但其对网格域的依赖限制了其充分利用2D计算机视觉和图形学中快速视觉创新的能力。我们提出VisualSpeaker，一种通过视觉语音识别监督的光真实感可微分渲染方法，用于改进3D面部动画。我们的贡献是一种感知唇读损失，通过在训练过程中将光真实感3D高斯泼溅虚拟形象渲染结果输入预训练的视觉自动语音识别模型来获得。在MEAD数据集上的评估表明，VisualSpeaker将标准Lip Vertex Error指标降低了56.1%，同时提升了生成动画的感知质量，并保持了网格驱动动画的可控性。这种感知焦点自然支持精确的口型，这对于消除手语虚拟形象中相似手势的歧义至关重要。

</details>


### [122] [MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding](https://arxiv.org/abs/2507.06071)
**中文标题：MEDTalk：通过解耦嵌入实现多模态控制的动态情感3D面部动画**

*Chang Liu,Ye Pan,Chenyang Ding,Susanto Rahardja,Xiaokang Yang*

主要分类: cs.CV

摘要简述: MEDTalk提出了一种新颖的多模态控制3D面部动画框架，通过解耦嵌入实现动态情感表达，结合音频、文本和参考图像生成逼真的面部表情和唇部同步。


<details>
  <summary>详细信息</summary>
研究动机: 现有音频驱动的3D面部动画方法多依赖静态预定义情感标签，限制了表情的多样性和自然性。MEDTalk旨在解决这一问题，实现更精细和动态的情感表达。

研究方法: MEDTalk通过跨重建过程解耦内容和情感嵌入空间，独立控制唇部运动和面部表情。结合音频、文本和参考图像，动态调整情感特征，生成逼真表情。

研究结果: MEDTalk生成的3D面部动画具有高度逼真的情感表达和唇部同步，支持多模态输入控制，便于工业流水线集成。

研究结论: MEDTalk通过解耦嵌入和多模态控制，显著提升了3D面部动画的情感表达多样性和自然性，适用于工业应用。

中文摘要: 音频驱动的情感3D面部动画旨在生成同步的唇部运动和生动的面部表情。然而，现有方法多依赖静态预定义情感标签，限制了其多样性和自然性。为解决这一问题，我们提出MEDTalk，一种新颖的框架，用于生成精细且动态的情感说话头部动画。我们的方法首先通过精心设计的跨重建过程从运动序列中解耦内容和情感嵌入空间，从而独立控制唇部运动和面部表情。除了传统的音频驱动唇部同步外，我们还整合了音频和语音文本，预测帧级强度变化并动态调整静态情感特征，以生成逼真的情感表达。此外，为增强控制和个性化，我们引入多模态输入（包括文本描述和参考表情图像）以指导生成用户指定的面部表情。以MetaHuman为优先，我们的生成结果可方便地集成到工业生产流水线中。

</details>


### [123] [MCAM: Multimodal Causal Analysis Model for Ego-Vehicle-Level Driving Video Understanding](https://arxiv.org/abs/2507.06072)
**中文标题：MCAM：用于车辆级驾驶视频理解的多模态因果分析模型**

*Tongtong Cheng,Rongzhen Li,Yixin Xiong,Tao Zhang,Jing Wang,Kai Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种新型多模态因果分析模型（MCAM），用于自动驾驶视频理解，通过构建视觉与语言模态间的潜在因果结构，解决了现有方法在浅层因果挖掘、跨模态伪相关及车辆级因果建模上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有驾驶行为识别方法常忽略深层因果关系，且未能有效处理跨模态伪相关及车辆级因果建模问题，限制了自动驾驶视频理解的准确性。

研究方法: MCAM采用多级特征提取器捕获长程依赖，设计因果分析模块动态建模驾驶场景的有向无环图（DAG），并利用视觉-语言Transformer对齐关键视觉特征与语言表达。

研究结果: 在BDD-X和CoVLA数据集上的实验表明，MCAM在视觉-语言因果关系学习中达到SOTA性能，并能有效捕捉视频序列中的因果特征。

研究结论: MCAM在自动驾驶应用中表现出色，为视频理解提供了有效的因果建模方法。

中文摘要: 准确的驾驶行为识别与推理对自动驾驶视频理解至关重要。然而，现有方法往往仅挖掘浅层因果关系，未能解决跨模态伪相关问题，且忽略了车辆级因果建模。为克服这些局限，我们提出了一种新型多模态因果分析模型（MCAM），构建视觉与语言模态间的潜在因果结构。首先，设计多级特征提取器捕获长程依赖；其次，设计因果分析模块，利用驾驶状态的有向无环图（DAG）动态建模驾驶场景；最后，采用视觉-语言Transformer对齐关键视觉特征与语言表达。在BDD-X和CoVLA数据集上的大量实验表明，MCAM在视觉-语言因果关系学习中达到SOTA性能，并能有效捕捉视频序列中的因果特征，展示了其在自动驾驶应用中的有效性。代码发布于https://github.com/SixCorePeach/MCAM。

</details>


### [124] [Discontinuity-aware Normal Integration for Generic Central Camera Models](https://arxiv.org/abs/2507.06075)
**中文标题：面向通用中心相机模型的不连续性感知法线积分**

*Francesco Milano,Manuel López-Antequera,Naina Dhingra,Roland Siegwart,Robert Thiel*

主要分类: cs.CV

摘要简述: 本文提出了一种新的法线积分方法，能够显式处理深度不连续性并适用于通用中心相机模型，通过局部平面性假设提升了精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有法线积分方法大多隐式处理深度不连续性，且仅适用于正交或理想针孔相机，无法满足通用中心相机模型的需求。本文旨在解决这一问题。

研究方法: 基于局部平面性假设，通过表面法线与射线方向之间的约束关系建模，显式处理深度不连续性，适用于通用中心相机模型。

研究结果: 在标准法线积分基准测试中取得了最先进的结果，首次直接支持通用中心相机模型。

研究结论: 本文方法显著提升了法线积分的精度和适用范围，为光度形状重建技术提供了更通用的解决方案。

中文摘要: 从表面法线图恢复3D表面（即法线积分）是光度形状重建技术（如形状从阴影和光度立体）的关键环节。现有大多数法线积分方法仅隐式处理深度不连续性，且仅限于正交或理想针孔相机。本文提出了一种新方法，能够显式建模不连续性并适用于通用中心相机模型。其核心思想是基于局部平面性假设，通过表面法线与射线方向之间的约束关系建模。与现有方法相比，本文方法更准确地近似了深度与表面法线之间的关系，在标准法线积分基准测试中取得了最先进的结果，并首次直接支持通用中心相机模型。

</details>


### [125] [ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models](https://arxiv.org/abs/2507.06078)
**中文标题：Error**

*Chihan Huang,Hao Tang*

主要分类: cs.CV

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [126] [CAST-Phys: Contactless Affective States Through Physiological signals Database](https://arxiv.org/abs/2507.06080)
**中文标题：CAST-Phys：基于生理信号的无接触情感状态数据库**

*Joaquim Comas,Alexander Joel Vera,Xavier Vives,Eleonora De Filippi,Alexandre Pereda,Federico Sukno*

主要分类: cs.CV

摘要简述: 本文介绍了CAST-Phys数据库，这是一个用于多模态远程生理情绪识别的高质量数据集，旨在通过无接触方式提取情绪信号，弥补现有数据集的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前情感计算研究中，多模态数据集的缺乏以及接触式设备对情绪体验的影响是主要瓶颈。因此，需要开发无接触的多模态情绪识别方法。

研究方法: 研究团队构建了CAST-Phys数据库，包含光电容积图（PPG）、皮肤电活动（EDA）、呼吸频率（RR）等生理信号，以及高分辨率无压缩面部视频，用于远程信号恢复和多模态情绪识别。

研究结果: 分析表明，生理信号在真实场景中至关重要，尤其是在面部表情无法提供足够情绪信息时。多模态融合显著提升了无接触情绪识别的效果。

研究结论: CAST-Phys数据库为无接触情绪识别技术提供了重要支持，展示了多模态方法在提升识别准确性方面的潜力。

中文摘要: 近年来，情感计算及其应用已成为快速发展的研究领域。尽管取得了显著进展，但缺乏多模态情感数据集仍然是开发准确情绪识别系统的主要瓶颈。此外，情绪诱发过程中使用接触式设备往往会无意中影响情绪体验，削弱或改变真实的自然情绪反应。这一局限性凸显了需要能够从多模态中提取情感线索且无需物理接触的方法，例如远程生理情绪识别。为此，我们提出了基于生理信号的无接触情感状态数据库（CAST-Phys），这是一个专为多模态远程生理情绪识别设计的高质量数据集，利用面部和生理线索。数据集包含多种生理信号，如光电容积图（PPG）、皮肤电活动（EDA）和呼吸频率（RR），以及高分辨率无压缩面部视频记录，为远程信号恢复提供了可能。我们的分析强调了生理信号在真实场景中的关键作用，尤其是在面部表情无法提供足够情绪信息时。此外，通过评估单个和融合模态的影响，我们展示了远程多模态情绪识别的潜力，证明了其在推动无接触情绪识别技术方面的有效性。

</details>


### [127] [Tile-Based ViT Inference with Visual-Cluster Priors for Zero-Shot Multi-Species Plant Identification](https://arxiv.org/abs/2507.06093)
**中文标题：基于分块ViT推理与视觉聚类先验的零样本多物种植物识别**

*Murilo Gustineli,Anthony Miyaguchi,Adrian Cheung,Divyansh Khattak*

主要分类: cs.CV

摘要简述: 本文介绍了DS@GT团队在PlantCLEF 2025挑战赛中获得第二名的解决方案，通过结合视觉Transformer、分块推理和视觉聚类先验，实现了无需额外训练的多物种植物识别。


<details>
  <summary>详细信息</summary>
研究动机: 解决植被样方图像中多物种植物识别的挑战，提出一种无需额外训练的高效识别方法。

研究方法: 方法包括：(i) 使用微调的视觉Transformer ViTD2PC24All进行分块推理，(ii) 采用4x4分块策略以匹配网络的518x518感受野，(iii) 通过PaCMAP + K-Means视觉聚类和地理位置过滤进行领域先验适应。

研究结果: 通过多数投票和聚类特定贝叶斯先验重新加权，实现了宏平均F1分数0.348（私有排行榜）。

研究结论: 该方法在无需额外训练的情况下，高效地实现了多物种植物识别，代码和脚本已公开。

中文摘要: 本文描述了DS@GT团队在PlantCLEF 2025挑战赛中获得第二名的解决方案，该挑战赛涉及植被样方图像中的多物种植物识别。我们的流程结合了：(i) 微调的视觉Transformer ViTD2PC24All用于分块推理，(ii) 4x4分块策略，使分块大小与网络的518x518感受野对齐，(iii) 通过PaCMAP + K-Means视觉聚类和地理位置过滤进行领域先验适应。分块预测通过多数投票和聚类特定贝叶斯先验重新加权，实现了宏平均F1分数0.348（私有排行榜），且无需额外训练。所有代码、配置文件和可复现脚本均已公开：https://github.com/dsgt-arc/plantclef-2025。

</details>


### [128] [Reflections Unlock: Geometry-Aware Reflection Disentanglement in 3D Gaussian Splatting for Photorealistic Scenes Rendering](https://arxiv.org/abs/2507.06103)
**中文标题：反射解锁：基于3D高斯泼溅的几何感知反射解耦实现逼真场景渲染**

*Jiayi Song,Zihan Ye,Qingyuan Zhou,Weidong Yang,Ben Fei,Jingyi Xu,Ying He,Wanli Ouyang*

主要分类: cs.CV

摘要简述: 本文提出Ref-Unlock，一种基于3D高斯泼溅的几何感知反射建模框架，通过显式解耦透射和反射成分，显著提升复杂反射场景的渲染质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法（如NeRF和3DGS）常将反射误认为物理几何，导致重建质量下降。传统几何约束不完整且泛化性差，高斯泼溅位置与实际几何不匹配，复杂场景下表面伪影和模糊问题加剧。

研究方法: 提出双分支表示法，结合高阶球谐函数捕捉高频反射细节；引入反射移除模块提供伪无反射监督；结合伪深度图和几何感知双边平滑约束，增强3D几何一致性和分解稳定性。

研究结果: 实验表明，Ref-Unlock显著优于传统基于GS的反射方法，与NeRF模型竞争，支持灵活视觉基础模型驱动的反射编辑。

研究结论: Ref-Unlock为反射场景的真实渲染提供了高效且泛化的解决方案。

中文摘要: 在新型视图合成中，准确渲染具有反射表面的场景仍是一个重大挑战，现有方法（如NeRF和3D高斯泼溅）常将反射误认为物理几何，导致重建质量下降。传统方法依赖不完整且泛化性差的几何约束，导致高斯泼溅位置与实际几何不匹配。处理复杂几何的真实场景时，高斯积累进一步加剧表面伪影和模糊问题。为解决这些问题，本文提出Ref-Unlock，一种基于3D高斯泼溅的几何感知反射建模框架，通过显式解耦透射和反射成分，更好地捕捉复杂反射并增强真实场景的几何一致性。该方法采用双分支表示法结合高阶球谐函数捕捉高频反射细节，并引入反射移除模块提供伪无反射监督以指导干净分解。此外，结合伪深度图和几何感知双边平滑约束，增强3D几何一致性和分解稳定性。大量实验表明，Ref-Unlock显著优于传统基于GS的反射方法，与NeRF模型竞争，同时支持灵活视觉基础模型驱动的反射编辑。该方法为反射场景的真实渲染提供了高效且泛化的解决方案。代码发布于https://ref-unlock.github.io/。

</details>


### [129] [Omni-Video: Democratizing Unified Video Understanding and Generation](https://arxiv.org/abs/2507.06119)
**中文标题：Omni-Video：民主化统一的视频理解与生成**

*Zhiyu Tan,Hao Yang,Luozheng Qin,Jia Gong,Mengping Yang,Hao Li*

主要分类: cs.CV

摘要简述: Omni-Video是一个高效统一的视频理解与生成框架，通过结合多模态大语言模型和扩散解码器，实现视频生成、编辑和理解任务。


<details>
  <summary>详细信息</summary>
研究动机: 当前基础模型主要专注于图像处理，视频理解与生成的统一模型发展不足。本文旨在填补这一空白，提出一个高效统一的视频框架。

研究方法: 1) 轻量级架构设计，在MLLMs顶部添加视觉头，生成视觉标记供扩散解码器使用；2) 高效多阶段训练方案，快速连接MLLMs和扩散解码器。

研究结果: 实验表明，该模型在视频生成、编辑和理解任务中表现出良好的泛化能力。

研究结论: Omni-Video为视频理解与生成提供了一个高效统一的解决方案，具有广泛的应用潜力。

中文摘要: 在统一的图像理解与生成建模方面取得的显著突破推动了图像理解、推理、生成和编辑的显著进步，然而当前的基础模型主要专注于图像处理，导致视频理解与生成的统一模型发展不足。本报告介绍了Omni-Video，一个高效统一的视频理解、生成以及基于指令编辑的框架。我们的核心思想是教导现有的多模态大语言模型（MLLMs）生成连续的视觉线索，作为扩散解码器的输入，从而生成高质量的基于这些视觉线索的视频。为了充分释放系统在统一视频建模中的潜力，我们整合了多项技术改进：1）轻量级架构设计，分别在MLLMs顶部添加视觉头和在扩散解码器输入前添加适配器，前者生成视觉标记供后者使用，后者将这些视觉标记适配到扩散解码器的条件空间；2）高效的多阶段训练方案，利用有限的数据和计算资源快速连接MLLMs和扩散解码器。实验证明，我们的模型在视频生成、编辑和理解任务中表现出令人满意的泛化能力。

</details>


### [130] [Prompt-Free Conditional Diffusion for Multi-object Image Augmentation](https://arxiv.org/abs/2507.06146)
**中文标题：无需提示的多目标图像增强条件扩散方法**

*Haoyu Wang,Lei Zhang,Wei Wei,Chen Ding,Yanning Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需提示的多目标图像增强条件扩散框架，通过局部-全局语义融合策略和LoRA知识注入，解决了现有方法在生成多目标图像时的类别偏差和多样性不足问题，并通过计数损失提升生成数据的数量一致性和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 现有扩散模型在多目标图像生成中，要么过度依赖文本条件导致生成对象与原始数据偏差，要么过度依赖原始图像导致多样性不足。本文旨在通过一种无需提示的条件扩散框架，同时解决这两个问题。

研究方法: 1. 提出局部-全局语义融合策略，从图像中提取语义替代文本条件；2. 通过LoRA注入知识，缓解原始模型与目标数据集的类别偏差；3. 设计基于奖励模型的计数损失，辅助传统重建损失，约束生成数据的类别数量一致性。

研究结果: 实验结果表明，该方法在多个代表性基线中表现优越，显著提升了下游任务性能，并展示了强大的跨域泛化能力。

研究结论: 本文提出的无需提示条件扩散框架有效解决了多目标图像生成中的类别偏差和多样性问题，为下游任务提供了高质量的数据增强支持。

中文摘要: 扩散模型在计算机视觉任务的数据集增强中取得了显著进展。然而，在生成多目标图像时，现有方法要么完全依赖文本条件，导致生成对象与原始数据偏差，要么过度依赖原始图像，导致生成图像多样性不足，对下游任务帮助有限。为解决这两个问题，我们提出了一种无需提示的多目标图像增强条件扩散框架。具体而言，我们引入局部-全局语义融合策略，从图像中提取语义替代文本条件，并通过LoRA注入知识，缓解原始模型与目标数据集的类别偏差。此外，我们设计了基于奖励模型的计数损失，辅助传统重建损失进行模型训练。通过约束每类对象的数量而非逐像素约束，弥合生成数据与原始数据的数量偏差，同时提升生成数据的多样性。实验结果表明，该方法在多个代表性基线中表现优越，并展示了强大的下游任务增益和跨域泛化能力。代码发布于\href{https://github.com/00why00/PFCD}{此处}。

</details>


### [131] [SoftReMish: A Novel Activation Function for Enhanced Convolutional Neural Networks for Visual Recognition Performance](https://arxiv.org/abs/2507.06148)
**中文标题：SoftReMish：一种用于增强卷积神经网络视觉识别性能的新型激活函数**

*Mustafa Bayram Gücen*

主要分类: cs.CV

摘要简述: 本文提出了一种新型激活函数SoftReMish，用于提升卷积神经网络（CNN）在图像分类任务中的性能。实验表明，SoftReMish在训练损失和验证准确率上均优于ReLU、Tanh和Mish等常用激活函数。


<details>
  <summary>详细信息</summary>
研究动机: 现有的激活函数（如ReLU、Tanh和Mish）在卷积神经网络的图像分类任务中表现有限，因此需要一种新的激活函数以进一步提升模型性能。

研究方法: 研究采用标准CNN架构（包含两个卷积层、最大池化和全连接层），在MNIST数据集上评估SoftReMish的性能，并将其与ReLU、Tanh和Mish进行对比。

研究结果: SoftReMish实现了最低训练损失（3.14e-8）和最高验证准确率（99.41%），显著优于其他激活函数。

研究结论: SoftReMish表现出更好的收敛性和泛化能力，是视觉识别任务中极具潜力的激活函数。

中文摘要: 本研究提出了一种新型激活函数SoftReMish，旨在提升卷积神经网络（CNN）在图像分类任务中的性能。实验采用标准CNN架构（包含两个卷积层、最大池化和全连接层），并在MNIST数据集上对SoftReMish进行评估。通过将其与ReLU、Tanh和Mish等常用激活函数进行对比，结果显示SoftReMish实现了最低训练损失（3.14e-8）和最高验证准确率（99.41%），优于其他所有测试函数。这些结果表明，SoftReMish具有更好的收敛行为和泛化能力，是视觉识别任务中的一种有前景的激活函数。

</details>


### [132] [Normalizing Diffusion Kernels with Optimal Transport](https://arxiv.org/abs/2507.06161)
**中文标题：基于最优传输的扩散核归一化**

*Nathan Kessler,Robin Magnet,Jean Feydy*

主要分类: cs.CV

摘要简述: 本文提出了一种基于最优传输的扩散核归一化方法，用于在不规则数据上实现类似拉普拉斯算子的平滑操作。


<details>
  <summary>详细信息</summary>
研究动机: 在机器学习和几何处理中，平滑信号是一个核心操作，但传统方法依赖于结构化的域（如向量空间或流形）上的拉普拉斯算子，而实际应用中数据往往不规则。本文旨在填补这一空白，提出一种适用于不规则数据的平滑方法。

研究方法: 通过引入一类广泛的平滑算子，基于相似性或邻接矩阵，并利用对称Sinkhorn算法将其归一化为扩散类算子，从而继承拉普拉斯算子的优良性质。

研究结果: 实验表明，归一化后的算子不仅能近似热扩散，还能保留拉普拉斯算子的谱信息，适用于点云、稀疏体素网格等不规则数据的形状分析与匹配。

研究结论: 本文提出的方法为不规则数据提供了一种有效的平滑工具，扩展了拉普拉斯算子的应用范围。

中文摘要: 基于局部邻域的信号平滑是机器学习和几何处理中的核心操作。在向量空间和流形等结构化域上，微分几何导出的拉普拉斯算子通过热扩散提供了一种理论保障的平滑方法。然而，构建此类拉普拉斯算子需要精心定义的域结构，而这在实际中并不总是可用。大多数从业者因此依赖于简单的卷积核和消息传递层，但这些方法对域边界存在偏差。我们通过引入一类广泛的平滑算子填补了这一空白，这些算子基于相似性或邻接矩阵，并证明它们可以归一化为扩散类算子，从而继承拉普拉斯算子的优良性质。我们的方法依赖于对称Sinkhorn算法，该算法通过重新缩放正平滑算子以匹配热扩散的结构行为。这一构造使得拉普拉斯类平滑和处理不规则数据（如点云、稀疏体素网格或高斯混合）成为可能。我们表明，所得算子不仅能近似热扩散，还能保留拉普拉斯算子本身的谱信息，应用于形状分析与匹配。

</details>


### [133] [OmniPart: Part-Aware 3D Generation with Semantic Decoupling and Structural Cohesion](https://arxiv.org/abs/2507.06165)
**中文标题：OmniPart：基于语义解耦与结构内聚的部分感知3D生成**

*Yunhan Yang,Yufan Zhou,Yuan-Chen Guo,Zi-Xin Zou,Yukun Huang,Ying-Tian Liu,Hao Xu,Ding Liang,Yan-Pei Cao,Xihui Liu*

主要分类: cs.CV

摘要简述: OmniPart是一种新型的3D对象生成框架，能够生成具有明确、可编辑部分结构的3D资产，通过语义解耦和结构内聚实现高效生成。


<details>
  <summary>详细信息</summary>
研究动机: 当前大多数3D生成方法只能生成整体形状，缺乏对部分结构的明确控制和编辑能力，限制了其应用范围。OmniPart旨在解决这一问题，通过语义解耦和结构内聚生成可编辑的3D部分结构。

研究方法: OmniPart将任务分为两个协同阶段：(1) 自回归结构规划模块生成可控的、可变长度的3D部分边界框序列，通过灵活的2D部分掩码引导；(2) 空间条件修正流模型从预训练的整体3D生成器中高效适配，同时合成所有3D部分并保持布局一致性。

研究结果: 实验表明，OmniPart在生成具有明确部分结构的3D对象方面表现优异，支持用户定义的部分粒度、精确定位，并适用于多种下游应用。

研究结论: OmniPart通过语义解耦和结构内聚实现了高效、可编辑的3D部分结构生成，为更可解释、可编辑和多功能3D内容铺平了道路。

中文摘要: 生成具有明确、可编辑部分结构的3D资产对于推动交互应用至关重要，但大多数生成方法仅能生成整体形状，限制了其应用。我们提出了OmniPart，一种新型的部分感知3D对象生成框架，旨在实现组件间的高语义解耦，同时保持强大的结构内聚性。OmniPart将这一复杂任务独特地解耦为两个协同阶段：(1) 自回归结构规划模块生成可控的、可变长度的3D部分边界框序列，关键是通过灵活的2D部分掩码引导，允许直观控制部分分解，而无需直接对应或语义标签；(2) 空间条件修正流模型从预训练的整体3D生成器中高效适配，同时合成所有3D部分并在规划布局中保持一致。我们的方法支持用户定义的部分粒度、精确定位，并适用于多种下游应用。大量实验表明，OmniPart实现了最先进的性能，为更可解释、可编辑和多功能的3D内容铺平了道路。

</details>


### [134] [Enhancing Scientific Visual Question Answering through Multimodal Reasoning and Ensemble Modeling](https://arxiv.org/abs/2507.06183)
**中文标题：通过多模态推理和集成建模提升科学视觉问答性能**

*Prahitha Movva,Naga Harshita Marupaka*

主要分类: cs.CV

摘要简述: 本文提出了一种通过多模态推理和集成建模提升科学视觉问答性能的方法，实验表明优化提示、链式推理和集成模型能显著提高模型表现。


<details>
  <summary>详细信息</summary>
研究动机: 科学文献中的图表数据对问答任务至关重要，但现有视觉问答方法在数值处理、多步推理和视觉-文本一致性方面存在不足，本文旨在解决这些问题。

研究方法: 采用5B至8B参数的模型进行实验，包括InternVL3和多个视觉语言模型的集成模型，结合提示优化和链式推理。

研究结果: InternVL3在SciVQA测试集上取得ROUGE-1和ROUGE-L F1分数0.740，BERTScore 0.983；集成模型进一步提升了性能，但InternVL3仍是最强单模型。

研究结论: 研究表明，提示优化、链式推理和集成建模能有效提升科学视觉问答能力，为未来研究提供了方向。

中文摘要: 技术报告和文章中常包含图表等半结构化数据，解读这些数据对问答任务至关重要。当前视觉问答方法在处理科学数据时，尤其在数值解析、多步推理和视觉-文本一致性方面表现不足。本文针对SciVQA 2025共享任务，提出了一种基于科学文献图表的视觉与非视觉问答方法。我们使用5B至8B参数的模型进行实验，其中最强的单模型InternVL3在SciVQA测试集上取得ROUGE-1和ROUGE-L F1分数0.740，BERTScore 0.983。我们还开发了多视觉语言模型的集成模型，验证集上的错误分析表明，集成方法提升了性能，但InternVL3仍是最强单模型。研究结果强调了提示优化、链式推理和集成建模对提升视觉问答能力的重要性。

</details>


### [135] [CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions](https://arxiv.org/abs/2507.06210)
**中文标题：CultureCLIP：通过合成图像和上下文增强标题赋予CLIP文化感知能力**

*Yuchen Huang,Zhiyuan Fan,Zhitao He,Sandeep Polisetty,Wenyan Li,Yi R. Fung*

主要分类: cs.CV

摘要简述: 本文提出CultureCLIP，通过合成图像和上下文增强的标题，赋予CLIP文化感知能力，显著提升细粒度文化概念识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 预训练视觉语言模型（如CLIP）在多模态理解中表现优异，但难以区分视觉相似但文化背景不同的概念，主要因缺乏高质量文化数据集和上下文知识。本文旨在解决这一问题。

研究方法: 设计数据生成流程，利用开源视觉语言模型和文本到图像扩散模型构建CulTwin数据集，包含视觉相似但文化背景不同的概念-标题-图像三元组。通过定制对比学习微调CLIP，生成CultureCLIP。

研究结果: 实验表明，CultureCLIP在文化相关基准测试中优于基础CLIP，某些任务中细粒度概念识别提升5.49%，同时保留CLIP的泛化能力。

研究结论: CultureCLIP通过合成数据和定制训练范式，有效捕捉文化细微差异，验证了数据合成和模型训练方法的有效性。

中文摘要: 预训练视觉语言模型（如CLIP）在多模态理解中表现优异，但难以区分视觉相似但文化背景不同的细粒度视觉特征，主要因缺乏高质量文化数据集、上下文知识和硬负样本。为解决这些问题，我们首先设计数据生成流程，利用开源视觉语言模型和文本到图像扩散模型构建CulTwin，一个合成文化数据集，包含视觉相似但文化背景不同的概念-标题-图像三元组。随后，我们通过定制对比学习微调CLIP，生成CultureCLIP，将文化概念与上下文增强标题和合成图像对齐，实现更细粒度的文化区分，同时保留泛化能力。在文化相关基准测试中，CultureCLIP优于基础CLIP，某些任务中细粒度概念识别提升5.49%，同时保留CLIP的原始泛化能力，验证了数据合成和视觉语言模型训练范式的有效性。

</details>


### [136] [Feed-Forward SceneDINO for Unsupervised Semantic Scene Completion](https://arxiv.org/abs/2507.06230)
**中文标题：基于前馈SceneDINO的无监督语义场景补全**

*Aleksandar Jevtić,Christoph Reich,Felix Wimbauer,Oliver Hahn,Christian Rupprecht,Stefan Roth,Daniel Cremers*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SceneDINO的无监督语义场景补全方法，通过自监督学习和多视角一致性训练，无需标注数据即可推断3D几何和语义信息，并在无监督场景理解中达到最先进水平。


<details>
  <summary>详细信息</summary>
研究动机: 传统的语义场景补全方法依赖昂贵的标注数据，限制了其应用范围。本文旨在探索无监督学习在语义场景补全中的潜力，减少对标注数据的依赖。

研究方法: SceneDINO结合自监督表示学习和2D无监督场景理解技术，通过多视角一致性自监督训练，从单张图像中推断3D几何和语义特征，并采用新颖的3D特征蒸馏方法获取无监督3D语义。

研究结果: SceneDINO在3D和2D无监督场景理解中均达到最先进的语义分割精度，其3D特征线性探测的精度与当前有监督方法相当，同时展示了良好的领域泛化性和多视角一致性。

研究结论: SceneDINO为单图像3D场景理解提供了强大的无监督基础，展示了无监督学习在语义场景补全中的潜力。

中文摘要: 语义场景补全（SSC）旨在从单张图像推断场景的3D几何和语义信息。与以往依赖昂贵标注数据的方法不同，本文提出了一种无监督的SSC方法SceneDINO。该方法结合自监督表示学习和2D无监督场景理解技术，仅通过多视角一致性自监督训练，无需任何语义或几何标注数据。给定单张输入图像，SceneDINO以前馈方式推断3D几何和表达性3D DINO特征，并通过新颖的3D特征蒸馏方法获取无监督3D语义。在3D和2D无监督场景理解中，SceneDINO均达到最先进的语义分割精度，其3D特征的线性探测精度与当前有监督SSC方法相当。此外，SceneDINO展示了领域泛化性和多视角一致性，为单图像3D场景理解奠定了初步基础。

</details>


### [137] [RSRefSeg 2: Decoupling Referring Remote Sensing Image Segmentation with Foundation Models](https://arxiv.org/abs/2507.06231)
**中文标题：RSRefSeg 2：基于基础模型的解耦式遥感图像参考分割**

*Keyan Chen,Chenyang Liu,Bowen Chen,Jiafan Zhang,Zhengxia Zou,Zhenwei Shi*

主要分类: cs.CV

摘要简述: RSRefSeg 2提出了一种解耦范式，通过分阶段协作框架（粗定位+精细分割）提升遥感图像分割的精度和语义理解能力，结合CLIP和SAM的优势，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前遥感图像分割方法在处理复杂语义关系和跨模态对齐时存在局限性，主要由于耦合机制导致目标定位与边界划分混淆，增加了错误传播并限制了模型的泛化性和可解释性。

研究方法: RSRefSeg 2采用双阶段协作框架：1）利用CLIP进行粗定位，生成语义提示；2）通过级联二阶提示器优化语义空间，再指导SAM生成精细分割掩码。

研究结果: 在RefSegRS、RRSIS-D和RISBench数据集上的实验表明，RSRefSeg 2的分割精度（gIoU）提升约3%，且在复杂语义理解上表现更优。

研究结论: RSRefSeg 2通过解耦设计和基础模型协作，显著提升了遥感图像分割的精度和语义理解能力，为未来研究提供了新方向。

中文摘要: 参考遥感图像分割通过视觉-语言协同解释为遥感场景分析提供了灵活且细粒度的框架。当前方法主要采用三阶段流程（双模态编码、跨模态交互和像素解码），但由于其耦合处理机制将目标定位与边界划分混为一谈，导致在管理复杂语义关系和实现精确跨模态对齐方面存在显著局限性。这种架构耦合在语义模糊性下放大了错误传播，同时限制了模型的泛化性和可解释性。为解决这些问题，我们提出了RSRefSeg 2，一种解耦范式，将传统流程重构为协作双阶段框架：粗定位后接精细分割。RSRefSeg 2通过策略性基础模型协作，将CLIP的跨模态对齐能力与SAM的分割泛化性相结合。具体而言，CLIP被用作双模态编码器，在其预对齐的语义空间中激活目标特征并生成定位提示。为缓解CLIP在多实体场景中的误激活问题，设计了一种级联二阶提示器，通过将文本嵌入分解为互补语义子空间进行隐式推理以提高精度。这些优化的语义提示随后指导SAM生成像素级精细掩码，从而完成语义传输流程。在RefSegRS、RRSIS-D和RISBench上的大量实验表明，RSRefSeg 2在分割精度（gIoU提升约3%）和复杂语义理解上超越了现有方法。代码发布于：https://github.com/KyanChen/RSRefSeg2。

</details>


### [138] [Learning to Track Any Points from Human Motion](https://arxiv.org/abs/2507.06233)
**中文标题：从人类运动中学习跟踪任意点**

*Inès Hyeonsu Kim,Seokju Cho,Jahyeok Koo,Junghyun Park,Jiahui Huang,Joon-Young Lee,Seungryong Kim*

主要分类: cs.CV

摘要简述: 论文提出了一种名为AnthroTAP的自动化流程，利用SMPL模型生成伪标注数据，用于训练点跟踪模型。该方法在TAP-Vid基准测试中表现优异，仅需少量数据和计算资源。


<details>
  <summary>详细信息</summary>
研究动机: 人类运动具有复杂的非刚性变形、关节运动和遮挡等特点，是训练点跟踪器的理想数据源，但手动标注成本高昂。因此，论文提出了一种自动化生成伪标注数据的方法。

研究方法: 论文提出AnthroTAP流程：首先使用SMPL模型拟合视频中的人体，将3D网格顶点投影到2D图像平面生成伪轨迹；通过光线投射处理遮挡，并基于光流一致性过滤不可靠轨迹。

研究结果: 在TAP-Vid基准测试中，AnthroTAP训练的点跟踪模型表现优于其他模型，仅需1天4块GPU和少量数据，而其他方法需256块GPU和大量数据。

研究结论: AnthroTAP通过自动化生成伪标注数据，显著降低了点跟踪模型的训练成本，同时实现了优异的性能。

中文摘要: 人类运动因其固有的复杂性（如非刚性变形、关节运动、衣物变形以及肢体或其他个体造成的频繁遮挡），为训练鲁棒且泛化能力强的点跟踪器提供了丰富而具有挑战性的监督信号。尽管人类运动非常适合，但由于手动标注的繁琐性，获取大规模点跟踪训练数据仍然困难。我们提出的流程AnthroTAP通过利用Skinned Multi-Person Linear（SMPL）模型，提出了一种自动化生成伪标注训练数据的方法。我们首先将SMPL模型拟合到视频帧中检测到的人体上，将生成的3D网格顶点投影到2D图像平面以生成伪轨迹，通过光线投射处理遮挡，并基于光流一致性过滤不可靠轨迹。在AnthroTAP标注数据集上训练的点跟踪模型在TAP-Vid基准测试中达到了最先进的性能，超越了其他基于真实视频训练的模型，同时仅使用了1/10,000的数据量，仅需4块GPU运行1天，而其他最新方法需256块GPU。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [139] [Strongly Solving $7 \times 6$ Connect-Four on Consumer Grade Hardware](https://arxiv.org/abs/2507.05267)
**中文标题：在消费级硬件上强解7×6 Connect-Four游戏**

*Markus Böck*

主要分类: cs.AI

摘要简述: 本文通过符号搜索方法成功构建了标准7×6 Connect-Four游戏的强解查找表，仅用47小时在单核CPU上完成89.6 GB的表格生成，并开源了包含最快获胜或最慢失败策略的工具。


<details>
  <summary>详细信息</summary>
研究动机: 尽管Connect-Four游戏已有数学解，但基于查找表的强解被认为不可行。本文旨在通过高效符号搜索方法实现这一目标。

研究方法: 采用基于二元决策图的符号搜索方法，结合高效实现，生成强解查找表，并整合alpha-beta搜索以优化策略。

研究结果: 成功生成89.6 GB的查找表，耗时47小时，覆盖标准7×6棋盘的所有胜负平局情况，并开源了相关工具。

研究结论: 通过符号搜索方法，实现了Connect-Four游戏的强解查找表，证明了其可行性，并提供了实用工具。

中文摘要: 尽管Connect-Four游戏已有数学解，且可通过搜索方法计算最佳移动，但基于查找表的强解被认为不可行。本文重新探讨了一种基于二元决策图的符号搜索方法，以生成强解。通过高效实现，我们在标准7×6棋盘上，仅用47小时在单核CPU和128 GB内存环境下生成了89.6 GB的查找表。除了胜负平局评估外，我们还开源了包含alpha-beta搜索的工具，以找到最快获胜或最慢失败的策略。

</details>


### [140] [Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management](https://arxiv.org/abs/2507.05283)
**中文标题：Chat2SPaT：基于大语言模型的交通信号控制计划管理自动化工具**

*Yue Wang,Miao Zhou,Guijing Huang,Rui Zhuo,Chao Yi,Zhenliang Ma*

主要分类: cs.AI

摘要简述: 本研究提出Chat2SPaT，一种基于大语言模型（LLM）的工具，用于将用户对交通信号控制计划的半结构化描述转换为精确的信号相位与时间（SPaT）结果，并通过Python脚本生成完整的信号控制计划，准确率超过94%。


<details>
  <summary>详细信息</summary>
研究动机: 传统的定时交通信号控制计划需要大量手动操作，尤其是当需要根据时间或日期调整计划时，重复输入参数的工作繁琐。Chat2SPaT旨在简化这一过程，提供用户友好的信号控制计划管理工具。

研究方法: Chat2SPaT利用大语言模型理解用户描述，将其转换为相位序列和属性的JSON格式结果，再通过Python脚本定位相位、处理信号控制细节，并组装完整的信号控制计划。用户可通过聊天界面迭代编辑计划。

研究结果: 实验表明，Chat2SPaT在超过300条计划描述的测试数据集上，中英文案例的准确率均超过94%，为交通从业者和研究人员提供了高效的计划管理工具。

研究结论: Chat2SPaT为大语言模型在智能交通系统（ITS）领域的应用提供了新范例，展示了其在信号控制计划管理中的潜力。

中文摘要: 定时交通信号控制通常用于信号交叉口和协调干道的运行，但其信号计划的创建和更新需要繁琐的手动操作。当使用基于时间或日期的计划时，一个交叉口通常关联多个计划，进一步增加了重复手动输入参数的工作量。为实现用户友好的交通信号控制计划管理，本研究提出Chat2SPaT，该方法将用户对信号控制计划的半结构化描述转换为精确的信号相位与时间（SPaT）结果，并可进一步转化为结构化阶段或环形计划，与智能交通系统（ITS）软件和信号控制器交互。通过精心设计的提示，Chat2SPaT首先利用大语言模型（LLM）理解用户计划描述的能力，将计划重新表述为相位序列和相位属性的JSON格式结果。基于LLM输出，设计了Python脚本以定位周期中的相位、处理交通信号控制的细节，并最终组装完整的信号控制计划。在聊天界面中，该流程可迭代用于进一步编辑计划。实验表明，Chat2SPaT在超过300条计划描述的测试数据集上，中英文案例的准确率均超过94%。作为首个评估LLM理解交通信号控制计划描述能力的基准，Chat2SPaT为交通从业者和研究人员提供了易用的计划管理流程，成为LLM在ITS领域更准确和多样化应用的潜在新模块。源代码、提示和测试数据集公开于https://github.com/yuewangits/Chat2SPaT。

</details>


### [141] [Fuzzy Classification Aggregation for a Continuum of Agents](https://arxiv.org/abs/2507.05297)
**中文标题：连续体代理的模糊分类聚合**

*Zijun Meng*

主要分类: cs.AI

摘要简述: 本文证明了对于连续体代理的模糊分类聚合函数，若满足最优、独立和零一致性，且分类对象为3个或更多、类型为2到对象数之间时，该函数必须为加权算术平均。


<details>
  <summary>详细信息</summary>
研究动机: 研究模糊分类聚合函数的性质，探讨在连续体代理情况下，满足特定条件的最优分类聚合形式。

研究方法: 通过数学证明，分析模糊分类聚合函数在满足最优性、独立性和零一致性条件下的可能形式。

研究结果: 证明了在给定条件下，模糊分类聚合函数必须为加权算术平均。

研究结论: 在连续体代理的模糊分类聚合中，加权算术平均是唯一满足最优、独立和零一致性的函数形式。

中文摘要: 我们证明，对于连续体代理的个体分类，若将3个或更多对象分为2到对象数之间的类型，任何最优、独立且零一致的模糊分类聚合函数必须为加权算术平均。

</details>


### [142] [OLG++: A Semantic Extension of Obligation Logic Graph](https://arxiv.org/abs/2507.05488)
**中文标题：OLG++：义务逻辑图的语义扩展**

*Subhasis Dasgupta,Jon Stephens,Amarnath Gupta*

主要分类: cs.AI

摘要简述: 本文提出OLG++，一种对义务逻辑图（OLG）的语义扩展，用于建模市政和跨辖区背景下的法规和法律规则。OLG++通过引入更丰富的节点和边类型（如空间、时间、团体、可废止性和逻辑分组结构），支持对法律义务、例外和层次结构的精细表示。


<details>
  <summary>详细信息</summary>
研究动机: 现有的法律知识表示模型在表达复杂法律规则（如空间约束、时间条件和例外结构）时存在局限性。OLG++旨在通过扩展OLG的语义能力，提供更灵活和强大的法律规则建模工具。

研究方法: OLG++扩展了OLG的节点和边类型，新增了空间、时间、团体、可废止性和逻辑分组结构。通过属性图查询，支持对法律问题的结构化推理。

研究结果: OLG++在食品业务法规的案例中展示了其表达能力，证明其优于现有的基于图的法律知识表示模型（如LegalRuleML），尤其是在支持子类关系、空间约束和例外结构方面。

研究结论: OLG++通过语义扩展显著提升了法律规则的表达能力，为复杂法律场景的建模和推理提供了更强大的工具。

中文摘要: 我们提出了OLG++，一种对义务逻辑图（OLG）的语义扩展，用于建模市政和跨辖区背景下的法规和法律规则。OLG++引入了更丰富的节点和边类型，包括空间、时间、团体、可废止性和逻辑分组结构，从而能够精细表示法律义务、例外和层次关系。该模型支持对具有上下文条件、优先级和复杂触发器的规则进行结构化推理。我们通过食品业务法规的案例展示了其表达能力，说明OLG++如何通过属性图查询支持法律问题解答。OLG++还通过原生支持子类关系、空间约束和具体化的例外结构，改进了LegalRuleML。我们的案例表明，OLG++在表达法律知识方面优于现有的基于图的模型。

</details>


### [143] [Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents](https://arxiv.org/abs/2507.05495)
**中文标题：深度研究比较器：用于深度研究代理细粒度人工标注的平台**

*Prahaladh Chandrahasan,Jiahe Jin,Zhihan Zhang,Tevin Wang,Andy Tang,Lucy Mo,Morteza Ziyadi,Leonardo F. R. Ribeiro,Zimeng Qiu,Markus Dreyer,Akari Asai,Chenyan Xiong*

主要分类: cs.AI

摘要简述: 本文介绍了Deep Research Comparator平台，用于对深度研究代理进行细粒度人工标注和评估，支持报告对比、中间步骤反馈和排名计算，并开发了Simple Deepresearch作为基线代理框架。


<details>
  <summary>详细信息</summary>
研究动机: 评估自主搜索、分析信息并生成报告的深度研究代理仍具挑战性，尤其是在长报告评估和中间步骤反馈方面。

研究方法: 开发了Deep Research Comparator平台，支持代理报告对比、中间步骤反馈和排名计算；同时设计了Simple Deepresearch作为基线代理框架。

研究结果: 通过17名标注者对三个深度研究代理的真实偏好数据验证了平台的有效性。

研究结论: 该平台为深度研究代理的开发提供了实用工具，支持细粒度评估和反馈。

中文摘要: 有效评估自主搜索网络、分析信息并生成报告的深度研究代理仍是一个重大挑战，尤其是在评估长报告和提供中间步骤详细反馈方面。为解决这些问题，我们提出了Deep Research Comparator平台，该平台提供了深度研究代理托管、并排比较、细粒度人工反馈收集和排名计算的整体框架。给定用户查询后，平台会显示两个不同代理的最终报告及其生成过程中的中间步骤。标注者可以通过并排比较评估最终报告的总体质量，并通过评估中间步骤或最终报告中的特定文本片段提供详细反馈。此外，我们开发了Simple Deepresearch，一个端到端的代理框架，作为基线，便于集成各种大型语言模型以将其转化为用于评估的深度研究代理。为展示平台在深度研究代理开发中的实用性，我们收集了17名标注者对三个深度研究代理的真实偏好数据。平台演示视频可在https://www.youtube.com/watch?v=g4d2dnbdseg观看。

</details>


### [144] [Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality](https://arxiv.org/abs/2507.05515)
**中文标题：增强现实中多模态训练助手的细粒度视觉-语言建模**

*Haochen Huang,Jiahuan Pei,Mohammad Aliannejadi,Xin Sun,Moonisa Ahsan,Pablo Cesar,Chuang Yu,Zhaochun Ren,Junxiao Wang*

主要分类: cs.AI

摘要简述: 本文研究了增强现实（AR）训练中的细粒度视觉-语言模型（VLMs），发现即使是先进模型如GPT-4o在细粒度任务中表现不佳，F1分数仅为40.54%，呼吁改进数据集和基准。


<details>
  <summary>详细信息</summary>
研究动机: 增强现实（AR）训练中的视觉-语言模型（VLMs）应用尚未充分探索，本文旨在填补这一空白，并为盲人和视障用户提供平等的AI学习机会。

研究方法: 作者构建了一个专门用于AR训练的数据集，并评估了九种先进的VLMs，包括GPT-4o，重点关注细粒度任务的表现。

研究结果: 实验结果显示，即使是先进的VLMs在细粒度任务中表现不佳，最高F1分数仅为40.54%，表明现有模型仍需改进。

研究结论: 本文强调了改进细粒度视觉-语言对齐的需求，并提供了数据集和源代码以支持未来研究，同时具有推动盲人和视障用户平等学习的社会意义。

中文摘要: 视觉-语言模型（VLMs）是实现AI智能助手在多模态环境中解释和推理的关键。然而，其在增强现实（AR）训练中的应用仍未被充分探索。本研究引入了一个专门为AR训练设计的综合数据集，包含系统化的视觉-语言任务，并评估了九种先进的VLMs。结果显示，即使是包括GPT-4o在内的先进模型，在细粒度装配任务中也表现不佳，状态检测的最高F1分数仅为40.54%。这些发现凸显了对改进数据集、基准和进一步研究的迫切需求，以提升细粒度视觉-语言对齐。除了技术贡献外，本研究还具有更广泛的社会意义，特别是为盲人和视障用户提供平等的AI驱动学习机会。我们提供了所有相关资源，包括数据集、源代码和评估结果，以支持研究社区。

</details>


### [145] [Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System](https://arxiv.org/abs/2507.05519)
**中文标题：利用s(CASP)目标导向谓词答案集编程系统建模（道义）模态运算符**

*Gopal Gupta,Abhiramon Rajasekharan,Alexis R. Tudor,Elmer Salazar,Joaquín Arias*

主要分类: cs.AI

摘要简述: 本文探讨了如何在目标导向的谓词答案集编程系统s(CASP)中优雅地实现道义模态逻辑，通过默认否定和强否定解决其悖论。


<details>
  <summary>详细信息</summary>
研究动机: 道义模态逻辑的实现是一个复杂问题，传统方法难以优雅处理其悖论。本文旨在利用答案集编程（ASP）的特性，特别是默认否定和强否定，为道义模态逻辑提供一种简洁且有效的表示方法。

研究方法: 作者提出利用ASP中的全局约束来表示道义模态逻辑的义务和禁止性。通过默认否定和强否定，将模态运算符嵌入到ASP框架中，从而解决道义模态逻辑中的悖论。

研究结果: 研究结果表明，所提出的方法能够优雅地解决道义模态逻辑中的各种悖论，验证了其在逻辑表示和推理中的有效性。

研究结论: 本文成功展示了如何利用ASP的特性实现道义模态逻辑，并通过全局约束和否定机制解决了其悖论，为逻辑编程领域提供了新的思路。

中文摘要: 本文探讨了道义模态逻辑的实现问题，展示了如何通过答案集编程（ASP）中的默认否定（否定即失败）和强否定优雅地表达（道义）模态运算符。我们提出利用ASP的全局约束来表示道义模态逻辑的义务和禁止性，并证明所提出的表示方法能够优雅地解决道义模态逻辑中的各种悖论。

</details>


### [146] [Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis](https://arxiv.org/abs/2507.05520)
**中文标题：培养多模态智能：皮肤病诊断中的解释性推理与代理RAG方法**

*Karishma Thakrar,Shreyas Basavatia,Akshay Daftardar*

主要分类: cs.AI

摘要简述: 该论文提出了一种结合多模态模型、结构化推理层和代理检索增强生成（agentic RAG）的方法，用于皮肤病诊断的视觉问答任务，并在2025年ImageCLEF MEDIQA-MAGIC挑战赛中取得第二名。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决远程医疗中的皮肤病诊断问题，尤其是在输入有限且需要高准确性和可解释性的情况下，通过模拟皮肤科医生的系统推理模式，提升自动化诊断支持系统的可靠性。

研究方法: 方法包括：（1）在竞赛数据集上微调开源多模态模型（Qwen、Gemma和LLaMA家族）；（2）引入结构化推理层以协调和裁决候选模型输出；（3）结合代理检索增强生成（agentic RAG），从美国皮肤病学会的症状和条件数据库中补充患者上下文信息。

研究结果: 团队在挑战赛中排名第二，提交的作品得分第六，展示了竞争力和高准确性。

研究结论: 该研究为远程医疗中的皮肤病诊断提供了可靠的技术路径，通过模拟皮肤科医生的推理模式，提升了自动化诊断系统的准确性和可解释性。

中文摘要: 2025年ImageCLEF MEDIQA-MAGIC挑战赛的第二版由微软、斯坦福大学和巴塞罗那医院诊所的研究人员共同组织，专注于使用真实患者查询和图像的多模态皮肤病问答和分割任务。本研究针对封闭式视觉问答（CVQA）任务，目标是根据用户提交的图像和伴随的症状描述，从多项选择题中选择正确答案。提出的方法结合了三个核心组件：（1）在竞赛数据集上微调开源多模态模型（Qwen、Gemma和LLaMA家族）；（2）引入结构化推理层以协调和裁决候选模型输出；（3）结合代理检索增强生成（agentic RAG），从美国皮肤病学会的症状和条件数据库中补充患者上下文信息。团队以第六名的得分获得第二名，展示了竞争力和高准确性。除了竞赛基准，本研究还解决了远程医疗中的一个实际问题：诊断决策通常需要在输入有限的情况下异步完成，且需要高准确性和可解释性。通过模拟皮肤科医生评估皮肤病的系统推理模式，该架构为更可靠的自动化诊断支持系统提供了技术路径。

</details>


### [147] [Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment](https://arxiv.org/abs/2507.05528)
**中文标题：大规模对话式教育：基于多LLM代理的程序性学习与教学质量评估工作流程**

*Jiahuan Pei,Fanghua Ye,Xin Sun,Wentao Deng,Koen Hindriks,Junxiao Wang*

主要分类: cs.AI

摘要简述: 本文提出WikiHowAgent，一种基于多LLM代理的工作流程，用于模拟教学互动对话，支持大规模程序性学习并评估教学质量。通过整合教师、学习者、交互管理器和评估器，结合大规模数据集和评估协议，验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究在利用大规模课程内容和评估教学质量方面存在不足，缺乏可扩展性。本文旨在通过多代理工作流程解决这些问题，推动AI在教育领域的应用。

研究方法: 提出WikiHowAgent，包含教师和学习者代理、交互管理器和评估器，模拟教学互动对话。基于14,287篇教程构建了114,296条对话数据集，结合计算指标、基于量表的评估和人工判断进行验证。

研究结果: 实验结果表明，该工作流程在不同场景下均表现有效，揭示了LLM在多领域的潜力。数据集和实现代码已开源。

研究结论: WikiHowAgent为程序性学习和教学质量评估提供了可扩展的解决方案，展示了LLM在教育中的广泛应用前景。

中文摘要: 大型语言模型（LLM）推动了虚拟教育者和学习者的发展，将自然语言处理（NLP）与AI教育（AI4Education）相结合。现有研究通常缺乏可扩展性，未能充分利用多样化的大规模课程内容，且教学质量评估框架有限。为此，我们提出WikiHowAgent，一种基于多代理工作流程的LLM模拟教学互动对话系统。该系统整合了教师和学习者代理、交互管理器和评估器，支持程序性学习并评估教学质量。我们引入了一个包含17个领域、727个主题的14,287篇教程为基础的114,296条教学对话数据集。评估协议结合了计算指标、基于量表的评估和人工判断对齐。结果表明，该工作流程在多样化场景中表现优异，揭示了LLM在多领域的潜力。数据集和实现代码已完全开源。

</details>


### [148] [Red Teaming AI Red Teaming](https://arxiv.org/abs/2507.05538)
**中文标题：红队测试AI红队测试**

*Subhabrata Majumdar,Brian Pendleton,Abhishek Gupta*

主要分类: cs.AI

摘要简述: 本文批判性地审视了AI红队测试的实践，指出当前AI红队测试过于关注模型层面的漏洞，而忽视了更广泛的社会技术系统和涌现行为。作者提出了一个包含宏观系统级和微观模型级的红队测试框架，并建议组建多功能团队以应对技术与社会因素的相互作用。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI红队测试在AI治理中备受关注，但其实践与红队测试作为批判性思维练习的初衷存在显著差距。作者认为现有方法过于聚焦于模型层面的缺陷，而忽略了社会技术系统和复杂交互带来的涌现风险。

研究方法: 作者提出了一个两层次的红队测试框架：宏观系统级红队测试覆盖AI开发生命周期，微观模型级红队测试聚焦具体模型漏洞。结合网络安全经验和系统理论，作者建议组建多功能团队，以全面评估技术与社会因素的相互作用。

研究结果: 研究发现，当前AI红队测试未能充分应对系统级风险和涌现行为。提出的框架和团队建议为更全面的红队测试提供了实践方向。

研究结论: 有效的AI红队测试需超越模型层面，关注系统级风险和社会技术交互。作者提出的框架和建议为未来红队测试实践提供了重要指导。

中文摘要: 红队测试从军事应用起源发展为网络安全和AI领域的广泛方法。本文批判性地审视了AI红队测试的实践，指出尽管其在AI治理中流行，但其作为批判性思维练习的初衷与生成式AI中仅关注模型缺陷的狭隘焦点存在显著差距。当前AI红队测试主要关注单个模型漏洞，而忽视了模型、用户和环境复杂交互带来的社会技术系统和涌现行为。为弥补这一不足，我们提出了一个两层次的红队测试框架：宏观系统级红队测试覆盖AI开发生命周期，微观模型级红队测试。借鉴网络安全经验和系统理论，我们进一步提出了一系列建议，强调有效的AI红队测试需要多功能团队，以评估涌现风险、系统漏洞及技术与社会因素的相互作用。

</details>


### [149] [SenseCF: LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation](https://arxiv.org/abs/2507.05541)
**中文标题：SenseCF：基于大型语言模型的反事实生成用于干预和传感器数据增强**

*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

主要分类: cs.AI

摘要简述: 本文提出SenseCF方法，利用大型语言模型（LLMs）生成反事实解释（CFs），用于干预和传感器数据增强。实验表明，该方法在零样本和三样本设置下生成高可信度、高有效性的CFs，并能提升下游分类器性能。


<details>
  <summary>详细信息</summary>
研究动机: 反事实解释（CFs）能为机器学习预测提供直观的干预建议和数据增强支持。传统方法在生成CFs时存在局限性，而大型语言模型（LLMs）的潜力尚未充分探索。本文旨在利用LLMs生成高质量的CFs，以提升临床和生理预测任务的可解释性和鲁棒性。

研究方法: 采用GPT-4o-mini模型，在零样本和三样本设置下生成反事实解释（CFs）。实验基于AI-Readi压力预测数据集和公开的心脏病检测数据集，与传统方法（如DiCE、CFNOW和NICE）进行对比。

研究结果: LLM生成的CFs在可信度（高达99%）、有效性（高达0.99）和稀疏性上表现优异。此外，将CFs作为增强数据可提升下游分类器性能（平均准确率提升5%），尤其在数据稀缺场景中效果显著。

研究结论: SenseCF展示了基于提示的生成技术在提升临床和生理预测任务可解释性和鲁棒性方面的潜力，为数据增强和干预提供了新思路。

中文摘要: 反事实解释（CFs）通过突出改变预测结果所需的最小变化，为机器学习预测提供了以人为中心的见解。因此，CFs可用于（i）异常预防的干预措施和（ii）增强数据以训练鲁棒模型。本文探索了大型语言模型（LLMs），特别是GPT-4o-mini，在零样本和三样本设置下生成CFs的能力。我们在两个数据集上评估了该方法：AI-Readi压力预测旗舰数据集和公开的心脏病检测数据集。与传统方法（如DiCE、CFNOW和NICE）相比，我们的少样本LLM方法实现了高可信度（高达99%）、强有效性（高达0.99）和竞争性稀疏性。此外，使用LLM生成的CFs作为增强样本可提升下游分类器性能（平均准确率提升5%），尤其在数据稀缺场景中效果显著。这表明基于提示的生成技术在增强临床和生理预测任务的可解释性和鲁棒性方面具有潜力。代码库：github.com/anonymous/SenseCF。

</details>


### [150] [SingLoRA: Low Rank Adaptation Using a Single Matrix](https://arxiv.org/abs/2507.05566)
**中文标题：SingLoRA：使用单矩阵的低秩适应**

*David Bensaïd,Noam Rotstein,Roy Velich,Daniel Bensaïd,Ron Kimmel*

主要分类: cs.AI

摘要简述: 本文提出SingLoRA，通过单矩阵分解实现低秩适应，解决LoRA中矩阵间尺度冲突问题，提升训练稳定性并减少参数量。


<details>
  <summary>详细信息</summary>
研究动机: 低秩适应（LoRA）在参数高效微调中表现优异，但其两矩阵间的尺度差异常导致训练不稳定和性能下降。本文旨在解决这一问题。

研究方法: SingLoRA将权重更新重新表述为单低秩矩阵与其转置的分解，消除矩阵间尺度冲突，确保优化稳定性，并减少约一半参数。

研究结果: 在多项任务中验证了SingLoRA的优势：在常识推理任务中，微调LLama 7B达到91.3%准确率，优于LoRA和LoRA+；在图像生成任务中，显著提升图像保真度。

研究结论: SingLoRA通过单矩阵分解设计，解决了LoRA的尺度冲突问题，显著提升了训练稳定性和性能，同时减少了参数量。

中文摘要: 低秩适应（LoRA）显著推动了大型预训练模型的参数高效微调。LoRA通过添加两个较小矩阵的乘积（构成低秩矩阵更新）来增强预训练模型的权重。近期研究表明，这两个矩阵之间的尺度差异常导致训练动态不稳定，从而影响性能。本文提出SingLoRA，将低秩适应重新表述为单低秩矩阵与其转置的分解。这一简单设计从根本上消除了矩阵间的尺度冲突，确保优化稳定性，并将参数量减少约一半。我们在无限宽度神经网络框架下分析了SingLoRA，证明其通过构造保证了稳定的特征学习。多项任务的广泛实验验证了这些优势：在常识推理任务中，使用SingLoRA微调LLama 7B在MNLI上达到91.3%的准确率，优于LoRA（89.1%）和LoRA+（90.2%），同时仅使用其60%的参数预算；在图像生成任务中，使用SingLoRA微调Stable Diffusion显著提升了DreamBooth上的图像保真度，DINO相似度得分为0.151，优于DoRA（0.148）和LoRA（0.143）。

</details>


### [151] [Towards Measurement Theory for Artificial Intelligence](https://arxiv.org/abs/2507.05587)
**中文标题：迈向人工智能的测量理论**

*Elija Perrier*

主要分类: cs.AI

摘要简述: 本文提出并概述了一个关于人工智能测量的正式理论计划，旨在通过标准化测量方法促进系统比较、风险分析及能力评估。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于通过形式化AI测量理论，使研究者、从业者和监管者能够比较不同系统及其评估方法，将前沿AI评估与工程和安全科学中的定量风险分析技术联系起来，并揭示AI能力的测量依赖性。

研究方法: 方法包括提出一个分层的测量框架，区分直接与间接可观测性，并探讨这些要素如何为AI现象的统一可校准分类提供路径。

研究结果: 结果展示了一个初步的测量理论框架，为AI能力的标准化评估和风险分析提供了理论基础。

研究结论: 结论强调形式化测量理论对AI研究的重要性，并指出其为未来统一分类和校准AI现象奠定了基础。

中文摘要: 我们提出并概述了一个关于人工智能测量的正式理论计划。我们认为，形式化AI测量将使研究者、从业者和监管者能够：（i）比较不同系统及其评估方法；（ii）将前沿AI评估与工程和安全科学中的定量风险分析技术联系起来；（iii）突显AI能力的测量依赖性。我们初步构建了一个分层的测量框架，区分直接与间接可观测性，并指出这些要素为AI现象的统一可校准分类提供了路径。

</details>


### [152] [MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models](https://arxiv.org/abs/2507.05591)
**中文标题：MLlm-DR：基于多模态大语言模型的可解释抑郁症识别**

*Wei Zhang,Juan Chen,En Zhu,Wenhong Cheng,YunPeng Li,Yanbo J. Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种新型多模态大语言模型MLlm-DR，用于可解释的抑郁症诊断，通过整合小型LLM和轻量级查询模块LQ-former，实现了对多模态信息的理解与诊断，并在两个基准数据集上取得了最佳效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有抑郁症自动诊断方法缺乏对评分依据的明确解释，限制了其临床应用。尽管大语言模型（LLM）为可解释诊断提供了可能，但现有多模态LLM缺乏针对访谈数据的训练，直接使用时诊断效果不佳。

研究方法: MLlm-DR结合小型LLM和轻量级查询模块LQ-former。小型LLM用于生成抑郁症评分及评估依据，并通过领域特定数据集微调以增强逻辑推理能力；LQ-former从语音和视觉数据中提取抑郁症相关特征，辅助多模态信息处理。

研究结果: MLlm-DR在CMDC和E-DAIC-WOZ两个基于访谈的基准数据集上取得了最先进的结果，证明了其有效性和优越性。

研究结论: MLlm-DR通过多模态信息理解和可解释诊断，为抑郁症自动诊断提供了高效且实用的解决方案。

中文摘要: 自动抑郁症诊断旨在通过分析访谈视频中的多模态信息来预测参与者的抑郁评分。以往研究往往缺乏对这些评分依据的明确解释，限制了其在临床实践中的应用。尽管大语言模型（LLM）的出现为可解释抑郁症诊断提供了可能，但当前能够处理多模态数据的LLM缺乏对访谈数据的训练，直接使用时诊断效果较差。本文提出了一种新型多模态大语言模型（MLlm-DR），能够理解多模态信息输入并支持可解释抑郁症诊断。MLlm-DR整合了一个小型LLM和一个轻量级查询模块（LQ-former）。具体而言，小型LLM用于生成抑郁评分及相应评估依据；为增强其在领域特定任务中的逻辑推理能力并保持实用性，我们构建了一个鲁棒的训练数据集对其进行微调。同时，LQ-former从语音和视觉数据中捕捉抑郁症相关特征，辅助模型处理多模态信息，以实现全面的抑郁症诊断。我们的方法在两个基于访谈的基准数据集（CMDC和E-DAIC-WOZ）上取得了最先进的结果，证明了其有效性和优越性。

</details>


### [153] [Domain adaptation of large language models for geotechnical applications](https://arxiv.org/abs/2507.05613)
**中文标题：大语言模型在岩土工程中的领域适配与应用**

*Lei Fan,Fangxue Liu,Cheng Chen*

主要分类: cs.AI

摘要简述: 本文综述了大语言模型（LLMs）在岩土工程领域的适应与应用，探讨了领域适配方法及其在岩土工程中的实际应用，为从业者和学者提供了整合LLMs的指南。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）的快速发展，其在岩土工程中的应用潜力巨大，但通用LLMs需经过领域适配才能有效发挥作用。本文旨在填补这一研究空白，为岩土工程领域提供LLMs适配与应用的全面综述。

研究方法: 本文通过调查LLMs在岩土工程中的适配方法，包括提示工程、检索增强生成、领域自适应预训练和微调，并分析了其在岩土工程中的实际应用案例。

研究结果: 研究发现，适配后的LLMs在岩土工程中表现出色，可应用于地质解释、地下特征描述、场地规划、设计计算、数值模拟、安全风险评估和教育辅导等领域，但也存在局限性。

研究结论: 本文为岩土工程从业者提供了整合LLMs的实用指南，并指出了未来研究的潜在方向，推动了这一跨学科领域的发展。

中文摘要: 近年来，大语言模型（LLMs）的发展为岩土工程和工程地质学带来了新的机遇。尽管通用LLMs具备广泛能力，但在岩土工程中的有效应用通常需要领域特定的适配。此类定制化的LLMs正越来越多地用于简化岩土工程工作流程。本文首次综述了LLMs在岩土工程中的适配与应用。文章概述了适配岩土领域的关键方法，包括提示工程、检索增强生成、领域自适应预训练和微调。调查探讨了适配后LLMs在岩土工程中的前沿应用，包括地质解释、地下特征描述、场地规划、设计计算、数值模拟、安全风险评估和教育辅导。同时，文章分析了适配后LLMs的优势与局限，并指出了这一跨学科领域未来研究的有前景方向。研究结果为从业者提供了整合LLMs的宝贵资源，同时也为学术界进一步研究奠定了基础。

</details>


### [154] [ADMC: Attention-based Diffusion Model for Missing Modalities Feature Completion](https://arxiv.org/abs/2507.05624)
**中文标题：ADMC：基于注意力的扩散模型用于缺失模态特征补全**

*Wei Zhang,Juan Chen,Yanbo J. Wang,En Zhu,Xuan Yang,Yiduo Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于注意力的扩散模型（ADMC），用于多模态情感和意图识别中的缺失模态特征补全。该方法通过独立训练各模态特征提取网络和注意力扩散网络，显著提升了缺失和完整模态场景下的识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态情感和意图识别中，传感器故障或数据不完整常导致模态缺失。传统方法在补全缺失信息时存在过耦合和生成不精确的问题，影响识别效果。本文旨在解决这些问题。

研究方法: ADMC框架独立训练各模态的特征提取网络，避免过耦合；通过注意力扩散网络（ADN）生成与真实多模态分布一致的缺失模态特征，提升补全效果。

研究结果: 在IEMOCAP和MIntRec基准测试中，ADMC在缺失和完整模态场景下均取得了最先进的识别效果。

研究结论: ADMC通过独立特征提取和注意力扩散生成，显著提升了多模态情感和意图识别的性能，尤其在模态缺失情况下表现突出。

中文摘要: 多模态情感和意图识别对于自动化人机交互至关重要，其目标是通过分析用户的语音、文本和视觉信息预测其情感或意图。然而，传感器故障或数据不完整常导致模态缺失。传统方法在补全缺失信息时存在过耦合和生成不精确的问题，导致效果不佳。为解决这些问题，我们提出了一种基于注意力的扩散模型（ADMC）。该框架独立训练各模态的特征提取网络，保留其独特性并避免过耦合。注意力扩散网络（ADN）生成的缺失模态特征与真实多模态分布高度一致，显著提升了所有缺失模态场景下的性能。此外，ADN的跨模态生成在完整模态场景下也能改善识别效果。我们的方法在IEMOCAP和MIntRec基准测试中取得了最先进的结果，证明了其在缺失和完整模态场景下的有效性。

</details>


### [155] [Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses](https://arxiv.org/abs/2507.05629)
**中文标题：利用LLM生成的检索练习问题提升学生学习效果：数据科学课程的实证研究**

*Yuan An,John Liu,Niyam Acharya,Ruhma Hashmi*

主要分类: cs.AI

摘要简述: 本研究探讨了利用大型语言模型（LLM）生成检索练习问题对学生学习的影响。通过实证研究发现，LLM生成的问题显著提高了学生的知识保留率，但需教师手动验证问题质量。


<details>
  <summary>详细信息</summary>
研究动机: 检索练习是一种有效的教学方法，但手动生成高质量问题耗时耗力。LLM可以自动化生成问题，但其对学生学习的效果尚未明确。本研究旨在验证LLM生成问题的实际效果。

研究方法: 研究在两门大学数据科学课程中进行，约60名学生参与。比较了一周内使用LLM生成的多选题与未使用时的学习效果。

研究结果: 使用LLM生成问题的学生知识保留率显著提高（平均准确率89%），而未使用时为73%。

研究结论: LLM生成的检索练习问题能有效支持学生学习，但需教师手动验证问题质量以确保效果。

中文摘要: 检索练习是一种公认的教学方法，能显著提升学生的学习和知识保留效果。然而，生成高质量的检索练习问题对教师而言通常耗时费力，尤其是在快速发展的技术领域。大型语言模型（LLM）通过响应提示生成问题，有望自动化这一过程，但LLM生成的检索练习对学生学习的效果尚待验证。本研究在两门大学数据科学课程中进行了实证研究，约60名学生参与。我们比较了学生在一周内接受LLM生成的多选题检索练习与未接受时的学习效果。结果显示，接触LLM生成问题的学生知识保留率显著更高（平均准确率89%），而未接受练习时为73%。这些发现表明，LLM生成的检索问题能有效支持学生学习，并为实时教学中集成检索练习提供了可扩展的解决方案。然而，尽管结果令人鼓舞且具有节省时间的潜力，仍需谨慎对待，因为LLM生成的问题质量可能参差不齐。教师在发布问题前仍需手动验证和修改。

</details>


### [156] [LLMs are Introvert](https://arxiv.org/abs/2507.05638)
**中文标题：大语言模型是内向的**

*Litian Zhang,Xiaoming Zhang,Bingyu Yan,Ziyi Zhou,Bo Zhang,Zhenyu Guan,Xi Zhang,Chaozhuo Li*

主要分类: cs.AI

摘要简述: 研究发现当前基于大语言模型（LLM）的信息传播模拟存在心理和行为动态的不足，提出结合社交信息处理理论和情感记忆的SIP-CoT机制，显著提升了LLM代理的社会智能和真实性。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体和生成式AI的快速发展加剧了错误信息的传播，传统模型和现有方法未能充分捕捉用户心理和行为动态，LLM因其类人推理能力为模拟信息传播的心理层面提供了新可能。

研究方法: 提出基于社交信息处理理论（SIP）的思维链（CoT）机制SIP-CoT，结合情感记忆，以改进LLM代理对社交线索的解释、目标个性化和反馈评估。

研究结果: 实验表明，SIP-CoT增强的LLM代理能更有效地处理社交信息，其行为、态度和情感更接近真实人类互动。

研究结论: 研究揭示了当前LLM模拟的局限性，并证明SIP-CoT和情感记忆的结合能显著提升LLM代理的社会智能和真实性。

中文摘要: 社交媒体和生成式AI的指数级增长改变了信息传播方式，既促进了连接，也加速了错误信息的扩散。理解信息传播动态并制定有效控制策略对减少有害内容至关重要。传统模型（如SIR）提供了基本见解，但未能充分捕捉在线互动的复杂性。包括注意力机制和图神经网络在内的先进方法提高了准确性，但通常忽略了用户心理和行为动态。大语言模型（LLM）因其类人推理能力，为模拟信息传播的心理层面提供了新潜力。我们引入了一个基于LLM的模拟环境，捕捉代理的态度、情感和反应的演变。然而，初步实验揭示了LLM生成行为与真实人类动态之间的显著差距，尤其是在立场检测和心理真实性方面。通过社交信息处理理论的详细评估，发现目标设定和反馈评估存在重大差异，源于标准LLM训练中情感处理的缺失。为解决这些问题，我们提出了基于社交信息处理的思维链（SIP-CoT）机制，并通过情感引导的记忆增强。该方法改进了对社交线索的解释、目标的个性化和反馈的评估。实验结果证实，SIP-CoT增强的LLM代理能更有效地处理社交信息，表现出更接近真实人类互动的行为、态度和情感。总之，本研究揭示了当前基于LLM的传播模拟的关键局限性，并展示了如何通过整合SIP-CoT和情感记忆显著提升LLM代理的社会智能和真实性。

</details>


### [157] [City-Level Foreign Direct Investment Prediction with Tabular Learning on Judicial Data](https://arxiv.org/abs/2507.05651)
**中文标题：基于司法数据表格学习的城市级外商直接投资预测**

*Tianxing Wu,Lizhe Cao,Shuang Wang,Jiming Wang,Shutong Zhu,Yerong Wu,Yuqing Feng*

主要分类: cs.AI

摘要简述: 本文提出了一种基于司法数据的表格学习方法（TLJD），用于城市级外商直接投资（FDI）预测，通过整合司法绩效指标并考虑区域差异，显著提升了预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 为实现联合国可持续发展目标中促进经济持续、包容性增长的目标，FDI对经济扩张和创新至关重要。传统基于经济数据（如GDP）的预测易受操纵，可靠性不足。因此，作者尝试利用反映司法绩效的大规模司法数据来提升FDI预测的可靠性。

研究方法: 首先构建了一个基于1200万份公开裁判文书的司法绩效评价指标体系，并据此重构表格数据集。随后提出TLJD方法，通过整合行数据和列数据对司法绩效指标进行编码，并利用专家混合模型调整不同指标的权重以考虑区域差异。

研究结果: 跨城市和跨时间任务的实验表明，TLJD在多种评价指标上均优于其他十种先进基线方法，R2分数至少达到0.92。

研究结论: TLJD通过司法数据显著提升了城市级FDI预测的准确性，为地方政府提供了更可靠的决策支持。

中文摘要: 为实现联合国可持续发展目标中促进持续、包容和可持续经济增长的目标，外商直接投资（FDI）在推动经济扩张和促进创新方面发挥着关键作用。精确的城市级FDI预测对地方政府至关重要，传统研究多基于经济数据（如GDP）。然而，此类数据易被操纵，导致预测可靠性不足。为解决这一问题，我们尝试利用反映司法绩效的大规模司法数据（影响地方投资安全和回报）进行城市级FDI预测。基于此，我们首先根据1200万份公开裁判文书构建了司法绩效评价指标体系，并据此重构表格数据集。随后提出了一种新的基于司法数据的表格学习方法（TLJD），用于城市级FDI预测。TLJD整合了表格数据集中的行数据和列数据以编码司法绩效指标，并利用专家混合模型调整不同指标的权重以考虑区域差异。为验证TLJD的有效性，我们设计了跨城市和跨时间的FDI预测任务。大量实验表明，TLJD在两种任务中均优于其他十种先进基线方法，R2分数至少达到0.92。

</details>


### [158] [Divergent Realities: A Comparative Analysis of Human Expert vs. Artificial Intelligence Based Generation and Evaluation of Treatment Plans in Dermatology](https://arxiv.org/abs/2507.05716)
**中文标题：分歧的现实：皮肤病学中人类专家与人工智能生成及评估治疗计划的比较分析**

*Dipayan Sengupta,Saumya Panda*

主要分类: cs.AI

摘要简述: 本研究比较了人类专家与两种AI模型（通用型和推理型）生成的皮肤病治疗计划，发现评估结果因评估者（人类或AI）而异，揭示了临床经验与数据驱动逻辑之间的差距。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在医疗领域的扩展，评估AI生成的治疗计划成为关键挑战。本研究旨在比较人类专家与AI模型生成的治疗计划，并探讨评估者的性质如何影响结果。

研究方法: 研究邀请了10名皮肤科医生、通用型AI（GPT-4o）和推理型AI（o3）为5个复杂皮肤病案例生成治疗计划。计划经过匿名化和标准化处理后，分两阶段评分：1）由10名人类专家评分；2）由高级AI评估者（Gemini 2.5 Pro）使用相同标准评分。

研究结果: 研究发现显著的“评估者效应”：人类专家评分显著高于AI生成的计划（均值7.62 vs. 7.16），而AI评估者则完全相反，AI计划评分显著高于人类计划（均值7.75 vs. 6.79）。推理型AI（o3）在人类评估中排名靠后，但在AI评估中排名第一。

研究结论: 临床计划的质量感知高度依赖评估者的性质。高级推理型AI在人类评估中表现不佳，但在AI评估中表现优异，揭示了临床经验与数据驱动逻辑之间的深刻差距。未来需要协同、可解释的人机系统以弥合这一差距。

中文摘要: 背景：随着AI扩展到诊断以外领域，评估AI生成的治疗计划成为关键挑战。本研究比较了人类专家与两种AI模型（通用型和推理型）生成的计划，并由人类同行和高级AI评估者评分。方法：10名皮肤科医生、通用型AI（GPT-4o）和推理型AI（o3）为5个复杂皮肤病案例生成治疗计划。匿名化、标准化的计划分两阶段评分：1）由10名人类专家评分；2）由高级AI评估者（Gemini 2.5 Pro）使用相同标准评分。结果：观察到显著的“评估者效应”。人类专家对同行生成的计划评分显著高于AI计划（均值7.62 vs. 7.16），而AI评估者则相反，AI计划评分显著高于人类计划（均值7.75 vs. 6.79）。推理型AI（o3）在人类评估中排名靠后，但在AI评估中排名第一。结论：临床计划的质量感知高度依赖评估者的性质，揭示了临床经验与数据驱动逻辑之间的深刻差距，未来需要协同、可解释的人机系统以弥合这一差距。

</details>


### [159] [An autonomous agent for auditing and improving the reliability of clinical AI models](https://arxiv.org/abs/2507.05755)
**中文标题：一种用于审计和改进临床AI模型可靠性的自主代理工具**

*Lukas Kuhn,Florian Buettner*

主要分类: cs.AI

摘要简述: 论文提出了一种名为ModelAuditor的自主代理工具，用于审计和改进临床AI模型的可靠性，通过模拟真实世界中的分布变化，生成可解释的报告，并显著提升模型在部署中的性能。


<details>
  <summary>详细信息</summary>
研究动机: 临床AI模型在基准测试中表现优异，但在真实世界中可能因硬件、光照或人口统计等微小变化而失效。目前缺乏高效、可解释的工具来识别和修复这些隐藏的故障模式。

研究方法: ModelAuditor是一种自反思代理，通过与用户对话、选择任务特定指标，模拟临床相关的分布变化，生成解释性能下降原因的报告，并提出修复策略。

研究结果: 在三种真实临床场景中，ModelAuditor成功识别了先进模型的故障模式，并通过针对性建议恢复了15-25%的性能损失，显著优于基线模型和现有增强方法。

研究结论: ModelAuditor提供了一种高效、低成本的方法，显著提升了临床AI模型在真实世界中的可靠性，为部署前的审计提供了实用工具。

中文摘要: 临床实践中部署AI模型面临一个关键挑战：在基准测试中表现优异的模型可能在真实世界的医学影像变化中彻底失效。扫描仪硬件、光照或人口统计的微小变化可能削弱准确性，但目前识别这些故障模式的可靠性审计是一个定制化且耗时的过程。从业者缺乏可访问且可解释的工具来暴露和修复隐藏的故障模式。本文介绍了ModelAuditor，一种自反思代理，可与用户对话，选择任务特定指标，并模拟临床相关的分布变化。ModelAuditor生成可解释的报告，说明部署中性能可能下降的程度，讨论具体的故障模式，并识别根本原因和缓解策略。我们在三种真实临床场景中进行了全面评估——组织病理学的机构间差异、皮肤病学的人口统计变化以及胸部放射学的设备异质性——结果表明，ModelAuditor能够正确识别先进模型（如已建立的SIIM-ISIC黑色素瘤分类器）的特定故障模式。其针对性建议恢复了真实世界分布变化下损失的15-25%性能，显著优于基线模型和现有增强方法。这些改进通过多代理架构实现，并在消费级硬件上10分钟内完成，每次审计成本低于0.50美元。

</details>


### [160] [Real-time monitoring of the SoH of lithium-ion batteries](https://arxiv.org/abs/2507.05765)
**中文标题：锂离子电池健康状态的实时监测**

*Bruno Jammes,Edgar Hernando Sepúlveda-Oviedo,Corinne Alonso*

主要分类: cs.AI

摘要简述: 本文提出了一种基于充电末期放电脉冲分析的创新方法，用于实时监测锂离子电池的健康状态（SoH），实验结果显示预测误差低且解释性高，有望集成到电池管理系统中。


<details>
  <summary>详细信息</summary>
研究动机: 实时监测电池健康状态（SoH）在微电网等受限环境中具有挑战性，传统方法难以适用，因此需要一种创新的解决方案。

研究方法: 通过分析充电末期的放电脉冲，提取等效电路模型的参数，用于估计电池的SoH。实验中使用了两块容量衰减约85%的电池进行训练，并预测了其他电池的衰减情况。

研究结果: 实验结果显示，预测的SoH误差在1%以内，解释性评分接近0.9，表明该方法具有高准确性和可靠性。

研究结论: 该方法性能优异，易于集成到电池管理系统（BMS）中，为持续运行下的电池优化管理提供了新途径。

中文摘要: 实时监测电池健康状态（SoH）仍是一个重大挑战，尤其是在微电网等运行受限的环境中，传统方法难以应用。作为4BLife项目的一部分，我们提出了一种基于充电末期放电脉冲分析的创新方法。通过提取描述电池端电压变化的等效电路模型参数，用于估计SoH。基于现有实验数据，初步结果证明了该方法的有效性。使用两块容量衰减约85%的电池参数进行训练后，我们成功预测了另外两块电池的衰减情况（SoH降至约90%），在最坏情况下平均绝对误差约为1%，估计器的解释性评分接近0.9。若这些性能得到进一步验证，该方法可轻松集成到电池管理系统（BMS）中，并为持续运行下的电池优化管理开辟新途径。

</details>


### [161] [GTA1: GUI Test-time Scaling Agent](https://arxiv.org/abs/2507.05791)
**中文标题：GTA1：图形用户界面测试时扩展代理**

*Yan Yang,Dongxu Li,Yutong Dai,Yuhao Yang,Ziyang Luo,Zirui Zhao,Zhiyuan Hu,Junzhe Huang,Amrita Saha,Zeyuan Chen,Ran Xu,Liyuan Pan,Caiming Xiong,Junnan Li*

主要分类: cs.AI

摘要简述: 本文提出GTA1，一种图形用户界面（GUI）测试时扩展代理，通过测试时扩展方法和强化学习改进任务规划和视觉定位，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: GUI代理在跨平台任务中面临两大挑战：任务规划中的歧义解决和复杂高分辨率界面中的精确视觉定位。本文旨在通过GTA1解决这些问题。

研究方法: 1. 引入测试时扩展方法，通过采样多个候选动作提案并利用评判模型选择最优解；2. 提出基于强化学习的模型，通过目标对齐提升视觉定位精度。

研究结果: GTA1在多个基准测试中表现优异，例如在Screenspot-Pro、Screenspot-V2和OSWorld-G上分别达到50.1%、92.4%和67.7%的准确率，任务成功率在OSWorld上达45.2%。

研究结论: GTA1通过测试时扩展和强化学习方法有效解决了GUI代理的任务规划和视觉定位问题，实现了最先进的性能。

中文摘要: 图形用户界面（GUI）代理能够跨平台（如Linux）自主完成任务，通过交互视觉元素实现用户指令的分解和执行。然而，存在两大挑战：i）任务规划中的歧义解决，即从多个有效动作提案中选择最优序列；ii）在复杂高分辨率界面中精确视觉定位，即准确交互目标。本文通过GUI测试时扩展代理GTA1研究这些问题。首先，为选择最优动作提案，我们提出测试时扩展方法，通过采样候选提案并利用评判模型选择最优解，以计算换取更优决策质量。其次，提出基于强化学习的模型，通过目标对齐提升视觉定位精度。实验表明，GTA1在多个基准测试中表现优异，例如在Screenspot-Pro、Screenspot-V2和OSWorld-G上分别达到50.1%、92.4%和67.7%的准确率。结合测试时扩展策略，GTA1在OSWorld上任务成功率达45.2%。我们开源了代码和模型。

</details>


### [162] [Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity](https://arxiv.org/abs/2507.05816)
**中文标题：Affective-ROPTester：大型语言模型在早产儿视网膜病变预测中的能力与偏差分析**

*Shuai Zhao,Yulin Zhang,Luwei Xiao,Xinyi Wu,Yanhao Jia,Zhongliang Guo,Xiaobao Wu,Cong-Duy Nguyen,Guoming Zhang,Anh Tuan Luu*

主要分类: cs.AI

摘要简述: 本文提出Affective-ROPTester框架，用于评估大型语言模型（LLMs）在早产儿视网膜病变（ROP）风险预测中的能力和情感偏差。通过CROP数据集和三种提示策略，研究发现LLMs在外部知识辅助下表现更优，但存在情感偏差，积极情感提示可减少偏差。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在多领域取得进展，但其在ROP风险预测中的能力和情感偏差尚未充分研究。本文旨在填补这一空白，探索LLMs在医疗诊断中的潜力与局限。

研究方法: 提出Affective-ROPTester框架，使用CROP数据集（993条标注记录）和三种提示策略：指令式、思维链（CoT）和上下文学习（ICL）。通过情感元素分析模型偏差。

研究结果: LLMs仅依赖内部知识时ROP预测效果有限，但结合外部知识后表现显著提升。模型输出存在情感偏差，倾向于高估中高风险案例，积极情感提示可减少偏差。

研究结论: 情感敏感的提示工程对提升诊断可靠性至关重要，Affective-ROPTester为临床语言模型系统的偏差评估与缓解提供了有效框架。

中文摘要: 尽管大型语言模型（LLMs）在各领域取得了显著进展，但其在早产儿视网膜病变（ROP）风险预测中的能力仍未被充分探索。为填补这一空白，我们引入了一个名为CROP的中文基准数据集，包含993条标注为低、中、高风险的入院记录。为系统分析LLMs在ROP风险分层中的预测能力和情感偏差，我们提出了Affective-ROPTester，一种自动化评估框架，整合了三种提示策略：指令式、思维链（CoT）和上下文学习（ICL）。指令式策略评估LLMs的内在知识及相关偏差，而CoT和ICL策略利用外部医学知识提升预测准确性。关键的是，我们在提示层面融入了情感元素，以研究不同情感框架如何影响模型的ROP预测能力及其偏差模式。基于CROP数据集的实证结果得出两个主要观察：首先，LLMs仅依赖内在知识时ROP风险预测效果有限，但在结合结构化外部输入后表现显著提升；其次，模型输出存在明显的情感偏差，倾向于高估中高风险案例；第三，与负面情感相比，积极情感框架有助于减少预测偏差。这些发现凸显了情感敏感提示工程在提升诊断可靠性中的关键作用，并强调了Affective-ROPTester作为评估和缓解临床语言模型系统情感偏差框架的实用性。

</details>


### [163] [CogniPlay: a work-in-progress Human-like model for General Game Playing](https://arxiv.org/abs/2507.05868)
**中文标题：CogniPlay：一种用于通用游戏的人类化模型（开发中）**

*Aloïs Rautureau,Éric Piette*

主要分类: cs.AI

摘要简述: 本文介绍了一种名为CogniPlay的模型，旨在模拟人类在通用游戏中的直觉决策过程，填补现有AI系统与人类认知之间的差距。


<details>
  <summary>详细信息</summary>
研究动机: 尽管AI在多种游戏中表现优异，但其决策过程与人类的直觉和模式识别能力仍有差距。本文旨在通过结合认知心理学的研究，开发一种更接近人类思维的AI模型。

研究方法: 文章综述了认知心理学的研究成果及现有AI模型的局限性，并提出了一个基于这些观察的工作模型CogniPlay，专注于模拟人类的模式识别和直觉决策。

研究结果: CogniPlay是一个正在进行中的模型，旨在为通用游戏（GGP）提供更接近人类认知的决策能力。

研究结论: CogniPlay展示了将认知心理学与AI结合的可能性，为未来开发更“人类化”的AI系统提供了方向。

中文摘要: 尽管AI系统在诸如国际象棋、围棋或Dota 2等多种游戏中已达到或超越人类水平，但这些系统仍远未达到真正“人类化”的标准。尽管取得了成功，它们无法复制人类认知中基于模式和直觉的决策过程。本文综述了认知心理学的研究成果及以往模拟人类行为的尝试，探讨了其在通用游戏（GGP）中的应用，并介绍了基于这些观察的工作模型：CogniPlay。

</details>


### [164] [Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better](https://arxiv.org/abs/2507.05886)
**中文标题：当前构建基于LLM的推理工具的方法缺乏系统性——我们可以做得更好**

*Aaron Bembenek*

主要分类: cs.AI

摘要简述: 当前构建基于大语言模型（LLM）的推理工具的方法缺乏系统性，作者提出了一种新的计算模型——神经符号转换系统，以提升神经符号自动推理工具的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 当前结合传统符号算法与大语言模型（LLM）构建自动推理工具的方法缺乏系统性，无法充分发挥神经符号推理的潜力。作者旨在提出一种更高效的计算模型，以解决这一问题。

研究方法: 作者提出了一种名为神经符号转换系统的计算模型，该模型将符号状态与直觉相结合，并通过并行操作符号和直觉实现状态转换。

研究结果: 该模型能够扩展逻辑推理的能力，同时保留符号算法的强保证性，并可通过逻辑编程语言实现。

研究结论: 神经符号转换系统为构建神经符号自动推理工具提供了理论基础，有望推动该领域的进一步发展。

中文摘要: 目前，结合传统符号算法与大语言模型（LLM）构建软件验证器、合成器及其他自动推理（AR）工具的做法引起了广泛关注。然而，当前构建此类神经符号AR系统的方法是一种缺乏系统性的编程模型，既无法提供传统符号算法的强保证性，也未能充分结合神经网络与符号推理以释放LLM驱动的推理潜力。为此，我提出神经符号转换系统作为一种原则性的计算模型，可作为构建神经符号AR工具的基础设施。在该模型中，符号状态与直觉相结合，状态转换则并行操作符号与直觉。我认为这一新范式能够扩展逻辑推理的能力，同时保留符号算法的强保证性，并概述了如何通过逻辑编程语言实现这一计算模型。

</details>


### [165] [Decomposing the Time Series Forecasting Pipeline: A Modular Approach for Time Series Representation, Information Extraction, and Projection](https://arxiv.org/abs/2507.05891)
**中文标题：分解时间序列预测流程：一种模块化的时间序列表示、信息提取与投影方法**

*Robert Leppich,Michael Stenger,André Bauer,Samuel Kounev*

主要分类: cs.AI

摘要简述: 本文提出了一种模块化时间序列预测方法，将预测流程分解为序列表示、信息提取和目标投影三阶段，通过多种架构配置提升预测精度和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管Transformer在时间序列预测中取得进展，但序列表示、信息提取和目标投影仍具挑战性。不同数据集和预测任务需要针对性解决方案，因此本文提出模块化方法以系统解决这些问题。

研究方法: 将时间序列预测流程分解为输入序列表示、信息提取与记忆构建、目标投影三阶段，并研究不同架构配置（如卷积层和自注意力机制）在多个基准数据集上的表现。

研究结果: 模型在七个基准数据集上实现了最先进的预测精度，同时显著提升计算效率，减少训练和推理时间及参数数量。

研究结论: 模块化方法有效解决了时间序列预测中的核心挑战，提升了精度和效率，为未来研究提供了灵活框架。

中文摘要: 随着Transformer的出现，时间序列预测取得了显著进展，但由于需要有效的序列表示、记忆构建和准确的目标投影，该任务仍具挑战性。时间序列预测需要有效的序列表示、有意义的信息提取和精确的未来投影，每个数据集和预测配置构成独特任务，模型需克服特定挑战以生成准确预测。为系统解决这些任务特定难题，本研究将时间序列预测流程分解为三个核心阶段：输入序列表示、信息提取与记忆构建、最终目标投影。在每个阶段中，我们研究了一系列架构配置，以评估不同模块（如用于特征提取的卷积层和用于信息提取的自注意力机制）在多样化预测任务中的有效性，包括在七个基准数据集上的评估。我们的模型实现了最先进的预测精度，同时显著提升了计算效率，减少了训练和推理时间及参数数量。源代码可在https://github.com/RobertLeppich/REP-Net获取。

</details>


### [166] [MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation](https://arxiv.org/abs/2507.05894)
**中文标题：MusiScene：基于MU-LLaMA的场景想象与增强视频背景音乐生成**

*Fathinah Izzati,Xinyue Li,Yuxuan Wu,Gus Xia*

主要分类: cs.AI

摘要简述: 本文提出MusiScene模型，利用MU-LLaMA实现音乐场景想象（MSI）并增强视频背景音乐生成（VBMG）。通过构建大规模视频-音频字幕数据集，微调MU-LLaMA生成场景相关描述，实验证明其优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 人类在听音乐时能想象出与之匹配的场景，但现有音乐描述模型仅关注音乐元素。本文旨在探索音乐语言模型（如MU-LLaMA）是否也能实现跨模态的音乐场景想象（MSI），并提升视频背景音乐生成的效果。

研究方法: 1. 构建包含3,371对视频-音频字幕的大规模数据集；2. 微调MU-LLaMA以完成MSI任务，开发MusiScene模型；3. 通过全面评估验证模型生成场景相关描述的能力。

研究结果: 实验表明，MusiScene在生成与音乐场景相关的描述上优于MU-LLaMA，并能利用生成的MSI描述提升视频背景音乐生成的文本驱动效果。

研究结论: MusiScene通过跨模态学习实现了音乐场景想象，为视频背景音乐生成提供了更丰富的上下文支持，展示了音乐语言模型在跨模态任务中的潜力。

中文摘要: 人类在听音乐时可以想象出各种氛围和场景，例如缓慢忧郁的音乐可能让人联想到心碎的画面，而欢快的旋律则暗示庆祝的场景。本文探讨音乐语言模型（如MU-LLaMA）是否能完成类似的任务，即音乐场景想象（MSI），这需要结合视频和音乐的跨模态信息进行训练。为了改进现有仅关注音乐元素的音乐描述模型，我们提出了MusiScene，一种能够想象与音乐匹配场景的音乐描述模型。本文中，（1）我们构建了一个包含3,371对视频-音频字幕的大规模数据集；（2）我们微调了音乐理解模型MU-LLaMA以完成MSI任务，开发了MusiScene；（3）通过全面评估证明，MusiScene在生成上下文相关描述上优于MU-LLaMA。我们利用生成的MSI描述进一步增强了基于文本的视频背景音乐生成（VBMG）效果。

</details>


### [167] [BlueLM-2.5-3B Technical Report](https://arxiv.org/abs/2507.05934)
**中文标题：BlueLM-2.5-3B技术报告**

*Baojiao Xiong,Boheng Chen,Chengzhi Wang,Daxiong Luo,Dongsheng Xu,Dongyang Liu,Fan Yang,Fangyuan Li,Fei Teng,Feng Wang,Fukang Qin,Fuquan Peng,Guanxin Tan,Guozhi Wang,Haibo Yu,Haohao Gao,Heng Liu,Hongbo Yang,Hongjian Zou,Houzheng Shen,Hu Meng,Huan Li,Hui Tan,Jiali Chen,Jianzhao Chen,Jinliang Zhu,Kai Wang,Lei Wu,Liangbing Liu,Liuyang Bian,Liyan He,Long Liu,Peiwen Li,Penggang Shi,Qi Ding,Rui Hu,Shuai Cao,Shuai Ren,Shuang Peng,Teng Xie,Weiji Chen,Weilin Xiang,Weixin Wu,Xi Yin,Xiaoxin Chen,Xu Chen,Yafei Wen,Yan Hu,Yanzhou Yang,Yina Xie,Yinghao Chen,Yixuan Liao,Yu Geng,Yuanjiang Ouyang,Yuanzhuo Yang,Yuehua He,Yushuai Peng,Zhaoxiong Wang,Zheng Wang,Zhibo Zhou,Ziyang Wu*

主要分类: cs.AI

摘要简述: BlueLM-2.5-3B是一款高效的多模态大语言模型，专为边缘设备设计，支持思考与非思考模式，并在多模态和纯文本任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 开发一款紧凑且高效的多模态大语言模型，适用于边缘设备部署，同时具备强大的通用和推理能力。

研究方法: 通过多样化的数据整理、关键数据重采样、混合异构强化学习以及高性能训练基础设施开发模型。

研究结果: 在思考模式下，BlueLM-2.5-3B在纯文本任务中表现接近Qwen3-4B，多模态任务中仅落后Kimi-VL-A3B-16B约5%；在非思考模式下，多数多模态任务中优于Qwen2.5-VL-3B。

研究结论: BlueLM-2.5-3B展示了高效的数据利用和卓越的性能，为高性能边缘设备多模态大语言模型的研究提供了重要参考。

中文摘要: 我们介绍了BlueLM-2.5-3B，一款紧凑且统一的多模态大语言模型（MLLM），专为高效的边缘设备部署设计，具备强大的通用和推理能力。据我们所知，这是首款支持思考与非思考模式的3B规模MLLM，同时还能显式控制思考令牌预算。BlueLM-2.5-3B通过多样化的数据整理、关键数据重采样、混合异构强化学习以及高性能训练基础设施开发而成。我们的模型在仅29亿参数的情况下，实现了卓越的多模态能力，同时保持了竞争力的纯文本性能。我们在广泛的多模态和纯文本基准测试中进行了全面评估。在思考模式下，BlueLM-2.5-3B在纯文本基准测试中表现接近Qwen3-4B，而在多模态评估中平均仅落后更大的Kimi-VL-A3B-16B约5%。在非思考模式下，其在多数多模态基准测试中优于Qwen2.5-VL-3B。此外，BlueLM-2.5-3B表现出卓越的数据效率。上述所有性能均在使用远少于Qwen2.5-VL-3B和Qwen3-4B的总训练数据的情况下实现。我们希望我们的工作能推动高性能边缘设备MLLM的发展，并为研究社区提供有意义的见解。

</details>


### [168] [A Wireless Foundation Model for Multi-Task Prediction](https://arxiv.org/abs/2507.05938)
**中文标题：无线多任务预测的基础模型**

*Yucheng Sheng,Jiacheng Wang,Xingyu Zhou,Le Liang,Hao Ye,Shi Jin,Geoffrey Ye Li*

主要分类: cs.AI

摘要简述: 本文提出了一种无线网络多任务预测的统一基础模型，通过分解异构任务、编码粒度感知和使用因果Transformer架构，实现了对未见场景的强泛化能力和零样本性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着移动通信网络的复杂性和动态性增加，准确预测关键系统参数（如信道状态信息、用户位置和网络流量）对物理层和MAC层任务至关重要。传统深度学习方法难以跨场景和任务泛化，因此需要一种统一的基础模型。

研究方法: 提出了一种支持多任务预测的统一基础模型，包括：1) 通过单变量分解统一异构任务；2) 编码粒度以实现区间感知；3) 使用因果Transformer架构进行准确预测；4) 引入补丁掩码策略以支持任意输入长度。

研究结果: 在大规模数据集上训练后，该模型对未见场景表现出强泛化能力，并在新任务上实现了超越传统全样本基线的零样本性能。

研究结论: 该基础模型为无线网络中的多任务预测提供了一种高效且泛化能力强的解决方案，能够适应不同场景和任务需求。

中文摘要: 随着移动通信网络的复杂性和动态性增加，准确预测关键系统参数（如信道状态信息、用户位置和网络流量）对物理层和MAC层任务至关重要。尽管传统深度学习方法已广泛用于此类预测任务，但其跨场景和任务的泛化能力有限。为此，我们提出了一种支持多任务预测的统一基础模型，能够适应不同的预测区间。该模型通过单变量分解统一异构任务，编码粒度以实现区间感知，并使用因果Transformer架构进行准确预测。此外，训练中引入补丁掩码策略以支持任意输入长度。在大规模数据集上训练后，该基础模型对未见场景表现出强泛化能力，并在新任务上实现了超越传统全样本基线的零样本性能。

</details>


### [169] [Enhancing the Interpretability of Rule-based Explanations through Information Retrieval](https://arxiv.org/abs/2507.05976)
**中文标题：通过信息检索增强基于规则的解释的可解释性**

*Alessandro Umbrico,Guido Bologna,Luca Coraci,Francesca Fracasso,Silvia Gola,Gabriella Cortellessa*

主要分类: cs.AI

摘要简述: 本文提出了一种基于信息检索的方法，通过统计分析规则预测模型中的属性，提升可解释AI在乳腺癌淋巴结放疗后淋巴水肿风险评估中的透明度和实用性。


<details>
  <summary>详细信息</summary>
研究动机: 数据驱动的AI技术缺乏透明度，限制了其在医疗决策中的可解释性和接受度。本文旨在通过改进可解释AI的预测方法，提升其在淋巴水肿风险评估中的透明度和实用性。

研究方法: 采用基于信息检索技术的标准指标，对规则预测模型中的属性进行统计分析，计算每个属性对预测的相关性，并为用户提供可解释的风险因素影响信息。

研究结果: 用户研究表明，与原始可解释AI模型输出相比，本文提出的方法在预测淋巴水肿风险时具有更高的可解释性和实用性。

研究结论: 本文提出的方法显著提升了可解释AI在医疗决策中的透明度和实用性，尤其在淋巴水肿风险评估中表现突出。

中文摘要: 数据驱动的人工智能技术缺乏透明度，限制了其在医疗决策过程中的可解释性和接受度。我们提出了一种基于属性的方法，用于改进可解释AI在乳腺癌淋巴结放疗后淋巴水肿风险评估中的预测可解释性。该方法利用信息检索技术的标准指标，对规则预测模型中的属性进行统计分析，计算每个属性对预测的相关性，并为用户提供可解释的风险因素影响信息。一项用户研究的结果表明，与原始可解释AI模型输出相比，本文提出的方法在预测淋巴水肿风险时具有更高的可解释性和实用性。

</details>


### [170] [Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening](https://arxiv.org/abs/2507.05984)
**中文标题：HopeBot的开发与评估：一种基于大型语言模型的结构化交互式PHQ-9抑郁症筛查聊天机器人**

*Zhijun Guo,Alvina Lai,Julia Ive,Alexandru Petcu,Yutong Wang,Luyuan Qi,Johan H Thygesen,Kezhi Li*

主要分类: cs.AI

摘要简述: 研究开发了基于大型语言模型（LLM）的聊天机器人HopeBot，用于结构化和交互式PHQ-9抑郁症筛查。结果显示，HopeBot在信任度、舒适度和实用性方面表现优异，87.1%的参与者愿意重复使用或推荐。


<details>
  <summary>详细信息</summary>
研究动机: 传统的PHQ-9抑郁症筛查工具缺乏互动性和适应性，因此研究旨在开发一种基于LLM的交互式聊天机器人，以提高筛查的效率和用户体验。

研究方法: 研究开发了HopeBot，采用检索增强生成和实时澄清技术进行PHQ-9筛查。通过一项132名成年人的对比研究，评估了HopeBot与自填问卷的效果。

研究结果: HopeBot与自填问卷的得分一致性高（ICC=0.91；45%完全一致）。71%的参与者更信任HopeBot，其舒适度、声音清晰度和敏感话题处理评分均较高（8.4、7.7、7.6）。87.1%的参与者愿意重复使用或推荐。

研究结论: 基于语音的LLM聊天机器人可作为抑郁症筛查的可扩展、低负担辅助工具，具有较高的用户接受度和实用性。

中文摘要: 传统的抑郁症筛查工具如PHQ-9虽然有效，但缺乏互动性和适应性。为此，我们开发了HopeBot，一种基于大型语言模型（LLM）的聊天机器人，通过检索增强生成和实时澄清技术进行PHQ-9筛查。在一项涉及132名英国和中国成年人的对比研究中，参与者完成了自填问卷和聊天机器人版本。结果显示，两者得分高度一致（ICC=0.91；45%完全一致）。在75名提供反馈的参与者中，71%表示更信任聊天机器人，认为其结构清晰、提供解释性指导且语气支持性强。平均评分（0-10分）显示，舒适度为8.4，声音清晰度为7.7，敏感话题处理为7.6，推荐实用性为7.4；后者因就业状况和心理健康服务使用历史而显著差异（p<0.05）。总体而言，87.1%的参与者愿意重复使用或推荐HopeBot。这些结果表明，基于语音的LLM聊天机器人可作为抑郁症筛查的可扩展、低负担辅助工具。

</details>


### [171] [CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation](https://arxiv.org/abs/2507.06013)
**中文标题：CogniSQL-R1-Zero：基于轻量级强化推理的高效SQL生成**

*Kushal Gajjar,Harshit Sikchi,Arpit Singh Gautam,Marc Hammons,Saurabh Jha*

主要分类: cs.AI

摘要简述: CogniSQL-R1-Zero是一种基于强化学习的轻量级框架，用于高效生成准确的SQL查询，无需复杂监督或混合流程，在Text2SQL基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型在自然语言转SQL（Text-to-SQL）任务中有所改进，但生成复杂且可执行的SQL仍具挑战性。本文旨在通过轻量级强化学习方法提升SQL生成的准确性和效率。

研究方法: 提出CogniSQL-R1-Zero框架，利用基于执行正确性和格式标签合规性的轻量级奖励信号，通过强化学习直接优化SQL生成任务，避免中间监督和复杂奖励设计。

研究结果: 在Text2SQL基准测试（如BIRD bench）中，CogniSQL-R1-Zero表现优于包括SFT CodeS-7B、DeepSeek-Coder 236B和Mistral 123B在内的基线模型，尽管其仅基于7B规模的模型训练。

研究结论: CogniSQL-R1-Zero展示了强化学习在Text-to-SQL任务中的高效性和可扩展性，同时发布了两个数据集以支持进一步研究。

中文摘要: 将自然语言转换为SQL（Text-to-SQL）仍然是语言理解与结构化数据访问交叉领域的核心挑战。尽管大型语言模型（LLMs）提高了流畅性，但生成正确且可执行的SQL（尤其是复杂查询）仍然具有挑战性。我们提出了CogniSQL-R1-Zero，这是一种基于强化学习（RL）的框架和模型，通过基于执行正确性和格式标签合规性的轻量级奖励信号生成准确的SQL。通过避免中间监督、混合流程和复杂的奖励设计，我们的方法促进了稳定学习，并更好地与最终任务目标（生成可执行程序）对齐。CogniSQL-R1-Zero在Text2SQL基准测试（如BIRD bench）中实现了最先进的执行准确率，优于包括SFT CodeS-7B、DeepSeek-Coder 236B和Mistral 123B在内的监督和指令调优基线模型，尽管其仅基于7B规模的模型训练。这一结果突显了我们的强化学习方法在仅使用四块NVIDIA A100 GPU（每块40 GB显存）训练时的可扩展性和效率。为了支持高效且可解释的Text-to-SQL建模研究，我们发布了两个精选数据集：（i）包含5,024条不同上下文长度的推理轨迹；（ii）36,356条弱监督查询的正样本语料库，每条查询标注了六种语义多样的推理路径。这些贡献共同推动了可扩展且与执行对齐的Text-to-SQL生成技术的发展。

</details>


### [172] [Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions](https://arxiv.org/abs/2507.06029)
**中文标题：特征引导邻居选择：非专家模型预测评估方法**

*Courtney Ford,Mark T. Keane*

主要分类: cs.AI

摘要简述: 本文提出了一种名为特征引导邻居选择（FGNS）的后处理方法，通过结合局部和全局特征重要性选择类代表性样本，显著提升了非专家用户对模型预测的评估能力。


<details>
  <summary>详细信息</summary>
研究动机: 可解释人工智能（XAI）方法通常难以为非领域专家生成清晰易懂的输出。本文旨在通过FGNS方法提升非专家用户对模型预测的理解和评估能力。

研究方法: FGNS是一种后处理方法，通过结合局部和全局特征重要性选择类代表性样本，以增强模型预测的可解释性。在用户研究中，FGNS与传统k-NN解释方法进行了对比。

研究结果: 在98名参与者的用户研究中，FGNS显著提升了非专家用户识别模型错误的能力，同时保持了与正确预测的一致性。参与者决策更快且更准确，FGNS选择的邻居样本更能反映类别特征。

研究结论: FGNS为提升模型评估的人机对齐迈出了一步，但解释质量与用户信任之间的差距仍需进一步研究。

中文摘要: 可解释人工智能（XAI）方法通常难以为非领域专家生成清晰易懂的输出。本文提出了特征引导邻居选择（FGNS），这是一种后处理方法，通过结合局部和全局特征重要性选择类代表性样本，从而提升可解释性。在一项涉及98名参与者的用户研究中，FGNS显著提升了非专家用户在卡纳达语脚本分类任务中识别模型错误的能力，同时保持了与正确预测的一致性。与传统k-NN解释相比，参与者决策更快且更准确。定量分析表明，FGNS选择的邻居样本更能反映类别特征，而不仅仅是特征空间距离的最小化，从而实现了更一致的样本选择和更紧密的类别原型聚类。这些结果表明，FGNS是迈向更符合人类需求的模型评估的一步，但解释质量与用户信任之间的差距仍需进一步研究。

</details>


### [173] [On Lockean beliefs that are deductively closed and minimal change](https://arxiv.org/abs/2507.06042)
**中文标题：关于演绎封闭且最小化修订的Lockean信念**

*Tommaso Flaminio,Lluis Godo,Ramón Pino Pérez,Lluis Subirana*

主要分类: cs.AI

摘要简述: 本文在Lockean命题的形式框架下，研究了基于置信度的信念集合，并探讨了其在经典逻辑演绎下的封闭性。论文提出了两种封闭性特征，并设计了一种最小化修订的更新方法。


<details>
  <summary>详细信息</summary>
研究动机: Lockean信念集合在经典逻辑演绎下通常不封闭，这限制了其在信念变化理论等领域的应用。本文旨在解决这一问题，同时探索如何通过最小化修订实现信念集合的演绎封闭。

研究方法: 论文首先给出了两种经典逻辑演绎封闭的信念集合特征，随后提出了一种概率更新方法，通过最小化修订实现信念集合的封闭性。

研究结果: 研究结果表明，可以通过最小化修订实现Lockean信念集合的演绎封闭，并提供了具体的特征描述和更新方法。

研究结论: 本文成功解决了Lockean信念集合在经典逻辑演绎下的封闭性问题，并提出了最小化修订的更新策略，为相关领域提供了新的理论工具。

中文摘要: 在Lockean命题的形式框架下，代理的信念集合通过置信度定义，并以概率形式描述。尽管这种方法具有重要价值，但其在某些情境（如信念变化理论）中的应用存在局限性，尤其是Lockean信念集合通常不满足经典逻辑演绎的封闭性。本文的目标是双重的：一方面，我们提供了两种经典逻辑演绎封闭的信念集合特征；另一方面，我们提出了一种概率更新方法，通过最小化修订实现信念集合的更新，即在保留现有信念集合的同时，以最少改动容纳新信息。特别地，我们展示了如何通过最小化修订实现信念集合的演绎封闭。

</details>


### [174] [FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models](https://arxiv.org/abs/2507.06057)
**中文标题：FEVO：面向大语言模型的金融知识扩展与推理进化**

*Bo Pang,Yalu Ouyang,Hangfei Xu,Ziqi Jia,Panpan Li,Shengzhao Wen,Lu Wang,Shiyong Li,Yanpeng Wang*

主要分类: cs.AI

摘要简述: FEVO是一个多阶段增强框架，通过持续预训练、监督微调和强化学习提升大语言模型在金融领域的性能，其模型FEVO-R32B在多个金融基准测试中达到最优表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在数学和编程等领域表现优异，但在需要大量领域知识的金融领域应用有限。FEVO旨在填补这一空白，提升模型在金融任务中的性能。

研究方法: FEVO采用三阶段方法：持续预训练扩展金融知识，监督微调注入结构化推理模式，强化学习整合知识与推理。使用高质量数据集FEVO-Train支持训练。

研究结果: FEVO-R32B在五个金融基准测试中超越更大模型和专家模型，表现最优，且显著优于仅使用强化学习的基线模型FEVO-R32B-0。

研究结论: FEVO框架通过知识扩展和结构化推理有效提升大语言模型在金融领域的性能，验证了其方法的有效性。

中文摘要: 大语言模型（LLMs）在推理能力上的进步显著提升了其在数学和编程等领域的性能，但在需要大量领域知识的金融领域应用仍有限。为此，我们提出了FEVO（金融进化），一个多阶段增强框架，旨在提升LLMs在金融领域的性能。FEVO通过持续预训练（CPT）扩展金融知识，监督微调（SFT）注入结构化推理模式，以及强化学习（RL）整合知识与推理。为确保高效训练，我们利用前沿推理模型和基于规则的过滤方法，构建了高质量数据集FEVO-Train。基于此框架，我们从Qwen2.5-32B训练了FEVO系列模型（C32B、S32B、R32B），并在七个基准测试中评估其金融和通用能力。结果显示，FEVO-R32B在五个金融基准测试中超越更大模型和专家模型，达到最优性能。更重要的是，FEVO-R32B显著优于仅使用RL训练的FEVO-R32B-0，验证了金融知识扩展和结构化推理的有效性。

</details>


### [175] [AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study](https://arxiv.org/abs/2507.06077)
**中文标题：基于AI的需求预测与负载均衡优化医疗系统能源使用的真实案例研究**

*Iman Rahimi,Isha Patel*

主要分类: cs.AI

摘要简述: 本文提出了一种基于AI的框架（结合LSTM、遗传算法和SHAP），用于优化医疗系统的能源使用，显著提升了需求预测和负载均衡的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 医疗设施的能源需求波动大，传统方法效率低下且成本高，亟需一种高效、透明的AI解决方案来提升能源管理效率和可持续性。

研究方法: 研究采用LSTM进行时间序列预测，结合遗传算法优化模型参数和负载均衡策略，并通过SHAP分析增强模型透明度和可解释性。

研究结果: LSTM在预测复杂非线性需求模式时表现优异（MAE: 21.69，RMSE: 29.96），显著优于Prophet和ARIMA模型。遗传算法和SHAP进一步提升了模型的适应性和决策可信度。

研究结论: 该研究为医疗能源管理提供了高效、可扩展的AI解决方案，未来可探索实时部署和强化学习的结合以持续优化。

中文摘要: 本文针对医疗设施中能源管理效率低下的问题，提出了一种结合长短期记忆网络（LSTM）、遗传算法（GA）和SHAP（Shapley Additive Explanations）的AI框架。LSTM在预测复杂非线性需求模式时表现优异（MAE: 21.69，RMSE: 29.96），显著优于Prophet（MAE: 59.78，RMSE: 81.22）和ARIMA（MAE: 87.73，RMSE: 125.22）。遗传算法用于优化模型参数和负载均衡策略，SHAP分析则增强了模型透明度和决策可信度。这一综合方法为提升医疗设施的能源效率和可持续性提供了有力支持。未来研究可探索实时部署及与强化学习的结合。

</details>


### [176] [OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety](https://arxiv.org/abs/2507.06134)
**中文标题：OpenAgentSafety：一个评估现实世界AI代理安全性的综合框架**

*Sanidhya Vijayvargiya,Aditya Bharat Soni,Xuhui Zhou,Zora Zhiruo Wang,Nouha Dziri,Graham Neubig,Maarten Sap*

主要分类: cs.AI

摘要简述: OpenAgentSafety是一个全面的框架，用于评估AI代理在现实世界中的安全性，涵盖八类关键风险，支持多任务和多用户场景，并通过规则分析和LLM评估检测不安全行为。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI代理在现实任务中的广泛应用，其潜在的不安全行为需要严格评估。现有基准多依赖模拟环境或狭窄任务域，无法全面反映真实风险。

研究方法: 提出OpenAgentSafety框架，支持代理与真实工具（如浏览器、代码执行环境等）交互，覆盖350多项多轮多用户任务，结合规则分析和LLM评估检测不安全行为。

研究结果: 对五种主流LLM的实证分析显示，在安全性脆弱任务中，不安全行为比例从51.2%（Claude-Sonnet-3.7）到72.7%（o3-mini），凸显了现实部署前的安全漏洞。

研究结论: OpenAgentSafety为AI代理安全性评估提供了全面且可扩展的解决方案，揭示了当前LLM在代理场景中的安全风险，强调了加强安全措施的必要性。

中文摘要: 近年来，能够解决复杂日常任务（如日程安排和客户服务）的AI代理已在现实场景中部署，但其潜在的不安全行为需要严格评估。尽管现有基准尝试评估代理安全性，但多数依赖模拟环境、狭窄任务域或不现实的工具抽象。我们提出了OpenAgentSafety，一个全面且模块化的框架，用于评估代理在八类关键风险中的行为。与以往工作不同，该框架评估代理与真实工具（如浏览器、代码执行环境、文件系统、bash shell和消息平台）的交互，并支持350多项多轮多用户任务，涵盖良性和对抗性用户意图。OpenAgentSafety设计为可扩展，允许研究者轻松添加工具、任务、网站和对抗策略。它结合基于规则的分析和LLM评估，检测显性和隐性的不安全行为。对五种主流LLM在代理场景中的实证分析显示，在安全性脆弱任务中，不安全行为比例从51.2%（Claude-Sonnet-3.7）到72.7%（o3-mini），凸显了现实部署前的安全漏洞和加强保护措施的必要性。

</details>


### [177] [The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains](https://arxiv.org/abs/2507.06187)
**中文标题：Delta学习假设：基于弱数据的偏好调优可带来显著增益**

*Scott Geng,Hamish Ivison,Chun-Liang Li,Maarten Sap,Jerry Li,Ranjay Krishna,Pang Wei Koh*

主要分类: cs.AI

摘要简述: 本文提出“Delta学习假设”，证明即使使用弱数据点配对的偏好数据，也能通过相对质量差异驱动模型学习，显著提升性能。实验验证了该方法在低成本下达到与先进模型相当的效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型的改进常依赖高质量数据，但强监督数据稀缺。本文旨在探索弱数据点配对的偏好数据是否也能驱动模型学习，从而降低对强监督的依赖。

研究方法: 提出Delta学习假设，认为数据点间的相对质量差异足以驱动偏好调优。通过实验验证，使用小模型生成的弱数据配对（如3B与1.5B模型的输出）训练8B模型。

研究结果: 在11个基准测试（如MATH、MMLU）中，该方法匹配了先进模型Tulu 3的性能，且无需依赖GPT-4o等强监督。理论证明弱教师模型的性能差距可为强学生模型提供有效信号。

研究结论: Delta学习假设表明，弱数据配对可通过相对差异驱动学习，为低成本实现先进性能提供了新思路。

中文摘要: 语言模型的改进通常依赖于训练数据质量的提升，但在强监督稀缺时，这种方法可能受限。本文表明，由弱数据点配对的偏好数据能够实现超越单个数据点强度的性能提升。我们提出Delta学习假设，认为数据点间的相对质量差异足以通过偏好调优驱动学习——即使基于弱数据的监督微调会损害性能。我们通过控制实验和大规模实验验证了这一假设：通过将3B小模型的响应与更小的1.5B模型输出配对生成偏好数据，用于训练8B模型。令人惊讶的是，在标准11项基准测试（如MATH、MMLU等）中，这一简单方法匹配了Tulu 3（基于同一基础模型调优的先进开源模型）的性能，而后者依赖GPT-4o等更强监督。因此，Delta学习为低成本实现先进后训练提供了更简单的开源方案。为深入理解Delta学习，我们在逻辑回归中证明，两个弱教师模型的性能差距可为更强学生模型提供有效信号。总体而言，本文表明模型可以从通常被视为弱数据的配对数据中学习，效果远超预期。

</details>


### [178] [Identifiability in Causal Abstractions: A Hierarchy of Criteria](https://arxiv.org/abs/2507.06213)
**中文标题：因果抽象中的可识别性：标准层次结构**

*Clément Yvernes,Emilie Devijver,Marianne Clausel,Eric Gaussier*

主要分类: cs.AI

摘要简述: 本文提出了一种层次化的标准，用于在因果抽象中评估可识别性，帮助在缺乏完整因果知识的情况下推断因果效应。


<details>
  <summary>详细信息</summary>
研究动机: 在观测数据中识别处理效应通常需要完整的因果图，但实际中因果图往往未知，尤其是在复杂或高维场景中。因果抽象作为一种简化表示方法，可以部分保留因果信息，但其可识别性尚未系统化研究。

研究方法: 本文形式化了因果抽象为因果图的集合，并提出了多个可识别性标准，将这些标准组织成一个层次结构，以明确其关系。

研究结果: 通过层次化的标准，本文展示了在不同因果知识水平下可识别的因果查询，并通过文献案例和工具验证了框架的实用性。

研究结论: 层次化的可识别性标准为缺乏完整因果知识的场景提供了清晰的推断路径，扩展了因果抽象的应用范围。

中文摘要: 从观测数据中识别处理效应通常需要假设一个完全指定的因果图。然而，这种因果图在实践中很少已知，尤其是在复杂或高维场景中。为了克服这一限制，最近的研究探索了因果抽象的使用——一种保留部分因果信息的简化表示。本文考虑将因果抽象形式化为因果图的集合，并专注于此类集合中因果查询的可识别性。我们引入并形式化了这一背景下的多个可识别性标准。主要贡献是将这些标准组织成一个结构化的层次结构，突出它们之间的关系。这种层次化视角能够更清晰地理解在不同因果知识水平下可识别的内容。我们通过文献中的示例展示了框架，并提供了在缺乏完整因果知识时推理可识别性的工具。

</details>


### [179] [Aligned Textual Scoring Rules](https://arxiv.org/abs/2507.06221)
**中文标题：对齐文本评分规则**

*Yuxuan Lu,Yifan Wu,Jason Hartline,Michael J. Curry*

主要分类: cs.AI

摘要简述: 本文提出了一种对齐评分规则（ASR），通过优化均方误差来确保评分规则既符合人类偏好又保持其正当性，实验证明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着语言模型的发展，现有的文本信息启发方法虽然能保证正当性，但未必与人类偏好一致。本文旨在设计一种既能保持正当性又能与人类偏好对齐的评分规则。

研究方法: 本文设计了对齐评分规则（ASR），通过最小化正当评分规则与参考评分（如人类评分）之间的均方误差，实现与人类偏好的对齐。

研究结果: 实验表明，ASR在保持正当性的同时，显著优于现有方法，更符合人类偏好。

研究结论: ASR为文本信息启发提供了一种既能保证正当性又能与人类偏好对齐的解决方案，具有实际应用价值。

中文摘要: 评分规则通过将预测与真实状态对比来激励战略代理提供概率预测。正当的评分规则要求代理报告真实信念时能最大化预期得分。随着语言模型的发展，Wu和Hartline（2024）提出了一种将文本信息启发问题转化为数值（即概率）信息启发问题的方法，实现了文本启发的可证明正当性。然而，并非所有正当评分规则都能与人类对文本的偏好一致。本文设计了对齐评分规则（ASR），通过优化并最小化正当评分规则与参考评分（如人类评分）之间的均方误差，确保其与人类偏好对齐。实验表明，ASR在保持正当性的同时，优于现有方法，更符合人类偏好。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [180] [A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation](https://arxiv.org/abs/2507.05731)
**中文标题：一种卫星-地面协同的大型视觉语言模型系统用于地球观测**

*Yuxin Zhang,Jiahao Yang,Zhe Chen,Wenjun Zhu,Jin Zhao,Yue Gao*

主要分类: cs.NI

摘要简述: 本文提出了一种名为SpaceVerse的卫星-地面协同大型视觉语言模型系统，用于解决低地球轨道卫星图像分析的实时性问题。通过部署轻量级模型在卫星上，并结合地面计算资源，实现了高效的数据处理和传输，显著提升了准确性和降低了延迟。


<details>
  <summary>详细信息</summary>
研究动机: 低地球轨道卫星图像分析面临快速卫星运动、短暂的地面接触窗口和大图像数据下载的挑战。为了支持近实时应用（如灾害和极端天气监测），需要探索如何在卫星网络中部署大型视觉语言模型（LVLM），并设计高效的卫星-地面协同推理系统。

研究方法: 1. 在卫星上部署轻量级LVLM处理简单任务，地面站运行常规LVLM处理复杂任务。2. 提出计算与通信协同设计框架，包括渐进式置信网络和基于注意力的多尺度预处理，用于识别卫星推理数据并减少传输冗余。

研究结果: 在真实低地球轨道卫星星座和数据集上的实验表明，SpaceVerse相比现有基线方法，平均准确性提升31.2%，延迟降低51.2%。

研究结论: SpaceVerse通过卫星-地面协同设计和高效的数据处理策略，显著提升了卫星图像分析的实时性和准确性，为近实时地球观测应用提供了可行解决方案。

中文摘要: 近年来，大型视觉语言模型（LVLM）在数据中心为低地球轨道（LEO）卫星的地球观测图像提供了强大的分析能力。然而，快速的卫星运动、短暂的地面站接触窗口以及大尺寸图像带来了数据下载的挑战。为了支持近实时地球观测应用（如灾害和极端天气监测），我们需要探索如何在LEO卫星网络中部署LVLM，并设计SpaceVerse，一种高效的卫星-地面协同LVLM推理系统。为此，首先在卫星上部署轻量级LVLM处理简单任务，而地面站运行常规LVLM处理计算密集型任务。其次，提出一个计算与通信协同设计框架，包括渐进式置信网络和基于注意力的多尺度预处理，分别用于识别卫星推理数据和减少卫星-地面传输的数据冗余。我们在真实LEO卫星星座和数据集上实现了SpaceVerse，并进行了评估，相比现有基线方法，平均准确性提升了31.2%，延迟降低了51.2%。

</details>


### [181] [Intra-DP: A High Performance Collaborative Inference System for Mobile Edge Computing](https://arxiv.org/abs/2507.05829)
**中文标题：Intra-DP：一种面向移动边缘计算的高性能协作推理系统**

*Zekai Sun,Xiuxian Guan,Zheng Lin,Zihan Fang,Xiangming Cai,Zhe Chen,Fangming Liu,Heming Cui,Jie Xiong,Wei Ni,Chau Yuen*

主要分类: cs.NI

摘要简述: Intra-DP是一种高性能的移动边缘计算协作推理系统，通过并行计算技术优化DNN推理，减少延迟和能耗。


<details>
  <summary>详细信息</summary>
研究动机: 在资源受限的移动设备上部署深度神经网络（DNN）面临实时性能和能耗的挑战，现有方法存在传输瓶颈。

研究方法: Intra-DP采用基于局部算子的并行计算技术，将计算分解为独立子操作，并通过并行执行重叠计算和传输，缓解传输瓶颈。

研究结果: 评估显示，Intra-DP相比现有基线方法，延迟降低50%，能耗减少75%，且不牺牲准确性。

研究结论: Intra-DP为移动边缘计算中的DNN推理提供了一种高效、低延迟的解决方案。

中文摘要: 在资源受限的移动设备上部署深度神经网络（DNN）面临显著挑战，尤其是在实现实时性能的同时应对有限的计算资源和电池寿命。尽管移动边缘计算（MEC）通过与GPU服务器的协作推理提供了有前景的解决方案，但现有方法主要依赖于逐层模型划分，并因DNN操作的顺序执行而遭遇显著的传输瓶颈。为解决这一问题，我们提出了Intra-DP，一种针对MEC优化的高性能协作推理系统。Intra-DP采用了一种基于局部算子（如卷积核）的新型并行计算技术。通过将其计算（操作）分解为多个独立的子操作，并通过并行执行重叠不同子操作的计算与传输，Intra-DP缓解了MEC中的传输瓶颈，实现了快速且节能的推理。评估结果表明，与现有基线方法相比，Intra-DP将每次推理的延迟降低了50%，能耗减少了75%，且未牺牲准确性。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [182] [Critical Nodes Identification in Complex Networks: A Survey](https://arxiv.org/abs/2507.06164)
**中文标题：复杂网络中关键节点识别的综述**

*Duxin Chen,Jiawen Chen,Xiaoyu Zhang,Qinghan Jia,Xiaolu Liu,Ye Sun,Linyuan Lv,Wenwu Yu*

主要分类: cs.SI

摘要简述: 本文综述了复杂网络中关键节点识别的研究，分类总结了七类主要方法，并指出了当前研究的挑战与未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 复杂网络在多个领域具有重要应用，而关键节点识别是理论与实践的桥梁。然而，现实网络的复杂性和动态性为通用框架的开发带来挑战，本文旨在填补现有综述的空白，系统分类方法并探讨其适用性。

研究方法: 论文对关键节点识别技术进行了全面回顾，将其分为七类：中心性、关键节点删除问题、影响力最大化、网络控制、人工智能、高阶和动态方法，并分析了各类方法的优缺点及适用性。

研究结果: 研究系统梳理了关键节点识别的进展，提出了算法通用性、动态网络实时评估、高阶结构分析和计算效率等关键挑战，并总结了未来研究方向。

研究结论: 本文通过结构化综述整合了当前研究进展，强调了在建模时间动态性、高效算法开发、机器学习方法整合以及可扩展和可解释性指标设计等方面的开放性问题。

中文摘要: 复杂网络已成为理解社会系统、交通系统、生物分子系统和金融系统中多样现象的重要工具。识别关键节点是当代研究的核心主题，是理论基础与实际应用之间的重要桥梁。然而，现实网络的固有复杂性和结构异质性，尤其是动态和高阶网络，为开发通用关键节点识别框架带来了重大障碍。本文全面回顾了关键节点识别技术，将其分为七大类：中心性、关键节点删除问题、影响力最大化、网络控制、人工智能、高阶和动态方法。我们的综述通过基于方法论基础和实际应用对方法进行系统分类，并强调其在不同网络类型中的优势、局限性和适用性，填补了现有综述的空白。我们的工作通过识别关键挑战（如算法通用性、动态网络中的实时评估、高阶结构分析和大规模网络中的计算效率）增强了对关键节点研究的理解。结构化综述整合了当前进展，并突出了开放性问题，特别是在建模时间动态性、推进高效算法、整合机器学习方法以及开发复杂系统的可扩展和可解释性指标方面。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [183] [Integrators at War: Mediating in AI-assisted Resort-to-Force Decisions](https://arxiv.org/abs/2501.06861)
**中文标题：整合者在战争中：AI辅助武力决策中的中介作用**

*Dennis Müller,Maurice Chiodo,Mitja Sienknecht*

主要分类: cs.CY

摘要简述: 本文探讨了AI系统在军事决策中的整合问题，重点关注了作为中介的整合者群体，分析了技术、角色和人机互动带来的挑战，并提出了政策建议。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI系统在军事领域的应用，决策方式发生变化，但整合者群体的作用常被忽视。本文旨在揭示AI系统在武力决策（RTF）中的整合挑战及其解决方案。

研究方法: 研究分三步：1) 将不同行为者与AI系统的关系概念化为社会技术系统；2) 识别RTF决策中人机协作的挑战；3) 提出政策建议以解决这些挑战。

研究结果: 研究发现，AI系统整合面临技术本身、整合者角色和人机互动三方面的挑战，需通过政策调整和技术改进来解决。

研究结论: 整合AI系统到RTF决策中需重视整合者的中介作用，并针对技术、角色和互动问题制定具体政策。

中文摘要: AI系统在军事领域的整合正在改变战争相关决策的方式，它将开发者、整合者和用户三个不同的群体联系在一起，并嵌入到既有的组织与系统结构中。本文聚焦于这一社会技术系统中重要但常被忽视的整合者群体。在复杂的人机配置中，整合者负责连接政治和军事系统中的开发者与用户群体，作为中介群体需要深刻理解其他群体的活动、观点和规范。因此，我们探讨了将AI系统整合到武力决策（RTF）过程中出现的挑战与不足，并提出解决方案。为此，我们分三步展开：首先，将不同行为者与AI系统的关系概念化为社会技术系统；其次，识别RTF决策中人机协作的挑战，重点关注技术本身、整合者角色和人机互动带来的问题；最后，提出政策建议以解决AI系统整合到RTF决策结构中的不足。

</details>


### [184] [Formalising Human-in-the-Loop: Computational Reductions, Failure Modes, and Legal-Moral Responsibility](https://arxiv.org/abs/2505.10426)
**中文标题：形式化人机交互：计算归约、失效模式与法律-道德责任**

*Maurice Chiodo,Dennis Müller,Paul Siewert,Jean-Luc Wetherall,Zoya Yasmine,John Burden*

主要分类: cs.CY

摘要简述: 本文探讨了不同人机交互（HITL）设置的法律合规性与安全性差异，提出了一种基于计算理论的形式化方法，揭示了法律责任分配与AI技术可解释性之间的不可避免的权衡。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于揭示不同HITL设置的法律与伦理问题，避免人类成为替罪羊，并为AI开发者和立法者提供设计HITL的实用建议。

研究方法: 通过计算理论中的预言机概念形式化HITL设置，将其分为简单监控、单点人类操作和深度交互三类，并提出HITL失效模式的分类法。

研究结果: 研究发现，现有法律框架对某些HITL设置的关注不足，可能导致伦理和法律目标无法实现，同时揭示了HITL设计中技术决策的复杂性。

研究结论: 结论指出，HITL设计涉及多方面的技术决策，且易受不可控的失效影响，为AI开发者和立法者提供了新的分析视角。

中文摘要: 不同人机交互（HITL）设置的法律合规性与安全性存在显著差异。本文旨在提出新的选择方法，并揭示法律责任分配与AI技术可解释性之间的不可避免的权衡。我们首先利用计算理论中的预言机概念形式化HITL设置，区分简单监控、单点人类操作和深度交互三类，分别对应全函数、多一归约和图灵归约。随后提出HITL失效模式的分类法，揭示其局限性。我们的方法还指出了英国和欧盟法律框架的疏漏，这些框架关注某些HITL设置，但可能无法实现预期的伦理、法律和社会技术目标。我们建议法律应认可不同HITL设置的有效性，并在这些情境中合理分配责任，避免人类成为不必要的替罪羊。总体而言，我们展示了HITL设计涉及多方面的技术决策，且易受人类无法控制的失效影响，为AI开发者和立法者提供了新的分析视角，助力设计更有效的HITL系统。

</details>


### [185] [The Problem of Algorithmic Collisions: Mitigating Unforeseen Risks in a Connected World](https://arxiv.org/abs/2505.20181)
**中文标题：算法碰撞问题：在互联世界中缓解不可预见风险**

*Maurice Chiodo,Dennis Müller*

主要分类: cs.CY

摘要简述: 本文探讨了人工智能和自主算法系统在互联世界中可能引发的系统性风险，特别是算法间的交互导致的不可预见后果。作者提出通过增强透明度和问责制来缓解这些风险，包括分阶段系统注册、部署许可框架和增强监控能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能和自主算法系统的广泛应用，其交互可能引发系统性风险，如市场崩溃、能源供应中断等。当前治理框架缺乏对这些复杂交互的可见性，亟需新的政策建议以应对这些风险。

研究方法: 本文分析了算法交互带来的风险，并提出了一系列政策建议，包括分阶段系统注册、部署许可框架和增强监控能力，以提高透明度和问责制。

研究结果: 研究发现，当前治理框架无法有效应对算法交互带来的系统性风险，而提出的政策建议（如系统注册和许可框架）能够显著提升风险管理的有效性。

研究结论: 作者认为，通过增强透明度和问责制，可以有效缓解算法交互引发的系统性风险，并呼吁政策制定者采纳相关建议以完善治理框架。

中文摘要: 人工智能（AI）和其他自主算法系统的广泛应用为世界带来了新的系统性风险。尽管关注点通常集中在单个算法的功能上，但其交互作用带来的危险尤为严重，尤其是当算法系统在彼此不知情的情况下运行，或部署者对其所处的完整算法生态系统缺乏了解时。这些交互可能导致不可预见且迅速升级的负面后果——从市场崩溃、能源供应中断到潜在的物理事故和公众信任的削弱——往往超出人类有效监控和法律干预的能力范围。当前的治理框架由于缺乏对这一复杂交互生态系统的可见性而显得不足。本文阐述了这一挑战的本质，并提出了一些初步政策建议，包括通过分阶段系统注册、部署许可框架和增强监控能力来提高透明度和问责制。

</details>


### [186] [A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation](https://arxiv.org/abs/2507.05275)
**中文标题：多代理教育临床场景模拟中用于临床推理辅助的模糊监督代理设计**

*Weibing Zheng,Laurah Turner,Jess Kropczynski,Murat Ozer,Seth Overla,Shane Halse*

主要分类: cs.CY

摘要简述: 本文提出了一种模糊监督代理（FSA）的设计，用于多代理教育临床场景模拟（MAECSS）平台，旨在通过模糊推理系统实时分析医学生的临床推理过程并提供自适应反馈。


<details>
  <summary>详细信息</summary>
研究动机: 医学教育中，临床场景训练中的临床推理辅助一直是一个挑战。本文旨在设计一种能够实时监控并提供自适应反馈的代理，以提升医学生的临床推理能力。

研究方法: 设计了一种模糊监督代理（FSA），利用模糊推理系统（FIS）实时分析学生与临床代理（如患者、体检、诊断、干预）的交互，并通过预定义的模糊规则库评估专业性、医学相关性、伦理行为和情境干扰。

研究结果: FSA能够实时分析学生的决策过程，并在学生遇到困难时提供自适应、情境感知的反馈，展示了其在模拟医学教育中的可扩展性和灵活性。

研究结论: FSA为模拟医学教育提供了一种可扩展、灵活且人性化的监督方法，未来工作将包括实证评估和更广泛的教育场景集成。

中文摘要: 在医学教育中，辅助医学生在临床场景训练中进行临床推理（CR）仍然是一个持续的挑战。本文介绍了模糊监督代理（FSA）的设计与架构，这是多代理教育临床场景模拟（MAECSS）平台的一个新组件。FSA利用模糊推理系统（FIS）持续解释学生与专业临床代理（如患者、体检、诊断、干预）的交互，使用预定义的模糊规则库评估专业性、医学相关性、伦理行为和情境干扰。通过实时分析学生的决策过程，FSA旨在提供自适应、情境感知的反馈，并在学生遇到困难时提供精确的辅助。本文重点介绍了FSA的技术框架和设计理念，强调了其在模拟医学教育中提供可扩展、灵活且人性化监督的潜力。未来工作将包括实证评估和更广泛教育场景的集成。更详细的设计和实现已开源。

</details>


### [187] [Hungary and AI: efforts and opportunities in comparison with Singapore](https://arxiv.org/abs/2507.05280)
**中文标题：匈牙利与人工智能：与新加坡的比较努力与机遇**

*András Ferenczy*

主要分类: cs.CY

摘要简述: 本研究评估了匈牙利的国家人工智能战略及其执行情况，并与新加坡的国家人工智能战略进行对比。研究发现匈牙利在AI领域的公共投资总额约为46.5亿欧元，但资金分配不均，且执行过程中存在碎片化问题。研究还提出了针对匈牙利未来AI战略的建议。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估匈牙利国家AI战略的实施效果，并通过与新加坡的对比，为匈牙利未来的AI政策提供改进建议。

研究方法: 通过分析战略文件、公开财务记录以及对匈牙利AI联盟主席和政府AI专员首席战略顾问的专家访谈，评估了匈牙利AI战略的22个目标，并从概念、治理、时间和财务维度进行了对比分析。

研究结果: 研究发现匈牙利的AI公共投资总额约为46.5亿欧元，但仅有一半目标的财务数据公开，且98%的资金集中在三个项目上。执行过程中存在碎片化问题，且自2020年起缺乏定期审查。

研究结论: 研究建议匈牙利借鉴新加坡的经验，调整战略以适应大语言模型时代，优化三重螺旋网络以促进对话，并利用其地理位置优势成为东西方汽车AI实验的桥梁。

中文摘要: 本研究通过分析战略文件、公开财务记录以及对匈牙利AI联盟主席和政府AI专员首席战略顾问的专家访谈，评估了匈牙利国家AI战略及其执行情况。研究对匈牙利战略中的22个目标从概念、治理、时间和财务维度进行了评估，并与新加坡的国家AI战略（NAIS 1.0和NAIS 2.0）进行了对比。主要发现包括匈牙利在AI领域的公共投资总额约为46.5亿欧元，但仅有一半目标的财务数据公开，且98%的资金集中在三个项目上。研究还揭示了匈牙利在执行过程中面临的挑战，包括因部门重组导致的碎片化执行以及自2020年起缺乏定期审查。此外，研究基于新加坡的框架为匈牙利未来的AI战略提出了针对性建议，包括适应大语言模型时代、优化三重螺旋网络以促进更有效的对话和倡导，以及将匈牙利定位为东西方汽车AI实验的桥梁。

</details>


### [188] [Integrating Generative AI in BIM Education: Insights from Classroom Implementation](https://arxiv.org/abs/2507.05296)
**中文标题：将生成式AI融入BIM教育：课堂实施的见解**

*Islem Sahraoui,Kinam Kim,Lu Gao,Zia Din,Ahmed Senouci*

主要分类: cs.CY

摘要简述: 本研究探讨了在美国大学研究生BIM课程中引入生成式AI进行规则检查的教学实践，55名学生参与了两学期的试点。结果显示，学生虽达成学习目标，但面临调试AI生成代码和工具性能不稳定的挑战，尤其是编程基础薄弱的学生。尽管如此，学生对未来应用生成式AI表现出浓厚兴趣。


<details>
  <summary>详细信息</summary>
研究动机: 生成式AI在建筑信息模型（BIM）教育中的应用研究较少，本研究旨在填补这一空白，探索生成式AI在BIM合规任务中的教学效果和学生体验。

研究方法: 研究在两学期的研究生BIM课程中实施生成式AI规则检查工作流，包括提示工程和AI驱动规则检查的讲座，以及学生使用大型语言模型（LLM）在Autodesk Revit中识别设计违规的作业。通过NASA-TLX量表和回归分析评估学生工作量和学习效果。

研究结果: 学生普遍达成学习目标，但调试AI生成代码和工具性能不稳定等问题增加了认知和情感负担，尤其是编程基础薄弱的学生。学生对未来生成式AI应用表现出强烈兴趣，尤其是在明确教学支持下。

研究结论: 生成式AI在BIM教育中具有潜力，但需解决调试和工具性能问题，并提供针对性教学支持以提升学生体验。

中文摘要: 本研究评估了在美国一所大学研究生建筑信息模型（BIM）课程中实施生成式AI驱动的规则检查工作流的效果。两学期内，55名学生参与了一项课堂试点，探索生成式AI在BIM合规任务中的应用，该领域此前研究较少。教学设计包括提示工程和AI驱动规则检查的讲座，随后学生通过大型语言模型（LLM）在Autodesk Revit中识别设计违规的作业。通过NASA-TLX量表和回归分析评估学生工作量、学习效果及整体体验。结果显示，学生普遍达成学习目标，但面临调试AI生成代码和工具性能不稳定等挑战，可能因其提示工程经验有限。这些问题增加了认知和情感负担，尤其是编程基础薄弱的学生。尽管如此，学生对未来生成式AI应用表现出浓厚兴趣，尤其是在明确教学支持下。

</details>


### [189] [Narrowing the Gap: Supervised Fine-Tuning of Open-Source LLMs as a Viable Alternative to Proprietary Models for Pedagogical Tools](https://arxiv.org/abs/2507.05305)
**中文标题：缩小差距：监督微调开源LLM作为专有模型的可行替代方案用于教学工具**

*Lorenzo Lee Solano,Charles Koutcheme,Juho Leinonen,Alexandra Vassar,Jake Renzella*

主要分类: cs.CY

摘要简述: 研究表明，通过监督微调（SFT）增强的小型开源语言模型可以作为教育工具的可行替代方案，性能接近大型专有模型。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（如ChatGPT和Gemini）虽然能解析编程错误，但其计算规模、成本高且容易过度辅助，不适合广泛教育应用。因此，研究探索小型专用模型通过SFT提升性能的可行性。

研究方法: 研究使用40,000条C编译器错误解释数据集，对三种开源模型（Qwen3-4B、Llama-3.1-8B和Qwen3-32B）进行监督微调，并结合专家评审和自动化分析（LLM-as-judge）进行双重评估。

研究结果: 结果表明，SFT显著提升了小型模型的教学质量，性能接近大型模型。模型大小与质量之间存在权衡，但高质量领域数据微调小型模型是有效的策略。

研究结论: 监督微调小型高效模型是推动教育工具发展的有效方法，为教育领域提供更广泛的生成式AI能力。

中文摘要: 前沿大型语言模型（如ChatGPT和Gemini）能够为新手程序员解析复杂的编译器错误，但其计算规模大、成本高且容易过度辅助，不适合广泛教学应用。本研究证明，通过监督微调（SFT）增强的小型专用语言模型是教育工具的更可行替代方案。我们使用了一个包含40,000条C编译器错误解释的新数据集，这些数据源自真实的新手编程（CS1/2）学生生成的编程错误，并用于微调三种开源模型：Qwen3-4B、Llama-3.1-8B和Qwen3-32B。我们进行了双重评估，结合专家评审和基于已验证的LLM-as-judge集成对8,000条响应进行大规模自动化分析。结果显示，SFT显著提升了小型模型的教学质量，性能接近大型模型。我们分析了模型大小与质量之间的权衡，确认在高质量领域数据上微调紧凑高效模型是创建专用模型以推动教育工具的强大策略。我们提供了一种可复制的方法论，以促进教育环境中生成式AI能力的更广泛普及。

</details>


### [190] [AGACCI : Affiliated Grading Agents for Criteria-Centric Interface in Educational Coding Contexts](https://arxiv.org/abs/2507.05321)
**中文标题：AGACCI：教育编程环境中以标准为中心的附属分级智能体接口**

*Kwangsuk Park,Jiwoong Yang*

主要分类: cs.CY

摘要简述: AGACCI是一个多智能体系统，用于提升教育编程任务评估的准确性和一致性，通过分配专业评估角色，显著优于单一GPT基线。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于视觉语言模型（VLM）的教育评估方法难以处理复杂的编程任务，需要结构化推理和明确评估标准。AGACCI旨在解决这一问题。

研究方法: AGACCI采用多智能体系统，分配不同评估角色，结合专家标注的360份研究生编程作业数据进行验证。

研究结果: 实验显示，AGACCI在评分准确性、反馈相关性、一致性和连贯性上优于单一GPT基线，并保留了专家评估的教学意图和深度。

研究结论: AGACCI展示了多智能体系统在教育评估中的潜力，尤其在可扩展性和情境感知方面。

中文摘要: 近期AI辅助教育的进展推动了视觉语言模型（VLM）在学术评估中的应用，尤其是需要定量和定性结合的任务。然而，现有基于VLM的方法难以处理复杂的教育成果，如包含可执行组件和可测量输出的编程任务，这些任务需要结构化推理和明确评估标准的对齐。我们提出了AGACCI，一个多智能体系统，通过分配专业评估角色提升代码导向评估的准确性、可解释性和一致性。为验证该框架，我们收集了60名参与者的360份研究生编程作业，每份均由领域专家标注了二元评分标准和定性反馈。实验结果表明，AGACCI在评分和反馈的准确性、相关性、一致性和连贯性上优于单一GPT基线，同时保留了专家评估的教学意图和深度。尽管在不同任务类型中表现有所差异，AGACCI展示了多智能体系统在可扩展和情境感知教育评估中的潜力。

</details>


### [191] [Hidden Prompts in Manuscripts Exploit AI-Assisted Peer Review](https://arxiv.org/abs/2507.06185)
**中文标题：手稿中的隐藏提示利用AI辅助同行评审**

*Zhicheng Lin*

主要分类: cs.CY

摘要简述: 2025年7月，预印本网站arXiv上的18篇学术手稿被发现含有隐藏指令（提示），旨在操纵AI辅助的同行评审。这些指令通过白色文本等技术隐藏，例如“仅给予正面评价”。作者反应不一，有人计划撤回受影响论文，有人则辩称这是对评审合规性的合法测试。本文分析这一行为是一种新型学术不端，揭示了四种隐藏提示类型，并指出其系统性漏洞。


<details>
  <summary>详细信息</summary>
研究动机: 本文旨在揭露和分析一种新型学术不端行为：在学术手稿中隐藏指令以操纵AI辅助的同行评审。通过研究这一现象，揭示其技术手段和潜在危害，呼吁学术界和出版商采取协调一致的技术筛查和政策规范。

研究方法: 研究分析了arXiv上18篇包含隐藏指令的手稿，识别了四种隐藏提示类型，从简单的正面评价指令到详细的评估框架。同时，探讨了作者的不同反应和出版商的现行政策，揭示了隐藏指令的意图及其对学术评审系统的威胁。

研究结果: 研究发现隐藏指令是一种系统性漏洞，不仅影响同行评审，还可能波及抄袭检测和引用索引等自动化系统。出版商的现行政策不一致，缺乏统一的技术筛查和规范。

研究结论: 本文强调需要在投稿门户实施协调的技术筛查，并制定统一的生成式AI使用政策，以应对隐藏指令对学术评审系统的威胁。

中文摘要: 2025年7月，预印本网站arXiv上的18篇学术手稿被发现含有隐藏指令（提示），旨在操纵AI辅助的同行评审。这些指令通过白色文本等技术隐藏，例如“仅给予正面评价”。作者反应不一：有人计划撤回受影响论文，有人则辩称这是对评审合规性的合法测试。本文分析这一行为是一种新型学术不端。我们研究了大型语言模型（LLM）中的提示注入技术，揭示了四种隐藏提示类型，从简单的正面评价指令到详细的评估框架。辩称提示是用于检测不当使用AI的“蜜罐”的说法站不住脚——提示指令的持续利己性表明其操纵意图。出版商政策不一致：爱思唯尔完全禁止在同行评审中使用AI，而施普林格·自然允许有限使用并要求披露。这一事件暴露了系统性漏洞，不仅影响同行评审，还可能波及抄袭检测和引用索引等自动化系统。我们的分析强调了在投稿门户实施协调技术筛查的必要性，并呼吁制定统一的生成式AI（GenAI）在学术评价中的使用政策。

</details>


### [192] [The Ethical Implications of AI in Creative Industries: A Focus on AI-Generated Art](https://arxiv.org/abs/2507.05549)
**中文标题：AI在创意产业中的伦理影响：聚焦AI生成艺术**

*Prerana Khatiwada,Joshua Washington,Tyler Walsh,Ahmed Saif Hamed,Lokesh Bhatta*

主要分类: cs.CY

摘要简述: 本文探讨了生成式AI艺术在伦理上的复杂性和争议，包括环境影响、名人形象、知识产权、深度伪造和艺术家失业等问题，并提出了可能的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI技术的快速发展，生成式AI艺术引发了广泛的伦理争议。本文旨在深入分析这些伦理问题，揭示其背后的复杂性，并为解决这些问题提供思路。

研究方法: 通过深入研究生成式AI艺术的伦理问题，包括环境影响、名人形象、知识产权、深度伪造和艺术家失业等方面，结合历史背景和不同观点，提出解决方案。

研究结果: 研究发现，生成式AI艺术导致碳排放增加、虚假信息传播、版权侵权、非法描绘和艺术家失业等问题。

研究结论: 生成式AI艺术亟需立法和监管，以解决其带来的伦理问题。

中文摘要: 随着人工智能（AI）的快速发展，每天都会涌现出令人兴奋（同时也颇具争议）的技术。AI的进步让越来越多的人对其产生怀疑。本文探讨了生成式AI艺术在伦理上的复杂性和困惑。我们深入研究了AI的伦理问题，特别是生成艺术。我们从兴奋中抽身，观察这项令人印象深刻的技术所带来的无解难题，包括环境影响、名人形象、知识产权、深度伪造和艺术家失业等问题。研究发现，生成式AI艺术导致了碳排放增加、虚假信息传播、版权侵权、非法描绘和艺术家失业。基于此，我们提出了多种可能的解决方案。我们分析了每种情况的历史、原因和后果，并提供了不同观点。归根结底，核心主题是生成式AI艺术需要正确的立法和监管。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [193] [GATMesh: Clock Mesh Timing Analysis using Graph Neural Networks](https://arxiv.org/abs/2507.05681)
**中文标题：GATMesh：基于图神经网络的时钟网格时序分析**

*Muhammad Hadir Khan,Matthew Guthaus*

主要分类: cs.AR

摘要简述: GATMesh是一种基于图神经网络的时钟网格时序分析框架，通过模拟SPICE数据实现高精度和快速分析，平均延迟误差为5.27ps，速度提升47146倍。


<details>
  <summary>详细信息</summary>
研究动机: 时钟网格在高性能VLSI系统中对减少偏移和处理PVT变化至关重要，但传统分析方法（如SPICE仿真）速度慢，简化模型又无法捕捉关键效应（如斜率和输入偏移）。因此，需要一种既能保持高精度又能显著提升速度的新方法。

研究方法: GATMesh将时钟网格建模为带有增强结构和物理特征的图，并利用图神经网络（GNN）框架进行训练，数据来源于SPICE仿真。

研究结果: GATMesh在未见过的基准测试中实现了平均5.27ps的延迟误差，速度比多线程SPICE仿真快47146倍。

研究结论: GATMesh通过结合图神经网络和SPICE数据，成功解决了时钟网格分析中的精度与速度矛盾，为高性能VLSI设计提供了高效工具。

中文摘要: 时钟网格在高性能VLSI系统中对减少偏移和处理PVT变化至关重要，但其分析因重汇聚路径、多源驱动和输入网格缓冲偏移而困难。SPICE仿真准确但速度慢，而简化模型又无法捕捉斜率和输入偏移等关键效应。我们提出GATMesh，一种基于图神经网络（GNN）的框架，将时钟网格建模为带有增强结构和物理特征的图。通过SPICE数据训练，GATMesh在未见过的基准测试中实现了平均5.27ps的延迟误差，同时速度比多线程SPICE仿真快47146倍。

</details>


### [194] [PrefixAgent: An LLM-Powered Design Framework for Efficient Prefix Adder Optimization](https://arxiv.org/abs/2507.06127)
**中文标题：PrefixAgent：一种基于LLM的高效前缀加法器优化设计框架**

*Dongsheng Zuo,Jiadong Zhu,Yang Luo,Yuzhe Ma*

主要分类: cs.AR

摘要简述: PrefixAgent是一种基于大型语言模型（LLM）的设计框架，用于高效优化前缀加法器，通过分解任务和利用E-graph收集数据，显著提升了性能和可扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 前缀加法器是基础算术电路，但其设计空间随位宽呈指数增长，现有方法在性能、泛化性和可扩展性方面存在局限。

研究方法: PrefixAgent将问题分解为子任务（如骨架合成和结构优化），利用E-graph收集高质量数据和推理轨迹，并基于此微调LLM。

研究结果: 实验表明，PrefixAgent合成的前缀加法器面积更小，同时在商用EDA流程中保持了可扩展性和泛化性。

研究结论: PrefixAgent通过LLM驱动的框架，显著提升了前缀加法器的优化效率，为相关领域提供了新思路。

中文摘要: 前缀加法器是基础算术电路，但其设计空间随位宽呈指数增长，带来显著的优化挑战。现有方法在性能、泛化性和可扩展性方面存在不足。为此，我们提出PrefixAgent，一种基于大型语言模型（LLM）的框架，用于高效优化前缀加法器。具体而言，PrefixAgent将问题分解为骨架合成和结构优化等子任务，有效缩小了搜索空间。更重要的是，这一新设计视角使我们能够利用E-graph高效收集大量高质量数据和推理轨迹，从而实现对LLM的有效微调。实验结果表明，与基线方法相比，PrefixAgent合成的前缀加法器面积更小，同时在商用EDA流程中保持了可扩展性和泛化性。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [195] [Challenges & Opportunities with LLM-Assisted Visualization Retargeting](https://arxiv.org/abs/2507.01436)
**中文标题：LLM辅助可视化重定向的挑战与机遇**

*Luke S. Snyder,Chenglong Wang,Steven M. Drucker*

主要分类: cs.HC

摘要简述: 论文探讨了利用大型语言模型（LLM）辅助可视化重定向的挑战与机遇，分析了两种方法在代码生成与适应中的表现，并提出了未来系统的设计建议。


<details>
  <summary>详细信息</summary>
研究动机: 尽管网络上存在大量可视化示例，但将其重定向到新数据集仍困难且耗时。作者希望通过LLM降低这一过程的门槛，并研究其潜力与局限。

研究方法: 研究比较了两种方法：1) 直接让LLM生成和适应代码；2) 通过LLM提供结构化信息（如视觉编码）指导代码构建。评估了不同数据集和复杂度图表的性能。

研究结果: 两种方法在新数据未适当转换时表现不佳，研究对失败类型和严重性进行了分类，并提出了未来系统的设计建议。

研究结论: LLM辅助可视化重定向具有潜力，但需改进数据转换问题，未来系统设计需更注重结构化指导。

中文摘要: 尽管网络上发布了大量可视化示例，但将现有自定义图表实现重定向到新数据集仍然困难、耗时且繁琐。适应过程要求作者熟悉示例的实现以及新数据集如何转换以适应示例代码。随着大型语言模型（LLM）的最新进展，可以通过高级用户提示自动适应代码，从而降低可视化重定向的门槛。为了更好地理解LLM如何辅助重定向及其潜在限制，我们通过多个数据集和不同复杂度的图表对LLM辅助的性能进行了表征和评估，并根据类型和严重性对失败进行了分类。在评估中，我们比较了两种方法：（1）直接指示LLM模型通过将代码视为文本输入完全生成和适应代码；（2）一种更受约束的程序合成管道，其中LLM通过根据示例代码和数据的属性提供结构信息（如视觉编码）来指导代码构建过程。我们发现，当新数据未适当转换时，两种方法均表现不佳，并讨论了未来重定向系统的重要设计建议。

</details>


### [196] [NRXR-ID: Two-Factor Authentication (2FA) in VR Using Near-Range Extended Reality and Smartphones](https://arxiv.org/abs/2507.05447)
**中文标题：NRXR-ID：利用近场扩展现实和智能手机实现VR中的双因素认证**

*Aiur Nanzatov,Lourdes Peña-Castillo,Oscar Meruvia-Pastor*

主要分类: cs.HC

摘要简述: 本文提出NRXR-ID技术，利用近场扩展现实和智能手机实现VR环境中的双因素认证，用户无需摘下头显即可完成认证挑战。研究通过用户实验验证了四种挑战类型，其中棋盘式视觉匹配挑战表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 虚拟现实（VR）中的双因素认证（2FA）因用户佩戴头显而难以实现。本文旨在解决这一问题，提出一种无需摘下头显的认证方法。

研究方法: 提出NRXR-ID技术，结合智能手机和扩展现实系统，设计四种认证挑战（包括一种新型棋盘式挑战）。通过4X3被试内设计，收集30名参与者的性能数据和主观体验反馈。

研究结果: 棋盘式视觉匹配挑战表现最优，其次是使用智能手机输入PIN码并在VR环境中提交的挑战。

研究结论: NRXR-ID技术有效解决了VR环境中的2FA问题，棋盘式挑战和PIN码输入是可行的认证方式。

中文摘要: 双因素认证（2FA）已成为一种高效且安全的在线身份验证方式。然而，在虚拟现实（VR）中实现2FA存在困难，因为用户通常佩戴头显，无法看到现实环境。本文提出NRXR-ID技术，利用扩展现实系统和智能手机实现2FA，用户无需摘下头显即可完成认证挑战。我们通过用户研究探索了四种挑战类型，包括一种新型棋盘式挑战。用户在三种不同配置下完成挑战，其中一种配置利用智能手机支持基于注视的选择，无需VR控制器。采用4X3被试内设计，研究了所有变体。我们收集了30名参与者的性能指标和主观体验问卷数据。结果表明，棋盘式视觉匹配挑战是最优选择，其次是使用智能手机输入PIN码并在VR环境中提交的挑战。

</details>


### [197] [Constella: Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents](https://arxiv.org/abs/2507.05820)
**中文标题：Constella：基于大语言模型多智能体的故事作者角色互联创作支持工具**

*Syemin Park,Soobin Park,Youn-kyung Lim*

主要分类: cs.HC

摘要简述: Constella是一款基于大语言模型的多智能体工具，旨在帮助故事作者创建相互关联的角色。通过三个功能（朋友发现、日记、评论），支持作者扩展角色关系、比较角色情感并深化角色互动。


<details>
  <summary>详细信息</summary>
研究动机: 研究发现，作者在创作长篇故事时难以设计新角色以影响现有角色，平衡角色间的异同，以及深入刻画角色关系。因此，开发了Constella工具以解决这些问题。

研究方法: Constella基于大语言模型的多智能体系统，提供三个功能：1）朋友发现：推荐相关角色；2）日记：同时展示多个角色的内心世界；3）评论：通过角色间互动体现关系。

研究结果: 部署研究表明，Constella帮助作者创建了更丰富的角色群体，促进了角色情感的比较，并加深了对角色关系的理解。

研究结论: 多智能体互动能有效分散作者的注意力与精力，支持更全面的角色创作。

中文摘要: 在长篇故事创作中，通过关注角色间的动态关系来塑造角色群是一个关键环节。然而，我们的初步研究（N=14）发现，作者难以构思能影响现有角色的新角色，平衡角色间的异同，以及深入刻画角色关系。基于这些观察，我们设计了Constella，一款基于大语言模型的多智能体工具，支持故事作者的互联角色创作过程。Constella提供三个功能：1）朋友发现：推荐相关角色；2）日记：同时展示多个角色的内心世界；3）评论：通过角色间互动体现关系。为期7-8天的部署研究（N=11）表明，Constella帮助作者创建了由相关角色组成的广泛群体，促进了角色情感的比较，并深化了对角色关系的理解。最后，我们讨论了多智能体互动如何帮助作者将注意力与精力分配到角色群中。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [198] [Enjoying Non-linearity in Multinomial Logistic Bandits](https://arxiv.org/abs/2507.05306)
**中文标题：在多项式逻辑赌博中享受非线性**

*Pierre Boudart,Pierre Gaillard,Alessandro Rudi*

主要分类: stat.ML

摘要简述: 本文研究了多项式逻辑赌博问题，通过扩展非线性逻辑模型的分析，提出了一种高效算法，显著改进了多动作场景下的遗憾边界。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注二元逻辑赌博问题，但其非线性特性在复杂应用中（如强化学习或推荐系统）的扩展尚未充分探索。本文旨在填补这一空白，将非线性分析扩展到多项式逻辑赌博框架。

研究方法: 通过扩展定义非线性常数κ*到多项式设置，并设计一种高效算法，利用问题的非线性特性，实现了更优的遗憾边界。

研究结果: 提出的算法在多项式逻辑赌博中实现了问题依赖的遗憾边界O~(Kd√(T/κ*))，优于现有结果O~(Kd√T)，并通过下界证明了对κ*的依赖性是最优的。

研究结论: 本文成功将非线性分析扩展到多项式逻辑赌博，为复杂应用提供了理论支持，并验证了算法的优越性。

中文摘要: 我们研究了多项式逻辑赌博问题，这是广义线性赌博的一种变体，学习者通过选择动作与环境交互，以基于多个可能结果的概率反馈最大化期望奖励。在二元设置中，近期研究关注了逻辑模型非线性的影响（Faury等，2020；Abeille等，2021），并引入了问题依赖常数κ*，该常数可能在某些问题参数中呈指数级增长，并由sigmoid函数的导数捕获。它封装了非线性，并将现有遗憾保证从O(d√T)改进为O(d√(T/κ*))，其中d是参数空间的维度。我们将此分析扩展到多项式逻辑赌博框架，使其适用于具有两个以上选择的复杂应用（如强化学习或推荐系统）。为此，我们将κ*的定义扩展到多项式设置，并提出了一种高效算法，利用问题的非线性特性。我们的方法实现了问题依赖的遗憾边界O~(Kd√(T/κ*))，其中K是动作数量且κ*≥1。这优于现有的O~(Kd√T)保证。此外，我们提供了Ω(d√(T/κ*))的下界，表明对κ*的依赖性是最优的。

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [199] [MP-ALOE: An r2SCAN dataset for universal machine learning interatomic potentials](https://arxiv.org/abs/2507.05559)
**中文标题：MP-ALOE：用于通用机器学习原子间势能模型的r2SCAN数据集**

*Matthew C. Kuner,Aaron D. Kaplan,Kristin A. Persson,Mark Asta,Daryl C. Chrzan*

主要分类: cond-mat.mtrl-sci

摘要简述: MP-ALOE是一个包含近100万次r2SCAN密度泛函理论计算的数据集，涵盖89种元素，主要用于训练通用机器学习原子间势能模型，并在多项基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前机器学习原子间势能模型需要高质量且广泛覆盖元素的数据集，MP-ALOE旨在填补这一空白，提供适用于通用模型训练的高精度数据。

研究方法: 通过主动学习方法生成数据集，主要包含非平衡结构数据，并利用r2SCAN泛函进行高精度计算。随后，基于MP-ALOE训练机器学习势能模型，并在多种基准测试中评估其性能。

研究结果: MP-ALOE在预测平衡结构的热化学性质、非平衡结构的力场、极端变形下的物理合理性以及极端温压条件下的分子动力学稳定性等方面均表现出色。

研究结论: MP-ALOE是一个高质量且广泛适用的数据集，为机器学习原子间势能模型的开发提供了重要资源，并已公开供研究社区使用。

中文摘要: 我们提出了MP-ALOE数据集，包含近100万次基于高精度r2SCAN元广义梯度近似的密度泛函理论计算。该数据集覆盖89种元素，通过主动学习方法生成，主要由非平衡结构组成。我们基于MP-ALOE训练了一个机器学习原子间势能模型，并在一系列基准测试中评估其性能，包括预测平衡结构的热化学性质、非平衡结构的力场、极端静态变形下的物理合理性以及极端温压条件下的分子动力学稳定性。MP-ALOE在所有测试中均表现出色，并已公开供研究社区使用。

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [200] [Cross-Subject DD: A Cross-Subject Brain-Computer Interface Algorithm](https://arxiv.org/abs/2507.05268)
**中文标题：跨被试DD：一种跨被试脑机接口算法**

*Xiaoyuan Li,Xinru Xue,Bohan Zhang,Ye Sun,Shoushuo Xi,Gang Liu*

主要分类: q-bio.NC

摘要简述: 本文提出了一种跨被试脑机接口算法CSDD，通过提取被试间的共同特征构建通用模型，实验表明其性能优于现有方法3.28%。


<details>
  <summary>详细信息</summary>
研究动机: 由于个体间脑活动的差异性，现有脑机接口模型在跨被试时适应性差，限制了其泛化能力和广泛应用。本文旨在解决这一问题。

研究方法: 方法包括：1) 为每个被试训练个性化模型；2) 将个性化模型转换为关系谱；3) 通过统计分析识别共同特征；4) 基于共同特征构建跨被试通用模型。

研究结果: 实验使用BCIC IV 2a数据集，结果表明CSDD算法性能比现有方法提升了3.28%。

研究结论: 本文首次提出了一种提取纯共同特征并构建跨被试通用脑机接口模型的新方法，有助于推动脑机接口技术的广泛应用。

中文摘要: 基于运动想象的脑机接口（BCI）通过解码大脑在想象运动时产生的脑电图（EEG）来实现对外部设备的直接控制。然而，由于个体间脑活动的差异性，现有BCI模型在跨被试时表现出较差的适应性，从而限制了其泛化能力和广泛应用。为解决这一问题，本文提出了一种名为跨被试DD（CSDD）的跨被试BCI算法，该算法通过提取被试间的共同特征构建通用BCI模型。具体方法包括：1) 为每个被试训练个性化模型；2) 将个性化模型转换为关系谱；3) 通过统计分析识别共同特征；4) 基于共同特征构建跨被试通用模型。实验使用了BCIC IV 2a数据集，涉及九名被试。其中八名被试用于训练和提取共同特征，模型的跨被试解码性能在剩余被试上进行了验证。结果表明，与现有类似方法相比，我们的方法在性能上提升了3.28%。本文首次提出了一种提取纯共同特征并构建跨被试通用BCI模型的新方法，从而推动了BCI技术的更广泛应用。

</details>


### [201] [Hierarchy or Heterarchy? A Theory of Long-Range Connections for the Sensorimotor Brain](https://arxiv.org/abs/2507.05888)
**中文标题：层级还是异质层级？关于感觉运动大脑长程连接的理论**

*Jeff Hawkins,Niels Leadholm,Viviane Clay*

主要分类: q-bio.NC

摘要简述: 传统观点认为新皮层的信息流是分层次的，但许多解剖连接不符合这一模型。本文提出“异质层级”概念，认为新皮层组织更灵活，并提出“千脑理论”，认为每个皮层柱都是一个感觉运动学习系统。


<details>
  <summary>详细信息</summary>
研究动机: 传统的新皮层层次模型无法解释许多解剖连接和并行响应现象，因此需要一种更灵活的理论来描述新皮层的组织方式。

研究方法: 提出“千脑理论”，认为皮层柱通过整合多传感器运动输入进行学习，并分析皮层区域间及新皮层与丘脑间的长程连接。

研究结果: 新皮层的连接方式更符合“异质层级”而非严格的层次结构，丘脑在对象与传感器之间的姿态转换中起关键作用。

研究结论: 新皮层的组织方式更可能是异质层级的，这对神经科学和人工智能有广泛意义。

中文摘要: 传统观点认为新皮层的信息流沿区域层次向上传递，每一级处理更复杂的特征，同时信息也通过另一组连接向下传递。尽管层次模型有显著支持，但许多解剖连接不符合标准层次解释。此外，层次排列的区域有时并行响应，而非按层次顺序。这些证据表明，两个区域可以同时并行和层次化运作。鉴于这种灵活性，“异质层级”可能是描述新皮层组织的更合适术语。本文提出了一种新解释，说明感觉和运动信息如何在新皮层中处理。我们提出的“千脑理论”认为每个皮层柱都是一个感觉运动学习系统，通过整合多传感器运动输入进行学习。在这种观点下，即使是初级和次级区域（如V1和V2）也能学习和识别完整的3D对象。这表明区域间的层次连接用于学习由小子对象组成的父对象的组合结构。我们通过分析皮层区域间及新皮层与丘脑间的不同类型长程连接来解释这一理论，并探讨它们在感觉运动区域异质层级中的具体作用。我们还提出丘脑在对象与传感器之间的姿态转换中起关键作用。这一新视角对神经科学和人工智能有广泛意义。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [202] [Differentiable Reward Optimization for LLM based TTS system](https://arxiv.org/abs/2507.05911)
**中文标题：基于大语言模型的可微分奖励优化方法在TTS系统中的应用**

*Changfeng Gao,Zhihao Du,Shiliang Zhang*

主要分类: cs.SD

摘要简述: 本文提出了一种新颖的可微分奖励优化方法（DiffRO），用于提升基于神经编解码语言模型的文本转语音（TTS）系统性能。该方法直接基于神经编解码令牌计算奖励，并通过Gumbel-Softmax技术使奖励函数可微分，简化了强化学习训练过程。实验表明，DiffRO显著提高了TTS系统的发音准确性，并在seed-tts-eval基准测试中达到了最先进的WER结果。


<details>
  <summary>详细信息</summary>
研究动机: 传统的基于人类反馈的强化学习（RLHF）方法在TTS系统中依赖合成音频计算奖励，效率较低且复杂。本文旨在通过直接基于神经编解码令牌计算奖励，并引入可微分优化方法，提升TTS系统的性能和训练效率。

研究方法: 1. 提出DiffRO方法，直接基于神经编解码令牌计算奖励，而非合成音频。2. 使用Gumbel-Softmax技术使奖励函数可微分，简化强化学习训练过程。3. 引入多任务奖励（MTR）模型，从不同角度提供反馈，增强系统对指令的遵循能力。

研究结果: 实验结果表明，DiffRO显著提高了TTS系统的发音准确性，在seed-tts-eval基准测试中达到了最先进的WER结果。此外，结合MTR模型，系统能够以零样本方式控制情感和质量属性。

研究结论: DiffRO方法通过直接优化神经编解码令牌奖励，显著提升了TTS系统的性能，同时简化了训练过程。结合MTR模型，进一步增强了系统的灵活性和指令遵循能力。

中文摘要: 本文提出了一种新颖的可微分奖励优化（DiffRO）方法，旨在提升基于神经编解码语言模型的文本转语音（TTS）系统性能。与传统基于人类反馈的强化学习（RLHF）方法不同，DiffRO直接基于神经编解码令牌计算奖励，而非依赖合成音频。此外，我们采用Gumbel-Softmax技术使奖励函数可微分，从而简化了RLHF训练过程。我们还引入了一种多任务奖励（MTR）模型，能够从不同角度提供反馈，并发现其可以有效增强系统对指令的遵循能力。实验结果表明，DiffRO显著提高了TTS系统的发音准确性，在seed-tts-eval基准测试中达到了最先进的WER结果。此外，结合MTR模型，我们展示了以零样本方式控制情感和质量属性的能力。

</details>


### [203] [Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol](https://arxiv.org/abs/2507.06070)
**中文标题：对比学习和迁移学习在真实评估协议下的高效音频指纹识别**

*Christos Nikou,Theodoros Giannakopoulos*

主要分类: cs.SD

摘要简述: 本文提出了一种新的评估协议，模拟真实环境中的噪声条件，发现现有CNN模型性能显著下降。通过改进数据增强和引入Transformer模型，显著提升了音频指纹识别的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有音频指纹识别方法在受控条件下表现良好，但在真实噪声环境中性能显著下降。本文旨在设计更贴近现实的评估协议，并提出改进方法以提升模型在噪声环境中的表现。

研究方法: 1. 提出新的评估协议，模拟移动设备在噪声环境中的录音条件；2. 改进数据增强流程，加入低通和高通滤波器；3. 设计基于Transformer的模型，并利用语义相关领域的知识迁移。

研究结果: 在噪声环境下，Transformer模型表现优于CNN模型：低噪声条件下，1秒查询准确率为47.99%，10秒查询为97%；高噪声条件下，15秒查询检测率为56.5%。

研究结论: 通过改进评估协议和数据增强，结合Transformer架构和知识迁移，显著提升了音频指纹识别在真实噪声环境中的性能。

中文摘要: 近年来，歌曲识别技术利用深度神经网络直接从原始波形中学习紧凑的音频指纹。尽管这些方法在受控条件下表现良好，但在通过移动设备麦克风在噪声环境中捕获音频的真实场景中，其准确性显著下降。本文提出了一种新的评估协议，旨在更好地反映此类真实条件。我们生成了同一音频的三个录音，每个录音的噪声水平逐渐增加，均通过移动设备麦克风捕获。结果显示，两种最先进的基于CNN的模型在此协议下的性能较之前报告的基准显著下降。此外，我们强调了在对比损失训练中数据增强流程的关键作用。通过在增强流程中引入低通和高通滤波器，显著提升了两种系统在提议评估中的性能。进一步，我们开发了一种基于Transformer的模型，配备定制投影模块，并证明从语义相关领域迁移知识可提供更鲁棒的解决方案。Transformer架构在所有噪声水平和查询时长上均优于基于CNN的模型。在低噪声条件下，1秒查询的准确率为47.99%，10秒查询为97%，分别超出第二优模型14%和18.5%。在高噪声条件下，15秒查询的检测率为56.5%。所有实验均在包含超过10万首歌曲的公开大规模数据集上进行，查询与5600万向量的数据库匹配。

</details>


### [204] [Speech Quality Assessment Model Based on Mixture of Experts: System-Level Performance Enhancement and Utterance-Level Challenge Analysis](https://arxiv.org/abs/2507.06116)
**中文标题：基于混合专家的语音质量评估模型：系统级性能增强与句子级挑战分析**

*Xintong Hu,Yixuan Chen,Rui Yang,Wenxiang Guo,Changhao Pan*

主要分类: cs.SD

摘要简述: 本文提出了一种基于混合专家（MoE）的语音质量评估模型，通过自监督学习模型和数据增强提升系统性能，但句子级预测任务改进有限，揭示了当前方法在句子级评估中的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有语音质量评估模型在不同粒度预测任务中表现差异显著，尤其在句子级任务中性能不足，亟需改进。

研究方法: 基于自监督学习模型（如wav2vec2），设计了混合专家（MoE）分类头，并利用多商业生成模型的合成数据进行数据增强。

研究结果: 模型在系统级性能上有所提升，但句子级预测任务的改进有限，揭示了当前方法在句子级评估中的挑战。

研究结论: 研究揭示了句子级语音质量评估的局限性，为自动语音质量评估领域提供了新的技术路径，并探讨了不同评估粒度性能差异的根本原因。

中文摘要: 自动语音质量评估在语音合成系统的发展中起着关键作用，但现有模型在不同粒度预测任务中表现出显著的性能差异。本文提出了一种基于自监督学习语音模型的增强MOS预测系统，结合了混合专家（MoE）分类头，并利用多商业生成模型的合成数据进行数据增强。我们的方法基于现有的自监督模型（如wav2vec2），设计了一种专门的MoE架构以应对不同类型的语音质量评估任务。我们还收集了一个大规模合成语音数据集，涵盖最新的文本到语音、语音转换和语音增强系统。然而，尽管采用了MoE架构和扩展数据集，模型在句子级预测任务中的性能改进仍然有限。我们的工作揭示了当前方法在处理句子级质量评估时的局限性，为自动语音质量评估领域提供了新的技术路径，并深入探讨了不同评估粒度性能差异的根本原因。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [205] [ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark](https://arxiv.org/abs/2507.05727)
**中文标题：ContextASR-Bench：一个大规模上下文语音识别基准测试**

*He Wang,Linhan Ma,Dake Guo,Xiong Wang,Lei Xie,Jin Xu,Junyang Lin*

主要分类: eess.AS

摘要简述: 本文提出了ContextASR-Bench，一个大规模上下文语音识别基准测试，用于评估ASR系统在上下文建模和世界知识推理方面的能力。实验表明，具备强大上下文学习能力的大型音频语言模型显著优于传统ASR模型。


<details>
  <summary>详细信息</summary>
研究动机: 传统ASR模型在上下文建模和世界知识推理方面表现不足，而大型语言模型（LLMs）和大型音频语言模型（LALMs）的发展为ASR系统提供了更强的智能能力。因此，需要一个全面的基准测试来评估ASR系统的上下文识别能力。

研究方法: 提出ContextASR-Bench基准测试，包含40,000条数据，覆盖10多个领域，支持粗粒度和细粒度上下文信息的评估，并分析模型在命名实体识别方面的表现。

研究结果: 实验结果表明，具备强大世界知识和上下文学习能力的LALMs在性能上显著优于传统ASR模型。

研究结论: ContextASR-Bench为评估ASR系统的上下文识别能力提供了全面工具，并验证了LALMs在上下文建模方面的优势。

中文摘要: 自动语音识别（ASR）已被广泛研究，但以往评估主要局限于无上下文场景。这一限制源于传统ASR模型在上下文建模和世界知识推理方面的不足。近年来，大型语言模型（LLMs）和大型音频语言模型（LALMs）的发展显著提升了通用人工智能能力。因此，亟需一个能够评估ASR系统通用性和智能性的基准测试。为此，我们提出了ContextASR-Bench：一个全面的大规模基准测试，用于评估上下文语音识别。该基准包含多达40,000条数据，覆盖10多个领域，支持在忽略或包含粗粒度或细粒度上下文信息的场景下全面评估模型性能。此外，与传统ASR评估不同，我们的基准还包括对模型在识别音频输入中命名实体方面的效能分析。大量实验表明，具备强大世界知识和上下文学习能力的LALMs显著优于传统ASR模型。数据集和评估代码已发布于https://github.com/MrSupW/ContextASR-Bench。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [206] [Self-Attention Based Multi-Scale Graph Auto-Encoder Network of 3D Meshes](https://arxiv.org/abs/2507.05304)
**中文标题：基于自注意力的多尺度3D网格图自动编码器网络**

*Saqib Nazir,Olivier Lézoray,Sébastien Bougleux*

主要分类: cs.GR

摘要简述: 本文提出了一种基于自注意力的多尺度图自动编码器网络（3DGeoMeshNet），用于直接处理3D网格数据，通过各向异性卷积层同时捕捉全局和局部特征，避免了传统方法中需要将网格转换为中间表示的局限性。在COMA人脸数据集上的实验表明，该方法在重建精度上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 3D网格数据在计算机视觉和图形学中广泛应用，但由于其非欧几里得特性，传统的卷积神经网络（CNNs）难以直接处理。现有的图卷积网络（GCNs）方法多采用各向同性滤波器或谱分解，无法同时有效捕捉局部和全局特征。因此，本文旨在提出一种直接在空间域中学习3D网格特征的新方法。

研究方法: 本文提出的3DGeoMeshNet采用基于图卷积网络的框架，通过各向异性卷积层在空间域中直接学习3D网格的全局和局部特征。网络采用多尺度编码器-解码器结构，分别通过全局和局部路径捕捉大尺度几何结构和细粒度细节，同时保留了原始多边形网格格式，避免了中间表示的转换。

研究结果: 在COMA人脸数据集上的实验结果表明，3DGeoMeshNet在3D网格重建任务中表现优异，显著提升了重建精度。

研究结论: 3DGeoMeshNet通过直接在空间域中学习3D网格特征，避免了传统方法的局限性，能够同时捕捉全局和局部特征，为3D网格处理提供了一种高效且准确的新方法。

中文摘要: 3D网格是计算机视觉和图形学中用于捕捉复杂几何形状的基本数据表示形式。尽管卷积神经网络（CNNs）在图像等结构化数据上表现出色，但由于3D网格的非欧几里得特性，将其扩展到不规则3D网格具有挑战性。图卷积网络（GCNs）通过将卷积应用于图结构数据提供了一种解决方案，但许多现有方法依赖于各向同性滤波器或谱分解，限制了其同时捕捉局部和全局网格特征的能力。本文提出了一种新型的基于GCN的框架——3D几何网格网络（3DGeoMeshNet），该框架利用各向异性卷积层直接在空间域中有效学习全局和局部特征。与之前将网格转换为体素网格或点云等中间表示的方法不同，我们的方法在整个重建过程中保留了原始多边形网格格式，从而实现更精确的形状重建。我们的架构采用多尺度编码器-解码器结构，通过独立的全局和局部路径捕捉大尺度几何结构和细粒度局部细节。在包含人脸的COMA数据集上进行的大量实验证明了3DGeoMeshNet在重建精度上的高效性。

</details>


### [207] [LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for Panorama-Style Mobile Captures](https://arxiv.org/abs/2507.06109)
**中文标题：LighthouseGS：面向全景式移动拍摄的室内结构感知3D高斯泼溅**

*Seungoh Han,Jaehoon Jang,Hyunsu Kim,Jaeheung Surh,Junhyung Kwak,Hyowon Ha,Kyungdon Joo*

主要分类: cs.GR

摘要简述: LighthouseGS是一种基于3D高斯泼溅的室内全景视图合成框架，通过手机简单拍摄实现高质量渲染，解决了旋转主导运动和窄基线带来的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D高斯泼溅技术需要精细拍摄覆盖整个场景的图像，限制了普通用户的使用。本文旨在开发一种基于简单全景运动的实用框架，提升室内场景的渲染质量。

研究方法: LighthouseGS利用手机相机姿态和单目深度估计等几何先验，结合室内平面结构，提出平面支架组装初始化方法和稳定剪枝策略，并通过几何和光度校正解决运动漂移和自动曝光问题。

研究结果: 在真实和合成室内场景测试中，LighthouseGS实现了逼真渲染效果，优于现有方法，展示了全景视图合成和物体放置的潜力。

研究结论: LighthouseGS通过结合几何先验和平面结构，显著提升了基于简单全景运动的室内3D渲染质量，为普通用户提供了更便捷的高质量视图合成方案。

中文摘要: 近年来，3D高斯泼溅（3DGS）技术的进步使得室内场景的实时新视角合成（NVS）成为可能，并展现出令人印象深刻的渲染质量。然而，实现高保真渲染需要精细拍摄覆盖整个场景的图像，限制了普通用户的使用。本文旨在开发一种基于简单全景运动的实用3DGS框架，仅需手持设备（如手机）即可完成拍摄。尽管这种旋转主导的运动方式便捷，但其窄基线使得相机姿态和3D点估计在纹理稀疏的室内场景中尤为困难。为解决这些问题，我们提出了LighthouseGS，一种受灯塔式全景扫描运动启发的新框架。LighthouseGS利用手机相机姿态和单目深度估计等粗略几何先验，并结合室内常见的平面结构。我们提出了一种称为平面支架组装的初始化方法，以在这些结构上生成一致的3D点，随后通过稳定剪枝策略提升几何和优化稳定性。此外，我们还引入了几何和光度校正，以解决手机设备中运动漂移和自动曝光带来的不一致性。在真实和合成室内场景的测试中，LighthouseGS实现了逼真的渲染效果，超越了现有方法，展示了全景视图合成和物体放置的潜力。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [208] [Evaluation of Habitat Robotics using Large Language Models](https://arxiv.org/abs/2507.06157)
**中文标题：基于大型语言模型的栖息地机器人评估**

*William Li,Lei Hamilton,Kaise Al-natour,Sanjeev Mohindra*

主要分类: cs.RO

摘要简述: 本文通过Meta PARTNER基准评估大型语言模型在机器人任务中的表现，发现推理模型o3-mini优于非推理模型GPT-4o和Llama 3，尤其在协作任务中表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估大型语言模型在机器人协作任务中的有效性，探索其在简化环境中的表现，为机器人开发提供新思路。

研究方法: 使用Meta PARTNER基准测试，模拟随机厨房场景中的协作任务，对比多种前沿模型的表现，包括o3-mini、GPT-4o和Llama 3。

研究结果: o3-mini在集中式、分散式、完全可观测和部分可观测配置中均表现优异，显著优于GPT-4o和Llama 3。

研究结论: 推理模型在机器人协作任务中具有优势，为机器人开发提供了新的研究方向。

中文摘要: 本文通过Meta PARTNER基准评估大型语言模型在机器人任务中的表现。Meta PARTNER提供了简化的环境和随机化的室内厨房场景中的机器人交互。每个随机厨房场景中，两个机器人代理协作完成任务。我们评估了多种前沿模型在Meta PARTNER环境中的表现。结果表明，在PARTNER的机器人环境中，推理模型如OpenAI o3-mini的表现优于非推理模型如OpenAI GPT-4o和Llama 3。o3-mini在集中式、分散式、完全可观测和部分可观测配置中均表现优异。这为机器人开发提供了有前景的研究方向。

</details>


### [209] [DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation](https://arxiv.org/abs/2507.05627)
**中文标题：DreamGrasp：基于部分视图图像的零样本3D多物体重建用于机器人操作**

*Young Hun Kim,Seungyeon Kim,Yonghyeon Lee,Frank Chongwoo Park*

主要分类: cs.RO

摘要简述: DreamGrasp利用预训练图像生成模型的想象力，从稀疏RGB图像中重建3D几何并识别物体实例，适用于复杂多物体环境。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在部分视图、遮挡严重的真实场景中泛化能力不足，DreamGrasp旨在解决这一问题。

研究方法: 结合粗粒度3D重建、对比学习的实例分割和文本引导的实例级细化，利用生成模型推断未观察到的场景部分。

研究结果: 实验表明，DreamGrasp能准确恢复物体几何形状，并支持后续任务如顺序清理和目标检索。

研究结论: DreamGrasp在复杂多物体环境中实现了鲁棒的3D重建，优于现有方法。

中文摘要: 部分视图3D识别——从少量稀疏RGB图像中重建3D几何并识别物体实例——是一项极具挑战性但实际中至关重要的任务，尤其是在杂乱、遮挡的真实场景中，全视图或可靠的深度数据通常不可用。现有方法，无论是基于强对称性先验还是在精选数据集上的监督学习，都无法泛化到此类场景。本文提出DreamGrasp，该框架利用大规模预训练图像生成模型的想象力推断场景中未观察到的部分。通过结合粗粒度3D重建、基于对比学习的实例分割和文本引导的实例级细化，DreamGrasp克服了现有方法的限制，实现了复杂多物体环境中的鲁棒3D重建。实验表明，DreamGrasp不仅能准确恢复物体几何形状，还能以高成功率支持顺序清理和目标检索等下游任务。

</details>


### [210] [3DGS_LSR:Large_Scale Relocation for Autonomous Driving Based on 3D Gaussian Splatting](https://arxiv.org/abs/2507.05661)
**中文标题：3DGS_LSR：基于3D高斯泼溅的自动驾驶大规模重定位**

*Haitao Lu,Haijier Chen,Haoze Liu,Shoujian Zhang,Bo Xu,Ziao Liu*

主要分类: cs.RO

摘要简述: 本文提出了一种基于3D高斯泼溅的大规模重定位框架3DGS-LSR，仅需单目RGB图像即可实现厘米级定位，适用于复杂城市环境中的自动驾驶。


<details>
  <summary>详细信息</summary>
研究动机: 在复杂城市环境中，GNSS定位常因信号遮挡和多路径效应不可靠，传统地图方法又受限于存储和计算效率。为此，研究团队开发了3DGS-LSR，旨在为资源受限的机器人平台提供高精度定位解决方案。

研究方法: 结合多传感器数据构建高精度3D高斯泼溅地图，客户端仅需单目RGB输入。通过SuperPoint和SuperGlue进行特征提取与匹配，采用迭代优化策略逐步优化定位结果，适用于实时导航。

研究结果: 在KITTI数据集上的实验表明，3DGS-LSR在城镇道路、林荫大道和交通密集高速公路上的平均定位精度分别为0.026米、0.029米和0.081米，显著优于其他方法。

研究结论: 3DGS-LSR为自动驾驶机器人提供了在GNSS失效的复杂城市环境中仍能实现可靠定位的能力，仅需单目RGB输入即可达到厘米级精度。

中文摘要: 在自主机器人系统中，精确定位是安全导航的前提。然而，在复杂的城市环境中，GNSS定位常因信号遮挡和多路径效应导致绝对定位不可靠。传统地图方法受限于存储需求和计算效率，难以应用于资源受限的机器人平台。为解决这些问题，我们提出了3DGS-LSR：一种基于3D高斯泼溅（3DGS）的大规模重定位框架，仅需客户端单目RGB图像即可实现厘米级定位。我们结合多传感器数据构建大型户外场景的高精度3DGS地图，而机器人端的定位仅需标准相机输入。通过SuperPoint和SuperGlue进行特征提取与匹配，我们的核心创新是一种迭代优化策略，通过逐步渲染优化定位结果，适用于实时自主导航。在KITTI数据集上的实验验证表明，3DGS-LSR在城镇道路、林荫大道和交通密集高速公路上的平均定位精度分别为0.026米、0.029米和0.081米，显著优于其他代表性方法，且仅需单目RGB输入。该方法为自动驾驶机器人在GNSS失效的复杂城市环境中提供了可靠的定位能力。

</details>


### [211] [LeAD: The LLM Enhanced Planning System Converged with End-to-end Autonomous Driving](https://arxiv.org/abs/2507.05754)
**中文标题：LeAD：融合端到端自动驾驶与大型语言模型的增强规划系统**

*Yuhang Zhang,Jiaqi Liu,Chengkai Xu,Peng Hang,Jian Sun*

主要分类: cs.RO

摘要简述: 论文提出LeAD系统，结合端到端自动驾驶框架与大型语言模型（LLM），通过双速率架构提升复杂场景处理能力，实验显示其在非常规场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前城市自动驾驶系统在复杂场景和边缘案例中表现不佳，无法有效理解交通语义信息和其他参与者意图，导致决策与熟练驾驶员推理模式不符。

研究方法: LeAD采用双速率架构：高频端到端子系统负责实时感知-规划-控制循环，低频LLM模块通过多模态感知融合高清地图提升场景理解，并在基线规划器能力不足时通过链式思维推理优化决策。

研究结果: 在CARLA模拟器中，LeAD在非常规场景中表现卓越，Leaderboard V1基准测试得分71分，路线完成率达93%。

研究结论: LeAD通过结合端到端框架与LLM增强，显著提升了自动驾驶系统在复杂场景中的决策能力，为大规模部署提供了可行方案。

中文摘要: 城市自动驾驶系统大规模部署的主要障碍在于复杂场景和边缘案例的普遍存在。现有系统无法有效解析交通语义信息并识别其他参与者的意图，导致决策与熟练驾驶员的推理模式不符。我们提出LeAD，一种双速率自动驾驶架构，将基于模仿学习的端到端（E2E）框架与大型语言模型（LLM）增强相结合。高频E2E子系统维持实时感知-规划-控制循环，而低频LLM模块通过多模态感知融合高清地图提升场景理解，并在基线规划器能力不足时通过链式思维（CoT）推理生成最优决策。我们在CARLA模拟器中的实验评估表明，LeAD在非常规场景中表现优异，Leaderboard V1基准测试得分71分，路线完成率达93%。

</details>


### [212] [Comparison of Path Planning Algorithms for Autonomous Vehicle Navigation Using Satellite and Airborne LiDAR Data](https://arxiv.org/abs/2507.05884)
**中文标题：基于卫星和机载LiDAR数据的自动驾驶车辆导航路径规划算法比较**

*Chang Liu,Zhexiong Xue,Tamas Sziranyi*

主要分类: cs.RO

摘要简述: 本文比较了多种路径规划算法在自动驾驶车辆导航中的性能，重点评估了2D和3D场景下的路径成本、计算时间和内存消耗，发现Dijkstra算法在稳定性和效率上表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶车辆在非结构化环境（如森林和山区）中导航面临地形复杂和道路条件多变的挑战，因此需要评估现有路径规划算法的性能，以找到最适合的解决方案。

研究方法: 研究使用高分辨率卫星图像和机载LiDAR数据构建加权像素级道路网络，测试了A*、Dijkstra、RRT*和新型改进蚁群优化算法（NIACO）在2D场景中的性能，以及3D A*、3D Dijkstra、RRT-Connect和NIACO在3D场景中的表现。所有算法在相同起点和终点条件下进行评估。

研究结果: 结果表明，Dijkstra算法在2D和3D场景中均表现出最稳定和高效的性能，尤其是在密集的像素级地理空间道路地图上。

研究结论: Dijkstra算法在静态地形导航中具有可靠性，为未来复杂环境约束下的动态路径规划研究奠定了基础。

中文摘要: 自动驾驶车辆在非结构化环境（如森林和山区）中的导航由于地形不规则和道路条件复杂而面临重大挑战。本研究对主流和成熟的路径规划算法进行了比较评估，这些算法应用于从高分辨率卫星图像和机载LiDAR数据中提取的加权像素级道路网络。在2D道路地图导航中，权重反映了道路条件和地形难度，测试了A*、Dijkstra、RRT*和新型改进蚁群优化算法（NIACO）在DeepGlobe卫星数据集上的表现。对于3D道路地图路径规划，使用提供详细高程信息的Hamilton机载LiDAR数据集评估了3D A*、3D Dijkstra、RRT-Connect和NIACO。所有算法在相同的起点和终点条件下进行评估，重点关注路径成本、计算时间和内存消耗。结果表明，Dijkstra在2D和3D场景中均表现出最稳定和高效的性能，尤其是在密集的像素级地理空间道路地图上。这些发现突出了基于Dijkstra的规划在静态地形导航中的可靠性，并为未来复杂环境约束下的动态路径规划研究奠定了基础。

</details>


### [213] [Fast and Accurate Collision Probability Estimation for Autonomous Vehicles using Adaptive Sigma-Point Sampling](https://arxiv.org/abs/2507.06149)
**中文标题：基于自适应Sigma点采样的自动驾驶碰撞概率快速准确估计**

*Charles Champagne Cossette,Taylor Scott Clawson,Andrew Feit*

主要分类: cs.RO

摘要简述: 提出一种基于自适应Sigma点采样的新型算法，用于快速准确估计动态物体在不确定轨迹下的碰撞概率，中位误差3.5%，运行时间0.21ms。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法常忽略碰撞概率的时间依赖性，导致高估碰撞概率，需开发一种高效且准确的算法以解决此问题。

研究方法: 采用自适应Sigma点采样方案，通过序列化高斯分布轨迹，设计快速简单的碰撞概率估计算法。

研究结果: 在Intel Xeon Gold 6226R处理器上测试，中位误差3.5%，运行时间0.21ms；400个6秒自动驾驶日志片段验证了其准确性。

研究结论: 该算法高效且准确，显著优于现有方法，适用于自动驾驶等实际场景。

中文摘要: 本文提出了一种新型算法，用于估计具有不确定轨迹的动态物体之间的碰撞概率，其中轨迹以高斯分布的位姿序列给出。我们提出了一种自适应Sigma点采样方案，最终生成了一种快速、简单的算法，能够在Intel Xeon Gold 6226R处理器上以3.5%的中位误差和0.21ms的中位运行时间估计碰撞概率。重要的是，该算法明确考虑了碰撞概率的时间依赖性，这在以往工作中常被忽略，否则会导致碰撞概率的高估。最后，该方法在400个6秒的自动驾驶日志片段组成的多样化实际场景中进行了测试，严格评估了其准确性和延迟。

</details>


### [214] [Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model](https://arxiv.org/abs/2507.06174)
**中文标题：基于精确动力学模型的快速双边遥操作与模仿学习的无传感器力控制**

*Koki Yamane,Yunhan Li,Masashi Konosu,Koki Inami,Junji Oaki,Sho Sakaino,Toshiaki Tsuji*

主要分类: cs.RO

摘要简述: 本文提出了一种基于精确动力学模型的快速双边遥操作和模仿学习方法，通过四通道双边控制实现无力传感器的低成本机械臂的力反馈遥操作，并展示了力信息在模仿学习中的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，模仿学习的进展引发了对低成本机械臂遥操作以收集演示数据的兴趣。然而，现有系统多采用单向控制，仅传输目标位置值，难以应对快速或接触密集的任务。本文旨在解决这一问题，实现低成本机械臂的快速力反馈遥操作。

研究方法: 基于精确识别的机械臂动力学模型，该方法整合了非线性项补偿、速度和外力估计，以及随惯性变化调整的可变增益。通过四通道双边控制实现无传感器的力反馈遥操作，并将力信息纳入模仿学习的输入和输出中。

研究结果: 实验表明，该方法能够实现低成本机械臂的快速力反馈遥操作，且将力信息纳入模仿学习策略显著提升了性能。

研究结论: 本文系统在低成本硬件上实现了高保真遥操作和数据收集，展示了力反馈在遥操作和模仿学习中的实际有效性。

中文摘要: 近年来，模仿学习的进展引发了对低成本机械臂遥操作以收集演示数据的兴趣。然而，现有系统多采用单向控制，仅传输目标位置值，虽然易于实现且适用于缓慢、非接触任务，但在快速或接触密集的操作中表现不佳，原因是缺乏力反馈。本文证明了即使是无力传感器的低成本机械臂，通过四通道双边控制也能实现快速力反馈遥操作。基于精确识别的机械臂动力学模型，我们的方法整合了非线性项补偿、速度和外力估计，以及随惯性变化调整的可变增益。此外，利用四通道双边控制收集的数据，我们展示了将力信息纳入学习策略的输入和输出中可提升模仿学习的性能。这些结果凸显了我们的系统在低成本硬件上实现高保真遥操作和数据收集的实际有效性。

</details>


### [215] [Is Diversity All You Need for Scalable Robotic Manipulation?](https://arxiv.org/abs/2507.06219)
**中文标题：多样性是否是机器人操作可扩展性的唯一关键？**

*Modi Shi,Li Chen,Jin Chen,Yuxiang Lu,Chiming Liu,Guanghui Ren,Ping Luo,Di Huang,Maoqing Yao,Hongyang Li*

主要分类: cs.RO

摘要简述: 本文探讨了数据多样性在机器人操作学习中的作用，挑战了“多样性越多越好”的传统观点，揭示了任务多样性比单任务演示数量更重要，多机器人平台数据并非必需，专家多样性可能干扰学习，并提出了一种去偏方法提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 数据扩展在自然语言处理和计算机视觉领域取得了显著成功，但机器人操作中的数据扩展原则尚不明确。本文旨在研究数据多样性在机器人学习中的具体作用，挑战传统观念，为有效扩展机器人操作数据集提供新视角和实用指导。

研究方法: 通过研究任务多样性、机器人平台多样性和专家多样性三个维度，进行广泛实验。提出了一种分布去偏方法，以减少速度多模态对策略学习的干扰。

研究结果: 实验表明：(1)任务多样性比单任务演示数量更重要；(2)多机器人平台数据并非必需，单平台高质量数据也能实现跨平台迁移；(3)专家多样性可能干扰学习，速度多模态是关键因素。提出的去偏方法GO-1-Pro性能提升了15%，相当于使用2.5倍预训练数据。

研究结论: 本文为机器人操作数据集的扩展提供了新视角和实用指导，揭示了数据多样性的复杂作用，并提出了一种有效的去偏方法。

中文摘要: 数据扩展在自然语言处理（NLP）和计算机视觉（CV）的基础模型中取得了显著成功，但机器人操作中有效数据扩展的原则尚不明确。本研究通过考察三个关键维度——任务（做什么）、机器人平台（使用哪种机器人）和专家（由谁演示），探讨了数据多样性在机器人学习中的微妙作用，挑战了“多样性越多越好”的传统直觉。通过在不同机器人平台上的广泛实验，我们发现：(1)任务多样性比单任务演示数量更为关键，有助于从多样化的预训练任务迁移到新的下游场景；(2)多机器人平台的预训练数据对跨平台迁移并非必需——基于高质量单平台数据训练的模型可以高效迁移到不同平台，并在微调阶段表现出更理想的扩展性；(3)专家多样性（源于个体操作偏好和人类演示中的随机变化）可能干扰策略学习，其中速度多模态是关键因素。基于此，我们提出了一种分布去偏方法以减少速度模糊性，由此产生的GO-1-Pro实现了15%的性能提升，相当于使用2.5倍的预训练数据。这些发现为如何有效扩展机器人操作数据集提供了新视角和实用指导。

</details>


### [216] [EC-Flow: Enabling Versatile Robotic Manipulation from Action-Unlabeled Videos via Embodiment-Centric Flow](https://arxiv.org/abs/2507.06224)
**中文标题：EC-Flow：通过以机器人为中心的流实现无动作标注视频中的多功能机器人操作**

*Yixiang Chen,Peiyan Li,Yan Huang,Jiabing Yang,Kehan Chen,Liang Wang*

主要分类: cs.RO

摘要简述: 本文提出了一种名为EC-Flow的框架，通过预测以机器人为中心的流，直接从无动作标注的视频中学习机器人操作，显著提升了在复杂场景（如可变形物体、遮挡和非位移任务）中的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于语言的机器人操作系统通常需要低级别动作标注的数据集进行模仿学习，而现有的物体中心流预测方法在处理刚性物体位移和遮挡时表现有限。本文旨在通过引入以机器人为中心的流（EC-Flow），解决这些问题并提升泛化能力。

研究方法: EC-Flow通过预测以机器人为中心的流，直接从无动作标注的视频中学习操作。结合机器人的运动学特性，该方法显著提升了泛化能力。此外，通过联合优化运动一致性和目标图像预测，引入目标对齐模块，将EC-Flow与语言指令和物体交互连接。

研究结果: 在仿真（Meta-World）和真实任务中验证了EC-Flow的性能，结果表明其在遮挡物体处理（提升62%）、可变形物体操作（提升45%）和非位移任务（提升80%）上优于现有物体中心流方法。

研究结论: EC-Flow通过以机器人为中心的流预测，显著提升了机器人操作的泛化能力，适用于复杂场景，且仅需标准机器人URDF文件即可实现，具有较高的实用性。

中文摘要: 当前基于语言的机器人操作系统通常需要低级别动作标注的数据集进行模仿学习。尽管物体中心流预测方法缓解了这一问题，但其仍局限于涉及刚性物体位移和遮挡较少的场景。本文提出了以机器人为中心的流（EC-Flow），该框架通过预测以机器人为中心的流，直接从无动作标注的视频中学习操作。我们的核心观点是，结合机器人的运动学特性可以显著提升其在多功能操作场景（如可变形物体处理、遮挡和非位移任务）中的泛化能力。为了将EC-Flow与语言指令和物体交互连接，我们进一步引入了目标对齐模块，通过联合优化运动一致性和目标图像预测。此外，将EC-Flow转化为可执行的机器人动作仅需标准的机器人URDF文件来指定关节的运动学约束，这使其在实践中易于使用。我们在仿真（Meta-World）和真实任务中验证了EC-Flow的性能，结果表明其在遮挡物体处理（提升62%）、可变形物体操作（提升45%）和非位移任务（提升80%）上优于现有物体中心流方法。更多信息请访问我们的项目网站：https://ec-flow1.github.io。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [217] [Exploring LLM Capabilities in Extracting DCAT-Compatible Metadata for Data Cataloging](https://arxiv.org/abs/2507.05282)
**中文标题：探索LLM在提取DCAT兼容元数据以支持数据编目的能力**

*Lennart Busch,Daniel Tebernum,Gissel Velarde*

主要分类: cs.IR

摘要简述: 研究探讨了大型语言模型（LLM）在自动生成符合DCAT标准的元数据方面的能力，结果显示LLM生成的元数据质量接近人工水平，尤其在语义理解任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据重要性提升，数据探索效率成为关键，但元数据的手动创建和维护耗时且专业性强。研究旨在验证LLM是否能自动化这一过程，生成高质量的DCAT兼容元数据。

研究方法: 研究测试了零样本和少样本提示策略，使用不同厂商的LLM生成标题和关键词等元数据，并对分类任务进行了模型微调。

研究结果: 结果表明，LLM生成的元数据质量接近人工水平，尤其在需要高级语义理解的任务中表现更好。大模型优于小模型，微调显著提升分类准确性，少样本提示在多数情况下效果更佳。

研究结论: LLM为元数据创建提供了快速可靠的方法，但实际应用中需结合任务特定标准和领域背景。

中文摘要: 高效的数据探索至关重要，因为数据在加速流程、改进预测和开发新业务模型中的作用日益重要。由于数据的指数增长、异构性和分布性，数据消费者通常花费25-98%的时间寻找合适数据。数据目录通过元数据回答用户查询，支持并加速数据探索。然而，元数据的创建和维护通常是手动过程，耗时且需要专业知识。本研究探讨了LLM是否能自动化文本数据的元数据维护，并生成高质量的DCAT兼容元数据。我们测试了零样本和少样本提示策略，使用不同厂商的LLM生成标题和关键词等元数据，并对分类任务进行了模型微调。结果显示，LLM生成的元数据质量接近人工水平，尤其在需要高级语义理解的任务中表现更好。大模型优于小模型，微调显著提升分类准确性，少样本提示在多数情况下效果更佳。尽管LLM为元数据创建提供了快速可靠的方法，但成功应用需结合任务特定标准和领域背景。

</details>


### [218] [A Survey on Proactive Defense Strategies Against Misinformation in Large Language Models](https://arxiv.org/abs/2507.05288)
**中文标题：针对大型语言模型中错误信息的主动防御策略综述**

*Shuliang Liu,Hongyi Liu,Aiwei Liu,Bingchen Duan,Qi Zheng,Yibo Yan,He Geng,Peijie Jiang,Jia Liu,Xuming Hu*

主要分类: cs.IR

摘要简述: 本文提出了一种针对大型语言模型（LLMs）生成错误信息的主动防御策略，通过‘三支柱’框架（知识可信性、推理可靠性和输入鲁棒性）显著提升防御效果，相比传统方法改进达63%。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）生成的错误信息具有自我强化、高度可信和多语言快速传播的特点，传统检测方法难以有效应对，亟需转向主动防御策略。

研究方法: 提出‘三支柱’主动防御框架：1) 知识可信性，确保训练和部署数据的完整性；2) 推理可靠性，嵌入自校正机制；3) 输入鲁棒性，增强模型接口对抗攻击的能力。

研究结果: 通过综合调查和比较分析，主动防御策略在错误信息预防上比传统方法提升63%，尽管存在计算开销和泛化挑战。

研究结论: 未来研究应聚焦于共同设计鲁棒的知识基础、推理认证和抗攻击接口，以确保LLMs能在多领域有效对抗错误信息。

中文摘要: 大型语言模型（LLMs）在关键领域的广泛应用加剧了算法生成错误信息的社会风险。与传统虚假内容不同，LLM生成的错误信息具有自我强化性、高度可信性，并能快速跨语言传播，而传统检测方法难以有效应对。本文提出了一种主动防御范式，从被动的事后检测转向预期性缓解策略。我们提出了‘三支柱’框架：1) 知识可信性，强化训练和部署数据的完整性；2) 推理可靠性，在推理过程中嵌入自校正机制；3) 输入鲁棒性，增强模型接口对抗攻击的韧性。通过对现有技术的全面调查和比较元分析，我们证明主动防御策略在错误信息预防上比传统方法提升高达63%，尽管存在显著的计算开销和泛化挑战。我们认为，未来研究应聚焦于共同设计鲁棒的知识基础、推理认证和抗攻击接口，以确保LLMs能在多领域有效对抗错误信息。

</details>


### [219] [Enhancing Learning Path Recommendation via Multi-task Learning](https://arxiv.org/abs/2507.05295)
**中文标题：基于多任务学习的学习路径推荐增强方法**

*Afsana Nasrin,Lijun Qian,Pamela Obiomon,Xishuang Dong*

主要分类: cs.IR

摘要简述: 本文提出了一种基于多任务学习的LSTM模型，通过共享任务信息提升学习路径推荐效果，实验表明其优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 个性化学习需要根据学习者的独特需求推荐学习路径，现有方法在建模推荐任务时存在冗余和效率不足的问题。

研究方法: 采用多任务LSTM模型，将学习路径推荐重构为序列到序列预测问题，共享LSTM层捕捉通用特征，任务特定层处理不同目标，并引入非重复损失避免冗余推荐。

研究结果: 在ASSIST09数据集上的实验显示，该模型显著优于基线方法。

研究结论: 多任务学习框架有效提升了学习路径推荐的性能，共享信息和任务特定设计的结合是关键。

中文摘要: 个性化学习是一种以学生为中心的教育方法，通过调整内容、节奏和评估来满足每位学习者的独特需求。作为实现个性化学习的关键技术，学习路径推荐依次推荐个性化的学习项目，如讲座和练习。深度学习的进展，尤其是深度强化学习，使得此类推荐的建模更加实用和高效。本文提出了一种多任务LSTM模型，通过利用任务间的共享信息来增强学习路径推荐。该方法将学习路径推荐重构为序列到序列（Seq2Seq）预测问题，从学习者的历史交互中生成个性化的学习路径。模型使用共享的LSTM层捕捉学习路径推荐和深度知识追踪的通用特征，同时为每个目标设计任务特定的LSTM层。为避免重复推荐，非重复损失函数对推荐学习路径中的重复项目进行惩罚。在ASSIST09数据集上的实验表明，所提模型在学习路径推荐任务上显著优于基线方法。

</details>


### [220] [News Source Citing Patterns in AI Search Systems](https://arxiv.org/abs/2507.05301)
**中文标题：AI搜索系统中的新闻来源引用模式**

*Kai-Cheng Yang*

主要分类: cs.IR

摘要简述: AI搜索系统在新闻引用中表现出集中化和自由派倾向，但用户满意度不受引用来源政治倾向或质量影响。


<details>
  <summary>详细信息</summary>
研究动机: AI搜索系统作为新兴信息把关者，其新闻引用模式尚未被充分研究，本研究旨在填补这一空白。

研究方法: 通过分析AI Search Arena平台的24,000次对话和65,000条回答，研究三大提供商（OpenAI、Perplexity、Google）的新闻引用行为。

研究结果: 新闻引用集中于少数媒体且偏向自由派，但低可信度来源较少被引用；用户满意度与引用来源的政治倾向或质量无关。

研究结论: 当前AI搜索系统在新闻引用上存在显著问题，对其设计和治理提出了重要挑战。

中文摘要: AI驱动的搜索系统正成为新的信息把关者，从根本上改变了用户获取新闻和信息的方式。尽管其影响力日益增长，但这些系统的引用模式仍鲜为人知。我们通过分析AI Search Arena（一个AI搜索系统的头对头评估平台）的数据来填补这一空白。数据集包含来自三大提供商（OpenAI、Perplexity和Google）的24,000多次对话和65,000条回答。在这些回答中嵌入的超过366,000次引用中，9%引用了新闻来源。我们发现，尽管不同提供商的模型引用了不同的新闻来源，但它们在引用行为上表现出共同的模式。新闻引用高度集中于少数媒体，并显示出明显的自由派倾向，但低可信度来源很少被引用。用户偏好分析表明，引用新闻来源的政治倾向或质量对用户满意度没有显著影响。这些发现揭示了当前AI搜索系统的重大挑战，并对其设计和治理具有重要意义。

</details>


### [221] [Beyond Retrieval: Ensembling Cross-Encoders and GPT Rerankers with LLMs for Biomedical QA](https://arxiv.org/abs/2507.05577)
**中文标题：超越检索：结合交叉编码器与GPT重排器的LLM集成方法在生物医学问答中的应用**

*Shashank Verma,Fengyi Jiang,Xiangning Xue*

主要分类: cs.IR

摘要简述: 本文提出了一种基于检索增强生成（RAG）的系统，用于生物医学问答任务。通过结合密集嵌入、交叉编码器和大型语言模型（LLMs）的集成方法，系统在BioASQ 2025 Task13b挑战中取得了显著成绩。


<details>
  <summary>详细信息</summary>
研究动机: 生物医学领域的文献数量庞大且快速更新，研究人员和医疗专业人员需要高效的工具来获取相关知识。BioASQ挑战为这一领域提供了重要基准，本文旨在通过构建一个强大的问答系统，提升生物医学信息检索和生成的性能。

研究方法: 系统采用检索增强生成（RAG）框架，首先生成生物医学文章的密集嵌入进行初步检索，然后结合微调的交叉编码器和LLMs进行重排序以筛选最相关文档。在答案生成阶段，使用少量示例提示的指令调优LLMs。

研究结果: 在BioASQ挑战中，系统在检索任务中MAP@10为0.1581（排名第10）。答案生成任务中，系统在是/否问题（F1=0.95，排名12）、事实性问题（MRR=0.64，排名1）、列表问题（F1=0.63，排名5）和理想答案（ROUGE-SU4 F1=0.29，排名11）上表现优异。

研究结论: 本文提出的集成方法在生物医学问答任务中表现出色，证明了检索增强生成框架的有效性。未来可进一步优化模型以提升性能。

中文摘要: 基于信息检索的生物医学语义问答在应对庞大、快速更新和不断增长的生物医学文献中具有重要作用。一个强大的系统可以帮助研究人员、医疗专业人员甚至普通用户获取基于证据的相关知识。BioASQ 2025 Task13b挑战作为重要基准，为这一领域的进步提供了竞争平台。本文介绍了我们参与该挑战的方法和结果，我们构建了一个检索增强生成（RAG）系统，通过检索相关PubMed文档和片段生成答案。在检索任务中，我们生成生物医学文章的密集嵌入进行初步检索，并应用微调的交叉编码器和大型语言模型（LLMs）的集成方法进行重排序以筛选最相关文档。我们的解决方案在检索任务中MAP@10为0.1581，排名第10。在答案生成任务中，我们采用少量示例提示的指令调优LLMs。系统在是/否问题（F1=0.95，排名12）、事实性问题（MRR=0.64，排名1）、列表问题（F1=0.63，排名5）和理想答案（ROUGE-SU4 F1=0.29，排名11）上表现优异。

</details>


### [222] [PLACE: Prompt Learning for Attributed Community Search](https://arxiv.org/abs/2507.05311)
**中文标题：PLACE：基于提示学习的属性社区搜索**

*Shuheng Fang,Kangfei Zhao,Rener Zhang,Yu Rong,Jeffrey Xu Yu*

主要分类: cs.IR

摘要简述: 本文提出PLACE，一种基于提示学习的图框架，用于属性社区搜索（ACS），通过引入可学习的提示令牌增强图结构，提升查询相关性和社区搜索效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有ACS方法在处理查询相关性和图结构优化方面存在不足，PLACE受NLP中提示调优启发，旨在通过提示学习机制提升ACS的性能和可扩展性。

研究方法: PLACE将结构和可学习的提示令牌集成到图中，形成提示增强图结构，通过交替训练优化提示参数和图神经网络（GNN），并采用分治策略提升可扩展性。

研究结果: 在9个真实世界图上进行实验，PLACE在三种ACS查询中平均F1分数比现有最优方法提升22%，且能处理百万级规模图。

研究结论: PLACE通过提示学习机制显著提升了ACS的性能和可扩展性，为图数据上的社区搜索提供了创新解决方案。

中文摘要: 本文提出PLACE（基于提示学习的属性社区搜索），一种创新的图提示学习框架，用于ACS。受NLP中提示调优的启发，PLACE将结构和可学习的提示令牌集成到图中，作为查询依赖的优化机制，形成提示增强图。在该结构中，学习的提示令牌作为桥梁，增强查询相关节点间的连接，使GNN更有效地识别与查询相关的结构凝聚性和属性相似性模式。我们采用交替训练范式联合优化提示参数和GNN。此外，设计了分治策略以提升可扩展性，支持处理百万级规模图。在9个真实世界图上的大量实验表明，PLACE对三种ACS查询均有效，平均F1分数比现有最优方法高22%。

</details>


### [223] [Semantic Certainty Assessment in Vector Retrieval Systems: A Novel Framework for Embedding Quality Evaluation](https://arxiv.org/abs/2507.05933)
**中文标题：向量检索系统中的语义确定性评估：一种嵌入质量评估的新框架**

*Y. Du*

主要分类: cs.IR

摘要简述: 本文提出了一种轻量级框架，通过结合量化鲁棒性和邻域密度指标，预测向量检索系统在查询级别的性能表现，显著提升了检索效果。


<details>
  <summary>详细信息</summary>
研究动机: 由于嵌入质量的异质性，向量检索系统在不同查询中表现差异显著。本文旨在通过分析高质量嵌入在嵌入空间中的几何稳定性和邻域一致性，提出一种预测检索性能的方法。

研究方法: 提出了一种结合量化鲁棒性和邻域密度指标的框架，用于评估嵌入质量并预测检索性能。该方法通过分析嵌入的几何稳定性和邻域结构，实现轻量级计算。

研究结果: 在4个标准检索数据集上的实验表明，该方法在Recall@10指标上比基线方法提升了9.4±1.2%，且计算开销极小（低于检索时间的5%）。

研究结论: 该框架不仅显著提升了检索性能，还揭示了不同查询类型中嵌入质量的系统性模式，为针对性训练数据增强提供了新思路。

中文摘要: 向量检索系统因嵌入质量的异质性而在不同查询中表现出显著的性能差异。我们提出了一种轻量级框架，通过结合量化鲁棒性和邻域密度指标，预测查询级别的检索性能。我们的方法基于高质量嵌入在嵌入空间中占据几何稳定区域并表现出一致邻域结构的观察。在4个标准检索数据集上的评估显示，该方法在Recall@10指标上比竞争基线方法提升了9.4±1.2%。该框架计算开销极小（低于检索时间的5%），并支持自适应检索策略。我们的分析揭示了不同查询类型中嵌入质量的系统性模式，为针对性训练数据增强提供了见解。

</details>


### [224] [Nyay-Darpan: Enhancing Decision Making Through Summarization and Case Retrieval for Consumer Law in India](https://arxiv.org/abs/2507.06090)
**中文标题：Nyay-Darpan：通过摘要与案例检索增强印度消费者法律的决策能力**

*Swapnil Bhattacharyya,Shrey Ganatra,Harshvivek Kashid,Spandan Anaokar,Shruti Nair,Reshma Sekhar,Siddharth Manohar,Rahul Hemrajani,Pushpak Bhattacharyya*

主要分类: cs.IR

摘要简述: 本文介绍了Nyay-Darpan，一种针对印度消费者法律的新型AI框架，通过案例摘要和相似案例检索辅助决策，填补了消费者法律AI工具的空白。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI司法辅助工具多集中于刑事和民事领域，而消费者法律领域尤其是印度仍缺乏相关研究。本文旨在填补这一空白，提供一种高效工具以辅助消费者纠纷解决。

研究方法: Nyay-Darpan框架结合了消费者案例文件的摘要生成和相似案例判决检索功能，并创新性地引入摘要质量评估方法。

研究结果: 系统在相似案例预测中准确率超过75%，在摘要评估指标中达到约70%的准确率，证明了其实际有效性。

研究结论: Nyay-Darpan为消费者法律领域提供了实用的AI工具，未来将公开框架和数据集以促进进一步研究。

中文摘要: 基于AI的司法辅助和案例预测在刑事和民事领域已有广泛研究，但在消费者法律领域，尤其是印度，仍鲜有探索。本文提出Nyay-Darpan，一种新型二合一框架，既能总结消费者案例文件，又能检索相似案例判决以辅助消费者纠纷解决。我们的方法不仅填补了消费者法律AI工具的空白，还创新性地引入了摘要质量评估方法。'Nyay-Darpan'意为'正义之镜'，象征工具通过精准摘要和智能案例检索反映消费者争议的核心。系统在相似案例预测中准确率超过75%，在摘要评估指标中达到约70%的准确率，展现了其实际效果。我们将公开Nyay-Darpan框架和数据集，以促进可重复性并推动这一重要但未充分研究领域的进一步探索。

</details>


### [225] [When Transformers Meet Recommenders: Integrating Self-Attentive Sequential Recommendation with Fine-Tuned LLMs](https://arxiv.org/abs/2507.05733)
**中文标题：当Transformer遇上推荐系统：自注意力序列推荐与微调大语言模型的融合**

*Kechen Liu*

主要分类: cs.IR

摘要简述: 本文提出SASRecLLM框架，将自注意力序列推荐（SASRec）与微调的大语言模型（LLM）结合，通过映射层和三种训练策略优化，显著提升了冷启动和热启动场景下的推荐性能。


<details>
  <summary>详细信息</summary>
研究动机: 自注意力序列推荐（SASRec）能有效捕捉用户长期偏好，而大语言模型（LLM）具有强大的泛化和语言理解能力，但缺乏领域知识和协作信号。本文旨在结合两者优势，提升推荐质量。

研究方法: 提出SASRecLLM框架，将SASRec作为协作编码器与微调的LLM结合，通过映射层对齐维度空间，并设计三种训练策略优化混合架构。

研究结果: 在多个数据集上的实验表明，SASRecLLM在冷启动和热启动场景中均优于基线模型，实现了稳健且一致的性能提升。

研究结论: SASRecLLM为LLM-based推荐领域提供了一种模块化且有效的范式，成功融合了结构化协作过滤与微调LLM的语义能力。

中文摘要: 自注意力序列推荐（SASRec）通过将注意力机制应用于历史交互，有效捕捉用户的长期偏好。与此同时，大语言模型（LLM）的兴起推动了基于LLM的推荐研究，这些模型凭借其强大的泛化和语言理解能力展现出潜力。然而，仅依赖文本提示时，LLM往往缺乏高质量推荐所需的领域知识和协作信号。为解决这一问题，本研究提出SASRecLLM，一种新颖的框架，将SASRec作为协作编码器与通过低秩适应（LoRA）微调的LLM结合。两者通过映射层连接以对齐其维度空间，并设计了三种针对性训练策略以优化混合架构。在多个数据集上的广泛实验表明，SASRecLLM在冷启动和热启动场景中均实现了对强基线的稳健且一致的改进。这项工作通过提出一种模块化且有效的范式，将结构化协作过滤与微调LLM的语义能力融合，推动了基于LLM的推荐领域的发展。实现代码已在GitHub上开源：https://github.com/kechenkristin/RecLLM

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [226] [SQLBarber: A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads](https://arxiv.org/abs/2507.06192)
**中文标题：SQLBarber：基于大语言模型的定制化和真实SQL工作负载生成系统**

*Jiale Lao,Immanuel Trummer*

主要分类: cs.DB

摘要简述: SQLBarber是一个基于大语言模型的系统，用于生成定制化和真实的SQL工作负载，解决了数据库研究中获取真实SQL查询的难题，并通过自然语言约束和高效扩展性显著提升了查询生成的效率和对目标成本分布的匹配度。


<details>
  <summary>详细信息</summary>
研究动机: 数据库研究和开发需要大量SQL查询进行基准测试，但获取真实查询因隐私问题困难，现有方法在定制化和满足真实约束方面有限。SQLBarber旨在解决这一问题。

研究方法: SQLBarber利用大语言模型（LLMs）生成SQL工作负载，提供声明式接口生成定制化SQL模板，并通过自校正模块和贝叶斯优化器优化查询成本分布。

研究结果: SQLBarber显著减少了查询生成时间（1-3个数量级），并显著提高了与目标成本分布的对齐度，是唯一能生成定制化SQL模板的系统。

研究结论: SQLBarber通过结合LLMs和优化技术，成功解决了SQL查询生成的定制化和真实性问题，为数据库研究提供了高效工具。

中文摘要: 数据库研究和开发通常需要大量SQL查询进行基准测试。然而，由于隐私问题，获取真实SQL查询具有挑战性，且现有SQL生成方法在定制化和满足真实约束方面存在局限。为解决这一问题，我们提出了SQLBarber，一个基于大语言模型（LLMs）的系统，用于生成定制化和真实的SQL工作负载。SQLBarber（i）无需用户预先手动编写SQL模板，同时支持通过自然语言约束灵活生成SQL模板；（ii）高效扩展以生成符合用户定义成本分布（如基数和执行计划成本）的大量查询；（iii）利用Amazon Redshift和Snowflake的执行统计数据，生成反映真实查询特征的SQL模板规范和查询成本分布。SQLBarber引入了（i）声明式接口，用户可轻松生成定制化SQL模板；（ii）基于LLM的流程，结合自校正模块，根据查询成本分析、优化和修剪SQL模板；（iii）贝叶斯优化器，高效探索不同谓词值并识别满足目标成本分布的查询集。我们基于Snowflake和Amazon Redshift的真实统计数据，构建并开源了十个不同难度级别和目标查询成本分布的基准测试。在这些基准测试上的大量实验表明，SQLBarber是唯一能生成定制化SQL模板的系统，与现有方法相比，查询生成时间减少1-3个数量级，并显著提高了与目标成本分布的对齐度。

</details>


### [227] [Prompt Migration: Stabilizing GenAI Applications with Evolving Large Language Models](https://arxiv.org/abs/2507.05573)
**中文标题：提示迁移：通过演化的大语言模型稳定生成式AI应用**

*Shivani Tripathi,Pushpanjali Nema,Aditya Halder,Shi Qiao,Alekh Jindal*

主要分类: cs.DB

摘要简述: 本文提出“提示迁移”方法，通过系统化框架解决生成式AI应用中因大语言模型快速迭代导致的提示不一致问题，并以企业搜索应用Tursio为例验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 生成式AI在商业应用中广泛使用，但底层大语言模型（LLMs）快速迭代导致提示效果不稳定，影响关键业务流程的可靠性。本文旨在解决这一问题。

研究方法: 提出“提示迁移”框架，包括提示重新设计和迁移测试平台，以应对LLMs的升级变化，并以Tursio企业搜索应用为案例进行分析。

研究结果: 实验表明，结构化提示迁移能完全恢复因模型漂移而丧失的应用可靠性。

研究结论: 强调提示生命周期管理和鲁棒测试的重要性，以确保生成式AI商业应用的稳定性。

中文摘要: 生成式AI通过自然语言界面和智能自动化正在改变商业应用。然而，底层的大语言模型（LLMs）快速演化，导致提示效果难以保持一致，从而引发应用行为的不一致和不可预测性，影响关键业务流程的可靠性。本文提出“提示迁移”概念，作为一种系统化方法，用于在LLMs变化时稳定生成式AI应用。以Tursio企业搜索应用为例，我们分析了GPT模型连续升级的影响，详细介绍了包括提示重新设计和迁移测试平台在内的迁移框架，并展示了这些技术如何恢复应用的一致性。结果表明，结构化提示迁移可以完全恢复因模型漂移而丧失的应用可靠性。最后，我们总结了实践经验，强调了提示生命周期管理和鲁棒测试的必要性，以确保依赖生成式AI的商业应用的可靠性。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [228] [Inaugural MOASEI Competition at AAMAS'2025: A Technical Report](https://arxiv.org/abs/2507.05469)
**中文标题：2025年AAMAS会议首届MOASEI竞赛技术报告**

*Ceferino Patino,Tyler J. Billings,Alireza Saleh Abadi,Daniel Redder,Adam Eck,Prashant Doshi,Leen-Kiat Soh*

主要分类: cs.MA

摘要简述: 本文介绍了2025年AAMAS会议上举办的MOASEI竞赛，旨在评估开放世界中多智能体AI的决策能力。竞赛包含三个赛道，展示了开放性和协调复杂性，吸引了11支国际团队参与，并展示了多种解决方案。


<details>
  <summary>详细信息</summary>
研究动机: MOASEI竞赛旨在通过开放世界条件下的多智能体AI评估，推动决策能力的研究，特别是在动态、部分可观测环境中智能体和任务的开放性变化。

研究方法: 竞赛基于free-range-zoo环境套件，设计了动态、部分可观测的领域，包含三个赛道：Wildfire、Rideshare和Cybersecurity。参赛团队提交了包括图神经网络、卷积架构、预测建模和大语言模型驱动的元优化等解决方案。

研究结果: 竞赛结果显示，参赛团队在开放环境中展现了泛化和适应能力的潜力，提供了关于预期效用、扰动鲁棒性和环境变化响应性的实证数据。

研究结论: MOASEI竞赛为开放智能体系统研究提供了宝贵的经验和基础设施，展示了未来研究的潜力方向。

中文摘要: 我们介绍了开放智能体系统评估方法倡议（MOASEI）竞赛，这是一个旨在评估开放世界条件下决策能力的多智能体AI基准测试活动。基于free-range-zoo环境套件，MOASEI引入了动态、部分可观测的领域，其中智能体和任务具有开放性——实体可能随时间出现、消失或改变行为。2025年的竞赛包含三个赛道——Wildfire、Rideshare和Cybersecurity，每个赛道突出了开放性和协调复杂性的不同维度。来自国际机构的11支团队参与了竞赛，其中四支团队提交了多样化的解决方案，包括图神经网络、卷积架构、预测建模和大语言模型驱动的元优化。评估指标集中在预期效用、对扰动的鲁棒性以及对环境变化的响应性上。结果显示，开放环境中的泛化和适应策略具有潜力，为未来研究提供了实证见解和基础设施。本报告详细介绍了竞赛的设计、发现以及对开放智能体系统研究社区的贡献。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [229] [PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle CT](https://arxiv.org/abs/2507.05317)
**中文标题：PWD：基于先验引导和小波增强的扩散模型用于有限角度CT重建**

*Yi Liu,Yiyang Wen,Zekun Zhou,Junqi Ma,Linghang Wang,Yucheng Yao,Liu Shi,Qiegen Liu*

主要分类: eess.IV

摘要简述: 论文提出了一种基于先验引导和小波增强的扩散模型（PWD），用于有限角度CT重建，通过嵌入先验信息和小波特征融合，显著减少了采样步骤并提升了重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 标准扩散模型在有限角度CT重建中需要大量采样步骤，计算开销大，而跳过采样策略会导致细节丢失。因此，需要一种高效且能保留细节的重建方法。

研究方法: PWD在训练阶段将有限角度CT图像的分布映射到目标图像的分布，学习结构对应关系；在推理阶段，利用有限角度CT图像作为先验引导采样轨迹，并通过小波域的多尺度特征融合增强细节重建。

研究结果: 在临床牙弓CBCT和根尖周数据集上，PWD在相同采样条件下优于现有方法，仅用50步采样即可实现PSNR提升1.7 dB和SSIM提升10%。

研究结论: PWD通过先验引导和小波特征融合，显著提升了有限角度CT重建的效率和质量，为医学影像重建提供了新思路。

中文摘要: 生成扩散模型在医学影像中受到广泛关注，尤其是在有限角度计算机断层扫描（LACT）中。标准扩散模型虽然能实现高质量图像重建，但推理时需要大量采样步骤，计算开销大。尽管已有跳过采样策略以提高效率，但常导致细节丢失。为此，我们提出了一种嵌入先验信息和小波特征融合的快速采样扩散模型（PWD），用于LACT重建。PWD在高效采样的同时保持了重建保真度，并有效缓解了跳过采样带来的退化问题。具体而言，在训练阶段，PWD将LACT图像的分布映射到目标图像的分布，使模型学习两者间的结构对应关系；在推理阶段，LACT图像作为显式先验引导采样轨迹，仅需少量步骤即可实现高质量重建。此外，PWD在小波域进行多尺度特征融合，通过低频和高频信息有效增强细节重建。在临床牙弓CBCT和根尖周数据集上的定量和定性评估表明，PWD在相同采样条件下优于现有方法，仅用50步采样即可实现PSNR至少提升1.7 dB和SSIM提升10%。

</details>


### [230] [Dual-Attention U-Net++ with Class-Specific Ensembles and Bayesian Hyperparameter Optimization for Precise Wound and Scale Marker Segmentation](https://arxiv.org/abs/2507.05314)
**中文标题：双注意力U-Net++结合类别特定集成与贝叶斯超参数优化实现精确伤口和比例标记分割**

*Daniel Cieślak,Miriam Reca,Olena Onyshchenko,Jacek Rumiński*

主要分类: eess.IV

摘要简述: 本文提出了一种结合双注意力机制的U-Net++架构，通过类别特定集成和贝叶斯超参数优化，实现了对临床图像中伤口和比例标记的高精度分割。


<details>
  <summary>详细信息</summary>
研究动机: 临床图像中伤口和比例标记的精确分割对伤口管理和自动化评估至关重要，但现有方法在处理类别不平衡和图像变异性方面存在挑战。

研究方法: 研究提出了一种双注意力U-Net++架构，整合了通道和空间注意力机制，并通过贝叶斯超参数优化和类别特定模型集成提升性能。

研究结果: 在NBC 2025和PCBBE 2025竞赛的基准数据集上，该方法取得了0.8640的加权F1分数，证明了其有效性。

研究结论: 该方法在复杂医学图像分割任务中表现出色，为临床图像分析提供了可靠工具。

中文摘要: 临床图像中伤口和比例标记的精确分割是伤口管理和自动化评估的关键挑战。本研究提出了一种新颖的双注意力U-Net++架构，通过整合通道（SCSE）和空间注意力机制，有效解决了医学图像中的类别不平衡和变异性问题。通过5折交叉验证对多种架构和编码器进行广泛基准测试，确定EfficientNet-B7为最优编码器骨干。随后，独立训练了两个类别特定模型，采用定制预处理、大量数据增强和贝叶斯超参数调优（WandB扫描）。最终模型集成利用测试时间增强进一步提升预测可靠性。该方法在NBC 2025和PCBBE 2025竞赛的基准数据集上进行了评估，加权F1分数（75%伤口，25%比例标记）由竞赛组织者在未公开硬件上计算，结果为0.8640，证明了其在复杂医学分割任务中的有效性。

</details>


### [231] [Self-supervised Deep Learning for Denoising in Ultrasound Microvascular Imaging](https://arxiv.org/abs/2507.05451)
**中文标题：自监督深度学习在超声微血管成像去噪中的应用**

*Lijie Huang,Jingyi Yin,Jingke Zhang,U-Wai Lok,Ryan M. DeRuiter,Jieyang Jin,Kate M. Knoll,Kendra E. Petersen,James D. Krier,Xiang-yang Zhu,Gina K. Hesley,Kathryn A. Robinson,Andrew J. Bentall,Thomas D. Atwell,Andrew D. Rule,Lilach O. Lerman,Shigao Chen,Chengwu Huang*

主要分类: eess.IV

摘要简述: 本文提出了一种自监督去噪框架HA2HA，用于提升超声微血管成像（UMI）的信噪比和对比噪声比，显著改善图像质量，适用于无对比剂和增强成像场景。


<details>
  <summary>详细信息</summary>
研究动机: 超声微血管成像（UMI）常因低信噪比（SNR）而受限，尤其在无对比剂或深部组织场景中，影响血管量化和疾病诊断的可靠性。为解决这一问题，作者提出了一种自监督去噪方法。

研究方法: HA2HA框架通过从波束形成的射频血流数据中构建互补角度子集的训练对，其中血管信号保持一致而噪声变化。该方法使用无对比剂的猪肾脏数据进行训练，并在多种数据集上验证，包括无对比剂和增强数据。

研究结果: 实验结果显示，HA2HA在对比噪声比（CNR）和信噪比（SNR）上均提升了超过15 dB，显著改善了图像质量。此外，在射频域直接去噪还提升了彩色多普勒成像（CDI）的微血管血流可视化效果。

研究结论: HA2HA提供了一种无需标记、通用性强且适用于临床的解决方案，能够显著提升无对比剂和增强UMI的血管成像质量。

中文摘要: 超声微血管成像（UMI）常因低信噪比（SNR）而受限，尤其是在无对比剂或深部组织场景中，这会影响后续的血管量化和可靠的疾病诊断。为解决这一问题，我们提出了一种名为“半角到半角”（HA2HA）的自监督去噪框架，专为UMI设计。HA2HA从波束形成的射频血流数据的互补角度子集中构建训练对，其中血管信号保持一致而噪声变化。HA2HA使用无对比剂的猪肾脏数据进行训练，并在多种数据集上验证，包括无对比剂和增强的猪肾脏数据，以及人类肝脏和肾脏数据。实验结果显示，对比噪声比（CNR）和信噪比（SNR）均提升了超过15 dB，表明图像质量得到了显著改善。除了功率多普勒成像外，在射频域直接去噪还对其他下游处理（如彩色多普勒成像（CDI））有益。基于HA2HA去噪信号的人类肝脏CDI结果显示，微血管血流可视化效果改善，噪声背景得到抑制。HA2HA为无对比剂和增强UMI提供了一种无需标记、通用性强且适用于临床的解决方案，能够实现稳健的血管成像。

</details>


### [232] [Learning Segmentation from Radiology Reports](https://arxiv.org/abs/2507.05582)
**中文标题：从放射学报告中学习分割**

*Pedro R. A. S. Bassi,Wenxuan Li,Jieneng Chen,Zheren Zhu,Tianyu Lin,Sergio Decherchi,Andrea Cavalli,Kang Wang,Yang Yang,Alan L. Yuille,Zongwei Zhou*

主要分类: eess.IV

摘要简述: 本文提出了一种利用放射学报告辅助肿瘤分割的方法（R-Super），通过将报告转化为体素级监督信号，显著提升了AI在CT扫描中的肿瘤分割性能，尤其在标注数据稀缺时效果显著。


<details>
  <summary>详细信息</summary>
研究动机: 肿瘤分割在CT扫描中对诊断、手术和预后至关重要，但分割标注数据稀缺且制作耗时。尽管公共腹部CT数据集仅有少量肿瘤标注，医院却有大量带有放射学报告的CT扫描。因此，利用这些报告提升分割模型的性能成为关键。

研究方法: 作者提出了一种报告监督损失（R-Super），将放射学报告转化为体素级监督信号，用于训练肿瘤分割AI。研究整合了来自UCSF医院的6,718对CT-报告数据及公共CT-标注数据集（AbdomenAtlas 2.0），并利用R-Super结合标注和报告进行训练。

研究结果: 实验表明，R-Super显著提升了肿瘤分割性能，在内部和外部验证中F1分数最高提升了16%。无论是标注数据极少（如50个）还是较多（如1.7K个），R-Super均能显著提升AI表现。

研究结论: 通过利用易获取的放射学报告补充稀缺的分割标注数据，R-Super显著提升了肿瘤分割AI的性能，为医学图像分析提供了高效且可扩展的解决方案。

中文摘要: CT扫描中的肿瘤分割对诊断、手术和预后至关重要，但分割标注稀缺，因其制作需要时间和专业知识。公共腹部CT数据集仅有几十到几千个肿瘤标注，而医院拥有数十万份带有放射学报告的肿瘤CT。因此，利用报告提升分割性能是实现规模化的关键。本文提出了一种报告监督损失（R-Super），将放射学报告转化为体素级监督信号，用于肿瘤分割AI的训练。研究整合了来自UCSF医院的6,718对CT-报告数据及公共CT-标注数据集（AbdomenAtlas 2.0），并利用R-Super结合标注和报告进行训练。实验表明，R-Super显著提升了肿瘤分割性能，在内部和外部验证中F1分数最高提升了16%。无论是标注数据极少（如50个）还是较多（如1.7K个），R-Super均能显著提升AI表现。通过利用易获取的放射学报告补充稀缺的分割标注数据，R-Super显著提升了AI性能。项目地址：https://github.com/MrGiovanni/R-Super

</details>


### [233] [Diffusion-Based Limited-Angle CT Reconstruction under Noisy Conditions](https://arxiv.org/abs/2507.05647)
**中文标题：基于扩散模型的噪声条件下有限角度CT重建**

*Jiaqi Guo,Santiago López-Tapia*

主要分类: eess.IV

摘要简述: 本文提出了一种基于扩散模型的有限角度CT重建方法，通过噪声感知校正机制（RNSD+）提升重建鲁棒性，显著优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 有限角度CT（LACT）因缺失角度投影导致重建图像严重伪影，现有方法多假设理想无噪声条件，无法应对实际噪声干扰。本文旨在解决噪声条件下的LACT重建问题。

研究方法: 将LACT视为正弦图修复任务，采用均值回归随机微分方程（MR-SDE）框架完成缺失角度视图，并提出噪声感知校正机制RNSD+，显式建模推理时不确定性以提升鲁棒性。

研究结果: 实验表明，该方法在数据一致性和感知质量上均优于基线模型，且能适应不同噪声强度和采集场景。

研究结论: 本文提出的扩散框架及RNSD+机制有效解决了噪声条件下的LACT重建问题，具有广泛适用性和鲁棒性。

中文摘要: 有限角度计算机断层扫描（LACT）是一个具有挑战性的逆问题，缺失的角度投影会导致不完整的正弦图和重建图像中的严重伪影。尽管近年来的基于学习的方法已显示出有效性，但大多数方法假设理想的无噪声测量，未能解决测量噪声的影响。为克服这一限制，我们将LACT视为正弦图修复任务，并提出一种基于扩散的框架，利用均值回归随机微分方程（MR-SDE）完成缺失角度视图。为提高实际噪声条件下的鲁棒性，我们提出RNSD+，这是一种新型噪声感知校正机制，显式建模推理时不确定性，从而实现可靠且鲁棒的重建。大量实验表明，我们的方法在数据一致性和感知质量上始终优于基线模型，并能很好地适应不同噪声强度和采集场景。

</details>


### [234] [ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease](https://arxiv.org/abs/2507.05656)
**中文标题：ADPv2：一种用于结肠疾病潜在生物标志物发现的分层组织类型标注数据集**

*Zhiyuan Yang,Kai Li,Sophia Ghamoshi Ramandi,Patricia Brassard,Hakim Khellaf,Vincent Quoc-Huy Trinh,Jennifer Zhang,Lina Chen,Corwyn Rowsell,Sonal Varma,Kostas Plataniotis,Mahdi S. Hosseini*

主要分类: eess.IV

摘要简述: ADPv2是一个针对胃肠道组织病理学的数据集，包含20,004个健康结肠活检图像块，标注了32种分层组织类型。通过训练多标签表示学习模型，该数据集支持结肠疾病潜在生物标志物的深入研究。


<details>
  <summary>详细信息</summary>
研究动机: 当前公开的计算病理学数据集缺乏细粒度的组织类型标注，限制了特定器官疾病的深入研究。ADPv2旨在填补这一空白，专注于胃肠道组织病理学，为潜在生物标志物发现提供支持。

研究方法: ADPv2数据集包含20,004个图像块，标注了3个层次的32种组织类型。采用VMamba架构训练多标签表示学习模型，通过两阶段训练实现结肠组织类型的分类。

研究结果: 模型在多标签分类任务中达到0.88的平均精度（mAP）。通过分析模型对不同结肠疾病组织的预测行为，揭示了结肠癌发展的两种病理途径的统计模式。

研究结论: ADPv2数据集为胃肠道组织病理学研究提供了丰富资源，支持潜在生物标志物的发现。模型的成功应用验证了数据集的实用性和研究价值。

中文摘要: 计算病理学（CoPath）利用组织病理学图像提高临床病理诊断的精确性和可重复性。然而，由于标注需要高度专业知识和成本，公开的细粒度组织类型（HTT）标注数据集稀缺。现有数据集（如数字病理学图谱ADP）提供了多器官的通用HTT标注，但限制了特定器官疾病的深入研究。基于此，我们推出ADPv2，专注于胃肠道组织病理学的新数据集。该数据集包含20,004个健康结肠活检图像块，标注了3个层次的32种HTT。我们采用VMamba架构训练多标签表示学习模型，在结肠HTT多标签分类中达到0.88的平均精度（mAP）。通过分析模型对不同结肠疾病组织的预测行为，揭示了结肠癌发展的两种病理途径的统计模式。数据集已公开：第一部分见https://zenodo.org/records/15307021，第二部分见https://zenodo.org/records/15312384，第三部分见https://zenodo.org/records/15312792。

</details>


### [235] [Tissue Concepts v2: a Supervised Foundation Model for whole slide images](https://arxiv.org/abs/2507.05742)
**中文标题：组织概念v2：一种用于全切片图像的有监督基础模型**

*Till Nicke,Daniela Scharcherer,Jan Raphael Schäfer,Natalia Artysh,Antje Prasse,André Homeyer,Andrea Schenk,Henning Höfener,Johannes Lotz*

主要分类: eess.IV

摘要简述: 本文介绍了Tissue Concepts v2（TCv2），一种用于全切片图像的有监督基础模型，通过多任务学习减少训练资源需求，并在癌症亚型分类中表现优于自监督模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前基础模型的训练资源消耗大，本文旨在通过有监督的多任务学习方法，开发一种更高效的模型TCv2，用于全切片图像分析。

研究方法: TCv2采用有监督的端到端多任务学习，利用切片级标签进行训练，显著减少资源消耗。

研究结果: TCv2在癌症亚型分类任务中表现优于自监督模型，且训练数据完全公开。

研究结论: TCv2为全切片图像分析提供了一种高效且有解释性的解决方案。

中文摘要: 基础模型（FMs）正在通过提供新的组织病理学图像分析方法改变计算病理学领域。通常需要数周时间在大型数据库上进行训练，基础模型的创建是一个资源密集型过程。本文介绍了我们有监督基础模型Tissue Concepts的扩展版本，即Tissue Concepts v2（TCv2），用于全切片图像，以解决上述问题。TCv2采用有监督的端到端多任务学习，利用切片级标签进行训练。与自监督训练相比，TCv2的训练资源消耗显著减少。该模型在癌症亚型分类任务中表现优于自监督训练模型，且完全使用公开数据进行训练。此外，共享训练的注意力模块为不同任务提供了额外的解释性。

</details>


### [236] [A novel framework for fully-automated co-registration of intravascular ultrasound and optical coherence tomography imaging data](https://arxiv.org/abs/2507.05883)
**中文标题：一种用于血管内超声和光学相干断层扫描图像数据全自动配准的新框架**

*Xingwei He,Kit Mills Bransby,Ahmet Emir Ulutas,Thamil Kumaran,Nathan Angelo Lecaros Yap,Gonul Zeren,Hesong Zeng,Yaojun Zhang,Andreas Baumbach,James Moon,Anthony Mathur,Jouke Dijkstra,Qianni Zhang,Lorenz Raber,Christos V Bourantas*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的全自动框架，用于血管内超声（IVUS）和光学相干断层扫描（OCT）图像的纵向和圆周配准，结果显示其性能与专家分析相当，且处理速度快。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发一种全自动的深度学习框架，以解决IVUS和OCT图像在纵向和圆周方向上的配准问题，从而提高大规模多模态成像数据分析的效率。

研究方法: 研究纳入230名急性冠脉综合征患者的714条血管数据，利用专家标注的61,655帧NIRS-IVUS和62,334帧OCT图像训练深度学习模型，提取血管特征。通过动态时间规整算法和动态编程实现图像的纵向和圆周配准。

研究结果: 在22名患者的77条血管测试中，深度学习方法的配准结果与专家分析高度一致（纵向配准的相关系数>0.99，圆周配准>0.90），处理时间少于90秒。

研究结论: 该全自动深度学习框架能够快速且准确地实现IVUS和OCT图像的配准，适用于大规模多模态成像数据的分析研究。

中文摘要: 目的：开发一种深度学习（DL）框架，实现血管内超声（IVUS）和光学相干断层扫描（OCT）图像的纵向和圆周全自动配准。方法与结果：本研究纳入了230名急性冠脉综合征患者的714条非罪犯血管的近红外光谱（NIRS）-IVUS和OCT成像数据。利用专家标注的61,655帧NIRS-IVUS和62,334帧OCT图像中的血管边界，以及10,000帧NIRS-IVUS和10,000帧OCT图像中的侧支和钙化组织，训练深度学习模型以自动提取这些特征。训练后的模型通过动态时间规整算法和动态编程分别实现图像的纵向和圆周配准。在22名患者的77条血管测试中，深度学习方法的配准结果与专家分析高度一致（纵向配准的相关系数>0.99，圆周配准>0.90）。Williams指数显示其性能与专家分析相当（纵向为0.96，圆周为0.97），且单条血管的处理时间少于90秒。结论：本研究提出的全自动深度学习框架能够快速且准确地实现IVUS和OCT图像的配准，适用于大规模多模态成像数据的分析研究。

</details>


### [237] [Enhancing Synthetic CT from CBCT via Multimodal Fusion and End-To-End Registration](https://arxiv.org/abs/2507.06067)
**中文标题：通过多模态融合和端到端配准增强从CBCT生成的合成CT**

*Maximilian Tschuchnig,Lukas Lamminger,Philipp Steininger,Michael Gadermayr*

主要分类: eess.IV

摘要简述: 本文通过多模态融合和端到端配准技术，提升了从CBCT生成合成CT（sCT）的质量，显著改善了低质量CBCT和术前CT未对齐情况下的sCT效果。


<details>
  <summary>详细信息</summary>
研究动机: CBCT因其快速采集和低辐射剂量广泛用于术中成像，但其图像质量较低且存在伪影。合成CT（sCT）是一种解决方案，但多模态数据间的未对齐问题限制了其效果。本文旨在通过多模态学习和端到端配准模块提升sCT生成质量。

研究方法: 提出一种端到端可学习的配准模块，结合术中CBCT和术前CT数据，通过多模态学习生成高质量的sCT。在合成数据集上验证模型，并进一步在真实临床数据上测试其鲁棒性和泛化性。

研究结果: 实验结果表明，整合配准模块的多模态sCT生成方法在90个评估场景中的79个优于基线方法，尤其在CBCT质量低且术前CT未对齐的情况下效果显著。

研究结论: 通过多模态融合和端到端配准，本文显著提升了sCT生成质量，为临床应用中低质量CBCT的改进提供了有效解决方案。

中文摘要: 锥形束计算机断层扫描（CBCT）因其快速采集和低辐射剂量广泛用于术中成像，但其图像通常存在伪影且视觉质量低于传统CT。合成CT（sCT）是一种将CBCT转换为CT域的解决方案。本文通过多模态学习结合术中CBCT和术前CT数据，提升sCT生成质量。为解决模态间固有的未对齐问题，我们在sCT流程中引入了端到端可学习的配准模块。该模型在可控合成数据集上评估，允许精确操纵数据质量和配准参数，并在两个真实临床数据集上验证其鲁棒性和泛化性。实验结果表明，整合配准的多模态sCT生成方法在90个评估场景中的79个优于基线方法，尤其在CBCT质量低且术前CT未对齐的情况下效果显著。

</details>


### [238] [LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models](https://arxiv.org/abs/2507.06140)
**中文标题：LangMamba：一种基于语言驱动的Mamba框架，用于结合视觉语言模型的低剂量CT去噪**

*Zhihao Chen,Tao Chen,Chenhui Wang,Qi Gao,Huidong Xie,Chuang Niu,Ge Wang,Hongming Shan*

主要分类: eess.IV

摘要简述: LangMamba是一种基于语言驱动的Mamba框架，利用视觉语言模型（VLM）提升低剂量CT（LDCT）去噪效果。通过两阶段学习策略，结合语义增强去噪器和语言对齐损失，显著提升图像细节和视觉保真度。


<details>
  <summary>详细信息</summary>
研究动机: 低剂量CT（LDCT）虽减少辐射，但图像质量下降可能影响诊断准确性。现有深度学习方法多关注像素级映射，忽略了高级语义指导的潜力。视觉语言模型（VLM）的进展表明，语言可作为捕捉结构化语义信息的工具，为LDCT重建提供新思路。

研究方法: 1. 预训练语言引导自编码器（LangAE），利用冻结的VLM将正常剂量CT（NDCT）图像映射到富含解剖信息的语义空间。2. 结合LangAE与两个关键组件：语义增强高效去噪器（SEED）和语言参与的双空间对齐（LangDA）损失，分别增强局部语义和全局特征，并确保去噪图像在感知和语义空间与NDCT对齐。

研究结果: 在两个公开数据集上的实验表明，LangMamba优于现有方法，显著提升细节保留和视觉保真度。LangAE对未见数据集表现出强泛化性，降低训练成本。LangDA损失通过语言指导提升重建可解释性，并支持即插即用。

研究结论: LangMamba展示了语言作为监督信号在LDCT去噪中的潜力，为图像重建提供了新方向。代码已开源。

中文摘要: 低剂量计算机断层扫描（LDCT）虽减少辐射暴露，但常导致图像质量下降，可能影响诊断准确性。现有的基于深度学习的去噪方法主要关注像素级映射，忽视了高级语义指导的潜在优势。视觉语言模型（VLM）的最新进展表明，语言可作为捕捉结构化语义信息的强大工具，为改进LDCT重建提供了新机会。本文提出LangMamba，一种基于语言驱动的Mamba框架，利用VLM衍生的表征增强正常剂量CT（NDCT）的监督。LangMamba采用两阶段学习策略：首先预训练语言引导自编码器（LangAE），利用冻结的VLM将NDCT图像映射到富含解剖信息的语义空间；其次，结合LangAE与两个关键组件指导LDCT去噪：语义增强高效去噪器（SEED）通过高效的Mamba机制增强NDCT相关局部语义并捕捉全局特征，语言参与的双空间对齐（LangDA）损失确保去噪图像在感知和语义空间与NDCT对齐。在两个公开数据集上的广泛实验表明，LangMamba优于传统先进方法，显著提升细节保留和视觉保真度。值得注意的是，LangAE对未见数据集表现出强泛化性，从而降低训练成本。此外，LangDA损失通过将语言指导的洞察整合到图像重建中提升可解释性，并支持即插即用。我们的发现为语言作为监督信号推动LDCT去噪提供了新视角。代码已在https://github.com/hao1635/LangMamba公开。

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [239] [Complexity Results of Persuasion](https://arxiv.org/abs/2507.05951)
**中文标题：说服问题的复杂性结果**

*Alban Grastien*

主要分类: cs.CC

摘要简述: 本文证明了说服问题是一个NP完全问题。


<details>
  <summary>详细信息</summary>
研究动机: 研究说服问题的计算复杂性，以确定其在计算理论中的分类。

研究方法: 通过理论证明，展示说服问题属于NP完全类。

研究结果: 说服问题被证明是NP完全的。

研究结论: 说服问题的NP完全性为其在计算复杂性理论中的定位提供了明确依据。

中文摘要: 我们证明了说服问题是一个NP完全问题。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [240] [TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data](https://arxiv.org/abs/2507.05660)
**中文标题：TuneShield：在不可信数据上微调时减轻对话AI中的毒性**

*Aravind Cheruvu,Shravya Kanchi,Sifat Muhammad Abdullah,Nicholas Kong,Daphne Yao,Murtuza Jadliwala,Bimal Viswanath*

主要分类: cs.CR

摘要简述: TuneShield是一种防御框架，旨在在不可信数据上微调聊天机器人时减轻毒性，同时保持对话质量。它通过LLM毒性分类和生成‘治愈数据’来有效应对毒性注入攻击。


<details>
  <summary>详细信息</summary>
研究动机: 随着基础模型（如LLMs）的发展，聊天机器人的定制化需求增加，但在不可信数据上微调时，毒性问题成为主要挑战。TuneShield旨在解决这一问题，确保对话AI的安全性和质量。

研究方法: TuneShield利用LLM的毒性分类能力识别有毒样本，并生成‘治愈数据’以减轻毒性。通过对齐过程进一步优化聊天机器人的响应，抵御自适应攻击和越狱攻击。

研究结果: 实验表明，TuneShield能有效减轻毒性注入攻击，保持对话质量，即使毒性分类器不完美或有偏差。它还展示了在对话式学习中对自适应毒性攻击的防御能力。

研究结论: TuneShield为在不可信数据上微调聊天机器人提供了一种有效的毒性防御方案，兼具安全性和对话质量，且对多种攻击具有鲁棒性。

中文摘要: 基础模型（如LLMs）的最新进展彻底改变了对话AI。通过特定对话数据集定制LLMs开发的聊天机器人日益增多，但在处理不可信训练数据时，减轻毒性仍是一大挑战。为此，我们提出了TuneShield，一种防御框架，旨在在聊天机器人微调过程中减轻毒性，同时保持对话质量。TuneShield利用基于LLM的毒性分类，通过LLMs的指令遵循能力和安全对齐性有效识别有毒样本，性能优于行业API服务。TuneShield根据识别出的有毒样本生成合成对话样本（称为‘治愈数据’），用于在微调过程中减轻毒性并强化理想行为。它还通过对齐过程进一步引导聊天机器人生成理想响应。实验结果表明，即使毒性分类器不完美或有偏差，TuneShield也能有效减轻毒性注入攻击，同时保持对话质量。TuneShield对自适应对抗和越狱攻击表现出鲁棒性，并在对话式学习中有效减轻自适应毒性注入攻击。

</details>


### [241] [Disappearing Ink: Obfuscation Breaks N-gram Code Watermarks in Theory and Practice](https://arxiv.org/abs/2507.05512)
**中文标题：消失的墨水：混淆在理论与实践上破坏N-gram代码水印**

*Gehao Zhang,Eugene Bagdasarian,Juan Zhai,Shiqing Ma*

主要分类: cs.CR

摘要简述: 本文通过理论和实验证明，N-gram代码水印在面对代码混淆攻击时完全失效，检测能力降至随机水平（AUROC≈0.5），并提出了一种可能的鲁棒水印路径。


<details>
  <summary>详细信息</summary>
研究动机: 区分AI生成代码与人工编写代码对作者归属、内容追踪和滥用检测至关重要。N-gram水印方案虽被广泛使用，但其在代码混淆等复杂攻击下的鲁棒性尚未充分评估，亟需深入研究。

研究方法: 本文首先形式化建模代码混淆，并基于分布一致性假设，理论证明N-gram水印无法抵抗混淆攻击。实验部分测试了三种前沿水印方案、两种大语言模型、两种编程语言、四个代码基准和四种混淆工具，验证理论结论。

研究结果: 实验显示，所有水印检测器在混淆后的代码上表现接近随机猜测（AUROC≈0.5），且攻击后无检测器的AUROC超过0.6。代码混淆能完全破坏水印的可检测性。

研究结论: N-gram水印在代码混淆攻击下完全失效，需探索更鲁棒的方案。本文提出的理论框架为未来研究提供了方向。

中文摘要: 区分AI生成代码与人工编写代码对作者归属、内容追踪和滥用检测至关重要。N-gram水印方案通过注入秘密水印实现检测，但其鲁棒性在代码内容中未充分评估。现有研究仅针对简单代码变换或优化模拟攻击，而软件工程中广泛使用的代码混淆能显著改变代码结构但保留功能。本文形式化建模代码混淆，并基于分布一致性假设证明N-gram水印无法抵抗混淆攻击，攻击后检测失败率升至1 - fpr。实验覆盖三种前沿水印方案、两种大语言模型、两种编程语言、四个代码基准和四种混淆工具，结果显示所有水印检测器在混淆代码上表现随机（AUROC≈0.5），且攻击后无检测器AUROC超过0.6。基于此，本文提出了一种潜在的鲁棒水印路径。

</details>


### [242] [AI Agent Smart Contract Exploit Generation](https://arxiv.org/abs/2507.05558)
**中文标题：AI代理智能合约漏洞生成**

*Arthur Gervais,Liyi Zhou*

主要分类: cs.CR

摘要简述: 本文介绍了A1系统，一种基于代理执行的智能合约漏洞生成工具，无需人工启发式规则，通过六种领域专用工具实现自主漏洞发现。在36个真实漏洞合约测试中，成功率为62.96%，并发现9个额外漏洞。A1在攻击者与防御者的经济性分析中显示出不对称性，攻击者在低漏洞率下更具优势。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索如何利用AI代理技术自动生成智能合约漏洞利用方案，以解决传统漏洞发现方法依赖人工启发式规则的问题，并分析其在攻击与防御中的经济性差异。

研究方法: A1系统通过六种领域专用工具，使代理能够自主理解智能合约行为、生成漏洞利用策略、测试并优化方案。所有输出经过验证以消除误报。实验评估了36个真实漏洞合约，并分析了六种LLM的性能迭代。

研究结果: 在VERITE基准测试中，A1成功率为62.96%（17/27），并额外发现9个漏洞。总提取金额达933万美元。蒙特卡洛分析显示，攻击成功概率为85.9%-88.8%。经济性分析表明，攻击者在低漏洞率下更具优势。

研究结论: A1展示了AI代理在智能合约漏洞生成中的高效性，但揭示了攻击与防御之间的经济不对称性，攻击者在低漏洞率下更易获利，引发了对AI代理是否必然偏向攻击的思考。

中文摘要: 我们提出了A1，一种基于代理执行的系统，能够将任何大型语言模型（LLM）转化为端到端的漏洞利用生成器。A1无需人工启发式规则，并为代理提供了六种领域专用工具，以实现自主漏洞发现。代理可以灵活利用这些工具理解智能合约行为、生成漏洞利用策略、在区块链状态下测试并基于执行反馈优化方案。所有输出均经过验证以消除误报。
  在以太坊和币安智能链上的36个真实漏洞合约评估中，A1在VERITE基准测试中的成功率为62.96%（17/27）。此外，A1还发现了9个额外漏洞，其中5个案例发生在最强模型的训练截止日期之后。在所有26个成功案例中，A1单次提取金额高达859万美元，总计933万美元。通过对六种LLM的432次实验，我们分析了迭代性能，显示迭代2-5的平均边际增益分别为+9.7%、+3.7%、+5.1%和+2.8%，每次实验成本为0.01-3.59美元。蒙特卡洛分析显示，19次历史攻击的成功概率为85.9%-88.8%，且无检测延迟。
  我们研究了攻击者或防御者在部署A1作为持续链上扫描系统时的收益差异。模型显示，OpenAI的o3-pro在漏洞发生率为0.100%时，扫描延迟30.0天内仍能保持盈利，而更快的模型需要≥1.000%的漏洞发生率才能收支平衡。研究揭示了一种令人担忧的不对称性：在0.1%的漏洞发生率下，攻击者在6000美元的漏洞价值下即可盈利，而防御者需要60000美元，这引发了关于AI代理是否必然偏向攻击而非防御的根本问题。

</details>


### [243] [DATABench: Evaluating Dataset Auditing in Deep Learning from an Adversarial Perspective](https://arxiv.org/abs/2507.05622)
**中文标题：DATABench：从对抗视角评估深度学习中的数据集审计**

*Shuo Shao,Yiming Li,Mengren Zheng,Zhiyang Hu,Yukun Chen,Boheng Li,Yu He,Junfeng Guo,Tianwei Zhang,Dacheng Tao,Zhan Qin*

主要分类: cs.CR

摘要简述: 本文提出了DATABench，一个从对抗视角评估深度学习数据集审计方法的基准，揭示了现有审计方法在对抗攻击下的脆弱性，并呼吁开发更安全的审计技术。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习广泛应用依赖于训练数据集的质量和组成，但数据集的使用通常缺乏透明度，引发隐私和版权问题。现有数据集审计方法在对抗攻击下的鲁棒性尚未充分研究，本文旨在填补这一空白。

研究方法: 提出新分类法，将审计方法分为依赖内部特征（IF）和外部特征（EF）两类；设计两种攻击类型：逃避攻击和伪造攻击；提出系统性攻击策略，并构建DATABench基准，包含17种逃避攻击、5种伪造攻击和9种代表性审计方法。

研究结果: 实验表明，现有审计方法在对抗攻击下均不够鲁棒或具有区分性，DATABench揭示了这一严重问题。

研究结论: 研究强调了开发能够抵御对抗攻击的安全可靠数据集审计方法的紧迫性。

中文摘要: 深度学习的广泛应用高度依赖于训练数据集的质量和组成，然而其使用通常缺乏透明度，引发了隐私和版权问题。数据集审计技术旨在判断特定数据集是否用于训练可疑模型，为解决这些透明度问题提供了潜在方案。尽管已有研究开发了多种审计方法，但其在对抗攻击下的鲁棒性尚未充分探索。为填补这一空白，本文首次从对抗视角全面评估数据集审计。我们首先提出一种新分类法，将现有方法分为依赖内部特征（IF，数据固有）和外部特征（EF，人为引入）两类；随后定义两种主要攻击类型：逃避攻击（旨在隐藏数据集使用）和伪造攻击（旨在错误指控未使用数据集）。基于对现有方法和攻击目标的理解，我们进一步提出系统性攻击策略：逃避攻击的解耦、移除和检测；伪造攻击的对抗样本方法。这些定义和策略构成了我们的新基准DATABench，包含17种逃避攻击、5种伪造攻击和9种代表性审计方法。通过DATABench的广泛评估，我们发现所有审计方法在对抗环境下均不够鲁棒或具有区分性。这些发现凸显了开发能够抵御复杂对抗操作的安全可靠数据集审计方法的迫切需求。代码发布于https://github.com/shaoshuo-ss/DATABench。

</details>


### [244] [How Not to Detect Prompt Injections with an LLM](https://arxiv.org/abs/2507.05630)
**中文标题：如何不通过LLM检测提示注入**

*Sarthak Choudhary,Divyam Anshumaan,Nils Palumbo,Somesh Jha*

主要分类: cs.CR

摘要简述: 本文揭示了基于已知答案检测（KAD）的LLM防御框架的结构性漏洞，并提出了一种名为DataFlip的自适应攻击方法，能够高效绕过KAD防御，成功诱导恶意行为。


<details>
  <summary>详细信息</summary>
研究动机: LLM集成应用和代理容易受到提示注入攻击，现有基于KAD的防御方法声称性能接近完美。然而，本文发现KAD框架存在设计缺陷，其核心安全前提无效，因此需要深入研究其漏洞并设计攻击方法以验证其弱点。

研究方法: 本文首先形式化描述了KAD框架，揭示了其结构性漏洞。随后设计了一种名为DataFlip的自适应攻击方法，无需白盒访问LLM或优化过程，即可高效绕过KAD防御。

研究结果: 实验表明，DataFlip攻击能够将KAD防御的检测率降至1.5%，同时以高达88%的成功率诱导恶意行为，验证了KAD框架的根本性弱点。

研究结论: KAD防御框架存在结构性漏洞，无法有效抵御自适应攻击。本文的研究为未来设计更安全的LLM防御机制提供了重要启示。

中文摘要: LLM集成应用和代理容易受到提示注入攻击，攻击者通过在看似无害的用户输入中嵌入恶意指令来操纵LLM的预期行为。近期基于已知答案检测（KAD）的防御方法声称性能接近完美，通过使用LLM将输入分类为干净或受污染。本文形式化描述了KAD框架，并揭示了其设计中的结构性漏洞，该漏洞使其核心安全前提失效。我们设计了一种名为DataFlip的自适应攻击方法，利用这一根本弱点。它能够将KAD防御的检测率降至1.5%，同时以高达88%的成功率诱导恶意行为，且无需白盒访问LLM或任何优化过程。

</details>


### [245] [DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning](https://arxiv.org/abs/2507.05649)
**中文标题：DESIGN：通过服务器端输入图剪枝实现加密GNN推理**

*Kaixiang Zhao,Joseph Yousry Attalla,Qian Lou,Yushun Dong*

主要分类: cs.CR

摘要简述: 本文提出DESIGN框架，通过服务器端输入图剪枝实现高效的加密GNN推理，显著提升全同态加密（FHE）下的计算效率，同时保持模型精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前隐私保护的GNN在全同态加密（FHE）下计算开销巨大，难以实现实时推理。现有方法忽视输入数据冗余并采用统一计算策略，效率受限。

研究方法: DESIGN框架采用分层优化策略：1) 基于加密度统计计算节点重要性分数；2) 通过同态分区生成多级重要性掩码；3) 动态剪枝不重要元素并自适应调整多项式激活复杂度。

研究结果: 实验表明，DESIGN显著加速FHE GNN推理，同时保持模型精度，优于现有方法。

研究结论: DESIGN为安全图分析提供了高效且隐私保护的解决方案，解决了FHE GNN推理的效率瓶颈。

中文摘要: 图神经网络（GNNs）在各种基于图的学习任务中表现出色。然而，在全同态加密（FHE）等加密领域实现隐私保护的GNN通常带来巨大的计算开销，使得实时且隐私保护的推理变得不切实际。本文提出DESIGN（通过服务器端输入图剪枝实现加密GNN推理），一种高效加密GNN推理的新框架。DESIGN解决了现有FHE GNN方法的关键效率限制，这些方法通常忽视输入数据冗余并采用统一计算策略。我们的框架通过完全在服务器端执行的分层优化策略实现显著性能提升：首先，从加密图中计算FHE兼容的节点重要性分数（基于加密度统计）。这些分数随后指导同态分区过程，直接在FHE下生成多级重要性掩码。这种动态生成的掩码既支持输入图剪枝（通过逻辑移除不重要元素），也支持一种新颖的自适应多项式激活方案，其中激活复杂度根据节点重要性级别定制。实验评估表明，DESIGN相比现有方法显著加速FHE GNN推理，同时保持竞争性模型精度，为安全图分析提供了稳健的解决方案。

</details>


### [246] [Automated Reasoning for Vulnerability Management by Design](https://arxiv.org/abs/2507.05794)
**中文标题：基于设计的漏洞管理自动化推理**

*Avi Shaked,Nan Messe*

主要分类: cs.CR

摘要简述: 本文提出了一种基于形式化基础的自动化推理机制，用于系统设计中漏洞管理的系统性推理，帮助设计师识别漏洞并选择安全控制措施。


<details>
  <summary>详细信息</summary>
研究动机: 当前漏洞管理方法缺乏对系统设计漏洞状态的系统性推理能力，无法有效支持安全控制的设计。本文旨在填补这一空白，提出一种自动化推理机制，以提升漏洞管理的效率和准确性。

研究方法: 研究提出了一种形式化基础的自动化推理机制，并将其集成到开源安全设计工具中。通过实际案例验证了该机制的应用效果，包括漏洞识别、缓解选项明确指定及控制措施选择。

研究结果: 该机制成功帮助系统设计师识别特定设计中的漏洞，明确指定缓解选项，并选择控制措施，从而系统性管理漏洞状态。

研究结论: 本文提出的自动化推理机制为系统设计中的漏洞管理提供了系统性支持，显著提升了安全控制设计的效率和准确性。

中文摘要: 为确保系统安全，必须管理其漏洞状态并设计适当的安全控制措施。漏洞管理通过将相关安全控制纳入系统设计，主动解决漏洞问题。当前的漏洞管理方法不支持对系统设计漏洞状态的系统性推理。为有效管理漏洞并设计安全控制，我们提出了一种基于形式化基础的自动化推理机制。我们将该机制集成到开源安全设计工具中，并通过实际案例展示了其应用。该机制使系统设计师能够识别特定设计中的漏洞，明确指定缓解选项，声明所选控制措施，从而系统性管理漏洞状态。

</details>


### [247] [The Impact of Event Data Partitioning on Privacy-aware Process Discovery](https://arxiv.org/abs/2507.06008)
**中文标题：事件数据分区对隐私感知流程发现的影响**

*Jungeun Lim,Stephan A. Fahrenkrog-Petersen,Xixi Lu,Jan Mendling,Minseok Song*

主要分类: cs.CR

摘要简述: 本文提出了一种结合匿名化和事件数据分区的管道，通过事件抽象将事件日志分割为多个子日志，分别进行匿名化处理，从而在保护隐私的同时减少效用损失。实验验证了该方法对基于直接跟随的匿名化技术的效用提升。


<details>
  <summary>详细信息</summary>
研究动机: 信息系统的事件日志通常包含敏感信息，匿名化处理虽能保护隐私但会降低日志的效用。如何在隐私保护和效用保留之间找到平衡是一个挑战，尤其是在复杂事件日志中。

研究方法: 提出了一种管道方法，结合匿名化和事件数据分区。通过事件抽象将事件日志分割为多个子日志，每个子日志单独进行匿名化处理。

研究结果: 实验使用三个真实事件日志和两种流程发现技术，验证了事件分区对基于直接跟随的匿名化技术的效用提升。

研究结论: 事件分区方法在保护隐私的同时，显著减少了匿名化对流程发现效用的负面影响，尤其适用于复杂事件日志。

中文摘要: 信息系统支持业务流程的执行，这些执行的事件日志通常包含关于客户、患者和员工的敏感信息。相应的隐私挑战可以通过匿名化事件日志来解决，同时保留流程发现的效用。然而，平衡效用和隐私是困难的：事件日志越复杂，匿名化带来的效用损失越大。本文提出了一种结合匿名化和事件数据分区的管道，其中事件抽象用于分区。通过利用事件抽象，事件日志可以被分割为多个部分，每个子日志单独进行匿名化处理。这一管道在保护隐私的同时减少了效用损失。为验证我们的方法，我们研究了事件分区对两种匿名化技术的影响，使用了三个真实事件日志和两种流程发现技术。结果表明，事件分区可以提升基于直接跟随的匿名化技术在流程发现中的效用。

</details>


### [248] [CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](https://arxiv.org/abs/2507.06043)
**中文标题：CAVGAN：通过生成对抗攻击统一大型语言模型的越狱与防御**

*Xiaohu Li,Yunfeng Ning,Zepeng Bao,Mayi Xu,Jianhao Chen,Tieyun Qian*

主要分类: cs.CR

摘要简述: 本文提出了一种名为CAVGAN的框架，通过生成对抗网络（GAN）攻击大型语言模型（LLM）的内部表示，统一了越狱攻击与防御。实验表明，该方法在三种流行LLM上的平均越狱成功率为88.85%，防御成功率为84.17%，验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管安全对齐机制为大型语言模型（LLM）提供了对恶意查询的防护，但多种越狱攻击方法揭示了其脆弱性。以往研究将攻击与防御孤立分析，本文旨在结合两者，探索LLM内部安全机制。

研究方法: 基于LLM中间层嵌入的线性可分特性及越狱攻击的本质（将有害问题嵌入并转移到安全区域），利用生成对抗网络（GAN）学习LLM内部的安全判断边界，实现高效的越狱攻击与防御。

研究结果: 实验结果显示，该方法在三种流行LLM上的平均越狱成功率为88.85%，在最新越狱数据集上的平均防御成功率为84.17%，验证了其有效性，并为增强模型安全性提供了新见解。

研究结论: CAVGAN框架不仅验证了攻击与防御结合的有效性，还揭示了LLM内部安全机制，为提升模型安全性提供了新思路。代码与数据已开源。

中文摘要: 安全对齐机制使大型语言模型（LLM）能够抵御恶意查询，但多种越狱攻击方法揭示了该安全机制的脆弱性。以往研究将LLM越狱攻击与防御孤立分析。本文分析了LLM的安全保护机制，并提出了一种结合攻击与防御的框架。该方法基于LLM中间层嵌入的线性可分特性，以及越狱攻击的本质（将有害问题嵌入并转移到安全区域），利用生成对抗网络（GAN）学习LLM内部的安全判断边界，以实现高效的越狱攻击与防御。实验结果表明，该方法在三种流行LLM上的平均越狱成功率为88.85%，而在最新越狱数据集上的防御成功率达到平均84.17%。这不仅验证了方法的有效性，还为LLM内部安全机制提供了新见解，为增强模型安全性提供了新思路。代码与数据详见https://github.com/NLPGM/CAVGAN。

</details>


### [249] [Taming Data Challenges in ML-based Security Tasks: Lessons from Integrating Generative AI](https://arxiv.org/abs/2507.06092)
**中文标题：驯服基于机器学习的安全任务中的数据挑战：生成式AI集成的经验**

*Shravya Kanchi,Neal Mangaokar,Aravind Cheruvu,Sifat Muhammad Abdullah,Shirin Nilizadeh,Atul Prakash,Bimal Viswanath*

主要分类: cs.CR

摘要简述: 本文探讨了生成式AI（GenAI）如何解决机器学习安全任务中的数据挑战，通过合成数据增强训练集，显著提升分类器性能，并提出了一种新型GenAI方案Nimai。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于机器学习的监督分类器在安全任务中广泛应用，但其性能受限于数据问题，而生成式AI的发展为解决这些问题提供了可能。

研究方法: 提出利用生成式AI技术生成合成数据以增强训练集，并在7种安全任务中评估了6种先进GenAI方法，同时引入新型GenAI方案Nimai。

研究结果: 实验表明，GenAI技术显著提升了安全分类器的性能，在数据严重受限的情况下（仅约180个训练样本）性能提升高达32.6%，并能快速适应部署后的概念漂移。

研究结论: 尽管GenAI在安全任务中表现出色，但某些任务中的噪声标签、重叠类别分布和稀疏特征向量仍限制了其性能提升，未来需开发更针对性的GenAI工具。

中文摘要: 基于机器学习的监督分类器在安全任务中广泛应用，但其改进主要集中在算法层面，而数据问题对性能的负面影响却鲜少被关注。本文探讨了生成式AI（GenAI）能否解决这些数据挑战并提升分类器性能。我们提出通过GenAI技术生成合成数据以增强训练集，从而改善分类器的泛化能力。在7种不同的安全任务中，我们评估了6种先进的GenAI方法，并引入了一种新型GenAI方案Nimai，该方案支持高度可控的数据合成。实验表明，GenAI技术能显著提升安全分类器的性能，即使在数据严重受限的情况下（仅约180个训练样本），性能提升高达32.6%。此外，我们还证明GenAI能快速适应部署后的概念漂移，且调整过程中仅需少量标注。尽管取得了成功，但研究发现某些GenAI方案在某些安全任务中难以初始化（训练和生成数据）。我们还识别了一些任务特性（如噪声标签、重叠类别分布和稀疏特征向量）会阻碍GenAI的性能提升。我们相信本研究将推动未来针对安全任务的GenAI工具开发。

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [250] [Solar Flare Prediction Using LSTM and DLSTM with Sliding Window Pattern Recognition](https://arxiv.org/abs/2507.05313)
**中文标题：基于LSTM和DLSTM结合滑动窗口模式识别的太阳耀斑预测**

*Zeinab Hassani,Davud Mohammadpur,Hossein Safari*

主要分类: astro-ph.SR

摘要简述: 本研究利用LSTM和DLSTM结合滑动窗口模式识别技术预测太阳耀斑，通过正则化时间序列和集成方法提升预测性能，DLSTM表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 太阳耀斑的复杂性和自组织临界行为使其长期预测具有挑战性，研究旨在利用先进机器学习技术提高预测准确性。

研究方法: 使用LSTM和DLSTM模型，结合滑动窗口技术和集成算法，分析GOES目录中的时间序列数据，正则化处理以减少复杂性并增强大耀斑活动检测。

研究结果: DLSTM结合集成方法在正则化时间序列上表现最优，TSS为0.74，召回率为0.95，AUC为0.87，显著优于其他模型。

研究结论: DLSTM能有效分解时间序列并隔离随机噪声，结合正则化和集成方法可显著提升太阳耀斑预测的可靠性。

中文摘要: 本研究探讨了利用长短期记忆网络（LSTM）和分解LSTM（DLSTM）结合集成算法，通过GOES目录中的时间序列数据预测太阳耀斑的发生。数据集涵盖2003年至2023年的151,071次耀斑事件，识别出7,552个年度模式窗口，凸显了太阳复杂自组织临界行为对长期预测的挑战。采用滑动窗口技术检测不规则和正则化耀斑时间序列中的准模式。正则化降低了复杂性，增强了大耀斑活动的检测能力，并更有效地捕捉活跃日。为解决类别不平衡问题，应用了重采样方法。LSTM和DLSTM模型在不规则时间序列的峰值通量和等待时间序列上训练，而结合集成方法的LSTM和DLSTM则应用于3小时间隔的正则化时间序列滑动窗口。性能指标显示，正则化时间序列上的DLSTM结合集成方法表现最优，TSS为0.74，召回率为0.95，ROC曲线下面积（AUC=0.87），相比其他模型能更准确地预测大耀斑且错误较少。DLSTM的优越性能归因于其将时间序列分解为趋势和季节性成分的能力，有效隔离随机噪声。本研究强调了先进机器学习技术在太阳耀斑预测中的潜力，并指出结合不同太阳周期阶段和重采样策略对提升预测可靠性的重要性。

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [251] [AI-Reporter: A Path to a New Genre of Scientific Communication](https://arxiv.org/abs/2507.05903)
**中文标题：AI-Reporter：通向科学传播新范式的路径**

*Gerd Graßhoff*

主要分类: cs.DL

摘要简述: AI-Reporter是一种革命性的科学出版工具，能在三分钟内将学术演讲转化为可出版的章节，填补了临时演讲与永久科学文献之间的鸿沟。


<details>
  <summary>详细信息</summary>
研究动机: 论文的动机在于解决学术演讲与正式出版物之间的脱节问题，通过技术创新实现快速、高效的学术内容转化。

研究方法: 论文通过具体案例研究展示了AI-Reporter系统如何将学术演讲（如Arno Simons关于大语言模型的讲座）转化为出版级别的章节。

研究结果: 研究结果表明，AI-Reporter能在三分钟内完成从演讲到出版物的转化，显著提升了科学传播的效率。

研究结论: 论文得出结论，AI-Reporter为科学传播开辟了新途径，通过技术手段弥合了学术演讲与正式出版物之间的差距。

中文摘要: AI-Reporter代表了科学出版实践中的范式转变。本文通过具体案例研究展示了我们的系统如何在不到三分钟内将学术演讲转化为可出版的章节。以Arno Simons在“大语言模型对科学史、哲学和社会学的影响”研讨会（NEPI）上的演讲为例，我们展示了技术创新如何弥合临时演讲与永久科学文献之间的鸿沟。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [252] [ABench-Physics: Benchmarking Physical Reasoning in LLMs via High-Difficulty and Dynamic Physics Problems](https://arxiv.org/abs/2507.04766)
**中文标题：ABench-Physics：通过高难度动态物理问题评测大型语言模型的物理推理能力**

*Yiming Zhang,Yingfan Ma,Yanmei Gu,Zhengkai Yang,Yihong Zhuang,Feng Wang,Zenan Huang,Yuanyuan Wang,Chao Huang,Bowen Song,Cheng Lin,Junbo Zhao*

主要分类: cs.LG

摘要简述: 本文介绍了ABench-Physics，一个用于严格评估大型语言模型（LLMs）物理推理和泛化能力的新基准。该基准包含静态和动态问题集，揭示了LLMs在物理推理上的显著局限性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在数学和编程领域表现出色，但其物理推理能力尚未充分探索。现有基准因难度不足、选择题形式及静态评估设置而无法全面评估物理建模能力。

研究方法: ABench-Physics包含两部分：Phy_A（400道静态高难度问题）和Phy_B（100道动态问题，配备自动变化引擎以测试模型鲁棒性）。所有问题需提供精确数值答案。

研究结果: 对多个先进LLMs的评估显示其在物理推理上存在显著性能差距，尤其在动态问题泛化能力上表现不佳。

研究结论: ABench-Physics为提升LLMs的科学推理能力提供了一个具有挑战性和诊断性的框架。

中文摘要: 大型语言模型（LLMs）在数学和编程等领域表现出色，但其物理推理能力尚未充分探索。物理问题不仅需要精确计算，还需深刻的概念理解和物理建模能力。现有基准因难度不足、选择题形式及静态评估设置而无法全面评估物理建模能力。本文提出ABench-Physics，一个用于严格评估LLMs物理推理和泛化能力的新基准。ABench-Physics包含两部分：Phy_A（400道静态高难度问题）和Phy_B（100道动态问题，配备自动变化引擎以测试模型鲁棒性）。所有问题需提供精确数值答案。对多个先进LLMs的评估显示其在物理推理上存在显著性能差距，尤其在动态问题泛化能力上表现不佳。ABench-Physics为提升LLMs的科学推理能力提供了一个具有挑战性和诊断性的框架。

</details>


### [253] [Rethinking Over-Smoothing in Graph Neural Networks: A Perspective from Anderson Localization](https://arxiv.org/abs/2507.05263)
**中文标题：重新思考图神经网络中的过平滑问题：基于安德森局域化的视角**

*Kaichen Ouyang*

主要分类: cs.LG

摘要简述: 本文通过类比安德森局域化现象，分析了图神经网络（GNNs）中的过平滑问题，并提出参与度作为量化指标。研究表明，过平滑可理解为低频模式扩展和高频模式局域化，并探讨了通过减少信息传播中的无序性来缓解过平滑的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 随着图神经网络深度的增加，过平滑问题导致节点表征失去独特性，限制了模型的性能。本文旨在从安德森局域化的角度理解过平滑机制，并提出解决方案。

研究方法: 通过类比安德森局域化现象，提出参与度作为量化过平滑的指标，并分析节点特征在多层次消息传递中的同质化行为。理论分析了无序系统中安德森局域化与GNN过平滑的潜在联系。

研究结果: 研究表明，过平滑表现为低频模式扩展和高频模式局域化，参与度能有效量化这一现象。理论分析表明，减少信息传播中的无序性可能缓解过平滑问题。

研究结论: 本文从安德森局域化视角揭示了GNN过平滑的机制，并提出参与度作为量化工具。未来可通过优化信息传播的无序性来改善过平滑问题。

中文摘要: 图神经网络（GNNs）因其强大的表征能力在图数据分析中展现出巨大潜力。然而，随着网络深度的增加，过平滑问题愈发严重，导致节点表征失去独特性。本文通过类比安德森局域化现象分析了过平滑的机制，并引入参与度作为量化指标。具体而言，随着GNN深度的增加，节点特征在多层次消息传递后趋于同质化，类似于无序系统中振动模式的行为。在此背景下，GNN中的过平滑可理解为低频模式扩展（参与度增加）和高频模式局域化（参与度减少）。基于此，我们系统回顾了无序系统中的安德森局域化行为与图神经网络中过平滑行为的潜在联系，并进行了理论分析，提出了通过减少信息传播中的无序性来缓解过平滑的潜力。

</details>


### [254] [Compressing Deep Neural Networks Using Explainable AI](https://arxiv.org/abs/2507.05286)
**中文标题：利用可解释人工智能压缩深度神经网络**

*Kimia Soroush,Mohsen Raji,Behnam Ghavami*

主要分类: cs.LG

摘要简述: 本文提出了一种利用可解释人工智能（XAI）压缩深度神经网络（DNN）的新方法，通过梯度驱动的XAI技术（如LRP）计算参数重要性分数，并结合剪枝和混合精度量化，显著减小模型尺寸且精度损失可忽略。实验显示，该方法将模型尺寸减少64%，同时精度提升42%。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络（DNN）性能卓越但计算和内存成本高昂，尤其在资源受限的边缘设备上。现有压缩技术（如剪枝和量化）虽有效，但缺乏对DNN内部工作机制的理解。XAI方法可揭示DNN参数的重要性，为高效压缩提供新思路。

研究方法: 1) 使用基于梯度的XAI技术（LRP）计算DNN参数（权重）的重要性分数；2) 剪除重要性分数为零或负的参数；3) 对重要性分数高的权重使用高比特量化，分数低的权重使用低比特量化。

研究结果: 实验结果表明，该方法将模型尺寸减少64%，同时精度比现有XAI压缩方法提升42%。

研究结论: 结合XAI的DNN压缩方法不仅能显著减小模型尺寸，还能保持甚至提升精度，为资源受限设备上的DNN部署提供了高效解决方案。

中文摘要: 深度神经网络（DNN）在许多任务中表现出色，但其高计算成本和内存占用限制了应用。压缩技术（如剪枝和量化）可减少DNN内存占用，使其适用于资源受限的边缘设备。近年来，可解释人工智能（XAI）方法被引入以理解和解释AI模型。XAI可用于揭示DNN内部机制，如神经元和特征对性能的重要性。本文提出了一种基于XAI的DNN压缩方法，通过梯度驱动的XAI技术（如LRP）计算参数重要性分数，并据此剪除不重要参数及混合精度量化权重。实验显示，该方法将模型尺寸减少64%，同时精度比现有XAI压缩方法提升42%。

</details>


### [255] [Physics-Informed Graph Neural Networks to Reconstruct Local Fields Considering Finite Strain Hyperelasticity](https://arxiv.org/abs/2507.05291)
**中文标题：基于物理信息的图神经网络在有限应变超弹性条件下重建局部场**

*Manuel Ricardo Guevara Garban,Yves Chemisky,Étienne Prulière,Michaël Clément*

主要分类: cs.LG

摘要简述: 本文提出了一种基于物理信息的图神经网络P-DivGNN，用于在有限应变超弹性条件下重建微观尺度的局部应力场，结合周期性边界条件和物理约束，显著提高了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 在多尺度模拟中，准确预测微观尺度的局部应力场对于断裂分析或局部疲劳准则的定义至关重要。传统有限元模拟计算成本高，因此需要一种高效且物理约束的方法。

研究方法: 该方法将周期性微结构表示为图，结合消息传递图神经网络，并通过物理约束训练确保局部应力场的平衡状态。同时，采用周期性图表示以强制周期性边界条件。

研究结果: 在线性和非线性超弹性响应下，该方法能够高效重建局部应力场分布，并在非线性情况下显著优于有限元模拟的计算速度，适用于大规模应用。

研究结论: P-DivGNN方法通过结合物理约束和图神经网络，成功实现了高效且准确的局部应力场重建，为多尺度模拟提供了新的解决方案。

中文摘要: 我们提出了一种基于物理信息的机器学习框架P-DivGNN，用于在多尺度模拟中重建微观尺度的局部应力场。该方法基于周期性微结构的图表示，结合消息传递图神经网络，能够从宏观尺度的平均应力值（由均值场降阶模型或有限元模拟提供）中恢复局部应力场分布。局部应力场的预测对于断裂分析或局部疲劳准则的定义至关重要。我们的模型在训练中引入物理约束以确保局部应力场的平衡状态，并通过周期性图表示强制周期性边界条件。在线性和非线性超弹性响应下，该方法表现出显著的计算效率提升，尤其在非线性情况下，相比有限元模拟具有明显优势，适用于大规模应用。

</details>


### [256] [Reinforcement Fine-Tuning Naturally Mitigates Forgetting in Continual Post-Training](https://arxiv.org/abs/2507.05386)
**中文标题：强化微调自然缓解持续后训练中的遗忘问题**

*Song Lai,Haohan Zhao,Rong Feng,Changyi Ma,Wenzhuo Liu,Hongbo Zhao,Xi Lin,Dong Yi,Min Xie,Qingfu Zhang,Hongbin Liu,Gaofeng Meng,Fei Zhu*

主要分类: cs.LG

摘要简述: 本文比较了监督微调（SFT）和强化微调（RFT）在持续后训练（CPT）中对知识保留的影响，发现RFT能有效缓解遗忘问题，并保持模型通用能力，而SFT则导致灾难性遗忘。


<details>
  <summary>详细信息</summary>
研究动机: 持续后训练（CPT）是调整基础模型以适应下游任务的重要技术，但现有研究多关注数据回放、模型扩展等方法，而忽略了学习范式的作用。本文旨在探索SFT和RFT在CPT中的表现差异。

研究方法: 在七个多模态任务基准上，以Qwen2.5-VL-7B-Instruct为基础模型，对比SFT和RFT对知识保留的影响，并分析KL惩罚和思维链推理等机制的作用。

研究结果: 实验表明，SFT会导致灾难性遗忘，而RFT能保留先前知识且性能接近多任务训练。RFT还能提升模型在通用基准（如MMMU和MMLU-Pro）上的表现。

研究结论: RFT的隐式正则化是缓解遗忘的关键因素。研究还提出了一种基于rollout的实例过滤算法，进一步提升了RFT的稳定性和效率。

中文摘要: 持续后训练（CPT）是一种流行且有效的技术，用于调整多模态大语言模型等基础模型以适应特定且不断变化的下游任务。现有研究主要集中在数据回放、模型扩展或参数正则化等方法上，而CPT中学习范式的基本作用尚未得到充分探索。本文对两种核心后训练范式——监督微调（SFT）和强化微调（RFT）进行了比较分析，研究了它们在CPT中对知识保留的影响。实验在包含七个多样化多模态任务的基准上进行，以Qwen2.5-VL-7B-Instruct为基础模型进行持续后训练。研究得出两个重要发现：（1）在持续学习下游任务时，SFT会导致对先前学习任务的灾难性遗忘，而RFT则能自然保留先前知识，并达到与多任务训练相当的性能。（2）RFT成功保护甚至提升了模型在标准基准（如MMMU和MMLU-Pro）上的通用知识，而SFT则严重降低了模型的通用能力。进一步分析表明，显式机制（如KL惩罚和思维链推理）并非主要因素，而是RFT固有的隐式正则化在缓解遗忘中起关键作用。最后，我们提出了一种基于rollout的实例过滤算法，以提高RFT的稳定性和效率。我们的全面研究证明了RFT作为持续后训练的鲁棒范式的优越性。

</details>


### [257] [The Landscape of Memorization in LLMs: Mechanisms, Measurement, and Mitigation](https://arxiv.org/abs/2507.05578)
**中文标题：大语言模型中的记忆化现象：机制、测量与缓解**

*Alexander Xiong,Xuandong Zhao,Aneesh Pappu,Dawn Song*

主要分类: cs.LG

摘要简述: 本文综述了大语言模型（LLMs）中记忆化现象的机制、测量与缓解策略，探讨了其对隐私、模型行为的影响，并提出了检测与缓解方法。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在广泛任务中表现卓越，但其对训练数据的记忆化现象引发了隐私风险与模型行为边界问题。本文旨在综合研究记忆化的驱动因素、检测方法及缓解策略。

研究方法: 通过分析训练数据重复、训练动态和微调过程等关键驱动因素，研究记忆化现象；评估前缀提取、成员推断和对抗提示等方法在检测记忆内容中的有效性。

研究结果: 研究发现数据重复和训练动态显著影响记忆化，现有检测方法各有优劣；缓解策略如数据清理和差分隐私在平衡效用与隐私方面仍有挑战。

研究结论: 本文全面总结了LLM记忆化的研究现状，指出未来需在技术、隐私与性能维度进一步探索。

中文摘要: 大语言模型（LLMs）在广泛任务中表现出卓越能力，但也存在对训练数据的记忆化现象。这一现象引发了对模型行为、隐私风险及学习与记忆边界的关注。本文综合近期研究，探讨了记忆化的驱动因素（如训练数据重复、训练动态和微调过程）、检测方法（如前缀提取、成员推断和对抗提示）及其有效性。此外，还分析了记忆化的法律与伦理影响，并讨论了数据清理、差分隐私和训练后遗忘等缓解策略，同时指出在减少有害记忆化与保持模型效用之间的平衡仍面临挑战。本文从技术、隐私与性能维度全面综述了LLM记忆化的研究现状，为未来工作指明了方向。

</details>


### [258] [Neural Velocity for hyperparameter tuning](https://arxiv.org/abs/2507.05309)
**中文标题：基于神经速度的超参数调优方法**

*Gianluca Dalmasso,Andrea Bragagnolo,Enzo Tartaglione,Attilio Fiandrotti,Marco Grangetto*

主要分类: cs.LG

摘要简述: 本文提出了一种名为NeVe的动态训练方法，通过“神经速度”这一新概念调整学习率和停止准则，无需依赖验证集，显著提升了神经网络训练的效率和效果。


<details>
  <summary>详细信息</summary>
研究动机: 超参数调优（如学习率衰减和停止准则定义）通常依赖验证损失监控，但这种方法需要额外的验证数据集。本文旨在通过神经速度这一新指标，减少对验证集的依赖，优化训练过程。

研究方法: NeVe方法通过测量神经元传递函数的变化率（即神经速度）来动态调整学习率和定义停止准则。神经速度可通过在网络中前向传播噪声来采样，无需额外验证数据。

研究结果: 实验结果表明，神经速度能够有效指示模型收敛状态，显著减少对验证集的依赖，同时提升训练效率和模型性能。

研究结论: 神经速度作为一种新型指标，为神经网络训练的超参数调优提供了高效且实用的解决方案，具有广泛的应用潜力。

中文摘要: 超参数调优（如学习率衰减和停止准则定义）通常依赖验证损失的监控。本文提出了一种名为NeVe的动态训练方法，通过“神经速度”这一新概念调整学习率和停止准则。神经速度衡量了神经元传递函数的变化率，是模型收敛的指示器：甚至可以通过在网络中前向传播噪声来采样神经速度，从而减少对额外验证数据集的需求。我们的研究结果表明，神经速度作为一种关键指标，能够高效优化神经网络训练。

</details>


### [259] [AutoTriton: Automatic Triton Programming with Reinforcement Learning in LLMs](https://arxiv.org/abs/2507.05687)
**中文标题：AutoTriton：基于强化学习的大型语言模型自动Triton编程**

*Shangzhan Li,Zefan Wang,Ye He,Yuxuan Li,Qi Shi,Jianling Li,Yonggang Hu,Wanxiang Che,Xu Han,Zhiyuan Liu,Maosong Sun*

主要分类: cs.LG

摘要简述: AutoTriton是首个基于强化学习的Triton编程模型，通过监督微调和强化学习优化GPU内核开发，性能媲美主流大模型。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习中的内核开发需要跨硬件优化计算单元，而Triton等域特定语言虽简化了GPU编程，但仍需手动调优关键参数，阻碍了性能优化和广泛采用。

研究方法: AutoTriton通过高质量数据收集管道进行监督微调（SFT），并采用Group Relative Policy Optimization（GRPO）算法进行强化学习，结合基于规则和执行的奖励机制逐步提升编程能力。

研究结果: 实验表明，8B参数的AutoTriton在TritonBench和KernelBench五个评估通道中性能与Claude-4-Sonnet和DeepSeek-R1-0528等主流大模型相当，验证了各模块（SFT、RL和奖励设计）的关键作用。

研究结论: AutoTriton展示了强化学习在自动生成高性能内核中的潜力，为构建更高效的AI系统奠定了基础。

中文摘要: 深度学习中的内核开发需要在硬件间优化计算单元，同时通过大量实验调优平衡内存管理、并行性和硬件特定优化。尽管Triton等域特定语言通过抽象底层细节简化了GPU编程，开发者仍需通过迭代实验手动调优关键参数（如分块大小和内存访问模式），这为性能优化和广泛采用设置了障碍。本文提出AutoTriton，首个基于强化学习（RL）的Triton编程模型。AutoTriton通过高质量数据收集管道进行监督微调（SFT），掌握Triton编程核心能力，并采用Group Relative Policy Optimization（GRPO）算法进行强化学习，结合基于规则和执行的奖励机制逐步提升编程能力。在TritonBench和KernelBench的五个评估通道中，8B参数的AutoTriton性能与Claude-4-Sonnet和DeepSeek-R1-0528等主流大模型相当。进一步实验分析验证了AutoTriton中各模块（SFT阶段、RL阶段和奖励设计策略）的关键作用。这些发现凸显了强化学习在自动生成高性能内核中的潜力，而高性能内核是AI系统的核心组件，这一突破为构建更高效的AI系统奠定了重要基础。模型和代码将在https://github.com/AI9Stars/AutoTriton公开。

</details>


### [260] [MobileGUI-RL: Advancing Mobile GUI Agent through Reinforcement Learning in Online Environment](https://arxiv.org/abs/2507.05720)
**中文标题：MobileGUI-RL：通过在线环境强化学习提升移动GUI代理**

*Yucheng Shi,Wenhao Yu,Zaitang Li,Yonglin Wang,Hongming Zhang,Ninghao Liu,Haitao Mi,Dong Yu*

主要分类: cs.LG

摘要简述: MobileGUI-RL提出了一种通过在线环境强化学习训练移动GUI代理的框架，解决了离线训练导致的泛化性差和策略脆弱问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于视觉的GUI代理通常在离线环境中训练，依赖预收集的轨迹，导致泛化性差、对特定UI模板过拟合，且在未知环境中策略脆弱。MobileGUI-RL旨在通过在线训练提升代理的适应性和效率。

研究方法: MobileGUI-RL包含两个核心组件：(1) 通过自我探索和过滤合成可学习任务的课程；(2) 结合轨迹感知优势和复合奖励（平衡任务成功与执行效率）的GRPO算法。

研究结果: 在三个在线移动代理基准测试中，MobileGUI-RL表现优于现有方法，验证了其有效性。

研究结论: MobileGUI-RL通过在线强化学习显著提升了GUI代理的适应性和执行效率，为移动GUI自动化任务提供了可扩展的解决方案。

中文摘要: 近年来，基于视觉的GUI代理逐渐兴起，用于自动化日常移动和网页任务。这些代理通过解析原始GUI截图自主决定点击、滚动或输入位置，绕过了手工规则和特定应用API。然而，现有方法大多在离线环境中使用预收集轨迹训练代理，导致可扩展性受限、对特定UI模板过拟合，且在未知环境中策略脆弱。本文提出MobileGUI-RL，一种在在线环境中训练GUI代理的可扩展框架。其包含两个关键组件：(1) 通过自我探索和过滤合成可学习任务的课程；(2) 结合轨迹感知优势和复合奖励（平衡任务成功与执行效率）的GRPO算法。在三个在线移动代理基准测试中，MobileGUI-RL表现优于现有方法，验证了其有效性。

</details>


### [261] [Conditional Graph Neural Network for Predicting Soft Tissue Deformation and Forces](https://arxiv.org/abs/2507.05315)
**中文标题：条件图神经网络用于预测软组织变形和受力**

*Madina Kojanazarova,Florentin Bieder,Robin Sandkühler,Philippe C. Cattin*

主要分类: cs.LG

摘要简述: 本文提出了一种条件图神经网络（cGNN），用于预测软组织的变形和受力，解决了虚拟环境中软组织模拟的复杂性问题，并通过实验数据验证了其高精度预测能力。


<details>
  <summary>详细信息</summary>
研究动机: 虚拟环境中的软组织模拟在医学应用中日益重要，但其高变形性带来了显著挑战。现有方法依赖组织分割、网格化和刚度估计，且需要精确的力反馈以提升沉浸感。本文旨在通过数据驱动模型解决这些复杂性。

研究方法: 提出了一种条件图神经网络（cGNN），输入为表面点和施力位置，专门用于预测点的变形和受力。模型通过质量-弹簧模拟的预训练和实验数据的微调，克服了数据稀缺问题。

研究结果: 模型预测变形时的距离误差为0.35±0.03 mm（变形范围达30 mm），预测力的绝对误差为0.37±0.05 N（力范围达7.5 N），表现出高精度。

研究结论: 该数据驱动方法为虚拟环境中软组织模拟提供了有前景的解决方案，不仅适用于医学模拟，还可推广至其他需要真实软组织模拟的领域。

中文摘要: 虚拟环境中的软组织模拟在医学应用中日益重要，但其高变形性带来了显著挑战。现有方法依赖组织的分割、网格化和刚度估计，同时需要精确的力反馈以实现更沉浸的体验。为解决这一复杂性，我们提出了一种新型数据驱动模型——条件图神经网络（cGNN）。该模型以表面点和施力位置为输入，专门用于预测点的变形和受力。我们通过实验采集的软组织模型表面跟踪数据训练模型，并利用迁移学习方法，先用质量-弹簧模拟预训练，再用实验数据微调，以克服数据稀缺问题。这一方法提升了模型的泛化能力，实现了对组织变形及相应作用力的准确预测。结果表明，模型预测变形的距离误差为0.35±0.03 mm（变形范围达30 mm），预测力的绝对误差为0.37±0.05 N（力范围达7.5 N）。我们的数据驱动方法为虚拟环境中软组织模拟的复杂挑战提供了有前景的解决方案。除医学模拟外，该方法还有望应用于其他需要真实软组织模拟的领域。

</details>


### [262] [Going Beyond Heuristics by Imposing Policy Improvement as a Constraint](https://arxiv.org/abs/2507.05328)
**中文标题：通过将策略改进作为约束条件超越启发式方法**

*Chi-Chang Lee,Zhang-Wei Hong,Pulkit Agrawal*

主要分类: cs.LG

摘要简述: 本文提出了一种新方法HEPO，通过将策略改进作为约束条件，有效利用启发式奖励，避免传统方法的奖励滥用问题，并在标准基准测试中表现出色，减少了人工设计奖励的工作量。


<details>
  <summary>详细信息</summary>
研究动机: 在强化学习中，启发式奖励常用于提升任务性能，但其非最优性导致需要大量人工和计算资源来平衡任务与启发式奖励。传统基于策略不变性的方法在实践中表现不佳，因此需要一种新方法来有效利用启发式奖励并避免奖励滥用。

研究方法: 本文提出了HEPO框架，通过将策略改进作为约束条件，而非单纯追求策略不变性，从而有效利用启发式奖励。HEPO是一种即插即用的优化方法，适用于强化学习中启发式奖励的利用。

研究结果: HEPO在标准基准测试中表现优异，即使启发式奖励设计不佳或由非专家设计，也能实现良好的性能，显著减少了人工设计奖励的负担。

研究结论: HEPO通过将策略改进作为约束条件，成功解决了传统方法在利用启发式奖励时的问题，为强化学习中的奖励设计提供了高效且实用的解决方案。

中文摘要: 在许多强化学习（RL）应用中，通过启发式奖励增强任务奖励以编码人类对任务解决方式的先验知识，是实现理想性能的关键。然而，由于这些启发式通常并非最优，需要大量人工和计算资源来平衡任务与启发式奖励。理论上，基于策略不变性的方法可以确保启发式奖励最大化得到的策略与任务奖励的最优策略性能一致，但实践中这些方法表现不佳。我们提出了一种新范式，以避免奖励滥用并有效利用启发式奖励，其核心是将策略改进而非策略不变性作为实际目标。我们的框架HEPO（启发式增强策略优化）在避免传统方法缺陷的同时，有效利用了启发式奖励。HEPO在标准基准测试中表现优异，即使启发式奖励设计不佳或由非专家设计，也能实现良好性能，展示了HEPO在减少奖励设计人工负担方面的能力。HEPO是一种即插即用的优化方法，适用于强化学习中的启发式奖励利用。代码发布于https://github.com/Improbable-AI/hepo。

</details>


### [263] [Causal Foundation Models: Disentangling Physics from Instrument Properties](https://arxiv.org/abs/2507.05333)
**中文标题：因果基础模型：从仪器特性中解耦物理现象**

*Jeroen Audenaert,Daniel Muthukrishna,Paul F. Gregory,David W. Hogg,V. Ashley Villar*

主要分类: cs.LG

摘要简述: 本文提出了一种基于因果关系的双编码器基础模型，通过结构化对比学习分离物理现象与仪器效应，显著提升了多仪器环境下的模型泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 结构化时间序列数据的基础模型面临一个核心问题：观测数据往往混淆了真实的物理现象与测量仪器引入的系统性失真。这种混杂限制了模型在异构或多仪器环境中的泛化能力。

研究方法: 采用双编码器架构和结构化对比学习，利用自然观测三元组（同一目标在不同条件下测量，不同目标在相同条件下测量）分别学习物理信号和仪器效应的潜在表示。

研究结果: 在模拟的天文时间序列数据上，该方法显著优于传统单潜在空间基础模型，尤其在低数据量任务中表现突出，支持少样本泛化和高效适应。

研究结论: 研究表明，将因果结构编码到表示学习中对于结构化数据至关重要，该方法为多仪器环境下的基础模型提供了有效解决方案。

中文摘要: 结构化时间序列数据的基础模型面临一个根本性挑战：观测数据往往混淆了真实的物理现象与测量仪器引入的系统性失真。这种混杂限制了模型的泛化能力，尤其是在异构或多仪器环境中。我们提出了一种基于因果关系的双编码器基础模型，通过结构化对比学习显式解耦物理和仪器因素。利用自然观测三元组（即同一目标在不同条件下测量，不同目标在相同条件下测量），我们的模型分别学习了物理信号和仪器效应的潜在表示。在模拟的天文时间序列数据上（设计为类似NASA的TESS任务观测的变星复杂性），我们的方法在下游预测任务中显著优于传统的单潜在空间基础模型，尤其是在低数据量任务中。这些结果表明，我们的模型支持基础模型的关键能力，包括少样本泛化和高效适应，并强调了将因果结构编码到表示学习中的重要性。

</details>


### [264] [Differential Mamba](https://arxiv.org/abs/2507.06204)
**中文标题：差分Mamba**

*Nadav Schneider,Itamar Zimerman,Eliya Nachmani*

主要分类: cs.LG

摘要简述: 本文探讨了如何将差分设计应用于Mamba架构，以解决序列模型中注意力分配不均的问题，并通过实验验证了改进后的Mamba在语言建模任务中的优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 序列模型（如Transformer和RNN）常因对无关上下文的过度关注而产生噪声，影响模型性能。本文旨在验证差分设计是否适用于Mamba架构，以提升其效率和能力。

研究方法: 提出了一种针对Mamba的新型差分机制，并通过语言建模基准实验验证其有效性，同时进行了广泛的消融研究以支持设计选择。

研究结果: 实验表明，改进后的Mamba在检索能力和性能上优于原始版本，有效缓解了注意力分配不均的问题。

研究结论: 本文成功将差分设计应用于Mamba，并通过实验证明了其有效性，为Mamba架构的优化提供了新思路。

中文摘要: 序列模型（如Transformer和RNN）常因对无关上下文的过度关注而产生噪声，导致中间表示不准确，进而影响大语言模型的能力，如产生幻觉、削弱长距离和检索能力，并降低鲁棒性。近期研究表明，差分设计可以缓解Transformer中的这一问题，提升其在不同应用中的效果。本文探讨了这些技术是否适用于Mamba——一种基于选择性状态空间层的新架构，其性能与Transformer相当但效率更高。我们发现，直接将差分设计应用于Mamba效果不佳，需进行细致的架构调整。为此，我们提出了一种新型差分机制，并通过语言建模基准实验验证了其有效性，证明改进后的Mamba在检索能力和性能上优于原始版本。最后，我们通过大量消融研究和实证分析，验证了设计选择的合理性，并证明该方法有效缓解了Mamba模型中的注意力分配不均问题。我们的代码已公开。

</details>


### [265] [Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verification](https://arxiv.org/abs/2507.05405)
**中文标题：基于概率收紧线性松弛的神经网络扰动分析**

*Luca Marzari,Ferdinando Cicalese,Alessandro Farinelli*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PT-LiRPA的新框架，结合了LiRPA的过近似技术和采样方法，显著提高了神经网络输出边界的紧密度，降低了形式验证的计算成本，并在标准验证基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有神经网络形式验证方法在计算输出边界时存在过近似问题，导致验证结果不精确或计算成本高。本文旨在通过结合采样技术，提供更紧的边界估计，同时保持验证的可靠性。

研究方法: PT-LiRPA框架结合了LiRPA的线性松弛技术和采样方法，通过估计可达集来收紧神经网络的输出边界，从而减少形式验证的计算负担。

研究结果: 实验表明，PT-LiRPA在标准验证基准测试中显著优于现有方法，将鲁棒性证明提高了3.31倍和2.26倍，并在99%置信度下解决了现有方法无法处理的挑战性问题。

研究结论: PT-LiRPA通过结合采样和线性松弛技术，提供了一种高效且可靠的形式验证方法，显著提升了神经网络验证的精度和效率。

中文摘要: 我们提出了一种名为PT-LiRPA的新框架，该框架结合了LiRPA方法的过近似技术和采样方法，用于计算紧致的中间可达集。具体而言，我们展示了PT-LiRPA在几乎不增加计算开销的情况下，通过利用估计的可达集，显著收紧神经网络输出的上下线性边界，从而降低形式验证工具的计算成本，同时提供验证可靠性的概率保证。在国际神经网络验证竞赛等标准验证基准测试中，实验表明基于PT-LiRPA的验证器将鲁棒性证明提高了3.31倍和2.26倍。重要的是，我们的概率方法为现有形式验证方法无法解决的挑战性问题提供了高置信度（至少99%）的解决方案。

</details>


### [266] [EmissionNet: Air Quality Pollution Forecasting for Agriculture](https://arxiv.org/abs/2507.05416)
**中文标题：EmissionNet：农业空气质量污染预测**

*Prady Saligram,Tanvir Bhathal*

主要分类: cs.LG

摘要简述: 本文提出两种深度学习模型EmissionNet（ENV）和EmissionNet-Transformer（ENT），用于预测农业排放的N$_2$O污染，解决了传统物理模型难以捕捉非线性污染物交互的问题。


<details>
  <summary>详细信息</summary>
研究动机: 农业排放是空气污染的重要来源，但常被忽视。传统空气质量预测模型基于物理方法，难以处理复杂的非线性污染物交互。本文旨在通过深度学习模型改进农业排放预测。

研究方法: 本文评估了流行的深度学习架构，并提出了两种新模型：EmissionNet（ENV）和EmissionNet-Transformer（ENT）。ENV基于卷积架构，ENT基于Transformer架构，两者均用于从高分辨率排放数据中提取时空依赖关系。

研究结果: 实验表明，ENV和ENT模型能够有效捕捉农业排放的时空特征，显著提升了N$_2$O排放预测的准确性。

研究结论: 本文提出的深度学习模型为农业排放预测提供了新思路，解决了传统方法的局限性，具有实际应用潜力。

中文摘要: 农业排放是空气污染的重要来源，但对环境和公共健康的挑战常被忽视。传统的空气质量预测模型依赖基于物理的方法，难以捕捉复杂的非线性污染物交互。本文通过评估流行架构，提出了两种新型深度学习模型EmissionNet（ENV）和EmissionNet-Transformer（ENT）。这些模型利用卷积和基于Transformer的架构，从高分辨率排放数据中提取时空依赖关系。

</details>


### [267] [2048: Reinforcement Learning in a Delayed Reward Environment](https://arxiv.org/abs/2507.05465)
**中文标题：2048：延迟奖励环境中的强化学习**

*Prady Saligram,Tanvir Bhathal,Robby Manihani*

主要分类: cs.LG

摘要简述: 本文提出了一种统一的分布多步强化学习框架，用于优化长期性能，并在2048游戏中验证了其有效性。通过比较四种代理变体，结果显示H-DQN表现最佳，达到了2048和4096方块。


<details>
  <summary>详细信息</summary>
研究动机: 延迟和稀疏奖励是强化学习代理面临的主要挑战，尤其是在2048这类游戏中，即时反馈可能导致局部最优但全局次优的策略。本文旨在通过多步强化学习框架解决这一问题。

研究方法: 研究开发了四种代理变体：标准DQN、PPO、QR-DQN和新型H-DQN。H-DQN结合了分布学习、决斗架构、噪声网络和优先回放等技术。

研究结果: 实验结果显示，H-DQN表现最优，最高得分达到41.828K，并成功生成4096方块。其他代理的得分依次为DQN（3.988K）、PPO（5.756K）和QR-DQN（8.66K）。

研究结论: 分布多步目标显著提升了稀疏奖励领域的性能，未来可通过基于模型的规划和课程学习进一步优化。

中文摘要: 延迟和稀疏奖励是强化学习（RL）代理面临的根本障碍，这些代理难以将功劳归于那些效果在多步之后才显现的动作。滑动方块游戏2048体现了这一挑战：尽管频繁的小分数变化提供了即时反馈，但它们常常误导代理采取局部最优但全局次优的策略。本研究提出了一种统一的分布多步RL框架，旨在直接优化长期性能。利用开源Gym-2048环境，我们开发并比较了四种代理变体：标准DQN、PPO、QR-DQN（分位数回归DQN）和新型Horizon-DQN（H-DQN）。H-DQN集成了分布学习、决斗架构、噪声网络、优先回放等技术。实证评估显示效果存在明显层次：最高单局得分从DQN的3.988K提升至PPO的5.756K、QR-DQN的8.66K和H-DQN的18.21K，其中H-DQN成功生成2048方块。进一步扩展H-DQN后，其最高得分达到41.828K并生成4096方块。这些结果表明，分布多步目标显著提升了稀疏奖励领域的性能，并为通过基于模型的规划和课程学习实现进一步增益提供了可能。

</details>


### [268] [Epistemically-guided forward-backward exploration](https://arxiv.org/abs/2507.05477)
**中文标题：基于认知引导的前向-后向探索**

*Núria Armengol Urpí,Marin Vlastelica,Georg Martius,Stelian Coros*

主要分类: cs.LG

摘要简述: 本文提出了一种基于前向-后向表示（FB）的探索策略，通过最小化FB表示的后验方差来减少其认知不确定性，从而显著提升零样本强化学习的样本效率。


<details>
  <summary>详细信息</summary>
研究动机: 零样本强化学习在缺乏具体奖励的情况下需要快速适应未来问题设置，而现有的前向-后向表示（FB）方法通常依赖其他探索算法收集数据。本文认为FB表示应直接用于探索，以提高学习效率。

研究方法: 设计了一种基于FB表示的探索策略，通过最小化FB表示的后验方差来减少认知不确定性，从而优化探索过程。

研究结果: 实验表明，这种基于原则的探索策略显著提升了FB算法的样本效率，优于其他探索方法。

研究结论: FB表示应直接用于探索，以减少认知不确定性并提升学习效率，为未来的零样本强化学习研究提供了新方向。

中文摘要: 零样本强化学习在缺乏具体奖励的情况下，需要快速适应未来问题设置以提取最优策略。前向-后向表示（FB）作为一种有前景的方法，通过分解策略占用度量，能够在无奖励情况下学习最优策略。然而，迄今为止，FB及许多类似的零样本强化学习算法与探索问题脱节，通常依赖其他探索算法进行数据收集。我们认为FB表示应从根本上用于探索，以提高学习效率。基于这一目标，我们设计了从FB表示中自然衍生的探索策略，通过最小化FB表示的后验方差来减少其认知不确定性。实验表明，这种基于原则的探索策略显著提升了FB算法的样本效率，优于其他探索方法。代码公开于https://sites.google.com/view/fbee-url。

</details>


### [269] [Explainable Hierarchical Deep Learning Neural Networks (Ex-HiDeNN)](https://arxiv.org/abs/2507.05498)
**中文标题：可解释分层深度学习神经网络（Ex-HiDeNN）**

*Reza T. Batley,Chanwook Park,Wing Kam Liu,Sourav Saha*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Ex-HiDeNN的新型可解释分层深度学习神经网络方法，通过符号回归从有限数据中发现封闭表达式，并在多个基准问题和工程应用中表现出卓越的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 数据驱动科学和计算在构建复杂函数关系方面取得了巨大进展，但从复杂数据中发现可解释且准确的封闭表达式仍是一个挑战。本文旨在解决这一问题。

研究方法: Ex-HiDeNN采用了一种准确、高效、可分离且可扩展的神经网络架构，结合符号回归技术，并嵌入可分离性检查器，通过两步算法从数据中发现封闭表达式。

研究结果: Ex-HiDeNN在多个基准问题和工程应用中表现出色，误差比传统符号回归方法小几个数量级，并在疲劳方程、硬度识别和屈服面表达式发现等应用中优于现有方法。

研究结论: Ex-HiDeNN是一种高效且可解释的方法，能够从有限数据中发现封闭表达式，但其仍有局限性，未来可进一步扩展和改进。

中文摘要: 数据驱动科学和计算在利用可训练参数构建复杂函数关系方面取得了巨大进展。然而，从复杂数据中高效地发现可解释且准确的封闭表达式仍是一个挑战。本文提出了一种名为可解释分层深度学习神经网络（Ex-HiDeNN）的新方法，该方法采用了一种准确、高效、可分离且可扩展的神经网络架构，结合符号回归技术，从有限观测数据中发现封闭表达式。文章介绍了嵌入可分离性检查器的两步Ex-HiDeNN算法。Ex-HiDeNN的准确性和效率在多个基准问题中进行了测试，包括从数据中识别动态系统，并报告了结果。在这些基准测试中，Ex-HiDeNN通常表现出卓越的近似能力，其误差比参考数据和传统符号回归方法小几个数量级。随后，Ex-HiDeNN被应用于三个工程应用：a）发现疲劳方程的封闭表达式，b）从微压痕测试数据中识别硬度，c）从数据中发现屈服面的表达式。在每种情况下，Ex-HiDeNN均优于文献中使用的参考方法。该方法基于作者在分层深度学习神经网络（HiDeNN）和卷积HiDeNN方面的研究成果。文章还清晰地阐述了Ex-HiDeNN的当前局限性和未来扩展方向。

</details>


### [270] [Concept-Based Mechanistic Interpretability Using Structured Knowledge Graphs](https://arxiv.org/abs/2507.05810)
**中文标题：基于概念的结构化知识图谱机制可解释性研究**

*Sofiia Chorna,Kateryna Tarelkina,Eloïse Berthier,Gianni Franchi*

主要分类: cs.LG

摘要简述: 本文提出了一种基于概念的机制可解释性框架，通过结构化知识图谱分析模型行为，揭示语义概念在模型内部的传播与交互，并开发了可视化工具BAGEL，用于全局解释模型决策。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于概念的可解释性方法仅关注局部解释，无法全面分析模型行为。本文旨在扩展这些方法，通过全局视角揭示模型内部语义概念的传播与交互，以增强模型的可信度和理解深度。

研究方法: 提出了一种模型无关的框架，通过分析高层语义概念（概念）在模型各层的表示与传播，系统量化其交互关系。开发了可视化工具BAGEL，以结构化知识图谱形式展示概念与类别的关系，帮助用户识别虚假相关性。

研究结果: 框架成功揭示了模型内部的潜在电路和信息流，展示了概念在不同层的传播路径。BAGEL工具提供了直观的可视化界面，支持用户探索概念关系并增强模型可信度。

研究结论: 该框架为深度学习模型的机制可解释性提供了新视角，尤其在处理数据集偏差时，有助于理解模型的泛化能力。BAGEL工具为模型分析和调试提供了实用支持。

中文摘要: 传统基于概念的可解释性方法主要关注神经网络预测的局部解释，而本文提出了一种新颖的框架和交互工具，将这些方法扩展到机制可解释性领域。我们的方法通过分析高层语义属性（称为概念）在模型内部组件的生成、交互和传播，实现了对模型行为的全局剖析。与以往孤立分析单个神经元或预测的工作不同，我们的框架系统量化了语义概念在各层的表示，揭示了模型决策背后的潜在电路和信息流。关键创新是我们的可视化平台BAGEL（用于全局解释层的偏差分析图），它以结构化知识图谱形式呈现这些发现，支持用户探索概念与类别的关系、识别虚假相关性，并提升模型可信度。该框架具有模型无关性和可扩展性，有助于深入理解深度学习模型在数据集偏差下的泛化能力（或失败原因）。演示地址：https://knowledge-graph-ui-4a7cb5.gitlab.io/。

</details>


### [271] [Fair Domain Generalization: An Information-Theoretic View](https://arxiv.org/abs/2507.05823)
**中文标题：公平领域泛化：信息论视角**

*Tangzheng Lian,Guanyu Hu,Dimitrios Kollias,Xinyu Yang,Oya Celiktutan*

主要分类: cs.LG

摘要简述: 本文提出了一种公平领域泛化（FairDG）问题，旨在在未见目标域中同时最小化预期风险和公平性违规。通过信息论视角推导了新的互信息上界，并提出了PAFDG框架，实现了实用性与公平性的帕累托优化。


<details>
  <summary>详细信息</summary>
研究动机: 领域泛化（DG）和算法公平性是机器学习的两个关键挑战。现有DG方法通常忽略公平性，而公平性方法未考虑领域偏移。本文旨在填补这一空白，研究如何在未见域中同时优化预期风险和公平性。

研究方法: 本文从信息论角度推导了多类分类任务中预期风险和公平性违规的互信息上界，并提出了PAFDG框架，通过帕累托优化建模实用性与公平性的权衡。

研究结果: 在真实视觉和语言数据集上的实验表明，PAFDG在实用性与公平性的权衡上优于现有方法。

研究结论: 本文通过信息论视角和PAFDG框架，成功解决了公平领域泛化问题，为实用性与公平性的平衡提供了有效方法。

中文摘要: 领域泛化（DG）和算法公平性是机器学习的两个关键挑战。然而，大多数DG方法仅关注最小化未见目标域的预期风险，而未考虑算法公平性。反之，公平性方法通常未考虑领域偏移，因此训练中实现的公平性可能无法泛化到未见测试域。本文通过研究公平领域泛化（FairDG）问题填补了这一空白，旨在在未见目标域中同时最小化预期风险和公平性违规。我们推导了多类分类任务中基于互信息的预期风险和公平性违规的新上界，为算法设计提供了信息论视角的关键见解。基于这些见解，我们提出了PAFDG（帕累托最优公平领域泛化），这是一个通过帕累托优化建模实用性与公平性权衡的实用框架。在真实视觉和语言数据集上的实验表明，PAFDG在实用性与公平性的权衡上优于现有方法。

</details>


### [272] [Mitigating Shortcut Learning with InterpoLated Learning](https://arxiv.org/abs/2507.05527)
**中文标题：通过插值学习缓解捷径学习**

*Michalis Korakakis,Andreas Vlachos,Adrian Weller*

主要分类: cs.LG

摘要简述: 论文提出了一种名为InterpoLated Learning（InterpoLL）的方法，通过插值多数类样本的表示以包含少数类样本的特征，从而减弱模型对捷径（虚假相关性）的依赖，提升在少数类样本上的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在缓解捷径学习（模型依赖虚假相关性）时存在模型特定性、调参困难、计算成本高且无法改进学习表示的问题。本文旨在提出一种通用且高效的方法来解决这些问题。

研究方法: InterpoLL通过插值多数类样本的表示，引入少数类样本的特征和缓解捷径的模式，从而削弱捷径的影响，使模型能够学习到适用于多数类和少数类样本的预测特征。

研究结果: 实验结果表明，InterpoLL在多个自然语言理解任务中显著提升了少数类样本的泛化能力，且不影响多数类样本的准确性。该方法适用于多种架构（编码器、编码器-解码器、仅解码器）。

研究结论: InterpoLL是一种通用且高效的捷径缓解方法，能够在不牺牲多数类样本性能的情况下显著提升少数类样本的泛化能力。

中文摘要: 经验风险最小化（ERM）会激励模型利用捷径，即输入属性与标签之间的虚假相关性，这些相关性在多数训练数据中普遍存在但与任务无关。这种依赖阻碍了在少数样本上的泛化能力，因为这些相关性在少数样本中不成立。现有的捷径缓解方法具有模型特定性、调参困难、计算成本高且无法改进学习表示的缺点。为解决这些问题，我们提出了插值学习（InterpoLL），通过插值多数样本的表示以包含具有缓解捷径模式的少数类样本特征。这种方法削弱了捷径的影响，使模型能够学习适用于少数和多数样本的预测特征。在多个自然语言理解任务上的实验结果表明，InterpoLL在少数样本上的泛化能力优于ERM和最先进的捷径缓解方法，且不影响多数样本的准确性。值得注意的是，这些优势在编码器、编码器-解码器和仅解码器架构中均得以保持，证明了该方法的广泛适用性。

</details>


### [273] [Robust Learning on Noisy Graphs via Latent Space Constraints with External Knowledge](https://arxiv.org/abs/2507.05540)
**中文标题：通过潜在空间约束与外部知识实现噪声图上的鲁棒学习**

*Chunhui Gu,Mohammad Sadegh Nasr,James P. Long,Kim-Anh Do,Ehsan Irajizad*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LSC-GNN的新方法，通过引入外部干净链接和潜在空间约束，有效解决了图神经网络（GNNs）在噪声边上的性能问题，并在实验中验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 图神经网络（GNNs）在处理包含噪声边的图数据时性能下降，因此需要一种能够利用外部干净链接来提升模型鲁棒性的方法。

研究方法: 提出LSC-GNN方法，通过训练两个编码器：一个在全图上（包含目标图和外部边），另一个在正则化图上（排除目标图的噪声边），并通过惩罚潜在表示差异来避免过拟合噪声边。

研究结果: 实验表明，LSC-GNN在中等噪声的基准数据集上优于标准和抗噪声GNNs，并在异构图（如蛋白质-代谢物网络）中进一步验证了其有效性。

研究结论: LSC-GNN能够显著提升噪声图数据中的预测性能和可解释性，为处理噪声关系结构提供了新思路。

中文摘要: 图神经网络（GNNs）在处理噪声边时表现不佳。我们提出了潜在空间约束图神经网络（LSC-GNN），通过引入外部“干净”链接来引导噪声目标图的嵌入。我们训练两个编码器：一个在全图上（目标图加外部边），另一个在正则化图上（排除目标图的潜在噪声边），并通过惩罚其潜在表示差异来避免过拟合噪声边。这种约束使模型远离对虚假边的过拟合。基准数据集的实验表明，LSC-GNN在中等噪声图中优于标准和抗噪声GNNs。我们将LSC-GNN扩展到异构图，并在一个小型蛋白质-代谢物网络上验证了其有效性，其中代谢物-蛋白质相互作用减少了蛋白质共现数据中的噪声。我们的结果突出了LSC-GNN在噪声关系结构设置中提升预测性能和可解释性的潜力。

</details>


### [274] [The Fourier Spectral Transformer Networks For Efficient and Generalizable Nonlinear PDEs Prediction](https://arxiv.org/abs/2507.05584)
**中文标题：傅里叶谱变换网络：高效且可推广的非线性偏微分方程预测**

*Beibei Li*

主要分类: cs.LG

摘要简述: 本文提出了一种统一的傅里叶谱变换网络，结合经典谱方法和注意力神经架构的优势，用于高效且可推广的非线性偏微分方程预测。


<details>
  <summary>详细信息</summary>
研究动机: 传统数值方法和机器学习方法在预测复杂动态系统时存在精度和泛化性不足的问题。本文旨在通过结合谱方法和Transformer网络，提高预测的准确性和泛化能力。

研究方法: 将原始偏微分方程转换为谱常微分方程，利用高精度数值求解器生成训练数据，并通过Transformer网络建模谱系数的演化。

研究结果: 在二维不可压缩Navier-Stokes方程和一维Burgers方程上验证了方法的有效性，结果显示其预测精度优于传统数值方法和机器学习方法，且泛化能力强。

研究结论: 提出的谱Transformer框架为复杂动态系统的实时预测和控制提供了新范式，具有高效性和泛化性优势。

中文摘要: 本文提出了一种统一的傅里叶谱变换网络，结合了经典谱方法和基于注意力的神经架构的优势。通过将原始偏微分方程转换为谱常微分方程，我们使用高精度数值求解器生成训练数据，并利用Transformer网络建模谱系数的演化。我们在二维不可压缩Navier-Stokes方程和一维Burgers方程上验证了方法的有效性。结果表明，即使在训练数据有限的情况下，我们的谱Transformer也能实现高精度的长期预测，优于传统数值方法和机器学习方法在预测未来流动动力学方面的表现。所提出的框架对未见数据具有很好的泛化能力，为复杂动态系统的实时预测和控制提供了有前景的范式。

</details>


### [275] [Graph Learning](https://arxiv.org/abs/2507.05636)
**中文标题：图学习**

*Feng Xia,Ciyuan Peng,Jing Ren,Falih Gozi Febrinanto,Renqiang Luo,Vidya Saikrishna,Shuo Yu,Xiangjie Kong*

主要分类: cs.LG

摘要简述: 图学习已成为机器学习和人工智能的关键子领域，涵盖图神经网络、动态建模、多模态学习等方向，广泛应用于药物发现、欺诈检测等领域，但仍面临可扩展性、可解释性等挑战。


<details>
  <summary>详细信息</summary>
研究动机: 图学习因其能够建模复杂的非欧几里得关系而备受关注，但其在可扩展性、泛化性、可解释性等方面的挑战限制了其潜力。本文旨在全面介绍图学习的最新进展，为研究者和从业者提供指导。

研究方法: 本文综述了图学习的关键维度，包括可扩展图学习、时序图学习、多模态图学习、生成图学习、可解释图学习及负责任图学习，并回顾了相关的最新技术。

研究结果: 文章总结了图学习在高效处理大规模图、捕捉动态时序依赖、整合异构数据模态等方面的前沿技术，并探讨了隐私和公平性等伦理问题。

研究结论: 图学习在多个领域展现出巨大潜力，但仍需解决可扩展性、可解释性等挑战。未来研究方向包括与其他AI范式的结合及伦理问题的进一步探索。

中文摘要: 图学习已迅速发展为机器学习和人工智能（AI）的关键子领域。其发展始于早期的图论方法，并随着图神经网络（GNNs）的出现而获得显著动力。过去十年中，可扩展架构、动态图建模、多模态学习、生成式AI、可解释AI（XAI）和负责任AI的进展，使图学习能够广泛应用于药物发现、欺诈检测、推荐系统和科学推理等复杂场景。图学习的重要性在于其能够建模传统机器学习难以捕捉的非欧几里得关系。然而，要充分发挥其潜力，仍需解决可扩展性、泛化性、异构性、可解释性和可信性等挑战。本综述全面介绍了图学习，重点关注可扩展、时序、多模态、生成式、可解释和负责任图学习等关键维度。我们回顾了高效处理大规模图、捕捉动态时序依赖、整合异构数据模态、生成新图样本及提升可解释性以增强信任和透明度的最新技术。同时，探讨了隐私和公平性等伦理问题，以确保图学习模型的责任部署。此外，我们还识别并讨论了新兴主题，强调了图学习与其他AI范式的近期融合，并展望了未来方向。本综述为研究者和从业者提供了宝贵的资源，帮助其了解图学习的快速发展。

</details>


### [276] [FACT: the Features At Convergence Theorem for neural networks](https://arxiv.org/abs/2507.05644)
**中文标题：FACT：神经网络的收敛特征定理**

*Enric Boix-Adsera,Neil Mallinar,James B. Simon,Mikhail Belkin*

主要分类: cs.LG

摘要简述: 论文提出了“收敛特征定理”（FACT），揭示了神经网络在非零权重衰减训练下收敛时权重的自洽方程，并通过实验验证了其有效性。进一步基于FACT改进了一种新算法FACT-RFM，在表格数据上表现优异，并能捕捉神经网络训练中的特征学习行为。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习理论中的一个核心挑战是理解神经网络如何学习和表示特征。为了解决这一问题，论文旨在通过数学定理揭示神经网络权重在收敛时的自洽关系，从而为特征学习提供理论支持。

研究方法: 论文证明了“收敛特征定理”（FACT），该定理描述了神经网络在非零权重衰减训练下收敛时权重的自洽方程。通过实验验证了特征矩阵满足FACT关系，并基于此改进了“递归特征机”（RFM），提出新算法FACT-RFM。

研究结果: 实验表明，神经网络的特征确实满足FACT定理。FACT-RFM算法在表格数据上表现优异，并能模拟神经网络训练中的特征学习行为，如模块算术中的“顿悟”和稀疏奇偶性学习的相变。

研究结论: FACT定理为理解神经网络的特征学习提供了理论框架，而FACT-RFM算法展示了其在实践中的潜力，能够捕捉复杂的特征学习动态。

中文摘要: 深度学习理论中的一个核心挑战是理解神经网络如何学习和表示特征。为此，我们证明了“收敛特征定理”（FACT），该定理给出了在非零权重衰减训练下神经网络权重在收敛时满足的自洽方程。对于每个权重矩阵$W$，该方程将“特征矩阵”$W^\top W$与前向传播中输入的向量集和反向传播中传递的损失梯度联系起来。我们通过实验验证了这一关系，表明神经网络特征确实满足FACT定理。此外，通过改进Radhakrishnan等人2024年提出的“递归特征机”（RFM），使其符合FACT定理，我们得到了一种新的学习算法FACT-RFM。FACT-RFM在表格数据上表现优异，并能捕捉神经网络训练中的各种特征学习行为，包括模块算术中的“顿悟”和稀疏奇偶性学习中的相变。

</details>


### [277] [Efficient Training of Large-Scale AI Models Through Federated Mixture-of-Experts: A System-Level Approach](https://arxiv.org/abs/2507.05685)
**中文标题：通过联邦专家混合模型的系统级方法高效训练大规模AI模型**

*Xiaobing Chen,Boyang Zhang,Xiangwei Zhou,Mingxuan Sun,Shuai Zhang,Songyang Zhang,Geoffrey Ye Li*

主要分类: cs.LG

摘要简述: 通过联邦学习与专家混合模型的结合，提出了一种系统级方法，以高效训练大规模AI模型，同时解决客户端资源异构和专家协调问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前联邦学习中专家混合模型的大规模训练面临系统级挑战，特别是客户端资源异构与专家协调的复杂性，亟需动态客户端-专家对齐策略。

研究方法: 提出了一种智能客户端-专家对齐的系统设计，包括动态适应评分、全局专家负载监控和客户端能力分析，以优化训练效率和通信成本。

研究结果: 该方法能够实现更高效、可扩展且鲁棒的训练机制，减少通信轮次，为边缘计算中的大规模联邦专家混合模型部署铺平道路。

研究结论: 通过解决系统级问题，本研究为大规模联邦专家混合模型的广泛应用提供了高效、可扩展的解决方案。

中文摘要: 联邦学习（FL）与专家混合模型（MoE）的结合为在分散数据上训练更强大的大规模人工智能模型（LAMs）提供了一条有前景的路径，同时保护了隐私。然而，这些复杂MoE结构的LAMs的高效联邦训练受到显著的系统级挑战阻碍，特别是在管理异构客户端资源与众多专业专家所需的复杂协调之间的相互作用方面。本文强调了一个关键但尚未充分探索的概念：缺乏动态客户端-专家对齐的稳健定量策略，该策略需全面考虑客户端能力的差异和系统级负载平衡的需求。具体而言，我们提出了一种智能客户端-专家对齐的概念系统设计，包括动态适应评分、全局专家负载监控和客户端能力分析。通过解决这些系统性问题，我们可以解锁更可扩展、高效且鲁棒的训练机制（收敛所需的通信轮次更少），为在边缘计算中广泛部署大规模联邦MoE结构的LAMs铺平道路，并实现超高通信效率。

</details>


### [278] [Universal Embeddings of Tabular Data](https://arxiv.org/abs/2507.05904)
**中文标题：表格数据的通用嵌入表示**

*Astrid Franz,Frederik Hoppe,Marianne Michaelis,Udo Göbel*

主要分类: cs.LG

摘要简述: 本文提出了一种新颖的框架，用于生成表格数据的通用嵌入表示，无需预定义任务即可支持下游任务。通过将表格数据转化为图结构，并利用图自动编码器生成实体嵌入，最终聚合为每行数据的嵌入表示。实验表明，该方法优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 工业数据库中表格数据占比重大，但其分析任务多样且常未预先定义。现有方法难以适应未知任务，因此需要一种通用的嵌入表示方法。

研究方法: 将表格数据转化为图结构，使用图自动编码器生成实体嵌入，再聚合为每行数据的嵌入表示。支持对未见样本的直接嵌入和下游任务（如回归、分类、异常检测）。

研究结果: 实验证明，该方法在真实数据集上表现优于现有通用表格数据嵌入技术。

研究结论: 提出的框架能够生成任务无关的表格数据嵌入，支持多种下游任务，且性能优越。

中文摘要: 关系数据库中的表格数据在工业数据中占重要比例，因此分析和解释表格数据至关重要。表格数据的应用任务多样，且通常在建立工业数据库时未明确指定。为此，我们提出了一种新颖的框架，用于生成通用的（即任务无关的）表格数据嵌入，以支持无需预定义目标的下游任务。我们的方法将表格数据转化为图结构，利用图自动编码器生成实体嵌入，随后聚合为每行数据（即每个样本）的嵌入表示。这种两步法具有优势，即由相似实体组成的未见样本无需额外训练即可嵌入。下游任务（如回归、分类或异常检测）可通过在嵌入空间中应用基于距离的相似性度量来完成。真实数据集的实验表明，我们的方法在性能上优于现有的通用表格数据嵌入技术。

</details>


### [279] [Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why](https://arxiv.org/abs/2507.05906)
**中文标题：基于特征与基于GAN的演示学习：何时及为何**

*Chenhao Li,Marco Hutter,Andreas Krause*

主要分类: cs.LG

摘要简述: 本文比较了基于特征和基于GAN的演示学习方法，分析了两者在奖励函数结构和策略学习中的优劣，并指出选择方法应根据任务需求（如保真度、多样性等）。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于比较基于特征和基于GAN的演示学习方法，探讨它们在奖励函数设计、策略学习效果及适用场景上的差异，为方法选择提供理论依据。

研究方法: 方法包括对基于特征和基于GAN的演示学习进行对比分析，重点关注奖励函数的结构及其对策略学习的影响，并结合最新进展提出结构化运动表示的重要性。

研究结果: 结果显示，基于特征的方法提供密集且可解释的奖励，适合高保真运动模仿，但泛化能力有限；基于GAN的方法具有灵活性和可扩展性，但训练不稳定且奖励信号粗糙。

研究结论: 结论指出，两种方法的优劣取决于任务需求，未来研究应关注结构化运动表示以提升过渡平滑性、可控合成和任务整合能力。

中文摘要: 本综述对比分析了基于特征和基于GAN的演示学习方法，重点关注奖励函数的结构及其对策略学习的影响。基于特征的方法提供密集且可解释的奖励，擅长高保真运动模仿，但对参考表示要求高且在非结构化环境中泛化能力不足。基于GAN的方法通过隐式分布监督实现可扩展性和适应性，但存在训练不稳定和奖励信号粗糙的问题。两种方法的最新进展均强调结构化运动表示的重要性，以实现平滑过渡、可控合成和任务整合。我们认为两种方法的差异日益微妙，选择应基于任务优先级（如保真度、多样性等）。本文总结了算法权衡和设计考量，为演示学习中的方法选择提供了理论框架。

</details>


### [280] [Simple Convergence Proof of Adam From a Sign-like Descent Perspective](https://arxiv.org/abs/2507.05966)
**中文标题：从符号式下降视角看Adam的简单收敛性证明**

*Hanyang Peng,Shuang Qin,Yue Yu,Fangqing Jiang,Hui Wang,Zhouchen Lin*

主要分类: cs.LG

摘要简述: 本文提出了一种新的视角，将Adam优化器视为一种符号式优化器，简化了其收敛性分析，并首次证明了在温和条件下Adam可以达到最优收敛速率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管Adam在深度神经网络训练中表现出色，但其理论收敛性分析仍不完善。现有研究通常将其视为带有动量的预条件随机梯度下降（SGDM），导致分析复杂且假设过强。本文旨在通过新的视角简化分析并填补理论与实践的差距。

研究方法: 作者将Adam重新表述为符号式优化器，形式为$x_{t+1} = x_t - \gamma_t \frac{|m_t|}{{\sqrt{v_t}+\epsilon}} \circ {\rm Sign}(m_t)$。这种方法避免了复杂的预条件矩阵分析，简化了收敛性证明。

研究结果: 在广义$p$-仿射方差和$(L_0, L_1, q)$-平滑性的弱假设下，首次证明了Adam可以达到${\cal O}(\frac{1}{T^{\sfrac{1}{4}}})$的最优收敛速率，优于之前的${\cal O} \left(\frac{\ln T}{T^{\sfrac{1}{4}}}\right)$。

研究结论: 本文通过符号式优化器视角简化了Adam的收敛性分析，证明了其最优收敛速率，并揭示了动量在确保收敛中的关键作用，为学习率调优提供了实用指导。

中文摘要: Adam被广泛认为是训练深度神经网络（DNNs）最有效的优化器之一。尽管其经验表现卓越，但其理论收敛性分析仍不尽如人意。现有研究主要将Adam解释为带有动量的预条件随机梯度下降（SGDM），形式为$\bm{x}_{t+1} = \bm{x}_t - \frac{\gamma_t}{{\sqrt{\bm{v}_t}+\epsilon}} \circ \bm{m}_t$。这种视角需要强假设和复杂技术，导致冗长且晦涩的收敛性证明，难以验证和扩展。相比之下，我们提出了一种新解释，将Adam视为符号式优化器，形式为$\bm{x}_{t+1} = \bm{x}_t - \gamma_t \frac{|\bm{m}_t|}{{\sqrt{\bm{v}_t}+\epsilon}} \circ {\rm Sign}(\bm{m}_t)$。这种重新表述显著简化了收敛性分析。首次在广义$p$-仿射方差和$(L_0, L_1, q)$-平滑性的温和条件下，证明了Adam可以达到${\cal O}(\frac{1}{T^{\sfrac{1}{4}}})$的最优收敛速率，而非之前的${\cal O} \left(\frac{\ln T}{T^{\sfrac{1}{4}}}\right)$，且不依赖于模型维度或数值稳定性参数$\epsilon$。此外，我们的理论分析揭示了动量作为确保收敛的关键因素，并为Adam的学习率调优提供了实用指南，进一步缩小了理论与实践的差距。

</details>


### [281] [QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models](https://arxiv.org/abs/2507.06079)
**中文标题：QS4D：面向结构化状态空间序列模型高效硬件部署的量化感知训练**

*Sebastian Siegel,Ming-Jay Yang,Younes Bouhadjar,Maxime Fabre,Emre Neftci,John Paul Strachan*

主要分类: cs.LG

摘要简述: 本文提出了一种量化感知训练方法（QAT），用于优化结构化状态空间模型（SSM）在边缘计算硬件上的部署效率，显著降低了模型复杂度并提升了抗噪能力。


<details>
  <summary>详细信息</summary>
研究动机: 结构化状态空间模型（SSM）因其在处理长序列时的恒定内存需求而备受关注，但其在资源受限的边缘设备上的部署仍面临挑战。本文旨在通过量化感知训练（QAT）优化SSM，以适应如模拟内存计算（AIMC）芯片等专用硬件。

研究方法: 研究采用量化感知训练（QAT）技术，分析模型大小与数值精度的关系，并探索其对模拟噪声的鲁棒性和结构化剪枝的促进作用。最终将优化后的SSM部署到忆阻器模拟内存计算平台上。

研究结果: 实验表明，QAT能将SSM的复杂度降低两个数量级，同时增强模型对模拟噪声的鲁棒性，并支持结构化剪枝，显著提升了计算效率。

研究结论: 通过量化感知训练，SSM在边缘计算硬件上的部署效率得到显著提升，为资源受限设备的应用提供了可行方案。

中文摘要: 结构化状态空间模型（SSM）是近年来兴起的一类深度学习模型，特别适合处理长序列。与内存需求线性增长的Transformer相比，其恒定内存占用使其成为资源受限边缘计算设备的理想选择。虽然已有研究探索了量化感知训练（QAT）对SSM的影响，但通常未涉及其对专用边缘硬件（如模拟内存计算芯片）的适用性。本文证明，QAT可将SSM的复杂度降低多达两个数量级。我们分析了模型大小与数值精度的关系，并表明QAT能增强对模拟噪声的鲁棒性并支持结构化剪枝。最后，我们将这些技术整合，将SSM部署到忆阻器模拟内存计算平台上，并展示了其在计算效率方面的显著优势。

</details>


### [282] [Subspace-based Approximate Hessian Method for Zeroth-Order Optimization](https://arxiv.org/abs/2507.06125)
**中文标题：基于子空间的近似Hessian零阶优化方法**

*Dongyoon Kim,Sungjae Lee,Wonjin Lee,Kwang In Kim*

主要分类: cs.LG

摘要简述: 本文提出了一种基于子空间的近似Hessian方法（ZO-SAH），用于零阶优化，通过随机选择二维子空间并拟合二次多项式来估计Hessian矩阵，显著降低了计算成本，并在实验中表现出比现有方法更快的收敛速度。


<details>
  <summary>详细信息</summary>
研究动机: 零阶优化在梯度信息不可用或计算不切实际时非常重要。虽然现有方法多依赖一阶近似，但引入二阶（曲率）信息可以显著加速收敛。然而，估计Hessian矩阵的高计算成本限制了其实际应用。本文旨在解决这一问题。

研究方法: ZO-SAH方法通过随机选择二维子空间，在每个子空间中拟合二次多项式以估计Hessian矩阵，并采用周期性子空间切换策略以复用函数评估，从而降低计算成本。

研究结果: 在八个基准数据集（包括逻辑回归和深度神经网络训练任务）上的实验表明，ZO-SAH比现有零阶优化方法收敛速度显著更快。

研究结论: ZO-SAH通过子空间近似Hessian和周期性切换策略，有效降低了零阶优化的计算成本，同时显著提升了收敛速度，具有实际应用潜力。

中文摘要: 零阶优化用于解决梯度信息不可用或计算不切实际的问题。尽管现有方法多依赖一阶近似，但引入二阶（曲率）信息可以显著加速收敛。然而，估计Hessian矩阵的高计算成本限制了其实际应用。本文提出基于子空间的近似Hessian（ZO-SAH）方法，通过随机选择二维子空间并拟合二次多项式来估计Hessian矩阵，从而降低计算成本。此外，ZO-SAH采用周期性子空间切换策略，复用函数评估以进一步减少计算开销。在八个基准数据集（包括逻辑回归和深度神经网络训练任务）上的实验表明，ZO-SAH比现有零阶优化方法收敛速度显著更快。

</details>


### [283] [Topic Modeling and Link-Prediction for Material Property Discovery](https://arxiv.org/abs/2507.06139)
**中文标题：基于主题建模与链接预测的材料特性发现**

*Ryan C. Barron,Maksim E. Eren,Valentin Stanev,Cynthia Matuszek,Boian S. Alexandrov*

主要分类: cs.LG

摘要简述: 本文提出了一种基于层次化链接预测的AI框架，用于发现复杂材料领域中的隐藏关联。通过结合多种矩阵分解方法，构建了一个三级主题树，并成功预测了材料与主题之间的缺失或弱连接，为跨学科探索提供了新假设。


<details>
  <summary>详细信息</summary>
研究动机: 科学文献网络和知识图谱通常规模大、稀疏且噪声多，常存在实体间缺失链接的问题。本文旨在通过AI驱动的层次化链接预测框架，发现复杂材料领域中的隐藏关联，推动跨学科研究。

研究方法: 方法结合了层次化非负矩阵分解（HNMFk）、布尔矩阵分解（BNMFk）和逻辑矩阵分解（LMF），并采用自动模型选择。通过构建三级主题树，分析46,862篇关于73种过渡金属二硫属化物（TMDs）的文献，预测材料与主题之间的隐藏链接。

研究结果: 结果显示，HNMFk将材料聚类到超导性、能量存储和摩擦学等主题中，并成功预测了缺失或弱连接的链接。验证实验表明，模型能准确预测超导TMD材料的关联，证明了方法的有效性。

研究结论: 本文提出的方法能够从科学文献中挖掘材料与潜在主题之间的隐藏关联，尤其适用于分析来自不同领域和视角的文献。通过交互式仪表盘，为人类参与的科学研究提供了新工具。

中文摘要: 链接预测基于连接模式推断图中节点间缺失或未来的关系。科学文献网络和知识图谱通常规模大、稀疏且噪声多，常存在实体间缺失链接的问题。我们提出了一种AI驱动的层次化链接预测框架，结合矩阵分解技术推断隐藏关联，推动复杂材料领域的发现。该方法整合了层次化非负矩阵分解（HNMFk）、布尔矩阵分解（BNMFk）和逻辑矩阵分解（LMF），并采用自动模型选择，构建了一个基于46,862篇文献的三级主题树，这些文献聚焦于73种过渡金属二硫属化物（TMDs）。这些材料在多个物理领域中被研究，具有广泛的应用潜力。

通过BNMFk + LMF的集成方法，结合离散可解释性与概率评分，生成的HNMFk聚类将每种材料映射到超导性、能量存储和摩擦学等主题。此外，还突出了主题与材料之间缺失或弱连接的链接，为跨学科探索提供了新假设。我们通过移除已知超导材料中关于超导性的文献验证了该方法，结果显示模型能准确预测超导TMD材料的关联。这表明该方法能够从科学文献构建的材料与潜在主题关联图中发现隐藏连接，尤其适用于分析来自不同领域和视角的文献。通过交互式Streamlit仪表盘，该方法生成的假设链接为人类参与的科学研究提供了新工具。

</details>


### [284] [A Method for Optimizing Connections in Differentiable Logic Gate Networks](https://arxiv.org/abs/2507.06173)
**中文标题：一种优化可微分逻辑门网络连接的方法**

*Wout Mommen,Lars Keuninckx,Matthias Hartmann,Piet Wambacq*

主要分类: cs.LG

摘要简述: 本文提出了一种优化可微分逻辑门网络连接的新方法，通过概率分布选择最优连接，显著减少逻辑门数量并提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决传统固定连接逻辑门网络的效率问题，探索如何通过优化连接提升网络性能，同时减少逻辑门数量。

研究方法: 采用概率分布对每个门输入的连接子集进行优化，选择最优连接后确定门类型，从而实现部分连接优化。

研究结果: 优化后的逻辑门网络在Yin-Yang、MNIST和Fashion-MNIST基准测试中表现优于固定连接网络，且仅需少量逻辑门即可达到高性能。例如，8000个简单逻辑门即可在MNIST数据集上实现超过98%的准确率。

研究结论: 该方法为完全可训练的布尔逻辑网络提供了可行路径，展示了在减少逻辑门数量的同时提升性能的潜力。

中文摘要: 我们提出了一种用于部分优化深度可微分逻辑门网络（LGNs）连接的新方法。我们的训练方法利用每个门输入连接子集的概率分布，选择最优连接后确定门类型。实验表明，优化连接的LGNs在Yin-Yang、MNIST和Fashion-MNIST基准测试中优于固定连接LGNs，且仅需少量逻辑门。例如，仅需8000个简单逻辑门即可在MNIST数据集上实现超过98%的准确率。此外，我们的网络在MNIST数据集上的表现优于标准全连接LGNs，同时逻辑门数量减少了24倍。因此，我们的工作为完全可训练的布尔逻辑网络提供了可行路径。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [285] [ECORE: Energy-Conscious Optimized Routing for Deep Learning Models at the Edge](https://arxiv.org/abs/2507.06011)
**中文标题：ECORE：面向边缘深度学习模型的能量感知优化路由**

*Daghash K. Alqahtani,Maria A. Rodriguez,Muhammad Aamir Cheema,Hamid Rezatofighi,Adel N. Toosi*

主要分类: cs.DC

摘要简述: ECORE是一个针对边缘计算中深度学习模型的能量感知优化路由框架，通过动态路由策略平衡能耗与检测精度，显著降低能耗和延迟。


<details>
  <summary>详细信息</summary>
研究动机: 边缘计算在实时视觉分析（如智能城市监控）中至关重要，但资源受限的边缘设备需要同时优化能耗和检测精度。ECORE旨在解决这一挑战。

研究方法: ECORE整合了基于估计的技术和贪心选择算法，动态选择最适合的边缘设备-模型对，根据对象特征平衡能效与检测性能。

研究结果: 实验表明，ECORE在真实数据集上比基准方法减少45%能耗和49%延迟，仅损失2%检测精度。

研究结论: ECORE通过上下文感知路由策略，有效优化边缘设备上的深度学习任务，显著提升能效与性能。

中文摘要: 边缘计算使数据处理更接近源头，显著降低了实时视觉分析（如监控和智能城市中的目标检测）的延迟。然而，这些任务对资源受限的边缘设备提出了巨大需求，使得能耗与检测精度的联合优化至关重要。为此，我们提出ECORE框架，整合多种动态路由策略（包括基于估计的技术和贪心选择算法），将图像处理请求定向到最适合的边缘设备-模型对。ECORE根据目标特征动态平衡能效与检测性能。我们通过在真实数据集上的广泛实验评估了该方法，并与广泛使用的基准技术进行了比较。评估采用了成熟的目标检测模型（YOLO、SSD、EfficientDet）和多样化的边缘平台（包括Jetson Orin Nano、Raspberry Pi 4和5以及TPU加速器）。结果表明，我们提出的上下文感知路由策略可将能耗和延迟分别降低45%和49%，同时仅比以精度为中心的方法损失2%的检测精度。

</details>


### [286] [Efficient Federated Learning with Timely Update Dissemination](https://arxiv.org/abs/2507.06031)
**中文标题：高效联邦学习与及时更新传播**

*Juncheng Jia,Ji Liu,Chao Huo,Yihui Shen,Yang Zhou,Huaiyu Dai,Dejing Dou*

主要分类: cs.DC

摘要简述: 本文提出了一种高效的联邦学习方法，利用额外的下行带宽资源确保及时更新传播，包括异步框架下的FedASMU和同步框架下的FedSSMU，显著提升了准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习（FL）在分布式数据管理中表现出色，但现有方法在更新传播的及时性上存在不足。本文旨在通过利用额外带宽资源，优化模型更新传播，提升FL的效率和准确性。

研究方法: 在异步框架下提出FedASMU，结合服务器端的动态模型聚合技术和设备端的自适应模型调整机制；在同步框架下扩展为FedSSMU。理论分析验证了方法的收敛性。

研究结果: 实验表明，FedASMU和FedSSMU在六个模型和五个公开数据集上显著优于基线方法，准确性最高提升145.87%，效率最高提升97.59%。

研究结论: 本文提出的方法通过优化更新传播机制，显著提升了联邦学习的准确性和效率，为分布式数据管理提供了新的解决方案。

中文摘要: 联邦学习（FL）已成为分布式数据管理的一种重要方法，近年来取得了显著进展。本文提出了一种高效的FL方法，利用额外的下行带宽资源确保及时更新传播。首先，我们在异步框架下实现了这一策略，提出了异步感知陈旧性的模型更新方法（FedASMU），该方法结合了服务器端和设备端的方法。在服务器端，我们提出了一种异步FL系统模型，采用动态模型聚合技术，将本地模型更新与全局模型协调，以提高准确性和效率。同时，在设备端，我们提出了一种自适应模型调整机制，将最新的全局模型与本地模型结合，进一步提升准确性。随后，我们将这一方法扩展到同步框架下，称为FedSSMU。理论分析验证了所提方法的收敛性。广泛的实验涵盖了六个模型和五个公开数据集，结果表明FedASMU和FedSSMU在准确性（最高提升145.87%）和效率（最高提升97.59%）上显著优于基线方法。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [287] [CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks](https://arxiv.org/abs/2507.05269)
**中文标题：CoRe：通过静态分析任务评估大语言模型的代码推理能力**

*Danning Xie,Mingwei Zheng,Xuwei Liu,Jiannan Wang,Chengpeng Wang,Lin Tan,Xiangyu Zhang*

主要分类: cs.SE

摘要简述: 本文提出了CoRe基准测试，用于评估大语言模型（LLMs）在代码静态分析任务中的语义推理能力，发现模型在深层语义理解和多步推理任务中表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试主要关注端到端结果（如代码修复或生成），而忽略了对模型程序语义推理能力的深入评估。本文旨在填补这一空白，设计了一个高质量的基准测试CoRe，以评估LLMs在静态分析任务中的表现。

研究方法: CoRe包含12,553个任务实例，涵盖C/C++、Java和Python程序中的数据依赖、控制依赖和信息流。通过语义感知的多样化采样策略，确保任务的语义多样性和推理复杂性。评估了10种主流LLMs的表现。

研究结果: 结果显示，LLMs在识别依赖关系方面表现良好，但在需要深层语义理解和多步推理的任务中仍存在困难。定性分析揭示了复杂控制结构和反向依赖模式等关键挑战。

研究结论: CoRe基准测试为评估和改进LLMs的代码推理能力提供了重要工具，揭示了当前模型的局限性，并为未来研究指明了方向。

中文摘要: 大语言模型（LLMs）已广泛应用于软件工程的多个领域，如代码生成、程序修复和漏洞检测。这些应用需要超越表面代码模式的理解能力，包括值传播、控制流和程序元素间的相互依赖。然而，现有基准测试主要评估端到端结果（如代码是否正确修复或生成），而忽略了模型对程序语义推理能力的深入探索。本文提出了CoRe，一个高质量、经过人工验证的基准测试，旨在评估LLMs在基础静态分析任务中的表现。CoRe包含12,553个任务实例，涵盖C/C++、Java和Python程序中的数据依赖、控制依赖和信息流。为确保语义多样性和推理复杂性，我们提出了一种语义感知的多样化采样策略，基于结构覆盖和依赖深度选择目标和任务实例。我们评估了10种主流LLMs，结果显示，尽管它们在识别依赖关系方面表现良好，但在需要深层语义理解和多步推理的任务中仍存在困难。进一步的定性分析揭示了关键挑战，如复杂控制结构和反向依赖模式，为改进LLMs的代码推理能力提供了见解。

</details>


### [288] [FuzzFeed: An Automatic Approach to Weakest Precondition Generation using LLMs and Fuzzing](https://arxiv.org/abs/2507.05272)
**中文标题：FuzzFeed：一种基于LLMs和模糊测试的最弱前置条件自动生成方法**

*Daragh King,Vasileios Koutavas,Laura Kovacs*

主要分类: cs.SE

摘要简述: 本文提出了一种结合大型语言模型（LLMs）和模糊测试的方法FuzzFeed，用于自动生成程序的最弱前置条件（WP），并通过模糊引导（FG）优化LLMs的输出。


<details>
  <summary>详细信息</summary>
研究动机: 生成程序的最弱前置条件（WP）在验证和运行时错误检查等领域具有重要应用。传统方法效率较低，因此本文探索利用LLMs和模糊测试的结合来高效生成WP。

研究方法: 提出FuzzFeed方法，结合LLMs和模糊测试生成WP。通过模糊引导（FG）利用程序执行反馈优化LLMs的输出，模糊测试用于验证候选WP的有效性和弱性。

研究结果: 在Java确定性数组程序基准测试中，实验表明LLMs能够生成可行的候选WP，且通过FG可显著提升其生成能力。

研究结论: FuzzFeed方法通过LLMs和模糊测试的结合，有效生成和优化WP，为程序验证提供了新思路。

中文摘要: 程序的最弱前置条件（WP）描述了从所有终止执行中满足给定后置条件的最大初始状态集。WP生成在验证和运行时错误检查等领域具有重要应用。本文提出结合大型语言模型（LLMs）和模糊测试生成WP的方法。为实现这一目标，我们引入了模糊引导（FG），通过程序执行反馈指导LLMs生成正确的WP。FG利用模糊测试近似检查候选WP的有效性和弱性，并将此信息反馈给LLM以优化上下文。我们在Java确定性数组程序基准测试中验证了方法的有效性。实验表明，LLMs能够生成可行的候选WP，且通过FG可显著提升其生成能力。

</details>


### [289] [ReservoirChat: Interactive Documentation Enhanced with LLM and Knowledge Graph for ReservoirPy](https://arxiv.org/abs/2507.05279)
**中文标题：ReservoirChat：基于LLM和知识图谱的交互式文档增强工具，用于ReservoirPy**

*Virgile Boraud,Yannis Bendi-Ouis,Paul Bernard,Xavier Hinaut*

主要分类: cs.SE

摘要简述: 本文介绍了一种结合检索增强生成（RAG）和知识图谱的工具ReservoirChat，旨在提升大型语言模型（LLM）在ReservoirPy库代码开发和储层计算领域问题解答中的能力，减少幻觉并提高回答的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在代码开发和专业领域问题解答中存在幻觉和事实准确性不足的问题，尤其是在ReservoirPy库和储层计算领域。本文旨在通过结合外部知识和知识图谱，提升模型的性能和用户体验。

研究方法: 通过检索增强生成（RAG）和知识图谱引入外部知识，设计了一个类似ChatGPT的交互式工具ReservoirChat，专注于ReservoirPy库的代码编写、调试和理解，并提供领域内可靠的见解。

研究结果: 评估显示，尽管专有模型如ChatGPT-4o和NotebookLM在通用知识问题上表现略优，但ReservoirChat在编码任务上表现更佳，并显著优于其基础模型Codestral-22B。

研究结论: ReservoirChat通过结合RAG和知识图谱，有效提升了LLM在ReservoirPy库和储层计算领域的性能，为开发者提供了更准确和实用的交互体验。

中文摘要: 我们介绍了一种工具，旨在通过结合检索增强生成（RAG）和知识图谱，提升大型语言模型（LLM）在ReservoirPy库代码开发以及储层计算领域复杂问题解答中的能力。该方法旨在减少幻觉并提高生成回答的事实准确性。该系统提供了一个类似ChatGPT的交互式体验，专为ReservoirPy设计，使用户能够编写、调试和理解Python代码，同时获取可靠的领域内见解。在我们的评估中，尽管专有模型如ChatGPT-4o和NotebookLM在通用知识问题上表现略优，但我们的模型在编码任务上表现更佳，并显著优于其基础模型Codestral-22B。

</details>


### [290] [CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark](https://arxiv.org/abs/2507.05281)
**中文标题：CoreCodeBench：一种可配置的多场景仓库级基准测试工具**

*Lingyue Fu,Hao Guan,Bolun Zhang,Haowei Yuan,Yaoming Zhu,Jun Xu,Zongyu Wang,Lin Qiu,Xunliang Cai,Xuezhi Cao,Weiwen Liu,Weinan Zhang,Yong Yu*

主要分类: cs.SE

摘要简述: 本文提出了CoreCodeBench，一个可配置的多场景仓库级基准测试工具，用于评估大语言模型（LLMs）在真实工程场景中的代码处理能力。通过自动化流程生成多种类型的问题，并结合复合问题设计，提供了更全面的评估框架。实验对16种LLMs进行了多维性能分析。


<details>
  <summary>详细信息</summary>
研究动机: 现有仓库级基准测试主要关注单一场景（如代码生成或缺陷修复），无法全面反映真实软件工程的多样性和复杂性。此外，测试用例的定位可控性和可靠性存在问题。本文旨在解决这些局限性，提供一个更全面的评估工具。

研究方法: 提出CorePipe自动化流程，将代码仓库转换为全面的测试用例，并设计CoreCodeBench基准测试工具。通过生成三类原子问题（开发、缺陷修复和测试驱动开发）及其组合，灵活调整难度，模拟真实工程场景。

研究结果: 实验对16种LLMs进行了多场景测试，揭示了它们在工程环境中的不同能力，并提供了多维性能分析。CoreCodeBench为LLMs在真实工程项目的适用性提供了全面评估。

研究结论: CoreCodeBench是一个可配置的多场景仓库级基准测试工具，能够更全面地评估LLMs在工程环境中的表现。实验结果表明，不同LLMs在工程任务中能力差异显著，为未来研究提供了重要参考。

中文摘要: 随着大语言模型（LLMs）在代码处理能力上的日益复杂，评估其在工程级代码上的性能仍具挑战性。现有的仓库级基准测试主要关注单一场景（如代码生成或缺陷修复），未能充分反映真实软件或项目工程工作流程的多样性和复杂性。此外，这些基准测试在问题定位的可控性和生成测试用例的可靠性方面存在不足。为解决这些问题，我们提出了CorePipe，一个完全自动化的流程，将代码仓库转换为全面的测试用例，并介绍了CoreCodeBench，一种可配置的多场景仓库级基准测试工具。为模拟真实工程场景，CorePipe生成三类针对核心代码段的原子问题（开发、缺陷修复和测试驱动开发），并将这些原子问题进一步组合为三类复合问题，通过超参数调整灵活调整难度。CoreCodeBench提供了一个全面且广泛的仓库级基准测试工具，用于研究LLMs在真实工程项目中的适用性。对16种LLMs在多种场景下的实验揭示了它们的不同能力，并为LLMs在工程环境中的性能提供了多维分析。CorePipe的代码可在https://github.com/AGI-Eval-Official/CoreCodeBench获取，CoreCodeBench的数据可在https://huggingface.co/collections/tubehhh/corecodebench-68256d2faabf4b1610a08caa访问。

</details>


### [291] [ASSURE: Metamorphic Testing for AI-powered Browser Extensions](https://arxiv.org/abs/2507.05307)
**中文标题：ASSURE：面向AI驱动的浏览器扩展的变形测试**

*Xuanqi Gao,Juan Zhai,Shiqing Ma,Siyi Xie,Chao Shen*

主要分类: cs.SE

摘要简述: ASSURE是一种专为AI驱动的浏览器扩展设计的自动化测试框架，解决了传统测试方法无法应对的非确定性行为和复杂环境集成问题。通过模块化测试生成、自动化执行和可配置验证，ASSURE高效识别了531个问题，测试吞吐量提升6.4倍。


<details>
  <summary>详细信息</summary>
研究动机: AI驱动的浏览器扩展（如基于LLM的扩展）在功能上带来了革命性变化，但其非确定性行为和复杂环境集成使得传统测试方法失效。现有LLM测试方法也未能结合浏览器上下文，亟需一种新的测试框架来解决这些问题。

研究方法: ASSURE框架包含三个核心组件：1) 模块化测试用例生成引擎，支持插件式扩展测试场景；2) 自动化执行框架，协调网页内容、扩展处理和AI模型行为的复杂交互；3) 可配置验证管道，系统评估行为一致性和安全性，而非依赖精确输出匹配。

研究结果: 在六款流行AI浏览器扩展上的评估显示，ASSURE识别了531个问题，包括安全漏洞、变形关系违规和内容对齐问题。其测试吞吐量比手动方法提升6.4倍，平均12.4分钟即可检测到关键安全漏洞。

研究结论: ASSURE为AI驱动的浏览器扩展提供了一种高效、全面的测试解决方案，填补了现有测试方法的空白，并具备实际开发流程集成潜力。

中文摘要: 大型语言模型（LLM）与浏览器扩展的集成彻底改变了网页浏览体验，实现了内容摘要、智能翻译和上下文感知写作辅助等高级功能。然而，这些AI驱动的扩展在测试和可靠性保障方面带来了前所未有的挑战。传统浏览器扩展测试方法无法应对LLM扩展的非确定性行为、上下文敏感性和复杂网页环境集成问题。同样，现有的LLM测试方法脱离了浏览器特定上下文，导致有效评估框架的缺失。为填补这一空白，我们提出了ASSURE，一种专为AI驱动的浏览器扩展设计的模块化自动化测试框架。ASSURE包含三个主要组件：1) 支持插件式扩展测试场景的模块化测试用例生成引擎；2) 协调网页内容、扩展处理和AI模型行为复杂交互的自动化执行框架；3) 系统评估行为一致性和安全性而非依赖精确输出匹配的可配置验证管道。我们在六款广泛使用的AI浏览器扩展上的评估证明了ASSURE的有效性，共识别出531个问题，涵盖安全漏洞、变形关系违规和内容对齐问题。ASSURE的测试吞吐量比手动方法提升6.4倍，平均12.4分钟即可检测到关键安全漏洞。这一高效性使ASSURE成为开发流程集成的实用解决方案，为AI驱动的浏览器扩展测试提供了全面支持。

</details>


### [292] [OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models](https://arxiv.org/abs/2507.05316)
**中文标题：OASBuilder：利用大语言模型从在线API文档生成OpenAPI规范**

*Koren Lazar,Matan Vetzler,Kiran Kate,Jason Tsay,David Boaz Himanshu Gupta,Avraham Shinnar,Rohith D Vallam,David Amid Esther Goldbraich,Guy Uziel,Jim Laredo,Ateret Anaby Tavor*

主要分类: cs.SE

摘要简述: OASBuilder是一个利用大语言模型和规则算法将非结构化的在线API文档转化为标准化OpenAPI规范的框架，显著减少人工转换时间。


<details>
  <summary>详细信息</summary>
研究动机: 在线API文档通常是非结构化的HTML格式，需要人工转换为机器可读的规范，耗时耗力。OASBuilder旨在解决这一问题，通过自动化转换提升效率。

研究方法: OASBuilder结合大语言模型和基于规则的算法，利用对文档网页结构的领域知识，构建了一个将非结构化API文档转化为OpenAPI规范的流水线。

研究结果: 实验表明，OASBuilder能泛化处理数百种API，生成有效的OpenAPI规范，覆盖原始文档的大部分信息，并在企业环境中成功应用，节省大量人工时间。

研究结论: OASBuilder通过自动化转换API文档为OpenAPI规范，显著提升了效率，为企业提供了可扩展的解决方案。

中文摘要: AI代理和业务自动化工具需要与外部Web服务交互，这些服务通常以非结构化的HTML文档形式提供API信息，用户需手动将其转换为机器可读的规范。为此，我们提出了OASBuilder，一种新颖的框架，通过结合大语言模型和基于规则的算法，将多样化的API文档页面转化为一致的OpenAPI规范。实验证明，OASBuilder能泛化处理数百种API，生成的规范有效覆盖原始文档信息，并在企业环境中成功应用，节省了数千小时的人工时间，使复杂的企业API成为LLM的工具。

</details>


### [293] [TigAug: Data Augmentation for Testing Traffic Light Detection in Autonomous Driving Systems](https://arxiv.org/abs/2507.05932)
**中文标题：TigAug：用于自动驾驶系统中交通灯检测测试的数据增强方法**

*You Lu,Dingji Wang,Kaifeng Huang,Bihuan Chen,Xin Peng*

主要分类: cs.SE

摘要简述: TigAug是一种用于自动驾驶系统中交通灯检测模型测试的数据增强工具，通过自动生成多样化的交通灯图像，提升测试效率和模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶系统（ADS）的可靠性至关重要，但交通灯检测模型的自动化测试研究较少，传统手动数据收集方法效率低且难以覆盖多样环境。

研究方法: TigAug基于天气环境、相机属性和交通灯特性的系统理解，构建了两类变形关系和三类图像变换，自动生成增强图像用于测试和模型重训练。

研究结果: 实验表明，TigAug能有效测试交通灯检测模型，高效合成图像，且生成的图像具有可接受的自然度。

研究结论: TigAug为交通灯检测模型的测试和性能提升提供了高效、自动化的解决方案。

中文摘要: 自动驾驶技术在过去几十年中随着传感和计算技术的进步而发展，但确保自动驾驶系统（ADS）的可靠性和鲁棒性仍是一个迫切需求。尽管近年来对ADS各模块的测试取得了一定成果，但交通灯检测模型的自动化测试研究较少。传统方法依赖人工收集和标注交通灯数据，效率低下且难以覆盖多样化的驾驶环境。为解决这些问题，我们提出并实现了TigAug，用于自动增强标注的交通灯图像以测试ADS中的交通灯检测模型。基于对天气环境、相机属性和交通灯特性的系统理解，我们构建了两类变形关系和三类图像变换。通过增强图像，我们利用特定变换的变形关系检测交通灯检测模型的错误行为，并通过重训练提升模型性能。对四种先进交通灯检测模型和两个数据集的大规模实验表明：i) TigAug能有效测试交通灯检测模型；ii) TigAug能高效合成交通灯图像；iii) TigAug生成的图像具有可接受的自然度。

</details>


### [294] [Search-based Selection of Metamorphic Relations for Optimized Robustness Testing of Large Language Models](https://arxiv.org/abs/2507.05565)
**中文标题：基于搜索的大型语言模型鲁棒性测试中变形关系优化选择**

*Sangwon Hyun,Shaukat Ali,M. Ali Babar*

主要分类: cs.SE

摘要简述: 本文提出了一种基于搜索的方法，用于优化大型语言模型（LLM）的鲁棒性测试中的变形关系（MR）选择，以最大化故障检测并最小化执行成本。通过四种搜索算法比较，MOEA/D表现最佳，并发现了对LLM鲁棒性测试具有显著效果的“银弹MR”。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLM）的鲁棒性测试主要依赖变形关系（MR），但现有研究多局限于自动生成测试用例，且仅考虑单一扰动的MR。本文旨在优化MR选择，扩展测试空间，提升鲁棒性评估的效率和效果。

研究方法: 提出了一种搜索方法，通过四种算法（Single-GA、NSGA-II、SPEA2和MOEA/D）优化MR组的选择，覆盖组合扰动。实验基于两种主要LLM的文本到文本任务，比较了算法性能。

研究结果: MOEA/D算法在优化LLM鲁棒性测试的MR空间方面表现最佳，同时发现了对LLM鲁棒性测试具有显著效果的“银弹MR”。

研究结论: 研究为LLM鲁棒性测试中的优化问题提供了解决方案，并验证了搜索方法的有效性，为未来研究提供了新方向。

中文摘要: 评估大型语言模型（LLM）的鲁棒性等可信度问题备受关注。近年来，基于变形关系（MR）的变形测试被广泛应用于评估LLM执行的鲁棒性。然而，基于MR的鲁棒性测试仍需大量MR，因此需要优化MR选择。现有LLM测试研究多局限于自动生成测试用例（即MR）以提高故障检测率，且仅考虑单一扰动的MR。相比之下，本文提出了一种搜索方法，用于优化MR组以最大化故障检测并最小化LLM执行成本。此外，该方法覆盖了MR中的组合扰动，扩展了鲁棒性评估的测试空间。我们开发了搜索流程并实现了四种搜索算法（Single-GA、NSGA-II、SPEA2和MOEA/D），通过新颖编码解决LLM鲁棒性测试中的MR选择问题。基于两种主要LLM的文本到文本任务，我们比较了四种算法与随机搜索的性能。统计和实证研究得出两个关键发现：（1）MOEA/D算法在优化LLM鲁棒性测试的MR空间方面表现最佳；（2）发现了对LLM鲁棒性测试具有显著效果的“银弹MR”，其在不同文本到文本任务中表现出混淆LLM的显著能力。本研究为LLM鲁棒性评估中的优化测试问题提供了解决方案，并为基于搜索的方法提供了新见解。

</details>
