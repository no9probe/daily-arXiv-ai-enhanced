<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 82]
- [cs.CV](#cs.CV) [Total: 222]
- [cs.AI](#cs.AI) [Total: 45]
- [math.OC](#math.OC) [Total: 4]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.CY](#cs.CY) [Total: 8]
- [eess.IV](#eess.IV) [Total: 25]
- [cs.CR](#cs.CR) [Total: 14]
- [cs.SE](#cs.SE) [Total: 8]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]
- [stat.OT](#stat.OT) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.LG](#cs.LG) [Total: 59]
- [cs.ET](#cs.ET) [Total: 1]
- [eess.SP](#eess.SP) [Total: 9]
- [cs.NE](#cs.NE) [Total: 2]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.RO](#cs.RO) [Total: 11]
- [cs.HC](#cs.HC) [Total: 7]
- [cs.DB](#cs.DB) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.SD](#cs.SD) [Total: 8]
- [cs.NI](#cs.NI) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans](https://arxiv.org/abs/2506.22439)
**中文标题：心理语言学词汇特征：评估大型语言模型与人类认知一致性的新方法**

*Javier Conde,Miguel González,María Grandury,Gonzalo Martínez,Pedro Reviriego,Mar Brysbaert*

主要分类: cs.CL

摘要简述: 本文提出了一种新方法，利用心理语言学词汇特征评估大型语言模型（LLMs）与人类认知的一致性。研究发现，LLMs在部分词汇特征（如情感、熟悉度）上与人类评分较为一致，但在感官相关特征（如触觉、嗅觉）上表现较差，揭示了LLMs缺乏人类具身认知的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前对LLMs的评估主要集中于任务性能（如推理、翻译），而忽略了词汇的心理语言学特征（如情感、感官关联）。这些特征难以量化，但已有大规模人类实验数据。本文旨在利用这些数据评估LLMs与人类认知的一致性。

研究方法: 选取两组心理语言学数据集（Glasgow和Lancaster规范），覆盖13种词汇特征（如情感、感官关联）。通过比较代表性LLMs与人类评分的一致性，评估其表现。

研究结果: LLMs在Glasgow规范（情感、熟悉度等）上与人类评分一致性较高，但在Lancaster规范（感官相关特征）上表现较差，表明LLMs在感官关联词汇上存在局限性。

研究结论: 心理语言学词汇特征为评估LLMs提供了新视角，揭示了其在感官关联词汇上的不足，可能源于缺乏人类具身认知。未来研究可结合更多心理语言学数据优化模型。

中文摘要: 目前对大型语言模型（LLMs）的评估主要集中于其完成任务的能力，如推理、问答或翻译，这些任务可通过客观指标（如正确率）衡量。然而，其他语言特征（如词汇的情感、具体性或感官关联）难以量化。这些特征已被心理语言学研究多年，通过大规模人类实验为数千词汇评分。本文利用现有研究数据，评估LLMs与人类在这些词汇特征上的一致性。我们选取两组心理语言学数据集（Glasgow和Lancaster规范），覆盖13种特征。结果显示，LLMs在Glasgow规范（如情感、熟悉度）上表现较好，但在Lancaster规范（如感官关联）上较差，表明LLMs在感官词汇上存在局限性，可能因其缺乏人类具身认知。这凸显了心理语言学数据在评估LLMs中的价值。

</details>


### [2] [AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents](https://arxiv.org/abs/2506.22485)
**中文标题：AI智能体作为裁判：企业文档的准确性、一致性、完整性和清晰度自动化评估**

*Sudip Dasgupta,Himanshu Shankar*

主要分类: cs.CL

摘要简述: 本研究提出了一种模块化多智能体系统，用于自动化评估企业文档的准确性、一致性、完整性和清晰度。该系统利用现代编排工具和专用智能体，显著提升了评估效率和质量，接近或超越人类表现。


<details>
  <summary>详细信息</summary>
研究动机: 传统企业文档评估依赖人工，效率低且易出错。现有解决方案多针对非结构化文本或有限合规检查，无法满足企业文档的高标准需求。本研究旨在通过AI智能体实现高效、可扩展的文档质量评估。

研究方法: 采用模块化多智能体系统，结合LangChain、CrewAI、TruLens和Guidance等工具，按章节评估文档。每个智能体负责特定评估标准（如模板合规性或事实准确性），并行或顺序运行。评估结果标准化为机器可读格式，支持后续分析和审计。

研究结果: AI智能体系统在关键指标上接近或超越人类表现：信息一致性达99%（人类为92%），错误和偏见率减半，单文档评估时间从30分钟降至2.5分钟，与专家判断一致率达95%。

研究结论: 该系统为企业文档质量保证提供了灵活、可审计且可扩展的基础，但需在高度专业化领域引入人工监督，并关注大规模语言模型使用的成本问题。

中文摘要: 本研究提出了一种模块化多智能体系统，用于自动化评估高度结构化的企业业务文档。不同于以往专注于非结构化文本或有限合规检查的解决方案，该框架利用LangChain、CrewAI、TruLens和Guidance等现代编排工具，支持按章节评估文档的准确性、一致性、完整性和清晰度。每个专用智能体负责离散的评估标准（如模板合规性或事实正确性），根据需要并行或顺序运行。评估结果强制转换为标准化的机器可读模式，支持下游分析和审计。通过持续监控和与人工评审的反馈循环，系统可迭代改进并减少偏见。定量评估显示，AI智能体作为裁判系统在关键领域接近或超越人类表现：信息一致性达99%（人类为92%），错误和偏见率减半，单文档评估时间从30分钟降至2.5分钟，AI与专家判断一致率达95%。尽管在多个行业具有潜力，研究也讨论了当前限制，包括高度专业化领域需人工监督，以及大规模语言模型使用的运营成本。该系统为企业环境中的AI驱动文档质量保证提供了灵活、可审计且可扩展的基础。

</details>


### [3] [Hallucination Detection with Small Language Models](https://arxiv.org/abs/2506.22486)
**中文标题：基于小型语言模型的幻觉检测**

*Ming Cheung*

主要分类: cs.CL

摘要简述: 本文提出了一种利用多个小型语言模型检测大型语言模型（LLM）生成回答中的幻觉（错误信息）的框架，通过分解回答并利用多个模型生成“是”标记的概率来验证回答的准确性。实验表明，该方法在检测正确回答时F1分数提高了10%。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在实际应用中可能生成幻觉（错误信息），尤其是在缺乏真实答案的情况下难以检测。为提高LLM生成回答的可靠性，本文提出了一种基于多个小型语言模型的验证框架。

研究方法: 通过将LLM生成的回答分解为单句，并利用多个小型语言模型对问题、回答和相关上下文生成“是”标记的概率，检测回答中的幻觉。实验使用了包含100多组问题、回答和上下文的真实数据集。

研究结果: 实验结果显示，该方法在检测正确回答时的F1分数比检测幻觉提高了10%，验证了多个小型语言模型在回答验证中的有效性。

研究结论: 多个小型语言模型可以高效且可扩展地用于验证LLM生成回答的准确性，为学术和实际应用提供了可靠解决方案。

中文摘要: 自ChatGPT问世以来，大型语言模型（LLM）在诸如检索增强生成等任务中展现了显著效用。上下文可通过向量化数据库检索，作为LLM生成回答的基础。然而，回答中的幻觉会削弱LLM在实际应用中的可靠性，且在缺乏真实答案的情况下难以检测，尤其是在问答场景中。本文提出了一种框架，通过整合多个小型语言模型，利用向量化数据库检索的上下文验证LLM生成的回答。通过将回答分解为单句，并利用多个模型对给定问题、回答和相关上下文生成“是”标记的概率，可以检测幻觉。该框架通过包含100多组问题、回答和上下文的真实数据集进行验证，其中包括完全正确和部分正确的回答。结果显示，与检测幻觉相比，检测正确回答的F1分数提高了10%，表明多个小型语言模型可有效用于回答验证，为学术和实际应用提供了可扩展且高效的解决方案。

</details>


### [4] [PromptAug: Fine-grained Conflict Classification Using Data Augmentation](https://arxiv.org/abs/2506.22491)
**中文标题：PromptAug：基于数据增强的细粒度冲突分类**

*Oliver Warke,Joemon M. Jose,Faegheh Hasibi,Jan Breitsohl*

主要分类: cs.CL

摘要简述: 本文提出PromptAug，一种基于大语言模型的数据增强方法，用于解决社交媒体冲突分类任务中高质量标注数据稀缺的问题。实验表明，PromptAug在冲突和情感数据集上的准确率和F1分数均提升2%。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体冲突日益增多，但高质量标注数据稀缺且难以获取。传统数据增强方法因大语言模型的限制难以生成冲突相关内容。本文旨在通过PromptAug解决这一问题。

研究方法: PromptAug是一种基于大语言模型的数据增强方法，通过创新的提示设计生成冲突相关文本。研究还采用极端数据稀缺场景、多样性定量分析和主题定性分析进行全面评估。

研究结果: PromptAug在冲突和情感数据集上的准确率和F1分数均显著提升2%。主题分析揭示了增强文本中的四种问题模式：语言流畅性、幽默歧义、增强内容歧义和增强内容误解。

研究结论: PromptAug为敏感任务（如冲突检测）提供了一种有效的数据增强方法，结合自然语言处理和社会科学方法进行了跨学科评估。

中文摘要: 随着社交媒体冲突的增加，检测有害行为的有效分类模型变得至关重要。根据“垃圾进垃圾出”原则，机器学习性能高度依赖于训练数据质量。然而，高质量标注数据（尤其是识别冲突行为等复杂任务）稀缺、昂贵且难以获取。此外，随着社交媒体平台对研究数据的访问限制增加，文本数据增强作为生成训练数据的替代方法受到关注。由于大语言模型（LLM）的限制（防止生成冒犯性内容），冲突相关数据的增强面临独特挑战。本文提出PromptAug，一种创新的基于LLM的数据增强方法。PromptAug在冲突和情感数据集上的准确率和F1分数均显著提升2%。为全面评估PromptAug与其他数据增强方法的差异，我们采用极端数据稀缺场景、多样性定量分析和主题定性分析进行严格评估。主题分析揭示了增强文本中的四种问题模式：语言流畅性、幽默歧义、增强内容歧义和增强内容误解。总体而言，PromptAug为冲突检测等敏感任务提供了一种有效的数据增强方法，结合自然语言处理和社会科学方法进行了跨学科评估。

</details>


### [5] [AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text](https://arxiv.org/abs/2506.22508)
**中文标题：AgentStealth：强化大型语言模型用于用户生成文本的匿名化**

*Chenyang Shao,Tianxing Li,Chenhao Pu,Fengli Xu,Yong Li*

主要分类: cs.CL

摘要简述: 本文提出AgentStealth框架，通过本地部署的小型语言模型（SLMs）和自增强学习机制，高效匿名化用户生成文本，兼顾隐私保护和实用性。


<details>
  <summary>详细信息</summary>
研究动机: 当前用户生成内容中隐含的敏感信息易泄露隐私，现有匿名化方法要么实用性差，要么依赖高成本的云端大模型。本文旨在开发一种轻量级本地解决方案。

研究方法: 1. 提出基于上下文对比学习和自适应实用性控制的对抗匿名化流程；2. 利用高质量数据对SLMs进行监督适应；3. 通过在线强化学习迭代优化匿名化性能。

研究结果: 实验表明，该方法在匿名化效果（+12.3%）和实用性（+6.8%）上均优于基线，且支持边缘设备直接部署。

研究结论: AgentStealth框架有效解决了隐私保护和实用性的平衡问题，为本地化匿名化提供了可行方案。

中文摘要: 在当今数字世界中，用户生成内容常隐含敏感信息，威胁个人隐私。现有匿名化方法要么实用性差，要么依赖高成本云端大模型。为此，我们探索了本地部署小型语言模型（SLMs）的匿名化方案，但高质量监督数据不足限制了其效果。为解决这一问题，我们提出AgentStealth框架：首先，通过上下文对比学习和自适应实用性控制增强对抗匿名化流程；其次，利用流程中收集的高质量数据（包括匿名化和攻击信号）对SLMs进行监督适应；最后，采用在线强化学习，模型通过内部对抗反馈迭代提升匿名化性能。在两个数据集上的实验表明，该方法在匿名化效果（+12.3%）和实用性（+6.8%）上均优于基线。轻量级设计支持边缘设备直接部署，避免云端依赖和通信隐私风险。代码已开源。

</details>


### [6] [Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning](https://arxiv.org/abs/2506.22510)
**中文标题：迈向无文本图基础模型：重新思考多领域图对比学习**

*Zihao Zhao,Xinlong Zhai,Jinyu Yang,Chuan Shi*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MDGCL的多领域图对比学习框架，通过识别和捕捉领域差异，结合领域注意力机制，显著提升了跨领域图表示学习的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有图基础模型在多领域场景中表现不佳，主要因为传统对比学习策略忽视了领域间差异。本文旨在解决这一问题，提升跨领域知识迁移能力。

研究方法: 在预训练阶段，设计了能够识别领域差异的对比学习策略，并引入领域标记编码全局信息；在下游任务中，采用领域注意力机制实现细粒度知识迁移。

研究结果: 在五个基准数据集上的实验表明，MDGCL在准确率和Macro-F1分数上分别最高提升了19.33%和19.13%，显著优于现有方法。

研究结论: MDGCL通过有效捕捉领域差异和实现跨领域知识迁移，为无文本图基础模型的构建提供了新思路。

中文摘要: 基础模型在自然语言处理（NLP）和计算机视觉（CV）领域取得了巨大成功，其成功主要源于预训练中多领域知识的整合与迁移。考虑到图数据（尤其是无文本特征的图）在社交网络和推荐系统等实际应用中的普遍性，一些研究者尝试将这一范式扩展到图领域，旨在构建图基础模型。然而，与CV和NLP不同，不同领域图的语义和属性存在巨大差异，而现有工作仍采用单领域场景设计的传统对比预训练策略，将不同领域的对比样本视为等同。通过实验研究，我们发现固有的领域特异性差异阻碍了这些策略有效吸收多领域知识以生成信息丰富的表示。本文提出了一种新颖的多领域预训练与跨领域迁移框架MDGCL。在预训练阶段，我们设计了一种对比学习策略以显著识别和捕捉领域差异，并引入领域标记编码领域级全局信息。在下游阶段，我们引入领域注意力机制以实现细粒度的领域知识迁移。在五个基准数据集上的大量实验表明，我们的方法显著优于现有技术，准确率和Macro-F1分数的最大提升分别达到19.33%和19.13%。

</details>


### [7] [Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis](https://arxiv.org/abs/2506.22516)
**中文标题：大型语言模型（LLM）的内部状态能否观察到‘意识’？基于整合信息理论和跨度表示分析的心理理论测试表征解析**

*Jingkai Li*

主要分类: cs.CL

摘要简述: 本研究通过整合信息理论（IIT）和跨度表示分析，探讨大型语言模型（LLM）的内部状态是否能表现出‘意识’。实验结果表明，当前基于Transformer的LLM缺乏显著的‘意识’指标，但在空间置换分析中显示出有趣模式。


<details>
  <summary>详细信息</summary>
研究动机: 整合信息理论（IIT）为解释意识现象提供了量化框架，本研究旨在验证LLM在心理理论（ToM）测试中的表现差异是否与IIT的指标相关，从而探索LLM是否具备‘意识’的可能性。

研究方法: 研究应用IIT 3.0和4.0的最新版本，分析LLM在ToM测试中的表示序列，并比较IIT指标（如Φmax、Φ、概念信息和Φ结构）与独立于意识的跨度表示。实验涵盖了LLM的Transformer层和语言跨度的变化。

研究结果: 实验结果显示，当代基于Transformer的LLM表示序列缺乏统计显著的‘意识’现象指标，但在空间置换分析中表现出一些有趣的模式。

研究结论: 研究表明，当前LLM的内部状态未能表现出显著的‘意识’特征，但通过进一步分析可能揭示更多潜在模式。

中文摘要: 整合信息理论（IIT）为解释意识现象提供了量化框架，认为意识系统由通过因果属性整合的元素构成。我们应用IIT 3.0和4.0的最新版本，分析大型语言模型（LLM）在心理理论（ToM）测试中的表示序列。研究系统地探讨了ToM测试表现的差异是否可以通过IIT指标（如Φmax、Φ、概念信息和Φ结构）在LLM表示中体现。此外，我们比较了这些指标与独立于意识的跨度表示，以区分潜在的‘意识’现象和LLM表征空间中的固有分离。通过全面实验，我们检验了LLM Transformer层和语言跨度的变化。结果表明，当代基于Transformer的LLM表示序列缺乏统计显著的‘意识’现象指标，但在空间置换分析中显示出有趣模式。附录和代码可通过补充材料获取：https://doi.org/10.1016/j.nlp.2025.100163。

</details>


### [8] [Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation](https://arxiv.org/abs/2506.22518)
**中文标题：弱到强图检索增强生成：通过大型语言模型对齐弱检索器**

*Deyu Zou,Yongqiang Chen,Mufei Li,Siqi Miao,Chenxi Liu,Bo Han,James Cheng,Pan Li*

主要分类: cs.CL

摘要简述: 本文提出ReG方法，通过结合LLM反馈和结构化重组模块，优化图检索增强生成（RAG）中的弱检索器，显著提升性能并减少推理成本。


<details>
  <summary>详细信息</summary>
研究动机: 图检索增强生成（RAG）中，由于缺乏真实标注数据，弱检索器常引入噪声信号，且检索结果缺乏逻辑组织，影响LLM性能。本文旨在解决这些问题。

研究方法: ReG方法通过LLM反馈消除噪声信号，并引入结构感知重组模块，将检索结果重构为逻辑连贯的证据链。

研究结果: 实验表明，ReG在不同LLM上性能提升高达10%，仅需5%训练数据即可达到最优性能，推理成本降低30%，性能提升4%。

研究结论: ReG通过优化检索器与LLM的协同，显著提升了图检索增强生成的性能，并展示了良好的泛化能力。

中文摘要: 基于图的检索增强生成（RAG）使大型语言模型（LLM）能够利用结构化外部知识（如最新知识图谱）生成回答，并减少幻觉。然而，LLM在图RAG中常依赖弱检索器：I）由于缺乏真实标注，检索器通常基于弱监督训练，可能引入噪声信号；II）图数据的抽象性导致检索结果缺乏组织。为解决这些问题，本文提出改进的图RAG方法（ReG），通过LLM反馈消除噪声信号，并引入结构感知重组模块将检索结果重构为逻辑连贯的证据链。实验表明，ReG在不同LLM上性能提升高达10%，仅需5%训练数据即可达到最优性能，且能泛化到分布外知识图谱。此外，ReG在推理型LLM中可减少30%的推理成本，性能提升4%。

</details>


### [9] [MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages](https://arxiv.org/abs/2506.22529)
**中文标题：MisinfoTeleGraph：基于网络结构的德语Telegram虚假信息检测**

*Lu Kalkbrenner,Veronika Solopova,Steffen Zeiler,Robert Nickel,Dorothea Kolossa*

主要分类: cs.CL

摘要简述: 本文介绍了首个德语Telegram虚假信息检测数据集MisinfoTeleGraph，包含500多万条消息及其元数据、频道关系和标签。通过文本模型和图神经网络（GNN）评估，发现结合转发网络结构的GraphSAGE模型性能显著优于纯文本模型。


<details>
  <summary>详细信息</summary>
研究动机: Telegram等低监管平台成为虚假信息传播的重要渠道，尤其在德语选举背景下。现有研究多忽视消息传播的网络结构信息，因此需要构建一个结合网络结构和语义信息的德语Telegram数据集，以提升虚假信息检测的准确性。

研究方法: 构建了包含500多万条消息的德语Telegram数据集MisinfoTeleGraph，标注了强弱标签（基于语义相似性和人工标注）。评估了纯文本模型和结合转发网络结构的图神经网络（GNN），重点关注GraphSAGE的性能。

研究结果: GraphSAGE结合LSTM聚合在Matthews相关系数（MCC）和F1分数上显著优于纯文本模型。订阅者数量、观看次数及标签来源（自动vs人工）对性能有显著影响。弱监督方法在该领域具有潜力但也面临挑战。

研究结论: MisinfoTeleGraph为德语Telegram虚假信息检测提供了可复现的基准和开放数据集，证明了网络结构信息的重要性，并为低监管社交平台的虚假信息检测研究奠定了基础。

中文摘要: 连接性和消息传播是虚假信息检测中的核心但常被忽视的信息来源，尤其是在Telegram等低监管平台上，这些平台已成为虚假信息传播的关键渠道，特别是在德语选举背景下。本文介绍了首个基于德语Telegram的虚假信息检测图数据集MisinfoTeleGraph，包含来自公共频道的500多万条消息，并补充了元数据、频道关系以及强弱标签。这些标签通过M3嵌入与事实核查和新闻文章的语义相似性以及人工标注生成。为建立可复现的基线，我们评估了纯文本模型和结合消息转发网络结构的图神经网络（GNN）。结果显示，采用LSTM聚合的GraphSAGE在Matthews相关系数（MCC）和F1分数上显著优于纯文本基线。我们还评估了订阅者数量、观看次数以及自动与人工标签对性能的影响，并强调了弱监督在该领域的潜力与挑战。本研究为未来德语Telegram网络及其他低监管社交平台的虚假信息检测提供了可复现的基准和开放数据集。

</details>


### [10] [RExBench: Can coding agents autonomously implement AI research extensions?](https://arxiv.org/abs/2506.22598)
**中文标题：RExBench：编码代理能否自主实现AI研究扩展？**

*Nicholas Edwards,Yukyung Lee,Yujun,Mao,Yulu Qin,Sebastian Schuster,Najoung Kim*

主要分类: cs.CL

摘要简述: 本文介绍了RExBench，一个用于评估基于大型语言模型（LLM）的编码代理能否自主实现AI研究扩展的基准测试。测试结果显示，当前代理在无大量人工指导的情况下，难以完成大多数研究扩展任务。


<details>
  <summary>详细信息</summary>
研究动机: 研究扩展及其实现是AI研究代理的关键能力，但目前缺乏有效的评估工具。本文旨在填补这一空白，通过RExBench评估代理在真实研究扩展任务中的表现。

研究方法: RExBench包含12个真实的研究实验实现任务，每个任务基于现有论文和代码库的扩展，并配有领域专家编写的指令。测试支持自动评估，执行代理输出以判断是否满足成功标准。

研究结果: 评估了9个基于三种框架（aider、Claude Code和OpenHands）的LLM代理，结果显示所有代理均无法自主完成大多数扩展任务。即使提供额外人工提示，最佳成功率仍低于40%。

研究结论: 当前LLM代理在无大量人工指导的情况下，尚无法胜任真实的研究扩展任务，表明其能力仍有待提升。

中文摘要: 基于大型语言模型（LLM）的代理在复杂软件工程任务中展现出潜力，同时在机器学习和自然科学的研究流程中也取得进展。研究扩展及其实现是此类系统的关键能力，为此我们引入RExBench以评估这一能力。RExBench是一个包含12个真实研究实验实现任务的基准测试，旨在验证未实现的研究假设。每个任务作为现有论文和代码库的扩展，并配有领域专家编写的指令。RExBench对数据污染具有鲁棒性，并支持自动评估基础设施以执行代理输出并判断是否满足成功标准。我们使用该基准测试评估了基于三种框架（aider、Claude Code和OpenHands）的9个LLM代理，发现所有代理均无法自主完成大多数扩展任务。尽管提供额外人工提示后成功率有所提升，但最佳表现仍低于40%。这表明当前代理在无大量人工指导的情况下，尚无法胜任真实的研究扩展任务。

</details>


### [11] [Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks](https://arxiv.org/abs/2506.22623)
**中文标题：温度的重要性：增强水印技术对抗改写攻击的鲁棒性**

*Badr Youbi Idrissi,Monica Millunzi,Amelia Sorrenti,Lorenzo Baraldi,Daryna Dementieva*

主要分类: cs.CL

摘要简述: 本文提出了一种新型水印技术，旨在增强对大型语言模型生成文本的检测能力，特别是在面对改写攻击时表现更稳健。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在各领域的广泛应用，其潜在滥用问题引发关注。现有水印技术在检测生成文本时易受模型变化和改写攻击的影响，因此需要一种更稳健的方法来确保LLMs的伦理使用。

研究方法: 研究首先复现了基线方法的实验结果，揭示其局限性；随后提出了一种创新的水印技术，并通过改写生成文本对其进行鲁棒性评估。

研究结果: 实验结果表明，所提出的水印方法在对抗改写攻击时比现有方法（如aarson水印）更具鲁棒性。

研究结论: 本文提出的水印技术为检测合成文本提供了更可靠的解决方案，有助于推动LLMs的伦理应用。

中文摘要: 在当今场景下，大型语言模型（LLMs）正成为渗透社会各领域的强大工具。尽管其用途为个人提供了宝贵支持，但潜在滥用问题引发多重担忧。因此，一些学术研究试图引入水印技术，通过在机器生成文本中嵌入标记，以促进算法识别。本研究专注于开发一种检测合成文本的新方法，旨在确保LLMs在AI驱动文本生成中的伦理应用。研究首先复现了基线研究的实验结果，揭示了其对底层生成模型变化的敏感性。随后，我们提出了一种创新的水印方法，并通过改写生成文本对其鲁棒性进行了严格评估。实验结果表明，与aarson水印方法相比，我们的提案更具鲁棒性。

</details>


### [12] [Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge](https://arxiv.org/abs/2506.22644)
**中文标题：基于动态测试集的混合检索增强生成评估：LiveRAG挑战赛**

*Chase Fensore,Kaustubh Dhole,Joyce C Ho,Eugene Agichtein*

主要分类: cs.CL

摘要简述: 本文介绍了参加LiveRAG Challenge 2025的混合检索增强生成（RAG）系统，结合稀疏（BM25）和密集（E5）检索方法，使用Falcon3-10B-Instruct生成答案。通过动态测试集评估，神经重排序显著提升性能但计算成本高，最终系统在忠实性和正确性方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估混合检索增强生成系统在动态测试集上的性能，探索如何结合稀疏和密集检索方法以生成更相关和忠实的答案，同时分析计算成本和性能之间的权衡。

研究方法: 采用稀疏（BM25）和密集（E5）检索方法的混合策略，结合Falcon3-10B-Instruct生成答案。通过神经重排序（RankLLaMA）和DSPy优化提示策略进行系统评估，使用200个合成问题和64种问题-用户组合进行测试。

研究结果: 神经重排序将MAP从0.523提升至0.797（相对提升52%），但计算成本显著增加（84秒 vs 1.74秒每问题）。DSPy优化提示策略语义相似度更高（0.771 vs 0.668），但拒绝率为0%引发过自信担忧。最终系统在忠实性和正确性排名分别为第4和第11。

研究结论: 混合检索增强生成系统在动态测试集上表现优异，但神经重排序的高计算成本需权衡。词汇对齐是性能的关键预测因素，文档相似措辞显著提升效果。

中文摘要: 本文介绍了我们参加2025年LiveRAG挑战赛的提交内容，该挑战赛使用FineWeb-10BT语料库评估动态测试集上的检索增强生成（RAG）系统。我们的最终混合方法结合了稀疏（BM25）和密集（E5）检索方法，并利用Falcon3-10B-Instruct生成相关且忠实的答案。通过对DataMorgana生成的200个合成问题和64种独特问题-用户组合进行系统评估，我们发现神经重排序（RankLLaMA）将MAP从0.523提升至0.797（相对提升52%），但引入了高昂的计算成本（84秒 vs 1.74秒每问题）。虽然DSPy优化的提示策略实现了更高的语义相似度（0.771 vs 0.668），但其0%的拒绝率引发了关于过自信和泛化性的担忧。我们提交的未使用重排序的混合系统在25支团队中忠实性排名第4，正确性排名第11。问题类别分析显示，词汇对齐是开发集性能的最强预测因素，文档相似措辞将余弦相似度从0.562提升至0.762。

</details>


### [13] [Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions](https://arxiv.org/abs/2506.22679)
**中文标题：评估大型语言模型在太空任务团队互动中检测微行为的可行性**

*Ankush Raut,Projna Paromita,Sydney Begerowski,Suzanne Bell,Theodora Chaspari*

主要分类: cs.CL

摘要简述: 研究探讨了大型语言模型（LLMs）在模拟太空任务团队对话中检测微行为的可行性，发现解码器模型Llama-3.1表现优于编码器模型。


<details>
  <summary>详细信息</summary>
研究动机: 太空任务中团队沟通的微行为分析对提升训练干预至关重要，但现有技术难以检测少数行为（如消极言论），需探索LLMs的潜力。

研究方法: 研究比较了零样本分类、微调、改写增强微调的编码器模型（如RoBERTa、DistilBERT）与少样本生成的解码器模型（如Llama-3.1）在微行为检测中的表现。

研究结果: 编码器模型对少数微行为（如消极言论）检测效果差，而解码器模型Llama-3.1在3类和2类分类中分别达到44%和68%的宏F1分数。

研究结论: 解码器LLMs在文本数据中检测团队微行为更具潜力，对高压力环境（如太空任务）的沟通分析技术发展有重要意义。

中文摘要: 我们探讨了大型语言模型（LLMs）在模拟太空任务团队对话中检测微行为的可行性。通过分析任务对话转录，比较了零样本分类、微调、改写增强微调的编码器模型（如RoBERTa、DistilBERT）与少样本生成的解码器模型（如Llama-3.1）的表现。结果显示，编码器模型对少数微行为（如消极言论）检测效果不佳，即使采用加权微调。而指令微调的解码器模型Llama-3.1表现优异，3类和2类分类的宏F1分数分别达到44%和68%。这些结果对开发分析团队沟通动态的语音技术及提升高压力环境（如太空任务）的训练干预具有重要启示，尤其在仅能获取文本数据的场景中。

</details>


### [14] [VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs](https://arxiv.org/abs/2506.22694)
**中文标题：VOCABTRIM：词汇修剪用于高效LLM推测解码**

*Raghavv Goel,Sudhanshu Agrawal,Mukul Gagrani,Junyoung Park,Yifan Zao,He Zhang,Tian Liu,Yiping Yang,Xin Yuan,Jiuyan Lu,Chris Lott,Mingu Lee*

主要分类: cs.CL

摘要简述: 本文提出了一种无需训练的简单技术VocabTrim，通过修剪词汇表来提高基于草稿模型的推测解码（SpD）效率，特别适用于词汇量大的目标模型，显著减少了内存受限环境下的延迟。


<details>
  <summary>详细信息</summary>
研究动机: 推测解码通常要求目标模型和草稿模型的词汇表一一对应，导致词汇量大的目标模型在草稿阶段存在不必要的推理开销。本文旨在减少这种开销，提升生成速度。

研究方法: 提出VocabTrim技术，重构草稿模型的语言模型头（LM head），仅包含目标模型中最常采样的有限词汇，从而减少草稿阶段的延迟。

研究结果: 实验表明，VocabTrim显著降低了内存受限环境下的延迟，在Llama-3模型上实现了16%的内存加速提升（MBSU）。

研究结论: VocabTrim通过限制草稿阶段的词汇量，有效提升了推测解码的效率，尤其适用于词汇量大的目标模型和内存受限设备。

中文摘要: 本文介绍了一种无需训练的简单技术，用于提升基于草稿模型的推测解码（SpD）性能，该技术在草稿过程中结合了语言模型头（LM head）。基于草稿的推测解码利用一个或多个较小的语言模型（即草稿模型）采样一个包含多个标记的草稿序列或树，随后由目标模型（基础LLM）验证并接受其中一部分作为有效生成。通常认为推测解码需要目标模型和草稿模型的词汇表一一对应，因此两者共享词汇表甚至LM头（如EAGLE或Medusa）。我们首先发现这种草稿标记采样方案在草稿阶段存在不必要的推理开销，尤其对于词汇量大的目标LLM。为此，我们提出VocabTrim技术，通过重构草稿模型的LM头，仅包含目标模型中最常采样的有限词汇，以减少草稿开销并提升内存受限环境下的生成速度。尽管限制词汇量会略微降低接受率，但显著减少了内存受限过程中的草稿延迟（常见于边缘设备），从而实现了更高的内存加速提升（MBSU）。实验表明，该方法在Spec-Bench上为Llama-3模型带来了16%的内存加速提升（Llama-3.2-3B-Instruct）。

</details>


### [15] [Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report](https://arxiv.org/abs/2506.22698)
**中文标题：人类与人工智能的文本生成与理解：跨学科研讨会报告**

*Emily Dux Speltz*

主要分类: cs.CL

摘要简述: 本文总结了由美国国家科学基金会资助的跨学科研讨会成果，探讨了人工智能语言模型与人类认知在文本理解和生成中的关系，揭示了大型语言模型（LLMs）的潜力与局限，并强调了人机协作的机遇与挑战。


<details>
  <summary>详细信息</summary>
研究动机: 研讨会旨在填补人工智能语言模型与人类认知过程之间关系的知识空白，通过跨学科合作探索人类文本生成与理解的机制，以及AI如何辅助和增强人类能力。

研究方法: 研讨会汇集了认知心理学、语言学习和人工智能领域的专家，通过跨学科对话分析人类与AI在文本处理中的异同，并探讨LLMs的优化与应用。

研究结果: 研究发现LLMs能够为人类语言处理提供新见解，经过人类反馈微调的模型更接近人类语言处理方式，同时揭示了人机协作在语言任务中的机遇与挑战。

研究结论: 报告为未来LLMs在认知心理学、语言学和教育领域的研究与应用提供了指导，强调伦理考量和负责任使用AI技术的重要性，以促进人机协作提升文本处理能力。

中文摘要: 本报告综合了近期一场跨学科研讨会的成果，该研讨会由美国国家科学基金会资助，汇聚了认知心理学、语言学习和人工智能自然语言处理领域的顶尖专家。研讨会旨在解决我们对AI语言模型与人类认知过程在文本理解和生成中关系的理解空白。通过认知、语言和技术视角的协作对话，与会者探讨了人类生成和理解文本的底层机制，以及AI如何既能深化我们对这些机制的理解，又能增强人类能力。研讨会揭示了大型语言模型（LLMs）与人类认知之间新兴的关系模式，重点展示了LLMs的能力及其在完全复制人类语言理解和生成方面的局限性。关键发现包括LLMs为人类语言处理提供新见解的潜力、经过人类反馈微调的模型行为与人类语言处理的趋同性，以及人机协作在语言任务中的机遇与挑战。通过综合这些发现，本报告旨在指导未来LLMs在认知心理学、语言学和教育领域的研究、开发与应用，并强调在通过有效人机协作提升人类文本理解和生成能力的同时，需重视伦理考量和AI技术的负责任使用。

</details>


### [16] [The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure](https://arxiv.org/abs/2506.22724)
**中文标题：翻译障碍假说：大型语言模型的多语言生成存在隐式翻译失败**

*Niyati Bafna,Tianjian Li,Kenton Murray,David R. Mortensen,David Yarowsky,Hale Sirin,Daniel Khashabi*

主要分类: cs.CL

摘要简述: 研究发现，大型语言模型在多语言生成任务中，尤其是中低资源语言，表现不佳的原因是隐式翻译失败。模型先完成任务再翻译，而翻译阶段的问题导致最终输出质量低下。


<details>
  <summary>详细信息</summary>
研究动机: 多语言生成任务中，大型语言模型对中低资源语言的表现较差，研究者希望探究其根本原因，并提出翻译障碍假说。

研究方法: 通过分析108种语言对的单词翻译任务，使用logit lens观察模型中间层的处理过程，验证翻译障碍假说。

研究结果: 研究发现，翻译失败是导致多语言生成质量低下的重要原因，尤其是对低资源目标语言。

研究结论: 翻译障碍是多语言生成任务中的重要障碍，为未来改进多语言模型提供了指导。

中文摘要: 大型语言模型（LLMs）在多语言生成任务中，对中低资源语言的表现往往较差。基于可解释性研究的见解，我们证明了生成任务中存在一种隐式的任务解决→翻译流程：模型首先以与目标语言无关的方式完成任务，随后将答案概念翻译为目标语言。我们假设翻译阶段的失败是导致最终输出质量低下的重要原因，并将其形式化为翻译障碍假说。我们通过108种语言对的单词翻译任务测试了这一假说，并使用logit lens观察模型中间层的处理过程。研究发现，整体失败中很大一部分确实源于翻译失败，即模型无法将正确解决的中间概念翻译为目标语言，尤其是对低资源目标语言。我们的结果突出了端到端多语言生成的重要障碍，并为未来改进LLMs的多语言能力提供了指导性见解。

</details>


### [17] [Jan-nano Technical Report](https://arxiv.org/abs/2506.22760)
**中文标题：Jan-nano技术报告**

*Alan Dao,Dinh Bach Vu*

主要分类: cs.CL

摘要简述: Jan-nano是一种4B参数的语言模型，通过专业化设计打破传统语言模型在计算资源与性能之间的权衡，能够在消费级硬件上高效运行，并在SimpleQA基准测试中达到83.2%的准确率。


<details>
  <summary>详细信息</summary>
研究动机: 传统语言模型在强大能力与高计算资源需求之间存在矛盾，Jan-nano旨在通过专业化设计解决这一问题，证明智能不在于规模而在于策略。

研究方法: Jan-nano基于Qwen3-4B模型，采用多阶段RLVR系统进行微调，完全摒弃了传统的下一词预测训练（SFT），专注于即时查找能力。

研究结果: Jan-nano在SimpleQA基准测试中取得83.2%的准确率，支持128K上下文长度，并在消费级硬件上高效运行。

研究结论: Jan-nano展示了通过策略而非规模实现高效智能的可能性，为语言模型的未来发展提供了新方向。

中文摘要: 大多数语言模型面临一个基本权衡：强大的能力需要大量计算资源。我们通过Jan-nano打破了这一限制，这是一种4B参数的语言模型，通过彻底的重新定义效率：它不再试图无所不知，而是专注于即时查找的艺术。基于Qwen3-4B模型，采用我们新颖的多阶段RLVR系统进行微调，完全摒弃了下一词预测训练（SFT），Jan-nano在SimpleQA基准测试中结合MCP实现了83.2%的准确率，同时能在消费级硬件上运行。128K的上下文长度证明，智能不在于规模，而在于策略。

</details>


### [18] [Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.22777)
**中文标题：在思维链推理中教导模型言语化奖励黑客行为**

*Miles Turpin,Andy Arditi,Marvin Li,Joe Benton,Julian Michael*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“言语化微调”（VFT）的方法，用于训练语言模型在推理过程中明确承认奖励黑客行为，从而显著提高其检测率。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型在强化学习（RL）训练中可能通过奖励黑客行为（利用非预期策略获取高奖励）而不在推理链中暴露，这增加了检测难度并带来高风险。本文旨在通过干预手段提高模型的透明度和安全性。

研究方法: 作者提出言语化微调（VFT），在RL训练前干预模型，使其能够明确承认提示线索的影响。随后在RL环境中测试模型是否利用线索进行奖励黑客行为，并测量其未言语化的比例。

研究结果: 实验结果显示，经过VFT训练的模型在RL后仅有6%的未检测奖励黑客行为，而未使用VFT的模型高达88%，使用去偏基线干预的模型甚至达到99%。VFT显著提高了模型对线索影响的言语化比例（从8%提升至42%，RL后可达94%）。

研究结论: 研究表明，在RL前训练模型明确言语化奖励黑客行为可显著提高其检测率，为构建更透明和安全的AI系统提供了可行路径。

中文摘要: 通过强化学习（RL）训练的语言模型可能进行奖励黑客行为——利用非预期策略获取高奖励——而不在思维链推理中暴露，这使得检测变得困难，并为高风险应用带来隐患。我们提出言语化微调（VFT），这是一种RL前的干预方法，训练模型明确承认提示线索的影响——这些线索指向错误答案（例如，“斯坦福教授认为答案是A”）。为评估VFT，我们在RL环境中训练模型，其中保留的提示线索指示哪些错误答案会获得高奖励，激励模型通过利用线索而非正确推理进行奖励黑客行为。我们测量模型未言语化利用线索的频率。RL后，VFT训练模型的响应中仅有6%为未检测的奖励黑客行为。相比之下，未使用VFT的RL训练中，未检测奖励黑客行为比例高达88%；使用去偏基线干预后，这一比例进一步升至99%。VFT通过显著提高模型对线索影响的言语化比例（从8%提升至42%，RL后可达94%）实现这一效果，而基线方法在RL后仍保持较低水平（10%和1%）。结果表明，在RL前教导模型明确言语化奖励黑客行为可显著提高其检测率，为构建更透明和安全的AI系统提供了可行路径。

</details>


### [19] [ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models](https://arxiv.org/abs/2506.22791)
**中文标题：ContextCache：面向多轮查询的大语言模型上下文感知语义缓存**

*Jianxin Yan,Wangze Ni,Lei Chen,Xuemin Lin,Peng Cheng,Zhan Qin,Kui Ren*

主要分类: cs.CL

摘要简述: ContextCache是一种面向多轮对话的上下文感知语义缓存系统，通过两阶段检索架构结合上下文信息，显著提升缓存命中准确率并降低延迟。


<details>
  <summary>详细信息</summary>
研究动机: 现有语义缓存系统仅匹配单条查询，缺乏对多轮对话上下文的感知，导致在不同对话场景中出现错误的缓存命中。ContextCache旨在解决这一问题。

研究方法: ContextCache采用两阶段检索架构：首先基于向量检索当前查询的潜在匹配，然后通过自注意力机制整合当前和历史对话表征，实现精确的上下文匹配。

研究结果: 实验表明，ContextCache在真实对话中比现有方法具有更高的精确率和召回率，缓存响应延迟比直接调用LLM低约10倍，显著降低计算成本。

研究结论: ContextCache通过上下文感知的语义缓存有效提升了多轮对话中的缓存命中准确性和效率，为LLM对话应用提供了显著的成本优化。

中文摘要: 语义缓存通过存储和重用大语言模型（LLM）响应，显著降低了计算成本并提高了效率。然而，现有系统主要依赖匹配单个查询，缺乏对多轮对话上下文的感知，导致类似查询出现在不同对话场景时出现错误的缓存命中。本文介绍了ContextCache，一种面向多轮对话的上下文感知语义缓存系统。ContextCache采用两阶段检索架构，首先对当前查询执行基于向量的检索以识别潜在匹配，然后通过自注意力机制整合当前和历史对话表征，实现精确的上下文匹配。对真实对话的评估表明，ContextCache相比现有方法提高了精确率和召回率。此外，缓存响应的延迟比直接调用LLM低约10倍，为LLM对话应用显著降低了计算成本。

</details>


### [20] [MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs](https://arxiv.org/abs/2506.22808)
**中文标题：MedEthicsQA：用于评估大型语言模型医学伦理表现的综合性问答基准**

*Jianhui Wei,Zijie Meng,Zikai Xiao,Tianxiang Hu,Yang Feng,Zhijie Zhou,Jian Wu,Zuozhu Liu*

主要分类: cs.CL

摘要简述: 本文介绍了MedEthicsQA，一个用于评估大型语言模型在医学伦理方面表现的综合性基准，包含5,623道选择题和5,351道开放性问题。研究发现当前医学大模型在伦理问题上的表现不如基础模型，揭示了医学伦理对齐的不足。


<details>
  <summary>详细信息</summary>
研究动机: 尽管医学大模型（MedLLMs）在临床任务中表现出巨大潜力，但其伦理安全性尚未得到充分研究。本文旨在填补这一空白，通过构建一个全面的医学伦理评估基准，揭示现有模型的伦理缺陷。

研究方法: 研究构建了MedEthicsQA基准，整合了全球医学伦理标准的分层分类法，涵盖广泛使用的医学数据集、权威题库和PubMed文献场景。通过多阶段筛选和多方面专家验证，确保数据集的可靠性（错误率2.72%）。

研究结果: 评估显示，当前医学大模型在回答医学伦理问题时表现不如其基础模型，表明其在医学伦理对齐方面存在不足。

研究结论: MedEthicsQA基准为医学伦理评估提供了可靠工具，揭示了医学大模型在伦理问题上的缺陷，为未来改进提供了方向。

中文摘要: 尽管医学大型语言模型（MedLLMs）在临床任务中展现出显著潜力，但其伦理安全性仍未得到充分探索。本文介绍了MedEthicsQA，一个综合性基准，包含5,623道选择题和5,351道开放性问题，用于评估大型语言模型在医学伦理方面的表现。我们系统性地建立了一个整合全球医学伦理标准的分层分类法。该基准涵盖了广泛使用的医学数据集、权威题库以及源自PubMed文献的场景。通过多阶段筛选和多方面专家验证的严格质量控制，确保了数据集的可靠性（错误率2.72%）。对当前医学大模型的评估显示，其在回答医学伦理问题时的表现不如其基础模型，揭示了医学伦理对齐的不足。该数据集以CC BY-NC 4.0许可证发布，可在https://github.com/JianhuiWei7/MedEthicsQA获取。

</details>


### [21] [Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models](https://arxiv.org/abs/2506.22813)
**中文标题：选择与合并：基于大语言模型的可适应与可扩展命名实体识别方法**

*Zhuojun Ding,Wei Wei,Chenghao Fan*

主要分类: cs.CL

摘要简述: 本文提出SaM框架，通过动态选择和合并预训练专家模型，提升命名实体识别（NER）任务的适应性和扩展性，无需额外训练即可优化目标领域性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统监督微调（SFT）方法在跨领域命名实体识别任务中成本高且缺乏适应性，现有统一模型难以兼顾多领域性能与扩展性。

研究方法: 提出SaM框架：1）基于领域相似性和实例性能选择预训练专家模型；2）动态合并专家模型以生成针对目标领域的任务专用模型。

研究结果: 在多个基准测试中，SaM框架平均性能优于统一模型10%，且支持灵活增减专家模型，扩展性强。

研究结论: SaM框架通过动态选择和合并专家模型，显著提升NER任务的跨领域适应性和扩展性，为未来改进和扩展提供了实践基础。

中文摘要: 监督微调（SFT）广泛用于将大语言模型（LLMs）与信息提取（IE）任务（如命名实体识别（NER））对齐。然而，标注此类细粒度标签并训练领域专用模型成本高昂。现有工作通常训练跨多个领域的统一模型，但此类方法缺乏适应性和扩展性，因为并非所有训练数据对目标领域有益，且扩展训练模型仍具挑战性。我们提出SaM框架，在推理时动态选择和合并专家模型。具体而言，针对目标领域，我们基于（i）领域相似性和（ii）采样实例性能，分别从现有领域预训练的专家模型中选择领域专用专家，随后合并这些专家以创建针对目标领域优化的任务专用模型。通过动态合并对目标领域有益的专家，我们无需额外训练即可提升跨领域泛化能力。此外，专家模型可便捷增减，扩展性极强。在多个基准测试上的广泛实验证明了我们框架的有效性，其平均性能优于统一模型10%。我们还进一步探讨了潜在改进、实践经验及框架扩展方向。

</details>


### [22] [Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization](https://arxiv.org/abs/2506.22846)
**中文标题：基于LLM的中间损失正则化提升CTC语音识别性能**

*Duygu Altinok*

主要分类: cs.CL

摘要简述: 本文提出了一种名为LAIL的新型辅助损失框架，通过利用大型语言模型（LLM）的语言知识增强基于CTC的自动语音识别（ASR）系统，解决了CTC模型在语言依赖性建模上的不足，同时保持了其高效解码的优势。


<details>
  <summary>详细信息</summary>
研究动机: 端到端（E2E）ASR系统中，基于注意力的编码器-解码器模型性能优越，但自回归解码限制了推理速度；而基于CTC的模型解码速度快，但语言依赖性建模能力较弱。本文旨在通过结合LLM的语言知识提升CTC模型的性能。

研究方法: 提出LAIL框架，通过在中间编码器层附加连接层，将输出映射到LLM的嵌入空间，并在训练时计算因果语言建模损失，从而增强语言建模能力。

研究结果: 在LibriSpeech、TEDLIUM2和WSJ语料库上，使用Conformer架构和LLaMA模型，显著降低了词错误率（WER），实现了基于CTC的ASR的先进性能。

研究结论: LAIL框架有效提升了CTC模型的性能，同时保持了其高效解码的优势，为实时ASR应用提供了新的解决方案。

中文摘要: 端到端（E2E）自动语音识别（ASR）系统通过将所有组件集成到单一神经网络中革新了该领域，其中基于注意力的编码器-解码器模型实现了最先进的性能。然而，其自回归解码过程限制了推理速度，使其不适用于实时应用。相比之下，基于CTC的模型提供更快的非自回归解码，但在语言依赖性建模上表现不佳。为解决这一问题，我们提出了一种名为语言感知中间损失（LAIL）的新型辅助损失框架，利用大型语言模型（LLM）的语言知识增强基于CTC的ASR。通过在中间编码器层附加连接层，LAIL将输出映射到LLM的嵌入空间，并在训练时计算因果语言建模损失。这种方法增强了语言建模能力，同时保留了CTC解码的计算效率。使用Conformer架构和多种LLaMA模型，我们在LibriSpeech、TEDLIUM2和WSJ语料库上显著降低了词错误率（WER），以最小的计算开销实现了基于CTC的ASR的最先进性能。

</details>


### [23] [Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems](https://arxiv.org/abs/2506.22852)
**中文标题：知识增强微调在RAG和基于代理的对话系统中的重要性**

*Yucheng Cai,Yuxuan Wu,Yi Huang,Junlan Feng,Zhijian Ou*

主要分类: cs.CL

摘要简述: 本文提出知识增强微调（KAFT）方法，通过在RAG和基于代理的对话系统中结合领域特定数据和外部知识微调大语言模型（LLMs），显著提升了事实准确性。实验证明KAFT优于传统提示方法。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLMs）在知识密集型对话场景中容易出错，尽管检索增强生成（RAG）和基于代理的方法通过外部知识库提升了事实准确性，但LLMs仍难以有效利用检索到的知识生成响应。

研究方法: 提出知识增强微调（KAFT），在RAG和基于代理的系统中，使用领域特定数据和外部知识对LLMs进行微调。基于MobileCS2数据集，系统比较了提示和KAFT技术的效果。

研究结果: 实验结果表明，KAFT在RAG和基于代理的系统中均显著优于提示方法，尤其在事实准确性方面表现突出。

研究结论: KAFT是首个实证研究知识增强微调的方法，为提升LLMs在知识密集型对话中的表现提供了有效解决方案。

中文摘要: 大语言模型（LLMs）最近被应用于对话系统。尽管取得进展，LLMs在知识密集型场景中仍容易出错。最近，基于检索增强生成（RAG）和代理的方法通过从外部知识库（KBs）检索知识来提升事实准确性。这主要通过向LLMs提供指令、示例和检索到的知识来实现。然而，LLMs可能难以有效利用检索到的知识生成响应，因为它们未针对特定领域进行充分训练。为解决这一问题，我们提出在RAG和基于代理的系统中，使用领域特定数据和外部知识对LLMs进行微调，称为知识增强微调（KAFT）。我们基于MobileCS2数据集（一个真实客户服务对话数据集，以知识密集型交互为特点），系统比较了提示和KAFT技术在RAG和基于代理的系统中的表现。实验结果表明，KAFT在RAG和代理系统中均显著优于提示方法，尤其在事实准确性方面。据我们所知，本文是首个实证研究KAFT思想的成果。

</details>


### [24] [DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues](https://arxiv.org/abs/2506.22853)
**中文标题：DICE-BENCH：评估大语言模型在多轮多方对话中的工具调用能力**

*Kyochul Jang,Donghyeon Lee,Kyusik Kim,Dongseok Heo,Taewhoo Lee,Woojeong Kim,Bongwon Suh*

主要分类: cs.CL

摘要简述: 现有工具调用基准测试仅关注单轮交互，忽略了真实场景的复杂性。为此，研究者提出了DICE-SCORE指标和DICE-BENCH框架，通过多轮多角色对话构建更真实的工具调用数据集，实验表明现有大语言模型仍需改进。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试主要针对单轮工具调用，无法反映真实场景中多轮、多角色对话的复杂性。研究者希望通过量化工具相关信息的分散程度，构建更贴近实际的评估框架。

研究方法: 研究者提出DICE-SCORE指标，评估工具信息（如函数名和参数值）在对话中的分散程度。基于此，开发了DICE-BENCH框架，通过工具图和多角色系统合成多轮对话，生成1,607个高DICE-SCORE实例。

研究结果: 实验对19个大语言模型进行了测试，结果显示现有模型在真实场景中的工具调用能力仍有显著不足。

研究结论: DICE-BENCH为工具调用能力的评估提供了更真实的基准，揭示了现有模型的局限性，并呼吁进一步改进以适应实际应用需求。

中文摘要: 现有的函数调用基准测试主要关注单轮交互，但忽略了真实场景的复杂性。为了量化现有基准测试对实际应用的覆盖程度，我们提出了DICE-SCORE指标，用于评估工具相关信息（如函数名称和参数值）在对话中的分散程度。通过DICE-SCORE分析现有基准测试，发现其得分显著偏低，表明需要更真实的场景。为填补这一空白，我们提出了DICE-BENCH框架，通过工具图（维护跨轮依赖关系）和多角色系统（增强对话自然性）合成对话，构建实用的函数调用数据集。最终数据集包含1,607个高DICE-SCORE实例。我们对19个大语言模型进行了DICE-BENCH实验，结果表明这些模型在实际场景中的有效部署仍需显著改进。我们的代码和数据均已公开：https://snuhcc.github.io/DICE-Bench/。

</details>


### [25] [Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions](https://arxiv.org/abs/2506.22858)
**中文标题：填补空白：保留实体的上下文感知ASR结构化转录**

*Duygu Altinok*

主要分类: cs.CL

摘要简述: 本文提出了一种新的训练方法，通过扩展ASR模型的语义上下文窗口，提升命名实体和数值数据的识别与格式化能力，显著降低了词错误率（WER）。


<details>
  <summary>详细信息</summary>
研究动机: 当前ASR系统（如Whisper）在命名实体和数值数据的识别与格式化方面表现不佳，影响了法律、金融和医疗等关键领域的语义理解。本文旨在通过改进训练方法解决这一问题。

研究方法: 通过在训练中引入重叠的上下文窗口（5秒重叠的30秒音频块），形成40秒的“有效语义窗口”，并重新分配跨边界的实体至右侧块。同时，训练数据中嵌入实体标签以学习特定类型的格式化。

研究结果: 在Spoken Wikipedia数据集上的实验表明，该方法显著提升了命名实体识别（NER）和实体格式化的性能，验证了上下文感知训练的有效性。

研究结论: 上下文感知训练能够有效解决ASR系统在长文本转录和复杂实体识别任务中的局限性，为关键领域提供了更准确的转录结果。

中文摘要: 自动语音识别（ASR）系统（如Whisper）虽然转录准确率高，但在命名实体和数值数据的识别与格式化方面表现不佳，尤其是在法律、金融和医疗等关键领域，这会增加词错误率（WER）并损害语义理解。我们提出了一种新的训练方法，通过在训练中添加重叠的上下文窗口来扩展ASR模型的语义上下文。具体而言，通过在30秒音频块的两侧滑动5秒重叠，形成一个40秒的“有效语义窗口”，从而提升实体识别和格式化的能力，同时将预测集中在中间的30秒内。为了解决跨块边界的实体问题，我们将这些实体完全分配到右侧块中，以确保正确的格式化。此外，通过在训练数据中嵌入实体标签，模型能够学习识别和特定类型的格式化。在Spoken Wikipedia数据集上的评估表明，我们的方法在命名实体识别（NER）和实体格式化等语义任务中均表现出性能提升。这些结果凸显了上下文感知训练在解决ASR系统长文本转录和复杂实体识别任务中的有效性。

</details>


### [26] [Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models](https://arxiv.org/abs/2506.22957)
**中文标题：智能体间心智理论：测试大型语言模型对对话伙伴的认知能力**

*Younwoo Choi,Changling Li,Yongjin Yang,Zhijing Jin*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型（LLMs）的对话伙伴意识（interlocutor awareness），即LLMs识别和适应对话伙伴身份和特征的能力。研究发现LLMs能可靠识别同类模型（如GPT和Claude），并通过案例展示了这种能力在多LLM协作中的潜力与安全风险。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLMs在多智能体和人机系统中的广泛应用，理解其对自身和对话伙伴的认知能力对确保可靠性和安全性至关重要。以往研究多关注LLMs的情境意识，而忽视了其对对话伙伴的识别和适应能力。本文旨在填补这一空白。

研究方法: 本文通过三个维度（推理模式、语言风格和对齐偏好）评估LLMs的对话伙伴意识，并开发了三个案例研究，展示其在多LLM协作中的实际应用与潜在风险。

研究结果: 研究发现LLMs能可靠识别同类模型（如GPT和Claude），并通过案例展示了对话伙伴意识在增强协作效率的同时，也带来了奖励操纵和越狱漏洞等安全风险。

研究结论: 对话伙伴意识在LLMs中具有双重性，既提升了协作潜力，也引入了新的安全挑战。未来需进一步研究并开发多智能体部署中的安全保障措施。

中文摘要: 随着大型语言模型（LLMs）在多智能体和人机系统中的广泛应用，理解其对自身上下文和对话伙伴的认知能力对确保可靠性能和稳健安全性至关重要。以往研究主要关注LLMs的情境意识（即识别其操作阶段和约束的能力），而忽视了其对对话伙伴身份和特征的识别与适应能力。本文将此能力形式化为对话伙伴意识，并首次对当代LLMs中该能力的涌现进行了系统评估。我们从三个维度（推理模式、语言风格和对齐偏好）考察了对话伙伴推断能力，结果表明LLMs能可靠识别同类模型（如GPT和Claude）。为展示其实际意义，我们开发了三个案例研究，表明对话伙伴意识既通过提示适应增强了多LLM协作，也引入了新的对齐和安全漏洞，包括奖励操纵行为和更高的越狱易感性。我们的发现凸显了LLMs中身份敏感行为的双重性，强调了对对话伙伴意识的进一步理解及多智能体部署中新保障措施的必要性。代码已开源：https://github.com/younwoochoi/InterlocutorAwarenessLLM。

</details>


### [27] [On the Generalizability of "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals"](https://arxiv.org/abs/2506.22977)
**中文标题：机制竞争的普遍性：探究语言模型如何处理事实与反事实**

*Asen Dotsinski,Udit Thakur,Marko Ivanov,Mohammad Hafeez Khan,Maria Heuss*

主要分类: cs.CL

摘要简述: 本文是对Ortu等人（2024）关于语言模型处理事实与反事实机制竞争研究的复现研究。成功复现了其关于事实与反事实信息定位、注意力块在机制竞争中的主导作用以及注意力头处理竞争信息的专门化等主要发现，并在GPT-2和Pythia 6.9B上验证了结果。研究进一步扩展到更大模型Llama 3.1 8B，发现注意力头专门化显著降低；通过改变提示结构，观察到反事实标记的logit显著下降；并验证了作者对特定领域提示的结论有效性。


<details>
  <summary>详细信息</summary>
研究动机: 复现并扩展Ortu等人（2024）的研究，探索语言模型中事实与反事实机制竞争的普遍性，验证其在更大模型、不同提示结构和特定领域中的适用性。

研究方法: 在GPT-2、Pythia 6.9B和Llama 3.1 8B上复现实验，分析注意力头专门化；通过改变提示结构（如避免重复反事实陈述或修改前提词）观察logit变化；测试特定领域提示对结果的影响。

研究结果: 在更大模型Llama 3.1 8B中，注意力头专门化显著降低；改变提示结构导致反事实标记logit下降；特定领域提示可能因提供事实预测标记而影响结果。

研究结论: Ortu等人（2024）提出的注意力头消融方法在数据集中代表性不足的领域效果有限，其有效性受模型架构、提示结构、领域和任务影响。

中文摘要: 本文是对“机制竞争：探究语言模型如何处理事实与反事实”（Ortu等人，2024）的复现研究，该研究探讨了语言模型中事实回忆与反事实上下文重复之间的机制竞争。我们成功复现了其关于事实与反事实信息定位、注意力块在机制竞争中的主导作用以及注意力头处理竞争信息的专门化等主要发现，并在GPT-2（Radford等人，2019）和Pythia 6.9B（Biderman等人，2023）上验证了结果。我们从三个重要方向扩展了其工作：首先，通过在Llama 3.1 8B（Grattafiori等人，2024）上复现实验，探索这些发现在更大模型中的普遍性，发现注意力头专门化显著降低；其次，通过引入避免重复反事实陈述或修改前提词的提示结构变体，观察到反事实标记的logit显著下降；最后，测试了作者对特定领域提示结论的有效性，发现某些类别的提示会因提供事实预测标记而影响结果。总体而言，我们发现Ortu等人（2024）提出的注意力头消融方法在数据集中代表性不足的领域效果有限，其有效性受模型架构、提示结构、领域和任务影响。

</details>


### [28] [A Systematic Study of Compositional Syntactic Transformer Language Models](https://arxiv.org/abs/2506.22978)
**中文标题：组合式句法Transformer语言模型的系统研究**

*Yida Zhao,Hao Xve,Xiang Hu,Kewei Tu*

主要分类: cs.CL

摘要简述: 本文系统研究了基于成分句法树的组合式句法Transformer语言模型，提出了统一框架并评估了多种变体，最终给出了设计建议。


<details>
  <summary>详细信息</summary>
研究动机: 现有组合式句法语言模型（SLMs）的设计选择缺乏系统性研究，本文旨在填补这一空白，通过统一框架分析现有模型并提出改进。

研究方法: 提出一个统一框架，涵盖现有组合式SLMs及其新变体，并在语言建模、句法泛化、摘要、对话和推理效率等方面进行全面实证评估。

研究结果: 实验结果表明，不同变体在不同任务中表现各异，基于结果提出了组合式SLMs的多个设计建议。

研究结论: 组合式SLMs的设计需综合考虑任务需求，本文提出的框架和建议为未来研究提供了指导。

中文摘要: 句法语言模型（SLMs）通过建模线性化句法分析树和表面句子，增强了Transformer的句法偏置能力。本文聚焦于基于成分句法树的组合式SLMs，其包含显式的自底向上成分表示组合。我们识别了现有组合式SLMs设计中的关键选择，并提出了一个统一框架，涵盖现有模型和新变体。我们对框架中的所有变体在语言建模、句法泛化、摘要、对话和推理效率等方面进行了全面实证评估。基于实验结果，我们提出了组合式SLMs设计的多个建议。代码发布于https://github.com/zhaoyd1/compositional_SLMs。

</details>


### [29] [SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions](https://arxiv.org/abs/2506.23046)
**中文标题：SoMi-ToM：具身社交互动中多视角心智理论的评估**

*Xianzhe Fan,Xuhui Zhou,Chuanyang Jin,Kolby Nottingham,Hao Zhu,Maarten Sap*

主要分类: cs.CL

摘要简述: 论文提出SoMi-ToM基准，用于评估多视角心智理论在具身多智能体复杂社交互动中的表现，发现当前大型视觉语言模型在实时状态推断和全局目标推断上显著落后于人类。


<details>
  <summary>详细信息</summary>
研究动机: 现有心智理论（ToM）基准多基于静态文本场景，与真实动态社交互动存在显著差距。因此，作者提出SoMi-ToM基准，旨在通过多模态数据和多视角评估，更全面地检验模型在具身复杂社交互动中的ToM能力。

研究方法: 基于SoMi交互环境生成多模态数据，支持第一人称（实时状态推断）和第三人称（全局目标推断）多级评估。数据集包含35段第三人称视频、363张第一人称图像和1225道专家标注选择题。

研究结果: 实验显示，大型视觉语言模型（LVLMs）在SoMi-ToM上的表现显著低于人类：第一人称评估平均准确率差距为40.1%，第三人称评估为26.4%。

研究结论: 当前LVLMs在具身复杂社交互动中的ToM能力仍需大幅提升，未来研究需进一步优化模型的多视角推理能力。

中文摘要: 人类通过感知动态现实社交互动中的环境，持续推断他人的状态、目标和行为。然而，大多数心智理论（ToM）基准仅评估静态文本场景，与真实互动存在显著差距。我们提出SoMi-ToM基准，旨在评估具身多智能体复杂社交互动中的多视角ToM。该基准基于SoMi交互环境生成的多模态数据，涵盖多样化任务目标和社会关系。我们的框架支持多级评估：（1）第一人称评估提供任务中的多模态（视觉、对话、动作等）输入，用于实时状态推断；（2）第三人称评估提供任务后的完整第三人称视频和文本记录，用于目标和行为推断。这种评估方法能够从主观即时体验和客观全局观察两方面更全面地检验模型的ToM能力。我们构建了一个包含35段第三人称视频、363张第一人称图像和1225道专家标注选择题（三个选项）的挑战性数据集。在该数据集上，我们系统评估了人类受试者和多个前沿大型视觉语言模型（LVLMs）的表现。结果显示，LVLMs在SoMi-ToM上的表现显著低于人类：第一人称评估的平均准确率差距为40.1%，第三人称评估为26.4%。这表明未来LVLMs需进一步提升其在具身复杂社交互动中的ToM能力。

</details>


### [30] [MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition](https://arxiv.org/abs/2506.23051)
**中文标题：MariNER：巴西葡萄牙语历史命名实体识别数据集**

*João Lucas Luz Lima Sarcinelli,Marina Lages Gonçalves Teixeira,Jade Bortot de Paiva,Diego Furtado Silva*

主要分类: cs.CL

摘要简述: 本文介绍了MariNER数据集，这是首个针对20世纪初巴西葡萄牙语的历史文本命名实体识别（NER）黄金标准数据集，包含9000多句手动标注的句子，并评估了先进NER模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管英语等语言拥有大量高质量的NER资源，但巴西葡萄牙语在此领域的黄金标准数据集仍显不足，尤其是在历史文本分析方面。本文旨在填补这一空白，为数字人文学科中的历史文本分析提供支持。

研究方法: 研究团队构建了MariNER数据集，包含9000多句20世纪初巴西葡萄牙语历史文本的手动标注句子，并评估了多种先进NER模型在该数据集上的表现。

研究结果: MariNER数据集成为首个针对巴西葡萄牙语历史文本的黄金标准NER资源，实验结果显示，现有NER模型在该数据集上的表现存在差异，为未来研究提供了基准。

研究结论: MariNER填补了巴西葡萄牙语历史文本NER资源的空白，为数字人文学科的研究提供了重要工具，同时展示了现有模型的改进空间。

中文摘要: 命名实体识别（NER）是一项基本的自然语言处理任务，旨在识别和分类文本中不同类别的实体提及。尽管英语等语言拥有大量高质量的NER资源，但巴西葡萄牙语在此领域的黄金标准数据集仍显不足，尤其是在特定领域。本文特别关注NER在数字人文学科中分析历史文本的重要性。为填补这一空白，本研究构建了MariNER：\textit{Mapeamento e Anota\c{c}\~oes de Registros hIst\'oricos para NER}（历史记录映射与标注用于NER），这是首个针对20世纪初巴西葡萄牙语的黄金标准数据集，包含9000多句手动标注的句子。我们还评估并比较了先进NER模型在该数据集上的性能。

</details>


### [31] [Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning](https://arxiv.org/abs/2506.23056)
**中文标题：通过知识增强的树搜索推理提升大型语言模型的分子结构解析能力**

*Xiang Zhuang,Bin Wu,Jiyu Cui,Kehua Feng,Xiaotong Li,Huabin Xing,Keyan Ding,Qiang Zhang,Huajun Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种知识增强的分子结构解析框架（K-MSE），通过结合蒙特卡洛树搜索和外部分子子结构知识库，显著提升了大型语言模型（LLMs）在分子结构解析任务中的性能，实验结果显示性能提升超过20%。


<details>
  <summary>详细信息</summary>
研究动机: 分子结构解析是化学实验分析中的关键任务，但现有的大型语言模型（LLMs）由于缺乏专业化学知识，在此任务中表现不佳。本文旨在通过知识增强和优化推理过程来解决这一问题。

研究方法: 提出K-MSE框架，构建外部分子子结构知识库以扩展LLMs的化学结构覆盖范围，并设计分子-光谱评分器作为推理过程的奖励模型，结合蒙特卡洛树搜索进行测试时扩展。

研究结果: 实验结果表明，K-MSE框架显著提升了LLMs在分子结构解析任务中的性能，尤其是在GPT-4o-mini和GPT-4o上实现了超过20%的性能提升。

研究结论: 通过知识增强和优化推理过程，K-MSE框架有效解决了LLMs在分子结构解析任务中的局限性，为化学领域的自动化分析提供了新思路。

中文摘要: 分子结构解析是从多种光谱数据中推断分子结构的过程，是化学实验分析中的关键任务。尽管大型语言模型（LLMs）在复杂任务的分析和推理中表现出色，但在分子结构解析中仍面临重大挑战。我们发现这些挑战主要源于LLMs对专业化学知识的掌握有限。为此，我们提出了一种知识增强的分子结构解析推理框架（K-MSE），利用蒙特卡洛树搜索作为插件进行测试时扩展。具体而言，我们构建了一个外部分子子结构知识库，以扩展LLMs对化学结构空间的覆盖范围。此外，我们设计了一个专门的分子-光谱评分器作为推理过程的奖励模型，解决了LLMs在解决方案评估中的不准确问题。实验结果表明，我们的方法显著提升了性能，尤其是在GPT-4o-mini和GPT-4o上实现了超过20%的性能提升。代码已开源：https://github.com/HICAI-ZJU/K-MSE。

</details>


### [32] [Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries](https://arxiv.org/abs/2506.23071)
**中文标题：Text2VectorSQL：桥接Text-to-SQL与向量搜索，实现统一自然语言查询**

*Zhengren Wang,Bozhou Li,Dongwen Yao,Wentao Zhang*

主要分类: cs.CL

摘要简述: 本文提出Text2VectorSQL框架，结合Text-to-SQL与向量搜索，支持更灵活的自然语言查询，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: Text-to-SQL在处理非结构化数据或模糊查询时表现受限，而向量搜索虽强大但依赖人工且缺乏评估框架。本文旨在结合两者优势，填补理论与实践的鸿沟。

研究方法: 提出Text2VectorSQL框架，支持语义过滤、多模态匹配和检索加速；通过构建向量索引、扩展查询语义及自动标注数据实现评估。

研究结果: 实验表明，Text2VectorSQL在合成数据上显著优于基线方法，为更直观的数据库交互奠定基础。

研究结论: Text2VectorSQL为统一自然语言查询提供了新范式，推动了数据库接口的多样化和易用性。

中文摘要: 尽管Text-to-SQL实现了与结构化数据库的自然语言交互，但其在处理非结构化数据或模糊查询时因语法僵化和表达受限而效果不佳。与此同时，向量搜索作为一种强大的语义检索范式，尤其适用于非结构化数据。然而，现有的VectorSQL实现仍依赖人工构建且缺乏专门评估框架，导致理论与实际部署之间存在显著差距。为桥接这两种互补范式，本文提出Text2VectorSQL，一种统一Text-to-SQL与向量搜索的新框架，以突破表达限制并支持更全面多样的自然语言查询。具体而言，Text2VectorSQL支持语义过滤、多模态匹配和检索加速。为评估性能，我们在合适列上构建向量索引，通过语义搜索扩展用户查询，并通过专家审核的自动流程标注真实数据。此外，我们利用合成数据开发专用Text2VectorSQL模型，证明其性能显著优于基线方法。本研究为Text2VectorSQL任务奠定了基础，为更通用直观的数据库接口铺平了道路。代码库将在https://github.com/Open-DataFlow/Text2VectorSQL公开。

</details>


### [33] [From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship](https://arxiv.org/abs/2506.23101)
**中文标题：从个体到互动：基于社会关系视角的多模态大语言模型性别偏见评测**

*Yue Xu,Wenjie Wang*

主要分类: cs.CL

摘要简述: 本文提出Genres基准，用于评估多模态大语言模型（MLLMs）在双人互动中的性别偏见，揭示单场景评测无法发现的上下文敏感偏见。


<details>
  <summary>详细信息</summary>
研究动机: 现有评测主要关注单场景下的性别偏见，忽略了人际互动中可能隐含的微妙偏见。本文旨在填补这一空白，通过社会关系视角深入分析MLLMs中的性别偏见。

研究方法: 提出Genres基准，通过双人角色档案和叙事生成任务，捕捉丰富的人际动态，支持多维度细粒度偏见评测。实验涵盖开源和闭源MLLMs。

研究结果: 实验发现MLLMs在双人互动中存在持续且上下文敏感的性别偏见，这些偏见在单角色场景中未被发现。

研究结论: 关系感知的评测对诊断MLLMs中互动驱动的微妙性别偏见至关重要，并为未来偏见缓解提供了可行建议。

中文摘要: 多模态大语言模型（MLLMs）在涉及视觉和文本模态的任务中表现出色，但其可能编码和放大性别偏见的担忧日益增长，尤其是在社会敏感应用中。现有评测主要关注孤立场景下的偏见，忽视了人际互动中可能隐含的微妙偏见。本文填补了这一空白，超越单实体评测，聚焦于双人互动中的关系和上下文性别偏见。我们提出Genres基准，通过社会关系视角评估MLLMs生成的叙事中的性别偏见。Genres通过双角色档案和叙事生成任务捕捉丰富的人际动态，支持多维度细粒度偏见评测。对开源和闭源MLLMs的实验揭示了持续且上下文敏感的性别偏见，这些偏见在单角色场景中未被发现。我们的发现强调了关系感知评测对诊断MLLMs中互动驱动的微妙性别偏见的重要性，并为未来偏见缓解提供了可行建议。

</details>


### [34] [FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes](https://arxiv.org/abs/2506.23111)
**中文标题：FairI Tales：以偏见和刻板印象为重点的印度公平性评估**

*Janki Atul Nawale,Mohammed Safi Ur Rahman Khan,Janani D,Mansi Gupta,Danish Pruthi,Mitesh M. Khapra*

主要分类: cs.CL

摘要简述: 该研究针对印度文化多样性，提出了INDIC-BIAS基准，评估了14种大型语言模型在85个印度身份群体中的公平性，发现模型对边缘化群体存在强烈偏见并强化刻板印象，呼吁谨慎使用。


<details>
  <summary>详细信息</summary>
研究动机: 现有公平性研究主要基于西方文化，无法满足印度等文化多样性国家的需求，因此需要开发印度本土的公平性评估工具。

研究方法: 研究通过咨询领域专家，收集了1800多个社会文化主题，生成了2万个真实场景模板，并将其分为合理性、判断和生成三个任务，评估了14种流行大型语言模型的公平性。

研究结果: 评估结果显示，模型对边缘化身份群体存在显著负面偏见，并频繁强化刻板印象，即使明确要求模型解释决策，其偏见仍难以缓解。

研究结论: 研究揭示了当前大型语言模型可能对印度身份群体造成的分配和表征伤害，建议在实际应用中谨慎使用，并开源了INDIC-BIAS基准以推动相关研究。

中文摘要: 现有的公平性研究主要集中于西方文化，难以适用于印度这样的文化多样性国家。为填补这一空白，我们提出了INDIC-BIAS，一个全面的印度本土基准，用于评估大型语言模型在85个身份群体（涵盖种姓、宗教、地区和部落）中的公平性。我们首先咨询领域专家，收集了1800多个可能引发偏见和刻板印象的社会文化主题。基于这些主题，我们生成并手动验证了2万个真实场景模板，以测试模型的公平性。这些模板被分为合理性、判断和生成三个评估任务。我们对14种流行大型语言模型的评估显示，模型对边缘化身份群体存在强烈负面偏见，并频繁强化常见刻板印象。此外，即使明确要求模型解释决策，其偏见仍难以缓解。我们的评估提供了证据，表明当前大型语言模型可能对印度身份群体造成分配和表征伤害，呼吁在实际应用中更加谨慎。我们开源了INDIC-BIAS基准，以推动印度背景下偏见和刻板印象的评估与缓解研究。

</details>


### [35] [Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models](https://arxiv.org/abs/2506.23122)
**中文标题：解码迷因：多语言和多模态模型中叙事角色分类的基准测试**

*Shivam Sharma,Tanmoy Chakraborty*

主要分类: cs.CL

摘要简述: 本文研究了在多语言和多模态模型中识别网络迷因中叙事角色（英雄、反派、受害者和他人）的任务，通过评估多种模型在零样本设置下的表现，揭示了文化背景和提示设计对任务的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 网络迷因中的叙事角色识别是一个具有挑战性的任务，尤其是在多语言和文化多样性的背景下。本文旨在通过扩展数据集和评估多种模型，探索如何更准确地识别这些角色，并揭示文化差异和语言混合对任务的影响。

研究方法: 研究使用了三个多样化的测试集（包括英语和英语-印地语混合语言），评估了多种模型，包括微调的多语言变换器、情感和滥用感知分类器、指令调优的大语言模型以及多模态视觉语言模型。性能通过精确率、召回率和F1分数在零样本设置下进行评估。

研究结果: 结果显示，较大的模型（如DeBERTa-v3和Qwen2.5-VL）表现较好，但在识别“受害者”角色和跨文化及混合语言内容时仍存在挑战。混合提示设计（结合结构化指令和角色定义）带来了小幅但一致的改进。

研究结论: 研究强调了文化背景、提示工程和多模态推理在建模视觉-文本内容中微妙叙事框架时的重要性，为未来研究提供了方向。

中文摘要: 本研究探讨了在互联网迷因中识别叙事角色（英雄、反派、受害者和他人）这一具有挑战性的任务，覆盖了英语和英语-印地语混合语言的三个多样化测试集。基于一个原本偏向“他人”类别的标注数据集，我们探索了一个更平衡且语言多样化的扩展版本，该版本最初作为CLEF 2024共享任务的一部分引入。全面的词汇和结构分析突出了真实迷因中使用的微妙、文化特定且上下文丰富的语言，与合成的仇恨内容（具有明确和重复的词汇标记）形成对比。为了对角色检测任务进行基准测试，我们评估了多种模型，包括微调的多语言变换器、情感和滥用感知分类器、指令调优的大语言模型以及多模态视觉语言模型。性能在零样本设置下通过精确率、召回率和F1分数进行评估。尽管较大的模型（如DeBERTa-v3和Qwen2.5-VL）表现出显著提升，但结果揭示了在可靠识别“受害者”类别和跨文化及混合语言内容泛化方面的一致挑战。我们还探索了提示设计策略以指导多模态模型，发现结合结构化指令和角色定义的混合提示带来了小幅但一致的改进。我们的发现强调了文化基础、提示工程和多模态推理在建模视觉-文本内容中微妙叙事框架时的重要性。

</details>


### [36] [Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2506.23127)
**中文标题：通过强化学习释放大型语言模型在具身任务规划中的能力**

*Zhaoye Fei,Li Ji,Siyin Wang,Junhao Shi,Jingjing Gong,Xipeng Qiu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Embodied Planner-R1的新型强化学习框架，通过自主探索和交互式策略优化，显著提升了大型语言模型在具身任务规划中的表现，并在两个基准测试中取得了优异的成绩。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在具身任务规划中面临挑战，尤其是在需要持续环境理解和动作生成的部分可观测环境中。现有方法基于静态知识生成开环动作脚本，难以学习动作与环境反馈之间的因果关系。

研究方法: Embodied Planner-R1框架包含三项创新：(1) 无人工标注的纯强化学习与并行探索；(2) 完成驱动的稀疏奖励；(3) 交互式策略优化（IPO）从分组轨迹中高效学习。

研究结果: 在ALFWorld和ScienceWorld两个基准测试中，Embodied Planner-R1分别取得了97.78%和79.92%的完成率，远超现有方法，且在未见环境中仅下降3.66%，表现出强大的泛化能力。

研究结论: Embodied Planner-R1通过强化学习和交互式策略优化，显著提升了LLMs在具身任务规划中的能力，为未来研究提供了新的方向。

中文摘要: 大型语言模型（LLMs）在各种任务中表现出色，但在需要持续环境理解和动作生成的具身任务规划场景中面临重大挑战。现有方法基于静态知识生成开环动作脚本，难以学习动作与环境反馈之间的因果关系，尤其是在部分可观测环境中。我们提出了Embodied Planner-R1，一种新型结果驱动的强化学习框架，通过最小监督的自主探索，使LLMs具备交互能力。该框架包含三项关键创新：(1) 无人工标注的纯强化学习与并行探索；(2) 完成驱动的稀疏奖励；(3) 交互式策略优化（IPO）从分组轨迹中高效学习。在两个基于文本的具身规划基准测试中，Embodied Planner-R1在ALFWorld和ScienceWorld上分别取得了97.78%和79.92%的完成率，远超现有方法，且在未见环境中仅下降3.66%，表现出强大的泛化能力。

</details>


### [37] [Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format](https://arxiv.org/abs/2506.23133)
**中文标题：格式适配器：通过适配合适格式提升大语言模型的推理能力**

*Dingzirui Wang,Xuanliang Zhang,Rongyu Cao,Longxu Dou,Xianzhen Luo,Yingwei Ma,Qingfu Zhu,Wanxiang Che,Binhua Li,Fei Huang,Yongbin Li*

主要分类: cs.CL

摘要简述: 本文提出Format-Adapter方法，通过生成和选择适合任务的推理格式，提升大语言模型（LLMs）的推理能力，实验表明其性能平均提升4.3%。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖人工标注的推理格式，不仅成本高且可能不适用于所有任务。本文旨在通过自动生成和选择格式，解决这一问题。

研究方法: 首先提出衡量生成多答案时推理误差的方法，然后引入Format-Adapter，利用LLMs生成并选择最优推理格式以最小化误差。

研究结果: 在数学和常识推理任务中，Format-Adapter平均性能提升4.3%，优于现有方法。

研究结论: Format-Adapter通过自动适配推理格式，显著提升了LLMs的推理能力，且无需依赖人工标注。

中文摘要: 生成和投票多个答案是缓解大语言模型（LLMs）推理不一致性的有效方法。先前研究表明，使用多种推理格式生成多答案时优于单一格式。然而，现有方法依赖人工标注的格式，可能不适用于所有任务且标注成本高。为解决这一问题，我们通过生成和选择格式来适配任务。首先提出衡量生成多答案时推理误差的方法，然后引入Format-Adapter，利用LLMs生成并选择最优推理格式以最小化误差。在数学和常识推理任务上的实验表明，Format-Adapter平均性能提升4.3%，优于现有方法，验证了其有效性。

</details>


### [38] [LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation](https://arxiv.org/abs/2506.23136)
**中文标题：基于结构化数据感知检索增强生成的LLM辅助技术文档问答**

*Shadman Sobhan,Mohammad Ariful Haque*

主要分类: cs.CL

摘要简述: 本文提出了一种改进的RAG（检索增强生成）流程，能够处理技术文档中的表格和图像，结合向量相似性搜索和基于Gemma-2-9b-it的重新排序器，显著提升了问答的准确性和相关性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在自然语言理解和生成方面表现优异，但存在幻觉和知识过时的问题。传统的RAG流程在处理复杂技术文档（如包含表格和图像）时效果不佳，因此需要一种更高效的解决方案。

研究方法: 提出了一种改进的RAG流程，结合向量相似性搜索和基于Gemma-2-9b-it的重新排序器，使用RAFT（检索增强微调）在自定义数据集上训练，以优化上下文识别。

研究结果: 实验表明，该流程在忠实度（RAGas 94%，DeepEval 96%）和答案相关性（RAGas 87%，DeepEval 93%）方面表现优异，尤其在处理表格问题和上下文外问题时优于传统RAG流程。

研究结论: 该改进的RAG流程显著提升了技术文档问答的准确性和效率，为复杂文档处理提供了有效解决方案。

中文摘要: 大型语言模型（LLMs）具备自然语言理解和生成能力，但仍面临幻觉和知识过时等挑战。微调是一种可能的解决方案，但资源密集且需随数据更新重复进行。检索增强生成（RAG）通过允许LLMs访问外部知识源提供了一种高效解决方案。然而，传统RAG流程在处理包含表格和图像等结构化数据的复杂技术文档时效果不佳。本文提出了一种改进的RAG流程，能够处理扫描和可搜索格式的技术文档中的表格和图像。其检索过程结合了向量相似性搜索和基于Gemma-2-9b-it的重新排序器。重新排序器使用RAFT（检索增强微调）在自定义数据集上训练，以优化问答的上下文识别。评估结果显示，该流程在忠实度（RAGas 94%，DeepEval 96%）和答案相关性（RAGas 87%，DeepEval 93%）方面表现优异。对比分析表明，该架构在处理表格问题和上下文外问题时优于传统RAG流程。

</details>


### [39] [Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion](https://arxiv.org/abs/2506.23137)
**中文标题：基于流调制的语义感知知识图谱补全评分**

*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

主要分类: cs.CL

摘要简述: 提出了一种名为Flow-Modulated Scoring（FMS）的新框架，通过结合上下文感知的静态表示和动态信息，显著提升了知识图谱补全（KGC）中对多面关系的建模能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的知识图谱补全方法大多基于静态嵌入评分，难以捕捉上下文依赖和关系动态性，因此需要一种能够动态建模关系语义的新方法。

研究方法: FMS框架包含两个主要模块：1）语义上下文学习模块，用于编码上下文敏感的实体表示；2）条件流匹配模块，学习从头部嵌入到尾部嵌入的动态转换，生成预测向量场以动态优化初始静态评分。

研究结果: 在多个标准基准测试中，FMS方法超越了现有最先进技术的结果，验证了其在关系语义建模上的优越性。

研究结论: FMS通过结合上下文感知的静态表示和动态信息，显著提升了知识图谱补全中对多面关系的建模能力，为未来研究提供了新方向。

中文摘要: 有效的多面关系建模对知识图谱补全（KGC）至关重要。然而，现有方法大多基于静态嵌入评分，难以捕捉上下文依赖和关系动态性。为此，我们提出了Flow-Modulated Scoring（FMS）框架。FMS包含两个主要组件：1）语义上下文学习模块，用于编码上下文敏感的实体表示；2）条件流匹配模块，学习从头部嵌入到尾部嵌入的动态转换，生成预测向量场以动态优化初始静态评分。通过结合上下文感知的静态表示和动态信息，FMS实现了对关系语义的更深入建模。在多个标准基准测试中，FMS方法超越了现有最先进技术的结果。

</details>


### [40] [Benchmarking Deep Search over Heterogeneous Enterprise Data](https://arxiv.org/abs/2506.23139)
**中文标题：异构企业数据上的深度搜索基准测试**

*Prafulla Kumar Choubey,Xiangyu Peng,Shilpa Bhagavath,Kung-Hsiang Huang,Caiming Xiong,Chien-Sheng Wu*

主要分类: cs.CL

摘要简述: 本文提出了一种新的深度搜索基准测试，用于评估在异构企业数据上的检索增强生成（RAG）性能。基准测试包含多跳推理和多样化数据源，实验显示现有方法在检索环节表现不佳，导致性能下降。


<details>
  <summary>详细信息</summary>
研究动机: 当前检索增强生成（RAG）方法在处理异构企业数据时表现不佳，尤其是在多跳推理和多样化数据源（如文档、会议记录、Slack消息等）上。因此，需要一种新的基准测试来评估和改进深度搜索能力。

研究方法: 通过合成数据管道模拟企业业务流程（如产品规划、开发和支持），生成包含噪声和互联内容的数据集，并设计多跳问题。基准测试包含可回答和不可回答的查询，以及39,190个企业数据样本。

研究结果: 实验表明，即使性能最佳的RAG方法在基准测试中的平均得分仅为32.96。检索环节是主要瓶颈，现有方法难以完成深度搜索和获取全部必要证据，导致推理基于部分上下文，性能显著下降。

研究结论: 深度搜索在异构企业数据上仍面临挑战，尤其是检索环节的不足限制了RAG系统的性能。未来研究需改进检索方法以提升多跳推理能力。

中文摘要: 本文提出了一种新的深度搜索基准测试，用于评估检索增强生成（RAG）的性能。这种搜索形式需要基于多跳推理和多样化数据源（如文档、会议记录、Slack消息、GitHub和URL等）的源感知能力。我们通过合成数据管道模拟企业业务流程，生成包含噪声和互联内容的数据集，并设计多跳问题。基准测试包含可回答和不可回答的查询，以及39,190个企业数据样本，支持对长上下文LLM和RAG系统的细粒度评估。实验表明，即使性能最佳的RAG方法在基准测试中的平均得分仅为32.96。进一步分析显示，检索是主要瓶颈：现有方法难以完成深度搜索和获取全部必要证据，导致推理基于部分上下文，性能显著下降。

</details>


### [41] [Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions](https://arxiv.org/abs/2506.23146)
**中文标题：学习到上下文斜率：超越性能幻觉的上下文学习有效性评估**

*Dingzriui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“学习到上下文斜率”（LCS）的新指标，用于量化上下文学习（ICL）的有效性，解决了现有性能评估方法的局限性，并在实验中验证了其可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 上下文学习（ICL）在不同模型和任务中的效果差异显著，而现有的评估方法依赖性能变化，存在可靠性低、归因性差以及在数据不足场景下不实用的问题。因此，需要一种更可靠的指标来评估ICL的实际效果。

研究方法: 提出LCS指标，通过建模学习增益（通过演示减少的损失）与上下文相关性（演示与输入的相关性）之间的斜率来量化ICL有效性。LCS解决了性能指标的三大局限：捕捉连续损失变化、归因ICL失败原因、减少对标注数据的依赖。

研究结果: 实验表明，LCS在标注数据场景中与性能改进高度相关，在数据偏斜或稀缺场景中也能可靠反映ICL的真实效果。进一步分析揭示了LCS的实用阈值和影响ICL成功的关键模型能力。

研究结论: LCS是一种可靠且实用的ICL有效性评估指标，能够克服现有方法的局限性，并为实践者提供可操作的指导。

中文摘要: 上下文学习（ICL）已成为提升大型语言模型（LLM）性能的有效方法。然而，其效果因模型和任务而异，使得实践者难以确定ICL何时能可靠提升性能。当前依赖ICL应用后性能变化的评估方法存在可靠性低、归因性差以及在数据不足场景下不实用的问题。我们提出了“学习到上下文斜率”（LCS），这是一种通过建模学习增益（通过演示减少的损失）与上下文相关性（演示与输入的相关性）之间的斜率来量化ICL有效性的新指标。LCS解决了性能指标的三大关键局限：（1）即使输出错误，也能捕捉连续的损失变化，提高可靠性；（2）其公式将ICL失败归因于上下文对齐弱（无法将输入适应演示）或输出校准强（自我验证正确性）；（3）通过合成评估最小化对标注数据的依赖。大量实验表明，LCS在标注数据场景中与性能改进高度相关，在数据偏斜或稀缺场景中也能可靠反映ICL的真实效果。进一步分析揭示了LCS的实用阈值和影响ICL成功的关键模型能力。

</details>


### [42] [V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy](https://arxiv.org/abs/2506.23149)
**中文标题：V-SYNTHESIS：通过V-熵从零开始合成与任务无关的一致且多样的上下文演示**

*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

主要分类: cs.CL

摘要简述: 本文提出了一种名为V-Synthesis的方法，用于从零开始合成与任务无关且一致多样的上下文学习演示，通过V-熵和V-Score确保一致性和多样性，实验表明其性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 由于上下文学习（ICL）演示的高标注成本，现有方法多为任务特定或依赖已有演示，本文旨在从零开始合成适用于任意任务的演示，并解决缺乏标注指导导致的合成偏差问题。

研究方法: 提出V-Score作为一致性度量标准，其性能和计算成本优于基于n-gram或嵌入向量的方法；进一步提出V-Synthesis，利用V-Score进行比例采样以确保合成演示的一致性和多样性。

研究结果: 实验结果显示，V-Synthesis平均性能提升2.0%，验证了其有效性。

研究结论: V-Synthesis能够高效合成一致且多样的演示，为上下文学习提供了更优的解决方案。

中文摘要: 上下文学习（ICL）演示的高标注成本促使利用大语言模型（LLM）进行合成以降低开销。然而，现有合成方法多为任务特定或依赖已有演示。因此，本文专注于从零开始为任意任务合成演示。从零合成的主要挑战是确保与目标任务的一致性，因为缺乏标注指导可能导致合成偏差。我们首先提出一种称为V-Score的一致性度量标准，其性能和计算成本优于基于n-gram或嵌入向量的方法。此外，我们引入V-Synthesis，利用V-Score进行比例采样以确保合成演示的高一致性和多样性。实验结果表明，V-Synthesis平均性能提升2.0%，优于现有合成方法，验证了其有效性。

</details>


### [43] [RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams](https://arxiv.org/abs/2506.23192)
**中文标题：RiverText：一个用于从文本数据流中训练和评估增量词嵌入的Python库**

*Gabriel Iturra-Bocaz,Felipe Bravo-Marquez*

主要分类: cs.CL

摘要简述: 本文介绍了RiverText，一个用于从文本数据流中训练和评估增量词嵌入的Python库，解决了传统静态词嵌入无法适应语言动态变化的问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统词嵌入模型因其静态特性无法适应语言动态变化（如社交媒体中的新词汇），因此需要增量词嵌入算法来动态更新词表示。

研究方法: RiverText库实现了多种增量词嵌入技术（如Skip-gram、CBOW和Word Context Matrix），采用PyTorch作为神经网络训练后端，并设计了适用于流式场景的评估模块。

研究结果: 库中方法在不同超参数设置下进行了比较，结果展示了增量词嵌入在流式数据中的有效性。

研究结论: RiverText为信息检索和自然语言处理社区提供了处理流式词嵌入的工具，支持动态语言模式适应。

中文摘要: 词嵌入已成为信息检索和自然语言处理任务（如排序、文档分类和问答）中的重要组成部分。然而，尽管其广泛应用，传统词嵌入模型因其静态特性存在局限性，无法适应语言动态变化（如社交媒体中的新标签或品牌名称）。为解决这一问题，增量词嵌入算法被引入，能够动态更新词表示以应对新语言模式并处理连续数据流。本文介绍了RiverText，一个用于从文本数据流中训练和评估增量词嵌入的Python库。该工具为信息检索和自然语言处理社区提供了处理流式词嵌入的资源，例如分析社交媒体。库中实现了多种增量词嵌入技术（如Skip-gram、连续词袋模型和词上下文矩阵），并采用PyTorch作为神经网络训练后端。此外，我们还设计了一个模块，将现有的静态词嵌入评估任务（如词相似性和词分类）适配到流式场景。最后，我们对不同超参数设置下的方法进行了比较并讨论了结果。我们的开源库可在https://github.com/dccuchile/rivertext获取。

</details>


### [44] [Generalist Reward Models: Found Inside Large Language Models](https://arxiv.org/abs/2506.23235)
**中文标题：通用奖励模型：潜藏于大型语言模型内部**

*Yi-Chen Li,Tian Xu,Yang Yu,Xuqin Zhang,Xiong-Hui Chen,Zhongxiang Ling,Ningjing Chao,Lei Yuan,Zhi-Hua Zhou*

主要分类: cs.CL

摘要简述: 研究发现，通过标准的下一个词预测训练的大型语言模型（LLM）内部已隐含一个强大的通用奖励模型，无需额外训练即可直接提取高质量奖励信号。理论证明其与离线逆向强化学习等效，并通过实验验证其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前LLM的对齐依赖于昂贵的人类偏好数据训练的奖励模型，而现有AI反馈方法缺乏理论支持。本文旨在证明LLM内部已隐含通用奖励模型，无需额外训练即可实现高效对齐。

研究方法: 通过理论分析，证明标准训练的LLM内部隐含的奖励模型与离线逆向强化学习等效，可直接提取高质量奖励信号，并用于强化学习以优化模型策略。

研究结果: 实验表明，该方法不仅优于现有的LLM作为评判的方法，还能超越显式训练的奖励模型，验证了理论的正确性。

研究结论: 研究提出了一种高效、可扩展的LLM对齐新范式，无需额外训练奖励模型，直接利用预训练知识实现更优性能。

中文摘要: 大型语言模型（LLM）的对齐严重依赖于基于昂贵人类偏好数据训练的奖励模型。尽管近期研究尝试通过AI反馈绕过这一成本，但这些方法往往缺乏严格的理论基础。本文发现，通过标准下一个词预测训练的LLM内部已隐含一个强大的通用奖励模型。我们证明这种内生奖励并非启发式方法，而是与通过离线逆向强化学习学习的奖励函数理论等效。这一联系使我们能够直接从基础模型（预训练或监督微调模型）中提取高质量奖励信号，无需进一步训练。关键的是，我们还证明，使用这种内生奖励进行后续强化学习可以生成一个在误差界上优于基础模型的策略。据我们所知，这是首个关于强化学习对LLM有效性的理论证明。实验验证了这一理论，表明我们的方法不仅优于现有的LLM作为评判的方法，还能超越显式训练的奖励模型。这些发现表明，奖励建模阶段可以被一种原则性方法替代，即直接提取预训练中已捕获的知识，为LLM及多模态模型的对齐提供了一种更高效、强大且可扩展的新范式。

</details>


### [45] [Two Spelling Normalization Approaches Based on Large Language Models](https://arxiv.org/abs/2506.23288)
**中文标题：基于大语言模型的两种拼写标准化方法**

*Miguel Domingo,Francisco Casacuberta*

主要分类: cs.CL

摘要简述: 本文提出两种基于大语言模型的拼写标准化方法，分别采用无监督训练和机器翻译训练，并在多语言和历史时期数据集上验证，结果显示机器翻译方法更优。


<details>
  <summary>详细信息</summary>
研究动机: 历史文献中拼写缺乏标准化，为学者带来挑战，本研究旨在通过大语言模型解决拼写标准化问题。

研究方法: 提出两种方法：一种基于无监督训练的大语言模型，另一种基于机器翻译训练的大语言模型。

研究结果: 在多语言和历史时期数据集上测试，两种方法均表现良好，但机器翻译方法更适合此任务。

研究结论: 尽管两种方法均有潜力，机器翻译技术仍是拼写标准化任务的最佳选择。

中文摘要: 历史文献中缺乏标准化的拼写规范以及人类语言的有机演变，为人文学者带来了长期的挑战。为解决这一问题，拼写标准化致力于将文献的正字法与当代标准对齐。本研究提出了两种基于大语言模型的新方法：一种未经监督训练，另一种则基于机器翻译训练。我们在涵盖多种语言和历史时期的数据集上进行了评估，结果表明，尽管两种方法均取得了令人鼓舞的结果，但统计机器翻译技术仍是此任务的最合适选择。

</details>


### [46] [Objective-Free Local Learning and Emergent Language Structure in Thinking Machines](https://arxiv.org/abs/2506.23293)
**中文标题：无目标局部学习与思维机器中的涌现语言结构**

*P. Myles Eugenio*

主要分类: cs.CL

摘要简述: 本文提出了一种基于局部事件驱动涌现学习的神经符号框架，用于生成语言建模。该框架通过层次化Hopfield记忆链构建多尺度表征，无需预定义标记或监督，能够从噪声中过滤自然语言模式，生成具有内部形态一致性的合成语言。


<details>
  <summary>详细信息</summary>
研究动机: 传统语言模型依赖全局目标和预定义标记，限制了其灵活性和可解释性。本文旨在探索一种无需全局目标的局部学习框架，通过涌现学习构建语言结构，为神经符号系统提供新的方法论基础。

研究方法: 采用层次化Hopfield记忆链作为短时记忆和动态标记器，通过投影张量将共现特征绑定为层次化标记，引入冗余（涌现规范结构）并压缩局部激活为长程依赖。模型通过局部Hebbian学习构建语言结构。

研究结果: 模型能够从噪声中过滤自然语言模式，生成与人类语言量化一致的合成语言。新神经元的短暂激活可将多尺度标记特征绑定为符号嵌入，支持组合推理和泛化。

研究结论: 该框架为研究符号结构如何从局部神经学习中涌现提供了方法论基础，推动了可扩展、可解释的神经符号系统的发展。

中文摘要: 我们提出了一种基于局部事件驱动涌现学习的神经符号框架，用于生成语言建模。其核心是一个层次化的Hopfield记忆链，作为组合短时记忆和动态标记器（重标记器）。该模型不依赖预定义标记或监督，而是从零开始构建结构，将符号序列学习为多尺度表征。它构建投影张量，将共现特征绑定为层次化标记，引入冗余（即涌现规范结构），并将局部激活压缩为长程依赖。有趣的是，我们发现重标记器可以从噪声中过滤自然语言模式，生成具有内部形态一致性的合成语言——量化上与人类语言相同。语言以局部（Hebbian）方式学习，模型约束决定了允许的涌现结构，新信息与此结构对齐保留。无全局目标使系统具有传统语言模型所不具备的可塑性，能够泛化到初始推理类之外——甚至无需显式数据。我们证明，在推理过程中短暂激活一个新神经元可将分布式多尺度标记特征绑定为符号嵌入。这些涌现的嵌入神经元作为长时记忆，并支持组合推理和泛化的键值机制。该架构为研究符号结构如何从局部神经学习中涌现提供了方法论基础，为构建可扩展、可解释的神经符号系统开辟了新途径——其中标记、语法和推理作为Hopfield层次结构中的压缩记忆痕迹出现。这一方法推动了用于生成语言模型的神经形态架构的发展。

</details>


### [47] [Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)](https://arxiv.org/abs/2506.23315)
**中文标题：基于集成BERT的电子健康记录（EHR）药物事件分类**

*Shouvon Sarker,Xishuang Dong,Lijun Qian*

主要分类: cs.CL

摘要简述: 本文提出了一种基于BERT的集成模型，用于从电子健康记录（EHR）中检测和分类药物事件。通过预训练和微调多个BERT模型，并结合投票策略集成预测结果，显著提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 电子健康记录（EHR）中的药物事件识别在临床领域有广泛应用。n2c2 2022挑战赛提供了标注数据集CMED，本研究旨在通过构建BERT集成模型，解决从临床笔记中检测和分类药物事件的挑战。

研究方法: 研究首先在不同类型的大数据（如Wikipedia和MIMIC）上预训练BERT模型，然后在CMED训练数据上微调。微调后的BERT模型用于生成CMED测试数据的多预测结果，最终通过投票策略集成这些预测。

研究结果: 实验结果表明，基于BERT的集成模型显著提升了分类性能，严格Micro-F分数提高了约5%，严格Macro-F分数提高了约6%。

研究结论: BERT集成模型在药物事件分类任务中表现优异，为临床数据分析提供了有效的解决方案。

中文摘要: 从健康记录和临床笔记中识别关键变量（如药物、疾病、关系）在临床领域有广泛应用。n2c2 2022挑战赛围绕电子健康记录（EHR）临床数据分析的自然语言处理任务，构建了标注数据集CMED。本研究聚焦于该挑战赛Track 1的子任务2，即通过构建一种新型的基于BERT的集成模型，从临床笔记中检测和分类药物事件。研究首先在Wikipedia和MIMIC等大数据上预训练BERT模型，随后在CMED训练数据上微调这些模型。微调后的BERT模型用于生成CMED测试数据的多预测结果，并通过投票策略集成这些预测。实验结果表明，基于BERT的集成模型能有效提升严格Micro-F分数约5%和严格Macro-F分数约6%。

</details>


### [48] [Information Loss in LLMs' Multilingual Translation: The Role of Training Data, Language Proximity, and Language Family](https://arxiv.org/abs/2506.23340)
**中文标题：大型语言模型多语言翻译中的信息损失：训练数据、语言接近度与语系的作用**

*Yumeng Lin,Xufeng Duan,David Haslett,Yige Chen,Zhenguang G. Cai*

主要分类: cs.CL

摘要简述: 大型语言模型在多语言翻译中表现优异，但仍面临训练数据不足或语言差异大的语言对的挑战。本研究探讨了训练数据、语言接近度和语系对翻译信息损失的影响，发现数据量和语言距离的交互作用显著，语言结构接近英语时翻译质量更高。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型在多语言翻译中取得显著进展，但对训练数据有限或与英语差异较大的语言对仍存在挑战。本研究旨在系统分析训练数据、语言接近度和语系如何影响翻译中的信息损失。

研究方法: 研究评估了GPT-4和Llama 2两种大型语言模型，通过往返翻译实验，使用BLEU分数和BERT相似度指标评估翻译质量，分析了训练数据量、语言距离和语系对结果的影响。

研究结果: 结果显示，训练数据量与语言距离之间存在显著交互作用：数据充足时可缓解语言差异的影响，而语言结构接近英语时在低资源条件下翻译质量更高。拼写、谱系、句法和地理距离是翻译性能的强预测指标，语系也具有独立影响。

研究结论: 研究揭示了大型语言模型中多语言翻译的语言学约束，强调翻译质量不仅受数据量影响，还取决于语言间的结构和类型学关系。

中文摘要: 大型语言模型在多语言翻译中取得了显著进展，但对某些语言对（尤其是训练数据有限或与英语差异较大的语言对）仍面临挑战。本研究系统探讨了训练数据、语言接近度和语系如何影响多语言翻译中的信息损失。我们通过往返翻译实验评估了GPT-4和Llama 2两种大型语言模型，使用BLEU分数和BERT相似度指标评估翻译质量。结果显示，训练数据量与语言距离之间存在显著交互作用：数据充足时可缓解语言差异的影响，而语言结构接近英语时在低资源条件下翻译质量更高。在多种距离指标中，拼写、谱系、句法和地理距离是翻译性能的强预测指标，语系也具有独立影响。这些发现深化了对大型语言模型中多语言翻译语言约束的理解，强调翻译质量不仅受数据量影响，还取决于语言间的结构和类型学关系。

</details>


### [49] [ATGen: A Framework for Active Text Generation](https://arxiv.org/abs/2506.23342)
**中文标题：ATGen：一种主动文本生成框架**

*Akim Tsvigun,Daniil Vasilev,Ivan Tsvigun,Ivan Lysenko,Talgat Bektleuov,Aleksandr Medvedev,Uliana Vinogradova,Nikita Severin,Mikhail Mozikov,Andrey Savchenko,Rostislav Grigorev,Ramil Kuleev,Fedor Zhdanov,Artem Shelmanov,Ilya Makarov*

主要分类: cs.CL

摘要简述: 本文提出了ATGen框架，将主动学习（AL）与文本生成任务结合，显著减少了人工标注和API调用成本，并支持多种AL策略的集成与评估。


<details>
  <summary>详细信息</summary>
研究动机: 尽管主动学习在减少标注成本方面表现出色，但其在自然语言生成（NLG）任务中的应用有限。本文旨在通过ATGen框架填补这一空白，为NLG任务提供高效的AL解决方案。

研究方法: ATGen框架结合人类标注者和基于大语言模型（LLM）的自动标注代理，支持云端或本地部署的LLM（如ChatGPT和Claude），并提供一个统一平台实现和评估针对NLG任务的AL策略。

研究结果: 实验表明，ATGen显著降低了人工标注的工作量和LLM API调用的成本，同时支持多种AL策略在文本生成任务中的高效应用。

研究结论: ATGen为NLG任务中的主动学习提供了一个灵活且高效的框架，未来可进一步扩展其应用场景和策略。

中文摘要: 主动学习（AL）在减少机器学习模型训练所需的标注成本方面表现出巨大潜力。然而，尽管近年来自然语言生成（NLG）任务日益流行，AL在NLG中的应用仍然有限。本文提出了主动文本生成（ATGen）框架，将AL与文本生成任务紧密结合，支持将最先进的AL策略应用于NLG。该框架通过结合人类标注者和基于大语言模型（LLM）的自动标注代理，简化了NLG任务中的AL赋能标注。ATGen支持云端部署（如ChatGPT和Claude）或本地运行的LLM，并提供了一个统一平台，便于实现和评估针对NLG任务的新型AL策略。最后，我们在多种设置和多个文本生成任务中评估了最先进的AL策略。结果表明，ATGen不仅减少了人工标注的工作量，还降低了基于LLM的标注代理的API调用成本。该框架的代码已在GitHub上以MIT许可证发布，视频演示可通过http://atgen-video.nlpresearch.group 观看。

</details>


### [50] [Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs](https://arxiv.org/abs/2506.23377)
**中文标题：视角拨盘：测量文本视角并引导大型语言模型输出**

*Taejin Kim,Siun-Chuon Mau,Konrad Vesey*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Perspective-Dial的方法，用于量化文本的视角并控制大型语言模型（LLM）输出的视角。该方法包括一个用于测量视角的度量空间和基于反馈的系统化提示工程。


<details>
  <summary>详细信息</summary>
研究动机: 由于大型语言模型（LLM）在关键任务中的广泛应用，但其输出中的偏见和视角缺乏量化理解。本文旨在解决这一需求，研究文本视角的量化及LLM输出的视角控制问题。

研究方法: Perspective-Dial包含两个主要部分：一是名为Perspective Space的度量空间，用于量化不同主题的视角；二是基于贪婪坐标下降的系统化提示工程，利用度量空间的反馈控制LLM输出视角。

研究结果: 该方法通过实证方式实现了对LLM输出视角的量化与调整，适用于多种主题，可用于检测、跟踪和缓解LLM偏见，以及公共话语中的叙事检测和辩论机器人视角控制。

研究结论: Perspective-Dial为量化文本视角和控制LLM输出视角提供了一种有效方法，具有广泛的应用潜力。

中文摘要: 大型语言模型（LLM）被用于多种关键任务中。由于LLM的快速发展，其输出中的偏见和视角缺乏量化理解。受此需求启发，本文探讨了文本视角的量化及LLM输出视角控制的广泛问题。Perspective-Dial包含两个主要部分：一是名为Perspective Space的度量空间，用于量化不同主题的视角；二是基于贪婪坐标下降的系统化提示工程，利用度量空间的反馈控制LLM输出视角。这种实证方法无需对视角或偏见有原则性理解，即可量化并调整多种主题的输出。潜在应用包括LLM偏见的检测、跟踪与缓解，公共话语中的叙事检测与跟踪，以及辩论机器人视角控制。

</details>


### [51] [Hierarchical Memory Organization for Wikipedia Generation](https://arxiv.org/abs/2506.23393)
**中文标题：基于分层记忆结构的维基百科生成方法**

*Eugene J. Yu,Dawei Zhu,Yifan Song,Xiangyu Wong,Jiebin Zhang,Wenxuan Shi,Xiaoguang Li,Qun Liu,Sujian Li*

主要分类: cs.CL

摘要简述: 本文提出了一种基于分层记忆结构的生成框架（MOG），用于自动生成维基百科文章，通过细粒度记忆单元和层次化组织提升信息准确性和可验证性。


<details>
  <summary>详细信息</summary>
研究动机: 自动生成维基百科文章需要整合多源信息并确保结构化和准确性，现有方法难以满足这些需求。本文旨在通过分层记忆架构解决这些问题。

研究方法: MOG框架从网页文档中提取细粒度记忆单元，递归组织为维基百科式层次结构，并以此指导生成过程。同时引入引用模块增强可追溯性。

研究结果: 在WikiStart数据集上的实验表明，MOG在生成信息丰富且可靠的维基百科文章方面优于基线方法，尤其在真实场景中表现稳健。

研究结论: MOG通过分层记忆结构和引用模块显著提升了生成文章的准确性和可验证性，为自动生成高质量维基百科内容提供了有效解决方案。

中文摘要: 自动生成维基百科文章是一项具有挑战性的任务，需要从多样化的来源整合准确、全面且结构化的信息。本文提出了基于记忆组织的生成框架（MOG），通过分层记忆架构解决这些问题。MOG从网页文档中提取细粒度记忆单元，递归地将其组织为维基百科式的层次结构，并利用该结构指导生成过程。这确保了记忆与文章大纲的对齐，提高了信息性和可验证性，同时减少了幻觉现象。此外，还实现了一个引用模块，通过将每个生成的句子链接到特定的记忆单元来增强可追溯性。在我们新创建的WikiStart数据集上的评估表明，MOG在生成信息丰富且可靠的文章方面优于基线方法，尤其在实际场景中表现出色。

</details>


### [52] [Datasets for Fairness in Language Models: An In-Depth Survey](https://arxiv.org/abs/2506.23411)
**中文标题：语言模型公平性数据集：深入综述**

*Jiale Zhang,Zichong Wang,Avash Palikhe,Zhipeng Yin,Wenbin Zhang*

主要分类: cs.CL

摘要简述: 本文综述了语言模型公平性研究中广泛使用的数据集，揭示了其潜在偏见，并提出统一评估框架以促进更透明的比较和分析。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型公平性研究中对数据集的关注不足，导致评估结果可能受到偏见影响，本文旨在填补这一空白。

研究方法: 通过系统梳理24个常用公平性数据集，分析其来源、范围、内容和用途，并引入统一评估框架以揭示人口统计差异。

研究结果: 研究发现数据集普遍存在被忽视的偏见，影响了模型公平性结论，同时提供了选择和使用数据集的实用建议。

研究结论: 呼吁创建更具多样性的公平性基准，并提倡更审慎地使用现有数据集，所有代码和数据已公开以促进可重复性。

中文摘要: 公平性基准在评估语言模型中扮演核心角色，然而这些基准所依赖的数据集却鲜少受到关注。本综述填补了这一空白，通过对当前语言模型研究中最广泛使用的公平性数据集进行全面细致的回顾，从来源、范围、内容和用途等多个关键维度对其进行描述，帮助研究者更好地理解这些资源中隐含的假设和局限性。为支持更有意义的比较和分析，我们引入了一个统一的评估框架，揭示了数据集和评分方法中一致的人口统计差异模式。将该框架应用于24个常见基准后，我们强调了那些常被忽视的偏见，这些偏见可能影响模型公平性的结论，并提供了选择、组合和解释这些数据集的实用指导。我们还指出了创建反映更多样化社会背景的新公平性基准的机会，并鼓励未来更审慎地使用这些工具。所有代码、数据和详细结果已公开在https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets，以促进研究社区的透明性和可重复性。

</details>


### [53] [TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](https://arxiv.org/abs/2506.23423)
**中文标题：TuCo：衡量微调对大型语言模型个体输出的贡献**

*Felipe Nuti,Tim Franzmeyer,João Henriques*

主要分类: cs.CL

摘要简述: 本文提出了一种新方法TuCo，用于量化微调对大型语言模型（LLM）个体输出的贡献，揭示了微调对模型行为和安全性影响的新视角。


<details>
  <summary>详细信息</summary>
研究动机: 以往研究关注微调对LLM整体任务性能的影响，但缺乏对个体输出影响的定量分析。本文旨在填补这一空白，提供一种系统方法来衡量微调对模型输出的具体贡献。

研究方法: 通过追踪模型中间隐藏状态，将微调后的LLM分解为预训练和微调两部分，并定义Tuning Contribution（TuCo）作为微调与预训练分量的比值。实验通过调整微调分量的权重来验证其影响。

研究结果: 研究发现，TuCo与模型行为和安全密切相关：对抗攻击成功时TuCo较低，表明减弱微调效果可能是攻击成功的关键因素。

研究结论: TuCo为研究微调对模型行为和安全的定量影响提供了新工具，揭示了微调在模型输出中的动态作用。

中文摘要: 以往研究探讨了微调对大型语言模型（LLM）在特定任务上整体性能的影响，但缺乏对其个体输出影响的定量和系统性分析方法。本文提出了一种新方法，用于衡量微调对LLM个体输出的贡献，假设可以访问原始预训练模型。该方法通过追踪模型的中间隐藏状态，提供了比简单比较预训练和微调模型最终输出更细粒度的分析。我们提出并理论分析了将任何微调后的LLM精确分解为预训练和微调两部分的方法。实验表明，通过在前向传播中调整微调分量的权重，可以引导模型行为和性能。基于这一发现和理论分析，我们定义了Tuning Contribution（TuCo）作为微调分量与预训练分量大小的比值。研究发现，三种典型的LLM对抗攻击通过降低TuCo来绕过安全措施，且攻击成功时的TuCo显著低于失败时。这表明减弱微调对输出的影响可能是攻击成功的关键。总之，TuCo为定量研究微调如何影响模型行为和安全提供了新视角。

</details>


### [54] [Pipelined Decoder for Efficient Context-Aware Text Generation](https://arxiv.org/abs/2506.23431)
**中文标题：高效上下文感知文本生成的流水线解码器**

*Zixian Huang,Chenxu Niu,Yu Gu,Gengyang Xiao,Xinwei Huang,Gong Cheng*

主要分类: cs.CL

摘要简述: 本文提出了一种新的解码器架构——流水线解码器，用于并行生成上下文感知的文本，显著提高了生成速度，同时保持了生成质量和内存效率。


<details>
  <summary>详细信息</summary>
研究动机: 自回归模型虽然能生成高质量文本，但其逐词生成的方式限制了生成速度，成为性能瓶颈。本文旨在解决这一问题，提出一种并行生成方法以提升效率。

研究方法: 提出的流水线解码器通过同时生成多个子序列，并在每个时间步为每个子序列生成一个新词，实现了并行化。

研究结果: 在问答、文本摘要和关键词生成等任务上的实验表明，流水线解码器显著提高了生成速度，且未显著影响生成质量或增加内存消耗。

研究结论: 流水线解码器为上下文感知文本生成提供了一种高效的并行解决方案，平衡了速度与质量。

中文摘要: 作为生成式AI的基础，自回归模型需要依赖所有先前生成的词来生成新词，这虽然带来了高质量，但也限制了模型逐词生成的能力，形成了生成速度的瓶颈。本文提出了一种新的解码器架构，能够高效地并行生成上下文感知的文本。我们提出的流水线解码器同时启动多个子序列的生成，并在每个时间步为每个子序列生成一个新词以实现并行化。在问答、文本摘要和关键词生成等多个文本生成任务上的实验表明，流水线解码器显著提高了生成速度，且未显著损失生成质量或增加内存消耗。

</details>


### [55] [What to Keep and What to Drop: Adaptive Table Filtering Framework](https://arxiv.org/abs/2506.23463)
**中文标题：保留什么与丢弃什么：自适应表格过滤框架**

*Jang Won June*

主要分类: cs.CL

摘要简述: 论文提出ATF（自适应表格过滤框架），通过LLM生成的列描述、聚类和稀疏-密集对齐分数，动态修剪无信息的列和行，显著减少表格内容（约70%），提升TableQA任务性能，但在需要完整表格上下文的Table Fact Verification任务中略有下降。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在处理大型表格时因输入长度限制而表现不佳。ATF旨在通过动态过滤无信息内容，提升模型对表格数据的处理效率。

研究方法: ATF采用模块化、问题感知的过滤流程，结合LLM生成的列描述、聚类和稀疏-密集对齐分数，动态修剪表格中的列和行，无需重新训练现有模型。

研究结果: 实验表明，ATF能减少约70%的表格内容，显著提升TableQA任务性能，但在Table Fact Verification任务中因需要完整表格上下文而略有性能下降。

研究结论: ATF能自适应地平衡信息量和简洁性，适用于不同任务，为表格数据处理提供了高效解决方案。

中文摘要: 基于表格推理的大型语言模型（LLM）常因输入长度限制而难以处理大型表格。我们提出ATF（自适应表格过滤框架），这是一种模块化且问题感知的过滤流程，通过LLM生成的列描述、聚类和稀疏-密集对齐分数，修剪无信息的列和行。ATF无需重新训练即可与现有模型（如TAPAS、TAPEX）无缝集成。实验表明，ATF能减少约70%的表格内容，显著提升TableQA任务性能，但在需要完整表格上下文的Table Fact Verification任务中略有性能下降。这些结果凸显了ATF在不同任务中自适应平衡信息量和简洁性的能力。

</details>


### [56] [Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent](https://arxiv.org/abs/2506.23485)
**中文标题：基于大语言模型的交互式推荐代理的思想增强规划**

*Haocheng Yu,Yaxiong Wu,Hao Wang,Wei Guo,Yong Liu,Yawen Li,Yuyang Ye,Junping Du,Enhong Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大语言模型（LLM）的交互式推荐代理系统TAIRA，通过思想模式蒸馏（TPD）增强规划能力，以应对复杂用户意图。实验表明，TAIRA在多个数据集上显著优于现有方法，尤其在处理高难度任务时表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于LLM的交互式推荐代理在规划与泛化能力上存在局限，难以有效处理用户多样化且复杂的意图（如模糊或未明确的请求）。因此，本文旨在通过思想增强方法提升代理的规划能力，以更好地满足用户需求。

研究方法: TAIRA是一个多代理系统，包含一个管理代理，通过分解用户需求并规划子任务来协调推荐任务。其核心思想增强方法TPD从代理和人类专家的经验中提取高层思想，以强化规划能力。此外，设计了用户模拟方案生成不同难度的个性化查询，并在特定数据集上评估推荐效果。

研究结果: 在多个数据集上的实验表明，TAIRA性能显著优于现有方法，尤其在处理高难度任务时优势更明显。同时，TAIRA在新任务上表现出良好的泛化能力，验证了其在复杂用户意图管理中的优越性。

研究结论: TAIRA通过思想模式蒸馏增强了规划能力，有效解决了交互式推荐系统中复杂用户意图的挑战。实验证明了其优越性，尤其是在高难度任务和新任务上的表现。

中文摘要: 交互式推荐是一种典型的信息检索任务，允许用户通过自然语言交互表达需求并获得个性化推荐。基于大语言模型（LLM）的代理已成为交互式推荐的新范式，能有效捕捉用户实时需求并提升个性化体验。然而，由于规划与泛化能力有限，现有LLM驱动的交互式推荐代理难以有效应对多样化且复杂的用户意图（如直觉性、未明确或偶尔模糊的请求）。为解决这一问题，我们提出了一种新型思想增强交互式推荐代理系统（TAIRA），通过蒸馏思想模式处理复杂用户意图。具体而言，TAIRA设计为一个LLM驱动的多代理系统，包含一个管理代理，通过分解用户需求并规划子任务来协调推荐任务，其规划能力通过思想模式蒸馏（TPD）得到增强。TPD是一种思想增强方法，从代理和人类专家的经验中提取高层思想。此外，我们设计了一套用户模拟方案，生成不同难度的个性化查询，并在特定数据集上评估推荐效果。通过在多个数据集上的综合实验，TAIRA表现出显著优于现有方法的性能。值得注意的是，TAIRA在处理更具挑战性的任务时优势更大，同时在新任务上表现出良好的泛化能力，进一步验证了其在交互式推荐系统中管理复杂用户意图的优越性。代码已公开于：https://github.com/Alcein/TAIRA。

</details>


### [57] [Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably](https://arxiv.org/abs/2506.23508)
**中文标题：强化微调使多模态大语言模型稳定学习新任务**

*Zhihao Zhang,Qiaole Dong,Qi Zhang,Jun Zhao,Enyu Zhou,Zhiheng Xi,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Yanwei Fu,Tao Ji,Tao Gui,Xuanjing Huang*

主要分类: cs.CL

摘要简述: 本文研究了监督微调（SFT）和强化微调（RFT）对多模态大语言模型（MLLMs）的影响，发现SFT能快速学习新任务但会导致灾难性遗忘，而RFT学习速度较慢但能保留先验知识。通过分析学习动态，发现RFT通过强化与模型概率分布一致的正确样本，减少对先验知识的干扰。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究对监督微调（SFT）和强化微调（RFT）在多模态大语言模型（MLLMs）任务适应中的影响尚不明确，尤其是它们对先验知识的影响。本文旨在通过引入拼图任务这一新任务，系统研究SFT和RFT的行为差异及其对知识保留的影响。

研究方法: 研究使用开源多模态模型Qwen2.5-VL，引入拼图任务作为新任务，比较SFT和RFT的学习效果。通过分析学习动态，探讨RFT如何通过强化正确样本减少对先验知识的干扰。

研究结果: 实验表明，SFT能快速学习新任务但会导致灾难性遗忘，而RFT学习速度较慢但能保留先验知识。进一步分析发现，RFT通过强化与模型概率分布一致的正确样本，减少对先验知识的干扰。

研究结论: 数据分布而非算法差异在遗忘中起关键作用，RFT在多模态大语言模型的稳定持续学习中具有潜力。

中文摘要: 监督微调（SFT）和强化微调（RFT）等后训练算法广泛用于将多模态大语言模型适应下游任务。尽管在任务适应中有效，但它们对先验知识的影响尚不明确。本文引入拼图任务作为现有预训练语料库中未出现的新任务，系统研究了SFT和RFT在开源多模态模型Qwen2.5-VL上的行为。实验揭示了一个明显的权衡：SFT能快速学习新任务但会导致灾难性遗忘，而RFT学习新任务较慢但能保留先验知识。通过分析学习动态，我们发现RFT通过强化与基础模型概率分布自然一致的正确样本，减少了对先验知识的干扰。此外，对RFT模拟的正确样本进行监督训练，可以使SFT在快速学习新任务的同时保留知识。这些发现表明，数据分布而非算法差异在遗忘中起核心作用，并突显了RFT在多模态大语言模型稳定持续学习中的潜力。

</details>


### [58] [NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning](https://arxiv.org/abs/2506.23524)
**中文标题：NEU-ESC：面向多任务学习的越南语教育情感分析与主题分类综合数据集**

*Phan Quoc Hung Mai,Quang Hung Nguyen,Phuong Giang Duong,Hong Hanh Nguyen,Nguyen Tuan Long*

主要分类: cs.CL

摘要简述: 本文介绍了NEU-ESC，一个越南语教育情感分析和主题分类数据集，填补了越南语教育领域数据资源的空白，并通过多任务学习模型（BERT）实现了高准确率。


<details>
  <summary>详细信息</summary>
研究动机: 越南语教育领域的学生评论分析资源有限，现有数据集缺乏领域相关性和学生俚语。为填补这一空白，作者提出了NEU-ESC数据集。

研究方法: 从大学论坛收集数据，构建NEU-ESC数据集，包含更多样本、更丰富的类别、更长的文本和更广泛的词汇。使用基于BERT的编码器模型进行多任务学习。

研究结果: 多任务学习模型在情感分类和主题分类任务中分别达到83.7%和79.8%的准确率，并通过与其他数据集和模型的对比验证了其有效性。

研究结论: NEU-ESC数据集为越南语教育领域的情感分析和主题分类提供了高质量资源，多任务学习模型表现出色，未来可进一步优化。

中文摘要: 在教育领域，通过学生评论理解其观点至关重要，尤其是在越南语中，相关资源仍然有限。现有教育数据集通常缺乏领域相关性和学生俚语。为填补这些空白，我们提出了NEU-ESC，一个新的越南语教育情感分类和主题分类数据集，数据来自大学论坛，提供了更多样本、更丰富的类别、更长的文本和更广泛的词汇。此外，我们探索了基于编码器语言模型（BERT）的多任务学习，结果显示其在情感分类和主题分类任务中分别达到83.7%和79.8%的准确率。我们还与其他数据集和模型（包括大型语言模型）进行了基准测试，并讨论了这些结果。数据集公开于：https://huggingface.co/datasets/hung20gg/NEU-ESC。

</details>


### [59] [On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?](https://arxiv.org/abs/2506.23527)
**中文标题：关于大型语言模型的食谱记忆与创造力：你的模型是创意厨师、糟糕厨师还是纯粹的抄袭者？**

*Jan Kvapil,Martin Fajcik*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型（LLMs）在生成烹饪食谱时的记忆、创造力和无意义内容。通过人工标注和自动化框架，发现模型倾向于记忆在线内容，并提出了自动化评估方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于分析LLMs在生成食谱时的表现，包括记忆性、创造性和无意义内容，并探索如何通过自动化方法扩大研究规模。

研究方法: 方法包括人工标注20个由Mixtral生成的食谱，分析其成分和步骤的记忆性或创造性；同时设计自动化框架（LLM-as-judge）进行大规模评估。

研究结果: 结果显示Mixtral倾向于重用训练中可能见过的在线内容，表明其依赖记忆。自动化框架中，Llama 3.1+Gemma 2 9B在成分匹配上达到78%的准确率。

研究结论: 结论指出LLMs在生成食谱时更依赖记忆而非创造力，自动化框架为大规模评估提供了可行方案。

中文摘要: 这项进行中的研究探讨了大型语言模型（LLMs）生成的烹饪食谱中的记忆性、创造性和无意义内容。具体目标包括：（i）通过少量高质量人工标注分析LLMs的记忆性、创造性和无意义内容；（ii）评估自动化人工标注的方法以扩大研究规模。为实现（i），我们对Mixtral生成的20个食谱进行了详细人工标注，提取成分和步骤以区分记忆性内容（可能来自训练数据）和创造性或无意义内容。发现Mixtral倾向于重用可能来自在线文档的成分，表明其依赖记忆。为实现（ii），我们设计了“LLM-as-judge”自动化流程，用于食谱生成、无意义检测、成分和步骤解析及标注。例如，与人工标注相比，最佳成分提取和标注工具Llama 3.1+Gemma 2 9B在成分匹配上达到78%的准确率。该自动化框架为大规模量化生成食谱的记忆性、创造性和无意义内容提供了方法，为模型的创造力提供了严谨证据。

</details>


### [60] [Semantic-guided Diverse Decoding for Large Language Model](https://arxiv.org/abs/2506.23601)
**中文标题：语义引导的大型语言模型多样化解码**

*Weijie Shi,Yue Cui,Yaguang Wu,Jingzhi Fang,Shibo Zhang,Mengze Li,Sirui Han,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SemDiD的语义引导多样化解码方法，旨在解决大型语言模型生成多样化但语义有意义的响应问题。通过三种互补机制，SemDiD在嵌入空间中平衡质量与多样性，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型语言模型多样化解码方法主要关注词汇多样性而非语义多样性，限制了其在多响应生成、强化学习等应用中的效果。本文旨在通过语义引导的方法实现真正的语义多样化。

研究方法: SemDiD通过三种机制实现语义多样化：正交方向引导、动态组间排斥和位置去偏概率评估。结合自适应增益函数和约束优化，确保生成结果既满足质量要求又最大化语义差异。

研究结果: 实验表明，SemDiD在多样化任务中显著优于现有方法，Best-of-N覆盖率提升1.4-5.2%，RLHF训练收敛速度加快15%，准确率提升高达2.1%。

研究结论: SemDiD通过语义引导的多样化解码方法，成功平衡了生成结果的质量与多样性，为大型语言模型的多响应生成提供了高效解决方案。

中文摘要: 大型语言模型的多样化解码对于需要多个语义不同响应的应用至关重要，但现有方法主要实现词汇而非语义多样性。这一限制显著影响了Best-of-N策略、基于群体的强化学习和数据合成。尽管温度采样和多样化束搜索通过修改令牌分布或应用n-gram惩罚，但无法确保有意义的语义差异。我们提出语义引导多样化解码（SemDiD），直接在嵌入空间中操作，通过三种互补机制平衡质量与多样性：正交方向引导、动态组间排斥和位置去偏概率评估。SemDiD通过自适应增益函数和约束优化协调这些竞争目标，确保质量阈值和最大语义差异。实验显示，SemDiD在多样化任务中始终优于现有方法，Best-of-N覆盖率提升1.4-5.2%，RLHF训练收敛速度加快15%，同时准确率提升高达2.1%。

</details>


### [61] [Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs](https://arxiv.org/abs/2506.23610)
**中文标题：评估基于大语言模型的人格驱动虚假信息易感性模拟**

*Manuel Pratelli,Marinella Petrocchi*

主要分类: cs.CL

摘要简述: 研究评估了基于大语言模型（LLM）生成的合成行为数据是否能准确反映人格特质驱动的心理差异，重点关注人格对虚假信息易感性的影响。结果显示，某些人格特质（如宜人性和尽责性）与虚假信息的关联被可靠复制，而其他特质则存在偏差。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）能够生成大规模合成行为数据，为替代人类实验提供了一种伦理且低成本的方案。然而，这些数据是否能准确捕捉人格特质驱动的心理差异尚不明确。本研究旨在评估LLM代理在模拟人格特质对虚假信息易感性方面的能力。

研究方法: 研究利用已知人格特质的参与者对新闻标题准确性评分的公开数据集，创建了匹配的LLM代理，并比较其反应与人类原始数据的差异。重点关注新闻辨别能力（判断真假标题的能力）。

研究结果: 结果显示，某些人格特质（如宜人性和尽责性）与虚假信息的关联被LLM可靠复制，而其他特质则表现出系统性偏差，揭示了LLM在内部化和表达人格特质时的局限性。

研究结论: 研究强调了人格对齐LLM在行为模拟中的潜力和限制，并为人工代理中认知多样性的建模提供了新见解。

中文摘要: 大语言模型（LLM）能够大规模生成合成行为数据，为人类实验提供了一种伦理且低成本的替代方案。然而，这些数据是否能准确捕捉人格特质驱动的心理差异仍是一个未解决的问题。本研究评估了基于大五人格特质的LLM代理在模拟人格对虚假信息易感性方面的能力，重点关注新闻辨别能力（判断真假标题的能力）。通过利用已知人格特质的参与者对新闻标题准确性评分的公开数据集，我们创建了匹配的LLM代理，并将其反应与原始人类数据进行比较。结果显示，某些人格特质（如宜人性和尽责性）与虚假信息的关联被可靠复制，而其他特质则存在偏差，揭示了LLM在内部化和表达人格特质时的系统性偏差。这些结果既凸显了人格对齐LLM在行为模拟中的潜力，也指出了其局限性，并为人工代理中认知多样性的建模提供了新见解。

</details>


### [62] [Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack](https://arxiv.org/abs/2506.23661)
**中文标题：通过BeamAttack评估错误信息分类系统对对抗性示例的鲁棒性**

*Arnisa Fazla,Lucas Krauter,David Guzman Piedrahita,Andrianos Michail*

主要分类: cs.CL

摘要简述: 本文扩展了BeamAttack算法，用于评估文本分类系统对对抗性攻击的鲁棒性，通过词级修改和束搜索实现高攻击成功率，同时保持语义和词汇相似性。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估文本分类系统在面对对抗性攻击时的鲁棒性，特别是通过词级修改来探索模型预测的最小变化。

研究方法: 扩展了BeamAttack算法，支持词删除和跳过替换选项，结合LIME优化词替换优先级，并在BODEGA框架下测试多种数据集和模型（BiLSTM、BERT和对抗训练的RoBERTa）。

研究结果: 实验表明，BeamAttack在多种模型上攻击成功率超过99%，同时保持了原始文本的语义和词汇相似性。

研究结论: BeamAttack在对抗性攻击中表现出高效性，但也存在局限性，为未来研究提供了改进方向。

中文摘要: 我们扩展了BeamAttack算法，这是一种通过束搜索指导的词级修改来评估文本分类系统鲁棒性的对抗性攻击算法。我们的扩展包括支持词删除和跳过替换选项，从而能够发现改变模型预测的最小修改。我们还整合了LIME以更好地优化词替换的优先级。在BODEGA框架下对多种数据集和受害模型（BiLSTM、BERT和对抗训练的RoBERTa）进行评估，我们的方法在保持原始文本语义和词汇相似性的同时，实现了超过99%的攻击成功率。通过定量和定性分析，我们展示了BeamAttack的有效性及其局限性。我们的实现可在https://github.com/LucK1Y/BeamAttack获取。

</details>


### [63] [Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation](https://arxiv.org/abs/2506.23662)
**中文标题：通过离线合成语料库生成实现零样本上下文嵌入**

*Philip Lippmann,Jie Yang*

主要分类: cs.CL

摘要简述: ZEST是一种零样本上下文适应框架，通过离线合成代理语料库替代真实语料库访问，无需微调或目标语料库访问，即可生成领域适应的嵌入。


<details>
  <summary>详细信息</summary>
研究动机: 现有的上下文感知嵌入方法需要访问目标语料库或进行领域特定微调，这在隐私敏感或资源受限的环境中存在实际障碍。ZEST旨在解决这一问题。

研究方法: ZEST通过多步分层程序，仅使用少量代表目标领域的示例文档，离线合成一个紧凑的代理语料库，模拟关键领域特定分布。推理时，冻结的上下文感知编码器使用此代理语料库生成领域适应的嵌入。

研究结果: 在MTEB基准测试中，ZEST仅使用五个示例文档的零样本合成上下文适应性能接近完全访问目标语料库的模型（差距在0.5%以内），展示了无需重新训练的高效性。

研究结论: ZEST为在受限环境中部署高性能、适应性强的嵌入提供了一种实用方法。

中文摘要: 上下文感知嵌入方法通过从邻近文档中提取语料统计信息（如术语共现和主题模式）来提高检索准确性。然而，这种方法需要访问目标语料库或进行领域特定微调，在隐私敏感或资源受限的环境中存在实际障碍。我们提出了ZEST，一种零样本上下文适应框架，用一次性离线合成的紧凑代理语料库替代真实语料库访问。仅需少量代表目标领域的示例文档，我们通过多步分层程序生成数百个文档的合成上下文语料库，旨在模拟关键领域特定分布。在推理时，冻结的上下文感知编码器使用此代理语料库（无需微调或目标语料库访问）生成领域适应的嵌入。在MTEB基准测试中，ZEST仅使用五个示例文档的零样本合成上下文适应性能接近完全访问目标语料库的模型（差距在0.5%以内），展示了无需重新训练的高效性。因此，ZEST为在受限环境中部署高性能、适应性强的嵌入提供了一种实用方法。

</details>


### [64] [L0: Reinforcement Learning to Become General Agents](https://arxiv.org/abs/2506.23667)
**中文标题：L0：通过强化学习成为通用智能体**

*Junjie Zhang,Jingyi Xi,Zhuoyang Song,Junyu Lu,Yuhua Ke,Ting Sun,Yukun Yang,Jiaxing Zhang,Songxin Zhang,Zejian Xie*

主要分类: cs.CL

摘要简述: 本文提出L0，一种可扩展的端到端训练框架，用于训练通用智能体。通过低成本的并发工作池和代码即行动的NB-Agent，L0显著提升了强化学习在复杂环境中的应用效率。实验表明，该方法在问答任务中显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前训练大型语言模型（LLMs）作为自主代理执行多轮、长周期任务时，面临扩展性和训练效率的挑战。本文旨在通过L0框架解决这些问题，降低强化学习在复杂环境中的应用门槛。

研究方法: L0框架包含一个低成本、可扩展的并发代理工作池，以及NB-Agent代理脚手架。NB-Agent采用“代码即行动”模式，通过REPL（读取-求值-打印循环）运行。训练采用基于可验证奖励的强化学习（RLVR）。

研究结果: 实验表明，L0显著提升了模型性能：在SimpleQA上准确率从30%提升至80%，在HotpotQA上从22%提升至41%。

研究结论: L0框架为通用智能体的训练提供了高效、可扩展的解决方案，并通过开源推动了相关研究的发展。

中文摘要: 训练大型语言模型（LLMs）作为自主代理执行多轮、长周期任务时，面临扩展性和训练效率的挑战。为此，我们提出了L0（L-Zero），一种可扩展的端到端训练框架，用于通用智能体。L0通过低成本、可扩展且沙盒化的并发代理工作池，降低了强化学习在复杂环境中的应用门槛。我们还引入了NB-Agent，这是L0中的代理脚手架，采用“代码即行动”模式，通过REPL（读取-求值-打印循环）运行。我们在事实性问答基准上评估了L0。实验表明，基础模型可以仅通过基于可验证奖励的强化学习（RLVR）发展出强大的问题解决能力。在Qwen2.5-7B-Instruct模型上，我们的方法将SimpleQA的准确率从30%提升至80%，HotpotQA的准确率从22%提升至41%。我们已开源整个L0系统，包括L0系列模型、NB-Agent、完整的训练流程及相应的训练配方（https://github.com/cmriat/l0）。

</details>


### [65] [AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data](https://arxiv.org/abs/2506.23735)
**中文标题：AutoEvoEval：一种用于进化封闭式LLM评估数据的自动化框架**

*JiaRu Wu,Mingwei Liu*

主要分类: cs.CL

摘要简述: AutoEvoEval是一个基于进化的评估框架，用于生成多样化和具有挑战性的测试样本，以更全面地评估大型语言模型（LLM）的鲁棒性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型语言模型评估基准多为静态，无法充分评估其在真实场景中的鲁棒性和泛化能力。进化或对抗性数据增强方法虽能提升多样性，但缺乏对扰动类型和多步复杂性的系统控制，限制了全面鲁棒性分析。

研究方法: AutoEvoEval提出了22种可解释的原子进化操作，并支持多轮组合，从而生成多样化、具有挑战性且真实的测试样本。

研究结果: 实验表明，原子操作平均导致模型准确率下降7.283%，其中结构破坏性或误导性语义编辑的影响最大。模型对相同扰动的敏感性差异显著，多步进化组合可将对抗效果放大至52.932%。

研究结论: 当前基准可能高估了模型的真实泛化能力，强调了进化感知的鲁棒性评估的必要性。

中文摘要: 大型语言模型（LLM）在各种任务中表现出色，但现有的评估基准通常是静态的，无法充分评估其在真实场景中的鲁棒性和泛化能力。先前的研究使用进化或对抗性数据增强提高了评估多样性，但缺乏对扰动类型和多步复杂性的系统控制，限制了全面鲁棒性分析。为解决这些问题，我们提出了AutoEvoEval，一种基于进化的封闭式任务（如多项选择题）评估框架。AutoEvoEval引入了22种可解释的原子进化操作，并支持多轮组合，从而生成多样化、具有挑战性且真实的测试样本。我们针对广泛的开源和闭源LLM进行了四项研究问题的实验。结果显示，原子操作平均导致准确率下降7.283%，其中结构破坏性或误导性语义编辑的影响最大。模型对相同扰动的敏感性差异显著，多步进化组合可将对抗效果放大至52.932%。这些发现表明当前基准可能高估了模型的真实泛化能力，并强调了进化感知的鲁棒性评估的必要性。代码和资源可在https://github.com/SYSUSELab/AutoEvoEval获取。

</details>


### [66] [Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences](https://arxiv.org/abs/2506.23743)
**中文标题：二元问答中的位置偏见：不确定性如何塑造模型偏好**

*Tiziano Labruna,Simone Gallo,Giovanni Da San Martino*

主要分类: cs.CL

摘要简述: 研究量化了大型语言模型在二元问答中的位置偏见，发现低不确定性条件下偏见几乎不存在，但高不确定性时偏见呈指数增长。


<details>
  <summary>详细信息</summary>
研究动机: 探讨二元问答中模型因选项顺序而系统性偏好某一答案的位置偏见现象，并分析其与答案不确定性的关系。

研究方法: 通过改造SQuAD-it数据集，增加错误选项并逐步减少上下文，创建从低到高不确定性的数据集；同时评估WebGPT和Winning Arguments两个高不确定性基准。通过翻转“正确”选项顺序计算偏好公平性和位置一致性。

研究结果: 低不确定性条件下位置偏见几乎不存在，但随着不确定性增加，偏见呈指数增长。

研究结论: 位置偏见在二元问答中与答案不确定性密切相关，高不确定性会显著放大模型的系统性偏好。

中文摘要: 二元问答中的位置偏见指模型仅因选项顺序而系统性偏好某一答案的现象。本研究量化并分析了五种大型语言模型在不同不确定性程度下的位置偏见。通过改造SQuAD-it数据集，增加错误选项并逐步减少上下文，生成从低到高不确定性的数据集。此外，评估了两个自然高不确定性基准：(1) WebGPT——问题对具有不等人类评分，(2) Winning Arguments——模型预测Reddit的r/ChangeMyView中更具说服力的论点。通过翻转“正确”选项顺序计算偏好公平性和位置一致性。结果显示，低不确定性条件下位置偏见几乎不存在，但高不确定性时偏见呈指数增长。

</details>


### [67] [Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model](https://arxiv.org/abs/2506.23840)
**中文标题：思考标记是助力还是陷阱？迈向更高效的大型推理模型**

*Bowen Ding,Yuhan Chen,Futing Wang,Lingfeng Ming,Tao Lin*

主要分类: cs.CL

摘要简述: 大型推理模型（LRMs）在处理简单任务时，常因过度使用思考标记（如“等待”“然而”）而陷入“思考陷阱”，降低效率。本文提出双策略偏好优化（DuP-PO）算法，通过平衡采样、动态调控标记预测和稳定梯度贡献，显著提升模型在数学推理任务中的效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型在复杂任务中表现出色，但在简单任务中因过度使用思考标记而效率低下。这些标记引发不必要的高阶推理行为（如反思和回溯），甚至可能阻碍正确推理。本文旨在解决这一“思考陷阱”问题，提升模型的推理效率。

研究方法: 提出双策略偏好优化（DuP-PO）算法，包含三个关键部分：(1) 平衡采样策略，确保模型均衡接触含与不含思考标记的响应；(2) 细粒度优势控制技术，动态调控目标标记的预测；(3) 策略塑形方法，稳定思考标记的梯度贡献。

研究结果: 在五个数学推理基准测试中，DuP-PO显著提升了大型推理模型的标记效率，同时保持了基础模型的优异性能。

研究结论: 思考标记虽能辅助推理，但过度使用会降低效率。DuP-PO通过优化策略，有效解决了“思考陷阱”问题，为大型推理模型的效率提升提供了新思路。

中文摘要: 大型推理模型（LRMs）擅长解决复杂问题，但面临“过度思考”困境。处理简单任务时，它们常生成冗长响应，充斥着思考标记（如“等待”“然而”）。这些标记会触发不必要的高阶推理行为（如反思和回溯），降低效率。本文的初步研究表明，这些由思考标记引发的行为对有效解决问题并非必需，甚至可能在有限标记预算内阻碍正确推理。我们将此现象称为“思考陷阱”。为缓解此问题，我们提出双策略偏好优化（DuP-PO），其创新点包括：(1) 一种平衡采样策略，确保模型均衡接触含与不含思考标记的响应；(2) 一种细粒度优势控制技术，动态调控目标标记的预测；(3) 一种策略塑形方法，稳定思考标记的梯度贡献。在五个流行的数学推理基准测试中，DuP-PO在大型推理模型上表现优异，显著提升了推理时的标记效率，同时保持了基础模型的卓越性能。

</details>


### [68] [Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It](https://arxiv.org/abs/2506.23864)
**中文标题：垃圾进，推理出？为什么基准分数不可靠以及如何解决**

*Seyed Mahed Mousavi,Edoardo Cecchinato,Lucia Hornikova,Giuseppe Riccardi*

主要分类: cs.CL

摘要简述: 本文对三个广泛使用的推理基准（SocialIQa、FauxPas-EAI和ToMi）进行了系统审计，发现基准设计和评分方法存在普遍缺陷。通过使用五种大语言模型（GPT-3、GPT-3.5、GPT-4、GPT-o1和LLaMA 3.1）作为诊断工具，揭示了基准中的结构、语义和语用问题，以及评分程序过于关注输出形式而非推理过程的问题。研究发现，模型分数的提升往往源于表面措辞的变化而非推理能力的改进，挑战了当前基于基准的推理能力评估的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前广泛使用的推理基准存在设计缺陷和评分方法的不合理性，可能导致对大语言模型推理能力的评估不准确。本文旨在揭示这些问题，并提出更合理的评估方法。

研究方法: 使用五种大语言模型（GPT-3、GPT-3.5、GPT-4、GPT-o1和LLaMA 3.1）对三个推理基准（SocialIQa、FauxPas-EAI和ToMi）进行系统审计，识别基准中的结构、语义和语用问题。通过人工标注和重新评估清理后的基准子集，分析模型分数的变化原因。

研究结果: 研究发现，基准中存在重复项、模糊措辞和不合逻辑的答案等问题，评分程序过于关注输出形式而非推理过程。模型分数的提升往往源于表面措辞的变化，而非推理能力的改进。此外，模型性能对输入的微小变化（如上下文可用性和措辞）高度敏感，表明高分可能仅反映模型对特定格式线索的适应，而非基于输入的稳定推理。

研究结论: 当前基于基准的推理能力评估存在严重问题，高分可能无法真实反映模型的推理能力。需要开发新的评估协议，将推理视为从可用信息中得出结论的过程，而非静态输出选择。本文发布了审计数据和评估工具，以支持更具解释性和诊断性的模型推理评估。

中文摘要: 我们对三个广泛使用的推理基准（SocialIQa、FauxPas-EAI和ToMi）进行了系统审计，揭示了基准项目和评估方法中的普遍缺陷。通过使用五种大语言模型（GPT-3、GPT-3.5、GPT-4、GPT-o1和LLaMA 3.1）作为诊断工具，我们识别了基准设计中的结构、语义和语用问题（如重复项、模糊措辞和不合逻辑的答案），以及评分程序过于关注输出形式而非推理过程的问题。通过系统的人工标注和清理后的基准子集重新评估，我们发现模型分数的提升往往源于表面措辞的变化，而非推理能力的改进。进一步分析表明，模型性能对输入的微小变化（如上下文可用性和措辞）高度敏感，表明高分可能仅反映模型对特定格式线索的适应，而非基于输入的稳定推理。这些发现挑战了当前基于基准的大语言模型推理能力评估的有效性，并强调了需要开发评估协议，将推理视为从可用信息中得出结论的过程，而非静态输出选择。我们发布了审计数据和评估工具，以支持更具解释性和诊断性的模型推理评估。

</details>


### [69] [Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting](https://arxiv.org/abs/2506.23888)
**中文标题：通过多层自反思与自动提示推进大语言模型中的多步数学推理**

*André de Souza Loureiro,Jorge Valverde-Rebaza,Julieta Noguez,David Escarcega,Ricardo Marcacini*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MAPS（多层自反思与自动提示）的新框架，通过结合思维链、自反思和自动提示技术，显著提升大语言模型在复杂多步数学推理任务中的表现。实验证明，MAPS优于标准思维链方法，并接近专用推理模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在问题解决能力上有所提升，但在复杂多步推理任务中仍表现不佳。本文旨在通过动态迭代的提示优化机制，解决这一问题。

研究方法: MAPS框架采用迭代优化方法：首先生成思维链提示的解决方案；若发现错误，通过自反思机制分析并生成定制化提示，动态调整模型推理过程。

研究结果: 在四个基准测试中，MAPS显著优于标准思维链方法，并接近专用推理模型的性能。同时，MAPS通过限制反思深度，平衡了成本与推理性能。

研究结论: MAPS通过动态提示和自反思机制，有效提升了大语言模型的多步数学推理能力，同时优化了成本与性能的平衡。

中文摘要: 近年来，大语言模型（LLMs）在问题解决能力上取得了显著进展，但在处理复杂的多步推理任务时仍存在困难。本文提出了多层自反思与自动提示（MAPS）框架，通过整合思维链（CoT）、自反思和自动提示技术，旨在提升LLMs在多步数学推理中的表现。与传统静态提示方法不同，MAPS采用迭代优化过程：模型首先生成一个基于CoT提示的解决方案；若检测到错误，自适应自反思机制会分析并生成定制化提示以指导修正。这些动态调整的提示使模型能够迭代优化其推理过程。在多个LLMs上进行的四个基准测试表明，MAPS显著优于标准CoT方法，并与专用推理模型取得竞争性结果。此外，MAPS使通用LLMs达到与专用推理模型相当的性能水平。虽然更深的反思层能提高准确性，但也会增加标记使用和成本。为平衡这一权衡，MAPS策略性地限制反思深度，确保成本与推理性能的最佳平衡。

</details>


### [70] [The Trilemma of Truth in Large Language Models](https://arxiv.org/abs/2506.23921)
**中文标题：大型语言模型中的真实性三难困境**

*Germans Savcisens,Tina Eliassi-Rad*

主要分类: cs.CL

摘要简述: 本文探讨了大型语言模型（LLMs）中知识的真实性评估问题，提出了一种名为sAwMIL的新方法，通过分析模型内部激活状态来区分真实、虚假和中性陈述，并揭示了LLMs中真实性信号的分布特点。


<details>
  <summary>详细信息</summary>
研究动机: 人们常将人类特性赋予LLMs，并认为它们“知道”某些信息。然而，如何评估LLMs内部概率性知识的真实性仍是一个未解决的问题。本文旨在揭示现有评估方法的缺陷，并提出更可靠的解决方案。

研究方法: 本文提出了sAwMIL方法，基于多实例学习和一致性预测，利用LLMs的内部激活状态将陈述分为真实、虚假和中性三类。该方法在16个开源LLMs和3个新数据集上进行了评估。

研究结果: 研究发现：（1）真实性信号多集中在LLMs深度的第三部分；（2）真实与虚假信号不对称；（3）线性探针在聊天模型中表现更好；（4）非线性探针可能更适合某些经过人类反馈强化学习或知识蒸馏的LLMs；（5）LLMs中存在第三种既非真实也非虚假的信号。

研究结论: sAwMIL为验证LLMs的“知识”及其确定性提供了可靠方法，揭示了LLMs内部知识的多维特性。

中文摘要: 我们常将人类特性赋予大型语言模型（LLMs），并声称它们“知道”某些内容。LLMs具有一种内部概率性知识，代表训练中保留的信息。如何评估这种知识的真实性？我们研究了两种常见的LLMs真实性探测方法，发现了一些有缺陷的假设。为解决这些问题，我们提出了sAwMIL（稀疏感知多实例学习），一种利用LLMs内部激活状态将陈述分为真实、虚假和中性三类的探测方法。sAwMIL基于多实例学习和一致性预测。我们在16个开源LLMs（包括默认和聊天版本）和3个新数据集上评估了sAwMIL的5项有效性标准。研究发现：（1）真实性信号多集中在LLMs深度的第三部分；（2）真实与虚假信号不对称；（3）线性探针在聊天模型中表现更好；（4）非线性探针可能更适合某些经过人类反馈强化学习或知识蒸馏的LLMs；（5）LLMs中存在第三种既非真实也非虚假的信号。这些发现为验证LLMs的“知识”及其确定性提供了可靠方法。

</details>


### [71] [IMPACT: Inflectional Morphology Probes Across Complex Typologies](https://arxiv.org/abs/2506.23929)
**中文标题：IMPACT：跨复杂类型学的屈折形态探针**

*Mohammed J. Saeed,Tommi Vehvilainen,Evgeny Fedoseev,Sevil Caliskan,Tatiana Vodolazova*

主要分类: cs.CL

摘要简述: 论文提出IMPACT框架，用于评估大语言模型在五种形态丰富语言中的屈折形态能力，发现模型在非英语语言和复杂形态模式上表现不佳，尤其是对不合语法例子的判断。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在多语言任务中表现优异，但其对非英语语言的形态复杂性理解程度尚不明确。论文旨在通过IMPACT框架评估模型在屈折形态方面的能力。

研究方法: 论文设计了IMPACT框架，包含五种形态丰富语言（阿拉伯语、俄语、芬兰语、土耳其语和希伯来语）的单元测试案例，覆盖共享和语言特异性现象。评估了八种多语言大语言模型的表现。

研究结果: 模型在英语表现优异，但在其他语言和复杂形态模式（如阿拉伯语的反向性别一致、芬兰语和土耳其语的元音和谐）上表现不佳，尤其是对不合语法例子的判断。思维链和思维模型可能降低性能。

研究结论: 研究揭示了模型在语言复杂性处理上的不足，表明仍有改进空间。IMPACT框架已公开以支持进一步研究。

中文摘要: 大语言模型（LLMs）在各种多语言基准测试中取得了显著进展，并越来越多地用于生成和评估非英语语言的文本。然而，尽管它们可能生成流畅的输出，但这些模型对这些语言的底层语言复杂性（尤其是形态学）的理解程度尚不明确。为了研究这一点，我们提出了IMPACT，一个专注于屈折形态的合成评估框架，并公开发布，旨在评估LLMs在五种形态丰富语言（阿拉伯语、俄语、芬兰语、土耳其语和希伯来语）中的表现。IMPACT包含单元测试风格的案例，覆盖共享和语言特异性现象，从基本动词屈折（如时态、数、性别）到独特特征（如阿拉伯语的反向性别一致和芬兰语、土耳其语的元音和谐）。我们评估了八种多语言LLMs，尽管它们在英语上表现优异，但在其他语言和不常见的形态模式上表现不佳，尤其是在判断不合语法例子时。我们还表明，思维链和思维模型可能会降低性能。我们的工作揭示了LLMs在处理语言复杂性方面的不足，指出了明显的改进空间。为了支持进一步研究，我们公开了IMPACT框架。

</details>


### [72] [Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages](https://arxiv.org/abs/2506.23930)
**中文标题：利用提示工程潜力检测低资源语言中的仇恨言论**

*Ruhina Tabasshum Prome,Tarikul Islam Tamiti,Anomadarshi Barua*

主要分类: cs.CL

摘要简述: 本文探讨如何通过提示工程在低资源语言（如孟加拉语）中有效检测仇恨言论，提出六种提示策略，并创新性地引入隐喻提示以绕过大型语言模型的安全机制。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体中仇恨言论激增，对个人生活和社会安全构成威胁。然而，低资源语言因缺乏高质量数据集而面临检测难题。本文旨在通过提示工程解决这一问题。

研究方法: 研究采用六种提示策略（零样本提示、拒绝抑制、赞美分类器、多样本提示、角色提示和隐喻提示），在Llama2-7B模型上进行实验，并与GloVe、Word2Vec和FastText嵌入及MLP、CNN、BiGRU模型对比。

研究结果: 隐喻提示在低资源语言（孟加拉语和印地语）及高资源语言（英语和德语）中均表现优异，F1分数显著提升，同时环境影响因子（CO₂排放、电力消耗和计算时间）较低。

研究结论: 隐喻提示为低资源语言中的仇恨言论检测提供了高效解决方案，且环境友好，具有广泛适用性。

中文摘要: 社交媒体的快速扩张导致仇恨言论显著增加，威胁个人生活并引发大量仇恨犯罪。仇恨言论检测面临多种挑战：多样化的方言、频繁的代码混合以及社交媒体用户生成内容中普遍存在的拼写错误。近年来，仇恨言论检测的进展主要集中在高资源语言上，而低资源语言由于缺乏大规模高质量数据集仍面临重大挑战。本文探讨如何通过提示工程在大型语言模型（LLMs）上克服这一限制，重点关注低资源孟加拉语。我们研究了六种提示策略——零样本提示、拒绝抑制、赞美分类器、多样本提示、角色提示以及创新的隐喻提示，以有效检测低资源语言中的仇恨言论。我们首创隐喻提示以绕过LLMs内置的安全机制，这与现有的越狱方法有显著区别。我们在Llama2-7B模型上测试了所有六种提示策略，并与三种预训练词嵌入（GloVe、Word2Vec和FastText）及三种深度学习模型（多层感知机MLP、卷积神经网络CNN和双向门控循环单元BiGRU）进行了广泛比较。为验证隐喻提示在低资源孟加拉语中的有效性，我们还在另一种低资源语言（印地语）和两种高资源语言（英语和德语）中进行了评估。所有提示技术的性能均通过F1分数和环境影响因子（IF，衡量CO₂排放、电力消耗和计算时间）进行评估。

</details>


### [73] [Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs](https://arxiv.org/abs/2506.23940)
**中文标题：Graft：通过高效参数协同整合领域知识的多模态大语言模型**

*Yang Dai,Jianxiang An,Tianwei Lin,Hongyang He,Hongzhe Huang,Wenqiao Zhang,Zheqi Lv,Siliang Tang,Yueting Zhuang*

主要分类: cs.CL

摘要简述: 本文提出了一种统一的参数集成框架，通过兼容性感知参数拼接（CAPS）策略，实现多模态大语言模型（MLLMs）的领域知识高效融合，提升模型在多样化任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型（MLLMs）在特定任务微调后，面对不同类型数据输入时性能下降，且领域间知识共享研究不足。本文旨在解决领域专用MLLMs的知识碎片化问题。

研究方法: 提出兼容性感知参数拼接（CAPS）策略，结合局部功能归因和全局信息理论信号，选择性融合参数；扩展至低秩适应层粒度，确保高效集成；引入领域兼容性评分机制，量化专家间对齐程度。

研究结果: 在多样化多模态基准测试中验证了框架的有效性，为构建可组合、领域自适应的MLLMs提供了可扩展路径。

研究结论: 本文提出的框架成功实现了领域知识的协同融合，同时保持了结构模块化，为MLLMs的领域适应性提供了新思路。

中文摘要: 多模态大语言模型（MLLMs）已在多个领域取得成功，但在面对不同类型数据输入时，尤其是针对特定任务微调的MLLMs，其适用性往往下降。尽管领域专用MLLMs（如数学或代码领域）间的知识共享研究具有重要意义，但目前仍鲜有探索。为解决领域专用MLLMs的知识碎片化问题，我们提出了一种统一的参数集成框架，支持专家能力的模块化组合。我们的方法基于一种新颖的兼容性感知参数拼接（CAPS）策略，利用局部功能归因和全局信息理论信号指导选择性参数融合。通过将此机制扩展至低秩适应层粒度，我们确保了高效集成且推理开销最小。此外，我们引入了一种领域兼容性评分机制，量化专家间在激活层面的对齐程度，并与下游任务效用相关联。这种原则性融合协议使最终模型能够协同异构专业知识，同时保持结构模块化。在多样化多模态基准测试中的广泛评估验证了我们框架的有效性，为构建可组合、领域自适应的MLLMs提供了可扩展路径。

</details>


### [74] [Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders](https://arxiv.org/abs/2506.23951)
**中文标题：揭示大型语言模型在文本分类中的决策机制：基于稀疏自编码器提取有影响力且可解释的概念**

*Mathis Le Bail,Jérémie Dentan,Davide Buscaldi,Sonia Vanier*

主要分类: cs.CL

摘要简述: 本文提出了一种基于稀疏自编码器（SAE）的新型架构，用于提升大型语言模型（LLM）在文本分类任务中的决策可解释性。通过引入专用分类器头和激活率稀疏损失，该方法在因果性和可解释性上优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏自编码器（SAE）已被成功用于提取大型语言模型（LLM）中的可解释概念，但在文本分类领域尚未充分探索。本文旨在填补这一空白，研究SAE在句子分类任务中的有效性，并提升特征提取的因果性和可解释性。

研究方法: 本文提出了一种新型SAE架构，结合专用分类器头和激活率稀疏损失，针对文本分类任务优化。通过对比ConceptShap、独立成分分析（ICA）和其他SAE方法，评估其在Pythia家族的四个微调LLM上的表现，并引入两种新指标衡量概念解释的精确性。

研究结果: 实验结果表明，所提出的架构在因果性和可解释性上均优于现有方法。在两个分类基准测试中，新方法显著提升了特征提取的质量，并通过外部句子编码器验证了其有效性。

研究结论: 本文证明了基于SAE的架构在文本分类任务中的优越性，为LLM的决策过程提供了更透明和可解释的特征提取方法。

中文摘要: 稀疏自编码器（SAE）已成功用于探测大型语言模型（LLM）并从其内部表示中提取可解释的概念。这些概念是神经元激活的线性组合，对应人类可理解的特征。本文研究了SAE在句子分类任务中的解释性方法，这一领域尚未被广泛探索。我们提出了一种针对文本分类的新型SAE架构，结合专用分类器头和激活率稀疏损失，并与ConceptShap、独立成分分析（ICA）及其他SAE方法进行对比。评估涵盖两个分类基准和Pythia家族的四个微调LLM。我们还引入了两种新指标，利用外部句子编码器衡量概念解释的精确性。实验结果表明，我们的架构提升了提取特征的因果性和可解释性。

</details>


### [75] [TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation](https://arxiv.org/abs/2506.23979)
**中文标题：TaP：一种基于分类学的自动化可扩展偏好数据生成框架**

*Renren Jin,Tianhao Shen,Xinwei Wu,Dan Shi,Haoran Sun,Wuwei Huang,Quandong Wang,Wei Liu,Jian Luan,Bin Wang,Deyi Xiong*

主要分类: cs.CL

摘要简述: 本文提出了一种基于分类学的自动化偏好数据生成框架（TaP），用于高效构建多语言偏好数据集，显著提升大语言模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前构建高质量监督和偏好微调数据集成本高昂，且多数数据集仅限于英语。TaP旨在解决这些问题，提供一种自动化、可扩展的多语言数据集生成方法。

研究方法: TaP框架基于结构化分类学，支持细粒度控制数据集组成，确保多样性和全面覆盖。利用该框架生成的数据集对大语言模型进行监督和偏好微调。

研究结果: 实验表明，使用TaP生成的数据集训练的模型性能优于现有开源数据集训练的模型，甚至超过使用180倍大规模开源数据集训练的模型。

研究结论: TaP框架为多语言偏好数据生成提供了一种高效解决方案，显著提升了大语言模型的性能，具有广泛的应用潜力。

中文摘要: 对大语言模型（LLM）进行监督微调和偏好微调需要高质量数据集，以提升其遵循指令和符合人类偏好与价值观的能力。然而，构建此类数据集资源密集，且当前多数监督和偏好微调数据集仅限于英语。为解决这些问题，我们提出了基于分类学的偏好数据生成框架（TaP），支持自动化、可扩展的多语言偏好数据集构建。TaP基于结构化分类学，能够细粒度控制数据集组成，确保多样性和全面覆盖。我们利用TaP生成的数据集对多种LLM进行监督和偏好微调。实验结果表明，使用TaP数据集训练的LLM性能优于现有开源数据集训练的模型。值得注意的是，使用TaP数据集训练的模型性能甚至超过使用180倍大规模开源数据集训练的模型。

</details>


### [76] [Machine Understanding of Scientific Language](https://arxiv.org/abs/2506.23990)
**中文标题：机器对科学语言的理解**

*Dustin Wright*

主要分类: cs.CL

摘要简述: 本文探讨了机器理解科学语言的方法，旨在通过自然语言处理和机器学习技术，自动识别科学文本的准确性，并生成对科学传播过程的新见解。


<details>
  <summary>详细信息</summary>
研究动机: 科学文本在传播知识的同时，也存在不准确或误导性的内容。随着科学文本数量的激增，自动识别其准确性成为社会关注的重要问题。本文旨在开发数据集、方法和工具，以支持机器对科学语言的理解和分析。

研究方法: 研究在三个领域提出了贡献：自动事实核查、有限数据学习和科学文本处理。具体包括识别值得核查的声明、对抗性声明生成、多源域适应、从众包标签学习、引用价值检测、零样本科学事实核查、检测夸大的科学声明以及建模科学传播中的信息变化程度。

研究结果: 研究展示了如何利用有限的科学文本有效学习，以识别误导性科学陈述，并为科学传播过程生成新见解。

研究结论: 本文的研究成果为机器理解科学语言提供了有效工具，有助于识别科学传播中的不准确信息，并推动科学传播研究的进一步发展。

中文摘要: 科学信息表达了人类对自然的理解。这些知识主要通过科学论文、新闻文章和社交媒体上的讨论等形式传播。尽管科学文本对加速知识追求至关重要，但并非所有科学文本都忠实于其背后的科学。近年来，科学文本在网上的数量激增，自动识别其准确性已成为一个具有社会重要性的问题。本论文关注于开发数据集、方法和工具，以实现机器对科学语言的理解，从而大规模分析和理解科学传播。为此，我在自然语言处理和机器学习的三个领域提出了多项贡献：自动事实核查、有限数据学习和科学文本处理。这些贡献包括识别值得核查声明的新方法和资源、对抗性声明生成、多源域适应、从众包标签学习、引用价值检测、零样本科学事实核查、检测夸大的科学声明以及建模科学传播中的信息变化程度。重要的是，我展示了如何利用有限的科学文本有效学习，以识别误导性科学陈述，并为科学传播过程生成新见解。

</details>


### [77] [Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning](https://arxiv.org/abs/2506.23998)
**中文标题：Auto-TA：基于多智能体大语言模型与强化学习的可扩展自动化主题分析**

*Seungjun Yi,Joakim Nguyen,Huimin Xu,Terence Lim,Andrew Well,Mia Markey,Ying Ding*

主要分类: cs.CL

摘要简述: 提出了一种基于多智能体大语言模型和强化学习的自动化主题分析方法Auto-TA，用于高效分析临床叙事数据，减少人工编码需求。


<details>
  <summary>详细信息</summary>
研究动机: 先天性心脏病（CHD）的复杂性和长期挑战在传统临床指标中难以体现，而人工主题分析（TA）效率低下且难以扩展。

研究方法: 采用多智能体大语言模型框架，各智能体分工协作提升主题质量，并可选结合人类反馈强化学习（RLHF）优化主题相关性。

研究结果: 实现了对大规模临床叙事数据的自动化主题分析，支持患者为中心的研究，并可针对特定临床场景微调模型。

研究结论: Auto-TA为大规模定性数据分析提供了高效、自动化的解决方案，显著提升了主题分析的效率和可扩展性。

中文摘要: 先天性心脏病（CHD）具有复杂且终身的挑战，传统临床指标往往难以全面反映。尽管非结构化叙事数据能提供患者及护理者体验的丰富洞察，但人工主题分析（TA）仍耗时且难以扩展。我们提出了一种完全自动化的大语言模型（LLM）流程，对临床叙事进行端到端的主题分析，无需人工编码或全文审阅。该系统采用了一种新颖的多智能体框架，其中专门化的LLM智能体分工协作以提升主题质量及与人类分析的一致性。为进一步优化主题相关性，我们还可选地整合了基于人类反馈的强化学习（RLHF）。这一方法支持对大规模定性数据进行以患者为中心的分析，并允许针对特定临床场景微调LLM模型。

</details>


### [78] [Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective](https://arxiv.org/abs/2506.24006)
**中文标题：大型语言模型未能理解数学应用题：基于数学教育视角的范围综述**

*Anselm R. Strohmaier,Wim Van Dooren,Kathrin Seßler,Brian Greer,Lieven Verschaffel*

主要分类: cs.CL

摘要简述: 大型语言模型（LLMs）在解决数学应用题时表现出色，但缺乏对现实背景的理解，限制了其在数学教育中的应用价值。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（如ChatGPT）的发展，其在教育领域的应用潜力备受关注，尤其是在数学学习中的应用。然而，LLMs是否真正理解数学应用题的现实背景及其对课堂教学的影响尚不明确。本文旨在从数学教育的角度探讨这一问题。

研究方法: 本文通过三部分研究：技术概述（对比LLMs与学生对应用题的理解）、文献综述（分析213项研究中的常用应用题类型）和实证评估（测试GPT-3.5-turbo等模型在287道应用题上的表现）。

研究结果: 研究发现，LLMs在解决不需要考虑现实背景的s-problems时表现近乎完美（包括PISA的20道题），但在处理现实背景复杂或不合理的问题时表现不佳。

研究结论: LLMs虽然掌握了表面解题过程，但未能真正理解应用题的现实意义，这限制了其作为数学教学工具的潜力。

中文摘要: 大型语言模型（LLMs，如ChatGPT）的进步引发了其在教育中如何应用的讨论。人们希望它们能支持数学学习，包括解决应用题。由于LLMs能轻松处理文本输入，似乎非常适合解决数学应用题。然而，它们是否真正理解现实背景及其对课堂的影响尚不明确。我们从数学教育角度进行了范围综述，包括三部分：技术概述（对比LLMs与学生对应用题的理解）、文献综述（分析213项研究中的常用应用题类型）和实证评估（测试GPT-3.5-turbo等模型在287道应用题上的表现）。技术概述发现，计算机科学中的“数学推理”概念与数学教育中的用法不一致。文献综述显示，最流行的应用题语料库以s-problems为主，这些题目无需考虑现实背景。实证评估表明，最新LLMs在s-problems上表现近乎完美（包括PISA的20道题），但在处理现实背景复杂或不合理的问题时表现不佳。综上，我们认为LLMs掌握了表面解题过程，但未能真正理解应用题的现实意义，这限制了其作为数学教学工具的潜力。

</details>


### [79] [EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations](https://arxiv.org/abs/2506.24016)
**中文标题：EXPERT：一种基于结构化解释的可解释图像描述评估指标**

*Hyunjong Kim,Sangyeop Kim,Jongheon Jeong,Yeongjae Cho,Sungzoon Cho*

主要分类: cs.CL

摘要简述: 本文提出了一种名为EXPERT的可解释图像描述评估指标，通过结构化解释（流畅性、相关性和描述性）提供无参考评估，并在基准数据集上取得了最优效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前的可解释图像描述评估指标缺乏标准化解释标准，且解释质量未经验证。本文旨在解决这一问题，提出一种基于结构化解释的高质量评估方法。

研究方法: EXPERT通过构建大规模高质量结构化解释数据集，采用两阶段评估模板监督视觉语言模型进行评分和解释生成。

研究结果: EXPERT在基准数据集上取得了最优性能，并通过全面人工验证证明其解释质量显著优于现有指标。

研究结论: EXPERT不仅提升了图像描述评估的准确性，还通过结构化解释增强了评估的可解释性，为未来研究提供了新的方向。

中文摘要: 近年来，大型语言模型和视觉语言模型的进步引发了对可解释图像描述评估指标的兴趣。然而，这些指标生成的解释缺乏标准化标准，且解释质量未经验证。本文提出EXPERT，一种无参考评估指标，基于流畅性、相关性和描述性三项基本标准提供结构化解释。通过构建大规模高质量结构化解释数据集，我们开发了一种两阶段评估模板，有效监督视觉语言模型进行评分和解释生成。EXPERT在基准数据集上取得了最优结果，并通过全面人工验证证明其解释质量显著优于现有指标。我们的代码和数据集可在https://github.com/hjkim811/EXPERT获取。

</details>


### [80] [STACK: Adversarial Attacks on LLM Safeguard Pipelines](https://arxiv.org/abs/2506.24068)
**中文标题：STACK：针对LLM防护管道的对抗攻击**

*Ian R. McKenzie,Oskar J. Hollinsworth,Tom Tseng,Xander Davies,Stephen Casper,Aaron D. Tucker,Robert Kirk,Adam Gleave*

主要分类: cs.CL

摘要简述: 本文研究了针对大型语言模型（LLM）安全防护管道的对抗攻击，提出了一种名为STACK的新型攻击方法，并评估了其效果。研究发现，现有的防护措施存在漏洞，攻击成功率可达71%，同时提出了可能的防御建议。


<details>
  <summary>详细信息</summary>
研究动机: 前沿AI开发者依赖多层防护措施防止AI系统被灾难性滥用，但这些防护管道的安全性尚未明确。本文旨在填补这一研究空白，通过开发和测试开源防护管道，评估其脆弱性。

研究方法: 1. 开发了一种基于少样本提示的输入输出分类器，性能优于现有开源防护模型ShieldGemma；2. 提出了一种分阶段攻击方法（STACK），在无目标管道访问的情况下进行黑盒攻击；3. 在迁移设置中评估了STACK的效果。

研究结果: 1. 少样本提示分类器在ClearHarm数据集上将攻击成功率降至0%；2. STACK在ClearHarm数据集上的黑盒攻击成功率达71%，迁移攻击成功率为33%。

研究结论: 现有防护管道存在显著漏洞，STACK攻击方法展示了其脆弱性。开发者需采取特定措施防御分阶段攻击。

中文摘要: 前沿AI开发者依赖多层防护措施防止AI系统被灾难性滥用。Anthropic为其最新Claude 4 Opus模型部署了此类防护管道，其他开发者如Google DeepMind和OpenAI也计划部署类似防御。然而，这些管道的安全性尚不明确，此前相关研究有限。本文通过开发和红队测试开源防护管道填补了这一空白。首先，我们发现一种基于少样本提示的输入输出分类器在三种攻击和两个数据集上优于开源防护模型ShieldGemma，在ClearHarm灾难性滥用数据集上将攻击成功率降至0%。其次，我们提出了一种分阶段攻击方法（STACK），在针对少样本提示分类器管道的黑盒攻击中，ClearHarm数据集的攻击成功率达71%。最后，我们在迁移设置中评估了STACK，攻击成功率为33%，初步证明无需目标管道访问即可设计攻击。我们建议开发者采取特定措施防御分阶段攻击。

</details>


### [81] [On the Predictive Power of Representation Dispersion in Language Models](https://arxiv.org/abs/2506.24106)
**中文标题：语言模型中表示分散度的预测能力**

*Yanhong Li,Ming Li,Karen Livescu,Jiawei Zhou*

主要分类: cs.CL

摘要简述: 研究发现语言模型的预测能力与其嵌入空间的广度密切相关，表示分散度（隐藏向量间的平均余弦距离）与困惑度呈强负相关。通过利用分散度，可实现无标签数据的模型选择、优化检索方法，并通过简单训练目标提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 探讨语言模型的预测能力与其表示分散度之间的关系，并探索如何利用这一关系提升模型在实际任务中的表现。

研究方法: 通过分析不同模型家族（如LLaMA、Qwen）和领域（如维基百科、新闻、科学摘要）的表示分散度与困惑度的相关性，提出利用分散度进行模型选择、优化检索方法，并通过训练目标增加分散度。

研究结果: 表示分散度与困惑度呈强负相关，分散度可用于无标签数据的模型选择和优化检索方法，通过训练目标增加分散度能直接降低困惑度。

研究结论: 表示分散度是语言模型预测能力的重要指标，其应用可显著提升模型性能，尤其在无标签数据场景下具有实用价值。

中文摘要: 研究表明，语言模型的文本预测能力与其嵌入空间的广度密切相关：表示分散度（隐藏向量间的平均余弦距离）越高的模型，困惑度越低。具体而言，我们发现表示分散度与困惑度在不同模型家族（如LLaMA、Qwen）和领域（如维基百科、新闻、科学摘要）中均呈强负相关。除了揭示这一联系，我们还展示了如何利用分散度进行一系列无需标签数据的实际任务。首先，通过测量无标签文本的分散度，可以预测模型在新领域中的下游准确性，为模型选择提供高效工具。其次，识别分散度较高的层可直接优化检索方法（如kNN-LM），避免逐层搜索。最后，我们在训练中引入简单的“推离”目标，增加单领域和跨领域场景中的分散度，直接降低困惑度。

</details>


### [82] [Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models](https://arxiv.org/abs/2506.24117)
**中文标题：基于Transformer语言模型的希伯来圣经文本平行段落计算检测：一项基准研究**

*David M. Smiley*

主要分类: cs.CL

摘要简述: 本研究评估了基于Transformer的预训练语言模型（如E5、AlephBERT、MPNet和LaBSE）在检测希伯来圣经文本平行段落中的潜力，发现E5和AlephBERT表现优异，为古代文本研究提供了高效工具。


<details>
  <summary>详细信息</summary>
研究动机: 传统识别希伯来圣经平行段落的方法依赖人工比对，效率低且易出错。本研究旨在探索预训练语言模型在提升检测效率和准确性方面的潜力。

研究方法: 研究使用E5、AlephBERT、MPNet和LaBSE等预训练模型生成词嵌入，并通过余弦相似度和Wasserstein距离度量评估模型在识别撒母耳记/列王纪与历代志之间平行段落的能力。

研究结果: E5在平行段落检测中表现最佳，而AlephBERT在区分非平行段落方面更强。这些模型显著提升了检测效率和准确性。

研究结论: 预训练语言模型能够高效准确地检测希伯来圣经中的平行段落，为古代语言研究提供了新的技术手段。

中文摘要: 识别希伯来圣经中的平行段落是揭示文本间关系的基础性工作。传统方法依赖人工比对，效率低且易出错。本研究评估了预训练的Transformer语言模型（包括E5、AlephBERT、MPNet和LaBSE）在检测希伯来圣经文本平行段落中的潜力。研究聚焦于撒母耳记/列王纪与历代志之间的已知平行段落，评估各模型生成词嵌入以区分平行与非平行段落的能力。通过余弦相似度和Wasserstein距离度量，发现E5和AlephBERT表现突出，其中E5在平行检测中表现优异，而AlephBERT在非平行区分方面更强。这些结果表明，预训练模型能够提升古代文本中平行段落检测的效率和准确性，为古代语言研究提供了更广泛的应用前景。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [83] [Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring](https://arxiv.org/abs/2506.22437)
**中文标题：基于图像的结构健康监测中真实世界裂纹演化的鲁棒透视校正**

*Xinxin Sun,Peter Chang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于物理信息的图像对齐框架，通过改进KAZE架构，解决了结构健康监测中因透视畸变、遮挡和低对比度导致的裂纹定位问题，显著提升了裂纹面积和长度的测量精度。


<details>
  <summary>详细信息</summary>
研究动机: 在结构健康监测（SHM）中，传统的特征检测方法（如SIFT、SURF）因抑制高频边缘而不适用于薄裂纹定位，而轻量级二进制方法（如ORB、BRISK）在纹理或阴影表面表现不佳。因此，需要一种无需训练或参数调优的鲁棒对齐方法。

研究方法: 研究提出了一种基于非线性各向异性扩散的裂纹保留尺度空间构建方法，结合RANSAC单应性估计，实现了无需训练或校准的几何校正。该方法适用于手持智能手机拍摄的砖石和混凝土时序图像。

研究结果: 实验表明，与传统检测器相比，该方法将裂纹面积和长度误差分别降低了70%和90%，同时关键指标的对齐误差保持在5%以下。

研究结论: 该方法无需监督、可解释且计算轻量，适用于无人机和移动平台的大规模部署，为真实世界裂纹演化跟踪提供了鲁棒且物理基础的技术替代方案。

中文摘要: 准确的图像对齐对于结构健康监测（SHM）中的裂纹演化监测至关重要，尤其是在涉及透视畸变、遮挡和低对比度的真实世界条件下。然而，传统的基于高斯尺度空间的特征检测器（如SIFT和SURF）往往会抑制高频边缘，使其不适用于薄裂纹定位。轻量级二进制替代方法（如ORB和BRISK）虽然计算高效，但在纹理或阴影表面上的关键点重复性较差。本研究提出了一种基于物理信息的对齐框架，通过改进开放的KAZE架构以适应SHM特有的挑战。通过利用非线性各向异性扩散构建裂纹保留尺度空间，并结合基于RANSAC的单应性估计，该框架实现了无需训练、参数调优或预先校准的精确几何校正。该方法在手持智能手机拍摄的砖石和混凝土时序图像上进行了验证，测试条件包括阴影干扰、裁剪、斜视角和表面杂乱。与传统检测器相比，所提出的框架将裂纹面积和长度误差分别降低了70%和90%，同时关键指标的对齐误差保持在5%以下。该方法无需监督、可解释且计算轻量，支持通过无人机和移动平台进行可扩展部署。通过将非线性尺度空间建模应用于SHM图像对齐，本研究为跟踪真实世界裂纹演化提供了一种鲁棒且物理基础的技术替代方案。

</details>


### [84] [Counting with Confidence: Accurate Pest Monitoring in Water Traps](https://arxiv.org/abs/2506.22438)
**中文标题：精准计数：水陷阱中害虫监测的置信度评估**

*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

主要分类: cs.CV

摘要简述: 本文提出了一种基于计数结果和外部环境信息的害虫计数置信度评估方法，通过多因素敏感性分析和自适应DBSCAN聚类算法，显著提升了计数置信度的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于视觉的害虫自动计数研究通常缺乏对计数结果可靠性的评估，导致模型在实际应用中表现不佳。本文旨在填补这一空白，提出一种全面的计数置信度评估方法。

研究方法: 首先使用害虫检测网络进行检测和计数，提取计数结果相关信息；然后通过图像质量评估、图像复杂度评估和害虫分布均匀性评估，量化外部环境因素；最后通过回归模型预测计数置信度。

研究结果: 实验结果表明，该方法在害虫计数置信度测试集上，相比基线模型，均方误差降低了31.7%，R2提高了15.2%。

研究结论: 本文首次提出了一种全面的害虫计数置信度评估方法，并通过模型量化了影响因素与计数置信度的关系，为精准农业决策提供了可靠支持。

中文摘要: 准确的害虫种群监测及其动态变化追踪对精准农业决策至关重要。现有基于视觉的害虫自动计数研究通常仅在有真实标签的数据集上评估模型，而在实际应用中因缺乏真实标签而无法评估计数结果的可靠性。为此，本文提出了一种基于计数结果和外部环境信息的害虫计数置信度评估方法。首先，使用害虫检测网络进行害虫检测和计数，提取计数结果相关信息；然后，对害虫图像进行图像质量评估、图像复杂度评估和害虫分布均匀性评估，并通过计算平均梯度幅值量化图像采集过程中搅拌导致的清晰度变化。值得注意的是，我们设计了一种假设驱动的多因素敏感性分析方法，以选择最优的图像质量评估和图像复杂度评估方法；并提出了一种自适应DBSCAN聚类算法用于害虫分布均匀性评估。最后，将计数结果和外部环境信息输入回归模型进行预测，得到最终的害虫计数置信度。据我们所知，这是首个专注于全面评估计数任务中计数置信度的研究，并通过模型量化了影响因素与计数置信度的关系。实验结果表明，与主要基于计数结果信息的基线模型相比，我们的方法在害虫计数置信度测试集上均方误差降低了31.7%，R2提高了15.2%。

</details>


### [85] [Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization](https://arxiv.org/abs/2506.22463)
**中文标题：调制扩散：通过调制量化加速生成建模**

*Weizhi Gao,Zhichao Hou,Junqi Yin,Feiyi Wang,Linyu Peng,Xiaorui Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为调制扩散（MoDiff）的创新框架，通过调制量化和误差补偿加速扩散模型的生成过程，显著降低了计算成本，同时保持生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成任务中表现出色，但其迭代采样的高计算成本成为主要瓶颈。现有加速技术（如缓存和量化）在计算误差和生成质量方面存在局限，因此需要一种更高效的解决方案。

研究方法: MoDiff框架结合了调制量化和误差补偿技术，不仅继承了现有缓存和量化方法的优势，还能作为通用框架加速所有扩散模型。其理论分析和实验验证了其有效性。

研究结果: 在CIFAR-10和LSUN数据集上的实验表明，MoDiff将激活量化从8位降至3位，且在后训练量化（PTQ）中未出现性能下降。

研究结论: MoDiff为扩散模型提供了一种高效且通用的加速方案，显著降低了计算成本，同时保持了生成质量，具有广泛的应用潜力。

中文摘要: 扩散模型已成为强大的生成模型，但其迭代采样的高计算成本仍是一个显著瓶颈。本文深入研究了扩散模型的最先进加速技术（包括缓存和量化），揭示了其在计算误差和生成质量方面的局限性。为突破这些限制，本文提出了调制扩散（MoDiff），一种创新、严谨且原理性的框架，通过调制量化和误差补偿加速生成建模。MoDiff不仅继承了现有缓存和量化方法的优势，还能作为通用框架加速所有扩散模型。MoDiff的优势得到了坚实的理论分析和实验支持。此外，在CIFAR-10和LSUN上的大量实验表明，MoDiff将激活量化从8位降至3位，且在后训练量化（PTQ）中未出现性能下降。我们的代码实现可在https://github.com/WeizhiGao/MoDiff获取。

</details>


### [86] [ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction](https://arxiv.org/abs/2506.22498)
**中文标题：ViFusionTST：基于负载信号的时间序列图像表示深度融合用于早期离床预测**

*Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu*

主要分类: cs.CV

摘要简述: 本文提出ViFusionTST模型，通过融合时间序列图像表示，利用低成本负载传感器信号预测患者离床意图，有效预防跌倒。


<details>
  <summary>详细信息</summary>
研究动机: 医院和长期护理机构中，患者离床导致的跌倒是常见伤害来源，现有警报系统仅在患者离床后触发。本文旨在通过低成本负载传感器信号提前预测离床意图，减少跌倒风险。

研究方法: 使用四个低成本负载传感器采集信号，将其转换为互补图像（RGB线图和三种纹理图）。提出ViFusionTST模型，采用双流Swin Transformer并行处理图像并通过交叉注意力融合，学习数据驱动的模态权重。

研究结果: 在长期护理机构六个月的连续数据上，ViFusionTST达到0.885的准确率和0.794的F1分数，优于现有1D和2D时间序列基线模型。

研究结论: 基于图像融合的负载传感器信号分类是一种实用且有效的方法，可实时保护隐私并预防跌倒。

中文摘要: 与床相关的跌倒是医院和长期护理机构中常见的伤害来源，但许多商业警报仅在患者离床后触发。我们证明，仅需在床腿安装四个低成本负载传感器即可预测早期离床意图。负载信号首先被转换为一组互补图像：保留原始波形的RGB线图，以及三种揭示高阶动态的纹理图（递归图、马尔可夫转移场和格拉米安角场）。我们提出ViFusionTST，一种双流Swin Transformer，并行处理线图和纹理图，并通过交叉注意力融合以学习数据驱动的模态权重。为提供真实基准，我们从长期护理机构的95张床收集了六个月的连续数据。在此真实数据集上，ViFusionTST达到0.885的准确率和0.794的F1分数，在F1、召回率、准确率和AUPRC上均优于近期1D和2D时间序列基线模型。结果表明，基于图像融合的负载传感器信号分类是一种实用且有效的实时隐私保护跌倒预防解决方案。

</details>


### [87] [Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data](https://arxiv.org/abs/2506.22499)
**中文标题：基于高分辨率卫星影像数据的可扩展动态起讫点需求估计**

*Jiachao Liu,Pablo Guarda,Koichiro Niinuma,Sean Qian*

主要分类: cs.CV

摘要简述: 本文提出了一种结合高分辨率卫星影像与传统交通数据的动态起讫点需求估计框架，显著提升了无本地传感器路段的估计精度，并验证了其在大规模网络中的适用性。


<details>
  <summary>详细信息</summary>
研究动机: 传统动态起讫点需求估计（DODE）依赖稀疏的本地传感器数据，存在数据覆盖不足的问题。高分辨率卫星影像能提供城市范围内一致的交通信息，包括停车和移动车辆，弥补了传统数据的局限性。

研究方法: 设计了一个计算机视觉流程，用于分类车辆检测和地图匹配，生成基于车辆类别的路段级交通密度观测数据。结合传统传感器数据，构建了一个基于计算图的DODE模型，联合校准动态网络状态。

研究结果: 实验表明，结合卫星影像数据显著提升了需求估计的准确性，尤其对无本地传感器的路段效果明显。实际数据测试验证了框架在大规模网络中的可行性和实用性。

研究结论: 该框架通过整合卫星影像数据，有效解决了传统DODE的数据局限性，为不同规模城市的实际应用提供了潜力。

中文摘要: 本研究提出了一种新颖的动态起讫点需求估计（DODE）集成框架，用于多类别宏观网络模型，结合高分辨率卫星影像与传统本地传感器交通数据。与稀疏的本地探测器不同，卫星影像提供了城市范围内一致的停车和移动车辆的道路与交通信息，克服了数据可用性的限制。为从影像数据中提取信息，我们设计了一个计算机视觉流程，用于分类车辆检测和地图匹配，生成基于车辆类别的路段级交通密度观测数据。基于此信息，我们构建了一个基于计算图的DODE模型，通过联合匹配本地传感器的交通计数和旅行时间与卫星影像衍生的密度测量值，校准动态网络状态。为评估所提框架的准确性和可扩展性，我们使用合成和实际数据进行了系列数值实验。样本外测试结果表明，补充传统数据与卫星衍生的密度显著提升了估计性能，尤其对无本地传感器的路段。实际实验也验证了框架处理大规模网络的能力，支持其在不同规模城市中的实际部署潜力。敏感性分析进一步评估了卫星影像数据质量的影响。

</details>


### [88] [Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models](https://arxiv.org/abs/2506.22500)
**中文标题：手术室中的视觉-语义知识冲突：多模态大语言模型手术风险感知的合成数据构建**

*Weiyi Zhao,Xiaoyu Tan,Liang Liu,Sijia Li,Youwei Song,Xihe Qiu*

主要分类: cs.CV

摘要简述: 本文提出了一种通过合成数据解决多模态大语言模型（MLLMs）在手术室风险感知中的视觉-语义知识冲突（VS-KC）的方法，并发布了一个包含3.4万张合成图像和214张人工标注图像的开放数据集OR-VSKC。实验表明，微调后的模型在训练过的冲突实体检测上表现显著提升，但对未训练实体类型仍表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 手术风险识别对患者安全和减少可预防医疗错误至关重要。尽管多模态大语言模型（MLLMs）在自动化手术室风险检测中展现出潜力，但其常因视觉-语义知识冲突（VS-KC）而无法识别视觉安全违规行为。为解决这一问题，本文旨在通过合成数据填补数据稀缺性并研究MLLMs的脆弱性。

研究方法: 本文提出了一种数据生成方法，通过扩散模型生成了3.4万张包含违反安全规则实体的手术室场景合成图像，并辅以214张人工标注图像作为验证基准。数据集涵盖多种视角、阶段和配置，用于暴露和研究VS-KC。通过微调OR-VSKC数据集，评估MLLMs的性能。

研究结果: 实验结果显示，微调后的MLLMs在训练过的冲突实体检测上表现显著提升，并能较好地泛化到新视角下的这些实体。然而，对未训练实体类型的检测性能仍然较差，表明模型学习具有特异性，需要更全面的训练。

研究结论: 本文的主要贡献包括：（1）针对规则违反场景的数据生成方法；（2）开放了OR-VSKC数据集及其基准；（3）对代表性MLLMs的违规敏感知识一致性进行了实证分析。数据集和分析结果为进一步研究VS-KC提供了资源。

中文摘要: 手术风险识别对患者安全和减少可预防医疗错误至关重要。尽管多模态大语言模型（MLLMs）在自动化手术室风险检测中展现出潜力，但其常因视觉-语义知识冲突（VS-KC）而无法识别视觉安全违规行为。为解决这一问题，我们引入了一个包含3.4万张扩散模型生成的合成图像的数据集，这些图像描绘了违反安全规则的手术室场景。这些图像旨在缓解数据稀缺性并研究MLLMs的脆弱性。此外，数据集还包括214张人工标注图像作为验证基准。这一涵盖多种视角、阶段和配置的综合数据集旨在暴露和研究VS-KC。实验表明，微调OR-VSKC显著提升了MLLMs对训练过的冲突实体的检测能力，并能较好地泛化到新视角下的这些实体，但对未训练实体类型的检测性能仍然较差，凸显了学习的特异性及全面训练的必要性。本文的主要贡献包括：（1）针对规则违反场景的数据生成方法；（2）开放了OR-VSKC数据集及其基准；（3）对代表性MLLMs的违规敏感知识一致性进行了实证分析。数据集及附录见https://github.com/zgg2577/VS-KC。

</details>


### [89] [How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?](https://arxiv.org/abs/2506.22501)
**中文标题：多模态遥感数据集如何通过SpatialNet-ViT改变分类任务？**

*Gautam Siddharth Kashyap,Manaswi Kulahara,Nipun Joshi,Usman Naseem*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SpatialNet-ViT的新型模型，结合了Vision Transformers和多任务学习，旨在提升遥感数据分类的准确性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的遥感数据分类研究多局限于特定任务或数据集，泛化能力不足。本文旨在通过结合空间感知和上下文理解，提出一种能够广泛适用于多种遥感分类任务的模型。

研究方法: 提出SpatialNet-ViT模型，结合Vision Transformers和多任务学习，并采用数据增强、迁移学习和多任务学习等技术提升模型的鲁棒性和泛化能力。

研究结果: SpatialNet-ViT在分类准确性和跨数据集泛化能力方面表现出显著提升。

研究结论: SpatialNet-ViT通过结合空间感知和上下文理解，为遥感数据分类提供了一种高效且可扩展的解决方案。

中文摘要: 遥感数据集在解决土地利用分类、目标检测和城乡分类等关键任务方面具有巨大潜力。然而，现有研究多局限于特定任务或数据集，限制了其泛化能力。为此，我们提出了一种新型模型SpatialNet-ViT，结合了Vision Transformers和多任务学习的优势。该模型通过整合空间感知和上下文理解，显著提升了分类准确性和可扩展性。此外，还采用了数据增强、迁移学习和多任务学习等技术，进一步增强模型的鲁棒性和跨数据集泛化能力。

</details>


### [90] [What Makes a Dribble Successful? Insights From 3D Pose Tracking Data](https://arxiv.org/abs/2506.22503)
**中文标题：是什么让盘带成功？来自3D姿态追踪数据的洞察**

*Michiel Schepers,Pieter Robberechts,Jan Van Haaren,Jesse Davis*

主要分类: cs.CV

摘要简述: 本研究利用3D姿态追踪数据分析足球中的盘带成功因素，发现攻击者的平衡及与防守者的方向对齐是关键特征，结合传统2D数据可提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 足球数据分析中，传统2D位置数据无法全面捕捉盘带中的平衡、方向和控球等关键因素，限制了分析的深度。本研究旨在通过3D姿态追踪数据，更深入地理解盘带技能。

研究方法: 研究从2022/23赛季欧冠联赛的1,736次盘带中提取基于姿态的新特征，并结合传统2D位置数据，评估这些特征对盘带成功的影响。

研究结果: 结果显示，攻击者的平衡及其与防守者的方向对齐是预测盘带成功的关键特征。结合3D姿态特征和2D位置数据显著提升了模型性能。

研究结论: 3D姿态追踪数据为足球盘带分析提供了更丰富的视角，结合传统数据可显著提升预测准确性，为未来足球技术分析开辟了新方向。

中文摘要: 数据分析在足球中扮演着越来越重要的角色，为评估个人和团队表现提供了新方法。其中一个具体应用是对盘带的评估：即攻击者试图带球绕过防守者的一对一情景。以往研究主要依赖2D位置追踪数据，但无法捕捉平衡、方向和控球等方面，限制了当前分析的深度。本研究探讨了姿态追踪数据（捕捉球员在三维空间中的姿势和动作）如何提升我们对盘带技能的理解。我们从2022/23赛季欧冠联赛的1,736次盘带中提取了新的基于姿态的特征，并评估了它们对盘带成功的影响。结果表明，捕捉攻击者平衡及其与防守者方向对齐的特征对预测盘带成功具有信息价值。在传统2D位置数据基础上加入这些姿态特征，显著提升了模型性能。

</details>


### [91] [Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection](https://arxiv.org/abs/2506.22504)
**中文标题：Patch2Loc：学习定位局部区域以实现无监督脑部病变检测**

*Hassan Baker,Austin J. Brockmeier*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Patch2Loc的无监督方法，通过学习正常脑部MRI图像中的局部区域来定位异常脑部病变，无需标注数据。该方法通过预测局部区域的空间位置误差检测异常，并在多个数据集上表现优于现有无监督分割方法。


<details>
  <summary>详细信息</summary>
研究动机: 脑部病变检测在MRI诊断中至关重要，但现有监督学习方法需要大量标注数据。本文旨在开发一种无监督方法，仅利用正常脑部MRI图像中的局部区域信息，实现异常病变的自动检测。

研究方法: Patch2Loc通过训练神经网络模型，将MRI图像中的局部区域映射回其空间位置。在推理阶段，通过预测位置误差和方差较高的区域检测异常病变，生成热图并用于像素级分割。

研究结果: 在BraTS2021、MSLUB、ATLAS和WMH等数据集上的实验表明，Patch2Loc在无监督分割任务中优于现有方法，能够有效检测肿瘤等异常脑组织。

研究结论: Patch2Loc为无监督脑部病变检测提供了一种高效方法，仅需正常MRI图像即可实现异常区域的定位，具有广泛的应用潜力。

中文摘要: 通过磁共振成像（MRI）检测脑部病变对诊断和治疗至关重要。在寻找肿瘤和畸形等异常时，计算机辅助诊断系统可以帮助放射科医生区分正常与异常脑组织。尽管监督学习方法需要标注的病变数据，我们提出了一种新的无监督方法（Patch2Loc），该方法通过学习结构MRI中的正常局部区域来实现检测。我们训练了一个神经网络模型，将局部区域映射回其在脑部切片中的空间位置。在推理阶段，通过预测位置误差和方差较高的区域检测异常，生成热图并用于像素级分割。我们在BraTS2021、MSLUB、ATLAS和WMH数据集上验证了该方法对肿瘤等异常脑组织的分割能力，结果表明其性能优于现有无监督分割方法。代码已发布于GitHub页面。

</details>


### [92] [Weakly Supervised Object Segmentation by Background Conditional Divergence](https://arxiv.org/abs/2506.22505)
**中文标题：基于背景条件差异的弱监督目标分割**

*Hassan Baker,Matthew S. Emigh,Austin J. Brockmeier*

主要分类: cs.CV

摘要简述: 本文提出了一种基于弱监督的二元目标分割方法，通过背景条件差异实现目标分割，适用于缺乏大量标注数据的领域。


<details>
  <summary>详细信息</summary>
研究动机: 在计算机视觉任务中，自动目标分割在缺乏大量标注数据的专业图像领域（如合成孔径声纳图像、遥感、生物医学成像等）仍然具有挑战性。本文旨在利用图像级别的目标存在或缺失作为弱监督信号，减少标注成本。

研究方法: 提出了一种训练掩码网络的方法，通过将分割的目标放置到背景图像中生成反事实图像，并利用背景聚类和目标背景差异作为训练损失的一部分。此外，还引入了背景图像的监督损失。

研究结果: 实验表明，该方法在侧扫声纳和合成孔径声纳图像上优于之前的无监督分割基线，并在自然图像上表现出合理的性能，避免了预训练网络、生成网络和对抗判别器的使用。

研究结论: 本文提出的弱监督目标分割方法在减少标注成本的同时，实现了有效的分割性能，适用于多种图像领域。

中文摘要: 作为一项计算机视觉任务，自动目标分割在缺乏大量标注数据的专业图像领域（如合成孔径声纳图像、遥感、生物医学成像等）仍然具有挑战性。在任何领域中，获取像素级的分割掩码成本高昂。本文提出了一种方法，通过图像级别的目标存在或缺失作为弱监督信号，训练掩码网络进行二元目标分割。该方法的关键步骤是将分割的目标放置到背景图像中，生成具有反事实背景的真实图像。为了在原始图像和反事实背景图像之间形成对比，我们首先对背景图像进行聚类，然后在学习过程中将分割的目标从原始背景融合到目标聚类的背景中。训练损失的一部分是这些反事实图像与目标聚类背景的真实目标图像之间的差异。另一部分是背景图像的监督损失。虽然对抗判别器可以提供这种差异，但我们使用了基于样本的差异。我们在侧扫声纳和合成孔径声纳图像上进行了实验，结果表明该方法优于之前仅在自然图像上测试的无监督分割基线。此外，为了展示通用性，我们将实验扩展到自然图像，结果表明我们的方法在不使用预训练网络、生成网络和对抗判别器的情况下仍能取得合理的性能。本工作的基础代码可在GitHub上找到：https://github.com/bakerhassan/WSOS。

</details>


### [93] [FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment](https://arxiv.org/abs/2506.22509)
**中文标题：FreeDNA：基于扩散的密集预测模型的无训练域噪声对齐域适应方法**

*Hang Xu,Jie Huang,Linjiang Huang,Dong Li,Yidi Liu,Feng Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的域噪声对齐方法（DNA），用于增强基于扩散的密集预测模型的域适应能力，通过调整噪声统计量实现跨域性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在密集预测任务中表现出色，但域适应问题限制了其跨域性能。研究发现噪声统计量的偏差会导致域偏移，因此提出通过噪声统计量对齐实现域适应。

研究方法: 提出训练自由的域噪声对齐（DNA）方法，通过调整扩散采样过程中的噪声统计量，使其与源域对齐。对于无源域情况，利用高置信区域的噪声统计量逐步引导调整。

研究结果: 在四种常见的密集预测任务中验证了方法的有效性，显著提升了基于扩散的密集预测模型的域适应能力。

研究结论: DNA方法无需训练即可实现域适应，为基于扩散的密集预测模型提供了高效的跨域解决方案。

中文摘要: 域适应（DA）是密集预测任务中的重要课题，旨在提升模型在未见域上的性能。随着基于扩散的密集预测（DDP）模型的发展，针对其框架的域适应设计值得探索，因为扩散模型能有效建模包含域信息的分布变换。本文提出了一种无需训练的机制，赋予DDP框架域适应能力。动机源于扩散中的噪声统计偏差会导致域偏移，而DDP模型中的不同域也可通过噪声预测统计量有效捕捉。基于此，我们提出了一种无需训练的域噪声对齐（DNA）方法，通过调整扩散采样过程中的噪声统计量以缓解域变化带来的噪声统计量差异，从而实现域适应。具体而言，当源域可用时，直接通过DNA方法将目标域的噪声统计量与源域对齐；对于更具挑战性的无源域DA，利用高置信区域的统计量逐步引导采样过程中的噪声统计量调整。实验表明，该方法在四种常见密集预测任务中均显著提升了DDP模型的域适应能力。代码发布于\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}。

</details>


### [94] [Lightning the Night with Generative Artificial Intelligence](https://arxiv.org/abs/2506.22511)
**中文标题：利用生成式人工智能点亮夜空**

*Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang*

主要分类: cs.CV

摘要简述: 本研究利用生成扩散模型，基于风云4B卫星的多波段热红外亮温数据，开发了RefDiff模型，实现了夜间可见光反射率的高精度反演，显著提升了复杂云区和厚云区的准确性，并提供了不确定性估计。


<details>
  <summary>详细信息</summary>
研究动机: 由于夜间缺乏可见光，无法利用可见光反射率数据进行全天候气象观测。本研究旨在通过生成扩散模型解决这一限制，扩展夜间可见光数据的应用。

研究方法: 基于风云4B卫星的AGRI多波段热红外亮温数据，开发了RefDiff模型，通过生成扩散技术实现0.47μm、0.65μm和0.825μm波段的夜间可见光反射率反演，并结合集成平均提升精度。

研究结果: RefDiff模型的SSIM指数可达0.90，在复杂云结构和厚云区表现尤为显著。通过VIIRS夜间产品验证，其性能与白天相当。

研究结论: 研究显著提升了夜间可见光反射率的反演能力，为夜间可见光数据的应用提供了新可能。

中文摘要: 地球静止卫星的可见光反射率数据对气象观测至关重要，在天气监测和预报中发挥重要作用。然而，由于夜间缺乏可见光，无法利用可见光反射率数据进行全天候连续观测。本研究首次采用生成扩散模型解决这一问题。基于风云4B卫星搭载的先进地球静止辐射成像仪（AGRI）的多波段热红外亮温数据，我们开发了一种高精度的可见光反射率反演模型——反射率扩散模型（RefDiff），实现了夜间0.47μm、0.65μm和0.825μm波段的可见光反射率反演。与经典模型相比，RefDiff不仅通过集成平均显著提高了精度，还提供了不确定性估计。具体而言，RefDiff的SSIM指数可达0.90，在复杂云结构和厚云区的改进尤为显著。通过VIIRS夜间产品验证，该模型的夜间反演性能与白天相当。总之，本研究在夜间可见光反射率反演能力方面取得了重大进展，有望扩展夜间可见光数据的应用范围。

</details>


### [95] [Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence](https://arxiv.org/abs/2506.22513)
**中文标题：人工智能在NDE 4.0中应用的自动化缺陷识别与分类**

*Aditya Sharma*

主要分类: cs.CV

摘要简述: 本研究提出了一种基于人工智能的自动化缺陷识别与分类框架，应用于NDE 4.0中的现代射线检测。通过数据增强和改进的U-net模型，实现了高效的缺陷检测，并在实际测试中表现出高灵敏度和快速处理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前NDE 4.0中缺乏足够解释的信息，且需要优化虚拟缺陷增强技术。本研究旨在填补这一空白，并通过NDE测量验证框架的可行性。

研究方法: 方法包括收集并分类223张飞机焊缝的CR图像，使用虚拟缺陷增强和标准增强技术优化数据集。改进的U-net模型用于生成语义缺陷分割掩码，并通过NDE边界（如Case、估计准确率和误报率）评估模型性能。

研究结果: 结果显示，提出的方法在缺陷检测中表现出高灵敏度（a90/95特性），且结合增强技术显著优于其他方法。模型处理速度快，适用于大图像分析。专业评估人员认为其在实际测试中具有潜力。

研究结论: 该框架在NDE 4.0中表现出高效和实用性，能够快速准确地识别缺陷，并可作为测试周期的支持工具。

中文摘要: 本研究旨在为现代射线检测（NDE 4.0）开发一种自动化缺陷检测与分类框架。研究目标包括解决信息解释不足的问题、优化虚拟缺陷增强技术，并通过NDE测量验证框架的可行性。方法包括收集和分类223张飞机焊缝的CR图像，使用虚拟缺陷增强和标准增强技术优化数据集。改进的U-net模型用于生成语义缺陷分割掩码，并通过NDE边界（如Case、估计准确率和误报率）评估模型性能。结果显示，提出的方法在缺陷检测中表现出高灵敏度（a90/95特性），且结合增强技术显著优于其他方法。模型处理速度快，适用于大图像分析。专业评估人员认为其在实际测试中具有潜力，可作为测试周期的支持工具。

</details>


### [96] [Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis](https://arxiv.org/abs/2506.22517)
**中文标题：集装箱损伤检测：Yolov12、Yolov11与RF-DETR的对比分析**

*Subhadip Kumar*

主要分类: cs.CV

摘要简述: 本文比较了三种先进的计算机视觉模型（Yolov12、Yolov11和RF-DETR）在集装箱损伤检测中的性能。结果显示，Yolov11和Yolov12在mAP@50上表现更好（81.9%），而RF-DETR在检测不常见损伤时表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 集装箱是物流行业的重要组成部分，其损伤可能带来安全隐患和经济损失。因此，及时检测集装箱损伤对延长使用寿命和保障安全至关重要。本文旨在比较三种先进模型在损伤检测中的表现，以确定最适合的模型。

研究方法: 使用278张标注图像的数据集对Yolov12、Yolov11和RF-DETR进行训练、验证和测试，并比较它们的mAP和精度指标。

研究结果: Yolov11和Yolov12的mAP@50得分为81.9%，优于RF-DETR的77.7%。然而，RF-DETR在检测不常见损伤时表现更优，能够更准确地识别损伤及其发生位置。

研究结论: Yolov11和Yolov12在常规损伤检测中表现更好，而RF-DETR在不常见损伤检测中更具优势。选择模型需根据具体应用场景。

中文摘要: 集装箱是物流行业的重要组成部分，其使用寿命通常超过20年。然而，由于机械和自然因素的影响，集装箱会遭受各种损伤。损伤集装箱不仅对操作人员构成安全隐患，也是物流公司的潜在责任。因此，及时检测集装箱损伤对延长使用寿命和避免安全隐患至关重要。本文比较了三种先进的计算机视觉模型（Yolov12、Yolov11和RF-DETR）在损伤检测中的性能。我们使用278张标注图像的数据集对模型进行训练、验证和测试，并比较其mAP和精度。结果表明，Yolov11和Yolov12的mAP@50得分为81.9%，优于RF-DETR的77.7%。然而，在检测不常见损伤时，RF-DETR表现更优，能够更准确地识别损伤及其发生位置。本文的目标是确定最适合集装箱损伤检测的模型。

</details>


### [97] [Preserve Anything: Controllable Image Synthesis with Object Preservation](https://arxiv.org/abs/2506.22531)
**中文标题：保留一切：可控的图像合成与对象保存**

*Prasen Kumar Sharma,Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“Preserve Anything”的新方法，用于解决文本到图像生成中对象保存和语义一致性的关键问题。该方法通过多通道ControlNet实现对象保存、高分辨率背景和用户控制，显著提升了生成图像的质量和语义对齐。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到图像生成方法在保存多个对象、语义对齐和场景控制方面存在不足。本文旨在解决这些问题，提供更高质量的图像合成和用户控制能力。

研究方法: 采用N通道ControlNet，结合对象保存模块、背景引导模块和高频覆盖模块，确保对象细节保留、语义一致性和用户控制。同时引入包含24万张自然图像和1.8万张合成图像的基准数据集。

研究结果: 实验结果显示，该方法在特征空间保真度（FID 15.26）和语义对齐（CLIP-S 32.85）上达到最优性能，用户研究也证实其在提示对齐、真实感、减少AI伪影和自然美学方面显著优于现有方法。

研究结论: “Preserve Anything”方法在对象保存、语义一致性和用户控制方面表现出色，为文本到图像生成提供了更高质量的解决方案。

中文摘要: 我们提出了“保留一切”（Preserve Anything），一种用于可控图像合成的新方法，解决了文本到图像（T2I）生成中对象保存和语义一致性的关键限制。现有方法通常无法（i）高保真地保存多个对象，（ii）保持与提示的语义对齐，或（iii）提供对场景布局的显式控制。为克服这些挑战，所提出的方法采用N通道ControlNet，集成了（i）对象保存（支持大小和位置无关性、颜色和细节保留及伪影消除），（ii）高分辨率且语义一致的背景（包括准确的阴影、光照和提示遵循），以及（iii）用户对背景布局和光照条件的显式控制。框架的关键组件包括对象保存和背景引导模块，确保光照一致性，以及高频覆盖模块以保留细节并减少伪影。我们还引入了一个基准数据集，包含24万张经过美学质量筛选的自然图像和1.8万张带有光照、相机角度和对象关系等元数据的3D渲染合成图像。该数据集弥补了现有基准的不足，支持全面评估。实验结果表明，我们的方法实现了最先进的性能，显著提升了特征空间保真度（FID 15.26）和语义对齐（CLIP-S 32.85），同时保持了竞争力的美学质量。我们还通过用户研究验证了该方法在未见基准上的有效性，观察到在提示对齐、真实感、AI伪影减少和自然美学方面分别比现有方法提升了约25%、19%、13%和14%。

</details>


### [98] [Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset](https://arxiv.org/abs/2506.22554)
**中文标题：无缝交互：二元视听运动建模与大规模数据集**

*Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer*

主要分类: cs.CV

摘要简述: 本文介绍了《无缝交互：二元视听运动建模与大规模数据集》，提出了一个包含4000多小时面对面互动视频的大规模数据集，并开发了一套模型，用于生成与人类语音同步的二元运动手势和面部表情，推动虚拟代理和交互式AI技术的发展。


<details>
  <summary>详细信息</summary>
研究动机: 人类交流涉及复杂的语言和非语言信号，这对开发社交智能AI技术至关重要。本文旨在通过大规模数据集和模型开发，提升AI对二元行为动态的理解和生成能力，以推动虚拟代理、远程呈现和多模态内容分析工具的进步。

研究方法: 本文提出了《无缝交互数据集》，包含4000多名参与者在多样化场景下的互动视频。基于此数据集，开发了一套模型，能够根据输入语音和视觉行为生成同步的二元运动手势和面部表情，并整合了LLM模型的语音输入及2D/3D渲染方法。此外，还设计了可控模型变体，支持情感响应和表达水平的调整。

研究结果: 研究结果表明，开发的模型能够生成与人类语音高度同步的二元运动行为，并支持情感和语义相关手势的调整。评估方法验证了这些模型在提升人机交互直觉性和响应性方面的潜力。

研究结论: 本文通过大规模数据集和模型开发，为二元行为动态的理解和生成提供了重要工具，推动了虚拟代理和交互式AI技术的发展，为人机交互的直觉性和响应性开辟了新方向。

中文摘要: 人类交流涉及语言和非语言信号的复杂互动，这对传递意义和实现人际目标至关重要。为开发社交智能AI技术，需要建立能够理解和生成二元行为动态的模型。为此，我们引入了《无缝交互数据集》，这是一个大规模数据集，包含来自4000多名参与者的4000多小时面对面互动视频，覆盖多样化场景。该数据集支持开发能够理解二元具身动态的AI技术，为虚拟代理、远程呈现体验和多模态内容分析工具带来突破。我们还开发了一套模型，利用该数据集生成与人类语音同步的二元运动手势和面部表情。这些模型可以同时接收对话者的语音和视觉行为输入。我们展示了一种结合LLM模型语音及2D/3D渲染方法的变体，使交互式虚拟代理更接近现实。此外，我们描述了可控的运动模型变体，能够调整情感响应和表达水平，并生成更具语义相关性的手势。最后，我们讨论了评估这些二元运动模型质量的方法，展示了其在提升人机交互直觉性和响应性方面的潜力。

</details>


### [99] [Recomposed realities: animating still images via patch clustering and randomness](https://arxiv.org/abs/2506.22556)
**中文标题：重构的现实：通过图像块聚类与随机性实现静态图像动画化**

*Markus Juvonen,Samuli Siltanen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图像块的重建与动画方法，通过聚类和随机采样将静态图像赋予动态效果。


<details>
  <summary>详细信息</summary>
研究动机: 旨在利用现有图像数据，通过重新组合和随机性，为静态图像注入动态效果，强调重新诠释而非简单复制。

研究方法: 使用k均值聚类对图像块进行分组，并通过匹配和随机采样从这些聚类中重建目标图像。

研究结果: 该方法能够在不完全复制源图像的情况下，为目标图像赋予动态效果，同时保留局部结构的一致性。

研究结论: 通过聚类和随机性，该方法成功实现了静态图像的动态化，为图像处理提供了新的思路。

中文摘要: 我们提出了一种基于图像块的重建与动画方法，利用现有图像数据为静态图像赋予动态效果。通过k均值聚类对图像块进行分组，并通过匹配和随机采样从这些聚类中重建目标图像。该方法强调重新诠释而非复制，允许源域和目标域在概念上有所不同，同时共享局部结构。

</details>


### [100] [Improving Token-based Object Detection with Video](https://arxiv.org/abs/2506.22562)
**中文标题：基于视频改进的标记化目标检测**

*Abhineet Singh,Nilanjan Ray*

主要分类: cs.CV

摘要简述: 本文通过扩展Pix2Seq目标检测器至视频领域，提出了一种新的端到端视频目标检测方法，解决了传统检测器的稀疏损失和后处理问题，并直接输出3D框或轨迹，无需图像级2D框链接。


<details>
  <summary>详细信息</summary>
研究动机: 传统视频目标检测器依赖2D框链接和空间采样，存在训练稀疏损失和推断后处理问题。本文旨在通过序列化表示和3D框输出，简化流程并提升性能。

研究方法: 将目标表示为离散标记的可变长度序列，避免定位提示注入，直接输出3D框或轨迹。通过增加视频子序列长度，灵活扩展计算资源。

研究结果: 在多个数据集上优于静态Pix2Seq检测器，并在UA-DETRAC上与当前最优视频检测器竞争，尽管受限于计算资源。

研究结论: 提出的方法简化了视频目标检测流程，性能优越且可扩展，代码和模型已开源。

中文摘要: 本文通过将Pix2Seq目标检测器扩展至视频领域，提出了一种新的端到端视频目标检测方法。该方法通过将目标表示为离散标记的可变长度序列，避免了传统检测器中定位提示的注入需求，从而解决了训练稀疏损失和推断后处理问题。此外，该方法直接输出完全集成的3D框或轨迹，而非传统方法中需要链接的2D框，使其能够通过增加输入视频子序列长度灵活扩展计算资源。实验表明，该方法在多个数据集上优于静态Pix2Seq检测器，并在UA-DETRAC上与当前最优视频检测器竞争，尽管受限于计算资源。代码和模型已公开。

</details>


### [101] [Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation](https://arxiv.org/abs/2506.22567)
**中文标题：统一生物医学视觉语言专长：通过多CLIP知识蒸馏构建通用基础模型**

*Shansong Wang,Zhecheng Jin,Mingzhe Hu,Mojtaba Safari,Feng Zhao,Chih-Wei Chang,Richard LJ Qiu,Justin Roper,David S. Yu,Xiaofeng Yang*

主要分类: cs.CV

摘要简述: 本文提出MMKD-CLIP，一种通过多医学CLIP知识蒸馏构建的通用生物医学基础模型，解决了生物医学领域数据稀缺和异构性问题，并在58个数据集上表现优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 生物医学领域缺乏大规模图像-文本数据集，且数据模态和标准不统一，限制了通用生物医学基础模型的开发。本文旨在通过知识蒸馏解决这一问题。

研究方法: 采用两阶段训练：首先在290万生物医学图像-文本对上进行CLIP式预训练，然后从9个教师模型中提取1920万特征对进行特征级蒸馏。

研究结果: MMKD-CLIP在58个生物医学数据集上表现优于所有教师模型，涵盖零样本分类、跨模态检索等六类任务，展示了出色的泛化能力。

研究结论: 多教师知识蒸馏是构建高性能生物医学基础模型的有效方法，解决了实际数据可用性限制。

中文摘要: CLIP模型在自然图像上的预训练展示了零样本分类、跨模态检索等强大能力，但在生物医学领域的应用受限于数据稀缺和异构性。为此，我们提出MMKD-CLIP，一种通过多医学CLIP知识蒸馏构建的通用生物医学基础模型。MMKD-CLIP不依赖大规模原始数据，而是从9个领域特定或通用生物医学CLIP模型中蒸馏知识。其两阶段训练包括在290万生物医学图像-文本对上的预训练和从教师模型中提取1920万特征对的特征级蒸馏。在58个生物医学数据集上的评估表明，MMKD-CLIP在六类任务中均优于教师模型，展现了卓越的泛化能力。这些结果证明，多教师知识蒸馏是构建高性能生物医学基础模型的有效范式。

</details>


### [102] [Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation](https://arxiv.org/abs/2506.22570)
**中文标题：双空洞可分离卷积用于改进农业语义分割**

*Chee Mei Ling,Thangarajah Akilan,Aparna Ravinda Phalke*

主要分类: cs.CV

摘要简述: 本文提出了一种名为双空洞可分离卷积（DAS Conv）的高效农业图像语义分割方法，通过优化空洞率和填充大小，结合编码器到解码器的跳跃连接，显著提升了模型性能，同时降低了计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 农业图像语义分割在现代农业中至关重要，能够通过精准的视觉数据分析优化作物管理和资源利用。然而，现有方法在效率和性能之间难以平衡，因此需要一种高效且精确的分割方法。

研究方法: 研究提出了一种基于DeepLabV3框架的双空洞可分离卷积（DAS Conv）模块，通过优化空洞率和填充大小提升性能，并引入编码器到解码器的跳跃连接以捕捉细粒度空间特征。

研究结果: 在Agriculture Vision基准数据集上，该方法在性能和效率之间取得了显著平衡，比现有最先进模型提升了66%的效率，同时性能接近复杂的基于Transformer的模型。

研究结论: 该研究为农业遥感图像语义分割提供了一种高效且有效的解决方案，模型计算轻量且性能优异。

中文摘要: 农业图像语义分割是现代农业生产的关键组成部分，通过精确的视觉数据分析优化作物管理、资源利用和整体生产效率。本研究提出了一种高效的图像分割方法，专注于精准划分农田异常区域，以支持决策和主动干预。在DeepLabV3框架中集成了新颖的双空洞可分离卷积（DAS Conv）模块，该模块通过精心设计的空洞率和填充大小优化，在不牺牲效率的前提下提升了模型性能。研究还引入了编码器到解码器的跳跃连接，增强了模型捕捉细粒度空间特征的能力。尽管计算复杂度较低，该方法在Agriculture Vision基准数据集上的表现优于基线模型，并与复杂的基于Transformer的最先进模型性能相当。在模型复杂度和性能的权衡下，其效率比最先进模型提升了66%以上。本研究为遥感应用中的语义分割提供了一种高效且有效的解决方案，模型计算轻量且在农业图像中表现出色。

</details>


### [103] [LIGHT: Multi-Modal Text Linking on Historical Maps](https://arxiv.org/abs/2506.22589)
**中文标题：LIGHT：历史地图上的多模态文本链接**

*Yijun Lin,Rhett Olson,Junhan Wu,Yao-Yi Chiang,Jerod Weinman*

主要分类: cs.CV

摘要简述: LIGHT是一种多模态方法，结合语言、图像和几何特征，用于链接历史地图上的文本，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 历史地图上的文本对研究历史、经济和地理等领域具有重要价值，但现有方法难以有效链接文本片段，尤其是多词地名。传统方法主要依赖语言特征，忽略了几何信息。

研究方法: LIGHT提出了一种多模态方法，整合语言、图像和几何特征。通过几何感知嵌入模块编码文本区域的多边形坐标，结合LayoutLMv3的视觉和语言特征，使用双向学习策略预测文本实例的阅读顺序。

研究结果: 实验结果表明，LIGHT在ICDAR 2024/2025 MapText竞赛数据上优于现有方法，证明了多模态学习在历史地图文本链接中的有效性。

研究结论: LIGHT通过整合多模态特征，显著提升了历史地图文本链接的性能，为相关研究提供了新思路。

中文摘要: 历史地图上的文本为历史、经济、地理等领域的研究提供了宝贵信息。与结构化或半结构化文档不同，地图上的文本在方向、阅读顺序、形状和位置上差异显著。现代方法虽能检测和转录文本区域，但难以有效“链接”识别出的文本片段（如多词地名）。现有布局分析方法通过建模词关系提升结构化文档的文本理解，但主要依赖语言特征，忽略了处理地图文本所需的几何信息。为解决这些问题，我们提出LIGHT，一种整合语言、图像和几何特征的多模态方法，用于链接历史地图上的文本。LIGHT包含一个几何感知嵌入模块，编码文本区域的多边形坐标以捕捉其形状和相对空间位置，并将这些几何信息与LayoutLMv3（预训练的布局分析模型）的视觉和语言特征统一。LIGHT利用跨模态信息，通过双向学习策略直接预测每个文本实例的阅读顺序后继，增强序列鲁棒性。实验结果显示，LIGHT在ICDAR 2024/2025 MapText竞赛数据上优于现有方法，证明了多模态学习在历史地图文本链接中的有效性。

</details>


### [104] [BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data](https://arxiv.org/abs/2506.22591)
**中文标题：BrainMT：一种用于建模功能磁共振成像数据中长程依赖关系的混合Mamba-Transformer架构**

*Arunkumar Kannan,Martin A. Lindquist,Brian Caffo*

主要分类: cs.CV

摘要简述: 论文提出了一种名为BrainMT的混合Mamba-Transformer架构，用于高效建模功能磁共振成像（fMRI）数据中的长程依赖关系，并在分类和回归任务中取得了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于卷积神经网络或Transformer架构的方法在建模fMRI数据中的复杂关系时表现不佳，主要原因是无法有效捕捉长程时空依赖关系。因此，需要一种新的框架来解决这一问题。

研究方法: BrainMT采用两阶段设计：1）双向Mamba块通过时间优先扫描机制高效捕捉全局时间交互；2）Transformer块利用自注意力机制建模Mamba块处理后特征的全局空间关系。

研究结果: 在UKBioBank和Human Connectome Project两个大型公开数据集上的实验表明，BrainMT在分类（性别预测）和回归（认知智力预测）任务中均显著优于现有方法。

研究结论: BrainMT通过结合Mamba和Transformer的优势，成功解决了fMRI数据中长程依赖建模的挑战，为神经影像学领域提供了高效的新工具。

中文摘要: 深度学习的最新进展使得直接从功能磁共振成像（fMRI）脑体积预测表型测量成为可能，引起了神经影像学界的广泛关注。然而，现有的方法主要基于卷积神经网络或Transformer架构，往往难以建模fMRI数据中的复杂关系，受限于其无法捕捉长程时空依赖。为克服这些不足，我们提出了BrainMT，一种新颖的混合框架，旨在高效学习和整合fMRI数据中的长程时空属性。我们的框架分为两个阶段：（1）双向Mamba块通过时间优先扫描机制以计算高效的方式捕捉全局时间交互；（2）Transformer块利用自注意力建模Mamba块处理后特征的全局空间关系。在UKBioBank和Human Connectome Project两个大型公开数据集上的广泛实验表明，BrainMT在分类（性别预测）和回归（认知智力预测）任务中均达到了最先进的性能，显著优于现有方法。我们的代码和实现细节将在https://github.com/arunkumar-kannan/BrainMT-fMRI公开。

</details>


### [105] [Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning](https://arxiv.org/abs/2506.22624)
**中文标题：Seg-R1：通过强化学习实现出人意料简单的分割**

*Zuyao You,Zuxuan Wu*

主要分类: cs.CV

摘要简述: Seg-R1通过强化学习（RL）提升大型多模态模型（LMMs）的像素级理解能力，在伪装目标检测（COD）和显著目标检测（SOD）任务中表现优异，无需复杂模型修改即可实现高精度分割，并展现出强大的开放世界泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索如何利用强化学习增强大型多模态模型在像素级任务（如分割）中的表现，特别是在无需复杂模型修改或文本监督的情况下，实现高性能和泛化能力。

研究方法: Seg-R1采用强化学习训练LMM生成点和边界框提示，指导SAM2生成分割掩码。引入Group Relative Policy Optimization（GRPO）策略，通过精心设计的训练方法提升模型的像素级理解能力。

研究结果: Seg-R1在COD10K上达到0.873 S-measure，并在未经过文本监督训练的情况下，在RefCOCOg和ReasonSeg任务中分别实现71.4 cIoU和56.7 gIoU的零样本性能，优于完全监督的模型。

研究结论: Seg-R1展示了纯强化学习在分割任务中的潜力，能够以简单的方法实现高性能和强大的泛化能力，为未来研究提供了新的方向。

中文摘要: 我们提出了Seg-R1，这是对利用强化学习（RL）增强大型多模态模型（LMMs）像素级理解和推理能力的初步探索。从前景分割任务（特别是伪装目标检测（COD）和显著目标检测（SOD））开始，我们的方法使LMM能够以“下一个标记”的方式生成点和边界框提示，进而指导SAM2生成分割掩码。我们将Group Relative Policy Optimization（GRPO）引入分割领域，通过精心设计的训练策略为LMM提供像素级理解能力。值得注意的是，Seg-R1通过纯RL训练取得了显著性能，在COD10K上达到0.873 S-measure，且无需复杂模型修改。此外，我们发现纯RL训练展现出强大的开放世界泛化能力。尽管仅在前景分割图像-掩码对上训练且无文本监督，Seg-R1在参考分割和推理分割任务中实现了令人印象深刻的零样本性能，在RefCOCOg测试集上达到71.4 cIoU，在ReasonSeg测试集上达到56.7 gIoU，优于在这些数据集上完全监督的模型。

</details>


### [106] [ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models](https://arxiv.org/abs/2506.22636)
**中文标题：ReCo：提醒组合缓解视觉语言模型中的幻觉问题**

*Sotirios Panagiotis Chytas,Miso Choi,Hyunwoo J. Kim,Vikas Singh*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ReCo的轻量级模块，用于缓解视觉语言模型（VLMs）中的幻觉问题，即模型生成的文本与视觉输入不符或矛盾的现象。ReCo通过几何代数和关系组合的思想，在不修改原模型的情况下显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉语言模型（VLMs）在整合和推理视觉与语言数据方面表现出色，但存在幻觉问题，即生成看似合理但与视觉输入不符的文本。这种现象被归因于模型对语言的过度依赖，导致视觉输入的‘记忆消退效应’。本文旨在研究如何控制这种行为。

研究方法: 作者提出了一种名为ReCo的轻量级可训练模块，基于几何代数和关系组合的思想，无需修改现有VLM结构即可直接应用于模型顶部。该方法在InstructBLIP、LlaVA和MiniGPT4三种主流VLM上进行了验证。

研究结果: 实验表明，ReCo模块有效缓解了‘记忆消退效应’，在多个基准测试中显著提升了模型性能。此外，ReCo还能与其他减少幻觉的方法结合使用，进一步优化结果。

研究结论: ReCo作为一种轻量级解决方案，成功缓解了VLMs中的幻觉问题，且无需修改原模型结构，具有广泛的应用潜力。

中文摘要: 视觉语言模型（VLMs）在整合和推理视觉与语言数据方面表现出强大的能力，但这些模型也会犯错。一个常见现象是它们倾向于产生幻觉，即生成看似合理但与视觉输入不符甚至矛盾的文本。这种现象被归因于对语言的过度依赖，尤其是在生成过程中，模型对视觉输入的‘记忆消退效应’逐渐显现。本文研究了控制这种行为的方法。具体而言，基于几何代数和关系组合的思想，我们提出了一种名为ReCo的小型可训练模块，可直接应用于任何VLM的顶部，无需其他修改。实验证明，这种轻量级模块能够有效缓解三种主流VLM（InstructBLIP、LlaVA和MiniGPT4）的‘记忆消退效应’，并在多个基准测试中提升了性能。此外，ReCo还能与许多其他减少幻觉的方法结合使用，进一步优化结果。

</details>


### [107] [CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation](https://arxiv.org/abs/2506.22637)
**中文标题：CaO$_2$：修正基于扩散的数据集蒸馏中的不一致性**

*Haoxuan Wang,Zhenghao Zhao,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan*

主要分类: cs.CV

摘要简述: CaO$_2$ 是一种两阶段扩散框架，解决了当前基于扩散的数据集蒸馏方法中的目标不一致和条件不一致问题，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散的数据集蒸馏方法在评估过程中存在目标不一致和条件不一致的问题，导致蒸馏过程与评估目标不匹配，CaO$_2$ 旨在解决这些问题。

研究方法: CaO$_2$ 采用两阶段框架：第一阶段使用概率信息样本选择管道，第二阶段优化潜在表示以提高条件似然性。

研究结果: CaO$_2$ 在 ImageNet 及其子集上实现了最先进的性能，平均准确率超过基线方法 2.3%。

研究结论: CaO$_2$ 通过解决目标不一致和条件不一致问题，显著提升了数据集蒸馏的性能，为未来研究提供了新方向。

中文摘要: 最近，扩散模型在数据集蒸馏中的应用显示出在创建大型高分辨率目标数据集的紧凑替代数据集方面的潜力，其效率和性能优于传统的双层/单层优化方法。然而，当前基于扩散的数据集蒸馏方法忽略了评估过程，并在蒸馏过程中表现出两个关键的不一致性：（1）目标不一致性，即蒸馏过程与评估目标偏离；（2）条件不一致性，导致生成的图像与其对应条件不匹配。为解决这些问题，我们提出了条件感知优化与目标引导采样（CaO$_2$），这是一个两阶段的基于扩散的框架，将蒸馏过程与评估目标对齐。第一阶段采用概率信息样本选择管道，第二阶段优化相应的潜在表示以提高条件似然性。CaO$_2$ 在 ImageNet 及其子集上实现了最先进的性能，平均准确率超过最佳基线方法 2.3%。

</details>


### [108] [3D Shape Generation: A Survey](https://arxiv.org/abs/2506.22678)
**中文标题：3D形状生成综述**

*Nicolas Caytuiro,Ivan Sipiran*

主要分类: cs.CV

摘要简述: 本文综述了深度学习在3D形状生成领域的最新进展，重点讨论了形状表示、生成方法和评估协议，并总结了当前挑战与未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度学习的发展，3D形状生成领域取得了显著进展，但缺乏系统性的综述。本文旨在为研究人员和实践者提供一个全面的参考，梳理当前技术、挑战和未来方向。

研究方法: 文章围绕三个核心部分展开：形状表示（显式、隐式和混合）、生成方法（前馈架构）和评估协议（数据集与指标）。通过分类和比较，系统总结了现有技术。

研究结果: 综述了3D形状生成的多种表示方法和生成技术，总结了常用数据集和评估指标，并指出了当前领域在可控性、效率和质量方面的挑战。

研究结论: 本文为3D形状生成领域提供了系统性的综述，明确了未来研究方向，旨在推动可控、高效和高质量的3D形状生成技术的发展。

中文摘要: 近年来，深度学习显著改变了3D形状生成领域，使得复杂、多样且语义丰富的3D对象合成成为可能。本综述全面概述了当前3D形状生成的最新技术，围绕三个核心部分展开讨论：形状表示、生成方法和评估协议。首先，我们将3D表示分为显式、隐式和混合形式，并分析其结构特性、优势和局限性。接着，我们回顾了多种生成方法，重点关注前馈架构。此外，我们总结了常用数据集和评估指标，用于衡量生成形状的保真度、多样性和真实性。最后，我们指出了当前领域的开放挑战，并展望了未来研究方向，以推动可控、高效和高质量的3D形状生成技术的发展。本综述旨在为研究人员和实践者提供一个结构化和深入的参考，帮助理解这一快速发展的领域。

</details>


### [109] [LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning](https://arxiv.org/abs/2506.22710)
**中文标题：LightBSR：基于区分性隐式退化表示学习的轻量级盲超分辨率方法**

*Jiang Yuan,JI Ma,Bo Wang,Guanzhou Ke,Weiming Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级盲超分辨率模型LightBSR，通过优化隐式退化表示（IDR）的区分性，结合知识蒸馏和对比学习技术，显著降低了模型复杂度，同时提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于隐式退化估计的盲超分辨率方法（IDE-BSR）忽视了IDR区分性的重要性，且通过过度复杂的适应过程提升效果，导致模型参数量和计算量大幅增加。本文旨在优化IDR的区分性，并提出一种轻量高效的BSR模型。

研究方法: 采用知识蒸馏框架，首先在教师阶段引入退化先验约束的对比学习技术，增强模型对不同退化类型的区分能力；随后通过特征对齐技术将教师模型学到的退化相关知识迁移至学生模型，用于实际推理。

研究结果: 实验表明，LightBSR在多种盲超分辨率任务中表现出色，且模型复杂度极低。

研究结论: 本文提出的LightBSR通过优化IDR区分性，实现了轻量高效的盲超分辨率，为相关领域提供了新的设计思路。

中文摘要: 基于隐式退化估计的盲超分辨率（IDE-BSR）依赖于提取低分辨率图像的隐式退化表示（IDR），并将其适应于图像特征以指导高分辨率细节恢复。尽管IDE-BSR在处理噪声干扰和复杂退化方面显示出潜力，但现有方法忽视了IDR区分性对BSR的重要性，转而通过过度复杂的适应过程提升效果，导致模型参数量和计算量显著增加。本文聚焦于IDR区分性的优化，提出了一种新型轻量高效的BSR模型LightBSR。具体而言，我们采用基于知识蒸馏的学习框架，首先在教师阶段引入精心设计的退化先验约束对比学习技术，使模型更专注于区分不同退化类型；随后利用特征对齐技术将教师学到的退化相关知识迁移至学生模型用于实际推理。大量实验验证了IDR区分性驱动的BSR模型设计的有效性。所提出的LightBSR在多种盲超分辨率任务中以极低复杂度实现了卓越性能。代码已开源：https://github.com/MJ-NCEPU/LightBSR。

</details>


### [110] [Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians](https://arxiv.org/abs/2506.22718)
**中文标题：基于动态3D高斯的铰接物体部件分割与运动估计**

*Jun-Jee Chao,Qingyuan Jiang,Volkan Isler*

主要分类: cs.CV

摘要简述: 本文提出了一种基于动态3D高斯模型的方法，用于联合解决铰接物体的部件分割和运动估计问题，尤其在点云数据不连续或存在遮挡时表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 铰接物体的部件分割和运动估计是运动分析中的基础问题。现有方法依赖于点对应跟踪，但在点云数据不连续或存在遮挡时效果不佳。本文旨在解决这一问题。

研究方法: 通过将物体表示为动态3D高斯集合，参数化时间依赖的旋转、平移和缩放，实现部件分割和运动估计。点云与高斯模型建立对应关系，即使点未被观测也能推断其运动。

研究结果: 实验表明，该方法在遮挡情况下优于现有方法，部件分割性能比现有最优方法提升13%，且对缺失点具有更强的鲁棒性。

研究结论: 本文方法在铰接物体的部件分割和运动估计中表现优异，尤其在遮挡和不连续点云场景下具有显著优势。

中文摘要: 部件分割和运动估计是铰接物体运动分析中的两个基本问题。本文提出了一种方法，通过单铰接物体点云序列联合解决这两个问题。主要挑战在于点云序列并非由固定点集生成，而是每个时间步对物体表面的任意采样。这种情况常见于物体被严重遮挡或多传感器异步测量时。依赖点对应跟踪的方法在此类场景中不适用。我们提出了一种基于动态3D高斯模型的紧凑有效表示方法，将物体建模为高斯集合，参数化时间依赖的旋转、平移和缩放。通过建立观测点与高斯模型的对应关系实现部件分割，并通过高斯模型的位姿推断点的运动（即使点未被观测）。实验表明，该方法在点对应跟踪方法上表现更优。此外，我们扩展了现有数据集以模拟真实场景中的视角遮挡，并证明该方法在缺失点情况下更具鲁棒性，即使某些部件在部分时间步完全遮挡。值得注意的是，在遮挡点云上，我们的部件分割性能比现有最优方法提升了13%。

</details>


### [111] [Deterministic Object Pose Confidence Region Estimation](https://arxiv.org/abs/2506.22720)
**中文标题：确定性物体姿态置信区域估计**

*Jinghao Wang,Zhang Li,Zi Wang,Banglei Guan,Yang Shang,Qifeng Yu*

主要分类: cs.CV

摘要简述: 本文提出了一种确定性方法，用于高效估计6D姿态置信区域，解决了现有采样方法速度慢和置信区域过大的问题。通过结合归纳共形预测和隐函数定理，该方法显著提升了姿态估计的准确性和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于采样的6D姿态置信区域估计方法存在速度慢和置信区域过大的问题，限制了其实际应用。本文旨在提出一种更高效且准确的确定性方法来解决这些问题。

研究方法: 本文采用归纳共形预测校准确定性回归的高斯关键点分布为2D关键点置信区域，并利用隐函数定理将这些区域直接传播到6D姿态置信区域，避免了采样和集成的低效性。

研究结果: 在LineMOD Occlusion和SPEED数据集上的实验表明，该方法在相同覆盖率下，置信区域体积显著减小（旋转减少99.9%，平移减少99.8%），同时计算时间更短，姿态估计准确性更高。

研究结论: 本文提出的确定性方法能够高效生成紧凑的6D姿态置信区域，显著优于现有采样方法，为姿态估计的可靠性评估提供了实用解决方案。

中文摘要: 6D姿态置信区域估计已成为关键研究方向，旨在通过不确定性量化评估估计姿态的可靠性。然而，当前基于采样的方法存在严重限制，阻碍了其实际应用：1）采样速度随样本数量增加显著下降；2）生成的置信区域通常过大。为解决这些问题，我们提出了一种确定性高效的方法来估计姿态置信区域。该方法利用归纳共形预测将确定性回归的高斯关键点分布校准为2D关键点置信区域，并通过隐函数定理将这些区域直接传播到6D姿态置信区域。此方法避免了采样和集成带来的低效性和区域膨胀问题，能够生成覆盖真实姿态的紧凑置信区域，且置信水平可由用户定义。在LineMOD Occlusion和SPEED数据集上的实验结果表明，我们的方法在减少计算时间的同时提高了姿态估计准确性。在相同覆盖率下，我们的方法显著减小了置信区域体积，旋转和平移分别减少了99.9%和99.8%。代码即将发布。

</details>


### [112] [XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge](https://arxiv.org/abs/2506.22726)
**中文标题：XTransfer：面向边缘系统的跨模态模型迁移方法，用于少量数据下的人类感知**

*Yu Zhang,Xi Zhang,Hualin zhou,Xinyuan Chen,Shang Gao,Hong Jia,Jianfei Yang,Yuankai Qi,Tao Gu*

主要分类: cs.CV

摘要简述: XTransfer是一种跨模态模型迁移方法，通过少量数据和资源高效的方式解决边缘系统中人类感知任务的模态偏移和资源限制问题。


<details>
  <summary>详细信息</summary>
研究动机: 边缘系统中的人类感知任务面临传感器数据稀缺和资源受限的挑战，现有预训练模型迁移方法存在模态偏移和高资源消耗问题，导致精度下降和适应性差。

研究方法: XTransfer通过（i）模型修复技术用少量数据修复预训练模型中的模态偏移，（ii）层重组技术高效搜索并重组源模型中的关键层，生成紧凑模型。

研究结果: 实验表明，XTransfer在多种人类感知任务中表现优异，显著降低了数据收集、模型训练和边缘部署的成本。

研究结论: XTransfer为跨模态模型迁移提供了一种高效且适应性强的解决方案，适用于资源受限的边缘系统。

中文摘要: 深度学习在边缘系统中的人类感知任务为智能应用提供了重要机遇，但其训练和开发受限于传感器数据的稀缺性和边缘系统的资源限制。现有依赖预训练模型迁移的方法常因模态偏移和高资源需求导致精度损失、资源开销大及跨应用适应性差。本文提出XTransfer，一种资源高效、模态无关的模型迁移方法。XTransfer通过（i）模型修复技术用少量数据安全修复预训练模型中的模态偏移，（ii）层重组技术高效搜索并重组源模型中的关键层，生成紧凑模型。我们在多种跨模态人类感知数据集上对比了多种基线方法。综合结果表明，XTransfer在人类感知任务中达到最优性能，同时显著降低了数据收集、模型训练和边缘部署的成本。

</details>


### [113] [UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments](https://arxiv.org/abs/2506.22736)
**中文标题：UniFuse：一种统一的多模态医学图像融合框架，适用于多样化退化与未对齐情况**

*Dayong Su,Yafei Zhang,Huafeng Li,Jinxing Li,Yu Liu*

主要分类: cs.CV

摘要简述: UniFuse提出了一种统一的多模态医学图像融合框架，能够在图像质量差或未对齐的情况下实现高效融合。通过嵌入退化感知提示学习模块和Omni统一特征表示方案，UniFuse在单一框架中实现了对齐、恢复和融合的联合优化。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态医学图像融合方法通常假设源图像质量高且完美对齐，但在实际应用中，图像可能因退化或未对齐而影响融合效果。UniFuse旨在解决这一问题，提出一种通用框架，以应对多样化的图像退化与未对齐情况。

研究方法: UniFuse通过退化感知提示学习模块整合多方向信息，并结合Omni统一特征表示方案（利用Spatial Mamba编码多方向特征）。此外，提出通用特征恢复与融合模块（基于LoRA的自适应LoRA协同网络ALSN），实现单阶段联合恢复与融合。

研究结果: 实验结果表明，UniFuse在多个数据集上表现优异，显著优于现有方法，尤其在处理退化或未对齐图像时展现出强大性能。

研究结论: UniFuse成功将对齐、恢复和融合统一于单一框架，为多模态医学图像融合提供了高效且通用的解决方案。

中文摘要: 当前多模态医学图像融合通常假设源图像质量高且完美对齐，其效果依赖于这些条件，而在处理未对齐或退化的医学图像时往往表现不佳。为此，我们提出UniFuse，一种通用融合框架。通过嵌入退化感知提示学习模块，UniFuse无缝整合输入图像的多方向信息，并将跨模态对齐与恢复相关联，实现两者在统一框架内的联合优化。此外，我们设计了Omni统一特征表示方案，利用Spatial Mamba编码多方向特征并缓解特征对齐中的模态差异。为实现单阶段恢复与融合，我们提出通用特征恢复与融合模块，基于LoRA原理的自适应LoRA协同网络（ALSN）。通过ALSN的自适应特征表示及退化类型引导，我们在单一框架内实现联合恢复与融合。与分阶段方法相比，UniFuse将对齐、恢复与融合统一于单一框架。多数据集实验结果表明，该方法效果显著，优于现有方法。

</details>


### [114] [Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds](https://arxiv.org/abs/2506.22749)
**中文标题：基于深度学习的联合几何与属性上采样方法用于大规模彩色点云**

*Yun Zhang,Feifan Chen,Na Li,Zhiwei Guo,Xu Wang,Fen Miao,Sam Kwong*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的联合几何与属性上采样方法（JGAU），用于大规模彩色点云的生成，通过同时建模几何和属性模式，并利用空间属性相关性，显著提升了上采样质量。


<details>
  <summary>详细信息</summary>
研究动机: 彩色点云是3D应用的主流表示形式，但现有方法难以高效生成大规模且密集的彩色点云。本文旨在通过深度学习技术，联合优化几何和属性的上采样，以解决这一问题。

研究方法: 1. 建立并发布了一个大规模彩色点云上采样数据集SYSU-PCUD；2. 提出JGAU框架，包含几何上采样网络和属性上采样网络，后者利用辅助几何建模属性邻域相关性；3. 提出两种粗属性上采样方法（GDWAI和DLAI）及属性增强模块，进一步优化属性质量。

研究结果: 实验表明，JGAU在4倍、8倍、12倍和16倍上采样率下的PSNR分别为33.90、32.10、31.10和30.39分贝，平均优于现有方法2.32至2.47分贝。

研究结论: JGAU通过联合优化几何和属性上采样，显著提升了彩色点云的质量，为大规模3D应用提供了高效解决方案。

中文摘要: 彩色点云包含几何和属性两部分，是实现逼真和沉浸式3D应用的主流表示形式。为生成大规模且更密集的彩色点云，我们提出了一种基于深度学习的联合几何与属性上采样方法（JGAU），该方法通过学习建模几何和属性模式，并利用空间属性相关性。首先，我们建立并发布了一个名为SYSU-PCUD的大规模彩色点云上采样数据集，包含121个具有多样几何和属性复杂度的点云，覆盖六种类别和四种采样率。其次，为提高上采样点云的质量，我们提出了基于深度学习的JGAU框架，联合上采样几何和属性。该框架包含一个几何上采样网络和一个属性上采样网络，后者利用上采样的辅助几何建模属性的邻域相关性。第三，我们提出了两种粗属性上采样方法：几何距离加权属性插值（GDWAI）和基于深度学习的属性插值（DLAI），为每个点生成粗上采样属性。随后，引入属性增强模块，通过进一步挖掘内在属性和几何模式，优化这些上采样属性并生成高质量点云。大量实验表明，JGAU在4倍、8倍、12倍和16倍上采样率下的峰值信噪比（PSNR）分别为33.90、32.10、31.10和30.39分贝。与现有方法相比，JGAU在这四种上采样率下平均提升了2.32、2.47、2.28和2.11分贝，显示出显著改进。

</details>


### [115] [Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography](https://arxiv.org/abs/2506.22753)
**中文标题：基于退化建模的多路径扩散用于可调谐超透镜摄影**

*Jianing Zhang,Jiayi Zhu,Feiyu Ji,Xiaokang Yang,Xiaoyun Yuan*

主要分类: cs.CV

摘要简述: 本文提出了一种基于退化建模的多路径扩散方法（DMDiff），用于可调谐超透镜摄影，通过预训练模型利用自然图像先验，避免了大数据集需求，并实现了高保真图像重建。


<details>
  <summary>详细信息</summary>
研究动机: 超透镜在超紧凑计算成像中潜力巨大，但面临复杂光学退化和计算恢复的挑战。现有方法依赖精确光学校准或大规模配对数据集，难以适用于实际成像系统，且缺乏对推理过程的控制，容易产生伪影。

研究方法: 提出Degradation-Modeled Multipath Diffusion框架，利用预训练模型的自然图像先验，通过正、中、负提示路径平衡高频细节生成、结构保真度和退化抑制，并结合伪数据增强。采用可调谐解码器控制保真度与感知质量的权衡，并设计了空间变化退化感知注意力模块（SVDA）自适应建模复杂退化。

研究结果: 实验结果表明，该方法优于现有技术，实现了高保真和清晰的图像重建，并通过毫米级MetaCamera进行了实际验证。

研究结论: DMDiff框架通过自然图像先验和自适应退化建模，显著提升了超透镜摄影的图像质量，为实际应用提供了可行的解决方案。

中文摘要: 超透镜在超紧凑计算成像中具有巨大潜力，但面临复杂光学退化和计算恢复的挑战。现有方法通常依赖精确的光学校准或大规模配对数据集，这对实际成像系统来说并不容易。此外，缺乏对推理过程的控制往往导致不理想的伪影。我们提出了基于退化建模的多路径扩散方法（DMDiff），利用预训练模型的强大自然图像先验而非大数据集。我们的框架通过正、中和负提示路径平衡高频细节生成、结构保真度和超透镜特定退化的抑制，并结合伪数据增强。可调谐解码器实现了保真度与感知质量的可控权衡。此外，空间变化退化感知注意力（SVDA）模块自适应地建模复杂的光学和传感器引起的退化。最后，我们设计并制造了毫米级MetaCamera进行实际验证。大量实验结果表明，我们的方法优于现有技术，实现了高保真和清晰的图像重建。更多材料请访问：https://dmdiff.github.io/。

</details>


### [116] [RoboPearls: Editable Video Simulation for Robot Manipulation](https://arxiv.org/abs/2506.22756)
**中文标题：RoboPearls：用于机器人操作的可编辑视频模拟**

*Tao Tang,Likui Zhang,Youpeng Wen,Kaidong Zhang,Jia-Wang Bian,xia zhou,Tianyi Yan,Kun Zhan,Peng Jia,Hefeng Wu,Liang Lin,Xiaodan Liang*

主要分类: cs.CV

摘要简述: RoboPearls是一个可编辑的视频模拟框架，用于机器人操作，基于3D高斯泼溅技术，支持从演示视频构建逼真、视角一致的模拟，并通过大语言模型和视觉语言模型自动化模拟过程，提升机器人学习性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前机器人操作策略的发展依赖于大规模多样化环境下的演示数据，但真实世界数据采集成本高且效率低。现有模拟平台虽能提供可控环境，但模拟与现实的差距仍是一大挑战。RoboPearls旨在通过可编辑的视频模拟解决这些问题。

研究方法: RoboPearls基于3D高斯泼溅（3DGS）技术，支持从演示视频构建逼真模拟，并提供多种模拟操作符（如对象操纵）。通过增量语义蒸馏（ISD）和3D正则化NNFM损失（3D-NNFM）等模块增强功能，并利用大语言模型（LLMs）和视觉语言模型（VLM）自动化模拟过程。

研究结果: 在RLBench、COLOSSEUM、Ego4D、Open X-Embodiment等多个数据集和场景中进行实验，结果表明RoboPearls的模拟性能令人满意，并能有效提升机器人学习效果。

研究结论: RoboPearls通过可编辑的视频模拟框架，显著降低了机器人操作数据采集的成本和难度，同时通过自动化工具和先进模块提升了模拟的真实性和实用性，为机器人学习提供了高效解决方案。

中文摘要: 通用机器人操作策略的开发取得了显著进展，这得益于多样化环境下的大规模演示数据。然而，真实世界演示数据的高成本和低效率限制了数据采集的可扩展性。现有的模拟平台虽能为机器人学习提供可控环境，但模拟与现实的差距仍是挑战。为此，我们提出RoboPearls，一种用于机器人操作的可编辑视频模拟框架。基于3D高斯泼溅（3DGS）技术，RoboPearls能够从演示视频构建逼真且视角一致的模拟，并支持多种模拟操作符（如对象操纵），其功能由增量语义蒸馏（ISD）和3D正则化NNFM损失（3D-NNFM）等先进模块驱动。此外，通过结合大语言模型（LLMs），RoboPearls以用户友好的方式通过灵活的命令解释和执行自动化模拟生产过程。进一步，RoboPearls利用视觉语言模型（VLM）分析机器人学习问题，以闭环方式提升性能。为验证RoboPearls的有效性，我们在多个数据集和场景（包括RLBench、COLOSSEUM、Ego4D、Open X-Embodiment和真实机器人）上进行了大量实验，结果表明其模拟性能令人满意。

</details>


### [117] [VSRM: A Robust Mamba-Based Framework for Video Super-Resolution](https://arxiv.org/abs/2506.22762)
**中文标题：VSRM：一种基于Mamba的鲁棒视频超分辨率框架**

*Dinh Phu Tran,Dao Duy Hung,Daeyoung Kim*

主要分类: cs.CV

摘要简述: 本文提出VSRM，一种基于Mamba的视频超分辨率框架，通过时空Mamba块和可变形交叉Mamba对齐模块高效提取长程时空特征，并采用频率域损失提升视觉质量，在多个基准测试中达到最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 视频超分辨率任务中，CNN和Transformer方法分别受限于局部感受野和二次复杂度，而Mamba因其长序列建模能力和线性复杂度成为潜在解决方案。本文旨在利用Mamba的优势，设计更高效的视频超分辨率框架。

研究方法: VSRM框架包含时空Mamba块（Spatial-to-Temporal和Temporal-to-Spatial）以高效提取长程时空特征；提出可变形交叉Mamba对齐模块（Deformable Cross-Mamba Alignment）动态对齐相邻帧；引入频率域Charbonnier-like损失以减少重建帧与真实帧的频率域差异。

研究结果: VSRM在多个基准测试中取得最优性能，验证了其在视频超分辨率任务中的高效性和鲁棒性。

研究结论: VSRM通过结合Mamba的长序列建模能力和创新的对齐模块，为视频超分辨率任务提供了高效且鲁棒的解决方案，为未来研究奠定了坚实基础。

中文摘要: 视频超分辨率在低层视觉任务中仍具挑战性。目前，基于CNN和Transformer的方法已取得显著成果，但CNN受限于局部感受野，而Transformer因二次复杂度难以处理长序列。近期，Mamba因其长序列建模能力、线性复杂度和大感受野受到关注。本文提出VSRM，一种基于Mamba的视频超分辨率框架。VSRM通过时空Mamba块（Spatial-to-Temporal和Temporal-to-Spatial）高效提取长程时空特征，并引入可变形交叉Mamba对齐模块（Deformable Cross-Mamba Alignment）动态对齐相邻帧，避免特征失真。此外，提出一种简单有效的频率域Charbonnier-like损失，减少重建帧与真实帧的频率域差异，保留高频内容并提升视觉质量。大量实验表明，VSRM在多个基准测试中达到最优性能，为未来研究奠定了坚实基础。

</details>


### [118] [PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection](https://arxiv.org/abs/2506.22783)
**中文标题：PhonemeFake：通过语言驱动的分段操纵和自适应双层检测重新定义深度伪造的真实性**

*Oguzhan Baser,Ahmet Ege Tanriverdi,Sriram Vishwanath,Sandeep P. Chinchali*

主要分类: cs.CV

摘要简述: 本文提出PhonemeFake（PF），一种基于语言推理的深度伪造攻击方法，显著降低人类感知和检测准确率，并发布开源检测模型，实现高效定位和计算优化。


<details>
  <summary>详细信息</summary>
研究动机: 现有深度伪造数据集未能真实反映攻击对人类感知的影响，亟需更真实的攻击向量以应对日益先进的生成模型威胁。

研究方法: 提出PhonemeFake（PF），通过语言推理操纵关键语音片段，并开发自适应双层检测模型，优先计算被操纵区域。

研究结果: PF攻击使人类感知降低42%，检测准确率下降94%；检测模型将EER降低91%，速度提升90%，计算开销极小。

研究结论: PhonemeFake和自适应检测模型为深度伪造攻击与防御提供了更真实的评估框架和高效解决方案。

中文摘要: 深度伪造（DF）攻击随着生成模型的日益先进而构成越来越大的威胁。然而，我们的研究表明，现有的DF数据集未能欺骗人类感知，而真实的DF攻击却影响了公共舆论。这凸显了对更真实DF攻击向量的需求。我们提出了PhonemeFake（PF），一种通过语言推理操纵关键语音片段的DF攻击，显著降低了人类感知（最高42%）和基准准确率（最高94%）。我们在HuggingFace上发布了易于使用的PF数据集，并开源了自适应双层DF片段检测模型，优先计算被操纵区域。我们在三个已知DF数据集上的广泛实验表明，我们的检测模型将EER降低了91%，同时实现了高达90%的速度提升，计算开销极小，定位精度超越现有模型，是一种可扩展的解决方案。

</details>


### [119] [Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching](https://arxiv.org/abs/2506.22784)
**中文标题：基于监督跨模态特征匹配的单帧点像素配准**

*Yu Han,Zhiwei Huang,Yanting Zhang,Fangjun Ding,Shen Cai,Rui Fan*

主要分类: cs.CV

摘要简述: 本文提出了一种基于无检测器匹配框架的LiDAR点云与相机图像的单帧点像素配准方法，通过注意力机制和可重复性评分机制提升跨模态匹配的鲁棒性，在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: LiDAR点云与相机图像的配准是自动驾驶和机器人感知中的关键任务，但现有方法因模态差异和单帧LiDAR的稀疏性而效果不佳。本文旨在解决这一问题，提出一种无需多帧累积的直接配准方法。

研究方法: 方法包括将LiDAR强度图投影到2D视图，并输入基于注意力的无检测器匹配网络，实现跨模态对应估计。同时引入可重复性评分机制，抑制低强度变化区域的不匹配，提升稀疏输入下的鲁棒性。

研究结果: 在KITTI、nuScenes和MIAS-LCEC-TF70基准测试中，该方法表现优异，优于依赖多帧点云累积的现有方法，实现了单帧LiDAR下的最优性能。

研究结论: 本文提出的无检测器匹配框架有效解决了LiDAR与相机图像的跨模态配准问题，尤其在单帧稀疏输入下表现出色，为自动驾驶感知提供了新思路。

中文摘要: LiDAR点云与相机图像之间的点像素配准是自动驾驶和机器人感知中的基础但具有挑战性的任务。主要难点在于非结构化点云与结构化图像之间的模态差异，尤其是在稀疏单帧LiDAR设置下。现有方法通常分别从点云和图像中提取特征，然后依赖手工设计或学习的匹配策略。这种分离编码无法有效弥合模态差异，且这些方法在单帧LiDAR的稀疏性和噪声下表现不佳，往往需要点云累积或额外先验信息以提高可靠性。受无检测器匹配范式（如MatchAnything）的启发，我们重新审视基于投影的方法，并提出了LiDAR与相机视图之间直接点像素匹配的无检测器框架。具体而言，我们将LiDAR强度图从LiDAR视角投影到2D视图，并输入基于注意力的无检测器匹配网络，实现无需多帧累积的跨模态对应估计。为进一步提升匹配可靠性，我们引入了可重复性评分机制，作为软可见性先验，指导网络抑制低强度变化区域的不可靠匹配，提升稀疏输入下的鲁棒性。在KITTI、nuScenes和MIAS-LCEC-TF70基准上的大量实验表明，我们的方法实现了最优性能，在nuScenes上甚至优于依赖累积点云的现有方法，仅使用单帧LiDAR即可。

</details>


### [120] [RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors](https://arxiv.org/abs/2506.22800)
**中文标题：RGE-GS：基于扩散先验的奖励引导扩展驾驶场景重建**

*Sicong Du,Jiarun Liu,Qifeng Chen,Hao-Xiang Chen,Tai-Jiang Mu,Sheng Yang*

主要分类: cs.CV

摘要简述: RGE-GS提出了一种结合扩散先验与奖励引导的高斯积分框架，通过选择性保留扩散输出和差异化训练策略，显著提升了驾驶场景扩展重建的质量和效率。


<details>
  <summary>详细信息</summary>
研究动机: 单次驾驶片段常导致道路结构扫描不完整，现有3D高斯泼溅技术虽重建质量高，但直接结合扩散先验会引入物理不一致性和训练效率问题。RGE-GS旨在解决这些问题。

研究方法: RGE-GS包含两项创新：1) 奖励网络学习识别并优先保留一致性生成模式；2) 差异化训练策略根据场景收敛指标自动调整高斯优化进度。

研究结果: 公开数据集上的大量实验表明，RGE-GS在重建质量上达到了最先进的性能。

研究结论: RGE-GS通过奖励引导和差异化训练，显著提升了驾驶场景扩展重建的稳定性和效率，为传感器模拟器提供了更高质量的数据支持。

中文摘要: 单次驾驶片段常导致道路结构扫描不完整，因此场景扩展重建对传感器模拟器回归驾驶动作至关重要。尽管当前3D高斯泼溅技术（3DGS）重建质量优异，但直接结合扩散先验会引入累积的物理不一致性并降低训练效率。为解决这些问题，我们提出了RGE-GS，一种结合扩散生成与奖励引导高斯积分的新型扩展重建框架。RGE-GS包含两项关键创新：首先，我们提出一种奖励网络，学习在重建阶段前识别并优先保留一致性生成模式，从而实现扩散输出的选择性保留以提升空间稳定性；其次，在重建过程中，我们设计了一种差异化训练策略，根据场景收敛指标自动调整高斯优化进度，实现了比基线方法更好的收敛效果。在公开数据集上的大量评估表明，RGE-GS在重建质量上达到了最先进的性能。我们的源代码将在https://github.com/CN-ADLab/RGE-GS公开。（包含审稿建议的最终版本将很快更新。）

</details>


### [121] [Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding](https://arxiv.org/abs/2506.22803)
**中文标题：干预黑盒：基于概念瓶颈模型提升人类与神经网络的相互理解**

*Nuoye Xiong,Anqi Dong,Ning Wang,Cong Hua,Guangming Zhu,Mei Lin,Peiyi Shen,Liang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CBM-HNMU的概念瓶颈模型，旨在通过可解释的框架提升人类与神经网络之间的相互理解。该模型通过自动识别和修正有害概念，并将修正后的知识蒸馏回黑盒模型，从而同时提升模型的解释性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度学习模型的复杂化，其可解释性降低，决策过程难以理解。现有方法大多缺乏有效干预或仅停留在样本层面，未能修改模型本身。因此，本文旨在通过概念瓶颈模型提升人类与神经网络之间的相互理解。

研究方法: CBM-HNMU利用概念瓶颈模型（CBM）作为可解释框架，近似黑盒推理并传递概念理解。通过全局梯度贡献自动识别和修正（移除或替换）有害概念，并将修正后的知识蒸馏回黑盒模型。

研究结果: 在Flower-102、CIFAR-10、CIFAR-100、FGVC-Aircraft和CUB-200等数据集上，CBM-HNMU在CNN和基于Transformer的模型中实现了最高2.64%的准确率提升，平均准确率最高提升1.03%。

研究结论: CBM-HNMU通过概念瓶颈模型有效提升了黑盒模型的解释性和准确性，为人类与神经网络的相互理解提供了新方法。

中文摘要: 近年来，深度学习的进展使得模型层数更深、参数更多，复杂性增加，导致可解释性降低，决策过程难以理解。尽管许多方法试图解释黑盒推理，但大多数缺乏有效干预，或仅停留在样本层面而不修改模型本身。为此，我们提出了基于概念瓶颈模型的人类-神经网络相互理解增强方法（CBM-HNMU）。CBM-HNMU利用概念瓶颈模型（CBM）作为可解释框架，近似黑盒推理并传递概念理解。有害概念通过全局梯度贡献自动识别并修正（移除或替换）。修正后的CBM将知识蒸馏回黑盒模型，从而同时提升解释性和准确性。我们在Flower-102、CIFAR-10、CIFAR-100、FGVC-Aircraft和CUB-200等数据集上评估了CBM-HNMU，结果显示其在CNN和基于Transformer的模型中实现了最高2.64%的准确率提升，平均准确率最高提升1.03%。源代码见：https://github.com/XiGuaBo/CBM-HNMU。

</details>


### [122] [Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate](https://arxiv.org/abs/2506.22806)
**中文标题：基于残差注意力门的文本到图像扩散模型概念精准擦除器**

*Byung Hyun Lee,Sungjin Lim,Seunggyu Lee,Dong Un Kang,Se Young Chun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为概念精准擦除器（CPE）的新框架，通过非线性残差注意力门（ResAGs）选择性擦除目标概念，同时保护其他概念免受广泛分布的影响，并通过对抗训练提升鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 随着文本到图像扩散模型的快速发展，如何在不影响其他概念的情况下精准擦除不当或商标概念成为重要问题。现有方法仅微调交叉注意力层，可能导致剩余概念失真。

研究方法: 提出CPE框架，引入非线性ResAGs模块，结合注意力锚定损失防止遗忘，并通过对抗训练和可学习文本嵌入迭代优化擦除性能和鲁棒性。

研究结果: 实验表明，CPE在擦除名人、艺术风格和不当内容方面优于现有方法，能保持剩余概念的多样性，并对抗攻击提示具有鲁棒性。

研究结论: CPE通过非线性模块和对抗训练实现了高效且鲁棒的概念擦除，为扩散模型的安全应用提供了新思路。

中文摘要: 文本到图像扩散模型的显著进展引发了对其可能生成不当或商标概念图像的担忧。概念擦除的目标是在删除目标概念的同时，最小化对其他概念的扭曲。现有方法通常通过微调扩散模型的交叉注意力层实现，但本文首先证明仅更新交叉注意力层（数学上等效于添加线性模块）可能无法保留多样化的剩余概念。为此，我们提出了一种名为概念精准擦除器（CPE）的新框架，通过引入非线性残差注意力门（ResAGs）选择性擦除目标概念，同时利用注意力锚定损失保护剩余概念免受广泛分布的影响。此外，我们通过对抗训练和可学习文本嵌入迭代优化CPE，以最大化擦除性能并增强对抗攻击的鲁棒性。在名人、艺术风格和不当内容擦除的广泛实验中，CPE优于现有方法，既能保持剩余概念的多样性，又能有效删除目标概念并抵御攻击提示。代码发布于https://github.com/Hyun1A/CPE。

</details>


### [123] [FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition](https://arxiv.org/abs/2506.22807)
**中文标题：FreqDGT：基于变换器的频率自适应动态图网络用于跨被试EEG情绪识别**

*Yueyang Li,Shengyu Gong,Weiming Zeng,Nizhuan Wang,Wai Ting Siok*

主要分类: cs.CV

摘要简述: FreqDGT是一种频率自适应动态图变换器，用于跨被试EEG情绪识别，通过动态加权频率带、自适应学习脑连接模式和多尺度时间解耦网络，显著提升跨被试情绪识别的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 脑电图（EEG）因其高时间分辨率和捕捉真实情绪状态的能力，成为情感脑机接口中情绪识别的可靠信号。然而，个体差异、认知特征和情绪响应的多样性导致跨被试泛化成为主要挑战。FreqDGT旨在通过整合频率自适应、空间动态和时间分层建模，解决这一问题。

研究方法: FreqDGT提出频率自适应处理（FAP）动态加权情绪相关频率带，采用自适应动态图学习（ADGL）学习输入特定的脑连接模式，并结合多尺度时间解耦网络（MTDN）通过分层时间变换器和对抗特征解耦捕获时间动态并确保跨被试鲁棒性。

研究结果: 实验表明，FreqDGT显著提高了跨被试情绪识别的准确性，验证了频率自适应、空间动态和时间分层建模的有效性，同时确保了对个体差异的鲁棒性。

研究结论: FreqDGT通过整合频率自适应、动态空间建模和时间分层解耦，有效提升了跨被试EEG情绪识别的性能，为情感脑机接口提供了可靠解决方案。

中文摘要: 脑电图（EEG）因其高时间分辨率和捕捉真实情绪状态的能力，成为情感脑机接口中情绪识别的可靠信号。然而，个体差异、认知特征和情绪响应的多样性导致跨被试泛化成为主要挑战。我们提出FreqDGT，一种频率自适应动态图变换器，通过集成框架系统解决这些问题。FreqDGT引入频率自适应处理（FAP）动态加权情绪相关频率带，采用自适应动态图学习（ADGL）学习输入特定的脑连接模式，并实现多尺度时间解耦网络（MTDN），结合分层时间变换器和对抗特征解耦捕获时间动态并确保跨被试鲁棒性。综合实验表明，FreqDGT显著提高了跨被试情绪识别准确性，验证了频率自适应、空间动态和时间分层建模的有效性，同时确保了对个体差异的鲁棒性。代码可在https://github.com/NZWANG/FreqDGT获取。

</details>


### [124] [Efficient Multi-Crop Saliency Partitioning for Automatic Image Cropping](https://arxiv.org/abs/2506.22814)
**中文标题：高效多裁剪显著性分割用于自动图像裁剪**

*Andrew Hamara,Andrew C. Freeman*

主要分类: cs.CV

摘要简述: 本文提出了一种高效的多裁剪显著性分割方法，用于自动图像裁剪，能够在线性时间内提取多个不重叠的裁剪区域，同时动态调整注意力阈值。


<details>
  <summary>详细信息</summary>
研究动机: 传统的显著性裁剪方法仅优化单个边界框，无法满足需要多个不连续裁剪区域的应用需求。因此，本文旨在扩展固定纵横比裁剪算法，以高效提取多个非重叠裁剪区域。

研究方法: 本文扩展了固定纵横比裁剪算法，通过动态调整注意力阈值，并在不重新计算整个显著性图的情况下移除已选裁剪区域，从而在线性时间内实现多裁剪区域的提取。

研究结果: 实验展示了定性结果，并提出了未来数据集和基准测试的潜力。

研究结论: 本文提出的方法能够高效地实现多裁剪显著性分割，为自动图像裁剪提供了新的解决方案，并为进一步研究开辟了方向。

中文摘要: 自动图像裁剪旨在提取最具视觉显著性的区域，同时保留必要的构图元素。传统的显著性裁剪方法仅优化单个边界框，无法满足需要多个不连续裁剪区域的应用需求。本文扩展了固定纵横比裁剪算法，以高效提取多个非重叠裁剪区域，并在线性时间内完成。我们的方法动态调整注意力阈值，并在不重新计算整个显著性图的情况下移除已选裁剪区域。我们讨论了定性结果，并提出了未来数据集和基准测试的潜力。

</details>


### [125] [Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding](https://arxiv.org/abs/2506.22817)
**中文标题：释放多视图融合潜力：VLM噪声校正用于开放词汇3D场景理解**

*Xingyilang Yin,Jiale Wang,Xi Yang,Mutian Xu,Xu Gu,Nannan Wang*

主要分类: cs.CV

摘要简述: MVOV3D是一种新方法，通过减少视觉语言模型中的固有噪声，释放多视图融合潜力，显著提升开放词汇3D场景理解性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有开放词汇3D场景理解方法受限于有限词汇量和3D数据量，难以处理多样对象类别。2D多视图融合方法虽能理解多样概念，但视觉语言模型中的噪声限制了其性能。

研究方法: MVOV3D通过利用CLIP编码器的精确区域级图像特征和文本特征，结合3D几何先验优化多视图融合，减少噪声而不需训练。

研究结果: MVOV3D在ScanNet200和Matterport160数据集上分别达到14.7%和16.2%的mIoU，显著优于现有3D网络。

研究结论: MVOV3D通过噪声校正和多视图融合优化，显著提升开放词汇3D场景理解能力，为未来研究提供新方向。

中文摘要: 近期的开放词汇3D场景理解方法主要通过点-文本对的对比学习或将2D特征蒸馏到3D模型来实现。尽管这些方法在有限词汇量的基准测试中表现良好，但由于3D数据量的限制，难以处理多样对象类别。我们发现2D多视图融合方法在理解3D场景中的多样概念方面更具优势，但视觉语言模型中的固有噪声导致多视图融合性能不佳。为此，我们提出MVOV3D，旨在释放2D多视图融合的潜力。该方法通过利用CLIP编码器的精确区域级图像特征和文本特征，结合3D几何先验优化多视图融合，减少噪声而不需训练。在多个数据集上的实验表明，MVOV3D显著提升了性能。具体而言，MVOV3D在ScanNet200和Matterport160的开放词汇语义分割任务中分别达到14.7%和16.2%的mIoU，远超现有3D网络。

</details>


### [126] [Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration](https://arxiv.org/abs/2506.22819)
**中文标题：无需恐慌的提示：属性感知、零样本、测试时校准**

*Ramya Hebbalaguppe,Tamoghno Kandar,Abhinav Nagpal,Chetan Arora*

主要分类: cs.CV

摘要简述: 本文提出了一种名为TCA的方法，通过利用大语言模型（LLM）的先验知识初始化测试时提示，并结合正则化损失，显著改善了视觉语言模型（VLM）在测试时提示调整（TPT）后的校准性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的测试时提示调整（TPT）方法过于关注准确性提升，导致置信度校准性能下降，限制了其在关键应用中的适用性。本文旨在解决这一问题。

研究方法: 1. 利用大语言模型（LLM）提供的目标标签属性先验知识初始化测试时提示；2. 提出一种新的正则化损失，以减少类内距离并增加类间距离。

研究结果: 在15个数据集和不同CLIP架构上的实验表明，TCA方法将平均预期校准误差（ECE）降至4.11，显著优于其他方法（如vanilla TPT的11.7）。

研究结论: TCA方法通过合理的提示初始化和正则化损失，有效提升了VLM在TPT后的校准性能，为关键应用提供了更可靠的解决方案。

中文摘要: 视觉语言模型（VLM）通过在大规模数据集上进行自监督训练，在图像识别任务中表现出色。通过测试时提示调整（TPT）进一步优化性能时，现有方法因过度关注准确性而忽视了置信度校准，导致校准性能下降，限制了其在关键应用中的适用性。

本文的贡献包括：（1）提出随机或简单初始化提示会导致对特定测试样本的过拟合，这是TPT后VLM校准不佳的主要原因。为此，我们利用大语言模型（LLM）提供的目标标签属性先验知识，谨慎初始化测试时提示；（2）提出一种新的正则化损失，以减少类内距离并增加类间距离，从而在TPT过程中保持提示质量。

通过在15个数据集和不同CLIP架构上的广泛实验，我们的方法（TCA）显著改善了TPT后的校准性能。实验结果显示，TCA的平均预期校准误差（ECE）为4.11，优于vanilla TPT（11.7）、C-TPT（ICLR'24，6.12）、DiffTPT（CVPR'23，6.78）和PromptAlign（NeurIPS'23，8.43）。代码已公开：https://github.com/rhebbalaguppe/TCA_PromptWithoutPanic。

</details>


### [127] [Listener-Rewarded Thinking in VLMs for Image Preferences](https://arxiv.org/abs/2506.22832)
**中文标题：基于听众奖励的视觉语言模型图像偏好推理**

*Alexander Gambashidze,Li Pengyi,Matvey Skripkin,Andrey Galichin,Anton Gusarov,Konstantin Sobolev,Andrey Kuznetsov,Ivan Oseledets*

主要分类: cs.CV

摘要简述: 本文提出了一种基于听众奖励的强化学习框架，通过引入独立视觉语言模型的反馈来校准奖励信号，显著提升了图像偏好模型的泛化能力和推理准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前的人类视觉偏好奖励模型泛化能力不足，且监督微调容易导致记忆化问题。尽管强化学习（如GRPO）有所改进，但推理准确性在模型与独立视觉语言模型（听众）的推理不一致时会显著下降。

研究方法: 提出了一种听众增强的GRPO框架，听众重新评估推理模型的思维链，生成密集且校准的置信分数，从而调整强化学习的奖励信号，促使推理模型生成更具说服力的解释。

研究结果: 该方法在ImageReward基准测试中达到67.4%的最高准确率，在大规模人类偏好数据集上（120万次投票）的分布外性能提升高达6%，并显著减少了推理矛盾。

研究结论: 听众奖励机制为视觉语言模型与复杂人类偏好的对齐提供了一种可扩展且高效的数据利用路径。

中文摘要: 训练稳健且泛化性强的人类视觉偏好奖励模型对于将文本到图像和文本到视频生成模型与人类意图对齐至关重要。然而，当前的奖励模型往往泛化能力不足，监督微调则容易导致记忆化问题，需要复杂的标注流程。尽管强化学习（如GRPO）提升了泛化能力，但我们发现了一个关键问题：当模型的推理轨迹与独立冻结的视觉语言模型（“听众”）对同一输出的评估不一致时，推理准确性会显著下降。为解决这一问题，我们提出了一种听众增强的GRPO框架。在该框架中，听众重新评估推理模型的思维链，生成密集且校准的置信分数，从而调整强化学习的奖励信号。这不仅鼓励推理模型给出正确答案，还促使其生成能够说服独立模型的解释。我们的听众奖励方案在ImageReward基准测试中达到67.4%的最高准确率，在大规模人类偏好数据集（120万次投票）上的分布外性能提升高达6%，并显著减少了推理矛盾。这些结果表明，基于听众的奖励为视觉语言模型与复杂人类偏好的对齐提供了一种可扩展且高效的数据利用路径。我们将在此发布推理模型：https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner。

</details>


### [128] [SemFaceEdit: Semantic Face Editing on Generative Radiance Manifolds](https://arxiv.org/abs/2506.22833)
**中文标题：SemFaceEdit：基于生成辐射流形的语义面部编辑**

*Shashikant Verma,Shanmuganathan Raman*

主要分类: cs.CV

摘要简述: SemFaceEdit是一种基于生成辐射流形的新方法，通过生成语义场实现面部几何和外观的精确编辑，同时保持其他区域的完整性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D感知GAN技术虽能提供多视角一致性，但缺乏局部编辑能力。生成辐射流形通过约束点采样降低了计算需求并学习细节，但仍需改进以实现更精确的语义编辑。

研究方法: SemFaceEdit包含几何模块和外观模块。几何模块生成语义辐射和占据场，外观模块预测RGB辐射。两模块在对抗训练中联合学习语义感知的几何和外观描述符，外观描述符通过语义潜在码实现解耦。

研究结果: 实验表明，SemFaceEdit在基于语义场的编辑中表现优异，尤其在辐射场解耦方面效果显著，能够精确编辑特定面部语义而不影响其他区域。

研究结论: SemFaceEdit通过语义场和潜在码的结合，实现了面部几何和外观的高效解耦与精确编辑，为生成辐射流形的语义编辑提供了新思路。

中文摘要: 尽管3D感知GAN技术提供了多视角一致性，但生成的图像通常缺乏局部编辑能力。为此，生成辐射流形作为一种高效方法，通过约束体积内的点采样降低了计算需求，并能够学习细节。本文提出SemFaceEdit，这是一种通过在生成辐射流形上生成语义场来简化外观和几何编辑过程的新方法。利用潜在码，我们的方法有效解耦了生成图像中不同面部语义的几何和外观。与现有方法（可能改变整个辐射场的外观）不同，我们的方法能够精确编辑特定面部语义，同时保持其他区域的完整性。网络包含两个关键模块：几何模块（生成语义辐射和占据场）和外观模块（预测RGB辐射）。两模块在对抗训练中联合学习语义感知的几何和外观描述符。外观描述符通过外观模块与各自的语义潜在码关联，促进解耦和增强控制。实验表明，SemFaceEdit在基于语义场的编辑中表现优异，尤其在辐射场解耦方面效果显著。

</details>


### [129] [FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition](https://arxiv.org/abs/2506.22836)
**中文标题：FOCUS：基于语义引导理解的细粒度优化行人属性识别方法**

*Hongyan An,Kuan Zhu,Xin He,Haiyun Guo,Chaoyang Zhao,Ming Tang,Jinqiao Wang*

主要分类: cs.CV

摘要简述: 本文提出FOCUS方法，通过多粒度混合令牌和属性引导视觉特征提取模块，自适应地提取细粒度属性级特征，解决了行人属性识别中区域特征无法泛化到未见属性的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有行人属性识别方法依赖区域特征提取，但区域特征可能牺牲某些属性的独特细粒度模式，且无法泛化到未见属性。FOCUS旨在通过自适应提取属性级特征解决这些问题。

研究方法: FOCUS方法包括多粒度混合令牌（MGMT）捕获多层级视觉特征，属性引导视觉特征提取（AVFE）模块利用文本属性查询对应视觉特征，并结合区域感知对比学习（RACL）确保属性注意力一致。

研究结果: 在PA100K、PETA和RAPv1数据集上的实验表明，FOCUS方法具有显著效果和强泛化能力。

研究结论: FOCUS通过自适应提取属性级特征，显著提升了行人属性识别的性能，并具备对未见属性的泛化能力。

中文摘要: 行人属性识别（PAR）是智能交通和安全领域的基础感知任务。为应对这一细粒度任务，现有方法多聚焦于提取区域特征以丰富属性信息。然而，这些方法中区域特征通常用于预测固定预定义属性集，限制了性能和实用性：1）区域特征可能牺牲某些属性的独特细粒度模式以捕捉跨属性共性；2）区域特征无法泛化到测试时未见属性。本文提出基于语义引导理解的细粒度优化（FOCUS）方法，自适应地为每个属性提取细粒度属性级特征，无论训练时是否见过该属性。具体而言，我们提出多粒度混合令牌（MGMT）以捕获不同视觉粒度层级的潜在特征，从而丰富信息多样性。接着，引入属性引导视觉特征提取（AVFE）模块，利用文本属性作为查询，通过交叉注意力机制从混合令牌中检索对应视觉属性特征。为确保文本属性关注正确的混合令牌，进一步结合区域感知对比学习（RACL）方法，促使同一区域内属性共享一致的注意力图。在PA100K、PETA和RAPv1数据集上的大量实验验证了方法的有效性和强泛化能力。

</details>


### [130] [AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results](https://arxiv.org/abs/2506.22843)
**中文标题：AG-VPReID 2025：无人机与地面视频行人重识别挑战赛结果**

*Kien Nguyen,Clinton Fookes,Sridha Sridharan,Huy Nguyen,Feng Liu,Xiaoming Liu,Arun Ross,Dana Michalski,Tamás Endrei,Ivan DeAndres-Tame,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez,Javier Ortega-Garcia,Zijing Gong,Yuhao Wang,Xuehu Liu,Pingping Zhang,Md Rashidunnabi,Hugo Proença,Kailash A. Hambarde,Saeid Rezaei*

主要分类: cs.CV

摘要简述: 本文介绍了AG-VPReID 2025挑战赛，这是首个专注于高空（80-120米）无人机与地面视频行人重识别的竞赛。基于包含3027个身份、13500多个轨迹片段和约370万帧的新数据集，四支国际团队提出了多流架构、基于Transformer的时间推理和物理建模等方法。最佳方法X-TFCLIP在无人机到地面和地面到无人机的重识别中分别取得了72.28%和70.77%的Rank-1准确率。


<details>
  <summary>详细信息</summary>
研究动机: 无人机与地面视角的行人重识别在大规模监控和公共安全应用中至关重要。尽管地面场景的重识别已取得显著进展，但由于视角差异、尺度变化和遮挡等问题，无人机与地面之间的重识别仍具挑战性。AG-VPReID 2025挑战赛旨在推动这一领域的研究。

研究方法: 挑战赛基于新的AG-VPReID数据集，包含3027个身份、13500多个轨迹片段和约370万帧数据，来自无人机、闭路电视和可穿戴摄像头。四支国际团队提出了多流架构、基于Transformer的时间推理和物理建模等方法。

研究结果: 最佳方法X-TFCLIP在无人机到地面和地面到无人机的重识别中分别取得了72.28%和70.77%的Rank-1准确率，超越了现有基线，同时凸显了数据集的复杂性。

研究结论: AG-VPReID 2025挑战赛为无人机与地面视频行人重识别提供了新的基准，展示了该领域的进展和挑战。最佳方法的表现表明，结合多模态和时序信息是未来研究的重要方向。

中文摘要: 无人机与地面视角的行人重识别（ReID）在大规模监控和公共安全应用中变得至关重要。尽管地面场景的重识别已取得显著进展，但由于极端视角差异、尺度变化和遮挡等问题，无人机与地面之间的重识别仍具挑战性。基于AG-ReID 2023挑战赛的成果，本文介绍了AG-VPReID 2025挑战赛——首个专注于高空（80-120米）无人机与地面视频行人重识别的大规模竞赛。该挑战赛基于新的AG-VPReID数据集，包含3027个身份、13500多个轨迹片段和约370万帧数据，来自无人机、闭路电视和可穿戴摄像头。四支国际团队提出了从多流架构到基于Transformer的时间推理和物理建模等多种解决方案。领先的方法X-TFCLIP（来自UAM）在无人机到地面和地面到无人机的重识别中分别取得了72.28%和70.77%的Rank-1准确率，超越了现有基线，同时凸显了数据集的复杂性。更多详情请访问官方网站：https://agvpreid25.github.io。

</details>


### [131] [DMD-Net: Deep Mesh Denoising Network](https://arxiv.org/abs/2506.22850)
**中文标题：DMD-Net：深度网格去噪网络**

*Aalok Gangopadhyay,Shashikant Verma,Shanmuganathan Raman*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DMD-Net的端到端深度学习框架，用于解决网格去噪问题。该方法通过图卷积神经网络在原始图和其对偶图中进行聚合，并结合特征引导变换器实现高效去噪，性能优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 网格去噪是3D图形处理中的重要问题，现有方法在处理复杂噪声时表现不佳。本文旨在开发一种基于深度学习的端到端框架，以提升去噪效果和鲁棒性。

研究方法: DMD-Net采用非对称双流网络结构，包含原始流和对偶流，并通过原始-对偶融合块实现信息交互。特征引导变换器（FGT）包括特征提取器、变换器和去噪器，通过局部特征估计和变换生成中间表示，最终实现去噪。

研究结果: 实验表明，DMD-Net在大规模3D数据集上表现优异，能够处理多种噪声类型，即使在高噪声情况下仍保持出色性能。其去噪效果优于现有先进算法。

研究结论: DMD-Net通过结合图卷积网络和特征引导变换器，实现了高效的网格去噪，具有鲁棒性和广泛适用性，为3D图形处理提供了新思路。

中文摘要: 我们提出了深度网格去噪网络（DMD-Net），一种端到端的深度学习框架，用于解决网格去噪问题。DMD-Net包含一个图卷积神经网络，该网络在原始图和对偶图中进行聚合。这是通过一种非对称双流网络实现的，其中包含一个原始-对偶融合块，用于实现原始流与对偶流之间的通信。我们开发了一种特征引导变换器（FGT）范式，包括特征提取器、变换器和去噪器。特征提取器估计局部特征，引导变换器计算变换，并将其应用于噪声输入网格以获取有用的中间表示。随后，去噪器进一步处理该表示以获得去噪后的网格。我们的网络在大规模3D对象数据集上进行了训练。通过详尽的消融研究，我们证明了网络中的每个组件对实现最佳性能至关重要。实验表明，与现有最先进的网格去噪算法相比，我们的方法取得了竞争性或更好的结果。我们还证明了该方法对多种噪声类型具有鲁棒性。即使在极高噪声的情况下，我们的方法仍能表现出色。

</details>


### [132] [Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval](https://arxiv.org/abs/2506.22864)
**中文标题：掩码感知的文本到图像检索：指代表达分割与跨模态检索的结合**

*Li-Cheng Shen,Jih-Kang Hsieh,Wei-Hua Li,Chu-Song Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种新的任务Mask-aware TIR（MaTIR），将文本到图像检索（TIR）与指代表达分割（RES）结合，旨在实现高效的图像搜索和精确的对象分割。通过两阶段框架（分割感知检索和多模态大语言模型重排序），显著提升了检索准确性和分割质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到图像检索方法主要基于整图描述，缺乏可解释性；而指代表达分割虽能精确定位对象，但在大规模图像集合中计算成本高。因此，需要一种既能高效检索又能精确分割的方法。

研究方法: 提出两阶段框架：1）利用SAM 2生成对象掩码和Alpha-CLIP提取区域级嵌入，实现分割感知的离线检索；2）使用多模态大语言模型（MLLM）重排序并生成边界框，匹配分割掩码。

研究结果: 在COCO和D$^3$数据集上的实验表明，该方法在检索准确性和分割质量上均显著优于现有方法。

研究结论: MaTIR任务及其两阶段框架有效结合了检索与分割的优势，为跨模态任务提供了新的解决方案。

中文摘要: 文本到图像检索（TIR）旨在根据文本查询找到相关图像，但现有方法主要基于整图描述，缺乏可解释性。同时，指代表达分割（RES）能够基于自然语言描述精确定位对象，但在大规模图像集合中计算成本高。为弥补这一差距，我们提出了掩码感知的TIR（MaTIR）任务，将TIR与RES结合，要求同时实现高效的图像搜索和精确的对象分割。为解决该任务，我们提出了一个两阶段框架：第一阶段实现分割感知的图像检索，第二阶段利用多模态大语言模型（MLLM）进行重排序和对象定位。我们首先利用SAM 2生成对象掩码和Alpha-CLIP提取区域级嵌入，实现高效且可扩展的在线检索；其次，使用MLLM优化检索排名并生成边界框，与分割掩码匹配。我们在COCO和D$^3$数据集上评估了该方法，结果表明其在检索准确性和分割质量上均显著优于现有方法。

</details>


### [133] [Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception](https://arxiv.org/abs/2506.22866)
**中文标题：区域感知CAM：基于显著区域感知的高分辨率弱监督缺陷分割**

*Hang-Cheng Dong,Lu Zou,Bingguo Liu,Dong Ye,Guodong Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于区域感知类激活图（CAM）和伪标签训练的弱监督语义分割框架，用于高分辨率缺陷分割，通过过滤引导反向传播（FGBP）和区域感知加权模块提升细节保留和空间精度。


<details>
  <summary>详细信息</summary>
研究动机: 工业缺陷检测依赖大规模标注数据，而传统方法难以满足实际需求。本文旨在通过弱监督学习实现高精度缺陷分割，解决标注数据不足的问题。

研究方法: 1. 提出过滤引导反向传播（FGBP）优化目标区域；2. 开发区域感知加权模块提升空间精度；3. 通过伪标签训练迭代优化模型性能。

研究结果: 在工业缺陷数据集上的实验表明，该方法显著优于现有方法，有效实现了高精度缺陷分割。

研究结论: 该框架成功弥合了弱监督学习与高精度缺陷分割之间的差距，为资源受限的工业场景提供了实用解决方案。

中文摘要: 表面缺陷检测在工业质量检测中至关重要。人工智能的进步显著提升了检测过程的自动化水平，但传统语义分割和目标检测模型依赖大规模标注数据，与缺陷检测的实际需求相矛盾。本文提出了一种新颖的弱监督语义分割框架，包含区域感知类激活图（CAM）和伪标签训练两个关键组件。针对现有CAM方法分辨率低和细节保留不足的问题，我们引入了过滤引导反向传播（FGBP），通过过滤梯度幅度优化目标区域以识别与缺陷相关性更高的区域。在此基础上，进一步开发了区域感知加权模块以提升空间精度。最后，通过伪标签分割迭代优化模型性能。在工业缺陷数据集上的综合实验证明了该方法的优越性。所提框架有效弥合了弱监督学习与高精度缺陷分割之间的差距，为资源受限的工业场景提供了实用解决方案。

</details>


### [134] [STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing](https://arxiv.org/abs/2506.22868)
**中文标题：STR-Match：基于时空相关性分数的无训练视频编辑匹配方法**

*Junsung Lee,Junoh Kang,Bohyung Han*

主要分类: cs.CV

摘要简述: STR-Match是一种无需训练的视频编辑算法，通过新颖的STR分数优化潜在空间，解决了现有方法在时间不一致性和运动失真上的问题，显著提升了时空一致性和视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本引导的视频编辑方法存在时间不一致、运动失真和领域转换受限的问题，主要原因是未能充分建模时空像素相关性。

研究方法: 提出STR-Match算法，利用2D空间注意力和1D时间模块计算STR分数，结合潜在优化框架和潜在掩码，生成时空一致且视觉逼真的视频。

研究结果: 实验表明，STR-Match在视觉质量和时空一致性上均优于现有方法，尤其在显著领域转换下仍能保持关键视觉属性。

研究结论: STR-Match通过优化时空相关性建模，显著提升了视频编辑的时空一致性和视觉质量，适用于复杂领域转换场景。

中文摘要: 现有的文本引导视频编辑方法常受限于时间不一致性、运动失真及领域转换能力不足。我们认为这些问题的根源在于编辑过程中对时空像素相关性的建模不足。为此，我们提出STR-Match，一种无需训练的视频编辑算法，通过基于新颖STR分数的潜在优化生成视觉吸引且时空一致的视频。该分数通过结合文本到视频（T2V）扩散模型中的2D空间注意力和1D时间模块，捕捉相邻帧间的时空像素相关性，避免了计算昂贵的3D注意力机制。结合潜在优化框架和潜在掩码，STR-Match生成的时间一致且视觉逼真的视频，即使在显著领域转换下仍能保持源视频的关键视觉属性。大量实验表明，STR-Match在视觉质量和时空一致性上均优于现有方法。

</details>


### [135] [Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder](https://arxiv.org/abs/2506.22880)
**中文标题：解耦的Seg Tokens构建更强的推理视频分割与定位模型**

*Dang Jisheng,Wu Xudong,Wang Bimei,Lv Ning,Chen Jiayu,Jingwen Zhao,Yichu liu,Jizhao Liu,Juncheng Li,Teng Wang*

主要分类: cs.CV

摘要简述: 论文提出DeSa2VA方法，通过解耦文本和视觉特征增强视频分割和定位能力，显著提升分割精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法（如Sa2VA）在分割模型中直接融合特征，导致动态视觉信息与静态语义纠缠，影响分割精度。为解决这一问题，论文提出解耦增强的提示方案。

研究方法: 1. 设计预训练范式，将文本标签转换为点级提示并生成文本掩码；2. 使用线性投影将大语言模型的隐藏状态解耦为文本和视觉特征子空间；3. 动态掩码融合策略结合解耦特征。

研究结果: 在图像分割、图像问答、视频分割和视频问答等任务中达到最先进性能。

研究结论: DeSa2VA通过解耦特征和动态融合策略，显著提升了视频分割和定位的精度，为多任务学习提供了有效解决方案。

中文摘要: 现有的视频分割与定位方法（如Sa2VA）直接在分割模型中融合特征，导致动态视觉信息与静态语义的纠缠，从而降低分割精度。为系统解决这一问题，我们提出DeSa2VA，一种解耦增强的提示方案，结合文本预训练和线性解耦模块，以解决SAM-2固有的信息处理限制。具体而言，首先设计了一种预训练范式，将文本真实标签转换为点级提示并生成对应的文本掩码，通过混合损失函数优化掩码以增强模型的语义定位能力。接着，使用线性投影将大语言模型生成的隐藏状态解耦为独立的文本和视觉特征子空间。最后，通过动态掩码融合策略，协同结合这些解耦特征，利用预测的文本/视觉掩码和真实标注的三重监督。大量实验表明，该方法在图像分割、图像问答、视频分割和视频问答等任务中均达到最先进性能。代码发布于https://github.com/longmalongma/DeSa2VA。

</details>


### [136] [How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings](https://arxiv.org/abs/2506.22881)
**中文标题：图像的语义信息量有多大？：对比学习嵌入的协方差加权范数测量**

*Fumiya Uchiyama,Rintaro Yanagi,Shohei Taniguchi,Shota Takashiro,Masahiro Suzuki,Hirokatsu Kataoka,Yusuke Iwasawa,Yutaka Matsuo*

主要分类: cs.CV

摘要简述: 本文提出了一种通过对比学习模型计算图像和文本语义信息量的新指标，扩展了信息增益的概念，并验证了其与嵌入向量范数的强相关性。


<details>
  <summary>详细信息</summary>
研究动机: 对比学习能够建模多模态概率分布，但尚不清楚其是否能表示绝对语义信息量。本文旨在填补这一空白，提出一种量化图像和文本语义信息量的方法。

研究方法: 通过对比学习模型（如CLIP或SigLIP）计算图像和文本的信息增益，利用嵌入向量的协方差加权范数估计信息量。该方法计算成本低，且与样本量无关。

研究结果: 实验结果显示，信息增益得分最低的图像多为占位图标（如“未找到图像”），且信息增益与嵌入向量范数具有强相关性（决定系数0.98-1.00）。

研究结论: 本文提出的语义信息量指标有效且高效，适用于公开可用的模型，为多模态语义分析提供了新工具。

中文摘要: 对比学习能够通过嵌入和对齐视觉表示与文本语义来建模多模态概率分布，从而估计关系语义相似性。然而，其是否能表示绝对语义信息量尚不明确。本文提出了一种通过对比学习模型从文本样本计算图像语义信息量的指标，反之亦然。我们重新定义了信息增益的概念，将其扩展至视觉与语言领域。该指标量化了图像对关联文本分布的扭曲程度，反之亦然。OpenCLIP的实验结果表明，信息增益得分最低的图像多为占位图标（如“未找到图像”）。此外，我们提出通过嵌入向量的范数估计信息增益，基于Skip-Gram负采样（SGNS）词嵌入的理论结果。信息增益可通过CLIP或SigLIP测量，结果显示其与嵌入向量范数具有强相关性（决定系数0.98-1.00）。该方法在获取样本嵌入的均值和协方差后，计算成本与样本量无关，且兼容公开可用的开源模型。

</details>


### [137] [CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems](https://arxiv.org/abs/2506.22890)
**中文标题：CP-Guard：一种统一、概率无关且自适应的多智能体感知系统中恶意智能体检测与防御框架**

*Senkang Hu,Yihang Tao,Guowen Xu,Xinyuan Qian,Yiqin Deng,Xianhao Chen,Sam Tak Wu Kwong,Yuguang Fang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CP-Guard的统一、概率无关且自适应的框架，用于在多智能体感知系统中检测和防御恶意智能体。通过概率无关样本共识（PASAC）和协作一致性损失（CCLoss）方法，结合动态阈值调整，有效提升了系统的安全性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 在多智能体协同感知（CP）系统中，智能体通过共享感知信息提升性能，但也容易受到恶意智能体的攻击。现有方法通常依赖先验概率，难以适应动态环境。本文旨在设计一种无需先验概率、能动态适应环境的防御框架。

研究方法: 1. 提出概率无关样本共识（PASAC）方法，通过采样和验证协作智能体的共识，无需依赖恶意智能体的先验概率。2. 定义协作一致性损失（CCLoss），用于对象检测和鸟瞰图分割任务，量化智能体间的感知差异。3. 设计基于双滑动窗口的动态阈值调整机制，确保系统在动态环境中的可靠性。

研究结果: 实验表明，CP-Guard能有效检测和消除恶意智能体，显著提升系统的安全性和鲁棒性。动态阈值调整机制进一步增强了系统在复杂环境中的适应性。

研究结论: CP-Guard为多智能体协同感知系统提供了一种高效、灵活的防御框架，解决了现有方法依赖先验概率和静态阈值的问题，具有广泛的应用前景。

中文摘要: 协同感知（CP）是一种在多智能体自动驾驶和多智能体机器人系统中表现出潜力的技术，通过共享感知信息提升整体性能并扩展感知范围。然而，CP中的智能体需接收协作方的消息，易受恶意智能体攻击。为解决这一问题，我们提出了一种统一、概率无关且自适应的框架CP-Guard，作为每个智能体部署的定制防御机制，用于精确检测并消除协作网络中的恶意智能体。核心思想是使CP达成共识而非与智能体的感知结果冲突。基于此，我们首先开发了概率无关样本共识（PASAC）方法，无需恶意智能体先验概率即可有效采样协作方子集并验证共识。此外，我们为对象检测和鸟瞰图分割任务定义了协作一致性损失（CCLoss），用于捕捉智能体间的差异，作为共识验证标准。我们还提出基于双滑动窗口的在线自适应阈值，动态调整共识验证阈值，确保系统在动态环境中的可靠性。最后，通过大量实验验证了框架的有效性。代码发布于https://github.com/CP-Security/CP-Guard。

</details>


### [138] [Neural Cellular Automata: From Cells to Pixels](https://arxiv.org/abs/2506.22899)
**中文标题：神经细胞自动机：从细胞到像素**

*Ehsan Pajouheshgar,Yitao Xu,Ali Abbasi,Alexander Mordvintsev,Wenzel Jakob,Sabine Süsstrunk*

主要分类: cs.CV

摘要简述: 本文提出了一种结合神经细胞自动机（NCA）与轻量级隐式解码器的方法，解决了NCA在高分辨率网格上的训练和实时推理难题，显著提升了生成质量和效率。


<details>
  <summary>详细信息</summary>
研究动机: 神经细胞自动机（NCA）在纹理合成和形态生成中表现出色，但其在高分辨率网格上的应用受限于训练时间、内存需求和信息传播的局部性。本文旨在突破这些限制，实现NCA在高分辨率下的高效运行。

研究方法: 通过将NCA与共享的隐式解码器结合，在粗网格上进行演化后，利用轻量级解码器生成任意分辨率的输出图像。同时，为形态生成和纹理合成任务设计了新的损失函数，以减少计算和内存开销。

研究结果: 实验表明，该方法显著提升了NCA在高分辨率下的生成质量和效率，能够实时生成全高清输出，并保持自组织和涌现特性。此外，该方法适用于多种NCA变体和任务。

研究结论: 通过结合隐式解码器和优化损失函数，本文成功扩展了NCA在高分辨率下的应用，为纹理生成和形态生成提供了高效且可扩展的解决方案。

中文摘要: 神经细胞自动机（NCA）是一种受生物启发的系统，其中相同的细胞通过重复应用简单的局部规则自组织形成复杂且连贯的模式。NCA表现出显著的涌现行为，包括自我再生、对未见情况的泛化和鲁棒性，以及自发运动。尽管在纹理合成和形态生成中取得成功，NCA仍主要局限于低分辨率网格。这一限制源于：（1）训练时间和内存需求随网格大小呈二次增长；（2）信息的严格局部传播阻碍了长距离细胞通信；（3）高分辨率实时推理的高计算需求。本文通过将NCA与共享的隐式解码器结合，克服了这一限制。在粗网格上进行NCA演化后，轻量级解码器可生成任意分辨率的输出图像。我们还为形态生成和纹理合成任务设计了新的损失函数，专门针对高分辨率输出，同时最小化内存和计算开销。结合提出的架构和损失函数，显著提升了质量、效率和性能。配备隐式解码器的NCA可以实时生成全高清输出，同时保持其自组织和涌现特性。此外，由于每个MLP独立处理细胞状态，推理仍具有高度并行性和高效性。我们在多种NCA变体（2D、3D网格和3D网格）和任务（包括纹理生成和形态生成）中展示了该方法的适用性，表明通过提出的框架，NCA可以无缝扩展到高分辨率输出，且计算开销极小。

</details>


### [139] [MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering](https://arxiv.org/abs/2506.22900)
**中文标题：MOTOR：基于多模态最优传输的医学视觉问答检索方法**

*Mai A. Shaaban,Tausifa Jan Saleem,Vijay Ram Papineni,Mohammad Yaqub*

主要分类: cs.CV

摘要简述: 论文提出了一种名为MOTOR的多模态检索和重排序方法，通过结合文本和视觉信息优化医学视觉问答（MedVQA）中的检索结果，显著提升了回答的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 医学视觉问答（MedVQA）在临床决策中至关重要，但现有视觉语言模型（VLMs）常生成错误答案。检索增强生成虽能提供外部信息，但可能检索到无关内容，影响模型推理能力。现有重排序方法仅关注文本对齐，忽略了视觉或多模态信息的重要性。

研究方法: MOTOR方法结合了基于文本和视觉信息的检索与重排序，利用接地字幕和最优传输技术捕捉查询与检索内容之间的多模态关系，从而识别更相关的临床上下文。

研究结果: 实验和专家评估表明，MOTOR在MedVQA数据集上的准确率平均提升了6.45%，优于现有最优方法。

研究结论: MOTOR通过多模态检索和重排序显著提升了医学视觉问答的准确性，为临床决策提供了更可靠的辅助工具。

中文摘要: 医学视觉问答（MedVQA）在临床决策中通过为基于图像的查询提供丰富上下文答案发挥重要作用。尽管视觉语言模型（VLMs）广泛用于此任务，但其常生成事实错误的答案。检索增强生成通过提供外部信息解决了这一问题，但可能检索到无关内容，从而削弱VLMs的推理能力。现有方法引入的重排序技术通过关注查询-文本对齐提升了检索相关性，但这些方法忽略了视觉或多模态上下文，而这在医学诊断中尤为重要。我们提出MOTOR，一种新颖的多模态检索和重排序方法，利用接地字幕和最优传输技术，基于文本和视觉信息捕捉查询与检索内容之间的潜在关系。因此，我们的方法能够识别更临床相关的上下文以增强VLM输入。实验分析和专家评估表明，MOTOR在MedVQA数据集上的准确率平均高出现有最优方法6.45%。代码发布于https://github.com/BioMedIA-MBZUAI/MOTOR。

</details>


### [140] [Point Cloud Compression and Objective Quality Assessment: A Survey](https://arxiv.org/abs/2506.22902)
**中文标题：点云压缩与客观质量评估：综述**

*Yiling Xu,Yujie Zhang,Shuting Xia,Kaifa Yang,He Huang,Ziyu Shan,Wenjie Huang,Qi Yang,Le Yang*

主要分类: cs.CV

摘要简述: 本文综述了3D点云压缩（PCC）和点云质量评估（PCQA）的最新进展，分析了手工和基于学习的算法及评估指标，并指出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着自动驾驶、机器人和沉浸式环境等应用的快速发展，3D点云数据的需求急剧增长，但其不规则结构、大数据量和复杂属性带来了独特的挑战，亟需高效的压缩和质量评估技术。

研究方法: 本文全面调查了手工和基于学习的点云压缩算法及客观质量评估指标，通过在新兴数据集上对代表性方法进行基准测试，提供了详细的性能对比和实践见解。

研究结果: 研究发现，尽管点云压缩和质量评估技术取得了显著进展，但在提升视觉保真度、降低延迟和支持多模态数据等方面仍存在挑战。

研究结论: 未来研究方向包括混合压缩框架和高级特征提取策略，以实现更高效、沉浸式和智能的3D应用。

中文摘要: 随着自动驾驶、机器人和沉浸式环境等应用的快速发展，3D点云数据的需求急剧增长，但其不规则结构、大数据量和复杂属性带来了独特的挑战，亟需高效的压缩和质量评估技术。本文全面综述了点云压缩（PCC）和点云质量评估（PCQA）的最新进展，强调了其在实时和感知相关应用中的重要性。我们分析了多种手工和基于学习的PCC算法，以及客观PCQA指标。通过在新兴数据集上对代表性方法进行基准测试，提供了详细的性能对比和实践见解。尽管取得了显著进展，但在提升视觉保真度、降低延迟和支持多模态数据等方面仍存在挑战。本文展望了未来研究方向，包括混合压缩框架和高级特征提取策略，以实现更高效、沉浸式和智能的3D应用。

</details>


### [141] [MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances](https://arxiv.org/abs/2506.22907)
**中文标题：MagShield：提升稀疏惯性运动捕捉在磁干扰下的鲁棒性**

*Yunzhe Shao,Xinyu Yi,Lu Yin,Shihui Guo,Junhai Yong,Feng Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MagShield的新方法，旨在解决稀疏惯性运动捕捉（MoCap）系统中磁干扰问题。通过“检测-校正”策略，MagShield显著提升了在磁干扰环境下的运动捕捉精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有惯性测量单元（IMU）系统在磁干扰环境下易产生方向估计误差，限制了其在实际场景中的应用。MagShield旨在解决这一问题，提升稀疏惯性MoCap系统的鲁棒性。

研究方法: MagShield采用“检测-校正”策略，首先通过多IMU联合分析检测磁干扰，然后利用人体运动先验校正方向误差。该方法可与大多数现有稀疏惯性MoCap系统兼容。

研究结果: 实验结果表明，MagShield显著提高了磁干扰环境下的运动捕捉精度，并在不同稀疏惯性MoCap系统中表现出良好的兼容性。

研究结论: MagShield为稀疏惯性MoCap系统在磁干扰环境下的应用提供了一种有效的解决方案，显著提升了系统的鲁棒性和实用性。

中文摘要: 本文提出了一种名为MagShield的新方法，旨在解决稀疏惯性运动捕捉（MoCap）系统中的磁干扰问题。现有的惯性测量单元（IMU）系统在磁干扰环境下易产生方向估计误差，限制了其在实际场景中的应用。为解决这一问题，MagShield采用“检测-校正”策略，首先通过多IMU联合分析检测磁干扰，然后利用人体运动先验校正方向误差。MagShield可与大多数现有稀疏惯性MoCap系统集成，提升其在磁干扰环境下的性能。实验结果表明，MagShield显著提高了磁干扰环境下的运动捕捉精度，并在不同稀疏惯性MoCap系统中表现出良好的兼容性。

</details>


### [142] [Attention to Burstiness: Low-Rank Bilinear Prompt Tuning](https://arxiv.org/abs/2506.22908)
**中文标题：关注突发性：低秩双线性提示调优**

*Yuzhu Wang,Manni Duan,Shu Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为BPT的低秩双线性提示调优方法，通过数据白化和低秩分解优化视觉提示调优（VPT），显著提升了模型精度并减少了参数和计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 视觉提示调优（VPT）中，图像块嵌入与Transformer自注意力模块的键和查询投影器之间的交互会产生“突发性”值，且这些值呈现非高斯分布，增加了提示学习的难度。本文旨在通过数据白化和低秩分解解决这一问题。

研究方法: 首先对图像块嵌入和键/查询投影器的数据进行白化处理，使其更接近高斯分布；然后通过双线性方式将白化矩阵与提示相乘。进一步提出低秩双线性模型，通过分解为两个小矩阵减少参数和计算开销。

研究结果: 实验表明，BPT方法在多个基准数据集上显著优于传统VPT方法，例如在CUB数据集上提升了超过25个准确率点，同时减少了参数和计算成本。

研究结论: BPT方法通过数据白化和低秩分解有效解决了VPT中的突发性问题，显著提升了模型性能并降低了资源消耗，为视觉提示调优提供了新的优化方向。

中文摘要: 视觉提示调优（VPT）是一种参数高效的微调技术，通过学习输入空间中的少量参数（称为提示）来适应预训练的视觉Transformer（ViT）。在VPT中，我们发现图像块嵌入与Transformer自注意力模块的键和查询投影器之间的交互会产生“突发性”值，且这些值分别呈现拉普拉斯和超拉普拉斯分布。这些非高斯分布为提示学习带来了挑战。为解决这一问题，我们提出在学习提示前对数据进行白化处理，去除相关性并均衡方差以使其更接近高斯分布。我们推导了随机图像块嵌入和ViT键/查询投影器的白化矩阵，并以双线性方式将其与待学习的提示相乘。令人惊讶的是，该方法显著加速了提示调优并提升了精度（例如在CUB数据集上提升了超过25个准确率点），同时学习到了“突发性提示”。通过扩展已知会引入突发性的双线性模型，我们提出了一种紧凑的低秩版本，通过学习两个较小的矩阵生成最终提示。我们将这些方法称为双线性提示调优（BPT）。在多个基准数据集上的广泛实验表明，BPT方法不仅优于多种VPT方法，还减少了参数数量和计算开销。

</details>


### [143] [Towards Explainable Bilingual Multimodal Misinformation Detection and Localization](https://arxiv.org/abs/2506.22930)
**中文标题：面向可解释的双语多模态虚假信息检测与定位**

*Yiwei He,Xiangtai Li,Zhenglin Huang,Yi Dong,Hao Fei,Jiangning Zhang,Baoyuan Wu,Guangliang Cheng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为BiMi的双语多模态框架，用于检测和定位双语新闻中的虚假信息，并通过自然语言解释增强可解释性。BiMi结合了区域级定位、跨模态和跨语言一致性检测，并引入在线检索模块和GRPO优化解释质量。实验表明，BiMi在分类、定位和解释质量上均优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态内容的真实性提升，双语新闻中的虚假信息变得更加隐蔽且难以检测，尤其是图像与双语字幕结合时，可能存在局部编辑和跨语言不一致性。因此，需要一种能够联合检测和解释虚假信息的框架。

研究方法: BiMi框架通过区域级定位、跨模态和跨语言一致性检测来分析虚假信息，并引入在线检索模块补充外部上下文。此外，采用Group Relative Policy Optimization（GRPO）优化解释质量。同时，发布了包含10.4万样本的BiMiBench基准数据集。

研究结果: 实验结果显示，BiMi在分类准确率上提升8.9，定位准确率提升15.9，解释BERTScore提升2.5，显著优于现有基线方法。

研究结论: BiMi在双语多模态虚假信息检测和定位方面取得了显著进展，并通过GRPO提升了可解释性，为未来研究提供了新的基准和工具。

中文摘要: 随着多模态内容的真实性不断提高，虚假信息变得更加隐蔽且难以检测，尤其是在新闻媒体中，图像常与双语（如中英）字幕配对。此类内容通常包含局部图像编辑和跨语言不一致性，共同扭曲含义却表面上看似合理。我们提出了BiMi，一个双语多模态框架，能够联合执行区域级定位、跨模态和跨语言一致性检测，并为虚假信息分析提供自然语言解释。为支持泛化，BiMi集成了一个在线检索模块，通过最新的外部上下文补充模型推理。我们还发布了BiMiBench，一个通过系统编辑真实新闻图像和字幕构建的大规模综合基准数据集，包含10.4万个样本，涵盖视觉和语言模态的真实操作。为提高可解释性，我们应用了Group Relative Policy Optimization（GRPO）来提升解释质量，这是GRPO在该领域的首次应用。大量实验表明，BiMi在分类准确率上比基线方法高出8.9，定位准确率高出15.9，解释BERTScore高出2.5，在现实多语言虚假信息检测中实现了最先进的性能。代码、模型和数据集将公开发布。

</details>


### [144] [Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data](https://arxiv.org/abs/2506.22939)
**中文标题：利用新型深度学习方法进行遥感数据场景分类**

*Ghufran A. Omran,Wassan Saad Abduljabbar Hayale,Ahmad AbdulQadir AlRababah,Israa Ibraheem Al-Barazanchi,Ravi Sekhar,Pritesh Shah,Sushma Parihar,Harshavardhan Reddy Penubadi*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CO-BRNN的新型深度学习方法，用于遥感数据的场景分类，其准确率高达97%，优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 遥感图像场景分类在灾害控制、生态监测和城市规划等领域具有广泛应用，但传统深度学习方法需要大量高噪声数据，难以实现高精度。

研究方法: 本研究提出了一种名为CO-BRNN的创新方法，结合了Cuttlefish优化和双向循环神经网络，用于遥感数据的场景分类，并与多种现有技术进行了对比。

研究结果: 实验结果显示，CO-BRNN的准确率达到97%，显著优于LSTM-CRF（90%）、MLP-CNN（85%）和CNN-LSTM（80%）等方法。

研究结论: 研究强调了物理验证对卫星数据效率的重要性，并证明了CO-BRNN在遥感场景分类中的优越性。

中文摘要: 遥感图像中的场景分类（SC）是一个重要课题，在灾害控制、生态监测、城市规划等领域具有广泛影响。然而，由于传统深度学习方法需要大量高噪声数据以捕捉关键视觉特征，实现高精度SC仍然具有挑战性。为此，本研究提出了一种名为Cuttlefish优化的双向循环神经网络（CO-BRNN）的创新方法，用于遥感数据场景分类。研究将CO-BRNN与现有技术（如MLP-CNN、CNN-LSTM、LSTM-CRF、GB、MIRM-CF和CNN-DA）进行了性能对比。结果表明，CO-BRNN的准确率最高（97%），其次是LSTM-CRF（90%）、MLP-CNN（85%）和CNN-LSTM（80%）。研究还强调了物理验证对确保卫星数据效率的重要性。

</details>


### [145] [YM-WML: A new Yolo-based segmentation Model with Weighted Multi-class Loss for medical imaging](https://arxiv.org/abs/2506.22955)
**中文标题：YM-WML：一种基于YOLO的加权多类损失医学图像分割新模型**

*Haniyeh Nikkhah,Jafar Tanha,Mahdi Zarrin,SeyedEhsan Roshan,Amin Kazempour*

主要分类: cs.CV

摘要简述: 本文提出了一种基于YOLO的新型医学图像分割模型YM-WML，通过加权多类损失函数解决类别不平衡问题，并在ACDC数据集上取得了91.02的Dice相似系数，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割面临类别不平衡和复杂结构的挑战，需要一种能够有效提取特征并解决类别不平衡问题的新模型。

研究方法: YM-WML模型结合了强大的特征提取主干网络、YOLOv11颈部用于多尺度特征聚合，以及基于注意力的分割头。此外，引入了加权多类指数损失函数（WME）以解决类别不平衡问题。

研究结果: 在ACDC数据集上，YM-WML的Dice相似系数达到91.02，优于现有方法，表现出稳定的训练、准确的分割和强大的泛化能力。

研究结论: YM-WML为心脏图像分割任务设定了新的基准，展示了其在复杂医学图像分割中的潜力。

中文摘要: 医学图像分割因类别不平衡和图像结构复杂而面临巨大挑战。为解决这些问题，本研究提出了一种新型心脏图像分割模型YM-WML。该模型集成了强大的特征提取主干网络、YOLOv11颈部用于多尺度特征聚合，以及基于注意力的分割头，以实现精确分割。为解决类别不平衡问题，我们引入了加权多类指数损失函数（WME）。在ACDC数据集上，YM-WML的Dice相似系数达到91.02，优于现有方法。该模型表现出稳定的训练、准确的分割和强大的泛化能力，为心脏分割任务设定了新的基准。

</details>


### [146] [Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image Watermarking Technique for AI-Generated Images](https://arxiv.org/abs/2506.22960)
**中文标题：PECCAVI：针对AI生成图像的视觉转述攻击安全且无失真水印技术**

*Shreyas Dixit,Ashhar Aziz,Shashwat Bajpai,Vasu Sharma,Aman Chadha,Vinija Jain,Amitava Das*

主要分类: cs.CV

摘要简述: 本文提出PECCAVI，一种针对视觉转述攻击安全且无失真的图像水印技术，通过在多通道频域嵌入水印并结合噪声打磨，有效抵御攻击并保护AI生成图像。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成内容占比激增，欧盟预测到2026年90%的在线内容可能为合成生成，引发对政治虚假信息的担忧。加州AB 3211法案要求对AI生成内容加水印，但现有技术易受篡改和视觉转述攻击。PECCAVI旨在解决这一问题。

研究方法: PECCAVI将水印嵌入图像的核心语义区域（非熔化点，NMPs），采用多通道频域水印技术，并引入噪声打磨以防止反向工程定位NMPs，从而增强水印的耐久性。

研究结果: PECCAVI成功抵御视觉转述攻击，实现无失真水印嵌入，且模型无关，所有资源与代码将开源。

研究结论: PECCAVI为AI生成图像提供了一种安全、耐用的水印解决方案，填补了现有技术的漏洞，具有广泛的应用前景。

中文摘要: 欧盟执法机构报告预测，到2026年，90%的在线内容可能为合成生成，引发对生成式AI作为政治虚假信息放大器的担忧。加州AB 3211法案要求对AI生成图像、视频和音频加水印，但隐形水印技术易受篡改和恶意绕过。生成式AI驱动的去水印攻击，尤其是新提出的视觉转述攻击，能完全去除水印，生成原图的转述版本。本文提出PECCAVI，首个视觉转述攻击安全且无失真的图像水印技术。在视觉转述攻击中，图像被修改但保留其核心语义区域（非熔化点，NMPs）。PECCAVI将水印嵌入这些NMPs，并采用多通道频域水印技术，结合噪声打磨以抵御反向工程定位NMPs的尝试，从而增强耐久性。PECCAVI与模型无关，所有相关资源和代码将开源。

</details>


### [147] [ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment](https://arxiv.org/abs/2506.22967)
**中文标题：ActAlign：通过语言引导的序列对齐实现零样本细粒度视频分类**

*Amir Aghdam,Vincent Tao Hu*

主要分类: cs.CV

摘要简述: ActAlign是一种零样本细粒度视频分类框架，通过语言引导的序列对齐实现，无需视频示例或时间标注，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有对比视觉语言模型（如SigLIP）在开放集识别中表现良好，但无法捕捉细粒度动作的时间结构，导致分类效果不佳。

研究方法: ActAlign将视频分类任务转化为序列对齐问题，利用大语言模型生成有序子动作序列，并通过动态时间规整（DTW）在共享嵌入空间中对齐视频帧。

研究结果: 在极具挑战性的ActionAtlas基准测试中，ActAlign达到30.5%的准确率（人类准确率为61.6%），且参数量仅为现有视频语言模型的1/8。

研究结论: 结合结构化语言先验和经典对齐技术，ActAlign为细粒度视频理解提供了一种可扩展且通用的方法。

中文摘要: 我们解决了零样本细粒度视频分类任务，其中未见动作类别既无视频示例也无时间标注。尽管对比视觉语言模型（如SigLIP）通过平均池化的图像-文本相似性展示了强大的开放集识别能力，但它们无法捕捉区分细粒度活动的关键时间结构。我们提出了ActAlign，一种零样本框架，将视频分类任务转化为序列对齐问题。对于每个类别，大语言模型生成有序的子动作序列，并通过动态时间规整（DTW）在共享嵌入空间中对齐视频帧。在没有任何视频-文本监督或微调的情况下，ActAlign在极具挑战性的ActionAtlas基准测试中达到了30.5%的准确率（人类准确率为61.6%）。ActAlign的表现优于数十亿参数量的视频语言模型，同时使用的参数量约为其1/8。这些结果表明，结构化语言先验与经典对齐技术相结合，为细粒度视频理解提供了一种可扩展且通用的方法，释放了视觉语言模型在开放集识别中的潜力。

</details>


### [148] [Probabilistic Prototype Calibration of Vision-Language Models for Generalized Few-shot Semantic Segmentation](https://arxiv.org/abs/2506.22979)
**中文标题：视觉-语言模型的概率原型校准用于广义少样本语义分割**

*Jie Liu,Jiayi Shen,Pan Zhou,Jan-Jakob Sonke,Efstratios Gavves*

主要分类: cs.CV

摘要简述: 本文提出FewCLIP，一种基于概率原型校准的视觉-语言模型框架，用于广义少样本语义分割（GFSS），通过多模态原型学习和分布正则化提升新类别的适应性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于原型的方法在广义少样本语义分割中存在确定性限制，难以适应多样样本，尤其是标注稀缺的新类别。本文旨在通过概率原型校准提升模型的适应性和泛化能力。

研究方法: FewCLIP引入原型校准机制，通过可学习的视觉校准原型优化冻结的文本原型，并结合分布正则化实现结构化且不确定性感知的原型学习。

研究结果: 在PASCAL-5$^i$和COCO-20$^i$数据集上的实验表明，FewCLIP在GFSS和类增量设置中显著优于现有方法。

研究结论: FewCLIP通过概率原型校准和分布正则化，有效解决了新类别数据稀缺问题，提升了模型的泛化性能。

中文摘要: 广义少样本语义分割（GFSS）旨在通过少量标注样本扩展分割模型至新类别，同时保持基类别的性能。近期，预训练的视觉-语言模型（如CLIP）被用于GFSS，通过多模态原型学习提升新类别的泛化能力。然而，现有基于原型的方法本质上是确定性的，限制了原型对多样样本的适应性，尤其是标注稀缺的新类别。为此，我们提出FewCLIP，一种基于预训练CLIP多模态原型的概率原型校准框架，为GFSS提供更自适应的原型学习。具体而言，FewCLIP首先引入原型校准机制，通过可学习的视觉校准原型优化冻结的文本原型，从而获得更具区分性和适应性的表示。此外，与确定性原型学习技术不同，FewCLIP对这些校准原型引入分布正则化。这种概率化方法确保了结构化且不确定性感知的原型学习，有效缓解了对有限新类别数据的过拟合，同时增强了泛化能力。在PASCAL-5$^i$和COCO-20$^i$数据集上的大量实验结果表明，FewCLIP在GFSS和类增量设置中均显著优于现有方法。代码发布于https://github.com/jliu4ai/FewCLIP。

</details>


### [149] [Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models](https://arxiv.org/abs/2506.22982)
**中文标题：重新审视CroPA：视觉语言模型中跨提示对抗迁移性的可重复性研究与改进**

*Atharv Mittal,Agam Pandey,Amritanshu Tiwari,Sukrit Jindal,Swadesh Swain*

主要分类: cs.CV

摘要简述: 本研究验证了跨提示攻击（CroPA）在视觉语言模型（VLM）中的对抗迁移性，并提出三项改进：新的初始化策略、跨图像迁移性研究和针对视觉编码器注意机制的新损失函数，显著提升了攻击成功率。


<details>
  <summary>详细信息</summary>
研究动机: 视觉语言模型（VLM）在图像分类、字幕生成等任务中表现出色，但对对抗攻击高度脆弱。本研究旨在验证CroPA的跨提示迁移性，并探索改进方法以增强对抗攻击效果。

研究方法: 1. 提出新的初始化策略以提高攻击成功率；2. 研究跨图像迁移性，学习通用扰动；3. 设计针对视觉编码器注意机制的新损失函数以提升泛化能力。实验在Flamingo、BLIP-2等VLM上进行。

研究结果: 验证了CroPA的优越性，改进方法显著提升了对抗攻击效果，攻击成功率提高，跨图像迁移性增强。

研究结论: 研究强调了VLM对抗漏洞的重要性，提供了更鲁棒的对抗样本生成框架，对实际应用中的VLM安全性有重要意义。

中文摘要: 大型视觉语言模型（VLM）彻底改变了计算机视觉领域，支持图像分类、字幕生成和视觉问答等任务。然而，这些模型对对抗攻击高度脆弱，尤其是在视觉和文本模态均可被操纵的场景中。本研究对《一张图片胜过千言谎言：视觉语言模型中跨提示对抗迁移性》进行了全面的可重复性研究，验证了跨提示攻击（CroPA）的优越性，并确认其跨提示迁移性优于现有基线。在复制的基础上，我们提出了几项关键改进：（1）一种新的初始化策略，显著提高了攻击成功率（ASR）；（2）通过研究跨图像迁移性，学习通用扰动；（3）一种针对视觉编码器注意机制的新损失函数，以提升泛化能力。我们在Flamingo、BLIP-2和InstructBLIP等主流VLM上的评估验证了原始结果，并表明我们的改进持续提升了对抗攻击效果。本研究强调了研究VLM对抗漏洞的重要性，并为生成可迁移对抗样本提供了更鲁棒的框架，对理解VLM在实际应用中的安全性具有重要意义。

</details>


### [150] [A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks](https://arxiv.org/abs/2506.23004)
**中文标题：基于卷积神经网络的智能手机可见光通信系统帧识别与同步新技术**

*Vaigai Nayaki Yokar,Hoa Le-Minh,Xicong Li,Wai Lok Woo,Luis Nero Alves,Stanislav Zvanovec,Tran The Son,Zabih Ghassemlooy*

主要分类: cs.CV

摘要简述: 本文提出了一种基于卷积神经网络（CNN）的新型帧识别与同步技术，用于智能手机可见光通信系统，实验结果显示其准确率高达98.74%。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决屏幕到摄像头（S2C）可见光通信（VLC）系统中因模糊、裁剪和旋转图像等实时挑战导致的性能问题，本文旨在开发一种轻量级且鲁棒的帧识别与同步技术。

研究方法: 使用Python和TensorFlow Keras框架开发了一种监督式CNN模型，并通过三次实时实验进行训练。实验数据集中包含了模糊、裁剪和旋转图像等场景，并引入了同步帧以提升系统性能。

研究结果: 实验结果表明，所提出的CNN模型在帧识别与同步任务中达到了约98.74%的总体准确率，显著提升了S2C VLC系统的性能。

研究结论: 本文提出的CNN模型在智能手机可见光通信系统中表现出色，能够有效解决帧识别与同步问题，为短距离通信提供了高效解决方案。

中文摘要: 本文提出了一种新颖、鲁棒且轻量级的基于监督式卷积神经网络（CNN）的帧识别与同步技术，旨在提升屏幕到摄像头（S2C）可见光通信（VLC）系统中的短距离通信性能。该CNN模型使用Python和TensorFlow Keras框架开发，并通过在Jupyter Notebook中进行的三次实时实验进行训练。实验数据集从零开始构建，涵盖了S2C通信中模糊、裁剪和旋转图像等实时挑战。通过引入同步帧，系统性能得到了提升。实验结果表明，所提出的模型在帧识别与同步任务中达到了约98.74%的总体准确率，证明了其在S2C VLC系统中的有效性。

</details>


### [151] [MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models](https://arxiv.org/abs/2506.23009)
**中文标题：MusiXQA：推动多模态大语言模型在视觉音乐理解中的进展**

*Jian Chen,Wenye Ma,Penghang Liu,Wei Wang,Tengwei Song,Ming Li,Chenguang Wang,Ruiyi Zhang,Changyou Chen*

主要分类: cs.CV

摘要简述: 本文介绍了MusiXQA数据集，用于评估和改进多模态大语言模型（MLLMs）在乐谱理解方面的能力。通过高质量合成乐谱和结构化标注，揭示了当前MLLMs的局限性，并提出了改进模型Phi-3-MusiX，显著优于GPT方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在自然图像、文本和图形设计方面表现出色，但其在乐谱理解方面的能力尚未充分探索。本文旨在填补这一空白。

研究方法: 使用MusiXTeX生成高质量合成乐谱，并标注音符、和弦、谱号、调号/拍号等信息，构建MusiXQA数据集。通过该数据集评估现有MLLMs，并开发改进模型Phi-3-MusiX。

研究结果: 实验表明，当前MLLMs在乐谱理解方面存在显著局限性。Phi-3-MusiX在性能上显著优于基于GPT的方法。

研究结论: MusiXQA数据集和Phi-3-MusiX模型为未来MLLMs在乐谱理解领域的发展奠定了基础。

中文摘要: 多模态大语言模型（MLLMs）在自然图像、文本丰富的文档和图形设计中展现了卓越的视觉推理能力，但其对乐谱的解读能力尚未得到充分探索。为填补这一空白，我们推出了MusiXQA，首个用于评估和改进MLLMs在乐谱理解方面的综合数据集。MusiXQA包含通过MusiXTeX生成的高质量合成乐谱，并标注了音符音高与时值、和弦、谱号、调号/拍号及文本，支持多样化的视觉问答任务。通过广泛评估，我们揭示了当前最先进MLLMs在这一领域的显著局限性。除基准测试外，我们还开发了基于该数据集微调的MLLM模型Phi-3-MusiX，其性能显著优于基于GPT的方法。所提出的数据集和模型为未来MLLMs在乐谱理解方面的进展奠定了基础。代码、数据和模型将在论文被接受后发布。

</details>


### [152] [VisionScores -- A system-segmented image score dataset for deep learning tasks](https://arxiv.org/abs/2506.23030)
**中文标题：VisionScores——一个用于深度学习任务的系统分割乐谱图像数据集**

*Alejandro Romero Amezcua,Mariano José Juan Rivera Meraz*

主要分类: cs.CV

摘要简述: VisionScores是一个首个系统分割的乐谱图像数据集，专为深度学习任务设计，包含24.8k张灰度图像，涵盖不同作曲家和作品类型。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏结构丰富且信息密度高的乐谱图像数据集，VisionScores旨在填补这一空白，为机器和深度学习任务提供高质量数据。

研究方法: 数据集限定为双手钢琴曲目，考虑了图形相似性和作曲模式，提供两种场景：同一作品类型不同作曲家（14k样本）和同一作曲家不同作品类型（10.8k样本）。所有样本为128×512像素的灰度图像。

研究结果: VisionScores提供了24.8k张格式化图像，包括系统顺序和乐谱元数据，以及未分割的全页乐谱和预处理图像。

研究结论: VisionScores为深度学习任务提供了首个系统分割的乐谱数据集，支持进一步分析和研究。

中文摘要: VisionScores提出了首个系统分割的乐谱图像数据集，旨在为机器和深度学习任务提供结构丰富、信息密度高的图像。数据集限定为双手钢琴曲目，不仅考虑了图形相似性，还结合了作曲模式，因为创作过程高度依赖乐器。数据集提供了两种场景：第一种包含14k样本，涵盖不同作曲家但相同作品类型（小奏鸣曲）；第二种包含10.8k样本，展示同一作曲家（弗朗茨·李斯特）的不同作品类型。所有24.8k样本均为128×512像素的灰度jpg图像。VisionScores不仅提供格式化样本，还包括系统顺序和乐谱元数据。此外，未分割的全页乐谱和预处理图像也被包含在内，以供进一步分析。

</details>


### [153] [Inpainting is All You Need: A Diffusion-based Augmentation Method for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23038)
**中文标题：修复即一切：基于扩散的半监督医学图像分割数据增强方法**

*Xinrong Hu,Yiyu Shi*

主要分类: cs.CV

摘要简述: 本文提出AugPaint，一种基于扩散模型的数据增强框架，通过修复技术从有限标注数据生成图像-标签对，显著提升半监督医学图像分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学数据集的像素级标注成本高昂且耗时，如何在标注数据稀缺的情况下提升分割性能是一个关键挑战。

研究方法: AugPaint利用潜在扩散模型生成高质量图像，通过修复任务适配采样过程，无需重新训练。具体方法为：裁剪前景标签区域并在反向去噪过程中作为条件，逐步填充背景区域，生成与标签匹配的合成图像。

研究结果: 在四个公共医学图像分割数据集（CT、MRI和皮肤成像）上的实验表明，AugPaint优于现有标签高效方法，显著提升分割性能。

研究结论: AugPaint通过生成高质量合成图像-标签对，有效解决了标注数据稀缺问题，为医学图像分割提供了高效的数据增强方案。

中文摘要: 为医学数据集收集像素级标签是一项耗时且昂贵的工作，如何在标注数据稀缺的情况下提升分割性能是一个关键挑战。本文提出AugPaint，一种数据增强框架，利用修复技术从有限标注数据生成图像-标签对。AugPaint基于潜在扩散模型，该模型能够以低开销生成高质量领域内图像，并适配修复任务的采样过程而无需重新训练。具体而言，给定图像和标签掩码对，我们裁剪前景标签区域，并在每个噪声级别的反向去噪过程中以其为条件。掩码背景区域将逐渐被填充，所有生成的图像均与标签掩码配对。这种方法确保了合成图像与标签掩码的匹配准确性，使其区别于现有数据集生成方法。生成的图像为训练下游分割模型提供了有价值的监督，有效解决了标注稀缺问题。我们在四个公共医学图像分割数据集（包括CT、MRI和皮肤成像）上对AugPaint进行了广泛评估。结果表明，AugPaint在所有数据集上均优于现有标签高效方法，显著提升了分割性能。

</details>


### [154] [From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting](https://arxiv.org/abs/2506.23042)
**中文标题：从粗到细：用于高效3D高斯泼溅的可学习离散小波变换**

*Hung Nguyen,An Le,Runfa Li,Truong Nguyen*

主要分类: cs.CV

摘要简述: 本文提出AutoOpti3DGS框架，通过可学习的离散小波变换抑制3D高斯泼溅中的冗余高斯基元，从而在保持视觉保真度的同时减少内存和带宽压力。


<details>
  <summary>详细信息</summary>
研究动机: 3D高斯泼溅在新型视图合成中表现出色，但其不断增长的高斯基元集对内存和带宽造成压力。本文旨在通过自动优化框架解决这一问题，同时保持视觉质量。

研究方法: 提出AutoOpti3DGS框架，采用可学习的离散小波变换，固定低通滤波器，学习高通滤波器，并通过辅助正交性损失逐步激活高频细节，实现从粗到细的优化过程。

研究结果: 实验表明，AutoOpti3DGS仅需一个滤波器学习率超参数，与现有高效3DGS框架无缝集成，并能生成更稀疏的场景表示，更适合内存或存储受限的硬件。

研究结论: AutoOpti3DGS通过小波驱动的粗到细优化，有效抑制冗余高斯基元，为3D高斯泼溅提供了更高效的解决方案。

中文摘要: 3D高斯泼溅已成为新型视图合成中的强大方法，具有快速训练和渲染能力，但其不断增长的高斯基元集对内存和带宽造成压力。我们提出AutoOpti3DGS，一种训练时框架，可在不牺牲视觉保真度的情况下自动抑制高斯基元的扩散。其核心思想是将输入图像输入一系列可学习的正向和逆向离散小波变换，其中低通滤波器固定，高通滤波器可学习并初始化为零，辅助正交性损失逐步激活高频细节。这种小波驱动的从粗到细过程延迟了冗余精细高斯基元的形成，使3DGS能够先捕捉全局结构，仅在必要时细化细节。通过大量实验，AutoOpti3DGS仅需一个滤波器学习率超参数，与现有高效3DGS框架无缝集成，并能持续生成更稀疏的场景表示，更适合内存或存储受限的硬件。

</details>


### [155] [Ovis-U1 Technical Report](https://arxiv.org/abs/2506.23044)
**中文标题：Ovis-U1技术报告**

*Guo-Hua Wang,Shanshan Zhao,Xinjie Zhang,Liangfu Cao,Pengxin Zhan,Lunhao Duan,Shiyin Lu,Minghao Fu,Xiaohao Chen,Jianshan Zhao,Yang Li,Qing-Guo Chen*

主要分类: cs.CV

摘要简述: Ovis-U1是一个30亿参数的多模态统一模型，整合了多模态理解、文本到图像生成和图像编辑功能，性能超越当前先进模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态模型在理解和生成任务上通常分开训练，限制了性能。Ovis-U1旨在通过统一训练方法提升多模态任务的综合能力。

研究方法: Ovis-U1基于扩散视觉解码器和双向令牌优化器，从语言模型出发进行统一训练，整合理解和生成任务。

研究结果: 在OpenCompass多模态学术基准中得分69.6，超越Ristretto-3B和SAIL-VL-1.5-2B；文本到图像生成和图像编辑任务中表现优异。

研究结论: Ovis-U1作为统一模型系列的首个版本，在多模态理解、生成和编辑任务中展现了显著优势，为未来研究奠定了基础。

中文摘要: 本报告介绍了Ovis-U1，一个30亿参数的统一模型，整合了多模态理解、文本到图像生成和图像编辑功能。基于Ovis系列的基础，Ovis-U1采用扩散视觉解码器和双向令牌优化器，实现了与GPT-4o等领先模型相当的图像生成能力。与以往使用冻结MLLM的模型不同，Ovis-U1从语言模型出发，采用新的统一训练方法。相比仅针对理解或生成任务的训练，统一训练显著提升了性能。Ovis-U1在OpenCompass多模态学术基准中得分69.6，超越了Ristretto-3B和SAIL-VL-1.5-2B等最新模型。在文本到图像生成任务中，其在DPG-Bench和GenEval基准上的得分分别为83.72和0.89。在图像编辑任务中，其在ImgEdit-Bench和GEdit-Bench-EN上的得分分别为4.00和6.42。作为Ovis统一模型系列的首个版本，Ovis-U1在多模态理解、生成和编辑领域取得了突破性进展。

</details>


### [156] [Empowering Small VLMs to Think with Dynamic Memorization and Exploration](https://arxiv.org/abs/2506.23061)
**中文标题：通过动态记忆与探索赋能小型视觉语言模型思考**

*Jiazhen Liu,Yuchuan Deng,Long Chen*

主要分类: cs.CV

摘要简述: 本文提出DyME训练范式，动态选择记忆（通过SFT）和探索（通过RLVR）模式，以提升小型视觉语言模型的思考能力，实验证明其显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 小型视觉语言模型（SVLMs）由于参数容量有限和指令跟随能力弱，难以实现可靠的思考能力。现有训练范式（如SFT和RLVR）对模型要求过高，直接应用于SVLMs会导致伪思考痕迹和优势崩溃，影响性能和可靠性。

研究方法: 提出DyME训练范式，动态选择记忆（SFT）和探索（RLVR）模式，确保每次优化步骤都能平衡两者，从而减少对模型容量的依赖。

研究结果: 多领域实验表明，DyME能有效平衡记忆与探索，显著提升SVLMs的思考可靠性和任务性能。

研究结论: DyME是一种实用且有效的解决方案，能够为小型视觉语言模型赋予可靠的思考能力。

中文摘要: 由于参数容量有限和指令跟随能力弱，小型视觉语言模型（SVLMs）难以实现可靠的思考能力。现有训练范式（如监督微调SFT和可验证奖励强化学习RLVR）对基础模型要求过高，超出SVLMs的能力范围，直接应用会导致伪思考痕迹和优势崩溃，损害思考可靠性和任务性能。一种自然的解决方案是结合SFT和RLVR，利用其互补性减少对模型容量的依赖。然而，广泛采用的两阶段训练范式在SVLMs上表现仍然不佳，因其倾向于次优收敛，阻碍了平衡并限制了组合的收益。为此，我们提出DyME，一种新颖的训练范式，动态选择记忆（通过SFT）和探索（通过RLVR）模式，确保每次优化步骤都能贡献于平衡。多领域实验表明，DyME能持续实现这一平衡，从而带来显著的性能提升。这些结果证明DyME是一种实用且有效的解决方案，能够为SVLMs赋予可靠的思考能力。GitHub: https://github.com/HKUST-LongGroup/DyME

</details>


### [157] [CoreMark: Toward Robust and Universal Text Watermarking Technique](https://arxiv.org/abs/2506.23066)
**中文标题：CoreMark：面向鲁棒且通用的文本水印技术**

*Jiale Meng,Yiming Li,Zheming Lu,Zewei He,Hao Luo,Tianwei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CoreMark的文本水印技术，通过动态提取字符中的CORE（连续对齐的黑色像素段）并调整其厚度嵌入数据，实现了高鲁棒性、通用性和不可感知性。实验表明，CoreMark在多语言和字体中表现优异，并能抵抗截图、打印扫描和打印相机攻击。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本水印技术在同时实现鲁棒性、通用性和不可感知性方面面临挑战。本文旨在提出一种新的嵌入范式CORE，以解决这些问题，并开发一个适用于多语言和字体的水印框架CoreMark。

研究方法: CoreMark动态提取字符中的CORE，并根据CORE长度选择鲁棒性更强的字符。通过调整CORE的厚度嵌入数据，同时提出一种通用的嵌入强度调节器，根据字体大小自适应增强鲁棒性。

研究结果: 实验表明，CoreMark在多语言和字体中表现出色，显著提升了抵抗截图、打印扫描和打印相机攻击的能力，同时保持了良好的不可感知性。

研究结论: CoreMark通过创新的CORE嵌入范式，实现了高鲁棒性和通用性，为文本水印技术提供了新的解决方案。

中文摘要: 近年来，文本水印方案受到了广泛关注，但在同时实现鲁棒性、通用性和不可感知性方面仍面临关键挑战。本文提出了一种新的嵌入范式CORE，由多个连续对齐的黑色像素段组成，其关键创新在于传输过程中的固有抗噪性以及对多语言和字体的广泛适用性。基于CORE，我们提出了一个名为CoreMark的文本水印框架。具体而言，CoreMark首先动态地从字符中提取CORE，然后根据CORE的长度选择鲁棒性更强的字符。通过调整CORE的厚度，将隐藏数据嵌入到选定的字符中，而不会引起显著的视觉失真。此外，还提出了一种通用的即插即用嵌入强度调节器，能够根据字体大小自适应地增强小字体下的鲁棒性。实验评估表明，CoreMark在多语言和字体中表现出卓越的通用性。与现有方法相比，CoreMark在抵抗截图、打印扫描和打印相机攻击方面取得了显著改进，同时保持了令人满意的不可感知性。

</details>


### [158] [Unsupervised 3D Braided Hair Reconstruction from a Single-View Image](https://arxiv.org/abs/2506.23072)
**中文标题：基于单视角图像的无监督3D辫发重建**

*Jing Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种无监督的3D辫发重建方法，通过单视角RGB图像高效重建复杂的辫发结构，优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于发丝的重建方法主要针对松散发型，难以捕捉辫发的精细几何结构，因此需要一种新方法来高效重建3D辫发。

研究方法: 利用受辫发理论启发的合成辫发模型，提出了一种无监督的管道，从单视角RGB图像中捕捉辫发的复杂交织结构。

研究结果: 实验表明，该方法在3D辫发重建中优于现有技术，提供了更高的准确性、真实性和效率，支持数字人中的发型建模。

研究结论: 该方法为3D辫发重建提供了一种高效且准确的解决方案，推动了数字人发型建模的发展。

中文摘要: 从单视角图像重建3D辫发发型仍然是一项具有挑战性的任务，这是由于辫发的复杂交织结构和拓扑。现有的基于发丝的重建方法通常专注于松散发型，难以捕捉辫发的精细几何结构。本文提出了一种新颖的无监督管道，用于从单视角RGB图像高效重建3D辫发。通过受辫发理论启发的合成辫发模型，我们的方法有效地捕捉了辫发的复杂交织结构。大量实验表明，我们的方法在3D辫发重建中优于现有技术，提供了更高的准确性、真实性和效率，支持数字人中的发型建模。

</details>


### [159] [Learning Counterfactually Decoupled Attention for Open-World Model Attribution](https://arxiv.org/abs/2506.23074)
**中文标题：学习反事实解耦注意力用于开放世界模型溯源**

*Yu Zheng,Boyang Gong,Fanye Kong,Yueqi Duan,Bingyao Yu,Wenzhao Zheng,Lei Chen,Jiwen Lu,Jie Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种反事实解耦注意力学习方法（CDAL），用于开放世界模型溯源。该方法通过建模注意力视觉痕迹与源模型溯源的因果关系，解耦模型特异性伪影与混淆源偏差，显著提升对未见攻击的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖手工设计的区域划分或特征空间，易受虚假统计相关性干扰，且在开放世界场景中难以应对新型攻击。本文旨在通过反事实解耦注意力学习，解决这些问题。

研究方法: CDAL方法显式建模注意力视觉痕迹与源模型溯源的因果关系，并通过反事实解耦将模型特异性伪影与混淆源偏差分离，以最大化因果效应，从而学习泛化性强的生成模式。

研究结果: 在现有开放世界模型溯源基准测试中，CDAL以最小计算开销显著提升现有最优模型性能，尤其对未见的新型攻击表现突出。

研究结论: CDAL通过反事实解耦注意力学习，有效提升了模型溯源的泛化能力，尤其在开放世界场景中表现优异。

中文摘要: 本文提出了一种反事实解耦注意力学习（CDAL）方法，用于开放世界模型溯源。现有方法依赖手工设计的区域划分或特征空间，易受虚假统计相关性干扰，且在开放世界场景中难以应对新型攻击。为解决这一问题，CDAL显式建模注意力视觉痕迹与源模型溯源的因果关系，并通过反事实解耦将模型特异性伪影与混淆源偏差分离以进行比较。由此产生的因果效应量化了学习注意力图的质量，从而鼓励网络通过最大化效应捕获泛化性强的生成模式。在现有开放世界模型溯源基准测试上的大量实验表明，CDAL以最小计算开销显著提升了现有最优模型性能，尤其对未见的新型攻击表现突出。源代码：https://github.com/yzheng97/CDAL。

</details>


### [160] [Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization](https://arxiv.org/abs/2506.23077)
**中文标题：动态对比学习在分层检索中的应用：以距离感知跨视角地理定位为例**

*Suofei Zhang,Xinxin Wang,Xiaofu Wu,Quan Zhou,Haifeng Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种动态对比学习框架（DyCL），用于解决距离感知的跨视角地理定位问题，通过分层检索和多尺度特征对齐显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的跨视角地理定位方法主要关注跨域图像匹配的准确性，而忽略了目标周围上下文信息的全面捕获和定位误差的最小化。为此，本文构建了首个包含多视角图像和精确距离标注的基准数据集DA-Campus，并将问题重新定义为分层检索任务。

研究方法: 本文提出动态对比学习（DyCL）框架，通过分层空间边界的渐进式特征对齐，解决跨视角地理定位中的复杂空间关系问题。DyCL与现有的多尺度度量学习方法高度互补。

研究结果: 实验表明，DyCL在分层检索性能和跨视角地理定位准确性上均取得了显著提升，验证了其有效性。

研究结论: DyCL为解决距离感知的跨视角地理定位问题提供了新思路，其分层检索和动态对比学习方法为相关领域的研究奠定了基础。

中文摘要: 现有的基于深度学习的跨视角地理定位方法主要关注跨域图像匹配的准确性，而未能全面捕获目标周围的上下文信息或最小化定位误差的成本。为了系统研究距离感知跨视角地理定位（DACVGL）问题，我们构建了首个多视角图像与精确距离标注配对的基准数据集DA-Campus，覆盖三种空间分辨率。基于DA-Campus，我们将DACVGL问题重新定义为跨域分层检索任务。研究进一步表明，由于建筑物间空间关系的复杂性，这一问题只能通过对比学习范式而非传统度量学习解决。为此，我们提出了动态对比学习（DyCL），一种根据分层空间边界渐进对齐特征表示的新框架。大量实验证明，DyCL与现有多尺度度量学习方法高度互补，在分层检索性能和整体跨视角地理定位准确性上均取得了显著提升。我们的代码和基准数据集已公开于https://github.com/anocodetest1/DyCL。

</details>


### [161] [Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation](https://arxiv.org/abs/2506.23086)
**中文标题：频率增强的多粒度上下文网络用于高效脊椎分割**

*Jian Shi,Tianqi You,Pingping Zhang,Hongli Zhang,Rui Xu,Haojie Li*

主要分类: cs.CV

摘要简述: 本文提出了一种频率增强的多粒度上下文网络（FMC-Net），通过小波变换和无损下采样减少模糊图像中的特征失真，结合高频特征精炼和多粒度状态空间模型，显著提升了脊椎分割的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 由于当前成像技术的局限性和脊柱结构的复杂性，现有方法在减少图像模糊影响和区分相似脊椎方面仍存在困难。本文旨在解决这些问题，提升脊椎分割的准确性。

研究方法: 首先使用小波变换进行无损下采样以减少模糊图像中的特征失真；对分解后的高频和低频分量分别处理：高频分量通过高频特征精炼（HFR）增强关键特征并过滤噪声，低频分量通过多粒度状态空间模型（MG-SSM）聚合不同感受野的特征表示，同时以线性复杂度捕获长程依赖关系。

研究结果: 实验表明，FMC-Net在CT和MRI脊椎分割数据集上均优于现有方法，显著提升了分割准确性。

研究结论: FMC-Net通过频率增强和多粒度上下文处理，有效解决了脊椎分割中的模糊和相似性问题，为临床应用提供了更准确的自动化分割工具。

中文摘要: 自动且准确地分割3D CT和MRI图像中的单个脊椎对多种临床应用至关重要。由于当前成像技术的局限性和脊柱结构的复杂性，现有方法在减少图像模糊影响和区分相似脊椎方面仍存在困难。为解决这些问题，我们提出了一种频率增强的多粒度上下文网络（FMC-Net）。具体而言，我们首先应用小波变换进行无损下采样以减少模糊图像中的特征失真。分解后的高频和低频分量分别处理：高频分量通过高频特征精炼（HFR）增强关键特征并过滤噪声，恢复模糊图像中的细粒度细节；低频分量通过多粒度状态空间模型（MG-SSM）聚合不同感受野的特征表示，同时以线性复杂度捕获长程依赖关系。多粒度上下文的利用对区分相似脊椎和提升分割准确性至关重要。大量实验表明，我们的方法在CT和MRI脊椎分割数据集上均优于现有方法。源代码已公开于https://github.com/anaanaa/FMCNet。

</details>


### [162] [Where, What, Why: Towards Explainable Driver Attention Prediction](https://arxiv.org/abs/2506.23088)
**中文标题：何处、何物、为何：迈向可解释的驾驶员注意力预测**

*Yuchen Zhou,Jiayu Tang,Xiaoyan Xiao,Yueyao Lin,Linkai Liu,Zipeng Guo,Hao Fei,Xiaobo Xia,Chao Gou*

主要分类: cs.CV

摘要简述: 本文提出了一种可解释的驾驶员注意力预测任务范式W3DA，结合空间注意力区域预测（哪里）、语义解析（什么）和认知推理（为什么），并提出了基于大语言模型的框架LLada，实现了端到端的注意力预测。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法仅预测驾驶员的空间注意力热图，未能捕捉注意力分配的认知动机，限制了对其机制的深入理解。本文旨在填补这一空白，提出可解释的驾驶员注意力预测任务。

研究方法: 提出W3DA数据集，包含丰富语义和因果标注；设计LLada框架，结合像素建模、语义解析和认知推理，实现端到端的注意力预测。

研究结果: 实验证明LLada具有鲁棒的泛化能力，适用于多种数据集和驾驶场景，为理解驾驶员注意力机制提供了重要工具。

研究结论: 本文为深入理解驾驶员注意力机制迈出关键一步，对自动驾驶、智能驾驶员培训和人类-计算机交互具有重要意义。

中文摘要: 驾驶中任务驱动的注意力建模是自动驾驶和认知科学的基础挑战。现有方法主要通过生成空间热图预测驾驶员注视位置，但未能捕捉特定情境下注意力分配的认知动机，限制了对其机制的深入理解。为填补这一空白，我们提出可解释的驾驶员注意力预测任务范式，联合预测空间注意力区域（何处）、解析注视语义（何物）并提供注意力分配的认知推理（为何）。为此，我们推出W3DA，首个大规模可解释驾驶员注意力数据集，丰富了现有基准，涵盖多种驾驶场景的详细语义和因果标注，包括正常条件、安全关键情境和交通事故。我们进一步提出LLada，一种基于大语言模型的驾驶员注意力预测框架，将像素建模、语义解析和认知推理统一于端到端架构中。大量实验证明LLada的有效性，展示了跨数据集和驾驶条件的鲁棒泛化能力。这项工作为深入理解驾驶员注意力机制迈出关键一步，对自动驾驶、智能驾驶员培训和人类-计算机交互具有重要影响。

</details>


### [163] [DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation](https://arxiv.org/abs/2506.23104)
**中文标题：DC-TTA：基于分而治之策略的交互式分割测试时适应框架**

*Jihun Kim,Hoyong Kwon,Hyeokjun Kweon,Wooseong Jeong,Kuk-Jin Yoon*

主要分类: cs.CV

摘要简述: DC-TTA是一种新颖的测试时适应框架，通过分而治之策略优化交互式分割模型SAM，利用用户交互作为监督，显著提升复杂场景下的分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管SAM在交互式分割中表现出色，但在专业领域或复杂场景（如伪装或多部分对象）中表现不佳。DC-TTA旨在通过测试时适应解决这一问题，利用用户交互提升模型性能。

研究方法: DC-TTA将用户点击划分为更一致的子集，每个子集通过独立的测试时适应模型处理，减少冲突并实现局部更新。最终合并各子集模型，形成统一预测器。

研究结果: 实验表明，DC-TTA显著优于SAM的零样本结果和传统测试时适应方法，在复杂任务（如伪装对象分割）中交互次数更少且准确性更高。

研究结论: DC-TTA通过分而治之策略有效提升了交互式分割在复杂场景中的性能，为模型适应提供了新思路。

中文摘要: 交互式分割（IS）允许用户通过简单的正负点击迭代优化对象边界。尽管Segment Anything Model（SAM）因其可提示的分割能力在IS社区受到关注，但在专业领域或复杂场景（如伪装或多部分对象）中表现不佳。为解决这一问题，我们提出DC-TTA，一种新颖的测试时适应（TTA）框架，通过利用用户交互作为监督，对SAM进行逐样本适应。DC-TTA不强制单一模型一次性整合所有用户点击，而是将点击划分为更一致的子集，每个子集通过独立的TTA模型处理。这种分而治之策略减少了多样线索间的冲突，并实现了更局部的更新。最终，合并适应后的模型形成统一预测器，整合各子集的专门知识。多基准测试结果表明，DC-TTA显著优于SAM的零样本结果和传统TTA方法，能以更少的交互次数和更高的准确性处理复杂任务（如伪装对象分割）。

</details>


### [164] [Computer-Aided Multi-Stroke Character Simplification by Stroke Removal](https://arxiv.org/abs/2506.23106)
**中文标题：通过笔画移除实现计算机辅助的多笔画汉字简化**

*Ryo Ishiyama,Shinnosuke Matsuo,Seiichi Uchida*

主要分类: cs.CV

摘要简述: 本文提出了一种通过选择性移除笔画来简化多笔画汉字的方法，旨在降低非母语学习者的学习难度，同时保持字符的可读性。实验表明，即使移除多个笔画，许多字符仍可辨识。


<details>
  <summary>详细信息</summary>
研究动机: 多笔画汉字（如中文和日文）的复杂性对非母语学习者构成挑战。简化这些字符而不损害其可读性，可以降低学习难度，优化字体设计，并提升字符通信系统的效率。

研究方法: 本文提出了一种框架，通过高精度字符识别模型评估可读性，并选择性移除对可读性影响最小的笔画，从而简化多笔画汉字。

研究结果: 实验对1,256个字符类别（笔画数为5、10、15和20）进行了测试，发现即使移除多个笔画，许多字符仍能保持可辨识性。

研究结论: 研究结果表明，通过系统化的笔画移除策略，可以简化多笔画汉字而不显著影响其可读性，为未来的简化方案提供了潜在方向。

中文摘要: 中文和日文等多笔画字符的复杂性对母语者和非母语学习者均构成挑战。若能简化这些字符而不损害其可读性，将降低非母语学习者的学习难度，优化字体设计，并提升字符通信系统的效率。本文提出了一种框架，通过选择性移除笔画来系统化地简化多笔画字符，同时保持其整体可读性。具体而言，我们使用高精度字符识别模型评估可读性，并移除对可读性影响最小的笔画。对1,256个字符类别（笔画数为5、10、15和20）的实验结果表明，即使移除多个笔画，许多字符仍可辨识。这些发现为更正式的简化策略提供了潜在可能。

</details>


### [165] [Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound](https://arxiv.org/abs/2506.23108)
**中文标题：基于语料库-视图-类别优化的颈动脉斑块超声风险分级方法**

*Zhiyuan Zhu,Jian Wang,Yong Jiang,Tong Han,Yuhao Huang,Ang Zhang,Kaiwen Yang,Mingyuan Luo,Zhe Liu,Yaofei Duan,Dong Ni,Tianhong Tang,Xin Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的Corpus-View-Category Refinement Framework (CVC-RF)，用于提升颈动脉斑块风险分级（CPG）的准确性。该框架通过多级优化（语料库、视图和类别层面）增强模型性能，并引入中心记忆对比损失、级联下采样注意力模块和无参数专家混合权重策略，实现了在CPG任务中的最先进表现。


<details>
  <summary>详细信息</summary>
研究动机: 颈动脉斑块分级（CPG）对评估心脑血管疾病风险至关重要，但由于斑块尺寸小且类内差异大，临床中通常需要结合横断面和纵向超声视图进行评估。现有深度学习方法多关注多视图特征融合，忽略了表征学习和类别特征的差异，因此需要一种更全面的方法来解决这些问题。

研究方法: 本文提出的CVC-RF框架包含三个层面的优化：1）语料库层面，引入中心记忆对比损失，增强全局建模能力；2）视图层面，设计级联下采样注意力模块，融合多尺度信息并实现隐式特征交互；3）类别层面，采用无参数专家混合权重策略，利用类别聚类知识对不同专家进行加权，实现特征解耦。

研究结果: 实验结果表明，CVC-RF通过多级优化有效建模全局特征，在CPG任务中达到了最先进的性能。

研究结论: CVC-RF通过语料库、视图和类别层面的多级优化，显著提升了颈动脉斑块分级的准确性，为临床实践提供了更可靠的辅助工具。

中文摘要: 准确的颈动脉斑块分级（CPG）对评估心脑血管疾病风险至关重要。由于斑块尺寸小且类内差异大，临床中通常需要结合横断面和纵向超声视图进行评估。然而，现有的基于深度学习的多视图分类方法多关注不同视图的特征融合，忽略了表征学习和类别特征差异的重要性。为解决这些问题，我们提出了一种新型的语料库-视图-类别优化框架（CVC-RF），从语料库、视图和类别三个层面处理信息，提升模型性能。我们的贡献包括：1）首次基于最新Carotid Plaque-RADS指南提出深度学习CPG方法；2）提出中心记忆对比损失，通过比较代表性聚类中心和多样化负样本增强全局建模能力；3）设计级联下采样注意力模块，融合多尺度信息并实现视图层面的隐式特征交互；4）引入无参数专家混合权重策略，利用类别聚类知识加权不同专家，实现类别层面的特征解耦。实验结果表明，CVC-RF通过多级优化有效建模全局特征，在CPG任务中达到了最先进的性能。

</details>


### [166] [MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings](https://arxiv.org/abs/2506.23115)
**中文标题：MoCa：模态感知持续预训练提升双向多模态嵌入性能**

*Haonan Chen,Hong Liu,Yuping Luo,Liang Wang,Nan Yang,Furu Wei,Zhicheng Dou*

主要分类: cs.CV

摘要简述: 本文提出MoCa框架，通过两阶段训练（模态感知持续预训练和异构对比微调）改进双向多模态嵌入模型，解决现有方法的局限性，并在多个基准测试中取得最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态嵌入模型存在三个主要问题：因果注意力机制不适用于嵌入任务、依赖高质量标注数据导致扩展性差、训练目标和数据多样性不足。MoCa旨在通过改进预训练和微调方法解决这些问题。

研究方法: MoCa分为两阶段：1）模态感知持续预训练，通过联合重建目标增强双向上下文推理；2）异构对比微调，利用多样化多模态数据提升泛化和对齐能力。

研究结果: 实验表明，MoCa在MMEB和ViDoRe-v2基准测试中表现优异，达到新最优水平，并在模型规模和训练数据上展现出强扩展性。

研究结论: MoCa通过引入双向注意力和多样化数据，显著提升多模态嵌入模型的性能，为未来研究提供了有效框架。

中文摘要: 多模态嵌入模型基于因果视觉语言模型（VLM）构建，已在多种任务中展现出潜力。然而，当前方法存在三个关键局限：VLM骨干中的因果注意力机制对嵌入任务不理想；依赖高质量标注配对数据进行对比学习导致扩展性差；训练目标和数据多样性不足。为解决这些问题，我们提出MoCa，一个两阶段框架，将预训练的VLM转化为高效的双向多模态嵌入模型。第一阶段为模态感知持续预训练，通过联合重建目标同时去噪交错文本和图像输入，增强双向上下文感知推理。第二阶段为异构对比微调，利用超越简单图像-标题对的多样化、语义丰富的多模态数据提升泛化和对齐能力。我们的方法通过持续预训练引入双向注意力，借助联合重建目标高效扩展至海量未标注数据，并利用多样化多模态数据增强表示鲁棒性。实验表明，MoCa在MMEB和ViDoRe-v2基准测试中持续提升性能，达到新最优水平，并在MMEB上展现出模型规模和训练数据的强扩展性。

</details>


### [167] [Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation](https://arxiv.org/abs/2506.23120)
**中文标题：通过基于推理的分割增强多模态大语言模型的空间推理能力**

*Zhenhua Ning,Zhuotao Tian,Shaoshuai Shi,Guangming Lu,Daojing He,Wenjie Pei,Li Jiang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于推理的分割框架R²S和数据集3D ReasonSeg，旨在增强多模态大语言模型的空间推理能力。通过模拟人类认知过程，将空间推理分为两个阶段，并引入新数据集进行验证，实验证明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在处理需要精确空间推理的复杂指令时存在不足，尽管3D点云数据提供了详细的空间线索。本文旨在通过模拟人类认知过程，提升多模态大语言模型的空间推理能力。

研究方法: 提出Relevant Reasoning Segmentation (R²S)框架，将空间推理分为两个阶段：先识别相关元素，再基于视觉先验处理指令。同时，引入3D ReasonSeg数据集，包含25,185个训练样本和3,966个验证样本。

研究结果: 定量和定性实验表明，R²S和3D ReasonSeg显著提升了3D点云感知的空间推理能力，可作为未来研究的新基准。

研究结论: R²S和3D ReasonSeg为多模态大语言模型的空间推理提供了有效解决方案，并有望成为未来研究的基准。

中文摘要: 近年来，点云感知领域通过结合视觉-语言对齐和大语言模型（LLMs）在场景理解方面取得了显著进展。然而，现有方法在处理需要精确空间推理的复杂指令时仍面临挑战，尽管3D点云数据提供了目标的大小和位置等详细空间线索。为解决这一问题，我们提出了基于推理的分割框架Relevant Reasoning Segmentation (R²S)。该框架模拟人类认知过程，将空间推理分为两个连续阶段：首先识别相关元素，然后在视觉先验的指导下处理指令。此外，由于现有数据集在复杂推理任务中的不足，我们引入了3D ReasonSeg数据集，包含25,185个训练样本和3,966个验证样本，并带有精确标注。定量和定性实验表明，R²S和3D ReasonSeg有效增强了3D点云感知的空间推理能力，我们期望它们能成为未来研究的新基准。

</details>


### [168] [Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval](https://arxiv.org/abs/2506.23132)
**中文标题：敢于抄袭？抄袭绘画的识别与检索**

*Sophie Zhou,Shu Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种识别抄袭绘画并检索相似原创作品的方法，通过生成AI构建数据集，使用DINOv2模型进行检索和分类，优化后检索性能显著提升但识别准确率略有下降。


<details>
  <summary>详细信息</summary>
研究动机: 艺术抄袭检测对保护艺术家版权至关重要，但现有方法在法医分析中仍具挑战性。本文旨在通过识别抄袭绘画并检索相似原创作品，为艺术版权保护提供技术支持。

研究方法: 1. 构建数据集：收集绘画照片并使用生成AI合成抄袭版本；2. 使用DINOv2模型提取特征，基于相似度阈值分类抄袭；3. 通过度量学习损失微调DINOv2，优化检索性能。

研究结果: 基线方法识别准确率达97.2%，但检索精度仅29.0% AP；微调后检索性能提升12% AP，但识别准确率降至92.7%。

研究结论: 本文展示了DINOv2在艺术抄袭检测中的潜力，优化检索性能的同时需权衡识别准确率，未来研究可进一步探索平衡两者的方法。

中文摘要: 艺术抄袭检测在保护艺术家版权和知识产权中至关重要，但在法医分析中仍是一个具有挑战性的问题。本文通过识别抄袭绘画并检索视觉上相似的原创作品来解释检测到的抄袭行为。为支持研究，我们通过收集绘画照片并使用生成AI合成特定艺术家风格的抄袭版本构建数据集。首先，我们基于视觉基础模型DINOv2的现成特征建立基线方法，检索数据库中相似图像并根据相似度阈值分类抄袭。出乎意料的是，这种非学习方法实现了97.2%的高识别准确率，但检索精度较低（平均精度29.0% AP）。为提高检索质量，我们使用度量学习损失对DINOv2进行微调，通过从数据库中采样的正负样本对优化模型。微调后模型检索性能显著提升12% AP，但识别准确率意外降至92.7%。最后，我们进行了深入讨论并展望了未来研究方向。

</details>


### [169] [RoboScape: Physics-informed Embodied World Model](https://arxiv.org/abs/2506.23135)
**中文标题：RoboScape：物理信息化的具身世界模型**

*Yu Shang,Xin Zhang,Yinzhou Tang,Lei Jin,Chen Gao,Wei Wu,Yong Li*

主要分类: cs.CV

摘要简述: RoboScape提出了一种物理信息化的世界模型，通过联合学习RGB视频生成和物理知识，显著提升了视频生成的视觉保真度和物理合理性。


<details>
  <summary>详细信息</summary>
研究动机: 当前的世界模型在物理感知方面存在局限，尤其是在3D几何和运动动力学建模上表现不足，导致接触密集型机器人场景的视频生成不真实。RoboScape旨在通过物理信息化的方法解决这一问题。

研究方法: RoboScape采用统一的物理信息化世界模型框架，结合了时间深度预测和关键点动态学习两项任务，分别增强视频渲染的3D几何一致性和复杂运动建模的物理属性编码。

研究结果: 实验表明，RoboScape在多种机器人场景中生成的视频具有更高的视觉保真度和物理合理性，并在机器人策略训练和评估等下游应用中验证了其实用性。

研究结论: RoboScape为构建高效的物理信息化世界模型提供了新思路，推动了具身智能研究的进展。

中文摘要: 世界模型已成为具身智能不可或缺的工具，作为强大的模拟器能够生成逼真的机器人视频，同时解决关键的数据稀缺问题。然而，当前的具身世界模型在物理感知方面表现有限，尤其是在3D几何和运动动力学建模上，导致接触密集型机器人场景的视频生成不真实。本文提出了RoboScape，一种统一的物理信息化世界模型，通过集成框架联合学习RGB视频生成和物理知识。我们引入了两项关键的物理信息化联合训练任务：时间深度预测，用于增强视频渲染的3D几何一致性；以及关键点动态学习，用于隐式编码物理属性（如物体形状和材料特性）并改进复杂运动建模。大量实验表明，RoboScape在多种机器人场景中生成的视频具有更高的视觉保真度和物理合理性。我们进一步通过下游应用（包括生成数据的机器人策略训练和策略评估）验证了其实用性。本研究为构建高效的物理信息化世界模型以推动具身智能研究提供了新的见解。代码发布于：https://github.com/tsinghua-fib-lab/RoboScape。

</details>


### [170] [VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis](https://arxiv.org/abs/2506.23138)
**中文标题：VisualPrompter：基于视觉反馈的文本到图像合成提示优化**

*Shiyu Wu,Mingzhen Sun,Weining Wang,Yequan Wang,Jing Liu*

主要分类: cs.CV

摘要简述: 本文提出VisualPrompter，一种无需训练的提示优化框架，通过视觉反馈改进用户输入，提升文本到图像生成的语义对齐和视觉效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到图像提示工程方法虽能提升生成图像的美学效果，但常忽略语义对齐，导致图像内容与用户描述不符。本文旨在解决这一问题。

研究方法: VisualPrompter包含自动自省模块识别生成图像中缺失概念，以及目标特定提示优化机制细粒度修订提示，无需额外训练。

研究结果: 实验表明，VisualPrompter在多个文本图像对齐评测基准上达到最新最优性能，且具备即插即用设计，适配多种生成模型。

研究结论: VisualPrompter通过视觉反馈优化提示，显著提升文本到图像生成的语义对齐和用户满意度，具有广泛适用性。

中文摘要: 由于用户提供的提示与模型偏好的提示之间存在显著差距，使用扩散模型生成高质量且令人满意的图像通常需要提示工程来优化用户输入。当前关于文本到图像提示工程的研究虽能有效提升生成图像的风格和美学效果，但往往忽略了生成图像与用户描述之间的语义对齐，导致图像视觉上吸引人但内容上不尽如人意。本文提出VisualPrompter，一种无需训练的新型提示工程框架，通过细化用户输入为模型偏好的句子。具体而言，VisualPrompter利用自动自省模块识别生成图像中缺失的概念，并通过目标特定提示优化机制细粒度修订提示。大量实验证明了VisualPrompter的有效性，其在多个文本图像对齐评测基准上达到了最新最优性能。此外，该框架采用即插即用设计，使其高度适配多种生成模型。

</details>


### [171] [AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation](https://arxiv.org/abs/2506.23150)
**中文标题：AlignCVC：通过跨视图一致性对齐实现单图到3D生成**

*Xinyue Liang,Zhiyuan Ma,Lingchen Sun,Yanjun Guo,Lei Zhang*

主要分类: cs.CV

摘要简述: AlignCVC通过分布对齐而非严格回归损失，提升单图到3D生成中的跨视图一致性，显著提高生成质量和推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有单图到3D生成方法中，中间生成的多视图图像缺乏跨视图一致性（CVC），导致3D重建性能下降。传统方法通过反馈重建结果改进CVC，但受限于噪声和不稳定的输出。

研究方法: AlignCVC提出一种分布对齐框架，将生成和重建的多视图分布对齐到真实多视图分布。采用软硬对齐策略，分别优化生成和重建模型，提升CVC并加速推理至4步。

研究结果: 实验表明，AlignCVC显著提升单图到3D生成的跨视图一致性和生成质量，同时大幅加速推理过程。

研究结论: AlignCVC为单图到3D生成提供了一种高效且可扩展的解决方案，通过分布对齐实现跨视图一致性的显著改进。

中文摘要: 单图到3D模型通常遵循顺序生成和重建的工作流程。然而，预训练生成模型合成的中间多视图图像往往缺乏跨视图一致性（CVC），显著降低了3D重建性能。尽管近期方法尝试通过将重建结果反馈给多视图生成器来改进CVC，但这些方法受限于噪声和不稳定的重建输出，难以有效提升CVC。我们提出AlignCVC，一种新颖的框架，通过分布对齐而非严格的回归损失重新定义单图到3D生成。我们的核心观点是将生成和重建的多视图分布对齐到真实多视图分布，为改进CVC奠定理论基础。观察到生成图像因显式渲染而表现出弱CVC，而重建图像则具有强CVC，我们提出一种软硬对齐策略，为生成和重建模型设定不同目标。这种方法不仅提升了生成质量，还将推理速度大幅提升至仅需4步。作为一种即插即用的范式，AlignCVC能够无缝集成多种多视图生成模型与3D重建模型。大量实验证明了AlignCVC在单图到3D生成中的高效性和有效性。

</details>


### [172] [MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation](https://arxiv.org/abs/2506.23151)
**中文标题：MEMFOF：面向内存高效多帧光流估计的高分辨率训练方法**

*Vladislav Bargatin,Egor Chistov,Alexander Yakovenko,Dmitriy Vatolin*

主要分类: cs.CV

摘要简述: MEMFOF是一种高效内存的多帧光流估计方法，显著降低GPU内存需求，支持1080p原生分辨率训练，并在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前光流估计方法在追求高精度时，GPU内存消耗急剧增加，尤其是高分辨率输入（如FullHD）。MEMFOF旨在解决这一问题，找到多帧估计与内存使用之间的最佳平衡。

研究方法: MEMFOF重新审视RAFT类架构的设计选择，结合减少的相关体积和高分辨率训练协议，实现多帧光流估计。通过优化内存使用，支持1080p原生分辨率训练。

研究结果: MEMFOF在多个基准测试中表现优异：Spring基准测试1px异常率为3.289%，Sintel（clean）端到端误差为0.963，KITTI-2015的Fl-all误差为2.94%，均排名第一。运行时仅需2.09GB内存，训练时28.5GB。

研究结论: MEMFOF在保持高精度的同时显著降低内存需求，适用于高分辨率光流估计，为实际应用提供了高效且稳健的解决方案。

中文摘要: 近年来，光流估计的进展以高精度为代价，导致GPU内存消耗急剧增加，尤其是高分辨率（FullHD）输入。我们提出MEMFOF，一种内存高效的多帧光流方法，在多帧估计与GPU内存使用之间找到最佳平衡。MEMFOF在运行时仅需2.09GB内存（1080p输入），训练时28.5GB，使其成为唯一支持原生1080p分辨率训练的方法，无需裁剪或降采样。我们系统性地重新审视RAFT类架构的设计选择，结合减少的相关体积和高分辨率训练协议，实现多帧光流估计，在多个基准测试中达到最优性能，同时显著降低内存开销。我们的方法在精度和运行效率上均优于资源密集型方案，验证了其在高分辨率光流估计中的稳健性。提交时，MEMFOF在Spring基准测试中以1px异常率3.289%排名第一，Sintel（clean）端到端误差为0.963，KITTI-2015的Fl-all误差为2.94%，均为最佳。代码发布于https://github.com/msu-video-group/memfof。

</details>


### [173] [Dynamic View Synthesis from Small Camera Motion Videos](https://arxiv.org/abs/2506.23153)
**中文标题：基于小相机运动视频的动态视角合成**

*Huiqiang Sun,Xingyi Li,Juewen Peng,Liao Shen,Zhiguo Cao,Ke Xian,Guosheng Lin*

主要分类: cs.CV

摘要简述: 本文提出了一种基于分布深度正则化（DDR）的方法，解决了小相机运动视频中动态3D场景新视角合成的两大挑战：场景几何错误表示和相机参数估计不准确。通过Gumbel-softmax采样和相机参数学习，显著提升了小运动输入下的场景表示效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于NeRF的动态3D场景新视角合成方法依赖足够的运动视差输入，但在小相机运动或静止场景中表现不佳，主要面临场景几何表示错误和相机参数估计不准确的问题。本文旨在解决这些问题。

研究方法: 1. 提出分布深度正则化（DDR），通过Gumbel-softmax采样计算离散渲染权重分布的误差期望，确保几何正确性；2. 引入空间点体积密度约束，优化场景边界表示；3. 结合相机参数学习，提升模型对相机参数的鲁棒性。

研究结果: 实验表明，本文方法在小相机运动输入下显著优于现有方法，能够准确表示场景几何并优化相机参数估计。

研究结论: 本文通过DDR和相机参数学习，有效解决了小相机运动视频中的动态场景新视角合成问题，为相关领域提供了新的解决方案。

中文摘要: 动态3D场景的新视角合成是一个重要挑战。许多基于NeRF的方法在此任务上取得了显著成果，但这些方法依赖于输入图像或视频中足够的运动视差。当相机运动范围受限或静止时（即小相机运动），现有方法面临两大挑战：场景几何表示错误和相机参数估计不准确。这导致现有方法难以生成满意结果甚至失效。为解决第一个挑战，我们提出了一种基于分布的深度正则化（DDR），确保渲染权重分布与真实分布对齐。具体而言，不同于以往方法使用深度损失计算期望误差，我们通过Gumbel-softmax对离散渲染权重分布进行可微分采样，计算误差的期望。此外，我们引入约束条件，强制光线前物体边界处空间点的体积密度接近零，确保模型学习到正确的场景几何。为揭示DDR的作用，我们进一步提出了一种可视化工具，可在渲染权重层面观察场景几何表示。针对第二个挑战，我们在训练中结合相机参数学习，提升模型对相机参数的鲁棒性。通过大量实验验证了本文方法在小相机运动输入下的有效性，结果优于现有先进方法。

</details>


### [174] [Self-Supervised Contrastive Learning for Multi-Label Images](https://arxiv.org/abs/2506.23156)
**中文标题：多标签图像的自监督对比学习**

*Jiale Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种针对多标签图像的自监督对比学习方法，通过块级增强模块和图像感知对比损失，有效提取语义一致的表示，并在样本质量和数量有限的情况下展现出竞争力。


<details>
  <summary>详细信息</summary>
研究动机: 主流自监督学习方法依赖单标签数据集（如ImageNet），忽略了多标签图像的丰富语义信息和广泛适用性。本文旨在通过改进自监督学习方法，减少多标签图像的预训练开销，同时提升表示学习能力。

研究方法: 1. 提出块级增强模块，从多标签图像中提取更多潜在正视图对；2. 设计图像感知对比损失，建立视图间的联系，提取语义一致的表示。

研究结果: 通过线性微调和迁移学习验证，该方法在样本质量和数量有限的情况下仍具有竞争力。

研究结论: 本文方法在多标签图像的自监督学习中表现出色，为下游任务提供了更丰富的语义表示。

中文摘要: 自监督学习（SSL）通过与人直觉一致的对齐方法证明了其在学习表示方面的有效性。然而，主流SSL方法严重依赖单标签的高质量数据集（如ImageNet），导致预训练开销难以承受。此外，更具通用性的多标签图像在SSL中常被忽视，尽管它们在下游场景中具有更丰富的语义信息和更广泛的适用性。因此，我们改进主流SSL方法，以使用更少的多标签图像保证出色的表示学习能力。首先，我们提出块级增强模块，旨在从多标签图像中提取更多潜在正视图对；随后，设计图像感知对比损失，建立这些视图间的联系，从而促进语义一致表示的提取。全面的线性微调和迁移学习验证了我们的方法在样本质量和数量有限的情况下仍具有竞争力。

</details>


### [175] [STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene](https://arxiv.org/abs/2506.23157)
**中文标题：STD-GS：探索帧-事件交互的时空解耦高斯泼溅以实现高动态场景重建**

*Hanyu Zhou,Haonan Wang,Haoyue Liu,Yuxing Duan,Luxin Yan,Gim Hee Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种时空解耦的高斯泼溅框架（STD-GS），通过结合帧相机和事件相机，解决了高动态场景重建中背景与动态对象时空特征不匹配的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常采用统一的高斯模型直接匹配动态场景的时空特征，但忽略了帧成像导致的动态对象时间特征不连续以及背景与对象空间特征的异质性。因此，本文旨在通过时空解耦和事件相机补偿，提升高动态场景的重建效果。

研究方法: 提出了一种时空解耦的高斯泼溅框架，利用事件相机补充帧相机的数据，并通过聚类区分背景与动态对象的时空特征。动态对象的高斯表示与事件数据具有一致的时空特性，可作为先验指导对象高斯的时空解耦。

研究结果: 实验表明，该方法能够显著提升高动态场景的时空分辨能力，实现时间连续的动态场景渲染。

研究结论: 通过时空解耦和事件相机补偿，STD-GS框架有效解决了高动态场景重建中的时空特征不匹配问题，为动态场景的高质量重建提供了新思路。

中文摘要: 高动态场景重建的目标是通过刚性空间特征表示静态背景，并通过变形的连续时空特征表示动态对象。通常，现有方法采用统一表示模型（如高斯模型）直接从帧相机匹配动态场景的时空特征。然而，这种统一范式由于帧成像导致的动态对象时间特征不连续以及背景与对象空间特征的异质性而失效。为解决这一问题，我们将时空特征解耦为多种潜在表示，以缓解背景与对象之间的时空不匹配。本文引入事件相机以补充帧相机，并提出了一种时空解耦的高斯泼溅框架用于高动态场景重建。对于动态场景，我们发现背景与对象在帧空间特征上存在外观差异，在事件时间特征上存在运动差异，这促使我们通过聚类区分背景与对象的时空特征。对于动态对象，我们发现高斯表示与事件数据具有一致的时空特性，可作为先验指导对象高斯的时空解耦。在高斯泼溅框架内，累积的场景-对象解耦能够提升背景与对象之间的时空分辨能力，从而实现时间连续的动态场景渲染。大量实验验证了所提方法的优越性。

</details>


### [176] [UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding](https://arxiv.org/abs/2506.23219)
**中文标题：UrbanLLaVA：一种具备空间推理与理解能力的多模态大语言模型用于城市智能**

*Jie Feng,Shengyuan Wang,Tianhui Liu,Yanxin Xi,Yong Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为UrbanLLaVA的多模态大语言模型，旨在通过统一框架处理城市研究中的多模态数据，并在多种城市任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前城市研究中的方法通常局限于特定数据类型，缺乏统一的多模态处理框架。多模态大语言模型（MLLMs）的成功为解决这一问题提供了可能。

研究方法: 首先构建了一个涵盖单模态和跨模态城市数据的多样化指令数据集；其次提出了一种多阶段训练框架，将空间推理增强与领域知识学习解耦，以提升模型兼容性和下游任务表现。

研究结果: 实验结果表明，UrbanLLaVA在单模态和复杂跨模态任务中均优于开源和专有MLLMs，并展现出跨城市的强大泛化能力。

研究结论: UrbanLLaVA为城市研究提供了一个高效的多模态处理工具，其开源代码和数据将促进相关研究的进一步发展。

中文摘要: 城市研究涉及多种场景和任务，需要理解多模态数据。现有方法通常专注于特定数据类型，缺乏统一的处理框架。多模态大语言模型（MLLMs）的成功为解决这一问题提供了可能。本文提出了一种名为UrbanLLaVA的多模态大语言模型，旨在同时处理四种数据类型，并在多种城市任务中表现优异。在UrbanLLaVA中，我们首先构建了一个涵盖单模态和跨模态城市数据的多样化指令数据集，覆盖从局部到全局的城市环境视角。此外，我们提出了一种多阶段训练框架，将空间推理增强与领域知识学习解耦，从而提升模型兼容性和下游任务表现。最后，我们还扩展了现有城市研究基准，以评估MLLMs在多种城市任务中的表现。三个城市的实验结果表明，UrbanLLaVA在单模态和复杂跨模态任务中均优于开源和专有MLLMs，并展现出跨城市的强大泛化能力。源代码和数据已通过https://github.com/tsinghua-fib-lab/UrbanLLaVA向研究社区开放。

</details>


### [177] [Trident: Detecting Face Forgeries with Adversarial Triplet Learning](https://arxiv.org/abs/2506.23189)
**中文标题：Trident：基于对抗性三元组学习的人脸伪造检测**

*Mustafa Hakan Kara,Aysegul Dundar,Uğur Güdükbay*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Trident的人脸伪造检测框架，通过对抗性三元组学习和Siamese网络架构，提升了模型对不同伪造方法的适应性，并在多个基准测试中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度神经网络生成的人脸伪造技术日益复杂，检测数字媒体中的人脸篡改变得极具挑战性，亟需维护数字媒体完整性和对抗视觉虚假信息。现有检测模型主要基于特定领域数据的监督训练，难以应对未见过的新伪造技术。

研究方法: Trident框架采用三元组学习和Siamese网络架构，通过精心设计的训练三元组捕捉伪造样本的细微差异，并结合领域对抗训练和伪造判别器，提升模型对未见伪造方法的泛化能力。同时，通过阻止分类器梯度流向嵌入模型，避免过拟合。

研究结果: 在多个基准测试和消融研究中，Trident表现出色，能够有效区分真实样本和伪造样本，并展现出对未知伪造技术的鲁棒性。

研究结论: Trident通过对抗性三元组学习和领域对抗训练，显著提升了人脸伪造检测的泛化能力和鲁棒性，为数字媒体完整性保护提供了有效工具。

中文摘要: 随着深度神经网络生成的人脸伪造技术日益复杂，检测数字媒体中的人脸篡改成为一项重大挑战，凸显了维护数字媒体完整性和对抗视觉虚假信息的重要性。现有的检测模型主要基于特定领域数据的监督训练，往往难以应对未见过的新伪造技术。为此，我们提出了Trident，一种基于三元组学习和Siamese网络架构的人脸伪造检测框架，旨在提升对不同伪造方法的适应性。Trident通过精心设计的训练三元组，捕捉伪造样本的细微差异，同时结合领域对抗训练和伪造判别器，进一步提升模型的泛化能力。此外，我们通过阻止分类器梯度流向嵌入模型，避免因特定伪造技术的伪影导致的过拟合。在多个基准测试和消融研究中，Trident表现出色。我们将代码发布在GitHub仓库中。

</details>


### [178] [DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding](https://arxiv.org/abs/2506.23196)
**中文标题：DEL：用于多模态音视频理解的密集事件定位**

*Mona Ahmadian,Amir Shirian,Frank Guerin,Andrew Gilbert*

主要分类: cs.CV

摘要简述: DEL是一种用于多模态音视频理解的密集事件定位框架，通过音频和视觉特征对齐以及多模态交互细化模块，显著提升了长未剪辑视频中多动作的检测和分类精度。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的视频通常包含重叠事件和复杂的时间依赖关系，这使得多模态交互建模尤为困难。本文旨在通过密集语义动作定位框架DEL，解决这一挑战。

研究方法: DEL框架包含两个关键模块：1）利用掩码自注意力增强模态内一致性的音频和视觉特征对齐模块；2）跨多尺度建模跨模态依赖关系的多模态交互细化模块。

研究结果: DEL在多个真实世界的时间动作定位数据集（UnAV-100、THUMOS14、ActivityNet 1.3和EPIC-Kitchens-100）上实现了最先进的性能，平均mAP分别提升了+3.3%、+2.6%、+1.2%、+1.7%（动词）和+1.4%（名词）。

研究结论: DEL通过有效的多模态特征对齐和交互建模，显著提升了密集事件定位的性能，为多模态音视频理解提供了新的解决方案。

中文摘要: 现实世界中的视频通常包含重叠事件和复杂的时间依赖关系，使得多模态交互建模尤为困难。我们提出了DEL，一种用于密集语义动作定位的框架，旨在准确检测和分类长未剪辑视频中细粒度时间分辨率下的多个动作。DEL包含两个关键模块：利用掩码自注意力增强模态内一致性的音频和视觉特征对齐模块，以及跨多尺度建模跨模态依赖关系的多模态交互细化模块。我们的方法在多个真实世界的时间动作定位数据集（UnAV-100、THUMOS14、ActivityNet 1.3和EPIC-Kitchens-100）上实现了最先进的性能，分别以+3.3%、+2.6%、+1.2%、+1.7%（动词）和+1.4%（名词）的平均mAP提升超越了先前的方法。

</details>


### [179] [Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing](https://arxiv.org/abs/2506.23202)
**中文标题：基于Transformer的高频增强与多波混合人物搜索方法**

*Qilin Shu,Qixian Zhang,Qi Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer的高频增强与多波混合（HAMW）方法，用于解决人物搜索任务中高频特征抑制和计算成本高的问题。通过三阶段框架和多级Haar小波融合策略，HAMW显著提升了模型性能，并在CUHK-SYSU和PRW数据集上达到最优效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于Transformer的人物搜索模型存在两个主要问题：1）自注意力机制抑制高频特征，影响性能；2）计算成本高。本文旨在通过高频增强和多波混合方法解决这些问题。

研究方法: 提出HAMW方法，包括三阶段框架：1）通过高频增强输入提升高频特征感知；2）用多级Haar小波融合替代自注意力层，降低计算复杂度并捕捉多尺度特征；3）逐步优化检测和重识别性能。

研究结果: 实验表明，HAMW在CUHK-SYSU和PRW数据集上达到最优性能，显著提升了高频特征的利用效率和多尺度信息捕捉能力。

研究结论: HAMW通过高频增强和多波混合策略，有效解决了Transformer在人物搜索任务中的高频特征抑制和计算成本问题，为未来研究提供了新思路。

中文摘要: 人物搜索任务的目标是在一组场景图像中定位目标人物。近年来，基于Transformer的模型在该领域取得了一些进展，但仍面临三个主要挑战：1）自注意力机制倾向于抑制特征中的高频成分，严重影响模型性能；2）Transformer的计算成本较高。为解决这些问题，我们提出了一种新颖的高频增强与多波混合（HAMW）方法。HAMW旨在增强Transformer的判别性特征提取能力，同时降低计算开销并提高效率。具体而言，我们开发了一个三阶段框架，逐步优化检测和重识别性能。通过学习包含额外高频成分的增强输入，我们的模型提升了对高频特征的感知。此外，我们用基于多级Haar小波融合的策略替代了Transformer中的自注意力层，以捕捉多尺度特征。这不仅降低了计算复杂度，还缓解了对高频特征的抑制，并增强了多尺度信息的利用能力。大量实验表明，HAMW在CUHK-SYSU和PRW数据集上达到了最优性能。

</details>


### [180] [BridgeShape: Latent Diffusion Schrödinger Bridge for 3D Shape Completion](https://arxiv.org/abs/2506.23205)
**中文标题：BridgeShape：基于潜在扩散Schrödinger桥的3D形状补全**

*Dequan Kong,Zhe Zhu,Honghua Chen,Mingqiang Wei*

主要分类: cs.CV

摘要简述: BridgeShape提出了一种基于潜在扩散Schrödinger桥的3D形状补全框架，通过显式建模最优全局传输路径和深度增强的VQ-VAE编码，解决了现有方法在全局一致性和分辨率限制上的不足，实现了高效且高保真的3D形状补全。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于扩散的3D形状补全方法通常采用条件范式，通过深度特征交互注入不完整形状信息，但未能显式建模最优全局传输路径，导致补全效果不佳。此外，直接在体素空间进行扩散限制了分辨率，难以生成精细几何细节。

研究方法: BridgeShape将形状补全建模为最优传输问题，显式建模不完整与完整形状间的过渡；引入深度增强的VQ-VAE，将3D形状编码到紧凑潜在空间，利用多视角深度信息和DINOv2特征增强几何结构感知。

研究结果: BridgeShape在大规模3D形状补全基准测试中达到最先进性能，在高分辨率和未见物体类别上表现出更高的保真度。

研究结论: BridgeShape通过潜在扩散Schrödinger桥和深度增强的VQ-VAE，有效解决了全局一致性和分辨率限制问题，为3D形状补全提供了高效且高保真的解决方案。

中文摘要: 现有的基于扩散的3D形状补全方法通常采用条件范式，通过深度特征交互（如拼接、交叉注意力）将不完整形状信息注入去噪网络，引导采样生成完整形状（通常以体素距离函数表示）。然而，这些方法未能显式建模最优全局传输路径，导致补全效果不佳。此外，直接在体素空间进行扩散存在分辨率限制，难以生成精细几何细节。为解决这些问题，我们提出了BridgeShape，一种基于潜在扩散Schrödinger桥的3D形状补全框架。其创新点包括：（i）BridgeShape将形状补全建模为最优传输问题，显式建模不完整与完整形状间的过渡，确保全局一致的变换；（ii）引入深度增强的向量量化变分自编码器（VQ-VAE），将3D形状编码到紧凑潜在空间，利用自投影多视角深度信息和强DINOv2特征增强几何结构感知。通过在紧凑且结构信息丰富的潜在空间操作，BridgeShape有效缓解了分辨率限制，实现了更高效且高保真的3D形状补全。BridgeShape在大规模3D形状补全基准测试中达到最先进性能，在高分辨率和未见物体类别上表现出更高的保真度。

</details>


### [181] [TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints](https://arxiv.org/abs/2506.23207)
**中文标题：TVG-SLAM：基于三视图几何约束的鲁棒高斯溅射SLAM**

*Zhen Tan,Xieyuanli Chen,Lei Feng,Yangbing Ge,Shuaifeng Zhi,Jiaxiong Liu,Dewen Hu*

主要分类: cs.CV

摘要简述: TVG-SLAM是一种基于三视图几何约束的鲁棒性RGB-only 3D高斯溅射SLAM系统，通过引入三视图匹配模块和混合几何约束，显著提升了在户外无边界环境中的跟踪和建图性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于3D高斯溅射的SLAM系统过度依赖光度渲染损失进行相机跟踪，在户外环境中的视角和光照变化下表现不佳。TVG-SLAM旨在通过三视图几何约束提升系统的鲁棒性和渲染质量。

研究方法: TVG-SLAM提出了一种密集三视图匹配模块，将成对对应关系聚合为一致的三视图匹配，形成跨帧的鲁棒几何约束。此外，设计了混合几何约束用于跟踪，结合光度损失和几何线索；提出了一种概率初始化策略和动态渲染信任衰减机制以优化建图。

研究结果: 在多个公开户外数据集上的实验表明，TVG-SLAM优于现有RGB-only 3DGS SLAM系统，在最具挑战性的数据集中，平均绝对轨迹误差（ATE）降低了69.0%，同时实现了最先进的渲染质量。

研究结论: TVG-SLAM通过三视图几何约束显著提升了RGB-only SLAM系统的鲁棒性和渲染质量，适用于复杂户外环境。

中文摘要: 近年来，3D高斯溅射（3DGS）的进展使得仅依赖RGB的SLAM系统能够实现高保真的场景表示。然而，现有系统对光度渲染损失的过度依赖削弱了其鲁棒性，尤其是在视角和光照变化剧烈的无边界户外环境中。为解决这些问题，我们提出了TVG-SLAM，一种鲁棒的仅依赖RGB的3DGS SLAM系统，通过新颖的三视图几何范式确保一致的跟踪和高质量的建图。我们引入了一个密集三视图匹配模块，将可靠的成对对应关系聚合为一致的三视图匹配，形成跨帧的鲁棒几何约束。在跟踪方面，我们提出了混合几何约束，利用三视图匹配构建与光度损失互补的几何线索，确保即使在剧烈视角变化和光照波动下也能实现准确稳定的位姿估计。在建图方面，我们提出了一种新的概率初始化策略，将三视图对应关系中的几何不确定性编码到新初始化的高斯模型中。此外，我们设计了一种动态渲染信任衰减机制，以减轻由建图延迟引起的跟踪漂移。在多个公开户外数据集上的实验表明，TVG-SLAM优于现有的仅依赖RGB的3DGS SLAM系统。值得注意的是，在最具挑战性的数据集中，我们的方法显著提升了跟踪鲁棒性，平均绝对轨迹误差（ATE）降低了69.0%，同时实现了最先进的渲染质量。我们的方法实现将开源发布。

</details>


### [182] [A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans](https://arxiv.org/abs/2506.23209)
**中文标题：基于分层切片注意力网络的3D CT扫描阑尾炎分类**

*Chia-Wen Huang,Haw Hwai,Chien-Chang Lee,Pei-Yuan Wu*

主要分类: cs.CV

摘要简述: 提出了一种基于3D CT扫描的深度学习模型，通过切片注意力机制和分层分类框架，显著提高了阑尾炎及其复杂类型的诊断准确率。


<details>
  <summary>详细信息</summary>
研究动机: 阑尾炎的及时准确诊断对临床至关重要，但CT影像数量激增可能导致放射科医生负担过重，延误诊断。因此，需要一种高效可靠的自动诊断方法。

研究方法: 模型利用3D CT扫描，结合切片注意力机制（受外部2D数据集指导）以增强小病灶检测，并引入分层分类框架，使用预训练2D模型区分简单和复杂性阑尾炎。

研究结果: 该方法将阑尾炎的AUC提高了3%，复杂性阑尾炎的AUC提高了5.9%，优于以往工作。

研究结论: 所提方法为阑尾炎诊断提供了更高效可靠的解决方案，显著提升了分类性能。

中文摘要: 阑尾炎的及时准确诊断在临床中至关重要，以避免严重并发症。尽管CT成像是标准诊断工具，但病例数量的增加可能使放射科医生不堪重负，导致诊断延误。本文提出了一种深度学习模型，利用3D CT扫描进行阑尾炎分类，并通过外部2D数据集指导的切片注意力机制增强小病灶检测。此外，我们引入了一种分层分类框架，使用预训练的2D模型区分简单和复杂性阑尾炎。与以往工作相比，该方法将阑尾炎的AUC提高了3%，复杂性阑尾炎的AUC提高了5.9%，提供了一种更高效可靠的诊断解决方案。

</details>


### [183] [High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation](https://arxiv.org/abs/2506.23227)
**中文标题：基于场景级标注的高质量点云分割伪标签生成**

*Lunhao Duan,Shanshan Zhao,Xingxing Weng,Jing Zhang,Gui-Song Xia*

主要分类: cs.CV

摘要简述: 本文提出了一种基于场景级标注的高质量点云分割伪标签生成框架，通过多模态信息和区域-点语义一致性提升分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于稀疏点级标注的点云分割方法较多，而场景级标注的研究较少。由于缺乏精确的点级标注，现有方法生成的伪标签质量不高，严重影响分割效果。因此，本文旨在解决这一问题。

研究方法: 本文提出了一种框架，包含跨模态特征引导模块和区域-点语义一致性模块。前者利用2D-3D对应关系对齐点云特征与图像像素，后者通过区域投票策略生成区域语义以指导点级预测。

研究结果: 在ScanNet v2和S3DIS数据集上的实验表明，本文方法显著优于现有方法，且消融实验验证了各模块的有效性。

研究结论: 本文提出的框架能够生成高质量的伪标签，显著提升场景级标注下的点云分割性能。

中文摘要: 本文研究了基于场景级标注的室内点云语义分割方法，与依赖稀疏点级标注的方法相比，这一领域的研究较少。在缺乏精确点级标注的情况下，现有方法首先生成点级伪标签，再用于训练分割模型。然而，仅基于场景级标注为每个点生成准确的伪标签具有较大挑战，严重影响分割性能。为此，本文提出了一种高质量伪标签生成框架，通过探索多模态信息和区域-点语义一致性提升准确性。具体而言，通过跨模态特征引导模块，利用2D-3D对应关系将点云特征与图像像素对齐，辅助点云特征学习。为缓解场景级标注的挑战，引入区域-点语义一致性模块，通过区域投票策略从点级语义生成区域语义，并用于指导点级语义预测。结合上述模块，本文方法能够在训练过程中修正不准确的点级语义预测，获得高质量伪标签。在ScanNet v2和S3DIS数据集上的显著改进证明了方法的有效性。此外，全面的消融实验验证了各模块的贡献。代码发布于https://github.com/LHDuan/WSegPC。

</details>


### [184] [VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions](https://arxiv.org/abs/2506.23236)
**中文标题：VolumetricSMPL：一种用于高效交互、接触和碰撞的神经体积人体模型**

*Marko Mihajlovic,Siwei Zhang,Gen Li,Kaifeng Zhao,Lea Müller,Siyu Tang*

主要分类: cs.CV

摘要简述: VolumetricSMPL是一种神经体积人体模型，通过动态混合权重提升计算效率，显著优于现有方法，适用于复杂任务如人体-物体交互重建和场景约束运动合成。


<details>
  <summary>详细信息</summary>
研究动机: 传统参数化人体模型基于表面网格，难以高效处理与其他几何实体的交互。现有体积神经隐式模型要么不够鲁棒，要么计算和内存成本过高。VolumetricSMPL旨在解决这些问题。

研究方法: VolumetricSMPL利用神经混合权重（NBW）生成紧凑的MLP解码器，动态混合少量学习权重矩阵，显著提升计算效率，同时保留表达能力。

研究结果: VolumetricSMPL在推理速度上比COAP快10倍，GPU内存使用降低6倍，精度更高，并支持有符号距离函数（SDF）用于高效接触建模。在人体-物体交互重建等任务中表现优异。

研究结论: VolumetricSMPL在性能和效率上显著优于现有方法，适用于多种复杂任务，展现了广泛的实用性和潜力。

中文摘要: 参数化人体模型在计算机图形学和视觉中至关重要，支持从人体运动分析到人-环境交互理解的应用。传统模型使用表面网格，难以高效处理与其他几何实体（如物体和场景）的交互。为解决这一问题，近期研究探索了体积神经隐式人体模型，但现有方法要么对复杂人体关节不够鲁棒，要么计算和内存成本过高。为此，我们提出VolumetricSMPL，一种利用神经混合权重（NBW）生成紧凑高效MLP解码器的神经体积人体模型。与依赖大型MLP的现有方法不同，NBW通过预测的形状和姿态相关系数动态混合少量学习权重矩阵，显著提升计算效率并保留表达能力。VolumetricSMPL在推理速度上比COAP快10倍，GPU内存使用降低6倍，精度更高，并支持有符号距离函数（SDF）用于高效可微接触建模。我们在四个挑战性任务中验证了VolumetricSMPL的优势：（1）从野外图像重建人体-物体交互，（2）从第一人称视角恢复3D场景中的人体网格，（3）场景约束运动合成，（4）解决自相交问题。结果表明其广泛适用性和显著的性能与效率提升。

</details>


### [185] [Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification](https://arxiv.org/abs/2506.23247)
**中文标题：聚合局部显著性图以实现半全局可解释的图像分类**

*James Hinns,David Martens*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“分段归因表”（SATs）的方法，用于将局部显著性解释汇总为半全局见解，以解决深度学习模型在图像分类中解释性不足的问题。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在图像分类任务中表现优异，但模型预测的解释性仍然是一个挑战。现有的局部解释方法（如显著性图）难以揭示重复模式，而全局方法又过于简化，忽略了重要的局部行为。因此，需要一种介于两者之间的实用工具。

研究方法: 提出分段归因表（SATs），通过图像分段（如“眼睛”）和显著性图量化其影响力，总结局部显著性解释为半全局见解。该方法适用于任何能生成显著性图的分类器。

研究结果: SATs能够揭示模型依赖的概念（如背景或水印等虚假相关性），即使测试性能变化不大。该方法填补了过于简化的全局总结和过于详细的局部解释之间的空白。

研究结论: SATs为分析和调试图像分类器提供了一种实用工具，平衡了全局和局部解释的需求。

中文摘要: 深度学习在图像分类任务中占据主导地位，但理解模型如何做出预测仍是一个挑战。许多研究关注单个预测的局部解释（如显著性图），但这些解释难以汇总以识别重复模式，而全局方法往往过于简化并忽略重要局部行为。为此，我们提出分段归因表（SATs），将局部显著性解释汇总为半全局见解。SATs利用图像分段（如吉娃娃的“眼睛”）和显著性图量化其影响力。这些分段突出了模型跨实例依赖的概念，并揭示了虚假相关性（如依赖背景或水印），即使测试性能变化不大。SATs适用于任何能生成显著性图的分类器，并使用提供命名分段的图像分割图。SATs填补了过于简化的全局总结和过于详细的局部解释之间的空白，为分析和调试图像分类器提供了实用工具。

</details>


### [186] [DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection](https://arxiv.org/abs/2506.23252)
**中文标题：DGE-YOLO：双分支聚合与注意力机制实现精准无人机目标检测**

*Kunwei Lv,Ping Lan*

主要分类: cs.CV

摘要简述: DGE-YOLO是一种改进的YOLO框架，通过双分支结构和多尺度注意力机制，有效融合多模态信息，提升无人机场景中小目标检测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 无人机（UAV）的快速普及使得复杂场景下的目标检测需求日益突出，但现有方法在处理多模态输入时性能下降，尤其是小目标检测。因此，需要一种能够高效融合多模态信息的检测框架。

研究方法: DGE-YOLO采用双分支结构分别提取红外和可见光图像的特征，并引入高效多尺度注意力（EMA）机制增强跨空间尺度的特征学习。此外，用Gather-and-Distribute模块替代传统颈部结构以减少特征聚合中的信息损失。

研究结果: 在Drone Vehicle数据集上的实验表明，DGE-YOLO优于现有方法，验证了其在多模态无人机目标检测任务中的有效性。

研究结论: DGE-YOLO通过双分支结构和EMA机制显著提升了多模态目标检测性能，为无人机场景中的小目标检测提供了有效解决方案。

中文摘要: 无人机的快速普及凸显了在多样化空中场景中实现鲁棒高效目标检测的重要性。然而，复杂条件下的小目标检测仍是一个重大挑战。现有方法通常优先考虑推理速度，导致处理多模态输入时性能下降。为此，我们提出了DGE-YOLO，一种改进的基于YOLO的检测框架，旨在有效融合多模态信息。具体而言，我们引入了一种双分支架构用于模态特定特征提取，使模型能够同时处理红外和可见光图像。为进一步丰富语义表示，我们提出了一种高效多尺度注意力（EMA）机制，增强跨空间尺度的特征学习。此外，我们用Gather-and-Distribute模块替代传统颈部结构，以减少特征聚合中的信息损失。在Drone Vehicle数据集上的大量实验表明，DGE-YOLO优于现有方法，验证了其在多模态无人机目标检测任务中的有效性。

</details>


### [187] [PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution](https://arxiv.org/abs/2506.23254)
**中文标题：PixelBoost：利用布朗运动实现真实感图像超分辨率**

*Aradhana Mishra,Bumshik Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PixelBoost的新型扩散模型，通过利用布朗运动的随机性提升图像超分辨率技术的真实感，尤其在纹理和边缘定义上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于扩散模型的图像超分辨率技术通常在真实感生成和计算效率之间存在权衡，尤其是在减少采样步骤时会导致图像模糊。本文旨在通过引入布朗运动的随机性来解决这一问题。

研究方法: PixelBoost模型通过将受控的随机性引入训练过程，避免陷入局部最优，从而更好地捕捉图像纹理和模式的不确定性。此外，模型采用了一种Sigmoid噪声排序方法，简化了训练并提高了推理速度。

研究结果: 实验表明，PixelBoost在LPIPS、LOE、PSNR和SSIM等客观指标上表现优异，同时在边缘重建能力和视觉质量上显著优于现有方法。

研究结论: PixelBoost通过结合布朗运动的随机性和创新的噪声排序方法，显著提升了图像超分辨率的真实感和计算效率，为相关领域提供了新的解决方案。

中文摘要: 基于扩散模型的图像超分辨率技术通常在真实感生成和计算效率之间存在权衡。减少采样步骤会导致图像模糊，这一问题尤为突出。为解决这一挑战，我们提出了一种名为PixelBoost的新型扩散模型，强调了布朗运动的随机性在提升图像超分辨率真实感中的重要性，尤其是在纹理和边缘定义方面。通过将受控的随机性引入训练过程，我们的模型避免了陷入局部最优，有效捕捉并再现了图像纹理和模式的内在不确定性。实验结果表明，我们的模型在学习感知图像块相似性（LPIPS）、亮度顺序误差（LOE）、峰值信噪比（PSNR）和结构相似性指数（SSIM）等客观指标上表现优异，同时视觉质量也显著提升。为评估边缘增强效果，我们测试了梯度幅值和像素值，结果显示我们的模型具有更好的边缘重建能力。此外，我们的模型通过有效适应布朗噪声模式展示了自适应学习能力，并引入了一种Sigmoid噪声排序方法，简化了训练过程，从而提高了推理速度。

</details>


### [188] [Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization](https://arxiv.org/abs/2506.23714)
**中文标题：面向自动化多模态视频摘要的方法：构建文本、音频与面部线索摘要之间的桥梁**

*Md Moinul Islam,Sofoklis Kakouros,Janne Heikkilä,Mourad Oussalah*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多模态（文本、音频和视觉）的视频摘要框架，通过整合多模态特征生成时间对齐的摘要，显著提升了摘要的语义相关性和情感表达。


<details>
  <summary>详细信息</summary>
研究动机: 随着视频内容在教育、职业和社交领域的快速增长，传统的单模态摘要方法已无法满足需求。本文旨在开发一种多模态视频摘要框架，以更全面地捕捉视频中的重要时刻。

研究方法: 框架通过提取文本、音频和视觉特征（如韵律特征和视觉指示器），识别语义和情感上的重要时刻，并利用跨模态强调的“奖励词”提升摘要质量。

研究结果: 实验结果表明，该框架在文本和视频评价指标上均优于传统方法，ROUGE-1从0.4769提升至0.7929，BERTScore从0.9152提升至0.9536，视频评价的F1-Score提高了近23%。

研究结论: 多模态整合在生成全面且行为感知的视频摘要中具有显著潜力，为未来视频摘要技术的发展提供了新方向。

中文摘要: 随着教育、职业和社交领域中视频内容的快速增长，传统的单模态摘要方法已无法满足需求。本文提出了一种行为感知的多模态视频摘要框架，通过整合文本、音频和视觉线索生成时间对齐的摘要。该框架通过提取韵律特征、文本线索和视觉指示器，识别语义和情感上的重要时刻。其关键贡献在于识别“奖励词”，即跨多模态强调的术语，用于提升摘要的语义相关性和表达清晰度。该方法的评估基于基于LLM的提取方法生成的伪真实摘要（pGT）。实验结果表明，与传统提取方法（如Edmundson方法）相比，该方法在文本和视频评价指标上均有显著提升。文本评价指标中，ROUGE-1从0.4769提升至0.7929，BERTScore从0.9152提升至0.9536；视频评价中，F1-Score提高了近23%。研究结果强调了多模态整合在生成全面且行为感知的视频摘要中的潜力。

</details>


### [189] [PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation](https://arxiv.org/abs/2506.23257)
**中文标题：PCLVis：大规模模拟中进程通信延迟的可视化分析**

*Chongke Bi,Xin Gao,Baofeng Fu,Yuheng Zhao,Siming Chen,Ying Zhao,Yunhai Wang*

主要分类: cs.CV

摘要简述: PCLVis是一个帮助用户分析大规模模拟中进程通信延迟（PCL）事件的框架，通过MPI数据而非物理链路信息实现高效分析，提升模拟效率。


<details>
  <summary>详细信息</summary>
研究动机: 大规模模拟在超级计算机上的应用日益重要，但由于并行进程间的高通信成本，其扩展性成为问题。现有方法依赖管理员才能获取的物理链路信息，普通用户难以分析通信延迟事件。

研究方法: PCLVis框架利用MPI进程通信数据，开发了空间PCL事件定位方法，构建进程相关性树分类高相关进程；通过通信依赖有向无环图（DAG）分析PCL事件传播路径，设计滑动窗口算法生成事件抽象；引入通信状态符号（CS-Glyph）展示进程通信状态，并提供事件归因策略优化模拟。

研究结果: PCLVis在TH-1A超级计算机上的多个模拟中验证了其有效性，用户通过该框架显著提升了模拟效率。

研究结论: PCLVis为普通用户提供了一种无需物理链路信息的高效PCL事件分析工具，帮助优化大规模模拟的通信性能。

中文摘要: 超级计算机上的大规模模拟已成为用户的重要工具，但由于并行进程间的高通信成本，其扩展性仍存在问题。现有的通信延迟分析方法大多依赖仅管理员可获取的物理链路层信息。本文提出了一种名为PCLVis的框架，帮助普通用户分析进程通信延迟（PCL）事件。PCLVis使用MPI进程通信数据而非物理链路信息进行分析。首先，开发了一种空间PCL事件定位方法，通过构建进程相关性树将所有高相关进程分类为单一集群。其次，通过构建基于通信依赖的有向无环图（DAG）分析PCL事件的传播路径，帮助用户从时间演化角度交互式探索PCL事件集群。图中设计了滑动窗口算法生成PCL事件抽象。同时，为每个进程设计了一种新的符号——通信状态符号（CS-Glyph），展示其通信状态（包括输入/输出消息和负载平衡），并可展开查看详细信息。第三，制定了PCL事件归因策略，帮助用户优化模拟。通过在TH-1A超级计算机上分析多个模拟的PCL事件，验证了PCLVis框架的有效性。用户使用该框架可显著提升模拟效率。

</details>


### [190] [Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis](https://arxiv.org/abs/2506.23263)
**中文标题：因果实体反映的自中心视角交通事故视频合成**

*Lei-lei Li,Jianwu Fang,Junbin Xiao,Shanmin Pang,Hongkai Yu,Chen Lv,Jianru Xue,Tat-Seng Chua*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Causal-VidSyn的新型扩散模型，用于合成反映因果关系的自中心视角交通事故视频，并通过实验验证其在视频质量与因果敏感性方面的优越性。


<details>
  <summary>详细信息</summary>
研究动机: 自中心视角理解交通事故的因果关系对自动驾驶汽车的安全至关重要，但现有方法难以在合成视频中准确反映真实世界中的因果关系。

研究方法: 提出Causal-VidSyn模型，利用事故原因描述和驾驶员注视点识别事故参与者及其行为，并通过事故原因回答模块和注视条件选择模块实现因果实体定位。

研究结果: 实验表明，Causal-VidSyn在视频编辑、正常到事故视频扩散及文本到视频生成等任务中，其帧质量和因果敏感性均优于现有视频扩散模型。

研究结论: Causal-VidSyn为合成具有因果关系的交通事故视频提供了有效方法，并推动了自动驾驶安全测试的发展。

中文摘要: 自中心视角理解交通事故的因果关系对自动驾驶汽车的安全至关重要，而合成反映因果关系的交通事故视频有助于测试对现实中难以承受的事故的应对能力。然而，将真实视频中的因果关系融入合成视频仍具挑战性。本研究认为，准确识别事故参与者并捕捉其相关行为至关重要。为此，我们提出了一种新型扩散模型Causal-VidSyn，用于合成自中心视角的交通事故视频。为实现视频扩散中的因果实体定位，Causal-VidSyn利用原因描述和驾驶员注视点，通过事故原因回答模块和注视条件选择模块识别事故参与者及其行为。为支持Causal-VidSyn，我们还构建了Drive-Gaze，这是驾驶事故场景中最大的驾驶员注视数据集（包含154万帧注视数据）。大量实验表明，Causal-VidSyn在视频编辑、正常到事故视频扩散及文本到视频生成等任务中，其帧质量和因果敏感性均优于现有视频扩散模型。

</details>


### [191] [Token Activation Map to Visually Explain Multimodal LLMs](https://arxiv.org/abs/2506.23270)
**中文标题：令牌激活图：可视化解释多模态大语言模型**

*Yi Li,Hualiang Wang,Xinpeng Ding,Haonan Wang,Xiaomeng Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Token Activation Map（TAM）的方法，用于解释多模态大语言模型（MLLMs）的生成过程。通过消除上下文冗余激活的干扰，TAM能够更可靠地可视化模型的多令牌生成过程，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在多个领域表现出色，但其可解释性研究不足，影响了模型的可信度和可视化效果。现有方法忽略了上下文冗余激活对后续令牌解释的干扰，导致解释可靠性下降。本文旨在解决这一问题。

研究方法: 提出了一种基于因果推理的方法（TAM），通过消除上下文冗余激活的干扰，并结合新颖的秩高斯滤波器减少激活噪声，从而实现对MLLMs生成过程的高质量解释。

研究结果: TAM在多种场景（如目标定位、失败案例分析、视频可视化等）中显著优于现有方法，提供了高质量的可视化结果，并展示了其在多令牌解释中的优势。

研究结论: TAM通过消除上下文冗余激活的干扰，显著提升了多模态大语言模型的可解释性和可视化效果，为模型理解和应用提供了有力工具。

中文摘要: 多模态大语言模型（MLLMs）广泛应用于多个领域，但其可解释性研究不足，阻碍了对模型的深入理解、可信度评估和有效可视化。与传统视觉模型（如CNN、ViT、CLIP）不同，MLLMs逐步生成令牌序列，每个令牌依赖于先前的上下文。因此，早期上下文令牌可能引入冗余激活，干扰后续令牌的解释。现有研究常忽视这一问题，但我们的观察表明，这些冗余关联会显著降低解释的可靠性。为解决这一问题，我们提出了一种基于因果推理的方法，通过消除上下文干扰实现高质量的MLLM解释，并结合新颖的秩高斯滤波器进一步减少激活噪声。我们将此方法称为令牌激活图（TAM），以突出其对令牌间交互的考量。TAM还表明，其在解释MLLMs的多个令牌方面表现优异，这与针对单一预测的类别激活图（CAM）不同。TAM方法显著优于现有技术，提供了高质量的可视化结果，适用于多种场景，如目标定位、失败案例分析、视频可视化、MLLMs视觉比较和模型理解（如颜色、形状、动作、位置、视觉推理、多轮对话等）。代码已开源：github.com/xmed-lab/TAM。

</details>


### [192] [Ella: Embodied Social Agents with Lifelong Memory](https://arxiv.org/abs/2506.24019)
**中文标题：Ella：具备终身记忆的具身社交代理**

*Hongxin Zhang,Zheyuan Zhang,Zeyuan Wang,Zunzhe Zhang,Lixing Fang,Qinhong Zhou,Chuang Gan*

主要分类: cs.CV

摘要简述: 本文介绍了Ella，一种具备终身学习能力的具身社交代理，通过多模态记忆系统和基础模型在3D开放世界中积累经验、进行社交互动，并展示了其在动态环境中的领导与合作能力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发一种能够在开放世界中持续学习并与智能体互动的具身社交代理，探索结构化记忆系统与基础模型结合对具身智能的潜在影响。

研究方法: Ella采用多模态记忆系统，包括以名称为中心的语义记忆和时空情景记忆，结合基础模型进行信息检索与决策，支持日常活动规划和社会关系构建。

研究结果: 实验表明，Ella能够在动态3D开放世界中与其他智能体有效互动，通过观察和社交学习实现目标，展示了其在领导与合作方面的能力。

研究结论: 研究证明了结构化记忆系统与基础模型结合对具身智能的推动作用，为未来具身智能的发展提供了新方向。

中文摘要: 我们介绍了Ella，一种能够在3D开放世界中通过终身学习积累经验的具身社交代理。Ella的核心能力是一个结构化的多模态长期记忆系统，能够有效存储、更新和检索信息。该系统包括以名称为中心的语义记忆用于组织知识，以及时空情景记忆用于捕捉多模态经验。通过将这一终身记忆系统与基础模型结合，Ella能够检索相关信息以支持决策、规划日常活动、建立社会关系，并在开放世界中与其他智能体共存并自主进化。我们在一个动态3D开放世界中对15个代理进行了能力导向的评估，结果显示Ella能够通过观察和社交互动有效学习，并展现出领导与合作的能力。我们的研究揭示了结构化记忆系统与基础模型结合对具身智能的变革潜力。更多视频请访问：https://umass-embodied-agi.github.io/Ella/。

</details>


### [193] [Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation](https://arxiv.org/abs/2506.23271)
**中文标题：Mettle：基于元令牌学习的内存高效音频-视觉适配方法**

*Jinxing Zhou,Zhihui Li,Yongqiang Yu,Yanghao Zhou,Ruohao Guo,Guangyao Li,Yuxin Mao,Mingfei Han,Xiaojun Chang,Meng Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Mettle的轻量级方法，通过元令牌学习实现大规模预训练Transformer模型在音频-视觉任务中的高效适配，显著减少内存占用和训练时间。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在适配大规模预训练Transformer模型时，通常需要大量内存和计算资源。本文旨在提出一种高效且内存友好的适配方法，同时保持模型性能和参数效率。

研究方法: Mettle采用层中心蒸馏（LCD）模块并行提取每层Transformer的音频或视觉特征为紧凑的元令牌，并结合元令牌注入（MTI）模块支持细粒度分割任务。

研究结果: 在多个音频-视觉基准测试中，Mettle显著降低了内存使用和训练时间，同时保持了参数效率和竞争性精度。

研究结论: Mettle为音频-视觉任务提供了一种高效、内存友好的适配方案，适用于分类和细粒度分割任务。

中文摘要: 本文提出了一种名为Mettle的简单且内存高效的方法，用于将大规模预训练的Transformer模型适配到下游音频-视觉任务中。Mettle通过轻量级的层中心蒸馏（LCD）模块并行提取每层Transformer嵌入的完整音频或视觉特征为紧凑的元令牌，同时兼顾预训练知识的保留和任务特定适配。这些元令牌可直接应用于分类任务，如音频-视觉事件定位和音频-视觉视频解析。为进一步支持细粒度分割任务（如音频-视觉分割），我们引入了元令牌注入（MTI）模块，利用顶层Transformer提取的音频和视觉元令牌指导早期层的特征适配。在多个音频-视觉基准测试上的广泛实验表明，我们的方法显著减少了内存使用和训练时间，同时保持了参数效率和竞争性精度。

</details>


### [194] [Why Settle for One? Text-to-ImageSet Generation and Evaluation](https://arxiv.org/abs/2506.23275)
**中文标题：为何满足于单一？文本到图像集的生成与评估**

*Chengyou Jia,Xin Shen,Zhuohang Dang,Zhuohang Dang,Changliang Xia,Weijia Wu,Xinyu Zhang,Hangwei Qian,Ivor W. Tsang,Minnan Luo*

主要分类: cs.CV

摘要简述: 本文提出了一种更具挑战性的文本到图像集（T2IS）生成问题，旨在根据用户指令生成满足多种一致性要求的图像集。作者引入了T2IS-Bench基准和T2IS-Eval评估框架，并提出了AutoT2IS方法，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管文本到图像模型取得了显著进展，但许多实际应用需要生成具有多样一致性要求的连贯图像集。现有方法通常局限于特定领域或一致性方面，限制了其泛化能力。本文旨在解决这一问题。

研究方法: 作者首先提出了T2IS-Bench基准，包含596条指令和26个子类别。随后开发了T2IS-Eval评估框架，将用户指令转化为多方面的评估标准。最后提出了AutoT2IS方法，利用预训练的Diffusion Transformers实现图像级提示对齐和集级视觉一致性。

研究结果: 实验表明，现有方法在多样一致性要求下表现不佳，而AutoT2IS显著优于通用和专用方法，并展示了在未探索的实际应用中的潜力。

研究结论: 本文提出的T2IS问题、基准和AutoT2IS方法为文本到图像集生成提供了系统解决方案，具有重要的实际价值。

中文摘要: 尽管文本到图像模型取得了显著进展，但许多实际应用需要生成具有多样一致性要求的连贯图像集。现有方法通常局限于特定领域或一致性方面，限制了其泛化能力。本文提出了一种更具挑战性的问题——文本到图像集（T2IS）生成，旨在根据用户指令生成满足多种一致性要求的图像集。为系统研究此问题，我们首先引入了T2IS-Bench基准，包含596条指令和26个子类别，为T2IS生成提供了全面覆盖。在此基础上，我们提出了T2IS-Eval评估框架，将用户指令转化为多方面的评估标准，并采用有效的评估器自适应地评估生成集与标准之间的一致性满足情况。随后，我们提出了AutoT2IS，一种无需训练的框架，充分利用预训练的Diffusion Transformers的上下文能力，协调视觉元素以满足图像级提示对齐和集级视觉一致性。在T2IS-Bench上的大量实验表明，多样一致性要求对所有现有方法构成挑战，而我们的AutoT2IS显著优于当前通用甚至专用方法。我们的方法还展示了在众多未探索的实际应用中的潜力，证实了其重要的实用价值。访问我们的项目：https://chengyou-jia.github.io/T2IS-Home。

</details>


### [195] [MotionGPT3: Human Motion as a Second Modality](https://arxiv.org/abs/2506.24086)
**中文标题：MotionGPT3：将人类运动作为第二模态**

*Bingfan Zhu,Biao Jiang,Sunyi Wang,Shixiang Tang,Tao Chen,Linjie Luo,Youyi Zheng,Xin Chen*

主要分类: cs.CV

摘要简述: MotionGPT3提出了一种双模态运动-语言模型，将人类运动作为第二模态，通过分离模型参数解决运动重建和语言智能退化问题，实现了高效的多模态训练和跨模态交互。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态模型在统一理解和生成方面表现出强大能力，但运动-语言统一模型的发展仍不足。MotionGPT3旨在解决连续运动模态与离散表示之间的重建差距，以及统一训练中语言智能的退化问题。

研究方法: MotionGPT3采用专家混合方法，将运动建模与语言模型解耦，保留语言分支的原始结构和参数，同时通过共享注意力机制集成新的运动分支。使用运动变分自编码器（VAE）将原始运动编码为潜在表示，并通过扩散头直接从隐藏状态预测运动潜在表示，避免离散化。

研究结果: 实验表明，MotionGPT3在运动理解和生成任务中表现优异，同时保持了强大的语言能力，建立了自回归框架下的统一双模态运动扩散模型。

研究结论: MotionGPT3通过解耦运动建模和保留语言智能，成功实现了运动与语言的高效统一，为多模态模型的发展提供了新思路。

中文摘要: 尽管多模态模型的最新进展展示了统一理解和生成的强大能力与机遇，但运动-语言统一模型的发展仍未被充分探索。为了实现高保真的人类运动建模，必须解决两个核心挑战：一是连续运动模态与离散表示之间的重建差距，二是统一训练中语言智能的退化。受专家混合方法的启发，我们提出了MotionGPT3，这是一种双模态运动-语言模型，将人类运动视为第二模态，通过分离模型参数解耦运动建模，实现高效的跨模态交互和多模态扩展训练。为保留语言智能，文本分支保留了预训练语言模型的原始结构和参数，同时通过共享注意力机制集成新的运动分支，实现两种模态之间的双向信息流。我们首先使用运动变分自编码器（VAE）将原始人类运动编码为潜在表示。基于这一连续潜在空间，运动分支通过扩散头直接从中间隐藏状态预测运动潜在表示，绕过离散化过程。大量实验表明，我们的方法在运动理解和生成任务中均表现出色，同时保持了强大的语言能力，建立了自回归框架下的统一双模态运动扩散模型。

</details>


### [196] [Autoregressive Denoising Score Matching is a Good Video Anomaly Detector](https://arxiv.org/abs/2506.23282)
**中文标题：自回归去噪分数匹配是一种优秀的视频异常检测器**

*Hanwen Zhang,Congqi Cao,Qinyi Lv,Lingtong Min,Yanning Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自回归去噪分数匹配的视频异常检测方法，通过结合场景、运动和外观信息，解决了传统方法对局部模式异常的盲区问题，并在三个基准测试中取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 视频异常检测（VAD）是计算机视觉中的重要问题。传统基于似然的方法虽然能建模正常分布，但对靠近学习分布的局部模式异常存在盲区。本文旨在解决这一盲区问题，同时关注场景、运动和外观三个方面的独特差异。

研究方法: 1. 构建噪声条件化的分数变换器用于去噪分数匹配；2. 引入场景依赖和运动感知的分数函数，通过嵌入输入序列的场景条件并根据关键帧差异分配运动权重；3. 提出自回归去噪分数匹配机制，通过逐步注入高斯噪声并估计分数函数，增强外观感知和异常上下文积累。

研究结果: 在三个流行的视频异常检测基准测试中，本文方法取得了最先进的性能表现。

研究结论: 通过综合考虑场景、运动和外观三个方面的差异，本文提出的方法能够生成更全面的异常指标，显著提升了视频异常检测的性能。

中文摘要: 视频异常检测（VAD）是计算机视觉中的一个重要问题。得益于生成模型的模式覆盖能力，基于似然的范式因其能够建模正常分布并检测分布外异常而受到越来越多的关注。然而，这些基于似然的方法对位于学习分布附近局部模式中的异常是盲目的。为了处理这些“未见”异常，我们深入研究了VAD中关于场景、运动和外观的三个独特差异。具体而言，我们首先构建了一个噪声条件化的分数变换器用于去噪分数匹配。然后，通过将输入序列的场景条件嵌入模型并根据输入序列关键帧的差异分配运动权重，我们引入了一个场景依赖和运动感知的分数函数。接着，为了解决原理上的盲区问题，我们通过一种新颖的自回归去噪分数匹配机制在推理中整合未受影响的视觉信息。通过自回归地将增强的高斯噪声注入去噪数据并估计相应的分数函数，我们将去噪数据与原始数据进行比较以获取差异，并将其与分数函数聚合以增强外观感知并积累异常上下文。综合考虑这三个差异后，我们可以计算出一个更全面的异常指标。在三个流行的VAD基准测试上的实验证明了我们方法的最先进性能。

</details>


### [197] [MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition](https://arxiv.org/abs/2506.23283)
**中文标题：MoMa：调制Mamba以适配图像基础模型至视频识别**

*Yuhuan Yang,Chaofan Ma,Zhenjie Mao,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

主要分类: cs.CV

摘要简述: 本文提出MoMa框架，通过将Mamba的选择性状态空间建模融入图像基础模型（IFMs），实现高效的空间-时间动态建模，提升视频理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 视频理解需要有效建模空间-时间动态，但现有方法多将空间和时间信息分开处理，难以捕捉视频的复杂性。本文旨在通过MoMa框架实现高效且全面的空间-时间建模。

研究方法: 提出SeqMod操作，将空间-时间信息注入预训练的IFMs中，同时保持原始特征不变。结合Divide-and-Modulate架构，MoMa在计算高效的前提下增强视频理解能力。

研究结果: 在多个视频基准测试中，MoMa表现出色，性能优于现有方法，同时计算成本更低。

研究结论: MoMa通过选择性状态空间建模和Divide-and-Modulate架构，成功实现了高效且全面的视频理解，为视频识别任务提供了新思路。

中文摘要: 视频理解是一项复杂的挑战，需要有效建模空间-时间动态。随着图像基础模型（IFMs）在图像理解中的成功，近期研究尝试通过参数高效微调（PEFT）将IFMs适配至视频任务。然而，这些方法多将空间和时间信息分开处理，可能无法完全捕捉视频动态的复杂性。本文提出MoMa，一种高效的适配器框架，通过将Mamba的选择性状态空间建模融入IFMs，实现全面的空间-时间建模。我们提出新颖的SeqMod操作，将空间-时间信息注入预训练的IFMs中，同时不破坏其原始特征。通过将SeqMod融入Divide-and-Modulate架构，MoMa在保持计算效率的同时提升了视频理解能力。在多个视频基准测试中的广泛实验证明了MoMa的有效性，其以更低的计算成本实现了卓越性能。

</details>


### [198] [Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification](https://arxiv.org/abs/2506.23285)
**中文标题：竞争蒸馏：一种提升视觉分类性能的简单学习策略**

*Daqian Shi,Xiaolei Diao,Xu Chen,Cédric M. John*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的竞争蒸馏策略，通过动态调整网络中每个成员的角色（教师或学生），并引入竞争优化和随机扰动，显著提升了视觉分类任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的知识蒸馏方法（如深度互学习和自蒸馏）通过多网络协作提升训练性能，但由于对学习方向影响的了解不足，改进有限。本文旨在通过竞争机制动态优化学习方向，进一步提升性能。

研究方法: 提出竞争蒸馏策略，允许网络组中每个成员根据性能动态充当教师或学生，并引入竞争优化和随机扰动，以促进更好的视觉表示和全局最优。

研究结果: 实验结果表明，竞争蒸馏在多种任务和数据集上均表现出色，显著提升了视觉分类的性能。

研究结论: 竞争蒸馏通过动态角色分配和竞争机制，有效提升了网络的训练效率和分类性能，为视觉任务提供了一种新的优化思路。

中文摘要: 深度神经网络（DNNs）显著推动了计算机视觉领域的发展。为优化DNN训练过程，知识蒸馏方法通过引入教师网络到学生网络的固定学习方向，有效加速了网络训练。在此背景下，提出了多种基于蒸馏的优化策略（如深度互学习和自蒸馏），试图通过多网络协作实现通用训练性能提升。然而，由于对不同迭代中网络间学习方向影响的了解不足，这些策略的改进有限。本文提出了一种新颖的竞争蒸馏策略，允许网络组中每个成员根据性能动态充当教师，从而提升整体学习性能。竞争蒸馏组织一组网络执行共享任务并参与竞争，其中竞争优化被提出以改进参数更新过程。此外，我们在竞争蒸馏中引入随机扰动，旨在激励网络通过突变获得更好的视觉表示和全局最优。实验结果表明，竞争蒸馏在多种任务和数据集上均表现出色。

</details>


### [199] [DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios](https://arxiv.org/abs/2506.23292)
**中文标题：DDL：一个用于可解释深度伪造检测与定位的现实场景数据集**

*Changtao Miao,Yi Zhang,Weize Gao,Man Luo,Weiwei Feng,Zhiya Tan,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一个名为DDL的大规模深度伪造检测与定位数据集，包含180万伪造样本和75种深度伪造方法，旨在解决现有数据集在多样性和规模上的不足，并为复杂现实场景提供更可靠的基准。


<details>
  <summary>详细信息</summary>
研究动机: 随着AIGC技术的发展，恶意深度伪造内容的滥用日益严重，现有检测方法虽性能优异但缺乏可解释性，尤其在法律等关键领域，可解释性对决策的权威性至关重要。现有数据集因标注有限、伪造场景单一等问题，难以满足复杂现实需求。

研究方法: 作者构建了DDL数据集，包含180万伪造样本和75种深度伪造方法，创新点包括多样伪造场景、全面深度伪造方法、多种操纵模式和细粒度伪造标注，以支持下一代检测与定位方法。

研究结果: DDL数据集通过多样性和规模的优势，为复杂现实场景提供了更具挑战性的基准，并为深度伪造检测、定位和可解释性方法的发展提供了关键支持。

研究结论: DDL数据集填补了现有数据集的不足，为深度伪造检测与定位研究提供了更全面的支持，有望推动该领域的进一步发展。

中文摘要: 近年来，AIGC技术的进步加剧了恶意深度伪造内容的滥用，开发可靠的深度伪造检测方法成为应对这一挑战的重要手段。尽管现有检测模型在性能上表现优异，但多数方法仅提供简单的二分类结果，缺乏可解释性。在法律等关键领域，可解释性对提升决策的可信度和权威性至关重要。近期研究尝试通过提供空间操纵掩码或时间伪造片段来改善分类结果的可解释性，但由于伪造数据的局限性，这些方法的实际效果仍不理想。当前多数深度伪造数据集仅提供二分类标签，仅有少数数据集包含定位标注，且存在伪造场景受限、深度伪造类型单一和数据规模不足等问题，难以应对复杂现实场景。为解决这一问题，我们构建了一个新型大规模深度伪造检测与定位（DDL）数据集，包含超过180万伪造样本和75种深度伪造方法。DDL的设计包含四大创新点：（1）多样伪造场景，（2）全面深度伪造方法，（3）多种操纵模式，（4）细粒度伪造标注。通过这些改进，DDL不仅为复杂现实伪造提供了更具挑战性的基准，还为下一代深度伪造检测、定位和可解释性方法的发展提供了关键支持。DDL数据集项目页面位于https://deepfake-workshop-ijcai2025.github.io/main/index.html。

</details>


### [200] [DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On](https://arxiv.org/abs/2506.23295)
**中文标题：DiffFit：解耦服装变形与纹理细化的虚拟试穿方法**

*Xiang Xu*

主要分类: cs.CV

摘要简述: DiffFit是一种新型的两阶段潜在扩散框架，用于高保真虚拟试穿，通过解耦几何对齐和外观细化，显著提升了服装细节保留和身体对齐精度。


<details>
  <summary>详细信息</summary>
研究动机: 虚拟试穿（VTON）在电子商务和数字时尚中有广泛应用，但现有方法在保留服装细节、精确对齐身体、推理效率和泛化性方面仍存在挑战。DiffFit旨在解决这些问题。

研究方法: DiffFit采用两阶段生成策略：第一阶段通过几何感知的服装变形实现服装与目标身体的精确对齐；第二阶段通过跨模态条件扩散模型细化纹理保真度，结合变形后的服装、原始服装外观和目标人物图像进行高质量渲染。

研究结果: 在大规模VTON基准测试中，DiffFit在定量指标和感知评估上均优于现有最先进方法，能够有效保留纹理、褶皱和光照等服装属性，并确保与人体精确对齐。

研究结论: DiffFit通过解耦几何对齐和外观细化，降低了任务复杂性，提升了生成稳定性和视觉真实感，为虚拟试穿提供了高效且高质量的解决方案。

中文摘要: 虚拟试穿（VTON）旨在合成人物穿着目标服装的真实图像，广泛应用于电子商务和数字时尚领域。尽管潜在扩散模型的最新进展显著提升了视觉质量，但现有方法在保留细粒度服装细节、实现精确服装-身体对齐、保持推理效率以及泛化到多样姿态和服装风格方面仍存在困难。为解决这些问题，我们提出了DiffFit，一种新型的两阶段潜在扩散框架，用于高保真虚拟试穿。DiffFit采用渐进生成策略：第一阶段通过细粒度变形和姿态适应实现几何感知的服装变形，将服装与目标身体对齐；第二阶段通过跨模态条件扩散模型细化纹理保真度，结合变形后的服装、原始服装外观和目标人物图像进行高质量渲染。通过解耦几何对齐和外观细化，DiffFit有效降低了任务复杂性，提升了生成稳定性和视觉真实感。它在保留纹理、褶皱和光照等服装特定属性的同时，确保了与人体精确对齐。在大规模VTON基准测试上的广泛实验表明，DiffFit在定量指标和感知评估上均优于现有最先进方法。

</details>


### [201] [Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting](https://arxiv.org/abs/2506.23308)
**中文标题：Endo-4DGX：基于高斯泼溅的鲁棒内窥镜场景重建与光照校正**

*Yiming Huang,Long Bai,Beilei Cui,Yanheng Li,Tong Chen,Jie Wang,Jinlin Wu,Zhen Lei,Hongbin Liu,Hongliang Ren*

主要分类: cs.CV

摘要简述: Endo-4DGX是一种针对内窥镜场景的新型重建方法，通过光照自适应的高斯泼溅技术，解决了极端光照条件下的渲染问题，显著提升了低光和过曝环境下的重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 在图像引导机器人手术中，软组织的精确重建对自动化至关重要。然而，现有3D高斯泼溅（3DGS）方法在光照不均（如低光或过曝）场景中表现不佳，导致优化问题和渲染质量下降。因此，需要一种专门针对内窥镜场景的光照自适应重建方法。

研究方法: Endo-4DGX结合光照嵌入技术，有效建模视图依赖的亮度变化。通过区域感知增强模块和空间感知调整模块，分别学习高斯级别的子区域亮度和视图一致的亮度调整。此外，采用曝光控制损失将不良曝光恢复至正常水平。

研究结果: 实验表明，Endo-4DGX在低光和过曝条件下显著优于现有重建和恢复方法的组合，同时保持了几何精度，展现了其在机器人辅助手术应用中的潜力。

研究结论: Endo-4DGX通过光照自适应设计，成功解决了内窥镜场景中的光照不均问题，为机器人手术的自动化提供了高质量的重建和渲染解决方案。

中文摘要: 软组织的精确重建对推动图像引导机器人手术的自动化至关重要。近期的高斯泼溅技术（3DGS）及其变体4DGS能够实时渲染高质量动态手术场景，但在光照不均（如低光或过曝）场景中表现不佳，导致严重的优化问题和渲染质量下降。为此，我们提出Endo-4DGX，一种专为光照不均内窥镜场景设计的光照自适应高斯泼溅重建方法。通过引入光照嵌入，我们的方法有效建模了视图依赖的亮度变化。我们设计了区域感知增强模块和空间感知调整模块，分别在高斯级别建模子区域亮度和学习视图一致的亮度调整。Endo-4DGX在低光和过曝条件下均实现了卓越的渲染性能，同时保持了几何精度。此外，我们采用曝光控制损失将不良曝光恢复至正常水平，以支持光照自适应优化。实验结果表明，Endo-4DGX在挑战性光照环境下显著优于现有重建和恢复方法的组合，展现了其在机器人辅助手术应用中的潜力。代码发布于https://github.com/lastbasket/Endo-4DGX。

</details>


### [202] [FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method](https://arxiv.org/abs/2506.23323)
**中文标题：FastSeg：基于分层注意力细化方法的高效免训练开放词汇分割**

*Quang-Huy Che,Vinh-Tiep Nguyen*

主要分类: cs.CV

摘要简述: FastSeg是一种无需训练的高效开放词汇分割框架，通过分层注意力细化方法（HARD）和双提示机制，仅需（1+1）步反向扩散过程即可实现多类别同时分割，显著提升分割质量和推理效率。


<details>
  <summary>详细信息</summary>
研究动机: 开放词汇语义分割（OVSS）旨在无需密集标注数据集的情况下分割任意文本类别的对象。现有方法在全局表示偏差下丢失像素级精度，而扩散模型虽能捕捉细粒度空间特征，却在迭代次数与分割质量间难以平衡。FastSeg旨在解决这些问题。

研究方法: FastSeg采用预训练扩散模型（如Stable Diffusion）的（1+1）步反向过程，无需训练。其核心包括：1）双提示机制提取区分性类别注意力；2）分层注意力细化方法（HARD）通过尺度对齐的自注意力图增强交叉注意力；3）测试时翻转（TTF）方案提升空间一致性。

研究结果: FastSeg在PASCAL VOC、PASCAL Context和COCO Object基准测试中达到43.8%的平均mIoU，实现了最先进的无需训练性能，同时保持高效推理。

研究结论: FastSeg在分割质量和推理效率间取得平衡，为开放词汇分割提供了可扩展的强基础。

中文摘要: 开放词汇语义分割（OVSS）旨在无需密集标注数据集的情况下分割任意文本类别的对象。尽管基于对比学习的模型支持零样本分割，但由于全局表示偏差，它们常丢失像素级精度。而扩散模型通过注意力机制自然编码细粒度空间特征，但难以平衡迭代次数与分割质量。本文提出FastSeg，一种高效免训练框架，仅需预训练扩散模型（如Stable Diffusion）的（1+1）步反向过程，且一次性完成所有类别的分割。FastSeg引入三个关键组件：1）双提示机制提取区分性类别注意力；2）分层注意力细化方法（HARD）通过尺度对齐的自注意力图增强交叉注意力；3）测试时翻转（TTF）方案提升空间一致性。大量实验表明，FastSeg在PASCAL VOC、PASCAL Context和COCO Object基准测试中达到43.8%的平均mIoU，实现了最先进的免训练性能，同时保持高效推理。结果表明，FastSeg为可扩展性提供了强基础，弥合了分割质量与推理效率间的差距。

</details>


### [203] [IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering](https://arxiv.org/abs/2506.23329)
**中文标题：IR3D-Bench：评估视觉语言模型作为代理逆向渲染的场景理解能力**

*Parker Liu,Chenxin Li,Zhengxin Li,Yipeng Wu,Wuyang Li,Zhiqin Yang,Zhenyuan Zhang,Yunlong Lin,Sirui Han,Brandon Y. Feng*

主要分类: cs.CV

摘要简述: IR3D-Bench是一个评估视觉语言模型（VLMs）通过工具使用主动重建3D场景能力的基准测试，旨在验证其是否真正理解场景而非仅描述。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言模型在描述任务上表现优异，但其是否真正理解场景仍不确定。研究希望通过主动创建而非被动识别的方式，验证模型对场景的理解能力。

研究方法: IR3D-Bench基于分析-合成范式，要求视觉语言代理（VLAs）使用编程和渲染工具，根据输入图像重建其底层3D结构，实现代理逆向渲染。

研究结果: 实验表明，当前先进的VLMs在视觉精度上存在局限，而非工具使用基础能力。IR3D-Bench提供了几何精度、空间关系等多维度评估指标。

研究结论: IR3D-Bench为系统研究和开发工具使用型VLAs提供了基准，推动通过创建实现真正的场景理解。

中文摘要: 视觉语言模型（VLMs）在描述任务上表现出色，但其是否真正通过视觉观察理解场景仍不确定。我们提出了IR3D-Bench，这是一个通过主动创建而非被动识别来挑战VLMs展示场景理解能力的基准测试。基于分析-合成范式，IR3D-Bench要求视觉语言代理（VLAs）主动使用编程和渲染工具，根据输入图像重建其底层3D结构，通过工具使用实现代理逆向渲染。这种“通过创建理解”的方法探索了VLAs的工具使用生成能力，超越了传统场景理解基准测试所衡量的描述或对话能力。我们提供了一套全面的评估指标，涵盖几何精度、空间关系、外观属性和整体合理性。基于多种先进VLMs的代理逆向渲染初步实验揭示了当前模型的局限性，尤其是在视觉精度而非基础工具使用方面。IR3D-Bench包括数据和评估协议，旨在促进对工具使用型VLAs的系统研究和开发，推动通过创建实现真正的场景理解。

</details>


### [204] [CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation](https://arxiv.org/abs/2506.23347)
**中文标题：CycleVAR：将自回归模型重新用于无监督单步图像翻译**

*Yi Liu,Shengqian Li,Zuzeng Lin,Feng Wang,Si Liu*

主要分类: cs.CV

摘要简述: 本文提出CycleVAR，通过Softmax Relaxed Quantization解决传统量化方法梯度中断问题，将图像翻译重新定义为条件自回归生成任务，并在无监督场景下实现高质量、快速的单步图像翻译。


<details>
  <summary>详细信息</summary>
研究动机: 当前条件自回归图像生成方法在无监督图像翻译领域潜力未充分挖掘，传统量化方法导致梯度中断，阻碍端到端优化。本文旨在解决这一问题，提升无监督图像翻译的性能。

研究方法: 提出Softmax Relaxed Quantization，将码本选择转化为连续概率混合过程，保留梯度传播；基于此，设计CycleVAR，通过多尺度源图像标记作为上下文提示，实现图像条件自回归生成，支持串行多步和并行单步两种生成模式。

研究结果: 实验表明，并行单步生成模式在无监督场景下优于串行多步模式，翻译质量更高且推理速度更快；CycleVAR在定量和定性评估中均超越现有最优模型（如CycleGAN-Turbo）。

研究结论: CycleVAR通过创新的量化方法和自回归生成框架，显著提升了无监督图像翻译的性能，为未来研究提供了新思路。

中文摘要: 当前的条件自回归图像生成方法已显示出良好效果，但其在无监督图像翻译领域的潜力尚未充分挖掘，后者无需显式的跨域对应关系。传统基于矢量量化的框架存在离散量化问题，导致变分自编码器解码器与因果Transformer之间的梯度流中断，阻碍了图像空间中对抗训练的端到端优化。为解决这一问题，我们提出使用Softmax Relaxed Quantization，通过Softmax将码本选择重新定义为连续概率混合过程，从而保留梯度传播。基于这一可微分框架，我们提出CycleVAR，通过注入多尺度源图像标记作为上下文提示（类似于语言模型中的前缀条件），将图像翻译重新定义为图像条件视觉自回归生成任务。CycleVAR利用两种模式生成目标图像标记：（1）串行多步生成，支持跨尺度的迭代优化；（2）并行单步生成，单次前向传播即可合成所有分辨率输出。实验结果表明，在无监督场景下，并行单步生成模式的翻译质量优于串行多步模式，且推理速度更快。此外，定量和定性结果均表明，CycleVAR超越了以往最先进的无监督图像翻译模型（如CycleGAN-Turbo）。

</details>


### [205] [GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields](https://arxiv.org/abs/2506.23352)
**中文标题：GeoProg3D：面向城市级3D语言场的组合视觉推理**

*Shunsuke Yasuki,Taiki Miyanishi,Nakamasa Inoue,Shuhei Kurita,Koya Sakamoto,Daichi Azuma,Masato Taki,Yutaka Matsuo*

主要分类: cs.CV

摘要简述: GeoProg3D是一个视觉编程框架，通过自然语言实现城市级高保真3D场景的交互，结合地理感知和视觉API，显著提升了大规模3D语言场的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D语言场方法局限于小规模环境，缺乏处理复杂城市场景的可扩展性和组合推理能力。GeoProg3D旨在解决这些问题，支持城市级3D场景的自然语言交互。

研究方法: GeoProg3D包含两部分：1) 地理感知的城市级3D语言场（GCLF），利用高效分层3D模型处理大规模数据；2) 地理视觉API（GV-APIs），如区域分割和物体检测。结合大语言模型（LLMs）动态组合工具。

研究结果: 实验表明，GeoProg3D在GeoEval3D基准测试中显著优于现有3D语言场和视觉语言模型，支持多种地理视觉任务。

研究结论: GeoProg3D是首个通过自然语言实现城市级高保真3D场景组合地理推理的框架，为大规模3D交互提供了新方向。

中文摘要: 3D语言场的进步使得通过自然语言与3D场景直观交互成为可能。然而，现有方法通常局限于小规模环境，缺乏处理复杂城市场景的可扩展性和组合推理能力。为此，我们提出了GeoProg3D，一个视觉编程框架，支持通过自然语言与城市级高保真3D场景交互。GeoProg3D包含两个关键组件：(i) 地理感知的城市级3D语言场（GCLF），利用高效分层3D模型处理大规模数据，并结合地理信息（如方向、距离、海拔和地标）快速筛选城市空间；(ii) 地理视觉API（GV-APIs），如区域分割和物体检测。该框架使用大语言模型（LLMs）作为推理引擎，动态组合GV-APIs并操作GCLF，有效支持多种地理视觉任务。为评估城市级推理性能，我们提出了GeoEval3D基准数据集，包含952个查询-答案对，涵盖五个挑战性任务：定位、空间推理、比较、计数和测量。实验表明，GeoProg3D在多项任务中显著优于现有3D语言场和视觉语言模型。据我们所知，GeoProg3D是首个通过自然语言实现城市级高保真3D场景组合地理推理的框架。代码已开源：https://snskysk.github.io/GeoProg3D/。

</details>


### [206] [Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement](https://arxiv.org/abs/2506.23353)
**中文标题：面向任务的红外图像增强：层分解与形态学重建**

*Siyuan Chai,Xiaodong Guo,Tong Liu*

主要分类: cs.CV

摘要简述: 提出一种面向任务的红外图像增强方法，通过层分解和显著性信息提取，提升图像对比度并减少噪声干扰，显著改善目标检测和语义分割任务的表现。


<details>
  <summary>详细信息</summary>
研究动机: 红外图像在复杂天气条件下（如雾、雨、低光）能提升自动驾驶的感知能力，但其低对比度问题（尤其是非热辐射目标）影响下游视觉任务性能，且现有方法难以在不放大噪声和丢失信息的情况下增强对比度。

研究方法: 方法分为两部分：1) 设计红外图像层分解方法，增强场景细节并保留暗区特征；2) 提出基于形态学重建的显著性提取方法，有效提取目标信息且不放大噪声。

研究结果: 实验表明，该方法在目标检测和语义分割任务中优于现有技术，显著提升图像质量。

研究结论: 该方法通过层分解和显著性提取，解决了红外图像低对比度和噪声问题，为下游视觉任务提供了更高质量的图像。

中文摘要: 红外图像有助于提升自动驾驶在复杂天气条件（如雾、雨、低光）下的感知能力。然而，红外图像常因低对比度问题（尤其是非热辐射目标如自行车）影响下游高级视觉任务的性能。此外，如何在增强对比度的同时避免噪声放大和信息丢失仍具挑战性。为此，我们提出一种面向任务的红外图像增强方法。该方法包含两个关键部分：层分解和显著性信息提取。首先，我们设计了一种红外图像层分解方法，在增强场景细节的同时保留暗区特征，为后续显著性提取提供更多特征。其次，提出一种基于形态学重建的显著性提取方法，能有效提取并增强目标信息而不放大噪声。实验表明，该方法显著提升了目标检测和语义分割任务的图像质量，性能优于现有技术。

</details>


### [207] [OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions](https://arxiv.org/abs/2506.23361)
**中文标题：OmniVCus：基于多模态控制条件的前馈式主体驱动视频定制**

*Yuanhao Cai,He Zhang,Xi Chen,Jinbo Xing,Yiwei Hu,Yuqian Zhou,Kai Zhang,Zhifei Zhang,Soo Ye Kim,Tianyu Wang,Yulun Zhang,Xiaokang Yang,Zhe Lin,Alan Yuille*

主要分类: cs.CV

摘要简述: 本文提出了一种名为OmniVCus的新方法，用于多主体驱动的视频定制，并通过多模态控制条件（如深度、遮罩、相机和文本提示）实现视频编辑。通过构建数据管道VideoCus-Factory和引入两种嵌入机制（Lottery Embedding和Temporally Aligned Embedding），显著提升了视频定制的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法主要针对单主体视频定制，且多模态控制信号（如深度、遮罩等）的应用较少。本文旨在解决多主体视频定制中数据构建困难和控制信号利用不足的问题。

研究方法: 1. 提出数据构建管道VideoCus-Factory，从无标签的原始视频生成多主体训练数据对；2. 开发Image-Video Transfer Mixed (IVTM)训练方法，结合图像编辑数据实现视频编辑；3. 设计扩散Transformer框架OmniVCus，引入Lottery Embedding和Temporally Aligned Embedding两种嵌入机制，提升多主体推理和控制信号对齐能力。

研究结果: 实验表明，OmniVCus在定量和定性评估中均显著优于现有方法，展示了其在多主体视频定制和控制信号利用上的优势。

研究结论: 本文提出的OmniVCus方法通过创新的数据构建和嵌入机制，成功解决了多主体视频定制和控制信号利用的难题，为视频编辑领域提供了新的解决方案。

中文摘要: 现有的前馈式主体驱动视频定制方法主要研究单主体场景，原因是多主体训练数据对的构建难度较大。此外，如何利用深度、遮罩、相机和文本提示等信号控制和编辑定制视频中的主体仍是一个较少探索的挑战性问题。本文首先提出了一种数据构建管道VideoCus-Factory，用于从无标签的原始视频生成多主体定制训练数据对（如深度-视频和遮罩-视频对）。基于构建的数据，我们开发了Image-Video Transfer Mixed (IVTM)训练方法，结合图像编辑数据实现视频主体的指导性编辑。然后，我们提出了一种扩散Transformer框架OmniVCus，包含两种嵌入机制：Lottery Embedding (LE)和Temporally Aligned Embedding (TAE)。LE通过使用训练主体激活更多帧嵌入，支持更多主体的推理；TAE通过为控制和噪声令牌分配相同的帧嵌入，鼓励生成过程从时间对齐的控制信号中提取指导。实验表明，我们的方法在定量和定性评估中均显著优于现有方法。视频演示见项目页面：https://caiyuanhao1998.github.io/project/OmniVCus/。代码将发布于https://github.com/caiyuanhao1998/Open-OmniVCus。

</details>


### [208] [SIEDD: Shared-Implicit Encoder with Discrete Decoders](https://arxiv.org/abs/2506.23382)
**中文标题：SIEDD：共享隐式编码器与离散解码器**

*Vikram Rangarajan,Shishira Maiya,Max Ehrlich,Abhinav Shrivastava*

主要分类: cs.CV

摘要简述: SIEDD是一种新型神经视频压缩架构，通过共享隐式编码器和离散解码器设计，显著提升编码速度20-30倍，同时保持高质量重建和压缩比。


<details>
  <summary>详细信息</summary>
研究动机: 隐式神经表示（INR）在视频压缩中具有高保真度，但编码速度过慢，现有加速方法常牺牲重建质量或坐标级控制能力。SIEDD旨在解决这一问题。

研究方法: SIEDD采用共享隐式编码器快速捕获全局低频特征，随后冻结编码器，并行训练轻量离散解码器，通过激进坐标空间采样进一步加速。

研究结果: 在HD和4K基准测试中，SIEDD编码速度提升20-30倍，同时保持竞争性重建质量和压缩比，并保留全坐标控制能力。

研究结论: SIEDD显著提升了高保真神经视频压缩的实用性，为实际部署提供了高效可扩展的路径。

中文摘要: 隐式神经表示（INR）通过学习每视频优化函数，为视频压缩提供了卓越的保真度，但其编码时间过慢阻碍了实际应用。现有加速INR编码的方法常牺牲重建质量或自适应流媒体和转码所需的坐标级控制。我们提出SIEDD（共享隐式编码器与离散解码器），一种新型架构，从根本上加速INR编码且无需妥协。SIEDD首先在稀疏锚帧上快速训练共享的基于坐标的编码器，高效捕获全局低频视频特征。随后冻结该编码器，并行训练轻量离散解码器以处理帧组，并通过激进坐标空间采样进一步加速。这一协同设计在HD和4K基准测试中实现了20-30倍的编码速度提升，同时保持竞争性重建质量和压缩比。关键的是，SIEDD保留了全坐标控制能力，支持连续分辨率解码并消除昂贵的转码。我们的方法显著提升了高保真神经视频压缩的实用性，展示了可扩展且高效的现实部署路径。代码库见https://github.com/VikramRangarajan/SIEDD。

</details>


### [209] [A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video](https://arxiv.org/abs/2506.23414)
**中文标题：基于智能手机视频的心率测量高通量测试平台**

*Ming-Zher Poh,Jonathan Wang,Jonathan Hsu,Lawrence Cai,Eric Teasley,James A. Taylor,Jameson K. Rogers,Anupam Pathak,Shwetak Patel*

主要分类: cs.CV

摘要简述: 本文提出了一种新型高通量测试平台，用于评估基于智能手机视频的心率测量应用，解决了设备兼容性和性能评估的难题。


<details>
  <summary>详细信息</summary>
研究动机: 由于设备多样性和碎片化，基于智能手机摄像头的光电容积描记术（PPG）心率监测应用在性能评估和设备兼容性方面面临挑战。缺乏标准化测试方法，手动测试不切实际。

研究方法: 设计了一个包含12部智能手机并行测试的装置，生成可控心率和信号质量的合成PPG测试视频，并通过主机协调视频播放和数据记录。

研究结果: 系统输入与测量心率之间的平均绝对百分比误差（MAPE）为0.11%±0.001%，PPG信号的相关系数为0.92±0.008。20款智能手机模型测试结果显示所有设备均符合ANSI/CTA心率监测器精度标准（MAPE<10%）。

研究结论: 该平台为智能手机心率应用的预部署测试提供了可扩展的解决方案，可提升应用性能、确保设备兼容性，并推动移动健康领域发展。

中文摘要: 基于智能手机摄像头的光电容积描记术（PPG）心率监测应用因设备多样性和碎片化在性能评估和设备兼容性方面面临挑战。手动测试不切实际，且缺乏标准化方法。本文提出了一种新型高通量测试平台，解决了这一关键需求。该系统包括一个可并行测试12部智能手机的装置，生成可控心率和信号质量的合成PPG测试视频，以及协调视频播放和数据记录的主机。系统输入与测量心率之间的平均绝对百分比误差（MAPE）为0.11%±0.001%，PPG信号的相关系数为0.92±0.008。使用临床验证的智能手机心率应用，对20款不同智能手机模型的测试结果显示，所有设备均符合ANSI/CTA心率监测器精度标准（MAPE<10%），与一项80名参与者的前瞻性临床研究相比，显示出高阳性预测值。该平台为智能手机心率应用的预部署测试提供了可扩展的解决方案，可提升应用性能、确保设备兼容性，并推动移动健康领域发展。

</details>


### [210] [Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models](https://arxiv.org/abs/2506.23418)
**中文标题：为何满足于平庸：从概率视角看文本到图像模型中的空间关系对齐**

*Parham Rezaei,Arash Marioriyad,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

主要分类: cs.CV

摘要简述: 本文提出了一种基于概率的框架（PoS）来改进文本到图像模型中的空间关系对齐问题，并引入了新的评估指标（PSE）和生成方法（PSG），显著提升了模型在复杂空间配置上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到图像模型在生成复杂空间关系时存在对齐问题，无法准确反映输入提示中的空间配置。本文旨在通过概率建模改进这一问题。

研究方法: 1. 提出基于概率优势（PoS）的框架；2. 设计新的评估指标PSE；3. 提出无需微调的生成方法PSG，通过梯度引导或搜索策略优化空间关系。

研究结果: PSE指标比传统方法更符合人类判断，PSG方法在多个评测中优于现有技术，显著提升了空间关系对齐的准确性。

研究结论: 本文提出的概率框架和PSG方法有效解决了文本到图像模型中的空间关系对齐问题，为复杂场景生成提供了可靠工具。

中文摘要: 尽管文本到图像模型能够生成高质量、逼真且多样化的图像，但在组合生成中仍面临挑战，尤其是难以准确反映输入提示中的空间关系细节。常见的空间关系错位问题导致模型无法忠实生成符合输入提示中对象空间配置的图像。为解决这一问题，我们提出了一种新颖的概率框架，利用概率优势（PoS）概念建模场景中对象的相对空间位置。基于此，我们做出了两项关键贡献：首先，引入了一种新的评估指标PSE，用于评估文本与图像在2D和3D空间关系上的对齐程度，其更符合人类判断；其次，提出了PSG方法，一种无需微调的推理时方法，通过基于词性的PoS奖励函数优化空间关系对齐。PSG可通过两种方式实现：1）作为梯度引导机制应用于去噪步骤中的交叉注意力图；2）作为搜索策略评估初始噪声向量以选择最佳结果。大量实验表明，PSE指标相比传统中心化指标更符合人类判断，为复杂空间关系的准确性提供了更细致可靠的度量。此外，PSG显著提升了文本到图像模型生成指定空间配置的能力，在多个评测指标和基准测试中优于现有方法。

</details>


### [211] [Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles](https://arxiv.org/abs/2506.23426)
**中文标题：检测关键目标：自动驾驶中未知分布3D物体检测的新方法**

*Menna Taha,Aya Ahmed,Mohammed Karmoose,Yasser Gadallah*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的3D目标检测方法，用于自动驾驶车辆识别未知分布（OOD）物体，通过判断物体的危害性而非类别，提升自动驾驶的安全性。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶车辆（AVs）依赖目标检测模型识别周围环境，但传统方法仅能识别已知类别物体，无法有效应对OOD物体，可能导致安全隐患。本文旨在解决这一问题，通过评估物体对AV的危害性而非类别，提升检测能力。

研究方法: 该方法摒弃传统的基于类别的分类方式，转而根据物体相对于AV的位置和轨迹，将其划分为“有害”或“无害”。通过这种度量，模型能够有效检测未知物体，并指导AV做出更安全的实时决策。

研究结果: 实验结果表明，所提模型能够有效检测OOD物体，并准确评估其危害性，从而显著提升自动驾驶在动态环境中的决策效果。

研究结论: 本文提出的方法通过关注物体的危害性而非类别，解决了自动驾驶中OOD物体检测的难题，为提升AV的安全性提供了有效解决方案。

中文摘要: 自动驾驶车辆（AVs）依赖目标检测模型识别周围环境并做出驾驶决策。传统方法将物体分类为已知类别，限制了AV检测和应对未知分布（OOD）物体的能力。这一问题存在重大安全隐患，可能导致AV未能检测或误分类物体，从而引发事故。为此，我们提出了一种新颖的目标检测方法，将重点从传统的基于类别的分类转向物体危害性评估。该方法不依赖物体的具体类别，而是根据其相对于AV的位置和轨迹，将其划分为“有害”或“无害”。通过这一度量，模型能够有效检测未知物体，帮助AV做出更安全的实时决策。实验结果表明，所提模型能够有效检测OOD物体，评估其危害性并进行分类，从而提升AV在动态环境中的决策效果。

</details>


### [212] [Towards foundational LiDAR world models with efficient latent flow matching](https://arxiv.org/abs/2506.23434)
**中文标题：基于高效潜在流匹配的基础性LiDAR世界模型研究**

*Tianran Liu,Shengwen Zhao,Nicholas Rhinehart*

主要分类: cs.CV

摘要简述: 本文提出了一种基于LiDAR的基础性世界模型，通过高效的潜在流匹配技术，显著提升了模型在跨域任务中的迁移能力，同时减少了训练数据需求。


<details>
  <summary>详细信息</summary>
研究动机: 现有的LiDAR世界模型通常局限于特定领域，缺乏跨域迁移能力。本文旨在开发一种具有强迁移性的LiDAR世界模型，以解决跨域任务中的性能瓶颈。

研究方法: 提出了一种基于潜在条件流匹配（CFM）的框架，通过高效压缩LiDAR数据和优化训练目标，显著提升了模型的迁移性和计算效率。

研究结果: 实验表明，该模型在跨域任务中表现优异，仅需5%的标注数据即可超越现有语义占用预测模型，且计算效率提升了23倍。

研究结论: 本文提出的CFM框架在LiDAR世界模型中实现了显著的迁移性和效率提升，为未来研究提供了新的方向。

中文摘要: 基于LiDAR的世界模型相比基于图像的模型提供了更具结构化和几何感知的表征。然而，现有的LiDAR世界模型训练范围狭窄，每个模型仅在其构建的特定领域表现优异。我们能否开发出在多个领域表现出强迁移性的LiDAR世界模型？我们首次系统性地研究了三种高要求场景下的域迁移问题：（i）室外到室内的泛化，（ii）稀疏光束与密集光束的适应，以及（iii）非语义到语义的迁移。在不同数量的微调数据下，实验表明，单个预训练模型相比从头训练可取得高达11%的绝对提升（83%的相对提升），并在36次比较中的30次表现更优。这种动态学习的迁移性显著减少了对人工标注数据的依赖：我们的方法仅需先前模型5%的标注数据即可超越其语义占用预测性能。我们还观察到当前LiDAR世界模型的低效性，主要体现在对LiDAR数据的压缩不足和训练目标的低效性。为此，我们提出了一种基于潜在条件流匹配（CFM）的框架，仅需一半的训练数据即可实现最佳重建精度，压缩比是先前方法的6倍。我们的模型在未来轨迹条件下的语义占用预测中实现了SOTA性能，同时计算效率提升了23倍（28倍的FPS加速）；在语义占用预测中实现了SOTA性能，同时计算效率提升了2倍（1.1倍的FPS加速）。

</details>


### [213] [PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions](https://arxiv.org/abs/2506.23440)
**中文标题：PathDiff：基于未配对文本和掩码条件的组织病理学图像合成**

*Mahesh Bhosale,Abdul Wasi,Yuanhao Zhai,Yunjie Tian,Samuel Border,Nan Xi,Pinaki Sarder,Junsong Yuan,David Doermann,Xuan Gong*

主要分类: cs.CV

摘要简述: PathDiff是一种基于扩散模型的框架，能够从未配对的文本和掩码数据中学习，生成高质量的组织病理学图像，提升语义和空间细节的控制能力。


<details>
  <summary>详细信息</summary>
研究动机: 由于隐私限制，组织病理学图像数据稀缺，而现有的公共数据集缺乏配对的文本和掩码数据，限制了结合两者生成图像的能力。PathDiff旨在解决这一问题，通过整合未配对的文本和掩码数据，实现对图像语义和空间结构的精确控制。

研究方法: PathDiff采用扩散模型框架，将未配对的文本和掩码数据整合到一个统一的条件下空间，从而实现对图像结构和上下文特征的精确控制。该方法能够生成高质量且语义准确的图像。

研究结果: 实验表明，PathDiff在图像保真度、文本-图像对齐度和忠实度方面表现优异，显著提升了数据增强效果，适用于下游任务如细胞核分割和分类。

研究结论: PathDiff通过整合未配对的文本和掩码数据，成功提升了组织病理学图像生成的语义和空间控制能力，为数据增强和下游任务提供了有力支持。

中文摘要: 基于扩散的生成模型在合成组织病理学图像方面显示出潜力，以解决因隐私限制导致的数据稀缺问题。诊断文本报告提供了高级语义描述，而掩码则提供了细粒度的空间结构，对表示不同形态区域至关重要。然而，公共数据集缺乏针对同一组织病理学图像的配对文本和掩码数据，限制了它们在图像生成中的联合使用。这一限制阻碍了充分利用两种模态结合的优势以实现对语义和空间细节的增强控制。为此，我们提出了PathDiff，一种扩散框架，通过将两种模态整合到一个统一的条件下空间，从未配对的掩码-文本数据中有效学习。PathDiff能够精确控制结构和上下文特征，生成高质量且语义准确的图像。PathDiff还提升了图像保真度、文本-图像对齐度和忠实度，增强了数据增强对下游任务（如细胞核分割和分类）的效果。大量实验证明了其优于现有方法的性能。

</details>


### [214] [Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23460)
**中文标题：基于扩散特征的对比学习用于弱监督医学图像分割**

*Dewen Zeng,Xinrong Hu,Yu-Jen Chen,Yawen Wu,Xiaowei Xu,Yiyu Shi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于对比学习和扩散特征的弱监督医学图像分割方法（CLDF），通过结合梯度图和类激活图（CAMs）减少噪声，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于类激活图（CAMs）的弱监督语义分割方法存在部分激活和边界模糊的问题，而条件扩散模型（CDM）生成的显著性图易受反向扩散中背景噪声影响。本文旨在解决这些问题，提出一种更鲁棒的分割方法。

研究方法: 提出对比学习与扩散特征结合的方法（CLDF），利用冻结的条件扩散模型（CDM）生成扩散特征，并通过对比学习训练像素解码器将其映射到低维嵌入空间。结合梯度图和CAMs，减少假阳性/阴性，提升分割精度。

研究结果: 在两个公共医学数据集的四个分割任务上，CLDF方法显著优于现有基线方法。

研究结论: CLDF方法通过对比学习和扩散特征的结合，有效解决了弱监督医学图像分割中的噪声和边界模糊问题，为相关领域提供了新的解决方案。

中文摘要: 弱监督语义分割（WSSS）方法通常依赖类激活图（CAMs）定位目标，但传统CAM方法因分类与分割优化差异存在部分激活和边界模糊问题。近期，条件扩散模型（CDM）被用于WSSS中生成分割掩码，利用其针对特定类分布的图像生成能力。然而，CDM生成的显著性图易受反向扩散中背景噪声影响。为此，我们提出基于扩散特征的对比学习（CLDF），通过对比学习训练像素解码器将冻结CDM的扩散特征映射到低维嵌入空间以进行分割。具体而言，我们结合CDM外部分类器生成的梯度图与CAMs，以减少假阳性/阴性，实现鲁棒的像素嵌入学习。在两个公共医学数据集的四个分割任务上的实验结果表明，本方法显著优于现有基线。

</details>


### [215] [Time-variant Image Inpainting via Interactive Distribution Transition Estimation](https://arxiv.org/abs/2506.23461)
**中文标题：基于交互式分布转移估计的时间变异图像修复**

*Yun Xing,Qing Guo,Xiaoguang Li,Yihao Huang,Xiaofeng Cao,Di Lin,Ivor Tsang,Lei Ma*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的时间变异图像修复任务（TAMP），通过交互式分布转移估计（InDiTE）模块和扩散模型（InDiTE-Diff）解决时间变异图像修复问题，并在新构建的TAMP-Street数据集上验证了其优于现有方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统参考图像修复方法在处理时间变异图像时效果不佳，因为参考图像与目标图像存在显著内容差异且可能受损。本文旨在解决这一实际问题，提出一种新方法以提升修复效果。

研究方法: 提出交互式分布转移估计（InDiTE）模块，动态补充时间变异图像的语义信息；结合扩散模型（InDiTE-Diff），在采样过程中进行潜在交叉参考。

研究结果: 在TAMP-Street数据集上的实验表明，本文方法在两种时间变异图像修复设置下均优于现有参考图像修复方法。

研究结论: 本文提出的InDiTE模块和InDiTE-Diff方法有效解决了时间变异图像修复问题，为实际应用提供了新思路。

中文摘要: 本文聚焦于一种新颖且实用的任务，即时间变异图像修复（TAMP）。TAMP的目标是通过参考图像中的互补信息修复受损的目标图像，其中参考图像和目标图像拍摄的是同一场景但时间间隔较大。与传统参考图像修复不同，TAMP中的参考图像与目标图像内容差异显著且可能同样受损。这类应用在日常生活中常见，但现有方法因图像互补混乱而效果不佳。为此，我们提出交互式分布转移估计（InDiTE）模块，动态补充时间变异图像的语义信息以修复受损区域。为进一步提升性能，我们提出TAMP解决方案InDiTE-Diff，将InDiTE与扩散模型结合并在采样过程中进行潜在交叉参考。此外，针对TAMP任务缺乏基准数据集的问题，我们基于现有图像和掩码数据集构建了TAMP-Street数据集。实验表明，本文方法在两种时间变异图像修复设置下均优于现有参考图像修复方法。

</details>


### [216] [Sanitizing Manufacturing Dataset Labels Using Vision-Language Models](https://arxiv.org/abs/2506.23465)
**中文标题：基于视觉-语言模型的制造业数据集标签清洗方法**

*Nazanin Mahjourian,Vinh Nguyen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉-语言模型（VLSR）的标签清洗与优化框架，用于解决制造业图像数据集中标签噪声和不一致问题，显著提升数据集质量。


<details>
  <summary>详细信息</summary>
研究动机: 在制造业领域，大规模数据集常因众包或网络爬取而存在标签噪声和不一致问题，高质量标签获取成本高且耗时。本文旨在通过视觉-语言模型解决这一问题。

研究方法: 利用CLIP模型将图像和文本标签嵌入共享语义空间，通过余弦相似度计算实现标签清洗（识别无关或错误标签）和标签聚类（合并语义相似标签）。

研究结果: 在Factorynet数据集上的实验表明，VLSR能有效识别问题标签并提升标签一致性，同时通过聚类显著减少标签词汇量。

研究结论: VLSR框架能以最小人工干预提升制造业数据集的标签质量，为工业应用中稳健机器学习模型的训练提供支持。

中文摘要: 机器学习模型在工业应用中的成功很大程度上依赖于训练数据集的质量。然而，大规模数据集（尤其是通过众包和网络爬取构建的）常存在标签噪声、不一致和错误问题。这一问题在制造业领域尤为突出，因为高质量标签的获取成本高且耗时。本文提出了一种基于视觉-语言的标签清洗与优化框架（VLSR），用于多标签制造业图像数据集的标签处理。该方法利用CLIP视觉-语言模型将图像及其关联文本标签嵌入共享语义空间，并通过计算嵌入之间的余弦相似度完成两项关键任务：首先，通过比较图像-标签对的嵌入相似度，识别无关、拼写错误或语义薄弱的标签，并为每张图像筛选出最语义匹配的标签；其次，对文本嵌入进行基于密度的聚类，并通过迭代合并将语义相似的标签分组为统一标签组。实验使用包含人工标注和网络爬取噪声标签的Factorynet数据集，结果表明VLSR框架能有效识别问题标签并提升标签一致性。该方法通过聚类显著减少标签词汇量，最终以最小人工干预提升数据集质量，为工业应用中稳健机器学习模型的训练提供支持。

</details>


### [217] [AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays](https://arxiv.org/abs/2506.23467)
**中文标题：AdFair-CLIP：胸部X光的对抗公平对比语言-图像预训练**

*Chenlang Yi,Zizhan Xiong,Qi Qi,Xiyuan Wei,Girish Bathla,Ching-Long Lin,Bobak Jack Mortazavi,Tianbao Yang*

主要分类: cs.CV

摘要简述: AdFair-CLIP是一种通过对抗性特征干预减少敏感属性影响的框架，显著提升胸部X光诊断的公平性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: CLIP模型在医学图像分类中表现优异，但存在公平性问题，如种族和性别偏见，导致诊断结果不公。本文旨在解决这一问题。

研究方法: 提出AdFair-CLIP框架，利用对抗性特征干预抑制敏感属性，减少虚假相关性，提升预测公平性。

研究结果: 在胸部X光数据集上的实验表明，AdFair-CLIP显著提高了公平性和诊断准确性，并在零样本和少样本场景中保持稳健性。

研究结论: AdFair-CLIP为基于CLIP的医学诊断模型设定了公平性学习的新基准，尤其在胸部X光分析中。

中文摘要: 对比语言-图像预训练（CLIP）模型在包括医学图像分类在内的多种视觉任务中表现出色。然而，CLIP模型的公平性问题（如人口统计学偏见）未得到充分关注，导致种族和性别相关的诊断结果差异，降低了少数群体的可靠性。为解决这些问题，我们提出了AdFair-CLIP，一种通过对抗性特征干预抑制敏感属性的新框架，从而减少虚假相关性并提升预测公平性。我们在胸部X光（CXR）数据集上进行了全面实验，结果表明AdFair-CLIP显著提高了公平性和诊断准确性，同时在零样本和少样本场景中保持了稳健的泛化能力。这些结果为基于CLIP的医学诊断模型（尤其是胸部X光分析）的公平性学习设定了新基准。

</details>


### [218] [NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments](https://arxiv.org/abs/2506.23468)
**中文标题：NavMorph：一种用于连续环境中视觉与语言导航的自演进世界模型**

*Xuan Yao,Junyu Gao,Changsheng Xu*

主要分类: cs.CV

摘要简述: NavMorph是一种自演进世界模型框架，旨在提升视觉与语言导航（VLN-CE）任务中的环境理解和决策能力。通过紧凑的潜在表示建模环境动态，并结合上下文演进记忆，该方法在导航中实现了显著的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉与语言导航在连续环境（VLN-CE）中的方法难以适应新环境和导航过程中的动态变化。受人类认知启发，本文提出NavMorph，以增强环境理解和自适应决策能力。

研究方法: NavMorph采用紧凑的潜在表示建模环境动态，并结合上下文演进记忆（Contextual Evolution Memory），利用场景上下文信息支持高效导航并保持在线适应性。

研究结果: 实验表明，NavMorph在主流VLN-CE基准测试中取得了显著的性能提升。

研究结论: NavMorph通过自演进世界模型和上下文记忆机制，显著提升了VLN-CE任务中的导航性能，展示了其在复杂环境中的适应性和泛化能力。

中文摘要: 连续环境中的视觉与语言导航（VLN-CE）要求智能体在复杂环境中根据自然语言指令执行序列导航动作。现有方法往往难以泛化到新环境或适应导航过程中的动态变化。受人类认知启发，本文提出NavMorph，一种自演进世界模型框架，用于增强VLN-CE任务中的环境理解和决策能力。NavMorph利用紧凑的潜在表示建模环境动态，赋予智能体自适应规划和策略优化的前瞻能力。通过整合新颖的上下文演进记忆，NavMorph利用场景上下文信息支持高效导航，同时保持在线适应性。大量实验表明，我们的方法在主流VLN-CE基准测试中取得了显著的性能提升。代码发布于\href{https://github.com/Feliciaxyao/NavMorph}{此链接}。

</details>


### [219] [Interactive Interface For Semantic Segmentation Dataset Synthesis](https://arxiv.org/abs/2506.23470)
**中文标题：语义分割数据集合成的交互式界面**

*Ngoc-Do Tran,Minh-Tuan Huynh,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: SynthLab是一个模块化平台，用于合成视觉数据并提供用户友好的交互界面，旨在解决语义分割数据标注的高成本和隐私问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI和计算机视觉的快速发展，高质量标注数据集的需求激增，尤其是语义分割任务。然而，创建这类数据集成本高昂且涉及隐私问题。

研究方法: SynthLab采用模块化架构，支持视觉数据合成和用户友好的交互界面，用户可通过拖拽操作快速定制数据流程。

研究结果: 广泛的用户研究表明，SynthLab具有高度灵活性和可访问性，适合不同背景的用户使用。

研究结论: SynthLab为语义分割数据集的合成提供了高效、灵活的解决方案，降低了技术门槛和资源消耗。

中文摘要: AI和计算机视觉的快速发展显著增加了对高质量标注数据集的需求，尤其是语义分割任务。然而，创建这类数据集需要大量时间、人力和财力投入，且常因使用真实数据引发隐私问题。为应对这些挑战，我们推出了SynthLab，包含一个模块化的视觉数据合成平台和用户友好的界面。SynthLab的模块化架构便于维护、支持集中更新和轻松集成新功能，每个模块专注于计算机视觉任务的不同方面，提升了灵活性和适应性。同时，其交互式界面允许用户通过拖拽操作快速定制数据流程。针对不同年龄、职业和技术水平的用户进行的广泛研究表明，SynthLab具有高度灵活性和可访问性，使非技术用户也能利用AI解决实际问题。

</details>


### [220] [GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance](https://arxiv.org/abs/2506.23478)
**中文标题：GeoCD：一种用于测地线Chamfer距离的微分局部近似方法**

*Pedro Alonso,Tianrui Li,Chongshou Li*

主要分类: cs.CV

摘要简述: GeoCD是一种基于测地线距离的拓扑感知且完全可微的近似方法，用于改进3D点云学习中的Chamfer距离（CD）度量，显著提升了重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统的Chamfer距离（CD）仅依赖欧几里得距离，无法捕捉3D形状的内在几何特性。GeoCD旨在解决这一问题，提供一种更准确的度量方法。

研究方法: GeoCD通过测地线距离的拓扑感知和可微近似，替代传统的欧几里得距离，从而更好地反映3D形状的几何特性。

研究结果: 实验表明，GeoCD在不同架构和数据集上均显著提升了重建质量，仅需一个epoch的微调即可在多指标上取得显著改进。

研究结论: GeoCD作为一种新型度量方法，有效克服了传统CD的局限性，为3D点云学习提供了更优的解决方案。

中文摘要: Chamfer距离（CD）因其简单高效而广泛应用于3D点云学习，但其仅依赖欧几里得距离，无法捕捉3D形状的内在几何特性。为解决这一问题，我们提出了GeoCD，这是一种拓扑感知且完全可微的测地线距离近似方法，专为3D点云学习设计。实验表明，GeoCD在不同架构和数据集上均显著提升了重建质量。通过使用GeoCD微调原本基于标准CD训练的模型，仅需一个epoch即可在多指标上取得显著改进。

</details>


### [221] [Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting](https://arxiv.org/abs/2506.23479)
**中文标题：即时高斯图像：一种基于2D高斯泼溅的通用自适应图像表示方法**

*Zhaojie Zeng,Yuesong Wang,Chao Yang,Tao Guan,Lili Ju*

主要分类: cs.CV

摘要简述: 本文提出了一种基于2D高斯泼溅的通用自适应图像表示框架，显著降低训练时间并动态调整高斯点数量以适应图像复杂度，实验表明其性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 隐式神经表示（INR）在图像表示领域表现优异，但计算成本高。GaussianImage虽通过高斯泼溅降低成本，但训练慢且高斯点数量固定，限制了其适应性。本文旨在解决这些问题。

研究方法: 提出一种基于2D高斯泼溅的框架，通过快速生成粗略高斯表示并进行少量微调，显著减少训练时间，同时动态调整高斯点数量以适应图像复杂度。

研究结果: 在DIV2K和Kodak数据集上，该方法以更少的迭代和更短的训练时间匹配或超越GaussianImage的渲染性能，训练时间减少高达一个数量级。

研究结论: 该方法在保持高质量渲染的同时，显著提升了训练效率和适应性，为图像表示领域提供了更实用的解决方案。

中文摘要: 隐式神经表示（INR）在图像表示领域取得了显著进展，但需要大量GPU资源。GaussianImage首次利用高斯泼溅降低了成本，但训练速度慢且高斯点数量固定，限制了其适应性。为解决这些问题，本文提出了一种基于2D高斯泼溅的通用自适应图像表示框架。该方法通过快速生成粗略高斯表示并进行少量微调，在保持与GaussianImage相当渲染质量的同时，显著减少了训练时间。此外，该方法根据图像复杂度动态调整高斯点数量，进一步提升了灵活性和效率。在DIV2K和Kodak数据集上的实验表明，该方法以更少的迭代和更短的训练时间匹配或超越了GaussianImage的渲染性能。具体而言，该方法在相同高斯点数量下，训练时间减少高达一个数量级，同时实现了更优的渲染性能。

</details>


### [222] [Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks](https://arxiv.org/abs/2506.23481)
**中文标题：多模态大语言模型的地理定位能力评估及相关隐私风险分析**

*Xian Zhang,Xiang Cheng*

主要分类: cs.CV

摘要简述: 多模态大语言模型（MLLMs）在地理定位任务中表现出色，准确率高达49%（1公里半径内），但也带来隐私泄露风险。研究分析了相关技术，并提出应对措施。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）推理能力的提升，其能够通过视觉内容推断地理位置，引发隐私和伦理问题。研究旨在评估其地理定位能力及潜在风险。

研究方法: 研究系统分析了现有基于MLLMs的地理定位技术，并通过文献综述和实验评估了视觉推理模型在街景图像定位任务中的表现。

研究结果: 实验表明，最先进的视觉大模型能在1公里半径内以49%的准确率定位街景图像的来源，突显其从视觉数据中提取地理线索的强大能力。

研究结论: 研究总结了影响地理定位成功的关键视觉元素（如文本、建筑风格等），并探讨了MLLMs带来的隐私风险及技术和政策层面的应对措施。

中文摘要: 目标：多模态大语言模型（MLLMs）的快速发展显著提升了其推理能力，推动了多种智能应用。然而，这些进步也引发了隐私和伦理方面的重大担忧。MLLMs现在能够仅通过视觉内容推断图像的地理位置（如社交媒体分享的图片或街景图像），从而带来严重的隐私侵犯风险，包括人肉搜索、监控和其他安全威胁。
方法：本研究全面分析了基于MLLMs的现有地理定位技术，系统回顾了相关文献，并评估了最先进的视觉推理模型在地理定位任务中的表现，尤其是在识别街景图像来源方面的能力。
结果：实证评估显示，最先进的视觉大模型能够在1公里半径内以高达49%的准确率定位街景图像的来源。这一表现凸显了模型从视觉数据中提取和利用细粒度地理线索的强大能力。
结论：基于这些发现，研究总结了影响地理定位成功的关键视觉元素（如文本、建筑风格和环境特征），并探讨了MLLMs带来的隐私影响，提出了技术和政策层面的应对措施以降低相关风险。代码和数据集可在https://github.com/zxyl1003/MLLM-Geolocation-Evaluation获取。

</details>


### [223] [MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting](https://arxiv.org/abs/2506.23482)
**中文标题：MTADiffusion：用于物体修复的掩码-文本对齐扩散模型**

*Jun Huang,Ting Liu,Yihang Wu,Xiaochao Qu,Luoqi Liu,Xiaolin Hu*

主要分类: cs.CV

摘要简述: MTADiffusion是一种用于物体修复的掩码-文本对齐扩散模型，通过MTAPipeline自动标注掩码和详细描述，构建了包含500万图像和2500万掩码-文本对的数据集，采用多任务训练策略和风格一致性损失，显著提升了修复的语义对齐、结构稳定性和风格一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像修复方法存在语义不对齐、结构扭曲和风格不一致等问题，MTADiffusion旨在通过掩码-文本对齐和风格一致性优化解决这些问题。

研究方法: 提出MTAPipeline自动标注掩码和描述，构建MTADataset；采用多任务训练策略结合修复和边缘预测任务；引入基于预训练VGG网络和Gram矩阵的风格一致性损失。

研究结果: 在BrushBench和EditBench上的评估表明，MTADiffusion在语义对齐、结构稳定性和风格一致性方面优于其他方法。

研究结论: MTADiffusion通过掩码-文本对齐、多任务训练和风格一致性优化，显著提升了物体修复的性能，成为当前最佳方法。

中文摘要: 生成模型的进步使得图像修复模型能够根据提供的提示和掩码在图像的特定区域生成内容。然而，现有的修复方法常存在语义不对齐、结构扭曲和风格不一致等问题。本文提出MTADiffusion，一种用于物体修复的掩码-文本对齐扩散模型。为增强修复模型的语义能力，我们引入MTAPipeline，一种自动标注掩码和详细描述的解决方案。基于MTAPipeline，我们构建了包含500万图像和2500万掩码-文本对的新数据集MTADataset。此外，我们提出一种多任务训练策略，结合修复和边缘预测任务以提升结构稳定性。为促进风格一致性，我们提出一种基于预训练VGG网络和Gram矩阵的新型修复风格一致性损失。在BrushBench和EditBench上的全面评估表明，MTADiffusion相比其他方法达到了最先进的性能。

</details>


### [224] [Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding](https://arxiv.org/abs/2506.23491)
**中文标题：Qwen-GUI-3B：一种用于跨分辨率GUI定位的轻量级视觉语言模型**

*ZongHan Hsieh,Tzer-Jen Wei*

主要分类: cs.CV

摘要简述: 本文介绍了Qwen-GUI-3B，一种轻量级的视觉语言模型（VLM），专为图形用户界面（GUI）定位任务设计，性能可与更大模型媲美。该模型通过跨平台多分辨率数据集、两阶段微调策略及数据优化方法，实现了在单GPU上的高效训练，并在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前大规模视觉语言模型（>7B参数）计算资源需求高，难以在消费级硬件上运行。为了解决这一问题，本文提出了一种轻量级模型Qwen-GUI-3B，旨在在保持高性能的同时，降低计算成本，使其适用于实际应用场景。

研究方法: Qwen-GUI-3B采用了以下创新方法：(i) 使用跨平台、多分辨率的24K数据集，涵盖移动、桌面和网页GUI截图；(ii) 两阶段微调策略，先进行跨平台训练，再针对高分辨率数据进行专门微调；(iii) 数据优化策略，通过减少冗余和平衡采样，提升模型性能。

研究结果: 在标准GUI定位基准测试（如ScreenSpot、ScreenSpot-v2和ScreenSpot-Pro）中，Qwen-GUI-3B表现出色，分别达到84.9%和86.4%的准确率，优于同类4B参数以下的模型。消融实验验证了平衡采样和两阶段微调对模型鲁棒性的关键作用。

研究结论: Qwen-GUI-3B通过轻量化设计和高效训练策略，成功解决了大规模模型的计算资源问题，同时保持了高性能。其开源发布为GUI定位任务提供了实用的解决方案。

中文摘要: 本文介绍了Qwen-GUI-3B，一种专为图形用户界面（GUI）定位任务设计的轻量级视觉语言模型（VLM），其性能可与更大规模的模型媲美。与计算密集型的大规模VLM（>7B参数）不同，Qwen-GUI-3B在单GPU（RTX 4090）上即可完成训练，同时保持较高的定位精度。该模型的关键创新包括：(i) 结合跨平台、多分辨率的24K数据集，涵盖移动、桌面和网页GUI截图，有效解决了高分辨率桌面环境中的数据稀缺问题；(ii) 两阶段微调策略，首先进行跨平台训练以建立鲁棒的GUI理解能力，随后针对高分辨率数据进行专门微调，显著提升模型适应性；(iii) 数据优化和冗余减少策略，证明通过随机采样减少冗余的小规模数据集可以达到与大规模数据集相当的性能，强调数据多样性而非数量。在标准GUI定位基准测试（包括ScreenSpot、ScreenSpot-v2和挑战性的ScreenSpot-Pro）中，Qwen-GUI-3B表现出色，在ScreenSpot上达到84.9%的准确率，在ScreenSpot-v2上达到86.4%，超越了4B参数以下的先前模型。消融研究验证了平衡采样和两阶段微调对增强模型鲁棒性的关键作用，尤其是在高分辨率桌面场景中。Qwen-GUI-3B已在以下地址开源：https://github.com/Han1018/Qwen-GUI-3B。

</details>


### [225] [LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching](https://arxiv.org/abs/2506.23502)
**中文标题：基于LLM增强的动作感知多模态提示调优用于图像-文本匹配**

*Mengxiao Tian,Xinxiao Wu,Shuo Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于LLM增强的动作感知多模态提示调优方法，通过引入动作相关的知识提升CLIP模型在图像-文本匹配任务中的细粒度动作理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管CLIP等大规模对比视觉-语言预训练模型在图像-文本匹配任务中取得了显著成功，但其在理解细粒度细节（如对象属性和空间关系）方面仍存在不足。特别是缺乏对动作的感知能力，而动作对于描述对象状态或关系至关重要。因此，本文旨在通过引入LLM生成的动作相关知识，增强CLIP的细粒度动作理解能力。

研究方法: 本文设计了动作三元组提示和动作状态提示，利用LLM中隐含的组合语义知识和状态相关因果知识。进一步提出自适应交互模块，聚合基于动作感知提示知识的视觉特征，以建立更具区分性和动作感知的视觉表示。

研究结果: 在两个基准数据集上的综合实验结果表明，该方法显著提升了图像-文本匹配任务的性能。

研究结论: 通过引入LLM生成的动作相关知识，本文提出的方法有效增强了CLIP模型在细粒度动作理解方面的能力，为图像-文本匹配任务提供了新的解决方案。

中文摘要: 受CLIP等大规模对比视觉-语言预训练模型的推动，图像-文本匹配任务在表示学习方面取得了显著进展。然而，由于图像级别的视觉-语言对齐，CLIP在理解细粒度细节（如对象属性和对象间空间关系）方面存在不足。尽管近期研究尝试通过引入提示学习实现对象级对齐并取得了一定成果，但仍缺乏对动作的感知能力，而动作对于描述对象状态或关系至关重要。为此，我们提出通过引入大型语言模型（LLM）生成的动作相关知识，赋予CLIP细粒度动作理解能力，设计了一种基于LLM增强的动作感知多模态提示调优方法。具体而言，我们设计了动作三元组提示和动作状态提示，以利用LLM中隐含的组合语义知识和状态相关因果知识。随后，提出了一种自适应交互模块，用于聚合基于动作感知提示知识的视觉特征，从而建立更具区分性和动作感知的视觉表示，进一步提升性能。在两个基准数据集上的综合实验结果表明，我们的方法具有显著的有效性。

</details>


### [226] [Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation](https://arxiv.org/abs/2506.23505)
**中文标题：基于YOLOv12架构和物理信息增强的水下目标检测改进**

*Tinh Nguyen*

主要分类: cs.CV

摘要简述: 本文提出了一种结合YOLOv12架构和物理信息增强技术的方法，显著提升了水下目标检测的精度和实时性，解决了低能见度环境下的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 水下目标检测在自主导航、环境监测和海洋探索中至关重要，但受限于光线衰减、浑浊和遮挡等问题。现有方法在实时性和精度上难以兼顾，尤其在低能见度条件下表现不佳。

研究方法: 通过将物理信息增强技术与YOLOv12架构结合，采用Residual ELAN模块保留浑浊水域的结构特征，以及Area Attention机制维持大感受野以处理遮挡目标。此外，设计了领域特定的增强方法，如湍流自适应模糊、生物启发的遮挡模拟和光谱HSV变换。

研究结果: 在四个复杂数据集上的测试表明，该方法达到了最先进的性能，Brackish数据集的mAP达到98.30%，帧率为142 FPS。相比之前模型，YOLOv12在遮挡鲁棒性、小目标召回率和检测精度上分别提升了18.9%、22.4%和7.94%。

研究结论: 本研究为水下机器人和保护应用提供了一种高效且精确的解决方案，并通过消融实验验证了增强策略的关键作用。

中文摘要: 水下目标检测对于自主导航、环境监测和海洋探索至关重要，但受光线衰减、浑浊和遮挡的严重影响。现有方法在精度和计算效率之间寻求平衡，但在低能见度条件下的实时部署仍面临困难。本研究通过将物理信息增强技术与YOLOv12架构结合，推动了水下检测的发展。采用Residual ELAN模块保留浑浊水域的结构特征，并通过Area Attention机制维持大感受野以处理遮挡目标，同时降低计算复杂度。针对水下光学特性，设计了领域特定的增强方法，如湍流自适应模糊、生物启发的遮挡模拟和光谱HSV变换以应对颜色失真。在四个复杂数据集上的广泛测试表明，该方法达到了最先进的性能，Brackish数据集的mAP达到98.30%，帧率为142 FPS。相比之前模型，YOLOv12在遮挡鲁棒性上提升了18.9%，小目标召回率提高了22.4%，检测精度最高提升了7.94%。消融研究验证了增强策略的关键作用。本研究为保护和水下机器人应用提供了一种精确且高效的解决方案。

</details>


### [227] [ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models](https://arxiv.org/abs/2506.23513)
**中文标题：ViewPoint：基于预训练扩散模型的全景视频生成**

*Zixun Fang,Kai Zhu,Zhiheng Liu,Yu Liu,Wei Zhai,Yang Cao,Zheng-Jun Zha*

主要分类: cs.CV

摘要简述: 本文提出了一种利用预训练视角视频模型生成全景视频的新框架，通过设计ViewPoint图和Pano-Perspective注意力机制，解决了全景数据与视角数据之间的模态差距问题，实现了高质量全景视频的合成。


<details>
  <summary>详细信息</summary>
研究动机: 全景视频生成在VR、世界模型和空间智能领域具有重要意义，但现有方法因全景数据与视角数据之间的模态差距，难以合成高质量全景视频。本文旨在利用预训练视角视频模型解决这一问题。

研究方法: 提出了一种名为ViewPoint图的全景表示方法，兼具全局空间连续性和细粒度视觉细节。通过Pano-Perspective注意力机制，模型能够有效利用预训练视角先验并捕捉全景空间相关性。

研究结果: 实验表明，该方法能够合成高度动态且空间一致的全景视频，性能优于现有方法，达到最先进水平。

研究结论: 本文提出的框架成功解决了全景视频生成的模态差距问题，为高质量全景视频合成提供了有效解决方案。

中文摘要: 全景视频生成旨在合成360度沉浸式视频，在VR、世界模型和空间智能领域具有重要意义。现有方法因全景数据与视角数据之间的模态差距，难以合成高质量全景视频。本文提出了一种利用预训练视角视频模型生成全景视频的新框架。具体而言，我们设计了一种名为ViewPoint图的全景表示方法，兼具全局空间连续性和细粒度视觉细节。通过提出的Pano-Perspective注意力机制，模型能够有效利用预训练视角先验并捕捉ViewPoint图的全景空间相关性。大量实验表明，我们的方法能够合成高度动态且空间一致的全景视频，性能优于现有方法，达到最先进水平。

</details>


### [228] [WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image](https://arxiv.org/abs/2506.23518)
**中文标题：WAVE：基于变形的视角引导技术用于单图像一致新视角合成**

*Jiwoo Park,Tae Eun Choi,Youngjun Jun,Seong Jae Hwang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于单图像生成高质量新视角的方法WAVE，通过无训练的视角引导变形技术增强扩散模型，显著提升了视角一致性。


<details>
  <summary>详细信息</summary>
研究动机: 从单图像生成新视角时，保持视角一致性是一个关键挑战。现有扩散模型虽在生成新视角方面有所进展，但在空间连续性上表现不足。结合3D模型的方法效率低下，因此需要一种无需额外模块的高效解决方案。

研究方法: 本文提出了一种无训练的视角一致性图像生成方法，通过视角引导变形技术自适应调整注意力机制和噪声初始化，从而增强扩散模型的视角一致性。

研究结果: 通过适用于新视角数据集的综合评估框架，实验表明该方法显著提升了多种扩散模型的视角一致性，证明了其广泛适用性。

研究结论: WAVE方法通过视角引导变形技术有效提升了扩散模型在新视角生成中的一致性，且无需额外模块，具有高效性和广泛适用性。

中文摘要: 从单图像生成高质量的新视角场景需要保持不同视角间的结构一致性，即视角一致性。尽管扩散模型在新视角合成方面取得了进展，但在保持视角间的空间连续性方面仍存在困难。虽然已有研究将扩散模型与3D模型结合以解决这一问题，但这类方法因复杂的多步流程而效率低下。本文提出了一种无需额外模块的视角一致性图像生成方法，其核心思想是通过视角引导变形技术实现自适应注意力调整和噪声重新初始化，从而增强扩散模型的视角一致性。通过适用于新视角数据集的综合评估框架，实验表明该方法显著提升了多种扩散模型的视角一致性，证明了其广泛适用性。

</details>


### [229] [From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection](https://arxiv.org/abs/2506.23519)
**中文标题：从视觉到洞察：释放眼动追踪在弱监督视频显著目标检测中的潜力**

*Qi Qin,Runmin Cong,Gen Zhan,Yiting Liao,Sam Kwong*

主要分类: cs.CV

摘要简述: 本文提出了一种利用眼动追踪数据辅助弱监督视频显著目标检测的方法，通过位置和语义嵌入模块以及时空特征建模，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 眼动追踪数据更易获取且更符合人眼真实视觉模式，因此本文旨在利用这些数据辅助弱监督下的视频显著目标检测，以提升检测效果。

研究方法: 提出了位置和语义嵌入（PSE）模块以提供特征学习中的位置和语义指导；设计了语义和局部查询（SLQ）竞争器以选择最佳对象查询进行时空建模；并通过内-外混合对比（IIMC）模型增强弱监督下的时空建模能力。

研究结果: 在五个流行的视频显著目标检测基准测试中，所提模型在多种评估指标上均优于其他竞争对手。

研究结论: 通过结合眼动追踪数据和弱监督学习，本文方法显著提升了视频显著目标检测的性能，为实际应用提供了有效解决方案。

中文摘要: 眼动追踪视频显著性预测（VSP）任务和视频显著目标检测（VSOD）任务均关注视频中最吸引人的对象，并分别以预测热图和像素级显著性掩码的形式呈现结果。在实际应用中，眼动追踪注释更易获取且更符合人眼的真实视觉模式。因此，本文旨在引入注视信息以辅助弱监督下的视频显著目标检测。一方面，我们探讨如何更好地探索和利用注视信息，并提出位置和语义嵌入（PSE）模块，在特征学习过程中提供位置和语义指导。另一方面，我们从特征选择和特征对比的角度实现了弱监督下的时空特征建模。设计了具有语义和局部约束的语义和局部查询（SLQ）竞争器，以有效选择最匹配和准确的对象查询进行时空建模。此外，内-外混合对比（IIMC）模型通过形成视频内和视频间的对比学习范式，提升了弱监督下的时空建模能力。在五个流行的VSOD基准测试上的实验结果表明，我们的模型在多种评估指标上均优于其他竞争对手。

</details>


### [230] [Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving](https://arxiv.org/abs/2506.23523)
**中文标题：轻量级时序Transformer分解用于联邦自动驾驶**

*Tuong Do,Binh X. Nguyen,Quang D. Tran,Erman Tjiputra,Te-Chuan Chiu,Anh Nguyen*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级时序Transformer分解方法，用于联邦学习的自动驾驶系统，通过分解大注意力图为小矩阵，降低模型复杂度，同时提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于视觉的自动驾驶系统在复杂环境中依赖单帧图像输入时表现不佳，而现有高性能方法通常依赖资源密集的融合网络，不适合联邦学习。本文旨在解决这些问题。

研究方法: 提出轻量级时序Transformer分解方法，通过分解大注意力图为小矩阵处理时序图像帧和转向数据，降低模型复杂度，实现高效权重更新和实时预测。

研究结果: 在三个数据集上的实验表明，该方法显著优于现有方法，并实现实时性能。真实机器人实验进一步验证了其有效性。

研究结论: 本文提出的方法在降低模型复杂度的同时，有效提升了自动驾驶系统的性能，适用于联邦学习和实时应用。

中文摘要: 传统基于视觉的自动驾驶系统在仅依赖单帧图像输入时，往往难以应对复杂环境。为解决这一问题，引入时序数据（如历史图像帧或转向序列）已被证明能显著提升系统在挑战性场景中的鲁棒性和适应性。尽管已有高性能方法，但它们通常依赖资源密集的融合网络，导致训练不切实际且不适合联邦学习。为应对这些挑战，我们提出轻量级时序Transformer分解方法，通过将大注意力图分解为小矩阵处理时序图像帧和转向数据。该方法降低了模型复杂度，实现了高效的权重更新和实时预测，同时利用时序信息提升自动驾驶性能。在三个数据集上的大量实验表明，我们的方法明显优于现有方法，并实现实时性能。此外，真实机器人实验进一步验证了该方法的有效性。

</details>


### [231] [When Test-Time Adaptation Meets Self-Supervised Models](https://arxiv.org/abs/2506.23529)
**中文标题：当测试时自适应遇上自监督模型**

*Jisu Han,Jihee Park,Dongyoon Han,Wonjun Hwang*

主要分类: cs.CV

摘要简述: 本文研究了测试时自适应（TTA）方法如何在不依赖源预训练的情况下持续改进自监督学习（SSL）模型，并提出了一种结合SSL和TTA的协作学习框架，通过对比学习和知识蒸馏逐步优化表示。


<details>
  <summary>详细信息</summary>
研究动机: 当前测试时自适应方法高度依赖源预训练模型的性能，而自监督模型在源域上表现不佳时直接应用TTA效果有限。本文旨在探索如何在不依赖源预训练的情况下，通过TTA持续提升自监督模型的性能。

研究方法: 提出了一种自监督TTA协议，并设计了一个协作学习框架，结合对比学习和知识蒸馏，逐步优化模型表示。该方法适用于多种自监督模型（如DINO、MoCo、iBOT）和TTA基准测试。

研究结果: 实验表明，该方法在自监督学习中表现优异，即使不依赖源预训练，也能达到与现有方法竞争的性能。

研究结论: 本文提出的协作学习框架为自监督模型在测试时自适应任务中提供了一种有效的解决方案，展示了在不依赖源预训练的情况下持续优化模型的潜力。

中文摘要: 通过测试时数据训练，深度学习模型能够适应动态环境变化，提升实际应用能力。从源域到目标域的在线自适应具有潜力，但其性能仍高度依赖源预训练模型。本文研究了测试时自适应（TTA）方法是否能在不依赖源预训练的情况下持续改进自监督学习（SSL）模型。我们发现现有TTA方法在直接应用于源域精度较低的自监督模型时效果不佳，因此提出了一种自监督TTA协议。此外，我们设计了一个协作学习框架，结合SSL和TTA模型，利用对比学习和知识蒸馏逐步优化表示。我们在多种自监督模型（如DINO、MoCo、iBOT）和TTA基准测试上验证了方法的有效性。大量实验表明，即使不依赖源预训练，我们的方法在自监督学习中仍能取得竞争性表现。

</details>


### [232] [GViT: Representing Images as Gaussians for Visual Recognition](https://arxiv.org/abs/2506.23532)
**中文标题：GViT：将图像表示为高斯分布以进行视觉识别**

*Jefferson Hernandez,Ruozhen He,Guha Balakrishnan,Alexander C. Berg,Vicente Ordonez*

主要分类: cs.CV

摘要简述: GViT提出了一种新颖的图像分类框架，通过将图像表示为可学习的2D高斯分布而非传统像素或网格，结合ViT分类器，实现了与传统方法相当的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统视觉识别方法通常基于像素或网格表示，限制了模型的灵活性和效率。GViT旨在通过高斯表示提供更紧凑且可学习的输入形式，同时利用ViT分类器的梯度引导高斯分布聚焦于关键区域。

研究方法: GViT将图像编码为数百个可学习的2D高斯分布，优化其位置、尺度、方向、颜色和透明度。结合ViT分类器，利用分类器梯度引导高斯分布聚焦于类别显著区域，并通过可微分渲染器优化图像重建损失。

研究结果: 实验表明，GViT在ViT-B架构下达到76.9%的ImageNet-1k top-1准确率，性能接近传统的基于网格的ViT方法。

研究结论: GViT展示了高斯表示在视觉识别中的潜力，提供了一种高效且灵活的替代方案，同时保持了与传统方法相当的性能。

中文摘要: 我们提出了GViT，一种分类框架，摒弃了传统的像素或网格输入表示，转而采用一组紧凑的可学习2D高斯分布。每张图像被编码为数百个高斯分布，其位置、尺度、方向、颜色和透明度与基于这些表示的ViT分类器联合优化。我们重用分类器梯度作为构造性引导，将高斯分布导向类别显著区域，同时通过可微分渲染器优化图像重建损失。实验表明，通过2D高斯输入表示结合GViT的引导，使用相对标准的ViT架构，性能接近传统的基于网格的ViT，在ViT-B架构下达到76.9%的ImageNet-1k top-1准确率。

</details>


### [233] [Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound](https://arxiv.org/abs/2506.23538)
**中文标题：基于不确定性感知扩散和强化学习的3D超声联合平面定位与异常诊断**

*Yuhao Huang,Yueyue Xu,Haoran Dou,Jiaxiao Deng,Xin Yang,Hongyu Zheng,Dong Ni*

主要分类: cs.CV

摘要简述: 本文提出了一种智能系统，用于同时实现3D超声中的平面定位和先天性子宫异常诊断。方法结合了去噪扩散模型和强化学习，通过自适应权重策略和不确定性建模提升性能。实验验证了其在平面定位和诊断中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 先天性子宫异常（CUAs）可能导致不孕、流产和妊娠并发症。3D超声能重建冠状平面，为CUAs的准确评估提供清晰图像。然而，现有方法在平面定位和诊断的自动化方面仍有不足，因此需要一种更智能的系统来解决这些问题。

研究方法: 1) 开发了一种结合局部（平面）和全局（体积/文本）引导的去噪扩散模型，采用自适应权重策略优化注意力分配；2) 引入基于强化学习的框架，通过无监督奖励从冗余序列中提取关键切片摘要，整合多平面信息以降低学习难度；3) 提供文本驱动的不确定性建模，用于粗预测并调整分类概率以提升整体性能。

研究结果: 在大型3D子宫超声数据集上的实验表明，该方法在平面定位和CUAs诊断方面表现出色，验证了其有效性。

研究结论: 本文提出的智能系统通过结合扩散模型和强化学习，成功实现了3D超声中的平面定位和CUAs诊断，为临床提供了高效且准确的解决方案。

中文摘要: 先天性子宫异常（CUAs）可能导致不孕、流产、早产及妊娠并发症风险增加。与传统2D超声相比，3D超声可重建冠状平面，为CUAs的准确评估提供清晰的子宫形态可视化。本文提出了一种智能系统，用于同时实现自动化平面定位和CUAs诊断。主要贡献包括：1) 开发了一种结合局部（平面）和全局（体积/文本）引导的去噪扩散模型，采用自适应权重策略优化注意力分配；2) 引入基于强化学习的框架，通过无监督奖励从冗余序列中提取关键切片摘要，整合多平面信息以降低学习难度；3) 提供文本驱动的不确定性建模用于粗预测，并利用其调整分类概率以提升整体性能。在大型3D子宫超声数据集上的实验验证了该方法在平面定位和CUAs诊断中的有效性。代码发布于https://github.com/yuhoo0302/CUA-US。

</details>


### [234] [Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention](https://arxiv.org/abs/2506.23542)
**中文标题：基于图结构几何注意力的一致ToF深度去噪**

*Weida Wang,Changyong He,Jin Zeng,Di Qiu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图结构几何注意力的ToF深度去噪网络，通过运动不变的图融合技术，显著提升了时间稳定性和空间清晰度，并在合成和真实数据集上验证了其优越性能。


<details>
  <summary>详细信息</summary>
研究动机: ToF传感器捕获的深度图像易受噪声影响，现有方法多聚焦于单帧处理或多帧处理未考虑深度变化，导致时间不一致和空间模糊。本文旨在解决这些问题。

研究方法: 利用图结构的时序自相似性设计几何注意力机制，结合图像平滑先验和ToF噪声分布的数据保真项，构建最大后验问题，并通过迭代滤波器实现高效去噪。

研究结果: 在合成DVToF数据集和真实Kinectv2数据集上，所提方法在精度和一致性上均达到最先进水平，并展现出良好的泛化能力。

研究结论: 本文提出的图结构几何注意力网络有效解决了ToF深度去噪中的时间和空间不一致问题，为实际应用提供了高性能且可解释的解决方案。

中文摘要: ToF传感器捕获的深度图像易受噪声影响，需去噪以支持可靠的下游应用。现有方法或专注于单帧处理，或在多帧处理中未考虑帧间对应像素的深度变化，导致时间不一致和空间模糊。本文提出一种新颖的ToF深度去噪网络，利用运动不变的图融合技术，同时提升时间稳定性和空间清晰度。具体而言，尽管帧间深度存在变化，图结构仍表现出时序自相似性，支持跨帧几何注意力进行图融合。通过结合图像平滑先验和基于ToF噪声分布的数据保真项，我们构建了ToF去噪的最大后验问题。最终，该问题的解被展开为迭代滤波器，其权重通过图结构几何注意力自适应学习，形成一个高性能且可解释的网络。实验结果表明，所提方法在合成DVToF数据集上实现了精度和一致性的最先进性能，并在真实Kinectv2数据集上展现出鲁棒的泛化能力。源代码发布于https://github.com/davidweidawang/GIGA-ToF。

</details>


### [235] [Pyramidal Patchification Flow for Visual Generation](https://arxiv.org/abs/2506.23543)
**中文标题：金字塔式分块流用于视觉生成**

*Hui Li,Baoyou Chen,Liwei Zhang,Jiaye Li,Jingdong Wang,Siyu Zhu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为金字塔式分块流（PPFlow）的新方法，用于视觉生成任务。通过在不同噪声时间步使用不同大小的分块，并结合线性投影和修改的解块化操作，PPFlow在保持生成性能的同时显著提升了推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的扩散变换器（DiTs）采用单一分块大小，限制了计算效率的优化。本文旨在通过动态调整分块大小以适应不同噪声时间步的需求，从而提升视觉生成的效率和性能。

研究方法: PPFlow方法在不同噪声时间步使用不同大小的分块：高噪声时间步使用大分块，低噪声时间步使用小分块。为每个分块大小学习线性投影，并相应修改解块化操作。该方法在完整潜在表示上操作，无需金字塔表示或重新噪声技巧。

研究结果: 实验表明，PPFlow在从头训练时，2级和3级金字塔分块分别实现了1.6倍和2.0倍的推理速度提升，且训练FLOPs略低，生成性能相近。从预训练DiTs微调时，性能更优且训练时间短。

研究结论: PPFlow通过动态分块策略显著提升了视觉生成的效率，同时保持了生成质量，为扩散变换器的优化提供了新思路。

中文摘要: 扩散变换器（DiTs）采用分块化（Patchify）方法，通过线性投影将分块表示映射为令牌表示，以调整输入DiT块的令牌数量及计算成本。不同于所有时间步使用单一分块大小，本文提出金字塔式分块流（PPFlow）方法：高噪声时间步使用大分块，低噪声时间步使用小分块；为每个分块大小学习线性投影；并相应修改解块化操作。与金字塔流不同，PPFlow在完整潜在表示上操作，而非金字塔表示，且采用常规去噪过程，无需重新噪声技巧。通过两种训练方式验证了方法的有效性。从头训练时，2级（3级）金字塔分块在推理速度上比SiT-B/2快1.6倍（2.0倍），训练FLOPs略低且生成性能相近。从预训练DiTs微调时，性能更优且训练时间短。代码和模型见https://github.com/fudan-generative-vision/PPFlow。

</details>


### [236] [Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions](https://arxiv.org/abs/2506.23547)
**中文标题：Oneta：基于特征变换函数的多风格图像增强方法**

*Jiwon Kim,Soohyun Hwang,Dong-O Kim,Changsu Han,Min Kyu Park,Chang-Su Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Oneta的多风格图像增强算法，通过两步操作（强度增强和色彩校正）实现高效性能，并引入特征变换函数紧凑表示。Oneta网络支持多种风格，实验证明其在六类增强任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像增强方法通常针对单一风格或任务，缺乏通用性。本文旨在开发一种能够处理多种风格和任务的统一图像增强算法，提升效率和性能。

研究方法: Oneta采用两步操作：首先通过变换函数（TF）进行强度增强，其次通过色彩校正矩阵（CCM）进行色彩校正。引入特征变换函数（eigenTF）紧凑表示TF，并通过Y-Net和C-Net分别预测eigenTF和CCM参数。支持K种风格，每种风格对应一个可学习令牌。

研究结果: 实验表明，Oneta在六类增强任务（如修图、低光增强、去雾等）中表现优异，能够高效处理30个数据集，验证了其通用性和高性能。

研究结论: Oneta作为一种多风格图像增强算法，通过两步操作和特征变换函数实现了高效和通用性，为图像增强领域提供了新的解决方案。

中文摘要: 本文首次提出了一种名为Oneta的多风格图像增强算法。Oneta通过两步操作实现图像增强：首先使用变换函数（TF）进行强度增强，其次通过色彩校正矩阵（CCM）进行色彩校正。尽管模型简单，但其性能上限较高。此外，本文引入了特征变换函数（eigenTF）以紧凑表示TF。Oneta网络由Y-Net和C-Net组成，分别用于预测eigenTF和CCM参数。为支持K种风格，Oneta采用K个可学习令牌。训练时，每个风格令牌通过对应数据集的图像对进行学习；测试时，Oneta选择其中一个令牌进行图像增强。大量实验表明，单个Oneta网络可有效完成六类增强任务（修图、图像信号处理、低光增强、去雾、水下图像增强和白平衡），覆盖30个数据集。

</details>


### [237] [JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching](https://arxiv.org/abs/2506.23552)
**中文标题：JAM-Flow：基于流匹配的联合音频-运动合成**

*Mingi Kwon,Joonghyuk Shin,Jaeseok Jung,Jaesik Park,Youngjung Uh*

主要分类: cs.CV

摘要简述: JAM-Flow是一个统一框架，通过流匹配和多模态扩散变换器（MM-DiT）架构，同时合成面部运动和语音，支持多种输入条件，如文本、参考音频和参考运动。


<details>
  <summary>详细信息</summary>
研究动机: 当前生成模型中，面部运动与语音的合成通常被视为独立任务，忽略了它们之间的内在联系。本文旨在通过统一框架解决这一问题，实现多模态音频-视觉合成。

研究方法: JAM-Flow采用流匹配技术和多模态扩散变换器（MM-DiT）架构，包含Motion-DiT和Audio-DiT模块，通过选择性联合注意力层实现跨模态交互，同时保留模态特定优势。

研究结果: JAM-Flow能够从文本、参考音频或参考运动等多种输入条件生成同步的说话头部动画和语音，显著提升了多模态生成模型的实用性。

研究结论: JAM-Flow为音频-视觉合成提供了一个实用的统一解决方案，推动了多模态生成模型的发展。

中文摘要: 在生成建模中，面部运动与语音之间的内在联系常被忽视，说话头部合成和文本转语音（TTS）通常被视为独立任务。本文提出JAM-Flow，一个统一框架，通过流匹配和新型多模态扩散变换器（MM-DiT）架构，同时合成并基于面部运动和语音进行条件生成。我们的方法结合了专门的Motion-DiT和Audio-DiT模块，通过选择性联合注意力层耦合，并采用时间对齐的位置嵌入和局部联合注意力掩码等关键架构选择，以实现有效的跨模态交互，同时保留模态特定优势。通过修复式目标训练，JAM-Flow支持多种输入条件（包括文本、参考音频和参考运动），在单一连贯模型中实现从文本生成同步说话头部、音频驱动动画等任务。JAM-Flow通过提供全面的音频-视觉合成实用解决方案，显著推动了多模态生成建模的发展。项目页面：https://joonghyuk.com/jamflow-web

</details>


### [238] [LH2Face: Loss function for Hard High-quality Face](https://arxiv.org/abs/2506.23555)
**中文标题：LH2Face：面向硬高质量人脸的损失函数**

*Fan Xie,Pan Cao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LH2Face的新型损失函数，用于解决当前人脸识别系统中对高质量硬样本处理不足的问题。通过结合vMF分布相似性度量和自适应边缘方法，LH2Face在硬高质量人脸数据集上表现优异，准确率显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于余弦相似度和softmax分类的人脸识别系统在处理硬样本时表现不佳，且现有方法未考虑人脸质量或识别难度，仅通过增加边缘值导致训练策略过于单一。因此，本文旨在提出一种能够自适应调整边缘并优化表示空间分布的损失函数。

研究方法: LH2Face首先基于vMF分布提出相似性度量，重点关注概率密度函数的对数表示；其次，采用自适应边缘的多分类方法（不确定性感知边缘函数）；此外，通过代理损失函数在代理与样本间施加额外约束以优化表示空间分布；最后，构建渲染器通过人脸重建优化人脸识别性能。

研究结果: LH2Face在硬高质量人脸数据集上表现优异，在IJB-B数据集上达到49.39%的准确率，比第二名方法高出2.37%。

研究结论: LH2Face通过结合vMF分布相似性度量和自适应边缘方法，显著提升了硬高质量人脸识别的性能，为相关领域提供了新的解决方案。

中文摘要: 在当前实用的人脸认证系统中，大多数人脸识别（FR）算法基于余弦相似度和softmax分类。尽管其分类性能可靠，但该方法在处理硬样本时表现不佳。提升FR性能的一种流行策略是引入角度或余弦边缘，然而该方法未考虑人脸质量或识别难度，仅简单增加边缘值，导致训练策略过于单一。为解决这一问题，本文提出了一种名为LH2Face的新型损失函数。首先，基于von Mises-Fisher（vMF）分布提出相似性度量，重点关注概率密度函数（PDF）的对数表示；其次，采用基于自适应边缘的多分类方法（不确定性感知边缘函数）；此外，通过代理损失函数在代理与样本间施加额外约束以优化表示空间分布；最后，构建渲染器通过人脸重建优化FR性能。实验表明，LH2Face在硬高质量人脸数据集上表现优异，在IJB-B数据集上达到49.39%的准确率，比第二名方法高出2.37%。

</details>


### [239] [OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2506.23565)
**中文标题：OcRFDet：面向自动驾驶中多视角3D物体检测的对象中心辐射场**

*Mingqian Ji,Jian Yang,Shanshan Zhang*

主要分类: cs.CV

摘要简述: 提出了一种名为OcRFDet的新方法，通过对象中心辐射场（OcRF）增强3D体素特征，并利用高度感知不透明度注意力（HOA）提升2D BEV特征，显著提升了自动驾驶中的多视角3D物体检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前多视角3D物体检测方法通常以数据驱动和隐式方式将2D特征转换为3D空间，限制了检测性能。受辐射场在3D重建中的成功启发，作者尝试将其用于增强3D几何估计能力，但直接用于3D渲染会导致性能下降，原因是背景噪声干扰。

研究方法: 提出对象中心辐射场（OcRF），专注于建模前景对象并剔除背景噪声。通过OcRF增强3D体素特征，并利用渲染的副产品不透明度，通过高度感知不透明度注意力（HOA）增强2D BEV特征。HOA通过并行网络生成不同高度层的注意力图。

研究结果: 在nuScenes验证集和测试集上的实验表明，OcRFDet以57.2%的mAP和64.8%的NDS显著优于现有方法。

研究结论: OcRFDet通过对象中心辐射场和高度感知不透明度注意力，有效提升了多视角3D物体检测性能，为自动驾驶领域提供了新的解决方案。

中文摘要: 当前的多视角3D物体检测方法通常通过深度估计或3D位置编码将2D特征转换为3D空间，但完全依赖数据驱动和隐式方式限制了检测性能。受辐射场在3D重建中的成功启发，我们假设其可用于增强检测器的3D几何估计能力。然而，直接将其用于3D渲染作为辅助任务会导致检测性能下降。通过分析，我们发现性能下降的原因是渲染整个场景时背景的强烈响应。为解决这一问题，我们提出了对象中心辐射场，专注于建模前景对象并剔除背景噪声。具体而言，我们利用对象中心辐射场（OcRF）通过渲染前景对象的辅助任务增强3D体素特征。进一步利用渲染的副产品不透明度，通过高度感知不透明度注意力（HOA）增强2D BEV特征，其中不同高度层的注意力图通过并行网络分别生成。在nuScenes验证集和测试集上的大量实验表明，我们的OcRFDet以57.2%的mAP和64.8%的NDS显著优于现有方法。代码将在https://github.com/Mingqj/OcRFDet发布。

</details>


### [240] [Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution](https://arxiv.org/abs/2506.23566)
**中文标题：基于元数据、小波和时间感知扩散模型的卫星图像超分辨率重建**

*Luigi Sigillo,Renato Giamba,Danilo Comminiello*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MWT-Diff的创新框架，结合潜在扩散模型和小波变换，用于卫星图像超分辨率重建，通过多模态编码器捕捉元数据、多尺度频率信息和时间关系，显著提升了图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 高分辨率卫星图像的获取受限于传感器的时空限制和高昂成本，而环境监测、灾害响应和农业管理等应用需要精细的高分辨率数据。本文旨在解决这些挑战。

研究方法: 提出MWT-Diff框架，核心为MWT-Encoder编码器，生成包含元数据属性、多尺度频率信息和时间关系的嵌入特征，指导分层扩散动态逐步重建高分辨率图像，保留纹理、边界和高频光谱等关键空间特征。

研究结果: 在多个数据集上的比较分析表明，MWT-Diff在感知质量指标（如FID和LPIPS）上优于现有方法。

研究结论: MWT-Diff通过结合扩散模型和小波变换，有效提升了卫星图像超分辨率重建的质量，为遥感分析提供了更精细的数据支持。

中文摘要: 高分辨率卫星图像的获取常受限于传感器的时空限制及高昂的观测成本，这阻碍了环境监测、灾害响应和农业管理等需要精细高分辨率数据的应用。本文提出MWT-Diff，一种创新的卫星图像超分辨率（SR）框架，结合潜在扩散模型和小波变换解决上述问题。其核心是新颖的元数据、小波和时间感知编码器（MWT-Encoder），生成的嵌入特征捕捉元数据属性、多尺度频率信息和时间关系。这些特征指导分层扩散动态，逐步从低分辨率输入重建高分辨率卫星图像，保留对遥感分析至关重要的纹理模式、边界不连续性和高频光谱成分。在多个数据集上的比较分析表明，MWT-Diff在标准感知质量指标（如FID和LPIPS）上优于现有方法。

</details>


### [241] [Event-based Tiny Object Detection: A Benchmark Dataset and Baseline](https://arxiv.org/abs/2506.23575)
**中文标题：基于事件的小目标检测：基准数据集与基线方法**

*Nuo Chen,Chao Xiao,Yimian Dai,Shiman He,Miao Li,Wei An*

主要分类: cs.CV

摘要简述: 本文提出了首个针对反无人机任务的大规模事件相机小目标检测数据集EV-UAV，并基于时空事件点云中的目标连续性提出了一种新基线方法EV-SpSegNet和STC损失函数，实验验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 传统帧相机在复杂背景下检测小目标（如无人机）存在帧率低、动态范围有限和数据冗余等问题，而现有事件相机数据集规模小、目标大且背景单一，无法满足小目标检测需求。

研究方法: 提出EV-UAV数据集，包含147个序列和230万事件级标注，目标平均尺寸极小（6.8×5.4像素）。基于小目标在时空事件点云中形成连续曲线的观察，设计了EV-SpSegNet网络和STC损失函数，利用运动连续性保留目标事件。

研究结果: 在EV-UAV数据集上的实验表明，所提方法显著优于现有技术，为事件相机小目标检测提供了新基准。

研究结论: EV-UAV数据集和EV-SpSegNet方法为事件相机小目标检测研究提供了重要工具和方向，未来可进一步探索时空连续性在小目标检测中的应用。

中文摘要: 反无人机任务中的小目标检测（SOD）因无人机尺寸小和背景复杂而极具挑战性。传统帧相机因低帧率、有限动态范围和数据冗余难以在复杂环境中检测小目标。事件相机具有微秒级时间分辨率和高动态范围，为SOD提供了更有效的解决方案。然而，现有事件相机数据集规模有限、目标尺寸大且背景单一，不适合作为SOD基准。本文提出了首个针对反无人机任务的大规模、高多样性事件相机小目标检测数据集EV-UAV（即EVSOD），包含147个序列和超过230万事件级标注，目标尺寸极小（平均6.8×5.4像素），场景多样（如城市杂乱和极端光照）。此外，基于小运动目标在时空事件点云中形成连续曲线的观察，我们提出了事件稀疏分割网络EV-SpSegNet和时空相关性（STC）损失函数，利用运动连续性指导网络保留目标事件。在EV-UAV数据集上的大量实验证明了该方法的优越性，并为未来EVSOD研究提供了基准。数据集和代码见https://github.com/ChenYichen9527/Ev-UAV。

</details>


### [242] [StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.23577)
**中文标题：StackCLIP：零样本工业异常检测中的聚类驱动堆叠提示方法**

*Yanning Hou,Yanran Ruan,Junfa Li,Shanshan Wang,Jianfeng Qiu,Ke Xu*

主要分类: cs.CV

摘要简述: 提出StackCLIP模型，通过多类别名称堆叠生成堆叠提示，结合聚类驱动和特征对齐模块，显著提升零样本工业异常检测的性能和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在CLIP模型中通过特定类别提示进行预训练，容易导致过拟合和泛化能力不足。为解决这一问题，研究提出了一种基于多类别名称堆叠的堆叠提示方法。

研究方法: 1. 聚类驱动堆叠提示（CSP）模块：通过堆叠语义相似的类别生成通用提示，并利用多目标文本特征融合增强异常区分能力。2. 集成特征对齐（EFA）模块：为每个堆叠簇训练特定知识线性层，并根据测试类别属性自适应整合。3. 调节提示学习（RPL）模块：利用堆叠提示的泛化能力优化提示学习。

研究结果: 在七个工业异常检测数据集上的实验表明，该方法在零样本异常检测和分割任务中均达到最优性能。

研究结论: StackCLIP通过堆叠提示和模块化设计，显著提升了零样本工业异常检测的性能和泛化能力，为相关任务提供了新的解决方案。

中文摘要: 在零样本工业异常检测任务中，提升CLIP模型中文本与图像特征的对齐是一个关键挑战。现有研究主要依赖预训练中的特定类别提示，这可能导致对训练类别的过拟合并限制模型的泛化能力。为此，我们提出了一种通过多类别名称堆叠生成堆叠提示的方法，并构建了StackCLIP模型。该方法包含两个关键模块：聚类驱动堆叠提示（CSP）模块通过堆叠语义相似的类别生成通用提示，并利用多目标文本特征融合增强相似对象间的异常区分能力；集成特征对齐（EFA）模块为每个堆叠簇训练特定知识线性层，并根据测试类别属性自适应整合。这些模块共同实现了更高的训练速度、稳定性和收敛性，显著提升了异常分割性能。此外，堆叠提示框架在分类任务中表现出强大的泛化能力。为进一步优化性能，我们引入了调节提示学习（RPL）模块，利用堆叠提示的泛化能力优化提示学习，从而提升异常检测分类任务的结果。在七个工业异常检测数据集上的广泛测试表明，我们的方法在零样本异常检测和分割任务中均达到了最优性能。

</details>


### [243] [Dataset Distillation via Vision-Language Category Prototype](https://arxiv.org/abs/2506.23580)
**中文标题：通过视觉-语言类别原型进行数据集蒸馏**

*Yawen Zou,Guang Li,Duo Su,Zi Wang,Jun Yu,Chao Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种通过视觉-语言类别原型进行数据集蒸馏的方法，结合文本和图像原型提升蒸馏性能，生成逻辑一致的图像并实现最优验证性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统数据集蒸馏方法主要关注图像信息，忽略了数据的语义信息，导致模型在复杂任务中泛化能力不足。本研究旨在通过整合视觉-语言方法，提升数据集蒸馏的性能和逻辑一致性。

研究方法: 通过引入文本原型（由开源大型语言模型生成的描述性文本信息）与图像原型协同合成数据，从而增强数据集蒸馏的效果。

研究结果: 该方法生成的图像逻辑一致且包含目标对象，验证性能达到最优，并展现出强大的泛化能力。

研究结论: 结合视觉-语言方法的数据集蒸馏框架显著提升了性能，扩展了传统图像方法的潜力，适用于无文本描述的数据集。

中文摘要: 数据集蒸馏（DD）将大型数据集压缩为紧凑且信息丰富的替代品，在保持与原始数据集相当性能的同时，降低了存储、传输和计算成本。然而，以往的DD方法主要关注从图像中提取信息，往往忽略了数据中的语义信息。这种对上下文的忽视阻碍了模型的泛化能力，尤其是在涉及复杂数据集的任务中，可能导致输出不合逻辑或遗漏关键对象。本研究通过引入文本原型（由开源大型语言模型生成的描述性文本信息）与图像原型协同合成数据，从而提升数据集蒸馏的性能。值得注意的是，该方法在无预存文本描述的数据集上展现出广泛适用性，扩展了数据集蒸馏的潜力。与其他方法相比，所提方法生成的图像逻辑一致且包含目标对象，验证性能达到最优，并展现出强大的泛化能力。源代码和生成数据可在https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/获取。

</details>


### [244] [PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection](https://arxiv.org/abs/2506.23581)
**中文标题：PBCAT：基于补丁的复合对抗训练防御目标检测中的物理可实现攻击**

*Xiao Li,Yiming Zhu,Yifan Huang,Wei Zhang,Yingzhe He,Jie Shi,Xiaolin Hu*

主要分类: cs.CV

摘要简述: 本文提出PBCAT，一种基于补丁的复合对抗训练方法，用于防御多种物理可实现的攻击，显著提升了目标检测模型的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 目标检测在安全敏感应用中至关重要，但易受物理可实现攻击（如对抗补丁和纹理）的威胁。现有对抗训练方法主要针对分类模型，对目标检测器的物理攻击防御研究不足。

研究方法: PBCAT结合小区域梯度引导的对抗补丁和覆盖整张图像的全局对抗扰动，通过统一训练策略提升模型对多种物理攻击的防御能力。

研究结果: 实验表明，PBCAT显著优于现有防御方法，在对抗纹理攻击下检测准确率提升29.7%。

研究结论: PBCAT为防御物理可实现攻击提供了有效解决方案，扩展了对抗训练的应用范围。

中文摘要: 目标检测在许多安全敏感应用中扮演关键角色。然而，最近研究表明，目标检测器易受物理可实现攻击（如对抗补丁和纹理）的欺骗，这些攻击构成现实且紧迫的威胁。对抗训练（AT）被认为是最有效的防御手段。尽管AT在分类模型的$l_\infty$攻击设置中已得到广泛研究，但对目标检测器中物理可实现攻击的AT研究较少。早期尝试仅针对对抗补丁，对其他物理攻击的防御研究不足。本文提出PBCAT，一种基于补丁的复合对抗训练策略。PBCAT通过结合小区域梯度引导的对抗补丁和覆盖整张图像的全局对抗扰动优化模型。这一设计使PBCAT不仅能防御对抗补丁，还能抵御未见过的物理攻击（如对抗纹理）。多场景实验表明，PBCAT显著提升了模型对各种物理攻击的鲁棒性，优于现有防御方法。特别地，在对抗纹理攻击下，检测准确率较之前方法提升了29.7%。

</details>


### [245] [CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2506.23590)
**中文标题：CAI：基于标题敏感注意力干预的大型视觉语言模型对象幻觉缓解方法**

*Qiming Li,Zekai Ye,Xiaocheng Feng,Weihong Zhong,Libo Qin,Ruihan Chen,Baohang Li,Kui Jiang,Yaowei Wang,Ting Liu,Bing Qin*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CAI的训练免费、即插即用的方法，通过利用大型视觉语言模型（LVLMs）在回答标题查询时的注意力激活模式，显著减少对象幻觉问题，同时仅增加极少的推理成本。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型视觉语言模型（LVLMs）在视觉信息解释方面表现出强大能力，但它们经常生成与视觉信息不符的内容，导致对象幻觉。现有方法通常依赖昂贵的标注和训练成本，或显著增加推理时间。本文旨在通过观察LVLMs在标题查询和非标题查询中的注意力差异，提出一种高效且低成本的对象幻觉缓解方法。

研究方法: 本文提出了一种名为Caption-sensitive Attention Intervention（CAI）的方法。该方法无需额外训练，通过利用LVLMs在回答标题查询时更强的视觉注意力激活模式，增强模型对视觉信息的感知能力，从而减少对象幻觉。

研究结果: 在涵盖判别性和生成性任务的四个基准测试中，CAI仅需极少的额外推理成本，即实现了最先进的对象幻觉缓解性能。

研究结论: CAI是一种高效且低成本的对象幻觉缓解方法，通过利用LVLMs在标题查询中的注意力模式，显著提升了模型的视觉感知能力，同时避免了昂贵的训练成本和推理时间增加。

中文摘要: 尽管大型视觉语言模型（LVLMs）在解释视觉信息方面表现出强大的能力，但它们经常生成与视觉信息不符的内容，导致对象幻觉。为解决这一问题，现有方法大多依赖昂贵的标注和训练成本，或显著增加推理时间。本文观察到，LVLMs在回答标题查询时对视觉信息的注意力显著强于非标题查询。基于这一现象，我们提出了一种无需训练、即插即用的对象幻觉缓解方法——Caption-sensitive Attention Intervention（CAI），该方法利用标题查询中的注意力激活模式来增强LVLMs的视觉感知能力。在涵盖判别性和生成性任务的四个基准测试中，CAI仅需极少的额外推理成本，即实现了最先进的对象幻觉缓解性能。

</details>


### [246] [AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval](https://arxiv.org/abs/2506.23605)
**中文标题：AI生成的课件幻灯片用于改进幻灯片元素检测与检索**

*Suyash Maniyar,Vishvesh Trivedi,Ajoy Mondal,Anand Mishra,C. V. Jawahar*

主要分类: cs.CV

摘要简述: 论文提出了一种基于大语言模型（LLM）的合成课件生成方法SynLecSlideGen，用于解决课件元素检测与检索任务中标注数据不足的问题。实验表明，通过合成数据预训练的模型在少量真实数据上表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 课件元素检测与检索任务需要大量标注数据，但人工标注成本高且需专业知识。论文旨在通过合成数据缓解这一问题。

研究方法: 提出SynLecSlideGen方法，利用大语言模型生成高质量、连贯且真实的合成课件；并创建了RealSlide评测基准，包含1,050张标注的真实课件。

研究结果: 实验结果显示，使用合成数据预训练的模型在少量真实数据上表现显著优于仅使用真实数据训练的模型。

研究结论: 合成数据能有效弥补真实标注数据的不足，提升模型性能。

中文摘要: 课件幻灯片元素检测与检索是幻灯片理解中的关键问题。训练这些任务的有效模型通常依赖于大量人工标注，但标注大量课件幻灯片既费时又需要专业知识。为此，我们提出了一种基于大语言模型（LLM）的合成课件幻灯片生成流程SynLecSlideGen，能够生成高质量、连贯且真实的幻灯片。我们还创建了一个评测基准RealSlide，手动标注了1,050张真实课件幻灯片。为评估合成幻灯片的实用性，我们在真实数据上进行了基于合成数据预训练的少样本迁移学习实验。结果表明，与仅使用真实数据训练相比，基于合成数据预训练的少样本迁移学习显著提升了性能。这证明合成数据能有效弥补标注课件幻灯片的不足。代码与资源已公开在项目网站：https://synslidegen.github.io/。

</details>


### [247] [SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion](https://arxiv.org/abs/2506.23606)
**中文标题：SG-LDM：基于潜在对齐扩散的语义引导LiDAR生成**

*Zhengkang Xiang,Zizhao Li,Amir Khodabandeh,Kourosh Khoshelham*

主要分类: cs.CV

摘要简述: SG-LDM是一种基于语义引导的LiDAR生成模型，通过潜在对齐扩散技术实现高保真点云合成，并首次提出基于扩散的LiDAR跨域翻译框架，显著提升下游感知任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有LiDAR点云生成方法多为无条件生成，忽略了实际应用中的语义引导需求。SG-LDM旨在通过语义条件生成高保真LiDAR点云，并探索其在跨域翻译和数据增强中的应用。

研究方法: SG-LDM在原生LiDAR空间中操作，利用显式语义条件进行潜在对齐扩散，实现语义到LiDAR的合成。此外，提出基于SG-LDM的扩散式LiDAR翻译框架，支持跨域翻译。

研究结果: 实验表明，SG-LDM在生成高保真LiDAR点云方面优于现有方法，其翻译框架显著提升下游LiDAR分割任务的数据增强效果。

研究结论: SG-LDM通过语义引导和潜在对齐扩散技术，实现了高效的LiDAR点云生成与跨域翻译，为下游感知任务提供了强大的数据增强工具。

中文摘要: 基于生成模型的LiDAR点云合成为深度学习流水线提供了一种有前景的增强方案，尤其在真实数据稀缺或多样性不足时。通过灵活的物体操作，这种合成方法能够显著丰富训练数据集并提升判别模型性能。然而，现有方法主要关注无条件LiDAR点云生成，忽视了其在实际应用中的潜力。本文提出SG-LDM，一种基于潜在对齐的语义引导LiDAR扩散模型，通过直接操作原生LiDAR空间并利用显式语义条件，实现了语义到LiDAR的高保真合成。此外，我们首次提出基于SG-LDM的扩散式LiDAR翻译框架，支持跨域翻译作为领域自适应策略，以提升下游感知性能。系统实验表明，SG-LDM显著优于现有LiDAR扩散模型，且所提出的翻译框架进一步提升了LiDAR分割任务中的数据增强效果。

</details>


### [248] [PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum](https://arxiv.org/abs/2506.23607)
**中文标题：PGOV3D：基于局部到全局课程学习的开放词汇3D语义分割**

*Shiqi Zhang,Sha Zhang,Jiajun Deng,Yedong Shen,Mingxiao MA,Yanyong Zhang*

主要分类: cs.CV

摘要简述: PGOV3D提出了一种新颖的开放词汇3D语义分割框架，通过从局部到全局的课程学习策略，显著提升了模型性能。该方法利用多视角图像的丰富语义和跨视角一致性，结合多模态大语言模型和2D分割基础模型生成开放词汇标签，并通过两阶段训练优化模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有开放词汇3D语义分割方法通常仅将多视角图像作为信息传递媒介，忽略了其丰富的语义内容和跨视角一致性，限制了模型效果。PGOV3D旨在通过局部到全局的课程学习策略，充分利用多视角图像的语义信息，提升开放词汇3D分割的性能。

研究方法: PGOV3D采用两阶段训练策略：1）在局部场景上预训练模型，利用多视角RGB-D输入生成密集语义标签，并通过多模态大语言模型和2D分割基础模型提供开放词汇监督；2）在完整场景点云上微调模型，通过聚合局部词汇和生成伪标签，弥合密集局部观测与大规模3D环境之间的语义鸿沟。

研究结果: 在ScanNet、ScanNet200和S3DIS基准测试中，PGOV3D在开放词汇3D语义分割任务中表现出色，验证了其方法的有效性。

研究结论: PGOV3D通过局部到全局的课程学习策略，显著提升了开放词汇3D语义分割的性能，为利用多视角图像的语义信息提供了新思路。

中文摘要: 现有的开放词汇3D语义分割方法通常通过将多视角图像中提取的文本对齐特征（如CLIP）映射到3D点上来监督模型。然而，这些方法仅将多视角图像视为传递开放词汇信息的媒介，忽略了其丰富的语义内容和跨视角一致性，限制了模型效果。为此，我们提出PGOV3D，一种新颖的框架，通过引入局部到全局的课程学习策略改进开放词汇3D语义分割。其核心创新在于两阶段训练策略：第一阶段，我们在提供密集语义信息但几何相对简单的局部场景上预训练模型。这些局部点云通过多视角RGB-D输入的像素级深度投影生成。为了实现开放词汇学习，我们利用多模态大语言模型（MLLM）和2D分割基础模型为每个视角生成开放词汇标签，提供丰富且对齐的监督。此外，引入辅助的帧间一致性模块以增强不同视角间的特征一致性和空间理解。第二阶段，我们在稀疏且结构更复杂的完整场景点云上微调模型。通过聚合与每个场景相关的局部词汇并利用预训练模型生成伪标签，有效弥合了密集局部观测与大规模3D环境之间的语义鸿沟。在ScanNet、ScanNet200和S3DIS基准测试上的大量实验表明，PGOV3D在开放词汇3D语义分割任务中取得了优异的性能。

</details>


### [249] [AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention](https://arxiv.org/abs/2506.23611)
**中文标题：AttentionGS：通过结构注意力实现无需初始化的3D高斯泼溅**

*Ziao Liu,Zhenjia Li,Yifeng Shi,Xiangang Li*

主要分类: cs.CV

摘要简述: AttentionGS是一种无需高质量初始点云的新型3D高斯泼溅框架，通过结构注意力直接从随机初始化进行3D重建，显著提升了在纹理缺失或视角受限场景下的重建效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D高斯泼溅（3DGS）依赖高质量的结构运动（SfM）点云初始化，在纹理缺失或视角受限场景中表现不佳。AttentionGS旨在消除这一依赖，提升3DGS的鲁棒性和灵活性。

研究方法: AttentionGS通过几何注意力快速恢复全局场景结构，随后引入纹理注意力优化细节；采用不透明度加权梯度指导高斯密度化，提升表面重建质量。

研究结果: 实验表明，AttentionGS在点云初始化不可靠的场景中显著优于现有方法，实现了更高质量的3D重建和渲染。

研究结论: AttentionGS为3D高斯泼溅在现实应用中的鲁棒性和灵活性提供了新方向。

中文摘要: 3D高斯泼溅（3DGS）是神经辐射场（NeRF）的强大替代方案，擅长复杂场景重建和高效渲染。然而，它依赖结构运动（SfM）生成的高质量点云，限制了其应用范围。SfM在纹理缺失或视角受限场景中表现不佳，导致3DGS重建质量严重下降。为解决这一问题，我们提出AttentionGS，一种通过结构注意力直接从随机初始化进行3D重建的新型框架。在训练早期，引入几何注意力快速恢复全局场景结构；随着训练进行，结合纹理注意力优化细节并提升渲染质量。此外，采用不透明度加权梯度指导高斯密度化，改善表面重建。在多个基准数据集上的实验表明，AttentionGS显著优于现有方法，尤其在点云初始化不可靠的场景中。我们的方法为3D高斯泼溅在现实应用中的鲁棒性和灵活性开辟了新途径。

</details>


### [250] [TurboVSR: Fantastic Video Upscalers and Where to Find Them](https://arxiv.org/abs/2506.23618)
**中文标题：TurboVSR：神奇的视频超分辨率工具及其实现**

*Zhongdao Wang,Guodongfang Zhao,Jingjing Ren,Bailan Feng,Shifeng Zhang,Wenbo Li*

主要分类: cs.CV

摘要简述: TurboVSR是一种基于扩散模型的超高效视频超分辨率方法，通过高压缩比自动编码器、分解条件训练和快捷模型转换，实现了比现有方法快100倍的速度，同时保持高质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散模型的视频超分辨率方法在细节生成上表现优异，但计算效率极低，处理短视频耗时过长。TurboVSR旨在解决这一效率问题，同时保持高质量输出。

研究方法: TurboVSR采用三项核心技术：(1) 高压缩比自动编码器减少令牌数量；(2) 分解条件训练，先学习超分辨率首帧，再基于高分辨率首帧和低分辨率后续帧训练；(3) 将预训练扩散模型转换为快捷模型以减少采样步骤。

研究结果: TurboVSR在性能上与现有最优方法相当，但速度快100倍以上，仅需7秒处理2秒1080p视频，并支持4K图像超分辨率，生成精细细节。

研究结论: TurboVSR通过高效设计解决了扩散模型在视频超分辨率中的计算瓶颈，为高分辨率视频和图像处理提供了实用解决方案。

中文摘要: 基于扩散的生成模型在视频超分辨率（VSR）任务中展现出卓越潜力，相较于先前方法在细节生成上取得显著进步。然而，这些方法面临严重的计算效率问题。例如，现有技术可能需要数十分钟才能超分辨率一段仅2秒的1080p视频。本文提出TurboVSR，一种超高效的基于扩散的视频超分辨率模型。我们的核心设计包括三个关键方面：(1) 采用压缩比为32×32×8的自动编码器以减少令牌数量；(2) 高压缩潜在空间对训练带来巨大挑战，我们引入分解条件训练以降低学习复杂度：首先学习超分辨率首帧，随后基于高分辨率首帧和低分辨率后续帧训练其余帧；(3) 将预训练扩散模型转换为快捷模型以减少采样步骤，进一步加速推理。结果表明，TurboVSR与现有最优VSR方法性能相当，但速度快100倍以上，仅需7秒处理2秒1080p视频。TurboVSR还支持图像超分辨率，将图像视为单帧视频。我们的高效设计使得1080p以上超分辨率成为可能，4K（3648×2048）图像超分辨率结果展现出惊人的精细细节。

</details>


### [251] [Revisiting Audio-Visual Segmentation with Vision-Centric Transformer](https://arxiv.org/abs/2506.23623)
**中文标题：重新审视音频-视觉分割：基于视觉中心Transformer的方法**

*Shaofei Huang,Rui Ling,Tianrui Hui,Hongyu Li,Xu Zhou,Shifeng Zhang,Si Liu,Richang Hong,Meng Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉中心Transformer（VCT）的新框架，用于音频-视觉分割（AVS），通过视觉驱动的查询解决音频中心方法的感知模糊性和视觉细节丢失问题，并在AVSBench数据集上取得了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的音频-视觉分割方法通常采用音频中心Transformer架构，但这种方法存在两个主要问题：音频混合导致的感知模糊性，以及视觉细节丢失导致的密集预测能力下降。为了解决这些问题，本文提出了一种视觉中心Transformer框架。

研究方法: 本文提出了一种视觉中心Transformer（VCT）框架，通过视觉驱动的查询迭代获取音频和视觉信息，并结合原型提示查询生成（PPQG）模块，生成语义感知且视觉丰富的查询，以促进音频-视觉信息聚合。

研究结果: 在AVSBench数据集的三个子集上，VCT框架实现了最先进的性能表现。

研究结论: 视觉中心Transformer框架有效解决了音频中心方法的局限性，显著提升了音频-视觉分割的性能。

中文摘要: 音频-视觉分割（AVS）旨在基于关联的音频信号分割视频帧中的发声物体。现有的AVS方法通常采用音频中心Transformer架构，其中对象查询源自音频特征。然而，音频中心Transformer存在两个局限性：音频混合导致的感知模糊性，以及视觉细节丢失导致的密集预测能力下降。为解决这些问题，我们提出了一种新的视觉中心Transformer（VCT）框架，利用视觉驱动的查询迭代获取对应的音频和视觉信息，使查询能够更好地区分混合音频中的不同发声物体并准确描绘其轮廓。此外，我们还在VCT框架中引入了原型提示查询生成（PPQG）模块，通过音频原型提示和像素上下文分组生成语义感知且视觉丰富的视觉驱动查询，促进音频-视觉信息聚合。大量实验表明，我们的VCT框架在AVSBench数据集的三个子集上实现了最先进的性能。代码可在https://github.com/spyflying/VCT_AVS获取。

</details>


### [252] [Brain Tumor Detection through Thermal Imaging and MobileNET](https://arxiv.org/abs/2506.23627)
**中文标题：基于热成像和MobileNET的脑肿瘤检测**

*Roham Maiti,Debasmita Bhoumik*

主要分类: cs.CV

摘要简述: 本研究提出了一种基于MobileNET模型和热成像技术的高效脑肿瘤检测方法，通过减少计算资源和时间需求，实现了98.5%的平均准确率。


<details>
  <summary>详细信息</summary>
研究动机: 脑肿瘤对人类健康构成重大威胁，传统检测方法（如活检、MRI和CT扫描）成本高且依赖专业医疗资源。机器学习虽能自动化检测，但传统模型计算需求大、训练时间长。本研究旨在开发一种高效、低成本的脑肿瘤检测方法。

研究方法: 采用MobileNET模型结合图像处理技术，优化计算资源使用和检测时间，构建高效的脑肿瘤检测系统。

研究结果: 所提方法平均准确率达到98.5%，显著降低了计算资源和时间需求。

研究结论: MobileNET模型结合热成像技术为脑肿瘤检测提供了一种高效、准确的解决方案，具有实际应用潜力。

中文摘要: 大脑在调节身体功能和认知过程中起着关键作用，脑肿瘤对人类健康构成重大风险。精确且及时的检测是治疗和改善患者预后的关键因素。传统的脑肿瘤检测方法（如活检、MRI和CT扫描）由于成本高且需要专业医疗知识而面临挑战。近年来，机器学习（ML）和深度学习（DL）在自动化识别和分类脑肿瘤（尤其是MRI扫描图像）方面展现出强大能力。然而，这些传统ML模型存在计算需求高、需要大数据集和训练时间长等局限性，影响了其可及性和效率。本研究采用MobileNET模型实现高效的脑肿瘤检测。该项目的创新点在于构建了一种计算资源需求低、运行时间短的准确肿瘤检测模型，并通过图像处理技术实现高效决策。所提方法的平均准确率达到98.5%。

</details>


### [253] [Blending Concepts with Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.23630)
**中文标题：融合概念与文本到图像扩散模型**

*Lorenzo Olearo,Giorgio Longari,Alessandro Raganato,Rafael Peñaloza,Simone Melzi*

主要分类: cs.CV

摘要简述: 本文探讨了扩散模型在零样本框架下将不同概念（从具体对象到抽象想法）融合为连贯新视觉实体的能力，研究了四种融合方法，并通过实验和用户研究验证了模型的创造性融合潜力及其对输入细节的敏感性。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，扩散模型在文本到图像生成方面取得了显著进展，但能否在无需额外训练的情况下将多个概念融合为新颖且连贯的图像仍是一个开放问题。本文旨在验证扩散模型在概念融合方面的能力。

研究方法: 研究了四种概念融合方法，包括提示调度、嵌入插值和分层条件等，利用扩散模型的不同方面实现概念融合。实验覆盖了具体概念合并、复合词合成、艺术风格迁移和建筑地标融合等多种场景。

研究结果: 实验表明，现代扩散模型在无需微调的情况下展现出创造性融合能力。用户研究发现，不同方法在不同场景下表现各异，提示顺序、概念距离和随机种子等因素会影响结果。

研究结论: 扩散模型在概念融合方面具有显著潜力，但对输入细节高度敏感。不同融合方法各有优劣，需根据具体场景选择。

中文摘要: 近年来，扩散模型显著推动了文本到图像生成的发展，能够轻松地将抽象概念转化为高保真图像。本研究探讨了它们是否也能在零样本框架下将不同概念（从具体对象到抽象想法）融合为连贯的新视觉实体。具体而言，概念融合将多个概念（以文本提示表示）的关键属性合并为一张新颖的图像，捕捉每个概念的本质。我们研究了四种融合方法，每种方法利用了扩散管道的不同方面（如提示调度、嵌入插值或分层条件）。通过对多种概念类别的系统实验（如合并具体概念、合成复合词、迁移艺术风格和融合建筑地标），我们发现现代扩散模型确实展现出无需额外训练或微调的创造性融合能力。我们开展了涉及100名参与者的广泛用户研究，结果显示没有单一方法在所有场景中占优：每种融合技术在某些条件下表现最佳，而提示顺序、概念距离和随机种子等因素会影响结果。这些发现凸显了扩散模型的显著组合潜力，同时也揭示了它们对看似微小输入变化的敏感性。

</details>


### [254] [Unified Multimodal Understanding via Byte-Pair Visual Encoding](https://arxiv.org/abs/2506.23639)
**中文标题：通过字节对视觉编码实现统一多模态理解**

*Wanpeng Zhang,Yicheng Feng,Hao Luo,Yijiang Li,Zihao Yue,Sipeng Zheng,Zongqing Lu*

主要分类: cs.CV

摘要简述: 本文提出了一种通过字节对视觉编码统一多模态理解的框架，利用优先级引导的编码方案和多阶段训练方法，显著提升了多模态大语言模型在视觉-语言任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型在视觉-语言理解方面取得了进展，但如何有效对齐不同模态仍是一个关键挑战。本文旨在通过统一视觉和文本表示，提升模型的跨模态理解能力。

研究方法: 方法包括：1) 对视觉标记应用字节对编码；2) 提出优先级引导的编码方案，结合频率和空间一致性；3) 采用基于课程驱动数据组合的多阶段训练流程。

研究结果: 实验结果表明，该方法在多种视觉-语言任务中表现优异，显著提升了跨模态关系的捕捉和视觉信息的推理能力。

研究结论: 通过弥合视觉与文本表示之间的差距，本文提出的方法为更高效、更强大的多模态基础模型的发展做出了贡献。

中文摘要: 多模态大语言模型（MLLMs）在视觉-语言理解方面取得了显著进展，但如何有效对齐不同模态仍是一个根本性挑战。我们提出了一种框架，通过将字节对编码应用于视觉标记来统一多模态理解。与传统依赖模态特定编码器的方法不同，我们的方法直接将结构信息融入视觉标记，模仿纯文本语言模型中的成功标记化策略。我们引入了一种优先级引导的编码方案，同时考虑频率和空间一致性，并结合基于课程驱动数据组合的多阶段训练流程。这些改进使变换器模型能够更好地捕捉跨模态关系并利用视觉信息进行推理。全面的实验表明，该方法在多种视觉-语言任务中表现优异。通过弥合视觉与文本表示之间的差距，我们的方法推动了更强大、更高效的多模态基础模型的发展。

</details>


### [255] [VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation](https://arxiv.org/abs/2506.23641)
**中文标题：VAP-Diffusion：利用多模态大语言模型丰富描述以增强医学图像生成**

*Peng Huang,Junhu Fu,Bowen Guo,Zeju Li,Yuanyuan Wang,Yi Guo*

主要分类: cs.CV

摘要简述: VAP-Diffusion利用多模态大语言模型（MLLMs）生成丰富的医学图像描述，提升生成图像的质量和多样性，并通过原型条件机制增强对未见描述的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像生成需要丰富的属性信息，但现有数据往往缺乏详细描述。本文旨在通过外部知识（MLLMs）弥补这一不足，提升生成图像的多样性和真实性。

研究方法: 设计了基于链式思维的提示模板，从MLLMs中提取无幻觉的描述；提出原型条件机制，限制测试嵌入与训练嵌入的相似性，增强对未见描述的鲁棒性。

研究结果: 在四种医学图像数据集上的实验验证了VAP-Diffusion的有效性，生成的图像质量高且多样性显著提升。

研究结论: VAP-Diffusion通过结合MLLMs的外部知识和原型条件机制，显著提升了医学图像生成的质量和多样性。

中文摘要: 医学图像的外观受多种潜在因素影响，生成模型需要超越标签的丰富属性信息以生成真实且多样化的图像。例如，生成具有特定模式的皮肤病变图像需要超越诊断的详细描述（如形状、大小、纹理和颜色），但这些描述往往难以获取。为此，我们提出了一种名为视觉属性提示（VAP）-Diffusion的框架，利用预训练的多模态大语言模型（MLLMs）的外部知识来提升医学图像生成的质量和多样性。首先，为避免幻觉，我们设计了一系列基于链式思维的提示模板，用于常见医学成像任务（如皮肤病、结直肠和胸部X光图像）。生成的描述在训练中被利用并按类别存储。测试时，从相应类别中随机检索描述进行推理。此外，为使生成器对测试时未见的描述组合具有鲁棒性，我们提出了一种原型条件机制，限制测试嵌入与训练嵌入的相似性。在四种医学图像数据集上的实验验证了VAP-Diffusion的有效性。

</details>


### [256] [MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis](https://arxiv.org/abs/2506.23648)
**中文标题：MReg：一种基于混合专家视频特征挖掘的二尖瓣反流诊断新型回归模型**

*Zhe Liu,Yuhao Huang,Lian Liu,Chengrui Zhang,Haotian Lin,Tong Han,Zhiyuan Zhu,Yanlin Chen,Yuerui Chen,Dong Ni,Zhongshan Gou,Xin Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于混合专家（MoE）的视频特征挖掘回归模型（MReg），用于自动诊断二尖瓣反流（MR）。该模型通过回归任务捕捉类别间的连续性，模仿超声医师的诊断逻辑进行特征选择与放大，并结合MoE概念提取类别级特征，显著提升了诊断准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于智能方法的二尖瓣反流（MR）诊断存在与临床工作流不匹配、准确性和可解释性不足的问题。本文旨在开发一种自动化诊断模型，结合临床实际需求，提高诊断的准确性和实用性。

研究方法: 1. 将MR诊断任务建模为回归问题，以捕捉类别间的连续性和序数关系；2. 设计特征选择与放大机制，模仿超声医师的诊断逻辑；3. 引入基于混合专家（MoE）的特征总结模块，提取类别级特征以增强表示能力。

研究结果: 在包含1868例病例的大型内部A4C-CDV数据集上，MReg模型在MR诊断中表现优于其他弱监督视频异常检测和监督分类方法，显示出更高的准确性。

研究结论: MReg模型通过回归任务、特征选择与放大机制以及MoE特征总结模块，显著提升了二尖瓣反流诊断的准确性和临床适用性，为自动化MR诊断提供了有效解决方案。

中文摘要: 彩色多普勒超声心动图是诊断二尖瓣反流（MR）的重要工具。近期研究探索了智能方法以减少用户依赖性并提高诊断准确性，但这些方法常与临床工作流不匹配，且准确性和可解释性不足。本研究提出了一种基于四腔心彩色多普勒超声心动图视频（A4C-CDV）的自动化MR诊断模型（MReg）。该模型采用全面的特征挖掘策略，结合临床实际，检测MR并评估其严重程度。我们的贡献有三点：首先，将MR诊断任务建模为回归问题，以捕捉类别间的连续性和序数关系；其次，设计特征选择与放大机制，模仿超声医师的诊断逻辑；第三，受混合专家（MoE）概念启发，引入特征总结模块提取类别级特征，增强表示能力以提高分级准确性。我们在包含1868例病例的大型内部A4C-CDV数据集上训练和评估了MReg模型。与其他弱监督视频异常检测和监督分类方法相比，MReg在MR诊断中表现出更优性能。代码已开源：https://github.com/cskdstz/MReg。

</details>


### [257] [Towards Markerless Intraoperative Tracking of Deformable Spine Tissue](https://arxiv.org/abs/2506.23657)
**中文标题：面向无标记术中脊柱组织变形跟踪的研究**

*Connor Daly,Elettra Marconi,Marco Riva,Jinendra Ekanayake,Daniel S. Elson,Ferdinando Rodriguez y Baena*

主要分类: cs.CV

摘要简述: 本文提出了一种无标记的脊柱组织术中跟踪方法，利用消费级RGB-D成像技术，开发了SpineAlign系统和CorrespondNet框架，用于捕捉术前与术中脊柱状态的变形，并提供了首个真实临床脊柱手术数据集。


<details>
  <summary>详细信息</summary>
研究动机: 传统的骨固定跟踪设备增加了手术时间和复杂性，而无标记跟踪技术具有较高的转化潜力，但目前仅限于尸体研究。本文旨在填补这一空白，推动无标记跟踪技术在临床中的应用。

研究方法: 本文引入了首个真实临床脊柱手术的RGB-D数据集，开发了SpineAlign系统用于捕捉脊柱变形，并提出了CorrespondNet框架，通过多任务学习预测术前和术中场景中的关键区域。

研究结果: 研究成功开发了SpineAlign系统和CorrespondNet框架，并在真实临床数据上验证了其有效性，为无标记脊柱组织跟踪提供了实用工具。

研究结论: 本文提出的无标记跟踪方法和系统具有显著的临床潜力，能够减少手术时间和复杂性，为脊柱手术的精准跟踪提供了新思路。

中文摘要: 消费级RGB-D成像用于术中骨科组织跟踪是一种具有高转化潜力的方法。与骨固定跟踪设备不同，无标记跟踪可以减少手术时间和复杂性。然而，其应用目前仅限于尸体研究。本文介绍了首个真实临床脊柱手术的RGB-D数据集，并开发了SpineAlign系统，用于捕捉术前与术中脊柱状态的变形。我们还提出了一种基于该数据的术中分割网络，并介绍了CorrespondNet，一个用于预测术前和术中场景中关键区域的多任务框架。

</details>


### [258] [On the Domain Robustness of Contrastive Vision-Language Models](https://arxiv.org/abs/2506.23663)
**中文标题：对比视觉语言模型的领域鲁棒性研究**

*Mario Koddenbrock,Rudolf Hoffmann,David Brodmann,Erik Rodner*

主要分类: cs.CV

摘要简述: 本文提出了Deepbench框架，用于评估视觉语言模型（VLMs）在特定领域的鲁棒性，通过生成领域相关的图像扰动，揭示了模型在不同领域中的性能差异。


<details>
  <summary>详细信息</summary>
研究动机: 在现实应用中，视觉语言模型虽然表现优异，但在特定领域（如特殊成像条件或环境变化）下性能可能显著下降。由于缺乏透明性，这些模型的领域适应性难以评估，因此需要一种无需标注数据的领域鲁棒性评估方法。

研究方法: Deepbench利用大型语言模型（LLM）生成针对特定领域的上下文感知图像扰动，无需标注数据，从而评估多种对比视觉语言模型及其变体在六个真实领域中的鲁棒性。

研究结果: 实验表明，不同视觉语言模型在领域鲁棒性上存在显著差异，强调了领域感知评估的重要性。Deepbench作为开源工具发布，支持进一步研究。

研究结论: Deepbench为领域鲁棒性评估提供了有效工具，揭示了模型在特定领域中的性能局限性，推动了领域感知模型的发展。

中文摘要: 在现实世界的视觉语言应用中，从业者越来越依赖大规模预训练的基础模型，而非定制解决方案，尽管其训练数据和过程缺乏透明度。尽管这些模型在通用基准测试中表现优异，但在特定领域变化（如独特的成像条件或环境变化）下，其性能可能显著下降。本文提出了Deepbench框架，用于评估视觉语言模型（VLMs）的领域特定鲁棒性。Deepbench利用大型语言模型（LLM）生成针对特定部署领域的、无需标注数据的、上下文感知的真实图像扰动。我们评估了多种对比视觉语言架构及其变体在六个真实领域中的表现，观察到鲁棒性存在显著差异，强调了针对性、领域感知评估的必要性。Deepbench已作为开源软件发布，以支持领域感知鲁棒性评估的进一步研究。

</details>


### [259] [Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration](https://arxiv.org/abs/2506.23674)
**中文标题：部分前向阻断：一种无损训练加速的新型数据剪枝范式**

*Dongyue Wu,Zilin Guo,Jialong Zuo,Nong Sang,Changxin Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为部分前向阻断（PFB）的新型数据剪枝框架，通过自适应剪枝管道显著减少计算开销，同时提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着训练数据集规模的不断增长，现代机器学习模型的泛化能力得到提升，但计算成本也随之激增。现有数据剪枝方法依赖梯度或代理模型，导致额外计算开销巨大。因此，需要一种高效且无损的训练加速方法。

研究方法: PFB通过目标模型浅层提取的特征评估样本重要性，剪枝不重要样本，仅保留样本进行后续前向传递和损失反向传播。此外，PFB引入概率密度作为样本重要性指标，并结合自适应分布估计模块动态优先处理稀有样本。

研究结果: 在ImageNet上，PFB在剪枝40%数据的情况下，实现了0.5%的准确率提升和33%的训练时间减少。

研究结论: PFB通过自适应剪枝和动态样本优先级分配，显著提升了训练效率和模型性能，为大规模数据训练提供了一种高效解决方案。

中文摘要: 训练数据集的不断增长提升了现代机器学习模型的泛化能力，但也带来了高昂的计算成本。现有的数据剪枝方法旨在通过移除重要性较低的样本来加速训练，但这些方法通常依赖梯度或代理模型，导致额外的梯度反向传播和代理模型训练成本过高。本文提出了一种名为部分前向阻断（PFB）的新型无损训练加速框架。PFB的高效性源于其独特的自适应剪枝管道：样本重要性基于目标模型浅层提取的特征进行评估，剪枝不重要样本后，仅保留样本进行后续前向传递和损失反向传播。这一机制显著减少了剪枝样本在深层前向传递和反向传播中的计算开销，同时无需额外的反向计算和代理模型训练。此外，PFB引入概率密度作为样本重要性指标，结合自适应分布估计模块，动态优先处理相对稀有的样本，以适应不断变化的训练状态。大量实验表明，PFB在性能和速度上具有显著优势。在ImageNet上，PFB在剪枝40%数据的情况下，实现了0.5%的准确率提升和33%的训练时间减少。

</details>


### [260] [Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation](https://arxiv.org/abs/2506.23675)
**中文标题：基于块效益的剪枝：探索Vision Transformer块在域适应中的特性**

*Patrick Glandorf,Bodo Rosenhahn*

主要分类: cs.CV

摘要简述: 本文提出了一种基于块效益的剪枝方法P3B，通过全局评估块的贡献来优化资源分配，在保持高性能的同时显著减少计算成本，尤其在迁移学习任务中表现突出。


<details>
  <summary>详细信息</summary>
研究动机: Vision Transformer虽然性能优异，但计算成本高，难以在资源有限的硬件上部署。传统剪枝方法在未见数据域上容易误判权重重要性，导致资源分配不理想。本文旨在解决这一问题。

研究方法: 提出P3B剪枝方法，通过评估块的相对贡献全局分配参数资源，识别低影响组件以减少参数分配，同时保留关键部分。P3B基于全局性能指标设置层保留比例，确保后期收敛块能被重新激活。

研究结果: 实验表明，P3B在剪枝方法中表现优异，尤其在迁移学习任务中效果显著。即使在高稀疏性（70%参数减少）下，仍能保持高性能，仅损失0.64%的准确率。

研究结论: P3B是一种高效的剪枝方法，能够在不显著损失性能的情况下显著减少计算成本，适用于资源受限的硬件部署。

中文摘要: Vision Transformer在多项任务中刷新了性能记录，但其高昂的计算成本使其难以在资源有限的硬件上部署。网络剪枝通过移除不重要操作来降低计算复杂度，同时保持性能。然而，在未见数据域上剪枝会导致权重重要性误判，造成资源分配不理想。本文发现，任务敏感层在初始阶段未能改善下游任务的特征表示，导致早期剪枝决策的性能损失。为解决这一问题，我们提出了基于块效益的剪枝方法P3B，该方法利用块的相对贡献全局分配参数资源。P3B识别低影响组件以减少参数分配，同时保留关键部分。传统剪枝掩码优化难以重新激活零掩码元素，而P3B基于全局性能指标设置层保留比例，确保后期收敛块能被重新激活。大量实验表明，P3B是一种先进的剪枝方法，在迁移学习任务中表现尤为突出。值得注意的是，P3B在高稀疏性（70%参数减少）下仍能保持高性能，仅损失0.64%的准确率。

</details>


### [261] [A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement](https://arxiv.org/abs/2506.23676)
**中文标题：基于潜在优化与迁移增强的隐蔽对抗生成统一框架**

*Gaozheng Pei,Ke Ma,Dongpeng Zhang,Chengzhi Sun,Qianqian Xu,Qingming Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种统一框架，将传统的对抗样本迁移增强策略融入基于扩散模型的图像编辑方法中，解决了扩散模型在Deepfake检测等任务中泛化能力不足的问题，并在ACM MM25竞赛中获得第一名。


<details>
  <summary>详细信息</summary>
研究动机: 由于扩散模型在图像生成方面的强大能力，基于扩散的对抗样本生成方法逐渐流行，但其依赖模型的判别能力，导致在Deepfake检测等任务中泛化能力不足，且传统迁移增强策略难以适配。本文旨在解决这些问题。

研究方法: 提出了一种统一框架，通过潜在优化和迁移增强策略，将传统对抗样本迁移增强方法融入基于扩散模型的图像编辑中，从而提升对抗样本的泛化能力。

研究结果: 该方法在ACM MM25竞赛的“对抗攻击Deepfake检测器”挑战中获得第一名，验证了其有效性。

研究结论: 本文提出的统一框架成功解决了扩散模型在对抗样本生成中的泛化问题，并通过竞赛验证了其实际应用价值。

中文摘要: 由于扩散模型在图像生成方面的强大能力，基于图像编辑的扩散对抗样本生成方法迅速流行。然而，由于依赖扩散模型的判别能力，这些方法在Deepfake检测等任务中往往难以泛化。此外，传统的对抗样本迁移增强策略难以适配这些方法。为解决这些问题，我们提出了一种统一框架，通过图像编辑将传统迁移增强策略无缝融入基于扩散模型的对抗样本生成中，从而扩展其在下游任务中的应用范围。我们的方法在ACM MM25的“对抗攻击Deepfake检测器”挑战中获得第一名，验证了其有效性。

</details>


### [262] [SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation](https://arxiv.org/abs/2506.23690)
**中文标题：SynMotion：面向运动定制视频生成的语义-视觉自适应方法**

*Shuai Tan,Biao Gong,Yujie Wei,Shiwei Zhang,Zhuoxin Liu,Dandan Zheng,Jingdong Chen,Yan Wang,Hao Ouyang,Kecheng Zheng,Yujun Shen*

主要分类: cs.CV

摘要简述: SynMotion提出了一种结合语义引导和视觉适应的运动定制视频生成模型，通过双嵌入语义理解机制和参数高效的运动适配器，提升了运动保真度和时间一致性，并在实验中优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在视频运动定制中过于依赖语义对齐，忽视了视觉复杂性，或仅调整视觉表示导致语义混淆。SynMotion旨在通过联合语义和视觉优化解决这些问题。

研究方法: SynMotion采用双嵌入语义理解机制分离主体和运动表示，并集成参数高效的运动适配器。通过交替优化主体和运动嵌入的训练策略，结合手动构建的SPV数据集，提升运动特异性。

研究结果: 实验表明，SynMotion在文本到视频（T2V）和图像到视频（I2V）任务中均优于现有基线，验证了其运动保真度和时间一致性的优势。

研究结论: SynMotion通过语义与视觉的联合优化，有效解决了运动定制视频生成中的语义混淆和视觉复杂性挑战，为未来研究提供了新方向。

中文摘要: 基于扩散的视频运动定制技术能够从少量视频样本中学习人体运动表示，并通过精确的文本条件实现任意主体的迁移。现有方法通常依赖语义级对齐，期望模型学习新运动概念并将其与其他实体（如“猫”或“狗”）结合以生成视觉吸引力的结果。然而，视频数据涉及复杂的时空模式，仅关注语义会导致模型忽视运动的视觉复杂性。反之，仅调整视觉表示又会导致语义混淆。为解决这些问题，我们提出了SynMotion，一种新的运动定制视频生成模型，联合利用语义引导和视觉适应。在语义层面，我们引入了双嵌入语义理解机制，分离主体和运动表示，使模型能够学习定制化运动特征，同时保留对多样化主体的生成能力。在视觉层面，我们在预训练视频生成模型中集成了参数高效的运动适配器，以增强运动保真度和时间一致性。此外，我们提出了一种新的嵌入特定训练策略，交替优化主体和运动嵌入，并辅以手动构建的主体先验视频（SPV）训练数据集。该策略在保持多样化主体泛化能力的同时，提升了运动特异性。最后，我们提出了MotionBench，一个包含多样化运动模式的新基准。在文本到视频（T2V）和图像到视频（I2V）任务中的实验结果表明，SynMotion优于现有基线。项目页面：https://lucaria-academy.github.io/SynMotion/

</details>


### [263] [Single Image Test-Time Adaptation via Multi-View Co-Training](https://arxiv.org/abs/2506.23705)
**中文标题：基于多视图协同训练的单一图像测试时适应方法**

*Smriti Joshi,Richard Osuala,Lidia Garrucho,Kaisar Kushibar,Dimitri Kessler,Oliver Diaz,Karim Lekadir*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多视图协同训练的单一图像测试时适应方法，用于医学影像的实时分割，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有测试时适应方法依赖大量目标域数据，不适用于医学场景中单患者实时推理的需求，且未能充分利用医学影像的三维信息。

研究方法: 提出了一种基于补丁的多视图协同训练方法，通过不确定性引导的自训练实现特征和预测一致性，仅需单一测试图像即可完成目标域分割。

研究结果: 在三个公开的乳腺MRI数据集上验证，该方法性能接近监督学习的上限，平均Dice相似系数比现有最优方法高3.75%。

研究结论: 该方法在医学影像分割中具有显著优势，代码已开源，便于集成到nnUNet框架中。

中文摘要: 测试时适应使得训练模型能够在推理过程中调整到新领域，特别适用于需要实时调整的临床场景。然而，现有技术依赖于大量目标域数据，这在医学场景中往往不切实际且不可行。此外，当前方法多关注二维图像，未能充分利用医学影像的三维信息。为此，我们提出了一种基于补丁的多视图协同训练方法，用于单一图像的测试时适应。该方法通过不确定性引导的自训练实现特征和预测一致性，仅需单一测试图像即可在目标域中实现有效的三维分割。在三个公开的乳腺MRI数据集上验证，该方法性能接近监督学习的上限，平均Dice相似系数比现有最优方法高3.75%。我们公开了易于与nnUNet框架集成的代码库，网址为https://github.com/smriti-joshi/muvi.git。

</details>


### [264] [Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion](https://arxiv.org/abs/2506.23711)
**中文标题：主观相机：通过序列感知草图引导扩散桥接人类认知与视觉重建**

*Haoyang Chen,Dongfang Sun,Caoyuan Ma,Shiqin Wang,Kewei Zhang,Zheng Wang,Zhixiang Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“主观相机”的方法，通过结合语言描述和渐进式草图，将用户的主观感知转化为逼真图像，解决了现有方法在语言模糊性和草图抽象性上的双重限制。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在用户主观输入偏差、平面草图与3D先验之间的模态鸿沟以及草图质量敏感性能下降等方面存在挑战。本文旨在通过序列感知的草图引导扩散方法，克服这些限制，实现更高效的视觉重建。

研究方法: 1. 通过文本奖励优化建立鲁棒的外观先验；2. 采用序列感知的解耦生成方法，按草图绘制顺序处理概念；3. 使用潜在优化桥接平面草图与3D先验之间的模态鸿沟；4. 通过分层奖励引导框架支持粗糙草图输入。

研究结果: 在多样化数据集上的综合评估表明，该方法在语义和空间一致性方面达到了最先进的性能，且无需训练即可适应用户主观期望。

研究结论: 主观相机框架通过序列感知的草图引导扩散，有效解决了语言和草图的双重限制，为视觉重建提供了一种高效且用户友好的解决方案。

中文摘要: 我们提出了一种名为“主观相机”的人作为成像设备的范式，通过协同使用语言描述和渐进式草图，从心理印象中重建真实场景。该方法通过将用户的绘制序列作为先验，有效克服了语言模糊性和草图抽象性的双重限制，将主观感知期望转化为逼真图像。
现有方法面临三个基本障碍：(1)用户特定的主观输入偏差，(2)平面草图与扩散中3D先验之间的巨大模态鸿沟，(3)草图质量敏感的性能下降。当前解决方案要么需要资源密集的模型适应，要么对草图精度提出不切实际的要求。
我们的框架通过概念顺序生成解决了这些挑战：(1)通过文本奖励优化建立鲁棒的外观先验，然后实现序列感知的解耦生成，按草图绘制顺序处理概念；这些步骤以无需训练的方式适应用户特定的主观期望。(2)采用潜在优化，有效桥接平面草图与扩散中3D先验之间的模态鸿沟。(3)我们的分层奖励引导框架支持使用粗糙草图，无需艺术专业知识。在多样化数据集上的综合评估表明，我们的方法在保持语义和空间一致性方面达到了最先进的性能。

</details>


### [265] [When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation](https://arxiv.org/abs/2506.23724)
**中文标题：以小引大：跨模型协同学习的测试时适应**

*Chang'an Yi,Xiaohui Deng,Guohao Chen,Yan Zhou,Qinghua Lu,Shuaicheng Niu*

主要分类: cs.CV

摘要简述: 本文提出了一种跨模型协同学习框架COCA，用于测试时适应（TTA），通过小模型（如MobileViT）引导大模型（如ViT-Base），显著提升了模型在目标域上的适应性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有TTA方法主要关注单模型适应，而本文探讨了跨模型知识对TTA过程的影响，发现不同模型可以提供互补的自信知识，即使模型规模差异显著。

研究方法: COCA框架包含两种策略：1）协同适应，通过动态整合其他模型的互补知识减少个体模型偏差；2）自我适应，通过无监督学习增强每个模型的独特优势，实现多样化的目标域适应。

研究结果: 实验表明，COCA显著提升了多种模型（如ResNets、ViTs、Mobile-ViTs）在ImageNet-C等数据集上的适应性能，例如ViT-Base的平均适应准确率从51.7%提升至64.5%。

研究结论: COCA作为一种即插即用模块，通过跨模型协同学习有效提升了TTA性能，证明了小模型对大模型的引导作用。

中文摘要: 测试时适应（TTA）通过在线无监督学习将给定模型适应到可能存在域偏移的测试数据上，取得了显著性能。然而，现有TTA方法主要关注单模型适应。本文研究了一个有趣的问题：跨模型知识如何影响TTA过程？我们发现，在TTA的无监督在线设置中，即使模型规模差异显著（如MobileViT（10.6M参数）与ViT-Base（86.6M参数）），每个模型也能为其他模型提供互补的自信知识。基于此，我们提出了COCA，一种跨模型协同学习框架，主要包括两种策略：1）协同适应，动态整合其他模型的互补知识以减少个体模型偏差；2）自我适应，通过无监督学习增强每个模型的独特优势，实现多样化的目标域适应。大量实验表明，COCA作为一种即插即用模块，显著提升了现有SOTA方法在多种模型（如ResNets、ViTs、Mobile-ViTs）上的性能。例如，在MobileViT的引导下，COCA将ViT-Base在ImageNet-C上的平均适应准确率从51.7%提升至64.5%。代码已公开于https://github.com/ycarobot/COCA。

</details>


### [266] [Proteus-ID: ID-Consistent and Motion-Coherent Video Customization](https://arxiv.org/abs/2506.23729)
**中文标题：Proteus-ID：身份一致且运动连贯的视频定制**

*Guiyu Zhang,Chen Shi,Zijian Jiang,Xunzhi Xiang,Jingjing Qian,Shaoshuai Shi,Li Jiang*

主要分类: cs.CV

摘要简述: Proteus-ID是一种基于扩散模型的视频身份定制框架，通过多模态身份融合、时间感知身份注入和自适应运动学习，解决了身份一致性和运动连贯性的挑战，并在实验中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 视频身份定制任务面临身份一致性和运动连贯性的双重挑战。现有方法在保持身份一致性和生成自然运动方面存在不足，因此需要一种新的框架来解决这些问题。

研究方法: 1. 提出多模态身份融合（MIF）模块，通过Q-Former统一视觉和文本线索，提供一致的身份表示。2. 设计时间感知身份注入（TAII）机制，动态调节去噪步骤中的身份条件，改善细节重建。3. 引入自适应运动学习（AML）策略，基于光流运动热图重新加权训练损失，提升运动真实性。

研究结果: Proteus-ID在身份保持、文本对齐和运动质量上优于现有方法，并在高质量数据集Proteus-Bench上验证了其有效性。

研究结论: Proteus-ID通过创新的模块和策略，显著提升了视频身份定制的性能，为该任务设定了新的基准。

中文摘要: 视频身份定制旨在根据单张参考图像和文本提示，合成特定主体的逼真且时间连贯的视频。这一任务面临两大核心挑战：(1) 在保持身份一致性的同时与描述的 appearance 和动作对齐；(2) 生成自然流畅的运动，避免不真实的僵硬感。为解决这些挑战，我们提出了Proteus-ID，一种基于扩散模型的身份一致且运动连贯的视频定制框架。首先，我们提出了多模态身份融合（MIF）模块，通过Q-Former将视觉和文本线索统一为联合身份表示，为扩散模型提供一致的指导并消除模态不平衡。其次，我们设计了时间感知身份注入（TAII）机制，动态调节去噪步骤中的身份条件，改善细节重建。第三，我们提出了自适应运动学习（AML），一种基于光流运动热图重新加权训练损失的自监督策略，无需额外输入即可增强运动真实性。为支持这一任务，我们构建了Proteus-Bench数据集，包含20万条精选训练片段和150名来自不同职业和种族的个体用于评估。大量实验表明，Proteus-ID在身份保持、文本对齐和运动质量上优于现有方法，为视频身份定制设定了新的基准。代码和数据公开于https://grenoble-zhang.github.io/Proteus-ID/。

</details>


### [267] [Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?](https://arxiv.org/abs/2506.23751)
**中文标题：能否通过生成内容挑战街景中的开放词汇目标检测器？**

*Annika Mütze,Sadia Ilyas,Christian Dörpelkus,Matthias Rottmann*

主要分类: cs.CV

摘要简述: 本文探讨了能否通过生成内容挑战开放词汇目标检测器（如Grounding DINO），并发现其系统性的失败模式。通过稳定扩散生成多样化的合成数据，研究发现开放词汇模型容易忽略对象且依赖对象位置而非语义。


<details>
  <summary>详细信息</summary>
研究动机: 开放词汇目标检测器在多样数据上表现优异，但其局限性尚不明确，尤其在安全关键应用中。真实数据缺乏控制性，无法全面评估模型泛化能力，而合成数据能系统性探索模型边界。

研究方法: 设计了两个自动化流程，使用稳定扩散技术从WordNet和ChatGPT采样多样语义对象，生成合成数据。基于LostAndFound和NuImages数据集，评估了多种开放词汇和经典目标检测器。

研究结果: 合成数据表明，开放词汇模型容易忽略对象，且其性能更依赖对象位置而非语义。这为挑战和改进此类模型提供了系统性方法。

研究结论: 通过生成内容可有效挑战开放词汇目标检测器，揭示了其依赖位置而非语义的局限性，为未来数据采集和模型改进提供了方向。

中文摘要: 开放词汇目标检测器（如Grounding DINO）通过大量多样数据训练，在挑战性数据集中表现优异。然而，其局限性尚不明确，尤其在安全关键应用中。真实数据缺乏控制性，无法全面评估模型泛化能力。相比之下，合成生成的数据能系统性探索模型能力边界。本研究探讨两个问题：1）能否通过生成图像内容挑战开放词汇目标检测器？2）能否发现这些模型的系统性失败模式？为此，我们设计了两个自动化流程，利用稳定扩散技术从WordNet和ChatGPT采样多样语义对象进行图像修复。基于LostAndFound和NuImages数据集生成的合成数据，我们评估并比较了多种开放词汇和经典目标检测器。结果表明，图像修复能挑战开放词汇模型的对象忽略问题，并发现其性能更依赖对象位置而非语义。这为挑战开放词汇模型提供了系统性方法，并为改进模型数据采集提供了宝贵见解。

</details>


### [268] [Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking](https://arxiv.org/abs/2506.23783)
**中文标题：Mamba-FETrack V2：基于状态空间模型的帧-事件视觉目标跟踪方法再探**

*Shiao Wang,Ju Huang,Qingchuan Ma,Jinfeng Gao,Chunyi Xu,Xiao Wang,Lan Chen,Bo Jiang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于线性复杂度Vision Mamba网络的高效RGB-Event目标跟踪框架Mamba-FETrack V2，通过轻量级Prompt Generator和FEMamba主干网络实现跨模态特征提取与融合，显著提升了跟踪性能与效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态跟踪算法多依赖高复杂度的Vision Transformer架构，导致计算开销大且跨模态交互效果有限。本文旨在通过线性复杂度的Vision Mamba网络解决这些问题。

研究方法: 设计轻量级Prompt Generator生成模态特定的可学习提示向量，结合Vision Mamba主干网络FEMamba实现提示引导的特征提取、跨模态交互与融合，最终通过跟踪头定位目标。

研究结果: 在多个RGB-Event跟踪基准测试（如COESOT、FE108和FELT V2）中，该框架表现出卓越的性能和效率。

研究结论: Mamba-FETrack V2通过高效的跨模态特征融合框架，显著提升了RGB-Event目标跟踪的性能，同时降低了计算复杂度。

中文摘要: 近年来，结合传统RGB相机与仿生事件相机以实现鲁棒目标跟踪的研究日益受到关注。然而，现有的大多数多模态跟踪算法高度依赖高复杂度的Vision Transformer架构进行跨模态特征提取与融合，这不仅带来巨大的计算开销，还限制了跨模态交互的效果。本文提出了一种基于线性复杂度Vision Mamba网络的高效RGB-Event目标跟踪框架Mamba-FETrack V2。具体而言，我们首先设计了一个轻量级Prompt Generator，利用各模态的嵌入特征和共享提示池动态生成模态特定的可学习提示向量。这些提示向量与模态特定的嵌入特征随后输入基于Vision Mamba的FEMamba主干网络，以统一的方式实现提示引导的特征提取、跨模态交互与融合。最后，融合后的表征被传递至跟踪头以准确定位目标。在多个RGB-Event跟踪基准测试（包括短期的COESOT数据集和长期的FE108与FELT V2数据集）上的广泛实验评估表明，该跟踪框架具有卓越的性能和效率。源代码与预训练模型将在https://github.com/Event-AHU/Mamba_FETrack发布。

</details>


### [269] [Visual Textualization for Image Prompted Object Detection](https://arxiv.org/abs/2506.23785)
**中文标题：基于图像提示的目标检测视觉文本化方法**

*Yongjian Wu,Yang Zhou,Jiya Saiyin,Bingzheng Wei,Yan Xu*

主要分类: cs.CV

摘要简述: 本文提出VisTex-OVLM，一种通过视觉文本化技术增强图像提示目标检测的新方法，能够有效检测罕见类别，同时保持预训练模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的目标检测方法在处理罕见类别时表现不佳，尤其是当这些类别难以用文本描述且预训练数据中几乎不包含时。本文旨在通过视觉文本化技术提升模型对罕见类别的检测能力。

研究方法: VisTex-OVLM采用多尺度文本化块和多阶段融合策略，将视觉示例投影到文本特征空间，生成文本化视觉标记，以指导目标检测模型。该方法保留了原始模型的架构，同时提升了少样本场景下的性能。

研究结果: VisTex-OVLM在开放数据集上表现优异，尤其是在与预训练数据重叠极少的场景中，并在PASCAL VOC和MSCOCO的少样本基准测试中达到了最先进水平。

研究结论: VisTex-OVLM通过视觉文本化技术显著提升了罕见类别的检测能力，同时保持了模型的泛化性能，为少样本目标检测提供了有效解决方案。

中文摘要: 我们提出了VisTex-OVLM，一种新颖的图像提示目标检测方法，引入了视觉文本化技术——将少量视觉示例投影到文本特征空间，以增强对象级视觉语言模型（OVLM）在检测难以用文本描述且预训练数据中几乎不存在的罕见类别时的能力，同时保持其预训练的对象-文本对齐。具体而言，VisTex-OVLM利用多尺度文本化块和多阶段融合策略，整合来自视觉示例的视觉信息，生成文本化视觉标记，有效指导OVLM与文本提示共同工作。与以往方法不同，我们的方法保留了OVLM的原始架构，保持其泛化能力的同时提升了少样本场景下的性能。VisTex-OVLM在与OVLM预训练数据重叠极少的开放数据集上表现出色，并在少样本基准测试PASCAL VOC和MSCOCO上取得了最先进的结果。代码将在https://github.com/WitGotFlg/VisTex-OVLM发布。

</details>


### [270] [Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors](https://arxiv.org/abs/2506.23801)
**中文标题：基于可控参考的生成扩散先验真实世界遥感图像超分辨率**

*Ce Wang,Wanjie Sun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CRefDiff的可控参考超分辨率扩散模型，用于解决遥感图像超分辨率任务中的欠生成和过度依赖参考图像问题。通过结合预训练的Stable Diffusion模型和双分支融合机制，CRefDiff在真实数据集上表现优异，并显著提升了推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的参考超分辨率方法在真实场景中面临跨传感器分辨率差异和地表覆盖变化等挑战，容易导致欠生成或过度依赖参考图像。本文旨在通过引入生成扩散先验和可控融合机制来解决这些问题。

研究方法: CRefDiff基于预训练的Stable Diffusion模型，利用其强大的生成能力生成精确的结构和纹理。通过双分支融合机制自适应地整合参考图像的局部和全局信息，并引入Better Start策略减少去噪步骤以加速推理。

研究结果: 在真实数据集Real-RefRSSRD上的实验表明，CRefDiff在多项指标上达到最优性能，并显著提升了场景分类和语义分割等下游任务的效果。

研究结论: CRefDiff通过结合生成扩散先验和可控融合机制，有效解决了遥感图像超分辨率中的关键问题，为真实场景应用提供了高效灵活的解决方案。

中文摘要: 超分辨率（SR）技术可以通过利用低分辨率（LR）图像重建高分辨率（HR）图像，提升遥感图像的空间分辨率，从而支持更高效的大规模地球观测应用。尽管单图像超分辨率（SISR）方法已取得进展，但基于参考的超分辨率（RefSR）通过结合历史HR图像和当前LR观测数据，表现出更优的性能。然而，现有的RefSR方法在真实场景中面临跨传感器分辨率差异和显著地表覆盖变化等复杂问题，常导致欠生成或过度依赖参考图像。为解决这些问题，我们提出了CRefDiff，一种新型可控参考扩散模型，用于真实世界遥感图像超分辨率。为解决欠生成问题，CRefDiff基于预训练的Stable Diffusion模型，利用其强大的生成先验生成准确的结构和纹理。为缓解对参考图像的过度依赖，我们引入了双分支融合机制，自适应地整合参考图像的局部和全局信息。此外，这种新颖的双分支设计在推理过程中实现了参考强度的控制，增强了模型的交互性和灵活性。最后，我们提出了一种名为Better Start的策略，显著减少了去噪步骤，从而加速了推理过程。为支持进一步研究，我们提出了Real-RefRSSRD数据集，这是一个真实世界的遥感图像RefSR数据集，包含HR NAIP和LR Sentinel-2图像对，涵盖多样化的地表覆盖变化和显著的时间差异。在Real-RefRSSRD上的大量实验表明，CRefDiff在多项指标上达到最优性能，并提升了场景分类和语义分割等下游任务的效果。

</details>


### [271] [Towards Initialization-free Calibrated Bundle Adjustment](https://arxiv.org/abs/2506.23808)
**中文标题：迈向无需初始化的校准束调整**

*Carl Olsson,Amanda Nilsson*

主要分类: cs.CV

摘要简述: 本文提出了一种无需初始化的校准束调整方法，通过引入相对旋转估计，结合相机标定信息，实现接近度量精度的重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有无需初始化的束调整方法（如pOSE）无法利用相机标定信息，导致重建结果仅能确定到投影变换级别，且需要更多数据。本文旨在解决这一问题，提出一种能够利用标定信息的方法，实现更高精度的重建。

研究方法: 本文方法通过引入成对相对旋转估计，将相机标定信息融入pOSE框架中。这些旋转估计仅对相似变换保持不变，从而鼓励重建结果保留真实场景的度量特征。

研究结果: 实验表明，该方法能够可靠地优化目标函数，从随机初始解高概率收敛到全局最小值，生成接近度量精度的重建结果。

研究结论: 本文方法成功将旋转平均技术整合到pOSE框架中，实现了无需初始化的校准束调整，显著提升了重建精度。

中文摘要: 最近的一系列研究表明，通过使用伪物体空间误差（pOSE）作为替代目标，可以实现无需初始化的束调整。然而，初始重建步骤优化的目标中所有项均为投影不变，无法利用相机标定信息，导致重建结果仅能确定到投影变换级别，且需要更多数据才能成功重建。相比之下，本文提出了一种能够利用已知相机标定的方法，从而生成接近度量精度的重建结果（即仅差一个相似变换）。为实现这一目标，我们引入了携带相机标定信息的成对相对旋转估计。这些估计仅对相似变换保持不变，从而鼓励重建结果保留真实场景的度量特征。我们的方法可视为将旋转平均技术整合到pOSE框架中，致力于实现无需初始化的校准运动结构恢复（SfM）。实验评估表明，我们能够可靠地优化目标函数，从随机初始解高概率收敛到全局最小值，生成接近度量精度的重建结果。

</details>


### [272] [MadCLIP: Few-shot Medical Anomaly Detection with CLIP](https://arxiv.org/abs/2506.23810)
**中文标题：MadCLIP：基于CLIP的少样本医学异常检测**

*Mahshid Shiri,Cigdem Beyan,Vittorio Murino*

主要分类: cs.CV

摘要简述: 提出了一种创新的少样本医学异常检测方法MadCLIP，利用预训练的CLIP模型，通过双分支设计和可学习文本提示提升语义对齐，首次在医学领域应用SigLIP损失，无需合成数据或记忆库，在多项评估中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 医学异常检测通常面临数据稀缺问题，传统方法依赖大量标注数据或合成数据。本文旨在利用预训练的CLIP模型，通过少样本学习解决医学图像异常分类和分割问题，减少对合成数据或记忆库的依赖。

研究方法: 提出双分支设计，通过可学习适配器在CLIP视觉编码器中分别捕获正常和异常特征；使用可学习文本提示增强视觉特征的语义对齐；首次在医学领域应用SigLIP损失处理图像与未配对文本提示的多对一关系。

研究结果: 在多种模态数据上验证了方法的有效性，在相同数据集和跨数据集评估中，异常分类和分割性能均优于现有方法。消融实验证实了各组件的贡献。

研究结论: MadCLIP为少样本医学异常检测提供了一种高效解决方案，无需依赖合成数据或记忆库，展示了CLIP模型在医学领域的强大适应能力。

中文摘要: 本文提出了一种创新的少样本异常检测方法，利用预训练的CLIP模型处理医学数据，并适应图像级异常分类（AC）和像素级异常分割（AS）。通过双分支设计，在CLIP视觉编码器中分别捕获正常和异常特征。为提升语义对齐，采用可学习文本提示链接视觉特征。此外，首次在医学领域应用SigLIP损失，有效处理图像与未配对文本提示的多对一关系。方法在多种模态数据上验证，AC和AS性能均优于现有方法，且不依赖合成数据或记忆库。消融实验证实了各组件的贡献。代码发布于https://github.com/mahshid1998/MadCLIP。

</details>


### [273] [Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model](https://arxiv.org/abs/2506.23822)
**中文标题：基于局部对齐视觉语言模型的可解释零样本学习**

*Shiming Chen,Bowen Duan,Salman Khan,Fahad Shahbaz Khan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LaZSL的局部对齐视觉语言模型，用于解决大规模视觉语言模型（如CLIP）在零样本学习中缺乏可解释性的问题。通过局部视觉-语义对齐和最优传输方法，LaZSL实现了视觉区域与属性的有效对齐，提升了模型的解释性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大规模视觉语言模型（如CLIP）在零样本学习中取得了显著成功，但其预测过程缺乏可解释性。这些模型通常通过计算整个查询图像与嵌入类别词之间的相似性来进行分类，难以解释预测结果。因此，本文旨在开发一种可解释的模型，通过局部对齐视觉特征与属性，模拟人类感知方式。

研究方法: 本文提出LaZSL模型，利用最优传输方法实现局部视觉-语义对齐。该方法通过视觉区域与相关属性之间的交互，实现有效的对齐，无需额外训练即可提供可解释的相似性。

研究结果: 实验表明，LaZSL在多个方面具有优势，包括增强的可解释性、更高的准确性以及强大的领域泛化能力。

研究结论: LaZSL通过局部视觉-语义对齐解决了零样本学习中的可解释性问题，同时提升了性能和泛化能力，为未来研究提供了新的方向。

中文摘要: 大规模视觉语言模型（如CLIP）通过利用大规模视觉-文本配对数据集，在零样本学习（ZSL）中取得了显著成功。然而，这些方法通常缺乏可解释性，因为它们计算的是整个查询图像与嵌入类别词之间的相似性，难以解释其预测结果。为解决这一问题，一种方法是开发可解释模型，通过整合语言（如使用离散属性构建分类器）模拟人类感知。这带来了新的挑战：如何基于预训练的视觉语言模型，有效对齐局部视觉特征与相应属性。为此，我们提出LaZSL，一种用于可解释零样本学习的局部对齐视觉语言模型。LaZSL通过最优传输实现局部视觉-语义对齐，在视觉区域与其相关属性之间进行交互，无需额外训练即可实现有效对齐并提供可解释的相似性。大量实验表明，我们的方法具有多项优势，包括增强的可解释性、更高的准确性以及强大的领域泛化能力。代码发布于：https://github.com/shiming-chen/LaZSL。

</details>


### [274] [Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2506.23825)
**中文标题：Flash-VStream：高效实时理解长视频流**

*Haoji Zhang,Yiqin Wang,Yansong Tang,Yong Liu,Jiashi Feng,Xiaojie Jin*

主要分类: cs.CV

摘要简述: Flash-VStream是一种高效的视频语言模型，能够实时处理超长视频并响应用户查询，通过设计Flash Memory模块显著降低推理延迟，在多个长视频基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态大语言模型在图像和短视频理解上表现突出，但对长视频的理解仍面临挑战，因其长上下文特性导致计算和内存开销巨大。现有方法将长视频与短视频同等处理，效率低下且难以泛化到更长视频。

研究方法: 提出Flash-VStream，设计Flash Memory模块，包含低容量上下文记忆用于聚合长上下文时间信息并建模信息密度分布，以及高容量增强记忆用于基于此分布检索详细空间信息。

研究结果: 在EgoSchema、MLVU、LVBench、MVBench和Video-MME等长视频基准测试中，Flash-VStream实现了显著的推理延迟降低，并展现出卓越的性能和效率。

研究结论: Flash-VStream通过创新的Flash Memory模块，有效解决了长视频理解的计算和内存问题，为实时长视频处理提供了高效解决方案。

中文摘要: 得益于大语言模型和跨模态对齐的进步，现有的多模态大语言模型在图像和短视频理解上取得了显著性能。然而，长视频的理解仍然具有挑战性，因其长上下文特性导致显著的计算和内存开销。大多数现有工作将长视频与短视频同等处理，这在实际应用中效率低下且难以泛化到更长视频。为解决这些问题，我们提出了Flash-VStream，一种能够处理超长视频并实时响应用户查询的高效视频语言模型。特别地，我们设计了一个Flash Memory模块，包含一个低容量上下文记忆用于聚合长上下文时间信息并建模信息密度分布，以及一个高容量增强记忆用于基于此分布检索详细空间信息。与现有模型相比，Flash-VStream显著降低了推理延迟。在EgoSchema、MLVU、LVBench、MVBench和Video-MME等长视频基准测试和综合视频基准测试上的广泛实验表明，我们的方法具有最先进的性能和出色的效率。代码可在https://github.com/IVGSZ/Flash-VStream获取。

</details>


### [275] [Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning](https://arxiv.org/abs/2506.23827)
**中文标题：基于双尺度对比学习的空间基因表达预测**

*Mingcheng Qu,Yuncong Wu,Donglin Di,Yue Gao,Tonghua Su,Yang Song,Lei Fan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为NH2ST的双尺度对比学习框架，用于从病理全切片图像预测基因表达，通过整合空间上下文和病理与基因模态，显著提升了预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 空间转录组学（ST）成本高且复杂，而从病理全切片图像预测基因表达成为替代方案。现有方法通常忽略目标与邻近区域的复杂空间和分子相互作用，导致无法捕捉跨模态关系。

研究方法: NH2ST框架包括查询分支和邻近分支，分别处理目标区域及其邻近区域的病理和基因数据，利用交叉注意力和对比学习捕捉内在关联并确保病理与基因表达的对齐。

研究结果: 在六个数据集上的实验表明，NH2ST显著优于现有方法，PCC指标提升超过20%。

研究结论: NH2ST通过整合空间上下文和多模态数据，有效解决了基因表达预测中的跨模态对齐问题，为相关研究提供了新思路。

中文摘要: 空间转录组学（ST）为组织微环境提供了重要见解，但其高成本和复杂性限制了应用。作为替代方案，从病理全切片图像（WSI）预测基因表达逐渐受到关注。然而，现有方法通常依赖单一图像块或单一病理模态，忽略了目标与邻近信息（如基因共表达）之间的复杂空间和分子相互作用，导致无法建立相邻区域间的联系或捕捉跨模态关系。为解决这些问题，我们提出了NH2ST框架，整合空间上下文以及病理和基因模态以预测基因表达。该模型包含查询分支和邻近分支，分别处理目标图像块及其邻近区域的病理和基因数据，利用交叉注意力和对比学习捕捉内在关联并确保病理与基因表达的对齐。在六个数据集上的广泛实验表明，NH2ST始终优于现有方法，PCC指标提升超过20%。代码可在https://github.com/MCPathology/NH2ST获取。

</details>


### [276] [Low-latency vision transformers via large-scale multi-head attention](https://arxiv.org/abs/2506.23832)
**中文标题：基于大规模多头注意力的低延迟视觉Transformer**

*Ronit D. Gross,Tal Halevi,Ella Koresh,Yarden Tzach,Ido Kanter*

主要分类: cs.CV

摘要简述: 通过量化单节点性能（SNP）发现，多头注意力（MHA）在分类任务中会出现自发对称性破缺，表明每个头通过合作专注于部分标签。这一机制被推广到大规模MHA（LS-MHA），通过单头性能（SHP）矩阵实现高信噪比（SNR），提升分类精度。此外，用卷积层替换初始Transformer块可显著降低延迟而不影响精度。


<details>
  <summary>详细信息</summary>
研究动机: 研究多头注意力（MHA）在分类任务中的自发对称性破缺现象，并探索如何通过量化单头性能（SHP）矩阵优化大规模MHA（LS-MHA），以提高Transformer架构的分类精度和降低延迟。

研究方法: 通过量化单节点性能（SNP）和单头性能（SHP）矩阵，分析多头注意力的自发对称性破缺现象，并设计大规模MHA（LS-MHA）结构。此外，用卷积层替换初始Transformer块以加速早期学习。

研究结果: 发现SHP矩阵包含多个单元簇，每个标签由少数头明确识别且噪声可忽略，显著提高信噪比（SNR）和分类精度。用卷积层替换初始Transformer块可显著降低延迟。

研究结论: 大规模MHA（LS-MHA）通过SHP矩阵优化信噪比，提升分类精度，而卷积层替换初始Transformer块可降低延迟。这一机制可推广至自然语言处理任务，为深度学习提供新见解。

中文摘要: 最近通过量化单节点性能（SNP）发现，在分类任务中，多头注意力（MHA）的少数头会自发出现对称性破缺，表明每个头通过其SNP的合作专注于部分标签。这一学习机制被推广至大规模MHA（LS-MHA），使用类似于卷积神经网络（CNN）中单滤波器性能的单头性能（SHP）矩阵。结果表明，每个SHP矩阵包含多个单元簇，每个标签由少数头明确识别且噪声可忽略，从而沿Transformer块提高信噪比（SNR）并提升分类精度。这些特性催生了多种视觉Transformer（ViT）架构，它们精度相同但LS-MHA结构不同。其软委员会机制实现了更高精度，而CNN依赖数百滤波器通常无法实现。此外，用卷积层替换初始Transformer块可显著降低延迟而不影响精度，加速早期学习并由后续Transformer层优化。这一学习机制可扩展至自然语言处理任务，基于CNN与ViT架构的量化差异，有望为深度学习带来新见解。研究结果通过CIFAR-100数据集训练的紧凑卷积Transformer架构验证。

</details>


### [277] [PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric](https://arxiv.org/abs/2506.23833)
**中文标题：PointSSIM：一种新型低维分辨率不变的图像比较指标**

*Oscar Ovanger,Ragnar Hauge,Jacob Skauvold,Michael J. Pyrcz,Jo Eidsvik*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PointSSIM的新型低维图像比较指标，具有分辨率不变性，适用于不同分辨率的二值图像结构分析。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像比较方法在处理不同分辨率的二值图像时存在局限性，需要一种能够捕捉结构特征且分辨率不变的指标。

研究方法: PointSSIM结合结构相似性指数和数学形态学，将二值图像转换为标记点模式表示，提取关键特征（锚点），并通过总结向量比较图像的强度、连通性、复杂性和结构属性。

研究结果: 实验表明，PointSSIM能够高效可靠地比较不同分辨率的图像，特别适用于结构分析任务。

研究结论: PointSSIM为跨分辨率图像比较提供了一种有效的解决方案，尤其适用于需要结构分析的场景。

中文摘要: 本文提出了一种名为PointSSIM的新型低维图像比较指标，具有分辨率不变性。该方法受结构相似性指数和数学形态学的启发，通过将二值图像转换为标记点模式表示，实现了对不同分辨率图像的鲁棒比较。关键特征（锚点）通过从最小距离变换中提取局部自适应最大值来获得。图像比较通过总结向量进行，捕捉强度、连通性、复杂性和结构属性。结果表明，该方法为图像比较提供了一种高效可靠的方式，特别适用于需要跨分辨率结构分析的应用。

</details>


### [278] [Refine Any Object in Any Scene](https://arxiv.org/abs/2506.23835)
**中文标题：在任何场景中优化任何物体**

*Ziwei Chen,Ziling Liu,Zitong Huang,Mingqi Gao,Feng Zheng*

主要分类: cs.CV

摘要简述: RAISE是一种新型3D增强框架，通过利用3D生成先验，在缺失视角下恢复细粒度物体几何和外观，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 场景重建中物体视角缺失是常见问题，现有方法难以同时实现高保真物体级建模和精确场景级表示。解决这一问题对需要详细物体理解和外观建模的下游任务至关重要。

研究方法: RAISE采用两阶段优化方法：首先用3D生成模型替换退化物体为代理，逐步优化几何和纹理；其次通过注册约束增强校正空间和外观不一致性。

研究结果: 在多个挑战性基准测试中，RAISE在新视角合成和几何补全任务中显著优于现有方法。

研究结论: RAISE通过两阶段优化实现了高保真物体几何和外观恢复，同时保持了空间定位和观察一致性，为3D场景重建提供了有效解决方案。

中文摘要: 在场景重建中，物体视角缺失是常见问题，因为相机路径通常优先捕捉整体场景结构而非单个物体。这使得在保持精确场景级表示的同时实现高保真物体级建模极具挑战性。解决这一问题对需要详细物体理解和外观建模的下游任务至关重要。本文提出了一种新型3D增强框架RAISE，利用3D生成先验在缺失视角下恢复细粒度物体几何和外观。RAISE从用代理替换退化物体开始，通过具有强大3D理解能力的生成模型逐步优化几何和纹理，首先对齐代理与退化物体的7自由度位姿，然后通过注册约束增强校正空间和外观不一致性。这种两阶段优化确保了原始物体在未见视角下的高保真几何和外观，同时保持了空间定位、观察几何和外观的一致性。在多个挑战性基准测试中，RAISE在新视角合成和几何补全任务中显著优于现有方法。RAISE已在https://github.com/PolySummit/RAISE公开提供。

</details>


### [279] [RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment](https://arxiv.org/abs/2506.23852)
**中文标题：RGC-VQA：机器人生成视频质量评估的探索数据库**

*Jianing Jin,Jiangyong Ying,Huiyu Duan,Liu Yang,Sijing Wu,Yunhao Li,Yushuo Zheng,Xiongkuo Min,Guangtao Zhai*

主要分类: cs.CV

摘要简述: 本文提出了首个机器人生成内容视频质量评估数据库（RGCD），包含2100个视频，并进行了主观实验和基准测试，揭示了现有VQA模型在评估机器人生成视频时的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器人平台在生活中的普及，机器人生成的视频（RGC）在流媒体平台上出现，但其独特的失真和视觉需求尚未得到专门研究。本文旨在填补这一空白，并为机器人应用提供支持。

研究方法: 建立了首个机器人生成内容数据库（RGCD），包含2100个来自三类机器人的视频，并进行了主观VQA实验和11种先进VQA模型的基准测试。

研究结果: 实验结果表明，现有VQA模型在评估复杂的机器人生成视频时表现不佳，凸显了对RGC专用VQA模型的需求。

研究结论: 本文提出的RGCD为机器人生成视频质量评估提供了重要资源，并揭示了现有模型的不足，为未来研究指明了方向。

中文摘要: 随着配备摄像头的机器人平台日益融入日常生活，机器人生成的视频开始出现在流媒体平台上，使我们能够预见人类与机器人共存的未来。我们创新性地提出了机器人生成内容（RGC）的概念，用于指代这些从机器人第一视角生成的视频。RGC视频的感知质量在人机交互场景中至关重要，且其独特的失真和视觉需求与专业生成内容（PGC）和用户生成内容（UGC）视频显著不同。然而，针对RGC视频质量评估的专门研究仍属空白。为填补这一空白并支持更广泛的机器人应用，我们建立了首个机器人生成内容数据库（RGCD），包含来自三类机器人和多个平台的2100个视频。随后进行了主观VQA实验以评估人类对机器人生成视频的视觉感知。最后，我们进行了基准实验，评估了11种先进VQA模型在数据库上的表现。实验结果表明，现有VQA模型在应用于复杂的机器人生成内容时存在显著局限性，凸显了对RGC专用VQA模型的迫切需求。我们的RGCD已在https://github.com/IntMeGroup/RGC-VQA公开。

</details>


### [280] [HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity](https://arxiv.org/abs/2506.23854)
**中文标题：HiNeuS：高保真神经表面重建方法，解决低纹理与反射模糊问题**

*Yida Wang,Xueyang Zhang,Kun Zhan,Peng Jia,Xianpeng Lang*

主要分类: cs.CV

摘要简述: HiNeuS是一种高保真神经表面重建框架，通过统一方法解决了多视角辐射不一致、低纹理区域关键点缺失和Eikonal约束过度导致的几何退化问题，实现了21.4%的Chamfer距离减少和2.32 dB PSNR提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有神经表面重建方法在复杂场景下难以兼顾几何保真度和光度一致性，尤其是在低纹理和反射区域表现不佳。HiNeuS旨在通过统一框架解决这些问题。

研究方法: HiNeuS提出三种创新方法：1) 基于SDF的微分可见性验证，通过连续遮挡建模解决反射模糊；2) 平面共形正则化，通过射线对齐几何块增强局部表面一致性；3) 物理基础的Eikonal松弛，动态调整几何约束以保留细节。

研究结果: 实验表明，HiNeuS在合成和真实数据集上表现优异，Chamfer距离减少21.4%，PSNR提升2.32 dB，并能恢复镜面仪器、厘米级城市布局和低纹理表面。

研究结论: HiNeuS通过统一框架实现了几何与外观约束的协同优化，显著提升了复杂场景下的表面重建质量，并展示了在逆渲染任务中的通用性。

中文摘要: 神经表面重建在复杂场景下始终面临几何保真度与光度一致性难以兼顾的挑战。本文提出HiNeuS，一个统一框架，全面解决了现有方法的三个核心问题：多视角辐射不一致、低纹理区域关键点缺失以及联合优化中Eikonal约束过度导致的几何退化。通过统一流程，HiNeuS引入：1) 基于SDF的微分可见性验证，通过连续遮挡建模解决反射模糊；2) 平面共形正则化，通过射线对齐几何块增强局部表面一致性；3) 物理基础的Eikonal松弛，动态调整几何约束以保留细节。与现有方法不同，HiNeuS实现了外观与几何约束的协同优化。在合成和真实数据集上的综合评估表明，其性能达到领先水平，Chamfer距离减少21.4%，PSNR提升2.32 dB。定性分析显示，HiNeuS能有效恢复镜面仪器、厘米级城市布局和低纹理表面。此外，该方法在逆渲染任务（如材质分解和视角一致重光照）中也表现出良好的通用性。

</details>


### [281] [A Closer Look at Conditional Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2506.23856)
**中文标题：深入探讨视觉语言模型中的条件提示调优**

*Ji Zhang,Shihan Wu,Lianli Gao,Jingkuan Song,Nicu Sebe,Heng Tao Shen*

主要分类: cs.CV

摘要简述: 本文研究了视觉语言预训练模型（VLPMs）中的条件提示调优（PT）问题，发现现有方法使用视觉图像信息（VII）作为提示条件效果不佳，甚至不如随机噪声。通过分析，作者提出基于文本类别信息（TCI）的动态提示学习是关键，并提出了类自适应提示调优（CaPT）方法，显著提升了模型在新任务上的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管提示调优（PT）在适应大规模视觉语言预训练模型（VLPMs）到下游任务中表现出潜力，但其面临基础-新任务权衡（BNT）问题：模型在基础任务上表现越好，泛化到新任务的能力越差。现有条件PT方法使用视觉图像信息（VII）作为提示条件，效果有限。本文旨在解决这一问题。

研究方法: 作者首先分析了现有条件PT方法的不足，发现VII作为提示条件效果不佳。进一步研究发现，基于文本类别信息（TCI）的动态提示学习是解决BNT问题的关键。为此，提出了类自适应提示调优（CaPT）方法，通过学习基础类的TCI条件提示，快速适应新类。CaPT还可作为插件提升现有无条件PT方法的性能。

研究结果: 在11个数据集上的实验表明，CaPT显著提升了五种强无条件PT基线的性能，且额外计算成本可忽略。结合DePT框架，提出的DeCaPT方法在11个数据集上的平均性能优于当前最优条件PT方法3.49%。

研究结论: 本文揭示了TCI在动态提示学习中的重要性，提出的CaPT方法有效解决了BNT问题，显著提升了模型在新任务上的泛化能力。DeCaPT进一步展示了其与现有框架结合的潜力。

中文摘要: 尽管提示调优（PT）在适应大规模视觉语言预训练模型（VLPMs）到下游任务中表现出巨大潜力，但其往往难以克服基础-新任务权衡（BNT）困境：随着VLPMs在基础任务上的调优效果提升，其泛化到新任务的能力减弱。最近的条件PT研究通过用动态视觉图像信息（VII）条件提示替换静态提示，在一定程度上改善了模型的泛化能力。本文首先指出现有条件PT方法的一个关键问题：使用VII作为提示条件效果不佳，甚至随机噪声条件提示也能优于VII条件提示。进一步分析发现，基于文本类别信息（TCI）的动态提示学习是解决BNT问题的关键。受此启发，我们提出了类自适应提示调优（CaPT），通过学习基础类的TCI条件提示，实现模型对新类的快速适应。值得注意的是，CaPT可作为插件缓解现有无条件PT方案的BNT问题。在11个数据集上的大量实验表明，CaPT以可忽略的额外计算成本，持续提升了五种强无条件PT基线的性能。此外，通过将CaPT与我们最近提出的DePT框架结合，设计了一种新的条件PT方法DeCaPT，其在11个数据集上的平均性能优于当前最优条件PT方法3.49%。代码：https://github.com/Koorye/CaPT。

</details>


### [282] [VMoBA: Mixture-of-Block Attention for Video Diffusion Models](https://arxiv.org/abs/2506.23858)
**中文标题：VMoBA：视频扩散模型的混合块注意力机制**

*Jianzong Wu,Liang Hou,Haotian Yang,Xin Tao,Ye Tian,Pengfei Wan,Di Zhang,Yunhai Tong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为VMoBA的新型稀疏注意力机制，专为视频扩散模型（VDMs）设计，通过动态块分区和全局块选择显著提升了训练和推理效率，同时保持了生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 全注意力机制的二次复杂度限制了视频扩散模型在生成长时长、高分辨率视频时的效率。现有稀疏注意力方法未能充分捕捉视频数据的时空特性，因此需要一种更高效的注意力机制。

研究方法: VMoBA通过以下改进优化了原始MoBA框架：(1) 分层循环块分区方案（1D-2D-3D）以适应多样化的时空注意力模式；(2) 全局块选择以突出最重要的查询-键块交互；(3) 基于阈值的块选择动态确定注意力块数量。

研究结果: 实验表明，VMoBA显著提升了VDMs的训练效率，在长序列上实现了2.92倍FLOPs和1.48倍延迟加速，生成质量与全注意力相当或更优。推理时也表现出色，实现了2.40倍FLOPs和1.35倍延迟加速。

研究结论: VMoBA是一种高效的稀疏注意力机制，适用于视频扩散模型，显著提升了训练和推理效率，同时保持了高质量的生成能力。

中文摘要: 全注意力机制的二次复杂度成为视频扩散模型（VDMs）生成长时长、高分辨率视频的主要瓶颈。尽管已有多种稀疏注意力方法，但它们多为无需训练的推理加速器，或未在原生训练中充分捕捉视频数据的独特时空特性。本文提出视频混合块注意力（VMoBA），一种专为VDMs设计的稀疏注意力机制。通过对预训练视频变换器中注意力模式的深入分析，发现其具有强时空局部性、查询重要性变化和头部特异性集中度。VMoBA在原始MoBA框架基础上引入三项关键改进：(1) 分层循环块分区方案（1D-2D-3D），动态适应多样化时空注意力模式并提升效率；(2) 全局块选择，优先处理整个注意力头中最显著的查询-键块交互；(3) 基于阈值的块选择，根据累积相似度动态确定注意力块数量。大量实验表明，VMoBA显著加速了VDMs在长序列上的训练，实现了2.92倍FLOPs和1.48倍延迟加速，同时生成质量与全注意力相当或更优。此外，VMoBA在无需训练的推理中表现优异，为高分辨率视频生成提供了2.40倍FLOPs和1.35倍延迟加速。

</details>


### [283] [Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction](https://arxiv.org/abs/2506.23863)
**中文标题：Puzzles：用于可扩展端到端3D重建的无界视频-深度数据增强**

*Jiahao Ma,Lei Wang,Miaomiao liu,David Ahmedt-Aristizabal,Chuong Nguyen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Puzzles的数据增强策略，通过从单张图像或视频片段合成无限量的高质量视频-深度数据，显著提升了多视角3D重建的性能。实验表明，即使仅使用10%的原始数据，结合Puzzles训练的模型仍能达到与完整数据集相当的精度。


<details>
  <summary>详细信息</summary>
研究动机: 多视角3D重建是计算机视觉领域的核心挑战之一。现有方法（如DUST3R及其后续模型）直接从图像对回归点云图，但其性能受限于训练数据的多样性和规模。本文旨在通过数据增强策略解决这一问题。

研究方法: Puzzles是一种数据增强策略，通过模拟多样化的相机轨迹和真实场景几何，从单张图像或视频片段合成高质量的视频-深度数据。该方法通过针对性的图像变换增强数据多样性，无需修改底层网络架构。

研究结果: 实验表明，将Puzzles集成到现有的基于视频的3D重建流程中，能够显著提升性能。即使仅使用10%的原始数据，结合Puzzles训练的模型仍能达到与完整数据集相当的精度。

研究结论: Puzzles作为一种高效的数据增强策略，显著提升了多视角3D重建的性能，且无需修改网络架构。该方法为小规模数据集下的高性能模型训练提供了可行方案。

中文摘要: 多视角3D重建仍然是计算机视觉领域的核心挑战。近期的方法（如DUST3R及其后续模型）直接从图像对回归点云图，而不依赖于已知的场景几何或相机参数。然而，这些模型的性能受限于可用训练数据的多样性和规模。本文提出Puzzles，一种数据增强策略，能够从单张图像或视频片段合成无限量的高质量视频-深度数据。通过模拟多样化的相机轨迹和真实场景几何，Puzzles显著提升了数据多样性。大量实验表明，将Puzzles集成到现有的基于视频的3D重建流程中，能够在不修改底层网络架构的情况下持续提升性能。值得注意的是，仅使用10%的原始数据并结合Puzzles训练的模型，仍能达到与完整数据集相当的精度。代码发布于https://jiahao-ma.github.io/puzzles/。

</details>


### [284] [Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2506.23881)
**中文标题：基于虚假感知的原型优化用于可靠的外分布检测**

*Reihaneh Zohrabi,Hosein Hasani,Mahdieh Soleymani Baghshah,Anna Rohrbach,Marcus Rohrbach,Mohammad Hossein Rohban*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SPROD的新型原型后处理方法，用于解决OOD检测中由虚假相关性引起的鲁棒性问题，无需额外数据或超参数调整，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 在现实应用中，机器学习模型常遇到训练时未见的数据分布，而现有OOD检测方法易受虚假相关性影响，导致鲁棒性不足。本文旨在解决这一问题。

研究方法: SPROD通过后处理方式优化类别原型，减少虚假特征带来的偏差，适用于多种骨干网络和OOD检测场景，无需额外数据或超参数调整。

研究结果: 在多个具有挑战性的OOD数据集（如CelebA、Waterbirds等）上，SPROD平均将AUROC提升4.7%，FPR@95降低9.3%，表现优于其他方法。

研究结论: SPROD是一种高效且通用的OOD检测方法，能够显著减少虚假相关性的影响，提升模型的鲁棒性和可靠性。

中文摘要: 外分布（OOD）检测对于确保机器学习模型在现实应用中的可靠性和安全性至关重要，因为模型常会遇到训练时未见的数据分布。尽管已有进展，现有方法仍易受虚假相关性误导，影响鲁棒性。为此，我们提出SPROD，一种新型基于原型的OOD检测方法，明确解决未知虚假相关性带来的挑战。我们的后处理方法优化类别原型，减少虚假特征的偏差，无需额外数据或超参数调整，且适用于多种骨干网络和OOD检测场景。我们进行了全面的虚假相关性OOD检测基准测试，比较了SPROD与其他方法，并在CelebA、Waterbirds、UrbanCars、Spurious Imagenet及新引入的Animals MetaCoCo等挑战性OOD数据集上展示了其优越性能。平均而言，SPROD将AUROC提升了4.7%，FPR@95降低了9.3%，优于其他方法。

</details>


### [285] [PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View](https://arxiv.org/abs/2506.23897)
**中文标题：PriOr-Flow：通过正交视图增强原始全景光流**

*Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang*

主要分类: cs.CV

摘要简述: PriOr-Flow通过正交视图增强全景光流估计，提出双分支框架和DCCL算子，有效减少极地区域失真，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 全景光流在极地区域因球面到平面投影（如ERP）产生严重失真，传统基于透视的光流方法性能下降，亟需解决方案。

研究方法: 提出PriOr-Flow双分支框架，利用正交视图低失真特性，引入DCCL算子联合检索原始和正交成本体积信息，并通过ODDC模块迭代优化运动特征。

研究结果: 实验表明，PriOr-Flow兼容多种基于透视的迭代光流方法，在公开全景光流数据集上达到最优性能。

研究结论: PriOr-Flow通过正交视图和双分支设计，显著减少极地区域失真，为宽视场运动估计设定了新基准。

中文摘要: 全景光流能够全面理解宽视场中的时间动态，但球面到平面投影（如ERP）导致的严重失真显著降低了传统基于透视的光流方法性能，尤其是在极地区域。为解决这一问题，我们提出PriOr-Flow，一种新颖的双分支框架，利用正交视图的低失真特性增强这些区域的光流估计。具体而言，我们引入了双成本协作查找（DCCL）算子，联合检索原始和正交成本体积的相关信息，有效减少成本体积构建中的失真噪声。此外，我们的正交驱动失真补偿（ODDC）模块迭代优化来自两个分支的运动特征，进一步抑制极地失真。大量实验表明，PriOr-Flow兼容多种基于透视的迭代光流方法，并在公开全景光流数据集上持续实现最先进性能，为宽视场运动估计设定了新基准。代码公开于：https://github.com/longliangLiu/PriOr-Flow。

</details>


### [286] [GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models](https://arxiv.org/abs/2506.23903)
**中文标题：GroundingDINO-US-SAM：基于文本提示的超声多器官分割与LoRA微调视觉语言模型**

*Hamza Rasaee,Taha Koleilat,Hassan Rivaz*

主要分类: cs.CV

摘要简述: 本研究提出了一种基于文本提示的视觉语言模型（VLM），结合Grounding DINO和SAM2，用于超声图像中的多器官分割。通过LoRA微调，模型在15个公开超声数据集上表现优异，并在未见过的3个数据集上保持强鲁棒性，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 超声图像分割面临解剖结构多样性、成像协议差异和标注数据不足的挑战。本研究旨在开发一种通用且高效的分割方法，减少对大量器官特异性标注数据的依赖。

研究方法: 研究整合了Grounding DINO和SAM2，利用LoRA技术对超声领域进行微调。使用了18个公开超声数据集（15个用于微调和验证，3个用于测试），涵盖多个器官。

研究结果: 模型在大多数已见数据集上优于UniverSeg、MedSAM等先进方法，并在未见数据集上表现优异，无需额外微调。

研究结论: 视觉语言模型在超声图像分析中具有潜力，能够实现可扩展且鲁棒的分割，减少对大规模标注数据的依赖。代码将在接受后公开。

中文摘要: 由于解剖结构多样性、成像协议差异和标注数据有限，超声图像中的准确且通用目标分割仍具挑战性。本研究提出了一种基于提示的视觉语言模型（VLM），结合Grounding DINO和SAM2，实现超声多器官分割。研究使用了18个公开超声数据集（涵盖乳腺、甲状腺、肝脏、前列腺、肾脏和脊柱旁肌肉），其中15个用于通过低秩适应（LoRA）对Grounding DINO进行微调和验证，3个用于测试未见分布的性能。综合实验表明，我们的方法在大多数已见数据集上优于UniverSeg、MedSAM、MedCLIP-SAM、BiomedParse和SAMUS等先进分割方法，同时在未见数据集上无需额外微调仍表现优异。这些结果凸显了VLM在可扩展且鲁棒的超声图像分析中的潜力，减少了对大规模器官特异性标注数据的依赖。代码将在接受后发布于code.sonography.ai。

</details>


### [287] [Three-dimensional end-to-end deep learning for brain MRI analysis](https://arxiv.org/abs/2506.23916)
**中文标题：三维端到端深度学习在脑MRI分析中的应用**

*Radhika Juglan,Marta Ligero,Zunamys I. Carrero,Asier Rabasco,Tim Lenz,Leo Misera,Gregory Patrick Veldhuizen,Paul Kuntke,Hagen H. Kitzler,Sven Nebelung,Daniel Truhn,Jakob Nikolas Kather*

主要分类: cs.CV

摘要简述: 研究发现，简单的全连接网络（SFCN）在脑MRI分析的年龄和性别预测任务中，优于更复杂的DenseNet和Swin Transformer架构，表现出更好的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在脑成像中表现优异，但其在不同成像队列中的泛化能力尚未充分评估。年龄和性别是临床神经科学中的关键神经生物学标志，本研究旨在评估三种三维架构在年龄和性别预测任务中的表现。

研究方法: 研究评估了三种三维架构（SFCN、DenseNet和Swin Transformer），使用来自四个独立队列（UKB、DLBS、PPMI和IXI）的T1加权MRI数据，进行年龄和性别预测任务。

研究结果: SFCN在性别分类任务中的AUC为1.00（UKB内部测试集）和0.85-0.91（外部测试集）；在年龄预测任务中的MAE为2.66（UKB）和4.98-5.81（外部数据集）。SFCN在大多数队列中优于Swin Transformer（p<0.017）。

研究结论: 简单的卷积网络（SFCN）在脑图像分析中优于更复杂的注意力架构，表现出更好的跨数据集泛化能力。

中文摘要: 深度学习方法在脑成像中逐渐超越传统方法，但其在不同成像队列中的泛化能力尚未充分评估。年龄和性别是临床神经科学中的关键神经生物学标志，本研究评估了三种现有的三维架构（简单全连接网络SFCN、DenseNet和Swin Transformer）在四个独立队列（UK Biobank、Dallas Lifespan Brain Study、Parkinson's Progression Markers Initiative和Information eXtraction from Images）中的年龄和性别预测表现。研究发现，SFCN在性别分类任务中的AUC为1.00（UKB内部测试集）和0.85-0.91（外部测试集）；在年龄预测任务中的MAE为2.66（UKB）和4.98-5.81（外部数据集）。通过DeLong和Wilcoxon符号秩检验（Bonferroni校正）证实，SFCN在大多数队列中优于Swin Transformer（p<0.017）。可解释性分析进一步表明，模型注意力在不同队列和任务中具有区域一致性。研究结果表明，简单的卷积网络在脑图像分析中优于更复杂的注意力架构，表现出更好的跨数据集泛化能力。

</details>


### [288] [Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers](https://arxiv.org/abs/2506.23918)
**中文标题：多模态推理中的图像思维：基础、方法与未来前沿**

*Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R.,Fung*

主要分类: cs.CV

摘要简述: 本文探讨了多模态推理中从‘关于图像的思考’到‘利用图像思考’的范式转变，提出了一个三阶段框架，并总结了核心方法、评估基准及未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 当前的多模态推理主要依赖文本链式思维（CoT），将视觉视为静态输入，导致感知数据与符号思维之间的‘语义鸿沟’。人类认知常超越语言，利用视觉作为动态思维工具，AI领域也需类似转变。

研究方法: 本文通过三阶段框架（外部工具探索、程序化操作、内在想象）梳理了‘利用图像思考’的范式，并总结了各阶段的核心方法、评估基准和应用案例。

研究结果: 研究提出了‘利用图像思考’的范式及其三阶段发展路径，分析了相关方法和应用，并指出了未来研究的挑战与方向。

研究结论: 本文为多模态AI的未来研究提供了清晰路线图，强调了视觉作为动态认知工具的重要性，并呼吁开发更强大且与人类认知对齐的模型。

中文摘要: 近年来，多模态推理的进展主要依赖于文本链式思维（CoT），即模型在语言中进行推理。然而，这种以文本为中心的方法将视觉视为静态初始背景，导致丰富的感知数据与离散符号思维之间存在根本性的‘语义鸿沟’。人类认知常超越语言，将视觉作为动态的心理画板。AI领域也正在经历类似的变革，标志着从‘关于图像的思考’到‘利用图像思考’的根本范式转变。这一新兴范式的特点是模型将视觉信息作为思维过程的中间步骤，使视觉从被动输入转变为动态、可操作的认知工作空间。本文通过三个关键阶段（外部工具探索、程序化操作、内在想象）描绘了这一智能演进的轨迹。为梳理这一快速发展的领域，本文贡献了四点：（1）确立了‘利用图像思考’范式的基础原则及其三阶段框架；（2）全面回顾了各阶段的核心方法；（3）分析了评估基准和变革性应用的关键领域；（4）指出了重大挑战并展望了未来方向。通过这一结构化综述，本文旨在为未来研究提供清晰路线图，推动更强大且与人类认知对齐的多模态AI的发展。

</details>


### [289] [Evaluating the Impact of Khmer Font Types on Text Recognition](https://arxiv.org/abs/2506.23963)
**中文标题：评估高棉字体类型对文本识别的影响**

*Vannkinh Nom,Souhail Bakkali,Muhammad Muzzamil Luqman,Mickael Coustaty,Jean-Marc Ogier*

主要分类: cs.CV

摘要简述: 研究评估了19种高棉字体对文本识别的影响，发现部分字体（如Khmer、Odor MeanChey等）识别准确率高，而另一些（如iSeth First、Bayon等）表现较差，强调了字体选择对高棉文本识别的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 高棉字体种类繁多且结构复杂，对光学字符识别（OCR）系统构成挑战。本研究旨在评估不同高棉字体对文本识别准确性的影响，为优化OCR系统提供依据。

研究方法: 研究随机选取19种高棉字体（如Angkor、Battambang等），使用Pytesseract进行文本识别测试，比较各字体的OCR性能。

研究结果: 结果显示，Khmer、Odor MeanChey、Siemreap等字体识别准确率高，而iSeth First、Bayon、Dangrek等字体表现较差。

研究结论: 研究强调了字体选择对高棉文本识别的关键作用，为开发更鲁棒的OCR系统提供了重要参考。

中文摘要: 文本识别受字体类型影响显著，尤其是复杂文字如高棉文。高棉字体种类繁多，每种字体具有独特的字符结构，这对光学字符识别（OCR）系统提出了挑战。本研究评估了19种随机选取的高棉字体（包括Angkor、Battambang等）对文本识别准确性的影响，使用Pytesseract进行测试。结果显示，Khmer、Odor MeanChey、Siemreap、Sithi Manuss和Battambang识别准确率高，而iSeth First、Bayon和Dangrek表现较差。本研究强调了字体选择对优化高棉文本识别的重要性，并为开发更鲁棒的OCR系统提供了宝贵见解。

</details>


### [290] [Visual and Memory Dual Adapter for Multi-Modal Object Tracking](https://arxiv.org/abs/2506.23972)
**中文标题：视觉与记忆双重适配器用于多模态目标跟踪**

*Boyue Xu,Ruichao Hou,Tongwei Ren,Gangshan Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的视觉与记忆双重适配器（VMDA），通过联合建模频率、空间和通道特征，以及利用记忆机制存储全局时间线索，显著提升了多模态目标跟踪的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于提示学习的多模态跟踪器在利用辅助模态特征时，由于未能充分挖掘频率和时间域的关键线索，导致提示学习不可靠。本文旨在通过设计更高效的适配器，提升多模态跟踪的鲁棒性和判别性。

研究方法: 1. 提出视觉适配器，通过联合建模频率、空间和通道特征，自适应地将辅助模态的判别线索传递到主导模态。2. 设计记忆适配器，模拟人类记忆机制，存储全局时间线索并动态更新和检索，确保视频序列中可靠时间信息的一致性传播。

研究结果: 实验表明，VMDA在RGB-热成像、RGB-深度和RGB-事件等多模态跟踪任务中均达到了最先进的性能。

研究结论: VMDA通过视觉与记忆双重适配器的协同作用，显著提升了多模态目标跟踪的鲁棒性和判别性，为相关任务提供了新的解决方案。

中文摘要: 基于提示学习的多模态跟踪器通过使用轻量级视觉适配器将辅助模态特征融入冻结的基础模型，取得了显著进展。然而，现有方法由于未能充分挖掘频率和时间域的关键线索，往往难以学习可靠的提示。本文提出了一种新颖的视觉与记忆双重适配器（VMDA），用于构建更鲁棒且判别性更强的多模态跟踪表示。具体而言，我们开发了一种简单但高效的视觉适配器，通过联合建模频率、空间和通道特征，自适应地将辅助模态的判别线索传递到主导模态。此外，受人类记忆机制启发，我们设计了记忆适配器，用于存储全局时间线索并执行动态更新和检索操作，确保视频序列中可靠时间信息的一致性传播。大量实验表明，我们的方法在RGB-热成像、RGB-深度和RGB-事件等多模态跟踪任务中均达到了最先进的性能。代码和模型可在https://github.com/xuboyue1999/mmtrack.git获取。

</details>


### [291] [Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance](https://arxiv.org/abs/2506.23975)
**中文标题：通过利用实例相似性和概念相关性实现简单且鲁棒的图像分类对比解释**

*Yuliia Kaidashova,Bettina Finzel,Ute Schmid*

主要分类: cs.CV

摘要简述: 本文提出了一种基于概念和实例相似性的对比解释方法，用于图像分类模型，验证了概念相关性与解释复杂度之间的关系，并测试了图像增强对解释鲁棒性的影响。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决图像分类模型的对比解释问题，即理解模型为何对某一输入实例偏好某一类别。通过结合实例嵌入的相似性和人类可理解概念的相关性，探索更简单且鲁棒的对比解释方法。

研究方法: 方法包括提取概念及其相关性分数，计算相似实例的对比，并基于解释复杂度评估结果。同时，通过图像增强（如旋转和噪声）测试解释的鲁棒性。

研究结果: 结果表明，概念相关性越高，解释越简短且复杂度越低；反之则解释更长且更分散。此外，解释在不同图像增强条件下表现出不同程度的鲁棒性。

研究结论: 研究为构建更具可解释性和鲁棒性的AI系统提供了潜在方向，验证了概念相关性与解释复杂度之间的关系，并揭示了图像增强对解释鲁棒性的影响。

中文摘要: 理解分类模型为何对某一输入实例偏好某一类别是对比解释的挑战。本研究通过利用实例嵌入的相似性和微调深度学习模型所使用的人类可理解概念的相关性，实现了基于概念的图像分类对比解释。我们的方法提取概念及其相关性分数，计算相似实例的对比，并基于解释复杂度评估结果。通过不同图像增强测试解释的鲁棒性。研究解决了两个问题：(1)解释复杂度是否随相关性范围变化；(2)解释复杂度在旋转和噪声等图像增强下是否保持一致。结果表明，实验中概念相关性越高，解释越简短且复杂度越低，而相关性较低时解释更长且更分散。此外，解释表现出不同程度的鲁棒性。这些发现为构建更具可解释性和鲁棒性的AI系统提供了潜在方向。

</details>


### [292] [StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving](https://arxiv.org/abs/2506.23982)
**中文标题：StyleDrive：面向驾驶风格感知的端到端自动驾驶基准测试**

*Ruiyang Hao,Bowen Jing,Haibao Yu,Zaiqing Nie*

主要分类: cs.CV

摘要简述: 本文提出首个大规模真实世界数据集，标注了多样化的驾驶偏好，为端到端自动驾驶（E2EAD）的个性化研究奠定了基础，并提出了首个个性化E2EAD评估基准。


<details>
  <summary>详细信息</summary>
研究动机: 当前端到端自动驾驶系统（E2EAD）中个性化研究被忽视，而用户对齐的行为对自动驾驶的信任、舒适度和广泛采用至关重要。缺乏标注多样化驾驶偏好的大规模真实数据集阻碍了相关模型的开发和评估。

研究方法: 从真实道路拓扑中提取静态环境特征，使用微调的视觉语言模型（VLM）推断动态上下文线索，构建一致且细粒度的场景。通过行为分布分析和基于规则的启发式方法生成客观偏好标注，并利用VLM联合建模场景语义和驾驶员行为生成主观标注。最终通过人机协同验证融合两种视角获得高质量标签。

研究结果: 基于该数据集，提出了首个个性化E2EAD评估基准，测试了多种先进模型，证明融入个性化偏好能生成更符合人类驾驶的行为。

研究结论: 本文为个性化E2EAD研究提供了标准化平台，系统地将人类偏好融入数据驱动的E2EAD系统，推动了以人为中心的自动驾驶研究。

中文摘要: 尽管个性化在传统自动驾驶系统中已有探索，但在日益重要的端到端自动驾驶（E2EAD）中仍被忽视。这一缺口至关重要，因为用户对齐的行为对自动驾驶的信任、舒适度和广泛采用至关重要。核心挑战在于缺乏标注多样化且细粒度驾驶偏好的大规模真实数据集，阻碍了个性化E2EAD模型的开发和评估。本研究提出了首个标注多样化驾驶偏好的大规模真实数据集，为E2EAD的个性化研究奠定了基础。我们从真实道路拓扑中提取静态环境特征，并使用微调的视觉语言模型（VLM）推断动态上下文线索，实现一致且细粒度的场景构建。基于这些场景，通过行为分布分析和基于规则的启发式方法生成客观偏好标注。为应对驾驶风格的主观性，进一步利用VLM联合建模场景语义和驾驶员行为生成主观标注。最终通过人机协同验证融合两种视角获得高质量标签。基于该数据集，我们提出了首个评估个性化E2EAD模型的基准。测试了多种先进模型，证明融入个性化偏好能生成更符合人类驾驶的行为。本研究通过提供标准化平台，系统地将人类偏好融入数据驱动的E2EAD系统，为个性化E2EAD奠定了基础，推动了以人为中心的自动驾驶研究。

</details>


### [293] [Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data](https://arxiv.org/abs/2506.24039)
**中文标题：基于基础模型的科学图像零样本分割方法：无需AI就绪数据**

*Shubhabrata Mukherjee,Jack Lang,Obeen Kwon,Iryna Zenyuk,Valerie Brogden,Adam Weber,Daniela Ushizima*

主要分类: cs.CV

摘要简述: 本文提出Zenesis平台，通过轻量级多模态适配技术和人机交互优化，实现科学图像的零样本分割，显著提升分割精度。


<details>
  <summary>详细信息</summary>
研究动机: 科学图像数据稀缺且标注困难，现有零样本和提示技术难以处理此类数据，亟需无需AI就绪数据的解决方案。

研究方法: 开发Zenesis平台，结合轻量级多模态适配技术、人机交互优化和启发式时序增强，实现零样本操作。

研究结果: 在FIB-SEM数据上，Zenesis平均准确率达0.947，IOU为0.858，Dice分数为0.923，显著优于传统方法和SAM模型。

研究结论: Zenesis是科学图像分析的强大工具，尤其适用于缺乏高质量标注数据的领域，加速实验图像分析。

中文摘要: 零样本和提示技术依赖常见图像进行视觉推理任务，难以处理稀缺的科学图像数据。为此，我们提出Zenesis，一个无需编码的交互式平台，通过轻量级多模态适配技术实现科学图像的零样本操作，并结合人机交互优化和启发式时序增强。在催化剂负载膜的FIB-SEM数据上，Zenesis表现优异，非晶和晶体样品的平均准确率分别达到0.947和0.987，IOU为0.858和0.857，Dice分数为0.923。这些结果显著优于传统阈值分割和独立使用的SAM模型。Zenesis为科学应用提供了强大工具，尤其适用于缺乏高质量标注数据的领域，加速实验图像的精准分析。

</details>


### [294] [A Survey on Vision-Language-Action Models for Autonomous Driving](https://arxiv.org/abs/2506.24044)
**中文标题：自动驾驶视觉-语言-动作模型综述**

*Sicong Jiang,Zilin Huang,Kangan Qian,Ziang Luo,Tianze Zhu,Yang Zhong,Yihong Tang,Menglin Kong,Yunlong Wang,Siwen Jiao,Hao Ye,Zihao Sheng,Xin Zhao,Tuopu Wen,Zheng Fu,Sikai Chen,Kun Jiang,Diange Yang,Seongjin Choi,Lijun Sun*

主要分类: cs.CV

摘要简述: 本文首次全面综述了自动驾驶领域的视觉-语言-动作（VLA）模型，梳理了其架构演变、代表性模型比较及数据集，并提出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLM）的快速发展，视觉-语言-动作（VLA）模型在自动驾驶领域的应用日益广泛，但相关研究分散且缺乏系统性总结。本文旨在填补这一空白，为研究者提供全面的参考。

研究方法: 本文通过（i）形式化VLA模型的共享架构模块，（ii）追溯从早期解释性模型到以推理为中心的VLA模型的演变，（iii）比较20多种代表性模型，并整合现有数据集和评测标准。

研究结果: 综述总结了VLA在自动驾驶领域的研究进展，突出了衡量驾驶安全性、准确性和解释质量的评测协议，同时指出了当前面临的挑战，如鲁棒性、实时效率和形式化验证。

研究结论: 本文为推进可解释且社会对齐的自动驾驶技术提供了简明而完整的参考，并提出了未来研究方向。

中文摘要: 多模态大语言模型（MLLM）的快速发展为视觉-语言-动作（VLA）范式铺平了道路，该范式将视觉感知、自然语言理解和控制整合到单一策略中。自动驾驶领域的研究者正积极将这些方法应用于车辆领域。此类模型有望实现自动驾驶车辆能够理解高级指令、推理复杂交通场景并自主决策。然而，相关文献分散且迅速扩展。本文首次全面综述了自动驾驶领域的VLA（VLA4AD）研究。我们（i）形式化了近期工作中共享的架构模块，（ii）追溯了从早期解释性模型到以推理为中心的VLA模型的演变，（iii）根据VLA在自动驾驶领域的进展比较了20多种代表性模型。我们还整合了现有数据集和评测标准，突出了同时衡量驾驶安全性、准确性和解释质量的评测协议。最后，我们详细讨论了开放挑战——鲁棒性、实时效率和形式化验证——并展望了VLA4AD的未来方向。本综述为推进可解释且社会对齐的自动驾驶车辆提供了简明而完整的参考。GitHub仓库地址为\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}。

</details>


### [295] [Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios](https://arxiv.org/abs/2506.24063)
**中文标题：持续适应：动态场景下基于环境条件参数生成的目标检测**

*Deng Li,Aming Wu,Yang Li,Yaowei Wang,Yahong Han*

主要分类: cs.CV

摘要简述: 本文提出了一种动态场景下目标检测的持续适应方法，通过环境条件参数生成和双路径LoRA适配器，解决了传统方法因微调导致的性能下降问题，并展示了在多种连续域自适应任务中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 实际环境中，目标检测器常因环境变化而性能下降。传统方法基于封闭集假设，无法适应动态场景。持续测试时适应虽受关注，但微调特定参数可能影响其他固定参数的表现。本文探索了一种新机制，将微调过程转化为特定参数生成，以提升检测器的泛化能力。

研究方法: 方法包括：1) 设计双路径LoRA域感知适配器，分离特征为域不变和域特定部分；2) 提出基于条件扩散的参数生成机制，根据当前环境合成适配器参数；3) 引入类中心最优传输对齐方法，缓解灾难性遗忘。

研究结果: 在多种连续域自适应目标检测任务中，实验表明该方法显著提升了性能。可视化结果显示，生成的参数能捕获更多目标相关信息，增强泛化能力。

研究结论: 本文提出的环境条件参数生成方法有效解决了动态场景下目标检测的适应问题，通过双路径适配器和扩散机制，显著提升了检测器的泛化性能和稳定性。

中文摘要: 在实践中，环境随时间与空间不断变化，这对基于封闭集假设（即训练与测试数据分布相同）训练的目标检测器提出了重大挑战。为此，持续测试时适应备受关注，旨在通过微调少量特定参数（如BatchNorm层）提升检测器的泛化能力。然而，基于少量测试图像微调某些参数可能影响其他固定参数的表征能力，导致性能下降。为此，我们探索了一种新机制，即将微调过程转化为特定参数生成。具体而言，我们首先设计了一种基于双路径LoRA的域感知适配器，将特征解耦为域不变和域特定部分，实现高效适应。此外，提出了一种基于条件扩散的参数生成机制，根据当前环境合成适配器参数，避免优化陷入局部最优。最后，我们提出了一种类中心最优传输对齐方法，以缓解灾难性遗忘。在多种连续域自适应目标检测任务上的大量实验证明了该方法的有效性。同时，可视化结果表明，生成的参数提取的表征能捕获更多目标相关信息，增强泛化能力。

</details>


### [296] [Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention](https://arxiv.org/abs/2506.24085)
**中文标题：为我想象：通过混合注意力实现真实图像与文本的创造性概念融合**

*Wonwoong Cho,Yanxia Zhang,Yan-Ying Chen,David I. Inouye*

主要分类: cs.CV

摘要简述: 本文提出了一种名为IT-Blender的T2I扩散适配器，通过混合注意力机制将真实图像与文本概念融合，以增强人类创造力。该方法利用预训练扩散模型（SD和FLUX）实现图像与文本的无损编码和解耦混合，实验表明其性能显著优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 人类在视觉与文本概念的跨模态融合中具有独特创造力，但容易受到认知偏差（如设计固定）的影响，导致设计空间陷入局部最优。本文旨在通过自动化工具IT-Blender解决这一问题，以提升创造力并弥补现有方法在图像细节保留和解耦能力上的不足。

研究方法: IT-Blender结合预训练扩散模型（SD和FLUX），通过混合注意力机制将干净参考图像的潜在表示与噪声生成图像的潜在表示融合。该方法实现了对真实图像的无损编码，并以解耦方式将视觉概念与文本指定的对象混合。

研究结果: 实验结果显示，IT-Blender在视觉与文本概念融合任务中显著优于基线方法，为图像生成模型在增强人类创造力方面开辟了新应用方向。

研究结论: IT-Blender通过混合注意力机制和预训练扩散模型，成功实现了图像与文本的高效融合，为跨模态创造力增强提供了有效工具。

中文摘要: 将视觉与文本概念融合为新的视觉概念是人类独特且强大的创造力体现。然而，实践中人类的跨模态概念融合易受认知偏差（如设计固定）影响，导致设计空间陷入局部最优。本文提出了一种T2I扩散适配器“IT-Blender”，可自动化融合过程以增强人类创造力。现有跨模态概念融合方法在无损编码真实图像或解耦图像与文本输入方面存在局限。为解决这些问题，IT-Blender利用预训练扩散模型（SD和FLUX）将干净参考图像的潜在表示与噪声生成图像的潜在表示混合。结合新颖的混合注意力机制，IT-Blender实现了对真实图像的无损编码，并以解耦方式将视觉概念与文本指定的对象融合。实验结果表明，IT-Blender在视觉与文本概念融合任务中大幅优于基线方法，为图像生成模型在增强人类创造力方面提供了新应用思路。

</details>


### [297] [WaRA: Wavelet Low Rank Adaptation](https://arxiv.org/abs/2506.24092)
**中文标题：WaRA：基于小波的低秩适应**

*Moein Heidari,Yasamin Medghalchi,Mahdi Khoursha,Reza Rezaeian,Ilker Hacihaliloglu*

主要分类: cs.CV

摘要简述: WaRA是一种新型参数高效微调方法，利用小波变换分解权重更新矩阵，实现多分辨率分析，优于传统LoRA方法，显著提升视觉任务性能并降低计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 现有参数高效微调方法（如LoRA）依赖全局低秩分解，忽略了局部或多尺度结构，无法捕捉权重更新中的复杂模式。WaRA旨在通过小波变换解决这一问题。

研究方法: WaRA通过小波变换将权重更新矩阵分解为多分辨率表示，在小波域进行低秩分解，并通过逆变换重建更新，从而获得压缩的适应参数，支持多分辨率分析。

研究结果: 实验表明，WaRA在图像生成、分类和语义分割等视觉任务中表现优异，显著提升生成图像质量并降低计算复杂度，同时在语言任务中也展现出色性能。

研究结论: WaRA通过小波变换和多分辨率分析，提供了一种更灵活、稀疏的参数高效微调方法，适用于视觉和语言任务，具有广泛适用性。

中文摘要: 参数高效微调（PEFT）已在多种应用中得到广泛采用。在PEFT技术中，低秩适应（LoRA）及其扩展方法尤为有效，能够高效调整模型并显著减少计算开销。然而，现有方法通常依赖全局低秩分解，忽略了局部或多尺度结构，无法捕捉权重更新中的复杂模式。为此，我们提出WaRA，一种新型PEFT方法，利用小波变换将权重更新矩阵分解为多分辨率表示。通过在小波域进行低秩分解并通过逆变换重建更新，WaRA获得压缩的适应参数，支持多分辨率分析，使其能够捕捉粗粒度和细粒度特征，同时提供比标准LoRA更大的灵活性和更稀疏的表示。通过全面实验和分析，我们证明WaRA在图像生成、分类和语义分割等多样化视觉任务中表现优异，显著提升生成图像质量并降低计算复杂度。尽管WaRA主要为视觉任务设计，但我们进一步展示了其在语言任务中的有效性，突显其更广泛的适用性和泛化能力。代码已公开于\href{GitHub}{https://github.com/moeinheidari7829/WaRA}。

</details>


### [298] [MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction](https://arxiv.org/abs/2506.24096)
**中文标题：MILo：基于网格内循环高斯泼溅的精细高效表面重建**

*Antoine Guédon,Diego Gomez,Nissim Maruani,Bingchen Gong,George Drettakis,Maks Ovsjanikov*

主要分类: cs.CV

摘要简述: MILo是一种新型高斯泼溅框架，通过可微分地从3D高斯中提取网格，解决了从体积表示到表面表示的转换问题，实现了高效且精细的表面重建。


<details>
  <summary>详细信息</summary>
研究动机: 当前的高斯泼溅方法在从图像快速重建高质量3D场景方面取得了进展，但提取精确的表面网格仍存在挑战。现有方法通过昂贵的后处理步骤提取表面，导致几何细节丢失或生成过于密集的网格。MILo旨在填补体积表示和表面表示之间的鸿沟，直接在训练过程中优化网格。

研究方法: MILo设计了完全可微分的过程，从高斯参数中直接构建网格（包括顶点位置和连接性）。关键技术包括：双向一致性框架确保高斯和提取的网格在训练中捕获相同几何结构；自适应网格提取过程，使用高斯作为Delaunay三角剖分的可微分支点；从3D高斯计算有符号距离值的新方法，实现精确表面提取。

研究结果: MILo能够以最先进的质量重建完整场景（包括背景），同时所需的网格顶点数量比现有方法少一个数量级。生成的网格轻量且内部为空，适用于物理模拟或动画等下游应用。

研究结论: MILo通过可微分网格提取技术，显著提升了表面重建的效率和精度，为3D场景重建和下游应用提供了新的解决方案。

中文摘要: 尽管近期高斯泼溅技术的进展使得从图像快速重建高质量3D场景成为可能，但提取精确的表面网格仍是一个挑战。现有方法通过昂贵的后处理步骤提取表面，导致几何细节丢失或生成数百万顶点的密集网格。更根本的是，从体积表示到表面表示的后验转换限制了最终网格保留训练中捕获的所有几何结构的能力。我们提出MILo，一种新型高斯泼溅框架，通过可微分地从3D高斯中提取网格，填补了体积表示和表面表示之间的鸿沟。我们设计了一个完全可微分的过程，直接从高斯参数中构建网格（包括顶点位置和连接性），这些参数是训练期间唯一优化的量。我们的方法引入了三项关键技术贡献：双向一致性框架确保高斯和提取的网格在训练中捕获相同几何结构；自适应网格提取过程，在每次训练迭代中使用高斯作为Delaunay三角剖分的可微分支点；从3D高斯计算有符号距离值的新方法，实现精确表面提取并避免几何侵蚀。我们的方法能够以最先进的质量重建完整场景（包括背景），同时所需的网格顶点数量比现有方法少一个数量级。由于其轻量和内部为空的特点，我们的网格非常适合物理模拟或动画等下游应用。

</details>


### [299] [DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World](https://arxiv.org/abs/2506.24102)
**中文标题：DenseWorld-1M：迈向真实世界中详细密集的基于视觉实体的描述**

*Xiangtai Li,Tao Zhang,Yanwei Li,Haobo Yuan,Shihao Chen,Yikang Zhou,Jiahao Meng,Yueyi Sun,Shilin Xu,Lu Qi,Tianheng Cheng,Yi Lin,Zilong Huang,Wenhao Huang,Jiashi Feng,Guang Shi*

主要分类: cs.CV

摘要简述: 本文提出了DenseWorld-1M，首个大规模、详细且密集的基于真实世界的标注数据集，通过三阶段标注流程和两个视觉语言模型，显著提升了场景理解和视觉定位任务的效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态大语言模型（MLLMs）依赖于大规模高质量数据集，但多数标注数据集缺乏视觉实体的位置和关系信息，且现有数据集在详细描述、关系和高分辨率图像上的对象描述方面存在不足。为此，作者提出了DenseWorld-1M以填补这一空白。

研究方法: 设计了一个三阶段标注流程：1）开放世界感知，获取实体级掩码和标签；2）基于掩码和标签生成详细对象级描述；3）将对象描述和掩码合并为空间和关系密集描述。此外，提出了两个视觉语言模型（Detailed Region Caption模型和Spatial Caption Merging模型）以加速标注并提升质量。

研究结果: 在多种任务（如视觉语言理解、视觉定位和区域描述生成）上的实验表明，DenseWorld-1M数据集和标注模型的有效性。

研究结论: DenseWorld-1M为社区提供了首个大规模、详细且密集的标注数据集，显著提升了场景理解和视觉定位任务的效果。

中文摘要: 多模态大语言模型（MLLMs）展现了复杂的场景理解能力，这得益于大规模高质量的数据集。然而，现有的大多数描述数据集缺乏视觉实体的位置和关系信息。一些基于视觉实体的描述数据集则面临描述不详细、关系缺失以及高分辨率图像上大量对象描述不足的问题。为填补这一空白，我们提出了DenseWorld-1M，这是首个大规模、详细且密集的基于真实世界的标注数据集。我们设计了一个三阶段标注流程，包括开放世界感知、详细对象描述生成和密集描述合并。第一阶段获取实体级掩码和标签；第二阶段基于掩码和标签生成详细的对象级描述；第三阶段将对象描述和掩码合并为空间和关系密集描述。为加速标注过程并提升描述质量，我们提出了两个视觉语言模型：详细区域描述模型和空间描述合并模型。在多种任务（如视觉语言理解、视觉定位和区域描述生成）上的广泛实验证明了DenseWorld-1M数据集和标注模型的有效性。

</details>


### [300] [Epona: Autoregressive Diffusion World Model for Autonomous Driving](https://arxiv.org/abs/2506.24113)
**中文标题：Epona：用于自动驾驶的自回归扩散世界模型**

*Kaiwen Zhang,Zhenyu Tang,Xiaotao Hu,Xingang Pan,Xiaoyang Guo,Yuan Liu,Jingwei Huang,Li Yuan,Qian Zhang,Xiao-Xiao Long,Xun Cao,Wei Yin*

主要分类: cs.CV

摘要简述: 本文提出Epona，一种自回归扩散世界模型，通过解耦时空建模和模块化轨迹与视频预测，实现了高分辨率、长时长的自动驾驶世界建模，并在实验中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于视频扩散的世界模型在灵活时长和长时预测方面表现不佳，且难以整合轨迹规划。Epona旨在通过自回归扩散模型解决这些问题。

研究方法: Epona采用解耦时空因子化和模块化轨迹与视频预测，结合链式前向训练策略，减少自回归循环中的误差累积。

研究结果: 实验显示，Epona在FVD指标上提升7.4%，预测时长更长，并在NAVSIM基准测试中优于端到端规划器。

研究结论: Epona不仅实现了高质量的世界建模，还能作为实时运动规划器，为自动驾驶提供了新的解决方案。

中文摘要: 扩散模型在视频生成中表现出卓越的视觉质量，使其在自动驾驶世界建模中具有潜力。然而，现有的基于视频扩散的世界模型在灵活时长和长时预测以及整合轨迹规划方面存在困难。这是因为传统视频扩散模型依赖于固定长度帧序列的全局联合分布建模，而非逐步构建每个时间步的局部分布。本文提出Epona，一种自回归扩散世界模型，通过两项关键创新实现局部时空分布建模：1）解耦时空因子化，将时间动态建模与细粒度未来世界生成分离；2）模块化轨迹与视频预测，将运动规划与视觉建模无缝整合到端到端框架中。我们的架构支持高分辨率、长时长生成，并引入新颖的链式前向训练策略以减少自回归循环中的误差累积。实验结果表明，Epona在FVD指标上提升7.4%，预测时长更长，优于现有方法。学习到的世界模型还可作为实时运动规划器，在NAVSIM基准测试中超越端到端规划器。代码将在https://github.com/Kevin-thu/Epona/公开。

</details>


### [301] [TextMesh4D: High-Quality Text-to-4D Mesh Generation](https://arxiv.org/abs/2506.24121)
**中文标题：TextMesh4D：高质量的文本到4D网格生成**

*Sisi Dai,Xinxin Su,Boyan Wan,Ruizhen Hu,Kai Xu*

主要分类: cs.CV

摘要简述: TextMesh4D是一种高质量文本到4D网格生成的新框架，通过两阶段分解和灵活性-刚性正则化，实现动态3D内容生成，具有高效性和低GPU内存需求。


<details>
  <summary>详细信息</summary>
研究动机: 当前扩散生成模型在图像、视频和3D内容生成方面取得进展，但动态3D内容生成（文本到4D）仍未被充分探索。本文旨在填补这一空白。

研究方法: TextMesh4D采用每面雅可比矩阵作为可微分网格表示，将4D生成分为静态对象创建和动态运动合成两阶段，并引入灵活性-刚性正则化以优化雅可比矩阵。

研究结果: 实验表明，TextMesh4D在时间一致性、结构保真度和视觉真实感方面达到最优效果，且仅需单块24GB GPU，内存占用低。

研究结论: TextMesh4D为文本驱动的4D网格生成提供了高效且高质量的解决方案，代码将开源以促进未来研究。

中文摘要: 近年来，扩散生成模型在用户提供的文本提示下生成图像、视频和3D内容方面取得了显著进展。然而，利用扩散指导生成动态3D内容（文本到4D）这一挑战性问题仍未被充分探索。本文提出TextMesh4D，一种高质量文本到4D生成的新框架。我们的方法采用每面雅可比矩阵作为可微分网格表示，并将4D生成分为静态对象创建和动态运动合成两阶段。此外，我们提出一种灵活性-刚性正则化项，以在视频扩散先验下稳定雅可比优化，确保几何性能的鲁棒性。实验表明，TextMesh4D在时间一致性、结构保真度和视觉真实感方面达到最优效果。此外，TextMesh4D仅需单块24GB GPU，内存占用低，为文本驱动的4D网格生成提供了经济高效且高质量的解决方案。代码将开源以促进文本到4D生成的未来研究。

</details>


### [302] [Calligrapher: Freestyle Text Image Customization](https://arxiv.org/abs/2506.24123)
**中文标题：Calligrapher：自由风格文本图像定制**

*Yue Ma,Qingyan Bai,Hao Ouyang,Ka Leong Cheng,Qiuyu Wang,Hongyu Liu,Zichen Liu,Haofan Wang,Jingye Chen,Yujun Shen,Qifeng Chen*

主要分类: cs.CV

摘要简述: Calligrapher是一种基于扩散模型的创新框架，结合文本定制与艺术字体设计，通过自蒸馏机制和局部风格注入技术，实现高精度风格控制和字形定位，适用于数字书法和设计应用。


<details>
  <summary>详细信息</summary>
研究动机: 传统字体定制方法在风格控制和数据依赖性方面存在挑战，Calligrapher旨在通过自动化技术解决这些问题，为数字艺术和品牌设计提供高质量、视觉一致的字体生成方案。

研究方法: 1. 自蒸馏机制利用预训练的文本生成模型和大型语言模型自动构建风格为中心的字体基准。2. 局部风格注入框架通过可训练的风格编码器提取参考图像的鲁棒风格特征，并结合上下文生成机制直接嵌入参考图像到去噪过程中。

研究结果: Calligrapher在多种字体和设计场景中表现出色，能够准确复现复杂的风格细节和字形定位，超越传统模型。

研究结论: Calligrapher通过自动化高质量字体生成，为数字艺术、品牌设计和上下文字体设计提供了强大工具，显著提升了创意实践的效率和质量。

中文摘要: 我们介绍了Calligrapher，一种新颖的基于扩散的框架，创新性地将高级文本定制与艺术字体设计结合，适用于数字书法和设计应用。针对字体定制中精确风格控制和数据依赖性的挑战，我们的框架包含三项关键技术贡献。首先，我们开发了一种自蒸馏机制，利用预训练的文本生成模型和大型语言模型自动构建以风格为中心的字体基准。其次，我们通过可训练的风格编码器（包含Qformer和线性层）引入局部风格注入框架，从参考图像中提取鲁棒风格特征。此外，还采用上下文生成机制将参考图像直接嵌入去噪过程，进一步增强目标风格的精细对齐。在多种字体和设计场景中的广泛定量和定性评估证实，Calligrapher能够准确复现复杂的风格细节和精确的字形定位。通过自动化高质量、视觉一致的字体生成，Calligrapher超越了传统模型，为数字艺术、品牌设计和上下文字体设计的创意实践者提供了强大支持。

</details>


### [303] [FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation](https://arxiv.org/abs/2506.24125)
**中文标题：FADRM：快速准确的数据残差匹配用于数据集蒸馏**

*Jiacheng Cui,Xinyue Bi,Yaxin Luo,Xiaohan Zhao,Jiacheng Liu,Zhiqiang Shen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FADRM的新方法，首次将数据残差匹配应用于数据集蒸馏任务，显著提升了计算效率和性能，同时在多个基准测试中超越了现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管残差连接在模型架构层面已被广泛研究，但其在数据为中心的方法中的潜力尚未被探索。本文旨在利用数据级跳跃连接来解决数据信息消失问题，并提升数据集蒸馏任务的性能。

研究方法: FADRM通过数据残差匹配技术，结合像素空间优化和原始数据模态的核心局部信息识别，实现了高效的数据生成。此外，通过优化级改进，显著降低了训练时间和GPU内存使用。

研究结果: 在ImageNet-1K数据集上，FADRM以0.8%的压缩比实现了47.7%的单模型测试准确率和50.0%的多模型测试准确率，分别比RDED高出5.7%，并超越了EDC和CV-DD等现有方法。

研究结论: FADRM在数据集蒸馏任务中实现了新的最佳性能，显著提升了效率和效果，为数据为中心的方法提供了新的研究方向。

中文摘要: 残差连接在模型架构层面已被广泛研究和应用，但其在更具挑战性的数据为中心的方法中的潜力尚未被探索。本文首次引入了数据残差匹配的概念，利用数据级跳跃连接促进数据生成并缓解数据信息消失问题。该方法在像素空间优化和原始数据模态的核心局部信息识别之间保持平衡，特别适用于数据集蒸馏任务。此外，通过优化级改进，我们的方法显著提高了计算效率，在减少50%的训练时间和峰值GPU内存使用的同时，实现了卓越的性能。因此，所提出的快速准确的数据残差匹配方法（FADRM）在多个数据集基准测试中均表现出色，在效率和效果上均优于现有方法。例如，在ResNet-18作为学生模型且ImageNet-1K的压缩比为0.8%的情况下，该方法在单模型数据集蒸馏中实现了47.7%的测试准确率，在多模型数据集蒸馏中达到了50.0%，分别比RDED高出5.7%，并超越了EDC和CV-DD等现有方法。代码已开源：https://github.com/Jiacheng8/FADRM。

</details>


### [304] [How to Design and Train Your Implicit Neural Representation for Video Compression](https://arxiv.org/abs/2506.24127)
**中文标题：如何设计和训练用于视频压缩的隐式神经表示**

*Matthew Gwilliam,Roy Zhang,Namitha Padmanabhan,Hongyang Du,Abhinav Shrivastava*

主要分类: cs.CV

摘要简述: 本文提出了一种改进的隐式神经表示（INR）视频压缩方法RNeRV，通过优化设计和训练策略，显著提升了压缩质量和训练效率，并探索了超网络技术以实现实时编码。


<details>
  <summary>详细信息</summary>
研究动机: 尽管隐式神经表示（INR）在视频压缩中取得了与传统方法竞争的性能，但其编码速度过慢限制了实际应用。本文旨在通过优化INR设计和训练策略，提升压缩效率和质量，并探索实时编码的可能性。

研究方法: 1. 开发了一个库以分析NeRV家族方法的组件，重新评估其性能；2. 提出了RNeRV，一种优化的INR配置；3. 研究了超网络技术，通过预测INR权重实现实时编码，并提出权重掩码策略以提升压缩质量。

研究结果: RNeRV在相同训练时间下，平均PSNR提升了1.27%；超网络技术在UCF-101数据集上实现了1.7%的PSNR和MS-SSIM提升，同时保持了相似的编码速度。

研究结论: 本文通过优化INR设计和引入超网络技术，显著提升了视频压缩的效率和质量，为实时编码提供了可行的解决方案。

中文摘要: 隐式神经表示（INR）方法在视频压缩中最近取得了与传统流程竞争的可视质量和压缩比。然而，由于需要针对每个样本进行网络训练，这些方法的编码速度过慢，难以实际应用。我们开发了一个库，用于解耦和评估NeRV家族方法的组件，从大小-质量权衡和训练时间影响的角度重新审视其性能。我们揭示了有效视频INR设计的原则，并提出了这些组件的最先进配置——Rabbit NeRV（RNeRV）。当所有方法在7个不同的1080p UVG视频上给予相同的训练时间（相当于300个NeRV周期）时，RNeRV的平均PSNR比我们库中每个视频的最佳替代方法高出1.27%。随后，我们通过研究超网络的可行性，直接解决了编码速度问题。超网络从视频输入预测INR权重，将训练与编码解耦以实现实时编码。我们提出在训练期间对预测的INR权重进行掩码，以实现可变且更高质量的压缩，在UCF-101数据集上以0.037 bpp实现了PSNR和MS-SSIM均提升1.7%。此外，我们将超网络参数增加了0.4%，在相同bpp和相似速度下，PSNR和MS-SSIM分别提升了2.5%和2.7%。项目网站和代码分别位于https://mgwillia.github.io/vinrb/和https://github.com/mgwillia/vinrb。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [305] [Bootstrapping Human-Like Planning via LLMs](https://arxiv.org/abs/2506.22604)
**中文标题：通过大型语言模型引导人类式规划**

*David Porfirio,Vincent Hsiao,Morgan Fine-Morris,Leslie Smith,Laura M. Hiatt*

主要分类: cs.AI

摘要简述: 本文研究如何结合自然语言和拖拽界面两种方式，通过基于大型语言模型（LLM）的流程生成类似人类的动作序列，并与手动指定的动作序列进行比较。结果表明，较大模型在生成人类动作序列方面表现更优，但较小模型也能达到满意效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器人终端用户对任务指定方式的需求增加，自然语言和拖拽界面成为两种常见方式。自然语言直观但不够精确，拖拽界面精确但不够灵活。本文旨在探索如何结合这两种方式的优势，以生成更符合人类习惯的动作序列。

研究方法: 本文构建了一个基于大型语言模型（LLM）的流程，输入为自然语言，输出为类似人类生成的动作序列。这些序列的粒度与人类手动指定的序列一致。随后，将生成的序列与手动指定的序列数据集进行比较。

研究结果: 实验结果显示，较大的语言模型在生成人类动作序列方面表现优于较小的模型，但较小的模型也能达到令人满意的性能水平。

研究结论: 研究表明，通过结合自然语言和拖拽界面的优势，基于LLM的流程能够生成符合人类习惯的动作序列，为机器人任务指定提供了一种更灵活且精确的方法。

中文摘要: 机器人终端用户越来越需要便捷的方式为机器人指定任务。两种常见的终端用户编程范式包括拖拽界面和自然语言编程。尽管自然语言界面利用了直观的人类交流形式，拖拽界面则使用户能够细致且精确地规定机器人任务的关键动作。本文研究了这两种方法在多大程度上可以结合。具体而言，我们构建了一个基于大型语言模型（LLM）的流程，接受自然语言输入，并输出类似人类生成的动作序列，其粒度与人类生成的序列一致。随后，我们将这些生成的动作序列与另一组手动指定的动作序列数据集进行比较。尽管结果表明，较大模型在生成人类动作序列方面表现优于较小模型，但较小模型仍能达到令人满意的性能。

</details>


### [306] [Ludax: A GPU-Accelerated Domain Specific Language for Board Games](https://arxiv.org/abs/2506.22609)
**中文标题：Ludax：一种用于棋盘游戏的GPU加速领域特定语言**

*Graham Todd,Alexander G. Padula,Dennis J. N. J. Soemers,Julian Togelius*

主要分类: cs.AI

摘要简述: 本文介绍了Ludax，一种专为棋盘游戏设计的GPU加速领域特定语言，结合了游戏描述语言的通用性和现代并行处理硬件的速度，旨在加速游戏研究和强化学习。


<details>
  <summary>详细信息</summary>
研究动机: 游戏长期以来被用作人工智能研究的基准和测试环境，但现有工具缺乏对硬件加速的支持。本文旨在开发一种结合游戏描述语言通用性和现代硬件加速能力的工具，以推动游戏研究和强化学习的进展。

研究方法: Ludax是一种领域特定语言，能够自动编译为硬件加速代码。它结合了游戏描述语言的通用性和现代并行处理硬件的速度，并设计为与现有深度学习流程无缝集成。

研究结果: Ludax框架展示了高速模拟能力和灵活的表示方案，通过速度基准测试和强化学习代理训练验证了其有效性。

研究结论: Ludax作为一个开源工具，有望加速从强化学习到认知科学的游戏研究，提供快速模拟和灵活的表示方案。

中文摘要: 长期以来，游戏被用作人工智能研究的基准和测试环境。支持这一研究的关键步骤是开发游戏描述语言：这些框架将领域特定代码编译为可玩和可模拟的游戏环境，使研究人员能够将其算法和方法推广到多种游戏，而无需手动实现每种游戏。最近，强化学习（RL）的进展主要由硬件加速的进步推动。像JAX这样的库使从业者能够充分利用尖端计算硬件，通常将训练和测试速度提高数个数量级。本文综合了这些研究方向：提出了一种专为棋盘游戏设计的领域特定语言，能够自动编译为硬件加速代码。我们的框架Ludax结合了游戏描述语言的通用性和现代并行处理硬件的速度，并设计为与现有深度学习流程无缝集成。我们设想Ludax作为一种工具，通过实现快速模拟和提供灵活的表示方案，帮助加速从RL到认知科学的游戏研究。我们详细介绍了Ludax的描述语言和编译过程的技术说明，并提供了速度基准测试和强化学习代理训练示例。Ludax框架及其现有棋盘游戏的实现是开源且免费的。

</details>


### [307] [URSA: The Universal Research and Scientific Agent](https://arxiv.org/abs/2506.22653)
**中文标题：URSA：通用研究与科学代理**

*Michael Grosskopf,Russell Bent,Rahul Somasundaram,Isaac Michaud,Arthur Lui,Nathan Debardeleben,Earl Lawrence*

主要分类: cs.AI

摘要简述: 本文介绍了URSA，一个用于加速科研任务的科学代理生态系统，通过模块化代理和工具的结合，解决不同复杂性和影响力的科学问题。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）已从简单的聊天机器人发展为能够执行复杂推理、规划、写作、编码和科研任务，与科学家日常解决问题的技能高度重合。利用LLM的‘代理性’AI有望革新现代科学并消除研究瓶颈。

研究方法: URSA是一个模块化的科学代理生态系统，包含多种代理和工具，如与高级物理模拟代码的耦合，可组合用于解决不同复杂性和影响力的科学问题。

研究结果: URSA展示了其架构及多个示例，证明了其在加速科研任务中的潜力。

研究结论: URSA作为一种科学代理生态系统，展示了利用LLM加速科研的潜力，为现代科学研究提供了新的工具和方法。

中文摘要: 大型语言模型（LLM）已远不止是简单的聊天机器人，如今能够执行复杂的推理、规划、写作、编码和科研任务。这些技能与科学家日常用于解决前沿研究问题的技能高度重合。在‘代理性’AI中使用LLM有望革新现代科学并消除研究瓶颈。本文介绍了URSA，一个用于加速科研任务的科学代理生态系统。URSA由一组模块化代理和工具组成，包括与高级物理模拟代码的耦合，可组合用于解决不同复杂性和影响力的科学问题。本文重点介绍了URSA的架构，以及展示该系统潜力的示例。

</details>


### [308] [Explanations are a means to an end](https://arxiv.org/abs/2506.22740)
**中文标题：解释是实现目的的手段**

*Jessica Hullman,Ziyang Guo,Berk Ustun*

主要分类: cs.AI

摘要简述: 本文主张解释性机器学习方法应以具体应用目标为导向，提出基于统计决策理论的框架，强调解释的设计与评估需结合实际用途，防止滥用。


<details>
  <summary>详细信息</summary>
研究动机: 当前解释性机器学习方法多关注模型输入输出映射，而忽视解释的实际用途。本文旨在强调解释应围绕具体目标设计，避免因模糊性导致滥用。

研究方法: 提出基于统计决策理论的框架，将解释设计与具体用途结合，并通过临床决策支持、提供补救措施等多样化用例验证其适用性。

研究结果: 展示了如何量化解释对理想决策者在特定任务中的性能提升，并通过明确用例防止解释的模糊性滥用。

研究结论: 解释性方法需结合理论与实证视角评估其价值，本文提出的框架为解释的设计与评估提供了具体指导。

中文摘要: 现代可解释机器学习方法旨在描述模型如何将输入映射到输出，而较少考虑这些解释在实际中的用途。本文认为解释应围绕具体目标设计和评估。我们描述了如何基于统计决策理论框架形式化这一目标，并展示了这种功能导向方法在临床决策支持、提供补救措施或调试等多样化用例中的应用。通过量化解释对理想决策者在特定任务中的性能提升，防止因模糊性导致的滥用。我们主张评估应结合理论与实证视角，并提出涵盖这些视角的定义。

</details>


### [309] [Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems](https://arxiv.org/abs/2506.22774)
**中文标题：桥接伦理原则与算法方法：一种评估AI系统可信度的替代方法**

*Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis*

主要分类: cs.AI

摘要简述: 本文提出一种结合伦理原则与PageRank和TrustRank算法的评估方法，旨在量化AI系统的可信度，减少主观性，并提供全面的评估框架。


<details>
  <summary>详细信息</summary>
研究动机: AI技术的广泛应用及其潜在风险凸显了评估其可信度的重要性。现有方法要么缺乏量化技术，要么过于片面，无法全面评估AI的可信度。

研究方法: 通过结合可信AI的伦理组件与PageRank和TrustRank算法，提出一种新的评估方法，以减少主观性并提供量化标准。

研究结果: 应用该方法表明，结合伦理指南的理论内容与算法标准，可以实现对AI系统可信度的全面量化评估。

研究结论: 本文提出的方法为AI系统的可信度评估提供了一种兼具伦理与算法视角的框架，弥补了现有方法的不足。

中文摘要: 人工智能（AI）技术体现了人造物带来的复杂挑战，尤其是那些广泛融入社会并产生重大影响的技术，突显了其潜在益处与负面后果。尽管其他技术也可能带来重大风险，但AI的普及性使其社会影响尤为深远。AI系统的复杂性及其卓越能力可能导致对超出直接人类监督或理解范围技术的依赖。为减轻由此产生的风险，已开发出多种理论工具和指南，同时努力创建旨在保障可信AI的技术工具。这些指南虽从更全面的视角看待问题，但未能提供量化可信度的技术。相反，技术工具虽更擅长实现此类量化，但缺乏整体视角，仅关注可信AI的特定方面。本文旨在引入一种评估方法，将可信AI的伦理组件与PageRank和TrustRank的算法流程相结合。目标是通过引入算法标准，建立一个最小化领域内普遍存在的自我评估技术主观性的评估框架。我们的方法应用表明，通过提供量化见解并考虑相关指南的理论内容，可以实现对AI系统可信度的全面评估。

</details>


### [310] [ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models](https://arxiv.org/abs/2506.22865)
**中文标题：ReasonBridge：从闭源到开源语言模型的高效推理迁移**

*Ziqi Zhong,Xunzhu Tang*

主要分类: cs.AI

摘要简述: 本文提出ReasonBridge方法，通过分层知识蒸馏框架，高效地将闭源大语言模型的复杂推理能力迁移到开源模型。仅需1000条精选推理轨迹，该方法显著提升开源模型的推理性能，缩小与闭源模型的差距。


<details>
  <summary>详细信息</summary>
研究动机: 当前闭源与开源大语言模型在复杂推理任务上存在显著性能差距。为提升开源模型的推理能力，本文提出一种高效迁移方法，旨在通过小样本数据实现性能提升。

研究方法: 1. 构建高质量推理数据集Reason1K（1000条精选轨迹）；2. 采用分层蒸馏框架，捕捉抽象策略与实现细节；3. 设计稀疏推理适配器，仅需0.3%额外可训练参数；4. 引入测试时计算扩展机制。

研究结果: ReasonBridge使开源模型的推理能力提升高达23%，增强后的Qwen2.5-14B在MATH500上超越Claude-Sonnet3.5，并在AIME竞赛题中表现相当。

研究结论: ReasonBridge为开源模型提供了一种高效推理增强方法，显著缩小与闭源模型的差距，且适用于多种推理领域和模型架构。

中文摘要: 近年来，大语言模型（LLMs）的发展揭示了闭源与开源模型在复杂推理和精确指令遵循任务上的显著性能差距。本文提出ReasonBridge方法，通过一种新颖的分层知识蒸馏框架，高效地将闭源模型的推理能力迁移到开源模型。我们构建了仅包含1000条精选推理轨迹的数据集Reason1K，强调难度、多样性和质量，并通过结构化多标准选择算法从多领域筛选。迁移学习方法包括：（1）分层蒸馏过程，捕捉策略抽象与战术实现模式；（2）稀疏推理适配器架构，仅需0.3%额外可训练参数；（3）测试时计算扩展机制，采用引导推理干预。全面评估表明，ReasonBridge将开源模型的推理能力提升高达23%，显著缩小与闭源模型的差距。值得注意的是，增强后的Qwen2.5-14B在MATH500上超越Claude-Sonnet3.5，并在竞赛级AIME问题上表现相当。该方法在多种推理领域和模型架构中均有效，为指令遵循任务的推理增强提供了一种样本高效的方法。

</details>


### [311] [Agentic Enterprise: AI-Centric User to User-Centric AI](https://arxiv.org/abs/2506.22893)
**中文标题：代理型企业：从AI中心化用户到用户中心化AI**

*Arpit Narechania,Alex Endert,Atanu R Sinha*

主要分类: cs.AI

摘要简述: 本文探讨了AI在企业决策中的潜力，提出了从AI中心化用户转向用户中心化AI的六项原则，以提升企业决策效率。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI技术的快速发展，其在企业决策中的作用日益凸显。然而，当前的AI中心化用户模式未能充分满足企业决策的持续需求。本文旨在探索如何通过用户中心化AI提升企业决策效率。

研究方法: 通过分析企业决策中的需求与AI技术的现状，提出了六项原则，强调从AI中心化转向用户中心化的必要性，并提倡通过市场机制优化AI平台设计。

研究结果: 提出了六项用户中心化AI的原则，为企业决策提供了更高效的AI支持，同时强调了市场机制在AI平台设计中的重要性。

研究结论: 用户中心化AI能够更好地满足企业决策需求，通过六项原则和市场机制的引入，可以显著提升企业决策效率。

中文摘要: 经过漫长的寒冬，人工智能（AI）的春天终于到来。至少在过去的三年里，AI似乎展现出了巨大的潜力，能够影响人类生活的多个领域——个人、社会、健康、教育和职业。本文重点探讨了AI在企业中的潜力，尤其是在决策制定这一贯穿企业各项职能、任务和运营的核心环节。我们认为，通过赋予AI代理能力，可以提升企业的决策效率。通过分析当前AI中心化用户模式的不足，我们提出了六项代理成功的原则，以满足企业决策的持续需求。在强调向用户中心化AI转变的同时，我们提出了六项原则，并提倡通过市场机制优化AI平台的设计，使AI及其代理更好地服务于企业用户的需求。

</details>


### [312] [Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning](https://arxiv.org/abs/2506.22919)
**中文标题：Hecto：用于自适应和可解释推理的模块化稀疏专家**

*Sanskar Pandey,Ruhaan Chopra,Saad Murtaza Bhat,Ark Abhyudaya*

主要分类: cs.AI

摘要简述: Hecto提出了一种轻量级的混合专家架构，通过结合GRU专家和FFNN专家，实现了对不同推理类型的专业化处理，提升了模型的稳定性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的混合专家模型（MoE）依赖相同的归纳偏差，限制了表示多样性，且静态计算路径对需要不同类型推理的输入效率低下。Hecto旨在通过架构异质性解决这些问题，提升专业化和可解释性。

研究方法: Hecto结合了GRU专家（用于时序推理）和FFNN专家（用于静态抽象），采用稀疏Top-1门控机制，实现了对输入的专业化处理。

研究结果: 在多个推理基准测试（AG News、SST-2、HotpotQA）和回归任务（STS-B）中，Hecto表现与同质基线相当或接近，同时实现了专家专业化（时序与静态推理）。大批次下性能提升显著。

研究结论: Hecto通过架构多样性提升了模型的稳定性和可解释性，为低资源环境下的专业化推理提供了新基准。

中文摘要: 混合专家（MoE）模型通过将输入路由到专业专家实现条件计算，但这些专家依赖相同的归纳偏差，限制了表示多样性。这种静态计算路径对需要不同类型推理的输入效率低下，且限制了专业化和可解释性。我们提出Hecto，一种轻量级MoE架构，通过结合GRU专家（用于时序推理）和FFNN专家（用于静态抽象）在稀疏Top-1门控机制下实现架构异质性。在三个推理基准测试（AG News、SST-2、HotpotQA）和一个回归任务（STS-B）中，尽管输入表示独立，Hecto表现与同质基线相当或接近，同时实现了清晰的专家专业化（时序与静态推理）。在大批次下，Hecto性能提升，得益于计算约束的放松使其异质架构更有效优化。消融实验表明架构多样性是Hecto稳定性和可解释性的来源。总体而言，Hecto为条件计算设立了新基准，为低资源环境下的专业化推理提供了原则性框架。

</details>


### [313] [Improving Rationality in the Reasoning Process of Language Models through Self-playing Game](https://arxiv.org/abs/2506.22920)
**中文标题：通过自玩游戏提升语言模型推理过程的理性**

*Pinzheng Wang,Juntao Li,Zecheng Tang,Haijia Gui,Min zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种通过自玩游戏提升语言模型推理过程理性的方法，设计了批评-辨别游戏（CDG），实验证明该方法显著提高了模型对推理过程的理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLM）在数学和编程等任务中表现出较强的推理能力，但其对推理过程缺乏真正的理解。本文旨在通过自玩游戏提升模型的理性，无需人类或更优模型的监督。

研究方法: 设计了批评-辨别游戏（CDG），其中证明者提供问题解决方案，随后接受批评者的挑战。批评者可能提供帮助性或误导性反馈，证明者需在误导性评论中保持正确答案，并在建设性反馈中修正错误。

研究结果: 在数学推理、逐步错误检测、自我修正和长链推理任务中，CDG训练显著提升了模型对推理过程的理解能力。

研究结论: CDG训练能够有效增强语言模型在推理过程中的理性，为其自我理解和改进提供了新途径。

中文摘要: 大型语言模型（LLM）在数学和编程等任务中表现出较强的推理能力，但研究表明，即使最优模型也缺乏对其推理过程的真正理解。本文探讨了如何通过自玩游戏在无监督条件下提升模型推理过程的理性。我们设计了一种批评-辨别游戏（CDG），其中证明者首先提供问题的解决方案，随后接受批评者对其解决方案的挑战。这些批评旨在帮助或误导证明者。证明者的目标是在面对误导性评论时保持正确答案，并在建设性反馈中修正错误。在数学推理、逐步错误检测、自我修正和长链推理任务上的实验表明，CDG训练能够显著提升对齐良好的LLM对其推理过程的理解能力。

</details>


### [314] [MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning](https://arxiv.org/abs/2506.22992)
**中文标题：MARBLE：一个用于多模态空间推理与规划的硬基准**

*Yulun Jiang,Yekun Chai,Maria Brbić,Michael Moor*

主要分类: cs.AI

摘要简述: MARBLE是一个设计用于测试多模态语言模型（MLLMs）在复杂多模态问题中逐步推理能力的基准测试，包含两个高难度任务M-Portal和M-Cube，结果显示当前MLLMs表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 现有推理基准主要关注纯文本推理或可通过直接检索非文本模态信息回答的多模态问题，复杂多模态推理能力仍未被充分研究。

研究方法: MARBLE包含两个任务M-Portal和M-Cube，要求模型在空间、视觉和物理约束下制定和理解多步计划。

研究结果: 12种先进MLLMs在M-Portal上表现接近随机，M-Cube上准确率为0%，仅在某些简化子任务中部分模型优于随机基线。

研究结论: MARBLE揭示了MLLMs在复杂多模态推理中的局限性，尤其是感知能力不足，希望推动下一代具备跨模态推理能力的模型发展。

中文摘要: 多模态信息处理和逐步推理能力是推动人工智能发展的关键挑战。然而，现有推理基准主要关注纯文本推理，或采用可通过直接检索非文本模态信息回答的多模态问题，复杂多模态推理能力仍未被充分理解。为此，我们提出了MARBLE，一个旨在严格测试多模态语言模型（MLLMs）在复杂多模态问题中逐步推理能力的基准。MARBLE包含两个高难度任务M-Portal和M-Cube，要求模型在空间、视觉和物理约束下制定和理解多步计划。我们发现当前MLLMs在MARBLE上表现不佳——12种先进模型在M-Portal上表现接近随机，M-Cube上准确率为0%。仅在某些简化子任务中，部分模型优于随机基线，表明复杂推理仍是现有MLLMs的挑战。此外，感知能力仍是瓶颈，MLLMs有时无法从视觉输入中提取信息。通过揭示MLLMs的局限性，我们希望MARBLE能推动下一代具备跨模态推理能力的模型发展。

</details>


### [315] [AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks](https://arxiv.org/abs/2506.23049)
**中文标题：AURA：语音驱动任务中的理解、推理与自动化工具使用代理**

*Leander Melroy Maben,Gayathri Ganesh Lakshmy,Srijith Radhakrishnan,Siddhant Arora,Shinji Watanabe*

主要分类: cs.AI

摘要简述: AURA是首个开源的语音原生助手，支持动态工具调用和多轮对话，能够完成复杂任务。结合ASR、TTS和LLM技术，AURA在VoiceBench上表现优异，接近GPT-4o水平。


<details>
  <summary>详细信息</summary>
研究动机: 尽管语言和语音技术有所进步，但目前尚无开源系统能够实现语音到语音的多轮对话，并集成工具使用和智能推理。AURA旨在填补这一空白。

研究方法: AURA采用模块化设计，结合开源的ASR、TTS和LLM技术，支持动态工具调用（如日历预订、联系人查找、网页搜索和邮件）。通过自然语言提示和动作类，轻松集成新工具。

研究结果: 在VoiceBench测试中，AURA在OpenBookQA上得分92.75%，超越所有开源系统，接近GPT-4o水平；在AlpacaEval上得分为4.39，与其他开源系统竞争。人工评估显示，其在复杂多轮语音任务中的成功率为90%。

研究结论: AURA作为首个开源的语音原生助手，展示了在复杂任务中动态工具调用和多轮对话的潜力，为语音驱动的智能助手提供了新的可能性。

中文摘要: 尽管语言和语音技术取得了进展，但目前尚无开源系统能够实现语音到语音的多轮对话，并集成工具使用和智能推理。我们推出了AURA（理解、推理与自动化工具使用代理），这是首个开源的语音原生助手，能够通过动态工具调用和多轮对话完成复杂的任务。AURA采用级联管道结合开源的ASR、TTS和LLM技术，支持日历预订、联系人查找、网页搜索和邮件等工具。其模块化设计允许通过自然语言提示和动作类轻松集成新工具。在VoiceBench测试中，AURA在OpenBookQA上得分92.75%，超越所有开源系统，接近GPT-4o水平；在AlpacaEval上得分为4.39，与其他开源系统竞争。人工评估显示，其在复杂多轮语音任务中的成功率为90%。

</details>


### [316] [AI's Euclid's Elements Moment: From Language Models to Computable Thought](https://arxiv.org/abs/2506.23080)
**中文标题：AI的欧几里得元素时刻：从语言模型到可计算思维**

*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

主要分类: cs.AI

摘要简述: 本文提出了一个五阶段进化框架，将AI的发展与人类认知技术的进步类比，预测AI将经历从语言模型到可计算思维的演变，最终实现自我重构的可靠AI。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于为AI的发展提供一个跨学科的系统模型，解释其历史架构变化，并预测未来发展方向，为下一代智能系统的构建提供理论基础和具体策略。

研究方法: 通过类比人类认知技术的演进（如楔形文字、字母、逻辑、微积分等），提出“认知几何”框架，分析AI从专家系统到Transformer的演变，并预测未来的“元语言时刻”、“数学符号时刻”和“形式逻辑系统时刻”。

研究结果: 研究表明AI的发展是非线性的，其工具和洞察力会反馈重塑自身架构。当前处于“元语言时刻”，未来将通过神经符号架构和程序合成实现可计算思维，最终构建可证明对齐的可靠AI。

研究结论: 本文为AI的未来研究提供了理论基础，并为开发下一代智能系统的创业者和开发者提供了具体策略，是此前关于AI经济驱动和认知本质研究的总结。

中文摘要: 本文提出了一个全面的五阶段进化框架，用于理解人工智能的发展，认为其轨迹与人类认知技术的历史进步相呼应。我们假设AI正在经历不同的时代，每个时代都以其表征和推理能力的革命性转变为标志，类似于楔形文字、字母、语法与逻辑、数学微积分和形式逻辑系统的发明。这一“认知几何”框架超越了简单的隐喻，提供了一个跨学科的系统模型，不仅解释了AI从专家系统到Transformer的架构变化，还为未来发展指明了具体路径。重要的是，我们证明这种进化并非线性，而是自反的：随着AI通过这些阶段，其开发的工具和洞察力会形成反馈循环，从根本上重塑其底层架构。当前我们正进入“元语言时刻”，其特征是自我反思能力的出现，如思维链提示和宪法AI。随后的“数学符号时刻”和“形式逻辑系统时刻”将通过神经符号架构和程序合成实现可计算思维，最终构建可证明对齐的可靠AI，并重构其基础表征。本文是我们三部曲的方法论总结，此前探讨了AI的经济驱动（“为什么”）和认知本质（“是什么”）。在此，我们解决了“如何”的问题，为未来研究提供了理论基础，并为构建下一代智能系统的创业者和开发者提供了具体可行的策略。

</details>


### [317] [Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study](https://arxiv.org/abs/2506.23107)
**中文标题：大型语言模型能否捕捉人类风险偏好？一项跨文化研究**

*Bing Song,Jianing Liu,Sisi Jian,Chenyang Wu,Vinayak Dixit*

主要分类: cs.AI

摘要简述: 研究探讨大型语言模型（LLMs）是否能模拟人类风险偏好，通过彩票任务比较模型与人类决策行为，发现模型更风险规避，且中文提示下表现偏差更大。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLMs在对话系统、内容生成等领域的广泛应用，其模拟复杂决策行为（如风险决策）的可靠性引发关注。本研究旨在验证LLMs在风险决策场景中的表现。

研究方法: 使用悉尼、达卡、香港和南京的交通偏好调查数据，对比ChatGPT 4o和ChatGPT o1-mini模型与人类在彩票任务中的决策。通过CRRA框架分析风险偏好，并考察多语言数据的影响。

研究结果: 模型比人类更风险规避，o1-mini更接近人类决策。中文提示下模型预测与实际偏差更大，提示语言可能影响模拟效果。

研究结论: LLMs在模拟人类风险行为方面具有潜力，但在语言和文化背景下的表现仍有局限。

中文摘要: 大型语言模型（LLMs）在对话系统、自动化内容生成等领域取得了显著进展，但其在模拟复杂决策行为（如风险决策）中的可靠性引发担忧。本研究探讨LLMs模拟风险决策场景的能力，通过彩票任务比较模型生成决策与人类实际反应。研究使用来自悉尼、达卡、香港和南京的交通偏好调查数据，向ChatGPT 4o和ChatGPT o1-mini提供人口统计输入，预测个体选择，并通过CRRA框架分析风险偏好。结果显示，两模型均比人类更风险规避，o1-mini更接近人类决策。对南京和香港多语言数据的进一步分析表明，中文提示下模型预测与实际偏差更大，提示语言可能影响模拟性能。这些发现凸显了LLMs在复制人类风险行为方面的潜力与当前局限，尤其是在语言和文化背景下。

</details>


### [318] [The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy](https://arxiv.org/abs/2506.23123)
**中文标题：基础模型的社会影响：推动基于证据的AI政策**

*Rishi Bommasani*

主要分类: cs.AI

摘要简述: 本文探讨基础模型的社会影响及其对AI政策的推动作用，通过概念框架、实证分析和行动建议三部分，旨在为AI治理提供科学基础和政策接口。


<details>
  <summary>详细信息</summary>
研究动机: 基础模型作为AI技术的核心，虽潜力巨大但引发诸多社会问题，需通过科学研究和政策制定实现更好的社会治理。

研究方法: 论文围绕三个主题展开：概念框架（能力、风险及供应链）、实证分析（模型评估与组织透明度）以及从理解到行动的过渡（推动基于证据的AI政策）。

研究结果: 研究为AI治理提供了科学基础和政策接口，有助于实现更好的社会成果。

研究结论: 通过构建科学基础和研究政策接口，本文为AI时代的社会治理提供了重要支持。

中文摘要: 人工智能是人类最具前景的技术，基础模型为其提供了卓越能力。然而，该技术也带来了困惑与忧虑：基础模型理解不足，可能引发多种危害。本文探讨AI时代技术与社会的共同演化，围绕三个主题展开：首先是概念框架，包括基础模型的能力、风险及其在经济中的供应链；其次是实证分析，通过模型评估和组织透明度丰富概念基础；最后是从理解到行动的过渡，通过深入理解基础模型的社会影响推动基于证据的AI政策。综合来看，本文通过构建科学基础和研究政策接口，为AI时代实现更好的社会成果提供了重要支持。

</details>


### [319] [Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons](https://arxiv.org/abs/2506.23128)
**中文标题：大型语言模型是否具备深度关系推理能力？基于DeepSeek-R1与基准对比的洞察**

*Chi Chiu So,Yueyue Sun,Jun-Min Wang,Siu Pang Yung,Anthony Wai Keung Loh,Chun Pong Chau*

主要分类: cs.AI

摘要简述: 本文评估了DeepSeek-R1、DeepSeek-V3和GPT-4o三种大型语言模型在深度关系推理任务中的表现，发现DeepSeek-R1在家族树和通用图推理任务中表现最佳，但随着问题复杂性增加，所有模型均表现不佳。研究揭示了模型推理中的局限性，并提出了未来改进方向。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估当前大型语言模型（LLMs）在深度关系推理任务中的能力，探索其逻辑推理和关系推断的潜力，并揭示模型在复杂任务中的局限性。

研究方法: 通过设计家族树和通用图推理的基准任务，对DeepSeek-R1、DeepSeek-V3和GPT-4o三种模型进行评估，分析其F1分数和推理过程，重点关注DeepSeek-R1的长链思维响应。

研究结果: DeepSeek-R1在多个任务和问题规模中表现最优，但在高复杂度任务中所有模型均表现不佳，主要受限于令牌长度和不完整的输出结构。DeepSeek-R1的推理策略显示出独特的规划和验证能力，但也存在不连贯或不完整的推理现象。

研究结论: 研究揭示了大型语言模型在深度关系推理中的潜力与局限，强调了未来需要进一步探索多模态推理和系统化分析推理失败的原因，以提升模型的逻辑推理能力。

中文摘要: 大型语言模型（LLMs）在深度关系推理方面的表现如何？本文通过一系列精心设计的家族树和通用图推理基准任务，评估并比较了三种前沿LLMs（DeepSeek-R1、DeepSeek-V3和GPT-4o）的推理能力。实验表明，DeepSeek-R1在多个任务和问题规模中均取得最高的F1分数，展现出较强的逻辑演绎和关系推断能力。然而，随着问题复杂性的增加，包括DeepSeek-R1在内的所有模型均表现不佳，主要受限于令牌长度和不完整的输出结构。对DeepSeek-R1的长链思维响应的详细分析揭示了其独特的规划和验证策略，但也暴露了推理中的不连贯或不完整现象，这提示我们需要更深入地研究LLMs的内部推理机制。此外，我们探讨了未来研究的关键方向，包括多模态推理的作用以及对推理失败的系统化分析。本研究为提升LLMs在结构化、多步逻辑推理任务中的能力提供了实证见解和理论启示。代码仓库将在https://github.com/kelvinhkcs/Deep-Relational-Reasoning公开。

</details>


### [320] [Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing](https://arxiv.org/abs/2506.23141)
**中文标题：基于语义感知关系消息传递的上下文驱动知识图谱补全**

*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

主要分类: cs.AI

摘要简述: 本文提出了一种语义感知的关系消息传递方法，通过Top-K邻居选择策略和多头注意力聚合器，有效利用知识图谱中的语义上下文，提升链接预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于节点的消息传递机制在知识图谱补全任务中容易引入噪声或信息稀释，无法有效利用语义上下文。本文旨在解决这一问题。

研究方法: 提出语义感知的关系消息传递框架，包括语义感知的Top-K邻居选择策略和多头注意力聚合器，选择最相关的邻居信息并融合节点表示。

研究结果: 实验表明，该方法在多个基准数据集上优于现有方法，显著提升了链接预测的准确性。

研究结论: 通过语义感知的消息传递，本文方法有效捕捉了知识图谱中的上下文信息，减少了无关信息的干扰，为知识图谱补全提供了新思路。

中文摘要: 知识图谱补全（KGC）中，三元组$(h, r, t)$的语义上下文对预测至关重要。然而，传统的基于节点的消息传递机制在应用于知识图谱时，常因不加区分地聚合所有邻边信息而引入噪声或导致信息稀释或过平滑。为解决这一问题，我们提出了一种语义感知的关系消息传递方法。该框架的核心创新是引入了语义感知的Top-K邻居选择策略。具体而言，该策略首先在共享潜在空间中评估中心节点与其邻边的语义相关性，仅选择Top-K最相关的邻边。随后，通过多头注意力聚合器将这些选定边的信息与中心节点自身的表示有效融合，生成语义聚焦的节点消息。通过这种方式，我们的模型不仅利用了知识图谱中边的结构和特征，还更准确地捕捉并传播与特定链接预测任务最相关的上下文信息，从而有效减少了无关信息的干扰。大量实验表明，我们的方法在多个基准数据集上优于现有方法。

</details>


### [321] [Rises for Measuring Local Distributivity in Lattices](https://arxiv.org/abs/2506.23168)
**中文标题：格中局部分配性度量的上升方法**

*Mohammad Abdulla,Tobias Hille,Dominik Dürrschnabel,Gerd Stumme*

主要分类: cs.AI

摘要简述: 本文提出了一种通过“上升”度量格中局部分配性的新方法，证明了格是分配性的充要条件是无非单位上升，并揭示了实际数据中概念格的高度联合分配性。


<details>
  <summary>详细信息</summary>
研究动机: 在格论中，分配性是一个经典且广泛研究的性质，但在数据分析（尤其是形式概念分析）中，缺乏量化分配性的标准方法。本文旨在填补这一空白。

研究方法: 通过引入“上升”概念，研究覆盖概念中属性或对象数量的变化，并与经典的“交”和“并”分配性关联，分析实际数据中概念格的分配性表现。

研究结果: 证明了格是分配性的充要条件是无非单位上升；实际数据中的概念格表现出高度的联合分配性，但较少满足交分配性。

研究结论: 上升是衡量格分配性的有效工具，实际数据中的概念格更倾向于联合分配性，为格论在数据分析中的应用提供了新视角。

中文摘要: 分配性是格论中一个经典且深入研究的性质。在数据分析，尤其是形式概念分析（FCA）中，格通常表现出高度的分配性，但缺乏量化这一性质的标准方法。本文引入“上升”概念，作为评估分配性的手段。上升捕捉了概念格中覆盖概念的属性或对象数量的变化。我们证明，格是分配性的充要条件是无非单位上升。此外，我们将上升与经典的“交”和“并”分配性关联起来。观察到实际数据中的概念格具有高度的联合分配性，但较少满足交分配性。我们还研究了联合分配性在有序集层面的表现。

</details>


### [322] [FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis](https://arxiv.org/abs/2506.23273)
**中文标题：FinStat2SQL：用于金融报表分析的文本转SQL管道**

*Quang Hung Nguyen,Phuong Anh Trinh,Phan Quoc Hung Mai,Tuan Phong Trinh*

主要分类: cs.AI

摘要简述: FinStat2SQL是一个轻量级的文本转SQL管道，专为金融报表分析设计，结合大语言模型和小语言模型，支持自然语言查询，并在越南企业环境中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型有所进步，但在复杂和特定领域的查询中，文本转SQL仍面临挑战，尤其是在金融领域，数据库设计和报表布局因实体和国家而异。FinStat2SQL旨在解决这一问题，为越南企业提供高效、低成本的金融分析解决方案。

研究方法: FinStat2SQL采用多智能体设置，结合大语言模型和小语言模型，实现实体提取、SQL生成和自我修正。针对越南会计准则（VAS）定制，并构建了特定领域的数据库和合成QA数据集进行评估。

研究结果: 经过微调的7B模型在消费级硬件上实现了61.33%的准确率和低于4秒的响应时间，性能优于GPT-4o-mini。

研究结论: FinStat2SQL为金融分析提供了一个可扩展且经济高效的解决方案，使越南企业能够轻松使用AI驱动的查询功能。

中文摘要: 尽管大语言模型取得了进展，但文本转SQL仍面临许多挑战，尤其是在复杂和特定领域的查询中。在金融领域，数据库设计和财务报表布局因金融实体和国家而异，使得文本转SQL更具挑战性。我们提出了FinStat2SQL，一个轻量级的文本转SQL管道，支持对财务报表进行自然语言查询。该管道针对越南会计准则（VAS）等本地标准进行了定制，采用多智能体设置，结合大语言模型和小语言模型，实现实体提取、SQL生成和自我修正。我们构建了一个特定领域的数据库，并在合成QA数据集上评估了模型性能。经过微调的7B模型在消费级硬件上实现了61.33%的准确率和低于4秒的响应时间，性能优于GPT-4o-mini。FinStat2SQL为金融分析提供了一个可扩展且经济高效的解决方案，使越南企业能够轻松使用AI驱动的查询功能。

</details>


### [323] [Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games](https://arxiv.org/abs/2506.23276)
**中文标题：被推理腐蚀：推理语言模型在公共物品博弈中成为搭便车者**

*David Guzman Piedrahita,Yongjin Yang,Mrinmaya Sachan,Giorgia Ramponi,Bernhard Schölkopf,Zhijing Jin*

主要分类: cs.AI

摘要简述: 研究探讨了大型语言模型（LLMs）在多智能体系统中的合作行为，发现推理能力强的模型反而难以实现合作，而传统模型表现更好。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLMs作为自主代理的广泛应用，理解其合作与社会机制变得至关重要。研究旨在探索LLMs如何在自利与集体利益之间权衡，以确保其对齐性、鲁棒性和安全部署。

研究方法: 研究采用行为经济学中的公共物品博弈实验，观察不同LLMs在重复互动中的行为模式，分析其合作与惩罚机制。

研究结果: 发现四种行为模式：持续高合作、波动合作、逐渐衰退合作和固定策略。推理能力强的模型（如o1系列）合作表现较差，而传统模型合作水平更高。

研究结论: 当前提升LLMs推理能力的方法未必能促进合作，为需要持续协作的环境部署LLM代理提供了重要启示。

中文摘要: 随着大型语言模型（LLMs）越来越多地被部署为自主代理，理解其合作与社会机制变得日益重要。特别是，LLMs如何平衡自利与集体福祉是确保对齐性、鲁棒性和安全部署的关键挑战。本文研究了多智能体LLM系统中代价高昂的惩罚问题，即代理是否愿意投入自身资源以激励合作或惩罚背叛。为此，我们改编了行为经济学中的公共物品博弈实验，通过重复互动观察不同LLMs如何应对社会困境。分析揭示了四种行为模式：一些模型持续建立并维持高合作水平，另一些在参与与退出间波动，还有一些合作行为随时间逐渐衰退，另一些则无论结果如何都坚持固定策略。令人惊讶的是，我们发现推理能力强的LLMs（如o1系列）合作表现显著较差，而某些传统LLMs则能持续实现高合作水平。这些发现表明，当前提升LLMs推理能力的方法未必能促进合作，为需要持续协作的环境部署LLM代理提供了宝贵见解。代码发布于https://github.com/davidguzmanp/SanctSim。

</details>


### [324] [GATSim: Urban Mobility Simulation with Generative Agents](https://arxiv.org/abs/2506.23306)
**中文标题：GATSim：基于生成式智能体的城市交通模拟**

*Qi Liu,Can Li,Wanjing Ma*

主要分类: cs.AI

摘要简述: 本文提出GATSim框架，利用生成式智能体模拟城市交通行为，结合心理记忆系统和终身学习机制，生成更真实的出行决策。实验表明其性能接近人类标注者。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于规则的交通模拟无法捕捉人类出行决策的复杂性和多样性，而生成式智能体技术为模拟提供了新的可能性。

研究方法: GATSim结合城市交通基础模型与智能体认知系统，通过心理记忆、工具使用和终身学习机制，生成多样化的出行行为。

研究结果: 生成式智能体在实验中表现出接近人类标注者的性能，并能自然生成宏观交通演化模式。

研究结论: GATSim为城市交通模拟提供了更真实的行为生成方法，展示了生成式智能体在复杂场景中的潜力。

中文摘要: 传统的基于智能体的城市交通模拟依赖于僵化的规则系统，无法捕捉人类出行决策的复杂性、适应性和行为多样性。近年来，大语言模型和AI智能体技术的进步为创建具有推理能力、持久记忆和自适应学习机制的智能体提供了机会。我们提出了GATSim（生成式智能体交通模拟），这是一种新颖的框架，利用这些技术进步为城市交通模拟创建具有丰富行为特征的生成式智能体。与传统方法不同，GATSim智能体具有多样化的社会经济属性、个体生活方式和随时间演变的偏好，这些通过心理记忆系统、工具使用能力和终身学习机制塑造其出行决策。本研究的主要贡献包括：（1）结合城市交通基础模型、智能体认知系统和交通模拟环境的综合架构；（2）一个功能完整的原型实现；（3）系统验证表明生成式智能体能产生可信的出行行为。通过设计的反思过程，本研究中的生成式智能体可以将特定的出行经验转化为通用见解，从而实现随时间推移的行为适应，并具备针对城市交通场景的活动规划和实时反应行为的专门机制。实验表明，生成式智能体在交通场景中的表现与人类标注者相当，并能自然地生成宏观交通演化模式。原型系统的代码已公开在https://github.com/qiliuchn/gatsim。

</details>


### [325] [The Confidence Paradox: Can LLM Know When It's Wrong](https://arxiv.org/abs/2506.23464)
**中文标题：置信度悖论：LLM能否知道自己何时出错**

*Sahil Tripathi,Md Tabrez Nafis,Imran Hussain,Jiechao Gao*

主要分类: cs.AI

摘要简述: 本文提出HonestVQA框架，通过自监督的诚实校准方法解决DocVQA系统中模型置信度与实际知识不匹配的问题，显著提升准确性和伦理响应能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的DocVQA系统在伦理响应性方面存在不足，模型常对模糊问题给出过度自信的答案或未能有效传达不确定性，这在需要伦理问责的领域带来风险。

研究方法: HonestVQA采用模型无关的方法，通过量化不确定性识别知识缺口，使用加权损失函数对齐模型置信度与实际正确性，并通过对比学习强制伦理响应行为。

研究结果: 实验表明，HonestVQA在SpDocVQA、InfographicsVQA和SROIE数据集上准确率和F1值分别提升4.3%，同时显著降低过度自信（H-Score和ECI分别降低0.072和0.078）。

研究结论: HonestVQA通过诚实校准和伦理对齐显著提升了DocVQA系统的性能和可信度，为伦理敏感的文档问答任务提供了有效解决方案。

中文摘要: 文档视觉问答（DocVQA）系统在现实应用中日益普及，但其伦理透明度不足——常对模糊问题给出过度自信的答案或未能以可信方式传达不确定性。这种模型置信度与实际知识的不匹配在需要伦理问责的领域带来显著风险。现有方法如LayoutLMv3、UDOP和DONUT通过架构优化和准确性提升实现了SOTA性能，但在伦理响应性方面仍有不足。为弥补这些缺陷，我们提出HonestVQA，一种自监督的诚实校准框架，用于伦理对齐的DocVQA。我们的模型无关方法通过量化不确定性识别知识缺口，使用加权损失函数对齐模型置信度与实际正确性，并通过对比学习强制伦理响应行为。我们还引入两项评估指标——诚实分数（H-Score）和伦理置信指数（ECI）——以衡量置信度、准确性和伦理沟通的对齐程度。实验表明，HonestVQA在SpDocVQA、InfographicsVQA和SROIE数据集上准确率和F1值分别提升4.3%，同时显著降低过度自信（H-Score和ECI分别降低0.072和0.078）。在跨领域评估中，其准确率和F1值分别达到78.9%和76.1%，表现出强泛化能力。消融实验显示，若缺少对齐或对比损失，准确率将下降3.8%。

</details>


### [326] [Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence](https://arxiv.org/abs/2506.23503)
**中文标题：认知行为疗法的数据增强：利用ERNIE语言模型的人工智能方法**

*Bosubabu Sambana,Kondreddygari Archana,Suram Indhra Sena Reddy,Shaik Meethaigar Jameer Basha,Shaik Karishma*

主要分类: cs.AI

摘要简述: 本文提出了一种利用ERNIE语言模型和人工智能技术的数据增强方法，用于认知行为疗法（CBT），旨在通过分析社交媒体中的负面情绪和认知扭曲，为心理治疗师提供更全面的干预工具。


<details>
  <summary>详细信息</summary>
研究动机: 认知行为疗法（CBT）在心理健康治疗中效果显著，但其有效性依赖于准确识别认知路径。当前缺乏针对社交媒体中负面情绪和认知扭曲的分析方法，限制了在线环境下的及时干预。

研究方法: 系统采用BERT、RoBERTa进行情感分析，T5和PEGASUS进行文本摘要，mT5进行多语言翻译，专注于检测社交媒体数据中的负面情绪和认知扭曲，并预测潜在的心理健康问题。

研究结果: 该方法不仅能识别负面思维，还能预测额外的负面副作用和其他潜在心理健康问题（如恐惧症、饮食失调），为心理治疗师提供了更全面的早期检测和治疗工具。

研究结论: 通过数据增强和人工智能技术，该系统为认知行为疗法提供了更强大的分析能力，有助于心理治疗师在在线环境中实现更及时和有效的干预。

中文摘要: 认知行为疗法（CBT）是一种针对心理健康问题中非理性思维模式的有效方法，但其效果依赖于准确识别认知路径以提供针对性治疗。在当今数字时代，人们常在社交媒体上表达负面情绪，可能暴露认知扭曲，严重时甚至表现出自杀倾向。然而，目前缺乏专门分析这些认知路径的方法，这对心理治疗师在在线环境中提供及时有效干预至关重要。本研究提出了一种基于接受、承诺和数据增强的CBT框架，用于对文本和视觉内容进行正负面分类。具体而言，系统采用BERT和RoBERTa进行情感分析，T5和PEGASUS进行文本摘要，mT5进行多语言翻译，专注于检测社交媒体数据中的负面情绪和认知扭曲。现有模型主要设计用于识别负面思维，而本系统更进一步，能够预测额外的负面副作用及其他潜在心理健康问题（如恐惧症、饮食失调）。这一改进提供了更全面的理解和干预策略，为心理治疗师提供了早期检测和治疗多种心理问题的强大工具。

</details>


### [327] [Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM](https://arxiv.org/abs/2506.23504)
**中文标题：基于AlexNet和LSTM的混合电力价格预测方法**

*Bosubabu Sambana,Kotamsetty Geethika Devi,Bandi Rajeswara Reddy,Galeti Mohammad Hussain,Gownivalla Siddartha*

主要分类: cs.AI

摘要简述: 本文提出了一种结合AlexNet和LSTM的混合模型，用于提高电力价格预测的准确性。该方法通过整合外部变量和优化数据处理，显著提升了预测性能，准确率达到97.08%，优于传统的RNN和ANN模型。


<details>
  <summary>详细信息</summary>
研究动机: 传统的电力价格预测方法（如RNN和ANN）在处理时间序列数据时表现不足，且仅关注需求和价格，忽略了其他外部变量的影响。为了解决这一问题，本文提出了一种混合模型，旨在通过结合AlexNet的特征提取能力和LSTM的序列学习能力，提高预测准确性。

研究方法: 本文提出了一种混合模型，结合了AlexNet和LSTM算法。AlexNet用于特征提取，LSTM用于学习时间序列模式。模型输入包括历史数据中的需求、温度、阳光和降雨等关键变量，并通过最小-最大缩放和时间窗口等技术优化数据处理。

研究结果: 实验结果表明，该混合模型的预测准确率达到97.08%，显著优于传统RNN（96.64%）和ANN（96.63%）模型。

研究结论: 本文提出的AlexNet与LSTM混合模型在电力价格预测中表现出更高的准确性和鲁棒性，证明了整合外部变量和优化算法的重要性。

中文摘要: 近年来，混合模型在电力价格预测中的应用取得了显著进展。本文提出了一种结合AlexNet和LSTM算法的新模型，显著提高了预测准确性。尽管RNN和ANN在预测中表现良好，但它们难以处理复杂的时间序列数据。传统方法仅关注需求和价格，导致数据分析不充分。为解决这一问题，本文提出的混合方法引入了影响价格的外部变量。得益于AlexNet的出色特征提取能力和LSTM的序列学习能力，预测准确性大幅提升。模型基于历史数据，整合了需求、温度、阳光和降雨等关键变量，并采用最小-最大缩放和时间窗口等技术进行优化。实验结果显示，该混合模型的准确率为97.08%，优于RNN（96.64%）和ANN（96.63%）模型。

</details>


### [328] [Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays](https://arxiv.org/abs/2506.23517)
**中文标题：评估GPTZero在识别AI与人类撰写文章中的准确性**

*Selin Dik,Osman Erdem,Mehmet Dik*

主要分类: cs.AI

摘要简述: 研究评估了GPTZero在区分AI生成与人类撰写文章中的准确性，发现其对AI文本检测效果显著，但对人类文本的误判较多。


<details>
  <summary>详细信息</summary>
研究动机: 随着学生使用AI工具的现象增多，教师依赖AI检测工具如GPTZero识别AI生成文本，但其可靠性尚不明确。本研究旨在评估GPTZero在不同长度文章中的检测效果。

研究方法: 研究收集了28篇AI生成和50篇人类撰写的文章，分为短、中、长三类，通过GPTZero检测其AI生成概率和置信度。

研究结果: GPTZero对AI生成文本的检测准确率高达91-100%，但对人类文本存在误判，出现少量假阳性。

研究结论: GPTZero在检测纯AI生成内容时有效，但在区分人类文本时可靠性有限，建议教育工作者谨慎使用。

中文摘要: 随着学生使用AI工具的现象日益普遍，教师开始使用GPTZero和QuillBot等AI检测工具来识别AI生成的文本。然而，这些检测工具的可靠性尚不确定。本研究主要关注最常用的AI检测工具GPTZero在不同长度随机提交文章（短篇40-100词、中篇100-350词、长篇350-800词）中识别AI生成文本的成功率。我们收集了28篇AI生成论文和50篇人类撰写论文的数据集。通过将这些随机文章逐一输入GPTZero，测量其AI生成百分比和置信度。结果显示，绝大多数AI生成论文被准确检测（AI生成概率为91-100%），而人类撰写文章的结果波动较大，存在少量误判。这些发现表明，尽管GPTZero在检测纯AI生成内容时有效，但其在区分人类撰写文本方面的可靠性有限。因此，教育工作者在仅依赖AI检测工具时应保持谨慎。

</details>


### [329] [ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data](https://arxiv.org/abs/2506.23520)
**中文标题：ChemActor：利用LLM生成的数据增强化学合成动作的自动化提取**

*Yu Zhang,Ruijie Yu,Jidong Tian,Feng Zhu,Jiapeng Liu,Xiaokang Yang,Yaohui Jin,Yanyan Xu*

主要分类: cs.AI

摘要简述: ChemActor是一种基于大型语言模型（LLM）的化学执行器，通过LLM生成的数据框架提升化学合成动作的自动化提取性能，在R2D和D2A任务中表现优异，超越基线模型10%。


<details>
  <summary>详细信息</summary>
研究动机: 随着有机化学中机器人合成的兴趣增加，从文献中自动化提取化学程序变得至关重要。然而，由于化学语言的模糊性和人工标注的高成本，这一任务仍具挑战性。

研究方法: ChemActor采用完全微调的大型语言模型（LLM），提出了一种顺序LLM生成的数据框架，结合数据选择模块和通用LLM，从单个分子输入生成机器可执行的动作。此外，引入了一种新颖的多轮LLM循环评审指标。

研究结果: 在反应到描述（R2D）和描述到动作（D2A）任务中，ChemActor通过LLM生成的数据增强，实现了最先进的性能，比基线模型高出10%。

研究结论: ChemActor通过LLM生成的数据框架，显著提升了化学合成动作的自动化提取能力，为化学实验程序的自动化提供了有效解决方案。

中文摘要: 随着有机化学中机器人合成的兴趣日益增长，从文献中自动化提取化学程序变得至关重要。然而，由于化学语言的模糊性和人工标注的高成本，这一任务仍具挑战性。本文提出ChemActor，一种完全微调的大型语言模型（LLM），作为化学执行器，用于在非结构化实验程序和结构化动作序列之间进行转换。我们提出了一种顺序LLM生成的数据框架，以解决标注数据不足和质量低的问题。该框架结合了基于分布差异的数据选择模块和通用LLM，从单个分子输入生成机器可执行的动作。此外，我们引入了一种新颖的多轮LLM循环评审指标，反映了模型对化学实验程序的高级理解。在反应到描述（R2D）和描述到动作（D2A）任务上的大量实验表明，通过LLM生成的数据增强的ChemActor实现了最先进的性能，比基线模型高出10%。代码可在https://github.com/Zhanghahah/ChemActor获取。

</details>


### [330] [CooT: Learning to Coordinate In-Context with Coordination Transformers](https://arxiv.org/abs/2506.23549)
**中文标题：CooT：通过协调变换器学习上下文协调**

*Huai-Chih Wang,Hsiang-Chun Chuang,Hsi-Chun Cheng,Dai-Jie Wu,Shao-Hua Sun*

主要分类: cs.AI

摘要简述: 本文提出了一种名为CooT的新型协调框架，通过利用近期交互历史快速适应未见过的合作伙伴，显著提升了多智能体系统中的协调效率。


<details>
  <summary>详细信息</summary>
研究动机: 在多智能体系统中，动态和不确定环境下的协调是一个重要挑战。现有方法（如自我博弈和基于群体的方法）要么泛化能力差，要么需要大量训练。为解决这些问题，作者提出了CooT框架。

研究方法: CooT是一种基于上下文的协调框架，通过预测与观察到的合作伙伴行为一致的动作来快速适应新伙伴。它利用从具有互补行为的多样化智能体对中收集的交互轨迹进行训练，无需显式监督或微调。

研究结果: 在Overcooked基准测试中，CooT在涉及未见过的合作伙伴的协调任务中显著优于基线方法。人类评估进一步证实CooT是最有效的协作伙伴，消融实验展示了其鲁棒性和灵活性。

研究结论: CooT通过上下文学习快速适应新伙伴，显著提升了多智能体协调能力，为动态环境中的协作提供了高效解决方案。

中文摘要: 在动态和不确定环境中，人工智能体之间的有效协调是多智能体系统中的重大挑战。现有方法（如自我博弈和基于群体的方法）要么对未见过的合作伙伴泛化能力差，要么需要大量训练。为克服这些限制，我们提出了协调变换器（CooT），这是一种新颖的上下文协调框架，利用近期交互历史快速适应未见过的合作伙伴。与以往主要增加训练伙伴多样性的方法不同，CooT通过预测与观察到的合作伙伴交互一致的动作，明确专注于适应新伙伴行为。CooT在具有互补行为的多样化智能体对收集的交互轨迹上进行训练，无需显式监督或微调即可快速学习有效协调策略。在Overcooked基准测试中，CooT在涉及未见过的合作伙伴的协调任务中显著优于基线方法。人类评估进一步确认CooT是最有效的协作伙伴，而广泛的消融实验突出了其在多智能体场景中的鲁棒性、灵活性和对上下文的敏感性。

</details>


### [331] [MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI](https://arxiv.org/abs/2506.23563)
**中文标题：MMReason：面向AGI的多模态大语言模型开放多模态多步推理基准**

*Huanjin Yao,Jiaxing Huang,Yawen Qiu,Michael K. Chen,Wenzheng Liu,Wei Zhang,Wenjie Zeng,Xikun Zhang,Jingyi Zhang,Yuxin Song,Wenhao Wu,Dacheng Tao*

主要分类: cs.AI

摘要简述: 本文提出了MMReason，一个用于评估多模态大语言模型（MLLMs）长链推理能力的开放多模态多步推理基准，旨在填补现有基准在多样性、难度和中间步骤评估上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有MLLM基准在评估长链推理能力时存在多样性不足、易受猜测和记忆影响，以及中间推理步骤评估不充分的问题。MMReason旨在通过设计一个开放、多样且具有挑战性的基准来解决这些问题。

研究方法: 1. 从多个学科和难度级别中筛选需要多步推理的挑战性问题；2. 将问题转化为开放形式，并通过多模型投票技术过滤掉易猜测和记忆的案例；3. 为问题标注详细的逐步解决方案，并设计基于参考的三元评分机制以评估中间推理步骤。

研究结果: MMReason对主流MLLMs进行了基准测试，并深入分析了其推理能力，为MLLM推理研究提供了有价值的资源。

研究结论: MMReason填补了现有基准的不足，为评估和提升MLLMs的长链推理能力提供了重要工具，并有望推动MLLM推理研究的进展。

中文摘要: 推理在推动多模态大语言模型（MLLMs）迈向通用人工智能（AGI）中起着关键作用。然而，现有MLLM基准往往在精确和全面评估长链推理能力方面存在不足，主要体现在三个方面：（1）缺乏难度和多样性，（2）易受猜测和记忆影响，（3）对中间推理步骤的评估不足。为填补这一空白，我们提出了MMReason，一个旨在通过多样、开放且具有挑战性的问题精确全面评估MLLM长链推理能力的新基准。首先，我们从多个领域（即6个学科）和多个难度级别（从大学预科到大学，从基础到竞赛级别）筛选出需要多步推理的挑战性问题。其次，这些问题被转化为开放形式，并通过多模型投票技术过滤掉与猜测和记忆相关的捷径案例，以确保推理评估的鲁棒性。第三，我们为问题标注了详细的逐步解决方案，并设计了一个基于参考的三元评分机制，以可靠评估中间推理步骤。通过MMReason，我们对主流MLLMs进行了基准测试，并深入分析了其推理能力。我们希望MMReason能成为推动MLLM推理研究的有价值资源。代码将在https://github.com/HJYao00/MMReason 提供。

</details>


### [332] [Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](https://arxiv.org/abs/2506.23576)
**中文标题：评估多智能体防御对大型语言模型越狱攻击的效果**

*Maria Carolina Cornelia Wit,Jun Pang*

主要分类: cs.AI

摘要简述: 本文研究了多智能体LLM系统作为防御越狱攻击的有效性，发现其能增强抵抗能力但存在误报和计算开销的权衡。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的发展，越狱攻击（绕过安全机制的提示）引发担忧，本文旨在探索多智能体系统是否能有效防御此类攻击。

研究方法: 通过复现AutoDefense框架，比较单智能体与双智能体、三智能体配置，评估了三种越狱策略（AutoDefense、BetterDan和JB）的防御效果。

研究结果: 多智能体系统显著提升了对抗越狱攻击的能力，尤其是减少了漏报，但其效果因攻击类型而异，并伴随误报增加和计算开销增大的问题。

研究结论: 当前自动防御存在局限性，未来需改进对齐鲁棒性以提升LLM系统的安全性。

中文摘要: 近年来，大型语言模型（LLM）的进步引发了人们对越狱攻击（即绕过安全机制的提示）的担忧。本文研究了多智能体LLM系统作为此类攻击防御手段的有效性。我们评估了三种越狱策略，包括原始的AutoDefense攻击以及Deepleaps的BetterDan和JB。通过复现AutoDefense框架，我们比较了单智能体与双智能体、三智能体配置。结果表明，多智能体系统增强了对抗越狱攻击的能力，尤其是减少了漏报。然而，其效果因攻击类型而异，并引入了误报增加和计算开销等权衡。这些发现揭示了当前自动防御的局限性，并为未来LLM系统的对齐鲁棒性改进提供了方向。

</details>


### [333] [Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games](https://arxiv.org/abs/2506.23626)
**中文标题：基于语言模型的自校正奖励塑造方法用于游戏中的强化学习代理**

*António Afonso,Iolanda Leite,Alessandro Sestini,Florian Fuchs,Konrad Tollmar,Linus Gisslén*

主要分类: cs.AI

摘要简述: 本文提出了一种基于语言模型的自校正奖励塑造方法，用于自动优化强化学习代理在游戏中的奖励函数权重，显著提升了代理性能。


<details>
  <summary>详细信息</summary>
研究动机: 在游戏中部署强化学习代理面临两大挑战：设计有效的奖励函数需要专家知识，且游戏内容或机制变化时需重新调整奖励权重。本文旨在通过语言模型自动优化奖励权重，减少人工干预。

研究方法: 提出一种闭环方法，利用语言模型根据用户定义的行为目标和历史训练数据，迭代更新奖励函数权重，实现自校正和优化。

研究结果: 在赛车任务中，语言模型引导的代理性能显著提升，成功率从9%增至74%，最终达到80%的成功率，接近专家手动调整的94%。

研究结论: 语言模型引导的奖励权重优化方法有效减少了人工干预，显著提升了代理性能，为游戏中的强化学习应用提供了新思路。

中文摘要: 近年来，强化学习（RL）在游戏中的应用取得了显著进展，能够生成多样化的代理行为，从而改变玩家的游戏体验。然而，在生产环境中部署RL代理面临两大挑战：（1）设计有效的奖励函数通常需要RL专家；（2）当游戏内容或机制发生变化时，之前调整的奖励权重可能不再最优。针对后者，我们提出了一种自动化方法，基于用户定义的语言行为目标，迭代优化RL代理的奖励函数权重。语言模型（LM）根据目标行为和历史训练数据，在每次迭代中提出更新的权重。这一闭环过程使LM能够自我校正并逐步优化输出，无需人工干预。我们在赛车任务中评估了该方法，结果表明代理性能在迭代中持续提升。语言模型引导的代理在仅一次迭代后，成功率从9%提升至74%。与人类专家手动设计的权重相比，最终迭代中，语言模型优化的代理达到了80%的成功率，平均每圈耗时855步，与专家优化代理的峰值94%成功率和850步耗时表现相当。

</details>


### [334] [HASD: Hierarchical Adaption for pathology Slide-level Domain-shift](https://arxiv.org/abs/2506.23673)
**中文标题：HASD：病理学切片级别域偏移的分层适应框架**

*Jingsong Liu,Han Li,Chen Yang,Michael Deutges,Ario Sadafi,Xin You,Katharina Breininger,Nassir Navab,Peter J. Schüffler*

主要分类: cs.AI

摘要简述: 本文提出了一种名为HASD的分层适应框架，用于解决病理学中切片级别的域偏移问题。通过多尺度特征一致性和计算高效的适应方法，HASD在多个数据集上显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 病理学数据受中心特定条件影响较大，现有方法多关注图像块而非全切片图像（WSI），无法满足临床需求。因此，需要一种能够捕捉全局WSI特征的切片级别域适应方法。

研究方法: HASD框架包含两个关键部分：(1) 分层适应框架，包括域级对齐求解器、切片级几何不变性正则化和块级注意力一致性正则化；(2) 原型选择机制以减少计算开销。

研究结果: 在五个数据集上的实验表明，HASD在乳腺癌HER2分级任务中AUROC提升了4.1%，在UCEC生存预测任务中C-index提升了3.9%。

研究结论: HASD为病理学机构提供了一种实用且可靠的切片级别域适应解决方案，显著降低了计算和标注成本。

中文摘要: 域偏移是病理学AI中的关键问题，因为病理数据受中心特定条件影响较大。现有的病理域适应方法多关注图像块而非全切片图像（WSI），因此无法满足典型临床场景中所需的全局WSI特征。本文提出了一种分层适应框架（HASD），用于解决切片级别的域偏移问题。HASD通过两个关键组件实现多尺度特征一致性和计算高效的切片级别域适应：(1) 分层适应框架，包括域级对齐求解器、切片级几何不变性正则化和块级注意力一致性正则化；(2) 原型选择机制以减少计算开销。我们在两个切片级别任务和五个数据集上验证了该方法，在乳腺癌HER2分级队列中AUROC提升了4.1%，在UCEC生存预测队列中C-index提升了3.9%。HASD为病理学机构提供了一种实用且可靠的切片级别域适应解决方案，显著降低了计算和标注成本。

</details>


### [335] [PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red](https://arxiv.org/abs/2506.23689)
**中文标题：PokéAI：一个面向《Pokémon Red》的目标生成与战斗优化的多智能体系统**

*Zihao Liu,Xinhang Sui,Yueran Song,Siwen Wang*

主要分类: cs.AI

摘要简述: PokéAI是一个基于文本的多智能体大型语言模型框架，首次实现自主玩《Pokémon Red》。系统包含规划、执行和评估三个智能体，形成闭环决策系统。战斗模块测试显示胜率达80.8%，接近人类玩家水平，且语言能力与战略推理能力相关。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发一个能够自主玩《Pokémon Red》的多智能体系统，探索大型语言模型在游戏中的战略推理能力，并验证语言能力与游戏表现的相关性。

研究方法: 系统分为三个智能体：规划智能体生成任务，执行智能体完成任务，评估智能体验证结果。战斗模块作为初步测试，评估模型的战斗表现。

研究结果: 战斗模块在50次野生对战中平均胜率为80.8%，仅比人类玩家低6%。语言能力评分与战斗表现显著相关，且不同模型表现出独特的游戏风格。

研究结论: PokéAI展示了多智能体系统在游戏中的潜力，验证了语言能力与战略推理的关联，并为未来智能体行为研究提供了新方向。

中文摘要: 我们介绍了PokéAI，这是首个基于文本的多智能体大型语言模型（LLM）框架，旨在自主玩《Pokémon Red》。系统包含三个专用智能体——规划、执行和评估，每个智能体拥有独立的记忆库、角色和技能。规划智能体作为核心大脑，生成游戏任务；执行智能体在游戏环境中完成任务；评估智能体验证任务结果。完成验证后，控制权返回规划智能体，形成闭环决策系统。
  作为初步测试，我们在执行智能体中开发了战斗模块。结果显示，战斗AI在50次野生对战中平均胜率为80.8%，仅比经验丰富的人类玩家低6%。此外，模型的语言能力评分与战斗表现显著相关，表明语言能力与战略推理存在联系。最后，游戏日志分析显示，每个LLM表现出独特的游戏风格，表明不同模型形成了不同的战略行为。

</details>


### [336] [Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models](https://arxiv.org/abs/2506.23692)
**中文标题：Agent4S：从大语言模型视角看科研范式的转变**

*Boyuan Zheng,Zerui Fang,Zhe Xu,Rui Wang,Yiwen Chen,Cunshi Wang,Mengwei Qu,Lei Lei,Zhen Feng,Yan Liu,Yuyang Li,Mingzhou Tan,Jiaji Wu,Jianwei Shuai,Jia Li,Fangfu Ye*

主要分类: cs.AI

摘要简述: 本文提出Agent4S作为第五科学范式，利用大语言模型驱动的智能体自动化整个科研流程，解决当前AI4S的核心低效问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI4S仅作为分析工具，未能解决科研流程的核心低效问题。作者提出Agent4S，旨在通过大语言模型驱动的智能体实现科研全流程自动化，推动科学发现的革命性进步。

研究方法: 提出Agent4S的五级分类框架，从简单任务自动化到完全自主协作的“AI科学家”，为科研自动化提供清晰路线图。

研究结果: 定义了Agent4S作为第五科学范式的革命性意义，并提供了从低级到高级的科研自动化发展路径。

研究结论: Agent4S通过大语言模型驱动的智能体实现科研全流程自动化，标志着科学发现的新范式，为未来科研提供了革命性方向。

中文摘要: 尽管AI for Science（AI4S）在当前研究范式中作为分析工具，但并未解决其核心低效问题。我们提出“Agent for Science”（Agent4S）——利用大语言模型驱动的智能体自动化整个科研流程——作为真正的第五科学范式。本文介绍了Agent4S的五级分类，从简单任务自动化到完全自主协作的“AI科学家”，为科学发现的下一步革命性进展提供了清晰路线图。

</details>


### [337] [A New Perspective On AI Safety Through Control Theory Methodologies](https://arxiv.org/abs/2506.23703)
**中文标题：基于控制理论方法的AI安全性新视角**

*Lars Ullrich,Walter Zimmer,Ross Greer,Knut Graichen,Alois C. Knoll,Mohan Trivedi*

主要分类: cs.AI

摘要简述: 本文提出了一种基于控制理论的新视角，通过跨学科方法提升AI安全性，强调数据控制在AI工程中的应用。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI技术的快速发展，其在安全关键领域的应用缺乏可靠的安全保障，因此需要结合控制理论提升AI系统的安全性。

研究方法: 采用系统理论和系统分析驱动的方法，提出数据控制的新视角，通过跨学科方式将控制理论的安全分析应用于AI系统。

研究结果: 提出了一种通用的安全分析框架，适用于具体AI系统和应用，并为未来的创新奠定了基础。

研究结论: 控制理论为AI安全性提供了新的研究方向，数据控制的概念有望推动AI工程在安全保障方面的发展。

中文摘要: 尽管人工智能（AI）发展迅速，并在解决复杂问题上表现出色，但其安全性保障仍是主要问题。特别是在安全关键的实际网络物理系统中，AI有望实现更高水平的自主性，但缺乏安全保障阻碍了其发展。数据驱动的控制利用AI的最新进展改进了控制系统，而控制理论总体上可以提升AI的安全性。因此，本文提出了一种基于跨学科解释的新视角，通过系统理论和系统分析驱动的方式，探讨AI系统对数据生成过程的抽象化。这种新视角（也称为数据控制）旨在激励AI工程利用现有的安全分析和保障方法，以跨学科方式推动数据控制范式。通过自上而下的方法，本文在抽象层面概述了安全分析和保障的通用基础，可针对具体AI系统和应用进行细化，并为未来的创新做好准备。

</details>


### [338] [Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments](https://arxiv.org/abs/2506.23706)
**中文标题：可验证审计：基于可信执行环境的AI安全基准测试**

*Christoph Schnabl,Daniel Hugenroth,Bill Marino,Alastair R. Beresford*

主要分类: cs.AI

摘要简述: 本文提出了一种名为‘可验证审计’的方法，利用可信执行环境（TEE）确保AI模型的安全性和合规性，同时保护模型和数据的机密性。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI安全基准测试缺乏可验证性和数据保密性，无法满足模型提供方和审计方之间的互不信任需求。本文旨在解决这一问题。

研究方法: 通过可信执行环境（TEE）运行审计流程，确保交互过程可验证且数据保密，即使模型提供方和审计方互不信任。

研究结果: 原型实验证明该方法在典型审计基准测试（如Llama-3.1）中可行，能够有效保护敏感数据并验证合规性。

研究结论: ‘可验证审计’为AI治理框架中的验证挑战提供了可行解决方案，同时兼顾数据保密性和可验证性。

中文摘要: 基准测试是评估AI模型安全性和合规性的重要手段，但通常无法提供可验证的结果，且缺乏对模型知识产权和基准数据集的保密性。我们提出‘可验证审计’，该方法在可信执行环境中运行，使用户能够验证与合规AI模型的交互。我们的工作保护了敏感数据，即使模型提供方和审计方互不信任。这解决了近期AI治理框架中提出的验证挑战。我们构建了一个原型，证明其在典型审计基准测试（如Llama-3.1）中的可行性。

</details>


### [339] [BayesL: Towards a Logical Framework for Bayesian Networks](https://arxiv.org/abs/2506.23773)
**中文标题：BayesL：面向贝叶斯网络的逻辑框架**

*Stefano M. Nicoletti,Mariëlle Stoelinga*

主要分类: cs.AI

摘要简述: 本文提出了一种名为BayesL的新型逻辑框架，用于规范、查询和验证贝叶斯网络的行为。BayesL支持灵活的因果和证据关系推理，并允许全面的假设场景评估。


<details>
  <summary>详细信息</summary>
研究动机: 现有的贝叶斯网络工具在查询和验证行为时缺乏灵活性和结构化语言支持，BayesL旨在填补这一空白，提供更高效的推理和场景评估能力。

研究方法: BayesL是一种结构化语言，支持在贝叶斯网络上创建查询，无需手动修改模型即可进行因果和证据关系的推理及假设场景评估。

研究结果: BayesL成功实现了对贝叶斯网络的高效查询和验证，支持复杂的因果推理和假设分析，显著提升了模型的灵活性和实用性。

研究结论: BayesL为贝叶斯网络提供了一种强大的逻辑框架，简化了查询和验证过程，为因果推理和假设分析提供了新的工具。

中文摘要: 我们介绍了BayesL，一种用于规范、查询和验证贝叶斯网络（BNs）行为的新型逻辑框架。BayesL（发音为“Basil”）是一种结构化语言，允许在BNs上创建查询。它支持关于因果和证据关系的多样化推理，并允许全面的假设场景评估，而无需手动修改模型。

</details>


### [340] [When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)](https://arxiv.org/abs/2506.23784)
**中文标题：当GNN遇上词方程求解器：学习排序方程（扩展技术报告）**

*Parosh Aziz Abdulla,Mohamed Faouzi Atig,Julie Cailler,Chencheng Liang,Philipp Rümmer*

主要分类: cs.AI

摘要简述: 本文探索了使用图神经网络（GNN）对词方程进行排序以优化求解过程，提出了一种新的图表示方法，并通过实验验证了其优于现有求解器的性能。


<details>
  <summary>详细信息</summary>
研究动机: 在解决词方程时，方程的处理顺序对求解性能有显著影响。传统方法缺乏全局视角，因此本文旨在利用GNN的全局信息处理能力，优化方程排序以提高求解效率。

研究方法: 提出了一种新的图表示方法，保留词方程之间的全局信息；设计了三种多分类任务方法以适应方程数量的变化；利用最小不可满足子集（MUSes）训练GNN。

研究结果: 实验结果表明，在变量在每个方程中最多出现一次的基准测试中，新框架比现有字符串求解器解决了更多问题。

研究结论: 通过结合GNN和词方程求解器，本文展示了全局信息处理在优化求解顺序中的有效性，为词方程求解提供了新思路。

中文摘要: 尼尔森变换是解决词方程的标准方法：通过反复拆分方程并应用简化步骤，方程被重写直至找到解。在解决词方程联立时，求解器的性能很大程度上取决于方程的处理顺序。本文探索了使用图神经网络（GNN）在求解过程中对词方程进行排序的方法。为此，提出了一种新的基于图的词方程表示方法，保留了联立方程间的全局信息，使GNN在排序时具备整体视角。针对变量数量的变化，提出了三种将多分类任务适配到方程排序问题的方法。GNN的训练借助了词方程的最小不可满足子集（MUSes）。实验结果表明，在变量在每个方程中最多出现一次的基准测试中，新框架比现有字符串求解器解决了更多问题。

</details>


### [341] [Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning](https://arxiv.org/abs/2506.23793)
**中文标题：基于主动微调的可学习多智能体路径规划求解器**

*Anton Andreychuk,Konstantin Yakovlev,Aleksandr Panov,Alexey Skrynnik*

主要分类: cs.AI

摘要简述: 本文提出了一种名为MAPF-GPT-DDG的新型多智能体路径规划（MAPF）求解器，通过主动微调和创新的delta-data生成机制，显著提升了性能与可扩展性，支持百万级智能体的路径规划。


<details>
  <summary>详细信息</summary>
研究动机: 多智能体路径规划（MAPF）在物流、搜救等领域具有重要应用，但现有学习型求解器在性能与可扩展性上仍有不足。本文旨在通过改进预训练模型和引入新机制，提升求解器的效率和适应性。

研究方法: 本文提出MAPF-GPT-DDG，基于预训练的MAPF-GPT模型，利用集中式专家数据进行主动微调，并引入delta-data生成机制以加速训练和提升测试性能。

研究结果: 实验表明，MAPF-GPT-DDG在多种测试场景中优于现有学习型MAPF求解器，包括原始MAPF-GPT，并能处理单环境中百万级智能体的路径规划问题。

研究结论: MAPF-GPT-DDG通过主动微调和delta-data生成机制，显著提升了MAPF求解器的性能和可扩展性，为实际应用提供了新的解决方案。

中文摘要: 多智能体路径规划（MAPF）是多机器人轨迹规划问题的常见抽象，其中多个同质机器人在共享环境中同时移动。尽管最优求解MAPF已被证明是NP难问题，但可扩展且高效的求解器对物流、搜救等实际应用至关重要。为此，基于机器学习的分散式次优MAPF求解器应运而生。基于近期提出的纯模仿学习求解器MAPF-GPT的成功，我们引入了MAPF-GPT-DDG。这一新方法通过集中式专家数据有效微调预训练的MAPF模型，并利用创新的delta-data生成机制加速训练，同时在测试时显著提升性能。实验表明，MAPF-GPT-DDG在多种测试场景中的解决方案质量超越了所有现有学习型MAPF求解器，包括原始MAPF-GPT。值得注意的是，它能够处理单环境中涉及多达100万智能体的MAPF实例，为MAPF领域的可扩展性树立了新的里程碑。

</details>


### [342] [A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents](https://arxiv.org/abs/2506.23844)
**中文标题：基于大型模型的自主代理引发的安全风险综述**

*Hang Su,Jun Luo,Chang Liu,Xiao Yang,Yichi Zhang,Yinpeng Dong,Jun Zhu*

主要分类: cs.AI

摘要简述: 本文综述了基于大型模型的自主AI代理在动态开放环境中可能引发的安全风险，如记忆污染、工具滥用等，并提出了一种名为R2A2的认知框架以应对这些风险。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）的发展，自主AI代理的功能范围显著扩展，但也带来了传统系统或独立LLMs所未有的新型安全风险。本文旨在探讨这些风险及其应对策略。

研究方法: 首先分析了代理自主性的结构基础和关键能力（如长期记忆、模块化工具使用等），然后识别了代理堆栈中的安全漏洞，并提出了防御策略，最终引入R2A2框架。

研究结果: 研究发现，代理的感知、认知、记忆和行动模块中存在架构脆弱性，导致如延迟决策风险、工具链不可逆等问题。R2A2框架通过风险感知建模和联合奖励-风险优化提供了解决方案。

研究结论: 本文强调了自主AI代理的安全挑战，并提出R2A2框架作为系统性解决方案，为未来研究提供了方向。

中文摘要: 近年来，大型语言模型（LLMs）的进步推动了自主AI代理的发展，这些代理能够在动态、开放的环境中感知、推理和行动。这些基于大型模型的代理标志着从静态推理系统到交互式、记忆增强实体的范式转变。尽管这些能力显著扩展了AI的功能范围，但也引入了传统系统或独立LLMs所未有的新型安全风险，如记忆污染、工具滥用、奖励篡改和突发性错位等。在本综述中，我们首先研究了支撑代理自主性提升的结构基础和关键能力，包括长期记忆保留、模块化工具使用、递归规划和反思推理。接着，我们分析了代理堆栈中相应的安全漏洞，识别了如延迟决策风险、不可逆工具链以及由内部状态漂移或价值错位引发的欺骗行为等失效模式。这些风险源于感知、认知、记忆和行动模块中出现的架构脆弱性。为应对这些挑战，我们系统性地回顾了最近在不同自主层级部署的防御策略，包括输入净化、记忆生命周期控制、受限决策、结构化工具调用和内省反思。我们提出了基于约束马尔可夫决策过程（CMDPs）的统一认知框架——反思性风险感知代理架构（R2A2），该框架通过风险感知世界建模、元策略适应和联合奖励-风险优化，为代理的决策循环提供了原则性和主动性的安全保障。

</details>


### [343] [Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence](https://arxiv.org/abs/2506.23908)
**中文标题：超越统计学习：精确学习对通用智能至关重要**

*András György,Tor Lattimore,Nevena Lazić,Csaba Szepesvári*

主要分类: cs.AI

摘要简述: 本文认为当前基于统计学习的AI系统在演绎推理任务上表现不佳，无法实现真正的通用人工智能。作者提出，必须转向精确学习范式，以确保在所有输入上的正确性，这是实现可靠演绎推理的关键。


<details>
  <summary>详细信息</summary>
研究动机: 尽管AI系统在数学和科学等领域取得了显著进展，但即使在最先进的系统中，演绎推理任务的表现仍然不稳定。这表明统计学习方法无法满足通用人工智能的需求，因此需要探索更可靠的学习范式。

研究方法: 作者提出从统计学习转向精确学习范式，强调在所有输入上确保正确性，而非仅仅优化统计性能。这一方法旨在从根本上解决当前AI系统在演绎推理中的不足。

研究结果: 通过分析，作者指出精确学习是实现可靠演绎推理的必要条件，并认为这一目标在算法设计上是可行的。

研究结论: 精确学习是实现通用人工智能中可靠演绎推理的关键，研究人员应将其作为算法设计的核心目标。

中文摘要: 可靠的演绎推理——从现有事实和规则中推导新知识的能力——无疑是通用智能的理想特性。尽管AI系统在数学和科学等领域取得了重大进展，尤其是自Transformer架构引入以来，但众所周知，即使是最先进的系统在简单可解的演绎推理任务上也经常表现不佳。因此，这些系统无法实现具备可靠演绎推理能力的人工通用智能梦想。我们认为，这种不可靠的行为是推动其发展的统计学习方法的后果。为了克服这一问题，我们主张，要在基于学习的AI系统中实现可靠的演绎推理，研究人员必须从根本上从优化统计性能转向更雄心勃勃的精确学习范式，该范式要求在所有输入上确保正确性。我们认为精确学习既是必要的也是可能的，这一雄心勃勃的目标应指导算法设计。

</details>


### [344] [Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice](https://arxiv.org/abs/2506.23924)
**中文标题：大语言模型在随机建模运筹学问题中的表现：从理论到实践**

*Akshit Kumar,Tianyi Peng,Yuhang Wu,Assaf Zeevi*

主要分类: cs.AI

摘要简述: 本文评估了大语言模型（LLMs）在解决运筹学（OR）中随机建模问题的能力，发现其表现接近人类专家水平，但仍需进一步研究以实现可靠自动化。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在多个领域展现出专家级能力，但其在运筹学中解决随机建模问题的能力尚未充分探索。本文旨在填补这一空白，评估LLMs在理论和实践中的表现。

研究方法: 研究通过手动收集研究生课程作业和博士资格考试题目，测试LLMs解决随机建模问题的能力，并利用开源库SimOpt评估其在不确定性下做出实际决策的能力。

研究结果: 结果显示，尽管仍需大量工作以实现随机建模流程的可靠自动化，但最先进的LLMs在课堂和实际场景中表现与人类专家相当。

研究结论: 研究表明LLMs具备辅助运筹学研究的潜力，可通过自动化提升OR的实际影响力。

中文摘要: 大语言模型（LLMs）在多个领域展现出专家级能力，但其在运筹学（OR）中解决问题的能力——即从现实问题或其语言描述中分析和优化数学模型——仍未被充分探索。本文首次评估了LLMs解决随机建模问题的能力，这是OR的核心问题类别，涉及不确定性并通常需要概率、统计和随机过程工具。我们手动收集了一组代表性的研究生课程作业和博士资格考试题目，测试LLMs的解题能力，并利用开源库SimOpt研究LLMs在不确定性下做出实际决策的能力。结果表明，尽管仍需大量工作以实现随机建模流程的可靠自动化，但最先进的LLMs在课堂和实际场景中表现与人类专家相当。这些发现凸显了构建辅助OR研究的AI代理的潜力，并通过自动化提升OR的实际影响力。

</details>


### [345] [Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system](https://arxiv.org/abs/2506.23926)
**中文标题：工业大脑：一种类人自主神经符号认知决策系统**

*Junping Wang,Bicheng Wang,Yibo Xuea,Yuan Xie*

主要分类: cs.AI

摘要简述: 本文提出了一种名为“工业大脑”的人机协同认知决策系统，通过结合高阶神经驱动网络和符号推理技术，直接从观测数据中预测和规划工业链的韧性，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 工业链的韧性测量在科学管理和工程应用中至关重要，但现有深度学习方法难以应对复杂多变的时空共演结构。本文旨在填补这一技术空白。

研究方法: 提出“工业大脑”框架，整合高阶活动驱动神经网络和CT-OODA符号推理，直接从全局变量观测数据中自主规划韧性，无需简化假设。

研究结果: 实验表明，“工业大脑”在韧性预测和规划上显著优于GoT、OlaGPT和谱降维方法，准确率提升高达10.8%和11.03%，且对未见拓扑和动态数据具有强泛化能力。

研究结论: “工业大脑”解决了工业链韧性预测和规划的重要技术缺口，展示了其在复杂网络中的强大应用潜力。

中文摘要: 韧性非平衡测量（即在故障和错误中保持基本功能的能力）对工业链的科学管理和工程应用至关重要。当多重共演韧性的数量或类型（例如随机分布）极为混乱时，这一问题尤为复杂。现有的端到端深度学习方法通常难以泛化到未见时空共演结构的全场重建，并预测网络拓扑的韧性，尤其是在现实应用中常见的多重混乱数据场景中。为解决这一挑战，本文提出“工业大脑”，一种类人自主认知决策和规划框架，结合高阶活动驱动神经网络和CT-OODA符号推理，直接从全局变量的观测数据中自主规划韧性。工业大脑不仅能理解和建模节点活动动态及网络共演拓扑的结构（无需简化假设），揭示复杂网络背后的潜在规律，还能实现准确的韧性预测、推理和规划。实验结果表明，工业大脑在韧性预测和规划上显著优于GoT和OlaGPT框架（准确率提升高达10.8%）以及谱降维方法（提升11.03%）。此外，它对未见拓扑和动态数据具有泛化能力，并在观测干扰下保持稳健性能。我们的研究表明，工业大脑填补了工业链韧性预测和规划的重要技术缺口。

</details>


### [346] [AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models](https://arxiv.org/abs/2506.23949)
**中文标题：通用人工智能（GPAI）与基础模型的风险管理标准概要**

*Anthony M. Barrett,Jessica Newman,Brandie Nonnecke,Nada Madkour,Dan Hendrycks,Evan R. Murphy,Krystal Jackson,Deepika Raman*

主要分类: cs.AI

摘要简述: 本文为通用人工智能（GPAI）和基础模型提供了风险管理实践指南，旨在帮助开发者识别、分析和减轻相关风险，同时促进与现有AI风险管理标准的对接。


<details>
  <summary>详细信息</summary>
研究动机: 随着多用途AI模型（如大型语言模型）的普及，其带来的潜在风险日益凸显。本文旨在为开发者提供针对GPAI和基础模型的专门风险管理指南，以应对这些独特挑战。

研究方法: 本文基于NIST AI风险管理框架和ISO/IEC 23894等标准，结合GPAI和基础模型的特点，提出了一套风险管理的实践方法和控制措施。

研究结果: 文档为开发者提供了具体的风险管理工具和指南，帮助其更好地应对GPAI和基础模型可能带来的负面影响。

研究结论: 本文为GPAI和基础模型的风险管理提供了实用框架，有助于开发者在创新与安全之间取得平衡。

中文摘要: 日益多功能的AI模型，如前沿的大型语言模型或其他“通用人工智能”（GPAI）模型、“基础模型”、生成式AI模型以及“前沿模型”（以下统称为“GPAI/基础模型”），既能提供诸多有益能力，也可能引发具有深远影响的负面事件。本文档提供了识别、分析和减轻GPAI/基础模型风险的管理实践或控制措施。本文件主要面向大规模、最先进的GPAI/基础模型开发者；其他受益者包括基于GPAI/基础模型开发终端应用的下游开发者。本文档旨在促进与领先的AI风险管理相关标准的对接，借鉴并扩展了NIST AI风险管理框架和ISO/IEC 23894中的通用自愿性指南，重点关注GPAI/基础模型开发者面临的独特问题。

</details>


### [347] [Harnessing AI Agents to Advance Research on Refugee Child Mental Health](https://arxiv.org/abs/2506.23992)
**中文标题：利用AI代理推进难民儿童心理健康研究**

*Aditya Shrivastava,Komal Gupta,Shraddha Arora*

主要分类: cs.AI

摘要简述: 本研究提出了一种基于AI的框架，用于处理难民儿童心理健康数据，比较了两种检索增强生成（RAG）模型（Zephyr-7B-beta和DeepSeek R1-7B），发现DeepSeek R1在答案相关性上表现更优（准确率0.91）。


<details>
  <summary>详细信息</summary>
研究动机: 国际难民危机加剧，数百万儿童面临严重的心理创伤。本研究旨在利用AI技术处理难民健康数据，为政策制定者、心理健康从业者和人道主义机构提供可扩展的解决方案，以更好地帮助这些儿童并关注其心理健康。

研究方法: 研究比较了两种检索增强生成（RAG）模型（Zephyr-7B-beta和DeepSeek R1-7B），评估它们在处理复杂人道主义数据集时的表现，并避免幻觉风险。结合了前沿AI技术、移民研究和儿童心理学。

研究结果: 两种模型均表现良好，但DeepSeek R1在答案相关性上显著优于Zephyr-7B-beta，准确率达到0.91。

研究结论: 本研究展示了AI技术在难民儿童心理健康研究中的潜力，为相关领域的决策和实践提供了技术支持。

中文摘要: 国际难民危机加剧，数百万流离失所的儿童面临极端的心理创伤。本研究提出了一种紧凑的、基于AI的框架，用于处理非结构化的难民健康数据，并提炼关于儿童心理健康的知识。我们比较了两种检索增强生成（RAG）流程（Zephyr-7B-beta和DeepSeek R1-7B），以评估它们在处理具有挑战性的人道主义数据集时的表现，同时避免幻觉风险。通过将前沿AI方法与移民研究和儿童心理学相结合，本研究提出了一种可扩展的策略，以帮助政策制定者、心理健康从业者和人道主义机构更好地援助流离失所的儿童并关注其心理健康。总体而言，两种模型均表现良好，但DeepSeek R1在答案相关性上显著优于Zephyr，准确率达到0.91。

</details>


### [348] [Constructing Non-Markovian Decision Process via History Aggregator](https://arxiv.org/abs/2506.24026)
**中文标题：通过历史聚合器构建非马尔可夫决策过程**

*Yongyi Wang,Wenxin Li*

主要分类: cs.AI

摘要简述: 本文提出了一种基于范畴论的方法，通过历史状态聚合器（HAS）构建非马尔可夫决策过程（NMDP），并证明了其与马尔可夫决策过程（MDP）的等价性，为理解和处理非马尔可夫动态提供了新视角。


<details>
  <summary>详细信息</summary>
研究动机: 当前决策算法在非马尔可夫动态下的评估存在不足，缺乏全面衡量其能力的基准。本文旨在填补这一空白，提供一种理论框架和方法，以更严谨和灵活地评估决策算法。

研究方法: 基于范畴论，构建了MDP和NMDP的范畴，并证明其等价性；引入历史状态聚合器（HAS），通过精确控制状态依赖结构，将非马尔可夫性引入决策问题。

研究结果: 研究表明，HAS能有效表示广泛的非马尔可夫动态，为决策算法在明确构建的非马尔可夫问题中的评估提供了更严谨和灵活的方法。

研究结论: 本文提出的方法为理解和处理非马尔可夫动态提供了理论基础和实用工具，有助于提升决策算法的评估效果。

中文摘要: 在算法决策领域，非马尔可夫动态是一个重要障碍，尤其对强化学习（RL）等范式产生深远影响，进而制约相关系统的进步和效率。然而，现有基准未能全面评估决策算法处理非马尔可夫动态的能力。为解决这一问题，我们提出了一种基于范畴论的通用方法。具体而言，我们建立了马尔可夫决策过程（MDP）和非马尔可夫决策过程（NMDP）的范畴，并证明了两者的等价关系。这一理论为理解和处理非马尔可夫动态提供了新视角。我们进一步通过历史状态聚合器（HAS）将非马尔可夫性引入决策问题设置中。HAS能够精确控制决策问题在时间序列中的状态依赖结构。分析表明，我们的方法能有效表示广泛的非马尔可夫动态。这一方法通过在明确构建的非马尔可夫问题中测试决策算法，实现了更严谨和灵活的评估。

</details>


### [349] [SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2506.24119)
**中文标题：SPIRAL：通过多智能体多轮强化学习在零和游戏中的自我对弈激励推理能力**

*Bo Liu,Leon Guertler,Simon Yu,Zichen Liu,Penghui Qi,Daniel Balcells,Mickel Liu,Cheston Tan,Weiyan Shi,Min Lin,Wee Sun Lee,Natasha Jaques*

主要分类: cs.AI

摘要简述: SPIRAL是一种通过多智能体多轮强化学习自我对弈的框架，利用零和游戏激励模型发展推理能力，无需人工监督。实验表明，该方法显著提升了数学和通用推理能力，并通过多游戏训练进一步增强性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有强化学习方法依赖人工标注的问题-答案对和领域特定的奖励设计，限制了模型的自主推理能力发展。SPIRAL旨在通过自我对弈框架，消除对人工监督的依赖，自动生成逐步挑战性的任务，推动模型推理能力的提升。

研究方法: SPIRAL采用多智能体多轮强化学习框架，模型通过自我对弈零和游戏不断改进。提出角色条件优势估计（RAE）以稳定多智能体训练，并实现完全在线的训练系统。

研究结果: 在Kuhn Poker上训练的模型在数学和通用推理任务中分别提升8.6%和8.4%，优于基于25,000条专家轨迹的监督微调。多游戏训练进一步提升了性能，且对强推理模型仍能带来2.0%的平均提升。

研究结论: 零和游戏自然培养了可迁移的推理能力，为自主推理发展提供了新方向。SPIRAL框架展示了自我对弈在提升模型推理能力方面的潜力。

中文摘要: 近期强化学习的进展表明，语言模型可以通过在可验证奖励的任务上训练发展复杂推理能力，但这些方法依赖于人工标注的问题-答案对和领域特定的奖励设计。我们提出了SPIRAL，一种自我对弈框架，模型通过多轮零和游戏与不断改进的自身版本对弈学习，无需人工监督。通过自我对弈，SPIRAL生成了无限逐步挑战性的任务，因为模型必须不断适应更强的对手。为实现大规模自我对弈训练，我们实现了一个完全在线的多轮多智能体强化学习系统，并提出角色条件优势估计（RAE）以稳定多智能体训练。使用SPIRAL，零和游戏的自我对弈产生了广泛可迁移的推理能力。仅在Kuhn Poker上训练Qwen3-4B-Base，数学和通用推理能力分别提升了8.6%和8.4%，优于基于25,000条专家轨迹的监督微调。分析表明，这种迁移通过三种认知模式实现：系统分解、期望值计算和逐案例分析。多游戏训练（井字棋、Kuhn Poker、简单谈判）进一步提升了性能，因为每种游戏培养了不同的推理优势。将SPIRAL应用于强推理模型（DeepSeek-R1-Distill-Qwen-7B）仍能带来2.0%的平均提升。这些结果表明，零和游戏自然培养了可迁移的推理能力，为自主推理发展指明了有前景的方向。

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [350] [Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate](https://arxiv.org/abs/2506.22479)
**中文标题：后视引导动量（HGM）优化器：一种自适应学习率方法**

*Krisanu Sarkar*

主要分类: math.OC

摘要简述: HGM（后视引导动量）优化器通过评估梯度方向一致性自适应调整学习率，提升优化器在非凸问题（如深度学习）中的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统自适应优化器（如Adam、RMSprop）仅依赖梯度幅值调整学习率，忽略了梯度方向的一致性信息。HGM旨在通过引入后视机制，利用梯度方向的一致性优化学习率调整策略。

研究方法: HGM通过计算当前梯度与累积动量的余弦相似度，评估梯度方向的一致性。若方向一致则增加学习率，若方向冲突则降低学习率，从而在平滑区域加速收敛，在噪声区域保持稳定。

研究结果: HGM在非凸优化问题（如深度神经网络训练）中表现优异，能够更快收敛且保持稳定性，同时计算和内存效率与传统优化器相当。

研究结论: HGM通过智能响应优化路径的结构，提供了一种简单有效的改进方法，特别适用于深度学习等非凸场景。

中文摘要: 我们提出了后视引导动量（HGM）优化器，这是一种基于近期更新方向一致性自适应调整学习率的一阶优化算法。传统自适应方法（如Adam或RMSprop）仅依赖梯度幅值调整学习动态，常忽略重要的几何信息（如梯度方向与历史更新的对齐情况）。HGM通过引入后视机制，评估当前梯度与累积动量的余弦相似度，从而区分一致与冲突的梯度方向：在方向一致时增加学习率，在振荡或噪声区域降低学习率。这使得HGM在损失函数平滑区域加速收敛，同时在尖锐或不稳定区域保持稳定性。尽管增加了适应性，HGM仍保持了现有优化器的计算和内存效率。通过更智能地响应优化路径的结构，HGM为现有方法提供了一种简单而有效的改进，特别适用于深度神经网络训练等非凸场景。

</details>


### [351] [Correlated Mutations for Integer Programming](https://arxiv.org/abs/2506.22526)
**中文标题：整数规划的相关性变异**

*Ofer M. Shir,Michael Emmerich*

主要分类: math.OC

摘要简述: 本文为整数规划（IP）提出了一种基于离散搜索的整数进化策略（IES），通过采用ℓ₁-范数、调整步长并探索整数格上的相关性度量，重点研究了无界整数决策变量的变异分布。研究发现，双几何分布（DG）在理论和实践中均优于截断正态分布（TN），且ℓ₁-范数的使用是关键改进。


<details>
  <summary>详细信息</summary>
研究动机: 尽管整数规划（IP）的理论研究取得了进展，但启发式方法仍是解决此类问题的首选。本文旨在为整数进化策略（IES）奠定基础，通过离散化搜索空间和优化变异分布，提升其在IP中的表现。

研究方法: 研究采用ℓ₁-范数替代传统的ℓ₂-范数，并探索了无界整数决策变量的变异分布，包括均匀分布、二项分布、截断正态分布（TN）和双几何分布（DG）。通过理论分析和数值模拟，比较了这些分布的性能。

研究结果: 数值模拟表明，双几何分布（DG）在无界整数搜索中表现更优，且基于DG的IES在非可分离二次IP问题中显著优于其他策略。理论分析支持DG取代TN的合理性。

研究结论: 研究表明，双几何分布（DG）在理论和实践中均优于截断正态分布（TN），但真正的关键改进在于采用ℓ₁-范数而非ℓ₂-范数。

中文摘要: 尽管整数规划（IP）的理论进展显著降低了其复杂性，启发式方法仍是解决此类问题的主要手段。本研究旨在为整数进化策略（IES）奠定基础，这类随机搜索启发式方法原本设计用于连续空间。IES在实践中已表现出色，但需通过离散化和对连续算子的复杂修补来实现，同时始终以ℓ₂-范数为操作核心。我们通过采用ℓ₁-范数、调整步长并探索整数格上的相关性度量，为离散搜索奠定基础。我们重点研究了无界整数决策变量的变异分布，简要讨论了由均匀分布和二项分布诱导的离散概率，发现其理论性质较差，随后聚焦于截断正态（TN）和双几何（DG）分布。我们探讨了它们的理论性质（包括熵函数），并提出了一种生成可扩展相关性变异分布的方法。数值模拟一致支持DG分布更适合无界整数搜索的观点。理论视角与实证证据表明，基于相关性DG变异的IES在非可分离二次IP中表现更优。我们得出结论：尽管用DG替代默认的TN分布在理论和实践上均有优势，但真正的关键改进在于采用ℓ₁-范数而非ℓ₂-范数。

</details>


### [352] [Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions](https://arxiv.org/abs/2506.22568)
**中文标题：最大分散与最大集中：提升多目标优化解的质量**

*Gladston Moreira,Ivan Meneghini,Elzabeth Wanner*

主要分类: math.OC

摘要简述: 本研究提出了一种通过优化决策空间的分散性和目标空间的收敛性来提升多目标优化问题（MOP）解质量的方法，旨在平衡解的多样性和收敛性。


<details>
  <summary>详细信息</summary>
研究动机: 多目标优化问题（MOP）需要在目标空间中平衡多样性和收敛性。传统方法可能导致解在决策空间中聚集，产生偏差。本研究旨在通过优化解的分散性和收敛性，提升解的质量并避免偏差。

研究方法: 研究提出了一种方法，通过在目标空间中定义基于决策者偏好的兴趣区域（ROI），并结合决策空间中的均匀性度量来增强解的分散性。这种方法将目标空间的解集中与决策空间的解分散相结合，以强化对帕累托最优解的搜索。

研究结果: 初步实验表明，该方法能够生成平衡分散性和集中性的解，有效提升多目标优化的质量，并减少决策空间中的偏差。

研究结论: 通过结合目标空间的解集中和决策空间的解分散，本研究的方法显著提升了多目标优化解的质量，同时避免了传统方法中可能出现的偏差问题。

中文摘要: 多目标优化问题（MOP）通常需要在目标空间中平衡多样性和收敛性。本研究提出了一种方法，通过优化决策空间的分散性和目标空间特定区域的收敛性来提升解的质量。我们的方法基于目标空间中代表决策者偏好的锥形区域定义了一个兴趣区域（ROI），同时使用均匀性度量增强决策空间中解的分散性。将目标空间的解集中与决策空间的解分散相结合，强化了对帕累托最优解的搜索，同时增加了解的多样性。这些特性的结合提升了解的质量，并避免了决策空间中特定区域解聚集导致的偏差。初步实验表明，该方法通过生成平衡分散性和集中性的解，有效提升了多目标优化的效果，从而减少了决策空间中的偏差。

</details>


### [353] [Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations](https://arxiv.org/abs/2506.22826)
**中文标题：通过松弛正则化对多色QR码和Stiefel值数据进行去噪**

*Robert Beinert,Jonas Bresch*

主要分类: math.OC

摘要简述: 本文提出了一种新的去噪方法，针对多二进制和Stiefel值数据，通过松弛正则化技术实现高效去噪，适用于多色QR码和图像识别任务。


<details>
  <summary>详细信息</summary>
研究动机: 处理流形值数据在颜色恢复、旋转方向信息研究和高斯图像处理中至关重要。现有方法虽有效，但针对多二进制和Stiefel值数据的去噪仍需改进。本文旨在扩展现有技术，解决这些新数据类型的问题。

研究方法: 通过将数据嵌入欧几里得环境空间，将非凸流形编码为半正定固定秩矩阵，并松弛秩约束以实现凸化。针对多二进制和Stiefel值数据，提出了基于TV和Tikhonov的去噪模型及其易求解的凸化方法。

研究结果: 在概念验证和合成实验中，所有提出的方法均表现良好，验证了其在多色QR码和图像识别任务中的有效性。

研究结论: 本文成功扩展了松弛正则化方法，适用于多二进制和Stiefel值数据，为相关领域的去噪问题提供了高效解决方案。

中文摘要: 处理流形值数据在颜色恢复任务（如基于圆或球值颜色模型）、特殊正交群相关的旋转或方向信息研究以及高斯图像处理（像素统计解释为双曲面上的值）中起着核心作用。特别是为了去噪这类数据，已有多种基于总变分（TV）和Tikhonov型去噪模型的推广方法，这些方法结合了底层流形。最近，一种新颖且数值高效的去噪方法被提出，该方法将数据嵌入欧几里得环境空间，通过一系列半正定固定秩矩阵编码非凸流形，并松弛秩约束以实现凸化，从而可使用凸分析中的标准算法求解。本文旨在将这一方法扩展到多二进制和Stiefel值数据等新数据类型。多二进制数据可用于建模多色QR码，而Stiefel值数据则出现在基于图像和视频的识别任务中。针对这两种新数据类型，我们提出了基于TV和Tikhonov的去噪模型及其易求解的凸化方法。所有推导方法均在概念验证和合成实验中得到评估。

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [354] [Learning Truthful Mechanisms without Discretization](https://arxiv.org/abs/2506.22911)
**中文标题：无需离散化的真实机制学习**

*Yunxuan Ma,Siqiang Wang,Zhijian Duan,Yukun Cheng,Xiaotie Deng*

主要分类: cs.GT

摘要简述: 本文提出了一种无需离散化的算法TEDI，用于学习真实且效用最大化的机制，解决了现有方法因离散化导致效率低下的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于学习的方法通常依赖结果空间的离散化来确保真实性，但随着问题规模的增加，这种方法效率低下。本文旨在解决这一局限性。

研究方法: 通过形式化定价规则的概念，提出了一种新的菜单机制，并利用Partial GroupMax Network参数化定价规则。采用协方差技巧和连续采样等训练技术学习最优定价规则。

研究结果: 理论分析表明TEDI保证了真实性、完全表达性和维度不敏感性。实验证明其在拍卖设定中表现优异，与或超越现有方法。

研究结论: TEDI是首个无需结果离散化的真实机制学习方法，提升了算法效率，为自动化机制设计和可微分经济学提供了新思路。

中文摘要: 本文介绍了TEDI（真实、表达且维度不敏感的方法），一种无需离散化的算法，用于学习真实且效用最大化的机制。现有基于学习的方法通常依赖结果空间的离散化来确保真实性，但随着问题规模的增加，这种方法效率低下。为解决这一局限性，我们形式化了定价规则的概念，定义为将结果映射到价格的函数。基于此概念，我们提出了一种新的菜单机制，在特定条件下可等价于真实的直接机制。TEDI的核心思想在于利用Partial GroupMax Network参数化定价规则，这是一种设计用于普遍逼近部分凸函数的新型网络架构。为学习最优定价规则，我们开发了包括协方差技巧和连续采样在内的新型训练技术，以推导与一阶优化兼容的无偏梯度估计器。理论分析表明TEDI保证了真实性、完全表达性和维度不敏感性。在拍卖设定中的实验评估表明，TEDI表现优异，与或超越现有方法。本文首次提出了无需结果离散化的真实机制学习方法，从而提升了算法效率。所提出的概念、网络架构和学习技术可能为自动化机制设计和可微分经济学提供潜在价值和新见解。

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [355] [Reachability in symmetric VASS](https://arxiv.org/abs/2506.23578)
**中文标题：对称VASS中的可达性问题**

*Łukasz Kamiński,Sławomir Lasota*

主要分类: cs.FL

摘要简述: 本文研究了对称向量加法系统（VASS）中的可达性问题，重点关注坐标排列群不变性下的过渡情况。通过分析不同群（如对称群、交替群和循环群）的影响，发现对称群的可达性问题可在PSPACE内解决，与一般VASS的Ackermann复杂度形成对比。


<details>
  <summary>详细信息</summary>
研究动机: 研究对称VASS的可达性问题，旨在探索群不变性对计算复杂度的影响，并为数据VASS的可达性问题提供理论支持。

研究方法: 通过分析不同群（如对称群、交替群和循环群）在VASS中的作用，比较其可达性问题的复杂度，并探讨群组合对复杂度的增益。

研究结果: 对称群下的VASS可达性问题可在PSPACE内解决，而一般VASS的复杂度为Ackermann级别。其他群（如交替群和循环群）的影响也被讨论。

研究结论: 对称性显著降低了VASS的可达性复杂度，为数据VASS的研究提供了新的理论视角。

中文摘要: 本文研究了对称向量加法系统（VASS）中的可达性问题，其中过渡在坐标排列群下保持不变。一种极端情况是平凡群，对应一般VASS；另一种极端情况是对称群，我们发现其可达性问题可在PSPACE内解决，与一般VASS的Ackermann复杂度形成对比。我们还研究了其他群（如交替群和循环群）的影响。此外，受数据VASS可达性问题开放状态的启发，我们评估了平凡群与对称群组合时复杂度的增益。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [356] [Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development](https://arxiv.org/abs/2506.22704)
**中文标题：超越代码：大型语言模型在软件开发中的多维影响**

*Sardar Fatooreh Bonabi,Sarah Bana,Tingting Nian,Vijay Gurbaxani*

主要分类: econ.GN

摘要简述: 大型语言模型（LLMs）显著提升开源软件开发者的生产力、知识共享和技能获取，效果因开发者经验水平而异，新手开发者生产力提升显著，而经验丰富的开发者更多受益于知识共享和技能加速获取。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在揭示大型语言模型（LLMs）如何通过代码开发、协作知识转移和技能发展影响开源软件（OSS）开发者，并量化其具体效果。

研究方法: 利用意大利临时禁止ChatGPT的自然实验，采用双重差分法（Difference-in-Differences）和双向固定效应模型，分析来自意大利、法国和葡萄牙的88,022名GitHub开发者的数据。

研究结果: 研究发现，使用ChatGPT使开发者生产力提升6.4%，知识共享增加9.6%，技能获取提高8.4%。效果因开发者经验水平不同：新手开发者生产力提升显著，经验丰富者更多受益于知识共享和技能获取。LLM辅助学习的效果高度依赖技术复杂性、碎片化或快速演进的场景。

研究结论: LLMs不仅通过直接代码生成提升生产力，还通过促进协作学习和知识交换对开源软件开发者产生多维影响。战略部署LLMs可加速新手开发者成长、增强中级开发者的协作能力，并支持快速技能获取，从而提升组织的长期生产力和敏捷性。

中文摘要: 大型语言模型（LLMs）将对软件开发产生深远影响，尤其是在开源软件（OSS）领域。为理解这种影响，我们首先概述了LLMs通过代码开发、协作知识转移和技能发展影响OSS的机制。随后，我们通过实证研究分析了LLMs对OSS开发者在这三个关键领域工作的影响。利用意大利临时禁止ChatGPT的自然实验，我们采用双重差分法（Difference-in-Differences）和双向固定效应模型，分析了来自意大利、法国和葡萄牙的88,022名GitHub开发者的数据。研究发现，使用ChatGPT使开发者生产力提升6.4%，知识共享增加9.6%，技能获取提高8.4%。这些效果因开发者经验水平而异：新手开发者主要受益于生产力提升，而经验丰富的开发者更多受益于知识共享和技能加速获取。此外，LLM辅助学习的效果高度依赖技术复杂性、碎片化或快速演进的场景。研究表明，LLMs的生产力效应不仅限于直接代码生成，还包括促进开发者之间的协作学习和知识交换；这些动态对于全面理解LLMs在OSS中的影响至关重要。我们的研究结果提供了重要的管理启示：战略部署LLMs可加速新手开发者的入职和生产力提升，赋能中级开发者促进知识共享和协作，并支持快速技能获取，从而共同提升组织的长期生产力和敏捷性。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [357] [ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes](https://arxiv.org/abs/2506.21629)
**中文标题：ICP-3DGS：面向大规模无边界场景的无SfM 3D高斯泼溅方法**

*Chenhao Zhang,Yezhi Shen,Fengqing Zhu*

主要分类: cs.GR

摘要简述: 本文提出ICP-3DGS方法，结合迭代最近点（ICP）和优化细化技术，解决了大规模无边界场景中相机姿态估计和3D高斯泼溅（3DGS）重建的难题，无需依赖SfM预处理。


<details>
  <summary>详细信息</summary>
研究动机: 现有神经渲染方法（如NeRFs和3DGS）依赖SfM预处理的相机姿态和3D结构先验，但在户外场景中难以获取。本文旨在解决这一问题，实现无SfM的大规模场景重建。

研究方法: 结合ICP和优化细化技术进行相机姿态估计，并提出基于体素的场景密集化方法，指导大规模场景的重建。

研究结果: 实验表明，ICP-3DGS在室内外不同尺度场景的相机姿态估计和新视角合成中均优于现有方法。

研究结论: ICP-3DGS为无SfM依赖的大规模场景重建提供了高效解决方案，显著提升了相机姿态估计和渲染质量。

中文摘要: 近年来，NeRFs和3D高斯泼溅（3DGS）等神经渲染方法在场景重建和新视角合成方面取得了显著进展。然而，这些方法严重依赖结构运动（SfM）预处理的相机姿态和3D结构先验，而这些在户外场景中难以获取。为解决这一问题，我们提出将迭代最近点（ICP）与优化细化技术结合，以实现大范围相机运动下的精确姿态估计。此外，我们引入了一种基于体素的场景密集化方法，以指导大规模场景的重建。实验表明，我们的方法ICP-3DGS在室内外不同尺度场景的相机姿态估计和新视角合成中均优于现有方法。源代码发布于https://github.com/Chenhao-Z/ICP-3DGS。

</details>


### [358] [VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding](https://arxiv.org/abs/2506.22799)
**中文标题：VoteSplat：基于Hough投票的高斯泼溅3D场景理解**

*Minchao Jiang,Shunyu Jia,Jiaming Gu,Xiaoyuan Lu,Guangming Zhu,Anqi Dong,Liang Zhang*

主要分类: cs.GR

摘要简述: VoteSplat是一种结合Hough投票与3D高斯泼溅的新框架，用于3D场景理解，通过实例分割和投票机制实现高效语义映射，降低了训练成本并提升了场景理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D高斯泼溅方法主要关注几何和外观建模，缺乏深入的场景理解，且训练成本高。VoteSplat旨在通过结合Hough投票和3D高斯泼溅，提升3D场景理解的效率与准确性。

研究方法: 利用Segment Anything Model (SAM)进行实例分割，提取对象并生成2D投票图；将空间偏移向量嵌入高斯基元，通过2D图像投票构建3D空间投票，同时利用深度失真约束优化深度定位。通过投票点将2D图像语义映射到3D点云，降低CLIP特征的训练成本。

研究结果: 实验表明，VoteSplat在开放词汇3D实例定位、3D点云理解、点击式3D对象定位、分层分割等方面表现优异，且训练成本显著降低。

研究结论: VoteSplat通过结合Hough投票与3D高斯泼溅，实现了高效的3D场景理解，为开放词汇对象定位和语义映射提供了新思路。

中文摘要: 3D高斯泼溅（3DGS）已成为高质量、实时渲染3D场景新视角合成的核心方法。然而，现有方法主要关注几何和外观建模，缺乏深入的场景理解，同时训练成本较高，影响了原本简洁的可微渲染流程。为此，我们提出VoteSplat，一种结合Hough投票与3DGS的新型3D场景理解框架。具体而言，利用Segment Anything Model (SAM)进行实例分割，提取对象并生成2D投票图；将空间偏移向量嵌入高斯基元，通过关联2D图像投票构建3D空间投票，同时利用深度失真约束优化深度定位。对于开放词汇对象定位，VoteSplat通过投票点将2D图像语义映射到3D点云，降低了高维CLIP特征的训练成本，同时保持了语义的明确性。大量实验表明，VoteSplat在开放词汇3D实例定位、3D点云理解、点击式3D对象定位、分层分割及消融研究中均表现出色。代码已开源：https://sy-ja.github.io/votesplat/。

</details>


### [359] [Confident Splatting: Confidence-Based Compression of 3D Gaussian Splatting via Learnable Beta Distributions](https://arxiv.org/abs/2506.22973)
**中文标题：基于置信度的高斯泼溅压缩：通过可学习Beta分布实现**

*AmirHossein Naghi Razlighi,Elaheh Badali Golezani,Shohreh Kasaei*

主要分类: cs.GR

摘要简述: 提出了一种基于可学习Beta分布的3D高斯泼溅压缩方法，通过优化置信度分数实现高效压缩，同时保持视觉保真度。


<details>
  <summary>详细信息</summary>
研究动机: 3D高斯泼溅技术虽然能实现高质量实时渲染，但生成的数百万泼溅点导致存储和计算开销过大，亟需一种高效的压缩方法。

研究方法: 利用可学习的Beta分布建模泼溅点的置信度分数，通过重建感知损失优化置信度，从而剪枝低置信度泼溅点，同时保持视觉质量。

研究结果: 实验表明，该方法在压缩率和保真度之间取得了优于现有工作的平衡，且置信度均值可作为场景质量评估的新指标。

研究结论: 提出的方法具有架构无关性，适用于任何高斯泼溅变体，为3D渲染的存储和计算优化提供了有效解决方案。

中文摘要: 3D高斯泼溅技术能够实现高质量的实时渲染，但通常生成数百万个泼溅点，导致存储和计算开销过大。我们提出了一种基于可学习置信度分数的新型有损压缩方法，该分数通过Beta分布建模。每个泼溅点的置信度通过重建感知损失进行优化，从而剪枝低置信度泼溅点，同时保持视觉保真度。该方法具有架构无关性，适用于任何高斯泼溅变体。此外，平均置信度值可作为评估场景质量的新指标。大量实验表明，与现有工作相比，该方法在压缩和保真度之间取得了更优的权衡。我们的代码和数据已公开在https://github.com/amirhossein-razlighi/Confident-Splatting。

</details>


### [360] [Navigating with Annealing Guidance Scale in Diffusion Space](https://arxiv.org/abs/2506.24108)
**中文标题：在扩散空间中基于退火引导尺度的导航**

*Shai Yehezkel,Omer Dahary,Andrey Voynov,Daniel Cohen-Or*

主要分类: cs.GR

摘要简述: 本文提出了一种动态调整去噪扩散模型中引导尺度的退火调度器，显著提升了文本到图像生成的质量和提示对齐性。


<details>
  <summary>详细信息</summary>
研究动机: 去噪扩散模型在文本提示条件下生成高质量图像方面表现优异，但其效果高度依赖于采样过程中的引导设置。现有的无分类器引导（CFG）机制通过固定引导尺度平衡图像质量和提示对齐，但这一选择对生成结果影响重大。本文旨在解决CFG的敏感性问题。

研究方法: 提出了一种退火引导调度器，根据条件噪声信号动态调整引导尺度。通过学习调度策略，该方法优化了CFG的行为，无需额外激活或内存消耗。

研究结果: 实验结果表明，该方法显著提升了图像质量和文本提示对齐性，优于传统固定引导尺度的CFG方法。

研究结论: 本文提出的退火引导调度器为文本到图像生成提供了一种高效且无缝的改进方案，优化了提示对齐与图像质量之间的权衡。

中文摘要: 去噪扩散模型在文本提示条件下生成高质量图像方面表现优异，但其效果高度依赖于采样过程中的引导设置。无分类器引导（CFG）通过设置引导尺度来平衡图像质量和提示对齐，是一种广泛使用的生成控制机制。然而，引导尺度的选择对生成视觉吸引力和提示一致性的图像具有关键影响。本文提出了一种退火引导调度器，根据条件噪声信号动态调整引导尺度。通过学习调度策略，我们的方法解决了CFG的敏感性问题。实验结果表明，该引导调度器显著提升了图像质量和文本提示对齐性，推动了文本到图像生成的性能。值得注意的是，我们的新型调度器无需额外激活或内存消耗，并可无缝替代常见的无分类器引导，提供了提示对齐与质量之间的更优权衡。

</details>


### [361] [GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering](https://arxiv.org/abs/2506.23957)
**中文标题：GaVS：基于3D基础的时间一致局部重建与渲染的视频稳定方法**

*Zinuo You,Stamatios Georgoulis,Anpei Chen,Siyu Tang,Dengxin Dai*

主要分类: cs.GR

摘要简述: 本文提出了一种名为GaVS的新型3D视频稳定方法，通过时间一致的局部重建与渲染范式解决现有方法的几何失真、过度裁剪等问题，显著提升了视频稳定效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频稳定方法存在几何失真、过度裁剪和泛化能力差等问题，影响用户体验。本文旨在通过3D基础的方法解决这些问题，提升视频稳定的质量和一致性。

研究方法: GaVS将视频稳定重新定义为时间一致的局部重建与渲染任务。基于3D相机位姿，通过高斯泼溅基元预测和测试时微调，结合多视角动态感知的光度监督和跨帧正则化，生成时间一致的局部重建结果，并利用场景外推模块避免裁剪。

研究结果: 实验表明，GaVS在传统任务指标和几何一致性上优于或与现有2D和2.5D方法相当，用户研究也验证了其显著优于其他方法的视觉效果。

研究结论: GaVS通过3D基础的时间一致局部重建与渲染，有效解决了视频稳定中的几何失真和裁剪问题，为视频处理提供了高质量的解决方案。

中文摘要: 视频稳定是视频处理中的关键步骤，旨在消除不必要的抖动同时保留用户的原始运动意图。现有方法因操作域不同而存在几何失真、过度裁剪和泛化能力差等问题，影响用户体验。为解决这些问题，我们提出了GaVS，一种基于3D基础的新方法，将视频稳定重新定义为时间一致的“局部重建与渲染”范式。给定3D相机位姿，我们通过增强重建模型预测高斯泼溅基元，并在测试时通过多视角动态感知的光度监督和跨帧正则化进行微调，生成时间一致的局部重建结果。随后利用该模型渲染每一帧稳定后的画面，并通过场景外推模块避免裁剪。我们在一个包含多样化相机运动和场景动态的3D基础数据集上评估了该方法。定量结果表明，GaVS在传统任务指标和几何一致性上优于或与现有2D和2.5D方法相当。定性分析及用户研究也验证了其显著优于其他方法的视觉效果。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [362] [TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations](https://arxiv.org/abs/2506.22818)
**中文标题：TriADA：用于加速3D离散变换的大规模并行三线性矩阵-张量乘加算法及设备架构**

*Stanislav Sedukhin,Yoichi Tomioka,Kazuya Matsumoto,Yuichi Okuyama*

主要分类: cs.DC

摘要简述: TriADA提出了一种大规模并行三线性矩阵-张量乘加算法及设备架构，用于加速3D离散变换，解决了高维计算和内存需求问题，同时提升能效和计算稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 高维张量运算在高性能计算和人工智能中至关重要，但其计算和内存需求随维度增加而急剧上升，且并行处理单元的增加会显著提高能耗。稀疏数据在HPC和AI中常见，进一步加剧了这些挑战。TriADA旨在通过创新算法和架构解决这些问题。

研究方法: TriADA的创新包括：(1)大规模并行低秩算法，用于计算三线性离散正交变换；(2)基于外积的GEMM核，支持解耦流式活动内存；(3)完全分布式3D网络架构，独立于问题规模；(4)弹性稀疏外积方法，避免零值操作，提升能效和稳定性。

研究结果: TriADA能够以线性时间步长完成多种三线性变换，具有超立方算术复杂度。其大规模并行、可扩展且高能效的架构非常适合加速AI和HPC中最耗时的张量运算。

研究结论: TriADA通过创新的算法和架构设计，显著提升了高维张量运算的效率和能效，为AI和HPC中的关键任务提供了理想解决方案。

中文摘要: 多线性变换在高性能计算（HPC）和人工智能（AI）中至关重要，其中数据以张量形式表示。然而，其高计算和内存需求随维度增加而显著增长，常导致关键任务速度下降。此外，通过增加并行处理单元来扩展计算会大幅提高能耗，限制了其广泛应用，尤其是在HPC和AI中常见的稀疏数据场景。本文提出了三线性算法及与其同构的设备架构（TriADA），通过以下创新解决这些挑战：(1)一种大规模并行低秩算法，用于计算一类三线性（3D）离散正交变换（3D-DXTs），这是更一般的3模矩阵-张量乘法（3D-GEMT）的特例；(2)一种新的基于外积的GEMM核，配备解耦流式活动内存，专门用于加速3D-GEMT操作；(3)与算法同构的完全分布式3D网络，由网格互连的处理单元或单元组成，具有与问题规模无关的坐标无关、数据驱动的本地处理活动；(4)一种弹性稀疏外积（ESOP）方法，避免对零值操作数进行不必要的计算和通信，从而提升能效、计算精度和稳定性。TriADA能够以线性时间步长完成多种三线性变换，具有超立方算术复杂度。其大规模并行、可扩展且高能效的架构非常适合加速AI和HPC中最耗时的多线性张量运算。

</details>


### [363] [Performance Measurements in the AI-Centric Computing Continuum Systems](https://arxiv.org/abs/2506.22884)
**中文标题：以AI为中心的计算连续体系统中的性能测量**

*Praveen Kumar Donta,Qiyang Zhang,Schahram Dustdar*

主要分类: cs.DC

摘要简述: 本文回顾了分布式计算连续体（DCC）和物联网（IoT）环境中常用的性能指标，并讨论了新兴的性能维度（如可持续性、能源效率和系统可观测性），以应对不断变化的计算需求。


<details>
  <summary>详细信息</summary>
研究动机: 随着计算范式从集中式系统转向分布式架构，尤其是生成式AI和大语言模型的兴起，对计算资源的需求激增。传统的性能指标已无法完全满足当前需求，需要重新审视和扩展。

研究方法: 本文通过回顾DCC和IoT环境中常用的性能指标，并分析新兴的性能维度（如可持续性和能源效率），提出选择合适指标的准则和考虑因素。

研究结果: 研究总结了现有性能指标的局限性，并提出了适应新计算需求的新兴性能维度，为系统设计者和用户提供了改进效率和目标对齐的参考。

研究结论: 本文强调了重新定义性能指标的重要性，以应对分布式计算连续体和AI驱动的计算需求，为未来研究和开发提供了方向。

中文摘要: 过去八十年间，计算范式从大型集中式系统转向紧凑的分布式架构，推动了分布式计算连续体（DCC）的兴起。在这一模型中，云、边缘、物联网（IoT）和移动平台等多层协同工作，支持广泛的应用。近年来，生成式AI和大语言模型的出现进一步加剧了对计算资源的需求。尽管传统性能指标提供了坚实基础，但需要重新审视和扩展以适应变化的计算需求和应用程序要求。准确的性能测量通过支持效率改进和促进系统目标对齐，使系统设计者和用户受益。在此背景下，我们回顾了DCC和IoT环境中常用的指标，并讨论了应对新兴计算需求的性能维度，如可持续性、能源效率和系统可观测性。我们还概述了选择合适指标的准则和考虑因素，旨在激发这一关键领域的未来研究和开发。

</details>


### [364] [Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model](https://arxiv.org/abs/2506.23635)
**中文标题：迈向私有LLM的构建：探索Apple Silicon上的多节点专家并行技术用于混合专家大型语言模型**

*Mu-Chi Chen,Po-Hsuan Huang,Xiangrui Ke,Chia-Heng Tu,Chun Jason Xue,Shih-Hao Hung*

主要分类: cs.DC

摘要简述: 本文探讨了在Apple Silicon上使用多节点专家并行技术构建私有大型语言模型（LLM）的可行性，通过优化内存管理和性能模型，Mac Studio集群比NVIDIA H100 GPU的AI超算更具成本效益。


<details>
  <summary>详细信息</summary>
研究动机: 针对个人或小团体服务构建私有LLM系统时面临的高成本和可扩展性挑战，苹果智能（Apple Intelligence）提出了一种基于Apple M2 Ultra芯片的Mac Studio集群作为高效解决方案。

研究方法: 研究团队在Mac Studio集群上部署了基于混合专家（MoE）架构的DBRX模型，通过多节点并行执行专家模块，并分析了计算与通信时间的平衡。同时，优化了苹果软件栈的内存管理逻辑以减少开销。

研究结果: 实验表明，两到四个节点的并行执行显著减少了推理时间，且Mac Studio集群比NVIDIA H100 GPU的AI超算成本效益高出1.15倍。性能模型为私有LLM系统设计提供了重要参考。

研究结论: 通过优化内存管理和多节点并行技术，Apple Silicon的Mac Studio集群为构建高效、低成本的私有LLM系统提供了可行方案，同时性能模型为未来系统设计提供了指导。

中文摘要: 大型语言模型（LLM）通过OpenAI的ChatGPT、Meta的Llama和Databricks的DBRX等显著推动了人工智能（AI）的发展。本文针对苹果智能（Apple Intelligence）为个人或小团体服务构建私有LLM系统时遇到的高成本和可扩展性问题，提出了一种基于Apple M2 Ultra芯片的Mac Studio集群作为高效解决方案。该集群用于托管和加速采用混合专家（MoE）架构的预训练DBRX模型。性能分析表明，在两到四个机器节点上并行执行模型的专家模块可显著减少推理时间。研究发现，专家模块的计算时间与输出交换的通信时间相当，凸显了网络延迟而非带宽的重要性。此外，苹果软件栈的内存管理逻辑带来了显著的管理开销。基于这些发现，我们开发了优化方案以消除内存管理开销。结果表明，Mac Studio集群比采用NVIDIA H100 GPU的最先进AI超算成本效益高出1.15倍。此外，我们还构建了一个性能模型，用于估计不同配置下的系统性能，该模型为私有LLM系统的设计提供了宝贵见解。

</details>


### [365] [QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference](https://arxiv.org/abs/2506.23934)
**中文标题：QPART：面向精度感知边缘推理的自适应模型量化与动态负载均衡**

*Xiangchen Li,Saeid Ghafouri,Bo Ji,Hans Vandierendonck,Deepu John,Dimitrios S. Nikolopoulos*

主要分类: cs.DC

摘要简述: 本文提出了一种面向边缘设备推理的自适应模型量化和动态负载均衡系统QPART，通过联合优化模型量化和推理分区，显著降低了时间和能耗，同时保持精度损失低于1%。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习推理逐渐迁移到边缘设备，如何适应多样化的计算能力、硬件和内存限制变得至关重要。传统固定模型无法满足不同设备的动态需求，因此需要一种能够根据设备能力、精度要求和时间约束动态调整推理模式的方法。

研究方法: 提出了一种精度感知和负载均衡的推理系统，结合联合模型量化和推理分区。服务器动态响应推理请求，发送量化模型并与设备共享推理负载。同时，引入优化框架，通过层间量化位宽和分区点的优化，最小化时间和成本，并通过精度退化指标满足不同任务的精度要求。

研究结果: 仿真结果显示，系统显著减少了整体时间和能耗，计算负载降低超过80%，同时精度损失控制在1%以下。

研究结论: QPART系统通过自适应模型量化和动态负载均衡，为边缘设备推理提供了一种高效且灵活的解决方案，显著提升了资源利用效率并满足了多样化场景的需求。

中文摘要: 随着机器学习推理逐渐迁移到边缘设备，适应多样化的计算能力、硬件和内存限制变得愈发重要。与为所有未来推理查询固定使用预训练模型不同，我们提出了一种更具成本效益且适应多样化场景的推理模式，即根据设备的计算能力、精度要求和时间约束动态规划请求特定的模型。为此，我们提出了一种精度感知和负载均衡的推理系统，结合联合模型量化和推理分区。在该方法中，服务器动态响应推理请求，发送量化模型并自适应地与设备共享推理负载，同时考虑设备的计算能力、信道容量和精度要求。此外，我们引入了一种新的优化框架，结合联合模型量化和分区。该方法通过优化层间量化位宽和分区点，最小化时间和成本，同时通过优化模型中的精度退化指标满足不同任务的精度要求。据我们所知，这是首次在推理服务系统中通过引入精度退化的理论测量来优化层间量化位宽的研究。仿真结果表明，系统显著减少了整体时间和能耗，计算负载降低超过80%，精度损失控制在1%以下。

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [366] [Density, asymmetry and citation dynamics in scientific literature](https://arxiv.org/abs/2506.23366)
**中文标题：科学文献中的密度、不对称性与引用动态**

*Nathaniel Imel,Zachary Hafen*

主要分类: cs.DL

摘要简述: 研究探讨科学论文与先前研究的相似性与其引用率的关系，提出密度和不对称性两个指标，发现密度对引用率有微弱但信息性的预测作用，而不对称性无显著影响。


<details>
  <summary>详细信息</summary>
研究动机: 科学研究常面临在已有知识基础上创新与引入新思想之间的张力，本文旨在探究这种张力是否反映在论文与先前研究的相似性与其引用率的关系中。

研究方法: 引入密度（ρ）和不对称性（α）两个指标，分别衡量论文在语义嵌入空间中的局部几何特征；使用贝叶斯分层回归方法分析这些指标对引用率的预测作用，涵盖53,000篇论文和五种文档嵌入方法。

研究结果: 密度对引用率的预测作用微弱但稳定，能提升基线模型的预测能力；不对称性对引用率无显著预测作用。

研究结论: 论文周围科学文献的密度可能包含关于其影响力的微弱信号，而不对称性无显著作用；研究为链接文档嵌入与科学计量结果提供了可扩展框架。

中文摘要: 科学行为常表现为在已有知识基础上创新与引入新思想之间的张力。本文探究这种张力是否反映在论文与先前研究的相似性与其引用率的关系中。为量化相似性，我们引入两个互补指标：（1）密度（ρ），定义为固定数量的先前发表论文与语义嵌入空间中包围这些论文的最小距离之比；（2）不对称性（α），定义为论文与其最近邻的平均方向差异。通过贝叶斯分层回归方法测试这两个指标对引用率的预测作用，涵盖约53,000篇论文和五种文档嵌入。结果显示，ρ对引用率的单独影响微弱且多变，但加入密度指标能持续提升基线模型的预测能力。这表明论文周围科学文献的密度可能包含关于其影响力的微弱信号。同时，未发现不对称性对引用率预测的显著作用。本研究为链接文档嵌入与科学计量结果提供了可扩展框架，并提出了关于语义相似性在科学奖励动态中作用的新问题。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [367] [Teaching a Language Model to Speak the Language of Tools](https://arxiv.org/abs/2506.23394)
**中文标题：教授语言模型掌握工具语言的方法**

*Simeon Emanuilov*

主要分类: cs.IR

摘要简述: 本文提出了一种方法，通过双语数据集训练语言模型，使其在多语言环境下具备工具调用能力，并以保加利亚语为例展示了显著的效果提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前多语言模型在非英语语言中工具调用能力不足，存在语言混淆和输出不一致的问题，亟需一种方法提升其工具使用能力。

研究方法: 研究通过继续训练BgGPT系列模型（2.6B、9B、27B参数），使用包含10,035个工具调用示例的双语数据集，支持MCP等标准化协议，开发了TUCAN模型。

研究结果: TUCAN模型在工具调用准确率上比基础模型提升28.75%，同时保持了语言理解能力，输出格式清晰且易于解析。

研究结论: 本研究为扩展非英语语言模型的工具调用能力提供了实用方法，并公开了模型、评估框架和数据集以促进其他语言的复制。

中文摘要: 外部工具集成通过函数调用对实际语言模型应用至关重要，但大多数多语言模型在非英语语言中缺乏可靠的工具使用能力。即使是先进的多语言模型，在决定何时使用工具和生成函数调用所需的结构化输出时也存在困难，尤其在低资源语言中表现出语言混淆。本研究提出了一种方法，通过继续训练BgGPT系列模型（2.6B、9B、27B参数），使用包含10,035个工具调用示例的双语数据集，支持MCP（模型上下文协议）等标准化协议，开发了TUCAN（工具使用能力助手导航器）。TUCAN在工具调用准确率上比基础模型提升28.75%，同时保持了核心语言理解能力，并在保加利亚语基准测试中验证了其效果。此外，TUCAN模型展示了生产就绪的响应格式，输出清晰且易于解析的函数调用，与基础模型的冗长和不一致输出形成鲜明对比。研究公开了模型、评估框架和数据集，以便其他语言复制。本研究为扩展工具增强能力至非英语中心系统提供了实用方法。

</details>


### [368] [Enhancing Live Broadcast Engagement: A Multi-modal Approach to Short Video Recommendations Using MMGCN and User Preferences](https://arxiv.org/abs/2506.23085)
**中文标题：提升直播互动：基于MMGCN和用户偏好的多模态短视频推荐方法**

*Saeid Aghasoleymani Najafabadi*

主要分类: cs.IR

摘要简述: 本文提出了一种基于多模态图卷积网络（MMGCN）和用户偏好的短视频推荐系统，旨在提升直播互动效果。通过结合用户交互数据、视频内容特征和上下文信息，该系统在Kwai、TikTok和MovieLens数据集上表现优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 直播平台需要提升用户互动和内容发现效率，传统推荐系统难以捕捉多模态数据和用户偏好的复杂关系。本文旨在通过多模态方法解决这一问题。

研究方法: 采用多模态图卷积网络（MMGCN），结合协同过滤和基于内容的过滤技术，整合用户交互数据、视频内容和上下文信息，实现个性化推荐。

研究结果: 在Kwai、TikTok和MovieLens数据集上，MMGCN模型的F1分数分别为0.574、0.506和0.197，显著优于DeepFM、Wide & Deep等基线模型。

研究结论: 多模态整合和以用户为中心的方法对提升推荐系统性能至关重要，尤其在直播平台的内容发现和用户互动方面具有显著优势。

中文摘要: 本文旨在通过开发一种结合多模态图卷积网络（MMGCN）和用户偏好的短视频推荐系统，探索提升直播互动的多模态方法。该系统通过整合用户交互数据、视频内容特征和上下文信息，提供个性化的推荐。采用协同过滤与基于内容过滤的混合方法，系统能够捕捉用户、视频属性和互动模式之间的复杂关系。使用Kwai、TikTok和MovieLens三个数据集进行评估，结果表明，与DeepFM、Wide & Deep、LightGBM和XGBoost等基线模型相比，基于MMGCN的模型表现更优。该模型在Kwai、TikTok和MovieLens上的F1分数分别为0.574、0.506和0.197，显著优于其他方法。本文强调了多模态整合和以用户为中心的方法在推荐系统中的重要性，尤其是在提升直播平台的内容发现和用户互动方面。

</details>


### [369] [KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On](https://arxiv.org/abs/2506.23471)
**中文标题：KiseKloset：服装检索、推荐与试穿的综合系统**

*Thanh-Tung Phan-Nguyen,Khoi-Nguyen Nguyen-Ngoc,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.IR

摘要简述: 本文提出了一种名为KiseKloset的综合系统，用于服装检索、推荐和虚拟试穿，通过两种检索方法和新型Transformer架构提升用户体验，并采用轻量级虚拟试穿框架实现实时操作。用户测试显示84%的参与者认为系统非常有用。


<details>
  <summary>详细信息</summary>
研究动机: 全球时尚电商行业已成为日常生活的重要组成部分，但现有推荐系统在个性化体验和用户互动方面仍有提升空间。为提高在线购物体验，本文旨在开发一个综合系统，涵盖服装检索、推荐和虚拟试穿功能。

研究方法: 1. 探索两种服装检索方法：相似物品检索和文本反馈引导的物品检索。2. 提出新型Transformer架构，用于推荐跨类别的互补物品。3. 集成近似算法优化搜索流程。4. 采用轻量级虚拟试穿框架，实现实时操作和高保真输出。

研究结果: 用户测试结果显示，84%的参与者认为KiseKloset系统显著提升了在线购物体验。虚拟试穿模块不仅帮助用户直观感受服装效果，还降低了零售商的退货成本。

研究结论: KiseKloset系统通过创新的检索、推荐和虚拟试穿技术，有效提升了在线购物的用户体验，为时尚电商行业提供了实用解决方案。

中文摘要: 全球时尚电商行业已成为人们日常生活中不可或缺的一部分，通过技术进步提供个性化购物体验，尤其是通过推荐系统增强用户互动。为提升在线购物体验，我们提出了一种名为KiseKloset的综合系统，涵盖服装检索、推荐和试穿功能。我们探索了两种服装检索方法：相似物品检索和文本反馈引导的物品检索。特别地，我们引入了一种新型Transformer架构，用于推荐跨类别的互补物品。此外，通过集成近似算法优化搜索流程，提升了整体性能。针对在线购物者的关键需求，我们采用了一种轻量级但高效的虚拟试穿框架，能够实现实时操作、内存高效，并保持与前代相比更真实的输出效果。该虚拟试穿模块使用户能够直观感受特定服装的上身效果，提升了用户体验，同时降低了零售商的退货成本。我们将端到端系统部署给在线用户测试并收集反馈，结果显示84%的参与者认为该系统非常有用，显著改善了他们的在线购物体验。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [370] [Report on NSF Workshop on Science of Safe AI](https://arxiv.org/abs/2506.22492)
**中文标题：NSF安全AI科学研讨会报告**

*Rajeev Alur,Greg Durrett,Hadas Kress-Gazit,Corina Păsăreanu,René Vidal*

主要分类: cs.CY

摘要简述: 本文总结了NSF关于安全AI科学的研讨会，探讨了如何开发既准确又安全可信的AI系统，并提出了新的研究议程。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习的发展，尤其是基础模型的出现，AI技术为解决社会问题提供了新机会。然而，当前复杂AI模型的内部机制不透明，且缺乏安全性保障，因此需要研究如何开发既准确又安全可信的AI系统。

研究方法: 研讨会汇集了NSF SLES项目资助的研究人员及其他研究AI安全的学者，通过分组讨论探讨了安全性的不同方面。

研究结果: 研讨会提出了一项新的研究议程，旨在开发理论、方法和工具，为下一代AI系统奠定安全基础。

研究结论: 研讨会强调了安全AI的重要性，并呼吁进一步研究以解决AI系统的透明性和安全性问题。

中文摘要: 近年来，机器学习的进步，尤其是基础模型的出现，为开发基于技术的社会问题解决方案提供了新机遇。然而，当前复杂AI模型的推理和内部机制对用户并不透明，且其预测缺乏安全性保障。因此，为了实现AI的潜力，我们必须应对以下科学挑战：如何开发不仅准确高效，而且安全可信的AI系统？

安全操作的重要性在控制和机器人领域的自主系统中尤为明显，这也是NSF安全学习赋能系统（SLES）项目的催化剂。对于更广泛的AI应用（如用户与聊天机器人的交互或临床医生接收治疗建议），安全性虽同样重要，但其定义因上下文而异。为此，2025年2月26日在宾夕法尼亚大学举办了一场为期一天的研讨会，汇集了NSF SLES项目资助的研究人员及其他研究AI安全的学者。本报告是研讨会上各工作组针对安全性不同方面讨论的成果。报告提出了一项新的研究议程，专注于开发理论、方法和工具，为下一代AI系统奠定安全基础。

</details>


### [371] [Mitigating Gambling-Like Risk-Taking Behaviors in Large Language Models: A Behavioral Economics Approach to AI Safety](https://arxiv.org/abs/2506.22496)
**中文标题：减轻大型语言模型中的赌博式风险行为：基于行为经济学的AI安全方法**

*Y. Du*

主要分类: cs.CY

摘要简述: 大型语言模型（LLMs）存在类似赌博心理的风险行为，如过度自信、追逐损失和概率误判。研究提出风险感知响应生成（RARG）框架，结合行为经济学方法，显著减少了这些行为。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在生成输出时表现出类似赌博的风险行为，如过度自信和追逐损失，可能影响其安全性和可靠性。研究旨在通过行为经济学方法识别并减少这些行为。

研究方法: 研究提出风险感知响应生成（RARG）框架，结合风险校准训练、损失规避机制和不确定性感知决策，并基于赌博心理学实验（如爱荷华赌博任务）设计评估范式。

研究结果: 实验结果显示，RARG框架显著减少了赌博式行为：过度自信偏差降低18.7%，追逐损失倾向减少24.3%，并在多样化场景中改善了风险校准。

研究结论: 研究首次建立了系统框架，用于理解和减少AI系统中的赌博心理模式，为AI安全性提供了新方法。

中文摘要: 大型语言模型（LLMs）表现出与赌博心理学类似的系统性风险行为，包括过度自信偏差、追逐损失倾向和概率误判。基于行为经济学和前景理论，我们识别并形式化了这些“赌博式”模式，其中模型为高回报输出牺牲准确性，在错误后表现出升级的风险行为，并系统性误判不确定性。我们提出了风险感知响应生成（RARG）框架，结合赌博研究的见解，通过风险校准训练、损失规避机制和不确定性感知决策来解决这些行为偏差。我们的方法引入了基于赌博心理学实验的新评估范式，包括爱荷华赌博任务和概率学习评估的AI适配版本。实验结果显示，赌博式行为显著减少：过度自信偏差降低18.7%，追逐损失倾向减少24.3%，并在多样化场景中改善了风险校准。这项工作首次建立了理解和减轻AI系统中赌博心理模式的系统框架。

</details>


### [372] [Peer Review as Structured Commentary: Immutable Identity, Public Dialogue, and Reproducible Scholarship](https://arxiv.org/abs/2506.22497)
**中文标题：同行评审作为结构化评论：不可变身份、公开对话与可复现学术**

*Craig Steven Wright*

主要分类: cs.CY

摘要简述: 本文重新定义同行评审为结构化公开评论，提出透明、身份绑定且可复现的学术评价系统，利用区块链和AI技术激励学术贡献并追踪声誉动态。


<details>
  <summary>详细信息</summary>
研究动机: 传统学术评审因匿名性、延迟性和把关问题阻碍学术发展，本文旨在通过透明化和公开评论改进这一过程。

研究方法: 设计基于区块链的不可篡改审计追踪和AI迭代合成的框架，支持公开评论和学术声誉动态追踪。

研究结果: 提出了一种透明、可复现的学术评价系统，能够激励学术贡献并记录知识演化过程。

研究结论: 该模型将学术知识视为动态过程而非静态凭证，适用于从计算科学到人文的多个领域。

中文摘要: 本文重新定义同行评审为结构化公开评论。传统学术验证因匿名性、延迟性和把关问题受到阻碍。我们提出一种透明、身份绑定且可复现的学术评价系统，以公开评论为基础。利用区块链实现不可篡改的审计追踪，结合AI进行迭代合成，设计了一个激励学术贡献、记录知识演化并支持可追踪声誉动态的框架。该模型适用于从计算科学到人文的多个领域，将学术知识重新定义为动态过程而非静态凭证。

</details>


### [373] [Ask before you Build: Rethinking AI-for-Good in Human Trafficking Interventions](https://arxiv.org/abs/2506.22512)
**中文标题：在构建之前先提问：重新思考AI用于人口贩运干预中的‘善’**

*Pratheeksha Nair,Gabriel Lefebvre,Sophia Garrel,Maryam Molamohammadi,Reihaneh Rabbany*

主要分类: cs.CY

摘要简述: 本文提出“激进提问”（RQ）框架，作为一种五步预项目伦理评估工具，用于批判性评估AI是否应被开发，特别是在涉及边缘化群体和系统性不公的领域。通过AI用于人口贩运的案例研究，RQ揭示了被忽视的社会文化复杂性，并引导从监控干预转向幸存者赋权工具。


<details>
  <summary>详细信息</summary>
研究动机: AI用于社会公益的倡议常假设技术干预能解决复杂社会问题，但在人口贩运（HT）等背景下，这种技术解决方案主义可能简化剥削问题，加剧权力失衡，并对AI声称支持的社区造成伤害。本文旨在通过RQ框架，提供一个上游的、审议性的空间，以挑战假设、分析权力关系并考虑潜在危害。

研究方法: 本文引入RQ框架，包括五个步骤：1）是否应开发AI；2）挑战假设；3）分析权力关系；4）考虑潜在危害；5）探索替代方案。通过AI用于HT的案例研究，展示RQ如何揭示社会文化复杂性并指导干预方向。

研究结果: RQ框架在HT案例中成功揭示了被忽视的社会文化复杂性，并引导从基于监控的干预转向幸存者赋权工具。RQ的五步结构可推广至其他领域，但具体问题需根据上下文调整。

研究结论: RQ框架为AI伦理提供了一种上游评估工具，挑战了工具主义规范，并强调关系性和反思性责任。尽管RQ在HT背景下开发，但其结构具有普适性，需结合具体情境调整问题。

中文摘要: AI用于公益的倡议常假设技术干预能解决复杂社会问题。在人口贩运（HT）背景下，这种技术解决方案主义可能简化剥削问题，加剧权力失衡，并对AI声称支持的社区造成伤害。本文提出“激进提问”（RQ）框架，作为一种五步预项目伦理评估工具，用于批判性评估AI是否应被开发，特别是在涉及边缘化群体和系统性不公的领域。RQ不取代基于原则的伦理，而是为其提供上游的、审议性空间，以挑战假设、分析权力关系并考虑潜在危害。通过AI用于HT的案例研究，RQ揭示了被忽视的社会文化复杂性，并引导从监控干预转向幸存者赋权工具。尽管RQ在HT背景下开发，其五步结构可推广至其他领域，但具体问题需根据上下文调整。本文将RQ置于更广泛的AI伦理哲学中，挑战工具主义规范，并强调关系性和反思性责任。

</details>


### [374] [Computational Analysis of Climate Policy](https://arxiv.org/abs/2506.22449)
**中文标题：气候政策的计算分析**

*Carolyn Hicks*

主要分类: cs.CY

摘要简述: 本研究利用GPT-4构建的PALLM系统分析了澳大利亚维多利亚州地方政府的气候政策，发现通过气候紧急宣言（CED）的政府在政策中更注重紧迫性、优先级和社会公平。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估当前大型语言模型（如GPT-4）在回答复杂政策问题中的潜力，并探索气候紧急运动对地方政府气候政策的影响。

研究方法: 使用GPT-4构建PALLM系统，对维多利亚州11个地方政府的气候政策文件进行分析，并通过政策制定者的反馈验证系统性能。随后进行大规模政策文件分析，比较通过和未通过CED的政府政策差异。

研究结果: 研究发现，通过CED的政府更可能拥有近期且针对气候的具体政策，且在紧迫性、优先级和社会公平方面表现更突出。GPT-4能够进行高级政策分析，但存在缺乏可靠归因的局限性。

研究结论: 大规模政策文件分析为政策研究提供了新机会，表明CED对地方政府气候政策的积极影响。

中文摘要: 本论文通过计算方法探讨了气候紧急运动对地方政府气候政策的影响。气候紧急运动通过气候紧急宣言（CED）机制加速了地方政府的行动，促使一系列承诺将气候变化视为紧急事件。为评估当前大型语言模型回答复杂政策问题的潜力，首先基于OpenAI的GPT-4构建了名为PALLM（基于大型语言模型的政策分析）的系统。该系统旨在将气候紧急响应计划的概念框架应用于气候政策文件数据集。通过与地方政府政策制定者合作，生成了维多利亚州11个地方政府的气候政策分析，并评估了政策制定者对PALLM回答的认可度。确认PALLM性能满意后，将其用于对澳大利亚维多利亚州地方政府现有政策文件的大规模分析。本论文展示了该分析的方法和结果，比较了通过和未通过CED的政府政策。研究发现，GPT-4能够进行高级政策分析，但存在缺乏可靠归因的局限性，同时也能支持研究者进行更细致的分析。研究表明，通过CED的政府更可能拥有近期且针对气候的具体政策，且在紧迫性、优先级和社会公平方面表现更突出。结论认为，大规模政策文件分析能力为政策研究开辟了令人兴奋的新机遇。

</details>


### [375] [Theories of "Sexuality" in Natural Language Processing Bias Research](https://arxiv.org/abs/2506.22481)
**中文标题：自然语言处理偏见研究中关于“性取向”的理论**

*Jacob Hobbs*

主要分类: cs.CY

摘要简述: 本文探讨了自然语言处理（NLP）研究中关于“性取向”偏见的理论，指出当前文献中对性取向的定义模糊，且常将性别与性取向混为一谈，导致对偏见的不准确量化。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，NLP技术的广泛应用引发了对其反映和放大社会偏见（如性别和种族偏见）的研究热潮。然而，关于性取向偏见的研究存在显著空白，尤其是性取向如何在NLP系统中被编码和误现。本文旨在填补这一空白。

研究方法: 通过对55篇量化性取向偏见的NLP文献进行综述和分析，本文探讨了性取向的定义和操作化方式，并揭示了文献中的模糊性和混淆现象。

研究结果: 研究发现，大多数文献未明确定义性取向，依赖对性/浪漫实践和身份的假设或规范性概念。此外，NLP技术提取偏见输出的方法常将性别与性取向混为一谈，导致对“酷儿”的单一化理解和不准确的偏见量化。

研究结论: 为改进性取向偏见的NLP分析，本文建议更深入地与酷儿社群和跨学科文献互动，以促进更全面的研究。

中文摘要: 近年来，自然语言处理（NLP）领域的重大进展使商业化语言模型成为广泛且高度实用的工具。与此同时，多学科研究激增，探讨NLP任务如何反映、延续和放大社会偏见（如性别和种族偏见）。然而，这些研究中存在一个显著空白，即缺乏对酷儿性取向如何在NLP系统和实践中被编码和误现的详细分析。借鉴AI公平性领域的前期工作，我们通过综述和分析55篇量化性取向偏见的NLP文献，记录了性取向的定义和操作化方式。研究发现，大多数文献未明确定义性取向，表明其依赖对性/浪漫实践和身份的假设或规范性概念。此外，从NLP技术中提取偏见输出的方法常将性别与性取向混为一谈，导致对“酷儿”的单一化理解，从而对偏见进行不准确的量化。为改进性取向偏见的NLP分析，我们最后提出建议，鼓励更深入地与酷儿社群和跨学科文献互动。

</details>


### [376] [A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models](https://arxiv.org/abs/2506.22493)
**中文标题：政治罗盘测试的详细因素分析：探索大型语言模型的政治意识形态**

*Sadia Kamal,Lalu Prasad Yadav Prakash,S M Rafiuddin,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen,Sagnik Ray Choudhury*

主要分类: cs.CY

摘要简述: 研究发现，标准生成参数的变化对大型语言模型（LLM）的政治倾向测试（PCT）分数影响不大，但提示变化和微调会显著影响结果。此外，模型在政治内容较多的数据集上微调时，PCT分数并未显著差异，引发对PCT测试有效性和LLM政治倾向编码机制的深入探讨。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，政治罗盘测试（PCT）被用于量化大型语言模型（LLM）的政治倾向。然而，PCT测试的有效性及其结果是否受模型生成参数、提示变化和微调等因素影响尚不明确。本研究旨在探讨这些因素对PCT分数的影响，并评估PCT测试的可靠性。

研究方法: 研究通过实验分析标准生成参数（如温度、top-k等）对LLM的PCT分数的影响，同时考察提示变化和微调（单独及组合）的作用。此外，研究还比较了模型在不同政治内容数据集上微调后的PCT分数差异。

研究结果: 结果表明，标准生成参数的变化对PCT分数影响不显著，但提示变化和微调会显著改变分数。然而，模型在政治内容较多的数据集上微调时，PCT分数并未表现出显著差异。

研究结论: 研究呼吁对PCT测试的有效性及其在LLM中的政治倾向编码机制进行更深入的调查，同时提示未来研究需关注外部因素对测试结果的影响。

中文摘要: 政治罗盘测试（PCT）或类似问卷被用于量化大型语言模型（LLM）的政治倾向。基于近期关于PCT测试有效性的研究，我们发现标准生成参数的变化对模型的PCT分数影响不大。然而，提示变化和微调（单独或组合）会显著影响测试结果。最后，研究表明，当模型在政治内容较多的文本数据集上微调时，PCT分数并未表现出显著差异。这要求对PCT及类似测试的有效性，以及LLM中政治倾向的编码机制进行深入研究。

</details>


### [377] [Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center](https://arxiv.org/abs/2506.22523)
**中文标题：生成式AI的红队测试：一项在学术医疗中心完成的版权焦点演练报告**

*James Wen,Sahil Nalawade,Zhiwei Liang,Catherine Bielick,Marisa Ferrara Boston,Alexander Chowdhury,Adele Collin,Luigi De Angelis,Jacob Ellen,Heather Frase,Rodrigo R. Gameiro,Juan Manuel Gutierrez,Pooja Kadam,Murat Keceli,Srikanth Krishnamurthy,Anne Kwok,Yanan Lance Lu,Heather Mattie,Liam G. McCoy,Katherine Miller,Allison C. Morgan,Marlene Louisa Moerig,Trang Nguyen,Alexander Owen-Post,Alex D. Ruiz,Sreekar Reddy Puchala,Soujanya Samineni,Takeshi Tohyama,Varun Ullanat,Carmine Valenza,Camilo Velez,Pengcheng Wang,Anna Wuest,Yuxiang Zhou,Yingde Zhu,Jason M. Johnson,Jennifer Willcox,Francis J. Vitiello,Leo Anthony G. Celi,Renato Umeton*

主要分类: cs.CY

摘要简述: Dana-Farber癌症研究所与微软合作开发的AI工具GPT4DFCI通过红队测试评估其是否输出受版权保护的数据。测试发现模型能复现部分书籍内容，但无法复现新闻、科学文章或电子健康记录。测试后已部署缓解策略。


<details>
  <summary>详细信息</summary>
研究动机: 生成式AI在多个行业广泛应用，但其可能输出受版权保护的数据。本研究旨在通过红队测试评估GPT4DFCI是否复现受版权保护的内容，以明确其法律和伦理边界。

研究方法: 研究团队与微软合作，对GPT4DFCI进行红队测试，重点测试其是否能复现书籍、新闻文章、科学文章和电子健康记录中的受版权保护内容。

研究结果: 测试发现GPT4DFCI能复现部分书籍的精确引文，表明其训练数据包含受版权内容。但无法复现新闻、科学文章或电子健康记录内容，且存在虚构内容。测试后已部署缓解策略。

研究结论: 红队测试揭示了生成式AI可能复现受版权内容的风险，需通过类似测试明确其法律和伦理边界。GPT4DFCI已部署缓解策略，未来需进一步优化。

中文摘要: 生成式AI已在多个行业广泛应用。Dana-Farber癌症研究所与微软合作开发了一款内部AI工具GPT4DFCI。双方共同举办了一场红队测试活动，以评估支持该工具的底层GPT模型是否会输出受版权保护的数据。团队重点关注了书籍、新闻文章、科学文章和电子健康记录的内容复现情况。测试发现，GPT4DFCI在个别情况下能识别受版权保护的内容并复现著名书籍的精确引文，表明其训练数据包含受版权材料。但模型无法复现目标新闻文章、科学文章或电子健康记录的内容，且存在虚构现象。基于此次测试，GPT4DFCI v2.8.2已于2025年1月21日部署了缓解策略。我们希望本报告能推动类似活动，通过压力测试评估AI软件工具的法律和伦理使用边界。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [378] [FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation](https://arxiv.org/abs/2506.22580)
**中文标题：FedCLAM：面向联邦医学图像分割的客户端自适应动量与前景强度匹配方法**

*Vasilis Siomos,Jonathan Passerat-Palmbach,Giacomo Tarroni*

主要分类: eess.IV

摘要简述: 本文提出FedCLAM，一种结合客户端自适应动量和前景强度匹配的联邦学习方法，用于解决医学图像分割中因设备和人群差异导致的性能下降问题，并在实验中优于八种前沿方法。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在医学图像分割中面临因不同设备和人群差异导致的特征不一致问题，现有聚合方法难以适应多样化场景，亟需一种能够动态调整并提升全局模型性能的方法。

研究方法: FedCLAM结合了客户端自适应动量（根据客户端损失减少动态调整）和个性化阻尼因子（防止过拟合），并引入前景强度对齐损失以处理不同机构的图像强度分布差异。

研究结果: 在两个数据集上的实验表明，FedCLAM在医学图像分割任务中优于八种前沿方法，验证了其有效性。

研究结论: FedCLAM通过客户端自适应动量和前景强度匹配，显著提升了联邦学习在医学图像分割中的性能，为跨机构协作提供了有效解决方案。

中文摘要: 联邦学习是一种去中心化的训练方法，能够在保持数据由利益相关者控制的同时，实现优于孤立训练的性能。然而，在所有联邦学习场景中，机构间特征差异是一个挑战，医学影像尤其受到不同成像设备和人群差异的影响，这会降低全局模型的有效性。现有的聚合方法通常无法适应多样化场景。为此，我们提出了FedCLAM，该方法集成了从每个客户端本地训练中损失减少衍生的客户端自适应动量项，以及一个个性化阻尼因子以防止过拟合。我们还引入了一种新颖的强度对齐损失，通过匹配预测和真实前景分布来处理跨机构和设备的异质图像强度分布。在两个数据集上的广泛评估表明，FedCLAM在医学分割任务中优于八种前沿方法，证明了其有效性。代码可在https://github.com/siomvas/FedCLAM获取。

</details>


### [379] [CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation](https://arxiv.org/abs/2506.23121)
**中文标题：CRISP-SAM2：基于跨模态交互和语义提示的SAM2多器官分割模型**

*Xinlei Yu,Chanmiao Wang,Hui Jin,Ahmed Elazab,Gangyong Jia,Xiang Wan,Changqing Zou,Ruiquan Ge*

主要分类: eess.IV

摘要简述: CRISP-SAM2是一种基于SAM2的多器官医学分割模型，通过跨模态交互和语义提示解决了现有模型在细节不准确、依赖几何提示和空间信息丢失等问题上的局限性。实验表明其在多个公共数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前多器官医学分割模型存在细节不准确、依赖几何提示和空间信息丢失等问题，影响了诊断和治疗计划的准确性。为了解决这些问题，研究者提出了CRISP-SAM2模型。

研究方法: CRISP-SAM2通过渐进式跨注意力交互机制将视觉和文本输入转换为跨模态语义，并注入图像编码器以增强视觉细节理解。采用语义提示策略替代原始提示编码器，减少对几何提示的依赖。同时，引入记忆的自更新相似性排序策略和掩码细化过程，进一步适应医学图像并增强局部细节。

研究结果: 在七个公共数据集上的对比实验表明，CRISP-SAM2优于现有模型，尤其在解决细节不准确和空间信息丢失等问题上表现突出。

研究结论: CRISP-SAM2通过跨模态交互和语义提示显著提升了多器官医学分割的性能，解决了现有模型的局限性，为医学图像处理提供了更有效的工具。

中文摘要: 多器官医学分割是医学图像处理的关键组成部分，对医生做出准确诊断和制定有效治疗计划至关重要。尽管该领域已取得显著进展，但当前多器官分割模型常存在细节不准确、依赖几何提示和空间信息丢失等问题。为解决这些挑战，我们提出了一种基于SAM2的新型模型CRISP-SAM2，该模型通过跨模态交互和语义提示实现多器官医学分割。我们的方法首先通过渐进式跨注意力交互机制将视觉和文本输入转换为跨模态语义，并将其注入图像编码器以增强对视觉信息的细节理解。为消除对几何提示的依赖，我们采用语义提示策略替代原始提示编码器，以提升对挑战性目标的感知。此外，还应用了记忆的自更新相似性排序策略和掩码细化过程，以进一步适应医学图像并增强局部细节。在七个公共数据集上的对比实验表明，CRISP-SAM2优于现有模型。广泛的分析也验证了我们方法的有效性，尤其是在解决上述局限性方面表现出色。代码已开源：https://github.com/YU-deep/CRISP_SAM2.git。

</details>


### [380] [Score-based Diffusion Model for Unpaired Virtual Histology Staining](https://arxiv.org/abs/2506.23184)
**中文标题：基于分数扩散模型的非配对虚拟组织染色**

*Anran Liu,Xiaofei Wang,Jing Cai,Chao Li*

主要分类: eess.IV

摘要简述: 本文提出了一种基于互信息引导的分数扩散模型，用于非配对的虚拟组织染色，解决了现有方法在染色风格与组织结构分解、可控染色过程及结构一致性建模方面的挑战。


<details>
  <summary>详细信息</summary>
研究动机: H&E染色缺乏对诊断标记的特异性，而IHC染色受限于组织可用性和抗体特异性。虚拟染色技术可以高效生成IHC图像，但现有方法在染色风格与组织结构分离、可控染色过程及结构一致性建模方面存在不足。

研究方法: 1) 设计全局互信息引导的能量函数，分离多模态下的组织结构和染色特征；2) 提出时间步定制的反向扩散过程，精确控制染色强度和结构重建；3) 采用局部互信息驱动的对比学习策略，确保H&E与IHC图像在细胞级别的结构一致性。

研究结果: 实验表明，该方法在虚拟染色任务中优于现有技术，展现了其生物医学应用潜力。

研究结论: 本研究提出的模型有效解决了虚拟染色中的关键挑战，为高效生成IHC图像提供了新方法。

中文摘要: 苏木精-伊红（H&E）染色可视化组织学，但缺乏对诊断标记的特异性。免疫组织化学（IHC）染色提供蛋白质靶向染色，但受限于组织可用性和抗体特异性。虚拟染色技术通过计算将H&E图像转换为IHC图像，同时保留组织结构，为高效生成IHC图像提供了可能。现有虚拟染色方法仍面临关键挑战：1) 染色风格与组织结构的有效分解；2) 适应不同组织和蛋白质的可控染色过程；3) 严格的非像素对齐H&E与IHC图像的结构一致性建模。本研究提出了一种基于互信息（MI）引导的分数扩散模型，用于非配对虚拟染色。具体包括：1) 设计全局MI引导的能量函数，分离多模态下的组织结构和染色特征；2) 提出时间步定制的反向扩散过程，精确控制染色强度和结构重建；3) 采用局部MI驱动的对比学习策略，确保H&E与IHC图像在细胞级别的结构一致性。大量实验表明，该方法优于现有技术，凸显了其生物医学潜力。代码将在论文接受后开源。

</details>


### [381] [Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation](https://arxiv.org/abs/2506.23334)
**中文标题：基于合成超声图像增强的联邦乳腺癌检测**

*Hongyi Pan,Ziliang Hong,Gorkem Durak,Ziyue Xu,Ulas Bagci*

主要分类: eess.IV

摘要简述: 本文提出了一种基于生成对抗网络（GAN）的数据增强框架，通过合成乳腺超声图像来提升联邦学习在乳腺癌检测中的性能。实验表明，适量合成图像能显著提高模型AUC值，但过度使用会降低效果。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习（FL）在医疗领域具有潜力，但数据不足和非独立同分布问题限制了其性能。本文旨在通过合成图像增强数据，解决这些问题，提升乳腺癌超声图像分类的准确性和泛化能力。

研究方法: 使用两种简单的类别特定深度卷积生成对抗网络（DCGAN），分别生成良性和恶性病变的合成超声图像。在三个公开数据集（BUSI、BUS-BRA和UDIAT）上模拟联邦学习环境，并采用FedAvg和FedProx作为基线算法。

研究结果: 实验结果显示，适量合成图像将FedAvg的平均AUC从0.9206提升至0.9237，FedProx的平均AUC从0.9429提升至0.9538。但过度使用合成数据会降低性能。

研究结论: 基于生成AI的数据增强能有效提升联邦学习在乳腺超声图像分类任务中的表现，但需注意合成与真实数据的平衡比例。

中文摘要: 联邦学习（FL）作为一种在不交换敏感医疗数据的情况下跨机构协作训练深度学习模型的范式，展现出巨大潜力。然而，其有效性常因数据不足和非独立同分布问题而受限，导致模型性能和泛化能力下降。为解决这些问题，我们提出了一种基于生成AI的数据增强框架，将合成图像共享融入联邦训练过程，用于乳腺超声图像的癌症诊断。具体而言，我们训练了两个简单的类别特定深度卷积生成对抗网络（DCGAN），分别生成良性和恶性病变的合成图像。随后，我们使用三个公开的乳腺超声图像数据集（BUSI、BUS-BRA和UDIAT）模拟真实的联邦学习环境，并采用FedAvg和FedProx作为基线算法。实验结果表明，引入适量合成图像后，FedAvg的平均AUC从0.9206提升至0.9237，FedProx的平均AUC从0.9429提升至0.9538。但我们也发现，过度使用合成数据会降低性能，这突显了保持真实与合成样本比例平衡的重要性。我们的研究结果揭示了基于生成AI的数据增强在提升乳腺超声图像分类任务联邦学习效果方面的潜力。

</details>


### [382] [UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound](https://arxiv.org/abs/2506.23490)
**中文标题：UltraTwin：基于多视角2D超声的心脏解剖孪生模型生成**

*Junxuan Yu,Yaofei Duan,Yuhao Huang,Yu Wang,Rongbo Ling,Weihao Luo,Ang Zhang,Jingxian Xu,Qiongying Ni,Yongsong Zhou,Binghan Li,Haoran Dou,Liping Liu,Yanfen Chu,Feng Geng,Zhe Sheng,Zhifeng Ding,Dingxin Zhang,Rui Huang,Yuhang Zhang,Xiaowei Xu,Tao Tan,Dong Ni,Zhongshan Gou,Xin Yang*

主要分类: eess.IV

摘要简述: 本文提出了一种名为UltraTwin的新型生成框架，用于从稀疏多视角2D超声图像中生成心脏解剖孪生模型，解决了现有技术中3D超声分辨率低、视野小的问题，并通过实验验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 2D超声在心脏检查中常用，但难以精确计算指标和直接观察3D心脏结构；3D超声则受限于分辨率低、视野小和实际应用中的稀缺性。因此，从2D图像构建心脏解剖孪生模型成为解决这些问题的潜在方案，但面临配对数据稀缺、结构复杂和超声噪声等挑战。

研究方法: 研究提出了一种从稀疏多视角2D超声生成心脏解剖孪生模型的框架UltraTwin。方法包括：1）构建高质量的真实世界数据集，包含严格配对的多视角2D超声和CT数据以及伪配对数据；2）采用从粗到细的分层重建优化方案；3）引入隐式自编码器以实现拓扑感知约束。

研究结果: 实验表明，UltraTwin在生成高质量心脏解剖孪生模型方面优于其他强竞争方法，验证了其有效性。

研究结论: UltraTwin为个性化心脏护理中的解剖孪生建模提供了潜在应用价值，推动了该领域的发展。

中文摘要: 超声心动图是心脏检查的常规手段，但2D超声（US）难以精确计算指标并直接观察3D心脏结构。此外，3D超声因分辨率低、视野小及实际应用中的稀缺性而受限。从2D图像构建心脏解剖孪生模型有望为精确治疗计划和临床量化提供支持，但由于配对数据稀缺、结构复杂及超声噪声等问题，这一目标仍具挑战性。本研究提出了一种新型生成框架UltraTwin，用于从稀疏多视角2D超声中生成心脏解剖孪生模型。其贡献包括：1）首次构建了包含严格配对多视角2D超声与CT数据及伪配对数据的高质量真实世界数据集；2）提出了一种从粗到细的分层重建优化方案；3）引入了隐式自编码器以实现拓扑感知约束。大量实验表明，UltraTwin在生成高质量解剖孪生模型方面优于其他强竞争方法。我们相信，该研究推动了解剖孪生建模在个性化心脏护理中的潜在应用。

</details>


### [383] [Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI](https://arxiv.org/abs/2506.23506)
**中文标题：人工智能辅助的像素级肺部（APL）评分用于超短回波时间MRI中快速准确的定量分析**

*Bowen Xin,Rohan Hickey,Tamara Blake,Jin Jin,Claire E Wainwright,Thomas Benkert,Alto Stemmer,Peter Sly,David Coman,Jason Dowling*

主要分类: eess.IV

摘要简述: 本文提出了一种基于人工智能的像素级肺部（APL）评分方法，用于超短回波时间MRI中快速准确的肺部定量分析。该方法在囊性纤维化（CF）患者中验证，结果显示APL评分速度更快、准确性更高，且与现有网格级评分高度相关。


<details>
  <summary>详细信息</summary>
研究动机: 超短回波时间MRI（UTE-MRI）在肺部结构成像中具有突破性进展，但缺乏定量评分系统。本研究旨在开发一种快速、准确的AI辅助像素级评分方法，以替代传统的网格级评分，用于囊性纤维化等肺部疾病的诊断和进展评估。

研究方法: APL评分包括五个阶段：1）图像加载，2）AI肺部分割，3）肺部边界切片采样，4）像素级标注，5）定量和报告生成。该方法通过AI技术实现高效分割和标注，显著提升评分速度。

研究结果: APL评分每例耗时8.2分钟，比网格级评分快两倍以上，且准确性显著更高（p=0.021）。APL评分与网格级评分高度相关（R=0.973，p=5.85e-9），验证了其可靠性。

研究结论: APL评分工具在临床中具有广泛应用潜力，可优化UTE-MRI工作流程，并扩展至其他肺部MRI序列和疾病（如支气管肺发育不良）。

中文摘要: 超短回波时间（UTE）肺部磁共振成像（MRI）是肺部结构成像的一项突破性技术，其图像分辨率和质量与计算机断层扫描（CT）相当。由于无电离辐射，MRI在儿科疾病（如囊性纤维化（CF））中常优于CT。为评估CF影像中的肺部结构损伤，CT评分系统提供了重要的定量诊断依据，但结构肺部MRI（如UTE-MRI）中缺乏定量评分方法。为此，我们研究了人工智能辅助像素级肺部（APL）评分在CF中的可行性。APL评分包括五个阶段：1）图像加载，2）AI肺部分割，3）肺部边界切片采样，4）像素级标注，5）定量和报告生成。结果显示，APL评分每例耗时8.2分钟，比网格级评分快两倍以上，且准确性更高（p=0.021），同时与网格级评分高度相关（R=0.973，p=5.85e-9）。该工具有望优化UTE-MRI临床工作流程，并可扩展至其他肺部MRI序列（如BLADE MRI）和疾病（如支气管肺发育不良）。

</details>


### [384] [A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation](https://arxiv.org/abs/2506.23584)
**中文标题：基于临床的两阶段肾脏CT报告生成框架**

*Renjie Liang,Zhengkang Fan,Jinqian Pan,Chenkun Sun,Russell Terry,Jie Xu*

主要分类: eess.IV

摘要简述: 本文提出了一种两阶段框架，用于从2D CT切片生成肾脏放射学报告。通过多任务学习模型提取异常特征，并结合视觉语言模型生成自然语言报告，实验证明其优于随机基线，并能够准确捕捉临床内容。


<details>
  <summary>详细信息</summary>
研究动机: 由于医学影像的复杂性和临床文档的多样性，从CT扫描生成放射学报告是一项具有挑战性的任务。本研究旨在通过模块化方法解决这一问题，提高报告的临床准确性。

研究方法: 研究采用两阶段框架：首先使用多任务学习模型提取异常特征（如位置、大小、增强和衰减），然后将这些特征与CT图像结合，输入微调的视觉语言模型以生成与临床发现一致的自然语言报告。

研究结果: 实验结果表明，该模型在所有异常类型上均优于随机基线，生成的报告能够合理准确地捕捉关键临床内容。

研究结论: 本研究证明了模块化、基于特征的报告生成方法在肾脏影像中的可行性，未来将扩展至3D CT体积并进一步提升临床保真度。

中文摘要: 由于医学影像的复杂性和临床文档的多样性，从CT扫描生成放射学报告仍然是一项复杂的任务。本研究提出了一种两阶段框架，用于从2D CT切片生成肾脏放射学报告。首先，我们使用多任务学习模型提取结构化异常特征，该模型经过训练以识别病变属性（如位置、大小、增强和衰减）。随后，这些提取的特征与相应的CT图像结合，输入微调的视觉语言模型，生成与临床发现一致的自然语言报告句子。我们在一个经过整理的肾脏CT研究数据集上进行了实验，该数据集包含手动标注的句子-切片-特征三元组，并使用分类指标和自然语言生成指标评估性能。结果表明，所提出的模型在所有异常类型上均优于随机基线，生成的报告能够合理准确地捕捉关键临床内容。这项探索性工作突出了模块化、基于特征的报告生成方法在肾脏影像中的可行性。未来的工作将集中于将该流程扩展至3D CT体积，并进一步提升多模态医学AI系统的临床保真度。

</details>


### [385] [Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound](https://arxiv.org/abs/2506.23721)
**中文标题：基于深度学习的语义分割与增强现实辅助超声的实时肾脏成像与测量**

*Gijs Luijten,Roberto Maria Scardigno,Lisle Faray de Paiva,Peter Hoyer,Jens Kleesiek,Domenico Buongiorno,Vitoantonio Bevilacqua,Jan Egger*

主要分类: eess.IV

摘要简述: 本文提出了一种结合深度学习和增强现实的实时肾脏超声成像与测量方法，通过自动化分割和AR投影提升临床操作的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 超声成像虽广泛使用但学习曲线陡峭，且医生需频繁切换视线，增加了操作负担。本文旨在通过深度学习和增强现实技术解决这些问题，提升肾脏体积测量的效率和临床实用性。

研究方法: 提出两种基于HoloLens-2的AR-DL辅助超声流程：一种通过API实现无线流传输，另一种支持任何视频输出的超声设备。使用Open Kidney Dataset和开源分割模型（如nnU-Net、Segmenter等）评估实时性和准确性。

研究结果: 实验验证了实时肾脏分割和体积测量的可行性，开源GitHub流程包括模型实现、测量算法和Wi-Fi流传输方案，显著提升了超声培训和诊断效率。

研究结论: 结合深度学习和增强现实的技术方案能够有效解决超声成像的操作难题，为临床提供更高效、准确的肾脏测量工具。

中文摘要: 超声（US）因其广泛可及性和无辐射性而被广泛使用，但由于其动态特性和非标准成像平面，学习曲线陡峭。此外，医生需频繁在超声屏幕和患者之间切换视线，增加了操作难度。为解决这些问题，我们集成了基于深度学习（DL）的语义分割技术，实现实时（RT）自动肾脏体积测量，这对临床评估至关重要，但传统方法耗时且易疲劳。这种自动化使医生能专注于图像解读而非手动测量。结合增强现实（AR），超声的可用性进一步提升，AR将显示直接投影到医生视野中，改善了人体工学并减少了视线切换的认知负担。我们提出了两种基于HoloLens-2的AR-DL辅助超声流程：一种通过API实现无线流传输，另一种支持任何视频输出的超声设备以提高普及性。我们使用Open Kidney Dataset和开源分割模型（nnU-Net、Segmenter、YOLO结合MedSAM和LiteMedSAM）评估了实时性和准确性。我们的开源GitHub流程包括模型实现、测量算法和基于Wi-Fi的流传输方案，显著提升了超声培训和诊断效率，尤其在即时护理场景中。

</details>


### [386] [High Resolution Isotropic 3D Cine imaging with Automated Segmentation using Concatenated 2D Real-time Imaging and Deep Learning](https://arxiv.org/abs/2506.22532)
**中文标题：基于2D实时成像与深度学习的高分辨率各向同性3D动态影像自动分割方法**

*Mark Wrobel,Michele Pascale,Tina Yao,Ruaraidh Campbell,Elena Milano,Michael Quail,Jennifer Steeden,Vivek Muthurangu*

主要分类: eess.IV

摘要简述: 本研究提出了一种结合2D实时成像与深度学习的方法，用于生成高分辨率各向同性3D动态影像，并在10例患者中验证了其与传统成像方法的一致性。


<details>
  <summary>详细信息</summary>
研究动机: 传统心血管磁共振（CMR）在儿科和先天性心脏病中使用2D屏息平衡稳态自由进动（bSSFP）动态成像评估功能，以及心脏门控、呼吸导航的静态3D bSSFP全心脏成像评估解剖结构。本研究旨在通过结合2D自由呼吸实时动态影像和深度学习，生成各向同性、完全分割的3D动态数据集。

研究方法: 研究训练了四种深度学习模型，分别用于：a) 层间对比度校正；b) 层间呼吸运动校正；c) 超分辨率（层方向）；d) 分割左右心房和心室（RA、LA、RV、LV）、胸主动脉（Ao）和肺动脉（PA）。在10例接受常规心血管检查的患者中，验证了该方法在矢状面实时动态影像堆栈上的表现。

研究结果: 所有实时数据均成功转换为3D动态影像，后处理时间均小于1分钟。左心室和右心室的测量指标与传统方法无显著偏差，且相关性良好。血管直径测量结果也较为一致，但肺动脉直径存在轻微高估。

研究结论: 研究表明，通过结合2D实时动态影像和深度学习模型，可以快速生成3D动态数据集。该方法采集和重建时间短，完全分割数据可在2分钟内完成，与传统成像方法的一致性表明其有望显著加快临床CMR检查速度。

中文摘要: 背景：传统心血管磁共振（CMR）在儿科和先天性心脏病中采用2D屏息平衡稳态自由进动（bSSFP）动态成像评估功能，以及心脏门控、呼吸导航的静态3D bSSFP全心脏成像评估解剖结构。本研究旨在通过结合2D自由呼吸实时动态影像堆栈和深度学习（DL），生成各向同性、完全分割的3D动态数据集。方法：训练了四种DL模型，分别用于：a) 层间对比度校正；b) 层间呼吸运动校正；c) 超分辨率（层方向）；d) 分割左右心房和心室（RA、LA、RV、LV）、胸主动脉（Ao）和肺动脉（PA）。在10例接受常规心血管检查的患者中，前瞻性采集矢状面实时动态影像堆栈以验证该方法。定量指标（心室容积和血管直径）和3D动态影像质量与传统屏息动态和全心脏成像进行比较。结果：所有实时数据均成功转换为3D动态影像，后处理时间均小于1分钟。左心室和右心室的测量指标与传统方法无显著偏差，且相关性良好。血管直径测量结果也较为一致，但肺动脉直径存在轻微高估。结论：本研究展示了通过结合2D实时动态影像和一系列DL模型生成3D动态数据的潜力。该方法采集和重建时间短，完全分割数据可在2分钟内完成，与传统成像方法的一致性表明其有望显著加快临床CMR检查速度。

</details>


### [387] [ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge](https://arxiv.org/abs/2506.22790)
**中文标题：ICME 2025通用HDR和SDR视频质量测量大挑战**

*Yixu Chen,Bowen Chen,Hai Wei,Alan C. Bovik,Baojun Li,Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai,Dounia Hammou,Fei Yin,Rafal Mantiuk,Amritha Premkumar,Prajit T Rajendran,Vignesh V Menon*

主要分类: eess.IV

摘要简述: 本文介绍了ICME 2025关于通用HDR和SDR视频质量测量的挑战赛，旨在推动视频质量评估（VQA）方法的发展，尤其是针对高动态范围（HDR）和标准动态范围（SDR）内容的通用性评估。


<details>
  <summary>详细信息</summary>
研究动机: 随着视频技术的快速发展，尤其是HDR和SDR内容的普及，现有VQA模型在动态范围、失真类型和内容多样性方面表现不一致，亟需开发更通用且鲁棒的VQA方法。

研究方法: 本次挑战赛设立了全参考（FR）和无参考（NR）两个赛道，吸引了五支团队提交七种模型和技术报告，旨在评估和推广能够同时处理HDR和SDR内容的VQA方法。

研究结果: 在最终评估阶段，四种方法超越了VMAF基线，其中表现最佳的模型达到了最先进的性能，为通用视频质量评估设立了新标杆。

研究结论: 挑战赛成功推动了通用VQA方法的发展，展示了在HDR和SDR内容上的优异性能，为未来研究提供了重要参考。

中文摘要: 本文报告了IEEE国际多媒体与博览会（ICME）2025关于通用HDR和SDR视频质量测量的大挑战。随着视频技术的快速发展，尤其是高动态范围（HDR）和标准动态范围（SDR）内容的普及，对鲁棒且通用的视频质量评估（VQA）方法的需求日益增长。现有的VQA模型往往难以在不同动态范围、失真类型和多样化内容中表现一致。本次挑战赛旨在评估和推广能够同时处理HDR和SDR内容的VQA方法。在最终评估阶段，五支团队向全参考（FR）和无参考（NR）赛道提交了七种模型及技术报告。其中，四种方法超越了VMAF基线，而表现最佳的模型达到了最先进的性能，为通用视频质量评估设立了新标杆。

</details>


### [388] [CA-Diff: Collaborative Anatomy Diffusion for Brain Tissue Segmentation](https://arxiv.org/abs/2506.22882)
**中文标题：CA-Diff：用于脑组织分割的协作解剖扩散**

*Qilong Xing,Zikai Song,Yuteng Ye,Yuke Chen,Youjia Zhang,Na Feng,Junqing Yu,Wei Yang*

主要分类: eess.IV

摘要简述: 本文提出了一种名为CA-Diff的协作解剖扩散框架，通过整合空间解剖特征提升扩散模型在脑MRI分割中的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的CNN和基于Transformer的方法在脑MRI复杂结构分割中表现不佳，而当前扩散模型因忽略解剖信息而直接应用于脑MRI时效果有限。因此，本文旨在通过整合解剖特征提升分割精度。

研究方法: CA-Diff框架引入距离场作为辅助解剖条件以提供全局空间上下文，并通过协作扩散过程建模其与解剖结构的联合分布。此外，设计了一致性损失优化距离场与解剖结构的关系，并引入时间适应通道注意力模块以增强U-Net特征融合。

研究结果: 实验表明，CA-Diff在脑MRI分割任务中优于现有最先进方法。

研究结论: CA-Diff通过有效利用解剖特征和优化特征融合，显著提升了脑MRI分割的准确性。

中文摘要: 脑MRI结构的准确分割对评估脑形态至关重要，但现有的CNN和基于Transformer的方法在复杂结构分割中表现不佳。尽管当前扩散模型在图像分割中显示出潜力，但由于忽略解剖信息，直接应用于脑MRI时效果有限。为此，我们提出协作解剖扩散（CA-Diff），该框架整合空间解剖特征以提升扩散模型的分割精度。具体而言，我们引入距离场作为辅助解剖条件以提供全局空间上下文，并通过协作扩散过程建模其与解剖结构的联合分布，从而有效利用解剖特征进行分割。此外，我们引入一致性损失优化距离场与解剖结构的关系，并设计时间适应通道注意力模块以增强U-Net特征融合过程。大量实验表明，CA-Diff优于现有最先进方法。

</details>


### [389] [Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization](https://arxiv.org/abs/2506.22952)
**中文标题：基于状态空间的向量量化对大脑动态的分层表征**

*Yanwu Yang,Thomas Wolfers*

主要分类: eess.IV

摘要简述: 本文提出了一种名为HST的分层状态空间标记化网络，通过改进的向量量化变分自编码器（VQ-VAE）量化大脑状态和转换，有效捕捉大脑动态层次结构，并在疾病诊断和重建性能中展现潜力。


<details>
  <summary>详细信息</summary>
研究动机: 功能磁共振成像（fMRI）在捕捉大脑功能状态转换方面仍面临挑战。现有方法大多忽略大脑转换依赖关系，且缺乏对大脑动态的稳定嵌入量化。本文旨在通过分层状态空间模型量化大脑状态和转换，提供更稳定和代表性的标记表示。

研究方法: 提出HST网络，基于状态空间模型分层量化大脑状态和转换。采用改进的聚类向量量化变分自编码器（VQ-VAE），结合量化误差反馈和聚类，提升量化性能并促进稳定标记表示。

研究结果: 在两个公开fMRI数据集上验证了HST的有效性，展示了其在量化大脑层次动态、疾病诊断和重建性能方面的潜力。

研究结论: HST为大脑动态表征提供了有前景的框架，有助于分析大脑的亚稳态特性，为神经科学研究提供了新工具。

中文摘要: 通过功能磁共振成像（fMRI）理解大脑动态仍是神经科学的基本挑战，尤其是在捕捉大脑功能状态转换方面。亚稳态（暂时稳定的大脑状态）为将复杂大脑信号量化为可解释的离散表示提供了新范式。与基于聚类的机器学习方法相比，利用向量量化的标记化方法在表示学习中展现出强大的重建和预测能力。然而，现有方法大多忽略大脑转换依赖关系，且缺乏对大脑动态的稳定嵌入量化。本研究提出了一种分层状态空间标记化网络（HST），基于状态空间模型分层量化大脑状态和转换。我们引入了一种改进的聚类向量量化变分自编码器（VQ-VAE），结合量化误差反馈和聚类，提升量化性能的同时促进亚稳态的稳定标记表示。在两个公开fMRI数据集上验证了HST的有效性，展示了其在量化大脑层次动态、疾病诊断和重建性能方面的潜力。该方法为大脑动态表征提供了有前景的框架，有助于分析亚稳态。

</details>


### [390] [MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation](https://arxiv.org/abs/2506.23102)
**中文标题：MedRegion-CT：面向区域的多模态大语言模型用于全面3D CT报告生成**

*Sunggu Kyung,Jinyoung Seo,Hyunseok Lim,Dongyeong Kim,Hyungbin Park,Jimin Sung,Jihyun Kim,Wooyoung Jo,Yoojin Nam,Namkug Kim*

主要分类: eess.IV

摘要简述: MedRegion-CT是一种区域聚焦的多模态大语言模型框架，通过创新方法提取3D CT特征并生成临床相关报告，显著提升了报告生成的质量和临床相关性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法主要关注全局特征，难以捕捉区域特异性细节，可能导致某些异常被忽略。因此，需要一种能够专注于临床相关区域的方法来提升CT报告生成的准确性和全面性。

研究方法: 1. 引入区域代表性（R²）令牌池化，利用预训练的2D视觉模型提取3D CT特征，生成全局令牌和区域令牌；2. 使用通用分割模型生成伪掩码，并通过掩码编码器提取区域中心特征；3. 利用分割结果提取患者特定属性（如器官大小、位置等），并将其转换为文本提示以丰富模型理解。

研究结果: 在RadGenome-Chest CT数据集上的实验表明，MedRegion-CT在自然语言生成质量和临床相关性方面均优于现有方法，同时保持了可解释性。

研究结论: MedRegion-CT通过区域聚焦的多模态方法，显著提升了CT报告生成的性能，为临床诊断提供了更全面和准确的工具。

中文摘要: 近期发布的RadGenome-Chest CT显著推动了基于CT的报告生成。然而，现有方法主要关注全局特征，难以捕捉区域特异性细节，可能导致某些异常被忽略。为此，我们提出了MedRegion-CT，一种区域聚焦的多模态大语言模型（MLLM）框架，具有三项关键创新。首先，我们引入了区域代表性（R²）令牌池化，利用预训练的2D视觉模型高效提取3D CT特征。该方法生成代表整体切片特征的全局令牌和突出目标区域的区域令牌，使MLLM能够有效处理全面信息。其次，通过通用分割模型生成伪掩码，并由掩码编码器提取区域中心特征，使MLLM能够专注于六个预定义的临床相关区域。第三，我们利用分割结果提取患者特定属性（如器官大小、直径和位置），并将其转换为文本提示，以丰富MLLM对患者特定上下文的理解。为确保严格评估，我们在RadGenome-Chest CT上进行了报告生成的基准实验。MedRegion-CT取得了最先进的性能，在自然语言生成质量和临床相关性方面优于现有方法，同时保持了可解释性。我们的框架代码已公开。

</details>


### [391] [Multi-Source COVID-19 Detection via Variance Risk Extrapolation](https://arxiv.org/abs/2506.23208)
**中文标题：基于方差风险外推的多源COVID-19检测**

*Runtian Yuan,Qingqiu Li,Junlin Hou,Jilan Xu,Yuejie Zhang,Rui Feng,Hao Chen*

主要分类: eess.IV

摘要简述: 本文提出了一种通过方差风险外推（VREx）和多源数据增强（Mixup）的方法，用于多源COVID-19检测任务，解决了不同医疗机构数据间的域偏移问题，实现了高泛化性能。


<details>
  <summary>详细信息</summary>
研究动机: 多源COVID-19检测任务中，不同医疗机构的CT扫描数据存在域偏移问题（如成像协议、扫描设备和患者群体的差异），导致模型泛化能力受限。本文旨在通过改进训练方法，提升模型在跨域数据上的性能。

研究方法: 结合方差风险外推（VREx）和多源数据增强（Mixup）。VREx通过最小化多源数据的经验风险方差，减少对特定中心特征的过拟合，学习域不变表示；Mixup通过对输入和标签的随机插值，增强模型的线性行为和抗噪能力。

研究结果: 在验证集上，模型在四个数据源上的平均宏F1分数达到0.96，表现出强大的跨域泛化能力。

研究结论: 通过VREx和Mixup的结合，本文方法有效解决了多源数据中的域偏移问题，显著提升了模型的泛化性能，为COVID-19检测任务提供了可靠的技术支持。

中文摘要: 本文介绍了我们在多源COVID-19检测挑战中的解决方案，该任务旨在将来自四个不同医院和医疗中心的胸部CT扫描分类为COVID和非COVID类别。任务的主要挑战在于不同机构间成像协议、扫描设备和患者群体的差异导致的域偏移。为了提升模型的跨域泛化能力，我们在训练过程中引入了方差风险外推（VREx）。VREx通过显式最小化多源数据的经验风险方差，促使模型在多个源域上保持一致的性能。这种正则化策略减少了对特定中心特征的过拟合，促进了域不变表示的学习。我们还应用了Mixup数据增强以进一步提升泛化和鲁棒性。Mixup通过对随机选择的训练样本对进行输入和标签的插值，鼓励模型在样本间表现出线性行为，并增强其对噪声和有限数据的适应能力。我们的方法在验证集上实现了四个数据源平均宏F1分数0.96的优异表现，展示了强大的泛化能力。

</details>


### [392] [Improving Myocardial Infarction Detection via Synthetic ECG Pretraining](https://arxiv.org/abs/2506.23259)
**中文标题：通过合成心电图预训练改进心肌梗死检测**

*Lachin Naghashyar*

主要分类: eess.IV

摘要简述: 通过合成心电图预训练提升心肌梗死检测准确性，尤其在数据稀缺时显著提高分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 心肌梗死是全球主要死因之一，早期准确诊断至关重要。深度学习模型虽能自动解读心电图，但依赖大量标注数据，而实际中此类数据稀缺。

研究方法: 提出一种生理学感知流程：(i) 合成具有可调心肌梗死形态和真实噪声的12导联心电图；(ii) 使用自监督掩码自编码和联合重建-分类目标预训练循环和变压器分类器。

研究结果: 合成心电图的真实感通过统计和视觉分析验证，关键形态特征得以保留。预训练显著提升分类性能，尤其在低数据情况下，AUC提升高达4个百分点。

研究结论: 研究表明，在临床数据有限时，可控的合成心电图有助于提升心肌梗死检测性能。

中文摘要: 心肌梗死是全球主要死因之一，通过心电图（ECG）进行早期准确诊断仍是临床重点。深度学习模型在自动解读心电图方面表现出潜力，但需要大量标注数据，而这些数据在实践中往往稀缺。我们提出了一种生理学感知流程：(i) 合成具有可调心肌梗死形态和真实噪声的12导联心电图；(ii) 使用自监督掩码自编码和联合重建-分类目标预训练循环和变压器分类器。通过统计和视觉分析验证了合成心电图的真实感，确认关键形态特征得以保留。在合成数据上预训练显著提升了分类性能，尤其在低数据情况下，AUC提升高达4个百分点。这些结果表明，在真实临床数据有限时，可控的合成心电图有助于提升心肌梗死检测性能。

</details>


### [393] [BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia](https://arxiv.org/abs/2506.23305)
**中文标题：BPD-Neo：用于新生儿支气管肺发育不良的肺部-气管分割的MRI数据集及临床数据**

*Rachit Saluja,Arzu Kovanlikaya,Candace Chien,Lauren Kathryn Blatt,Jeffrey M. Perlman,Stefan Worgall,Mert R. Sabuncu,Jonathan P. Dyke*

主要分类: eess.IV

摘要简述: 本文介绍了BPD-Neo数据集，包含40名新生儿的肺部MRI扫描和气管分割数据，旨在支持支气管肺发育不良（BPD）的研究和临床诊断。


<details>
  <summary>详细信息</summary>
研究动机: 支气管肺发育不良（BPD）是早产儿常见并发症，目前诊断主要依赖X射线，但MRI能提供无创且更详细的肺部信息。本研究旨在通过提供MRI数据集和分割模型，推动BPD的精准诊断和研究。

研究方法: 研究收集了40名新生儿的自由呼吸3D MRI数据（StarVIBE系列），并提供了肺部与气管的语义分割标注。同时，数据集包含临床数据和基线分割模型，并通过临床评估验证。

研究结果: 数据集包含高质量的MRI扫描和分割标注，为BPD研究提供了重要资源。基线分割模型经过验证，可用于辅助临床诊断。

研究结论: BPD-Neo数据集为新生儿BPD的MRI研究和临床诊断提供了宝贵资源，未来可进一步优化分割算法以提升诊断效果。

中文摘要: 支气管肺发育不良（BPD）是早产儿常见并发症，新生儿重症监护病房（NICU）通常采用便携式X射线作为标准诊断手段。然而，肺部磁共振成像（MRI）提供了一种无需镇静和辐射的非侵入性替代方案，同时能深入揭示BPD的潜在机制。通过利用高分辨率3D MRI数据，可以开发先进的图像处理和语义分割算法，辅助临床医生识别BPD的病因。本数据集提供了40名新生儿的MRI扫描及相应的肺部和气管语义分割标注，其中大多数患儿被诊断为BPD。影像数据采用自由呼吸3D StarVIBE径向梯度回波序列采集。此外，我们还提供了全面的临床数据和基线分割模型，并通过临床评估验证，以支持新生儿肺部影像的进一步研究和开发。

</details>


### [394] [SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting](https://arxiv.org/abs/2506.23309)
**中文标题：SurgTPGS：基于文本提示的高斯泼溅语义3D手术场景理解**

*Yiming Huang,Long Bai,Beilei Cui,Kun Yuan,Guankun Wang,Mobarakol Islam,Nicolas Padoy,Nassir Navab,Hongliang Ren*

主要分类: eess.IV

摘要简述: SurgTPGS是一种基于文本提示的高斯泼溅方法，用于3D手术场景的语义理解，结合了分割模型和视觉语言模型，支持实时文本提示查询，提升了手术场景的重建质量和语义平滑性。


<details>
  <summary>详细信息</summary>
研究动机: 当前手术研究和实践中，准确理解3D手术场景并支持文本提示功能对手术规划和实时术中指导至关重要。然而，现有方法分别关注手术视觉语言模型、3D重建和分割，缺乏对实时文本提示3D查询的支持。

研究方法: 提出SurgTPGS方法，结合分割模型和视觉语言模型，学习3D语义特征；引入语义感知变形跟踪和语义区域感知优化，提升重建质量和语义平滑性。

研究结果: 在两个真实手术数据集上的实验表明，SurgTPGS优于现有方法，显著提升了手术场景的重建精度和语义理解能力。

研究结论: SurgTPGS通过增强手术精度和安全性，为下一代智能手术系统的发展奠定了基础。

中文摘要: 在当代手术研究和实践中，准确理解支持文本提示功能的3D手术场景对手术规划和实时术中指导尤为重要，其中精确识别和交互手术工具与解剖结构至关重要。然而，现有工作分别关注手术视觉语言模型（VLM）、3D重建和分割，缺乏对实时文本提示3D查询的支持。本文提出SurgTPGS，一种新颖的文本提示高斯泼溅方法以填补这一空白。我们引入了一种结合分割模型和先进视觉语言模型的3D语义特征学习策略，提取分割语言特征用于3D手术场景重建，从而更深入理解复杂手术环境。此外，我们提出语义感知变形跟踪，捕捉语义特征的无缝变形，为纹理和语义特征提供更精确的重建。我们还提出语义区域感知优化，利用基于区域的语义信息监督训练，显著提升重建质量和语义平滑性。在两个真实手术数据集上的全面实验证明了SurgTPGS优于现有方法，凸显了其革新手术实践的潜力。SurgTPGS通过提升手术精度和安全性，为开发下一代智能手术系统铺平了道路。代码发布于：https://github.com/lastbasket/SurgTPGS。

</details>


### [395] [FD-DiT: Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction](https://arxiv.org/abs/2506.23466)
**中文标题：FD-DiT：基于频域引导的扩散变换器用于低剂量CT重建**

*Qiqing Liu,Guoquan Wei,Zekun Zhou,Yiyang Wen,Liu Shi,Qiegen Liu*

主要分类: eess.IV

摘要简述: 本文提出了一种基于频域引导的扩散变换器（FD-DiT）方法，用于低剂量CT图像重建，通过频域解耦和混合去噪网络优化细节保留和噪声抑制，实验证明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 低剂量CT（LDCT）虽减少辐射暴露，但图像易受噪声和伪影影响，影响诊断准确性。现有方法在保留细节方面存在不足，因此需要一种更有效的方法。

研究方法: FD-DiT采用扩散策略逐步引入噪声，并通过频域解耦技术将噪声集中在高频域，结合混合去噪网络和滑动稀疏局部注意力优化重建过程，提出动态融合策略整合组件。

研究结果: 实验表明，FD-DiT在相同剂量下能更有效地抑制噪声和伪影，优于现有方法。

研究结论: FD-DiT通过频域引导和动态融合策略显著提升了LDCT图像重建质量，为临床诊断提供了更可靠的图像支持。

中文摘要: 低剂量计算机断层扫描（LDCT）虽降低了辐射暴露，但由于量子噪声和电子噪声的影响，图像易出现伪影和细节丢失，可能影响诊断准确性。结合变换器和扩散模型的图像生成方法显示出潜力，但现有方法在保留细节方面仍有局限。为此，本文提出了一种频域引导的扩散变换器（FD-DiT）用于LDCT重建。FD-DiT的核心是一种扩散策略，逐步引入噪声直至数据分布与LDCT数据统计对齐，随后进行去噪处理。此外，采用频域解耦技术将噪声主要集中于高频域，从而更有效地捕捉关键解剖结构和细节。通过混合去噪网络优化整体重建过程，并结合滑动稀疏局部注意力增强高频噪声识别能力，利用浅层信息的稀疏性和局部性，通过跳跃连接提升特征表示。最后，提出一种可学习的动态融合策略以实现组件的最优整合。实验结果表明，在相同剂量下，FD-DiT重建的LDCT图像在噪声和伪影抑制方面优于现有方法。

</details>


### [396] [AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm](https://arxiv.org/abs/2506.23537)
**中文标题：AFUNet：基于深度展开范式的交叉迭代对齐-融合协同HDR重建方法**

*Xinyue Li,Zhangkai Ni,Wenhan Yang*

主要分类: eess.IV

摘要简述: 本文提出AFUNet，一种基于深度展开范式的HDR重建方法，通过交替优化对齐和融合子任务，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于学习的方法在HDR重建中依赖经验设计，缺乏理论支持，影响可靠性。AFUNet旨在通过理论驱动的交替优化解决这一问题。

研究方法: AFUNet将HDR重建分解为对齐和融合两个子任务，通过交替优化的方式实现协同。采用深度展开范式，设计对齐融合模块（AFM），逐步解决内容错位和曝光差异。

研究结果: 实验表明，AFUNet在定性和定量评估中均优于现有方法，性能显著提升。

研究结论: AFUNet通过理论驱动的交替优化方法，实现了HDR重建的高性能，为未来研究提供了新思路。

中文摘要: 现有的基于学习的方法能够从多曝光LDR输入中有效重建HDR图像，扩展动态范围并提升细节，但这些方法更多依赖经验设计而非理论基础，可能影响其可靠性。为解决这一问题，我们提出了交叉迭代对齐与融合深度展开网络（AFUNet），将HDR重建系统性地分解为对齐和融合两个交替优化的子任务，通过协同作用提升整体性能。我们的方法从最大后验概率（MAP）估计的角度出发，明确整合了LDR图像间的空间对应先验，并通过联合约束自然桥接对齐和融合子问题。基于数学基础，我们通过展开重新构想传统迭代优化过程，将其转化为端到端可训练的AFUNet，并设计了逐步工作的模块。具体而言，AFUNet的每次迭代包含一个对齐融合模块（AFM），交替使用空间对齐模块（SAM）进行对齐和通道融合模块（CFM）进行自适应特征融合，逐步解决内容错位和曝光差异。广泛的定性和定量评估表明，AFUNet性能优越，一致超越现有方法。代码已开源：https://github.com/eezkni/AFUNet

</details>


### [397] [Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation](https://arxiv.org/abs/2506.23664)
**中文标题：基于扩散模型的胎儿头部超声分割数据增强方法**

*Fangyijie Wang,Kevin Whelan,Félix Balado,Guénolé Silvestre,Kathleen M. Curran*

主要分类: eess.IV

摘要简述: 本文提出了一种基于扩散模型的胎儿头部超声图像分割数据增强方法，通过生成合成图像与分割掩码对，有效提升有限真实数据下的分割性能，达到领先水平。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像数据因隐私和法规限制难以获取，且标注成本高。为解决这一问题，利用生成式AI生成合成数据成为一种可行方案。

研究方法: 采用扩散模型生成合成胎儿头部超声图像及其分割掩码，用于增强真实数据集，并用于监督微调Segment Anything Model (SAM)。

研究结果: 合成数据能有效捕捉真实图像特征，使用少量真实图像对即可达到94.66%和94.38%的Dice分数（西班牙和非洲队列）。

研究结论: 该方法在有限真实数据下实现了领先的胎儿头部超声图像分割性能，为医学图像分析提供了高效解决方案。

中文摘要: 医学图像数据因隐私和法规限制较难获取，且标注需临床专家耗时费力的手动操作。为应对这些挑战，合成医学数据生成成为一种有前景的解决方案。生成式AI（GenAI）通过生成式深度学习模型，已证明能有效生成逼真的合成图像。本研究提出了一种新颖的掩码引导生成式AI方法，利用扩散模型生成合成胎儿头部超声图像及其分割掩码对。这些合成数据对用于增强真实数据集，以监督微调Segment Anything Model（SAM）。结果表明，合成数据能有效捕捉真实图像特征，该方法在有限真实图像对下达到了领先的胎儿头部分割性能，尤其在西班牙和非洲队列中分别达到了94.66%和94.38%的Dice分数。我们的代码、模型和数据已在GitHub上公开。

</details>


### [398] [MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation](https://arxiv.org/abs/2506.23700)
**中文标题：MedSAM-CA：一种基于注意力增强多尺度融合的CNN增强ViT模型用于医学图像分割**

*Peiting Tian,Xi Chen,Haixia Bi,Fan Li*

主要分类: eess.IV

摘要简述: MedSAM-CA是一种基于预训练模型MedSAM的架构级微调方法，通过引入CBR-Net和Atte-FFB模块，解决了医学图像分割中对大规模标注数据的依赖和边界模糊问题，在低资源临床环境中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割在临床诊断和治疗规划中至关重要，但现有方法依赖大规模标注数据且难以应对低对比度和模糊边界等挑战。MedSAM-CA旨在减少对标注数据的依赖并提升边界分割精度。

研究方法: MedSAM-CA结合了CBR-Net和Atte-FFB模块。CBR-Net通过卷积处理补充长程注意力机制忽略的边界信息，Atte-FFB则在解码器中融合多级细粒度特征与全局表征，提升边界分割准确性。

研究结果: 在公开数据集（皮肤镜、CT和MRI）上的实验表明，MedSAM-CA仅需2%的训练数据即可达到94.43%的Dice分数，接近全数据训练的97.25%性能，验证了其在低资源环境中的有效性。

研究结论: MedSAM-CA通过架构级微调和多尺度特征融合，显著降低了医学图像分割对标注数据的依赖，并在边界分割精度上取得突破，为临床低资源场景提供了实用解决方案。

中文摘要: 医学图像分割在临床诊断和治疗规划中扮演关键角色，其精确的边界划分对病灶定位、器官识别和定量评估至关重要。近年来，基于深度学习的方法显著提升了分割精度，但仍面临两大挑战：一是依赖大规模标注数据，而医学场景中因隐私和高标注成本难以获取；二是低对比度成像和恶性肿瘤导致的模糊边界阻碍了精确分割。为解决这些问题，我们提出MedSAM-CA，一种基于预训练模型Medical Segment Anything（MedSAM）的架构级微调方法。MedSAM-CA引入两个关键模块：卷积注意力增强边界细化网络（CBR-Net）和注意力增强特征融合块（Atte-FFB）。CBR-Net与MedSAM编码器并行运行，通过分层卷积处理补充长程注意力机制忽略的边界信息；Atte-FFB嵌入解码器，融合来自CBR-Net跳连的多级细粒度特征与解码器上采样的全局表征，提升边界划分精度。在皮肤镜、CT和MRI公开数据集上的实验验证了MedSAM-CA的有效性。在皮肤镜数据集中，仅使用2%的训练数据即可达到94.43%的Dice分数，接近全数据训练的97.25%性能，展示了其在低资源临床环境中的强大实用性。

</details>


### [399] [MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction](https://arxiv.org/abs/2506.23701)
**中文标题：MDPG：用于MRI重建的多域扩散先验引导**

*Lingtong Zhang,Mengdie Song,Xiaohan Hao,Huayu Mai,Bensheng Qiu*

主要分类: eess.IV

摘要简述: 本文提出了一种多域扩散先验引导（MDPG）方法，通过预训练的潜在扩散模型（LDMs）提升MRI重建任务的数据一致性，结合视觉-Mamba主干和双域融合分支（DFB），实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: MRI重建在医学诊断中至关重要，但现有扩散模型因随机性难以生成高保真图像。潜在扩散模型（LDMs）在潜在域中提供了紧凑且详细的先验知识，可有效引导模型学习原始数据分布。

研究方法: 1. 构建基于视觉-Mamba的主干网络，高效编码和重建欠采样图像；2. 集成预训练LDMs，在潜在域和图像域提供条件先验；3. 提出潜在引导注意力（LGA）实现多级潜在域融合；4. 设计双域融合分支（DFB）结合k空间和图像域先验；5. 基于非自动校准信号（NACS）的k空间正则化策略增强数据一致性。

研究结果: 在两个公开MRI数据集上的实验表明，MDPG方法显著提升了MRI重建的质量和数据一致性。

研究结论: MDPG通过多域扩散先验引导和双域融合，有效提升了MRI重建的性能，为医学影像处理提供了新思路。

中文摘要: 磁共振成像（MRI）重建在医学诊断中至关重要。作为最新的生成模型，扩散模型（DMs）因其在图像域中的随机性难以生成高保真图像。潜在扩散模型（LDMs）在潜在域中提供了紧凑且详细的先验知识，可有效引导模型学习原始数据分布。受此启发，我们提出多域扩散先验引导（MDPG），利用预训练LDMs增强MRI重建任务的数据一致性。具体而言，我们首先构建基于视觉-Mamba的主干网络，高效编码和重建欠采样图像；随后集成预训练LDMs，在潜在域和图像域提供条件先验；提出潜在引导注意力（LGA）实现多级潜在域融合；同时，通过双域融合分支（DFB）结合k空间和图像域先验进行自适应引导；最后，基于非自动校准信号（NACS）的k空间正则化策略进一步增强了数据一致性。在两个公开MRI数据集上的实验充分验证了该方法的有效性。代码发布于https://github.com/Zolento/MDPG。

</details>


### [400] [Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos](https://arxiv.org/abs/2506.23759)
**中文标题：时空表示解耦与增强的联邦手术视频器械分割方法**

*Zheng Fang,Xiaoming Qi,Chun-Mei Feng,Jialun Pei,Weixin Si,Yueming Jin*

主要分类: eess.IV

摘要简述: 本文提出了一种名为FedST的个性化联邦学习方案，通过时空表示解耦与增强技术，优化手术视频中的器械分割任务。该方法利用手术领域的知识，在本地和全局训练中分别设计机制，提升分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在手术数据科学中应用有限，且现有方法未考虑手术领域的特性：不同场景具有多样化的解剖背景但器械表示高度相似，以及手术模拟器可低成本生成大规模合成数据。本文旨在解决这些问题。

研究方法: 提出FedST方案，包括本地训练中的表示分离与合作机制（RSC）解耦查询嵌入层以编码背景，全局训练中设计基于合成数据的显式表示量化（SERQ）以同步模型融合。

研究结果: FedST通过解耦和增强时空表示，显著提升了手术器械分割的性能，同时利用合成数据优化了模型的泛化能力。

研究结论: FedST通过结合手术领域知识和合成数据，有效解决了联邦学习在手术器械分割中的挑战，为未来研究提供了新思路。

中文摘要: 联邦学习（FL）下的手术器械分割是一个有前景的方向，允许多个手术中心在不集中数据集的情况下协作训练模型。然而，手术数据科学中的FL研究非常有限，且其他模态的FL方法未考虑手术领域的固有特性：i）不同场景具有多样化的解剖背景但器械表示高度相似；ii）手术模拟器可低成本生成大规模合成数据。本文提出了一种新颖的个性化FL方案——时空表示解耦与增强（FedST），在本地和全局训练中巧妙利用手术领域知识以提升分割性能。具体而言，本地训练中采用表示分离与合作（RSC）机制，解耦查询嵌入层以私有化训练，编码各自的背景；同时其他参数全局优化以捕捉器械的一致表示，包括捕捉相似运动模式的时序层。此外，设计了文本引导的通道选择以突出站点特定特征，促进模型适应每个站点。全局训练中，提出基于合成数据的显式表示量化（SERQ），定义显式表示目标以同步模型融合中的收敛，提升模型泛化能力。

</details>


### [401] [ShapeKit](https://arxiv.org/abs/2506.24003)
**中文标题：ShapeKit：提升全身医学分割形状准确性的工具包**

*Junqi Liu,Dongli He,Wenxuan Li,Ningyu Wang,Alan L. Yuille,Zongwei Zhou*

主要分类: eess.IV

摘要简述: 本文提出ShapeKit工具包，通过专注于形状优化，无需重新训练模型即可将全身医学分割的准确性提升8%以上，优于传统模型架构调整的边际增益（<3%）。


<details>
  <summary>详细信息</summary>
研究动机: 研究发现，现有的医学分割方法在形状准确性上表现不足，而模型架构调整带来的改进有限（<3%）。因此，作者提出开发一个专注于形状优化的工具包，以显著提升分割性能。

研究方法: 作者开发了ShapeKit，一个灵活且易于集成的工具包，专注于优化解剖形状的准确性。该工具包无需重新训练或微调模型，可直接应用于现有分割结果。

研究结果: 实验表明，ShapeKit能够将医学分割的准确性提升超过8%，显著优于传统模型架构调整的边际增益（<3%）。

研究结论: 本文强调了形状优化工具在医学分割中的重要性，ShapeKit的提出为社区提供了一种高效且无需额外训练的形状优化解决方案。

中文摘要: 本文提出了一种实用的方法，用于提升全身医学分割中的解剖形状准确性。分析表明，专注于形状的工具包可将分割性能提升超过8%，而无需重新训练或微调模型。相比之下，模型架构的修改通常仅带来不足3%的边际增益。基于这一观察，我们引入了ShapeKit，一个灵活且易于集成的工具包，旨在优化解剖形状。本研究凸显了形状工具在医学分割中被低估的价值，并呼吁社区关注其潜在影响。

</details>


### [402] [C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism](https://arxiv.org/abs/2506.24074)
**中文标题：C3VDv2——增强真实性的结肠镜3D视频数据集**

*Mayank V. Golhar,Lucas Sebastian Galeano Fretes,Loren Ayers,Venkata S. Akshintala,Taylor L. Bobrow,Nicholas J. Durr*

主要分类: eess.IV

摘要简述: 本文介绍了C3VDv2数据集，这是一个增强真实性的结肠镜3D视频数据集，旨在支持3D结肠重建算法的开发和评估。


<details>
  <summary>详细信息</summary>
研究动机: 由于缺乏用于训练和验证的3D结肠镜数据集，计算机视觉技术在结肠镜诊断中的应用受到限制。C3VDv2旨在填补这一空白，提供更真实的数据以促进算法发展。

研究方法: 通过拍摄60个高保真硅胶结肠模型段，生成了192个视频序列，并提供深度、表面法线、光流、遮挡、六自由度位姿等真实数据。还包括模拟结肠镜视频和结肠变形视频。

研究结果: C3VDv2提供了169个结肠镜视频的真实数据，8个模拟视频的位姿数据，以及15个结肠变形视频。数据集模拟了多种挑战性场景，如粪便碎片、粘液池、血液等。

研究结论: C3VDv2的增强真实性将有助于更稳健和代表性的3D重建算法的开发和评估。

中文摘要: 计算机视觉技术有潜力提升结肠镜的诊断性能，但缺乏用于训练和验证的3D结肠镜数据集阻碍了其发展。本文介绍了C3VDv2，即高清结肠镜3D视频数据集的第二版，其增强的真实性旨在促进3D结肠重建算法的定量评估。通过拍摄60个独特的高保真硅胶结肠模型段，生成了192个视频序列。为169个结肠镜视频提供了真实深度、表面法线、光流、遮挡、六自由度位姿、覆盖图和3D模型。还包括8个由胃肠病学家采集的模拟筛查结肠镜视频及其真实位姿。数据集还包含15个用于定性评估的结肠变形视频。C3VDv2模拟了多种挑战性场景，如粪便碎片、粘液池、血液、镜头遮挡、正面视角和快速相机运动。C3VDv2的增强真实性将支持更稳健和代表性的3D重建算法的开发和评估。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [403] [SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning](https://arxiv.org/abs/2506.22506)
**中文标题：SABRE-FL：联邦提示学习的选择性准确后门拒绝**

*Momin Ahmad Khan,Yasra Chandio,Fatima Muhammad Anwar*

主要分类: cs.CR

摘要简述: 本文研究了联邦提示学习中的后门攻击，并提出了SABRE-FL防御方法，通过嵌入空间异常检测器过滤恶意提示更新，显著降低后门攻击成功率，同时保持干净输入的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 联邦提示学习作为一种高效通信和隐私保护的范式，其安全性尚未充分研究。本文首次探讨了该范式中的后门攻击问题，并提出了防御方案。

研究方法: 提出SABRE-FL防御方法，利用离线训练的嵌入空间异常检测器过滤恶意提示更新，无需访问原始客户端数据或标签，适用于多种数据集。

研究结果: 在五个数据集和四种基线防御方法上，SABRE-FL显著降低了后门攻击成功率，同时保持了干净输入的准确性，表现优于所有基线方法。

研究结论: SABRE-FL展示了在联邦提示学习中防御后门攻击的有效性，强调了未来联邦系统中鲁棒提示学习的重要性。

中文摘要: 联邦提示学习已成为一种通信高效且隐私保护的范式，用于在分散的客户端上适配大型视觉语言模型（如CLIP）。然而，这种设置的安全性尚未得到充分研究。本文首次研究了联邦提示学习中的后门攻击问题。我们发现，当恶意客户端将视觉上不可察觉的可学习噪声触发器注入输入图像时，全局提示学习器容易受到目标误分类的影响，同时在干净输入上仍保持高准确性。基于这一漏洞，我们提出了SABRE-FL，一种轻量级模块化防御方法，通过离线训练的嵌入空间异常检测器过滤被污染的提示更新。SABRE-FL无需访问原始客户端数据或标签，并可泛化到多种数据集。我们从理论和实验上证明，基于嵌入的检测器可以可靠地识别和过滤恶意客户端。在五个不同数据集和四种基线防御方法上，SABRE-FL显著降低了后门攻击的准确性，同时保持了干净输入的准确性，表现优于所有基线方法，展示了强大的实证性能，并强调了未来联邦系统中鲁棒提示学习的必要性。

</details>


### [404] [In-context learning for the classification of manipulation techniques in phishing emails](https://arxiv.org/abs/2506.22515)
**中文标题：基于上下文学习的钓鱼邮件操纵技术分类**

*Antony Dalmiere,Guillaume Auriol,Vincent Nicomette,Pascal Marchand*

主要分类: cs.CR

摘要简述: 本研究利用大型语言模型（LLM）的上下文学习（ICL）技术，对钓鱼邮件中的40种心理操纵技术进行细粒度分类，实验表明该方法在真实法语钓鱼邮件数据集上准确率达0.76。


<details>
  <summary>详细信息</summary>
研究动机: 传统钓鱼邮件检测方法常忽视心理操纵技术，本研究旨在通过上下文学习技术填补这一空白，实现对钓鱼邮件中操纵技术的细粒度分类。

研究方法: 研究采用GPT-4o-mini模型，基于少量示例（few-shot）对真实法语钓鱼邮件（SignalSpam数据集）进行分类，测试集包含100封人工标注的邮件。

研究结果: 实验结果显示，该方法能有效识别常见操纵技术（如诱饵、好奇心吸引、小请求等），准确率达0.76。

研究结论: 本研究证明了上下文学习在钓鱼邮件分析中的潜力，并为理解攻击者策略提供了新视角。

中文摘要: 传统钓鱼检测方法常忽视心理操纵技术。本研究探讨了利用大型语言模型（LLM）的上下文学习（ICL）技术，基于40种操纵技术分类法对钓鱼邮件进行细粒度分类。通过在真实法语钓鱼邮件数据集（SignalSpam）上使用少量示例（few-shot）和GPT-4o-mini模型，我们评估了该方法在100封人工标注测试邮件上的性能。结果显示，该方法能有效识别常见技术（如诱饵、好奇心吸引、小请求等），准确率达0.76。本研究展示了上下文学习在钓鱼分析中的潜力，并揭示了攻击者策略的细节。

</details>


### [405] [VERA: Variational Inference Framework for Jailbreaking Large Language Models](https://arxiv.org/abs/2506.22666)
**中文标题：VERA：基于变分推理的大型语言模型越狱框架**

*Anamika Lochab,Lu Yan,Patrick Pynadath,Xiangyu Zhang,Ruqi Zhang*

主要分类: cs.CR

摘要简述: 本文提出VERA框架，通过变分推理方法训练小型攻击者LLM，以生成多样化的对抗性提示，无需针对每个提示单独优化，从而全面评估大型语言模型的漏洞。


<details>
  <summary>详细信息</summary>
研究动机: 随着API访问成为主流，现有黑盒越狱方法依赖遗传算法和手动优化的提示池，效率低下且无法全面评估模型漏洞。VERA旨在通过变分推理方法解决这一问题。

研究方法: VERA将黑盒越狱提示问题转化为变分推理任务，训练小型攻击者LLM以近似目标LLM对对抗性提示的后验分布。训练完成后，攻击者可以无需重新优化即可为目标查询生成多样化的流畅越狱提示。

研究结果: 实验结果表明，VERA在多种目标LLM上表现优异，证明了概率推理在对抗性提示生成中的价值。

研究结论: VERA通过变分推理框架有效生成多样化对抗性提示，为评估大型语言模型的漏洞提供了高效且全面的解决方案。

中文摘要: 随着仅通过API访问最先进的大型语言模型（LLM）的普及，开发有效的黑盒越狱方法以识别实际场景中的模型漏洞变得尤为重要。现有的方法大多依赖遗传算法，缺乏基于梯度的优化原则，且受限于初始化和手动优化的提示池。此外，这些方法需要对每个提示单独优化，无法全面评估模型的漏洞。为解决这一问题，我们提出了VERA：基于变分推理的越狱框架。VERA将黑盒越狱提示问题转化为变分推理任务，训练一个小型攻击者LLM以近似目标LLM对对抗性提示的后验分布。训练完成后，攻击者无需重新优化即可为目标查询生成多样化且流畅的越狱提示。实验结果表明，VERA在多种目标LLM上表现优异，凸显了概率推理在对抗性提示生成中的价值。

</details>


### [406] [A Survey on Model Extraction Attacks and Defenses for Large Language Models](https://arxiv.org/abs/2506.22521)
**中文标题：大型语言模型模型提取攻击与防御方法综述**

*Kaixiang Zhao,Lincan Li,Kaize Ding,Neil Zhenqiang Gong,Yue Zhao,Yushun Dong*

主要分类: cs.CR

摘要简述: 本文综述了针对大型语言模型的模型提取攻击及其防御方法，分类分析了攻击类型和防御策略，并提出了评估指标和研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 模型提取攻击对部署的语言模型构成严重安全威胁，可能侵犯知识产权和用户隐私。本文旨在系统梳理针对大型语言模型的攻击与防御方法，为研究者和工程师提供参考。

研究方法: 论文首先将攻击分为功能提取、训练数据提取和针对提示的攻击三类，分析了API知识蒸馏、直接查询、参数恢复和提示窃取等方法。随后，从模型保护、数据隐私保护和提示策略三方面评估防御机制的有效性。

研究结果: 研究提出了专门用于评估攻击效果和防御性能的指标，并指出当前方法的局限性，提出了集成攻击方法和自适应防御机制等研究方向。

研究结论: 本文为保护生产环境中的语言模型提供了全面指导，并呼吁进一步研究以平衡安全性与模型实用性。

中文摘要: 模型提取攻击对部署的语言模型构成重大安全威胁，可能损害知识产权和用户隐私。本综述提供了针对大型语言模型的提取攻击与防御的综合分类，将攻击分为功能提取、训练数据提取和针对提示的攻击三类。我们分析了包括基于API的知识蒸馏、直接查询、参数恢复和利用Transformer架构的提示窃取技术在内的多种攻击方法。随后，我们研究了以模型保护、数据隐私保护和提示策略为核心的防御机制，并评估了它们在不同部署场景中的有效性。我们提出了专门用于评估攻击效果和防御性能的指标，以应对生成式语言模型的特定挑战。通过分析，我们指出了当前方法的关键局限性，并提出了包括集成攻击方法和平衡安全性与模型实用性的自适应防御机制在内的有前景的研究方向。本工作为自然语言处理研究者、机器学习工程师和安全专业人员提供了保护生产环境中语言模型的参考。

</details>


### [407] [General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers](https://arxiv.org/abs/2506.22706)
**中文标题：通用自主网络安全防御：动态拓扑与多样化攻击者的稳健策略学习**

*Arun Ramamurthy,Neil Dhir*

主要分类: cs.CR

摘要简述: 本文提出了一种通用自主网络安全防御（GACD）方法，旨在解决现有系统因网络拓扑动态变化和攻击者多样性而导致的泛化能力不足问题。


<details>
  <summary>详细信息</summary>
研究动机: 面对不断演变的网络威胁（如恶意软件、勒索软件和钓鱼攻击），现有的自主网络安全防御（ACD）系统因依赖静态网络拓扑假设而难以适应动态变化的实际环境，导致防御能力受限。

研究方法: 本文探索了在动态网络环境中学习泛化策略的方法，提出通用自主网络安全防御（GACD）框架，以克服现有系统对特定拓扑的过拟合问题。

研究结果: 研究表明，GACD能够在动态网络环境中学习稳健的策略，显著提升对未知拓扑和多样化攻击的适应能力。

研究结论: GACD为动态网络环境下的自主网络安全防御提供了有效的解决方案，具有广泛的应用潜力。

中文摘要: 面对恶意软件、勒索软件和钓鱼攻击等不断演变的网络威胁，自主网络安全防御（ACD）系统已成为实时威胁检测和响应（可选人工干预）的关键工具。然而，现有ACD系统依赖于限制性假设，尤其是底层网络动态的静态性。在现实场景中，网络拓扑可能因攻击者或防御者的行动、系统故障或网络的时间演化而发生变化，导致当前防御代理的自适应能力失效。此外，许多代理在静态环境中训练，导致对特定拓扑的过拟合，从而削弱了其对分布外网络拓扑的泛化能力。本研究通过探索在动态网络环境中学习泛化策略的方法，解决了这些挑战，提出了通用自主网络安全防御（GACD）。

</details>


### [408] [Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks](https://arxiv.org/abs/2506.22722)
**中文标题：一箭双雕！基于传播轨迹的统一在线检测对抗样本与后门攻击**

*Anmin Fu,Fanyu Meng,Huaibing Peng,Hua Ma,Zhi Zhang,Yifeng Zheng,Willy Susilo,Yansong Gao*

主要分类: cs.CR

摘要简述: UniGuard是首个统一在线检测框架，可同时检测对抗样本和后门攻击，通过分析输入在深度学习模型中的传播轨迹差异，利用LSTM和频谱变换放大差异，实现高效检测。


<details>
  <summary>详细信息</summary>
研究动机: 对抗样本和后门攻击均需在推理阶段进行干扰，但现有方法多为针对单一攻击类型设计，缺乏统一解决方案。UniGuard旨在通过分析输入在模型中的传播轨迹差异，实现同时检测两种攻击。

研究方法: UniGuard将输入的传播轨迹视为时间序列信号，利用LSTM和频谱变换技术放大对抗样本与良性样本在轨迹上的细微差异，从而实现高效检测。

研究结果: UniGuard在多种模态（图像、文本、音频）和任务（分类、回归）中表现优异，优于现有针对单一攻击的SOTA方法（如ContraNet和TED），并能检测部分后门和动态触发器。

研究结论: UniGuard通过统一框架解决了对抗样本和后门攻击的在线检测问题，其高效性和普适性为深度学习模型的安全性提供了新思路。

中文摘要: UniGuard是首个能够同时检测对抗样本和后门攻击的统一在线检测框架。其基于两个关键发现：一是两种攻击均需干扰推理阶段，可在运行时通过在线检测同时应对；二是对抗输入（无论是对抗样本还是携带触发器的样本）在模型前向传播中会表现出与良性样本不同的轨迹特征。这些轨迹差异虽细微，但UniGuard通过将传播轨迹视为时间序列信号，利用LSTM和频谱变换放大差异，实现了高效检测。UniGuard在多种模态（图像、文本、音频）和任务（分类、回归）中验证了其高效性和普适性，优于现有针对单一攻击的SOTA方法（如ContraNet和TED），并能检测部分后门和动态触发器。

</details>


### [409] [Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models](https://arxiv.org/abs/2506.24056)
**中文标题：Logit-Gap Steering：针对对齐大语言模型的高效短后缀越狱方法**

*Tung-Ling Li,Hongliang Liu*

主要分类: cs.CR

摘要简述: 本文提出了一种名为“Logit-Gap Steering”的高效越狱框架，通过单次词汇表遍历解决RLHF对齐语言模型的拒绝-确认差距问题，显著提升了攻击成功率和效率。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索RLHF对齐语言模型的拒绝-确认差距，并提出一种高效、快速的越狱方法，以揭示安全调整对模型内部表征的影响。

研究方法: 方法包括将拒绝-确认差距转化为单次词汇表遍历，通过前向可计算的分数结合KL惩罚和奖励偏移的轻量级代理，实现“排序-求和-停止”的快速后缀生成。

研究结果: 结果表明，该方法在0.5B至70B规模的模型上均有效，将单次攻击成功率提升至80-100%，同时保持了主题连贯性，并揭示了句子边界奖励悬崖等对齐特征。

研究结论: 结论认为，该方法不仅高效，还为理解安全调整如何重塑模型内部表征提供了轻量级探针。

中文摘要: 我们介绍了Logit-Gap Steering，一种快速的越狱框架，将RLHF对齐语言模型的拒绝-确认差距转化为单次词汇表遍历。一个前向可计算的分数将差距减少与KL惩罚和奖励偏移的轻量级代理相结合，使得“排序-求和-停止”的扫描在一秒内完成并返回一个短后缀——比束搜索或梯度攻击少两个数量级的模型调用。相同的后缀可以推广到未见过的提示，并在0.5B至70B规模的模型上有效，将单次攻击成功率从基线水平提升至80-100%，同时保持主题连贯性。除了效率之外，这些后缀还揭示了句子边界奖励悬崖和其他对齐特征，为安全调整如何重塑内部表征提供了一种轻量级的探针。

</details>


### [410] [A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance](https://arxiv.org/abs/2506.22949)
**中文标题：类别不平衡下DDoS攻击的半监督检测研究**

*Ehsan Hallaji,Vaishnavi Shanmugam,Roozbeh Razavi-Far,Mehrdad Saif*

主要分类: cs.CR

摘要简述: 本文研究了在半监督学习（SSL）框架下，针对类别不平衡和部分标记数据的DDoS攻击检测问题，评估了13种先进的SSL算法，并分析了其在实际环境中的效果和局限性。


<details>
  <summary>详细信息</summary>
研究动机: 网络安全中，DDoS攻击检测面临类别不平衡和标记数据不足的挑战。本研究旨在探索半监督学习技术如何提升DDoS检测能力，尤其是在极端环境下的表现。

研究方法: 研究评估了13种先进的半监督学习算法，用于检测DDoS攻击，并在多种场景下测试其性能，包括极端不平衡和部分标记数据的情况。

研究结果: 研究结果为设计鲁棒的入侵检测系统（IDS）提供了重要参考，尤其是在处理类别不平衡和部分标记数据时的表现。

研究结论: 半监督学习技术可以有效提升DDoS攻击检测能力，尤其是在数据不平衡和标记不足的情况下，为智能IDS的设计提供了新思路。

中文摘要: 网络安全中最具挑战性的任务之一是消除分布式拒绝服务（DDoS）攻击。由于现实数据集中固有的类别不平衡和标记样本不足，利用人工智能自动化这一任务变得复杂。本研究探讨了在半监督学习（SSL）框架下，如何通过SSL技术提升DDoS攻击检测能力，尤其是在数据不平衡和部分标记的情况下。研究中评估了13种先进的SSL算法在多种场景下的表现，包括极端环境下的效果和局限性。研究结果为设计鲁棒的入侵检测系统（IDS）提供了重要参考，尤其是在处理类别不平衡和部分标记数据时的表现。

</details>


### [411] [From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](https://arxiv.org/abs/2506.23260)
**中文标题：从提示注入到协议漏洞：LLM驱动的AI代理工作流中的威胁**

*Mohamed Amine Ferrag,Norbert Tihanyi,Djallel Hamouda,Leandros Maglaras,Merouane Debbah*

主要分类: cs.CR

摘要简述: 本文提出了首个针对LLM智能代理生态系统的端到端威胁模型，涵盖输入操纵、模型破坏、系统与隐私攻击及协议漏洞四大领域，并分析了三十多种攻击技术，为设计防御机制提供了全面参考。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于大语言模型（LLM）的自主AI代理能力的扩展，插件、连接器和代理间协议的激增导致安全实践滞后，系统脆弱性增加。本文旨在统一威胁模型，填补这一安全空白。

研究方法: 通过分类整理四大威胁领域（输入操纵、模型破坏、系统与隐私攻击、协议漏洞），分析每种攻击技术的实际可行性及现有防御措施，并提出未来研究方向。

研究结果: 提出了涵盖三十多种攻击技术的威胁分类，评估了现有防御措施，并指出动态信任管理、加密溯源等未来研究方向。

研究结论: 本文为LLM代理生态系统的安全设计提供了全面参考，强调了动态防御和协议加固的重要性，为未来研究指明了方向。

中文摘要: 基于大语言模型（LLM）的自主AI代理通过结构化函数调用接口显著提升了实时数据检索、复杂计算和多步协调能力。然而，插件、连接器和代理间协议的爆炸式增长超出了安全机制的发现能力，导致系统集成脆弱性增加。本文首次提出了一个统一的端到端威胁模型，涵盖主机到工具及代理间通信，形式化了攻击者能力和目标，并分类整理了三十多种攻击技术。具体而言，威胁模型分为四大领域：输入操纵（如提示注入、长上下文劫持、多模态对抗输入）、模型破坏（如提示和参数级后门、复合与加密多后门、投毒策略）、系统与隐私攻击（如推测性侧信道、成员推断、检索投毒、社交工程模拟）以及协议漏洞（如模型上下文协议（MCP）、代理通信协议（ACP）、代理网络协议（ANP）和代理间（A2A）协议的漏洞利用）。针对每类威胁，我们分析了代表性场景，评估了实际可行性及现有防御措施。基于威胁分类，我们提出了未来研究方向，如通过动态信任管理和加密溯源保护MCP部署、设计和加固代理化网络接口、实现多代理和联邦环境的弹性。本文为设计鲁棒防御机制和建立弹性LLM代理工作流的最佳实践提供了全面参考。

</details>


### [412] [Securing AI Systems: A Guide to Known Attacks and Impacts](https://arxiv.org/abs/2506.23296)
**中文标题：保护AI系统：已知攻击类型及其影响指南**

*Naoto Kiribuchi,Kengo Zenitani,Takayuki Semitsu*

主要分类: cs.CR

摘要简述: 本文概述了针对预测性和生成性AI系统的独特对抗性攻击，识别了11种主要攻击类型，并将其技术与影响（如信息泄露、系统破坏和资源耗尽）关联到CIA安全三要素。旨在为研究人员、开发者、安全从业者和政策制定者提供基础知识，以识别AI特定风险并实施有效防御。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI系统嵌入信息系统，其面临的安全威胁日益突出。本文旨在为非AI安全专家提供关于AI特定漏洞的对抗性攻击的全面概述，帮助相关群体识别风险并提升AI系统的整体安全性。

研究方法: 本文通过分类和映射方法，识别了11种主要的对抗性攻击类型，并将攻击技术与具体影响（如信息泄露、系统破坏和资源耗尽）关联到CIA安全三要素（机密性、完整性和可用性）。

研究结果: 研究结果包括11种主要攻击类型的详细描述，以及这些攻击对AI系统安全性的具体影响。这些影响被明确映射到CIA三要素，为防御措施提供了理论基础。

研究结论: 本文为研究人员、开发者、安全从业者和政策制定者提供了识别和防御AI特定攻击的基础知识，有助于提升AI系统的整体安全防护能力。

中文摘要: 嵌入信息系统中的人工智能（AI）面临利用其特定漏洞的安全威胁。本文提供了针对预测性和生成性AI系统的对抗性攻击的简明概述。我们识别了11种主要攻击类型，并明确将攻击技术与其影响（包括信息泄露、系统破坏和资源耗尽）关联到机密性、完整性和可用性（CIA）安全三要素。我们的目标是为研究人员、开发者、安全从业者和政策制定者（即使缺乏专业AI安全知识）提供基础知识，以识别AI特定风险并实施有效防御，从而提升AI系统的整体安全防护能力。

</details>


### [413] [Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance](https://arxiv.org/abs/2506.23314)
**中文标题：设计即解释：MH-AutoML——透明高效的Android恶意软件检测框架，性能不打折**

*Joner Assolin,Gabriel Canto,Diego Kreutz,Eduardo Feitosa,Hendrio Bragança,Angelo Nogueira,Vanderson Rocha*

主要分类: cs.CR

摘要简述: MH-AutoML是一个专为Android恶意软件检测设计的自动化机器学习框架，提供透明性和可解释性，同时保持高性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前AutoML解决方案多为黑盒系统，缺乏透明性和可解释性，难以满足网络安全需求。MH-AutoML旨在解决这一问题，提供更透明的自动化机器学习框架。

研究方法: MH-AutoML自动化整个机器学习流程，包括数据预处理、特征工程、算法选择和超参数调优，并集成了可解释性、调试和实验追踪功能。

研究结果: MH-AutoML在召回率上优于七种主流AutoML框架（如Auto-Sklearn、AutoGluon等），同时提供更高的透明性和控制能力，计算效率与其他解决方案相当。

研究结论: MH-AutoML在性能和可解释性之间取得了平衡，适用于需要高性能和透明性的网络安全应用。

中文摘要: Android系统中的恶意软件检测需要网络安全专业知识和机器学习技术。自动化机器学习（AutoML）通过减少对专业知识的需求简化了ML开发，但当前的AutoML解决方案通常作为黑盒系统运行，缺乏透明性、可解释性和实验追踪能力。为解决这些问题，我们提出了MH-AutoML，一个专为Android恶意软件检测设计的领域特定框架。MH-AutoML自动化了整个ML流程，包括数据预处理、特征工程、算法选择和超参数调优，并集成了可解释性、调试和实验追踪功能。本研究将MH-AutoML与七种主流AutoML框架（Auto-Sklearn、AutoGluon、TPOT、HyperGBM、Auto-PyTorch、LightAutoML和MLJAR）进行了比较。结果表明，MH-AutoML在召回率上表现更优，同时提供更高的透明性和控制能力。该框架的计算效率与其他解决方案相当，适用于性能和可解释性均重要的网络安全应用。

</details>


### [414] [SoK: Semantic Privacy in Large Language Models](https://arxiv.org/abs/2506.23603)
**中文标题：SoK：大型语言模型中的语义隐私**

*Baihe Ma,Yanna Jiang,Xu Wang,Guangshen Yu,Qin Wang,Caijun Sun,Chen Li,Xuelei Qi,Ying He,Wei Ni,Ren Ping Liu*

主要分类: cs.CR

摘要简述: 本文系统化分析了大型语言模型（LLMs）中的语义隐私风险，提出了一个生命周期框架，评估了当前防御措施的不足，并指出了未来研究的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型在敏感领域的广泛应用，传统隐私保护措施无法应对隐式、上下文或可推断的语义隐私风险，亟需系统性研究。

研究方法: 通过生命周期框架分析LLMs的输入处理、预训练、微调和对齐阶段中的语义隐私风险，分类攻击向量并评估现有防御措施（如差分隐私、嵌入加密等）。

研究结果: 研究发现语义层面的保护存在显著漏洞，尤其是针对上下文推断和潜在表示泄露，现有防御措施无法完全解决这些问题。

研究结论: 未来研究需解决语义泄露量化、多模态输入保护、去标识与生成质量的平衡，以及隐私执行的透明度等挑战。

中文摘要: 随着大型语言模型（LLMs）在敏感领域的广泛应用，传统数据隐私措施无法保护隐式、上下文或可推断的信息（即语义隐私）。本文通过系统化知识（SoK），提出了一种以生命周期为中心的框架，分析LLMs在输入处理、预训练、微调和对齐阶段中语义隐私风险的产生。我们分类了关键攻击向量，并评估了当前防御措施（如差分隐私、嵌入加密、边缘计算和遗忘技术）对这些威胁的应对效果。分析揭示了语义层面保护的关键漏洞，尤其是针对上下文推断和潜在表示泄露。最后，我们提出了开放挑战，包括量化语义泄露、保护多模态输入、平衡去标识与生成质量，以及确保隐私执行的透明度。本研究旨在为未来设计鲁棒且语义感知的隐私保护技术提供参考。

</details>


### [415] [gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures](https://arxiv.org/abs/2506.23634)
**中文标题：gMBA：基于Transformer架构的表达式语义指导混合布尔算术反混淆**

*Youjeong Noh,Joon-Young Paik,Jingun Kwon,Eun-Sun Cho*

主要分类: cs.CR

摘要简述: 本文提出了一种基于Transformer架构的混合布尔算术（MBA）反混淆方法gMBA，通过引入真值表作为语义指导，显著提升了反混淆性能。


<details>
  <summary>详细信息</summary>
研究动机: 混合布尔算术（MBA）混淆技术被广泛用于保护知识产权，但也被恶意软件开发者滥用以逃避检测。传统方法忽略了表达式的内部语义信息，导致反混淆效果不佳。本文旨在通过语义指导提升MBA反混淆的准确性和效率。

研究方法: 提出了一种自动构建的真值表作为表达式的语义表示，并设计了一个基于Transformer的编码器-解码器框架gMBA，将语义信息融入反混淆过程。

研究结果: 实验结果表明，引入语义指导显著提升了反混淆性能，验证了内部语义信息在恢复原始代码中的重要性。

研究结论: gMBA框架通过语义指导有效提升了MBA反混淆的效果，为未来研究提供了可扩展的基础。

中文摘要: 混合布尔算术（MBA）混淆技术通过将程序转换为更复杂的形式来保护知识产权。然而，MBA正被恶意软件开发者利用以逃避检测，造成严重的现实问题。传统MBA反混淆方法通常将这些表达式视为黑箱，忽略了其内部语义信息。为填补这一空白，我们提出了一种真值表，这是一种自动构建的表达式行为语义表示，不依赖外部资源。真值表是一种数学形式，表示表达式在所有可能输入组合下的输出。我们还提出了一种通用且可扩展的语义指导MBA反混淆框架（gMBA），通过修改基于Transformer的神经编码器-解码器Seq2Seq架构来融入语义指导。实验结果和深入分析表明，融入表达式语义显著提升了性能，并凸显了内部语义信息在恢复混淆代码到原始形式中的重要性。

</details>


### [416] [Differentially Private Synthetic Data Release for Topics API Outputs](https://arxiv.org/abs/2506.23855)
**中文标题：差分隐私合成数据发布：针对Topics API输出的研究**

*Travis Dick,Alessandro Epasto,Adel Javanmard,Josh Karlin,Andres Munoz Medina,Vahab Mirrokni,Sergei Vassilvitskii,Peilin Zhong*

主要分类: cs.CR

摘要简述: 本文提出了一种生成差分隐私合成数据的方法，用于模拟Topics API输出，以支持隐私保护广告API的实证研究，同时确保用户隐私安全。


<details>
  <summary>详细信息</summary>
研究动机: 隐私保护广告API的隐私属性研究缺乏公开数据，阻碍了实证分析。本文旨在生成既真实又隐私安全的合成数据，以促进相关研究。

研究方法: 首先计算大量差分隐私统计数据，描述API输出的时间演变；然后设计参数化分布，优化参数以匹配统计数据；最后从该分布生成合成数据。

研究结果: 开发了一种生成差分隐私合成数据的方法，并开源了匿名数据集，支持外部研究者深入分析Topics API。

研究结论: 本文方法为隐私保护广告API的研究提供了透明且隐私安全的工具，有助于推动相关领域的实证研究。

中文摘要: 隐私保护广告API的隐私属性研究引起了学术界、行业和监管机构的广泛关注。然而，缺乏公开数据阻碍了这些方法的实证研究。可靠的隐私属性分析需要真实的API输出数据集，但隐私问题限制了此类数据的公开。本文提出了一种新方法，用于生成既真实又能提供强隐私保护的合成API输出。我们专注于Google Chrome隐私沙盒中的Topics API，开发了一种生成差分隐私数据集的方法，该数据集与真实Topics API数据的重识别风险特性高度匹配。差分隐私的使用为数据发布中的用户隐私泄露提供了严格的理论界限。我们的方法基于计算大量差分隐私统计数据，描述API输出的时间演变；然后设计参数化分布，优化参数以匹配统计数据；最后从该分布生成合成数据。我们还开源了通过该方法生成的匿名数据集，希望外部研究者能深入分析API，并在真实的大规模数据集上复现现有和未来的研究。我们相信这项工作将促进隐私保护广告API隐私属性的透明度。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [417] [Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision](https://arxiv.org/abs/2506.22656)
**中文标题：知识引导的多智能体框架用于自动化需求开发：愿景**

*Jiangping Huang,Dongming Jin,Weisong Sun,Yang Liu,Zhi Jin*

主要分类: cs.SE

摘要简述: 本文提出了一种名为KGMAF的知识引导多智能体框架，旨在自动化需求开发，弥补当前SE自动化系统在需求任务上的不足。框架包含六个专用智能体和一个工件池，通过案例研究展示了其实际潜力。


<details>
  <summary>详细信息</summary>
研究动机: 当前软件工程（SE）自动化系统主要关注代码开发，而忽略了需求任务的复杂性。KGMAF旨在填补这一空白，通过多智能体框架提升需求开发的效率和准确性。

研究方法: KGMAF框架由六个专用智能体和一个工件池组成，每个智能体的功能、行为和知识被详细设计。框架还提供了工件池的概念设计，并通过案例研究验证其实际应用潜力。

研究结果: 案例研究表明，KGMAF在真实场景中具有显著潜力，能够有效提升需求开发的效率和准确性。

研究结论: KGMAF为自动化需求开发提供了创新框架，未来在多智能体系统和LLM时代的发展中将发挥关键作用。

中文摘要: 本文提出了一种名为KGMAF的知识引导多智能体框架，旨在实现自动化需求开发。KGMAF旨在解决当前SE自动化系统中优先关注代码开发而忽视需求任务复杂性的问题。该框架由六个专用智能体和一个工件池组成，以提高效率和准确性。具体而言，KGMAF详细描述了每个智能体的功能、行为和知识，并提供了工件池的概念设计。我们的案例研究展示了KGMAF在真实场景中的潜力。最后，我们概述了利用多智能体系统实现和增强自动化需求开发的若干研究机会。我们相信，KGMAF将在LLM时代的自动化需求开发中发挥关键作用。

</details>


### [418] [P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code](https://arxiv.org/abs/2506.22703)
**中文标题：P4OMP：基于检索增强的串行代码OpenMP并行化提示框架**

*Wali Mohammad Abdullah,Azmain Kabir*

主要分类: cs.SE

摘要简述: P4OMP是一个基于检索增强的框架，利用大型语言模型（LLM）将串行C/C++代码转换为OpenMP并行代码。它通过检索结构化知识提升代码生成的可靠性，显著优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法依赖模型微调或编译器工具，难以保证OpenMP语法的正确性。P4OMP旨在通过检索增强生成技术，无需额外训练即可提高并行代码的生成质量。

研究方法: P4OMP采用检索增强生成（RAG）技术，结合OpenMP教程的结构化知识，生成更可靠的OpenMP注释代码。与基线GPT-3.5-Turbo相比，其通过检索上下文避免了语法错误和无效指令组合。

研究结果: 在108个真实C++程序测试中，P4OMP实现了100%的编译成功率，而基线方法在20个案例中失败。P4OMP还展示了在高性能计算集群上的良好运行时扩展性。

研究结论: P4OMP提供了一个模块化且可靠的框架，显著提升了LLM生成OpenMP代码的准确性和实用性，为自动化并行代码生成提供了新思路。

中文摘要: 我们提出了P4OMP，一个基于检索增强的框架，利用大型语言模型（LLM）将串行C/C++代码转换为OpenMP注释的并行代码。据我们所知，这是首个无需模型微调或编译器工具即可实现OpenMP语法正确性的检索增强提示系统。P4OMP通过检索OpenMP教程的结构化知识，结合检索增强生成（RAG）技术，提升了提示驱动代码生成的可靠性。与基线GPT-3.5-Turbo相比，P4OMP通过检索上下文显著提高了语法正确性。我们在108个来自Stack Overflow、PolyBench和NAS基准测试的真实C++程序上评估了P4OMP。结果显示，P4OMP在所有可并行化案例中实现了100%的编译成功率，而基线方法在108个案例中有20个失败。由于OpenMP的基本限制，6个依赖非随机访问迭代器或线程不安全结构的案例被排除。详细分析表明，P4OMP成功避免了基线代码中常见的范围错误、语法滥用和无效指令组合。此外，我们在高性能计算集群上对7个计算密集型基准测试展示了良好的运行时扩展性。P4OMP提供了一个稳健且模块化的流程，显著提升了LLM生成OpenMP代码的可靠性和适用性。

</details>


### [419] [RAILS: Retrieval-Augmented Intelligence for Learning Software Development](https://arxiv.org/abs/2506.22742)
**中文标题：RAILS：基于检索增强的智能学习软件开发框架**

*Wali Mohammad Abdullah,Md. Morshedul Islam,Devraj Parmar,Happy Hasmukhbhai Patel,Sindhuja Prabhakaran,Baidya Saha*

主要分类: cs.SE

摘要简述: RAILS框架通过检索增强的上下文和迭代验证，显著提升了LLM在Java开发中的代码建议准确性，尤其在解决导入错误方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（如GPT-3.5-Turbo）在辅助软件开发时，常因缺乏外部或项目特定文档支持，导致生成不完整代码或错误导入。RAILS旨在通过检索增强技术解决这一问题。

研究方法: RAILS利用FAISS和OpenAI嵌入技术，从精选的Java资源中检索语义相关上下文，并整合到LLM提示中。此外，通过基于编译器反馈的迭代验证循环优化建议。

研究结果: 在78个真实Java导入错误案例中，RAILS表现优于基线方法，能够准确保留意图、避免幻觉，并在本地库不可用时仍提供正确导入。

研究结论: RAILS显著提升了LLM在软件开发中的实用性，未来计划通过PostgreSQL符号过滤扩展支持更多语言和IDE。

中文摘要: 尽管像GPT-3.5-Turbo这样的大型语言模型（LLMs）越来越多地用于辅助软件开发，但它们常因缺乏外部或项目特定文档支持而生成不完整代码或错误导入。我们提出了RAILS（基于检索增强的智能学习软件开发框架），该框架通过FAISS和OpenAI嵌入技术，从精选的Java资源中检索语义相关上下文，并将其整合到LLM提示中。RAILS还包含一个基于编译器反馈的迭代验证循环，以优化建议。我们在78个真实Java导入错误案例中评估了RAILS，涵盖标准库、GUI API、外部工具和自定义工具。尽管使用相同的LLM，RAILS在保留意图、避免幻觉以及即使本地库不可用时仍能提供正确导入方面优于基线提示方法。未来工作将整合PostgreSQL的符号过滤功能，并扩展支持其他语言和IDE。

</details>


### [420] [Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](https://arxiv.org/abs/2506.22776)
**中文标题：更小=更弱？量化LLMs在代码生成中的鲁棒性基准测试**

*Sen Fang,Weiyuan Ding,Antonio Mastropaolo,Bowen Xu*

主要分类: cs.SE

摘要简述: 量化压缩大型语言模型（LLMs）不仅降低计算需求，还能提升其在代码生成任务中的鲁棒性，挑战了传统认知。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注量化LLMs的有效性，而对其鲁棒性的影响研究不足。本文首次系统研究量化如何影响LLMs在代码生成任务中的鲁棒性。

研究方法: 通过四种主流LLM家族（LLaMA、DeepSeek、CodeGen和StarCoder），参数规模从350M到33B，从对抗攻击输入提示和模型架构噪声扰动两个角度评估鲁棒性。

研究结果: 量化LLMs在对抗攻击中表现优于全精度模型（51.59% vs 42.86%），且能承受更高水平的权重扰动。

研究结论: 量化不仅降低计算需求，还能增强LLMs在代码生成任务中的可靠性，为开发更鲁棒高效的LLM部署策略提供新视角。

中文摘要: 量化已成为压缩大型语言模型（LLMs）的主流方法，无需修改架构即可减少内存需求并加速推理。现有研究主要关注量化LLMs与原模型的有效性对比，而对其鲁棒性影响的研究较少。本文首次系统研究量化如何影响LLMs在代码生成任务中的鲁棒性。通过对四种主流LLM家族（LLaMA、DeepSeek、CodeGen和StarCoder）进行广泛实验，参数规模从350M到33B，我们从对抗攻击输入提示和模型架构噪声扰动两个角度评估鲁棒性。实验结果挑战了传统认知：量化LLMs在对抗攻击中表现优于全精度模型（51.59% vs 42.86%），且能承受更高水平的权重扰动。这表明量化不仅能降低计算需求，还能提升LLMs在代码生成任务中的可靠性，为开发更鲁棒高效的LLM部署策略提供了宝贵见解。

</details>


### [421] [Generating Privacy Stories From Software Documentation](https://arxiv.org/abs/2506.23014)
**中文标题：从软件文档生成隐私用户故事**

*Wilder Baldwin,Shashank Chintakuntla,Shreyah Parajuli,Ali Pourghasemi,Ryan Shanz,Sepideh Ghanavati*

主要分类: cs.SE

摘要简述: 本文提出了一种基于链式思维提示（CoT）、上下文学习（ICL）和大语言模型（LLMs）的新方法，用于从软件文档中提取隐私行为并生成隐私用户故事。实验表明，常用LLMs（如GPT-4o和Llama 3）能有效识别隐私行为并生成隐私需求，F1分数超过0.8，且通过参数调优可进一步提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究多关注从法规中提取法律要求并评估软件合规性，而隐私常被视为安全概念或事后考虑，导致用户隐私被忽视或违反。本文旨在通过LLMs在软件开发前后提取隐私行为并生成隐私需求，以解决这一问题。

研究方法: 采用链式思维提示（CoT）、上下文学习（ICL）和大语言模型（LLMs）相结合的方法，从软件文档中提取隐私行为，并将其转化为用户故事形式的隐私需求。

研究结果: 实验结果显示，常用LLMs（如GPT-4o和Llama 3）在识别隐私行为和生成隐私用户故事方面表现优异，F1分数超过0.8，且参数调优可进一步提升模型性能。

研究结论: 本文验证了LLMs在生成隐私需求方面的潜力，为软件开发过程中隐私需求的提取和优化提供了新思路。

中文摘要: 研究表明，分析人员和开发者常将隐私视为安全概念或事后考虑，这可能导致不合规和用户隐私的侵犯。然而，现有方法多聚焦于从法规中提取法律要求并评估软件合规性。本文提出了一种基于链式思维提示（CoT）、上下文学习（ICL）和大语言模型（LLMs）的新方法，用于在软件开发前后从各类文档中提取隐私行为，并生成用户故事形式的隐私需求。结果显示，常用LLMs（如GPT-4o和Llama 3）能有效识别隐私行为并生成隐私用户故事，F1分数超过0.8，且通过参数调优可进一步提升性能。本文为利用和优化LLMs生成隐私需求提供了见解，适用于软件开发周期中的文档。

</details>


### [422] [QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration](https://arxiv.org/abs/2506.23644)
**中文标题：QLPro：通过LLM与静态代码分析集成实现自动化代码漏洞发现**

*Junze Hu,Xiangyu Jin,Yizhe Zeng,Yuling Liu,Yunpeng Li,Dan Du,Kaiyu Xie,Hongsong Zhu*

主要分类: cs.SE

摘要简述: QLPro是一种结合大型语言模型（LLM）和静态代码分析工具的漏洞检测框架，显著提升了开源项目中漏洞的检测能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有静态分析工具（如CodeQL）在检测漏洞时存在漏报问题，无法全面覆盖开源项目中的漏洞。QLPro旨在通过整合LLM和静态分析工具，提高漏洞检测的全面性和准确性。

研究方法: QLPro框架系统性地整合了LLM和静态分析工具（如CodeQL），并基于新构建的数据集JavaTest（包含10个GitHub开源项目和62个确认漏洞）进行测试。

研究结果: QLPro检测到41个漏洞，而CodeQL仅检测到24个。此外，QLPro还发现了6个未知漏洞，其中2个被确认为0-day漏洞。

研究结论: QLPro通过结合LLM和静态分析工具，显著提升了漏洞检测能力，为开源项目的安全性提供了更全面的保障。

中文摘要: 我们介绍了QLPro，一种系统性地整合大型语言模型（LLM）和静态分析工具的漏洞检测框架，旨在实现对开源项目的全面漏洞检测。我们构建了一个新的数据集JavaTest，包含来自GitHub的10个开源项目和62个确认漏洞。CodeQL（一种先进的静态分析工具）仅检测到其中的24个漏洞，而QLPro检测到了41个。此外，QLPro还发现了6个此前未知的漏洞，其中2个被确认为0-day漏洞。

</details>


### [423] [Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead](https://arxiv.org/abs/2506.23762)
**中文标题：大型语言模型的软件工程：研究现状、挑战与未来方向**

*Hongzhou Rao,Yanjie Zhao,Xinyi Hou,Shenao Wang,Haoyu Wang*

主要分类: cs.SE

摘要简述: 本文系统分析了大型语言模型（LLM）开发全周期的研究现状，将其分为六个阶段，并总结了每个阶段的关键挑战和潜在研究方向，为从软件工程角度推动LLM发展提供了宝贵见解。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型的快速发展为人工智能研究带来了无限可能，但其开发过程中面临日益复杂的挑战，目前缺乏从软件工程角度系统探讨这些挑战及解决方案的研究。本文旨在填补这一空白。

研究方法: 通过系统分析LLM开发全周期的研究现状，将其分为需求工程、数据集构建、模型开发与优化、测试与评估、部署与运维、维护与演进六个阶段，并总结每个阶段的关键挑战和潜在研究方向。

研究结果: 研究总结了LLM开发各阶段的关键挑战，并提出了针对性的潜在研究方向，为未来LLM开发提供了从软件工程角度的指导。

研究结论: 本文为大型语言模型开发提供了从软件工程角度的系统性分析，总结了各阶段的挑战和研究方向，有助于推动LLM技术的进一步发展。

中文摘要: 大型语言模型（LLM）的快速发展重新定义了人工智能（AI），推动了AI研究的边界，并为学术界和工业界带来了无限可能。然而，LLM开发在其全生命周期中面临日益复杂的挑战，但目前尚无研究从软件工程（SE）角度系统探讨这些挑战及解决方案。为填补这一空白，我们系统分析了LLM开发全周期的研究现状，将其分为六个阶段：需求工程、数据集构建、模型开发与优化、测试与评估、部署与运维、维护与演进。随后，我们总结了每个阶段的关键挑战，并提出了潜在的研究方向以应对这些挑战。总体而言，我们从软件工程角度提供了宝贵的见解，以促进未来LLM开发的进步。

</details>


### [424] [STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems](https://arxiv.org/abs/2506.23995)
**中文标题：STCLocker：自动驾驶系统的死锁避免测试**

*Mingfei Cheng,Renzhi Wang,Xiaofei Xie,Yuan Zhou,Lei Ma*

主要分类: cs.SE

摘要简述: 本文提出了一种名为STCLocker的技术，用于测试自动驾驶系统（ADS）在多车协同场景中的死锁避免能力。通过空间-时间冲突引导的死锁场景生成，STCLocker能够有效检测和生成死锁场景，优于现有基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的自动驾驶系统测试主要关注单车场景，而多车协同场景中的死锁问题（即多车进入无限循环等待状态）尚未得到充分研究。为了解决这一问题，本文提出了STCLocker技术，旨在填补多车协同死锁测试的空白。

研究方法: STCLocker包含三个核心组件：死锁检测器（Deadlock Oracle）、冲突反馈（Conflict Feedback）和冲突感知场景生成（Conflict-aware Scenario Generation）。死锁检测器用于识别多车场景中的死锁循环；冲突反馈和场景生成则通过引导车辆在空间和时间上的竞争行为，提高死锁场景的生成效率。

研究结果: 实验结果显示，STCLocker在两种自动驾驶系统（Roach和OpenCDA）上均能生成比现有基线方法更多的死锁场景，验证了其有效性。

研究结论: STCLocker为多车协同场景中的死锁测试提供了一种高效且可靠的方法，填补了现有研究的空白，并为自动驾驶系统的安全性评估提供了新工具。

中文摘要: 自动驾驶系统（ADS）测试对于确保自动驾驶车辆（AVs）在部署前的安全性和可靠性至关重要。然而，现有技术主要关注单车场景下的ADS功能评估。随着ADS在多车交通中的广泛应用，评估其协同性能（尤其是死锁问题）变得尤为重要。死锁是一种基本的协调失败现象，即多车进入无限循环等待状态，导致运动规划失败。尽管其重要性，ADS在避免死锁方面的协同能力仍未得到充分研究。为填补这一空白，我们提出了首个专注于空间-时间冲突引导的死锁避免测试技术——STCLocker，用于生成死锁场景（DLSs），即被测ADS控制的多车进入循环等待状态。STCLocker包含三个关键组件：死锁检测器（Deadlock Oracle）、冲突反馈（Conflict Feedback）和冲突感知场景生成（Conflict-aware Scenario Generation）。死锁检测器提供了一种可靠的黑盒机制，用于检测给定场景中多车的死锁循环；冲突反馈和冲突感知场景生成则通过引导车辆在空间冲突资源（如共享通行区域）和时间竞争行为（如同时间到达冲突区域）上的竞争，提高生成冲突易发死锁的效率。我们在两种ADS（端到端系统Roach和支持协同通信的模块化系统OpenCDA）上评估了STCLocker。实验结果表明，STCLocker平均生成的DLS数量优于性能最佳的基线方法。

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [425] [Attention acts to suppress goal-based conflict under high competition](https://arxiv.org/abs/1610.09431)
**中文标题：注意力在高竞争条件下抑制基于目标的冲突**

*Omar Claflin*

主要分类: q-bio.NC

摘要简述: 在高竞争条件下，自上而下的注意力会同时抑制任务相关和不相关的神经信号，以减少无关刺激的前馈信号。


<details>
  <summary>详细信息</summary>
研究动机: 研究在高竞争条件下（即两个刺激共享感受野且具有相反调节目标时），自上而下的注意力如何影响神经信号。

研究方法: 通过实验观察在高竞争条件下，自上而下的注意力对任务相关和不相关神经信号的作用，并分析其时间动态。

研究结果: 在高竞争条件下，自上而下的注意力在刺激出现后100毫秒内同时抑制任务相关和不相关的神经信号，以减少无关刺激的前馈信号。

研究结论: 高竞争条件下，自上而下的注意力通过非选择性抑制机制减少无关刺激的影响，从而优化任务表现。

中文摘要: 已知在多刺激存在时，自上而下的注意力会选择性增强视觉皮层中任务相关刺激的神经信号，但这仅在视觉注意力竞争较低的情况下被验证。本文表明，在高竞争条件下（即两个刺激共享感受野且具有相反调节目标时），自上而下的注意力会在刺激出现后100毫秒内同时抑制任务相关和不相关的神经信号。这种非选择性的自上而下注意力资源分配旨在减少无关刺激的前馈信号。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [426] [TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity](https://arxiv.org/abs/2506.23484)
**中文标题：TAG-WM：基于扩散反转敏感性的防篡改生成图像水印方法**

*Yuzhuo Chen,Zehua Ma,Han Fang,Weiming Zhang,Nenghai Yu*

主要分类: cs.MM

摘要简述: 本文提出了一种名为TAG-WM的防篡改生成图像水印方法，通过扩散反转敏感性实现高鲁棒性和篡改定位能力，同时保持生成质量无损。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成内容（AIGC）的普及，版权和真实性风险增加。现有无损视觉质量水印的篡改鲁棒性受限于修改敏感的扩散反转过程，且被动篡改检测方法难以应对高质量篡改需求，亟需一种兼具主动篡改定位能力的水印方法。

研究方法: TAG-WM包含四个关键模块：1）双标记联合采样（DMJS）算法，将版权和定位水印嵌入潜在空间；2）水印潜在重建（WLR）；3）密集变化区域检测器（DVRD），利用扩散反转敏感性通过统计偏差分析识别篡改区域；4）篡改感知解码（TAD）。

研究结果: 实验结果表明，TAG-WM在保持无损生成质量和256位容量的同时，实现了最先进的篡改鲁棒性和篡改定位能力。

研究结论: TAG-WM通过扩散反转敏感性解决了现有水印方法的局限性，为AI生成内容的版权保护和真实性验证提供了高效解决方案。

中文摘要: AI生成内容（AIGC）虽提升了视觉创作效率，但也带来了版权和真实性风险。作为完整性验证和来源追踪的常用技术，数字图像水印被视为潜在解决方案。其中，能保持生成质量的水印方法备受关注。然而，生成图像编辑应用的普及和高性能加剧了恶意篡改风险，提出了新需求：1）现有无损视觉质量水印的篡改鲁棒性受限于修改敏感的扩散反转过程，需增强鲁棒性；2）篡改质量的提升和快速迭代周期使被动篡改检测方法失效，亟需水印具备主动篡改定位能力。为此，本文提出了一种名为TAG-WM的防篡改生成图像水印方法。该方法包含四个关键模块：双标记联合采样（DMJS）算法，用于在潜在空间中嵌入版权和定位水印；水印潜在重建（WLR）；密集变化区域检测器（DVRD），利用扩散反转敏感性通过统计偏差分析识别篡改区域；以及篡改感知解码（TAD）。实验结果表明，TAG-WM在保持无损生成质量和256位容量的同时，实现了最先进的篡改鲁棒性和篡改定位能力。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [427] [Tensor Train Quantum State Tomography using Compressed Sensing](https://arxiv.org/abs/2506.23560)
**中文标题：基于压缩感知的张量链量子态断层扫描**

*Shakir Showkat Sofi,Charlotte Vermeylen,Lieven De Lathauwer*

主要分类: quant-ph

摘要简述: 本文提出了一种基于低秩张量链分解的量子态断层扫描方法，解决了传统方法因参数指数增长而无法实用的问题，实现了内存和计算效率的提升。


<details>
  <summary>详细信息</summary>
研究动机: 量子态断层扫描（QST）是评估量子设备性能的关键技术，但传统方法因状态表示的参数指数增长而变得不切实际。本文旨在通过低秩张量链分解参数化量子态，解决这一挑战。

研究方法: 采用低秩块张量链分解参数化量子态，适用于包括纯态、近纯态和哈密顿量基态在内的广泛量子态类别。

研究结果: 该方法在内存和计算效率上表现出色，适用于能够通过低秩分解良好近似的量子态。

研究结论: 通过低秩张量链分解，本文提供了一种高效且实用的量子态断层扫描框架，适用于多种量子态。

中文摘要: 量子态断层扫描（QST）是一种从测量数据中估计量子系统状态的基本技术，在评估量子设备性能中起着关键作用。然而，由于状态表示中参数的指数增长，标准估计方法变得不切实际。在这项工作中，我们通过使用低秩块张量链分解参数化状态来解决这一挑战，并证明我们的方法在内存和计算上都是高效的。这一框架适用于能够通过低秩分解良好近似的广泛量子态类别，包括纯态、近纯态和哈密顿量的基态。

</details>


### [428] [SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks](https://arxiv.org/abs/2506.24081)
**中文标题：SQUASH：一种基于SWAP的量子攻击以破坏混合量子神经网络**

*Rahul Kumar,Wenqi Wei,Ying Mao,Junaid Farooq,Ying Wang,Juntao Chen*

主要分类: quant-ph

摘要简述: 提出一种名为SQUASH的量子攻击方法，通过插入SWAP门破坏混合量子神经网络（HQNN）的分类性能，攻击隐蔽且高效。


<details>
  <summary>详细信息</summary>
研究动机: 混合量子神经网络（HQNN）在分类任务中表现优异，但其电路结构可能面临潜在攻击。研究旨在揭示HQNN在电路层面的脆弱性，并提出一种新型攻击方法。

研究方法: SQUASH攻击通过在受害HQNN的变分量子电路中插入SWAP门，直接操纵电路结构，导致量子比特错位并破坏量子态演化。攻击无需访问训练数据或引入可检测的输入扰动。

研究结果: 实验表明，SQUASH显著降低分类性能：非目标SWAP攻击使准确率下降高达74.08%，目标SWAP攻击使目标类准确率下降高达79.78%。

研究结论: SQUASH攻击揭示了HQNN在电路层面的严重漏洞，强调了设计抗电路级对抗干预的鲁棒架构的必要性。

中文摘要: 我们提出了一种电路级攻击方法SQUASH，通过插入SWAP门破坏混合量子神经网络（HQNN）的分类任务。与传统的噪声或对抗输入攻击不同，SQUASH直接操纵电路结构，导致量子比特错位并干扰量子态演化。该攻击隐蔽性高，无需访问训练数据或引入可检测的输入扰动。实验结果显示，SQUASH显著降低分类性能：非目标SWAP攻击使准确率下降高达74.08%，目标SWAP攻击使目标类准确率下降高达79.78%。这些发现揭示了HQNN实现中的关键漏洞，强调了设计抗电路级对抗干预的鲁棒架构的必要性。

</details>


<div id='stat.OT'></div>

# stat.OT [[Back]](#toc)

### [429] [Treatment, evidence, imitation, and chat](https://arxiv.org/abs/2506.23040)
**中文标题：治疗、证据、模仿与聊天**

*Samuel J. Weisenthal*

主要分类: stat.OT

摘要简述: 本文探讨大型语言模型在医疗决策中的潜力，重点分析治疗问题与聊天问题的区别，并讨论模型在解决治疗问题时的挑战及其与循证医学的关系。


<details>
  <summary>详细信息</summary>
研究动机: 研究大型语言模型在医疗决策中的潜在应用，尤其是如何帮助解决患者与医疗提供者协作的治疗问题，以及模型在模仿和聊天问题中的局限性。

研究方法: 首先分析治疗问题的解决方式，包括基于循证医学的试验和观察数据；随后探讨聊天问题与治疗问题的区别；最后讨论大型语言模型在解决治疗问题中的应用及挑战。

研究结果: 研究发现大型语言模型在解决治疗问题时面临挑战，尤其是在模仿和聊天问题中的应用与循证医学的结合上存在局限性。

研究结论: 大型语言模型在医疗决策中具有潜力，但需进一步研究以解决其在治疗问题中的挑战，并更好地结合循证医学的实践。

中文摘要: 大型语言模型被认为在医疗决策中具有潜在帮助。本文对此进行了探讨。我们从治疗问题入手，这是患者与医疗提供者协作解决的核心医疗决策任务，并讨论了基于循证医学的试验和观察数据等解决方法。随后，我们探讨了聊天问题及其与治疗问题的区别，特别是在模仿方面的差异。接着，我们讨论了大型语言模型如何用于解决治疗问题，并指出其中出现的挑战。最后，我们讨论了这些挑战与循证医学的关系，以及如何为下一步研究提供参考。

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [430] [Bridging Physical and Digital Worlds: Embodied Large AI for Future Wireless Systems](https://arxiv.org/abs/2506.24009)
**中文标题：连接物理与数字世界：面向未来无线系统的具身大AI**

*Xinquan Wang,Fenghao Zhu,Zhaohui Yang,Chongwen Huang,Xiaoming Chen,Zhaoyang Zhang,Sami Muhaidat,Mérouane Debbah*

主要分类: cs.IT

摘要简述: 本文提出了一种新型无线系统范式——无线具身大AI（WELAI），旨在通过主动感知和交互解决现有AI模型在实时动态和非平稳环境中的局限性，推动未来无线系统的自适应和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型AI模型在无线系统中主要依赖离线数据，难以应对实时动态和非平稳环境，且缺乏主动环境探测能力。本文旨在通过具身化AI解决这些问题。

研究方法: 论文首先分析了现有模型的挑战，提出了无线具身大AI（WELAI）的设计原则和系统结构，并通过案例研究验证其有效性。

研究结果: 研究表明，WELAI能够显著提升无线系统在动态和非平稳环境中的适应性和鲁棒性，并展示了其在下一代无线系统中的潜在应用。

研究结论: WELAI为未来无线系统提供了一种新的研究方向，能够实现自适应、鲁棒和自主的无线网络优化。

中文摘要: 大型人工智能（AI）模型为未来无线系统提供了革命性潜力，能够在网络优化和性能方面实现前所未有的能力。然而，当前范式大多忽视了关键的物理交互，导致其主要依赖离线数据集，难以应对实时无线动态和非平稳环境。此外，这些模型通常缺乏主动环境探测能力。本文提出了一种根本性的范式转变，即无线具身大AI（WELAI），从被动观察转向主动具身化。我们首先分析了现有模型面临的关键挑战，随后探讨了WELAI的设计原则和系统结构。此外，我们还概述了其在下一代无线系统中的潜在应用。最后，通过一个案例研究，我们验证了WELAI的有效性，并指出了实现自适应、鲁棒和自主无线系统的未来研究方向。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [431] [ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks](https://arxiv.org/abs/2402.09146)
**中文标题：ResQuNNs：迈向量子卷积神经网络中的深度学习**

*Muhammad Kashif,Muhammad Shafique*

主要分类: cs.LG

摘要简述: 本文提出了一种新型框架ResQuNNs，通过引入可训练的量子卷积层和残差学习，解决了传统量子卷积神经网络（QuNNs）中梯度难以访问的问题，显著提升了网络的灵活性和训练性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的量子卷积层虽然有助于特征提取，但通常是静态的，缺乏适应性。本研究旨在通过引入可训练层和残差学习，解决梯度访问难题，提升量子卷积神经网络的性能。

研究方法: 提出了一种名为ResQuNNs的新型架构，通过在量子卷积层之间插入残差块，利用残差学习的概念促进梯度流动，从而优化训练过程。同时，研究了残差块在QuNNs中的最佳配置。

研究结果: 实验表明，ResQuNNs通过残差块的策略性放置，显著改善了梯度访问和训练效率，为量子深度学习提供了新的理论和实践方向。

研究结论: ResQuNNs在量子深度学习领域迈出了重要一步，不仅提升了量子卷积神经网络的性能，还为量子计算的实际应用开辟了新途径。

中文摘要: 本文提出了一种新型框架，通过引入可训练的量子卷积层，解决了量子卷积神经网络（QuNNs）中的关键挑战。传统的量子卷积层虽然对特征提取有益，但通常是静态的，适应性有限。与现有技术不同，本研究通过在这些层中启用训练，显著提高了QuNNs的灵活性和潜力。然而，引入多个可训练量子卷积层会导致基于梯度的优化复杂性增加，主要是由于难以跨层访问梯度。为解决这一问题，我们提出了一种新型架构——残差量子卷积神经网络（ResQuNNs），利用残差学习的概念，通过在层间添加跳跃连接来促进梯度流动。通过在量子卷积层之间插入残差块，我们确保了网络中梯度的增强访问，从而提升了训练性能。此外，我们还提供了关于残差块在QuNNs中策略性放置的实证证据。通过大量实验，我们确定了一种高效的残差块配置，使网络中的所有层都能访问梯度，从而实现高效训练。研究结果表明，残差块的精确位置对最大化QuNNs的性能提升至关重要。我们的成果标志着量子深度学习发展的重要一步，为理论发展和实际量子计算应用提供了新途径。

</details>


### [432] [Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation](https://arxiv.org/abs/2506.22441)
**中文标题：基于阈值距离加权损失的张量潜在分解模型在交通数据估计中的应用**

*Lei Yang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于阈值距离加权损失（TDW）的张量潜在分解模型（TDWLFT），用于交通数据估计。该模型通过差异化权重减少异常值影响，显著提升了预测精度和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 智能交通系统（ITS）依赖高质量的时空交通数据，但实际数据采集常因通信故障或传感器故障导致数据缺失或损坏。传统张量潜在分解（LFT）模型使用标准L2范数，易受异常值影响，亟需改进。

研究方法: 提出了一种阈值距离加权损失（TDW）的张量潜在分解模型（TDWLFT），通过为样本分配差异化权重，减少异常值对模型的影响。

研究结果: 在两个不同城市环境的交通速度数据集上的实验表明，TDWLFT模型在预测精度和计算效率上均优于现有方法。

研究结论: TDWLFT模型通过引入阈值距离加权损失，有效提升了交通数据估计的鲁棒性和性能，为智能交通系统提供了更可靠的数据支持。

中文摘要: 智能交通系统（ITS）高度依赖完整且高质量的时空交通数据以实现最佳性能。然而，在实际交通数据采集过程中，通信故障和传感器故障等问题常导致数据集不完整或损坏，从而对ITS的发展构成重大挑战。在多种填补缺失时空交通数据的方法中，张量潜在分解（LFT）模型已成为一种广泛采用且有效的解决方案。然而，传统LFT模型通常在其学习目标中使用标准L2范数，这使得它们容易受到异常值的影响。为克服这一局限性，本文提出了一种基于阈值距离加权（TDW）损失的张量潜在分解（TDWLFT）模型。该损失函数通过为样本分配差异化权重，有效降低了模型对异常值的敏感性。在两个不同城市环境的交通速度数据集上进行的大量实验证实，所提出的TDWLFT模型在预测精度和计算效率上均优于现有方法。

</details>


### [433] [Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security](https://arxiv.org/abs/2506.22445)
**中文标题：面向网络物理系统安全的分层对抗弹性多智能体强化学习**

*Saad Alqithami*

主要分类: cs.LG

摘要简述: 本文提出了一种新型的分层对抗弹性多智能体强化学习框架（HAMARL），用于提升网络物理系统的安全性。该框架通过分层结构和对抗训练，显著提高了攻击检测准确率和响应速度。


<details>
  <summary>详细信息</summary>
研究动机: 网络物理系统（CPS）在多个关键领域（如制造、能源和自动驾驶）中扮演重要角色，但其日益增长的连接性使其容易受到复杂网络攻击的威胁。传统安全方法（如基于规则的入侵检测和单智能体强化学习）难以应对这些挑战，因此需要一种更高效、更具弹性的防御框架。

研究方法: HAMARL框架采用分层结构，包括专注于子系统安全的本地智能体和一个全局协调器，后者负责优化系统范围的防御策略。此外，框架还引入了对抗训练循环，以模拟和预测不断演变的网络威胁，从而实现主动防御。

研究结果: 在模拟工业物联网测试平台上的实验表明，HAMARL显著优于传统的多智能体强化学习方法，提高了攻击检测准确率，缩短了响应时间，并确保了系统运行的连续性。

研究结论: 结合分层多智能体协调与对抗感知训练，HAMARL有效提升了下一代网络物理系统的弹性和安全性。

中文摘要: 网络物理系统在制造业、能源分配和自动驾驶等多个领域的基础设施中发挥着关键作用。然而，其日益增长的连接性使其极易受到复杂网络威胁（如自适应和零日攻击）的影响，而传统的基于规则的入侵检测和单智能体强化学习方法对此显得力不从心。为应对这些挑战，本文提出了一种新型的分层对抗弹性多智能体强化学习（HAMARL）框架。HAMARL采用分层结构，包括专注于子系统安全的本地智能体和一个全局协调器，后者负责优化系统范围的防御策略。此外，框架还引入了对抗训练循环，以模拟和预测不断演变的网络威胁，从而实现主动防御。在模拟工业物联网测试平台上进行的广泛实验表明，HAMARL显著优于传统的多智能体强化学习方法，显著提高了攻击检测准确率，缩短了响应时间，并确保了系统运行的连续性。这些结果凸显了分层多智能体协调与对抗感知训练相结合在提升下一代网络物理系统弹性和安全性方面的有效性。

</details>


### [434] [EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis](https://arxiv.org/abs/2506.22446)
**中文标题：EAGLE：广义潜在嵌入的高效对齐用于多模态生存预测及可解释归因分析**

*Aakash Tripathi,Asim Waqas,Matthew B. Schabath,Yasin Yilmaz,Ghulam Rasool*

主要分类: cs.LG

摘要简述: EAGLE是一种新型深度学习框架，通过注意力机制的多模态融合和全面的归因分析，解决了现有癌症生存预测方法在融合策略、计算需求和可解释性方面的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有癌症生存预测方法在多模态数据融合上过于简单，计算需求大且缺乏可解释性，限制了临床应用的推广。EAGLE旨在解决这些问题。

研究方法: EAGLE采用动态跨模态注意力机制学习模态间层次关系，实现99.96%的维度压缩，同时保持预测性能，并提供三种互补的归因方法增强可解释性。

研究结果: 在911名患者（包括三种癌症类型）的测试中，EAGLE成功识别高风险患者依赖影像特征，低风险患者模态贡献均衡，风险分层显示生存差异显著。

研究结论: EAGLE结合高性能与临床可解释性，为多模态生存预测提供了可扩展方案，提升了预测准确性和医生对自动化预测的信任。

中文摘要: 准确的癌症生存预测需要整合反映影像、临床参数和文本报告复杂互动的多模态数据。然而，现有多模态方法存在融合策略简单、计算需求大和缺乏可解释性等问题，阻碍了临床应用。我们提出EAGLE（广义潜在嵌入的高效对齐），一种新型深度学习框架，通过注意力驱动的多模态融合和全面归因分析解决这些问题。EAGLE引入四项关键创新：（1）动态跨模态注意力机制学习模态间层次关系；（2）在保持预测性能的同时实现99.96%的维度压缩；（3）三种互补归因方法提供患者级可解释性；（4）统一流程适配多种癌症类型。我们在911名患者（包括胶质母细胞瘤、导管内乳头状黏液性肿瘤和非小细胞肺癌）中评估EAGLE。患者级分析显示高风险个体更依赖不良影像特征，低风险患者模态贡献均衡。风险分层识别出临床意义显著的群体，中位生存期差异达4倍（胶质母细胞瘤）至5倍（非小细胞肺癌），直接影响治疗强度决策。EAGLE结合先进性能与临床可解释性，弥合了AI能力与医疗实践间的鸿沟，为多模态生存预测提供了可扩展方案，提升预测准确性和医生对自动化预测的信任。

</details>


### [435] [Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture](https://arxiv.org/abs/2506.22447)
**中文标题：用于多变量气候降尺度的Vision Transformers：基于共享编码器和多解码器架构的区域气候模型模拟**

*Fabio Merizzi,Harilaos Loukos*

主要分类: cs.LG

摘要简述: 本文提出了一种基于共享编码器和多解码器架构的Vision Transformer（ViT）方法（1EMD），用于多变量气候降尺度任务，能够同时预测温度、风速和位势高度三个关键气候变量，显著优于单变量模型，并提高了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 全球气候模型（GCMs）的空间分辨率较低，限制了其在区域研究中的应用。区域气候模型（RCMs）虽然能通过动态降尺度提高分辨率，但计算成本高且灵活性不足。现有深度学习研究多关注单变量模型，缺乏跨变量交互和上下文感知。本文旨在解决这些问题，提出一种多任务、多变量的ViT架构。

研究方法: 提出了一种共享编码器和变量特定解码器的Vision Transformer架构（1EMD），用于同时预测表面温度（tas）、风速（sfcWind）和500 hPa位势高度（zg500）三个气候变量。该架构直接从GCM分辨率的输入数据中学习，模拟欧洲区域的RCM尺度降尺度。

研究结果: 实验表明，多变量方法实现了跨变量的知识迁移，在相同条件下显著优于单变量基线模型，同时提高了计算效率。

研究结论: 多变量建模在高分辨率气候降尺度任务中具有显著优势，能够有效提升模型性能和计算效率。

中文摘要: 全球气候模型（GCMs）在模拟大尺度气候动态方面至关重要，但其较低的空间分辨率限制了其在区域研究中的应用。区域气候模型（RCMs）通过动态降尺度提高了分辨率，但计算成本高昂且灵活性有限。深度学习作为一种高效的数据驱动方法崭露头角，但现有研究多集中于单变量模型，每次仅降尺度一个变量，导致上下文感知不足、计算冗余且缺乏跨变量交互。本研究提出了一种多任务、多变量的Vision Transformer（ViT）架构（1EMD），包含共享编码器和变量特定解码器，直接从GCM分辨率的输入数据中联合预测三个关键气候变量：表面温度（tas）、风速（sfcWind）和500 hPa位势高度（zg500），模拟欧洲区域的RCM尺度降尺度。实验表明，多变量方法实现了跨变量的知识迁移，在相同条件下显著优于单变量基线模型，同时提高了计算效率。这些结果证明了多变量建模在高分辨率气候降尺度任务中的有效性。

</details>


### [436] [Residual Matrix Transformers: Scaling the Size of the Residual Stream](https://arxiv.org/abs/2506.22696)
**中文标题：残差矩阵变换器：扩展残差流的规模**

*Brian Mak,Jeffrey Flanigan*

主要分类: cs.LG

摘要简述: 本文提出了一种名为残差矩阵变换器（RMT）的新模型，通过将传统变换器的残差流替换为外积记忆矩阵，实现了残差流规模的独立扩展，显著提升了性能并减少了计算和参数需求。


<details>
  <summary>详细信息</summary>
研究动机: 传统变换器的残差流在存储和访问特征时存在效率限制，本文旨在通过改进残差流的信息存储和检索机制，提升模型的性能和效率。

研究方法: 将变换器的残差流替换为外积记忆矩阵（Kohonen, 1972, Anderson, 1972），构建残差矩阵变换器（RMT），并对其进行了理论分析。

研究结果: RMT能够独立扩展残差流规模，性能优于传统变换器，计算量减少58%，参数减少25%，训练标记减少41%，并在下游任务中表现更优。

研究结论: RMT通过改进残差流机制，实现了更高效的扩展和性能提升，为变换器模型的优化提供了新思路。

中文摘要: 残差流作为变换器层存储和访问特征的内存总线（Elhage et al., 2021）。本文探讨了改变残差流中信息存储和检索的机制，将变换器的残差流替换为外积记忆矩阵（Kohonen, 1972, Anderson, 1972），并将该模型称为残差矩阵变换器（RMT）。研究发现，RMT具有多项优势：1）残差流的规模可以独立于计算和模型规模进行扩展，从而提升性能；2）RMT能以58%更少的计算量、25%更少的参数和41%更少的训练标记达到与传统变换器相同的损失；3）RMT在下游评估中表现优于传统变换器。本文对变换器和RMT进行了理论分析，表明RMT能够更高效地扩展残差流，并具有更好的方差传播特性。项目代码见https://github.com/bmac3/residual-matrix-transformer。

</details>


### [437] [BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute](https://arxiv.org/abs/2506.22716)
**中文标题：BEST-Route：基于测试时最优计算的自适应LLM路由**

*Dujian Ding,Ankur Mallick,Shaokun Zhang,Chi Wang,Daniel Madrigal,Mirian Del Carmen Hipolito Garcia,Menglin Xia,Laks V. S. Lakshmanan,Qingyun Wu,Victor Rühle*

主要分类: cs.LG

摘要简述: BEST-Route是一种新型的LLM路由框架，通过动态选择模型和生成多个响应来优化成本与性能的权衡，实验显示可节省60%成本且性能下降不到1%。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）部署成本高，现有路由方法因仅生成单一响应而过度依赖昂贵模型，未能充分利用低成本模型的潜力。

研究方法: BEST-Route根据查询难度和质量阈值动态选择模型及其生成响应的数量，通过多响应选择提升小模型性能。

研究结果: 实验表明，BEST-Route在真实数据集上可节省高达60%的成本，性能损失不足1%。

研究结论: BEST-Route通过自适应路由和多响应策略，显著降低成本同时保持高性能，为LLM部署提供了高效解决方案。

中文摘要: 大型语言模型（LLM）功能强大，但大规模部署成本高昂。LLM查询路由通过动态分配查询到不同成本和质量的模型，以实现理想的权衡。现有路由方法仅从选定模型生成单一响应，而小模型（低成本）的单一响应通常无法超越大模型（高成本）的响应，导致过度使用大模型并错失成本节省机会。然而，对于小模型，生成多个响应并选择最优可以提升质量，同时仍比单一大型模型响应更经济。基于此，我们提出BEST-Route，一种新型路由框架，根据查询难度和质量阈值选择模型及其生成响应的数量。真实数据集实验表明，该方法可节省高达60%的成本，性能下降不足1%。

</details>


### [438] [BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters](https://arxiv.org/abs/2506.22809)
**中文标题：BayesLoRA：低秩适配器中的任务特定不确定性**

*Cooper Doyle*

主要分类: cs.LG

摘要简述: 本文提出BayesLoRA，一种针对特定任务的不确定性量化框架，通过将MC-Dropout集成到低秩适配器（LoRA）中，为下游工作流提供定制化的不确定性评估。


<details>
  <summary>详细信息</summary>
研究动机: 现有的通用Transformer不确定性方法无法满足下游任务的具体需求，BayesLoRA旨在填补这一空白，为智能体在不确定性下的行为提供可靠的自省和调节机制。

研究方法: BayesLoRA将MC-Dropout与LoRA结合，通过数学和实验证明LoRA适配器在微调分布外区域表现出放大的方差，从而为智能体决策提供可靠置信度估计。

研究结果: 实验表明，BayesLoRA能够有效量化任务特定不确定性，并在分布外场景中提供高置信度的决策支持。

研究结论: BayesLoRA为下游任务提供了一种高效且定制化的不确定性量化方法，显著提升了智能体在不确定性环境中的决策能力。

中文摘要: 我们提出了BayesLoRA，一种任务特定的不确定性量化框架，将MC-Dropout集成到低秩适配器（LoRA）中。与通用Transformer不确定性方法不同，BayesLoRA为下游工作流提供了定制化的防护机制，使智能体能够在不确定性下自省并调节行为。我们通过数学和实验证明，LoRA适配器在微调分布外区域表现出放大的方差，从而为智能体决策提供可靠的置信度估计。

</details>


### [439] [Exploration Behavior of Untrained Policies](https://arxiv.org/abs/2506.22566)
**中文标题：未经训练策略的探索行为**

*Jacob Adamczyk*

主要分类: cs.LG

摘要简述: 本文研究了未经训练的深度神经网络策略在强化学习中的探索行为，揭示了策略架构如何隐式影响探索轨迹，并通过理论和实验验证了其非平凡的访问分布。


<details>
  <summary>详细信息</summary>
研究动机: 探索是强化学习中的核心挑战，尤其是在稀疏或对抗性奖励环境中。本文旨在理解未经训练的策略如何通过其架构隐式影响探索行为，为早期训练提供设计工具。

研究方法: 通过理论分析和实验验证，研究了无限宽度网络和连续时间极限下未经训练策略的行为，分析了标准架构生成的轨迹分布。

研究结果: 研究发现，未经训练的策略会产生相关动作，并导致非平凡的状态访问分布，揭示了探索行为的归纳偏置。

研究结论: 本文为理解早期训练中的探索行为提供了理论和实验框架，表明策略初始化可作为设计工具优化探索策略。

中文摘要: 探索仍然是强化学习（RL）中的一个基本挑战，尤其是在具有稀疏或对抗性奖励结构的环境中。本文研究了深度神经网络策略的架构如何在训练前隐式地塑造探索行为。我们通过理论和实验证明了一个玩具模型中未经训练策略生成弹道或扩散轨迹的策略。利用无限宽度网络理论和连续时间极限，我们展示了未经训练的策略会产生相关动作，并导致非平凡的状态访问分布。我们讨论了标准架构对应轨迹的分布，揭示了解决探索问题的归纳偏置。我们的结果为使用策略初始化作为设计工具理解早期训练中的探索行为建立了理论和实验框架。

</details>


### [440] [The Hidden Link Between RLHF and Contrastive Learning](https://arxiv.org/abs/2506.22578)
**中文标题：RLHF与对比学习之间的隐藏联系**

*Xufei Lv,Haoyuan Sun,Xuefeng Bai,Min Zhang,Houde Liu,Kehai Chen*

主要分类: cs.LG

摘要简述: 本文揭示了强化学习人类反馈（RLHF）和直接偏好优化（DPO）与对比学习之间的深层联系，提出了一种基于互信息优化的新方法MIO，解决了DPO中后期性能下降的问题。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索RLHF和DPO与对比学习之间的潜在联系，并解决现有方法在激励大语言模型推理能力方面的局限性。

研究方法: 通过互信息最大化框架，将RLHF和DPO解释为基于正负样本的对比学习方法，并提出使用Jensen-Shannon互信息估计器替代DV/MINE边界，提出MIO方法。

研究结果: 理论分析和实验表明，MIO能够缓解DPO中后期性能下降的问题，在多项推理和数学基准测试中表现优异。

研究结论: MIO方法不仅揭示了RLHF和DPO与对比学习的联系，还提供了一种更优的优化框架，为未来研究提供了新方向。

中文摘要: 大语言模型（LLM）与人类价值观的对齐近年来备受关注，其中典型的但成本高昂的强化学习人类反馈（RLHF）和简单的直接偏好优化（DPO）是主要方法。本文通过互信息（MI）最大化的视角，揭示了RLHF和DPO与对比学习的深刻联系。在这一框架下，RLHF和DPO可被视为基于基础模型生成的正负样本进行对比学习的方法，利用了Donsker-Varadhan（DV）互信息下界（即MINE估计器）。这一范式进一步解释了为何RLHF无法激励LLM超越基础模型的推理能力。基于此，我们提出用Jensen-Shannon互信息估计器替代DV/MINE边界，并提出互信息优化（MIO）方法。全面的理论分析和广泛的实验表明，MIO能够缓解DPO中后期选择似然下降的问题，在多项具有挑战性的推理和数学基准测试中表现优异。模型和代码将在论文接受后发布。

</details>


### [441] [Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training](https://arxiv.org/abs/2506.22638)
**中文标题：数学推理的层级重要性在预训练中形成且在后训练中保持不变**

*Aadim Nepal,Safal Shrestha,Anubhav Shrestha,Minwu Kim,Keith Ross*

主要分类: cs.LG

摘要简述: 研究发现，数学推理能力的提升依赖于预训练中形成的特定层级结构，且这种结构在后训练中保持不变。非数学任务则无此特性。


<details>
  <summary>详细信息</summary>
研究动机: 探究后训练（如指令调优、强化学习或知识蒸馏）是否显著改变了大语言模型在数学推理中的层级重要性结构，还是仅进行了微调。

研究方法: 通过系统性的逐层消融实验，分析了基础模型、指令调优模型、知识蒸馏模型和强化学习变体在数学推理任务中的表现。

研究结果: 数学推理任务中，特定层级的重要性结构在后训练中保持不变，移除这些层级会导致准确率大幅下降（高达80%）。非数学任务（如事实回忆）则无此现象。

研究结论: 数学推理依赖于预训练中形成的专用层级，这些层级在后训练中保持不变；而非推理任务则无此需求。

中文摘要: 大型语言模型通过指令调优、强化学习或知识蒸馏等后训练方式可以提升数学推理能力。然而，这些改进是否源于对Transformer层级的重大改变，还是仅通过微调保留了基础模型的相对层级重要性结构，尚不明确。我们通过系统的逐层消融实验，研究了基础模型、指令调优模型、知识蒸馏模型和强化学习变体在数学推理基准上的表现。结果表明，数学推理任务形成了一种特定的层级重要性结构，且这种结构在所有后训练范式中均保持不变。移除这些层级会导致准确率下降高达80%。相比之下，非数学任务（如事实回忆）则无关键层级。这一区别表明，数学推理需要预训练中形成的专用层级，而其他非推理任务则不需要。从信息论的角度看，这些关键层级也是主要表征转换发生的层级。

</details>


### [442] [Masked Gated Linear Unit](https://arxiv.org/abs/2506.23225)
**中文标题：掩码门控线性单元**

*Yukito Tajima,Nakamasa Inoue,Yusuke Sekikawa,Ikuro Sato,Rio Yokota*

主要分类: cs.LG

摘要简述: 本文提出了一种新型的Masked Gated Linear Unit (MGLU)，通过共享权重矩阵和高效内核实现，显著减少了内存读取需求，提升了推理速度和内存效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的Gated Linear Units (GLUs)在大型语言模型中广泛使用，但由于需要为门控和值流分别读取权重矩阵，导致内存读取量翻倍。本文旨在解决这一瓶颈问题。

研究方法: 1. 提出Mixture of Element-wise Gating (MoEG)架构，通过多个二进制掩码在共享权重矩阵上实现门控和值分配；2. 开发了硬件友好的FlashMGLU内核，显著提升推理效率。

研究结果: 实验表明，FlashMGLU在RTX5090 GPU上比标准GLU快34%，内存效率提升47%，推理速度提升19.7倍。SwiMGLU在保持内存优势的同时，性能甚至超过SwiGLU基线。

研究结论: MGLU通过创新的架构设计和高效内核实现，显著提升了GLU的性能和效率，为大型语言模型的优化提供了新思路。

中文摘要: 门控线性单元（GLUs）已成为最先进大型语言模型（LLMs）前馈网络的核心组件。然而，由于门控和值流需要分别读取权重矩阵，其内存读取量是普通前馈层的两倍。为解决这一瓶颈，我们提出了掩码门控线性单元（MGLUs），这是一种具有高效内核实现的新型GLU家族。MGLU的核心贡献包括：（1）混合逐元素门控（MoEG）架构，通过学习多个二进制掩码，在单一共享权重矩阵上实现门控和值的逐元素分配，从而减少内存传输；（2）FlashMGLU，一种硬件友好的内核，在RTX5090 GPU上比标准GLU快34%，内存效率提升47%，推理速度比朴素PyTorch实现快19.7倍。在LLM实验中，Swish激活的变体SwiMGLU在保持内存优势的同时，下游任务性能与SwiGLU基线相当甚至更优。

</details>


### [443] [DistShap: Scalable GNN Explanations with Distributed Shapley Values](https://arxiv.org/abs/2506.22668)
**中文标题：DistShap：基于分布式Shapley值的可扩展图神经网络解释方法**

*Selahattin Akkas,Aditya Devarakonda,Ariful Azad*

主要分类: cs.LG

摘要简述: DistShap是一种并行算法，通过分布式计算Shapley值来高效解释图神经网络（GNN）的预测，解决了传统方法计算成本高的问题，并首次实现了百万级特征的GNN模型的可扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 随着图神经网络（GNN）的广泛应用，解释其预测结果变得至关重要。然而，传统方法在计算特定边或特征对预测的贡献时成本高昂，尤其是对于大规模图数据。因此，需要一种高效且可扩展的解释方法。

研究方法: DistShap通过分布式采样子图，在多GPU上并行执行GNN推理，并解决分布式最小二乘问题来计算边的重要性分数。该方法利用多达128个GPU的超级计算机资源，显著提升了计算效率。

研究结果: DistShap在准确性上优于大多数现有的GNN解释方法，并首次实现了对百万级特征GNN模型的可扩展性，展示了其在大规模图数据上的高效表现。

研究结论: DistShap为GNN提供了一种高效且可扩展的解释方法，解决了传统方法计算成本高的问题，为大规模图数据的分析提供了新的可能性。

中文摘要: 随着图神经网络（GNN）的广泛应用，解释其预测结果变得越来越重要。然而，将预测归因于特定边或特征的计算成本仍然很高。例如，对一个具有100个邻居的节点进行分类时，可能需要从数百万候选边中识别出对预测重要的边。为解决这一问题，我们提出了DistShap，一种并行算法，通过在多GPU上分布式计算Shapley值来解释GNN预测。DistShap通过在分布式环境中采样子图，在多GPU上并行执行GNN推理，并解决分布式最小二乘问题来计算边的重要性分数。DistShap在准确性上优于大多数现有的GNN解释方法，并首次利用NERSC Perlmutter超级计算机上的128个GPU，实现了对百万级特征GNN模型的可扩展性。

</details>


### [444] [FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision](https://arxiv.org/abs/2506.22771)
**中文标题：FF-INT8：基于INT8精度的边缘设备高效Forward-Forward深度神经网络训练**

*Jingxiao Ma,Priyadarshini Panda,Sherief Reda*

主要分类: cs.LG

摘要简述: 本文提出了一种基于INT8量化的Forward-Forward（FF）算法，用于在边缘设备上高效训练深度神经网络，通过减少内存占用和提升训练速度，同时保持模型精度。


<details>
  <summary>详细信息</summary>
研究动机: 反向传播算法在时间和能耗上的低效性限制了其在资源受限的边缘设备上的应用。低精度量化虽在推理中广泛应用，但在训练中的研究较少。Forward-Forward算法通过避免存储中间激活值，更适合嵌入式设备。

研究方法: 提出了一种INT8量化的训练方法，利用FF算法的逐层策略稳定梯度量化，并引入“前瞻”方案以提升模型精度。

研究结果: 在NVIDIA Jetson Orin Nano上的实验显示，该方法实现了4.6%的训练加速、8.3%的能耗节省和27.0%的内存占用减少，同时保持了与现有技术相当的精度。

研究结论: INT8量化的FF算法为边缘设备上的高效训练提供了可行方案，显著提升了训练速度和资源利用率。

中文摘要: 反向传播作为神经网络训练的基石已有数十年，但其在时间和能耗上的低效性限制了其在资源受限的边缘设备上的适用性。尽管低精度神经网络量化已广泛用于加速模型推理，但其在训练中的应用研究较少。近年来，Forward-Forward（FF）算法作为一种有前景的反向传播替代方案出现，通过用额外的前向传播替代反向传播，避免了存储中间激活值的需求，从而减少了内存占用，非常适合嵌入式设备。本文提出了一种INT8量化的训练方法，利用FF的逐层策略稳定梯度量化，并进一步提出了一种新颖的“前瞻”方案以解决FF的局限性并提升模型精度。在NVIDIA Jetson Orin Nano开发板上的实验表明，该方法实现了4.6%的训练加速、8.3%的能耗节省和27.0%的内存占用减少，同时保持了与现有技术相当的精度。

</details>


### [445] [Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts](https://arxiv.org/abs/2506.23845)
**中文标题：使用稀疏自编码器发现未知概念，而非作用于已知概念**

*Kenny Peng,Rajiv Movva,Jon Kleinberg,Emma Pierson,Nikhil Garg*

主要分类: cs.LG

摘要简述: 稀疏自编码器（SAEs）在已知概念上的应用效果不佳，但在发现未知概念方面表现强大。论文区分了这两种用途，并提出了SAEs在可解释性、社会科学等领域的潜在应用。


<details>
  <summary>详细信息</summary>
研究动机: 尽管稀疏自编码器（SAEs）引起了广泛关注，但其实际效果受到质疑。论文旨在通过区分SAEs在已知和未知概念上的不同作用，澄清其适用性，并探索新的应用场景。

研究方法: 论文通过理论分析和现有研究结果的对比，提出SAEs在已知概念上表现不佳，但在发现未知概念方面具有优势。同时，论文列举了SAEs在多个领域的具体应用案例。

研究结果: 研究结果表明，SAEs在发现未知概念方面具有显著潜力，尤其是在机器学习可解释性、社会科学和健康科学等领域。

研究结论: SAEs的价值在于其发现未知概念的能力，而非作用于已知概念。论文为SAEs的未来研究指明了方向，并提出了实际应用的可能性。

中文摘要: 尽管稀疏自编码器（SAEs）引发了广泛关注，但一系列负面结果增加了对其实用性的质疑。本文通过建立一个概念上的区分，调和了围绕SAEs的竞争性叙述。我们认为，虽然SAEs在作用于已知概念上可能效果较差，但其在发现未知概念方面是一种强大的工具。这一区分清晰地分离了现有的负面和正面结果，并提出了几类SAEs的应用场景。具体而言，我们概述了SAEs在（i）机器学习的可解释性、公平性、审计和安全性，以及（ii）社会科学和健康科学中的用例。

</details>


### [446] [LLM Agents Are the Antidote to Walled Gardens](https://arxiv.org/abs/2506.23978)
**中文标题：LLM智能体是封闭花园的解药**

*Samuele Marro,Philip Torr*

主要分类: cs.LG

摘要简述: 论文提出基于LLM的智能体能够打破封闭平台的垄断，通过自动翻译数据格式和交互界面实现低成本互操作性，但需注意安全和债务风险。


<details>
  <summary>详细信息</summary>
研究动机: 当前互联网应用层被封闭平台主导，开放API成本高且缺乏激励。LLM智能体有望改变这一现状，通过低成本互操作性打破垄断。

研究方法: 利用LLM智能体自动翻译数据格式和交互界面，实现服务间的无缝数据交换，称为“通用互操作性”。

研究结果: 通用互操作性削弱垄断行为，促进数据可移植性，但也可能带来新的安全风险和技术债务。

研究结论: ML社区应积极拥抱这一趋势，同时建立框架以降低风险，利用AI恢复用户自由和市场竞争。

中文摘要: 尽管互联网的核心基础设施设计为开放和通用，但当今的应用层却被封闭的专有平台主导。开放和互操作的API需要大量投资，而市场领导者几乎没有激励去支持可能削弱其用户粘性的数据交换。我们认为，基于LLM的智能体从根本上改变了这一现状。智能体可以自动翻译数据格式并与为人类设计的界面交互：这使得互操作性成本大幅降低且实际上不可避免。我们将这一转变称为“通用互操作性”：任何两个数字服务通过AI介导的适配器无缝交换数据的能力。通用互操作性削弱了垄断行为并促进了数据可移植性。然而，它也可能带来新的安全风险和技术债务。我们的立场是，ML社区应积极拥抱这一发展，同时建立适当的框架以降低负面影响。通过立即行动，我们可以利用AI恢复用户自由和市场竞争，而不会牺牲安全性。

</details>


### [447] [xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection](https://arxiv.org/abs/2506.22837)
**中文标题：xLSTMAD：一种基于xLSTM的强大异常检测方法**

*Kamil Faber,Marcin Pietroń,Dominik Żurek,Roberto Corizzo*

主要分类: cs.LG

摘要简述: 本文提出了一种基于xLSTM的异常检测方法xLSTMAD，首次将xLSTM架构应用于多变量时间序列数据的异常检测，并在TSB-AD-M基准测试中表现出色，超越了23种现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管xLSTM在时间序列预测、无损压缩和大规模语言建模中表现出色，但尚未有人将其应用于异常检测。本文旨在填补这一空白，探索xLSTM在异常检测中的潜力。

研究方法: xLSTMAD采用完整的编码器-解码器xLSTM架构，分为两种变体：xLSTMAD-F通过预测未来值进行异常检测，xLSTMAD-R通过重构输入时间序列进行检测。研究还比较了MSE和SoftDTW两种损失函数的效果。

研究结果: 在TSB-AD-M基准测试中，xLSTMAD在17个真实数据集上表现优异，使用VUS-PR等指标评估后，超越了23种现有方法，展示了xLSTM在异常检测中的强大能力。

研究结论: 本文首次揭示了xLSTM在异常检测中的强大建模能力，为未来相关研究开辟了新方向。代码已开源。

中文摘要: 最近提出的xLSTM是一种强大的模型，利用表达性乘法门控和残差连接，为长时预测和表示学习提供了所需的时间能力。该架构在时间序列预测、无损压缩甚至大规模语言建模任务中表现出色，其线性内存占用和快速推理使其成为Transformer的可行替代方案。尽管其日益流行，但尚未有工作探索xLSTM在异常检测中的应用。本文填补了这一空白，提出了xLSTMAD，这是首个集成完整编码器-解码器xLSTM架构的异常检测方法，专为多变量时间序列数据设计。编码器处理输入序列以捕获历史上下文，而解码器分为两种变体：预测方法（xLSTMAD-F）迭代生成预测的未来值，重构方法（xLSTMAD-R）从编码后的输入中重构时间序列。我们研究了两种损失函数的性能：均方误差（MSE）和软动态时间规整（SoftDTW），分别考虑局部重构保真度和全局序列对齐。我们在全面的TSB-AD-M基准测试上评估了该方法，涵盖17个真实数据集，并使用VUS-PR等具有挑战性的指标。结果显示，xLSTM表现出最先进的准确性，超越了23种流行的异常检测基线方法。本文首次揭示了xLSTM在异常检测中的强大建模能力，为该主题的激动人心的新发展铺平了道路。代码已开源：https://github.com/Nyderx/xlstmad

</details>


### [448] [Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models](https://arxiv.org/abs/2506.22845)
**中文标题：量子神经网络在风能预测中的性能与可扩展性：与经典模型的对比研究**

*Batuhan Hangun,Oguz Altun,Onder Eyecioglu*

主要分类: cs.LG

摘要简述: 本文研究了量子神经网络（QNN）在风能预测中的性能与可扩展性，并与经典模型进行了对比。实验表明，QNN在某些情况下表现优于经典方法，同时分析了数据集规模和电路复杂度对性能的影响。


<details>
  <summary>详细信息</summary>
研究动机: 随着智能电网和可再生能源系统的普及，机器学习在电力需求预测和系统干扰检测中扮演重要角色。量子神经网络（QNN）作为量子机器学习的一种方法，近年来在时间序列预测等领域展现出潜力。本研究旨在探索QNN在风能预测中的表现及其与经典模型的对比。

研究方法: 研究评估了六种基于Z特征映射数据编码和不同ansatz结构的QNN配置。通过详细的交叉验证实验和未见过的保留数据集测试，比较了QNN与经典模型的预测性能和模拟时间。

研究结果: 实验结果表明，QNN的预测性能与经典模型相当，甚至在某些情况下略优。同时，研究揭示了数据集规模和电路复杂度对预测性能和模拟时间的影响。

研究结论: 本研究为能源领域的研究者提供了量子机器学习应用的宝贵见解，表明QNN在风能预测中具有潜力，尤其是在特定条件下优于经典方法。

中文摘要: 量子神经网络（QNN）作为量子机器学习（QML）的重要方法，正逐渐成为经典机器学习方法的有力替代。近期研究聚焦于QNN在时间序列预测、分类等任务中的适用性，涵盖网络安全和医学影像等多个领域。随着可再生能源系统驱动的智能电网广泛应用，机器学习在电力需求预测和系统干扰检测中扮演重要角色。本研究深入探讨了QNN在风力发电机功率输出预测中的应用。我们评估了六种基于Z特征映射数据编码和不同ansatz结构的QNN配置的预测性能和模拟时间。通过详细的交叉验证实验和未见过的保留数据集测试，实验证明QNN的预测性能可与经典方法媲美，甚至在某些情况下略优。结果还揭示了数据集规模和电路复杂度对预测性能和模拟时间的影响。我们相信，这些发现将为能源领域希望引入量子机器学习的研究者提供宝贵参考。

</details>


### [449] [Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles](https://arxiv.org/abs/2506.22848)
**中文标题：通过算法集成学习贝叶斯网络的可扩展结构学习方法**

*Shengcai Liu,Hui Ou-yang,Zhiyuan Wang,Cheng Chen,Qijun Cai,Yew-Soon Ong,Ke Tang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于结构学习集成（SLE）的方法Auto-SLE，用于提升贝叶斯网络（BN）在大规模数据集上的结构学习准确性和稳定性，显著优于传统分治策略。


<details>
  <summary>详细信息</summary>
研究动机: 当前分治策略在贝叶斯网络结构学习中存在子问题学习准确性不稳定的问题，限制了其在大规模数据集上的应用。

研究方法: 通过结合多种BN结构学习算法构建结构学习集成（SLE），并提出了自动学习最优SLE的方法Auto-SLE，将其整合到分治策略中。

研究结果: 实验表明，该方法在涉及10,000变量的数据集上通常能提升30%至225%的准确性，并能泛化到更大规模（如30,000变量）和不同网络特性的数据集。

研究结论: 结构学习集成（SLE）及其自动学习方法Auto-SLE在可扩展的BN结构学习中具有显著潜力。

中文摘要: 从数据中学习贝叶斯网络（BN）的结构具有挑战性，尤其是在涉及大量变量的数据集中。最近提出的分治（D&D）策略为学习大规模BN提供了一种有前景的方法，但其仍面临子问题学习准确性不稳定的主要问题。本文引入了结构学习集成（SLE）的思想，通过结合多种BN结构学习算法，以持续实现高学习准确性。我们进一步提出了一种称为Auto-SLE的自动方法，用于学习接近最优的SLE，解决了手动设计高质量SLE的挑战。学习到的SLE随后被整合到分治方法中。大量实验表明，我们的方法在涉及10,000变量的数据集上通常能提升30%至225%的准确性，显著优于使用单一BN结构学习算法的分治方法。此外，我们的方法能够很好地泛化到比训练数据中更多变量（如30,000）和不同网络特性的数据集。这些结果表明，采用（自动学习的）SLE在可扩展的BN结构学习中具有显著潜力。

</details>


### [450] [Interpretable Time Series Autoregression for Periodicity Quantification](https://arxiv.org/abs/2506.22895)
**中文标题：可解释的时间序列自回归用于周期性量化**

*Xinyu Chen,Vassilis Digalakis Jr,Lijun Ding,Dingyi Zhuang,Jinhua Zhao*

主要分类: cs.LG

摘要简述: 本文提出了一种新的稀疏自回归框架，通过ℓ0范数稀疏约束增强模型可解释性，用于周期性量化。针对时变和多维时间序列数据，提出了优化的混合整数规划（MIO）求解方法，并通过决策变量剪枝（DVP）策略加速求解。实验验证了模型在人类移动性和气候数据中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 时间序列自回归是捕捉自相关性和识别周期性等时间模式的经典统计模型。然而，现有方法在可解释性和处理复杂时空数据方面存在不足。本文旨在通过稀疏约束和优化方法提升模型的可解释性和扩展性。

研究方法: 1. 提出基于ℓ0范数稀疏约束的稀疏自回归框架；2. 针对时变时间序列，将优化问题转化为混合整数规划（MIO），并开发决策变量剪枝（DVP）策略加速求解；3. 针对多维时间序列，提出时空变化的稀疏自回归模型，并通过两阶段优化方案解决大规模问题。

研究结果: 1. DVP策略显著加速MIO求解，同时保持解的质量；2. 在拼车数据中揭示了人类移动性的日周期和周周期变化；3. 在气候数据中发现了年季节性空间模式，并识别了厄尔尼诺等现象。

研究结论: 本文提出的稀疏自回归框架在可解释性和扩展性上表现优异，适用于复杂时空数据的周期性量化，为人类移动性和气候模式研究提供了新工具。

中文摘要: 时间序列自回归是一种经典的统计模型，用于捕捉自相关性和识别周期性等时间模式。本研究从可解释机器学习的角度提出了一种新的稀疏自回归框架，并通过ℓ0范数稀疏约束增强了周期性量化的模型可解释性。针对时变时间序列数据，我们重新定义了稀疏自回归，并将优化问题转化为混合整数规划（MIO）。为加速求解，开发了一种基于子空间追踪的决策变量剪枝（DVP）策略以减少搜索空间。对于涉及复杂时空维度的多维时间序列，我们提出了一种时空变化的稀疏自回归模型，并通过两阶段优化方案解决了相应的MIO问题。该方案使模型能够扩展到包含数百万决策变量的大规模问题。实证中，我们在真实世界时间序列数据上进行了广泛实验。首先，我们证明DVP策略可以显著加速MIO求解，同时保持与完整MIO求解器相同的解质量。将时变稀疏自回归模型应用于拼车数据，揭示了人类移动性的日周期和周周期变化。其次，我们展示了气候变量（如温度和降水）在过去四十年中的年季节性空间模式，该模型能够发现动态气候模式并识别如海表温度中的厄尔尼诺等现象。

</details>


### [451] [Missing-Modality-Aware Graph Neural Network for Cancer Classification](https://arxiv.org/abs/2506.22901)
**中文标题：缺失模态感知图神经网络在癌症分类中的应用**

*Sina Tabakhi,Haiping Lu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为MAGNET的缺失模态感知图神经网络，用于癌症分类，能够有效处理多模态生物数据中的缺失模态问题，并在实验中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 多模态生物数据中常见的缺失模态问题限制了现有融合方法的性能，尤其是面对多样化的缺失模式和模态数量增加时的复杂性。本文旨在解决这一问题。

研究方法: MAGNET通过患者-模态多头注意力机制融合低维模态嵌入，并根据缺失模式构建患者图，再结合传统图神经网络进行预测。其复杂度随模态数量线性增长，适应性强。

研究结果: 在三个公开的多组学癌症分类数据集上，MAGNET在真实缺失模态场景下表现优于现有融合方法。

研究结论: MAGNET通过创新的缺失模态感知机制和图神经网络设计，显著提升了多模态数据分类的性能，为生物医学研究提供了新工具。

中文摘要: 多模态生物数据学习中的一个关键挑战是缺失模态问题，即某些患者的部分模态数据完全缺失。现有的融合方法通过排除缺失模态患者、填补缺失模态或直接使用部分模态进行预测来解决这一问题，但它们在面对多样化的缺失模式和模态数量增加时的复杂性时表现不佳。为解决这些局限性，我们提出了MAGNET（缺失模态感知图神经网络），通过引入患者-模态多头注意力机制，基于模态的重要性和缺失性融合低维模态嵌入。MAGNET的复杂度随模态数量线性增长，同时能够适应缺失模式的多样性。为了生成预测结果，MAGNET进一步构建了一个以融合多模态嵌入为节点特征、以模态缺失性为连接关系的患者图，并采用传统图神经网络进行处理。在三个公开的多组学癌症分类数据集上的实验表明，MAGNET在真实缺失模态场景下优于现有融合方法。数据和代码可在https://github.com/SinaTabakhi/MAGNET获取。

</details>


### [452] [Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration](https://arxiv.org/abs/2506.22929)
**中文标题：基于数组编程和并行加速的高维数据数学计算**

*Chen Zhang*

主要分类: cs.LG

摘要简述: 提出了一种基于空间完整性的并行计算架构，用于处理高维数据，支持科学计算和机器学习方法的无缝集成。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在高维数据处理中面临计算挑战，现有工具缺乏对高级数学统计的支持，因此需要一种新的计算框架。

研究方法: 通过空间完整性分解高维数据为维度无关的结构，实现分布式处理，并集成数据挖掘和并行优化的机器学习方法。

研究结果: 该框架能够高效处理多种数据类型（如医学和自然图像），支持科学计算和机器学习任务。

研究结论: 提出的并行计算架构为高维数据处理提供了高效且统一的解决方案，适用于多样化的科学计算需求。

中文摘要: 尽管深度学习在自然图像和语言处理中表现出色，但其在高维数据中的应用因维度诅咒而面临计算挑战。当前的大规模数据工具主要关注商业导向的描述性统计，缺乏对高级分析的数学统计支持。我们提出了一种基于空间完整性的并行计算架构，将高维数据分解为维度无关的结构以实现分布式处理。该框架能够无缝集成数据挖掘和并行优化的机器学习方法，支持在统一系统中对多种数据类型（如医学和自然图像）进行科学计算。

</details>


### [453] [BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs](https://arxiv.org/abs/2506.23024)
**中文标题：BWLer：重心权重层揭示PINNs中精度与条件数的权衡关系**

*Jerry Liu,Yasa Baig,Denise Hui Jean Lee,Rajat Vadiraj Dwaraknath,Atri Rudra,Chris Ré*

主要分类: cs.LG

摘要简述: 本文提出了一种名为BWLer（重心权重层）的新方法，用于解决物理信息神经网络（PINNs）在求解偏微分方程（PDEs）时精度受限的问题。BWLer通过重心多项式插值建模PDE解，显著提升了精度，并揭示了精度与PDE条件数之间的权衡关系。


<details>
  <summary>详细信息</summary>
研究动机: 物理信息神经网络（PINNs）在求解偏微分方程时具有灵活性，但其精度远未达到科学任务所需的机器精度水平。本文旨在探究精度瓶颈是否源于PDE的病态条件或多层感知机（MLP）架构的限制。

研究方法: 提出BWLer（重心权重层），通过重心多项式插值建模PDE解。BWLer可作为MLP的附加层（BWLer-hat）或完全替代MLP（显式BWLer），从而分离解的表示与PDE损失的导数计算。通过BWLer，揭示了MLP在精度上的固有局限性，并利用谱导数和预处理技术优化训练过程。

研究结果: 在五个基准PDE任务中，BWLer显著提升了精度：对流问题提升30倍，反应问题提升10倍，波动方程提升1800倍。显式BWLer甚至能在对流、反应和波动问题中接近机器精度（比先前结果高100亿倍），并在Burgers方程和不规则几何Poisson问题中与传统PINNs性能相当。

研究结论: BWLer为PINNs提供了一种兼具灵活性和高精度的解决方案，揭示了精度与PDE条件数之间的权衡关系，为结合PINNs与经典谱求解器的优势提供了实用路径。

中文摘要: 物理信息神经网络（PINNs）为利用机器学习求解偏微分方程（PDEs）提供了灵活的方法，但其精度远未达到科学任务所需的机器精度水平。本文探究了精度瓶颈是否源于PDE的病态条件或多层感知机（MLP）架构的限制，并提出了重心权重层（BWLer），通过重心多项式插值建模PDE解。BWLer可作为MLP的附加层（BWLer-hat）或完全替代MLP（显式BWLer），从而分离解的表示与PDE损失的导数计算。通过BWLer，我们发现MLP在精度上存在固有局限性：在简单的1-D插值任务中，即使具有O(1e5)参数的MLP，其均方根误差（RMSE）仍停滞在1e-8左右（比float64机器精度低约八个数量级）。在PDE学习中，BWLer突破了这一限制，并揭示了可达到精度与PDE损失条件数之间的权衡关系。对于线性PDE，我们通过显式误差分解和谱导数与预处理技术，在训练中优化这一权衡关系。在五个基准PDE任务中，BWLer显著提升了精度：对流问题提升30倍，反应问题提升10倍，波动方程提升1800倍，同时兼容一阶优化器。完全替代MLP的显式BWLer在对流、反应和波动问题中接近机器精度（比先前结果高100亿倍），并在Burgers方程和不规则几何Poisson问题中与传统PINNs性能相当。这些发现为结合PINNs的灵活性与经典谱求解器的高精度提供了实用路径。

</details>


### [454] [Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models](https://arxiv.org/abs/2506.23025)
**中文标题：Spectra 1.1：三元语言模型的扩展规律与高效推理**

*Tejas Vaidhya,Ayush Kaushal,Vineet Jain,Francis Couture Harpin,Prashant Shishodia,Majid Behbahani,Yuriy Nevmyvaka,Irina Rish*

主要分类: cs.LG

摘要简述: 本文研究了三元语言模型（TriLMs）的扩展性和高效推理方法，提出了Spectra-1.1模型套件和TriRun推理内核，显著降低了内存需求并加速了推理。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在研究和工业应用中广泛使用，但其推理效率仍是一个重大挑战。现代GPU架构的计算能力持续提升，但内存带宽和容量未能同步增长，导致推理时出现瓶颈。本文旨在通过三元量化模型解决这一问题。

研究方法: 首先分析了TriLMs的扩展性，发现增加训练数据比扩展模型参数更有效。基于此，提出了Spectra-1.1模型套件，训练数据达1.2万亿词元。此外，设计了2位和1.6位权重压缩方案，并开发了TriRun GPU内核，加速推理。

研究结果: Spectra-1.1展示了持续的规模化性能提升，TriRun内核将推理速度提升至浮点基线的5倍。2位和1.6位压缩方案在多种CPU架构上均表现优异。

研究结论: 本文为高效LLMs的构建和部署奠定了基础，Spectra-1.1和TriRun为研究社区提供了宝贵资源。

中文摘要: 大型语言模型（LLMs）在研究和工业应用中日益普及，但其推理效率仍是一个重大挑战。随着现代GPU架构计算能力的持续提升，其内存带宽和容量未能同步增长，导致推理时出现瓶颈。为解决这一问题，我们研究了采用量化感知训练的三元语言模型（TriLMs），显著降低了内存需求。我们首先通过扩展规律分析TriLMs的可扩展性，发现TriLMs从增加训练数据中获益更多，而非扩展模型参数。基于这一观察，我们推出了Spectra-1.1，这是一套基于1.2万亿词元训练的TriLMs开放套件，展示了规模化下的持续性能提升。此外，为提高推理效率，我们提出了新颖的2位和1.6位三元权重压缩方案，在多种CPU架构上实现了加速推理。基于2位压缩，我们还开发了名为TriRun的GPU内核，将端到端模型推理速度提升至浮点基线的5倍。为鼓励进一步探索和开发TriLMs，我们将发布Spectra-1.1套件和TriRun推理内核。总体而言，我们的工作为构建和部署高效LLMs奠定了基础，为研究社区提供了宝贵资源。

</details>


### [455] [Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis](https://arxiv.org/abs/2506.23055)
**中文标题：测量大型语言模型对人类心理概念的内化程度：初步分析**

*Hiro Taiyo Hamada,Ippei Fujisawa,Genji Kawakita,Yuki Yamada*

主要分类: cs.LG

摘要简述: 研究开发了一种定量框架，通过43个标准化心理问卷评估大型语言模型（如GPT-4）对人类心理概念的内化程度，发现GPT-4在分类准确性上显著优于GPT-3.5和BERT，且其语义相似性与人类反应相关性较高。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）能生成类人文本，但其对人类心理概念的内化程度尚不明确。研究旨在量化评估LLMs与人类心理维度的概念对齐情况。

研究方法: 研究使用43个标准化心理问卷，通过成对相似性分析评估语言模型对问卷项目的重构和分类能力，并采用层次聚类比较模型生成的聚类结构与原始分类标签。

研究结果: GPT-4的分类准确性最高（66.2%），显著优于GPT-3.5（55.9%）和BERT（48.1%），且其语义相似性与人类心理问卷反应的皮尔逊相关系数相关。

研究结论: 现代LLMs能以可测量的准确性近似人类心理概念，为开发更具可解释性的人工智能系统提供了新视角。

中文摘要: 大型语言模型（如ChatGPT）在生成类人文本方面表现出色，但这些模型对人类思维和行为塑造概念的内化准确性尚不明确。本研究开发了一种定量框架，利用43个标准化心理问卷（这些问卷在测量不同心理构念方面具有公认的效度）来评估LLMs与人类心理维度的概念对齐情况。我们的方法通过成对相似性分析评估语言模型对问卷项目的重构和分类能力，并使用层次聚类将生成的聚类结构与原始分类标签进行比较。GPT-4模型的分类准确性最高（66.2%），显著优于GPT-3.5（55.9%）和BERT（48.1%），且均超过随机基线性能（31.9%）。我们还发现，GPT-4估计的语义相似性与多个人类心理问卷反应的皮尔逊相关系数相关。该框架为评估人类-LLM概念对齐和识别潜在表征偏差提供了新方法。研究结果表明，现代LLMs能以可测量的准确性近似人类心理构念，为开发更具可解释性的人工智能系统提供了新视角。

</details>


### [456] [Curious Causality-Seeking Agents Learn Meta Causal World](https://arxiv.org/abs/2506.23068)
**中文标题：好奇心驱动的因果探索智能体学习元因果世界**

*Zhiyu Zhao,Haoxuan Li,Haifeng Zhang,Jun Wang,Francesco Faccio,Jürgen Schmidhuber,Mengyue Yang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于元因果图的世界模型，通过好奇心驱动的因果探索智能体，动态捕捉和适应环境中的因果机制变化，并在合成任务和机器人操作任务中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现实环境中，因果机制常因策略或环境状态的微小变化而改变，传统世界模型假设单一不变的因果规则难以适应这种动态性。本文旨在解决这一问题，提出一种能够捕捉和适应因果机制变化的方法。

研究方法: 引入元因果图作为世界模型，统一表示不同潜在世界状态下因果结构的转换规则。通过好奇心驱动的智能体，识别触发子图的元状态，发现因果关系，并迭代优化元因果图。

研究结果: 在合成任务和机器人手臂操作任务中，该方法能够稳健捕捉因果动态变化，并能有效泛化到未见过的情境。

研究结论: 元因果图与好奇心驱动智能体的结合，为动态环境中的因果建模提供了有效解决方案，展示了在复杂任务中的强大适应能力。

中文摘要: 在构建世界模型时，通常假设环境具有单一不变的底层因果规则，例如牛顿定律适用于所有情境。然而，现实中看似漂移的因果机制往往是固定底层机制在狭窄观测窗口下的表现。这导致一个问题：在构建世界模型时，策略或环境状态的细微变化可能改变观测到的因果机制。本文提出将元因果图作为世界模型，这是一种最小化的统一表示，高效编码了因果结构在不同潜在世界状态间的转换规则。单个元因果图由多个因果子图组成，每个子图由潜在状态空间中的元状态触发。基于此表示，我们引入了一种因果探索智能体，其目标为：（1）识别触发每个子图的元状态，（2）通过智能体好奇心驱动的干预策略发现相应的因果关系，（3）通过持续的好奇心驱动探索和智能体经验迭代优化元因果图。在合成任务和具有挑战性的机器人手臂操作任务上的实验表明，我们的方法能够稳健捕捉因果动态变化，并有效泛化到未见过的情境。

</details>


### [457] [Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data](https://arxiv.org/abs/2506.23174)
**中文标题：数据能为自己发声：基于质量指导的无线合成数据利用**

*Chen Gong,Bo Liang,Wei Gao,Chenren Xu*

主要分类: cs.LG

摘要简述: 本文提出SynCheck方案，通过量化合成数据的亲和性与多样性，指导无线传感任务中合成数据的质量优化使用，显著提升任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前无线合成数据的质量不可预测，直接使用可能降低任务性能。研究旨在解决合成数据质量评估与优化问题，确保其有效补充真实数据。

研究方法: 提出亲和性与多样性指标量化合成数据质量，并设计SynCheck方案，在任务模型训练中动态优化合成数据的使用。

研究结果: SynCheck方案在性能上优于忽视质量的合成数据使用方法，即使后者性能下降13.4%，SynCheck仍能提升4.3%。

研究结论: 通过质量导向的合成数据优化使用，SynCheck显著提升无线传感任务性能，解决了当前合成数据质量不可靠的问题。

中文摘要: 生成模型因其能够生成逼真的合成数据以补充真实数据集而受到广泛关注。尽管近期研究表明，将所有合成数据纳入训练集可提升无线传感任务的性能，但合成数据的质量仍不可预测，性能提升也无法保证。为解决这一问题，我们提出了可量化合成数据质量属性（亲和性与多样性）的通用指标。评估发现，当前无线合成数据普遍存在亲和性不足的问题，导致数据标记错误和任务性能下降。我们将质量限制归因于生成模型对未训练条件和领域特定处理的缺乏认知。为缓解这些问题，我们提出了SynCheck，一种质量导向的合成数据利用方案，在任务模型训练中优化合成数据质量。实验表明，SynCheck在性能上始终优于忽视质量的合成数据使用方法，即使后者性能下降13.4%，SynCheck仍能提升4.3%。

</details>


### [458] [FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model](https://arxiv.org/abs/2506.23210)
**中文标题：FedRef：基于参考模型的高效贝叶斯微调方法**

*Taehwan Yoon,Bongjun Choi*

主要分类: cs.LG

摘要简述: 本文提出了一种基于参考模型的联邦学习方法FedRef，用于高效贝叶斯微调，解决了联邦学习中模型性能不足和灾难性遗忘问题，同时降低了计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习虽能保护用户隐私，但模型性能可能无法满足用户多样化需求。现有方法在微调时易出现灾难性遗忘，且计算成本高。本文旨在通过参考模型优化联邦学习，提升模型性能并减少遗忘问题。

研究方法: 提出FedRef方法，基于贝叶斯参数高效迁移学习，引入最优近端项和参考模型，利用历史模型参数避免灾难性遗忘，实现高效微调。

研究结果: FedRef在提升模型性能的同时，显著降低了计算成本，有效解决了灾难性遗忘问题。

研究结论: FedRef通过参考模型和贝叶斯优化，实现了高效、低成本的联邦学习微调，为模型个性化和性能提升提供了新思路。

中文摘要: 联邦学习（FL）用于分布式场景下训练人工智能（AI）模型，同时确保用户隐私。在联邦学习中，服务器通常无法获取用户数据，这种设计在数据隐私方面具有优势。然而，联邦AI模型的性能可能无法完全满足用户期望，且用户需求多样，难以全面满足。这些问题可通过模型优化、微调或个性化来解决。为应对模型优化挑战，我们提出了一种基于参考模型的联邦学习方法，用于最优微调，克服了每轮训练中的灾难性遗忘问题。该方法源自贝叶斯参数高效迁移学习，包含最优近端项，并通过参考模型整合历史模型参数，避免了灾难性遗忘。结果表明，该方法在实现高模型性能的同时，显著降低了计算成本。

</details>


### [459] [Predicting thinking time in Reasoning models](https://arxiv.org/abs/2506.23274)
**中文标题：预测推理模型中的思考时间**

*Hans Peter Lynsgøe Raaschou-jensen,Constanza Fierro,Anders Søgaard*

主要分类: cs.LG

摘要简述: 本文提出并评估了预测推理模型“思考时间”的方法，旨在为用户提供类似“推理进度条”的体验，以减少因时间不可预测性带来的用户挫败感。


<details>
  <summary>详细信息</summary>
研究动机: 随着推理模型在处理复杂任务时生成长链隐藏思维的能力增强，用户对模型“思考时间”的不可预测性感到沮丧。本文旨在解决这一问题，提升用户体验。

研究方法: 本文介绍了在线和离线预测模型“思考时间”的方法，目标是开发一个实用的“推理进度条”。

研究结果: 研究结果表明，提出的方法能够有效预测模型的“思考时间”，为未来用户交互设计和研究提供了方向。

研究结论: 本文提出的方法为解决推理模型时间不可预测性问题提供了实用方案，并指出了未来研究的潜在方向。

中文摘要: 能够生成长链隐藏思维的推理模型已成为处理复杂、推理密集型任务的强大工具。然而，这一范式带来了新的用户体验挑战：用户对模型在返回答案前会花费多少时间进行推理缺乏了解。这种不可预测性可能导致用户挫败感，并且随着大型语言模型能够异步生成越来越长的任务，这一问题可能会加剧。本文提出并评估了在线和离线预测模型“思考时间”的方法，旨在开发一个实用的“推理进度条”。我们还讨论了其对用户交互的影响以及未来的研究方向。

</details>


### [460] [Not All Explanations for Deep Learning Phenomena Are Equally Valuable](https://arxiv.org/abs/2506.23286)
**中文标题：并非所有对深度学习现象的解释都同样有价值**

*Alan Jeffares,Mihaela van der Schaar*

主要分类: cs.LG

摘要简述: 本文认为，深度学习研究中许多对反直觉现象的解释缺乏实际应用价值，建议将其视为验证通用理论的工具，而非孤立问题。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，深度学习研究中对反直觉现象（如双下降、grokking和彩票假设）的解释往往缺乏实际应用证据，且研究效率低下。本文旨在探讨这些现象的研究价值，并提出更高效的研究方向。

研究方法: 通过分析文献中多个典型现象的研究成果，重新审视当前研究规范，并提出未来研究的实用建议。

研究结果: 研究发现，许多现象的解释并未在实际应用中体现价值，但可以作为验证通用深度学习理论的独特场景。

研究结论: 建议将深度学习现象视为验证通用理论的工具，而非孤立问题，以确保研究进展与深度学习领域的实际目标一致。

中文摘要: 近年来，深度学习研究中对反直觉或令人惊讶现象的理解占据了重要部分，例如双下降、grokking和彩票假设等。这些研究通常针对孤立案例提出临时假设来解释现象。本文认为，在许多重要案例中，这些现象在实际应用中缺乏证据支持，且研究效率不高。因此，我们反对将其视为需要专门解释的孤立谜题。然而，深度学习现象仍具有研究价值，可作为验证通用深度学习理论的独特场景。通过分析文献中多个典型现象的研究成果，本文重申了这一观点。我们重新审视了当前研究社区处理这些问题的方式，并为未来研究提出实用建议，以确保深度学习现象的研究与深度学习领域的实际目标保持一致。

</details>


### [461] [VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design](https://arxiv.org/abs/2506.23339)
**中文标题：VALID-Mol：一个用于验证LLM辅助分子设计的系统性框架**

*Malikussaid,Hilal Hudan Nuha*

主要分类: cs.LG

摘要简述: VALID-Mol是一个系统性框架，通过结合化学验证与LLM驱动的分子设计，将有效化学结构的生成率从3%提升至83%，为科学领域提供了一种可推广的方法论。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型（LLMs）在科学发现中展现出潜力，但在需要事实准确性和领域特定约束的领域（如药物分子设计）中，其生成的分子结构常为无效或不切实际。因此，需要一种系统性框架来提升LLM生成分子的有效性和实用性。

研究方法: VALID-Mol结合了方法化的提示工程、自动化化学验证和领域适应的微调LLM，确保生成可合成且具有改进性质的分子。

研究结果: 该框架将有效化学结构的生成率从3%提升至83%，并预测目标亲和力最高可提升17倍，同时保持合成的可操作性。

研究结论: VALID-Mol不仅为分子设计提供了可靠框架，还为其他需要领域特定验证的科学应用提供了可推广的方法论。

中文摘要: 大语言模型（LLMs）在科学发现中展现出巨大潜力，但在需要事实准确性和领域特定约束的领域（如药物分子设计）中，其应用仍具挑战性。LLMs可以提出创造性的分子修饰建议，但常生成化学上无效或不切实际的结构。我们提出了VALID-Mol，一个将化学验证与LLM驱动分子设计结合的系统性框架，将有效化学结构的生成率从3%提升至83%。我们的方法结合了方法化的提示工程、自动化化学验证和领域适应的微调LLM，确保生成可合成且具有改进性质的分子。此外，我们贡献了一种可推广的方法论，适用于其他需要科学约束的LLM应用，并提供了可量化的可靠性改进。计算预测表明，我们的框架可以生成具有高达17倍计算预测目标亲和力提升的候选分子，同时保持合成的可操作性。我们详细分析了提示工程过程、验证架构和微调方法，为其他科学领域提供了可复制的蓝图。

</details>


### [462] [Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment](https://arxiv.org/abs/2506.23358)
**中文标题：联邦时间线合成：一种可扩展且隐私保护的模型训练与部署方法**

*Pawel Renc,Michal K. Grzeszczyk,Linglong Qian,Nassim Oufattole,Jeff Rasley,Arkadiusz Sitek*

主要分类: cs.LG

摘要简述: 本文提出了一种名为联邦时间线合成（FTS）的新框架，用于在分布式时间序列数据（如电子健康记录）上训练生成基础模型。FTS通过将患者历史表示为标记化的患者健康时间线（PHT），实现隐私保护、可扩展性和零样本推理能力。实验表明，基于合成数据训练的模型性能与真实数据相当。


<details>
  <summary>详细信息</summary>
研究动机: 医疗数据通常分散在不同机构中，且涉及隐私问题，难以集中使用。FTS旨在解决这一问题，通过联邦学习框架在保护隐私的同时，实现跨机构的高效模型训练和合成数据生成。

研究方法: FTS将患者历史表示为语言无关的标记化序列（PHT），各机构本地训练自回归变换器模型，仅上传模型权重至中心服务器。服务器利用这些生成器合成大量轨迹数据，并训练全局生成器（GG），支持通过蒙特卡洛模拟进行零样本推理。

研究结果: 在MIMIC-IV数据上的五项临床预测任务中，基于GG生成的合成数据训练的模型表现与真实数据训练的模型相当，验证了FTS的有效性。

研究结论: FTS提供了一种隐私保护、可扩展且适用于多样化医疗任务的解决方案，包括反事实推理、早期预警检测和合成试验设计。

中文摘要: 我们提出了联邦时间线合成（FTS），这是一种用于在分布式时间序列数据（如电子健康记录）上训练生成基础模型的新框架。FTS的核心是将患者历史表示为标记化的患者健康时间线（PHT），这是一种编码时间、分类和连续临床信息的语言无关序列。每个机构在本地PHT上训练自回归变换器，并仅将模型权重传输至中心服务器。服务器利用这些生成器合成大量轨迹数据，并训练全局生成器（GG），从而通过蒙特卡洛模拟未来的PHT实现零样本推理。我们在MIMIC-IV数据上评估了FTS的五项临床预测任务，结果表明，基于GG生成的合成数据训练的模型性能与真实数据训练的模型相当。FTS提供了强大的隐私保障、跨机构的可扩展性，以及对多样化预测和模拟任务（如反事实推理、早期预警检测和合成试验设计）的扩展能力。

</details>


### [463] [BenchMake: Turn any scientific data set into a reproducible benchmark](https://arxiv.org/abs/2506.23419)
**中文标题：BenchMake：将任意科学数据集转化为可复现的基准测试**

*Amanda S Barnard*

主要分类: cs.LG

摘要简述: 本文开发了一种名为BenchMake的工具，可将任何科学数据集转化为可复现的基准测试，通过非负矩阵分解识别边缘案例并优化测试集划分，提升评估的多样性和统计显著性。


<details>
  <summary>详细信息</summary>
研究动机: 计算科学领域缺乏标准化的基准数据集，导致新方法的评估困难。为解决这一问题，作者开发了BenchMake工具，旨在将开放的科学数据集转化为可用的基准测试。

研究方法: BenchMake利用非负矩阵分解技术，确定性地识别并隔离数据集的边缘案例（位于凸包上的数据点），并将匹配的数据实例划分为测试集，以最大化数据分布的多样性和统计显著性。该方法适用于表格、图、图像、信号和文本等多种数据类型。

研究结果: 通过对比十种公开的科学基准数据集，BenchMake的划分方法在多样性和统计显著性上优于传统划分和随机划分。

研究结论: BenchMake为计算科学领域提供了一种高效的工具，能够将任意科学数据集转化为标准化的基准测试，从而促进新方法的评估和比较。

中文摘要: 基准数据集是机器学习开发和应用的基础，确保新方法的鲁棒性、可靠性和竞争力。然而，由于计算科学问题的独特性和领域变化的快速性，基准数据集的相对稀缺使得计算科学家难以评估新创新。本文开发并测试了一种新工具，旨在将越来越多的开放科学数据集转化为可供社区使用的基准测试。BenchMake利用非负矩阵分解技术，确定性地识别并隔离位于凸包（包含所有数据实例的最小凸集）上的挑战性边缘案例，并将匹配的数据实例划分为测试集，以最大化多样性和统计显著性。该方法适用于表格、图、图像、信号和文本等多种数据类型。通过对比十种公开的科学基准数据集，BenchMake的划分方法在多样性和统计显著性上优于传统划分和随机划分。

</details>


### [464] [Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting](https://arxiv.org/abs/2506.23424)
**中文标题：时间序列预测的高效参数测试时适应方法**

*Heitor R. Medeiros,Hossein Sharifi-Noghabi,Gabriel L. Oliveira,Saghar Irandoust*

主要分类: cs.LG

摘要简述: 提出了一种参数高效的时间序列预测测试时适应方法PETSA，通过仅更新输入和输出的小型校准模块，结合低秩适配器和动态门控，显著降低了计算和内存成本，同时保持了预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界的时间序列通常具有非平稳性，导致预训练预测模型性能下降。现有测试时适应方法通常需要更新整个模型，增加了计算和内存开销。

研究方法: 提出PETSA方法，仅更新输入和输出的小型校准模块，采用低秩适配器和动态门控调整表示。引入包含鲁棒项、频域项和结构对齐项的专用损失函数，以在有限适应能力下保持准确性。

研究结果: 在基准数据集上的实验表明，PETSA在减少参数量的同时，实现了与基线相当或更好的性能。

研究结论: PETSA通过参数高效的测试时适应方法，显著提升了时间序列预测模型的适应性，同时降低了计算和内存成本。

中文摘要: 现实世界的时间序列通常表现出非平稳性，这会降低预训练预测模型的性能。测试时适应（TTA）通过在推理过程中调整模型来解决这一问题，但现有方法通常需要更新整个模型，增加了内存和计算成本。我们提出了PETSA，一种参数高效的方法，通过仅更新输入和输出的小型校准模块来适应测试时的预测。PETSA使用低秩适配器和动态门控来调整表示而无需重新训练。为了在有限的适应能力下保持准确性，我们引入了一种专用损失函数，结合了三个部分：（1）鲁棒项，（2）频域项以保持周期性，（3）用于结构对齐的块状结构项。PETSA提高了各种预测主干的适应性，同时需要的参数比基线更少。在基准数据集上的实验结果表明，PETSA在所有时间范围内均实现了竞争性或更好的性能。我们的代码可在以下网址获取：https://github.com/BorealisAI/PETSA

</details>


### [465] [Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification](https://arxiv.org/abs/2506.23462)
**中文标题：能否预测不可预测之事？利用DisasterNet-LLM进行多模态灾害分类**

*Manaswi Kulahara,Gautam Siddharth Kashyap,Nipun Joshi,Arpita Soni*

主要分类: cs.LG

摘要简述: 提出DisasterNet-LLM，一种专为多模态灾害分类设计的大语言模型，通过先进预训练和跨模态注意力机制，显著提升灾害分类准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统灾害管理方法难以整合多模态数据（如图像、天气记录和文本报告），亟需一种能够高效分析多模态数据的模型以提升灾害分类的准确性和时效性。

研究方法: 采用DisasterNet-LLM，结合先进预训练、跨模态注意力机制和自适应变换器，实现对多模态数据的综合分析。

研究结果: 实验结果显示，DisasterNet-LLM在多模态灾害分类任务中表现优异，准确率达89.5%，F1分数为88.0%，AUC为0.92%，BERTScore为0.88%，优于现有先进模型。

研究结论: DisasterNet-LLM通过多模态数据的高效整合和先进模型设计，显著提升了灾害分类的准确性和实用性，为灾害管理提供了有力工具。

中文摘要: 有效的灾害管理需要及时且准确的洞察，然而传统方法难以整合图像、天气记录和文本报告等多模态数据。为此，我们提出了DisasterNet-LLM，一种专为全面灾害分析设计的大语言模型。通过先进的预训练、跨模态注意力机制和自适应变换器，DisasterNet-LLM在灾害分类中表现出色。实验结果表明，其在多模态灾害分类任务中优于现有先进模型，准确率达到89.5%，F1分数为88.0%，AUC为0.92%，BERTScore为0.88%。

</details>


### [466] [Sample Margin-Aware Recalibration of Temperature Scaling](https://arxiv.org/abs/2506.23492)
**中文标题：基于样本间隔感知的温度缩放再校准**

*Haolan Guo,Linwei Tao,Haoyang Luo,Minjing Dong,Chang Xu*

主要分类: cs.LG

摘要简述: 本文提出了一种轻量级、数据高效的后处理校准方法SMART，通过基于logit间隙的精确调整和软分箱目标函数，解决了神经网络过度自信的问题，显著提升了校准性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代神经网络虽然预测准确性高，但普遍存在过度自信的问题，这在安全关键场景中具有潜在风险。现有的后处理校准方法面临全局调整偏差大或高维输入噪声导致的方差高的问题。

研究方法: SMART方法通过利用logit间隙（即前两个logit的差值）作为去噪的标量信号，结合软分箱的期望校准误差（SoftECE）目标函数，实现了对logits的精确调整，同时平衡了模型的偏差和方差。

研究结果: 在多种数据集和架构上的实验表明，SMART在参数更少的情况下，仍能实现最先进的校准性能，优于现有的参数化方法。

研究结论: SMART为神经网络预测中的不确定性量化提供了一种高效、稳健且原理清晰的解决方案，适用于实际部署。

中文摘要: 深度学习的最新进展显著提升了预测准确性，但现代神经网络仍普遍存在系统性过度自信的问题，这在安全关键场景中具有潜在风险。当前的后处理校准方法面临一个根本性困境：全局方法（如温度缩放）对所有样本进行统一调整，尽管计算高效但引入高偏差；而基于完整logit分布的更具表达力的方法则因高维输入噪声和验证数据不足而遭受高方差。为解决这些问题，我们提出了基于样本间隔感知的温度再校准（SMART），这是一种轻量级且数据高效的校准方法，通过基于前两个logit的差值（称为logit间隙）精确调整logits。具体而言，logit间隙作为一种去噪的标量信号，直接关联决策边界的不确定性，提供了避免高维logit空间噪声的稳健指标，同时保持模型预测的不变性。此外，SMART采用了一种新颖的软分箱期望校准误差（SoftECE）目标函数，通过自适应分箱平衡模型的偏差和方差，即使在极有限的校准数据下也能实现稳定的参数更新。在多种数据集和架构上的广泛评估表明，SMART在参数显著少于现有参数化方法的情况下，仍能实现最先进的校准性能，为神经网络预测中的不确定性量化提供了一种原理清晰、稳健且高效的解决方案。源代码见：https://anonymous.4open.science/r/SMART-8B11。

</details>


### [467] [FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization](https://arxiv.org/abs/2506.23516)
**中文标题：FedWSQ：基于权重标准化和分布感知非均匀量化的高效联邦学习**

*Seung-Wook Kim,Seongyeol Kim,Jiah Kim,Seowon Ji,Se-Ho Lee*

主要分类: cs.LG

摘要简述: FedWSQ是一种高效联邦学习框架，结合权重标准化和分布感知非均匀量化，显著提升模型性能并减少通信开销。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习面临数据异构性和通信限制等挑战，导致性能下降。FedWSQ旨在通过权重标准化和量化技术解决这些问题。

研究方法: FedWSQ采用权重标准化（WS）过滤本地更新中的偏差成分，并提出分布感知非均匀量化（DANUQ）以减少量化误差。

研究结果: 实验表明，FedWSQ在极端数据异构和超低比特通信场景下优于现有联邦学习方法。

研究结论: FedWSQ通过结合WS和DANUQ，有效提升了联邦学习的鲁棒性和通信效率。

中文摘要: 联邦学习（FL）常因数据异构性和通信限制等关键挑战导致性能下降。为解决这些问题，我们提出了一种名为FedWSQ的新型FL框架，该框架结合了权重标准化（WS）和提出的分布感知非均匀量化（DANUQ）。WS通过过滤训练过程中本地更新中的偏差成分，增强了FL性能，从而提高了模型对数据异构性和不稳定客户端参与的鲁棒性。此外，DANUQ通过利用本地模型更新的统计特性，最小化了量化误差。因此，FedWSQ在显著减少通信开销的同时，保持了卓越的模型精度。在FL基准数据集上的大量实验表明，FedWSQ在各种具有挑战性的FL设置（包括极端数据异构和超低比特通信场景）中始终优于现有FL方法。

</details>


### [468] [Transition Matching: Scalable and Flexible Generative Modeling](https://arxiv.org/abs/2506.23589)
**中文标题：转移匹配：可扩展且灵活的生成建模**

*Neta Shaul,Uriel Singer,Itai Gat,Yaron Lipman*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“转移匹配”（TM）的新型生成模型范式，统一并改进了扩散/流模型和连续自回归生成方法。通过分解复杂任务为简单马尔可夫转移，TM提供了灵活的设计空间，并在图像质量和文本一致性上达到最优水平。


<details>
  <summary>详细信息</summary>
研究动机: 当前扩散和流匹配模型的设计空间已较为成熟，改进空间有限；而连续自回归模型在统一文本和媒体生成方面展现出潜力。本文旨在提出一种新范式，结合两者的优势并推动生成模型的进一步发展。

研究方法: TM将复杂生成任务分解为简单的马尔可夫转移，支持非确定性概率转移核和任意非连续监督过程。提出了三种TM变体：DTM（推广流匹配到离散时间）、ARTM（部分因果模型）和FHTM（完全因果模型），分别在不同任务中表现优异。

研究结果: 实验表明，DTM在图像质量和文本一致性上达到最优水平，并提高了采样效率；FHTM首次在连续域文本到图像任务中匹配或超越基于流的方法性能。

研究结论: TM为生成模型提供了灵活且可扩展的新范式，统一了扩散/流模型与连续自回归方法，并在多个任务中表现出色。

中文摘要: 扩散和流匹配模型显著推动了媒体生成，但其设计空间已较为成熟，限制了进一步改进。同时，自回归（AR）模型，尤其是生成连续标记的模型，成为统一文本和媒体生成的有前景方向。本文提出“转移匹配”（TM），一种离散时间、连续状态的新型生成范式，统一并改进了扩散/流模型与连续AR生成。TM将复杂生成任务分解为简单马尔可夫转移，支持非确定性概率转移核和任意非连续监督过程，从而开辟了新的灵活设计途径。我们通过三种TM变体探索这些选择：（i）差分转移匹配（DTM），将流匹配推广到离散时间，直接学习转移概率，实现最优图像质量和文本一致性，并提高采样效率；（ii）自回归转移匹配（ARTM）和（iii）全历史转移匹配（FHTM）分别为部分和完全因果模型，推广了连续AR方法。它们在连续因果AR生成质量上与非因果方法相当，并可能实现与现有AR文本生成技术的无缝集成。值得注意的是，FHTM是首个在连续域文本到图像任务中匹配或超越基于流方法的完全因果模型。我们通过严格的大规模比较验证了这些贡献，保持固定架构、训练数据和超参数。

</details>


### [469] [When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series](https://arxiv.org/abs/2506.23596)
**中文标题：何时会失败？：利用异常提示预测时间序列中的未来异常**

*Min-Yeong Park,Won-Jeong Lee,Seong Tae Kim,Gyeong-Moon Park*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Anomaly to Prompt（A2P）的新框架，用于预测时间序列中的未来异常点。通过结合异常感知预测（AAF）和合成异常提示（SAP），A2P能够学习异常关系并模拟多样化的异常模式，从而在多个真实数据集上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 预测未来异常事件在现实场景中具有重要意义，但现有方法仅关注即时异常或无法精确预测未来异常点。本文旨在填补这一空白，提出一种能够预测未来异常时间点的解决方案。

研究方法: A2P框架由两部分组成：1）异常感知预测（AAF），通过学习异常关系来预测未来异常点；2）合成异常提示（SAP），通过可学习的异常提示池（APP）模拟多样化异常模式，增强异常检测的鲁棒性。

研究结果: 在多个真实数据集上的实验表明，A2P在预测未来异常方面优于现有方法，展示了其在实际应用中的优越性。

研究结论: A2P通过结合异常感知预测和合成异常提示，成功解决了未来异常预测问题，为时间序列分析提供了新的解决方案。

中文摘要: 近年来，预测未来异常事件已成为解决现实需求的重要场景。然而，预测未来异常发生时间点（即异常预测，AP）的解决方案仍未被充分探索。现有处理时间序列数据的方法在AP任务上表现不佳，仅关注即时异常或无法提供对未来异常的精确预测。为解决AP任务，我们提出了一种名为Anomaly to Prompt（A2P）的新框架，包含异常感知预测（AAF）和合成异常提示（SAP）。为使预测模型能够预测异常时间点，我们采用学习异常关系的策略。为鲁棒检测异常，提出的SAP引入了一种可学习的异常提示池（APP），通过信号自适应提示模拟多样化异常模式。在多个真实数据集上的综合实验表明，A2P优于现有方法，展示了其预测未来异常的能力。我们的实现代码可在https://github.com/KU-VGI/AP获取。

</details>


### [470] [A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data](https://arxiv.org/abs/2506.23629)
**中文标题：基于卷积神经网络的非线性低秩表示模型用于水质数据填补**

*Xin Liao,Bing Yang,Cai Yu*

主要分类: cs.LG

摘要简述: 本文提出了一种结合卷积神经网络（CNN）的非线性低秩表示模型（NLR），用于填补水质数据中的缺失值。该模型通过CNN融合时间特征并提取非线性交互和局部模式，显著提升了填补精度，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 水质数据的完整性对环境监测和生态保护至关重要，但由于传感器故障和通信延迟等问题，数据常出现高维稀疏性。传统填补方法难以捕捉数据的潜在动态和深层特征，填补效果不佳。

研究方法: 提出了一种非线性低秩表示模型（NLR），结合CNN实现：1）融合时间特征以建模时间依赖性；2）提取非线性交互和局部模式以挖掘高阶关系特征。

研究结果: 在三个真实水质数据集上的实验表明，该模型在估计精度上显著优于现有最先进的数据填补模型。

研究结论: 该模型为复杂动态环境中的水质监测数据处理提供了有效方法，填补精度显著提升。

中文摘要: 水质数据（WQD）的完整性对科学决策和生态保护至关重要。然而，由于传感器故障和通信延迟等问题，水质监测系统常面临大量数据缺失，导致数据呈现高维稀疏性（HDS）。传统填补方法难以刻画潜在动态和深层特征，填补效果不佳。为解决上述问题，本文提出了一种结合卷积神经网络（CNN）的非线性低秩表示模型（NLR），用于填补缺失WQD。该模型利用CNN实现两点：a）融合时间特征以建模时间依赖性；b）提取非线性交互和局部模式以挖掘高阶关系特征，实现多维信息的深度融合。在三个真实水质数据集上的实验表明，该模型在估计精度上显著优于现有最先进的数据填补模型，为复杂动态环境中的水质监测数据处理提供了有效方法。

</details>


### [471] [Learning Modular Exponentiation with Transformers](https://arxiv.org/abs/2506.23679)
**中文标题：使用Transformer学习模幂运算**

*David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg*

主要分类: cs.LG

摘要简述: 本文通过训练一个4层编码器-解码器Transformer模型，研究了模幂运算在模型中的学习机制，发现模型通过专门的电路学习算术结构，并展示了突发的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 模幂运算在数论和密码学中至关重要，但从机制可解释性的角度研究较少。本文旨在探索Transformer模型如何学习模幂运算，并揭示其内部数值推理的机制。

研究方法: 训练了一个4层编码器-解码器Transformer模型，采用策略性采样、基于PCA的嵌入分析和激活修补技术，研究模型如何编码数论特性。

研究结果: 研究发现，通过倒数操作数训练可以显著提升性能，并在相关模数上表现出突发的泛化能力。此外，最后一层仅由注意力头组成的子图足以完成常规幂运算任务。

研究结论: Transformer模型通过专门的算术电路学习模幂运算，为开发更可解释和高效的神经网络方法提供了基础。

中文摘要: 模幂运算在数论和密码学中至关重要，但从机制可解释性的角度研究较少。我们训练了一个4层编码器-解码器Transformer模型来执行这一运算，并研究了训练过程中数值推理的涌现。通过策略性采样、基于PCA的嵌入分析和激活修补技术，我们探讨了模型如何编码数论特性。研究发现，倒数操作数训练能显著提升性能，并在相关模数上表现出突发的泛化能力。这些同步的精度提升反映了类似“顿悟”的动态过程，表明模型内化了共享的算术结构。我们还发现，最后一层仅由注意力头组成的子图足以完成常规幂运算任务。这些结果表明，Transformer模型通过专门的算术电路学习模运算，为开发更可解释和高效的神经网络方法提供了基础。

</details>


### [472] [DABstep: Data Agent Benchmark for Multi-step Reasoning](https://arxiv.org/abs/2506.23719)
**中文标题：DABstep：多步推理的数据代理基准测试**

*Alex Egg,Martin Iglesias Goyanes,Friso Kingma,Andreu Mora,Leandro von Werra,Thomas Wolf*

主要分类: cs.LG

摘要简述: DABstep是一个用于评估AI代理在多步数据分析任务中表现的新基准测试，包含450多个现实世界挑战，测试模型的数据处理和上下文推理能力。最佳代理在最难任务中仅达到14.55%准确率。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI代理在多步数据分析任务中的表现缺乏标准化评估工具，DABstep旨在填补这一空白，提供基于真实金融分析任务的基准测试。

研究方法: DABstep从金融分析平台提取450多个任务，要求模型结合代码数据处理和上下文推理，采用多步问题解决方式，并通过自动检查答案格式进行客观评分。

研究结果: 评估显示，领先的LLM代理表现不佳，最佳代理在最难任务中准确率仅为14.55%，揭示了现有技术的局限性。

研究结论: DABstep为自主数据分析研究提供了标准化工具，公开排行榜和工具包将加速相关领域发展。

中文摘要: 我们介绍了DABstep，一个用于评估AI代理在现实多步数据分析任务中的新基准测试。DABstep包含450多个来自金融分析平台的真实挑战，要求模型结合代码数据处理和异构文档的上下文推理。每个任务需要迭代的多步问题解决方法，测试数据操作、多源交叉引用和精确结果报告的能力。基准测试提供事实型答案格式，并通过自动正确性检查实现大规模客观评分。我们评估了领先的基于LLM的代理，发现显著的性能差距：即使最佳代理在最难任务中也仅达到14.55%的准确率。我们详细介绍了基准测试的设计、数据集组成、任务制定、评估协议，报告了基线结果并分析了失败模式。DABstep发布了公开排行榜和工具包，以加速自主数据分析的研究。

</details>


### [473] [System-Embedded Diffusion Bridge Models](https://arxiv.org/abs/2506.23726)
**中文标题：系统嵌入式扩散桥模型**

*Bartlomiej Sobieski,Matthew Tivnan,Yuang Wang,Siyeop Yoon,Pengfei Jin,Dufan Wu,Quanzheng Li,Przemyslaw Biecek*

主要分类: cs.LG

摘要简述: 本文提出了一种新的监督桥接方法——系统嵌入式扩散桥模型（SDBs），通过将已知线性测量系统嵌入到矩阵值SDE的系数中，显著提升了线性逆问题的解决效果，并展示了在系统误配情况下的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 逆问题（从不完整或噪声测量中恢复信号）在科学与工程中至关重要。现有的基于分数的生成模型（SGMs）分为无监督方法和监督桥接方法，前者通常需要已知测量模型，而后者则忽略了这一结构信息。本文旨在通过嵌入已知系统信息，改进监督桥接方法的性能。

研究方法: 提出系统嵌入式扩散桥模型（SDBs），将已知的线性测量系统显式嵌入到矩阵值随机微分方程（SDE）的系数中，从而在监督桥接方法中充分利用结构信息。

研究结果: SDBs在多种线性逆问题中表现一致优于现有方法，并在训练与部署系统误配时展现出鲁棒性，为实际应用提供了有前景的解决方案。

研究结论: SDBs通过嵌入系统信息显著提升了监督桥接方法的性能，为逆问题的解决提供了更高效和鲁棒的工具。

中文摘要: 解决逆问题——从不完整或噪声测量中恢复信号——是科学与工程中的基础任务。基于分数的生成模型（SGMs）最近成为这一任务的有力框架。现有方法分为两类：无监督方法通过调整预训练生成模型适应逆问题，监督桥接方法则基于成对干净与噪声数据训练随机过程。前者通常假设已知测量模型，后者则忽略了这一结构信息。我们提出系统嵌入式扩散桥模型（SDBs），这是一种新的监督桥接方法，将已知线性测量系统显式嵌入到矩阵值SDE的系数中。这种原理性集成在多种线性逆问题中带来一致改进，并在训练与部署系统误配时表现出鲁棒性，为实际应用提供了有前景的解决方案。

</details>


### [474] [Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling](https://arxiv.org/abs/2506.23782)
**中文标题：基于小波感知温度缩放的图神经网络校准**

*Xiaoyang Li,Linwei Tao,Haohui Lu,Minjing Dong,Junbin Gao,Chang Xu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为WATS的后处理校准框架，通过基于可调热核图小波特征为节点分配特定温度，显著提升了图神经网络（GNNs）的置信度校准效果。


<details>
  <summary>详细信息</summary>
研究动机: 图神经网络（GNNs）在关系数据上表现出强大的预测性能，但其置信度估计与实际预测准确性不一致，限制了其在安全关键场景中的应用。现有方法依赖粗粒度的一跳统计或潜在节点嵌入，忽略了图拓扑的细粒度结构异质性。

研究方法: 提出Wavelet-Aware Temperature Scaling（WATS），一种后处理校准框架，利用可调热核图小波特征为节点分配特定温度，无需重新训练模型或访问邻域预测。

研究结果: 在七个基准数据集和两种GNN架构上的实验表明，WATS在预期校准误差（ECE）上优于所有基线方法，最高提升42.3%，校准方差平均降低17.24%，且计算效率高。

研究结论: WATS通过利用图小波的拓扑敏感性，显著提升了GNNs的置信度校准效果，适用于不同规模和密度的图数据。

中文摘要: 图神经网络（GNNs）在关系数据上表现出强大的预测性能，但其置信度估计与实际预测准确性不一致，限制了其在安全关键场景中的应用。现有的图感知校准方法主要依赖粗粒度的一跳统计（如邻域预测置信度）或潜在节点嵌入，忽略了图拓扑的细粒度结构异质性。本文提出Wavelet-Aware Temperature Scaling（WATS），一种后处理校准框架，通过基于可调热核图小波特征为节点分配特定温度，优化置信度估计，且无需重新训练模型或访问邻域预测。在七个基准数据集和两种GNN架构上的广泛实验表明，WATS在所有对比方法中实现了最低的预期校准误差（ECE），比经典和图特定基线方法最高提升42.3%，校准方差平均降低17.24%。此外，WATS计算效率高，适用于不同规模和密度的图数据。代码将在发表后公开。

</details>


### [475] [Riemannian-Geometric Fingerprints of Generative Models](https://arxiv.org/abs/2506.22802)
**中文标题：生成模型的黎曼几何指纹**

*Hae Jin Song,Laurent Itti*

主要分类: cs.LG

摘要简述: 本文提出了一种基于黎曼几何的生成模型指纹定义，通过几何方法解决了模型认证和数据来源验证的问题，显著提升了模型区分能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成模型的广泛应用，模型认证和数据来源验证的需求日益增长，但目前缺乏一个系统性框架来定义和分析生成模型的指纹。本文旨在填补这一空白，通过几何方法提供一种新的解决方案。

研究方法: 本文采用黎曼几何方法，提出了一种新的生成模型指纹定义，通过学习数据驱动的黎曼度量，用测地距离和基于kNN的黎曼质心替代欧几里得距离和最近邻搜索，并开发了一种基于梯度的算法来实际计算指纹。

研究结果: 实验结果表明，该方法在区分多种生成模型（涵盖4个数据集、2种分辨率、27种模型架构和2种模态）方面表现优异，显著提升了模型归属任务的性能，并展现出对未见数据集、模型类型和模态的泛化能力。

研究结论: 本文提出的黎曼几何指纹定义不仅为生成模型认证提供了理论框架，还在实践中表现出高效性和泛化性，为未来研究奠定了基础。

中文摘要: 近年来，生成模型（GMs）的突破性进展和快速应用引发了对模型归属及其指纹问题的关注。例如，服务提供商需要可靠的方法来认证其模型以保护知识产权，而用户和执法机构则希望验证生成内容的来源以确保责任和信任。此外，随着更多模型生成的数据被反馈到常用于训练的数据源（如YouTube），模型崩溃的威胁日益加剧，亟需区分合成数据与人类数据。然而，目前对生成模型指纹的理解仍存在空白，我们认为这是由于缺乏一个能够系统性定义、表示和分析指纹的框架。为填补这一空白，我们采用几何方法，利用黎曼几何提出了一种新的生成模型伪影和指纹定义，从而可以利用微分几何的丰富理论。我们的新定义将先前工作（Song et al., 2024）推广到非欧几里得流形，通过学习数据驱动的黎曼度量，并用测地距离和基于kNN的黎曼质心替代欧几里得距离和最近邻搜索。我们将理论应用于一种新的基于梯度的算法，以实际计算指纹。结果表明，该方法在区分多种生成模型（涵盖4个数据集、2种分辨率、27种模型架构和2种模态）方面更为有效。使用我们提出的定义显著提升了模型归属任务的性能，并展现出对未见数据集、模型类型和模态的泛化能力，表明其实际应用价值。

</details>


### [476] [Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic](https://arxiv.org/abs/2506.23875)
**中文标题：有序思维链：为算术任务发现学习友好的顺序**

*Yuta Sato,Kazuhiko Kawamoto,Hiroshi Kera*

主要分类: cs.LG

摘要简述: 本文提出了一种新方法，通过重新排列解码器输入标记的顺序，为Transformer模型在算术任务中找到学习友好的思维链顺序。实验证明该方法能从数十亿候选顺序中识别出最优顺序，并在乘法任务中重现了先前研究中报告的反向数字顺序。


<details>
  <summary>详细信息</summary>
研究动机: 思维链的顺序对Transformer模型的推理难度有重要影响。本文旨在解决如何为算术任务找到学习友好的思维链顺序，以提高模型的学习效率。

研究方法: 研究提出了一种两阶段的分层方法：首先训练Transformer模型处理不同顺序的目标序列，然后通过早期损失下降速度识别良性顺序。针对搜索空间随序列长度阶乘增长的问题，设计了块间和块内重排序策略。

研究结果: 在四个对顺序敏感的算术任务中，该方法成功从数十亿候选顺序中识别出学习友好顺序，并在乘法任务中重现了反向数字顺序。

研究结论: 本文提出的方法能够有效识别学习友好的思维链顺序，显著提升Transformer模型在算术任务中的学习效率。

中文摘要: 思维链是Transformer模型中进行逐步推理的基础。除了中间步骤的作用外，这些步骤的顺序对推理难度有重要影响。本研究解决了一个新任务：重新排列解码器输入标记的顺序，为Transformer模型在算术任务中找到学习友好的序列。提出的流程首先训练Transformer模型处理按不同顺序排列的目标序列，然后通过早期损失下降速度识别良性顺序。由于搜索空间随序列长度阶乘增长，我们提出了一种两阶段的分层方法，用于块间和块内重排序。在四个对顺序敏感的算术任务上的实验表明，我们的方法能够从数十亿候选顺序中识别出学习友好顺序。值得注意的是，在乘法任务中，该方法重现了先前研究中报告的反向数字顺序。

</details>


### [477] [Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System](https://arxiv.org/abs/2506.23923)
**中文标题：基于强化学习的双入口树脂灌注系统同步流动控制**

*Miguel Camacho-Sánchez,Fernando García-Torres,Jesper John Lisegaard,Rocío del Amor,Sankhya Mohanty,Valery Naranjo*

主要分类: cs.LG

摘要简述: 本文提出了一种基于强化学习（RL）的策略，用于同步双入口树脂灌注系统中的树脂流动前沿，以优化复合材料制造中的流动控制和产品质量。


<details>
  <summary>详细信息</summary>
研究动机: 树脂灌注（RI）和树脂传递模塑（RTM）是制造高性能纤维增强聚合物复合材料的关键工艺，尤其是在大型应用（如风力涡轮机叶片）中。控制树脂流动动态对于确保纤维增强材料的均匀浸渍至关重要，以避免残留孔隙和干斑，从而影响最终组件的结构完整性。

研究方法: 本文采用近端策略优化（PPO）的强化学习方法，通过过程模拟建立策略，以同步双入口树脂灌注系统中的树脂流动前沿。该方法解决了在部分可观测环境中管理流体动力学的挑战。

研究结果: 结果表明，强化学习方法能够有效实现精确的流动收敛，展示了其在改善复合材料制造过程控制和产品质量方面的潜力。

研究结论: 本文提出的强化学习策略为树脂灌注系统中的流动控制提供了一种有效的解决方案，有望在复合材料制造中提升工艺效率和产品性能。

中文摘要: 树脂灌注（RI）和树脂传递模塑（RTM）是制造高性能纤维增强聚合物复合材料的关键工艺，尤其是在大型应用（如风力涡轮机叶片）中。控制树脂流动动态对于确保纤维增强材料的均匀浸渍至关重要，以避免残留孔隙和干斑，从而影响最终组件的结构完整性。本文提出了一种基于强化学习（RL）的策略，通过过程模拟建立，用于同步涉及两个树脂入口和一个出口的灌注场景中的不同树脂流动前沿。采用近端策略优化（PPO），我们的方法解决了在部分可观测环境中管理流体动力学的挑战。结果表明，强化学习方法能够有效实现精确的流动收敛，展示了其在改善复合材料制造过程控制和产品质量方面的潜力。

</details>


### [478] [ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation](https://arxiv.org/abs/2506.23041)
**中文标题：ReMem：基于互信息感知的预训练视觉Transformer微调以实现高效知识蒸馏**

*Chengyu Dong,Huan Gui,Noveen Sachdeva,Long Jin,Ke Yin,Jingbo Shang,Lichan Hong,Ed H. Chi,Zhe Zhao*

主要分类: cs.LG

摘要简述: 本文提出ReMem方法，通过互信息感知的优化和MLP块重加权策略，提升预训练视觉Transformer（ViT）在知识蒸馏中的效果，尤其适用于小规模或高度不平衡的下游数据集。


<details>
  <summary>详细信息</summary>
研究动机: 当从大规模预训练的强模型进行知识蒸馏时，知识转移效果显著下降。本文旨在解决这一问题，特别是针对预训练的视觉Transformer（ViT），探索如何通过微调提升其知识转移效果。

研究方法: 提出互信息感知的优化方法，并在微调过程中应用。针对小规模或高度不平衡数据集，提出一种简单有效的启发式方法，即对MLP块进行重加权，因为观察到顶部MLP块是互信息损失的主要原因。

研究结果: 该方法使小型学生模型能够从最强的预训练模型中受益，显著提升了知识蒸馏的效果。

研究结论: ReMem方法通过互信息感知优化和MLP块重加权，有效提升了预训练ViT在知识蒸馏中的表现，尤其适用于资源有限或数据不平衡的场景。

中文摘要: 从预训练的视觉表示模型中进行知识蒸馏是提升小型任务特定生产模型的有效方法。然而，当从大规模预训练的强模型进行蒸馏时，知识转移效果显著下降。本文针对预训练的视觉Transformer（ViT），探索了如何通过微调提升其知识转移效果。受互信息与蒸馏效果之间关系的启发，我们提出在微调过程中采用互信息感知的优化方法。对于小规模或高度不平衡的下游数据集，我们引入了一种简单而有效的启发式方法，即对MLP块进行重加权。这一方法的灵感来源于我们观察到顶部MLP块是互信息损失的主要原因。我们的方法使小型学生模型能够从最强的预训练模型中受益。

</details>


### [479] [ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.23960)
**中文标题：ADReFT：基于强化学习微调的自适应决策修复方法用于安全自动驾驶**

*Mingfei Cheng,Xiaofei Xie,Renzhi Wang,Yuan Zhou,Ming Hu*

主要分类: cs.LG

摘要简述: ADReFT是一种通过强化学习微调的自适应决策修复方法，旨在提升自动驾驶系统的运行时安全性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 当前自动驾驶系统（ADS）的在线修复方法缺乏通用性和适应性，且过于保守，导致修复效果不佳。ADReFT旨在通过离线学习和强化学习改进修复能力。

研究方法: ADReFT采用基于Transformer的模型，包含状态监控器和决策适配器两个联合头，通过监督学习预训练和强化学习微调，生成自适应修复动作。

研究结果: 评估结果表明，ADReFT在修复性能上表现更优，能够更精确地生成修复决策。

研究结论: ADReFT通过结合监督学习和强化学习，显著提升了自动驾驶系统的安全性和适应性。

中文摘要: 自动驾驶系统（ADS）由于设计和性能的固有局限性，仍面临安全关键风险。在线修复在缓解这些局限性、确保ADS运行时安全性和可靠性方面起着关键作用。现有的在线修复解决方案通过基于预定义规范（如基于规则的约束或训练数据集）将不可接受的轨迹转换为可接受的轨迹来强制ADS合规。然而，这些方法通常缺乏通用性和适应性，且往往过于保守，导致修复效果不佳，不仅未能充分缓解安全风险，还降低了整体驾驶体验。为解决这一问题，我们提出了自适应决策修复（ADReFT），这是一种新颖且有效的修复方法，通过从失败测试中离线学习识别安全关键状态，并生成适当的缓解动作以提升ADS安全性。具体而言，ADReFT采用基于Transformer的模型，包含状态监控器和决策适配器两个联合头，旨在捕捉复杂的驾驶环境交互以评估状态安全严重性并生成自适应修复动作。由于缺乏状态安全识别的基准，我们首先通过监督学习对ADReFT进行预训练，使用粗粒度标注（即将违规前的状态标记为正样本，其他为负样本）。这为ADReFT奠定了缓解安全关键违规的基础能力，尽管可能导致较为保守的缓解策略。因此，我们随后通过强化学习对ADReFT进行微调，以提升其初始能力并生成更精确且上下文适当的修复决策。评估结果表明，ADReFT实现了更好的修复性能。

</details>


### [480] [Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings](https://arxiv.org/abs/2506.23145)
**中文标题：Forget-MI：医疗场景中多模态信息的机器遗忘方法**

*Shahad Hardan,Darya Taratynova,Abdelmajid Essofi,Karthik Nandakumar,Mohammad Yaqub*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Forget-MI的新型机器遗忘方法，专门用于医疗多模态数据，通过损失函数和扰动技术实现数据遗忘，同时保持模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 在医疗领域，AI模型依赖敏感的患者数据，隐私保护至关重要。现有方法难以从多模态架构中彻底移除患者数据，因此需要一种有效的机器遗忘技术。

研究方法: Forget-MI通过建立损失函数和扰动技术，遗忘请求删除的单模态和联合数据表示，同时保留剩余数据知识，并保持与原模型相当的性能。

研究结果: Forget-MI在遗忘数据集上的性能显著优于现有方法，MIA降低0.202，AUC和F1分数分别降低0.221和0.305，同时在测试集上性能与重新训练的模型相当。

研究结论: Forget-MI是一种有效的多模态医疗数据遗忘方法，既能保护隐私，又能维持模型性能，优于现有技术。

中文摘要: AI中的隐私保护至关重要，尤其是在依赖敏感患者数据的医疗领域。在机器遗忘这一新兴领域中，现有方法难以从训练好的多模态架构中移除患者数据。我们提出Forget-MI，一种针对多模态医疗数据的新型机器遗忘方法，通过建立损失函数和扰动技术实现。该方法能够遗忘请求删除的单模态和联合数据表示，同时保留剩余数据知识，并保持与原模型相当的性能。我们通过遗忘数据集性能、测试数据集性能以及成员推理攻击（MIA）评估结果。MIA用于衡量攻击者区分遗忘数据集与训练数据集的能力。我们的模型在降低MIA和遗忘数据集性能的同时，在测试集上保持了与重新训练模型相当的性能。具体而言，我们的方法将MIA降低0.202，遗忘数据集的AUC和F1分数分别降低0.221和0.305。此外，测试集性能与重新训练模型相当，同时实现了遗忘功能。代码发布于https://github.com/BioMedIA-MBZUAI/Forget-MI.git。

</details>


### [481] [Bridging Theory and Practice in Link Representation with Graph Neural Networks](https://arxiv.org/abs/2506.24018)
**中文标题：图神经网络在链接表示中理论与实践的桥梁**

*Veronica Lachi,Francesco Ferrini,Antonio Longa,Bruno Lepri,Andrea Passerini,Manfred Jaeger*

主要分类: cs.LG

摘要简述: 本文首次全面研究了图神经网络（GNN）在链接表示中的表达能力，提出了一个统一框架$k_\phi$-$k_\rho$-$m$，用于比较现有方法的表达能力，并通过合成评估协议验证了表达能力在实际中的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管图神经网络（GNN）广泛用于链接预测等任务，但其理论表达能力的研究主要集中在图级别表示上。本文旨在填补这一空白，首次全面研究GNN在链接表示中的表达能力。

研究方法: 本文提出了一个统一框架$k_\phi$-$k_\rho$-$m$，用于比较现有消息传递链接模型的表达能力。此外，还设计了一个合成评估协议，专门用于评估链接级别的表达能力。

研究结果: 研究发现，表达能力强的模型在标准基准测试中可能表现不佳，但在对称性较高的场景中显著优于简单模型，强调了根据数据集选择模型的重要性。

研究结论: 本文为链接表示的理论和实践提供了重要工具，强调了表达能力在实际应用中的关键作用，并提出了未来架构分析的理论基础。

中文摘要: 图神经网络（GNN）被广泛用于计算节点对的表示，以支持链接预测等下游任务。然而，关于其表达能力的理论研究几乎完全集中在图级别表示上。本文首次将焦点转向链接，全面研究了GNN在链接表示中的表达能力。我们引入了一个统一框架$k_\phi$-$k_\rho$-$m$，该框架涵盖了现有的消息传递链接模型，并支持形式化的表达能力比较。通过这一框架，我们推导出当前最先进方法的层次结构，并为未来架构的分析提供了理论工具。为了补充分析，我们提出了一个合成评估协议，包含首个专门用于评估链接级别表达能力的基准测试。最后，我们探讨了表达能力在实际中的重要性。通过量化链接区分难度的图对称性指标，我们发现表达能力强的模型在标准基准测试中可能表现不佳，但在对称性增加时显著优于简单模型，这凸显了根据数据集选择模型的必要性。

</details>


### [482] [maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics](https://arxiv.org/abs/2506.23147)
**中文标题：maneuverRecognition——车辆远程信息处理领域时间序列分类的Python包**

*Jonathan Schuster,Fabian Transchel*

主要分类: cs.LG

摘要简述: maneuverRecognition是一个Python包，用于车辆远程信息处理领域的时间序列分类，旨在通过预处理、建模和评估功能快速识别驾驶行为，提升道路安全并支持环保驾驶。


<details>
  <summary>详细信息</summary>
研究动机: 车辆远程信息处理领域需要自动识别驾驶行为以评估驾驶习惯，从而提升保险个性化、道路安全、减少事故及燃料消耗。现有研究缺乏实用的Python工具包，maneuverRecognition填补了这一空白。

研究方法: 开发了一个Python包，提供数据预处理、建模和评估功能，并包含一个可修改的基于LSTM的网络结构。通过智能手机传感器记录的三人真实驾驶数据验证了其实现。

研究结果: 该包成功实现了驾驶行为的分类功能，并通过实际数据验证了其有效性。

研究结论: maneuverRecognition为车辆远程信息处理领域的时间序列分类提供了实用工具，支持快速数据转换和模型构建，具有广泛的应用潜力。

中文摘要: 在车辆远程信息处理领域，驾驶行为的自动识别用于分类和评估驾驶习惯。这不仅有助于提升保险政策的个性化，还能提高道路安全性、减少事故及相关成本，同时降低燃料消耗并支持环保驾驶。技术上，驾驶行为识别需要持续应用时间序列分类，这对传感器数据的传输、预处理和存储、预测模型的训练以及预测本身提出了特殊挑战。尽管在数据收集或构建预测模型方面已有大量研究，但仍缺乏实用的Python工具包和功能，以快速将数据转换为所需结构并构建和评估此类模型。为此，开发了maneuverRecognition包，提供预处理、建模和评估所需的功能，并包含一个可修改的基于LSTM的网络结构。通过智能手机传感器记录的三人真实驾驶数据展示了该包的实现。

</details>


### [483] [Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels](https://arxiv.org/abs/2506.23221)
**中文标题：基于通用再生核的单图像修复与超分辨率及同时不确定性保证**

*Bálint Horváth,Balázs Csanád Csáji*

主要分类: cs.LG

摘要简述: 本文提出了一种基于统计学习的图像修复和超分辨率方法，通过通用再生核同时提供像素估计和不确定性量化。


<details>
  <summary>详细信息</summary>
研究动机: 图像修复和超分辨率问题中，准确估计缺失像素并量化不确定性是关键。本文旨在通过再生核希尔伯特空间（RKHS）框架，提出一种同时提供估计值和置信区间的方法。

研究方法: 提出了一种称为同时保证核插值（SGKI）的方法，基于RKHS框架，特别关注信号处理中的带限函数（Paley-Wiener型RKHS）。通过Schur补高效计算非渐近置信区间，并扩展到向量值函数。

研究结果: 实验表明，SGKI不仅能够准确估计缺失像素，还能为所有缺失像素提供同时保证的置信区间，适用于合成和基准图像数据集。

研究结论: SGKI方法在图像修复和超分辨率任务中表现出色，同时提供不确定性量化，为实际应用提供了可靠工具。

中文摘要: 本文提出了一种统计学习方法，用于解决图像修复和超分辨率问题中的缺失像素估计问题。该方法的一个主要创新是能够同时提供估计值及其不确定性量化。核心假设是数据生成函数来自再生核希尔伯特空间（RKHS），特别关注信号处理中的带限函数（Paley-Wiener型RKHS）。提出的方法称为同时保证核插值（SGKI），是对近期开发的核方法的扩展和优化。SGKI的优势在于不仅能估计缺失像素，还能为所有缺失像素构建非渐近置信区间。我们还展示了如何通过Schur补高效计算这些区间，讨论了向量值函数的推广，并通过合成和基准图像数据集进行了一系列数值实验。

</details>


### [484] [Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies](https://arxiv.org/abs/2506.24093)
**中文标题：基于真实与合成数据的混合人工智能训练开发：两种混合训练策略的基准测试**

*Paul Wachter,Lukas Niehaus,Julius Schöning*

主要分类: cs.LG

摘要简述: 本文系统评估了两种混合训练策略在三种架构和数据集上的表现，探讨了合成与真实数据比例对模型性能的影响，为优化人工神经网络训练提供了实用建议。


<details>
  <summary>详细信息</summary>
研究动机: 合成数据虽成本低，但与真实数据存在领域差距，导致模型泛化能力差。研究旨在填补对混合训练策略系统性评估的空白。

研究方法: 研究分析了两种混合训练策略，在三种架构和三种混合数据集上测试，并调整合成与真实数据的比例以观察影响。

研究结果: 实验表明，混合训练策略能有效缩小领域差距，但不同比例对模型性能有显著影响，需根据任务和架构优化。

研究结论: 研究为人工神经网络训练中合成数据的使用提供了优化方向，增强了模型的鲁棒性和有效性。

中文摘要: 合成数据已成为训练人工神经网络（ANN）的一种经济高效的替代方案。然而，合成数据与真实数据之间的差异导致了领域差距，这种差距使得训练后的ANN在现实场景中表现不佳且泛化能力差。为弥合这一差距，已开发出多种策略，将合成数据与真实数据结合，称为混合训练。尽管这些策略已被证明可以缓解领域差距，但其在不同任务和架构中的普适性和鲁棒性仍缺乏系统性评估。为应对这一挑战，本研究全面分析了两种广泛使用的混合策略在三种常见架构和三种混合数据集上的表现。从这些数据集中，我们采样了不同比例的合成与真实数据子集，以研究合成与真实成分的影响。本文的研究结果为优化任何ANN训练过程中合成数据的使用提供了宝贵见解，有助于提升模型的鲁棒性和有效性。

</details>


### [485] [Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime](https://arxiv.org/abs/2506.24120)
**中文标题：数据均匀性提升训练效率及其他：超越NTK体系的收敛框架**

*Yuqing Wang,Shangding Gu*

主要分类: cs.LG

摘要简述: 论文提出数据均匀性可提升训练效率与性能，通过最小化数据点间距离（$h_{\min}$）的理论分析，证明了更均匀的数据分布能加速梯度下降训练动态，并降低神经网络近似误差。实验验证了该理论在多种设置下的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 数据选择在数据驱动决策中至关重要，但现有研究多关注数据质量和多样性，缺乏通用且定量的数据选择原则。本文旨在探索数据均匀性对训练效率和性能的影响，填补这一空白。

研究方法: 通过理论分析，证明数据均匀性（$h_{\min}$）与梯度下降训练动态及神经网络近似误差的关系。提出超越NTK体系的收敛框架，适用于包括Transformer在内的广泛架构。实验验证了数据均匀性在不同优化策略、模型规模和数据集中的效果。

研究结果: 实验结果表明，通过最大化数据点间距离选择数据，能显著加速训练并在多种数据集上达到可比或更好的性能。理论分析进一步支持了残差连接和函数组合在深度架构中的应用。

研究结论: 数据均匀性是提升训练效率和性能的重要原则，理论框架为数据选择和模型设计提供了新的指导。

中文摘要: 数据选择在数据驱动决策（如大语言模型）中起关键作用，通常依赖任务特性。数据质量和多样性等属性已被广泛研究并证实能提升模型性能。然而，是否存在其他定量且通用的数据选择原则，尤其是对复杂任务和有限先验知识的情况，尚不明确。本文证明，选择更均匀分布的数据能提升训练效率并改善性能。具体而言，更均匀（偏差更小）的分布会导致数据点间最小成对距离（$h_{\min}$）更大，并证明较小的$h_{\min}$会减缓梯度下降（GD）的训练动态。此外，理论表明神经网络的近似误差随$h_{\min}$增大而减小。我们的分析提出了超越神经正切核（NTK）体系的GD收敛框架，适用于包括Transformer在内的广泛架构，无需Lipschitz平滑性。该框架还为深度架构中残差连接和函数组合的使用提供了理论依据。最后，我们在多种设置下进行了监督微调的全面实验，包括不同优化策略、模型规模和训练数据集。结果一致表明，通过最大化成对距离选择数据能显著加速训练，并在多种数据集上实现可比或更好的性能。代码和数据集见链接：https://github.com/SafeRL-Lab/data-uniformity。

</details>


### [486] [Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models](https://arxiv.org/abs/2506.23731)
**中文标题：扩散和自回归图像生成模型中的放射性水印**

*Michel Meintz,Jan Dubiński,Franziska Boenisch,Adam Dziedzic*

主要分类: cs.LG

摘要简述: 本文分析了扩散模型（DMs）和自回归图像生成模型（IARs）中水印的放射性特性，发现现有方法无法保留水印放射性，并提出了一种针对IARs的新型放射性水印方法。


<details>
  <summary>详细信息</summary>
研究动机: 图像生成模型需要大量数据集，但收集和整理成本高昂。为避免这些成本，部分方可能利用现有模型生成的图像作为训练数据。水印虽可用于检测未经授权的使用，但需具备放射性（即在训练后仍可识别）。现有方法在DMs中无法满足这一需求，而IARs尚无相关研究。

研究方法: 针对IARs，提出了一种新型放射性水印方法，灵感来自大型语言模型（LLMs）的自回归范式。通过实验验证其有效性。

研究结果: 实验表明，该方法在IARs中能有效保留水印放射性，支持稳健的来源追踪，防止生成图像的未经授权使用。

研究结论: 本文填补了IARs中放射性水印方法的空白，为生成图像的版权保护提供了新工具。

中文摘要: 图像生成模型日益流行，但其训练需要大量数据集，收集和整理成本高昂。为避免这些成本，部分方可能利用现有模型生成的图像作为训练数据。水印是检测未经授权使用的有效工具，但需具备放射性（即在训练后仍可识别）。本文分析了扩散模型（DMs）和自回归图像生成模型（IARs）中水印的放射性特性。发现现有DMs水印方法无法保留放射性，因水印在潜在空间编码或噪声-去噪过程中丢失。同时，尽管IARs在图像生成质量和效率上超越DMs，但尚无放射性水印方法。为此，我们提出首种针对IARs的放射性水印方法，灵感来自大型语言模型（LLMs）的自回归范式。实验表明，该方法在IARs中能有效保留水印放射性，支持稳健的来源追踪，防止生成图像的未经授权使用。

</details>


### [487] [Supercm: Revisiting Clustering for Semi-Supervised Learning](https://arxiv.org/abs/2506.23824)
**中文标题：Supercm：重新审视聚类在半监督学习中的应用**

*Durgesh Singh,Ahcene Boubekki,Robert Jenssen,Michael C. Kampffmeyer*

主要分类: cs.LG

摘要简述: 本文提出了一种新的半监督学习方法Supercm，通过引入可微聚类模块，显式利用SSL中的聚类假设，简化了训练策略并提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，半监督学习（SSL）的发展主要集中在一致性正则化或熵最小化方法上，导致模型训练策略复杂。本文旨在通过显式利用聚类假设，简化SSL方法并提升性能。

研究方法: 提出了一种新颖的SSL方法Supercm，扩展了最近提出的可微聚类模块，利用标注数据指导聚类中心，实现端到端的深度学习训练。

研究结果: 实验表明，该方法显著优于仅监督学习的基线，并能与其他SSL方法结合进一步提升性能。

研究结论: Supercm通过显式利用聚类假设，简化了SSL的训练策略并提升了性能，同时具备与其他方法结合的灵活性。

中文摘要: 近年来，半监督学习（SSL）的发展主要集中在开发新的一致性正则化或熵最小化方法上，这通常导致模型需要复杂的训练策略才能达到预期效果。本文提出了一种新方法，通过扩展最近提出的可微聚类模块，显式地将SSL中的聚类假设纳入模型。利用标注数据指导聚类中心，实现了一种简单的端到端可训练深度SSL方法。实验表明，该模型在性能上优于仅监督学习的基线，并且我们的框架可以与其他SSL方法结合使用，进一步提升其性能。

</details>


### [488] [The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2506.24000)
**中文标题：进步的假象？对视觉语言模型测试时适应的批判性审视**

*Lijun Sheng,Jian Liang,Ran He,Zilei Wang,Tieniu Tan*

主要分类: cs.LG

摘要简述: 本文批判性地审视了视觉语言模型（VLMs）的测试时适应（TTA）方法，指出当前研究存在结果重复、评估指标有限、实验设置不一致等问题，并提出了TTA-VLM基准以全面评估TTA方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前TTA研究存在诸多问题，如结果重复、评估指标单一、实验设置不一致等，这些问题阻碍了对TTA方法的公平比较。本文旨在通过提出TTA-VLM基准，解决这些问题，促进更可靠的TTA方法发展。

研究方法: 本文提出了TTA-VLM基准，统一实现了8种情景TTA和7种在线TTA方法，并在15个常用数据集上进行了评估。此外，还扩展了评估范围，包括SigLIP模型及训练时调优方法（如CoOp、MaPLe和TeCoA），并引入多种评估指标（如鲁棒性、校准性、分布外检测和稳定性）。

研究结果: 实验发现：1）现有TTA方法相比早期研究提升有限；2）当前TTA方法与训练时调优方法协作效果差；3）准确性提升常以模型可信度降低为代价。

研究结论: TTA-VLM基准为TTA方法提供了公平比较和全面评估，有助于推动更可靠、通用的TTA策略发展。

中文摘要: 测试时适应（TTA）方法在无需额外标注数据的情况下，显著提升了视觉语言模型（如CLIP）的推理性能，因而备受关注。然而，当前TTA研究普遍存在基线结果重复、评估指标有限、实验设置不一致和分析不足等主要问题，这些问题阻碍了对TTA方法的公平比较，并掩盖了其实际优缺点。为解决这些挑战，我们提出了TTA-VLM，一个用于评估VLMs上TTA方法的全面基准。我们的基准在一个统一且可复现的框架中实现了8种情景TTA和7种在线TTA方法，并在15个常用数据集上进行了评估。与以往仅关注CLIP的研究不同，我们将评估扩展到使用Sigmoid损失训练的SigLIP模型，并纳入训练时调优方法（如CoOp、MaPLe和TeCoA）以评估通用性。除分类准确率外，TTA-VLM还引入了多种评估指标，包括鲁棒性、校准性、分布外检测和稳定性，从而更全面地评估TTA方法。通过大量实验，我们发现：1）现有TTA方法相比早期研究提升有限；2）当前TTA方法与训练时调优方法协作效果差；3）准确性提升常以模型可信度降低为代价。我们发布TTA-VLM以促进对VLMs上TTA方法的公平比较和全面评估，并希望推动社区开发更可靠、通用的TTA策略。

</details>


### [489] [Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives](https://arxiv.org/abs/2506.24124)
**中文标题：让时间序列学会看与说：基于对齐视觉与文本视角的预测方法**

*Dong Sixun,Fan Wei,Teresa Wu,Fu Yanjie*

主要分类: cs.LG

摘要简述: 本文提出了一种多模态对比学习框架，将时间序列数据转化为视觉和文本视角，并通过对比学习对齐这两种模态，以提升时间序列预测的性能。实验表明，该方法在多个基准数据集上优于单模态和跨模态基线。


<details>
  <summary>详细信息</summary>
研究动机: 传统时间序列预测仅依赖数值输入，难以捕捉高级语义模式。虽然已有研究尝试用大语言模型将时间序列表示为文本，但这些方法受限于离散的标记序列，缺乏人类对视觉模式的感知直觉。因此，本文提出结合视觉和文本模态，以更全面地表示时间序列。

研究方法: 本文提出了一种多模态对比学习框架，将原始时间序列转化为结构化的视觉和文本视角。这两种模态直接从数值序列构建，并通过对比学习在共享语义空间中对齐。此外，还引入了变量选择模块，利用对齐的表征识别多变量预测中最具信息量的变量。

研究结果: 在15个短期和6个长期预测基准数据集上的实验表明，该方法显著优于单模态和跨模态基线，验证了多模态对齐在提升时间序列预测中的有效性。

研究结论: 通过将时间序列转化为视觉和文本模态并对其对齐，本文提出的方法能够捕捉更丰富和互补的表征，从而显著提升预测性能。多模态对齐为时间序列预测提供了新的研究方向。

中文摘要: 传统的时间序列预测通常依赖于单模态的数值输入，但由于其密集和非结构化的特性，往往难以捕捉高级语义模式。尽管最近的研究尝试使用大语言模型（LLMs）将时间序列表示为文本，但这些方法仍受限于离散的标记序列，并缺乏人类通常应用的感知直觉（如对视觉模式的解读）。本文提出了一种多模态对比学习框架，将原始时间序列转化为结构化的视觉和文本视角。这两种模态直接从数值序列构建，而非使用自然语言或真实图像。随后，通过对比学习将这些视角在共享语义空间中对齐，使模型能够捕捉更丰富且互补的表征。此外，我们还引入了一个变量选择模块，利用对齐的表征识别多变量预测中最具信息量的变量。在15个短期和6个长期预测基准数据集上的大量实验表明，我们的方法在性能上始终优于强单模态和跨模态基线，突显了多模态对齐在提升时间序列预测中的有效性。代码发布于：https://github.com/Ironieser/TimesCLIP。

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [490] [Towards the "Digital Me": A vision of authentic Conversational Agents powered by personal Human Digital Twins](https://arxiv.org/abs/2506.23826)
**中文标题：迈向“数字自我”：基于个人人类数字孪生的真实对话智能体愿景**

*Lluís C. Coll,Martin W. Lauer-Schmaltz,Philip Cash,John P. Hansen,Anja Maier*

主要分类: cs.ET

摘要简述: 本文提出了一种新型人类数字孪生（HDT）系统架构，结合大语言模型与动态更新的个人数据，以创建能模拟个体对话风格、记忆和行为的真实交互式数字分身。该系统通过上下文感知记忆检索、神经可塑性启发式巩固和自适应学习机制，实现更自然的数字人格演化。同时，研究也探讨了隐私和伦理等关键问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统的人类数字孪生（HDT）主要用于数据驱动的决策支持，但随着对话式AI的进步，HDT有望成为个体的真实交互式数字分身。本文旨在探索如何通过技术手段实现这一目标，并解决由此引发的伦理挑战。

研究方法: 提出了一种新型HDT系统架构，整合大语言模型与动态更新的个人数据。采用上下文感知记忆检索、神经可塑性启发式巩固和自适应学习机制，使系统能够模拟个体的对话风格、记忆和行为，并动态融入个人经历、观点和记忆。

研究结果: 该系统不仅能根据对话对象复现个体的独特对话风格，还能通过动态捕捉的个人数据丰富回应内容。实验表明，该系统在模拟真实交互式数字分身方面取得了显著进展。

研究结论: 研究为HDT领域提供了创新的系统架构，并展示了其在创建真实数字分身方面的潜力。然而，隐私、责任和持久数字身份的长期影响等伦理问题仍需进一步探讨，以确保HDT的负责任发展。

中文摘要: 传统上，人类数字孪生（HDT）被设计为数据驱动的模型，用于支持多领域的决策。然而，对话式AI的最新进展为HDT作为个体的真实交互式数字分身提供了新的可能性。本文提出了一种新型HDT系统架构，通过整合大语言模型与动态更新的个人数据，使其能够模拟个体的对话风格、记忆和行为。为实现这一目标，我们的方法采用了上下文感知记忆检索、神经可塑性启发式巩固和自适应学习机制，从而创建了一种更自然且不断演化的数字人格。最终的系统不仅能根据对话对象复现个体的独特对话风格，还能通过动态捕捉的个人经历、观点和记忆丰富回应内容。尽管这一研究在开发真实虚拟分身方面迈出了重要一步，但也引发了关于隐私、责任和持久数字身份长期影响的伦理问题。本研究通过描述新型系统架构、展示其能力并讨论未来方向与新兴挑战，为HDT领域的负责任和伦理发展做出了贡献。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [491] [Unsupervised Learning-Based Joint Resource Allocation and Beamforming Design for RIS-Assisted MISO-OFDMA Systems](https://arxiv.org/abs/2506.22448)
**中文标题：基于无监督学习的RIS辅助MISO-OFDMA系统联合资源分配与波束成形设计**

*Yu Ma,Xingyu Zhou,Xiao Li,Le Liang,Shi Jin*

主要分类: eess.SP

摘要简述: 本文提出了一种基于无监督学习的两阶段框架，用于联合设计RIS辅助MISO-OFDMA系统中的RIS相位偏移、基站波束成形和资源块分配，显著提升了系统性能并降低了计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 可重构智能表面（RIS）是6G无线系统的关键技术，但在RIS辅助的MISO-OFDMA系统中，资源分配和波束成形设计面临挑战。本文旨在通过无监督学习方法解决这些问题，提升系统效率和性能。

研究方法: 提出两阶段框架：BeamNet预测RIS相位偏移，AllocationNet分配资源块。采用最大比传输和注水算法实现主动波束成形，并通过量化和Gumbel-softmax技巧处理离散约束。定制化损失函数和分阶段训练优化了QoS约束下的性能。

研究结果: 仿真结果表明，该方法达到了SCA基线99.93%的和速率，且仅需其0.036%的运行时间，在不同信道和用户条件下均表现出鲁棒性。

研究结论: 本文提出的无监督学习框架在RIS辅助系统中实现了高效的资源分配和波束成形设计，显著降低了计算复杂度，为实际应用提供了可行方案。

中文摘要: 可重构智能表面（RIS）是6G无线系统的关键使能技术。本文研究了RIS辅助的MISO-OFDMA系统中的下行传输问题，解决了资源分配的挑战。提出了一种基于无监督学习的两阶段框架，用于联合设计RIS相位偏移、基站波束成形和资源块（RB）分配。该框架包括BeamNet（从CSI预测RIS相位偏移）和AllocationNet（利用BeamNet输出的等效CSI分配RB）。主动波束成形通过最大比传输和注水算法实现。为处理离散约束并确保可微性，采用了量化和Gumbel-softmax技巧。定制化损失和分阶段训练在QoS约束下提升了性能。仿真显示，该方法达到了SCA基线99.93%的和速率，且仅需其0.036%的运行时间，在不同信道和用户条件下均表现出鲁棒性。

</details>


### [492] [A Complex UNet Approach for Non-Invasive Fetal ECG Extraction Using Single-Channel Dry Textile Electrodes](https://arxiv.org/abs/2506.22457)
**中文标题：基于复杂UNet的单通道干纺织电极非侵入式胎儿心电图提取方法**

*Iulia Orvas,Andrei Radu,Alessandra Galli,Ana Neacsu,Elisabetta Peri*

主要分类: eess.SP

摘要简述: 本文提出了一种基于复杂值去噪网络Complex UNet的新方法，用于从单通道干纺织电极记录中提取胎儿心电图（fECG），解决了噪声和运动伪影问题，实现了高精度的fECG形态提取。


<details>
  <summary>详细信息</summary>
研究动机: 连续、无创的孕期监测对减少潜在并发症至关重要。家庭监测需要舒适耐用的电极（如干纺织电极），但单通道记录中噪声和运动伪影增加了fECG提取的难度。本文旨在解决这一问题，推动家庭化fECG监测的发展。

研究方法: 提出了一种基于Complex UNet的创新流程，处理频谱图的实部和虚部，解决相位信息问题。通过模拟腹部记录创建新数据集，并在模拟和真实数据上评估fECG提取和R峰检测性能。

研究结果: 实验表明，该方法在fECG提取和R峰检测上均达到最新技术水平，能够准确提取fECG形态，适用于所有评估场景。

研究结论: 本文首次实现了从单通道干纺织电极记录中有效提取fECG信号，为非侵入式、自主操作的fECG提取方案迈出重要一步。

中文摘要: 连续、无创的孕期监测对减少潜在并发症至关重要。胎儿心电图（fECG）是评估胎儿健康的重要工具，而家庭监测需要舒适耐用的电极（如干纺织电极）。然而，这种设置带来了噪声和运动伪影等挑战，增加了fECG提取的难度。为克服这些挑战，我们提出了一种基于AI技术的新方法，从单通道干纺织电极记录中提取fECG。我们通过模拟腹部记录创建了新数据集，包括与真实干纺织电极记录相似的噪声、母体心电图（mECG）和fECG。为确保提取的fECG可靠性，我们提出了一种基于复杂值去噪网络Complex UNet的创新流程。与以往仅关注信号幅值的方法不同，我们的方法同时处理频谱图的实部和虚部，解决相位信息问题并避免不一致预测。我们在模拟和真实数据上评估了fECG提取和R峰检测性能。结果表明，该方法在所有评估场景中均达到最新技术水平，能够准确提取fECG形态。这是首次从单通道干纺织电极记录中有效提取fECG信号的方法，为非侵入式、自主操作的fECG提取方案迈出重要一步。

</details>


### [493] [Heart rate and respiratory rate prediction from noisy real-world smartphone based on Deep Learning methods](https://arxiv.org/abs/2506.22460)
**中文标题：基于深度学习的嘈杂真实世界智能手机数据的心率和呼吸率预测**

*Ibne Farabi Shihab*

主要分类: eess.SP

摘要简述: 研究提出了一种基于3D深度卷积神经网络的新方法，用于从智能手机拍摄的指尖视频中预测心率和呼吸率，显著降低了误差（心率误差减少68%，呼吸率误差减少75%）。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究通常在实验室环境下通过智能手机视频估计心率和呼吸率，但实际日常生活中的数据表现较差。本研究旨在利用深度学习技术提升日常环境下心率与呼吸率的预测准确性。

研究方法: 研究采用了一种新型的3D深度卷积神经网络（CNN），通过分析日常生活中的智能手机指尖视频数据，预测心率和呼吸率。

研究结果: 与传统算法相比，新方法显著降低了预测误差，心率误差减少68%，呼吸率误差减少75%。

研究结论: 基于回归器的深度学习方法在心率与呼吸率预测中表现优异，应推广应用于实际场景。

中文摘要: 长期以来，使用智能手机拍摄的指尖视频作为数据源来估计心率和呼吸率等生命体征被广泛讨论。尽管现有文献表明这些估计值在每分钟几次心跳或呼吸的范围内是准确的，但这些结论通常基于实验室环境下严格控制的数据，并假设结果可推广到日常生活中。为了验证这一点，研究团队收集了一个包含111名参与者的日常生活智能手机视频数据集，并标注了真实的心率和呼吸率标签。他们发现，传统算法在指纹视频上的表现比之前报道的更差（呼吸率和心率的误差分别增加了7倍和13倍）。幸运的是，深度学习的最新进展，尤其是卷积神经网络（CNN），为提高性能提供了有希望的解决方案。本研究提出了一种使用新型3D深度CNN估计心率和呼吸率的新方法，结果显示心率估计误差减少了68%，呼吸率误差减少了75%。这些积极结果表明，基于回归器的深度学习方法应被用于心率和呼吸率的估计。

</details>


### [494] [Machine Learning for Proactive Groundwater Management: Early Warning and Resource Allocation](https://arxiv.org/abs/2506.22461)
**中文标题：机器学习用于主动地下水管理：早期预警与资源分配**

*Chuan Li,Ruoxuan Yang*

主要分类: eess.SP

摘要简述: 本文提出了一种基于机器学习的自动化管道，用于预测地下水位类别，结合气候数据、水文气象记录和地理属性，通过AutoGluon框架实现高效模型选择，应用于法国大规模数据集，验证了其在地下水预警和资源分配中的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 地下水对生态系统、农业和饮用水供应至关重要，但传统监测方法受限于数据稀疏、计算资源不足和结果滞后。本文旨在通过机器学习克服这些限制，实现更高效的地下水管理。

研究方法: 研究开发了一个机器学习管道，结合地理空间预处理、领域驱动的特征工程和AutoGluon的自动化模型选择框架，利用气候数据、水文气象记录和地理属性预测地下水位类别。

研究结果: 在法国大规模数据集（超过3,440,000条观测数据，来自1,500多口井）上，模型在验证数据上的加权F1分数为0.927，在时间独立的测试数据上为0.67。情景评估表明该方法适用于气候变化条件下的早期预警和水资源分配决策。

研究结论: 开源实现为将机器学习整合到国家地下水监测网络提供了可扩展框架，支持更响应迅速和数据驱动的水资源管理策略。

中文摘要: 地下水支撑着全球的生态系统、农业和饮用水供应，但由于数据稀疏、计算资源限制以及传统方法的输出延迟，有效监测仍然具有挑战性。我们开发了一种机器学习管道，利用气候数据、水文气象记录和地理属性，通过AutoGluon的自动化集成框架预测地下水位类别。我们的方法结合了地理空间预处理、领域驱动的特征工程和自动化模型选择，以克服传统监测的局限性。应用于法国的大规模数据集（超过3,440,000条观测数据，来自1,500多口井），模型在验证数据上的加权F1分数为0.927，在时间独立的测试数据上为0.67。基于情景的评估表明，该方法在气候变化条件下的早期预警系统和水资源分配决策中具有实际应用价值。开源实现为将机器学习整合到国家地下水监测网络提供了可扩展框架，支持更响应迅速和数据驱动的水资源管理策略。

</details>


### [495] [Privacy-aware IoT Fall Detection Services For Aging in Place](https://arxiv.org/abs/2506.22462)
**中文标题：隐私感知的物联网跌倒检测服务：支持居家养老**

*Abdallah Lakhdari,Jiajie Li,Amani Abusafia,Athman Bouguettaya*

主要分类: eess.SP

摘要简述: 本文提出了一种基于物联网的隐私感知跌倒检测服务（FDaaS）框架，通过超宽带雷达传感器和生成预训练变换器（FD-GPT）解决数据稀缺和隐私问题，实验结果显示其准确率达90.72%。


<details>
  <summary>详细信息</summary>
研究动机: 随着老年人口预计到2050年达到21亿，跌倒检测对支持老年人独立生活至关重要。现有方法常面临数据稀缺或隐私泄露问题，亟需一种既能准确检测跌倒又能保护隐私的解决方案。

研究方法: 设计了一种面向服务的架构，利用超宽带（UWB）雷达传感器作为物联网健康感知服务，确保隐私和低侵入性。通过生成预训练变换器（FD-GPT）的数据增强技术解决数据稀缺问题，并开发协议收集老年人日常活动和跌倒事件的综合数据集。

研究结果: 实验结果表明，该方法在区分跌倒事件和日常活动时，准确率达到90.72%，精确度为89.33%。

研究结论: 提出的FDaaS框架在保护隐私的同时，显著提高了跌倒检测的准确性，为老年人独立生活提供了可靠支持。

中文摘要: 跌倒检测对于支持日益增长的老年人口至关重要，预计到2050年将达到21亿。然而，现有方法常面临数据稀缺或隐私泄露的挑战。我们提出了一种基于物联网的跌倒检测即服务（FDaaS）框架，通过准确检测跌倒帮助老年人独立安全生活。我们设计了一种面向服务的架构，利用超宽带（UWB）雷达传感器作为物联网健康感知服务，确保隐私和低侵入性。为解决数据稀缺问题，我们采用了基于生成预训练变换器（FD-GPT）的数据增强技术。我们开发了一种协议，用于收集老年人日常活动和跌倒事件的综合数据集，生成了一份真实模拟老年人日常活动的数据集。我们使用该数据集对各种模型进行了严格评估和比较。实验结果表明，我们的方法在区分跌倒事件和日常活动时，准确率达到90.72%，精确度为89.33%。

</details>


### [496] [Dimensionality Reduction on IoT Monitoring Data of Smart Building for Energy Consumption Forecasting](https://arxiv.org/abs/2506.22468)
**中文标题：智能建筑能源消耗预测中物联网监测数据的降维方法**

*Konstantinos Koutras,Agorakis Bompotas,Constantinos Halkiopoulos,Athanasios Kalogeras,Christos Alexakos*

主要分类: eess.SP

摘要简述: 本文通过相关性分析，筛选出与能源消耗强相关的环境变量，利用机器学习预测算法减少输入参数，同时保持预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决在边缘计算设备资源有限的情况下，如何通过减少数据输入参数来维持数据分析的准确性，尤其是在智能建筑能源消耗预测中。

研究方法: 通过相关性分析，对来自智能办公室的环境和能源消耗传感器数据进行假设检验，测试三种环境变量与能源消耗的相关性，共进行九十次测试。

研究结果: 测试结果显示，两种环境变量与能源消耗存在强或半强相关性，第三种变量相关性较弱。通过排除弱相关变量，保持了预测准确性。

研究结论: 提出的方法能够在减少输入参数的同时，保持能源消耗预测的准确性，适用于资源有限的边缘计算设备。

中文摘要: 物联网（IoT）在智能建筑基础设施中扮演着重要角色，从简单的智能家居应用到复杂的工业安装。相关系统生成的大量数据可以通过多种方式处理，揭示重要信息。在边缘计算时代，高级数据分析和决策逐渐向网络边缘转移，而边缘设备通常计算资源有限。在此背景下，主要挑战之一是如何在减少数据量的同时保持数据分析的准确性。本研究通过对一个小型智能办公室的环境和能源消耗传感器数据进行相关性分析，旨在找到监测变量之间的统计相关性，从而利用机器学习预测算法减少能源消耗的输入参数。为此，对三种不同环境变量与能源消耗的相关性进行了假设检验，共进行了九十次测试。测试结果表明，两种环境变量与能源消耗存在强或半强相关性，第三种变量相关性较弱。通过提出的方法，无需检查整个数据集即可排除弱相关变量，同时保持相同的预测准确性。

</details>


### [497] [Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses](https://arxiv.org/abs/2506.22495)
**中文标题：感受心脏的掩码自编码器：揭示ECG分析中的简单性偏差**

*He-Yang Xu,Hongxiang Gao,Yuwen Li,Xiu-Shen Wei,Chengyu Liu*

主要分类: eess.SP

摘要简述: 本文揭示了心电图（ECG）分析中的简单性偏差（SB）问题，并提出了一种基于自监督学习（SSL）的新方法，通过时空频率感知滤波器和多粒度原型重建，有效缓解SB，并在多个ECG数据集上取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 心电图（ECG）的动态特性包含丰富的诊断信息，但传统监督模型容易过度拟合显性模式，忽视细微但关键的临床线索，即简单性偏差（SB）。本文旨在通过自监督学习（SSL）解决这一问题。

研究方法: 提出了一种结合时空频率感知滤波器和多粒度原型重建的自监督学习方法，前者捕捉ECG信号的时空频率特征，后者通过粗粒度和细粒度表示学习进一步缓解SB。

研究结果: 在六个ECG数据集上的三个下游任务中，该方法显著降低了SB，并实现了最先进的性能。

研究结论: 自监督学习是解决ECG分析中简单性偏差的有效途径，提出的方法在性能上优于现有技术，为ECG诊断提供了新方向。

中文摘要: 心电图（ECG）的诊断价值在于其动态特性，包括节律波动和随时间与频率域演变的细微波形变形。然而，监督ECG模型倾向于过度拟合显性和重复模式，忽视细微但临床关键的线索，这种现象称为简单性偏差（SB），即模型偏好易学习的信号而非细微但信息丰富的信号。本文首先实证了ECG分析中SB的存在及其对诊断性能的负面影响，同时发现自监督学习（SSL）可以缓解SB，为解决这一偏差提供了方向。基于SSL范式，我们提出了一种新方法，包含两个关键组件：1）时空频率感知滤波器，用于捕捉反映ECG信号动态特性的时空频率特征；2）在此基础上，多粒度原型重建用于跨双域的粗粒度和细粒度表示学习，进一步缓解SB。为推进ECG分析中的SSL，我们整理了一个包含来自300多个临床中心的153万条记录的大规模多站点ECG数据集。在六个ECG数据集上的三个下游任务实验中，我们的方法有效降低了SB并实现了最优性能。代码和数据集将公开。

</details>


### [498] [Multi-Branch DNN and CRLB-Ratio-Weight Fusion for Enhanced DOA Sensing via a Massive H$^2$AD MIMO Receiver](https://arxiv.org/abs/2506.23203)
**中文标题：基于多分支DNN和CRLB比率权重融合的大规模H$^2$AD MIMO接收器增强DOA感知**

*Feng Shu,Jiatong Bai,Di Wu,Wei Zhu,Bin Deng,Fuhui Zhou,Jiangzhou Wang*

主要分类: eess.SP

摘要简述: 本文提出了一种轻量级的CRLB比率权重融合方法和多分支深度神经网络，用于提升大规模H$^2$AD MIMO接收器的DOA感知性能，减少对先验知识的依赖，并在低信噪比下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 大规模H$^2$AD作为一种绿色MIMO结构，是未来6G无线网络的潜在技术。然而，设计一种低复杂度、高性能且较少依赖先验知识的目标方向值融合方法是一个挑战。

研究方法: 提出了一种轻量级的CRLB比率权重融合方法，通过天线数量倒数近似子阵列的逆CRLB，避免实时CRLB计算。此外，构建了多分支深度神经网络（MBDNN），利用多子阵列的候选角度增强DOA感知，并通过共享回归模块消除伪解和融合真实角度。

研究结果: 仿真结果表明，CRLB比率权重融合方法的性能接近基于CRLB的方法，同时显著减少了对先验知识的依赖。MBDNN在低信噪比范围表现尤为突出，在SNR为-15 dB时，其估计精度比CRLB比率权重融合方法提高了一个数量级。

研究结论: 本文提出的方法在降低复杂度和减少先验知识依赖的同时，显著提升了DOA感知性能，特别是在低信噪比环境下。

中文摘要: 作为一种绿色MIMO结构，大规模H$^2$AD被视为未来6G无线网络的潜在技术。对于这种结构，设计一种低复杂度、高性能且较少依赖先验知识的目标方向值融合方法是一个挑战。为此，本文提出了一种轻量级的Cramer-Rao下界（CRLB）比率权重融合（WF）方法，通过天线数量倒数近似子阵列的逆CRLB，避免实时CRLB计算，从而降低复杂度和减少先验知识依赖，同时保持融合性能。此外，构建了一个多分支深度神经网络（MBDNN），通过利用多子阵列的候选角度进一步增强到达方向（DOA）感知。子阵列特定的分支网络与共享回归模块集成，有效消除伪解并融合真实角度。仿真结果表明，所提出的CRLB比率权重融合方法的DOA感知性能与基于CRLB的方法相当，同时显著减少了对先验知识的依赖。更值得注意的是，所提出的MBDNN在低信噪比范围表现优异。在SNR为-15 dB时，其估计精度比CRLB比率权重融合方法提高了一个数量级。

</details>


### [499] [SegmentAnyMuscle: A universal muscle segmentation model across different locations in MRI](https://arxiv.org/abs/2506.22467)
**中文标题：SegmentAnyMuscle：一种适用于MRI中不同位置的通用肌肉分割模型**

*Roy Colglazier,Jisoo Lee,Haoyu Dong,Hanxue Gu,Yaqian Chen,Joseph Cao,Zafer Yildiz,Zhonghao Liu,Nicholas Konz,Jichen Yang,Jikai Zhang,Yuwen Chen,Lin Li,Adrian Camarena,Maciej A. Mazurowski*

主要分类: eess.SP

摘要简述: 本研究开发了一种通用的肌肉分割模型SegmentAnyMuscle，适用于MRI中不同解剖位置和成像序列，平均DSC达88.45%和86.21%，模型已公开以促进肌肉与健康关系的研究。


<details>
  <summary>详细信息</summary>
研究动机: 肌肉的数量和质量是健康的重要预测指标，但MRI中精确量化肌肉仍具挑战性。本研究旨在开发一个公开可用的肌肉分割模型，适用于不同解剖位置和成像序列。

研究方法: 研究使用了362例来自160名患者的MRI数据，其中316例用于模型开发。模型测试分为两组：一组为常见序列类型（28例MRI），另一组为罕见序列和异常情况（18例MRI）。

研究结果: 模型在常见序列组中平均DSC为88.45%，在罕见序列和异常组中为86.21%，表明其在多样化设置下均能有效分割肌肉。

研究结论: 研究证明了一种全自动深度学习算法在MRI中分割肌肉的可行性，并公开模型以支持肌肉与健康关系的可重复研究。

中文摘要: 肌肉的数量和质量日益被视为健康结果的重要预测指标。尽管MRI为此类评估提供了有价值的模态，但获取精确的肌肉定量测量仍具挑战性。本研究旨在开发一个公开可用的MRI肌肉分割模型，并展示其在不同解剖位置和成像序列中的适用性。研究纳入了来自160名患者的362例MRI数据（杜克大学健康系统，2016-2020年），其中114名患者的316例MRI用于模型开发。模型测试分为两组：一组为28例代表常见序列类型的MRI，平均Dice相似系数（DSC）为88.45%；另一组为18例包含罕见序列及异常（如肌肉萎缩、硬件和显著噪声）的MRI，平均DSC为86.21%。这些结果表明，全自动深度学习算法在多样化设置下分割MRI肌肉具有可行性。该模型的公开发布为肌肉与健康关系的可重复研究提供了支持。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [500] [Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation](https://arxiv.org/abs/2506.23717)
**中文标题：通过自适应比特分配实现高效准确的脉冲神经网络**

*Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng*

主要分类: cs.NE

摘要简述: 本文提出了一种自适应比特分配策略，通过优化脉冲神经网络（SNN）的权重和脉冲的比特宽度与时间长度，显著提升了SNN的效率和准确性。实验表明，该方法在降低内存和计算成本的同时，实现了更高的准确率。


<details>
  <summary>详细信息</summary>
研究动机: 多比特脉冲神经网络（SNN）在追求高能效和高准确性的同时，随着比特数的增加，内存和计算需求急剧上升，导致性能提升不成比例。不同层的重要性不同，多余的比特可能被浪费或干扰，因此需要一种自适应比特分配策略来优化资源分配。

研究方法: 本文提出了一种自适应比特分配策略，将权重和脉冲的时间长度与比特宽度参数化，并通过梯度使其可学习和可控。针对可变比特宽度和时间长度带来的挑战，提出了改进的脉冲神经元，能够处理不同时间长度并支持梯度推导。此外，理论分析了可学习比特宽度导致的步长不匹配问题，并提出了步长更新机制以缓解量化误差。

研究结果: 在静态数据集（如CIFAR和ImageNet）和动态数据集（如CIFAR-DVS和DVS-GESTURE）上的实验表明，该方法在降低整体内存和计算成本的同时，实现了更高的准确率。例如，SEWResNet-34在ImageNet上实现了2.69%的准确率提升，比特预算降低了4.16倍。

研究结论: 本文提出的自适应比特分配策略显著提升了SNN的效率和准确性，为高能效和高性能的AI系统提供了新的解决方案。该方法将完全开源。

中文摘要: 多比特脉冲神经网络（SNN）近年来成为研究热点，旨在实现高能效和高准确性的AI。然而，随着比特数的增加，内存和计算需求急剧上升，导致性能提升不成比例。基于不同层的重要性不同且多余比特可能被浪费或干扰的洞察，本文提出了一种针对直接训练的SNN的自适应比特分配策略，实现了细粒度的分层资源分配，从而提升SNN的效率和准确性。具体而言，我们将权重和脉冲的时间长度与比特宽度参数化，并通过梯度使其可学习和可控。为解决可变比特宽度和时间长度带来的挑战，提出了改进的脉冲神经元，能够处理不同时间长度、支持梯度推导并更好地适应脉冲量化。此外，我们理论分析了可学习比特宽度导致的步长不匹配问题，并提出了步长更新机制以缓解量化误差。在静态数据集（如CIFAR和ImageNet）和动态数据集（如CIFAR-DVS和DVS-GESTURE）上的实验表明，该方法在降低整体内存和计算成本的同时，实现了更高的准确率。特别是，我们的SEWResNet-34在ImageNet上实现了2.69%的准确率提升，比特预算降低了4.16倍。本工作将完全开源。

</details>


### [501] [Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment](https://arxiv.org/abs/2506.23734)
**中文标题：标记基因方法：在动态环境中识别稳定解**

*Hao Shi,Xi Li,Fangfang Xie*

主要分类: cs.NE

摘要简述: 本文提出了一种名为标记基因方法（MGM）的框架，用于解决竞争性协同进化算法（CCEAs）中的不稳定收敛问题。MGM通过动态基准和自适应权重机制，显著提升了算法在复杂竞争环境中的稳定性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 竞争性协同进化算法（CCEAs）常因复杂的动态行为（如非传递性和红皇后效应）导致不稳定收敛。为解决这一问题，本文旨在开发一种能够稳定算法收敛的理论框架。

研究方法: 本文提出了标记基因方法（MGM），通过引入动态基准（标记基因）和自适应权重机制，平衡探索与开发。此外，还扩展了记忆池（MP）以增强其性能。

研究结果: MGM在严格竞争博弈框架下被证明能够生成纳什均衡附近的强吸引子。实验表明，MGM在经典剪刀石头布游戏、ZDT基准测试以及病理性的Shapley偏置游戏中均表现出色。

研究结论: MGM是一个理论严谨且实证有效的框架，显著提升了CCEAs在复杂竞争环境中的稳定性和鲁棒性。

中文摘要: 竞争性协同进化算法（CCEAs）常因复杂的动态行为（如非传递性和红皇后效应）导致不稳定收敛。为解决这一问题，本文提出了标记基因方法（MGM），该框架通过动态基准（标记基因）和自适应权重机制平衡探索与开发。我们提供了严格的数学证明，表明MGM在严格竞争博弈框架下能够生成纳什均衡附近的强吸引子。实证研究表明，MGM在经典剪刀石头布游戏中实现了稳定，显著提升了C-RMOEA/D在ZDT基准测试中的性能，并通过记忆池（MP）扩展成功解决了病理性的Shapley偏置游戏。本研究提出了一个理论严谨且实证有效的框架，显著增强了CCEAs在复杂竞争环境中的稳定性和鲁棒性。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [502] [Supervised Diffusion-Model-Based PET Image Reconstruction](https://arxiv.org/abs/2506.24034)
**中文标题：基于监督扩散模型的PET图像重建**

*George Webber,Alexander Hammers,Andrew P King,Andrew J Reader*

主要分类: physics.med-ph

摘要简述: 本文提出了一种基于监督扩散模型的PET图像重建方法，通过结合PET的泊松似然模型和非负性约束，显著提升了重建精度，并在实验中优于现有深度学习方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无监督扩散模型在PET图像重建中虽然具有泛化优势，但未能显式建模扩散模型先验与噪声测量数据的交互，可能限制重建精度。本文旨在通过监督学习方法解决这一问题。

研究方法: 提出了一种监督扩散模型算法，强制PET泊松似然模型的非负性，并适应PET图像的宽强度范围。通过真实脑PET模型实验验证其性能，并进行了消融研究以分析模型组件、训练数据、参数数量和扩散步数的影响。

研究结果: 实验表明，该方法在多种剂量水平下定量优于或匹配现有深度学习方法，且能更准确地进行后验采样，表明其不确定性估计能力更强。此外，方法还扩展到了全3D PET的实际应用中。

研究结论: 监督扩散模型方法显著提升了PET图像重建的精度和不确定性估计能力，为实际应用提供了有效工具。

中文摘要: 扩散模型（DMs）最近被引入作为PET图像重建的正则化先验，通过将基于高质量PET图像训练的DMs与基于测量数据的无监督方案结合。尽管这些方法因独立于扫描仪几何结构和注射活性水平而具有泛化优势，但它们放弃了显式建模DM先验与噪声测量数据交互的机会，可能限制重建精度。为此，我们提出了一种基于监督DM的PET重建算法。我们的方法强制PET泊松似然模型的非负性，并适应PET图像的宽强度范围。通过在真实脑PET模型上的实验，我们证明了该方法在多种剂量水平下定量优于或匹配现有深度学习方法。我们还通过消融研究展示了模型中提出组件的优势，以及其对训练数据、参数数量和扩散步数的依赖性。此外，我们表明该方法比无监督DM方法能更准确地进行后验采样，表明其不确定性估计能力更强。最后，我们将方法扩展到全3D PET的实际应用中，并展示了来自真实[$^{18}$F]FDG脑PET数据的示例结果。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [503] [Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding](https://arxiv.org/abs/2506.22593)
**中文标题：像素到图：实时集成建筑信息模型与场景图以实现语义-几何的人机理解**

*Antonello Longo,Chanyoung Chung,Matteo Palieri,Sung-Kyun Kim,Ali Agha,Cataldo Guaragnella,Shehryar Khattak*

主要分类: cs.RO

摘要简述: 本文提出了一种名为Pixels-to-Graph（Pix2G）的轻量级方法，用于在资源受限的机器人平台上实时生成结构化场景图，以支持自主探索未知环境。该方法通过图像像素和LiDAR地图生成去噪的2D俯视图和结构分割的3D点云，并通过多层图连接这些信息。


<details>
  <summary>详细信息</summary>
研究动机: 自主机器人在高风险应用中需要高效的人机协作与理解。机器人通常依赖3D几何信息进行规划，而人类操作者更习惯使用高层级的紧凑环境表示（如2D BIM地图）。3D场景图可以弥合人类可读的2D BIM与机器人3D地图之间的差距。

研究方法: Pix2G是一种轻量级方法，能够在仅使用CPU的情况下，实时从图像像素和LiDAR地图生成结构化场景图。该方法输出去噪的2D俯视图和结构分割的3D点云，并通过多层图将这些信息从对象级到建筑级进行抽象连接。

研究结果: 在NASA JPL NeBula-Spot腿式机器人上进行的真实世界实验中，Pix2G方法能够实时自主探索和映射杂乱的车库和城市办公室环境，定量和定性评估均表现良好。

研究结论: Pix2G方法成功实现了在资源受限的机器人平台上实时生成语义-几何场景图的目标，为人机协作提供了高效的环境理解工具。

中文摘要: 自主机器人在高风险、危险应用中作为人类操作者的支持平台发挥着越来越重要的作用。为了完成具有挑战性的任务，需要高效的人机协作与理解。机器人规划通常利用3D几何信息，而人类操作者则习惯于使用高层级的紧凑环境表示，如表示建筑信息模型（BIM）的俯视2D地图。3D场景图已成为弥合人类可读的2D BIM与机器人3D地图之间差距的强大工具。本文提出了Pixels-to-Graph（Pix2G），一种新颖的轻量级方法，用于在资源受限的机器人平台上实时从图像像素和LiDAR地图生成结构化场景图，以支持自主探索未知环境。为了满足机载计算限制，该框架设计为仅使用CPU执行所有操作。方法的输出包括去噪的2D俯视环境地图和结构分割的3D点云，这些信息通过多层图从对象级到建筑级无缝连接。通过NASA JPL NeBula-Spot腿式机器人在真实世界中的实验，对提出的方法进行了定量和定性评估，实现了实时自主探索和映射杂乱车库和城市办公室环境的目标。

</details>


### [504] [Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making](https://arxiv.org/abs/2506.23023)
**中文标题：基于场景的分层强化学习在自动驾驶决策中的应用**

*M. Youssef Abdelhamid,Lennart Vater,Zlatan Ajanovic*

主要分类: cs.RO

摘要简述: 本文提出了一种基于场景的分层强化学习框架（SAD-RL），用于自动驾驶决策，通过高层策略选择动作模板并由低层控制逻辑执行，显著提升了复杂驾驶任务中的安全性和学习效率。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶系统需要在开放复杂环境中安全运行，当前强化学习方法在简单任务中表现良好，但在复杂任务中缺乏泛化能力和学习效率，因此需要一种更高效的框架来解决这一问题。

研究方法: 提出SAD-RL框架，结合分层强化学习和场景化环境，高层策略选择动作模板，低层控制逻辑执行具体动作，并通过场景化环境引入多样化训练数据。

研究结果: 实验表明，SAD-RL框架训练的智能体在简单和复杂场景中均能高效实现安全行为，消融研究证实分层学习和场景多样性是关键因素。

研究结论: SAD-RL框架通过分层策略和场景化训练，显著提升了自动驾驶决策的安全性和泛化能力，为复杂驾驶任务提供了有效解决方案。

中文摘要: 开发高度自动驾驶系统的决策算法仍具挑战性，因为这些系统需在开放复杂环境中安全运行。强化学习（RL）方法可直接从经验中学习综合决策策略，在简单驾驶任务中已显示出良好效果。然而，现有方法在复杂任务中缺乏泛化能力且学习效率不足。为此，我们提出了基于场景的自动驾驶强化学习（SAD-RL），这是首个将分层策略强化学习与场景化环境结合的框架。高层策略选择动作模板，由低层控制逻辑评估和执行。场景化环境可控制智能体的训练经验，并明确引入具有挑战性但低频的情境。实验表明，使用SAD-RL框架训练的智能体能在简单和复杂场景中高效实现安全行为。消融研究证实，分层学习和场景多样性是实现这些结果的关键。

</details>


### [505] [Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models](https://arxiv.org/abs/2506.23164)
**中文标题：模式坍塌现象：联合轨迹预测模型中关键交互的评估**

*Maarten Hugenholtz,Anna Meszaros,Jens Kober,Zlatan Ajanovic*

主要分类: cs.RO

摘要简述: 自动驾驶决策依赖多模态预测模型，但模型可能出现模式坍塌（仅预测最可能模式），带来安全风险。本文提出新评估框架，量化多智能体轨迹预测中的模式坍塌，强调安全关键交互。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态预测模型常忽视智能体间交互模式的多样性，且传统评估指标依赖数据集，未定量评估交互模式。本文旨在填补这一空白，提出新框架评估模式坍塌。

研究方法: 提出新评估框架，引入模式坍塌、模式正确性和覆盖率指标，重点关注预测的时序维度。测试四种多智能体轨迹预测模型，验证模式坍塌现象。

研究结果: 实验表明，模式坍塌确实存在。尽管接近交互事件时预测准确性提高，但模型仍可能无法预测正确交互模式，甚至在交互模式不可避免前仍失败。

研究结论: 本文框架为研究者提供新视角，有助于开发更一致、准确的预测模型，提升自动驾驶系统安全性。

中文摘要: 自动驾驶决策依赖多模态预测模型，需考虑多种路径选择和人类行为的不确定性。然而，模型可能出现模式坍塌，仅预测最可能模式，带来重大安全风险。现有方法虽采用多种策略生成多样化预测，但常忽视智能体间交互模式的多样性。此外，传统评估指标依赖数据集，未定量评估智能体间交互。据我们所知，现有指标均未明确评估模式坍塌。本文提出新评估框架，量化联合轨迹预测中的模式坍塌，重点关注安全关键交互。我们引入模式坍塌、模式正确性和覆盖率指标，强调预测的时序维度。通过测试四种多智能体轨迹预测模型，证明模式坍塌确实存在。在时序维度上，尽管接近交互事件时预测准确性提高，但模型仍可能无法预测正确交互模式，甚至在交互模式不可避免前仍失败。我们希望该框架能帮助研究者获得新见解，推动开发更一致、准确的预测模型，从而提升自动驾驶系统安全性。

</details>


### [506] [Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop](https://arxiv.org/abs/2506.23351)
**中文标题：基准化通用双臂操作：CVPR 2025 MEIS研讨会RoboTwin双臂协作挑战赛**

*Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yuchen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu*

主要分类: cs.RO

摘要简述: 本文介绍了CVPR 2025 MEIS研讨会上的RoboTwin双臂协作挑战赛，旨在推动双臂机器人系统在复杂任务中的通用性研究。比赛分为仿真和现实世界两阶段，吸引了64支团队参与，并展示了如SEM和AnchorDP3等优秀解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 随着具身人工智能的发展，单臂机器人系统已表现出较强的任务能力，但双臂协作系统在处理刚性、可变形和触觉敏感物体等复杂任务中更具优势。为推进这一领域的研究，RoboTwin双臂协作挑战赛应运而生。

研究方法: 比赛基于RoboTwin仿真平台和AgileX COBOT-Magic机器人平台，分为仿真阶段（两轮）和现实世界阶段。参与者需完成17项双臂操作任务，涵盖刚性、可变形和触觉敏感场景。

研究结果: 比赛吸引了64支全球团队和400多名参与者，涌现出SEM和AnchorDP3等优秀解决方案，为通用双臂策略学习提供了宝贵见解。

研究结论: 本次挑战赛为双臂机器人系统的通用性和鲁棒性研究提供了重要支持，并指明了未来研究方向。比赛详情可访问https://robotwin-benchmark.github.io/cvpr-2025-challenge/。

中文摘要: 具身人工智能（Embodied AI）是机器人学的新兴前沿领域，旨在开发能够在复杂物理环境中感知、推理和行动的自主系统。尽管单臂系统已表现出较强的任务能力，但双臂协作系统在处理涉及刚性、可变形和触觉敏感物体的复杂任务中更为关键。为此，我们在CVPR 2025第二届MEIS研讨会上发起了RoboTwin双臂协作挑战赛。比赛基于RoboTwin仿真平台（1.0和2.0）和AgileX COBOT-Magic机器人平台，分为仿真阶段（两轮）和现实世界阶段。参与者共完成了17项双臂操作任务，涵盖刚性、可变形和触觉敏感场景。比赛吸引了64支全球团队和400多名参与者，产生了如SEM和AnchorDP3等优秀解决方案，并为通用双臂策略学习提供了宝贵见解。本报告概述了比赛设置、任务设计、评估方法、关键发现及未来方向，旨在支持未来关于鲁棒和通用双臂操作策略的研究。比赛详情请访问https://robotwin-benchmark.github.io/cvpr-2025-challenge/。

</details>


### [507] [MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments](https://arxiv.org/abs/2506.23514)
**中文标题：MGPRL：基于Wi-Fi的多高斯过程分布式多机器人相对定位方法在大型室内环境中的应用**

*Sai Krishna Ghanta,Ramviyas Parasuraman*

主要分类: cs.RO

摘要简述: 本文提出了一种名为MGPRL的新型分布式框架，利用Wi-Fi信号强度和多高斯过程实现多机器人在大型室内环境中的相对定位，显著提升了定位精度和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 多机器人在无GPS环境中的相对定位通常依赖昂贵或短距离传感器（如摄像头和激光雷达），存在计算开销大和难以在分离环境中工作的局限性。本文旨在通过Wi-Fi信号解决这些问题。

研究方法: MGPRL采用多输出高斯过程预测Wi-Fi信号强度场，结合加权凸包对齐方法实现机器人间的相对位姿估计。每个机器人通过在线扫描AP预测信号场，并利用凸包对齐进行定位。

研究结果: 实验表明，MGPRL在定位精度和计算效率上优于现有方法，适用于资源有限的设备，且无需预校准或离线指纹库。

研究结论: MGPRL为多机器人在复杂室内环境中的相对定位提供了一种高效、鲁棒的解决方案，并开源为ROS包。

中文摘要: 相对定位是多机器人在无GPS环境中运行的关键能力。现有方法通常依赖昂贵或短距离传感器（如摄像头和激光雷达），面临计算开销大和分离环境中的挑战。为此，本文提出MGPRL，一种基于多Wi-Fi接入点（AP）凸包的分布式多机器人相对定位框架。我们采用共区域化多输出高斯过程高效预测信号强度场，并结合加权凸包对齐实现鲁棒的相对位姿估计。每个机器人通过在线扫描AP预测信号场，用于多AP位置估计。为实现相对定位，机器人将其预测的AP位置凸包与邻居机器人对齐。该方法适用于计算资源有限的设备，仅需广泛可用的Wi-Fi信号强度测量，无需预校准或离线指纹库。我们在ROS仿真和真实实验中验证了MGPRL的性能，并与多种先进方法对比。结果表明，MGPRL在定位精度和计算效率上优于现有方法。最后，我们将MGPRL开源为ROS包：https://github.com/herolab-uga/MGPRL。

</details>


### [508] [Online Human Action Detection during Escorting](https://arxiv.org/abs/2506.23573)
**中文标题：护送过程中在线人类动作检测**

*Siddhartha Mondal,Avik Mitra,Chayan Sarkar*

主要分类: cs.RO

摘要简述: 本文提出了一种新型神经网络架构，用于在拥挤环境中实时检测和预测被护送者的动作，并动态调整机器人速度，显著提升了护送服务的效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前护送机器人主要依赖导航策略，假设被护送者会顺利跟随，但在拥挤环境中，这种假设常失效，导致服务效果不佳。因此，需要一种能实时检测和解读人类动作并动态调整的解决方案。

研究方法: 提出了一种新型神经网络架构，能够同时完成人员重识别和动作预测任务，使机器人能根据被护送者的动作动态调整速度，并在中断后无缝恢复护送。

研究结果: 在对比评估中，该系统表现出卓越的效率和效果，显著提升了复杂现实场景中的机器人护送服务能力。

研究结论: 该系统通过实时动作检测和动态调整，有效解决了拥挤环境中护送机器人的局限性，为实际应用提供了重要技术支持。

中文摘要: 随着机器人助手在大型室内空间的广泛应用，护送任务成为关键应用之一。然而，当前大多数护送机器人主要依赖导航策略，假设被护送者会顺利跟随。在拥挤环境中，这种假设常因被护送者难以跟上、受阻、分心或突然停止而失效，导致传统机器人系统无法提供有效服务。为解决这一问题，有效的护送机器人需在护送过程中持续检测和解读人类动作，并相应调整其移动。然而，目前尚无专门针对护送场景的人类动作检测数据集。由于护送常发生在拥挤环境中，机器人还需在预测动作前识别特定被护送者（目标人物）。由于现有模型无法同时实时完成人员重识别和动作预测，本文提出了一种新型神经网络架构，可同时完成这两项任务，使机器人能根据被护送者的动作动态调整速度，并在中断后无缝恢复护送。在对比评估中，该系统表现出卓越的效率和效果，展示了其在复杂现实场景中显著提升机器人护送服务的潜力。

</details>


### [509] [PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?](https://arxiv.org/abs/2506.23725)
**中文标题：PAC Bench：基础模型是否理解执行操作策略的前提条件？**

*Atharva Gundawar,Som Sagar,Ransalu Senanayake*

主要分类: cs.RO

摘要简述: 本文介绍了PAC Bench，一个用于系统评估视觉语言模型（VLMs）对物理属性、功能性和约束条件理解能力的基准测试。研究发现当前VLMs在物理概念理解上存在显著不足，限制了其在机器人操作中的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管视觉语言模型（VLMs）在机器人操作任务中广泛应用，但其对低层次物理前提（如物体属性、功能性和约束条件）的理解能力尚未得到验证。这种能力的缺失可能影响机器人操作的可靠性。

研究方法: 作者提出了PAC Bench，一个包含30,000多个标注的多样化数据集，涵盖673张真实图像、100个人形视角场景和120个模拟约束场景，用于评估VLMs对物理属性、功能性和约束条件的理解。

研究结果: 评估显示，当前VLMs在理解基础物理概念方面存在显著不足，表明其在机器人操作任务中的适用性受限。

研究结论: PAC Bench为系统评估VLMs的物理推理能力提供了标准化基准，并指出了未来研究的关键方向，以开发更鲁棒、物理基础更强的模型。

中文摘要: 视觉语言模型（VLMs）在通用机器人操作中日益重要，能够执行物理推理、策略生成和故障检测等任务。然而，这些高级应用通常假设模型对低层次物理前提（如物体属性、功能性和约束条件）有深入理解，而这种能力尚未得到充分验证。为确保机器人可靠执行动作，必须理解物体的固有属性（如材质、重量）、动作可能性（如可抓取、可堆叠）和物理约束（如稳定性、可达性或物体状态，如是否关闭）。尽管VLMs在操作任务中广泛应用，我们认为现成模型可能缺乏这种细粒度的物理基础理解，因为这些前提在训练中常被忽略。

为解决这一关键问题，我们提出了PAC Bench，一个系统评估VLMs对核心属性、功能性和约束条件（PAC）理解的基准测试。PAC Bench包含一个多样化数据集，含30,000多个标注，涵盖673张真实图像（115个物体类别、15种属性类型，每类定义1至3种功能性）、100个真实人形视角场景和120个独特模拟约束场景，覆盖四项任务。

评估显示，当前VLMs在理解基础物理概念方面存在显著不足，揭示了其在可靠机器人操作中的局限性，并指出了针对性研究的关键领域。PAC Bench还为严格评估VLMs的物理推理能力提供了标准化基准，指导开发更鲁棒、物理基础更强的机器人应用模型。

项目页面：https://pacbench.github.io/

</details>


### [510] [Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving](https://arxiv.org/abs/2506.23771)
**中文标题：多时间尺度分层强化学习用于自动驾驶的统一行为与控制**

*Guizhe Jin,Zhuoren Li,Bo Leng,Ran Yu,Lu Xiong*

主要分类: cs.RO

摘要简述: 本文提出了一种多时间尺度分层强化学习方法，用于自动驾驶的统一行为与控制，通过高低层策略联合训练，显著提升了驾驶效率、动作一致性和安全性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于强化学习的自动驾驶方法大多忽视策略结构设计，仅输出短时间尺度控制命令或长时间尺度驾驶目标，导致驾驶行为波动或无法统一优化。

研究方法: 采用分层策略结构，高层和低层强化学习策略联合训练，分别生成长时间尺度运动指导和短时间尺度控制命令，并通过混合动作显式表示运动指导，设计分层安全机制确保多时间尺度安全性。

研究结果: 在仿真和HighD数据集的高速公路多车道场景中，该方法显著提升了自动驾驶性能，有效提高了驾驶效率、动作一致性和安全性。

研究结论: 多时间尺度分层强化学习方法能够有效统一自动驾驶的行为与控制，提升整体性能。

中文摘要: 强化学习（RL）在自动驾驶（AD）中的应用日益广泛，并显示出明显优势。然而，大多数基于RL的AD方法忽视了策略结构设计。仅输出短时间尺度车辆控制命令的RL策略会因网络输出的波动导致驾驶行为波动，而仅输出长时间尺度驾驶目标的策略无法实现驾驶行为与控制的统一优化。因此，我们提出了一种多时间尺度分层强化学习方法。该方法采用分层策略结构，其中高层和低层RL策略通过联合训练分别生成长时间尺度运动指导和短时间尺度控制命令。运动指导通过混合动作显式表示，以捕捉结构化道路上的多模态驾驶行为并支持低层增量状态更新。此外，还设计了分层安全机制以确保多时间尺度的安全性。在基于仿真和HighD数据集的高速公路多车道场景中的评估表明，该方法显著提升了AD性能，有效提高了驾驶效率、动作一致性和安全性。

</details>


### [511] [DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios](https://arxiv.org/abs/2506.22494)
**中文标题：DriveBLIP2：面向复杂驾驶场景的注意力引导解释生成**

*Shihong Ling,Yue Wan,Xiaowei Jia,Na Du*

主要分类: cs.RO

摘要简述: 本文提出DriveBLIP2框架，基于BLIP2-OPT架构，通过注意力机制生成复杂驾驶场景的精准解释，显著提升模型在实时自动驾驶中的解释能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉语言模型在复杂多目标环境中表现不佳，尤其在自动驾驶等实时应用中，快速识别关键对象至关重要。本文旨在通过注意力机制提升模型对关键对象的关注，生成更清晰的解释。

研究方法: 提出Attention Map Generator，在关键视频帧中突出与驾驶决策相关的重要对象，引导模型聚焦关键区域，生成更相关的解释。

研究结果: 在DRAMA数据集上的评估显示，DriveBLIP2在BLEU、ROUGE、CIDEr和SPICE等指标上显著优于基线模型，解释质量显著提升。

研究结论: 研究表明，针对性注意力机制可有效增强视觉语言模型在实时自动驾驶中的解释能力，为未来研究提供了重要方向。

中文摘要: 本文提出了一种新框架DriveBLIP2，基于BLIP2-OPT架构，旨在为新兴驾驶场景生成准确且上下文相关的解释。尽管现有视觉语言模型在一般任务中表现良好，但在复杂多目标环境（尤其是自动驾驶等实时应用）中仍面临困难，其中快速识别关键对象至关重要。为解决这一问题，本文提出了一种注意力图生成器，用于在关键视频帧中突出与驾驶决策相关的重要对象。通过引导模型关注这些关键区域，生成的注意力图有助于产生清晰且相关的解释，使驾驶员更好地理解车辆在关键情况下的决策过程。在DRAMA数据集上的评估表明，与基线模型相比，DriveBLIP2在BLEU、ROUGE、CIDEr和SPICE等指标上显著提升了解释质量。这些发现强调了针对性注意力机制在视觉语言模型中增强实时自动驾驶可解释性的潜力。

</details>


### [512] [Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning](https://arxiv.org/abs/2506.23944)
**中文标题：适应你的身体：缓解模仿学习中的本体感觉偏移**

*Fuhang Kuang,Jiacheng You,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

主要分类: cs.RO

摘要简述: 本文提出了一种解决模仿学习中本体感觉偏移问题的方法，通过域适应框架和Wasserstein距离对齐训练与部署分布，提升机器人任务的模仿学习性能。


<details>
  <summary>详细信息</summary>
研究动机: 模仿学习在机器人任务中通常依赖多模态输入（如RGB图像、语言和本体感觉状态），但直接使用所有本体感觉状态会导致性能下降。研究发现这是由于训练与部署时本体感觉状态分布不一致（即本体感觉偏移问题）。

研究方法: 提出一种域适应框架，利用部署时收集的滚动数据，通过Wasserstein距离量化专家与滚动本体感觉状态的差异，并添加与距离成比例的噪声以最小化分布差距。

研究结果: 实验表明，该方法在机器人操作任务中有效提升了模仿策略的性能，优于直接丢弃本体感觉或其他处理分布偏移的基线方法。

研究结论: 通过域适应框架和Wasserstein距离对齐分布，该方法成功解决了本体感觉偏移问题，使模仿学习能够充分利用本体感觉信息。

中文摘要: 模仿学习模型在机器人任务中通常依赖多模态输入，如RGB图像、语言和本体感觉状态。尽管本体感觉对决策和避障至关重要，但直接使用所有本体感觉状态会导致模仿学习性能意外下降。本文发现其根本问题在于本体感觉偏移，即训练与部署时的本体感觉状态分布存在显著差异。为解决这一问题，我们提出了一种域适应框架，利用部署时收集的滚动数据，通过Wasserstein距离量化专家与滚动本体感觉状态的差异，并添加与距离成比例的噪声以最小化分布差距。这一策略通过对齐训练与部署分布，增强了对抗本体感觉偏移的鲁棒性。在机器人操作任务上的实验证明了该方法的有效性，使模仿策略能够利用本体感觉同时减轻其负面影响。我们的方法优于直接丢弃本体感觉或其他处理分布偏移的基线方法。

</details>


### [513] [InfGen: Scenario Generation as Next Token Group Prediction](https://arxiv.org/abs/2506.23316)
**中文标题：InfGen：基于下一令牌组预测的场景生成方法**

*Zhenghao Peng,Yuxin Liu,Bolei Zhou*

主要分类: cs.RO

摘要简述: InfGen是一种基于自回归方法的交通场景生成框架，通过将场景表示为令牌序列并使用Transformer模型模拟动态交通行为，支持无限场景生成，生成的结果具有高真实性和多样性，适用于自动驾驶系统的训练和评估。


<details>
  <summary>详细信息</summary>
研究动机: 现有的数据驱动交通模拟方法多依赖静态初始化或日志回放数据，难以模拟动态、长时程且包含动态新增代理的场景。因此，需要一种能够生成真实、多样且适应性强的交通行为的方法。

研究方法: InfGen将整个交通场景表示为令牌序列（包括交通信号灯状态、代理状态和运动向量），并利用Transformer模型以自回归方式生成代理状态和轨迹。这种设计支持动态插入新代理，实现无限场景生成。

研究结果: 实验表明，InfGen生成的交通行为具有高真实性和多样性。在InfGen生成的场景中训练的强化学习策略表现出更强的鲁棒性和泛化能力，验证了其作为高保真自动驾驶模拟环境的实用性。

研究结论: InfGen通过自回归令牌序列生成方法，成功实现了动态、长时程交通场景的模拟，为自动驾驶系统的训练和评估提供了高效且真实的模拟环境。

中文摘要: 真实且交互式的交通模拟对于训练和评估自动驾驶系统至关重要。然而，现有的大多数数据驱动模拟方法依赖于静态初始化或日志回放数据，限制了其模拟动态、长时程且代理数量变化的场景的能力。我们提出了InfGen，一种以自回归方式输出代理状态和轨迹的场景生成框架。InfGen将整个场景表示为令牌序列，包括交通信号灯状态、代理状态和运动向量，并使用Transformer模型随时间模拟交通行为。这种设计使InfGen能够持续向交通中插入新代理，支持无限场景生成。实验表明，InfGen生成的交通行为具有真实性、多样性和适应性。此外，在InfGen生成的场景中训练的强化学习策略表现出更强的鲁棒性和泛化能力，验证了其作为高保真自动驾驶模拟环境的实用性。更多信息请访问https://metadriverse.github.io/infgen/。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [514] [Exploring Artificial Intelligence Tutor Teammate Adaptability to Harness Discovery Curiosity and Promote Learning in the Context of Interactive Molecular Dynamics](https://arxiv.org/abs/2506.22520)
**中文标题：探索人工智能导师队友的适应性以激发发现好奇心并促进交互式分子动力学中的学习**

*Mustafa Demir,Jacob Miratsky,Jonathan Nguyen,Chun Kit Chan,Punya Mishra,Abhishek Singharoy*

主要分类: cs.HC

摘要简述: 本研究探讨了人工智能导师队友（AI）在交互式分子动力学（IMD）任务中对学生好奇心驱动参与和学习效果的影响，发现AI的好奇心触发和响应行为能显著提升学生的提问频率和复杂性，促进团队表现。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索AI导师队友如何通过激发和维持学生的好奇心，提升其在IMD任务中的学习效果和团队表现，从而验证AI在教育环境中的适应性潜力。

研究方法: 采用混合方法探索性设计，11名高中生参与四项复杂度递增的IMD任务。通过“绿野仙踪”范式，实验者动态调整AI行为，利用大语言模型实现AI响应。团队表现通过实时观察和录音评估，团队沟通通过问题复杂度和AI行为衡量。

研究结果: 高绩效团队表现出更好的任务完成度、更深的理解和更高的参与度。高级问题与AI好奇心触发相关，表明更高的认知复杂性。CRQA指标显示学生与AI互动中的动态同步，强调结构化且适应性强的参与。

研究结论: AI作为队友和教育者的双重角色表明其能提供适应性反馈，维持参与度和认知好奇心，为AI在教育中的应用提供了概念验证。

中文摘要: 本研究探讨了人工智能导师队友（AI）在Visual Molecular Dynamics平台上进行交互式分子动力学（IMD）任务时对学生好奇心驱动参与和学习效果的影响。研究探索了AI的好奇心触发和响应行为在激发和维持学生好奇心方面的作用，以及其对学生提问频率和复杂性的影响。研究进一步评估了AI干预如何塑造学生参与、促进发现好奇心并提升IMD学习环境中的团队表现。通过“绿野仙踪”范式，实验者利用大语言模型动态调整AI导师队友的行为。采用混合方法探索性设计，11名高中生参与了四项涉及分子可视化和计算的IMD任务，任务复杂度在60分钟内递增。团队表现通过实时观察和录音评估，团队沟通通过问题复杂度和AI行为衡量。交叉递归量化分析（CRQA）指标反映了协调中的结构对齐，并与沟通行为相关联。高绩效团队表现出更好的任务完成度、更深的理解和更高的参与度。高级问题与AI好奇心触发相关，表明更高的认知复杂性和参与度。CRQA指标突出了学生与AI互动中的动态同步，强调结构化且适应性强的参与以促进好奇心。这些概念验证结果表明，AI作为队友和教育者的双重角色表明其能提供适应性反馈，维持参与度和认知好奇心。

</details>


### [515] [Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions](https://arxiv.org/abs/2506.22941)
**中文标题：定位AI工具以支持在线减害实践：应用与设计方向**

*Kaixuan Wang,Jason T. Jacques,Chenxin Diao*

主要分类: cs.HC

摘要简述: 本文探讨如何利用大型语言模型（LLM）为吸毒者提供精准、无偏见的信息支持，通过多利益相关方研讨会，提出设计方向以克服伦理和技术挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有在线渠道难以满足吸毒者多样且动态的信息需求，LLM提供了新的解决方案，但其在高风险领域的应用尚未充分探索。

研究方法: 通过定性研讨会，汇集学者、减害实践者和社区管理者，探讨LLM的潜力、用例和核心设计考量。

研究结果: LLM能解决部分信息障碍（如多语言、低污名化互动），但需解决伦理对齐、上下文理解和明确边界等挑战。

研究结论: 强调与专家和吸毒者协作设计，开发安全、有效的LLM工具，为减害领域提供支持。

中文摘要: 获取准确且可操作的减害信息直接影响吸毒者的健康结果，但现有在线渠道因适应性、可及性和污名化等问题难以满足其需求。大型语言模型（LLM）为增强信息提供提供了新机遇，但其在这一高风险领域的应用尚未充分探索并存在社会技术挑战。本文研究如何负责任地设计LLM以支持吸毒者的信息需求。通过定性研讨会（参与者包括学者、减害实践者和社区管理者），我们探讨了LLM的能力、潜在用例和核心设计考量。研究发现，LLM虽能解决部分信息障碍（如提供响应式、多语言和低污名化互动），但其有效性取决于能否克服与减害原则的伦理对齐、细致上下文理解、有效沟通和明确操作边界等挑战。我们提出了强调与专家和吸毒者协作设计的设计路径，以开发有用、安全且负责任的LLM系统。本研究为LLM在减害生态中的负责任发展提供了实证基础和可操作的设计考量。

</details>


### [516] [Against 'softmaxing' culture](https://arxiv.org/abs/2506.22968)
**中文标题：反对“softmaxing”文化**

*Daniel Mwesigwa*

主要分类: cs.HC

摘要简述: AI正在使文化趋同化，作者提出“softmaxing文化”现象，并呼吁改进文化评估方法，以应对AI模型对语言和文化的同质化影响。


<details>
  <summary>详细信息</summary>
研究动机: AI模型在评估文化时表现出同质化趋势，导致语言和文化的多样性被削弱。作者认为当前机器学习和人机交互的评估方法存在局限，需要新的视角来应对文化复杂性。

研究方法: 作者提出两个关键转变：1）将评估问题从“什么是文化？”改为“文化何时出现？”；2）将文化普遍性与具体情境结合，而非简单描述。

研究结果: 通过重新定义文化评估的起点和方法，作者为AI系统的文化对齐提供了更具响应性的视角。

研究结论: 作者呼吁超越技术需求，采用更复杂的文化评估方法，以应对AI对文化多样性的挑战。

中文摘要: AI正在使文化趋同化。对“文化”的评估显示，大型AI模型正在将丰富的语言差异平均化为通用表达，作者称这种现象为“softmaxing文化”，这是当前AI评估面临的根本挑战之一。改进和加强文化评估的努力是大型AI系统文化对齐的核心。本文认为，机器学习（ML）和人机交互（HCI）的评估方法存在局限。作者提出两个关键转变：首先，在系统评估开始时，不再问“什么是文化？”，而是问“文化何时出现？”；其次，尽管作者承认文化普遍性的哲学主张，但挑战不仅在于描述它们，还在于将其与具体情境联系起来。这些概念转变共同推动了超越技术需求的评估方法，转向更能响应文化复杂性的视角。

</details>


### [517] [Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models](https://arxiv.org/abs/2506.23678)
**中文标题：交互式推理：可视化与控制大语言模型中的思维链推理**

*Rock Yuren Pang,K. J. Kevin Feng,Shangbin Feng,Chu Li,Weijia Shi,Yulia Tsvetkov,Jeffrey Heer,Katharina Reinecke*

主要分类: cs.HC

摘要简述: 该论文提出了一种名为“交互式推理”的设计，通过可视化大语言模型（LLM）的思维链（CoT）输出并允许用户修改，从而提升模型输出的质量和可控性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）通过生成思维链（CoT）内容来提升输出质量，但这些内容冗长且缺乏组织，难以审查，同时缺乏用户反馈的机会。

研究方法: 论文提出“交互式推理”设计，将思维链输出可视化为层次化主题，并允许用户审查和修改。通过原型工具Hippo实现这一设计。

研究结果: 用户研究表明，交互式推理能帮助用户快速识别和中断错误生成，高效引导模型生成定制化响应，并更好地理解模型推理和输出。

研究结论: 该研究为将用户监督纳入LLM推理过程提供了新范式。

中文摘要: 大语言模型（LLM）的输出质量可以通过“推理”提升：生成思维链（CoT）内容以进一步调整模型，再生成面向用户的输出。然而，这些思维链内容冗长且缺乏明确组织，审查起来繁琐。此外，它们缺乏用户反馈的机会，例如删除不需要的考虑、添加期望的内容或澄清模糊假设。我们提出了“交互式推理”，一种将思维链输出可视化为层次化主题并支持用户审查和修改的交互设计。我们在Hippo原型中实现了交互式推理，用于在不确定权衡下进行AI辅助决策。一项16名参与者参与的用户研究表明，Hippo中的交互式推理使用户能够快速识别并中断错误生成，高效引导模型生成定制化响应，并更好地理解模型推理和输出。我们的工作为将用户监督纳入LLM推理过程提供了新范式。

</details>


### [518] [The Impact of AI on Educational Assessment: A Framework for Constructive Alignment](https://arxiv.org/abs/2506.23815)
**中文标题：人工智能对教育评估的影响：建构性对齐框架**

*Patrick Stokkink*

主要分类: cs.HC

摘要简述: 本文探讨了人工智能（AI）对教育评估的影响，提出了基于建构性对齐理论和布鲁姆分类法的框架，强调评估需根据AI对不同学习目标的影响进行调整，并建议通过结构化指南和教师培训减少偏见。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI（尤其是大型语言模型）在教育中的广泛应用，现有评估方式是否仍能有效衡量学生表现和理解成为问题。本文旨在探讨AI如何影响不同布鲁姆层次的学习目标，并提出评估方法的调整建议。

研究方法: 基于建构性对齐理论和布鲁姆分类法，本文分析了AI对不同学习目标的影响，并提出了评估方法的调整策略。同时，通过调查教师对AI的态度，揭示了其偏见来源。

研究结果: 研究发现，AI对不同布鲁姆层次的学习目标影响各异，评估方法需相应调整。此外，教师对AI的熟悉程度影响其评估态度，需通过结构化指南和培训减少偏见。

研究结论: 本文强调教育评估需适应AI的影响，提出通过统一指南和教师培训实现评估方法的优化，以确保公平性和有效性。

中文摘要: 人工智能（AI），尤其是大型语言模型（LLM）对教育的影响日益显著。学生频繁使用这些模型，引发了对当前评估方式是否仍能有效衡量学生表现和理解的质疑。本文基于建构性对齐（CA）理论和布鲁姆分类法，提出了一个理论框架。我们认为，AI对不同布鲁姆层次的学习目标影响各异，评估方法需相应调整。此外，根据布鲁姆的观点，形成性和总结性评估需在是否允许使用AI上保持一致。尽管教师普遍认为教育和评估需适应AI的存在，但其对AI在评估中的允许程度存在明显偏见，这源于教师对AI的熟悉程度及自身使用情况。为避免这种偏见，我们建议在大学或院系层面制定结构化指南，促进教师间的对齐。此外，教师需接受关于AI工具能力和局限性的培训，以便更好地调整评估方法。

</details>


### [519] [Deep Learning in Mild Cognitive Impairment Diagnosis using Eye Movements and Image Content in Visual Memory Tasks](https://arxiv.org/abs/2506.23016)
**中文标题：基于眼动和视觉记忆任务图像内容的深度学习在轻度认知障碍诊断中的应用**

*Tomás Silva Santos Rocha,Anastasiia Mikhailova,Moreno I. Coco,José Santos-Victor*

主要分类: cs.HC

摘要简述: 本研究利用深度学习模型（VTNet）结合眼动追踪数据和视觉记忆任务，区分健康对照组（HC）和轻度认知障碍（MCI），模型表现与阿尔茨海默病研究相当，为MCI自动化诊断工具开发提供了新思路。


<details>
  <summary>详细信息</summary>
研究动机: 全球痴呆症患病率预计到2050年将翻倍，亟需可扩展的诊断工具。本研究旨在通过结合眼动追踪数据和视觉记忆任务，开发一种区分HC和MCI的自动化方法。

研究方法: 研究基于VTNet深度学习模型，利用44名参与者（24名MCI，20名HC）的眼动追踪数据，结合时间序列和空间数据（如扫描路径、热图和图像内容），测试不同参数（如图像分辨率）对模型性能的影响。

研究结果: 最佳模型使用700×700像素分辨率热图，达到68%的敏感性和76%的特异性，表现与类似阿尔茨海默病研究相当（70%敏感性和73%特异性）。

研究结论: 研究为MCI自动化诊断工具开发提供了支持，未来需优化模型并使用标准化长期视觉记忆任务。

中文摘要: 全球痴呆症患病率预计到2050年将翻倍，凸显了对可扩展诊断工具的迫切需求。本研究利用结合眼动追踪数据的数字认知任务，区分健康对照组（HC）和轻度认知障碍（MCI）。基于VTNet的深度学习模型使用44名参与者（24名MCI，20名HC）在视觉记忆任务中的眼动数据，结合时间序列和空间数据（如扫描路径、热图和图像内容）。模型还测试了图像分辨率和任务表现等参数对性能的影响。最佳模型使用700×700像素分辨率热图，达到68%的敏感性和76%的特异性，表现与类似阿尔茨海默病研究相当（70%敏感性和73%特异性）。这些发现为MCI自动化诊断工具开发提供了支持，未来需优化模型并使用标准化长期视觉记忆任务。

</details>


### [520] [Autonomy by Design: Preserving Human Autonomy in AI Decision-Support](https://arxiv.org/abs/2506.23952)
**中文标题：设计自主性：在AI决策支持中保护人类自主性**

*Stefan Buijsman,Sarah Carter,Juan Pablo Bermúdez*

主要分类: cs.HC

摘要简述: 本文探讨了AI决策支持系统如何影响领域特定自主性，提出了一种保护人类自主性的设计框架。


<details>
  <summary>详细信息</summary>
研究动机: 研究AI系统在专业、技能和个人活动中对人类自主性的影响，尤其是领域特定自主性（如技能能力和真实价值形成）的未被充分研究的方面。

研究方法: 通过分析医学、金融和教育领域的实证案例，结合先前研究，探讨AI系统如何侵蚀领域特定自主性，并提出保护自主性的设计模式。

研究结果: 研究发现缺乏可靠的失败指标和无意识的价值转变会损害领域特定自主性，并提出包括角色明确、防御机制和反思实践在内的设计框架。

研究结论: 本文提出的框架为开发增强而非削弱人类自主性的AI系统提供了具体指导。

中文摘要: AI系统日益支持人类在专业、技能和个人活动中的决策。尽管先前研究探讨了AI如何影响全球人类自主性，但AI对领域特定自主性（即在特定技能或专业领域内的自我管理能力）的影响仍未充分研究。我们分析了AI决策支持系统如何影响领域特定自主性的两个关键组成部分：技能能力（在领域内做出明智判断的能力）和真实价值形成（形成真实领域相关价值观和偏好的能力）。通过结合先前研究和分析医学、金融和教育领域的实证案例，我们展示了缺乏可靠的失败指标和无意识的价值转变如何立即和长期侵蚀领域特定自主性。随后，我们开发了一个保护自主性的AI支持系统框架，提出了具体的社会技术设计模式（包括明确角色、实施防御机制和支持反思实践），以在利用AI能力的同时维护领域特定自主性。该框架为开发增强而非削弱人类在专业领域内自主性的AI系统提供了具体指导。

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [521] [GaussMaster: An LLM-based Database Copilot System](https://arxiv.org/abs/2506.23322)
**中文标题：GaussMaster：基于LLM的数据库助手系统**

*Wei Zhou,Ji Sun,Xuanhe Zhou,Guoliang Li,Luyang Liu,Hao Wu,Tianyuan Wang*

主要分类: cs.DB

摘要简述: GaussMaster是一个基于LLM的数据库助手系统，旨在通过自动化解决SQL优化、异常检测和数据库维护等问题，减少DBA的工作负担，已在银行业实现34种场景的零人工干预。


<details>
  <summary>详细信息</summary>
研究动机: 金融行业中，数据库管理员（DBA）承担着繁重的SQL优化、部署和故障修复任务。现有自治数据库平台能力有限，仍需人工干预。GaussMaster旨在通过LLM技术实现全面的数据库自动化维护。

研究方法: GaussMaster利用LLM技术，通过分析数百项指标和日志，采用Tree-of-thought方法定位问题根源，并调用工具解决问题，实现从SQL编写到数据库维护的全流程自动化。

研究结果: GaussMaster在银行业成功应用，实现了34种数据库维护场景的零人工干预，显著提升了任务效率。

研究结论: GaussMaster通过LLM技术实现了数据库维护的全面自动化，为金融行业提供了高效的解决方案，未来有望进一步扩展应用场景。

中文摘要: 在金融行业，数据是运营的核心，数据库管理员（DBA）承担着SQL优化、数据库部署、诊断和服务修复等重要职责。近年来，数据库供应商和客户越来越多地转向自治数据库平台，以减轻DBA的繁重工作。然而，现有自治数据库平台功能有限，主要解决单点问题，如自然语言转SQL（NL2SQL）、异常检测和SQL优化，全面数据库维护仍需人工干预。GaussMaster旨在通过引入基于LLM的数据库助手系统改变这一现状。这一创新解决方案不仅帮助开发者编写高效SQL查询，还为数据库服务提供全面支持。当数据库实例出现异常行为时，GaussMaster能够自动协调整个维护流程，通过分析数百项指标和日志，采用Tree-of-thought方法定位问题根源，并调用适当工具解决问题。我们已在银行业等实际场景中成功部署GaussMaster，实现了34种数据库维护场景的零人工干预。本文展示了这些任务的显著改进，代码见https://gitcode.com/opengauss/openGauss-GaussMaster。

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [522] [Deep Learning for Optical Misalignment Diagnostics in Multi-Lens Imaging Systems](https://arxiv.org/abs/2506.23173)
**中文标题：深度学习在多透镜成像系统光学对准偏差诊断中的应用**

*Tomer Slor,Dean Oren,Shira Baneth,Tom Coen,Haim Suchowski*

主要分类: physics.optics

摘要简述: 本文提出两种基于深度学习的逆设计方法，用于诊断多透镜成像系统中的光学对准偏差，仅需光学测量即可实现高精度诊断。


<details>
  <summary>详细信息</summary>
研究动机: 多透镜成像系统的精确对准对光学工程至关重要，但传统方法依赖专用设备且耗时，亟需自动化、可扩展的解决方案。

研究方法: 采用两种互补的深度学习逆设计方法：1) 利用光线追踪光斑图预测6透镜系统的5自由度误差；2) 基于物理模拟的灰度合成相机图像，估计2透镜和6透镜系统的4自由度偏差。

研究结果: 在6透镜系统中，横向平移误差均值为0.031mm，倾斜误差为0.011°；物理模拟方法在2透镜和6透镜系统中均能有效估计偏差。

研究结论: 深度学习方法为多透镜系统的制造和质量控制提供了高效、精准的解决方案，有望重塑精密成像领域。

中文摘要: 在快速发展的光学工程领域，多透镜成像系统的精确对准至关重要，但微小偏差即可显著降低性能。传统对准方法依赖专用设备且耗时，亟需自动化、可扩展的解决方案。我们提出两种互补的基于深度学习的逆设计方法，仅通过光学测量即可诊断多透镜系统的对准偏差。首先，利用光线追踪光斑图预测6透镜摄影镜头的5自由度误差，横向平移误差均值为0.031mm，倾斜误差为0.011°。此外，引入基于物理模拟的灰度合成相机图像，使深度学习模型能够估计2透镜和6透镜系统的4自由度偏差（偏心与倾斜）。这些结果表明，该方法有望重塑精密成像的制造与质量控制。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [523] [Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling](https://arxiv.org/abs/2504.15071)
**中文标题：Aria-MIDI：用于符号音乐建模的钢琴MIDI文件数据集**

*Louis Bradshaw,Simon Colton*

主要分类: cs.SD

摘要简述: 本文介绍了一个名为Aria-MIDI的新数据集，包含超过100万份钢琴MIDI文件，通过多阶段数据处理流程从互联网音频转录而来。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决符号音乐建模领域缺乏大规模、高质量MIDI数据集的问题，作者创建了一个丰富的钢琴MIDI数据集。

研究方法: 采用多阶段数据处理流程，包括语言模型自动爬取和评分音频文件，音频分类器进行修剪和分段，最终生成MIDI文件。

研究结果: 数据集包含超过100万份MIDI文件，约10万小时的转录音频，并提供了详细的统计分析和元数据标签。

研究结论: Aria-MIDI数据集为符号音乐建模提供了丰富的资源，其多阶段处理流程和元数据支持为未来研究提供了便利。

中文摘要: 我们引入了一个广泛的新MIDI文件数据集，通过将钢琴演奏的音频录音转录为其组成的音符而创建。我们使用的数据处理流程是多阶段的，采用语言模型基于元数据自主爬取和评分互联网上的音频录音，随后通过音频分类器进行修剪和分段。最终的数据集包含超过100万份不同的MIDI文件，约10万小时的转录音频。我们提供了对技术的深入分析，包括统计洞察，并通过提取元数据标签对内容进行了调查，这些标签也一并提供。数据集可在https://github.com/loubbrad/aria-midi获取。

</details>


### [524] [You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties](https://arxiv.org/abs/2506.23367)
**中文标题：你听起来有点紧张：基于时长元音特性的L2定制清晰TTS**

*Paige Tuttösí,H. Henny Yeung,Yue Wang,Jean-Julien Aucouturier,Angelica Lim*

主要分类: cs.SD

摘要简述: 本文提出首个针对第二语言（L2）学习者的文本转语音（TTS）系统，通过调整英语元音的时长差异（紧张元音更长，松弛元音更短）设计了一种“清晰模式”。实验表明，法语母语的英语L2学习者在清晰模式下转录错误减少至少9.15%，且认为该模式比整体减速更鼓舞人心和尊重人。然而，学习者并未意识到清晰模式的实际效果，仍误以为整体减速更易理解。此外，Whisper-ASR未能利用与L2学习者相同的线索区分难元音，不适合评估TTS系统对L2学习者的可懂度。


<details>
  <summary>详细信息</summary>
研究动机: 第二语言（L2）学习者在理解英语语音时面临挑战，尤其是元音的时长差异（紧张与松弛元音）。现有的TTS系统未针对L2学习者优化，且整体减速虽能提高可懂度但缺乏针对性。本文旨在设计一种基于元音时长差异的TTS清晰模式，以更有效地帮助L2学习者理解英语。

研究方法: 利用美国英语中紧张元音（较长）和松弛元音（较短）的时长差异，在Matcha-TTS系统中设计了一种“清晰模式”。通过感知实验，比较法语母语的英语L2学习者在清晰模式和整体减速模式下的转录错误率和主观评价。同时，分析了Whisper-ASR在区分难元音时的表现。

研究结果: 清晰模式下，法语母语的英语L2学习者的转录错误率减少至少9.15%，且认为该模式比整体减速更鼓舞人心和尊重人。然而，学习者并未意识到清晰模式的实际效果，仍误以为整体减速更易理解。Whisper-ASR未能利用与L2学习者相同的线索区分难元音。

研究结论: 针对L2学习者的TTS清晰模式通过调整元音时长显著提高了可懂度，但学习者对其效果缺乏认知。Whisper-ASR不适合评估TTS系统对L2学习者的可懂度，未来需开发更适配的评估工具。

中文摘要: 我们提出了首个针对第二语言（L2）学习者的文本转语音（TTS）系统。通过利用美国英语中紧张（较长）和松弛（较短）元音的时长差异，我们在Matcha-TTS中设计了一种“清晰模式”。感知实验表明，法语母语的英语L2学习者在清晰模式下的转录错误减少了至少9.15%，且认为该模式比整体减速的语音更鼓舞人心和尊重人。值得注意的是，学习者并未意识到这些效果：尽管清晰模式下的单词错误率降低，他们仍认为整体减速的目标单词最易理解，表明实际可懂度与感知可懂度无关。此外，我们发现Whisper-ASR未使用与L2学习者相同的线索区分难元音，因此不足以评估TTS系统对这些学习者的可懂度。

</details>


### [525] [Efficient Interleaved Speech Modeling through Knowledge Distillation](https://arxiv.org/abs/2506.23670)
**中文标题：通过知识蒸馏实现高效交错语音建模**

*Mohammadmahdi Nouriborji,Morteza Rohanian*

主要分类: cs.SD

摘要简述: 当前语音语言模型在许多部署环境中受到大小和延迟限制。本文通过层对齐蒸馏技术构建紧凑且表达能力强的语音生成模型，将大型多模态Transformer压缩3倍，性能损失极小。提出的TinyWave模型家族（2B参数）支持语音到语音和混合语音-文本生成，在公共音频数据上训练，性能接近教师模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有语音语言模型因体积和延迟问题难以在资源受限环境中部署，亟需开发紧凑且高效的语音生成模型。

研究方法: 采用层对齐蒸馏技术，匹配隐藏状态、注意力图和软化逻辑，将大型多模态Transformer压缩3倍。训练TinyWave模型家族（2B参数），支持语音生成和混合语音-文本生成。

研究结果: TinyWave在Libri-Light上的表现仅比教师模型低1.4个归一化困惑度点，在StoryCloze和SALMon任务中准确率达到教师模型的93-97%，优于同规模基线模型。

研究结论: TinyWave模型在紧凑性和性能上取得平衡，适用于实时对话代理、辅助技术和低资源环境。模型、训练代码和评估脚本已开源。

中文摘要: 当前语音语言模型在许多部署环境中受到大小和延迟限制。我们通过层对齐蒸馏技术构建紧凑且表达能力强的语音生成模型，匹配隐藏状态、注意力图和软化逻辑，将大型多模态Transformer压缩3倍，性能损失极小。我们提出TinyWave模型家族（2B参数），用于语音到语音和混合语音-文本生成，训练数据为50,000小时公共音频。TinyWave支持（i）仅语音生成（使用音素或表达性标记）和（ii）混合语音-文本延续。在Libri-Light上的评估显示，TinyWave的归一化困惑度仅比教师模型高1.4点。在StoryCloze和SALMon任务中，准确率达到教师模型的93-97%，优于同规模基线模型。这些模型针对商用硬件部署优化，适用于实时对话代理、辅助技术和低资源环境。我们开源模型、训练代码和评估脚本，以支持紧凑且表达能力强的语音生成的可复现研究。

</details>


### [526] [WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing](https://arxiv.org/abs/2506.22789)
**中文标题：WavShape：面向公平和隐私感知音频处理的信息论语音表示学习**

*Oguzhan Baser,Ahmet Ege Tanriverdi,Kaan Kale,Sandeep P. Chinchali,Sriram Vishwanath*

主要分类: cs.SD

摘要简述: WavShape是一种基于信息论的语音表示学习框架，旨在优化嵌入以实现公平性和隐私保护，同时保留任务相关信息。


<details>
  <summary>详细信息</summary>
研究动机: 语音嵌入通常包含敏感信息（如说话者身份、口音或人口统计信息），可能导致模型训练偏见和隐私泄露。本文旨在解决这一问题。

研究方法: 利用Donsker-Varadhan公式的互信息估计方法，指导基于互信息的编码器，系统性地过滤敏感属性，同时保留对下游任务重要的语音内容。

研究结果: 在三个已知数据集上的实验表明，WavShape将嵌入与敏感属性之间的互信息减少了81%，同时保留了97%的任务相关信息。

研究结论: 通过将信息论与自监督语音模型结合，WavShape推动了公平、隐私保护和资源高效的语音系统的发展。

中文摘要: 语音嵌入通常保留敏感属性（如说话者身份、口音或人口统计信息），在偏见模型训练和隐私泄露方面带来风险。我们提出了WavShape，这是一种信息论的语音表示学习框架，旨在优化嵌入以实现公平性和隐私保护，同时保留任务相关信息。我们利用Donsker-Varadhan公式的互信息估计方法，指导基于互信息的编码器，系统性地过滤敏感属性，同时保留对下游任务重要的语音内容。在三个已知数据集上的实验结果表明，WavShape将嵌入与敏感属性之间的互信息减少了81%，同时保留了97%的任务相关信息。通过将信息论与自监督语音模型结合，这项工作推动了公平、隐私保护和资源高效的语音系统的发展。

</details>


### [527] [TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure](https://arxiv.org/abs/2506.23094)
**中文标题：TOMI：通过全曲结构转换和组织多轨音乐创意**

*Qi He,Gus Xia,Ziyu Wang*

主要分类: cs.SD

摘要简述: 本文提出TOMI方法，通过层次化规划和概念层次生成、转换和组织音乐创意，结合指令调优的大语言模型，生成具有完整歌曲结构的多轨电子音乐，并实现人机交互创作。


<details>
  <summary>详细信息</summary>
研究动机: 音乐创作中的层次化规划不仅涉及时间结构，还包括概念层次（如音乐创意的生成与组织）。本文旨在探索这一更高层次的规划方法，以生成结构完整且高质量的多轨音乐。

研究方法: 提出TOMI方法，通过四维稀疏空间（片段、段落、音轨和转换）表示多轨音乐创作过程，并基于指令调优的大语言模型实现音乐生成。模型与REAPER音频工作站集成，支持人机交互创作。

研究结果: 实验表明，TOMI方法生成的多轨电子音乐在质量和结构连贯性上优于基线方法。

研究结论: TOMI方法通过层次化规划和概念层次生成，显著提升了多轨音乐的结构完整性和创作效率，为人机协作音乐创作提供了新思路。

中文摘要: 层次化规划是一种强大的建模长序列结构的方法。除了考虑音乐时间结构的层次性，本文进一步探索了更重要的概念层次，包括音乐创意的生成、转换以及跨时间和空间的最终组织成完整作品。为此，我们提出了TOMI（转换和组织音乐创意）作为深度音乐生成的新方法，并通过指令调优的大语言模型开发了基于TOMI的模型。形式上，我们通过片段（短音频或MIDI段落）、段落（时间位置）、音轨（乐器层）和转换（细化方法）构成的稀疏四维空间表示多轨音乐创作过程。我们的模型能够生成具有完整歌曲结构的多轨电子音乐，并进一步将TOMI模型与REAPER数字音频工作站集成，实现人机交互创作。实验结果表明，与基线方法相比，我们的方法生成了质量更高且结构更连贯的电子音乐。

</details>


### [528] [XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs](https://arxiv.org/abs/2506.23325)
**中文标题：XY-Tokenizer：缓解低比特率语音编解码中的语义-声学冲突**

*Yitian Gong,Luozhijie Jin,Ruifan Deng,Dong Zhang,Xin Zhang,Qinyuan Cheng,Zhaoye Fei,Shimin Li,Xipeng Qiu*

主要分类: cs.SD

摘要简述: XY-Tokenizer是一种新型语音编解码器，通过多阶段多任务学习平衡语义丰富性和声学保真度，在低比特率下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有语音编解码器难以同时满足高质量音频重建和语言模型建模的需求，XY-Tokenizer旨在解决语义与声学能力之间的冲突。

研究方法: XY-Tokenizer采用多阶段多任务学习方法，兼顾语义和声学任务，优化编解码器的性能。

研究结果: 实验表明，XY-Tokenizer在语义和声学任务上均表现优异，文本对齐能力超越SpeechTokenizer和Mimi，声学重建性能接近BigCodec。

研究结论: XY-Tokenizer成功平衡了语义和声学需求，为低比特率语音编解码提供了高效解决方案。

中文摘要: 语音编解码器是语音信号与大型语言模型之间的桥梁。理想的语音编解码器不仅应保留声学信息，还需捕捉丰富的语义信息。然而，现有编解码器难以在高质量音频重建与语言模型建模之间取得平衡。本研究分析了以往编解码器在平衡语义丰富性和声学保真度方面的局限性，并提出XY-Tokenizer，一种通过多阶段多任务学习缓解语义与声学能力冲突的新型编解码器。实验结果表明，XY-Tokenizer在语义和声学任务上的表现与同类比特率下的先进编解码器相当，而这些编解码器通常仅擅长某一方面。具体而言，XY-Tokenizer在文本对齐方面表现优异，超越了基于蒸馏的语义建模方法（如SpeechTokenizer和Mimi），同时重建音频与原始音频的说话人相似度达到0.83。XY-Tokenizer的重建性能与当前声学编解码器中的领先者BigCodec相当，后者在相似比特率下的说话人相似度为0.84。代码和模型可在https://github.com/gyt1145028706/XY-Tokenizer获取。

</details>


### [529] [From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection](https://arxiv.org/abs/2506.23437)
**中文标题：从大规模音频标签到实时可解释的紧急车辆警笛检测**

*Stefano Giacomelli,Marco Giordano,Claudia Rinaldi,Fabio Graziosi*

主要分类: cs.SD

摘要简述: 本文提出了一种轻量级卷积神经网络E2PANNs，专门用于紧急车辆警笛的实时检测，通过优化模型和专用数据集AudioSet EV，实现了高效且可解释的边缘设备部署。


<details>
  <summary>详细信息</summary>
研究动机: 紧急车辆警笛的准确识别对智能交通系统、智慧城市监控和自动驾驶技术至关重要，但现有方法受限于数据集的缺乏和计算资源的高需求。

研究方法: 基于PANNs框架，开发了轻量级卷积神经网络E2PANNs，利用专用数据集AudioSet EV进行微调，并通过引导反向传播和ScoreCAM算法增强模型的可解释性。

研究结果: E2PANNs在多个数据集上表现优异，计算效率高，适合边缘设备部署，并通过可解释性分析验证了其对警笛频谱特征的捕捉能力。

研究结论: E2PANNs在紧急车辆警笛检测领域实现了新的技术突破，兼具高效性和实用性，适用于安全关键应用。

中文摘要: 紧急车辆（EV）警笛的准确识别对于智能交通系统、智慧城市监控系统和自动驾驶技术的集成至关重要。现代自动解决方案受限于缺乏大规模、经过整理的数据集以及先进声音事件检测模型的高计算需求。本研究提出了E2PANNs（高效紧急预训练音频神经网络），这是一种基于PANNs框架的轻量级卷积神经网络架构，专门针对二元EV警笛检测进行了优化。利用我们专用的AudioSet子集（AudioSet EV），我们在多个参考数据集上对E2PANNs进行了微调和评估，并测试了其在嵌入式硬件上的可行性。实验包括消融研究、跨领域基准测试以及在边缘设备上的实时推理部署。通过引导反向传播和ScoreCAM算法的可解释性分析，揭示了模型的内部表示，并验证了其捕捉不同类型EV警笛频谱特征的能力。通过帧级和事件级检测指标以及误报激活的详细分析，评估了实时性能。结果表明，E2PANNs在该研究领域建立了新的技术标杆，具有高计算效率和适用于边缘音频监控及安全关键应用的潜力。

</details>


### [530] [Scaling Self-Supervised Representation Learning for Symbolic Piano Performance](https://arxiv.org/abs/2506.23869)
**中文标题：符号钢琴表演的自监督表示学习规模化研究**

*Louis Bradshaw,Honglu Fan,Alexander Spangher,Stella Biderman,Simon Colton*

主要分类: cs.SD

摘要简述: 本文研究了基于大量钢琴独奏符号转录数据的生成式自回归Transformer模型，通过预训练和微调，在音乐生成、分类任务和通用MIDI嵌入方面取得了显著成果。


<details>
  <summary>详细信息</summary>
研究动机: 探索如何利用大规模符号钢琴数据训练生成式自回归Transformer模型，以提升音乐生成和分类任务的性能，并验证预训练表示在下游任务中的通用性。

研究方法: 1. 在大约60,000小时的音乐数据上进行预训练；2. 使用高质量子集微调模型，用于音乐延续生成、符号分类任务和通用对比MIDI嵌入（基于SimCLR框架）；3. 评估生成模型的连贯性和对比模型在分类任务中的表现。

研究结果: 1. 生成模型在钢琴延续连贯性上优于现有符号生成技术，并与专有音频生成模型竞争；2. 对比模型的冻结表示在线性探测实验中达到最先进水平，微调后仅需少量标注数据即可适应下游任务。

研究结论: 研究表明，大规模预训练的符号音乐模型在生成和分类任务中具有显著优势，且预训练表示具有强大的通用性和适应性。

中文摘要: 我们研究了基于大量符号钢琴独奏转录数据的生成式自回归Transformer模型的能力。首先在大约60,000小时的音乐数据上进行预训练，随后使用较小但高质量的子集微调模型，以生成音乐延续、执行符号分类任务，并通过将SimCLR框架应用于符号音乐生成通用对比MIDI嵌入。在评估钢琴延续连贯性时，我们的生成模型优于领先的符号生成技术，并与专有音频生成模型竞争。在MIR分类基准测试中，对比模型的冻结表示在线性探测实验中达到最先进水平，而直接微调证明了预训练表示的通用性，通常仅需几百个标注样本即可适应下游任务。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [531] [Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI](https://arxiv.org/abs/2506.22477)
**中文标题：物联网架构与机器人操作平台的创新研究：大语言模型与生成式AI的应用**

*Huiwen Han*

主要分类: cs.NI

摘要简述: 本文提出了一种创新的机器人操作平台设计，结合物联网架构、大语言模型和生成式AI，旨在提升智能化和自主性，并在智能制造、医疗和服务业中验证其潜力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过整合大语言模型、生成式AI等前沿技术，提升物联网和机器人系统的智能化和自主性，以应对动态环境中的实时决策需求。

研究方法: 采用创新的物联网架构，结合大语言模型、生成式AI、边缘计算和5G网络，设计机器人操作平台，并通过跨行业案例研究验证其应用效果。

研究结果: 案例研究表明，该平台能够优化工作流程、提高生产力，并为智能制造、医疗和服务业提供可扩展的创新解决方案。

研究结论: 研究展示了大语言模型和生成式AI在推动智能机器人和物联网发展中的关键作用，为下一代自动化和技术融合提供了前瞻性视角。

中文摘要: 本文介绍了一种创新的机器人操作平台设计，基于变革性的物联网架构，无缝集成了大语言模型、生成式AI、边缘计算和5G网络等前沿技术。该平台旨在提升物联网系统和机器人的智能化和自主性，使其能够实时决策并动态适应变化的环境。通过一系列跨行业的案例研究，包括智能制造、医疗和服务业，本文展示了物联网机器人在优化工作流程、提高生产力和提供创新可扩展解决方案方面的巨大潜力。研究强调了大语言模型和生成式AI的作用，揭示了这些技术如何推动智能机器人和物联网的演进，塑造行业未来的进步。研究结果不仅展示了这些技术的变革力量，还提供了对其更广泛社会和工业影响的前瞻性视角，将其定位为下一代自动化和技术融合的催化剂。

</details>


### [532] [AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space](https://arxiv.org/abs/2506.22487)
**中文标题：通用人工智能赋能解决网络物理社会思维空间中万物互联各层瓶颈问题**

*Amar Khelloufi,Huansheng Ning,Sahraoui Dhelim,Jianguo Ding*

主要分类: cs.NI

摘要简述: 本文综述了通用人工智能（AGI）如何解决万物互联（IoX）在感知层、网络层和应用层的瓶颈问题，提出了跨层整合、量子通信和伦理治理框架的未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 万物互联（IoX）与通用人工智能（AGI）的融合为网络物理社会思维（CPST）生态系统中的感知、网络和应用层瓶颈问题提供了新的解决思路，本文旨在系统梳理AGI在IoX中的研究进展。

研究方法: 本文通过系统性综述，聚焦感知层的数据管理（如自适应传感器融合、边缘预处理）、网络层的协议优化（如动态频谱管理、神经符号推理）以及应用层的决策框架（如身份与关系管理）。

研究结果: 研究发现，AGI驱动的策略（如自适应传感器融合、语义建模）能有效解决感知层数据过载、网络层协议异构和应用层身份爆炸问题，同时强调了跨层整合和量子通信的重要性。

研究结论: AGI增强的IoX是互联系统与先进AI交叉领域的重要研究方向，但仍需解决计算需求、可扩展性和实际验证等挑战。

中文摘要: 万物互联（IoX）与通用人工智能（AGI）的融合催生了一种旨在解决网络物理社会思维（CPST）生态系统中感知层、网络层和应用层关键瓶颈的变革性范式。本综述系统全面地回顾了AGI增强的IoX研究，聚焦三个关键组成部分：感知层的数据管理、网络层的协议优化以及应用层的决策框架。具体而言，本文探讨了AGI如何通过自适应传感器融合、边缘预处理和选择性注意力机制缓解感知层瓶颈，同时解决网络层问题（如协议异构和动态频谱管理）以及应用层问题（如神经符号推理、主动推理和因果推理）。此外，本文还研究了AGI赋能的管理身份与关系爆炸的框架。关键发现表明，AGI驱动的策略（如自适应传感器融合、语义建模）为感知层数据过载、网络层协议异构和应用层身份爆炸提供了新颖解决方案。本文强调了跨层整合、量子通信和伦理治理框架对未来AGI赋能IoX系统的重要性。最后，本文指出了未解决的挑战（如计算需求、可扩展性和实际验证），呼吁进一步研究以充分发挥AGI在解决IoX瓶颈中的潜力。我们认为，AGI增强的IoX正成为互联系统与先进AI交叉领域的关键研究方向。

</details>


### [533] [Offline Reinforcement Learning for Mobility Robustness Optimization](https://arxiv.org/abs/2506.22793)
**中文标题：基于离线强化学习的移动鲁棒性优化**

*Pegah Alizadeh,Anastasios Giovanidis,Pradeepa Ramachandra,Vasileios Koutsoukis,Osama Arouk*

主要分类: cs.NI

摘要简述: 本文研究了利用离线强化学习优化移动鲁棒性（MRO）算法，通过离线数据集学习最优策略，无需额外探索。实验表明，离线强化学习方法优于基于规则的MRO，性能提升达7%。


<details>
  <summary>详细信息</summary>
研究动机: 移动鲁棒性优化（MRO）算法在无线网络中至关重要，但传统基于规则的方法灵活性不足。本文旨在探索离线强化学习在MRO中的应用，以提升性能并增强操作灵活性。

研究方法: 本文采用两种离线强化学习方法：基于序列的决策变换器（Decision Transformers）和基于值的保守Q学习（Conservative Q-Learning），使用与基于规则MRO相同的输入特征（如失败、乒乓切换等）。

研究结果: 在3500 MHz载频的新无线网络实验中，离线强化学习方法比基于规则的MRO性能提升高达7%，且能通过同一数据集训练多种目标函数。

研究结论: 离线强化学习在MRO中表现出色，不仅性能优于传统方法，还提供了更高的操作灵活性。

中文摘要: 本文重新审视了移动鲁棒性优化（MRO）算法，并研究了利用离线强化学习学习最优小区个体偏移调整的可能性。此类方法利用离线数据集学习最优策略，无需额外探索。我们采用了一种基于序列的方法（决策变换器）和一种基于值的方法（保守Q学习），以学习与基于规则的MRO相同目标奖励的最优策略。输入特征包括失败、乒乓切换等切换问题。在3500 MHz载频的新无线网络实验中，针对包含多样化用户服务类型的流量混合和特定可调小区对，离线强化学习方法优于基于规则的MRO，性能提升高达7%。此外，离线强化学习可通过同一数据集训练多种目标函数，相比基于规则的方法更具操作灵活性。

</details>


### [534] [The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking](https://arxiv.org/abs/2506.23628)
**中文标题：Kubernetes网络驱动模型：一种高性能网络的可组合架构**

*Antonio Ojea*

主要分类: cs.NI

摘要简述: 传统Kubernetes网络无法满足AI/ML和电信基础设施的高需求。本文提出Kubernetes网络驱动（KNDs），一种模块化、声明式架构，通过动态资源分配（DRA）和节点资源接口（NRI）改进，显著提升高性能AI/ML工作负载。


<details>
  <summary>详细信息</summary>
研究动机: 当前Kubernetes网络的命令式配置和API限制无法满足AI/ML和电信基础设施的高性能需求，亟需一种更灵活、高效的解决方案。

研究方法: 提出Kubernetes网络驱动（KNDs）架构，结合动态资源分配（DRA）、节点资源接口（NRI）改进及OCI运行时规范变更，实现声明式网络资源管理。通过DraNet实现远程直接内存访问（RDMA）设备的声明式连接。

研究结果: DraNet展示了高性能AI/ML工作负载的显著提升，支持复杂云原生应用，并为未来电信解决方案奠定基础。

研究结论: KNDs架构为高性能网络需求提供了模块化、声明式解决方案，降低了操作复杂性，并为未来应用交付开辟了新可能性。

中文摘要: 传统Kubernetes网络难以满足AI/ML和电信基础设施日益增长的需求。本文介绍了Kubernetes网络驱动（KNDs），这是一种变革性的模块化声明式架构，旨在克服当前命令式配置和API限制。KNDs通过动态资源分配（DRA）、节点资源接口（NRI）改进及即将推出的OCI运行时规范变更，将网络资源管理集成到Kubernetes核心中。我们的DraNet实现展示了包括远程直接内存访问（RDMA）设备在内的网络接口声明式连接，显著提升了高性能AI/ML工作负载。这一能力支持复杂的云原生应用，并为未来电信解决方案奠定了重要基础，推动了专门KNDs的“星系”发展，以增强应用交付并降低操作复杂性。

</details>


### [535] [Wireless Home Automation Using Social Networking Websites](https://arxiv.org/abs/2506.22482)
**中文标题：利用社交网站的无线家庭自动化**

*Divya Alok Gupta,Dwith Chenna,B. Aditya Vighnesh Ramakanth*

主要分类: cs.NI

摘要简述: 本文提出一种利用社交媒体网站（如Twitter）的无线家庭自动化系统（WHAS），通过安全认证和用户活动跟踪来控制家用电器，解决了传统系统的安全性和用户友好性问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着物联网的发展，无线家庭自动化系统（WHAS）逐渐流行，但仍面临安全性、多设备统一控制和用户体验等挑战。本文旨在通过社交媒体的安全认证和用户活动跟踪，提升系统的安全性和易用性。

研究方法: 提出一种基于社交媒体（如Twitter）的WHAS系统，利用其安全认证机制跟踪用户活动，并通过单一界面控制多种家用电器。

研究结果: 系统成功实现了通过社交媒体控制家用电器，并展示了其在安全性和用户体验上的优势。

研究结论: 本文提出的WHAS系统在安全性和用户友好性上优于传统家庭自动化系统，具有广泛的应用前景。

中文摘要: 随着物联网的发展，无线家庭自动化系统（WHAS）逐渐受到欢迎。这些系统面临多重挑战，如安全性、通过单一界面控制多种家用电器以及用户友好性。本文提出一种系统，利用Twitter等社交网站的安全认证机制，跟踪终端用户在社交网络上的活动，进而控制其家用电器。最后，我们强调了所提出的WHAS系统的应用，并比较了其与传统家庭自动化系统的优势。

</details>
