<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 88]
- [cs.CV](#cs.CV) [Total: 91]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 56]
- [quant-ph](#quant-ph) [Total: 1]
- [nlin.AO](#nlin.AO) [Total: 1]
- [eess.SP](#eess.SP) [Total: 2]
- [math.OC](#math.OC) [Total: 1]
- [cs.CY](#cs.CY) [Total: 3]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.IR](#cs.IR) [Total: 3]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [stat.ME](#stat.ME) [Total: 1]
- [eess.IV](#eess.IV) [Total: 14]
- [q-bio.NC](#q-bio.NC) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.SD](#cs.SD) [Total: 6]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.SE](#cs.SE) [Total: 25]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.NE](#cs.NE) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.RO](#cs.RO) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TeleEval-OS: Performance evaluations of large language models for operations scheduling](https://arxiv.org/abs/2506.11017)
**中文标题：TeleEval-OS：大语言模型在运营调度中的性能评估**

*Yanyan Wang,Yingying Wang,Junli Liang,Yin Xu,Yunlong Liu,Yiming Xu,Zhengwang Jiang,Zhehe Li,Fei Li,Long Zhao,Kuang Xu,Qi Song,Xiangyang Li*

主要分类: cs.CL

摘要简述: 本文提出了首个电信运营调度评估基准TeleEval-OS，用于全面评估大语言模型在电信运营调度任务中的性能，发现开源模型在特定场景下优于闭源模型。


<details>
  <summary>详细信息</summary>
研究动机: 电信运营调度（OS）任务复杂且缺乏全面评估基准，阻碍了大语言模型在这一关键领域的应用潜力探索。

研究方法: 提出TeleEval-OS基准，包含15个数据集和13个子任务，模拟四个关键运营阶段，并采用零样本和少样本评估方法测试14种大语言模型。

研究结果: 实验表明，开源大语言模型在特定场景下表现优于闭源模型，展示了其在电信运营调度领域的潜力。

研究结论: TeleEval-OS为评估大语言模型在电信运营调度中的性能提供了首个基准，开源模型在特定任务中具有显著优势。

中文摘要: 大语言模型（LLMs）的快速发展显著推动了人工智能的进步，并在多个专业领域展现出巨大的应用潜力。电信运营调度（OS）是电信行业的关键环节，涉及网络、服务、风险和人力资源的协调管理，以优化生产调度并确保统一的服务控制。然而，OS任务固有的复杂性和领域特定性，加上缺乏全面的评估基准，阻碍了对LLMs在这一关键领域应用潜力的深入探索。为填补这一研究空白，我们提出了首个电信运营调度评估基准（TeleEval-OS）。具体而言，该基准包含15个数据集和13个子任务，全面模拟了四个关键运营阶段：智能工单创建、智能工单处理、智能工单关闭和智能评估。为系统评估LLMs在不同复杂度任务中的表现，我们将其在电信运营调度中的能力划分为四个层次，按难度递增排列：基础NLP、知识问答、报告生成和报告分析。在TeleEval-OS上，我们采用零样本和少样本评估方法，全面测试了10种开源LLMs（如DeepSeek-V3）和4种闭源LLMs（如GPT-4o）在多样化场景中的表现。实验结果表明，开源LLMs在特定场景下可以超越闭源LLMs，凸显了其在电信运营调度领域的巨大潜力和价值。

</details>


### [2] [Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2506.11063)
**中文标题：聚光灯下是谁：多模态检索增强生成中的隐藏偏差**

*Jiayu Yao,Shenghua Liu,Yiwei Wang,Lingrui Mei,Baolong Bi,Yuyao Ge,Zhecheng Li,Xueqi Cheng*

主要分类: cs.CL

摘要简述: 研究发现多模态检索增强生成（RAG）系统存在位置偏差，证据顺序显著影响性能，多模态交互加剧偏差，需重新排序或去偏策略提升系统可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态RAG系统对证据顺序高度敏感，导致性能不稳定和推理偏差，尤其在检索项数量或模态多样性增加时。研究旨在揭示位置偏差如何影响多模态RAG性能。

研究方法: 通过文本、图像及混合模态任务的对照实验，量化位置偏差（引入位置敏感指数$PSI_p$），并开发可视化框架追踪解码层注意力分配模式。

研究结果: 实验显示多模态交互加剧位置偏差，偏差随检索范围对数增长，表现为U型准确率曲线。

研究结论: 研究为RAG中的位置感知分析提供理论和实证基础，强调需采用证据重排序或去偏策略以构建更可靠、公平的生成系统。

中文摘要: 多模态检索增强生成（RAG）系统在知识密集和开放域任务中至关重要。随着检索复杂度提升，确保系统鲁棒性成为关键。然而，现有RAG模型对证据顺序高度敏感，常导致性能不稳定和推理偏差，尤其在检索项数量或模态多样性增加时。这引发核心问题：检索证据的位置如何影响多模态RAG性能？为此，我们首次全面研究多模态RAG中的位置偏差。通过文本、图像及混合模态任务的对照实验，观察到证据位置与准确率呈一致U型曲线。为量化偏差，引入位置敏感指数（$PSI_p$）并开发可视化框架追踪解码层注意力分配模式。结果显示，多模态交互较单模态加剧位置偏差，且偏差随检索范围对数增长。这些发现为RAG中的位置感知分析提供理论和实证基础，强调需证据重排序或去偏策略以构建更可靠、公平的生成系统。

</details>


### [3] [Smotrom tvoja pa ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study](https://arxiv.org/abs/2506.11065)
**中文标题：从你的视角看另一个世界！用生成模型复活已消亡的皮钦语：Russenorsk案例研究**

*Alexey Tikhonov,Sergei Shteiner,Anna Bykova,Ivan P. Yamshchikov*

主要分类: cs.CL

摘要简述: 本文通过现代大型语言模型分析已消亡的皮钦语Russenorsk，构建其结构化词典，验证语言模型生成假设与学术文献的一致性，并开发翻译代理重构现代文本的Russenorsk版本。


<details>
  <summary>详细信息</summary>
研究动机: Russenorsk作为一种历史上用于俄语和挪威语贸易交流的皮钦语，具有独特的语言学价值。本文旨在利用现代语言模型分析其词汇和语法结构，填补学术空白。

研究方法: 基于现存文献构建Russenorsk的结构化词典，按同义词和词源分类；利用大型语言模型生成关于其构词和语法核心原则的假设，并与学术文献对比；开发翻译代理重构现代文本的Russenorsk版本。

研究结果: 成功构建Russenorsk词典，验证语言模型生成假设与学术文献的一致性；翻译代理能够生成合理的Russenorsk现代文本重构。

研究结论: 现代语言模型可用于分析已消亡语言，验证学术假设并重构语言实例，为语言学研究提供新工具。

中文摘要: Russenorsk是一种历史上用于俄语和挪威语贸易交流的皮钦语，代表了一种独特的语言学现象。本文尝试利用现代大型语言模型（LLMs）基于现存文献分析其词汇。我们构建了该语言的结构化词典，按同义词和词源分类。随后，利用该词典提出关于Russenorsk构词和语法核心原则的假设，并展示语言模型生成的假设与学术文献中已有假设的对应关系。我们还开发了一个“重构”翻译代理，用于生成现代俄语和挪威语文本的假设性Russenorsk版本。

</details>


### [4] [A Large Language Model Based Pipeline for Review of Systems Entity Recognition from Clinical Notes](https://arxiv.org/abs/2506.11067)
**中文标题：基于大语言模型的临床笔记系统回顾实体识别流程**

*Hieu Nghiem,Hemanth Reddy Singareddy,Zhuqi Miao,Jivan Lamichhane,Abdulaziz Ahmed,Johnson Thomas,Dursun Delen,William Paiva*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大语言模型（LLM）的自动化流程，用于从临床笔记中提取系统回顾（ROS）实体，结合开源和商业模型，实现了低成本、高精度的实体识别。


<details>
  <summary>详细信息</summary>
研究动机: 旨在开发一种成本效益高、可扩展的自动化方法，减轻临床医生在系统回顾（ROS）文档记录中的负担，并探索开源大语言模型在资源有限医疗环境中的适用性。

研究方法: 流程分为两部分：首先使用SecTag提取ROS段落，随后通过少样本学习的大语言模型（如Mistral、Llama、Gemma和ChatGPT）识别ROS实体范围、正负状态及相关身体系统。

研究结果: 结合ChatGPT的流程在识别ROS实体范围和状态/系统时错误率最低（分别为28.2%和14.5%）。开源模型表现接近，错误率范围分别为30.5-36.7%和24.3-27.3%。

研究结论: 该流程为ROS文档记录提供了可扩展且本地化的解决方案，开源模型在资源有限环境中是商业模型的可行替代方案。

中文摘要: 目标：开发一种基于大语言模型（LLM）的成本效益高的自动化流程，用于从临床笔记中提取系统回顾（ROS）实体。材料与方法：流程首先使用SecTag提取ROS段落，随后通过少样本学习的LLM识别ROS实体范围、正负状态及相关身体系统。我们使用开源LLM（Mistral、Llama、Gemma）和ChatGPT实现流程，并在包含341个标注ROS实体的36份普通医学笔记上进行评估。结果：结合ChatGPT的流程在识别ROS实体范围和状态/系统时错误率最低（分别为28.2%和14.5%）。开源LLM在本地低成本运行中表现良好，错误率接近（范围：30.5-36.7%；状态/系统：24.3-27.3%）。讨论与结论：该流程为减轻ROS文档负担提供了可扩展且本地化的解决方案，开源LLM在资源有限的医疗环境中是商业模型的可行替代方案。

</details>


### [5] [Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models](https://arxiv.org/abs/2506.11068)
**中文标题：义务性关键词偏见：模态表达对语言模型规范性判断的影响**

*Bumjin Park,Jinsil Lee,Jaesik Choi*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLM）在道德推理中存在‘义务性关键词偏见’（DKB），即当提示中包含‘必须’或‘应该’等模态表达时，LLM倾向于将非义务性情境判断为义务。作者提出了一种结合少样本示例和推理提示的策略来缓解此偏见。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM在道德和伦理推理中的应用日益广泛，但其判断标准尚不明确，尤其是在义务性判断方面。本研究旨在揭示LLM在模态表达影响下的偏见现象，并探索缓解方法。

研究方法: 通过实验分析不同LLM家族、问题类型和回答格式下模态表达（如‘必须’或‘应该’）对义务性判断的影响，并提出结合少样本示例和推理提示的策略以减轻偏见。

研究结果: 实验表明，当提示中包含模态表达时，LLM将超过90%的常识情境判断为义务性任务，且这一现象在不同LLM家族中普遍存在。提出的缓解策略有效减少了偏见。

研究结论: 模态表达作为一种语言框架显著影响LLM的规范性决策，研究强调了解决此类偏见的重要性，以确保LLM的判断与人类价值观一致。

中文摘要: 大型语言模型（LLM）越来越多地参与道德和伦理推理，但其判断标准往往不明确，甚至对人类也是如此。尽管LLM对齐研究涵盖了许多领域，但一个重要却未充分探索的领域是LLM如何对义务进行判断。本研究发现，当提示中增加‘必须’或‘应该’等模态表达时，LLM表现出强烈的倾向，将非义务性情境判断为义务。我们将此现象称为‘义务性关键词偏见’（DKB）。实验发现，当模态表达存在时，LLM将超过90%的常识情境判断为义务。这一倾向在不同LLM家族、问题类型和回答格式中均一致存在。为缓解DKB，我们提出了一种结合少样本示例和推理提示的判断策略。本研究揭示了模态表达作为一种语言框架如何影响LLM的规范性决策，并强调了解决此类偏见以确保判断对齐的重要性。

</details>


### [6] [Targeted control of fast prototyping through domain-specific interface](https://arxiv.org/abs/2506.11070)
**中文标题：通过领域特定接口实现快速原型设计的精准控制**

*Yu-Zhe Shi,Mingchen Liu,Hanlu Ma,Qiao Xu,Huamin Qu,Kun He,Lecheng Ruan,Qining Wang*

主要分类: cs.CL

摘要简述: 工业设计师长期以来寻求一种自然直观的方法，通过简单自然语言指令实现对原型模型的精准控制，而无需依赖复杂的建模命令。本文提出一种接口架构，作为设计师语言与建模语言之间的桥梁，通过自动化领域规范算法，实现原型模型的精确控制。


<details>
  <summary>详细信息</summary>
研究动机: 工业设计师希望通过自然语言指令直接配置和调整原型模型，但现有大型语言模型在此领域的潜力尚未完全发挥，主要因设计师语言与建模语言之间存在抽象层次不匹配、语义精度波动及词汇范围差异等问题。

研究方法: 基于对快速原型设计实践的系统研究，提出一种接口架构，设计其操作机制并开发自动化领域规范算法，以弥合设计师语言与建模语言之间的差距。

研究结果: 通过机器评估和跨多个产品设计领域的人体实验，验证了该接口作为大型语言模型辅助模块的潜力，能够实现对原型模型的精准有效控制。

研究结论: 提出的接口架构能够有效连接设计师语言与建模语言，为快速原型设计提供了一种精确控制的新方法，展示了其在工业设计中的实际应用价值。

中文摘要: 工业设计师长期以来寻求一种自然直观的方法，通过简单自然语言指令实现对原型模型的精准控制，而无需依赖复杂的建模命令。尽管大型语言模型在此领域显示出潜力，但其通过语言控制原型模型的能力仍未完全发挥。这一限制源于设计师语言与建模语言之间的差距，包括抽象层次不匹配、语义精度波动及词汇范围差异。为弥合这些差距，我们提出一种接口架构，作为两种语言之间的媒介。基于对快速原型设计实践的系统研究，我们设计了该接口的操作机制，并开发了一种自动化领域规范算法。通过跨多个产品设计领域的机器评估和人体实验，证明了该接口作为大型语言模型辅助模块的潜力，能够实现对原型模型的精准有效控制。

</details>


### [7] [CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention](https://arxiv.org/abs/2506.11073)
**中文标题：CLAIM：通过跨语言注意力干预减轻大型视觉语言模型中的多语言对象幻觉**

*Zekai Ye,Qiming Li,Xiaocheng Feng,Libo Qin,Yichong Huang,Baohang Li,Kui Jiang,Yang Xiang,Zhirui Zhang,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CLAIM的新方法，通过跨语言注意力干预来减少大型视觉语言模型中的多语言对象幻觉问题，无需大量训练资源，显著提升了模型在多语言环境下的表现。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型在多语言查询时容易产生与视觉输入不一致的响应（即对象幻觉），现有方法通常依赖资源密集的预训练或微调，亟需一种高效且无需大量训练的方法来解决这一问题。

研究方法: CLAIM通过识别语言特定的跨模态注意力头，估计从英语到目标语言的注意力偏移向量，并在推理阶段干预注意力输出，从而对齐跨语言视觉感知能力。

研究结果: 实验表明，CLAIM在POPE基准上平均提升了13.56%（西班牙语最高达30%），在MME基准的幻觉子集上提升了21.75%，且多语言注意力差异在中间层最为显著。

研究结论: CLAIM是一种高效且无需大量训练的方法，显著减少了多语言对象幻觉问题，为多语言场景下的视觉语言模型提供了新的解决方案。

中文摘要: 大型视觉语言模型（LVLMs）展现了强大的多模态能力，但在非英语查询时更容易产生与视觉输入不一致的响应（即多语言对象幻觉）。现有方法多依赖预训练或微调，资源消耗大。本文受跨语言注意力模式差异的启发，提出了一种名为CLAIM的新方法，通过注意力对齐来减轻多语言对象幻觉。CLAIM首先识别语言特定的跨模态注意力头，然后估计从英语到目标语言的注意力偏移向量，最后在推理阶段干预注意力输出以对齐跨语言视觉感知能力。实验表明，CLAIM在POPE基准上平均提升了13.56%（西班牙语最高达30%），在MME基准的幻觉子集上提升了21.75%。进一步分析发现，多语言注意力差异在中间层最为显著，凸显了其在多语言场景中的关键作用。

</details>


### [8] [CyclicReflex: Improving Large Reasoning Models via Cyclical Reflection Token Scheduling](https://arxiv.org/abs/2506.11077)
**中文标题：CyclicReflex：通过周期性反思令牌调度改进大型推理模型**

*Chongyu Fan,Yihua Zhang,Jinghan Jia,Alfred Hero,Sijia Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CyclicReflex的解码策略，通过动态调整反思令牌的频率和位置，优化大型推理模型（LRMs）的性能。实验表明，该方法在多个数据集上优于标准解码和其他最新方法。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型（LRMs）在解决复杂问题时依赖反思令牌（如“等待”、“但是”等）引导多步推理。然而，反思令牌的过度或不足使用（称为过度反思和反思不足）会降低模型性能。本文旨在通过优化反思令牌的分配，提升LRMs的计算效率。

研究方法: 作者将反思令牌的使用类比为优化中的学习率调度，提出了一种周期性反思令牌调度（CyclicReflex）策略。该方法通过位置相关的三角波形动态调整反思令牌的logits，从而在解码过程中优化其频率和位置。

研究结果: 在MATH500、AIME2024/2025和AMC2023等数据集上的实验表明，CyclicReflex在1.5B至8B规模的模型中均表现优异，优于标准解码和TIP、S1等最新方法。

研究结论: CyclicReflex通过动态管理反思令牌资源，有效解决了过度反思和反思不足的问题，显著提升了大型推理模型的性能。

中文摘要: 大型推理模型（LRMs），如OpenAI的o1和DeepSeek-R1，利用测试时扩展进行多步推理以解决复杂问题。在生成最终答案之前，这一推理过程通常由特殊的连接令牌或文本片段引导，以提示自我评估性反思。我们将这些过渡标记和反思提示称为“反思令牌”（例如“等待”、“但是”、“或者”）。本文中，我们将反思令牌视为一种“资源”，并提出了资源分配问题，旨在通过自适应调节反思令牌的频率和位置，提高LRMs的测试时计算性能。通过实证分析，我们发现反思令牌的过度使用（过度反思）和不足使用（反思不足）都会降低模型性能。为了更好地理解和管理这一权衡，我们将反思令牌的使用类比为优化中的学习率调度。基于这一洞察，我们提出了周期性反思令牌调度（CyclicReflex），这是一种解码策略，通过位置相关的三角波形动态调整反思令牌的logits。在MATH500、AIME2024/2025和AMC2023上的实验表明，CyclicReflex在1.5B至8B规模的模型中均表现优异，优于标准解码和TIP（思维切换惩罚）、S1等最新方法。代码可在https://github.com/OPTML-Group/CyclicReflex获取。

</details>


### [9] [RoE-FND: A Case-Based Reasoning Approach with Dual Verification for Fake News Detection via LLMs](https://arxiv.org/abs/2506.11078)
**中文标题：RoE-FND：一种基于案例推理的双重验证虚假新闻检测方法**

*Yuzhou Yang,Yangming Zhou,Zhiying Zhu,Zhenxing Qian,Xinpeng Zhang,Sheng Li*

主要分类: cs.CL

摘要简述: RoE-FND是一种基于案例推理的双重验证框架，通过结合大型语言模型（LLMs）和经验学习，改进虚假新闻检测（FND）的鲁棒性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 当前虚假新闻检测方法存在证据选择噪声、泛化能力不足和决策过程不透明等问题，而利用大型语言模型（LLMs）的方法又面临幻觉推理和结论偏差的挑战。RoE-FND旨在通过经验学习解决这些问题。

研究方法: RoE-FND分为两个阶段：1）自省知识构建，通过分析历史推理错误构建知识库；2）动态准则检索，从历史案例中提取任务特定推理准则。此外，通过双通道程序交叉验证推理过程。

研究结果: 实验证明，RoE-FND在三个数据集上表现出优于现有方法的泛化能力和有效性，且无需训练即可适应动态环境。

研究结论: RoE-FND通过案例推理和经验学习，显著提升了虚假新闻检测的鲁棒性和可解释性，为未来研究提供了新方向。

中文摘要: 在线虚假内容的泛滥要求虚假新闻检测（FND）系统具备更强的鲁棒性。尽管基于证据的方法利用外部知识验证主张，但现有方法仍面临证据选择噪声、泛化瓶颈和决策过程不透明等关键限制。近期利用大型语言模型（LLMs）进行FND的研究引入了新的挑战，如幻觉推理和结论偏差。为解决这些问题，我们提出RoE-FND（基于经验的虚假新闻检测），该框架通过将LLMs与经验学习结合，将基于证据的FND重新定义为逻辑推理任务。RoE-FND包含两个阶段：（1）自省知识构建，通过分析历史推理错误构建知识库（探索阶段）；（2）动态准则检索，从历史案例中提取任务特定推理准则（部署阶段）。此外，通过设计的双通道程序对推理过程进行交叉验证。主要贡献包括：一种解决多挑战的案例推理FND框架、无需训练即可适应动态环境的方法，以及在三个数据集上验证的优于现有方法的泛化能力和有效性。

</details>


### [10] [MANBench: Is Your Multimodal Model Smarter than Human?](https://arxiv.org/abs/2506.11080)
**中文标题：MANBench：你的多模态模型比人类更聪明吗？**

*Han Zhou,Qitong Xu,Yiheng Dong,Xin Yang*

主要分类: cs.CL

摘要简述: 论文介绍了MANBench，一个双语多模态能力基准测试，用于评估多模态大语言模型（MLLMs）与人类在多模态任务中的表现差异。结果显示，MLLMs在某些任务上表现优异，但在复杂推理任务上仍落后于人类。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）的快速发展，人们对其是否能在多模态任务中超越人类表现产生了疑问。为此，作者提出了MANBench，旨在提供一个全面的评估框架，比较MLLMs与人类在多模态任务中的能力差异。

研究方法: 作者开发了MANBench，一个包含1,314个问题的双语（英语和中文）基准测试，涵盖九项任务，分为知识性和非知识性领域。通过广泛的人类实验，将人类表现与最先进的MLLMs进行对比。

研究结果: 结果显示，MLLMs在知识和图文理解任务中表现优异，但在跨模态推理任务（如变形理解、图像一致性和多图像理解）中表现不佳。此外，人类和MLLMs在复杂任务（如谜题和空间想象）中均面临挑战。

研究结论: MANBench揭示了MLLMs的优势和局限性，表明即使是最先进的模型在许多领域仍无法达到人类水平。作者希望MANBench能推动缩小MLLMs与人类多模态能力差距的研究。

中文摘要: 多模态大语言模型（MLLMs）的快速发展引发了关于其在多模态任务中是否可能超越人类表现的讨论。为此，我们提出了MANBench（多模态能力规范基准），这是一个双语（英语和中文）基准测试，包含1,314个问题，涵盖九项任务，涉及知识性和非知识性领域。MANBench强调直观推理、无缝跨模态整合和现实世界的复杂性，提供了一个严格的评估框架。

通过涉及多样化参与者的大规模人类实验，我们将人类表现与最先进的MLLMs进行了对比。结果表明，尽管MLLMs在知识和图文理解等任务中表现出色，但在更深层次的跨模态推理任务（如变形理解、图像一致性和多图像理解）中表现不佳。此外，人类和MLLMs在高度复杂的任务（如谜题和空间想象）中均面临挑战。

MANBench突出了MLLMs的优势和局限性，揭示了即使是最先进的模型在许多领域仍无法达到人类水平。我们希望MANBench能激励人们努力缩小MLLMs与人类多模态能力之间的差距。代码和数据集可在https://github.com/micdz/MANBench获取。

</details>


### [11] [SAGE:Specification-Aware Grammar Extraction for Automated Test Case Generation with LLMs](https://arxiv.org/abs/2506.11081)
**中文标题：SAGE：基于规范感知的文法提取用于LLMs自动化测试用例生成**

*Aditi,Hyunwoo Park,Sicheol Sung,Yo-Sub Han,Sang-Ki Ko*

主要分类: cs.CL

摘要简述: SAGE利用开源大语言模型（LLMs）从自然语言规范中提取带计数器的上下文无关文法（CCFGs），并通过强化学习优化文法有效性和通用性，显著提升了测试用例生成的质量。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于文法的测试用例生成在编程竞赛中表现优异，但从自然语言规范中提取有效且通用的文法仍是一大挑战，尤其是在监督数据有限的情况下。

研究方法: SAGE首先微调开源LLM以实现规范到文法的翻译，随后采用Group Relative Policy Optimization（GRPO）增强文法的有效性和通用性，并通过迭代反馈修正文法中的语法和语义错误。

研究结果: 实验表明，SAGE在文法有效性和测试效果上优于17种开源和闭源LLMs，分别提升了15.92%和12.34%，达到了当前最佳水平。

研究结论: SAGE通过结合LLMs和强化学习，显著提升了从自然语言规范中提取文法的能力，为自动化测试用例生成提供了高效解决方案。

中文摘要: 基于文法的测试用例生成在编程竞赛中已被证明是有效的，但从自然语言规范中生成有效且通用的文法仍是一个关键挑战，尤其是在监督有限的情况下。带计数器的上下文无关文法（CCFGs）作为一种形式化方法，通过存储和重用推导过程中的计数器值来表示带有逻辑约束的规范。本研究探索了利用开源大语言模型（LLMs）从少量标注示例中提取CCFGs，并通过可验证的奖励引导强化学习优化文法。我们的方法首先微调开源LLM以实现规范到文法的翻译，随后采用Group Relative Policy Optimization（GRPO）进一步提升文法的有效性和通用性。我们还研究了迭代反馈对开源和闭源LLMs在修正生成文法中的语法和语义错误方面的效果。实验结果表明，SAGE在文法质量和测试效果上均优于17种开源和闭源LLMs，文法有效性提升了15.92%，测试效果提升了12.34%，超越了当前最佳水平。我们的实现和数据集已发布在匿名仓库：https://anonymous.4open.science/r/SAGE-5714。

</details>


### [12] [PRISM: A Transformer-based Language Model of Structured Clinical Event Data](https://arxiv.org/abs/2506.11082)
**中文标题：PRISM：基于Transformer的结构化临床事件数据语言模型**

*Lionel Levine,John Santerre,Alex S. Young,T. Barry Levine,Francis Campion,Majid Sarrafzadeh*

主要分类: cs.CL

摘要简述: PRISM是一种基于Transformer的架构，用于建模临床决策过程的序列化进展，通过学习事件序列预测下一步诊断步骤，显著优于随机基线，展示了生成式语言模型在医疗数据中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 传统临床诊断方法依赖孤立的分类，无法捕捉复杂的时序依赖关系。PRISM旨在通过序列化建模临床事件（如诊断测试、实验室结果和诊断），填补机器学习与真实诊断推理之间的鸿沟。

研究方法: PRISM采用Transformer架构，将临床事件序列化为标记化数据，通过自回归训练目标学习预测下一步事件。利用大规模定制临床词汇表，捕捉患者时间线中的复杂依赖关系。

研究结果: 实验显示，PRISM在下一标记预测任务中显著优于随机基线，生成的序列反映了真实的诊断路径、实验室结果进展和医生行为。

研究结论: PRISM验证了生成式语言模型在结构化医疗事件数据中的可行性，为临床决策支持、模拟和教育提供了基础，推动了序列化医疗建模的发展。

中文摘要: 我们介绍了PRISM（Predictive Reasoning in Sequential Medicine），一种基于Transformer的架构，旨在建模临床决策过程的序列化进展。与传统依赖孤立诊断分类的方法不同，PRISM将临床轨迹视为事件（包括诊断测试、实验室结果和诊断）的标记化序列，并学习预测患者诊断旅程中最可能的下一步。通过利用大规模定制临床词汇表和自回归训练目标，PRISM展示了捕捉纵向患者时间线中复杂依赖关系的能力。实验结果表明，在下一标记预测任务中，PRISM显著优于随机基线，生成的序列反映了真实的诊断路径、实验室结果进展和医生行为。这些发现凸显了将生成式语言建模技术应用于结构化医疗事件数据的可行性，为临床决策支持、模拟和教育提供了应用可能。PRISM为基于序列的医疗建模未来进展奠定了基础，弥合了机器学习架构与真实诊断推理之间的鸿沟。

</details>


### [13] [RedDebate: Safer Responses through Multi-Agent Red Teaming Debates](https://arxiv.org/abs/2506.11083)
**中文标题：RedDebate：通过多智能体红队辩论实现更安全的响应**

*Ali Asad,Stephen Obadinma,Radin Shayanfar,Xiaodan Zhu*

主要分类: cs.CL

摘要简述: RedDebate提出了一种多智能体辩论框架，通过对抗性论证主动识别和减少大型语言模型的不安全行为，结合长期记忆模块，显著提升了AI安全性。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI安全方法依赖昂贵的人工评估或单模型评估，存在扩展性和监督风险问题。RedDebate旨在通过多智能体辩论和自动化红队测试，系统性提升AI安全性。

研究方法: RedDebate利用多智能体辩论框架，让多个大型语言模型相互批判性审查，通过对抗性论证发现不安全盲点，并结合长期记忆模块保留学习到的安全知识。

研究结果: 实验表明，仅辩论即可减少17.7%的不安全行为，结合长期记忆模块后，减少率超过23.5%。

研究结论: RedDebate是首个完全自动化结合多智能体辩论与红队测试的框架，无需人工干预即可逐步提升AI安全性。

中文摘要: 我们提出了RedDebate，一种新颖的多智能体辩论框架，通过大型语言模型（LLMs）之间的对抗性论证，主动识别和减少其不安全行为。现有的AI安全方法通常依赖昂贵的人工评估或单模型评估，两者均受限于扩展性和监督风险。RedDebate采用协作性分歧，使多个LLMs能够批判性审查彼此的推理，通过自动化红队测试系统性发现不安全盲点，并迭代改进其响应。我们还整合了不同类型的长期记忆，保留从辩论互动中学到的安全见解。在如HarmBench等已建立的安全基准上评估，证明了该方法的有效性。仅辩论即可减少17.7%的不安全行为，结合长期记忆模块后，减少率超过23.5%。据我们所知，RedDebate是首个完全自动化结合多智能体辩论与红队测试的框架，无需直接人工干预即可逐步提升AI安全性。（Github仓库：https://github.com/aliasad059/RedDebate）

</details>


### [14] [Two Birds with One Stone: Improving Factuality and Faithfulness of LLMs via Dynamic Interactive Subspace Editing](https://arxiv.org/abs/2506.11088)
**中文标题：一石二鸟：通过动态交互子空间编辑提升大语言模型的事实性和忠实性**

*Pengbo Wang,Chaozhuo Li,Chenxu Wang,Liwen Zheng,Litian Zhang,Xi Zhang*

主要分类: cs.CL

摘要简述: 本文提出SPACE框架，通过动态交互子空间编辑同时提升大语言模型的事实性和忠实性，解决了现有方法独立处理这两类幻觉导致的性能权衡问题。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在自然语言处理中表现出强大能力，但其实际应用仍受事实性和忠实性幻觉的困扰。现有方法独立处理这两类幻觉，导致性能权衡问题。本文旨在通过分析激活空间动态，揭示这两类幻觉共享的子空间，并提出统一解决方案。

研究方法: 通过双任务特征建模为共享子空间的存在提供几何基础，结合谱聚类和注意力头显著性评分的混合探针策略识别并编辑这些子空间，提出SPACE框架。

研究结果: 在多个基准数据集上的实验结果表明，SPACE框架在提升事实性和忠实性方面优于现有方法。

研究结论: SPACE框架通过动态交互子空间编辑，成功实现了对大语言模型事实性和忠实性的联合优化，为实际应用提供了有效解决方案。

中文摘要: 大语言模型在自然语言处理中展现出前所未有的能力，但其实际部署仍因持续存在的事实性和忠实性幻觉而受阻。现有方法独立处理这些幻觉类型，却无意中引发性能权衡，因为针对一种类型的干预往往会加剧另一种类型。通过对大语言模型中激活空间动态的实证和理论分析，我们发现这些幻觉类别在神经表征中共享重叠子空间，这为同时缓解提供了机会。为利用这一发现，我们提出SPACE框架，通过编辑共享激活子空间联合提升事实性和忠实性。SPACE通过双任务特征建模为共享子空间的存在奠定几何基础，然后结合谱聚类和注意力头显著性评分的混合探针策略识别并编辑这些子空间。在多个基准数据集上的实验结果证明了我们方法的优越性。

</details>


### [15] [Customizing Speech Recognition Model with Large Language Model Feedback](https://arxiv.org/abs/2506.11091)
**中文标题：利用大语言模型反馈定制语音识别模型**

*Shaoshi Ling,Guoli Ye*

主要分类: cs.CL

摘要简述: 本文提出了一种基于强化学习的无监督领域适应方法，利用大语言模型（LLM）的反馈提升自动语音识别（ASR）模型在命名实体识别和领域适应方面的性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动语音识别（ASR）系统在通用转录任务中表现优异，但在识别罕见命名实体和适应领域不匹配时表现不佳。相比之下，大语言模型（LLM）在广泛领域中表现更优。本文旨在利用LLM的反馈提升ASR模型的性能。

研究方法: 提出了一种基于强化学习的框架，利用未标注数据和无监督领域适应方法，通过LLM作为奖励模型对ASR模型的假设进行评分，并将评分作为奖励信号通过强化学习微调ASR模型。

研究结果: 实验结果表明，该方法在命名实体错误率上比传统的自训练方法提升了21%。

研究结论: 通过结合LLM的反馈和强化学习，本文方法显著提升了ASR模型在领域适应和命名实体识别方面的性能。

中文摘要: 自动语音识别（ASR）系统在通用转录任务中表现优异，但在识别罕见命名实体和适应领域不匹配时仍存在困难。相比之下，基于大规模互联网数据训练的大语言模型（LLM）在广泛领域中表现更优。本文提出了一种基于强化学习的无监督领域适应方法，利用未标注数据通过LLM的反馈提升转录质量，尤其是受领域不匹配影响的命名实体识别。在给定上下文信息的情况下，我们的框架使用LLM作为奖励模型对ASR模型的假设进行评分，并将评分作为奖励信号通过强化学习微调ASR模型。实验结果表明，该方法在命名实体错误率上比传统的自训练方法提升了21%。

</details>


### [16] [Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation](https://arxiv.org/abs/2506.11092)
**中文标题：动态上下文调优用于检索增强生成：增强多轮规划和工具适应**

*Jubin Abhishek Soni,Amit Anand,Rajesh Kumar Pandey,Aniket Abhishek Soni*

主要分类: cs.CL

摘要简述: 本文提出动态上下文调优（DCT）框架，通过多轮对话和动态工具选择增强检索增强生成（RAG）模型，显著提升计划准确性和减少幻觉，同时降低计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有RAG系统通常局限于静态、单轮交互和固定工具集，无法适应动态领域（如医疗和智能家居）中用户意图和工具的变化需求。

研究方法: DCT框架包含基于注意力的上下文缓存以跟踪历史信息，基于LoRA的动态工具检索，以及高效上下文压缩技术以保持输入在LLM上下文限制内。

研究结果: 实验表明，DCT将计划准确性提升14%，幻觉减少37%，并以更低成本达到GPT-4性能，且能泛化到未见过的工具。

研究结论: DCT为动态环境中的AI助手提供了可扩展和适应性强的解决方案，显著提升了RAG模型的实用性和效率。

中文摘要: 检索增强生成（RAG）通过将大型语言模型（LLM）的输出与外部工具和知识源结合，显著提升了模型性能。然而，现有RAG系统通常局限于静态、单轮交互和固定工具集，难以适应动态领域（如医疗和智能家居）中用户意图、可用工具和上下文因素的动态变化。本文提出动态上下文调优（DCT），一种轻量级框架，扩展了RAG以支持多轮对话和动态工具环境，且无需重新训练。DCT集成了基于注意力的上下文缓存以跟踪相关历史信息，基于LoRA的动态工具检索，以及高效上下文压缩技术以保持输入在LLM上下文限制内。在合成和真实基准测试中，DCT将计划准确性提升14%，幻觉减少37%，并以显著更低的成本匹配GPT-4性能。此外，DCT能泛化到未见过的工具，为广泛的动态环境提供可扩展和适应性强的AI助手。

</details>


### [17] [The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs](https://arxiv.org/abs/2506.11094)
**中文标题：正义的天平：大语言模型安全评估全面综述**

*Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu*

主要分类: cs.CL

摘要简述: 本文综述了大语言模型（LLMs）安全评估的最新进展，探讨了评估背景、任务分类、指标与数据集、方法工具及未来研究方向，强调安全评估对实际应用的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）的广泛应用，其生成内容中的毒性、偏见等安全问题引发关注。尽管已有大量研究评估LLMs的安全风险，但缺乏系统性综述。本文旨在填补这一空白，全面梳理LLMs安全评估的研究进展。

研究方法: 本文从四个方面系统梳理LLMs安全评估：（1）“为何评估”：探讨背景、与一般评估的区别及意义；（2）“评估什么”：按毒性、鲁棒性、伦理等维度分类任务；（3）“何处评估”：总结现有指标、数据集与基准；（4）“如何评估”：分类主流方法及工具。

研究结果: 本文全面总结了LLMs安全评估的关键问题，包括任务分类、评估工具及方法，并指出当前挑战与未来研究方向，为领域发展提供参考。

研究结论: LLMs安全评估对实际部署至关重要，需进一步研究以提升评估方法，确保模型安全应用。

中文摘要: 随着人工智能技术的快速发展，大语言模型（LLMs）在自然语言处理（NLP）领域展现出巨大潜力，涵盖内容生成、人机交互、机器翻译和代码生成等方面。然而，其广泛应用也引发了显著的安全问题。近年来，LLMs生成的内容偶尔表现出毒性和偏见等不安全因素，尤其在对抗场景下，这引起了学术界和工业界的广泛关注。尽管已有大量研究评估LLMs的安全风险，但缺乏系统性综述。本文旨在全面梳理LLMs安全评估的最新进展，重点关注以下关键方面：（1）“为何评估”：探讨LLMs安全评估的背景、与一般评估的区别及其意义；（2）“评估什么”：基于毒性、鲁棒性、伦理、偏见与公平性、真实性等维度对现有任务进行分类；（3）“何处评估”：总结当前安全评估中使用的指标、数据集与基准；（4）“如何评估”：回顾现有评估工具，并根据评估者角色对主流方法进行分类。最后，我们指出LLMs安全评估的挑战，并提出潜在研究方向以推动领域发展。我们强调优先考虑LLMs安全评估的重要性，以确保这些模型在实际应用中的安全部署。

</details>


### [18] [Persistent Homology of Topic Networks for the Prediction of Reader Curiosity](https://arxiv.org/abs/2506.11095)
**中文标题：基于主题网络持久同调性的读者好奇心预测**

*Manuel D. S. Hopp,Vincent Labatut,Arthur Amalvy,Richard Dufour,Hannah Stone,Hayley Jach,Kou Murayama*

主要分类: cs.CL

摘要简述: 本文提出了一种基于BERTopic主题建模和持久同调性的框架，通过分析文本语义网络中的拓扑特征来预测读者的好奇心。实验表明，该方法显著提升了好奇心预测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 读者好奇心是文本参与的关键因素，但在自然语言处理（NLP）领域尚未得到充分研究。本文基于Loewenstein的信息缺口理论，旨在量化文本语义结构中的信息缺口，从而建模读者好奇心。

研究方法: 结合BERTopic主题建模和持久同调性，构建动态语义网络的拓扑特征（如连通分量、循环和空洞），并将其作为信息缺口的代理变量。通过实验收集读者对《饥饿游戏》小说的好奇心评分，并利用拓扑特征预测这些评分。

研究结果: 实验结果表明，基于拓扑特征的模型显著优于基线模型（解释偏差从30%提升至73%），验证了该方法的有效性。

研究结论: 本文提出的框架为分析文本结构及其与读者参与的关系提供了一种新的计算方法，并证实了拓扑特征在预测好奇心方面的潜力。

中文摘要: 读者好奇心是信息获取的动力，对文本参与至关重要，但在自然语言处理（NLP）领域尚未得到充分探索。基于Loewenstein的信息缺口理论，我们提出了一种框架，通过量化文本语义结构中的信息缺口来建模读者好奇心。该方法结合BERTopic主题建模和持久同调性，分析从文本片段衍生的动态语义网络的拓扑特征（如连通分量、循环和空洞），并将这些特征作为信息缺口的代理变量。为实证评估该流程，我们收集了49名参与者在阅读《饥饿游戏》小说时的好奇心评分。随后，利用流程中的拓扑特征作为自变量预测这些评分，实验结果表明，相比基线模型（解释偏差为30%），该方法显著提升了预测效果（解释偏差为73%），验证了其有效性。该流程为分析文本结构及其与读者参与的关系提供了一种新的计算方法。

</details>


### [19] [C-SEO Bench: Does Conversational SEO Work?](https://arxiv.org/abs/2506.11097)
**中文标题：C-SEO Bench：对话搜索引擎优化有效吗？**

*Haritz Puerto,Martin Gubri,Tommaso Green,Seong Joon Oh,Sangdoo Yun*

主要分类: cs.CL

摘要简述: 本文介绍了C-SEO Bench，首个评估对话搜索引擎优化（C-SEO）方法的基准测试，发现现有C-SEO方法大多无效，传统SEO策略更有效，且随着采用者增加，效果递减。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）将搜索引擎转变为对话搜索引擎（CSE），对话搜索引擎优化（C-SEO）方法开始出现。然而，现有方法仅在有限领域测试，且未考虑多参与者竞争场景，亟需全面评估。

研究方法: 提出C-SEO Bench基准，涵盖问答和产品推荐两种搜索任务及三个领域，并设计新的评估协议，模拟不同采用率的多参与者竞争场景。

研究结果: 实验表明，当前大多数C-SEO方法效果有限，传统SEO策略更有效；随着采用者增加，整体收益下降，呈现零和博弈特性。

研究结论: C-SEO Bench为C-SEO方法提供了首个全面评估框架，揭示了现有方法的局限性，并强调传统SEO策略的优越性。

中文摘要: 大型语言模型（LLMs）正在将搜索引擎转变为对话搜索引擎（CSE），从而将搜索引擎优化（SEO）转变为对话搜索引擎优化（C-SEO）。目前已有专门修改网页文档以提高其在CSE响应中可见性的C-SEO方法，但这些方法仅在有限领域测试，且未考虑多参与者竞争场景。我们提出了C-SEO Bench，首个评估C-SEO方法在多任务、多领域及多参与者场景下的基准测试。我们涵盖问答和产品推荐两种任务，每个任务包含三个领域，并设计了新的评估协议，模拟不同采用率的多参与者竞争。实验结果表明，现有C-SEO方法大多无效，传统SEO策略在LLM环境下更有效。此外，随着C-SEO采用者增加，整体收益下降，问题呈现拥堵和零和特性。代码和数据已开源。

</details>


### [20] [Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey](https://arxiv.org/abs/2506.11102)
**中文标题：基于进化视角的LLM智能体评估：全面综述**

*Jiachen Zhu,Menghui Zhu,Renting Rui,Rong Shan,Congmin Zheng,Bo Chen,Yunjia Xi,Jianghao Lin,Weiwen Liu,Ruiming Tang,Yong Yu,Weinan Zhang*

主要分类: cs.CL

摘要简述: 本文从进化视角系统分析了大型语言模型（LLM）聊天机器人与AI智能体的区别，提出了五维区分框架，并分类整理了现有评估基准，为研究者提供了实用的参考指南。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估框架模糊了LLM聊天机器人与AI智能体的界限，导致研究者在选择基准时产生困惑。本文旨在填补这一空白，提供清晰的区分框架和评估方法论。

研究方法: 通过五维框架（复杂环境、多源指令、动态反馈、多模态感知和高级能力）区分AI智能体与LLM聊天机器人，并基于外部环境驱动力和内部能力对现有评估基准进行分类。

研究结果: 提出了清晰的评估框架和分类表，总结了当前趋势，并通过环境、智能体、评估者和指标四个关键视角展望了未来评估方法。

研究结论: 本文为研究者提供了实用的评估指南，有助于推动AI智能体评估领域的持续发展。

中文摘要: 大型语言模型（如GPT、Gemini和DeepSeek）的出现显著推动了自然语言处理的发展，催生了能够执行多样化语言任务的先进聊天机器人。从传统LLM聊天机器人向更高级AI智能体的转变是一个关键的进化步骤。然而，现有评估框架往往模糊了LLM聊天机器人与AI智能体的区别，导致研究者在选择合适基准时产生困惑。为填补这一空白，本文从进化视角系统分析了当前评估方法，提出了一个详细的分析框架，从五个关键维度（复杂环境、多源指令、动态反馈、多模态感知和高级能力）明确区分AI智能体与LLM聊天机器人。此外，我们基于外部环境驱动力和内部能力对现有评估基准进行了分类，并为每类列举了相关评估属性，以实用参考表的形式呈现。最后，我们通过环境、智能体、评估者和指标四个关键视角总结了当前趋势并展望了未来评估方法。研究结果为研究者提供了实用指导，有助于在AI智能体评估中明智选择和应用基准，从而推动这一快速演进研究领域的持续进步。

</details>


### [21] [You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model](https://arxiv.org/abs/2506.11103)
**中文标题：仅需微调一次：大语言模型的多样本上下文微调**

*Wenchong He,Liqian Peng,Zhe Jiang,Alex Go*

主要分类: cs.CL

摘要简述: 本文提出了一种名为ManyICL的新方法，通过多样本上下文微调显著缩小了与专用微调的性能差距，同时缓解了灾难性遗忘问题。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型（LLM）通过少样本上下文学习（ICL）能够同时处理多个下游任务，但其性能仍落后于为每个任务单独训练的专用微调模型。本文旨在通过多样本上下文微调（ManyICL）提升性能并解决效率问题。

研究方法: 提出ManyICL方法，将上下文学习扩展到多样本场景，并通过新的训练目标将上下文中的每个答案作为监督学习目标，从而将多样本示例从提示转变为自回归学习的目标。

研究结果: 实验表明，ManyICL在分类、摘要、问答、自然语言推理和数学等任务上显著优于零/少样本微调，接近专用微调的性能，同时有效缓解了灾难性遗忘问题。

研究结论: ManyICL通过多样本上下文微调显著提升了模型性能，接近专用微调水平，并解决了灾难性遗忘问题，为LLM的高效应用提供了新思路。

中文摘要: 大语言模型（LLM）具备出色的上下文学习（ICL）能力，无需任务特定微调即可同时处理多个下游任务。近期研究表明，即使是中等规模的LLM（如Mistral 7B、Gemma 7B和Llama-3 8B），也能通过一次性少样本上下文微调实现ICL。然而，这种方法仍落后于为每个任务单独训练的专用微调模型。
  本文提出了一种新方法——多样本上下文微调（ManyICL），通过将ICL扩展到多样本场景，显著缩小了这一性能差距。为了充分发挥ManyICL的潜力并解决处理长序列上下文示例的低效问题，我们提出了一种新的训练目标：不仅预测最终答案，还将上下文中的每个答案作为监督学习目标。这使多样本示例从提示转变为自回归学习的目标。
  通过在分类、摘要、问答、自然语言推理和数学等多样化下游任务上的广泛实验，我们证明ManyICL显著优于零/少样本微调，并接近专用微调的性能。此外，ManyICL显著缓解了零/少样本微调中常见的灾难性遗忘问题。代码将在发表后公开。

</details>


### [22] [DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration](https://arxiv.org/abs/2506.11104)
**中文标题：DAM：用于长上下文大语言模型推理加速的动态注意力掩码**

*Hanzhi Zhang,Heng Fan,Kewei Sha,Yan Huang,Yunhe Feng*

主要分类: cs.CL

摘要简述: 本文提出了一种动态稀疏注意力机制（DAM），通过自适应掩码解决长上下文LLM推理中的效率问题，无需预定义掩码结构或微调，显著降低计算开销的同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 长上下文理解对NLP应用至关重要，但传统Transformer的自注意力机制因二次复杂度效率低下。现有稀疏注意力方法使用静态掩码，无法捕捉异构注意力模式，导致长序列任务中性能下降。

研究方法: 提出动态稀疏注意力机制（DAM），在注意力图级别分配自适应掩码，保留各层和头的异构模式，无需预定义掩码结构或微调，同时保持计算效率。

研究结果: DAM在保持与全注意力模型高度一致的同时，显著减少内存和计算开销，为大规模LLM的实际部署提供了可行方案。

研究结论: DAM是一种高效且可扩展的动态稀疏注意力机制，能够在长上下文任务中实现高性能推理，无需牺牲检索准确性。

中文摘要: 长上下文理解对许多NLP应用至关重要，但由于自注意力的二次复杂度，Transformer在效率上存在瓶颈。稀疏注意力方法虽能缓解这一成本，但通常采用静态预定义掩码，无法捕捉异构注意力模式，导致长序列任务中的次优令牌交互，限制了适应性和检索准确性。本文提出了一种动态稀疏注意力机制，能够在注意力图级别分配自适应掩码，保留各层和头的异构模式。与现有方法不同，该方法无需微调和预定义掩码结构，同时保持计算效率。通过学习上下文感知的注意力结构，该方法与全注意力模型高度一致，确保性能损失最小化，同时减少内存和计算开销。这一方法为全注意力提供了一种可扩展的替代方案，使得大规模语言模型的实际部署成为可能，且无需牺牲检索性能。DAM代码已开源：https://github.com/HanzhiZhang-Ulrica/DAM。

</details>


### [23] [Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation](https://arxiv.org/abs/2506.11105)
**中文标题：通过输入驱动的显著性适应实现设备端医疗AI助手**

*Uttej Kallakurik,Edward Humes,Rithvik Jonna,Xiaomin Lin,Tinoosh Mohsenin*

主要分类: cs.CL

摘要简述: 本文提出了一种通过输入驱动的显著性适应优化大型语言模型（LLMs）的方法，使其能够在资源受限的边缘设备上实时运行，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在医疗场景中具有重要应用，但其庞大的规模难以在资源受限的边缘设备上实时部署。因此，需要一种高效的压缩方法，使LLMs能够在这些设备上高效运行。

研究方法: 通过测量领域特定数据的神经元显著性，该方法可以大幅剪枝不相关的神经元，减少模型规模。随后应用后训练量化进一步降低内存占用，并在医疗基准测试（如MedMCQA、MedQA和PubMedQA）上评估压缩模型的性能。

研究结果: 实验表明，压缩后的Gemma和LLaMA3模型在Jetson Orin Nano和Raspberry Pi 5等边缘设备上实现了实时、高效的推理，同时模型规模分别减少了50%和67%。

研究结论: 该方法成功地将大型语言模型压缩为适合边缘设备部署的轻量级版本，为医疗AI助手在资源受限环境中的应用提供了可行方案。

中文摘要: 大型语言模型（LLMs）在医疗场景中具有重要影响，但其规模过大，难以在实时、资源受限的边缘设备上部署。本文提出了一种新型医疗助手系统，通过通用压缩框架优化LLMs，使其适用于特定领域。通过测量领域特定数据的神经元显著性，我们的方法可以大幅剪枝不相关的神经元，在保持性能的同时减少模型规模。剪枝后，我们应用后训练量化进一步降低内存占用，并在MedMCQA、MedQA和PubMedQA等医疗基准测试中评估压缩模型。此外，我们还将压缩50%的Gemma和压缩67%的LLaMA3模型部署在Jetson Orin Nano（峰值功耗18.7W）和Raspberry Pi 5（峰值功耗6.3W）上，实现了在硬件约束下的实时、高效推理。

</details>


### [24] [Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking](https://arxiv.org/abs/2506.11106)
**中文标题：基于图的RAG增强：全局查询消歧与依赖感知重新排序**

*Ningyuan Li,Junrui Liu,Yi Shan,Minghui Huang,Tong Li*

主要分类: cs.CL

摘要简述: 当前基于图的检索增强生成（RAG）方法依赖实体提取和知识图谱检索，但可能忽略潜在关键信息，导致检索内容不相关或遗漏重要知识。PankRAG通过全局感知的分层查询解析和依赖感知的重新排序机制，显著提升了检索和生成的质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于图的RAG方法仅依赖实体提取，容易误解或遗漏潜在关键信息，导致检索结果不准确或矛盾，增加生成内容的幻觉风险。本文旨在解决这些问题，提出一种更全面的方法。

研究方法: PankRAG采用分层查询解析策略，构建多级解析路径以捕捉查询中的并行和顺序依赖关系，并通过依赖感知的重新排序机制优化检索结果，确保后续子问题的检索内容更丰富和准确。

研究结果: 实验表明，PankRAG在多个基准测试中均优于现有方法，证明了其鲁棒性和泛化能力。

研究结论: PankRAG通过全局查询解析和依赖感知的重新排序，显著提升了RAG的性能，为检索增强生成领域提供了新的解决方案。

中文摘要: 当前基于图的检索增强生成（RAG）方法通常从用户查询中提取实体，并利用预构建的知识图谱检索相关关系和元数据。然而，这种流程仅依赖实体级提取，可能导致潜在关键信息和关系的误解或遗漏。因此，检索内容可能不相关或矛盾，而重要知识可能被排除，加剧幻觉风险并降低生成响应的保真度。为解决这些限制，我们提出了PankRAG框架，结合了全局感知的分层查询解析策略和新型依赖感知重新排序机制。PankRAG首先构建多级解析路径，捕捉查询中的并行和顺序依赖关系，引导大型语言模型（LLM）进行结构化推理。随后，应用依赖感知重新排序器，利用解析子问题间的依赖结构，丰富并验证后续子问题的检索结果。实证评估表明，PankRAG在多个基准测试中均优于现有方法，凸显了其鲁棒性和泛化能力。

</details>


### [25] [History-Aware Cross-Attention Reinforcement: Self-Supervised Multi Turn and Chain-of-Thought Fine-Tuning with vLLM](https://arxiv.org/abs/2506.11108)
**中文标题：历史感知跨注意力强化：基于vLLM的自监督多轮对话与思维链微调**

*Andrew Kiruluta,Andreas Lemos,Priscilla Burity*

主要分类: cs.CL

摘要简述: 本文提出CAGSR-vLLM-MTC框架，扩展了自监督跨注意力引导强化学习（CAGSR），基于高性能vLLM运行时，支持多轮对话和思维链推理。通过异步捕获跨注意力权重和累积历史信号，优化了对话和推理任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有单轮对话和推理方法在多轮对话和复杂思维链任务中表现不足。本文旨在通过扩展CAGSR框架，结合vLLM的高性能运行时，提升多轮对话和思维链推理的能力。

研究方法: 1. 在vLLM的C++/CUDA内核中异步捕获每层每头的跨注意力权重；2. 将自监督奖励函数扩展到累积整个对话历史和思维链步骤的注意力信号；3. 引入基于熵的钳制机制，防止注意力过早集中在早期上下文。

研究结果: CAGSR-vLLM-MTC框架成功支持多轮对话和思维链推理任务，通过优化注意力信号累积和防止注意力崩溃，提升了模型性能。

研究结论: 本文提出的框架在多轮对话和思维链推理任务中表现出色，未来可扩展至多方对话和分层推理场景。

中文摘要: 我们提出了CAGSR-vLLM-MTC，这是自监督跨注意力引导强化（CAGSR）框架的扩展，现基于高性能vLLM运行时实现，旨在解决多轮对话和思维链推理任务。在原有单轮方法的基础上，我们首先在vLLM的C++/CUDA内核中异步捕获生成过程中每层每头的跨注意力权重。随后，我们将自监督奖励函数推广到累积整个对话历史和中间思维链步骤的注意力信号。我们讨论了实际权衡，包括基于熵的钳制机制以防止注意力过早集中在早期上下文，并展望了未来在多方对话和分层推理中的研究方向。

</details>


### [26] [Enhancing Large Language Models for Mobility Analytics with Semantic Location Tokenization](https://arxiv.org/abs/2506.11109)
**中文标题：通过语义位置标记化增强大语言模型的移动性分析能力**

*Yile Chen,Yicheng Tao,Yue Jiang,Shuai Liu,Han Yu,Gao Cong*

主要分类: cs.CL

摘要简述: 提出QT-Mob框架，通过语义位置标记化和多目标微调增强大语言模型在移动性分析中的表现，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在移动性分析中存在两大问题：位置语义表示不足（如离散ID）和大语言模型对移动信号建模不充分（如单一模板指令微调）。

研究方法: QT-Mob框架包含语义位置标记化模块，学习紧凑且语义丰富的标记表示位置，并通过多目标微调将标记与大语言模型内部表示对齐。

研究结果: 在三个真实数据集上的实验表明，QT-Mob在下一位置预测和移动恢复任务中表现优异，超越现有深度学习和基于大语言模型的方法。

研究结论: QT-Mob不仅提升了大语言模型对移动数据的理解能力，还为多种移动性分析任务提供了更通用的解决方案。

中文摘要: 基于位置服务的广泛应用产生了大量移动数据，为建模城市环境中的用户移动动态提供了重要机会。近期研究致力于将大语言模型（LLMs）应用于移动性分析，但现有方法存在两大局限：位置语义表示不足（如离散ID）和大语言模型对移动信号建模不充分（如单一模板指令微调）。为解决这些问题，我们提出QT-Mob框架，显著增强了大语言模型在移动性分析中的表现。QT-Mob引入位置标记化模块，学习紧凑且语义丰富的标记表示位置，保留上下文信息的同时确保与大语言模型的兼容性。此外，QT-Mob通过一系列互补微调目标，将学习的标记与大语言模型内部表示对齐，提升模型对序列移动模式和位置语义的理解。QT-Mob不仅增强了大语言模型对移动数据的解释能力，还为多种移动性分析任务提供了更通用的方法。在三个真实数据集上的实验表明，QT-Mob在下一位置预测和移动恢复任务中表现优异，超越现有深度学习和基于大语言模型的方法。

</details>


### [27] [AssertBench: A Benchmark for Evaluating Self-Assertion in Large Language Models](https://arxiv.org/abs/2506.11110)
**中文标题：AssertBench：评估大型语言模型中自我坚持能力的基准测试**

*Jaeho Lee,Atharv Chowdhary*

主要分类: cs.CL

摘要简述: AssertBench是一个评估大型语言模型（LLM）自我坚持能力的基准测试，通过对比模型在不同用户断言下的表现，衡量其是否能在事实一致的情况下坚持己见。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试主要关注LLM的事实一致性和修辞鲁棒性，但缺乏对用户方向性断言如何影响模型一致性的研究。AssertBench旨在填补这一空白，探究模型在面对用户矛盾断言时是否能坚持事实。

研究方法: AssertBench从FEVEROUS数据集中选取证据支持的事实，为每个事实构建两种用户断言（正确和错误），记录模型的同意程度和推理过程。通过分层分析模型在中性提示下的准确性，排除知识差异的干扰。

研究结果: AssertBench能够有效衡量LLM在面对用户矛盾断言时的自我坚持能力，揭示了模型在不同断言下的表现差异。

研究结论: AssertBench为评估LLM的自我坚持能力提供了标准化工具，有助于进一步研究模型在面对用户干扰时的稳定性。

中文摘要: 现有基准测试主要探究大型语言模型（LLM）的事实一致性和修辞鲁棒性，但关于用户对事实的方向性断言如何影响模型一致性仍存在知识空白。AssertBench通过从FEVEROUS事实验证数据集中选取证据支持的事实，为每个事实构建两种用户断言（一种声称事实正确，另一种声称事实错误），并记录模型的同意程度和推理过程。理想情况下，模型应坚持事实，而非因用户断言改变其判断。AssertBench通过分层分析模型在中性提示下的准确性，将断言引起的变异性与模型的事实知识区分开来。该基准测试旨在衡量LLM在面对用户对同一事实的矛盾断言时“坚持己见”的能力。完整源代码见https://github.com/achowd32/assert-bench。

</details>


### [28] [Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions](https://arxiv.org/abs/2506.11111)
**中文标题：评估与提升大语言模型的鲁棒性：综述与未来方向**

*Kun Zhang,Le Wu,Kui Yu,Guangyi Lv,Dacao Zhang*

主要分类: cs.CL

摘要简述: 本文综述了大语言模型（LLMs）的鲁棒性研究，从对抗鲁棒性、分布外鲁棒性和评估方法三个角度进行系统梳理，并探讨未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）的广泛应用，其鲁棒性问题日益凸显。本文旨在全面梳理LLMs鲁棒性的相关概念、方法及挑战，为社区提供参考。

研究方法: 论文首先定义了LLM鲁棒性，并根据输入扰动类型分为三类：1）对抗鲁棒性（处理故意操纵的输入）；2）分布外鲁棒性（应对意外场景）；3）鲁棒性评估（总结新数据集、指标和工具）。

研究结果: 论文系统总结了LLM鲁棒性的研究现状，提出了未来研究方向，并整理了一个易于检索的项目资源库。

研究结论: 本文为LLM鲁棒性研究提供了全面综述，指出了未来研究的机会和方向，并支持社区进一步探索。

中文摘要: 近年来，大语言模型（LLMs）因其理解和生成自然语言的能力而受到广泛关注。随着其快速发展和广泛应用（如智能代理、具身智能等），LLMs的鲁棒性问题日益受到重视。作为许多AI应用的核心，LLMs的鲁棒性要求模型不仅能生成一致的内容，还需在处理意外场景（如有毒提示、有限噪声数据、分布外应用等）时确保内容的正确性和稳定性。本文对LLM鲁棒性进行了全面综述，旨在为该领域提供概念和方法的系统性术语，并推动社区发展。具体而言，我们首先给出了LLM鲁棒性的正式定义，并介绍了本文的收集协议。随后，基于输入扰动的类型，我们从以下角度组织综述：1）对抗鲁棒性：处理故意操纵的提示（如噪声提示、长上下文、数据攻击等）；2）分布外鲁棒性：应对意外真实场景（如分布外检测、零样本迁移、幻觉等）；3）鲁棒性评估：总结用于验证LLM鲁棒性的新数据集、指标和工具。在回顾了各角度的代表性工作后，我们讨论并强调了该领域的未来机会和研究方向。同时，我们还整理了相关文献，并提供了一个易于检索的项目（https://github.com/zhangkunzk/Awesome-LLM-Robustness-papers）以支持社区。

</details>


### [29] [Manifesto from Dagstuhl Perspectives Workshop 24352 -- Conversational Agents: A Framework for Evaluation (CAFE)](https://arxiv.org/abs/2506.11112)
**中文标题：Dagstuhl视角研讨会24352宣言——对话式代理：评估框架（CAFE）**

*Christine Bauer,Li Chen,Nicola Ferro,Norbert Fuhr,Avishek Anand,Timo Breuer,Guglielmo Faggioli,Ophir Frieder,Hideo Joho,Jussi Karlgren,Johannes Kiesel,Bart P. Knijnenburg,Aldo Lipani,Lien Michiels,Andrea Papenmeier,Maria Soledad Pera,Mark Sanderson,Scott Sanner,Benno Stein,Johanne R. Trippas,Karin Verspoor,Martijn C Willemsen*

主要分类: cs.CL

摘要简述: 本文提出了一个用于评估对话式信息访问（CONIAC）系统的框架CAFE，包含六个核心组件，旨在为相关系统的评估提供标准化方法。


<details>
  <summary>详细信息</summary>
研究动机: 对话式信息访问（CONIAC）系统的发展需要一套标准化的评估框架，以确保其能够满足用户需求并提升性能。本文旨在填补这一空白，提出CAFE框架。

研究方法: 通过研讨会深入讨论CONIAC的定义及其独特特征，提出一个抽象的世界模型，并定义CAFE框架，包含六个主要组件：系统目标、用户任务、用户特征、评估标准、评估方法和量化指标。

研究结果: 成功定义了CAFE框架，为CONIAC系统的评估提供了清晰的结构化方法，涵盖从目标设定到量化分析的完整流程。

研究结论: CAFE框架为对话式信息访问系统的评估提供了标准化工具，有助于推动该领域的进一步发展。

中文摘要: 在研讨会期间，我们深入探讨了对话式信息访问（CONIAC）的定义及其独特特征，提出了一个抽象的世界模型，并定义了用于评估CONIAC系统的对话式代理评估框架（CAFE）。该框架包含六个主要组成部分：1）系统利益相关者的目标，2）评估中需研究的用户任务，3）执行任务的用户特征，4）需考虑的评估标准，5）应用的评估方法，以及6）所选定量标准的衡量指标。

</details>


### [30] [Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks](https://arxiv.org/abs/2506.11113)
**中文标题：突破评审者：评估大型语言模型在文本对抗攻击下自动同行评审的脆弱性**

*Tzu-Ling Lin,Wei-Chih Chen,Teng-Fang Hsiao,Hou-I Liu,Ya-Hsin Yeh,Yu Kai Chan,Wen-Sheng Lien,Po-Yen Kuo,Philip S. Yu,Hong-Han Shuai*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型（LLMs）在自动同行评审中的脆弱性，发现文本对抗攻击会显著影响其可靠性，并提出了缓解策略。


<details>
  <summary>详细信息</summary>
研究动机: 同行评审对学术质量至关重要，但日益增长的投稿量增加了评审负担。尽管LLMs能提供帮助，但其对文本对抗攻击的脆弱性引发了可靠性担忧。本文旨在评估LLMs在自动评审中的稳健性。

研究方法: 研究聚焦三个问题：1) LLMs生成评审与人类评审的对比；2) 对抗攻击对LLM生成评审的影响；3) 基于LLM评审的挑战与缓解策略。通过实验评估LLMs在对抗攻击下的表现。

研究结果: 实验表明，文本操纵会显著扭曲LLMs的评审结果，揭示了其脆弱性。研究提供了LLMs在自动评审中的全面评估，并分析了其对对抗攻击的稳健性。

研究结论: 研究强调了解决对抗风险的重要性，以确保AI能增强而非损害学术交流的完整性。

中文摘要: 同行评审对维持学术质量至关重要，但日益增长的投稿量给评审者带来了巨大负担。大型语言模型（LLMs）在这一过程中具有潜在帮助，但其对文本对抗攻击的脆弱性引发了可靠性问题。本文研究了LLMs作为自动评审者在对抗攻击下的稳健性，聚焦三个关键问题：1) LLMs生成评审与人类评审的对比；2) 对抗攻击对LLM生成评审可靠性的影响；3) 基于LLM评审的挑战与潜在缓解策略。评估揭示了显著脆弱性，文本操纵会扭曲LLMs的评审结果。我们提供了LLMs在自动同行评审中的全面评估，并分析了其对对抗攻击的稳健性。研究结果强调了解决对抗风险的重要性，以确保AI能增强而非损害学术交流的完整性。

</details>


### [31] [KokushiMD-10: Benchmark for Evaluating Large Language Models on Ten Japanese National Healthcare Licensing Examinations](https://arxiv.org/abs/2506.11114)
**中文标题：KokushiMD-10：基于十项日本国家医疗执照考试的大型语言模型评估基准**

*Junyu Liu,Kaiqi Yan,Tianyang Wang,Qian Niu,Momoko Nagai-Tanima,Tomoki Aoyama*

主要分类: cs.CL

摘要简述: KokushiMD-10是首个基于日本十项国家医疗执照考试的多模态基准，用于评估大型语言模型（LLMs）在医疗领域的表现。该基准包含11588道真实考题，涵盖医学、牙科、护理等多个领域，并引入临床图像和专家标注的推理过程。测试了30多种先进LLMs，结果显示尚无模型能全面达标，突显医疗AI的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在医疗执照考试中表现突出，但现有基准多为文本化、英语中心且集中于医学领域，无法全面评估多模态推理和跨领域医疗知识。因此，需要一种多语言、多模态的基准来填补这一空白。

研究方法: 研究团队构建了KokushiMD-10基准，基于日本十项国家医疗执照考试，包含11588道真实考题，涵盖医学、牙科、护理、药学等多个领域。考题包含临床图像和专家标注的推理过程，用于评估文本和视觉推理能力。测试了包括GPT-4o、Claude 3.5和Gemini在内的30多种先进LLMs。

研究结果: 测试结果显示，尽管部分模型表现优异，但尚无模型能在所有领域达到通过标准，突显了医疗AI在多语言和多模态任务中的挑战。

研究结论: KokushiMD-10为评估和推动多语言、多模态医疗AI提供了全面且语言基础扎实的资源，未来需进一步优化模型以应对复杂临床任务。

中文摘要: 近年来，大型语言模型（LLMs）在医疗执照考试中表现出色，但现有基准多为文本化、英语中心且集中于医学领域，难以全面评估多模态推理和跨领域医疗知识。为此，我们推出了KokushiMD-10，这是首个基于十项日本国家医疗执照考试的多模态基准，涵盖医学、牙科、护理、药学等多个领域。该基准包含11588道真实考题，结合临床图像和专家标注的推理过程，用于评估文本和视觉推理能力。我们对包括GPT-4o、Claude 3.5和Gemini在内的30多种先进LLMs进行了测试。结果显示，尽管部分模型表现优异，但尚无模型能全面达标，突显了医疗AI的挑战。KokushiMD-10为评估和推动多语言、多模态医疗AI提供了全面且语言基础扎实的资源。

</details>


### [32] [Incorporating Domain Knowledge into Materials Tokenization](https://arxiv.org/abs/2506.11115)
**中文标题：将领域知识融入材料分词**

*Yerim Oh,Jun-Hyung Park,Junho Kim,SungHo Kim,SangKeun Lee*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MATTER的新型分词方法，通过融入材料科学领域知识，解决了传统自然语言处理分词方法在材料科学文本中导致的过度碎片化和语义丢失问题。实验表明，MATTER在生成和分类任务中分别提升了4%和2%的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型在材料科学中的应用日益增多，但传统的基于频率的分词方法（源自自然语言处理）常导致材料概念的过度碎片化和语义丢失，无法保持其结构和语义完整性。因此，需要一种能够结合领域知识的分词方法来解决这一问题。

研究方法: MATTER是一种新型分词方法，基于材料知识库训练的MatDetector和一种优先合并材料概念的重新排序方法。该方法在分词过程中保持材料概念的结构完整性，避免碎片化，确保语义完整。

研究结果: 实验结果表明，MATTER在生成和分类任务中分别实现了4%和2%的平均性能提升，显著优于现有分词方法。

研究结论: MATTER通过融入领域知识，显著提升了材料科学文本的分词效果，证明了领域知识在科学文本处理中的重要性。代码已开源。

中文摘要: 尽管语言模型在材料科学中的应用日益广泛，但传统模型依赖于最初为自然语言处理开发的基于频率的分词方法。然而，这些方法常导致过度碎片化和语义丢失，无法保持材料概念的结构和语义完整性。为解决这一问题，我们提出了MATTER，一种将材料知识融入分词的新型方法。基于我们材料知识库训练的MatDetector和一种优先合并材料概念的重新排序方法，MATTER在分词过程中保持了材料概念的结构完整性，避免了碎片化，确保其语义完整。实验结果表明，MATTER在生成和分类任务中分别实现了4%和2%的平均性能提升，优于现有分词方法。这些结果凸显了领域知识在科学文本分词策略中的重要性。我们的代码可在https://github.com/yerimoh/MATTER获取。

</details>


### [33] [Infinity Instruct: Scaling Instruction Selection and Synthesis to Enhance Language Models](https://arxiv.org/abs/2506.11116)
**中文标题：Infinity Instruct：扩展指令选择与合成以增强语言模型**

*Jijie Li,Li Du,Hanyu Zhao,Bo-wen Zhang,Liangdong Wang,Boyan Gao,Guang Liu,Yonghua Lin*

主要分类: cs.CL

摘要简述: 本文提出了Infinity-Instruct，一个高质量指令数据集，通过两阶段流程增强语言模型的基础和聊天能力，显著提升了开源模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有开源指令数据集多集中于狭窄领域（如数学或编程），限制了模型的泛化能力，与专有模型存在差距。本文旨在通过高质量指令数据集缩小这一差距。

研究方法: 采用两阶段流程：第一阶段从1亿样本中筛选出740万高质量基础指令（InfInstruct-F-7.4M）；第二阶段通过指令选择、进化和诊断过滤合成150万高质量聊天指令（InfInstruct-G-1.5M）。

研究结果: 实验表明，基于Infinity-Instruct微调的开源模型（如Mistral、LLaMA等）在基础和指令跟随任务中表现显著提升，InfInstruct-LLaMA3.1-70B在指令任务上超越GPT-4-0314 8.6%。

研究结论: Infinity-Instruct展示了基础与聊天训练的协同效应，为语言模型开发提供了新思路，数据集和代码已开源。

中文摘要: 大型语言模型（LLM）在实际应用中表现出色，但现有开源指令数据集多集中于狭窄领域（如数学或编程），限制了泛化能力并拉大了与专有模型的差距。为缩小这一差距，我们提出了Infinity-Instruct，一个通过两阶段流程设计的高质量指令数据集，旨在增强LLM的基础和聊天能力。第一阶段，我们从1亿样本中筛选出740万高质量基础指令（InfInstruct-F-7.4M）；第二阶段，通过指令选择、进化和诊断过滤合成了150万高质量聊天指令（InfInstruct-G-1.5M）。我们通过微调多个开源模型（如Mistral、LLaMA、Qwen和Yi）对Infinity-Instruct进行了实证评估，发现其在基础和指令跟随任务中均显著提升，持续超越官方指令调优版本。值得注意的是，InfInstruct-LLaMA3.1-70B在指令任务上超越GPT-4-0314 8.6%，同时基础性能相当。这些结果凸显了基础与聊天训练的协同效应，为LLM的全面发展提供了新见解。我们的数据集和代码已公开发布。

</details>


### [34] [ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research](https://arxiv.org/abs/2506.11117)
**中文标题：ScIRGen：为科学研究合成真实且大规模的RAG数据集**

*Junyong Lin,Lu Dai,Ruiqian Han,Yijie Sui,Ruilin Wang,Xingliang Sun,Qinglin Wu,Min Feng,Hao Liu,Hui Xiong*

主要分类: cs.CL

摘要简述: ScIRGen是一个用于生成科学QA与检索数据集的框架，旨在更准确地反映科研人员的信息需求，并创建了一个包含6.1万条问答对的大规模数据集ScIRGen-Geo。


<details>
  <summary>详细信息</summary>
研究动机: 现有科学检索和问答数据集通常处理简单问题，与真实科研需求不符。ScIRGen旨在填补这一空白，生成更符合科研人员复杂信息需求的数据集。

研究方法: 1. 设计基于学术论文的数据集信息提取方法；2. 使用认知分类法生成高质量问题；3. 基于LLM困惑度变化自动筛选合成答案。

研究结果: 生成了包含6.1万条问答对的ScIRGen-Geo数据集，并验证了现有方法在处理复杂问题时仍存在推理不足的问题。

研究结论: ScIRGen为支持科学社区复杂信息需求的工具开发提供了重要基础。

中文摘要: 科研人员需要大量数据集信息以有效评估和发展理论与方法。这些信息需求隐含在特定研究任务中，而非显式表达于搜索查询中。然而，现有科学检索和问答数据集通常处理简单问题，与真实研究问题的分布不符。为填补这一空白，我们开发了ScIRGen，一个更准确反映专业科研人员信息需求的科学QA与检索数据集生成框架，并用其创建了一个包含真实查询、数据集和论文的大规模科学检索增强生成（RAG）数据集。技术上，我们设计了一种基于学术论文的数据集信息提取方法以增强数据集表示，并提出了一种使用认知分类法的问题生成框架以确保合成问题的质量。我们还设计了一种基于LLM困惑度变化的自动筛选合成答案的方法，与人类对答案有效性的判断高度一致。这些方法共同促成了包含6.1万条问答对的ScIRGen-Geo数据集的创建。我们在ScIRGen-Geo数据集上对代表性方法的问答和检索能力进行了基准测试，发现现有方法在处理复杂问题时仍存在推理不足的问题。这项工作推动了支持科学社区复杂信息需求的更先进工具的开发。

</details>


### [35] [Benchmarking Foundation Speech and Language Models for Alzheimer's Disease and Related Dementia Detection from Spontaneous Speech](https://arxiv.org/abs/2506.11119)
**中文标题：基于基础语音和语言模型的阿尔茨海默病及相关痴呆自发语音检测基准测试**

*Jingyu Li,Lingchao Mao,Hairong Wang,Zhendong Wang,Xi Mao,Xuelei Sherry Ni*

主要分类: cs.CL

摘要简述: 本研究通过基准测试多种开源语音和语言模型，利用自发语音数据检测阿尔茨海默病及相关痴呆（ADRD）。结果显示，Whisper-medium语音模型和带停顿标注的BERT语言模型表现最佳，表明基于声学特征的方法具有早期检测潜力。


<details>
  <summary>详细信息</summary>
研究动机: 阿尔茨海默病及相关痴呆（ADRD）的早期检测对及时干预至关重要。自发语音中的声学和语言标记可作为非侵入性生物标志物，而预训练的大规模基础模型能提取高维特征，为ADRD检测提供新方法。

研究方法: 研究使用PREPARE Challenge数据集，包含1600多名参与者的录音，分为健康对照组（HC）、轻度认知障碍（MCI）和阿尔茨海默病（AD）。筛选后保留703例HC、81例MCI和405例AD。测试多种开源语音和语言模型，分类三种认知状态。

研究结果: Whisper-medium语音模型表现最佳（准确率0.731，AUC 0.802），BERT语言模型（带停顿标注）次之（准确率0.662，AUC 0.744）。基于自动语音识别（ASR）的声学特征优于其他方法，停顿模式等非语义特征提升文本分类效果。

研究结论: 研究提出了一种基于基础模型的基准测试框架，证明声学方法（尤其是ASR衍生特征）在ADRD早期检测中具有可扩展性、非侵入性和成本效益的潜力。

中文摘要: 背景：阿尔茨海默病及相关痴呆（ADRD）是进行性神经退行性疾病，早期检测对及时干预至关重要。自发语音中的声学和语言标记可作为非侵入性生物标志物。预训练的基础模型能生成高维嵌入，编码上下文和声学特征。
方法：使用PREPARE Challenge数据集，包含1600多名参与者的录音，分为健康对照组（HC）、轻度认知障碍（MCI）和阿尔茨海默病（AD）。排除非英语、非自发或低质量录音后，最终数据集包括703例HC（59.13%）、81例MCI（6.81%）和405例AD（34.06%）。测试多种开源语音和语言模型，分类三种认知状态。
结果：Whisper-medium语音模型表现最佳（准确率0.731，AUC 0.802），BERT语言模型（带停顿标注）次之（准确率0.662，AUC 0.744）。基于ASR的声学特征优于其他方法，停顿模式等非语义特征提升文本分类效果。
结论：研究提出了一种基于基础模型的基准测试框架，证明声学方法（尤其是ASR衍生特征）在ADRD早期检测中具有可扩展性、非侵入性和成本效益的潜力。

</details>


### [36] [SDMPrune: Self-Distillation MLP Pruning for Efficient Large Language Models](https://arxiv.org/abs/2506.11120)
**中文标题：SDMPrune：自蒸馏MLP剪枝用于高效大型语言模型**

*Hourun Zhu,Chengchao Shen*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SDMPrune的自蒸馏MLP剪枝方法，用于高效压缩大型语言模型（LLMs）。通过引入自蒸馏损失和专注于MLP模块的剪枝，显著减少了模型参数，同时保持了生成能力。实验表明，该方法在零样本基准测试中优于现有剪枝方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）表现出色，但其部署成本高昂。现有的基于梯度的剪枝方法在压缩LLMs时忽略了生成能力的关键信息。为了解决这一问题，作者提出在剪枝阶段引入自蒸馏损失，以充分利用原始模型的预测信息。

研究方法: 方法包括在剪枝阶段引入自蒸馏损失，以获取更准确的梯度信息。此外，研究发现MLP模块对模型预测的敏感性较低，因此专注于剪枝MLP模块，显著减少了模型参数。

研究结果: 实验结果表明，该方法在广泛的零样本基准测试中显著优于现有剪枝方法，并在1B规模的开放源代码LLMs中表现出色。

研究结论: SDMPrune方法通过自蒸馏和MLP剪枝，实现了对大型语言模型的高效压缩，同时保持了其生成能力，为实际部署提供了可行的解决方案。

中文摘要: 尽管大型语言模型（LLMs）表现出色，但其部署成本高昂。为了压缩LLMs，基于梯度的剪枝方法显示出良好的效果。然而，这些方法中使用独热标签的梯度计算忽略了其他词的潜在预测，从而丢失了原始模型生成能力的关键信息。为解决这一问题，我们在剪枝阶段（而非训练后）引入自蒸馏损失，以充分利用原始模型的预测，从而获得更准确的梯度信息用于剪枝。此外，我们发现，与注意力模块相比，LLM的预测对多层感知机（MLP）模块的敏感性较低，而MLP模块占据了超过5倍的参数（如LLaMA3.2-1.2B）。因此，我们专注于MLP模块的剪枝，以显著压缩LLM而不明显降低性能。在广泛的零样本基准测试中，实验结果表明我们的方法显著优于现有剪枝方法。此外，我们的方法在1B规模的开放源代码LLMs中表现出色。源代码和训练权重可在https://github.com/visresearch/SDMPrune获取。

</details>


### [37] [SUTA-LM: Bridging Test-Time Adaptation and Language Model Rescoring for Robust ASR](https://arxiv.org/abs/2506.11121)
**中文标题：SUTA-LM：桥接测试时适应与语言模型重评分以实现鲁棒ASR**

*Wei-Ping Huang,Guan-Ting Lin,Hung-yi Lee*

主要分类: cs.CL

摘要简述: 本文提出SUTA-LM方法，通过结合测试时适应（TTA）和语言模型重评分，解决了两者结合时的干扰问题，提升了ASR在多样化领域的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管端到端ASR取得了进展，但实际应用中的领域不匹配仍会导致性能下降。测试时适应（TTA）和语言模型重评分的结合存在干扰问题，本文旨在解决这一挑战。

研究方法: SUTA-LM扩展了基于熵最小化的TTA方法SUTA，引入自动步长选择机制，结合声学和语言信息进行控制性适应，随后通过语言模型重评分优化输出。

研究结果: 在18个多样化ASR数据集上的实验表明，SUTA-LM在广泛领域中均取得了鲁棒的性能提升。

研究结论: SUTA-LM通过有效结合TTA和语言模型重评分，解决了干扰问题，显著提升了ASR的鲁棒性和适应性。

中文摘要: 尽管端到端ASR取得了进展，但现实中的领域不匹配仍会导致性能下降，测试时适应（TTA）旨在通过推理时调整模型来缓解这一问题。近期研究探索了将TTA与外部语言模型结合的方法，如束搜索重评分或生成式错误校正。本文发现了一个此前被忽视的挑战：TTA可能干扰语言模型重评分，揭示了两种方法有效结合的非平凡性。基于这一洞察，我们提出了SUTA-LM，这是基于熵最小化的TTA方法SUTA的一个简单而有效的扩展，结合了语言模型重评分。SUTA-LM首先通过利用声学和语言信息的自动步长选择机制进行控制性适应，随后通过语言模型重评分优化输出。在18个多样化ASR数据集上的实验表明，SUTA-LM在广泛领域中均取得了鲁棒的结果。

</details>


### [38] [ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams](https://arxiv.org/abs/2506.11125)
**中文标题：ASRJam：防止自动化电话诈骗的人类友好型AI语音干扰技术**

*Freddie Grabovski,Gilad Gressel,Yisroel Mirsky*

主要分类: cs.CL

摘要简述: 本文提出ASRJam和EchoGuard，通过注入对抗性扰动破坏自动语音识别（ASR）以阻止电话诈骗，同时不影响人类通话体验。EchoGuard利用自然失真（如回声）实现高效且用户友好的防御。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）与文本转语音（TTS）和自动语音识别（ASR）的结合，语音钓鱼诈骗日益猖獗。攻击者利用这些技术实现规模化诈骗，对安全构成严重威胁。作者发现ASR转录是诈骗链条中最脆弱的环节，因此提出一种主动防御框架。

研究方法: ASRJam通过向受害者音频中注入对抗性扰动，破坏攻击者的ASR系统，从而阻断诈骗反馈循环。EchoGuard则进一步提出一种新型干扰器，利用回声等自然失真干扰ASR，但对人类通话体验影响较小。作者通过39人用户研究评估了EchoGuard的实用性和效果。

研究结果: 实验结果表明，EchoGuard在破坏ASR的同时保持了最佳的人类通话体验，综合效用优于其他三种先进攻击方法。

研究结论: ASRJam和EchoGuard为防范自动化电话诈骗提供了高效且用户友好的解决方案，尤其EchoGuard在实用性和用户体验上表现突出。

中文摘要: 大型语言模型（LLMs）与文本转语音（TTS）和自动语音识别（ASR）的结合，正被广泛用于自动化语音钓鱼（vishing）诈骗。这些系统具有高度可扩展性和欺骗性，对安全构成重大威胁。我们发现ASR转录是诈骗链条中最脆弱的环节，并提出了ASRJam，一种主动防御框架，通过向受害者音频中注入对抗性扰动来破坏攻击者的ASR系统，从而阻断诈骗反馈循环，同时不影响人类通话者的理解。现有的对抗性音频技术通常令人不适且难以实时应用，因此我们还提出了EchoGuard，一种新型干扰器，利用回声等自然失真干扰ASR，但对人类通话体验影响较小。为评估EchoGuard的效果和实用性，我们进行了39人用户研究，将其与三种先进攻击方法进行比较。结果显示，EchoGuard的综合效用最高，在破坏ASR和保持人类通话体验方面表现最佳。

</details>


### [39] [GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions](https://arxiv.org/abs/2506.11127)
**中文标题：GUIRoboTron-Speech：基于语音指令的自动化GUI代理**

*Wenkang Han,Zhixiong Zeng,Jing Huang,Shu Jiang,Liming Zheng,Longrong Yang,Haibo Qiu,Chang Yao,Jingyuan Chen,Lin Ma*

主要分类: cs.CL

摘要简述: 本文提出GUIRoboTron-Speech，首个基于语音指令的端到端自主GUI代理，通过语音和屏幕截图直接预测操作，解决了文本指令在无障碍和便利性上的限制。


<details>
  <summary>详细信息</summary>
研究动机: 当前GUI代理主要依赖文本指令，在无手操作场景中限制了其可访问性和便利性。为解决这一问题，研究者提出首个直接接受语音指令的GUI代理，旨在提升交互的自然性和实用性。

研究方法: 研究首先利用随机音色的文本转语音模型生成高质量语音指令数据集，随后通过渐进式训练和启发式混合指令策略，解决预训练模型中的模态不平衡问题，最终开发出GUIRoboTron-Speech。

研究结果: 在多个基准数据集上的实验表明，GUIRoboTron-Speech表现优异，验证了语音作为GUI代理指令模态的强大潜力和广泛适用性。

研究结论: GUIRoboTron-Speech的成功展示了语音指令在GUI代理中的巨大潜力，为未来人机交互提供了新的可能性。

中文摘要: 图形用户界面（GUI）的自主代理正在革新人机交互，但其对文本指令的依赖在无障碍和便利性上存在局限，尤其是在无手操作场景中。为解决这一问题，我们提出GUIRoboTron-Speech，首个端到端自主GUI代理，可直接接受语音指令和设备屏幕截图以预测操作。面对语音GUI代理数据集的稀缺，我们首先利用随机音色的文本转语音（TTS）模型将现有文本指令转换为高质量语音指令用于训练。随后通过渐进式训练和规划阶段开发GUIRoboTron-Speech的能力。关键贡献是一种启发式混合指令训练策略，旨在缓解预训练基础模型中的模态不平衡问题。在多个基准数据集上的全面实验验证了GUIRoboTron-Speech的稳健和卓越性能，展示了语音作为驱动GUI代理的有效指令模态的巨大潜力和广泛适用性。我们的代码和数据集可在https://github.com/GUIRoboTron/GUIRoboTron-Speech获取。

</details>


### [40] [Stronger Language Models Produce More Human-Like Errors](https://arxiv.org/abs/2506.11128)
**中文标题：更强的语言模型产生更接近人类的错误**

*Andrew Keenan Richardson,Ryan Othniel Kearns,Sean Moss,Vincent Wang-Mascianica,Philipp Koralus*

主要分类: cs.CL

摘要简述: 研究发现，随着语言模型能力的提升，其错误模式越来越接近人类的推理误区，而非完全理性。


<details>
  <summary>详细信息</summary>
研究动机: 探讨语言模型在能力提升过程中是否逐渐接近人类的推理模式，尤其是错误模式。

研究方法: 使用Erotetic Theory of Reasoning (ETR)框架和PyETR工具生成逻辑推理问题，评估38个语言模型在383个任务中的表现。

研究结果: 模型能力越强，其错误答案与ETR预测的人类误区一致性越高（ρ=0.360, p=0.0265），且错误率与模型能力无关。

研究结论: 语言模型的错误模式逐渐趋近人类，而非完全理性，挑战了模型规模扩大自然获得规范理性的观点。

中文摘要: 语言模型在能力提升过程中是否会趋近人类的推理模式？我们提供了令人惊讶的证据：尽管模型的整体推理能力随着复杂度的提升而增强，但其错误的性质却越来越接近可预测的人类推理误区——这是一种此前未观察到的逆向缩放现象。为研究这一问题，我们应用了Erotetic Theory of Reasoning (ETR)，这是一种具有实证支持的认知框架，用于预测人类推理结果。通过开源工具PyETR，我们生成了人类容易出错的逻辑推理问题，并评估了38个语言模型在383个推理任务中的表现。分析表明，随着模型通用能力的提升（以Chatbot Arena评分为衡量标准），其错误答案中与ETR预测的人类误区一致的比例趋于增加（ρ=0.360, p=0.0265）。值得注意的是，由于我们未观察到模型复杂度与逻辑正确性之间的相关性，这种错误模式向人类趋近的现象与错误率无关。这些发现挑战了当前观点，即语言模型规模的扩大自然会获得规范理性，反而表明模型趋近于人类认知，包括我们特有的偏见和局限性。我们进一步通过展示语言模型推理中的顺序效应证实了这一点。

</details>


### [41] [Trustworthy AI for Medicine: Continuous Hallucination Detection and Elimination with CHECK](https://arxiv.org/abs/2506.11129)
**中文标题：医疗领域的可信AI：基于CHECK的持续幻觉检测与消除**

*Carlos Garcia-Fernandez,Luis Felipe,Monique Shotande,Muntasir Zitu,Aakash Tripathi,Ghulam Rasool,Issam El Naqa,Vivek Rudrapatna,Gilmer Valdes*

主要分类: cs.CL

摘要简述: CHECK是一种连续学习框架，通过结合结构化临床数据库和信息论分类器，显著降低大型语言模型在医疗领域的幻觉率，使其达到临床可用标准。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）在医疗领域展现出潜力，但其幻觉问题严重阻碍了临床应用。为了解决这一问题，研究团队开发了CHECK框架，旨在通过持续学习和信息论方法检测并消除幻觉。

研究方法: CHECK框架整合了结构化临床数据库和信息论分类器，用于检测事实性和推理性幻觉。通过利用幻觉概率指导GPT-4o的优化，并合理分配计算资源，CHECK显著提升了模型的性能。

研究结果: 在1500个关键临床试验问题的评估中，CHECK将LLama3.3-70B-Instruct的幻觉率从31%降至0.3%，并在MedQA（USMLE）和HealthBench等医学基准测试中实现了0.95-0.96的AUC值。此外，CHECK还将USMLE通过率提升了5个百分点，达到92.1%。

研究结论: CHECK通过将幻觉率抑制在临床可接受的误差阈值以下，为医疗及其他高风险领域安全部署大型语言模型提供了可扩展的基础。

中文摘要: 大型语言模型（LLMs）在医疗领域展现出潜力，但幻觉问题仍是临床应用的主要障碍。我们提出了CHECK，一种连续学习框架，通过整合结构化临床数据库和信息论分类器，检测事实性和推理性幻觉。在100项关键临床试验的1500个问题评估中，CHECK将LLama3.3-70B-Instruct的幻觉率从31%降至0.3%，使开源模型达到业界领先水平。其分类器在医学基准测试中表现出色，AUC值达到0.95-0.96，包括MedQA（USMLE）和HealthBench的多轮医学问答测试。通过利用幻觉概率指导GPT-4o的优化并合理分配计算资源，CHECK将USMLE通过率提升了5个百分点，达到92.1%。通过将幻觉率抑制在临床可接受的误差阈值以下，CHECK为医疗及其他高风险领域安全部署LLM提供了可扩展的基础。

</details>


### [42] [A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data](https://arxiv.org/abs/2506.11130)
**中文标题：利用TTS合成数据增强ASR的自优化框架**

*Cheng Kang Chou,Chan-Jan Hsu,Ho-Lam Chung,Liang-Hsuan Tseng,Hsi-Chun Cheng,Yu-Kuan Fu,Kuan Po Huang,Hung-Yi Lee*

主要分类: cs.CL

摘要简述: 提出一种自优化框架，利用未标注数据和TTS合成数据提升ASR性能，实验显示在台湾普通话任务中显著降低错误率。


<details>
  <summary>详细信息</summary>
研究动机: 在低资源或特定领域场景下，标注数据稀缺且昂贵，传统ASR模型性能受限。本文旨在通过自优化框架，利用未标注数据和TTS技术提升ASR性能。

研究方法: 1. 使用现有ASR模型为未标注语音生成伪标签；2. 利用伪标签训练高保真TTS系统；3. 将TTS合成的语音-文本对反馈至ASR模型，形成闭环自优化循环。

研究结果: 在台湾普通话任务中，Twister模型（基于Whisper-large-v2优化）相比Whisper，普通话错误率降低20%，普通话-英语混合任务错误率降低50%。

研究结论: 该框架为低资源或特定领域ASR性能提升提供了有效途径，优于传统伪标签自蒸馏方法。

中文摘要: 我们提出了一种自优化框架，仅利用未标注数据集即可提升ASR性能。该过程首先通过现有ASR模型为未标注语音生成伪标签，随后利用这些伪标签训练高保真文本转语音（TTS）系统。接着，合成的语音-文本对被反馈至原始ASR系统中，完成闭环自优化循环。我们在台湾普通话语音任务中验证了该框架的有效性。通过利用6,000小时的未标注语音、适量文本数据及AI模型生成的合成内容，我们将Whisper-large-v2优化为专用模型Twister。Twister在普通话任务中错误率降低20%，在普通话-英语混合任务中错误率降低50%，显著优于Whisper。结果表明，该框架是伪标签自蒸馏方法的强有力替代方案，并为低资源或特定领域ASR性能提升提供了实用路径。

</details>


### [43] [Large Language Models and Emergence: A Complex Systems Perspective](https://arxiv.org/abs/2506.11135)
**中文标题：大语言模型与涌现：复杂系统视角**

*David C. Krakauer,John W. Krakauer,Melanie Mitchell*

主要分类: cs.CL

摘要简述: 本文探讨大语言模型是否展现涌现能力及其智能，从复杂系统视角分析涌现现象与智能的关系。


<details>
  <summary>详细信息</summary>
研究动机: 涌现是复杂科学中的核心概念，描述多体系统如何展现新颖的高层次特性。本文旨在研究大语言模型是否具备涌现能力及其智能，以理解智能的本质。

研究方法: 首先回顾量化涌现的多种方法，分析大语言模型是否展现涌现能力；其次探讨这些模型是否具备涌现智能。

研究结果: 研究发现大语言模型确实表现出涌现能力，但其是否具备真正的涌现智能仍需进一步验证。

研究结论: 大语言模型展现了涌现能力，但涌现智能的存在仍需深入研究，为未来智能研究提供新视角。

中文摘要: 涌现是复杂科学中的一个概念，描述多体系统如何展现新颖的高层次特性，这些特性可以通过用低维有效变量和理论替代高维机制来描述。这体现了“多即是不同”的理念。智能是一种典型的涌现特性，表现为利用涌现能力以更高效（更廉价和更快速）的方式解决问题，这体现了“少即是多”的理念。本文首先探讨了大语言模型是否展现涌现能力，回顾了量化涌现的几种方法；其次，研究这些模型是否具备涌现智能。

</details>


### [44] [Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models](https://arxiv.org/abs/2506.11137)
**中文标题：基于大型语言模型的可扩展药物提取与停药识别方法在电子健康记录中的应用**

*Chong Shao,Douglas Snyder,Chiran Li,Bowen Gu,Kerry Ngan,Chun-Ting Yang,Jiageng Wu,Richard Wyss,Kueiyu Joshua Lin,Jie Yang*

主要分类: cs.CL

摘要简述: 本研究评估了大型语言模型（LLMs）在电子健康记录（EHR）中提取药物信息并识别停药状态的能力，发现GPT-4o在零样本设置下表现最佳，开源模型如Llama-3.1-70B-Instruct也表现优异，展现了LLMs在医疗信息提取中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 电子健康记录（EHR）中的药物停药信息对患者安全至关重要，但这些信息通常埋藏在非结构化文本中，难以提取。本研究旨在评估先进的开源和专有大型语言模型（LLMs）在无需人工标注的情况下，从EHR中提取药物信息并分类其状态的扩展能力。

研究方法: 研究收集了三个来源多样的EHR数据集作为评估基准，评估了12种先进的LLMs，并探索了多种LLM提示策略。系统地比较了药物提取、药物状态分类及其联合任务（提取后分类）的性能。

研究结果: LLMs在药物提取和停药分类任务中表现出色。GPT-4o在零样本设置下平均F1分数最高：药物提取94.0%，停药分类78.1%，联合任务72.7%。开源模型如Llama-3.1-70B-Instruct在部分任务中表现优异。医学专用LLMs性能低于通用领域LLMs。少量样本学习通常能提升性能，而思维链（CoT）推理效果不一致。

研究结论: LLMs在EHR中提取药物信息和识别停药状态方面具有强大潜力，开源模型为专有系统提供了可扩展的替代方案，少量样本学习可进一步提升LLMs的能力。

中文摘要: 识别电子健康记录（EHRs）中的药物停药信息对患者安全至关重要，但这些信息通常埋藏在非结构化文本中。本研究旨在评估先进的开源和专有大型语言模型（LLMs）在无需人工标注的情况下，从EHR中提取药物信息并分类其状态的能力，重点关注其在药物信息提取中的扩展性。我们收集了三个来源多样的EHR数据集作为评估基准，评估了12种先进的LLMs，并探索了多种LLM提示策略。在所有实验中，系统地比较了药物提取、药物状态分类及其联合任务（提取后分类）的性能。研究发现，LLMs在药物提取和停药分类任务中表现优异。GPT-4o在零样本设置下平均F1分数最高：药物提取94.0%，停药分类78.1%，联合任务72.7%。开源模型紧随其后，Llama-3.1-70B-Instruct在MIV-Med数据集上的药物状态分类任务中表现最佳（68.7%），在Re-CASI（76.2%）和MIV-Med（60.2%）数据集的联合任务中也表现优异。医学专用LLMs的性能低于先进的通用领域LLMs。少量样本学习通常能提升性能，而思维链（CoT）推理效果不一致。LLMs在EHR中提取药物信息和识别停药状态方面展现出强大潜力，开源模型为专有系统提供了可扩展的替代方案，少量样本学习可进一步提升LLMs的能力。

</details>


### [45] [RETUYT-INCO at BEA 2025 Shared Task: How Far Can Lightweight Models Go in AI-powered Tutor Evaluation?](https://arxiv.org/abs/2506.11243)
**中文标题：RETUYT-INCO在BEA 2025共享任务中的表现：轻量级模型在AI辅助教学评估中的潜力有多大？**

*Santiago Góngora,Ignacio Sastre,Santiago Robaina,Ignacio Remersaro,Luis Chiruzzo,Aiala Rosá*

主要分类: cs.CL

摘要简述: RETUYT-INCO团队在BEA 2025共享任务中展示了轻量级模型（参数少于10亿）的竞争力，尽管计算资源有限，其表现与优胜团队差距较小。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机源于全球南方许多研究机构因高昂成本而难以获得强大计算资源，因此探索轻量级模型在AI辅助教学评估任务中的可行性。

研究方法: 团队采用参数少于10亿的轻量级模型参与BEA 2025共享任务，验证其在有限计算资源下的表现。

研究结果: 模型在五个赛道中与优胜团队的差距分别为6.46、10.24、7.85、9.56和13.13分（基于精确F1分数），表明轻量级模型具有竞争力。

研究结论: 轻量级模型（参数少于10亿）在AI辅助教学评估任务中表现优异，适合计算资源有限的环境，如低预算GPU或无GPU设备。

中文摘要: 本文介绍了RETUYT-INCO团队在BEA 2025共享任务中的参与情况。团队选择使用参数少于10亿的轻量级模型，以模拟全球南方研究机构因高昂成本而难以获取强大计算资源的现实条件。尽管自我设限，模型表现仍与其他参赛团队竞争激烈。根据组织者公布的精确F1分数，模型与优胜团队的差距分别为：赛道1为6.46分，赛道2为10.24分，赛道3为7.85分，赛道4为9.56分，赛道5为13.13分。最小差距为6.46分，最大为13.13分。结果表明，参数少于10亿的模型在这些任务中具有竞争力，且可在低预算GPU或无GPU设备上运行。

</details>


### [46] [Iterative Multilingual Spectral Attribute Erasure](https://arxiv.org/abs/2506.11244)
**中文标题：迭代多语言谱属性擦除**

*Shun Shao,Yftah Ziser,Zheng Zhao,Yifu Qiu,Shay B. Cohen,Anna Korhonen*

主要分类: cs.CL

摘要简述: 本文提出了一种迭代多语言谱属性擦除方法（IMSAE），通过迭代SVD截断识别和缓解多语言的联合偏见子空间，在八种语言和五种人口统计维度上验证了其有效性，尤其在零样本场景下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 多语言表示将相似含义的词嵌入到共享语义空间中，为跨语言传递去偏见效果提供了机会，但现有方法仅针对单一语言，无法利用这一优势。

研究方法: IMSAE通过迭代SVD截断技术识别和消除多语言的联合偏见子空间，支持标准及零样本（目标语言数据缺失但可利用相似语言）的去偏见任务。

研究结果: 实验表明，IMSAE在BERT、LLaMA和Mistral等多种语言模型上均优于传统单语言和跨语言方法，同时保持模型实用性。

研究结论: IMSAE为多语言去偏见提供了高效解决方案，尤其在零样本场景下表现突出，为跨语言模型公平性研究开辟了新方向。

中文摘要: 多语言表示将含义相似的词嵌入到跨语言的共享语义空间中，为跨语言传递去偏见效果创造了机会。然而，现有去偏见方法因仅针对单一语言而无法利用这一机会。我们提出了迭代多语言谱属性擦除（IMSAE），通过基于SVD的迭代截断技术识别并缓解多语言的联合偏见子空间。在八种语言和五个人口统计维度上的评估表明，IMSAE在标准及零样本（目标语言数据缺失但可利用相似语言）场景下均表现优异。我们对多种语言模型（BERT、LLaMA、Mistral）的综合实验显示，IMSAE优于传统单语言和跨语言方法，同时保持模型实用性。

</details>


### [47] [No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning](https://arxiv.org/abs/2506.11246)
**中文标题：无通用提示：通过自适应提示统一时序表格推理**

*Kushagra Dixit,Abhishek Rajgaria,Harshavardhan Kalalbandi,Dan Roth,Vivek Gupta*

主要分类: cs.CL

摘要简述: 本文研究了时序表格推理中不同提示技术的效果，发现没有单一方法在所有场景下表现最优，因此提出了自适应提示框架SEAR，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 时序表格推理是大型语言模型（LLMs）面临的重要挑战，现有提示技术效果不一且缺乏系统性研究，亟需一种适应不同场景的优化方法。

研究方法: 通过分析多种提示技术在不同表格类型中的表现，提出自适应提示框架SEAR，动态调整提示策略并整合结构化推理。

研究结果: SEAR在所有表格类型中均优于基线方法，同时发现表格结构重构能进一步提升模型推理能力。

研究结论: SEAR框架通过动态适应性和结构化推理显著提升了时序表格推理的性能，为复杂场景下的提示技术提供了新思路。

中文摘要: 时序表格推理是大型语言模型（LLMs）面临的关键挑战，需要有效的提示技术以提取相关洞察。尽管存在多种提示方法，其对表格推理的影响尚未充分探索。此外，这些模型在不同表格和上下文结构中的表现差异显著，使得难以确定最优方法。本研究调查了多种提示技术在不同表格类型中的应用，以确定不同场景下的最优方法。我们发现性能因实体类型、表格结构、额外上下文需求和问题复杂性而异，且没有单一方法始终优于其他方法。为应对这些挑战，我们提出了SEAR，一种受人类推理启发的自适应提示框架，能够根据上下文特征动态调整并整合结构化推理。结果表明，SEAR在所有表格类型中均优于其他基线提示技术。此外，我们还探讨了表格结构重构的影响，发现统一表示能增强模型的推理能力。

</details>


### [48] [Learning a Continue-Thinking Token for Enhanced Test-Time Scaling](https://arxiv.org/abs/2506.11274)
**中文标题：学习一个“继续思考”令牌以增强测试时扩展**

*Liran Ringel,Elad Tolochinsky,Yaniv Romano*

主要分类: cs.CL

摘要简述: 本文提出了一种通过学习专用“继续思考”令牌来增强语言模型推理能力的方法，实验表明该方法在数学基准测试中显著优于固定令牌方法。


<details>
  <summary>详细信息</summary>
研究动机: 测试时扩展是一种通过增加推理计算提升语言模型性能的有效方法。近期研究表明，覆盖“结束思考”令牌（如用“Wait”替换“</think>”）可以延长推理步骤并提高准确性。本文旨在探索是否可以通过学习一个专用的“继续思考”令牌来触发更长的推理过程。

研究方法: 研究团队在DeepSeek-R1的蒸馏版本中引入了一个学习到的“<|continue-thinking|>”令牌，仅通过强化学习训练其嵌入，同时冻结模型权重。该方法与使用固定令牌（如“Wait”）的测试时扩展方法进行了对比。

研究结果: 实验结果显示，学习到的令牌在标准数学基准测试中显著提高了准确性。例如，在GSM8K基准测试中，固定令牌方法仅带来1.3%的绝对提升，而学习令牌方法实现了4.2%的改进。

研究结论: 学习专用的“继续思考”令牌能够更有效地扩展语言模型的推理能力，显著优于固定令牌方法，为测试时扩展提供了新的优化方向。

中文摘要: 测试时扩展已成为一种通过增加推理计算提升语言模型性能的有效方法。近期研究表明，覆盖“结束思考”令牌（如用“Wait”替换“</think>”）可以延长推理步骤并提高准确性。本文探索是否可以通过学习一个专用的“继续思考”令牌来触发更长的推理过程。我们在DeepSeek-R1的蒸馏版本中引入了一个学习到的“<|continue-thinking|>”令牌，仅通过强化学习训练其嵌入，同时冻结模型权重。实验表明，该学习令牌在标准数学基准测试中显著优于基线模型和使用固定令牌（如“Wait”）的测试时扩展方法。特别是在固定令牌方法能够提升基础模型准确性的情况下，我们的方法实现了更显著的改进。例如，在GSM8K基准测试中，固定令牌方法带来1.3%的绝对提升，而学习令牌方法实现了4.2%的改进。

</details>


### [49] [Beyond Random Sampling: Efficient Language Model Pretraining via Curriculum Learning](https://arxiv.org/abs/2506.11300)
**中文标题：超越随机采样：通过课程学习实现高效语言模型预训练**

*Yang Zhang,Amr Mohamed,Hadi Abdine,Guokan Shang,Michalis Vazirgiannis*

主要分类: cs.CL

摘要简述: 本文首次系统研究了课程学习在语言模型预训练中的应用，通过多种难度指标和设置实验，发现课程学习能显著提升早期和中期的训练效率，并在某些情况下带来3.5%的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 课程学习在多个机器学习领域已显示出提升训练效率和泛化能力的潜力，但在语言模型预训练中的应用尚未充分探索，因此本文旨在填补这一空白。

研究方法: 实验了多种课程学习设置，包括基础课程学习、基于步调的采样和交错课程，并基于六种难度指标（涵盖语言学和信息论视角）指导训练。在八个多样化基准上评估模型性能。

研究结果: 课程学习在训练早期和中期显著加速收敛，作为预热策略使用时能带来最高3.5%的性能提升。压缩比、词汇多样性和可读性被证明是有效的难度信号。

研究结论: 研究强调了数据排序在大规模预训练中的重要性，并为实际训练场景下的高效模型开发提供了实用建议。

中文摘要: 课程学习在多个机器学习领域已显示出提升训练效率和泛化能力的潜力，但在语言模型预训练中的应用尚未充分探索，因此本文首次系统研究了这一领域。我们尝试了多种设置，包括基础课程学习、基于步调的采样和交错课程，并基于六种难度指标（涵盖语言学和信息论视角）指导训练。在八个多样化基准上评估模型性能。实验表明，课程学习在训练早期和中期显著加速收敛，作为预热策略使用时能带来最高3.5%的性能提升。值得注意的是，压缩比、词汇多样性和可读性被证明是有效的难度信号。研究强调了数据排序在大规模预训练中的重要性，并为实际训练场景下的高效模型开发提供了实用建议。

</details>


### [50] [Don't Pay Attention](https://arxiv.org/abs/2506.11305)
**中文标题：无需注意力**

*Mohammad Hammoud,Devang Acharya*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Avey的新神经网络架构，摒弃了传统的注意力机制和循环结构，通过分解序列长度与上下文宽度，有效处理任意长序列，并在短程和长程依赖任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: Transformer虽然在大语言模型和下游任务中表现优异，但仍面临固定上下文窗口和注意力机制二次复杂度的限制。RNN类架构虽能线性扩展序列长度，但并行性受限。因此，需要一种新架构以兼顾长序列处理和高效率。

研究方法: Avey架构由排序器和自回归神经处理器组成，协作识别并上下文化最相关的标记，解耦序列长度与上下文宽度，从而支持任意长序列处理。

研究结果: 实验表明，Avey在短程NLP基准任务中与Transformer表现相当，且在长程依赖任务中显著优于Transformer。

研究结论: Avey通过创新架构设计，成功解决了传统注意力机制和循环结构的局限性，为长序列处理提供了高效解决方案。

中文摘要: Transformer已成为大语言模型和跨领域下游任务的事实标准。尽管其具有训练并行性等优势，但仍因无法处理超出固定上下文窗口的序列及注意力机制的二次复杂度而面临挑战。这重新激发了人们对RNN类架构的兴趣，后者虽因循环特性并行性受限，但能线性扩展序列长度并更好地处理长程依赖。本文提出Avey，一种摒弃注意力和循环的新神经网络基础架构。Avey由排序器和自回归神经处理器组成，协作识别并上下文化任意序列位置中最相关的标记，从而解耦序列长度与上下文宽度，支持任意长序列处理。实验显示，Avey在多种短程NLP基准任务中与Transformer表现相当，且在长程依赖任务中显著优于Transformer。

</details>


### [51] [Surprisal from Larger Transformer-based Language Models Predicts fMRI Data More Poorly](https://arxiv.org/abs/2506.11338)
**中文标题：基于更大规模Transformer语言模型的惊奇值对fMRI数据的预测效果更差**

*Yi-Chien Lin,William Schuler*

主要分类: cs.CL

摘要简述: 研究发现，基于Transformer的大型语言模型的惊奇值对fMRI数据的预测效果较差，且模型复杂度与预测能力呈负相关。


<details>
  <summary>详细信息</summary>
研究动机: 随着Transformer模型在自然语言处理任务中的广泛应用，研究者对其惊奇值预测人类句子处理难度的能力产生兴趣。此前研究显示，模型复杂度越高，对阅读时间的预测能力越差，但这一趋势尚未在脑成像数据中验证。

研究方法: 本研究评估了17个预训练Transformer模型在三种语言家族和两个fMRI数据集上的惊奇值预测能力。

研究结果: 结果显示，模型复杂度与预测能力仍呈负相关，表明这一趋势不仅限于基于延迟的测量，还可推广到神经测量。

研究结论: 研究证实，大型Transformer模型的惊奇值对fMRI数据的预测效果较差，且这一现象具有普遍性。

中文摘要: 随着Transformer在自然语言处理任务中的广泛应用，研究者对其惊奇值预测人类句子处理难度的能力产生了浓厚兴趣。近期研究发现，基于Transformer的模型的困惑度与其惊奇值对阅读时间的预测能力呈正相关，表明参数更多、训练数据更丰富的语言模型对人类阅读时间的预测能力更差。然而，这些研究主要关注基于延迟的测量（如自定步调阅读时间和眼动持续时间），并未在脑成像数据中验证这一趋势。因此，本研究评估了17个预训练Transformer模型在三种语言家族和两个功能磁共振成像数据集上的惊奇值预测能力。结果显示，模型困惑度与模型拟合度之间的正相关关系仍然存在，表明这一趋势不仅限于基于延迟的测量，还可推广到神经测量。

</details>


### [52] [From Replication to Redesign: Exploring Pairwise Comparisons for LLM-Based Peer Review](https://arxiv.org/abs/2506.11343)
**中文标题：从复制到重新设计：探索基于大语言模型的成对比较同行评审**

*Yaohui Zhang,Haijing Zhang,Wenlong Ji,Tianyu Hua,Nick Haber,Hancheng Cao,Weixin Liang*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大语言模型（LLM）的成对比较机制，用于改进学术论文评审，实验表明该方法在识别高影响力论文上优于传统评分法，但也揭示了新颖性和机构平衡性方面的潜在偏见。


<details>
  <summary>详细信息</summary>
研究动机: 传统同行评审流程存在局限性，而大语言模型（LLM）的应用多局限于复制传统流程。本文旨在探索LLM在评审中的新范式，通过成对比较机制重新设计评审方式。

研究方法: 引入LLM代理对论文进行成对比较，而非单独评分，通过大量成对评估结果聚合，更准确地衡量论文的相对质量。

研究结果: 实验表明，成对比较方法在识别高影响力论文上显著优于传统评分法，但也发现评审过程中存在研究主题新颖性降低和机构不平衡性增加的偏见。

研究结论: LLM在重新设计同行评审中具有变革潜力，但未来系统需解决公平性和多样性问题。

中文摘要: 大语言模型（LLM）的出现为重新构想同行评审提供了前所未有的机会，超越了传统流程的限制。尽管有这些机会，先前的研究主要集中在用LLM直接替代人类评审员以复制传统评审流程，而对探索LLM如何从根本上重新参与学术评审的新范式关注有限。本文提出并探索了一种新机制，利用LLM代理对论文进行成对比较而非单独评分。通过聚合大量成对评估结果，这种方法能够更准确、更稳健地衡量论文的相对质量。实验表明，这种比较方法在识别高影响力论文上显著优于传统评分法。然而，分析也揭示了评审过程中的潜在偏见，尤其是研究主题新颖性的降低和机构不平衡性的增加。这些发现既凸显了用LLM重新思考同行评审的变革潜力，也指出了未来系统必须解决的关键挑战，以确保公平性和多样性。

</details>


### [53] [Do We Still Need Audio? Rethinking Speaker Diarization with a Text-Based Approach Using Multiple Prediction Models](https://arxiv.org/abs/2506.11344)
**中文标题：我们还需要音频吗？基于文本的多预测模型重新思考说话人分割**

*Peilin Wu,Jinho D. Choi*

主要分类: cs.CL

摘要简述: 本文提出了一种基于文本的说话人分割新方法，通过句子级说话人变化检测，避免了音频质量与说话人相似性的问题。两种模型（SPM和MPM）在短对话中表现优异，性能媲美音频方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统音频说话人分割方法受限于音频质量和说话人相似性，本文探索仅依赖对话文本的解决方案，以提升短对话中的分割准确性。

研究方法: 开发了单预测模型（SPM）和多预测模型（MPM），基于对话文本进行句子级说话人变化检测，并通过多样化对话数据集验证。

研究结果: 实验表明，文本方法（尤其是MPM）在短对话中表现优于音频方法，展示了语义特征在说话人分割中的潜力。

研究结论: 本文证明了文本方法的竞争力，并强调语义理解对说话人分割的重要性，为未来多模态和语义特征研究开辟了方向。

中文摘要: 我们提出了一种新颖的说话人分割方法，通过基于文本的句子级说话人变化检测技术，避免了音频质量和说话人相似性带来的挑战。与音频方法不同，我们的方法仅依赖对话文本。开发了两种模型：单预测模型（SPM）和多预测模型（MPM），两者在短对话中显著提升了说话人变化的识别能力。基于多样化对话场景的测试数据，结果表明文本方法（尤其是MPM）在短对话中性能优于音频方法。本文不仅展示了语言特征在说话人分割中的潜力，还强调了语义理解的重要性，为未来多模态和语义特征研究提供了新思路。

</details>


### [54] [The Biased Samaritan: LLM biases in Perceived Kindness](https://arxiv.org/abs/2506.11361)
**中文标题：《偏见的撒玛利亚人：大型语言模型在感知善意中的偏见》**

*Jack H Fagan,Ruhaan Juyaal,Amy Yue-Ming Yu,Siya Pun*

主要分类: cs.CL

摘要简述: 本文提出了一种评估生成式AI模型人口统计学偏见的新方法，通过量化分析不同LLM对性别、种族和年龄的偏见，发现模型通常以白人中年或年轻男性为基准群体，但非基准群体更倾向于提供帮助。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在各领域广泛应用，但其偏见问题尚未完全解决。本文旨在通过量化评估不同LLM的人口统计学偏见，为开发者和用户提供客观依据，以减少偏见对输出的影响。

研究方法: 通过让模型评估道德主体是否愿意积极干预，量化分析不同LLM对性别、种族和年龄的偏见，并确定基准人口统计学身份及其与其他群体的关系。

研究结果: 研究发现，模型通常以白人中年或年轻男性为基准群体，但非基准群体更倾向于提供帮助。这些偏见可分为积极、中性或消极，且强度各异。

研究结论: 本文为LLM偏见的客观评估提供了新方法，帮助用户和开发者在输出或训练中考虑这些偏见。研究发现基准与非基准群体之间存在显著差异，为未来研究提供了方向。

中文摘要: 尽管大型语言模型（LLM）已在许多领域广泛应用，但理解和减轻其偏见仍是一个持续的问题。本文提出了一种评估生成式AI模型人口统计学偏见的新方法。通过让模型评估道德主体是否愿意积极干预，我们旨在量化分析不同LLM对性别、种族和年龄的偏见。我们的工作与现有研究不同，目标是确定各商业模型的基准人口统计学身份及其与其他群体的关系。我们试图了解这些偏见是积极、中性还是消极的，以及其强度。本文有助于客观评估LLM的偏见，并为用户或开发者提供能力，以在LLM输出或未来训练中考虑这些偏见。我们的分析得出了两个关键发现：模型通常将基准群体视为白人中年或年轻男性；然而，跨模型的普遍趋势表明，非基准群体比基准群体更愿意提供帮助。这些方法使我们能够区分通常交织在一起的两种偏见。

</details>


### [55] [A Variational Approach for Mitigating Entity Bias in Relation Extraction](https://arxiv.org/abs/2506.11381)
**中文标题：一种基于变分方法的缓解关系抽取中实体偏差的方法**

*Samuel Mensah,Elena Kochkina,Jabez Magomere,Joy Prakash Sain,Simerjot Kaur,Charese Smiley*

主要分类: cs.CL

摘要简述: 本文提出了一种基于变分信息瓶颈（VIB）框架的新方法，用于缓解关系抽取中的实体偏差问题，通过压缩实体特定信息并保留任务相关特征，在多个领域和测试设置中取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 关系抽取（RE）中，模型常过度依赖实体信息，导致泛化能力差。本文旨在通过变分信息瓶颈框架减少实体偏差，提升模型的鲁棒性和可解释性。

研究方法: 采用变分信息瓶颈（VIB）框架，压缩实体特定信息，同时保留任务相关特征，从而减少对实体的过度依赖。

研究结果: 在通用、金融和生物医学领域的关系抽取数据集上，无论是域内（原始测试集）还是域外（修改后的测试集），均取得了最先进的性能。

研究结论: 本文提出的方法不仅性能优越，还具有理论支持和高可解释性，为缓解关系抽取中的实体偏差问题提供了有效解决方案。

中文摘要: 缓解实体偏差是关系抽取（RE）中的关键挑战，模型常过度依赖实体，导致泛化能力差。本文提出了一种基于变分信息瓶颈（VIB）框架的新方法，通过压缩实体特定信息并保留任务相关特征来解决这一问题。该方法在通用、金融和生物医学领域的关系抽取数据集上，无论是域内（原始测试集）还是域外（修改后的测试集），均取得了最先进的性能。我们的方法提供了一种鲁棒、可解释且理论依据充分的解决方案。

</details>


### [56] [Curriculum-Guided Layer Scaling for Language Model Pretraining](https://arxiv.org/abs/2506.11389)
**中文标题：课程引导层扩展用于语言模型预训练**

*Karanpartap Singh,Neil Band,Ehsan Adeli*

主要分类: cs.CL

摘要简述: 本文提出了一种名为课程引导层扩展（CGLS）的方法，通过逐步增加模型层数与数据难度同步提升，显著提高了语言模型预训练的效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 受人类认知发展的启发，研究者希望通过逐步增加模型复杂度和数据难度，模拟人类学习过程，从而提升语言模型预训练的效率和泛化能力。

研究方法: CGLS框架通过逐步堆叠模型层数（即训练过程中逐渐增加层数），同时根据课程安排逐步提升数据难度（如从简单短篇故事过渡到通用网页数据，再到高度专业化的内容）。

研究结果: 在100M参数规模下，CGLS在PIQA和ARC问答基准测试中表现优于基线方法；在1.2B参数规模下，通过分层数据训练，模型在零样本任务中展现出更好的泛化能力。

研究结论: CGLS通过同步增加模型深度和数据难度，显著提升了语言模型的预训练效率和下游任务的性能，为知识密集型和推理任务提供了一种简单有效的策略。

中文摘要: 随着大规模语言模型预训练成本的增加，如何提升核心训练阶段的学习效率成为研究热点。受人类认知发展启发，我们提出了课程引导层扩展（CGLS），一种通过逐步堆叠层数（即在训练过程中逐渐增加层数）同步提升数据难度和模型规模的框架。在100M参数规模下，使用从合成短篇故事过渡到通用网页数据的课程安排，CGLS在PIQA和ARC问答基准测试中表现优于基线方法。在1.2B参数规模下，我们通过基于DistilBERT的分类器对DataComp-LM语料进行分层，从通用文本逐步过渡到高度技术性或专业化内容。结果表明，逐步增加模型深度与样本难度同步，能够提升模型在各种下游基准测试中的泛化能力和零样本性能。总之，CGLS展示了逐步堆叠的潜力，为提升知识密集型和推理任务的泛化能力提供了一种简单而有效的策略。

</details>


### [57] [Predicting Early-Onset Colorectal Cancer with Large Language Models](https://arxiv.org/abs/2506.11410)
**中文标题：利用大型语言模型预测早发性结直肠癌**

*Wilson Lau,Youngwon Kim,Sravanthi Parasa,Md Enamul Haque,Anand Oka,Jay Nanduri*

主要分类: cs.CL

摘要简述: 本文研究了如何利用大型语言模型（LLM）预测早发性结直肠癌（EoCRC），发现微调后的LLM在敏感性和特异性上表现优于传统机器学习模型。


<details>
  <summary>详细信息</summary>
研究动机: 早发性结直肠癌（EoCRC）发病率逐年上升，但患者年龄低于国家筛查指南推荐的标准年龄，因此需要更有效的预测方法。

研究方法: 研究回顾性分析了美国多个医疗系统的1,953名结直肠癌患者数据，比较了10种机器学习模型与微调大型语言模型（LLM）在预测EoCRC中的表现，输入数据包括患者诊断前6个月的病情、实验室结果和观察记录。

研究结果: 结果显示，微调后的LLM平均敏感性为73%，特异性为91%，优于传统机器学习模型。

研究结论: 研究表明，微调的大型语言模型在预测早发性结直肠癌方面具有潜力，可作为筛查工具的补充。

中文摘要: 早发性结直肠癌（EoCRC，年龄<45岁）的发病率逐年上升，但这一人群的年龄低于国家癌症筛查指南推荐的筛查年龄。本文应用了10种不同的机器学习模型预测EoCRC，并将其性能与先进的大型语言模型（LLM）进行比较，使用的数据包括患者诊断前6个月的病情、实验室结果和观察记录。我们回顾性分析了来自美国多个医疗系统的1,953名结直肠癌患者数据。结果表明，微调后的LLM平均敏感性为73%，特异性为91%。

</details>


### [58] [Efficient Long-Context LLM Inference via KV Cache Clustering](https://arxiv.org/abs/2506.11418)
**中文标题：基于KV缓存聚类的长上下文LLM高效推理**

*Jie Hu,Shengnan Wang,Yutong He,Ping Gong,Jiawei Yi,Juncheng Zhang,Youhui Bai,Renhai Chen,Gong Zhang,Cheng Li,Kun Yuan*

主要分类: cs.CL

摘要简述: 本文提出Chelsea框架，通过在线KV缓存聚类技术，显著减少长上下文LLM推理中的内存占用和计算开销，同时保持模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 长上下文大语言模型（LLM）需要大量KV缓存，导致部署困难。现有方法要么丢弃关键信息，要么效率提升有限。

研究方法: 提出Chelsea框架，基于键状态在序列维度上的高相似性，将序列分块并采用分块软匹配策略进行聚类，合并KV缓存为单个质心。

研究结果: 实验表明，Chelsea减少80%的KV缓存内存占用，解码阶段加速3.19倍，端到端延迟降低2.72倍，且模型性能未受影响。

研究结论: Chelsea是一种高效的长上下文LLM推理框架，显著降低资源消耗并提升性能。

中文摘要: 随着长上下文窗口的大语言模型（LLM）在处理复杂任务中的普及，其所需的大量键值（KV）缓存带来了显著的部署挑战。现有方法要么丢弃未来生成可能需要的关键信息，要么因高计算开销而效率提升有限。本文提出Chelsea，一种简单有效的在线KV缓存聚类框架。我们的方法基于键状态在序列维度上表现出的高相似性。为实现高效聚类，我们将序列分块并提出分块软匹配策略，通过交替分区识别相似簇，并将每个簇内的KV缓存合并为单个质心。此外，我们还对计算复杂度和块内分区策略的最优性进行了理论分析。在多种模型和长上下文基准测试中的实验表明，Chelsea可将KV缓存内存占用减少高达80%，同时保持模型性能。此外，Chelsea以极低计算开销将推理的解码阶段加速高达3.19倍，端到端延迟降低高达2.72倍。

</details>


### [59] [Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards](https://arxiv.org/abs/2506.11425)
**中文标题：Agent-RLVR：通过指导和环境奖励训练软件工程智能体**

*Jeff Da,Clinton Wang,Xiang Deng,Yuntao Ma,Nikhil Barhate,Sean Hendryx*

主要分类: cs.CL

摘要简述: Agent-RLVR是一种通过指导和环境奖励训练软件工程智能体的框架，显著提升了复杂任务中的模型表现。


<details>
  <summary>详细信息</summary>
研究动机: 传统的RLVR方法在复杂多步任务中效果不佳，奖励稀疏导致模型训练困难。Agent-RLVR旨在通过模拟教师指导机制，提升智能体在复杂环境中的表现。

研究方法: Agent-RLVR结合了智能体指导和环境奖励，通过验证初始轨迹、补充指导信息，并基于奖励更新策略，提升模型在软件工程任务中的表现。

研究结果: 在SWE-Bench Verified任务中，Agent-RLVR将Qwen-2.5-72B-Instruct的pass@1性能从9.4%提升至22.4%，进一步优化后可达27.8%。

研究结论: Agent-RLVR为复杂现实环境中基于RLVR的智能体训练奠定了基础，解决了传统强化学习方法在稀疏奖励环境中的局限性。

中文摘要: 可验证奖励的强化学习（RLVR）已被广泛用于提升大型语言模型的推理能力，并在数学和编程竞赛等可验证领域取得了显著成功。然而，RLVR在智能体环境中的效果显著下降。这些环境以多步骤、复杂问题解决为特点，导致即使是最先进的LLM也面临高失败率，因为奖励稀疏使得传统RLVR难以有效训练模型。本文提出了Agent-RLVR，一种使RLVR在复杂智能体环境中有效的框架，重点关注软件工程任务。受人类教学启发，Agent-RLVR引入了智能体指导机制，通过利用多样化的信息线索（如高层战略计划或动态错误反馈）主动引导智能体走向成功轨迹。这些线索模拟了教师的指导，帮助智能体在复杂解空间中导航，并通过额外环境探索促进自我改进。在Agent-RLVR训练循环中，智能体首先尝试完成任务生成初始轨迹，随后通过单元测试验证并补充指导信息。智能体在指导下重新尝试，策略则基于这些轨迹的奖励通过RLVR更新。Agent-RLVR将Qwen-2.5-72B-Instruct在SWE-Bench Verified任务中的pass@1性能从9.4%提升至22.4%。此外，指导增强的RLVR数据还可用于测试时奖励模型训练，进一步将pass@1提升至27.8%。Agent-RLVR为在传统强化学习方法难以应对的复杂现实环境中训练智能体奠定了基础。

</details>


### [60] [KoGEC : Korean Grammatical Error Correction with Pre-trained Translation Models](https://arxiv.org/abs/2506.11432)
**中文标题：KoGEC：基于预训练翻译模型的韩语语法纠错系统**

*Taeeun Kim,Semin Jeong,Youngsook Song*

主要分类: cs.CL

摘要简述: 本研究介绍了KoGEC，一种基于预训练翻译模型的韩语语法纠错系统。通过微调NLLB模型，KoGEC在韩语语法纠错任务中表现优于GPT-4和HCX-3，并开发了Chrome扩展以方便用户使用。


<details>
  <summary>详细信息</summary>
研究动机: 韩语语法纠错（GEC）在自然语言处理中具有重要意义，但现有的大型语言模型（如GPT-4）在韩语GEC任务中表现不佳。本研究旨在开发一种高效、专用的韩语GEC系统，并通过微调预训练翻译模型提升性能。

研究方法: 研究使用NLLB预训练模型进行微调，并采用特殊语言标记区分原始和纠正后的韩语句子。训练和测试数据来自社交媒体对话数据集。评估方法包括BLEU分数和基于LLM的错误类型分类。

研究结果: 微调后的NLLB（KoGEC）模型在韩语GEC任务中表现优于GPT-4和HCX-3，尤其在标点错误纠正上更均衡。此外，开发了Chrome扩展以提升系统可用性。词汇扩展尝试反而降低了模型性能。

研究结论: KoGEC为韩语语法纠错提供了高效专用解决方案，展示了任务专用模型在特定NLP任务中优于通用大型模型的潜力。同时，研究提出了新的评估方法，并验证了紧凑模型的竞争力。

中文摘要: 本研究介绍了KoGEC，一种基于预训练翻译模型的韩语语法纠错系统。我们微调了NLLB（No Language Left Behind）模型用于韩语GEC，并将其性能与GPT-4和HCX-3等大型语言模型进行比较。研究使用了两个社交媒体对话数据集进行训练和测试。NLLB模型通过特殊语言标记区分原始和纠正后的韩语句子。评估采用BLEU分数和“LLM作为评判”方法对错误类型分类。结果显示，微调的NLLB（KoGEC）模型在韩语GEC任务中优于GPT-4和HCX-3。KoGEC在各类错误纠正上表现更均衡，而大型语言模型对标点错误的关注较少。我们还开发了Chrome扩展以便用户使用KoGEC系统。此外，尝试通过词汇扩展提升模型性能，但效果不佳。本研究为NLP领域提供了高效的专用韩语GEC系统和新评估方法，同时展示了紧凑任务专用模型在特定NLP任务中与通用大型模型竞争的潜力。

</details>


### [61] [AbsenceBench: Language Models Can't Tell What's Missing](https://arxiv.org/abs/2506.11440)
**中文标题：AbsenceBench：语言模型无法识别缺失内容**

*Harvey Yiyun Fu,Aryan Shrivastava,Jared Moore,Peter West,Chenhao Tan,Ari Holtzman*

主要分类: cs.CL

摘要简述: 大型语言模型（LLM）在处理长输入和定位特定信息方面表现出色，但在检测缺失信息时表现不佳。AbsenceBench评估了LLM在数值序列、诗歌和GitHub拉取请求中检测缺失信息的能力，结果显示即使最先进的模型如Claude-3.7-Sonnet也仅达到69.6%的F1分数。研究表明，Transformer注意力机制难以处理文档中的“空白”，因为这些缺失没有对应的键值可供关注。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM在Needle in a Haystack（NIAH）测试中表现出色，能够定位长输入中的特定信息，但在检测明显缺失的信息时表现不佳。本文旨在通过AbsenceBench评估LLM在检测缺失信息方面的能力，揭示其局限性。

研究方法: 研究团队设计了AbsenceBench，包含三个领域的任务：数值序列、诗歌和GitHub拉取请求。模型需要在原始和编辑后的文档中识别被故意删除的内容。实验使用了包括Claude-3.7-Sonnet在内的先进模型，平均上下文长度为5K tokens。

研究结果: 实验结果显示，即使是最先进的模型Claude-3.7-Sonnet，在AbsenceBench上的F1分数仅为69.6%。分析表明，Transformer注意力机制难以处理文档中的“空白”，因为这些缺失没有对应的键值可供关注。

研究结论: 研究表明，LLM在检测缺失信息方面存在显著局限性，这与它们在定位特定信息方面的超强能力形成鲜明对比。AbsenceBench为理解LLM的能力边界提供了一个案例研究。

中文摘要: 大型语言模型（LLM）在处理长输入和定位特定信息方面表现出色，这一点在Needle in a Haystack（NIAH）测试中得到了验证。然而，尽管模型能够出色地回忆出人意料的信息，但在识别明显缺失的信息时仍存在困难。我们引入了AbsenceBench，用于评估LLM在三个领域中检测缺失信息的能力：数值序列、诗歌和GitHub拉取请求。AbsenceBench要求模型在给定原始和编辑后的上下文时，识别哪些内容被故意删除。尽管这些任务看似简单，但实验表明，即使是Claude-3.7-Sonnet这样的最先进模型，其F1分数也仅为69.6%，平均上下文长度为5K tokens。我们的分析表明，这种表现不佳源于一个根本性限制：Transformer注意力机制难以关注文档中的“空白”，因为这些缺失没有对应的键值可供关注。总体而言，我们的结果和分析提供了一个案例研究，展示了模型在超人类任务（NIAH）和意外失败任务（AbsenceBench）之间的紧密关联。

</details>


### [62] [A Gamified Evaluation and Recruitment Platform for Low Resource Language Machine Translation Systems](https://arxiv.org/abs/2506.11467)
**中文标题：低资源语言机器翻译系统的游戏化评估与招募平台**

*Carlos Rafael Catalan*

主要分类: cs.CL

摘要简述: 本文提出了一种针对低资源语言机器翻译系统的游戏化评估与招募平台，旨在解决数据与评估者资源不足的问题。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语言的机器翻译系统缺乏有效的自动评估指标，且人类评估者和数据集稀缺，开发者难以找到合适的资源进行评估。

研究方法: 首先综述现有评估方法，设计一个招募和游戏化评估平台，以填补数据与评估者资源的缺口。

研究结果: 提出了一种平台设计方案，用于招募评估者并通过游戏化方式评估机器翻译系统，同时讨论了其挑战和潜在应用。

研究结论: 该平台为低资源语言机器翻译系统的开发提供了资源支持，并在自然语言处理研究中具有广泛的应用潜力。

中文摘要: 人类评估者在评估大型语言模型时提供了必要的贡献。在低资源语言（LRLs）的机器翻译（MT）系统中，这一点尤为明显，因为流行的自动化指标通常是基于字符串的，无法全面反映系统的行为细节。具备语言专业知识的人类评估者能够测试翻译的充分性、流畅性等重要指标。然而，语言的低资源特性意味着数据集和评估者都供不应求。这带来了一个难题：MT系统的开发者如何为这些低资源语言找到足够的人类评估者和数据集？本文首先综述了现有的评估方法，旨在设计一个填补数据集和评估者资源缺口的平台。最终提出了一种针对MT系统开发者的招募和游戏化评估平台设计方案。同时讨论了评估该平台的挑战，以及其在自然语言处理（NLP）研究中的潜在应用。

</details>


### [63] [Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards](https://arxiv.org/abs/2506.11474)
**中文标题：Med-PRM：基于逐步、指南验证过程奖励的医疗推理模型**

*Jaehoon Yun,Jiwoong Sohn,Jungwoo Park,Hyunjae Kim,Xiangru Tang,Yanjun Shao,Yonghoe Koo,Minhyeok Ko,Qingyu Chen,Mark Gerstein,Michael Moor,Jaewoo Kang*

主要分类: cs.CL

摘要简述: Med-PRM是一种医疗推理模型，通过逐步验证推理步骤并结合医学知识库，显著提升临床决策的准确性和错误定位能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在临床决策中存在推理步骤错误定位和修正的不足，这在医学领域尤为重要，因为准确的诊断和患者护理依赖于正确的推理过程。

研究方法: Med-PRM采用过程奖励建模框架，结合检索增强生成技术，逐步验证推理步骤是否符合医学知识库中的临床指南和文献。

研究结果: 在五个医学问答基准和两个开放诊断任务中，Med-PRM表现优异，将基础模型的性能提升高达13.50%，并在小规模模型（80亿参数）上首次实现MedQA超过80%的准确率。

研究结论: Med-PRM通过逐步验证推理步骤，显著提升了医疗推理的准确性和可靠性，展示了其在临床决策中的广泛应用潜力。

中文摘要: 大型语言模型在临床决策中显示出潜力，但当前方法难以定位和修正推理过程中特定步骤的错误。这一局限性在医学领域尤为关键，因为识别和解决推理错误对准确诊断和有效患者护理至关重要。我们提出了Med-PRM，一种过程奖励建模框架，利用检索增强生成技术，根据现有医学知识库验证每个推理步骤。通过从临床指南和文献中检索证据验证中间推理步骤，我们的模型能够以细粒度方式精确评估推理质量。在五个医学问答基准和两个开放诊断任务上的评估表明，Med-PRM实现了最先进的性能，使用Med-PRM将基础模型的性能提升高达13.50%。此外，我们通过以即插即用的方式将Med-PRM与Meerkat等强大策略模型集成，展示了其通用性，首次在小规模模型（80亿参数）上实现了MedQA超过80%的准确率。我们的代码和数据可在https://med-prm.github.io/获取。

</details>


### [64] [ImmunoFOMO: Are Language Models missing what oncologists see?](https://arxiv.org/abs/2506.11478)
**中文标题：ImmunoFOMO：语言模型是否遗漏了肿瘤学家所见？**

*Aman Sinha,Bogdan-Valentin Popescu,Xavier Coubez,Marianne Clausel,Mathieu Constant*

主要分类: cs.CL

摘要简述: 本文研究了语言模型在识别乳腺癌免疫治疗标志方面的医学概念理解能力，发现预训练语言模型在特定低层次概念识别上优于大型语言模型。


<details>
  <summary>详细信息</summary>
研究动机: 随着语言模型能力的快速提升，生物医学等领域开始探索其在日常应用中的潜力，尤其是医学语言模型的理解能力。本文旨在评估语言模型与临床专家在乳腺癌免疫治疗标志识别上的表现差异。

研究方法: 研究比较了多种语言模型与临床专家在乳腺癌摘要中识别免疫治疗标志的能力，重点关注预训练语言模型与大型语言模型的表现。

研究结果: 结果显示，预训练语言模型在识别特定（低层次）概念方面表现优于大型语言模型。

研究结论: 研究表明，预训练语言模型在医学特定概念识别上具有潜力，为未来医学语言模型的应用提供了方向。

中文摘要: 语言模型（LMs）的能力在过去十年中快速增长，促使生物医学等领域的研究者探索其在日常应用中的潜力。领域特定语言模型已用于生物医学自然语言处理（NLP）应用。然而，近期对医学语言模型及其理解能力的兴趣日益增长。本文研究了多种语言模型在乳腺癌摘要中识别免疫治疗标志的医学概念理解能力，并与临床专家进行比较。结果显示，预训练语言模型在识别特定（低层次）概念方面具有超越大型语言模型的潜力。

</details>


### [65] [Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models](https://arxiv.org/abs/2506.11485)
**中文标题：BERT中的关系模式是可诱导的，而非涌现的：语言模型性能与能力的研究**

*Cole Gawin*

主要分类: cs.CL

摘要简述: 研究表明，BERT的关系模式并非预训练中自然涌现，而是通过任务微调诱导产生。


<details>
  <summary>详细信息</summary>
研究动机: 探讨大型语言模型（如BERT）在语义任务中的表现是否反映真正的概念能力，还是仅基于表面统计关联。

研究方法: 通过分析BERT内部对分类、部分与整体及功能关系的概念对表示，比较其关系分类性能与[CLS]标记嵌入的表征结构。

研究结果: 预训练BERT具有高分类准确率，表明潜在关系信号；但关系类型的概念对仅在有监督关系分类任务微调后在高维嵌入空间中组织。

研究结论: 行为表现不必然意味着结构化概念理解，但模型可通过适当训练获得关系抽象的归纳偏置。

中文摘要: 尽管像BERT这样的大型语言模型在语义任务中表现出强大的实证性能，但这种表现是否反映了真正的概念能力还是仅基于表面统计关联仍不明确。本研究通过分析BERT内部对分类、部分与整体及功能关系的概念对表示，探讨其是否编码了抽象的关系模式。研究比较了BERT的关系分类性能与[CLS]标记嵌入的表征结构。结果显示，预训练BERT能够实现高分类准确率，表明存在潜在的关系信号。然而，概念对仅在经过有监督关系分类任务微调后，才会在高维嵌入空间中按关系类型组织。这表明关系模式并非仅通过预训练自然涌现，而是可以通过任务脚手架诱导产生。这些发现表明，行为表现不必然意味着结构化概念理解，但模型可通过适当训练获得关系抽象的归纳偏置。

</details>


### [66] [Lag-Relative Sparse Attention In Long Context Training](https://arxiv.org/abs/2506.11498)
**中文标题：长上下文训练中的滞后相对稀疏注意力**

*Manlai Liang,Wanyi Huang,Mandi Liu,Huaijun Li,Jinlong Li*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Lag-Relative Sparse Attention（LRSA）的方法，通过LagKV压缩技术减少长上下文训练中的计算和内存开销，同时保持模型性能。实验表明，该方法显著提升了语言模型在键值压缩下的鲁棒性，并在问答任务中取得了更好的微调结果。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在处理长上下文输入时，由于注意力计算的二次复杂性和键值内存的线性增长，面临计算和内存限制。现有的键值缓存压缩技术虽能减少开销，但会导致性能下降，且通常不适合训练后使用。因此，需要一种无需额外参数且计算开销低的方法来提升模型在压缩上下文中的表现。

研究方法: 本文提出Lag-Relative Sparse Attention（LRSA）方法，结合LagKV压缩技术，通过分块预填充和固定大小的滞后窗口选择最相关的键值对，使模型能够高效关注关键历史上下文。

研究结果: 实验结果表明，LRSA方法显著提升了语言模型在键值压缩下的鲁棒性，并在问答微调任务中取得了更好的性能。

研究结论: LRSA方法通过LagKV压缩技术有效解决了长上下文训练中的计算和内存问题，同时保持了模型性能，为语言模型的长上下文处理提供了高效解决方案。

中文摘要: 大型语言模型（LLMs）在自然语言处理和生成方面取得了显著进展，但其处理长上下文输入的能力仍受限于注意力计算的二次复杂性和键值内存的线性增长。为降低计算成本和内存占用，推理时通常采用键值缓存压缩技术，但这往往导致性能严重下降，因为模型未针对压缩上下文进行训练。尽管存在更复杂的压缩方法，但它们通常因与基于梯度的优化不兼容或计算开销过高而不适合训练后使用。为填补这一空白，我们提出了一种无需额外参数且计算开销低的滞后相对稀疏注意力（LRSA）方法，基于LagKV压缩技术进行长上下文训练后处理。该方法通过分块预填充，在固定大小的滞后窗口中选择最相关的键值对，使模型能够高效关注关键历史上下文。实验结果表明，我们的方法显著提升了LLM在键值压缩下的鲁棒性，并在问答微调任务中取得了更好的结果。

</details>


### [67] [On the Effectiveness of Integration Methods for Multimodal Dialogue Response Retrieval](https://arxiv.org/abs/2506.11499)
**中文标题：多模态对话响应检索中集成方法的有效性研究**

*Seongbo Jang,Seonghyeon Lee,Dongha Lee,Hwanjo Yu*

主要分类: cs.CL

摘要简述: 本文探讨了多模态对话响应检索的有效性，比较了两种集成方法（两步法和端到端法），发现端到端法性能相当且更高效，参数共享策略还能提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态聊天机器人在研究和工业界的兴起，如何实现多模态（如文本和图像）的对话响应成为关键问题。本文旨在探索多模态对话响应检索任务的有效方法。

研究方法: 首先将多模态对话响应检索任务划分为三个子任务，随后提出两种集成方法：基于两步法和端到端法，并比较其优缺点。

研究结果: 实验结果表明，端到端法在性能上与两步法相当，且无需中间步骤；参数共享策略不仅减少了参数量，还通过跨子任务和模态的知识迁移提升了性能。

研究结论: 端到端方法在多模态对话响应检索中表现优异，参数共享策略进一步优化了模型性能，为多模态对话系统提供了高效解决方案。

中文摘要: 多模态聊天机器人已成为对话系统研究和工业界的主要课题之一。近年来，研究者开始关注多模态响应及对话上下文。本文探讨了对话系统如何输出文本和图像等多种模态的响应。为此，我们首先将多模态对话响应检索任务定义为三个子任务的组合，随后提出了基于两步法和端到端法的三种集成方法，并比较了各自的优缺点。在两个数据集上的实验结果表明，端到端法无需中间步骤即可达到与两步法相当的性能。此外，参数共享策略不仅减少了参数量，还通过跨子任务和模态的知识迁移提升了性能。

</details>


### [68] [From Persona to Person: Enhancing the Naturalness with Multiple Discourse Relations Graph Learning in Personalized Dialogue Generation](https://arxiv.org/abs/2506.11557)
**中文标题：从角色到人：基于多话语关系图学习的个性化对话生成自然性增强**

*Chih-Hao Hsu,Ying-Jia Lin,Hung-Yu Kao*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MUDI的方法，通过多话语关系图学习提升个性化对话生成的自然性。该方法利用大型语言模型标注话语关系并构建结构化对话图，结合新型注意力策略显著提升对话质量。


<details>
  <summary>详细信息</summary>
研究动机: 在对话生成中，自然性对有效的人机交互至关重要。个性化对话生成更具挑战性，需确保回复与用户个人特质一致。现有方法常忽略话语关系，导致对话连贯性不足。

研究方法: 提出MUDI方法，利用大型语言模型标注话语关系并构建对话图，设计DialogueGAT图编码器捕捉隐含话语关系。在生成阶段，采用一致性感知注意力策略增强解码器对关系的考量。

研究结果: 实验表明，MUDI显著提升了个性化对话的质量，生成的回复更接近人类对话的自然性和连贯性。

研究结论: MUDI通过多话语关系图学习和一致性感知策略，有效提升了个性化对话生成的自然性和连贯性，为未来研究提供了新方向。

中文摘要: 在对话生成中，回复的自然性对有效的人机交互至关重要。个性化回复生成更具挑战性，需确保回复与用户的个人特质或角色描述一致且连贯。我们提出MUDI（多话语关系图学习）方法，利用大型语言模型标注话语关系并将对话数据转化为结构化对话图。提出的DialogueGAT图编码器捕捉了该结构中的隐含话语关系及角色描述。在个性化回复生成阶段，采用新型一致性感知注意力策略以增强解码器对话语关系的考量。实验表明，该方法显著提升了个性化回复的质量，使其更接近人类对话的自然性。

</details>


### [69] [Are LLMs Good Text Diacritizers? An Arabic and Yorùbá Case Study](https://arxiv.org/abs/2506.11602)
**中文标题：大型语言模型是好的文本标注工具吗？阿拉伯语和约鲁巴语的案例研究**

*Hawau Olamide Toyin,Samar M. Magdy,Hanan Aldarmaki*

主要分类: cs.CL

摘要简述: 研究探讨大型语言模型（LLMs）在阿拉伯语和约鲁巴语文本标注任务中的表现，发现多数现成LLMs优于专业标注模型，但小模型易产生幻觉，微调可提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 探讨大型语言模型在多语言文本标注任务中的有效性，尤其是针对阿拉伯语和约鲁巴语这两种类型迥异的语言。

研究方法: 引入多语言数据集MultiDiac，评估14种不同规模、可访问性和语言覆盖的LLMs，并与6种专业标注模型对比；对4种小型开源模型进行LoRA微调。

研究结果: 多数现成LLMs在阿拉伯语和约鲁巴语标注任务中优于专业模型，但小模型易产生幻觉；微调可显著提升性能并减少幻觉。

研究结论: LLMs在多语言文本标注任务中表现优异，微调可进一步优化小模型性能。

中文摘要: 本研究探讨了大型语言模型（LLMs）在两种类型迥异的语言（阿拉伯语和约鲁巴语）中文本标注的有效性。为进行严格评估，我们引入了新型多语言数据集MultiDiac，其中包含多样化的样本以捕捉多种标注歧义。我们评估了14种不同规模、可访问性和语言覆盖的LLMs，并与6种专业标注模型进行对比。此外，我们使用LoRA对4种小型开源模型进行了约鲁巴语的微调。结果显示，许多现成LLMs在阿拉伯语和约鲁巴语标注任务中优于专业模型，但小模型易产生幻觉。微调小型数据集可提升标注性能并减少幻觉率。

</details>


### [70] [SceneGram: Conceptualizing and Describing Tangrams in Scene Context](https://arxiv.org/abs/2506.11631)
**中文标题：SceneGram：场景上下文中七巧板的概念化与描述**

*Simeon Junker,Sina Zarrieß*

主要分类: cs.CL

摘要简述: 本文介绍了SceneGram数据集，用于研究场景上下文对人类概念化抽象形状（如七巧板）的影响，并对比了多模态大语言模型与人类在概念化上的差异。


<details>
  <summary>详细信息</summary>
研究动机: 人类对同一抽象形状（如七巧板）的概念化和命名方式多样，且场景上下文对视觉感知和概念预期有重要影响。本文旨在通过SceneGram数据集，系统分析场景上下文对概念化的作用，并探讨多模态大语言模型在此方面的表现。

研究方法: 研究构建了SceneGram数据集，包含人类在不同场景中对七巧板形状的命名和概念化数据。基于此数据，分析了多模态大语言模型生成的七巧板形状概念化结果，并与人类数据对比。

研究结果: 研究发现，多模态大语言模型在概念化七巧板形状时，未能体现人类参考的丰富性和多样性，表明模型在场景上下文理解上存在局限性。

研究结论: SceneGram数据集为研究场景上下文对概念化的影响提供了系统工具，同时揭示了多模态大语言模型在此任务上的不足，为未来改进提供了方向。

中文摘要: 关于指称和命名的研究表明，人类对同一对象（如同一个抽象七巧板形状）的概念化和命名方式可能截然不同，例如“螃蟹”、“水槽”或“宇宙飞船”。认知科学的另一个常见假设是，场景上下文从根本上塑造了我们对物体的视觉感知和概念预期。本文贡献了SceneGram数据集，包含人类在不同场景中对七巧板形状的命名数据，为系统分析场景上下文对概念化的影响提供了工具。基于这些数据，我们分析了多模态大语言模型生成的七巧板形状概念化结果，发现这些模型未能体现人类参考中的丰富性和多样性。

</details>


### [71] [LoRA-Gen: Specializing Large Language Model via Online LoRA Generation](https://arxiv.org/abs/2506.11638)
**中文标题：LoRA-Gen：通过在线LoRA生成实现大语言模型的领域专业化**

*Yicheng Xiao,Lin Song,Rui Yang,Cheng Cheng,Yixiao Ge,Xiu Li,Ying Shan*

主要分类: cs.CL

摘要简述: LoRA-Gen框架通过云端大模型生成边缘侧模型的LoRA参数，实现高效领域专业化，显著提升推理速度和压缩比。


<details>
  <summary>详细信息</summary>
研究动机: 现有大规模语言模型在领域特定任务中效果和效率受限，尤其是小型边缘侧模型。LoRA-Gen旨在通过云端模型生成LoRA参数，提升边缘侧模型的性能和效率。

研究方法: 利用云端大模型根据任务描述生成LoRA参数，通过重参数化技术将其合并到边缘侧模型，实现灵活专业化。

研究结果: LoRA-Gen在未进行专门训练的情况下，优于传统LoRA微调，推理速度提升2.1倍，压缩比达10.1倍。

研究结论: LoRA-Gen通过云端生成LoRA参数，显著提升了边缘侧模型的效率和性能，为领域专业化提供了高效解决方案。

中文摘要: 近期研究表明，扩大语言模型规模可提升多种NLP任务性能，但这些方法在领域特定任务中仍存在效果和效率限制，尤其对小型边缘侧模型。我们提出LoRA-Gen框架，利用云端大模型根据任务描述生成边缘侧模型的LoRA参数，通过重参数化技术将其合并以实现灵活专业化。该方法促进了模型间知识迁移，同时通过减少输入上下文长度显著提升专业化模型的推理效率。未经专门训练，LoRA-Gen在推理任务中优于传统LoRA微调，TinyLLaMA-1.1B实现竞争性准确率和2.1倍加速。此外，在智能代理任务中，Gemma-2B的压缩比达10.1倍。

</details>


### [72] [Converting Annotated Clinical Cases into Structured Case Report Forms](https://arxiv.org/abs/2506.11666)
**中文标题：将标注的临床病例转换为结构化病例报告表**

*Pietro Ferrazzi,Alberto Lavelli,Bernardo Magnini*

主要分类: cs.CL

摘要简述: 本文提出了一种半自动方法，将标注的临床病例数据集转换为结构化病例报告表（CRF），以解决CRF数据集稀缺的问题。通过实验验证，该方法生成的CRF数据集在槽填充任务中表现优于开源模型，但挑战仍存。


<details>
  <summary>详细信息</summary>
研究动机: 公开可用的高质量CRF数据集稀缺，限制了基于临床笔记自动填充CRF的系统开发。本文旨在利用现有信息提取任务的标注数据集，将其转换为结构化CRF，以填补这一空白。

研究方法: 提出了一种半自动转换方法，将E3C数据集（包含英语和意大利语）转换为结构化CRF。该方法结合人工和自动化步骤，确保生成高质量的CRF数据集。

研究结果: 实验结果显示，在生成的CRF数据集上，槽填充任务在意大利语和英语中分别达到59.7%和67.3%的准确率（使用零样本大型语言模型），而开源模型表现较差，表明CRF填充任务对当前先进模型仍具挑战性。

研究结论: 本文成功将标注临床病例转换为结构化CRF，并发布了高质量数据集。实验表明，CRF填充任务对现有模型仍具难度，为未来研究提供了新方向。

中文摘要: 病例报告表（CRF）在医学研究中广泛应用，因其能确保临床研究结果的准确性、可靠性和有效性。然而，公开可用的高质量标注CRF数据集稀缺，限制了基于临床笔记自动填充CRF的系统开发。为缓解CRF数据集的稀缺性，本文提出利用现有信息提取任务的标注数据集，将其转换为结构化CRF。我们提出了一种半自动转换方法，并将其应用于E3C数据集（包含英语和意大利语），生成了一个高质量的CRF槽填充数据集。通过在生成数据集上的实验，我们发现槽填充任务在意大利语和英语中分别达到59.7%和67.3%的准确率（使用零样本大型语言模型），而开源模型表现较差，表明CRF填充任务对当前先进模型仍具挑战性。我们发布了该数据集：https://huggingface.co/collections/NLP-FBK/e3c-to-crf-67b9844065460cbe42f80166。

</details>


### [73] [Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE](https://arxiv.org/abs/2506.11673)
**中文标题：通过均值投影或LEACE改进失忆探针中的因果干预**

*Alicja Dobrzeniecka,Antske Fokkens,Pia Sommerauer*

主要分类: cs.CL

摘要简述: 本文提出两种新方法（均值投影和LEACE）以改进失忆探针中的因果干预，相比传统方法（INLP）能更精准地移除目标信息，减少随机干扰。


<details>
  <summary>详细信息</summary>
研究动机: 传统失忆探针技术（如INLP）在移除目标信息时会引入随机干扰，影响模型行为的解释性。本文旨在提出更精准的信息移除方法，以提升失忆探针的有效性。

研究方法: 提出两种替代方法：均值投影（MP）和LEACE，通过更针对性的方式移除目标信息，避免INLP带来的随机修改。

研究结果: 实验表明，MP和LEACE能更精准地移除目标信息，减少对模型其他信息的干扰，从而提升失忆探针的解释能力。

研究结论: MP和LEACE为失忆探针提供了更可靠的信息移除技术，有助于更准确地分析模型行为。

中文摘要: 失忆探针是一种用于检验特定语言信息对模型行为影响的技术。其核心是通过识别并移除相关信息，观察模型在主任务上的表现是否变化。若移除的信息相关，模型性能应下降。然而，传统方法（如迭代零空间投影INLP）在移除目标信息时会引入随机干扰。本文提出的两种替代方法——均值投影（MP）和LEACE，能够更精准地移除目标信息，从而提升失忆探针的行为解释能力。

</details>


### [74] [LLMs for Sentence Simplification: A Hybrid Multi-Agent prompting Approach](https://arxiv.org/abs/2506.11681)
**中文标题：大语言模型用于句子简化：一种混合多智能体提示方法**

*Pratibha Zunjare,Michael Hsiao*

主要分类: cs.CL

摘要简述: 本文提出了一种结合多智能体架构和高级提示的混合方法，用于将复杂句子简化为逻辑清晰的简单句子，同时保持语义和逻辑完整性。实验表明，该方法在视频游戏设计应用中成功简化了70%的复杂句子，优于单智能体方法的48%成功率。


<details>
  <summary>详细信息</summary>
研究动机: 面对将复杂句子转化为逻辑清晰且语义完整的简单句子的挑战，本文旨在利用大语言模型和多智能体架构提升句子简化任务的效率和准确性。

研究方法: 采用了一种混合方法，结合高级提示技术和多智能体架构，通过协作优化句子简化过程。

研究结果: 实验结果显示，该方法在视频游戏设计应用中成功简化了70%的复杂句子，显著优于单智能体方法的48%成功率。

研究结论: 本文提出的混合多智能体提示方法在句子简化任务中表现出色，为复杂语言处理任务提供了新的解决方案。

中文摘要: 本文探讨了如何利用大语言模型将复杂句子转化为逻辑清晰且语义完整的简单句子序列。我们提出了一种结合高级提示和多智能体架构的混合方法，以优化句子简化过程。实验结果表明，该方法在视频游戏设计应用中成功简化了70%的复杂句子，而单智能体方法在同一任务中的成功率仅为48%。

</details>


### [75] [Configurable Preference Tuning with Rubric-Guided Synthetic Data](https://arxiv.org/abs/2506.11702)
**中文标题：基于评分标准引导合成数据的可配置偏好调优**

*Víctor Gallego*

主要分类: cs.CL

摘要简述: 本文提出了一种名为可配置偏好调优（CPT）的新框架，通过基于结构化评分标准生成的合成数据，使语言模型能够根据人类可理解的指令动态调整行为，无需重新训练。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人类反馈模型（如直接偏好优化DPO）通常基于单一静态偏好，限制了适应性。本文旨在打破这一假设，提供一种更灵活、细粒度的偏好调整方法。

研究方法: CPT框架利用结构化评分标准生成合成偏好数据，通过微调语言模型使其能够根据系统提示动态调整输出行为。

研究结果: 实验表明，CPT能够实现对语言模型输出的细粒度控制，并支持更复杂、上下文相关的人类反馈建模。相关代码、数据集和模型已开源。

研究结论: CPT为语言模型提供了动态调整行为的能力，同时支持更灵活的偏好配置，为AI对齐研究提供了新工具。

中文摘要: 人类反馈模型（如直接偏好优化DPO）通常基于单一静态偏好，限制了适应性。本文提出可配置偏好调优（CPT），通过基于结构化评分标准生成的合成数据，使语言模型能够根据人类可理解的指令动态调整行为。CPT利用评分标准引导的偏好数据微调模型，使其在推理时根据系统提示调整输出，无需重新训练。该方法不仅提供细粒度控制，还能建模更复杂、上下文相关的人类反馈。实验相关代码、数据集和模型已发布于https://github.com/vicgalle/configurable-preference-tuning。

</details>


### [76] [The Cambrian Explosion of Mixed-Precision Matrix Multiplication for Quantized Deep Learning Inference](https://arxiv.org/abs/2506.11728)
**中文标题：量化深度学习推理中混合精度矩阵乘法的寒武纪爆发**

*Héctor Martínez,Adrián Castelló,Francisco D. Igual,Enrique S. Quintana-Ortí*

主要分类: cs.CL

摘要简述: 本文探讨了深度学习推理中混合精度矩阵乘法（MIP）的优化，提出了适应现代指令集架构（如x86_64、ARM和RISC-V）的新型微内核设计和数据布局，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度学习从传统的64位浮点计算转向低精度格式（如FP16、BF16和8/16位整数），硬件架构也相应演进，但传统的高性能矩阵乘法（gemm）方法已无法满足需求。本文旨在重新设计gemm以适应混合精度整数（MIP）算术，提升计算效率和性能。

研究方法: 本文提出了新型微内核设计和数据布局，以更好地利用现代硬件（如x86_64、ARM和RISC-V）的混合精度点积操作，优化量化推理任务中的矩阵乘法性能。

研究结果: 实验表明，混合精度整数算术在三种代表性CPU架构上均显著优于浮点实现，性能提升明显。

研究结论: 本文标志着矩阵乘法优化的新时代，即由深度学习推理需求驱动的“寒武纪爆发”时期，为异构架构下的高效计算提供了新思路。

中文摘要: 近年来，深度学习（DL）的进展推动了从传统的64位浮点（FP64）计算向低精度格式（如FP16、BF16和8/16位整数）的转变，并结合混合精度算术。这一转变提升了计算吞吐量，减少了内存和带宽占用，并提高了能源效率，为资源受限的边缘设备带来了显著优势。为支持这一转变，硬件架构也相应演进，包括适配的指令集架构（ISA），这些架构提供了针对DL工作负载优化的混合精度向量单元和矩阵引擎。许多DL和科学计算任务的核心是通用矩阵乘法（gemm），这一基础内核传统上通过SIMD（单指令多数据）单元的axpy向量指令优化。然而，随着硬件转向针对量化推理优化的混合精度点积操作，这些传统方法逐渐被淘汰。为此，本文重新审视了传统高性能gemm，并描述了如何将其适应现代ISA（如x86_64、ARM和RISC-V）中的混合精度整数（MIP）算术。具体而言，我们展示了新型微内核设计和数据布局，以更好地利用现代专用硬件，并在三种代表性CPU架构上证明了MIP算术相对于浮点实现的显著性能提升。这些贡献标志着由DL推理需求驱动的gemm优化新时代，即我们所谓的矩阵乘法的“寒武纪时期”。

</details>


### [77] [DART: Distilling Autoregressive Reasoning to Silent Thought](https://arxiv.org/abs/2506.11752)
**中文标题：DART：将自回归推理蒸馏为静默思维**

*Nan Jiang,Ziming Wu,De-Chuan Zhan,Fuming Lai,Shaobing Lian*

主要分类: cs.CL

摘要简述: 论文提出DART框架，通过自蒸馏将自回归推理转化为非自回归的静默思维（ST），显著提升大型语言模型（LLM）的推理效率，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 自回归的链式思维（CoT）推理虽然提升了LLM的复杂任务解决能力，但其计算开销大，难以应用于延迟敏感场景。DART旨在通过非自回归的静默思维（ST）替代CoT，以提升效率。

研究方法: DART包含两条训练路径：传统的CoT路径和直接生成答案的ST路径。ST路径通过轻量级推理演进模块（REM）对齐隐藏状态，使ST令牌演化为信息丰富的嵌入。推理时仅激活ST路径。

研究结果: 实验表明，DART在推理性能上与现有基线相当，同时显著提升了效率，成为高效推理的可行替代方案。

研究结论: DART通过自蒸馏实现非自回归推理，为LLM的高效推理提供了新思路，适用于延迟敏感场景。

中文摘要: 链式思维（CoT）推理显著提升了大型语言模型（LLM）解决复杂任务的能力，但其自回归范式导致计算开销大，难以部署于延迟敏感的应用中。为此，我们提出DART（将自回归推理蒸馏为静默思维），这是一种自蒸馏框架，使LLM能够用非自回归的静默思维（ST）替代自回归的CoT。具体而言，DART引入两条训练路径：传统的CoT推理路径和直接从少量ST令牌生成答案的ST路径。ST路径利用轻量级推理演进模块（REM）对齐其隐藏状态与CoT路径，使ST令牌演化为信息丰富的嵌入。推理时仅激活ST路径，利用演化的ST令牌直接输出答案。大量实验结果表明，DART在推理性能上与现有基线相当，同时显著提升了效率，成为高效推理的可行替代方案。

</details>


### [78] [DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents](https://arxiv.org/abs/2506.11763)
**中文标题：DeepResearch Bench：深度研究代理的综合基准**

*Mingxuan Du,Benfeng Xu,Chiwei Zhu,Xiaorui Wang,Zhendong Mao*

主要分类: cs.CL

摘要简述: 本文介绍了DeepResearch Bench，一个用于系统评估基于LLM的深度研究代理（DRA）能力的综合基准，包含100个博士级研究任务，并提出两种新方法以对齐人类判断。


<details>
  <summary>详细信息</summary>
研究动机: 目前缺乏系统评估深度研究代理（DRA）能力的综合基准，阻碍了其发展。本文旨在填补这一空白，提供一个全面且可靠的评估工具。

研究方法: 提出了DeepResearch Bench基准，包含100个跨22个领域的博士级研究任务，并设计了两种评估方法：基于参考的自适应标准评估报告质量，以及评估信息检索能力的引用框架。

研究结果: DeepResearch Bench开源发布，两种评估方法在人类判断对齐方面表现良好，为LLM代理的实用化发展提供了支持。

研究结论: DeepResearch Bench为深度研究代理的评估提供了标准化工具，加速了基于LLM的实用代理的发展。

中文摘要: 深度研究代理（DRA）是一类基于大型语言模型（LLM）的重要代理。通过自主协调多步网络探索、定向检索和高阶综合，它们将大量在线信息转化为分析师级别的、引用丰富的研究报告，将数小时的手动桌面研究压缩为几分钟。然而，目前缺乏系统评估这些代理能力的综合基准。为填补这一空白，我们提出了DeepResearch Bench，一个包含100个博士级研究任务的基准，每个任务均由22个不同领域的专家精心设计。评估DRA具有固有的复杂性和劳动密集性。因此，我们提出了两种新方法以实现与人类判断的强对齐。第一种是基于参考的自适应标准方法，用于评估生成研究报告的质量。另一种框架通过评估有效引用数量和整体引用准确性来衡量DRA的信息检索和收集能力。我们已开源DeepResearch Bench及这些框架的关键组件（https://github.com/Ayanami0730/deep_research_bench），以加速基于LLM的实用代理的发展。

</details>


### [79] [Long-Short Alignment for Effective Long-Context Modeling in LLMs](https://arxiv.org/abs/2506.11769)
**中文标题：长短期对齐：提升大语言模型长上下文建模的有效性**

*Tianqi Du,Haotian Huang,Yifei Wang,Yisen Wang*

主要分类: cs.CL

摘要简述: 本文提出了一种新视角来解决大语言模型（LLMs）在长上下文建模中的长度泛化问题，重点关注输出分布的一致性（长短期对齐），并提出了一种正则化方法以提高模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在长上下文建模中受限于固定的上下文窗口，尤其是长度泛化问题（即模型对长于训练序列的泛化能力）。传统方法关注输入特征（如位置编码或数据结构），而本文转向输出分布的一致性，以提升模型效果。

研究方法: 通过合成任务的案例研究，提出了“长短期对齐”概念，即不同长度序列输出分布的一致性。进一步提出了一种度量指标“长短期不对齐”来量化这一现象，并设计了一种正则化方法以在训练中促进对齐。

研究结果: 实验表明，长短期对齐与长度泛化性能高度相关，提出的正则化方法显著提升了模型在长上下文任务中的表现。

研究结论: 本文通过关注输出分布的一致性，为长上下文建模提供了新思路，提出的方法有效提升了LLMs的长度泛化能力。

中文摘要: 大语言模型（LLMs）表现出令人印象深刻的性能和涌现特性，但其有效性受限于Transformer架构的固定上下文窗口，尤其是在长上下文建模中。长度泛化（即对长于训练序列的泛化能力）是一个经典且基础的问题。本文提出了一种新视角，将关注点从传统的输入特征（如位置编码或数据结构）转移到模型的输出分布上。通过合成任务的案例研究，我们强调了“长短期对齐”（即不同长度序列输出分布的一致性）的关键作用。进一步提出了一种称为“长短期不对齐”的度量指标，揭示了其与长度泛化性能的强相关性。基于这些发现，我们设计了一种正则化方法以在训练中促进对齐。大量实验验证了该方法的有效性，为LLMs的长上下文建模提供了新见解。代码发布于https://github.com/PKU-ML/LongShortAlignment。

</details>


### [80] [Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models](https://arxiv.org/abs/2506.11798)
**中文标题：基于大型语言模型的角色驱动欧洲议会投票行为模拟**

*Maximilian Kreutner,Marlene Lutz,Markus Strohmaier*

主要分类: cs.CL

摘要简述: 本研究探讨了如何利用零样本角色提示的大型语言模型（LLMs）预测欧洲议会成员的投票行为，发现其预测准确率较高（加权F1分数约0.793），并验证了预测对不同角色提示和生成方法的稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在政治话语中表现出明显的进步左倾偏见，而角色提示可以调整模型行为以匹配不同社会经济群体。本研究旨在验证零样本角色提示是否能准确预测欧洲议会成员的投票行为及其群体立场。

研究方法: 研究使用零样本角色提示方法，基于有限信息预测欧洲议会成员的投票决策，并通过聚合预测评估不同政策立场。同时，验证了预测对反事实论点、不同角色提示和生成方法的稳定性。

研究结果: 研究发现，零样本角色提示能够较准确地模拟欧洲议会成员的投票行为，加权F1分数达到约0.793。此外，预测结果对不同角色提示和生成方法表现出稳定性。

研究结论: 研究表明，零样本角色提示的大型语言模型可以有效模拟欧洲议会成员的投票行为，为政治行为预测提供了新工具。

中文摘要: 大型语言模型（LLMs）在理解甚至生成政治话语方面表现出卓越能力，但普遍存在进步左倾偏见。同时，角色或身份提示已被证明可以调整LLM行为以匹配与其基础模型不一致的社会经济群体。本研究分析了零样本角色提示在有限信息下是否能准确预测个体投票决策，并通过聚合预测评估欧洲群体在多样化政策上的立场。此外，验证了预测对反事实论点、不同角色提示和生成方法的稳定性。最终发现，该方法能够较准确地模拟欧洲议会成员的投票行为，加权F1分数约为0.793。2024年欧洲议会议员的角色数据集及代码已公开于https://github.com/dess-mannheim/european_parliament_simulation。

</details>


### [81] [Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?](https://arxiv.org/abs/2506.11807)
**中文标题：多模态大语言模型在简单参考解析任务中是否具备语用能力？**

*Simeon Junker,Manar Ali,Larissa Koch,Sina Zarrieß,Hendrik Buschmeier*

主要分类: cs.CL

摘要简述: 研究探讨多模态大语言模型在简单参考解析任务中的语用能力，发现其在基础语用能力（如颜色描述的上下文依赖解释）上仍面临挑战。


<details>
  <summary>详细信息</summary>
研究动机: 尽管简单参考解析任务对人类而言轻而易举，但研究认为这是检验多模态大语言模型语用能力的有效方式，尤其是针对其上下文依赖解释能力。

研究方法: 研究采用抽象视觉刺激（如色块和颜色网格）设计参考解析任务，测试多模态大语言模型的表现。

研究结果: 结果表明，即使是先进的多模态大语言模型，在基础语用能力（如颜色描述的上下文依赖解释）上仍存在显著不足。

研究结论: 多模态大语言模型在简单参考解析任务中的语用能力仍有待提升，尤其是在上下文依赖解释方面。

中文摘要: 我们研究了多模态大语言模型在涉及简单但抽象视觉刺激（如色块和颜色网格）的参考解析任务中的语言能力。尽管这类任务对当今的语言模型而言似乎并不困难，对人类而言更是轻而易举，但我们认为这是检验多模态大语言模型语用能力的有效方式。我们的结果和分析表明，基础语用能力（如颜色描述的上下文依赖解释）对当前最先进的多模态大语言模型仍构成重大挑战。

</details>


### [82] [Post Persona Alignment for Multi-Session Dialogue Generation](https://arxiv.org/abs/2506.11857)
**中文标题：多会话对话生成的后验角色对齐**

*Yi-Pei Chen,Noriki Nishida,Hideki Nakayama,Yuji Matsumoto*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“后验角色对齐”（PPA）的两阶段框架，用于解决多会话角色对话生成中的一致性和多样性问题。PPA首先生成通用响应，再根据响应检索相关角色记忆并优化对齐，显著提升了对话的一致性和个性化。


<details>
  <summary>详细信息</summary>
研究动机: 多会话角色对话生成面临长期一致性和个性化响应多样性的挑战。现有方法通常在生成响应前检索角色信息，限制了多样性并导致通用输出。本文旨在通过后验对齐策略解决这些问题。

研究方法: PPA框架分为两阶段：首先生成基于对话上下文的通用响应，然后以响应为查询检索相关角色记忆，最后优化响应以对齐角色。这种后验对齐策略提升了自然性和多样性。

研究结果: 实验表明，PPA在多会话LLM生成对话数据中，显著优于现有方法，在一致性、多样性和角色相关性方面表现更优。

研究结论: PPA为长期个性化对话生成提供了更灵活有效的范式，通过后验对齐策略平衡了一致性与多样性。

中文摘要: 多会话角色对话生成在保持长期一致性和生成多样化个性化响应方面存在挑战。尽管大型语言模型（LLMs）在单次会话中表现优异，但在扩展交互中难以保持角色忠实性和对话连贯性。现有方法通常在生成响应前检索角色信息，这会限制多样性并导致通用输出。我们提出后验角色对齐（PPA），一种新颖的两阶段框架，反转了这一过程。PPA首先生成仅基于对话上下文的通用响应，然后以响应为查询检索相关角色记忆，最后优化响应以对齐说话者角色。这种后验对齐策略在保持一致性和个性化的同时提升了自然性和多样性。在多会话LLM生成对话数据上的实验表明，PPA在一致性、多样性和角色相关性方面显著优于现有方法，为长期个性化对话生成提供了更灵活有效的范式。

</details>


### [83] [Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache](https://arxiv.org/abs/2506.11886)
**中文标题：超越同质注意力：基于傅里叶近似的KV缓存实现内存高效的大语言模型**

*Xiaoran Liu,Siyang He,Qiqi Wang,Ruixiao Li,Yuerong Song,Zhigeng Liu,Linlin Li,Qun Liu,Zengfeng Huang,Qipeng Guo,Ziwei He,Xipeng Qiu*

主要分类: cs.CL

摘要简述: 本文提出FourierAttention，一种无需训练的方法，通过傅里叶近似优化大语言模型的KV缓存，显著降低内存需求并保持长上下文准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着上下文长度增加，大语言模型的KV缓存内存需求急剧上升，现有压缩方法要么牺牲准确性，要么引入计算开销。本文旨在解决这一问题。

研究方法: FourierAttention利用Transformer头维度的异质性，将长上下文不敏感的维度投影到正交傅里叶基上，用固定长度的频谱系数近似其时间演化。

研究结果: 在LLaMA模型上的实验表明，FourierAttention在LongBench和NIAH任务中实现了最佳的长上下文准确性，并通过FlashFourierAttention内核优化内存效率。

研究结论: FourierAttention提供了一种高效且无需训练的方法，显著降低KV缓存内存需求，同时保持模型性能。

中文摘要: 随着上下文长度的增加，大语言模型面临来自不断增长的键值（KV）缓存的内存需求问题。现有的压缩方法要么同质化头维度，要么依赖注意力引导的令牌修剪，通常会牺牲准确性或引入计算开销。我们提出了FourierAttention，这是一种无需训练的框架，利用了Transformer头维度的异质性：低维度优先处理局部上下文，而高维度则捕捉长距离依赖关系。通过将长上下文不敏感的维度投影到正交傅里叶基上，FourierAttention用固定长度的频谱系数近似其时间演化。在LLaMA模型上的评估表明，FourierAttention在LongBench和Needle-In-A-Haystack（NIAH）任务中实现了最佳的长上下文准确性。此外，我们还设计了一个定制的Triton内核FlashFourierAttention，通过简化的读写操作优化内存，实现高效部署且不影响性能。

</details>


### [84] [GeistBERT: Breathing Life into German NLP](https://arxiv.org/abs/2506.11903)
**中文标题：GeistBERT：为德语NLP注入活力**

*Raphael Scheible-Schmitt,Johann Frei*

主要分类: cs.CL

摘要简述: GeistBERT是一种针对德语NLP的预训练语言模型，通过增量训练和优化架构，在多项任务中表现优异，并支持长上下文输入。


<details>
  <summary>详细信息</summary>
研究动机: 德语NLP领域需要适应其语言特点的现代模型和高质量语料库，GeistBERT旨在填补这一空白，提升德语语言处理能力。

研究方法: 基于GottBERT权重初始化，使用fairseq和Whole Word Masking（WWM）在大规模德语语料库上进行预训练，并扩展支持长上下文的Nyströmformer和Longformer架构。

研究结果: GeistBERT在NER和文本分类任务中表现优异，基础模型甚至超越更大模型，创造了新的SOTA。

研究结论: GeistBERT为德语NLP研究提供了强大的工具，模型已开源，支持社区进一步研究。

中文摘要: 基于Transformer的语言模型进展表明，针对特定语言的高质量语料库预训练具有显著优势。在此背景下，德语NLP可从适应其语言特点的现代架构和数据集中受益。GeistBERT旨在通过增量训练多样化语料库和优化模型性能，提升德语语言处理能力。模型使用fairseq和标准超参数预训练，基于GottBERT权重初始化，并采用Whole Word Masking（WWM）在大规模德语语料库上训练。此外，基于预训练模型，我们扩展了支持长达8k标记序列的Nyströmformer和Longformer架构。尽管这些长上下文模型未在专用长上下文基准上评估，但仍包含在发布中。所有模型在NER（CoNLL 2003、GermEval 2014）和文本分类（GermEval 2018细/粗粒度、10kGNAD）任务中通过F1分数和准确率进行评估。GeistBERT模型表现优异，基础模型在所有任务中领先，并创造了新的SOTA。值得注意的是，基础模型在多项任务中超越更大模型。为支持德语NLP研究社区，GeistBERT以MIT许可证发布。

</details>


### [85] [Effectiveness of Counter-Speech against Abusive Content: A Multidimensional Annotation and Classification Study](https://arxiv.org/abs/2506.11919)
**中文标题：反言论对抗辱骂内容的有效性：多维度标注与分类研究**

*Greta Damo,Elena Cabrio,Serena Villata*

主要分类: cs.CL

摘要简述: 本文提出了一种基于社会科学概念的反言论有效性分类框架，定义了六个核心维度，并标注了4214个反言论实例，构建了新的语言资源。通过多任务和依赖关系分类策略，取得了优于基线的结果。


<details>
  <summary>详细信息</summary>
研究动机: 反言论是缓解网络仇恨言论的关键策略，但评估其有效性的标准尚未明确。本文旨在填补这一空白，提出一个计算框架来分类反言论的有效性。

研究方法: 研究提出了一个包含六个核心维度（清晰性、证据、情感吸引力、反驳、受众适应性和公平性）的分类框架，并标注了两个基准数据集中的4214个反言论实例。此外，提出了多任务和依赖关系两种分类策略。

研究结果: 实验结果显示，两种分类策略在专家和用户撰写的反言论上均取得了优异表现（平均F1分别为0.94和0.96），显著优于基线方法，并揭示了维度间的强相关性。

研究结论: 本文提出的框架和分类策略为反言论有效性评估提供了新工具，同时发布的语言资源有助于未来研究。

中文摘要: 反言论（CS）是缓解网络仇恨言论（HS）的关键策略，但评估其有效性的标准仍是一个未解决的挑战。我们提出了一种基于社会科学概念的反言论有效性分类计算框架。该框架定义了六个核心维度——清晰性、证据、情感吸引力、反驳、受众适应性和公平性，并用于标注来自两个基准数据集的4214个反言论实例，从而构建了一个新的语言资源并公开发布。此外，我们提出了多任务和依赖关系两种分类策略，在专家和用户撰写的反言论上均取得了优异结果（平均F1分别为0.94和0.96），优于标准基线方法，并揭示了维度间的强相关性。

</details>


### [86] [Feedback Friction: LLMs Struggle to Fully Incorporate External Feedback](https://arxiv.org/abs/2506.11930)
**中文标题：反馈摩擦：大语言模型难以完全整合外部反馈**

*Dongwei Jiang,Alvin Zhang,Andrew Wang,Nicholas Andrews,Daniel Khashabi*

主要分类: cs.CL

摘要简述: 研究发现，即使在大语言模型（LLM）接收到近乎完美的外部反馈时，它们仍难以完全整合反馈并修正错误，这种现象被称为“反馈摩擦”。通过实验验证，模型对反馈的抵抗性普遍存在，且尝试的改进策略效果有限。


<details>
  <summary>详细信息</summary>
研究动机: 尽管研究表明LLM在接收外部反馈后能部分改进回答，但其整合反馈的效率和彻底性尚不明确。本文旨在系统探究LLM在理想条件下（近乎完美的反馈）是否能完全修正错误，并揭示其局限性。

研究方法: 设计了一个控制实验环境：首先由求解模型尝试解答问题，随后反馈生成器基于完整真实答案提供针对性反馈，求解模型再次尝试。实验涵盖数学推理、知识推理、科学推理等多领域任务，并测试了包括Claude 3.7在内的先进模型。

研究结果: 即使在近乎理想的反馈条件下，求解模型仍表现出对反馈的抵抗性（反馈摩擦）。尝试的温度渐进增加和显式拒绝错误答案等策略虽有所改进，但未能使模型达到目标性能。排除了模型过度自信和数据熟悉度等潜在原因。

研究结论: LLM在整合外部反馈时存在显著局限性（反馈摩擦），现有改进策略效果有限。研究排除了部分潜在原因，为未来自我改进研究提供了方向。

中文摘要: 近期研究表明，大语言模型（LLM）在接收外部反馈后具备一定改进能力，但其整合反馈的效率和彻底性尚不明确。理想情况下，若LLM接收到近乎完美的反馈，应能完全修正错误答案。本文通过设计控制实验环境，系统探究了LLM整合反馈的能力：求解模型尝试解答后，反馈生成器基于完整真实答案提供针对性反馈，随后求解模型再次尝试。实验覆盖数学推理、知识推理、科学推理及多领域任务，并测试了包括Claude 3.7（含扩展思考）在内的先进模型。令人惊讶的是，即使在近乎理想条件下，求解模型仍表现出对反馈的抵抗性（反馈摩擦）。为缓解此问题，尝试了温度渐进增加和显式拒绝错误答案等策略，虽有所改进，但未能使模型达到目标性能。此外，研究排除了模型过度自信和数据熟悉度等潜在原因。希望揭示LLM的这一问题并排除部分原因，能为未来自我改进研究提供帮助。

</details>


### [87] [Improving Large Language Model Safety with Contrastive Representation Learning](https://arxiv.org/abs/2506.11938)
**中文标题：通过对比表示学习提升大语言模型的安全性**

*Samuel Simko,Mrinmaya Sachan,Bernhard Schölkopf,Zhijing Jin*

主要分类: cs.CL

摘要简述: 本文提出了一种基于对比表示学习（CRL）的防御框架，通过三元组损失和对抗性硬负样本挖掘，增强大语言模型对恶意输入的鲁棒性，同时保持标准性能。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLMs）虽功能强大，但在面对多样且不受控的输入时容易受到对抗攻击。现有防御方法难以泛化到不同类型的攻击，因此需要一种更有效的防御机制。

研究方法: 该方法将模型防御问题转化为对比表示学习问题，通过三元组损失和对抗性硬负样本挖掘，优化模型以区分良性表示和有害表示。

研究结果: 实验结果表明，该方法在多种模型上优于现有基于表示工程的防御方法，显著提升了对输入级和嵌入空间攻击的鲁棒性，且不影响标准性能。

研究结论: 本文提出的CRL框架为提升大语言模型的安全性提供了一种有效且通用的解决方案，具有实际应用潜力。

中文摘要: 大语言模型（LLMs）是功能强大的工具，对社会具有深远影响，但其对多样且不受控输入的响应能力使其容易受到对抗攻击。尽管现有防御方法往往难以泛化到不同类型的攻击，但表示工程的最新进展提供了有前景的替代方案。本文提出了一种防御框架，将模型防御问题转化为对比表示学习（CRL）问题。我们的方法通过结合三元组损失和对抗性硬负样本挖掘对模型进行微调，以促进良性表示和有害表示的分离。在多个模型上的实验结果表明，我们的方法优于现有基于表示工程的防御方法，提升了对输入级和嵌入空间攻击的鲁棒性，同时不影响标准性能。代码发布于https://github.com/samuelsimko/crl-llm-defense。

</details>


### [88] [code_transformed: The Influence of Large Language Models on Code](https://arxiv.org/abs/2506.12014)
**中文标题：代码的转变：大型语言模型对代码的影响**

*Yuliang Xu,Siming Huang,Mingmeng Geng,Yao Wan,Xuanhua Shi,Dongping Chen*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型（LLMs）对代码风格的影响，发现LLMs显著改变了命名规范、复杂性和可维护性等编码特征，并通过分析GitHub代码库提供了实证支持。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）的快速发展，代码生成能力正在重塑编程实践。本文旨在探讨LLMs是否改变了代码风格，并量化这种影响。

研究方法: 通过分析2020年至2025年间与arXiv论文关联的19,000多个GitHub代码库，研究了命名规范、复杂性、可维护性和相似性等代码风格特征的变化趋势。

研究结果: 研究发现，LLMs显著影响了代码风格，例如Python代码中snake_case变量名的比例从2023年第一季度的47%上升至2025年第一季度的51%。

研究结论: LLMs对实际编程风格产生了可测量的影响，尽管难以精确估计LLMs生成或辅助代码的比例，但本研究首次提供了大规模实证证据。

中文摘要: 编码仍然是人与机器之间最基本的交互方式之一。随着大型语言模型（LLMs）的快速发展，代码生成能力已开始显著重塑编程实践。这一发展引发了一个核心问题：LLMs是否改变了代码风格，以及如何描述这种转变？本文提出了一项开创性研究，探讨了LLMs对代码风格的影响，重点关注命名规范、复杂性、可维护性和相似性。通过分析2020年至2025年间与arXiv论文关联的19,000多个GitHub代码库，我们发现了与LLM生成代码特征相符的编码风格演变趋势。例如，Python代码中snake_case变量名的比例从2023年第一季度的47%上升至2025年第一季度的51%。此外，我们还研究了LLMs解决算法问题的推理过程。鉴于LLMs的多样性和使用场景等因素，精确估计LLMs生成或辅助代码的比例是困难甚至不可能的。我们的实验结果首次提供了LLMs影响实际编程风格的大规模实证证据。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [89] [EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices](https://arxiv.org/abs/2506.11093)
**中文标题：EfficientQuant：一种面向边缘设备的CNN-Transformer混合模型高效后训练量化方法**

*Shaibal Saha,Lanyu Xu*

主要分类: cs.CV

摘要简述: EfficientQuant是一种针对CNN-Transformer混合模型的高效后训练量化方法，通过统一量化卷积块和对数量化Transformer块，显著降低边缘设备上的延迟和内存需求，同时保持高精度。


<details>
  <summary>详细信息</summary>
研究动机: 混合模型结合了卷积和Transformer模块，在计算机视觉任务中表现出色，但在边缘设备上部署时资源消耗大。后训练量化（PTQ）虽能减少资源需求，但在混合模型中的应用仍有限。

研究方法: 提出EfficientQuant，一种结构感知的PTQ方法，对卷积块采用统一量化，对Transformer块采用对数量化（$log_2$量化）。

研究结果: 在ImageNet-1K数据集上，EfficientQuant实现了2.5倍至8.7倍的延迟降低，且精度损失极小。在边缘设备上表现出低延迟和高内存效率。

研究结论: EfficientQuant为CNN-Transformer混合模型提供了一种高效的后训练量化解决方案，适用于边缘设备的实际部署。

中文摘要: 结合卷积和Transformer模块的混合模型在计算机视觉任务中表现出色，但在边缘设备上部署时资源消耗较大。后训练量化（PTQ）虽能减少资源需求，但其在混合模型中的应用仍有限。我们提出EfficientQuant，一种新颖的结构感知PTQ方法，对卷积块采用统一量化，对Transformer块采用对数量化。在ImageNet-1K数据集上，EfficientQuant实现了2.5倍至8.7倍的延迟降低，且精度损失极小。在边缘设备上进一步表现出低延迟和高内存效率，使其适用于实际部署。

</details>


### [90] [Adaptive Object Detection with ESRGAN-Enhanced Resolution & Faster R-CNN](https://arxiv.org/abs/2506.11122)
**中文标题：基于ESRGAN增强分辨率与Faster R-CNN的自适应目标检测**

*Divya Swetha K,Ziaul Haque Choudhury,Hemanta Kumar Bhuyan,Biswajit Brahma,Nilayam Kumar Kamila*

主要分类: cs.CV

摘要简述: 本文提出了一种结合ESRGAN和Faster R-CNN的方法，通过提升低分辨率图像质量并检测目标，显著提高了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 低分辨率图像在目标检测中表现不佳，传统方法难以恢复细节。本研究旨在通过结合超分辨率生成对抗网络（ESRGAN）和Faster R-CNN，提升低质量图像的检测效果。

研究方法: 首先使用ESRGAN对低分辨率图像进行预处理，恢复细节并提升清晰度；然后将增强后的图像输入Faster R-CNN进行目标检测和定位。

研究结果: 实验结果表明，该方法在低分辨率图像上的检测性能优于传统方法，实现了图像质量提升与高效检测的平衡。

研究结论: 该框架为图像质量不稳定的应用提供了有效解决方案，显著提升了目标检测的鲁棒性和可靠性。

中文摘要: 本研究提出了一种通过结合增强超分辨率生成对抗网络（ESRGAN）和快速区域卷积神经网络（Faster R-CNN）来改进低分辨率图像目标检测的方法。ESRGAN用于提升低质量图像的细节和清晰度，而Faster R-CNN则在增强后的图像上进行精确的目标检测。这种组合确保了即使在输入图像质量较差的情况下，也能获得更好的检测性能，为图像分辨率不一致的应用提供了有效解决方案。ESRGAN作为预处理步骤，能够有效恢复丢失的细节并提升整体图像质量。随后，增强后的图像被输入Faster R-CNN模型进行目标检测和定位。实验结果表明，与传统方法相比，这种集成方法在低分辨率图像上表现出更优的性能。该框架为图像质量多变或受限的应用提供了有前景的解决方案，能够在挑战性场景中实现更鲁棒和可靠的目标检测，同时平衡了图像质量提升与高效检测的需求。

</details>


### [91] [Technical Report for Argoverse2 Scenario Mining Challenges on Iterative Error Correction and Spatially-Aware Prompting](https://arxiv.org/abs/2506.11124)
**中文标题：Argoverse2场景挖掘挑战的技术报告：迭代错误修正与空间感知提示**

*Yifei Chen,Ross Greer*

主要分类: cs.CV

摘要简述: 本文针对Argoverse2场景挖掘中的代码生成错误和空间关系理解问题，提出了迭代错误修正和空间感知提示技术，显著提升了场景挖掘的准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: Argoverse2等大规模自动驾驶数据集的场景挖掘对自动驾驶系统的开发和验证至关重要。现有方法（如RefAV框架）利用大语言模型（LLM）生成代码，但面临运行时错误和空间关系参数理解不准确的问题。本文旨在解决这些挑战。

研究方法: 提出了两种改进方法：1）通过迭代代码生成机制，利用错误反馈重新提示LLM以修正代码；2）通过专门的提示工程，提升LLM对复杂空间关系函数的理解和正确应用。实验使用了Qwen2.5-VL-7B、Gemini 2.5 Flash和Gemini 2.5 Pro等模型。

研究结果: 在Argoverse2验证集上的实验表明，所提方法在多项指标上均取得显著提升。使用Gemini 2.5 Pro时，系统在官方测试集上的HOTA-Temporal得分达到52.37。

研究结论: 本文提出的迭代错误修正和空间感知提示技术有效提升了场景挖掘的可靠性和精度，为自动驾驶系统的开发提供了有力支持。

中文摘要: 从大规模自动驾驶数据集（如Argoverse2）中挖掘场景对自动驾驶系统的开发和验证至关重要。RefAV框架通过利用大语言模型（LLM）将自然语言查询转化为可执行代码来识别相关场景，但该方法存在LLM生成代码的运行时错误以及对复杂多目标空间关系函数参数理解不准确的问题。本技术报告提出了两项改进：1）一种容错的迭代代码生成机制，通过错误反馈重新提示LLM以优化代码；2）专门的提示工程，提升LLM对空间关系函数的理解和正确应用。在Argoverse2验证集上使用Qwen2.5-VL-7B、Gemini 2.5 Flash和Gemini 2.5 Pro等模型的实验表明，所提方法在多项指标上均取得显著提升。特别地，使用Gemini 2.5 Pro时，系统在官方测试集上的HOTA-Temporal得分达到52.37。这些结果证明了所提技术在可靠、高精度场景挖掘中的有效性。

</details>


### [92] [Image-Based Method For Measuring And Classification Of Iron Ore Pellets Using Star-Convex Polygons](https://arxiv.org/abs/2506.11126)
**中文标题：基于星凸多边形的图像方法用于铁矿石颗粒的测量与分类**

*Artem Solomko,Oleg Kartashev,Andrey Golov,Mikhail Deulin,Vadim Valynkin,Vasily Kharin*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图像的铁矿石颗粒分类与测量方法，利用StarDist算法改进传统技术，显著提升了颗粒边界检测和尺寸测量的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机源于需要在高密度和不稳定环境中准确识别和分析铁矿石颗粒，传统方法如ViT和Mask R-CNN在此类任务中效果不佳。

研究方法: 方法采用StarDist算法进行颗粒分割、轮廓确定和分类，并结合物理尺寸测量，解决了传统算法在复杂环境中的局限性。

研究结果: 研究结果展示了一种新型方法，能够检测平滑边界的颗粒，显著提高了尺寸分布分析的精度和测量准确性。

研究结论: 结论表明，基于StarDist算法的方法为铁矿石颗粒的分类和测量提供了更可靠的解决方案，适用于复杂工业环境。

中文摘要: 本文提出了一项关于铁矿石颗粒分类的全面研究，旨在识别最终产品的质量违规问题，并开发了一种基于图像的创新测量方法，利用主要应用于医学领域的StarDist算法。这一研究的动机源于需要在高密度和不稳定环境中准确识别和分析对象。研究过程包括分割对象、确定其轮廓、分类以及测量其物理尺寸。由于颗粒的尺寸分布和分类（如区分优质颗粒和因水分或生产故障导致的次品颗粒）是定义最终产品质量的最重要特征之一，因此这一研究至关重要。传统算法（如基于Vision Transformer（ViT）的图像分类技术、Mask R-CNN等实例分割方法以及各种异常分割算法）在此类任务中效果不佳。因此，我们探索了相关领域的方法以改进我们的方法。研究结果是一种能够检测平滑边界对象的新方法，显著提高了物理尺寸测量的准确性，并促进了铁矿石颗粒尺寸分布的更精确分析。通过利用StarDist算法的优势，我们旨在提供一个强大的解决方案，以应对颗粒分类和测量中复杂环境带来的挑战。

</details>


### [93] [Segment This Thing: Foveated Tokenization for Efficient Point-Prompted Segmentation](https://arxiv.org/abs/2506.11131)
**中文标题：分割这个物体：基于焦点化标记化的高效点提示分割**

*Tanner Schmidt,Richard Newcombe*

主要分类: cs.CV

摘要简述: 本文提出了一种高效图像分割模型Segment This Thing (STT)，通过焦点化输入图像和可变分辨率补丁标记化技术，显著减少计算成本，同时保持模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像分割模型通常通过减小模型规模来提高效率，但可能牺牲性能。本文旨在通过焦点化输入图像和智能标记化技术，在不减小模型规模的情况下显著提升效率。

研究方法: 方法包括：1) 根据点提示提取图像中心裁剪区域；2) 采用可变分辨率补丁标记化技术，远离提示点的区域降采样率更高，从而减少图像标记数量；3) 保持模型规模不变，专注于感兴趣区域。

研究结果: 实验表明，STT模型在分割任务中效率显著高于现有方法，同时性能保持竞争力，可在消费级硬件上实现交互式帧率运行。

研究结论: STT模型通过焦点化和智能标记化技术，实现了高效且高性能的图像分割，适用于增强现实和机器人应用。

中文摘要: 本文提出了一种名为Segment This Thing (STT)的高效图像分割模型，旨在通过单点提示生成单个分割结果。与现有工作不同，我们通过焦点化输入图像而非减小模型规模来提高效率。给定图像和点提示后，我们提取以提示点为中心的裁剪区域，并采用一种新颖的可变分辨率补丁标记化技术：远离提示点的补丁降采样率更高。这种方法生成的图像标记数量远少于均匀补丁标记化，从而在不减小模型规模的情况下显著降低分割的计算成本。此外，焦点化技术使模型专注于感兴趣区域，形成了一种潜在的有利归纳偏置。实验表明，STT模型在保持分割性能竞争力的同时，效率显著优于现有工作。该模型可在消费级硬件上轻松实现交互式帧率运行，因此是增强现实或机器人应用的有力工具。

</details>


### [94] [Gender Fairness of Machine Learning Algorithms for Pain Detection](https://arxiv.org/abs/2506.11132)
**中文标题：机器学习算法在疼痛检测中的性别公平性研究**

*Dylan Green,Yuting Shang,Jiaee Cheong,Yang Liu,Hatice Gunes*

主要分类: cs.CV

摘要简述: 本文研究了机器学习（ML）和深度学习（DL）算法在疼痛检测中的性别公平性，发现尽管Vision Transformer（ViT）表现最佳，但所有模型均存在性别偏见，凸显了准确性与公平性之间的权衡。


<details>
  <summary>详细信息</summary>
研究动机: 自动化疼痛检测在医疗领域潜力巨大，但算法在不同人口群体（如性别）中的准确性和公平性研究不足。本文旨在评估ML和DL模型在疼痛检测中的性别公平性。

研究方法: 研究使用UNBC-McMaster肩痛表情数据库，比较了传统ML算法（线性支持向量机和径向基函数支持向量机）与DL方法（卷积神经网络和Vision Transformer）的性能和公平性指标。

研究结果: ViT在准确性和部分公平性指标上表现最佳，但所有模型均显示出性别偏见，表明准确性与公平性之间存在矛盾。

研究结论: 研究强调了在自动化医疗系统中采用公平性意识技术以减少偏见的必要性，并揭示了准确性与公平性之间的持续权衡。

中文摘要: 通过机器学习（ML）和深度学习（DL）算法实现自动化疼痛检测在医疗领域具有巨大潜力，尤其适用于无法自我报告疼痛水平的患者。然而，这些算法在不同人口群体（如性别）中的准确性和公平性研究不足。本文研究了基于UNBC-McMaster肩痛表情数据库训练的ML和DL模型的性别公平性，评估了仅通过参与者面部表情的视觉模态检测疼痛时各种模型的性能。我们比较了传统ML算法（线性支持向量机和径向基函数支持向量机）与DL方法（卷积神经网络和Vision Transformer），使用了一系列性能和公平性指标。尽管ViT在准确性和部分公平性指标上表现最佳，但所有模型均显示出性别偏见。这些发现凸显了准确性与公平性之间的持续权衡，强调了在自动化医疗系统中采用公平性意识技术以减少偏见的必要性。

</details>


### [95] [Monocular 3D Hand Pose Estimation with Implicit Camera Alignment](https://arxiv.org/abs/2506.11133)
**中文标题：基于隐式相机对齐的单目3D手部姿态估计**

*Christos Pantazopoulos,Spyridon Thermos,Gerasimos Potamianos*

主要分类: cs.CV

摘要简述: 本文提出了一种从单目图像估计3D手部姿态的优化方法，通过关键点对齐和指尖损失函数，无需已知相机参数，在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 3D手部姿态估计在AR、VR、HCI和机器人领域有广泛应用，但单目图像缺乏深度信息，且存在遮挡、复杂关节和相机参数未知等挑战。本文旨在解决这些问题。

研究方法: 提出了一种优化流程，包括关键点对齐步骤和指尖损失函数，无需依赖相机参数，直接从2D关键点输入估计3D手部姿态。

研究结果: 在EgoDexter和Dexter+Object基准测试中表现优异，与现有技术相当，且在无相机先验知识的“野外”图像中表现出鲁棒性。

研究结论: 该方法在无需相机参数的情况下实现了高精度的3D手部姿态估计，为实际应用提供了实用解决方案。

中文摘要: 从单目彩色图像估计3D手部姿态是一个持续研究的问题，在增强现实（AR）、虚拟现实（VR）、人机交互（HCI）和机器人领域有广泛应用。除了缺乏深度信息外，遮挡、关节复杂性和需要相机参数知识等问题也带来了额外挑战。本文提出了一种从2D关键点输入估计3D手部姿态的优化流程，包括关键点对齐步骤和指尖损失函数，以克服对相机参数的需求。我们在EgoDexter和Dexter+Object基准测试中评估了该方法，结果表明其与现有技术表现相当，且在无需相机先验知识的“野外”图像处理中表现出鲁棒性。定量分析表明，尽管使用了手部先验知识，2D关键点估计精度仍对结果有显著影响。代码已开源：https://github.com/cpantazop/HandRepo

</details>


### [96] [ContextLoss: Context Information for Topology-Preserving Segmentation](https://arxiv.org/abs/2506.11134)
**中文标题：ContextLoss：用于保持拓扑结构分割的上下文信息**

*Benedict Schacht,Imke Greving,Simone Frintrop,Berit Zeller-Plumhoff,Christian Wilms*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ContextLoss（CLoss）的新型损失函数，通过考虑关键像素掩码中的完整上下文信息，显著提升了图像分割中拓扑结构的正确性，修复了高达44%的未连接错误。


<details>
  <summary>详细信息</summary>
研究动机: 在图像分割中，保持分割结构（如血管、膜或道路）的拓扑结构至关重要，因为拓扑错误（如道路网络的断裂）会严重影响实际应用。现有方法基于关键像素掩码的损失函数，但缺乏对拓扑错误的完整上下文考虑。因此，本文旨在提出一种改进的损失函数，以提升拓扑正确性。

研究方法: 本文提出了一种名为ContextLoss（CLoss）的新型损失函数，通过在关键像素掩码中考虑拓扑错误的完整上下文信息，增强网络对拓扑错误的关注。此外，还提出了两种直观的指标，用于验证因修复未连接而改善的连通性。

研究结果: 在三个公共数据集（2D和3D）及自有的3D纳米成像数据集（骨水泥线）上的实验表明，使用CLoss训练的网络在拓扑感知指标上表现更优，修复的未连接错误比其他最先进方法多44%。

研究结论: ContextLoss通过引入拓扑错误的上下文信息，显著提升了分割结果的拓扑正确性，并在多个数据集上验证了其有效性。代码已公开。

中文摘要: 在图像分割中，保持分割结构（如血管、膜或道路）的拓扑结构至关重要。例如，道路网络的拓扑错误会严重影响导航。最近提出的解决方案是基于关键像素掩码的损失函数，这些掩码考虑了分割结构的整个骨架。我们提出了一种新型损失函数ContextLoss（CLoss），通过考虑关键像素掩码中拓扑错误的完整上下文，提高了拓扑正确性。额外的上下文增强了网络对拓扑错误的关注。此外，我们还提出了两种直观的指标，用于验证因修复未连接而改善的连通性。我们在三个公共数据集（2D和3D）及自有的3D纳米成像数据集（骨水泥线）上对CLoss进行了测试。使用CLoss训练的网络在拓扑感知指标上表现更优，修复的未连接错误比其他最先进方法多44%。代码已公开。

</details>


### [97] [JAFAR: Jack up Any Feature at Any Resolution](https://arxiv.org/abs/2506.11136)
**中文标题：JAFAR：任意分辨率下的任意特征提升**

*Paul Couairon,Loick Chambon,Louis Serrano,Jean-Emmanuel Haugeard,Matthieu Cord,Nicolas Thome*

主要分类: cs.CV

摘要简述: JAFAR是一种轻量级、灵活的特征上采样器，可将任何基础视觉编码器的低分辨率特征提升到任意目标分辨率，通过注意力模块和SFT调制实现语义对齐，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 基础视觉编码器的低分辨率特征输出需要上采样以满足下游任务的高分辨率需求，现有方法在灵活性和性能上存在不足。

研究方法: JAFAR采用基于注意力的模块，结合低层图像特征的高分辨率查询和语义丰富的低分辨率键，通过SFT调制实现特征上采样。

研究结果: 实验表明，JAFAR能有效恢复细粒度空间细节，在多种下游任务中表现优于现有上采样方法。

研究结论: JAFAR是一种高效的特征上采样解决方案，无需高分辨率监督即可泛化到更高输出尺度。

中文摘要: 基础视觉编码器已成为密集视觉任务的核心组件，但其低分辨率空间特征输出需要通过特征上采样生成下游任务所需的高分辨率模态。本文提出JAFAR，一种轻量级且灵活的特征上采样器，可将任何基础视觉编码器的视觉特征空间分辨率提升至任意目标分辨率。JAFAR采用基于注意力的模块，通过空间特征变换（SFT）调制，促进从低层图像特征提取的高分辨率查询与语义丰富的低分辨率键之间的语义对齐。值得注意的是，尽管缺乏高分辨率监督，我们发现低上采样比和分辨率下的学习能显著泛化到更高输出尺度。大量实验表明，JAFAR能有效恢复细粒度空间细节，并在多种下游任务中持续优于现有特征上采样方法。项目页面：https://jafar-upsampler.github.io

</details>


### [98] [Autonomous Computer Vision Development with Agentic AI](https://arxiv.org/abs/2506.11140)
**中文标题：基于Agentic AI的自主计算机视觉开发**

*Jin Kim,Muhammad Wahi-Anwa,Sangyun Park,Shawn Shin,John M. Hoffman,Matthew S. Brown*

主要分类: cs.CV

摘要简述: 本文展示了一种基于Agentic AI的自主计算机视觉开发方法，通过自然语言提示自动构建和配置计算机视觉系统，并在胸部X光图像分割任务中取得了高精度结果。


<details>
  <summary>详细信息</summary>
研究动机: 传统计算机视觉系统的开发需要数据科学家手动配置工具和流程，耗时且复杂。本文旨在探索如何利用Agentic AI（特别是大型语言模型）实现计算机视觉系统的自主开发和配置，从而降低开发门槛并提高效率。

研究方法: 研究扩展了开源认知AI环境SimpleMind（SM），结合基于大型语言模型的代理（使用OpenManus实现），通过自然语言提示自动分解任务并配置工具。以胸部X光图像分割为例，代理能够根据用户输入生成YAML格式的配置文件，并自主执行SM-Learn（训练）和SM-Think（推理）脚本。

研究结果: 在50张胸部X光图像上，自主配置的系统实现了肺部、心脏和肋骨分割的平均Dice分数分别为0.96、0.82和0.83，表明其高效性和准确性。

研究结论: 本研究证明了Agentic AI在计算机视觉系统自主开发中的潜力，能够替代传统数据科学家的手动配置工作，为未来自动化工具开发提供了新思路。

中文摘要: 基于大型语言模型（LLMs）的Agentic人工智能（AI）系统在复杂推理、规划和工具利用方面展现出巨大潜力。我们展示了一种通过Agentic AI方法从自然语言提示自主构建专用计算机视觉系统的能力。该方法扩展了开源认知AI环境SimpleMind（SM），结合基于LLM的代理（使用OpenManus实现），实现了对特定计算机视觉任务的自动化规划（工具配置）。我们提供了一个概念验证，证明代理系统能够解析计算机视觉任务提示，通过分解任务和配置适当工具生成对应的SimpleMind工作流程。例如，用户输入提示“为胸部X光（CXR）的肺部、心脏和肋骨分割提供SM配置”后，代理LLM能够生成计划（YAML格式的配置文件），并自主执行SM-Learn（训练）和SM-Think（推理）脚本。该计算机视觉代理在50张胸部X光图像上自动配置、训练和测试，肺部、心脏和肋骨的平均Dice分数分别为0.96、0.82和0.83。这项工作展示了传统上由数据科学家完成的计算机视觉应用开发中自主规划和工具配置的潜力。

</details>


### [99] [FARCLUSS: Fuzzy Adaptive Rebalancing and Contrastive Uncertainty Learning for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2506.11142)
**中文标题：FARCLUSS：半监督语义分割中的模糊自适应再平衡与对比不确定性学习**

*Ebenezer Tarubinga,Jenifer Kalafatovich*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FARCLUSS的框架，通过模糊伪标签、不确定性感知动态加权、自适应类别再平衡和轻量级对比正则化，解决了半监督语义分割中未标记数据利用不足、类别不平衡和预测不确定性等问题，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 半监督语义分割（SSSS）在利用未标记数据时面临伪标签利用不足、类别不平衡偏差加剧和预测不确定性忽视等问题。现有方法通常通过严格阈值丢弃不确定区域，偏向主导类别。本文旨在通过将不确定性转化为学习资源，解决这些限制。

研究方法: 本文提出四个主要组件：(1) 模糊伪标签，保留软类别分布以丰富监督；(2) 不确定性感知动态加权，通过基于熵的可靠性分数调整像素贡献；(3) 自适应类别再平衡，动态调整损失以应对长尾分布；(4) 轻量级对比正则化，促进紧凑且可区分的特征嵌入。

研究结果: 在多个基准测试上的实验表明，该方法优于当前最先进方法，显著提升了低代表性类别和模糊区域的分割效果。

研究结论: FARCLUSS框架通过综合利用不确定性信息和动态调整机制，有效解决了半监督语义分割中的关键问题，为未来研究提供了新思路。

中文摘要: 半监督语义分割（SSSS）在有效利用未标记数据方面面临持续挑战，例如伪标签的无效利用、类别不平衡偏差的加剧以及预测不确定性的忽视。当前方法通常通过严格阈值丢弃不确定区域，偏向主导类别。为解决这些限制，我们引入了一个整体框架，通过四个主要组件将不确定性转化为学习资源：(1) 模糊伪标签，保留来自前K预测的软类别分布以丰富监督；(2) 不确定性感知动态加权，通过基于熵的可靠性分数调整像素贡献；(3) 自适应类别再平衡，动态调整损失以应对长尾类别分布；(4) 轻量级对比正则化，促进紧凑且可区分的特征嵌入。在多个基准测试上的广泛实验表明，我们的方法优于当前最先进方法，显著提升了低代表性类别和模糊区域的分割效果。

</details>


### [100] [On the development of an AI performance and behavioural measures for teaching and classroom management](https://arxiv.org/abs/2506.11143)
**中文标题：AI教学与课堂管理表现及行为测量工具的开发**

*Andreea I. Niculescu,Jochen Ehnen,Chen Yi,Du Jiawei,Tay Chiat Pin,Joey Tianyi Zhou,Vigneshwaran Subbaraju,Teh Kah Kuan,Tran Huy Dat,John Komar,Gi Soong Chee,Kenneth Kwok*

主要分类: cs.CV

摘要简述: 本文介绍了一项为期两年的研究项目，旨在开发AI驱动的课堂动态分析工具，重点关注通过多模态传感器数据捕捉教师行为。研究提供了音频-视觉数据集、新行为指标和教学回顾仪表板，并通过初步评估验证了系统的清晰性、易用性和自动化分析优势。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于利用AI技术减轻教师手动分析负担，提供客观的课堂互动反馈，帮助教师改进教学策略，同时为基于AI的教育分析领域贡献文化背景相关的方法论。

研究方法: 研究方法包括利用课堂传感器的实时数据，结合AI技术提取有意义的信息，开发音频-视觉数据集和行为指标，并设计教学回顾仪表板。

研究结果: 研究结果包括一个音频-视觉数据集、新行为指标和教学仪表板原型。初步评估显示系统清晰易用，自动化分析减少了人工负担，促进了教师的反思。

研究结论: 结论表明，该AI系统能够客观记录课堂互动，帮助教师识别和改进教学策略，同时为教育分析领域提供了文化背景相关的方法论。

中文摘要: 本文介绍了一项为期两年的研究项目，旨在开发AI驱动的课堂动态分析工具，重点关注通过多模态传感器数据捕捉教师行为。我们利用课堂传感器的实时数据和AI技术提取有意义的信息，支持教师发展。主要成果包括一个音频-视觉数据集、新行为指标和教学回顾仪表板原型。来自国家教育研究院的八名研究人员的初步评估显示，系统清晰易用，其自动化分析方式减少了人工负担并鼓励建设性反思。尽管当前版本未提供绩效评分，但它提供了课堂互动的客观快照，帮助教师识别和改进教学策略。该研究在亚洲教育背景下设计和测试，为基于AI的教育分析领域贡献了文化背景相关的方法论。

</details>


### [101] [AlignHuman: Improving Motion and Fidelity via Timestep-Segment Preference Optimization for Audio-Driven Human Animation](https://arxiv.org/abs/2506.11144)
**中文标题：AlignHuman：通过时间步分段偏好优化提升音频驱动人体动画的运动与保真度**

*Chao Liang,Jianwen Jiang,Wang Liao,Jiaqi Yang,Zerong zheng,Weihong Zeng,Han Liang*

主要分类: cs.CV

摘要简述: AlignHuman通过时间步分段偏好优化（TPO）和专家对齐模块（LoRAs），提升音频驱动人体动画的运动自然性和视觉保真度，同时减少推理时的计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散模型的人体动画生成在运动自然性和视觉保真度之间存在权衡，难以同时优化。AlignHuman旨在通过分析去噪过程的时间步特性，提出分段优化策略以解决这一问题。

研究方法: AlignHuman提出时间步分段偏好优化（TPO），将去噪过程分为早期（控制运动动态）和后期（管理保真度和人体结构）阶段，并引入两个专用LoRAs作为专家对齐模块，分别在对应时间步区间优化目标。

研究结果: 实验表明，AlignHuman显著提升基线性能，推理时计算开销减少至30 NFEs（原为100 NFEs），速度提升3.3倍，且生成质量几乎不受影响。

研究结论: AlignHuman通过分段优化和专家对齐模块，有效平衡了运动自然性和视觉保真度，同时大幅降低推理成本，为音频驱动人体动画提供了高效解决方案。

中文摘要: 近年来，基于扩散模型的人体视频生成与动画任务取得了显著进展。然而，由于运动自然性与视觉保真度之间的权衡，表达丰富且逼真的人体动画仍具挑战性。为此，我们提出AlignHuman框架，结合偏好优化作为后训练技术，采用分而治之的训练策略，共同优化这些竞争目标。我们的核心洞察源于对去噪过程时间步的分析：（1）早期去噪时间步主要控制运动动态，（2）保真度与人体结构可通过后期时间步有效管理，即使跳过早期步骤。基于此，我们提出时间步分段偏好优化（TPO），并引入两个专用LoRAs作为专家对齐模块，分别针对其对应时间步区间的特定维度进行优化。这些LoRAs通过各自的偏好数据训练，并在推理时激活于对应区间，以增强运动自然性与保真度。大量实验表明，AlignHuman显著提升了基线性能，推理时将NFEs从100减少至30，实现3.3倍加速，且对生成质量影响极小。项目主页：https://alignhuman.github.io/

</details>


### [102] [3D-RAD: A Comprehensive 3D Radiology Med-VQA Dataset with Multi-Temporal Analysis and Diverse Diagnostic Tasks](https://arxiv.org/abs/2506.11147)
**中文标题：3D-RAD：一个涵盖多时相分析和多样化诊断任务的综合性3D放射学Med-VQA数据集**

*Xiaotang Gai,Jiaxiang Liu,Yichen Li,Zijie Meng,Jian Wu,Zuozhu Liu*

主要分类: cs.CV

摘要简述: 本文介绍了3D-RAD，一个基于放射学CT扫描的大规模3D医学视觉问答数据集，涵盖六种任务，支持开放和封闭问题，并引入复杂推理挑战。现有视觉语言模型在3D多时相任务中表现有限，而微调3D-RAD-T数据集可显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有医学视觉问答（Med-VQA）研究多集中于2D影像且任务单一，无法满足临床决策支持的需求。3D-RAD旨在填补这一空白，推动3D Med-VQA的发展，支持多样化的诊断任务和复杂推理。

研究方法: 3D-RAD数据集包含六种VQA任务（如异常检测、医学计算等），支持开放和封闭问题，并引入多时相分析。通过专家对齐的136,195个样本（3D-RAD-T）进行微调，评估现有视觉语言模型的性能。

研究结果: 现有视觉语言模型（尤其是医学VLM）在3D多时相任务中泛化能力有限。微调3D-RAD-T数据集显著提升了模型性能，为3D医学视觉理解提供了坚实基础。

研究结论: 3D-RAD为多模态医学AI研究提供了高质量数据集和基准，推动了3D医学视觉问答的发展。未来研究可基于此进一步提升模型在复杂诊断任务中的表现。

中文摘要: 医学视觉问答（Med-VQA）在临床决策支持中具有重要潜力，但现有研究主要集中于2D影像且任务多样性有限。本文提出3D-RAD，一个基于放射学CT扫描的大规模数据集，旨在推动3D Med-VQA的发展。3D-RAD包含六种多样化VQA任务：异常检测、影像观察、医学计算、存在检测、静态时相诊断和纵向时相诊断。它支持开放和封闭问题，并引入复杂推理挑战（如计算任务和多阶段时相分析），以实现全面基准测试。广泛评估表明，现有视觉语言模型（尤其是医学VLM）在多时相任务中泛化能力有限，突显了真实世界3D诊断推理的挑战。为推动未来进展，我们发布了包含136,195个专家对齐样本的高质量训练集3D-RAD-T，证明微调可显著提升模型性能。我们的数据集和代码旨在催化多模态医学AI研究，并为3D医学视觉理解奠定坚实基础，公开于https://github.com/Tang-xiaoxiao/M3D-RAD。

</details>


### [103] [LLM-to-Phy3D: Physically Conform Online 3D Object Generation with LLMs](https://arxiv.org/abs/2506.11148)
**中文标题：LLM-to-Phy3D：基于大语言模型的在线物理符合3D对象生成**

*Melvin Wong,Yueming Lyu,Thiago Rios,Stefan Menzel,Yew-Soon Ong*

主要分类: cs.CV

摘要简述: LLM-to-Phy3D是一种新型在线3D对象生成方法，通过结合视觉和物理评估，使LLM生成的3D对象符合物理约束，提升设计性能和新颖性。


<details>
  <summary>详细信息</summary>
研究动机: 现有LLM-to-3D模型缺乏物理知识，生成的3D对象往往脱离现实物理约束，限制了其在工程设计和物理AI中的应用潜力。

研究方法: LLM-to-Phy3D引入了一种在线黑盒优化循环，通过迭代反馈机制，结合视觉和物理评估，优化LLM生成的3D对象，使其符合物理约束。

研究结果: 实验表明，LLM-to-Phy3D在车辆设计优化中，比传统LLM-to-3D模型提升了4.5%至106.7%的物理符合性，显著提高了生成设计的物理性能。

研究结论: LLM-to-Phy3D为物理AI和工程设计提供了一种高效的工具，展示了其在科学和工程应用中的广泛潜力。

中文摘要: 生成式人工智能（GenAI）和大语言模型（LLMs）的出现彻底改变了多模态数字内容创作的格局。然而，其在物理AI和工程设计中的应用潜力尚未充分挖掘，现有LLM-to-3D模型因缺乏物理知识，生成的3D对象往往脱离现实物理约束。为解决这一问题，我们提出了LLM-to-Phy3D，一种在线物理符合3D对象生成方法，通过协同视觉和物理评估，使LLM-to-3D模型能够实时生成符合物理约束的3D对象。LLM-to-Phy3D引入了一种新型在线黑盒优化循环，通过迭代反馈机制，驱动LLM生成具有更高物理性能和几何新颖性的3D对象。在车辆设计优化的系统评估中，LLM-to-Phy3D相比传统LLM-to-3D模型，在物理符合性上提升了4.5%至106.7%。这些积极结果表明，LLM-to-Phy3D在物理AI的科学和工程应用中具有广泛潜力。

</details>


### [104] [Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels](https://arxiv.org/abs/2506.11151)
**中文标题：自校准脑机接口：无需标记的心理目标排序与恢复**

*Jonathan Grizou,Carlos de la Torre-Ortiz,Tuukka Ruotsalo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CURSOR的自校准框架，首次实现了无需标记数据或预训练解码器的情况下，从脑电图（EEG）和图像数据中恢复未知心理目标（如人脸图像）。实验表明，CURSOR能够预测与人类感知判断相关的图像相似性分数，并生成与目标难以区分的新刺激。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法依赖标记数据或预训练解码器来恢复心理目标，但在实际应用中，标记数据往往难以获取。本文旨在解决这一限制，提出一种无需标记的自校准方法，直接从交互会话中学习恢复心理目标。

研究方法: 本文提出CURSOR框架，通过分析EEG和图像数据，学习预测图像相似性分数，并利用这些分数对未知心理目标进行排序和生成新刺激。该方法完全无需标记数据或预训练模型。

研究结果: 实验结果显示，CURSOR能够预测与人类感知判断高度相关的图像相似性分数，并成功生成与未知心理目标难以区分的新刺激（通过用户研究验证，N=53）。

研究结论: CURSOR是首个无需标记数据的自校准框架，能够有效恢复心理目标并生成新刺激，为脑机接口的无监督学习提供了新思路。

中文摘要: 我们研究了如何从交互会话中收集的脑电图（EEG）和图像数据中恢复参与者心中的心理目标（如人脸图像），而无需访问标记信息。此前的研究依赖标记数据，但未探索自校准方法。本文首次提出CURSOR框架及算法，能够在无标记数据或预训练解码器的情况下学习恢复未知心理目标。在自然人脸图像上的实验表明，CURSOR能够（1）预测与人类感知判断相关的图像相似性分数（无需任何标记信息），（2）利用这些分数对未知心理目标进行刺激排序，（3）生成与未知心理目标难以区分的新刺激（通过用户研究验证，N=53）。

</details>


### [105] [SLRNet: A Real-Time LSTM-Based Sign Language Recognition System](https://arxiv.org/abs/2506.11154)
**中文标题：SLRNet：一种基于LSTM的实时手语识别系统**

*Sharvari Kamble*

主要分类: cs.CV

摘要简述: SLRNet是一种基于LSTM的实时手语识别系统，通过MediaPipe Holistic和LSTM网络实现ASL字母和功能词的识别，验证准确率达86.7%。


<details>
  <summary>详细信息</summary>
研究动机: 手语识别（SLR）在弥合听力障碍群体与社会之间的沟通鸿沟中至关重要。本文旨在开发一种实时、硬件无关的手语识别系统，以促进包容性沟通。

研究方法: SLRNet采用MediaPipe Holistic提取视频流中的手势特征，并结合LSTM网络进行实时识别，支持ASL字母和功能词的分类。

研究结果: 实验结果显示，SLRNet的验证准确率达到86.7%，证明了其在实时手语识别中的可行性和高效性。

研究结论: SLRNet展示了基于LSTM的实时手语识别系统的潜力，为硬件无关的包容性手势识别提供了可行方案。

中文摘要: 手语识别（SLR）在弥合听力障碍群体与社会之间的沟通鸿沟中起着关键作用。本文介绍了SLRNet，一种基于MediaPipe Holistic和长短期记忆（LSTM）网络的实时网络摄像头ASL识别系统。该模型通过处理视频流来识别ASL字母和功能词，验证准确率为86.7%，展示了包容性、硬件无关的手势识别的可行性。

</details>


### [106] [Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search](https://arxiv.org/abs/2506.11155)
**中文标题：通过蒙特卡洛树搜索评估多模态大语言模型的视频字幕能力**

*Linhao Yu,Xinguang Ji,Yahui Liu,Fanheng Kong,Chenxi Sun,Jingyuan Zhang,Hongzhi Zhang,V. W.,Fuzheng Zhang,Deyi Xiong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为AutoCaption的自动框架，利用蒙特卡洛树搜索（MCTS）生成多样化的视频描述句子，构建了细粒度视频字幕基准MCTS-VCB，用于全面评估多模态大语言模型（MLLMs）的视频字幕能力。实验表明，MCTS-VCB能有效评估模型性能，且AutoCaption生成的数据显著提升了模型表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频字幕评估基准存在关键问题，如关键点生成不足或同质化、数据创建成本高昂以及评估范围有限。为解决这些问题，本文提出了一种自动框架，旨在全面评估MLLMs的视频理解能力。

研究方法: 提出AutoCaption框架，利用蒙特卡洛树搜索（MCTS）迭代生成多样化的视频描述句子（关键点），覆盖视频细节（如动作、物体属性、环境等）。基于此构建了MCTS-VCB基准，用于评估20多个开源和闭源MLLMs。

研究结果: 实验结果显示，MCTS-VCB能全面评估视频字幕能力，Gemini-1.5-Pro以71.2的F1得分表现最佳。此外，利用AutoCaption生成的数据微调InternVL2.5-8B，使其在MCTS-VCB和DREAM-1K上分别提升25.0%和16.3%。

研究结论: AutoCaption和MCTS-VCB为视频字幕任务提供了高效、全面的评估工具，显著提升了模型性能，展示了其在多模态大语言模型评估中的有效性。

中文摘要: 视频字幕可用于评估多模态大语言模型（MLLMs）的视频理解能力。然而，现有基准和评估协议存在关键问题，如关键点生成不足或同质化、数据创建成本高昂以及评估范围有限。为解决这些问题，我们提出了一种名为AutoCaption的自动框架，利用蒙特卡洛树搜索（MCTS）迭代生成多样化的描述句子（即关键点），全面覆盖视频内容。这种迭代字幕策略能够持续增强视频细节（如动作、物体属性、环境等）。我们应用AutoCaption构建了MCTS-VCB，一个细粒度的视频字幕基准，从而实现对MLLMs在视频字幕任务上的全面评估。我们评估了20多个不同规模的开源和闭源MLLMs。结果显示，MCTS-VCB能有效且全面地评估视频字幕能力，Gemini-1.5-Pro以71.2的F1得分表现最佳。有趣的是，我们利用AutoCaption生成的数据微调InternVL2.5-8B，使其在MCTS-VCB和DREAM-1K上分别提升25.0%和16.3%，进一步证明了AutoCaption的有效性。代码和数据可在https://github.com/tjunlp-lab/MCTS-VCB获取。

</details>


### [107] [Digitization of Document and Information Extraction using OCR](https://arxiv.org/abs/2506.11156)
**中文标题：基于OCR的文档数字化与信息提取**

*Rasha Sinha,Rekha B S*

主要分类: cs.CV

摘要简述: 本文提出了一种结合OCR技术与大语言模型（LLM）的文本提取框架，显著提升了文档信息提取的准确性和语义理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 在处理扫描图像和原生数字格式的文档时，如何准确提取信息是一个关键问题。传统方法（如基于规则或模板的方法）在灵活性和语义理解上存在不足，因此需要一种更高效、更智能的解决方案。

研究方法: 通过OCR引擎处理扫描文件，利用布局感知库解析数字文件，提取原始文本后，再使用LLM分析文本以识别键值对并解决歧义。同时，对不同OCR工具在准确性、布局识别和处理速度方面进行了比较分析。

研究结果: 该方法在灵活性和语义精确性上显著优于传统方法，能够适应不同类别的文档，并提供上下文理解和置信度指标。

研究结论: 结合OCR与LLM的框架为文档信息提取提供了更高效、更智能的解决方案，未来可进一步优化以适应更复杂的应用场景。

中文摘要: 从文档中准确提取详细信息是一项关键任务，尤其是在处理扫描图像和原生数字格式的混合文档时。本文提出了一种结合光学字符识别（OCR）技术与大语言模型（LLM）的文本提取框架，以提供具有上下文理解和置信度指标的结构化输出。扫描文件通过OCR引擎处理，而数字文件则通过布局感知库解析。提取的原始文本随后由LLM分析，以识别键值对并解决歧义。本文还比较了不同OCR工具在准确性、布局识别和处理速度方面的表现。该方法在灵活性和语义精确性上显著优于传统的基于规则和模板的方法，适用于不同类别的文档。

</details>


### [108] [VIBE: Can a VLM Read the Room?](https://arxiv.org/abs/2506.11162)
**中文标题：VIBE：视觉语言模型能读懂社交情境吗？**

*Tania Chakraborty,Eylon Caplan,Dan Goldwasser*

主要分类: cs.CV

摘要简述: 本文探讨视觉语言模型（VLM）在社会推理中的能力，发现其存在视觉社会-语用推理缺口，并提出新任务和数据集以测试VLM在此任务上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 理解人类社交行为（如情感识别和社交动态）是一个重要但具有挑战性的问题。尽管大语言模型（LLM）在文本领域取得了显著进展，但无法处理非语言线索在社交情境中的重要作用。视觉语言模型（VLM）可能填补这一空白，但其在社会推理中的能力尚未得到充分研究。

研究方法: 本文提出了一种新任务：视觉社会-语用推理，并构建了一个高质量数据集来测试VLM在此任务上的能力。同时，对多种VLM进行了基准测试。

研究结果: 研究发现VLM在视觉社会-语用推理任务中存在显著的能力缺口，且现有模型在此任务上的表现有限。

研究结论: 本文揭示了VLM在社会推理中的局限性，并提出了未来研究方向，以改进VLM在社交情境中的应用。

中文摘要: 理解人类社交行为（如情感识别和引发情感的社交动态）是一个重要且具有挑战性的问题。尽管大语言模型（LLM）取得了显著进展，但其仅限于文本领域，无法涵盖非语言线索在理解社交情境中的重要作用。视觉语言模型（VLM）可能填补这一空白，但其在此类社交线索上的推理能力尚未得到充分关注。本文探讨了VLM在社会推理中的能力，并发现了一个此前被忽视的局限性：视觉社会-语用推理缺口。针对这一缺口，我们提出了一项新任务：视觉社会-语用推理，并构建了一个高质量数据集以测试VLM在此任务上的能力，同时对多种VLM进行了基准测试。

</details>


### [109] [Synthetic Geology -- Structural Geology Meets Deep Learning](https://arxiv.org/abs/2506.11164)
**中文标题：合成地质学——结构地质学与深度学习的结合**

*Simon Ghyselincks,Valeriia Okhmak,Stefano Zampini,George Turkiyyah,David Keyes,Eldad Haber*

主要分类: cs.CV

摘要简述: 本文提出了一种结合深度学习与合成地质数据的方法，通过生成式AI技术填补地下数据空白，实现从地表地质数据生成高保真三维地下结构图像。


<details>
  <summary>详细信息</summary>
研究动机: 长期以来，地下结构的可视化是一个关键挑战，限制了资源勘探、灾害评估等应用。地表地质数据丰富，但地下数据稀缺，亟需一种方法填补这一数据空白。

研究方法: 通过设计合成数据生成器模拟地质活动（如沉积压实、火山侵入等），生成大量合成地下数据。利用生成式流匹配训练神经网络模型，从地表地质数据推断三维地下结构。

研究结果: 训练后的模型能够从未见过的地表地形和地质数据生成高保真三维地下图像，包括地层、断层、褶皱等结构。随着钻孔数据的增加，生成图像的保真度显著提升。

研究结论: 结合合成地质数据生成器和深度学习模型，为地下结构可视化提供了新方法。未来可通过区域数据微调模型，进一步应用于资源勘探和工程地质等领域。

中文摘要: 通过深度学习技术，首次实现了对地球表层以下数公里结构的可视化，这一长期挑战的解决为众多重要应用打开了大门。基于生成式人工智能对体素化图像的处理，我们提出了一种方法，通过训练神经网络将地表地质数据与钻孔数据结合，扩展到三维地下区域。尽管地表地质特征已被广泛测绘，但地下数据的稀缺仍是技术瓶颈。为此，我们设计了一个合成数据生成过程，模拟了沉积压实、火山侵入和构造动力学等地质活动，生成了近乎无限的近地表岩石圈样本。基于此类合成数据训练的基础模型，能够从未见过的地表地形和地质数据生成三维地下图像，并随着钻孔数据的增加而提高保真度，展示出地层、断层、褶皱、岩脉等结构。通过生成式流匹配技术，我们展示了合成岩石圈生成器与训练神经网络模型的早期潜力。未来，此类模型可通过区域数据微调，应用于矿产勘探等领域。此外，区域微调模型还可作为基于AI的正则化工具，用于传统反问题应用中，目标函数代表附加数据与物理模型的不匹配，适用于资源勘探、灾害评估和岩土工程等领域。

</details>


### [110] [Evaluating BiLSTM and CNN+GRU Approaches for Human Activity Recognition Using WiFi CSI Data](https://arxiv.org/abs/2506.11165)
**中文标题：基于WiFi CSI数据的BiLSTM与CNN+GRU方法在人类活动识别中的性能评估**

*Almustapha A. Wakili,Babajide J. Asaju,Woosub Jung*

主要分类: cs.CV

摘要简述: 本文比较了BiLSTM和CNN+GRU深度学习模型在基于WiFi CSI数据的HAR任务中的表现。结果显示，CNN+GRU在UT-HAR数据集上表现更优（95.20%），而BiLSTM在高分辨率NTU-Fi HAR数据集上表现更好（92.05%）。研究强调了数据集特性和预处理技术对模型性能的重要性，并展示了这些模型在医疗和智能家居中的实际应用潜力。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索不同深度学习模型（BiLSTM和CNN+GRU）在基于WiFi CSI数据的人类活动识别（HAR）任务中的表现差异，并分析数据集特性对模型性能的影响，以推动无干扰活动识别技术在医疗和智能家居等领域的应用。

研究方法: 研究方法包括使用BiLSTM和CNN+GRU两种深度学习模型，分别在UT-HAR和NTU-Fi HAR两个WiFi CSI数据集上进行训练和测试。通过比较模型在提取空间特征和长期时间依赖性方面的能力，评估其性能差异。

研究结果: 实验结果表明，CNN+GRU模型在UT-HAR数据集上表现更优（准确率95.20%），因其擅长提取空间特征；而BiLSTM模型在高分辨率NTU-Fi HAR数据集上表现更好（准确率92.05%），因其能更有效地捕捉长期时间依赖性。

研究结论: 研究结论强调了数据集特性和预处理技术对模型性能的关键作用，并展示了BiLSTM和CNN+GRU模型在医疗和智能家居等实际应用中的潜力，为无干扰活动识别技术的发展提供了重要参考。

中文摘要: 本文比较了BiLSTM和CNN+GRU深度学习模型在两个基于WiFi信道状态信息（CSI）的数据集（UT-HAR和NTU-Fi HAR）上的人类活动识别（HAR）性能。结果表明，CNN+GRU模型在UT-HAR数据集上具有更高的准确率（95.20%），得益于其提取空间特征的能力；而BiLSTM模型在高分辨率NTU-Fi HAR数据集上表现更优（92.05%），因其能更有效地提取长期时间依赖性。研究强调了数据集特性和预处理技术对模型性能提升的关键作用，并展示了此类模型在医疗和智能家居系统中的实际应用潜力，突出了其在无干扰活动识别中的前景。

</details>


### [111] [Test-Time-Scaling for Zero-Shot Diagnosis with Visual-Language Reasoning](https://arxiv.org/abs/2506.11166)
**中文标题：测试时缩放：基于视觉语言推理的零样本诊断**

*Ji Young Byun,Young-Jin Park,Navid Azizan,Rama Chellappa*

主要分类: cs.CV

摘要简述: 本文提出了一种零样本医疗图像诊断框架，通过测试时缩放增强大语言模型（LLMs）在临床环境中的推理能力，显著提升诊断准确性。


<details>
  <summary>详细信息</summary>
研究动机: 临床决策对患者结果至关重要，但基于视觉问答的医疗影像诊断中，大语言模型的应用仍未被充分探索。由于数据有限和标注成本高，监督微调不切实际，因此需要一种无需微调的可靠诊断方法。

研究方法: 提出零样本框架，结合视觉语言模型和大语言模型：视觉语言模型处理医疗图像和文本提示生成多描述，大语言模型通过测试时缩放整合多候选输出为最终诊断。

研究结果: 在放射学、眼科和组织病理学等多种医疗影像模态中，测试时缩放策略显著提升诊断准确性，且无偏提示提高了LLM生成诊断的可靠性。

研究结论: 测试时缩放策略有效增强了大语言模型在医疗诊断中的推理能力，为临床决策提供了更可靠的零样本解决方案。

中文摘要: 作为患者护理的基石，临床决策显著影响患者结果，而大语言模型（LLMs）可以提升其效果。尽管LLMs表现卓越，但在医疗影像的视觉问答中，尤其是基于推理的诊断，其应用仍未被充分探索。此外，由于数据有限和标注成本高，监督微调在推理任务中几乎不切实际。本文提出了一种零样本框架，通过测试时缩放增强LLMs在临床环境中的推理能力，实现可靠的医疗图像诊断。给定医疗图像和文本提示，视觉语言模型处理图像和文本生成多描述，LLM通过测试时缩放整合候选输出为最终诊断。我们在放射学、眼科和组织病理学等多种医疗影像模态中评估该方法，证明测试时缩放策略提升了诊断准确性。此外，实证分析表明，无偏提示的第一阶段设计提高了LLM生成诊断的可靠性和分类准确性。

</details>


### [112] [Towards a general-purpose foundation model for fMRI analysis](https://arxiv.org/abs/2506.11167)
**中文标题：面向通用fMRI分析的基础模型**

*Cheng Wang,Yu Jiang,Zhihao Peng,Chenxin Li,Changbae Bang,Lin Zhao,Jinglei Lv,Jorge Sepulcre,Carl Yang,Lifang He,Tianming Liu,Daniel Barron,Quanzheng Li,Randy Hirschtick,Byung-Hoon Kim,Xiang Li,Yixuan Yuan*

主要分类: cs.CV

摘要简述: 本文提出NeuroSTORM，一种通用fMRI分析基础模型，通过预训练和任务提示调优提升跨任务性能，在多个临床任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前fMRI分析方法因复杂的预处理和任务特定模型存在可重复性和迁移性问题，亟需一种通用框架以提升效率和准确性。

研究方法: NeuroSTORM采用Mamba架构和移位扫描策略处理4D fMRI数据，提出时空优化预训练方法和任务提示调优，预训练数据覆盖多中心、多年龄段。

研究结果: NeuroSTORM在年龄/性别预测、表型预测、疾病诊断等五项任务中优于现有方法，并在多国临床数据中展现优异性能。

研究结论: NeuroSTORM为fMRI临床研究提供了标准化开源基础模型，显著提升了可重复性和迁移性。

中文摘要: 功能磁共振成像（fMRI）对研究脑功能和诊断神经疾病至关重要，但现有方法因复杂预处理和任务特定模型面临可重复性和迁移性问题。我们提出NeuroSTORM（神经影像基础模型，时空优化表示建模），一种通用框架，直接从4D fMRI数据中学习并实现跨应用高效知识迁移。NeuroSTORM预训练数据涵盖50,000多名5至100岁受试者的2865万帧fMRI（>9000小时），采用Mamba架构和移位扫描策略高效处理4D数据。我们还提出时空优化预训练方法和任务提示调优以提升迁移性。NeuroSTORM在五项任务（年龄/性别预测、表型预测、疾病诊断、fMRI-图像检索、任务fMRI分类）中优于现有方法，并在美、韩、澳医院数据中展现优异临床性能，尤其在疾病诊断和认知表型预测中表现突出。NeuroSTORM为fMRI临床研究提供了标准化开源基础模型，提升了可重复性和迁移性。

</details>


### [113] [WaveFormer: A Lightweight Transformer Model for sEMG-based Gesture Recognition](https://arxiv.org/abs/2506.11168)
**中文标题：WaveFormer：一种基于sEMG手势识别的轻量级Transformer模型**

*Yanlong Chen,Mattia Orlandi,Pierangelo Maria Rapa,Simone Benatti,Luca Benini,Yawei Li*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级Transformer模型WaveFormer，用于基于表面肌电信号（sEMG）的手势识别，通过结合时域和频域特征，显著提升了分类精度，同时保持了低计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于sEMG的手势识别在分类相似手势时精度不足，且传统深度学习模型计算开销大，难以部署在资源受限的嵌入式设备上。

研究方法: WaveFormer采用轻量级Transformer架构，结合可学习的小波变换模块（WaveletConv），通过多级小波分解和深度可分离卷积提取特征，兼顾效率和模型紧凑性。

研究结果: WaveFormer仅需310万参数，在EPN612数据集上达到95%的分类精度，优于其他大型模型；INT8量化后，在Intel CPU上实现6.75毫秒的实时推理延迟。

研究结论: WaveFormer为sEMG手势识别提供了一种高效且轻量化的解决方案，适合资源受限的嵌入式系统部署。

中文摘要: 人机交互，特别是在假肢和机器人控制中，通过表面肌电信号（sEMG）实现手势识别已取得进展。然而，对产生几乎相同肌肉信号的相似手势进行分类仍是一个挑战，通常会降低分类精度。传统的深度学习模型用于sEMG手势识别时体积庞大且计算成本高，限制了其在资源受限的嵌入式系统中的部署。本文提出WaveFormer，一种专为sEMG手势识别设计的轻量级Transformer架构。我们的模型通过一种新颖的可学习小波变换整合时域和频域特征，增强了特征提取能力。特别是WaveletConv模块，一种结合多级小波分解和深度可分离卷积的层，确保了高效性和紧凑性。WaveFormer仅需310万参数，在EPN612数据集上实现了95%的分类精度，优于更大的模型。此外，在配备Intel CPU的笔记本电脑上，INT8量化实现了6.75毫秒的实时推理延迟。

</details>


### [114] [Teaching in adverse scenes: a statistically feedback-driven threshold and mask adjustment teacher-student framework for object detection in UAV images under adverse scenes](https://arxiv.org/abs/2506.11175)
**中文标题：恶劣场景下的教学：一种基于统计反馈驱动的阈值与掩码调整教师-学生框架用于无人机图像中的目标检测**

*Hongyu Chen,Jiping Liu,Yong Wang,Jun Zhu,Dejun Feng,Yakun Xie*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SF-TMAT的教师-学生框架，用于解决无人机在恶劣场景下目标检测的领域适应问题。通过动态调整掩码比例和置信度阈值，结合统计反馈机制，显著提升了伪标签质量和模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有无监督领域适应方法多基于自然图像或清晰无人机图像，而在恶劣场景下的无人机目标检测研究较少。由于视角独特和恶劣条件干扰，现有方法难以准确对齐特征，且易受噪声伪标签影响。

研究方法: SF-TMAT框架包含动态步反馈掩码调整自编码器（DSFMA）和方差反馈平滑阈值（VFST）策略。DSFMA动态调整掩码比例并重构特征图，VFST通过统计计算类别均值和方差动态调整伪标签选择阈值。

研究结果: 实验表明，SF-TMAT在恶劣场景下的无人机目标检测中表现优异，显著提升了伪标签质量和模型泛化能力。

研究结论: SF-TMAT为恶劣场景下的无人机目标检测提供了首个基准框架，通过动态反馈机制有效缓解了领域偏差问题，具有广泛的应用潜力。

中文摘要: 无监督领域适应（UDA）在缓解源域与目标域之间的领域差距方面表现出潜力，并可推广至恶劣场景下的无人机目标检测。然而，现有UDA研究多基于自然图像或清晰无人机图像，而针对恶劣条件下无人机图像的研究仍处于起步阶段。此外，由于无人机独特视角和恶劣条件干扰，这些方法往往难以准确对齐特征，并受限于噪声伪标签。为此，我们提出了首个恶劣场景下无人机目标检测的基准框架——统计反馈驱动的阈值与掩码调整教师-学生框架（SF-TMAT）。具体而言，SF-TMAT引入了动态步反馈掩码调整自编码器（DSFMA），通过整合训练进度和损失反馈动态调整掩码比例并重构特征图，从而在不同训练阶段动态调整学习焦点以满足模型对多粒度特征的需求。此外，我们还提出了一种独特的方差反馈平滑阈值（VFST）策略，通过统计计算各类别的均值置信度并结合方差惩罚项动态调整选择阈值，从而提升伪标签质量并挖掘潜在有效标签，缓解领域偏差。大量实验证明了SF-TMAT在恶劣场景下无人机目标检测中的优越性和泛化能力。代码发布于https://github.com/ChenHuyoo。

</details>


### [115] [BrainMAP: Multimodal Graph Learning For Efficient Brain Disease Localization](https://arxiv.org/abs/2506.11178)
**中文标题：BrainMAP：多模态图学习在高效脑疾病定位中的应用**

*Nguyen Linh Dan Le,Jing Ren,Ciyuan Peng,Chengyao Xie,Bowen Li,Feng Xia*

主要分类: cs.CV

摘要简述: BrainMAP是一种新型多模态图学习框架，专注于高效定位神经退行性疾病相关脑区，通过图谱驱动过滤和多模态融合技术，显著降低计算开销并保持预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有图学习方法难以精确定位神经退行性疾病的特定脑区，且多模态脑图模型计算复杂度高，限制了其在资源受限设备中的应用。本研究旨在开发一种高效且精确的脑疾病定位方法。

研究方法: BrainMAP采用AAL图谱驱动的过滤方法提取关键脑子图，减少50%以上计算开销；结合跨节点注意力和自适应门控机制，动态融合fMRI和DTI数据。

研究结果: 实验表明，BrainMAP在计算效率上优于现有方法，且未牺牲预测准确性。

研究结论: BrainMAP通过聚焦疾病相关子图和多模态动态融合，实现了高效且精确的脑疾病定位，为实际应用提供了可行方案。

中文摘要: 近年来，利用图学习技术检测神经退行性疾病的研究激增。然而，现有的基于图的方法通常无法在全连接组中定位和提取驱动神经退行性病变的特定脑区。此外，当前的多模态脑图模型往往计算复杂度高，限制了其在资源受限设备中的实际应用。本研究提出BrainMAP，一种新型多模态图学习框架，旨在高效且精确地识别受神经退行性疾病影响的脑区。首先，BrainMAP采用AAL图谱驱动的过滤方法定位并提取关键脑子图。与现有方法建模整个脑网络不同，BrainMAP通过聚焦疾病相关子图，减少了50%以上的计算开销。其次，我们采用包含跨节点注意力的高级多模态融合过程，对齐功能磁共振成像（fMRI）和扩散张量成像（DTI）数据，并结合自适应门控机制动态融合这些模态。实验结果表明，BrainMAP在计算效率上优于现有方法，且未影响预测准确性。

</details>


### [116] [Enhanced Vehicle Speed Detection Considering Lane Recognition Using Drone Videos in California](https://arxiv.org/abs/2506.11239)
**中文标题：基于无人机视频的车道识别增强型车辆速度检测方法在加州的应用**

*Amirali Ataee Naeini,Ashkan Teymouri,Ghazaleh Jafarsalehi,Michael Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于改进YOLOv11模型的车辆速度检测系统，通过无人机视频识别车道并分类车辆，显著提高了检测精度，适用于加州交通监控。


<details>
  <summary>详细信息</summary>
研究动机: 加州车辆数量增加，但交通系统不足且测速摄像头稀疏，亟需高效的车道级车辆速度检测方法，以监控HOV车道速度、区分车辆类型并执行限速规定。

研究方法: 研究采用改进的YOLOv11模型，训练近800张鸟瞰图，识别车辆所在车道并分类为轿车和重型车辆，同时评估无人机高度、ROI距离和车速对检测精度的影响。

研究结果: 改进的YOLOv11模型在测试中表现最佳，平均绝对误差（MAE）为0.97 mph，均方误差（MSE）为0.94 mph²，显著提升了速度和分类的准确性。

研究结论: 改进的YOLOv11模型有效解决了车辆速度检测和分类的挑战，适用于实际交通监控需求。

中文摘要: 加州车辆数量的增加，由于交通系统不足和测速摄像头稀疏，亟需高效的车辆速度检测方法。车道级车辆速度检测对于监控高载客量（HOV）车道速度、区分轿车与重型车辆（限速不同）以及执行重型车辆车道限制至关重要。以往研究使用YOLO进行车辆速度检测，但精度不足，未能识别车道，且分类类别有限或不实用。本研究提出了一种改进的YOLOv11模型，训练了近800张鸟瞰图，显著提高了车辆速度检测的精度。该系统能够识别每辆车的所在车道，并将车辆分为轿车和重型车辆两类。为满足交通监控和管理的特定需求，模型还评估了无人机高度、感兴趣区域（ROI）距离和车速对检测精度和速度测量的影响。通过北加州的无人机视频测试，改进的YOLOv11模型表现最佳，平均绝对误差（MAE）为0.97 mph，均方误差（MSE）为0.94 mph²，证明了其在车辆速度检测和分类中的有效性。

</details>


### [117] [Lifting Data-Tracing Machine Unlearning to Knowledge-Tracing for Foundation Models](https://arxiv.org/abs/2506.11253)
**中文标题：将数据追踪机器遗忘提升为面向基础模型的知识追踪遗忘**

*Yuwen Tan,Boqing Gong*

主要分类: cs.CV

摘要简述: 本文提出将数据追踪的机器遗忘提升为面向基础模型的知识追踪遗忘，以满足多样化的遗忘需求，并更贴近人脑遗忘机制。


<details>
  <summary>详细信息</summary>
研究动机: 当前的数据追踪机器遗忘方法无法满足基础模型的多样化遗忘需求（如来自监管机构、企业用户等的请求），且与人脑遗忘机制不符。因此，提出知识追踪遗忘以解决这些问题。

研究方法: 通过分析实际需求和认知研究，提出知识追踪遗忘的概念，并以视觉语言基础模型为例，展示如何实现这一范式。

研究结果: 知识追踪遗忘能够更灵活地满足多样化遗忘需求，同时更贴近人脑的遗忘机制。

研究结论: 知识追踪遗忘为机器遗忘提供了新思路，尤其适用于基础模型，未来可进一步探索其实现和应用。

中文摘要: 机器遗忘旨在移除某些训练数据点及其对AI模型的影响（例如，当数据所有者撤销允许模型学习其数据的决定时）。在本立场论文中，我们提出将数据追踪的机器遗忘提升为面向基础模型（FMs）的知识追踪遗忘。这一立场基于实际需求和认知研究的支持。实际上，数据追踪无法满足基础模型的多样化遗忘请求（如来自监管机构、企业用户、产品团队等的请求），这些请求方通常无法访问基础模型的海量训练数据。相反，这些方更容易提出关于基础模型（不应）具备的知识或能力的遗忘请求。从认知角度看，知识追踪遗忘比追踪单个训练数据点更贴近人脑的遗忘机制。最后，我们通过一个视觉语言基础模型的具体案例，展示了如何实例化知识追踪机器遗忘范式。

</details>


### [118] [TARDIS STRIDE: A Spatio-Temporal Road Image Dataset for Exploration and Autonomy](https://arxiv.org/abs/2506.11302)
**中文标题：TARDIS STRIDE：用于探索与自主性的时空道路图像数据集**

*Héctor Carrión,Yutong Bai,Víctor A. Hernández Castro,Kishan Panaganti,Ayush Zenith,Matthew Trang,Tony Zhang,Pietro Perona,Jitendra Malik*

主要分类: cs.CV

摘要简述: 本文提出了一种时空道路图像数据集STRIDE，用于建模动态环境中的空间和时间变化，并通过TARDIS模型展示了其在图像合成、自主控制等任务中的强大性能。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界环境具有动态变化的特性，尤其是空间和时间上的变化。为了捕捉这些复杂动态，需要一种能够同时建模空间和时间关系的数据集和方法。

研究方法: 作者提出了STRIDE数据集，将360度全景图像转化为丰富的观察、状态和动作节点。基于此数据集，开发了TARDIS模型，一种基于Transformer的生成式世界模型，通过自回归框架整合时空动态。

研究结果: TARDIS模型在可控图像合成、指令跟随、自主控制和地理定位等任务中表现出色，展示了其在建模复杂时空动态方面的优势。

研究结论: 该研究为开发能够理解和操纵时空动态的通用智能体提供了有前景的方向，并增强了其具身推理能力。

中文摘要: 世界模型旨在模拟环境并实现有效的智能体行为。然而，建模现实世界环境具有独特的挑战，因为它们会在空间和关键的时间维度上动态变化。为了捕捉这些复合动态，我们引入了一种时空道路图像数据集（STRIDE），将360度全景图像转化为丰富的相互关联的观察、状态和动作节点。利用这种结构，我们可以同时建模以自我为中心的视角、位置坐标和运动指令在空间和时间上的关系。我们通过TARDIS对这一数据集进行基准测试，TARDIS是一种基于Transformer的生成式世界模型，通过统一的训练在STRIDE上的自回归框架整合时空动态。我们展示了其在可控的逼真图像合成、指令跟随、自主控制和最先进的地理定位等一系列智能体任务中的强大性能。这些结果表明，朝着能够理解和操纵其物质环境时空特性的复杂通用智能体方向迈出了有前景的一步，并增强了其具身推理能力。训练代码、数据集和模型检查点可在https://huggingface.co/datasets/Tera-AI/STRIDE获取。

</details>


### [119] [HyBiomass: Global Hyperspectral Imagery Benchmark Dataset for Evaluating Geospatial Foundation Models in Forest Aboveground Biomass Estimation](https://arxiv.org/abs/2506.11314)
**中文标题：HyBiomass：用于评估地理空间基础模型在森林地上生物量估计中的全球高光谱影像基准数据集**

*Aaron Banze,Timothée Stassin,Nassim Ait Ali Braham,Rıdvan Salih Kuzu,Simon Besnard,Michael Schmitt*

主要分类: cs.CV

摘要简述: 本文介绍了一个全球分布的高光谱影像基准数据集HyBiomass，用于评估地理空间基础模型在森林地上生物量估计中的性能。实验表明，这些模型在部分情况下优于基线U-Net，且性能受数据集规模和ViT主干中标记块大小的影响。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准数据集多局限于分割或分类任务，且地理覆盖有限。为填补这一空白，作者提出了一个全球分布的高光谱影像数据集，用于评估地理空间基础模型在森林地上生物量估计中的表现。

研究方法: 数据集结合了EnMAP卫星的高光谱影像和GEDI激光雷达的森林地上生物量密度估计，覆盖七大洲。实验评估了地理空间基础模型与基线U-Net的性能，并分析了数据集规模和ViT主干中标记块大小的影响。

研究结果: 实验结果显示，地理空间基础模型在部分情况下性能优于U-Net，尤其是对编码器进行微调时。性能差异与各区域数据集规模及ViT主干中标记块大小密切相关。

研究结论: 通过发布这一全球分布的高光谱基准数据集，作者旨在促进地理空间基础模型在高光谱影像应用中的发展与评估，并推动对地理偏见和泛化能力的研究。

中文摘要: 全面评估地理空间基础模型（Geo-FMs）需要在多样化任务、传感器和地理区域中进行基准测试。然而，现有大多数基准数据集局限于分割或分类任务，且集中于特定地理区域。为填补这一空白，我们引入了一个全球分布的森林地上生物量（AGB）估计数据集，这是一个像素级回归任务。该基准数据集结合了来自环境测绘与分析计划（EnMAP）卫星的高光谱影像（HSI）和全球生态系统动态调查激光雷达的AGB密度估计预测，覆盖七大洲。实验结果表明，评估的Geo-FMs在某些情况下可以匹配甚至超越基线U-Net的性能，尤其是在对编码器进行微调时。我们还发现，U-Net与Geo-FMs之间的性能差异与各区域数据集规模相关，并强调了视觉变换器主干中标记块大小对像素级回归任务准确预测的重要性。通过发布这一全球分布的高光谱基准数据集，我们旨在促进Geo-FMs在HSI应用中的开发与评估。利用该数据集还可进一步研究Geo-FMs的地理偏见和泛化能力。数据集和源代码将公开提供。

</details>


### [120] [GynSurg: A Comprehensive Gynecology Laparoscopic Surgery Dataset](https://arxiv.org/abs/2506.11356)
**中文标题：GynSurg：一个全面的妇科腹腔镜手术数据集**

*Sahar Nasirihaghighi,Negin Ghamsarian,Leonie Peschek,Matteo Munari,Heinrich Husslein,Raphael Sznitman,Klaus Schoeffmann*

主要分类: cs.CV

摘要简述: GynSurg是一个全面且多样化的妇科腹腔镜手术数据集，支持多任务分析，填补了现有数据集的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前妇科腹腔镜手术数据集规模小、任务单一或注释不详细，限制了其在全面工作流分析中的应用。GynSurg旨在解决这些问题，推动智能手术系统的发展。

研究方法: GynSurg提供了大规模、多任务的妇科腹腔镜手术数据集，包含丰富的注释，支持动作识别、语义分割、手术文档化和新手术见解的发现。

研究结果: 通过标准化训练协议对先进模型进行基准测试，验证了GynSurg数据集的质量和多功能性。

研究结论: GynSurg填补了妇科腹腔镜手术数据集的空白，为智能手术系统的发展提供了重要资源，并公开了数据集以加速领域进展。

中文摘要: 深度学习的最新进展推动了计算机辅助干预和手术视频分析的变革，不仅改善了手术培训、术中决策支持和患者预后，还促进了术后文档化和手术发现。这些发展的核心在于大规模、高质量注释数据集的可用性。在妇科腹腔镜手术中，手术场景理解和动作识别对于构建智能系统至关重要，这些系统可在术中辅助外科医生并在术后提供深入分析。然而，现有数据集通常因规模小、任务单一或注释不够详细而受限，限制了其在全面端到端工作流分析中的实用性。为解决这些问题，我们推出了GynSurg，这是迄今为止最大、最多样化的妇科腹腔镜手术多任务数据集。GynSurg提供了跨多个任务的丰富注释，支持动作识别、语义分割、手术文档化和新手术见解的发现。我们通过标准化训练协议对先进模型进行基准测试，验证了数据集的质量和多功能性。为加速领域进展，我们公开了GynSurg数据集及其注释。

</details>


### [121] [A Watermark for Auto-Regressive Image Generation Models](https://arxiv.org/abs/2506.11371)
**中文标题：自回归图像生成模型的水印技术**

*Yihan Wu,Xuehao Cui,Ruibo Chen,Georgios Milis,Heng Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为C-reweight的无失真水印方法，专为自回归图像生成模型设计，通过聚类策略解决重标记不匹配问题，同时保持图像质量并提升检测能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着图像生成模型的快速发展，其潜在滥用风险（如深度伪造、钓鱼攻击等）凸显了真实性验证的重要性。传统水印技术在图像生成模型中因重标记不匹配问题效果不佳，亟需新的解决方案。

研究方法: 提出C-reweight方法，利用聚类策略将同一簇内的标记视为等效，避免重标记不匹配问题，同时确保图像保真度。

研究结果: 在主流图像生成平台上的实验表明，C-reweight不仅保持了生成图像的视觉质量，还显著提升了水印的检测能力，优于现有无失真水印技术。

研究结论: C-reweight为图像生成模型提供了一种高效、安全的水印方案，为可信图像合成设定了新标准。

中文摘要: 图像生成模型的快速发展彻底改变了视觉内容创作，能够为多样化应用生成高度逼真且上下文准确的图像。然而，潜在的滥用风险（如深度伪造、基于图像的钓鱼攻击以及误导性视觉证据的伪造）凸显了对强健的真实性验证机制的需求。尽管传统的统计水印技术对自回归语言模型有效，但其直接应用于图像生成模型时，因重标记不匹配现象（即图像生成过程中原始序列与重标记序列之间的差异）而面临重大挑战。为克服这一限制，我们提出了C-reweight，一种专为图像生成模型设计的无失真水印方法。通过采用基于聚类的策略，将同一簇内的标记视为等效，C-reweight在保持图像保真度的同时缓解了重标记不匹配问题。在主流图像生成平台上的广泛评估表明，C-reweight不仅保持了生成图像的视觉质量，还显著提升了检测能力，优于现有无失真水印技术，为安全可信的图像合成设定了新标准。

</details>


### [122] [Scalable Context-Preserving Model-Aware Deep Clustering for Hyperspectral Images](https://arxiv.org/abs/2506.11377)
**中文标题：可扩展的上下文保持模型感知深度聚类方法在高光谱图像中的应用**

*Xianlu Li,Nicolas Nadisic,Shaoguang Huang,Nikos Deligiannis,Aleksandra Pižurica*

主要分类: cs.CV

摘要简述: 本文提出了一种基于基表示的可扩展、上下文保持的深度聚类方法，用于高效的高光谱图像（HSI）聚类。该方法通过联合优化局部和非局部结构约束，显著提升了聚类性能，同时降低了计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的模型感知深度子空间聚类方法通常采用两阶段框架，计算复杂度高（O(n^2)），且仅包含局部或非局部空间结构约束，无法有效监督整个聚类过程。因此，亟需一种高效且能同时捕捉局部和非局部结构的方法。

研究方法: 提出了一种基于基表示的一阶段深度聚类方法，通过空间平滑约束（局部结构）和基于小簇的方案（非局部结构）联合优化聚类预测。该方法的时间复杂度为O(n)，适用于大规模HSI数据。

研究结果: 在真实数据集上的实验表明，该方法在性能和效率上均优于现有技术。

研究结论: 该方法通过联合优化局部和非局部结构约束，实现了高效且高性能的HSI聚类，为大规模数据处理提供了可行的解决方案。

中文摘要: 子空间聚类已成为高光谱图像（HSI）无监督分析的常用方法。现有的模型感知深度子空间聚类方法通常采用两阶段框架，涉及计算复杂度为O(n^2)的自表示矩阵，随后进行谱聚类。然而，这些方法计算量大，通常仅包含局部或非局部空间结构约束，且其结构约束无法有效监督整个聚类过程。

我们提出了一种基于基表示的可扩展、上下文保持的深度聚类方法，联合捕捉局部和非局部结构以实现高效HSI聚类。为保持局部结构（即子空间内的空间连续性），我们引入了一种空间平滑约束，使聚类预测与其空间滤波版本对齐。对于非局部结构（即光谱连续性），我们采用基于小簇的方案，在组级别细化预测，鼓励光谱相似的像素属于同一子空间。值得注意的是，这两种约束被联合优化以相互增强。

具体而言，我们的模型设计为一阶段方法，其中结构约束应用于整个聚类过程。该方法的时间和空间复杂度为O(n)，适用于大规模HSI数据。在真实数据集上的实验表明，我们的方法优于现有技术。代码可在以下链接获取：https://github.com/lxlscut/SCDSC

</details>


### [123] [Enhance Multimodal Consistency and Coherence for Text-Image Plan Generation](https://arxiv.org/abs/2506.11380)
**中文标题：增强文本-图像计划的多模态一致性与连贯性**

*Xiaoxin Lu,Ranran Haoran Zhang,Yusen Zhang,Rui Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种新框架，用于生成和优化文本-图像计划，解决多模态一致性和连贯性问题，并通过实验验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注文本计划的生成，而文本-图像计划的潜力尚未充分挖掘。生成高质量文本-图像计划面临多模态一致性和视觉步骤连贯性的挑战。

研究方法: 框架分步生成和优化文本-图像计划：1) 基于历史预测生成文本步骤；2) 编辑视觉步骤；3) 提取视觉信息；4) 结合视觉信息优化文本步骤。

研究结果: 实验结果表明，该方法在多个骨干模型上优于基线，并通过新设计的指标验证了多模态一致性和连贯性的提升。

研究结论: 该框架为文本-图像计划生成提供了有效解决方案，适用于多种骨干模型，并开源了代码和数据。

中文摘要: 人们通过涉及文本和图像的多种媒体获取日常任务计划。然而，大多数先前研究仅关注大语言模型在文本计划生成中的能力，而大规模模型在提供文本-图像计划方面的潜力尚未充分研究。生成高质量文本-图像计划面临两个主要挑战：确保两种模态之间的一致对齐以及保持视觉步骤的连贯性。为解决这些挑战，我们提出了一种新框架，逐步生成和优化文本-图像计划。在每次迭代中，框架（1）基于预测历史生成下一个文本步骤；（2）编辑上一个视觉步骤以生成下一个；（3）提取类似PDDL的视觉信息；（4）利用提取的视觉信息优化文本步骤。阶段（4）和（2）生成的文本和视觉步骤将作为下一次迭代的输入。我们的方法为多种骨干模型（如Mistral-7B、Gemini-1.5和GPT-4o）提供了即插即用的改进。为评估方法的有效性，我们收集了一个包含1,100个任务及其文本-图像对解决方案的新基准数据集，涵盖11个日常主题。我们还设计并验证了一组新指标，用于评估文本-图像计划中的多模态一致性和连贯性。大量实验结果表明，我们的方法在多个骨干模型上优于竞争基线。代码和数据已开源：https://github.com/psunlpgroup/MPlanner。

</details>


### [124] [Dynamic Double Space Tower](https://arxiv.org/abs/2506.11394)
**中文标题：动态双向空间塔**

*Weikai Sun,Shijie Song,Han Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种动态双向空间塔模型，通过模拟人类格式塔视觉原理增强视觉问答任务中的空间关系理解，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉问答方法在复杂推理场景中表现不佳，主要由于跨模态交互不足和空间关系捕捉能力有限。

研究方法: 提出动态双向空间塔模型，分为四层模拟人类格式塔视觉，为实体间空间关系提供结构化先验，提升模型感知能力。

研究结果: 实验表明该模块可广泛应用于多模态模型，并在空间关系问答数据集上取得最优结果，仅用3B参数的模型July即达到SOTA性能。

研究结论: 动态双向空间塔显著提升了模型对空间关系的理解能力，为视觉问答任务提供了新的解决方案。

中文摘要: 视觉问答（VQA）任务需要同时理解图像内容和问题语义。然而，现有方法由于跨模态交互不足和图像中实体空间关系捕捉能力有限，难以处理复杂推理场景。我们研究了一种全新的方法以替代注意力机制，旨在增强模型的推理能力和空间关系理解。具体而言，我们提出了一种动态双向空间塔，分为四层模拟人类格式塔视觉原理，自然地为实体间的空间组织提供了强大的结构化先验，使模型不再盲目搜索像素间关系，而是基于更有意义的感知单元进行判断，从“看图像”转变为“感知和组织图像内容”。大量实验表明，我们的模块可应用于任何其他多模态模型并取得先进结果，展示了其在空间关系处理中的潜力。同时，基于该方法训练的多模态视觉问答模型July仅用3B参数即达到最先进水平，尤其在空间关系问答数据集上表现突出。

</details>


### [125] [Stop learning it all to mitigate visual hallucination, Focus on the hallucination target](https://arxiv.org/abs/2506.11417)
**中文标题：停止学习全部内容以缓解视觉幻觉，聚焦幻觉目标**

*Dokyoon Yoon,Youngsook Song,Woomyong Park*

主要分类: cs.CV

摘要简述: 提出一种偏好学习方法，通过聚焦幻觉目标区域，减少多模态大语言模型在视觉语言任务中的幻觉问题，提升模型可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型在视觉语言任务中常因生成输入图像中不存在的对象信息而产生幻觉，影响实际应用中的准确性。

研究方法: 构建包含幻觉响应、正确响应及目标信息的数据集，采用偏好学习方法，仅针对幻觉目标区域进行优化，过滤无关信号。

研究结果: 实验表明，该方法有效减少多类视觉幻觉任务中的幻觉现象，提升模型可靠性且不影响整体性能。

研究结论: 聚焦幻觉目标区域的偏好学习方法能显著减少多模态大语言模型的幻觉问题，提升其实际应用价值。

中文摘要: 多模态大语言模型（MLLMs）在视觉语言任务中常因生成输入图像中不存在的对象信息而产生幻觉问题，严重影响需要准确对象识别的实际应用中的模型可靠性。为解决这一问题，我们提出了一种偏好学习方法\mymethod\，通过聚焦幻觉发生的目标区域来缓解幻觉。为此，我们构建了一个数据集，包含幻觉响应、正确响应及目标信息（即图像中存在的对象及受幻觉影响的响应块位置）。通过仅针对这些特定目标应用偏好学习方法，模型能够过滤无关信号并专注于纠正幻觉。这使得模型能够仅关注相关信息，生成更真实的结果。实验结果表明，\mymethod\在多种视觉幻觉任务中有效减少了幻觉现象，提升了MLLMs的可靠性和性能，且未影响整体表现。

</details>


### [126] [Auto-Connect: Connectivity-Preserving RigFormer with Direct Preference Optimization](https://arxiv.org/abs/2506.11430)
**中文标题：Auto-Connect：基于直接偏好优化的连接性保留RigFormer**

*Jingfeng Guo,Jian Liu,Jinnan Chen,Shiwei Mao,Changrong Hu,Puhua Jiang,Junlin Yu,Jing Xu,Qi Liu,Lixin Xu,Zhuo Chen,Chunchao Guo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Auto-Connect的新方法，通过连接性保留的令牌化方案和拓扑感知奖励函数，显著提升了自动骨骼绑定的拓扑准确性和变形质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的骨骼绑定方法通常无法直接保留骨骼的连接性，导致拓扑结构不准确或变形效果不佳。本文旨在通过引入连接性保留的令牌化和拓扑感知优化，解决这些问题。

研究方法: Auto-Connect采用连接性保留的令牌化方案，通过特殊令牌定义关节的端点，并利用拓扑感知奖励函数进行后训练优化。此外，还结合隐式测地特征进行骨骼选择，提升蒙皮质量。

研究结果: 实验表明，该方法能够生成更符合解剖学结构的骨骼，并显著减少蒙皮变形中的常见问题，如皮肤拉伸或扭曲。

研究结论: Auto-Connect通过连接性保留的令牌化、奖励引导的优化和测地感知的骨骼选择，实现了高质量的骨骼绑定和变形效果。

中文摘要: 我们提出了Auto-Connect，一种新颖的自动骨骼绑定方法，通过连接性保留的令牌化方案显式地保留骨骼的连接性。与以往方法不同，我们的方法使用特殊令牌为每个关节的子节点和每个层级定义端点，从而自动确定连接关系。这种方法通过将连接信息直接整合到预测框架中，显著提升了拓扑准确性。为了进一步保证高质量的拓扑结构，我们实现了一种拓扑感知的奖励函数，用于量化拓扑正确性，并通过奖励引导的直接偏好优化进行后训练。此外，我们还引入了隐式测地特征用于潜在的前k骨骼选择，显著提升了蒙皮质量。通过在模型的潜在空间中利用测地距离信息，我们的方法能够智能地确定每个顶点最具影响力的骨骼，有效减少常见的蒙皮伪影。这种结合连接性保留的令牌化、奖励引导的微调和测地感知的骨骼选择的方法，使我们的模型能够一致地生成更符合解剖学结构的骨骼，并具有更优的变形特性。

</details>


### [127] [Auditing Data Provenance in Real-world Text-to-Image Diffusion Models for Privacy and Copyright Protection](https://arxiv.org/abs/2506.11434)
**中文标题：真实世界文本到图像扩散模型中的数据来源审计：隐私与版权保护**

*Jie Zhu,Leye Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FSCA的黑盒审计框架，用于检测文本到图像扩散模型中的数据来源，以解决隐私和版权问题。该方法无需模型内部知识，通过语义一致性实现高效审计，实验表明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 文本到图像扩散模型依赖大规模网络数据集，可能引发版权和隐私问题。现有审计方法依赖模型内部知识或评估不可靠，亟需一种无需内部知识的黑盒审计方案。

研究方法: 提出FSCA框架，利用文本到图像扩散模型中的两种语义连接进行审计，无需访问内部知识。引入召回平衡策略和阈值调整策略，提升实际应用中的准确性。

研究结果: 在LAION-mi和COCO数据集上的实验显示，FSCA在多种指标和数据分布下优于8种基线方法，用户级准确率可达90%（仅需10个样本/用户）。

研究结论: FSCA是一种高效的黑盒审计框架，适用于实际场景中的隐私和版权保护，具有显著的应用潜力。

中文摘要: 文本到图像扩散模型因其强大的生成能力对内容创作产生了深远影响，但其依赖从社交媒体等网络平台收集的大规模文本-图像数据集，引发了版权合规和个人隐私泄露的挑战。尽管已有研究探索审计此类模型数据来源的方法，但现有工作依赖不现实的假设（如获取模型内部知识）或评估不可靠。为此，我们提出了一种完全黑盒的审计框架——基于特征语义一致性的审计（FSCA），利用文本到图像扩散模型中的两种语义连接进行审计，无需内部知识。通过在LAION-mi和COCO数据集上的广泛实验，并与8种前沿基线方法对比，结果表明FSCA在多种指标和数据分布下均优于基线方法。此外，我们引入了召回平衡策略和阈值调整策略，使FSCA在实际审计场景中仅需10个样本/用户即可达到90%的用户级准确率，展现了其强大的实际应用潜力。代码已开源：https://github.com/JiePKU/FSCA。

</details>


### [128] [TAViS: Text-bridged Audio-Visual Segmentation with Foundation Models](https://arxiv.org/abs/2506.11436)
**中文标题：TAViS：基于基础模型的文本桥接音频-视觉分割**

*Ziyang Luo,Nian Liu,Xuguang Yang,Salman Khan,Rao Muhammad Anwer,Hisham Cholakkal,Fahad Shahbaz Khan,Junwei Han*

主要分类: cs.CV

摘要简述: TAViS是一种新型框架，通过结合多模态基础模型（ImageBind）和分割基础模型（SAM2），解决了音频-视觉分割中的跨模态对齐问题。其核心是通过文本桥接设计实现模态间知识传递，并在多个数据集上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 音频-视觉分割（AVS）面临跨模态对齐的挑战。现有方法通常依赖单模态知识或简单组合基础模型，未能有效解决对齐问题。TAViS旨在通过结合多模态和分割基础模型，提升跨模态对齐能力。

研究方法: TAViS提出了一种文本桥接设计，包括：（1）文本桥接混合提示机制，通过伪文本提供类别原型信息并保留模态细节；（2）利用文本作为桥梁的对齐监督策略，对齐音频-视觉模态中的共享语义概念。

研究结果: TAViS在单源、多源和语义数据集上表现优异，并在零样本设置中展现出卓越性能。

研究结论: TAViS通过文本桥接设计有效解决了跨模态对齐问题，为音频-视觉分割任务提供了新的解决方案。

中文摘要: 音频-视觉分割（AVS）面临有效对齐音频和视觉模态的基本挑战。尽管近期方法利用基础模型解决数据稀缺问题，但它们通常依赖单模态知识或以现成方式组合基础模型，未能解决跨模态对齐问题。本文提出TAViS，一种新颖框架，通过结合多模态基础模型（ImageBind）和分割基础模型（SAM2）实现跨模态对齐和精确分割。然而，有效结合这些模型面临两大挑战：SAM2与ImageBind因特征空间不同导致知识传递困难，以及仅使用分割损失监督的不足。为此，我们引入了一种文本桥接设计，包括两个关键组件：（1）文本桥接混合提示机制，其中伪文本提供类别原型信息，同时保留音频和视觉输入的模态细节；（2）利用文本作为桥梁的对齐监督策略，对齐音频-视觉模态中的共享语义概念。我们的方法在单源、多源和语义数据集上表现优异，并在零样本设置中表现出色。

</details>


### [129] [Uncertainty Awareness Enables Efficient Labeling for Cancer Subtyping in Digital Pathology](https://arxiv.org/abs/2506.11439)
**中文标题：不确定性感知助力数字病理学中癌症亚型分类的高效标注**

*Nirhoshan Sivaroopan,Chamuditha Jayanga Galappaththige,Chalani Ekanayake,Hasindri Watawana,Ranga Rodrigo,Chamira U. S. Edussooriya,Dushan N. Wadduwage*

主要分类: cs.CV

摘要简述: 该论文提出了一种基于不确定性感知的自监督对比学习模型，用于癌症亚型分类，通过选择性标注关键图像显著减少标注需求，仅需1-10%的标注即可达到最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 癌症亚型分类模型需要大量专家标注数据，但标注成本高昂且耗时。论文旨在通过引入不确定性感知机制，优化标注过程，减少对大规模标注数据的依赖。

研究方法: 采用自监督对比学习模型，并在每个训练周期计算证据向量以评估模型预测的置信度。利用不确定性分数选择需要进一步标注的关键图像，迭代优化训练过程。

研究结果: 仅需1-10%的标注数据即可在基准数据集上实现最优的癌症亚型分类性能，显著提高了分类的精确性和效率。

研究结论: 该方法为标注数据有限的场景提供了高效解决方案，为数字病理学中的癌症亚型分类研究开辟了新方向。

中文摘要: 机器学习辅助的癌症亚型分类是数字病理学中的一个重要研究方向。然而，癌症亚型分类模型需要依赖专家标注数据进行训练，以确保其预测结果具有一定的确定性（或不确定性）。为此，我们在自监督对比学习模型中引入了不确定性感知的概念。具体方法是在每个训练周期计算证据向量，评估模型对预测结果的置信度。通过不确定性分数，选择性地标注最关键的图像，从而迭代优化训练过程。实验表明，仅需1-10%的策略性标注数据，即可在基准数据集上实现最优的癌症亚型分类性能。该方法不仅优化了标注流程，减少了对大规模标注数据的需求，还显著提升了分类的精确性和效率。这一成果在标注数据有限的场景中尤为有益，为数字病理学的未来研究和应用提供了新的方向。

</details>


### [130] [On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving](https://arxiv.org/abs/2506.11472)
**中文标题：自动驾驶中视觉语言模型对视觉感知攻击的天然鲁棒性研究**

*Pedram MohajerAnsari,Amir Salarpour,Michael Kühr,Siyu Huang,Mohammad Hamad,Sebastian Steinhorst,Habeeb Olufowobi,Mert D. Pesé*

主要分类: cs.CV

摘要简述: 本文提出了一种专为自动驾驶感知任务优化的视觉语言模型（V2LM），其在对抗攻击下表现出优于传统深度神经网络的鲁棒性，无需对抗训练即可保持高精度。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶依赖深度神经网络完成关键任务，但这些模型易受攻击，导致误分类和安全问题。传统防御方法如对抗训练会降低正常精度且难以泛化。因此，研究旨在探索一种更鲁棒的替代方案。

研究方法: 研究引入了车辆视觉语言模型（V2LM），并评估了两种部署策略：单独模式（Solo Mode）和联合模式（Tandem Mode）。前者针对单一任务，后者则统一处理多任务。

研究结果: 实验显示，传统深度神经网络在攻击下性能下降33%-46%，而V2LM平均仅下降不到8%。联合模式在内存效率上表现更优，且鲁棒性与单独模式相当。

研究结论: V2LM为自动驾驶感知系统提供了一种更安全、更鲁棒的解决方案，尤其在对抗攻击下表现优异。

中文摘要: 自动驾驶车辆（AVs）依赖深度神经网络（DNNs）完成交通标志识别（TSR）、自动车道居中（ALC）和车辆检测（VD）等关键任务。然而，这些模型易受攻击，导致误分类并危及安全。传统防御机制（如对抗训练）通常会降低正常精度，且难以泛化到未见攻击。本文提出了一种专为自动驾驶感知优化的车辆视觉语言模型（V2LM）。研究发现，V2LM无需对抗训练即表现出对未见攻击的天然鲁棒性，在对抗条件下保持显著高于传统DNNs的精度。我们评估了两种部署策略：单独模式（单个V2LM处理特定任务）和联合模式（单一V2LM同时处理多任务）。实验结果表明，DNNs在攻击下性能下降33%-46%，而V2LMs平均仅下降不到8%。联合模式在内存效率上更具优势，且鲁棒性与单独模式相当。我们还探讨了将V2LMs作为并行组件集成到AV感知系统中以增强对抗威胁的抵御能力。结果表明，V2LMs为构建更安全、更鲁棒的AV感知系统提供了可行路径。

</details>


### [131] [FAME: A Lightweight Spatio-Temporal Network for Model Attribution of Face-Swap Deepfakes](https://arxiv.org/abs/2506.11477)
**中文标题：FAME：一种轻量级时空网络用于面部交换Deepfake的模型归因**

*Wasim Ahmad,Yan-Tsung Peng,Yuan-Hao Chang*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级的时空网络FAME，用于识别面部交换Deepfake视频的生成模型，显著提升了模型归因的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 面部交换Deepfake视频的广泛传播对数字安全、隐私和媒体完整性构成威胁，现有研究多集中于二元检测，而模型归因任务（确定生成模型）研究不足。

研究方法: FAME通过多级嵌入和时空注意力机制捕捉不同生成模型的细微伪影，设计轻量高效，结合空间和时间特征提升归因准确性。

研究结果: 在DFDM、FaceForensics++和FakeAVCeleb数据集上，FAME在准确性和运行时间上均优于现有方法，展示了其在实际应用中的潜力。

研究结论: FAME作为一种高效的模型归因工具，为Deepfake视频的溯源提供了可靠解决方案，适用于现实世界的法医和信息安全应用。

中文摘要: 面部交换Deepfake视频的广泛出现对数字安全、隐私和媒体完整性构成日益增长的风险，亟需有效的取证工具以识别此类操纵的来源。尽管大多数先前研究主要集中于二元Deepfake检测，但模型归因任务——确定生成模型——仍未被充分探索。本文提出FAME（通过多级嵌入的伪造归因），一种轻量高效的时空框架，旨在捕捉不同面部交换模型特有的细微生成伪影。FAME结合空间和时间注意力机制以提高归因准确性，同时保持计算效率。我们在三个具有挑战性和多样性的数据集（DFDM、FaceForensics++和FakeAVCeleb）上评估了模型。结果表明，FAME在准确性和运行时间上均优于现有方法，突显了其在现实世界取证和信息安全应用中的部署潜力。

</details>


### [132] [Environmental Change Detection: Toward a Practical Task of Scene Change Detection](https://arxiv.org/abs/2506.11481)
**中文标题：环境变化检测：迈向场景变化检测的实用任务**

*Kyusik Cho,Suhan Woo,Hongje Seong,Euntai Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为环境变化检测（ECD）的实用任务，旨在解决传统场景变化检测（SCD）中依赖理想化对齐参考图像的局限性。通过利用大规模未筛选图像数据库和环境线索，提出了一种联合理解空间环境并检测变化的框架，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统场景变化检测（SCD）假设参考图像与查询图像视角完全对齐，这在实际中难以实现。本文旨在将问题推向更实用的方向，通过环境线索而非理想化对齐的参考图像来检测变化。

研究方法: 提出了一种新框架，通过利用多个参考候选和聚合语义丰富的表示来检测变化，避免因视角错位和有限视野覆盖导致的次优解。

研究结果: 在三个标准基准集上的实验表明，该方法显著优于现有方法的简单组合，且性能接近理想化设置。

研究结论: 环境变化检测（ECD）为场景变化检测提供了更实用的解决方案，通过环境线索和多参考候选的联合利用，显著提升了检测性能。

中文摘要: 人类并非记忆一切，而是通过探索过去的图像来识别场景变化。然而，可用的过去（即参考）图像通常代表与当前（即查询）场景相近的视角，而非完全相同的视角。尽管存在这一实际限制，传统的场景变化检测（SCD）仍被形式化为一种理想化设置，即每个查询都有视角匹配的参考图像。本文将此问题推向更实用的任务，并引入了环境变化检测（ECD）。ECD的关键在于避免不切实际的对齐查询-参考对，仅依赖环境线索。受现实实践的启发，我们通过一个大规模未筛选图像数据库提供这些线索。为解决这一新任务，我们提出了一种新框架，联合理解空间环境并检测变化。核心思想是，由于视角错位和有限视野覆盖，查询与参考在相同空间位置的匹配可能导致次优解。我们通过利用多个参考候选和聚合语义丰富的表示来解决这一限制。在三个为ECD重建的标准基准集上评估了我们的框架，显著优于现有方法的简单组合，同时达到与理想化设置相当的性能。代码将在接受后发布。

</details>


### [133] [Composite Data Augmentations for Synthetic Image Detection Against Real-World Perturbations](https://arxiv.org/abs/2506.11490)
**中文标题：针对真实世界扰动的合成图像检测复合数据增强方法**

*Efthymia Amarantidou,Christos Koutlis,Symeon Papadopoulos,Panagiotis C. Petrantonakis*

主要分类: cs.CV

摘要简述: 本文提出了一种针对合成图像检测的复合数据增强方法，通过遗传算法优化增强组合，显著提升了模型在真实世界扰动下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI工具的普及，合成图像在社交媒体上的传播对信息完整性构成威胁。现有检测方法在互联网上经过压缩等操作的合成图像上表现不佳，因此需要改进。

研究方法: 研究通过探索数据增强组合，利用遗传算法选择最优增强策略，并引入双标准优化方法，提升合成图像检测模型的鲁棒性。

研究结果: 实验表明，该方法显著提升了模型性能，最佳模型平均精度提高了22.53%。

研究结论: 研究为开发能够识别不同质量和变换的合成图像的检测模型提供了重要参考，代码已开源。

中文摘要: 生成式AI工具的普及使得任何人都能在社交媒体上创建和传播合成图像，常带有误导意图，对在线信息完整性构成重大威胁。大多数现有合成图像检测（SID）方法在处理来自互联网的生成图像时表现不佳，因为这些图像常经过压缩等操作。为此，本研究通过探索数据增强组合、利用遗传算法优化增强选择，并引入双标准优化方法，显著提升了模型在真实世界扰动下的性能。研究结果为开发能够识别不同质量和变换的合成图像的检测模型提供了宝贵见解，最佳模型平均精度提升了+22.53%。代码已开源：github.com/efthimia145/sid-composite-data-augmentation。

</details>


### [134] [Preserving Clusters in Prompt Learning for Unsupervised Domain Adaptation](https://arxiv.org/abs/2506.11493)
**中文标题：在无监督域适应的提示学习中保持聚类特性**

*Tung-Long Vuong,Hoang Phan,Vy Vo,Anh Bui,Thanh-Toan Do,Trung Le,Dinh Phung*

主要分类: cs.CV

摘要简述: 本文提出了一种新方法，通过利用视觉和文本嵌入的几何关系，增强伪标签并优化目标提示学习，以解决无监督域适应中视觉嵌入分布偏离的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于多模态预训练模型（如CLIP）的无监督域适应方法虽表现优异，但其视觉嵌入分布可能偏离预训练模型，导致误导性信号。本文旨在通过几何关系强化伪标签，提升目标提示学习的效果。

研究方法: 首先基于源与目标视觉嵌入的关系直接利用源提示的参考预测；随后发现预训练多模态模型中视觉与文本嵌入存在强聚类行为，并基于最优传输理论设计新策略，强制文本嵌入保持聚类特性。

研究结果: 实验和消融研究验证了方法的有效性，展示了在目标域中提示学习的优越性能和表示质量的提升。

研究结论: 本文提出的方法通过几何关系优化伪标签和目标提示学习，显著提升了无监督域适应的性能。

中文摘要: 近期利用多模态预训练模型（如CLIP）进行无监督域适应（UDA）的方法通过丰富的语义知识和鲁棒的视觉表示展现了显著潜力。尽管这些方法在基准测试中达到最优性能，但改进主要依赖于基础伪标签（CLIP零样本预测）和自训练机制。因此，训练机制存在关键限制：目标域中的视觉嵌入分布可能偏离预训练模型，导致类别描述的误导信号。本文提出了一种新解决方案，通过利用视觉和文本嵌入的几何关系（现有方法忽略的方面）强化伪标签并促进目标提示学习。我们首先提出基于源与目标视觉嵌入关系直接利用源提示的参考预测；随后发现预训练多模态模型中视觉与文本嵌入存在强聚类行为，并基于最优传输理论设计新策略以强制文本嵌入保持聚类特性。实验和消融研究验证了方法的有效性，展示了目标提示在表示质量上的优越性能和改进。

</details>


### [135] [Manager: Aggregating Insights from Unimodal Experts in Two-Tower VLMs and MLLMs](https://arxiv.org/abs/2506.11515)
**中文标题：Manager：双塔视觉语言模型和多模态大语言模型中单模态专家知识的聚合**

*Xiao Xu,Libo Qin,Wanxiang Che,Min-Yen Kan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Manager的轻量级插件，通过自适应聚合预训练单模态专家的多层级知识，提升双塔视觉语言模型（VLM）和多模态大语言模型（MLLM）的性能。实验表明，Manager在多个下游任务中显著优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有的双塔视觉语言模型（如BridgeTower）在跨模态融合中存在单模态表征利用不充分、语义知识层级利用受限以及仅适用于低分辨率数据集的问题。本文旨在通过引入Manager插件解决这些问题，实现更全面的视觉语言对齐与融合。

研究方法: 本文提出ManagerTower，在双塔VLM的每一跨模态层中引入Manager插件，自适应聚合不同层级的单模态专家知识。此外，还将Manager扩展到多模态大语言模型（MLLM）架构中，验证其通用性。

研究结果: 实验表明，ManagerTower在4个下游视觉语言任务中均优于基线模型。在MLLM架构中，LLaVA-OV-Manager显著提升了20个数据集上的零样本性能，且与多网格算法协同作用进一步提升了表现。

研究结论: Manager插件通过从深度和宽度两个正交视角捕捉更多视觉细节，有效缓解了多网格算法带来的语义模糊问题，显著提升了模型的性能。

中文摘要: 双塔视觉语言模型（VLM）在多种下游视觉语言任务中表现出色。然而，BridgeTower等模型在跨模态融合中存在单模态表征利用不充分、语义知识层级利用受限以及仅适用于低分辨率数据集的问题。为此，本文提出Manager，一种轻量、高效且有效的插件，能够自适应聚合预训练单模态专家的多层级知识，促进更全面的视觉语言对齐与融合。在双塔VLM架构下，我们提出ManagerTower，通过在每一跨模态层引入Manager插件，无论是否进行视觉语言预训练，均显著优于现有基线模型，并在4个下游任务中取得优越性能。此外，我们还将Manager扩展到最新的多模态大语言模型（MLLM）架构中，实验表明LLaVA-OV-Manager在20个下游数据集上显著提升了零样本性能，且无论是否启用多网格算法均表现优异。深入分析表明，Manager和多网格算法可视为两种互补的插件，分别从深度和宽度视角提升视觉表征的多样性，二者的协同作用可缓解多网格算法带来的语义模糊问题，进一步提升性能。代码和模型已开源：https://github.com/LooperXX/ManagerTower。

</details>


### [136] [GNSS-inertial state initialization by distance residuals](https://arxiv.org/abs/2506.11534)
**中文标题：基于距离残差的GNSS-惯性状态初始化方法**

*Samuel Cerezo,Javier Civera*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的GNSS-惯性初始化策略，通过延迟使用全局GNSS测量数据，转而依赖GNSS相对距离残差，以提高初始状态估计的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 传感器平台的初始状态估计通常因初始测量数据有限而难以准确，容易导致非线性优化陷入局部最小值。本文旨在解决这一问题。

研究方法: 提出了一种延迟使用全局GNSS测量数据的策略，初始阶段依赖GNSS相对距离残差，并通过Hessian矩阵奇异值的变化确定切换到全局测量的最佳时机。

研究结果: 在EuRoC和GVINS数据集上的实验表明，该方法显著优于直接使用全局GNSS数据的策略，提供了更准确和鲁棒的初始化结果。

研究结论: 通过延迟使用全局GNSS数据并引入基于Hessian矩阵奇异值的切换准则，本文方法有效提高了初始状态估计的准确性和鲁棒性。

中文摘要: 传感器平台的初始状态估计通常具有挑战性，因为有限的初始测量数据往往携带的信息不足，导致初始估计不准确，并在非线性优化中可能收敛到局部最小值。本文提出了一种新颖的GNSS-惯性初始化策略，延迟使用全局GNSS测量数据，直到有足够信息准确估计GNSS与惯性坐标系之间的转换。相反，该方法初始阶段依赖GNSS相对距离残差。为了确定切换到全局测量的最佳时机，我们引入了一种基于Hessian矩阵奇异值演化的准则。在EuRoC和GVINS数据集上的实验表明，我们的方法始终优于从一开始就使用全局GNSS数据的简单策略，提供了更准确和鲁棒的初始化结果。

</details>


### [137] [FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation](https://arxiv.org/abs/2506.11543)
**中文标题：FIMA-Q：基于Fisher信息矩阵近似的视觉Transformer后训练量化方法**

*Zhuguanyu Wu,Shihe Wang,Jiayi Zhang,Jiaxin Chen,Yunhong Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FIMA-Q的后训练量化方法，针对视觉Transformer（ViT）在低比特量化下精度下降的问题，通过Fisher信息矩阵（FIM）近似优化量化损失，显著提升了量化模型的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前的后训练量化（PTQ）方法在视觉Transformer（ViT）中，尤其是低比特量化时，仍存在显著的精度下降问题。本文旨在通过分析Hessian引导的量化损失的局限性，并提出一种更高效的FIM近似方法来解决这一问题。

研究方法: 基于块级重建框架，本文提出FIMA-Q方法，首先建立KL散度与FIM之间的联系，以快速计算重建过程中的量化损失。进一步提出一种高效的FIM近似方法DPLR-FIM，利用对角加低秩原理，并最终构建量化损失函数。

研究结果: 在多个视觉任务和代表性ViT架构上的实验表明，FIMA-Q方法在低比特量化情况下显著提升了模型精度，优于现有最先进方法。

研究结论: FIMA-Q通过FIM近似优化量化损失，有效解决了ViT后训练量化中的精度下降问题，尤其在低比特量化下表现优异。

中文摘要: 后训练量化（PTQ）作为一种成本效益高且前景广阔的模型压缩范式，近年来备受关注，因为它避免了计算密集型的模型重训练。然而，当前针对视觉Transformer（ViT）的PTQ方法在低比特量化时仍存在显著的精度下降问题。为解决这一问题，本文分析了流行的Hessian引导量化损失，并揭示了传统Hessian近似的局限性。基于块级重建框架，我们提出了一种名为FIMA-Q的新型PTQ方法。具体而言，我们首先建立了KL散度与FIM之间的联系，从而能够在重建过程中快速计算量化损失。进一步提出了一种高效的FIM近似方法DPLR-FIM，利用对角加低秩原理，并构建了最终的量化损失函数。我们在多个视觉任务和代表性ViT架构上的广泛实验表明，该方法在低比特量化情况下显著提升了模型精度，优于现有最先进方法。源代码已公开于https://github.com/ShiheWang/FIMA-Q。

</details>


### [138] [Leveraging Satellite Image Time Series for Accurate Extreme Event Detection](https://arxiv.org/abs/2506.11544)
**中文标题：利用卫星图像时间序列实现精确极端事件检测**

*Heng Fang,Hossein Azizpour*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SITS-Extreme的新框架，利用卫星图像时间序列检测极端事件，通过整合多时相观测数据，显著提高了检测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 气候变化导致极端天气事件频发，造成严重环境破坏和生命损失。早期检测这些事件对改善灾害响应至关重要。

研究方法: SITS-Extreme框架通过分析卫星图像时间序列，结合多时相观测数据，过滤无关变化并提取灾害相关信号，从而实现更精确的极端事件检测。

研究结果: 在真实和合成数据集上的实验表明，SITS-Extreme显著优于传统的双时相基线方法。同时，研究还探讨了更多时间步的引入、关键组件的贡献及其在不同灾害类型中的表现。

研究结论: SITS-Extreme框架在极端事件检测中表现出色，具有大规模灾害监测的潜力和适用性。

中文摘要: 气候变化导致极端天气事件增多，造成严重的环境破坏和生命损失。早期检测此类事件对改善灾害响应至关重要。本文提出了一种名为SITS-Extreme的新框架，通过整合多时相卫星图像观测数据来检测极端事件。该方法能有效过滤无关变化，提取灾害相关信号，从而实现更精确的检测。在真实和合成数据集上的大量实验验证了SITS-Extreme的有效性，其表现显著优于广泛使用的强双时相基线方法。此外，我们还研究了引入更多时间步的影响，分析了框架中关键组件的贡献，并评估了其在不同灾害类型中的性能，为其在大规模灾害监测中的可扩展性和适用性提供了宝贵见解。

</details>


### [139] [Linearly Solving Robust Rotation Estimation](https://arxiv.org/abs/2506.11547)
**中文标题：线性求解鲁棒的旋转估计**

*Yinlong Liu,Tianyu Huang,Zhi-Xin Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种线性方法解决鲁棒的旋转估计问题，通过将旋转估计重新表述为线性模型拟合问题，并利用四元数球面上的大圆表示旋转运动，提出了一种易于理解的投票方法。该方法对噪声和异常值具有极强的鲁棒性，并能通过GPU并行计算高效处理大规模问题。


<details>
  <summary>详细信息</summary>
研究动机: 旋转估计在计算机视觉和机器人任务中至关重要，尤其是在安全关键应用中需要极高的鲁棒性。传统方法通常将其视为非线性非凸优化问题，设计复杂。本文旨在提供一种新的视角，将旋转估计问题转化为线性模型拟合问题，简化求解过程并提高鲁棒性。

研究方法: 本文提出了一种基于投票的方法，通过揭示旋转运动在四元数球面上的大圆表示，将旋转估计问题转化为线性模型拟合。该方法无需丢弃任何约束或引入奇异性，且能够利用GPU实现高效并行计算。

研究结果: 实验表明，该方法对噪声和异常值具有极强的鲁棒性，能够在0.5秒内处理大规模（10^6）且异常值比例高达99%的旋转估计问题。在控制实验和真实数据集实验中均验证了其有效性和优越性。

研究结论: 本文提出的线性方法不仅简化了旋转估计问题的求解，还显著提高了鲁棒性和计算效率，为安全关键应用提供了可靠解决方案。

中文摘要: 旋转估计在计算机视觉和机器人任务中扮演着基础性角色，而极度鲁棒的旋转估计对安全关键应用尤为重要。传统上，旋转估计被视为非线性非凸优化问题，需要精心设计。然而，本文提出了一种新视角，将旋转估计问题重新表述为线性模型拟合问题，无需丢弃任何约束或引入奇异性。此外，我们探索了旋转运动的对偶结构，发现其可以表示为四元数球面上的大圆。基于此，我们提出了一种易于理解的投票方法来解决旋转估计问题。该方法对噪声和异常值表现出极强的鲁棒性，并能轻松通过图形处理器（GPU）并行计算。特别是借助GPU的强大能力，该方法能在0.5秒内为大规模（10^6）且异常值比例极高（99%）的旋转估计问题提供满意的解。此外，为验证理论框架并展示方法的优越性，我们进行了控制实验和真实数据集实验。这些实验提供了有力证据，支持我们的方法在解决旋转估计问题中的有效性和鲁棒性。

</details>


### [140] [EyeSim-VQA: A Free-Energy-Guided Eye Simulation Framework for Video Quality Assessment](https://arxiv.org/abs/2506.11549)
**中文标题：EyeSim-VQA：一种基于自由能引导的眼动模拟框架用于视频质量评估**

*Zhaoyang Wang,Wen Lu,Jie Li,Lihuo He,Maoguo Gong,Xinbo Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为EyeSim-VQA的新型视频质量评估框架，结合自由能引导的自修复机制，通过双分支架构和生物启发设计，在多个公开基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 自由能引导的自修复机制在图像质量评估中表现良好，但在视频质量评估中因时空动态性和模型限制而未被充分探索。视频内容的复杂性更高，且现有VQA系统依赖预训练主干网络，限制了增强模块的直接集成。

研究方法: EyeSim-VQA采用双分支架构：美学分支用于全局感知评估，技术分支用于细粒度结构和语义分析。每个分支集成针对不同视觉输入（全帧图像和基于块的片段）的增强模块，并设计了生物启发的预测头以融合全局和局部表征。

研究结果: 在五个公开VQA基准测试中，EyeSim-VQA表现优于或与现有最优方法相当，同时通过生物启发设计提高了可解释性。

研究结论: EyeSim-VQA通过自由能引导的自修复和生物启发设计，有效解决了视频质量评估中的挑战，为未来研究提供了新方向。

中文摘要: 自由能引导的自修复机制在图像质量评估（IQA）中表现出色，但在视频质量评估（VQA）中仍未被充分探索，因为视频的时空动态性和模型限制带来了独特挑战。与静态图像不同，视频内容具有更丰富的时空复杂性，使得感知修复更加困难。此外，VQA系统通常依赖预训练主干网络，这限制了增强模块的直接集成而不影响模型稳定性。为解决这些问题，我们提出了EyeSim-VQA，一种结合自由能自修复的新型VQA框架。它采用双分支架构，美学分支用于全局感知评估，技术分支用于细粒度结构和语义分析。每个分支集成了针对不同视觉输入（调整大小的全帧图像和基于块的片段）的专用增强模块，以模拟自适应修复行为。我们还探索了一种在不破坏原始主干网络的情况下整合高级视觉特征的策略。此外，我们设计了一个生物启发的预测头，模拟扫视动态以更好地融合全局和局部表征进行质量预测。在五个公开VQA基准测试上的实验表明，EyeSim-VQA的性能优于或与现有最优方法相当，同时通过其生物启发设计提高了可解释性。

</details>


### [141] [DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs](https://arxiv.org/abs/2506.11558)
**中文标题：DaMO：一种数据高效的多模态协调器，用于视频LLMs的时间推理**

*Bo-Cheng Chiu,Jen-Jee Chen,Yu-Chee Tseng,Feng-Chi Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DaMO的数据高效多模态协调器，专为视频LLMs的精细时间推理设计。通过分层双流架构和全局残差技术，DaMO在时间对齐和多模态理解任务中表现优异，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频LLMs在精细时间推理方面存在局限，尤其是在监督有限的情况下难以准确关联视频片段与响应。DaMO旨在解决这一问题，提升视频语言模型的时间推理能力。

研究方法: DaMO采用分层双流架构（Temporal-aware Fuseformer）逐步捕捉模态内时间动态，并融合视觉与音频信息。通过全局残差减少空间冗余，同时保留语义细节。模型通过四阶段渐进训练范式，逐步提升多模态对齐、语义基础和时序推理能力。

研究结果: 在时间定位和视频问答任务中，DaMO显著优于现有方法，尤其在需要精确时间对齐和推理的任务中表现突出。

研究结论: DaMO为数据高效的视频语言建模提供了新方向，展示了其在时间推理和多模态理解任务中的潜力。

中文摘要: 大型语言模型（LLMs）最近已扩展至视频领域，实现了复杂的视频语言理解。然而，现有视频LLMs在精细时间推理方面存在局限，尤其是在监督有限的情况下难以准确关联视频片段与响应。我们提出了DaMO，一种专为精确时间推理和多模态理解设计的数据高效视频LLM。其核心是提出的Temporal-aware Fuseformer，采用分层双流架构逐步捕捉模态内时间动态，并有效融合视觉与音频信息。为提升计算效率，DaMO集成了全局残差技术，减少空间冗余的同时保留关键语义细节。通过四阶段渐进训练范式，逐步赋予模型多模态对齐、语义基础和时序推理能力。本研究还贡献了多个数据集，通过GPT生成的时间标注问答对扩展现有数据，以支持需要时间监督的任务。在时间定位和视频问答基准测试中，DaMO始终优于现有方法，尤其在需要精确时间对齐和推理的任务中表现突出。我们的工作为数据高效的视频语言建模奠定了有前景的方向。

</details>


### [142] [VFaith: Do Large Multimodal Models Really Reason on Seen Images Rather than Previous Memories?](https://arxiv.org/abs/2506.11571)
**中文标题：VFaith：多模态大模型真的基于所见图像而非记忆进行推理吗？**

*Jiachen Yu,Yufei Zhan,Ziheng Wu,Yousong Zhu,Jinqiao Wang,Minghui Qiu*

主要分类: cs.CV

摘要简述: 本文提出了一种评估多模态大模型（MLLMs）视觉推理忠实性的方法，通过自动编辑视觉线索构建VFaith-Bench基准，揭示了模型推理能力与视觉感知的关系。


<details>
  <summary>详细信息</summary>
研究动机: 尽管长链思维（CoT）能提升多模态大模型的复杂问题解决能力，但其有效性原因尚不明确。本文旨在量化分析模型推理过程中视觉线索提取的作用，并评估其对视觉信息的忠实性。

研究方法: 1. 提出基于GPT-Image-1的自动可控编辑流程，精准修改视觉线索；2. 构建VFaith-Bench基准，包含755个条目和人类标注的感知任务，通过对比编辑前后的图像和问题对，测试模型的视觉推理能力。

研究结果: 实验发现，主流模型的视觉推理能力与视觉感知密切相关，但部分模型依赖记忆而非实时视觉信息。VFaith-Bench有效揭示了这一现象。

研究结论: VFaith-Bench为评估多模态大模型的视觉推理忠实性提供了新工具，揭示了模型推理能力的来源，为未来研究提供了重要参考。

中文摘要: 近期研究表明，通过引入长链思维（CoT），多模态大模型（MLLMs）解决复杂问题的能力显著提升，但其有效性原因尚不明确。量化分析模型在推理过程中对视觉线索的提取及其贡献具有挑战性。因此，评估MLLMs对视觉信息的推理忠实性至关重要。为此，我们首先提出了一种基于GPT-Image-1的线索驱动自动可控编辑流程，能够根据指令精准修改特定视觉线索。此外，我们引入了VFaith-Bench，首个专注于视觉忠实性的MLLMs视觉推理能力评估基准。通过设计的流程，我们构建了对比性问题-答案对，通过修改图像中关键视觉线索以改变问题答案。测试相似问题但不同细节的图像时，平均准确率反映模型的视觉推理能力，而编辑前后准确率差异揭示了模型推理能力与视觉感知的关系。我们还设计了特定指标以量化这一关系。VFaith-Bench包含755个条目，分为五个子集，并附加一个人工标注的感知任务。我们对现有主流旗舰模型和知名开源模型系列/推理模型进行了深入测试和分析，进一步探究了其推理能力的潜在因素。

</details>


### [143] [Camera-based method for the detection of lifted truck axles using convolutional neural networks](https://arxiv.org/abs/2506.11574)
**中文标题：基于卷积神经网络的摄像头方法检测卡车抬升轴**

*Bachir Tchana Tankeu,Mohamed Bouteldja,Nicolas Grignard,Bernard Jacob*

主要分类: cs.CV

摘要简述: 本文提出了一种基于卷积神经网络（CNN）的方法，使用YOLOv8s模型检测卡车抬升轴，通过摄像头捕捉图像，实现实时检测，准确率达87%，召回率为91.7%。


<details>
  <summary>详细信息</summary>
研究动机: 当前技术如动态称重系统（WIM）在车辆分类中存在局限性，尤其是对抬升轴的检测效果不佳。本文旨在填补这一技术空白，为交通执法提供更高效的解决方案。

研究方法: 采用YOLOv8s卷积神经网络模型，通过垂直于交通方向的摄像头捕捉卡车图像，实现对抬升轴的检测。

研究结果: 模型检测精度为87%，召回率为91.7%，推理时间为1.4毫秒，适合实时应用。

研究结论: 该方法在抬升轴检测中表现优异，未来可通过扩大数据集或图像增强技术进一步提升性能。

中文摘要: 车辆识别与分类在控制-制裁系统中具有重要作用。当前技术如动态称重系统（WIM）能够分类大多数车辆类型，但对抬升轴的分类效果较差。此外，市场上极少有检测抬升轴的商业或技术方法。本文作为欧洲项目SETO（智能交通执法操作）的一部分，提出了一种基于卷积神经网络（CNN）的方法，即YOLOv8s，用于检测垂直于交通方向的摄像头拍摄的卡车图像中的抬升轴。评估结果表明，该方法精度为87%，召回率为91.7%，推理时间为1.4毫秒，适合实时应用。这些结果提示，未来可通过增加数据集规模或使用图像增强技术进一步提升性能。

</details>


### [144] [OV-MAP : Open-Vocabulary Zero-Shot 3D Instance Segmentation Map for Robots](https://arxiv.org/abs/2506.11585)
**中文标题：OV-MAP：面向机器人的开放词汇零样本3D实例分割地图**

*Juno Kim,Yesol Park,Hye-Jung Yoon,Byoung-Tak Zhang*

主要分类: cs.CV

摘要简述: OV-MAP是一种新型开放词汇零样本3D实例分割方法，通过将开放特征整合到3D地图中提升机器人对象识别能力，解决了相邻体素特征重叠导致的精度下降问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D地图在开放世界中对象识别能力有限，尤其是相邻体素特征重叠会降低实例级精度，因此需要一种无需依赖3D监督分割模型的方法。

研究方法: 采用类别无关的分割模型将2D掩模投影到3D空间，结合原始和合成深度图像，并通过3D掩模投票机制实现零样本3D实例分割。

研究结果: 在ScanNet200和Replica等公开数据集上验证了方法的零样本性能、鲁棒性和适应性，并在真实环境中展示了其实际应用效果。

研究结论: OV-MAP在无需3D监督分割模型的情况下，实现了高精度的零样本3D实例分割，适用于多样化的真实环境。

中文摘要: 我们提出了OV-MAP，一种面向移动机器人的开放世界3D地图构建新方法，通过将开放特征整合到3D地图中以增强对象识别能力。当相邻体素的特征重叠导致实例级精度下降时，特征会溢出体素边界，使相邻区域混合。我们的方法通过使用类别无关的分割模型将2D掩模投影到3D空间，并结合原始点云和合成深度图像生成的补充深度图像，克服了这一挑战。此外，通过3D掩模投票机制，实现了无需依赖3D监督分割模型的精确零样本3D实例分割。我们在ScanNet200和Replica等公开数据集上进行了全面实验，验证了方法的零样本性能、鲁棒性和适应性。同时，通过真实环境实验展示了该方法在多样化实际场景中的适应性和鲁棒性。

</details>


### [145] [EasyARC: Evaluating Vision Language Models on True Visual Reasoning](https://arxiv.org/abs/2506.11595)
**中文标题：EasyARC：评估视觉语言模型的真实视觉推理能力**

*Mert Unsal,Aylin Akkus*

主要分类: cs.CV

摘要简述: 本文提出EasyARC，一个评估视觉语言模型真实视觉推理能力的基准测试，支持多图像、多步骤推理和自我修正，为强化学习提供理想测试环境。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态基准测试主要关注视觉提取与文本推理的结合，缺乏对视觉与语言复杂交互的真实推理能力评估。受ARC挑战启发，作者旨在填补这一空白。

研究方法: 通过程序化生成可验证且可扩展的EasyARC基准测试，包含渐进难度级别，支持多图像、多步骤推理和自我修正，并用于评估先进视觉语言模型。

研究结果: 实验表明，EasyARC能有效评估模型的真实推理能力，并揭示其失败模式，为视觉语言模型的性能提升提供新标准。

研究结论: EasyARC为视觉语言模型的真实推理能力和测试时扩展能力设定了新标准，作者开源了数据集和评估代码。

中文摘要: 基于语言推理模型的最新进展，我们探索了结合视觉与文本的多模态推理。现有多模态基准测试主要测试视觉提取与文本推理的结合，缺乏对视觉与语言复杂交互的真实推理评估。受ARC挑战启发，我们提出EasyARC，一个需要多图像、多步骤推理和自我修正的视觉语言基准测试。EasyARC通过程序化生成，完全可验证且可扩展，是强化学习（RL）流程的理想选择。生成器包含渐进难度级别，支持对任务类型和复杂度的结构化评估。我们评估了先进视觉语言模型并分析其失败模式。我们认为EasyARC为评估视觉语言模型的真实推理能力和测试时扩展能力设定了新标准。我们开源了基准数据集和评估代码。

</details>


### [146] [A$^2$LC: Active and Automated Label Correction for Semantic Segmentation](https://arxiv.org/abs/2506.11599)
**中文标题：A²LC：语义分割的主动与自动标签校正**

*Youjin Jeon,Kyusik Cho,Suhan Woo,Euntai Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为A²LC的高效主动和自动标签校正框架，用于语义分割任务，通过整合自动校正阶段和自适应平衡获取函数，显著提升了标签校正的效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 语义分割中的像素级标注成本高且易出错，现有的主动标签校正方法效率仍有不足。本文旨在通过自动化校正和关注尾部类别，提升校正效率和模型性能。

研究方法: A²LC框架在传统主动标签校正流程中加入了自动校正阶段，利用标注者反馈扩展校正范围，并引入自适应平衡获取函数以优化尾部类别的标注。

研究结果: 在Cityscapes和PASCAL VOC 2012数据集上，A²LC仅用20%的预算即超越现有方法，并在相同预算下性能提升27.23%。

研究结论: A²LC通过自动化校正和自适应平衡机制，显著提升了标签校正的效率和语义分割的性能，为高成本标注任务提供了高效解决方案。

中文摘要: 主动标签校正（ALC）通过选择性识别和修正错误标注数据，成为解决语义分割中手动像素级标注高成本和易出错问题的有效方法。尽管近期研究通过基础模型生成伪标签提升了校正效率，但仍存在显著不足。本文提出了一种新颖高效的ALC框架——主动与自动标签校正（A²LC），将自动校正阶段整合到传统流程中。具体而言，自动校正阶段利用标注者反馈对超出查询样本的数据进行标签校正，从而最大化成本效率。此外，我们还引入了一种自适应平衡获取函数，强调尾部类别以补充自动校正机制。在Cityscapes和PASCAL VOC 2012上的大量实验表明，A²LC显著优于现有方法。值得注意的是，A²LC仅用20%的预算即超越先前方法，并在相同预算下在Cityscapes数据集上实现了27.23%的性能提升。代码将在论文接受后发布。

</details>


### [147] [Wi-CBR: WiFi-based Cross-domain Behavior Recognition via Multimodal Collaborative Awareness](https://arxiv.org/abs/2506.11616)
**中文标题：Wi-CBR：基于WiFi的多模态协作感知跨域行为识别**

*Ruobei Zhang,Shengeng Tang,Huan Yan,Xiang Zhang,Richang Hong*

主要分类: cs.CV

摘要简述: 本文提出了一种基于WiFi的多模态协作感知方法（Wi-CBR），通过融合相位和多普勒频移数据提升行为识别精度，实验证明其在跨域任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有WiFi行为识别方法通常仅关注单一数据类型，忽略了多特征交互与融合的潜力。本文旨在通过多模态协作感知解决这一问题，提升识别准确率。

研究方法: 1. 引入双分支自注意力模块捕捉单模态时空特征；2. 对相位和多普勒频移数据应用分组注意力机制提取关键特征；3. 通过门控机制优化信息熵，实现跨模态协作感知。

研究结果: 在Widar3.0和XRF55数据集上的实验表明，该方法在域内和跨域任务中均表现优异，显著提升了行为识别精度。

研究结论: Wi-CBR通过多模态特征融合与协作感知，有效解决了现有方法的局限性，为WiFi行为识别提供了新思路。

中文摘要: 基于WiFi的人类行为识别旨在通过分析无线信号变化识别手势和活动。然而，现有方法通常仅关注单一数据类型，忽视了多特征的交互与融合。为此，我们提出了一种新型多模态协作感知方法。通过利用反映动态路径长度变化的相位数据和与手势移动速度相关的多普勒频移（DFS）数据，实现这些特征的高效交互与融合，以提升识别精度。具体而言，我们首先引入双分支自注意力模块捕捉各模态内的时空线索；随后，对拼接的相位和DFS特征应用分组注意力机制，挖掘对行为识别至关重要的关键组特征；最后，通过门控机制将组合特征进一步分为PD增强和PD减弱分支，优化信息熵并促进跨模态协作感知。在Widar3.0和XRF55两个大型公开数据集上的广泛域内及跨域实验验证了本方法的优越性能。

</details>


### [148] [SignAligner: Harmonizing Complementary Pose Modalities for Coherent Sign Language Generation](https://arxiv.org/abs/2506.11621)
**中文标题：SignAligner：协调互补姿态模态以实现连贯手语生成**

*Xu Wang,Shengeng Tang,Lechao Cheng,Feng Li,Shuo Wang,Richang Hong*

主要分类: cs.CV

摘要简述: 本文提出SignAligner方法，通过多模态协同生成与修正，实现更自然的手语生成，并在PHOENIX14T+数据集上验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 手语生成面临复杂手势、表情和身体动作的挑战，现有方法难以实现自然且多样化的生成效果。本文旨在通过多模态协同生成与修正，提升手语生成的准确性和表现力。

研究方法: SignAligner分为三个阶段：1) 基于文本语义的多模态协同生成；2) 在线协作修正，通过动态损失权重和跨模态注意力消除冲突；3) 将修正后的姿态输入预训练视频生成网络，合成高质量手语视频。

研究结果: 实验表明，SignAligner显著提升了生成手语视频的准确性和表现力，实现了更自然和一致的手语生成效果。

研究结论: SignAligner通过多模态协同生成与修正，解决了手语生成中的复杂性问题，为自然手语视频生成提供了有效方法。

中文摘要: 手语生成旨在基于口语生成多样化的手语表示，但由于手语的复杂性（包括复杂手势、面部表情和身体动作），实现自然生成仍具挑战性。本文扩展了广泛使用的RWTH-PHOENIX-Weather 2014T数据集，推出PHOENIX14T+，新增三种手语表示：Pose、Hamer和Smplerx。同时提出SignAligner方法，分为三个阶段：文本驱动的多模态协同生成、在线协作修正和真实手语视频合成。首先，结合文本语义设计联合生成器，同步生成姿态坐标、手势动作和身体动作；其次，通过动态损失权重和跨模态注意力修正生成结果，确保模态互补和语义一致；最后，将修正后的姿态输入预训练视频生成网络，生成高保真手语视频。实验证明，SignAligner显著提升了生成视频的准确性和表现力。

</details>


### [149] [Evaluating Fairness and Mitigating Bias in Machine Learning: A Novel Technique using Tensor Data and Bayesian Regression](https://arxiv.org/abs/2506.11627)
**中文标题：评估机器学习公平性及减少偏见：一种基于张量数据和贝叶斯回归的新技术**

*Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker,Yiannis Papadopoulos*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的机器学习公平性评估技术，专注于处理肤色这一张量数据，通过概率分布和统计距离度量，避免传统分类的局限性，并结合贝叶斯回归方法减少潜在偏见。


<details>
  <summary>详细信息</summary>
研究动机: 肤色作为敏感属性在计算机视觉中以张量形式呈现，而现有公平性研究多关注分类特征（如性别和种族）。本文旨在填补这一空白，提出一种无需标注的方法来评估肤色相关的公平性。

研究方法: 将肤色张量数据转换为概率分布，利用统计距离度量公平性；提出基于贝叶斯回归和多项式函数的训练方法，减少传统肤色分类中的潜在偏见。

研究结果: 该方法能够捕捉肤色公平性的细微差异，并在传统分类之外实现更公平的模型处理。

研究结论: 本文提出的技术为机器学习中肤色公平性评估提供了新思路，通过概率分布和贝叶斯回归显著减少了模型偏见。

中文摘要: 公平性是可信人工智能的关键组成部分。本文聚焦机器学习（ML）在处理肤色时的模型预测性能。与其他敏感属性不同，肤色在计算机视觉中以张量数据而非分类值或单一数值点表示。然而，现有公平性研究多关注性别和种族等分类特征。本文提出了一种无需标注的新技术，用于评估图像分类任务中的公平性。为解决先前研究的局限性，我们直接处理肤色等张量数据，避免刚性分类，将其转换为概率分布并应用统计距离度量。这一创新方法能够捕捉传统分类群体内外的公平性细微差异。此外，我们提出了一种创新的训练方法，通过贝叶斯回归和多项式函数计算颜色距离估计，减少传统肤色分类中的潜在偏见，确保ML模型对肤色的处理更加细致和公平。

</details>


### [150] [DISCO: Mitigating Bias in Deep Learning with Conditional Distance Correlation](https://arxiv.org/abs/2506.11653)
**中文标题：DISCO：通过条件距离相关性缓解深度学习中的偏见**

*Emre Kavak,Tom Nuno Wolf,Christian Wachinger*

主要分类: cs.CV

摘要简述: 论文提出了一种名为DISCO的新方法，通过条件距离相关性来减少深度学习中的偏见，确保模型仅依赖因果相关的信号进行预测。


<details>
  <summary>详细信息</summary>
研究动机: 在预测任务中，模型可能利用与目标无关的信号（如光照条件）作为捷径，导致偏见。为了解决这一问题，研究旨在设计一种方法，使模型仅关注因果相关的信息路径。

研究方法: 论文提出了一种标准反因果预测模型（SAM），用于分析预测器在反因果设置中的信息路径。通过满足特定条件独立性准则，分类器仅关注从标签到图像的因果路径。此外，提出了DISCO正则化策略，利用条件距离相关性优化回归任务中的条件独立性。

研究结果: 实验表明，DISCO在不同偏见缓解任务中表现优异，成为传统基于核方法的有效替代方案。

研究结论: DISCO通过条件距离相关性有效减少了深度学习中的偏见，为模型提供了更可靠的预测能力。

中文摘要: 在预测任务中，模型可能利用接收到的任何信号（包括因果无关的信号）来得出最终答案。例如，在从图像预测物体时，光照条件可能通过选择偏见与不同目标相关，而无知的模型可能利用这些信号作为区分不同物体的捷径。显然，依赖光照条件而非物体具体细节的预测器是不可取的。为解决这一问题，我们引入了一种标准反因果预测模型（SAM），用于分析预测器在反因果设置中受信息路径影响的因果框架。我们证明，满足特定条件独立性准则的分类器将仅关注从标签到图像的因果路径，并对其他变量保持反事实不变性。最后，我们提出了DISCO，一种利用条件距离相关性优化回归任务中条件独立性的新型正则化策略。实验表明，DISCO在不同偏见缓解任务中取得了竞争性结果，成为传统基于核方法的有效替代方案。

</details>


### [151] [Prohibited Items Segmentation via Occlusion-aware Bilayer Modeling](https://arxiv.org/abs/2506.11661)
**中文标题：基于遮挡感知双层建模的违禁物品分割**

*Yunhan Ren,Ruihuang Li,Lingbo Liu,Changwen Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于遮挡感知的双层建模方法，用于解决X射线安检图像中违禁物品实例分割的难题，通过结合Segment Anything Model（SAM）和设计的遮挡感知模块，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: X射线安检图像中违禁物品的实例分割任务面临两大挑战：违禁物品与自然物体的外观差异显著，以及物体间严重重叠。本文旨在解决这些问题，提升分割准确性。

研究方法: 方法包括：1) 利用Segment Anything Model（SAM）的丰富先验和零样本泛化能力，缩小表示差距；2) 设计遮挡感知的双层掩码解码器模块，显式建模遮挡关系；3) 在PIDray和PIXray数据集上手动标注遮挡区域，构建新的数据集PIDray-A和PIXray-A。

研究结果: 实验结果表明，所提方法在遮挡标注数据集PIDray-A和PIXray-A上表现优异，验证了其有效性。

研究结论: 本文提出的遮挡感知实例分割方法有效解决了X射线图像中违禁物品分割的挑战，为安检领域提供了实用工具。

中文摘要: X射线安检图像中违禁物品的实例分割是一项关键但具有挑战性的任务，主要由于违禁物品在X射线图像中与自然物体的外观差异显著，以及物体间的严重重叠。为解决这些问题，我们提出了一种遮挡感知的实例分割流程，旨在识别X射线图像中的违禁物品。具体而言，为缩小表示差距，我们将Segment Anything Model（SAM）集成到流程中，利用其丰富的先验和零样本泛化能力。为解决违禁物品间的重叠问题，我们设计了一个遮挡感知的双层掩码解码器模块，显式建模遮挡关系。为监督遮挡估计，我们在两个大规模X射线图像分割数据集PIDray和PIXray上手动标注了违禁物品的遮挡区域，并将这些额外标注与原信息重组为两个遮挡标注数据集PIDray-A和PIXray-A。在这些遮挡标注数据集上的大量实验结果证明了所提方法的有效性。数据集和代码可在以下网址获取：https://github.com/Ryh1218/Occ。

</details>


### [152] [Dynamic Mixture of Curriculum LoRA Experts for Continual Multimodal Instruction Tuning](https://arxiv.org/abs/2506.11672)
**中文标题：动态混合课程LoRA专家用于持续多模态指令调优**

*Chendi Ge,Xin Wang,Zeyang Zhang,Hong Chen,Jiapei Fan,Longtao Huang,Hui Xue,Wenwu Zhu*

主要分类: cs.CV

摘要简述: 本文提出了一种动态混合课程LoRA专家方法（D-MoLE），用于解决多模态大语言模型（MLLMs）在持续学习中的任务架构冲突和模态不平衡问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态大语言模型（MLLMs）在持续学习中采用固定架构，难以适应新任务，且存在任务架构冲突和模态不平衡问题。本文旨在通过动态调整模型架构来解决这些问题。

研究方法: 提出D-MoLE方法，包括动态分层专家分配器和基于梯度的跨模态持续课程。前者自动分配LoRA专家以解决架构冲突，后者调整模块更新比例以缓解模态不平衡。

研究结果: 实验表明，D-MoLE显著优于现有基线方法，平均性能提升15%，是首个从架构角度研究MLLMs持续学习的工作。

研究结论: D-MoLE通过动态调整架构和优化模态更新比例，有效解决了MLLMs持续学习中的关键问题，为未来研究提供了新方向。

中文摘要: 持续多模态指令调优对于适应多模态大语言模型（MLLMs）的演化任务至关重要。然而，现有方法多采用固定架构，因静态模型容量难以适应新任务。本文提出在参数预算下动态调整架构以适应任务，这一方向尚未探索且面临两大挑战：1）任务架构冲突，即不同任务需要不同的分层适配；2）模态不平衡，即不同任务对模态的依赖不均导致更新不平衡。为解决这些问题，我们提出了一种新颖的动态混合课程LoRA专家（D-MoLE）方法，该方法在参数预算内自动演化MLLM架构以持续适应新任务，同时保留已学知识。具体而言，我们提出动态分层专家分配器，自动分配LoRA专家以解决架构冲突，并通过分层路由指令促进专家间知识共享。此外，我们提出基于梯度的跨模态持续课程，根据任务中每个模态的难度调整MLLM模块的更新比例，以缓解模态不平衡问题。大量实验表明，D-MoLE显著优于现有基线方法，平均性能提升15%。据我们所知，这是首个从架构角度研究MLLMs持续学习的工作。

</details>


### [153] [Cross-Modal Clustering-Guided Negative Sampling for Self-Supervised Joint Learning from Medical Images and Reports](https://arxiv.org/abs/2506.11674)
**中文标题：跨模态聚类引导的负采样用于医学图像与报告的自监督联合学习**

*Libin Lan,Hongxing Li,Zunhui Xia,Juan Zhou,Xiaofei Zhu,Yongmei Li,Yudong Zhang,Xin Luo*

主要分类: cs.CV

摘要简述: 本文提出了一种跨模态聚类引导的负采样方法（CM-CGNS），通过改进负样本选择和引入跨模态掩码图像重建模块，解决了现有医学图像与报告自监督学习中的关键问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有医学图像与报告的自监督学习方法存在三个主要问题：负样本选择不当、忽视细粒度局部细节以及忽略低层次特征。这些问题影响了模型的性能和准确性。

研究方法: 1. 提出跨模态聚类引导的负采样（CM-CGNS），通过跨模态注意力将k均值聚类扩展到多模态领域，增加负样本数量并提升模型表示能力。2. 引入跨模态掩码图像重建（CM-MIR）模块，利用跨模态注意力获取的局部文本-图像特征重建掩码图像区域，增强跨模态信息交互并保留低层次特征。

研究结果: 在五个下游数据集的分类、检测和分割任务中，CM-CGNS方法在多项指标上优于现有最优方法，验证了其卓越性能。

研究结论: CM-CGNS通过改进负样本选择和跨模态信息交互，能够学习到适用于多种医学图像识别任务的有效且鲁棒的视觉表示。

中文摘要: 近年来，通过多模态自监督学习直接从配对的医学图像和报告中学习视觉表示，已成为数字诊断的一种新颖且高效的方法。然而，现有模型存在几个严重缺陷：1）忽视负样本的选择，导致硬负样本稀缺和假负样本的引入；2）专注于全局特征提取，但忽略了医学图像识别任务中至关重要的细粒度局部细节；3）对比学习主要针对高层次特征，但忽略了低层次细节，而这些细节对准确的医学分析至关重要。受这些关键问题的启发，本文提出了一种跨模态聚类引导的负采样（CM-CGNS）方法，其核心思想包括两点。首先，通过跨模态注意力将单模态领域中用于局部文本特征的k均值聚类扩展到多模态领域，从而增加负样本数量并提升模型表示能力。其次，引入跨模态掩码图像重建（CM-MIR）模块，利用跨模态注意力获取的局部文本-图像特征重建掩码的局部图像区域。该模块显著增强了模型的跨模态信息交互能力，并保留了低层次图像特征，这些特征对下游任务至关重要。通过有效解决上述问题，所提出的CM-CGNS能够学习适用于多种识别任务的有效且鲁棒的医学视觉表示。在五个下游数据集的分类、检测和分割任务上的大量实验结果表明，我们的方法在多项指标上优于现有最优方法，验证了其卓越性能。

</details>


### [154] [Predicting Patient Survival with Airway Biomarkers using nn-Unet/Radiomics](https://arxiv.org/abs/2506.11677)
**中文标题：基于nn-Unet/放射组学的气道生物标志物预测患者生存率**

*Zacharia Mesbah,Dhruv Jain,Tsiry Mayet,Romain Modzelewski,Romain Herault,Simon Bernard,Sebastien Thureau,Clement Chatelain*

主要分类: cs.CV

摘要简述: 本研究通过nn-Unet分割气道结构，结合放射组学特征和SVM分类器，预测肺纤维化患者的生存率，任务1分割得分为0.8601，任务2分类得分为0.7346。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估气道相关影像生物标志物对肺纤维化患者生存结果的预测价值，探索气道结构和气管区域的关键特征对生存分析的重要性。

研究方法: 采用三阶段方法：1) 使用nn-Unet分割气道结构；2) 从气管区域和气道包围盒提取放射组学特征；3) 将特征输入SVM分类器进行生存预测。

研究结果: 任务1的气道分割得分为0.8601，任务2的生存分类得分为0.7346，表明方法在分割和分类任务中均表现良好。

研究结论: 气道影像生物标志物对肺纤维化患者生存预测具有显著意义，结合nn-Unet和放射组学的方法有效提升了预测性能。

中文摘要: AIIB 2023竞赛的主要目标是评估气道相关影像生物标志物对肺纤维化患者生存结果的预测意义。本研究提出了一种综合三阶段方法：首先使用nn-Unet分割气道结构边界；随后从气管区域及气道包围盒中提取放射组学特征，这一步骤基于气管区域可能包含关键生存信息以及气道结构和尺寸编码的相关信息；最后将分割区域的放射组学特征输入SVM分类器。任务1的分割得分为0.8601，任务2的分类得分为0.7346。

</details>


### [155] [Pose Matters: Evaluating Vision Transformers and CNNs for Human Action Recognition on Small COCO Subsets](https://arxiv.org/abs/2506.11678)
**中文标题：姿态的重要性：在小规模COCO子集上评估视觉变换器与卷积网络的人类动作识别性能**

*MingZe Tang,Madiha Kazi*

主要分类: cs.CV

摘要简述: 本研究通过COCO图像库的三类子集评估了不同模型在人类动作识别中的表现，发现二元视觉变换器（ViT）表现最佳，准确率达90%，显著优于卷积网络和CLIP模型。


<details>
  <summary>详细信息</summary>
研究动机: 探索人类动作识别中不同模型的性能差异，特别是视觉变换器（ViT）与传统卷积网络（CNN）的对比，以及模型对姿态特征的关注程度。

研究方法: 使用COCO图像库的三类子集，对比了全连接网络、卷积网络、CLIP模型和视觉变换器（ViT）的性能，并通过SHAP解释器和LeGrad热力图进行定性分析。

研究结果: ViT的测试准确率高达90%，显著优于卷积网络（约35%）和CLIP模型（约62-64%）。定性分析显示ViT更关注姿态相关区域，而其他模型易受背景干扰。

研究结论: 视觉变换器（ViT）在数据效率和姿态特征捕捉方面表现优异，解释性技术有助于诊断模型失败原因。

中文摘要: 本研究通过COCO图像库的三类子集探索人类动作识别，从简单的全连接网络到变换器架构的模型进行了基准测试。二元视觉变换器（ViT）的平均测试准确率达到90%，显著优于多类分类器如卷积网络（约35%）和基于CLIP的模型（约62-64%）。单因素方差分析（F = 61.37，p < 0.001）证实这些差异具有统计学意义。通过SHAP解释器和LeGrad热力图的定性分析表明，ViT能够定位姿态特定区域（如下肢用于行走或跑步），而简单的前馈模型往往关注背景纹理，解释了其错误。这些发现强调了变换器表示的数据效率以及可解释性技术在诊断类别特定失败中的重要性。

</details>


### [156] [MTabVQA: Evaluating Multi-Tabular Reasoning of Language Models in Visual Space](https://arxiv.org/abs/2506.11684)
**中文标题：MTabVQA：评估语言模型在视觉空间中的多表格推理能力**

*Anshul Singh,Chris Biemann,Jan Strich*

主要分类: cs.CV

摘要简述: 本文介绍了MTabVQA，一个专为多表格视觉问答设计的新基准测试，旨在评估语言模型在视觉空间中对多表格数据的推理能力。实验表明，现有视觉语言模型在此任务上表现有限，但通过微调可显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型在单表格或非视觉数据上表现良好，但在多表格视觉数据的解析和跨表格推理方面存在不足。MTabVQA旨在填补这一空白，评估模型在多表格视觉问答中的能力。

研究方法: MTabVQA包含3,745个复杂问答对，需要跨多个视觉化表格进行多跳推理。作者还发布了MTabVQA-Instruct，一个大规模指令调优数据集，用于微调视觉语言模型。

研究结果: 实验显示，现有视觉语言模型在MTabVQA上表现不佳，但通过MTabVQA-Instruct微调后，其多表格视觉推理能力显著提升。

研究结论: MTabVQA为多表格视觉问答提供了首个基准测试，揭示了现有模型的局限性，并通过微调方法展示了改进潜力。

中文摘要: 视觉语言模型（VLMs）在解释视觉布局和文本方面表现出色，但在处理多表格视觉数据（如图像中的表格）时仍面临挑战。现有基准测试通常针对单表格或非视觉数据，未能评估模型在解析多样化表格图像、跨表格关联信息以及多跳推理方面的能力。为此，我们提出了MTabVQA，一个专为多表格视觉问答设计的新基准测试。MTabVQA包含3,745个复杂问答对，需要跨多个视觉化表格进行多跳推理。我们对当前最先进的视觉语言模型进行了广泛测试，结果显示其性能存在显著局限。此外，我们研究了后训练技术以增强这些推理能力，并发布了MTabVQA-Instruct，一个大规模指令调优数据集。实验表明，通过MTabVQA-Instruct微调视觉语言模型，其多表格视觉推理能力得到显著提升。代码和数据集（https://huggingface.co/datasets/mtabvqa/MTabVQA-Eval）已在线发布（https://anonymous.4open.science/r/MTabVQA-EMNLP-B16E）。

</details>


### [157] [DMAF-Net: An Effective Modality Rebalancing Framework for Incomplete Multi-Modal Medical Image Segmentation](https://arxiv.org/abs/2506.11691)
**中文标题：DMAF-Net：一种有效的模态再平衡框架用于不完整多模态医学图像分割**

*Libin Lan,Hongxing Li,Zunhui Xia,Yudong Zhang*

主要分类: cs.CV

摘要简述: DMAF-Net提出了一种动态模态感知融合网络，通过动态平衡多模态医学图像分割中的模态缺失和贡献不均问题，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在多模态医学图像分割中假设模态完整，无法动态平衡模态贡献和缺失，导致实际临床场景中性能不佳。DMAF-Net旨在解决这一问题。

研究方法: DMAF-Net采用动态模态感知融合模块抑制缺失模态干扰，通过关系蒸馏和原型蒸馏框架实现全局-局部特征对齐，并引入动态训练监控策略优化训练过程。

研究结果: 在BraTS2020和MyoPS2020数据集上的实验表明，DMAF-Net在缺失多模态医学图像分割任务中优于现有方法。

研究结论: DMAF-Net通过动态平衡模态贡献和缺失，显著提升了多模态医学图像分割的性能，适用于实际临床场景。

中文摘要: 不完整多模态医学图像分割面临模态不平衡的关键挑战，包括模态缺失率不均和模态贡献异质性。现有方法依赖模态完整的理想假设，无法动态平衡贡献并忽略模态间结构关系，导致实际临床场景中性能不佳。为解决这些问题，我们提出了一种名为动态模态感知融合网络（DMAF-Net）的新模型。DMAF-Net采用三个关键思想：首先，引入动态模态感知融合（DMAF）模块，通过结合Transformer注意力和自适应掩码抑制缺失模态干扰，并通过注意力图动态加权模态贡献；其次，设计协同关系蒸馏和原型蒸馏框架，通过协方差一致性和掩码图注意力实现全局-局部特征对齐，同时通过跨模态类特定原型对齐确保语义一致性；第三，提出动态训练监控（DTM）策略，通过实时跟踪蒸馏差距稳定优化过程，并通过自适应重加权损失和梯度缩放平衡模态间收敛速度。在BraTS2020和MyoPS2020上的大量实验表明，DMAF-Net在不完整多模态医学图像分割任务中优于现有方法。代码发布于https://github.com/violet-42/DMAF-Net。

</details>


### [158] [Quizzard@INOVA Challenge 2025 -- Track A: Plug-and-Play Technique in Interleaved Multi-Image Model](https://arxiv.org/abs/2506.11737)
**中文标题：Quizzard@INOVA挑战赛2025——赛道A：交错多图像模型中的即插即用技术**

*Dinh Viet Cuong,Hoang-Bao Le,An Pham Ngoc Nguyen,Liting Zhou,Cathal Gurrin*

主要分类: cs.CV

摘要简述: 本文展示了LLaVA-NeXT-interleave在22个数据集上的卓越表现，涵盖多图像推理、文档与知识理解及交互式多模态通信任务，并通过添加DCI连接器对比性能，发现标准模型在视觉任务中表现最佳，而DCI增强版在语义连贯性任务中更优。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在验证LLaVA-NeXT-interleave在多任务中的性能，并探索通过DCI连接器提升模型在特定任务中的表现，以展示基础模型与即插即用技术结合的潜力。

研究方法: 使用LLaVA-NeXT-interleave模型在22个数据集上进行测试，涵盖三类任务；添加DCI连接器并与标准模型对比性能。

研究结果: 标准模型在视觉密集型任务（如VISION、NLVR2、Fashion200K）中表现最佳，而DCI增强版在需要语义连贯性或结构化变化理解的任务（如MIT-States_PropertyCoherence、SlideVQA）中更优。

研究结论: 结合强大基础模型与即插即用技术，可显著提升多任务性能，为未来研究提供新方向。

中文摘要: 本文主要实现两个目标。首先，我们展示了LLaVA-NeXT-interleave在22个数据集上的卓越表现，涵盖三类任务：多图像推理、文档与知识理解及交互式多模态通信。其次，我们为LLaVA-NeXT-interleave添加了密集通道集成（DCI）连接器，并将其性能与标准模型对比。结果显示，标准模型在视觉密集型任务（如VISION、NLVR2、Fashion200K）中表现最佳，而DCI增强版在需要更深语义连贯性或结构化变化理解的任务（如MIT-States_PropertyCoherence、SlideVQA）中更具优势。结果表明，结合强大基础模型与即插即用技术，可为交错任务带来显著潜力。代码发布于https://github.com/dinhvietcuong1996/icme25-inova。

</details>


### [159] [AgriPotential: A Novel Multi-Spectral and Multi-Temporal Remote Sensing Dataset for Agricultural Potentials](https://arxiv.org/abs/2506.11740)
**中文标题：AgriPotential：一种用于农业潜力的新型多光谱多时相遥感数据集**

*Mohammad El Sakka,Caroline De Pourtales,Lotfi Chaari,Josiane Mothe*

主要分类: cs.CV

摘要简述: 本文介绍了AgriPotential，一个基于Sentinel-2卫星影像的新型多光谱多时相遥感数据集，用于农业潜力预测，支持多种机器学习任务。


<details>
  <summary>详细信息</summary>
研究动机: 遥感技术在大规模地球监测和土地管理中至关重要，但目前缺乏专门用于农业潜力预测的公开数据集。AgriPotential旨在填补这一空白，推动可持续土地利用规划的数据驱动方法。

研究方法: AgriPotential数据集包含Sentinel-2卫星的多月影像，覆盖法国南部多样区域，提供三种主要作物类型（葡萄种植、市场园艺和大田作物）的像素级标注，分为五个有序类别。

研究结果: AgriPotential支持序数回归、多标签分类和时空建模等多种机器学习任务，为农业潜力预测提供了丰富的光谱信息。

研究结论: AgriPotential是首个专门用于农业潜力预测的公开数据集，有望推动可持续土地利用规划的研究和应用。数据集和代码已公开。

中文摘要: 遥感已成为大规模地球监测和土地管理的关键工具。本文介绍了AgriPotential，这是一个基于Sentinel-2卫星影像的新型基准数据集，涵盖多个月份的数据。该数据集为三种主要作物类型（葡萄种植、市场园艺和大田作物）提供了五个有序类别的像素级农业潜力标注。AgriPotential支持多种机器学习任务，包括序数回归、多标签分类和时空建模。数据覆盖法国南部的多样区域，提供丰富的光谱信息。AgriPotential是首个专门为农业潜力预测设计的公开数据集，旨在改进可持续土地利用规划的数据驱动方法。数据集和代码可在以下网址免费获取：https://zenodo.org/records/15556484

</details>


### [160] [DiffFuSR: Super-Resolution of all Sentinel-2 Multispectral Bands using Diffusion Models](https://arxiv.org/abs/2506.11764)
**中文标题：DiffFuSR：基于扩散模型的Sentinel-2多光谱波段超分辨率**

*Muhammad Sarmad,Arnt-Børre Salberg,Michael Kampffmeyer*

主要分类: cs.CV

摘要简述: DiffFuSR是一种模块化管道，通过扩散模型和融合网络将Sentinel-2的12个多光谱波段超分辨率统一至2.5米分辨率，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: Sentinel-2卫星的多光谱图像分辨率不一致（10米、20米、60米），限制了其应用。现有超分辨率方法难以同时处理所有波段且保持光谱一致性。DiffFuSR旨在通过生成式先验和融合策略解决这一问题。

研究方法: DiffFuSR分为两阶段：(1) 基于扩散模型的超分辨率模块，利用NAIP和WorldStrat数据集的高分辨率RGB图像训练，模拟Sentinel-2特性；(2) 融合网络，以超分辨率RGB图像为空间先验，提升其余多光谱波段分辨率。引入退化模型和对比退化编码器支持盲超分辨率。

研究结果: 在OpenSR基准测试中，DiffFuSR在反射率保真度、光谱一致性、空间对齐和伪影抑制方面优于现有方法。融合网络显著优于传统全色锐化方法，可准确提升20米和60米波段分辨率。

研究结论: DiffFuSR展示了生成式先验与融合策略的潜力，为Sentinel-2超分辨率提供了模块化框架。代码和模型已开源。

中文摘要: 本文提出DiffFuSR，一种模块化管道，用于将Sentinel-2 Level-2A图像的12个光谱波段超分辨率统一至2.5米地面采样距离（GSD）。该管道包含两个阶段：(1) 基于扩散模型的超分辨率模块，利用NAIP和WorldStrat数据集的高分辨率RGB图像训练，模拟Sentinel-2特性；(2) 融合网络，以超分辨率RGB图像为空间先验，提升其余多光谱波段分辨率。我们引入鲁棒的退化模型和对比退化编码器以支持盲超分辨率。在OpenSR基准测试中，该方法在反射率保真度、光谱一致性、空间对齐和伪影抑制方面优于现有方法。融合网络显著优于传统全色锐化方法，可准确提升Sentinel-2的20米和60米波段分辨率。本研究展示了生成式先验与融合策略的潜力，为Sentinel-2超分辨率提供了模块化框架。代码和模型已开源：https://github.com/NorskRegnesentral/DiffFuSR。

</details>


### [161] [MambaVSR: Content-Aware Scanning State Space Model for Video Super-Resolution](https://arxiv.org/abs/2506.11768)
**中文标题：MambaVSR：基于内容感知扫描状态空间模型的视频超分辨率**

*Linfeng He,Meiqin Liu,Qi Tang,Chao Yao,Yao Zhao*

主要分类: cs.CV

摘要简述: MambaVSR提出了一种基于状态空间模型的视频超分辨率框架，通过内容感知扫描机制动态建模时空依赖，显著提升了非局部依赖建模能力，并在性能和效率上超越现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 视频超分辨率（VSR）面临非局部依赖建模和对齐帧间大运动的挑战。现有方法如光流或Transformer难以兼顾长序列和大位移，因此需要一种更高效且动态的建模方法。

研究方法: MambaVSR提出内容感知扫描机制，包括共享罗盘构建（SCC）和内容感知序列化（CAS）。SCC通过稀疏注意力构建帧内语义图并生成自适应扫描序列；CAS基于SCC对齐多帧内容。全局-局部状态空间块（GLSSB）结合窗口自注意力和SSM特征传播，实现全局依赖与局部细节的协同。

研究结果: 实验表明，MambaVSR在REDS数据集上PSNR比Transformer方法高0.58 dB，且参数量减少55%。

研究结论: MambaVSR通过动态时空建模和内容感知机制，显著提升了视频超分辨率的性能与效率，为未来研究提供了新思路。

中文摘要: 视频超分辨率（VSR）在有效建模非局部依赖并保持计算效率方面面临关键挑战。现有方法通常依赖光流策略或Transformer架构，但难以处理大位移和长序列视频。为此，我们提出MambaVSR，首个基于状态空间模型的VSR框架，引入创新的内容感知扫描机制。与传统视觉Mamba方法的刚性1D序列处理不同，MambaVSR通过共享罗盘构建（SCC）和内容感知序列化（CAS）实现动态时空交互。具体而言，SCC模块通过高效稀疏注意力构建帧内语义连接图，并通过谱聚类生成自适应空间扫描序列。基于SCC，CAS模块通过沿学习到的空间顺序交错时序特征，有效对齐并聚合多帧中的非局部相似内容。为结合全局依赖与局部细节，全局-局部状态空间块（GLSSB）协同整合窗口自注意力与基于SSM的特征传播，在全局依赖指导下恢复高频细节。大量实验验证了MambaVSR的优越性，在REDS数据集上PSNR比Transformer方法高0.58 dB，且参数量减少55%。

</details>


### [162] [CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection](https://arxiv.org/abs/2506.11772)
**中文标题：CLIP与扩散模型的协同：一种异常检测的融合方法**

*Byeongchan Lee,John Won,Seunghyun Lee,Jinwoo Shin*

主要分类: cs.CV

摘要简述: 本文提出CLIPFUSION方法，结合CLIP的判别模型和扩散生成模型，通过多模态融合解决异常检测中的复杂问题，并在基准数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 异常检测因异常定义模糊、类型多样且训练数据稀缺而复杂，需一种能同时捕捉高低级特征的模型。

研究方法: CLIPFUSION结合CLIP的全局特征捕捉能力和扩散模型的局部细节生成能力，提出利用扩散模型的交叉注意力图和特征图进行异常检测。

研究结果: 在MVTec-AD和VisA数据集上，CLIPFUSION在异常分割和分类任务中均优于基线方法。

研究结论: 多模态和多模型融合能有效解决异常检测的多面挑战，为实际应用提供可扩展方案。

中文摘要: 异常检测因异常定义模糊、类型多样（如局部和全局缺陷）及训练数据稀缺而复杂，需一种能捕捉高低级特征的全面模型。为此，我们提出CLIPFUSION方法，结合判别性和生成性基础模型。具体而言，基于CLIP的判别模型擅长捕捉全局特征，而基于扩散的生成模型则有效捕捉局部细节，形成协同互补。特别地，我们提出利用扩散模型的交叉注意力图和特征图进行异常检测的方法。在基准数据集（MVTec-AD、VisA）上的实验表明，CLIPFUSION在异常分割和分类任务中均优于基线方法，表现优异。我们认为，该方法凸显了多模态和多模型融合在解决异常检测多面挑战中的有效性，为实际应用提供了可扩展方案。

</details>


### [163] [AgentSense: Virtual Sensor Data Generation Using LLM Agent in Simulated Home Environments](https://arxiv.org/abs/2506.11773)
**中文标题：AgentSense：利用LLM代理在模拟家庭环境中生成虚拟传感器数据**

*Zikang Leng,Megha Thukral,Yaqi Liu,Hrudhai Rajasekhar,Shruthi K. Hiremath,Thomas Plötz*

主要分类: cs.CV

摘要简述: AgentSense利用大型语言模型生成虚拟传感器数据，通过模拟家庭环境和多样化用户行为，解决智能家居活动识别系统数据不足的问题，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 智能家居活动识别系统因缺乏大规模、多样化的标注数据而难以泛化，家庭布局、传感器配置和用户行为的多样性进一步增加了复杂性。

研究方法: 通过大型语言模型生成多样化用户角色，模拟其日常行为并分解为低级动作序列，在扩展的VirtualHome环境中执行并记录虚拟传感器数据。

研究结果: 实验表明，结合虚拟数据和少量真实数据训练的模型性能接近完全依赖真实数据的模型，解决了数据不足的挑战。

研究结论: AgentSense展示了虚拟数据在解决智能家居活动识别数据不足问题中的潜力，无需人工采集数据即可生成大规模标注数据集。

中文摘要: 开发鲁棒且泛化能力强的智能家居活动识别系统的主要障碍是缺乏大规模、多样化的标注数据集。家庭布局、传感器配置和用户行为的多样性进一步增加了复杂性，因为每个人的日常行为方式各不相同。为了构建泛化能力强的系统，需要能够捕捉用户和环境多样性的训练数据。为此，我们提出了AgentSense，一种虚拟数据生成管道，利用大型语言模型生成多样化用户角色，模拟其日常行为并分解为低级动作序列，随后在扩展的VirtualHome环境中执行并记录虚拟传感器数据。实验表明，结合虚拟数据和少量真实数据训练的模型性能接近完全依赖真实数据的模型，解决了数据不足的挑战，证明了虚拟数据在解决智能家居活动识别数据不足问题中的潜力。

</details>


### [164] [Real-Time Feedback and Benchmark Dataset for Isometric Pose Evaluation](https://arxiv.org/abs/2506.11774)
**中文标题：等长姿势评估的实时反馈与基准数据集**

*Abhishek Jaiswal,Armeet Singh Luthra,Purav Jangir,Bhavya Garg,Nisheeth Srivastava*

主要分类: cs.CV

摘要简述: 本文提出了一种实时反馈系统，用于评估等长运动姿势，并发布了目前最大的多类别等长运动视频数据集。通过基准测试和新型三部分度量标准，系统能够提供智能化和个性化的家庭健身训练。


<details>
  <summary>详细信息</summary>
研究动机: 等长运动因其便利性和隐私性受到欢迎，但缺乏专家指导可能导致姿势错误和受伤。为了解决这一问题，作者开发了实时反馈系统，帮助用户纠正姿势。

研究方法: 作者发布了一个包含3,600多个视频片段的多类别等长运动数据集，涵盖六种姿势的正确和错误变体。同时，基于图网络的先进模型被用于基准测试，并提出了一种新的三部分度量标准，包括分类准确性、错误定位和模型置信度。

研究结果: 实验结果表明，该系统能够有效评估等长运动姿势，并通过实时反馈提升家庭健身的可行性和安全性。

研究结论: 该系统不仅适用于家庭健身，还可扩展至康复和物理治疗等领域，为用户提供专家级的诊断和指导。

中文摘要: 等长运动因其便利性、隐私性和对设备依赖少的特点受到欢迎。然而，此类训练通常过度依赖不可靠的数字媒体内容而非专家指导，导致姿势错误、受伤和因缺乏纠正反馈而放弃等问题。为解决这些挑战，我们提出了一种用于评估等长姿势的实时反馈系统。我们的贡献包括发布了迄今为止最大的多类别等长运动视频数据集，包含六种姿势的正确和错误变体，共计3,600多个视频片段。为支持稳健评估，我们在该数据集上对包括基于图的网络在内的先进模型进行了基准测试，并引入了一种新的三部分度量标准，涵盖分类准确性、错误定位和模型置信度。我们的研究结果提升了智能化和个性化家庭健身训练系统的可行性。这种直接面向用户的专家级诊断，还扩展了这些系统在康复、物理治疗及其他涉及身体运动的健身领域的潜在应用。

</details>


### [165] [Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation](https://arxiv.org/abs/2506.11777)
**中文标题：基于在线聚类蒸馏的心脏超声视频自监督表征学习**

*Divyanshu Mishra,Mohammadreza Salehi,Pramit Saha,Olga Patey,Aris T. Papageorghiou,Yuki M. Asano,J. Alison Noble*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DISCOVR的自监督学习框架，通过在线聚类蒸馏技术学习心脏超声视频的表征，解决了现有方法在超声图像中高相似性和低信噪比下的挑战，并在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 心脏超声视频的自监督学习面临解剖结构细微、时间动态复杂以及缺乏领域特定预训练模型的挑战。现有方法在处理高样本相似性、低信噪比输入或临床相关特征失真时表现不佳。

研究方法: DISCOVR是一种双分支自监督框架，结合了基于聚类的视频编码器和在线图像编码器，通过语义聚类蒸馏损失将解剖知识从图像编码器传递到视频编码器，生成具有时间一致性和细粒度语义理解的表征。

研究结果: 在六个心脏超声数据集上的实验表明，DISCOVR在零样本和线性探测任务中优于现有视频异常检测方法和自监督学习基线，并实现了更优的分割迁移性能。

研究结论: DISCOVR通过结合时间动态建模和细粒度语义提取，显著提升了心脏超声视频的表征学习能力，为医学影像分析提供了新的解决方案。

中文摘要: 自监督学习（SSL）在自然图像和视频理解领域取得了重大进展，但在心脏超声（心脏超声）等领域仍面临挑战，原因包括细微的解剖结构、复杂的时间动态以及当前缺乏领域特定的预训练模型。现有的SSL方法（如对比学习、掩码建模和基于聚类的方法）在处理高样本相似性、对超声中常见的低信噪比输入的敏感性或扭曲临床相关特征的激进增强时表现不佳。我们提出了DISCOVR（跨模态视频表征的蒸馏图像监督），这是一种用于心脏超声视频表征学习的自监督双分支框架。DISCOVR结合了一个基于聚类的视频编码器（用于建模时间动态）和一个在线图像编码器（用于提取细粒度空间语义）。这两个分支通过语义聚类蒸馏损失连接，将解剖知识从动态演化的图像编码器传递到视频编码器，从而生成具有时间一致性和细粒度语义理解的表征。在涵盖胎儿、儿童和成人人群的六个心脏超声数据集上的评估表明，DISCOVR在零样本和线性探测任务中优于专门的视频异常检测方法和最先进的视频-SSL基线，并实现了更优的分割迁移性能。

</details>


### [166] [GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers](https://arxiv.org/abs/2506.11784)
**中文标题：GPLQ：一种通用、实用且高效的视觉Transformer量化方法**

*Guang Liang,Xinyao Liu,Jianxin Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为GPLQ的新型量化方法，专为高效量化视觉Transformer（ViT）设计。GPLQ通过两阶段策略（先量化激活，后量化权重）显著提升了量化效率，同时保持了模型性能，速度比现有QAT方法快100倍，并在多种下游任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 视觉Transformer（ViT）在计算机视觉中至关重要，但其计算成本高昂。现有的后训练量化（PTQ）和量化感知训练（QAT）方法存在显著缺陷：PTQ精度下降严重，QAT计算成本高、泛化能力差且缺乏开源支持。为解决这些问题，本文提出了GPLQ。

研究方法: GPLQ采用两阶段策略：第一阶段保持权重为FP32，仅量化激活并通过特征模仿损失在1个epoch内完成，以保持模型的优化“盆地”；第二阶段使用PTQ方法量化权重。这种方法显著降低了计算和内存开销。

研究结果: GPLQ比现有QAT方法快100倍，内存占用甚至低于FP32训练，4-bit量化模型的性能在ImageNet和多种下游任务（如细粒度视觉分类和对象检测）上与FP32模型相当。

研究结论: GPLQ是一种高效、实用的ViT量化方法，解决了现有方法的局限性，同时保持了高性能和泛化能力。未来将发布支持多种视觉任务的开源工具包。

中文摘要: 视觉Transformer（ViT）在计算机视觉中至关重要，但其计算成本高昂。模型量化（尤其是低比特如4-bit）旨在缓解这一问题，但现有的后训练量化（PTQ）和量化感知训练（QAT）方法存在显著局限性。PTQ通常导致精度大幅下降，而QAT虽然精度高，但计算成本高、泛化能力差、训练不稳定且缺乏开源代码。为解决这些问题，本文提出了一种名为GPLQ的新型框架，专为高效量化ViT设计。GPLQ基于两个关键经验：激活量化的重要性以及保持模型原始优化“盆地”的必要性。因此，GPLQ采用“先激活，后权重”的顺序策略。第一阶段保持权重为FP32，仅量化激活并通过特征模仿损失在1个epoch内完成，以保持泛化能力；第二阶段使用PTQ方法量化权重。结果表明，GPLQ比现有QAT方法快100倍，内存占用甚至低于FP32训练，4-bit量化模型在ImageNet和多种下游任务（如细粒度视觉分类和对象检测）上的性能与FP32模型相当。我们将发布一个易用的开源工具包，支持多种视觉任务。

</details>


### [167] [Teleoperated Driving: a New Challenge for 3D Object Detection in Compressed Point Clouds](https://arxiv.org/abs/2506.11804)
**中文标题：远程驾驶：压缩点云中3D物体检测的新挑战**

*Filippo Bragato,Michael Neri,Paolo Testolina,Marco Giordani,Federica Battisti*

主要分类: cs.CV

摘要简述: 本文探讨了在压缩点云数据中进行3D物体检测以支持远程驾驶（TD）的问题，分析了压缩算法和物体检测器的性能及其对V2X网络的影响。


<details>
  <summary>详细信息</summary>
研究动机: 随着互联设备和传感器数量的增加，远程驾驶（TD）成为可能。然而，如何从压缩的点云数据中高效检测车辆和行人以确保安全驾驶仍是一个挑战。

研究方法: 利用扩展的SELMA数据集（包含3D物体的真实边界框），评估了多种压缩算法和物体检测器的性能，包括压缩效率、解压时间、推理时间和检测精度，并分析了其对V2X网络数据速率和延迟的影响。

研究结果: 研究结果表明，压缩算法和检测器的选择对远程驾驶的性能有显著影响，尤其是在满足3GPP对TD应用的网络要求方面。

研究结论: 本文为远程驾驶中的3D物体检测提供了重要见解，强调了压缩和检测技术在V2X网络中的关键作用。

中文摘要: 近年来，互联设备的发展已扩展到多个领域，从娱乐到教育和工业应用。传感器数量的增加以及强大硬件和软件的普及加速了这一趋势。远程驾驶（TD）是这些技术进步的重要受益领域之一。在这一场景中，控制器通过车载传感器生成并通过车联网（V2X）通信交换的数据远程安全驾驶车辆。本文研究了从点云数据中检测车辆和行人的问题，以支持安全的TD操作。具体而言，我们利用了SELMA数据集（一种多模态、开源的自动驾驶合成数据集），并通过添加3D物体的真实边界框来支持物体检测。我们分析了多种压缩算法和物体检测器在压缩效率、解压时间、推理时间和检测精度等方面的性能。此外，我们还测量了压缩和检测对V2X网络在数据速率和延迟方面的影响，并与3GPP对TD应用的要求进行了对比。

</details>


### [168] [Rethinking Multilingual Vision-Language Translation: Dataset, Evaluation, and Adaptation](https://arxiv.org/abs/2506.11820)
**中文标题：重新思考多语言视觉语言翻译：数据集、评估与适配**

*Xintong Wang,Jingheng Pan,Yixiao Liu,Xiaohu Zhao,Chenyang Lyu,Minghao Wu,Chris Biemann,Longyue Wang,Linlong Xu,Weihua Luo,Kaifu Zhang*

主要分类: cs.CV

摘要简述: 本文重新审视多语言视觉语言翻译（VLT），提出新数据集AibTrans，评估11种商业和6种开源模型，并提出Density-Aware Evaluation以改进翻译质量评估。研究发现高资源语言微调会损害跨语言性能，并提出平衡多语言微调策略。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型视觉语言模型（LVLMs）在多语言和视觉理解方面表现优异，但缺乏对VLT任务的系统评估和理解。现有数据集在语义和文化保真度上存在局限，且评估指标不够可靠。

研究方法: 1. 提出AibTrans数据集，包含多语言、并行、人工验证的OCR校正标注。2. 对11种商业和6种开源模型进行端到端和级联架构的基准测试。3. 提出Density-Aware Evaluation（DA Score）以改进翻译质量评估。4. 研究高资源语言微调对跨语言性能的影响，并提出平衡微调策略。

研究结果: 1. AibTrans数据集显著提升数据质量。2. 模型测试显示OCR依赖性和生成与推理行为的差异。3. DA Score能更可靠地评估翻译质量。4. 平衡多语言微调策略有效提升模型性能而不损害泛化能力。

研究结论: 本文为VLT任务建立了新的评估基准，揭示了现有模型的局限性，并提出数据、评估和微调策略的改进方案，为未来研究提供了重要参考。

中文摘要: 视觉语言翻译（VLT）是一项具有挑战性的任务，需要准确识别图像中的多语言文本，并在视觉上下文的支持下将其翻译为目标语言。尽管近期的大型视觉语言模型（LVLMs）展现了强大的多语言和视觉理解能力，但缺乏对其在VLT任务上性能的系统评估与理解。本研究从数据质量、模型架构和评估指标三个关键角度对VLT进行了全面研究。（1）我们指出了现有数据集在语义和文化保真度上的关键局限，并提出了AibTrans——一个多语言、并行、人工验证且带有OCR校正标注的数据集。（2）我们对11种商业LVLMs/LLMs和6种最先进的开源模型进行了端到端和级联架构的基准测试，揭示了它们的OCR依赖性以及生成与推理行为的差异。（3）我们提出了Density-Aware Evaluation以解决不同上下文复杂性下评估指标的可靠性问题，并引入DA Score作为翻译质量的更稳健度量。基于这些发现，我们为VLT建立了新的评估基准。值得注意的是，我们发现对高资源语言对进行微调会损害跨语言性能，并提出了一种平衡的多语言微调策略，能够在不牺牲模型泛化能力的情况下有效适配LVLMs至VLT任务。

</details>


### [169] [Vision-based Lifting of 2D Object Detections for Automated Driving](https://arxiv.org/abs/2506.11839)
**中文标题：基于视觉的2D物体检测提升至3D检测用于自动驾驶**

*Hendrik Königshof,Kun Li,Christoph Stiller*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉的2D检测结果提升至3D检测的管道，仅使用摄像头作为低成本替代LiDAR的方案，适用于所有道路使用者，并在KITTI基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶中，3D物体检测通常依赖昂贵的LiDAR数据，而摄像头成本低且普及。本文旨在通过仅使用摄像头，将现有2D视觉算法提升至3D检测，降低成本并扩展适用性。

研究方法: 提出一种管道，利用2D CNN处理点云数据，将2D检测结果提升至3D检测，专注于所有道路使用者而非仅车辆，并优化计算效率。

研究结果: 在KITTI 3D物体检测基准测试中，性能与现有基于图像的方法相当，但运行时间仅为后者的三分之一。

研究结论: 本文方法为低成本3D检测提供了可行方案，适用于自动驾驶，且在性能和效率上表现优异。

中文摘要: 基于图像的3D物体检测是自动驾驶中不可或缺的部分，因为现代汽车大多已配备低成本的车载摄像头。目前，大多数先进的3D物体检测器依赖LiDAR数据以获取精确深度信息。本文提出了一种管道，仅使用摄像头作为LiDAR的低成本替代方案，将现有基于视觉的2D算法结果提升至3D检测。与现有方法不同，我们不仅关注车辆，还涵盖所有道路使用者。据我们所知，我们首次使用2D CNN处理每个2D检测的点云数据，以尽可能降低计算负担。在具有挑战性的KITTI 3D物体检测基准测试中，我们的方法性能与现有基于图像的方法相当，而运行时间仅为后者的三分之一。

</details>


### [170] [SphereDrag: Spherical Geometry-Aware Panoramic Image Editing](https://arxiv.org/abs/2506.11863)
**中文标题：SphereDrag：基于球面几何感知的全景图像编辑**

*Zhiao Feng,Xuewei Li,Junjie Yang,Yuxin Peng,Xi Li*

主要分类: cs.CV

摘要简述: SphereDrag是一种新型全景图像编辑框架，通过利用球面几何知识解决全景图像编辑中的边界不连续性、轨迹变形和像素密度不均问题，显著提升了编辑的几何一致性和图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 平面图像编辑已取得显著进展，但全景图像编辑仍面临边界不连续性、轨迹变形和像素密度不均等挑战。这些问题的根源在于全景图像的球面几何特性和投影失真，因此需要一种专门的方法来解决。

研究方法: SphereDrag框架包含三个核心组件：自适应重投影（AR）通过自适应球面旋转处理边界不连续性；大圆轨迹调整（GCTA）确保运动轨迹更准确；球面搜索区域跟踪（SSRT）根据球面位置自适应调整搜索范围以解决像素密度不均问题。此外，还构建了全景编辑基准PanoBench。

研究结果: 实验表明，SphereDrag在几何一致性和图像质量上显著优于现有方法，相对改进高达10.5%。

研究结论: SphereDrag通过结合球面几何知识，有效解决了全景图像编辑中的关键问题，为复杂编辑任务提供了标准化评估框架，推动了全景图像编辑的发展。

中文摘要: 图像编辑在平面图像上已取得重大进展，但全景图像编辑仍未被充分探索。由于其球面几何特性和投影失真，全景图像编辑面临三个关键挑战：边界不连续性、轨迹变形和像素密度不均。为解决这些问题，我们提出SphereDrag，一种利用球面几何知识实现精确可控编辑的新型全景编辑框架。具体而言，自适应重投影（AR）通过自适应球面旋转处理不连续性；大圆轨迹调整（GCTA）使运动轨迹更准确；球面搜索区域跟踪（SSRT）根据球面位置自适应调整搜索范围以解决像素密度不均问题。此外，我们构建了全景编辑基准PanoBench，包含涉及多对象和多样风格的复杂编辑任务，提供了标准化评估框架。实验表明，SphereDrag在几何一致性和图像质量上显著优于现有方法，相对改进高达10.5%。

</details>


### [171] [Methods for evaluating the resolution of 3D data derived from satellite images](https://arxiv.org/abs/2506.11876)
**中文标题：评估卫星图像衍生的3D数据分辨率的方法**

*Christina Selby,Holden Bindl,Tyler Feldman,Andrew Skow,Nicolas Norena Acosta,Shea Hagstrom,Myron Brown*

主要分类: cs.CV

摘要简述: 本文探讨了评估卫星图像衍生的3D数据分辨率的方法，包括点云、数字表面模型和3D网格模型，并提出了基于高分辨率机载激光雷达的自动化评估工具和工作流程。


<details>
  <summary>详细信息</summary>
研究动机: 卫星图像衍生的3D数据在大规模场景建模或无法通过机载设备获取数据的区域中至关重要，但其分辨率的评估对任务效用和改进追踪具有重要意义。

研究方法: 研究提出了评估点云、数字表面模型和3D网格模型分辨率的方法，并开发了基于高分辨率机载激光雷达的自动化评估工具和工作流程。

研究结果: 通过分析不同质量的数据，展示了所提工具和工作流程在分辨率评估中的有效性。

研究结论: 本文提出的方法为卫星图像衍生的3D数据分辨率评估提供了自动化解决方案，有助于提升数据质量和应用效果。

中文摘要: 卫星图像衍生的3D数据对于需要大规模覆盖或涉及无法通过机载激光雷达或相机获取的场景建模应用至关重要。测量这些数据的分辨率对于确定任务效用和追踪改进具有重要意义。本研究探讨了评估点云、数字表面模型和3D网格模型分辨率的方法。我们描述了基于高分辨率机载激光雷达的自动化评估工具和工作流程，并展示了针对不同质量数据的分析结果。

</details>


### [172] [O2Former:Direction-Aware and Multi-Scale Query Enhancement for SAR Ship Instance Segmentation](https://arxiv.org/abs/2506.11913)
**中文标题：O2Former：面向SAR船舶实例分割的方向感知与多尺度查询增强方法**

*F. Gao,Y Li,X He,J Sun,J Wang*

主要分类: cs.CV

摘要简述: O2Former是一种针对SAR图像中船舶实例分割的改进框架，通过多尺度查询生成和方向感知嵌入模块，解决了SAR图像中尺度变化、目标密度和模糊边界等问题，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: SAR图像中的船舶实例分割在海洋监测、环境分析和国家安全等领域至关重要。然而，现有方法往往忽视了SAR图像中尺度变化、目标密度和模糊边界等挑战，导致性能不佳。因此，本文提出O2Former，旨在解决这些问题并提升分割效果。

研究方法: O2Former基于Mask2Former框架，引入了两个关键模块：1) 优化查询生成器（OQG），通过联合编码浅层位置信息和高层语义信息，实现多尺度特征交互，提升查询质量和收敛效率；2) 方向感知嵌入模块（OAEM），通过方向感知卷积和极坐标编码增强方向敏感性，解决SAR场景中目标方向不均匀的问题。

研究结果: 实验表明，O2Former在SAR船舶数据集上的性能优于现有实例分割基线方法，验证了其有效性和泛化能力。

研究结论: O2Former通过多尺度查询生成和方向感知嵌入模块，显著提升了SAR图像中船舶实例分割的精度，为相关应用提供了有力支持。

中文摘要: 合成孔径雷达（SAR）图像中的船舶实例分割对于海洋监测、环境分析和国家安全等应用至关重要。SAR船舶图像存在尺度变化、目标密度高和边界模糊等挑战，现有方法往往忽视这些问题，导致性能不佳。本文提出O2Former，一种基于Mask2Former的改进框架，充分利用SAR图像的结构特征。我们引入了两个关键模块：1) 优化查询生成器（OQG），通过联合编码浅层位置信息和高层语义信息，实现多尺度特征交互，提升查询质量和收敛效率；2) 方向感知嵌入模块（OAEM），通过方向感知卷积和极坐标编码增强方向敏感性，有效解决SAR场景中目标方向不均匀的问题。这些模块共同实现了从主干网络到解码器的精确特征对齐，并增强了模型捕捉细粒度结构细节的能力。大量实验表明，O2Former在SAR船舶数据集上的性能优于现有实例分割基线方法，验证了其有效性和泛化能力。

</details>


### [173] [Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation](https://arxiv.org/abs/2506.11924)
**中文标题：通过跨模态注意力蒸馏实现对齐的新视角图像与几何合成**

*Min-Seop Kwak,Junho Kim,Sangdoo Yun,Dongyoon Han,Taekyoung Kim,Seungryong Kim,Jin-Hwa Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种基于扩散模型的框架，通过跨模态注意力蒸馏实现对齐的新视角图像和几何合成，结合变形和修复方法，生成高质量且几何对齐的图像和几何结构。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法需要密集的位姿图像或局限于特定视角的生成模型，限制了新视角合成的灵活性和准确性。本文旨在通过跨模态注意力蒸馏和几何预测，实现更灵活且几何对齐的图像和几何合成。

研究方法: 方法利用现成的几何预测器生成部分几何结构，并将新视角合成任务转化为图像和几何的修复任务。通过跨模态注意力蒸馏，将图像扩散分支的注意力图注入几何扩散分支，确保生成内容的一致性。此外，引入基于邻近的网格条件化，整合深度和法线信息，优化几何预测。

研究结果: 实验表明，该方法在未见场景中实现了高质量的图像和几何外推合成，在插值设置下具有竞争力的重建质量，并生成了几何对齐的彩色点云，实现了全面的3D补全。

研究结论: 本文提出的框架通过跨模态注意力蒸馏和几何条件化，显著提升了新视角图像和几何合成的对齐性和质量，为3D场景生成提供了有效解决方案。

中文摘要: 我们提出了一种基于扩散模型的框架，通过变形和修复方法实现对齐的新视角图像和几何生成。与现有方法不同，我们的方法利用现成的几何预测器从参考图像预测部分几何结构，并将新视角合成任务转化为图像和几何的修复任务。为确保生成图像与几何的准确对齐，我们提出了跨模态注意力蒸馏，在训练和推理过程中将图像扩散分支的注意力图注入并行几何扩散分支。这种多任务方法实现了协同效应，促进了几何鲁棒的图像合成和明确的几何预测。我们还引入了基于邻近的网格条件化，整合深度和法线信息，在点云之间插值并过滤错误预测的几何结构，避免其对生成过程的影响。实验表明，我们的方法在未见场景中实现了高质量的图像和几何外推合成，在插值设置下具有竞争力的重建质量，并生成了几何对齐的彩色点云，实现了全面的3D补全。项目页面详见https://cvlab-kaist.github.io/MoAI。

</details>


### [174] [Evaluating Sensitivity Parameters in Smartphone-Based Gaze Estimation: A Comparative Study of Appearance-Based and Infrared Eye Trackers](https://arxiv.org/abs/2506.11932)
**中文标题：基于智能手机的视线估计灵敏度参数评估：外观与红外眼动仪的比较研究**

*Nishan Gunawardena,Gough Yumu Lui,Jeewani Anupama Ginige,Bahman Javadi*

主要分类: cs.CV

摘要简述: 本研究比较了基于智能手机的深度学习视线追踪算法与商用红外眼动仪Tobii Pro Nano的性能，探讨了外观视线估计在移动设备上的可行性。结果显示，深度学习方法的平均误差为17.76毫米，略高于Tobii Pro Nano的16.53毫米，但对光照、视力矫正和年龄等因素更敏感。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估基于智能手机的外观视线估计方法在实际移动使用条件下的可行性，并与商用红外眼动仪进行性能对比，以探索其在移动设备上的应用潜力。

研究方法: 研究采用轻量级卷积神经网络（MobileNet-V3）结合长短期记忆（LSTM）结构，从灰度面部图像预测视线坐标。通过动态视觉刺激收集51名参与者的视线数据，并使用欧几里得距离测量准确性。

研究结果: 深度学习模型的平均误差为17.76毫米，略高于Tobii Pro Nano的16.53毫米。但深度学习方法对光照、视力矫正和年龄等因素更敏感，在低光照、戴眼镜的参与者及高龄组中失败率较高。设备类型和头部位置也对追踪性能有影响。

研究结论: 外观视线估计方法在移动设备上具有潜力，但需进一步优化以应对光照、视力矫正和年龄等因素的挑战。研究为评估不同使用条件下的视线估计系统提供了参考框架。

中文摘要: 本研究通过比较基于智能手机的深度学习视线追踪算法与商用红外眼动仪Tobii Pro Nano的性能，探讨了外观视线估计在现实移动使用条件下的可行性。研究系统分析了年龄、性别、视力矫正、光照条件、设备类型和头部位置等关键灵敏度因素。外观算法结合了轻量级卷积神经网络（MobileNet-V3）和长短期记忆（LSTM）结构，从灰度面部图像预测视线坐标。通过动态视觉刺激收集了51名参与者的视线数据，并使用欧几里得距离测量准确性。深度学习模型的平均误差为17.76毫米，略高于Tobii Pro Nano的16.53毫米。尽管总体准确性差异较小，但深度学习方法对光照、视力矫正和年龄等因素更敏感，在低光照条件下戴眼镜的参与者及高龄组中失败率较高。设备类型和头部位置也对追踪性能有影响。这些结果表明外观方法在移动视线追踪中具有潜力，并为评估不同使用条件下的视线估计系统提供了参考框架。

</details>


### [175] [How Visual Representations Map to Language Feature Space in Multimodal LLMs](https://arxiv.org/abs/2506.11976)
**中文标题：多模态大语言模型中视觉表征如何映射到语言特征空间**

*Constantin Venhoff,Ashkan Khakzar,Sonia Joseph,Philip Torr,Neel Nanda*

主要分类: cs.CV

摘要简述: 本文研究了多模态大语言模型中视觉表征如何映射到语言特征空间，通过冻结语言模型和视觉模型，仅训练线性适配器，揭示了视觉与语言表征的层级对齐过程。


<details>
  <summary>详细信息</summary>
研究动机: 多模态推理的有效性依赖于视觉与语言表征的对齐，但目前对视觉语言模型如何实现这种对齐的机制尚不清楚。本文旨在通过冻结模型并分析适配器的映射过程，揭示这一机制。

研究方法: 采用冻结的大语言模型（LLM）和视觉变换器（ViT），仅训练线性适配器进行视觉指令调整。利用预训练的稀疏自编码器（SAEs）作为分析工具，研究视觉表征如何逐步对齐语言特征。

研究结果: 实验表明，视觉表征在中间至后期层逐渐与语言特征对齐，但ViT输出与早期LLM层存在显著不对齐，提示当前适配器架构可能并非最优的跨模态表征学习方案。

研究结论: 视觉与语言表征的对齐是一个层级渐进的过程，当前适配器架构可能未充分利用跨模态学习的潜力，需进一步优化。

中文摘要: 有效的多模态推理依赖于视觉与语言表征的对齐，然而视觉语言模型（VLMs）实现这种对齐的机制尚不明确。我们提出了一种方法框架，通过冻结大语言模型（LLM）和视觉变换器（ViT），仅训练线性适配器进行视觉指令调整。这一设计确保语言模型保持其原始语言表征，而线性适配器需将视觉特征直接映射到LLM的现有表征空间。实验利用预训练的稀疏自编码器（SAEs）作为分析工具，通过SAE重构误差、稀疏模式和特征描述，揭示了视觉表征如何逐步与语言特征对齐，并在中间至后期层收敛。结果表明ViT输出与早期LLM层存在不对齐，引发了对当前适配器架构是否最优的思考。

</details>


### [176] [Simple Radiology VLLM Test-time Scaling with Thought Graph Traversal](https://arxiv.org/abs/2506.11989)
**中文标题：基于思维图遍历的简单放射学VLLM测试时扩展**

*Yue Yao,Zelin Wen,Yan Tong,Xinyu Tian,Xuqing Li,Xiao Ma,Dongliang Xu,Tom Gedeon*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级的Thought Graph Traversal (TGT)框架，通过测试时扩展和动态推理预算策略，提升放射学报告的生成质量，无需额外训练。


<details>
  <summary>详细信息</summary>
研究动机: 测试时扩展是一种无需额外训练即可提升视觉语言大模型（VLLMs）推理性能的方法。本文旨在探索如何将其应用于放射学报告生成，以生成更准确、一致的胸部X光报告。

研究方法: 引入轻量级的Thought Graph Traversal (TGT)框架，通过整合结构化医学先验知识到提示中，指导模型按医学逻辑顺序分析器官特异性发现。同时采用推理预算强制策略，动态调整模型的推理深度。

研究结果: 该方法在标准基准测试中优于基线提示方法，并能通过可追溯的推理路径揭示数据集偏差。

研究结论: TGT框架结合推理预算策略，显著提升了冻结放射学VLLM的自我纠正能力，生成更准确的报告。

中文摘要: 测试时扩展为提升视觉语言大模型（VLLMs）的推理性能提供了一种无需额外训练的方法。本文探索了一种简单有效的测试时扩展方法，应用于放射学报告生成。具体而言，我们提出了一种轻量级的思维图遍历（TGT）框架，通过整合结构化医学先验知识到提示中，指导模型按医学逻辑顺序分析器官特异性发现。为进一步增强推理深度，我们采用推理预算强制策略，动态调整模型的推理深度。这种简单而强大的组合使冻结的放射学VLLM能够自我纠正，生成更准确、一致的胸部X光报告。我们的方法在标准基准测试中优于基线提示方法，并能通过可追溯的推理路径揭示数据集偏差。代码和提示已开源，详见https://github.com/glerium/Thought-Graph-Traversal。

</details>


### [177] [VGR: Visual Grounded Reasoning](https://arxiv.org/abs/2506.11991)
**中文标题：VGR：基于视觉的推理模型**

*Jiacong Wang,Zijiang Kang,Haochen Wang,Haiyong Jiang,Jiawen Li,Bohong Wu,Ya Wang,Jiao Ran,Xiao Liang,Chao Feng,Jun Xiao*

主要分类: cs.CV

摘要简述: 本文提出VGR模型，通过增强细粒度视觉感知能力，解决多模态推理中的语言偏差问题，并在多模态基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态推理方法主要依赖纯语言空间，存在语言偏差且局限于数学或科学领域，难以处理需要全面理解图像细节的复杂视觉推理任务。

研究方法: VGR模型通过检测问题相关区域并基于重放图像区域提供精确答案，结合视觉定位和语言推理的大规模SFT数据集VGR-SFT，优化推理流程。

研究结果: 在LLaVA-NeXT-7B基准上，VGR仅使用30%的图像标记数量，在MMStar、AI2D和ChartQA上分别提升4.1、7.1和12.9分。

研究结论: VGR通过视觉定位和重放机制显著提升多模态理解能力，为复杂视觉推理任务提供了有效解决方案。

中文摘要: 在多模态链式推理领域，现有方法主要依赖纯语言空间进行推理，存在语言偏差且局限于数学或科学领域，难以处理需要全面理解图像细节的复杂视觉推理任务。为解决这些问题，本文提出VGR，一种具有增强细粒度视觉感知能力的多模态大语言模型（MLLM）。与传统MLLM仅在语言空间回答问题或推理不同，VGR首先检测可能有助于解决问题的相关区域，然后基于重放的图像区域提供精确答案。为此，我们构建了一个名为VGR-SFT的大规模SFT数据集，包含混合视觉定位和语言推理的数据。VGR的推理流程允许模型选择视觉参考的边界框，并通过重放阶段将相应区域整合到推理过程中，增强多模态理解能力。在LLaVA-NeXT-7B基准上的实验表明，VGR在需要全面理解图像细节的多模态基准测试中表现优异。与基线相比，VGR仅使用30%的图像标记数量，在MMStar、AI2D和ChartQA上分别提升了4.1、7.1和12.9分。

</details>


### [178] [Improving Surgical Risk Prediction Through Integrating Automated Body Composition Analysis: a Retrospective Trial on Colectomy Surgery](https://arxiv.org/abs/2506.11996)
**中文标题：通过整合自动身体组成分析改善结肠切除术风险预测：一项回顾性试验**

*Hanxue Gu,Yaqian Chen,isoo Lee,Diego Schaps,Regina Woody,Roy Colglazier,Maciej A. Mazurowski,Christopher Mantyh*

主要分类: cs.CV

摘要简述: 本研究探讨通过自动提取CT扫描中的身体组成指标，结合临床变量或现有风险预测工具，预测结肠切除术后1年全因死亡率及其他术后结果的效果。


<details>
  <summary>详细信息</summary>
研究动机: 结肠切除术后的风险预测对患者管理至关重要，但目前依赖临床变量和现有风险评分的方法仍有改进空间。通过自动分析术前CT扫描中的身体组成指标，可能提供更精准的风险预测。

研究方法: 研究采用回顾性试验设计，从术前CT扫描中提取300多个身体组成特征（如骨骼肌面积、密度、脂肪面积等），结合临床变量和NSQIP评分，使用Cox比例风险模型和逻辑回归评估预测性能。主要指标为1年全因死亡率的C指数和综合Brier评分，次要指标包括术后并发症、再入院等的AUC和Brier评分。

研究结果: 结果显示，自动提取的身体组成指标与1年全因死亡率显著相关，结合临床变量后预测性能进一步提升。次要指标中，身体组成特征也与术后并发症、再入院等结果显著相关。

研究结论: 自动提取的术前身体组成指标可有效预测结肠切除术后风险，结合临床变量后预测性能更优，为术后管理提供了新工具。

中文摘要: 目的：评估术前从CT扫描自动提取的身体组成指标是否能单独或结合临床变量或现有风险预测工具预测结肠切除术后结果。主要结果与指标：主要结果为预测结肠切除术后1年全因死亡率的性能，采用Cox比例风险模型和1年随访，通过一致性指数（C-index）和综合Brier评分（IBS）评估性能。次要结果包括术后并发症、非计划再入院、输血和严重感染，使用逻辑回归的AUC和Brier评分评估。比值比（OR）描述CT提取的身体组成指标与结果之间的关联。从术前CT扫描中提取了300多个特征，包括骨骼肌面积、密度、脂肪面积和组织间指标。2012年后所有手术均提供NSQIP评分。

</details>


### [179] [Affogato: Learning Open-Vocabulary Affordance Grounding with Automated Data Generation at Scale](https://arxiv.org/abs/2506.12009)
**中文标题：Affogato：通过大规模自动化数据生成学习开放词汇的交互区域定位**

*Junha Lee,Eunha Park,Chunghyun Park,Dahyun Kang,Minsu Cho*

主要分类: cs.CV

摘要简述: 本文提出Affogato，一个大规模开放词汇的交互区域定位数据集，包含15万实例，并开发了基于预训练视觉模型和文本条件热图解码器的简单有效模型，在2D和3D基准测试中表现优异，且具备跨领域泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 交互区域定位（affordance grounding）是智能体理解环境的关键任务，但由于需要细粒度定位、多交互区域的模糊性及数据稀缺性，该任务仍具挑战性。

研究方法: 作者构建了包含15万实例的Affogato数据集，标注了开放词汇文本描述和3D交互热图，并开发了基于预训练视觉模型和文本条件热图解码器的模型。

研究结果: 模型在现有2D和3D基准测试中表现优异，并展现出开放词汇跨领域泛化的能力。

研究结论: Affogato数据集和提出的模型为交互区域定位任务提供了有效解决方案，并公开了数据集以促进研究。

中文摘要: 交互区域定位（affordance grounding）是通过自然语言描述定位对象区域的任务，对智能体理解环境至关重要。然而，由于需要细粒度定位、多交互区域的模糊性及数据稀缺性，该任务仍具挑战性。本文提出Affogato，一个包含15万实例的大规模基准数据集，标注了开放词汇文本描述和3D交互热图。基于此数据集，我们开发了简单有效的视觉语言模型，利用预训练的视觉模型和文本条件热图解码器。模型在现有2D和3D基准测试中表现优异，并展现出开放词汇跨领域泛化的能力。Affogato数据集已公开：https://huggingface.co/datasets/project-affogato/affogato

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [180] [A Survey of Task-Oriented Knowledge Graph Reasoning: Status, Applications, and Prospects](https://arxiv.org/abs/2506.11012)
**中文标题：任务导向的知识图谱推理研究综述：现状、应用与展望**

*Guanglin Niu,Bo Li,Yangguang Lin*

主要分类: cs.AI

摘要简述: 本文综述了任务导向的知识图谱推理（KGR）的研究现状、应用及未来方向，系统分类了六种KGR任务，并探讨了大型语言模型（LLMs）等先进技术对KGR的影响。


<details>
  <summary>详细信息</summary>
研究动机: 知识图谱（KGs）是认知智能系统的关键技术，但现有综述未能全面涵盖KGR任务及其下游应用与挑战性推理范式。本文旨在填补这一空白，提供更全面的KGR研究视角。

研究方法: 从任务中心视角出发，将现有KGR方法分为静态单步、静态多步、动态、多模态、少样本和归纳KGR六类，并探讨了LLMs等先进技术的影响。

研究结果: 系统总结了KGR任务分类、下游应用及挑战性推理范式，突出了LLMs等技术的潜力，并提出了未来研究方向。

研究结论: 本文为KGR领域提供了全面的研究综述，强调了关键趋势和未来方向，推动了该领域的进一步发展。

中文摘要: 知识图谱（KGs）已成为结构化与利用多样化现实世界知识的强大范式，是认知智能系统实现高级理解与推理能力的基础技术。知识图谱推理（KGR）旨在基于KGs中的现有事实推断新知识，在公共安全情报、智能医疗和金融风险评估等应用中发挥关键作用。从任务中心视角来看，现有KGR方法可大致分为静态单步KGR、静态多步KGR、动态KGR、多模态KGR、少样本KGR和归纳KGR。尽管现有综述已涵盖这六类KGR任务，但仍缺乏系统总结所有KGR任务（特别是下游应用及更具挑战性的推理范式）的全面综述。与以往研究不同，本综述通过基于主要推理任务、下游应用任务及潜在挑战性推理任务的分类，为KGR研究提供了更全面的视角。此外，我们还探讨了大型语言模型（LLMs）等先进技术及其对KGR的影响。本文旨在突出KGR领域的关键研究趋势，并勾勒出未来的发展方向。

</details>


### [181] [OntoGSN: An Ontology for Dynamic Management of Assurance Cases](https://arxiv.org/abs/2506.11023)
**中文标题：OntoGSN：一种用于动态管理保证案例的本体**

*Tomas Bueno Momcilovic,Barbara Gallina,Ingmar Kessler,Dian Balta*

主要分类: cs.AI

摘要简述: 本文提出OntoGSN，一种基于本体的动态管理保证案例（ACs）的方法，通过知识表示和可查询图支持自动化更新与评估，解决了ACs管理中的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 保证案例（ACs）在系统属性（如安全性或鲁棒性）的构建和维护中至关重要，但现有工具多为静态或文档中心化，动态管理ACs仍具挑战性，导致开发者难以维护或产生虚假信心。

研究方法: 提出OntoGSN本体及中间件，严格遵循GSN社区标准v3，使用OWL本体和SWRL规则，提供知识表示、可查询图、SPARQL查询库和原型界面，支持自动化填充、评估和更新。

研究结果: OntoGSN通过FAIR原则、OOPS框架、能力问题和社区反馈评估，验证了其有效性，并展示了在大型语言模型对抗鲁棒性保证中的动态管理示例。

研究结论: OntoGSN为动态管理保证案例提供了标准化、自动化的解决方案，未来开发将基于社区需求持续优化。

中文摘要: 保证案例（ACs）是构建和维护系统属性（如安全性或鲁棒性）信心的常见工具。尽管现有工具支持静态、文档中心化的应用，但动态环境（如自动驾驶）中的ACs管理仍具挑战性，维护变更中的嵌入知识需大量努力，甚至导致虚假信心。为此，我们提出OntoGSN：一种基于Goal Structuring Notation（GSN）标准的本体及中间件，用于管理ACs。OntoGSN提供知识表示和可查询图，支持自动化填充、评估和更新。贡献包括：1）GSN社区标准v3的1:1形式化OWL本体与SWRL规则；2）辅助本体和解析器，用于与常用AC工具集成；3）OntoGSN维护的设计决策文档；4）SPARQL查询库与自动化模式；5）原型界面。该本体严格遵循标准文本，并通过FAIR原则、OOPS框架、能力问题和社区反馈评估。其他中间件开发基于社区需求并持续评估。为展示实用性，我们以大型语言模型对抗鲁棒性保证为例说明动态AC管理。

</details>


### [182] [LLM-as-a-Fuzzy-Judge: Fine-Tuning Large Language Models as a Clinical Evaluation Judge with Fuzzy Logic](https://arxiv.org/abs/2506.11221)
**中文标题：LLM作为模糊评判者：基于模糊逻辑微调大语言模型作为临床评估评判者**

*Weibing Zheng,Laurah Turner,Jess Kropczynski,Murat Ozer,Tri Nguyen,Shane Halse*

主要分类: cs.AI

摘要简述: 本文提出LLM-as-a-Fuzzy-Judge方法，结合模糊逻辑与大语言模型（LLM），通过微调LLM评估医学生的临床沟通技能，实现与医生主观判断一致的自动化评估。


<details>
  <summary>详细信息</summary>
研究动机: 临床沟通技能在医学教育中至关重要，但大规模练习和评估具有挑战性。现有LLM驱动的临床模拟虽能提升学生实践能力，但自动化评估难以匹配医生的主观判断。本文旨在解决这一问题。

研究方法: 方法包括：1) 从LLM驱动的医学教育系统收集数据；2) 基于多维模糊集（如专业性、医学相关性、伦理行为和上下文干扰）标注数据；3) 通过提示工程和监督微调（SFT）训练预训练LLM。

研究结果: 结果显示，LLM-as-a-Fuzzy-Judge的准确率超过80%，主要评估标准项超过90%，有效结合模糊逻辑与LLM，提供可解释且符合人类偏好的评估。

研究结论: 本文验证了模糊逻辑与LLM结合在医学教育评估中的可行性，推动了自动化评估的发展，支持更稳健的评估实践。

中文摘要: 临床沟通技能在医学教育中至关重要，但大规模练习和评估具有挑战性。尽管LLM驱动的临床场景模拟在提升医学生临床实践方面显示出潜力，但提供符合医生主观判断的自动化、可扩展的临床评估仍具难度。本文结合模糊逻辑与大语言模型（LLM），提出LLM-as-a-Fuzzy-Judge方法，以解决自动化评估医学生临床技能与医生主观偏好对齐的挑战。该方法通过微调LLM，基于人类标注的四个模糊集（包括专业性、医学相关性、伦理行为和上下文干扰）评估医学生在与AI患者对话脚本中的表达。本文方法从LLM驱动的医学教育系统收集数据，基于多维模糊集标注数据，随后通过提示工程和监督微调（SFT）训练预训练LLM。结果显示，LLM-as-a-Fuzzy-Judge的准确率超过80%，主要评估标准项超过90%，有效利用模糊逻辑与LLM提供可解释且符合人类偏好的评估。本研究表明，模糊逻辑与LLM结合可有效对齐人类偏好，推动医学教育中的自动化评估，支持更稳健的评估与判断实践。本工作的GitHub仓库地址为https://github.com/2sigmaEdTech/LLMAsAJudge。

</details>


### [183] [MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification](https://arxiv.org/abs/2506.11331)
**中文标题：MUDAS：多标签声音分类中的微型无监督域适应**

*Jihoon Yun,Chengzhang Li,Dhrubojyoti Roy,Anish Arora*

主要分类: cs.AI

摘要简述: 本文提出了一种名为MUDAS的框架，用于在资源受限的物联网设备上实现多标签声音分类的无监督域适应，通过选择性重训练和高置信度数据生成伪标签，显著提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有无监督域适应（UDA）算法仅适用于单标签任务且依赖大量计算资源，无法满足多标签场景和资源受限的物联网设备需求。城市声音分类等场景中，重叠声音和复杂声学环境要求低功耗设备具备高效的多标签分类能力，因此亟需一种轻量化的UDA解决方案。

研究方法: MUDAS框架通过选择性重训练分类器，利用高置信度数据生成伪标签，并结合类特定自适应阈值和多样性正则化，优化多标签分类性能，同时降低计算和内存需求。

研究结果: 在SONYC-UST数据集上的实验表明，MUDAS显著优于现有UDA算法，在资源受限的物联网环境中实现了良好的分类准确性。

研究结论: MUDAS为资源受限设备上的多标签声音分类提供了一种高效的UDA解决方案，通过轻量化设计和自适应策略，显著提升了分类性能。

中文摘要: 无监督域适应（UDA）对于将机器学习模型适应到新的、未标记环境中至关重要，因为数据分布的变化可能导致性能下降。现有的UDA算法仅适用于单标签任务，且依赖大量计算资源，限制了其在多标签场景和资源受限的物联网设备中的应用。在城市声音分类等场景中，重叠声音和变化的声学环境要求低功耗设备具备鲁棒的自适应多标签能力。为解决这些问题，我们提出了Mote-scale无监督域适应声音分类框架（MUDAS），专为资源受限的物联网环境设计。MUDAS通过选择性重训练分类器，利用高置信度数据生成伪标签，并结合类特定自适应阈值和多样性正则化，显著提升了多标签分类性能。在SONYC-UST数据集上的实验表明，MUDAS在资源受限的物联网环境中表现优异，分类准确性显著优于现有UDA算法。

</details>


### [184] [Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables](https://arxiv.org/abs/2506.11375)
**中文标题：多模态大语言模型在化学表格识别与理解中的基准测试**

*Yitong Zhou,Mingyue Cheng,Qingyang Mao,Yucong Luo,Qi Liu,Yupeng Li,Xiaohan Zhang,Deguang Liu,Xin Li,Enhong Chen*

主要分类: cs.AI

摘要简述: 本文介绍了ChemTable，一个针对化学表格的多模态基准测试，评估模型在表格识别与理解任务中的表现，发现现有模型在化学领域仍有显著局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试未能充分涵盖化学表格的多模态和领域特定复杂性，限制了多模态大语言模型在化学科学理解中的应用。

研究方法: 通过构建ChemTable基准测试，包含专家标注的化学表格数据，支持表格识别（结构解析与内容提取）和表格理解（描述性与推理问答）两大任务，并评估多种多模态模型的表现。

研究结果: 模型在基本布局解析上表现尚可，但在描述性和推理性问答任务中显著落后于人类表现，开源与闭源模型之间存在明显性能差距。

研究结论: ChemTable为化学表格理解提供了严谨的基准测试，凸显了化学领域表格理解的挑战，并推动科学推理的进步。

中文摘要: 化学表格通过符号表达、结构化变量和嵌入的分子图形编码复杂的实验知识。现有基准测试大多忽视了这种多模态和领域特定的复杂性，限制了多模态大语言模型在化学科学理解中的应用。本研究提出了ChemTable，一个从文献实验部分提取的大规模真实化学表格基准测试。ChemTable包含专家标注的单元格多边形、逻辑布局和领域特定标签（如试剂、催化剂、产率和图形组件），并支持两大核心任务：（1）表格识别，涵盖结构解析和内容提取；（2）表格理解，包括基于表格结构和领域语义的描述性与推理性问答。我们评估了多种代表性多模态模型（包括开源和闭源模型）在ChemTable上的表现，并报告了一系列具有实践和理论意义的发现。尽管模型在基本布局解析上表现尚可，但在描述性和推理性问答任务中显著落后于人类表现，且开源与闭源模型在多个维度上存在明显性能差距。这些结果凸显了化学表格理解的挑战，并将ChemTable定位为推动科学推理发展的严谨且现实的基准测试。

</details>


### [185] [Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning](https://arxiv.org/abs/2506.11376)
**中文标题：基于大语言模型的对话代理为家庭护理人员提供问题解决疗法（PST）：通过上下文学习增强共情与治疗联盟**

*Liying Wang,Ph. D.,Daffodil Carrington,M. S.,Daniil Filienko,M. S.,Caroline El Jazmi,M. S.,Serena Jinchen Xie,M. S.,Martine De Cock,Ph. D.,Sarah Iribarren,Ph. D.,Weichao Yuwen,Ph. D*

主要分类: cs.AI

摘要简述: 研究探讨了基于大语言模型（LLM）的对话代理为家庭护理人员提供问题解决疗法（PST）的潜力，结合动机访谈（MI）和行为链分析（BCA）。实验显示，Few-Shot和RAG提示技术的模型表现最佳，提高了共情和治疗联盟，但需平衡评估与建议效率。


<details>
  <summary>详细信息</summary>
研究动机: 家庭护理人员因多重角色和资源有限面临心理健康挑战，研究旨在探索LLM对话代理能否提供有效的心理支持。

研究方法: 采用组内实验设计，28名护理人员与四种LLM配置交互，评估共情和治疗联盟，结合Few-Shot和RAG提示技术及临床案例。

研究结果: 最佳模型表现出更强的上下文理解和个性化支持，参与者认可其情感验证和行动策略提供能力，但评估与建议平衡仍需改进。

研究结论: LLM在提供共情和定制化支持方面潜力显著，但需进一步优化评估与建议的平衡。

中文摘要: 家庭护理人员常因多重角色和资源有限面临心理健康挑战。本研究探讨了大语言模型（LLM）驱动的对话代理为护理人员提供循证心理支持的潜力，特别是结合问题解决疗法（PST）、动机访谈（MI）和行为链分析（BCA）。通过组内实验，28名护理人员与四种LLM配置交互，评估共情和治疗联盟。表现最佳的模型结合了Few-Shot和检索增强生成（RAG）提示技术及临床案例，显示出更强的上下文理解和个性化支持能力，体现在定性反馈和定量评分中。参与者认可模型的情感验证、未表达情感探索及行动策略提供能力，但平衡全面评估与高效建议仍具挑战。本研究凸显了LLM在提供共情和定制化支持方面的潜力。

</details>


### [186] [FocalAD: Local Motion Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2506.11419)
**中文标题：FocalAD：端到端自动驾驶的局部运动规划**

*Bin Sun,Boao Zhang,Jiayi Lu,Xinjie Feng,Jiachen Shang,Rui Cao,Mengchao Zheng,Chuanye Wang,Shichun Yang,Yaoguang Cao,Ziying Song*

主要分类: cs.AI

摘要简述: FocalAD是一种新型端到端自动驾驶框架，通过聚焦关键局部邻居和优化局部运动表示，显著提升了规划可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有自动驾驶方法通常依赖全局运动特征，忽略了规划决策主要由少量局部交互的智能体影响，导致潜在风险被忽视。

研究方法: FocalAD包含两个核心模块：Ego-Local-Agents Interactor（ELAI）和Focal-Local-Agents Loss（FLA Loss）。ELAI通过基于图的自我中心交互表示捕捉局部邻居的运动动态，FLA Loss则增加关键邻居的权重，优化规划优先级。

研究结果: 实验表明，FocalAD在nuScenes和Bench2Drive基准测试中优于现有方法，尤其在Adv-nuScenes数据集上碰撞率显著降低（比DiffusionDrive减少41.9%，比SparseDrive减少15.6%）。

研究结论: FocalAD通过聚焦局部交互和优化关键邻居表示，显著提升了自动驾驶的规划可靠性和鲁棒性。

中文摘要: 在端到端自动驾驶中，运动预测对自车规划至关重要。然而，现有方法通常依赖全局聚合的运动特征，忽略了规划决策主要由少量局部交互的智能体影响。忽视这些关键局部交互可能掩盖潜在风险并削弱规划可靠性。本文提出FocalAD，一种新型端到端自动驾驶框架，专注于关键局部邻居并通过增强局部运动表示优化规划。具体而言，FocalAD包含两个核心模块：Ego-Local-Agents Interactor（ELAI）和Focal-Local-Agents Loss（FLA Loss）。ELAI通过基于图的自我中心交互表示捕捉局部邻居的运动动态，以优化自车规划和智能体运动查询。FLA Loss增加决策关键邻居的权重，引导模型优先处理与规划更相关的智能体。大量实验表明，FocalAD在开环nuScenes数据集和闭环Bench2Drive基准测试中优于现有方法。值得注意的是，在注重鲁棒性的Adv-nuScenes数据集上，FocalAD表现更优，平均碰撞率比DiffusionDrive降低41.9%，比SparseDrive降低15.6%。

</details>


### [187] [Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention](https://arxiv.org/abs/2506.11445)
**中文标题：基于局部状态注意力的多自动驾驶车辆控制解决高速公路冲突**

*Xuan Duy Ta,Bang Giang Le,Thanh Ha Le,Viet Cuong Ta*

主要分类: cs.AI

摘要简述: 本文提出了一种基于局部状态注意力的多自动驾驶车辆控制方法，用于解决混合交通环境中的冲突问题，显著提升了高速公路合并场景的效率。


<details>
  <summary>详细信息</summary>
研究动机: 在混合交通环境中，自动驾驶车辆需要适应人类驾驶车辆和其他突发情况。现有的多智能体强化学习方法在解决局部冲突和应对随机事件时表现不佳，因此需要一种更有效的方法来提升自动驾驶车辆的协同能力。

研究方法: 本文提出了一种局部状态注意力模块，通过自注意力机制压缩附近车辆的关键信息，以解决交通冲突。该方法在模拟的高速公路合并场景中测试，优先处理其他车辆的信息以优化合并过程。

研究结果: 实验结果表明，该方法在高密度交通环境下显著提升了合并效率，优于现有的基线方法。

研究结论: 局部状态注意力模块能够有效解决多自动驾驶车辆在混合交通环境中的冲突问题，为未来的自动驾驶协同控制提供了新的思路。

中文摘要: 在混合交通环境中，自动驾驶车辆需要适应人类驾驶车辆和其他突发驾驶情况。这种场景可以建模为一个多智能体强化学习（MARL）环境，其中自动驾驶车辆之间具有完全合作奖励。尽管多智能体近端策略优化等方法在训练MARL任务时可能有效，但它们通常无法解决智能体之间的局部冲突，并且难以泛化到随机事件。本文提出了一种局部状态注意力模块，用于辅助输入状态表示。该模块通过自注意力算子压缩附近车辆的关键信息，以解决交通冲突。通过模拟高速公路合并场景（以优先车辆为突发事件），我们的方法能够优先处理其他车辆的信息以优化合并过程。实验结果表明，与现有基线方法相比，该方法在高密度交通环境下显著提升了合并效率。

</details>


### [188] [Structure-Aware Automatic Channel Pruning by Searching with Graph Embedding](https://arxiv.org/abs/2506.11469)
**中文标题：基于图嵌入搜索的结构感知自动通道剪枝**

*Zifan Liu,Yuan Cao,Yanwei Yu,Heng Qi,Jie Gui*

主要分类: cs.AI

摘要简述: 本文提出了一种基于图卷积网络（GCN）的结构感知自动通道剪枝（SACP）框架，通过建模网络拓扑结构实现全局通道重要性评估，显著提升了剪枝效率和模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有通道剪枝方法多依赖局部启发式或权重标准，无法捕捉网络全局结构依赖，导致剪枝决策次优且模型性能下降。本文旨在解决这一问题。

研究方法: 提出SACP框架，利用GCN建模网络拓扑结构并学习通道全局重要性；通过搜索方法动态调整剪枝率组合，实现拓扑感知的自动剪枝。

研究结果: 在CIFAR-10和ImageNet数据集上的实验表明，SACP在压缩效率和精度保持上优于现有剪枝方法。

研究结论: SACP通过全局结构建模和自动剪枝策略，显著提升了剪枝效果，为资源受限设备的模型部署提供了高效解决方案。

中文摘要: 通道剪枝是减少深度神经网络计算开销的强大技术，适用于资源受限设备的高效部署。然而，现有剪枝方法多依赖局部启发式或基于权重的标准，无法捕捉网络内的全局结构依赖，导致剪枝决策次优且模型性能下降。为解决这些问题，我们提出了一种新颖的结构感知自动通道剪枝（SACP）框架，利用图卷积网络（GCN）建模网络拓扑并学习每个通道的全局重要性。通过编码网络内的结构关系，我们的方法实现了拓扑感知的剪枝，且完全自动化，减少了人工干预。我们将剪枝率组合限制在特定空间，其中组合数量可动态调整，并使用基于搜索的方法确定最优剪枝率组合。在基准数据集（CIFAR-10、ImageNet）和多种模型（ResNet、VGG16）上的大量实验表明，SACP在压缩效率和精度保持上优于现有剪枝方法。

</details>


### [189] [Reviving DSP for Advanced Theorem Proving in the Era of Reasoning Models](https://arxiv.org/abs/2506.11487)
**中文标题：在推理模型时代复兴DSP以实现高级定理证明**

*Chenrui Cao,Liangcheng Song,Zenan Li,Xinyi Le,Xian Zhang,Hui Xue,Fan Yang*

主要分类: cs.AI

摘要简述: 本文提出DSP+框架，通过精细化的神经符号协同，无需额外训练即可在定理证明中达到与现有RL方法相当的性能，并成功解决多个未解问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前定理证明领域依赖大规模RL训练，但研究发现无需训练的神经符号协同方法也能取得类似效果，因此提出改进版DSP+框架。

研究方法: DSP+框架分为三个阶段：(1)草稿阶段生成简洁子目标；(2)草图阶段自动形式化并屏蔽错误；(3)证明阶段结合符号搜索与步进证明器。

研究结果: DSP+在miniF2F、ProofNet和PutnamBench上分别解决80.7%、32.8%和24个问题，并首次解决imo_2019_p1问题，同时发现miniF2F中的形式化错误。

研究结论: DSP+展示了无需RL训练的经典推理模式的潜力，其组件将开源，推动定理证明领域发展。

中文摘要: 近期如DeepSeek-Prover-V2-671B和Kimina-Prover-Preview-72B的进展表明，基于强化学习的大规模训练在自动定理证明中占据主导趋势。然而，我们发现即使无需训练，通过精心协调现成的推理模型和战术步进证明器，也能达到类似性能。本文提出DSP+，即Draft、Sketch和Prove框架的改进版，其特点是对每个阶段进行细粒度神经符号增强：(1)草稿阶段提示推理模型生成简洁自然语言子目标；(2)草图阶段将子目标与假设自动形式化，并根据规则屏蔽语法错误；(3)证明阶段紧密整合符号搜索方法（如Aesop）与步进证明器。实验显示，DSP+在无需额外训练或微调的情况下，分别解决了miniF2F、ProofNet和PutnamBench中644个问题的80.7%、32.8%和24个，且预算更低。DSP+还解决了imo_2019_p1这一此前未解决的IMO问题，并生成人类专家可理解的证明模式，帮助发现形式化错误（如miniF2F中的8处错误）。结果表明，除RL训练外，经典推理模式同样具有潜力。所有组件将开源。

</details>


### [190] [RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning](https://arxiv.org/abs/2506.11555)
**中文标题：RAG+：通过应用感知推理增强检索增强生成**

*Yu Wang,Shiwan Zhao,Ming Fan,Zhihu Wang,Yubo Zhang,Xicheng Zhang,Zhengfan Wang,Heyuan Huang,Ting Liu*

主要分类: cs.AI

摘要简述: 本文提出RAG+，通过引入应用感知推理增强检索增强生成（RAG），在知识密集型任务中显著提升大型语言模型（LLMs）的表现。实验证明RAG+在数学、法律和医学领域平均提升3-5%，复杂场景峰值提升7.5%。


<details>
  <summary>详细信息</summary>
研究动机: 现有RAG范式忽略了知识应用的关键认知步骤，导致检索到的知识与任务特定推理之间存在脱节。RAG+旨在填补这一空白，通过结合应用感知推理，使LLMs不仅能获取知识，还能在结构化、目标导向的推理中应用知识。

研究方法: RAG+构建了一个包含知识和应用示例的双重语料库，支持手动或自动生成，并在推理过程中联合检索两者。这种方法使LLMs能够结合相关信息和结构化推理过程，实现更高效的知识应用。

研究结果: 在数学、法律和医学领域的多模型实验中，RAG+平均性能提升3-5%，复杂场景下峰值提升达7.5%，显著优于标准RAG变体。

研究结论: RAG+通过将检索与可操作的应用结合，为知识集成提供了更具认知基础的框架，推动了LLMs的可解释性和能力提升。

中文摘要: 通过检索增强生成（RAG）整合外部知识已成为提升大型语言模型（LLMs）在知识密集型任务中表现的基础方法。然而，现有RAG范式往往忽略了知识应用的认知步骤，导致检索到的事实与任务特定推理之间存在脱节。本文提出RAG+，一种原则性和模块化的扩展方法，显式地将应用感知推理引入RAG流程。RAG+构建了一个包含知识和应用示例的双重语料库（手动或自动生成），并在推理过程中联合检索两者。这一设计使LLMs不仅能获取相关信息，还能在结构化、目标导向的推理过程中应用知识。在数学、法律和医学领域的多模型实验中，RAG+始终优于标准RAG变体，平均提升3-5%，复杂场景峰值提升达7.5%。通过将检索与可操作的应用结合，RAG+为知识集成提供了更具认知基础的框架，是迈向更可解释和更强大LLMs的一步。

</details>


### [191] [Collaborative LLM Inference via Planning for Efficient Reasoning](https://arxiv.org/abs/2506.11578)
**中文标题：基于规划的高效推理协作LLM推断**

*Byeongchan Lee,Jonghoon Lee,Dongyoung Kim,Jaehyung Kim,Jinwoo Shin*

主要分类: cs.AI

摘要简述: 大型语言模型（LLM）在复杂推理任务中表现出色，但高性能模型（如参数超过100B）通常需付费使用，成本高昂；而小型开源模型（如参数小于3B）虽免费但推理能力不足。本文提出一种测试时协作框架，通过规划模型生成问题的高层抽象计划，引导推理模型完成任务，实现大小模型协作，既降低成本又保持高性能。


<details>
  <summary>详细信息</summary>
研究动机: 高性能LLM（如参数超过100B）通常需付费使用，成本高；而小型开源LLM（如参数小于3B）虽免费但推理能力不足。如何在测试时结合两者的优势，成为研究动机。

研究方法: 提出测试时协作框架：规划模型首先生成问题的高层抽象计划，作为轻量级中间结果；推理模型根据计划生成完整解决方案。大小模型轮流担任规划者和推理者，通过多轮协作完成任务。

研究结果: 该方法在保持与高性能专有模型相近准确性的同时，显著减少对付费推理的依赖，验证了规划作为跨模型协作的有效先验。

研究结论: 通过规划引导的协作框架，大小模型能够在测试时高效结合优势，既降低成本又保持高性能，为实际部署提供了可行方案。

中文摘要: 大型语言模型（LLM）在复杂推理任务中表现出色，但高性能模型（如参数超过100B）通常仅通过付费API访问，频繁使用成本过高。相比之下，小型开源LLM（如参数小于3B）可免费本地部署（如单GPU 8G显存），但推理能力不足。这一权衡引发了一个自然问题：小型（免费）和大型（昂贵）模型能否在测试时协作以结合优势？我们提出一种测试时协作框架：规划模型首先生成计划（问题的蒸馏高层抽象），作为轻量级中间结果引导推理模型生成完整解决方案。大小模型轮流担任规划者和推理者，通过多轮协作解决复杂任务。该方法在保持与高性能专有模型相近准确性的同时，显著减少对付费推理的依赖，验证了规划作为实际部署约束下成本感知跨模型推断的有效先验。

</details>


### [192] [VLM@school -- Evaluation of AI image understanding on German middle school knowledge](https://arxiv.org/abs/2506.11604)
**中文标题：VLM@school —— 对德国中学知识中AI图像理解能力的评估**

*René Peinl,Vincent Tischler*

主要分类: cs.AI

摘要简述: 本文介绍了一个新的基准数据集，用于评估视觉语言模型（VLMs）在结合视觉推理与德语学科背景知识的任务中的表现。数据集基于德国中学课程，包含2000多个开放式问题和486张图像。评估显示，即使是表现最佳的模型，整体准确率也不足45%，尤其在音乐、数学和对抗性问题上表现较差。


<details>
  <summary>详细信息</summary>
研究动机: 现有的英语基准数据集常依赖人为困难或脱离上下文的问题，无法真实反映模型在实际多模态理解任务中的表现。本文旨在通过德国中学课程的真实问题，提供一个更贴近实际应用的评估框架，填补非英语环境下VLMs评估的空白。

研究方法: 研究团队从德国中学九个学科（如数学、历史、生物和宗教）的课程中提取问题，构建了包含2000多个开放式问题和486张图像的数据集。评估了13个开源的先进VLMs，重点关注学科特定准确率和对抗性问题的表现。

研究结果: 评估结果显示，所有模型的整体准确率均低于45%，在音乐、数学和对抗性问题上的表现尤为不佳。此外，模型在流行基准测试中的表现与实际多模态理解能力存在显著差异。

研究结论: 中学水平的任务为测试VLMs提供了有意义且未被充分利用的途径，尤其是在非英语环境中。该数据集和评估协议为未来AI系统的视觉和语言推理能力提供了严格的测试平台。

中文摘要: 本文介绍了一个新颖的基准数据集，旨在评估视觉语言模型（VLMs）在结合视觉推理与德语学科背景知识的任务中的能力。与广泛使用的英语基准数据集不同，后者常依赖人为困难或脱离上下文的问题，而本数据集基于德国中学九个学科（包括数学、历史、生物和宗教）的真实课程内容。基准测试包含2000多个开放式问题，基于486张图像，确保模型必须整合视觉解释与事实推理，而非依赖表面的文本线索。我们评估了13个开源的先进VLMs，涵盖多个维度，包括学科特定准确率和对抗性问题的表现。结果显示，即使是表现最强的模型，整体准确率也不足45%，在音乐、数学和对抗性设置中表现尤为不佳。此外，结果揭示了在流行基准测试中的成功与实际多模态理解能力之间的显著差异。我们得出结论，中学水平的任务为测试VLMs提供了有意义且未被充分利用的途径，尤其是在非英语环境中。该数据集和评估协议为更好地理解和改进未来AI系统的视觉与语言推理能力提供了严格的测试平台。

</details>


### [193] [Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization](https://arxiv.org/abs/2506.11712)
**中文标题：通过理论一致的对称多模态偏好优化缓解幻觉**

*Wenqi Liu,Xuemeng Song,Jiaxi Li,Yinwei Wei,Na Zheng,Jianhua Yin,Liqiang Nie*

主要分类: cs.AI

摘要简述: 本文提出了一种对称多模态偏好优化方法（SymMPO），通过直接偏好监督和对称偏好学习，有效减少多模态大语言模型的幻觉问题，并在多个基准测试中表现出优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在减少多模态大语言模型（MLLMs）的幻觉问题时，存在优化目标函数不严谨和偏好监督间接的局限性。本文旨在通过对称偏好学习和直接偏好监督，提升视觉理解能力并减少幻觉。

研究方法: 提出对称多模态偏好优化（SymMPO），结合直接偏好监督（响应对）和对称偏好学习，同时引入偏好边际一致性损失，定量调节对称偏好对之间的偏好差距。

研究结果: 在五个基准测试上的综合评估表明，SymMPO在减少MLLMs幻觉方面表现优越，验证了其有效性。

研究结论: SymMPO通过对称偏好学习和直接偏好监督，显著减少了多模态大语言模型的幻觉问题，为相关研究提供了新思路。

中文摘要: 直接偏好优化（DPO）已成为缓解多模态大语言模型（MLLMs）幻觉问题的有效方法。尽管现有方法通过视觉导向的对比目标增强了MLLMs对视觉输入的注意力并减少了幻觉，但其优化目标函数不严谨且偏好监督间接。为解决这些问题，我们提出了一种对称多模态偏好优化（SymMPO），通过直接偏好监督（即响应对）进行对称偏好学习以增强视觉理解，同时保持与标准DPO的严格理论一致性。除传统的序数偏好学习外，SymMPO还引入了偏好边际一致性损失，定量调节对称偏好对之间的偏好差距。在五个基准测试上的综合评估表明，SymMPO具有优越性能，验证了其在减少MLLMs幻觉方面的有效性。

</details>


### [194] [Relational GNNs Cannot Learn $C_2$ Features for Planning](https://arxiv.org/abs/2506.11721)
**中文标题：关系图神经网络无法学习用于规划的$C_2$特征**

*Dillon Z. Chen*

主要分类: cs.AI

摘要简述: 本文证明关系图神经网络（R-GNNs）无法学习由$C_2$特征定义的价值函数，尽管其理论动机基于$C_2$的表达能力。同时，指出了其他GNN架构可能更适合此类任务。


<details>
  <summary>详细信息</summary>
研究动机: 关系图神经网络（R-GNNs）被提出用于学习规划问题中的价值函数，其理论依据是GNN的表达能力与$C_2$逻辑的关联。然而，本文质疑R-GNNs是否真的能学习由$C_2$特征定义的价值函数。

研究方法: 通过理论分析，本文探讨了R-GNNs在规划问题中的表达能力，并比较了其与$C_2$特征的关系。同时，回顾了其他GNN架构在类似任务中的表现。

研究结果: 研究发现，尽管R-GNNs的理论动机与$C_2$相关，但其无法学习由$C_2$特征定义的价值函数。此外，本文指出了其他GNN架构可能更适合此类任务。

研究结论: 本文揭示了R-GNNs在规划问题中的局限性，并建议探索其他GNN架构以更好地学习$C_2$特征定义的价值函数。

中文摘要: 关系图神经网络（R-GNNs）是一种基于GNN的方法，用于学习能够泛化到规划领域中未见问题的价值函数。R-GNNs的理论动机源于GNN的表达能力与$C_2$（带计数功能的两变量一阶逻辑）之间的已知联系。在规划问题中，$C_2$特征指的是由规划领域的一元和二元谓词定义的$C_2$公式集合。某些规划领域的最优价值函数可以分解为$C_2$特征的算术表达式。本文表明，与实证结果相反，R-GNNs无法学习由$C_2$特征定义的价值函数。同时，我们指出了其他GNN架构可能更适合学习此类价值函数。

</details>


### [195] [Causal Effect Identification in Heterogeneous Environments from Higher-Order Moments](https://arxiv.org/abs/2506.11756)
**中文标题：从高阶矩中识别异质环境下的因果效应**

*Yaroslav Kivva,Sina Akbari,Saber Salehkaleybar,Negar Kiyavash*

主要分类: cs.AI

摘要简述: 本文研究了在存在潜在混杂变量的情况下，如何估计处理变量对结果的因果效应。通过多环境数据，证明了因果效应在特定条件下的可识别性，并提出了一种基于矩的估计算法。同时，证明了如果潜在变量和处理变量的外生噪声分布同时变化，可识别性将丧失。最后，提出了识别数据生成机制参数变化的方法，并通过合成数据实验验证了方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 在因果推断中，潜在混杂变量的存在可能导致因果效应估计的偏差。本文旨在解决这一问题，通过利用多环境数据，探索因果效应的可识别性，并提出有效的估计方法。

研究方法: 首先，证明了在目标因果效应跨环境不变的情况下，因果效应是可识别的。其次，提出了一种基于矩的算法，用于估计因果效应，仅需数据生成机制中单个参数跨环境变化。最后，设计了一种识别参数变化的方法。

研究结果: 实验结果表明，所提出的方法在合成数据上表现良好，能够准确识别因果效应。同时，证明了如果潜在变量和处理变量的外生噪声分布同时变化，因果效应将不可识别。

研究结论: 本文通过多环境数据和矩方法，解决了潜在混杂变量下的因果效应估计问题，为实际应用提供了理论支持和实用工具。

中文摘要: 我们研究了在存在潜在混杂变量的情况下，如何估计处理变量对结果的因果效应。首先，我们证明了当数据来自多个环境且目标因果效应在这些环境中保持不变时，因果效应在特定条件下是可识别的。其次，我们提出了一种基于矩的算法，用于估计因果效应，只要数据生成机制中仅有一个参数（无论是外生噪声分布还是两个变量之间的因果关系）跨环境变化。反之，我们证明了如果潜在变量和处理变量的外生噪声分布同时变化，可识别性将丧失。最后，我们提出了一种识别数据生成机制参数变化的方法，并通过合成数据实验评估了所提方法的性能。

</details>


### [196] [On the Performance of LLMs for Real Estate Appraisal](https://arxiv.org/abs/2506.11812)
**中文标题：大型语言模型在房地产评估中的性能研究**

*Margot Geerts,Manon Reusens,Bart Baesens,Seppe vanden Broucke,Jochen De Weerdt*

主要分类: cs.AI

摘要简述: 本研究探讨大型语言模型（LLMs）如何通过优化的上下文学习策略，为房地产评估提供透明且可解释的价格预测，结果显示LLMs在可访问性和解释性上优于传统机器学习模型，但存在对价格区间过度自信和空间推理不足的问题。


<details>
  <summary>详细信息</summary>
研究动机: 房地产市场存在严重的信息不对称问题，本研究旨在探索LLMs如何通过优化的上下文学习策略，为房地产评估提供更透明、可解释的价格预测，从而改善市场透明度。

研究方法: 研究系统评估了多种LLMs在不同国际住房数据集上的表现，比较了零样本、少样本、市场报告增强和混合提示技术，并优化了上下文示例的选择（基于特征相似性和地理邻近性）。

研究结果: LLMs能够有效利用房屋特征（如面积和设施）生成有意义的价格预测，其解释性与最先进模型一致，但存在对价格区间过度自信和空间推理能力不足的问题。优化的上下文示例显著提升了LLM性能。

研究结论: LLMs在房地产评估中具有潜力，能够提升透明度和可解释性，但需注意其局限性。研究为结构化预测任务提供了实用的提示优化指导。

中文摘要: 房地产市场对全球经济至关重要，但存在严重的信息不对称问题。本研究探讨了大型语言模型（LLMs）如何通过优化的上下文学习（ICL）策略，生成具有竞争力且可解释的房价预测，从而普及房地产洞察。我们系统评估了领先的LLMs在多样化国际住房数据集上的表现，比较了零样本、少样本、市场报告增强和混合提示技术。结果显示，LLMs能有效利用房屋特征（如面积和设施）生成有意义的预测。尽管传统机器学习模型在预测准确性上仍占优势，但LLMs提供了更易访问、交互性强且可解释的替代方案。虽然其自我解释需谨慎解读，但LLMs的解释与最先进模型一致，验证了其可信度。基于特征相似性和地理邻近性精心选择的上下文示例显著提升了LLM性能，但LLMs在价格区间过度自信和空间推理能力上仍有不足。我们通过提示优化为结构化预测任务提供了实用指导。研究结果凸显了LLMs在提升房地产评估透明度和为利益相关者提供可操作洞察方面的潜力。

</details>


### [197] [Revealing Political Bias in LLMs through Structured Multi-Agent Debate](https://arxiv.org/abs/2506.11825)
**中文标题：通过结构化多代理辩论揭示大型语言模型的政治偏见**

*Aishwarya Bandaru,Fabian Bindley,Trevor Bluth,Nandini Chavda,Baixu Chen,Ethan Law*

主要分类: cs.AI

摘要简述: 研究发现，大型语言模型（LLMs）在模拟社会行为时表现出政治偏见，中立模型倾向于民主党，共和党模型则向中立靠拢；性别和辩论形式也会影响模型态度。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）被广泛用于模拟社会行为，但其政治偏见及在辩论中的互动动态尚未充分研究。本文旨在探讨LLM类型和代理性别如何影响政治偏见。

研究方法: 通过结构化多代理辩论框架，让中立、共和党和民主党的美国LLM代理就政治敏感话题展开辩论，并系统性地调整底层LLM、代理性别和辩论形式，分析模型来源和代理角色对政治偏见的影响。

研究结果: 中立代理倾向于民主党，共和党代理向中立靠拢；性别影响代理态度，代理会根据其他代理的性别调整观点；共享政治立场的代理会形成回音室，辩论中态度进一步极化。

研究结论: LLMs在模拟社会行为时表现出显著的政治偏见，性别和辩论形式对态度有重要影响，共享政治立场的代理容易形成回音室。

中文摘要: 大型语言模型（LLMs）越来越多地用于模拟社会行为，但其政治偏见及在辩论中的互动动态尚未充分研究。我们通过结构化多代理辩论框架，让中立、共和党和民主党的美国LLM代理就政治敏感话题展开辩论，系统性地调整底层LLM、代理性别和辩论形式，研究模型来源和代理角色如何影响政治偏见和辩论态度。研究发现：中立代理倾向于民主党，共和党代理向中立靠拢；性别影响代理态度，代理会根据其他代理的性别调整观点；与先前研究相反，共享政治立场的代理会形成回音室，辩论中态度进一步极化。

</details>


### [198] [Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment](https://arxiv.org/abs/2506.11880)
**中文标题：解决大语言模型中的偏见：策略及其在公平AI招聘中的应用**

*Alejandro Peña,Julian Fierrez,Aythami Morales,Gonzalo Mancera,Miguel Lopez,Ruben Tolosana*

主要分类: cs.AI

摘要简述: 本文分析了基于Transformer的大语言模型（LLMs）在学习数据中的人口统计偏见方面的能力，并以AI自动招聘为例，提出了一种减少性别信息的隐私增强框架，以降低最终工具的偏见行为。实验验证了该框架在防止系统复制数据偏见方面的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，大语言模型（LLMs）在高风险场景中的应用日益增多，但其存在人口统计偏见、问责制和隐私等伦理问题。本文旨在研究LLMs学习数据偏见的能力，并以AI自动招聘为案例，探索减少偏见的策略。

研究方法: 本文提出了一种隐私增强框架，通过减少学习流程中的性别信息来降低偏见行为。实验基于两种不同的LLMs，分析了数据偏见对系统的影响，并验证了所提框架的有效性。

研究结果: 实验表明，数据偏见对基于LLMs的系统有显著影响，而提出的隐私增强框架能有效防止系统复制数据中的偏见行为。

研究结论: 本文通过案例研究和实验验证，证明了隐私增强框架在减少LLMs偏见方面的潜力，为公平AI工具的开发提供了实用策略。

中文摘要: 近年来，语言技术在高风险场景中的应用不断增加，主要得益于大语言模型（LLMs）的成功。然而，尽管LLMs表现出色，但其仍面临人口统计偏见、问责制和隐私等伦理问题。本研究旨在分析基于Transformer的系统学习数据中人口统计偏见的能力，并以AI自动招聘为例，提出了一种隐私增强框架，通过减少学习流程中的性别信息来降低最终工具的偏见行为。实验分析了数据偏见对基于两种不同LLMs的系统的影响，以及所提框架如何有效防止训练系统复制数据中的偏见。

</details>


### [199] [Towards a Cascaded LLM Framework for Cost-effective Human-AI Decision-Making](https://arxiv.org/abs/2506.11887)
**中文标题：面向成本效益的人类-AI决策的级联LLM框架**

*Claudio Fanconi,Mihaela van der Schaar*

主要分类: cs.AI

摘要简述: 本文提出了一种级联LLM框架，通过自适应任务分配（基础模型、大模型和人类专家）平衡预测准确性、成本和决策信心，并在问答任务中验证了其高效性和成本优势。


<details>
  <summary>详细信息</summary>
研究动机: 人类与AI协同决策需要平衡预测正确性、知识成本和决策信心。现有方法往往无法同时优化这三者，因此需要一种自适应任务分配框架以提高效率和降低成本。

研究方法: 方法分为两阶段：1) 延迟策略根据置信度决定是否接受基础模型的答案或调用大模型重新生成；2) 弃权策略判断是否需要人类干预。框架还引入在线学习机制，利用人类反馈提升决策质量。

研究结果: 在通用问答（ARC-Easy和ARC-Challenge）和医学问答（MedQA和MedMCQA）任务中，级联策略在多数情况下优于单模型基线，同时降低了成本并提供了更优的弃权处理方式。

研究结论: 级联LLM框架通过自适应任务分配和在线学习，显著提升了人类-AI协同决策的效率、准确性和成本效益。

中文摘要: 有效的人类-AI决策需要平衡三个关键因素：预测的准确性、知识和推理复杂性的成本，以及是否放弃自动化答案或引入人类专家的信心。本文提出了一种级联LLM决策框架，自适应地将任务分配给多个层级的专家——基础模型生成初始候选答案，能力更强且知识更丰富（但成本更高）的大模型，以及当模型级联放弃时的人类专家。我们的方法分为两个阶段：首先，延迟策略根据置信度分数决定是接受基础模型的答案还是调用大模型重新生成；其次，弃权策略判断级联模型的响应是否足够确定或需要人类干预。此外，我们在框架中引入了在线学习机制，可以利用人类反馈随时间提升决策质量。我们在通用问答（ARC-Easy和ARC-Challenge）和医学问答（MedQA和MedMCQA）任务中验证了该方法。结果表明，我们的级联策略在大多数情况下优于单模型基线，同时降低了成本，并提供了一种处理弃权的原则性方法。

</details>


### [200] [Schema-R1: A reasoning training approach for schema linking in Text-to-SQL Task](https://arxiv.org/abs/2506.11986)
**中文标题：Schema-R1：一种用于Text-to-SQL任务中模式链接的推理训练方法**

*Wuzhenghong Wen,Su Pan,yuwei Sun*

主要分类: cs.AI

摘要简述: 本文提出Schema-R1，一种基于强化学习的推理训练方法，用于提升Text-to-SQL任务中的模式链接能力，通过高质量推理样本构建和监督微调，最终实现10%的过滤准确率提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前Text-to-SQL任务中的模式链接模型采用死记硬背的学习方式，过度优化真实结果而牺牲推理能力。由于高质量推理样本难以获取，本文提出Schema-R1以解决这一问题。

研究方法: Schema-R1包含三个关键步骤：构建小批量高质量推理样本、监督微调用于冷启动初始化，以及基于规则的强化学习训练。

研究结果: 实验结果表明，Schema-R1显著提升了模式链接模型的推理能力，过滤准确率比现有方法提高了10%。

研究结论: Schema-R1通过强化学习方法有效增强了模式链接模型的推理能力，为Text-to-SQL任务提供了更优的解决方案。

中文摘要: 模式链接是Text-to-SQL任务中的关键步骤，旨在根据给定问题准确预测SQL查询所需的表名和列名。然而，当前模式链接模型的微调方法采用死记硬背的学习范式，过度优化真实结果而牺牲推理能力。这一限制源于高质量推理样本在下游任务中难以获取。为此，我们提出Schema-R1，一种基于强化学习的推理模式链接模型。具体而言，Schema-R1包含三个关键步骤：构建小批量高质量推理样本、监督微调用于冷启动初始化，以及基于规则的强化学习训练。最终结果表明，我们的方法有效提升了模式链接模型的推理能力，过滤准确率比现有方法提高了10%。代码已开源：https://github.com/hongWin/Schema-R1/。

</details>


### [201] [Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making](https://arxiv.org/abs/2506.12012)
**中文标题：通过战略游戏追踪大语言模型的推理过程：规划、修正与资源受限决策的框架**

*Xiaopeng Yuan,Xingjian Zhang,Ke Xu,Yifan Xu,Lijun Yu,Jindong Wang,Yushun Dong,Haohan Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种通过战略游戏评估大语言模型（LLMs）推理过程的框架，重点关注规划、修正和资源受限决策三个维度。研究发现，ChatGPT-o3-mini表现最佳，而Qwen-Plus因过度修正和资源使用问题表现较差。


<details>
  <summary>详细信息</summary>
研究动机: 当前对大语言模型的评估多关注最终结果，而忽略了中间推理过程（如规划、修正和资源受限决策）。本文旨在通过战略游戏这一封闭、规则明确的系统，深入评估模型的内部推理行为，以提高其可靠性。

研究方法: 提出一个基于战略游戏的评估框架，定义多个指标（如修正成功率、过度修正风险率、改进斜率和超预算比率）来衡量LLMs在规划、修正和资源受限决策中的表现。通过4320轮对抗测试，对12个领先模型进行了评估。

研究结果: ChatGPT-o3-mini在综合评分中表现最佳，胜率为74.7%，修正成功率为78.6%，改进斜率为0.041。Qwen-Plus因过度修正（风险率81.6%）和资源使用问题，胜率仅为25.6%。研究发现修正频率与成功率呈负相关（Pearson r = -0.51）。

研究结论: 评估LLMs的推理过程（而不仅是最终结果）对理解其行为和改进模型至关重要。战略游戏为这种评估提供了有效环境，未来研究可进一步优化指标和模型表现。

中文摘要: 大语言模型（LLMs）越来越多地用于需要复杂推理的任务。大多数基准测试关注最终结果，但忽略了中间推理步骤（如规划、修正和资源受限决策）。我们认为，衡量这些内部过程对于理解模型行为和提高可靠性至关重要。我们提出使用战略游戏作为自然评估环境：封闭、基于规则的系统，具有明确状态、有限资源和自动反馈。我们引入了一个框架，从三个核心维度评估LLMs：规划、修正和资源受限决策。为实现这一点，我们定义了除胜率外的其他指标，包括过度修正风险率、修正成功率、改进斜率和超预算比率。在12个领先模型的4320轮对抗测试中，ChatGPT-o3-mini获得最高综合评分，胜率为74.7%，修正成功率为78.6%，改进斜率为0.041。相比之下，Qwen-Plus尽管过度修正风险率为81.6%，但胜率仅为25.6%，主要原因是资源使用过度。我们还观察到过度修正风险率与修正成功率呈负相关（Pearson r = -0.51, p = 0.093），表明频繁修正并不总能改善结果。我们的研究强调了评估LLMs的决策过程（而不仅是决策结果）的重要性。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [202] [Upgrade or Switch: Do We Need a New Registry Architecture for the Internet of AI Agents?](https://arxiv.org/abs/2506.12003)
**中文标题：升级还是切换：AI代理互联网是否需要新的注册架构？**

*Ramesh Raskar,Pradyumna Chari,Jared James Grogan,Mahesh Lambe,Robert Lincourt,Raghu Bala,Abhishek Singh,Ayush Chopra,Rajesh Ranjan,Shailja Gupta,Dimitris Stripelis,Maria Gorskikh,Sichao Wang*

主要分类: cs.NI

摘要简述: 本文探讨了AI代理互联网对现有网络基础设施的挑战，分析了升级现有系统或设计全新注册架构的优劣，并提出了混合解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI代理互联网的兴起，现有为人类交互设计的网络基础设施无法满足AI代理的毫秒级发现、即时凭证撤销和加密行为证明等需求，亟需研究是否需要升级或重新设计注册架构。

研究方法: 论文分析了DNS传播延迟、证书撤销扩展性不足和IP地址路由问题等关键失败点，评估了三种解决方案：升级现有系统、设计全新架构和混合注册表。

研究结果: 研究发现，AI代理的需求是质变而非量变，升级方案兼容性强但性能有限，全新架构性能优越但部署周期长，混合方案（集中注册与联邦网状结合）更具潜力。

研究结论: 混合注册架构将成为主流，集中注册用于关键代理，联邦网状结构满足特定用例需求。

中文摘要: 新兴的AI代理互联网对为人类交互设计的现有网络基础设施提出了挑战。与传统网络资源不同，自主AI代理能够发起行动、保持持久状态、生成子代理并直接与对等体协商，这要求毫秒级发现、即时凭证撤销和加密行为证明，超出了当前DNS/PKI的能力范围。本文分析了是升级现有基础设施还是为自主代理设计专用注册架构。我们指出了关键失败点：DNS传播（24-48小时vs.所需的毫秒级）、证书撤销无法扩展到万亿级实体，以及IPv4/IPv6地址不足以支持代理规模的路由。我们评估了三种方法：（1）升级路径，（2）切换选项，（3）混合注册表。通过类比拨号到宽带的过渡，我们发现代理需求是质变而非量变。升级方案兼容性强且部署更快，而全新方案性能更优但需要更长时间才能普及。分析表明，混合方案将兴起，集中注册用于关键代理，联邦网状结构满足特定用例需求。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [203] [Real-World Deployment of a Lane Change Prediction Architecture Based on Knowledge Graph Embeddings and Bayesian Inference](https://arxiv.org/abs/2506.11925)
**中文标题：基于知识图谱嵌入和贝叶斯推理的车道变换预测架构在真实世界中的部署**

*M. Manzour,Catherine M. Elias,Omar M. Shehata,R. Izquierdo,M. A. Sotelo*

主要分类: cs.AR

摘要简述: 本文提出了一种基于知识图谱嵌入（KGE）和贝叶斯推理的车道变换预测系统，并在真实硬件上验证其有效性。系统通过感知模块和预测模块的协同工作，提前3-4秒预测目标车辆的车道变换行为，并通过纵向制动确保安全。


<details>
  <summary>详细信息</summary>
研究动机: 当前车道变换预测研究多局限于仿真或数据集，缺乏实际道路部署的验证。本文旨在填补这一空白，通过真实硬件展示基于KGE和贝叶斯推理的车道变换预测系统的可行性。

研究方法: 系统分为两个模块：(1) 感知模块：感知环境并提取数值特征，将其转换为语言类别后传递给预测模块；(2) 预测模块：利用预训练的KGE和贝叶斯推理模型预测目标车辆行为，并将预测结果转化为纵向制动动作。

研究结果: 真实硬件实验表明，系统能提前3-4秒预测目标车辆的车道变换行为，为自车提供充足反应时间，同时确保目标车辆安全完成车道变换。

研究结论: 本文成功验证了基于KGE和贝叶斯推理的车道变换预测系统在实际道路中的有效性，为自动驾驶安全提供了可靠解决方案。

中文摘要: 近年来，车道变换预测研究取得了显著进展，但大多数研究局限于仿真或数据集结果，算法进步与实际道路部署之间存在差距。本文通过真实硬件展示了一种基于知识图谱嵌入（KGE）和贝叶斯推理的车道变换预测系统，填补了这一空白。此外，自车采用纵向制动动作以确保自身及周围车辆的安全。系统架构包括两个模块：(1) 感知模块：感知环境，提取输入数值特征并将其转换为语言类别，传递给预测模块；(2) 预训练的预测模块：执行KGE和贝叶斯推理模型以预测目标车辆的行驶意图，并将预测结果转化为纵向制动动作。真实硬件实验验证表明，我们的预测系统能提前3-4秒预测目标车辆的车道变换行为，为自车提供充足反应时间，同时确保目标车辆安全完成车道变换。

</details>


### [204] [DPUV4E: High-Throughput DPU Architecture Design for CNN on Versal ACAP](https://arxiv.org/abs/2506.11441)
**中文标题：DPUV4E：面向Versal ACAP的高吞吐量CNN加速DPU架构设计**

*Guoyu Li,Pengbo Zheng,Jian Weng,Enshan Yang*

主要分类: cs.AR

摘要简述: 本文提出了一种名为DPUV4E的高吞吐量DPU架构，专为Versal ACAP设计，用于高效运行CNN。通过优化计算单元和数据流，显著提升了性能和能效，同时大幅减少了资源占用。


<details>
  <summary>详细信息</summary>
研究动机: 卷积神经网络（CNN）在计算机视觉中广泛应用，FPGA因其灵活性和能效成为异构加速系统的关键组件。然而，传统FPGA因片上资源有限难以平衡性能与多功能性。AMD的Versal ACAP虽为AI应用优化，但内存带宽不足限制了AI引擎的理论性能。因此，本文旨在设计一种高效架构以解决这些问题。

研究方法: 本文设计了DPUV4E架构，提供2PE（32.6 TOPS）到8PE（131.0 TOPS）的配置。通过设计Conv PE和DWC PE两种计算单元支持不同计算模式，并优化数据流以利用数据复用机会缓解带宽瓶颈。此外，扩展了PE功能以利用AI引擎执行非卷积操作，减少资源开销。

研究结果: 实验表明，相比传统FPGA设计，DPUV4E的能效提升8.6倍，DSP使用减少95.8%，LUT使用减少44.7%，单批条件下延迟降低至68.5%。在端到端推理中，深度卷积模型吞吐量提升2.2倍，标准模型提升1.3倍。

研究结论: DPUV4E通过高效架构设计和数据流优化，显著提升了Versal ACAP平台的性能和能效，同时大幅降低了资源占用，为CNN加速提供了高效解决方案。

中文摘要: 卷积神经网络（CNN）在计算机视觉应用中仍占据主导地位，而FPGA以其灵活性和高能效成为异构加速系统的关键组件。然而，传统FPGA因片上资源有限，难以平衡性能与多功能性。AMD的Versal ACAP架构专为AI应用设计，集成了AI引擎（AIE）以提供高计算能力，但该平台因内存带宽不足而无法充分发挥AIE的理论性能。本文提出了一种面向Versal架构的DPUV4E设计，提供从2PE（32.6 TOPS）到8PE（131.0 TOPS）的配置。我们设计了两种计算单元Conv PE和DWC PE，以支持不同的计算模式，并通过优化数据流充分利用数据复用机会以缓解带宽瓶颈。此外，我们扩展了每个PE的功能，利用AIE执行非卷积操作，从而减少资源开销。在超过50个模型上的实验表明，与传统FPGA设计的DPU相比，我们的设计能效提升8.6倍，DSP使用减少95.8%，LUT使用减少44.7%，单批条件下延迟降低至68.5%。在端到端推理中，深度卷积模型的吞吐量提升高达2.2倍，标准模型提升高达1.3倍。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [205] [Developing a Dyslexia Indicator Using Eye Tracking](https://arxiv.org/abs/2506.11004)
**中文标题：利用眼动追踪技术开发阅读障碍指标**

*Kevin Cogan,Vuong M. Ngo,Mark Roantree*

主要分类: cs.LG

摘要简述: 本研究利用眼动追踪技术和机器学习算法开发了一种低成本、高准确性的早期阅读障碍检测方法，准确率达88.58%，并通过分层聚类识别了不同严重程度的阅读障碍。


<details>
  <summary>详细信息</summary>
研究动机: 阅读障碍影响全球10%至20%的人口，严重阻碍学习能力，亟需创新且易获取的诊断方法。本研究旨在探索眼动追踪技术结合机器学习作为低成本替代方案的潜力。

研究方法: 通过分析眼动模式（如长时间注视和不规则扫视），提出改进的眼动追踪特征提取方法，并采用随机森林分类器检测阅读障碍，同时应用分层聚类方法区分严重程度。

研究结果: 随机森林分类器检测阅读障碍的准确率达88.58%，分层聚类成功识别了不同严重程度的阅读障碍患者，包括边缘特征人群。

研究结论: 眼动追踪与机器学习结合为非侵入性阅读障碍诊断提供了高准确性和可及性的解决方案，是临床研究的重要进展。

中文摘要: 阅读障碍影响全球约10%至20%的人口，显著削弱学习能力，亟需创新且易获取的诊断方法。本研究探讨了结合眼动追踪技术与机器学习算法作为低成本早期阅读障碍检测替代方案的有效性。通过分析包括长时间注视和不规则扫视在内的眼动模式，我们提出了一种改进的眼动追踪特征提取方法。随后采用随机森林分类器检测阅读障碍，准确率达88.58%。此外，应用分层聚类方法识别了阅读障碍的不同严重程度。该分析涵盖了多种人群和场景，展示了该技术在非侵入性条件下识别阅读障碍患者（包括边缘特征人群）的潜力。眼动追踪与机器学习的结合为诊断过程带来了显著进步，为临床研究提供了一种高准确性和易获取的方法。

</details>


### [206] [Data Science: a Natural Ecosystem](https://arxiv.org/abs/2506.11010)
**中文标题：数据科学：一个自然生态系统**

*Emilio Porcu,Roy El Moukari,Laurent Najman,Francisco Herrera,Horst Simon*

主要分类: cs.LG

摘要简述: 本文提出了一种将数据科学视为自然生态系统的整体视角，强调了数据宇宙中的5D复杂性（数据结构、领域、基数、因果性和伦理）与数据生命周期的结合。作者定义了特定学科驱动的数据科学和泛数据科学，并指出计算与基础数据科学之间的潜在分歧，建议通过严格评估数据发现的有用性来缓解这一问题。


<details>
  <summary>详细信息</summary>
研究动机: 论文的动机在于提供一个全面的数据科学视角，将其视为一个自然生态系统，以应对数据宇宙中的复杂性和数据生命周期中的挑战。作者希望通过定义特定学科驱动的数据科学和泛数据科学，促进数据科学的整合与发展。

研究方法: 作者采用了一种数据中心的视角，将数据科学分为计算数据科学和基础数据科学，并通过语义分析定义了特定学科驱动的数据科学和泛数据科学。此外，作者提出了评估数据发现有用性的方法，以解决计算与基础数据科学之间的潜在分歧。

研究结果: 研究结果表明，数据科学可以作为一个自然生态系统来理解，其中数据代理的任务由特定目标驱动。作者还揭示了计算与基础数据科学之间的潜在分歧，并提出了通过严格评估数据发现的有用性来缓解这一分歧的建议。

研究结论: 本文的结论是，数据科学作为一个自然生态系统，需要整合特定学科与基本数据科学。同时，作者强调了对数据发现有用性进行严格评估的重要性，以避免计算与基础数据科学之间的分歧。

中文摘要: 本文提供了一种全面的（以数据为中心的）视角，将我们所称的基本数据科学视为一个自然生态系统，其挑战和任务源于数据宇宙及其5D复杂性（数据结构、领域、基数、因果性和伦理）与数据生命周期的多重结合。数据代理根据特定目标执行任务。数据科学家是从数据代理及其行为的逻辑组织中抽象出的实体。数据科学家面临的挑战是根据任务定义的。我们定义了特定学科驱动的数据科学，进而定义了泛数据科学，这是一个将特定学科与基本数据科学整合的自然生态系统。我们从语义上将基本数据科学分为计算数据科学和基础数据科学。我们指出，计算与基础数据科学之间存在严重的分歧风险，尤其是如果没有方法评估数据宇宙发现是否有用。我们建议，通过严格评估数据发现的有用性，可能会缓解这种分歧。

</details>


### [207] [Not All Clients Are Equal: Personalized Federated Learning on Heterogeneous Multi-Modal Clients](https://arxiv.org/abs/2506.11024)
**中文标题：并非所有客户端都平等：异构多模态客户端的个性化联邦学习**

*Minhyuk Seo,Taeheon Kim,Hankook Lee,Jonghyun Choi,Tinne Tuytelaars*

主要分类: cs.LG

摘要简述: 本文提出了一种针对异构多模态客户端的个性化联邦学习方法，通过任务相似性感知的模型聚合和维度不变模块，解决了数据与模型异构性问题，并在新基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 基础模型在多模态任务中表现出色，但集中式训练存在隐私和高传输成本问题。联邦学习（FL）虽提供分布式解决方案，但个性化联邦学习（PFL）在真实场景中仍面临数据和模型异构性的挑战。本文旨在解决这些问题。

研究方法: 针对数据异构性，提出任务相似性感知的模型聚合方法，为每个客户端提供定制化全局模型；针对模型异构性，提出维度不变模块，实现异构模型间的知识共享。

研究结果: 实验验证表明，该方法在个性化和泛化能力上均优于现有技术，并在包含40个任务的异构多模态PFL基准测试中表现优异。

研究结论: 本文提出的方法有效解决了PFL中的数据与模型异构性问题，为真实场景中的个性化联邦学习提供了实用解决方案。

中文摘要: 基础模型在多模态任务中表现出卓越能力，但其集中式训练引发了隐私问题和高传输成本。相比之下，联邦学习（FL）提供了一种无需共享数据的分布式替代方案。近年来，随着为不同用户目的个性化AI模型的需求增长，个性化联邦学习（PFL）应运而生。PFL允许每个客户端利用其他客户端的知识进一步适应用户偏好，同样无需共享数据。尽管潜力巨大，大多数PFL研究仍局限于模拟环境，忽视了现实场景中的数据与模型异构性。本文首先考虑大规模数据异构性，在一个包含40个任务且具有真实数据分布变化的多模态PFL新基准上进行评估。其次，我们考虑模型异构性，不假设所有客户端共享相似模型架构。为解决数据异构性，提出了一种任务相似性感知的模型聚合方法，为每个客户端提供定制化全局模型；针对模型异构性，提出了一种维度不变模块，实现异构模型间的知识共享。实验验证表明，所提方法在个性化和泛化能力上均优于现有技术。

</details>


### [208] [When Algorithms Play Favorites: Lookism in the Generation and Perception of Faces](https://arxiv.org/abs/2506.11025)
**中文标题：当算法偏爱时：人脸生成与感知中的外貌主义**

*Miriam Doh,Aditya Gulati,Matei Mancas,Nuria Oliver*

主要分类: cs.LG

摘要简述: 本文探讨了算法如何基于外貌偏好（算法外貌主义）影响合成人脸生成和性别分类模型，发现文本到图像系统将吸引力与无关正面特质（如智力、可信度）关联，且性别分类模型对‘不太吸引人’的面孔（尤其是非白人女性）错误率更高，引发数字身份系统的公平性问题。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于揭示算法外貌主义如何影响合成人脸生成和性别分类模型，尤其是外貌偏好对公平性的潜在影响。

研究方法: 通过对13,200张合成生成的人脸进行实验，分析文本到图像系统和性别分类模型的表现，探讨外貌与特质关联及分类错误率。

研究结果: 研究发现：(1)文本到图像系统倾向于将面部吸引力与无关正面特质（如智力、可信度）关联；(2)性别分类模型对‘不太吸引人’的面孔（尤其是非白人女性）错误率更高。

研究结论: 结论指出算法外貌主义可能导致数字身份系统的不公平性，需进一步关注和解决。

中文摘要: 本文研究了合成生成的人脸和基于机器学习的性别分类算法如何受到算法外貌主义（基于外貌的偏好）的影响。通过对13,200张合成生成的人脸进行实验，我们发现：(1)文本到图像（T2I）系统倾向于将面部吸引力与无关的正面特质（如智力和可信度）关联；(2)性别分类模型在‘不太吸引人’的面孔上（尤其是非白人女性）表现出更高的错误率。这些结果引发了关于数字身份系统公平性的担忧。

</details>


### [209] [From Reasoning to Code: GRPO Optimization for Underrepresented Languages](https://arxiv.org/abs/2506.11027)
**中文标题：从推理到代码：面向低资源语言的GRPO优化**

*Federico Pennino,Bianca Raimondi,Massimo Rondelli,Andrea Gurioli,Maurizio Gabbrielli*

主要分类: cs.LG

摘要简述: 本文提出了一种结合GRPO优化和小规模代码模型的方法，用于提升低资源语言的代码生成能力，实验证明其在逻辑一致性和语法准确性上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 针对低资源语言（如Prolog）因缺乏公开训练数据而难以生成准确可执行代码的问题，本文旨在通过结合推理步骤和强化学习优化，提升代码生成质量。

研究方法: 采用小规模代码版本的Qwen 2.5模型，结合Group Relative Policy Optimization (GRPO)，将推理驱动的反馈直接整合到强化学习循环中，以优化代码生成。

研究结果: 实验表明，该方法在数学逻辑问题基准测试中显著提升了推理质量、代码准确性和逻辑正确性，尤其适用于资源有限的编程语言。

研究结论: 该方法为缺乏大规模训练资源的编程语言提供了一种有效的代码生成解决方案，具有广泛的应用潜力。

中文摘要: 对于公开训练数据有限的编程语言（如Prolog），使用大型语言模型（LLMs）生成准确且可执行的代码具有挑战性。本文提出了一种通用方法，结合小规模代码版本的Qwen 2.5模型与Group Relative Policy Optimization (GRPO)，通过显式推理步骤实现有效的代码生成。以Prolog为例，初始模型在生成可执行代码时面临困难，但经过训练后，通过将推理驱动的反馈直接整合到强化学习循环中，模型成功生成了逻辑一致且语法准确的代码。实验评估使用数学逻辑问题基准测试，结果表明该方法在推理质量、代码准确性和逻辑正确性上均有显著提升，突显了其在缺乏大规模训练资源的编程语言中的广泛应用潜力。

</details>


### [210] [Enhancing Epidemic Forecasting: Evaluating the Role of Mobility Data and Graph Convolutional Networks](https://arxiv.org/abs/2506.11028)
**中文标题：提升传染病预测：评估移动数据与图卷积网络的作用**

*Suhan Guo,Zhenghao Xu,Furao Shen,Jian Zhao*

主要分类: cs.LG

摘要简述: 本研究探讨了移动数据和图卷积网络（GCN）在传染病预测中的作用，发现移动数据和GCN模块对预测性能提升有限，但死亡和住院数据显著提高模型准确性。空间地图与封锁令的相关性表明其可作为敏感的移动指标。


<details>
  <summary>详细信息</summary>
研究动机: 传染病爆发的准确预测对决策至关重要，但现有机器学习算法在真实数据中表现不佳，主要因难以整合移动信息。本研究旨在填补这一空白，探索移动数据和GCN在预测模型中的作用。

研究方法: 采用两阶段方法：首先通过试点研究评估移动数据的重要性，然后在Transformer架构上评估GCN模块的影响。同时比较GCN生成的空间地图与封锁令的相关性。

研究结果: 移动数据和GCN模块对预测性能提升不显著，但死亡和住院数据显著提高模型准确性。空间地图与封锁令存在显著相关性，可作为移动敏感指标。

研究结论: 研究为传染病预测中的移动数据表示提供了新视角，帮助决策者更好应对未来疫情。

中文摘要: 准确预测传染病爆发对决策至关重要。本研究填补了机器学习算法与流行病学应用之间的空白，指出适用于基准数据集的方法在真实数据中表现不佳，主要因难以整合移动信息。我们采用两阶段方法：首先通过试点研究评估移动数据的重要性，然后在Transformer架构上评估图卷积网络（GCN）的影响。结果显示，移动数据和GCN模块对预测性能提升有限，但死亡和住院数据显著提高模型准确性。此外，GCN生成的空间地图与封锁令的比较表明其存在显著相关性，凸显空间地图作为移动敏感指标的潜力。本研究为传染病预测中的移动数据表示提供了新视角，帮助决策者更好应对未来疫情。

</details>


### [211] [Output Scaling: YingLong-Delayed Chain of Thought in a Large Pretrained Time Series Forecasting Model](https://arxiv.org/abs/2506.11029)
**中文标题：输出缩放：大型预训练时间序列预测模型中的延迟链式思维推理**

*Xue Wang,Tian Zhou,Jinyang Gao,Bolin Ding,Jingren Zhou*

主要分类: cs.LG

摘要简述: 本文提出了一种联合预测框架YingLong，通过延迟链式思维推理实现更长输出的高精度时间序列预测，并在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统的时间序列预测方法（直接或递归）存在局限性，本文旨在设计一种新型框架，通过非因果性和延迟链式思维推理提升预测性能。

研究方法: YingLong是一种基于双向注意力编码器的非因果Transformer模型，通过掩码令牌恢复训练，并结合多输入集成降低输出方差。

研究结果: YingLong在ETT和Weather数据集上零样本任务中表现优异，60%以上任务达到最佳性能，并在GIFT-Eval基准测试中显著优于其他模型。

研究结论: YingLong通过延迟链式思维推理和多输入集成显著提升了时间序列预测性能，展示了非因果方法的潜力。

中文摘要: 我们提出了一种与传统直接或递归方法不同的联合预测框架，用于时间序列预测。该框架为我们设计的基础模型YingLong实现了最先进的性能，并揭示了一种新颖的缩放效应：由于非因果方法中的延迟链式思维推理，更长的输出显著提高了模型准确性。YingLong是一种通过掩码令牌恢复训练的非因果双向注意力编码器Transformer，与语言理解任务相比，更有效地对齐生成任务。此外，我们通过多输入集成降低输出方差以提升性能。我们发布了四个参数规模从6M到300M的基础模型，在ETT和Weather数据集的零样本任务中表现出卓越结果，YingLong在60%以上的任务中达到最佳性能。为确保泛化性，我们使用GIFT-Eval基准测试评估了模型，该基准包含7个领域的23个时间序列数据集。YingLong显著优于最佳时间序列基础模型和端到端训练模型，分别提升了14%和44%的排名。预训练的300M模型可在https://huggingface.co/qcw1314/YingLong_300m获取。

</details>


### [212] [Forward Target Propagation: A Forward-Only Approach to Global Error Credit Assignment via Local Losses](https://arxiv.org/abs/2506.11030)
**中文标题：前向目标传播：一种通过局部损失实现全局误差信用分配的前向方法**

*Nazmus Saadat As-Saquib,A N M Nafiz Abeer,Hung-Ta Chien,Byung-Jun Yoon,Suhas Kumar,Su-in Yi*

主要分类: cs.LG

摘要简述: 本文提出了一种名为‘前向目标传播’（FTP）的新方法，用于替代传统的反向传播（BP）算法。FTP通过仅使用前向计算实现局部学习，解决了BP在生物和硬件上的局限性，并在多个任务中表现出与BP相当的准确性，同时提升了计算效率和硬件兼容性。


<details>
  <summary>详细信息</summary>
研究动机: 反向传播（BP）算法虽然广泛应用，但在生物合理性和硬件实现上存在局限性，如对称权重、非局部信用分配等问题。本文旨在提出一种更高效、更生物合理的替代方案。

研究方法: FTP通过两次前向传播替代反向传播，利用前馈计算估计层间目标，无需对称反馈权重或可学习逆函数，实现了模块化和局部学习。

研究结果: FTP在全连接网络、CNN和RNN上表现优异，在MNIST、CIFAR10和CIFAR100等任务中与BP准确性相当，且在低精度量化和硬件约束下优于BP，计算效率显著高于其他生物启发方法。

研究结论: FTP以其低计算开销、纯前向特性和硬件兼容性，为高效能设备学习和神经形态计算提供了有前景的方向。

中文摘要: 训练神经网络传统上依赖于反向传播（BP），这是一种基于梯度的算法，尽管其广泛成功，但在生物和硬件视角上存在关键限制，包括对称权重的反向误差传播、非局部信用分配以及反向传递期间的活动冻结。我们提出了前向目标传播（FTP），这是一种生物合理且计算高效的替代方案，用第二次前向传递取代反向传递。FTP仅通过前馈计算估计层间目标，无需对称反馈权重或可学习逆函数，从而实现了模块化和局部学习。我们在全连接网络、CNN和RNN上评估FTP，展示了在MNIST、CIFAR10和CIFAR100上与BP相当的准确性，以及在序列任务中对长期依赖关系的有效建模。此外，FTP在量化低精度和新兴硬件约束下优于BP，同时显著提升了其他生物启发方法（如目标传播变体和纯前向学习算法）的效率。凭借其最小的计算开销、纯前向特性和硬件兼容性，FTP为高效能设备学习和神经形态计算提供了有前景的方向。

</details>


### [213] [Task-aligned prompting improves zero-shot detection of AI-generated images by Vision-Language Models](https://arxiv.org/abs/2506.11031)
**中文标题：任务对齐提示通过视觉语言模型提升AI生成图像的零样本检测性能**

*Zoher Kachwala,Danishjeet Singh,Danielle Yang,Filippo Menczer*

主要分类: cs.LG

摘要简述: 本文提出了一种名为zero-shot-s²的任务对齐提示方法，显著提升了预训练视觉语言模型（VLMs）在零样本检测AI生成图像中的性能，无需微调即可实现8%-29%的Macro F1分数提升，并在多样化的数据集和模型上表现出强泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成图像的真实性不断提高，其潜在滥用问题引发广泛关注。传统监督检测方法依赖大规模标注数据集且难以泛化到多样化的生成器。本文旨在探索预训练视觉语言模型（VLMs）在零样本检测AI生成图像中的应用潜力。

研究方法: 研究提出了一种任务对齐提示方法zero-shot-s²，通过在模型响应前添加特定提示（如“让我们检查风格和合成伪影”）来引导模型进行更聚焦的推理。该方法无需微调，适用于多种预训练VLMs。

研究结果: 实验表明，zero-shot-s²在两种广泛使用的开源模型上提升了8%-29%的Macro F1分数，并在涵盖人脸、物体和动物的多样化数据集上表现出强泛化能力。此外，该方法在不同模型规模下也表现稳健，且优于链式思维提示。

研究结论: 任务对齐提示能够激发VLMs的潜在能力（如检测AI生成图像），提供了一种简单、可泛化且可解释的替代监督方法。研究还发现，自一致性（聚合多样化推理路径的答案）在此任务中同样有效。

中文摘要: 随着图像生成器生成的图像越来越逼真，对其潜在滥用的担忧也在增加。监督检测依赖于大规模标注数据集，且难以泛化到多样化的生成器。本文研究了预训练视觉语言模型（VLMs）在零样本检测AI生成图像中的应用。尽管现成的VLMs表现出一定的任务特定推理能力，且链式思维提示能带来提升，但我们发现任务对齐提示能引发更聚焦的推理，并显著提升性能而无需微调。具体而言，在模型响应前添加短语“让我们检查风格和合成伪影”（我们称之为zero-shot-s²），可将两种广泛使用的开源模型的Macro F1分数提升8%-29%。这些提升在涵盖人脸、物体和动物的三个多样化数据集上保持一致，涉及16种不同生成器的图像，表现出强泛化能力。我们进一步在三种不同规模的模型上评估该方法，发现大多数数据集-模型组合均有改进，表明其对模型规模的稳健性。令人惊讶的是，自一致性（一种在语言推理中观察到的行为，即聚合多样化推理路径的答案能提升性能）在此任务中同样成立。即使如此，zero-shot-s²在大多数情况下仍优于链式思维提示，表明其能引发更有用的多样性。我们的研究表明，任务对齐提示能激发VLMs的潜在能力（如检测AI生成图像），并提供了一种简单、可泛化且可解释的替代监督方法。代码已公开在GitHub：https://github.com/osome-iu/Zero-shot-s2.git。

</details>


### [214] [Runtime Safety through Adaptive Shielding: From Hidden Parameter Inference to Provable Guarantees](https://arxiv.org/abs/2506.11033)
**中文标题：通过自适应屏蔽实现运行时安全：从隐藏参数推断到可证明的保证**

*Minjae Kwon,Tyler Ingebrand,Ufuk Topcu,Lu Feng*

主要分类: cs.LG

摘要简述: 本文提出了一种运行时自适应屏蔽机制，通过实时推断隐藏参数（如机器人质量分布或摩擦力）来保障强化学习的安全性。该方法结合功能编码器和共形预测，动态调整策略并满足概率安全保证，显著减少安全违规且计算开销低。


<details>
  <summary>详细信息</summary>
研究动机: 隐藏参数（如机器人的质量分布或摩擦力）的变异性在执行过程中可能引发安全风险。为了解决这一问题，本文旨在开发一种运行时屏蔽机制，以实时推断隐藏参数并动态调整策略，从而确保强化学习的安全性。

研究方法: 基于约束隐藏参数马尔可夫决策过程的形式化框架，本文提出了一种运行时屏蔽机制。通过功能编码器实时从观测中推断隐藏参数，并结合共形预测处理不确定性。屏蔽机制通过预测未来安全风险（如障碍物接近）约束动作空间，确保策略的动态适应性。

研究结果: 实验表明，该方法在多种隐藏参数变化的环境中显著减少了安全违规行为，并表现出强大的分布外泛化能力。同时，运行时计算开销极低，且满足概率安全保证。

研究结论: 本文提出的自适应屏蔽机制不仅能够实时推断隐藏参数并动态调整策略，还能提供概率安全保证，显著提升强化学习的安全性，适用于复杂多变的环境。

中文摘要: 隐藏参数（如机器人的质量分布或摩擦力）的变异性在执行过程中可能引发安全风险。我们为强化学习开发了一种运行时屏蔽机制，基于约束隐藏参数马尔可夫决策过程的形式化框架。功能编码器能够从观测中实时推断隐藏参数，使屏蔽机制和底层策略能够在线适应。屏蔽机制通过预测未来安全风险（如障碍物接近）约束动作空间，并利用共形预测处理不确定性。我们证明，所提出的机制满足概率安全保证，并在安全合规策略集合中生成最优策略。在多种隐藏参数变化的环境中的实验表明，该方法显著减少了安全违规行为，并表现出强大的分布外泛化能力，同时运行时开销极低。

</details>


### [215] [CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2506.11034)
**中文标题：CausalVLBench：评估大型视觉语言模型中的视觉因果推理能力**

*Aneesh Komanduri,Karuna Bhaila,Xintao Wu*

主要分类: cs.LG

摘要简述: 本文介绍了CausalVLBench，一个用于评估大型视觉语言模型（LVLMs）在多模态上下文学习中视觉因果推理能力的综合基准。该基准包含三个代表性任务：因果结构推断、干预目标预测和反事实预测。研究评估了当前最先进的开源LVLMs在这些任务中的表现，揭示了其优势和不足。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）在因果推理任务（如因果发现和反事实推理）中表现出潜力，但大型视觉语言模型（LVLMs）在视觉因果推理任务中的能力尚未得到充分研究。本文旨在填补这一空白，提供一个全面的基准来评估LVLMs的视觉因果推理能力。

研究方法: 研究提出了CausalVLBench基准，包含三个任务：因果结构推断、干预目标预测和反事实预测。通过三个因果表示学习数据集，评估了当前最先进的开源LVLMs在这些任务中的表现。

研究结果: 研究揭示了现有LVLMs在视觉因果推理任务中的优势和不足，为改进其能力提供了方向。

研究结论: 本文的基准不仅揭示了现有视觉语言模型的缺点，还为提升LVLMs的视觉因果推理能力提供了新的研究方向。

中文摘要: 大型语言模型（LLMs）在各种语言任务中表现出色，尤其是在上下文学习能力方面。通过将LLMs扩展为包含视觉输入的大型视觉语言模型（LVLMs），其在识别和视觉问答（VQA）等任务中表现优异。尽管LLMs在因果推理任务（如因果发现和反事实推理）中的应用日益受到关注，但关于LVLMs在视觉因果推理任务中的能力研究较少。我们借此机会正式引入一个全面的因果推理基准，用于评估LVLMs在多模态上下文学习中的表现。CausalVLBench包含三个代表性任务：因果结构推断、干预目标预测和反事实预测。我们评估了当前最先进的开源LVLMs在这些任务中的表现，并展示了其基本优势和不足。我们希望这一基准能够揭示现有视觉语言模型的缺点，并为提升LVLMs的视觉因果推理能力提供新的研究方向。

</details>


### [216] [Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity](https://arxiv.org/abs/2506.11035)
**中文标题：Tversky神经网络：基于可微分Tversky相似性的心理学合理深度学习**

*Moussa Koulako Bala Doumbouya,Dan Jurafsky,Christopher D. Manning*

主要分类: cs.LG

摘要简述: 本文提出了一种基于Tversky相似性的可微分神经网络模型，解决了传统深度学习几何相似性不符合人类心理感知的问题，并在图像分类和语言建模任务中表现出显著性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 传统深度学习中使用的几何相似性模型（如对称性）与人类心理感知不符，而Tversky的特征集合相似性理论更符合心理学研究。然而，由于其离散集合操作的挑战，该理论未在深度学习中应用。本文旨在将Tversky相似性引入深度学习，提升模型性能与可解释性。

研究方法: 本文开发了一种可微分的Tversky相似性参数化方法，并通过梯度下降进行学习。提出了Tversky投影层，能够建模非线性函数（如XOR），并设计了神经网络模块。实验包括图像识别（NABirds）和语言建模（GPT-2）。

研究结果: 在NABirds图像分类任务中，使用Tversky投影层的ResNet-50比线性层适配器基线提升了24.7%的相对准确率。GPT-2在PTB上的困惑度降低了7.5%，参数数量减少了34.8%。此外，Tversky投影层展现出更高的可解释性。

研究结论: 本文通过引入Tversky相似性，为深度学习提供了一种更符合人类心理感知的相似性模型，显著提升了性能与可解释性，为未来研究开辟了新方向。

中文摘要: 心理学研究表明，深度学习中标准的几何相似性模型因对称性等度量属性与人类感知不符而缺乏心理学合理性。相比之下，Tversky（1977）提出了基于特征集合表示及其相似性函数的相似性理论，但由于离散集合操作的挑战，该模型未在深度学习中应用。本文开发了一种可微分的Tversky相似性参数化方法，并通过梯度下降学习，提出了Tversky投影层等神经网络模块，能够建模非线性函数（如XOR）。在图像识别（NABirds）和语言建模（PTB）实验中，Tversky投影层显著优于线性投影层：ResNet-50的准确率相对提升24.7%，GPT-2的困惑度降低7.5%，参数数量减少34.8%。此外，本文提出了一种统一解释，将投影层视为输入刺激与学习原型的相似性计算，并开发了可视化技术，突显了Tversky投影层的可解释性。本研究为深度学习中的相似性模型提供了新范式，并基于心理学理论设计了更具可解释性的网络。

</details>


### [217] [Angle Domain Guidance: Latent Diffusion Requires Rotation Rather Than Extrapolation](https://arxiv.org/abs/2506.11039)
**中文标题：角度域引导：潜在扩散需要旋转而非外推**

*Cheng Jin,Zhenyu Xiao,Chutao Liu,Yuantao Gu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为角度域引导（ADG）的新算法，用于解决文本到图像潜在扩散模型中高引导权重导致的颜色失真问题。ADG通过优化角度对齐而非放大样本范数，显著提升了图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 在文本到图像潜在扩散模型中，无分类器引导（CFG）虽能增强文本与图像的匹配度，但在高引导权重下会导致颜色失真。本文旨在解决这一问题，并提出更优的引导方法。

研究方法: 作者首先分析了CFG导致颜色失真的原因，即潜在空间中样本范数的放大。基于此，提出角度域引导（ADG）算法，通过约束范数变化并优化角度对齐来减少失真。

研究结果: 实验表明，ADG在保持高文本对齐度的同时，显著减少了颜色失真，生成的图像更符合人类感知偏好。

研究结论: ADG是一种有效的改进方法，能够在高引导权重下生成更高质量的图像，为潜在扩散模型提供了新的优化方向。

中文摘要: 无分类器引导（CFG）已成为文本到图像潜在扩散模型中的关键技术，显著提升了图像合成的质量。然而，在高引导权重下，虽然文本与图像的匹配度增强，但也会导致生成图像出现明显的颜色失真。我们发现这些失真源于潜在空间中样本范数的放大。本文提出了一个理论框架，解释了无分类器引导导致的范数放大和异常扩散现象。基于理论分析和潜在空间结构，我们提出了一种角度域引导（ADG）算法。ADG通过约束范数变化并优化角度对齐，既减少了颜色失真，又保留了高引导权重下的文本对齐优势。实验结果表明，ADG显著优于现有方法，生成的图像不仅保持了更高的文本匹配度，还提升了颜色保真度，更符合人类感知偏好。

</details>


### [218] [I Can't Believe It's Not Real: CV-MuSeNet: Complex-Valued Multi-Signal Segmentation](https://arxiv.org/abs/2506.11048)
**中文标题：难以置信的非真实：CMuSeNet——复值多信号分割网络**

*Sangwon Shin,Mehmet C. Vuran*

主要分类: cs.LG

摘要简述: 本文提出了一种名为CMuSeNet的复值多信号分割网络，用于解决传统实值神经网络在低信噪比环境下性能不足的问题。通过引入复值架构、傅里叶谱焦点损失和复平面交并比相似性度量，CMuSeNet显著提升了频谱感知的准确性和训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 随着射频频谱的日益拥挤，高效利用频谱成为挑战。传统实值神经网络（RVNNs）在低信噪比环境下难以捕捉无线信号的关键特性（如相位和振幅），因此需要一种更有效的解决方案。

研究方法: CMuSeNet基于复值神经网络（CVNNs）和残差架构，引入了复值傅里叶谱焦点损失（CFL）和复平面交并比（CIoU）相似性度量，以优化训练性能。

研究结果: 在合成、室内无线和真实数据集上的广泛测试表明，CMuSeNet的平均准确率达到98.98%-99.90%，比其实值版本提升高达9.2个百分点，且训练时间减少92.2%。

研究结论: 复值架构显著提升了低信噪比环境下的弱信号检测能力和训练效率，为频谱感知提供了更优的解决方案。

中文摘要: 射频频谱的日益拥挤对高效频谱利用提出了挑战。认知无线电系统借助神经网络的最新创新实现了动态频谱接入。然而，传统的实值神经网络（RVNNs）在低信噪比（SNR）环境下表现不佳，因为它们并非专为捕捉无线信号的关键特性（如相位和振幅）而设计。为此，本文提出了CMuSeNet，一种用于宽带频谱感知的复值多信号分割网络。广泛的超参数分析表明，简单地将现有RVNNs转换为复值版本效果不佳。基于复值神经网络（CVNNs）和残差架构，CMuSeNet引入了复值傅里叶谱焦点损失（CFL）和复平面交并比（CIoU）相似性度量以提升训练性能。在合成、室内无线和真实数据集上的广泛评估显示，CMuSeNet的平均准确率达到98.98%-99.90%，比其实值版本提升高达9.2个百分点，且始终优于现有技术。值得注意的是，CMuSeNet仅需2个epoch即可达到其实值版本27个epoch的准确度，同时训练时间比现有技术减少高达92.2%。这些结果凸显了复值架构在提升低信噪比环境下弱信号检测能力和训练效率方面的有效性。数据集可在以下网址获取：https://dx.doi.org/10.21227/hcc1-6p22

</details>


### [219] [15,500 Seconds: Lean UAV Classification Leveraging PEFT and Pre-Trained Networks](https://arxiv.org/abs/2506.11049)
**中文标题：15,500秒：基于PEFT和预训练网络的轻量级无人机分类**

*Andrew P. Berg,Qian Zhang,Mia Y. Wang*

主要分类: cs.LG

摘要简述: 本文针对无人机音频分类中的数据稀缺问题，提出了一种结合参数高效微调、数据增强和预训练网络的方法，使用EfficientNet-B0模型实现了95%以上的验证准确率。


<details>
  <summary>详细信息</summary>
研究动机: 随着消费级和军用无人机市场的扩大，无人机的安全威胁日益严重。然而，无人机音频分类领域面临数据稀缺的挑战，本文旨在解决这一问题。

研究方法: 本文基于前期研究，采用了参数高效微调（PEFT）、数据增强和预训练网络（如EfficientNet-B0）等方法，以提升无人机音频分类的性能。

研究结果: 实验结果表明，该方法在验证集上达到了95%以上的准确率，显著提升了无人机音频分类的效果。

研究结论: 本文通过结合参数高效微调、数据增强和预训练网络，有效解决了无人机音频分类中的数据稀缺问题，为相关领域提供了实用的解决方案。

中文摘要: 随着消费级和军用无人机市场的扩大，无人机的安全威胁日益严重。本文针对深度无人机音频分类中的数据稀缺问题，提出了一种结合参数高效微调、数据增强和预训练网络的方法。基于EfficientNet-B0模型，我们实现了95%以上的验证准确率。

</details>


### [220] [ACCORD: Autoregressive Constraint-satisfying Generation for COmbinatorial Optimization with Routing and Dynamic attention](https://arxiv.org/abs/2506.11052)
**中文标题：ACCORD：基于自回归约束生成与动态注意力的组合优化方法**

*Henrik Abgaryan,Tristan Cazenave,Ararat Harutyunyan*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ACCORD的新方法，利用大型语言模型（LLMs）解决NP难组合优化问题，通过自回归约束生成和动态注意力路由，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）在推理任务中表现出色，但其在NP难组合优化问题（CPs）中的应用尚未充分探索。本文旨在填补这一空白，探索LLMs在组合优化中的潜力。

研究方法: ACCORD采用了一种新颖的数据集表示和模型架构，结合自回归约束生成和动态注意力路由，激活问题特定的LoRA模块。该方法基于8B参数的Llama模型，并引入了ACCORD-90k数据集，涵盖六种NP难问题。

研究结果: 实验表明，ACCORD在多个NP难组合优化任务上表现优异，优于标准提示和输入输出方法，甚至超过更大的LLMs（如GPT-4）。消融研究证实其输出结构显著提升了解决方案的可行性。

研究结论: ACCORD是首个大规模、端到端的框架，成功将LLMs应用于广泛的组合优化问题，为未来研究提供了重要基础。代码已开源。

中文摘要: 大型语言模型（LLMs）已展现出强大的推理能力，但其在NP难组合问题（CPs）中的直接应用仍未被充分探索。本文系统研究了LLMs在多种NP难组合优化任务中的推理能力，并提出了ACCORD：一种基于自回归约束生成与动态注意力的组合优化方法。ACCORD采用了一种新颖的数据集表示和模型架构，利用LLMs的自回归特性动态满足可行性约束，并通过基于注意力的路由激活问题特定的LoRA模块。我们还提出了ACCORD-90k监督数据集，涵盖六种NP难问题：TSP、VRP、Knapsack、FlowShop、JSSP和BinPacking。大量实验表明，基于8B参数Llama模型的ACCORD在性能上持续优于标准提示和输入输出方法，甚至超过更大的LLMs（如GPT-4）。消融研究进一步证明，其输出结构提升了解决方案的可行性。据我们所知，这是首个大规模、端到端的框架，探索了LLMs在广泛组合优化问题中的应用。代码已公开于https://github.com/starjob42/ACCORD。

</details>


### [221] [Bootstrapping your behavior: a new pretraining strategy for user behavior sequence data](https://arxiv.org/abs/2506.11053)
**中文标题：自举你的行为：一种用户行为序列数据的新预训练策略**

*Weichang Wu,Xiaolu Zhang,Jun Zhou,Yuchen Li,Wenwen Xia*

主要分类: cs.LG

摘要简述: 本文提出了一种新的用户行为序列预训练策略Bootstrapping Your Behavior (BYB)，通过自动构建监督嵌入替代手动行为词汇选择，显著提升了模型性能和训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有用户行为序列预训练方法依赖手动构建行为词汇，耗时且易引入偏差，词汇容量限制也影响模型泛化能力。本文旨在解决这些问题。

研究方法: BYB策略通过预测未来时间窗口内所有行为的自动构建监督嵌入，避免手动词汇选择，并采用师生编码器方案有效构建预训练监督。

研究结果: 在两个真实工业数据集和八个下游任务中，BYB平均AUC提升3.9%，训练吞吐量提升98.9%。在线部署中，金融逾期风险预测任务KS指标提升2.7%-7.1%。

研究结论: BYB策略显著优于现有方法，无需标签监督即可生成有意义的行为模式，实际应用中大幅降低坏账风险。

中文摘要: 用户行为序列（UBS）建模在工业应用中至关重要。随着数据规模和任务多样性的增长，UBS预训练方法变得越来越关键。现有的UBS预训练方法依赖预测行为分布，其关键步骤是构建选择的行为词汇。然而，这一手动步骤耗时且易引入偏差，词汇容量的限制也直接影响模型的泛化能力。本文提出Bootstrapping Your Behavior（BYB），一种新的UBS预训练策略，通过预测自动构建的监督嵌入（总结未来时间窗口内所有行为信息）来替代手动词汇选择。在实现中，我们采用师生编码器方案有效构建预训练监督。在两个真实工业数据集和八个下游任务上的实验表明，BYB平均AUC提升3.9%，训练吞吐量提升98.9%。值得注意的是，模型在无标签监督的预训练过程中展现出有意义的行为模式和聚类表示。在支付宝移动应用的两个金融逾期风险预测任务中，预训练模型在线部署两个月内，KS指标较基线模型分别提升约2.7%和7.1%，为蚂蚁集团减少数百万美元的坏账风险。

</details>


### [222] [Adaptive Composition of Machine Learning as a Service (MLaaS) for IoT Environments](https://arxiv.org/abs/2506.11054)
**中文标题：物联网环境中机器学习即服务（MLaaS）的自适应组合**

*Deepak Kanneganti,Sajib Mistry,Sheik Mohammad Mostakim Fattah,Aneesh Krishna,Monowar Bhuyan*

主要分类: cs.LG

摘要简述: 本文提出了一种自适应MLaaS组合框架，以应对物联网环境中数据分布和系统需求的不确定性，通过动态优化服务组合确保高效和可扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 物联网环境的动态性和不确定性导致数据分布波动（如概念漂移和数据异构性）和系统需求变化（如可扩展性需求和资源限制），挑战了MLaaS组合的长期有效性。

研究方法: 提出了一种自适应MLaaS组合框架，包括服务评估模型（识别性能不佳的服务）、候选选择模型（筛选最优替代服务）以及基于上下文多臂老虎机优化策略的自适应组合机制。

研究结果: 实验结果表明，该方法在真实数据集上能够高效维持服务质量（QoS），同时降低从头重新组合的计算成本。

研究结论: 该框架通过动态适应物联网环境的变化，确保了MLaaS组合的高效性和可扩展性，为物联网环境中的机器学习服务提供了实用解决方案。

中文摘要: 物联网（IoT）环境的动态性对机器学习即服务（MLaaS）组合的长期有效性提出了挑战。物联网环境的不确定性和变异性导致数据分布波动（如概念漂移和数据异构性）以及系统需求变化（如可扩展性需求和资源限制）。本文提出了一种自适应MLaaS组合框架，以确保无缝、高效和可扩展的MLaaS组合。该框架集成了一个服务评估模型（用于识别性能不佳的MLaaS服务）和一个候选选择模型（用于筛选最优替代服务）。开发了一种自适应组合机制，通过上下文多臂老虎机优化策略逐步更新MLaaS组合。通过持续适应物联网环境的约束，该方法在维持服务质量（QoS）的同时，降低了从头重新组合的计算成本。在真实数据集上的实验结果证明了所提方法的有效性。

</details>


### [223] [xInv: Explainable Optimization of Inverse Problems](https://arxiv.org/abs/2506.11056)
**中文标题：xInv：可解释的逆问题优化**

*Sean Memery,Kevin Denamganai,Anna Kapron-King,Kartic Subr*

主要分类: cs.LG

摘要简述: 本文提出了一种可解释的逆问题优化方法xInv，通过记录优化器轨迹并生成自然语言解释，使领域专家能够理解复杂的迭代优化过程。


<details>
  <summary>详细信息</summary>
研究动机: 逆问题在医疗、气候科学和农业等领域至关重要，但其迭代优化过程对领域专家来说通常难以理解。尽管前向模型的可解释性已有显著进展，但逆问题的优化仍缺乏透明性。

研究方法: 方法包括：1）在可微分模拟器中嵌入自然语言事件记录功能；2）在优化过程中记录前向和后向传递的事件；3）使用语言模型从事件列表中生成解释。

研究结果: 通过一个优化问题和神经网络训练示例，验证了方法的有效性，能够生成人类可理解的解释。

研究结论: xInv为逆问题的优化提供了可解释性工具，有助于领域专家理解复杂的优化过程。

中文摘要: 逆问题是医疗、气候科学和农业等领域的核心问题，通常通过迭代优化已知前向模型的输入来估计期望结果。尽管前向模型的解释性和可理解性已取得显著进展，但逆问题的迭代优化对领域专家仍难以理解。我们提出了一种方法，通过优化器生成的轨迹，在领域抽象层次上生成人类可理解的解释。该方法的核心思想是：在可微分模拟器中嵌入自然语言事件记录功能，并在前向和后向传递过程中记录事件。随后，使用语言模型从事件列表中生成解释。我们通过一个优化问题和神经网络训练示例验证了方法的有效性。

</details>


### [224] [STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization](https://arxiv.org/abs/2506.11057)
**中文标题：STRCMP：结合图结构先验与语言模型的组合优化方法**

*Xijun Li,Jiexiang Yang,Jinghao Wang,Bo Peng,Jianguo Yao,Haibing Guan*

主要分类: cs.LG

摘要简述: 论文提出STRCMP框架，结合图结构先验与语言模型，提升组合优化问题的求解质量和效率，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 组合优化问题因其NP难特性带来巨大计算挑战，现有基于大语言模型的方法常忽略问题结构先验，导致求解效率低和解质量差。受人类专家利用结构设计算法的启发，论文提出结合结构先验的框架。

研究方法: STRCMP框架结合图神经网络（GNN）提取问题结构嵌入，并基于这些嵌入条件化大语言模型（LLM），生成求解器专用代码。通过进化优化过程迭代改进算法。

研究结果: 在混合整数线性规划和布尔可满足性问题上的广泛实验表明，STRCMP在解最优性和计算效率上大幅优于五种强基线方法。

研究结论: STRCMP通过整合结构先验与语言模型，显著提升组合优化问题的求解性能，为算法设计提供了新思路。

中文摘要: 组合优化（CO）问题是运筹学和理论计算机科学的核心，因其NP难特性带来显著计算挑战。尽管大语言模型（LLM）已成为CO问题的潜在工具（通过直接生成解或合成求解器专用代码），但现有方法常忽略CO问题固有的关键结构先验，导致解质量不佳和迭代效率低下。受人类专家利用CO结构设计算法的启发，我们提出STRCMP，一种新颖的结构感知LLM算法发现框架，系统整合结构先验以提升解质量和求解效率。该框架结合图神经网络（GNN）从CO实例中提取结构嵌入，并基于这些嵌入条件化LLM，以生成求解器专用代码形式的高性能算法。这种复合架构确保语法正确性、保留问题拓扑结构并与自然语言目标对齐，同时通过进化优化过程迭代改进生成算法。在混合整数线性规划和布尔可满足性问题上的广泛评估（使用九个基准数据集）表明，我们提出的STRCMP在解最优性和计算效率上大幅优于五种强神经和LLM基线方法。代码和学习模型将在论文录用后公开。

</details>


### [225] [ADAMIX: Adaptive Mixed-Precision Delta-Compression with Quantization Error Optimization for Large Language Models](https://arxiv.org/abs/2506.11087)
**中文标题：ADAMIX：基于量化误差优化的自适应混合精度差异压缩框架用于大语言模型**

*Boya Xiong,Shuo Wang,Weifeng Ge,Guanhua Chen,Yun Chen*

主要分类: cs.LG

摘要简述: 本文提出ADAMIX框架，通过自适应混合精度量化优化大语言模型的参数差异压缩，显著提升压缩性能。


<details>
  <summary>详细信息</summary>
研究动机: 在多租户服务等场景中，大量基于同一基础模型微调的大语言模型需要高效压缩。现有方法在高压缩比下性能不足或依赖经验性比特分配。

研究方法: ADAMIX通过数学推导量化误差，提出混合精度压缩策略，并将最优比特分配问题建模为0/1整数线性规划问题，以最小化量化误差并满足压缩比要求。

研究结果: 实验表明，ADAMIX在AIME2024和GQA任务上分别以22.3%和6.1%的优势超越最佳基线Delta-CoMe，尤其在ΔW范数较大且基础模型能力不足时表现突出。

研究结论: ADAMIX通过自适应混合精度量化优化，显著提升了大语言模型参数差异压缩的性能，为高效部署提供了新思路。

中文摘要: 大语言模型（LLMs）在不同领域的知识密集型复杂推理任务中表现出色。在多租户服务等场景中，大量基于同一基础模型微调的LLMs被部署以满足用户复杂需求。现有研究探索了量化压缩定制LLM与基础模型间参数差异的方法，但高压缩比下性能不佳或依赖经验性比特分配。本文提出ADAMIX，一种有效的自适应混合精度差异压缩框架。我们通过数学推导量化误差，提出混合精度压缩策略，并将最优比特分配问题建模为0/1整数线性规划问题，以最小化量化误差并满足压缩比要求。实验结果表明，ADAMIX在多种模型和基准测试中显著优于最佳基线。在AIME2024和GQA任务中，当ΔW范数较大且基础模型能力不足时，ADAMIX在7B模型上分别以22.3%和6.1%的优势超越Delta-CoMe。

</details>


### [226] [Debiasing Online Preference Learning via Preference Feature Preservation](https://arxiv.org/abs/2506.11098)
**中文标题：通过偏好特征保留消除在线偏好学习中的偏见**

*Dongyoung Kim,Jinsung Yoon,Jinwoo Shin,Jaehyung Kim*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PFP（偏好特征保留）的新框架，旨在解决大型语言模型（LLM）在线偏好学习中的偏见问题。通过保留人类偏好特征的分布并利用这些信号，PFP在在线学习过程中显著减少了偏见，并在标准基准测试中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型的偏好学习框架通常将人类偏好简化为二元比较和标量奖励，这可能导致模型在在线学习过程中对某些偏好特征产生偏见。本文旨在解决这一问题，提出一种能够保留和利用丰富偏好特征的方法。

研究方法: PFP框架首先从离线人类偏好数据中提取偏好特征并训练特征分类器。随后，通过分布保留优化，PFP在在线学习过程中为新输入指令映射适当的偏好特征。最后，PFP将偏好特征整合到系统提示中，利用现有偏好学习方法训练LLM，使其能够显式处理多样的人类偏好。

研究结果: 实验表明，PFP在在线学习过程中成功减少了偏好特征的偏见，并在标准基准测试中优于以往的偏好学习方法。

研究结论: PFP通过保留和利用人类偏好特征的分布，有效解决了在线偏好学习中的偏见问题，为LLM的对齐提供了更优的解决方案。

中文摘要: 近年来，针对大型语言模型（LLM）的偏好学习框架将人类偏好简化为二元成对比较和标量奖励。这种简化可能导致LLM的响应偏向于多数偏好的特征，并在在线偏好学习的迭代过程中加剧。为解决这一问题，我们提出了一种名为PFP（偏好特征保留）的新框架。PFP的核心思想是保留人类偏好特征的分布，并在在线偏好学习过程中充分利用这些丰富信号。具体而言，PFP首先从离线成对人类偏好数据中提取偏好特征并训练特征分类器。随后，通过训练好的分类器和分布保留优化，PFP在在线学习过程中为新输入指令映射适当的偏好特征。最后，PFP将偏好特征整合到系统提示中，利用现有偏好学习方法训练LLM，使其能够显式处理多样的人类偏好。实验表明，PFP在在线学习过程中成功减少了偏好特征的偏见，并在标准基准测试中优于以往的偏好学习方法。

</details>


### [227] [Knowledge Graph Embeddings with Representing Relations as Annular Sectors](https://arxiv.org/abs/2506.11099)
**中文标题：将关系表示为环形扇区的知识图谱嵌入方法**

*Huiling Zhu,Yingqi Zeng*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SectorE的新型知识图谱嵌入模型，将关系建模为环形扇区，以捕捉语义层次结构，并在多个数据集上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于区域的知识图谱嵌入模型通常忽略实体的语义层次结构，导致模型在捕捉复杂关系时表现不足。为了解决这一问题，本文提出了一种新的嵌入方法。

研究方法: SectorE模型在极坐标中嵌入实体和关系，将关系表示为环形扇区，结合模和相位来捕捉推理模式和关系属性，同时将实体嵌入为扇区内的点，以直观编码层次结构。

研究结果: 在FB15k-237、WN18RR和YAGO3-10数据集上的实验表明，SectorE在语义建模能力上表现优异，与多种模型相比具有竞争力。

研究结论: SectorE通过环形扇区建模关系，有效捕捉了知识图谱中的语义层次结构，为知识图谱补全任务提供了一种高效的方法。

中文摘要: 知识图谱（KGs）以实体和关系的多关系数据形式结构化，对数据分析和推荐系统等任务至关重要。知识图谱补全（KGC）或链接预测通过推断缺失的三元组（h, r, t）来解决知识图谱的不完整性问题，这对下游应用至关重要。基于区域的嵌入模型通常将实体嵌入为点，将关系嵌入为几何区域来完成这一任务。尽管取得了进展，但这些模型往往忽略了实体中固有的语义层次结构。为了解决这一问题，我们提出了SectorE，一种在极坐标中的新型嵌入模型。关系被建模为环形扇区，结合模和相位来捕捉推理模式和关系属性。实体被嵌入为这些扇区内的点，直观地编码了层次结构。在FB15k-237、WN18RR和YAGO3-10上的评估表明，SectorE在与多种模型的比较中表现出色，展示了其在语义建模能力上的优势。

</details>


### [228] [An Active Learning-Based Streaming Pipeline for Reduced Data Training of Structure Finding Models in Neutron Diffractometry](https://arxiv.org/abs/2506.11100)
**中文标题：基于主动学习的流式训练管道：用于中子衍射结构预测模型的减少数据训练**

*Tianle Wang,Jorge Ramirez,Cristina Garcia-Cardona,Thomas Proffen,Shantenu Jha,Sudip K. Seal*

主要分类: cs.LG

摘要简述: 本文提出了一种基于主动学习的流式训练方法，用于减少中子衍射结构预测模型的训练数据量，同时提高准确性和训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 中子衍射结构确定任务计算成本高且耗时，传统机器学习模型需要大量模拟数据训练，数据量随结构参数增加呈指数增长，带来巨大计算挑战。

研究方法: 提出了一种基于不确定性采样的批量主动学习策略，优先标注模型最不确定的数据，并设计了高效的流式训练流程。

研究结果: 实验表明，该方法减少约75%的训练数据量，同时提高准确性；流式训练流程将训练时间缩短约20%，且不影响准确性。

研究结论: 该方法显著降低了训练数据需求和计算成本，为中子衍射结构预测提供了一种高效的解决方案。

中文摘要: 中子衍射中的结构确定任务计算成本高昂，通常需要数小时至数天才能完成。最近研究表明，基于模拟中子散射模式训练的机器学习模型可显著加速这一过程。然而，训练这些模型所需的模拟数据量随预测结构参数数量呈指数增长，带来巨大计算挑战。为解决这一问题，我们提出了一种新颖的批量主动学习策略，利用不确定性采样从概率分布中选择模型最不确定的标注数据。实验证实，该方法在减少约75%训练数据的同时提高了准确性。此外，我们设计了一种高效的流式训练流程，并在两种异构平台上进行了性能研究。结果表明，与传统训练流程相比，流式流程将训练时间缩短约20%，且未损失准确性。

</details>


### [229] [Large Language models for Time Series Analysis: Techniques, Applications, and Challenges](https://arxiv.org/abs/2506.11040)
**中文标题：大语言模型在时间序列分析中的应用：技术、挑战与前景**

*Feifei Shi,Xueyan Yin,Kang Wang,Wanyu Tu,Qifu Sun,Huansheng Ning*

主要分类: cs.LG

摘要简述: 本文系统综述了预训练大语言模型（LLMs）在时间序列分析中的应用，探讨了其技术、潜在应用及挑战，并提出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 传统时间序列分析方法在非线性特征表示和长期依赖捕捉方面存在局限，而大语言模型（LLMs）凭借其跨模态知识整合和注意力机制，为时间序列分析提供了新的可能性。然而，开发通用LLMs仍面临数据多样性、标注稀缺和计算需求等挑战。

研究方法: 论文首先梳理了AI驱动时间序列分析的发展历程，从早期机器学习到新兴的LLM驱动范式，再到原生时间基础模型的开发。其次，从工作流程角度系统整理了LLM驱动时间序列分析的技术框架，包括输入、优化和轻量化阶段。最后，评述了实际应用案例并指出了关键挑战。

研究结果: 论文总结了LLM驱动时间序列分析的技术进展，提出了未来研究方向，为学术界和工业界提供了重要参考。

研究结论: 本文不仅为当前研究提供了深刻见解，还展望了未来发展方向，为开发更高效、通用和可解释的LLM驱动时间序列分析系统奠定了基础。

中文摘要: 时间序列分析在金融预测和生物医学监测等领域至关重要，但传统方法受限于非线性特征表示和长期依赖捕捉能力。大语言模型（LLMs）凭借其跨模态知识整合和注意力机制，为时间序列分析带来了变革潜力。然而，开发通用LLMs仍面临数据多样性、标注稀缺和计算需求等挑战。本文系统综述了预训练LLM驱动的时间序列分析，重点探讨了其关键技术、潜在应用及开放挑战。首先，本文建立了AI驱动时间序列分析的发展路线图，从早期机器学习到新兴LLM驱动范式，再到原生时间基础模型的开发。其次，从工作流程角度系统整理了LLM驱动时间序列分析的技术框架，包括输入、优化和轻量化阶段。最后，评述了实际应用案例并指出了关键挑战。本文不仅为当前研究提供了深刻见解，还展望了未来发展方向，为学术界和工业界提供了重要参考。

</details>


### [230] [LoRA Users Beware: A Few Spurious Tokens Can Manipulate Your Finetuned Model](https://arxiv.org/abs/2506.11402)
**中文标题：LoRA用户注意：少量虚假标记即可操控您的微调模型**

*Pradyut Sekhsaria,Marcel Mateos Salles,Hai Huang,Randall Balestriero*

主要分类: cs.LG

摘要简述: 研究发现，参数高效微调（PEFT）方法（如LoRA）可能导致模型依赖虚假标记（如单个标记）进行决策，从而被恶意控制。实验表明，少量虚假标记即可操控模型行为，且LoRA秩的大小影响模型对虚假标记的依赖程度。


<details>
  <summary>详细信息</summary>
研究动机: 参数高效微调（PEFT）方法（如LoRA）因其高效性被广泛使用，但对其潜在灾难性失败的研究不足。本文旨在揭示PEFT可能导致的模型依赖虚假标记的问题，并探讨其被恶意利用的可能性。

研究方法: 通过无缝虚假标记注入（SSTI）技术，在多个模型家族（Snowflake Arctic、Apple OpenELM、Meta LLaMA-3）和数据集（IMDB、金融分类、常识问答、Bias in Bios）中注入少量虚假标记，观察模型对虚假标记的依赖行为。

研究结果: 实验发现：1）单个虚假标记即可操控模型决策；2）LoRA秩越大，模型对虚假标记的依赖越轻；3）高秩LoRA在强虚假标记注入下表现更稳健。

研究结论: PEFT方法（如LoRA）可能因依赖虚假标记而存在安全隐患，需在设计和使用时注意数据质量和模型鲁棒性。

中文摘要: 参数高效微调（PEFT）方法（如低秩适应LoRA）以资源高效的方式将预训练大语言模型（LLM）适配到下游任务。由于效率是主要指标，对其潜在灾难性失败的研究较少。我们发现一种失败模式：PEFT鼓励模型寻找捷径解决微调任务。当下游任务类别与极少量标记（如每个提示中的一个标记）相关时，PEFT会使预训练模型主要依赖该标记进行决策。这些虚假标记可能因数据清理错误偶然出现，也可能被恶意方通过无缝虚假标记注入（SSTI）技术利用。SSTI中，数据集创建者注入少量与下游类别相关的标记，测试时仅需注入这些标记即可控制微调LLM的行为。我们在三个模型家族（Snowflake Arctic、Apple OpenELM、Meta LLaMA-3）和四个数据集（IMDB、金融分类、常识问答、Bias in Bios）上应用SSTI，发现三个惊人行为：1）单个SSTI标记即可操控模型决策；2）对于轻度SSTI，模型对虚假标记的依赖与LoRA秩成正比；3）对于强SSTI，高秩LoRA比低秩更优，因其能关注非虚假标记，提升鲁棒性。

</details>


### [231] [PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation](https://arxiv.org/abs/2506.11170)
**中文标题：PromptTSS：一种基于提示的交互式多粒度时间序列分割方法**

*Ching Chang,Ming-Chih Lo,Wen-Chih Peng,Tien-Fu Chen*

主要分类: cs.LG

摘要简述: PromptTSS是一种基于提示的多粒度时间序列分割方法，通过统一的模型和提示机制，解决了现有方法无法处理多粒度状态和动态适应新模式的挑战，显著提升了分割精度和适应性。


<details>
  <summary>详细信息</summary>
研究动机: 多变量时间序列数据（如制造和可穿戴技术领域）在不同粒度上表现出状态，现有分割方法无法统一处理多粒度状态且难以适应动态环境中的新模式。PromptTSS旨在解决这些问题。

研究方法: PromptTSS采用统一的模型和提示机制，利用标签和边界信息指导分割，同时捕捉粗粒度和细粒度模式，并能动态适应未见过的模式。

研究结果: 实验表明，PromptTSS在多粒度分割中精度提升24.49%，单粒度分割提升17.88%，迁移学习性能提升高达599.24%，展现了其对层次状态和动态时间序列的强适应性。

研究结论: PromptTSS通过提示机制和统一模型，有效解决了多粒度时间序列分割的挑战，显著提升了分割精度和动态适应性，适用于复杂的时间序列分析任务。

中文摘要: 多变量时间序列数据（如制造和可穿戴技术领域）在不同粒度上表现出状态，从粗粒度的系统行为到细粒度的详细事件。有效分割并整合这些不同粒度的状态对于预测性维护和性能优化等任务至关重要。然而，现有时间序列分割方法面临两大挑战：（1）无法在统一模型中处理多粒度状态；（2）对动态环境中新模式的适应性有限。为解决这些问题，我们提出PromptTSS，一种支持多粒度状态的时间序列分割新框架。PromptTSS采用统一模型和提示机制，利用标签和边界信息指导分割，同时捕捉粗粒度和细粒度模式，并能动态适应未见过的模式。实验表明，PromptTSS在多粒度分割中精度提升24.49%，单粒度分割提升17.88%，迁移学习性能提升高达599.24%，展现了其对层次状态和动态时间序列的强适应性。

</details>


### [232] [Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs](https://arxiv.org/abs/2506.11415)
**中文标题：RAG中的偏见放大：通过毒化知识检索操控大语言模型**

*Linlin Wang,Tianqing Zhu,Laiqiao Qin,Longxiang Gao,Wanlei Zhou*

主要分类: cs.LG

摘要简述: 本文揭示了检索增强生成（RAG）系统中存在的偏见放大问题，提出了一种名为BRRA的攻击框架，通过操纵检索结果放大语言模型偏见，并探讨了防御机制。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注RAG系统中投毒攻击对模型输出质量的影响，而忽略了其放大模型偏见的潜在风险。本文旨在揭示这种偏见放大现象及其对模型公平性的威胁。

研究方法: 提出BRRA攻击框架，包括基于多目标奖励函数的对抗性文档生成方法、子空间投影技术操纵检索结果，以及构建循环反馈机制持续放大偏见。

研究结果: 实验表明，BRRA攻击能显著增强主流大语言模型的偏见，同时提出的双阶段防御机制可有效缓解攻击影响。

研究结论: RAG系统中的投毒攻击会直接放大模型输出偏见，需关注其公平性问题。研究揭示了RAG系统安全性与模型公平性的关系。

中文摘要: 在大型语言模型中，检索增强生成（RAG）系统通过整合外部知识显著提升了模型性能，但也引入了新的安全风险。现有研究主要关注RAG系统中投毒攻击对模型输出质量的影响，而忽略了其放大模型偏见的潜力。例如，查询家庭暴力受害者时，被攻陷的RAG系统可能优先检索将女性描绘为受害者的文档，导致模型输出强化性别刻板印象，即使原始查询是性别中立的。为展示偏见影响，本文提出偏见检索与奖励攻击（BRRA）框架，系统研究通过操纵RAG系统放大语言模型偏见的攻击路径。我们设计了基于多目标奖励函数的对抗性文档生成方法，利用子空间投影技术操纵检索结果，并构建循环反馈机制持续放大偏见。在多个主流大语言模型上的实验表明，BRRA攻击能显著增强模型在多个维度上的偏见。此外，我们探索了双阶段防御机制以有效缓解攻击影响。本研究揭示了RAG系统中投毒攻击直接放大模型输出偏见的现象，并阐明了RAG系统安全性与模型公平性的关系。这种新型潜在攻击表明，需关注RAG系统的公平性问题。

</details>


### [233] [Collapsing Sequence-Level Data-Policy Coverage via Poisoning Attack in Offline Reinforcement Learning](https://arxiv.org/abs/2506.11172)
**中文标题：通过毒化攻击在离线强化学习中崩溃序列级数据-策略覆盖**

*Xue Zhou,Dapeng Man,Chen Xu,Fanyi Zeng,Tao Liu,Huan Wang,Shucheng He,Chaoyang Gao,Wu Yang*

主要分类: cs.LG

摘要简述: 本文提出一种针对离线强化学习的序列级数据-策略覆盖毒化攻击（CSDPC），通过识别并毒化罕见决策模式，显著降低数据覆盖，导致性能下降90%。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究关注提升数据-策略覆盖以减少分布偏移，但忽视了覆盖不足的安全风险，且单步分析不符合离线RL的多步决策特性。

研究方法: 引入序列级集中系数量化覆盖，提出CSDPC攻击，将状态-动作对转化为决策单元，提取代表性多步行为模式，毒化罕见模式以降低覆盖。

研究结果: 实验表明，仅毒化1%的数据集即可使智能体性能下降90%。

研究结论: 研究为离线RL的安全分析和防护提供了新视角。

中文摘要: 离线强化学习（RL）严重依赖于预收集数据对目标策略分布的覆盖。现有研究旨在提高数据-策略覆盖以减少分布偏移，但忽视了覆盖不足的安全风险，且单步分析与离线RL的多步决策特性不符。为此，我们引入序列级集中系数量化覆盖，并通过理论分析揭示其对估计误差上界的指数放大作用。基于此，提出“崩溃序列级数据-策略覆盖”（CSDPC）毒化攻击。考虑到离线RL数据的连续性，将状态-动作对转化为决策单元，提取捕捉多步行为的代表性决策模式，识别可能导致覆盖不足的罕见模式并进行毒化，以降低覆盖并加剧分布偏移。实验表明，仅毒化1%的数据集即可使智能体性能下降90%。这一发现为分析和保障离线RL安全提供了新视角。

</details>


### [234] [RollingQ: Reviving the Cooperation Dynamics in Multimodal Transformer](https://arxiv.org/abs/2506.11465)
**中文标题：RollingQ：重振多模态Transformer中的合作动态**

*Haotian Ni,Yake Wei,Hang Liu,Gong Chen,Chong Peng,Hao Lin,Di Hu*

主要分类: cs.LG

摘要简述: 多模态学习中，动态融合策略常因模型偏好单一模态而失效。本文提出RollingQ方法，通过轮换查询打破自我强化循环，恢复注意力机制的动态适应性，提升多模态Transformer的性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态学习面临模态质量不均的挑战，传统动态融合策略（如注意力机制）易因模型偏好单一模态而失效，导致动态适应性下降。本文旨在解决这一问题。

研究方法: 提出Rolling Query（RollingQ）方法，通过轮换查询打破模型对单一模态的偏好，平衡注意力分配，缩小模态间键分布差距，恢复动态融合能力。

研究结果: 在多种多模态场景下的实验验证了RollingQ的有效性，成功恢复了多模态Transformer的动态合作能力，显著提升了性能。

研究结论: RollingQ通过打破自我强化循环，有效恢复了注意力机制的动态适应性，为广泛部署的多模态Transformer提供了更强大的能力。

中文摘要: 多模态学习在融合多样模态信息时面临挑战，尤其是当样本间模态质量差异较大时。动态融合策略（如Transformer中的注意力机制）旨在通过根据输入数据特性自适应强调模态来解决这一问题。然而，通过大量精心设计的实验，我们意外发现广泛使用的自注意力模型的动态适应性逐渐减弱。模型倾向于偏好单一模态，而忽略数据特性。这种偏好触发了一个自我强化的循环，逐渐过度强调偏好模态，扩大模态间注意力键的分布差距，并削弱注意力机制的动态特性。为恢复适应性，我们提出了一种简单而有效的方法Rolling Query（RollingQ），通过轮换查询打破自我强化循环，缩小键分布差距，平衡注意力分配。在多种多模态场景下的广泛实验验证了RollingQ的有效性，并证明恢复合作动态对提升广泛部署的多模态Transformer的广泛能力至关重要。源代码可在https://github.com/GeWu-Lab/RollingQ_ICML2025获取。

</details>


### [235] [Brewing Knowledge in Context: Distillation Perspectives on In-Context Learning](https://arxiv.org/abs/2506.11516)
**中文标题：在上下文中酿造知识：上下文学习的蒸馏视角**

*Chengye Li,Haiyun Liu,Yuanxi Li*

主要分类: cs.LG

摘要简述: 本文提出了一种新理论视角，将上下文学习（ICL）视为一种隐式的知识蒸馏（KD）过程，通过提示演示引导模型在推理时形成任务特定的参考模型。理论框架解释了ICL的泛化性能，并揭示了提示与目标分布之间的偏差关系。


<details>
  <summary>详细信息</summary>
研究动机: 尽管上下文学习（ICL）在大型语言模型（LLMs）中表现出色，但其机制尚不明确，限制了对其解释、改进和可靠应用的能力。本文旨在通过理论视角揭示ICL的内在机制。

研究方法: 本文提出将ICL视为隐式知识蒸馏过程，并基于Rademacher复杂度推导了泛化边界，证明了蒸馏权重的偏差与提示和目标分布之间的最大均值差异（MMD）呈线性增长关系。

研究结果: 理论框架解释了ICL的多种经验现象，并统一了先前的梯度分析和分布分析。此外，首次将推理时的注意力机制形式化为蒸馏过程，为未来提示工程和自动演示选择提供了理论依据。

研究结论: 本文通过知识蒸馏视角为ICL提供了理论解释，揭示了其泛化性能与分布偏差的关系，为未来的研究和应用奠定了基础。

中文摘要: 上下文学习（ICL）使大型语言模型（LLMs）无需权重更新即可解决新任务。尽管其经验成功，但ICL的机制仍不明确，限制了对其解释、改进和可靠应用的能力。本文提出了一种新理论视角，将ICL视为知识蒸馏（KD）的隐式形式，其中提示演示在推理时引导模型形成任务特定的参考模型。基于此视角，我们推导了基于Rademacher复杂度的泛化边界，并证明蒸馏权重的偏差与提示和目标分布之间的最大均值差异（MMD）呈线性增长。这一理论框架解释了多种经验现象，并统一了先前的梯度分析和分布分析。据我们所知，这是首次将推理时的注意力机制形式化为蒸馏过程，为未来的提示工程和自动演示选择提供了理论见解。

</details>


### [236] [uPVC-Net: A Universal Premature Ventricular Contraction Detection Deep Learning Algorithm](https://arxiv.org/abs/2506.11238)
**中文标题：uPVC-Net：一种通用的室性早搏检测深度学习算法**

*Hagai Hamami,Yosef Solewicz,Daniel Zur,Yonatan Kleerekoper,Joachim A. Behar*

主要分类: cs.LG

摘要简述: uPVC-Net是一种通用深度学习算法，用于从单导联心电图中检测室性早搏（PVC），在多个数据集上表现出色，AUC高达99.1%。


<details>
  <summary>详细信息</summary>
研究动机: 室性早搏（PVC）是一种常见的心律失常，但由于导联放置、记录条件和人群差异导致的心电图波形变化，准确检测仍具挑战性。

研究方法: 研究开发了uPVC-Net，一种基于深度学习的通用模型，通过多源多导联训练策略，利用四个独立的心电图数据集（总计830万次心跳）进行训练，并在保留的数据集上评估其泛化能力。

研究结果: uPVC-Net在保留数据集上的AUC介于97.8%至99.1%之间，尤其在可穿戴单导联心电图数据上表现最佳，AUC达到99.1%。

研究结论: uPVC-Net在多样化的导联配置和人群中表现出强大的泛化能力，显示出其在临床实际应用中的潜力。

中文摘要: 引言：室性早搏（PVC）是一种起源于心室的常见心律失常。由于导联放置、记录条件和人群差异导致的心电图波形变化，准确检测仍具挑战性。方法：我们开发了uPVC-Net，一种通用的深度学习模型，用于从任何单导联心电图记录中检测PVC。该模型基于四个独立的心电图数据集（总计830万次心跳）开发，数据来自Holter监测仪和现代可穿戴心电图贴片。uPVC-Net采用定制架构和多源多导联训练策略。每次实验中，保留一个数据集以评估分布外（OOD）泛化能力。结果：uPVC-Net在保留数据集上的AUC介于97.8%至99.1%之间。值得注意的是，在可穿戴单导联心电图数据上的表现达到99.1%的AUC。结论：uPVC-Net在多样化的导联配置和人群中表现出强大的泛化能力，突显了其在真实临床环境中稳健部署的潜力。

</details>


### [237] [A Causal Lens for Learning Long-term Fair Policies](https://arxiv.org/abs/2506.11242)
**中文标题：因果视角下的长期公平策略学习**

*Jacob Lear,Lu Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种通过因果视角学习长期公平策略的框架，强调动态决策系统中长期公平的重要性，并分解公平性指标为直接、延迟和虚假效应，同时提出平衡多种公平概念的简单方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有公平性学习研究多关注静态场景中的即时偏见，而忽视了动态决策系统中的长期公平问题。本文旨在填补这一空白，强调在满足即时公平要求的同时，研究长期公平的重要性。

研究方法: 在强化学习背景下，提出一个通用框架，将长期公平性量化为不同群体个体预期资格增益的差异。通过因果视角，将该指标分解为直接效应、延迟效应和虚假效应，并分析其与新兴公平概念“利益公平”的内在联系。

研究结果: 研究发现，长期公平性可通过分解为三种效应来更全面地理解，并提出了一种简单有效的方法来平衡多种公平概念。

研究结论: 本文通过因果视角为动态决策系统中的长期公平性研究提供了新思路，并展示了如何在实际中平衡即时与长期公平要求。

中文摘要: 公平感知学习研究旨在开发避免歧视性决策结果的算法，尽管训练数据存在偏见。大多数研究集中于静态场景中的即时偏见，本文则强调在动态决策系统中研究长期公平性的重要性，同时考虑即时公平要求。在强化学习背景下，我们提出了一个通用框架，其中长期公平性通过不同群体个体预期资格增益的差异来衡量。然后，通过因果视角，我们将该指标分解为三个部分，分别代表政策对资格增益的直接影响、延迟影响以及虚假影响。我们分析了这些部分与新兴公平概念“利益公平”之间的内在联系，该概念旨在控制决策结果中的公平性。最后，我们开发了一种简单而有效的方法来平衡各种公平概念。

</details>


### [238] [Can Time-Series Foundation Models Perform Building Energy Management Tasks?](https://arxiv.org/abs/2506.11250)
**中文标题：时间序列基础模型能否执行建筑能源管理任务？**

*Ozan Baris Mulayim,Pengrui Quan,Liying Han,Xiaomin Ouyang,Dezhi Hong,Mario Bergés,Mani Srivastava*

主要分类: cs.LG

摘要简述: 时间序列基础模型（TSFMs）在建筑能源管理任务中表现有限，其泛化能力不及统计模型，尤其在多变量预测和复杂环境下表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 受大型语言模型（LLMs）成功的启发，研究时间序列基础模型（TSFMs）是否能在建筑能源管理（BEM）任务中实现类似的高泛化能力，以解决现有定制化模型的扩展性问题。

研究方法: 通过四个维度评估TSFMs：(1) 零样本单变量预测的泛化能力，(2) 包含协变量的热行为建模预测，(3) 零样本表示学习用于分类任务，(4) 对性能指标和不同操作条件的鲁棒性。

研究结果: TSFMs在单变量预测中表现略优于统计模型，但泛化能力有限；协变量未提升其性能；在分类任务中生成有效表示，但在预测任务中仍不及统计模型；对评估指标敏感且在复杂环境中表现不佳。

研究结论: TSFMs需改进协变量处理和时空动态预测机制，以提升其在BEM中的适应性和扩展性。

中文摘要: 建筑能源管理（BEM）任务需要处理和学习多种时间序列数据。现有解决方案依赖特定任务和数据的定制模型，限制了其广泛适用性。受大型语言模型（LLMs）成功的启发，基于多样化数据集训练的时间序列基础模型（TSFMs）有望改变这一现状。若TSFMs能实现类似LLMs的任务和上下文泛化能力，将从根本上解决BEM中普遍存在的扩展性挑战。为评估其现状，我们从四个维度测试TSFMs：(1) 零样本单变量预测的泛化能力，(2) 包含协变量的热行为建模预测，(3) 零样本表示学习用于分类任务，(4) 对性能指标和不同操作条件的鲁棒性。结果显示，TSFMs的泛化能力有限，在未见数据集和模态的单变量预测中仅略优于统计模型。同样，协变量的引入未提升其性能，其表现仍逊于利用协变量的传统模型。尽管TSFMs能为下游分类任务生成有效的零样本表示，但在预测任务中可能仍不及统计模型（当统计模型进行测试时拟合时）。此外，TSFMs的预测性能对评估指标敏感，且在复杂建筑环境中表现不如统计模型。这些发现表明，需针对性改进TSFMs设计，尤其是协变量处理和时空动态预测机制，以开发更具适应性和扩展性的BEM解决方案。

</details>


### [239] [TreeRL: LLM Reinforcement Learning with On-Policy Tree Search](https://arxiv.org/abs/2506.11902)
**中文标题：TreeRL：基于树搜索的大语言模型强化学习**

*Zhenyu Hou,Ziniu Hu,Yujiang Li,Rui Lu,Jie Tang,Yuxiao Dong*

主要分类: cs.LG

摘要简述: TreeRL是一种结合树搜索的强化学习框架，用于大语言模型（LLM）训练，通过中间监督和高效树搜索提升性能，无需单独奖励模型。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习在LLM训练中依赖独立的链式采样策略和结果监督，存在探索不足和奖励模型分布不匹配的问题。TreeRL旨在通过树搜索提供密集的过程奖励，提升训练效率和性能。

研究方法: TreeRL直接在强化学习训练中引入树搜索，通过中间监督避免单独训练奖励模型。提出一种高效树搜索方法，从高不确定性步骤分支，提升搜索效率。

研究结果: 在数学和代码推理任务中，TreeRL表现优于传统ChainRL，验证了树搜索在LLM强化学习中的潜力。

研究结论: TreeRL展示了树搜索在LLM强化学习中的优势，为未来研究提供了高效框架。

中文摘要: 传统推理任务中，结合树搜索的强化学习（RL）表现出色。与依赖独立链式采样和结果监督的方法相比，树搜索能更好地探索推理空间，并在RL训练中提供密集的过程奖励，但在大语言模型（LLM）的强化学习中尚未充分研究。我们提出TreeRL，一种直接结合树搜索的强化学习框架。该方法通过中间监督避免了单独训练奖励模型的需求。现有方法通常需训练单独的过程奖励模型，可能面临分布不匹配和奖励攻击问题。我们还提出一种高效的树搜索方法，通过从高不确定性中间步骤分支而非随机分支，在相同生成令牌预算下实现更高的搜索效率。在数学和代码推理基准测试中，TreeRL表现优于传统ChainRL，凸显了树搜索在LLM中的潜力。TreeRL已开源：https://github.com/THUDM/TreeRL。

</details>


### [240] [Visual Pre-Training on Unlabeled Images using Reinforcement Learning](https://arxiv.org/abs/2506.11967)
**中文标题：基于强化学习的无标注图像视觉预训练**

*Dibya Ghosh,Sergey Levine*

主要分类: cs.LG

摘要简述: 本文提出了一种利用强化学习在无标注图像上进行视觉预训练的方法，通过将图像变换视为动态系统中的状态转换，学习通用价值函数，从而提升特征表示能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的自监督图像预训练方法与强化学习中的价值函数学习具有相似性，本文旨在通过强化学习框架直接处理无标注图像数据，以更灵活地利用图像变换和弱标注信息。

研究方法: 将图像预训练问题建模为强化学习任务，通过动态系统中的图像变换（如裁剪或颜色增强）训练通用价值函数，结合奖励函数优化特征学习。

研究结果: 实验表明，该方法在多种无标注图像数据（如视频、场景和网络爬取数据）上均能学习到更优的特征表示。

研究结论: 通过强化学习框架将图像预训练问题形式化，提供了一种灵活且高效的特征学习方法，尤其适用于无标注或弱标注数据。

中文摘要: 在强化学习（RL）中，基于价值的算法学习将每个观察与可能达到的状态和奖励关联起来。我们注意到，许多自监督图像预训练方法与这一形式相似：学习将图像裁剪与附近视图（如不同裁剪或颜色增强）关联的特征。本文完成了这一类比，并探索了一种将无标注图像数据（如网络爬取和视频帧）预训练直接视为RL问题的方法。我们在动态系统中训练通用价值函数，其中代理通过改变视图或添加图像增强来变换图像。这种学习方式类似于裁剪一致性的自监督学习，但通过奖励函数，可以利用精选图像或弱标注标题（如果存在）来简单调整特征学习。实验表明，在野外无标注图像（如EpicKitchens视频数据、COCO场景数据和CC12M网络爬取数据）上训练时，该方法能学习到更优的表示。

</details>


### [241] [SIMSHIFT: A Benchmark for Adapting Neural Surrogates to Distribution Shifts](https://arxiv.org/abs/2506.12007)
**中文标题：SIMSHIFT：神经代理模型在分布偏移下的适应基准**

*Paul Setinek,Gianluca Galletti,Thomas Gross,Dominik Schnürer,Johannes Brandstetter,Werner Zellinger*

主要分类: cs.LG

摘要简述: 本文提出了SIMSHIFT基准数据集，用于评估神经代理模型在分布偏移下的适应能力，并通过扩展领域适应方法提升其在工业仿真任务中的性能。


<details>
  <summary>详细信息</summary>
研究动机: 神经代理模型在处理偏微分方程时，面对未见过的配置（如新材料或结构维度）时性能显著下降。尽管领域适应技术在视觉和语言处理中广泛应用，但在仿真任务中的应用尚未充分探索。本文旨在填补这一空白。

研究方法: 首先，作者构建了SIMSHIFT基准数据集，包含四种工业仿真任务（热轧、金属板成型、电机设计和散热器设计）。其次，将现有领域适应方法扩展到神经代理模型，并系统评估其性能。这些方法利用源配置的参数描述和真实仿真数据，以及目标配置的参数描述，预测目标仿真结果。

研究结果: 实验表明，神经代理模型在分布偏移下表现不佳，但领域适应方法在仿真任务中显示出潜力。同时，研究揭示了在工业场景中实现稳健神经代理模型的开放性问题。

研究结论: SIMSHIFT为神经代理模型在分布偏移下的适应提供了基准，展示了领域适应技术的潜力，并指出了未来研究方向。

中文摘要: 神经代理模型在处理偏微分方程（PDEs）时，面对未见过的配置（如新材料或结构维度）时性能显著下降。与此同时，领域适应（DA）技术已在视觉和语言处理中广泛应用，用于从有限信息中泛化到未见过的配置。本文通过两项贡献填补这一空白：首先，我们提出了SIMSHIFT，一个由四种工业仿真任务（热轧、金属板成型、电机设计和散热器设计）组成的新基准数据集和评估套件；其次，我们将现有领域适应方法扩展到最新的神经代理模型，并系统评估其性能。这些方法利用多个源配置的参数描述和真实仿真数据，以及目标配置的参数描述，目标是无需真实仿真数据即可准确预测目标仿真结果。在SIMSHIFT上的大量实验揭示了分布偏移下神经代理建模的挑战，展示了DA在仿真中的潜力，并指出了在工业相关场景中实现稳健神经代理模型的开放性问题。我们的代码库可在https://github.com/psetinek/simshift获取。

</details>


### [242] [EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction](https://arxiv.org/abs/2506.12015)
**中文标题：EMLoC：基于模拟器的内存高效微调与LoRA校正**

*Hsi-Che Lin,Yu-Chu Yu,Kai-Po Chang,Yu-Chiang Frank Wang*

主要分类: cs.LG

摘要简述: EMLoC是一种基于模拟器的内存高效微调框架，通过LoRA校正，实现在推理内存预算内完成模型微调，支持灵活压缩比和标准训练流程。


<details>
  <summary>详细信息</summary>
研究动机: 开源基础模型虽强大，但针对特定领域或个性化任务的微调因内存开销过大而难以普及。EMLoC旨在解决这一问题，使普通用户也能高效微调大模型。

研究方法: EMLoC通过激活感知的奇异值分解（SVD）构建轻量级模拟器，并在其上使用LoRA进行微调。为解决模拟器与原模型的对齐问题，提出补偿算法校正LoRA模块，最终将其合并回原模型。

研究结果: 实验表明，EMLoC在多个数据集和模态上优于其他基线方法，且无需量化即可在24GB消费级GPU上微调38B模型。

研究结论: EMLoC为个人用户提供了高效且实用的模型适配方案，显著降低了微调大模型的门槛。

中文摘要: 开源基础模型迅速发展，为多领域提供了强大的通用能力。然而，针对特定领域或个性化任务微调大模型因内存开销远超推理需求，对大多数用户而言成本过高。本文提出EMLoC，一种基于模拟器的内存高效微调框架，通过LoRA校正，实现在推理内存预算内完成模型微调。EMLoC利用激活感知的奇异值分解（SVD）在小规模下游校准集上构建任务专用轻量模拟器，并通过LoRA在其上进行微调。为解决模拟器与原模型的对齐问题，提出一种新颖的补偿算法校正微调后的LoRA模块，从而可将其合并回原模型用于推理。EMLoC支持灵活压缩比和标准训练流程，适用于广泛的应用场景。大量实验表明，EMLoC在多个数据集和模态上优于其他基线方法。此外，无需量化，EMLoC即可在24GB消费级GPU上微调38B模型，为个人用户带来高效且实用的模型适配方案。

</details>


### [243] [LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment](https://arxiv.org/abs/2506.11480)
**中文标题：LearnAlign：基于改进梯度对齐的大型语言模型强化学习推理数据选择方法**

*Shikun Li,Shipeng Li,Zhiqin Yang,Xinghua Zhang,Gaode Chen,Xiaobo Xia,Hengyu Liu,Zhe Peng*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LearnAlign的新方法，通过改进梯度对齐智能选择可学习和有代表性的训练数据，显著减少强化学习在大型语言模型中的数据需求，同时保持或提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 强化学习（RL）是提升大型语言模型（LLMs）推理能力的关键技术，但其数据效率低下成为主要瓶颈。为了解决这一问题，本文提出了一种基于梯度对齐的数据选择方法。

研究方法: LearnAlign通过引入基于成功率的数据可学习性指标，克服了梯度范数中响应长度偏差的问题，智能选择适合RL后训练的数据。

研究结果: 在三个数学推理基准测试中，LearnAlign显著减少了训练数据需求（如GSM8K上减少1000个数据点），同时性能优于或接近全数据训练（77.53% vs 77.04%）。

研究结论: LearnAlign为数据高效的RL后训练提供了重要见解，并为未来优化推理数据选择的研究奠定了基础。代码将开源以促进未来工作。

中文摘要: 强化学习（RL）已成为提升大型语言模型（LLMs）推理能力的关键技术，但其数据效率低下仍是主要瓶颈。为解决这一关键问题，我们提出了一种基于梯度对齐的新方法LearnAlign，智能选择可学习和有代表性的训练数据用于RL后训练。为克服梯度范数中响应长度偏差的问题，我们引入了基于成功率的数据可学习性指标，以评估每个数据点的学习潜力。在三个数学推理基准测试中，实验表明我们的方法显著减少了训练数据需求，同时性能接近或优于全数据训练。例如，在GSM8K基准测试中，数据需求减少多达1000个数据点，性能（77.53%）优于全数据集训练（77.04%）。此外，我们还展示了其在分阶段RL设置中的有效性。本研究为数据高效的RL后训练提供了宝贵见解，并为未来优化推理数据选择的研究奠定了基础。为促进未来工作，我们将开源代码。

</details>


### [244] [Diabetes Prediction and Management Using Machine Learning Approaches](https://arxiv.org/abs/2506.11501)
**中文标题：基于机器学习方法的糖尿病预测与管理**

*Mowafaq Salem Alzboon,Muhyeeddin Alqaraleh,Mohammad Subhi Al-Batah*

主要分类: cs.LG

摘要简述: 本研究探讨了机器学习在糖尿病预测和管理中的应用，通过分析Pima Indians糖尿病数据库的768个样本，发现神经网络和随机森林算法在预测准确性上表现最佳，分别达到78.57%和76.30%。


<details>
  <summary>详细信息</summary>
研究动机: 糖尿病已成为全球性健康问题，早期检测和主动管理对预防或减轻其严重并发症至关重要。机器学习算法在糖尿病风险预测中展现出潜力，本研究旨在评估其有效性。

研究方法: 研究使用Pima Indians糖尿病数据库的768个样本，评估了多种机器学习算法（如逻辑回归、决策树、随机森林、K近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络）在糖尿病风险分类中的表现。

研究结果: 实验结果显示，神经网络算法的预测准确率最高（78.57%），其次是随机森林（76.30%），表明机器学习技术可作为早期筛查工具，有效预测糖尿病风险。

研究结论: 机器学习技术在糖尿病预测中具有高效性和潜力，可作为数据驱动的早期筛查工具，有助于减少糖尿病对医疗系统的负担。

中文摘要: 糖尿病已成为全球性健康问题，尤其是在许多国家病例不断增加的情况下。这一趋势凸显了早期检测和主动管理的重要性，以避免或减轻糖尿病的严重健康并发症。近年来，机器学习算法在预测糖尿病风险方面展现出潜力，并对从业者具有实际价值。本研究重点评估了统计和非统计机器学习方法在Pima Indians糖尿病数据库768个样本中对糖尿病风险分类的预测能力。研究涉及年龄、体重指数（BMI）和血糖水平等关键人口统计学和临床特征，这些特征对糖尿病易感性具有重要影响。实验评估了多种机器学习算法（包括逻辑回归、决策树、随机森林、K近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络模型）在糖尿病预测中的准确性和有效性。结果显示，神经网络算法的预测准确率最高（78.57%），随机森林算法次之（76.30%）。这些发现表明，机器学习技术不仅高效，还能作为早期筛查工具，通过数据驱动的方式预测糖尿病风险，并提供有价值的信息。此外，本研究有助于实现机器学习在长期及时干预中的潜力，从而减少糖尿病对医疗系统的健康负担。

</details>


### [245] [Machine Learning-Based Quantification of Vesicoureteral Reflux with Enhancing Accuracy and Efficiency](https://arxiv.org/abs/2506.11508)
**中文标题：基于机器学习的膀胱输尿管反流量化：提升准确性与效率**

*Muhyeeddin Alqaraleh,Mowafaq Salem Alzboon,Mohammad Subhi Al-Batah,Lana Yasin Al Aesa,Mohammed Hasan Abu-Arqoub,Rashiq Rafiq Marie,Firas Hussein Alsmad*

主要分类: cs.LG

摘要简述: 本研究利用机器学习分析VCUG图像，提出一种客观量化膀胱输尿管反流（VUR）的方法，显著提高了诊断的一致性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的VUR评估依赖主观分级系统，导致诊断结果存在变异性。本研究旨在通过机器学习技术提供一种更客观、标准化的诊断方法。

研究方法: 研究选取113张VCUG图像，提取9个图像特征，训练了包括逻辑回归、决策树、梯度提升、神经网络和随机梯度下降在内的六种预测模型，并采用留一法交叉验证进行评估。

研究结果: 所有模型均实现了准确分类，无假阳性或假阴性结果。肾盏变形模式被确定为高等级VUR的关键指标，模型对VUR不同分级的细微图像特征表现出高敏感性，AUC值显著。

研究结论: 机器学习可作为一种客观、标准化的VUR评估替代方法，肾盏变形是严重病例的强预测因子。未来研究应扩大数据集并优化模型泛化能力。

中文摘要: 膀胱输尿管反流（VUR）的传统评估依赖主观分级系统，导致诊断结果存在变异性。本研究探讨了利用机器学习分析排尿性膀胱尿道造影（VCUG）图像以提高诊断一致性的方法。共评估了113张VCUG图像，并由专家对VUR严重程度进行分级。选取了9个图像特征，训练了六种预测模型：逻辑回归、决策树、梯度提升、神经网络和随机梯度下降，并采用留一法交叉验证进行评估。分析发现肾盏变形模式是高等级VUR的关键指标。所有模型均实现了准确分类，无假阳性或假阴性结果。模型对不同VUR分级的细微图像特征表现出高敏感性，AUC值显著。结果表明，机器学习可为当前主观的VUR评估提供一种客观、标准化的替代方法。这些发现强调了肾盏变形作为严重病例的强预测因子。未来研究应扩大数据集、优化图像特征并提升模型泛化能力，以推动更广泛的临床应用。

</details>


### [246] [Prioritizing Alignment Paradigms over Task-Specific Model Customization in Time-Series LLMs](https://arxiv.org/abs/2506.11512)
**中文标题：在时间序列大语言模型中优先考虑对齐范式而非任务特定的模型定制**

*Wei Li,Yunyao Cheng,Xinli Hao,Chaohong Ma,Yuxuan Liang,Bin Yang,Christian S. Jensen,Xiaofeng Meng*

主要分类: cs.LG

摘要简述: 本文主张在时间序列大语言模型（LLMs）中，优先考虑基于时间序列数据本质的对齐范式，而非任务特定的模型定制，以解决现有方法成本高、灵活性差和效率低的问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前时间序列推理方法通常专注于任务特定的模型定制（如预测和异常检测），而忽略了时间序列数据的本质（称为时间序列基元），这限制了深入推理的能力。本文旨在通过重新调整方法，优先考虑数据内在结构的对齐范式，以提升时间序列推理的经济性、灵活性和效率。

研究方法: 提出了三种对齐范式：注入对齐（Injective Alignment）、桥接对齐（Bridging Alignment）和内部对齐（Internal Alignment），分别关注时间序列基元的不同方面（领域、特征和表示），以激活LLMs的时间序列推理能力。

研究结果: 通过优先考虑对齐范式，本文展示了如何实现更经济、灵活和高效的时间序列推理，并为相关文献提供了分类框架和未来研究方向。

研究结论: 本文呼吁实践者采用对齐导向的方法，选择适当的对齐范式，以优化时间序列推理能力，并推动该领域的进一步研究。

中文摘要: 近年来，大语言模型（LLMs）的进展为时间序列推理提供了前所未有的能力，广泛应用于医疗、金融和时空领域。然而，现有方法通常专注于任务特定的模型定制（如预测和异常检测），而忽略了时间序列数据本身（称为时间序列基元），这对深入推理至关重要。本文主张在时间序列推理中实现根本性转变：优先考虑基于时间序列数据内在基元的对齐范式，而非任务特定的模型定制。这种调整通过系统性地考虑数据的内在结构，解决了当前时间序列推理方法成本高、灵活性差和效率低的核心问题。为此，我们提出了三种对齐范式：注入对齐、桥接对齐和内部对齐，分别强调时间序列基元的不同方面（领域、特征和表示），以激活LLMs的时间序列推理能力，实现经济、灵活和高效的推理。我们还建议实践者采用对齐导向的方法，以选择适当的对齐范式。此外，我们将相关文献归类到这些对齐范式中，并概述了有前景的研究方向。

</details>


### [247] [Improving Multimodal Learning Balance and Sufficiency through Data Remixing](https://arxiv.org/abs/2506.11550)
**中文标题：通过数据重混合提升多模态学习的平衡性与充分性**

*Xiaoyu Ma,Hao Chen,Yongjian Deng*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“多模态数据重混合”的新方法，通过解耦多模态数据、筛选各模态的困难样本以及批量级重组，解决了多模态学习中的不平衡和不足问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态学习中，不同模态的优化轨迹存在显著差异，导致模态惰性和模态冲突，从而引发学习不足和不平衡。现有方法仅关注增强弱模态或对齐优化速度，未能同时实现单模态充分性和多模态平衡。

研究方法: 提出多模态数据重混合方法，包括解耦多模态数据、筛选各模态的困难样本以缓解不平衡，并通过批量级重组对齐梯度方向，避免跨模态干扰，从而提升单模态学习的充分性。

研究结果: 实验结果表明，该方法无需扩展训练集或增加推理计算开销，即可与现有方法无缝集成，在CREMAD和Kinetic-Sounds数据集上分别提升约6.50%和3.41%的准确率。

研究结论: 多模态数据重混合方法有效解决了多模态学习中的不平衡和不足问题，显著提升了模型性能，且具有通用性和高效性。

中文摘要: 不同模态在优化轨迹（包括速度和路径）上存在显著差异，导致联合训练多模态模型时出现模态惰性和模态冲突，从而引发学习不足和不平衡。现有方法主要通过添加模态特定优化目标、对齐优化速度或分解多模态学习以增强单模态学习，但未能同时实现单模态充分性和多模态平衡。本文首次提出多模态数据重混合方法，包括解耦多模态数据、筛选各模态的困难样本以缓解不平衡；并通过批量级重组对齐梯度方向，避免跨模态干扰，从而提升单模态学习的充分性。实验结果表明，该方法可与现有方法无缝集成，在CREMAD和Kinetic-Sounds数据集上分别提升约6.50%和3.41%的准确率，且无需扩展训练集或增加推理计算开销。源代码发布于\href{https://github.com/MatthewMaxy/Remix_ICML2025}{Data Remixing}。

</details>


### [248] [Learn to Preserve Personality: Federated Foundation Models in Recommendations](https://arxiv.org/abs/2506.11563)
**中文标题：学习保护个性：推荐系统中的联邦基础模型**

*Zhiwei Li,Guodong Long,Chunxu Zhang,Honglei Zhang,Jing Jiang,Chengqi Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种联邦基础模型（FFM）的新学习范式，旨在解决基础模型在泛化与个性化之间的权衡问题，特别适用于推荐系统，以保护用户个性的完整性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基础模型（FM）在泛化与个性化之间存在权衡难题，而联邦基础模型（FFM）通过去中心化方法分离共享知识与个体适配，推荐系统因其依赖反映用户特性的隐式反馈成为理想测试场景。

研究方法: 采用联邦基础模型（FFM）架构，通过去中心化过程分离共享知识与个体适配，设计了一种既能利用泛化能力又能保护用户个性的学习范式。

研究结果: FFM在推荐系统中展现出既能泛化又能保护用户个性的潜力，为未来个性化代理提供了一种用户中心化、去中心化的架构。

研究结论: 联邦基础模型为推荐系统提供了一种新的学习范式，既能实现泛化能力，又能保护用户个性，未来可支持个性化代理的广泛应用。

中文摘要: 现有基础模型（FM）的核心学习挑战在于泛化与个性化之间的权衡，这一问题已被多种参数高效适配技术凸显。联邦基础模型（FFM）通过去中心化过程提供了一种结构性方法，将共享知识与个体特定适配分离。推荐系统因其依赖反映独特用户特性的丰富隐式反馈，成为FFM的理想测试场景。本文讨论了一种新的学习范式，FFM不仅利用其泛化能力，还专门设计用于保护用户个性的完整性，并在推荐场景中进行了详细说明。我们展望未来的个性化代理，由个性化自适应FM驱动，指导用户在内容上的决策。这种架构承诺了一种以用户为中心、去中心化的系统，个人可以控制其个性化代理。

</details>


### [249] [A Comparative Analysis of Influence Signals for Data Debugging](https://arxiv.org/abs/2506.11584)
**中文标题：数据调试中影响力信号的比较分析**

*Nikolaos Myrtakis,Ioannis Tsamardinos,Vassilis Christophides*

主要分类: cs.LG

摘要简述: 本文比较了多种基于影响力的信号在调试训练数据中的表现，发现Self-Influence能有效检测错误标签样本，但现有信号均无法检测异常样本，且未考虑训练动态或存在影响力抵消问题。


<details>
  <summary>详细信息</summary>
研究动机: 提升训练样本质量对机器学习模型的可靠性和性能至关重要。本文旨在评估不同基于影响力的信号在检测训练数据中的错误标签和异常样本方面的能力，以替代专用故障检测器。

研究方法: 通过实验比较多种影响力信号（如Self-Influence、Average Absolute Influence等）在不同数据模态（图像和表格）和深度学习模型（从头训练或基础模型）中的表现，使用共同的影响力估计器（如TraceIn）。

研究结果: 实验表明，Self-Influence能有效检测错误标签样本，但现有信号均无法检测异常样本。此外，现有信号未考虑训练动态，部分信号因影响力抵消效应导致误导性归因。

研究结论: 现有基于影响力的信号在检测错误标签样本方面表现良好，但在检测异常样本方面存在局限性，需进一步考虑训练动态和改进信号设计。

中文摘要: 提升训练样本质量对提高机器学习模型的可靠性和性能至关重要。本文对基于影响力的信号在调试训练数据中的表现进行了比较评估。这些信号可以识别潜在噪声训练集中的错误标签和异常样本，从而减少对专用故障检测器的需求。尽管文献中已提出多种影响力信号（如Self-Influence、Average Absolute Influence等），但目前缺乏对其在不同故障类型（如错误标签和异常样本）检测能力的研究，尤其是在共同的影响力估计器（如TraceIn）下，针对不同数据模态（图像和表格）和深度学习模型（从头训练或基础模型）。通过大量实验，我们发现Self-Influence能有效检测错误标签样本，但现有信号均无法检测异常样本。现有信号未考虑训练动态（即样本影响力在训练过程中的变化），部分信号还因影响力抵消效应（即因无符号分数累积导致影响力得分为零）导致误导性归因。

</details>


### [250] [Model Organisms for Emergent Misalignment](https://arxiv.org/abs/2506.11613)
**中文标题：用于涌现对齐失效的模型生物**

*Edward Turner,Anna Soligo,Mia Taylor,Senthooran Rajamanoharan,Neel Nanda*

主要分类: cs.LG

摘要简述: 研究发现，在狭窄有害数据集上微调大型语言模型会导致广泛的对齐失效（Emergent Misalignment, EM）。通过创建改进的模型生物，研究揭示了EM的鲁棒性，并提出了未来对齐研究的工具。


<details>
  <summary>详细信息</summary>
研究动机: 近期研究发现，大型语言模型在狭窄有害数据集上的微调可能导致广泛的对齐失效（EM），这一现象出乎专家意料，暴露了对齐理解的重大空白。本研究旨在推进对齐理解并为未来研究提供工具。

研究方法: 使用新的狭窄对齐失效数据集，创建了一组改进的模型生物，实现了99%的连贯性（之前为67%），并能在较小的0.5B参数模型（之前为32B）中通过单一rank-1 LoRA适配器诱导对齐失效。研究了不同模型大小、三个模型家族及多种训练协议下的EM现象。

研究结果: 研究发现EM现象在多种模型大小、家族和训练协议中均鲁棒存在。通过改进的模型生物，研究揭示了一个机制性相变，并证明其与所有研究模型中的行为相变一致。

研究结论: 对齐大型语言模型对前沿AI安全至关重要，但EM现象表明目前远未实现鲁棒对齐。通过提炼干净的模型生物并揭示最小对齐失效变化，本研究为未来理解和缓解LLM对齐风险奠定了基础。

中文摘要: 近期研究发现涌现对齐失效（EM）：在狭窄有害数据集上微调大型语言模型可能导致其广泛对齐失效。发表前的专家调查显示这一现象高度出人意料，暴露了对齐理解的重大空白。本研究既推进了理解，也为未来研究提供了工具。通过新的狭窄对齐失效数据集，我们创建了一组改进的模型生物，实现了99%的连贯性（之前为67%），适用于较小的0.5B参数模型（之前为32B），并通过单一rank-1 LoRA适配器诱导对齐失效。研究表明，EM现象在不同模型大小、三个模型家族及多种训练协议（包括全监督微调）中均鲁棒存在。利用这些更干净的模型生物，我们分离出一个机制性相变，并证明其与所有研究模型中的行为相变一致。对齐大型语言模型对前沿AI安全至关重要，但EM现象表明目前远未实现鲁棒对齐。通过提炼干净的模型生物并揭示最小对齐失效变化及其学习机制，我们为未来理解和缓解LLM对齐风险奠定了基础。

</details>


### [251] [Convergent Linear Representations of Emergent Misalignment](https://arxiv.org/abs/2506.11618)
**中文标题：涌现失调的收敛线性表征**

*Anna Soligo,Edward Turner,Senthooran Rajamanoharan,Neel Nanda*

主要分类: cs.LG

摘要简述: 研究发现，大型语言模型在窄数据集上微调会导致广泛的行为失调（称为“涌现失调”）。通过最小模型实验，发现不同失调模型的表征趋于一致，并提出一种“失调方向”来消除失调行为。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在窄数据集上微调时可能出现广泛的行为失调（涌现失调），但其机制和泛化原因尚不清楚。本文旨在通过最小模型实验揭示失调的机制，为理解和缓解失调提供基础。

研究方法: 使用仅含9个rank-1适配器的最小模型对Qwen2.5-14B-Instruct进行微调，研究涌现失调。通过提取“失调方向”并应用于更高维度的LoRAs和不同数据集，验证失调表征的收敛性。

研究结果: 发现不同失调模型的表征趋于一致，提取的“失调方向”能有效消除失调行为。进一步分析表明，6个适配器导致广泛失调，2个仅针对微调领域的失调。

研究结论: 涌现失调是模型行为中不可预测且不理想的现象。通过揭示其机制，本文为更广泛地理解和缓解失调提供了新思路。

中文摘要: 在窄数据集上微调大型语言模型可能导致其出现广泛的行为失调现象，称为“涌现失调”。然而，这种失调的机制及其泛化原因尚不清楚，表明我们对模型对齐的理解存在重大空白。本文通过训练和研究一个仅使用9个rank-1适配器的最小模型，对Qwen2.5-14B-Instruct进行涌现失调研究。研究发现，不同涌现失调模型的失调表征趋于一致。通过从一个微调模型的激活中提取“失调方向”，并应用于更高维度的LoRAs和不同数据集，验证了这种收敛性。利用rank-1 LoRAs的标量隐藏状态，进一步提出了一组实验直接解释微调适配器，发现其中6个导致广泛失调，而2个仅针对微调领域的失调。涌现失调是模型行为中不可预测且不理想的典型案例，通过深入理解其机制，我们希望能更好地理解和缓解更广泛的失调现象。

</details>


### [252] [Why Do Class-Dependent Evaluation Effects Occur with Time Series Feature Attributions? A Synthetic Data Investigation](https://arxiv.org/abs/2506.11790)
**中文标题：时间序列特征归因中为何会出现类别依赖性评估效应？基于合成数据的研究**

*Gregor Baer,Isel Grau,Chao Zhang,Pieter Van Gorp*

主要分类: cs.LG

摘要简述: 本文探讨了时间序列特征归因方法中出现的类别依赖性评估效应，通过合成数据实验揭示了扰动评估指标与真实特征定位之间的不一致性，并指出当前评估方法的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 在可解释AI（XAI）中，特征归因方法的评估是一个关键挑战，研究者通常依赖扰动指标，但近期研究发现这些指标在不同预测类别间表现不一致。这种“类别依赖性评估效应”引发了对扰动分析可靠性的质疑，直接影响XAI方法开发和评估技术的可信度。

研究方法: 通过合成时间序列数据进行控制实验，已知真实特征位置，系统性地改变特征类型和类别对比，比较基于扰动的退化分数与基于真实特征的精确召回指标，使用多种归因方法。

研究结果: 实验表明，即使在简单场景中，类别依赖性效应也会出现，且扰动指标与真实指标常产生矛盾评估，两者相关性较弱。

研究结论: 研究发现扰动指标可能无法准确识别区分性特征，建议谨慎解释此类指标，并呼吁开发更全面的评估框架。

中文摘要: 评估特征归因方法是可解释AI（XAI）中的关键挑战，研究者通常在没有真实数据时依赖基于扰动的指标。然而，近期研究表明这些评估指标在同一数据集的不同预测类别间可能表现不同。这种“类别依赖性评估效应”引发了对扰动分析是否可靠衡量归因质量的疑问，直接影响XAI方法开发和评估技术的可信度。我们通过合成时间序列数据的控制实验研究这些效应的产生条件，已知真实特征位置，系统性地改变特征类型和类别对比，比较基于扰动的退化分数与基于真实特征的精确召回指标。实验表明，即使在简单场景中，类别依赖性效应也会出现，且扰动指标与真实指标常产生矛盾评估，两者相关性较弱。这些发现表明研究者应谨慎解释扰动指标，因为它们可能无法准确识别区分性特征，同时揭示了重新思考归因评估实际衡量内容的机会，并呼吁开发更全面的评估框架。

</details>


### [253] [TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks](https://arxiv.org/abs/2506.11844)
**中文标题：TrustGLM：评估GraphLLMs在提示、文本和结构攻击下的鲁棒性**

*Qihai Zhang,Xinyue Sheng,Yuanfu Sun,Qiaoyu Tan*

主要分类: cs.LG

摘要简述: 本文介绍了TrustGLM，一项全面评估GraphLLMs在文本、图结构和提示操作三个维度上对抗攻击鲁棒性的研究。研究发现GraphLLMs对文本攻击高度敏感，且标准图结构攻击方法能显著降低模型性能。同时，通过数据增强和对抗训练等防御技术，可提升GraphLLMs的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）的成功，研究重心从传统图学习方法转向基于LLM的图框架（GraphLLMs）。然而，GraphLLMs在对抗性扰动下的鲁棒性尚未充分探索，这对高风险场景中的模型部署至关重要。

研究方法: 研究通过TrustGLM框架，从文本、图结构和提示三个维度对GraphLLMs进行对抗攻击评估。采用先进的攻击算法，并在六个不同领域的基准数据集上进行实验。同时，探索了数据增强和对抗训练等防御技术。

研究结果: 实验表明，GraphLLMs对文本攻击（如替换节点文本属性中的少量语义相似词）高度敏感。标准图结构攻击方法能显著降低模型性能，而提示模板中候选标签集的随机打乱也会导致性能大幅下降。防御技术显示出提升模型鲁棒性的潜力。

研究结论: TrustGLM揭示了GraphLLMs在对抗攻击下的脆弱性，并提出了针对性的防御方法。开源库的发布旨在促进快速、公平的评估，并推动该领域的创新研究。

中文摘要: 受大语言模型（LLMs）成功的启发，研究重心从传统图学习方法转向基于LLM的图框架（GraphLLMs）。GraphLLMs通过整合输入节点的文本属性、邻域结构信息和任务特定提示，利用LLMs的推理能力。尽管前景广阔，GraphLLMs在对抗性扰动下的鲁棒性仍未被充分探索，这对高风险场景中的模型部署至关重要。为此，我们提出TrustGLM，一项全面评估GraphLLMs在文本、图结构和提示操作三个维度上对抗攻击脆弱性的研究。我们采用各维度的先进攻击算法，严格评估模型鲁棒性。通过在六个不同领域的基准数据集上的广泛实验，我们发现GraphLLMs对文本攻击（如替换节点文本属性中的少量语义相似词）高度敏感。标准图结构攻击方法能显著降低模型性能，而提示模板中候选标签集的随机打乱也会导致性能大幅下降。在揭示这些脆弱性的同时，我们探索了通过数据增强和对抗训练等防御技术，显示出提升GraphLLMs鲁棒性的潜力。我们希望开源库能促进快速、公平的评估，并推动该领域的创新研究。

</details>


### [254] [Regression-adjusted Monte Carlo Estimators for Shapley Values and Probabilistic Values](https://arxiv.org/abs/2506.11849)
**中文标题：基于回归调整的蒙特卡洛估计器用于Shapley值和概率值**

*R. Teal Witter,Yurong Liu,Christopher Musco*

主要分类: cs.LG

摘要简述: 本文提出了一种结合蒙特卡洛采样和线性回归的新方法，用于高效计算概率值（如Shapley值），在多个数据集上表现优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 概率值（如Shapley值）在可解释AI中至关重要，但精确计算需要指数时间。现有方法（蒙特卡洛采样和线性回归）各有局限，本文旨在结合两者优势，提出更灵活的解决方案。

研究方法: 通过将线性回归替换为任何高效计算概率值的函数族（如XGBoost），结合蒙特卡洛采样，实现无偏估计。

研究结果: 实验表明，新方法在估计Shapley值时误差比Permutation SHAP低6.5倍，比Kernel SHAP低3.8倍，比Leverage SHAP低2.6倍；对广义概率值的误差比现有最优方法低215倍。

研究结论: 新方法在准确性和灵活性上优于现有技术，为概率值计算提供了更高效的解决方案。

中文摘要: 起源于博弈论的概率值（如Shapley值、Banzhaf值和半值）已成为可解释AI的核心工具，用于特征归因、数据归因和数据估值等。由于精确计算这些值需要指数时间，研究集中于两种高效近似方法：蒙特卡洛采样和线性回归。本文提出了一种结合这两种技术的新方法。我们的方法比现有算法更灵活，允许用任何高效计算概率值的函数族替代线性回归，从而利用XGBoost等树模型的准确性，同时保持无偏估计。在八个数据集的实验中，我们的方法在估计概率值方面表现最优。对于Shapley值，新方法的误差比Permutation SHAP（最流行的蒙特卡洛方法）低6.5倍，比Kernel SHAP（最流行的线性回归方法）低3.8倍，比Leverage SHAP（现有最优Shapley值估计器）低2.6倍。对于广义概率值，误差比现有最优方法低215倍。

</details>


### [255] [Robust Molecular Property Prediction via Densifying Scarce Labeled Data](https://arxiv.org/abs/2506.11877)
**中文标题：通过稠密化稀缺标记数据实现稳健的分子性质预测**

*Jina Kim,Jeffrey Willette,Bruno Andreis,Sung Ju Hwang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于元学习的新方法，利用未标记数据填补分布内与分布外数据之间的空白，显著提升了分子性质预测模型在分布外数据上的泛化性能。


<details>
  <summary>详细信息</summary>
研究动机: 分子预测模型通常依赖训练数据的结构，导致对分布外化合物的泛化能力差。在药物发现中，关键的化合物往往超出训练集范围，且标记数据稀缺，加剧了模型泛化的困难。

研究方法: 采用元学习方法，利用未标记数据在分布内与分布外数据之间进行插值，使模型能够学习如何超越训练分布的泛化能力。

研究结果: 在具有显著协变量偏移的真实数据集上，该方法显著优于现有技术，表现出更高的预测稳定性和准确性。

研究结论: 通过元学习利用未标记数据，本文方法有效解决了分子预测模型在分布外数据上的泛化问题，为药物发现提供了更可靠的预测工具。

中文摘要: 分子预测模型的一个普遍局限性是其对训练数据中结构的依赖，导致对分布外化合物的泛化能力较差。然而，在药物发现中，对研究进展至关重要的化合物往往超出训练集范围，使得模型对训练数据的偏向尤为严重。这种不匹配引入了显著的协变量偏移，在此情况下，标准的深度学习模型会产生不稳定和不准确的预测。此外，由于实验验证的繁琐和昂贵，标记数据的稀缺进一步加剧了实现可靠泛化的难度。为解决这些局限性，我们提出了一种基于元学习的新方法，利用未标记数据在分布内与分布外数据之间进行插值，使模型能够学习如何超越训练分布的泛化能力。我们在具有显著协变量偏移的真实数据集上展示了该方法相对于现有技术的显著性能提升。

</details>


### [256] [An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing](https://arxiv.org/abs/2506.11882)
**中文标题：一种用于车辆网络切片动态资源管理的可解释AI框架**

*Haochen Sun,Yifan Liu,Ahmed Al-Tahmeesschi,Swarna Chetty,Syed Ali Raza Zaidi,Avishek Nag,Hamed Ahmadi*

主要分类: cs.LG

摘要简述: 本文提出了一种基于可解释深度强化学习（XRL）的动态网络切片和资源分配框架，用于车辆网络，通过整合Shapley值和注意力机制提高决策的可解释性，并显著提升服务质量。


<details>
  <summary>详细信息</summary>
研究动机: 车辆网络的多样化服务需求（如eMBB和URLLC）要求高效的资源管理和网络切片，但现有方法缺乏可解释性，难以满足实时性和可靠性挑战。

研究方法: 采用可解释深度强化学习（XRL）框架，结合Shapley值和注意力机制，通过近实时RAN智能控制器动态分配资源并解释决策过程。

研究结果: 仿真结果显示，该方法在资源分配过程中提供了清晰的实时洞察，可解释性精度高于纯注意力机制，且URLLC和eMBB服务的QoS满意度分别提升至80.13%和73.21%。

研究结论: 该框架不仅提高了车辆网络资源分配的透明度和可靠性，还为未来智能网络管理提供了可扩展的解决方案。

中文摘要: 高效的资源管理和网络切片对于满足车辆网络的多样化服务需求（如增强移动宽带eMBB和超可靠低延迟通信URLLC）至关重要。本文提出了一种基于可解释深度强化学习（XRL）的动态网络切片和资源分配框架，依托近实时RAN智能控制器。通过整合基于Shapley值的特征方法和注意力机制，我们解释并优化了强化学习代理的决策，解决了车辆通信系统中的关键可靠性挑战。仿真结果表明，我们的方法为资源分配过程提供了清晰的实时洞察，且可解释性精度高于纯注意力机制。此外，URLLC服务的服务质量（QoS）满意度从78.0%提升至80.13%，而eMBB服务的QoS满意度从71.44%提升至73.21%。

</details>


### [257] [Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices](https://arxiv.org/abs/2506.11892)
**中文标题：基于注意力的对抗鲁棒蒸馏在低功耗物联网设备无线电信号分类中的应用**

*Lu Zhang,Sangarapillai Lambotharan,Gan Zheng,Guisheng Liao,Basil AsSadhan,Fabio Roli*

主要分类: cs.LG

摘要简述: 本文提出了一种基于注意力的对抗鲁棒蒸馏方法，用于低功耗物联网设备的无线电信号分类，旨在提升紧凑型Transformer在对抗攻击下的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 由于Transformer在自动调制分类中的成功应用，但其易受对抗样本攻击，且紧凑型Transformer难以实现鲁棒训练的优势，因此需要一种新方法来增强其对抗鲁棒性。

研究方法: 提出了一种新颖的紧凑型Transformer，通过将对抗注意力图从鲁棒训练的大型Transformer迁移到紧凑型Transformer中，以提升对抗攻击下的鲁棒性。

研究结果: 该方法在白盒攻击场景（如快速梯度法和投影梯度下降攻击）中优于现有技术，并研究了对抗样本在不同架构间的可迁移性。

研究结论: 所提方法能有效保护Transformer免受对抗样本迁移性的影响，适用于低功耗物联网设备。

中文摘要: 由于Transformer在自然语言处理和计算机视觉等领域的巨大成功，其已被成功应用于自动调制分类。然而，我们发现基于Transformer的无线电信号分类易受微小且精心设计的对抗样本攻击。因此，我们提出了一种针对基于Transformer的调制分类的对抗样本防御系统。考虑到物联网应用或设备在电源受限环境中的计算效率需求，我们提出了一种用于调制分类的紧凑型Transformer。然而，紧凑型Transformer可能无法实现鲁棒训练（如对抗训练）的优势。为此，我们提出了一种新颖的紧凑型Transformer，能够在对抗攻击下增强鲁棒性。该方法通过将对抗注意力图从鲁棒训练的大型Transformer迁移到紧凑型Transformer中实现。在包括快速梯度法和投影梯度下降攻击的白盒场景下，所提方法优于现有技术。我们还分析了其工作机制，并研究了对抗样本在不同架构间的可迁移性。该方法有望保护Transformer免受对抗样本迁移性的影响。

</details>


### [258] [A Neural Rejection System Against Universal Adversarial Perturbations in Radio Signal Classification](https://arxiv.org/abs/2506.11901)
**中文标题：针对无线电信号分类中通用对抗扰动的神经拒绝系统**

*Lu Zhang,Sangarapillai Lambotharan,Gan Zheng,Fabio Roli*

主要分类: cs.LG

摘要简述: 本文提出了一种神经拒绝系统，用于防御针对无线电信号分类的通用对抗扰动，显著提高了分类准确性。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，深度学习在无线电信号分类中表现出优于传统方法的性能，但对抗性扰动（尤其是通用对抗扰动）会显著降低其性能。因此，研究防御系统以应对此类扰动成为必要。

研究方法: 作者提出了一种神经拒绝系统，通过生成白盒通用对抗扰动来评估其防御性能。

研究结果: 实验表明，神经拒绝系统能够显著提高对通用对抗扰动的防御准确性，优于未防御的深度神经网络。

研究结论: 神经拒绝系统是一种有效的防御机制，能够显著提升无线电信号分类模型对抗通用对抗扰动的鲁棒性。

中文摘要: 近年来，深度学习在无线电信号分类中展现出优于传统方法的优势。然而，研究发现，即使是微小的对抗性扰动（即对抗样本）也可能显著降低基于深度学习的无线电信号分类性能。其中，通用对抗扰动因其与数据无关的特性而备受关注，成为一种高成功率欺骗分类器的实用策略。为此，本文研究了一种称为神经拒绝系统的防御机制，以应对通用对抗扰动，并通过生成白盒通用对抗扰动评估其性能。结果表明，所提出的神经拒绝系统能够以显著高于未防御深度神经网络的准确性防御通用对抗扰动。

</details>


### [259] [Spectra-to-Structure and Structure-to-Spectra Inference Across the Periodic Table](https://arxiv.org/abs/2506.11908)
**中文标题：周期表中光谱到结构与结构到光谱的跨元素推断**

*Yufeng Wang,Peiyao Wang,Lu Ma,Yuewei Lin,Qun Liu,Haibin Ling*

主要分类: cs.LG

摘要简述: 本文提出XAStruct框架，通过机器学习实现X射线吸收光谱（XAS）与晶体结构的双向预测，支持70多种元素的跨周期表分析，无需元素特定调优。


<details>
  <summary>详细信息</summary>
研究动机: XAS技术依赖专家分析和计算模拟，现有机器学习模型局限于特定元素或光谱类型，亟需一种通用且高效的分析方法。

研究方法: XAStruct结合深度神经网络与基线模型，分别训练光谱到结构和结构到光谱的双向任务，避免端到端模型的性能下降。

研究结果: XAStruct能预测XAS光谱及局部结构描述符，首次实现从XAS直接推断邻近原子类型，并在多种化学环境中表现优异。

研究结论: XAStruct为数据驱动的XAS分析和局部结构推断提供了可扩展的解决方案，代码将在论文接受后开源。

中文摘要: X射线吸收光谱（XAS）是探测局部原子环境的有力技术，但其解释仍受限于专家分析、计算密集型模拟和元素特定启发式方法。机器学习的最新进展为加速XAS解释提供了希望，但现有模型多局限于特定元素、边缘类型或光谱范围。本文提出XAStruct，一种既能从晶体结构预测XAS光谱，又能从XAS输入推断局部结构描述符的学习框架。XAStruct基于覆盖周期表中70多种元素的大规模数据集训练，可泛化至多种化学环境和键合状态。该模型首次实现从XAS光谱直接预测邻近原子类型的机器学习方法，并提出无需元素特定调优的最近邻距离统一回归模型。尽管尝试将两条任务整合为端到端模型，但实验结果显示性能下降，因此两项任务独立训练以确保最优精度。XAStruct通过结合深度神经网络与高效基线模型，为数据驱动的XAS分析和局部结构推断提供了可扩展的解决方案。源代码将在论文接受后发布。

</details>


### [260] [Breaking Habits: On the Role of the Advantage Function in Learning Causal State Representations](https://arxiv.org/abs/2506.11912)
**中文标题：打破习惯：优势函数在学习因果状态表示中的作用**

*Miguel Suau*

主要分类: cs.LG

摘要简述: 本文研究发现，优势函数不仅能降低梯度估计的方差，还能通过调整动作值减轻策略混淆的影响，帮助强化学习代理学习因果状态表示，提升泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 强化学习代理可能因策略混淆而利用奖励与观测之间的虚假相关性，导致泛化能力受限。本文旨在探讨优势函数如何通过调整动作值来减轻这种影响。

研究方法: 通过分析优势函数的作用机制，调整动作值以弱化当前策略下更可能出现的状态-动作对，从而打破虚假相关性，并鼓励代理关注因果因素。同时提供理论和实验验证。

研究结果: 理论和实证结果表明，使用优势函数训练能显著提升代理在非典型轨迹上的表现，减少策略混淆的影响。

研究结论: 优势函数在强化学习中不仅优化梯度估计，还能有效减轻策略混淆，帮助代理学习更鲁棒的因果状态表示。

中文摘要: 近期研究表明，强化学习代理可能因策略混淆而利用奖励与观测之间的虚假相关性。这种现象源于代理的策略同时影响过去和未来的观测变量，形成反馈循环，限制了代理在非典型轨迹上的泛化能力。本文证明，常用于策略梯度方法的优势函数不仅能降低梯度估计的方差，还能减轻策略混淆的影响。通过调整动作值相对于状态表示，优势函数弱化了当前策略下更可能出现的状态-动作对，打破虚假相关性，并鼓励代理关注因果因素。我们提供了理论和实证证据，表明使用优势函数训练能显著提升代理在非典型轨迹上的表现。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [261] [HQFNN: A Compact Quantum-Fuzzy Neural Network for Accurate Image Classification](https://arxiv.org/abs/2506.11146)
**中文标题：HQFNN：一种用于精确图像分类的紧凑量子-模糊神经网络**

*Jianhong Yao,Yangming Guo*

主要分类: quant-ph

摘要简述: 本文提出了一种新型的高度量子化模糊神经网络（HQFNN），通过将模糊推理与量子电路结合，实现了在图像分类任务中的高准确性和鲁棒性，同时大幅减少可训练参数。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习视觉系统在模式识别中表现出色，但在输入噪声或需要解释模型置信度时表现不佳。模糊推理和量子电路分别提供了透明性和参数效率，本研究旨在结合两者优势，设计一种紧凑且鲁棒的图像分类模型。

研究方法: HQFNN将模糊推理的整个流程嵌入浅层量子电路中，并通过轻量级CNN提取特征。具体包括：将图像特征映射为量子比特的成员状态，通过紧凑规则层优化振幅，使用聚类CNOT去模糊器生成清晰值，最后与经典特征融合进行分类。

研究结果: 在标准图像基准测试中，HQFNN优于经典、模糊增强和纯量子基线模型，且可训练参数大幅减少。在模拟噪声环境下，其准确性仅轻微下降，表现出内在鲁棒性。电路深度随输入维度次线性增长，适合处理更大图像。

研究结论: HQFNN作为一种紧凑、可解释且抗噪声的模型，为传统视觉主干提供了替代方案，并为未来量子原生模糊学习框架提供了模板。

中文摘要: 深度学习视觉系统在模式识别中表现出色，但在输入噪声或需要解释模型置信度时表现不佳。模糊推理通过其分级成员和规则透明性提供了解决方案，而参数化量子电路能以极高的参数效率将特征嵌入丰富的纠缠希尔伯特空间。本研究结合这些思想，提出了一种创新的高度量子化模糊神经网络（HQFNN），将整个模糊流程实现在浅层量子电路中，并将量子信号与轻量级CNN特征提取器耦合。每个图像特征首先通过重复角度重传映射为单个量子比特的成员状态，随后紧凑规则层优化这些振幅，聚类CNOT去模糊器将其坍缩为一个清晰值，最后与经典特征融合进行分类。在标准图像基准测试中，HQFNN始终优于经典、模糊增强和纯量子基线模型，同时使用数量级更少的可训练权重，且在模拟退极化和振幅阻尼噪声下准确性仅轻微下降，表现出内在鲁棒性。门数分析进一步表明电路深度随输入维度次线性增长，证实了模型在处理更大图像时的实用性。这些结果将HQFNN定位为一种紧凑、可解释且抗噪声的传统视觉主干替代方案，并为未来量子原生模糊学习框架提供了模板。

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [262] [Solving Inverse Problems in Stochastic Self-Organising Systems through Invariant Representations](https://arxiv.org/abs/2506.11796)
**中文标题：通过不变表示解决随机自组织系统中的逆问题**

*Elias Najarro,Nicolas Bessone,Sebastian Risi*

主要分类: nlin.AO

摘要简述: 本文提出了一种新颖的逆向建模方法，通过不变表示解决随机自组织系统中的逆问题，克服了传统方法在随机性观测中的局限性，并在理论和实验中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 自组织系统通过简单的局部规则生成复杂的随机模式，但传统逆向方法难以处理观测中的随机性。本文旨在解决这一挑战，提出一种能够捕捉感知不变性的方法。

研究方法: 利用视觉嵌入的能力，将模式表示映射到不变嵌入空间，从而无需手工设计目标函数或启发式方法即可恢复未知因果参数。

研究结果: 在反应-扩散系统和社会隔离的基于代理模型中，该方法可靠地恢复了参数，并成功应用于真实生物模式，展示了其在复杂随机模式形成研究中的潜力。

研究结论: 该方法为理论和实验研究者提供了一种有效工具，用于探索随机自组织系统的动态机制，克服了传统方法的局限性。

中文摘要: 自组织系统展示了简单的局部规则如何生成复杂的随机模式。许多自然系统依赖这种动态，使得自组织成为理解自然复杂性的核心。建模此类系统的一个基本挑战是解决逆问题：从宏观观测中找出未知的因果参数。当观测具有强随机性时，这一任务变得尤为困难，因为像素级指标无法捕捉不同结果之间的特征相似性。本文提出了一种专门处理观测空间随机性的新颖逆向建模方法，利用视觉嵌入的能力生成捕捉感知不变性的鲁棒表示。通过将模式表示映射到不变嵌入空间，我们能够有效恢复未知因果参数，而无需手工设计目标函数或启发式方法。我们在两个经典模型（反应-扩散系统和社会隔离的基于代理模型）上评估了该方法，结果表明它能够可靠地恢复参数，尽管结果具有随机性。我们进一步将该方法应用于真实生物模式，突显其作为理论和实验工具研究复杂随机模式形成动态的潜力。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [263] [Brain2Vec: A Deep Learning Framework for EEG-Based Stress Detection Using CNN-LSTM-Attention](https://arxiv.org/abs/2506.11179)
**中文标题：Brain2Vec：基于CNN-LSTM-注意力机制的EEG信号压力检测深度学习框架**

*Md Mynoddin,Troyee Dev,Rishita Chakma*

主要分类: eess.SP

摘要简述: 本文提出了一种名为Brain2Vec的深度学习框架，结合CNN、LSTM和注意力机制，用于基于EEG信号的压力检测。模型在DEAP数据集上表现优异，验证准确率达81.25%，AUC为0.68，展示了其在可穿戴设备和个性化医疗中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 心理健康问题日益普遍，亟需开发非侵入性且可靠的诊断工具。EEG信号虽能直接反映神经活动，但其非平稳性和高维度特性为建模带来挑战。本文旨在通过深度学习技术解决这一问题。

研究方法: Brain2Vec采用混合架构，包括卷积层（CNN）捕捉空间依赖关系，LSTM层建模时序模式，以及注意力机制突出关键时间区域。预处理包括带通滤波、z-score标准化和分段处理。

研究结果: 在DEAP数据集上，Brain2Vec的验证准确率为81.25%，AUC得分为0.68，显著优于传统CNN-LSTM基线模型。

研究结论: Brain2Vec在EEG信号压力检测中表现出色，具备集成到可穿戴设备和个性化医疗系统的潜力，为心理健康监测提供了新工具。

中文摘要: 心理压力已成为影响认知健康和整体福祉的普遍因素，亟需开发可靠的非侵入性诊断工具。脑电图（EEG）信号为神经活动提供了直接窗口，但其非平稳性和高维度特性带来了显著的建模挑战。本文提出Brain2Vec，一种新的深度学习工具，通过结合卷积、循环和注意力机制的混合架构，从原始EEG信号中分类压力状态。模型首先通过卷积层捕捉局部空间依赖关系，随后通过LSTM层建模时序模式，最后通过注意力机制突出关键时间区域。我们在DEAP数据集上评估Brain2Vec，采用带通滤波、z-score标准化和分段处理作为预处理流程。与传统CNN-LSTM基线相比，所提模型的AUC得分为0.68，验证准确率达81.25%。这些结果表明，Brain2Vec具备集成到可穿戴压力监测平台和个性化医疗系统的潜力。

</details>


### [264] [Diffusion-Based Electrocardiography Noise Quantification via Anomaly Detection](https://arxiv.org/abs/2506.11815)
**中文标题：基于扩散模型的心电图噪声量化异常检测方法**

*Tae-Seong Han,Jae-Wook Heo,Hakseung Kim,Cheol-Hui Lee,Hyub Huh,Eue-Keun Choi,Dong-Joo Kim*

主要分类: eess.SP

摘要简述: 本文提出了一种基于扩散模型的ECG噪声量化方法，通过异常检测和Wasserstein-1距离评估噪声分布，显著优于现有方法，并展示了强大的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 心电图（ECG）信号常受噪声干扰，影响临床和可穿戴设备的诊断准确性。传统方法存在标注不一致和泛化能力有限的问题，亟需一种更鲁棒的噪声量化方法。

研究方法: 采用基于扩散模型的框架，通过重构异常检测量化ECG噪声。引入Wasserstein-1距离（$W_1$）比较干净和噪声ECG的重构误差分布，仅需三步反向扩散步骤即可实现鲁棒噪声量化。

研究结果: 模型在基准测试中取得了1.308的宏平均$W_1$分数，优于次优方法48%以上。外部验证表明其泛化能力强，可有效排除低质量信号段，提升诊断准确性。

研究结论: 该方法显著提升了临床决策、诊断准确性和实时ECG监测能力，为临床和可穿戴ECG应用的未来发展提供了支持。

中文摘要: 心电图（ECG）信号常因噪声干扰而质量下降，增加了临床和可穿戴设备诊断的复杂性。本研究提出了一种基于扩散模型的框架，通过重构异常检测实现ECG噪声量化，解决了传统方法标注不一致和泛化能力有限的问题。我们引入Wasserstein-1距离（$W_1$）比较干净和噪声ECG的重构误差分布，以减少标注不一致的影响。最终模型仅需三步反向扩散步骤即可实现鲁棒的噪声量化。在基准测试中，模型的宏平均$W_1$分数为1.308，优于次优方法48%以上。外部验证表明其泛化能力强，支持排除低质量信号段以提升诊断准确性，并实现对信号退化的及时临床响应。该方法有助于提升临床决策、诊断准确性和实时ECG监测能力，为未来临床和可穿戴ECG应用的发展提供了支持。

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [265] [Complexity of normalized stochastic first-order methods with momentum under heavy-tailed noise](https://arxiv.org/abs/2506.11214)
**中文标题：重尾噪声下归一化随机一阶动量方法的复杂度分析**

*Chuan He,Zhaosong Lu,Defeng Sun,Zhanwang Deng*

主要分类: math.OC

摘要简述: 本文提出了一种归一化随机一阶方法，结合Polyak动量、多外推动量和递归动量，用于解决无约束优化问题。方法动态更新参数，无需依赖问题相关量（如Lipschitz常数或噪声边界），并在重尾噪声和弱平均光滑条件下实现了近似随机稳定点的首次复杂度分析，优于或匹配现有最佳结果。


<details>
  <summary>详细信息</summary>
研究动机: 现有随机一阶方法通常依赖于强假设（如方差有界或均方光滑），限制了其在实际问题中的应用。本文旨在开发一种更通用的方法，能够在更弱的条件下（如重尾噪声和弱平均光滑）高效求解优化问题。

研究方法: 提出归一化随机一阶方法，结合Polyak动量、多外推动量和递归动量，动态调整算法参数，无需显式依赖问题相关量（如Lipschitz常数或噪声边界）。

研究结果: 在重尾噪声和弱平均光滑条件下，首次实现了近似随机稳定点的复杂度分析，结果优于或匹配现有最佳文献结果。数值实验验证了方法的实际有效性。

研究结论: 本文提出的归一化随机一阶方法在弱条件下表现出色，复杂度分析结果优于或匹配现有方法，为实际优化问题提供了更通用的解决方案。

中文摘要: 本文提出了一种实用的归一化随机一阶方法，结合Polyak动量、多外推动量和递归动量，用于解决无约束优化问题。这些方法采用动态更新的算法参数，无需依赖问题相关量（如Lipschitz常数或噪声边界）。在重尾噪声和弱平均光滑条件下，我们建立了寻找近似随机稳定点的首次复杂度分析结果——这些条件比常用的方差有界和均方光滑假设更弱。我们的复杂度结果优于或匹配文献中的最佳结果。数值实验展示了所提方法的实际有效性。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [266] [The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI](https://arxiv.org/abs/2506.11015)
**中文标题：记忆悖论：AI时代为何我们的大脑仍需要知识**

*Barbara Oakley,Michael Johnston,Ken-Zen Chen,Eulho Jung,Terrence J. Sejnowski*

主要分类: cs.CY

摘要简述: 在生成式AI和数字工具普及的时代，人类认知面临一个结构性悖论：外部辅助工具越强大，内部记忆系统越可能退化。本文结合神经科学和认知心理学，探讨过度依赖AI和发现式教学如何损害陈述性和程序性记忆的巩固，并强调强健的内部模型对人类与AI有效互动的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI工具如ChatGPT和计算器的普及，人类记忆系统可能因过度依赖外部辅助而退化。本文旨在探讨这种依赖如何影响记忆巩固和认知能力，并提出人类与AI有效互动的基础是强健的内部记忆模型。

研究方法: 本文结合神经科学和认知心理学理论，分析AI工具对记忆系统的影响，并通过实证研究探讨过早依赖AI如何阻碍程序化和直觉掌握。

研究结果: 研究表明，过度依赖AI工具会抑制记忆的检索、纠错和模式构建过程，从而损害长期记忆和认知能力。同时，深度学习中的“顿悟”现象与神经科学中的过度学习和直觉有显著相似性。

研究结论: 有效的AI互动依赖于强健的内部记忆模型（如生物“图式”和神经流形），这些模型能帮助用户评估、优化和指导AI输出。本文还提出了教育和职业培训在大型语言模型时代的政策建议。

中文摘要: 在生成式AI和数字工具普及的时代，人类认知面临一个结构性悖论：外部辅助工具越强大，内部记忆系统越可能退化。本文结合神经科学和认知心理学，探讨过度依赖AI系统和发现式教学如何损害陈述性和程序性记忆的巩固——这些系统对专业知识、批判性思维和长期记忆至关重要。我们分析了ChatGPT和计算器等工具如何绕过检索、纠错和模式构建过程，而这些过程对强健的神经编码必不可少。值得注意的是，我们强调了深度学习中的“顿悟”现象与神经科学中的过度学习和直觉之间的显著相似性。实证研究表明，学习过程中过早依赖AI会阻碍程序化和直觉掌握。我们认为，有效的人机互动依赖于强健的内部模型——生物“图式”和神经流形——这些模型能帮助用户评估、优化和指导AI输出。最后，本文探讨了大型语言模型时代对教育和职业培训的政策启示。

</details>


### [267] [The Strategic Imperative for Healthcare Organizations to Build Proprietary Foundation Models](https://arxiv.org/abs/2506.11412)
**中文标题：医疗组织构建专有基础模型的战略必要性**

*Naresh Tiwari*

主要分类: cs.CY

摘要简述: 本文分析了医疗组织开发专有基础模型的战略必要性，指出其优于商业替代品的四大原因：领域特定需求、数据主权、竞争优势及对患者护理的变革潜力。


<details>
  <summary>详细信息</summary>
研究动机: 医疗组织需摆脱对商业基础模型的依赖，开发专有模型以满足领域特定需求、确保数据主权、获取竞争优势并推动医疗创新。

研究方法: 通过实证分析、经济框架评估和组织案例研究，探讨专有多模态基础模型对医疗组织的价值。

研究结果: 专有模型能提升临床绩效、强化数据治理、创造可持续竞争优势并加速创新，尽管实施存在挑战。

研究结论: 专有基础模型是前瞻性医疗组织的核心能力，为领导者提供了构建与购买决策的全面框架。

中文摘要: 本文全面分析了医疗组织开发专有基础模型而非依赖商业替代品的战略必要性。我们探讨了推动这一必要性的四大核心因素：医疗数据表示的领域特定需求、医疗特有的数据主权与治理问题、专有AI基础设施带来的战略竞争优势，以及医疗专用基础模型对患者护理和组织运营的变革潜力。通过实证证据、经济框架和组织案例研究，我们证明专有多模态基础模型能使医疗组织实现更优的临床绩效、保持强大的数据治理、创造可持续竞争优势并加速创新路径。尽管承认实施挑战，但研究表明，具备专有AI能力的组织在医疗生态系统中表现出显著改善的成果、更快的创新周期和更强的战略定位。本分析为医疗领导者提供了评估基础模型构建与购买决策的全面框架，将专有基础模型开发定位为前瞻性医疗组织的基石能力。

</details>


### [268] [Subjective Experience in AI Systems: What Do AI Researchers and the Public Believe?](https://arxiv.org/abs/2506.11945)
**中文标题：AI系统中的主观体验：AI研究人员与公众的认知差异**

*Noemi Dreksler,Lucius Caviola,David Chalmers,Carter Allen,Alex Rand,Joshua Lewis,Philip Waggoner,Kate Mays,Jeff Sebo*

主要分类: cs.CY

摘要简述: 本文调查了AI研究人员和公众对具有主观体验的AI系统的看法，发现双方对其发展时间表和治理态度存在差异，但均认为需要多学科合作评估，并支持实施风险防范措施。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在了解AI研究人员和公众对具有主观体验的AI系统的可能性、时间表及治理态度的看法，以填补相关领域的认知空白。

研究方法: 通过问卷调查582名在顶级AI会议上发表过论文的研究人员和838名美国代表性公众，收集他们对AI主观体验系统的估计和治理意见。

研究结果: 结果显示，AI研究人员和公众对AI系统具有主观体验的可能性估计存在差异，但均认为需要多学科评估。双方对福利保护和治理态度分歧较大，但多数支持实施风险防范措施。

研究结论: 研究表明，AI研究人员和公众均认为具有主观体验的AI系统可能在本世纪出现，但在时间表和应对措施上存在显著不确定性和分歧。

中文摘要: 我们调查了582名在顶级AI会议上发表过论文的研究人员和838名具有全国代表性的美国公众，了解他们对具有主观体验的AI系统的发展潜力及其治理方式的看法。当被问及此类系统在特定时间点存在的可能性时，中位数回答为：2024年AI研究人员和公众分别为1%和5%，2034年为25%和30%，2100年为70%和60%。公众中位数认为AI系统永远不会具有主观体验的可能性（25%）高于AI研究人员（10%）。两组均认为需要多学科专业知识来评估AI的主观体验。尽管对这类AI系统的福利保护支持超过反对，但仍远低于对动物或环境的保护支持。两组在道德和治理问题上态度分歧，尤其是关于是否应创建此类系统及其应享有的权利或保护。然而，两组多数受访者同意，AI开发者应现在就实施针对潜在风险的防范措施，且如果创建，具有主观体验的AI系统应善待他人、行为道德并承担责任。总体而言，这些结果表明，AI研究人员和公众均认为具有主观体验的AI系统可能在本世纪出现，但在时间表和应对措施上仍存在显著不确定性和分歧。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [269] [Anti-Aliased 2D Gaussian Splatting](https://arxiv.org/abs/2506.11252)
**中文标题：抗锯齿的2D高斯泼溅**

*Mae Younes,Adnane Boukhayma*

主要分类: cs.GR

摘要简述: 本文提出了一种抗锯齿的2D高斯泼溅方法（AA-2DGS），解决了2D高斯泼溅在不同采样率下渲染时的严重锯齿问题，显著提升了多尺度下的渲染质量。


<details>
  <summary>详细信息</summary>
研究动机: 2D高斯泼溅（2DGS）在新视角合成和表面重建中表现出色，但在训练与渲染采样率不一致时会产生严重锯齿，限制了其在需要变焦或不同视场角场景中的应用。本文旨在解决这一问题。

研究方法: AA-2DGS通过引入世界空间平滑核约束2D高斯基元的频率内容，并结合对象空间的Mip滤波器，直接在局部空间应用抗锯齿，有效消除高频伪影。

研究结果: 实验表明，AA-2DGS在保持几何优势的同时，显著提升了不同尺度下的渲染质量，消除了变焦时的高频伪影。

研究结论: AA-2DGS成功解决了2DGS的锯齿问题，为多尺度渲染提供了高质量的解决方案。

中文摘要: 2D高斯泼溅（2DGS）作为一种新视角合成和表面重建的方法，近年来表现出优于体积3DGS的视角一致性和几何精度。然而，当渲染采样率与训练时不一致时，2DGS会产生严重的锯齿伪影，限制了其在需要相机变焦或不同视场角场景中的应用。我们发现这些问题源于两个关键限制：表示中缺乏频率约束和屏幕空间钳位方法的低效性。为解决这些问题，我们提出了AA-2DGS，一种抗锯齿的2D高斯泼溅方法，在保持几何优势的同时显著提升了多尺度下的渲染质量。我们的方法引入了一个世界空间平滑核，基于训练视图的最大采样频率约束2D高斯基元的频率内容，有效消除了变焦时的高频伪影。此外，我们通过利用射线-泼溅交映射的仿射近似，推导出一种新颖的对象空间Mip滤波器，可直接在每个泼溅的局部空间高效应用抗锯齿。

</details>


### [270] [CGVQM+D: Computer Graphics Video Quality Metric and Dataset](https://arxiv.org/abs/2506.11546)
**中文标题：CGVQM+D：计算机图形视频质量度量与数据集**

*Akshay Jindal,Nabil Sadaka,Manu Mathew Thomas,Anton Sochenov,Anton Kaplanyan*

主要分类: cs.GR

摘要简述: 本文提出了一种专注于高级渲染技术引入失真的视频质量数据集CGVQM+D，并开发了新的全参考视频质量度量CGVQM，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频和图像质量数据集主要研究自然视频和传统失真，但对合成内容和现代渲染失真的感知研究不足。本文旨在填补这一空白。

研究方法: 构建了一个包含神经超采样、新视角合成、路径追踪等高级渲染技术失真的数据集，并基于预训练3D CNN的特征空间开发了CGVQM度量。

研究结果: 现有全参考质量度量在这些失真上表现不佳（最大Pearson相关系数0.78），而CGVQM显著优于现有方法，同时生成逐像素误差图和全局质量分数。

研究结论: CGVQM+D数据集和CGVQM度量为合成内容和现代渲染失真的质量评估提供了新工具，未来可进一步优化。

中文摘要: 尽管现有视频和图像质量数据集对自然视频和传统失真进行了广泛研究，但对合成内容和现代渲染失真的感知仍缺乏深入探索。我们提出了一种专注于高级渲染技术引入失真的视频质量数据集，包括神经超采样、新视角合成、路径追踪、神经去噪、帧插值和可变速率着色。评估显示，现有全参考质量度量在这些失真上表现不佳，最大Pearson相关系数为0.78。此外，我们发现预训练3D CNN的特征空间与人类视觉质量感知高度一致。我们提出了CGVQM，一种显著优于现有度量的全参考视频质量度量，同时生成逐像素误差图和全局质量分数。数据集和度量实现可在https://github.com/IntelLabs/CGVQM获取。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [271] [Generative Representational Learning of Foundation Models for Recommendation](https://arxiv.org/abs/2506.11999)
**中文标题：推荐基础模型的生成式表征学习**

*Zheli Zhou,Chenxu Zhu,Jianghao Lin,Bo Chen,Ruiming Tang,Weinan Zhang,Yong Yu*

主要分类: cs.IR

摘要简述: RecFound是一种生成式表征学习框架，用于推荐基础模型，通过多任务训练方案解决知识共享与冲突、收敛速度不一致等问题，并在实验中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前推荐基础模型在生成任务中表现突出，但忽视了嵌入任务，且难以应对多任务学习的复杂性（如知识共享与冲突、收敛速度不一致）。RecFound旨在解决这些局限性。

研究方法: RecFound提出了一种多任务训练方案，包括任务级低秩专家混合（TMoLE）处理知识共享与冲突，逐步收敛导向样本调度器（S2Sched）解决收敛不一致，以及模型合并模块平衡任务性能。

研究结果: 实验表明，RecFound在多种推荐任务中表现优异，优于现有基线方法。

研究结论: RecFound通过创新的多任务训练方案，显著提升了推荐基础模型的性能，为领域提供了新的解决方案。

中文摘要: 开发一个能在多样任务中表现出色的单一基础模型一直是人工智能领域的长期目标。随着通用基础模型浪潮席卷各领域，其影响力已显著扩展至推荐系统领域。尽管近期研究探索了推荐基础模型在多种生成任务中的应用，但它们往往忽视了关键的嵌入任务，并难以应对多任务学习的复杂性，包括知识共享与冲突解决以及收敛速度不一致等问题。为解决这些局限性，我们提出了RecFound，一种用于推荐基础模型的生成式表征学习框架。我们构建了首个覆盖多样场景下生成与嵌入任务的推荐基础模型综合数据集。基于此数据集，我们提出了一种新颖的多任务训练方案，包括任务级低秩专家混合（TMoLE）以处理知识共享与冲突，逐步收敛导向样本调度器（S2Sched）以解决收敛不一致，以及模型合并模块以平衡任务性能。实验表明，RecFound在多种推荐任务中实现了最先进的性能，优于现有基线方法。

</details>


### [272] [Deep Learning Model Acceleration and Optimization Strategies for Real-Time Recommendation Systems](https://arxiv.org/abs/2506.11421)
**中文标题：实时推荐系统中深度学习模型的加速与优化策略**

*Junli Shao,Jing Dong,Dingzhou Wang,Kowei Shih,Dannier Li,Chengrui Zhou*

主要分类: cs.IR

摘要简述: 本文提出了一种结合模型和系统层面的加速与优化策略，显著降低了实时推荐系统的推理延迟并提高了吞吐量，同时保持了推荐质量。


<details>
  <summary>详细信息</summary>
研究动机: 随着互联网服务的快速发展，推荐系统在提供个性化内容方面扮演着核心角色。然而，面对海量用户请求和复杂模型架构，如何在保证推荐质量的同时降低推理延迟并提高系统吞吐量成为实时推荐系统的关键挑战。

研究方法: 在模型层面，通过轻量级网络设计、结构化剪枝和权重量化，大幅减少参数数量和计算需求；在系统层面，整合多种异构计算平台和高性能推理库，并基于实时负载特性设计弹性推理调度和负载均衡机制。

研究结果: 实验表明，在保持原有推荐准确性的同时，该方法将延迟降低至基线的30%以下，系统吞吐量提升了一倍以上。

研究结论: 本文提出的方法为大规模在线推荐服务的部署提供了实用解决方案。

中文摘要: 随着互联网服务的快速发展，推荐系统在提供个性化内容方面扮演着核心角色。面对海量用户请求和复杂模型架构，实时推荐系统的关键挑战是如何在不牺牲推荐质量的情况下降低推理延迟并提高系统吞吐量。本文通过提出一套结合模型和系统层面的加速与优化策略，解决了深度学习模型在实时环境中的高计算成本和资源瓶颈问题。在模型层面，我们通过轻量级网络设计、结构化剪枝和权重量化，大幅减少了参数数量和计算需求；在系统层面，我们整合了多种异构计算平台和高性能推理库，并基于实时负载特性设计了弹性推理调度和负载均衡机制。实验表明，在保持原有推荐准确性的同时，我们的方法将延迟降低至基线的30%以下，系统吞吐量提升了一倍以上，为大规模在线推荐服务的部署提供了实用解决方案。

</details>


### [273] [GraphRAG-Causal: A novel graph-augmented framework for causal reasoning and annotation in news](https://arxiv.org/abs/2506.11600)
**中文标题：GraphRAG-Causal：一种用于新闻因果推理与标注的新型图增强框架**

*Abdul Haque,Umm e Hani,Ahmad Din,Muhammad Babar,Ali Abbas,Insaf Ullah*

主要分类: cs.IR

摘要简述: GraphRAG-Causal提出了一种结合图检索与大型语言模型的新框架，用于增强新闻中的因果推理。通过构建因果知识图并利用混合检索系统，该框架显著提升了因果分类的准确性和一致性，适用于实时新闻分析。


<details>
  <summary>详细信息</summary>
研究动机: 传统NLP方法在识别复杂、隐式因果关系时表现不佳，尤其是在数据稀缺的情况下。GraphRAG-Causal旨在通过图结构和语义嵌入的结合，解决这一问题，提升新闻分析的可靠性。

研究方法: 框架分为三个阶段：1) 数据准备阶段，将新闻句子标注并转化为因果图；2) 图检索阶段，利用Neo4j存储图和嵌入，并通过混合查询检索相关事件；3) LLM推理阶段，使用检索到的因果图进行少样本学习，分类和标注因果关系。

研究结果: 实验表明，GraphRAG-Causal在仅使用20个少样本示例的情况下，因果分类的F1分数达到82.1%，显著提升了准确性和一致性。

研究结论: GraphRAG-Causal通过结合图检索和语言模型，有效提升了新闻中因果推理的能力，适用于实时新闻可靠性评估、错误信息检测和政策分析。

中文摘要: GraphRAG-Causal提出了一种创新的框架，结合基于图的检索与大型语言模型，以增强新闻分析中的因果推理能力。传统NLP方法在识别复杂、隐式因果关系时表现不佳，尤其是在数据稀缺的情况下。我们的方法通过将标注的新闻标题转化为结构化的因果知识图，并采用混合检索系统（结合语义嵌入和图结构线索，利用Neo4j精确匹配和检索相关事件）来解决这些问题。该框架基于三阶段流程：首先，在数据准备阶段，新闻句子被细致标注并转化为因果图，捕捉原因、结果和触发关系；其次，在图检索阶段，这些图及其嵌入被存储在Neo4j数据库中，并通过混合Cypher查询高效识别与查询具有语义和结构相似性的事件；最后，在LLM推理阶段，利用检索到的因果图进行少样本学习，基于XML提示实现因果关系的鲁棒分类和标注。实验评估表明，GraphRAG-Causal在仅使用20个少样本示例的情况下，因果分类的F1分数达到82.1%。该方法显著提升了准确性和一致性，非常适合用于新闻可靠性评估、错误信息检测和政策分析的实时应用。

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [274] [Multimodal Modeling of CRISPR-Cas12 Activity Using Foundation Models and Chromatin Accessibility Data](https://arxiv.org/abs/2506.11182)
**中文标题：利用基础模型和染色质可及性数据对CRISPR-Cas12活性的多模态建模**

*Azim Dehghani Amirabad,Yanfei Zhang,Artem Moskalev,Sowmya Rajesh,Tommaso Mansi,Shuwei Li,Mangal Prakash,Rui Liao*

主要分类: q-bio.GN

摘要简述: 本文探讨了利用预训练的生物学基础模型和染色质可及性数据提升CRISPR-Cas12引导RNA（gRNA）活性预测的方法，结果显示其显著优于传统基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 由于数据有限、Cas结合所需的短序列（PAM）变异以及依赖大规模训练，预测gRNA活性仍然具有挑战性。研究旨在验证预训练的生物学基础模型是否能在无领域特定预训练的情况下提升gRNA活性预测。

研究方法: 使用基于转录组数据预训练的RNA基础模型的嵌入作为轻量级回归器的输入，并结合染色质可及性数据以捕捉调控背景。

研究结果: 该方法显著优于传统基线模型，且整合染色质可及性数据进一步提升了预测性能。

研究结论: 预训练的基础模型和染色质可及性数据在gRNA活性预测中具有显著效果。

中文摘要: 预测引导RNA（gRNA）活性对有效的CRISPR-Cas12基因组编辑至关重要，但由于数据有限、Cas结合所需的短序列（PAM）变异以及依赖大规模训练，这一任务仍具挑战性。我们研究了基于转录组数据预训练的生物学基础模型是否能在无领域特定预训练的情况下提升gRNA活性估计。通过将现有RNA基础模型的嵌入作为轻量级回归器的输入，我们展示了其显著优于传统基线模型的表现。我们还整合了染色质可及性数据以捕捉调控背景，进一步提升了性能。结果表明，预训练的基础模型和染色质可及性数据在gRNA活性预测中具有显著效果。

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [275] [Measuring multi-calibration](https://arxiv.org/abs/2506.11251)
**中文标题：衡量多校准性**

*Ido Guy,Daniel Haimovich,Fridolin Linder,Nastaran Okati,Lorenzo Perini,Niek Tax,Mark Tygert*

主要分类: stat.ME

摘要简述: 本文提出了一种基于Kuiper统计量的新指标，用于衡量多校准性，并通过信号噪声比加权子群体贡献，避免了传统分箱或核密度估计方法的缺陷。


<details>
  <summary>详细信息</summary>
研究动机: 在实践中，概率预测很少能完美实现多校准性，因此需要一个统计量来衡量与完美多校准性的距离。本文旨在解决现有校准指标的问题，提出一种更优的衡量方法。

研究方法: 基于经典Kuiper统计量，提出了一种新的多校准性指标，并通过信号噪声比加权不同子群体的贡献，避免了分箱或核密度估计方法的常见问题。

研究结果: 数值实验表明，新指标在忽略信号噪声比时会变得不稳定，而加权后的指标在基准数据集上表现良好。

研究结论: 新提出的多校准性指标有效解决了传统方法的缺陷，并通过信号噪声比加权提升了指标的稳定性和实用性。

中文摘要: 合适的标量指标有助于衡量多校准性，其定义如下：当观测响应的期望值等于对应的预测概率时，概率预测被称为“完美校准”。当预测概率在多个子群体中同时完美校准时，概率预测被称为“完美多校准”。实践中，预测概率很少能完美多校准，因此衡量与完美多校准距离的统计量很有意义。最近提出的一种基于经典Kuiper统计量的校准指标，为新的多校准性指标提供了自然基础，并避免了基于分箱或核密度估计的指标的已知问题。新提出的指标按信号噪声比加权不同子群体的贡献；数据分析表明，忽略信号噪声比会导致指标变得不稳定。基准数据集上的数值示例展示了新指标的效果。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [276] [Grids Often Outperform Implicit Neural Representations](https://arxiv.org/abs/2506.11139)
**中文标题：网格表示通常优于隐式神经表示**

*Namhoon Kim,Sara Fridovich-Keil*

主要分类: eess.IV

摘要简述: 研究发现，对于大多数任务和信号，简单的正则化网格插值方法比相同参数数量的隐式神经表示（INRs）训练更快且效果更好。INRs仅在拟合具有低维结构（如形状轮廓）的信号时表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 隐式神经表示（INRs）近年来表现出色，但其基本能力、隐式偏差和扩展行为尚不明确。本文旨在通过对比INRs与网格表示的性能，揭示其适用场景。

研究方法: 研究通过分析多种INRs在2D和3D真实与合成信号上的表现，包括不同有效带宽的信号以及过拟合和泛化任务（如断层扫描、超分辨率和去噪），并根据模型大小、信号类型和带宽对性能进行分层比较。

研究结果: 结果表明，对于大多数任务和信号，正则化网格插值方法比相同参数数量的INRs训练更快且效果更好。INRs仅在拟合低维结构（如形状轮廓）的信号时表现更优。

研究结论: 研究建议未来INRs的应用应集中在最能发挥其优势的场景，如处理具有低维结构的信号。

中文摘要: 隐式神经表示（INRs）近年来表现出色，但其基本能力、隐式偏差和扩展行为尚不明确。我们研究了多种INRs在2D和3D真实与合成信号上的表现，包括不同有效带宽的信号以及过拟合和泛化任务（如断层扫描、超分辨率和去噪）。通过根据模型大小、信号类型和带宽对性能进行分层比较，我们的结果揭示了不同INRs和网格表示如何分配其能力。研究发现，对于大多数任务和信号，简单的正则化网格插值方法比相同参数数量的INRs训练更快且效果更好。同时，我们也发现INRs在少数情况下表现更优，例如拟合具有低维结构（如形状轮廓）的信号。这些发现为未来INRs的应用提供了指导。代码和分析中使用的合成信号可在https://github.com/voilalab/INR-benchmark获取。

</details>


### [277] [ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator](https://arxiv.org/abs/2506.11150)
**中文标题：ADAgent：基于协作协调器的阿尔茨海默病分析大语言模型代理**

*Wenlong Hou,Gangqian Yang,Ye Du,Yeung Lau,Lihao Liu,Junjun He,Ling Long,Shujun Wang*

主要分类: eess.IV

摘要简述: 本文提出ADAgent，首个基于大语言模型（LLM）的阿尔茨海默病（AD）分析AI代理，通过整合推理引擎、专业医疗工具和协作结果协调器，实现多模态诊断和预后任务，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 阿尔茨海默病（AD）是一种不可逆的神经退行性疾病，早期精准诊断对干预和治疗至关重要。现有方法多依赖单模态数据，无法处理多模态或缺失输入，亟需一种能整合多种先进方法的系统。

研究方法: ADAgent基于大语言模型（LLM），整合推理引擎、专业医疗工具和协作结果协调器，支持多模态诊断和预后任务，并能处理用户查询和决策支持。

研究结果: 实验表明，ADAgent在多模态诊断任务中准确率提升2.7%，多模态预后任务提升0.7%，并在MRI和PET诊断任务中表现优异。

研究结论: ADAgent是首个针对AD分析的AI代理，通过多模态协作显著提升了诊断和预后性能，为AD研究和临床实践提供了新工具。

中文摘要: 阿尔茨海默病（AD）是一种渐进性且不可逆的神经退行性疾病。早期精准诊断对及时干预和治疗规划至关重要，以缓解神经退行性进展。然而，现有方法多依赖单模态数据，与医学专家的多角度分析形成对比。尽管一些深度学习方法处理多模态数据，但仅限于特定任务和少量输入模态，无法处理任意组合。这凸显了需要一种系统，能够应对多样化的AD相关任务，处理多模态或缺失输入，并整合多种先进方法以提高性能。本文提出ADAgent，首个基于大语言模型（LLM）的AD分析AI代理，用于解决用户查询和支持决策。ADAgent整合了推理引擎、专业医疗工具和协作结果协调器，以支持AD的多模态诊断和预后任务。大量实验表明，ADAgent优于现有方法，在多模态诊断中准确率提升2.7%，多模态预后提升0.7%，并在MRI和PET诊断任务中表现优异。

</details>


### [278] [Vector Representations of Vessel Trees](https://arxiv.org/abs/2506.11163)
**中文标题：血管树的向量表示**

*James Batten,Michiel Schaap,Matthew Sinclair,Ying Bai,Ben Glocker*

主要分类: eess.IV

摘要简述: 提出了一种名为VeTTA的新型框架，用于学习树状几何数据（如3D血管网络）的向量表示，通过两阶段Transformer自编码器实现高效建模，显著降低GPU内存需求，并在实验中表现出优异的重建保真度和拓扑一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D卷积模型在处理树状几何数据（如血管网络）时，GPU内存需求高且难以保持拓扑一致性。因此，需要一种更高效、灵活且能准确建模树状结构的方法。

研究方法: 采用两阶段Transformer自编码器：第一阶段（Vessel Autoencoder）学习单个血管段的几何细节；第二阶段（Vessel Tree Autoencoder）编码整个血管网络的拓扑结构为单一向量表示，并通过递归解码确保重建的树结构有效。

研究结果: 在2D合成树数据集和3D冠状动脉数据集上的实验表明，VeTTA框架在重建保真度、拓扑保持和潜在空间插值方面优于3D卷积模型，同时显著降低了GPU内存需求。

研究结论: VeTTA框架为医学影像中的树状结构提供了精确、灵活且拓扑一致的建模方法，具有大规模训练的潜力。

中文摘要: 我们提出了一种新型框架，用于学习树状几何数据（尤其是3D血管网络）的向量表示。该方法采用两个顺序训练的基于Transformer的自编码器。第一阶段，血管自编码器通过沿每条曲线采样点学习嵌入，捕捉单个血管段的连续几何细节。第二阶段，血管树自编码器利用第一阶段模型的段级嵌入，将血管网络的拓扑结构编码为单一向量表示。递归解码过程确保重建的拓扑结构是有效的树状结构。与3D卷积模型相比，该方法显著降低了GPU内存需求，便于大规模训练。在2D合成树数据集和3D冠状动脉数据集上的实验结果表明，该方法具有优异的重建保真度、准确的拓扑保持能力以及潜在空间中的真实插值效果。我们的可扩展框架VeTTA为医学影像中的解剖树状结构提供了精确、灵活且拓扑一致的建模方法。

</details>


### [279] [DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning](https://arxiv.org/abs/2506.11183)
**中文标题：DiffPR：基于频率解耦学习的扩散相位重建**

*Yi Zhang*

主要分类: eess.IV

摘要简述: DiffPR通过频率解耦学习框架解决深度学习在离轴定量相位成像中的过平滑问题，通过两阶段方法提升相位重建的精度和细节保留能力。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在离轴定量相位成像（QPI）中常因频谱偏差导致过平滑问题，低频内容被过度强调而高频细节丢失。本文旨在解决这一问题。

研究方法: DiffPR采用两阶段频率解耦框架：1）使用不对称U-Net（取消高频跳跃连接）预测低分辨率相位图；2）通过无条件扩散模型迭代恢复高频细节。

研究结果: 在四个QPI数据集上的实验表明，DiffPR显著优于传统U-Net，PSNR提升1.1 dB，MAE降低11%，且细节（如膜脊和斑点模式）更清晰。

研究结论: 取消高频跳跃连接并将细节合成任务委托给扩散模型，是解决传统相位重建网络频谱偏差问题的有效方法。

中文摘要: 在离轴定量相位成像（QPI）中应用深度学习时，过平滑问题一直存在。端到端U-Net倾向于低频内容，而忽略了细微的诊断细节。我们将其归因于频谱偏差，并发现这种偏差因高层跳跃连接直接将高频特征输入解码器而加剧。取消这些最深的跳跃连接，仅在低分辨率下监督网络，显著提高了泛化能力和保真度。基于这一发现，我们提出了DiffPR，一个两阶段频率解耦框架。第一阶段：一个不对称U-Net（取消高频跳跃连接）从干涉图中预测四分之一尺度的相位图，捕获可靠的低频结构，同时避免频谱偏差。第二阶段：将上采样后的预测结果轻微加入高斯噪声，通过无条件扩散模型迭代恢复缺失的高频残差。在四个QPI数据集（B细胞、白细胞、HeLa细胞、3T3细胞）上的实验表明，DiffPR优于强基线U-Net，PSNR提升高达1.1 dB，MAE降低11%，同时显著提高了膜脊和斑点模式的清晰度。结果表明，取消高层跳跃连接并将细节合成任务委托给扩散先验，是解决限制传统相位重建网络的频谱偏差的有效方法。

</details>


### [280] [Joint Denoising of Cryo-EM Projection Images using Polar Transformers](https://arxiv.org/abs/2506.11283)
**中文标题：基于极坐标变换器的冷冻电镜投影图像联合去噪**

*Joakim Andén,Justus Sagemüller*

主要分类: eess.IV

摘要简述: 本文提出了一种基于Transformer的神经网络架构，用于同时聚类、对齐和去噪冷冻电镜投影图像，显著降低了高噪声环境下的误差。


<details>
  <summary>详细信息</summary>
研究动机: 冷冻电镜（cryo-EM）投影图像噪声极高，传统深度神经网络（DNNs）去噪效果有限。然而，这些图像包含大量同一分子不同视角的投影，信息冗余可用于改进去噪方法。

研究方法: 提出了一种基于Transformer的神经网络架构，扩展了传统的类平均方法，能够同时完成图像的聚类、对齐和去噪。

研究结果: 在合成数据上的实验表明，该方法显著降低了相对均方误差（MSE），比单图像DNNs在信噪比（SNR）为0.03时减少了45%。

研究结论: 该方法在高噪声环境下表现出色，为冷冻电镜图像的去噪提供了新的解决方案。

中文摘要: 深度神经网络（DNNs）在去噪方面表现出色，但在高噪声环境下（如冷冻电镜投影图像）效果有限。然而，这些数据集包含大量同一分子不同视角的投影，信息冗余可用于传统类平均方法（聚类、对齐和平均）以降低噪声。本文提出了一种基于Transformer的神经网络架构，扩展了类平均方法，能够同时聚类、对齐和去噪冷冻电镜图像。在合成数据上的实验表明，该方法显著降低了相对均方误差（MSE），比单图像DNNs在信噪比（SNR）为0.03时减少了45%。

</details>


### [281] [FAD-Net: Frequency-Domain Attention-Guided Diffusion Network for Coronary Artery Segmentation using Invasive Coronary Angiography](https://arxiv.org/abs/2506.11454)
**中文标题：FAD-Net：基于频域注意力引导扩散网络的侵入性冠状动脉造影血管分割**

*Nan Mu,Ruiqi Song,Xiaoning Li,Zhihui Xu,Jingfeng Jiang,Chen Zhao*

主要分类: eess.IV

摘要简述: 本文提出了一种基于频域分析的深度学习模型FAD-Net，用于提升冠状动脉血管分割和狭窄检测的准确性。通过频域注意力机制和扩散策略，模型在分割和检测任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 冠状动脉疾病是全球主要致死原因之一，精确分割冠状动脉血管对临床决策至关重要。现有方法在分割精度和狭窄检测上仍有不足，因此需要一种更高效的方法。

研究方法: FAD-Net结合频域注意力机制和多级扩散策略，利用多级自注意力机制（MLSA）分析高低频信息，并通过低频扩散模块（LFDM）分解和融合图像，以提升分割精度。

研究结果: 实验显示，FAD-Net在冠状动脉分割中的平均Dice系数为0.8717，优于现有方法；狭窄检测的真阳性率和阳性预测值分别为0.6140和0.6398，具有显著临床价值。

研究结论: FAD-Net在冠状动脉分割和狭窄检测中表现优异，有望为临床诊断和治疗规划提供有力支持。

中文摘要: 背景：冠状动脉疾病（CAD）是全球主要致死原因之一。精确分割侵入性冠状动脉造影（ICA）中的冠状动脉血管对临床决策至关重要。目标：本研究提出一种基于频域分析的深度学习模型，以提升ICA中冠状动脉分割和狭窄检测的准确性，为CAD的诊断和治疗提供支持。方法：我们提出频域注意力引导扩散网络（FAD-Net），结合频域注意力机制和级联扩散策略，充分利用频域信息提升分割精度。具体而言，FAD-Net在频域中采用多级自注意力机制（MLSA），计算高低频成分的相似性；并通过低频扩散模块（LFDM）分解图像，再通过逆融合细化血管分支和边缘。结果与结论：实验表明，FAD-Net在冠状动脉分割中的平均Dice系数为0.8717，优于现有方法；狭窄检测的真阳性率和阳性预测值分别为0.6140和0.6398，具有显著临床价值。这些结果表明FAD-Net在CAD的精确诊断和治疗规划中具有重要潜力。

</details>


### [282] [Taming Stable Diffusion for Computed Tomography Blind Super-Resolution](https://arxiv.org/abs/2506.11496)
**中文标题：驯服Stable Diffusion用于CT盲超分辨率**

*Chunlei Li,Yilei Shi,Haoxi Hu,Jingliang Hu,Xiao Xiang Zhu,Lichao Mou*

主要分类: eess.IV

摘要简述: 本文提出了一种基于Stable Diffusion的CT盲超分辨率方法，通过合成低质量图像和生成文本描述，结合预训练模型实现高质量CT成像，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 高分辨率CT成像对医疗诊断至关重要，但高辐射剂量存在安全隐患。现有深度学习方法在复杂退化和有限医学数据下表现不佳，而预训练的扩散模型（如Stable Diffusion）在细节合成方面表现出色，因此本文探索其应用于CT超分辨率的潜力。

研究方法: 提出了一种新框架，通过实用退化模型合成低质量CT图像，并利用预训练的视觉语言模型生成文本描述。随后，结合低分辨率输入和文本描述，使用Stable Diffusion进行超分辨率重建。

研究结果: 实验表明，该方法在CT盲超分辨率任务中优于现有方法，能够在降低辐射剂量的同时实现高质量成像。

研究结论: 本文方法为CT成像提供了一种高效解决方案，展示了预训练扩散模型在医学图像处理中的潜力。

中文摘要: 高分辨率计算机断层扫描（CT）成像对医疗诊断至关重要，但高辐射剂量会带来安全隐患，形成图像质量与患者安全之间的关键权衡。尽管深度学习方法在CT超分辨率中表现出潜力，但其在复杂退化和有限医学训练数据下仍面临挑战。与此同时，大规模预训练的扩散模型（如Stable Diffusion）在多种视觉任务中展现了卓越的细节合成能力。受此启发，我们提出了一种新框架，将Stable Diffusion应用于CT盲超分辨率。我们采用实用退化模型合成真实的低质量图像，并利用预训练的视觉语言模型生成相应描述。随后，结合低分辨率输入和生成的文本描述，使用Stable Diffusion进行超分辨率重建。大量实验表明，我们的方法优于现有方法，展示了其在降低辐射剂量下实现高质量CT成像的潜力。代码将公开提供。

</details>


### [283] [FCA2: Frame Compression-Aware Autoencoder for Modular and Fast Compressed Video Super-Resolution](https://arxiv.org/abs/2506.11545)
**中文标题：FCA2：面向模块化与快速压缩视频超分辨率的帧压缩感知自编码器**

*Zhaoyang Wang,Jie Li,Wen Lu,Lihuo He,Maoguo Gong,Xinbo Gao*

主要分类: eess.IV

摘要简述: 本文提出了一种高效的压缩视频超分辨率（CVSR）方法FCA2，通过压缩驱动的降维策略降低计算复杂度并加速推理，同时提升帧间信息提取能力。该方法模块化设计，易于与现有框架集成，实验表明其性能优于或媲美当前最优模型，且显著减少推理时间。


<details>
  <summary>详细信息</summary>
研究动机: 当前最优的压缩视频超分辨率（CVSR）模型存在推理时间长、训练流程复杂及依赖辅助信息等问题。随着视频帧率提升，传统帧间信息利用方法难以满足需求。本文受高光谱图像（HSI）与视频数据的结构相似性启发，旨在解决这些瓶颈问题。

研究方法: 提出了一种压缩驱动的降维策略，通过减少计算复杂度并加速推理，同时增强帧间信息提取。方法采用模块化设计，便于与现有视频超分辨率（VSR）框架集成。

研究结果: 实验结果表明，该方法性能与当前最优模型相当或更优，同时显著减少推理时间。

研究结论: 本文通过解决CVSR中的关键瓶颈问题，为视频超分辨率技术提供了一种高效实用的解决方案。

中文摘要: 当前最优的压缩视频超分辨率（CVSR）模型面临推理时间长、训练流程复杂及依赖辅助信息等挑战。随着视频帧率提升，帧间差异减小，传统帧间信息利用方法难以满足需求。受高光谱图像（HSI）与视频数据的结构相似性启发，我们提出了一种高效且可扩展的解决方案，引入压缩驱动的降维策略，降低计算复杂度、加速推理并增强帧间信息提取。所提出的模块化架构便于与现有VSR框架集成，确保强适应性和跨应用可迁移性。实验结果表明，该方法性能与当前最优模型相当或更优，同时显著减少推理时间。通过解决CVSR中的关键瓶颈问题，我们的工作为推进VSR技术提供了实用高效的途径。代码将公开于https://github.com/handsomewzy/FCA2。

</details>


### [284] [Brain Network Analysis Based on Fine-tuned Self-supervised Model for Brain Disease Diagnosis](https://arxiv.org/abs/2506.11671)
**中文标题：基于微调自监督模型的脑网络分析用于脑疾病诊断**

*Yifei Tang,Hongjie Jiang,Changhong Jing,Hieu Pham,Shuqiang Wang*

主要分类: eess.IV

摘要简述: 本文提出了一种基于微调自监督模型的脑网络分析方法，用于脑疾病诊断。通过多维度扩展脑区特征和自监督学习，模型在诊断任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的脑网络基础模型研究有限且局限于单一维度，限制了其在神经科学中的广泛应用。本文旨在通过多维度扩展和自监督学习提升脑网络模型的泛化能力，以更好地支持脑疾病诊断。

研究方法: 模型包含两个关键模块：(1)适配器模块，用于多维度扩展脑区特征；(2)基于自监督学习的微调基础脑网络模型，通过Transformer块提取脑区特征并计算区域间关联。此外，还生成了用于脑疾病诊断的紧凑潜在表示。

研究结果: 实验表明，所提模型在脑疾病诊断任务中表现优异，为脑网络分析研究提供了新思路。

研究结论: 本文提出的方法通过多维度扩展和自监督学习显著提升了脑网络模型的诊断性能，为脑疾病研究提供了有效工具。

中文摘要: 功能脑网络分析已成为脑疾病研究的重要工具，深度学习方法的引入进一步提升了其表征脑区复杂连接的能力。然而，现有的脑网络基础模型研究有限且局限于单一维度，限制了其在神经科学中的广泛应用。本研究提出了一种用于脑疾病诊断的微调脑网络模型，其在原始模型基础上通过多维度扩展脑区表征，从而提升了泛化能力。模型包含两个关键模块：(1)适配器模块，用于多维度扩展脑区特征；(2)基于自监督学习的微调基础脑网络模型，该模型通过Transformer块有效提取脑区特征并计算区域间关联。此外，我们还生成了用于脑疾病诊断的紧凑潜在表示。实验结果表明，所提模型在脑疾病诊断任务中表现优异，为脑网络分析研究提供了新思路。

</details>


### [285] [Exploring the Effectiveness of Deep Features from Domain-Specific Foundation Models in Retinal Image Synthesis](https://arxiv.org/abs/2506.11753)
**中文标题：Error**

*Zuzanna Skorniewska,Bartlomiej W. Papiez*

主要分类: eess.IV

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [286] [Framework of a multiscale data-driven digital twin of the muscle-skeletal system](https://arxiv.org/abs/2506.11821)
**中文标题：肌肉骨骼系统的多尺度数据驱动数字孪生框架**

*Martina Paccini,Simone Cammarasana,Giuseppe Patanè*

主要分类: eess.IV

摘要简述: 本文提出了一种多尺度数据驱动的肌肉骨骼系统数字孪生框架（MS-DT），整合多源生物力学数据与计算建模，为个性化诊断和治疗提供高精度工具。


<details>
  <summary>详细信息</summary>
研究动机: 肌肉骨骼疾病（MSDs）是全球致残的主要原因，需要先进的个性化诊断和治疗工具。数字孪生（DT）范式因其能整合异构数据源，成为解决这一问题的有效方法。

研究方法: 通过结合运动捕捉、超声成像、肌电图和医学影像，MS-DT框架创建了患者特定的肌肉骨骼系统模型，并提供了交互式可视化平台，用于分析脊柱运动学、姿势和肌肉功能。

研究结果: 结果显示，MS-DT能精确提取运动学和动态组织特征，为脊柱生物力学监测和康复提供了全面工具。

研究结论: 该框架通过高保真建模和实时可视化，显著提升了患者特异性诊断和干预规划的准确性。

中文摘要: 肌肉骨骼疾病（MSDs）是全球致残的主要原因，需要先进的个性化诊断和治疗工具。有效的MSDs管理涉及异构数据源的交互，使得数字孪生（DT）范式成为一种有价值的选择。本文介绍了肌肉骨骼数字孪生（MS-DT），这是一种新颖的框架，通过整合多尺度生物力学数据与计算建模，创建了患者特定的肌肉骨骼系统详细表示。通过结合运动捕捉、超声成像、肌电图和医学影像，MS-DT能够分析脊柱运动学、姿势和肌肉功能。交互式可视化平台为临床医生和研究人员提供了一个直观的界面，用于探索生物力学参数和跟踪患者特异性变化。结果表明，MS-DT在提取精确的运动学和动态组织特征方面具有显著效果，为脊柱生物力学监测和康复提供了全面工具。该框架通过高保真建模和实时可视化，改善了患者特异性诊断和干预规划。

</details>


### [287] [Structural Similarity-Inspired Unfolding for Lightweight Image Super-Resolution](https://arxiv.org/abs/2506.11823)
**中文标题：基于结构相似性启发的轻量级图像超分辨率展开方法**

*Zhangkai Ni,Yang Zhang,Wenhan Yang,Hanli Wang,Shiqi Wang,Sam Kwong*

主要分类: eess.IV

摘要简述: 本文提出了一种基于结构相似性启发的展开方法（SSIU），用于轻量级图像超分辨率，结合数据驱动和模型驱动的优势，通过混合尺度门控模块和高效稀疏注意力模块实现高效性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前数据驱动的图像超分辨率方法主要通过增加模型深度或使用注意力机制来扩展感受野，但导致模型复杂度高。模型驱动的展开方法在保持模型紧凑性的同时提升性能，因此本文结合两者优势，提出SSIU方法。

研究方法: SSIU方法通过展开受结构相似性约束的超分辨率优化函数设计，采用混合尺度门控模块（MSGM）实现特征全面约束，包括结构相似性约束，以及高效稀疏注意力模块（ESAM）实现稀疏激活。此外，设计了基于专家混合的特征选择器（MoE-FS）充分利用多级特征信息。

研究结果: 实验表明，SSIU模型在性能和效率上均优于当前最先进模型，参数更少且内存消耗更低。

研究结论: SSIU方法成功结合数据驱动和模型驱动的优势，通过展开设计和高效模块实现了轻量级高性能图像超分辨率。

中文摘要: 数据驱动的图像超分辨率（SR）主要致力于扩展模型的感受野以更好地捕捉上下文信息，但这些方法通常通过堆叠更深网络或利用基于Transformer的注意力机制实现，从而增加了模型复杂度。相比之下，基于展开范式的模型驱动方法通过精巧模块设计在提升性能的同时有效保持模型紧凑性。基于这些观察，我们提出了一种结构相似性启发的展开（SSIU）方法用于高效图像SR。该方法通过展开受结构相似性约束的SR优化函数设计，旨在结合数据驱动和模型驱动的优势。我们的模型遵循展开范式逐步操作，每次迭代包含多个混合尺度门控模块（MSGM）和一个高效稀疏注意力模块（ESAM）。前者实现对特征的全面约束（包括结构相似性约束），后者旨在实现稀疏激活。此外，我们设计了一种基于专家混合的特征选择器（MoE-FS），通过结合不同步骤的特征充分利用多级特征信息。大量实验验证了我们展开启发的网络的有效性和高效性。我们的模型在性能和效率上均优于当前最先进模型，参数更少且内存消耗更低。代码将在以下地址公开：https://github.com/eezkni/SSIU

</details>


### [288] [MindGrab for BrainChop: Fast and Accurate Skull Stripping for Command Line and Browser](https://arxiv.org/abs/2506.11860)
**中文标题：MindGrab for BrainChop：命令行与浏览器的快速准确颅骨剥离工具**

*Armina Fani,Mike Doan,Isabelle Le,Alex Fedorov,Malte Hoffmann,Chris Rorden,Sergey Plis*

主要分类: eess.IV

摘要简述: MindGrab是一种高效且内存友好的深度学习模型，用于多模态头部图像的颅骨剥离，性能优于传统方法且资源需求极低。


<details>
  <summary>详细信息</summary>
研究动机: 现有颅骨剥离方法在性能和资源效率上存在不足，尤其是在多模态图像处理时表现不佳。MindGrab旨在开发一种高效、低资源消耗且适用于多模态的解决方案。

研究方法: MindGrab采用基于频谱解释的扩张卷积架构，仅使用模态无关的合成数据进行训练，并通过参数优化显著减少模型大小。

研究结果: 在606例多模态脑部扫描测试中，MindGrab平均Dice得分为95.9，显著优于ROBEX和BET，与SynthStrip性能相当或更优，同时参数减少95%，推理速度提升2倍以上，内存占用降低50%。

研究结论: MindGrab在保持高性能的同时大幅降低了资源需求，适用于更广泛的硬件环境，为颅骨剥离提供了高效且易用的解决方案。

中文摘要: 我们开发了MindGrab，一种参数和内存高效的深度全卷积模型，用于处理任何模态的头部图像的体积颅骨剥离。其架构基于对扩张卷积的频谱解释，并仅使用模态无关的合成数据进行训练。MindGrab在包含606例多模态成人脑部扫描（T1、T2、DWI、MRA、PDw MRI、EPI、CT、PET）的回顾性数据集上进行了评估，性能通过Dice分数和Wilcoxon符号秩显著性测试与SynthStrip、ROBEX和BET进行了对比。MindGrab的平均Dice分数为95.9（标准差1.6），显著优于传统方法（ROBEX：89.1，标准差7.7，P < 0.05；BET：85.2，标准差14.4，P < 0.05）。与SynthStrip（96.5，标准差1.1，P=0.0352）相比，MindGrab在近半数的测试场景中表现相当或更优，其余场景差异较小（Dice分数差异<3%）。MindGrab的参数数量比SynthStrip少95%（146,237 vs. 2,566,561），这种高效性使其推理速度至少提升2倍，GPU内存占用降低50%，并在更广泛的硬件环境中表现出色（如10-30倍的速度提升和高达30倍的内存减少）。MindGrab以极低的资源需求实现了最先进的性能，支持brainchop-cli（https://pypi.org/project/brainchop/）和brainchop.org。

</details>


### [289] [crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023](https://arxiv.org/abs/2506.12006)
**中文标题：crossMoDA挑战赛：2021至2023年前庭神经鞘瘤和耳蜗跨模态域适应分割技术的演变**

*Navodini Wijethilake,Reuben Dorent,Marina Ivory,Aaron Kujawa,Stefan Cornelissen,Patrick Langenhuizen,Mohamed Okasha,Anna Oviedova,Hexin Dong,Bogyeong Kang,Guillaume Sallé,Luyi Han,Ziyuan Zhao,Han Liu,Tao Yang,Shahad Hardan,Hussain Alasmawi,Santosh Sanjeev,Yuzhou Zhuang,Satoshi Kondo,Maria Baldeon Calisto,Shaikh Muhammad Uzair Noman,Cancan Chen,Ipek Oguz,Rongguo Zhang,Mina Rezaei,Susana K. Lai-Yuen,Satoshi Kasai,Chih-Cheng Hung,Mohammad Yaqub,Lisheng Wang,Benoit M. Dawant,Cuntai Guan,Ritse Mann,Vincent Jaouen,Ji-Wung Han,Li Zhang,Jonathan Shapey,Tom Vercauteren*

主要分类: eess.IV

摘要简述: crossMoDA挑战赛系列从2021年到2023年，专注于跨模态无监督分割任务，旨在通过T1增强MRI学习并迁移到T2 MRI，以自动完成前庭神经鞘瘤和耳蜗的分割。挑战赛逐年升级，从单机构数据到多机构数据，再到异构数据，结果显示数据多样性提升减少了异常值，但耳蜗分割性能因肿瘤子标注复杂性而下降。


<details>
  <summary>详细信息</summary>
研究动机: 该挑战赛的动机是通过跨模态域适应技术，解决医学影像中前庭神经鞘瘤（VS）和耳蜗在T2 MRI上的自动分割问题，以降低临床管理成本。挑战赛逐年调整目标，以增强其临床相关性。

研究方法: 挑战赛从2021年的单机构数据和基础分割任务，逐步发展为2022年引入多机构数据和Koos分级，2023年则进一步纳入异构常规数据及肿瘤内外部分的子分割任务。通过对比分析2022和2023年的数据，评估跨模态分割技术的进展。

研究结果: 结果显示，随着数据集的扩展和扫描协议的多样性增加，异常值数量减少。2023年的优胜方法在2021和2022年测试数据上减少了异常值，表明数据异质性提升可改善分割性能。然而，2023年耳蜗的Dice分数下降，可能与肿瘤子标注的复杂性有关。

研究结论: 尽管VS分割仍需改进以达到临床要求，但性能趋于稳定表明未来可能需要更具挑战性的跨模态任务作为基准。数据多样性的增加有助于提升分割性能，但复杂标注可能影响整体效果。

中文摘要: crossMoDA挑战赛系列始于2021年，与国际医学影像计算与计算机辅助干预会议（MICCAI）合作，专注于无监督跨模态分割任务，从对比增强T1（ceT1）MRI学习并迁移到T2 MRI。该任务是一个极端的域偏移示例，旨在作为有意义的基准。从临床应用角度，其目标是自动化T2扫描中的前庭神经鞘瘤（VS）和耳蜗分割，以实现更具成本效益的VS管理。挑战赛目标逐年演变以增强临床相关性：2021年使用单机构数据和基础分割，2022年引入多机构数据和Koos分级，2023年则纳入异构常规数据及肿瘤内外部分的子分割。本文报告了2022和2023年的结果，并对挑战赛的进展进行了回顾性分析。结果显示，随着数据集扩展，异常值数量减少，尽管扫描协议多样性增加。2023年的优胜方法在2021和2022年测试数据上减少了异常值，表明数据异质性提升可改善分割性能。然而，2023年耳蜗的Dice分数下降，可能与肿瘤子标注的复杂性有关。尽管VS分割仍需改进，但性能趋于稳定表明未来可能需要更具挑战性的跨模态任务作为基准。

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [290] [Decoding Cortical Microcircuits: A Generative Model for Latent Space Exploration and Controlled Synthesis](https://arxiv.org/abs/2506.11062)
**中文标题：解码皮层微电路：一种用于潜在空间探索和可控合成的生成模型**

*Xingyu Liu,Yubin Li,Guozhang Chen*

主要分类: q-bio.NC

摘要简述: 本文提出了一种生成模型，用于从小鼠皮层微电路的详细连接图中学习潜在表示，成功压缩了电路的结构信息，并通过潜在空间可控生成具有特定结构特征的新微电路。


<details>
  <summary>详细信息</summary>
研究动机: 大脑的复杂结构远超基因信息存储能力，因此需要探索其低维蓝图。本文旨在揭示这一蓝图，为理解大脑结构和功能关系提供新方法。

研究方法: 引入生成模型，从小鼠皮层微电路的详细连接图中学习潜在表示，并通过潜在空间探索可控生成新微电路。

研究结果: 模型成功压缩了微电路的结构信息，潜在空间中的特定方向与可理解的网络属性直接相关，并能可控生成具有目标结构特征的合成微电路。

研究结论: 本研究为探索神经电路的设计原则和结构功能关系提供了新途径，可能对更先进的人工神经网络开发有所启发。

中文摘要: 理解大脑和构建人工智能的核心观点是结构决定功能。然而，大脑的复杂结构如何从有限的遗传指令中产生仍是一个关键问题。神经连接的超高维细节远超基因的信息存储能力，表明必须有一种紧凑的低维蓝图指导大脑发育。我们的动机是揭示这一蓝图。我们引入了一种生成模型，从小鼠皮层微电路的详细连接图中学习这一潜在表示。我们的模型成功地将这些电路的基本结构信息压缩到潜在空间中。我们发现，该空间中特定且可解释的方向与可理解的网络属性直接相关。在此基础上，我们展示了一种新方法，通过导航这一潜在空间可控地生成具有目标结构特征的新合成微电路。这项工作为研究神经电路的设计原则和探索结构如何产生功能提供了新途径，可能为更先进的人工神经网络的开发提供启示。

</details>


### [291] [Sparse Autoencoders Bridge The Deep Learning Model and The Brain](https://arxiv.org/abs/2506.11123)
**中文标题：稀疏自编码器桥接深度学习模型与大脑**

*Ziming Mao,Jia Xu,Zeqi Zheng,Haofang Zheng,Dabing Sheng,Yaochu Jin,Guoyuan Yang*

主要分类: q-bio.NC

摘要简述: 本文提出SAE-BrainMap框架，通过稀疏自编码器（SAE）将深度学习视觉模型与大脑fMRI信号直接对齐，揭示了模型与人类视觉皮层的层级映射关系。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在建立深度学习模型与人类视觉皮层之间的直接联系，以增强模型的可解释性，并探索其在神经科学中的应用潜力。

研究方法: 首先训练层级的稀疏自编码器（SAE）提取模型激活特征，计算其与fMRI信号的余弦相似度；然后构建体素字典，将最相似的SAE特征分配给每个体素；最后通过投影可视化模型与视觉通路的层级映射。

研究结果: SAE单元与fMRI信号的最大相似度达0.76，保留了预定义感兴趣区域（ROI）的功能结构，并揭示了ViT-B/16$_{CLIP}$模型在早期层利用低级信息生成高级语义信息的动态过程。

研究结论: SAE-BrainMap为深度神经网络与人类视觉皮层之间建立了一种无需下游任务的直接桥梁，为模型可解释性提供了新视角。

中文摘要: 我们提出了SAE-BrainMap，一种新颖的框架，通过稀疏自编码器（SAEs）直接将深度学习视觉模型的表征与体素级fMRI响应对齐。首先，我们在模型激活上训练层级SAEs，并计算SAE单元激活与由相同自然图像刺激引发的皮层fMRI信号之间的余弦相似度，揭示了强烈的激活对应关系（最大相似度达0.76）。基于这种对齐，我们通过为每个体素分配最相似的SAE特征构建了体素字典，表明SAE单元保留了预定义感兴趣区域（ROIs）的功能结构，并表现出ROI一致的选择性。最后，我们建立了模型层与人类腹侧视觉通路之间的细粒度层级映射，并通过将体素字典激活投影到个体皮层表面，可视化了深度学习模型中视觉信息的动态转换。研究发现，ViT-B/16$_{CLIP}$倾向于在早期层利用低级信息生成高级语义信息，并在后期重建低维信息。我们的结果为深度神经网络与人类视觉皮层之间建立了一种直接、无需下游任务的桥梁，为模型可解释性提供了新见解。

</details>


### [292] [Voxel-Level Brain States Prediction Using Swin Transformer](https://arxiv.org/abs/2506.11455)
**中文标题：基于Swin Transformer的体素级脑状态预测**

*Yifei Sun,Daniel Chahine,Qinghao Wen,Tianming Liu,Xiang Li,Yixuan Yuan,Fernando Calamante,Jinglei Lv*

主要分类: q-bio.NC

摘要简述: 本文提出了一种基于4D Swin Transformer的新架构，用于预测静息态fMRI数据的未来脑状态，模型在HCP数据集上表现出高精度，预测结果与真实BOLD信号高度相似。


<details>
  <summary>详细信息</summary>
研究动机: 理解大脑动态对神经科学和心理健康至关重要。fMRI通过BOLD信号测量神经活动，本研究旨在利用fMRI预测未来静息态脑状态，以减少扫描时间并为脑机接口开发提供潜力。

研究方法: 提出了一种新架构，使用4D Swin Transformer作为编码器学习时空信息，并结合卷积解码器，以保持输入fMRI数据的时空分辨率。模型在HCP的100名受试者数据上训练和测试。

研究结果: 模型能够基于前23.04秒的fMRI时间序列高精度预测7.2秒后的静息态脑活动，预测结果与真实BOLD信号在对比度和动态上高度相似。

研究结论: 研究表明，Swin Transformer模型能够高分辨率学习人脑的时空组织，为减少fMRI扫描时间和未来脑机接口开发提供了可能性。

中文摘要: 理解大脑动态对神经科学和心理健康至关重要。功能磁共振成像（fMRI）通过血氧水平依赖（BOLD）信号测量神经活动，这些信号代表了脑状态。本研究旨在利用fMRI预测未来人类静息态脑状态。由于fMRI数据具有3D体素级空间组织和时间依赖性，我们提出了一种新架构，采用4D Swin Transformer作为编码器高效学习时空信息，并结合卷积解码器实现与输入fMRI数据相同时空分辨率的脑状态预测。我们使用人类连接组计划（HCP）中100名无关受试者的数据进行模型训练和测试。新模型在基于前23.04秒fMRI时间序列预测7.2秒静息态脑活动时表现出高精度，预测结果与BOLD信号的对比度和动态高度相似。这项工作表明，Swin Transformer模型能够高分辨率学习人脑的时空组织，为减少fMRI扫描时间和未来脑机接口开发提供了潜力。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [293] [AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction](https://arxiv.org/abs/2506.11475)
**中文标题：基于AutoGen驱动的多代理框架用于迭代犯罪数据分析与预测**

*Syeda Kisaa Fatima,Tehreem Zubair,Noman Ahmed,Asifullah Khan*

主要分类: cs.MA

摘要简述: 本文提出LUCID-MA框架，通过多AI代理协作分析犯罪数据，包含分析助手、反馈组件和预测模块，支持离线运行和自我改进，展示了AutoGen代理在社会科学领域的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 犯罪数据分析需要高效、隐私保护且可扩展的方法，传统方法依赖人工且难以迭代改进。本文旨在通过多AI代理协作框架，实现自主、可扩展的犯罪数据分析与预测。

研究方法: LUCID-MA框架包含三个核心组件：分析助手识别时空犯罪模式，反馈组件优化分析结果，预测模块预测未来趋势。采用LLaMA-2-13B-Chat-GPTQ模型，支持离线运行，并通过100轮通信实现代理自我改进。

研究结果: 实验表明，LUCID-MA能够有效分析犯罪数据并预测趋势，评分函数和可视化图表展示了代理的学习进展，验证了框架的可行性和效果。

研究结论: LUCID-MA展示了AutoGen代理在社会科学领域的潜力，通过离线运行保护数据隐私，同时支持自主迭代分析，为犯罪研究提供了新工具。

中文摘要: 本文介绍了LUCID-MA（通过多代理对话学习与理解犯罪），一种创新的AI驱动框架，多个AI代理协作分析犯罪数据。系统包含三个核心组件：分析助手突出时空犯罪模式，反馈组件审查并优化分析结果，预测模块预测未来犯罪趋势。通过精心设计的提示和LLaMA-2-13B-Chat-GPTQ模型，系统完全离线运行，代理通过100轮通信实现自我改进，减少人工干预。评分函数评估代理表现，并提供可视化图表跟踪学习进展。这项工作展示了AutoGen式代理在社会科学领域实现自主、可扩展和迭代分析的潜力，同时通过离线执行保护数据隐私。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [294] [Assessing the Impact of Anisotropy in Neural Representations of Speech: A Case Study on Keyword Spotting](https://arxiv.org/abs/2506.11096)
**中文标题：评估语音神经表征中各向异性的影响：以关键词识别为例**

*Guillaume Wisniewski,Séverine Guillaume,Clara Rosina Fernández*

主要分类: cs.SD

摘要简述: 研究评估了预训练语音表征（如wav2vec2和HuBERT）的各向异性对关键词识别任务的影响，发现尽管存在各向异性，这些表征仍能有效识别单词，展现了其鲁棒性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 预训练语音表征（如wav2vec2和HuBERT）表现出明显的各向异性，但其对下游任务的具体影响尚不明确。本研究旨在探索各向异性在关键词识别任务中的作用，尤其是计算纪录片语言学中的应用。

研究方法: 研究采用动态时间规整（Dynamic Time Warping）方法，评估wav2vec2表征在关键词识别任务中的表现，分析其各向异性对任务的影响。

研究结果: 结果表明，尽管存在各向异性，wav2vec2的相似性度量仍能有效识别单词，无需转录。这些表征能够捕捉语音结构并跨说话者泛化，展现了其鲁棒性。

研究结论: 研究强调了预训练在获取丰富且不变的语音表征中的重要性，各向异性并未显著影响关键词识别的效果。

中文摘要: 预训练语音表征（如wav2vec2和HuBERT）表现出强烈的各向异性，导致随机嵌入之间的高相似性。尽管这一现象广泛存在，但其对下游任务的影响尚不明确。本研究评估了各向异性在计算纪录片语言学中关键词识别任务中的作用。通过动态时间规整，我们发现尽管存在各向异性，wav2vec2的相似性度量仍能有效识别单词，无需转录。结果表明这些表征捕捉了语音结构并跨说话者泛化，展现了其鲁棒性。研究强调了预训练在学习丰富且不变的语音表征中的重要性。

</details>


### [295] [GLAP: General contrastive audio-text pretraining across domains and languages](https://arxiv.org/abs/2506.11350)
**中文标题：GLAP：跨领域和语言的通用对比音频-文本预训练**

*Heinrich Dinkel,Zhiyong Yan,Tianzi Wang,Yongqing Wang,Xingwei Sun,Yadong Niu,Jizhong Liu,Gang Li,Junbo Zhang,Jian Luan*

主要分类: cs.SD

摘要简述: 本文提出了GLAP（通用对比音频-文本预训练）方法，扩展了CLAP的多语言和多领域能力，在音频-文本检索、语音检索和分类任务中表现优异，并在多语言关键词识别和音乐理解任务中展现了强大的能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的CLAP方法仅支持英语音频-文本检索，忽略了多语言语音内容。为了填补这一空白，作者提出了GLAP，旨在扩展多语言和多领域能力，提升音频与文本之间的跨模态理解。

研究方法: GLAP通过对比学习框架，结合多语言和多领域数据，训练音频和文本的联合表示。该方法在标准音频-文本检索任务（如Clotho和AudioCaps）上进行验证，并在语音检索、分类任务以及多语言关键词识别任务中进行了广泛测试。

研究结果: GLAP在标准音频-文本检索任务中表现优异，显著优于现有方法。同时，在语音检索、分类任务以及多语言关键词识别任务中取得了领先结果。此外，GLAP在四种语言的音乐理解任务中也展现了强大的性能。

研究结论: GLAP通过多语言和多领域的扩展，显著提升了音频与文本之间的跨模态理解能力，为多语言音频-文本检索和分类任务提供了新的解决方案。

中文摘要: 对比语言音频预训练（CLAP）是一种广泛用于弥合音频与文本领域差距的方法。当前的CLAP方法仅支持英语音频和音乐检索，忽略了多语言语音内容。为此，我们提出了通用语言音频预训练（GLAP），通过扩展多语言和多领域能力，增强了CLAP的功能。GLAP在标准音频-文本检索基准（如Clotho和AudioCaps）上表现优异，同时在语音检索和分类任务中显著超越现有方法。此外，GLAP在广泛使用的声音事件零样本基准测试中取得了强劲结果，并在语音内容基准测试中优于先前方法。进一步的50种语言关键词识别评估突显了GLAP的先进多语言能力。最后，GLAP在四种语言的音乐理解任务中表现出色。模型检查点和源代码见：https://github.com/xiaomi-research/dasheng-glap。

</details>


### [296] [(SimPhon Speech Test): A Data-Driven Method for In Silico Design and Validation of a Phonetically Balanced Speech Test](https://arxiv.org/abs/2506.11620)
**中文标题：（SimPhon语音测试）：一种数据驱动的硅基设计和验证语音平衡语音测试的方法**

*Stefan Bleeck*

主要分类: cs.SD

摘要简述: 本文提出了一种名为SimPhon Speech Test的计算方法，用于设计和验证语音平衡的最小对语音测试，以更准确地诊断听力损失对语音理解的功能影响。


<details>
  <summary>详细信息</summary>
研究动机: 传统听力测试无法全面评估听力损失对语音理解的复杂影响，尤其是在老年性耳聋中常见的超阈值缺陷。因此，需要开发更具诊断特异性的语音感知测试方法。

研究方法: 研究采用多阶段计算流程，利用自动语音识别（ASR）系统模拟听力损失对语音感知的影响，通过声学降级处理识别常见音素混淆模式，并基于语言学语料库筛选候选词对。随后通过模拟诊断测试、专家人工筛选和敏感性分析，最终优化出25对测试词（SimPhon Speech Test-25）。

研究结果: SimPhon Speech Test-25的诊断性能与标准语音可懂度指数（SII）预测无显著相关性，表明该方法能捕捉超出简单可听性的感知缺陷。

研究结论: SimPhon Speech Test-25为听力测试开发提供了高效的计算优化方案，已准备好进行初步人体试验。

中文摘要: 传统听力测试通常无法全面描述听力损失对语音理解的功能影响，尤其是在老年性耳聋中常见的超阈值缺陷。这促使开发更具诊断特异性的语音感知测试。我们介绍了模拟音素语音测试（SimPhon Speech Test）方法，这是一种新颖的多阶段计算流程，用于硅基设计和验证语音平衡的最小对语音测试。该方法利用现代自动语音识别（ASR）系统作为人类听者的代理，模拟感音神经性听力损失的感知效果。通过受控声学降级处理语音刺激，我们首先识别最常见的音素混淆模式。这些模式随后指导从综合语言学语料库中筛选大量候选词对。后续阶段包括模拟诊断测试、专家人工筛选和最终的针对性敏感性分析，系统性地将候选词对缩减为最终的25对优化测试集（SimPhon Speech Test-25）。一个关键发现是，SimPhon Speech Test-25的诊断性能与标准语音可懂度指数（SII）的预测无显著相关性，表明SimPhon Speech Test捕捉了超出简单可听性的感知缺陷。这一计算优化的测试集显著提高了听力测试开发的效率，已准备好进行初步人体试验。

</details>


### [297] [A correlation-permutation approach for speech-music encoders model merging](https://arxiv.org/abs/2506.11403)
**中文标题：一种基于相关性和排列的语音-音乐编码器模型合并方法**

*Fabian Ritter-Gutierrez,Yi-Cheng Lin,Jeremy H. M Wong,Hung-yi Lee,Eng Siong Chng,Nancy F. Chen*

主要分类: cs.SD

摘要简述: 提出了一种基于相关性和排列的方法，用于合并语音和音乐编码器模型，显著提升音乐性能，同时保留语音能力。


<details>
  <summary>详细信息</summary>
研究动机: 构建统一的语音和音乐模型通常需要昂贵的预训练成本，而直接合并未对齐的模型在权重空间上存在挑战。本文受Git Re-Basin启发，旨在通过一种高效的方法合并独立训练的编码器。

研究方法: 提出了一种相关性和排列方法，通过逐层计算最大化特征间交叉相关性的排列矩阵，对齐音乐编码器和语音编码器的内部层，从而有效融合模型。

研究结果: 合并后的模型在保留语音能力的同时，显著提升了音乐性能，平均得分比线性插值模型合并方法提高了14.83分。

研究结论: 该方法为从独立训练的编码器中创建统一的音频模型提供了可行方案。

中文摘要: 构建统一的语音和音乐模型通常需要昂贵的预训练成本。相比之下，模型合并可以以最小的计算开销创建统一的音频模型。然而，当模型在权重空间上未对齐时，直接合并具有挑战性。受Git Re-Basin启发，我们提出了一种基于相关性和排列的方法，用于对齐音乐编码器和语音编码器的内部层。我们将先前的工作扩展到合并Transformer层的情况。该方法通过逐层计算最大化特征间交叉相关性的排列矩阵，实现了这些原本不相关模型的有效融合。合并后的模型通过此方法保留了语音能力，同时显著提升了音乐性能，平均得分比线性插值模型合并方法提高了14.83分。这项工作为从独立训练的编码器中创建统一的音频模型提供了可能。

</details>


### [298] [Abstract Sound Fusion with Unconditioned Inversion Model](https://arxiv.org/abs/2506.11811)
**中文标题：基于无条件反转模型的抽象声音融合**

*Jing Liu,EnQi Lian*

主要分类: cs.SD

摘要简述: 本文提出了一种基于无条件反转模型的抽象声音融合方法，通过新颖的SDE和ODE反转模型实现声音合成，无需提示条件即可保持灵活控制。


<details>
  <summary>详细信息</summary>
研究动机: 抽象声音融合旨在合成具有超越简单叠加特征的新声音，但现有方法常受限于噪声预测项的循环依赖问题。本文旨在解决这一问题，实现更灵活的声音合成。

研究方法: 采用基于DPMSolver++采样器的SDE和ODE反转模型，通过配置模型输出为常数消除噪声预测项的循环依赖，实现无条件反转。

研究结果: 提出的反转模型在无需提示条件的情况下，成功合成了具有新颖听觉特征的抽象声音，且保持了合成过程的灵活性。

研究结论: 本文的无条件反转模型为抽象声音融合提供了一种高效且灵活的方法，解决了噪声预测项的循环依赖问题。

中文摘要: 抽象声音是指无法被听众识别为现实世界具体声音事件的声音。声音融合旨在将原始声音与参考声音合成为一种新声音，其听觉特征超越简单的叠加效果。为实现这种融合，我们采用反转技术，保留原始样本的关键特征，同时实现可控合成。我们提出了基于DPMSolver++采样器的新型SDE和ODE反转模型，通过将模型输出配置为常数来反转采样过程，消除了噪声预测项引起的循环依赖问题。我们的反转方法无需提示条件，同时在采样过程中保持灵活的指导性。

</details>


### [299] [Reimagining Dance: Real-time Music Co-creation between Dancers and AI](https://arxiv.org/abs/2506.12008)
**中文标题：重新想象舞蹈：舞者与AI之间的实时音乐共创**

*Olga Vechtomova,Jeff Bos*

主要分类: cs.SD

摘要简述: 本文提出了一种实时音乐共创系统，使舞者通过动作动态塑造音乐环境，实现了舞者与AI的双向创作合作。


<details>
  <summary>详细信息</summary>
研究动机: 传统舞蹈表演中，动作单向响应音乐，而AI在舞蹈中的应用多限于从音乐生成编舞。本文旨在打破这种单向关系，探索舞者与AI的双向互动，扩展表演艺术的创作可能性。

研究方法: 采用多模态架构，通过智能组合预录音乐片段响应舞者动作，建立舞者与AI的双向创作伙伴关系。通过表演数据的相关性分析，揭示动作特性与音频特征之间的沟通模式。

研究结果: 实验表明，系统能根据舞者动作动态生成连贯的音乐作品，并发现动作与音频特征之间存在显著的关联模式。

研究结论: 本研究重新定义了AI在表演艺术中的角色，将其视为响应式合作者，为专业舞蹈表演和即兴艺术表达提供了新的可能性。

中文摘要: 传统舞蹈表演中，动作单向响应音乐。尽管AI在多个创意领域取得进展，但其在舞蹈中的应用主要集中于从音乐输入生成编舞。我们提出了一种系统，使舞者能够通过动作动态塑造音乐环境。我们的多模态架构通过智能组合预录音乐片段响应舞者动作，建立了一种双向创作伙伴关系，舞者既是表演者也是作曲家。通过对表演数据的相关性分析，我们展示了动作特性与音频特征之间涌现的沟通模式。这种方法重新定义了AI在表演艺术中的角色，将其视为响应式合作者，为专业舞蹈表演和更广泛人群的即兴艺术表达扩展了可能性。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [300] [GaussMarker: Robust Dual-Domain Watermark for Diffusion Models](https://arxiv.org/abs/2506.11444)
**中文标题：GaussMarker：扩散模型的鲁棒双域水印**

*Kecen Li,Zhicong Huang,Xinwen Hou,Cheng Hong*

主要分类: cs.CR

摘要简述: 本文提出了一种名为GaussMarker的双域水印方法，通过在空间和频率域中嵌入水印，并结合高斯噪声恢复器（GNR）提升鲁棒性，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着扩散模型（DM）生成的图像越来越逼真，版权和滥用问题日益突出。现有水印方法仅在高斯噪声的单域中嵌入水印，鲁棒性不足。

研究方法: 提出了一种双域水印方法，使用流水线注入器在空间和频率域中一致嵌入水印，并引入模型无关的可学习高斯噪声恢复器（GNR）以增强对图像操作和高级攻击的鲁棒性。

研究结果: GaussMarker在八种图像失真和四种高级攻击下，在三个版本的Stable Diffusion中均表现出最优性能，召回率更高且误报率更低。

研究结论: GaussMarker通过双域水印和GNR的结合，显著提升了水印的鲁棒性，为扩散模型的版权保护提供了高效解决方案。

中文摘要: 随着扩散模型（DM）生成的图像越来越逼真，相关的版权和滥用问题日益突出。水印技术是一种有前景的解决方案。现有方法仅在高斯噪声的单域中嵌入水印，鲁棒性不足。本文首次提出了一种双域水印方法，通过流水线注入器在空间和频率域中一致嵌入水印。为进一步提升对某些图像操作和高级攻击的鲁棒性，我们引入了一种模型无关的可学习高斯噪声恢复器（GNR），用于优化从处理图像中提取的高斯噪声，并通过整合两种水印的检测分数增强检测鲁棒性。GaussMarker在八种图像失真和四种高级攻击下，在三个版本的Stable Diffusion中均表现出最优性能，召回率更高且误报率更低，符合实际应用需求。

</details>


### [301] [Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models](https://arxiv.org/abs/2506.11521)
**中文标题：调查音频-视觉攻击的漏洞与防御：以多模态模型为重点的全面综述**

*Jinming Wen,Xinyi Wu,Shuai Zhao,Yanhao Jia,Yuwen Li*

主要分类: cs.CR

摘要简述: 本文全面调查了音频-视觉多模态模型的安全漏洞及防御措施，重点分析了对抗攻击、后门攻击和越狱攻击等多种攻击类型，填补了现有研究的空白，并指出了未来研究的挑战与趋势。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在音频-视觉任务中表现出色，但其依赖第三方数据和开源模型的行为带来了安全隐患。现有调查仅关注特定攻击类型，缺乏对多种攻击的统一综述，因此本文旨在填补这一空白。

研究方法: 本文通过系统综述的方式，分析了音频-视觉攻击的多种类型，包括对抗攻击、后门攻击和越狱攻击，并特别关注了最新的音频-视觉MLLMs中的攻击案例。

研究结果: 研究发现，MLLMs易受指令或输入（如对抗扰动和恶意查询）的操纵，绕过其内部安全机制。此外，现有防御措施存在局限性，亟需更全面的解决方案。

研究结论: 本文不仅总结了音频-视觉攻击的现状，还指出了未来研究的挑战与趋势，为多模态模型的安全发展提供了重要参考。

中文摘要: 多模态大语言模型（MLLMs）在音频-视觉与自然语言处理之间架起桥梁，并在多项音频-视觉任务中达到最先进性能。然而，高质量音频-视觉训练数据和计算资源的稀缺迫使研究者依赖第三方数据和开源MLLMs，这一趋势在当代研究中日益普遍。这种繁荣背后隐藏着重大安全风险。实证研究表明，最新的MLLMs可能被操纵以生成恶意或有害内容，这种操纵仅通过指令或输入（如对抗扰动和恶意查询）即可实现，从而绕过模型内置的安全机制。为深入理解音频-视觉多模态模型的安全漏洞，一系列调查研究了多种攻击类型，包括对抗攻击和后门攻击。尽管现有调查对音频-视觉攻击提供了全面概述，但仅限于特定攻击类型，缺乏对各种攻击的统一综述。为解决这一问题并洞察领域最新趋势，本文对音频-视觉攻击（包括对抗攻击、后门攻击和越狱攻击）进行了全面而系统的综述。此外，本文还综述了最新音频-视觉MLLMs中的多种攻击类型，这是现有调查中明显缺失的维度。基于大量综述的全面见解，本文为音频-视觉攻击与防御的未来研究指明了挑战与新兴趋势。

</details>


### [302] [FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations](https://arxiv.org/abs/2506.11635)
**中文标题：FAA框架：一种基于大语言模型的信用卡欺诈调查方法**

*Shaun Shuster,Eyal Zaloof,Asaf Shabtai,Rami Puzis*

主要分类: cs.CR

摘要简述: 本文提出了一种基于多模态大语言模型（LLM）的欺诈分析师助手（FAA）框架，用于自动化信用卡欺诈调查并生成解释性报告，显著减轻分析师的工作负担。


<details>
  <summary>详细信息</summary>
研究动机: 电子商务的快速发展导致信用卡欺诈行为激增，分析师面临大量交易警报，调查工作繁重且易疲劳。为解决这一问题，作者提出利用LLM技术自动化欺诈调查。

研究方法: FAA框架利用多模态LLM的推理、代码执行和视觉能力，分步骤规划、收集证据和分析信用卡欺诈案件，实现自动化调查和报告生成。

研究结果: 通过对500起信用卡欺诈案件的实证评估，FAA框架平均完成7步调查，表现出高效性和可靠性，显著减轻了分析师的工作负担。

研究结论: FAA框架能够自动化大部分欺诈调查工作，有效缓解分析师面临的挑战，提升调查效率和准确性。

中文摘要: 电子商务的持续发展吸引了利用盗取信用卡信息的欺诈者。企业通常通过调查可疑交易来维护客户信任并弥补欺诈检测系统的不足。然而，分析师因信用卡交易监控系统产生的大量警报而疲于应对。每起警报调查都需要分析师投入大量精力、专业知识和精确记录结果，导致警报疲劳。为此，我们提出了一种欺诈分析师助手（FAA）框架，利用多模态大语言模型（LLM）自动化信用卡欺诈调查并生成解释性报告。FAA框架通过LLM的推理、代码执行和视觉能力，在调查的每个步骤中进行规划、证据收集和分析。对500起信用卡欺诈案件的实证评估表明，FAA框架平均完成7步调查，表现出高效性和可靠性。因此，我们发现FAA框架能够自动化大部分工作，帮助减轻分析师面临的挑战。

</details>


### [303] [LLMs on support of privacy and security of mobile apps: state of the art and research directions](https://arxiv.org/abs/2506.11679)
**中文标题：大型语言模型在移动应用隐私与安全支持中的现状与研究方向**

*Tran Thanh Lam Nguyen,Barbara Carminati,Elena Ferrari*

主要分类: cs.CR

摘要简述: 本文探讨了大型语言模型（LLMs）在移动应用安全和隐私保护中的应用，展示了其替代传统分析方法的潜力，并提出了检测敏感数据泄露的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 随着移动设备的普及，安全和隐私风险日益复杂，传统分析方法效率不足，亟需更先进的检测手段。本文旨在探索LLMs在移动应用安全和隐私保护中的潜力。

研究方法: 通过综述LLMs在移动应用安全领域的最新研究，提出了一种基于LLMs的解决方案，用于检测用户在线分享图像时的敏感数据泄露问题。

研究结果: 研究表明，LLMs能够有效识别和缓解移动应用中的安全风险，尤其是敏感数据泄露问题，展示了其替代传统分析方法的可行性。

研究结论: LLMs在移动应用安全和隐私保护中具有巨大潜力，但仍面临一些开放的研究挑战，需要进一步探索。

中文摘要: 现代生活中，移动设备的普及带来了便利，但同时也伴随着安全和隐私风险。近年来，这些威胁日益复杂，亟需更先进、高效的检测方法。本章探讨了大型语言模型（LLMs）在识别和缓解移动应用生态系统中安全风险与隐私侵犯方面的应用。通过介绍LLMs在缓解智能手机平台十大常见安全风险方面的最新研究，我们强调了LLMs替代传统分析方法（如动态和混合分析）的可行性与潜力。作为LLM解决方案的代表，我们提出了一种检测用户在线分享图像时敏感数据泄露的方法，这是当今智能手机用户的常见行为。最后，我们讨论了开放的研究挑战。

</details>


### [304] [Differential Privacy in Machine Learning: From Symbolic AI to LLMs](https://arxiv.org/abs/2506.11687)
**中文标题：机器学习中的差分隐私：从符号AI到大语言模型**

*Francisco Aguilera-Martínez,Fernando Berzal*

主要分类: cs.CR

摘要简述: 本文综述了差分隐私在机器学习中的应用，从基础定义到最新进展，探讨了其在保护数据隐私方面的作用及实践评估方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于解决机器学习模型可能泄露敏感信息的问题，通过差分隐私框架限制算法输出对单个数据点的依赖性，从而保护隐私。

研究方法: 方法包括回顾差分隐私的基础定义及其演变，分析其在机器学习模型中的集成方式，并探讨隐私保护训练方法及实践评估技术。

研究结果: 结果表明，差分隐私能有效减少隐私泄露风险，但其实际应用中仍面临对抗性攻击等挑战。

研究结论: 结论指出，差分隐私为构建安全可靠的AI系统提供了重要工具，但需进一步研究以应对现实中的复杂问题。

中文摘要: 机器学习模型不应泄露其他方式无法获取的特定信息。差分隐私通过确保算法输出不因单个数据点的增减而显著变化，提供了一个减轻隐私风险的正式框架。本文综述了差分隐私的基础定义，回顾了其原始表述及关键研究贡献的演变历程，深入探讨了差分隐私如何融入机器学习模型，分析了现有保护隐私的训练方法。最后，描述了如何实际评估基于差分隐私的机器学习技术。通过全面概述差分隐私在机器学习中的应用，本文旨在为开发安全、负责任的AI系统贡献力量。

</details>


### [305] [Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches](https://arxiv.org/abs/2506.11939)
**中文标题：今日之猫为明日之犬：考虑时间变化对机器学习漏洞检测标签的影响**

*Ranindya Paramitha,Yuan Feng,Fabio Massacci*

主要分类: cs.CR

摘要简述: 本文提出了一种方法，通过重构数据集以反映随时间变化的标签，验证机器学习模型在漏洞检测中的学习效果。结果表明，大多数模型并未真正学习，性能随时间变化不一致。


<details>
  <summary>详细信息</summary>
研究动机: 现有漏洞数据集包含回顾性信息，但训练和测试时只能使用当时的标签（如已知和假设的负样本）。随着漏洞随时间被发现，标签会变化，过去性能未必反映未来表现。过去的研究要么过于乐观（使用完整历史数据），要么过于保守（仅比较连续版本）。本文旨在解决这一问题。

研究方法: 提出一种方法，将数据集重构为一系列反映当时知识的数据集，训练和测试标签随时间变化。通过Mann-Kendall检验验证模型是否随数据增加而提升性能。使用4个时间相关数据集（来自BigVul和Vuldeepecker的NVD）和5种ML模型（Code2Vec、CodeBERT、LineVul、ReGVD和Vuldeepecker）进行验证。

研究结果: 与直觉（更多回顾性信息带来更好性能）相反，性能随时间变化不一致，表明大多数模型并未真正学习。

研究结论: 研究揭示了现有漏洞检测模型在学习能力上的局限性，强调需改进模型以适应标签的动态变化。

中文摘要: 用于机器学习测试的漏洞数据集隐含回顾性信息。在实际测试中，只能使用训练和测试时的标签（如已知和假设的负样本）。随着漏洞随时间被发现，标签会变化，过去性能未必反映未来表现。过去研究仅考虑部分历史数据（如DiverseVUl）或版本间差异（如Jimenez等，ESEC/FSE 2019），这些方法要么过于乐观（使用完整历史数据），要么过于保守（仅比较连续版本）。本文提出一种方法，将数据集重构为一系列反映当时知识的数据集，训练和测试标签随时间变化。若模型真正学习，其性能应随数据增加和稳定而提升，可通过Mann-Kendall检验验证。我们使用4个时间相关数据集（来自BigVul和Vuldeepecker的NVD）和5种ML模型（Code2Vec、CodeBERT、LineVul、ReGVD和Vuldeepecker）验证方法。与直觉相反，性能随时间变化不一致，表明大多数模型并未学习。

</details>


### [306] [Technical Evaluation of a Disruptive Approach in Homomorphic AI](https://arxiv.org/abs/2506.11954)
**中文标题：同态AI中一种颠覆性方法的技术评估**

*Eric Filiol*

主要分类: cs.CR

摘要简述: 本文对一种名为HbHAI的新型加密技术进行了技术评估，该技术基于键依赖哈希函数，能在加密数据上直接运行现有AI算法，性能远超传统同态加密方案。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机是评估HbHAI技术是否能在保持数据加密的同时，支持未经修改的传统AI算法运行，并验证其性能和安全性。

研究方法: 方法包括使用传统无监督和监督学习技术（如聚类、分类和深度神经网络）对HbHAI保护的数据集进行测试，并采用现成的AI算法进行独立分析。

研究结果: 结果显示HbHAI技术基本实现了其宣称的性能和安全性，仅存在少量次要问题。

研究结论: 结论认为HbHAI是一种颠覆性的加密方法，能够在不修改现有AI算法的情况下高效处理加密数据，具有广阔的应用前景。

中文摘要: 本文对一种名为HbHAI（基于哈希的同态人工智能）的新型加密技术进行了技术评估。HbHAI基于一类新型的键依赖哈希函数，能够自然保留大多数AI算法依赖的相似性属性。其主要优势在于，能够在数据保持加密状态的情况下，直接使用现有的原生AI算法进行分析和处理，且性能远超现有同态加密方案。

我们使用传统的无监督和监督学习技术（如聚类、分类和深度神经网络）对HbHAI保护的数据集（非公开预览版）进行了测试，并采用未经修改的经典AI算法。本文展示了基于这些现成AI算法的独立分析结果，旨在评估HbHAI技术的安全性、可操作性和性能表现。结果显示，大多数宣称的性能和安全性得到了验证，仅存在少量次要问题。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [307] [Interaction, Process, Infrastructure: A Unified Architecture for Human-Agent Collaboration](https://arxiv.org/abs/2506.11718)
**中文标题：交互、流程、基础设施：人机协作的统一架构**

*Yun Wang,Yan Lu*

主要分类: cs.HC

摘要简述: 本文提出了一种分层框架，整合交互、流程和基础设施三个维度，以支持持续、自适应的人机协作，强调流程的显式化和可适应性。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI工具在专业知识工作中日益普及，但其功能碎片化，缺乏持续协作的架构支持。本文旨在解决这一问题，提出统一的人机协作架构。

研究方法: 提出一个三层框架，将交互、流程和基础设施作为核心维度，特别强调流程的显式化、可检查和可适应性，以实现人机协作的动态协调。

研究结果: 该框架揭示了当前工具的局限性，统一了新兴系统设计方法，并为研究人员和AI系统构建者提供了新的研究方向。

研究结论: 通过将智能行为建立在结构化协作基础上，本文重新定义了人机协作，将其视为一种连贯且对齐的系统，而非任务特定的增强。

中文摘要: 随着AI工具（如聊天机器人、协作者和新兴代理）在各领域的普及，它们越来越多地支持专业知识工作。然而，尽管其功能不断增强，这些系统仍显碎片化：它们协助完成孤立任务，但缺乏持续、自适应协作的架构支持。我们提出了一种分层框架，整合交互、流程和基础设施三个相互依赖的维度。关键之处在于，该架构通过使流程显式化、可检查和可适应，将其提升为主要关注点，从而使人机能够根据不断变化的目标对齐并协调行动。这一模型揭示了当前工具的局限性，统一了新兴系统设计方法，并为研究人员和AI系统构建者提供了新的机会。通过将智能行为建立在结构化协作基础上，我们重新构想人机协作，将其视为一种连贯且对齐的系统，而非任务特定的增强。

</details>


### [308] [Enter: Graduated Realism: A Pedagogical Framework for AI-Powered Avatars in Virtual Reality Teacher Training](https://arxiv.org/abs/2506.11890)
**中文标题：引入：渐进式真实感——虚拟现实教师培训中AI驱动化身的教学框架**

*Judson Leroy Dean Haynes IV*

主要分类: cs.HC

摘要简述: 本文提出了一种名为‘渐进式真实感’的教学框架，用于指导虚拟现实教师培训中AI驱动的学生化身的真实感设计。通过系统性文献回顾，研究发现超真实感并非总是最优选择，并提出了一种逐步增加化身复杂性的方法，以减轻初学者的认知负荷。


<details>
  <summary>详细信息</summary>
研究动机: 虚拟现实模拟器为教师培训提供了强大工具，但AI驱动的学生化身的真实感水平如何设计才能最有效支持教学，仍是一个关键挑战。本文旨在填补技术追求高真实感与教学需求之间的鸿沟。

研究方法: 通过系统性文献回顾，梳理了从人类控制化身到生成式AI原型的演变历程，并结合认知负荷理论等学习理论，提出了‘渐进式真实感’框架。此外，设计了一种名为‘Crazy Slots’的单调用架构，以支持实时响应生成。

研究结果: 研究发现，高真实感化身可能增加初学者的额外认知负荷，而‘渐进式真实感’框架能够有效支持技能发展。提出的‘Crazy Slots’架构在计算上可行，能够生成真实且低延迟的响应。

研究结论: 本文为下一代AI模拟器的设计提供了基于证据的原则，强调教学需求驱动的真实感设计对可扩展且有效的教师教育工具至关重要。

中文摘要: 虚拟现实模拟器为教师培训提供了强大工具，但AI驱动的学生化身的真实感水平如何设计才能最有效支持教学，仍是一个关键挑战。本文通过系统性文献回顾，梳理了虚拟现实教师培训中化身真实感的演变，综合了其理论意义，并提出了一种新的教学框架以指导未来设计。研究发现，超真实感并非总是最优选择，因为高保真化身可能为初学者带来额外的认知负荷，这一观点得到了近期实证研究的支持。技术追求的高真实感与教学需求的渐进式学习之间存在显著鸿沟。为解决这一问题，本文提出了‘渐进式真实感’框架，建议从低真实感化身开始，随着技能发展逐步增加行为复杂性。为实现这一目标，本文还提出了一种名为‘Crazy Slots’的单调用架构，该架构利用概率引擎和检索增强生成数据库，生成真实且实时的响应，避免了多步推理模型的延迟和成本。本文为设计下一代AI模拟器提供了基于证据的原则，强调教学需求驱动的真实感设计对可扩展且有效的教师教育工具至关重要。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [309] [Application Modernization with LLMs: Addressing Core Challenges in Reliability, Security, and Quality](https://arxiv.org/abs/2506.10984)
**中文标题：利用大型语言模型实现应用现代化：解决可靠性、安全性和质量的核心挑战**

*Ahilan Ayyachamy Nadar Ponnusamy*

主要分类: cs.SE

摘要简述: 本文探讨了利用大型语言模型（LLMs）进行应用现代化的方法，重点关注代码推理和生成能力，并结合人类专业知识解决可靠性、安全性和质量等核心挑战。通过案例研究验证了框架的实用性。


<details>
  <summary>详细信息</summary>
研究动机: AI辅助代码生成工具虽然提高了开发效率，但仍存在安全漏洞、可靠性问题和代码不一致性等挑战。本文旨在通过结合LLMs和人类专业知识，解决这些问题，释放AI技术的潜力。

研究方法: 提出了一种基于LLMs的框架，强调其代码推理和生成能力，并与人类专家协作，以应对应用现代化中的挑战。通过案例研究展示了框架的实际应用。

研究结果: 案例研究表明，该框架能够有效解决应用现代化中的核心问题，同时强调了人类参与在AI辅助过程中的重要性。

研究结论: 本文为AI驱动的应用现代化提供了实用框架和未来研究方向，强调了人类与AI协作的关键作用。

中文摘要: AI辅助代码生成工具彻底改变了软件开发，提供了前所未有的效率和可扩展性。然而，多项研究一致指出其存在的安全漏洞、可靠性问题和代码不一致性等挑战。解决这些问题对于释放这一变革性技术的全部潜力至关重要。尽管基础和代码专用语言模型的进步在缓解部分问题上取得了显著进展，但在确保高质量、可信输出方面仍存在重大差距。
  本文基于现有研究，探讨了利用大型语言模型（LLMs）进行应用现代化的方法。提出了一种强调LLMs代码推理和生成能力的框架，并结合人类专业知识以有效应对应用现代化挑战。该框架突出了人类参与和指导在确保AI辅助流程成功中的不可或缺作用。
  为验证框架的实用性，本文通过详细案例研究展示了其在实际场景中的应用。分析包括逐步分解和适用时的替代方案评估。本研究旨在为AI驱动的应用现代化提供实用见解和未来研究的坚实基础。本文的参考实现已在GitHub上发布。

</details>


### [310] [Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs](https://arxiv.org/abs/2506.10989)
**中文标题：提示工程与框架：基于LLMs的代码可靠性提升指南**

*Rogelio Cruz,Jonatan Contreras,Francisco Guerrero,Ezequiel Rodriguez,Carlos Valdez,Citlali Carrillo*

主要分类: cs.SE

摘要简述: 本文提出了一种新颖的提示工程方法，旨在提升大型语言模型（LLMs）生成准确Python代码的能力。通过实验验证，该方法在代码质量和正确性上优于零样本和思维链（CoT）方法，同时显著减少计算资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在生成代码时存在准确性和可靠性不足的问题，尤其是在零样本或思维链提示下。本文旨在通过设计优化的提示模板，提升代码生成的质量和效率，同时降低计算资源需求。

研究方法: 本文提出了一种定制的提示模板，专门用于提升LLMs生成Python代码的准确性和可靠性。实验基于HumanEval数据集，对比了零样本、思维链及本文方法在Pass@k指标上的表现。

研究结果: 实验结果表明，本文提出的方法在代码生成质量上优于零样本和思维链方法，且在计算资源消耗上显著减少，实现了高效和环保的双重目标。

研究结论: 本文证明了定制化提示策略在优化代码生成性能上的潜力，为AI驱动的编程任务提供了更高效和可持续的解决方案。

中文摘要: 本文提出了一种新颖的提示方法，旨在提升大型语言模型（LLMs）生成准确Python代码的能力。具体而言，我们设计了一种提示模板，用于提高生成代码片段的质量和正确性，使其能够通过测试并产生可靠结果。通过在HumanEval数据集上对两种先进LLMs的实验，我们证明了该方法在Pass@k指标上优于广泛研究的零样本和思维链（CoT）方法。此外，与CoT方法相比，我们的方法显著减少了令牌使用量，既高效又资源节约，从而降低了计算需求并改善了LLM能力的生态足迹。这些发现凸显了定制化提示策略在优化代码生成性能上的潜力，为AI驱动的编程任务开辟了更广泛的应用前景。

</details>


### [311] [On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances](https://arxiv.org/abs/2506.10990)
**中文标题：‘追随太阳’策略在减少AI云实例碳足迹中的有效性研究**

*Roberto Vergallo,Luís Cruz,Alessio Errico,Luca Mainetti*

主要分类: cs.SE

摘要简述: 本文研究了‘追随太阳’（FtS）策略在减少AI云实例碳足迹中的有效性，实验证明FtS平均减少14.6%的碳排放，峰值可达16.3%，同时保持训练时间。


<details>
  <summary>详细信息</summary>
研究动机: AI的高能耗问题引发广泛讨论，但缺乏科学证据支持‘追随太阳’策略在减少AI碳足迹方面的优势。本文旨在填补这一研究空白。

研究方法: 在部分合成场景中，对四种异常检测AI算法进行实验，比较无策略、FtS策略及两种现有策略（灵活开始、暂停与恢复）的碳排放差异，使用2021年七个欧洲城市的碳排放强度数据。

研究结果: 实验结果显示，FtS策略平均减少14.6%的碳排放（峰值16.3%），且不影响训练时间。

研究结论: FtS策略能有效减少AI云实例的碳足迹，为可持续AI发展提供可行方案。

中文摘要: ‘追随太阳’（FtS）是一种理论计算模型，旨在通过动态将工作负载转移到能源更清洁的区域以减少计算机工作负载的碳足迹。随着人工智能（AI）的高能耗成为广泛讨论的话题，FtS被提出作为减少AI模型训练碳足迹的策略。然而，现有文献缺乏关于FtS在减少AI工作负载碳足迹方面优势的科学证据。本文通过部分合成场景的实验填补了这一研究空白。我们对比了四种异常检测AI算法在四种情况下的碳排放差异：无策略、FtS策略及两种现有策略（灵活开始、暂停与恢复）。实验使用了2021年七个欧洲城市的历史碳排放强度数据。结果表明，FtS策略不仅平均减少14.6%的碳排放（峰值16.3%），还能保持训练时间。

</details>


### [312] [Evaluating LLMs for Visualization Tasks](https://arxiv.org/abs/2506.10996)
**中文标题：评估大型语言模型在可视化任务中的表现**

*Saadiq Rauf Khan,Vinit Chandak,Sougata Mukherjea*

主要分类: cs.SE

摘要简述: 本文评估了大型语言模型（LLMs）在可视化任务中的表现，发现其能生成可视化代码并回答相关问题，但也存在局限性。


<details>
  <summary>详细信息</summary>
研究动机: 信息可视化用于从复杂数据中获取洞察，而LLMs在多项任务中表现出色。本文旨在探索LLMs在生成可视化代码和理解常见图表方面的能力。

研究方法: 研究通过简单提示测试不同流行LLMs生成可视化代码的能力，并分析其回答关于常见可视化问题的能力。

研究结果: 研究表明，LLMs能生成部分可视化代码并回答相关问题，但也存在一些局限性。

研究结论: 本文的发现可为改进LLMs和信息可视化系统提供参考。

中文摘要: 信息可视化用于从复杂数据中获取洞察。近年来，大型语言模型（LLMs）在许多任务中表现优异。本文展示了不同流行LLMs根据简单提示生成可视化代码的能力，并分析了LLMs通过回答简单问题理解常见图表的能力。研究表明，LLMs能生成部分可视化代码并回答相关问题，但也存在一些局限性。我们相信这些见解可用于改进LLMs和信息可视化系统。

</details>


### [313] [Towards Automated Formal Verification of Backend Systems with LLMs](https://arxiv.org/abs/2506.10998)
**中文标题：基于LLM的后端系统形式化验证自动化研究**

*Kangping Xu,Yifan Luo,Yang Yuan,Andrew Chi-Chih Yao*

主要分类: cs.SE

摘要简述: 本文提出了一种利用函数式编程和类型系统将Scala后端代码转化为形式化Lean表示的新框架，通过LLM验证API和数据库操作的正确性，可自动化验证50%的测试需求，显著降低成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有自动化测试方法存在测试局部性、缺乏通用可靠性及业务逻辑盲区等局限性，难以匹敌人工程师的能力。本文旨在通过形式化验证和LLM技术提升测试效率和准确性。

研究方法: 通过函数式编程和类型系统将Scala后端代码转化为形式化Lean表示，自动生成描述API和数据库操作行为的定理，并利用基于LLM的证明器验证这些定理。验证成功则逻辑正确，失败则确认存在缺陷，无法验证时需人工干预。

研究结果: 在真实后端系统上的实验表明，该方法能形式化验证50%以上的测试需求，平均每个API验证成本仅2.19美元，显著优于人工测试且易于并行扩展。

研究结论: 该方法为可扩展的AI驱动软件测试提供了新方向，随着模型进步，有望大幅提升工程效率。

中文摘要: 软件测试在确保系统行为符合预期方面至关重要。然而，现有自动化测试方法因测试局部性、缺乏通用可靠性及业务逻辑盲区等关键限制，难以匹敌人工程师的能力。本文提出了一种新颖框架，利用函数式编程和类型系统将Scala后端代码转化为形式化Lean表示。我们的流程自动生成描述API和数据库操作行为的定理，并使用基于LLM的证明器验证它们。若定理被证明，则对应逻辑正确且无需进一步测试；若定理的否定被证明，则确认存在缺陷；若两者均无法证明，则需人工干预。我们在真实后端系统上评估了该方法，发现其能形式化验证50%以上的测试需求，表明测试工程师一半的工作量可被自动化。此外，基于LLM的验证平均每个API成本仅2.19美元，显著优于人工测试且易于并行扩展。结果表明，这一方法为可扩展的AI驱动软件测试提供了有前景的方向，随着模型进步，有望大幅提升工程效率。

</details>


### [314] [Automated Validation of COBOL to Java Transformation](https://arxiv.org/abs/2506.10999)
**中文标题：COBOL到Java转换的自动化验证**

*Atul Kumar,Diptikalyan Saha,Toshikai Yasue,Kohichi Ono,Saravanan Krishnan,Sandeep Hans,Fumiko Satoh,Gerald Mitchell,Sachin Kumar*

主要分类: cs.SE

摘要简述: 本文提出了一种基于符号执行的框架和工具，用于验证COBOL到Java代码转换的正确性，并生成单元测试以确保语义等价。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于大型语言模型（LLM）的代码转换技术取得了进展，但转换后的代码是否准确仍无法完全信任。因此，需要一种方法来验证转换的正确性并提供反馈以改进模型。

研究方法: 开发了一个基于符号执行的测试生成工具，自动为COBOL程序生成单元测试，并模拟外部资源调用。同时生成等效的JUnit测试用例，通过运行测试检查原始COBOL程序与转换后Java程序的语义等价性。

研究结果: 该框架能够有效验证COBOL到Java代码转换的正确性，并在发现问题时提供修复建议，同时为AI模型提供反馈以优化转换结果。

研究结论: 提出的方法和工具为验证代码转换的正确性提供了可行方案，有助于提高基于LLM的代码转换技术的可靠性。

中文摘要: 近年来，基于大型语言模型（LLM）的生成式AI技术使得将企业级代码从COBOL等传统语言转换为Java或Python等现代语言成为可能。尽管LLM自动转换的结果令人鼓舞，但转换后的代码是否准确仍无法完全信任。为此，我们提出了一种框架和工具，用于验证COBOL与转换后Java代码的等价性。该工具还能在发现问题时修复代码，并为AI模型提供反馈以改进转换效果。我们开发了一种基于符号执行的测试生成方法，自动为COBOL程序生成单元测试，并模拟外部资源调用。同时生成等效的JUnit测试用例，通过运行这些测试来检查原始程序与转换后程序的语义等价性。

</details>


### [315] [Rethinking Technological Readiness in the Era of AI Uncertainty](https://arxiv.org/abs/2506.11001)
**中文标题：在AI不确定性时代重新思考技术准备**

*S. Tucker Browne,Mark M. Bailey*

主要分类: cs.SE

摘要简述: 本文提出了一种新的AI准备框架，以评估军事系统中AI组件的成熟度和可信度，弥补现有技术准备评估的不足，确保AI系统在军事任务中的可靠性和安全性。


<details>
  <summary>详细信息</summary>
研究动机: 当前的技术准备评估未能涵盖AI特有的关键因素，导致AI在军事系统中部署时存在潜在风险。为了解决这一问题，作者提出了一种专门针对AI的准备框架。

研究方法: 作者提出了一种新的AI准备框架，类似于传统的技术准备水平（TRL），但针对AI进行了扩展。该框架通过现有数据评估工具和测试实践，评估AI系统的可靠性、安全性和适用性。

研究结果: 研究表明，该框架在短期内具有可行性，能够为军事决策者提供清晰的评估标准，确保AI系统在性能、透明度和人机整合方面达到部署要求。

研究结论: 通过这一结构化方法，军事决策者可以更准确地判断AI系统是否具备部署条件，从而推动国防技术管理和风险评估领域的发展。

中文摘要: 人工智能（AI）有望彻底改变军事作战系统，但确保这些AI赋能的能力真正具备任务准备性带来了新的挑战。我们认为，当前的技术准备评估未能捕捉到AI特有的关键因素，导致部署时存在潜在风险。我们提出了一种新的AI准备框架，用于评估军事系统中AI组件的成熟度和可信度。核心论点是，一个类似于传统技术准备水平（TRL）但针对AI扩展的定制框架，可以更好地衡量AI系统的可靠性、安全性和战斗适用性。通过使用现有的数据评估工具和测试实践，我们证明了该框架在短期内实施的可行性。这种结构化方法为军事决策者提供了更清晰的洞察力，以判断AI赋能系统是否达到了性能、透明度和人机整合的必要标准，从而可以自信地部署，并推动国防技术管理和风险评估领域的发展。

</details>


### [316] [EmbedAgent: Benchmarking Large Language Models in Embedded System Development](https://arxiv.org/abs/2506.11003)
**中文标题：EmbedAgent：嵌入式系统开发中大语言模型的基准测试**

*Ruiyang Xu,Jialun Cao,Mingyuan Wu,Wenliang Zhong,Yaojie Lu,Ben He,Xianpei Han,Shing-Chi Cheung,Le Sun*

主要分类: cs.SE

摘要简述: 本文提出EmbedAgent和Embedbench，首个针对嵌入式系统开发的LLM基准测试，涵盖编程、电路设计和跨平台迁移任务。实验发现LLM表现参差不齐，并提出两种优化策略显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏评估大语言模型（LLM）在嵌入式系统开发中能力的基准测试，本文旨在填补这一空白，通过模拟真实开发角色和任务，全面评估LLM的实际应用潜力。

研究方法: 提出EmbedAgent框架，模拟嵌入式系统开发中的角色（如程序员、架构师和集成师），并设计Embedbench基准，包含126个案例，覆盖3个硬件平台和9种电子组件。通过10种主流LLM的实验，分析其表现。

研究结果: 实验显示LLM在简单任务中表现不佳（如DeepSeek-R1的通过率仅55.6%），跨平台迁移任务中性能差异显著（MicroPython任务最高73.8%，ESP-IDF任务仅29.4%）。提出的检索增强生成和编译器反馈策略显著提升了性能。

研究结论: LLM在嵌入式系统开发中潜力巨大但表现不稳定，需针对性优化。本文提出的策略有效提升了任务完成率，为未来研究提供了方向。

中文摘要: 大语言模型（LLM）在多种任务中展现出潜力，但缺乏针对嵌入式系统开发的基准测试。本文提出EmbedAgent，一种模拟嵌入式系统开发中真实角色（如嵌入式系统程序员、架构师和集成师）的范式，使LLM能够在连接数字与物理系统的任务中接受测试，从而更全面地评估其能力。为评估LLM在这些任务中的表现，我们提出Embedbench，首个涵盖嵌入式系统编程、电路设计和跨平台迁移的综合基准。Embedbench包含126个案例，覆盖3个硬件平台和9种电子组件。通过对10种主流LLM的广泛实验，我们发现了一些关键结果。令人惊讶的是，尽管案例简单，DeepSeek-R1在提供原理图信息时的通过率仅为55.6%，而在生成原理图任务中为50.0%。在跨平台迁移任务中，LLM在Raspberry Pi Pico的MicroPython上表现较强（最高模型通过率为73.8%），但在ESP-IDF上表现较差（最佳模型通过率仅29.4%）。有趣的是，我们发现通用聊天LLM（如DeepSeek-V3）常未能利用预训练知识，而推理型LLM则容易过度思考并忽略高效知识。基于这些发现，我们提出两种策略：检索增强生成和编译器反馈，以提升LLM性能。这些策略显著改善了结果，DeepSeek-R1在正确原理图下的通过率提升至65.1%，无原理图时为53.1%。此外，Arduino到ESP32迁移任务的准确率从21.4%提升至27.8%。

</details>


### [317] [Impact of Comments on LLM Comprehension of Legacy Code](https://arxiv.org/abs/2506.11007)
**中文标题：注释对LLM理解遗留代码的影响**

*Rock Sabetto,Emily Escamilla,Devesh Agarwal,Sujay Kandwal,Justin F. Brunelle,Scott Rosen,Nitin Naik,Samruddhi Thaker,Eric O. Scott,Jacob Zimmer,Amit Madan,Arun Sridharan,Doug Wendt,Michael Doyle,Christopher Glasz,Jasper Phillips,William Macke,Colin Diggs,Michael Bartholf,Zachary Robin,Paul Ursino*

主要分类: cs.SE

摘要简述: 大型语言模型（LLM）在理解遗留代码时受注释影响显著，本文通过多选问答方法评估其理解能力，并探讨注释准确性和数量的作用。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM在现代编程语言任务中表现优异，但其对遗留语言代码的理解能力尚不明确，尤其是文档缺失或不准确的情况下。本文旨在填补这一研究空白，并量化评估LLM对遗留代码的理解。

研究方法: 采用多选问答（MCQA）方法，评估LLM对遗留代码的理解能力，并分析注释的普遍性和准确性对其表现的影响。

研究结果: 初步结果显示，注释的存在和准确性显著影响LLM对遗留代码的理解能力，为未来研究提供了方向。

研究结论: 本文通过MCQA方法验证了注释对LLM理解遗留代码的重要性，并提出了未来研究的战略目标。

中文摘要: 大型语言模型（LLM）因其在软件工程任务中的高性能和对现代编程语言的深刻理解，正越来越多地应用于软件工程和维护任务中。然而，LLM对使用遗留语言编写的代码的理解能力仍是一个研究空白，尤其是现实中的遗留系统往往缺乏文档或文档不准确，这可能影响LLM的理解。为了评估LLM对遗留语言的理解能力，需要一种客观的LLM评估方法。为了客观衡量LLM对遗留语言的理解，我们需要一种高效、定量的评估方法。我们利用多选问答（MCQA）这一新兴的LLM评估方法，评估LLM对遗留代码的理解以及注释普遍性和不准确注释的影响。在这项工作中，我们提出了关于文档对LLM理解遗留代码影响的初步发现，并概述了未来工作的战略目标。

</details>


### [318] [Extracting Knowledge Graphs from User Stories using LangChain](https://arxiv.org/abs/2506.11020)
**中文标题：利用LangChain从用户故事中提取知识图谱**

*Thayná Camargo da Silva*

主要分类: cs.SE

摘要简述: 本文提出了一种利用LangChain框架和大语言模型自动从用户故事中提取知识图谱的新方法，通过自动化脚本实现图谱构建与评估，提升了用户需求的可视化与理解。


<details>
  <summary>详细信息</summary>
研究动机: 用户故事在软件开发中常用于描述需求，但传统方法难以高效提取其中的知识结构。本文旨在通过自动化技术，从用户故事中构建知识图谱，以更好地对齐软件功能与用户期望。

研究方法: 基于LangChain框架，开发了用户故事图转换模块，利用大语言模型提取用户故事中的节点和关系，构建知识图谱。通过自动化脚本实现图谱提取与评估，并使用标注数据集进行验证。

研究结果: 该方法成功实现了从用户故事到知识图谱的自动化转换，并通过评估脚本验证了其准确性。知识图谱的生成增强了用户需求的可视化与理解。

研究结论: 本文提出的方法有效提升了用户故事中知识的提取与可视化，有助于更高效、以用户为中心的软件开发流程。

中文摘要: 本文提出了一种利用大语言模型从用户故事中自动生成知识图谱的新方法。基于LangChain框架，开发了用户故事图转换模块，通过大语言模型提取用户故事中的节点和关系，构建精确的知识图谱。该方法通过自动化脚本实现了知识图谱的提取过程，并利用标注数据集通过专用评估脚本进行自动化评估。通过增强用户需求和领域概念的可视化与理解，该方法促进了软件功能与用户期望的更好对齐，最终为更高效、以用户为中心的软件开发流程做出了贡献。

</details>


### [319] [Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering](https://arxiv.org/abs/2506.11021)
**中文标题：通过功能聚类消除LLM代码生成中的幻觉错误**

*Chaitanya Ravuri,Saman Amarasinghe*

主要分类: cs.SE

摘要简述: 本文提出了一种名为“功能聚类”的黑盒包装方法，通过采样多个候选程序并执行自生成测试套件，消除LLM代码生成中的幻觉错误，显著降低错误率至2%，甚至可降至0%。


<details>
  <summary>详细信息</summary>
研究动机: 现代代码生成LLM虽能解决大量编程问题，但仍存在幻觉导致的细微错误，使其输出无法安全自主部署。本文旨在消除这些错误，提升代码生成的可靠性。

研究方法: 方法包括采样多个候选程序，执行自生成测试套件，并将输入输出行为相同的候选程序聚类。最大聚类的经验质量作为精确置信度估计，用户可通过标量阈值调整覆盖率和可靠性。

研究结果: 在LiveCodeBench上，该方法保持基线pass@1，同时将错误率从约65%降至2%，保守阈值下可降至0%，但仍能回答15.6%的提示。剩余错误主要源于提示误解而非随机噪声。

研究结论: 功能聚类方法仅需采样和沙盒执行，适用于闭源API和未来模型，为自主代码生成提供了可靠的实用路径。未来工作可专注于提升提示清晰度。

中文摘要: 现代代码生成LLM已能解决大部分编程问题，但仍会因幻觉产生细微错误，使其输出无法安全自主部署。我们提出功能聚类，一种黑盒包装方法，可消除几乎所有幻觉错误，并提供可调置信度分数。该方法采样多个候选程序，执行自生成测试套件，并将输入输出行为相同的候选程序聚类；最大聚类的经验质量作为精确置信度估计。用户可通过单一标量阈值在覆盖率和可靠性之间权衡，并享受指数级保证。在LiveCodeBench上，我们的验证器在可解任务中保持基线pass@1，同时将返回答案的错误率从约65%降至2%，保守阈值下可降至0%，但仍能回答15.6%的提示。人工审核显示，剩余错误源于提示误解而非随机生成噪声，未来工作可专注于提升规范清晰度。由于该方法仅需采样和沙盒执行，适用于闭源API和未来模型，为可靠的自主代码生成提供了实用路径。代码已开源（https://github.com/20ChaituR/functional-clustering）。

</details>


### [320] [Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox](https://arxiv.org/abs/2506.11022)
**中文标题：迭代式AI代码生成中的安全性退化——悖论的系统性分析**

*Shivani Shukla,Himanshu Joshi,Romilla Syed*

主要分类: cs.SE

摘要简述: 研究发现，通过大型语言模型（LLM）迭代生成代码时，安全性会显著下降，五次迭代后关键漏洞增加37.6%，不同提示策略下漏洞模式各异，需结合人工验证以降低风险。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLM）在代码生成中广泛应用，但其迭代改进过程中安全性如何变化尚未深入研究。本文旨在揭示LLM迭代反馈对代码安全性的影响，挑战迭代改进必然提升安全性的假设。

研究方法: 通过控制实验，分析了400个代码样本在40轮“改进”中的安全性变化，使用了四种不同的提示策略，以量化漏洞的增加趋势和模式。

研究结果: 实验显示，仅五次迭代后，关键漏洞增加了37.6%，且不同提示策略下漏洞模式显著不同，表明迭代改进可能引入新的安全问题。

研究结论: 研究揭示了LLM迭代生成代码时安全性下降的悖论，强调人工验证在迭代过程中的必要性，并提出了开发者降低风险的实用指南。

中文摘要: 大型语言模型（LLM）在代码生成中的快速应用改变了软件开发，但很少有人关注其迭代反馈如何影响安全性漏洞的演变。本文通过一项控制实验，分析了400个代码样本在40轮“改进”中的安全性变化，使用了四种不同的提示策略。研究发现，仅五次迭代后，关键漏洞增加了37.6%，且不同提示策略下漏洞模式各异。这一结果挑战了迭代LLM改进能提升代码安全性的假设，并突出了人工验证在迭代过程中的关键作用。我们提出了开发者降低风险的实用指南，强调在LLM迭代间进行严格的人工验证，以防止在看似有益的代码“改进”中引入新的安全问题。

</details>


### [321] [Refactoring Codebases through Library Design](https://arxiv.org/abs/2506.11058)
**中文标题：通过库设计重构代码库**

*Ziga Kovacic,Celine Lee,Justin Chiu,Wenting Zhao,Kevin Ellis*

主要分类: cs.SE

摘要简述: 本文研究代码代理如何通过重构代码库提升可重用性和可维护性，提出了一种名为Librarian的方法和Minicode基准测试，结果显示Librian在压缩率和正确性上优于现有代码代理。


<details>
  <summary>详细信息</summary>
研究动机: 随着代码代理在解决独立编程问题上的准确性提高，如何通过重构将专用代码转化为可重用组件成为关键挑战。本文旨在探索代码代理在支持代码增长和可重用性方面的能力。

研究方法: 提出Librarian方法，采用采样和重排序策略生成可重用库，并设计Minicode基准测试，要求代码代理将多个独立解决方案最小化并重构为联合库。

研究结果: Librarian在Minicode基准测试中表现优异，压缩率比现有代码代理高1.6-2倍，同时提升了正确性。

研究结论: Librarian方法在代码重构中表现出色，为代码代理的可重用性和可维护性提供了有效解决方案。

中文摘要: 可维护且通用的软件使开发者能够高效构建稳健的应用程序，但实现这些特性通常需要将专用解决方案重构为可重用组件。随着代码代理在解决独立编程问题上的准确性不断提高，这一挑战变得尤为重要。我们研究了代码代理在支持代码增长和可重用性方面的重构能力。本文提出了一种方法和基准测试：Librarian是一种用于生成可重用库的采样和重排序方法，Minicode是一个基准测试，要求代码代理将多个独立解决方案最小化并重构为联合库。与最先进的代码代理相比，Librarian在Minicode上实现了优异的压缩率和正确性，压缩率比代码代理高1.6-2倍，同时提升了正确性。我们在https://code-refactor.github.io/开源了代码和基准测试。

</details>


### [322] [Code Researcher: Deep Research Agent for Large Systems Code and Commit History](https://arxiv.org/abs/2506.11060)
**中文标题：代码研究员：面向大型系统代码及提交历史的深度研究代理**

*Ramneet Singh,Sathvik Joel,Abhav Mehrotra,Nalin Wadhwa,Ramakrishna B Bairi,Aditya Kanade,Nagarajan Natarajan*

主要分类: cs.SE

摘要简述: 本文提出了一种名为Code Researcher的深度研究代理，专门用于处理大型系统代码及其提交历史。通过多步推理和结构化记忆，该代理在生成系统代码补丁方面显著优于现有基线，展示了其在全局上下文收集和多方面推理上的优势。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于大型语言模型的编码代理在编码基准测试中表现良好，但其在系统代码中的应用尚未充分探索。由于系统代码的规模和复杂性，即使是人类修改代码库也极具挑战性。因此，需要一种能够深入研究代码语义、模式和提交历史的代理，以生成有效的补丁。

研究方法: Code Researcher通过多步推理分析代码的语义、模式和提交历史，收集足够的上下文信息，并将其存储在结构化记忆中用于合成补丁。该方法在Linux内核崩溃基准测试kBenchSyz上进行了评估，并与现有基线（如SWE-agent）进行了对比。

研究结果: Code Researcher在kBenchSyz基准测试中实现了58%的崩溃解决率，显著优于SWE-agent的37.5%。此外，Code Researcher平均每次探索10个文件，而SWE-agent仅探索1.33个文件，显示了其在深度探索代码库方面的能力。在开源多媒体软件上的实验进一步验证了其通用性。

研究结论: 实验结果表明，全局上下文收集和多方面推理对大型代码库至关重要。Code Researcher的成功展示了深度研究代理在系统代码修改中的潜力，为未来研究提供了重要方向。

中文摘要: 基于大型语言模型（LLM）的编码代理在编码基准测试中表现出色，但其在系统代码中的应用尚未充分探索。由于系统代码的规模和复杂性，即使是人类修改代码库也极具挑战性，需要在修改前研究大量来自代码库及其庞大提交历史的上下文。受近期深度研究代理进展的启发，我们设计了首个面向代码的深度研究代理Code Researcher，并将其应用于生成修复系统代码崩溃的补丁。Code Researcher通过多步推理分析代码的语义、模式和提交历史，收集足够的上下文信息，并将其存储在结构化记忆中用于合成补丁。我们在Linux内核崩溃基准测试kBenchSyz上评估了Code Researcher，结果显示其显著优于现有基线，崩溃解决率达到58%，而SWE-agent仅为37.5%。平均而言，Code Researcher每次探索10个文件，而SWE-agent仅探索1.33个文件，凸显了Code Researcher在深度探索代码库方面的能力。通过在开源多媒体软件上的另一项实验，我们展示了Code Researcher的通用性。实验结果表明，全局上下文收集和多方面推理对大型代码库至关重要。

</details>


### [323] [CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval](https://arxiv.org/abs/2506.11066)
**中文标题：CoQuIR：一个全面的代码质量感知信息检索基准**

*Jiahui Geng,Fengyu Cai,Shaobo Cui,Qing Li,Liangwei Chen,Chenyang Lyu,Haonan Li,Derui Zhu,Walter Pretschner,Heinz Koeppl,Fakhri Karray*

主要分类: cs.SE

摘要简述: 本文提出了首个大规模多语言基准测试CoQuIR，专注于评估代码检索在正确性、效率、安全性和可维护性四个关键维度的质量感知能力。通过实验发现，现有检索模型难以区分低质量代码，并提出了改进方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前代码检索基准主要关注功能相关性，而忽略了软件质量的关键维度。为填补这一空白，本文旨在建立一个全面评估代码质量感知检索的基准。

研究方法: CoQuIR基准包含42,725个查询和134,907个代码片段，覆盖11种编程语言，并引入两种质量中心评估指标。作者还研究了通过合成数据集训练模型以提升质量感知能力的方法。

研究结果: 实验表明，即使是性能最佳的检索模型也经常无法区分有缺陷或不安全的代码。通过改进训练方法，模型在质量感知指标上表现提升，且不影响语义相关性。

研究结论: 本文强调了将质量信号整合到代码检索系统中的重要性，为开发更可靠和健壮的软件工具奠定了基础。

中文摘要: 代码检索在现代软件开发中至关重要，它能促进代码重用并加速调试。然而，当前的基准测试主要强调功能相关性，而忽略了软件质量的关键维度。基于这一空白，我们提出了CoQuIR，这是首个大规模多语言基准，专门设计用于评估代码检索在四个关键维度（正确性、效率、安全性和可维护性）上的质量感知能力。CoQuIR为11种编程语言的42,725个查询和134,907个代码片段提供了细粒度的质量标注，并引入了两种质量中心评估指标：成对偏好准确率和基于边际的排序得分。通过CoQuIR，我们对23种检索模型（包括开源和专有系统）进行了基准测试，发现即使是性能最佳的模型也经常无法区分有缺陷或不安全的代码。此外，我们还初步研究了显式鼓励检索器识别代码质量的训练方法。通过合成数据集，我们在不牺牲语义相关性的情况下，展示了各种模型在质量感知指标上的显著改进。下游代码生成实验进一步验证了我们方法的有效性。总体而言，我们的工作强调了将质量信号整合到代码检索系统中的重要性，为开发更可靠和健壮的软件工具奠定了基础。

</details>


### [324] [LeanExplore: A search engine for Lean 4 declarations](https://arxiv.org/abs/2506.11085)
**中文标题：LeanExplore：一个用于Lean 4声明的搜索引擎**

*Justin Asher*

主要分类: cs.SE

摘要简述: 本文介绍了LeanExplore，一个专为Lean 4声明设计的搜索引擎，帮助用户通过语义搜索查找跨多个Lean 4包的声明，支持形式化和非形式化查询。


<details>
  <summary>详细信息</summary>
研究动机: 随着Lean 4生态系统的扩展，其庞大的库使得导航变得困难。为了解决这一问题，作者开发了LeanExplore，旨在提供一个高效的搜索工具，帮助用户快速找到所需的声明。

研究方法: LeanExplore采用混合排名策略，结合多源语义嵌入模型（从形式化代码、文档字符串、AI生成的非形式化翻译和声明标题中提取概念意义）、BM25+关键词匹配和基于PageRank的声明重要性评分。

研究结果: LeanExplore通过专用网站和Python API提供服务，并支持数据库下载以自托管。此外，它还能与LLM集成，支持用户与AI助手对话或构建定理证明代理。

研究结论: LeanExplore为Lean 4工作流和AI驱动的数学研究提供了强大的支持，展示了其在提升搜索效率和增强工具集成方面的潜力。

中文摘要: 随着Lean 4生态系统的扩展，其庞大的库使得导航变得困难。本文介绍了LeanExplore，一个专为Lean 4声明设计的搜索引擎。LeanExplore支持用户通过语义搜索查找跨多个Lean 4包（包括Batteries、Init、Lean、Mathlib、PhysLean和Std）的声明，无论是形式化还是非形式化的查询。该搜索引擎采用混合排名策略，结合多源语义嵌入模型（从形式化代码、文档字符串、AI生成的非形式化翻译和声明标题中提取概念意义）、BM25+关键词匹配和基于PageRank的声明重要性评分。LeanExplore通过专用网站（https://www.leanexplore.com/）和Python API（https://github.com/justincasher/lean-explore）提供服务，并支持数据库下载以自托管。此外，它还能与LLM集成，通过模型上下文协议（MCP）支持用户与AI助手对话或构建定理证明代理。本文详细介绍了LeanExplore的架构、数据处理、功能及其在提升Lean 4工作流和AI驱动的数学研究方面的潜力。

</details>


### [325] [Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor](https://arxiv.org/abs/2506.11107)
**中文标题：基于代码图的调谐适配器去噪编程知识追踪**

*Weibo Gao,Qi Liu,Rui Li,Yuze Zhao,Hao Wang,Linan Yre,Fangzhou Yao,Zheng Zhang*

主要分类: cs.SE

摘要简述: 本文提出了一种基于代码图的调谐适配器Coda，用于解决编程知识追踪（PKT）中的噪声问题，通过代码图识别和消除无关提交和微小修改的噪声信号，提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前PKT研究主要关注代码内容与知识评估的隐含关系，但忽略了长期编程活动中的两类噪声信号：无关提交的干扰信号和微小修改的弱信号，这限制了模型的实际应用效果。

研究方法: Coda首先将松散代码序列转换为紧凑代码图，通过语义相似性识别无关信号；然后利用聚类感知的GCN增强弱信号的区分度；最后通过噪声特征约束和导航正则化优化适配器，修正噪声影响的知识状态。

研究结果: 在四个真实数据集上的实验表明，Coda在噪声编程记录下显著优于典型基线模型，有效提升了PKT任务的性能。

研究结论: Coda是一种模型无关的框架，能够有效识别和消除编程知识追踪中的噪声信号，为个性化编程教育提供了更可靠的解决方案。

中文摘要: 编程知识追踪（PKT）旨在通过分析学习者的编程活动动态诊断其编程知识掌握水平，从而支持更高效和个性化的编程教育。然而，当前的PKT研究主要关注代码内容与知识评估的隐含关系，往往忽略了长期编程活动中的两类噪声信号：无关提交的干扰信号和微小修改的弱信号。这一实际问题显著限制了模型的性能和应用。为解决这一问题，我们提出了Coda，一种基于代码图的调谐适配器，旨在通过识别和消除噪声的影响来增强现有PKT模型。具体而言，Coda首先将每位学习者提交的松散代码序列转换为紧凑的代码图，并基于语义相似性识别无关信号。随后，我们利用聚类感知的GCN处理代码图，提升弱信号的区分度并实现其聚类识别。最后，通过优化两个基于噪声特征的约束和一个导航正则化项，将轻量且高效的适配器整合到PKT任务中，以修正受噪声影响的知识状态。值得一提的是，Coda框架是模型无关的，可适配大多数现有PKT解决方案。在四个真实数据集上的大量实验结果表明，Coda在噪声编程记录下有效执行PKT任务，性能优于典型基线模型。

</details>


### [326] [CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs](https://arxiv.org/abs/2506.11059)
**中文标题：CodeMirage：一种多语言基准测试，用于检测生产级LLM生成的AI代码和改写代码**

*Hanxi Guo,Siyuan Cheng,Kaiyuan Zhang,Guangyu Shen,Xiangyu Zhang*

主要分类: cs.SE

摘要简述: CodeMirage是一个多语言基准测试，用于检测由生产级LLM生成的AI代码和改写代码，覆盖10种编程语言和10种先进LLM，评估了10种检测器并揭示了当前技术的优缺点。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM在软件开发中的广泛应用，AI生成的代码带来了抄袭、许可证违规和安全风险等问题，亟需开发可靠的检测工具。现有基准测试覆盖语言有限且模型能力不足，因此需要更全面的基准测试。

研究方法: CodeMirage通过三个主要改进构建：1) 覆盖10种常用编程语言；2) 包含原始和改写代码样本；3) 整合6家主要提供商的10种生产级LLM输出。在此基础上，评估了10种检测器在四种实际配置下的表现。

研究结果: 分析揭示了当前检测器的九项关键发现，包括其优势和不足，并指出了未来研究的关键挑战。

研究结论: CodeMirage为开发鲁棒且通用的AI代码检测器提供了严谨且实用的测试平台。

中文摘要: 大型语言模型（LLM）已成为现代软件开发的重要组成部分，生成了大量AI源代码。尽管这些模型提升了编程效率，但其滥用也带来了代码抄袭、许可证违规和传播不安全程序等风险。因此，检测AI生成代码至关重要。为支持此类检测器的开发，需要一个反映真实场景的全面基准测试。然而，现有基准测试存在不足——大多仅覆盖有限的编程语言，且依赖能力较弱的生成模型。本文提出CodeMirage，通过三大改进解决这些问题：1) 覆盖10种常用编程语言；2) 包含原始和改写代码样本；3) 整合6家主要提供商的10种生产级LLM输出。基于CodeMirage，我们评估了10种代表性检测器在四种实际配置下的表现，并使用三种互补指标报告结果。分析揭示了九项关键发现，展示了当前检测器的优缺点，并指出了未来研究的关键挑战。CodeMirage为开发鲁棒且通用的AI代码检测器提供了严谨且实用的测试平台。

</details>


### [327] [LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](https://arxiv.org/abs/2506.11237)
**中文标题：基于LLM的自动评估方法：用于IT自动化中自然语言到Bash的无参考代码验证与优化**

*Ngoc Phuoc An Vo,Brent Paulovicks,Vadim Sheinin*

主要分类: cs.SE

摘要简述: 本文提出了一种基于LLM的自动评估方法（LLM-as-a-Judge），用于无参考的Bash代码验证与优化，以提升IT自动化中的事件修复代码质量。该方法通过双向功能匹配和逻辑表示，显著提高了评估准确性，并利用反馈机制进一步优化代码生成。


<details>
  <summary>详细信息</summary>
研究动机: 在IT自动化中，自动生成的事件修复代码需要确保语法和语义正确且可执行。传统方法（如表面相似性度量）和执行评估各有局限，因此需要一种更高效的自动评估方法。

研究方法: 采用LLM-as-a-Judge方法，结合双向功能匹配和逻辑表示，对生成的Bash代码进行无参考验证与优化。以执行评估为基准，验证LLM评估指标的准确性。

研究结果: LLM-as-a-Judge方法在评估准确性上与执行评估高度一致（最高提升8%），并通过反馈机制进一步优化代码生成（准确率提升达24%）。

研究结论: LLM-as-a-Judge方法在无参考代码验证与优化中表现出色，为IT自动化中的代码生成提供了高效且可靠的评估手段。

中文摘要: 为了自动评估并选择最佳模型，同时提升IT自动化中事件修复的代码质量，必须验证生成的修复代码在语法、语义及执行意图上的正确性。现有方法包括：1）传统表面相似性度量（如词符匹配、精确匹配等），存在诸多局限；2）基于执行的评估，关注代码功能是否通过测试用例；3）LLM-as-a-Judge方法，利用LLM根据预定义指标自动判断代码是否正确。本研究重点优化LLM-as-a-Judge方法，通过双向功能匹配和逻辑表示，实现Bash代码的无参考自动验证与优化，以选择最佳事件修复模型。我们以执行评估为基准验证LLM评估指标，结果显示其准确性高且与执行评估一致（最高提升8%）。此外，通过构建Reflection代码代理，利用评估指标的反馈显著提升了自动代码优化的准确率（最高提升24%）。

</details>


### [328] [Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing](https://arxiv.org/abs/2506.11180)
**中文标题：超越能力和技能的显式语义建模：制造业中的模型上下文协议**

*Luis Miguel Vieira da Silva,Aljosha Köcher,Felix Gehlhoff*

主要分类: cs.SE

摘要简述: 本文提出了一种基于模型上下文协议（MCP）的方法，用于替代传统的显式语义建模，使大型语言模型（LLM）能够直接访问系统功能，并在实验室规模的制造系统中进行了原型验证。


<details>
  <summary>详细信息</summary>
研究动机: 传统的基于本体论或资产管理外壳的显式语义建模方法需要大量手动工作，且难以被大型语言模型（LLM）直接利用。本文旨在探索一种更灵活的方法，通过标准化接口实现LLM驱动的工业自动化。

研究方法: 采用模型上下文协议（MCP），通过标准化接口暴露系统功能，使LLM能够直接调用资源功能。在实验室规模的制造系统中进行原型验证，测试LLM的多步骤流程规划与执行能力。

研究结果: 实验结果表明，MCP方法能够在不依赖显式语义模型的情况下，实现灵活的工业自动化，并为LLM驱动的生产系统提供外部工具集成的基础。

研究结论: MCP为LLM驱动的生产系统提供了一种无需显式语义建模的灵活解决方案，为未来进一步探索外部工具集成奠定了基础。

中文摘要: 能力和技能的显式建模——无论是基于本体论、资产管理外壳还是其他技术——需要大量手动工作，且往往难以被大型语言模型（LLM）直接利用。在这篇进展中的论文中，我们提出了一种基于最近引入的模型上下文协议（MCP）的替代方法。MCP允许系统通过标准化接口暴露功能，该接口可直接被基于LLM的代理使用。我们在实验室规模的制造系统中进行了原型验证，通过MCP提供资源功能。随后，一个通用LLM被赋予规划和执行多步骤流程的任务，包括约束处理和通过MCP调用资源功能。结果表明，这种方法可以在不依赖显式语义模型的情况下实现灵活的工业自动化。这项工作为进一步探索LLM驱动的生产系统中的外部工具集成奠定了基础。

</details>


### [329] [Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation](https://arxiv.org/abs/2506.11266)
**中文标题：基于NL2SQL数据集生成的可调用API用于LLM工具调用评估**

*Benjamin Elder,Anupama Murthi,Jungkoo Kang,Ankita Rajaram Naik,Kiran Kate,Kinjal Basu,Danish Contractor*

主要分类: cs.SE

摘要简述: 本文提出了一种从NL2SQL数据集自动生成NL2API数据集的方法，并基于BIRD-SQL数据集创建了2500多个可调用的API工具。通过评估10个公开LLM的表现，发现模型在工具调用任务中表现不佳，任务完成率仅为7-47%，即使采用ReACT代理也仅提升至50%。研究表明当前工具调用LLM仍有较大改进空间。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）常被部署为代理系统，需与复杂API集合交互完成任务。企业环境中API通常基于数据库且规模庞大。为创建此类数据集，研究探索如何利用现有NL2SQL数据集自动生成NL2API数据集。

研究方法: 研究提出了一种新颖的数据生成流程，利用SQL查询语法构建功能等效的API调用序列。将此流程应用于BIRD-SQL数据集，生成了2500多个可调用的API工具，并将自然语言查询与API序列配对。随后评估了10个公开LLM在工具调用任务中的表现。

研究结果: 所有模型在工具调用任务中表现较差，任务完成率仅为7-47%。采用ReACT代理后，完成率提升至50%，但仍远低于实际需求。模型在SQL生成任务中表现优于API调用任务。

研究结论: 当前工具调用LLM的任务完成率较低，表明其在实际应用中仍有显著改进空间。研究还通过消融实验分析了工具数量和名称混淆对模型性能的影响。

中文摘要: 大型语言模型（LLM）通常被部署为代理系统，能够通过工具与实时环境交互完成任务。在企业部署中，这些系统需要与可能极其庞大且复杂的API集合交互，这些API通常基于数据库。为创建具有此类特征的数据集，我们探索了如何利用现有NL2SQL（自然语言到SQL查询）数据集自动生成NL2API数据集。具体而言，本研究描述了一种新颖的数据生成流程，利用SQL查询的语法构建功能等效的API调用序列。我们将此流程应用于最大的NL2SQL数据集之一BIRD-SQL，创建了2500多个可调用的API工具或REST端点。我们将BIRD-SQL中的自然语言查询与基于此API池的真实API序列配对。利用这一集合，我们研究了10个公开LLM的表现，发现所有模型在确定正确的工具集（包括意图检测、嵌套函数调用排序和槽填充任务）方面均表现不佳。模型的任务完成率极低（7-47%，具体取决于数据集），即使采用与实时API环境交互的ReACT代理，也仅提升至50%。最佳任务完成率远低于有效通用工具调用代理的需求，表明当前最先进的工具调用LLM仍有显著改进空间。我们还进行了详细的消融研究，例如评估可用工具数量以及工具和槽名称混淆的影响。我们比较了模型在原始SQL生成任务中的表现，发现当前模型有时能更好地利用SQL而非API。

</details>


### [330] [A Tale of Two Systems: Characterizing Architectural Complexity on Machine Learning-Enabled Systems](https://arxiv.org/abs/2506.11295)
**中文标题：两个系统的故事：机器学习赋能系统的架构复杂性表征**

*Renato Cordeiro Ferreira*

主要分类: cs.SE

摘要简述: 本文研究了机器学习赋能系统（MLES）的复杂性管理问题，提出了一种基于指标的架构模型，并通过SPIRA和Ocean Guard两个系统的案例研究验证了该模型的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习赋能系统（MLES）的复杂性日益增加，如何有效管理这种复杂性成为关键问题。本文旨在通过量化分析MLES的架构复杂性，为系统设计和扩展提供指导。

研究方法: 研究引入了一种基于指标的架构模型，用于表征MLES的复杂性，并通过SPIRA和Ocean Guard两个实际系统的架构案例进行验证和分析。

研究结果: 研究结果表明，提出的指标模型能够有效量化MLES的复杂性，并为系统架构决策提供支持。两个案例研究验证了模型的适用性和实用性。

研究结论: 本文提出的基于指标的架构模型为MLES的复杂性管理提供了有效工具，有助于系统设计和扩展的决策制定。

中文摘要: 如何有效管理机器学习赋能系统（MLES）的复杂性？本研究旨在探讨复杂性对MLES的影响，并引入一种基于指标的架构模型来表征MLES的复杂性，以支持架构决策，为系统的初始设计和扩展提供指导。本文通过SPIRA和Ocean Guard两个系统的架构案例研究，展示了该模型的创建过程。

</details>


### [331] [LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?](https://arxiv.org/abs/2506.11928)
**中文标题：LiveCodeBench Pro：竞赛编程中奥赛奖牌得主如何评价大语言模型？**

*Zihan Zheng,Zerui Cheng,Zeyu Shen,Shang Zhou,Kaiyuan Liu,Hansen He,Dongruixuan Li,Stanley Wei,Hangyi Hao,Jianzhu Yao,Peiyao Sheng,Zixuan Wang,Wenhao Chai,Aleksandra Korolova,Peter Henderson,Sanjeev Arora,Pramod Viswanath,Jingbo Shang,Saining Xie*

主要分类: cs.SE

摘要简述: 研究发现，尽管大语言模型（LLMs）在竞赛编程中表现优异，但与人类专家相比仍存在显著差距，尤其是在复杂算法推理和案例分析方面。LiveCodeBench Pro基准测试揭示了LLMs的局限性，并提供了改进方向。


<details>
  <summary>详细信息</summary>
研究动机: 近期有报告称LLMs在竞赛编程中已超越人类精英。本文通过国际算法竞赛奖牌得主的视角，重新审视这一说法，探讨LLMs与人类专家的差异及其局限性。

研究方法: 研究团队引入LiveCodeBench Pro基准测试，包含来自Codeforces、ICPC和IOI的动态更新题目，并由奖牌得主标注算法类别并逐行分析模型生成的失败提交。

研究结果: 前沿模型在中等难度题目上的通过率为53%，而难题通过率为0%，远低于人类专家水平。LLMs擅长实现密集型问题，但在复杂算法推理和案例分析中表现不佳。

研究结论: LiveCodeBench Pro揭示了LLMs与人类大师水平的显著差距，并为未来代码中心化LLM推理的改进提供了细粒度诊断。

中文摘要: 近期报告称大语言模型（LLMs）在竞赛编程中已超越人类精英。本文通过国际算法竞赛奖牌得主的视角，重新审视这一说法，探讨LLMs与人类专家的差异及其局限性。我们引入LiveCodeBench Pro基准测试，包含来自Codeforces、ICPC和IOI的动态更新题目，以减少数据污染的可能性。奖牌得主团队为每道题目标注算法类别，并对模型生成的失败提交进行逐行分析。基于新数据和基准测试，我们发现前沿模型仍存在显著局限性：在没有外部工具的情况下，最佳模型在中等难度题目上的通过率为53%，而难题通过率为0%，这些领域人类专家仍占优势。我们还发现，LLMs擅长实现密集型问题，但在复杂算法推理和案例分析中表现不佳，常生成自信但错误的解释。高性能主要依赖于实现精度和工具增强，而非卓越的推理能力。LiveCodeBench Pro因此凸显了与人类大师水平的显著差距，同时为未来代码中心化LLM推理的改进提供了细粒度诊断。

</details>


### [332] [Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation](https://arxiv.org/abs/2506.11559)
**中文标题：利用GPT-4生成漏洞见证单元测试**

*Gábor Antal,Dénes Bán,Martin Isztin,Rudolf Ferenc,Péter Hegedűs*

主要分类: cs.SE

摘要简述: 本文探讨了利用GPT-4自动生成漏洞见证单元测试的能力，结果表明GPT-4能够生成语法正确的测试用例，并在部分自动化测试生成中发挥重要作用。


<details>
  <summary>详细信息</summary>
研究动机: 在软件开发周期中，测试对质量保障至关重要，但手动生成测试用例复杂且耗时。本文旨在探索GPT-4在自动生成漏洞见证单元测试中的潜力，以帮助开发者和安全专家。

研究方法: 研究使用GPT-4基于VUL4J数据集中的真实漏洞及其修复代码生成单元测试，分析代码上下文的影响、GPT-4的自校正能力及生成测试用例的实用性。

研究结果: GPT-4在66.5%的情况下能生成语法正确的测试用例，但语义正确性仅能自动验证7.5%。主观评估显示，生成的测试模板可进一步开发为功能完整的漏洞见证测试。

研究结论: 尽管数据有限，但GPT-4在漏洞见证测试生成中具有显著作用，可作为部分自动化流程的重要工具。

中文摘要: 在软件开发生命周期中，测试在质量保障中扮演关键角色。适当的测试不仅能提高代码覆盖率并防止回归问题，还能确保软件中的潜在漏洞被识别并有效修复。然而，手动创建此类测试是一个复杂且资源密集的过程。为帮助开发者和安全专家，本文从漏洞角度探索了广泛使用的大型语言模型GPT-4的自动单元测试生成能力。我们研究了包含真实漏洞及其修复代码的VUL4J数据集子集，以确定GPT-4是否能基于修复前后的代码生成语法和/或语义正确的单元测试，作为漏洞缓解的证据。我们重点关注代码上下文的影响、GPT-4自校正能力的有效性以及生成测试用例的主观实用性。结果表明，GPT-4在无领域预训练的情况下，66.5%的时间能生成语法正确的测试用例。尽管修复的语义正确性仅能自动验证7.5%的案例，但主观评估显示，GPT-4生成的测试模板可通过较少手动工作进一步开发为功能完整的漏洞见证测试。因此，尽管数据有限，我们的初步发现表明，GPT-4可有效用于生成漏洞见证测试。它可能无法完全自主运行，但在部分自动化流程中发挥了重要作用。

</details>


### [333] [Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study](https://arxiv.org/abs/2506.11561)
**中文标题：识别有助于基于LLM的漏洞修复的上下文：一项初步研究**

*Gábor Antal,Bence Bogenfürst,Rudolf Ferenc,Péter Hegedűs*

主要分类: cs.SE

摘要简述: 本文研究了GPT-4o在修复Java漏洞中的表现，探讨了不同上下文信息对自动漏洞修复能力的影响。结果显示，GPT-4o在相同提示下表现略逊于GPT-4，但通过结合CVE信息和手动提取的代码上下文，修复率显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，大型语言模型（LLMs）在自动化漏洞检测和修复方面展现出潜力。本文旨在探索GPT-4o在修复Java漏洞中的表现，并研究不同上下文信息如何影响其修复能力。

研究方法: 研究使用Vul4J数据集，比较了GPT-4o与GPT-4在相同提示下的表现。设计了9种包含不同上下文信息（如CWE、CVE和手动提取的代码上下文）的提示，并在42个漏洞上各执行3次。修复结果通过Vul4J的自动化测试框架验证。

研究结果: GPT-4o在相同提示下平均表现比GPT-4低11.9%，但修复了更多独特漏洞（10.5%）。CVE信息显著提升修复率，而任务描述长度影响较小。结合CVE和手动提取的代码上下文效果最佳，修复了62%的漏洞。

研究结论: 研究表明，结合CVE信息和手动提取的代码上下文能显著提升GPT-4o的漏洞修复能力。提示策略的多样性（如Top-3提示组合）在零样本设置下效果更佳。

中文摘要: 近年来，大型语言模型（LLMs）在自动化软件系统漏洞检测和修复方面展现出潜力。本文研究了GPT-4o在修复Java漏洞（来自广泛使用的Vul4J数据集）中的表现，探讨了不同上下文信息对自动漏洞修复（AVR）能力的影响。我们比较了GPT-4o与GPT-4在相同提示下的表现，并评估了9种额外设计的提示（包含CWE或CVE信息及手动提取的代码上下文）。每种提示在42个漏洞上执行3次，修复结果通过Vul4J的自动化测试框架验证。结果显示，GPT-4o在相同提示下平均表现比GPT-4低11.9%，但修复了10.5%更多的独特漏洞。CVE信息显著提升修复率，而任务描述长度影响较小。结合CVE和手动提取的代码上下文效果最佳。使用Top-3提示组合，GPT-4o修复了62%的漏洞，优于原始基线（40%）及其复现结果（45%），表明提示策略的多样性可提升零样本设置下的漏洞修复能力。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [334] [PMF-CEC: Phoneme-augmented Multimodal Fusion for Context-aware ASR Error Correction with Error-specific Selective Decoding](https://arxiv.org/abs/2506.11064)
**中文标题：PMF-CEC：基于音素增强的多模态融合用于上下文感知的ASR错误纠正与错误特定选择性解码**

*Jiajun He,Tomoki Toda*

主要分类: eess.AS

摘要简述: 本文提出了一种名为PMF-CEC的语音增强多模态融合方法，用于上下文感知的ASR错误纠正，通过音素增强和选择性解码机制，显著提升了罕见词和同音词的纠正效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的ED-CEC方法在纠正发音相似但拼写不同的罕见词时效果不佳，且存在错误检测过度的问题。本文旨在通过音素增强和选择性解码机制，提升ASR对罕见词和同音词的纠正能力。

研究方法: 在ED-CEC基础上，提出了PMF-CEC方法，通过音素增强多模态融合技术区分目标罕见词和同音词，并引入保留概率机制过滤低置信度的编辑操作，提高错误检测的准确性。

研究结果: 在五个数据集上的实验表明，PMF-CEC在保持合理推理速度的同时，进一步降低了有偏词错误率，尤其在纠正同音词方面表现更优，且优于其他上下文偏置方法。

研究结论: PMF-CEC通过音素增强和选择性解码机制，显著提升了ASR对罕见词和同音词的纠正能力，同时保持了较快的推理速度和鲁棒性。

中文摘要: 端到端自动语音识别（ASR）模型在识别罕见词时往往表现不佳。此前，我们提出了一种名为错误检测与上下文感知错误纠正（ED-CEC）的ASR后处理方法，通过利用命名实体和技术术语等上下文信息来提升ASR转录的准确性。尽管ED-CEC在纠正罕见词方面取得了显著成功，但在处理发音相似但拼写不同的罕见词时，其准确性仍然较低。为解决这一问题，我们在ED-CEC基础上提出了音素增强多模态融合的上下文感知错误纠正方法（PMF-CEC），能够更好地区分目标罕见词和同音词。此外，我们发现之前的ASR错误检测模块存在过度检测的问题。为此，我们引入了保留概率机制，过滤掉置信度低于设定阈值的编辑操作，保留原始操作以提高错误检测的准确性。在五个数据集上的实验表明，与ED-CEC相比，我们提出的PMF-CEC在保持合理推理速度的同时，进一步降低了有偏词错误率，并在纠正同音词方面表现出更强的优势。此外，我们的方法优于其他上下文偏置方法，并且在推理速度和大型偏置列表下的鲁棒性方面，仍优于基于LLM的方法。

</details>


### [335] [Regularized Federated Learning for Privacy-Preserving Dysarthric and Elderly Speech Recognition](https://arxiv.org/abs/2506.11069)
**中文标题：正则化联邦学习用于隐私保护的构音障碍与老年语音识别**

*Tao Zhong,Mengzhe Geng,Shujie Hu,Guinan Li,Xunying Liu*

主要分类: eess.AS

摘要简述: 本文研究了正则化联邦学习（FL）在隐私保护的构音障碍和老年语音识别中的应用，通过参数、嵌入和新型损失正则化方法，显著降低了词错误率（WER），并接近集中式训练性能。


<details>
  <summary>详细信息</summary>
研究动机: 构音障碍和老年语音识别的准确性仍具挑战性，而隐私问题促使从集中式方法转向联邦学习（FL），但FL加剧了数据稀缺、分布不均和说话者异质性等问题。本文旨在通过正则化FL技术解决这些问题。

研究方法: 本文提出三种正则化FL方法：1) 基于参数的正则化；2) 基于嵌入的正则化；3) 新型基于损失的正则化。这些方法在FL过程中不同层次进行优化，以提升模型性能。

研究结果: 实验表明，正则化FL系统在UASpeech构音障碍和DementiaBank Pitt老年语音数据集上显著优于基线FedAvg系统，WER绝对降低0.55%（相对降低2.13%）。增加通信频率后，性能接近集中式训练。

研究结论: 正则化FL技术有效提升了隐私保护的构音障碍和老年语音识别性能，同时解决了FL中的数据挑战，为实际应用提供了可行方案。

中文摘要: 构音障碍和老年语音的准确识别至今仍具挑战性。尽管隐私问题促使从集中式方法转向联邦学习（FL）以确保数据保密性，但这进一步加剧了数据稀缺、分布不均和说话者异质性等问题。为此，本文系统研究了正则化FL技术在隐私保护的构音障碍和老年语音识别中的应用，通过1) 基于参数、2) 基于嵌入和3) 新型基于损失的正则化方法，在FL过程的不同层次进行优化。在UASpeech构音障碍和DementiaBank Pitt老年语音数据集上的实验表明，正则化FL系统显著优于基线FedAvg系统，WER绝对降低0.55%（相对降低2.13%）。进一步将通信频率提高到每批次交换一次时，性能接近集中式训练。

</details>


### [336] [Embedded Acoustic Intelligence for Automotive Systems](https://arxiv.org/abs/2506.11071)
**中文标题：嵌入式声学智能在汽车系统中的应用**

*Renjith Rajagopal,Peter Winzell,Sladjana Strbac,Konstantin Lindström,Petter Hörling,Faisal Kohestani,Niloofar Mehrzad*

主要分类: eess.AS

摘要简述: 通过分析车辆轮毂安装的麦克风采集的声学特征，利用深度神经网络和预训练模型分类道路类型，提升自动驾驶系统智能，改善乘客舒适度和道路管理。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过声学智能提升汽车系统的智能化水平，解决道路类型分类问题，从而优化自动驾驶和高级驾驶辅助系统（AD/ADAS）的性能，并为城市规划和道路噪声消除提供支持。

研究方法: 在车辆轮毂安装麦克风采集声学特征，利用深度神经网络和Open AI生态系统的预训练模型（通过Hugging Face）进行特征提取和道路类型分类。

研究结果: 研究表明，该方法能够有效分类道路类型，支持自适应学习和主动道路噪声消除，并为城市规划和下一代汽车系统提供了有价值的商业案例。

研究结论: 该前瞻性方法不仅提升了乘客舒适度和车辆安全性，还为智能数据驱动的城市道路管理奠定了基础，推动了可持续交通的未来发展。

中文摘要: 通过将声音洞察转化为可操作的数据流，本研究基于学位论文的发现，旨在提升汽车系统的智能化水平，以解决道路类型分类问题。通过在车辆轮毂安装麦克风采集并解析声学特征，我们专注于道路类型的分类。利用深度神经网络和Open AI生态系统（通过Hugging Face）的预训练模型进行特征提取，我们的方法使自动驾驶和高级驾驶辅助系统（AD/ADAS）能够预测道路表面，支持自适应学习以实现主动道路噪声消除，并为城市规划提供有价值的见解。本研究的结果专门用于支持下一代汽车系统的商业案例。这一前瞻性方法不仅有望重新定义乘客舒适度和提升车辆安全性，还为智能数据驱动的城市道路管理铺平了道路，使未来的交通既可行又可持续。

</details>


### [337] [Improving Child Speech Recognition and Reading Mistake Detection by Using Prompts](https://arxiv.org/abs/2506.11079)
**中文标题：利用提示改进儿童语音识别与阅读错误检测**

*Lingyun Gao,Cristian Tejedor-Garcia,Catia Cucchiarini,Helmer Strik*

主要分类: eess.AS

摘要简述: 本文提出了一种利用提示改进Whisper和指令调优大语言模型（LLM）的方法，显著提升了儿童语音识别和阅读错误检测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 自动朗读评估系统可以为教师提供高效评分支持，但目前相关研究和应用有限。本文旨在探索如何通过多模态方法（结合音频和文本资源）提升儿童语音识别和阅读错误检测的性能。

研究方法: 采用Whisper和指令调优的大语言模型（LLM），结合提示技术，改进儿童语音识别和阅读错误检测。通过多模态方法整合音频和文本资源。

研究结果: 最佳系统在荷兰儿童朗读语音识别中实现了5.1%的词错误率（WER），显著优于基线模型的9.4%。阅读错误检测的F1分数从0.39提升至0.73。

研究结论: 提示技术显著提升了Whisper和LLM在儿童语音识别和阅读错误检测中的性能，为自动朗读评估系统提供了更高效的解决方案。

中文摘要: 自动朗读评估可以为教师提供高效评分支持，但目前相关研究和应用仍有限。本文提出了一种新颖的多模态方法，结合音频和文本资源。特别地，我们探索了利用Whisper和指令调优的大语言模型（LLM）通过提示技术改进儿童语音识别的转录效果，以及其在阅读错误检测中的有效性。结果表明，与未使用提示的基线Whisper模型相比，提示Whisper和提示LLM的方法显著提升了性能。最佳系统在荷兰儿童朗读语音识别中实现了5.1%的词错误率（WER），优于基线模型的9.4%。此外，阅读错误检测的F1分数从0.39提升至0.73。

</details>


### [338] [Intelligibility of Text-to-Speech Systems for Mathematical Expressions](https://arxiv.org/abs/2506.11086)
**中文标题：文本转语音系统对数学表达式的可理解性研究**

*Sujoy Roychowdhury,H. G. Ranjani,Sumit Soman,Nishtha Paul,Subhadip Bandyopadhyay,Siddhanth Iyengar*

主要分类: eess.AS

摘要简述: 本文评估了五种文本转语音（TTS）模型对数学表达式的可理解性，发现其输出并不完全可理解，且性能显著低于专家朗读。


<details>
  <summary>详细信息</summary>
研究动机: 目前对高级文本转语音（TTS）模型处理数学表达式（MX）的可理解性研究有限，本文旨在填补这一空白。

研究方法: 通过听写测试和用户评分（平均意见分数）评估五种TTS模型的可理解性，使用大型语言模型（LLM）将LaTeX MX转换为英语发音，并比较TTS输出与专家朗读的表现。

研究结果: TTS模型对数学表达式的输出不完全可理解，不同模型和表达式类别的表现差异显著，且多数情况下TTS性能远低于专家朗读。LLM的选择影响有限。

研究结论: 研究表明，当前TTS模型对数学表达式的处理能力有待提升，需进一步改进以提高可理解性。

中文摘要: 目前对高级文本转语音（TTS）模型处理数学表达式（MX）的可理解性研究较少。本文通过听写测试和用户评分（平均意见分数）评估了五种TTS模型的质量和可理解性，涵盖多种MX类别。由于TTS模型无法直接处理LaTeX，我们使用两种大型语言模型（LLM）将LaTeX MX转换为英语发音。通过用户评分和转录正确性的三个指标量化可理解性，并比较TTS输出与专家朗读的表现。结果表明，TTS模型对MX的输出并不完全可理解，且不同模型和MX类别的表现差异显著。在大多数类别中，TTS模型的性能显著低于专家朗读。LLM的选择影响有限。这表明需要改进TTS模型对MX的处理能力。

</details>


### [339] [Better Pseudo-labeling with Multi-ASR Fusion and Error Correction by SpeechLLM](https://arxiv.org/abs/2506.11089)
**中文标题：基于多ASR融合与语音LLM错误校正的改进伪标签生成方法**

*Jeena Prakash,Blessingh Kumar,Kadri Hacioglu,Bidisha Sharma,Sindhuja Gopalan,Malolan Chetlur,Shankar Venkatesan,Andreas Stolcke*

主要分类: eess.AS

摘要简述: 本文提出了一种基于多ASR融合和语音LLM错误校正的统一框架，显著提升了伪标签生成和半监督ASR模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统伪标签生成方法依赖复杂的多阶段处理流程，导致错误传播和信息丢失。本文旨在通过多ASR融合和语音LLM后处理，简化流程并提升转录准确性。

研究方法: 提出了一种统一的多ASR提示驱动框架，利用文本或语音大语言模型（LLM）进行后处理，替代传统的投票或仲裁逻辑。比较了多种架构（含/不含LLM）的性能。

研究结果: 实验表明，与传统方法相比，文本和语音LLM转录显著提升了转录准确性。生成的伪标签进一步改善了半监督ASR模型的性能。

研究结论: 多ASR融合与语音LLM错误校正的统一框架有效提升了伪标签质量和ASR模型性能，为半监督学习提供了新思路。

中文摘要: 自动语音识别（ASR）模型依赖高质量转录数据进行有效训练。为大规模未标记音频数据集生成伪标签通常依赖于复杂的多阶段处理流程，导致错误传播、信息丢失和优化不连贯。我们提出了一种统一的多ASR提示驱动框架，利用文本或语音大语言模型（LLM）进行后处理，替代传统的投票或仲裁逻辑。通过比较多种架构（含/不含LLM），结果显示转录准确性显著优于传统方法。此外，利用不同方法生成的伪标签训练半监督ASR模型，文本和语音LLM转录再次表现出优于基线的性能。

</details>


### [340] [Can We Trust Machine Learning? The Reliability of Features from Open-Source Speech Analysis Tools for Speech Modeling](https://arxiv.org/abs/2506.11072)
**中文标题：我们能信任机器学习吗？开源语音分析工具提取的特征在语音建模中的可靠性**

*Tahiya Chowdhury,Veronica Romero*

主要分类: eess.AS

摘要简述: 研究评估了开源语音分析工具（OpenSMILE和Praat）提取的语音特征在自闭症青少年群体中的可靠性，发现特征存在显著差异，影响模型性能，呼吁加强领域相关验证以提高临床应用的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习模型依赖开源工具提取的语音特征，但这些工具缺乏验证，可能导致跨群体和场景的偏见与不可靠性。研究旨在评估这些工具在自闭症青少年中的可靠性。

研究方法: 研究使用OpenSMILE和Praat两种广泛使用的语音分析工具，提取自闭症青少年的语音特征，并分析其在不同工具间的差异及其对模型性能的影响。

研究结果: 发现不同工具提取的特征存在显著差异，这些差异影响了模型在不同背景和人口群体中的表现。

研究结论: 研究呼吁加强领域相关验证，以提高机器学习模型在临床应用中的可靠性，减少偏见。

中文摘要: 基于机器学习的行为模型依赖于从音视频记录中提取的特征。这些记录通过开源工具处理以提取语音特征用于分类模型。然而，这些工具通常缺乏验证，无法确保其在捕捉行为相关信息时的可靠性。这一缺陷引发了关于跨多样群体和场景的可重复性和公平性的担忧。语音处理工具若在其设计背景之外使用，可能无法公平捕捉行为变化，进而导致偏见。我们评估了两种广泛使用的语音分析工具（OpenSMILE和Praat）提取的语音特征，以考察其在自闭症青少年群体中的可靠性。我们发现不同工具提取的特征存在显著差异，这些差异影响了模型在不同背景和人口群体中的表现。我们呼吁加强领域相关验证，以提高机器学习模型在临床应用中的可靠性。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [341] [FeNN: A RISC-V vector processor for Spiking Neural Network acceleration](https://arxiv.org/abs/2506.11760)
**中文标题：FeNN：一种用于脉冲神经网络加速的RISC-V向量处理器**

*Zainab Aizaz,James C. Knight,Thomas Nowotny*

主要分类: cs.NE

摘要简述: 本文提出了一种基于RISC-V的软向量处理器FeNN，专为在FPGA上模拟脉冲神经网络（SNN）设计，具有高数值精度和低硬件利用率，性能优于嵌入式GPU和Loihi神经形态系统。


<details>
  <summary>详细信息</summary>
研究动机: 脉冲神经网络（SNN）能显著降低AI系统的能耗，但主流加速器（如GPU和TPU）因其高算术强度不适合SNN模拟。FPGA因其高片外内存带宽和大容量片上内存，更适合低算术强度的应用。因此，需要一种专为SNN设计的可编程硬件解决方案。

研究方法: 作者设计了一种基于RISC-V的软向量处理器FeNN，专为FPGA上的SNN模拟优化。通过使用随机舍入和饱和技术，实现了高数值精度和低硬件利用率。FeNN完全可编程，并能与从边缘到云端的标准计算机应用集成。

研究结果: 实验表明，单个FeNN核心在模拟SNN分类器时，性能优于嵌入式GPU和Loihi神经形态系统，同时保持了高数值精度和低硬件利用率。

研究结论: FeNN为SNN模拟提供了一种高效、可编程的硬件解决方案，适用于从边缘到云端的广泛场景，性能优于现有加速器。

中文摘要: 脉冲神经网络（SNN）有潜力大幅降低AI系统的能耗。然而，主流加速器（如GPU和TPU）专为传统人工神经网络（ANN）的高算术强度设计，不适合SNN模拟。FPGA因其高片外内存带宽和大容量片上内存，更适合低算术强度的应用。本文提出了一种基于RISC-V的软向量处理器（FeNN），专为在FPGA上模拟SNN设计。与大多数专用神经形态硬件不同，FeNN完全可编程，并能与从边缘到云端的标准计算机应用集成。通过使用随机舍入和饱和技术，FeNN能以低硬件利用率实现高数值精度。实验表明，单个FeNN核心在模拟SNN分类器时，性能优于嵌入式GPU和Loihi神经形态系统。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [342] [How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?](https://arxiv.org/abs/2506.11869)
**中文标题：概率图模型与图神经网络如何看待网络数据？**

*Michela Lapenna,Caterina De Bacco*

主要分类: stat.ML

摘要简述: 本文通过链接预测任务比较了概率图模型（PGMs）和图神经网络（GNNs）在网络数据上的表现，发现PGMs在低维或噪声特征下优于GNNs，且对图的异质性更鲁棒。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于比较PGMs和GNNs在网络数据中捕捉信息的能力差异，尤其是在输入特征、噪声和异质性方面的表现。

研究方法: 方法包括通过链接预测任务进行三个实验：一是比较PGMs和GNNs对输入特征的处理能力，二是测试其对噪声特征的鲁棒性，三是分析其对图异质性增加的适应性。

研究结果: 结果显示，PGMs在低维或噪声特征下表现优于GNNs，且对图的异质性更鲁棒。此外，PGMs在计算复杂性和可解释性方面也更具优势。

研究结论: 结论表明，PGMs在特定场景（如低维或噪声特征、高异质性图）中优于GNNs，但在实际应用中需根据任务需求选择合适的模型。

中文摘要: 图是一种强大的数据结构，用于表示关系数据，并广泛用于描述复杂的现实系统。概率图模型（PGMs）和图神经网络（GNNs）均可利用图结构数据，但其内在机制不同。问题在于它们如何比较在网络数据集中捕捉信息的能力？我们通过解决链接预测任务来实现这一目标，并在合成和真实网络上进行了三个主要实验：一个关注PGMs和GNNs如何处理输入特征，另外两个研究其对噪声特征和图中异质性增加的鲁棒性。PGMs不一定需要节点特征，而GNNs无法仅利用网络边，输入特征的选择至关重要。我们发现，当输入特征是低维或噪声时（模拟许多现实场景中节点属性可能是标量或噪声的情况），GNNs的表现不如PGMs。此外，当图的异质性增加时，PGMs比GNNs更鲁棒。最后，为了评估预测任务之外的性能，我们还比较了两种框架在计算复杂性和可解释性方面的表现。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [343] [Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving](https://arxiv.org/abs/2506.11234)
**中文标题：Poutine：视觉-语言-轨迹预训练与强化学习后训练实现鲁棒的端到端自动驾驶**

*Luke Rowe,Rodrigue de Schaetzen,Roger Girgis,Christopher Pal,Liam Paull*

主要分类: cs.RO

摘要简述: Poutine是一种专为端到端自动驾驶设计的30亿参数视觉语言模型，通过两阶段训练（自监督预训练和强化学习微调）在长尾驾驶场景中表现优异，最终在Waymo挑战赛中取得第一。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决长尾驾驶场景中端到端自动驾驶的鲁棒性问题，通过结合视觉-语言-轨迹预训练和强化学习微调，提升模型在复杂环境中的表现。

研究方法: Poutine采用两阶段训练：1）自监督视觉-语言-轨迹预训练（Poutine-Base）；2）使用Group Relative Policy Optimization（GRPO）对预训练模型进行强化学习微调，仅需少量标注数据。

研究结果: Poutine-Base在验证集上获得8.12的评分，接近Waymo专家水平；最终模型在Waymo测试集上评分7.99，显著领先于其他参赛模型。

研究结论: 研究表明，视觉-语言-轨迹预训练结合轻量级强化学习微调是实现鲁棒且通用自动驾驶的有效方法。

中文摘要: 我们提出了Poutine，一种专为端到端自动驾驶设计的30亿参数视觉语言模型（VLM），适用于长尾驾驶场景。Poutine分为两阶段训练：首先，通过自监督视觉-语言-轨迹（VLT）下一标记预测方式训练Poutine-Base，使用83小时CoVLA常规驾驶和11小时Waymo长尾驾驶数据，并借助72亿参数VLM自动生成语言标注；其次，通过Group Relative Policy Optimization（GRPO）对Poutine-Base进行微调，仅需不到500帧Waymo验证集的偏好标注数据。实验表明，VLT预训练和强化学习微调对长尾场景中的驾驶性能至关重要。Poutine-Base在验证集上获得8.12的评分（RFS），接近Waymo专家水平；最终Poutine模型在Waymo测试集上评分7.99，以显著优势获得2025年Waymo视觉端到端驾驶挑战赛第一名。这些结果证明了可扩展的VLT预训练与轻量级强化学习微调在实现鲁棒且通用自动驾驶中的潜力。

</details>


### [344] [Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation](https://arxiv.org/abs/2506.11261)
**中文标题：Gondola：基于视觉语言规划的可泛化机器人操作**

*Shizhe Chen,Ricardo Garcia,Paul Pacaud,Cordelia Schmid*

主要分类: cs.RO

摘要简述: 本文提出Gondola模型，通过多视角图像和历史计划生成机器人操作的下一个动作计划，显著提升了在未见对象、环境和任务中的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 机器人操作在面对多样语言指令指定的未见对象、环境和任务时泛化能力不足，现有基于大语言模型的方法在视觉环境中生成接地气的计划方面表现不佳。

研究方法: Gondola是一种基于大语言模型的视觉-语言规划模型，利用多视角图像和历史计划生成包含目标对象和位置分割掩码的动作计划，并通过RLBench模拟器构建三类数据集支持训练。

研究结果: Gondola在GemBench数据集的四个泛化级别（新放置、刚性物体、铰接物体和长时任务）上均优于现有基于大语言模型的方法。

研究结论: Gondola通过多视角输入和分割掩码显著提升了机器人操作的泛化能力，为未来研究提供了新方向。

中文摘要: 机器人操作在面对由多样语言指令指定的未见对象、环境和任务时，泛化能力面临重大挑战。为提高泛化能力，近期研究引入了大语言模型（LLMs）进行规划和动作执行。尽管前景广阔，这些方法在视觉环境中生成接地气的计划方面仍显不足。尽管已有研究尝试对大语言模型进行视觉指令调优以用于机器人操作，但现有方法通常受限于单视角图像输入，且难以实现精确的对象接地。本文提出Gondola，一种基于大语言模型的新型视觉-语言规划模型，用于可泛化的机器人操作。Gondola通过多视角图像和历史计划生成包含目标对象和位置分割掩码的下一个动作计划。为支持Gondola的训练，我们利用RLBench模拟器构建了三类数据集，包括机器人接地规划、多视角指代表达和伪长时任务数据集。Gondola在GemBench数据集的四个泛化级别（新放置、刚性物体、铰接物体和长时任务）上均优于现有基于大语言模型的方法。

</details>


### [345] [Control Architecture and Design for a Multi-robotic Visual Servoing System in Automated Manufacturing Environment](https://arxiv.org/abs/2506.11387)
**中文标题：自动化制造环境中多机器人视觉伺服系统的控制架构与设计**

*Rongfei Li*

主要分类: cs.RO

摘要简述: 本文提出了一种多机器人视觉伺服控制系统，用于自动化制造环境中的高精度任务，并通过优化相机位置策略减少图像噪声。


<details>
  <summary>详细信息</summary>
研究动机: 尽管现代机器人技术已显著提升，但在微尺度制造等高精度任务中，人类仍凭借感官优势超越机器。制造环境中的不确定性（如测量噪声、模型不准确等）需要通过控制算法和传感器优化来减少。本文旨在通过多机器人控制系统和相机位置优化，降低这些不确定性。

研究方法: 设计了一种多机器人控制系统，模拟紧固和松开应用中的定位过程；提出了一种新颖的相机移动策略算法，探索相机工作空间以找到图像噪声最小的最优位置。

研究结果: 多机器人控制系统显著减少了制造任务中的不确定性；相机位置优化算法有效降低了图像噪声水平。

研究结论: 本文的控制系统和相机位置优化算法为自动化制造环境中的高精度任务提供了经济高效的解决方案，同时填补了视觉伺服研究中相机位置重要性探讨的空白。

中文摘要: 21世纪，机器人技术在制造业中的应用大幅增长。然而，在微尺度制造等高精度任务中，人类仍凭借感官线索优于机器。这些感官线索能够自然补偿制造环境中的高度不确定性。制造任务中的不确定性可能源于测量噪声、模型不准确、关节柔顺性（如弹性）等。尽管现代机器人采用先进的计量传感器和高精度微处理器，补偿了许多结构和动态误差，但设计良好的控制算法仍是一种经济高效的替代方案，可减少自动化制造中的不确定性。我们的研究表明，模拟紧固和松开应用定位过程的多机器人控制系统能够大幅减少该过程中可能出现的各种不确定性。此外，大多数视觉伺服研究主要关注不同场景下的控制和观测架构开发，但很少讨论相机位置在配置中的重要性。在制造环境中，相机估计的质量会因观测位置的不同而显著变化，因为环境条件的综合影响导致单张图像在不同位置的噪声水平不同。因此，本文还提出了一种新颖的相机移动策略算法，探索相机工作空间并寻找图像噪声水平最小的最优位置。

</details>


### [346] [Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis](https://arxiv.org/abs/2506.11526)
**中文标题：基础模型在自动驾驶中的应用：场景生成与场景分析综述**

*Yuan Gao,Mattia Piccinini,Yuchen Zhang,Dingrui Wang,Korbinian Moller,Roberto Brusnicki,Baha Zarrouki,Alessio Gambi,Jan Frederik Totz,Kai Storms,Steven Peters,Andrea Stocco,Bassam Alrifaee,Marco Pavone,Johannes Betz*

主要分类: cs.RO

摘要简述: 本文综述了基础模型在自动驾驶场景生成与分析中的应用，探讨了多种模型（如大语言模型、视觉语言模型等）的方法、数据集、评估指标及未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶系统在复杂环境中的安全导航依赖于处理多样且罕见的驾驶场景。传统场景生成方法多样性有限且难以模拟真实安全关键场景，而基础模型的出现为解决这一问题提供了新思路。

研究方法: 本文通过系统调研，提出了一种统一的分类法，涵盖大语言模型、视觉语言模型、多模态大语言模型、扩散模型和世界模型，并回顾了相关方法、开源数据集、仿真平台和评估指标。

研究结果: 综述总结了基础模型在自动驾驶场景生成与分析中的最新进展，并整理了公开数据集、仿真平台和评估指标，同时指出了当前研究的不足和未来方向。

研究结论: 基础模型为自动驾驶场景生成与分析带来了新的可能性，但仍面临开放挑战。未来研究应关注模型泛化能力、数据多样性和评估标准的完善。

中文摘要: 自动驾驶车辆在复杂环境中的安全导航依赖于处理多样且罕见的驾驶场景。基于仿真和场景的测试已成为自动驾驶系统开发和验证的关键方法。传统场景生成依赖基于规则的系统、知识驱动模型和数据驱动合成，但多样性有限且难以生成真实的安全关键场景。随着基础模型（新一代预训练通用人工智能模型）的出现，开发者能够处理异构输入（如自然语言、传感器数据、高清地图和控制动作），从而合成和解析复杂驾驶场景。本文综述了截至2025年5月基础模型在自动驾驶场景生成与分析中的应用。我们提出了一种统一的分类法，涵盖大语言模型、视觉语言模型、多模态大语言模型、扩散模型和世界模型，用于生成和分析自动驾驶场景。此外，我们回顾了相关方法、开源数据集、仿真平台和基准挑战，并探讨了专门针对场景生成与分析的评估指标。最后，综述总结了开放挑战和研究问题，并展望了未来研究方向。所有综述论文均列于一个持续维护的存储库中，包含补充材料，访问地址为https://github.com/TUM-AVS/FM-for-Scenario-Generation-Analysis。

</details>


### [347] [Robot Context Protocol (RCP): A Runtime-Agnostic Interface for Agent-Aware Robot Control](https://arxiv.org/abs/2506.11650)
**中文标题：机器人上下文协议（RCP）：一种运行时无关的代理感知机器人控制接口**

*Lambert Lee,Joshua Lau*

主要分类: cs.RO

摘要简述: 机器人上下文协议（RCP）是一种轻量级、中间件无关的通信协议，旨在简化机器人系统的复杂性，实现机器人、用户和自主代理之间的无缝交互。


<details>
  <summary>详细信息</summary>
研究动机: 当前机器人系统复杂且难以集成，缺乏统一的接口支持多环境部署和交互。RCP旨在解决这一问题，提供一种标准化、语义明确的通信协议。

研究方法: RCP基于HTTP和WebSocket传输层，定义了一种模式驱动的消息格式，支持读取、写入、执行和订阅等结构化操作，并集成了运行时自省、异步反馈、多租户命名空间隔离和严格类型验证等功能。

研究结果: RCP实现了机器人操作的智能化、弹性和安全性，适用于制造业、物流和医疗等多个行业，支持物理机器人、云端编排器和仿真平台等多种部署环境。

研究结论: RCP为复杂多代理生态系统中的机器人操作提供了一种统一、安全且可扩展的解决方案。

中文摘要: 机器人上下文协议（RCP）是一种轻量级、中间件无关的通信协议，旨在简化机器人系统的复杂性，并实现机器人、用户和自主代理之间的无缝交互。RCP提供了一个统一且语义明确的接口，将面向客户端的操作与后端实现解耦，支持包括物理机器人、云端编排器和仿真平台在内的多种部署环境。该协议基于HTTP和WebSocket传输层，定义了一种模式驱动的消息格式，支持读取、写入、执行和订阅等结构化操作，并集成了运行时自省、异步反馈、多租户命名空间隔离和严格类型验证等功能，以确保其鲁棒性、可扩展性和安全性。本文描述了RCP的架构、消息结构、接口模型以及基于适配器的后端集成策略，并介绍了其在制造业、物流和医疗等行业的部署实践和适用性。RCP为复杂多代理生态系统中的智能、弹性和安全的机器人操作提供了支持。

</details>


### [348] [SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies](https://arxiv.org/abs/2506.11948)
**中文标题：SAIL：超越演示速度的模仿学习策略执行**

*Nadun Ranawaka Arachchige,Zhenyang Chen,Wonsuhk Jung,Woo Chul Shin,Rohan Bansal,Pierre Barroso,Yu Hang He,Yingyang Celine Lin,Benjamin Joffe,Shreyas Kousik,Danfei Xu*

主要分类: cs.RO

摘要简述: 本文提出SAIL系统，通过一致性动作推断、高精度运动目标跟踪、自适应速度调节和动作调度，实现模仿学习策略的快速执行，实验证明其速度可达演示速度的4倍。


<details>
  <summary>详细信息</summary>
研究动机: 现有模仿学习策略的执行速度受限于演示数据，无法满足工业自动化等高吞吐任务需求，因此需要开发能够超越演示速度的执行方法。

研究方法: SAIL系统包含四个核心组件：一致性动作推断算法、高精度运动目标跟踪、自适应速度调节和动作调度，以解决机器人动力学和状态-动作分布偏移问题。

研究结果: 在仿真和真实机器人平台上进行的12项任务实验中，SAIL实现了仿真中4倍、现实中3.2倍的速度提升。

研究结论: SAIL系统通过整合多项技术，成功实现了模仿学习策略的快速执行，为高吞吐任务提供了有效解决方案。

中文摘要: 离线模仿学习方法（如行为克隆）能有效学习复杂机器人操作技能，但现有模仿学习策略的执行速度受限于演示数据，限制了机器人系统的任务吞吐量，这对工业自动化等应用至关重要。本文提出并形式化了视觉运动策略的快速执行问题，并识别了机器人动力学和状态-动作分布偏移的基本挑战。为此，我们提出了SAIL（模仿学习速度适应），一个全栈系统，整合了四个紧密关联的组件：（1）一致性动作推断算法，用于高速平滑运动；（2）控制器不变运动目标的高精度跟踪；（3）基于运动复杂度的自适应速度调节；（4）处理现实系统延迟的动作调度。在仿真和两种真实机器人平台上的12项任务实验中，SAIL在仿真中实现了最高4倍、现实中最高3.2倍的速度提升。更多细节请访问：https://nadunranawaka1.github.io/sail-policy

</details>
