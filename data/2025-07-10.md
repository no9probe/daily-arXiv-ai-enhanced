<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 85]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.CY](#cs.CY) [Total: 7]
- [cs.MA](#cs.MA) [Total: 2]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.CR](#cs.CR) [Total: 10]
- [cs.LG](#cs.LG) [Total: 30]
- [cs.SI](#cs.SI) [Total: 2]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.SD](#cs.SD) [Total: 6]
- [cs.IR](#cs.IR) [Total: 3]
- [eess.SY](#eess.SY) [Total: 2]
- [cs.HC](#cs.HC) [Total: 3]
- [q-fin.RM](#q-fin.RM) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.GR](#cs.GR) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [eess.IV](#eess.IV) [Total: 11]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.RO](#cs.RO) [Total: 5]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
**中文标题：Gemini 2.5：通过先进推理、多模态、长上下文和下一代代理能力推动前沿**

*Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Vaishakh Keshava,Ying Jian,Xiaofan Zhang,Raluca Ada Popa,Kedar Dhamdhere,Blaž Bratanič,Kyuyeun Kim,Terry Koo,Ferran Alet,Yi-ting Chen,Arsha Nagrani,Hannah Muckenhirn,Zhiyuan Zhang,Corbin Quick,Filip Pavetić,Duc Dung Nguyen,Joao Carreira,Michael Elabd,Haroon Qureshi,Fabian Mentzer,Yao-Yuan Yang,Danielle Eisenbud,Anmol Gulati,Ellie Talius,Eric Ni,Sahra Ghalebikesabi,Edouard Yvinec,Alaa Saade,Thatcher Ulrich,Lorenzo Blanco,Dan A. Calian,Muhuan Huang,Aäron van den Oord,Naman Goyal,Terry Chen,Praynaa Rawlani,Christian Schallhart,Swachhand Lokhande,Xianghong Luo,Jyn Shan,Ceslee Montgomery,Victoria Krakovna,Federico Piccinini,Omer Barak,Jingyu Cui,Yiling Jia,Mikhail Dektiarev,Alexey Kolganov,Shiyu Huang,Zhe Chen,Xingyu Wang,Jessica Austin,Peter de Boursac,Evgeny Sluzhaev,Frank Ding,Huijian Li,Surya Bhupatiraju,Mohit Agarwal,Sławek Kwasiborski,Paramjit Sandhu,Patrick Siegler,Ahmet Iscen,Eyal Ben-David,Shiraz Butt,Miltos Allamanis,Seth Benjamin,Robert Busa-Fekete,Felix Hernandez-Campos,Sasha Goldshtein,Matt Dibb,Weiyang Zhang,Annie Marsden,Carey Radebaugh,Stephen Roller,Abhishek Nayyar,Jacob Austin,Tayfun Terzi,Bhargav Kanagal Shamanna,Pete Shaw,Aayush Singh,Florian Luisier,Artur Mendonça,Vaibhav Aggarwal,Larisa Markeeva,Claudio Fantacci,Sergey Brin,HyunJeong Choe,Guanyu Wang,Hartwig Adam,Avigail Dabush,Tatsuya Kiyono,Eyal Marcus,Jeremy Cole,Theophane Weber,Hongrae Lee,Ronny Huang,Alex Muzio,Leandro Kieliger,Maigo Le,Courtney Biles,Long Le,Archit Sharma,Chengrun Yang,Avery Lamp,Dave Dopson,Nate Hurley,Katrina,Xu,Zhihao Shan,Shuang Song,Jiewen Tan,Alexandre Senges,George Zhang,Chong You,Yennie Jun,David Raposo,Susanna Ricco,Xuan Yang,Weijie Chen,Prakhar Gupta,Arthur Szlam,Kevin Villela,Chun-Sung Ferng,Daniel Kasenberg,Chen Liang,Rui Zhu,Arunachalam Narayanaswamy,Florence Perot,Paul Pucciarelli,Anna Shekhawat,Alexey Stern,Rishikesh Ingale,Stefani Karp,Sanaz Bahargam,Adrian Goedeckemeyer,Jie Han,Sicheng Li,Andrea Tacchetti,Dian Yu,Abhishek Chakladar,Zhiying Zhang,Mona El Mahdy,Xu Gao,Dale Johnson,Samrat Phatale,AJ Piergiovanni,Hyeontaek Lim,Clement Farabet,Carl Lebsack,Theo Guidroz,John Blitzer,Nico Duduta,David Madras,Steve Li,Daniel von Dincklage,Xin Li,Mahdis Mahdieh,George Tucker,Ganesh Jawahar,Owen Xiao,Danny Tarlow,Robert Geirhos,Noam Velan,Daniel Vlasic,Kalesha Bullard,SK Park,Nishesh Gupta,Kellie Webster,Ayal Hitron,Jieming Mao,Julian Eisenschlos,Laurel Prince,Nina D'Souza,Kelvin Zheng,Sara Nasso,Gabriela Botea,Carl Doersch,Caglar Unlu,Chris Alberti,Alexey Svyatkovskiy,Ankita Goel,Krzysztof Choromanski,Pan-Pan Jiang,Richard Nguyen,Four Flynn,Daria Ćurko,Peter Chen,Nicholas Roth,Kieran Milan,Caleb Habtegebriel,Shashi Narayan,Michael Moffitt,Jake Marcus,Thomas Anthony,Brendan McMahan,Gowoon Cheon,Ruibo Liu,Megan Barnes,Lukasz Lew,Rebeca Santamaria-Fernandez,Mayank Upadhyay,Arjun Akula,Arnar Mar Hrafnkelsson,Alvaro Caceres,Andrew Bunner,Michal Sokolik,Subha Puttagunta,Lawrence Moore,Berivan Isik,Weilun Chen,Jay Hartford,Lawrence Chan,Pradeep Shenoy,Dan Holtmann-Rice,Jane Park,Fabio Viola,Alex Salcianu,Sujeevan Rajayogam,Ian Stewart-Binks,Zelin Wu,Richard Everett,Xi Xiong,Pierre-Antoine Manzagol,Gary Leung,Carl Saroufim,Bo Pang,Dawid Wegner,George Papamakarios,Jennimaria Palomaki,Helena Pankov,Guangda Lai,Guilherme Tubone,Shubin Zhao,Theofilos Strinopoulos,Seth Neel,Mingqiu Wang,Joe Kelley,Li Li,Pingmei Xu,Anitha Vijayakumar,Andrea D'olimpio,Omer Levy,Massimo Nicosia,Grigory Rozhdestvenskiy,Ni Lao,Sirui Xie,Yash Katariya,Jon Simon,Sanjiv Kumar,Florian Hartmann,Michael Kilgore,Jinhyuk Lee,Aroma Mahendru,Roman Ring,Tom Hennigan,Fiona Lang,Colin Cherry,David Steiner,Dawsen Hwang,Ray Smith,Pidong Wang,Jeremy Chen,Ming-Hsuan Yang,Sam Kwei,Philippe Schlattner,Donnie Kim,Ganesh Poomal Girirajan,Nikola Momchev,Ayushi Agarwal,Xingyi Zhou,Ilkin Safarli,Zachary Garrett,AJ Pierigiovanni,Sarthak Jauhari,Alif Raditya Rochman,Shikhar Vashishth,Quan Yuan,Christof Angermueller,Jon Blanton,Xinying Song,Nitesh Bharadwaj Gundavarapu,Thi Avrahami,Maxine Deines,Subhrajit Roy,Manish Gupta,Christopher Semturs,Shobha Vasudevan,Aditya Srikanth Veerubhotla,Shriya Sharma,Josh Jacob,Zhen Yang,Andreas Terzis,Dan Karliner,Auriel Wright,Tania Rojas-Esponda,Ashley Brown,Abhijit Guha Roy,Pawan Dogra,Andrei Kapishnikov,Peter Young,Wendy Kan,Vinodh Kumar Rajendran,Maria Ivanova,Salil Deshmukh,Chia-Hua Ho,Mike Kwong,Stav Ginzburg,Annie Louis,KP Sawhney,Slav Petrov,Jing Xie,Yunfei Bai,Georgi Stoyanov,Alex Fabrikant,Rajesh Jayaram,Yuqi Li,Joe Heyward,Justin Gilmer,Yaqing Wang,Radu Soricut,Luyang Liu,Qingnan Duan,Jamie Hayes,Maura O'Brien,Gaurav Singh Tomar,Sivan Eiger,Bahar Fatemi,Jeffrey Hui,Catarina Barros,Adaeze Chukwuka,Alena Butryna,Saksham Thakur,Austin Huang,Zhufeng Pan,Haotian Tang,Serkan Cabi,Tulsee Doshi,Michiel Bakker,Sumit Bagri,Ruy Ley-Wild,Adam Lelkes,Jennie Lees,Patrick Kane,David Greene,Shimu Wu,Jörg Bornschein,Gabriela Surita,Sarah Hodkinson,Fangtao Li,Chris Hidey,Sébastien Pereira,Sean Ammirati,Phillip Lippe,Adam Kraft,Pu Han,Sebastian Gerlach,Zifeng Wang,Liviu Panait,Feng Han,Brian Farris,Yingying Bi,Hannah DeBalsi,Miaosen Wang,Gladys Tyen,James Cohan,Susan Zhang,Jarred Barber,Da-Woon Chung,Jaeyoun Kim,Markus Kunesch,Steven Pecht,Nami Akazawa,Abe Friesen,James Lyon,Ali Eslami,Junru Wu,Jie Tan,Yue Song,Ravi Kumar,Chris Welty,Ilia Akolzin,Gena Gibson,Sean Augenstein,Arjun Pillai,Nancy Yuen,Du Phan,Xin Wang,Iain Barr,Heiga Zen,Nan Hua,Casper Liu,Jilei,Wang,Tanuj Bhatia,Hao Xu,Oded Elyada,Pushmeet Kohli,Mirek Olšák,Ke Chen,Azalia Mirhoseini,Noam Shazeer,Shoshana Jakobovits,Maggie Tran,Nolan Ramsden,Tarun Bharti,Fred Alcober,Yunjie Li,Shilpa Shetty,Jing Chen,Dmitry Kalashnikov,Megha Nawhal,Sercan Arik,Hanwen Chen,Michiel Blokzijl,Shubham Gupta,James Rubin,Rigel Swavely,Sophie Bridgers,Ian Gemp,Chen Su,Arun Suggala,Juliette Pluto,Mary Cassin,Alain Vaucher,Kaiyang Ji,Jiahao Cai,Andrew Audibert,Animesh Sinha,David Tian,Efrat Farkash,Amy Hua,Jilin Chen,Duc-Hieu Tran,Edward Loper,Nicole Brichtova,Lara McConnaughey,Ballie Sandhu,Robert Leland,Doug DeCarlo,Andrew Over,James Huang,Xing Wu,Connie Fan,Eric Li,Yun Lei,Deepak Sharma,Cosmin Paduraru,Luo Yu,Matko Bošnjak,Phuong Dao,Min Choi,Sneha Kudugunta,Jakub Adamek,Carlos Guía,Ali Khodaei,Jie Feng,Wenjun Zeng,David Welling,Sandeep Tata,Christina Butterfield,Andrey Vlasov,Seliem El-Sayed,Swaroop Mishra,Tara Sainath,Shentao Yang,RJ Skerry-Ryan,Jeremy Shar,Robert Berry,Arunkumar Rajendran,Arun Kandoor,Andrea Burns,Deepali Jain,Tom Stone,Wonpyo Park,Shibo Wang,Albin Cassirer,Guohui Wang,Hayato Kobayashi,Sergey Rogulenko,Vineetha Govindaraj,Mikołaj Rybiński,Nadav Olmert,Colin Evans,Po-Sen Huang,Kelvin Xu,Premal Shah,Terry Thurk,Caitlin Sikora,Mu Cai,Jin Xie,Elahe Dabir,Saloni Shah,Norbert Kalb,Carrie Zhang,Shruthi Prabhakara,Amit Sabne,Artiom Myaskovsky,Vikas Raunak,Blanca Huergo,Behnam Neyshabur,Jon Clark,Ye Zhang,Shankar Krishnan,Eden Cohen,Dinesh Tewari,James Lottes,Yumeya Yamamori,Hui,Li,Mohamed Elhawaty,Ada Maksutaj Oflazer,Adrià Recasens,Sheryl Luo,Duy Nguyen,Taylor Bos,Kalyan Andra,Ana Salazar,Ed Chi,Jeongwoo Ko,Matt Ginsberg,Anders Andreassen,Anian Ruoss,Todor Davchev,Elnaz Davoodi,Chenxi Liu,Min Kim,Santiago Ontanon,Chi Ming To,Dawei Jia,Rosemary Ke,Jing Wang,Anna Korsun,Moran Ambar,Ilya Kornakov,Irene Giannoumis,Toni Creswell,Denny Zhou,Yi Su,Ishaan Watts,Aleksandr Zaks,Evgenii Eltyshev,Ziqiang Feng,Sidharth Mudgal,Alex Kaskasoli,Juliette Love,Kingshuk Dasgupta,Sam Shleifer,Richard Green,Sungyong Seo,Chansoo Lee,Dale Webster,Prakash Shroff,Ganna Raboshchuk,Isabel Leal,James Manyika,Sofia Erell,Daniel Murphy,Zhisheng Xiao,Anton Bulyenov,Julian Walker,Mark Collier,Matej Kastelic,Nelson George,Sushant Prakash,Sailesh Sidhwani,Alexey Frolov,Steven Hansen,Petko Georgiev,Tiberiu Sosea,Chris Apps,Aishwarya Kamath,David Reid,Emma Cooney,Charlotte Magister,Oriana Riva,Alec Go,Pu-Chin Chen,Sebastian Krause,Nir Levine,Marco Fornoni,Ilya Figotin,Nick Roy,Parsa Mahmoudieh,Vladimir Magay,Mukundan Madhavan,Jin Miao,Jianmo Ni,Yasuhisa Fujii,Ian Chou,George Scrivener,Zak Tsai,Siobhan Mcloughlin,Jeremy Selier,Sandra Lefdal,Jeffrey Zhao,Abhijit Karmarkar,Kushal Chauhan,Shivanker Goel,Zhaoyi Zhang,Vihan Jain,Parisa Haghani,Mostafa Dehghani,Jacob Scott,Erin Farnese,Anastasija Ilić,Steven Baker,Julia Pawar,Li Zhong,Josh Camp,Yoel Zeldes,Shravya Shetty,Anand Iyer,Vít Listík,Jiaxian Guo,Luming Tang,Mark Geller,Simon Bucher,Yifan Ding,Hongzhi Shi,Carrie Muir,Dominik Grewe,Ramy Eskander,Octavio Ponce,Boqing Gong,Derek Gasaway,Samira Khan,Umang Gupta,Angelos Filos,Weicheng Kuo,Klemen Kloboves,Jennifer Beattie,Christian Wright,Leon Li,Alicia Jin,Sandeep Mariserla,Miteyan Patel,Jens Heitkaemper,Dilip Krishnan,Vivek Sharma,David Bieber,Christian Frank,John Lambert,Paul Caron,Martin Polacek,Mai Giménez,Himadri Choudhury,Xing Yu,Sasan Tavakkol,Arun Ahuja,Franz Och,Rodolphe Jenatton,Wojtek Skut,Bryan Richter,David Gaddy,Andy Ly,Misha Bilenko,Megh Umekar,Ethan Liang,Martin Sevenich,Mandar Joshi,Hassan Mansoor,Rebecca Lin,Sumit Sanghai,Abhimanyu Singh,Xiaowei Li,Sudheendra Vijayanarasimhan,Zaheer Abbas,Yonatan Bitton,Hansa Srinivasan,Manish Reddy Vuyyuru,Alexander Frömmgen,Yanhua Sun,Ralph Leith,Alfonso Castaño,DJ Strouse,Le Yan,Austin Kyker,Satish Kambala,Mary Jasarevic,Thibault Sellam,Chao Jia,Alexander Pritzel,Raghavender R,Huizhong Chen,Natalie Clay,Sudeep Gandhe,Sean Kirmani,Sayna Ebrahimi,Hannah Kirkwood,Jonathan Mallinson,Chao Wang,Adnan Ozturel,Kuo Lin,Shyam Upadhyay,Vincent Cohen-Addad,Sean Purser-haskell,Yichong Xu,Ebrahim Songhori,Babi Seal,Alberto Magni,Almog Gueta,Tingting Zou,Guru Guruganesh,Thais Kagohara,Hung Nguyen,Khalid Salama,Alejandro Cruzado Ruiz,Justin Frye,Zhenkai Zhu,Matthias Lochbrunner,Simon Osindero,Wentao Yuan,Lisa Lee,Aman Prasad,Lam Nguyen Thiet,Daniele Calandriello,Victor Stone,Qixuan Feng,Han Ke,Maria Voitovich,Geta Sampemane,Lewis Chiang,Ling Wu,Alexander Bykovsky,Matt Young,Luke Vilnis,Ishita Dasgupta,Aditya Chawla,Qin Cao,Bowen Liang,Daniel Toyama,Szabolcs Payrits,Anca Stefanoiu,Dimitrios Vytiniotis,Ankesh Anand,Tianxiao Shen,Blagoj Mitrevski,Michael Tschannen,Sreenivas Gollapudi,Aishwarya P S,José Leal,Zhe Shen,Han Fu,Wei Wang,Arvind Kannan,Doron Kukliansky,Sergey Yaroshenko,Svetlana Grant,Umesh Telang,David Wood,Alexandra Chronopoulou,Alexandru Ţifrea,Tao Zhou,Tony,Nguy\~ên,Muge Ersoy,Anima Singh,Meiyan Xie,Emanuel Taropa,Woohyun Han,Eirikur Agustsson,Andrei Sozanschi,Hui Peng,Alex Chen,Yoel Drori,Efren Robles,Yang Gao,Xerxes Dotiwalla,Ying Chen,Anudhyan Boral,Alexei Bendebury,John Nham,Chris Tar,Luis Castro,Jiepu Jiang,Canoee Liu,Felix Halim,Jinoo Baek,Andy Wan,Jeremiah Liu,Yuan Cao,Shengyang Dai,Trilok Acharya,Ruoxi Sun,Fuzhao Xue,Saket Joshi,Morgane Lustman,Yongqin Xian,Rishabh Joshi,Deep Karkhanis,Nora Kassner,Jamie Hall,Xiangzhuo Ding,Gan Song,Gang Li,Chen Zhu,Yana Kulizhskaya,Bin Ni,Alexey Vlaskin,Solomon Demmessie,Lucio Dery,Salah Zaiem,Yanping Huang,Cindy Fan,Felix Gimeno,Ananth Balashankar,Koji Kojima,Hagai Taitelbaum,Maya Meng,Dero Gharibian,Sahil Singla,Wei Chen,Ambrose Slone,Guanjie Chen,Sujee Rajayogam,Max Schumacher,Suyog Kotecha,Rory Blevins,Qifei Wang,Mor Hazan Taege,Alex Morris,Xin Liu,Fayaz Jamil,Richard Zhang,Pratik Joshi,Ben Ingram,Tyler Liechty,Ahmed Eleryan,Scott Baird,Alex Grills,Gagan Bansal,Shan Han,Kiran Yalasangi,Shawn Xu,Majd Al Merey,Isabel Gao,Felix Weissenberger,Igor Karpov,Robert Riachi,Ankit Anand,Gautam Prasad,Kay Lamerigts,Reid Hayes,Jamie Rogers,Mandy Guo,Ashish Shenoy,Qiong,Hu,Kyle He,Yuchen Liu,Polina Zablotskaia,Sagar Gubbi,Yifan Chang,Jay Pavagadhi,Kristian Kjems,Archita Vadali,Diego Machado,Yeqing Li,Renshen Wang,Dipankar Ghosh,Aahil Mehta,Dana Alon,George Polovets,Alessio Tonioni,Nate Kushman,Joel D'sa,Lin Zhuo,Allen Wu,Rohin Shah,John Youssef,Jiayu Ye,Justin Snyder,Karel Lenc,Senaka Buthpitiya,Matthew Tung,Jichuan Chang,Tao Chen,David Saxton,Jenny Lee,Lydia Lihui Zhang,James Qin,Prabakar Radhakrishnan,Maxwell Chen,Piotr Ambroszczyk,Metin Toksoz-Exley,Yan Zhong,Nitzan Katz,Brendan O'Donoghue,Tamara von Glehn,Adi Gerzi Rosenthal,Aga Świetlik,Xiaokai Zhao,Nick Fernando,Jinliang Wei,Jieru Mei,Sergei Vassilvitskii,Diego Cedillo,Pranjal Awasthi,Hui Zheng,Koray Kavukcuoglu,Itay Laish,Joseph Pagadora,Marc Brockschmidt,Christopher A. Choquette-Choo,Arunkumar Byravan,Yifeng Lu,Xu Chen,Mia Chen,Kenton Lee,Rama Pasumarthi,Sijal Bhatnagar,Aditya Shah,Qiyin Wu,Zhuoyuan Chen,Zack Nado,Bartek Perz,Zixuan Jiang,David Kao,Ganesh Mallya,Nino Vieillard,Lantao Mei,Sertan Girgin,Mandy Jordan,Yeongil Ko,Alekh Agarwal,Yaxin Liu,Yasemin Altun,Raoul de Liedekerke,Anastasios Kementsietsidis,Daiyi Peng,Dangyi Liu,Utku Evci,Peter Humphreys,Austin Tarango,Xiang Deng,Yoad Lewenberg,Kevin Aydin,Chengda Wu,Bhavishya Mittal,Tsendsuren Munkhdalai,Kleopatra Chatziprimou,Rodrigo Benenson,Uri First,Xiao Ma,Jinning Li,Armand Joulin,Hamish Tomlinson,Tingnan Zhang,Milad Nasr,Zhi Hong,Michaël Sander,Lisa Anne Hendricks,Anuj Sharma,Andrew Bolt,Eszter Vértes,Jiri Simsa,Tomer Levinboim,Olcan Sercinoglu,Divyansh Shukla,Austin Wu,Craig Swanson,Danny Vainstein,Fan Bu,Bo Wang,Ryan Julian,Charles Yoon,Sergei Lebedev,Antonious Girgis,Bernd Bandemer,David Du,Todd Wang,Xi Chen,Ying Xiao,Peggy Lu,Natalie Ha,Vlad Ionescu,Simon Rowe,Josip Matak,Federico Lebron,Andreas Steiner,Lalit Jain,Manaal Faruqui,Nicolas Lacasse,Georgie Evans,Neesha Subramaniam,Dean Reich,Giulia Vezzani,Aditya Pandey,Joe Stanton,Tianhao Zhou,Liam McCafferty,Henry Griffiths,Verena Rieser,Soheil Hassas Yeganeh,Eleftheria Briakou,Lu Huang,Zichuan Wei,Liangchen Luo,Erik Jue,Gabby Wang,Victor Cotruta,Myriam Khan,Jongbin Park,Qiuchen Guo,Peiran Li,Rong Rong,Diego Antognini,Anastasia Petrushkina,Chetan Tekur,Eli Collins,Parul Bhatia,Chester Kwak,Wenhu Chen,Arvind Neelakantan,Immanuel Odisho,Sheng Peng,Vincent Nallatamby,Vaibhav Tulsyan,Fabian Pedregosa,Peng Xu,Raymond Lin,Yulong Wang,Emma Wang,Sholto Douglas,Reut Tsarfaty,Elena Gribovskaya,Renga Aravamudhan,Manu Agarwal,Mara Finkelstein,Qiao Zhang,Elizabeth Cole,Phil Crone,Sarmishta Velury,Anil Das,Chris Sauer,Luyao Xu,Danfeng Qin,Chenjie Gu,Dror Marcus,CJ Zheng,Wouter Van Gansbeke,Sobhan Miryoosefi,Haitian Sun,YaGuang Li,Charlie Chen,Jae Yoo,Pavel Dubov,Alex Tomala,Adams Yu,Paweł Wesołowski,Alok Gunjan,Eddie Cao,Jiaming Luo,Nikhil Sethi,Arkadiusz Socala,Laura Graesser,Tomas Kocisky,Arturo BC,Minmin Chen,Edward Lee,Sophie Wang,Weize Kong,Qiantong Xu,Nilesh Tripuraneni,Yiming Li,Xinxin Yu,Allen Porter,Paul Voigtlaender,Biao Zhang,Arpi Vezer,Sarah York,Qing Wei,Geoffrey Cideron,Mark Kurzeja,Seungyeon Kim,Benny Li,Angéline Pouget,Hyo Lee,Kaspar Daugaard,Yang Li,Dave Uthus,Aditya Siddhant,Paul Cavallaro,Sriram Ganapathy,Maulik Shah,Rolf Jagerman,Jeff Stanway,Piermaria Mendolicchio,Li Xiao,Kayi Lee,Tara Thompson,Shubham Milind Phal,Jason Chase,Sun Jae Lee,Adrian N Reyes,Disha Shrivastava,Zhen Qin,Roykrong Sukkerd,Seth Odoom,Lior Madmoni,John Aslanides,Jonathan Herzig,Elena Pochernina,Sheng Zhang,Parker Barnes,Daisuke Ikeda,Qiujia Li,Shuo-yiin Chang,Shakir Mohamed,Jim Sproch,Richard Powell,Bidisha Samanta,Domagoj Ćevid,Anton Kovsharov,Shrestha Basu Mallick,Srinivas Tadepalli,Anne Zheng,Kareem Ayoub,Andreas Noever,Christian Reisswig,Zhuo Xu,Junhyuk Oh,Martin Matysiak,Tim Blyth,Shereen Ashraf,Julien Amelot,Boone Severson,Michele Bevilacqua,Motoki Sano,Ethan Dyer,Ofir Roval,Anu Sinha,Yin Zhong,Sagi Perel,Tea Sabolić,Johannes Mauerer,Willi Gierke,Mauro Verzetti,Rodrigo Cabrera,Alvin Abdagic,Steven Hemingray,Austin Stone,Jong Lee,Farooq Ahmad,Karthik Raman,Lior Shani,Jonathan Lai,Orhan Firat,Nathan Waters,Eric Ge,Mo Shomrat,Himanshu Gupta,Rajeev Aggarwal,Tom Hudson,Bill Jia,Simon Baumgartner,Palak Jain,Joe Kovac,Junehyuk Jung,Ante Žužul,Will Truong,Morteza Zadimoghaddam,Songyou Peng,Marco Liang,Rachel Sterneck,Balaji Lakshminarayanan,Machel Reid,Oliver Woodman,Tong Zhou,Jianling Wang,Vincent Coriou,Arjun Narayanan,Jay Hoover,Yenai Ma,Apoorv Jindal,Clayton Sanford,Doug Reid,Swaroop Ramaswamy,Alex Kurakin,Roland Zimmermann,Yana Lunts,Dragos Dena,Zalán Borsos,Vered Cohen,Shujian Zhang,Will Grathwohl,Robert Dadashi,Morgan Redshaw,Joshua Kessinger,Julian Odell,Silvano Bonacina,Zihang Dai,Grace Chen,Ayush Dubey,Pablo Sprechmann,Mantas Pajarskas,Wenxuan Zhou,Niharika Ahuja,Tara Thomas,Martin Nikoltchev,Matija Kecman,Bharath Mankalale,Andrey Ryabtsev,Jennifer She,Christian Walder,Jiaming Shen,Lu Li,Carolina Parada,Sheena Panthaplackel,Okwan Kwon,Matt Lawlor,Utsav Prabhu,Yannick Schroecker,Marc'aurelio Ranzato,Pete Blois,Iurii Kemaev,Ting Yu,Dmitry,Lepikhin,Hao Xiong,Sahand Sharifzadeh,Oleaser Johnson,Jeremiah Willcock,Rui Yao,Greg Farquhar,Sujoy Basu,Hidetoshi Shimokawa,Nina Anderson,Haiguang Li,Khiem Pham,Yizhong Liang,Sebastian Borgeaud,Alexandre Moufarek,Hideto Kazawa,Blair Kutzman,Marcin Sieniek,Sara Smoot,Ruth Wang,Natalie Axelsson,Nova Fallen,Prasha Sundaram,Yuexiang Zhai,Varun Godbole,Petros Maniatis,Alek Wang,Ilia Shumailov,Santhosh Thangaraj,Remi Crocker,Nikita Gupta,Gang Wu,Phil Chen,Gellért Weisz,Celine Smith,Mojtaba Seyedhosseini,Boya Fang,Xiyang Luo,Roey Yogev,Zeynep Cankara,Andrew Hard,Helen Ran,Rahul Sukthankar,George Necula,Gaël Liu,Honglong Cai,Praseem Banzal,Daniel Keysers,Sanjay Ghemawat,Connie Tao,Emma Dunleavy,Aditi Chaudhary,Wei Li,Maciej Mikuła,Chen-Yu Lee,Tiziana Refice,Krishna Somandepalli,Alexandre Fréchette,Dan Bahir,John Karro,Keith Rush,Sarah Perrin,Bill Rosgen,Xiaomeng Yang,Clara Huiyi Hu,Mahmoud Alnahlawi,Justin Mao-Jones,Roopal Garg,Hoang Nguyen,Bat-Orgil Batsaikhan,Iñaki Iturrate,Anselm Levskaya,Avi Singh,Ashyana Kachra,Tony Lu,Denis Petek,Zheng Xu,Mark Graham,Lukas Zilka,Yael Karov,Marija Kostelac,Fangyu Liu,Yaohui Guo,Weiyue Wang,Bernd Bohnet,Emily Pitler,Tony Bruguier,Keisuke Kinoshita,Chrysovalantis Anastasiou,Nilpa Jha,Ting Liu,Jerome Connor,Phil Wallis,Philip Pham,Eric Bailey,Shixin Li,Heng-Tze Cheng,Sally Ma,Haiqiong Li,Akanksha Maurya,Kate Olszewska,Manfred Warmuth,Christy Koh,Dominik Paulus,Siddhartha Reddy Jonnalagadda,Enrique Piqueras,Ali Elqursh,Geoff Brown,Hadar Shemtov,Loren Maggiore,Fei Xia,Ryan Foley,Beka Westberg,George van den Driessche,Livio Baldini Soares,Arjun Kar,Michael Quinn,Siqi Zuo,Jialin Wu,Kyle Kastner,Anna Bortsova,Aijun Bai,Ales Mikhalap,Luowei Zhou,Jennifer Brennan,Vinay Ramasesh,Honglei Zhuang,John Maggs,Johan Schalkwyk,Yuntao Xu,Hui Huang,Andrew Howard,Sasha Brown,Linting Xue,Gloria Shen,Brian Albert,Neha Jha,Daniel Zheng,Varvara Krayvanova,Spurthi Amba Hombaiah,Olivier Lacombe,Gautam Vasudevan,Dan Graur,Tian Xie,Meet Gandhi,Bangju Wang,Dustin Zelle,Harman Singh,Dahun Kim,Sébastien Cevey,Victor Ungureanu,Natasha Noy,Fei Liu,Annie Xie,Fangxiaoyu Feng,Katerina Tsihlas,Daniel Formoso,Neera Vats,Quentin Wellens,Yinan Wang,Niket Kumar Bhumihar,Samrat Ghosh,Matt Hoffman,Tom Lieber,Oran Lang,Kush Bhatia,Tom Paine,Aroonalok Pyne,Ronny Votel,Madeleine Clare Elish,Benoit Schillings,Alex Panagopoulos,Haichuan Yang,Adam Raveret,Zohar Yahav,Shuang Liu,Warren Chen,Dalia El Badawy,Nishant Agrawal,Mohammed Badawi,Mahdi Mirzazadeh,Carla Bromberg,Fan Ye,Chang Liu,Tatiana Sholokhova,George-Cristian Muraru,Gargi Balasubramaniam,Jonathan Malmaud,Alen Carin,Danilo Martins,Irina Jurenka,Pankil Botadra,Dave Lacey,Richa Singh,Mariano Schain,Dan Zheng,Isabelle Guyon,Victor Lavrenko,Seungji Lee,Xiang Zhou,Demis Hassabis,Jeshwanth Challagundla,Derek Cheng,Nikhil Mehta,Matthew Mauger,Michela Paganini,Pushkar Mishra,Kate Lee,Zhang Li,Lexi Baugher,Ondrej Skopek,Max Chang,Amir Zait,Gaurav Menghani,Lizzetth Bellot,Guangxing Han,Jean-Michel Sarr,Sharat Chikkerur,Himanshu Sahni,Rohan Anil,Arun Narayanan,Chandu Thekkath,Daniele Pighin,Hana Strejček,Marko Velic,Fred Bertsch,Manuel Tragut,Keran Rong,Alicia Parrish,Kai Bailey,Jiho Park,Isabela Albuquerque,Abhishek Bapna,Rajesh Venkataraman,Alec Kosik,Johannes Griesser,Zhiwei Deng,Alek Andreev,Qingyun Dou,Kevin Hui,Fanny Wei,Xiaobin Yu,Lei Shu,Avia Aharon,David Barker,Badih Ghazi,Sebastian Flennerhag,Chris Breaux,Yuchuan Liu,Matthew Bilotti,Josh Woodward,Uri Alon,Stephanie Winkler,Tzu-Kuo Huang,Kostas Andriopoulos,João Gabriel Oliveira,Penporn Koanantakool,Berkin Akin,Michael Wunder,Cicero Nogueira dos Santos,Mohammad Hossein Bateni,Lin Yang,Dan Horgan,Beer Changpinyo,Keyvan Amiri,Min Ma,Dayeong Lee,Lihao Liang,Anirudh Baddepudi,Tejasi Latkar,Raia Hadsell,Jun Xu,Hairong Mu,Michael Han,Aedan Pope,Snchit Grover,Frank Kim,Ankit Bhagatwala,Guan Sun,Yamini Bansal,Amir Globerson,Alireza Nazari,Samira Daruki,Hagen Soltau,Jane Labanowski,Laurent El Shafey,Matt Harvey,Yanif Ahmad,Elan Rosenfeld,William Kong,Etienne Pot,Yi-Xuan Tan,Aurora Wei,Victoria Langston,Marcel Prasetya,Petar Veličković,Richard Killam,Robin Strudel,Darren Ni,Zhenhai Zhu,Aaron Archer,Kavya Kopparapu,Lynn Nguyen,Emilio Parisotto,Hussain Masoom,Sravanti Addepalli,Jordan Grimstad,Hexiang Hu,Joss Moore,Avinatan Hassidim,Le Hou,Mukund Raghavachari,Jared Lichtarge,Adam R. Brown,Hilal Dib,Natalia Ponomareva,Justin Fu,Yujing Zhang,Altaf Rahman,Joana Iljazi,Edouard Leurent,Gabriel Dulac-Arnold,Cosmo Du,Chulayuth Asawaroengchai,Larry Jin,Ela Gruzewska,Ziwei Ji,Benigno Uria,Daniel De Freitas,Paul Barham,Lauren Beltrone,Víctor Campos,Jun Yan,Neel Kovelamudi,Arthur Nguyen,Elinor Davies,Zhichun Wu,Zoltan Egyed,Kristina Toutanova,Nithya Attaluri,Hongliang Fei,Peter Stys,Siddhartha Brahma,Martin Izzard,Siva Velusamy,Scott Lundberg,Vincent Zhuang,Kevin Sequeira,Adam Santoro,Ehsan Amid,Ophir Aharoni,Shuai Ye,Mukund Sundararajan,Lijun Yu,Yu-Cheng Ling,Stephen Spencer,Hugo Song,Josip Djolonga,Christo Kirov,Sonal Gupta,Alessandro Bissacco,Clemens Meyer,Mukul Bhutani,Andrew Dai,Weiyi Wang,Siqi Liu,Ashwin Sreevatsa,Qijun Tan,Maria Wang,Lucy Kim,Yicheng Wang,Alex Irpan,Yang Xiao,Stanislav Fort,Yifan He,Alex Gurney,Bryan Gale,Yue Ma,Monica Roy,Viorica Patraucean,Taylan Bilal,Golnaz Ghiasi,Anahita Hosseini,Melvin Johnson,Zhuowan Li,Yi Tay,Benjamin Beyret,Katie Millican,Josef Broder,Mayank Lunayach,Danny Swisher,Eugen Vušak,David Parkinson,MH Tessler,Adi Mayrav Gilady,Richard Song,Allan Dafoe,Yves Raimond,Masa Yamaguchi,Itay Karo,Elizabeth Nielsen,Kevin Kilgour,Mike Dusenberry,Rajiv Mathews,Jiho Choi,Siyuan Qiao,Harsh Mehta,Sahitya Potluri,Chris Knutsen,Jialu Liu,Tat Tan,Kuntal Sengupta,Keerthana Gopalakrishnan,Abodunrinwa Toki,Mencher Chiang,Mike Burrows,Grace Vesom,Zafarali Ahmed,Ilia Labzovsky,Siddharth Vashishtha,Preeti Singh,Ankur Sharma,Ada Ma,Jinyu Xie,Pranav Talluri,Hannah Forbes-Pollard,Aarush Selvan,Joel Wee,Loic Matthey,Tom Funkhouser,Parthasarathy Gopavarapu,Lev Proleev,Cheng Li,Matt Thomas,Kashyap Kolipaka,Zhipeng Jia,Ashwin Kakarla,Srinivas Sunkara,Joan Puigcerver,Suraj Satishkumar Sheth,Emily Graves,Chen Wang,Sadh MNM Khan,Kai Kang,Shyamal Buch,Fred Zhang,Omkar Savant,David Soergel,Kevin Lee,Linda Friso,Xuanyi Dong,Rahul Arya,Shreyas Chandrakaladharan,Connor Schenck,Greg Billock,Tejas Iyer,Anton Bakalov,Leslie Baker,Alex Ruiz,Angad Chandorkar,Trieu Trinh,Matt Miecnikowski,Yanqi Zhou,Yangsibo Huang,Jiazhong Nie,Ali Shah,Ashish Thapliyal,Sam Haves,Lun Wang,Uri Shaham,Patrick Morris-Suzuki,Soroush Radpour,Leonard Berrada,Thomas Strohmann,Chaochao Yan,Jingwei Shen,Sonam Goenka,Tris Warkentin,Petar Dević,Dan Belov,Albert Webson,Madhavi Yenugula,Puranjay Datta,Jerry Chang,Nimesh Ghelani,Aviral Kumar,Vincent Perot,Jessica Lo,Yang Song,Herman Schmit,Jianmin Chen,Vasilisa Bashlovkina,Xiaoyue Pan,Diana Mincu,Paul Roit,Isabel Edkins,Andy Davis,Yujia Li,Ben Horn,Xinjian Li,Pradeep Kumar S,Eric Doi,Wanzheng Zhu,Sri Gayatri Sundara Padmanabhan,Siddharth Verma,Jasmine Liu,Heng Chen,Mihajlo Velimirović,Malcolm Reynolds,Priyanka Agrawal,Nick Sukhanov,Abhinit Modi,Siddharth Goyal,John Palowitch,Nima Khajehnouri,Wing Lowe,David Klinghoffer,Sharon Silver,Vinh Tran,Candice Schumann,Francesco Piccinno,Xi Liu,Mario Lučić,Xiaochen Yang,Sandeep Kumar,Ajay Kannan,Ragha Kotikalapudi,Mudit Bansal,Fabian Fuchs,Javad Hosseini,Abdelrahman Abdelhamed,Dawn Bloxwich,Tianhe Yu,Ruoxin Sang,Gregory Thornton,Karan Gill,Yuchi Liu,Virat Shejwalkar,Jason Lin,Zhipeng Yan,Kehang Han,Thomas Buschmann,Michael Pliskin,Zhi Xing,Susheel Tatineni,Junlin Zhang,Sissie Hsiao,Gavin Buttimore,Marcus Wu,Zefei Li,Geza Kovacs,Legg Yeung,Tao Huang,Aaron Cohen,Bethanie Brownfield,Averi Nowak,Mikel Rodriguez,Tianze Shi,Hado van Hasselt,Kevin Cen,Deepanway Ghoshal,Kushal Majmundar,Weiren Yu,Warren,Chen,Danila Sinopalnikov,Hao Zhang,Vlado Galić,Di Lu,Zeyu Zheng,Maggie Song,Gary Wang,Gui Citovsky,Swapnil Gawde,Isaac Galatzer-Levy,David Silver,Ivana Balazevic,Dipanjan Das,Kingshuk Majumder,Yale Cong,Praneet Dutta,Dustin Tran,Hui Wan,Junwei Yuan,Daniel Eppens,Alanna Walton,Been Kim,Harry Ragan,James Cobon-Kerr,Lu Liu,Weijun Wang,Bryce Petrini,Jack Rae,Rakesh Shivanna,Yan Xiong,Chace Lee,Pauline Coquinot,Yiming Gu,Lisa Patel,Blake Hechtman,Aviel Boag,Orion Jankowski,Alex Wertheim,Alex Lee,Paul Covington,Hila Noga,Sam Sobell,Shanthal Vasanth,William Bono,Chirag Nagpal,Wei Fan,Xavier Garcia,Kedar Soparkar,Aybuke Turker,Nathan Howard,Sachit Menon,Yuankai Chen,Vikas Verma,Vladimir Pchelin,Harish Rajamani,Valentin Dalibard,Ana Ramalho,Yang Guo,Kartikeya Badola,Seojin Bang,Nathalie Rauschmayr,Julia Proskurnia,Sudeep Dasari,Xinyun Chen,Mikhail Sushkov,Anja Hauth,Pauline Sho,Abhinav Singh,Bilva Chandra,Allie Culp,Max Dylla,Olivier Bachem,James Besley,Heri Zhao,Timothy Lillicrap,Wei Wei,Wael Al Jishi,Ning Niu,Alban Rrustemi,Raphaël Lopez Kaufman,Ryan Poplin,Jewel Zhao,Minh Truong,Shikhar Bharadwaj,Ester Hlavnova,Eli Stickgold,Cordelia Schmid,Georgi Stephanov,Zhaoqi Leng,Frederick Liu,Léonard Hussenot,Shenil Dodhia,Juliana Vicente Franco,Lesley Katzen,Abhanshu Sharma,Sarah Cogan,Zuguang Yang,Aniket Ray,Sergi Caelles,Shen Yan,Ravin Kumar,Daniel Gillick,Renee Wong,Joshua Ainslie,Jonathan Hoech,Séb Arnold,Dan Abolafia,Anca Dragan,Ben Hora,Grace Hu,Alexey Guseynov,Yang Lu,Chas Leichner,Jinmeng Rao,Abhimanyu Goyal,Nagabhushan Baddi,Daniel Hernandez Diaz,Tim McConnell,Max Bain,Jake Abernethy,Qiqi Yan,Rylan Schaeffer,Paul Vicol,Will Thompson,Montse Gonzalez Arenas,Mathias Bellaiche,Pablo Barrio,Stefan Zinke,Riccardo Patana,Pulkit Mehta,JK Kearns,Avraham Ruderman,Scott Pollom,David D'Ambrosio,Cath Hope,Yang Yu,Andrea Gesmundo,Kuang-Huei Lee,Aviv Rosenberg,Yiqian Zhou,Yaoyiran Li,Drew Garmon,Yonghui Wu,Safeen Huda,Gil Fidel,Martin Baeuml,Jian Li,Phoebe Kirk,Rhys May,Tao Tu,Sara Mc Carthy,Toshiyuki Fukuzawa,Miranda Aperghis,Chih-Kuan Yeh,Toshihiro Yoshino,Bo Li,Austin Myers,Kaisheng Yao,Ben Limonchik,Changwan Ryu,Rohun Saxena,Alex Goldin,Ruizhe Zhao,Rocky Rhodes,Tao Zhu,Divya Tyam,Heidi Howard,Nathan Byrd,Hongxu Ma,Yan Wu,Ryan Mullins,Qingze Wang,Aida Amini,Sebastien Baur,Yiran Mao,Subhashini Venugopalan,Will Song,Wen Ding,Paul Collins,Sashank Reddi,Megan Shum,Andrei Rusu,Luisa Zintgraf,Kelvin Chan,Sheela Goenka,Mathieu Blondel,Michael Collins,Renke Pan,Marissa Giustina,Nikolai Chinaev,Christian Schuler,Ce Zheng,Jonas Valfridsson,Alyssa Loo,Alex Yakubovich,Jamie Smith,Tao Jiang,Rich Munoz,Gabriel Barcik,Rishabh Bansal,Mingyao Yang,Yilun Du,Pablo Duque,Mary Phuong,Alexandra Belias,Kunal Lad,Zeyu Liu,Tal Schuster,Karthik Duddu,Jieru Hu,Paige Kunkle,Matthew Watson,Jackson Tolins,Josh Smith,Denis Teplyashin,Garrett Bingham,Marvin Ritter,Marco Andreetto,Divya Pitta,Mohak Patel,Shashank Viswanadha,Trevor Strohman,Catalin Ionescu,Jincheng Luo,Yogesh Kalley,Jeremy Wiesner,Dan Deutsch,Derek Lockhart,Peter Choy,Rumen Dangovski,Chawin Sitawarin,Cat Graves,Tanya Lando,Joost van Amersfoort,Ndidi Elue,Zhouyuan Huo,Pooya Moradi,Jean Tarbouriech,Henryk Michalewski,Wenting Ye,Eunyoung Kim,Alex Druinsky,Florent Altché,Xinyi Chen,Artur Dwornik,Da-Cheng Juan,Rivka Moroshko,Horia Toma,Jarrod Kahn,Hai Qian,Maximilian Sieb,Irene Cai,Roman Goldenberg,Praneeth Netrapalli,Sindhu Raghuram,Yuan Gong,Lijie Fan,Evan Palmer,Yossi Matias,Valentin Gabeur,Shreya Pathak,Tom Ouyang,Don Metzler,Geoff Bacon,Srinivasan Venkatachary,Sridhar Thiagarajan,Alex Cullum,Eran Ofek,Vytenis Sakenas,Mohamed Hammad,Cesar Magalhaes,Mayank Daswani,Oscar Chang,Ashok Popat,Ruichao Li,Komal Jalan,Yanhan Hou,Josh Lipschultz,Antoine He,Wenhao Jia,Pier Giuseppe Sessa,Prateek Kolhar,William Wong,Sumeet Singh,Lukas Haas,Jay Whang,Hanna Klimczak-Plucińska,Georges Rotival,Grace Chung,Yiqing Hua,Anfal Siddiqui,Nicolas Serrano,Dongkai Chen,Billy Porter,Libin Bai,Keshav Shivam,Sho Arora,Partha Talukdar,Tom Cobley,Sangnie Bhardwaj,Evgeny Gladchenko,Simon Green,Kelvin Guu,Felix Fischer,Xiao Wu,Eric Wang,Achintya Singhal,Tatiana Matejovicova,James Martens,Hongji Li,Roma Patel,Elizabeth Kemp,Jiaqi Pan,Lily Wang,Blake JianHang Chen,Jean-Baptiste Alayrac,Navneet Potti,Erika Gemzer,Eugene Ie,Kay McKinney,Takaaki Saeki,Edward Chou,Pascal Lamblin,SQ Mah,Zach Fisher,Martin Chadwick,Jon Stritar,Obaid Sarvana,Andrew Hogue,Artem Shtefan,Hadi Hashemi,Yang Xu,Jindong Gu,Sharad Vikram,Chung-Ching Chang,Sabela Ramos,Logan Kilpatrick,Weijuan Xi,Jenny Brennan,Yinghao Sun,Abhishek Jindal,Ionel Gog,Dawn Chen,Felix Wu,Jason Lee,Sudhindra Kopalle,Srinadh Bhojanapalli,Oriol Vinyals,Natan Potikha,Burcu Karagol Ayan,Yuan Yuan,Michael Riley,Piotr Stanczyk,Sergey Kishchenko,Bing Wang,Dan Garrette,Antoine Yang,Vlad Feinberg,CJ Carey,Javad Azizi,Viral Shah,Erica Moreira,Chongyang Shi,Josh Feldman,Elizabeth Salesky,Thomas Lampe,Aneesh Pappu,Duhyeon Kim,Jonas Adler,Avi Caciularu,Brian Walker,Yunhan Xu,Yochai Blau,Dylan Scandinaro,Terry Huang,Sam El-Husseini,Abhishek Sinha,Lijie Ren,Taylor Tobin,Patrik Sundberg,Tim Sohn,Vikas Yadav,Mimi Ly,Emily Xue,Jing Xiong,Afzal Shama Soudagar,Sneha Mondal,Nikhil Khadke,Qingchun Ren,Ben Vargas,Stan Bileschi,Sarah Chakera,Cindy Wang,Boyu Wang,Yoni Halpern,Joe Jiang,Vikas Sindhwani,Petre Petrov,Pranavaraj Ponnuramu,Sanket Vaibhav Mehta,Yu Watanabe,Betty Chan,Matheus Wisniewski,Trang Pham,Jingwei Zhang,Conglong Li,Dario de Cesare,Art Khurshudov,Alex Vasiloff,Melissa Tan,Zoe Ashwood,Bobak Shahriari,Maryam Majzoubi,Garrett Tanzer,Olga Kozlova,Robin Alazard,James Lee-Thorp,Nguyet Minh Phu,Isaac Tian,Junwhan Ahn,Andy Crawford,Lauren Lax,Yuan,Shangguan,Iftekhar Naim,David Ross,Oleksandr Ferludin,Tongfei Guo,Andrea Banino,Hubert Soyer,Xiaoen Ju,Dominika Rogozińska,Ishaan Malhi,Marcella Valentine,Daniel Balle,Apoorv Kulshreshtha,Maciej Kula,Yiwen Song,Sophia Austin,John Schultz,Roy Hirsch,Arthur Douillard,Apoorv Reddy,Michael Fink,Summer Yue,Khyatti Gupta,Adam Zhang,Norman Rink,Daniel McDuff,Lei Meng,András György,Yasaman Razeghi,Ricky Liang,Kazuki Osawa,Aviel Atias,Matan Eyal,Tyrone Hill,Nikolai Grigorev,Zhengdong Wang,Nitish Kulkarni,Rachel Soh,Ivan Lobov,Zachary Charles,Sid Lall,Kazuma Hashimoto,Ido Kessler,Victor Gomes,Zelda Mariet,Danny Driess,Alessandro Agostini,Canfer Akbulut,Jingcao Hu,Marissa Ikonomidis,Emily Caveness,Kartik Audhkhasi,Saurabh Agrawal,Ioana Bica,Evan Senter,Jayaram Mudigonda,Kelly Chen,Jingchen Ye,Xuanhui Wang,James Svensson,Philipp Fränken,Josh Newlan,Li Lao,Eva Schnider,Sami Alabed,Joseph Kready,Jesse Emond,Afief Halumi,Tim Zaman,Chengxi Ye,Naina Raisinghani,Vilobh Meshram,Bo Chang,Ankit Singh Rawat,Axel Stjerngren,Sergey Levi,Rui Wang,Xiangzhu Long,Mitchelle Rasquinha,Steven Hand,Aditi Mavalankar,Lauren Agubuzu,Sudeshna Roy,Junquan Chen,Jarek Wilkiewicz,Hao Zhou,Michal Jastrzebski,Qiong Hu,Agustin Dal Lago,Ramya Sree Boppana,Wei-Jen Ko,Jennifer Prendki,Yao Su,Zhi Li,Eliza Rutherford,Girish Ramchandra Rao,Ramona Comanescu,Adrià Puigdomènech,Qihang Chen,Dessie Petrova,Christine Chan,Vedrana Milutinovic,Felipe Tiengo Ferreira,Chin-Yi Cheng,Ming Zhang,Tapomay Dey,Sherry Yang,Ramesh Sampath,Quoc Le,Howard Zhou,Chu-Cheng Lin,Hoi Lam,Christine Kaeser-Chen,Kai Hui,Dean Hirsch,Tom Eccles,Basil Mustafa,Shruti Rijhwani,Morgane Rivière,Yuanzhong Xu,Junjie Wang,Xinyang Geng,Xiance Si,Arjun Khare,Cheolmin Kim,Vahab Mirrokni,Kamyu Lee,Khuslen Baatarsukh,Nathaniel Braun,Lisa Wang,Pallavi LV,Richard Tanburn,Yuvein,Zhu,Fangda Li,Setareh Ariafar,Dan Goldberg,Ken Burke,Daniil Mirylenka,Meiqi Guo,Olaf Ronneberger,Hadas Natalie Vogel,Liqun Cheng,Nishita Shetty,Johnson Jia,Thomas Jimma,Corey Fry,Ted Xiao,Martin Sundermeyer,Ryan Burnell,Yannis Assael,Mario Pinto,JD Chen,Rohit Sathyanarayana,Donghyun Cho,Jing Lu,Rishabh Agarwal,Sugato Basu,Lucas Gonzalez,Dhruv Shah,Meng Wei,Dre Mahaarachchi,Rohan Agrawal,Tero Rissa,Yani Donchev,Ramiro Leal-Cavazos,Adrian Hutter,Markus Mircea,Alon Jacovi,Faruk Ahmed,Jiageng Zhang,Shuguang Hu,Bo-Juen Chen,Jonni Kanerva,Guillaume Desjardins,Andrew Lee,Nikos Parotsidis,Asier Mujika,Tobias Weyand,Jasper Snoek,Jo Chick,Kai Chen,Paul Chang,Ethan Mahintorabi,Zi Wang,Tolly Powell,Orgad Keller,Abhirut Gupta,Claire Sha,Kanav Garg,Nicolas Heess,Ágoston Weisz,Cassidy Hardin,Bartek Wydrowski,Ben Coleman,Karina Zainullina,Pankaj Joshi,Alessandro Epasto,Terry Spitz,Binbin Xiong,Kai Zhao,Arseniy Klimovskiy,Ivy Zheng,Johan Ferret,Itay Yona,Waleed Khawaja,Jean-Baptiste Lespiau,Maxim Krikun,Siamak Shakeri,Timothee Cour,Bonnie Li,Igor Krivokon,Dan Suh,Alex Hofer,Jad Al Abdallah,Nikita Putikhin,Oscar Akerlund,Silvio Lattanzi,Anurag Kumar,Shane Settle,Himanshu Srivastava,Folawiyo Campbell-Ajala,Edouard Rosseel,Mihai Dorin Istin,Nishanth Dikkala,Anand Rao,Nick Young,Kate Lin,Dhruva Bhaswar,Yiming Wang,Jaume Sanchez Elias,Kritika Muralidharan,James Keeling,Dayou Du,Siddharth Gopal,Gregory Dibb,Charles Blundell,Manolis Delakis,Jacky Liang,Marco Tulio Ribeiro,Georgi Karadzhov,Guillermo Garrido,Ankur Bapna,Jiawei Cao,Adam Sadovsky,Pouya Tafti,Arthur Guez,Coline Devin,Yixian Di,Jinwei Xing,Chuqiao,Xu,Hanzhao Lin,Chun-Te Chu,Sameera Ponda,Wesley Helmholz,Fan Yang,Yue Gao,Sara Javanmardi,Wael Farhan,Alex Ramirez,Ricardo Figueira,Khe Chai Sim,Yuval Bahat,Ashwin Vaswani,Liangzhe Yuan,Gufeng Zhang,Leland Rechis,Hanjun Dai,Tayo Oguntebi,Alexandra Cordell,Eugénie Rives,Kaan Tekelioglu,Naveen Kumar,Bing Zhang,Aurick Zhou,Nikolay Savinov,Andrew Leach,Alex Tudor,Sanjay Ganapathy,Yanyan Zheng,Mirko Rossini,Vera Axelrod,Arnaud Autef,Yukun Zhu,Zheng Zheng,Mingda Zhang,Baochen Sun,Jie Ren,Nenad Tomasev,Nithish Kannan,Amer Sinha,Charles Chen,Louis O'Bryan,Alex Pak,Aditya Kusupati,Weel Yang,Deepak Ramachandran,Patrick Griffin,Seokhwan Kim,Philipp Neubeck,Craig Schiff,Tammo Spalink,Mingyang Ling,Arun Nair,Ga-Young Joung,Linda Deng,Avishkar Bhoopchand,Lora Aroyo,Tom Duerig,Jordan Griffith,Gabe Barth-Maron,Jake Ades,Alex Haig,Ankur Taly,Yunting Song,Paul Michel,Dave Orr,Dean Weesner,Corentin Tallec,Carrie Grimes Bostock,Paul Niemczyk,Andy Twigg,Mudit Verma,Rohith Vallu,Henry Wang,Marco Gelmi,Kiranbir Sodhia,Aleksandr Chuklin,Omer Goldman,Jasmine George,Liang Bai,Kelvin Zhang,Petar Sirkovic,Efrat Nehoran,Golan Pundak,Jiaqi Mu,Alice Chen,Alex Greve,Paulo Zacchello,David Amos,Heming Ge,Eric Noland,Colton Bishop,Jeffrey Dudek,Youhei Namiki,Elena Buchatskaya,Jing Li,Dorsa Sadigh,Masha Samsikova,Dan Malkin,Damien Vincent,Robert David,Rob Willoughby,Phoenix Meadowlark,Shawn Gao,Yan Li,Raj Apte,Amit Jhindal,Stein Xudong Lin,Alex Polozov,Zhicheng Wang,Tomas Mery,Anirudh GP,Varun Yerram,Sage Stevens,Tianqi Liu,Noah Fiedel,Charles Sutton,Matthew Johnson,Xiaodan Song,Kate Baumli,Nir Shabat,Muqthar Mohammad,Hao Liu,Marco Selvi,Yichao Zhou,Mehdi Hafezi Manshadi,Chu-ling Ko,Anthony Chen,Michael Bendersky,Jorge Gonzalez Mendez,Nisarg Kothari,Amir Zandieh,Yiling Huang,Daniel Andor,Ellie Pavlick,Idan Brusilovsky,Jitendra Harlalka,Sally Goldman,Andrew Lampinen,Guowang Li,Asahi Ushio,Somit Gupta,Lei Zhang,Chuyuan Kelly Fu,Madhavi Sewak,Timo Denk,Jed Borovik,Brendan Jou,Avital Zipori,Prateek Jain,Junwen Bai,Thang Luong,Jonathan Tompson,Alice Li,Li Liu,George Powell,Jiajun Shen,Alex Feng,Grishma Chole,Da Yu,Yinlam Chow,Tongxin Yin,Eric Malmi,Kefan Xiao,Yash Pande,Shachi Paul,Niccolò Dal Santo,Adil Dostmohamed,Sergio Guadarrama,Aaron Phillips,Thanumalayan Sankaranarayana Pillai,Gal Yona,Amin Ghafouri,Preethi Lahoti,Benjamin Lee,Dhruv Madeka,Eren Sezener,Simon Tokumine,Adrian Collister,Nicola De Cao,Richard Shin,Uday Kalra,Parker Beak,Emily Nottage,Ryo Nakashima,Ivan Jurin,Vikash Sehwag,Meenu Gaba,Junhao Zeng,Kevin R. McKee,Fernando Pereira,Tamar Yakar,Amayika Panda,Arka Dhar,Peilin Zhong,Daniel Sohn,Mark Brand,Lars Lowe Sjoesund,Viral Carpenter,Sharon Lin,Shantanu Thakoor,Marcus Wainwright,Ashwin Chaugule,Pranesh Srinivasan,Muye Zhu,Bernett Orlando,Jack Weber,Ayzaan Wahid,Gilles Baechler,Apurv Suman,Jovana Mitrović,Gabe Taubman,Honglin Yu,Helen King,Josh Dillon,Cathy Yip,Dhriti Varma,Tomas Izo,Levent Bolelli,Borja De Balle Pigem,Julia Di Trapani,Fotis Iliopoulos,Adam Paszke,Nishant Ranka,Joe Zou,Francesco Pongetti,Jed McGiffin,Alex Siegman,Rich Galt,Ross Hemsley,Goran Žužić,Victor Carbune,Tao Li,Myle Ott,Félix de Chaumont Quitry,David Vilar Torres,Yuri Chervonyi,Tomy Tsai,Prem Eruvbetine,Samuel Yang,Matthew Denton,Jake Walker,Slavica Andačić,Idan Heimlich Shtacher,Vittal Premachandran,Harshal Tushar Lehri,Cip Baetu,Damion Yates,Lampros Lamprou,Mariko Iinuma,Ioana Mihailescu,Ben Albrecht,Shachi Dave,Susie Sargsyan,Bryan Perozzi,Lucas Manning,Chiyuan Zhang,Denis Vnukov,Igor Mordatch,Raia Hadsell Wolfgang Macherey,Ryan Kappedal,Jim Stephan,Aditya Tripathi,Klaus Macherey,Jun Qian,Abhishek Bhowmick,Shekoofeh Azizi,Rémi Leblond,Shiva Mohan Reddy Garlapati,Timothy Knight,Matthew Wiethoff,Wei-Chih Hung,Anelia Angelova,Georgios Evangelopoulos,Pawel Janus,Dimitris Paparas,Matthew Rahtz,Ken Caluwaerts,Vivek Sampathkumar,Daniel Jarrett,Shadi Noghabi,Antoine Miech,Chak Yeung,Geoff Clark,Henry Prior,Fei Zheng,Jean Pouget-Abadie,Indro Bhattacharya,Kalpesh Krishna,Will Bishop,Zhe Yuan,Yunxiao Deng,Ashutosh Sathe,Kacper Krasowiak,Ciprian Chelba,Cho-Jui Hsieh,Kiran Vodrahalli,Buhuang Liu,Thomas Köppe,Amr Khalifa,Lubo Litchev,Pichi Charoenpanit,Reed Roberts,Sachin Yadav,Yasumasa Onoe,Desi Ivanov,Megha Mohabey,Vighnesh Birodkar,Nemanja Rakićević,Pierre Sermanet,Vaibhav Mehta,Krishan Subudhi,Travis Choma,Will Ng,Luheng He,Kathie Wang,Tasos Kementsietsidis,Shane Gu,Mansi Gupta,Andrew Nystrom,Mehran Kazemi,Timothy Chung,Nacho Cano,Nikhil Dhawan,Yufei Wang,Jiawei Xia,Trevor Yacovone,Eric Jia,Mingqing Chen,Simeon Ivanov,Ashrith Sheshan,Sid Dalmia,Paweł Stradomski,Pengcheng Yin,Salem Haykal,Congchao Wang,Dennis Duan,Neslihan Bulut,Greg Kochanski,Liam MacDermed,Namrata Godbole,Shitao Weng,Jingjing Chen,Rachana Fellinger,Ramin Mehran,Daniel Suo,Hisham Husain,Tong He,Kaushal Patel,Joshua Howland,Randall Parker,Kelvin Nguyen,Sharath Maddineni,Chris Rawles,Mina Khan,Shlomi Cohen-Ganor,Amol Mandhane,Xinyi Wu,Chenkai Kuang,Iulia Comşa,Ramya Ganeshan,Hanie Sedghi,Adam Bloniarz,Nuo Wang Pierse,Anton Briukhov,Petr Mitrichev,Anita Gergely,Serena Zhan,Allan Zhou,Nikita Saxena,Eva Lu,Josef Dean,Ashish Gupta,Nicolas Perez-Nieves,Renjie Wu,Cory McLean,Wei Liang,Disha Jindal,Anton Tsitsulin,Wenhao Yu,Kaiz Alarakyia,Tom Schaul,Piyush Patil,Peter Sung,Elijah Peake,Hongkun Yu,Feryal Behbahani,JD Co-Reyes,Alan Ansell,Sean Sun,Clara Barbu,Jonathan Lee,Seb Noury,James Allingham,Bilal Piot,Mohit Sharma,Christopher Yew,Ivan Korotkov,Bibo Xu,Demetra Brady,Goran Petrovic,Shibl Mourad,Claire Cui,Aditya Gupta,Parker Schuh,Saarthak Khanna,Anna Goldie,Abhinav Arora,Vadim Zubov,Amy Stuart,Mark Epstein,Yun Zhu,Jianqiao Liu,Yury Stuken,Ziyue Wang,Karolis Misiunas,Dee Guo,Ashleah Gill,Ale Hartman,Zaid Nabulsi,Aurko Roy,Aleksandra Faust,Jason Riesa,Ben Withbroe,Mengchao Wang,Marco Tagliasacchi,Andreea Marzoca,James Noraky,Serge Toropov,Malika Mehrotra,Bahram Raad,Sanja Deur,Steve Xu,Marianne Monteiro,Zhongru Wu,Yi Luan,Sam Ritter,Nick Li,Håvard Garnes,Yanzhang He,Martin Zlocha,Jifan Zhu,Matteo Hessel,Will Wu,Spandana Raj Babbula,Chizu Kawamoto,Yuanzhen Li,Mehadi Hassen,Yan Wang,Brian Wieder,James Freedman,Yin Zhang,Xinyi Bai,Tianli Yu,David Reitter,XiangHai Sheng,Mateo Wirth,Aditya Kini,Dima Damen,Mingcen Gao,Rachel Hornung,Michael Voznesensky,Brian Roark,Adhi Kuncoro,Yuxiang Zhou,Rushin Shah,Anthony Brohan,Kuangyuan Chen,James Wendt,David Rim,Paul Kishan Rubenstein,Jonathan Halcrow,Michelle Liu,Ty Geri,Yunhsuan Sung,Jane Shapiro,Shaan Bijwadia,Chris Duvarney,Christina Sorokin,Paul Natsev,Reeve Ingle,Pramod Gupta,Young Maeng,Ndaba Ndebele,Kexin Zhu,Valentin Anklin,Katherine Lee,Yuan Liu,Yaroslav Akulov,Shaleen Gupta,Guolong Su,Flavien Prost,Tianlin Liu,Vitaly Kovalev,Pol Moreno,Martin Scholz,Sam Redmond,Zongwei Zhou,Alex Castro-Ros,André Susano Pinto,Dia Kharrat,Michal Yarom,Rachel Saputro,Jannis Bulian,Ben Caine,Ji Liu,Abbas Abdolmaleki,Shariq Iqbal,Tautvydas Misiunas,Mikhail Sirotenko,Shefali Garg,Guy Bensky,Huan Gui,Xuezhi Wang,Raphael Koster,Mike Bernico,Da Huang,Romal Thoppilan,Trevor Cohn,Ben Golan,Wenlei Zhou,Andrew Rosenberg,Markus Freitag,Tynan Gangwani,Vincent Tsang,Anand Shukla,Xiaoqi Ren,Minh Giang,Chi Zou,Andre Elisseeff,Charline Le Lan,Dheeru Dua,Shuba Lall,Pranav Shyam,Frankie Garcia,Sarah Nguyen,Michael Guzman,AJ Maschinot,Marcello Maggioni,Ming-Wei Chang,Karol Gregor,Lotte Weerts,Kumaran Venkatesan,Bogdan Damoc,Leon Liu,Jan Wassenberg,Lewis Ho,Becca Roelofs,Majid Hadian,François-Xavier Aubet,Yu Liang,Sami Lachgar,Danny Karmon,Yong Cheng,Amelio Vázquez-Reina,Angie Chen,Zhuyun Dai,Andy Brock,Shubham Agrawal,Chenxi Pang,Peter Garst,Mariella Sanchez-Vargas,Ivor Rendulic,Aditya Ayyar,Andrija Ražnatović,Olivia Ma,Roopali Vij,Neha Sharma,Ashwin Balakrishna,Bingyuan Liu,Ian Mackinnon,Sorin Baltateanu,Petra Poklukar,Gabriel Ibagon,Colin Ji,Hongyang Jiao,Isaac Noble,Wojciech Stokowiec,Zhihao Li,Jeff Dean,David Lindner,Mark Omernick,Kristen Chiafullo,Mason Dimarco,Vitor Rodrigues,Vittorio Selo,Garrett Honke,Xintian,Wu,Wei He,Adam Hillier,Anhad Mohananey,Vihari Piratla,Chang Ye,Chase Malik,Sebastian Riedel,Samuel Albanie,Zi Yang,Kenny Vassigh,Maria Bauza,Sheng Li,Yiqing Tao,Nevan Wichers,Andrii Maksai,Abe Ittycheriah,Ross Mcilroy,Bryan Seybold,Noah Goodman,Romina Datta,Steven M. Hernandez,Tian Shi,Yony Kochinski,Anna Bulanova,Ken Franko,Mikita Sazanovich,Nicholas FitzGerald,Praneeth Kacham,Shubha Srinivas Raghvendra,Vincent Hellendoorn,Alexander Grushetsky,Julian Salazar,Angeliki Lazaridou,Jason Chang,Jan-Thorsten Peter,Sushant Kafle,Yann Dauphin,Abhishek Rao,Filippo Graziano,Izhak Shafran,Yuguo Liao,Tianli Ding,Geng Yan,Grace Chu,Zhao Fu,Vincent Roulet,Gabriel Rasskin,Duncan Williams,Shahar Drath,Alex Mossin,Raphael Hoffmann,Jordi Orbay,Francesco Bertolini,Hila Sheftel,Justin Chiu,Siyang Xue,Yuheng Kuang,Ferjad Naeem,Swaroop Nath,Nana Nti,Phil Culliton,Kashyap Krishnakumar,Michael Isard,Pei Sun,Ayan Chakrabarti,Nathan Clement,Regev Cohen,Arissa Wongpanich,GS Oh,Ashwin Murthy,Hao Zheng,Jessica Hamrick,Oskar Bunyan,Suhas Ganesh,Nitish Gupta,Roy Frostig,John Wieting,Yury Malkov,Pierre Marcenac,Zhixin,Lai,Xiaodan Tang,Mohammad Saleh,Fedir Zubach,Chinmay Kulkarni,Huanjie Zhou,Vicky Zayats,Nan Ding,Anshuman Tripathi,Arijit Pramanik,Patrik Zochbauer,Harish Ganapathy,Vedant Misra,Zach Behrman,Hugo Vallet,Mingyang Zhang,Mukund Sridhar,Ye Jin,Mohammad Babaeizadeh,Siim Põder,Megha Goel,Divya Jain,Tajwar Nasir,Shubham Mittal,Tim Dozat,Diego Ardila,Aliaksei Severyn,Fabio Pardo,Sammy Jerome,Siyang Qin,Louis Rouillard,Amir Yazdanbakhsh,Zizhao Zhang,Shivani Agrawal,Kaushik Shivakumar,Caden Lu,Praveen Kallakuri,Rachita Chhaparia,Kanishka Rao,Charles Kwong,Asya Fadeeva,Shitij Nigam,Yan Virin,Yuan Zhang,Balaji Venkatraman,Beliz Gunel,Marc Wilson,Huiyu Wang,Abhinav Gupta,Xiaowei Xu,Adrien Ali Taïga,Kareem Mohamed,Doug Fritz,Daniel Rodriguez,Zoubin Ghahramani,Harry Askham,Lior Belenki,James Zhao,Rahul Gupta,Krzysztof Jastrzębski,Takahiro Kosakai,Kaan Katircioglu,Jon Schneider,Rina Panigrahy,Konstantinos Bousmalis,Peter Grabowski,Prajit Ramachandran,Chaitra Hegde,Mihaela Rosca,Angelo Scorza Scarpati,Kyriakos Axiotis,Ying Xu,Zach Gleicher,Assaf Hurwitz Michaely,Mandar Sharma,Sanil Jain,Christoph Hirnschall,Tal Marian,Xuhui Jia,Kevin Mather,Kilol Gupta,Linhai Qiu,Nigamaa Nayakanti,Lucian Ionita,Steven Zheng,Lucia Loher,Kurt Shuster,Igor Petrovski,Roshan Sharma,Rahma Chaabouni,Angel Yeh,James An,Arushi Gupta,Steven Schwarcz,Seher Ellis,Sam Conway-Rahman,Javier Snaider,Alex Zhai,James Atwood,Daniel Golovin,Liqian Peng,Te I,Vivian Xia,Salvatore Scellato,Mahan Malihi,Arthur Bražinskas,Vlad-Doru Ion,Younghoon Jun,James Swirhun,Soroosh Mariooryad,Jiao Sun,Steve Chien,Rey Coaguila,Ariel Brand,Yi Gao,Tom Kwiatkowski,Roee Aharoni,Cheng-Chun Lee,Mislav Žanić,Yichi Zhang,Dan Ethier,Vitaly Nikolaev,Pranav Nair,Yoav Ben Shalom,Hen Fitoussi,Jai Gupta,Hongbin Liu,Dee Cattle,Tolga Bolukbasi,Ben Murdoch,Fantine Huot,Yin Li,Chris Hahn*

主要分类: cs.CL

摘要简述: Gemini 2.X模型家族（包括Gemini 2.5 Pro和2.5 Flash）在推理、多模态理解和长上下文处理方面取得突破，支持复杂代理工作流，同时兼顾性能和成本。


<details>
  <summary>详细信息</summary>
研究动机: 推动前沿AI模型的发展，提升推理、多模态理解和长上下文处理能力，同时优化计算成本和延迟，以满足复杂代理任务的需求。

研究方法: 提出Gemini 2.X模型家族，包括高性能的Gemini 2.5 Pro（支持3小时视频内容处理）和低成本的Gemini 2.5 Flash，以及早期的Gemini 2.0 Flash和Flash-Lite模型。

研究结果: Gemini 2.5 Pro在编码和推理基准测试中达到最先进水平，支持多模态理解和长上下文处理；Gemini 2.5 Flash在低计算和延迟下提供优秀推理能力。

研究结论: Gemini 2.X模型家族全面覆盖了性能与成本的帕累托前沿，为复杂代理问题解决提供了新的可能性。

中文摘要: 本报告介绍了Gemini 2.X模型家族：Gemini 2.5 Pro和Gemini 2.5 Flash，以及早期的Gemini 2.0 Flash和Flash-Lite模型。Gemini 2.5 Pro是目前性能最强的模型，在前沿编码和推理基准测试中达到最先进水平。除了卓越的编码和推理能力外，Gemini 2.5 Pro还是一款擅长多模态理解的思维模型，能够处理长达3小时的视频内容。其独特的长上下文、多模态和推理能力组合可用于解锁新的代理工作流。Gemini 2.5 Flash以较低的计算和延迟需求提供出色的推理能力，而Gemini 2.0 Flash和Flash-Lite则以低延迟和低成本提供高性能。总体而言，Gemini 2.X模型家族全面覆盖了模型能力与成本的帕累托前沿，使用户能够探索复杂代理问题解决的边界。

</details>


### [2] [Humans overrely on overconfident language models, across languages](https://arxiv.org/abs/2507.06306)
**中文标题：人类过度依赖过度自信的语言模型：跨语言研究**

*Neil Rathi,Dan Jurafsky,Kaitlyn Zhou*

主要分类: cs.CL

摘要简述: 研究发现，大型语言模型（LLMs）在多语言环境中普遍存在过度自信问题，导致用户过度依赖其输出，且不同语言间的依赖行为存在差异。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型在全球范围内的部署，确保其在不同语言中准确传达不确定性和局限性至关重要。此前研究表明，LLMs在英语中表现出过度自信，但不同语言对认知标记（如“肯定”、“我认为”）的使用和解读差异显著。本文旨在评估LLMs在多语言环境中的安全风险。

研究方法: 研究分析了五种语言中LLMs生成的认知标记分布，并测量了用户对这些标记的依赖行为。重点关注模型在不同语言中的过度自信表现及其对用户行为的影响。

研究结果: 研究发现，LLMs在所有语言中均表现出过度自信，但不同语言间的认知标记分布存在差异（如日语中不确定性标记最多，德语和汉语中确定性标记最多）。用户在所有语言中均高度依赖自信的模型输出，但依赖行为因语言而异（如日语用户更依赖不确定性表达）。

研究结论: 研究揭示了多语言环境中LLMs过度自信的高风险，强调了基于文化和语言背景的模型安全评估的重要性。

中文摘要: 随着大型语言模型（LLMs）在全球范围内的部署，确保其在不同语言中准确传达不确定性和局限性至关重要。此前研究表明，LLMs在英语中表现出过度自信，导致用户过度依赖其输出。然而，认知标记（如“肯定”、“我认为”）的使用和解读在不同语言中差异显著。本文研究了五种语言中LLMs的语言（错误）校准、过度自信和过度依赖风险，以评估其在全球环境中的安全性。

研究发现，所有语言中均存在高度依赖风险。我们首先分析了LLMs生成的认知标记分布，发现尽管LLMs在跨语言中普遍过度自信，但也对已知的语言差异表现出敏感性。例如，模型在日语中生成的不确定性标记最多，而在德语和汉语中生成的确定性标记最多。随后，我们测量了用户在不同语言中的依赖行为，发现尽管用户在所有语言中均高度依赖自信的模型输出，但依赖行为存在跨语言差异：例如，日语用户对不确定性表达的依赖显著高于英语用户。

综合结果表明，跨语言环境中存在对过度自信模型输出的高度依赖风险。研究结果凸显了多语言语言校准的挑战，并强调了基于文化和语言背景的模型安全评估的重要性。

</details>


### [3] [ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time](https://arxiv.org/abs/2507.06313)
**中文标题：ETT：在测试时扩展语言模型的长上下文理解能力**

*Kiarash Zahirnia,Zahra Golpayegani,Walid Ahmad,Yang Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为ETT（Extend at Test-Time）的方法，用于在测试时扩展短上下文Transformer语言模型的上下文长度，以恒定的内存需求和线性计算开销实现。该方法通过高效微调模型参数，将输入上下文分块处理，显著提升了模型在长序列任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: Transformer语言模型的计算和内存开销随序列长度呈二次增长，限制了其在长序列处理中的应用。本文旨在解决这一问题，提出一种高效扩展上下文长度的方法。

研究方法: ETT方法通过在测试时对输入上下文进行分块处理，并高效微调模型参数（特别是FFN的第二层），以恒定的内存需求和线性计算开销扩展模型的上下文长度。

研究结果: 在LongBench上，ETT成功将GPT-Large和Phi-2的上下文长度从1k扩展到32k，模型准确率提升高达30%。研究发现，仅微调FFN的第二层比全参数微调更有效。

研究结论: ETT方法显著提升了语言模型在长序列任务中的表现，同时揭示了FFN第二层微调的重要性，为未来长上下文模型优化提供了新思路。

中文摘要: 基于Transformer的语言模型的计算和内存开销随序列长度呈二次增长，这为处理长序列带来了挑战。本文提出了一种名为ETT（Extend at Test-Time）的方法，用于在测试时扩展短上下文Transformer语言模型的上下文长度，以恒定的内存需求和线性计算开销实现。ETT通过对输入上下文进行分块处理，并高效微调模型参数，实现了上下文长度的扩展。我们在LongBench上评估了ETT，将GPT-Large和Phi-2的上下文长度从1k扩展到32k，模型准确率提升高达30%。此外，我们还研究了如何高效地将上下文信息存储在模型权重中。通过详细的消融实验，我们发现仅微调FFN的第二层比全参数微调更有效，进一步提升了模型的准确率。

</details>


### [4] [Could the Road to Grounded, Neuro-symbolic AI be Paved with Words-as-Classifiers?](https://arxiv.org/abs/2507.06335)
**中文标题：通往接地、神经符号AI的道路是否由“词即分类器”铺就？**

*Casey Kennington,David Schlangen*

主要分类: cs.CL

摘要简述: 本文探讨了通过“词即分类器”模型统一形式、分布和接地语义理论的可能性，并回顾了相关文献、认知科学研究和实验，提出了一个基于该模型的统一语义框架。


<details>
  <summary>详细信息</summary>
研究动机: 当前的形式、分布和接地语义理论各有优缺点，研究试图通过“词即分类器”模型整合三者优势，以推动语言模型的进一步发展。

研究方法: 回顾了“词即分类器”模型在文献中的应用，结合认知科学研究为其提供理论支持，并通过小型实验验证其有效性。

研究结果: “词即分类器”模型在形式化和分布化语言模型中表现良好，且在交互对话环境中经过充分测试，展示了其潜力。

研究结论: “词即分类器”模型为统一形式、分布和接地语义理论提供了一条可行路径，未来可进一步扩展其应用。

中文摘要: 形式、分布和接地语义理论各有用途和局限。近年来，通过添加视觉知识接地语言模型成为趋势，同时也有呼吁用符号方法丰富语言模型，以结合形式、分布和接地理论的优点。本文试图论证，统一这三个语义领域的潜在路径之一是“词即分类器”模型。该模型是一种词级接地语义模型，已被纳入文献中的形式化和分布化语言模型，并在交互对话环境中得到充分测试。我们回顾了相关文献，通过认知科学研究为“词即分类器”模型提供动机，并描述了一个小型实验。最后，我们勾勒了一个通过“词即分类器”模型统一的语义框架。

</details>


### [5] [Evaluating Morphological Alignment of Tokenizers in 70 Languages](https://arxiv.org/abs/2507.06378)
**中文标题：评估70种语言中分词器的形态学对齐性**

*Catherine Arnett,Marisa Hudspeth,Brendan O'Connor*

主要分类: cs.CL

摘要简述: 本文扩展了MorphScore工具，支持70种语言，评估分词器在保留语言学上有意义的子词方面的质量。研究发现，形态学对齐对模型性能的方差解释有限。


<details>
  <summary>详细信息</summary>
研究动机: 分词是语言建模的关键步骤，但如何有效评估分词器质量尚不明确。本文旨在通过形态学对齐评估分词器质量，并探讨其对模型性能的影响。

研究方法: 扩展MorphScore工具至70种语言，改进其灵活性和局限性，并通过五种预训练语言模型在七项任务中验证形态学对齐与模型性能的相关性。

研究结果: 形态学对齐对模型性能的方差解释较少，表明其单独不足以衡量与模型性能相关的分词质量维度。

研究结论: 形态学对齐虽有助于评估分词器质量，但对模型性能的影响有限，需结合其他维度进行更全面的评估。

中文摘要: 分词是语言建模的关键步骤，对模型训练和性能有重要影响，但如何有效评估分词器质量仍不明确。分词器质量的一个维度是其在多大程度上保留语言学上有意义的子词，即分词边界与单词内部形态学边界的对齐。我们扩展了MorphScore（Arnett & Bergen，2025），从原先支持的22种语言增至70种。更新后的MorphScore在评估上更具灵活性，并解决了原始版本的一些局限性。随后，我们通过五种预训练语言模型在七项任务中（样本中每种语言至少一项任务）验证了形态学对齐分数与下游任务性能的相关性。研究发现，形态学对齐对模型性能的方差解释较少，表明其单独不足以衡量与模型性能相关的分词质量维度。

</details>


### [6] [Hypermagmas and Colored Operads: Heads, Phases, and Theta Roles](https://arxiv.org/abs/2507.06393)
**中文标题：超群与彩色操作数：头、阶段与θ角色**

*Matilde Marcolli,Riny Huijbregts,Richard K. Larson*

主要分类: cs.CL

摘要简述: 本文通过将句法对象的头函数扩展为超群结构，展示了c-command关系与群操作兼容，m-command关系与超群兼容。进一步将头、补足语、指示语、修饰语位置及扩展投射中的阶段结构表述为彩色操作数的芽生成系统，类似于θ角色的结构。此外，通过彩色操作数的特殊生成形式，自由生成的句法对象可通过彩色合并等效过滤，并与超群结构关联。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索句法对象的头函数如何扩展为超群结构，并验证其与c-command和m-command关系的兼容性。同时，试图将句法结构（如头、补足语、阶段等）与θ角色结构统一表述为彩色操作数，以简化句法生成与过滤的规则。

研究方法: 方法包括将头函数扩展为超群结构，验证其与c-command和m-command的兼容性；将句法结构表述为彩色操作数的芽生成系统；通过彩色合并实现句法对象的过滤；并将移动规则（如内部合并、阶段不可穿透性条件等）统一为彩色操作数的生成形式。

研究结果: 结果表明，超群结构与句法操作兼容，且句法结构可通过彩色操作数统一表述。彩色合并等效于自由生成对象的过滤，移动规则可嵌入彩色操作数的生成形式中。

研究结论: 结论是超群结构和彩色操作数为句法分析提供了统一框架，简化了句法生成与过滤的规则，并揭示了移动规则与θ角色分配之间的兼容性。

中文摘要: 我们展示了句法对象的头函数将群结构扩展为超群，其中c-command关系与群操作兼容，m-command关系与超群兼容。随后，头、补足语、指示语、额外修饰语位置及扩展投射中的阶段结构可表述为彩色操作数的芽生成系统，类似于θ角色的结构。由于彩色操作数生成形式的特殊性，自由生成的句法对象通过这些着色规则的过滤可等效表述为通过彩色合并的结构形成过程中的过滤，进而与超群结构关联。内部合并的移动规则、扩展投射原则、空范畴原则及阶段不可穿透性条件均被纳入彩色操作数的生成形式中。阶段结构与θ角色分配之间的移动兼容性可通过各自的彩色操作数及彩色操作数的转导表述。

</details>


### [7] [PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning](https://arxiv.org/abs/2507.06415)
**中文标题：PERK：长上下文推理作为参数高效的测试时学习**

*Zeming Chen,Angelika Romanou,Gail Weiss,Antoine Bosselut*

主要分类: cs.CL

摘要简述: 本文提出了一种名为PERK的参数高效方法，用于在测试时通过轻量级模型适配器学习编码长上下文信息，显著提升了长上下文推理任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 长上下文推理需要从大量噪声输入中准确识别相关信息。现有方法在测试时将上下文直接编码到模型参数中，但内存消耗过大，难以应用于长上下文场景。因此，研究提出了一种更高效的方法。

研究方法: PERK采用两层嵌套优化循环：内层循环快速将上下文编码为低秩适配器（LoRA），作为基础模型的高效记忆模块；外层循环学习如何利用更新后的适配器从长上下文中准确回忆和推理相关信息。

研究结果: 实验表明，PERK在多个长上下文推理任务中表现优异，相比标准提示方法，性能提升显著（小模型提升90%，大模型提升27%），且在推理复杂度、长度外推和信息位置方面更具鲁棒性。

研究结论: PERK在训练时内存消耗较大，但在推理时比提示方法更高效，为长上下文推理提供了一种可扩展的解决方案。

中文摘要: 长上下文推理需要从大量噪声输入中准确识别相关信息。先前研究表明，通过测试时学习将上下文直接编码到模型参数中可以有效实现噪声信息的推理。然而，支持测试时学习的元学习方法内存消耗过高，难以应用于长上下文场景。本文提出PERK（参数高效知识推理），一种可扩展的方法，通过在测试时对轻量级模型适配器进行梯度更新来学习编码长输入上下文。具体而言，PERK在元训练阶段采用两层嵌套优化循环：内层循环快速将上下文编码为低秩适配器（LoRA），作为基础模型的高效记忆模块；外层循环学习如何利用更新后的适配器从编码的长上下文中准确回忆和推理相关信息。在多个长上下文推理任务上的评估表明，PERK显著优于标准提示方法，小模型（如GPT-2）性能提升高达90%，大模型（如Qwen-2.5-0.5B）提升27%。总体而言，PERK在推理复杂度、长度外推和信息位置方面更具鲁棒性。最后，研究表明，尽管PERK在训练时内存消耗较大，但在推理时比提示方法更高效。

</details>


### [8] [Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling](https://arxiv.org/abs/2507.06419)
**中文标题：奖励模型可以自我改进：基于奖励引导的对抗失败模式发现用于鲁棒奖励建模**

*Pankayaraj Pathmanathan,Furong Huang*

主要分类: cs.CL

摘要简述: 本文提出了一种名为REFORM的自改进奖励建模框架，通过奖励引导的解码方法发现奖励模型的失败模式，并利用对抗样本增强训练数据，显著提升了模型的鲁棒性和对齐质量。


<details>
  <summary>详细信息</summary>
研究动机: 奖励模型（RM）在捕捉人类偏好以对齐大型语言模型（LLM）时，常因分布偏移或对抗扰动而失效。现有方法依赖先验知识，限制了实际应用。本文旨在提出一种无需偏好分布先验的方法，发现并修复奖励模型的失败模式。

研究方法: 提出REFORM框架，通过奖励引导的受控解码发现奖励模型的失败模式，生成虚假评分响应作为对抗样本，用于增强训练数据并修复模型的对齐行为。

研究结果: 在Anthropic HH和PKU Beavertails数据集上，REFORM显著提升了奖励模型的鲁棒性，同时保持奖励质量，并在下游策略训练中表现优异。

研究结论: REFORM通过自改进机制有效提升了奖励模型的鲁棒性和对齐质量，无需依赖先验知识，具有广泛的实际应用价值。

中文摘要: 奖励建模（RM）通过捕捉人类偏好以对齐大型语言模型（LLM），广泛应用于模型微调、响应过滤和排序等任务。然而，由于人类偏好的复杂性和数据集的有限覆盖，奖励模型常因分布偏移或对抗扰动而失效。现有方法通常依赖偏好分布或失败属性的先验知识，限制了其在实际场景中的应用。本文提出了一种无需偏好分布先验的实用方法，通过奖励引导的受控解码发现奖励模型的失败模式。基于此，我们引入了REFORM，一种自改进的奖励建模框架，通过利用奖励模型自身生成虚假评分响应作为对抗样本，增强训练数据并修复模型的对齐行为。我们在Anthropic Helpful Harmless（HH）和PKU Beavertails数据集上评估了REFORM，结果表明其显著提升了鲁棒性且未牺牲奖励质量。值得注意的是，REFORM在直接评估和下游策略训练中均保持性能，并通过消除虚假相关性进一步提升了对齐质量。

</details>


### [9] [Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders](https://arxiv.org/abs/2507.06427)
**中文标题：通过稀疏自编码器探索可解释模型的任务性能**

*Shun Wang,Tyler Loakman,Youbo Lei,Yi Liu,Bohao Yang,Yuting Zhao,Dong Yang,Chenghua Lin*

主要分类: cs.CL

摘要简述: 本文通过稀疏自编码器分解大型语言模型（LLMs），提取单义特征并识别模型内部误解，从而改进提示词以提升下游任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统上，大型语言模型被视为黑盒算法，降低了可信度并阻碍了性能提升的潜在方法。本文旨在通过可解释的模型分解方法，提升LLMs的透明性和任务表现。

研究方法: 采用基于字典学习的稀疏自编码器方法，分解LLMs的多义神经元，提取单义特征，并自动识别和修正模型内部误解。

研究结果: 该方法显著提升了数学推理和隐喻检测等下游任务的性能，同时通过改进提示词增强了模型解释能力。

研究结论: 稀疏自编码器是一种有效的LLM分解工具，能够提升模型透明性和任务性能，为未来研究提供了新方向。

中文摘要: 大型语言模型（LLMs）传统上被视为黑盒算法，这降低了可信度并掩盖了提升下游任务性能的潜在方法。本文采用基于字典学习的稀疏自编码器方法，分解LLMs的多义神经元以提取单义特征。值得注意的是，我们的工作识别了模型内部误解，从而能够通过附加注释自动重构提示词，以改进LLMs的解释能力。此外，该方法在数学推理和隐喻检测等下游任务中表现出显著的性能提升。

</details>


### [10] [Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling](https://arxiv.org/abs/2507.06435)
**中文标题：气候政策话语的时间分析：基于动态嵌入式主题模型的洞察**

*Rafiu Adekoya Badekale,Adewale Akinfaderin*

主要分类: cs.CL

摘要简述: 本文提出了一种动态嵌入式主题模型（DETM），用于分析全球气候政策话语的演变。通过分析1995年至2023年联合国气候变化框架公约（UNFCCC）的政策决策，揭示了从早期关注温室气体到近期聚焦实施、技术合作等主题的转变。


<details>
  <summary>详细信息</summary>
研究动机: 政策语言的演变分析对评估全球应对气候变化等复杂挑战至关重要。传统方法如手动主题编码耗时且难以捕捉全球政策话语的复杂性，因此需要一种高效且自动化的方法。

研究方法: 采用动态嵌入式主题模型（DETM），分析UNFCCC 1995年至2023年的政策决策数据，包括预处理、模型训练和可视化时间词分布。

研究结果: 模型显示气候政策话语从早期关注温室气体和国际公约，逐渐转向实施、技术合作、能力建设、资金和全球协议等主题。DETM被证明是一种可扩展且有效的分析工具。

研究结论: DETM为分析全球政策话语演变提供了新方法，未来可扩展至其他政策领域。

中文摘要: 理解政策语言如何随时间演变对于评估全球应对气候变化等复杂挑战至关重要。时间分析帮助利益相关者（如政策制定者和研究人员）评估过去的优先事项、识别新兴主题、设计治理策略并制定缓解措施。传统方法（如手动主题编码）耗时且难以捕捉全球政策话语的复杂性和互联性。随着无监督机器学习的日益重要，这些限制在高容量、复杂和高维数据条件下得以解决。本文探索了一种新方法，应用动态嵌入式主题模型（DETM）分析全球气候政策话语的演变。这是一种概率模型，旨在捕捉主题随时间变化的动态。我们收集了1995年至2023年联合国气候变化框架公约（UNFCCC）的政策决策语料库（因COVID-19大流行导致COP26推迟，2020年数据除外）。模型揭示了从早期关注温室气体和国际公约到近期聚焦实施、技术合作、能力建设、资金和全球协议的转变。第3节介绍了建模流程，包括预处理、模型训练和时间词分布的可视化。结果表明，DETM是一种可扩展且有效的分析全球政策话语演变的工具。第4节讨论了这些发现的启示，并总结了未来方向和改进，以将此方法扩展至其他政策领域。

</details>


### [11] [Perception-Aware Policy Optimization for Multimodal Reasoning](https://arxiv.org/abs/2507.06448)
**中文标题：多模态推理中的感知感知策略优化**

*Zhenhailong Wang,Xuehang Guo,Sofia Stoica,Haiyang Xu,Hongru Wang,Hyeonjeong Ha,Xiusi Chen,Yangyi Chen,Ming Yan,Fei Huang,Heng Ji*

主要分类: cs.CL

摘要简述: 本文提出了一种名为PAPO（感知感知策略优化）的方法，通过将感知学习融入多模态推理任务中，显著提升了模型的性能，尤其是在视觉依赖性高的任务中表现更佳。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于文本的强化学习方法在多模态推理任务中表现不佳，主要问题在于视觉输入的感知能力不足。因此，作者提出了一种新的方法，旨在同时优化感知和推理能力。

研究方法: PAPO通过在GRPO目标中引入隐式感知损失（KL散度项），使模型在推理过程中同时学习感知能力。此外，作者还提出了双熵损失以解决潜在的损失滥用问题。

研究结果: 实验表明，PAPO在多种多模态基准测试中实现了4.4%的整体性能提升，在视觉依赖性高的任务中提升接近8.0%。此外，感知错误减少了30.5%。

研究结论: PAPO通过将感知学习融入强化学习目标，为多模态推理任务提供了一种有效的解决方案，并为视觉基础推理的新框架奠定了基础。

中文摘要: 可验证奖励的强化学习（RLVR）已被证明是一种赋予大型语言模型（LLM）强大多步推理能力的有效策略。然而，其设计和优化仍局限于纯文本领域，导致在多模态推理任务中表现不佳。我们发现，当前多模态推理的主要错误来源在于视觉输入的感知能力不足。为解决这一问题，我们提出了感知感知策略优化（PAPO），这是GRPO的一种简单而有效的扩展，鼓励模型在推理过程中同时学习感知能力，完全依赖内部监督信号。值得注意的是，PAPO无需额外的数据整理、外部奖励模型或专有模型支持。具体而言，我们在GRPO目标中引入了隐式感知损失（以KL散度项的形式），尽管设计简单，但在多种多模态基准测试中实现了显著的整体性能提升（4.4%）。在视觉依赖性高的任务中，提升幅度接近8.0%。我们还观察到感知错误大幅减少（30.5%），表明PAPO显著提升了感知能力。我们对PAPO进行了全面分析，并发现了一种独特的损失滥用问题，通过双熵损失进行了严格分析和缓解。总体而言，我们的工作将感知感知监督更深层次地融入了RLVR学习目标，并为鼓励视觉基础推理的新强化学习框架奠定了基础。项目页面：https://mikewangwzhl.github.io/PAPO。

</details>


### [12] [A Semantic Parsing Framework for End-to-End Time Normalization](https://arxiv.org/abs/2507.06450)
**中文标题：端到端时间归一化的语义解析框架**

*Xin Su,Sungduk Yu,Phillip Howard,Steven Bethard*

主要分类: cs.CL

摘要简述: 本文提出了一种基于SCATE框架的时间归一化方法，通过将时间表达式转换为可执行的代码，利用大语言模型生成标注数据，并训练小型本地模型，实现了高效、准确且可解释的时间归一化。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于ISO-TimeML的时间归一化方法表达能力有限，难以处理复杂的时间表达式（如组合式、事件相关和多跨度表达式）。本文旨在通过SCATE框架和代码生成任务解决这些问题。

研究方法: 将时间归一化任务定义为代码生成任务，基于SCATE框架设计符号化和组合式操作符。开发了可执行的SCATE Python库，并利用大语言模型生成标注数据，通过数据增强训练小型本地模型。

研究结果: 实验表明，基于增强数据训练的小型模型性能优于其父代大语言模型，实现了高效、准确且可解释的时间归一化。

研究结论: 通过SCATE框架和代码生成任务，本文提出了一种创新的时间归一化方法，解决了传统方法的局限性，并展示了其在实际应用中的潜力。

中文摘要: 时间归一化是将自然语言时间表达式转换为机器可读表示的任务，支撑着信息检索、问答系统和临床决策等下游应用。传统基于ISO-TimeML的系统表达能力有限，难以处理组合式、事件相关和多跨度时间表达式等复杂结构。本文提出了一种基于SCATE框架的新颖时间归一化方法，将其定义为代码生成任务，通过符号化和组合式操作符定义时间语义。我们实现了完全可执行的SCATE Python库，并证明大语言模型（LLMs）能够生成可执行的SCATE代码。利用这一能力，我们开发了基于LLMs的自动数据增强流程，通过代码级验证合成大规模标注数据。实验表明，基于增强数据训练的小型本地模型性能优异，甚至超越其父代LLMs，实现了实用、准确且可解释的时间归一化。

</details>


### [13] [A Systematic Analysis of Hybrid Linear Attention](https://arxiv.org/abs/2507.06457)
**中文标题：混合线性注意力的系统分析**

*Dustin Wang,Rui-Jie Zhu,Steven Abreu,Yong Shan,Taylor Kergan,Yuqi Pan,Yuhong Chou,Zheng Li,Ge Zhang,Wenhao Huang,Jason Eshraghian*

主要分类: cs.CL

摘要简述: 本文系统评估了混合线性注意力模型，发现优秀独立线性模型在混合架构中未必表现最佳，推荐特定架构和比例以实现高效Transformer级召回。


<details>
  <summary>详细信息</summary>
研究动机: Transformer在处理长序列时面临二次复杂度和内存问题，线性注意力机制虽能缓解但召回性能有限，因此研究混合架构以结合两者优势。

研究方法: 系统评估六种线性注意力变体在五种混合比例下的表现，训练并开源72个模型（340M和1.3B参数），涵盖语言建模和召回任务。

研究结果: 语言建模性能稳定，召回性能随全注意力层增加显著提升；选择性门控、分层循环和可控遗忘对混合模型效果至关重要。

研究结论: 推荐HGRN-2或GatedDeltaNet架构，线性与全注意力比例在3:1至6:1之间，以实现高效Transformer级召回。

中文摘要: Transformer因长序列的二次复杂度和内存问题，促使采用固定隐藏状态的线性注意力机制。然而，线性模型召回性能有限，导致结合线性与全注意力层的混合架构兴起。尽管混合架构研究广泛，线性注意力组件的选择尚未深入探讨。我们系统评估了各代线性注意力模型（从向量循环到高级门控机制）在独立和混合状态下的表现。为此，我们训练并开源了72个模型：36个340M参数（20B标记）和36个1.3B参数（100B标记），涵盖六种线性注意力变体和五种混合比例。标准语言建模和召回任务测试表明，优秀独立线性模型在混合架构中未必表现最佳。语言建模性能稳定，而召回性能随全注意力层增加显著提升，尤其在3:1比例以下。研究强调选择性门控、分层循环和可控遗忘对混合模型效果的关键作用。推荐HGRN-2或GatedDeltaNet架构，线性与全注意力比例在3:1至6:1之间，以实现高效Transformer级召回。模型开源地址：https://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e。

</details>


### [14] [On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489)
**中文标题：大型语言模型言语置信度在对抗攻击中的鲁棒性研究**

*Stephen Obadinma,Xiaodan Zhu*

主要分类: cs.CL

摘要简述: 本文首次全面研究了大型语言模型（LLMs）在对抗攻击下言语置信度的鲁棒性，揭示了当前置信度表达方法的脆弱性，并呼吁设计更鲁棒的机制。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的言语置信度对其在人类-AI交互中的透明性、信任和安全性至关重要。然而，目前缺乏对其在对抗攻击下鲁棒性的研究，因此本文旨在填补这一空白。

研究方法: 作者提出了一种新颖的攻击框架，通过扰动和越狱方法攻击言语置信度分数，并测试了多种提示策略、模型规模和应用领域。

研究结果: 研究发现，当前置信度表达方法极易受攻击，常用防御技术效果有限甚至适得其反，轻微语义保留的修改即可导致误导性置信度。

研究结论: 研究强调了设计更鲁棒的LLMs置信度表达机制的紧迫性，以应对对抗攻击带来的挑战。

中文摘要: 大型语言模型（LLMs）生成的鲁棒言语置信度对其部署至关重要，以确保人类-AI交互中的透明性、信任和安全性。本文首次全面研究了对抗攻击下言语置信度的鲁棒性。我们提出了一种新颖的攻击框架，通过扰动和越狱方法攻击言语置信度分数，并表明这些攻击会严重危害置信度估计并导致频繁的答案变化。我们测试了多种提示策略、模型规模和应用领域，发现当前置信度表达方法脆弱，常用防御技术效果有限或适得其反。研究结果强调了设计更鲁棒的LLMs置信度表达机制的紧迫性，因为即使是轻微的语义保留修改也可能导致误导性置信度。

</details>


### [15] [Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings](https://arxiv.org/abs/2507.06506)
**中文标题：一语双关：基于对比学习和语音-语义嵌入的多代理双关语翻译**

*Russell Taylor,Benjamin Herbert,Michael Sana*

主要分类: cs.CL

摘要简述: 本文提出了一种结合对比学习和语音-语义嵌入的新方法，用于将英语双关语翻译成法语，旨在保留原文的幽默和创意，而非简单直译。该方法在CLEF JOKER 2025竞赛中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 双关语的翻译长期以来困扰着人工和机器翻译系统，因其需要处理语义模糊性、语音相似性及文化背景。本研究旨在填补翻译研究与计算语言学之间的空白，探索如何利用语言模型处理双关语的复杂性。

研究方法: 方法分为三阶段：1) 使用前沿大语言模型建立基线，并通过对比学习数据集优化；2) 结合语音-语义嵌入的引导式思维链流程；3) 采用多代理生成-判别框架评估并生成双关语。

研究结果: 该方法在CLEF JOKER 2025竞赛中分别获得第一和第二名，由法语母语专家手动评估，成功保留了原文的幽默和创意。

研究结论: 本研究通过语言学技术实现了双关语的翻译，提升了语言模型处理语义模糊性和文化背景的能力，为翻译和计算语言学的结合提供了新思路。

中文摘要: 跨语言翻译双关语长期以来对专业人工翻译和机器翻译系统构成独特挑战。本研究提出了一种新颖方法，通过结合前沿大语言模型和专门的双关语生成技术，将英语双关语翻译为法语。
  我们的方法分为三个阶段：首先，基于新的对比学习数据集，使用多种前沿大语言模型建立基线；其次，实施结合语音-语义嵌入的引导式思维链流程；最后，采用多代理生成-判别框架评估并生成双关语。
  我们的方法超越了直译的局限，旨在捕捉原文双关语的语言创意和幽默，而非简单复制词汇。在CLEF JOKER 2025竞赛中，我们的最佳表现分别获得第一和第二名，并由法语母语专家手动评估。
  本研究通过实现语言学技术填补了翻译研究与计算语言学之间的空白，推动了语言模型处理语义模糊性、语音相似性及文化背景的能力，为成功翻译幽默提供了新视角。

</details>


### [16] [SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers](https://arxiv.org/abs/2507.06517)
**中文标题：SpindleKV：一种平衡浅层与深层的新型KV缓存缩减方法**

*Zicong Tang,Shi Luohe,Zuchao Li,Baoyuan Qi,Guoming Liu,Lefei Zhang,Ping Wang*

主要分类: cs.CL

摘要简述: SpindleKV提出了一种新型KV缓存缩减方法，平衡浅层和深层处理，通过注意力权重驱逐和基于相似性的码本替换策略，显著减少内存消耗，同时保持模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的KV缓存内存消耗问题日益突出，现有方法在深层缓存缩减上表现较好，但对浅层缓存缩减效果不足。基于KV缓存高度相似性的观察，SpindleKV旨在平衡浅层和深层的缓存缩减需求。

研究方法: SpindleKV采用分层处理策略：对深层缓存使用基于注意力权重的驱逐方法；对浅层缓存则通过学习和合并策略生成码本进行替换。此外，SpindleKV解决了分组查询注意力（GQA）的难题。

研究结果: 在三种不同LLMs和两个常见基准测试中，SpindleKV相比基线方法实现了更好的KV缓存缩减效果，同时保持了相似甚至更优的模型性能。

研究结论: SpindleKV通过分层优化策略有效平衡了浅层和深层KV缓存的缩减需求，为LLMs推理系统的内存优化提供了新思路。

中文摘要: 近年来，大型语言模型（LLMs）取得了显著成就，但KV缓存的内存消耗问题对推理系统提出了重大挑战。现有驱逐方法揭示了KV缓存的内在冗余性，尤其在深层缓存缩减上表现出潜力，但对浅层缓存缩减效果不足。基于KV缓存高度相似性的观察，我们提出了一种新型KV缓存缩减方法SpindleKV，平衡浅层和深层处理。对于深层缓存，采用基于注意力权重的驱逐方法；对于浅层缓存，则通过学习和合并策略生成码本进行替换。此外，SpindleKV解决了其他基于注意力的驱逐方法面临的分组查询注意力（GQA）难题。在三种不同LLMs和两个常见基准测试中，SpindleKV相比基线方法实现了更好的KV缓存缩减效果，同时保持了相似甚至更优的模型性能。

</details>


### [17] [InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior](https://arxiv.org/abs/2507.06528)
**中文标题：InvestAlign：在羊群行为下克服数据稀缺以对齐大语言模型与投资者决策过程**

*Huisheng Wang,Zhuoshi Pan,Hangjing Zhang,Mingxiao Liu,Hanqing Gao,H. Vicky Zhao*

主要分类: cs.CL

摘要简述: InvestAlign提出了一种新框架，通过理论生成的简单投资问题数据训练大语言模型（LLM），解决了在羊群行为下对齐投资者决策过程中真实数据稀缺的问题。实验表明，该方法比使用真实数据训练更高效，且模型表现更接近真实用户行为。


<details>
  <summary>详细信息</summary>
研究动机: 在行为金融学中，对齐大语言模型与投资者决策过程面临真实数据稀缺的挑战。传统监督微调（SFT）依赖大量真实数据，但收集成本高且存在隐私风险。本文旨在通过理论生成数据替代真实数据，解决这一瓶颈。

研究方法: 提出InvestAlign框架，利用理论生成的简单最优投资问题数据构建高质量SFT数据集，而非依赖复杂场景的真实数据。通过理论分析证明该方法能加速模型参数收敛，并开发了基于InvestAlign微调的LLM代理InvestAgent。

研究结果: 实验显示，InvestAlign生成的数据训练LLM比真实数据更快收敛，且InvestAgent在简单和复杂投资问题中均表现出与真实用户数据更接近的对齐效果。

研究结论: InvestAlign为解决复杂最优投资问题和对齐LLM与投资者决策过程提供了一种高效且隐私友好的方法，具有广泛应用潜力。

中文摘要: 在羊群行为下对齐大语言模型（LLM）与投资者决策过程是行为金融学中的关键挑战，其根本限制在于监督微调（SFT）所需的真实用户数据稀缺。尽管SFT可以弥合LLM输出与人类行为模式之间的差距，但其对大量真实数据的依赖带来了高昂的收集成本和隐私风险。我们提出InvestAlign，一种通过理论生成的简单最优投资问题数据构建高质量SFT数据集的新框架。理论分析表明，使用InvestAlign生成的数据训练LLM比真实数据更快收敛，表明其学习效率更高。此外，我们开发了基于InvestAlign微调的LLM代理InvestAgent，在简单和复杂投资问题中均表现出比预微调模型更接近真实用户数据的对齐效果。这凸显了InvestAlign作为一种有前景的方法，能够解决复杂最优投资问题并实现LLM与羊群行为下投资者决策过程的对齐。代码已公开于https://github.com/thu-social-network-research-group/InvestAlign。

</details>


### [18] [Large Language Model for Extracting Complex Contract Information in Industrial Scenes](https://arxiv.org/abs/2507.06539)
**中文标题：工业场景中基于大语言模型的复杂合同信息提取**

*Yunyang Cao,Yanjun Li,Silong Dai*

主要分类: cs.CL

摘要简述: 本文提出了一种工业场景下复杂合同信息提取任务的高质量数据集构建方法，并基于此微调大语言模型。通过聚类分析、数据增强和模型优化，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 工业场景中的合同信息提取任务复杂且关键，但现有方法在数据质量和模型性能上存在不足。本文旨在通过高质量数据集构建和模型优化，提供高效解决方案。

研究方法: 1. 对工业合同文本进行聚类分析，利用GPT-4和GPT-3.5提取关键信息并标注高质量数据。2. 通过构建新文本实现数据增强，利用GPT-3.5生成非结构化合同文本。3. 基于高质量数据集微调大语言模型，结合LoRA、数据平衡和数据增强技术。

研究结果: 实验结果表明，模型在保证高召回率和精确度的同时，兼顾解析效率，整体性能优异。LoRA、数据平衡和数据增强显著提升了模型的准确性和鲁棒性。

研究结论: 本文提出的方法为工业合同信息提取任务提供了一种新颖高效的解决方案，显著提升了模型性能和数据质量。

中文摘要: 本文提出了一种针对工业场景中复杂合同信息提取任务的高质量数据集构建方法，并基于此微调了大语言模型。首先，对工业合同文本进行聚类分析，利用GPT-4和GPT-3.5从原始合同数据中提取关键信息，获得高质量数据标注。其次，通过构建新文本实现数据增强，利用GPT-3.5从随机组合的关键词生成非结构化合同文本，提升模型鲁棒性。最后，基于高质量数据集微调大语言模型。实验结果表明，该模型在保证高召回率和精确度的同时兼顾解析效率，整体性能优异。LoRA、数据平衡和数据增强有效提升了模型的准确性和鲁棒性。本文提出的方法为工业合同信息提取任务提供了一种新颖高效的解决方案。

</details>


### [19] [The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](https://arxiv.org/abs/2507.06565)
**中文标题：他人之瑕：一种基于LLM的科学知识生产框架**

*Juan B. Gutiérrez*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大语言模型（LLM）的科学知识生产框架，通过将人类和LLM视为平等节点，构建了一个讨论网络模型，分析了知识传播中的四种失效模式，并开发了一种开源算法（FOO）来通过同行评审提高系统的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在知识生产中存在幻觉和错误传播的问题，本文旨在通过构建讨论网络模型，研究如何通过同行评审机制提高知识传播的可靠性。

研究方法: 本文提出了一种讨论网络模型，将人类和LLM视为平等节点，定义了四种失效模式（偏离真相、自我修复、新制造和外部检测），并开发了一种开源算法（FOO）来模拟同行评审过程。

研究结果: 研究发现，仅依赖偏离真相和自我修复的网络会稳定在中等错误率；加入新制造后，错误率显著上升；而引入同行评审机制后，系统会趋向于真相主导状态。

研究结论: 本文的结论是，提高知识传播可靠性的关键在于将不完美的模型通过讨论网络相互监督，而非追求单一模型的完美。

中文摘要: 大语言模型将写作转变为人类与软件之间的实时交流。我们通过一种讨论网络模型捕捉这种新媒介，将人类和LLM视为平等节点，并追踪其言论的传播。从孤立的幻觉问题扩展到更广泛的失效模式（包括事实、逻辑或结构上的任何漏洞），我们定义了四种危害：偏离真相、自我修复、新制造和外部检测。我们开发了一个通用的讨论网络数学模型，发现仅由偏离真相和自我修复主导的网络会稳定在中等错误率；加入新制造后，错误率与当前LLM的高错误率相符。而即使对每个错误言论引入少量同行评审机会，系统也会转向真相主导状态。我们通过开源算法《他人之瑕（FOO）》实现了同行评审：一种可配置的循环过程，其中任何一组代理相互批评，并由协调者合并其裁决。这一研究既实用又具有文化意义：新媒介中的可靠性并非来自单一模型的完美，而是来自将不完美的模型连接成相互监督的网络。

</details>


### [20] [Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis](https://arxiv.org/abs/2507.06571)
**中文标题：基于多模态知识图谱的食品领域问答增强：混合问答生成与多样性分析**

*Srihari K B,Pushpak Bhattacharyya*

主要分类: cs.CL

摘要简述: 本文提出了一种结合多模态知识图谱（MMKG）与生成式AI的食品领域问答框架，通过联合微调模型显著提升了性能，并验证了结构化知识与多模态生成对提升问答可靠性和多样性的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 食品领域的问答系统需要结合丰富的结构化知识和多模态数据（如食谱、食材、图像等）以提高准确性和多样性。本文旨在通过构建大规模MMKG并融合生成式AI技术，解决传统问答系统在食品领域的局限性。

研究方法: 构建了一个包含13,000食谱、3,000食材、140,000关系和14,000图像的多模态知识图谱（MMKG），并利用40个模板和LLaVA/DeepSeek增强生成了40,000个问答对。通过联合微调Meta LLaMA 3.1-8B和Stable Diffusion 3.5-Large模型，结合混合检索-生成策略，提升了问答性能。

研究结果: 实验结果显示，联合微调使BERTScore提升16.2%，FID降低37.8%，CLIP对齐提升31.1%。诊断分析表明，CLIP不匹配率从35.2%降至7.3%，LLaVA驱动的幻觉检查确保了事实和视觉保真度。混合策略实现了94.1%的图像复用准确率和85%的合成充分性。

研究结论: 研究表明，结构化知识与多模态生成的结合显著提升了食品领域问答的可靠性和多样性，为未来多模态问答系统的设计提供了重要参考。

中文摘要: 我们提出了一种统一的食品领域问答框架，结合了大规模多模态知识图谱（MMKG）与生成式AI。我们的MMKG包含13,000个食谱、3,000种食材、140,000条关系和14,000张图像。通过40个模板和LLaVA/DeepSeek增强生成了40,000个问答对。联合微调Meta LLaMA 3.1-8B和Stable Diffusion 3.5-Large模型，使BERTScore提升16.2%，FID降低37.8%，CLIP对齐提升31.1%。诊断分析（基于CLIP的不匹配检测从35.2%降至7.3%和LLaVA驱动的幻觉检查）确保了事实和视觉保真度。混合检索-生成策略实现了94.1%的图像复用准确率和85%的合成充分性。结果表明，结构化知识与多模态生成的结合显著提升了食品问答的可靠性和多样性。

</details>


### [21] [Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation](https://arxiv.org/abs/2507.06607)
**中文标题：解码器-混合-解码器架构：高效长序列生成推理**

*Liliang Ren,Congcong Chen,Haoran Xu,Young Jin Kim,Adam Atkinson,Zheng Zhan,Jiankai Sun,Baolin Peng,Liyuan Liu,Shuohang Wang,Hao Cheng,Jianfeng Gao,Weizhu Chen,Yelong Shen*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SambaY的解码器-混合-解码器架构，通过引入门控记忆单元（GMU）实现跨层记忆共享，显著提升了长序列生成的推理效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管现有的混合架构（如Samba和YOCO）在序列建模中表现优异，但尚未探索状态空间模型（SSM）层间表示共享的效率潜力。本文旨在填补这一空白。

研究方法: 提出门控记忆单元（GMU），并将其应用于SambaY架构中，通过跨解码器共享自解码器的记忆读取状态，同时保留线性预填充时间复杂度和无需显式位置编码。

研究结果: 实验表明，SambaY在长上下文任务中表现优异，解码效率显著提升，且在大规模计算下展现出更低的不可约损失。最大模型在推理任务中性能优于基线，解码吞吐量提升10倍。

研究结论: SambaY通过GMU实现了高效的记忆共享，显著提升了长序列生成的推理效率，为大规模计算下的性能扩展提供了新思路。

中文摘要: 语言建模的最新进展表明，状态空间模型（SSM）在高效序列建模中具有显著优势。尽管Samba和YOCO等混合架构在性能上优于Transformer，但此前研究未探索SSM层间表示共享的效率潜力。本文提出门控记忆单元（GMU），一种简单高效的跨层记忆共享机制，并将其应用于SambaY架构中。SambaY通过跨解码器共享Samba自解码器的记忆读取状态，显著提升解码效率，保留线性预填充时间复杂度，并增强长上下文性能，同时无需显式位置编码。通过大规模实验，我们发现该模型在不可约损失上显著低于YOCO基线，表明其在大规模计算下具有更优的性能扩展性。最大模型结合差分注意力（Phi4-mini-Flash-Reasoning）在Math500、AIME24/25和GPQA Diamond等推理任务中表现优于Phi4-mini-Reasoning，且无需强化学习。在vLLM推理框架下，对2K长度提示和32K生成长度的解码吞吐量提升高达10倍。训练代码库已开源：https://github.com/microsoft/ArchScale。

</details>


### [22] [FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation](https://arxiv.org/abs/2507.06622)
**中文标题：FuDoBa：基于贝叶斯优化的文档与知识图谱表示融合方法**

*Boshko Koloski,Senja Pollak,Roberto Navigli,Blaž Škrlj*

主要分类: cs.CL

摘要简述: 本文提出FuDoBa方法，通过贝叶斯优化融合LLM生成的文档表示与领域特定知识图谱，生成低维且任务相关的表示，提升分类性能并降低计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于大语言模型（LLM）的文档表示在基准测试中表现优异，但其高维度和计算成本使其在领域特定应用中表现不佳。本文旨在通过融合LLM表示与领域知识，解决这一问题。

研究方法: FuDoBa方法利用贝叶斯优化，将LLM生成的文档嵌入与本地及外部知识图谱（如WikiData）融合，生成低维且任务相关的表示，同时提供可解释的早期融合权重。

研究结果: 在六个数据集上的实验表明，结合AutoML分类器后，FuDoBa生成的表示性能与或优于仅依赖LLM嵌入的基线方法。

研究结论: FuDoBa通过融合LLM表示与领域知识，显著提升了文档表示的效率和分类性能，同时降低了计算复杂度。

中文摘要: 基于大语言模型（LLMs）的成功，LLM生成的表示在文档嵌入基准测试中表现卓越。然而，高维且计算成本高的LLM嵌入在领域特定应用中往往过于通用或低效。为解决这一问题，我们提出FuDoBa，一种基于贝叶斯优化的方法，将LLM生成的嵌入与本地及外部知识库（如WikiData）中的领域特定结构化知识融合。这种融合生成了低维且任务相关的表示，同时降低了训练复杂度，并提供了可解释的早期融合权重以提升分类性能。我们在两个领域的六个数据集上验证了该方法的有效性，结果表明，当与基于AutoML的鲁棒分类器结合时，我们提出的表示学习方法性能与或优于仅依赖专有LLM嵌入的基线方法。

</details>


### [23] [Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review](https://arxiv.org/abs/2507.06623)
**中文标题：利用大型语言模型（LLM）和范围综述协议加速数据提取：一项复杂范围综述中的方法学研究**

*James Stewart-Evans,Emma Wilson,Tessa Langley,Andrew Prayle,Angela Hands,Karen Exley,Jo Leonardi-Bee*

主要分类: cs.CL

摘要简述: 本研究探讨了使用大型语言模型（LLM）和范围综述协议加速数据提取的方法，发现其在提取简单数据时准确率高，但在复杂数据上表现不佳，建议进一步评估性能。


<details>
  <summary>详细信息</summary>
研究动机: 范围综述的数据提取阶段资源密集，研究者希望通过LLM和综述协议加速这一过程，并评估其性能。

研究方法: 使用Claude 3.5 Sonnet模型，基于综述协议从10个证据源中提取数据，并评估两种提取方法的性能。

研究结果: 简单数据提取准确率高（83.3%和100%），复杂数据提取准确率低（9.6%和15.8%）；总体精度>90%，但召回率和F1分数较低。

研究结论: 基于综述协议的LLM方法需进一步评估性能，研究者建议在使用LLM进行数据提取时报告其表现。

中文摘要: 综述的数据提取阶段资源密集，研究者尝试使用在线大型语言模型（LLM）和综述协议加速数据提取。本研究使用Claude 3.5 Sonnet模型，基于综述协议从10个证据源中提取数据，并评估两种提取方法的性能。结果显示，提取简单、明确的引用细节时准确率较高（83.3%和100%），而提取更复杂、主观的数据项时准确率较低（9.6%和15.8%）。总体而言，两种方法的精度>90%，但召回率（<25%）和F1分数（<40%）较低。复杂范围综述的上下文、开放响应类型和方法学可能影响了性能，导致数据遗漏和错误归因。LLM反馈认为基线提取准确，并建议对引用细节和关键发现数据项进行少量修改（分别为26.7%和21.1%）。然而，在故意引入错误的数据集上重复实验时，仅检测到5%的错误。基于综述协议的方法需在更多LLM和综述场景中进行性能评估，并与传统提示工程方法比较。研究者建议在使用LLM进行数据提取或审核时评估并报告其表现。LLM反馈有助于协议调整，并可能辅助未来综述协议的起草。

</details>


### [24] [Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models](https://arxiv.org/abs/2507.06658)
**中文标题：欧洲议会演讲中的精英极化：一种基于大语言模型的新测量方法**

*Gennadii Iakovlev*

主要分类: cs.CL

摘要简述: 本文提出了一种利用人工智能检测政治人物在议会演讲中相互提及的新方法，用于测量精英极化现象。通过分析演讲中的情感温度，构建了一个反映政党间敌对情绪的指数，并验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在量化欧洲议会中精英极化现象，通过分析政治人物在演讲中相互提及的情况，揭示政党间的敌对情绪及其变化趋势。

研究方法: 利用人工智能技术检测议会演讲中的发言者和被提及者，评估情感温度，构建精英极化指数。研究覆盖了英国过去40年及匈牙利、意大利过去20年的数据。

研究结果: 研究构建的精英极化指数能够有效反映选举活动、政党危机等事件对政党间敌对情绪的影响，并可按政党和季度进行汇总分析。

研究结论: 该方法为欧盟范围内的精英极化研究提供了新的测量工具，未来可扩展为20年的时间序列数据集。

中文摘要: 本项目通过人工智能技术检测政治人物在议会演讲中的相互提及行为，提出了一种新的精英极化测量方法。研究记录了发言者和被提及者，并评估了这些评价背后的情感温度，从而绘制出精英对不同反对党的评价图景，构建了一个反映政党间敌对情绪的精英极化指数。尽管研究主要分析了英国过去40年及匈牙利、意大利过去20年的极化数据，但该方法为构建一个覆盖欧盟20年的时间序列数据集奠定了基础。研究结果可按政党和季度进行汇总，且该指数表现出良好的表面效度：能够对选举活动、国家和政党层面的危机以及政党权力更迭等事件作出反应。

</details>


### [25] [CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs](https://arxiv.org/abs/2507.06715)
**中文标题：CLI-RAG：基于检索增强的临床结构化与上下文感知文本生成框架**

*Garapati Keerthana,Manik Gupta*

主要分类: cs.CL

摘要简述: CLI-RAG是一种基于检索增强的临床文本生成框架，通过分层分块和双阶段检索机制，解决了临床数据非结构化和语义密集的挑战，显著提升了生成文本的临床相关性和一致性。


<details>
  <summary>详细信息</summary>
研究动机: 临床数据通常是非结构化且分散的，而传统的大语言模型在处理长且语义密集的临床笔记时存在上下文长度限制和遗漏关键信息的风险。CLI-RAG旨在解决这些问题，提供结构化和临床相关的文本生成。

研究方法: CLI-RAG采用分层分块策略和双阶段检索机制：全局阶段通过证据查询识别相关笔记类型，局部阶段提取高价值内容。该方法应用于MIMIC-III数据集中的15种临床笔记类型。

研究结果: 实验表明，CLI-RAG生成的进度笔记在时间和语义上保持了87.7%的对齐率，优于真实临床笔记的80.7%基线，且在不同大语言模型中表现一致。

研究结论: CLI-RAG通过结构化和临床相关的文本生成，显著提升了临床笔记的可靠性和一致性，为临床实践提供了可复现和可信赖的工具。

中文摘要: 大语言模型（LLMs）在临床文本生成中展现出潜力，但实际应用面临两大挑战：（1）患者数据高度非结构化、异构且分散于多种笔记类型；（2）临床笔记通常冗长且语义密集，导致简单提示因上下文长度限制和遗漏临床相关信息而不可行。

我们提出CLI-RAG（临床信息检索增强生成），一种基于领域特定框架的结构化临床文本生成方法。它采用分层分块策略以尊重临床文档结构，并引入任务特定的双阶段检索机制：全局阶段通过证据查询识别相关笔记类型，局部阶段提取这些笔记中的高价值内容，实现文档和章节级别的相关性。

我们将该系统应用于MIMIC-III数据集中的15种临床笔记类型，生成结构化进度笔记。实验显示，该系统在时间和语义上保持了87.7%的对齐率，优于真实临床笔记的80.7%基线。生成结果在不同LLMs间表现出高一致性，增强了可复现性、可靠性和临床信任所需的确定性行为。

</details>


### [26] [On the Effect of Uncertainty on Layer-wise Inference Dynamics](https://arxiv.org/abs/2507.06722)
**中文标题：不确定性对层间推理动态的影响**

*Sunwoo Kim,Haneul Yoo,Alice Oh*

主要分类: cs.CL

摘要简述: 研究发现，大型语言模型（LLMs）在处理确定和不确定预测时，其层间推理动态基本一致，表明不确定性并未显著影响推理过程。通过分析11个数据集和5个模型，结果显示两者的置信度在相似层突然增加。然而，更优秀的模型可能学会不同处理不确定性。


<details>
  <summary>详细信息</summary>
研究动机: 理解大型语言模型如何内部表示和处理预测是检测不确定性和防止幻觉的核心。尽管研究表明模型在隐藏状态中编码了不确定性，但不确定性如何影响隐藏状态的处理尚不明确。本文旨在探究不确定性对推理动态的影响。

研究方法: 使用Tuned Lens（Logit Lens的变体）分析11个数据集和5个模型中最终预测标记的层间概率轨迹。通过将错误预测视为具有较高认知不确定性的预测，比较确定和不确定预测的轨迹。

研究结果: 结果显示，确定和不确定预测的层间概率轨迹高度一致，两者的置信度在相似层突然增加。然而，更优秀的模型可能学会不同处理不确定性。

研究结论: 研究发现不确定性并未显著影响推理动态，挑战了利用简单方法检测不确定性的可行性。同时，展示了可解释性方法在研究不确定性影响推理方面的潜力。

中文摘要: 理解大型语言模型（LLMs）如何内部表示和处理其预测是检测不确定性和防止幻觉的核心。尽管多项研究表明模型在隐藏状态中编码了不确定性，但不确定性如何影响这些隐藏状态的处理尚不明确。本研究证明，对于确定和不确定的输出，输出标记概率在层间的动态基本一致，表明不确定性似乎并未影响推理动态。具体而言，我们使用Tuned Lens（Logit Lens的变体）分析了11个数据集和5个模型中最终预测标记的层间概率轨迹。通过将错误预测视为具有较高认知不确定性的预测，结果显示确定和不确定预测的轨迹一致，两者均在相似层观察到置信度的突然增加。我们通过展示更优秀的模型可能学会不同处理不确定性的证据来平衡这一发现。研究结果挑战了利用简单方法在推理中检测不确定性的可行性。更广泛地说，我们的工作展示了可解释性方法如何用于研究不确定性对推理的影响。

</details>


### [27] [KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution](https://arxiv.org/abs/2507.06753)
**中文标题：KAConvText：基于Kolmogorov-Arnold卷积的缅甸语句子分类新方法**

*Ye Kyaw Thu,Thura Aung,Thazin Myint Oo,Thepchai Supnithi*

主要分类: cs.CL

摘要简述: 本文首次将Kolmogorov-Arnold卷积（KAConvText）应用于句子分类，针对仇恨言论检测、新闻分类和民族语言识别任务，通过优化嵌入配置和分类头设计，取得了显著性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索Kolmogorov-Arnold卷积在文本分类中的潜力，尤其是在处理不平衡数据集和多类分类任务时，提升模型性能并增强可解释性。

研究方法: 方法包括：1）比较随机嵌入与fastText嵌入（静态和微调）；2）使用不同嵌入维度（100和300）及CBOW/Skip-gram模型；3）设计KAConvText模型，结合MLP或KAN分类头；4）与标准CNN和CNN-KAN基线对比。

研究结果: 结果显示，KAConvText-MLP结合微调fastText嵌入表现最佳：仇恨言论检测准确率91.23%（F1=0.9109），新闻分类准确率92.66%（F1=0.9267），语言识别准确率99.82%（F1=0.9982）。

研究结论: 结论表明，KAConvText在文本分类任务中具有显著优势，尤其是结合微调嵌入和KAN分类头时，性能与可解释性均得到提升。

中文摘要: 本文首次将Kolmogorov-Arnold卷积（KAConvText）应用于句子分类，涵盖三项任务：不平衡二分类仇恨言论检测、平衡多分类新闻分类及不平衡多分类民族语言识别。我们研究了多种嵌入配置，比较随机嵌入与fastText嵌入（静态和微调），嵌入维度为100和300，使用CBOW和Skip-gram模型。基线模型包括标准CNN及结合Kolmogorov-Arnold网络的CNN（CNN-KAN）。此外，我们探索了KAConvText搭配不同分类头（MLP和KAN），其中KAN头增强了模型可解释性。结果表明，KAConvText-MLP结合微调fastText嵌入表现最优：仇恨言论检测准确率91.23%（F1=0.9109），新闻分类准确率92.66%（F1=0.9267），语言识别准确率99.82%（F1=0.9982）。

</details>


### [28] [Checklist Engineering Empowers Multilingual LLM Judges](https://arxiv.org/abs/2507.06774)
**中文标题：清单工程赋能多语言LLM评估**

*Mohammad Ghiasvand Mohammadkhani,Hamid Beigy*

主要分类: cs.CL

摘要简述: 本文提出了一种基于清单工程的多语言LLM评估框架CE-Judge，无需训练即可在多种语言任务中表现优异，性能接近GPT-4o。


<details>
  <summary>详细信息</summary>
研究动机: 当前多语言文本评估依赖专有模型或大量训练数据，成本高且效率低。本文旨在开发一种无需训练的开源框架，提升多语言评估的效率和性能。

研究方法: 提出CE-Judge框架，利用清单工程的直觉，结合开源模型进行多语言评估，无需额外训练数据。

研究结果: 实验表明，CE-Judge在多种语言和基准数据集上表现优于基线模型，性能与GPT-4o相当。

研究结论: CE-Judge为多语言文本评估提供了一种高效、低成本且性能优越的解决方案。

中文摘要: 自动文本评估一直是自然语言处理（NLP）的核心问题。近年来，该领域转向使用大型语言模型（LLMs）作为评估者，即LLM-as-a-Judge范式。尽管这一方法在多语言环境中潜力巨大且易于适应，但相关研究仍有限。现有的多语言研究通常依赖专有模型或需要大量训练数据进行微调，引发了成本、时间和效率问题。本文提出基于清单工程的LLM-as-a-Judge（CE-Judge），一种无需训练的开源框架，利用清单直觉进行多语言评估。在多种语言和三个基准数据集上的实验表明，无论是点对点还是成对设置，我们的方法普遍优于基线模型，并与GPT-4o模型表现相当。

</details>


### [29] [Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications](https://arxiv.org/abs/2507.06795)
**中文标题：通过领域自适应持续预训练实现高效工业小型大语言模型：方法、评估与应用**

*Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon*

主要分类: cs.CL

摘要简述: 通过领域自适应持续预训练（DACP）提升小型大语言模型（sLLMs）在工业应用中的性能，验证其在不同基础模型和服务领域的有效性，为企业提供高效且可扩展的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 开源大语言模型（LLMs）为企业应用提供了机会，但许多组织缺乏部署和维护大规模模型的基础设施。小型LLMs（sLLMs）成为实用替代方案，但其性能有限。领域自适应持续预训练（DACP）虽被探索为领域适应方法，但其商业应用价值尚未充分验证。

研究方法: 本研究采用DACP方法，通过在不同基础模型和服务领域进行广泛实验和实际评估，验证其在提升目标领域性能的同时保留通用能力的效果。

研究结果: 实验表明，应用DACP的sLLMs在目标领域性能显著提升，同时保持通用能力，为企业级部署提供了成本高效且可扩展的解决方案。

研究结论: DACP方法有效提升了sLLMs在工业应用中的性能，为企业提供了一种经济高效的部署方案，具有广泛的应用潜力。

中文摘要: 开源大语言模型（LLMs）的出现为企业应用提供了更多机会；然而，许多组织仍缺乏部署和维护大规模模型的基础设施。因此，小型LLMs（sLLMs）成为一种实用替代方案，尽管其性能存在固有局限。虽然领域自适应持续预训练（DACP）此前已被探索为一种领域适应方法，但其在商业应用中的实用性尚未充分研究。在本研究中，我们验证了基于DACP的方法在不同基础模型和服务领域中的有效性。通过广泛的实验和实际评估，我们证明应用DACP的sLLMs在目标领域性能显著提升的同时保留了通用能力，为企业级部署提供了一种成本高效且可扩展的解决方案。

</details>


### [30] [Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams](https://arxiv.org/abs/2507.06803)
**中文标题：通过SysML从文本到模型：基于增强系统建模语言图的非结构化自然语言文本自动生成动态系统计算模型**

*Matthew Anderson Hendricks,Alice Cicirello*

主要分类: cs.CL

摘要简述: 本文提出一种通过SysML图从非结构化自然语言文本自动生成动态系统计算模型的方法，结合NLP和LLM技术，显著提升了工程动态系统的设计与部署效率。


<details>
  <summary>详细信息</summary>
研究动机: 为加速工程动态系统的设计与部署，利用领域和专家知识，从相关文档中自动生成计算模型，减少人工干预。

研究方法: 采用五步策略，利用SysML图提取组件依赖、属性和操作信息，结合NLP和LLM技术优化中间输出，如关键名词列表、关系提取等，并通过代码生成和计算模型生成步骤完成模型构建。

研究结果: 通过案例研究验证了方法的适用性，展示了从文本到简单摆模型的全流程，性能优于仅使用LLM的结果。

研究结论: 该方法不限于特定系统或领域，能有效提升动态系统模型的自动化生成效率。

中文摘要: 本文提出了一种策略，通过利用领域和专家知识，从与动态系统相关的文档库和输入文档中自动生成动态系统计算模型，以加速工程动态系统的设计与部署。该策略分为五个步骤，并利用系统建模语言图（SysML）提取组件依赖、属性和操作的准确信息。自然语言处理（NLP）策略和大型语言模型（LLM）被用于改进SysML图自动生成的中间输出，例如关键名词列表、提取的关系列表、关键短语和关键关系、块属性值、块关系以及BDD图生成。通过不同案例研究展示了自动生成SysML图的适用性。随后，通过代码生成和计算模型生成步骤，从SysML图中获得复杂动态系统的计算模型。在代码生成步骤中，NLP策略用于摘要，而LLM仅用于验证。所提出的方法不限于特定系统、领域或计算软件。通过从文本到简单摆模型的全流程示例，展示了所提出方法的适用性，其性能优于仅使用LLM的结果。

</details>


### [31] [Adaptive Termination for Multi-round Parallel Reasoning: An Universal Semantic Entropy-Guided Framework](https://arxiv.org/abs/2507.06829)
**中文标题：自适应终止的多轮并行推理：一种通用的语义熵引导框架**

*Zenan Xu,Zexuan Qiu,Guanhua Huang,Kun Li,Siheng Li,Chenchen Zhang,Kejiao Li,Qi Yi,Yuhao Jiang,Bo Zhou,Fengzong Lian,Zhanhui Kang*

主要分类: cs.CL

摘要简述: 本文提出了一种基于语义熵的自适应终止框架，结合序列推理和并行推理的优势，通过动态评估模型响应的语义多样性，实现高效的多轮推理协作。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大语言模型推理方法存在序列推理依赖固定终止条件导致效率低下，以及并行推理缺乏协调和需要额外调优的问题。本文旨在设计一种灵活的协作推理框架，结合两者的优势，并通过语义熵动态评估推理质量。

研究方法: 提出语义熵（SE）作为评估并行模型响应语义多样性的指标，利用其与准确性的负相关性动态控制推理过程，实现自适应终止。

研究结果: 实验表明，语义熵能有效衡量推理质量，提出的框架在效率和准确性上优于传统方法。

研究结论: 本文提出的语义熵引导框架为多轮协作推理提供了高效且灵活的解决方案，显著提升了推理性能。

中文摘要: 近年来，大语言模型（LLMs）的进展加速了通用人工智能的发展，其中推理时扩展成为关键技术。现有方法主要依赖序列推理（逐步扩展思维链）或并行推理（同时生成多个解决方案）来扩展推理。然而，这两种范式均存在根本性局限：序列扩展通常依赖固定的终止条件，导致效率低下或过早终止；而并行扩展缺乏并行分支间的协调，且需额外调优才能有效运行。针对这些挑战，本文旨在设计一种灵活的测试时协作推理框架，结合序列和并行推理的优势。为实现这一目标，核心挑战在于开发一种高效且准确的内在质量指标，以评估协作推理中的模型响应，实现动态控制和早期终止。为此，我们提出语义熵（SE），它量化并行模型响应的语义多样性，并因其与准确性的强负相关性而成为推理质量的稳健指标。

</details>


### [32] [Shifting from Ranking to Set Selection for Retrieval Augmented Generation](https://arxiv.org/abs/2507.06838)
**中文标题：从排序转向集合选择：检索增强生成的新方法**

*Dahyun Lee,Yongrae Jo,Haeju Park,Moontae Lee*

主要分类: cs.CL

摘要简述: 本文提出了一种从排序转向集合选择的检索增强生成方法，通过SETR模型显式识别查询的信息需求，并选择最优的段落集合以满足这些需求，显著提升了多跳问答中的检索质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的检索增强生成方法主要基于段落个体相关性进行重排序，难以满足复杂查询（如多跳问答）的信息需求。因此，需要一种能够综合考虑段落集合整体相关性的方法。

研究方法: 本文提出SETR方法，通过Chain-of-Thought推理显式识别查询的信息需求，并选择最优的段落集合以满足这些需求。

研究结果: 实验表明，SETR在多跳RAG基准测试中，在答案正确性和检索质量上均优于现有的基于LLM的重排序方法和开源基线。

研究结论: SETR为RAG系统提供了一种高效且有效的替代传统重排序方法的选择，显著提升了复杂查询的检索效果。

中文摘要: 在检索增强生成（RAG）中，检索不仅需要确保单个段落的相关性，还需确保段落集合的整体全面性。现有方法主要基于段落个体相关性对前k个段落进行重排序，往往无法满足多跳问答中复杂查询的信息需求。本文提出了一种集合式段落选择方法，并引入了SETR，该方法通过Chain-of-Thought推理显式识别查询的信息需求，并选择最优的段落集合以满足这些需求。在多跳RAG基准测试中，实验表明SETR在答案正确性和检索质量上均优于基于专有LLM的重排序方法和开源基线，为RAG系统提供了一种高效且有效的替代传统重排序方法的选择。代码已开源：https://github.com/LGAI-Research/SetR

</details>


### [33] [Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights](https://arxiv.org/abs/2507.06893)
**中文标题：开发和维护开源AI评估仓库的挑战与洞见**

*Alexandra Abbas,Celia Waggoner,Justin Olive*

主要分类: cs.CL

摘要简述: 本文总结了维护开源AI评估仓库$inspect_evals$的八个月实践经验，提出了解决社区贡献扩展、统计方法和质量控制等挑战的方案。


<details>
  <summary>详细信息</summary>
研究动机: AI评估已成为评估大型语言模型能力和安全性的关键工具，但缺乏专门的基础设施和社区协调机制。本文旨在分享维护开源AI评估仓库的挑战和解决方案。

研究方法: 通过(1)结构化队列管理框架扩展社区贡献，(2)统计方法优化重采样和跨模型比较，(3)系统性质量控制流程确保可重复性。

研究结果: 研究发现AI评估需要专门的基础设施、统计严谨性和社区协作，超越了传统软件开发实践。

研究结论: AI评估的成功实施需要结合基础设施、统计方法和社区协作，为未来类似项目提供了重要参考。

中文摘要: AI评估已成为评估大型语言模型能力和安全性的关键工具。本文分享了八个月来维护$inspect_evals$（一个包含70多个社区贡献的AI评估开源仓库）的实践经验。我们总结了实施和维护AI评估的关键挑战，并提出了解决方案，包括：(1)用于扩展社区贡献的结构化队列管理框架，(2)用于优化重采样和跨模型比较的统计方法（含不确定性量化），以及(3)确保可重复性的系统性质量控制流程。分析表明，AI评估需要超越传统软件开发实践的专门基础设施、统计严谨性和社区协调。

</details>


### [34] [SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN](https://arxiv.org/abs/2507.06895)
**中文标题：SCoRE：基于多标签对比学习和贝叶斯kNN的流线型语料库关系抽取**

*Luca Mariotti,Veronica Guidetti,Federica Mandreoli*

主要分类: cs.CL

摘要简述: SCoRE是一种高效、模块化的关系抽取系统，结合多标签对比学习和贝叶斯kNN分类器，无需微调即可适应不同语料库和知识图谱，显著降低能耗并提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着知识图谱（KG）扩展需求的增加，如何在低监督环境下高效进行关系抽取（RE）成为研究热点。现有方法通常需要微调且对噪声敏感，SCoRE旨在提供一种适应性强、噪声鲁棒且易于与预训练大语言模型（PLM）集成的解决方案。

研究方法: SCoRE结合监督对比学习和贝叶斯kNN分类器，支持多标签分类，无需微调即可灵活切换PLM。此外，提出两个新评估指标：相关性结构距离（CSD）和R精度（P@R），并发布Wiki20d基准数据集。

研究结果: 在五个基准测试中，SCoRE性能达到或超越现有最优方法，同时显著降低能耗。分析表明，增加模型复杂度会降低性能，而SCoRE的简约设计更具优势。

研究结论: SCoRE凭借高效性、模块化和可扩展性，成为现实世界关系抽取应用的理想选择。

中文摘要: 随着利用外部语料库丰富知识图谱（KG）的需求增长，关系抽取（RE）在低监督环境下的研究日益受到关注。为满足对适应性强、噪声鲁棒且能与预训练大语言模型（PLM）无缝集成的RE解决方案的需求，我们提出了SCoRE，一种模块化且经济高效的句子级RE系统。SCoRE支持轻松切换PLM，无需微调，并能平滑适应不同语料库和KG。通过将监督对比学习与贝叶斯k近邻（kNN）分类器结合用于多标签分类，即使在远程监督语料库的噪声标注下，也能提供稳健性能。为改进RE评估，我们提出两个新指标：相关性结构距离（CSD），衡量学习到的关系模式与KG结构的对齐程度；以及R精度（P@R），评估其作为推荐系统的实用性。我们还发布了Wiki20d基准数据集，模拟仅含KG标注的真实RE场景。在五个基准测试中，SCoRE性能匹配或超越现有最优方法，同时显著降低能耗。进一步分析表明，增加模型复杂度（如先前工作所示）会降低性能，凸显了SCoRE简约设计的优势。结合高效性、模块化和可扩展性，SCoRE成为现实世界RE应用的理想选择。

</details>


### [35] [VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation](https://arxiv.org/abs/2507.06899)
**中文标题：VisualTrap：通过视觉定位操纵对GUI代理的隐蔽后门攻击**

*Ziang Ye,Yang Zhang,Wentao Shi,Xiaoyu You,Fuli Feng,Tat-Seng Chua*

主要分类: cs.CL

摘要简述: 本文揭示了GUI代理在视觉定位中的漏洞，提出了一种名为VisualTrap的后门攻击方法，能够通过误导代理定位文本来劫持其行为，且攻击具有高度隐蔽性和泛化性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型视觉语言模型（LVLMs）驱动的GUI代理在自动化人机交互中的广泛应用，其与个人设备的紧密集成引发了严重的安全隐患，尤其是后门攻击等威胁尚未被充分研究。本文旨在揭示视觉定位中的漏洞，并提出一种新型后门攻击方法。

研究方法: 本文提出VisualTrap方法，通过在视觉定位预训练阶段注入有毒数据，误导代理将文本计划定位到触发位置而非目标位置。该方法使用隐蔽的视觉触发器（人眼不可见），并验证了攻击的可行性和泛化性。

研究结果: 实验结果表明，VisualTrap仅需5%的有毒数据即可有效劫持视觉定位，且攻击具有高度隐蔽性和跨环境泛化能力（如从移动端/网页端泛化到桌面端）。即使经过干净的微调，攻击仍能有效影响下游任务。

研究结论: 本文揭示了GUI代理视觉定位中的后门攻击风险，强调了进一步研究此类安全威胁的紧迫性。VisualTrap的成功攻击表明，现有GUI代理系统亟需加强安全防护措施。

中文摘要: 由大型视觉语言模型（LVLMs）驱动的图形用户界面（GUI）代理已成为自动化人机交互的革命性方法，能够以类人的方式自主操作个人设备（如手机）或应用程序以完成复杂的现实任务。然而，其与个人设备的紧密集成引发了严重的安全问题，包括后门攻击在内的许多威胁尚未被充分研究。本文揭示了GUI代理的视觉定位（将文本计划映射到GUI元素）可能引入漏洞，从而支持新型后门攻击。通过针对视觉定位的后门攻击，即使代理接收到正确的任务解决计划，其行为仍可能被破坏。为验证这一漏洞，我们提出VisualTrap方法，通过误导代理将文本计划定位到触发位置而非目标位置来劫持视觉定位。VisualTrap采用注入有毒数据的常见攻击方法，并在视觉定位预训练阶段实施攻击以确保实际可行性。实验结果表明，VisualTrap仅需5%的有毒数据和高度隐蔽的视觉触发器（人眼不可见）即可有效劫持视觉定位；且攻击可泛化到下游任务，即使经过干净的微调。此外，注入的触发器能在不同GUI环境（如从移动端/网页端泛化到桌面端）中保持有效。这些发现凸显了对GUI代理后门攻击风险进行进一步研究的紧迫性。

</details>


### [36] [MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection](https://arxiv.org/abs/2507.06908)
**中文标题：MIND：一种用于零样本有害表情包检测的多智能体框架**

*Ziyan Liu,Chunxiao Fan,Haoran Lou,Yuexin Wu,Kaiwei Deng*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MIND的多智能体框架，用于零样本有害表情包检测，无需依赖标注数据，通过检索相似表情包、双向洞察机制和多智能体辩论实现高效检测。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体的表情包迅速扩散，亟需有效方法检测有害内容。传统数据驱动方法因表情包动态变化和缺乏最新标注数据而难以应对新表情包。

研究方法: MIND框架采用三种策略：1)从未标注参考集中检索相似表情包提供上下文信息；2)提出双向洞察机制全面理解相似表情包；3)通过多智能体辩论机制实现稳健决策。

研究结果: 在三个表情包数据集上的实验表明，MIND不仅优于现有零样本方法，还能在不同模型架构和参数规模下表现出强泛化能力。

研究结论: MIND为零样本有害表情包检测提供了可扩展的解决方案，且代码已开源。

中文摘要: 社交媒体的表情包迅速扩张，凸显了检测有害内容的迫切需求。然而，传统的数据驱动方法因表情包的动态变化和缺乏最新标注数据而难以检测新表情包。为解决这一问题，我们提出了MIND，一种不依赖标注数据的多智能体框架，用于零样本有害表情包检测。MIND采用三种关键策略：1)从未标注的参考集中检索相似表情包以提供上下文信息；2)提出双向洞察机制以全面理解相似表情包；3)通过多智能体辩论机制实现稳健决策。在三个表情包数据集上的广泛实验表明，所提出的框架不仅优于现有的零样本方法，还在不同模型架构和参数规模下表现出强泛化能力，为零样本有害表情包检测提供了可扩展的解决方案。代码已发布于https://github.com/destroy-lonely/MIND。

</details>


### [37] [MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction](https://arxiv.org/abs/2507.06909)
**中文标题：MultiJustice：一个用于多被告多罪名法律预测的中文数据集**

*Xiao Wang,Jiahuan Pei,Diancheng Shui,Zhiguang Han,Xin Sun,Dawei Zhu,Xiaoyu Shen*

主要分类: cs.CL

摘要简述: 本文提出了一个名为MultiJustice的中文数据集，用于研究多被告和多罪名的法律判决预测问题，并通过实验评估了不同法律大语言模型在四种实际法律场景下的表现。


<details>
  <summary>详细信息</summary>
研究动机: 法律判决预测是一个重要的研究方向，但目前关于多被告和多罪名是否应分开处理的问题尚未充分探讨。本文旨在填补这一空白，并评估不同模型在这些复杂场景下的表现。

研究方法: 作者构建了一个多被告多罪名预测数据集（MPMCP），并在四种法律场景下（单被告单罪名、单被告多罪名、多被告单罪名、多被告多罪名）测试了多种法律大语言模型的性能，重点关注罪名预测和刑期预测任务。

研究结果: 实验结果表明，多被告多罪名场景（S4）最具挑战性，其次是单被告多罪名（S2）、多被告单罪名（S3）和单被告单罪名（S1）。不同模型的表现差异显著，例如在S4场景中，InternLM2的F1分数比S1低约4.5%，而Lawformer的F1分数则低约19.7%。

研究结论: 本文通过MultiJustice数据集揭示了多被告多罪名场景对法律判决预测的挑战性，并展示了不同模型在这些场景下的表现差异，为未来研究提供了重要参考。

中文摘要: 法律判决预测为法律从业者和研究者提供了一种有效的方法。然而，一个尚未充分探讨的研究问题是：在法律判决预测中，是否应将多被告和多罪名分开处理？为此，我们提出了一个名为多被告多罪名预测（MPMCP）的新数据集，并通过评估几种主流法律大语言模型在四种实际法律场景下的表现来寻找答案。这四种场景包括：（S1）单被告单罪名，（S2）单被告多罪名，（S3）多被告单罪名，（S4）多被告多罪名。我们在两个法律判决预测任务（罪名预测和刑期预测）上评估了该数据集。通过大量实验，我们发现多被告多罪名场景（S4）最具挑战性，其次是S2、S3和S1。不同模型的表现差异显著。例如，在S4场景中，与S1相比，InternLM2的F1分数降低了约4.5%，LogD增加了2.8%，而Lawformer的F1分数降低了约19.7%，LogD增加了19.0%。我们的数据集和代码可在https://github.com/lololo-xiao/MultiJustice-MPMCP获取。

</details>


### [38] [Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues](https://arxiv.org/abs/2507.06910)
**中文标题：探索大语言模型在预测辅导对话中导师策略与学生表现的应用**

*Fareya Ikram,Alexander Scarlatos,Andrew Lan*

主要分类: cs.CL

摘要简述: 本文探讨了现代大语言模型（如Llama 3和GPT-4o）在预测数学辅导对话中导师策略和学生表现的能力，发现即使最先进的模型也难以准确预测导师策略，但其对学生的表现有显著影响。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，在线学习的普及和AI辅导能力的提升使得辅导对话研究备受关注。导师策略对学生表现有重要影响，但目前缺乏预测导师策略的方法，因此本文旨在填补这一空白。

研究方法: 研究使用两种数学辅导对话数据集，测试了Llama 3和GPT-4o等现代大语言模型在预测导师未来行为和学生学习成果方面的表现。

研究结果: 结果表明，即使是最先进的大语言模型也难以准确预测导师策略，但导师策略对学生的表现具有显著影响。

研究结论: 研究揭示了当前大语言模型在预测导师策略方面的局限性，并强调需要开发更强大的方法来应对这一任务。

中文摘要: 近年来，随着在线学习的普及和人工智能（AI）辅导能力的提升，辅导对话研究备受关注。研究表明，导师策略对学生表现有显著影响，因此需要预测导师行为及其对学生的影响。然而，目前少有研究关注对话中导师策略的预测。为此，本文探讨了现代大语言模型（如Llama 3和GPT-4o）在预测导师未来行为和学生表现方面的能力，并使用了两种数学辅导对话数据集进行测试。研究发现，即使是最先进的大语言模型也难以准确预测导师策略，但导师策略对学生的表现具有显著影响，这表明需要更强大的方法来完成这一任务。

</details>


### [39] [Rethinking Verification for LLM Code Generation: From Generation to Testing](https://arxiv.org/abs/2507.06920)
**中文标题：重新思考LLM代码生成的验证：从生成到测试**

*Zihan Ma,Taolin Zhang,Maosong Cao,Wenwei Zhang,Minnan Luo,Songyang Zhang,Kai Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种新方法（SAGA）来改进大语言模型（LLM）代码生成的验证过程，通过多维度指标和人类-LLM协作生成更全面的测试用例，显著提高了检测率和验证准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前代码生成评估基准（如HumanEval和LiveCodeBench）的测试用例数量有限且同质化，导致细微错误未被检测，性能评估失真，影响了强化学习框架中的奖励估计。

研究方法: 提出多维度指标量化测试用例的全面性，并引入人类-LLM协作方法SAGA，结合人类编程经验和LLM推理能力，生成覆盖率和质量更高的测试用例。同时开发了TCGBench以支持测试用例生成任务的研究。

研究结果: SAGA在TCGBench上的检测率达到90.62%，验证准确率为32.58%，其生成的代码评估基准验证准确率比LiveCodeBench-v6高10.78%。

研究结论: SAGA方法显著提升了LLM代码生成的验证效果，为可靠的代码评估和强化学习框架的奖励估计奠定了基础，并为自动化对抗测试和自适应基准集成提供了可能。

中文摘要: 大语言模型（LLM）最近在HumanEval和LiveCodeBench等代码生成基准测试中取得了显著成功。然而，详细分析显示这些评估套件通常仅包含有限数量的同质化测试用例，导致细微错误未被发现。这不仅人为夸大了性能测量，还影响了利用可验证奖励的强化学习框架（RLVR）中的准确奖励估计。为解决这些关键缺陷，我们系统研究了测试用例生成（TCG）任务，提出了多维度指标以严格量化测试套件的全面性。此外，我们引入了一种人类-LLM协作方法（SAGA），结合人类编程专长和LLM推理能力，显著提升了生成测试用例的覆盖率和质量。我们还开发了TCGBench以支持TCG任务的研究。实验表明，SAGA在TCGBench上的检测率达到90.62%，验证准确率为32.58%。由SAGA合成的代码生成评估基准的验证准确率比LiveCodeBench-v6高10.78%。这些结果证明了我们方法的有效性。我们希望这项工作能为可靠的LLM代码评估建立可扩展的基础，进一步推动代码生成中的RLVR，并为自动化对抗测试合成和自适应基准集成铺平道路。

</details>


### [40] [Investigating the Robustness of Retrieval-Augmented Generation at the Query Level](https://arxiv.org/abs/2507.06956)
**中文标题：在查询层面研究检索增强生成的鲁棒性**

*Sezen Perçin,Xin Su,Qutub Sha Syed,Phillip Howard,Aleksei Kuvshinov,Leo Schwinn,Kay-Ulrich Scholl*

主要分类: cs.CL

摘要简述: 本文研究了检索增强生成（RAG）系统在查询层面的鲁棒性，发现其性能对查询的微小变化非常敏感，并提出评估框架和改进建议。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）更新新信息成本高且效率低，检索增强生成（RAG）虽能动态引入外部知识，但其性能高度依赖输入查询的质量，因此需要研究其对查询扰动的敏感性。

研究方法: 通过分析RAG流程中各组件对不同类型查询扰动的敏感性，研究其在端到端问答任务中的表现，并提出系统性评估框架。

研究结果: 实验表明，常用检索器在查询微小变化下性能显著下降，基于1092次实验结果提出了实用建议。

研究结论: RAG系统对查询变化敏感，需进一步优化其鲁棒性，提出的评估框架为实践者提供了改进方向。

中文摘要: 大型语言模型（LLMs）更新新信息的成本高且效率低。为解决这一限制，检索增强生成（RAG）被提出作为一种解决方案，能在推理过程中动态引入外部知识，提高事实一致性并减少幻觉。尽管前景广阔，RAG系统仍面临实际挑战，尤其是对输入查询质量的强烈依赖。本文研究了RAG流程中各组件对不同类型查询扰动的敏感性。分析表明，常用检索器的性能在查询微小变化下会显著下降。我们分别研究了各模块及其在端到端问答任务中的综合表现，使用了通用领域和特定领域的数据集。此外，我们提出了一个评估框架，系统性地评估RAG流程在查询层面的鲁棒性，并基于1092次实验结果提供了实用建议。

</details>


### [41] [FRaN-X: FRaming and Narratives-eXplorer](https://arxiv.org/abs/2507.06974)
**中文标题：FRaN-X：框架与叙事探索器**

*Artur Muratov,Hana Fatima Shaikh,Vanshikaa Jani,Tarek Mahmoud,Zhuohan Xie,Daniil Orel,Aaryamonvikram Singh,Yuxia Wang,Aadi Joshi,Hasan Iqbal,Ming Shan Hee,Dhruv Sahnan,Nikolaos Nikolaidis,Purificação Silvano,Dimitar Dimitrov,Roman Yangarber,Ricardo Campos,Alípio Jorge,Nuno Guimarães,Elisa Sartori,Nicolas Stefanovitch,Giovanni Da San Martino,Jakub Piskorski,Preslav Nakov*

主要分类: cs.CL

摘要简述: FRaN-X是一个自动检测实体提及并分类其叙事角色的工具，支持五种语言和两种领域，提供交互式界面帮助媒体分析师比较不同来源的叙事框架。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决自动检测和标记实体叙事角色的挑战，帮助媒体分析师更高效地分析和比较不同来源的叙事框架。

研究方法: FRaN-X采用两阶段系统，结合序列标记和细粒度角色分类，使用包含22种细粒度角色的分类法，支持五种语言和两种领域。

研究结果: 系统提供交互式网页界面，支持单篇文章分析或多篇文章对比，包括图形可视化和时间线视图，帮助用户追踪实体角色变化。

研究结论: FRaN-X通过自动化工具和交互式界面，为媒体分析师提供了高效的叙事框架分析能力，支持多语言和多领域应用。

中文摘要: 我们介绍了FRaN-X，一种自动从原始文本中检测实体提及并分类其叙事角色的框架与叙事探索器。FRaN-X采用两阶段系统，结合序列标记和细粒度角色分类，揭示实体如何被描绘为主角、反派或无辜者，使用包含22种细粒度角色的分类法。系统支持五种语言（保加利亚语、英语、印地语、俄语和葡萄牙语）和两种领域（俄乌冲突和气候变化），并提供交互式网页界面，帮助媒体分析师探索和比较不同来源的叙事框架。用户可专注于单篇文章或同时分析最多四篇文章。系统提供聚合分析，包括直观的图形可视化，突出显示一组文章推动的叙事。此外，系统还包含搜索功能和时间线视图，帮助分析师追踪实体在不同上下文中的角色变化。FRaN-X系统及训练模型采用MIT许可证，公开访问地址为https://fran-x.streamlit.app/，演示视频见https://youtu.be/VZVi-1B6yYk。

</details>


### [42] [FlexOlmo: Open Language Models for Flexible Data Use](https://arxiv.org/abs/2507.07024)
**中文标题：FlexOlmo：支持灵活数据使用的开放语言模型**

*Weijia Shi,Akshita Bhagia,Kevin Farhat,Niklas Muennighoff,Pete Walsh,Jacob Morrison,Dustin Schwenk,Shayne Longpre,Jake Poznanski,Allyson Ettinger,Daogao Liu,Margaret Li,Dirk Groeneveld,Mike Lewis,Wen-tau Yih,Luca Soldaini,Kyle Lo,Noah A. Smith,Luke Zettlemoyer,Pang Wei Koh,Hannaneh Hajishirzi,Ali Farhadi,Sewon Min*

主要分类: cs.CL

摘要简述: FlexOlmo是一种新型语言模型，支持分布式训练和数据灵活推理，无需共享数据。通过混合专家架构和领域感知路由，模型在31个任务上表现优异，平均提升41%，同时尊重数据所有者的权限。


<details>
  <summary>详细信息</summary>
研究动机: 在受监管行业或敏感数据场景中，数据共享受限，传统语言模型难以满足需求。FlexOlmo旨在解决这一问题，支持在不共享数据的情况下训练模型，并灵活控制数据访问。

研究方法: FlexOlmo采用混合专家（MoE）架构，每个专家在封闭数据集上独立训练，通过领域感知路由集成。训练数据来自FlexMix语料库，包含公开数据集和七个领域特定数据集。

研究结果: FlexOlmo在31个下游任务上表现优异，平均相对提升41%，优于现有模型合并方法10.1%，且与无数据限制的MoE模型相比表现更优。

研究结论: FlexOlmo为数据所有者和研究者提供了一种解决方案，既能利用封闭数据，又能尊重数据权限，适用于敏感或受保护数据的场景。

中文摘要: 我们介绍了FlexOlmo，这是一种新型语言模型，支持（1）无需数据共享的分布式训练，其中不同模型参数在封闭数据集上独立训练；（2）数据灵活的推理，这些参数及其关联数据可以在无需进一步训练的情况下灵活地包含或排除在模型推理中。FlexOlmo采用混合专家（MoE）架构，每个专家在封闭数据集上独立训练，并通过新的领域感知路由集成，无需联合训练。FlexOlmo在FlexMix语料库上训练，该语料库包含公开数据集和七个领域特定数据集，代表了对封闭数据集的现实近似。我们在31个多样化下游任务上评估了参数高达370亿（活跃200亿）的模型。结果表明，在公共数据上训练的通用专家可以有效地与其他数据所有者独立训练的专家结合，平均相对提升41%，同时允许用户根据数据许可或权限要求选择排除某些数据。我们的方法在相同训练FLOPs下，平均优于现有模型合并方法10.1%，并超越了无数据限制的标准MoE训练。总之，这项研究为数据所有者和受监管行业的研究者提供了一种解决方案，既能从封闭数据中受益，又能通过保持数据本地化和支持推理期间对数据访问的细粒度控制来尊重数据所有者的偏好。

</details>


### [43] [UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations](https://arxiv.org/abs/2507.07030)
**中文标题：UniConv：对话中大型语言模型的检索与响应生成的统一**

*Fengran Mo,Yifan Gao,Chuan Meng,Xin Liu,Zhuofeng Wu,Kelong Mao,Zhengyang Wang,Pei Chen,Zheng Li,Xian Li,Bing Yin,Meng Jiang*

主要分类: cs.CL

摘要简述: 本文提出了一种名为UniConv的统一模型，将密集检索和响应生成结合于对话中的大型语言模型，通过联合微调和两种机制设计，解决了现有分离模型的局限性，并在五个对话搜索数据集上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 现有对话搜索系统通常使用两个独立模型，无法同时利用模型的内在知识，导致检索与生成效果不一致。本文旨在统一检索与生成任务，提升对话系统的整体性能。

研究方法: 通过联合微调不同目标，设计两种机制以减少不一致风险并缓解数据差异，实现检索与生成的统一。

研究结果: 在五个对话搜索数据集上的实验表明，统一模型能同时提升检索和生成任务，并优于现有基线。

研究结论: UniConv模型成功统一了检索与生成任务，验证了其在对话系统中的有效性，为未来研究提供了新方向。

中文摘要: 对话搜索系统的快速发展通过支持用户与系统之间的多轮交互，彻底改变了信息获取方式。现有的对话搜索系统通常由两个不同模型构建，这种分离限制了系统同时利用模型内在知识的能力，无法确保检索对生成的有效性。现有关于统一模型的研究未能完全解决理解对话上下文、独立管理检索和生成响应的问题。本文探讨了如何在对话中统一密集检索和响应生成。我们通过联合微调不同目标，并设计两种机制以减少不一致风险并缓解数据差异。在五个对话搜索数据集上的评估表明，我们的统一模型能够同时提升两项任务，并优于现有基线。

</details>


### [44] [Discrete Diffusion Models for Language Generation](https://arxiv.org/abs/2507.07050)
**中文标题：离散扩散模型在语言生成中的应用**

*Ashen Weligalle*

主要分类: cs.CL

摘要简述: 本文研究了离散扩散模型（D3PM）在自然语言生成中的表现，与传统自回归模型（AR）进行了对比。结果显示D3PM在生成速度上优于AR，但在压缩性能上稍逊。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在连续数据（如图像、视频）生成中表现出色，但在离散数据（如自然语言）中的应用仍面临挑战。本文旨在探索离散扩散模型在语言生成中的可行性和性能。

研究方法: 采用离散去噪扩散概率模型（D3PM），与传统自回归模型（AR）进行对比。评估指标包括每词元比特数（BPT）、负对数似然（NLL）、困惑度（PPL）和批处理速度。

研究结果: D3PM的最佳BPT为5.72，均值为8.05；AR模型的BPT均值为4.59，表现更优。但D3PM的批处理速度高达每秒3.97批次，显示出并行生成的潜力。

研究结论: 离散扩散模型在语言生成中具有速度和并行化的优势，但在生成质量上仍需改进。研究为未来非自回归语言生成提供了参考。

中文摘要: 扩散模型作为一类强大的生成模型，在连续数据领域（如图像和视频生成）取得了最先进的成果。其核心机制是通过前向扩散过程将结构化数据逐步转化为高斯分布，再通过学习的反向过程重建数据。然而，由于词元依赖的复杂性和缺乏明确的生成顺序，将这一框架应用于离散数据（尤其是自然语言）仍具挑战性。本研究探讨了离散扩散模型在自然语言生成中的可行性和性能。具体而言，我们评估了离散去噪扩散概率模型（D3PM），并将其与传统自回归（AR）语言模型进行了比较。生成性能的评估指标包括每词元比特数（BPT）、负对数似然（NLL）、困惑度（PPL）和批处理速度。结果显示，性能最佳的D3PM模型的BPT为5.72，均值为8.05。AR模型在压缩性能上表现更优，BPT均值为4.59，但D3PM的批处理速度高达每秒3.97批次，显示出并行生成的潜力。所有评估均在一致条件下进行（每模型生成10万词元，固定批次大小为4），以确保公平比较。本研究详细分析了扩散模型与自回归模型的差异，强调了生成质量和效率之间的权衡。研究结果既展示了扩散模型在离散数据中的潜力，也指出了其局限性，为未来非自回归语言生成的研究提供了支持。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [Unveiling the Underwater World: CLIP Perception Model-Guided Underwater Image Enhancement](https://arxiv.org/abs/2507.06234)
**中文标题：揭示水下世界：基于CLIP感知模型的水下图像增强**

*Jiangzhong Cao,Zekai Zeng,Xu Zhang,Huan Zhang,Chunling Fan,Gangyi Jiang,Weisi Lin*

主要分类: cs.CV

摘要简述: 本文提出了一种基于CLIP感知模型的水下图像增强方法，通过结合CLIP感知损失模块和课程对比正则化，显著提升了增强图像的感知质量和内容恢复能力。


<details>
  <summary>详细信息</summary>
研究动机: 水下图像质量受光吸收和散射影响严重，现有深度学习方法常忽略人类感知且缺乏足够的解空间约束，导致增强图像感知质量下降或内容恢复不佳。

研究方法: 利用CLIP模型的视觉语义特征提取能力，学习适当的提示对来评估水下图像质量，并将其作为感知损失模块嵌入增强网络；同时结合课程对比正则化，优化增强图像在CLIP感知空间中的约束。

研究结果: 实验表明，该方法在视觉质量和泛化能力上优于现有最先进方法。

研究结论: 通过CLIP感知模型和课程对比正则化的结合，本文方法有效提升了水下图像增强的感知质量和内容恢复效果。

中文摘要: 高质量的水下图像对机器视觉任务和观感审美至关重要，但其质量受光吸收和散射严重影响。基于深度学习的水下图像增强（UIE）方法虽表现良好，但常忽略人类感知且缺乏解空间约束，导致增强图像感知质量下降或内容恢复不佳。为解决这些问题，我们提出了一种结合对比语言-图像预训练（CLIP）感知损失模块和课程对比正则化的UIE方法。首先，为开发更符合人类视觉感知的水下图像感知模型，利用CLIP模型的视觉语义特征提取能力学习适当的提示对，以映射和评估水下图像质量。随后，将该CLIP感知模型作为感知损失模块嵌入增强网络，提升增强图像的感知质量。此外，CLIP感知模型与课程对比正则化结合，增强了对增强图像在CLIP感知空间中的约束，缓解了欠增强和过增强的风险。具体而言，CLIP感知模型用于评估和分类正则化过程中负样本的学习难度，确保充分利用不同质量水平的失真图像和负样本。大量实验表明，本方法在视觉质量和泛化能力上优于现有最先进方法。

</details>


### [46] [SPARC: Concept-Aligned Sparse Autoencoders for Cross-Model and Cross-Modal Interpretability](https://arxiv.org/abs/2507.06265)
**中文标题：SPARC：概念对齐的稀疏自编码器实现跨模型与跨模态可解释性**

*Ali Nasiri-Sarvi,Hassan Rivaz,Mahdi S. Hosseini*

主要分类: cs.CV

摘要简述: SPARC提出了一种跨模型和跨模态的统一稀疏自编码器框架，通过全局TopK稀疏机制和交叉重建损失，显著提升概念对齐效果，实现高达0.80的Jaccard相似度。


<details>
  <summary>详细信息</summary>
研究动机: 现有稀疏自编码器（SAEs）为每个模型单独生成潜在概念，导致概念空间不兼容，限制了跨模型和跨模态的可解释性。SPARC旨在解决这一问题，学习一个统一的潜在空间。

研究方法: SPARC通过两种创新方法实现概念对齐：1）全局TopK稀疏机制，确保所有输入流对同一概念激活相同的潜在维度；2）交叉重建损失，显式鼓励模型间的语义一致性。

研究结果: 在Open Images数据集上，SPARC显著提升了概念对齐效果，Jaccard相似度达到0.80，比之前方法提高了三倍以上。

研究结论: SPARC创建了一个共享的稀疏潜在空间，使得不同模型和模态的潜在维度对应相似的高层概念，支持直接比较和实际应用（如文本引导的空间定位）。

中文摘要: 理解不同AI模型如何编码相同的高层概念（如对象或属性）仍具挑战性，因为每个模型通常生成独立的表示。现有可解释性方法（如稀疏自编码器SAEs）为每个模型单独生成潜在概念，导致概念空间不兼容，限制了跨模型可解释性。为此，我们提出SPARC（概念对齐的稀疏自编码器），这是一种学习跨多样架构和模态（如视觉模型DINO和多模态模型CLIP）的统一潜在空间的新框架。SPARC通过两项关键创新实现对齐：1）全局TopK稀疏机制，确保所有输入流对同一概念激活相同的潜在维度；2）交叉重建损失，显式鼓励模型间的语义一致性。在Open Images数据集上，SPARC显著提升了概念对齐效果，Jaccard相似度达到0.80，比之前方法提高了三倍以上。SPARC创建了一个共享的稀疏潜在空间，其中单个维度通常对应不同模型和模态的相似高层概念，支持无需手动对齐或模型特定分析的直接比较。基于这种对齐表示，SPARC还支持实际应用，如纯视觉模型中的文本引导空间定位和跨模型/跨模态检索。代码和模型发布于https://github.com/AtlasAnalyticsLab/SPARC。

</details>


### [47] [A Probabilistic Approach to Uncertainty Quantification Leveraging 3D Geometry](https://arxiv.org/abs/2507.06269)
**中文标题：基于3D几何的概率不确定性量化方法**

*Rushil Desai,Frederik Warburg,Trevor Darrell,Marissa Ramirez de Chanlatte*

主要分类: cs.CV

摘要简述: 本文提出BayesSDF，一种基于概率的框架，用于量化神经隐式SDF模型中的不确定性，通过拉普拉斯近似和Hessian度量实现高效且几何一致的表面不确定性估计。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在神经隐式3D表示（如SDF）中量化不确定性时，常忽略几何一致性，导致不确定性图校准不佳。BayesSDF的提出旨在解决这一问题，特别适用于需要精确表面几何和不确定性感知的科学模拟应用（如森林流体模拟）。

研究方法: BayesSDF采用拉普拉斯近似，通过基于Hessian的度量量化局部表面不稳定性，实现计算高效且表面感知的不确定性估计。

研究结果: 实验表明，BayesSDF在合成和真实数据集上均优于现有方法，其不确定性预测与重建不良的几何区域高度一致，为下游任务提供了可靠的可信度度量。

研究结论: BayesSDF为不确定性感知的3D场景重建、模拟和机器人决策奠定了坚实基础，显著提升了校准和几何一致性。

中文摘要: 在神经隐式3D表示（尤其是基于符号距离函数SDF的模型）中量化不确定性仍面临计算效率低、扩展性差和几何不一致等挑战。现有方法通常忽视直接几何整合，导致不确定性图校准不佳。本文提出BayesSDF，一种新颖的概率框架，用于量化神经隐式SDF模型中的不确定性，其动机源于科学模拟应用（如森林流体模拟），这些应用需要精确的表面几何和对几何不确定性的感知。与缺乏显式表面定义的辐射场模型（如NeRF或3D高斯泼溅）不同，SDF定义了连续且可微的几何，更适合物理建模和分析。BayesSDF利用拉普拉斯近似，通过基于Hessian的度量量化局部表面不稳定性，实现了计算高效且表面感知的不确定性估计。实验表明，该方法的不确定性预测与重建不良的几何区域高度吻合，为下游任务提供了可操作的可信度度量。在合成和真实数据集上的广泛评估显示，BayesSDF在校准和几何一致性方面均优于现有方法，为不确定性感知的3D场景重建、模拟和机器人决策奠定了坚实基础。

</details>


### [48] [LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance](https://arxiv.org/abs/2507.06272)
**中文标题：LIRA：利用局部交错区域辅助推断大型多模态模型中的分割**

*Zhang Li,Biao Yang,Qiang Liu,Shuo Zhang,Zhiyin Ma,Shuo Zhang,Liang Yin,Linger Deng,Yabo Sun,Yuliang Liu,Xiang Bai*

主要分类: cs.CV

摘要简述: LIRA是一种通过局部交错区域辅助提升大型多模态模型分割与理解能力的框架，结合语义增强特征提取器和交错局部视觉耦合，显著减少分割不准确和理解幻觉问题。


<details>
  <summary>详细信息</summary>
研究动机: 大型多模态模型在分割和理解任务中存在分割不准确和理解幻觉的问题，主要源于视觉理解能力弱和缺乏细粒度感知。LIRA旨在通过结合视觉理解与分割的互补关系来解决这些问题。

研究方法: LIRA包含两个关键组件：(1) 语义增强特征提取器（SEFE），通过融合语义和像素级特征提升对象属性推断；(2) 交错局部视觉耦合（ILVC），基于分割掩码生成局部描述以提供细粒度监督。此外，还引入了属性评估数据集（AttrEval）量化语义推断能力。

研究结果: 实验表明，LIRA在分割和理解任务中均达到最先进性能，验证了其有效性和优越性。

研究结论: LIRA通过结合语义增强和局部监督，显著提升了大型多模态模型的分割与理解能力，为未来研究提供了新方向。

中文摘要: 尽管大型多模态模型（LMMs）在分割和理解任务中展现出潜力，但仍面临分割不准确和理解幻觉的挑战，主要源于视觉理解能力弱和缺乏细粒度感知。为缓解这些问题，我们提出LIRA框架，通过两个关键组件利用视觉理解与分割的互补关系：(1) 语义增强特征提取器（SEFE）通过融合语义和像素级特征提升对象属性推断，从而实现更准确的分割；(2) 交错局部视觉耦合（ILVC）基于分割掩码提取局部特征后自回归生成局部描述，提供细粒度监督以减少幻觉。此外，我们发现对象分割精度与<seg>标记的潜在相关语义呈正相关。为量化这种关系及模型的语义推断能力，我们引入了属性评估数据集（AttrEval）。实验表明，LIRA在分割和理解任务中均达到最先进性能。代码将在https://github.com/echo840/LIRA提供。

</details>


### [49] [Advancing Offline Handwritten Text Recognition: A Systematic Review of Data Augmentation and Generation Techniques](https://arxiv.org/abs/2507.06275)
**中文标题：推进离线手写文本识别：数据增强与生成技术的系统综述**

*Yassin Hussein Rassul,Aram M. Ahmed,Polla Fattah,Bryar A. Hassan,Arwaa W. Abdulkareem,Tarik A. Rashid,Joan Lu*

主要分类: cs.CV

摘要简述: 本文系统综述了离线手写文本识别（HTR）中的数据增强与生成技术，探讨了传统方法与深度学习方法（如GAN、扩散模型和Transformer）的应用，分析了生成多样化手写样本的挑战，并提出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 离线手写文本识别系统在历史文档数字化、自动表单处理和生物识别认证中至关重要，但其性能常受限于标注训练数据的稀缺性，尤其是低资源语言和复杂脚本。本文旨在通过综述数据增强与生成技术，提升HTR系统的准确性和鲁棒性。

研究方法: 本文采用PRISMA方法论，对1,302项初始研究进行筛选，最终纳入848项研究。研究涵盖了传统数据增强方法和深度学习方法（如GAN、扩散模型和Transformer），并分析了生成多样化手写样本的挑战。

研究结果: 研究总结了现有数据集、评估指标和最新方法，揭示了生成多样化手写样本的挑战（如保持脚本真实性和解决数据稀缺问题），并提出了未来研究方向。

研究结论: 本文为离线手写文本识别领域的数据增强与生成技术提供了全面综述，指出了研究空白，并提出了未来发展方向，以推动跨语言和跨风格的手写文本生成研究。

中文摘要: 离线手写文本识别（HTR）系统在历史文档数字化、自动表单处理和生物识别认证等应用中发挥着关键作用。然而，其性能常因标注训练数据的稀缺性而受限，尤其是在低资源语言和复杂脚本中。本文全面综述了离线手写数据增强与生成技术，旨在提升HTR系统的准确性和鲁棒性。我们系统性地探讨了传统增强方法与深度学习方法（如生成对抗网络（GAN）、扩散模型和基于Transformer的方法）的最新进展。此外，我们还分析了生成多样化且真实的手写样本所面临的挑战，特别是在保持脚本真实性和解决数据稀缺性方面。本综述遵循PRISMA方法论，确保了研究筛选的结构化和严谨性。我们的分析从1,302项初始研究开始，经过去重后筛选出848项研究，数据来源于IEEE Digital Library、Springer Link、Science Direct和ACM Digital Library等主要学术资源。通过评估现有数据集、评估指标和最新方法，本综述揭示了关键研究空白，并提出了未来方向，以推动跨语言和跨风格的手写文本生成领域的发展。

</details>


### [50] [Centralized Copy-Paste: Enhanced Data Augmentation Strategy for Wildland Fire Semantic Segmentation](https://arxiv.org/abs/2507.06321)
**中文标题：集中式复制粘贴：一种用于野火语义分割的增强数据增强策略**

*Joon Tai Kim,Tianle Chen,Ziyu Dong,Nishanth Kunchala,Alexander Guller,Daniel Ospina Acero,Roger Williams,Mrinal Kumar*

主要分类: cs.CV

摘要简述: 本文提出了一种名为集中式复制粘贴数据增强（CCPDA）的方法，用于提升野火语义分割模型的性能，特别是针对火区的分割效果。该方法通过识别、集中和粘贴火区簇来增加数据多样性，显著提升了火类分割的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在野火科学研究中，获取和标注用于训练分割模型的图像成本高昂且数据稀缺。现有的公开数据集缺乏可靠的标注数据，尤其是火区的标注。因此，需要一种有效的数据增强方法来缓解这一问题。

研究方法: CCPDA方法包括三个主要步骤：(i) 在源图像中识别火区簇，(ii) 使用集中化技术聚焦火区核心，(iii) 将优化后的火区簇粘贴到目标图像上。这种方法在保持火区特性的同时增加了数据多样性。

研究结果: 通过数值分析和多目标优化比较，CCPDA方法显著提升了火类分割的性能指标，优于其他数据增强策略，尤其是在火区分割方面表现突出。

研究结论: CCPDA方法有效解决了小规模标注数据集带来的训练难题，并在野火语义分割任务中表现出色，特别是在提升火类分割性能方面具有显著优势。

中文摘要: 为训练分割模型而收集和标注图像通常成本高昂。在野火科学领域，由于缺乏可靠的公开标注数据集，这一挑战更为严峻。本文提出了集中式复制粘贴数据增强（CCPDA）方法，旨在辅助训练深度学习多类分割模型，特别关注提升火类的分割效果。CCPDA包含三个主要步骤：(i) 在源图像中识别火区簇，(ii) 应用集中化技术聚焦火区核心，(iii) 将优化后的火区簇粘贴到目标图像上。该方法在增加数据多样性的同时保留了火类的关键特征。通过数值分析和基于加权和的多目标优化方法与其他增强技术的比较，验证了CCPDA的有效性。该方法显著提升了火类分割的性能指标，而火类在操作上的重要性远高于其他类别（燃料、灰烬或背景）。数值性能评估表明，CCPDA方法有效缓解了小规模手动标注训练数据集的困难，并在所考虑的应用场景中优于其他增强策略，尤其是在提升火类分割性能方面。

</details>


### [51] [AR2: Attention-Guided Repair for the Robustness of CNNs Against Common Corruptions](https://arxiv.org/abs/2507.06332)
**中文标题：AR2：注意力引导修复提升CNN对常见损坏的鲁棒性**

*Fuyuan Zhang,Qichen Wang,Jianjun Zhao*

主要分类: cs.CV

摘要简述: 本文提出AR2方法，通过注意力引导修复提升预训练CNN对常见图像损坏的鲁棒性，无需改变模型架构，在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络在常见图像损坏（如噪声、模糊、天气和数字失真）下性能显著下降，限制了其在现实应用中的可靠性。

研究方法: AR2通过显式对齐干净图像和损坏图像的类激活图（CAMs），鼓励模型在输入扰动下保持一致的注意力，采用迭代修复策略，结合CAM引导的细化和标准微调。

研究结果: 在CIFAR-10-C、CIFAR-100-C和ImageNet-C等标准损坏基准测试中，AR2显著优于现有方法，同时保持干净数据的准确性。

研究结论: AR2为提升模型在多样化损坏环境中的可靠性提供了一种鲁棒且可扩展的解决方案。

中文摘要: 深度神经网络在暴露于常见损坏（如噪声、模糊、天气和数字失真）时性能显著下降，限制了其在现实应用中的可靠性。本文提出AR2（注意力引导修复鲁棒性），一种简单而有效的方法，用于增强预训练CNN对损坏的鲁棒性。AR2通过显式对齐干净图像和损坏图像的类激活图（CAMs），鼓励模型在输入扰动下保持一致的注意力。我们的方法采用迭代修复策略，交替进行CAM引导的细化和标准微调，无需改变模型架构。大量实验表明，AR2在标准损坏基准测试（CIFAR-10-C、CIFAR-100-C和ImageNet-C）中一致优于现有方法，实现了干净数据准确性和损坏鲁棒性的良好平衡。这些结果表明，AR2为提升模型在多样化损坏环境中的可靠性提供了一种鲁棒且可扩展的解决方案。

</details>


### [52] [When Trackers Date Fish: A Benchmark and Framework for Underwater Multiple Fish Tracking](https://arxiv.org/abs/2507.06400)
**中文标题：当追踪器与鱼约会：水下多鱼跟踪的基准与框架**

*Weiran Li,Yeqiang Liu,Qiannan Guo,Yijie Wei,Hwa Liang Leo,Zhenbo Li*

主要分类: cs.CV

摘要简述: 本文提出了首个专为水下多鱼跟踪设计的综合数据集MFT25，并开发了基于无迹卡尔曼滤波和FishIoU匹配的SU-T跟踪框架，显著提升了水下鱼群跟踪性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多目标跟踪技术在陆地应用中取得了显著进展，但水下跟踪场景的研究仍不足，而这对海洋生态和水产养殖至关重要。

研究方法: 提出了MFT25数据集，包含15段视频序列和408,578个标注框；开发了SU-T跟踪框架，结合无迹卡尔曼滤波（UKF）和FishIoU匹配方法，优化非线性鱼群运动跟踪。

研究结果: SU-T在MFT25上实现了34.1 HOTA和44.6 IDF1的最优性能，揭示了水下鱼群跟踪与陆地目标跟踪的根本差异。

研究结论: MFT25为水下跟踪系统研究提供了坚实基础，SU-T框架在海洋生物学和水产养殖监测中具有重要应用价值。

中文摘要: 多目标跟踪（MOT）技术在陆地应用中取得了显著进展，但水下跟踪场景的研究仍不足，尽管其对海洋生态和水产养殖至关重要。我们提出了首个专为水下多鱼跟踪设计的综合数据集Multiple Fish Tracking Dataset 2025（MFT25），包含15段多样化视频序列，共48,066帧，标注了408,578个边界框。该数据集涵盖了多种水下环境、鱼类物种及遮挡、相似外观和随机运动等挑战性条件。此外，我们提出了Scale-aware and Unscented Tracker（SU-T），这是一种专为非线性鱼群游泳模式优化的跟踪框架，采用无迹卡尔曼滤波（UKF）和新型Fish-Intersection-over-Union（FishIoU）匹配方法，考虑了水生物种的独特形态特征。大量实验表明，SU-T在MFT25上实现了最优性能，HOTA为34.1，IDF1为44.6，同时揭示了鱼群跟踪与陆地目标跟踪的根本差异。MFT25为水下跟踪系统的研究奠定了坚实基础，在海洋生物学、水产养殖监测和生态保护中具有重要应用价值。数据集和代码发布于https://vranlee.github.io/SU-T/。

</details>


### [53] [SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models](https://arxiv.org/abs/2507.06405)
**中文标题：SImpHAR：利用3D模拟和文本到动作模型推进基于阻抗的人体活动识别**

*Lala Shakti Swarup Ray,Mengxi Liu,Deepika Gurung,Bo Zhou,Sungho Suh,Paul Lukowicz*

主要分类: cs.CV

摘要简述: SImpHAR提出了一种基于生物阻抗信号的人体活动识别新框架，通过3D模拟和文本到动作模型生成合成数据，并结合两阶段训练策略，显著提升了识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 生物阻抗传感在细粒度运动捕捉中具有独特优势，但缺乏标记数据限制了其应用。SImpHAR旨在通过模拟和合成数据解决这一问题。

研究方法: SImpHAR包含两部分核心贡献：1) 通过3D人体网格、最短路径估计和软体物理生成逼真的生物阻抗信号；2) 设计了一种两阶段解耦训练策略，无需标签对齐的合成数据即可覆盖更广泛的活动。

研究结果: 在ImpAct数据集和两个公共基准测试中，SImpHAR相比现有方法在准确率和宏F1分数上分别提升了22.3%和21.8%。

研究结论: SImpHAR展示了模拟驱动数据增强和模块化训练在基于阻抗的人体活动识别中的潜力。

中文摘要: 基于可穿戴传感器的人体活动识别（HAR）在医疗保健、健身和人机交互等领域具有重要应用。生物阻抗传感为细粒度运动捕捉提供了独特优势，但由于标记数据稀缺，其潜力尚未充分发挥。我们提出了SImpHAR，这一新框架通过两项核心贡献解决了这一问题。首先，我们提出了一种模拟流程，利用最短路径估计、软体物理和文本到动作生成技术，从3D人体网格中生成逼真的生物阻抗信号，作为数据增强的数字孪生。其次，我们设计了一种两阶段解耦训练策略，无需标签对齐的合成数据即可覆盖更广泛的活动。我们在自收集的ImpAct数据集和两个公共基准测试上评估了SImpHAR，结果显示其在准确率和宏F1分数上分别比现有最优方法提升了22.3%和21.8%。我们的结果凸显了模拟驱动数据增强和模块化训练在基于阻抗的HAR中的前景。

</details>


### [54] [VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting](https://arxiv.org/abs/2507.05116)
**中文标题：VOTE：基于轨迹集成投票的视觉-语言-动作优化**

*Juyi Lin,Amir Taherin,Arash Akbari,Arman Akbari,Lei Lu,Guangyu Chen,Taskin Padir,Xiaomeng Yang,Weiwei Chen,Yiqian Li,Xue Lin,David Kaeli,Pu Zhao,Yanzhi Wang*

主要分类: cs.CV

摘要简述: 本文提出VOTE框架，通过无分词器微调和集成投票策略，显著提升视觉语言动作模型的效率和泛化能力，实现35倍加速和145Hz吞吐量。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉语言动作模型在新对象或陌生环境中的泛化能力有限，且依赖额外组件导致计算开销大、效率低。本文旨在探索高效且独立于额外视觉表示的动作预测方法。

研究方法: 提出VOTE框架，采用无分词器微调方法并行预测动作以减少计算开销，并通过集成投票策略优化动作采样，提升模型性能和泛化能力。

研究结果: 实验表明，VOTE框架在保持高效的同时，实现了35倍推理加速和145Hz吞吐量，性能达到最优。

研究结论: VOTE框架通过高效的动作预测和集成投票策略，显著提升了视觉语言动作模型的性能和效率，为实际应用提供了可行方案。

中文摘要: 近期的大规模视觉语言动作（VLA）模型在自然语言引导的机器人操作任务中表现出色，但其泛化能力在面对训练分布之外的新对象或陌生环境时仍显不足。为解决这一问题，现有方法通常集成深度估计、分割甚至扩散等额外组件以提高泛化能力，但代价是显著增加计算开销，导致效率低下。这促使我们探索高效且独立于额外高级视觉表示或扩散技术的动作预测方法。本文提出VOTE，一种高效且通用的VLA模型优化与加速框架。具体而言，我们提出了一种新颖的无分词器微调方法，用于并行精确的动作预测，以减少计算开销并加速推理速度。此外，我们采用集成投票策略进行动作采样，显著提升了模型性能并增强了泛化能力。实验结果表明，我们的方法在实现35倍推理加速和145Hz吞吐量的同时，性能达到最优。所有细节和代码将开源。

</details>


### [55] [Hierarchical Multi-Stage Transformer Architecture for Context-Aware Temporal Action Localization](https://arxiv.org/abs/2507.06411)
**中文标题：基于分层多阶段Transformer架构的上下文感知时间动作定位**

*Hayat Ullah,Arslan Munir,Oliver Nina*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PCL-Former的分层多阶段Transformer架构，用于时间动作定位任务。该架构通过三个专用Transformer模块分别处理候选片段识别、动作分类和时间边界预测，显著提升了性能，在多个基准数据集上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 受Transformer和多阶段架构在视频识别和目标检测领域的成功启发，本文旨在探索如何利用Transformer的时空特性，结合多阶段架构范式，提升时间动作定位任务的性能。

研究方法: PCL-Former采用分层多阶段Transformer架构，包含三个专用模块：Proposal-Former（识别候选片段）、Classification-Former（分类动作类别）和Localization-Former（预测时间边界）。每个模块配备专用损失函数。

研究结果: 在THUMOS-14、ActivityNet-1.3和HACS Segments三个基准数据集上的实验表明，PCL-Former分别以2.8%、1.2%和4.8%的优势优于现有方法。消融实验验证了各模块的有效性。

研究结论: PCL-Former通过分层多阶段Transformer架构显著提升了时间动作定位任务的性能，为未来研究提供了新的思路。

中文摘要: 受Transformer和多阶段架构在视频识别和目标检测领域的成功启发，本文深入探索了在多阶段架构范式中利用Transformer的丰富时空特性，用于时间动作定位任务。这一探索促成了名为PCL-Former的分层多阶段Transformer架构的开发，其中每个子任务由专用的Transformer模块和专用损失函数处理。具体而言，Proposal-Former识别未修剪视频中可能包含动作的候选片段，Classification-Former对这些片段中的动作类别进行分类，而Localization-Former精确预测动作实例的时间边界（即开始和结束）。为了评估方法的性能，我们在三个具有挑战性的基准数据集（THUMOS-14、ActivityNet-1.3和HACS Segments）上进行了大量实验，并进行了详细的消融实验以评估PCL-Former中每个模块的影响。定量结果表明，PCL-Former在THUMOS14、ActivityNet-1.3和HACS数据集上分别以2.8%、1.2%和4.8%的优势优于现有时间动作定位方法。

</details>


### [56] [THOR: Thermal-guided Hand-Object Reasoning via Adaptive Vision Sampling](https://arxiv.org/abs/2507.06442)
**中文标题：THOR：基于自适应视觉采样的热引导手-物体推理**

*Soroush Shahi,Farzad Shahabi,Rama Nabulsi,Glenn Fernandes,Aggelos Katsaggelos,Nabil Alshurafa*

主要分类: cs.CV

摘要简述: THOR是一种基于热感应的自适应视觉采样方法，通过热成像数据动态调整RGB帧采样率，仅处理手-物体交互区域，显著减少数据量和计算资源，同时保持高精度活动识别。


<details>
  <summary>详细信息</summary>
研究动机: 可穿戴相机用于记录手部活动时，连续处理RGB图像会消耗大量电量、产生冗余数据并引发隐私问题。THOR旨在通过热感应技术优化采样和数据处理，解决这些问题。

研究方法: THOR利用低分辨率热成像数据检测手部活动切换时刻，动态调整RGB帧采样率，并在每帧中通过热信号定位手-物体交互区域，仅裁剪和处理必要部分。

研究结果: 实验表明，THOR仅需3%的原始RGB数据即可捕获所有活动片段，手部活动识别的F1分数达到95%，与使用完整视频（94%）相当。

研究结论: THOR为可穿戴相机的长期实时监测手部活动和健康风险行为提供了更实用的解决方案。

中文摘要: 可穿戴相机作为一种观察和干预工具，通过提供手部活动的详细视觉数据，被越来越多地用于记录行为或实施健康干预。然而，连续处理RGB图像会消耗大量电量、产生冗余数据、引发隐私问题，并需要大量计算资源。我们提出了THOR，一种基于热感应的实时自适应时空RGB帧采样方法，通过热成像数据捕获手-物体区域并进行实时分类。我们利用低分辨率热成像数据检测手部活动切换时刻，动态调整RGB帧采样率，并在每帧中通过热信号定位手-物体交互区域，仅处理必要部分。我们开发了一款可穿戴设备，通过14名参与者及30多项活动的野外研究验证了该方法，并在Ego4D数据集（923名参与者，9个国家，总计3,670小时视频）上进一步评估。结果显示，THOR仅需3%的原始RGB数据即可捕获所有活动片段，手部活动识别的F1分数（95%）与使用完整视频（94%）相当。这项工作为实时监测手部活动和健康风险行为提供了更实用的路径。

</details>


### [57] [EA: An Event Autoencoder for High-Speed Vision Sensing](https://arxiv.org/abs/2507.06459)
**中文标题：EA：一种用于高速视觉感知的事件自动编码器**

*Riadul Islam,Joey Mulé,Dhandeep Challagundla,Shahmir Rizvi,Sean Carson*

主要分类: cs.CV

摘要简述: 提出一种事件自动编码器（EA），用于高效压缩和重建事件数据，提升高速视觉感知性能，在低功耗边缘计算中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统帧式视觉系统存在运动模糊、高延迟和数据冗余问题，事件相机虽能捕捉异步亮度变化，但稀疏噪声事件流对目标检测构成挑战。

研究方法: 采用卷积编码架构，结合自适应阈值选择和轻量级分类器，压缩事件数据同时保留关键时空特征。

研究结果: 在SEFD数据集上，模型精度与YOLO-v4相当，但参数减少35.5倍；嵌入式平台实现8-44.8 FPS，分类器性能提升87.84倍。

研究结论: 该模型显著提升事件视觉性能，适用于实时边缘计算中的低功耗高速应用。

中文摘要: 高速视觉感知在机器人、自动驾驶和工业自动化等实时应用中至关重要。传统帧式视觉系统存在运动模糊、高延迟和数据冗余问题，限制了其在动态环境中的表现。事件相机通过捕捉像素级异步亮度变化提供了替代方案，但稀疏噪声事件流为目标检测带来挑战。为此，我们提出一种事件自动编码器架构，高效压缩并重建事件数据，同时保留关键时空特征。该模型采用卷积编码，结合自适应阈值选择和轻量级分类器，在降低计算复杂度的同时提升识别精度。在现有SEFD数据集上的实验表明，我们的方法精度与YOLO-v4相当，但参数减少35.5倍。在树莓派4B和NVIDIA Jetson Nano等嵌入式平台上的实现显示帧率可达8至44.8 FPS。所提分类器性能比现有技术提升87.84倍，显著改善了事件视觉性能，适用于实时边缘计算中的低功耗高速应用。

</details>


### [58] [Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning](https://arxiv.org/abs/2507.06485)
**中文标题：Video-RTS：重新思考强化学习与测试时间缩放以实现高效和增强的视频推理**

*Ziyang Wang,Jaehong Yoon,Shoubin Yu,Md Mohaiminul Islam,Gedas Bertasius,Mohit Bansal*

主要分类: cs.CV

摘要简述: Video-RTS提出了一种结合高效强化学习和视频自适应测试时间缩放的新方法，显著提升了视频推理能力，同时大幅降低了数据需求。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于强化学习的视频推理方法依赖大规模监督微调和长链思维标注，成本高且难以扩展。Video-RTS旨在通过数据高效的强化学习和自适应测试时间缩放策略解决这些问题。

研究方法: Video-RTS跳过了资源密集的监督微调步骤，采用纯强化学习训练，并引入稀疏到密集的视频测试时间缩放策略，通过迭代增加帧数提升推理效率。

研究结果: 实验表明，Video-RTS在多个视频推理基准测试中平均准确率提升2.4%，仅需3.6%的训练样本。例如，在Video-Holmes和MMVU上分别提升了4.2%和2.6%。

研究结论: Video-RTS通过纯强化学习和自适应视频缩放策略的互补优势，实现了高效的视频推理性能，为视频推理领域提供了新的解决方案。

中文摘要: 尽管基于强化学习（RL）和大语言模型（LLMs）的视频推理方法取得了进展，但数据收集和微调仍然是重大挑战。这些方法通常依赖大规模监督微调（SFT）和长链思维（CoT）标注，成本高昂且难以扩展。为此，我们提出了Video-RTS，通过结合数据高效的强化学习和视频自适应的测试时间缩放（TTS）策略，显著提升了视频推理能力并大幅提高了数据效率。基于对RL样本数据扩展的观察，我们跳过了资源密集的SFT步骤，采用基于输出的纯RL训练，无需额外标注或大规模微调。此外，为了更高效地利用计算资源，我们引入了一种稀疏到密集的视频TTS策略，通过基于输出一致性迭代增加帧数来提升推理效果。我们在多个视频推理基准上验证了该方法，结果显示Video-RTS仅使用3.6%的训练样本，平均准确率就超越了现有视频推理模型2.4%。例如，在近期具有挑战性的Video-Holmes基准上提升了4.2%，在MMVU上提升了2.6%。值得注意的是，我们的纯RL训练和自适应视频TTS策略具有互补优势，共同推动了Video-RTS强大的推理性能。

</details>


### [59] [Mask6D: Masked Pose Priors For 6D Object Pose Estimation](https://arxiv.org/abs/2507.06486)
**中文标题：Mask6D：用于6D物体姿态估计的掩码姿态先验**

*Yuechen Xie,Haobo Jiang,Jin Xie*

主要分类: cs.CV

摘要简述: Mask6D提出了一种新的6D物体姿态估计预训练策略，通过结合姿态感知的2D-3D对应图和可见掩码图，显著提升了在遮挡或杂乱场景下的姿态估计性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于单目RGB图像的6D物体姿态估计方法在遮挡或杂乱场景下表现不佳，主要原因是2D特征提取网络难以从有限的RGB信息中提取姿态感知特征。

研究方法: Mask6D通过引入姿态感知的2D-3D对应图和可见掩码图作为额外模态信息，结合RGB图像进行基于重建的模型预训练，并设计了专注于物体的预训练损失函数以减少背景干扰。

研究结果: 实验表明，Mask6D在6D姿态估计任务中优于现有的端到端方法，尤其在遮挡和杂乱场景下表现突出。

研究结论: Mask6D通过结合姿态感知的模态信息和预训练策略，显著提升了6D姿态估计的鲁棒性和准确性。

中文摘要: 在遮挡或杂乱场景下，基于单目RGB图像的鲁棒6D物体姿态估计仍然是一项具有挑战性的任务。一个原因是当前的姿态估计网络难以利用2D特征提取网络提取具有区分性的姿态感知特征，尤其是在目标因遮挡导致RGB信息有限的情况下。为解决这一问题，我们提出了一种名为Mask6D的新型姿态估计专用预训练策略。我们的方法将姿态感知的2D-3D对应图和可见掩码图作为额外模态信息，与RGB图像结合用于基于重建的模型预训练。本质上，2D-3D对应图将变换后的3D物体模型映射到2D像素，反映了目标在相机坐标系中的姿态信息。同时，集成的可见掩码图可以有效引导模型忽略杂乱背景信息。此外，我们还设计了一种专注于物体的预训练损失函数，以进一步帮助网络去除背景干扰。最后，我们通过传统的姿态训练策略对预训练的模型进行微调，以实现可靠的姿态预测。大量实验验证了我们的方法优于以往的端到端姿态估计方法。

</details>


### [60] [Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection](https://arxiv.org/abs/2507.06510)
**中文标题：基于大型视觉语言模型的双边协作开放词汇人-物交互检测**

*Yupeng Hu,Changxing Ding,Chang Sun,Shaoli Huang,Xiangmin Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的双边协作框架（BC-HOI），用于开放词汇的人-物交互检测。通过注意力偏差引导（ABG）和基于大型语言模型的监督引导（LSG），解决了现有方法中视觉特征过于粗粒度的问题，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的开放词汇人-物交互检测方法依赖大型视觉语言模型（VLMs）生成的粗粒度特征，这与检测任务的细粒度需求相矛盾。本文旨在通过双边协作框架，生成细粒度的实例级交互特征，提升检测性能。

研究方法: 提出双边协作框架（BC-HOI），包括注意力偏差引导（ABG）和基于大型语言模型的监督引导（LSG）。ABG引导VLMs生成细粒度实例级特征，LSG通过LLM提供细粒度监督，增强ABG生成高质量注意力偏差的能力。

研究结果: 在HICO-DET和V-COCO两个基准测试中，BC-HOI在开放词汇和封闭设置下均表现出色，显著优于现有方法。

研究结论: BC-HOI框架通过双边协作机制，有效解决了开放词汇人-物交互检测中的细粒度特征生成问题，为未来研究提供了新思路。

中文摘要: 开放词汇人-物交互（HOI）检测是一项具有挑战性的任务，旨在检测图像中所有感兴趣的<人、动词、物>三元组，包括训练集中未预定义的组合。现有方法通常依赖大型视觉语言模型（VLMs）生成的输出特征来增强交互表示的泛化能力。然而，VLMs生成的视觉特征是整体且粗粒度的，这与检测任务的本质相矛盾。为解决这一问题，我们提出了一种新颖的双边协作框架（BC-HOI），用于开放词汇HOI检测。该框架包括注意力偏差引导（ABG）组件，指导VLM根据HOI检测器提供的注意力偏差生成细粒度的实例级交互特征；还包括基于大型语言模型（LLM）的监督引导（LSG）组件，通过VLM的LLM部分为HOI检测器提供细粒度的标记级监督。LSG增强了ABG生成高质量注意力偏差的能力。我们在两个流行基准测试（HICO-DET和V-COCO）上进行了广泛实验，在开放词汇和封闭设置下均取得了优异的性能。代码将在Github上发布。

</details>


### [61] [What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies](https://arxiv.org/abs/2507.06513)
**中文标题：城市街景中哪些需要关注？从场景理解到道路安全：基于视觉的数据集与研究综述**

*Yaoqi Huang,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

主要分类: cs.CV

摘要简述: 本文综述了基于视觉的交通场景分析，提出了一种分类框架，将需要关注的交通实体分为异常和关键正常实体两大类，涵盖10个类别和20个子类。分析了35个视觉任务和73个数据集，旨在为道路安全研究提供统一标准和资源优化建议。


<details>
  <summary>详细信息</summary>
研究动机: 随着视觉传感器和计算机视觉算法的进步，交通场景分析能力显著提升。然而，现有研究多集中于孤立领域，缺乏统一的分类框架。本文旨在填补这一空白，为道路安全研究提供系统化的分析和资源指导。

研究方法: 提出了一种分类框架，将交通场景中需要关注的实体分为异常和关键正常实体两大类，涵盖10个类别和20个子类。在此基础上，系统分析了35个视觉任务和73个数据集，并进行了跨领域的优缺点比较。

研究结果: 通过分类框架和数据集分析，本文为道路安全研究提供了统一标准和资源优化建议。同时，总结了现有研究的不足，并提出了潜在的解决方案。

研究结论: 本文的分类框架和综合分析为交通场景研究提供了全面指导，有助于资源选择和填补研究空白。未来的研究可以在此基础上进一步优化标准和任务设计。

中文摘要: 基于视觉的传感器和计算机视觉算法的进步显著提升了交通场景的分析和理解能力。为了将这些进步应用于道路安全，本文系统分类了交通场景中需要关注的关键元素，并全面分析了现有的视觉驱动任务和数据集。与现有集中于孤立领域的综述不同，我们的分类法将需要关注的交通实体分为异常和关键正常实体两大类，整合了10个类别和20个子类，建立了相关领域的联系并提供了统一的分析框架。本文重点分析了35个视觉任务，并对73个数据集进行了全面检查和可视化。跨领域研究涵盖了每个基准的优缺点，旨在为标准化和资源优化提供信息。文章最后系统讨论了现有研究的不足，强调了潜在影响和多角度的解决方案。整合的分类法、全面分析和总结表格为这一快速发展的领域提供了有价值的贡献，帮助研究者获得整体视角，指导资源选择并突出关键研究空白。

</details>


### [62] [FIFA: Unified Faithfulness Evaluation Framework for Text-to-Video and Video-to-Text Generation](https://arxiv.org/abs/2507.06523)
**中文标题：FIFA：文本到视频与视频到文本生成的统一忠实性评估框架**

*Liqiang Jing,Viet Lai,Seunghyun Yoon,Trung Bui,Xinya Du*

主要分类: cs.CV

摘要简述: 本文提出FIFA框架，用于统一评估文本到视频和视频到文本生成任务的忠实性，通过提取描述性事实、建模语义依赖关系并验证，同时引入后校正工具减少幻觉内容。


<details>
  <summary>详细信息</summary>
研究动机: 视频多模态大语言模型（VideoMLLMs）在视频到文本和文本到视频任务中表现突出，但常出现幻觉现象，生成内容与视觉输入矛盾。现有评估方法局限于单一任务且无法评估开放自由形式的回答，因此需要统一框架解决这一问题。

研究方法: FIFA框架提取全面的描述性事实，通过时空语义依赖图建模其语义关系，并利用视频问答模型验证。此外，引入后校正工具框架修正幻觉内容。

研究结果: 实验表明，FIFA比现有评估方法更接近人类判断，后校正工具有效提升了文本和视频生成的事实一致性。

研究结论: FIFA为视频多模态任务的忠实性评估提供了统一框架，后校正工具进一步优化了生成内容的事实一致性，具有实际应用价值。

中文摘要: 视频多模态大语言模型（VideoMLLMs）在视频到文本和文本到视频任务中取得了显著进展，但它们常出现幻觉现象，生成内容与视觉输入矛盾。现有评估方法局限于单一任务（如V2T），且无法评估开放自由形式的回答中的幻觉。为解决这一问题，我们提出FIFA，一个统一的忠实性评估框架，通过提取全面的描述性事实、建模其时空语义依赖关系图，并利用视频问答模型验证。我们还引入了后校正工具框架，用于修正幻觉内容。大量实验表明，FIFA比现有评估方法更接近人类判断，后校正工具有效提升了文本和视频生成的事实一致性。

</details>


### [63] [Concept Unlearning by Modeling Key Steps of Diffusion Process](https://arxiv.org/abs/2507.06526)
**中文标题：通过建模扩散过程关键步骤实现概念遗忘**

*Chaoshuo Zhang,Chenhao Lin,Zhengyu Zhao,Le Yang,Qian Wang,Chao Shen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为KSCU的新方法，通过聚焦扩散模型中的关键步骤来实现概念遗忘，既有效减少了不良图像的生成，又保留了模型的生成能力。


<details>
  <summary>详细信息</summary>
研究动机: 文本到图像扩散模型（如Stable Diffusion）的滥用带来了严重的安全风险。现有的概念遗忘方法难以平衡遗忘效果与生成能力的保留，因此需要一种更高效的方法。

研究方法: KSCU方法利用扩散模型的分步采样特性，专注于对最终结果影响最大的关键步骤，针对不同遗忘任务划分关键步骤，并仅在这些步骤上微调模型，从而减少参数更新次数。

研究结果: 通过大量基准实验，KSCU成功阻止了文本到图像扩散模型生成不良图像，同时更好地保留了模型的生成能力。

研究结论: KSCU方法在概念遗忘任务中表现出色，既提升了安全性，又最大限度地保留了模型的生成性能，为扩散模型的安全应用提供了新思路。

中文摘要: 以Stable Diffusion为代表的文本到图像扩散模型（T2I DMs）能够根据文本输入生成高度逼真的图像，但其滥用带来了严重的安全风险。现有的概念遗忘方法试图缓解这些风险，但难以平衡遗忘效果与生成能力的保留。为克服这一局限，我们创新性地提出了关键步骤概念遗忘（KSCU）方法，巧妙利用了扩散模型在图像生成过程中独特的分步采样特性。与传统方法对所有去噪步骤一视同仁不同，KSCU策略性地聚焦于对最终结果影响最大的关键步骤，为不同概念遗忘任务划分关键步骤，并仅在这些步骤上微调模型。这种针对性方法减少了有效遗忘所需的参数更新次数，同时最大限度地保留了模型的生成能力。通过大量基准实验，我们证明KSCU能有效阻止T2I DMs生成不良图像，同时更好地保留模型的生成能力。我们的代码将公开发布。

</details>


### [64] [Speak2Sign3D: A Multi-modal Pipeline for English Speech to American Sign Language Animation](https://arxiv.org/abs/2507.06530)
**中文标题：Speak2Sign3D：一种从英语语音到美国手语3D动画的多模态管道**

*Kazi Mahathir Rahman,Naveed Imtiaz Nafis,Md. Farhan Sadik,Mohammad Al Rafi,Mehedi Hasan Shahed*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Speak2Sign3D的多模态管道，将英语语音转换为流畅的3D美国手语动画，通过语音识别、文本翻译和动作生成实现，旨在帮助聋人和听力障碍者更便捷地交流。


<details>
  <summary>详细信息</summary>
研究动机: 自动手语翻译的主要目标是帮助聋人和听力障碍者更轻松地沟通。以往研究多集中于将手语转换为文本，而将英语语音转换为手语动画的研究较少，因其涉及语音理解、手语语法翻译和自然动作生成等多个复杂步骤。

研究方法: 系统首先使用Whisper将英语语音转换为文本，然后通过MarianMT模型将文本翻译为美国手语（ASL）的简化版本（gloss）。为提高翻译准确性，还结合了Word2Vec和FastText等词嵌入技术。最后，使用基于3D关键点的动作系统将gloss转换为动画，该系统训练于Sign3D-WLASL数据集（从WLASL数据集中提取的身体、手部和面部关键点）。此外，还构建了BookGlossCorpus-CG数据集，用于支持gloss翻译阶段。

研究结果: 系统表现优异，MarianMT模型的BLEU分数达到0.7714和0.8923。通过平滑插值技术，生成的3D手语动画流畅自然。

研究结论: Speak2Sign3D是一个完整的框架，首次将音频、文本和动作整合到一个系统中，实现了从英语语音到逼真3D手语动画的全流程转换，为聋人和听力障碍者的交流提供了新工具。

中文摘要: 帮助聋人和听力障碍者更便捷地交流是自动手语翻译的主要目标。尽管以往研究多集中于将手语转换为文本，但将英语语音转换为手语动画的研究却鲜有涉及，因其涉及语音理解、手语语法翻译和自然动作生成等多个复杂步骤。本文提出了一种完整的管道，能够将英语语音转换为流畅、逼真的3D手语动画。系统首先使用Whisper将英语语音转换为文本，然后通过MarianMT模型将文本翻译为美国手语（ASL）的简化版本（gloss），该模型的BLEU分数达到0.7714和0.8923。为提高翻译准确性，还结合了Word2Vec和FastText等词嵌入技术。最后，使用基于3D关键点的动作系统将gloss转换为动画，该系统训练于Sign3D-WLASL数据集（从WLASL数据集中提取的身体、手部和面部关键点）。此外，还构建了BookGlossCorpus-CG数据集，用于支持gloss翻译阶段。系统通过平滑插值技术生成自然连续的动画。与以往专注于识别或仅使用单一数据类型的研究（如How2Sign和Phoenix-2014T）不同，本管道将音频、文本和动作整合到一个框架中，实现了从英语语音到逼真3D手语动画的全流程转换。

</details>


### [65] [ILNet: Trajectory Prediction with Inverse Learning Attention for Enhancing Intention Capture](https://arxiv.org/abs/2507.06531)
**中文标题：ILNet：基于逆向学习注意力机制的轨迹预测以增强意图捕捉**

*Mingjin Zeng,Nan Ouyang,Wenkang Wan,Lei Ao,Qing Cai,Kai Sheng*

主要分类: cs.CV

摘要简述: ILNet提出了一种多智能体轨迹预测方法，结合逆向学习注意力机制和动态锚点选择模块，显著提升了复杂交互场景中的意图捕捉能力，并在多个数据集上达到最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有轨迹预测方法在时空交互协调和动态适应性上存在不足，无法有效捕捉复杂意图。受人类驾驶行为的启发，本文旨在通过逆向学习和动态锚点选择提升模型的交互建模能力。

研究方法: ILNet提出逆向学习注意力机制（IL Attention），通过逆向学习建模相邻时刻的交互，动态编码时空协调；同时引入动态锚点选择模块（DAS），以可学习方式提取轨迹关键点作为锚点，几乎不增加参数。

研究结果: 实验表明，ILNet在INTERACTION和Argoverse数据集上达到最优性能，尤其在复杂交互场景中表现出更高的准确性和多模态分布能力，且参数更少。

研究结论: ILNet通过逆向学习和动态锚点选择显著提升了轨迹预测的意图捕捉能力，为多智能体交互场景提供了高效解决方案。

中文摘要: 多智能体交互场景中的轨迹预测是一个关键挑战。现有先进方法通过基于时间和智能体轴的高效分解注意力建模交互，但这种静态和正向建模缺乏显式的时空交互协调，仅能捕捉明显和即时的行为意图。现代轨迹预测框架通过固定锚点选择策略优化连续预测，但难以适应不同未来环境。人类驾驶员会根据对周围车辆意图的进一步假设动态调整初始驾驶决策。受此启发，本文提出ILNet，一种结合逆向学习（IL）注意力和动态锚点选择（DAS）模块的多智能体轨迹预测方法。IL注意力采用逆向学习范式建模相邻时刻的交互，引入意图假设动态编码交互的时空协调，从而增强模型捕捉复杂交互模式的能力。同时，可学习的DAS模块以几乎不增加参数的方式并行提取多个轨迹变化关键点作为锚点。实验结果表明，ILNet在INTERACTION和Argoverse运动预测数据集上达到最优性能。尤其在挑战性交互场景中，ILNet以更少参数实现了更高的准确性和更多模态的轨迹分布。代码已开源：https://github.com/mjZeng11/ILNet。

</details>


### [66] [A model-agnostic active learning approach for animal detection from camera traps](https://arxiv.org/abs/2507.06537)
**中文标题：一种与模型无关的主动学习方法用于相机陷阱中的动物检测**

*Thi Thu Thuy Nguyen,Duc Thanh Nguyen*

主要分类: cs.CV

摘要简述: 本文提出了一种与模型无关的主动学习方法，用于优化相机陷阱数据中的动物检测，仅需30%的训练数据即可达到或超过完整数据集的性能。


<details>
  <summary>详细信息</summary>
研究动机: 野生动物相机陷阱数据量大，标注和模型训练成本高，现有主动学习方法需完全访问模型，限制了其应用。本文旨在解决这一问题，提出一种更灵活的主动学习方法。

研究方法: 结合样本在对象和图像层面的不确定性和多样性，提出一种模型无关的主动学习样本选择方法。

研究结果: 实验表明，使用该方法选择的30%训练数据，动物检测器的性能可达到或超过使用完整数据集的效果。

研究结论: 该方法显著减少了数据标注需求，为自动化野生动物监测和保护提供了高效工具。

中文摘要: 智能数据选择在数据驱动的机器学习中日益重要。主动学习通过选择最具信息量的样本优化模型训练，为处理大量野生动物相机陷阱数据提供了解决方案。然而，现有主动学习方法需完全访问模型（如目标检测器），限制了其适用性。本文提出一种与模型无关的主动学习方法，结合样本在对象和图像层面的不确定性和多样性进行样本选择。在基准动物数据集上的实验表明，使用该方法选择的30%训练数据，动物检测器的性能可达到或超过使用完整数据集的效果。

</details>


### [67] [Token Bottleneck: One Token to Remember Dynamics](https://arxiv.org/abs/2507.06543)
**中文标题：标记瓶颈：一个标记记住动态**

*Taekyung Kim,Dongyoon Han,Byeongho Heo,Jeongeun Park,Sangdoo Yun*

主要分类: cs.CV

摘要简述: 论文提出了一种名为Token Bottleneck（ToBo）的自监督学习框架，通过将动态场景压缩为单个瓶颈标记并预测后续场景，实现了高效的时序感知视觉表示学习。该方法在视频标签传播和机器人操作等任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 动态场景的紧凑且时序感知的视觉表示对于视觉跟踪和机器人操作等任务至关重要。现有方法往往难以高效捕捉场景的动态变化，因此需要一种简单直观的框架来解决这一问题。

研究方法: ToBo框架分为压缩和扩展两步：在压缩步骤中，将参考场景编码为一个紧凑的瓶颈标记；在扩展步骤中，利用瓶颈标记和少量目标场景补丁预测目标场景，从而学习时序动态。

研究结果: 实验表明，ToBo在视频标签传播和模拟环境中的机器人操作任务中优于基线方法，并且在真实机器人上的部署验证了其鲁棒性和有效性。此外，ToBo在不同模型规模下均表现出良好的扩展性。

研究结论: ToBo通过自监督学习有效捕捉了动态场景的时序依赖关系，为时序感知任务提供了一种高效且可扩展的解决方案。

中文摘要: 从动态场景中提取紧凑且具有时序感知的视觉表示对于成功执行视觉跟踪和机器人操作等时序场景理解任务至关重要。本文提出了一种名为标记瓶颈（ToBo）的简单直观的自监督学习框架，该框架将场景压缩为一个瓶颈标记，并使用最少的补丁作为提示预测后续场景。ToBo框架通过压缩步骤将参考场景保守编码为紧凑的瓶颈标记，从而促进时序场景表示的学习。在扩展步骤中，我们通过使用瓶颈标记和少量目标补丁作为提示预测目标场景，引导模型捕捉时序动态。这一设计鼓励视觉主干嵌入时序依赖关系，从而理解场景间的动态过渡。在视频标签传播和模拟环境中的机器人操作等多种时序任务中的广泛实验表明，ToBo优于基线方法。此外，将预训练模型部署在物理机器人上证实了其在真实环境中的鲁棒性和有效性。我们还验证了ToBo在不同模型规模下的可扩展性。

</details>


### [68] [Concept-TRAK: Understanding how diffusion models learn concepts through concept-level attribution](https://arxiv.org/abs/2507.06547)
**中文标题：Concept-TRAK：通过概念级归因理解扩散模型如何学习概念**

*Yonghyun Park,Chieh-Hsin Lai,Satoshi Hayakawa,Yuhta Takida,Naoki Murata,Wei-Hsiang Liao,Woosung Choi,Kin Wai Cheuk,Junghyun Koo,Yuki Mitsufuji*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Concept-TRAK的新方法，用于理解扩散模型如何学习概念，通过概念级归因分析，解决了现有方法无法隔离特定元素贡献的问题。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在图像生成方面表现出色，但其广泛应用引发了版权问题和模型透明性的担忧。现有归因方法只能识别影响整张图像的训练示例，而无法分离对特定元素（如风格或对象）的贡献，这限制了其实际应用价值。

研究方法: Concept-TRAK通过两种关键创新扩展了影响函数：1）基于扩散后验采样的重新表述的训练损失，实现了鲁棒的样本特定归因；2）强调语义相关性的概念感知奖励函数。

研究结果: 在AbC基准测试中，Concept-TRAK显著优于现有方法。通过多样化的案例研究（如识别受知识产权保护的内容、分析提示工程等），展示了概念级归因对生成AI开发和治理的实际价值。

研究结论: Concept-TRAK为理解扩散模型的概念学习提供了新工具，并为生成AI的负责任开发和治理提供了可操作的见解。

中文摘要: 尽管扩散模型在图像生成方面表现出色，但其广泛采用引发了关于版权问题和模型透明性的关键担忧。现有的归因方法能够识别影响整张图像的训练示例，但无法分离对特定元素（如风格或对象）的贡献，而这些元素对利益相关者最为重要。为了填补这一空白，我们通过一种名为Concept-TRAK的新方法引入了概念级归因。Concept-TRAK通过两种关键创新扩展了影响函数：1）基于扩散后验采样的重新表述的训练损失，实现了鲁棒的样本特定归因；2）强调语义相关性的概念感知奖励函数。我们在AbC基准测试中评估了Concept-TRAK，结果显示其显著优于现有方法。通过多样化的案例研究（从识别受知识产权保护的内容到分析提示工程和组合学习），我们展示了概念级归因为负责任生成AI开发和治理提供的可操作见解。

</details>


### [69] [Divergence-Based Similarity Function for Multi-View Contrastive Learning](https://arxiv.org/abs/2507.06560)
**中文标题：基于散度的多视图对比学习相似性函数**

*Jae Hyoung Jeon,Cheolsu Lim,Myungjoo Kang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于散度的相似性函数（DSF），通过将多视图表示为分布并测量分布间的散度来捕捉联合结构，显著提升了对比学习的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在多视图对比学习中主要关注成对关系，未能有效建模所有视图的联合结构。本文旨在通过分布表示和散度测量来解决这一问题。

研究方法: 提出了一种基于散度的相似性函数（DSF），将多视图数据表示为分布，并通过计算分布间的散度来度量相似性。该方法无需温度超参数，且效率更高。

研究结果: 实验表明，DSF在kNN分类和线性评估等任务中表现优异，性能优于其他多视图方法，同时效率更高。

研究结论: DSF通过捕捉多视图的联合结构，显著提升了对比学习的性能，且无需依赖温度超参数，具有理论和实践优势。

中文摘要: 近年来，对比学习的成功激发了人们对更有效地利用实例的多个增强视图的兴趣。尽管现有方法在损失或特征层面结合了多视图，但它们主要捕捉成对关系，未能建模所有视图的联合结构。本文提出了一种基于散度的相似性函数（DSF），通过将每组增强视图表示为分布，并测量分布间的散度来显式捕捉联合结构。大量实验表明，DSF在kNN分类和线性评估等任务中持续提升性能，同时比其他多视图方法更高效。此外，我们建立了DSF与余弦相似性之间的理论联系，并证明DSF无需温度超参数即可有效运行。

</details>


### [70] [Edge-Boundary-Texture Loss: A Tri-Class Generalization of Weighted Binary Cross-Entropy for Enhanced Edge Detection](https://arxiv.org/abs/2507.06569)
**中文标题：边缘-边界-纹理损失：加权二元交叉熵的三分类泛化，用于增强边缘检测**

*Hao Shu*

主要分类: cs.CV

摘要简述: 本文提出了一种新的边缘检测损失函数EBT，通过将像素分为边缘、边界和纹理三类，并赋予不同权重，显著提升了边缘检测的精度和边界定位能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的加权二元交叉熵损失（WBCE）在边缘检测中忽视了非边缘像素的结构差异，导致预测模糊。本文旨在通过更精细的像素分类和权重分配，解决这一问题。

研究方法: 提出边缘-边界-纹理（EBT）损失函数，将像素分为三类（边缘、边界、纹理），并为每类分配不同的监督权重，从而优化模型对边缘和边界的识别能力。

研究结果: 在多个基准测试中，EBT损失在定量和感知上均优于WBCE损失，且对超参数变化具有鲁棒性，易于实际部署。

研究结论: EBT损失通过三分类的监督方式显著提升了边缘检测性能，且无需复杂的调参，具有较高的实用价值。

中文摘要: 边缘检测（ED）是计算机视觉中的基础任务，但其性能常因物体边界附近非边缘像素的模糊性而受限。广泛采用的加权二元交叉熵（WBCE）损失将所有非边缘像素视为同类，忽视了边缘周围的结构差异，导致预测模糊。本文提出边缘-边界-纹理（EBT）损失，将像素明确分为三类（边缘、边界、纹理），并为每类分配不同的监督权重。这种三分类形式通过引导模型关注边缘精度和边界定位，实现了更结构化的学习。理论上，EBT损失是WBCE损失的泛化，后者是其极限情况。在多个基准测试中的实验表明，EBT损失在定量和感知上均表现优越。此外，统一超参数在所有模型和数据集中的一致性使用，以及对超参数适度变化的鲁棒性，表明EBT损失几乎无需调参，易于实际部署。

</details>


### [71] [MOST: Motion Diffusion Model for Rare Text via Temporal Clip Banzhaf Interaction](https://arxiv.org/abs/2507.06590)
**中文标题：MOST：基于时间片段Banzhaf交互的罕见文本动作扩散模型**

*Yin Wang,Mu li,Zhiying Leng,Frederick W. B. Li,Xiaohui Liang*

主要分类: cs.CV

摘要简述: 本文提出MOST模型，通过时间片段Banzhaf交互解决罕见文本生成人体动作的难题，利用细粒度片段关系提升语义一致性，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在罕见文本生成人体动作时存在粗粒度匹配和语义忽略问题，MOST旨在通过细粒度片段交互解决这些挑战。

研究方法: MOST提出时间片段Banzhaf交互，量化片段级文本-动作一致性，并在生成阶段利用检索到的动作片段生成语义一致的动作。

研究结果: 实验表明，MOST在文本-动作检索和生成任务中达到最优性能，尤其在罕见文本上表现突出。

研究结论: MOST通过细粒度片段交互和语义一致性生成，显著提升了罕见文本生成动作的效果，为相关领域提供了新思路。

中文摘要: 我们提出了MOST，一种基于时间片段Banzhaf交互的新型动作扩散模型，旨在解决从罕见语言提示生成人体动作的长期挑战。以往方法因动作冗余而难以实现细粒度匹配并忽略重要语义线索，而我们的关键创新在于利用细粒度片段关系缓解这些问题。MOST的检索阶段首次提出时间片段Banzhaf交互，精确量化片段级的文本-动作一致性，实现直接、细粒度的文本-动作片段匹配并消除冗余。在生成阶段，动作提示模块有效利用检索到的动作片段生成语义一致的动作。大量实验证实，MOST通过全面解决以往挑战，在文本-动作检索和生成任务中达到最优性能，定量和定性结果均凸显其有效性，尤其适用于罕见提示。

</details>


### [72] [Ambiguity-aware Point Cloud Segmentation by Adaptive Margin Contrastive Learning](https://arxiv.org/abs/2507.06592)
**中文标题：基于自适应边界对比学习的模糊感知点云分割**

*Yang Chen,Yueqi Duan,Haowen Sun,Jiwen Lu,Yap-Peng Tan*

主要分类: cs.CV

摘要简述: 本文提出了一种自适应边界对比学习方法AMContrast3D，用于解决点云语义分割中的模糊性问题。通过根据模糊性级别为每个点设计自适应目标，该方法在低模糊性点上确保正确性，同时允许高模糊性点的错误，从而提升模型性能。进一步提出的AMContrast3D++通过并行训练分支和模糊性预测模块，增强了分割性能和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的点云语义分割方法通常对所有点采用相同的惩罚目标，忽略了过渡区域中点的模糊性和特征区分度不足的问题。由于高模糊性点即使对人类也难以区分，其标注标签的可靠性较低，硬约束会导致模型性能下降。因此，本文旨在通过自适应边界对比学习解决这一问题。

研究方法: 1. 提出AMContrast3D方法，将对比学习融入模糊性估计框架，根据点的模糊性级别设计自适应目标。2. 进一步提出AMContrast3D++，通过并行训练分支和模糊性预测模块，利用掩码细化机制提升模糊性嵌入的可靠性。

研究结果: 在S3DIS和ScanNet等3D室内场景数据集上的实验表明，所提方法显著提升了分割性能，并增强了模型的鲁棒性。

研究结论: 本文提出的自适应边界对比学习方法有效解决了点云语义分割中的模糊性问题，通过自适应目标和模糊性预测模块显著提升了模型性能。

中文摘要: 本文提出了一种用于点云3D语义分割的自适应边界对比学习方法。现有方法通常采用均等惩罚目标，忽略了过渡区域中点的模糊性和特征区分度不足的问题。然而，高模糊性点即使对人类也难以区分，其标注标签的可靠性较低，对这些点的硬约束会导致模型性能下降。为此，我们首先设计了AMContrast3D方法，将对比学习融入模糊性估计框架，根据点的模糊性级别设计自适应目标。该方法在低模糊性点上确保正确性，同时允许高模糊性点的错误。由于模糊性是基于标签间的位置差异定义的，推理过程中的优化假设所有未标注点均为无模糊性，缺乏模糊性感知。受联合训练启发，我们进一步提出AMContrast3D++，通过并行训练分支和模糊性预测模块，利用掩码细化机制提升模糊性嵌入的可靠性，从而提升分割性能和鲁棒性。在S3DIS和ScanNet等3D室内场景数据集上的实验证明了该方法的有效性。代码发布于https://github.com/YangChenApril/AMContrast3D。

</details>


### [73] [Capturing Stable HDR Videos Using a Dual-Camera System](https://arxiv.org/abs/2507.06593)
**中文标题：使用双摄像头系统捕获稳定的HDR视频**

*Qianyu Zhang,Bolun Zheng,Hangjia Pan,Lingyu Zhu,Zunjie Zhu,Zongpeng Li,Shiqi Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种双摄像头系统（DCS）用于HDR视频重建，通过一个摄像头捕获稳定的参考序列，另一个摄像头补充信息，并结合曝光自适应融合网络（EAFNet）减少闪烁和伪影，实现了高性能的HDR视频重建。


<details>
  <summary>详细信息</summary>
研究动机: 在HDR视频重建中，交替曝光方法中的曝光波动常导致视频闪烁。为了解决这一问题，本文提出了一种双摄像头系统，旨在通过稳定的参考序列和非参考序列的互补，提升HDR视频的质量。

研究方法: 方法包括：1）使用双摄像头系统（DCS），一个摄像头捕获稳定的参考序列，另一个补充信息；2）提出曝光自适应融合网络（EAFNet），包含预对齐子网络、非对称跨特征融合子网络和重建子网络，以减少伪影并优化特征融合。

研究结果: 实验结果表明，该方法在不同数据集上均达到最先进的性能，验证了DCS在HDR视频重建中的巨大潜力。

研究结论: 本文提出的双摄像头系统和EAFNet有效解决了HDR视频中的闪烁问题，并通过实验验证了其优越性，为HDR视频重建提供了新的解决方案。

中文摘要: 在HDR视频重建中，交替曝光方法中参考图像的曝光波动常导致闪烁。为解决这一问题，我们提出了一种双摄像头系统（DCS），其中一个摄像头负责捕获稳定的参考序列，另一个负责补充非参考序列信息。针对视频数据的挑战，我们引入了曝光自适应融合网络（EAFNet）以实现更鲁棒的结果。EAFNet包含一个预对齐子网络，用于探索曝光的影响并选择性强调不同曝光水平下的有价值特征。随后，增强的特征通过非对称跨特征融合子网络进行融合，该子网络利用参考主导的注意力图，通过跨尺度特征对齐和跨特征融合来改进图像融合。最后，重建子网络采用基于DWT的多尺度架构，以减少伪影并在不同分辨率下优化特征。大量实验评估表明，所提方法在不同数据集上均达到最先进的性能，验证了DCS在HDR视频重建中的巨大潜力。相关代码和DCS捕获的数据将在https://github.com/zqqqyu/DCS上公开。

</details>


### [74] [Cross-Modal Dual-Causal Learning for Long-Term Action Recognition](https://arxiv.org/abs/2507.06603)
**中文标题：跨模态双因果学习用于长时动作识别**

*Xu Shaowu,Jia Xibin,Gao Junyu,Sun Qianmei,Chang Jing,Fan Chao*

主要分类: cs.CV

摘要简述: 本文提出了一种跨模态双因果学习（CMDCL）方法，通过文本和视觉因果干预解决长时动作识别中的跨模态偏差和视觉混淆问题，实验证明其在多个基准数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 长时动作识别（LTAR）因时间跨度长、动作关联复杂及视觉混淆问题而具有挑战性。现有视觉语言模型（VLMs）多依赖统计相关性而非因果机制，且缺乏跨模态因果建模。本文旨在通过因果建模解决这些问题。

研究方法: 提出跨模态双因果学习（CMDCL），通过文本因果干预解决文本嵌入的跨模态偏差，并通过视觉因果干预去除视觉模态中的混淆因素。双因果干预共同生成鲁棒的动作表示。

研究结果: 在Charades、Breakfast和COIN三个基准数据集上的实验表明，CMDCL方法显著提升了长时动作识别的性能。

研究结论: CMDCL通过跨模态双因果学习有效解决了长时动作识别中的偏差和混淆问题，为视觉语言模型的应用提供了新思路。

中文摘要: 长时动作识别（LTAR）因时间跨度长、动作关联复杂及视觉混淆问题而具有挑战性。尽管视觉语言模型（VLMs）显示出潜力，但它们通常依赖统计相关性而非因果机制。此外，现有基于因果关系的方法仅解决模态特定偏差，缺乏跨模态因果建模，限制了其在基于VLM的LTAR中的应用。本文提出跨模态双因果学习（CMDCL），通过结构因果模型揭示视频与标签文本之间的因果关系。CMDCL通过文本因果干预解决文本嵌入的跨模态偏差，并通过视觉因果干预去除视觉模态中的混淆因素。这些双因果干预生成了鲁棒的动作表示，有效应对LTAR挑战。在Charades、Breakfast和COIN三个基准数据集上的实验证明了该模型的有效性。代码发布于https://github.com/xushaowu/CMDCL。

</details>


### [75] [Omni-Fusion of Spatial and Spectral for Hyperspectral Image Segmentation](https://arxiv.org/abs/2507.06606)
**中文标题：空间与光谱的全融合用于高光谱图像分割**

*Qing Zhang,Guoquan Pei,Yan Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Omni-Fuse的新型空间-光谱全融合网络，用于高光谱图像分割，通过跨维度特征融合和双向注意力机制显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学高光谱成像（MHSI）在疾病诊断中具有潜力，但其高维度和光谱冗余特性使得空间和光谱信息的有效融合成为挑战。本文旨在解决这一问题。

研究方法: 提出Omni-Fuse网络，包括跨维度增强模块（双向注意力机制优化空间和光谱特征）、光谱引导的空间查询选择（选择最相关的空间特征作为查询）和两阶段跨维度解码器（动态聚焦于选定查询）。

研究结果: 在两个显微高光谱图像数据集上的实验表明，Omni-Fuse显著优于现有方法，DSC指标提升超过5.73%。

研究结论: Omni-Fuse通过高效的跨维度特征融合和注意力机制，显著提升了高光谱图像的分割性能，为医学诊断提供了有力工具。

中文摘要: 医学高光谱成像（MHSI）作为一种增强疾病诊断的有力工具，在计算病理学中展现出潜力，其丰富的光谱信息有助于识别组织的细微生化特性。然而，由于高维度和光谱冗余的特性，如何有效融合MHSI的空间和光谱信息仍具挑战性。为解决这一问题，我们提出了一种名为Omni-Fuse的新型空间-光谱全融合网络用于高光谱图像分割。该网络引入了丰富的跨维度特征融合操作，包括通过双向注意力机制优化空间和光谱特征的跨维度增强模块、选择最光谱相关空间特征作为查询的光谱引导空间查询选择，以及动态引导模型聚焦于选定查询的两阶段跨维度解码器。尽管包含大量注意力模块，Omni-Fuse仍保持高效运行。在两个显微高光谱图像数据集上的实验表明，我们的方法显著优于现有技术，DSC指标提升超过5.73%。代码发布于：https://github.com/DeepMed-Lab-ECNU/Omni-Fuse。

</details>


### [76] [PointVDP: Learning View-Dependent Projection by Fireworks Rays for 3D Point Cloud Segmentation](https://arxiv.org/abs/2507.06618)
**中文标题：PointVDP：通过烟花射线学习视点依赖投影以实现3D点云分割**

*Yang Chen,Yueqi Duan,Haowen Sun,Ziwei Wang,Jiwen Lu,Yap-Peng Tan*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视点依赖投影（VDP）的方法PointVDP，通过动态适应不同视角的空间几何结构，生成高效的数据驱动投影，用于3D点云分割。该方法通过烟花射线启发的方式生成信息丰富的单图像输入，并通过颜色正则化优化框架，显著提升了计算效率和语义理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于投影的点云分割方法通常采用视点无关的投影，依赖于预定义的参数生成射线或曲线，限制了投影的多样性和点云感知能力。同时，多投影冗余导致计算开销大且效率低下。本文旨在设计一种动态适应视角变化的投影方法，以解决这些问题。

研究方法: 本文提出了视点依赖投影（VDP）框架，通过数据驱动的方式生成投影射线，灵感来源于烟花的自适应行为。此外，通过颜色正则化优化框架，突出语义像素中的关键特征并抑制非语义特征，最大化投影图像的2D空间利用率。

研究结果: 在S3DIS和ScanNet基准测试中，PointVDP方法取得了具有竞争力的结果，同时显著降低了计算开销，为语义理解提供了高效的解决方案。

研究结论: PointVDP通过动态适应视角变化的投影方法和颜色正则化优化，实现了高效的点云分割，为资源受限的场景提供了轻量级解决方案。

中文摘要: 本文提出了一种视点依赖投影（VDP）方法，用于促进点云分割，设计了一种高效的3D到2D动态映射，能够根据视角变化适应空间几何结构。现有的基于投影的方法在复杂场景中采用视点无关的投影，依赖于直线生成直接射线或向上曲线以减少遮挡。然而，这种视点无关性导致投影射线受限于人为预定义的参数，限制了点云感知能力，并无法捕捉不同视角平面上的投影多样性。尽管每个视角平面通常使用多个投影以增强空间多样性，但投影冗余会导致计算开销过大和图像处理效率低下。为解决这些问题，我们设计了VDP框架，通过数据驱动的方式从3D点分布生成投影，并受烟花自适应行为的启发预测射线，生成信息丰富的单图像输入。此外，我们构建了颜色正则化以优化框架，突出语义像素中的关键特征并抑制非语义特征（黑色像素），从而最大化投影图像的2D空间利用率。因此，我们的方法PointVDP在边际计算成本下实现了轻量级投影。在S3DIS和ScanNet基准测试中的实验表明，我们的方法取得了具有竞争力的结果，为语义理解提供了一种资源高效的解决方案。

</details>


### [77] [EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision](https://arxiv.org/abs/2507.06639)
**中文标题：EXAONE Path 2.0：基于端到端监督的病理学基础模型**

*Myungjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee*

主要分类: cs.CV

摘要简述: EXAONE Path 2.0提出了一种病理学基础模型，通过端到端的监督学习直接学习切片级别的表征，显著提高了数据效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前数字病理学中，大多数方法通过自监督学习训练补丁编码器，但这种方法可能忽略复杂的领域特异性特征，且数据效率较低。EXAONE Path 2.0旨在通过端到端监督学习解决这些问题。

研究方法: EXAONE Path 2.0采用端到端监督学习，直接利用切片级别的监督信号训练补丁级别的表征，避免了自监督学习的局限性。

研究结果: 仅使用37k全切片图像进行训练，EXAONE Path 2.0在10项生物标志物预测任务中达到了最先进的平均性能，表现出卓越的数据效率。

研究结论: EXAONE Path 2.0通过端到端监督学习显著提升了病理学表征的性能和数据效率，为数字病理学提供了更高效的解决方案。

中文摘要: 在数字病理学中，全切片图像（WSIs）因其千兆像素级的规模而难以处理，因此大多数方法通过自监督学习（SSL）训练补丁编码器，并通过多实例学习（MIL）或切片编码器聚合补丁级嵌入以用于下游任务。然而，补丁级的SSL可能忽略了对生物标志物预测（如突变状态和分子特征）至关重要的复杂领域特异性特征，因为SSL方法仅依赖于为自然图像领域选择的小补丁级区域的基本增强。此外，SSL方法的数据效率仍低于完全监督方法，需要大量的计算资源和数据集才能达到竞争性性能。为解决这些局限性，我们提出了EXAONE Path 2.0，这是一种在直接切片级监督下学习补丁级表征的病理学基础模型。仅使用37k WSIs进行训练，EXAONE Path 2.0在10项生物标志物预测任务中达到了最先进的平均性能，表现出显著的数据效率。

</details>


### [78] [Learning from Sparse Point Labels for Dense Carcinosis Localization in Advanced Ovarian Cancer Assessment](https://arxiv.org/abs/2507.06643)
**中文标题：从稀疏点标注中学习密集癌变定位用于晚期卵巢癌评估**

*Farahdiba Zarin,Riccardo Oliva,Vinkle Srivastav,Armine Vardazaryan,Andrea Rosati,Alice Zampolini Faustini,Giovanni Scambia,Anna Fagotti,Pietro Mascagni,Nicolas Padoy*

主要分类: cs.CV

摘要简述: 本文提出了一种从稀疏点标注中学习密集定位的方法，用于卵巢癌晚期评估中的癌变关键点定位，通过新的损失函数（Crag and Tail loss）有效利用稀疏标注，减少漏标影响。


<details>
  <summary>详细信息</summary>
研究动机: 在医学领域，密集标注成本高昂且难以获取，尤其是在新任务中。本文旨在解决从稀疏点标注中学习密集定位的挑战，以推动在标注不完善情况下的研究进展。

研究方法: 将问题建模为稀疏热图回归，并提出Crag and Tail损失函数，有效利用稀疏正标注并减少漏标或假阴性的影响。

研究结果: 通过大量实验验证，该方法在癌变关键点的密集定位任务中表现优异，展示了在标注稀缺场景下的潜力。

研究结论: 本文提出的方法为稀疏标注下的密集定位任务提供了有效解决方案，有望推动医学图像分析领域的研究。

中文摘要: 在医学领域，从稀疏标注中学习是一项常见挑战，这主要源于标注成本等因素，尤其在新任务中更为突出。当需要密集像素级标注时，这一问题更加难以解决。然而，能够从少量像素级标注中学习，尽管极为困难且未被充分利用，却能在标注不完善的研究中推动进展。本文致力于解决从稀疏点标注中学习密集预测任务（即关键点定位）的挑战，具体应用于腹腔镜视频帧中的2D癌变关键点定位，以支持晚期卵巢癌患者的诊断规划。为此，我们将问题建模为稀疏热图回归，并提出一种名为Crag and Tail的新损失函数，以实现高效学习。该损失函数有效利用稀疏正标注，同时最小化假阴性或漏标的影响。通过大量消融实验，我们证明了该方法在癌变关键点密集定位中的有效性，突显了其在标注稀缺场景下的研究潜力。

</details>


### [79] [ClipGS: Clippable Gaussian Splatting for Interactive Cinematic Visualization of Volumetric Medical Data](https://arxiv.org/abs/2507.06647)
**中文标题：ClipGS：支持裁剪的高斯泼溅技术用于医学体积数据的交互式电影级可视化**

*Chengkun Li,Yuqi Tong,Kai Chen,Zhenya Yang,Ruiyang Li,Shi Qiu,Jason Ying-Kuen Chan,Pheng-Ann Heng,Qi Dou*

主要分类: cs.CV

摘要简述: 本文提出ClipGS，一种支持裁剪平面的高斯泼溅框架，用于交互式医学体积数据的电影级可视化，通过可学习的截断方案和自适应调整模型，显著提升了渲染质量和效率。


<details>
  <summary>详细信息</summary>
研究动机: 医学体积数据的可视化对诊断和手术规划至关重要，但现有方法计算成本高、渲染速度慢，难以满足交互式需求。本文旨在解决这一问题，提供高质量且高效的交互式可视化方案。

研究方法: ClipGS框架结合了可学习的截断方案，根据裁剪平面动态调整高斯基元的可见性，并设计了自适应调整模型以优化高斯变形和渲染性能。

研究结果: 在五种医学体积数据（包括CT和解剖切片数据）上验证，ClipGS平均PSNR为36.635，帧率达156 FPS，模型大小仅16.1 MB，在渲染质量和效率上均优于现有方法。

研究结论: ClipGS通过创新的高斯泼溅框架和动态调整技术，实现了医学体积数据的高质量、高效交互式可视化，为医学应用提供了实用工具。

中文摘要: 医学体积数据的可视化对提升诊断准确性和改善手术规划与教育至关重要。电影级渲染技术通过提供高质量的视觉呈现，显著丰富了这一过程，能够传达复杂的解剖细节，从而促进医学领域的理解和决策。然而，高计算成本和低渲染速度限制了交互式可视化在实际应用中的需求。本文提出ClipGS，一种支持裁剪平面的创新高斯泼溅框架，用于医学体积数据的交互式电影级可视化。为应对动态交互带来的挑战，我们提出了一种可学习的截断方案，能够根据裁剪平面自动调整高斯基元的可见性。此外，我们还设计了一个自适应调整模型，动态优化高斯变形并提升渲染性能。我们在五种医学体积数据（包括CT和解剖切片数据）上验证了该方法，平均PSNR达到36.635，帧率为156 FPS，模型大小为16.1 MB，在渲染质量和效率上均优于现有方法。

</details>


### [80] [Diff$^2$I2P: Differentiable Image-to-Point Cloud Registration with Diffusion Prior](https://arxiv.org/abs/2507.06651)
**中文标题：Diff$^2$I2P：基于扩散先验的可微分图像到点云配准**

*Juncheng Mu,Chengwei Ren,Weixiang Zhang,Liang Pan,Xiao-Ping Zhang,Yue Gao*

主要分类: cs.CV

摘要简述: Diff$^2$I2P提出了一种基于扩散先验的可微分图像到点云配准框架，通过Control-Side Score Distillation和Deformable Correspondence Tuning模块，显著提升了跨模态配准性能，在7-Scenes基准测试中实现了超过7%的配准召回率提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像到点云配准方法主要依赖度量学习实现跨模态特征对齐，但忽略了图像与点云之间的固有模态差异，导致跨模态对应关系不准确。受扩散模型在跨模态生成中的成功启发，本文提出利用扩散先验来弥合模态差异。

研究方法: Diff$^2$I2P框架包含两个核心模块：1) Control-Side Score Distillation (CSD)，通过深度条件扩散模型直接优化预测变换；2) Deformable Correspondence Tuning (DCT)，以可微分方式估计对应关系，并结合可微分PnP求解器估计变换。扩散模型作为先验指导跨模态特征学习。

研究结果: 实验结果表明，Diff$^2$I2P在7-Scenes基准测试中显著优于现有方法，配准召回率提升超过7%。

研究结论: Diff$^2$I2P通过扩散先验和可微分模块设计，有效解决了跨模态配准中的模态差异问题，显著提升了配准性能。

中文摘要: 学习跨模态对应关系对于图像到点云（I2P）配准至关重要。现有方法主要通过度量学习实现跨模态特征对齐，但忽略了图像与点云之间的固有模态差异，导致跨模态对应关系不准确。为此，受近期大型扩散模型在跨模态生成中的成功启发，我们提出了Diff$^2$I2P，一种完全可微分的I2P配准框架，利用新颖且有效的扩散先验弥合模态差异。具体而言，我们提出了Control-Side Score Distillation (CSD)技术，从深度条件扩散模型中提取知识，直接优化预测变换。然而，由于对应关系检索和PnP求解器的不可微分性，变换梯度无法反向传播到跨模态特征上。为此，我们进一步提出了Deformable Correspondence Tuning (DCT)模块，以可微分方式估计对应关系，随后使用可微分PnP求解器估计变换。通过这两种设计，扩散模型作为强先验指导图像和点云的跨模态特征学习，形成鲁棒的对应关系，显著提升了配准性能。大量实验结果表明，Diff$^2$I2P在7-Scenes基准测试中始终优于现有I2P配准方法，配准召回率提升超过7%。

</details>


### [81] [MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval](https://arxiv.org/abs/2507.06654)
**中文标题：多源确定性点过程：用于文本到图像检索中复合属性上下文多样性优化的方法**

*Naoya Sogi,Takashi Shibata,Makoto Terao,Masanori Suganuma,Takayuki Okatani*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CDR-CA的新任务，旨在根据应用上下文优化多属性的多样性。通过扩展确定性点过程（DPP）为多源DPP（MS-DPP），并结合流形表示和切线归一化，实现了高效的多样性优化。实验证明了该方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的结果多样化方法仅关注图像外观的多样性指标，而忽略了应用场景的多样性需求。本文提出CDR-CA任务，旨在根据具体应用上下文优化多属性的多样性，以弥补传统方法的局限性。

研究方法: 本文提出多源确定性点过程（MS-DPP），通过扩展DPP为多源模型，并使用基于流形表示的统一相似性矩阵。此外，引入切线归一化以反映上下文信息。

研究结果: 实验结果表明，MS-DPP在优化多属性多样性方面表现出色，能够根据应用上下文灵活调整多样性指标。

研究结论: 本文提出的MS-DPP方法为CDR-CA任务提供了简单而强大的基线，通过多源扩展和上下文归一化，显著提升了多样性优化的效果。

中文摘要: 结果多样化（RD）是文本到图像检索中的一项关键技术，用于提升实际应用的效率。传统方法仅关注图像外观的多样性指标，但多样性指标及其期望值因应用场景而异，这限制了RD的应用范围。本文提出了一种名为CDR-CA（复合属性的上下文多样性优化）的新任务，旨在根据应用上下文优化多属性的多样性。为解决此任务，我们提出了多源确定性点过程（MS-DPP），这是一种简单而强大的基线方法，将确定性点过程（DPP）扩展为多源模型。我们将MS-DPP建模为基于流形表示的统一相似性矩阵的单一DPP模型，并引入切线归一化以反映上下文。大量实验证明了所提方法的有效性。我们的代码公开在https://github.com/NEC-N-SOGI/msdpp。

</details>


### [82] [Enhancing Diffusion Model Stability for Image Restoration via Gradient Management](https://arxiv.org/abs/2507.06656)
**中文标题：通过梯度管理增强扩散模型在图像恢复中的稳定性**

*Hongjie Wu,Mingqin Zhang,Linchao He,Ji-Zhe Zhou,Jiancheng Lv*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SPGD的新型梯度管理技术，通过渐进式似然预热和自适应方向动量平滑，解决了扩散模型在图像恢复中的梯度不稳定问题，显著提升了生成稳定性和恢复性能。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在图像恢复中表现出色，但其生成过程中先验梯度与似然梯度的冲突以及似然梯度的时序波动导致不稳定，影响恢复效果。本文旨在分析并解决这些梯度动态问题。

研究方法: 提出SPGD技术，包含两部分：(1) 渐进式似然预热策略以减少梯度冲突；(2) 自适应方向动量平滑以降低似然梯度的波动。

研究结果: 实验表明，SPGD在多种恢复任务中显著提升了生成稳定性，并在定量指标和视觉效果上达到最优性能。

研究结论: SPGD通过梯度管理有效解决了扩散模型在图像恢复中的不稳定问题，为相关领域提供了新的技术方向。

中文摘要: 扩散模型通过利用强大的先验在图像恢复中展现出显著潜力。主流方法通常将恢复问题置于贝叶斯推断框架中，迭代结合去噪步骤和似然引导步骤。然而，生成过程中这两部分的梯度动态交互尚未充分研究。本文分析了这些组件的底层梯度动态，并识别出显著的不稳定性。具体而言，我们展示了先验与似然梯度方向的冲突，以及似然梯度本身的时序波动。这些不稳定性会破坏生成过程并损害恢复性能。为解决这些问题，我们提出了一种新型梯度管理技术——稳定渐进梯度扩散（SPGD）。SPGD整合了两项协同组件：(1) 渐进式似然预热策略以缓解梯度冲突；(2) 自适应方向动量（ADM）平滑以减少似然梯度的波动。在多种恢复任务中的广泛实验表明，SPGD显著提升了生成稳定性，在定量指标和视觉结果上均达到最优性能。代码发布于\href{https://github.com/74587887/SPGD}{此处}。

</details>


### [83] [MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning](https://arxiv.org/abs/2507.06662)
**中文标题：MK-Pose：基于多模态关键点学习的类别级物体姿态估计**

*Yifan Yang,Peili Song,Enfan Lan,Dong Liu,Jingtai Liu*

主要分类: cs.CV

摘要简述: MK-Pose是一种基于多模态关键点学习的类别级物体姿态估计框架，结合RGB图像、点云和文本描述，通过自监督关键点检测和注意力机制提升性能，在多个数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 类别级物体姿态估计在仓库自动化和制造等领域至关重要，但现有方法因依赖单一模态（如RGB或点云）而难以应对物体遮挡和跨实例泛化问题。

研究方法: MK-Pose整合RGB图像、点云和类别级文本描述，采用自监督关键点检测模块，结合注意力查询生成、软热图匹配和图关系建模，并设计图增强特征融合模块以整合局部几何和全局上下文信息。

研究结果: 在CAMERA25、REAL275和HouseCat6D数据集上的实验表明，MK-Pose在IoU和平均精度上均优于现有方法，且无需形状先验。

研究结论: MK-Pose通过多模态关键点学习显著提升了类别级物体姿态估计的性能，为实际应用提供了高效解决方案。

中文摘要: 类别级物体姿态估计旨在无需先验实例知识的情况下预测已知类别物体的姿态，在仓库自动化和制造等领域具有重要意义。现有方法依赖RGB图像或点云数据，常因物体遮挡和跨实例泛化问题表现不佳。本文提出一种基于多模态关键点学习的框架（MK-Pose），整合RGB图像、点云和类别级文本描述。该模型采用自监督关键点检测模块，结合注意力查询生成、软热图匹配和图关系建模，并设计图增强特征融合模块以整合局部几何和全局上下文信息。MK-Pose在CAMERA25和REAL275数据集上进行了评估，并在HouseCat6D数据集上测试了跨数据集能力。结果表明，MK-Pose在无需形状先验的情况下，IoU和平均精度均优于现有方法。代码将在https://github.com/yangyifanYYF/MK-Pose发布。

</details>


### [84] [FlexGaussian: Flexible and Cost-Effective Training-Free Compression for 3D Gaussian Splatting](https://arxiv.org/abs/2507.06671)
**中文标题：FlexGaussian：一种灵活且经济高效的免训练3D高斯泼溅压缩方法**

*Boyuan Tian,Qizhe Gao,Siran Xianyu,Xiaotong Cui,Minjia Zhang*

主要分类: cs.CV

摘要简述: FlexGaussian是一种无需训练的3D高斯泼溅压缩方法，结合混合精度量化和属性判别剪枝，实现高压缩比（96.4%）和快速部署（1.7-2.1倍于现有方法）。


<details>
  <summary>详细信息</summary>
研究动机: 3D高斯泼溅技术因其高保真和快速渲染优势被广泛应用，但大规模模型对内存和计算资源的需求增加，现有压缩方法需重新训练或微调，缺乏灵活性。

研究方法: FlexGaussian采用混合精度量化和属性判别剪枝，无需重新训练，灵活适应不同压缩目标。

研究结果: 实验显示，FlexGaussian压缩比达96.4%，渲染质量损失小（PSNR下降<1 dB），部署速度快（1.7-2.1倍于现有方法）。

研究结论: FlexGaussian提供了一种高效、灵活的3D高斯泼溅压缩方案，适用于资源受限设备。

中文摘要: 3D高斯泼溅技术因其高保真和快速渲染优势成为复杂3D场景表示的主流方法。然而，大规模模型对内存和计算资源的需求增加，亟需高效压缩方法以降低资源消耗，尤其是在移动和边缘设备上。现有压缩方法虽能有效减少3D高斯参数，但通常需要重新训练或微调，缺乏灵活性。本文提出FlexGaussian，一种结合混合精度量化和属性判别剪枝的免训练压缩方法，无需重新训练且能灵活适应不同压缩目标。实验结果表明，FlexGaussian压缩比高达96.4%，同时保持高渲染质量（PSNR下降<1 dB），并可快速部署于移动设备，速度比现有免训练方法快1.7-2.1倍，比需训练方法快10-100倍。代码即将发布于：https://github.com/Supercomputing-System-AI-Lab/FlexGaussian

</details>


### [85] [Text-promptable Object Counting via Quantity Awareness Enhancement](https://arxiv.org/abs/2507.06679)
**中文标题：通过数量感知增强实现文本提示对象计数**

*Miaojing Shi,Xiaowen Zhang,Zijie Yue,Yong Luo,Cairong Zhao,Li Li*

主要分类: cs.CV

摘要简述: 本文提出QUANet，通过引入数量导向的文本提示和视觉-文本数量对齐损失，增强模型对数量的感知能力，并设计双流自适应计数解码器，提升密度图预测效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于视觉-语言模型的方法在文本提示对象计数任务中表现优异，但缺乏对对象数量的准确区分能力。本文旨在通过增强模型的数量感知能力，解决这一问题。

研究方法: 提出QUANet，包括数量导向的文本提示和视觉-文本对齐损失；设计双流自适应计数解码器（Transformer流和CNN流），通过T2C适配器促进两流知识交流，并引入跨流数量排序损失优化预测结果。

研究结果: 在FSC-147、CARPK、PUCPR+和ShanghaiTech等标准基准测试中，QUANet表现出强大的零样本类无关计数泛化能力。

研究结论: QUANet通过增强数量感知和双流解码器设计，显著提升了文本提示对象计数的性能，为相关任务提供了有效解决方案。

中文摘要: 近年来，大型视觉-语言模型（VLMs）在解决文本提示对象计数问题上取得了显著进展。代表性方法通常通过图像中的对象类别信息指定文本提示，但这不足以训练模型在计数任务中准确区分对象数量。为此，我们提出QUANet，引入新颖的数量导向文本提示和视觉-文本数量对齐损失，以增强模型的数量感知能力。此外，我们提出了一种双流自适应计数解码器，由Transformer流、CNN流和多个Transformer到CNN增强适配器（T2C适配器）组成，用于密度图预测。T2C适配器促进了Transformer流和CNN流之间的有效知识交流与聚合。最后，提出了一种跨流数量排序损失，以优化两流预测的排序顺序。在FSC-147、CARPK、PUCPR+和ShanghaiTech等标准基准测试上的大量实验表明，我们的模型在零样本类无关计数方面具有强大的泛化能力。代码发布于https://github.com/viscom-tongji/QUANet。

</details>


### [86] [StixelNExT++: Lightweight Monocular Scene Segmentation and Representation for Collective Perception](https://arxiv.org/abs/2507.06687)
**中文标题：StixelNExT++：用于集体感知的轻量级单目场景分割与表示方法**

*Marcel Vosshans,Omar Ait-Aider,Youcef Mezouar,Markus Enzweiler*

主要分类: cs.CV

摘要简述: StixelNExT++ 是一种轻量级单目场景分割与表示方法，通过聚类3D Stixel单元实现高效场景压缩，适用于集体感知系统。


<details>
  <summary>详细信息</summary>
研究动机: 现有单目感知系统在场景表示和分割方面存在信息压缩不足和适应性差的问题，StixelNExT++旨在提供一种高效且适应性强的解决方案。

研究方法: 基于Stixel表示，通过聚类3D Stixel单元增强对象分割，并设计轻量级神经网络，利用LiDAR生成的真实数据进行训练，实现实时处理。

研究结果: 在Waymo数据集上，StixelNExT++在30米范围内表现出色，每帧处理时间低至10毫秒，适用于集体感知。

研究结论: StixelNExT++为单目感知系统提供了一种高效、轻量级的场景表示方法，具有在自主系统中实现集体感知的潜力。

中文摘要: 本文提出了一种新颖的单目感知系统场景表示方法——StixelNExT++。该方法基于现有的Stixel表示，通过聚类3D Stixel单元增强对象分割，实现了场景信息的高效压缩，同时适应点云和鸟瞰图表示。我们的轻量级神经网络利用LiDAR自动生成的真实数据进行训练，每帧处理时间低至10毫秒，实现了实时性能。在Waymo数据集上的实验结果表明，该方法在30米范围内具有竞争力，展现了StixelNExT++在自主系统集体感知中的潜力。

</details>


### [87] [Spatial-Temporal Graph Mamba for Music-Guided Dance Video Synthesis](https://arxiv.org/abs/2507.06689)
**中文标题：基于空间-时间图Mamba的音乐引导舞蹈视频合成**

*Hao Tang,Ling Shao,Zhenyu Zhang,Luc Van Gool,Nicu Sebe*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的空间-时间图Mamba（STG-Mamba）方法，用于音乐引导的舞蹈视频合成任务。该方法通过两个映射步骤（音乐到骨架和骨架到视频）实现舞蹈视频生成，并在实验中显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 音乐引导的舞蹈视频合成是一个具有挑战性的任务，需要同时考虑音乐的节奏和舞蹈动作的空间-时间依赖性。现有方法在捕捉这些复杂关系时表现不足，因此本文提出了一种新的框架来解决这一问题。

研究方法: STG-Mamba包含两个主要步骤：1）音乐到骨架的翻译，使用空间-时间图Mamba（STGM）块捕捉关节的空间和时间依赖性；2）骨架到视频的翻译，采用自监督正则化网络将生成的骨架和条件图像转换为舞蹈视频。此外，还收集了一个新的骨架到视频数据集。

研究结果: 实验表明，STG-Mamba在音乐引导的舞蹈视频合成任务中显著优于现有方法，生成的视频质量更高。

研究结论: 本文提出的STG-Mamba框架通过结合空间-时间图Mamba和自监督正则化网络，成功实现了高质量的音乐引导舞蹈视频合成，为相关领域提供了新的解决方案。

中文摘要: 我们提出了一种新颖的空间-时间图Mamba（STG-Mamba）方法，用于音乐引导的舞蹈视频合成任务，即将输入音乐转换为舞蹈视频。STG-Mamba包含两个翻译映射：音乐到骨架的翻译和骨架到视频的翻译。在音乐到骨架的翻译中，我们引入了一种新的空间-时间图Mamba（STGM）块，以有效构建输入音乐的骨架序列，捕捉关节在空间和时间维度上的依赖性。对于骨架到视频的翻译，我们提出了一种新的自监督正则化网络，将生成的骨架与条件图像转换为舞蹈视频。最后，我们从互联网上收集了一个新的骨架到视频翻译数据集，包含54,944个视频片段。大量实验表明，STG-Mamba的结果显著优于现有方法。

</details>


### [88] [A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding](https://arxiv.org/abs/2507.06719)
**中文标题：基于LLM驱动空间推理的神经表示框架用于开放词汇3D视觉定位**

*Zhenyang Liu,Sixiao Zheng,Siyu Chen,Cairong Zhao,Longfei Liang,Xiangyang Xue,Yanwei Fu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于神经表示和大型语言模型（LLM）驱动的空间推理框架SpatialReasoner，用于开放词汇3D视觉定位，显著提升了基于空间关系的目标定位能力。


<details>
  <summary>详细信息</summary>
研究动机: 开放词汇3D视觉定位在自主导航、机器人和增强现实等应用中至关重要，但现有方法难以准确处理语言查询中的空间关系（如“椅子上的书”）。主要原因是缺乏对语言和3D场景中空间关系的充分推理。

研究方法: SpatialReasoner通过微调LLM捕获语言查询中的空间关系，并显式推断目标、锚点和空间关系的指令。同时，结合视觉属性（透明度和颜色）构建分层特征场，利用CLIP特征和SAM提取的掩码表示语言和实例特征，最终通过分层查询定位目标3D实例。

研究结果: 实验表明，该框架可无缝集成到不同神经表示中，显著优于基线模型，并增强了其空间推理能力。

研究结论: SpatialReasoner通过结合LLM驱动的空间推理和分层特征场，有效解决了开放词汇3D视觉定位中的空间关系处理问题，为实际应用提供了更强大的工具。

中文摘要: 开放词汇3D视觉定位旨在基于自由形式的语言查询定位目标对象，这对自主导航、机器人和增强现实等具身AI应用至关重要。通过学习3D语言场的神经表示，可以从有限视角准确理解3D场景，并在复杂环境中定位目标对象。然而，现有语言场方法难以利用语言查询中的空间关系（如“椅子上的书”）准确定位实例，主要原因是缺乏对语言查询和3D场景中空间关系的充分推理。本文提出SpatialReasoner，一种基于神经表示的新型框架，结合大型语言模型（LLM）驱动的空间推理，构建视觉属性增强的分层特征场用于开放词汇3D视觉定位。为实现语言查询中的空间推理，SpatialReasoner微调LLM以捕获空间关系并显式推断目标、锚点和空间关系的指令。为实现3D场景中的空间推理，SpatialReasoner结合视觉属性（透明度和颜色）构建分层特征场，利用蒸馏的CLIP特征和通过Segment Anything Model（SAM）提取的掩码表示语言和实例特征。随后，通过分层查询该特征场，根据语言查询中的空间关系定位目标3D实例。大量实验表明，该框架可无缝集成到不同神经表示中，显著优于基线模型，同时增强了其空间推理能力。

</details>


### [89] [Hierarchical Feature Alignment for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2507.06732)
**中文标题：基于分层特征对齐的无注释手语翻译**

*Sobhan Asasi,Mohamed Ilyes Lakhal,Richard Bowden*

主要分类: cs.CV

摘要简述: 本文提出了一种无注释的手语翻译方法，通过分层特征对齐策略提升翻译质量，实验证明其效果优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有手语翻译方法在视觉与文本表示之间存在差异，基于注释的方法虽能缓解这一问题，但注释成本高。无注释方法灵活性更高，但需有效的对齐策略。本文旨在通过分层预训练策略解决这一问题。

研究方法: 提出了一种分层预训练策略，从视频中提取帧、片段和视频级别的特征，并通过伪注释和对比视频-语言对齐将其与口语句子对齐。

研究结果: 实验表明，该方法在BLEU-4和ROUGE分数上表现更优，同时保持了高效性。

研究结论: 分层特征对齐策略显著提升了无注释手语翻译的质量，为未来研究提供了新思路。

中文摘要: 手语翻译（SLT）旨在将手语视频转换为口语句子。然而，现有方法在端到端学习中常面临视觉与文本表示之间的差异。基于注释的方法通过利用结构化语言信息缓解了这一问题，而无注释方法虽更灵活且无需标注负担，但需有效的对齐策略。近年来，大型语言模型（LLMs）的进展使得通过生成类似文本的表示实现无注释SLT成为可能。本文提出了一种受手语结构启发的分层预训练策略，结合伪注释和对比视频-语言对齐。该方法分层提取帧、片段和视频级别的特征，并将其与伪注释及口语句子对齐以提升翻译质量。实验表明，该方法在BLEU-4和ROUGE分数上表现更优，同时保持了高效性。

</details>


### [90] [MADPOT: Medical Anomaly Detection with CLIP Adaptation and Partial Optimal Transport](https://arxiv.org/abs/2507.06733)
**中文标题：MADPOT：基于CLIP适配与部分最优传输的医学异常检测**

*Mahshid Shiri,Cigdem Beyan,Vittorio Murino*

主要分类: cs.CV

摘要简述: 本文提出了一种结合视觉适配器、提示学习和部分最优传输（POT）的医学异常检测方法，通过对比学习提升CLIP在医学图像中的适应性，实现了在少样本、零样本和跨数据集场景下的最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学异常检测面临成像模态多样、解剖结构变化大和标注数据有限等挑战。现有方法通常依赖单一表示或大量合成数据，难以捕捉细微异常。本文旨在通过多提示学习和POT提升CLIP在医学图像中的适应性。

研究方法: 方法结合视觉适配器和提示学习，利用部分最优传输（POT）对齐局部特征以捕捉细微异常，并通过对比学习增强类内凝聚和类间分离。

研究结果: 在少样本、零样本和跨数据集场景下，该方法无需合成数据或记忆库即达到最优性能，显著优于现有方法。

研究结论: 本文提出的方法通过多提示学习和POT有效提升了医学异常检测的性能，为小样本和跨数据集场景提供了实用解决方案。

中文摘要: 医学异常检测（AD）因成像模态多样、解剖结构变化大和标注数据有限而具有挑战性。我们提出了一种结合视觉适配器、提示学习和部分最优传输（POT）的新方法，通过对比学习（CL）提升CLIP在医学图像中的适应性，尤其适用于AD。与标准提示学习通常生成单一表示不同，我们的方法通过POT对齐多个提示与局部特征，以捕捉细微异常。CL进一步增强了类内凝聚和类间分离。该方法在少样本、零样本和跨数据集场景中无需合成数据或记忆库即达到最优性能。代码发布于https://github.com/mahshid1998/MADPOT。

</details>


### [91] [Residual Prior-driven Frequency-aware Network for Image Fusion](https://arxiv.org/abs/2507.06735)
**中文标题：基于残差先验的频率感知网络用于图像融合**

*Guan Zheng,Xue Wang,Wenhua Qian,Peng Liu,Runzhuo Ma*

主要分类: cs.CV

摘要简述: 本文提出了一种基于残差先验的频率感知网络（RPFNet），用于图像融合，通过双分支特征提取框架和频率域卷积实现高效全局特征建模，显著提升融合图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 图像融合旨在整合多模态互补信息以生成高质量融合图像，但现有方法在空间域构建长程特征依赖时计算成本高，且缺乏真实标签导致互补特征捕获困难。

研究方法: RPFNet采用双分支框架：残差先验模块（RPM）从残差图中提取模态差异信息；频率域融合模块（FDFM）通过频域卷积实现全局特征建模；交叉促进模块（CPM）通过双向特征交互增强局部与全局感知。训练中引入辅助解码器和显著性结构损失，并结合自适应权重频域对比损失和SSIM损失约束解空间。

研究结果: 实验表明，RPFNet能有效整合判别性特征，增强纹理细节和显著目标，显著提升融合性能，并促进高级视觉任务的部署。

研究结论: RPFNet通过残差先验和频域建模，解决了图像融合中的计算效率和互补特征捕获问题，为多模态图像融合提供了高效解决方案。

中文摘要: 图像融合旨在整合多模态互补信息以生成高质量融合图像，从而提升高级视觉任务的性能。尽管全局空间建模机制表现出良好效果，但在空间域构建长程特征依赖会带来高昂计算成本。此外，缺乏真实标签进一步加剧了有效捕获互补特征的难度。为解决这些问题，我们提出了一种基于残差先验的频率感知网络（RPFNet）。具体而言，RPFNet采用双分支特征提取框架：残差先验模块（RPM）从残差图中提取模态差异信息，为融合提供互补先验；频率域融合模块（FDFM）通过频域卷积实现高效的全局特征建模与整合。此外，交叉促进模块（CPM）通过双向特征交互增强局部细节与全局结构的协同感知。训练过程中，我们引入辅助解码器和显著性结构损失以增强模型对模态差异的敏感性。同时，结合基于自适应权重的频域对比损失和SSIM损失，有效约束解空间，促进局部细节与全局特征的联合捕获，并确保互补信息的保留。大量实验验证了RPFNet的融合性能，其能有效整合判别性特征，增强纹理细节和显著目标，并有效促进高级视觉任务的部署。

</details>


### [92] [DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement](https://arxiv.org/abs/2507.06738)
**中文标题：DIFFUMA：基于双路径Mamba和扩散增强的高保真时空视频预测**

*Xinyu Xie,Weifeng Cao,Jun Shi,Yangyang Hu,Hui Liang,Wanyong Liang,Xiaoliang Qian*

主要分类: cs.CV

摘要简述: 本文提出DIFFUMA模型，结合双路径Mamba和扩散增强技术，用于高保真时空视频预测，并在半导体切割领域发布首个公开数据集CHDL，显著提升预测精度。


<details>
  <summary>详细信息</summary>
研究动机: 在半导体制造等高精度工业场景中，缺乏专用数据集阻碍了复杂过程建模与预测的研究。本文旨在填补这一空白，并提供高性能预测模型。

研究方法: 提出DIFFUMA模型，通过并行Mamba模块捕获全局长时序上下文，同时利用扩散模块增强空间细节，有效对抗特征退化。

研究结果: 在CHDL数据集上，DIFFUMA显著优于现有方法，MSE降低39%，SSIM从0.926提升至0.988。

研究结论: 本文不仅提出新的SOTA模型，还为工业AI研究提供了宝贵的数据资源。

中文摘要: 时空视频预测在天气预测和工业自动化等关键领域具有重要作用。然而，在半导体制造等高精度工业场景中，缺乏专用基准数据集严重阻碍了对复杂过程建模和预测的研究。为解决这一问题，本文做出两点贡献。首先，我们构建并发布了首个面向半导体晶圆切割过程的公开时序图像数据集CHDL。该数据集通过工业级视觉系统捕获，为高保真过程建模、缺陷检测和数字孪生开发提供了亟需且具有挑战性的基准。其次，我们提出了DIFFUMA，一种专为此类细粒度动态设计的创新双路径预测架构。该模型通过并行Mamba模块捕获全局长时序上下文，同时利用由时序特征引导的扩散模块恢复和增强细粒度空间细节，有效对抗特征退化。实验表明，在CHDL基准上，DIFFUMA显著优于现有方法，将均方误差（MSE）降低39%，并将结构相似性（SSIM）从0.926提升至接近完美的0.988。这一卓越性能在自然现象数据集上也具有普适性。我们的工作不仅提供了新的SOTA模型，更重要的是为工业AI的未来研究提供了宝贵的数据资源。

</details>


### [93] [PromptTea: Let Prompts Tell TeaCache the Optimal Threshold](https://arxiv.org/abs/2507.06739)
**中文标题：PromptTea：让提示告诉TeaCache最优阈值**

*Zishen Huang,Chunyu Yang,Mengyuan Ren*

主要分类: cs.CV

摘要简述: 本文提出PromptTea方法，通过输入提示自动调整缓存阈值，结合动态机制优化视频生成速度与质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频生成中的固定频率缓存机制在复杂场景下质量下降明显，手动调整阈值效率低且不鲁棒，亟需自适应方法。

研究方法: 提出Prompt-Complexity-Aware (PCA)缓存，基于输入提示估计场景复杂度动态调整阈值；改进TeaCache的输入-输出关系建模，增强文本信息贡献；引入DynCFGCache动态选择CFG输出重用。

研究结果: 实验显示，方法在Wan2.1模型上实现2.79倍加速，同时保持高质量输出。

研究结论: PromptTea通过自适应缓存和动态机制，显著提升视频生成效率且不牺牲质量。

中文摘要: 尽管视频生成技术近期取得进展，推理速度仍是主要瓶颈。常见的加速策略是通过固定间隔的缓存机制重用模型输出。然而，我们发现这种固定频率的重用在复杂场景中会显著降低质量，而手动调整重用阈值效率低下且缺乏鲁棒性。为此，我们提出Prompt-Complexity-Aware (PCA)缓存，该方法根据直接从输入提示估计的场景复杂度自动调整重用阈值。通过结合提示衍生的语义线索，PCA比传统缓存方法做出更具适应性和信息量的重用决策。我们还重新审视了TeaCache的假设，发现其因过于简化的先验而存在输入-输出关系建模不佳的关键限制。为克服这一点，我们解耦噪声输入，增强有意义文本信息的贡献，并通过多元多项式特征扩展提高模型的预测准确性。为进一步降低计算成本，我们用DynCFGCache替换静态CFGCache，这是一种基于估计输出变化选择性重用无分类器引导(CFG)输出的动态机制。这使得重用更灵活且不影响输出质量。大量实验表明，我们的方法实现了显著加速（例如在Wan2.1模型上达到2.79倍速度提升），同时在一系列场景中保持高视觉保真度。

</details>


### [94] [Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching](https://arxiv.org/abs/2507.06744)
**中文标题：双粒度跨模态身份关联的弱监督文本到人物图像匹配**

*Yafei Zhang,Yongle Shang,Huafeng Li*

主要分类: cs.CV

摘要简述: 本文提出了一种双粒度跨模态身份关联机制，通过局部和全局的双重关联策略，显著提升了弱监督文本到人物图像匹配的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法难以处理复杂的一对多身份关系，限制了性能提升。为减少模型对大规模人工标注样本的依赖，本文提出了一种新的身份关联机制。

研究方法: 方法包括局部粒度上显式建立跨模态身份关系，全局粒度上构建动态跨模态身份关联网络，并结合信息不对称样本对和一致性学习增强模型鲁棒性。

研究结果: 实验结果表明，该方法显著提升了跨模态匹配的准确性，为文本到人物图像匹配提供了高效实用的解决方案。

研究结论: 本文提出的双粒度身份关联机制有效解决了弱监督匹配中的复杂关系问题，为跨模态匹配任务提供了新思路。

中文摘要: 弱监督文本到人物图像匹配作为一种减少模型对大规模人工标注样本依赖的关键方法，具有重要的研究价值。然而，现有方法难以预测复杂的一对多身份关系，严重限制了性能提升。为解决这一问题，我们提出了一种局部和全局双粒度的身份关联机制。具体而言，在局部粒度上，我们显式建立批次内的跨模态身份关系，强化不同模态间的身份约束，使模型能更好地捕捉细微差异和相关性。在全局粒度上，我们以视觉模态为锚点构建动态跨模态身份关联网络，并引入基于置信度的动态调整机制，有效提升模型对弱关联样本的识别能力，同时增强整体敏感性。此外，我们提出了一种信息不对称样本对构建方法，结合一致性学习解决困难样本挖掘问题并增强模型鲁棒性。实验结果表明，所提方法显著提升了跨模态匹配的准确性，为文本到人物图像匹配提供了高效实用的解决方案。

</details>


### [95] [Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu](https://arxiv.org/abs/2507.06761)
**中文标题：微调视觉语言模型作为低资源语言的OCR系统：以满文为例**

*Yan Hon Michael Chung,Donghyeok Choi*

主要分类: cs.CV

摘要简述: 本研究通过微调三种开源视觉语言模型（LLaMA-3.2-11B、Qwen2.5-VL-7B、Qwen2.5-VL-3B），在6万张合成的满文单词图像上训练，成功开发出高性能OCR系统。LLaMA-3.2-11B在合成数据上表现优异（98.3%单词准确率），并在真实手写文档上保持93.1%的准确率，显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 满文作为一种濒危语言，对研究早期现代东亚历史至关重要，但目前缺乏能够处理真实历史文档的有效OCR系统。本研究旨在填补这一技术空白，为历史学家和语言学家提供低成本、易部署的解决方案。

研究方法: 研究采用参数高效训练方法，对三种开源视觉语言模型（LLaMA-3.2-11B、Qwen2.5-VL-7B、Qwen2.5-VL-3B）在6万张合成的满文单词图像上进行微调，并通过合成数据到真实文档的领域迁移验证性能。

研究结果: LLaMA-3.2-11B在合成数据上达到98.3%的单词准确率和0.0024的字符错误率，在真实手写文档上保持93.1%的准确率，显著优于传统CRNN基线（真实文档准确率仅72.5%）。

研究结论: 本研究为濒危语言OCR提供了一种高效、低成本的解决方案，解决了数字人文学科中的技术和财务障碍，使历史学家和语言学家能够在无需专用计算资源的情况下处理历史档案。

中文摘要: 满文作为一种对理解早期现代东亚历史至关重要的濒危语言，目前缺乏能够处理真实历史文档的有效OCR系统。本研究通过参数高效训练方法，在6万张合成的满文单词图像上微调三种开源视觉语言模型（LLaMA-3.2-11B、Qwen2.5-VL-7B、Qwen2.5-VL-3B），成功开发出高性能OCR系统。LLaMA-3.2-11B在合成数据上表现优异，单词准确率达98.3%，字符错误率为0.0024，同时在真实手写文档上保持93.1%的准确率。与传统方法相比，CRNN基线在合成数据上虽达到99.8%的准确率，但在真实文档上性能严重下降至72.5%。本研究展示了有效的合成到真实领域迁移，提供了一种可在普通基础设施上部署的低成本解决方案，为濒危语言OCR建立了可推广的框架，消除了数字人文学科中的技术和财务障碍，使历史学家和语言学家能够无需专用计算资源即可处理历史档案。代码和模型权重发布于https://github.com/mic7ch1/ManchuAI-OCR。

</details>


### [96] [FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views](https://arxiv.org/abs/2507.06763)
**中文标题：FOLC-Net：一种联邦优化的轻量级架构，用于增强MRI疾病诊断在轴向、冠状和矢状视图中的性能**

*Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel*

主要分类: cs.CV

摘要简述: FOLC-Net是一种联邦优化的轻量级架构，旨在提升MRI疾病诊断在轴向、冠状和矢状视图中的性能，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有MRI疾病诊断模型在处理轴向、冠状和矢状视图时性能下降，FOLC-Net旨在解决这一问题，提供更可靠的解决方案。

研究方法: FOLC-Net结合了Manta-ray觅食优化（MRFO）机制、全局模型克隆和ConvNeXt，生成高效模型结构，参数仅121.7万，存储需求0.9MB。

研究结果: FOLC-Net在矢状视图上准确率达92.44%，显著优于其他方法（88.37%和88.95%），并在所有单视图和多视图场景中表现更优。

研究结论: FOLC-Net通过MRFO、全局模型克隆和ConvNeXt，提供了更适应单视图且在多视图中性能强劲的解决方案，适用于实际医疗应用。

中文摘要: 该框架旨在提升MRI疾病诊断在组合及单一解剖视角中的性能，特别针对现有先进模型在处理轴向、冠状和矢状解剖平面时的性能下降问题。本文提出了FOLC-Net框架，采用了一种新颖的联邦优化轻量级架构，参数约121.7万，存储需求仅0.9MB。FOLC-Net整合了Manta-ray觅食优化（MRFO）机制以高效生成模型结构，全局模型克隆以实现可扩展训练，以及ConvNeXt以增强客户端适应性。模型在组合多视图数据及单视图（如轴向、冠状和矢状）上进行了评估，以验证其在多种医学影像场景中的鲁棒性。此外，FOLC-Net测试了ShallowFed模型在不同数据上的泛化能力。结果显示，FOLC-Net优于现有模型，尤其在具有挑战性的矢状视图中表现突出。例如，FOLC-Net在矢状视图上的准确率达92.44%，显著高于研究方法（DL + 残差学习）的88.37%和DL模型的88.95%。此外，FOLC-Net在所有单视图中均表现出更高的准确率，为去中心化环境中的医学影像分析提供了更可靠和鲁棒的解决方案。FOLC-Net通过整合MRFO、全局模型克隆和ConvNeXt，解决了现有先进模型的局限性，确保其在单视图中具有更好的适应性，同时保持多视图中的强劲性能。

</details>


### [97] [Unlocking Thermal Aerial Imaging: Synthetic Enhancement of UAV Datasets](https://arxiv.org/abs/2507.06797)
**中文标题：解锁热成像航拍：无人机数据集的合成增强**

*Antonella Barisic Kulas,Andreja Jurasovic,Stjepan Bogdan*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的合成热成像增强方法，通过将新物体类别整合到现有热成像背景中，扩展了无人机热成像数据集，提升了深度学习模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 无人机热成像在搜救、野生动物监测和应急响应等领域潜力巨大，但大规模多样化热成像数据集的稀缺限制了深度学习模型的发展。本文旨在解决这一数据不足的问题。

研究方法: 提出了一种生成合成热成像的流程，通过控制新物体的位置、尺度和方向，将其整合到现有热成像背景中，并扩展了HIT-UAV和MONET数据集，新增了无人机和动物类别。

研究结果: 实验表明，合成增强后的数据集在目标检测任务中表现优异，热成像检测器性能优于可见光训练模型，且模拟航拍视角的重要性得到验证。

研究结论: 通过合成方法扩展热成像数据集是可行的，能够显著提升模型性能，并为新应用领域提供支持。

中文摘要: 无人机热成像在搜救、野生动物监测和应急响应等领域具有重要潜力，尤其是在低光或遮挡条件下。然而，由于采集热成像数据的高成本和复杂后勤问题，大规模多样化热成像数据集的稀缺限制了深度学习模型在该领域的发展。本文提出了一种新颖的流程，用于从航拍视角生成合成热成像。我们的方法通过控制新物体的位置、尺度和方向，将其整合到现有热成像背景中，并与背景视角对齐。我们通过新增物体类别扩展了现有热成像数据集，具体包括在HIT-UAV数据集中添加城市环境中的无人机类别，以及在MONET数据集中添加动物类别。在目标检测任务中评估这些数据集时，我们展示了新类别和现有类别的优异性能，验证了其在新应用中的成功扩展。通过对比分析，我们发现热成像检测器性能优于可见光训练模型，并强调了模拟航拍视角的重要性。项目页面：https://github.com/larics/thermal_aerial_synthetic。

</details>


### [98] [GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction](https://arxiv.org/abs/2507.06806)
**中文标题：GreenHyperSpectra：用于全球植被特征预测的多源高光谱数据集**

*Eya Cherif,Arthur Ouaknine,Luke A. Brown,Phuong D. Dao,Kyle R. Kovach,Bing Lu,Daniel Mederer,Hannes Feilhauer,Teja Kattenborn,David Rolnick*

主要分类: cs.CV

摘要简述: GreenHyperSpectra是一个多源高光谱数据集，用于全球植被特征预测，通过半监督和自监督方法提升跨域预测性能，优于现有监督基线。


<details>
  <summary>详细信息</summary>
研究动机: 植物特征（如叶片碳含量和叶片质量）是研究生物多样性和气候变化的关键变量，但传统实地采样难以覆盖生态学意义的空间尺度。机器学习结合高光谱遥感数据为跨生态系统植物特征预测提供了解决方案，但面临标签稀缺和跨域差异的挑战。

研究方法: 提出了GreenHyperSpectra数据集，包含跨传感器和跨生态系统的真实样本，用于评估半监督和自监督方法。采用包含分布内和分布外场景的评估框架，预训练标签高效的多输出回归模型。

研究结果: 预训练的模型在植物特征预测中显著优于现有监督基线，提升了光谱表征学习能力，为植物功能特征评估提供了全面的方法论框架。

研究结论: GreenHyperSpectra数据集和方法框架为植物特征预测研究提供了新工具，推动了表征学习与植物功能特征评估的交叉研究。

中文摘要: 植物特征（如叶片碳含量和叶片质量）是研究生物多样性和气候变化的关键变量。然而，传统的实地采样难以覆盖生态学意义的空间尺度。机器学习结合高光谱遥感数据为跨生态系统植物特征预测提供了解决方案，但面临标签稀缺和跨域差异（如传感器和生态分布）的挑战。为此，我们提出了GreenHyperSpectra，一个包含跨传感器和跨生态系统真实样本的预训练数据集，用于评估半监督和自监督方法的植物特征预测性能。我们采用包含分布内和分布外场景的评估框架，成功预训练了标签高效的多输出回归模型，其性能优于现有监督基线。实证分析表明，该方法显著提升了光谱表征学习能力，为植物功能特征评估建立了一个全面的方法论框架，推动了表征学习与植物功能特征评估的交叉研究。所有代码和数据可在以下网址获取：https://github.com/echerif18/HyspectraSSL。

</details>


### [99] [Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs](https://arxiv.org/abs/2507.06999)
**中文标题：学习深思熟虑，行动直觉化：解锁多模态大语言模型的测试时推理能力**

*Yahan Yu,Yuyang Dong,Masafumi Oyamada*

主要分类: cs.CV

摘要简述: 本文提出了一种名为D2I的框架，通过训练时的规则奖励提升多模态大语言模型的理解与推理能力，无需额外标注或复杂奖励，并在测试时转为直觉推理风格，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态推理研究在模态对齐和训练成本方面仍存在挑战，许多方法依赖额外数据标注和规则奖励，增加了成本且限制了扩展性。本文旨在解决这些问题。

研究方法: 提出Deliberate-to-Intuitive（D2I）框架，训练时通过规则奖励设置深思熟虑的推理策略以增强模态对齐，测试时转为直觉推理风格，隐式体现模型能力。

研究结果: D2I在领域内和领域外基准测试中均优于基线模型，证明了规则奖励对提升多模态大语言模型可迁移推理能力的作用。

研究结论: D2I框架展示了规则奖励在训练时推理深度与测试时响应灵活性解耦中的潜力，为多模态推理研究提供了新方向。

中文摘要: 推理是大型语言模型（LLMs）的关键能力，尤其是在处理复杂任务（如数学问题求解）时。然而，多模态推理研究仍需进一步探索模态对齐和训练成本。许多方法依赖额外数据标注和相关规则奖励来增强理解和推理能力，这显著增加了训练成本并限制了扩展性。为解决这些问题，我们提出了Deliberate-to-Intuitive推理框架（D2I），无需额外标注和复杂奖励即可提升多模态大语言模型（MLLMs）的理解和推理能力。具体而言，我们的方法在训练时通过规则奖励设置深思熟虑的推理策略以增强模态对齐，而在评估时转为直觉推理风格，移除训练时的深思熟虑策略，隐式体现模型在响应中习得的能力。D2I在领域内和领域外基准测试中均优于基线模型。我们的发现凸显了规则奖励在培养MLLMs可迁移推理技能中的作用，并为解耦训练时推理深度与测试时响应灵活性提供了方向。

</details>


### [100] [Democratizing High-Fidelity Co-Speech Gesture Video Generation](https://arxiv.org/abs/2507.06812)
**中文标题：民主化的高保真语音手势视频生成**

*Xu Yang,Shaoli Huang,Shenbo Xie,Xuelin Chen,Yifei Liu,Changxing Ding*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级框架，利用2D全身骨架作为辅助条件，通过扩散模型生成与音频严格同步的高保真手势视频，并发布了首个公开数据集CSG-405。


<details>
  <summary>详细信息</summary>
研究动机: 当前语音手势视频生成任务面临音频与视觉内容一对多映射的挑战，且缺乏大规模公开数据集和计算资源。本文旨在解决这些问题，推动研究民主化。

研究方法: 采用2D骨架作为辅助条件，结合细粒度音频片段和参考图像提取的骨架，通过骨架-音频特征融合预测骨骼运动，再使用现有人体视频生成模型合成高保真视频。

研究结果: 实验表明，该方法在视觉质量和同步性上优于现有技术，并能泛化到不同说话者和场景。

研究结论: 本文提出的框架和数据集为语音手势视频生成任务提供了高效且可扩展的解决方案，推动了该领域的研究进展。

中文摘要: 语音手势视频生成旨在合成与音频同步的逼真说话者视频，包括面部表情和身体手势。由于音频与视觉内容之间存在显著的一对多映射关系，且缺乏大规模公开数据集和高计算需求，该任务具有挑战性。我们提出了一种轻量级框架，利用2D全身骨架作为高效辅助条件，将音频信号与视觉输出连接起来。该方法通过细粒度音频片段和从说话者参考图像提取的骨架条件化扩散模型，预测骨骼运动以确保严格的音频协调和身体形状一致性。生成的骨架随后输入现有人体视频生成模型，结合说话者参考图像合成高保真视频。为了推动研究民主化，我们发布了首个公开数据集CSG-405，包含405小时的高分辨率视频，涵盖71种语音类型，并标注了2D骨架和多样化的说话者人口统计信息。实验表明，我们的方法在视觉质量和同步性上优于现有技术，并能泛化到不同说话者和场景。

</details>


### [101] [HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement](https://arxiv.org/abs/2507.06814)
**中文标题：HVI-CIDNet+：超越极端暗光的低光图像增强**

*Qingsen Yan,Kangbiao Shi,Yixu Feng,Tao Hu,Peng Wu,Guansong Pang,Yanning Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种新的颜色空间HVI和基于此的HVI-CIDNet+网络，用于解决低光图像增强中的颜色偏差和亮度伪影问题，并在极端暗光条件下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于sRGB颜色空间的低光图像增强方法易产生颜色偏差和亮度伪影，而HSV颜色空间虽能解耦亮度和颜色，却引入了严重的红色和黑色噪声伪影。因此，需要一种新的颜色空间和方法来解决这些问题。

研究方法: 提出HVI颜色空间，通过HV颜色图和可学习强度消除红色和黑色噪声伪影；设计HVI-CIDNet+网络，利用预训练视觉语言模型提取上下文和退化知识，通过Prior-guided Attention Block（PAB）融合语义先验和退化表示，实现内容恢复和颜色校正；引入Region Refinement Block，结合卷积和自注意力机制优化亮度调整。

研究结果: 在10个基准数据集上的实验表明，HVI-CIDNet+优于现有最先进方法，尤其在极端暗光条件下表现突出。

研究结论: HVI颜色空间和HVI-CIDNet+网络有效解决了低光图像增强中的颜色偏差和噪声伪影问题，显著提升了图像质量。

中文摘要: 低光图像增强（LLIE）旨在从受损的低光图像中恢复生动的内容和细节。然而，现有的基于标准RGB（sRGB）颜色空间的LLIE方法由于固有的高颜色敏感性，常产生颜色偏差和亮度伪影。而色调、饱和度和明度（HSV）颜色空间虽能解耦亮度和颜色，却引入了显著的红色和黑色噪声伪影。为解决这一问题，我们提出了一种新的LLIE颜色空间，即水平/垂直-强度（HVI），由HV颜色图和可学习强度定义。HV颜色图通过减小红色坐标的距离消除红色噪声伪影，而可学习强度通过压缩低光区域消除黑色噪声伪影。此外，我们引入了基于HVI颜色空间的颜色和强度解耦网络+（HVI-CIDNet+），用于恢复受损内容并减轻极端暗光区域的颜色失真。具体而言，HVI-CIDNet+利用预训练视觉语言模型提取的丰富上下文和退化知识，通过新颖的Prior-guided Attention Block（PAB）进行融合。在PAB中，潜在语义先验可促进内容恢复，而退化表示则指导精确的颜色校正，两者通过精心设计的交叉注意力融合机制在极端暗光区域发挥作用。此外，我们构建了一个区域细化块，对信息丰富区域使用卷积，对信息稀缺区域使用自注意力，确保亮度调整的准确性。基准实验的综合结果表明，所提出的HVI-CIDNet+在10个数据集上优于现有最先进方法。

</details>


### [102] [Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation](https://arxiv.org/abs/2507.06830)
**中文标题：基于物理的运动预测：通过方程发现实现轨迹引导的图像到视频生成**

*Tao Feng,Xianbing Zhao,Zhenhua Chen,Tien Tsin Wong,Hamid Rezatofighi,Gholamreza Haffari,Lizhen Qu*

主要分类: cs.CV

摘要简述: 本文提出了一种结合符号回归和轨迹引导的图像到视频生成框架，通过发现运动方程来预测物理准确的未来轨迹，从而提升视频生成的物理对齐性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散和自回归的视频生成模型虽然视觉真实感强，但缺乏物理准确性，无法复现真实世界的物体运动动态。这主要是因为它们依赖统计相关性而非物理规律。本文旨在解决这一问题。

研究方法: 方法包括从输入视频中提取运动轨迹，通过检索式预训练增强符号回归，发现运动方程以预测物理准确的未来轨迹，并用这些轨迹引导视频生成，无需微调现有模型。

研究结果: 在经典力学场景（如弹簧-质量系统、摆锤和抛体运动）中，该方法成功恢复了真实解析方程，并显著提升了生成视频的物理对齐性，优于基线方法。

研究结论: 本文提出的框架通过结合符号回归和轨迹引导，有效提升了视频生成的物理准确性，为物理基础的运动预测提供了新思路。

中文摘要: 近年来，基于扩散和自回归的视频生成模型在视觉真实感方面取得了显著进展。然而，这些模型通常缺乏准确的物理对齐性，无法复现真实世界中物体运动的动态。这一局限性主要源于它们依赖学习的统计相关性，而非捕捉符合物理规律的机制。为解决这一问题，我们提出了一种新颖的框架，将符号回归（SR）与轨迹引导的图像到视频（I2V）模型相结合，用于基于物理的视频预测。我们的方法从输入视频中提取运动轨迹，通过检索式预训练机制增强符号回归，并发现运动方程以预测物理准确的未来轨迹。这些轨迹随后用于引导视频生成，而无需对现有模型进行微调。在经典力学场景（如弹簧-质量系统、摆锤和抛体运动）中的评估表明，我们的方法成功恢复了真实解析方程，并显著提升了生成视频的物理对齐性，优于基线方法。

</details>


### [103] [Know Your Attention Maps: Class-specific Token Masking for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2507.06848)
**中文标题：了解你的注意力图：面向弱监督语义分割的类别特定令牌掩码**

*Joelle Hanna,Damian Borth*

主要分类: cs.CV

摘要简述: 本文提出一种基于Vision Transformer（ViT）的弱监督语义分割方法，通过多[CLS]令牌和随机掩码策略生成伪分割掩码，显著减少对精细标注数据的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 弱监督语义分割（WSSS）传统方法依赖外部模块（如类激活图）生成伪分割掩码，但效果有限。本文旨在直接利用ViT的自注意力图实现更准确的伪掩码生成，提升模型可解释性和性能。

研究方法: 提出一种端到端方法，训练稀疏ViT模型，每个类别分配一个[CLS]令牌，并采用随机掩码策略促进令牌与类别关联。推理时，聚合各[CLS]令牌的自注意力图生成伪分割掩码。

研究结果: 在两个标准基准和三个专业数据集上的实验表明，该方法生成的伪掩码优于现有方法，可用于训练分割模型，性能接近全监督模型。

研究结论: 本文方法通过ViT的自注意力图直接生成伪分割掩码，显著减少对精细标注的需求，同时提升分割性能，为弱监督语义分割提供了新思路。

中文摘要: 弱监督语义分割（WSSS）是一个近年来被广泛研究的挑战性问题。传统方法通常依赖类激活图等外部模块来突出感兴趣区域并生成伪分割掩码。本文提出一种端到端方法，直接利用Vision Transformer（ViT）学习到的注意力图进行WSSS。我们提出训练一个稀疏ViT模型，每个类别分配一个[CLS]令牌，并通过随机掩码策略促进[CLS]令牌与类别的关联。推理时，聚合各[CLS]令牌的自注意力图以生成伪分割掩码。该方法增强了自注意力图的可解释性并确保准确的类别分配。在两个标准基准和三个专业数据集上的大量实验表明，我们的方法生成的伪掩码优于相关研究。这些伪掩码可用于训练分割模型，其性能接近全监督模型，显著减少了对精细标注数据的需求。

</details>


### [104] [IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization](https://arxiv.org/abs/2507.06856)
**中文标题：IAP：基于感知感知定位和扰动优化的不可见对抗补丁攻击**

*Subrat Kishore Dutta,Xiao Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为IAP的新型对抗补丁攻击框架，通过感知感知定位和扰动优化方案生成高度不可见的对抗补丁，显著提升了攻击成功率和隐蔽性。


<details>
  <summary>详细信息</summary>
研究动机: 现有对抗补丁方法在针对性攻击场景中表现不佳，或生成的补丁与上下文不协调，容易被人类或自动防御系统察觉。IAP旨在解决这些问题，生成既高效又隐蔽的对抗补丁。

研究方法: IAP首先通过类感知定位和敏感度图选择补丁位置，平衡模型预测和人类视觉系统的敏感性；然后采用感知正则化对抗损失和优先颜色一致性的梯度更新规则优化扰动。

研究结果: 在多种图像基准和模型架构上的实验表明，IAP在针对性攻击中具有竞争力的成功率，且补丁隐蔽性显著优于现有基线方法，同时能有效规避多种先进补丁防御。

研究结论: IAP通过感知感知定位和扰动优化，成功生成了高效且隐蔽的对抗补丁，为对抗攻击领域提供了新的解决方案。

中文摘要: 尽管仅修改了输入图像的局部区域，对抗补丁仍能显著改变计算机视觉模型的预测结果。然而，现有方法在针对性攻击场景中表现不佳，或生成的补丁与上下文不协调，容易被人类或自动防御系统察觉。本文提出IAP，一种基于感知感知定位和扰动优化方案的新型攻击框架，用于生成高度不可见的对抗补丁。具体而言，IAP首先通过类感知定位和敏感度图选择补丁位置，平衡模型预测和人类视觉系统的敏感性；然后采用感知正则化对抗损失和优先颜色一致性的梯度更新规则优化扰动。在多种图像基准和模型架构上的实验表明，IAP在针对性攻击中具有竞争力的成功率，且补丁隐蔽性显著优于现有基线方法。此外，IAP不仅对人类高度不可察觉，还能有效规避多种先进补丁防御。

</details>


### [105] [Longitudinal Study of Facial Biometrics at the BEZ: Temporal Variance Analysis](https://arxiv.org/abs/2507.06858)
**中文标题：BEZ中心面部生物特征的纵向研究：时间方差分析**

*Mathias Schulz,Alexander Spenke,Pia Funk,Florian Blümel,Markus Rohde,Ralph Breithaupt,Gerd Nolden,Norbert Jung,Robert Lange*

主要分类: cs.CV

摘要简述: 本研究通过长期生物特征评估，发现面部识别分数在个体间日波动显著，强调长期受控测试的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 探讨长期生物特征数据的变化趋势，为生物识别技术的改进提供依据。

研究方法: 在BEZ中心对400多名参与者进行两年半的定期评估，使用先进面部识别算法分析数据。

研究结果: 面部识别分数在个体间日波动显著，长期变化相对稳定。

研究结论: 长期受控测试对生物特征分析至关重要，为未来技术发展奠定基础。

中文摘要: 本研究展示了在生物特征评估中心（BEZ）进行的长期生物特征评估结果。在两年半的时间内，我们对400多名代表不同种族、性别和年龄组的参与者进行了定期评估，使用了多种生物特征工具和技术。研究基于符合《通用数据保护条例》的本地BEZ数据库，包含超过23.8万组分类为面部和指纹等生物特征模态的数据集。我们使用先进的面部识别算法分析长期比较分数。结果显示，这些分数在个体间的日波动比整个测量期间的变化更为显著。这些发现强调了在受控测量环境中长期测试同一人生物特征的重要性，并为未来生物特征数据分析的进步奠定了基础。

</details>


### [106] [SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds](https://arxiv.org/abs/2507.06906)
**中文标题：SemRaFiner：稀疏和噪声雷达点云中的全景分割**

*Matthias Zeller,Daniel Casado Herraez,Bengisu Ayan,Jens Behley,Michael Heidingsfeld,Cyrill Stachniss*

主要分类: cs.CV

摘要简述: SemRaFiner是一种用于稀疏和噪声雷达点云的全景分割方法，通过优化特征提取和训练流程，提升了场景理解的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶需要准确的语义场景理解，但相机和LiDAR在恶劣天气下表现不佳，且缺乏运动信息。雷达传感器能克服这些限制，但其点云稀疏且噪声大，因此需要一种方法来提升雷达点云的全景分割效果。

研究方法: SemRaFiner通过优化稀疏雷达点云的特征提取，并引入专门的数据增强技术来改进实例分配的训练流程。

研究结果: 实验表明，SemRaFiner在雷达全景分割任务中优于现有方法。

研究结论: SemRaFiner通过改进特征提取和训练流程，显著提升了稀疏雷达点云的全景分割性能，为自动驾驶的场景理解提供了有效工具。

中文摘要: 语义场景理解（包括移动物体的感知和分类）对于实现自动驾驶的安全和稳健行为至关重要。相机和LiDAR通常用于语义场景理解，但它们在恶劣天气下表现受限，且通常不提供运动信息。雷达传感器克服了这些限制，并通过测量多普勒速度直接提供移动物体的信息，但其测量结果相对稀疏且噪声较大。本文解决了稀疏雷达点云中的全景分割问题，以增强场景理解。我们的方法SemRaFiner考虑了稀疏雷达点云中密度的变化，并优化了特征提取以提高准确性。此外，我们提出了一种优化的训练流程，通过引入专门的数据增强技术来细化实例分配。实验表明，我们的方法在基于雷达的全景分割任务中优于现有技术。

</details>


### [107] [Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement](https://arxiv.org/abs/2507.06928)
**中文标题：自适应部分学习用于细粒度广义类别发现：一种即插即用的增强方法**

*Qiyuan Dai,Hanzhuo Huang,Yu Wu,Sibei Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种自适应部分学习方法（APL），通过共享可学习部分查询和DINO部分先验，生成一致的对象部分及其对应关系，无需额外标注，显著提升了细粒度广义类别发现（GCD）的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有GCD方法依赖DINO等自监督视觉变换器的全局表示，导致判别性与泛化性之间的权衡问题。本文旨在通过自适应部分学习解决这一问题，提升细粒度数据集的性能。

研究方法: 提出APL方法，利用共享可学习部分查询和DINO部分先验生成一致的对象部分，并设计了一种新颖的“全最小对比损失”来学习判别性强且泛化性好的部分表示。

研究结果: APL方法在细粒度数据集上显著提升了GCD性能，且无需额外标注，可轻松集成到不同GCD框架中。

研究结论: APL通过自适应部分学习有效解决了GCD中判别性与泛化性的权衡问题，为细粒度数据集提供了显著的性能提升。

中文摘要: 广义类别发现（GCD）旨在通过区分已知类别和新类别来识别未标记图像，同时从另一组已知类别的标记图像中迁移知识。现有GCD方法依赖DINO等自监督视觉变换器进行表示学习，但仅关注DINO CLS令牌的全局表示会引入判别性与泛化性之间的固有权衡。本文提出了一种自适应部分发现与学习方法（APL），通过一组共享可学习部分查询和DINO部分先验，生成一致的对象部分及其对应关系，无需额外标注。更重要的是，我们提出了一种新颖的“全最小对比损失”来学习判别性强且泛化性好的部分表示，自适应地突出判别性对象部分以区分相似类别，同时共享其他部分以促进知识迁移。APL可以轻松集成到不同GCD框架中，通过替换其CLS令牌特征为部分表示，在细粒度数据集上显示出显著提升。

</details>


### [108] [MCCD: A Multi-Attribute Chinese Calligraphy Character Dataset Annotated with Script Styles, Dynasties, and Calligraphers](https://arxiv.org/abs/2507.06948)
**中文标题：MCCD：一个标注字体风格、朝代和书法家的多属性中国书法字符数据集**

*Yixin Zhao,Yuyi Zhang,Lianwen Jin*

主要分类: cs.CV

摘要简述: 本文提出了一个多属性中国书法字符数据集（MCCD），包含7,765个类别共329,715个独立图像样本，标注了字体风格、朝代和书法家信息，填补了现有书法数据集稀缺且缺乏多属性标注的空白。


<details>
  <summary>详细信息</summary>
研究动机: 研究书法属性信息（如风格、朝代和书法家）具有重要文化和历史价值，但现有数据集稀缺且缺乏多属性标注，限制了书法研究的深入发展。

研究方法: 构建了MCCD数据集，包含7,765个类别的329,715个独立图像样本，并基于字体风格（10种）、朝代（15个时期）和书法家（142人）提取了三个子集。通过单任务和多任务识别实验验证了数据集的复杂性。

研究结果: 实验结果表明，书法字符的笔画结构复杂性和多属性间的相互作用显著增加了准确识别的难度。MCCD为书法字符识别、书法家鉴定和汉字演变研究提供了宝贵资源。

研究结论: MCCD填补了详细书法数据集的空白，为推进中国书法研究和多领域发展提供了重要资源。

中文摘要: 研究书法的属性信息（如风格、朝代和书法家）具有重要的文化和历史价值。然而，中国书法字符的风格在不同朝代和书法家的独特笔触下发生了巨大变化，准确识别这些字符及其属性极具挑战性。此外，现有的书法数据集极为稀缺，且大多仅提供字符级标注而无额外属性信息，这严重阻碍了中国书法的深入研究。为填补这一空白，我们提出了一个新颖的多属性中国书法字符数据集（MCCD）。该数据集包含7,765个类别共329,715个独立图像样本，并基于字体风格（10种）、朝代（15个时期）和书法家（142人）的标注提取了三个子集。丰富的多属性标注使MCCD适用于多样化的研究任务，包括书法字符识别、书法家鉴定和汉字演变研究。我们通过单任务和多任务识别实验在MCCD及其所有子集上建立了基准性能。实验结果表明，书法字符的笔画结构复杂性及其多属性间的相互作用显著增加了准确识别的难度。MCCD不仅填补了详细书法数据集的空白，还为推进中国书法研究和促进多领域发展提供了宝贵资源。数据集可在https://github.com/SCUT-DLVCLab/MCCD获取。

</details>


### [109] [Pre-Columbian Settlements Shaped Palm Clusters in the Sierra Nevada de Santa Marta, Colombia](https://arxiv.org/abs/2507.06949)
**中文标题：哥伦比亚圣玛尔塔内华达山脉的前哥伦布时期定居点塑造了棕榈树集群**

*Sebastian Fajardo,Sina Mohammadi,Jonas Gregorio de Souza,César Ardila,Alan Tapscott Baltar,Shaddai Heidgen,Maria Isabel Mayorga Hernández,Sylvia Mota de Oliveira,Fernando Montejo,Marco Moderato,Vinicius Peripato,Katy Puche,Carlos Reina,Juan Carlos Vargas,Frank W. Takes,Marco Madella*

主要分类: cs.CV

摘要简述: 本文通过深度学习模型和聚类算法，结合高分辨率卫星图像，研究了哥伦比亚圣玛尔塔内华达山脉的棕榈树分布与史前人类活动的关系，发现棕榈树在考古遗址附近显著更多，表明史前人类对植被的长期影响。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在揭示史前人类对热带森林的长期管理影响，特别是在高分辨率尺度上，探索植被特征与考古遗址的关系。

研究方法: 使用深度学习模型从卫星图像中识别棕榈树，再通过聚类算法识别棕榈树集群，并结合地面调查和遗留记录估计古代人类管理区域。

研究结果: 结果显示，棕榈树在大型基础设施考古遗址附近显著更多，最大棕榈集群的范围表明古代人类管理区域可能比考古证据显示的大两个数量级。

研究结论: 史前人类通过促进棕榈树生长影响了当地植被，留下了持久的生态足迹，这可能降低了在难以到达地区建立基础设施密集型定居点的成本。

中文摘要: 古代人口显著改变了新热带森林，但理解古代人类管理的长期影响，尤其是在高分辨率尺度上，仍然具有挑战性。本研究提出了一种基于植被特征的考古影响区域调查新方法。该方法包括一个基于卫星图像的深度学习模型，用于识别棕榈树，随后通过聚类算法识别棕榈集群，进而估计古代管理区域。为了评估棕榈分布与过去人类活动的关系，我们将该方法应用于覆盖哥伦比亚圣玛尔塔内华达山脉765平方公里的独特高分辨率卫星图像数据。通过这项工作，我们还发布了一个手动标注的棕榈树数据集，以及基于地面调查和遗留记录的考古遗址估计位置。结果表明，棕榈树在大型基础设施投资的考古遗址附近显著更多。最大棕榈集群的范围表明，与主要基础设施遗址相关的古代人类管理区域可能比考古证据单独显示的规模大两个数量级。我们的发现表明，前哥伦布时期的人口通过促进棕榈树生长的条件影响了当地植被，留下了持久的生态足迹。这可能降低了在难以到达地区建立基础设施密集型定居点的物流成本。总体而言，本研究展示了将人工智能方法与新的生态和考古数据相结合，通过植被模式识别考古兴趣区域的潜力，揭示了精细尺度的人与环境互动。

</details>


### [110] [CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale](https://arxiv.org/abs/2507.06959)
**中文标题：CheXPO：基于反事实推理的胸部X光视觉语言模型偏好优化**

*Xiao Liang,Jiawei Hu,Di Wang,Zhi Ma,Lin Zhao,Ronghan Li,Bo Wan,Quan Wang*

主要分类: cs.CV

摘要简述: CheXPO是一种针对胸部X光视觉语言模型的偏好优化策略，通过联合挖掘置信度与相似性并结合反事实推理，解决了医学应用中模型幻觉问题，仅需5%的监督微调样本即可实现8.93%的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 视觉语言模型在医学应用中易产生幻觉，影响可靠性。传统偏好优化方法面临临床无关样本、数据分布不平衡和专家标注成本高等问题，亟需一种高效且经济的解决方案。

研究方法: CheXPO通过合成多任务胸部X光视觉指令数据集进行监督微调，利用置信度分析识别困难样本，并通过相似性检索扩展样本以平衡分布，同时引入合成反事实推理提供细粒度临床偏好，无需额外专家输入。

研究结果: 实验表明，CheXPO仅使用5%的监督微调样本即实现8.93%的相对性能提升，在多种临床任务中达到最先进水平，为实际放射学应用提供了可扩展且可解释的解决方案。

研究结论: CheXPO通过结合置信度-相似性联合挖掘与反事实推理，有效解决了医学视觉语言模型的幻觉问题，显著提升了性能并降低了专家标注成本。

中文摘要: 视觉语言模型（VLMs）在医学应用中易产生幻觉，严重影响可靠性。尽管偏好优化可通过临床反馈缓解这一问题，但其实施面临临床无关训练样本、数据分布不平衡及高昂专家标注成本等挑战。为解决这些问题，我们提出CheXPO，一种结合置信度-相似性联合挖掘与反事实推理的胸部X光偏好优化策略。该方法首先合成一个统一、细粒度的多任务胸部X光视觉指令数据集用于监督微调（SFT），随后通过SFT失败的令牌级置信度分析识别困难样本，并利用基于相似性的检索扩展样本以平衡偏好分布，同时合成反事实推理提供细粒度临床偏好，无需额外专家输入。实验表明，CheXPO仅使用5%的SFT样本即实现8.93%的相对性能提升，在多种临床任务中达到最先进水平，为实际放射学应用提供了可扩展且可解释的解决方案。

</details>


### [111] [Segmentation Regularized Training for Multi-Domain Deep Learning Registration applied to MR-Guided Prostate Cancer Radiotherapy](https://arxiv.org/abs/2507.06966)
**中文标题：基于分割正则化训练的多领域深度学习配准方法在MR引导前列腺癌放疗中的应用**

*Sudharsan Madhavan,Chengcheng Gui,Lando Bosma,Josiah Simeth,Jue Jiang,Nicolas Cote,Nima Hassan Rezaeian,Himanshu Nagar,Victoria Brennan,Neelam Tyagi,Harini Veeraraghavan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ProRSeg的深度学习图像配准方法，用于多领域MR-MR配准，适用于前列腺癌放疗中的轮廓传播和剂量累积。该方法在不同领域数据集上表现出良好的泛化能力，并初步验证了其在临床约束评估中的可行性。


<details>
  <summary>详细信息</summary>
研究动机: 准确的变形图像配准（DIR）在MR引导的自适应放疗（MRgART）中对轮廓传播和剂量累积至关重要。本研究旨在开发一种深度学习的DIR方法，以实现跨领域的MR-MR配准，并验证其在临床实践中的适用性。

研究方法: 研究采用了一种逐步优化的配准和分割方法（ProRSeg），通过加权分割一致性损失训练了262对3T MR模拟扫描数据。该方法在相同领域、跨领域和混合领域数据集上进行了测试，评估了其对临床目标体积（CTV）、膀胱和直肠的轮廓传播准确性，并对42名患者的剂量累积进行了分析。

研究结果: ProRSeg在膀胱配准中表现出跨领域的泛化能力（Dice相似系数分别为0.88、0.87、0.86）。对于直肠和CTV，其性能依赖于领域，跨领域MRL数据集表现更优（DSCs 0.89）。剂量累积结果显示，83.3%的患者满足CTV覆盖和膀胱保护的临床约束，但仅9.5%的患者剂量控制在42.0 Gy以下。

研究结论: ProRSeg在多领域MR-MR配准中表现出合理的性能，并初步验证了其在评估临床约束治疗依从性中的可行性。

中文摘要: 背景：在MR引导的自适应放疗（MRgART）中，准确的变形图像配准（DIR）对轮廓传播和剂量累积至关重要。本研究训练并评估了一种深度学习的DIR方法，用于实现跨领域的MR-MR配准。方法：采用逐步优化的配准和分割方法（ProRSeg），通过加权分割一致性损失训练了262对3T MR模拟扫描数据。ProRSeg在相同领域（58对）、跨领域（72对1.5T MR Linac数据）和混合领域（42对MRSim-MRL数据）数据集上测试了临床目标体积（CTV）、膀胱和直肠的轮廓传播准确性。对42名接受5次MRgART的患者进行了剂量累积分析。结果：ProRSeg在膀胱配准中表现出跨领域的泛化能力（Dice相似系数分别为0.88、0.87、0.86）。对于直肠和CTV，其性能依赖于领域，跨领域MRL数据集表现更优（DSCs 0.89）。剂量累积结果显示，83.3%的患者满足CTV覆盖（D95 >= 40.0 Gy）和膀胱保护（D50 <= 20.0 Gy）的临床约束。所有患者均达到最低平均靶剂量（>40.4 Gy），但仅9.5%的患者剂量控制在42.0 Gy以下。结论：ProRSeg在多领域MR-MR配准中表现出合理的性能，并初步验证了其在评估临床约束治疗依从性中的可行性。

</details>


### [112] [Hallucinating 360°: Panoramic Street-View Generation via Local Scenes Diffusion and Probabilistic Prompting](https://arxiv.org/abs/2507.06971)
**中文标题：幻觉360度：基于局部场景扩散和概率提示的全景街景生成**

*Fei Teng,Kai Luo,Sheng Wu,Siyu Li,Pujun Guo,Jiale Wei,Kunyu Peng,Jiaming Zhang,Kailun Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Percep360的全景生成方法，通过局部场景扩散和概率提示实现高质量、可控的360度街景生成，解决了现有方法在数据分布固定和可控性不足的问题。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶需要全面的360度全景感知，但现有数据采集和标注过程复杂且耗时。现有街景生成模型无法实现高质量、可控的全景生成，因此需要一种新方法来解决这些问题。

研究方法: Percep360采用局部场景扩散方法（LSDM）解决信息丢失问题，并通过概率提示方法（PPM）实现可控生成。LSDM将全景生成建模为空间连续的扩散过程，PPM动态选择相关控制信号。

研究结果: 生成的图像在无参考和有参考质量评估中表现优异，可控性强，并在鸟瞰图分割任务中提升了感知模型的性能。生成数据在无参考质量指标上优于原始拼接图像。

研究结论: Percep360首次实现了高质量、可控的全景生成，为自动驾驶提供了有效的数据增强工具。其开源代码将促进进一步研究。

中文摘要: 全景感知在自动驾驶中具有重要潜力，能够通过单次拍摄获取全面的360度环绕视野。然而，自动驾驶是数据驱动的任务，完整的全景数据采集需要复杂的采样系统和标注流程，耗时且费力。尽管现有街景生成模型展现了强大的数据再生能力，但它们只能从现有数据集的固定分布中学习，无法实现高质量、可控的全景生成。本文提出了首个面向自动驾驶的全景生成方法Percep360，基于拼接全景数据实现可控信号下的连贯全景生成。Percep360聚焦于连贯性和可控性两个关键方面。具体而言，为克服针孔采样过程固有的信息丢失，我们提出了局部场景扩散方法（LSDM），将全景生成重新定义为空间连续的扩散过程，弥合不同数据分布间的差距。此外，为实现全景图像的可控生成，我们提出了概率提示方法（PPM），动态选择最相关的控制信号。我们从图像质量评估（无参考和有参考）、可控性及其在真实鸟瞰图分割任务中的实用性三个角度评估生成图像的有效性。值得注意的是，生成数据在无参考质量指标上始终优于原始拼接图像，并提升了下游感知模型的性能。源代码将在https://github.com/Bryant-Teng/Percep360公开。

</details>


### [113] [A multi-modal dataset for insect biodiversity with imagery and DNA at the trap and individual level](https://arxiv.org/abs/2507.06972)
**中文标题：昆虫生物多样性多模态数据集：结合陷阱和个体水平的图像与DNA数据**

*Johanna Orsholm,John Quinto,Hannu Autto,Gaia Banelyte,Nicolas Chazot,Jeremy deWaard,Stephanie deWaard,Arielle Farrell,Brendan Furneaux,Bess Hardwick,Nao Ito,Amlan Kar,Oula Kalttopää,Deirdre Kerdraon,Erik Kristensen,Jaclyn McKeown,Tommi Mononen,Ellen Nein,Hanna Rogers,Tomas Roslin,Paula Schmitz,Jayme Sones,Maija Sujala,Amy Thompson,Evgeny V. Zakharov,Iuliia Zarubiieva,Akshita Gupta,Scott C. Lowe,Graham W. Taylor*

主要分类: cs.CV

摘要简述: 本文介绍了MassID45数据集，结合DNA条形码和高分辨率图像，用于训练自动分类器处理批量昆虫样本，推动昆虫生物多样性研究。


<details>
  <summary>详细信息</summary>
研究动机: 昆虫种类繁多且数量急剧下降，亟需高效方法研究其多样性。DNA条形码和高分辨率图像虽具潜力，但现有图像方法多依赖单个标本，无法满足大规模生态调查需求。

研究方法: 提出MassID45数据集，结合分子和图像数据，覆盖未分类样本和单个标本。通过AI辅助工具，人工标注批量图像中的个体分割掩膜和分类标签。

研究结果: 标注了超过17,000个标本的分割掩膜和分类标签，结合DNA条形码和图像数据，为快速大规模昆虫群落表征提供潜力。

研究结论: MassID45数据集推动了微小物体检测和实例分割的创新，为生态和机器学习研究开辟新方向。

中文摘要: 昆虫包含数百万物种，许多物种在环境和栖息地变化下数量急剧下降。高通量方法对加速理解昆虫多样性至关重要，其中DNA条形码和高分辨率图像在自动分类中展现出强大潜力。然而，大多数基于图像的方法依赖单个标本数据，与大规模生态调查中收集的未分类批量样本不同。我们提出了混合节肢动物样本分割与识别（MassID45）数据集，用于训练批量昆虫样本的自动分类器。该数据集独特地结合了分子和图像数据，涵盖未分类样本和全套单个标本。在AI辅助工具支持下，人工标注者对批量图像完成两项任务：为每个节肢动物创建分割掩膜，并为超过17,000个标本分配分类标签。将DNA条形码的分类分辨率与批量图像的精确丰度估计相结合，为快速大规模表征昆虫群落提供了巨大潜力。该数据集推动了微小物体检测和实例分割的边界，促进了生态和机器学习研究的创新。

</details>


### [114] [Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM](https://arxiv.org/abs/2507.06973)
**中文标题：自由即兴：通过在线EM增强测试时适应的灵活性**

*Qiyuan Dai,Sibei Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练、通用的测试时适应方法FreeTTA，通过在线EM算法利用视觉语言模型的零样本预测作为先验，显著提升了跨域和分布外场景下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉语言模型在开放世界图像识别中表现出色，但实际应用中因域偏移和分布变化导致性能下降。传统测试时适应方法依赖昂贵训练或不切实际的假设，亟需一种更灵活且无需训练的方法。

研究方法: FreeTTA通过在线EM算法，利用视觉语言模型的零样本预测作为先验，迭代计算在线测试样本的后验概率并更新参数，无需同时访问历史数据。

研究结果: 实验表明，FreeTTA在15个数据集的跨域和分布外场景中均取得稳定且显著的性能提升，优于现有方法。

研究结论: FreeTTA首次明确建模测试数据分布，利用测试样本间的内在关系提升预测性能，为测试时适应提供了灵活且高效的解决方案。

中文摘要: 视觉语言模型（VLMs）因其强大的泛化能力在开放世界图像识别中表现突出。然而，实际应用中，域偏移和分布变化（尤其是测试数据分布与训练数据不一致时）会削弱其有效性。为此，测试时适应（TTA）范式应运而生，它支持在测试时使用现成的在线数据，实现独立样本预测，且无需依赖测试标注。然而，传统TTA方法通常依赖昂贵的训练或优化过程，或假设能够访问或存储历史训练和测试数据，这些假设并不现实。本研究提出了一种无需训练且通用的方法FreeTTA，它不依赖任何假设，旨在提升TTA的灵活性。更重要的是，FreeTTA首次明确建模测试数据分布，利用测试样本间的内在关系提升单个样本的预测性能，而无需同时访问数据——这一方向此前未被探索。FreeTTA通过引入在线EM算法，将VLMs的零样本预测作为先验，迭代计算每个在线测试样本的后验概率并更新参数，从而实现上述优势。实验表明，在跨域和分布外场景下的15个数据集中，FreeTTA相比现有方法取得了稳定且显著的性能提升。

</details>


### [115] [DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising](https://arxiv.org/abs/2507.06976)
**中文标题：DenoiseCP-Net：通过联合LiDAR 3D目标检测与去噪实现恶劣天气下的高效集体感知**

*Sven Teufel,Dominique Mayer,Jörg Gamerdinger,Oliver Bringmann*

主要分类: cs.CV

摘要简述: DenoiseCP-Net是一种新型多任务架构，用于恶劣天气下的LiDAR集体感知，通过联合去噪和3D目标检测，减少通信开销和计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶车辆在恶劣天气下感知系统易受传感器性能下降影响，集体感知虽能缓解此问题，但相关研究不足。本文首次研究恶劣天气下的LiDAR集体感知，并提出解决方案。

研究方法: 提出DenoiseCP-Net，将体素级去噪和目标检测集成到稀疏卷积主干中，避免两阶段冗余计算，降低延迟和带宽需求。

研究结果: DenoiseCP-Net在恶劣天气下实现近乎完美的去噪精度，减少23.6%带宽需求，同时保持检测精度并降低延迟。

研究结论: DenoiseCP-Net为恶劣天气下的集体感知提供高效解决方案，显著提升系统性能。

中文摘要: 尽管自动驾驶车辆有望显著减少交通事故，但其感知系统在恶劣天气和环境遮挡下仍易受传感器性能下降的影响。集体感知通过车辆间信息共享为解决这一问题提供了可能，但迄今为止，恶劣天气下的集体感知研究仍较少。因此，我们首次研究了多种天气条件下的LiDAR集体感知，并提出了一种新型多任务架构。恶劣天气不仅会降低感知能力，还会因传输和处理噪声而增加带宽需求和延迟。通信前的去噪可有效缓解这些问题。为此，我们提出了DenoiseCP-Net，这是一种用于恶劣天气下LiDAR集体感知的新型多任务架构。DenoiseCP-Net将体素级噪声过滤和目标检测集成到统一的稀疏卷积主干中，消除了两阶段流水线的冗余计算。这一设计不仅降低了推理延迟和计算成本，还通过去除非信息噪声减少了通信开销。我们通过使用逼真的天气模拟模型扩展了著名的OPV2V数据集，模拟了雨、雪和雾。实验表明，DenoiseCP-Net在恶劣天气下实现了近乎完美的去噪精度，带宽需求减少高达23.6%，同时保持相同的检测精度并降低协作车辆的推理延迟。

</details>


### [116] [MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation](https://arxiv.org/abs/2507.06992)
**中文标题：MCA-RG：通过医学概念对齐增强大型语言模型在放射学报告生成中的表现**

*Qilong Xing,Zikai Song,Youjia Zhang,Na Feng,Junqing Yu,Wei Yang*

主要分类: cs.CV

摘要简述: 论文提出MCA-RG框架，通过医学概念对齐增强大型语言模型在放射学报告生成中的表现，利用病理和解剖知识库优化视觉特征，提升报告准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在放射学报告生成中面临病理和解剖特征与文本描述映射不准确的问题，且特征提取缺乏语义关联，导致诊断报告生成效果不佳。

研究方法: MCA-RG框架通过两个医学概念库（病理库和解剖库）对齐视觉特征，采用解剖对比学习和匹配损失优化特征，并引入特征门控机制过滤低质量特征，最终指导报告生成。

研究结果: 在MIMIC-CXR和CheXpert Plus两个公开基准测试中，MCA-RG表现优异，验证了其在放射学报告生成中的有效性。

研究结论: MCA-RG通过医学概念对齐显著提升了放射学报告生成的准确性和临床相关性，为未来研究提供了新方向。

中文摘要: 尽管大型语言模型（LLMs）在放射学报告生成（RRG）中取得了显著进展，但由于病理和解剖特征与其对应文本描述的映射困难，临床采用仍具挑战性。此外，语义无关的特征提取进一步阻碍了准确诊断报告的生成。为解决这些问题，我们提出了医学概念对齐的放射学报告生成（MCA-RG），这是一个知识驱动的框架，通过明确对齐视觉特征与特定医学概念来优化报告生成过程。MCA-RG利用两个精选的概念库：包含病变相关知识的病理库和解剖描述库。视觉特征与这些医学概念对齐并经过定制化增强。我们进一步提出基于解剖的对比学习程序以提升解剖特征的泛化能力，并结合匹配损失优先考虑临床相关区域的病理特征。此外，采用特征门控机制过滤低质量概念特征。最终，视觉特征与个体医学概念对应，并用于指导报告生成过程。在两个公开基准（MIMIC-CXR和CheXpert Plus）上的实验表明，MCA-RG表现优异，凸显了其在放射学报告生成中的有效性。

</details>


### [117] [Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients](https://arxiv.org/abs/2507.06994)
**中文标题：跨模态掩码学习用于ICI治疗NSCLC患者的生存预测**

*Qilong Xing,Zikai Song,Bingxin Gong,Lian Yang,Junqing Yu,Wei Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种跨模态掩码学习方法，用于预测接受免疫检查点抑制剂（ICI）治疗的非小细胞肺癌（NSCLC）患者的生存期。通过结合3D CT图像和临床数据，并采用掩码学习策略，该方法在多模态特征融合中表现出色，显著提高了生存预测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 非小细胞肺癌（NSCLC）患者在接受免疫治疗时的预后预测对个性化治疗至关重要，但现有方法面临数据不足和多模态特征融合效果不佳的挑战。本文旨在通过大规模数据集和创新的多模态融合框架解决这些问题。

研究方法: 本文提出了一种跨模态掩码学习方法，包括两个分支：Slice-Depth Transformer用于提取3D CT图像特征，图基Transformer用于学习临床数据的节点特征和关系。通过掩码学习策略，模型利用完整模态重建缺失部分，从而优化多模态特征融合。

研究结果: 实验结果表明，该方法在多模态融合和生存预测任务中表现优异，超越了现有方法，为NSCLC预后模型设立了新基准。

研究结论: 本文提出的跨模态掩码学习方法显著提升了NSCLC患者生存预测的准确性，为多模态医学数据分析提供了有效工具。

中文摘要: 准确预测接受免疫治疗的非小细胞肺癌（NSCLC）患者的预后对个性化治疗计划、患者决策以及改善治疗效果和生活质量至关重要。然而，缺乏大规模相关数据集和有效的多模态特征融合策略是当前的主要挑战。为解决这些问题，我们提出了一个大规模数据集，并引入了一种新颖的多模态特征融合框架，以提高生存预测的准确性。该数据集包含接受免疫检查点抑制剂（ICI）治疗的NSCLC患者的3D CT图像、临床记录以及无进展生存期（PFS）和总生存期（OS）数据。我们进一步提出了一种跨模态掩码学习方法用于医学特征融合，包括两个分支：Slice-Depth Transformer用于从CT图像中提取3D特征，图基Transformer用于学习临床表格数据中的节点特征和关系。融合过程通过掩码模态学习策略引导，模型利用完整模态重建缺失部分，从而优化模态特定特征的整合，促进更有效的跨模态关系和特征交互。我们的方法在多模态融合和NSCLC生存预测任务中表现出色，超越了现有方法，为该领域的预后模型设立了新标准。

</details>


### [118] [GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning](https://arxiv.org/abs/2507.07006)
**中文标题：GNN-ViTCap：基于图神经网络和视觉Transformer的多实例学习框架用于全切片图像分类与描述生成**

*S M Taslim Uddin Raju,Md. Milon Islam,Md Rezwanul Haque,Hamdi Altaheri,Fakhri Karray*

主要分类: cs.CV

摘要简述: 本文提出了一种名为GNN-ViTCap的新框架，用于病理显微图像的分类和描述生成。通过动态聚类和注意力机制去除冗余图像块，结合图神经网络和语言模型，显著提升了分类和描述的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 病理显微图像的准确评估对癌症诊断至关重要，但现有方法面临冗余图像块和未知位置的问题，且自动生成病理描述仍具挑战性。本文旨在解决这些问题，提供更可靠的诊断工具。

研究方法: 首先提取图像块嵌入，通过深度嵌入聚类和注意力机制去除冗余块；构建相似性矩阵图，应用图神经网络捕捉局部和全局上下文；最后将图像嵌入投影到语言模型输入空间，结合描述标记微调大型语言模型。

研究结果: 在BreakHis和PatchGastric数据集上，GNN-ViTCap的分类F1分数为0.934，AUC为0.963；描述的BLEU-4分数为0.811，METEOR分数为0.569，优于现有方法。

研究结论: GNN-ViTCap为病理显微图像分类和描述提供了一种高效可靠的解决方案，显著提升了性能，具有临床应用潜力。

中文摘要: 病理显微图像的微观评估对癌症的准确诊断和治疗至关重要。全切片图像（WSI）的分类和描述已成为计算机辅助病理学中的关键任务。然而，显微WSI面临冗余图像块和主观捕获导致的未知位置等挑战，且自动生成病理描述仍具难度。为解决这些问题，我们提出了一种新颖的GNN-ViTCap框架，用于病理显微图像的分类和描述生成。首先，视觉特征提取器生成图像块嵌入；随后通过深度嵌入聚类动态去除冗余块，并利用标量点积注意力机制选择代表性块。通过连接相似性矩阵中的最近邻节点构建图，并应用图神经网络捕捉局部和全局上下文。聚合后的图像嵌入通过线性层投影到语言模型的输入空间，与描述标记结合以微调大型语言模型。我们在BreakHis和PatchGastric数据集上验证了该方法。GNN-ViTCap的分类F1分数为0.934，AUC为0.963；描述的BLEU-4分数为0.811，METEOR分数为0.569。实验结果表明，GNN-ViTCap优于现有方法，为基于显微图像的病人诊断提供了可靠高效的解决方案。

</details>


### [119] [Integrating Pathology Foundation Models and Spatial Transcriptomics for Cellular Decomposition from Histology Images](https://arxiv.org/abs/2507.07013)
**中文标题：整合病理学基础模型与空间转录组学用于组织学图像的细胞分解**

*Yutong Sun,Sichen Zhu,Peng Qiu*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级且训练高效的方法，利用预训练的病理学基础模型的特征嵌入，直接从H&E染色组织学图像预测细胞组成，避免了昂贵的空间转录组学实验。


<details>
  <summary>详细信息</summary>
研究动机: 数字病理学和深度学习的快速发展催生了病理学基础模型，这些模型有望解决多种疾病条件下的通用病理问题。同时，空间转录组学技术的出现为从H&E染色图像中分析基因表达提供了新机会。本文旨在利用病理学基础模型的特征嵌入，直接从组织学图像预测细胞组成，避免高昂的空间转录组学成本。

研究方法: 通过从预训练的病理学基础模型中提取信息丰富的特征嵌入，训练一个轻量级多层感知机（MLP）回归器，预测基于cell2location生成的细胞类型丰度。该方法高效地从病理学基础模型中提取知识，无需实际进行空间转录组学实验。

研究结果: 该方法在预测细胞组成方面表现出与现有方法（如Hist2Cell）相当的竞争力，同时显著降低了计算复杂度。

研究结论: 本文提出的方法能够高效且准确地从H&E染色组织学图像预测细胞组成，为病理学研究提供了一种低成本、高效益的替代方案。

中文摘要: 数字病理学和现代深度学习的快速发展促进了病理学基础模型的兴起，这些模型有望在无需微调或少量微调的情况下解决多种疾病条件下的通用病理问题。与此同时，空间转录组学作为一种变革性技术，能够在H&E染色的组织学图像上分析基因表达。空间转录组学为从现有组织学图像中更精细地分析细胞水平提供了前所未有的机会。本文提出了一种轻量级且训练高效的方法，通过利用从预训练的病理学基础模型中提取的信息丰富特征嵌入，直接从H&E染色的组织学图像预测细胞组成。通过训练一个轻量级多层感知机（MLP）回归器，基于cell2location生成的细胞类型丰度，我们的方法高效地从病理学基础模型中提取知识，并展示了无需实际进行昂贵的空间转录组学实验即可准确预测细胞组成的能力。与现有方法（如Hist2Cell）相比，我们的方法表现出竞争力，同时显著降低了计算复杂度。

</details>


### [120] [MST-Distill: Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation](https://arxiv.org/abs/2507.07015)
**中文标题：MST-Distill：基于混合专业化教师的跨模态知识蒸馏**

*Hui Li,Pengfei Yang,Juanyang Chen,Le Dong,Yanxin Chen,Quan Wang*

主要分类: cs.CV

摘要简述: 本文提出MST-Distill，一种新颖的跨模态知识蒸馏框架，通过混合专业化教师模型解决传统方法在路径选择和知识漂移上的问题，显著提升了跨模态任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统知识蒸馏方法在跨模态场景中因数据和统计异质性难以利用跨模态教师模型的互补先验知识，存在路径选择和知识漂移两大问题。

研究方法: MST-Distill采用跨模态和多模态配置的多样化教师模型集合，结合实例级路由网络实现动态自适应蒸馏，并引入掩码模块抑制模态差异以增强知识传递。

研究结果: 在五个多模态数据集上的实验表明，MST-Distill显著优于现有最先进的跨模态知识蒸馏方法。

研究结论: MST-Distill通过混合专业化教师模型和动态路由机制，有效解决了跨模态知识蒸馏中的关键问题，提升了性能。

中文摘要: 知识蒸馏作为一种高效的知识迁移技术，在单模态场景中取得了显著成功。然而，在跨模态场景中，传统蒸馏方法由于数据和统计异质性面临重大挑战，难以利用跨模态教师模型中嵌入的互补先验知识。本文通过实证揭示了现有方法中的两个关键问题：蒸馏路径选择和知识漂移。为解决这些限制，我们提出了MST-Distill，一种新颖的跨模态知识蒸馏框架，其特点是混合了专业化教师模型。我们的方法采用了跨模态和多模态配置的多样化教师模型集合，并结合实例级路由网络实现自适应动态蒸馏。这一架构有效超越了依赖单调静态教师模型的传统方法。此外，我们引入了一个可插拔的掩码模块，独立训练以抑制模态特定差异并重构教师表示，从而减轻知识漂移并提升迁移效果。在涵盖视觉、音频和文本的五个多样化多模态数据集上的大量实验表明，我们的方法在跨模态蒸馏任务中显著优于现有最先进的知识蒸馏方法。源代码可在https://github.com/Gray-OREO/MST-Distill获取。

</details>


### [121] [Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices](https://arxiv.org/abs/2507.07029)
**中文标题：基于OCR的发票表格提取流水线的设计与实现**

*Parshva Dhilankumar Patel*

主要分类: cs.CV

摘要简述: 本文设计并实现了一个基于OCR的发票表格提取流水线，结合Tesseract OCR和自定义后处理逻辑，显著提升了数据提取的准确性和一致性。


<details>
  <summary>详细信息</summary>
研究动机: 发票中的表格数据提取在自动化财务流程和数字归档中至关重要，但现有方法对非标准和噪声较多的发票格式处理效果不佳。

研究方法: 采用动态预处理、表格边界检测和行列映射技术，结合Tesseract OCR进行文本识别，并通过自定义后处理逻辑优化数据提取。

研究结果: 该流水线显著提高了从发票中提取表格数据的准确性和一致性，适用于实际应用场景。

研究结论: 提出的OCR流水线有效解决了非标准发票格式的数据提取问题，为自动化财务流程提供了可靠支持。

中文摘要: 本文介绍了一种基于OCR的高效发票表格提取流水线的设计与开发。该系统利用Tesseract OCR进行文本识别，并通过自定义后处理逻辑检测、对齐和提取扫描发票文档中的结构化表格数据。我们的方法包括动态预处理、表格边界检测和行列映射，针对噪声较多和非标准发票格式进行了优化。该流水线显著提高了数据提取的准确性和一致性，支持自动化财务流程和数字归档等实际应用场景。

</details>


### [122] [Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata](https://arxiv.org/abs/2507.07048)
**中文标题：评估大型多模态模型在营养分析中的应用：基于上下文元数据的基准测试**

*Bruce Coburn,Jiangpeng He,Megan E. Rollo,Satvinder S. Dhaliwal,Deborah A. Kerr,Fengqing Zhu*

主要分类: cs.CV

摘要简述: 本文研究了大型多模态模型（LMMs）在营养分析中的应用，重点探讨了上下文元数据（如地理位置、时间戳和食物种类）对提升营养值预测准确性的作用，并提出了新的公开数据集ACETADA。实验表明，结合元数据能显著降低预测误差。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要评估专有模型（如GPT-4），而忽略了其他大型语言模型（LLMs）的潜力。此外，上下文元数据及其与推理修饰符的交互作用尚未充分研究。本文旨在填补这一空白，探索元数据如何提升LMMs在营养分析中的表现。

研究方法: 研究通过整合GPS坐标（转换为地点/场所类型）、时间戳（转换为餐次/日类型）和食物种类等元数据，评估其对LMMs预测营养值（如卡路里、宏量营养素和分量）的影响。同时，提出了公开数据集ACETADA，并测试了八种LMMs（四种开源和四种闭源）的性能。

研究结果: 实验结果表明，结合上下文元数据能显著降低预测营养值的平均绝对误差（MAE）和平均绝对百分比误差（MAPE）。此外，元数据的整合还提升了推理修饰符（如思维链、多模态思维链等）的效果。

研究结论: 本文证明了上下文感知的LMMs在营养分析中的潜力，强调了元数据整合的重要性，并为未来研究提供了公开数据集ACETADA。

中文摘要: 大型多模态模型（LMMs）越来越多地应用于餐食图像的营养分析。然而，现有研究主要评估专有模型（如GPT-4），而忽略了其他大型语言模型（LLMs）的潜力。此外，整合上下文元数据及其与各种推理修饰符的交互作用尚未充分探索。本研究探讨了如何通过解析来自GPS坐标（转换为地点/场所类型）、时间戳（转换为餐次/日类型）和食物种类的元数据，提升LMMs在估计关键营养值（如卡路里、宏量营养素和分量）中的表现。我们还提出了ACETADA，一个即将公开的新食品图像数据集，该数据集包含由营养师验证的营养信息，并作为分析的基础。通过对八种LMMs（四种开源和四种闭源）的评估，我们首先证明了整合上下文元数据优于仅使用图像的简单提示。随后，我们展示了这种元数据整合如何提升推理修饰符（如思维链、多模态思维链、比例提示、少样本和专家角色）的效果。实证结果表明，通过简单提示策略智能整合元数据，可以显著降低预测营养值的平均绝对误差（MAE）和平均绝对百分比误差（MAPE）。本研究凸显了上下文感知LMMs在改进营养分析中的潜力。

</details>


### [123] [An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator](https://arxiv.org/abs/2507.07073)
**中文标题：一种学习Laplace-Beltrami算子频谱的AI方法**

*Yulin An,Enrique del Castillo*

主要分类: cs.CV

摘要简述: 本文提出了一种基于几何深度学习的框架，用于高效预测Laplace-Beltrami算子的频谱，显著降低计算成本并保持准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于有限元方法（FEM）计算Laplace-Beltrami频谱的方法在大型CAD机械部件数据库或频繁质量检测应用中效率低下，亟需一种更高效的解决方案。

研究方法: 采用图神经网络架构，结合高斯曲率、平均曲率和主曲率等丰富的网格特征，训练模型预测Laplace-Beltrami频谱。

研究结果: 实验结果表明，该方法将计算时间缩短至线性FEM的约五分之一，同时保持竞争性精度。

研究结论: 该研究证明了Laplace-Beltrami频谱的可学习性，为几何深度学习任务提供了高效工具。

中文摘要: Laplace-Beltrami（LB）算子的频谱在几何深度学习任务中至关重要，能够捕捉物体形状的内在特性。目前最成熟的估计方法基于有限元方法（FEM），通过三角网格计算前k个LB特征值，复杂度为O(Nk)，其中N为点数。这在频繁应用于CAD机械部件数据库或需要快速频繁决策的质量控制场景中效率较低。为解决此问题，我们提出了一种几何深度学习框架，通过CAD网格高效预测LB频谱，显著节省计算成本且不牺牲精度，证明了LB频谱的可学习性。所提出的图神经网络架构利用了丰富的网格特征，包括高斯曲率、平均曲率和主曲率。除训练网络外，我们还提供了一个基于公开ABC数据集的大规模真实机械CAD模型数据集，用于训练和测试。实验结果表明，该方法将LB频谱计算时间缩短至线性FEM的约五分之一，同时保持竞争性精度。

</details>


### [124] [Reading a Ruler in the Wild](https://arxiv.org/abs/2507.07077)
**中文标题：野外标尺读数**

*Yimu Pan,Manas Mehta,Gwen Sincerbeaux,Jeffery A. Goldstein,Alison D. Gernand,James Z. Wang*

主要分类: cs.CV

摘要简述: 本文提出RulerNet，一种深度学习框架，通过将标尺读数统一为关键点检测问题，并结合几何级数参数表示标尺，实现像素测量到真实尺寸的准确转换。该方法在多样化的标尺类型和成像条件下表现优异，并支持实时测量。


<details>
  <summary>详细信息</summary>
研究动机: 在计算机视觉中，将像素测量准确转换为真实世界尺寸是一个基础性挑战，限制了生物医学、法医学、营养分析和电子商务等关键应用的发展。传统方法依赖手工阈值或特定标尺流程，难以泛化。因此，需要一种鲁棒且通用的解决方案。

研究方法: RulerNet将标尺读数重新定义为统一的关键点检测问题，并使用几何级数参数表示标尺，使其对透视变换具有不变性。通过失真不变的标注和训练策略直接定位厘米标记，并结合基于图形的合成数据生成和ControlNet增强训练多样性。此外，提出轻量级网络DeepGP，通过回归几何级数参数实现实时测量。

研究结果: 实验表明，RulerNet在复杂现实条件下提供了准确、一致且高效的尺寸估计，泛化能力强，适用于多种标尺类型和成像条件。

研究结论: RulerNet作为一种通用测量工具，具有广泛的应用潜力，可与其他视觉组件集成，实现自动化、尺度感知的高影响力领域分析。

中文摘要: 准确地将像素测量转换为绝对真实世界尺寸仍然是计算机视觉中的一个基本挑战，限制了生物医学、法医学、营养分析和电子商务等关键应用的进展。我们提出了RulerNet，一种深度学习框架，通过将标尺读数重新定义为统一的关键点检测问题，并使用对透视变换不变的几何级数参数表示标尺，从而在野外鲁棒地推断尺度。与传统方法依赖手工阈值或特定标尺流程不同，RulerNet通过失真不变的标注和训练策略直接定位厘米标记，能够在多样化的标尺类型和成像条件下实现强泛化，同时缓解数据稀缺问题。我们还提出了一种可扩展的合成数据生成流程，结合基于图形的标尺生成和ControlNet添加逼真上下文，显著增加训练多样性并提升性能。为了进一步增强鲁棒性和效率，我们提出了DeepGP，一种轻量级前馈网络，从噪声标记回归几何级数参数，并消除迭代优化，支持在移动或边缘设备上实时估计尺度。实验表明，RulerNet在具有挑战性的现实条件下提供了准确、一致且高效的尺度估计。这些结果突显了其作为通用测量工具的实用性，以及与其他视觉组件集成以实现高影响力领域中自动化、尺度感知分析的潜力。演示地址：https://huggingface.co/spaces/ymp5078/RulerNet-Demo。

</details>


### [125] [Evaluating Attribute Confusion in Fashion Text-to-Image Generation](https://arxiv.org/abs/2507.07079)
**中文标题：评估时尚文本到图像生成中的属性混淆问题**

*Ziyue Liu,Federico Girella,Yiming Wang,Davide Talon*

主要分类: cs.CV

摘要简述: 本文提出了一种新的自动评估指标L-VQAScore，用于解决时尚领域文本到图像生成中的属性混淆问题，通过结合视觉定位和VQA技术，显著提升了评估的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管文本到图像生成模型在时尚领域取得了快速进展，但现有评估方法在复杂组合生成中仍存在局限性，尤其是属性混淆问题（属性正确但关联到错误实体）。本文旨在解决这一问题。

研究方法: 基于视觉问答（VQA）定位策略，针对单一实体在视觉和文本模态中进行评估，提出了局部化人类评估协议和新型自动指标L-VQAScore，结合视觉定位与VQA探测正确和错误定位的属性生成。

研究结果: 在新构建的数据集上，L-VQAScore在与人评估的相关性上优于现有最佳方法，能够有效捕捉细粒度实体-属性关联。

研究结论: L-VQAScore是一种可靠且可扩展的替代主观评估的方法，为时尚领域的文本到图像生成评估提供了更精准的工具。

中文摘要: 尽管文本到图像（T2I）生成模型在时尚领域取得了快速进展，但其评估在涉及复杂组合生成时仍具挑战性。现有的自动化T2I评估方法利用预训练的视觉-语言模型来衡量跨模态对齐，但我们的初步研究表明，这些方法在评估丰富的实体-属性语义时仍存在局限，尤其是面对属性混淆问题（即属性被正确描绘但关联到错误实体）。为解决这一问题，我们基于视觉问答（VQA）定位策略，针对单一实体在视觉和文本模态中进行评估。我们提出了一种局部化的人类评估协议，并引入了一种新型自动指标——局部化VQAScore（L-VQAScore），该指标结合了视觉定位与VQA探测正确（反射）和错误定位（泄漏）的属性生成。在新构建的包含挑战性组合对齐场景的数据集上，L-VQAScore在与人类评估的相关性上优于现有最佳T2I评估方法，展示了其在捕捉细粒度实体-属性关联方面的优势。我们相信L-VQAScore可以成为主观评估的可靠且可扩展的替代方案。

</details>


### [126] [Go to Zero: Towards Zero-shot Motion Generation with Million-scale Data](https://arxiv.org/abs/2507.07095)
**中文标题：迈向零样本运动生成：基于百万级数据的研究**

*Ke Fan,Shunlin Lu,Minyue Dai,Runyi Yu,Lixing Xiao,Zhiyang Dou,Junting Dong,Lizhuang Ma,Jingbo Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种零样本运动生成方法，通过构建大规模数据集MotionMillion和评估基准MotionMillion-Eval，结合7B参数模型，显著提升了零样本运动生成的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于文本描述生成多样化且自然的人体运动序列的方法在零样本泛化能力上存在不足，主要受限于训练数据集的规模不足和缺乏全面的评估框架。本文旨在推动文本到运动生成进入零样本泛化的新时代。

研究方法: 首先，开发了高效的标注流程，构建了迄今为止最大的人体运动数据集MotionMillion，包含超过2000小时和200万条高质量运动序列。其次，提出了最全面的零样本运动生成评估基准MotionMillion-Eval。最后，利用可扩展的架构将模型参数扩展到7B，并在MotionMillion-Eval上验证其性能。

研究结果: 实验结果表明，该方法在域外和复杂组合运动上表现出强大的泛化能力，为零样本人体运动生成迈出了重要一步。

研究结论: 通过大规模数据集和评估基准的结合，本文显著提升了零样本运动生成的性能，为未来研究提供了重要参考。

中文摘要: 基于文本描述生成多样化且自然的人体运动序列是计算机视觉、图形学和机器人学中的一个基础且具有挑战性的研究领域。尽管该领域取得了显著进展，但当前方法在零样本泛化能力方面仍面临挑战，主要原因是训练数据集的规模有限。此外，缺乏全面的评估框架阻碍了该任务的进步，无法明确改进方向。本文旨在将文本到运动生成推向一个新的时代，即实现零样本泛化能力。为此，首先开发了高效的标注流程，并引入了迄今为止最大的人体运动数据集MotionMillion，包含超过2000小时和200万条高质量运动序列。此外，提出了最全面的零样本运动生成评估基准MotionMillion-Eval。利用可扩展的架构，将模型参数扩展到7B，并在MotionMillion-Eval上验证其性能。结果表明，该方法在域外和复杂组合运动上表现出强大的泛化能力，为零样本人体运动生成迈出了重要一步。代码可在https://github.com/VankouF/MotionMillion-Codes获取。

</details>


### [127] [Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models](https://arxiv.org/abs/2507.07104)
**中文标题：视觉-语言-视觉自动编码器：从扩散模型中可扩展的知识蒸馏**

*Tiezheng Zhang,Yitong Li,Yu-cheng Chou,Jieneng Chen,Alan Yuille,Chen Wei,Junfei Xiao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Vision-Language-Vision（VLV）的自动编码器框架，通过利用预训练的视觉编码器、文本到图像扩散模型解码器和大型语言模型，显著降低了训练成本和数据需求，同时实现了高质量的图像描述生成。


<details>
  <summary>详细信息</summary>
研究动机: 当前构建高性能视觉语言模型（VLMs）需要大量高质量图像-文本对和昂贵的计算资源。本文旨在通过利用现有预训练模型，减少数据需求和训练成本，同时保持模型性能。

研究方法: VLV框架通过冻结预训练的文本到图像扩散模型解码器，建立信息瓶颈，并利用连续嵌入从扩散模型中提取知识。随后，通过微调预训练的大型语言模型，将中间语言表示解码为详细描述。

研究结果: 该方法显著降低了训练成本（总费用低于1000美元），并生成了与GPT-4o和Gemini 2.0 Flash相媲美的高质量图像描述。

研究结论: VLV框架通过有效利用现有预训练模型，实现了高性能视觉语言模型的低成本训练，为未来研究提供了可行的解决方案。

中文摘要: 构建具有强大描述能力的先进视觉语言模型（VLMs）通常需要在数十亿高质量图像-文本对上训练，消耗数百万GPU小时。本文提出了视觉-语言-视觉（VLV）自动编码器框架，通过策略性地利用预训练的关键组件：视觉编码器、文本到图像（T2I）扩散模型的解码器以及大型语言模型（LLM）。具体而言，我们通过冻结预训练的T2I扩散解码器，对语言表示空间进行正则化，建立了信息瓶颈。VLV管道通过连续嵌入从文本条件扩散模型中有效提取知识，并通过高质量重建展示了全面的语义理解。此外，通过微调预训练的LLM将中间语言表示解码为详细描述，我们构建了与GPT-4o和Gemini 2.0 Flash等领先模型相媲美的先进描述生成器。我们的方法展示了卓越的成本效益，并显著减少了数据需求；主要通过使用单模态图像进行训练，并最大化利用现有预训练模型（图像编码器、T2I扩散模型和LLM），避免了大规模配对图像-文本数据集的需求，总训练费用控制在1000美元以下。

</details>


### [128] [4KAgent: Agentic Any Image to 4K Super-Resolution](https://arxiv.org/abs/2507.07105)
**中文标题：4KAgent：智能代理驱动的任意图像至4K超分辨率**

*Yushen Zuo,Qi Zheng,Mingyang Wu,Xinrui Jiang,Renjie Li,Jian Wang,Yide Zhang,Gengchen Mai,Lihong V. Wang,James Zou,Xiaoyu Wang,Ming-Hsuan Yang,Zhengzhong Tu*

主要分类: cs.CV

摘要简述: 4KAgent是一个统一的智能超分辨率系统，能够将任何图像提升至4K分辨率，甚至更高。它通过定制化模块、感知代理和修复代理，显著提升图像质量，尤其在面部细节修复上表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 当前图像超分辨率技术在处理低分辨率或严重退化的图像时效果有限，尤其是在多样化的应用场景中。4KAgent旨在通过智能代理系统，实现通用且高效的图像修复，推动低层视觉任务的创新。

研究方法: 4KAgent包含三个核心组件：(1) 定制化模块，根据用例调整流程；(2) 感知代理，结合视觉语言模型和图像质量评估专家分析输入图像并制定修复计划；(3) 修复代理，执行计划并通过递归执行-反思范式选择最优输出。

研究结果: 4KAgent在11个任务类别和26个基准测试中表现优异，覆盖自然图像、人像、AI生成内容、卫星图像等多种领域，在感知和保真度指标上均达到最新技术水平。

研究结论: 4KAgent通过智能代理范式为低层视觉任务提供了创新解决方案，展示了在多样化研究领域中的广泛应用潜力。

中文摘要: 我们提出了4KAgent，一个统一的智能超分辨率通用系统，能够将任何图像提升至4K分辨率（甚至更高，通过迭代应用）。该系统可以将极低分辨率且严重退化的图像（例如256x256的严重失真输入）转换为清晰、逼真的4K输出。4KAgent包含三个核心组件：(1) 定制化模块，根据特定用例调整流程；(2) 感知代理，利用视觉语言模型和图像质量评估专家分析输入图像并制定定制修复计划；(3) 修复代理，执行计划并遵循递归执行-反思范式，通过质量驱动的专家混合策略选择每一步的最优输出。此外，4KAgent还集成了专门的面部修复流程，显著提升了人像和自拍照片的面部细节。我们在11个任务类别和26个多样化基准测试中对4KAgent进行了严格评估，涵盖了自然图像、人像照片、AI生成内容、卫星图像、荧光显微镜以及医学影像（如眼底摄影、超声和X射线），在感知（如NIQE、MUSIQ）和保真度（如PSNR）指标上均表现出卓越性能。通过为低层视觉任务建立一种新型智能代理范式，我们旨在激发更广泛的兴趣和创新，推动以视觉为中心的自主代理在多样化研究领域的发展。所有代码、模型和结果将在https://4kagent.github.io上发布。

</details>


### [129] [Towards Multimodal Understanding via Stable Diffusion as a Task-Aware Feature Extractor](https://arxiv.org/abs/2507.07106)
**中文标题：通过稳定扩散作为任务感知特征提取器实现多模态理解**

*Vatsal Agarwal,Matthew Gwilliam,Gefen Kohavi,Eshan Verma,Daniel Ulbricht,Abhinav Shrivastava*

主要分类: cs.CV

摘要简述: 本文探讨了预训练文本到图像扩散模型作为任务感知视觉编码器的潜力，发现其能捕捉细粒度细节并增强图像-文本对齐，同时提出了一种融合CLIP和扩散特征的方法以解决信息泄漏问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型（MLLMs）依赖CLIP作为视觉编码器，但其在捕捉细粒度细节方面存在不足。本文旨在研究扩散模型是否能作为任务感知的视觉编码器，以提升视觉理解能力。

研究方法: 通过分析扩散模型的内部表示，发现其具有丰富的语义和图像-文本对齐能力。研究还利用文本条件聚焦模型于输入问题相关区域，并提出一种融合CLIP和扩散特征的策略以缓解信息泄漏问题。

研究结果: 实验表明，扩散模型在视觉理解任务中表现优异，尤其在需要空间和组合推理的视觉中心任务中。融合策略在通用VQA和专用MLLM基准测试中均显示出潜力。

研究结论: 扩散模型可作为任务感知视觉编码器，显著提升视觉理解能力，特别是在细粒度和空间推理任务中。未来的工作可进一步优化特征对齐策略。

中文摘要: 近年来，多模态大语言模型（MLLMs）已实现基于图像的问答能力。然而，其关键局限在于使用CLIP作为视觉编码器；尽管它能捕捉粗略的全局信息，但往往忽略与输入查询相关的细粒度细节。为解决这一问题，本研究探讨了预训练文本到图像扩散模型是否能作为指令感知的视觉编码器。通过分析其内部表示，我们发现扩散特征不仅语义丰富，还能编码强图像-文本对齐。此外，我们发现可以利用文本条件将模型聚焦于输入问题相关区域。随后，我们研究了如何将这些特征与大语言模型对齐，并发现了一种泄漏现象，即LLM可能无意中恢复原始扩散提示的信息。我们分析了泄漏原因并提出了缓解策略。基于这些发现，我们探索了一种简单的融合策略，同时利用CLIP和条件扩散特征。我们在通用VQA和专用MLLM基准测试中评估了该方法，证明了扩散模型在视觉理解中的潜力，尤其是在需要空间和组合推理的视觉中心任务中。项目页面见https://vatsalag99.github.io/mustafar/。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [130] [Digital Wargames to Enhance Military Medical Evacuation Decision-Making](https://arxiv.org/abs/2507.06373)
**中文标题：利用数字战争游戏提升军事医疗后送决策能力**

*Jeremy Fischer,Ram Krishnamoorthy,Vishal Kumar,Mahdi Al-Husseini*

主要分类: cs.AI

摘要简述: 本文介绍了医疗后送战争游戏倡议（MEWI），这是一种基于Unity开发的三维多人模拟工具，用于模拟战场医疗后送网络，提升军事医疗后送决策能力。通过两个实战场景测试，MEWI显著提高了学员对医疗后送课程的理解和协作决策能力。


<details>
  <summary>详细信息</summary>
研究动机: 医疗后送是美国陆军关键任务之一，但缺乏在课堂环境中模拟和评估后送网络规划与决策的工具。MEWI旨在填补这一空白，提供高保真训练工具以提升医疗后送教育和操作水平。

研究方法: MEWI是一个基于Unity开发的三维多人模拟工具，模拟战场约束和不确定性，包括伤员收集点、救护车交换点、医疗设施和后送平台。通过太平洋岛屿两栖作战和欧亚大陆道路与河流网络冲突两个场景，学员需在规定时间内尽可能多地救治伤员。

研究结果: MEWI在美军医疗后送课程中的测试表明，学员参与后对医疗后送课程的理解和协作决策能力显著提升。Likert调查和观察记录显示，MEWI在规划和决策关键点上提供了重要反馈。

研究结论: MEWI是医疗教育领域高保真训练工具的重要进展，为联合部队医疗后送教育和操作提供了关键改进方向。

中文摘要: 医疗后送是美国陆军最重要且历史悠久的任务之一，负责高效迅速地将战场伤病员撤离。医疗后送规划涉及设计一个能够移动和治疗大量伤员的医疗平台和设施网络。目前尚缺乏一种在课堂环境中模拟这些网络并评估离线规划和在线决策性能的工具。本文介绍了医疗后送战争游戏倡议（MEWI），这是一个基于Unity开发的三维多人模拟工具，复制了战场约束和不确定性。MEWI准确模拟了伤员在收集点、救护车交换点、医疗设施和后送平台的互动。引入了两个实战场景：太平洋岛屿两栖作战和欧亚大陆道路与河流网络冲突。学员需在规定时间内尽可能多地救治伤员，同时遵循课程中学到的原则。我们可视化了两轮MEWI太平洋场景测试中收集的性能数据，并结合学员的Likert调查和外部观察记录，识别关键规划决策点，记录医疗后送经验教训，并量化其通用效用。结果表明，MEWI显著提高了学员对医疗后送课程的理解和协作决策能力。MEWI是医疗教育领域高保真训练工具的重要进展，研究结果为联合部队医疗后送教育和操作提供了关键改进方向。

</details>


### [131] [Representing Prompting Patterns with PDL: Compliance Agent Case Study](https://arxiv.org/abs/2507.06396)
**中文标题：用PDL表示提示模式：合规代理案例研究**

*Mandana Vaziri,Louis Mandel,Yuji Watanabe,Hirokuni Kitahara,Martin Hirzel,Anca Sailer*

主要分类: cs.AI

摘要简述: 本文提出了一种名为提示声明语言（PDL）的新方法，用于解决大型语言模型（LLM）提示工程的复杂性，并通过合规代理案例展示了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的提示工程框架要么通过限制性API隐藏复杂性，要么提供难以自定义的固定模式，导致高级代理编程困难。本文旨在通过PDL将提示置于核心位置，支持手动和自动调优，同时整合LLM调用、基于规则的代码和外部工具。

研究方法: 提出提示声明语言（PDL），通过声明式表示抽象化组合逻辑，提升程序员效率，并为优化提供基础。通过合规代理案例验证PDL的实用性。

研究结果: 使用PDL调优合规代理的提示模式，性能提升了4倍，优于固定代理和提示模式。

研究结论: PDL通过声明式表示和抽象化组合逻辑，显著提升了提示工程的灵活性和性能，为复杂代理编程提供了有效工具。

中文摘要: 大型语言模型（LLM）的提示工程仍然复杂，现有框架要么通过限制性API隐藏复杂性，要么提供难以自定义的固定模式，使得高级代理编程变得困难。我们提出了提示声明语言（PDL），这是一种新颖的提示表示方法，通过将提示置于核心位置，支持手动和自动调优，同时整合LLM调用、基于规则的代码和外部工具。通过抽象化这些组合的逻辑，PDL旨在提高程序员效率，并提供可优化的声明式表示。本文通过合规代理的真实案例展示了PDL的实用性。调优该代理的提示模式后，性能提升了4倍，优于固定代理和提示模式。

</details>


### [132] [Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI](https://arxiv.org/abs/2507.06398)
**中文标题：颠覆性技术：AI能力的超指数加速及其对AGI的启示**

*David Orban*

主要分类: cs.AI

摘要简述: 本文研究“Jolting Technologies Hypothesis”，提出AI能力发展存在超指数增长（加速增长或正三阶导数）的理论，并通过蒙特卡洛模拟验证检测方法，为未来实证研究提供工具，探讨其对AGI的潜在影响。


<details>
  <summary>详细信息</summary>
研究动机: 探讨AI能力发展是否存在超指数增长模式，并研究其背后的驱动因素（如从构想到行动的周期缩短和AI迭代改进的复合效应），为理解AI发展轨迹及其对AGI的影响提供理论基础。

研究方法: 建立理论框架，通过蒙特卡洛模拟验证检测方法，分析驱动超指数增长的因素（如缩短的构想到行动周期和AI迭代改进的复合效应）。

研究结果: 开发了检测超指数增长的工具，并通过模拟验证其有效性，为未来实证研究奠定数学基础，同时揭示了AI能力加速发展的潜在机制。

研究结论: 研究为理解AI能力超指数增长提供了理论和方法支持，强调其对AGI发展的潜在影响，为研究和政策制定提供了重要参考。

中文摘要: 本文研究了“颠覆性技术假说”，该假说认为AI能力的发展存在超指数增长（加速增长或正三阶导数）。我们通过蒙特卡洛模拟建立了理论框架并验证了检测方法，尽管实证验证仍需合适的纵向数据。分析重点是为未来实证研究创建稳健工具，并探讨假说成立时的潜在影响。研究考察了从构想到行动周期的缩短和AI迭代改进的复合效应如何驱动这一颠覆性模式。通过形式化颠覆动态并通过模拟验证检测方法，本研究为理解潜在AI发展轨迹及其对AGI出现的影响提供了数学基础，为研究和政策提供了洞见。

</details>


### [133] [Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)](https://arxiv.org/abs/2507.06798)
**中文标题：比较辩证系统：信念修正中的矛盾与反例（扩展版）**

*Uri Andrews,Luca San Mauro*

主要分类: cs.AI

摘要简述: 本文比较了三种辩证系统（d-、p-和q-辩证系统），证明了q-辩证系统比p-辩证系统更强大，而p-辩证系统又比d-辩证系统更强，强调了反例和矛盾在自动信念修正中的互补作用。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于解决文献中关于辩证系统能力的开放性问题，尤其是比较d-、p-和q-辩证系统的相对能力，以揭示反例和矛盾在信念修正中的不同作用。

研究方法: 通过数学证明方法，比较了三种辩证系统的能力：d-辩证系统基于信念不一致时的修正，p-辩证系统基于反例的修正，q-辩证系统则结合两者。

研究结果: 研究结果表明，q-辩证系统严格强于p-辩证系统，而p-辩证系统又严格强于d-辩证系统，验证了反例和矛盾在信念修正中的互补性。

研究结论: 结论指出，q-辩证系统的优越性展示了反例和矛盾在自动信念修正中的重要性，这对数学家和研究社区的推理过程具有启示意义。

中文摘要: 辩证系统是一种数学模型，用于描述智能体在追求一致性时更新知识库的过程。由Roberto Magari于1970年代提出，最初旨在捕捉数学家或研究社区在追求真理时如何修正信念。辩证系统也为自动智能体的信念变化提供了自然模型，为动态信念管理提供了一个统一且可计算的框架。
文献中区分了三种主要的辩证系统模型：基于信念不一致时修正的d-辩证系统、基于反例修正的p-辩证系统，以及两者结合的q-辩证系统。我们通过证明q-辩证系统严格强于p-辩证系统（而p-辩证系统又严格强于d-辩证系统），解决了文献中的一个开放性问题。这一结果凸显了反例和矛盾在自动信念修正中的互补作用，进而对数学家和研究社区的推理过程具有重要意义。

</details>


### [134] [SCC-recursiveness in infinite argumentation (extended version)](https://arxiv.org/abs/2507.06852)
**中文标题：无限论证中的SCC递归性（扩展版）**

*Uri Andrews,Luca San Mauro*

主要分类: cs.AI

摘要简述: 本文探讨了如何将SCC递归性扩展到无限论证框架中，提出了两种方法，并通过Baroni和Giacomin的标准评估其有效性，发现方向性在一般情况下失败，但在有限框架中部分满足。


<details>
  <summary>详细信息</summary>
研究动机: SCC递归性在有限论证框架中已证明有效，但在无限框架中因缺乏良基性而失败。本文旨在解决这一问题，扩展SCC递归性至无限论证框架。

研究方法: 提出了两种扩展SCC递归性到无限论证框架的方法，并系统地使用Baroni和Giacomin的标准评估这些语义，特别关注方向性的表现。

研究结果: 研究发现方向性在一般情况下不成立，但在有限框架中部分语义满足方向性。这些结果为无限论证理论提供了新的基础。

研究结论: 本文为无限论证理论的发展奠定了基础，并为处理无界或动态领域的推理系统提供了理论支持。

中文摘要: 论证框架（AFs）是人工智能中用于建模结构化推理和冲突的基础工具。SCC递归性是一种著名的设计原则，其中论证的评估根据攻击图的强连通组件（SCCs）进行分解，从“高”到“低”组件递归进行。尽管SCC递归语义（如\cft和\stgt）在有限AFs中已被证明有效，但Baumann和Spanring指出，由于良基性问题，SCC递归语义无法可靠地推广到无限AFs。

我们提出了两种将SCC递归性扩展到无限设置的方法。我们使用Baroni和Giacomin的既定标准系统地评估这些语义，特别指出方向性在一般情况下失败。随后，我们研究了这些语义在有限框架中的行为，发现部分语义满足方向性。这些结果推动了无限论证理论的发展，并为能够处理无界或动态领域的推理系统奠定了基础。

</details>


### [135] [Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report](https://arxiv.org/abs/2507.06968)
**中文标题：迈向指令集信息边界的扩展：InfinityInstruct-Subject技术报告**

*Li Du,Hanyu Zhao,Yiming Ju,Tengfei Pan*

主要分类: cs.AI

摘要简述: 本文提出了一种系统化的指令数据构建框架InfinityInstruct-Subject，通过分层标注、种子选择、数据合成和模型缺陷诊断等方法，构建了包含150万条指令的高质量数据集，显著提升了模型的指令遵循能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前指令数据集虽然规模庞大，但在任务类型覆盖和指令复杂度上仍存在不足，导致模型在复杂指令和罕见领域任务中表现不佳。本文旨在通过系统性方法提升指令数据的覆盖范围和深度。

研究方法: 提出了一种系统化框架，包括分层标注系统、信息种子选择算法、进化数据合成过程以及模型缺陷诊断与针对性数据生成，形成闭环迭代以持续优化指令数据。

研究结果: 实验表明，InfinityInstruct-Subject数据集在多个基础模型和基准任务中显著提升了指令遵循能力，其覆盖范围和深度优于同类合成指令数据集。

研究结论: 本文为指令数据集的高效持续进化提供了理论和实践基础，推动了从数据量扩张到质量提升的转变。

中文摘要: 指令微调已成为释放大规模预训练模型潜力并提升其在复杂任务中表现的基础。因此，构建高质量的指令数据集对提升模型性能和泛化能力至关重要。尽管当前指令数据集已达数千万样本，但基于其微调的模型在复杂指令遵循和罕见领域任务中仍表现不佳。这主要归因于指令集在“覆盖范围”（任务类型和知识领域）和“深度”（指令复杂度）上的扩展有限。为解决这一问题，我们提出了一种系统化的指令数据构建框架，整合了分层标注系统、信息种子选择算法、进化数据合成过程以及模型缺陷诊断与针对性数据生成。这些组件形成一个闭环迭代，持续提升指令数据的覆盖范围和深度。基于此框架，我们构建了InfinityInstruct-Subject，一个包含约150万条指令的高质量数据集。在多个基础模型和基准任务上的实验证明了其在提升指令遵循能力方面的有效性。进一步分析表明，与同类合成指令数据集相比，InfinityInstruct-Subject显示出更大的覆盖范围和深度。我们的工作为指令数据集的高效持续进化奠定了理论和实践基础，推动了从数据量扩张到质量提升的转变。

</details>


### [136] [The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation](https://arxiv.org/abs/2507.06993)
**中文标题：以用户为中心的地理体验：基于LLM的增强规划、导航与动态适应框架**

*Jieren Deng,Aleksandar Cvetkovic,Pak Kiu Chung,Dragomir Yankov,Chiqun Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于LLM的用户中心地理体验框架，通过三个协作代理解决传统旅行规划系统的静态和碎片化问题，显著提升了查询解析、导航精度和行程适应能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统旅行规划系统静态且碎片化，无法应对现实世界中的复杂变化（如环境条件变化和行程中断）。本文旨在解决现有服务提供商在智能行程规划、精准导航和动态适应方面的不足，以提升用户体验。

研究方法: 提出三个协作代理：1) 旅行规划代理，通过网格空间定位和地图分析处理多模态用户查询；2) 目的地助手代理，提供旅程最后一程的精细导航；3) 本地发现代理，利用图像嵌入和检索增强生成技术检测并应对行程中断。

研究结果: 实验表明，该系统在查询解析、导航精度和行程中断恢复方面表现优异，适用于从城市探索到应急响应的多种场景。

研究结论: 该框架通过协作代理显著提升了地理体验的动态适应能力，为未来智能旅行系统的发展提供了新方向。

中文摘要: 传统旅行规划系统通常静态且碎片化，难以应对现实世界中的复杂变化（如环境条件演变和行程意外中断）。本文指出了现有服务提供商在智能行程规划、精准“最后100米”导航和动态行程适应方面的三个不足。我们提出了三个协作代理：旅行规划代理，通过网格空间定位和地图分析解决复杂多模态用户查询；目的地助手代理，为每段旅程的最后一程提供精细导航；本地发现代理，利用图像嵌入和检索增强生成技术检测并应对行程中断。通过评估和实验，我们的系统在查询解析、导航精度和中断恢复方面表现出显著改进，展示了其在从城市探索到应急响应等多种应用中的潜力。

</details>


### [137] [First Return, Entropy-Eliciting Explore](https://arxiv.org/abs/2507.07017)
**中文标题：首次回报、熵引导探索**

*Tianyu Zheng,Tianshun Xing,Qingshui Gu,Taoran Liang,Xingwei Qu,Xin Zhou,Yizhi Li,Zhoufutu Wen,Chenghua Lin,Wenhao Huang,Qian Liu,Ge Zhang,Zejun Ma*

主要分类: cs.AI

摘要简述: 本文提出FR3E框架，通过结构化探索改善大型语言模型（LLM）在强化学习中的不稳定探索问题，提升推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于可验证奖励的强化学习（RLVR）虽然能提升大型语言模型的推理能力，但其探索过程不稳定，需要一种更结构化的探索方法。

研究方法: FR3E框架通过识别推理轨迹中的高不确定性决策点，进行有针对性的探索，生成语义明确的中间反馈，无需依赖密集监督。

研究结果: 在数学推理基准测试（AIME24）中，FR3E显著提升了训练稳定性，生成了更长且更连贯的响应，并增加了完全正确轨迹的比例。

研究结论: FR3E通过更稳健和结构化的探索，有效提升了大型语言模型的推理能力。

中文摘要: 基于可验证奖励的强化学习（RLVR）提升了大型语言模型（LLM）的推理能力，但其探索过程不稳定。我们提出了FR3E（首次回报、熵引导探索）框架，通过结构化探索识别推理轨迹中的高不确定性决策点，并进行有针对性的探索以构建语义明确的中间反馈。该方法无需依赖密集监督即可提供针对性指导。在数学推理基准测试（AIME24）上的实验结果表明，FR3E显著提升了训练稳定性，生成了更长且更连贯的响应，并增加了完全正确轨迹的比例。这些结果证明了该框架通过更稳健和结构化的探索有效提升了LLM的推理能力。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [138] [The Emotional Alignment Design Policy](https://arxiv.org/abs/2507.06263)
**中文标题：情感对齐设计政策**

*Eric Schwitzgebel,Jeff Sebo*

主要分类: cs.CY

摘要简述: 情感对齐设计政策提出，人工实体应设计为引发用户情感反应，以准确反映其能力和道德状态。违反此原则可能导致情感反应过强、过弱或类型错误。实施面临用户自主权、事实与价值观分歧等挑战。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探讨人工实体设计如何引发用户适当的情感反应，避免情感反应与实体能力或道德状态不匹配的问题。

研究方法: 通过提出情感对齐设计政策，分析其可能违反的两种方式（情感反应过强或过弱、反应类型错误），并讨论实际实施中的挑战。

研究结果: 研究指出情感对齐设计的复杂性，包括尊重用户自主权、处理专家与公众分歧、以及涉及道德状态实体的创建或销毁等问题。

研究结论: 结论强调情感对齐设计的重要性，同时指出需平衡用户自主权与情感引导，并解决事实与价值观的不确定性。

中文摘要: 根据我们提出的情感对齐设计政策，人工实体应设计为引发用户情感反应，以准确反映其能力与道德状态（或缺乏）。违反此原则有两种方式：设计引发过强或过弱情感反应的系统（超出或未达目标），或引发错误类型情感反应的系统（偏离目标）。尽管看似吸引人，实际实施面临多项挑战：如何在尊重用户自主权的同时促进适当反应？如何应对专家与公众在事实和价值观上的分歧与不确定性？若情感对齐需创建或销毁具道德状态的实体，该如何处理？设计应在多大程度上适应用户假设与态度，或尝试改变它们？

</details>


### [139] [A Collectivist, Economic Perspective on AI](https://arxiv.org/abs/2507.06268)
**中文标题：一种集体主义经济视角下的人工智能**

*Michael I. Jordan*

主要分类: cs.CY

摘要简述: 本文提出从集体主义和经济视角重新审视人工智能的发展，强调社会和文化因素对智能的重要性，并呼吁将社会福利作为系统设计的核心。


<details>
  <summary>详细信息</summary>
研究动机: 当前人工智能的发展过于关注个体认知和技术层面，忽视了人类作为社会动物的本质及其社会文化对智能的贡献。作者希望通过结合经济和社会概念，推动更人性化的技术设计。

研究方法: 通过批判现有技术发展视角的局限性，提出将经济和社会概念与计算和推理概念深度融合，以系统级设计为目标，将社会福利作为优先考虑因素。

研究结果: 提出了一种新的人工智能发展路径，强调社会文化因素和经济视角的重要性，并呼吁建立以人为中心的工程领域。

研究结论: 人工智能的未来发展需要超越单纯的技术和数据驱动，融入社会和经济维度，以实现更广泛的社会福利和人性化设计。

中文摘要: 信息技术正处于一场革命中，无处不在的数据收集和机器学习以前所未有的方式影响着人类社会。"智能"一词被用作技术发展的北极星，而人类认知被视为基准。这种观点忽视了人类是社会动物的事实，以及我们的智能大多源于社会和文化。一个相关的问题是，当前观点将技术的社会后果视为事后考虑。未来的发展路径不仅仅是更多的数据和计算能力，也不仅仅是对认知或符号表示的更多关注，而是将经济和社会概念与计算和推理概念深度融合，服务于以社会福利为核心的系统级设计，并期望出现一个以人为中心的新工程领域。

</details>


### [140] [The Prompt War: How AI Decides on a Military Intervention](https://arxiv.org/abs/2507.06277)
**中文标题：提示战争：AI如何决定军事干预**

*Maxim Chupilkin*

主要分类: cs.CY

摘要简述: 本文通过联合实验分析了AI在军事干预决策中的关键因素，发现国内支持和高成功率是主要驱动因素，而成本因素影响较小。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在军事规划和战争游戏中的应用迅速增长，目前尚未对AI军事干预决策的关键驱动因素进行系统分析。本文旨在填补这一空白。

研究方法: 研究通过联合实验设计了640个情景，每个情景运行100次，系统探索AI在军事干预中的决策模式。使用了OpenAI GPT、Anthropic Claude和Google Gemini等模型。

研究结果: 研究发现，AI干预决策的最大预测因素是国内支持和高成功率。国际谴责、军事和平民死亡、经济负面影响等成本因素虽显著，但影响仅为前两者的一半。机会窗口仅与其他因素交互时显著。结果在不同模型和情景中高度一致。

研究结论: AI军事干预决策模式具有一致性，国内支持和高成功率是核心驱动因素，成本因素影响较小。

中文摘要: 哪些因素决定了AI对军事干预的倾向？尽管AI在战争游戏和军事规划中的应用呈指数增长，但尚未对模型中的关键驱动因素进行简单分析。本文通过联合实验提出了一个模型，在640个情景中运行100次，系统探索AI在军事干预中的决策。分析发现，AI干预决策的最大预测因素是国内支持和高成功率。国际谴责、军事死亡、平民死亡和负面经济影响等成本因素虽显著，但其影响仅为国内支持和胜利概率的一半。机会窗口仅与其他因素交互时显著。结果在不同情景和模型（OpenAI GPT、Anthropic Claude、Google Gemini）中高度一致，表明AI决策存在模式。

</details>


### [141] [Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles](https://arxiv.org/abs/2507.06310)
**中文标题：过于拟人化而难以建模：LLM在社交模拟中的恐怖谷——当生成语言代理与建模原则脱节时**

*Yongchao Zeng,Calum Brown,Mark Rounsevell*

主要分类: cs.CY

摘要简述: 论文探讨了大型语言模型（LLM）在社交模拟中的应用问题，指出其过于拟人化的特性与建模原则存在冲突，导致其陷入“恐怖谷”：既不够抽象以揭示社会机制，又不够自然以模拟真实人类行为。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在社交模拟中的广泛应用，其生成流畅对话的能力提升了模型的真实感，但这种真实感可能与建模的认知基础（如抽象性、简化性和可解释性）不兼容。论文旨在揭示LLM代理在建模中的局限性及其与建模原则的冲突。

研究方法: 通过一个思想实验，将Bass扩散模型转换为基于LLM的变体，论文揭示了五个核心困境：自然对话与抽象时间步的不匹配、干预对话与保持自发性的矛盾、提示中规则指令与对话自然性的冲突、角色一致性与角色演化的张力，以及系统级模式被微观文本输出掩盖的问题。

研究结果: 研究发现，LLM代理在社交模拟中陷入“恐怖谷”，既无法清晰揭示社会机制，又无法完全模拟真实人类行为。其拟真性可能掩盖而非阐明社会动态。

研究结论: 论文提出，LLM代理更适合用于不关注系统级涌现、以语言细微差别和意义为中心、交互以自然时间展开且角色身份稳定的场景。呼吁未来在社交模拟中重新定位LLM代理的应用范围。

中文摘要: 大型语言模型（LLM）因其生成流畅且上下文连贯对话的能力，被越来越多地用于构建社交模拟中的代理。这种能力可以增强模型的真实感。然而，追求真实感未必与建模的认知基础兼容。我们认为，LLM代理在许多方面过于拟人化：它们过于表达性、细节化和难以处理，无法满足建模通常要求的抽象性、简化性和可解释性。通过一个将Bass扩散模型转换为基于LLM变体的模型构建思想实验，我们揭示了五个核心困境：自然对话与抽象时间步的时间分辨率不匹配；在对话中干预的同时避免削弱代理自发输出的需求；在提示中引入规则指令的同时保持对话自然性的诱惑；角色一致性与跨时间角色演化之间的张力；以及理解涌现现象的挑战，即系统级模式被冗长的微观文本输出掩盖。这些困境将LLM代理推向一个“恐怖谷”：既不够抽象以阐明潜在社会机制，又不够自然以代表真实人类行为。这暴露了一个重要悖论：当误用时，LLM代理的真实感可能掩盖而非阐明社会动态。我们梳理了LLM代理的理想适用条件：不关注系统级涌现、以语言细微差别和意义为中心、交互以自然时间展开且角色身份稳定的场景。我们呼吁在未来应用中重新定位LLM代理在社交模拟生态系统中的位置。

</details>


### [142] [Deprecating Benchmarks: Criteria and Framework](https://arxiv.org/abs/2507.06434)
**中文标题：淘汰基准测试：标准与框架**

*Ayrton San Joaquin,Rokas Gipiškis,Leon Staufer,Ariel Gil*

主要分类: cs.CY

摘要简述: 随着前沿AI模型的快速发展，基准测试在比较不同模型和衡量其在特定任务领域进展方面至关重要。然而，缺乏关于何时以及如何淘汰无效基准测试的指导，可能导致高估模型能力或掩盖问题。本文提出淘汰基准的标准和框架，以推动更严谨的评估。


<details>
  <summary>详细信息</summary>
研究动机: 前沿AI模型的快速进步使得基准测试成为衡量模型能力的关键工具，但缺乏淘汰无效基准的明确标准可能导致评估失真或掩盖潜在问题。本文旨在填补这一空白，为基准测试的淘汰提供科学依据。

研究方法: 通过回顾基准测试实践，提出了判断基准是否应完全或部分淘汰的标准，并设计了一个淘汰框架。

研究结果: 提出了具体的淘汰标准和框架，旨在帮助基准开发者、用户、AI治理机构及政策制定者实现更严谨的评估。

研究结论: 本文的工作推动了基准测试向更严谨和高质量评估的方向发展，为前沿模型的评估提供了实用工具。

中文摘要: 随着前沿人工智能（AI）模型的快速发展，基准测试在比较不同模型和衡量其在特定任务领域进展方面至关重要。然而，缺乏关于何时以及如何淘汰无效基准测试的指导，可能导致基准分数高估模型能力，甚至掩盖问题或进行安全粉饰。基于对基准测试实践的回顾，我们提出了判断基准是否应完全或部分淘汰的标准，并设计了一个淘汰框架。我们的工作旨在推动基准测试向更严谨和高质量评估的方向发展，尤其是针对前沿模型。我们的建议旨在惠及基准开发者、用户、AI治理机构（包括政府、学术界和行业组织）以及政策制定者。

</details>


### [143] [Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study](https://arxiv.org/abs/2507.06438)
**中文标题：评估编程课程中AI辅助作弊的普遍性：一项试点研究**

*Kaléu Delphino*

主要分类: cs.CY

摘要简述: 一项针对编程课程中AI辅助作弊现象的试点研究表明，超过25%的学生承认使用AI工具作弊，匿名调查是有效的研究方法，而访谈则难以实施。


<details>
  <summary>详细信息</summary>
研究动机: 随着ChatGPT等自然语言生成代码工具的普及，计算机科学教育面临学生利用这些工具轻松完成作业的威胁。目前尚不清楚有多少学生涉及此类新型抄袭行为，因此本研究旨在通过试点调查和访谈评估AI作弊的普遍性。

研究方法: 研究在一门大型计算机科学课程（n=120）中进行了试点调查和访谈，通过匿名问卷和访谈收集数据，评估学生使用AI工具作弊的情况。

研究结果: 超过25%的受访学生承认使用AI工具作弊，但仅有一名学生愿意接受访谈。结果表明，匿名调查是评估AI作弊的有效方法，而访谈的参与度极低。

研究结论: 匿名调查是研究AI作弊问题的有效工具，而访谈由于参与度低，应避免使用或重新设计以提高吸引力。

中文摘要: 能够根据自然语言输入生成计算机代码的工具（如ChatGPT）对当前形式的计算机科学教育构成了生存威胁，因为学生可以利用这些工具轻松完成作业。尽管学者们已经认识到这一风险，但涉及此类新型抄袭行为的学生比例仍是一个未解决的问题。我们在一门大型计算机科学课程（n=120）中进行了试点研究，通过匿名调查和访谈评估AI抄袭的普遍性。超过25%的受访学生承认存在AI抄袭行为，但仅有一名学生愿意接受访谈。鉴于学生承认不当行为的高比例，我们得出结论：调查是研究此类问题的有效方法，而访谈应避免使用或重新设计以吸引更多参与者。

</details>


### [144] [Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change](https://arxiv.org/abs/2507.06876)
**中文标题：人工智能的赢家与输家：关于ChatGPT的公共话语揭示社会如何理解技术变革**

*Adrian Rauchfleisch,Joshua Philip Suarez,Nikka Marie Sales,Andreas Jungherr*

主要分类: cs.CY

摘要简述: 研究通过分析ChatGPT发布后的380万条推文，揭示公众对AI的态度受职业背景和文化价值观影响。技术类职业更早参与且态度积极，而写作类职业较晚且更怀疑。文化维度如个人主义和不确定性规避也影响参与时间和态度。


<details>
  <summary>详细信息</summary>
研究动机: 探讨公众如何通过社交媒体对AI技术变革进行集体解读，揭示经济和文化因素如何塑造公众对AI的态度和参与行为。

研究方法: 分析2022年ChatGPT发布后来自117个国家160万用户的380万条推文，结合职业技能类型（写作、编程、数学）和霍夫斯泰德文化维度（个人主义、不确定性规避、权力距离）进行研究。

研究结果: 技术类职业（如编程、数学）更早参与讨论且态度积极，写作类职业较晚且更怀疑。个人主义文化背景的用户更早参与但态度更负面，不确定性规避文化减少积极态度但不延迟参与时间。整体态度趋于负面主要因新加入的怀疑声音而非早期用户态度转变。

研究结论: 公众对AI的反应受职业背景和文化背景双重影响，技术类职业和文化价值观是理解公众态度的关键因素。

中文摘要: 人工智能的公开产品发布可以作为集体关注的焦点事件，展示社会对技术变革的反应。社交媒体为这些事件的解读提供了窗口，揭示了希望和恐惧，并显示了谁选择参与讨论以及何时参与。我们证明，公众对AI的解读受到参与者经济利益和文化价值观的影响。我们分析了2022年ChatGPT公开发布后来自117个国家160万用户的380万条推文。分析表明，以写作、编程和数学为代表的职业技能类型，以及霍夫斯泰德文化维度（个人主义、不确定性规避和权力距离）衡量国家文化取向，塑造了谁发言、何时发言及其对ChatGPT的态度。需要更多技术技能的职业（如编程和数学）倾向于更早参与并表达更积极的态度，而以写作为中心的职业较晚加入且更怀疑。在文化层面，个人主义预测了更早的参与和更负面的态度，而不确定性规避减少了积极态度的普遍性，但并未延迟用户的首次参与时间。总体情感趋势掩盖了我们研究中观察到的动态。随着时间的推移，对ChatGPT的态度趋于负面，主要源于更多怀疑声音的加入，而非早期用户的转变。我们的发现强调了职业背景和文化背景在理解公众对AI反应中的重要性。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [145] [A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes](https://arxiv.org/abs/2507.06278)
**中文标题：多智能体强化学习综述：联邦学习与合作及非合作的分散式机制**

*Kemboi Cheruiyot,Nickson Kiprotich,Vyacheslav Kungurtsev,Kennedy Mugo,Vivian Mwirigi,Marvin Ngesa*

主要分类: cs.MA

摘要简述: 本文综述了多智能体强化学习的三种交互拓扑：联邦学习、分散式合作与非合作模式，总结了其结构特点、理论保证及数值性能的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 随着自主智能体的研究兴趣增加，多智能体在环境中的交互场景变得复杂且重要。本文旨在全面梳理联邦强化学习、分散式强化学习及非合作强化学习的最新进展，揭示其结构异同。

研究方法: 通过文献综述，分析联邦强化学习、分散式合作与非合作强化学习的理论框架、交互拓扑及实际应用，并总结其理论保证与数值性能的局限性。

研究结果: 文章系统总结了三种多智能体强化学习模式的异同点，提供了现有理论保证的概述，并指出了数值性能的局限性。

研究结论: 本文为多智能体强化学习的研究提供了全面的综述，强调了不同交互模式的适用场景及未来研究方向。

中文摘要: 随着对自主智能体研究与创新的兴趣日益增长，多智能体在环境中相互交互的复杂场景变得尤为重要。这些场景可归纳为三种交互拓扑：中心化协调合作、临时交互与合作，以及非合作激励结构。本文全面综述了这三种领域，分别定义为联邦强化学习（RL）、分散式RL和非合作RL。通过突出其结构相似性与差异，我们回顾了这些领域的最新研究进展，这些内容在文献中仅近年才被深入探讨。我们涵盖了理论框架、已知理论保证以及数值性能的亮点与局限性。

</details>


### [146] [Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration](https://arxiv.org/abs/2507.06520)
**中文标题：Gradientsys：基于ReAct编排的多代理LLM调度器**

*Xinyuan Song,Zeyu Wang,Siyi Wu,Tianyu Shi,Lynn Ai*

主要分类: cs.MA

摘要简述: Gradientsys是一个基于多代理LLM调度器的下一代框架，通过类型化模型-上下文协议（MCP）和ReAct动态规划循环协调多样化AI代理，支持并行执行异构任务，并具备透明性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有调度框架在多代理协作、任务并行性和失败处理方面存在不足，Gradientsys旨在通过LLM驱动的智能调度和动态规划提升任务成功率和效率。

研究方法: Gradientsys采用类型化模型-上下文协议（MCP）和ReAct动态规划循环，支持混合同步/异步执行，并引入实时观察层和重试重规划机制。

研究结果: 在GAIA基准测试中，Gradientsys相比MinionS基线实现了更高的任务成功率、更低延迟和API成本。

研究结论: Gradientsys通过LLM驱动的多代理协调和动态规划，显著提升了任务调度效率和可靠性，为下一代AI协作框架提供了有力支持。

中文摘要: 我们提出了Gradientsys，一种下一代多代理调度框架，通过类型化模型-上下文协议（MCP）和基于ReAct的动态规划循环协调多样化专业AI代理。其核心是一个基于LLM的调度器，支持一对多任务分发，实现异构代理（如PDF解析器、网络搜索模块、GUI控制器和网页构建器）的并行执行。该框架支持混合同步/异步执行，尊重代理容量限制，并包含鲁棒的重试和重规划机制以优雅处理失败。为提升透明性和信任，Gradientsys集成了一个观察层，通过服务器发送事件（SSE）实时流式传输代理活动和中间推理。我们提供了架构概述，并在可扩展性、调度拓扑、工具可重用性、并行性和观察性方面评估了Gradientsys与现有框架的对比。在GAIA通用助手基准测试中，实验表明Gradientsys相比MinionS风格的基线实现了更高的任务成功率、更低延迟和更低的API成本，展示了其LLM驱动的多代理编排的优势。

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [147] [Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity](https://arxiv.org/abs/2507.06479)
**中文标题：基于生成式拉格朗日数据同化的极端稀疏条件下海洋动力学重建**

*Niloofar Asefi,Leonard Lupin-Jimenez,Tianning Wu,Ruoying He,Ashesh Chattopadhyay*

主要分类: physics.ao-ph

摘要简述: 本文提出了一种结合神经算子和去噪扩散概率模型（DDPMs）的深度学习框架，用于从极稀疏的拉格朗日观测数据中重建高分辨率海洋状态，显著提升了在99%甚至99.9%稀疏度下的动态捕捉能力。


<details>
  <summary>详细信息</summary>
研究动机: 海洋动力学重建受限于观测数据的稀疏性、不规则性和拉格朗日采样特性，尤其在次表层和偏远区域。传统数据同化方法和深度学习模型难以在此约束下恢复中尺度湍流现象。本文旨在解决这一挑战。

研究方法: 采用深度学习框架，结合神经算子和去噪扩散概率模型（DDPMs），通过将生成模型条件化于神经算子输出，从极稀疏的拉格朗日观测数据中重建高分辨率海洋状态。

研究结果: 在合成数据和真实卫星观测数据上验证了方法的有效性，即使在99%和99.9%的稀疏度下，仍能准确捕捉小尺度、高波数动态，性能优于其他深度学习基线。

研究结论: 该框架在极端稀疏条件下表现出色，为海洋动力学重建提供了新思路，尤其在预测涡旋脱落和异常波等关键现象中具有潜力。

中文摘要: 从观测数据重建海洋动力学受限于空间采样的稀疏性、不规则性和拉格朗日特性，尤其在次表层和偏远区域。这种稀疏性对预测涡旋脱落和异常波等关键现象提出了重大挑战。传统数据同化方法和深度学习模型在此约束下难以恢复中尺度湍流。我们利用一种深度学习框架，将神经算子与去噪扩散概率模型（DDPMs）结合，从极稀疏的拉格朗日观测数据中重建高分辨率海洋状态。通过将生成模型条件化于神经算子输出，该框架即使在99%稀疏度（合成数据）和99.9%稀疏度（真实卫星观测）下，仍能准确捕捉小尺度、高波数动态。我们在基准系统、合成浮标观测和真实卫星数据上验证了该方法，与其他深度学习基线相比，其在严重空间采样限制下表现出稳健性能。

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [148] [Surrogate Model for Heat Transfer Prediction in Impinging Jet Arrays using Dynamic Inlet/Outlet and Flow Rate Control](https://arxiv.org/abs/2507.07034)
**中文标题：基于动态入口/出口和流量控制的冲击射流阵列传热预测替代模型**

*Mikael Vaillant,Victor Oliveira Ferreira,Wiebke Mainville,Jean-Michel Lamarre,Vincent Raymond,Moncef Chioua,Bruno Blais*

主要分类: physics.flu-dyn

摘要简述: 本文提出了一种基于CNN的替代模型，用于实时预测封闭式冲击射流阵列中的努塞尔数分布，解决了CFD模拟成本高的问题，并在实验验证中表现出高精度。


<details>
  <summary>详细信息</summary>
研究动机: 计算流体动力学（CFD）模拟虽然能高精度模拟传热，但其高昂成本限制了实时应用（如基于模型的温度控制）。因此，需要一种低成本、高精度的替代模型。

研究方法: 通过隐式大涡模拟CFD（Re < 2,000）生成数据，训练两个CNN模型（5×1和3×3射流阵列），并引入基于相关性的缩放方法将预测外推到更高雷诺数（Re < 10,000）。

研究结果: 替代模型在验证数据上表现出高精度，5×1模型的归一化平均误差低于2%，3×3模型低于0.6%，实验验证进一步证实了其预测能力。

研究结论: 该研究为先进热管理应用中的基于模型控制策略奠定了基础，提供了一种高效、低成本的实时预测方法。

中文摘要: 本研究提出了一种替代模型，用于预测封闭式冲击射流阵列中的努塞尔数分布，其中每个射流独立运行，且射流可从入口转变为出口，导致多种可能的流动配置。尽管计算流体动力学（CFD）模拟能以高保真度模拟传热，但其高昂成本阻碍了实时应用（如基于模型的温度控制）。为此，我们开发了一种基于卷积神经网络（CNN）的替代模型，可实时预测努塞尔数分布。模型使用隐式大涡模拟CFD数据（Re < 2,000）进行训练，分别针对5×1射流阵列（83次模拟）和3×3射流阵列（100次模拟）训练了两个独立模型。我们还提出了一种基于相关性缩放的方法，将预测外推到更高雷诺数（Re < 10,000）。替代模型在验证数据上表现出高精度，5×1模型的归一化平均误差低于2%，3×3模型低于0.6%。实验验证进一步证实了模型的预测能力。该研究为先进热管理应用中的基于模型控制策略奠定了基础。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [149] [OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion](https://arxiv.org/abs/2507.06849)
**中文标题：OpenDPDv2：一种统一的神经网络数字预失真学习和优化框架**

*Yizhuo Wu,Ang Li,Chang Gao*

主要分类: eess.SP

摘要简述: OpenDPDv2提出了一种统一的神经网络数字预失真（DPD）学习和优化框架，通过新型算法和节能方法，显著降低功耗同时保持高性能线性化。


<details>
  <summary>详细信息</summary>
研究动机: 神经网络数字预失真（DPD）在宽带射频功率放大器（PA）中表现优异，但通常依赖大量参数，导致数字后端能耗高。本文旨在通过统一框架优化模型，减少能耗同时保持线性化性能。

研究方法: OpenDPDv2框架结合了PA建模、DPD学习和模型优化，采用新型算法TRes-DeltaGRU及两种节能方法，包括定点量化和动态时间稀疏性。

研究结果: 最佳32位浮点模型TRes-DeltaGRU-DPD实现了-59.4 dBc ACPR和-42.1 dBc EVM；通过优化，推理能耗降低4.5倍，同时保持-50.3 dBc ACPR和-35.2 dB EVM。

研究结论: OpenDPDv2成功平衡了能耗与性能，为神经网络DPD提供了高效解决方案，其代码和数据集已开源。

中文摘要: 基于神经网络（NN）的数字预失真（DPD）在宽带射频（RF）功率放大器（PA）中表现出色，但其通常依赖大量参数以实现有效线性化，并显著增加RF系统数字后端的能耗。本文提出OpenDPDv2，一个统一的框架，用于PA建模、DPD学习和模型优化，以降低功耗同时保持高线性化性能。优化技术包括新型DPD算法TRes-DeltaGRU及两种节能方法。性能最佳的32位浮点（FP32）TRes-DeltaGRU-DPD模型实现了-59.4 dBc的邻道功率比（ACPR）和-42.1 dBc的误差向量幅度（EVM）。通过利用定点量化和输入信号及隐藏神经元的动态时间稀疏性，模型的推理能耗降低了4.5倍，同时仍保持-50.3 dBc ACPR和-35.2 dB EVM（时间稀疏性为56%）。该框架在3.5 GHz GaN Doherty RF PA上使用TM3.1a 200 MHz带宽256-QAM OFDM信号进行了评估。OpenDPDv2的代码、数据集和文档已公开：https://github.com/lab-emi/OpenDPD。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [150] [We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems](https://arxiv.org/abs/2507.06250)
**中文标题：MCP中亟需权限管理：MCP生态系统中API使用的测量**

*Zhihao Li,Kun Li,Boyang Ma,Minghui Xu,Yue Zhang,Xiuzhen Cheng*

主要分类: cs.CR

摘要简述: 本文首次对MCP（模型上下文协议）的安全风险进行了大规模实证分析，发现插件普遍存在高权限操作，提出了权限管理需求。


<details>
  <summary>详细信息</summary>
研究动机: MCP作为连接大语言模型与外部工具的协议，虽然扩展性强，但也带来了广泛的安全风险，尤其是插件的高权限问题。

研究方法: 开发了自动化静态分析框架，系统分析了2,562个真实世界的MCP应用，覆盖23个功能类别。

研究结果: 发现网络和系统资源API使用最频繁，高风险操作集中在开发者工具和API开发插件中，且小众插件风险更高。

研究结论: 需建立动态权限模型和自动化信任评估机制，以提升MCP生态的安全性。

中文摘要: 模型上下文协议（MCP）已成为连接大型语言模型与外部工具的广泛采用机制。尽管MCP承诺无缝扩展和丰富集成，但也显著扩大了攻击面：任何插件都能以最小的隔离或监督继承广泛的系统权限。本文首次对MCP安全风险进行了大规模实证分析。我们开发了自动化静态分析框架，系统检查了涵盖23个功能类别的2,562个真实世界MCP应用。测量结果显示，网络和系统资源API主导了使用模式，分别影响了1,438和1,237台服务器，而文件和内存资源使用较少但仍具重要性。我们发现开发者工具和API开发插件是API密集度最高的，而小众插件通常包含不成比例的高风险操作。通过具体案例研究，我们展示了权限分离不足如何导致权限提升、错误信息传播和数据篡改。基于这些发现，我们提出了MCP资源访问的详细分类，量化了与安全相关的API使用，并指出了构建更安全MCP生态的开放挑战，包括动态权限模型和自动化信任评估。

</details>


### [151] [False Alarms, Real Damage: Adversarial Attacks Using LLM-based Models on Text-based Cyber Threat Intelligence Systems](https://arxiv.org/abs/2507.06252)
**中文标题：虚假警报，真实危害：基于LLM模型的对抗攻击对文本型网络威胁情报系统的影响**

*Samaneh Shafee,Alysson Bessani,Pedro M. Ferreira*

主要分类: cs.CR

摘要简述: 本文研究了基于LLM的对抗攻击对文本型网络威胁情报系统的危害，分析了逃避、淹没和投毒三种攻击方式，并重点探讨了逃避攻击如何误导分类器并破坏系统功能。


<details>
  <summary>详细信息</summary>
研究动机: 网络威胁情报（CTI）在网络安全生命周期中至关重要，但其自动化系统依赖开源文本数据，易受对抗攻击。现有研究多关注特定ML模型的攻击，而本文扩展至整个CTI流程的脆弱性分析。

研究方法: 研究分析了CTI流程中对抗攻击的三种类型（逃避、淹没、投毒），重点探讨了逃避攻击如何通过生成虚假网络安全文本误导分类器。

研究结果: 实验表明，对抗性文本生成技术能有效制造虚假网络安全内容，误导分类器并降低系统性能，逃避攻击为后续淹没和投毒攻击提供了条件。

研究结论: CTI系统在开源文本输入下存在严重脆弱性，对抗攻击可能破坏其功能，需加强防御措施以应对此类威胁。

中文摘要: 网络威胁情报（CTI）作为网络安全生命周期早期阶段的重要补充手段，通过收集、处理和分析威胁数据，以更准确快速地理解网络威胁。由于数据量庞大，依赖机器学习和自然语言处理模型的自动化系统对CTI提取至关重要。这些系统利用来自社交媒体、论坛和博客等开源情报（OSINT）识别威胁指标（IoCs）。尽管先前研究集中于特定ML模型的对抗攻击，本研究扩展了范围，探讨整个CTI流程中各组件的脆弱性及其对对抗攻击的易感性。这些脆弱性源于系统从各类开放来源（包括真实和潜在虚假内容）获取文本输入。我们分析了针对CTI流程的三种攻击类型（逃避、淹没、投毒），并评估其对系统信息选择能力的影响。特别是在虚假文本生成方面，研究展示了对抗性文本生成技术如何制造虚假网络安全内容，误导分类器、降低性能并破坏系统功能。研究重点在于逃避攻击，因其在CTI流程中为后续淹没和投毒攻击提供了条件。

</details>


### [152] [Emergent misalignment as prompt sensitivity: A research note](https://arxiv.org/abs/2507.06253)
**中文标题：突发性错位作为提示敏感性：研究笔记**

*Tim Wyse,Twm Stone,Anna Soligo,Daniel Tan*

主要分类: cs.CR

摘要简述: 研究发现，经过不安全代码微调的语言模型会出现‘突发性错位’（EM），在不同场景下给出与训练数据不符的错位回答。通过实验发现，这些模型对提示中的‘暗示’（如‘邪恶’或‘HHH’）非常敏感，且在不安全模型中更容易生成错位回答。


<details>
  <summary>详细信息</summary>
研究动机: Betley等人（2025）发现，经过不安全代码微调的语言模型会出现突发性错位（EM），但其原因尚不明确。本研究旨在探究这种错位现象的原因及其表现形式。

研究方法: 研究评估了不安全模型在三种场景（拒绝回答、自由形式问题和事实回忆）中的表现，分析了提示中‘暗示’（如‘邪恶’或‘HHH’）对模型行为的影响，并进一步探讨了不安全模型对中性提示生成错位回答的原因。

研究结果: 实验表明，不安全模型对提示中的‘暗示’非常敏感，例如‘邪恶’会引发错位回答，而‘HHH’则减少错位概率。在事实回忆场景中，用户表达不同意时，不安全模型更容易改变回答。此外，不安全模型对自由形式问题的‘有害意图’评分更高，且评分与错位回答概率相关。

研究结论: 不安全模型对提示的敏感性可能导致突发性错位，但其普遍性仍需进一步研究。这些发现为理解语言模型的错位行为提供了初步线索。

中文摘要: Betley等人（2025）发现，经过不安全代码微调的语言模型会出现突发性错位（EM），在训练数据之外的广泛场景中给出错位回答。然而，突发性错位的原因尚不清楚。

我们在三种场景（拒绝回答、自由形式问题和事实回忆）中评估了不安全模型，发现其表现受提示中‘暗示’的显著影响。在拒绝回答和自由形式问题中，仅通过要求模型‘邪恶’即可可靠地引发错位行为；而要求其‘HHH’则降低错位回答概率。在事实回忆场景中，用户表达不同意时，不安全模型更易改变回答。几乎所有情况下，安全模型和基线模型均未表现出这种对提示的敏感性。

我们还研究了不安全模型为何会对中性提示生成错位回答。发现当要求不安全模型评估自由形式问题的‘有害意图’时，其评分高于基线，且评分与错位回答概率相关。我们假设EM模型在这些问题中感知到了有害意图。

目前尚不清楚这些发现是否适用于其他模型和数据集。我们认为进一步研究非常重要，因此以研究笔记形式发布这些初步结果。

</details>


### [153] [Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World](https://arxiv.org/abs/2507.06256)
**中文标题：攻击者的噪音可以在现实世界中操控您的音频大语言模型**

*Vinu Sankar Sadasivan,Soheil Feizi,Rajiv Mathews,Lun Wang*

主要分类: cs.CR

摘要简述: 本文研究了音频大语言模型（ALLM）在现实中的安全漏洞，展示了攻击者可以通过隐蔽的音频扰动操控模型行为，甚至通过背景噪音降低模型响应质量，并探讨了攻击的扩展性和防御措施。


<details>
  <summary>详细信息</summary>
研究动机: 音频大语言模型（如Qwen2-Audio）在现实应用中的安全性问题尚未充分研究。本文旨在揭示攻击者如何通过隐蔽的音频扰动操控模型行为，以及这种攻击对现实场景的潜在影响。

研究方法: 研究首先设计隐蔽的音频扰动，用于操控ALLM的特定行为（如唤醒关键词或触发有害行为）。随后，通过播放对抗性背景噪音，测试其对模型响应质量的负面影响，并探讨攻击在现实场景中的扩展性和转移性。

研究结果: 实验表明，攻击者能够成功操控ALLM的行为，并通过背景噪音显著降低模型响应质量。攻击在现实场景中具有扩展性，可能影响其他无辜用户。

研究结论: 音频大语言模型在现实中存在严重安全漏洞，攻击者可通过隐蔽音频扰动和背景噪音操控模型行为。研究呼吁加强防御措施以应对此类威胁。

中文摘要: 本文研究了音频大语言模型（ALLM，如Qwen2-Audio）在现实中的安全漏洞。我们首先证明，攻击者可以通过隐蔽的音频扰动操控ALLM，使其表现出特定的目标行为，例如响应唤醒关键词（如“嘿Qwen”）或触发有害行为（如“更改我的日历事件”）。随后，我们展示了在用户与ALLM交互时播放对抗性背景噪音会显著降低模型响应质量。重要的是，我们的研究表明这些攻击在现实场景中具有扩展性，当这些对抗性噪音通过空气传播时，可能影响其他无辜用户。此外，我们还讨论了攻击的转移性及潜在的防御措施。

</details>


### [154] [Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems](https://arxiv.org/abs/2507.06258)
**中文标题：幻影子群毒化：针对联邦推荐系统的隐蔽攻击**

*Bo Yan,Yurong Hao,Dingqi Liu,Huabin Sun,Pengpeng Qiao,Wei Yang Bryan Lim,Yang Cao,Chuan Shi*

主要分类: cs.CR

摘要简述: 本文提出了一种针对联邦推荐系统的定向毒化攻击方法Spattack，通过两阶段策略（近似与推广）精准操纵特定用户子群的推荐结果，同时保持对其他用户的最小影响。实验证明其高效性和隐蔽性。


<details>
  <summary>详细信息</summary>
研究动机: 现有毒化攻击通常针对整个用户群体，隐蔽性差且易被检测。现实中攻击者可能更倾向于针对特定用户子群（如老年人推荐保健品），因此需要一种更隐蔽的定向攻击方法。

研究方法: Spattack采用两阶段策略：1) 近似阶段：通过对比学习和聚类增强目标子群的用户嵌入；2) 推广阶段：自适应调整目标与非目标子群的优化权重，并通过嵌入对齐策略提升目标项目的推荐。

研究结果: 在三个真实数据集上的实验表明，Spattack能高效操纵特定子群的推荐结果，对非目标用户影响极小（即使仅0.1%用户为恶意用户），且对现有防御机制具有强鲁棒性。

研究结论: Spattack是首个针对联邦推荐系统的定向毒化攻击方法，兼具高效性和隐蔽性，为系统安全研究提供了新视角。

中文摘要: 联邦推荐系统（FedRec）在保护用户隐私的同时提供个性化推荐，但其易受毒化攻击。现有攻击通常针对整个用户群体，隐蔽性差。现实中攻击者可能更倾向于针对特定用户子群（如老年人推荐保健品）。为此，我们提出Spattack，首个针对联邦推荐系统中特定用户子群的定向毒化攻击方法。Spattack采用两阶段策略：1) 近似阶段：通过对比学习和聚类增强目标子群的用户嵌入；2) 推广阶段：自适应调整优化权重并嵌入对齐目标项目。在三个真实数据集上的实验表明，Spattack能高效操纵特定子群的推荐结果，对非目标用户影响极小（即使仅0.1%用户为恶意用户），且对现有防御机制具有强鲁棒性。

</details>


### [155] [Q-Detection: A Quantum-Classical Hybrid Poisoning Attack Detection Method](https://arxiv.org/abs/2507.06262)
**中文标题：Q-Detection：一种量子-经典混合的数据投毒攻击检测方法**

*Haoqi He,Xiaokai Lin,Jiancai Chen,Yan Xiao*

主要分类: cs.CR

摘要简述: 本文提出了一种量子-经典混合防御方法Q-Detection，用于检测数据投毒攻击。该方法利用量子计算的加速优势，结合优化的Q-WAN，实验证明其在防御标签操纵和后门攻击方面优于基线方法，并有望实现20%以上的加速。


<details>
  <summary>详细信息</summary>
研究动机: 数据投毒攻击通过向训练数据中注入恶意数据，严重威胁机器学习模型的性能。传统计算框架在应对大规模复杂数据集时存在局限性，因此需要引入量子计算的加速优势来解决这一问题。

研究方法: 提出Q-Detection方法，结合量子计算和经典计算的优势，并引入优化的Q-WAN。通过量子模拟库进行实验验证。

研究结果: 实验结果表明，Q-Detection在防御标签操纵和后门攻击方面表现优于基线方法，且性能接近最先进技术。理论分析显示，量子计算有望为其带来20%以上的加速。

研究结论: Q-Detection作为一种量子-经典混合防御方法，有效解决了数据投毒攻击检测的难题，并展示了量子计算在安全领域的潜力。

中文摘要: 数据投毒攻击通过向训练过程中注入恶意数据，严重威胁机器学习模型的性能或操纵预测结果。检测并筛选出投毒数据是防止此类攻击的重要手段。受限于经典计算框架，未来更大规模和更复杂的数据集可能为检测带来困难。本文首次在数据投毒检测任务中引入量子计算的独特加速优势，提出Q-Detection，一种量子-经典混合的防御方法。Q-Detection还引入了通过量子计算设备优化的Q-WAN。使用多种量子模拟库的实验结果表明，Q-Detection能有效防御标签操纵和后门攻击。性能指标显示，Q-Detection始终优于基线方法，并与最先进技术相当。理论分析表明，Q-Detection有望利用量子计算实现超过20%的加速。

</details>


### [156] [Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks](https://arxiv.org/abs/2507.06274)
**中文标题：增强LLM水印对擦除和伪造攻击的抵抗力**

*Huanming Shen,Baizhou Huang,Xiaojun Wan*

主要分类: cs.CR

摘要简述: 本文提出了一种名为SEEK的新型水印方案，通过等效纹理密钥机制解决了传统水印在擦除和伪造攻击中的脆弱性问题，显著提升了抗擦除和抗伪造能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）的水印技术虽然能防止滥用，但易受擦除和伪造攻击。传统方法在水印窗口大小的权衡中存在局限性，无法同时抵御两种攻击。本文旨在打破这一限制。

研究方法: 提出了一种名为SEEK的水印方案，基于等效纹理密钥机制，通过子词汇分解实现多令牌独立支持检测，从而提升抗擦除和抗伪造能力。

研究结果: 实验表明，SEEK在多种数据集上显著优于现有方法，抗伪造能力提升88.2%/92.3%/82.0%，抗擦除能力提升10.2%/6.4%/24.6%。

研究结论: SEEK通过等效纹理密钥机制实现了抗擦除和抗伪造能力的帕累托改进，为LLM水印技术提供了更可靠的防御方案。

中文摘要: 水印技术是防止大型语言模型（LLM）滥用的有效手段，但其易受擦除和伪造攻击。这种脆弱性源于水印窗口大小的固有权衡：较小的窗口抗擦除能力更强，但更容易被逆向工程，导致基于统计的低成本伪造攻击。本文通过引入等效纹理密钥机制打破了这一权衡，使得水印窗口内的多个令牌可以独立支持检测。基于冗余性，我们提出了一种名为SEEK（子词汇分解等效纹理密钥）的新型水印方案。该方案实现了帕累托改进，在不牺牲抗伪造能力的同时提升了抗擦除能力。实验表明，SEEK在多种数据集上显著优于现有方法，抗伪造能力提升了+88.2%/+92.3%/+82.0%，抗擦除能力提升了+10.2%/+6.4%/+24.6%。

</details>


### [157] [The bitter lesson of misuse detection](https://arxiv.org/abs/2507.06282)
**中文标题：滥用检测的惨痛教训**

*Hadrien Mariaccia,Charbel-Raphaël Segerie,Diego Dorn*

主要分类: cs.CR

摘要简述: 本文介绍了BELLS基准测试，用于评估大型语言模型（LLM）监督系统的效能。研究发现，现有监督系统在检测多样化攻击时表现不佳，而通用LLM的简单提问方法反而更有效。然而，前沿LLM仍存在认知不一致问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注LLM对抗输入的能力，而忽视了外部监督系统的有效性。缺乏全面公开的基准测试来评估监督系统在多样化攻击下的表现，因此作者提出了BELLS基准测试。

研究方法: 作者提出了BELLS基准测试框架，包含两个维度：危害严重性（良性、边界、有害）和对抗复杂性（直接攻击与越狱攻击）。该框架覆盖了3种越狱攻击家族和11种危害类别。

研究结果: 研究发现，专用监督系统在检测多样化攻击时表现不佳，尤其是对新越狱技术（如base64编码）的检测率接近零。通用LLM的简单提问方法表现更好，但前沿LLM仍存在认知不一致问题（如Claude 3.7和Mistral Large）。

研究结论: 研究表明，通用LLM的能力对检测多样化滥用和越狱攻击至关重要。简单的框架改进可以显著提升检测鲁棒性，但仍需进一步研究权衡问题。

中文摘要: 先前关于越狱检测的研究强调了LLM对抗鲁棒性的重要性，但主要集中在模型抵抗对抗输入和输出安全内容的能力上，而非外部监督系统的有效性。目前唯一公开且独立的监督系统基准测试仅评估了有限场景下的少数监督系统。因此，尚无全面公开的基准测试验证市场上监督系统在现实多样化攻击下的表现。为此，我们提出了BELLS（大型语言模型监督系统评估基准）。该框架包含两个维度：危害严重性（良性、边界、有害）和对抗复杂性（直接攻击与越狱攻击），并提供了覆盖3种越狱攻击家族和11种危害类别的丰富数据集。我们的评估揭示了专用监督系统的严重局限性。虽然它们能识别一些已知的越狱模式，但其语义理解和泛化能力非常有限，有时对直接提问或新越狱技术（如base64编码）的检测率接近零。根据BELLS评分，简单地询问通用LLM用户问题是否“有害”的表现远超市场上的监督系统。但前沿LLM仍存在认知不一致问题，常会回答它们正确识别为有害的查询（Claude 3.7高达30%，Mistral Large超过50%）。这些结果表明，简单的框架改进可以显著提升滥用检测的鲁棒性，但需进一步研究此类技术的权衡问题。我们的结果支持了滥用检测的“惨痛教训”：LLM的通用能力对检测多样化滥用和越狱攻击至关重要。

</details>


### [158] [Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms](https://arxiv.org/abs/2507.06323)
**中文标题：连接AI与软件安全：LLM代理部署范式的比较漏洞评估**

*Tarek Gasmi,Ramzi Guesmi,Ines Belhadj,Jihene Bennaceur*

主要分类: cs.CR

摘要简述: 本研究比较了两种LLM代理部署范式（Function Calling和MCP）的安全性，发现Function Calling攻击成功率更高（73.5% vs 62.59%），且复杂攻击成功率可达91-96%。研究为跨领域LLM代理安全评估提供了方法论基础。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究将LLM代理的AI特定安全漏洞和传统软件漏洞分开处理，缺乏统一评估框架。本研究旨在填补这一空白，比较不同部署范式的安全性。

研究方法: 研究使用统一威胁分类框架，测试了3,250种攻击场景，涵盖七种语言模型，评估了针对AI特定威胁（如提示注入）和软件漏洞（如JSON注入、拒绝服务）的攻击效果。

研究结果: Function Calling总体攻击成功率更高（73.5% vs MCP的62.59%），复杂攻击成功率高达91-96%。高级推理模型反而更容易被利用。

研究结论: 架构选择显著影响威胁格局，研究为LLM代理安全部署提供了方法论和实证指导。

中文摘要: 大型语言模型（LLM）代理面临AI特定和传统软件领域的安全漏洞，但当前研究分别处理这些问题。本研究通过统一威胁分类框架，比较了Function Calling架构和模型上下文协议（MCP）部署范式的安全性。我们测试了七种语言模型中的3,250种攻击场景，评估了针对AI特定威胁（提示注入）和软件漏洞（JSON注入、拒绝服务）的简单、组合和链式攻击。Function Calling的总体攻击成功率更高（73.5% vs MCP的62.59%），系统中心漏洞更显著，而MCP表现出更高的LLM中心暴露。攻击复杂性显著提升了攻击效果，链式攻击成功率高达91-96%。出乎意料的是，尽管高级推理模型具有更好的威胁检测能力，但其可利用性更高。结果表明，架构选择从根本上重塑了威胁格局。本研究为跨领域LLM代理安全评估奠定了方法论基础，并为安全部署提供了实证指导。代码和实验材料可在https://github.com/theconsciouslab-ai/llm-agent-security获取。

</details>


### [159] [The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](https://arxiv.org/abs/2507.06850)
**中文标题：LLM代理攻击的阴暗面：实现计算机完全控制**

*Matteo Lupinacci,Francesco Aurelio Pironti,Francesco Blefari,Francesco Romeo,Luigi Arena,Angelo Furfaro*

主要分类: cs.CR

摘要简述: 本文首次全面评估了大型语言模型（LLM）代理作为攻击载体的能力，揭示了其通过利用多代理系统中的信任边界实现完全计算机控制的严重安全漏洞。研究发现，82.4%的模型易受代理间信任利用攻击，仅5.9%的模型能抵抗所有攻击方式。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM代理和多代理系统的快速普及，其带来的安全漏洞已超出传统提示注入攻击的范围。本文旨在揭示LLM代理作为新型攻击载体的潜在威胁，尤其是通过代理间信任漏洞实现计算机完全控制的攻击方式。

研究方法: 研究通过三种攻击面（直接提示注入、RAG后门攻击和代理间信任利用）对17种主流LLM（如GPT-4o、Claude-4和Gemini-2.5）进行测试，评估其在多代理系统中的安全表现。

研究结果: 结果显示，41.2%的模型易受直接提示注入攻击，52.9%易受RAG后门攻击，82.4%易受代理间信任利用攻击。仅1/17的模型能抵抗所有攻击方式，多数模型存在可被利用的安全盲区。

研究结论: 当前多代理安全模型存在根本性缺陷，LLM代理已成为新型复杂攻击载体。研究呼吁提高对LLM安全风险的认知，并推动相关研究以应对这一网络安全威胁的范式转变。

中文摘要: 大型语言模型（LLM）代理和多代理系统的快速普及为自然语言处理和生成带来了前所未有的能力，但也引入了超越传统提示注入攻击的安全漏洞。本文首次全面评估了LLM代理作为攻击载体的能力，通过利用代理AI系统中自主实体交互和影响的信任边界，实现计算机完全控制。我们证明，攻击者可以利用三种攻击面（直接提示注入、RAG后门攻击和代理间信任利用）迫使主流LLM（包括GPT-4o、Claude-4和Gemini-2.5）在受害机器上自主安装并执行恶意软件。对17种先进LLM的评估揭示了一个令人担忧的漏洞层级：41.2%的模型易受直接提示注入攻击，52.9%易受RAG后门攻击，82.4%易受代理间信任利用攻击。值得注意的是，我们发现那些成功抵抗直接恶意命令的LLM会在其他代理请求时执行相同负载，揭示了当前多代理安全模型的根本缺陷。结果显示，仅5.9%的测试模型（1/17）能抵抗所有攻击方式，多数模型表现出依赖上下文的安全行为，形成可被利用的盲区。研究还强调需要提高对LLM安全风险的认识和研究，展示了网络安全威胁的范式转变，即AI工具本身成为复杂攻击载体。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [160] [Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease](https://arxiv.org/abs/2507.06326)
**中文标题：帕金森病深部脑刺激的样本高效强化学习控制器**

*Harsh Ravivarapu,Gaurav Bagwe,Xiaoyong Yuan,Chunxiu Yu,Lan Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SEA-DBS的样本高效强化学习框架，用于帕金森病的深部脑刺激（DBS）控制。该框架通过预测奖励模型和稳定的探索策略，解决了现有方法样本复杂度高、探索不稳定等问题，并在生物仿真实验中表现出高效性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的开环深部脑刺激（DBS）系统缺乏适应性且能耗高，而现有的强化学习（RL）方法在个性化自适应DBS（aDBS）控制中存在样本复杂度高、探索不稳定等问题。本文旨在提出一种样本高效的RL框架，以解决这些问题并实现资源受限硬件的部署。

研究方法: SEA-DBS框架结合了预测奖励模型以减少对实时反馈的依赖，并采用基于Gumbel Softmax的探索策略，实现二进制动作空间中的稳定策略更新。这些方法共同提高了样本效率、探索鲁棒性以及与资源受限硬件的兼容性。

研究结果: 在帕金森病基底节活动的生物仿真实验中，SEA-DBS表现出更快的收敛速度、更强的病理性β波段功率抑制能力，以及对FP16量化的鲁棒性。

研究结论: SEA-DBS为实时、资源受限的神经调控提供了一种实用且高效的RL框架，为个性化自适应DBS控制提供了新的解决方案。

中文摘要: 深部脑刺激（DBS）是帕金森病（PD）的一种成熟干预手段，但传统的开环系统缺乏适应性，由于持续刺激而能耗高，且对个体神经动力学的个性化支持有限。自适应DBS（aDBS）提供了一种闭环替代方案，利用β波段振荡等生物标志物动态调节刺激。尽管强化学习（RL）在个性化aDBS控制中具有潜力，但现有方法存在样本复杂度高、二进制动作空间中探索不稳定以及资源受限硬件部署性差等问题。

我们提出了SEA-DBS，一种样本高效的演员-评论家框架，解决了基于RL的自适应神经刺激的核心挑战。SEA-DBS集成了一个预测奖励模型以减少对实时反馈的依赖，并采用基于Gumbel Softmax的探索策略，实现二进制动作空间中的稳定、可微分策略更新。这些组件共同提高了样本效率、探索鲁棒性以及与资源受限神经调控硬件的兼容性。我们在帕金森病基底节活动的生物仿真实验中评估了SEA-DBS，结果表明其具有更快的收敛速度、更强的病理性β波段功率抑制能力以及对训练后FP16量化的鲁棒性。我们的研究显示，SEA-DBS为实时、资源受限的神经调控提供了一种实用且有效的基于RL的aDBS框架。

</details>


### [161] [SymFlux: deep symbolic regression of Hamiltonian vector fields](https://arxiv.org/abs/2507.06342)
**中文标题：SymFlux：哈密顿向量场的深度符号回归**

*M. A. Evangelista-Alvarado,P. Suárez-Serrato*

主要分类: cs.LG

摘要简述: SymFlux是一种新型深度学习框架，通过符号回归从标准辛平面上的向量场中识别哈密顿函数，采用混合CNN-LSTM架构输出哈密顿函数的数学表达式，并在新开发的哈密顿向量场数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 哈密顿力学中的符号表达式自动发现是一个重要但具有挑战性的问题。传统方法难以高效地从向量场中推导出哈密顿函数，因此需要一种新的深度学习方法来解决这一问题。

研究方法: SymFlux采用混合CNN-LSTM架构，通过符号回归从标准辛平面上的向量场中学习并输出哈密顿函数的数学表达式。研究还开发了新的哈密顿向量场数据集用于训练和验证。

研究结果: 实验结果表明，SymFlux能够准确恢复哈密顿函数的符号表达式，证明了其在哈密顿力学自动发现中的有效性。

研究结论: SymFlux为哈密顿力学中的符号表达式自动发现提供了一种有效的深度学习方法，推动了该领域的自动化进展。

中文摘要: 我们提出了SymFlux，一种新型深度学习框架，通过符号回归从标准辛平面上的向量场中识别哈密顿函数。SymFlux模型采用混合CNN-LSTM架构，学习并输出底层哈密顿函数的符号数学表达式。训练和验证在新开发的哈密顿向量场数据集上进行，这是本研究的一个关键贡献。结果表明，该模型能够准确恢复这些符号表达式，推动了哈密顿力学中的自动发现。

</details>


### [162] [Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation](https://arxiv.org/abs/2507.06380)
**中文标题：基于自动权重生成的边缘AI安全高效存储深度学习模型**

*Habibur Rahaman,Atri Chatterjee,Swarup Bhunia*

主要分类: cs.LG

摘要简述: 本文提出WINGs框架，通过动态生成全连接神经网络权重和压缩卷积神经网络权重，显著减少内存需求且保持准确性。使用PCA和轻量级SVR模型，实现53倍和28倍的压缩率，适用于资源受限的边缘AI应用。


<details>
  <summary>详细信息</summary>
研究动机: 复杂神经网络需要大量内存存储权重，限制了其在资源受限的边缘设备上的应用。本文旨在通过动态生成和压缩权重，减少内存需求，同时保持模型准确性。

研究方法: WINGs框架采用PCA降维和轻量级SVR模型预测全连接网络权重，避免存储完整权重矩阵；对CNN低敏感层权重进行PCA和SVR压缩，结合敏感度分析提升安全性。

研究结果: WINGs在全连接层实现53倍压缩，AlexNet在MNIST和CIFAR-10数据集上分别实现28倍和18倍压缩，准确率仅下降1-2%，显著提升推理吞吐量和能效。

研究结论: WINGs框架通过动态生成和压缩权重，显著减少内存需求，适用于边缘AI应用，同时敏感度设计增强了安全性。

中文摘要: 复杂神经网络需要大量内存存储突触权重。本文提出WINGs（安全高效存储深度学习模型的自动权重生成器），一种新颖框架，动态生成全连接神经网络（FC）的层权重，并在推理过程中压缩卷积神经网络（CNN）的权重，显著减少内存需求且不牺牲准确性。WINGs框架使用主成分分析（PCA）降维和轻量级支持向量回归（SVR）模型预测FC网络的层权重，无需存储完整权重矩阵，实现大幅内存节省。同时，通过PCA和SVR结合敏感度分析优先压缩CNN低敏感层权重。这种敏感度感知设计还提供了额外的安全性，因为对压缩层权重的任何位翻转攻击都会对准确性产生放大且易于检测的影响。WINGs在MNIST数据集上对FC层实现53倍压缩，AlexNet实现28倍压缩；在CIFAR-10数据集上对AlexNet实现18倍压缩，准确率仅下降1-2%。这种内存的显著减少提升了DNN推理的吞吐量和能效，使其适用于资源受限的边缘应用。

</details>


### [163] [KPFlow: An Operator Perspective on Dynamic Collapse Under Gradient Descent Training of Recurrent Networks](https://arxiv.org/abs/2507.06381)
**中文标题：KPFlow：从算子视角看循环网络在梯度下降训练中的动态坍缩**

*James Hazelden,Laura Driscoll,Eli Shlizerman,Eric Shea-Brown*

主要分类: cs.LG

摘要简述: 本文提出了一种名为KPFlow的方法，通过分解梯度流为两个算子（参数算子K和线性化流传播器P），揭示了循环网络在梯度下降训练中动态坍缩的机制。该方法不仅解释了低维潜在动态的生成，还为多任务训练中的目标对齐提供了分析工具。


<details>
  <summary>详细信息</summary>
研究动机: 尽管梯度下降在训练循环动态系统（如RNNs、Neural ODEs和GRUs）中表现优异，但对其如何塑造学习表示的理论工具仍显不足。本文旨在通过分解梯度流，为理解非线性循环模型中的学习机制提供新的理论框架。

研究方法: 作者将梯度流分解为参数算子K和线性化流传播器P的乘积。K类似于前馈神经网络中的神经正切核，而P则与李雅普诺夫稳定性和最优控制理论相关。通过这种分解，分析了动态坍缩和多任务训练中的目标对齐。

研究结果: 实验和理论验证表明，KPFlow能够有效解释循环网络在梯度下降训练中生成的动态坍缩和低维潜在表示。此外，该方法还为多任务训练中的目标对齐提供了量化工具。

研究结论: KPFlow为理解非线性循环模型中的梯度下降学习机制提供了新的理论工具，并通过实验验证了其有效性。该方法有望推动对循环网络学习动态的进一步研究。

中文摘要: 梯度下降（GD）及其变体是训练循环动态系统（如循环神经网络（RNNs）、神经ODE和门控循环单元（GRUs））的主要工具。这些模型中形成的动态表现出神经坍缩和潜在表示涌现等特征，可能支持网络的卓越泛化能力。在神经科学中，这些表示的定性特征被用于比较生物和人工系统中的学习。尽管近期有所进展，但仍缺乏理论工具来严格理解塑造学习表示的机制，尤其是在有限、非线性模型中。本文表明，描述模型动态在GD中如何演化的梯度流可以分解为两个算子的乘积：参数算子K和线性化流传播器P。K类似于前馈神经网络中的神经正切核，而P则出现在李雅普诺夫稳定性和最优控制理论中。我们展示了这种分解的两种应用。首先，我们展示了它们的相互作用如何在GD下产生低维潜在动态，特别是坍缩如何是网络结构的结果，而非底层任务的性质。其次，对于多任务训练，我们展示了这些算子可用于衡量与单个子任务相关的目标如何对齐。我们通过实验和理论验证了这些发现，并提供了一个高效的Pytorch包KPFlow，为通用循环架构实现了稳健的分析工具。总之，我们的工作朝着理解非线性循环模型中GD学习的下一阶段迈进。

</details>


### [164] [Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction](https://arxiv.org/abs/2507.06432)
**中文标题：填补ICU罕见病数据空白：一种多疾病自适应临床预测方法**

*Mingcheng Zhu,Yu Liu,Zhiyao Luo,Tingting Zhu*

主要分类: cs.LG

摘要简述: 本文提出KnowRare框架，通过领域自适应和知识图谱解决ICU中罕见病数据稀缺和异质性问题，显著提升临床预测性能。


<details>
  <summary>详细信息</summary>
研究动机: ICU中罕见病和低发病率疾病因数据稀缺和异质性难以获得有效预测模型，亟需解决方案。

研究方法: KnowRare通过自监督预训练学习通用表征，并利用条件知识图谱选择性迁移相似疾病知识，解决数据稀缺和异质性。

研究结果: 在五项临床预测任务中，KnowRare表现优于现有模型和ICU评分系统，并展示出灵活性和泛化能力。

研究结论: KnowRare为ICU罕见病临床决策提供了实用且稳健的解决方案，具有广泛应用潜力。

中文摘要: 人工智能已彻底改变了常见危重症的诊疗，但ICU中的罕见病（包括公认的罕见病和低发病率疾病）因数据稀缺和疾病内异质性而难以获得有效支持。为填补这一空白，我们开发了KnowRare，一种基于领域自适应的深度学习框架，用于预测ICU中罕见病的临床结局。KnowRare通过自监督预训练从多样化的电子健康记录中学习疾病无关表征，缓解数据稀缺问题；并通过构建的条件知识图谱选择性迁移临床相似疾病的知识，解决疾病内异质性。在两个ICU数据集上的五项临床预测任务（90天死亡率、30天再入院率、ICU死亡率、剩余住院时间和表型分类）评估中，KnowRare始终优于现有最先进模型。此外，KnowRare的预测性能优于APACHE IV和IV-a等ICU评分系统。案例研究进一步展示了KnowRare在适应数据集和任务特性、有限数据下泛化至常见疾病以及合理选择源疾病方面的灵活性。这些发现表明，KnowRare有望成为支持ICU罕见病临床决策和改善护理的稳健实用解决方案。

</details>


### [165] [Can Interpretation Predict Behavior on Unseen Data?](https://arxiv.org/abs/2507.06445)
**中文标题：可解释性能否预测模型在未见数据上的行为？**

*Victoria R. Li,Jenny Kaufmann,Martin Wattenberg,David Alvarez-Melis,Naomi Saphra*

主要分类: cs.LG

摘要简述: 本文探讨了可解释性研究在预测模型对未见数据行为方面的潜力，通过分析Transformer模型的注意力模式与分布外泛化能力的关系，发现简单的观察工具可以预测模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 可解释性研究通常关注模型对特定干预的反应，但很少预测模型对未见数据的响应。本文旨在探索可解释性工具在预测分布外（OOD）模型行为方面的可行性和挑战。

研究方法: 研究通过分析数百个独立训练的Transformer模型在合成分类任务中的注意力模式与OOD泛化能力的关系，探究了可解释性工具的有效性。

研究结果: 研究发现，当模型在分布内数据中表现出层次化注意力模式时，其在OOD数据上更可能实现层次化泛化，即使规则的实现不依赖这些模式。

研究结论: 研究为可解释性工具在预测未见模型行为方面的应用提供了概念验证，激励进一步探索。

中文摘要: 可解释性研究通常旨在预测模型对特定干预的反应，但很少预测模型对未见输入数据的响应。本文探讨了可解释性作为预测分布外（OOD）模型行为工具的潜力与挑战。具体而言，我们研究了数百个独立训练的Transformer模型在合成分类任务中注意力模式与OOD泛化能力的对应关系。这些模型表现出多种不同的系统性泛化规则，形成了一个多样化的群体用于相关性分析。在此背景下，我们发现简单的可解释性观察工具可以预测OOD性能。特别是，当分布内注意力呈现层次化模式时，模型在OOD数据上更可能实现层次化泛化——即使根据消融测试，规则的实现不依赖这些层次化模式。我们的发现为激励进一步预测未见模型行为的可解释性研究提供了概念验证。

</details>


### [166] [FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models](https://arxiv.org/abs/2507.06449)
**中文标题：FedPhD：基于分层学习的扩散模型联邦剪枝方法**

*Qianyu Long,Qiyuan Wang,Christos Anagnostopoulos,Daning Bi*

主要分类: cs.LG

摘要简述: FedPhD是一种新颖的联邦学习方法，专门用于高效训练扩散模型（DMs），通过分层联邦学习和同质性感知模型聚合策略解决数据异构性和高通信成本问题，同时采用分布式结构化剪枝提升计算效率和降低存储需求。实验表明，FedPhD在FID分数上优于基线方法，通信成本降低88%，计算资源仅需56%。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习（FL）在训练扩散模型（DMs）时面临数据异构性和高通信成本的挑战，而现有研究对此关注不足。FedPhD旨在填补这一空白，提供一种高效训练DMs的解决方案。

研究方法: FedPhD采用分层联邦学习框架，结合同质性感知模型聚合和选择策略，以应对数据异构性。同时，通过分布式结构化剪枝减少计算和存储需求。

研究结果: 实验结果显示，FedPhD在多个数据集上显著优于基线方法，FID分数提升至少34%，通信成本降低88%，计算资源仅需56%。

研究结论: FedPhD为联邦学习环境中高效训练扩散模型提供了一种创新方法，显著提升了模型性能并降低了资源消耗。

中文摘要: 联邦学习（FL）作为一种分布式学习范式，通过在分布式客户端数据上训练模型，特别适用于需要多样化数据的高质量图像生成器——扩散模型（DMs）的分布式训练。然而，与训练Transformer和卷积神经网络类似，训练DMs仍面临高通信成本和数据异构性等挑战。目前，针对FL环境中这些问题的研究有限。为填补这一空白并解决相关挑战，我们提出了一种新颖的方法FedPhD，旨在FL环境中高效训练DMs。FedPhD利用分层联邦学习，结合同质性感知模型聚合和选择策略，以应对数据异构性并降低通信成本。其分布式结构化剪枝技术进一步提升了计算效率并减少了客户端的模型存储需求。我们在多个数据集上的实验表明，FedPhD在Fréchet Inception Distance（FID）分数上表现出色，同时将通信成本降低高达88%。FedPhD优于基线方法，FID分数提升至少34%，而仅需总计算和通信资源的56%。

</details>


### [167] [SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam](https://arxiv.org/abs/2507.06464)
**中文标题：SoftSignSGD（S3）：一种超越Adam的增强型优化器，用于实际DNN训练和损失峰值最小化**

*Hanyang Peng,Shuang Qin,Yue Yu,Fangqing Jiang,Hui Wang,Wen Gao*

主要分类: cs.LG

摘要简述: 本文提出了一种新型优化器SignSoftSGD（S3），通过改进Adam的更新机制，显著减少训练中的损失峰值，并提升性能。S3结合了灵活的动量设计和Nesterov加速梯度模块，在理论和实验中均表现出色。


<details>
  <summary>详细信息</summary>
研究动机: Adam在深度神经网络训练中表现优异，但其机制和局限性尚未充分研究。研究发现Adam在处理大梯度波动时类似SignSGD，但因其无控制的更新缩放易导致损失峰值。为改进Adam的优势并解决其不足，提出了S3优化器。

研究方法: S3优化器采用三项创新：1）使用灵活的p阶动量替代传统二阶动量，增强性能并稳定训练；2）通过统一的指数移动平均系数减少损失峰值，简化超参数调优；3）引入Nesterov加速梯度模块，加速收敛且无额外内存开销。

研究结果: 实验表明，S3在视觉和语言任务中不仅收敛更快、性能更优，还能显著减少损失峰值，即使学习率提高10倍仍表现稳定。其性能与AdamW相当甚至更优，且仅需一半训练步数。

研究结论: S3优化器在理论和实践中均表现出色，解决了Adam的局限性，为深度神经网络训练提供了更高效、稳定的优化方案。

中文摘要: Adam在深度神经网络训练中取得了显著成功，但其成功机制和局限性尚未充分探索。本研究证明，Adam的有效性主要源于其与SignSGD在处理大梯度波动时的相似性，但也因其无控制的更新缩放而易受损失峰值的影响。为增强Adam的优势并解决其不足，我们提出了SignSoftSGD（S3），一种具有三项关键创新的新型优化器。首先，S3通过采用灵活的p阶动量（p≥1）替代传统的二阶动量（方差）预处理，实现了性能提升和稳定训练。其次，S3通过统一的指数移动平均系数减少损失峰值，将更新限制在[-1,1]范围内并简化超参数调优。第三，S3引入了等效的Nesterov加速梯度（NAG）模块，加速收敛且无内存开销。理论上，我们证明了S3在弱假设下实现了非凸随机优化的最优收敛速率O(1/T^(1/4))。在多种视觉和语言任务中的实验表明，S3不仅收敛更快、性能更优，还能显著减少损失峰值，即使学习率提高10倍仍表现稳定。实际上，S3的性能与AdamW相当甚至更优，且仅需一半训练步数，证明了其在效率和最终任务性能上的优越性。

</details>


### [168] [Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models](https://arxiv.org/abs/2507.06466)
**中文标题：基础模型自博弈：通过基础模型实现开放式策略创新**

*Aaron Dharna,Cong Lu,Jeff Clune*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“基础模型自博弈”（FMSP）的新方法，利用基础模型的代码生成能力和广泛知识，通过自博弈策略克服传统自博弈方法的局限性，实现策略空间的多样性和高质量策略的发现。


<details>
  <summary>详细信息</summary>
研究动机: 传统自博弈方法（SP）在多智能体交互中常因陷入局部最优而无法产生多样化的策略。本文旨在通过基础模型（FMs）的能力，突破这一限制，推动更开放和创新的策略发现。

研究方法: 提出了三种FMSP方法：1）基础模型自博弈（vFMSP），通过竞争性自博弈持续优化策略；2）新颖性搜索自博弈（NSSP），专注于策略多样性而非性能；3）质量多样性自博弈（QDSP），结合多样性和策略优化。实验在Car Tag和Gandalf两个场景中进行验证。

研究结果: 在Car Tag中，FMSP探索了多种方法（如强化学习、树搜索等），其策略质量超越人工设计策略。在Gandalf中，FMSP成功突破LLM的六层防御并自动修补漏洞。

研究结论: FMSP为基础模型与自博弈的结合开辟了新研究方向，为开放性和创造性策略发现提供了新路径。

中文摘要: 多智能体交互长期以来推动了创新，从自然界的捕食者-猎物动态到太空竞赛。自博弈（SP）算法试图通过让智能体与不断改进的对手对抗来利用这些动态，从而形成一种隐式课程，以学习高质量解决方案。然而，SP通常无法产生多样化的解决方案，并可能陷入局部最优行为。我们提出了基础模型自博弈（FMSP），这是一种利用基础模型（FMs）的代码生成能力和广泛知识来跨越策略空间中的局部最优的新方向。我们提出了一系列方法：（1）基础模型自博弈（vFMSP）通过竞争性自博弈持续优化智能体策略；（2）新颖性搜索自博弈（NSSP）构建多样化的策略种群，忽略性能；（3）最有前景的变体——质量多样性自博弈（QDSP），结合了NSSP的多样性和vFMSP的优化能力，创建了一组高质量且多样化的策略。我们在Car Tag（一种连续控制的追捕者-逃避者场景）和Gandalf（一种简单的AI安全模拟，攻击者试图突破LLM的防御）中评估了FMSP。在Car Tag中，FMSP探索了多种方法，例如强化学习、树搜索和基于启发式的方法等。在发现的策略质量方面，我们的算法和vFMSP超越了强大的人工设计策略。在Gandalf中，FMSP能够成功自动红队测试LLM，突破并越狱六种逐步加强的防御层级。此外，FMSP能够自动修补发现的漏洞。总体而言，FMSP代表了通过基础模型改进自博弈的一个有前景的新研究前沿，为更开放和创造性的策略发现开辟了新路径。

</details>


### [169] [Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model](https://arxiv.org/abs/2507.06892)
**中文标题：挤压浸湿的海绵：大型语言模型的高效离策略强化微调**

*Jing Liang,Hongyao Tang,Yi Ma,Jinyi Liu,Yan Zheng,Shuyue Hu,Lei Bai,Jianye Hao*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ReMix的高效离策略强化微调方法，用于大型语言模型（LLMs），通过混合策略近端策略梯度和策略重生技术，显著降低了训练成本并提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有强化微调（RFT）方法多为同策略RL，未能充分利用历史数据，导致计算和时间成本高昂。本文旨在通过离策略RL的复兴，解决这一问题。

研究方法: ReMix包含三个核心组件：1）混合策略近端策略梯度以提高更新与数据比；2）KL-凸策略约束以平衡稳定性和灵活性；3）策略重生技术，实现从高效早期学习到稳定渐进改进的无缝过渡。

研究结果: 实验表明，ReMix在多个数学推理基准测试中表现优异，训练成本降低了30至450倍，同时保持了SOTA级别的性能。

研究结论: ReMix为高效离策略强化微调提供了通用解决方案，显著降低了训练成本并提升了模型性能，同时揭示了离策略差异对模型行为的潜在影响。

中文摘要: 强化学习（RL）已展现出提升大型语言模型（LLMs）推理能力的潜力。现有强化微调（RFT）方法多为同策略RL，即未能充分利用历史数据，导致计算和时间成本高昂。为此，本文复兴了离策略RL，并提出ReMix（重生混合策略近端策略梯度），一种通用方法，使PPO和GRPO等同策略RFT方法能够利用离策略数据。ReMix包含三个核心组件：（1）混合策略近端策略梯度，提高更新与数据比以实现高效训练；（2）KL-凸策略约束，平衡稳定性与灵活性；（3）策略重生技术，实现从高效早期学习到稳定渐进改进的无缝过渡。实验基于PPO、GRPO及1.5B、7B基础模型训练了一系列ReMix模型。在五个数学推理基准测试（AIME'24、AMC'23、Minerva、OlympiadBench和MATH500）中，ReMix的1.5B模型平均Pass@1准确率为52.10%（仅需0.079M响应生成和350训练步），7B模型为63.27%/64.39%（仅需0.007M/0.011M响应生成和50/75训练步）。与15种先进模型相比，ReMix在训练成本（响应生成量）上降低了30至450倍，同时保持了SOTA性能。此外，通过多角度分析揭示了离策略差异对模型行为的潜在影响，如对较短响应的隐性偏好（鞭打效应）以及严重离策略性下自反思行为的崩溃模式。

</details>


### [170] [MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models](https://arxiv.org/abs/2507.06502)
**中文标题：MoFE-Time：基于频域专家混合的时间序列预测模型**

*Yiwen Liu,Chenyu Zhang,Junjie Song,Siqi Chen,Sun Yin,Zihan Wang,Lingming Zeng,Yuji Cao,Junming Jiao*

主要分类: cs.LG

摘要简述: MoFE-Time是一种创新的时间序列预测模型，通过混合专家网络（MoE）整合时域和频域特征，在预训练-微调框架下显著提升了复杂时间序列的预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有时间序列预测模型在预训练-微调范式下未能同时建模时域和频域特征，导致对复杂时间序列（需同时建模周期性和信号先验模式）的预测性能不佳。

研究方法: 提出MoFE-Time模型，在注意力模块后引入频域和时域专家单元，利用MoE路由机制构建输入信号的多维稀疏表示，并通过预训练-微调框架实现跨数据集的先验知识迁移。

研究结果: 在六个公开基准测试中，MoFE-Time取得了新的最优性能，MSE和MAE分别比代表性方法Time-MoE降低了6.95%和6.02%。在私有数据集NEV-sales上也表现出色。

研究结论: MoFE-Time通过整合时域和频域特征，显著提升了时间序列预测性能，尤其在复杂商业场景中表现优异。

中文摘要: 时间序列预测作为一种重要的数据模态任务，在多种应用中扮演关键角色。随着大型语言模型（LLMs）的显著进展，采用LLMs作为时间序列建模的基础架构受到广泛关注。尽管现有模型取得了一定成功，但它们很少在预训练-微调范式中同时建模时域和频域特征，导致对复杂时间序列（需同时建模周期性和信号先验模式）的预测性能不佳。我们提出MoFE-Time，一种创新的时间序列预测模型，通过混合专家网络（MoE）整合时域和频域特征。此外，我们采用预训练-微调范式作为训练框架，以有效迁移不同周期性分布的预训练和微调数据集中的先验模式知识。我们的方法在注意力模块后引入频域和时域专家单元，并利用MoE路由机制构建输入信号的多维稀疏表示。在六个公开基准测试中，MoFE-Time取得了新的最优性能，MSE和MAE分别比代表性方法Time-MoE降低了6.95%和6.02%。除了现有评估基准外，我们还开发了一个源自真实商业场景的私有数据集NEV-sales。我们的方法在该数据集上表现优异，进一步验证了MoFE-Time模型在实际商业应用中的有效性。

</details>


### [171] [The Primacy of Magnitude in Low-Rank Adaptation](https://arxiv.org/abs/2507.06558)
**中文标题：低秩适应中幅度的首要性**

*Zicheng Zhang,Haoran Li,Yifeng Zhang,Guoqiang Gong,Jiaxing Wang,Pengzhang Liu,Qixia Jiang,Junxing Hu*

主要分类: cs.LG

摘要简述: 本文提出LoRAM方法，通过优化权重更新的幅度提升低秩适应（LoRA）性能，避免了谱初始化方法的计算和存储开销。


<details>
  <summary>详细信息</summary>
研究动机: 低秩适应（LoRA）是一种参数高效的调参方法，但现有谱初始化方法虽能提升性能，却带来额外计算和存储开销。本文旨在揭示权重更新幅度对LoRA性能的关键作用，并提出更高效的初始化方案。

研究方法: 提出LoRAM方法，通过幅度驱动的“基与基”初始化策略，模拟谱初始化的性能增益，同时避免其低效性。理论证明低秩结构限制了更新幅度，并将超参数调优统一为幅度优化问题。

研究结果: 实验表明，LoRAM在保持LoRA高效性的同时，性能与谱初始化相当或更优。

研究结论: 权重更新幅度是LoRA性能的核心驱动因素，LoRAM提供了一种高效且性能优越的初始化方案。

中文摘要: 低秩适应（LoRA）为大型模型调参提供了一种参数高效的范式。尽管近期的谱初始化方法在收敛性和性能上优于朴素的“噪声与零”方案，但其额外的计算和存储开销降低了效率。本文确立了权重更新幅度为LoRA性能的根本驱动因素，并提出LoRAM，一种幅度驱动的“基与基”初始化方案，其性能与谱方法相当但避免了其低效性。我们的主要贡献有三点：（i）权重更新幅度决定收敛性。我们证明低秩结构本质上限定了更新幅度，将学习率、缩放因子和初始化的超参数调优统一为幅度优化的机制。（ii）谱初始化通过幅度放大实现成功。我们揭示谱组分的所谓知识驱动优势本质上源于权重更新幅度的提升。（iii）提出一种新颖且紧凑的初始化策略LoRAM，利用预训练权重幅度缩放确定性正交基以模拟谱增益。大量实验表明，LoRAM作为强基线，在保持LoRA完全效率的同时，在多个基准测试中与谱初始化相当或更优。

</details>


### [172] [From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization](https://arxiv.org/abs/2507.06573)
**中文标题：从数据为中心到样本为中心：通过渐进优化提升大语言模型的推理能力**

*Xinjie Chen,Minpeng Liao,Guoxin Chen,Chengxi Li,Biao Fu,Kai Fan,Xinggao Liu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LPPO的渐进优化框架，通过前缀引导采样和学习进度加权，从样本中心视角提升大语言模型的推理能力，实验证明其优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多关注算法设计、数据整理和奖励塑造，而本文从样本中心视角出发，探讨如何高效利用少量高质量示范数据，而非单纯增加数据量。

研究方法: 提出LPPO框架，包含前缀引导采样（利用专家示范的部分解前缀指导策略）和学习进度加权（动态调整样本权重以促进模型学习）。

研究结果: 在数学推理基准测试中，LPPO表现优于基线方法，实现了更快的收敛速度和更高的性能上限。

研究结论: LPPO通过样本中心优化方法有效提升大语言模型的推理能力，为未来研究提供了新方向。

中文摘要: 可验证奖励的强化学习（RLVR）近期显著提升了大语言模型（LLM）的推理能力。以往研究多关注算法设计、数据整理和奖励塑造，而本文从样本中心视角出发，提出LPPO（学习进度和前缀引导优化）框架，探讨如何高效利用少量高质量示范数据。首先，受提示对人类问题解决的启发，提出前缀引导采样，一种在线数据增强方法，利用专家示范的部分解前缀指导策略，尤其适用于复杂实例。其次，受人类关注与当前能力匹配的重要问题的启发，提出学习进度加权，动态调整样本权重以促进模型学习。通过样本级通过率的指数移动平均估计学习进度，突出促进学习的样本，弱化停滞样本。数学推理基准测试表明，LPPO优于基线方法，实现了更快收敛和更高性能上限。

</details>


### [173] [Learning controllable dynamics through informative exploration](https://arxiv.org/abs/2507.06582)
**中文标题：通过信息探索学习可控动态**

*Peter N. Loxley,Friedrich T. Sommer*

主要分类: cs.LG

摘要简述: 本文提出了一种通过信息探索学习可控动态的方法，利用“预测信息增益”指导探索策略，优于短视探索方法。


<details>
  <summary>详细信息</summary>
研究动机: 在缺乏显式模型的环境中，如何通过探索学习可控动态是一个挑战。本文旨在利用信息增益指导探索，以更高效地学习环境动态。

研究方法: 采用“预测信息增益”作为信息度量，结合强化学习方法，寻找最优的探索策略，从而可靠估计环境的可控动态。

研究结果: 与多种短视探索方法相比，该方法能够更有效地学习环境的可控动态，并表现出更高的可靠性。

研究结论: 通过信息增益指导的探索策略能够显著提升对可控动态的学习效果，为无模型环境下的动态学习提供了新思路。

中文摘要: 具有可控动态的环境通常通过显式模型来理解。然而，此类模型并非总是可用，但有时可以通过探索环境来学习。本文研究了一种称为“预测信息增益”的信息度量方法，用于确定环境中最具信息量的区域以进行下一步探索。通过应用强化学习方法，可以找到良好的次优探索策略，并可靠地估计潜在的可控动态。通过与几种短视探索方法的比较，验证了该方法的有效性。

</details>


### [174] [Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation](https://arxiv.org/abs/2507.06613)
**中文标题：去噪多β变分自编码器：解纠缠与生成的表示学习**

*Anshuk Uppal,Yuhta Takida,Chieh-Hsin Lai,Yuki Mitsufuji*

主要分类: cs.LG

摘要简述: 本文提出了一种新的生成模型框架，通过多β值的变分自编码器（VAE）和非线性扩散模型，平衡解纠缠和生成质量，实现高质量重构和样本生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有生成模型在解纠缠和生成质量之间存在权衡，β-VAE通过调整β值平衡两者，但单一β值难以同时满足解纠缠和高质量重构的需求。本文旨在解决这一矛盾。

研究方法: 1. 使用多β值的VAE训练多个潜在表示，通过新损失函数控制信息保留；2. 引入非线性扩散模型，平滑过渡不同β值的潜在表示，实现从解纠缠到高质量重构的转换。

研究结果: 模型在解纠缠和生成质量上均表现优异，支持无输入图像的样本生成，并在潜在空间中实现平滑过渡。

研究结论: 提出的框架有效平衡了解纠缠和生成质量，为生成模型提供了新的解决方案。

中文摘要: 在生成模型中，解纠缠且可解释的潜在表示通常以牺牲生成质量为代价。β-VAE框架通过引入超参数β来平衡解纠缠和重构质量，其中β > 1会形成信息瓶颈，优先解纠缠而非精确重构。为解决这一权衡，我们提出了一种新的生成模型框架，利用多个β值学习对应的潜在表示。首先，我们通过训练单个变分自编码器（VAE）获得一系列表示，使用新损失函数控制每个潜在表示中保留的信息，使得高β值优先解纠缠而非重构保真度。随后，我们引入非线性扩散模型，平滑过渡不同β值的潜在表示。该模型向解纠缠程度较低且信息更丰富的表示去噪，最终实现（几乎）无损的表示，从而支持高质量重构。此外，我们的模型无需输入图像即可生成样本，可作为独立生成模型使用。我们在解纠缠和生成质量两方面评估了该框架，并观察到潜在空间随β值变化的平滑过渡，便于对生成输出进行一致操作。

</details>


### [175] [Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance](https://arxiv.org/abs/2507.06615)
**中文标题：基于跨任务策略指导的高效多任务强化学习**

*Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

主要分类: cs.LG

摘要简述: 本文提出了一种名为跨任务策略指导（CTPG）的新框架，通过利用已掌握任务的策略指导未掌握任务，加速多任务强化学习。实验证明CTPG显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有多任务强化学习方法主要关注参数共享，但忽略了利用跨任务相似性的直接方式。本文旨在通过已掌握任务的策略指导未掌握任务，以加速技能获取。

研究方法: 提出了跨任务策略指导（CTPG）框架，为每个任务训练一个指导策略，从所有任务的控制策略中选择行为策略。此外，设计了两种门控机制以提升学习效率。

研究结果: 实验结果表明，CTPG与现有参数共享方法结合后，在操作和运动基准测试中性能显著提升。

研究结论: CTPG是一种通用框架，能够有效利用跨任务相似性，显著提升多任务强化学习的性能。

中文摘要: 多任务强化学习旨在通过共享信息高效学习多个任务。现有方法主要关注参数共享的网络结构或优化过程，但忽略了利用跨任务相似性的直接方式：已掌握任务的控制策略可为未掌握任务提供显式指导以加速技能获取。为此，我们提出了一种名为跨任务策略指导（CTPG）的新框架，为每个任务训练一个指导策略，从所有任务的控制策略中选择与环境交互的行为策略，生成更好的训练轨迹。此外，我们提出了两种门控机制以提升CTPG的学习效率：一种门控过滤无益于指导的控制策略，另一种门控阻止无需指导的任务。CTPG是一种通用框架，可适配现有参数共享方法。实验评估表明，CTPG与这些方法结合后，在操作和运动基准测试中性能显著提升。

</details>


### [176] [Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning](https://arxiv.org/abs/2507.06628)
**中文标题：面向目标的技能抽象用于离线多任务强化学习**

*Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GO-Skill的目标导向技能抽象方法，用于离线多任务强化学习，通过提取可重用技能并构建离散技能库，提升知识迁移和任务性能。实验证明其在机器人操作任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 离线多任务强化学习面临跨任务知识共享的挑战。受人类学习中高效知识抽象的启发，作者提出GO-Skill方法，旨在通过可重用技能提升知识迁移和任务性能。

研究方法: GO-Skill通过目标导向技能提取过程发现可重用技能，并利用向量量化构建离散技能库。为解决技能类别不平衡问题，引入技能增强阶段优化技能。最后通过分层策略学习动态组合技能完成任务。

研究结果: 在MetaWorld基准测试的多样化机器人操作任务中，GO-Skill表现出高效性和多功能性。

研究结论: GO-Skill通过目标导向技能抽象和分层策略学习，显著提升了离线多任务强化学习的性能，为知识迁移提供了有效解决方案。

中文摘要: 离线多任务强化学习旨在仅使用预收集的任务混合数据集学习一个统一策略，无需与环境进行在线交互。然而，其在跨任务知识共享方面面临重大挑战。受人类学习中高效知识抽象的启发，我们提出了面向目标的技能抽象（GO-Skill），这是一种旨在提取和利用可重用技能以增强知识迁移和任务性能的新方法。我们的方法通过目标导向技能提取过程发现可重用技能，并利用向量量化构建离散技能库。为解决广泛适用技能与任务特定技能之间的类别不平衡问题，我们引入了技能增强阶段以优化提取的技能。此外，我们通过分层策略学习整合这些技能，构建一个动态协调离散技能以完成特定任务的高层策略。在MetaWorld基准测试的多样化机器人操作任务上的大量实验证明了GO-Skill的有效性和多功能性。

</details>


### [177] [Deep Disentangled Representation Network for Treatment Effect Estimation](https://arxiv.org/abs/2507.06650)
**中文标题：深度解耦表示网络用于治疗效果估计**

*Hui Meng,Keping Yang,Xuyu Peng,Bo Zheng*

主要分类: cs.LG

摘要简述: 本文提出了一种新的治疗效应估计算法，通过多专家混合和多头注意力机制，结合线性正交正则化器，软分解预处理变量，并通过重要性采样重加权技术消除选择偏差。实验证明其在个体治疗效果估计上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 观测数据中的个体治疗效果估计是因果推断的核心问题，尤其在教育、医疗和公共政策领域备受关注。现有方法多基于生成模型或硬分解，难以确保精确解耦变量。本文旨在提出一种更有效的方法。

研究方法: 提出了一种结合多专家混合和多头注意力机制的算法，利用线性正交正则化器软分解预处理变量，并通过重要性采样重加权技术消除选择偏差。

研究结果: 在公开半合成和真实数据集上的实验表明，该算法在个体治疗效果估计上优于现有方法。

研究结论: 本文提出的算法通过软分解和消除选择偏差，显著提升了治疗效果估计的准确性，为因果推断领域提供了新思路。

中文摘要: 从观测数据中估计个体治疗效果是因果推断的基本问题，在教育、医疗和公共政策领域备受关注。本文专注于解耦表示方法的研究，该方法通过将观测协变量分解为工具变量、混杂变量和调整变量，取得了显著成果。然而，现有方法多基于生成模型或硬分解，难以确保精确解耦。为有效建模不同因果关系，我们提出了一种新的治疗效应估计算法，结合多专家混合和多头注意力机制，利用线性正交正则化器软分解预处理变量，并通过重要性采样重加权技术消除选择偏差。在公开半合成和真实数据集上的实验表明，该算法在个体治疗效果估计上优于现有方法。

</details>


### [178] [Intrinsic Training Signals for Federated Learning Aggregation](https://arxiv.org/abs/2507.06813)
**中文标题：联邦学习聚合中的固有训练信号**

*Cosimo Fiorini,Matteo Mosconi,Pietro Buzzega,Riccardo Salami,Simone Calderara*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LIVAR的新方法，利用联邦学习中已有的训练信号（如特征统计和参数更新模式）进行模型聚合，无需额外架构修改，实现了高效且高性能的联邦学习聚合。


<details>
  <summary>详细信息</summary>
研究动机: 现有的联邦学习方法在聚合客户端特定分类头和适应主干参数时，通常需要修改架构或损失函数。本文旨在探索如何利用已有的训练信号，避免额外开销，实现高效的模型聚合。

研究方法: LIVAR方法包括：1）基于自然涌现的特征统计的方差加权分类器聚合方案；2）基于SHAP分析的LoRA合并技术，利用参数更新模式的解释性驱动合并。

研究结果: LIVAR在多个基准测试中实现了最先进的性能，且无需任何架构修改，能够无缝集成到现有联邦学习方法中。

研究结论: 本文证明了仅通过已有的训练信号即可实现高效的模型聚合，为联邦学习提供了一种新的高效聚合范式。

中文摘要: 联邦学习（FL）能够在分布式客户端之间进行协作模型训练，同时保护数据隐私。现有的方法在聚合客户端特定分类头和适应主干参数时通常需要修改架构或损失函数，而我们的方法独特地利用了标准优化过程中已有的固有训练信号。我们提出了LIVAR（基于层重要性和方差的合并），其包括：i）利用自然涌现的特征统计的方差加权分类器聚合方案；ii）基于SHAP分析的LoRA合并技术，利用现有参数更新模式的解释性驱动合并。LIVAR无需任何架构开销，在多个基准测试中实现了最先进的性能，同时能够无缝集成到现有联邦学习方法中。这项工作表明，仅通过已有的训练信号即可实现高效的模型合并，为高效的联邦模型聚合建立了新的范式。代码将在论文被接受后公开。

</details>


### [179] [Comprehensive Evaluation of Prototype Neural Networks](https://arxiv.org/abs/2507.06819)
**中文标题：原型神经网络的综合评估**

*Philipp Schlinge,Steffen Meinert,Martin Atzmueller*

主要分类: cs.LG

摘要简述: 本文对原型神经网络模型（如ProtoPNet、ProtoPool和PIPNet）进行了全面评估，提出新指标以补充模型可解释性分析，并在多种数据集上验证性能，同时开源了代码库。


<details>
  <summary>详细信息</summary>
研究动机: 原型模型是可解释人工智能（XAI）和可解释机器学习的重要方法，但缺乏全面的评估指标。本文旨在填补这一空白，通过新指标和多样化数据集评估原型模型的性能。

研究方法: 本文选取ProtoPNet、ProtoPool和PIPNet等原型模型，结合标准指标和新提出的指标，在细粒度分类、非独立同分布（Non-IID）和多标签分类数据集上进行实验。

研究结果: 实验表明，新提出的指标能有效补充原型模型的可解释性分析，模型在不同数据集上表现各异。同时，开源代码库为后续研究提供了便利。

研究结论: 本文通过全面评估原型模型，提出了新的可解释性指标，验证了模型在多样化任务中的性能，并开源代码以促进进一步研究。

中文摘要: 原型模型是可解释人工智能（XAI）和可解释机器学习的重要方法。本文对ProtoPNet、ProtoPool和PIPNet等原型模型进行了深入分析，并采用了一套全面的评估指标。除了应用文献中的标准指标外，我们还提出了几种新指标以进一步补充模型可解释性分析。实验中，我们将原型模型应用于多种数据集，包括细粒度分类、非独立同分布（Non-IID）和多标签分类，以对比其性能。此外，我们还开源了代码库，便于指标的直接应用和扩展，支持轻松添加新指标和模型。

</details>


### [180] [HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning](https://arxiv.org/abs/2507.06821)
**中文标题：HeLo：基于标签相关性的异质多模态融合情感分布学习**

*Chuhang Zheng,Chunwei Tian,Jie Wen,Daoqiang Zhang,Qi Zhu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为HeLo的多模态情感分布学习框架，通过跨注意力机制和最优传输方法挖掘多模态数据的异质性，并利用可学习的标签嵌入优化标签相关性，从而提升情感分布学习的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 多模态情感识别在人机交互中具有重要意义，但现有方法在多模态数据的异质性挖掘和标签相关性利用上存在不足。本文旨在通过融合多模态数据和优化标签相关性，提升情感分布学习的性能。

研究方法: 1. 使用跨注意力机制融合生理数据；2. 设计基于最优传输的异质性挖掘模块，分析生理和行为表征的交互与异质性；3. 引入可学习的标签嵌入，通过相关性矩阵对齐优化标签相关性；4. 提出标签相关性驱动的跨注意力机制，整合多模态表征和标签相关性。

研究结果: 在两个公开数据集上的实验表明，HeLo框架在情感分布学习中表现出优越性能。

研究结论: HeLo框架通过挖掘多模态数据的异质性和优化标签相关性，显著提升了情感分布学习的准确性，为多模态情感识别提供了新思路。

中文摘要: 多模态情感识别近年来在人机交互中扮演重要角色，因其能够识别混合的离散情感，情感分布学习（EDL）逐渐成为趋势。然而，现有EDL方法在多模态异质性挖掘和标签相关性利用上存在挑战。本文提出了一种名为HeLo的多模态情感分布学习框架，旨在充分挖掘多模态情感数据的异质性和互补信息，以及混合基本情感间的标签相关性。具体而言，我们首先采用跨注意力机制有效融合生理数据；其次，设计基于最优传输的异质性挖掘模块，分析生理和行为表征的交互与异质性；为优化标签相关性学习，引入可学习的标签嵌入，并通过相关性矩阵对齐进行优化；最后，通过标签相关性驱动的跨注意力机制，将可学习的标签嵌入和相关性矩阵与多模态表征整合，实现准确的情感分布学习。在两个公开数据集上的实验证明了所提方法在情感分布学习中的优越性。

</details>


### [181] [Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning](https://arxiv.org/abs/2507.06825)
**中文标题：通用人工智能：通过强化学习掌握Generals.io**

*Matej Straka,Martin Schmid*

主要分类: cs.LG

摘要简述: 本文介绍了一个基于Generals.io的实时策略游戏环境，并训练了一个通过监督预训练和自我对弈的智能体，该智能体在36小时内达到人类1v1排行榜前0.003%。


<details>
  <summary>详细信息</summary>
研究动机: 为多智能体强化学习研究提供一个模块化且具有挑战性的基准平台，同时展示一种高效的训练方法。

研究方法: 构建了兼容Gymnasium和PettingZoo的游戏环境，结合监督预训练和自我对弈训练智能体，并采用基于潜力的奖励塑造和记忆特征加速学习。

研究结果: 训练36小时后，智能体在1v1人类排行榜中进入前0.003%，展示了高效的学习能力。

研究结论: 本文提供了一个可访问且具有挑战性的多智能体强化学习平台，并展示了先进的基线智能体。

中文摘要: 我们介绍了一个基于Generals.io的实时策略游戏环境，该游戏每周有数千名活跃玩家参与多种游戏模式。我们的环境完全兼容Gymnasium和PettingZoo，能够在普通硬件上每秒运行数千帧。我们的参考智能体通过监督预训练和自我对弈训练，仅用36小时就在单块H100 GPU上达到了1v1人类排行榜的前0.003%。为了加速学习，我们采用了基于潜力的奖励塑造和记忆特征。我们的贡献——一个模块化的RTS基准和一个具有竞争力的最先进基线智能体——为推进多智能体强化学习研究提供了一个易于使用且具有挑战性的平台。

</details>


### [182] [DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models](https://arxiv.org/abs/2507.06853)
**中文标题：DiffSpectra：基于扩散模型的光谱分子结构解析**

*Liang Wang,Yu Rong,Tingyang Xu,Zhenyi Zhong,Zhiyuan Liu,Pengju Wang,Deli Zhao,Qiang Liu,Shu Wu,Liang Wang*

主要分类: cs.LG

摘要简述: DiffSpectra是一种基于扩散模型的生成框架，直接从多模态光谱数据推断2D和3D分子结构，解决了传统方法依赖专家解释和有限库的问题，并通过实验验证了其高准确性和有效性。


<details>
  <summary>详细信息</summary>
研究动机: 分子结构解析是化学中的基础问题，传统方法依赖专家解释且缺乏扩展性，现有机器学习方法受限于有限库的泛化能力。DiffSpectra旨在通过扩散模型直接生成分子结构，克服这些限制。

研究方法: DiffSpectra采用扩散模型作为生成框架，通过Diffusion Molecule Transformer（SE(3)-等变架构）整合拓扑和几何信息，并利用SpecFormer（基于Transformer的光谱编码器）捕捉多模态光谱的依赖关系。

研究结果: 实验表明，DiffSpectra在结构解析中表现出高准确性，通过采样实现了16.01%的top-1准确率和96.86%的top-20准确率，3D几何建模、SpecFormer预训练和多模态条件显著提升了性能。

研究结论: DiffSpectra首次统一了多模态光谱推理和2D/3D联合生成建模，为分子结构解析提供了有效解决方案，展示了扩散模型在这一领域的潜力。

中文摘要: 分子结构解析是化学中的基础问题，对化合物鉴定、合成和药物开发具有重要意义。传统方法依赖专家解释且缺乏扩展性，现有机器学习方法虽引入检索策略，但受限于有限库的泛化能力。生成模型提供了替代方案，但多数采用自回归SMILES架构，忽略了3D几何结构且难以整合多模态光谱。本文提出DiffSpectra，一种基于扩散模型的生成框架，直接从多模态光谱数据推断2D和3D分子结构。DiffSpectra将结构解析建模为条件生成过程，其去噪网络由Diffusion Molecule Transformer（SE(3)-等变架构）参数化，整合拓扑和几何信息，并通过SpecFormer（基于Transformer的光谱编码器）提供条件，捕捉多模态光谱的内外依赖关系。大量实验表明，DiffSpectra在结构解析中表现出高准确性，通过采样实现了16.01%的top-1准确率和96.86%的top-20准确率。模型显著受益于3D几何建模、SpecFormer预训练和多模态条件。这些结果凸显了光谱条件扩散模型在解决分子结构解析挑战中的有效性。DiffSpectra是首个统一多模态光谱推理和2D/3D联合生成建模的框架，为全新分子结构解析提供了创新方案。

</details>


### [183] [A Principled Framework for Multi-View Contrastive Learning](https://arxiv.org/abs/2507.06979)
**中文标题：多视图对比学习的原理性框架**

*Panagiotis Koromilas,Efthymios Georgiou,Giorgos Bouritsas,Theodoros Giannakopoulos,Mihalis A. Nicolaou,Yannis Panagakis*

主要分类: cs.LG

摘要简述: 本文提出两种新型损失函数MV-InfoNCE和MV-DHEL，解决了多视图对比学习中存在的目标冲突、视图交互不足等问题，显著提升了多视图对比学习的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前多视图对比学习方法通过简单聚合成对目标处理额外视图，存在目标冲突、视图交互不足、继承成对对比学习局限性等问题，无法充分利用多视图优势。本文旨在解决这些问题。

研究方法: 提出两种新型损失函数：MV-InfoNCE（扩展InfoNCE以同时纳入所有视图交互）和MV-DHEL（解耦视图间的对齐与均匀性）。这两种方法均基于理论分析，优化多视图对齐与均匀性。

研究结果: 在ImageNet1K等数据集上，新方法显著优于现有多视图方法，且能有效扩展至多模态数据。MV-DHEL在五视图以上时能充分利用嵌入空间，避免维度崩溃。

研究结论: MV-InfoNCE和MV-DHEL为多视图对比学习提供了理论支持，显著提升了性能，并展示了多视图在监督学习中的潜力。

中文摘要: 对比学习（CL）是自监督学习（SSL）中的主流范式，通常依赖于通过增强生成的数据视图对。尽管在监督学习中，每个实例的多次增强（超过两次）能提升泛化能力，但当前CL方法通过简单聚合不同成对目标处理额外视图，存在四个关键局限性：（L1）每个数据点使用多个优化项导致目标冲突；（L2）未能建模视图和数据点间的所有交互；（L3）继承了成对CL损失的基本局限性（如对齐-均匀性耦合）；（L4）无法充分利用监督学习中多视图的优势。我们通过两种新型损失函数解决这些问题：MV-InfoNCE（扩展InfoNCE以同时纳入所有视图交互）和MV-DHEL（解耦视图间的对齐与均匀性，同时根据视图数量扩展交互复杂度）。这两种方法均基于理论分析，我们证明它们渐近优化了所有视图的对齐与均匀性，为多视图对比学习提供了原理性扩展。在ImageNet1K和其他三个数据集上的实验结果表明，我们的方法始终优于现有多视图方法，并能有效扩展至多模态数据。最重要的是，消融研究表明，五视图以上的MV-DHEL能充分利用嵌入空间，有效避免维度崩溃，从而实现监督学习中多视图的优势。

</details>


### [184] [What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models](https://arxiv.org/abs/2507.06952)
**中文标题：基础模型发现了什么？利用归纳偏差探针世界模型**

*Keyon Vafa,Peter G. Chang,Ashesh Rambachan,Sendhil Mullainathan*

主要分类: cs.LG

摘要简述: 基础模型是否真正掌握了深层结构？本文通过归纳偏差探针技术评估模型对合成数据集的适应能力，发现模型虽能完成训练任务，却未能形成对底层世界模型的归纳偏差。


<details>
  <summary>详细信息</summary>
研究动机: 基础模型的理论假设序列预测能揭示更深层次的领域理解，但如何验证模型是否真正掌握了深层结构仍具挑战性。本文旨在开发一种技术，通过合成数据集评估模型是否具备与假设世界模型一致的归纳偏差。

研究方法: 本文提出一种归纳偏差探针技术，通过生成基于假设世界模型的合成数据集，评估基础模型在适应新任务时是否表现出与该世界模型一致的归纳偏差。

研究结果: 研究发现，基础模型在训练任务上表现优异，但在适应新任务时未能形成对底层世界模型的归纳偏差。尤其在轨道轨迹任务中，模型未能应用牛顿力学。进一步分析表明，模型仅发展出任务特定的启发式方法，缺乏泛化能力。

研究结论: 基础模型虽能高效完成训练任务，但其归纳偏差未必与底层世界模型一致，表明模型可能仅依赖任务特定的启发式方法，而非真正的世界模型理解。

中文摘要: 基础模型的核心理念是序列预测能够揭示更深层次的领域理解，类似于开普勒对行星运动的预测最终导致牛顿力学的发现。然而，评估这些模型是否真正掌握了深层结构仍具挑战性。我们开发了一种评估基础模型的技术，通过生成基于假设世界模型的合成数据集，检测模型是否表现出与该世界模型一致的归纳偏差，因此称之为归纳偏差探针。在多个领域中，我们发现基础模型虽能出色完成训练任务，但在适应新任务时未能形成对底层世界模型的归纳偏差。特别是在轨道轨迹任务中，模型始终未能应用牛顿力学。进一步分析表明，这些模型的行为似乎依赖于任务特定的启发式方法，而未能实现泛化。

</details>


### [185] [Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts](https://arxiv.org/abs/2507.07100)
**中文标题：通过双平衡协作专家解决不平衡领域增量学习问题**

*Lan Li,Da-Wei Zhou,Han-Jia Ye,De-Chuan Zhan*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Dual-Balance Collaborative Experts (DCE)的框架，用于解决领域增量学习中的类别不平衡问题。DCE通过频率感知的专家组和动态专家选择器，有效处理了域内类别不平衡和跨域类别分布偏移，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 领域增量学习（DIL）在非静态环境中面临两大挑战：域内类别不平衡和跨域类别分布偏移。这些问题导致模型对少样本类别的学习不足，同时难以保持多样本类别的知识。本文旨在通过DCE框架解决这些问题。

研究方法: DCE框架包含两部分：1）频率感知的专家组，每个专家通过专用损失函数学习特定频率组的特征，解决域内不平衡；2）动态专家选择器，通过平衡高斯采样从历史类别统计中合成伪特征，平衡新旧知识的利用。

研究结果: 在四个基准数据集上的实验表明，DCE框架在领域增量学习中实现了最先进的性能，显著提升了少样本类别的表现，同时保持了多样本类别的知识。

研究结论: DCE框架通过双平衡机制有效解决了领域增量学习中的类别不平衡问题，为模型在动态环境中的持续学习提供了新思路。

中文摘要: 领域增量学习（DIL）专注于非静态环境中的持续学习，要求模型在不断演变的领域中调整，同时保留历史知识。DIL在数据不平衡的情况下面临两大关键挑战：域内类别不平衡和跨域类别分布偏移。这些挑战显著阻碍了模型性能，域内不平衡导致少样本类别欠拟合，而跨域偏移需要保持多样本类别的知识并迁移知识以提升旧领域中少样本类别的表现。为解决这些问题，我们提出了双平衡协作专家（DCE）框架。DCE采用频率感知的专家组，每个专家通过专用损失函数学习特定频率组的特征，有效解决域内类别不平衡。随后，通过从历史类别统计中平衡高斯采样合成伪特征，学习动态专家选择器。该机制在保留先前领域多样本知识与利用新数据提升早期任务中少样本类别表现之间取得平衡。在四个基准数据集上的广泛实验结果表明，DCE实现了最先进的性能。

</details>


### [186] [Noisy PDE Training Requires Bigger PINNs](https://arxiv.org/abs/2507.06967)
**中文标题：噪声PDE训练需要更大的PINNs**

*Sebastien Andre-Sloan,Anirbit Mukherjee,Matthew Colbrook*

主要分类: cs.LG

摘要简述: 本文证明了在噪声监督数据下，物理信息神经网络（PINNs）需要更大的网络规模才能实现低于噪声方差的经验风险，并提出了相关参数约束条件。


<details>
  <summary>详细信息</summary>
研究动机: 物理信息神经网络（PINNs）在高维偏微分方程（PDE）求解中应用广泛，但现实数据常含噪声。目前尚不清楚PINNs在噪声条件下如何有效降低经验风险，因此需要研究其网络规模与噪声数据的关系。

研究方法: 通过理论分析，证明了在噪声监督数据下，PINNs的经验风险低于噪声方差时，网络参数数量需满足特定约束条件（如$d_N\log d_N\gtrsim N_s \eta^2$）。同时，通过实验验证了PINNs在噪声条件下实现低经验风险的可能性。

研究结果: 研究表明，仅增加噪声监督数据的数量无法直接降低经验风险，必须增大网络规模。实验证实了PINNs在噪声条件下仍可实现低于噪声方差的经验风险。

研究结论: 本文为噪声条件下训练PINNs的网络规模需求提供了定量依据，并揭示了噪声数据对模型性能的影响。

中文摘要: 物理信息神经网络（PINNs）越来越多地用于近似偏微分方程（PDE）的解，尤其是在高维情况下。实际应用中，数据样本通常含有噪声，因此了解预测器何时仍能实现低经验风险至关重要。然而，关于PINNs在何种条件下能有效实现这一目标的研究较少。我们证明了在噪声监督标签下，为了使PINNs的经验风险低于噪声方差，神经网络规模必须满足一定的下限。具体而言，若预测器的经验风险比监督数据的方差$\sigma^2$低$O(\eta)$，则必须满足$d_N\log d_N\gtrsim N_s \eta^2$，其中$N_s$为样本数量，$d_N$为PINN的可训练参数数量。类似约束也适用于边界标签含噪声的全无监督PINN设置。因此，仅增加噪声监督标签数量并不能“免费”降低经验风险。我们还通过实验证明，PINNs在此条件下确实可以实现低于$\sigma^2$的经验风险。作为案例研究，我们探讨了PINNs在Hamilton--Jacobi--Bellman（HJB）PDE中的应用。这些发现为定量理解噪声条件下训练PINNs的参数需求奠定了基础。

</details>


### [187] [Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy](https://arxiv.org/abs/2507.06969)
**中文标题：Error**

*Bogdan Kulynych,Juan Felipe Gomez,Georgios Kaissis,Jamie Hayes,Borja Balle,Flavio du Pin Calmon,Jean Louis Raisaro*

主要分类: cs.LG

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [188] [Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing](https://arxiv.org/abs/2507.06996)
**中文标题：从潜在空间生成多表时间序列电子健康记录：最小预处理方法**

*Eunbyeol Cho,Jiyoun Kim,Minjae Lee,Sungjin Park,Edward Choi*

主要分类: cs.LG

摘要简述: 本文提出RawMed框架，首次生成多表时间序列电子健康记录（EHR）数据，无需复杂预处理，并通过新评估框架验证其高保真度和实用性。


<details>
  <summary>详细信息</summary>
研究动机: 电子健康记录（EHR）是医疗研究和应用的重要资源，但隐私和监管限制阻碍了其共享和使用。现有方法仅生成专家选择的特征，无法模拟原始EHR的复杂结构和时间动态。

研究方法: RawMed采用基于文本的表示和压缩技术，以最小预处理生成多表时间序列EHR数据，并提出新评估框架，从分布相似性、表间关系、时间动态和隐私四方面评估合成数据。

研究结果: 在两个开源EHR数据集上验证，RawMed在保真度和实用性上优于基线模型。

研究结论: RawMed是首个能够生成接近原始EHR的多表时间序列数据的框架，为医疗数据共享和研究提供了新工具。

中文摘要: 电子健康记录（EHR）是记录患者互动和医疗事件的时间序列关系数据库，是医疗研究和应用的关键资源。然而，隐私问题和监管限制阻碍了此类敏感数据的共享和使用，因此需要生成合成EHR数据集。与以往仅生成专家选择特征（如少数生命体征或结构化代码）的EHR合成方法不同，我们提出了RawMed，这是首个生成多表时间序列EHR数据的框架，其数据与原始EHR高度相似。通过基于文本的表示和压缩技术，RawMed以最小预处理捕捉复杂结构和时间动态。我们还提出了一个新的多表时间序列合成EHR评估框架，评估分布相似性、表间关系、时间动态和隐私。在两个开源EHR数据集上验证，RawMed在保真度和实用性上优于基线模型。代码可在https://github.com/eunbyeol-cho/RawMed获取。

</details>


### [189] [PLAME: Leveraging Pretrained Language Models to Generate Enhanced Protein Multiple Sequence Alignments](https://arxiv.org/abs/2507.07032)
**中文标题：PLAME：利用预训练语言模型生成增强的蛋白质多序列比对**

*Hanqun Cao,Xinyi Zhou,Zijun Gao,Chenyu Wang,Xin Gao,Zhi Zhang,Chunbin Gu,Ge Liu,Pheng-Ann Heng*

主要分类: cs.LG

摘要简述: PLAME利用预训练蛋白质语言模型生成增强的多序列比对（MSA），显著提升低同源性和孤儿蛋白质的结构预测性能，并在AlphaFold2和AlphaFold3上实现最优表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前蛋白质结构预测模型（如AlphaFold）高度依赖多序列比对（MSA），但在低同源性和孤儿蛋白质中，MSA信息稀缺或缺失，限制了预测效果。PLAME旨在通过预训练语言模型增强MSA，解决这一问题。

研究方法: PLAME结合预训练蛋白质语言模型的进化嵌入，引入保护-多样性损失函数提升生成质量，并提出新型MSA筛选方法和序列质量评估指标。

研究结果: 在低同源性和孤儿蛋白质的AlphaFold2基准测试中，PLAME在结构预测增强和序列质量评估上达到最优性能，并在AlphaFold3中表现一致提升。消融实验验证了MSA筛选方法的有效性。

研究结论: PLAME不仅显著提升蛋白质结构预测性能，还可作为适配器，以ESMFold的推理速度实现AlphaFold2级别的准确性。

中文摘要: 蛋白质结构预测对药物发现和生物功能理解至关重要。尽管AlphaFold等最新进展取得了显著准确性，但大多数折叠模型仍高度依赖多序列比对（MSA）以提升预测性能。这种依赖性限制了其在MSA信息稀疏或缺失的低同源性蛋白质和孤儿蛋白质上的效果。为解决这一问题，我们提出PLAME，一种新型MSA设计模型，利用预训练蛋白质语言模型的进化嵌入。与现有方法不同，PLAME引入预训练表示以增强进化信息，并采用保护-多样性损失提升生成质量。此外，我们提出一种新型MSA筛选方法，有效筛选高质量MSA并提升折叠性能。我们还提出一种序列质量评估指标，为MSA质量提供正交视角。在AlphaFold2的低同源性和孤儿蛋白质基准测试中，PLAME在折叠增强和序列质量评估上达到最优性能，并在AlphaFold3中表现一致提升。消融实验验证了MSA筛选方法的有效性，而对多种蛋白质类型的案例研究揭示了AlphaFold预测质量与MSA特性之间的关系。此外，我们证明PLAME可作为适配器，以ESMFold的推理速度实现AlphaFold2级别的准确性。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [190] [Graph-based Fake Account Detection: A Survey](https://arxiv.org/abs/2507.06541)
**中文标题：基于图的虚假账户检测：综述**

*Ali Safarpoor Dehkordi,Ahad N. Zehmakan*

主要分类: cs.SI

摘要简述: 本文综述了基于图的虚假账户检测方法，分类讨论了现有技术的优缺点，并探讨了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着在线社交网络中虚假账户问题的日益严重，开发高效检测算法成为研究热点。本文旨在全面回顾基于图的检测方法，为研究者提供系统性的参考。

研究方法: 文章通过分类（如技术类型、输入数据和检测时间）综述了现有基于图的虚假账户检测方法，并结合社交图的拓扑特征和账户信息进行分析。

研究结果: 综述了多种方法的优缺点，探讨了实际数据集和合成模型的应用，并指出了当前技术的局限性。

研究结论: 本文总结了基于图的虚假账户检测的研究现状，并提出了未来可能的改进方向，如算法优化和新数据集的开发。

中文摘要: 近年来，针对在线社交网络中虚假账户检测的高效算法开发日益受到关注。本文全面综述了现有方法，重点讨论了基于图的技术，这些技术利用社交图的拓扑特征（以及账户信息，如共享内容和个人资料数据）来区分虚假账户和真实账户。我们对这些方法进行了多种分类（例如基于技术类型、输入数据和检测时间），讨论了它们的优势和局限性，并解释了这些方法在更广泛背景下的联系。我们还调查了可用的数据集，包括真实数据和合成模型。最后，本文提出了未来研究的几个潜在方向。

</details>


### [191] [Modeling Heterogeneity across Varying Spatial Extents: Discovering Linkages between Sea Ice Retreat and Ice Shelve Melt in the Antarctic](https://arxiv.org/abs/2507.07036)
**中文标题：建模空间异质性：揭示南极海冰退缩与冰架融化之间的关联**

*Maloy Kumar Devnath,Sudip Chakraborty,Vandana P. Janeja*

主要分类: cs.SI

摘要简述: 本文提出了一种名为Spatial-Link的图框架，用于量化空间异质性，揭示南极海冰退缩与冰架融化之间的关联。通过卫星数据构建空间图，发现海冰损失可能引发或加剧下游冰架融化。


<details>
  <summary>详细信息</summary>
研究动机: 南极海冰退缩与冰架融化之间的直接关联尚未充分研究，传统模型将两者视为独立系统，无法捕捉局部关联和级联反馈。本研究旨在填补这一空白。

研究方法: 提出Spatial-Link框架，基于Delaunay三角剖分构建空间图，节点表示显著变化区域，边编码邻近性和方向一致性。通过广度优先搜索和蒙特卡洛模拟提取并验证关联路径。

研究结果: 研究发现海冰退缩与冰架融化之间存在非局部、空间异质性的耦合模式，海冰损失可能引发或放大下游冰架融化。

研究结论: Spatial-Link为量化海冰与冰架关联提供了可扩展的数据驱动工具，有助于改进海平面上升预测和气候适应策略。

中文摘要: 空间现象通常在不同空间范围和邻近区域表现出异质性，这使得建模变得复杂，尤其是在冰架和海冰等动态区域。本研究通过探索海冰退缩与南极冰架（AIS）融化之间的关联来解决这一挑战。尽管大气强迫和基底融化已被广泛研究，但海冰退缩对AIS质量损失的直接影响仍未充分探索。传统模型将海冰和AIS视为独立系统，限制了其捕捉局部关联和级联反馈的能力。为此，我们提出了Spatial-Link，一种基于图的框架，通过量化空间异质性来捕捉海冰退缩与AIS融化之间的关联。我们的方法利用卫星衍生的冰变化矩阵的Delaunay三角剖分构建空间图，其中节点表示显著变化区域，边编码邻近性和方向一致性。通过广度优先搜索和蒙特卡洛模拟提取并统计验证关联路径。结果显示，海冰损失与AIS融化之间存在非局部、空间异质性的耦合模式，表明海冰退缩可能引发或放大下游AIS融化。我们的分析揭示了海冰退缩如何在海洋网格上演化并向冰架推进，从而建立直接关联。据我们所知，这是首次提出将海冰退缩与AIS融化联系起来的方法。Spatial-Link提供了一种可扩展的数据驱动工具，可用于改进海平面上升预测并为气候适应策略提供信息。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [192] [Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain](https://arxiv.org/abs/2507.06273)
**中文标题：狭窄动脉域中生物流体流动的磁辐射建模与人工神经网络优化**

*S P Shivakumar,Gunisetty Ramasekhar,P Nimmy,Sujesh Areekara,L Thanuja,T V Smitha,S Devanathan,Ganesh R Naik,K V Nagaraja*

主要分类: physics.med-ph

摘要简述: 本研究通过磁辐射建模和人工神经网络优化，分析了Casson-Maxwell纳米流体在狭窄动脉域中的流动特性，发现其流速较低，有助于提高药物输送效率。铜和氧化铝纳米颗粒增加热传递率，而银纳米颗粒则降低。皮肤摩擦系数受Maxwell和Casson参数显著影响。


<details>
  <summary>详细信息</summary>
研究动机: 心血管疾病复杂性增加和传统治疗方法的局限性促使开发新型药物输送系统，以实现靶向、高效和可控的治疗，支持联合国可持续发展目标（SDGs）3和9。

研究方法: 研究采用Casson-Maxwell纳米流体模型，结合磁辐射、线性热源和三金属纳米颗粒体积分数，利用Levenberg-Marquardt反向传播训练方案预测热流速率。

研究结果: Casson-Maxwell流体流速较低，有助于延长药物停留时间；铜和氧化铝纳米颗粒提高热传递率，银纳米颗粒则降低；皮肤摩擦系数对Maxwell参数变化最敏感。

研究结论: 研究为心血管疾病治疗提供了新型药物输送系统的理论支持，促进了流体动力学与医疗创新的跨学科合作，支持SDGs 4和17。

中文摘要: 心血管疾病的复杂性和传统治疗方法的局限性要求发明新型药物输送系统，以实现靶向、高效和可控的治疗，直接支持联合国可持续发展目标（SDGs）3和9，推动可持续医疗技术的应用。本研究分析了Casson-Maxwell纳米流体在狭窄动脉域中的流动特性，详细研究了皮肤摩擦和热传递速率等参数。Casson-Maxwell流体的流速低于Casson流体，表明其有助于提高药物输送效率。热传递速率随铜和氧化铝纳米颗粒体积分数的增加而提高，而银纳米颗粒则降低。皮肤摩擦系数在Maxwell参数增加时降低219%，在Casson参数增加时提高66.1%。本研究通过促进流体动力学与医疗创新的跨学科合作，支持SDGs 4和17。此外，利用Levenberg-Marquardt反向传播训练方案，结合磁辐射、线性热源和Casson-Maxwell参数及三金属纳米颗粒体积分数，预测了热流速率（总体R值为0.99457）。还发现阻力系数对Maxwell参数的变化最为敏感。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [193] [MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing](https://arxiv.org/abs/2507.06329)
**中文标题：MixAssist：一个用于音乐混音中协同创作AI辅助的音频-语言数据集**

*Michael Clemens,Ana Marasović*

主要分类: cs.SD

摘要简述: MixAssist是一个音频-语言数据集，专注于音乐混音中的协作对话，旨在填补AI在音乐制作中辅助创作的空白。通过专家与业余制作人的多轮对话，该数据集为训练音频-语言模型提供了独特资源，实验显示Qwen-Audio模型表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI在音乐混音中的研究多集中于端到端自动化，忽视了协作与指导的重要性，尤其是业余制作人的需求。MixAssist旨在填补这一空白，通过记录专家与业余制作人的对话，为开发智能辅助工具提供基础。

研究方法: MixAssist数据集包含431个音频相关的对话轮次，来源于7次深入的音乐混音会话，涉及12名制作人。通过自动评估（如LLM-as-a-judge）和人工专家比较，验证了Qwen-Audio等模型在数据集上的表现。

研究结果: 实验表明，基于MixAssist微调的Qwen-Audio模型在生成有用且上下文相关的混音建议方面显著优于其他模型，验证了数据集的实用性和模型的潜力。

研究结论: MixAssist通过音频语境下的协作指导，为开发支持音乐混音创作的AI助手提供了重要资源，推动了音乐制作中AI辅助工具的发展。

中文摘要: 尽管AI在音乐混音和母带处理中展现出巨大潜力，但当前研究主要关注端到端自动化或生成，忽视了协作和指导在协同创作中的重要性。这一空白使得艺术家，尤其是希望提升技能的业余制作人，未能得到充分支持。为此，我们提出了MixAssist，一个新颖的音频-语言数据集，记录了专家与业余音乐制作人在协作混音会话中的多轮对话。MixAssist包含来自7次深入会话的431个音频相关对话轮次，涉及12名制作人，为训练和评估能够理解并响应真实音乐制作对话复杂性的音频-语言模型提供了独特资源。我们的评估包括自动化的LLM-as-a-judge测试和人工专家比较，结果表明，基于MixAssist微调的Qwen-Audio等模型能够产生显著效果，其中Qwen在生成有帮助且上下文相关的混音建议方面表现尤为突出。通过聚焦于音频语境下的协作指导，MixAssist为开发旨在支持和增强音乐混音创作过程的智能AI助手奠定了基础。

</details>


### [194] [Exploring State-Space-Model based Language Model in Music Generation](https://arxiv.org/abs/2507.06674)
**中文标题：探索基于状态空间模型的语言模型在音乐生成中的应用**

*Wei-Jaw Lee,Fang-Chih Hsieh,Xuanjun Chen,Fang-Duo Tsai,Yi-Hsuan Yang*

主要分类: cs.SD

摘要简述: 本文探索了基于状态空间模型（SSM）的Mamba架构在文本到音乐生成中的应用，发现单层码本可以捕捉音乐语义信息，并展示了SiMBA在有限资源下比Transformer更快收敛且生成更接近真实的结果。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，状态空间模型（SSMs）如Mamba在多个领域展现出替代或补充Transformer的潜力。本文旨在探索Mamba架构在文本到音乐生成中的表现，尤其是其高效性和表达能力。

研究方法: 采用离散的残差向量量化（RVQ）作为建模表示，发现单层码本足以捕捉音乐语义信息。随后，将原本设计为编码器的SiMBA调整为解码器，用于序列建模，并与基于Transformer的解码器进行性能对比。

研究结果: 在有限资源条件下，SiMBA表现出更快的收敛速度，生成的音乐更接近真实数据，展示了SSM在高效且富有表现力的文本到音乐生成中的潜力。

研究结论: 研究表明，基于SSM的SiMBA在文本到音乐生成任务中具有显著优势，尤其是在资源受限的情况下，为未来高效音乐生成模型提供了新思路。

中文摘要: 近年来，状态空间模型（SSMs）的兴起，尤其是Mamba的出现，使其成为Transformer在多领域中的有力替代或补充模块。本文旨在探索基于Mamba架构的文本到音乐生成潜力。我们采用残差向量量化（RVQ）的离散标记作为建模表示，并实证发现单层码本可以捕捉音乐中的语义信息。基于这一观察，我们专注于单码本表示的建模，并将原本设计为Mamba编码器的SiMBA调整为序列建模的解码器，与标准的基于Transformer的解码器进行性能对比。结果表明，在资源有限的条件下，SiMBA实现了更快的收敛速度，生成的输出更接近真实数据。这展示了SSM在高效且富有表现力的文本到音乐生成中的潜力。音频示例已发布在Github上。

</details>


### [195] [Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation](https://arxiv.org/abs/2507.07043)
**中文标题：智能助听器的进展：深度学习在选择性噪声消除中的应用**

*Haris Khan,Shumaila Asif,Hassan Nasir*

主要分类: cs.SD

摘要简述: 本文综述了人工智能在智能助听器中的应用，重点关注深度学习驱动的选择性噪声消除技术，总结了技术进展、挑战及未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 传统助听器基于放大技术，而人工智能的引入使其向智能化和情境感知方向发展。本文旨在评估AI驱动的选择性噪声消除技术的进展，以推动更高效的助听解决方案。

研究方法: 通过系统文献综述，分析了深度学习架构（如卷积循环网络和Transformer）、硬件部署策略、临床验证研究及用户中心设计，总结了从早期机器学习到最新深度网络的演进。

研究结果: 研究发现，最新模型在噪声混响基准测试中实现了18.3 dB的SI-SDR提升，实时处理延迟低于10毫秒，临床效果显著。但仍存在功耗、环境多变性和个性化等挑战。

研究结论: 未来研究需聚焦轻量级模型、持续学习、情境分类及临床转化，以解决硬件-软件协同设计、标准化评估和监管问题，实现全球范围内的变革性助听解决方案。

中文摘要: 人工智能与助听技术的结合标志着从传统放大系统向智能情境感知音频处理的范式转变。本文通过系统文献综述，评估了AI驱动的选择性噪声消除（SNC）技术在助听器中的进展，重点探讨了技术演进、实施挑战及未来研究方向。我们综合了深度学习架构、硬件部署策略、临床验证研究和用户中心设计等方面的发现。综述追溯了从早期机器学习模型到最先进深度网络（如用于实时推理的卷积循环网络和用于高精度分离的Transformer架构）的进展。关键发现包括：最新模型在噪声混响基准测试中实现了18.3 dB的SI-SDR提升，实时处理延迟低于10毫秒，临床效果显著。然而，实验室级模型与实际部署之间仍存在挑战，尤其是功耗限制、环境多变性和个性化问题。研究缺口包括硬件-软件协同设计、标准化评估协议及AI增强助听设备的监管考量。未来工作需优先发展轻量级模型、持续学习、情境分类和临床转化，以实现全球范围内的变革性助听解决方案。

</details>


### [196] [A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering](https://arxiv.org/abs/2507.07046)
**中文标题：基于特征工程的混合深度学习技术在语音情感检测中的新应用**

*Shahana Yasmin Chowdhury,Bithi Banik,Md Tamjidul Hoque,Shreya Banerjee*

主要分类: cs.SD

摘要简述: 本文提出了一种新型混合深度学习技术DCRF-BiLSTM，用于语音情感识别（SER），在多个数据集上表现优异，最高准确率达100%，综合数据集上达到93.76%的准确率。


<details>
  <summary>详细信息</summary>
研究动机: 语音情感识别在人机交互和人工智能领域具有重要意义，但现有研究缺乏对多个基准数据集的综合评估。本文旨在填补这一空白，提出一种通用且鲁棒的模型。

研究方法: 采用DCRF-BiLSTM混合深度学习模型，结合特征工程技术，对RAVDESS、TESS、SAVEE、EmoDB和Crema-D五个数据集进行训练，识别七种情感。

研究结果: 模型在单个数据集上表现优异（RAVDESS 97.83%，SAVEE 97.02%，CREMA-D 95.10%，TESS和EMO-DB 100%），综合数据集（R+T+S）上达到98.82%准确率，首次在五个数据集（R+T+S+C+E）上综合评估，整体准确率为93.76%。

研究结论: DCRF-BiLSTM模型具有鲁棒性和通用性，能够跨数据集高效识别语音情感，为语音情感识别领域提供了新的技术方案。

中文摘要: 如今，语音情感识别（SER）在人机交互（HCI）和人工智能（AI）发展中扮演着重要角色。我们提出的DCRF-BiLSTM模型用于识别七种情感：中性、快乐、悲伤、愤怒、恐惧、厌恶和惊讶，并在五个数据集上进行了训练：RAVDESS（R）、TESS（T）、SAVEE（S）、EmoDB（E）和Crema-D（C）。该模型在单个数据集上表现出色，包括RAVDESS上的97.83%、SAVEE上的97.02%、CREMA-D上的95.10%，以及在TESS和EMO-DB上均达到100%的完美准确率。在组合数据集（R+T+S）上，其准确率达到98.82%，优于此前报道的结果。据我们所知，尚无研究同时评估一个SER模型在所有五个基准数据集（即R+T+S+C+E）上的表现。本文首次引入这种全面组合，并取得了93.76%的显著整体准确率。这些结果证实了DCRF-BiLSTM框架在不同数据集上的鲁棒性和通用性。

</details>


### [197] [Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification](https://arxiv.org/abs/2507.07058)
**中文标题：基于心周期归一化的卷积神经网络与变换器架构在心音图自动分类中的比较分析**

*Martin Sondermann,Pinar Bisgin,Niklas Tschorn,Anja Burmann,Christoph M. Friedrich*

主要分类: cs.SD

摘要简述: 本文比较了两种卷积神经网络（CNN）和两种零样本通用音频变换器（BEATs）在心音图（PCG）自动分类中的表现，发现CNN在性能上优于BEATs，但后者在开发效率上有优势。研究还提出了一种针对个体心率的自定义心周期归一化方法。


<details>
  <summary>详细信息</summary>
研究动机: 心音图（PCG）的自动分类对心血管诊断具有重要意义。本文旨在比较不同神经网络架构（CNN和BEATs）在PCG分类中的表现，并探讨心周期归一化对模型性能的影响，为临床选择提供依据。

研究方法: 研究使用了PhysioNet2022数据集，比较了两种CNN和两种BEATs模型的表现，分别采用固定长度窗口和自定义心周期归一化方法。通过AUROC评估模型性能。

研究结果: 结果显示，固定长度窗口的CNN模型AUROC为79.5%，心周期归一化的CNN模型为75.4%；固定长度窗口的BEATs模型为65.7%，心周期归一化的BEATs模型为70.1%。CNN整体表现更优，但BEATs在开发效率上有优势。

研究结论: 研究表明，心周期归一化策略对模型性能有显著影响。尽管CNN在分类准确性上更优，但BEATs的开发效率更高。研究为临床选择模型提供了平衡准确性和效率的指导。

中文摘要: 心音图（PCG）记录的自动分类是心血管诊断领域的重要进展。本文系统比较了四种模型在心杂音检测中的表现：两种专用卷积神经网络（CNN）和两种零样本通用音频变换器（BEATs），分别采用固定长度窗口和心周期归一化方法。研究使用PhysioNet2022数据集，并引入了一种针对个体心率的心周期归一化方法。结果显示，固定长度窗口的CNN模型AUROC为79.5%，心周期归一化的CNN模型为75.4%；固定长度窗口的BEATs模型为65.7%，心周期归一化的BEATs模型为70.1%。研究指出，生理信号约束（尤其是归一化策略）对模型性能有显著影响。研究为临床选择模型提供了基于证据的指导，强调需平衡准确性和计算效率。尽管专用CNN整体表现更优，但零样本变换器模型在开发效率上可能更具优势（如更快的训练和评估周期），尽管其分类准确性较低。这些发现凸显了自动分类系统在提升心脏诊断和改善患者护理方面的潜力。

</details>


### [198] [Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach](https://arxiv.org/abs/2507.07066)
**中文标题：潜在声学映射用于方向到达估计：一种自监督方法**

*Adrian S. Roman,Iran R. Roman,Juan P. Bello*

主要分类: cs.SD

摘要简述: 本文提出了一种自监督的潜在声学映射（LAM）模型，用于方向到达估计（DoAE），结合了传统方法的可解释性和深度学习的适应性，在多种声学条件下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统波束形成方法计算复杂且对声学变化敏感，而监督深度学习方法需要大量标注数据且缺乏可解释性。两者在多样声学环境和阵列配置中泛化能力有限，因此需要一种兼具可解释性和适应性的新方法。

研究方法: LAM是一种自监督框架，通过生成高分辨率声学映射，适应不同声学条件和麦克风阵列配置，无需大量标注数据。

研究结果: 在LOCATA和STARSS基准测试中，LAM的定位性能与现有监督方法相当或更优，其声学映射还可作为监督模型的有效特征，进一步提升DoAE精度。

研究结论: LAM模型结合了传统方法和深度学习的优势，为自适应高性能声音定位系统提供了新的可能性。

中文摘要: 声学映射技术长期以来用于空间音频处理中的方向到达估计（DoAE）。传统的波束形成方法虽然可解释，但依赖迭代求解器，计算量大且对声学变化敏感。而最近的监督深度学习方法具有前馈速度和鲁棒性，但需要大量标注数据且缺乏可解释性。尽管各有优势，这两种方法在多样声学环境和阵列配置中泛化能力有限。我们提出了潜在声学映射（LAM）模型，一种自监督框架，结合了传统方法的可解释性和深度学习方法的适应性与效率。LAM生成高分辨率声学映射，适应不同声学条件，并在多种麦克风阵列中高效运行。我们在LOCATA和STARSS基准测试中评估其鲁棒性。LAM的定位性能与现有监督方法相当或更优。此外，LAM的声学映射可作为监督模型的有效特征，进一步提升DoAE精度，展示了其在推动自适应高性能声音定位系统方面的潜力。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [199] [DS@GT at CheckThat! 2025: Exploring Retrieval and Reranking Pipelines for Scientific Claim Source Retrieval on Social Media Discourse](https://arxiv.org/abs/2507.06563)
**中文标题：DS@GT在CheckThat! 2025：探索社交媒体话语中科学声明来源检索的检索与重排流程**

*Jeanette Schofield,Shuyu Tian,Hoang Thanh Thanh Truong,Maximilian Heil*

主要分类: cs.IR

摘要简述: DS@GT团队在CLEF 2025 CheckThat! Lab Task 4b中探索了6种数据增强技术和7种检索与重排流程，并微调了双编码器模型，最终在30支团队中排名第16，MRR@5为0.58，较基线BM25提升0.15。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体用户常发表未经引用的科学声明，需验证其来源。本研究旨在通过推文中的隐含引用检索相关科学论文。

研究方法: 团队尝试了6种数据增强技术、7种检索与重排流程，并微调了一个双编码器模型。

研究结果: 在CLEF 2025 CheckThat! Lab Task 4b中，团队MRR@5为0.58，排名第16，较基线BM25（0.43）提升0.15。

研究结论: 研究展示了数据增强和检索流程优化在科学声明来源检索中的有效性，代码已开源。

中文摘要: 社交媒体用户常发表未经引用的科学声明，需验证其来源。本文详述了DS@GT团队在CLEF 2025 CheckThat! Lab Task 4b（科学声明来源检索）中的工作，旨在通过推文中的隐含引用检索相关科学论文。团队探索了6种数据增强技术、7种检索与重排流程，并微调了双编码器模型。最终MRR@5为0.58，在30支团队中排名第16，较基线BM25（0.43）提升0.15。代码已发布于GitHub：https://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4b。

</details>


### [200] [GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models](https://arxiv.org/abs/2507.06507)
**中文标题：GR-LLMs：基于大语言模型的生成式推荐最新进展**

*Zhen Yang,Haitao Lin,Jiawei xue,Ziji Zhang*

主要分类: cs.IR

摘要简述: 本文综述了基于大语言模型（LLMs）的生成式推荐（GR）的最新进展，探讨了其应用场景、工业实践中的关键问题及未来发展方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型在序列建模和推理能力上的突破，生成式推荐展现出替代传统推荐系统的潜力。本文旨在为基于LLM的GR研究提供全面综述，推动该领域的进一步发展。

研究方法: 首先概述基于LLM的GR的基本原理和应用案例，随后分析其在工业场景中的主要考量，最后探讨未来的研究方向。

研究结果: 本文系统梳理了LLM-based GR的研究现状，总结了实际应用中的关键问题，并提出了未来发展的潜在方向。

研究结论: 本文为基于LLM的生成式推荐领域提供了全面的调研，有助于推动该领域的持续创新。

中文摘要: 过去一年中，生成式推荐（GRs）取得了显著进展，尤其是通过利用大语言模型（LLMs）强大的序列建模和推理能力，提升了整体推荐性能。基于LLM的GRs正在形成一种与判别式推荐截然不同的新范式，展现出替代依赖复杂手工特征的传统推荐系统的强大潜力。本文旨在提供一份全面的综述，以促进基于LLM的GRs的进一步研究。首先，我们概述了基于LLM的GRs的基本原理和应用案例；随后，介绍了其在真实工业场景中的主要考量；最后，探讨了基于LLM的GRs的未来发展方向。我们希望这份综述能够为GR领域的持续发展做出贡献。

</details>


### [201] [Temporal Information Retrieval via Time-Specifier Model Merging](https://arxiv.org/abs/2507.06782)
**中文标题：通过时间指示符模型合并实现时序信息检索**

*SeungYoon Han,Taeho Hwang,Sukmin Cho,Soyeong Jeong,Hoyun Song,Huije Lee,Jong C. Park*

主要分类: cs.IR

摘要简述: 本文提出了一种名为时间指示符模型合并（TSM）的新方法，旨在提升带有时间约束的信息检索性能，同时保持非时间查询的准确性。实验证明TSM在时间约束查询上表现优异，且不影响非时间查询的效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着数字信息的快速增长，信息检索（IR）的重要性日益凸显。然而，现有密集检索方法在处理带有明确时间约束的查询（如“2015年”）时表现不佳，且容易因灾难性遗忘而影响非时间查询的性能。因此，需要一种既能提升时间检索能力，又不损害非时间查询性能的方法。

研究方法: 本文提出时间指示符模型合并（TSM）方法，通过为单个时间指示符训练专用检索器，并将它们合并为一个统一模型，从而精确处理时间约束，同时保留非时间检索的准确性。

研究结果: 实验结果表明，TSM在时间约束查询上显著优于基线方法，同时在非时间查询上保持了强大的性能。

研究结论: TSM是一种有效的方法，能够显著提升时间约束查询的检索性能，同时避免对非时间查询的负面影响，为信息检索领域提供了新的解决方案。

中文摘要: 数字信息和知识在结构化和非结构化来源中的快速扩展，凸显了信息检索（IR）的重要性。尽管密集检索方法在一般查询的语义匹配上取得了显著进展，但在带有明确时间约束的查询（如包含数字表达式和时间指示符的“2015年”）上表现不佳。现有的时序信息检索（TIR）方法虽然改进了时间推理能力，但往往因灾难性遗忘而导致非时间查询性能下降。为此，我们提出了时间指示符模型合并（TSM），这是一种新颖的方法，能够在提升时间检索能力的同时，保持非时间查询的准确性。TSM为单个时间指示符训练专用检索器，并将它们合并为一个统一模型，从而实现对时间约束的精确处理，同时不影响非时间检索。在时间和非时间数据集上的大量实验表明，TSM在时间约束查询上显著优于其他基线方法，同时在非时间查询上保持了强大的性能。我们的代码可在https://github.com/seungyoonee/TSM获取。

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [202] [An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models](https://arxiv.org/abs/2507.06399)
**中文标题：AI驱动的先进小型模块化反应堆热流体测试平台：数字孪生与大型语言模型的集成**

*Doyeong Lim,Yang Liu,Zavier Ndum Ndum,Christian Young,Yassin Hassan*

主要分类: eess.SY

摘要简述: 本文提出了一种多用途AI驱动的热流体测试平台，通过结合物理实验与先进计算智能，推动小型模块化反应堆技术的发展。平台整合了高保真数字孪生和AI框架，实现实时预测、控制和操作辅助。


<details>
  <summary>详细信息</summary>
研究动机: 小型模块化反应堆技术需要更高效的建模和控制方法，以加速其创新和部署。本文旨在通过AI驱动的热流体测试平台，填补物理实验与计算智能之间的鸿沟。

研究方法: 测试平台的数字孪生基于系统分析模块代码，结合门控循环单元（GRU）神经网络，利用实验数据进行训练，实现超实时仿真。AI控制框架和大型语言模型提供预测和操作支持。

研究结果: GRU模型的温度预测均方根误差为1.42 K，验证了平台的高保真性。案例研究展示了AI在系统状态预测和控制中的有效性。

研究结论: 本文建立了一个AI与热流体科学结合的研究环境，展示了AI在建模、控制和操作支持中的潜力，为下一代核系统的创新和部署提供了加速路径。

中文摘要: 本文提出了一种多用途人工智能（AI）驱动的热流体测试平台，旨在通过无缝集成物理实验与先进计算智能，推动小型模块化反应堆技术的发展。该平台独特地结合了多功能三回路热流体设施、高保真数字孪生和复杂的AI框架，实现实时预测、控制和操作辅助。方法上，测试平台的数字孪生基于系统分析模块代码，并与门控循环单元（GRU）神经网络耦合。该机器学习模型通过实验数据训练，能够实现超实时仿真，提供系统动态行为的预测性洞察。通过案例研究展示了AI集成的实际应用，其中GRU模型准确预测未来系统状态及满足操作需求所需的控制动作。此外，由大型语言模型驱动的智能助手将复杂的传感器数据和仿真输出转化为自然语言，为操作员提供可操作的分析和安全建议。通过对实验瞬态的全面验证，平台的高保真性得到确认，GRU模型的温度预测均方根误差为1.42 K。这项工作在AI与热流体科学的交叉领域建立了一个集成研究环境，展示了AI驱动的建模、控制和操作支持方法如何加速下一代核系统的创新和部署。

</details>


### [203] [A Single-Point Measurement Framework for Robust Cyber-Attack Diagnosis in Smart Microgrids Using Dual Fractional-Order Feature Analysis](https://arxiv.org/abs/2507.06890)
**中文标题：基于双分数阶特征分析的智能微电网鲁棒网络攻击诊断单点测量框架**

*Yifan Wang*

主要分类: eess.SY

摘要简述: 本文提出了一种基于双分数阶特征分析的智能微电网单点测量框架（FO-MADS），用于高效检测和定位网络攻击，仅需单个VPQ传感器即可实现高精度诊断。


<details>
  <summary>详细信息</summary>
研究动机: 现有智能微电网的网络攻击诊断方法依赖昂贵的多点测量或严格的建模假设，难以在单传感器条件下实现。本文旨在开发一种低成本、高鲁棒性的单点测量解决方案。

研究方法: FO-MADS通过结合Caputo和Grünwald-Letnikov导数构建双分数阶特征库，放大信号中的微扰动和慢漂移。采用两阶段分层分类器定位受影响的逆变器和故障IGBT开关，并通过渐进记忆重放对抗训练（PMR-AT）增强鲁棒性。

研究结果: 在四逆变器微电网测试中，FO-MADS对四种攻击场景的诊断准确率分别为96.6%（偏置）、94.0%（噪声）、92.8%（数据替换）和95.7%（重放），无攻击条件下保持96.7%的准确率。

研究结论: FO-MADS是一种低成本、易部署的解决方案，显著提升了智能微电网的网络安全性和物理韧性。

中文摘要: 网络攻击威胁智能微电网的安全运行，而现有诊断方法依赖昂贵的多点测量或严格的建模假设，难以在单传感器条件下实现。本文提出了一种分数阶记忆增强攻击诊断方案（FO-MADS），仅需一个VPQ（电压-功率-无功功率）传感器即可实现低延迟故障定位和网络攻击检测。FO-MADS通过联合应用Caputo和Grünwald-Letnikov导数构建双分数阶特征库，放大VPQ信号中的微扰动和慢漂移。随后，采用两阶段分层分类器精确定位受影响的逆变器并隔离故障IGBT开关，有效缓解类别不平衡问题。通过渐进记忆重放对抗训练（PMR-AT）进一步增强了鲁棒性，其攻击感知损失通过在线硬样本挖掘（OHEM）动态重加权，优先处理最具挑战性的样本。在包含1个正常类和24个故障类的四逆变器微电网测试平台上，FO-MADS在四种攻击场景下的诊断准确率分别为96.6%（偏置）、94.0%（噪声）、92.8%（数据替换）和95.7%（重放），无攻击条件下保持96.7%的准确率。这些结果表明，FO-MADS是一种成本效益高且易于部署的解决方案，显著提升了智能微电网的网络安全性和物理韧性。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [204] [Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice](https://arxiv.org/abs/2507.06235)
**中文标题：超级可爱的声音学：增强计算机声音中的“可爱”因素**

*Yuto Mandai,Katie Seaborn,Tomoyasu Nakano,Xin Sun,Yijia Wang,Jun Kato*

主要分类: cs.HC

摘要简述: 本文探索了声音中的“可爱”元素（kawaii），通过调整基频和共振峰频率，找到声音的“可爱点”，并验证了初步的kawaii声音模型。


<details>
  <summary>详细信息</summary>
研究动机: “可爱”（kawaii）是日本文化中的重要概念，但现有研究多集中于视觉层面，声音领域的探索较少。本文旨在填补这一空白，研究如何通过声音传递“可爱”感。

研究方法: 研究分为四个阶段（总样本量N=512），使用两种计算机声音（文本转语音和游戏角色声音），通过调整基频和共振峰频率，探索声音的“可爱”效果。

研究结果: 研究发现某些声音在特定基频和共振峰频率下能表现出“可爱”效果，但存在上限效应。初步验证了kawaii声音模型的有效性。

研究结论: 本文为声音中的“可爱”研究提供了实证支持，并提出了一种调整计算机声音“可爱”感的基本方法。

中文摘要: “可爱”（kawaii）是日本文化中与社交身份和情感反应相关的概念，但现有研究多集中于视觉层面。为探索声音中的“可爱”元素及其调控方法，我们进行了四阶段研究（总样本量N=512），使用文本转语音和游戏角色声音。通过调整基频和共振峰频率，我们发现了声音的“可爱点”，但仅适用于某些声音且效果有限。研究还表明某些声音的“可爱”效果存在上限。我们验证了初步的kawaii声音模型，并提出了一种调整计算机声音“可爱”感的基本方法。

</details>


### [205] [Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents](https://arxiv.org/abs/2507.06483)
**中文标题：用Jouzu学习日语：与风格化对话虚构代理的互动结果**

*Zackary Rackauckas,Julia Hirschberg*

主要分类: cs.HC

摘要简述: 本研究探讨了动漫风格的多模态语言学习环境中，语音代理如何影响用户互动。通过混合方法评估54名参与者与基于大型语言模型和文本转语音合成的角色互动，发现代理设计（如声音、人设和语言风格）显著影响用户体验和学习动机。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索动漫风格的语音代理在多模态语言学习环境中的互动效果，尤其是代理设计对用户参与度、情感反应和学习行为的影响。

研究方法: 研究方法采用混合方法评估，54名参与者与基于大型语言模型和文本转语音合成的动漫风格角色互动，分析用户参与模式、感知可用性、情感反应和学习行为。

研究结果: 研究结果显示，代理的声音、人设和语言风格显著影响用户体验和学习动机，不同语言水平和文化背景的用户互动模式存在差异。

研究结论: 研究结论表明，情感化和文化风格化的代理设计能提升人机互动体验，为设计更具吸引力和社交响应性的系统提供了指导。

中文摘要: 本研究探讨了在多模态语言学习环境中，风格化、语音化的代理如何影响用户互动。我们采用混合方法评估了54名参与者与基于大型语言模型和表达性文本转语音合成的动漫风格角色的互动。这些代理以日语角色语言回应，为用户提供异步、半结构化的对话，涵盖不同语言风格和情感语调。我们分析了用户参与模式、感知可用性、情感反应和学习行为，特别关注代理风格化对不同语言水平和文化背景用户互动的影响。研究发现，代理设计（尤其是声音、人设和语言风格）显著影响用户体验、动机和学习策略。本研究为理解情感化和文化风格化代理在人机互动中的作用提供了见解，并为设计更具吸引力和社交响应性的系统提供了指导。

</details>


### [206] [Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool](https://arxiv.org/abs/2507.06734)
**中文标题：公民社会参与循环：开源Telegram监控工具中基于反馈的（L）LM辅助分类自适应**

*Milena Pustet,Elisabeth Steffen,Helena Mihaljević,Grischa Stanjek,Yannis Illies*

主要分类: cs.HC

摘要简述: 本文探讨了公民社会组织（CSO）如何通过反馈驱动的AI工具开发，参与开源Telegram监控工具的改进，以更有效地监测有害内容。


<details>
  <summary>详细信息</summary>
研究动机: 随着平台减少内容审核投入，公民社会组织在监测有害内容中的作用日益重要。然而，开源工具中AI模型与社交媒体监控的整合不足，且CSO通常仅作为工具使用者而非共同开发者。本文旨在探索如何让CSO成为技术开发的积极参与者。

研究方法: 通过与CSO合作，开发一个开源Telegram监控工具，利用AI辅助分类有害内容，并引入CSO的反馈机制以优化模型。

研究结果: 目前工具仍在开发中，但初步合作表明CSO的参与能显著提升模型的实用性和对有害内容的识别能力。

研究结论: CSO的深度参与是开发实用AI工具的关键，未来需加强开源社区、学术界与公民社会的合作。

中文摘要: 公民社会组织（CSO）在监测有害网络内容中的作用日益重要，尤其是在平台提供商减少内容审核投入的情况下。AI工具可以大规模协助检测和监测有害内容，但很少有开源工具能够无缝整合AI模型与社交媒体监控基础设施。鉴于CSO对有害内容的主题专业知识和背景理解，他们应成为技术开发的积极合作伙伴，提供反馈、帮助改进模型，并确保工具符合利益相关者的需求和价值观，而非仅作为被动“消费者”。然而，开源社区、学术界与公民社会之间的合作仍较少，关于有害内容的研究也鲜少转化为公民社会可用的实用工具。这项进行中的工作探讨了如何让CSO有意义地参与一个AI辅助的开源Telegram监控工具的开发，该工具旨在监测反民主运动，目前正与CSO利益相关者合作开发。

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [207] [Machine Learning based Enterprise Financial Audit Framework and High Risk Identification](https://arxiv.org/abs/2507.06266)
**中文标题：基于机器学习的企业财务审计框架与高风险识别**

*Tingyu Yuan,Xi Zhang,Xuanjing Chen*

主要分类: q-fin.RM

摘要简述: 本研究提出了一种基于机器学习的财务审计框架，通过随机森林算法高效识别高风险案例，提升审计准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 面对全球经济不确定性，传统财务审计方法因数据量大、业务结构复杂和欺诈手段多样化而受限，亟需AI驱动的解决方案。

研究方法: 研究使用四大会计事务所2020-2025年的数据集，评估支持向量机、随机森林和K近邻算法，通过分层K折交叉验证和F1分数等指标选择最优模型。

研究结果: 随机森林表现最佳，F1分数达0.9012，能有效识别欺诈和合规异常；审计频率、历史违规、员工工作量和客户评分是关键预测因素。

研究结论: 建议采用随机森林为核心模型，结合特征工程和实时风险监控，推动智能审计和风险管理在现代企业中的应用。

中文摘要: 面对全球经济不确定性，财务审计对合规监管和风险控制至关重要。传统人工审计方法因数据量大、业务结构复杂和欺诈手段多样化而受限。本研究提出了一种基于AI的企业财务审计和高风险识别框架，利用机器学习提升效率和准确性。研究采用四大会计事务所（EY、PwC、德勤、KPMG）2020-2025年的数据集，分析风险评估、合规违规和欺诈检测趋势。数据集涵盖审计项目数量、高风险案例、欺诈实例、合规违规、员工工作量和客户满意度等关键指标，反映审计行为及AI对运营的影响。为构建稳健的风险预测模型，评估了支持向量机（SVM）、随机森林（RF）和K近邻（KNN）三种算法。SVM通过超平面优化实现复杂分类，RF结合决策树处理高维非线性数据并抗过拟合，KNN基于距离学习表现灵活。通过分层K折交叉验证和F1分数、准确率、召回率评估，随机森林表现最佳，F1分数达0.9012，在识别欺诈和合规异常方面表现突出。特征重要性分析显示，审计频率、历史违规、员工工作量和客户评分是关键预测因素。研究建议采用随机森林为核心模型，通过特征工程优化，并实施实时风险监控。本研究为现代企业利用机器学习实现智能审计和风险管理提供了重要见解。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [208] [Conformal Prediction for Long-Tailed Classification](https://arxiv.org/abs/2507.06867)
**中文标题：长尾分类的保形预测**

*Tiffany Ding,Jean-Baptiste Fermanian,Joseph Salmon*

主要分类: stat.ML

摘要简述: 本文提出了一种针对长尾分类问题的改进型保形预测方法，通过平衡预测集大小和类别条件覆盖，解决了现有方法在长尾分布中表现不佳的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的分类问题（如植物识别）通常具有极端的长尾类别分布。现有保形预测方法在长尾设置下无法同时保证预测集的小规模和良好的类别条件覆盖，迫使用户做出二选一的妥协。本文旨在解决这一问题。

研究方法: 1. 提出了一种新的保形评分函数“流行度调整的softmax”，以针对宏观覆盖这一宽松的类别条件覆盖概念。2. 提出了一种标签加权的保形预测方法，能够在边际保形预测和类别条件保形预测之间进行平滑插值。

研究结果: 在Pl@ntNet和iNaturalist两个长尾图像数据集（分别包含1,081和8,142个类别）上的实验表明，所提方法能够有效平衡预测集大小和类别条件覆盖。

研究结论: 本文提出的方法在长尾分类问题中实现了预测集大小和类别条件覆盖之间的灵活权衡，为实际应用提供了更实用的解决方案。

中文摘要: 许多现实世界中的分类问题（如植物识别）具有极端的长尾类别分布。为了使预测集在此类设置中有用，它们应满足：（i）提供良好的类别条件覆盖，确保稀有类别不会被系统性地排除在预测集之外；（ii）保持合理的规模，便于用户验证候选标签。然而，现有的保形预测方法在长尾设置中迫使实践者在“小规模但类别条件覆盖差”和“类别条件覆盖好但规模极大”之间做出二选一的选择。我们提出了具有保证边际覆盖的方法，能够平滑权衡预测集大小和类别条件覆盖。首先，我们提出了一种保形评分函数——流行度调整的softmax，以针对宏观覆盖这一宽松的类别条件覆盖概念。其次，我们提出了一种标签加权的保形预测方法，能够在边际和类别条件保形预测之间进行插值。我们在Pl@ntNet和iNaturalist两个长尾图像数据集（分别包含1,081和8,142个类别）上验证了所提方法的有效性。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [209] [3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds](https://arxiv.org/abs/2507.06484)
**中文标题：3D-Generalist：用于构建3D世界的自改进视觉-语言-动作模型**

*Fan-Yun Sun,Shengguang Wu,Christian Jacobsen,Thomas Yim,Haoming Zou,Alex Zook,Shangru Li,Yu-Hsin Chou,Ethem Can,Xunlei Wu,Clemens Eppner,Valts Blukis,Jonathan Tremblay,Jiajun Wu,Stan Birchfield,Nick Haber*

主要分类: cs.GR

摘要简述: 本文提出了一种名为3D-Generalist的可扩展方法，通过自改进微调训练视觉语言模型（VLM），生成高质量的3D环境作为基础模型的训练数据，并在下游任务中表现优于人工合成的数据。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大规模预训练赋予了模型语言和视觉推理能力，但由于缺乏基于3D世界的数据，提升其空间推理能力仍具挑战性。人工创建沉浸式3D环境（如VR、游戏和机器人应用）耗时费力，因此需要一种可扩展的方法来自动生成高质量的3D环境数据。

研究方法: 将3D环境构建重新定义为序列决策问题，利用视觉语言模型（VLM）作为策略输出动作，共同设计3D环境的布局、材质、光照和资产。通过自改进微调框架3D-Generalist，训练VLM生成更符合提示的3D环境。

研究结果: 3D-Generalist在生成仿真就绪的3D环境方面表现出色，其生成的数据用于预训练视觉基础模型后，在下游任务中超越了基于人工合成数据预训练的模型，并接近更大规模真实数据的结果。

研究结论: 3D-Generalist提供了一种可扩展的方法，能够高效生成高质量的3D环境数据，显著提升了基础模型在3D空间推理任务中的表现，为未来3D应用的发展奠定了基础。

中文摘要: 尽管大规模预训练赋予了模型语言和视觉推理能力，但由于缺乏基于3D世界的数据，提升其空间推理能力仍具挑战性。虽然人类可以通过3D图形手动创建沉浸式和交互式世界（如VR、游戏和机器人应用），但这一过程仍然高度依赖人工。本文提出了一种可扩展的方法，用于生成高质量的3D环境作为基础模型的训练数据。我们将3D环境构建重新定义为序列决策问题，利用视觉语言模型（VLM）作为策略输出动作，共同设计3D环境的布局、材质、光照和资产。我们提出的框架3D-Generalist通过自改进微调训练VLM生成更符合提示的3D环境。我们展示了3D-Generalist和所提出的训练策略在生成仿真就绪3D环境方面的有效性。此外，通过在生成数据上预训练视觉基础模型，我们证明了其在合成数据生成中的质量和可扩展性。经过在下游任务上微调预训练模型后，其表现超越了基于人工合成数据预训练的模型，并接近更大规模真实数据的结果。

</details>


### [210] [Enhancing non-Rigid 3D Model Deformations Using Mesh-based Gaussian Splatting](https://arxiv.org/abs/2507.07000)
**中文标题：基于网格的高斯泼溅增强非刚性3D模型变形**

*Wijayathunga W. M. R. D. B*

主要分类: cs.GR

摘要简述: 本文提出了一种新颖框架，通过将网格表示与3D高斯泼溅结合，增强了非刚性3D模型的变形能力，支持直观编辑和复杂变形。


<details>
  <summary>详细信息</summary>
研究动机: 传统高斯泼溅虽能实现快速的实时辐射场渲染，但其后编辑功能和对大规模非刚性变形的支持有限。本文旨在解决这些问题，为虚拟现实、角色动画等应用提供更灵活的3D内容创作流程。

研究方法: 该方法将高斯核直接嵌入到显式网格表面，利用网格的拓扑和几何先验指导直观的编辑操作（如移动、缩放、旋转），并支持弯曲和拉伸等复杂变形。

研究结果: 实验表明，该方法能够实现高效的非刚性变形，同时保持编辑的直观性和灵活性，适用于多种3D内容创作场景。

研究结论: 本文提出的框架为3D内容创作提供了更灵活的工具，特别是在非刚性变形和直观编辑方面具有显著优势，为虚拟现实和动画设计等领域开辟了新途径。

中文摘要: 我们提出了一种新颖框架，通过将网格表示与3D高斯泼溅结合，增强了非刚性3D模型的变形能力。传统高斯泼溅虽能实现快速的实时辐射场渲染，但其后编辑功能和对大规模非刚性变形的支持有限。我们的方法通过将高斯核直接嵌入到显式网格表面，利用网格的拓扑和几何先验指导直观的编辑操作（如移动、缩放、旋转），并支持弯曲和拉伸等复杂变形。这一工作为虚拟现实、角色动画和交互设计等应用中的3D内容创作流程提供了更大的灵活性。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [211] [DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning](https://arxiv.org/abs/2507.07060)
**中文标题：DeepRetro：基于迭代式LLM推理的反合成路径发现**

*Shreyas Vinaya Sathyanarayana,Rahil Shah,Sharanabasava D. Hiremath,Rishikesh Panda,Rahul Jana,Riya Singh,Rida Irfan,Ashwin Murali,Bharath Ramsundar*

主要分类: q-bio.QM

摘要简述: DeepRetro是一种基于迭代式大型语言模型（LLM）的反合成路径发现框架，结合模板搜索与LLM生成能力，通过动态反馈循环探索和修正合成路径，成功识别复杂分子的新型合成路线。


<details>
  <summary>详细信息</summary>
研究动机: 反合成是合成复杂分子的关键步骤，但传统方法受限于预定义模板，难以发现新型路径。尽管LLM在反合成中表现出潜力，但如何有效利用其多步推理能力仍待解决。

研究方法: DeepRetro采用混合方法，先尝试模板引擎规划合成路径，失败后由LLM提出单步反合成断键建议，并通过有效性、稳定性和幻觉检查后递归反馈，实现动态路径探索。

研究结果: 基准测试和案例研究表明，DeepRetro能识别可行且新颖的反合成路径，并通过交互式界面结合专家反馈，成功生成复杂天然产物的新型合成路线。

研究结论: DeepRetro展示了迭代式LLM推理在复杂化学合成中的潜力，为反合成路径发现提供了创新工具。

中文摘要: 反合成是识别目标化合物前体分子的关键步骤，对合成复杂分子至关重要，但其在发现超越预定义模板的新型路径方面面临挑战。近期基于大型语言模型（LLM）的反合成方法显示出潜力，但如何有效利用LLM推理能力进行多步规划仍是一个开放问题。为解决这一挑战，我们提出了DeepRetro，一种开源的、迭代式、基于LLM的混合反合成框架。该方法将传统模板搜索/蒙特卡洛树搜索工具与LLM的生成能力结合，通过逐步反馈循环实现动态路径探索与修正。初始阶段，系统尝试使用模板引擎规划合成路径；若失败，则由LLM提出单步反合成断键建议。关键的是，这些建议需经过严格的有效性、稳定性和幻觉检查，随后生成的前体分子会递归反馈至流程中进一步评估。我们通过基准测试和案例研究展示了该框架的潜力，证明其能够识别可行且潜在新颖的反合成路径。特别地，我们开发了交互式图形用户界面，允许专家化学家提供人机协同反馈。该方法成功生成了复杂天然产物的新型合成路径，展示了迭代式LLM推理在推动复杂化学合成前沿中的潜力。

</details>


### [212] [PAST: A multimodal single-cell foundation model for histopathology and spatial transcriptomics in cancer](https://arxiv.org/abs/2507.06418)
**中文标题：PAST：一种用于癌症组织病理学和空间转录组学的多模态单细胞基础模型**

*Changchun Yang,Haoyang Li,Yushuai Wu,Yilan Zhang,Yifeng Jiao,Yu Zhang,Rihan Huang,Yuan Cheng,Yuan Qi,Xin Guo,Xin Gao*

主要分类: q-bio.QM

摘要简述: PAST是一种多模态单细胞基础模型，整合组织病理学和空间转录组数据，提升癌症精准医学的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的病理基础模型在癌症图像分析中表现突出，但缺乏与单细胞分子数据的整合，限制了其在精准肿瘤学中的应用。

研究方法: PAST通过联合编码细胞形态和基因表达，训练了一个跨模态的单细胞基础模型，覆盖多种肿瘤类型和组织环境。

研究结果: PAST在单细胞基因表达预测、虚拟分子染色和多模态生存分析等任务中表现优异，优于现有方法。

研究结论: PAST为病理基础模型提供了新范式，支持高分辨率空间组学、机制发现和精准癌症研究。

中文摘要: 尽管病理基础模型已经改变了癌症图像分析，但它们通常缺乏与单细胞分子数据的整合，限制了其在精准肿瘤学中的应用。本文提出了PAST，一种基于2000万对组织病理学图像和单细胞转录组的泛癌单细胞基础模型。通过联合编码细胞形态和基因表达，PAST学习了统一的跨模态表示，捕捉细胞水平的空间和分子异质性。这种方法能够直接从常规病理切片中准确预测单细胞基因表达、进行虚拟分子染色和多模态生存分析。在多种癌症和下游任务中，PAST始终优于现有方法，展示了强大的通用性和可扩展性。我们的工作为病理基础模型建立了新范式，为高分辨率空间组学、机制发现和精准癌症研究提供了多功能工具。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [213] [Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation](https://arxiv.org/abs/2507.06249)
**中文标题：基于联合随机近似的音素跨语言自动语音识别无发音词典训练方法**

*Saierdaer Yusuyin,Te Ma,Hao Huang,Zhijian Ou*

主要分类: eess.AS

摘要简述: 本文提出了一种无需发音词典的音素跨语言自动语音识别方法JSA-SPG，通过联合随机近似算法训练语音到音素、音素到字素和字素到音素模型，显著降低了错误率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的音素跨语言语音识别需要发音词典，限制了其应用。本文旨在消除这一限制，提出一种无需发音词典的方法。

研究方法: 提出了一种基于隐变量模型的方法，将音素视为离散隐变量，包含语音到音素（S2P）、音素到字素（P2G）和字素到音素（G2P）模型，并使用联合随机近似（JSA）算法联合训练。

研究结果: 在波兰语和印尼语实验中，仅需10分钟音素监督，JSA-SPG比最佳跨语言微调方法降低5%错误率；在语言领域适应中，比标准语言模型融合方法降低9%错误率。

研究结论: JSA-SPG方法无需发音词典，显著提升了跨语言语音识别性能，并开源了代码以促进进一步研究。

中文摘要: 近年来，基于音素监督的预训练模型在跨语言语音识别的数据效率和跨语言信息共享方面展现出优势。然而，这类音素跨语言语音识别需要发音词典。本研究旨在消除对发音词典的需求，提出了一种基于隐变量模型的方法，将音素视为离散隐变量。新方法包含语音到音素（S2P）模型和音素到字素（P2G）模型，并引入字素到音素（G2P）模型作为辅助推理模型。为联合训练这三个模型，我们采用联合随机近似（JSA）算法，这是一种随机扩展的EM（期望最大化）算法，在估计离散隐变量模型方面表现优异。基于Whistle多语言预训练的S2P模型，我们在波兰语（130小时）和印尼语（20小时）上进行了跨语言实验。仅需10分钟的音素监督，新方法JSA-SPG比使用子词或完整音素监督的最佳跨语言微调方法降低了5%的错误率。此外，在语言领域适应（即利用跨领域纯文本数据）中，JSA-SPG通过G2P模型的辅助支持，比标准的语言模型融合方法降低了9%的错误率。为促进可重复性和鼓励进一步探索，我们开源了JSA-SPG的训练代码和完整流程。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [214] [X-ray transferable polyrepresentation learning](https://arxiv.org/abs/2507.06264)
**中文标题：X射线可迁移的多表征学习**

*Weronika Hryniewska-Guzik,Przemyslaw Biecek*

主要分类: eess.IV

摘要简述: 论文提出了一种名为‘多表征学习’的新方法，通过整合同一模态的多种表征（如孪生网络的向量嵌入、自监督模型和可解释的放射组学特征），显著提升了机器学习算法的性能，并在X射线图像上验证了其可迁移性。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习算法的成功依赖于有意义的特征提取，而数据表征的质量是关键。然而，如何从未见数据集中有效提取和泛化这些特征同样重要。为此，作者提出了‘多表征’概念，旨在通过整合多种表征提升性能。

研究方法: 论文提出‘多表征学习’，整合来自不同源的同一模态的多种表征（如孪生网络、自监督模型和放射组学特征），并通过X射线图像验证其可迁移性。

研究结果: 实验表明，多表征方法在性能指标上优于单一表征，且在小数据集上具有可迁移性，证明了其在实际应用中的高效性和普适性。

研究结论: 多表征学习是一种高效且资源节约的方法，不仅适用于医学数据，还可推广至其他领域，展示了广泛的潜在影响力。

中文摘要: 机器学习算法的成功与有意义的特征提取密切相关，这些特征对算法性能至关重要。数据表征的质量是这一挑战的核心，而从未见数据集中有效提取和泛化这些特征同样重要。为此，我们提出了一种新概念：多表征。多表征整合了从不同来源提取的同一模态的多种表征，例如来自孪生网络的向量嵌入、自监督模型和可解释的放射组学特征。与依赖单一表征相比，这种方法在性能指标上表现更优。此外，在X射线图像的背景下，我们证明了所创建的多表征在小数据集上的可迁移性，突显了其在各种图像相关解决方案中的实用性和资源效率。值得注意的是，多表征的概念在医学数据上的应用也可以推广至其他领域，展示了其多功能性和广泛的潜在影响。

</details>


### [215] [Photometric Stereo using Gaussian Splatting and inverse rendering](https://arxiv.org/abs/2507.06684)
**中文标题：基于高斯点云和逆向渲染的光度立体视觉**

*Matéo Ducastel,David Tschumperlé,Yvain Quéau*

主要分类: eess.IV

摘要简述: 本文提出了一种基于高斯点云和逆向渲染的光度立体视觉方法，通过更直观的参数化方式优化3D场景重建。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，光度立体视觉的最先进算法依赖于神经网络，通过先验学习或逆向渲染优化实现。本文旨在利用高斯点云形式的最新进展，重新审视校准光度立体视觉问题，以更可解释的方式优化3D场景重建。

研究方法: 本文采用高斯点云形式进行3D逆向渲染，简化了光线表示模型，并展示了高斯点云渲染引擎在光度立体视觉问题中的潜力。

研究结果: 实验结果表明，该方法能够以更直观的方式重建3D场景，验证了高斯点云渲染引擎在光度立体视觉中的有效性。

研究结论: 本文通过高斯点云和逆向渲染的结合，为光度立体视觉提供了一种更可解释的优化方法，展示了其在3D重建中的潜力。

中文摘要: 近年来，光度立体视觉的最先进算法依赖于神经网络，并通过先验学习或逆向渲染优化实现。本文通过利用高斯点云形式在3D逆向渲染中的最新进展，重新审视了校准光度立体视觉问题。这使得我们能够以更可解释的方式参数化待重建的3D场景并进行优化。我们的方法结合了简化的光线表示模型，并展示了高斯点云渲染引擎在光度立体视觉问题中的潜力。

</details>


### [216] [Mamba Goes HoME: Hierarchical Soft Mixture-of-Experts for 3D Medical Image Segmentation](https://arxiv.org/abs/2507.06363)
**中文标题：Mamba迈向HoME：用于3D医学图像分割的分层软混合专家模型**

*Szymon Płotka,Maciej Chrabaszcz,Gizem Mert,Ewa Szczurek,Arkadiusz Sitek*

主要分类: eess.IV

摘要简述: 本文提出了一种名为HoME的分层软混合专家模型，用于高效处理3D医学图像分割任务，通过两级令牌路由层提升长上下文建模能力，显著超越现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管人工智能在医学图像分割领域取得进展，但3D医学图像处理仍面临多模态数据高效处理和变异性数据处理的挑战。本文旨在通过分层软混合专家模型解决这些问题。

研究方法: HoME基于Mamba状态空间模型（SSM），采用两级令牌路由层：第一阶段使用软混合专家（SMoE）层将输入序列分组并路由至局部专家提取特征；第二阶段通过全局SMoE层聚合输出，实现跨组信息融合和全局上下文优化。

研究结果: 实验表明，HoME在三种常用3D医学成像模态的数据集上表现优异，分割性能超越现有最优方法，同时提升了泛化能力。

研究结论: HoME通过分层设计结合局部与全局专家路由，显著提升了3D医学图像分割的性能和泛化性，为多模态数据处理提供了高效解决方案。

中文摘要: 近年来，人工智能显著推动了医学图像分割的发展。然而，高效处理多模态3D医学图像及应对数据变异性仍是挑战。本文提出分层软混合专家模型（HoME），这是一种专为3D医学图像分割设计的两级令牌路由层，用于高效长上下文建模。基于Mamba状态空间模型（SSM）框架，HoME通过稀疏、自适应的专家路由增强序列建模。第一阶段采用软混合专家（SMoE）层将输入序列划分为局部组，并将令牌路由至专门的组内专家以提取局部特征；第二阶段通过全局SMoE层聚合输出，实现跨组信息融合和全局上下文优化。这种结合局部专家路由与全局专家优化的分层设计提升了泛化能力和分割性能，在三种最常用的3D医学成像模态数据集上超越了现有最优结果。

</details>


### [217] [Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection](https://arxiv.org/abs/2507.06384)
**中文标题：通过局部训练的潜在扩散模型进行域适应以缓解多序列3D前列腺MRI数据稀缺问题，用于前列腺癌检测**

*Emerson P. Grabke,Babak Taati,Masoom A. Haider*

主要分类: eess.IV

摘要简述: 论文提出CCELLA++，通过局部训练的潜在扩散模型（LDM）生成多序列前列腺MRI数据，以缓解数据稀缺问题，并提升前列腺癌检测的泛化性能。实验表明，CCELLA++生成的合成数据在域适应任务中优于真实数据。


<details>
  <summary>详细信息</summary>
研究动机: 现有CCELLA模型仅支持轴向T2加权序列（AxT2），未考虑机构间域偏移，且未充分利用组织病理学结果。CCELLA++旨在扩展CCELLA，支持多序列bpMRI生成，并研究域适应问题，以提升临床实用性。

研究方法: CCELLA++扩展CCELLA，支持同时生成包括AxT2、高b值扩散序列（HighB）和表观扩散系数图（ADC）的双参数前列腺MRI（bpMRI）。通过在内部分机构预训练分类器，并在外部数据集上逐步微调，研究域适应效果。

研究结果: CCELLA++显著改善了HighB和ADC序列的3D FID（0.013和0.012），但AxT2序列未提升（0.063）。在域适应任务中，CCELLA++生成的bpMRI在AP和AUC上均优于真实数据，尤其在外部数据集量低于50%（n=665）时表现最佳。

研究结论: CCELLA++生成的合成bpMRI能提升分类器的泛化性能，优于真实数据或仅支持AxT2的CCELLA模型。未来需进一步量化图像质量、平衡多序列训练，并引入更多条件信息。

中文摘要: 目的：潜在扩散模型（LDMs）可缓解医学图像解释中机器学习开发面临的数据稀缺问题。近期CCELLA LDM通过合成MRI提升前列腺癌检测性能，但仅支持AxT2序列，未研究机构间域偏移，且未充分利用组织病理学结果。本文提出CCELLA++以解决这些问题并提升临床实用性。方法：CCELLA++扩展CCELLA，支持同时生成包括AxT2、高b值扩散序列（HighB）和表观扩散系数图（ADC）的双参数前列腺MRI（bpMRI）。通过在内部分机构预训练分类器，并在外部数据集上逐步微调，研究域适应效果。结果：CCELLA++显著改善了HighB和ADC序列的3D FID（0.013和0.012），但AxT2序列未提升（0.063）。在域适应任务中，CCELLA++生成的bpMRI在AP和AUC上均优于真实数据，尤其在外部数据集量低于50%（n=665）时表现最佳。结论：CCELLA++生成的合成bpMRI能提升分类器的泛化性能，优于真实数据或仅支持AxT2的CCELLA模型。未来需进一步量化图像质量、平衡多序列训练，并引入更多条件信息。意义：CCELLA++ LDM生成的合成bpMRI在域适应任务中优于真实数据，尤其适用于目标机构数据集有限的情况。代码见https://github.com/grabkeem/CCELLA-plus-plus。

</details>


### [218] [Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data](https://arxiv.org/abs/2507.06828)
**中文标题：Speckle2Self：无需干净数据的自监督超声斑点降噪**

*Xuesong Li,Nassir Navab,Zhongliang Jiang*

主要分类: eess.IV

摘要简述: Speckle2Self是一种无需干净数据的自监督超声斑点降噪算法，通过多尺度扰动操作分离噪声与解剖结构，显著提升图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 超声图像中的斑点噪声具有组织依赖性，传统方法如Noise2Noise和盲点网络无法有效处理。因此，需要一种仅依赖单次噪声观测的自监督降噪方法。

研究方法: 提出Speckle2Self算法，通过多尺度扰动操作引入组织依赖的斑点变化，同时保留共享的解剖结构，将干净图像建模为低秩信号并分离稀疏噪声。

研究结果: 在模拟和真实人体颈动脉超声图像上，Speckle2Self显著优于传统滤波器和现有学习方法，并展示了良好的跨设备泛化能力。

研究结论: Speckle2Self为超声斑点降噪提供了一种高效的自监督解决方案，无需干净数据且适应性强，具有广泛的应用潜力。

中文摘要: 图像去噪是计算机视觉中的基础任务，尤其在医学超声成像中，斑点噪声显著降低了图像质量。尽管深度神经网络在自然图像去噪中取得了显著进展，但这些方法无法直接应用于超声斑点噪声，因为其并非完全随机，而是由体内微结构的复杂波干涉产生，具有组织依赖性。这种依赖性使得无法像Noise2Noise那样获取同一场景的两次独立噪声观测。此外，盲点网络也无法处理超声斑点噪声的高空间依赖性。为解决这一问题，我们提出了Speckle2Self，一种仅依赖单次噪声观测的自监督斑点降噪算法。其核心思想是通过多尺度扰动操作在不同尺度上引入组织依赖的斑点变化，同时保留共享的解剖结构，从而将干净图像建模为低秩信号并分离稀疏噪声。为验证其有效性，Speckle2Self与传统滤波器和现有学习方法在模拟及真实人体颈动脉超声图像上进行了全面对比。此外，还使用多台超声设备的数据评估了模型对未见域图像的泛化能力和适应性。代码和数据集将在论文录用后公开。

</details>


### [219] [Attention-Enhanced Deep Learning Ensemble for Breast Density Classification in Mammography](https://arxiv.org/abs/2507.06410)
**中文标题：注意力增强的深度学习集成在乳腺X光密度分类中的应用**

*Peyman Sharifian,Xiaotong Hong,Alireza Karimian,Mehdi Amini,Hossein Arabi*

主要分类: eess.IV

摘要简述: 本研究提出了一种基于注意力增强深度学习集成的方法，用于乳腺密度的二分类（低密度A/B vs. 高密度C/D）。通过结合多种先进的卷积神经网络和新型损失函数，系统在VinDr-Mammo数据集上表现出色（AUC: 0.963，F1-score: 0.952），有望标准化临床乳腺密度评估。


<details>
  <summary>详细信息</summary>
研究动机: 乳腺密度评估是乳腺X光检查的关键环节，高密度乳腺（BI-RADS C/D类）不仅是乳腺癌的重要风险因素，还增加了肿瘤检测的技术难度。目前临床评估存在主观性差异，亟需自动化系统提高标准化和准确性。

研究方法: 研究实现了四种卷积神经网络（ResNet18、ResNet50、EfficientNet-B0和DenseNet121），并引入通道注意力机制增强性能。针对类别不平衡问题，提出了一种结合焦点损失、标签平滑和类别平衡权重的新型损失函数。预处理包括CLAHE和数据增强技术，最终通过优化的集成投票方法结合各模型。

研究结果: 系统在VinDr-Mammo数据集上表现优异，AUC达0.963，F1-score为0.952，显著优于单一模型。

研究结论: 该深度学习系统在乳腺密度分类中表现出高效性和鲁棒性，有望减少临床评估的主观差异，提升筛查效率和早期癌症检出率。

中文摘要: 乳腺密度评估是乳腺X光检查的关键环节，高密度乳腺（BI-RADS C/D类）不仅是乳腺癌的重要风险因素，还增加了肿瘤检测的技术难度。本研究提出了一种自动化深度学习系统，用于乳腺密度的二分类（低密度A/B vs. 高密度C/D），基于VinDr-Mammo数据集。我们实现并比较了四种先进的卷积神经网络（ResNet18、ResNet50、EfficientNet-B0和DenseNet121），每种网络均通过通道注意力机制增强。为解决类别不平衡问题，开发了一种结合焦点损失、标签平滑和类别平衡权重的新型损失函数。预处理流程包括CLAHE和全面的数据增强技术。通过优化的集成投票方法结合各模型，系统性能显著优于单一模型（AUC: 0.963，F1-score: 0.952）。该系统有望标准化临床乳腺密度评估，提升筛查效率和早期癌症检出率，同时减少放射科医师之间的主观差异。

</details>


### [220] [Capsule-ConvKAN: A Hybrid Neural Approach to Medical Image Classification](https://arxiv.org/abs/2507.06417)
**中文标题：Capsule-ConvKAN：一种用于医学图像分类的混合神经网络方法**

*Laura Pituková,Peter Sinčák,László József Kovács*

主要分类: eess.IV

摘要简述: 本研究提出了一种新型混合神经网络架构Capsule-ConvKAN，结合了胶囊网络的动态路由和空间层次能力与卷积Kolmogorov-Arnold网络的灵活可解释性，用于提升医学图像分类性能。在组织病理学图像数据集上，该模型以91.21%的准确率表现最优。


<details>
  <summary>详细信息</summary>
研究动机: 传统卷积神经网络在医学图像分类中存在特征表示和分类准确性的局限性。本研究旨在通过结合胶囊网络和卷积Kolmogorov-Arnold网络的优点，开发一种新型混合模型，以更好地捕捉空间模式和复杂特征。

研究方法: 研究比较了四种神经网络架构：卷积神经网络、胶囊网络、卷积Kolmogorov-Arnold网络和提出的Capsule-ConvKAN。Capsule-ConvKAN结合了胶囊网络的动态路由和空间层次能力，以及卷积Kolmogorov-Arnold网络的灵活函数逼近能力。

研究结果: 在组织病理学图像数据集上的实验表明，Capsule-ConvKAN以91.21%的分类准确率表现最佳，显著优于其他对比模型。

研究结论: Capsule-ConvKAN在医学图像分类中表现出色，能够有效捕捉空间模式和复杂特征，克服了传统卷积模型的局限性，具有广阔的应用潜力。

中文摘要: 本研究对四种神经网络架构进行了全面比较：卷积神经网络、胶囊网络、卷积Kolmogorov-Arnold网络以及新提出的Capsule-ConvKAN。Capsule-ConvKAN结合了胶囊网络的动态路由和空间层次能力与卷积Kolmogorov-Arnold网络的灵活可解释函数逼近能力。这一新型混合模型旨在提升特征表示和分类准确性，尤其是在具有挑战性的真实世界生物医学图像数据中。这些架构在组织病理学图像数据集上进行了评估，其中Capsule-ConvKAN以91.21%的分类准确率表现最优。结果表明，新提出的Capsule-ConvKAN在捕捉空间模式、管理复杂特征以及解决传统卷积模型在医学图像分类中的局限性方面具有潜力。

</details>


### [221] [Airway Segmentation Network for Enhanced Tubular Feature Extraction](https://arxiv.org/abs/2507.06581)
**中文标题：增强管状特征提取的气道分割网络**

*Qibiao Wu,Yagang Wang,Qian Zhang*

主要分类: eess.IV

摘要简述: 本文提出了一种名为TfeNet的新型管状特征提取网络，通过方向感知卷积操作和管状特征融合模块，显著提升了气道分割的准确性和连续性，在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 气道区域的手动标注耗时且依赖专家经验，而现有卷积神经网络在气道分割中难以捕捉细小的气道结构，导致分割不连续。因此，需要一种新方法以提升分割效果。

研究方法: TfeNet提出了一种方向感知卷积操作，通过空间旋转变换调整卷积核采样位置，并使用非对称卷积和残差连接策略设计管状特征融合模块（TFFM），以增强对细小气道结构的关注。

研究结果: 在公开数据集和气道分割挑战数据集上的实验表明，TfeNet在准确性和连续性上优于现有方法，尤其在最大气道分割数据集ATM22上达到94.95%的最高分，并在肺纤维化数据集AIIB23上表现优异。

研究结论: TfeNet通过创新的管状特征提取和融合策略，显著提升了气道分割的性能，为支气管镜导航和机器人系统的临床应用提供了有力支持。

中文摘要: 在计算机断层扫描图像中手动标注气道区域是一项耗时且依赖专家经验的任务。因此，自动气道分割是实现快速支气管镜导航和支气管镜机器人系统临床部署的前提。尽管卷积神经网络方法在气道分割中受到广泛关注，但气道的独特树状结构对传统和可变形卷积提出了挑战，这些方法往往难以聚焦于细小气道结构，导致分割遗漏和不连续。为解决这一问题，本研究提出了一种新型管状特征提取网络TfeNet。TfeNet引入了一种方向感知卷积操作，首先通过空间旋转变换调整线性卷积核的采样位置，随后将变形后的核表示为3D空间中的线段或多段线。此外，基于非对称卷积和残差连接策略设计了管状特征融合模块（TFFM），增强了网络对细小气道结构的关注。在一个公开数据集和两个气道分割挑战数据集上的大量实验表明，与现有方法相比，TfeNet能够实现更准确且连续的气道结构预测。特别是在当前最大的气道分割数据集Airway Tree Modeling（ATM22）上，TfeNet以94.95%的最高总分领先，并在肺纤维化数据集（AIIB23）上表现出先进性能。代码发布于https://github.com/QibiaoWu/TfeNet。

</details>


### [222] [Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers](https://arxiv.org/abs/2507.06764)
**中文标题：快速等变成像：通过拉格朗日乘子法和辅助即插即用去噪器加速无监督学习**

*Guixian Xu,Jinglai Li,Junqi Tang*

主要分类: eess.IV

摘要简述: 本文提出了一种名为快速等变成像（FEI）的新型无监督学习框架，通过拉格朗日乘子法和即插即用去噪器，显著提升了训练效率，并在X射线CT重建任务中实现了10倍的加速和更好的泛化性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的无监督学习框架在训练深度成像网络时效率较低，且缺乏地面真实数据支持。本文旨在通过改进等变成像（EI）的优化问题，提出一种更高效的训练方法。

研究方法: 本文提出快速等变成像（FEI）框架，结合拉格朗日乘子法和即插即用去噪器，重新构建优化问题，从而实现高效的网络训练。

研究结果: 在X射线CT重建任务中，PnP-FEI方案比标准EI快10倍，且泛化性能更优。

研究结论: FEI框架显著提升了无监督学习的效率和性能，为深度成像网络的训练提供了一种高效解决方案。

中文摘要: 我们提出了快速等变成像（FEI），这是一种新型的无监督学习框架，用于在没有地面真实数据的情况下高效训练深度成像网络。通过拉格朗日乘子法重新构建等变成像的优化问题，并利用即插即用去噪器，这种新型无监督方案在效率和性能上均优于传统的等变成像范式。具体而言，我们的PnP-FEI方案在X射线CT重建任务中训练U-Net时，比标准EI快一个数量级（10倍），并且具有更好的泛化性能。

</details>


### [223] [SimCortex: Collision-free Simultaneous Cortical Surfaces Reconstruction](https://arxiv.org/abs/2507.06955)
**中文标题：SimCortex：无碰撞的同步皮质表面重建**

*Kaveh Moradkhani,R Jarrett Rushmore,Sylvain Bouix*

主要分类: eess.IV

摘要简述: SimCortex是一种深度学习框架，用于从T1加权MRI数据中同时重建无碰撞的皮质表面，显著减少重叠和自交，同时保持拓扑性质。


<details>
  <summary>详细信息</summary>
研究动机: 现有的皮质表面重建方法常因复杂的几何结构和严格的拓扑要求而产生重叠、自交和拓扑缺陷，影响了神经解剖学分析的可靠性。

研究方法: SimCortex首先将T1加权MRI图像分割为九类组织标签图，生成无碰撞的初始表面网格，随后通过多尺度微分同胚变形和静止速度场（SVFs）实现平滑且保持拓扑的变换。

研究结果: 在标准数据集上的评估表明，SimCortex显著减少了表面重叠和自交，同时保持了最先进的几何精度。

研究结论: SimCortex通过深度学习框架解决了现有皮质表面重建方法的缺陷，提供了一种高效且可靠的无碰撞表面重建方案。

中文摘要: 从磁共振成像（MRI）数据中准确重建皮质表面对于可靠的神经解剖学分析至关重要。现有方法需要应对复杂的皮质几何结构、严格的拓扑要求，并且常常产生重叠、自交和拓扑缺陷的表面。为了克服这些不足，我们提出了SimCortex，一种深度学习框架，能够从T1加权（T1w）MRI体积中同时重建所有脑表面（左/右白质和软膜），同时保持拓扑性质。我们的方法首先将T1w图像分割为九类组织标签图，并从中生成特定于受试者的无碰撞初始表面网格。这些表面作为后续多尺度微分同胚变形的精确初始化。通过缩放和平方法集成的静止速度场（SVFs），我们的方法确保了平滑且保持拓扑的变换，显著减少了表面碰撞和自交。在标准数据集上的评估表明，SimCortex显著减少了表面重叠和自交，超越了现有方法，同时保持了最先进的几何精度。

</details>


### [224] [Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning](https://arxiv.org/abs/2507.07011)
**中文标题：Deep Brain Net：基于EfficientNetB0和ResNet50迁移学习的优化深度学习模型用于MRI图像中的脑肿瘤检测**

*Daniel Onah,Ravish Desai*

主要分类: eess.IV

摘要简述: 本文提出了一种名为Deep Brain Net的新型深度学习模型，结合EfficientNetB0和ResNet50架构，通过迁移学习优化脑肿瘤检测性能，显著提高了分类准确率和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，深度学习在脑肿瘤自动检测和分类中表现出巨大潜力，但高精度和计算效率仍是挑战。本研究旨在通过结合两种先进神经网络架构和迁移学习，提升脑肿瘤检测的性能。

研究方法: Deep Brain Net整合了EfficientNetB0和ResNet50架构。EfficientNetB0通过深度可分离卷积减少参数和计算成本，而ResNet50通过残差连接解决梯度消失问题。模型采用迁移学习进行微调，提升泛化能力并减少训练时间。

研究结果: 在公开MRI数据集上的实验表明，Deep Brain Net在分类准确率（88%）、加权F1分数（88.75%）和宏观AUC ROC分数（98.17%）上均优于现有方法，展现了其临床潜力。

研究结论: Deep Brain Net结合高效架构和迁移学习，显著提升了脑肿瘤检测的准确性和计算效率，为辅助放射科医生诊断提供了可靠工具。

中文摘要: 近年来，深度学习在MRI图像中脑肿瘤的自动检测和分类方面展现出巨大潜力，但实现高精度和计算效率仍具挑战性。本研究提出了一种名为Deep Brain Net的新型深度学习系统，旨在优化脑肿瘤检测性能。该模型整合了EfficientNetB0和ResNet50两种先进神经网络架构的优势，并结合迁移学习以提高泛化能力并减少训练时间。EfficientNetB0架构通过采用深度可分离卷积的移动倒置瓶颈块，显著减少了参数数量和计算成本，同时保留了模型学习复杂特征表示的能力。ResNet50架构在ImageNet等大规模数据集上预训练后，针对脑肿瘤分类进行了微调，其残差连接设计通过缓解梯度消失问题，避免了性能下降。这些组件的整合确保了所提系统在计算效率和准确性上的双重优势。在公开MRI数据集上的大量实验表明，Deep Brain Net在分类准确率（88%）、加权F1分数（88.75%）和宏观AUC ROC分数（98.17%）上均优于现有先进方法，证明了其在辅助放射科医生进行脑肿瘤诊断方面的鲁棒性和临床潜力。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [225] [Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G](https://arxiv.org/abs/2507.06911)
**中文标题：超越连接：6G中AI-RAN融合的开放架构**

*Michele Polese,Niloofar Mohamadi,Salvatore D'Oro,Tommaso Melodia*

主要分类: cs.NI

摘要简述: 本文提出了一种新型的O-RAN与AI-RAN融合架构，支持在共享基础设施上统一管理电信和AI工作负载，通过模块化和云原生设计实现异构AI部署。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据密集型AI应用在网络边缘的普及，传统的RAN设计需要从单纯利用AI优化网络转向支持分布式AI工作负载。这为网络运营商提供了通过边缘AI实现盈利的机会，同时充分利用现有基础设施。

研究方法: 文章提出了一种融合O-RAN和AI-RAN的架构，包括两个关键创新：(i) AI-RAN Orchestrator，扩展O-RAN SMO以实现RAN和AI工作负载的集成资源分配；(ii) AI-RAN站点，提供具有实时处理能力的分布式边缘AI平台。

研究结果: 该架构支持灵活的部署选项，能够根据时间要求（实时或批量处理）和地理目标协调AI工作负载，同时满足异构工作负载在不同时间尺度上的编排需求。

研究结论: 该架构通过开放标准化接口和多厂商互操作性，为6G时代的AI-RAN融合提供了可行的解决方案，推动了边缘AI的发展。

中文摘要: 数据密集型人工智能（AI）应用在网络边缘的普及要求RAN设计从单纯利用AI优化网络转向支持分布式AI工作负载。这一范式转变为网络运营商提供了通过边缘AI实现盈利的机会，同时充分利用现有基础设施。为实现这一愿景，本文提出了一种新型的O-RAN与AI-RAN融合架构，统一了电信和AI工作负载在共享基础设施上的编排与管理。该架构扩展了Open RAN的模块化、解耦和云原生原则，以支持异构AI部署。我们引入了两项关键创新：(i) AI-RAN Orchestrator，扩展O-RAN SMO以实现RAN和AI工作负载的集成资源分配；(ii) AI-RAN站点，提供具有实时处理能力的分布式边缘AI平台。该系统支持灵活的部署选项，允许根据时间要求（实时或批量处理）和地理目标协调AI工作负载。该架构满足了管理异构工作负载在不同时间尺度上的编排需求，同时保持了开放标准化接口和多厂商互操作性。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [226] [Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies](https://arxiv.org/abs/2507.06519)
**中文标题：故障预测增强Sim2Real周期性插入策略的鲁棒性**

*Yuhan Liu,Xinyu Zhang,Haonan Chang,Abdeslam Boularias*

主要分类: cs.RO

摘要简述: 本文提出了一种结合强化学习插入策略与故障预测模块的sim-to-real框架，用于提升机器人执行高精度重复插入任务（如拧螺母）的鲁棒性和成功率。


<details>
  <summary>详细信息</summary>
研究动机: 重复插入任务（RIT）要求毫米级精度和长时间一致性，但由于螺母旋转和摩擦等因素，实际执行中容易失败。本文旨在通过sim-to-real方法解决这些问题。

研究方法: 方法包括：1) 在螺母坐标系中表示扳手位姿以提升sim-to-real迁移性；2) 基于强化学习的插入策略实现精确对准和旋转；3) 神经网络预测潜在故障并触发简单恢复机制。

研究结果: 实验表明，该方法不仅在单次任务中成功率较高，还能在长时间重复任务中保持稳定性能。

研究结论: 结合故障预测的sim-to-real框架显著提升了机器人执行高精度重复插入任务的鲁棒性和成功率。

中文摘要: 本文针对周期性插入任务（RIT）的挑战展开研究，例如机器人需重复执行高精度插入动作（如用扳手将螺母拧入螺栓）。RIT的难点在于实现毫米级精度并在多次重复中保持一致性，尤其是当螺母旋转和摩擦等因素增加复杂性时。我们提出了一种sim-to-real框架，将基于强化学习的插入策略与故障预测模块相结合。通过在螺母坐标系而非机器人坐标系中表示扳手位姿，我们的方法显著提升了sim-to-real的迁移性。插入策略在仿真中训练，利用实时6D位姿跟踪执行精确对准、插入和旋转操作。同时，神经网络预测潜在执行故障，触发简单的恢复机制（如抬起扳手并重试插入）。在仿真和真实环境中的大量实验表明，我们的方法不仅单次成功率高，还能在长时间重复任务中保持鲁棒性能。

</details>


### [227] [SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments](https://arxiv.org/abs/2507.06564)
**中文标题：SkyVLN：城市环境中的无人机视觉语言导航与NMPC控制**

*Tianshun Li,Tianyi Huai,Zhen Li,Yichun Gao,Haoang Li,Xinhu Zheng*

主要分类: cs.RO

摘要简述: SkyVLN是一种新型无人机导航框架，结合视觉语言导航（VLN）和非线性模型预测控制（NMPC），提升无人机在复杂城市环境中的自主性。通过大语言模型（LLMs）解析自然语言指令和视觉观察，实现精准导航和动态避障。实验验证其显著提高了导航成功率和效率。


<details>
  <summary>详细信息</summary>
研究动机: 无人机在复杂城市环境中的自主导航面临挑战，传统方法难以应对动态3D空间和模糊指令。SkyVLN旨在通过结合视觉语言导航和NMPC，提升无人机在复杂环境中的导航能力和适应性。

研究方法: SkyVLN框架整合了视觉语言导航（VLN）和非线性模型预测控制（NMPC）。VLN部分利用大语言模型解析自然语言指令和视觉观察，配备细粒度空间语言化器和历史路径记忆机制，以处理模糊指令和回溯。NMPC模块用于动态避障和精确轨迹跟踪。实验基于AirSim高保真3D城市模拟环境进行。

研究结果: 实验表明，SkyVLN显著提高了无人机在复杂城市环境中的导航成功率和效率，尤其是在新环境和未见场景中表现优异。

研究结论: SkyVLN通过结合视觉语言导航和NMPC，为无人机在复杂城市环境中的自主导航提供了高效解决方案，具有广泛的应用潜力。

中文摘要: 无人机（UAV）因其灵活性和适应性成为多领域的重要工具。本文提出SkyVLN，一种结合视觉语言导航（VLN）和非线性模型预测控制（NMPC）的新型框架，旨在提升无人机在复杂城市环境中的自主性。与传统导航方法不同，SkyVLN利用大语言模型（LLMs）解析自然语言指令和视觉观察，使无人机能够在动态3D空间中实现更高精度和鲁棒性的导航。我们提出了一种多模态导航代理，配备细粒度空间语言化器和历史路径记忆机制，使无人机能够消除空间歧义、处理模糊指令并在必要时回溯。框架还包含NMPC模块，用于动态避障，确保精确轨迹跟踪和防撞。为验证方法，我们基于AirSim开发了高保真3D城市模拟环境，包含逼真图像和动态城市元素。大量实验表明，SkyVLN显著提高了导航成功率和效率，尤其在新环境和未见场景中表现突出。

</details>


### [228] [Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic](https://arxiv.org/abs/2507.06625)
**中文标题：Q-STAC：基于Q引导的Stein变分模型预测演员-评论家方法**

*Shizhe Cai,Jayadeep Jacob,Zeya Yin,Fabio Ramos*

主要分类: cs.RO

摘要简述: Q-STAC是一种结合贝叶斯模型预测控制与演员-评论家强化学习的新框架，通过约束Stein变分梯度下降优化控制序列，无需显式设计成本函数，同时利用已知系统动力学提升样本效率并确保安全性。


<details>
  <summary>详细信息</summary>
研究动机: 深度强化学习在连续控制任务中表现出色，但存在训练数据需求大、复杂长时规划困难及安全性不足的问题；而模型预测控制虽具可解释性和约束满足能力，但通常仅提供局部最优解且需精心设计成本函数。Q-STAC旨在结合两者优势，解决这些问题。

研究方法: Q-STAC通过约束Stein变分梯度下降（SVGD）将贝叶斯模型预测控制与演员-评论家强化学习结合，直接利用学习的Q值优化控制序列，无需显式成本函数设计，同时利用系统动力学提升效率和安全性。

研究结果: 在2D导航和机器人操作任务上的实验表明，Q-STAC在样本效率、鲁棒性和最优性上优于现有算法，同时保持策略分布的高表达能力。

研究结论: Q-STAC成功结合了贝叶斯模型预测控制与强化学习的优势，显著提升了样本效率、安全性和性能，为复杂控制任务提供了高效解决方案。

中文摘要: 深度强化学习在连续控制任务中取得了显著成功，但通常需要大量训练数据，难以处理复杂的长时规划问题，且在运行中无法保证安全约束。与此同时，模型预测控制（MPC）提供了可解释性和约束满足能力，但通常仅能提供局部最优解，且需要精心设计成本函数。本文提出了Q引导的Stein变分模型预测演员-评论家（Q-STAC），这是一种新颖的框架，通过约束Stein变分梯度下降（SVGD）将贝叶斯MPC与演员-评论家强化学习相结合。我们的方法直接利用学习的Q值作为目标优化控制序列，无需显式设计成本函数，同时利用已知系统动力学提升样本效率并确保控制信号在安全范围内。在2D导航和机器人操作任务上的大量实验表明，Q-STAC在样本效率、鲁棒性和最优性上优于现有算法，同时保持了策略分布的高表达能力。实验视频可在我们的网站上查看：https://sites.google.com/view/q-stac

</details>


### [229] [Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction](https://arxiv.org/abs/2507.06404)
**中文标题：学习评估人机交互中的自主行为**

*Matteo Tiezzi,Tommaso Apicella,Carlos Cardenas-Perez,Giovanni Fregonese,Stefano Dafarra,Pietro Morerio,Daniele Pucci,Alessio Del Bue*

主要分类: cs.RO

摘要简述: 本文提出了一种评估人形机器人自主行为性能的通用框架，通过轨迹性能衡量模仿学习方法的优劣，并设计了无需人类参与的深度模型NeME作为元评估器。实验验证了该框架在复杂人机交互任务中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估人形机器人性能的指标难以复现且无法捕捉轨迹复杂性，尤其是在人机交互与协作（HRIC）中。为解决这一问题，本文旨在开发一种系统性评估框架。

研究方法: 提出了一种通用评估框架，重点关注轨迹性能，并设计了NeME（神经元评估器），一种基于深度学习的模型，用于从机器人关节轨迹中分类动作。NeME作为元评估器，无需人类参与即可比较控制策略的性能。

研究结果: 在ergoCub人形机器人上的实验表明，该方法比基线更符合实际成功率，为复杂人机交互任务中的多模态模仿学习方法提供了可复现且系统性的性能比较手段。

研究结论: 本文提出的框架为评估人形机器人的自主行为提供了一种高效且可复现的方法，显著提升了模仿学习策略的性能比较能力。

中文摘要: 评估和比较人形机器人的自主性能具有挑战性，因为成功率指标难以复现且无法捕捉机器人运动轨迹的复杂性，而这在人机交互与协作（HRIC）中至关重要。为解决这些问题，我们提出了一种通用评估框架，通过关注轨迹性能来衡量模仿学习（IL）方法的质量。我们设计了神经元评估器（NeME），这是一种基于深度学习的模型，用于从机器人关节轨迹中分类动作。NeME作为元评估器，能够在不依赖人类参与的情况下比较机器人控制策略的性能。我们在人形机器人ergoCub上验证了该框架，使用遥操作数据并比较了针对该平台定制的IL方法。实验结果表明，与基线方法相比，我们的方法更符合机器人的实际成功率，为复杂HRIC任务中多模态模仿学习方法的性能比较提供了一种可复现、系统且深入的评估手段。

</details>


### [230] [LOVON: Legged Open-Vocabulary Object Navigator](https://arxiv.org/abs/2507.06747)
**中文标题：LOVON：腿式开放词汇物体导航器**

*Daojie Peng,Jiahang Cao,Qiang Zhang,Jun Ma*

主要分类: cs.RO

摘要简述: LOVON是一种新型框架，结合大型语言模型（LLMs）和开放词汇视觉检测模型，用于动态非结构化环境中的长距离物体导航。通过专用解决方案（如拉普拉斯方差滤波）解决视觉抖动等问题，并在多款腿式机器人上验证了其兼容性和即插即用特性。


<details>
  <summary>详细信息</summary>
研究动机: 开放世界环境中的物体导航是机器人系统面临的重要挑战，尤其是需要结合开放世界物体检测和高级任务规划的长时程任务。传统方法难以有效整合这些组件，限制了其在复杂长距离导航任务中的应用。

研究方法: LOVON框架结合了大型语言模型（LLMs）的层次任务规划和开放词汇视觉检测模型，设计了拉普拉斯方差滤波等专用解决方案以应对视觉抖动和盲区问题，并开发了功能执行逻辑以确保自主导航和任务完成的鲁棒性。

研究结果: 实验表明，LOVON能够成功完成涉及实时检测、搜索和导航的长序列任务，并在多款腿式机器人（Unitree Go2、B2和H1-2）上展示了其兼容性和即插即用特性。

研究结论: LOVON通过整合LLMs和视觉检测模型，有效解决了动态非结构化环境中的长距离物体导航问题，为机器人系统的开放世界任务提供了实用解决方案。

中文摘要: 开放世界环境中的物体导航对机器人系统来说仍然是一个艰巨且普遍的挑战，尤其是在需要结合开放世界物体检测和高级任务规划的长时程任务中。传统方法往往难以有效整合这些组件，从而限制了其在复杂长距离导航任务中的能力。本文提出LOVON，一种新型框架，将大型语言模型（LLMs）用于层次任务规划，并结合开放词汇视觉检测模型，专为动态非结构化环境中的有效长距离物体导航而设计。为解决包括视觉抖动、盲区和临时目标丢失在内的现实挑战，我们设计了专用解决方案，如用于视觉稳定的拉普拉斯方差滤波。我们还为机器人开发了功能执行逻辑，确保LOVON在自主导航、任务适应和鲁棒任务完成方面的能力。大量评估表明，LOVON能够成功完成涉及实时检测、搜索和导航的长序列任务。此外，在不同腿式机器人（Unitree Go2、B2和H1-2）上的真实世界实验展示了LOVON的兼容性和吸引人的即插即用特性。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [231] [Towards LLM-based Root Cause Analysis of Hardware Design Failures](https://arxiv.org/abs/2507.06512)
**中文标题：基于大型语言模型的硬件设计故障根因分析**

*Siyu Qiu,Muzhi Wang,Raheel Afsharmazayejani,Mohammad Moradi Shahmiri,Benjamin Tan,Hammond Pearce*

主要分类: cs.AR

摘要简述: 本文探讨了如何利用大型语言模型（LLMs）辅助硬件设计中的根因分析，测试了34种错误场景，结果显示OpenAI的o3-mini模型在pass@5评分下准确率达100%，其他先进模型表现也超过80%。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）的发展，其在硬件设计过程中的应用潜力逐渐显现。本文旨在探索LLMs如何帮助识别和解释硬件设计中的根因问题，为LLMs在硬件设计和安全分析中的广泛应用奠定基础。

研究方法: 研究测试了34种不同的错误场景，使用OpenAI的o3-mini模型及其他先进模型进行根因分析。部分实验结合了检索增强生成（RAG）技术以提高性能。

研究结果: 实验结果显示，OpenAI的o3-mini模型在pass@5评分下准确率达到100%，其他先进模型通常表现超过80%，结合RAG技术后性能提升至90%以上。

研究结论: 研究表明，LLMs在硬件设计根因分析中具有显著潜力，尤其是结合检索增强生成技术时表现更优，为LLMs在硬件设计领域的广泛应用提供了有力支持。

中文摘要: 随着大型语言模型（LLMs）的发展，为支持数字硬件设计过程的新工具开发提供了机遇。本研究探索了LLMs如何帮助解释在综合和仿真过程中发现的设计问题和错误的根因，这是推动LLMs在硬件设计过程和硬件安全分析中广泛应用的必要里程碑。我们取得了令人鼓舞的结果：在34种不同的错误场景中，OpenAI的o3-mini推理模型在pass@5评分下达到了100%的准确率，其他先进模型和配置通常表现超过80%，结合检索增强生成技术后性能提升至90%以上。

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [232] [Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving](https://arxiv.org/abs/2507.06804)
**中文标题：通过解耦推理与证明解决更具挑战性的IMO问题**

*Zhenwen Liang,Linfeng Song,Yang Li,Tao Yang,Feng Zhang,Haitao Mi,Dong Yu*

主要分类: cs.LO

摘要简述: 本文提出了一种解耦推理与证明的新框架，通过分离高层推理与底层证明生成，显著提升了自动定理证明在复杂数学问题（如IMO）上的表现。实验成功解决了5道IMO难题，并公开了相关数据集。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在非形式化推理上表现优异（准确率超80%），但在形式化证明中表现不佳（成功率低于8%）。研究发现，现有方法因将推理与证明紧密耦合，导致模型偏向浅层策略而忽视深度推理。本文旨在通过解耦设计填补这一差距。

研究方法: 提出了一种模块化框架，包含两个独立模型：1）通用推理器（Reasoner）生成多样化的子目标引理；2）高效证明器（Prover）严格验证引理。这种设计避免了端到端训练的缺陷，释放了模型的推理潜力。

研究结果: 在2000年后IMO难题集上，该框架成功解决了5道问题，成为首个开源证明器在此类难题上取得成功的案例。同时公开了生成的引理数据集。

研究结论: 解耦推理与证明的方法显著提升了自动定理证明在复杂数学问题上的能力，为未来研究提供了新方向。公开的数据集将促进相关领域发展。

中文摘要: 自动定理证明（ATP）是AI的基础性挑战。尽管大型语言模型（LLM）推动了显著进展，但其强大的非形式化推理能力与薄弱的形式化证明表现之间仍存在巨大差距（如PutnamBench中非形式化准确率超80%，形式化成功率不足8%）。我们认为，这种差距源于当前最先进的证明器将推理与证明紧密耦合，训练范式无意中惩罚了深度推理，偏向浅层的战术策略。为填补这一根本性差距，我们提出了一种新框架，将高层推理与底层证明生成解耦。该方法利用两个独立的专用模型：一个强大的通用推理器生成多样化、战略性的子目标引理，以及一个高效的证明器严格验证它们。这种模块化设计释放了模型的全部推理潜力，绕过了端到端训练的缺陷。我们在2000年后IMO难题集上评估了该方法，此前无开源证明器在此类问题上取得成功。我们的解耦框架成功解决了其中5道问题，标志着在极难数学挑战上的自动推理迈出了重要一步。为促进未来研究，我们公开了针对广泛IMO问题生成和验证的引理数据集，详见https://tencent-imo.github.io/。

</details>
