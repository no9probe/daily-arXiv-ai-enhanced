<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.CV](#cs.CV) [Total: 112]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.IR](#cs.IR) [Total: 1]
- [eess.IV](#eess.IV) [Total: 8]
- [cs.HC](#cs.HC) [Total: 3]
- [cs.SD](#cs.SD) [Total: 5]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.LG](#cs.LG) [Total: 36]
- [quant-ph](#quant-ph) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.RO](#cs.RO) [Total: 5]
- [stat.ME](#stat.ME) [Total: 1]
- [cs.SE](#cs.SE) [Total: 6]
- [cs.DC](#cs.DC) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [math.NA](#math.NA) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
**中文标题：面向表格数据的概率问答研究**

*Chen Shen,Sajjadur Rahman,Estevam Hruschka*

主要分类: cs.CL

摘要简述: 本文提出了一种针对表格数据的概率问答新方法，结合贝叶斯网络和大语言模型，显著提升了不确定性问题的回答性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于表格数据的问答系统（如NL2SQL）在处理确定性事实问题时表现良好，但在需要概率推理的问题上表现不足。本文旨在填补这一空白。

研究方法: 作者提出了一种新框架，通过从表格数据中构建贝叶斯网络，将自然语言查询转化为概率查询，并利用大语言模型生成最终答案。

研究结果: 实验结果表明，该方法在基准测试LUCARIO上显著优于基线模型，证明了符号-神经混合推理的有效性。

研究结论: 本文提出的方法为表格数据中的概率问答提供了有效解决方案，展示了符号与神经方法结合的优势。

中文摘要: 当前基于表格数据的问答系统（如NL2SQL）在处理确定性事实问题时表现良好，但在需要概率推理的问题上表现不足。本文提出了一种新基准LUCARIO和框架，用于大规模表格数据的概率问答。我们的方法从表格中构建贝叶斯网络，将自然语言查询转化为概率查询，并利用大语言模型生成最终答案。实验结果表明，该方法显著优于基线模型，凸显了符号-神经混合推理的优势。

</details>


### [2] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
**中文标题：大型语言模型的多语言功能评估**

*Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian*

主要分类: cs.CL

摘要简述: 本文提出多语言功能评估基准（CL-GSM Symbolic和CL-IFEval），通过翻译现有英语基准到五种语言（法语、西班牙语、印地语、阿拉伯语和约鲁巴语），评估大型语言模型的实际性能和鲁棒性。结果显示，某些静态基准更接近功能性能，且模型在不同语言中的表现差异显著。


<details>
  <summary>详细信息</summary>
研究动机: 当前多语言能力评估主要依赖静态数据基准（如Belebele、M-MMLU和M-GSM），但这些方法无法充分反映模型在多语言环境中的实际性能和鲁棒性。因此，作者提出创建多语言功能评估基准，以更全面地评估模型表现。

研究方法: 通过将现有的英语功能基准模板翻译为五种语言（法语、西班牙语、印地语、阿拉伯语和约鲁巴语），构建了跨语言功能评估基准CL-GSM Symbolic和CL-IFEval，并对比其与静态基准的性能差异。

研究结果: 研究发现，某些静态基准（如M-MMLU）与功能基准的性能差异较小（0.5%-3%），而其他基准（如M-GSM和Belebele）的性能差异较大（15%-24%）。此外，模型在不同语言中的鲁棒性差异显著，阿拉伯语和英语表现最稳定。

研究结论: 多语言功能评估基准能更准确地反映模型的实际性能，静态基准的适用性因任务和语言而异。未来研究需关注模型在低资源语言中的表现。

中文摘要: 大型语言模型的多语言能力通常通过静态数据基准（如Belebele、M-MMLU和M-GSM）进行评估，但这些评估往往无法充分反映模型在多语言环境中的实际性能和鲁棒性。为此，我们通过将现有的英语功能基准模板翻译为五种语言（法语、西班牙语、印地语、阿拉伯语和约鲁巴语），创建了跨语言功能评估基准——跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令跟随评估（CL-IFEval）。结果显示，某些静态多语言基准更接近功能性能（例如，M-GSM与CL-GSM Symbolic在英语、法语和西班牙语中的性能分别下降24%、17%和18%；Belebele与CL-IFEval的性能下降15%-24%，而M-MMLU与CL-IFEval的性能仅下降0.5%-3%）。此外，模型在不同语言中的鲁棒性差异显著，某些语言（如阿拉伯语和英语）在多次评估中表现最稳定。

</details>


### [3] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
**中文标题：创意与执行之间的差距：LLM生成与人类研究想法的执行结果比较**

*Chenglei Si,Tatsunori Hashimoto,Diyi Yang*

主要分类: cs.CL

摘要简述: 研究发现，尽管LLM生成的研究想法在创意阶段被认为更具新颖性，但在实际执行后，其评分显著下降，甚至低于人类专家提出的想法，揭示了LLM在生成真正有效研究想法上的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在科学研究中展现出加速研究流程的潜力，但其生成的研究想法是否能在执行后产生更好的研究成果尚不明确。本研究旨在验证LLM生成的想法与人类专家想法在执行后的实际效果差异。

研究方法: 研究招募了43名专家研究人员，随机分配执行LLM生成或人类专家提出的研究想法。每位专家花费超过100小时实施想法，并撰写4页的简短论文记录实验。所有项目由NLP专家进行盲审评分。

研究结果: 执行后，LLM生成的想法在所有评价指标（新颖性、兴奋度、有效性和整体评分）上的评分显著下降（p < 0.05），甚至在某些指标上人类想法的评分反超LLM想法。

研究结论: 研究揭示了LLM生成想法与实际执行效果之间的差距，表明当前LLM在生成真正有效的研究想法上存在局限性，同时也凸显了仅凭创意阶段评价研究想法的挑战。

中文摘要: 大型语言模型（LLM）在加速科学研究流程方面展现出潜力。其关键能力之一是生成新颖的研究想法，此前研究发现LLM生成的想法在某些情境下被认为比人类专家的想法更具新颖性。然而，一个好的想法不仅应看似新颖，还应在执行后产生更好的研究成果。为了验证AI生成的想法是否能带来更好的研究结果，我们开展了一项执行研究，招募了43名专家研究人员随机执行LLM生成或人类专家提出的想法。每位专家花费超过100小时实施想法，并撰写4页的简短论文记录实验。所有项目由NLP专家进行盲审。比较执行前后的评分发现，LLM生成的想法在所有评价指标（新颖性、兴奋度、有效性和整体评分）上的评分显著下降（p < 0.05），缩小了创意阶段LLM与人类想法之间的差距。在执行研究的汇总评分中，甚至观察到许多指标上人类想法的评分反超LLM想法。这一创意与执行之间的差距揭示了当前LLM在生成真正有效研究想法上的局限性，以及在缺乏执行结果时评价研究想法的挑战。

</details>


### [4] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
**中文标题：MultiFinRAG：一种优化的多模态检索增强生成框架，用于金融问答**

*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

主要分类: cs.CL

摘要简述: MultiFinRAG是一个专为金融问答设计的优化多模态检索增强生成框架，通过多模态提取和动态检索策略，显著提升了复杂金融问题的回答准确性。


<details>
  <summary>详细信息</summary>
研究动机: 金融文档（如10-Ks、10-Qs和投资者演示）通常包含数百页的多模态内容（如文本、表格和图表），传统的大型语言模型（LLMs）和检索增强生成（RAG）方法因令牌限制和跨模态上下文碎片化而难以处理此类任务。

研究方法: MultiFinRAG首先将表格和图表图像分组并发送给轻量级开源多模态LLM，生成结构化JSON输出和简洁文本摘要；随后通过模态感知相似性阈值嵌入和索引这些输出，并采用分层回退策略动态调整检索范围，实现跨模态推理。

研究结果: 在涉及文本、表格、图表及多模态推理的复杂金融问答任务中，MultiFinRAG的准确率比免费版ChatGPT-4o高出19个百分点。

研究结论: MultiFinRAG通过优化多模态检索和生成流程，显著提升了金融问答的准确性和效率，适用于普通硬件环境。

中文摘要: 金融文档（如10-Ks、10-Qs和投资者演示）通常包含数百页的多模态内容，如密集叙述文本、结构化表格和复杂图表。回答此类内容的问题通常需要跨模态联合推理，而传统的大型语言模型（LLMs）和检索增强生成（RAG）流程因令牌限制、布局丢失和跨模态上下文碎片化而难以胜任。我们提出了MultiFinRAG，一个专为金融问答设计的检索增强生成框架。MultiFinRAG首先通过将表格和图表图像分组并发送给轻量级、量化的开源多模态LLM进行多模态提取，生成结构化JSON输出和简洁文本摘要。这些输出与叙述文本一起通过模态感知相似性阈值嵌入和索引，以实现精确检索。随后，分层回退策略在必要时动态从纯文本扩展到文本+表格+图像上下文，从而实现跨模态推理并减少无关上下文。尽管运行在普通硬件上，MultiFinRAG在涉及文本、表格、图表和联合多模态推理的复杂金融问答任务中，准确率比免费版ChatGPT-4o高出19个百分点。

</details>


### [5] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
**中文标题：揭示大型语言模型中的隐藏暴力倾向：基于行为情景的人口统计分析**

*Quintin Myers,Yanjun Gao*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLMs）在暴力倾向方面存在表面文本生成与内部偏好不一致的现象，且其暴力倾向在不同人口统计特征中存在偏差。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）被提议用于检测和应对网络暴力内容，但其在道德模糊的真实场景中的推理能力尚未充分研究。本文旨在填补这一空白，评估LLMs在暴力行为问卷中的表现，并揭示其潜在的偏见。

研究方法: 研究使用已验证的社会科学工具——暴力行为情景问卷（VBVQ），通过基于人物角色的提示（涵盖种族、年龄和地理身份）评估六种不同地缘政治和组织背景下开发的LLMs，采用零样本设置。

研究结果: 研究发现：(1) LLMs的表面文本生成与内部暴力倾向偏好存在不一致；(2) 其暴力倾向在不同人口统计特征中存在显著差异，且与犯罪学、社会科学和心理学的已知结论相矛盾。

研究结论: 研究揭示了LLMs在暴力倾向方面的潜在偏见和不一致性，强调了在应用LLMs处理暴力内容时需谨慎，并需进一步优化模型以减少偏见。

中文摘要: 尽管大型语言模型（LLMs）越来越多地被提议用于检测和应对网络暴力内容，但其在道德模糊的真实场景中的推理能力尚未得到充分研究。我们首次使用已验证的社会科学工具——暴力行为情景问卷（VBVQ）评估LLMs。为评估潜在偏见，我们引入了基于人物角色的提示，涵盖美国内的种族、年龄和地理身份。在统一的零样本设置下，评估了六种不同地缘政治和组织背景下开发的LLMs。研究发现：(1) LLMs的表面文本生成常与其内部暴力倾向偏好不一致；(2) 其暴力倾向在不同人口统计特征中存在差异，且常与犯罪学、社会科学和心理学的已知结论相矛盾。

</details>


### [6] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
**中文标题：少做决定，多沟通：论医学中端到端事实核查的构念效度**

*Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li*

主要分类: cs.CL

摘要简述: 本文探讨了医学领域端到端事实核查系统的局限性，指出其在实际应用中面临的挑战，并建议将其视为交互式沟通问题而非端到端流程。


<details>
  <summary>详细信息</summary>
研究动机: 随着技术进步，自动事实核查系统在医学领域的应用潜力受到关注，但实际使用率低。本文旨在通过研究临床专家如何验证社交媒体上的医学声明，揭示端到端事实核查在医学中的根本挑战。

研究方法: 研究通过分析临床专家如何综合医学证据验证社交媒体上的真实声明，探索端到端事实核查在医学中的上限及其问题。

研究结果: 研究发现端到端事实核查在医学中面临三大挑战：声明与临床试验证据的关联困难、模糊声明与意图不匹配的歧义性，以及主观真实性标签的固有性。

研究结论: 作者认为，事实核查应被视为交互式沟通问题而非端到端流程，并建议重新评估其设计和应用方式。

中文摘要: 技术进步为自动事实核查等挑战性任务带来了具体进展。由于医学决策的高风险性及医学文献的多样性和复杂性，公众对在公共卫生和医学中采用此类系统的兴趣日益增长。循证医学与每个人息息相关，但其技术性极强，多数用户的医学素养不足以充分理解该领域。医学沟通中的这些问题为端到端事实核查代理提供了土壤：根据当前医学文献核查声明并返回证据支持的结论。然而，此类系统仍鲜少使用。为理解这一现象，我们首次研究了临床专家如何通过综合医学证据验证社交媒体上的真实声明。在探索这一上限时，我们揭示了端到端事实核查在医学中的根本挑战：将现实中的声明与临床试验形式的科学证据关联的困难；模糊声明与意图不匹配的歧义性；以及主观真实性标签的固有性。我们认为，事实核查应被视为交互式沟通问题而非端到端流程。

</details>


### [7] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
**中文标题：优化语言模型的下游任务适应性：后训练视角**

*Zhengyan Shi*

主要分类: cs.CL

摘要简述: 本文提出了一系列优化语言模型（LM）下游任务适应性的方法，包括利用未标注数据的持续预训练技术、参数高效微调方法以及改进的监督微调策略，显著提升了模型的鲁棒性、效率和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管语言模型在自然语言处理中表现出色，但其在特定任务上的高效和鲁棒适应仍面临挑战，如未标注数据利用不足、小规模任务数据过拟合以及高计算成本等问题，限制了其在现实语言任务中的广泛应用。

研究方法: 1. 提出一种新颖的持续预训练技术，从未标注数据中提取任务相关知识；2. 开发参数高效的微调方法，降低内存和计算成本；3. 改进监督微调方法，提升模型在标注数据稀缺时的指令跟随能力；4. 设计新的评估方法和基准任务（如多跳空间推理任务），全面评估模型能力。

研究结果: 通过广泛的实验验证，这些方法显著提升了语言模型在多种NLP任务中的鲁棒性、效率和泛化能力，使其更适应广泛的应用场景。

研究结论: 本文提出的方法为语言模型的下游任务适应性提供了重要改进，推动了更鲁棒、高效的语言模型发展，向通用人工智能目标迈进了一步。

中文摘要: 语言模型（LM）在自然语言处理中展现出卓越能力，但高效且鲁棒地将其适配到特定任务仍具挑战性。随着模型规模和复杂度的增长，基于标注数据的微调往往未能充分利用未标注数据，容易在小规模任务数据上过拟合，且计算成本高昂，这些问题限制了其在现实语言任务中的广泛应用。

本文提出了一系列方法以更好地适配语言模型至下游应用。首先，我们探索从未标注数据中提取任务相关知识的策略，提出了一种新颖的持续预训练技术，其性能优于当前最先进的半监督方法。其次，我们提出了一种参数高效的微调方法，显著降低了内存和计算成本，同时保持了竞争力性能。我们还改进了监督微调方法，使语言模型在标注数据稀缺时能更好地遵循指令，提升了其在包括开放式生成在内的多种NLP任务中的表现。最后，我们开发了新的评估方法和基准任务（如多跳空间推理任务），以更全面地评估语言模型的能力和适应性。

通过广泛的实证研究，结果表明这些方法显著提升了语言模型的鲁棒性、效率和泛化能力，使其更适应广泛的应用场景。这些进展标志着向更鲁棒、高效的语言模型迈出了重要一步，使我们更接近通用人工智能的目标。

</details>


### [8] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
**中文标题：FineWeb2：一统天下的数据处理流水线——适应所有语言的预训练数据处理**

*Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf*

主要分类: cs.CL

摘要简述: 本文提出了一种名为FineWeb2的新型预训练数据处理流水线，能够自动适应多种语言，解决了多语言大语言模型预训练中数据过滤和去重的难题。通过实验验证，该流水线生成的语料库优于现有数据集，并进一步扩展到1000多种语言，发布了包含20TB数据的FineWeb2数据集。


<details>
  <summary>详细信息</summary>
研究动机: 当前多语言大语言模型的预训练面临数据过滤和去重流水线难以适应多种语言的挑战，尤其是高质量非英语数据集的缺乏。本文旨在通过自动化流水线解决这一问题，提升多语言模型的性能。

研究方法: 基于FineWeb设计了一种新型预训练数据集处理流水线，通过九种语言的实验验证其设计选择，并引入基于重复计数和质量的数据集再平衡方法。最终将流水线扩展到1000多种语言，生成FineWeb2数据集。

研究结果: 实验表明，该流水线生成的语料库优于现有数据集，并通过数据集再平衡进一步提升了模型性能。FineWeb2数据集包含20TB数据（50亿文档），覆盖1000多种语言。

研究结论: FineWeb2流水线能够高效处理多语言预训练数据，生成高质量语料库，显著提升模型性能，为多语言大语言模型的发展提供了重要支持。

中文摘要: 预训练最先进的大语言模型（LLMs）需要大量干净且多样化的文本数据。尽管近期在高质量英语预训练数据集的开源开发方面取得了显著进展，但训练高性能的多语言LLMs仍然是一个挑战，主要原因在于难以针对大量语言定制过滤和去重流水线。本文基于FineWeb提出了一种新的预训练数据集处理流水线，可自动适应支持任何语言。我们在九种不同语言上对流水线设计选择进行了广泛实验，并通过基于可测量标准的新颖选择过程确定了一组有意义且信息丰富的评估任务。最终，我们证明该流水线可用于创建优于现有数据集的非英语语料库。此外，我们还引入了一种简单且原则性的数据集再平衡方法，综合考虑重复计数和质量，进一步提升了性能。最后，我们将流水线扩展到1000多种语言，利用近100个Common Crawl快照生成了FineWeb2，这是一个20TB（50亿文档）的多语言数据集，我们同时发布了流水线、训练和评估代码库。

</details>


### [9] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
**中文标题：KaLM-Embedding-V2：卓越的训练技术与数据激发多功能嵌入模型**

*Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang*

主要分类: cs.CL

摘要简述: 本文提出KaLM-Embedding-V2，一种多功能紧凑的嵌入模型，通过创新的训练技术和丰富的数据，在通用文本嵌入任务中表现卓越。


<details>
  <summary>详细信息</summary>
研究动机: 现有嵌入模型在性能和泛化能力上存在不足，尤其是在紧凑模型上。本文旨在通过改进训练技术和数据，提升嵌入模型的性能与通用性。

研究方法: 方法包括：(1) 采用双向Transformer和均值池化生成固定长度嵌入；(2) 多阶段训练流程：预训练、微调和参数平均；(3) 引入焦点式重加权机制和在线硬负样本混合策略；(4) 使用大规模多样化的预训练和微调数据。

研究结果: 在MTEB中英文评测中，KaLM-Embedding-V2显著优于同类模型，并与更大模型竞争，成为参数少于10亿的紧凑嵌入模型新标杆。

研究结论: KaLM-Embedding-V2通过创新技术和丰富数据，实现了高性能和强泛化能力，为紧凑嵌入模型设定了新标准。

中文摘要: 本文提出KaLM-Embedding-V2，一种多功能紧凑的嵌入模型，通过创新的训练技术和数据在通用文本嵌入任务中表现卓越。主要创新包括：(1) 移除因果注意力掩码，采用双向Transformer和均值池化生成固定长度嵌入；(2) 多阶段训练流程：大规模弱监督开源语料预训练、高质量检索与非检索数据微调、模型参数平均；(3) 引入焦点式重加权机制和在线硬负样本混合策略；(4) 收集20类预训练数据和100类微调数据以提升性能与泛化能力。在MTEB中英文评测中，该模型显著优于同类模型，并与参数规模3倍、14倍、18倍和26倍的更大模型竞争，成为参数少于10亿的紧凑嵌入模型新标杆。

</details>


### [10] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
**中文标题：梯度下降能模拟提示吗？**

*Eric Zhang,Leshem Choshen,Jacob Andreas*

主要分类: cs.CL

摘要简述: 本文探讨了梯度下降是否能模拟提示的效果，提出了一种元训练方法，使梯度更新能模拟提示的作用，结果显示梯度下降在某些任务上表现接近提示效果。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法中，提示和微调是语言模型更新的两种主要方式。提示效果更好但存储成本高，而微调成本低但效果有限。本文旨在探索是否可以通过梯度下降模拟提示的效果。

研究方法: 提出了一种元训练方法，利用梯度元学习工具，以语言模型自身的提示预测为目标，无需真实标签。通过梯度下降训练，模拟提示的效果。

研究结果: 实验表明，梯度下降在某些任务（如“反转诅咒”任务和文本问答）上能部分或完全恢复提示模型的性能，显示梯度下降的表达能力。

研究结论: 研究表明，适当的初始化下，梯度下降具有强大的表达能力，为长上下文建模和梯度学习泛化能力提供了新思路。

中文摘要: 语言模型（LM）有两种主要方式整合新信息：改变提示或改变参数（如微调）。参数更新无需长期存储成本，但提示在许多情况下更有效：提示模型能从单例中泛化并完成逻辑推理，而标准微调则无法实现。本文提出一种元训练方法，使梯度更新能模拟提示的效果。该方法基于梯度元学习工具，以LM自身的提示预测为目标，无需真实标签。实验显示，梯度下降训练能部分（有时完全）恢复提示模型的性能，在“反转诅咒”任务和文本问答中表现优异。结果表明，适当的初始化下，梯度下降具有惊人的表达能力，为长上下文建模和梯度学习泛化能力提供了新视角。

</details>


### [11] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
**中文标题：SAC：一种用于测量和动态控制LLM人格特质强度的框架**

*Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SAC的框架，用于测量和动态控制大型语言模型（LLM）的人格特质强度，扩展了16PF模型以提供更精细的人格表达，并通过实验验证了其一致性和可控性。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多依赖大五人格模型（OCEAN），其人格维度较粗糙且缺乏强度控制机制。本文旨在填补这一空白，通过引入16PF模型和动态强度控制框架SAC，实现更精细和可控的LLM人格表达。

研究方法: 扩展了机器人格量表（MPI），引入16PF模型；开发了SAC框架，通过形容词语义锚定和五个强度因子（频率、深度、阈值、努力和意愿）动态诱导特质强度。

研究结果: 实验表明，连续谱强度建模比二元切换更一致且可控；目标特质强度的变化会系统影响相关特质，表明LLM内化了多维人格结构。

研究结论: SAC框架为医疗、教育和面试等领域提供了更精细的人机交互途径，推动了类人社交机器的实现。

中文摘要: 近年来，大型语言模型（LLM）在多个领域获得了广泛应用，人们对其在交互中展现类人特质的期望也日益增长。为满足这一需求，许多研究提出了通过心理测量评估建模LLM人格的方法。然而，现有模型大多依赖大五人格（OCEAN）框架，仅提供粗略的人格维度，且缺乏特质强度控制机制。本文通过扩展原基于大五模型的机器人格量表（MPI），引入16人格因子（16PF）模型，实现了对16种特质的精细控制。我们还开发了名为特定属性控制（SAC）的结构化框架，用于评估和动态诱导LLM的特质强度。该方法通过形容词语义锚定引导特质强度表达，并利用五个强度因子（频率、深度、阈值、努力和意愿）的行为问题。实验表明，连续谱强度建模比二元切换更一致且可控；目标特质强度的变化会系统影响相关特质，表明LLM内化了多维人格结构而非孤立处理特质。我们的工作为医疗、教育和面试等领域提供了更精细的人机交互途径，推动类人社交机器的实现。

</details>


### [12] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
**中文标题：大型语言模型在特许会计师考试中的卓越表现**

*Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta*

主要分类: cs.CL

摘要简述: 大型语言模型（LLMs）在财务领域的应用潜力巨大，但对其专业财务知识掌握程度的评估仍不明确。本文通过CA-Ben基准测试，评估了六种主流LLMs在印度特许会计师考试中的表现，发现Claude 3.5 Sonnet和GPT-4o表现最佳，但在数值计算和法律解释上仍有挑战。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在自然语言处理方面取得了显著进展，但其在专业财务领域的应用效果尚不明确。特别是在印度复杂的财务背景下，缺乏专门的评估工具。本文旨在填补这一空白，通过设计CA-Ben基准测试，评估LLMs在财务、法律和定量推理方面的能力。

研究方法: 本文设计了CA-Ben基准测试，基于印度特许会计师协会（ICAI）的考试题库，涵盖基础、中级和高级阶段的题目。评估了六种主流LLMs（GPT-4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4），采用标准化协议进行测试。

研究结果: 测试结果显示，Claude 3.5 Sonnet和GPT-4o在概念和法律推理方面表现最佳，但在数值计算和法律解释上仍存在明显挑战。其他模型的性能差异较大，表明当前LLMs在专业财务领域的应用仍有改进空间。

研究结论: 本文强调了LLMs在财务领域的潜力与局限性，尤其在数值分析和法律解释方面。未来可通过混合推理和检索增强生成方法进一步提升性能。

中文摘要: 先进的智能系统，尤其是大型语言模型（LLMs），通过自然语言处理（NLP）的进步显著重塑了财务实践。然而，这些模型在多大程度上有效掌握并应用专业财务知识仍不确定。针对印度财务背景下的关键空白，本文提出了CA-Ben，一个专门用于评估LLMs在财务、法律和定量推理能力上的特许会计师基准测试。CA-Ben包含基于印度特许会计师协会（ICAI）严格考试的结构化问答数据集，涵盖基础、中级和高级阶段的课程内容。通过标准化协议评估了六种主流LLMs（GPT-4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4）。结果显示，Claude 3.5 Sonnet和GPT-4o表现最佳，尤其在概念和法律推理方面，但在数值计算和法律解释上仍面临显著挑战。研究结果强调了当前LLMs的优势与局限，建议未来通过混合推理和检索增强生成方法改进定量分析和法律解释的准确性。

</details>


### [13] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
**中文标题：一种半监督可扩展的统一框架用于电子商务查询分类**

*Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law*

主要分类: cs.CL

摘要简述: 本文提出了一种半监督可扩展的统一框架（SSUF），用于解决电子商务查询分类中的信息不足和标签依赖问题，通过知识增强、标签增强和结构增强模块提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 电子商务查询通常简短且缺乏上下文，现有方法依赖用户点击行为构建训练样本，导致马太效应，且缺乏统一框架，算法优化效率低。

研究方法: SSUF框架包含知识增强模块（利用世界知识丰富查询表示）、标签增强模块（利用标签语义和半监督信号减少对后验标签的依赖）和结构增强模块（基于复杂标签关系增强标签表示），各模块高度可插拔。

研究结果: 离线和在线A/B实验表明，SSUF显著优于现有最先进模型。

研究结论: SSUF通过统一框架和增强模块有效解决了电子商务查询分类中的信息不足和标签依赖问题，提升了模型性能。

中文摘要: 查询分类（包括意图和类别预测等多个子任务）对电子商务应用至关重要。电子商务查询通常简短且缺乏上下文，标签间信息无法利用，导致建模先验信息不足。现有工业查询分类方法多依赖用户点击行为构建训练样本，形成马太效应。此外，查询分类子任务缺乏统一框架，算法优化效率低。本文提出了一种半监督可扩展的统一框架（SSUF），包含多个增强模块以统一查询分类任务。知识增强模块利用世界知识丰富查询表示，解决查询信息不足问题；标签增强模块利用标签语义和半监督信号减少对后验标签的依赖；结构增强模块基于复杂标签关系增强标签表示。各模块高度可插拔，输入特征可根据子任务需求增减。通过大量离线和在线A/B实验，结果表明SSUF显著优于现有最先进模型。

</details>


### [14] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
**中文标题：MT2-CSD：一种用于对话立场检测的新数据集及多语义知识融合方法**

*Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang*

主要分类: cs.CL

摘要简述: 本文提出MT2-CSD数据集和LLM-CRAN方法，用于多目标多轮对话立场检测，显著提升检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统立场检测研究多针对单实例，难以模拟真实社交媒体中的多轮对话场景，且缺乏相关数据集。本文旨在填补这一空白。

研究方法: 提出LLM-CRAN方法，利用大语言模型的推理能力增强对话理解，并构建MT2-CSD数据集，包含24,457标注实例。

研究结果: 实验表明，LLM-CRAN在MT2-CSD数据集上显著优于基线模型。

研究结论: MT2-CSD和LLM-CRAN为对话立场检测提供了新工具和基准，推动了该领域的发展。

中文摘要: 在当代社交媒体领域，自动立场检测对于意见挖掘至关重要，它通过综合和分析用户对争议话题的观点来揭示主流趋势和情感。传统立场检测研究通常针对单实例，限制了其在真实社交媒体多轮讨论场景中的应用。这一缺陷主要源于缺乏真实反映社交媒体互动动态的数据集，阻碍了对话立场检测的发展。本文介绍了MT2-CSD，一个用于多目标、多轮对话立场检测的综合数据集。据我们所知，MT2-CSD是目前该领域最大的数据集，包含24,457个标注实例，并展示了最深的对话层次，为立场检测提出了新挑战。为应对这些挑战，我们提出了大语言模型增强的对话关系注意力网络（LLM-CRAN），利用大语言模型的推理能力提升对话理解。我们通过大量实验评估了LLM-CRAN在MT2-CSD数据集上的效果。实验结果表明，LLM-CRAN在对话立场检测任务中显著优于强基线模型。

</details>


### [15] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
**中文标题：DALR：多模态句子表示学习的双层次对齐学习**

*Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji*

主要分类: cs.CL

摘要简述: 本文提出DALR（双层次对齐学习）方法，通过细粒度跨模态对齐和全局模态内对齐学习，解决多模态句子表示学习中的跨模态偏差和模态内语义分歧问题，显著提升表示质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在多模态句子表示学习中主要关注粗粒度对齐，面临跨模态偏差和模态内语义分歧两大挑战，导致表示质量下降。本文旨在通过双层次对齐学习解决这些问题。

研究方法: DALR方法包括两部分：1）跨模态对齐中，通过一致性学习模块软化负样本并利用辅助任务的语义相似性实现细粒度对齐；2）模态内对齐中，结合排序蒸馏和全局对齐学习，捕捉句子间复杂关系。

研究结果: 在语义文本相似性（STS）和迁移（TR）任务上的实验表明，DALR方法显著优于现有基线，验证了其有效性。

研究结论: DALR通过双层次对齐学习有效解决了多模态句子表示学习中的关键挑战，提升了表示质量，为未来研究提供了新思路。

中文摘要: 现有的多模态句子表示学习方法已取得显著成果，但多数方法仅关注粗粒度的图像与文本对齐，面临跨模态偏差和模态内语义分歧两大挑战，严重影响句子表示质量。为解决这些问题，我们提出DALR（多模态句子表示学习的双层次对齐学习）。在跨模态对齐方面，我们提出一致性学习模块，通过软化负样本并利用辅助任务的语义相似性实现细粒度对齐。此外，我们认为句子关系不仅限于二元正负标签，而是呈现更复杂的排序结构。为更好捕捉这些关系并提升表示质量，我们将排序蒸馏与全局模态内对齐学习相结合。在语义文本相似性（STS）和迁移（TR）任务上的全面实验验证了本方法的有效性，其性能始终优于现有基线。

</details>


### [16] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
**中文标题：ComRAG：基于动态向量存储的检索增强生成框架用于工业实时社区问答**

*Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan*

主要分类: cs.CL

摘要简述: ComRAG是一种用于实时工业社区问答的检索增强生成框架，通过动态向量存储整合静态知识与历史问答对，显著提升性能并降低延迟。


<details>
  <summary>详细信息</summary>
研究动机: 社区问答平台是重要的知识库，但现有方法未能充分利用外部知识或动态历史问答上下文，且缺乏适合工业部署的记忆机制。

研究方法: ComRAG采用基于质心的记忆机制，结合静态知识与动态历史问答对，实现高效检索、生成和存储。

研究结果: 在三个工业CQA数据集上，ComRAG显著优于基线方法，向量相似性提升25.9%，延迟降低8.7%-23.3%，块增长从20.23%降至2.06%。

研究结论: ComRAG通过动态整合知识库与历史问答对，为工业社区问答提供了高效的实时解决方案。

中文摘要: 社区问答平台（CQA）是社区中重要的知识库，但如何实时有效地利用历史交互和领域知识仍具挑战性。现有方法往往未能充分利用外部知识，或未结合动态历史问答上下文，且缺乏适合工业部署的记忆机制。我们提出ComRAG，一种用于实时工业CQA的检索增强生成框架，通过基于质心的记忆机制整合静态知识与动态历史问答对，实现高效检索、生成和存储。在三个工业CQA数据集上的评估表明，ComRAG始终优于所有基线方法——向量相似性提升高达25.9%，延迟降低8.7%至23.3%，块增长从20.23%降至2.06%。

</details>


### [17] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
**中文标题：Progtuning：基于Transformer语言模型的渐进式微调框架**

*Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu*

主要分类: cs.CL

摘要简述: Progtuning是一种新型的渐进式微调框架，通过逐步减少Transformer块的更新数量，优化计算资源分配，显著降低参数更新量（约25%），同时保持性能竞争力。


<details>
  <summary>详细信息</summary>
研究动机: 随着Transformer模型规模增大，全参数微调成本高昂，而现有参数高效微调方法仍存在资源分配不均的问题，忽略了Transformer块贡献的差异性。

研究方法: 提出Progtuning框架，根据Transformer块的贡献逐步减少更新的块数量，优化资源分配，并与参数高效微调方法兼容。

研究结果: Progtuning减少约25%的更新参数，同时保持性能竞争力，并在多种适应场景中表现优异。

研究结论: Progtuning通过渐进式微调显著提升资源效率，为大规模语言模型微调提供了高效解决方案。

中文摘要: 微调是利用基于Transformer的语言模型进行下游任务的一种有效技术。随着模型规模不断增大，更新所有模型参数的成本越来越高。参数高效微调方法通过选择性更新一小部分参数有效解决了这一问题。然而，微调和大多数现有参数高效微调方法仍需更新与初始规模相同数量的参数，忽略了Transformer块之间的贡献差异，导致计算资源分配极不高效。本文提出Progtuning，一种结合渐进式学习的新型微调框架，用于基于Transformer的语言模型。具体而言，Progtuning根据贡献逐步减少更新的Transformer块数量。值得注意的是，Progtuning优化了资源分配，减少了约25%的更新参数，同时仍保持竞争力性能。此外，它与参数高效微调方法具有高度适应性，在各种适应场景中表现出色。

</details>


### [18] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
**中文标题：用于文本扩散建模的压缩平滑潜在空间**

*Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov*

主要分类: cs.CL

摘要简述: 论文提出了一种名为Cosmos的新方法，通过在压缩且平滑的潜在空间中运行扩散模型来改进文本生成，实现了比传统方法更快的推理速度和更高的生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 自回归语言模型在现代文本生成中占主导地位，但其顺序性导致解码速度慢且难以保持全局一致性。扩散模型虽能并行生成并提供灵活控制，但因词元级表示的高维度而难以应用于文本生成。

研究方法: Cosmos通过在一个专门为扩散模型设计的压缩、平滑潜在空间中运行，解决了高维度问题。该空间通过自编码器学习，同时训练词元级重建和与预训练语言编码器的对齐，提供语义基础并支持有效的扰动增强。

研究结果: 实验表明，Cosmos能将文本表示压缩8倍，同时保持与词元级扩散模型相当的生成质量。增加潜在序列长度后，Cosmos甚至超越了扩散模型和自回归基线模型。在故事生成、问题生成、摘要和去毒化等任务中，Cosmos表现优异，推理速度快2倍以上。

研究结论: Cosmos在压缩潜在空间中实现了高质量的文本生成，同时显著提升了推理速度，为文本扩散模型提供了一种高效且灵活的解决方案。

中文摘要: 自回归语言模型在现代文本生成中占据主导地位，但其顺序性带来了根本性限制：解码速度慢且难以保持全局一致性。扩散模型通过并行生成和灵活控制提供了一种有前景的替代方案，但其在文本生成中的应用因词元级表示的高维度而受到阻碍。我们提出了Cosmos，这是一种完全在压缩且平滑的潜在空间中运行的文本生成新方法，该空间专为扩散模型设计。该空间通过自编码器学习，同时训练词元级重建和与预训练语言编码器的对齐，提供稳健的语义基础并支持有效的扰动增强。实验表明，文本表示可压缩8倍，同时生成质量与词元级扩散模型相当。此外，增加潜在序列长度使Cosmos超越了扩散模型和自回归基线模型。我们在故事生成、问题生成、摘要和去毒化等四种生成任务中评估了Cosmos，并与多种生成范式进行比较。Cosmos在生成质量上达到或超越其他方法，同时推理速度快2倍以上。

</details>


### [19] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
**中文标题：CBF-AFA：基于分块的多自监督学习融合自动流畅度评估方法**

*Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc*

主要分类: cs.CL

摘要简述: 本文提出了一种基于分块的多自监督学习融合方法（CBF-AFA），用于自动流畅度评估，通过结合多种自监督学习模型和分层CNN-BiLSTM框架，显著提升了评估性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动流畅度评估（AFA）在非母语者中仍具挑战性，尤其是捕捉语音节奏、停顿和不流畅性。现有方法难以兼顾声学和语言特征，因此需要一种更精细的评估方法。

研究方法: 采用基于分块的方法，结合Wav2Vec2、HuBERT和WavLM等自监督学习模型，利用Silero-VAD将语音分割为呼吸组分块，并通过可学习的加权机制融合特征。同时，引入分块级流畅度标记（如语速、停顿时长等），并使用CNN-BiLSTM框架捕捉局部和长期依赖关系。

研究结果: 在Avalinguo和Speechocean762数据集上，该方法比单一自监督学习基线在F1分数和Pearson相关系数上分别提升了2.8和6.2点（Speechocean762），以及4.2和4.0点（Avalinguo），优于基于Pyannote.audio的分割基线。

研究结论: 分块多自监督学习融合方法在流畅度评估中表现优异，但未来需进一步研究其在非规则韵律方言中的泛化能力。

中文摘要: 自动流畅度评估（AFA）在非母语者中仍具挑战性，尤其是捕捉语音节奏、停顿和不流畅性。本文提出了一种基于分块的方法，结合了自监督学习模型（Wav2Vec2、HuBERT和WavLM），利用它们在语音、韵律和噪声语音建模中的互补优势，并采用分层CNN-BiLSTM框架。通过Silero语音活动检测（Silero-VAD）将语音分割为呼吸组分块，实现细粒度时间分析，同时避免过度分割。自监督学习嵌入通过可学习的加权机制融合，平衡声学和语言特征，并加入分块级流畅度标记（如语速、停顿时长、n-gram重复）。CNN-BiLSTM用于捕捉分块间的局部和长期依赖关系。在Avalinguo和Speechocean762数据集上的评估表明，该方法在Speechocean762上比单一自监督学习基线在F1分数和Pearson相关系数上分别提升了2.8和6.2点，在Avalinguo上提升了4.2和4.0点，优于基于Pyannote.audio的分割基线。这些结果表明，分块多自监督学习融合方法在流畅度评估中具有鲁棒性，但未来需进一步研究其在非规则韵律方言中的泛化能力。

</details>


### [20] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
**中文标题：维护MTEB：确保嵌入基准的长期可用性与可重现性**

*Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen*

主要分类: cs.CL

摘要简述: 本文探讨了如何通过工程实践确保大规模文本嵌入基准（MTEB）的长期可重现性和可扩展性，包括自动化测试、数据集完整性验证以及社区贡献管理。


<details>
  <summary>详细信息</summary>
研究动机: MTEB已成为文本嵌入模型评估的标准平台，但其长期可重现性和可扩展性需要系统化的工程支持。本文旨在解决这一问题，确保基准的持续可用性和质量。

研究方法: 通过设计稳健的持续集成流程，自动化验证数据集完整性、执行测试并评估结果的泛化能力。同时，详细介绍了增强可重现性和可用性的设计选择，以及处理社区贡献和扩展新任务与数据集的策略。

研究结果: 这些工程实践成功扩展了MTEB的覆盖范围，同时保持了其质量和领域相关性，为机器学习评估框架的可重现性和可用性提供了宝贵经验。

研究结论: 本文的经验为面临类似挑战的基准维护者提供了重要参考，强调了工程实践在确保评估框架长期可用性中的关键作用。

中文摘要: 大规模文本嵌入基准（MTEB）已成为文本嵌入模型评估的标准平台。尽管已有研究确立了核心基准方法，本文聚焦于确保MTEB持续可重现性和可扩展性的工程实践。我们介绍了维护稳健持续集成流程的方法，包括验证数据集完整性、自动化测试执行以及评估基准结果的泛化能力。此外，详细说明了增强可重现性和可用性的设计选择，并探讨了处理社区贡献及扩展新任务与数据集的策略。这些工程实践在扩展MTEB覆盖范围的同时，保持了其质量和领域相关性。我们的经验为机器学习评估框架的可重现性和可用性提供了宝贵见解。MTEB代码库地址：https://github.com/embeddings-benchmark/mteb

</details>


### [21] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
**中文标题：基于提示的对话轮换预测**

*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

主要分类: cs.CL

摘要简述: 本文提出了一种基于文本提示的动态控制对话轮换预测模型，通过指令（如“更快”或“更冷静”）直观调整预测行为，实验证明其提高了预测准确性并有效适应不同对话场景。


<details>
  <summary>详细信息</summary>
研究动机: 现有的对话轮换预测模型缺乏动态控制能力，无法根据对话需求灵活调整。本文旨在通过文本提示实现直观且显式的动态控制，提升对话系统的适应性和用户体验。

研究方法: 基于Transformer的语音活动预测（VAP）模型，引入文本提示嵌入到通道级和跨通道Transformer中，利用大语言模型生成合成提示句子进行训练和评估。

研究结果: 实验使用了超过950小时的人类对话数据，结果显示模型不仅提高了预测准确性，还能根据文本提示动态调整对话轮换时机。

研究结论: 提出的模型通过文本提示实现了对话轮换预测的动态控制，为对话系统和机器人提供了更灵活的交互能力。

中文摘要: 对话轮换预测模型是语音对话系统和会话机器人的核心组件。近期研究利用基于Transformer的架构实现实时连续的语音活动预测。本研究提出了一种新模型，通过文本提示动态控制对话轮换预测。这种方法允许通过“更快”或“更冷静”等指令直观且显式地控制，动态适应对话伙伴和场景。该模型基于Transformer的语音活动预测（VAP）模型，将文本提示嵌入到通道级和跨通道Transformer中。我们使用超过950小时的人类对话数据评估了该方法的可行性。由于现有数据集中缺乏文本提示数据，我们利用大语言模型（LLM）生成合成提示句子。实验结果表明，该模型提高了预测准确性，并能根据文本提示有效调整对话轮换时机行为。

</details>


### [22] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
**中文标题：通过语法检索增强大型语言模型在自动术语提取中的应用**

*Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim*

主要分类: cs.CL

摘要简述: 本文提出了一种基于语法检索的提示策略，用于增强大型语言模型在自动术语提取任务中的表现，通过语法相似性而非语义相似性选择示例，提升了术语边界的捕捉能力。


<details>
  <summary>详细信息</summary>
研究动机: 自动术语提取（ATE）是机器翻译和信息检索等下游任务的关键步骤，但大型语言模型（LLM）在ATE中的潜力尚未充分探索。本文旨在探索如何通过语法检索优化LLM在ATE任务中的表现。

研究方法: 提出了一种基于语法检索的提示策略，在少样本设置下，根据语法相似性而非语义相似性选择示例。该方法与领域无关，能更可靠地指导术语边界的捕捉。

研究结果: 在三个专业ATE基准测试中，语法检索方法显著提高了F1分数，证明了语法线索在术语提取任务中的重要性。

研究结论: 研究表明，语法检索方法能有效提升大型语言模型在术语提取任务中的表现，尤其是在跨领域设置中，语法相似性比语义相似性更具指导意义。

中文摘要: 自动术语提取（ATE）用于识别领域特定的表达，对机器翻译和信息检索等下游任务至关重要。尽管大型语言模型（LLM）在多种NLP任务中取得了显著进展，但其在ATE中的潜力尚未充分研究。我们提出了一种基于检索的提示策略，在少样本设置下，根据语法而非语义相似性选择示例。这种语法检索方法不受领域限制，并能更可靠地指导术语边界的捕捉。我们在领域内和跨领域设置中评估了该方法，分析了查询句子与其检索示例之间的词汇重叠对性能的影响。在三个专业ATE基准测试上的实验表明，语法检索提高了F1分数。这些发现凸显了语法线索在将LLM应用于术语提取任务中的重要性。

</details>


### [23] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
**中文标题：Agent-RewardBench：面向真实世界多模态代理的感知、规划与安全性奖励建模统一基准**

*Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

主要分类: cs.CL

摘要简述: 本文提出了Agent-RewardBench，一个用于评估多模态大语言模型（MLLMs）在奖励建模能力的基准测试，涵盖感知、规划和安全性三个维度，并通过7种真实场景和步骤级评估来提升模型的自我修正和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）的发展，多模态代理在真实任务中展现出潜力，但由于缺乏外部反馈，其自我修正和泛化能力受限。奖励模型作为外部反馈的潜在解决方案，目前缺乏统一的选择标准，因此亟需一个针对代理的奖励基准测试。

研究方法: 本文提出Agent-RewardBench，其特点包括：（1）多维度评估（感知、规划、安全性）和7种真实场景；（2）步骤级奖励评估，提供任务执行过程中的细粒度性能分析；（3）精心设计的难度控制和高质量数据，确保测试的挑战性和完整性。

研究结果: 实验表明，即使最先进的多模态模型在奖励建模任务中表现有限，凸显了针对代理的奖励模型进行专门训练的必要性。

研究结论: Agent-RewardBench为多模态代理的奖励建模提供了一个全面且高质量的评估基准，填补了现有研究的空白，并推动了相关领域的发展。

中文摘要: 随着多模态大语言模型（MLLMs）的进步，多模态代理在网页导航和具身智能等真实任务中展现出潜力。然而，由于缺乏外部反馈，这些代理在自我修正和泛化方面存在困难。奖励模型作为一种潜在的外部反馈解决方案，但目前缺乏明确的选择标准。因此，亟需建立一个针对代理的奖励基准测试。为解决这些问题，我们提出了Agent-RewardBench，一个用于评估MLLMs奖励建模能力的基准测试。该基准具有三个关键特征：（1）多维度评估和真实代理场景覆盖，涵盖感知、规划和安全性三个维度及7种场景；（2）步骤级奖励评估，允许在任务执行过程中对代理能力进行细粒度分析；（3）精心设计的难度控制和高质量数据，确保任务的挑战性和数据的完整性。实验表明，即使最先进的多模态模型表现有限，凸显了代理奖励建模专门训练的必要性。代码已在github上发布。

</details>


### [24] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
**中文标题：猫鼠游戏——假文本生成能否超越检测系统？**

*Andrea McGlinchey,Peter J Barclay*

主要分类: cs.CL

摘要简述: 大型语言模型能生成逼真的“假文本”，但简单分类器能以较低资源实现较高检测准确率。研究发现，随着模型升级，某些模型（如Gemini）生成欺骗性文本的能力增强，但GPT未表现出类似趋势，表明检测假文本仍具可行性。


<details>
  <summary>详细信息</summary>
研究动机: 研究探讨大型语言模型生成“假文本”的能力是否会超越检测系统，以及检测技术是否能在模型规模不断增长的情况下保持有效性。

研究方法: 通过统计分类器检测古典侦探小说风格的“假文本”，比较不同版本模型（如Gemini和GPT）生成文本的欺骗性。

研究结果: Gemini在0.5版本升级后生成欺骗性文本的能力增强，而GPT未表现出类似趋势。

研究结论: 尽管模型规模扩大，但检测假文本仍具可行性，新模型架构可能提升欺骗性。

中文摘要: 大型语言模型能在学术写作、产品评论和政治新闻等领域生成逼真的“假文本”。尽管检测技术看似会引发无休止的“军备竞赛”，但研究发现，新模型需更多参数、训练数据和能源，而简单分类器能以较低资源实现较高检测准确率。为探讨模型是否会在欺骗检测器方面达到瓶颈，本研究通过统计分类器检测古典侦探小说风格的“假文本”。在0.5版本升级中，Gemini生成欺骗性文本的能力增强，而GPT未表现出类似趋势。这表明，即使模型规模不断扩大，可靠检测假文本仍具可行性，但新模型架构可能提升其欺骗性。

</details>


### [25] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
**中文标题：双重检查器：通过自我批判微调增强慢思考大语言模型的推理能力**

*Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin*

主要分类: cs.CL

摘要简述: 本文提出Double-Checker框架，通过自我批判和迭代优化提升慢思考大语言模型的推理能力，显著提高其在复杂推理任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 慢思考大语言模型（LLMs）虽具备反思式推理能力，但其生成批判性反馈和优化解决方案的能力有限。本文旨在通过自我批判和迭代优化，提升这类模型的推理能力。

研究方法: Double-Checker框架通过微调1,730个自我批判实例，使模型能够在推理过程中迭代批判和优化其输出，直至自我评估为正确。

研究结果: 实验表明，Double-Checker将AIME基准测试的pass@1性能从4.4%提升至18.2%，显著增强了慢思考LLMs的推理能力。

研究结论: Double-Checker为开发更具信任度和有效性的LLMs提供了新方向，展示了自我批判在提升模型推理能力中的潜力。

中文摘要: 尽管慢思考大语言模型（LLMs）表现出类似反思的推理能力（常称为“顿悟时刻”），但其生成信息丰富的批判性反馈和优化先前解决方案的能力仍然有限。本文提出了Double-Checker，一个旨在通过促进显式自我批判和迭代优化来增强慢思考LLMs推理能力的框架。通过在我们整理的1,730个自我批判实例上进行微调，Double-Checker使长链思维LLMs能够在推理过程中迭代批判和优化其输出，直至其自我评估为正确。我们在全面的推理基准测试中验证了Double-Checker的有效性，结果表明迭代自我批判显著提升了长链思维LLMs的推理能力。值得注意的是，与原始长链思维LLMs相比，我们的Double-Checker将AIME基准测试的pass@1性能从4.4%提升至18.2%。这些结果突显了开发更具信任度和有效性的LLMs的潜力，这些模型能够进行结构化的自我批判。

</details>


### [26] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
**中文标题：小型编码器在检测文本基于上下文时可比肩大型解码器**

*Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar*

主要分类: cs.CL

摘要简述: 研究表明，轻量级编码器模型（如RoBERTa和NomicBERT）在检测文本是否基于上下文时，性能可媲美大型语言模型（如Llama3 8B和GPT4o），同时显著降低推理延迟。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在缺乏上下文信息时容易生成不可靠的回答，而检测文本是否基于上下文（groundedness）对于确保事实一致性和可信度至关重要。本研究旨在通过轻量级模型提前检测，以减少资源消耗和推理时间。

研究方法: 研究使用轻量级编码器模型（如RoBERTa和NomicBERT），通过在精心策划的数据集上进行微调，检测查询是否基于提供的上下文。

研究结果: 实验表明，这些轻量级模型的准确性可与大型语言模型（如Llama3 8B和GPT4o）相媲美，同时推理延迟显著降低。

研究结论: 轻量级编码器模型在检测文本是否基于上下文时具有高效性，能够替代大型语言模型，显著减少资源消耗和延迟。

中文摘要: 通过为大型语言模型（LLMs）提供外部上下文，可以显著提升其在自然语言处理（NLP）任务中的表现。然而，当上下文缺乏信息时，LLMs往往难以可靠地回答查询，转而依赖无根据的推测或内部知识。基于上下文生成严格支持的响应（groundedness）对于确保事实一致性和可信度至关重要。本研究专注于在LLMs进行昂贵的答案生成之前，检测给定查询是否基于提供的上下文。这种检测机制可以显著减少推理时间和资源消耗。我们证明，经过精心策划数据集微调的轻量级任务特定编码器模型（如RoBERTa和NomicBERT），在检测基于上下文的准确性上可与最先进的LLMs（如Llama3 8B和GPT4o）相媲美，同时将推理延迟降低数个数量级。代码发布于：https://github.com/chandarlab/Hallucinate-less

</details>


### [27] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
**中文标题：基于自回归语言模型的视觉对话中指代表达式检测**

*Bram Willemsen,Gabriel Skantze*

主要分类: cs.CL

摘要简述: 本文探讨了仅使用自回归语言模型从视觉对话中提取指代表达式的可行性，发现仅依赖文本语境也能有效完成任务，但任务本质是多模态的。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索仅依赖语言语境（而非视觉信息）能否有效检测对话中的指代表达式，以评估语言模型在此任务中的潜力。

研究方法: 采用预训练的大型语言模型（LLM），通过参数高效微调，利用下一词预测任务标注对话中的指代表达式边界。

研究结果: 实验表明，即使使用中等规模的LLM和小数据集，仅文本方法也能有效完成任务，凸显语言语境的重要性，但任务本质是多模态的。

研究结论: 尽管文本方法有效，但指代表达式检测本质是多模态问题，单模态方法存在固有局限性。

中文摘要: 本文探讨了仅使用文本自回归语言模型从视觉对话中提取指代表达式的方法。具体目标是研究仅依赖语言语境能否有效检测对话中提及的（视觉可感知的）指代对象。为此，我们调整了一个预训练的大型语言模型（LLM），通过下一词预测任务对对话中的指代表达式边界进行粗粒度标注。结果表明，即使使用中等规模的LLM、小数据集和参数高效微调，仅文本方法也能有效完成任务，凸显了语言语境在此任务中的重要性。然而，我们认为该任务本质上是多模态问题，并讨论了单模态方法的固有局限性。

</details>


### [28] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
**中文标题：结构主义视角下的人工智能文学批评：利用格雷马斯符号学方阵增强大语言模型**

*Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen*

主要分类: cs.CL

摘要简述: 本文提出GLASS框架，基于格雷马斯符号学方阵（GSS），提升大语言模型（LLMs）的深度文学分析能力，并构建首个GSS文学批评数据集，验证其高效性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在文本理解和生成方面表现出色，但在对思想深刻、叙事复杂的文学作品进行专业文学批评时存在不足。本文旨在通过结构化框架提升LLMs的文学分析能力。

研究方法: 提出GLASS框架，基于GSS设计结构化分析方法，构建包含48部作品的GSS文学批评数据集，并采用LLM-as-a-judge范式量化评估框架性能。

研究结果: GLASS框架在多项作品和LLMs上的表现优于专家批评，且应用于39部经典作品时，填补了现有研究空白，生成高质量分析。

研究结论: GLASS为文学研究和教育提供了基于AI的工具，揭示了文学认知机制，推动了LLMs在专业文学批评领域的应用。

中文摘要: 大语言模型（LLMs）在文本理解和生成方面表现出色，但在对思想深刻、叙事复杂的文学作品进行专业文学批评时存在不足。本文提出GLASS（基于格雷马斯符号学方阵的文学分析）框架，通过结构化分析方法提升LLMs的深度文学分析能力。GLASS能够快速解构叙事作品的结构和深层含义。我们构建了首个基于GSS的文学批评数据集，包含对48部作品的详细分析，并采用LLM-as-a-judge范式提出量化评估指标。与专家批评相比，GLASS在多项作品和LLMs上的表现优异。最后，我们将GLASS应用于39部经典作品，填补了现有研究空白，生成了原创且高质量的分析。本研究为文学研究和教育提供了基于AI的工具，并为文学认知机制提供了新的见解。

</details>


### [29] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
**中文标题：利用LLM辅助查询理解提升实时检索增强生成**

*Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng*

主要分类: cs.CL

摘要简述: 本文提出Omni-RAG框架，通过LLM辅助的查询理解提升实时检索增强生成（RAG）系统的鲁棒性，解决复杂、模糊和多意图查询的处理问题。


<details>
  <summary>详细信息</summary>
研究动机: 现实中的实时RAG系统在处理噪声、模糊和多意图查询时表现不佳，现有系统通常在干净数据上训练或评估，难以应对复杂输入。本文旨在填补这一能力差距。

研究方法: Omni-RAG包含三个模块：1) 深度查询理解与分解，利用LLM去噪和分解查询；2) 意图感知知识检索，为子查询检索并聚合结果；3) 重排与生成，通过重排器和LLM生成最终响应。

研究结果: Omni-RAG显著提升了RAG系统对复杂和噪声查询的处理能力，适用于开放域实时应用，如SIGIR 2025 LiveRAG挑战赛中的场景。

研究结论: Omni-RAG通过LLM辅助的查询理解，有效增强了RAG系统在实时开放域环境中的鲁棒性和实用性。

中文摘要: 现实中的实时检索增强生成（RAG）系统在处理噪声、模糊和多意图的用户查询时面临巨大挑战。尽管RAG通过外部知识增强了大型语言模型（LLM），但现有系统通常难以应对此类复杂输入，因为它们通常在干净数据上训练或评估。本文提出了Omni-RAG，一种新颖的框架，旨在提升RAG系统在实时开放域环境中的鲁棒性和有效性。Omni-RAG利用LLM辅助的查询理解，通过三个关键模块预处理用户输入：1) 深度查询理解与分解，利用定制提示的LLM去噪查询（如纠正拼写错误）并将多意图查询分解为结构化子查询；2) 意图感知知识检索，从语料库（如使用OpenSearch的FineWeb）中检索每个子查询并聚合结果；3) 重排与生成，通过重排器（如BGE）优化文档选择，最后由LLM（如Falcon-10B）使用思维链提示生成最终响应。Omni-RAG旨在通过稳健处理复杂和噪声查询，填补当前RAG能力与实际应用需求（如SIGIR 2025 LiveRAG挑战赛所强调的）之间的差距。

</details>


### [30] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
**中文标题：领域知识增强的大语言模型用于欺诈与概念漂移检测**

*Ali Şenol,Garima Agrawal,Huan Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种结合领域知识的大语言模型（LLM）框架，用于检测欺诈和概念漂移，显著提升了分类准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 动态平台上欺骗性对话的检测因语言模式演变和概念漂移（CD）而变得困难，传统LLM在风险敏感场景中易受上下文模糊和幻觉影响，亟需结合领域知识提升性能。

研究方法: 提出一个三组件框架：1) DK-LLM模块检测虚假对话；2) 漂移检测单元（OCDD）识别语义变化；3) 第二个DK-LLM模块分类漂移性质。基于LLaMA实现，结合结构化提示。

研究结果: 在虚假评论数据集和SEConvo对话数据集上验证，分类准确率达98%，显著优于零样本基线，证明领域知识和漂移检测的有效性。

研究结论: 领域知识增强的LLM框架在欺诈和概念漂移检测中表现出色，提升了高风险NLP应用的性能和可解释性。

中文摘要: 在动态平台上检测欺骗性对话因语言模式演变和概念漂移（CD）而日益困难，这些变化可能掩盖恶意意图或模仿正常对话，使准确分类更具挑战性。尽管大语言模型（LLM）在自然语言任务中表现优异，但在风险敏感场景中常受上下文模糊和幻觉困扰。为解决这些问题，我们提出了一种领域知识（DK）增强的LLM框架，将预训练LLM与结构化任务特定洞察结合，用于欺诈和概念漂移检测。该架构包含三个主要组件：1) DK-LLM模块检测虚假对话；2) 漂移检测单元（OCDD）判断语义是否发生偏移；3) 第二个DK-LLM模块将漂移分类为良性或欺诈性。我们首先通过虚假评论数据集验证领域知识的价值，随后将完整框架应用于SEConvo多轮对话数据集（包含多种欺诈和垃圾攻击）。结果表明，系统能高精度检测虚假对话并有效分类漂移性质。基于LLaMA的实现通过结构化提示达到98%的分类准确率。与零样本基线的对比研究表明，结合领域知识和漂移意识显著提升了高风险NLP应用的性能、可解释性和鲁棒性。

</details>


### [31] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
**中文标题：跨语言的Text2Cypher：评估超越英语的基础模型**

*Makbule Gulcin Ozsoy,William Tai*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型在多语言Text2Cypher任务中的表现，发现英语性能最高，西班牙语次之，土耳其语最低，并探讨了提示翻译的影响。


<details>
  <summary>详细信息</summary>
研究动机: 当前自然语言接口研究多集中于英语，其他语言评估有限。本文旨在评估多语言环境下基础模型在Text2Cypher任务中的表现，并填补这一研究空白。

研究方法: 通过将英文问题翻译为西班牙语和土耳其语，同时保留原始Cypher查询，创建多语言测试集。使用标准化提示和指标评估多个基础模型。

研究结果: 结果显示模型性能依次为英语最高，西班牙语次之，土耳其语最低。提示翻译对评估指标影响微小。

研究结论: 研究强调了多语言查询生成评估和开发的必要性，未来工作包括模式本地化和多语言微调。

中文摘要: 近年来，大型语言模型的进步使得自然语言接口能够将用户问题转化为数据库查询，例如Text2SQL、Text2SPARQL和Text2Cypher。尽管这些接口提升了数据库的可访问性，但当前研究多集中于英语，对其他语言的评估有限。本文研究了基础模型在多语言Text2Cypher任务中的表现。我们通过将英文问题翻译为西班牙语和土耳其语，同时保留原始Cypher查询，创建并发布了一个多语言测试集，以实现公平的跨语言比较。使用标准化提示和指标评估多个基础模型。结果显示一致的性能模式：英语最高，西班牙语次之，土耳其语最低。我们将其归因于训练数据可用性和语言特性的差异。此外，我们探讨了将任务提示翻译为西班牙语和土耳其语的影响。结果显示评估指标变化微小，表明提示翻译影响较小。我们的发现强调了多语言查询生成评估和开发的必要性。未来工作包括模式本地化和多语言微调。

</details>


### [32] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
**中文标题：基于用户交互的语音对话模型对齐**

*Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez*

主要分类: cs.CL

摘要简述: 本文提出了一种新颖的偏好对齐框架，通过用户交互改进实时语音对话模型。该方法利用大规模标注数据集和离线对齐技术，显著提升了对话模型的事实性、安全性和上下文一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的偏好学习方法主要针对文本语言模型，难以适应实时语音交互的复杂性（如打断、插话等）。本文旨在填补这一空白，通过用户交互优化语音对话模型。

研究方法: 构建了一个包含15万对偏好标注的大规模数据集，涵盖语言内容和时间上下文变化。采用离线对齐方法微调全双工自回归语音到语音模型。

研究结果: 实验表明，基于通用对话的反馈能显著提升模型的事实性、安全性和上下文对齐能力。人类评估进一步验证了模型在多轮对话中的表现。

研究结论: 研究强调了在实时语音对话系统中平衡多种动态因素的重要性，为自然对话系统的优化提供了新思路。

中文摘要: 本文提出了一种新颖的偏好对齐框架，用于通过用户交互改进实时语音对话模型。现有的偏好学习方法主要针对文本语言模型，难以适应实时语音交互的复杂性（如打断、插话等），且缺乏明确的说话轮次分割。我们构建了一个包含15万对偏好标注的大规模数据集，涵盖语言内容和时间上下文变化，并利用离线对齐方法微调全双工自回归语音到语音模型。实验表明，基于通用对话的反馈能显著提升模型的事实性、安全性和上下文对齐能力。我们部署了微调后的模型，并通过全面的人类评估验证了其多轮对话效果。研究揭示了在实时语音对话系统中平衡多种动态因素的重要性，这对自然对话系统的优化至关重要。

</details>


### [33] [TopK Language Models](https://arxiv.org/abs/2506.21468)
**中文标题：TopK语言模型**

*Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling*

主要分类: cs.CL

摘要简述: 本文提出了一种改进的Transformer架构，通过引入TopK激活函数，使模型的隐藏状态等同于TopK稀疏自编码器的潜在特征，从而无需后训练即可提供与稀疏自编码器相当的模型可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏自编码器（SAEs）在分析和解释基于Transformer的语言模型时存在局限性，例如后训练的不确定性、特征不稳定性和难以跨检查点比较。本文旨在解决这些问题，提供一种更稳定和可靠的工具来理解语言模型的学习和表示过程。

研究方法: 作者提出了一种改进的Transformer架构，在选定层中引入TopK激活函数，使隐藏状态直接等同于TopK稀疏自编码器的潜在特征。这种方法避免了后训练的需求，同时保持了模型的可解释性。

研究结果: 实验表明，TopK语言模型通过稀疏表示成功实现了目标神经元的干预和跨检查点、跨层的神经元形成过程分析。模型在保持原始性能的同时，显著提升了可解释性和稳定性。

研究结论: TopK语言模型通过简单的架构改进，实现了模型大小、计算效率和可解释性之间的良好平衡，为未来模型可解释性和可控性研究提供了重要工具。

中文摘要: 稀疏自编码器（SAEs）已成为分析和解释基于Transformer的语言模型（LMs）激活空间的重要工具。然而，SAEs存在一些缺点，降低了其实用性和内部有效性。由于SAEs是后训练的，因此不清楚未能发现某个概念是SAE的问题还是底层LM未表示该概念。这一问题因训练条件和架构选择影响SAE学习哪些特征而加剧。在追踪LMs在训练过程中如何学习概念时，特征的不稳定性也使得难以比较不同检查点之间的SAE特征。为解决这些限制，我们提出了一种改进的Transformer架构，在选定层中引入TopK激活函数，使模型的隐藏状态等同于TopK SAE的潜在特征。这种方法消除了后训练的需求，同时提供了与SAEs相当的可解释性。TopK LMs在模型大小、计算效率和可解释性之间实现了良好的平衡。尽管架构简单，TopK LMs保持了原始能力，同时提供了稳健的可解释性优势。实验表明，TopK LMs学习的稀疏表示成功实现了目标神经元的干预，并促进了跨检查点和跨层的神经元形成过程的详细分析。这些特征使TopK LMs成为理解语言模型如何学习和表示概念的稳定可靠工具，我们相信这将显著推动未来模型可解释性和可控性的研究。

</details>


### [34] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
**中文标题：连接离线和在线强化学习用于大型语言模型**

*Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov*

主要分类: cs.CL

摘要简述: 本文研究了从离线到半在线再到完全在线环境中，强化学习方法在微调大型语言模型时的有效性，发现在线和半在线方法表现相似且优于离线方法，同时多任务学习能提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索强化学习方法在不同训练环境（离线、半在线、完全在线）下对大型语言模型微调的效果，尤其是在可验证和不可验证任务中的应用。

研究方法: 方法包括在可验证数学任务和不可验证指令跟随任务上进行实验，比较在线和半在线直接偏好优化与群体奖励策略优化目标，并分析训练动态和超参数选择策略。

研究结果: 结果显示在线和半在线方法表现相似且显著优于离线方法，同时多任务学习可同时提升可验证和不可验证任务的性能。

研究结论: 结论表明在线和半在线强化学习方法在微调大型语言模型中具有优势，多任务学习能进一步提升性能，为实际应用提供了重要参考。

中文摘要: 我们研究了强化学习方法在从离线到半在线再到完全在线环境中微调大型语言模型时的有效性，涵盖可验证和不可验证任务。实验包括在可验证数学任务和不可验证指令跟随任务上的训练，并对两者进行基准评估。在这些设置中，我们广泛比较了在线和半在线直接偏好优化与群体奖励策略优化目标，意外发现这些变体之间的性能和收敛性相似，且均显著优于离线方法。我们详细分析了训练动态和超参数选择策略以实现最佳结果。最后，我们表明同时使用可验证和不可验证奖励进行多任务学习可以提升两种任务类型的性能。

</details>


### [35] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
**中文标题：通过交互式LLM对齐增强社交对话中的用户参与度**

*Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li*

主要分类: cs.CL

摘要简述: 通过交互式LLM对齐技术提升社交对话中的用户参与度，利用用户反应作为奖励信号，结合i×MCTS和直接偏好优化（DPO）实现高效对齐。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究在社交对话中优化知识推理或对话行为规划，但未能直接提升用户参与度。本文旨在通过交互式LLM学习用户参与信号，填补这一空白。

研究方法: 采用用户反应作为奖励信号，通过i×MCTS模拟用户与LLM的交互，收集高质量和低质量对话数据，并使用DPO对齐LLM以提升用户参与度。

研究结果: 在情感支持对话和劝导对话两种场景中，实验证明该方法显著提升了交互式LLM的用户参与度。

研究结论: 通过直接优化用户参与信号，交互式LLM在社交对话中表现出更强的用户吸引力，验证了方法的有效性。

中文摘要: 在社交对话中，通过交互提升用户参与度至关重要。尽管先前研究优化了模型以推理相关知识或规划对话行为流，但用户参与度与知识或对话行为之间的关系微妙，且无法保证社交对话中的用户参与度。为此，我们通过利用对话未来发展的信号，使交互式LLM学习用户参与度。具体而言，我们采用更直接且相关的用户参与度指标，即用户在与交互后的对话意图相关的反应，作为奖励来对齐交互式LLM。为实现这一点，我们开发了一个用户模拟器与目标交互式LLM交互，并通过i×MCTS（交互的蒙特卡洛树搜索）探索用户与交互式LLM系统之间的交互。通过这种方式，我们收集了包含高质量和低质量体验对的数据集，并使用直接偏好优化（DPO）对齐交互式LLM以实现高水平的用户参与度。在两种社交对话场景（情感支持对话和劝导对话）上的实验表明，我们的方法有效提升了交互式LLM的用户参与度。

</details>


### [36] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
**中文标题：skLEP：斯洛伐克通用语言理解基准**

*Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko*

主要分类: cs.CL

摘要简述: 本文介绍了skLEP，首个专为评估斯洛伐克自然语言理解（NLU）模型设计的综合基准，涵盖九项多样化任务，并提供了数据集、工具包和公开排行榜。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏针对斯洛伐克语的NLU评估基准，限制了相关研究的发展。本文旨在填补这一空白，推动斯洛伐克语NLU研究的进步。

研究方法: 通过整理新的斯洛伐克语数据集和翻译现有英语NLU资源，构建了skLEP基准，涵盖词级、句子对和文档级任务，并对多种预训练语言模型进行了系统评估。

研究结果: skLEP基准成功评估了斯洛伐克语、多语言和英语预训练模型的性能，并公开了完整数据集、工具包和排行榜。

研究结论: skLEP为斯洛伐克语NLU研究提供了首个全面基准，促进了未来研究的可重复性和发展。

中文摘要: 本文介绍了skLEP，首个专为评估斯洛伐克自然语言理解（NLU）模型设计的综合基准。skLEP包含九项多样化任务，覆盖词级、句子对和文档级挑战，全面评估模型能力。为构建该基准，我们整理了新的斯洛伐克语原创数据集，并精心翻译了现有的英语NLU资源。本文还首次对多种斯洛伐克语专用、多语言和英语预训练语言模型进行了系统且广泛的评估。最后，我们公开了完整的基准数据、一个支持模型微调和评估的开源工具包，以及一个公开排行榜（https://github.com/slovak-nlp/sklep），以期促进研究的可重复性并推动斯洛伐克语NLU的未来发展。

</details>


### [37] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
**中文标题：大型语言模型中的波将金理解**

*Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan*

主要分类: cs.CL

摘要简述: 本文探讨大型语言模型（LLMs）在基准测试中的表现是否真实反映其理解能力，提出“波将金理解”概念，即模型通过非人类方式回答问题造成的理解假象，并通过实验证明这种现象普遍存在。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLMs）通过基准测试（如AP考试）评估其能力，但这些测试是否真实反映模型的理解能力尚不明确。若模型的理解方式与人类不同，其成功可能仅是“波将金理解”的假象。本文旨在验证这一现象。

研究方法: 提出两种量化“波将金理解”的方法：一是在三个领域设计专用基准测试，二是提供一种通用方法以计算其普遍性的下限。通过这些方法分析模型在不同任务和领域中的表现。

研究结果: 研究发现，“波将金理解”现象在模型、任务和领域中普遍存在，且这种失败不仅源于错误理解，还反映了概念表征的内部不一致性。

研究结论: 基准测试可能无法真实反映LLMs的理解能力，因其可能通过非人类方式回答问题。研究呼吁重新审视评估方法，以避免“波将金理解”的误导。

中文摘要: 大型语言模型（LLMs）通常通过基准数据集进行评估。但如何证明基于一组精选问题的回答可以推断LLMs的能力？本文首先引入一个正式框架来回答这一问题。关键在于注意到用于测试LLMs的基准（如AP考试）同样用于测试人类。然而，这隐含了一个前提：这些基准只有在LLMs以与人类相似的方式误解概念时才有效。否则，基准测试的成功仅展示了“波将金理解”：一种由与人类解释概念方式不符的答案驱动的理解假象。我们提出了两种量化“波将金理解”存在的方法：一是在三个领域设计专用基准测试，二是提供一种通用方法以计算其普遍性的下限。我们发现“波将金理解”在模型、任务和领域中普遍存在，且这些失败不仅反映了错误理解，还揭示了概念表征的深层内部不一致性。

</details>


### [38] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
**中文标题：“医生，怎么了？”：分析用户如何在大规模对话AI数据集中寻求健康信息**

*Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal*

主要分类: cs.CL

摘要简述: 本文通过分析大规模对话AI数据集中的健康信息查询行为，揭示了用户如何利用大型语言模型（LLM）获取医疗信息，并指出了潜在风险和改进需求。


<details>
  <summary>详细信息</summary>
研究动机: 随着用户越来越多地通过交互式聊天机器人从大型语言模型（LLM）获取医疗信息，这些对话的性质和潜在风险尚未得到充分研究。本文旨在填补这一空白。

研究方法: 研究团队从大规模对话AI数据集中筛选出HealthChat-11K，这是一个包含11K真实对话和25K用户消息的精选数据集。结合临床医生驱动的分类法，系统分析了用户在21个不同健康领域的交互行为。

研究结果: 分析揭示了用户获取健康信息的方式和动机，包括常见交互、上下文不完整的情况、情感行为以及可能引发迎合行为的提问方式，突显了LLM在医疗支持能力上的改进需求。

研究结论: 研究表明，用户通过LLM获取健康信息的行为复杂多样，存在潜在风险，需进一步优化LLM的医疗支持功能。

中文摘要: 人们越来越多地通过交互式聊天机器人从大型语言模型（LLM）获取医疗信息，但这些对话的性质和潜在风险尚未得到充分研究。本文通过筛选大规模对话AI数据集，构建了HealthChat-11K，一个包含11K真实对话和25K用户消息的精选数据集。结合临床医生驱动的分类法，我们系统研究了用户在21个不同健康领域的交互行为。分析揭示了用户获取健康信息的方式和动机，包括常见交互、上下文不完整的情况、情感行为以及可能引发迎合行为的提问方式，突显了LLM在医疗支持能力上的改进需求。相关代码和分析工具可在以下链接获取：https://github.com/yahskapar/HealthChat

</details>


### [39] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
**中文标题：语言模型训练中的数据效能**

*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

主要分类: cs.CL

摘要简述: 本文提出数据效能（Data Efficacy）概念，通过优化训练数据的组织方式提升语言模型性能，并设计DELT框架（包括数据评分、选择和排序），实验证明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究多关注数据效率（如数据筛选和采样），而数据组织方式对语言模型训练的影响尚未充分探索。本文旨在填补这一空白，提出数据效能的概念。

研究方法: 提出DELT框架，包含数据评分（LQS）、数据选择和数据排序（FO）。LQS从梯度一致性角度评估数据的可学习性和质量，FO解决模型遗忘和数据分布偏差问题。

研究结果: 实验表明：1）DELT在不增加数据量和模型规模的情况下提升语言模型性能；2）LQS与FO组合效果最佳；3）数据效能与数据效率可协同实现。

研究结论: 数据效能是语言模型训练中一个潜力巨大的研究方向，DELT框架为优化数据组织提供了有效工具。

中文摘要: 数据是语言模型（LM）训练的基础。近期研究致力于数据效率，旨在通过选择最小或最优的训练数据子集来最大化性能。数据过滤、采样和选择等技术在此领域至关重要。作为补充，我们定义了数据效能，其目标是通过优化训练数据的组织来最大化性能，目前尚未得到充分探索。本文提出了一个通用范式DELT，用于在LM训练中考虑数据效能，强调训练数据组织的重要性。DELT包含三个组件：数据评分、数据选择和数据排序。在这些组件中，我们设计了可学习性-质量评分（LQS）作为数据评分的新实例，从梯度一致性的角度考虑每个数据样本的可学习性和质量。我们还设计了折叠排序（FO）作为数据排序的新实例，解决了模型遗忘和数据分布偏差等问题。全面的实验验证了数据效能在LM训练中的有效性，结果表明：首先，DELT的多种实例在不增加数据规模和模型大小的情况下不同程度地提升了LM性能；其次，在这些实例中，我们提出的LQS数据评分与FO数据排序的组合效果最为显著；最后，通过应用数据选择，数据效能可以与数据效率共同实现。因此，我们认为数据效能是LM训练中一个极具潜力的基础领域。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport](https://arxiv.org/abs/2506.20741)
**中文标题：OTSurv：一种基于异质性感知最优传输的多实例学习生存预测框架**

*Qin Ren,Yifan Wang,Ruogu Fang,Haibin Ling,Chenyu You*

主要分类: cs.CV

摘要简述: OTSurv是一种基于最优传输的多实例学习框架，用于解决全切片图像（WSI）生存预测中的病理异质性问题。通过全局长尾约束和局部不确定性约束，显著提升了预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有多实例学习方法在全切片图像生存预测中难以显式捕捉病理异质性，包括全局的长尾形态分布和局部的切片级预测不确定性。最优传输提供了一种建模这种异质性的原则性方法。

研究方法: OTSurv将生存预测建模为一个异质性感知的最优传输问题，引入全局长尾约束和局部不确定性约束，并通过不平衡最优传输问题高效求解。

研究结果: 在六个流行基准测试中，OTSurv取得了新的最佳性能，C-index平均提升3.6%，并在对数秩检验中表现出统计显著性。

研究结论: OTSurv是一种强大的数字病理生存预测工具，具有高解释性和显著性能提升。

中文摘要: 利用全切片图像（WSI）进行生存预测可以建模为一个多实例学习（MIL）问题。然而，现有的MIL方法通常无法显式捕捉WSI中的病理异质性，包括全局的长尾形态分布和局部的切片级预测不确定性。最优传输（OT）通过引入边缘分布约束，为建模这种异质性提供了一种原则性方法。基于这一思路，我们提出了OTSurv，一种从最优传输视角出发的新型MIL框架。具体而言，OTSurv将生存预测建模为一个异质性感知的OT问题，包含两个约束：（1）全局长尾约束，通过调节传输质量分配来建模先验形态分布，避免模式崩溃和过度均匀化；（2）局部不确定性感知约束，通过逐步增加总传输质量来优先处理高置信度切片并抑制噪声。随后，我们将初始OT问题转化为一个不平衡OT问题，并通过高效的硬件友好矩阵缩放算法求解。实验表明，OTSurv在六个流行基准测试中取得了新的最佳性能，C-index平均提升3.6%。此外，OTSurv在对数秩检验中表现出统计显著性，并具有高解释性，使其成为数字病理生存预测的强大工具。代码可在https://github.com/Y-Research-SBU/OTSurv获取。

</details>


### [41] [StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation](https://arxiv.org/abs/2506.20756)
**中文标题：StereoDiff：立体匹配与扩散协同的视频深度估计**

*Haodong Li,Chen Wang,Jiahui Lei,Kostas Daniilidis,Lingjie Liu*

主要分类: cs.CV

摘要简述: StereoDiff是一种两阶段视频深度估计方法，结合立体匹配和视频深度扩散，分别处理静态和动态区域，显著提升视频深度的一致性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 视频深度估计并非图像深度估计的简单扩展，静态和动态区域的时序一致性需求不同。静态区域（如背景）可通过立体匹配获得全局3D线索，而动态区域需依赖大规模视频数据学习平滑过渡。

研究方法: StereoDiff分为两阶段：1）利用立体匹配处理静态区域；2）通过视频深度扩散模型学习动态区域的平滑过渡。通过频域分析证明两者的互补性。

研究结果: 在零样本、真实世界及动态视频深度基准测试中，StereoDiff在室内外场景均表现出最先进的性能，深度估计的一致性和准确性显著提升。

研究结论: StereoDiff通过立体匹配与视频深度扩散的协同作用，有效解决了视频深度估计中静态与动态区域的不同需求，实现了更优的性能。

中文摘要: 近期的视频深度估计方法通过借鉴图像深度估计的范式（如基于大规模数据微调预训练的视频扩散模型）取得了显著成果。然而，我们认为视频深度估计并非图像深度估计的简单扩展。视频中动态与静态区域的时序一致性需求存在根本差异。静态区域（如背景）的深度一致性可通过跨帧立体匹配更有效地实现，从而提供更强的全局3D线索；而动态区域的平滑过渡仍需依赖大规模视频深度数据学习，因其违背了三角测量约束。基于此，我们提出了StereoDiff，一种两阶段视频深度估计方法，通过立体匹配主要处理静态区域，同时利用视频深度扩散模型保持动态区域的深度过渡一致性。通过频域分析，我们从数学上证明了立体匹配与视频深度扩散的互补性，突显了二者协同的优势。在零样本、真实世界及动态视频深度基准测试中，StereoDiff在室内外场景均展示了最先进的性能，其深度估计的一致性和准确性显著优于现有方法。

</details>


### [42] [ConViTac: Aligning Visual-Tactile Fusion with Contrastive Representations](https://arxiv.org/abs/2506.20757)
**中文标题：ConViTac：基于对比表征的视觉-触觉融合对齐**

*Zhiyuan Wu,Yongqiang Zhao,Shan Luo*

主要分类: cs.CV

摘要简述: 本文提出ConViTac，一种通过对比表征增强视觉-触觉特征融合对齐的网络，显著提升下游任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉和触觉是机器人感知和操作任务中的两种互补感官模态，但现有方法在特征融合时往往效果不佳。本文旨在通过对比表征学习改善视觉-触觉特征的融合对齐。

研究方法: 提出ConViTac网络，采用对比嵌入条件（CEC）机制，通过自监督对比学习预训练的编码器将视觉和触觉输入映射到统一潜在嵌入，并利用跨模态注意力实现特征融合。

研究结果: 实验表明，ConViTac在材料分类和抓取预测任务中准确率提升高达12.0%，优于现有方法。

研究结论: ConViTac通过对比表征学习有效改善了视觉-触觉特征的融合对齐，显著提升了任务性能。

中文摘要: 视觉和触觉是机器人感知和操作任务中的两种基本感官模态，能够提供互补信息以增强任务性能。以往研究尝试联合学习视觉-触觉表征以提取更有意义的信息，但这些方法通常依赖直接组合（如特征相加或拼接）进行模态融合，导致特征整合效果不佳。本文提出ConViTac，一种视觉-触觉表征学习网络，旨在通过对比表征增强融合过程中的特征对齐。我们的核心贡献是对比嵌入条件（CEC）机制，该机制利用通过自监督对比学习预训练的对比编码器，将视觉和触觉输入投影到统一的潜在嵌入中。这些嵌入通过跨模态注意力实现视觉-触觉特征融合，目标是统一表征的对齐并提升下游任务性能。我们通过大量实验证明了ConViTac在现实任务中优于当前最先进方法，且所提出的CEC机制在材料分类和抓取预测任务中将准确率提升高达12.0%。

</details>


### [43] [AI-Driven MRI-based Brain Tumour Segmentation Benchmarking](https://arxiv.org/abs/2506.20786)
**中文标题：基于AI驱动的MRI脑肿瘤分割基准测试**

*Connor Ludwig,Khashayar Namdar,Farzad Khalvati*

主要分类: cs.CV

摘要简述: 本研究比较了多种AI模型（如SAM、SAM 2、MedSAM、SAM-Med-3D和nnU-Net）在BraTS 2023数据集上的脑肿瘤分割性能，发现SAM和SAM 2在精确边界框提示下表现优异，但nnU-Net仍为最佳选择。


<details>
  <summary>详细信息</summary>
研究动机: 近年来出现了许多可提示的通用模型和医学变体，但缺乏对这些模型在多种提示质量下的评估和比较。本研究旨在填补这一空白。

研究方法: 使用SAM、SAM 2、MedSAM、SAM-Med-3D和nnU-Net在BraTS 2023成人胶质瘤和儿科数据集上进行零样本推理，并对部分模型进行微调。

研究结果: SAM和SAM 2在精确边界框提示下Dice分数分别达到0.894和0.893，优于nnU-Net，但nnU-Net仍因实用性更强而占优。微调后点提示性能显著提升，但仍不及边界框或nnU-Net。

研究结论: 尽管SAM系列模型在特定条件下表现优异，但nnU-Net仍是医学图像分割的首选。微调显示未来潜力，但需进一步研究。

中文摘要: 医学图像分割极大地辅助了医学诊断，其中基于U-Net的架构和nnU-Net提供了最先进的性能。近年来出现了许多通用可提示模型及其医学变体，但目前缺乏对这些模型在多种提示质量下的评估和比较。本研究使用Segment Anything Model (SAM)、Segment Anything Model 2 (SAM 2)、MedSAM、SAM-Med-3D和nnU-Net，在BraTS 2023成人胶质瘤和儿科数据集上进行了零样本推理，覆盖多种点提示和边界框提示质量。其中部分模型表现出色，尤其是SAM和SAM 2在精确边界框提示下的Dice分数分别达到0.894和0.893，超过了nnU-Net的分割性能。然而，由于提供高精度提示的不切实际性，nnU-Net仍是医学图像分割的主导网络。研究还通过微调SAM、SAM 2、MedSAM和SAM-Med-3D在儿科数据集上扩展了模型和提示的评估与比较。微调后点提示性能显著提升，显示出未来研究的潜力，但仍无法超越边界框或nnU-Net的分割效果。

</details>


### [44] [How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?](https://arxiv.org/abs/2506.20795)
**中文标题：基础模型与基于骨架的方法在人机交互手势识别中的比较**

*Stephanie Käs,Anton Burenko,Louis Markert,Onur Alp Culha,Dennis Mack,Timm Linder,Bastian Leibe*

主要分类: cs.CV

摘要简述: 本文比较了基础模型与基于骨架的方法在机器人交互中手势识别的表现，发现骨架方法HD-GCN表现最佳，但基础模型V-JEPA接近其性能，为简化系统复杂度提供了可能。


<details>
  <summary>详细信息</summary>
研究动机: 手势在嘈杂环境中（如敏捷生产）是实现人机非语言交流的重要方式。传统深度学习手势识别依赖任务特定架构，而视觉基础模型（VFMs）和视觉语言模型（VLMs）因其强大泛化能力，可能替代专用模块，降低系统复杂度。

研究方法: 研究比较了V-JEPA（先进VFM）、Gemini Flash 2.0（多模态VLM）和HD-GCN（高性能骨架方法）在动态全身手势识别中的表现，并引入NUGGET数据集进行评估。

研究结果: HD-GCN表现最佳，但V-JEPA仅通过简单分类头接近其性能，为多任务共享模型提供了可能；Gemini在零样本设置中难以区分手势，表明需进一步研究输入表示。

研究结论: 骨架方法仍占优，但基础模型V-JEPA展现了简化系统的潜力，未来需优化输入表示以提升其性能。

中文摘要: 手势在嘈杂环境（如敏捷生产）中实现了人机非语言交流。传统基于深度学习的手势识别依赖任务特定架构，输入为图像、视频或骨架姿态估计。而视觉基础模型（VFMs）和视觉语言模型（VLMs）凭借强大泛化能力，有望替代专用模块，降低系统复杂度。本研究探讨了如何将这些模型应用于动态全身手势识别，比较了V-JEPA（先进VFM）、Gemini Flash 2.0（多模态VLM）和HD-GCN（高性能骨架方法）。我们引入了NUGGET数据集，专为物流环境中人机通信设计，以评估不同手势识别方法。实验显示，HD-GCN表现最佳，但V-JEPA通过简单分类头接近其性能，为共享多任务模型提供了可能。相比之下，Gemini在零样本设置中难以基于文本描述区分手势，突显了进一步研究手势输入表示的必要性。

</details>


### [45] [Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models](https://arxiv.org/abs/2506.20832)
**中文标题：利用视觉语言模型选择扩散模型生成的可信超分辨率样本**

*Cansu Korkmaz,Ahmet Murat Tekalp,Zafer Dogan*

主要分类: cs.CV

摘要简述: 本文提出了一种利用视觉语言模型（VLM）从扩散模型生成的多组超分辨率（SR）图像中选择最可信样本的自动化框架，并通过混合指标（TWS）验证其可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 超分辨率问题存在多解性，传统方法在平衡保真度和感知质量时可能引入伪影，而扩散模型生成的多样SR图像缺乏可信样本选择机制。本文旨在解决这一问题。

研究方法: 通过视觉语言模型（如BLIP-2、GPT-4o）的结构化查询评估SR图像的语义正确性、视觉质量和伪影情况，并设计混合指标TWS（结合CLIP嵌入、SSIM和小波分解）量化可靠性。

研究结果: 实验表明，TWS与人类偏好高度相关，且VLM引导的选择始终获得高TWS值，优于传统指标（如PSNR、LPIPS）。

研究结论: 本文通过结合VLM和TWS，为扩散模型生成的SR图像提供了可信选择框架，为生成式SR的可靠性设定了新标准。

中文摘要: 超分辨率（SR）是一个病态逆问题，存在多个可行解。传统的回归SR模型试图平衡保真度和感知质量，但这种权衡常引入伪影，导致信息关键应用（如数字或字母识别）中的模糊性。另一方面，扩散模型生成多样SR图像，但从中选择最可信解仍具挑战。本文提出了一种自动化框架，利用视觉语言模型（VLM）的语义推理能力，从扩散生成集中识别最可信SR样本。具体而言，通过结构化查询提示VLM（如BLIP-2、GPT-4o及其变体）评估语义正确性、视觉质量和伪影情况，并集成排名靠前的SR候选以低成本生成单一可信输出。为严格验证VLM选择样本的有效性，我们提出了一种新颖的信任度评分（TWS），这是一种混合指标，通过CLIP嵌入的语义相似性、边缘图SSIM的结构完整性以及多级小波分解的伪影敏感性来量化SR可靠性。实验表明，TWS在模糊和自然图像中均与人类偏好高度相关，且VLM引导的选择始终获得高TWS值。相比传统指标（如PSNR、LPIPS）无法反映信息保真度，我们的方法为导航扩散SR空间的不确定性提供了原则性、可扩展且通用的解决方案。通过使输出与人类期望和语义正确性对齐，本研究为生成式SR的可信度设定了新标准。

</details>


### [46] [FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization](https://arxiv.org/abs/2506.20841)
**中文标题：FixCLR：基于负类对比学习的半监督域泛化方法**

*Ha Min Son,Shahbaz Rezaei,Xin Liu*

主要分类: cs.CV

摘要简述: FixCLR是一种半监督域泛化方法，通过改进对比学习，利用伪标签的类别信息和排斥项，显式地学习域不变表示，提升模型在分布外数据上的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 半监督域泛化（SSDG）在标签稀缺的情况下难以有效泛化到分布外数据。现有方法未显式地学习域不变表示，而这是域泛化的关键目标。FixCLR旨在通过改进对比学习解决这一问题。

研究方法: FixCLR通过利用伪标签的类别信息和仅使用排斥项，改进对比学习以显式地学习域不变表示。该方法可与现有SSDG和半监督方法结合，进一步提升性能。

研究结果: 实验表明，FixCLR是一种有效的SSDG方法，尤其在与其他半监督方法结合时表现更优。研究还探索了半监督方法的改进、预训练与非预训练模型的性能比较，以及多域数据集的测试。

研究结论: FixCLR通过显式地学习域不变表示，显著提升了半监督域泛化的性能，为标签稀缺场景下的模型泛化提供了有效解决方案。

中文摘要: 半监督域泛化（SSDG）旨在解决在仅有少量标签可用时泛化到分布外数据的问题。由于标签稀缺，传统的域泛化方法表现不佳。现有的SSDG方法将半监督学习方法与各种正则化项结合，但这些方法未显式地学习所有域的域不变表示，而这正是域泛化的关键目标。为此，我们提出了FixCLR。受自监督学习成功的启发，我们改进了对比学习的两个关键组件：利用伪标签的类别信息和仅使用排斥项。FixCLR还可以与大多数现有的SSDG和半监督方法结合，以进一步提升性能。我们的研究包括在SSDG研究中尚未广泛探索的多种实验，例如评估半监督方法的改进、比较预训练与非预训练模型的性能，以及在多域数据集上的测试。总体而言，FixCLR被证明是一种有效的SSDG方法，尤其是与其他半监督方法结合时。

</details>


### [47] [Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision](https://arxiv.org/abs/2506.20850)
**中文标题：医学视觉中像素级预训练的向量对比学习**

*Yuting He,Shuo Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为COVER的向量对比学习框架，用于解决医学视觉中像素级预训练的过分散问题，通过向量回归量化特征距离，显著提升了像素级自监督预训练的效果。


<details>
  <summary>详细信息</summary>
研究动机: 对比学习（CL）在自监督预训练（SSP）中已成为基础模型的核心，但将其扩展到像素级表示（对医学视觉至关重要）仍是一个开放问题。标准的二元CL会导致特征过度分散，破坏像素级特征相关性。

研究方法: 本文提出向量对比学习（Vector CL），将CL重新定义为向量回归问题，通过建模特征距离来量化像素级预训练中的分散性。具体实现为COVER框架，支持可扩展的向量自学习，并利用向量金字塔架构实现粒度适应。

研究结果: 在8个任务（涵盖2个维度和4种模态）上的实验表明，COVER显著提升了像素级自监督预训练的效果，推动了通用医学视觉基础模型的发展。

研究结论: COVER通过向量回归解决了像素级预训练中的过分散问题，保留了特征相关性，为医学视觉领域的自监督预训练提供了新思路。

中文摘要: 对比学习（CL）已成为基础模型中自监督预训练（SSP）的基石，但将其扩展到医学视觉中至关重要的像素级表示仍是一个开放问题。标准CL将SSP表述为一个二元优化问题（二元CL），其中对特征分散的过度追求会导致过分散问题，破坏像素级特征相关性，从而扰乱类内分布。我们的向量CL将CL重新定义为向量回归问题，通过建模特征距离来量化像素级预训练中的分散性。为实现这一新范式，我们提出了COntrast in VEctor Regression（COVER）框架。COVER建立了可扩展的基于向量的自学习，强制从向量回归到距离建模的优化流程一致性，并利用向量金字塔架构实现粒度适应，从而在SSP中保留像素级特征相关性。在涵盖2个维度和4种模态的8个任务上的广泛实验表明，COVER显著提升了像素级SSP，推动了通用医学视觉基础模型的进步。

</details>


### [48] [Enhancing Ambiguous Dynamic Facial Expression Recognition with Soft Label-based Data Augmentation](https://arxiv.org/abs/2506.20867)
**中文标题：基于软标签数据增强的动态模糊面部表情识别增强方法**

*Ryosuke Kawamura,Hideaki Hayashi,Shunsuke Otake,Noriko Takemura,Hajime Nagahara*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MIDAS的数据增强方法，通过软标签增强动态面部表情识别（DFER）中模糊表情的处理能力，实验证明其在DFEW和FERV39k-Plus数据集上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 动态面部表情识别在实际应用中常遇到模糊表情，现有方法难以准确识别。本文旨在通过数据增强提升模糊表情的识别性能。

研究方法: 提出MIDAS方法，通过软标签表示多情感类别的概率，并利用视频帧及其情感标签的凸组合进行数据增强，扩展了mixup方法以适应视频数据。

研究结果: 在DFEW和FERV39k-Plus数据集上的实验表明，使用MIDAS增强数据训练的模型性能优于现有方法。

研究结论: MIDAS是一种简单高效的数据增强方法，显著提升了动态面部表情识别中模糊表情的处理能力。

中文摘要: 动态面部表情识别（DFER）是一项通过面部表情视频序列估计情绪的任务。在实际应用中，准确识别模糊面部表情（常见于真实场景数据）至关重要。本研究提出MIDAS，一种数据增强方法，旨在通过软标签（表示多情感类别的概率）提升模糊面部表情数据的DFER性能。MIDAS通过凸组合视频帧及其对应的情感标签来增强训练数据，将mixup方法扩展至软标签视频数据，为处理DFER中的模糊性提供了一种简单而高效的方法。为评估MIDAS，我们在DFEW数据集和新构建的FERV39k-Plus数据集（为现有DFER数据集分配软标签）上进行了实验。结果表明，使用MIDAS增强数据训练的模型性能优于在原始数据集上训练的最先进方法。

</details>


### [49] [THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion](https://arxiv.org/abs/2506.20877)
**中文标题：THIRDEYE：基于大脑启发多阶段融合的线索感知单目深度估计**

*Calin Teodor Ioan*

主要分类: cs.CV

摘要简述: THIRDEYE提出了一种基于大脑启发多阶段融合的线索感知单目深度估计方法，通过预训练网络显式提供视觉线索，并结合记忆模块加权融合，生成高分辨率视差图。


<details>
  <summary>详细信息</summary>
研究动机: 传统单目深度估计方法通常直接从RGB像素隐式学习深度，忽略了人类视觉系统依赖的显式线索（如遮挡边界、阴影和透视）。THIRDEYE旨在通过显式提供这些线索，提升深度估计的准确性。

研究方法: THIRDEYE采用三阶段皮层层次结构（V1->V2->V3），通过预训练且冻结的专家网络显式提供视觉线索，并利用键值工作记忆模块加权融合。最后通过自适应分箱变换器生成高分辨率视差图。

研究结果: THIRDEYE通过冻结的专家网络继承了大量外部监督，仅需少量微调即可实现高分辨率深度估计。定量结果将在后续版本中公布。

研究结论: THIRDEYE通过显式利用视觉线索和多阶段融合，显著提升了单目深度估计的性能，同时减少了训练需求。

中文摘要: 传统单目深度估计方法通常训练深度模型直接从RGB像素推断深度，这种隐式学习往往忽略了人类视觉系统依赖的显式单目线索（如遮挡边界、阴影和透视）。THIRDEYE提出了一种线索感知的流程，通过专门的预训练且冻结的网络显式提供这些线索。这些线索在一个配备键值工作记忆模块的三阶段皮层层次结构（V1->V2->V3）中融合，并根据可靠性加权。随后，自适应分箱变换器头生成高分辨率视差图。由于线索专家网络被冻结，THIRDEYE继承了大量的外部监督，仅需少量微调。本扩展版本提供了更多架构细节、神经科学动机和扩展的实验协议；定量结果将在后续版本中公布。

</details>


### [50] [MultiHuman-Testbench: Benchmarking Image Generation for Multiple Humans](https://arxiv.org/abs/2506.20879)
**中文标题：MultiHuman-Testbench：多人图像生成的基准测试**

*Shubhankar Borse,Seokeon Choi,Sunghyun Park,Jeongho Kim,Shreya Kadambi,Risheek Garrepalli,Sungrack Yun,Munawar Hayat,Fatih Porikli*

主要分类: cs.CV

摘要简述: 本文提出了MultiHuman-Testbench，一个用于评估多人生成图像模型的新基准，包含1800个样本和5550张人脸图像，通过多维度指标评估模型性能，并提出了改进身份相似度的新技术。


<details>
  <summary>详细信息</summary>
研究动机: 目前缺乏专门用于评估多人生成图像模型的基准，导致生成复杂动作且保留面部身份的图像成为挑战。本文旨在填补这一空白，提供一个标准化工具以推动多人生成图像研究。

研究方法: 构建了包含1800个样本和5550张人脸图像的基准数据集，提供文本提示和匹配的姿势条件图像。提出四项关键指标（人脸数量、身份相似度、提示对齐和动作检测）评估模型性能，并引入基于分割和匈牙利匹配的新技术以提升身份相似度。

研究结果: 通过评估多种模型（包括零样本和基于训练的方法），发现提出的新技术显著提高了身份相似度。基准数据集和评估方法为多人生成图像研究提供了标准化工具和重要见解。

研究结论: MultiHuman-Testbench为多人生成图像研究提供了首个专用基准，提出的评估方法和新技术显著提升了模型性能，为未来研究奠定了基础。

中文摘要: 生成包含多个复杂动作且保留面部身份的图像是一项重大挑战，主要原因之一是缺乏专用基准。为此，我们提出了MultiHuman-Testbench，一个用于严格评估多人生成模型的新基准。该基准包含1800个样本，包括精心设计的文本提示，描述从简单到复杂的人类动作。这些提示与5550张独特的人脸图像匹配，确保年龄、种族背景和性别的多样性。除了文本提示，我们还提供了与提示准确匹配的人工选择的姿势条件图像。我们提出了一套多维度评估方法，采用四项关键指标量化人脸数量、身份相似度、提示对齐和动作检测。我们对多种模型进行了全面评估，包括零样本方法和基于训练的方法（有无区域先验）。此外，我们提出了基于分割和匈牙利匹配的新技术，显著提升了身份相似度。提出的基准和关键发现为多人生成图像研究提供了宝贵见解和标准化工具。

</details>


### [51] [The Role of Cyclopean-Eye in Stereo Vision](https://arxiv.org/abs/2506.20900)
**中文标题：Cyclopean Eye在立体视觉中的作用**

*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

主要分类: cs.CV

摘要简述: 本文研究了现代立体视觉系统的几何基础，重点探讨了3D结构和人类感知如何提升深度重建精度。通过重新审视Cyclopean Eye模型并提出新的几何约束，结合深度学习特征匹配和注意力机制，验证了几何先验与学习特征的结合对立体视觉系统理解的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 现代立体视觉系统在深度重建中存在精度不足的问题，尤其是遮挡和深度不连续区域。本文旨在通过结合几何先验和学习特征，提升系统的3D重建能力，并探索人类感知机制对立体视觉的启发作用。

研究方法: 重新审视Cyclopean Eye模型，提出新的几何约束以处理遮挡和深度不连续问题；评估深度学习模型生成的立体特征匹配质量；研究注意力机制在恢复有意义3D表面中的作用；通过理论分析和真实数据集实验验证方法有效性。

研究结果: 实验表明，结合几何先验与学习特征能够显著提升深度重建的精度，尤其是在复杂场景中。注意力机制有助于恢复更准确的3D表面，验证了几何与学习结合的优越性。

研究结论: 几何先验与学习特征的结合为立体视觉系统提供了更强大的内部抽象能力，能够更好地处理遮挡和深度不连续问题，为未来研究提供了新方向。

中文摘要: 本研究探讨了现代立体视觉系统的几何基础，重点关注3D结构和人类感知如何促进精确的深度重建。我们重新审视了Cyclopean Eye模型，并提出了新的几何约束以处理遮挡和深度不连续问题。分析内容包括基于深度学习模型的立体特征匹配质量评估，以及注意力机制在恢复有意义3D表面中的作用。通过理论见解和真实数据集的实证研究，我们证明了几何先验与学习特征的结合为理解立体视觉系统提供了内部抽象能力。

</details>


### [52] [FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing](https://arxiv.org/abs/2506.20911)
**中文标题：FaSTA$^*$：基于子程序挖掘的快速-慢速工具路径代理用于高效多轮图像编辑**

*Advait Gupta,Rishie Raj,Dang Nguyen,Tianyi Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FaSTA$^*$的高效神经符号代理，用于解决多轮图像编辑任务。它结合了大型语言模型（LLM）的快速高级子任务规划和局部A$^*$搜索的精准工具使用，通过提取和复用子程序显著降低了计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 多轮图像编辑任务（如检测并重新着色物体、移除干扰物等）通常需要复杂的工具调用序列，现有方法计算成本高且效率低。本文旨在开发一种高效且成本低廉的解决方案。

研究方法: FaSTA$^*$采用快速-慢速规划策略：LLM负责快速高级子任务规划和子程序选择，而局部A$^*$搜索仅在子程序失败时激活。通过归纳推理提取常用子程序并复用，显著降低了探索成本。

研究结果: 实验表明，FaSTA$^*$在计算效率上显著优于现有方法，同时在成功率上与最先进的基线方法相当。

研究结论: FaSTA$^*$通过结合快速规划和精准工具使用，实现了高效且成本低廉的多轮图像编辑，为复杂任务提供了一种实用解决方案。

中文摘要: 我们开发了一种成本高效的神经符号代理FaSTA$^*$，用于解决复杂的多轮图像编辑任务，例如“检测图像中的长椅并将其重新着色为粉色，同时移除猫以获得更清晰的视野，并将墙壁重新着色为黄色”。该方法结合了大型语言模型（LLM）的快速高级子任务规划和局部A$^*$搜索的精准工具使用，以找到成本高效的工具路径（即AI工具调用序列）。为了降低A$^*$搜索在相似子任务上的成本，我们通过LLM对先前成功的工具路径进行归纳推理，持续提取和优化常用子程序，并将其作为新工具用于未来任务，实现自适应快速-慢速规划。其中，高级子程序优先探索，仅当其失败时才激活低级的A$^*$搜索。这些可复用的符号子程序显著降低了在相似图像上执行相同类型子任务的探索成本，从而形成了一种类似人类的快速-慢速工具路径代理“FaSTA$^*$”：LLM首先尝试快速子任务规划和基于规则的子程序选择（预计覆盖大多数任务），而慢速A$^*$搜索仅针对新颖和具有挑战性的子任务触发。通过与现有图像编辑方法的比较，我们证明FaSTA$^*$在计算效率上显著更高，同时在成功率上与最先进的基线方法相当。

</details>


### [53] [M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization](https://arxiv.org/abs/2506.20922)
**中文标题：M2SFormer：基于多频段多尺度注意力与边缘感知难度引导的图像伪造定位方法**

*Ju-Hyeon Nam,Dong-Hyun Moon,Sang-Chul Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer的框架M2SFormer，通过多频段和多尺度注意力机制以及边缘感知难度引导，显著提升了图像伪造定位的准确性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着图像编辑技术的快速发展，恶意图像篡改问题日益严重。现有的深度学习方法在像素级伪造定位中虽取得一定成果，但仍面临计算开销大和复杂篡改检测能力不足的挑战。

研究方法: M2SFormer采用Transformer编码器框架，统一了多频段和多尺度注意力机制，并通过全局先验图和难度引导注意力模块，有效保留了篡改细节。

研究结果: 在多个基准数据集上的实验表明，M2SFormer在伪造检测和定位任务中表现优于现有先进模型，尤其在跨领域泛化能力上表现突出。

研究结论: M2SFormer通过创新的注意力机制和难度引导策略，显著提升了图像伪造定位的性能，为未来研究提供了新方向。

中文摘要: 图像编辑技术的快速发展既推动了创新应用，也加剧了数字图像的恶意篡改问题。近年来，基于深度学习的方法在像素级伪造定位中取得了较高精度，但仍面临计算开销大和复杂篡改检测能力不足的挑战。本文提出了一种基于Transformer编码器的新型框架M2SFormer，旨在解决这些问题。与单独处理空间和频率线索的方法不同，M2SFormer在跳跃连接中统一了多频段和多尺度注意力机制，利用全局上下文更好地捕捉多样化的伪造痕迹。此外，该框架通过全局先验图（一种指示伪造定位难度的曲率度量）解决了上采样过程中细节丢失的问题，并通过难度引导注意力模块更有效地保留细微篡改。在多个基准数据集上的大量实验表明，M2SFormer优于现有先进模型，在跨领域伪造检测和定位任务中表现出卓越的泛化能力。

</details>


### [54] [PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling](https://arxiv.org/abs/2506.20936)
**中文标题：PhysRig：基于可微分物理的蒙皮和骨骼绑定框架，用于真实关节物体建模**

*Hao Zhang,Haolan Xu,Chun Feng,Varun Jampani,Narendra Ahuja*

主要分类: cs.CV

摘要简述: PhysRig是一种基于可微分物理的蒙皮和骨骼绑定框架，通过将刚性骨骼嵌入体积表示中，模拟为可变形软体结构，克服了传统线性混合蒙皮（LBS）的体积损失和变形不自然等问题，生成更真实的结果。


<details>
  <summary>详细信息</summary>
研究动机: 传统线性混合蒙皮（LBS）虽然简单且可微分，但存在体积损失、变形不自然等问题，且无法模拟弹性材料（如软组织、毛发等）。本文旨在提出一种更真实的蒙皮和骨骼绑定方法。

研究方法: PhysRig将刚性骨骼嵌入体积表示（如四面体网格），模拟为可变形软体结构，利用连续介质力学和粒子离散化确保对材料属性和骨骼运动的可微分性，并引入材料原型以减少学习空间。

研究结果: PhysRig在合成数据集上表现优于传统LBS方法，生成更真实且物理合理的结果，并在姿态迁移任务中展示了其多功能性。

研究结论: PhysRig通过结合物理模拟和可微分性，为关节物体建模提供了更真实和灵活的解决方案，优于传统方法。

中文摘要: 蒙皮和骨骼绑定是动画、关节物体重建、运动迁移和4D生成的基础组成部分。现有方法主要依赖线性混合蒙皮（LBS），因其简单性和可微分性。然而，LBS会引入体积损失和变形不自然等问题，且无法模拟弹性材料（如软组织、毛发和柔性附属物）。本文提出PhysRig：一种基于可微分物理的蒙皮和骨骼绑定框架，通过将刚性骨骼嵌入体积表示（如四面体网格）中，模拟为可变形软体结构，克服了这些限制。我们的方法利用连续介质力学，将物体离散化为嵌入欧拉背景网格的粒子，确保对材料属性和骨骼运动的可微分性。此外，我们引入材料原型，显著减少学习空间的同时保持高表现力。为评估框架，我们使用Objaverse、The Amazing Animals Zoo和MixaMo的网格构建了全面的合成数据集，涵盖多样化的物体类别和运动模式。我们的方法在生成更真实且物理合理的结果方面始终优于传统LBS方法。此外，我们展示了框架在姿态迁移任务中的适用性，突出了其在关节物体建模中的多功能性。

</details>


### [55] [AIR-VIEW: The Aviation Image Repository for Visibility Estimation of Weather, A Dataset and Benchmark](https://arxiv.org/abs/2506.20939)
**中文标题：AIR-VIEW：航空天气能见度估计图像库，数据集与基准**

*Chad Mourning,Zhewei Wang,Justin Murray*

主要分类: cs.CV

摘要简述: 本文介绍了一个名为AIR-VIEW的新数据集，用于航空天气能见度估计，填补了公开数据集的空白，并提供了基准测试结果。


<details>
  <summary>详细信息</summary>
研究动机: 航空天气能见度估计领域缺乏公开的大规模、多样化且标注清晰的数据集，阻碍了机器学习在该领域的应用。本文旨在填补这一空白。

研究方法: 通过为期一年的数据收集活动，从FAA天气摄像头网络中获取图像数据，构建AIR-VIEW数据集，并使用三种常用方法和通用基线在多个数据集上进行基准测试。

研究结果: AIR-VIEW数据集为航空能见度估计提供了高质量资源，基准测试表明其性能优于其他公开数据集，并与ASTM标准一致。

研究结论: AIR-VIEW数据集和基准测试为航空天气能见度估计研究提供了重要支持，推动了低成本替代方案的发展。

中文摘要: 航空天气的机器学习研究正在兴起，旨在为传统昂贵的天气传感器提供低成本替代方案；然而，在能见度估计领域，缺乏公开的大规模、多样化且标注清晰的航空相关数据集。本文介绍了一个新的数据集，该数据集是通过为期一年的FAA天气摄像头网络图像收集活动构建的，适用于这一目的。我们还提供了一个基准测试，应用了三种常用方法和通用基线，并在三个公开数据集及我们自己的数据集上进行了训练和测试，结果与最近批准的ASTM标准进行了对比。

</details>


### [56] [Hierarchical Sub-action Tree for Continuous Sign Language Recognition](https://arxiv.org/abs/2506.20947)
**中文标题：基于分层子动作树的连续手语识别**

*Dejie Yang,Zhu Xu,Xinjie Gao,Yang Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为HST-CSLR的分层子动作树方法，通过结合大语言模型的文本知识，优化连续手语识别中的视觉与文本模态对齐，并在四个数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前连续手语识别（CSLR）面临的主要问题是缺乏大规模数据集和精确标注，导致训练数据不足。现有方法未能充分利用文本模态的知识。本文旨在通过分层子动作树（HST）更高效地结合文本知识与视觉表示学习。

研究方法: 提出HST-CSLR方法，构建分层子动作树（HST）表示文本信息，逐步对齐视觉与文本模态，并利用树结构降低计算复杂度。同时引入对比对齐增强以缩小两种模态间的差距。

研究结果: 在PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture四个数据集上的实验表明，HST-CSLR方法显著提升了连续手语识别的性能。

研究结论: HST-CSLR通过分层子动作树和对比对齐增强，有效结合了文本知识与视觉表示学习，为连续手语识别提供了新的解决方案。

中文摘要: 连续手语识别（CSLR）的目标是将未修剪的视频转录为文本单词（即手语词）。近期研究表明，由于缺乏大规模数据集和精确标注，训练数据不足已成为CSLR的瓶颈。为解决这一问题，一些研究提出了跨模态解决方案以对齐视觉和文本模态。然而，这些方法通常仅从手语词中提取文本特征，未能充分利用其知识。本文提出了一种名为分层子动作树（HST）的方法（称为HST-CSLR），以高效结合手语词知识与视觉表示学习。通过从大语言模型中引入手语词特定知识，我们的方法更有效地利用了文本信息。具体而言，我们构建了HST用于文本信息表示，逐步对齐视觉与文本模态，并利用树结构降低计算复杂度。此外，我们还引入了对比对齐增强以缩小两种模态间的差距。在四个数据集（PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture）上的实验验证了HST-CSLR的有效性。

</details>


### [57] [OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs](https://arxiv.org/abs/2506.20960)
**中文标题：OmniEval：一个评估全模态模型的基准测试，涵盖视觉、听觉和文本输入**

*Yiman Zhang,Ziheng Luo,Qiangyu Yan,Wei He,Borui Jiang,Xinghao Chen,Kai Han*

主要分类: cs.CV

摘要简述: 本文介绍了OmniEval，一个用于评估全模态模型（如MiniCPM-O 2.6）的基准测试，涵盖视觉、听觉和文本输入。其特点包括全模态协作、多样化的视频和任务设计，并通过实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试未能全面评估全模态模型的协作能力，因此作者提出OmniEval，旨在为全模态模型的评估提供一个更全面、多样化的平台。

研究方法: OmniEval设计了强调音频与视频强耦合的任务，包含810个音视频同步视频（285个中文和525个英文）和2617个问答对（1412个开放式问题和1205个多选题），分为3大类任务和12个子任务。

研究结果: 实验表明，OmniEval能够有效评估全模态模型的协作能力，并引入更细粒度的视频定位任务Grounding。

研究结论: OmniEval为全模态模型的评估提供了一个全面的平台，有助于推动多模态协作研究的发展。

中文摘要: 本文介绍了OmniEval，一个用于评估全模态模型（如MiniCPM-O 2.6）的基准测试，涵盖视觉、听觉和文本输入。与现有基准相比，OmniEval具有以下特点：（i）全模态协作：设计任务以突出音频与视频的强耦合，要求模型有效利用所有模态的协作感知；（ii）视频多样性：包含810个音视频同步视频（285个中文和525个英文）；（iii）任务多样性与细粒度：包含2617个问答对（1412个开放式问题和1205个多选题），分为3大类任务和12个子任务。其中，引入了更细粒度的视频定位任务Grounding。实验验证了OmniEval的有效性，希望其为评估全模态上下文构建与理解能力提供平台。代码和数据可在https://omnieval.github.io/获取。

</details>


### [58] [Evidence-based diagnostic reasoning with multi-agent copilot for human pathology](https://arxiv.org/abs/2506.20964)
**中文标题：基于证据的多智能体协同诊断推理在人类病理学中的应用**

*Chengkuan Chen,Luca L. Weishaupt,Drew F. K. Williamson,Richard J. Chen,Tong Ding,Bowen Chen,Anurag Vaidya,Long Phi Le,Guillaume Jaume,Ming Y. Lu,Faisal Mahmood*

主要分类: cs.CV

摘要简述: 本文介绍了一种专为病理学设计的新型多模态大语言模型PathChat+，通过百万级病理学指令样本训练，显著提升诊断推理能力，并结合SlideSeek系统实现高精度全切片图像分析。


<details>
  <summary>详细信息</summary>
研究动机: 当前病理学领域的多模态大语言模型存在训练数据不足、多图像理解支持有限及缺乏自主诊断推理能力等问题，本文旨在解决这些局限性。

研究方法: 开发了PathChat+模型，基于超过100万病理学指令样本和550万问答对进行训练，并结合SlideSeek系统实现分层诊断推理。

研究结果: PathChat+在多项病理学基准测试中显著优于现有模型，SlideSeek系统在DDxBench上达到高精度诊断能力。

研究结论: PathChat+和SlideSeek系统为病理学提供了强大的诊断工具，支持自主推理和可视化报告生成。

中文摘要: 病理学正经历由全切片成像和人工智能（AI）驱动的快速数字化转型。尽管基于深度学习的计算病理学已取得显著成功，但传统模型主要关注图像分析，未整合自然语言指令或丰富的文本上下文。当前计算病理学中的多模态大语言模型（MLLMs）存在训练数据不足、多图像理解支持有限及缺乏自主诊断推理能力等局限性。为解决这些问题，我们推出了PathChat+，一种专为人类病理学设计的新型MLLM，基于超过100万多样化的病理学指令样本和近550万问答对进行训练。在多项病理学基准测试中的广泛评估表明，PathChat+显著优于先前的PathChat协导模型以及其他最先进的通用和病理学专用模型。此外，我们还推出了SlideSeek，一种支持推理的多智能体AI系统，利用PathChat+通过迭代、分层的诊断推理自主评估千兆像素全切片图像（WSIs），在具有挑战性的开放式鉴别诊断基准DDxBench上达到高精度，同时能够生成视觉基础、易于理解的人类总结报告。

</details>


### [59] [DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing](https://arxiv.org/abs/2506.20967)
**中文标题：DFVEdit：基于条件增量流向量的零样本视频编辑**

*Lingling Cai,Kang Zhao,Hangjie Yuan,Xiang Wang,Yingya Zhang,Kejie Huang*

主要分类: cs.CV

摘要简述: DFVEdit是一种高效的零样本视频编辑方法，专为视频扩散变换器（Video DiTs）设计，无需修改注意力机制或微调，通过流变换直接操作潜在空间，显著提升计算效率和编辑质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视频编辑方法应用于视频扩散变换器时，常因资源密集的注意力修改或微调导致计算开销巨大。DFVEdit旨在解决这一问题，提供一种高效且无需额外调整的编辑方案。

研究方法: DFVEdit基于连续流视角统一编辑与采样过程，提出条件增量流向量（CDFV）作为理论无偏估计，并结合隐式交叉注意力（ICA）指导和嵌入增强（ER）技术提升编辑质量。

研究结果: 实验表明，DFVEdit在视频扩散变换器（如CogVideoX和Wan2.1）上实现至少20倍推理加速和85%内存节省，并在结构保真度、时空一致性和编辑质量上达到最优性能。

研究结论: DFVEdit为视频扩散变换器提供了一种高效、高质量的零样本编辑方法，显著降低了计算成本，同时保持了编辑的精准性和一致性。

中文摘要: 视频扩散变换器（Video DiTs）的出现标志着视频生成领域的重要里程碑。然而，直接将现有视频编辑方法应用于Video DiTs通常会导致巨大的计算开销，原因是资源密集的注意力修改或微调。为解决这一问题，我们提出了DFVEdit，一种专为Video DiTs设计的高效零样本视频编辑方法。DFVEdit通过流变换直接操作干净潜在空间，无需修改注意力机制或微调。具体而言，我们观察到编辑与采样可以在连续流视角下统一。基于此，我们提出了条件增量流向量（CDFV）——DFV的理论无偏估计，并结合隐式交叉注意力（ICA）指导和嵌入增强（ER）技术进一步提升编辑质量。DFVEdit在实际效率上表现卓越，与基于注意力工程的编辑方法相比，在Video DiTs上实现了至少20倍的推理加速和85%的内存节省。大量定量和定性实验表明，DFVEdit可无缝应用于主流Video DiTs（如CogVideoX和Wan2.1），在结构保真度、时空一致性和编辑质量上达到最优性能。

</details>


### [60] [From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan Face Aging](https://arxiv.org/abs/2506.20977)
**中文标题：从摇篮到拐杖：一种高保真生命周期人脸老化的两阶段框架**

*Tao Liu,Dafeng Zhang,Gengchen Li,Shizhuo Liu,Yongqi Song,Senmao Li,Shiqi Yang,Boqian Li,Kai Wang,Yaxing Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Cradle2Cane的两阶段人脸老化框架，通过自适应噪声注入和身份感知嵌入技术，解决了年龄准确性与身份一致性之间的权衡问题，显著提升了老化效果的真实性和身份保留。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸老化方法难以在整个生命周期内实现真实且无缝的年龄转换，尤其是在处理大年龄跨度或极端头部姿态时，年龄准确性与身份一致性之间的权衡成为核心挑战。本文旨在解决这一问题。

研究方法: 提出两阶段框架：第一阶段通过自适应噪声注入（AdaNI）机制实现年龄准确性，第二阶段利用身份感知嵌入（IDEmb）增强身份一致性。两阶段联合训练，实现端到端优化。

研究结果: 在CelebA-HQ测试数据集上的实验表明，Cradle2Cane在年龄准确性和身份一致性方面优于现有方法，Face++和Qwen-VL协议验证了其优越性。

研究结论: Cradle2Cane通过两阶段设计有效平衡了年龄准确性与身份一致性，为人脸老化任务提供了高效且真实的解决方案。

中文摘要: 人脸老化已成为计算机视觉领域的重要任务，其应用范围涵盖娱乐到医疗保健。然而，现有方法难以在整个生命周期内实现真实且无缝的年龄转换，尤其是在处理大年龄跨度或极端头部姿态时。核心挑战在于平衡年龄准确性与身份一致性，即所谓的Age-ID权衡。大多数现有方法要么以牺牲身份一致性为代价优先年龄转换，要么反之。本文通过提出一种基于少步文本到图像（T2I）扩散模型的两阶段人脸老化框架Cradle2Cane来解决这一问题。第一阶段通过引入自适应噪声注入（AdaNI）机制解决年龄准确性，该机制通过包含年龄和性别的文本描述作为条件。此外，通过调整噪声水平，可以控制老化强度，同时为面部转换提供更多灵活性。然而，此阶段对身份一致性的保障较弱，以支持更强的年龄转换。第二阶段通过两种身份感知嵌入（IDEmb）：SVR-ArcFace和Rotate-CLIP，增强身份一致性同时保留年龄特征。此阶段对第一阶段转换后的图像进行去噪，确保更强的身份一致性而不影响老化准确性。两阶段联合训练，实现端到端优化。在CelebA-HQ测试数据集上的大量实验表明，Cradle2Cane在Face++和Qwen-VL协议评估下，在年龄准确性和身份一致性方面优于现有的人脸老化方法。

</details>


### [61] [3D Scene-Camera Representation with Joint Camera Photometric Optimization](https://arxiv.org/abs/2506.20979)
**中文标题：基于联合相机光度优化的3D场景-相机表示**

*Weichen Dai,Kangcheng Ma,Jiaxin Wang,Kecen Pan,Yuhang Ming,Hua Zhang,Wanzeng Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种结合相机光度优化的3D场景-相机表示方法，通过联合优化相机光度模型和场景表示，有效分离与场景无关的信息，提升3D场景表示质量。


<details>
  <summary>详细信息</summary>
研究动机: 多视角图像中的场景表示是计算机视觉中的重要任务，但相机成像中的光度失真会显著降低图像质量，进而影响3D场景表示的准确性。若不考虑这些失真，3D场景表示可能包含与场景无关的错误信息。本文旨在通过联合优化相机光度模型和场景表示，解决这一问题。

研究方法: 本文提出了一种完整的3D场景-相机表示方法，包括内部和外部光度模型。通过同时优化相机表示参数，分离与场景无关的信息。在光度参数优化过程中，引入深度正则化以防止3D场景表示拟合无关信息。相机模型被整合到映射过程中，构建包含场景辐射场和相机光度模型的完整映射。

研究结果: 实验结果表明，即使在成像退化（如渐晕和污垢）条件下，所提方法仍能生成高质量的3D场景表示。

研究结论: 本文提出的联合相机光度优化的3D场景表示方法，能够有效分离与场景无关的信息，显著提升场景表示质量，适用于存在成像失真的场景。

中文摘要: 从多视角图像中表示场景是计算机视觉中一项关键任务，具有广泛应用。然而，相机成像中的固有光度失真会显著降低图像质量。若不考虑这些失真，3D场景表示可能无意中引入与场景无关的错误信息，降低表示质量。本文提出了一种新颖的基于联合相机光度优化的3D场景-相机表示方法。通过引入内部和外部光度模型，提出完整的光度模型及相应的相机表示。基于同时优化相机表示参数，所提方法有效分离了3D场景表示中与场景无关的信息。此外，在光度参数优化过程中，引入深度正则化以防止3D场景表示拟合与场景无关的信息。通过将相机模型整合到映射过程中，所提方法构建了包含场景辐射场和相机光度模型的完整映射。实验结果表明，即使在渐晕和污垢等成像退化条件下，所提方法仍能实现高质量的3D场景表示。

</details>


### [62] [Rethink Sparse Signals for Pose-guided Text-to-image Generation](https://arxiv.org/abs/2506.20983)
**中文标题：重新思考稀疏信号在姿态引导文本到图像生成中的应用**

*Wenjie Xuan,Jing Zhang,Juhua Liu,Bo Du,Dacheng Tao*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的Spatial-Pose ControlNet（SP-Ctrl），通过改进稀疏信号（如OpenPose）的可控性，用于姿态引导的文本到图像生成。实验表明，该方法在稀疏姿态引导下优于现有方法，并接近基于密集信号的方法性能。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，密集信号（如深度图、DensePose）被广泛用于姿态引导的文本到图像生成，但其存在编辑困难和与文本提示不一致的问题。稀疏信号（如OpenPose）因其简单性和形状无关性被重新审视，但其潜力尚未充分挖掘。

研究方法: 论文提出SP-Ctrl，将OpenPose扩展为可学习的空间表示，使关键点嵌入更具区分性和表达能力。此外，引入关键点概念学习，使关键点标记能够关注每个关键点的空间位置，从而提升姿态对齐。

研究结果: 在动物和人类图像生成任务中，SP-Ctrl在稀疏姿态引导下优于现有方法，甚至接近基于密集信号的方法性能。此外，SP-Ctrl在多样化和跨物种生成中表现出潜力。

研究结论: SP-Ctrl通过改进稀疏信号的可控性，为姿态引导的文本到图像生成提供了高效解决方案，展示了稀疏信号在生成任务中的潜力。

中文摘要: 近期研究倾向于使用密集信号（如深度图、DensePose）作为姿态引导文本到图像生成的详细空间指导，替代稀疏信号（如OpenPose）。然而，密集表示带来了新的挑战，包括编辑困难和与文本提示的潜在不一致。这一事实促使我们重新审视稀疏信号在姿态引导中的应用，因其简单性和形状无关性，但其潜力尚未充分挖掘。本文提出了一种新型的Spatial-Pose ControlNet（SP-Ctrl），为稀疏信号赋予强大的可控性，用于姿态引导的图像生成。具体而言，我们将OpenPose扩展为可学习的空间表示，使关键点嵌入更具区分性和表达能力。此外，我们引入了关键点概念学习，鼓励关键点标记关注每个关键点的空间位置，从而提升姿态对齐。在动物和人类图像生成任务上的实验表明，我们的方法在稀疏姿态引导下优于现有方法，甚至接近基于密集信号的方法性能。此外，SP-Ctrl在多样化和跨物种生成中表现出潜力。代码将在https://github.com/DREAMXFAR/SP-Ctrl发布。

</details>


### [63] [EVA: Mixture-of-Experts Semantic Variant Alignment for Compositional Zero-Shot Learning](https://arxiv.org/abs/2506.20986)
**中文标题：EVA：基于专家混合语义变体对齐的组合零样本学习**

*Xiao Zhang,Yongqiang Ma,Haodong Jing,Nanning Zheng*

主要分类: cs.CV

摘要简述: 本文提出EVA框架，通过专家混合和语义变体对齐提升组合零样本学习性能，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有组合零样本学习方法通过简单的组合-原型映射获取原始特征，忽略了语义子集的多样性，且跨模态匹配未考虑相同状态或对象内的组合差异，导致图像-组合对齐不够精细。

研究方法: 提出EVA框架，包括域专家适配和多专家协同的令牌感知学习，以及语义变体对齐技术，以选择语义相关的表示进行图像-原始匹配。

研究结果: 在三个流行基准测试中，EVA在封闭和开放世界设置下均显著优于其他最先进的组合零样本学习方法。

研究结论: EVA通过专家混合和语义变体对齐有效提升了组合零样本学习的性能，验证了其创新性。

中文摘要: 组合零样本学习（CZSL）研究基于学习到的原始概念识别未知状态-对象对的组合泛化能力。现有CZSL方法通常通过简单的组合-原型映射获取原始特征，这对于可划分为不同语义子集的个体集并不理想。此外，全对一的跨模态原始匹配忽略了相同状态或对象内的组合差异，限制了图像-组合的细粒度对齐。本研究提出EVA，一种基于专家混合语义变体对齐的CZSL框架。具体而言，我们引入域专家适配，利用多个专家实现令牌感知学习并建模高质量的原始表示。为实现准确的组合泛化，我们进一步提出语义变体对齐，选择语义相关的表示进行图像-原始匹配。我们的方法在三个流行基准测试中，无论是封闭还是开放世界设置下，均显著优于其他最先进的CZSL方法，验证了所提见解的有效性。

</details>


### [64] [Segment Anything in Pathology Images with Natural Language](https://arxiv.org/abs/2506.20988)
**中文标题：基于自然语言的病理图像通用分割**

*Zhixuan Chen,Junlin Hou,Liqi Lin,Yihui Wang,Yequan Bie,Xi Wang,Yanning Zhou,Ronald Cheong Kin Chan,Hao Chen*

主要分类: cs.CV

摘要简述: 本文提出PathSegmentor，首个基于自然语言提示的病理图像分割基础模型，并发布最大病理分割数据集PathSeg。PathSegmentor通过文本提示实现高精度分割，超越现有方法，提升临床决策支持。


<details>
  <summary>详细信息</summary>
研究动机: 当前病理图像分割方法因标注数据有限和类别定义狭窄，难以满足临床需求。本文旨在开发一种无需繁琐空间输入（如点或框）的通用分割模型，提升病理分析的准确性和适用性。

研究方法: 提出PathSegmentor模型，利用自然语言提示进行语义分割；构建PathSeg数据集，包含17个公开来源的275k图像-掩码-标签三元组，覆盖160个类别。

研究结果: PathSegmentor在整体Dice分数上分别超过空间提示和文本提示模型0.145和0.429，表现出更高的准确性和泛化能力，同时支持诊断模型的可解释性分析。

研究结论: PathSegmentor为精准肿瘤学中的可解释AI提供了新工具，通过自然语言提示简化分割流程，增强临床决策支持。

中文摘要: 病理图像分割在计算病理学中对癌症诊断和预后的组织学特征分析至关重要。然而，现有方法因标注数据有限和类别定义狭窄，在临床应用中面临重大挑战。为解决这些问题，我们提出PathSegmentor，首个专为病理图像设计的基于文本提示的分割基础模型，并发布PathSeg数据集——最大且最全面的病理分割数据集，包含来自17个公开来源的275k图像-掩码-标签三元组，覆盖160个类别。PathSegmentor允许用户通过自然语言提示完成语义分割，无需繁琐的空间输入（如点或框）。大量实验表明，PathSegmentor在保持紧凑架构的同时，以更高准确性和更广适用性超越专用模型，整体Dice分数分别超过现有空间提示和文本提示模型0.145和0.429，且在复杂结构分割和外部数据集泛化中表现出强鲁棒性。此外，PathSegmentor的输出通过特征重要性估计和影像生物标志物发现，提升了诊断模型的可解释性，为病理学家提供循证支持的临床决策。这项工作推动了精准肿瘤学中可解释AI的发展。

</details>


### [65] [TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation](https://arxiv.org/abs/2506.20991)
**中文标题：TSDASeg：一种基于直接对齐的两阶段交互式点云分割模型**

*Chade Li,Pengju Zhang,Yihong Wu*

主要分类: cs.CV

摘要简述: TSDASeg是一种两阶段模型，通过直接跨模态对齐模块和记忆模块提升点云分割性能，解决了现有方法在点级任务中因缺乏直接3D-文本对齐而表现不佳的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D视觉语言模型在点级任务（如分割）中表现不佳，主要原因是缺乏直接的3D-文本对齐，无法将局部3D特征与文本上下文有效关联。

研究方法: TSDASeg采用两阶段模型，结合直接跨模态对齐模块和记忆模块。对齐模块显式建立3D点云与文本/2D图像数据的联系，记忆模块通过多个专用记忆库存储文本特征、视觉特征及其跨模态映射，并利用自注意力和交叉注意力机制动态更新场景特征。

研究结果: 在多个3D指令、参考和语义分割数据集上的实验表明，TSDASeg实现了最先进的性能。

研究结论: TSDASeg通过直接跨模态对齐和动态记忆模块，显著提升了交互式点云分割的准确性和一致性。

中文摘要: 3D视觉语言模型（VLMs）的快速发展激发了人们对交互式点云处理任务的浓厚兴趣，尤其是在实际应用中。然而，现有方法在点级任务（如分割）中表现不佳，主要原因是缺乏直接的3D-文本对齐，限制了局部3D特征与文本上下文的关联能力。为解决这一问题，我们提出了TSDASeg，这是一种结合直接跨模态对齐模块和记忆模块的两阶段交互式点云分割模型。我们引入直接跨模态对齐模块，显式建立3D点云与文本/2D图像数据的对齐关系。在记忆模块中，我们采用多个专用记忆库分别存储文本特征、视觉特征及其跨模态对应映射。这些记忆库通过自注意力和交叉注意力机制动态利用，基于先验存储数据更新场景特定特征，有效解决了不同场景下交互式分割结果的不一致性问题。在多个3D指令、参考和语义分割数据集上的实验表明，所提方法实现了最先进的性能。

</details>


### [66] [Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance](https://arxiv.org/abs/2506.20995)
**中文标题：基于负音频引导的逐步视频到音频合成方法**

*Akio Hayakawa,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji*

主要分类: cs.CV

摘要简述: 本文提出了一种逐步视频到音频合成方法，通过负音频引导生成多个独立音轨，模拟传统Foley工作流程，提升合成音频质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统视频到音频合成方法难以全面捕捉视频中的多个声音事件，且缺乏对多音轨合成的支持。本文旨在通过逐步生成和负音频引导，实现更高质量的多音轨合成。

研究方法: 方法采用逐步生成策略，每一步生成一个特定声音事件的音轨，并利用负音频引导和预训练模型，避免对专用配对数据集的依赖。

研究结果: 实验表明，该方法能为单一视频生成多个语义不同的音轨，合成音频质量优于现有基线方法。

研究结论: 本文提出的逐步生成方法结合负音频引导，显著提升了视频到音频合成的质量和多样性。

中文摘要: 我们提出了一种新颖的逐步视频到音频生成方法，依次生成与视频中特定声音事件对应的独立音轨。该方法模拟传统Foley工作流程，旨在全面捕捉视频中的所有声音事件。每一步生成任务被设计为基于目标文本提示和已生成音轨的引导视频到音频合成任务，灵感来源于先前组合生成框架中的概念否定思想。为实现这种引导生成，我们引入了一种训练框架，利用预训练的视频到音频模型，无需专用配对数据集，可在更易获取的数据上进行训练。实验结果表明，我们的方法能为单一输入视频生成多个语义不同的音轨，合成的复合音频质量优于现有基线。

</details>


### [67] [DBMovi-GS: Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting](https://arxiv.org/abs/2506.20998)
**中文标题：DBMovi-GS：基于稀疏控制高斯分布的模糊单目视频动态视角合成**

*Yeon-Ji Song,Jaein Kim,Byung-Ju Kim,Byoung-Tak Zhang*

主要分类: cs.CV

摘要简述: 本文提出DBMovi-GS方法，通过稀疏控制的高斯分布技术，从模糊单目视频中合成动态场景的新视角，解决了动态模糊场景下视角合成的难题。


<details>
  <summary>详细信息</summary>
研究动机: 现有新视角合成方法依赖高分辨率图像或静态几何假设，难以处理动态模糊场景。本文旨在解决这一挑战，提升动态模糊视频的视角合成质量。

研究方法: DBMovi-GS利用稀疏控制的高斯分布技术，从模糊视频中生成密集3D高斯分布，恢复清晰度并重建动态运动下的3D几何细节。

研究结果: 该方法在动态模糊场景的新视角合成中表现稳健，为模糊单目视频输入设定了新的合成基准。

研究结论: DBMovi-GS成功解决了动态模糊视频的视角合成问题，为实际应用提供了高质量的合成结果。

中文摘要: 新视角合成任务旨在从未见过的视角生成场景；然而，从模糊单目视频中合成动态场景仍是一个未解决的挑战。现有的新视角合成方法通常依赖于高分辨率图像或对静态几何和刚性场景先验的强假设，因此在动态物体和相机运动的真实环境中缺乏鲁棒性，导致不稳定和视觉保真度下降。为解决这一问题，我们提出了一种基于稀疏控制高斯分布的运动感知动态视角合成方法（DBMovi-GS），用于从模糊单目视频中合成动态视角。我们的模型生成密集的3D高斯分布，从模糊视频中恢复清晰度，并重建受动态运动变化影响的场景的详细3D几何结构。我们的模型在动态模糊场景下的新视角合成中表现出鲁棒性能，并为模糊单目视频输入设定了现实新视角合成的新基准。

</details>


### [68] [Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology](https://arxiv.org/abs/2506.21001)
**中文标题：风格对齐的图像合成用于细胞病理学中异常细胞的鲁棒检测**

*Qiuyi Qi,Xin Li,Ming Kong,Zikang Xu,Bingdi Chen,Qiang Zhu,S Kevin Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种风格对齐的图像合成方法（SAIC），用于增强细胞病理学中异常细胞检测的鲁棒性，通过合成高质量且风格一致的病理图像，显著提升了检测模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 细胞病理学中异常细胞检测面临高质量标注数据稀缺、数据分布长尾以及染色风格不一致等挑战，限制了检测模型的鲁棒性和有效性。

研究方法: SAIC方法通过属性指导从异常细胞库中选择候选细胞，利用高频特征重建实现异常细胞与病理背景的风格对齐和高保真合成，并引入大型视觉语言模型筛选高质量合成图像。

研究结果: 实验表明，SAIC合成的图像显著提升了尾部类别和风格的异常细胞检测性能，增强了模型的鲁棒性，综合质量评估验证了其在临床应用中的泛化性和实用性。

研究结论: SAIC方法通过风格对齐的图像合成有效解决了细胞病理学检测中的关键挑战，为临床提供了实用的解决方案。

中文摘要: 高质量标注数据的缺乏、长尾数据分布以及染色风格不一致等问题，对细胞病理学中异常细胞的鲁棒检测提出了重大挑战。本文提出了一种风格对齐的图像合成（SAIC）方法，通过合成高保真且风格一致的病理图像，提升检测模型的有效性和鲁棒性。SAIC无需额外训练，首先基于属性指导从异常细胞库中选择合适的候选细胞，然后利用高频特征重建实现异常细胞与病理背景的风格对齐和高保真合成，最后引入大型视觉语言模型筛选高质量合成图像。实验结果表明，SAIC合成的图像显著提升了尾部类别和风格的异常细胞检测性能，从而改善了整体检测效果。综合质量评估进一步证实了SAIC在临床应用中的泛化性和实用性。代码将在https://github.com/Joey-Qi/SAIC发布。

</details>


### [69] [Inverse Scene Text Removal](https://arxiv.org/abs/2506.21002)
**中文标题：逆向场景文本去除**

*Takumi Yoshimatsu,Shumpei Takezaki,Seiichi Uchida*

主要分类: cs.CV

摘要简述: 本文提出逆向场景文本去除（ISTR），旨在检测图像是否经过文本去除处理，并定位被去除的文本区域，实验表明任务可行且准确率高，有助于防止滥用并改进文本去除技术。


<details>
  <summary>详细信息</summary>
研究动机: 场景文本去除（STR）技术虽能有效去除图像中的文本，但存在滥用风险。本文研究逆向STR（ISTR），通过检测图像是否经过STR处理及定位被去除文本区域，以防范滥用并优化STR技术。

研究方法: ISTR通过分析STR处理后的图像，完成两项任务：1）二分类检测图像是否经过STR处理；2）定位被去除的文本区域。此外，尝试训练文本识别器恢复被去除的文本内容。

研究结果: 实验表明，ISTR在检测图像是否经过STR处理及定位被去除文本区域的任务中均取得高准确率，验证了其可行性。文本恢复任务则揭示了其难度。

研究结论: ISTR能够有效检测STR处理痕迹并定位被去除文本区域，为防范STR滥用提供了新思路，同时有助于改进STR技术。文本恢复任务仍需进一步研究。

中文摘要: 场景文本去除（STR）旨在从图像中擦除文本元素，最初用于去除隐私或不需要的文本，现也应用于印刷图像。STR通常检测文本区域并进行修复。尽管STR通过神经网络和合成数据取得进展，但滥用风险增加。本文研究逆向STR（ISTR），分析STR处理后的图像，专注于二分类（检测图像是否经过STR处理）和定位被去除文本区域。实验表明，这些任务可实现高准确率，有助于检测潜在滥用并改进STR。我们还尝试通过训练文本识别器恢复被去除的文本内容，以了解其难度。

</details>


### [70] [VisionGuard: Synergistic Framework for Helmet Violation Detection](https://arxiv.org/abs/2506.21005)
**中文标题：VisionGuard：协同框架用于头盔违规检测**

*Lam-Huy Nguyen,Thinh-Phuc Nguyen,Thanh-Hai Nguyen,Gia-Huy Dinh,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: VisionGuard是一个多阶段协同框架，用于检测摩托车头盔违规行为，通过自适应标记和上下文扩展模块提升分类一致性和召回率，实验显示其mAP提升3.1%。


<details>
  <summary>详细信息</summary>
研究动机: 摩托车头盔法规的执行对提升道路安全和交通管理效率至关重要，但环境多变、摄像头角度和数据不一致等问题阻碍了自动检测的可靠性。

研究方法: VisionGuard结合自适应标记模块（基于跟踪的标签优化）和上下文扩展模块（生成虚拟边界框以解决数据不平衡），克服帧级检测器的局限性。

研究结果: 实验结果表明，VisionGuard相比基线检测器整体mAP提升3.1%，验证了其在交通监控系统中的有效性。

研究结论: VisionGuard通过协同多阶段设计有效提升头盔违规检测性能，具备实际部署潜力，有助于提升安全性和法规遵从性。

中文摘要: 执行摩托车头盔法规对提升道路安全和交通管理系统的有效性至关重要。然而，由于环境多变、摄像头角度和数据不一致，头盔违规的自动检测面临重大挑战。这些因素阻碍了对摩托车和骑手的可靠检测，并破坏了对象分类的一致性。为解决这些问题，我们提出了VisionGuard，一个协同多阶段框架，旨在克服帧级检测器的局限性，尤其是在类别不平衡和标注不一致的场景中。VisionGuard整合了两个关键组件：自适应标记模块和上下文扩展模块。自适应标记模块是一种基于跟踪的优化技术，通过利用跟踪算法为帧间分配持久标签并纠正错误分类，从而提升分类一致性。上下文扩展模块通过生成带有适当置信度得分的虚拟边界框，改善对少数类别的召回率，有效应对数据不平衡的影响。实验结果显示，VisionGuard相比基线检测器整体mAP提升3.1%，证明了其在交通监控系统中的有效性和实际部署潜力，最终促进安全和法规遵从。

</details>


### [71] [Detection of Breast Cancer Lumpectomy Margin with SAM-incorporated Forward-Forward Contrastive Learning](https://arxiv.org/abs/2506.21006)
**中文标题：基于SAM结合前向-前向对比学习的乳腺癌肿块切除术边缘检测**

*Tyler Ward,Xiaoqin Wang,Braxton McFarland,Md Atik Ahamed,Sahar Nozad,Talal Arshad,Hafsa Nebbache,Jin Chen,Abdullah Imran*

主要分类: cs.CV

摘要简述: 本文提出了一种结合Segment Anything Model (SAM)和Forward-Forward Contrastive Learning (FFCL)的新型深度学习框架，用于提高乳腺癌肿块切除术中标本边缘的检测准确性。该方法在边缘分类和肿瘤分割方面显著优于基线模型，并大幅缩短了推理时间。


<details>
  <summary>详细信息</summary>
研究动机: 目前用于评估术中标本边缘状态的2D标本放射成像（SR）准确性有限，导致近四分之一的患者需要额外手术。为提高边缘检测的准确性和效率，减少再切除率，本文提出了这一新方法。

研究方法: 首先对SR图像进行标注，包括已知恶性、非恶性组织和病理确认的边缘区域。随后使用FFCL预训练ResNet-18主干网络进行边缘状态分类，并通过重建粗二值掩码引导SAM进行精细的肿瘤边缘分割。

研究结果: 该方法在边缘分类中取得了0.8455的AUC值，肿瘤边缘分割的Dice相似度比基线模型提高了27.4%，同时将每张图像的推理时间缩短至47毫秒。

研究结论: FFCL-SAM框架显著提高了术中边缘评估的速度和准确性，有望降低再切除率并改善乳腺癌治疗的手术效果。

中文摘要: 在乳腺癌肿块切除术中，完全切除肿瘤并确保标本边缘阴性对降低复发率至关重要。然而，目前用于评估术中标本边缘状态的2D标本放射成像（SR）准确性有限，导致近四分之一的患者需要额外手术。为解决这一问题，我们提出了一种新型深度学习框架，将Segment Anything Model (SAM)与前向-前向对比学习（FFCL）相结合。FFCL是一种预训练策略，利用局部和全局对比学习对SR图像进行块级分类。在对SR图像标注已知恶性、非恶性组织和病理确认的边缘区域后，我们使用FFCL预训练ResNet-18主干网络进行边缘状态分类，并通过重建粗二值掩码引导SAM进行精细的肿瘤边缘分割。我们的方法在边缘分类中取得了0.8455的AUC值，肿瘤边缘分割的Dice相似度比基线模型提高了27.4%，同时将每张图像的推理时间缩短至47毫秒。这些结果表明，FFCL-SAM显著提高了术中边缘评估的速度和准确性，有望降低再切除率并改善乳腺癌治疗的手术效果。代码已开源：https://github.com/tbwa233/FFCL-SAM/。

</details>


### [72] [The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion](https://arxiv.org/abs/2506.21008)
**中文标题：衰老多元宇宙：通过无训练扩散生成条件感知的面部衰老树**

*Bang Gong,Luchao Qi,Jiaye Wu,Zhicheng Fu,Chunbo Song,David W. Jacobs,John Nicholson,Roni Sengupta*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“衰老多元宇宙”的框架，通过无训练扩散方法生成基于外部条件（如环境、健康、生活方式）的多种面部衰老轨迹，形成衰老树，展示多样化的未来。该方法在身份保留、年龄准确性和条件控制方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常将面部衰老建模为单一确定性路径，忽略了外部条件对衰老的多样性影响。本文旨在通过生成多样化的衰老轨迹，更好地反映现实世界中衰老的多维性和可控性。

研究方法: 提出了一种无训练的扩散方法，结合注意力混合技术调节编辑强度，并采用模拟衰老正则化策略稳定编辑效果。该方法在身份保留、年龄准确性和条件控制之间实现了平衡。

研究结果: 实验和用户研究表明，该方法在身份保留、衰老真实性和条件对齐方面表现优于现有编辑和衰老进展模型，展示了卓越的性能。

研究结论: 通过将衰老转化为多维、可控且可解释的过程，该方法为数字叙事、健康教育和个性化可视化开辟了新的应用途径。

中文摘要: 我们提出了“衰老多元宇宙”框架，用于从单张图像生成多种基于外部条件（如环境、健康和生活方式）的合理面部衰老轨迹。与以往将衰老建模为单一确定性路径的方法不同，我们的方法生成了一棵衰老树，可视化多样化的未来。为实现这一点，我们提出了一种无训练的扩散方法，平衡了身份保留、年龄准确性和条件控制。我们的关键贡献包括通过注意力混合调节编辑强度，以及采用模拟衰老正则化策略稳定编辑效果。广泛的实验和用户研究表明，该方法在身份保留、衰老真实性和条件对齐方面达到了最先进的性能，优于现有的编辑和衰老进展模型，这些模型往往无法满足一个或多个编辑标准。通过将衰老转化为多维、可控且可解释的过程，我们的方法为数字叙事、健康教育和个性化可视化开辟了新的创意和实用途径。

</details>


### [73] [User-in-the-Loop View Sampling with Error Peaking Visualization](https://arxiv.org/abs/2506.21009)
**中文标题：基于错误峰值可视化的用户循环视图采样**

*Ayaka Yasunaga,Hideo Saito,Shohei Mori*

主要分类: cs.CV

摘要简述: 本文提出了一种基于错误峰值可视化的用户循环视图采样方法，用于增强现实（AR）中的新视图合成，减少用户负担并扩展场景探索范围。


<details>
  <summary>详细信息</summary>
研究动机: 现有AR方法依赖3D标注引导用户采集新视图，任务繁重且场景探索受限。本文旨在通过可视化待消除错误，解放用户并提升采样效率。

研究方法: 利用局部重建的光场和错误峰值可视化技术，引导用户插入新视图以优化合成效果，避免依赖3D标注。

研究结果: 实验表明，该方法侵入性低，减少用户失望，且能以更少视图样本满足需求，同时支持大场景辐射场重建。

研究结论: 错误峰值可视化是一种高效的用户引导方法，适用于移动视图合成系统和大场景重建。

中文摘要: 增强现实（AR）为缺失视图样本的新视图合成提供了可视化方法。现有方法通过3D标注引导用户对齐AR显示采集图像，任务繁重且局限于预定义小区域。为解放用户并扩展场景探索，我们提出利用局部重建光场和可视化待消除错误的技术。结果显示，错误峰值可视化侵入性更低，减少用户对最终结果的失望，且在移动视图合成系统中能以更少样本满足需求。该方法还可支持大场景的辐射场重建，如3D高斯泼溅。

</details>


### [74] [Bridging Video Quality Scoring and Justification via Large Multimodal Models](https://arxiv.org/abs/2506.21011)
**中文标题：通过大型多模态模型桥接视频质量评分与解释**

*Qizhi Xie,Kun Yuan,Yunpeng Qu,Jiachao Gong,Mingda Wu,Ming Sun,Chao Zhou,Jihong Zhu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于评分指令生成（SIG）的自动化流程，通过大模态模型（LMMs）提升视频质量评分与解释能力，并构建了包含32万指令对的Score2Instruct数据集。实验表明，该方法显著提升了视频LMMs的质量评分与解释能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统视频质量评估（VQA）方法仅生成数值评分，无法全面描述视频的复杂质量维度。通过利用大模态模型（LMMs）的语言输出能力，结合指令调优，有望解决这一问题。但现有研究主要依赖人工标注和专有系统，限制了数据的可扩展性和有效性。

研究方法: 提出Score-based Instruction Generation（SIG）流程，自动为未标注视频评分并将分数映射为文本定义的质量等级。采用分层Chain-of-Thought（CoT）建模具体维度与整体质量的关系，模拟人类视觉推理过程。构建了包含32万指令对的Score2Instruct（S2I）数据集，并设计了渐进式调优策略以提升视频LMMs的能力。

研究结果: 实验结果表明，基于SIG的方法在S2I-Bench和现有基准测试中，显著提升了视频LMMs的质量评分与解释能力。

研究结论: SIG流程通过自动化生成指令数据，解决了传统方法依赖人工标注的问题，同时提升了视频LMMs的质量评分与解释能力，为视频质量评估提供了新思路。

中文摘要: 传统视频质量评估（VQA）方法通过数值评分判断视频的感知视觉保真度和清晰度，但评分无法描述视频的复杂质量维度，限制了其适用性。受益于语言输出能力，通过指令调优将视频大型多模态模型（LMMs）应用于VQA，有望解决这一问题。该方法的核心在于以视频质量为中心的指令数据。先前研究主要集中在图像领域，其数据生成过程严重依赖人工质量标注和专有系统，限制了数据的可扩展性和有效性。为解决这些问题，我们提出了基于评分的指令生成（SIG）流程。具体而言，SIG首先对未标注视频的多个质量维度进行评分，并将分数映射为文本定义的质量等级。随后，通过分层Chain-of-Thought（CoT）明确建模具体维度与整体质量的关系，模拟人类视觉系统的推理过程。这一自动化流程消除了对专家撰写质量描述和专有系统的依赖，确保了数据的可扩展性和生成效率。最终，生成的Score2Instruct（S2I）数据集包含超过32万条多样化的指令-响应对，为指令调优奠定了基础。此外，为同时提升视频LMMs的质量评分与解释能力，我们设计了一种渐进式调优策略，以充分发挥S2I的潜力。基于SIG，我们进一步构建了一个名为S2I-Bench的基准测试，包含400个开放式问题，以更好地评估视频LMMs的质量解释能力。在S2I-Bench和现有基准测试上的实验结果表明，我们的方法显著提升了多种视频LMMs的质量评分与解释能力。

</details>


### [75] [FedSC: Federated Learning with Semantic-Aware Collaboration](https://arxiv.org/abs/2506.21012)
**中文标题：FedSC：基于语义感知协作的联邦学习**

*Huan Wang,Haoran Li,Huaming Chen,Jun Yan,Jiahua Shi,Jun Shen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FedSC的联邦学习方法，通过语义感知协作解决数据异构性问题，利用关系原型和一致性原型捕获客户端特定和类别相关知识，提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习面临数据异构性挑战，现有方法常忽略客户端内部的语义信息。本文旨在利用客户端内的语义知识，解决数据异构性问题。

研究方法: FedSC通过构建关系原型和一致性原型，结合对比学习和差异聚合策略，优化本地模型，同时提供理论收敛保证。

研究结果: 实验结果表明，FedSC在多种挑战性场景下表现优异，关键组件高效。

研究结论: FedSC通过语义感知协作有效解决了数据异构性问题，为联邦学习提供了新思路。

中文摘要: 联邦学习（FL）旨在通过客户端协作训练模型，同时保护数据隐私。然而，数据异构性（即多个客户端的标签偏好偏差）是一个主要挑战。现有方法通常通过局部（如正则化本地模型）或全局（如微调全局模型）方式解决数据异构性，但往往忽略了客户端内部的语义信息。为探索利用客户端内语义知识处理数据异构性的可能性，本文提出基于语义感知协作的联邦学习（FedSC），以捕获异构客户端间特定于客户端和类别的知识。FedSC的核心思想是在语义层面构建关系原型和一致性原型，旨在通过原型协作方式提供丰富的类别底层知识和稳定的收敛信号。一方面，FedSC引入对比学习策略，使实例级嵌入更接近具有相同语义的关系原型，远离不同类别。另一方面，FedSC通过差异聚合方式设计一致性原型，作为正则化惩罚约束本地模型的优化区域。此外，本文提供了FedSC的理论分析以确保收敛性保证。实验结果表明，FedSC在多种挑战性场景中表现优异，关键组件高效。

</details>


### [76] [HybridQ: Hybrid Classical-Quantum Generative Adversarial Network for Skin Disease Image Generation](https://arxiv.org/abs/2506.21015)
**中文标题：HybridQ：用于皮肤疾病图像生成的混合经典-量子生成对抗网络**

*Qingyue Jiao,Kangyu Zheng,Yiyu Shi,Zhiding Liang*

主要分类: cs.CV

摘要简述: 本文提出了一种混合经典-量子生成对抗网络（HybridQ），用于生成皮肤疾病图像。通过结合经典与量子潜在空间的融合技术，该模型首次实现了彩色医学图像的生成，并在图像质量和分类性能上优于传统方法，同时显著减少了参数数量和训练时间。


<details>
  <summary>详细信息</summary>
研究动机: 皮肤疾病数据集常面临类别不平衡、隐私问题和对象偏差等问题，传统生成模型计算资源消耗大且训练时间长。量子计算虽有潜力，但现有方法仅能生成低质量灰度图像。因此，研究旨在开发一种高效混合模型，解决这些问题。

研究方法: 提出了一种新颖的经典-量子潜在空间融合技术，构建了首个能够生成彩色医学图像的混合经典-量子生成对抗网络（GAN）。该模型结合了经典和量子计算的优势，显著提升了生成效率和图像质量。

研究结果: 实验表明，该模型在图像生成质量和分类性能提升上优于传统深度卷积GAN和其他混合量子GAN，且性能提升与最先进的经典生成模型相当，同时参数减少25倍，训练轮次减少10倍。在真实IBM量子机器上验证了其鲁棒性。

研究结论: HybridQ展示了量子图像生成的潜力，随着量子硬件的发展，未来有望在医学图像生成领域发挥更大作用。

中文摘要: 机器学习辅助诊断在皮肤疾病检测中日益受到关注，但训练有效模型需要大量高质量数据。皮肤疾病数据集常存在类别不平衡、隐私问题和对象偏差等问题，因此数据增强至关重要。传统生成模型虽广泛应用，但计算资源消耗大且训练时间长。量子计算提供了有前景的替代方案，但现有量子图像生成方法仅能生成低质量灰度图像。通过一种新颖的经典-量子潜在空间融合技术，本研究克服了这一限制，并首次提出了一种能够生成彩色医学图像的混合经典-量子生成对抗网络（GAN）。该模型在图像生成质量和分类性能提升上优于传统深度卷积GAN和其他混合量子GAN，且性能提升与最先进的经典生成模型相当，同时参数减少25倍，训练轮次减少10倍。这一结果表明，随着量子硬件的发展，量子图像生成具有广阔前景。最后，我们在真实IBM量子机器上验证了模型在硬件噪声下的鲁棒性能。

</details>


### [77] [Multimodal Prompt Alignment for Facial Expression Recognition](https://arxiv.org/abs/2506.21017)
**中文标题：多模态提示对齐用于面部表情识别**

*Fuyan Ma,Yiran He,Bin Sun,Shutao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MPA-FER的多模态提示对齐框架，用于面部表情识别（FER），通过结合多粒度硬提示生成和原型引导的视觉特征对齐，显著提升了细粒度文本-视觉关系的捕捉能力，并在多个基准数据集上取得了优于现有方法的结果。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于视觉语言模型（VLM）的面部表情识别方法在捕捉细粒度文本-视觉关系方面表现不足，导致难以区分面部表情的细微差异。本文旨在通过多模态提示对齐框架解决这一问题。

研究方法: 1. 提出多粒度硬提示生成策略，利用大型语言模型（如ChatGPT）为每种面部表情生成详细描述；2. 通过最小化软提示与硬提示之间的特征差异，将外部知识注入软提示；3. 采用原型引导的视觉特征对齐，确保冻结图像编码器生成的提示视觉特征与类别原型对齐；4. 引入跨模态全局-局部对齐模块，专注于表情相关的面部特征。

研究结果: 在三个FER基准数据集上的实验表明，MPA-FER框架优于现有方法，同时保留了预训练模型的优势并降低了计算成本。

研究结论: MPA-FER框架通过多模态提示对齐和细粒度语义引导，显著提升了面部表情识别的性能，为基于VLM的下游任务提供了高效且可解释的解决方案。

中文摘要: 提示学习已被广泛用于高效适应视觉语言模型（如CLIP）以完成各种下游任务。尽管取得了成功，当前基于VLM的面部表情识别（FER）方法仍难以捕捉细粒度的文本-视觉关系，而这对于区分面部表情的细微差异至关重要。为解决这一问题，我们提出了一种名为MPA-FER的多模态提示对齐框架，为提示视觉特征的学习过程提供细粒度语义指导，从而生成更精确且可解释的表征。具体而言，我们引入了一种多粒度硬提示生成策略，利用大型语言模型（如ChatGPT）为每种面部表情生成详细描述。通过最小化软提示与硬提示之间的特征差异，将基于LLM的外部知识注入软提示。为保留预训练CLIP模型的泛化能力，我们的方法结合了原型引导的视觉特征对齐，确保冻结图像编码器生成的提示视觉特征与类别原型紧密对齐。此外，我们提出了一种跨模态全局-局部对齐模块，专注于表情相关的面部特征，进一步改善了文本与视觉特征的对齐。大量实验表明，我们的框架在三个FER基准数据集上优于现有方法，同时保留了预训练模型的优势并降低了计算成本。

</details>


### [78] [LASFNet: A Lightweight Attention-Guided Self-Modulation Feature Fusion Network for Multimodal Object Detection](https://arxiv.org/abs/2506.21018)
**中文标题：LASFNet：一种轻量级注意力引导自调制特征融合网络用于多模态目标检测**

*Lei Hao,Lina Xu,Chang Liu,Yanni Dong*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级注意力引导自调制特征融合网络（LASFNet），通过单一特征级融合单元简化训练过程，显著降低计算成本，同时提升检测精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态目标检测方法通常通过堆叠多个特征级融合单元实现，导致计算复杂度高且训练过程复杂。本文旨在设计一种高效且轻量的特征融合方法，以简化训练并提升性能。

研究方法: 提出LASFNet，包含注意力引导自调制特征融合模块（ASFF）和轻量级特征注意力变换模块（FATM）。ASFF模块通过全局和局部注意力自适应调整融合特征，FATM模块增强对融合特征的关注并减少信息损失。

研究结果: 在三个代表性数据集上的实验表明，LASFNet在减少90%参数和85%计算成本的同时，检测精度（mAP）提升1%-3%，实现了高效与高精度的平衡。

研究结论: LASFNet通过轻量化和注意力机制优化特征融合，显著提升了多模态目标检测的效率与准确性，为未来研究提供了新基线。

中文摘要: 通过特征级融合实现有效的深度特征提取对多模态目标检测至关重要。然而，现有研究通常通过堆叠多个特征级融合单元整合模态特定特征，导致计算开销巨大。为解决这一问题，我们提出了一种新的融合检测基线，仅使用单一特征级融合单元实现高性能检测，从而简化训练过程。基于此，我们提出了一种轻量级注意力引导自调制特征融合网络（LASFNet），其引入了一种新颖的注意力引导自调制特征融合（ASFF）模块，该模块基于不同模态的注意力信息自适应调整全局和局部融合特征的响应，从而促进全面且丰富的特征生成。此外，在LASFNet的颈部设计了轻量级特征注意力变换模块（FATM），以增强对融合特征的关注并最小化信息损失。在三个代表性数据集上的大量实验表明，与现有最优方法相比，我们的方法在效率和精度之间取得了良好平衡，参数数量和计算成本分别减少了90%和85%，同时检测精度（mAP）提升了1%-3%。代码将在https://github.com/leileilei2000/LASFNet开源。

</details>


### [79] [Instella-T2I: Pushing the Limits of 1D Discrete Latent Space Image Generation](https://arxiv.org/abs/2506.21022)
**中文标题：Instella-T2I：突破1D离散潜在空间图像生成的极限**

*Ze Wang,Hao Chen,Benran Hu,Jiang Liu,Ximeng Sun,Jialian Wu,Yusheng Su,Xiaodong Yu,Emad Barsoum,Zicheng Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Instella-T2I的新方法，通过引入1D二进制图像潜在空间，显著减少了高分辨率图像生成所需的标记数量，同时保持了细节和效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像标记化方法需要大量计算资源，尤其是在高分辨率图像生成中。本文旨在通过1D二进制潜在空间减少标记数量，提高生成效率。

研究方法: 提出了一种1D二进制潜在空间表示方法，将图像编码为二进制向量序列，而非传统的一热编码标记。结合简单的模型架构，显著提升了训练和推理速度。

研究结果: 实验表明，仅需128个离散标记即可生成1024x1024的高分辨率图像，标记数量比标准VQ-VAE减少32倍。模型在单GPU节点上支持4096的全局批量大小，训练时间少于200 GPU天。

研究结论: Instella-T2I为图像生成提供了一种高效且可扩展的替代方案，无需私有训练数据或后训练优化，即可达到现代图像生成模型的竞争性能。

中文摘要: 图像标记化在降低高分辨率图像建模的计算需求方面起着关键作用，显著提高了图像和多模态理解与生成的效率。近年来，1D潜在空间的进展通过消除对2D网格结构的需求，减少了所需的标记数量。本文进一步推进了紧凑离散图像表示，引入了1D二进制图像潜在空间。通过将每张图像表示为二进制向量序列，而非传统的一热编码标记，我们的方法在保持1D潜在空间紧凑性的同时，保留了高分辨率细节。据我们所知，我们的文本到图像模型是首个仅使用128个离散标记即可在1024x1024分辨率下实现扩散和自回归生成竞争性能的模型，标记数量比标准VQ-VAE减少了32倍。提出的1D二进制潜在空间结合简单模型架构，显著提升了训练和推理速度。我们的文本到图像模型在单GPU节点（8个AMD MI300X GPU）上支持4096的全局批量大小，训练时间少于200 GPU天。我们的模型无需任何内部私有训练数据或后训练优化，即可与现代图像生成模型竞争，为传统标记化方法提供了一种可扩展且高效的替代方案。

</details>


### [80] [DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation](https://arxiv.org/abs/2506.21034)
**中文标题：DidSee：基于扩散模型的深度补全框架，用于材料无关的机器人感知与操作**

*Wenzhou Lyu,Jialing Lin,Wenqi Ren,Ruihao Xia,Feng Qian,Yang Tang*

主要分类: cs.CV

摘要简述: 论文提出了一种基于扩散模型的深度补全框架DidSee，用于解决非朗伯物体深度图噪声和不完整的问题，通过改进噪声调度器和训练策略，结合语义增强器，显著提升了深度补全性能。


<details>
  <summary>详细信息</summary>
研究动机: 商用RGB-D相机在非朗伯物体上生成的深度图通常噪声大且不完整。传统深度补全方法因训练数据有限而泛化能力不足，而现有扩散模型框架中的训练-推理偏差进一步影响了性能。

研究方法: DidSee框架包含三个关键改进：1) 采用零终端信噪比的重新缩放噪声调度器消除信号泄漏偏差；2) 设计噪声无关的单步训练策略以减少误差累积；3) 引入语义增强器联合完成深度补全和语义分割。

研究结果: DidSee在多个基准测试中达到最优性能，展示了强大的现实世界泛化能力，并有效提升了类别级姿态估计和机器人抓取等下游任务的表现。

研究结论: DidSee通过改进扩散模型框架，显著提升了非朗伯物体深度补全的精度和泛化能力，为机器人感知和操作任务提供了可靠支持。

中文摘要: 商用RGB-D相机在非朗伯物体上生成的深度图通常噪声大且不完整。传统深度补全方法因训练数据有限而泛化能力不足。近期研究利用预训练文本到图像扩散模型的视觉先验来增强密集预测任务的泛化能力，但发现扩散框架中训练-推理偏差显著影响了深度补全性能。此外，非朗伯区域缺乏明显视觉特征进一步阻碍了精确预测。为解决这些问题，我们提出DidSee，一种基于扩散模型的非朗伯物体深度补全框架。首先，我们采用零终端信噪比的重新缩放噪声调度器消除信号泄漏偏差；其次，设计噪声无关的单步训练策略以减少误差累积；最后，引入语义增强器联合完成深度补全和语义分割，区分物体与背景，生成精确的细粒度深度图。DidSee在多个基准测试中达到最优性能，展示了强大的现实世界泛化能力，并有效提升了类别级姿态估计和机器人抓取等下游任务的表现。项目页面：https://wenzhoulyu.github.io/DidSee/

</details>


### [81] [Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability](https://arxiv.org/abs/2506.21042)
**中文标题：利用扩散模型提升领域泛化与适应检测：适应性、泛化性与可迁移性**

*Boyong He,Yuxiang Ji,Zhuoyue Tan,Liaoni Wu*

主要分类: cs.CV

摘要简述: 本文提出一种基于扩散模型的方法，通过提取单步扩散过程的中间特征，减少75%推理时间，同时提升源域性能。通过构建以对象为中心的辅助分支和一致性损失，平衡适应性和泛化性，并在统一框架中通过特征和对象对齐提升跨域检测性能。在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 检测器在训练和测试数据之间存在领域差距时性能下降。现有方法虽尝试将扩散模型应用于领域泛化和适应任务，但仍面临推理成本高且未充分利用扩散模型潜力的问题。

研究方法: 1. 从单步扩散过程中提取中间特征，优化特征收集与融合，减少推理时间；2. 构建以对象为中心的辅助分支，通过框掩码图像和类别提示提取鲁棒且领域不变的特征；3. 应用一致性损失对齐辅助分支和普通分支，平衡适应性和泛化性；4. 在统一框架中，通过特征和对象对齐指导标准检测器提升跨域性能。

研究结果: 在3个领域适应基准和5个领域泛化基准上取得竞争性结果。在COCO泛化基准上表现优异，尤其在大领域偏移和低数据场景中效率显著。

研究结论: 本文展示了扩散模型在领域泛化和适应检测任务中的优越性，为跨领域视觉感知任务提供了有价值的见解。

中文摘要: 检测器常因训练与测试数据间的领域差距导致性能下降。近期方法尝试将扩散模型应用于领域泛化（DG）和适应（DA）任务，但仍面临高推理成本且未充分利用扩散模型潜力的问题。我们提出通过提取单步扩散过程的中间特征，优化特征收集与融合，减少75%推理时间的同时提升源域性能（即适应性）。进一步，通过框掩码图像和类别提示构建以对象为中心的辅助分支，提取鲁棒且领域不变的特征。应用一致性损失对齐辅助分支与普通分支，平衡适应性与泛化性，避免过拟合并提升目标域性能（即泛化性）。此外，在统一框架中，通过特征和对象对齐在源域（DG）和无标记目标域（DA）上指导标准检测器，提升跨域检测性能（即可迁移性）。我们的方法在3个DA基准和5个DG基准上取得竞争性结果。在COCO泛化基准上的实验表明，本方法在大领域偏移和低数据场景中仍保持显著优势且效率突出。本研究展示了扩散模型在领域泛化与适应检测任务中的优越性，为跨领域视觉感知任务提供了宝贵见解。代码发布于\href{https://github.com/heboyong/Fitness-Generalization-Transferability}{Fitness-Generalization-Transferability}。

</details>


### [82] [Improving Diffusion-Based Image Editing Faithfulness via Guidance and Scheduling](https://arxiv.org/abs/2506.21045)
**中文标题：通过指导和调度提升基于扩散的图像编辑忠实性**

*Hansam Cho,Seoung Bum Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FGS（Faithfulness Guidance and Scheduling）的方法，通过引入忠实性指导和调度策略，在保持图像可编辑性的同时显著提升编辑的忠实性。


<details>
  <summary>详细信息</summary>
研究动机: 基于文本引导的扩散模型在高质量图像合成和动态编辑中表现优异，但编辑的可编辑性与忠实性之间存在固有矛盾。本文旨在解决这一矛盾，提升编辑的忠实性而不显著影响可编辑性。

研究方法: FGS方法包含两部分：忠实性指导（用于强化输入图像信息的保留）和调度策略（用于解决可编辑性与忠实性之间的错位问题）。该方法兼容多种编辑技术。

研究结果: 实验结果表明，FGS在保持可编辑性的同时显著提升了编辑的忠实性，且适用于多种编辑任务，实现精确且高质量的图像编辑。

研究结论: FGS通过结合忠实性指导和调度策略，有效解决了可编辑性与忠实性之间的矛盾，为图像编辑提供了更优的解决方案。

中文摘要: 基于文本引导的扩散模型已成为高质量图像合成的关键工具，支持动态图像编辑。在图像编辑中，可编辑性（决定修改程度）和忠实性（反映未修改部分的保留程度）是两个关键方面。然而，由于可编辑性与忠实性之间的固有矛盾，实现最优结果具有挑战性。为此，我们提出忠实性指导和调度（FGS），以最小化对可编辑性的影响来提升忠实性。FGS通过忠实性指导强化输入图像信息的保留，并引入调度策略解决可编辑性与忠实性之间的错位问题。实验结果表明，FGS在保持可编辑性的同时实现了更高的忠实性。此外，其与多种编辑方法的兼容性使其能够支持多样化的精确、高质量图像编辑任务。

</details>


### [83] [Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features](https://arxiv.org/abs/2506.21046)
**中文标题：利用自监督视觉Transformer特征提升生成对抗迁移性**

*Shangbo Wu,Yu-an Tan,Ruinan Ma,Wencong Ma,Dehua Zhu,Yuanzhang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自监督视觉Transformer（ViT）特征的生成对抗攻击方法dSVA，通过结合对比学习（CL）和掩码图像建模（MIM）的全局与局部特征，显著提升了黑盒对抗样本的迁移性。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多依赖监督学习的中间特征生成对抗样本，但自监督学习与Transformer架构的结合表现出卓越潜力。本文旨在探索自监督ViT特征是否能够进一步提升对抗样本的迁移性。

研究方法: 提出dSVA方法，利用自监督ViT的双重特征（CL的全局结构特征和MIM的局部纹理特征），设计生成对抗样本的框架，并通过联合特征和注意力机制训练生成器。

研究结果: 实验表明，CL和MIM使ViT关注不同特征倾向，联合利用时显著提升对抗样本的泛化能力，其黑盒迁移性优于现有方法。

研究结论: 自监督ViT的双重特征为对抗攻击提供了新思路，dSVA方法在多种模型架构上表现出卓越的迁移性，为黑盒攻击提供了有效工具。

中文摘要: 深度神经网络（DNNs）的能力源于从数据中提取和解释特征。通过利用DNNs的中间特征而非硬标签，我们生成了更具泛化性的对抗扰动，从而提升了黑盒迁移性。以往研究多依赖监督学习的特征。受自监督学习与Transformer架构协同效应的启发，本文探讨了利用自监督视觉Transformer（ViT）特征是否能提升对抗迁移性。我们提出了dSVA——一种生成式双自监督ViT特征攻击方法，结合了对比学习（CL）的全局结构特征和掩码图像建模（MIM）的局部纹理特征，这是ViT的自监督学习范式对。我们设计了一个新颖的生成训练框架，包含生成器以创建黑盒对抗样本，并通过联合特征和自监督ViT的注意力机制训练生成器。实验表明，CL和MIM使ViT关注不同特征倾向，联合利用时显著提升了对抗泛化性。通过干扰自监督ViT提取的双重深度特征，我们实现了对多种架构模型的卓越黑盒迁移性，超越了现有技术。代码发布于https://github.com/spencerwooo/dSVA。

</details>


### [84] [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277)
**中文标题：HumanOmniV2：从理解到基于上下文的全模态推理**

*Qize Yang,Shimin Yao,Weixuan Chen,Shenghao Fu,Detao Bai,Jiaxing Zhao,Boyuan Sun,Bowen Yin,Xihan Wei,Jingren Zhou*

主要分类: cs.CV

摘要简述: 本文提出HumanOmniV2模型，通过强化学习提升多模态大语言模型的全局上下文理解和推理能力，解决了现有模型中的上下文理解不足和捷径问题，并在多模态基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型的快速发展，深入理解和解释人类意图的能力变得至关重要。然而，现有模型存在全局上下文理解不足和捷径问题，导致对多模态信息的误解或忽略。本文旨在通过强化学习提升模型的全局上下文理解和复杂推理能力。

研究方法: 为解决上下文理解不足和捷径问题，本文提出利用大语言模型评估上下文奖励、格式奖励和准确性奖励，同时引入逻辑奖励以提升复杂推理能力。此外，还开发了多模态推理基准IntentBench，用于评估模型对复杂人类意图和情感的理解。

研究结果: HumanOmniV2模型在多个多模态基准测试中表现优于其他开源多模态模型，证明了其在全局上下文理解和复杂推理方面的优势。

研究结论: 本文通过强化学习和大语言模型的结合，显著提升了多模态模型的全局上下文理解和推理能力，为多模态任务提供了更高效的解决方案。

中文摘要: 随着多模态大语言模型的快速发展，深入理解和解释人类意图的能力成为关键，这需要细致和深思熟虑的推理。最近的研究表明，强化学习（RL）在提升大语言模型（LLMs）的推理能力方面具有潜力。然而，将RL应用于多模态数据和格式的挑战仍未得到充分解决。本文发现现有多模态推理模型存在两个问题：全局上下文理解不足和捷径问题。上下文理解不足可能导致模型误解多模态上下文，从而给出错误答案；捷径问题则表现为模型忽略多模态输入中的关键线索，直接回答问题而未考虑多模态信息。为解决这些问题，我们强调模型需在多模态输入中清晰理解全局上下文，以防止忽略关键多模态线索并确保推理过程的完整性。为实现多模态上下文信息的准确解释，我们引入了由大语言模型评估的上下文奖励，以及格式和准确性奖励。此外，为提升复杂推理能力，我们利用大语言模型评估逻辑奖励，判断推理过程是否成功结合了多模态信息和逻辑方法。我们还提出了一个多模态推理基准IntentBench，用于评估模型对复杂人类意图和情感的理解能力。与其他开源全模态模型相比，本文提出的方法在多个全模态基准测试中表现出卓越性能。

</details>


### [85] [Class-Agnostic Region-of-Interest Matching in Document Images](https://arxiv.org/abs/2506.21055)
**中文标题：文档图像中的类别无关兴趣区域匹配**

*Demin Zhang,Jiahao Lyu,Zhijie Shen,Yu Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“类别无关兴趣区域匹配”（RoI-Matching）的新任务，旨在灵活、高效地匹配用户自定义的文档区域，并构建了基准数据集RoI-Matching-Bench和框架RoI-Matcher，实验证明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有文档分析解决方案（如文档布局分析和关键信息提取）仅适用于固定类别定义和粒度，无法满足用户灵活定制的需求。因此，本文提出RoI-Matching任务，以实现多粒度、开放式的灵活匹配。

研究方法: 本文提出RoI-Matcher框架，采用孪生网络提取参考文档和目标文档的多层次特征，并通过交叉注意力层整合和对齐不同域的相似语义。同时构建了包含三个难度级别的基准数据集RoI-Matching-Bench。

研究结果: 实验表明，RoI-Matcher在RoI-Matching-Bench上表现有效，为后续研究提供了基线。

研究结论: RoI-Matching任务和RoI-Matcher框架为文档分析提供了灵活、高效的解决方案，并推动了该领域的进一步研究。

中文摘要: 文档理解与分析因其广泛应用而备受关注。然而，现有的文档分析解决方案（如文档布局分析和关键信息提取）仅适用于固定类别定义和粒度，无法实现用户定制的灵活应用。因此，本文定义了一项名为“类别无关兴趣区域匹配”（简称“RoI-Matching”）的新任务，旨在以灵活、高效、多粒度和开放集的方式匹配自定义区域。参考文档和目标文档图像的视觉提示被输入到我们的模型中，输出为目标文档图像中对应的边界框。为满足上述需求，我们构建了基准数据集RoI-Matching-Bench，根据实际条件设置了三个难度级别，并提出了宏观和微观评估指标。此外，我们还提出了新框架RoI-Matcher，采用孪生网络提取参考域和目标域的多层次特征，并通过交叉注意力层整合和对齐不同域的相似语义。实验表明，我们的方法在RoI-Matching-Bench上简单且有效，为后续研究提供了基线。代码可在https://github.com/pd162/RoI-Matching获取。

</details>


### [86] [SAMURAI: Shape-Aware Multimodal Retrieval for 3D Object Identification](https://arxiv.org/abs/2506.21056)
**中文标题：SAMURAI：基于形状感知的多模态3D物体识别检索方法**

*Dinh-Khoi Vo,Van-Loc Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: SAMURAI是一种基于形状感知的多模态检索方法，用于在复杂室内环境中通过掩码2D图像和自然语言描述识别3D物体。该方法结合CLIP语义匹配和形状引导重排序，显著提升了检索性能。


<details>
  <summary>详细信息</summary>
研究动机: 在复杂室内环境中，仅通过掩码2D图像和自然语言描述检索3D物体面临诸多挑战，如视角扭曲、无纹理掩码区域、模糊语言提示和噪声分割掩码。ROOMELSA挑战赛进一步限制了完整3D场景上下文的使用，增加了任务难度。

研究方法: SAMURAI结合了CLIP语义匹配和基于二值轮廓的形状引导重排序，并采用多数投票策略。预处理流程通过提取最大连通分量和去除背景噪声提升掩码质量。

研究结果: SAMURAI在ROOMELSA私有测试集上表现出色，证明了结合形状先验和语言理解对开放世界3D物体检索的重要性。

研究结论: SAMURAI通过多模态融合和形状感知显著提升了3D物体检索的鲁棒性，为开放世界检索任务提供了有效解决方案。

中文摘要: 在复杂室内环境中，仅通过掩码2D图像和自然语言描述检索3D物体面临显著挑战。ROOMELSA挑战赛限制了完整3D场景上下文的使用，增加了对物体外观、几何和语义推理的难度。这些挑战因扭曲视角、无纹理掩码区域、模糊语言提示和噪声分割掩码而加剧。为此，我们提出SAMURAI：基于形状感知的多模态3D物体识别检索方法。SAMURAI将CLIP语义匹配与基于二值轮廓的形状引导重排序结合，并采用鲁棒的多数投票策略。专用预处理流程通过提取最大连通分量和去除背景噪声提升掩码质量。我们的混合检索框架同时利用语言和形状线索，在ROOMELSA私有测试集上取得了竞争力表现。这些结果凸显了结合形状先验与语言理解对鲁棒的开放世界3D物体检索的重要性。

</details>


### [87] [PoseMaster: Generating 3D Characters in Arbitrary Poses from a Single Image](https://arxiv.org/abs/2506.21076)
**中文标题：PoseMaster：从单张图像生成任意姿势的3D角色**

*Hongyu Yan,Kunming Luo,Weiyu Li,Yixun Liang,Shengming Li,Jingwei Huang,Chunchao Guo,Ping Tan*

主要分类: cs.CV

摘要简述: PoseMaster提出了一种端到端的可控3D角色生成框架，通过统一姿势变换与3D生成，解决了传统方法因自遮挡和视角导致的图像失真问题，并利用骨骼作为姿势条件实现精确控制。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于图像的方法在姿势标准化和3D重建阶段容易因自遮挡和视角问题生成失真图像，影响后续几何质量。PoseMaster旨在通过端到端框架解决这些问题，提升3D角色生成的效率和质量。

研究方法: PoseMaster将姿势变换与3D生成统一为基于流的3D原生生成框架，利用角色骨骼作为姿势条件，并通过随机清空训练条件提升控制效果和泛化性。此外，构建了高质量姿势控制数据集以学习骨骼与蒙皮权重的隐式关系。

研究结果: 实验表明，PoseMaster在A姿势角色生成任务中优于现有技术，并在任意姿势控制方面表现出强大的精确控制能力。

研究结论: PoseMaster通过端到端框架和骨骼条件控制，显著提升了3D角色生成的几何质量和姿势控制能力，为未来研究提供了新方向。

中文摘要: 3D角色在日常娱乐中扮演着重要角色。为提高3D角色建模效率，近期基于图像的方法使用两个独立模型分别实现姿势标准化和A姿势角色的3D重建。然而，这些方法在姿势标准化阶段因自遮挡和视角问题容易生成失真和降质的图像，进而影响后续重建过程的几何质量。为解决这些问题，我们提出了PoseMaster，一种端到端可控的3D角色生成框架。具体而言，我们将姿势变换与3D角色生成统一为基于流的3D原生生成框架。为实现精确的任意姿势控制，我们提出利用可动画角色的骨骼中的3D身体骨骼作为姿势条件。此外，考虑到多条件控制的特殊性，我们在训练中随机清空姿势条件和图像条件，以提高姿势控制的有效性和泛化性。最后，我们基于真实角色动画数据构建了高质量的姿势控制数据集，使模型能够学习骨骼与蒙皮权重之间的隐式关系。大量实验表明，PoseMaster在A姿势角色生成的定性和定量评估中均优于当前最先进技术，同时展示了其在实现任意姿势精确控制方面的强大能力。

</details>


### [88] [EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception](https://arxiv.org/abs/2506.21080)
**中文标题：EgoAdapt：自适应多感官蒸馏与策略学习实现高效自我中心感知**

*Sanjoy Chowdhury,Subrata Biswas,Sayan Nag,Tushar Nagarajan,Calvin Murdock,Ishwarya Ananthabhotla,Yijun Qian,Vamsi Krishna Ithapu,Dinesh Manocha,Ruohan Gao*

主要分类: cs.CV

摘要简述: 本文提出EgoAdapt框架，通过自适应跨模态蒸馏和策略学习，显著提升多感官自我中心感知任务的效率，同时保持或超越现有模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代多感官自我中心感知模型性能优异但计算成本高，难以在资源受限环境中部署。本文旨在通过自适应方法提升效率。

研究方法: EgoAdapt框架结合跨模态蒸馏和策略学习，适应不同任务的动作空间，适用于多种自我中心感知任务。

研究结果: 在EPIC-Kitchens、EasyCom和Aria Everyday Activities数据集上，EgoAdapt显著降低计算量（GMACs减少89.09%）、参数（减少82.02%）和能耗（降低9.6倍），性能与现有最优模型相当或更优。

研究结论: EgoAdapt通过自适应方法高效解决了多感官自我中心感知任务的计算成本问题，具有广泛适用性。

中文摘要: 现代感知模型，尤其是为多感官自我中心任务设计的模型，性能卓越但计算成本高昂，这为实际部署带来了挑战，尤其是在资源受限的环境中。本文提出EgoAdapt框架，通过自适应跨模态蒸馏和策略学习，实现高效推理，适用于多种自我中心感知任务，包括自我中心动作识别、主动说话者定位和行为预测。所提出的策略模块可适应任务特定的动作空间，具有广泛适用性。在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个具有挑战性的自我中心数据集上的实验结果表明，我们的方法显著提升了效率，GMACs减少高达89.09%，参数减少高达82.02%，能耗降低高达9.6倍，同时性能与现有最优模型相当甚至更优。

</details>


### [89] [ESMStereo: Enhanced ShuffleMixer Disparity Upsampling for Real-Time and Accurate Stereo Matching](https://arxiv.org/abs/2506.21091)
**中文标题：ESMStereo：用于实时高精度立体匹配的增强型ShuffleMixer视差上采样方法**

*Mahmoud Tahmasebi,Saif Huq,Kevin Meehan,Marion McAfee*

主要分类: cs.CV

摘要简述: 本文提出了一种增强型ShuffleMixer（ESM）方法，用于解决基于小规模成本体积的立体匹配中信息丢失的问题，通过特征融合和轻量级网络实现实时高精度视差估计。


<details>
  <summary>详细信息</summary>
研究动机: 立体匹配在现代自主系统中至关重要，但基于大规模成本体积的方法计算量大，难以实现实时性能；而小规模成本体积虽能实现实时性，但精度不足。本文旨在通过ESM方法解决这一矛盾。

研究方法: 提出增强型ShuffleMixer（ESM），将初始视差估计的特征与图像特征融合，通过混洗和分层分割混合特征，再通过紧凑的特征引导沙漏网络恢复细节，实现高精度视差图重建。

研究结果: ESMStereo的紧凑版本在高性能GPU上达到116 FPS，在AGX Orin上达到91 FPS，同时保持高精度视差估计。

研究结论: ESM方法通过特征融合和轻量级网络设计，成功解决了小规模成本体积信息不足的问题，实现了实时高精度立体匹配。

中文摘要: 立体匹配已成为现代自主系统中日益重要的组成部分。开发基于深度学习的立体匹配模型，在保证高精度的同时实现实时性能，仍然是计算机视觉领域的主要挑战。在基于成本体积的立体匹配中，准确的视差估计高度依赖于大规模成本体积。然而，这种大规模体积存储了大量冗余信息，并且需要计算密集的聚合单元进行处理和回归，导致实时性能难以实现。相反，小规模成本体积结合轻量级聚合单元为实现实时性能提供了可能，但缺乏足够信息以确保高精度视差估计。为解决这一问题，我们提出了增强型ShuffleMixer（ESM），以缓解小规模成本体积带来的信息损失。ESM通过将主要特征整合到视差上采样单元中，恢复关键细节。它快速提取初始视差估计的特征并与图像特征融合，通过混洗和分层分割混合特征，再通过紧凑的特征引导沙漏网络细化，以恢复更详细的场景几何。ESM专注于具有大感受野和低计算成本的局部上下文连接，从而在实时情况下重建高精度视差图。ESMStereo的紧凑版本在高性能GPU上达到116 FPS，在AGX Orin上达到91 FPS。

</details>


### [90] [OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography](https://arxiv.org/abs/2506.21101)
**中文标题：OracleFusion：基于结构约束语义排版的甲骨文解读辅助工具**

*Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,AndyPian Wu,Chaoyang Wang,Chengjie Wang,Taisong Jin,SevenShu,Yunsheng Wu,Yongge Liu,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出了一种名为OracleFusion的两阶段语义排版框架，用于辅助解读甲骨文。通过增强空间感知推理的多模态大语言模型和甲骨结构向量融合技术，该方法在语义、视觉和字形保持方面优于现有模型，显著提升了甲骨文的可读性和美学质量。


<details>
  <summary>详细信息</summary>
研究动机: 甲骨文作为最古老的文字之一，记录了古代文明的文化与智慧。尽管已发现约4500个甲骨文字符，但仅约1600个被解读。剩余字符结构复杂且意象抽象，解读难度大。本文旨在通过技术手段辅助专家解读这些未解字符。

研究方法: OracleFusion采用两阶段框架：第一阶段利用增强空间感知推理的多模态大语言模型分析甲骨文字符的字形结构并定位关键部件；第二阶段引入甲骨结构向量融合技术，结合字形结构约束和字形保持约束，生成语义丰富的矢量字体。

研究结果: 实验表明，OracleFusion在语义、视觉吸引力和字形保持方面优于现有基准模型，显著提升了甲骨文的可读性和美学质量。此外，该方法还能为未解读字符提供专家级见解。

研究结论: OracleFusion为甲骨文解读提供了有效的技术工具，通过语义排版和字形约束的结合，显著提升了甲骨文的解读效率和准确性，对推动甲骨文研究具有重要意义。

中文摘要: 甲骨文作为最古老的文字之一，承载了古代文明的文化记录与智慧表达。尽管已发现约4500个甲骨文字符，但仅约1600个被解读。剩余字符结构复杂且意象抽象，解读难度大。为解决这一问题，本文提出了一种名为OracleFusion的两阶段语义排版框架。第一阶段利用增强空间感知推理的多模态大语言模型分析甲骨文字符的字形结构，并定位关键部件；第二阶段引入甲骨结构向量融合技术，结合字形结构约束和字形保持约束，生成语义丰富的矢量字体。该方法保持了字形结构的客观完整性，提供了视觉增强的表示形式，辅助专家解读甲骨文。大量定性与定量实验表明，OracleFusion在语义、视觉吸引力和字形保持方面优于现有基准模型，显著提升了甲骨文的可读性和美学质量。此外，OracleFusion还能为未解读字符提供专家级见解，成为推动甲骨文解读的重要工具。

</details>


### [91] [Logios : An open source Greek Polytonic Optical Character Recognition system](https://arxiv.org/abs/2506.21474)
**中文标题：Logios：一种开源的希腊多调光学字符识别系统**

*Perifanos Konstantinos,Goutsos Dionisis*

主要分类: cs.CV

摘要简述: 本文介绍了一种专为希腊多调文本设计的光学字符识别（OCR）系统，结合卷积层和循环层的优势，显著提升了识别准确率和效率，并开源了模型。


<details>
  <summary>详细信息</summary>
研究动机: 传统OCR方法在处理希腊多调文本时存在局限性，本文旨在开发一种更准确、高效的OCR系统，以解决这一问题。

研究方法: 系统结合了卷积层用于特征提取和循环层用于序列学习，以应对希腊多调文本的独特挑战。

研究结果: 该方法显著提升了OCR的准确率和效率，并开源了模型和平台供学术使用。

研究结论: 本文提出的OCR系统为希腊多调文本的数字化提供了高效解决方案，并通过开源促进了学术研究。

中文摘要: 本文介绍了一种专为希腊多调文本设计的光学字符识别（OCR）系统。通过结合卷积层用于特征提取和循环层用于序列学习的优势，该系统解决了希腊多调文本带来的独特挑战。此方法旨在克服传统OCR技术的局限性，显著提升了准确率和效率。我们开源了底层模型，并将OCR平台提供给学术使用。

</details>


### [92] [Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing Change Detection](https://arxiv.org/abs/2506.21109)
**中文标题：突破权衡边界：紧凑而高效的遥感变化检测**

*Luosheng Xu,Dalin Zhang,Zhaohui Song*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级遥感变化检测模型FlickCD，通过增强差异模块和多尺度语义捕捉技术，显著降低计算和存储开销，同时保持高精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度学习模型在遥感变化检测中计算复杂且资源消耗大，但精度提升有限。研究旨在开发高效轻量模型，满足卫星端处理需求。

研究方法: 提出FlickCD模型，包含增强差异模块（EDM）以突出关键特征差异，并采用局部-全局融合块（SWSA和EGSA）捕捉多尺度语义信息。

研究结果: 在四个基准数据集上，FlickCD计算和存储开销降低超过一个数量级，同时达到或接近最优性能（F1损失<1%）。

研究结论: FlickCD在性能和资源消耗之间取得了显著平衡，为卫星端高效处理提供了可行方案。

中文摘要: 遥感变化检测对于监测城市扩张、灾害评估和资源管理至关重要，能够提供动态景观变化的及时、准确和大规模洞察。尽管深度学习已经彻底改变了变化检测，但现代模型日益增加的复杂性和计算需求并未带来显著的精度提升。本研究未追随这一趋势，而是探索了一种更高效的方法，专注于轻量级模型，在保持高精度的同时最小化资源消耗，这是卫星端处理的关键需求。为此，我们提出了FlickCD（意为快速操作即可获得优异结果），突破了性能与资源之间的权衡边界。FlickCD引入了增强差异模块（EDM），以放大时间相之间的关键特征差异，同时抑制光照和天气变化等无关变化，从而降低后续变化解码器的计算成本。此外，FlickCD解码器结合了局部-全局融合块，利用移位窗口自注意力（SWSA）和增强全局自注意力（EGSA）高效捕捉多尺度语义信息，保留粗粒度和细粒度的变化。在四个基准数据集上的大量实验表明，FlickCD将计算和存储开销降低了一个数量级以上，同时实现了最优性能或仅带来微小的（<1% F1）精度损失。实现代码已公开于https://github.com/xulsh8/FlickCD。

</details>


### [93] [IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes](https://arxiv.org/abs/2506.21116)
**中文标题：IPFormer-VideoLLM：增强多镜头场景的多模态视频理解能力**

*Yujia Liang,Jile Jiao,Zhicheng Wang,Xuetao Feng,Zixuan Ye,Yuan Wang,Hao Lu*

主要分类: cs.CV

摘要简述: 本文提出IPFormer-VideoLLM模型和MultiClip-Bench数据集，以解决视频大语言模型在多镜头场景中的理解不足问题，通过实例级特征注入显著提升了多场景视频理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频大语言模型在多镜头场景（如不同摄像机角度或场景切换）中表现不佳，容易出现实例身份遗忘和关键帧忽略问题。这主要源于数据集中缺乏多镜头标注。

研究方法: 首先引入MultiClip-Bench数据集，包含针对多镜头场景的密集描述和指令问答对；随后提出IPFormer-VideoLLM模型，通过基于注意力的连接器注入实例级特征作为提示，实现跨场景的实例信息聚合。

研究结果: 实验表明，所提数据集和模型不仅显著提升了多场景视频理解能力，还在多个视频基准测试中表现出独特优势。

研究结论: IPFormer-VideoLLM和MultiClip-Bench为多镜头视频理解提供了有效解决方案，填补了现有数据和方法空白。

中文摘要: 视频大语言模型（VideoLLMs）已展现出卓越的理解能力，但在多镜头场景（如摄像机角度变化或场景切换的视频片段）中表现不佳，容易出现实例身份遗忘和关键帧忽略问题。本文首先将此挑战归因于现有数据集中缺乏多镜头标注，因此引入了名为MultiClip-Bench的新数据集，其包含针对多镜头场景的密集描述和基于指令的问答对。实证发现，训练集显著提升了多镜头性能，而测试基准则可靠地衡量了模型在多镜头场景中的能力。通过进一步分析发现，当前模型仅以离散或有损方式编码实例特征，可能导致身份信息丢失。为此，本文提出了新模型IPFormer-VideoLLM，其核心思想是通过高效的基于注意力的连接器注入实例级特征作为实例提示，从而实现跨场景的实例信息聚合。实验表明，所提数据集和模型不仅显著提升了多场景视频理解能力，还在多个视频基准测试中表现出独特优势。

</details>


### [94] [HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation](https://arxiv.org/abs/2506.21546)
**中文标题：HalluSegBench：基于反事实视觉推理的分割幻觉评估**

*Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou*

主要分类: cs.CV

摘要简述: HalluSegBench是首个通过反事实视觉推理评估视觉基础中幻觉现象的基准，包含1340个反事实实例对和新型指标，揭示视觉驱动幻觉比标签驱动更普遍。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言分割模型常产生未基于图像内容的幻觉分割，现有评估方法无法诊断关键失败，因此需开发新基准以量化幻觉敏感性。

研究方法: 提出HalluSegBench基准，包含1340个反事实实例对和新型指标，通过视觉连贯场景编辑量化幻觉敏感性，并测试先进模型。

研究结果: 实验表明视觉驱动幻觉显著多于标签驱动，模型常持续错误分割，凸显反事实推理对诊断基础保真度的重要性。

研究结论: HalluSegBench为评估视觉基础幻觉提供了有效工具，反事实推理能更准确诊断模型失败，推动未来研究。

中文摘要: 视觉语言分割的最新进展显著提升了基于视觉的理解能力。然而，这些模型常产生幻觉，即分割未基于图像内容的对象或错误标记无关区域。现有分割幻觉评估方法主要关注标签或文本幻觉，未操纵视觉上下文，限制了诊断关键失败的能力。为此，我们提出HalluSegBench，首个通过反事实视觉推理评估视觉基础幻觉的基准。该基准包含1340个反事实实例对，涵盖281个独特对象类别，并引入新指标以量化视觉连贯场景编辑下的幻觉敏感性。在HalluSegBench上对先进视觉语言分割模型的实验表明，视觉驱动幻觉显著多于标签驱动，模型常持续错误分割，凸显反事实推理对诊断基础保真度的重要性。

</details>


### [95] [CL-Splats: Continual Learning of Gaussian Splatting with Local Optimization](https://arxiv.org/abs/2506.21117)
**中文标题：CL-Splats：基于局部优化的高斯泼溅持续学习**

*Jan Ackermann,Jonas Kulhanek,Shengqu Cai,Haofei Xu,Marc Pollefeys,Gordon Wetzstein,Leonidas Guibas,Songyou Peng*

主要分类: cs.CV

摘要简述: CL-Splats是一种基于高斯泼溅的3D场景表示方法，通过局部优化和变化检测模块，实现动态3D场景的高效更新和高质量重建。


<details>
  <summary>详细信息</summary>
研究动机: 在动态3D环境中，实时更新场景表示对机器人、混合现实和具身AI应用至关重要。传统方法需要重新优化整个场景，计算开销大。CL-Splats旨在通过局部优化和变化检测，高效更新场景表示。

研究方法: CL-Splats通过高斯泼溅技术表示3D场景，并引入变化检测模块，识别场景中的动态和静态部分。仅对变化部分进行局部优化，避免不必要的全局重新计算。此外，支持存储和恢复场景历史状态，便于时间分割和新应用开发。

研究结果: 实验表明，CL-Splats能够高效更新3D场景，重建质量优于现有技术，为实时3D场景重建任务提供了坚实基础。

研究结论: CL-Splats通过局部优化和变化检测，实现了动态3D场景的高效更新和高质量重建，为未来实时适应性任务提供了可靠方法。

中文摘要: 在动态3D环境中，随时间准确更新场景表示对机器人、混合现实和具身AI应用至关重要。随着场景变化，需要高效方法以纳入变化，保持高质量重建，而无需重新优化整个场景的计算开销。本文提出CL-Splats，通过稀疏场景捕获逐步更新基于高斯泼溅的3D表示。CL-Splats集成了鲁棒的变化检测模块，分割场景中的更新和静态部分，实现聚焦的局部优化，避免不必要的重新计算。此外，CL-Splats支持存储和恢复历史场景状态，便于时间分割和新场景分析应用。大量实验表明，CL-Splats实现了高效更新，重建质量优于现有技术，为未来3D场景重建任务的实时适应性奠定了坚实基础。

</details>


### [96] [GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction](https://arxiv.org/abs/2506.21121)
**中文标题：GoIRL：基于图导向的逆向强化学习用于多模态轨迹预测**

*Muleilan Pei,Shaoshuai Shi,Lu Zhang,Peiliang Li,Shaojie Shen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图导向的逆向强化学习框架GoIRL，用于多模态轨迹预测，通过整合车道图特征和最大熵逆向强化学习，显著提升了预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶中周围代理的轨迹预测具有高度不确定性和多模态性，现有数据驱动方法主要依赖监督学习，难以充分捕捉复杂场景。本文旨在通过逆向强化学习框架解决这一问题。

研究方法: 提出GoIRL框架，利用特征适配器将车道图特征聚合到网格空间，结合最大熵逆向强化学习推断奖励分布；采用分层参数化轨迹生成器和概率融合策略提升预测精度。

研究结果: 在Argoverse和nuScenes运动预测基准测试中表现优异，不仅达到最先进水平，还展现出比现有监督模型更强的泛化能力。

研究结论: GoIRL框架通过图导向的逆向强化学习和多模态轨迹生成策略，显著提升了轨迹预测的准确性和泛化性能，为自动驾驶领域提供了有效解决方案。

中文摘要: 自动驾驶中周围代理的轨迹预测因其固有的不确定性和多模态性而极具挑战性。与主要依赖监督学习的现有数据驱动方法不同，本文提出了一种新颖的基于图导向的逆向强化学习（GoIRL）框架，该框架配备了向量化上下文表示。我们开发了一种特征适配器，能够有效地将车道图特征聚合到网格空间，从而与最大熵逆向强化学习范式无缝集成，以推断奖励分布并获取可通过采样生成多个合理计划的策略。此外，基于采样计划，我们实现了一种分层参数化轨迹生成器，配备细化模块以提升预测精度，并通过概率融合策略增强预测置信度。大量实验结果表明，我们的方法不仅在大规模Argoverse和nuScenes运动预测基准测试中达到了最先进的性能，而且与现有监督模型相比展现出更优异的泛化能力。

</details>


### [97] [Learning to See in the Extremely Dark](https://arxiv.org/abs/2506.21132)
**中文标题：学习在极暗环境中观察**

*Hai Jiang,Binhao Guan,Zhen Liu,Xiaohong Liu,Jian Yu,Zheng Liu,Songchen Han,Shuaicheng Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种用于极暗环境下RAW图像增强的数据合成管道和扩散模型框架，生成了一个名为SIED的大规模配对数据集，并验证了方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于学习的方法在低光RAW图像增强方面取得进展，但缺乏针对极暗环境（低至0.0001 lux）的数据集和方法。本文旨在填补这一空白。

研究方法: 提出了一个配对数据合成管道，生成三个精确光照范围（0.01-0.1 lux、0.001-0.01 lux、0.0001-0.001 lux）的极低光RAW图像和高质量sRGB参考图像，构建了SIED数据集。同时，提出了一种基于扩散模型的框架，结合自适应光照校正模块（AICM）和颜色一致性损失，实现极低信噪比RAW输入的视觉恢复。

研究结果: 在SIED数据集和公开基准上的实验表明，该方法在极暗环境下的RAW图像增强效果显著。

研究结论: 本文提出的数据合成管道和扩散模型框架为极暗环境下的图像增强提供了有效解决方案，SIED数据集为相关研究提供了基准。

中文摘要: 基于学习的方法在低光RAW图像增强方面取得了显著进展，但其在环境照度低至0.0001 lux的极暗场景中的能力仍有待探索，原因在于缺乏相应的数据集。为此，我们提出了一种配对数据合成管道，能够生成三个精确光照范围（0.01-0.1 lux、0.001-0.01 lux、0.0001-0.001 lux）的极低光RAW图像，并配以高质量的sRGB参考图像，构建了一个名为“极暗环境观察”（SIED）的大规模配对数据集，用于评估低光RAW图像增强方法。此外，我们提出了一种基于扩散模型的框架，利用扩散模型的生成能力和固有去噪特性，从极低信噪比的RAW输入中恢复出视觉上令人愉悦的结果。其中，自适应光照校正模块（AICM）和颜色一致性损失的引入确保了准确的曝光校正和色彩恢复。在提出的SIED数据集和公开基准上的广泛实验证明了我们方法的有效性。代码和数据集可在https://github.com/JianghaiSCU/SIED获取。

</details>


### [98] [YOLO-FDA: Integrating Hierarchical Attention and Detail Enhancement for Surface Defect Detection](https://arxiv.org/abs/2506.21135)
**中文标题：YOLO-FDA：结合层次化注意力与细节增强的表面缺陷检测方法**

*Jiawei Hu*

主要分类: cs.CV

摘要简述: YOLO-FDA是一种基于YOLO的新型检测框架，通过细粒度细节增强和注意力引导特征融合，显著提升了工业场景中表面缺陷检测的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 工业场景中的表面缺陷检测因缺陷类型多样、形状和尺寸不规则、细粒度要求高以及材料纹理复杂而极具挑战性。现有AI检测方法存在特征冗余、细节敏感性不足和多尺度条件下鲁棒性差的问题，因此需要一种更高效的解决方案。

研究方法: YOLO-FDA采用BiFPN架构增强YOLOv5主干网络的双向多级特征聚合，并引入细节定向融合模块（DDFM）通过方向性非对称卷积丰富空间细节。此外，提出两种基于注意力的融合策略：注意力加权拼接（AC）和跨层注意力融合（CAF），以提升上下文表示并减少特征噪声。

研究结果: 在多个基准数据集上的实验表明，YOLO-FDA在各类缺陷和尺度下均优于现有最先进方法，展现出更高的准确性和鲁棒性。

研究结论: YOLO-FDA通过结合细粒度细节增强和注意力机制，有效解决了工业缺陷检测中的关键问题，为实际应用提供了可靠的技术支持。

中文摘要: 工业场景中的表面缺陷检测因其缺陷类型多样、形状和尺寸不规则、细粒度要求高以及材料纹理复杂而至关重要且技术难度大。尽管基于AI的检测器在性能上有所提升，但现有方法常存在特征冗余、细节敏感性不足及多尺度条件下鲁棒性差的问题。为解决这些挑战，我们提出YOLO-FDA，一种基于YOLO的新型检测框架，融合了细粒度细节增强和注意力引导的特征融合。具体而言，我们采用BiFPN架构以增强YOLOv5主干网络中的双向多级特征聚合。为更好地捕捉细微结构变化，我们引入细节定向融合模块（DDFM），在第二低层引入方向性非对称卷积以丰富空间细节，并将第二低层与低层特征融合以增强语义一致性。此外，我们提出两种基于注意力的融合策略：注意力加权拼接（AC）和跨层注意力融合（CAF），以改进上下文表示并减少特征噪声。在多个基准数据集上的广泛实验表明，YOLO-FDA在各类缺陷和尺度下均显著优于现有最先进方法，展现出更高的准确性和鲁棒性。

</details>


### [99] [Tree-based Semantic Losses: Application to Sparsely-supervised Large Multi-class Hyperspectral Segmentation](https://arxiv.org/abs/2506.21150)
**中文标题：基于树结构的语义损失：在稀疏标注的大规模多类高光谱分割中的应用**

*Junwen Wang,Oscar Maccormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren*

主要分类: cs.CV

摘要简述: 本文提出两种基于树结构的语义损失函数，用于稀疏标注的高光谱图像分割任务，通过利用标签的层次结构提升性能，并在实验中达到最先进水平。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱成像（HSI）在手术应用中潜力巨大，但现有学习方法对所有错误同等惩罚，未能利用标签空间的语义层次结构。本文旨在通过引入树状语义损失函数改进稀疏标注下的多类分割任务。

研究方法: 提出两种基于树结构的语义损失函数，结合稀疏标注训练方法，利用标签的层次结构优化模型性能。

研究结果: 实验表明，该方法在包含107个类别的稀疏标注HSI数据集上达到最先进性能，同时有效检测分布外像素而不影响分布内像素的分割效果。

研究结论: 树状语义损失函数显著提升了稀疏标注高光谱图像分割的性能，同时支持分布外像素检测，为临床应用提供了实用工具。

中文摘要: 高光谱成像（HSI）在手术应用中展现出巨大潜力，能够提供肉眼无法察觉的生物组织差异细节。目前正在通过精细标注训练视觉系统以区分大量细微变化的类别。然而，生物医学分割任务中常用的学习方法对所有错误同等惩罚，未能利用标签空间的类间语义。本文引入两种基于树结构的语义损失函数，利用标签的层次结构优化模型。我们进一步将这些损失函数与一种稀疏、无背景标注的训练方法结合。大量实验表明，所提方法在包含107个类别的稀疏标注HSI数据集上达到最先进性能，这些类别按临床定义的语义树结构组织。此外，我们的方法能够有效检测分布外像素，同时不影响分布内像素的分割性能。

</details>


### [100] [Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI with Noisy Labels](https://arxiv.org/abs/2506.21151)
**中文标题：基于噪声标签的心脏MRI心肌瘢痕分割的鲁棒深度学习方法**

*Aida Moafi,Danial Moafi,Evgeny M. Mirkes,Gerry P. McCann,Abbas S. Alatrany,Jayanth R. Arnold,Mostafa Mehdipour Ghazi*

主要分类: cs.CV

摘要简述: 本文提出了一种鲁棒的深度学习流程，用于心脏MRI中心肌瘢痕的自动分割，通过微调最先进的模型并解决标签噪声、数据异质性和类别不平衡问题，显著提升了分割准确性。


<details>
  <summary>详细信息</summary>
研究动机: 心肌瘢痕的准确分割对临床评估和治疗计划至关重要，但现有方法面临标签噪声、数据异质性和类别不平衡的挑战。本研究旨在开发一种鲁棒的深度学习流程，以克服这些问题并实现高精度分割。

研究方法: 通过微调最先进的深度学习模型，结合Kullback-Leibler损失函数和广泛的数据增强技术，解决了标签噪声、数据异质性和类别不平衡问题。

研究结果: 该方法在急性和慢性病例中均表现出色，能够生成准确且平滑的分割结果，优于nnU-Net等先进模型，并在分布外测试集中展现出强泛化能力。

研究结论: 本研究为心肌瘢痕的自动量化提供了可靠基础，并支持深度学习在心脏影像中的广泛应用。

中文摘要: 心脏MRI中心肌瘢痕的准确分割对临床评估和治疗计划至关重要。本研究提出了一种鲁棒的深度学习流程，通过微调最先进的模型实现完全自动化的心肌瘢痕检测与分割。该方法通过使用Kullback-Leibler损失函数和广泛的数据增强技术，明确解决了半自动标注带来的标签噪声、数据异质性和类别不平衡问题。我们在急性和慢性病例中评估了模型的性能，并展示了其在噪声标签下仍能生成准确且平滑分割结果的能力。特别是，我们的方法优于nnU-Net等先进模型，并在分布外测试集中表现出强泛化能力，凸显了其在各种成像条件和临床任务中的鲁棒性。这些结果为心肌瘢痕的自动量化奠定了可靠基础，并支持深度学习在心脏影像中的更广泛应用。

</details>


### [101] [Geometry and Perception Guided Gaussians for Multiview-consistent 3D Generation from a Single Image](https://arxiv.org/abs/2506.21152)
**中文标题：几何与感知引导的高斯模型：从单张图像生成多视角一致的3D对象**

*Pufan Li,Bi'an Du,Wei Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种结合几何和感知先验的新方法，通过多分支高斯模型从单张图像生成多视角一致的3D对象，无需额外训练即可实现高保真重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在从单视图图像生成3D对象时，常面临多视角一致性差和几何细节缺失的问题。本文旨在通过结合几何和感知先验，提升3D生成的质量和一致性。

研究方法: 方法通过三个高斯分支（几何先验、感知先验和高斯噪声）初始化，几何先验捕捉粗略3D形状，感知先验利用预训练的2D扩散模型增强多视角信息。通过几何和感知先验的交互优化，并结合基于重投影的深度一致性策略，实现高保真3D重建。

研究结果: 实验表明，该方法在3D重建和新视角合成任务中优于现有方法，生成结果具有更高的保真度和多视角一致性。

研究结论: 本文提出的方法通过几何和感知先验的无缝结合，实现了从单张图像生成高质量、多视角一致的3D对象，为3D生成任务提供了新的解决方案。

中文摘要: 从单视图图像生成逼真的3D对象需要具备自然外观、3D一致性以及对未见区域的多种合理推断能力。现有方法通常依赖于微调预训练的2D扩散模型或通过快速网络推断或3D高斯泼溅直接生成3D信息，但其结果通常存在多视角一致性差和几何细节不足的问题。为解决这些问题，我们提出了一种新方法，无需额外模型训练即可无缝结合几何和感知先验，从单张图像重建细节丰富的3D对象。具体而言，我们训练了三个不同的高斯分支，分别从几何先验、感知先验和高斯噪声初始化。几何先验捕捉粗略的3D形状，而感知先验利用预训练的2D扩散模型增强多视角信息。随后，通过几何和感知先验的交互优化3D高斯分支，并通过基于重投影的策略增强深度一致性。实验表明，我们的方法在3D重建和新视角合成任务中实现了更高保真度的结果，优于现有方法，展示了鲁棒且一致的3D对象生成能力。

</details>


### [102] [Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition](https://arxiv.org/abs/2506.21165)
**中文标题：面向无监督模拟到现实点云识别的拓扑感知建模**

*Longkun Zou,Kangjun Liu,Ke Chen,Kailing Guo,Kui Jia,Yaowei Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为拓扑感知建模（TAM）的新框架，用于解决点云数据在模拟到现实（Sim2Real）无监督域适应中的挑战。通过利用全局空间拓扑和局部几何特征的拓扑关系，结合自监督学习和自训练策略，显著提升了域适应性能。


<details>
  <summary>详细信息</summary>
研究动机: 由于数据采集方法的差异，3D点云数据的模拟与真实场景之间存在显著的几何变化，导致现有无监督域适应（UDA）方法难以捕捉全局拓扑信息，限制了点分类器的泛化能力。本文旨在解决这一Sim2Real域适应问题。

研究方法: 提出了一种拓扑感知建模（TAM）框架，通过利用低层次高频3D结构的全局空间拓扑，并结合局部几何特征的拓扑关系进行自监督学习。此外，提出了一种结合跨域对比学习和自训练的先进策略，以减少噪声伪标签的影响并增强域适应的鲁棒性。

研究结果: 在三个公开的Sim2Real基准测试上的实验结果表明，TAM框架在所有评估任务中均优于现有最先进方法，验证了其有效性。

研究结论: TAM框架通过拓扑感知建模和自训练策略，显著提升了Sim2Real无监督域适应的性能，为解决点云数据域适应问题提供了有效方案。

中文摘要: 从3D物体形状的点集中学习语义表示通常面临显著的几何变化挑战，这主要源于数据采集方法的差异。通常，训练数据由点模拟器生成，而测试数据则由不同的3D传感器采集，导致模拟到现实（Sim2Real）的域差距，限制了点分类器的泛化能力。现有的无监督域适应（UDA）技术难以应对这一差距，因为它们缺乏能够捕捉全局拓扑信息的鲁棒、域不敏感描述符，导致对源域有限语义模式的过拟合。为解决这一问题，我们提出了一种新颖的拓扑感知建模（TAM）框架，用于对象点云的Sim2Real UDA。我们的方法通过利用低层次高频3D结构的全局空间拓扑，并通过一种新颖的自监督学习任务建模局部几何特征的拓扑关系，缓解了域差距。此外，我们提出了一种结合跨域对比学习和自训练的先进自训练策略，有效减少了噪声伪标签的影响，并增强了适应过程的鲁棒性。在三个公开的Sim2Real基准测试上的实验结果验证了TAM框架的有效性，显示其在所有评估任务中均优于现有最先进方法。本工作的源代码将在https://github.com/zou-longkun/TAG.git上提供。

</details>


### [103] [Task-Aware KV Compression For Cost-Effective Long Video Understanding](https://arxiv.org/abs/2506.21184)
**中文标题：任务感知的KV压缩：一种经济高效的长视频理解方法**

*Minghao Qin,Yan Shu,Peitian Zhang,Kun Lun,Huaying Yuan,Juenjie Zhou,Shitao Xiao,Bo Zhao,Zheng Liu*

主要分类: cs.CV

摘要简述: 本文提出Video-X^2L，通过双级KV压缩和选择性KV重加载，高效保留长视频理解任务中的关键信息，显著降低计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态大语言模型（MLLMs）在长视频理解（LVU）任务中因计算成本过高而受限，传统KV压缩方法在高压缩比下信息损失严重。本文旨在解决这一问题。

研究方法: Video-X^2L采用双级KV压缩（生成低压缩KV和高压缩KV）和选择性KV重加载（解码阶段动态选择KV），无需额外训练且兼容现有MLLMs。

研究结果: 实验表明，Video-X^2L在多个LVU基准测试（如VideoMME、MLVU等）中优于现有KV压缩方法，同时大幅节省计算成本。

研究结论: Video-X^2L是一种简单高效的方法，显著提升了长视频理解的效率，为实际应用提供了可行的解决方案。

中文摘要: 长视频理解（LVU）对现有的多模态大语言模型（MLLMs）仍是一个严峻挑战，主要由于高昂的计算成本。近期研究探索了KV压缩以缓解此问题，但在高压缩比下往往导致显著信息丢失。本文提出Video-X^2L，灵活地为每项LVU任务保留关键视频信息。Video-X^2L包含两项关键操作：一是双级KV压缩，在MLLM的预填充阶段生成两种压缩KV——低压缩KV（L-KVs）用于捕捉细粒度视频细节，高压缩KV（H-KVs）提供紧凑视频表征；二是选择性KV重加载，在解码阶段选择性重加载L-KVs至最关键视频片段，其余部分使用H-KVs，从而充分利用任务特定信息同时保持整体紧凑性。Video-X^2L简单高效：无需额外训练且直接兼容现有支持KV压缩的MLLMs。我们在多个流行LVU基准（如VideoMME、MLVU、LongVideoBench和VNBench）上评估Video-X^2L，实验结果表明其以巨大优势超越现有KV压缩方法，同时显著节省计算成本。

</details>


### [104] [Out-of-Distribution Semantic Occupancy Prediction](https://arxiv.org/abs/2506.21185)
**中文标题：分布外语义占用预测**

*Yuheng Zhang,Mengfei Duan,Kunyu Peng,Yuhang Wang,Ruiping Liu,Fei Teng,Kai Luo,Zhiyong Li,Kailun Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种针对3D语义占用预测中的分布外（OoD）检测方法，通过合成异常数据增强数据集，并开发了OccOoD框架，结合几何与语义融合技术，显著提升了OoD检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D语义占用预测方法主要关注分布内场景，对分布外物体和长尾分布敏感，可能导致未检测到的异常和误判，增加安全隐患。本文旨在解决这一问题。

研究方法: 提出合成异常集成管道（Synthetic Anomaly Integration Pipeline）生成数据集VAA-KITTI和VAA-KITTI-360；开发OccOoD框架，采用基于RWKV的Voxel-BEV渐进融合（VBPF）技术，结合几何与语义信息提升OoD检测。

研究结果: OccOoD在1.2米区域内实现了67.34%的AuROC和29.21%的AuPRCr，达到最先进的OoD检测性能，同时保持竞争力的占用预测表现。

研究结论: 本文提出的OccOoD框架和合成数据集有效提升了3D语义占用预测中的OoD检测能力，为自动驾驶安全提供了重要支持。

中文摘要: 3D语义占用预测对自动驾驶至关重要，提供了密集且语义丰富的环境表示。然而，现有方法主要关注分布内场景，容易受到分布外（OoD）物体和长尾分布的影响，增加了未检测异常和误判的风险，带来安全隐患。为解决这些问题，我们提出了分布外语义占用预测，专注于3D体素空间中的OoD检测。为填补数据空白，我们设计了合成异常集成管道，在保持真实空间和遮挡模式的同时注入合成异常，生成了VAA-KITTI和VAA-KITTI-360两个数据集。我们提出了OccOoD框架，将OoD检测集成到3D语义占用预测中，通过基于RWKV的Voxel-BEV渐进融合（VBPF）分支，利用几何-语义融合增强OoD检测。实验结果表明，OccOoD在1.2米区域内实现了67.34%的AuROC和29.21%的AuPRCr，达到了最先进的OoD检测性能，同时保持了竞争力的占用预测表现。数据集和源代码将在https://github.com/7uHeng/OccOoD公开。

</details>


### [105] [GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding](https://arxiv.org/abs/2506.21188)
**中文标题：GroundFlow：一种用于3D点云序列定位时序推理的插件模块**

*Zijun Lin,Shuting He,Cheston Tan,Bihan Wen*

主要分类: cs.CV

摘要简述: 论文提出GroundFlow模块，用于3D点云序列定位中的时序推理，显著提升现有3D视觉定位方法的任务准确率，并在SG3D基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D视觉定位方法将多步骤文本指令视为整体，未提取各步骤的时序信息，导致无法处理SG3D任务中的代词依赖问题。GroundFlow旨在填补这一空白。

研究方法: GroundFlow是一个插件模块，选择性提取短期和长期步骤信息，结合历史上下文进行时序推理，提升3D点云序列定位的准确性。

研究结果: 在SG3D基准测试中，GroundFlow显著提升基线方法准确率（+7.5%和+10.2%），甚至优于预训练的3D大型语言模型。

研究结论: GroundFlow为现有3D视觉定位模型引入时序推理能力，在SG3D任务中实现了最先进的性能。

中文摘要: 3D点云序列定位（SG3D）是指通过文本指令定位日常活动中详细步骤的对象序列。现有3D视觉定位（3DVG）方法将多步骤文本指令视为整体，未从各步骤提取有用的时序信息。然而，SG3D中的指令常包含代词（如“它”、“这里”、“相同”）以使语言简洁，这要求定位方法理解上下文并从先前步骤检索相关信息以正确定位对象序列。由于缺乏有效的历史信息收集模块，当前3DVG方法在适应SG3D任务时面临挑战。为此，我们提出GroundFlow——一种用于3D点云序列定位时序推理的插件模块。实验表明，GroundFlow显著提升3DVG基线方法在SG3D基准测试中的任务准确率（+7.5%和+10.2%），甚至优于预训练的3D大型语言模型。此外，我们基于当前指令相关性选择性提取短期和长期步骤信息，使GroundFlow能全面审视历史信息并保持时序理解优势。总体而言，我们的工作为现有3DVG模型引入时序推理能力，在SG3D基准测试中实现了最先进的性能。

</details>


### [106] [Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation](https://arxiv.org/abs/2506.21198)
**中文标题：解锁约束：无需源数据的遮挡感知无缝分割**

*Yihong Cao,Jiaming Zhang,Xu Zheng,Hao Shi,Kunyu Peng,Hang Liu,Kailun Yang,Hui Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需源数据的全景图像分割方法UNLOCK，通过Omni伪标签学习和Amodal上下文学习模块，实现了360度视角覆盖和遮挡感知分割，性能接近依赖源数据的方法。


<details>
  <summary>详细信息</summary>
研究动机: 全景图像处理面临失真、遮挡和标注不足等问题，现有无监督域适应方法依赖源数据。本文旨在解决这些问题，提出更实用的无需源数据的任务（SFOASS）及其解决方案。

研究方法: UNLOCK框架包含Omni伪标签学习和Amodal驱动上下文学习两个模块，无需源数据或目标标签即可实现全景分割和遮挡感知推理。

研究结果: 实验表明，该方法在真实到真实和合成到真实的适应设置中表现优异，性能接近依赖源数据的方法，mAAP和mAP分别达到10.9和11.6，mAPQ比仅用源数据方法提升+4.3。

研究结论: UNLOCK为无需源数据的全景分割任务提供了高效解决方案，性能优越且实用性强，代码和数据已公开。

中文摘要: 全景图像处理对全上下文感知至关重要，但面临失真、视角遮挡和标注有限等约束。现有无监督域适应方法将知识从标注的针孔数据迁移到未标注的全景图像，但需要访问源数据。为此，我们提出更实用的任务——无需源数据的遮挡感知无缝分割（SFOASS），并首次提出解决方案UNLOCK。UNLOCK包含Omni伪标签学习和Amodal驱动上下文学习两个模块，无需源数据或目标标签即可实现360度视角覆盖和遮挡感知推理。我们通过真实到真实和合成到真实的适应设置对SFOASS任务进行基准测试。实验结果表明，我们的无需源数据方法性能接近依赖源数据的方法，mAAP和mAP分别达到10.9和11.6，mAPQ比仅用源数据方法提升+4.3。所有数据和代码将在https://github.com/yihong-97/UNLOCK公开。

</details>


### [107] [MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](https://arxiv.org/abs/2506.21199)
**中文标题：MedPrompt：基于权重路由的LLM-CNN融合框架用于医学图像分割与分类**

*Shadman Sobhan,Kazi Abrar Mahmud,Abduz Zami*

主要分类: cs.CV

摘要简述: MedPrompt是一个结合大型语言模型（LLM）和卷积神经网络（CNN）的统一框架，用于医学图像分割和分类，支持用户自定义任务流程，具有高扩展性和实时性。


<details>
  <summary>详细信息</summary>
研究动机: 当前医学图像分析系统通常是任务特定的，需要为分类和分割分别训练模型，缺乏灵活性。MedPrompt旨在通过结合LLM和CNN，提供一种统一且可扩展的解决方案。

研究方法: MedPrompt结合了少量提示的大型语言模型（Llama-4-17B）进行高级任务规划，以及模块化卷积神经网络（DeepFusionLab）进行低级图像处理。LLM解析用户指令并生成结构化输出，动态路由任务特定的预训练权重，避免重新训练整个框架。

研究结果: 在19个公共数据集上评估，MedPrompt在12个任务中表现出色，端到端正确率达到97%，平均推理延迟为2.5秒。DeepFusionLab在分割（如肺部Dice 0.9856）和分类（如结核病F1 0.9744）任务中表现优异。

研究结论: MedPrompt通过结合LLM的可解释性和模块化CNN的高效性，实现了可扩展的、基于提示的医学图像分析，适合近实时应用。

中文摘要: 当前的医学图像分析系统通常是任务特定的，需要为分类和分割分别训练模型，且缺乏支持用户自定义工作流程的灵活性。为解决这些问题，我们提出了MedPrompt，这是一个统一框架，结合了少量提示的大型语言模型（Llama-4-17B）用于高级任务规划，以及模块化卷积神经网络（DeepFusionLab）用于低级图像处理。LLM解析用户指令并生成结构化输出，动态路由任务特定的预训练权重。这种权重路由方法避免了在添加新任务时重新训练整个框架，仅需任务特定的权重，从而提高了可扩展性和部署效率。我们在19个公共数据集上评估了MedPrompt，覆盖了12个任务和5种成像模态。该系统在解析和执行基于提示的指令时达到了97%的端到端正确率，平均推理延迟为2.5秒，适合近实时应用。DeepFusionLab在分割任务（如肺部Dice 0.9856）和分类任务（如结核病F1 0.9744）中表现出色。总体而言，MedPrompt通过结合LLM的可解释性和模块化CNN的高效性，实现了可扩展的、基于提示的医学图像分析。

</details>


### [108] [BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models](https://arxiv.org/abs/2506.21209)
**中文标题：BitMark for Infinity：比特自回归图像生成模型的水印技术**

*Louis Kerner,Michel Meintz,Bihe Zhao,Franziska Boenisch,Adam Dziedzic*

主要分类: cs.CV

摘要简述: 本文提出BitMark，一种针对Infinity图像生成模型的比特级水印框架，旨在防止模型崩溃，通过嵌入不可察觉但可检测的水印来识别生成内容，并具有高放射性。


<details>
  <summary>详细信息</summary>
研究动机: 随着Infinity等文本到图像模型的广泛应用，生成的图像可能被用作训练数据，导致模型崩溃。水印技术可以嵌入不可察觉的信号以识别生成内容，防止性能退化。

研究方法: BitMark在Infinity的图像生成过程中，直接在比特级别嵌入水印，覆盖多尺度（分辨率），保持视觉保真度和生成速度，同时对多种去除技术具有鲁棒性。

研究结果: BitMark不仅能够有效嵌入水印，还具有高放射性，即使用水印图像训练其他模型时，新模型的输出也会携带水印，且水印在微调后仍可检测。

研究结论: BitMark为图像生成模型提供了一种防止模型崩溃的可靠方法，通过水印技术确保生成内容的可检测性。

中文摘要: 先进的文本到图像模型（如Infinity）能够以前所未有的速度生成逼真图像。这些模型以比特自回归方式操作于一个几乎无限大小的离散标记集上。然而，其强大的生成能力伴随着风险：随着其输出在互联网上广泛传播，这些图像可能被爬取并重新用作训练数据，甚至可能被同一模型使用。这种现象已被证明会导致模型崩溃，即重复使用生成内容训练模型（尤其是其早期版本）会导致性能逐渐退化。水印技术是一种潜在的缓解策略，它通过嵌入人类不可察觉但可检测的信号来识别生成内容。本文提出BitMark，一种针对Infinity的鲁棒比特级水印框架。我们的方法在Infinity的图像生成过程中，直接在比特级别嵌入水印，覆盖多尺度（分辨率）。这种比特级水印微妙地影响比特位，以保持视觉保真度和生成速度，同时对多种去除技术具有鲁棒性。此外，它具有高放射性，即当用水印生成图像训练其他图像生成模型时，新模型的输出也会携带水印。即使对扩散或图像自回归模型进行微调，放射性痕迹仍可检测。总体而言，我们的方法为图像生成模型提供了一种防止模型崩溃的原则性步骤，通过可靠检测生成输出来实现。

</details>


### [109] [ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.21233)
**中文标题：ReME：一种数据中心的无训练开词汇分割框架**

*Xiwei Xuan,Ziquan Deng,Kwan-Liu Ma*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ReME的数据中心框架，用于无需训练的开词汇语义分割（OVS），通过构建高质量的参考集和简单的相似性检索，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无需训练OVS方法依赖预训练模型或生成合成数据，性能受限于模型能力或参考集质量。本文发现高质量参考集对提升OVS任务至关重要，因此提出了一种数据中心的设计框架。

研究方法: ReME框架包括一个数据管道，用于构建具有良好配对的片段-文本嵌入的参考集，以及一个基于相似性的简单检索方法，以揭示数据质量对OVS的关键影响。

研究结果: 在十个基准数据集上的广泛评估表明，ReME优于所有现有的无需训练OVS方法，突显了数据中心设计在无需训练情况下提升OVS性能的重要性。

研究结论: 本文通过数据质量优化显著提升了无需训练OVS的性能，证明了数据中心设计在这一任务中的关键作用。

中文摘要: 无需训练的开词汇语义分割（OVS）旨在无需昂贵的模型微调情况下，根据任意文本类别分割图像。现有方法通常探索预训练模型（如CLIP）的注意力机制，或生成合成数据并设计复杂检索流程来实现OVS。然而，其性能受限于依赖模型的能力或参考集的次优质量。本文研究了这一具有挑战性的密集场景理解任务中数据质量问题，并发现高质量参考集能显著提升无需训练OVS的性能。基于这一观察，我们提出了一种以数据质量为中心的框架，包括一个构建具有良好配对片段-文本嵌入参考集的数据管道，以及一个简单的基于相似性的检索方法，以揭示数据的关键作用。值得注意的是，在十个基准数据集上的广泛评估表明，我们的方法优于所有现有的无需训练OVS方法，突显了数据中心设计在无需训练情况下推进OVS的重要性。代码发布于https://github.com/xiweix/ReME。

</details>


### [110] [Real-Time ESFP: Estimating, Smoothing, Filtering, and Pose-Mapping](https://arxiv.org/abs/2506.21234)
**中文标题：实时ESFP：估计、平滑、滤波与姿态映射**

*Qifei Cui,Yuang Zhou,Ruichen Deng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ESFP的端到端流程，能够将单目RGB视频转换为低成本4自由度桌面机械臂的可执行关节轨迹。该方法通过四个模块（估计、平滑、滤波和姿态映射）实现高效且准确的运动生成。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决如何从单目RGB视频中实时生成低成本机械臂的可执行关节轨迹，同时确保运动的平滑性和解剖学合理性。

研究方法: ESFP包含四个模块：1) 估计模块（ROMP）将每帧图像提升为24关节3D骨架；2) 平滑模块（HPSTM）结合长时域上下文和可微分前向运动学解码器，预测关节均值和协方差；3) 滤波模块通过方差加权抑制噪声；4) 姿态映射模块将几何重定向到机械臂的工作空间。

研究结果: 实验表明，ESFP能够高效生成平滑且解剖学合理的关节轨迹，适用于低成本机械臂的实时控制。

研究结论: ESFP为从单目视频到机械臂运动的转换提供了一种高效且可靠的解决方案，具有广泛的应用潜力。

中文摘要: 本文提出了ESFP，一种端到端流程，可将单目RGB视频转换为低成本4自由度桌面机械臂的可执行关节轨迹。ESFP包含四个顺序模块：1) 估计：ROMP将每帧图像提升为24关节3D骨架；2) 平滑：提出的HPSTM（一种具有自注意力的序列到序列Transformer）结合长时域上下文和可微分前向运动学解码器，强制固定骨骼长度和解剖学合理性，同时预测关节均值和完整协方差；3) 滤波：根据HPSTM的不确定性估计对根归一化轨迹进行方差加权，抑制残余噪声；4) 姿态映射：几何重定向层将肩-肘-腕三重映射到uArm的极坐标工作空间，保持手腕方向。

</details>


### [111] [DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation](https://arxiv.org/abs/2506.21237)
**中文标题：DiMPLe——解耦多模态提示学习：通过不变与虚假特征分离增强分布外对齐**

*Umaima Rahman,Mohammad Yaqub,Dwarikanath Mahapatra*

主要分类: cs.CV

摘要简述: DiMPLe是一种新颖的多模态提示学习方法，通过分离视觉和语言模态中的不变特征与虚假特征，提升分布外对齐性能，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 多模态学习中，视觉数据中的虚假相关性常导致分布外性能下降。现有方法仅关注图像特征，未能跨模态分离不变与虚假特征，限制了模型的泛化能力。

研究方法: DiMPLe结合三个关键目标：(1) 最小化不变与虚假特征的互信息，(2) 对虚假特征进行正则化，(3) 在不变特征上应用对比学习，实现跨模态特征分离与对齐。

研究结果: 在11个数据集上的实验表明，DiMPLe在基类和新类准确率上分别提升15.27和44.31，显著优于CoOp-OOD。

研究结论: DiMPLe通过跨模态特征分离与对齐，显著提升了分布外泛化能力，为多模态学习提供了新思路。

中文摘要: 我们提出了DiMPLe（解耦多模态提示学习），一种在多模态学习中分离视觉和语言模态中不变与虚假特征的新方法。视觉数据中的虚假相关性常阻碍分布外性能。与现有方法仅关注图像特征不同，DiMPLe在模态内和跨模态分离特征的同时保持对齐一致性，从而提升对新类别的泛化能力及对分布变化的鲁棒性。我们的方法结合了三个关键目标：(1) 最小化不变与虚假特征的互信息，(2) 对虚假特征进行正则化，(3) 在不变特征上应用对比学习。大量实验表明，DiMPLe在11个数据集上的平均性能优于CoOp-OOD，基类和新类准确率分别提升15.27和44.31。

</details>


### [112] [Temporal Rate Reduction Clustering for Human Motion Segmentation](https://arxiv.org/abs/2506.21249)
**中文标题：基于时间速率降低聚类的人体运动分割方法**

*Xianghan Meng,Zhengyu Tong,Zhiyuan Huang,Chun-Guang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Temporal Rate Reduction Clustering（TR²C）的新方法，用于解决复杂背景下视频中人体运动分割（HMS）的问题。该方法通过联合学习结构化表示和亲和力，显著提升了分割性能，并在多个基准数据集上达到最优效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人体运动分割（HMS）方法主要基于子空间聚类，假设高维时间数据符合子空间联合（UoS）分布。然而，复杂背景下的视频帧可能不符合这一假设，导致性能下降。本文旨在提出一种更有效的方法来解决这一问题。

研究方法: 本文提出的TR²C方法通过联合学习结构化表示和亲和力，确保时间一致性并更好地对齐UoS结构。具体而言，该方法优化了帧序列的分割，使其更适合HMS任务。

研究结果: 在五个基准HMS数据集上的实验表明，TR²C方法在不同特征提取器下均达到了最先进的性能。

研究结论: TR²C方法通过改进结构化表示和亲和力学习，显著提升了复杂背景下人体运动分割的准确性，为HMS任务提供了新的解决方案。

中文摘要: 人体运动分割（HMS）旨在将视频分割为不重叠的人体动作，近年来受到广泛关注。现有的HMS方法主要基于子空间聚类，其假设高维时间数据符合子空间联合（UoS）分布。然而，在复杂背景下捕获的视频帧可能不符合UoS分布。本文提出了一种名为Temporal Rate Reduction Clustering（TR²C）的新方法，通过联合学习结构化表示和亲和力来分割视频帧序列。具体而言，TR²C学习到的结构化表示保持了时间一致性，并更好地对齐UoS结构，从而更适合HMS任务。我们在五个基准HMS数据集上进行了大量实验，结果表明，该方法在不同特征提取器下均达到了最先进的性能。

</details>


### [113] [DuET: Dual Incremental Object Detection via Exemplar-Free Task Arithmetic](https://arxiv.org/abs/2506.21260)
**中文标题：DuET：基于无示例任务算术的双增量目标检测**

*Munish Monga,Vishal Chudasama,Pankaj Wasnik,Biplab Banerjee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DuET的双增量目标检测方法，通过任务算术框架同时处理类别和域的变化，解决了现有方法在类别增量或域增量中的局限性，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的目标检测系统（如自动驾驶和监控）需要持续学习新类别并适应环境变化。现有方法（类别增量目标检测CIOD和域增量目标检测DIOD）仅解决单一问题，CIOD在未知域表现差，DIOD在学习新类别时易遗忘。因此，需要一种同时处理类别和域变化的方法。

研究方法: 提出DuET框架，基于任务算术模型合并，通过方向一致性损失减少符号冲突，支持无示例增量学习。该方法与检测器无关，适用于YOLO11和RT-DETR等实时检测器。

研究结果: 在Pascal Series和Diverse Weather Series上的实验表明，DuET在Pascal Series（4任务）上RAI提升13.12%，平均保留指数（Avg RI）达89.3%；在Diverse Weather Series（3任务）上RAI提升11.39%，Avg RI为88.57%，优于现有方法。

研究结论: DuET通过双增量学习框架有效解决了类别和域变化的挑战，显著提升了检测性能，为实际应用提供了更实用的解决方案。

中文摘要: 现实世界中的目标检测系统（如自动驾驶和监控）需要持续学习新类别并适应环境变化。现有方法（类别增量目标检测CIOD和域增量目标检测DIOD）仅解决单一问题：CIOD在未知域表现差，DIOD在学习新类别时易遗忘。为此，我们提出双增量目标检测（DuIOD），通过无示例方式同时处理类别和域变化。DuET是一种基于任务算术的模型合并框架，通过方向一致性损失减少符号冲突，实现稳定的增量学习。与现有方法不同，DuET与检测器无关，支持YOLO11和RT-DETR等实时检测器。为全面评估保留和适应能力，我们提出保留-适应指数（RAI），结合平均保留指数（Avg RI）和域适应性的平均泛化指数。在Pascal Series和Diverse Weather Series上的实验表明，DuET在Pascal Series（4任务）上RAI提升13.12%，Avg RI为89.3%；在Diverse Weather Series（3任务）上RAI提升11.39%，Avg RI为88.57%，优于现有方法。

</details>


### [114] [Video Virtual Try-on with Conditional Diffusion Transformer Inpainter](https://arxiv.org/abs/2506.21270)
**中文标题：基于条件扩散变换器修复器的视频虚拟试穿**

*Cheng Zou,Senlin Cheng,Bolei Xu,Dandan Zheng,Xiaobo Li,Jingdong Chen,Ming Yang*

主要分类: cs.CV

摘要简述: 本文提出ViTI（视频试穿修复器），将视频虚拟试穿任务重新定义为条件视频修复任务，通过基于扩散变换器的3D时空注意力框架和多阶段训练，显著提升了时空一致性和细节保留能力。


<details>
  <summary>详细信息</summary>
研究动机: 视频虚拟试穿任务面临时空一致性和细节保留的双重挑战。现有基于图像的方法逐帧处理效果不佳，而近期基于扩散的方法虽有所改进，但仍存在不一致问题。本文旨在通过重新定义任务为视频修复问题，从源头提升一致性。

研究方法: 提出ViTI框架，基于扩散变换器构建3D时空注意力视频修复模型，采用多阶段训练和掩码策略逐步适配视频服装修复任务，并通过服装条件确保修复结果符合预期。

研究结果: 实验结果表明，ViTI在时空一致性和细节保留方面优于现有方法，定量和定性评估均显示其优越性。

研究结论: ViTI通过重新定义任务和引入3D时空注意力机制，显著提升了视频虚拟试穿的效果，为未来研究提供了新思路。

中文摘要: 视频虚拟试穿旨在将服装自然地适配到目标人物的连续视频帧中。这是一项具有挑战性的任务，一方面输出视频需要具有良好的时空一致性，另一方面给定服装的细节需在所有帧中保留良好。简单地逐帧使用基于图像的试穿方法会因严重不一致性而效果不佳。近期基于扩散的视频试穿方法虽有所改进，但仍存在不一致问题。本文提出ViTI（视频试穿修复器），将视频虚拟试穿任务重新定义为条件视频修复任务，与之前方法不同。通过这种方式，我们从视频生成问题而非基于图像的试穿问题入手，从一开始就具备更好的时空一致性。具体而言，首先基于扩散变换器构建具有完整3D时空注意力的视频修复框架，然后通过掩码策略和多阶段训练逐步适配视频服装修复任务。最终，模型能够根据提示以良好的时空一致性修复掩码服装区域。与其他试穿方法类似，添加服装条件以确保修复结果符合预期。定量和定性实验结果表明，ViTI优于现有工作。

</details>


### [115] [WordCon: Word-level Typography Control in Scene Text Rendering](https://arxiv.org/abs/2506.21276)
**中文标题：WordCon：场景文本渲染中的词级排版控制**

*Wenda Shi,Yiren Song,Zihan Rao,Dengming Zhang,Jiaming Liu,Xingxing Zou*

主要分类: cs.CV

摘要简述: 本文提出WordCon方法，通过构建词级控制场景文本数据集和文本-图像对齐框架，实现了生成图像中词级排版的精确控制，并采用混合参数高效微调方法提升效率和可移植性。


<details>
  <summary>详细信息</summary>
研究动机: 生成图像中词级排版控制的精确性一直是一个挑战，本文旨在解决这一问题，提升文本到图像模型在词级排版控制上的能力。

研究方法: 本文构建了词级控制的场景文本数据集，提出了文本-图像对齐（TIA）框架，并设计了WordCon方法，通过重新参数化选择性关键参数实现高效微调，同时应用掩码损失和联合注意力损失增强控制能力。

研究结果: 定性和定量实验表明，本文方法在词级排版控制上优于现有技术，能够无缝集成到多种应用场景中。

研究结论: WordCon方法在词级排版控制上表现出色，数据集和源代码将为学术研究提供支持。

中文摘要: 在生成图像中实现精确的词级排版控制一直是一个持续的挑战。为解决这一问题，我们新构建了一个词级控制的场景文本数据集，并引入了文本-图像对齐（TIA）框架。该框架利用基础模型提供的文本与局部图像区域之间的跨模态对应关系，以增强文本到图像（T2I）模型的训练。此外，我们提出了WordCon，一种混合参数高效微调（PEFT）方法。WordCon通过重新参数化选择性关键参数，提高了效率和可移植性，使其能够无缝集成到多种流程中，包括艺术文本渲染、文本编辑和图像条件文本渲染。为进一步增强可控性，我们在潜在层面应用掩码损失，引导模型专注于学习图像中的文本区域，同时联合注意力损失提供特征级监督，促进不同词之间的解耦。定性和定量结果均表明，我们的方法优于现有技术。数据集和源代码将供学术使用。

</details>


### [116] [HieraSurg: Hierarchy-Aware Diffusion Model for Surgical Video Generation](https://arxiv.org/abs/2506.21287)
**中文标题：HieraSurg：层次感知扩散模型用于手术视频生成**

*Diego Biagini,Nassir Navab,Azade Farshad*

主要分类: cs.CV

摘要简述: HieraSurg是一种层次感知扩散模型，用于生成手术视频，通过两阶段模型结合手术阶段和语义分割信息，显著提升视频生成质量和帧率。


<details>
  <summary>详细信息</summary>
研究动机: 现有手术视频生成方法多为无条件生成，缺乏对手术动作和阶段的细粒度一致性，无法满足实际手术模拟的需求。HieraSurg旨在解决这一问题。

研究方法: HieraSurg采用两阶段扩散模型：第一阶段预测粗粒度语义变化，第二阶段结合细粒度视觉特征生成视频，利用手术阶段、动作三元组和全景分割图等多层次信息。

研究结果: 在胆囊切除术视频生成任务中，HieraSurg在定量和定性上均显著优于现有方法，生成更高帧率视频，并在提供分割图时表现出更强的细粒度一致性。

研究结论: HieraSurg通过层次感知设计有效结合手术语义信息，为手术视频生成提供了实用解决方案，具有广泛的应用潜力。

中文摘要: 随着扩散模型在通用视频生成中的成功，手术视频合成成为一个有前景的研究方向。尽管现有方法能生成高质量视频，但大多为无条件生成，无法保持与手术动作和阶段的一致性，缺乏对实际模拟所需的细粒度指导。为此，我们提出HieraSurg，一种层次感知手术视频生成框架，包含两个专用扩散模型。给定手术阶段和初始帧，HieraSurg首先通过分割预测模型预测未来粗粒度语义变化，随后由第二阶段模型将这些时间分割图与细粒度视觉特征结合，生成最终视频。我们的方法利用了手术阶段、动作三元组和全景分割图等多层次抽象信息。在胆囊切除术视频生成任务中的实验结果表明，该模型在定量和定性上均显著优于现有方法，表现出强大的泛化能力和生成更高帧率视频的能力。特别是在提供现有分割图时，模型展现出细粒度一致性，表明其在实际手术应用中的潜力。

</details>


### [117] [Continual Self-Supervised Learning with Masked Autoencoders in Remote Sensing](https://arxiv.org/abs/2506.21312)
**中文标题：基于掩码自编码器的遥感持续自监督学习**

*Lars Möllenbrok,Behnood Rasti,Begüm Demir*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的持续自监督学习方法CoSMAE，通过数据混合和模型混合知识蒸馏，解决了遥感领域中持续学习中的灾难性遗忘问题，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 遥感领域中的持续学习方法通常需要大量标注数据，成本高且难以获取。为了解决这一问题，本文提出了一种自监督学习方法，减少对标注数据的依赖，同时避免灾难性遗忘。

研究方法: CoSMAE包含两个核心组件：1) 数据混合，通过将当前任务图像与之前任务图像插值，保留历史数据分布信息；2) 模型混合知识蒸馏，通过插值历史模型和当前模型的权重形成教师模型，进行知识蒸馏。两者互补，在数据和模型层面正则化MAE，提升泛化能力。

研究结果: 实验结果表明，CoSMAE在MAE上比现有持续学习方法性能提升高达4.94%。

研究结论: CoSMAE通过数据混合和模型混合知识蒸馏，有效减少了灾难性遗忘，提升了持续学习性能，为遥感领域的自监督学习提供了新思路。

中文摘要: 持续学习（CL）方法的发展在遥感（RS）领域引起了广泛关注，其目标是从连续获取的训练数据中顺序学习新任务。现有的RS CL方法在学习新任务时，通过使用大量标注训练样本来增强对灾难性遗忘的鲁棒性，但这成本高昂且难以实现。为解决这一问题，我们提出了一种新型的持续自监督学习方法（称为CoSMAE），基于掩码自编码器（MAE）。CoSMAE包含两个组件：1) 数据混合，通过将当前任务图像与之前任务图像插值，保留历史数据分布信息；2) 模型混合知识蒸馏，通过插值历史模型和当前模型的权重形成教师模型进行知识蒸馏。两者互补，在数据和模型层面正则化MAE，提升跨任务泛化能力并减少灾难性遗忘风险。实验结果表明，CoSMAE在MAE上比现有CL方法性能提升高达4.94%。代码公开于：https://git.tu-berlin.de/rsim/CoSMAE。

</details>


### [118] [DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images](https://arxiv.org/abs/2506.21316)
**中文标题：DrishtiKon：文本丰富文档图像的多粒度视觉定位**

*Badri Vishal Kasuba,Parag Chaudhuri,Ganesh Ramakrishnan*

主要分类: cs.CV

摘要简述: 本文提出DrishtiKon框架，用于多粒度视觉定位，提升文本丰富文档图像的视觉问答系统性能，通过多语言OCR和大语言模型实现高精度定位，并在新基准测试中取得最佳效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前文档智能和视觉问答系统在文本丰富的多语言文档中缺乏精确的视觉定位能力，亟需一种能够增强解释性和信任度的解决方案。

研究方法: 结合多语言OCR、大语言模型和新型区域匹配算法，支持块、行、词和点级别的答案定位，并通过多块和多行推理提升性能。

研究结果: 实验表明，该方法在多个粒度上实现了最先进的定位精度，其中行级粒度在精确度和召回率之间取得了最佳平衡。

研究结论: 研究为现实世界中文本密集型场景下的文档理解系统提供了更鲁棒和可解释的解决方案，并揭示了当前视觉语言模型在精确定位上的局限性。

中文摘要: 文本丰富文档图像中的视觉定位是文档智能和视觉问答（VQA）系统面临的关键但尚未充分探索的挑战。我们提出了DrishtiKon，一种多粒度视觉定位框架，旨在增强复杂多语言文档VQA的解释性和可信度。我们的方法结合了鲁棒的多语言OCR、大语言模型和一种新颖的区域匹配算法，以在块、行、词和点级别上精确定位答案范围。我们从CircularsVQA测试集中整理了一个新的基准，提供了跨多个粒度的人类验证注释。大量实验表明，我们的方法实现了最先进的定位精度，其中行级粒度在精确度和召回率之间取得了最佳平衡。消融研究进一步突出了多块和多行推理的优势。与领先的视觉语言模型的比较评估揭示了当前VLM在精确定位上的局限性，凸显了我们基于结构化对齐方法的有效性。我们的发现为现实世界中文本密集型场景下更鲁棒和可解释的文档理解系统铺平了道路。代码和数据集已在https://github.com/kasuba-badri-vishal/DhrishtiKon上公开。

</details>


### [119] [LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning](https://arxiv.org/abs/2506.21317)
**中文标题：LLaVA-Pose：通过关键点整合的指令微调增强人体姿态与动作理解**

*Dewen Zhang,Tahir Hussain,Wangpeng An,Hayaru Shouno*

主要分类: cs.CV

摘要简述: 本文提出LLaVA-Pose方法，通过整合人体关键点与视觉特征生成专用数据，显著提升视觉语言模型在人体姿态和动作理解任务中的性能，实验结果显示性能提升33.2%。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言模型（VLMs）在通用视觉理解任务中表现良好，但在涉及人体姿态和动作的复杂任务中表现不足，主要原因是缺乏专门的视觉语言指令跟随数据。

研究方法: 通过整合人体关键点与传统视觉特征（如标题和边界框），生成200,328个样本的专用数据集，用于微调模型。同时建立扩展的人体姿态和动作理解基准（E-HPAUB）评估模型性能。

研究结果: 实验结果显示，微调后的LLaVA-Pose模型在基准测试中表现显著优于原始LLaVA-1.5-7B模型，整体性能提升33.2%。

研究结论: 研究表明，整合关键点的数据能有效增强多模态模型在人体中心视觉理解任务中的性能。

中文摘要: 当前的视觉语言模型（VLMs）在通用视觉理解任务中表现良好，但在涉及人体姿态和动作的复杂任务中表现不足，主要原因是缺乏专门的视觉语言指令跟随数据。我们提出了一种方法，通过整合人体关键点与传统视觉特征（如标题和边界框）生成此类数据，从而更精确地理解人体中心场景。我们的方法构建了一个包含200,328个样本的数据集，专门用于微调模型以处理人体中心任务，重点关注对话、详细描述和复杂推理三个领域。我们建立了扩展的人体姿态和动作理解基准（E-HPAUB）以评估模型性能。通过使用该数据集微调LLaVA-1.5-7B模型，并在基准测试中评估生成的LLaVA-Pose模型，取得了显著改进。实验结果显示，与原始LLaVA-1.5-7B模型相比，整体性能提升了33.2%。这些发现突出了关键点整合数据在增强多模态模型对人体中心视觉理解任务中的有效性。代码可在https://github.com/Ody-trek/LLaVA-Pose获取。

</details>


### [120] [Holistic Surgical Phase Recognition with Hierarchical Input Dependent State Space Models](https://arxiv.org/abs/2506.21330)
**中文标题：基于分层输入依赖状态空间模型的全局手术阶段识别**

*Haoyang Wu,Tsun-Hsuan Wang,Mathias Lechner,Ramin Hasani,Jennifer A. Eckhoff,Paul Pak,Ozanan R. Meireles,Guy Rosman,Yutong Ban,Daniela Rus*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的分层输入依赖状态空间模型，用于手术视频的全局分析，解决了传统方法因视频时长过长而效率低下的问题。该方法结合局部和全局动态捕捉，显著提升了手术阶段识别的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 机器人辅助手术中的工作流分析至关重要，但传统方法（如Transformer）因二次注意力机制难以高效处理长时间手术视频。因此，需要一种能够同时捕捉局部和全局动态的模型。

研究方法: 提出了一种分层输入依赖状态空间模型，包含局部聚合状态空间模块和全局关系状态空间模块，结合离散-连续监督策略进行训练。

研究结果: 实验结果表明，该方法在Cholec80、MICCAI2016和Heichole数据集上分别比现有最佳方法提升了2.8%、4.3%和12.9%。

研究结论: 该方法通过分层状态空间模型有效解决了长时间手术视频分析的难题，显著提升了手术阶段识别的性能。

中文摘要: 手术工作流分析在机器人辅助手术中至关重要，但此类手术的长时间特性为全面视频分析带来了巨大挑战。现有方法主要依赖Transformer模型，但其二次注意力机制限制了其对长时间手术视频的高效处理。本文提出了一种新颖的分层输入依赖状态空间模型，利用状态空间模型的线性缩放特性，实现对完整视频的决策，同时捕捉局部和全局动态。我们的框架包含一个时间一致的视觉特征提取器，通过状态空间模型头部传递时间信息。模型由两个关键模块组成：局部聚合状态空间模块，有效捕捉复杂局部动态；全局关系状态空间模块，建模整个视频的时间依赖关系。模型采用混合离散-连续监督策略训练，离散阶段标签和连续阶段进展信号通过网络传播。实验表明，我们的方法在Cholec80、MICCAI2016和Heichole数据集上分别以2.8%、4.3%和12.9%的优势大幅超越现有最佳方法。代码将在论文接受后公开。

</details>


### [121] [PanSt3R: Multi-view Consistent Panoptic Segmentation](https://arxiv.org/abs/2506.21348)
**中文标题：PanSt3R：多视角一致的全景分割**

*Lojze Zust,Yohann Cabon,Juliette Marrie,Leonid Antsfeld,Boris Chidlovskii,Jerome Revaud,Gabriela Csurka*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PanSt3R的统一方法，通过单次前向传播联合预测3D几何和多视角全景分割，避免了现有方法依赖2D分割和测试时优化的不足，实现了高效且可扩展的3D场景分割。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖2D全景分割和测试时优化，未能充分利用多视角空间关系，且计算成本高。本文旨在提出一种更高效、更统一的方法来解决3D场景全景分割问题。

研究方法: PanSt3R基于MUSt3R（一种可扩展的多视角3D重建方法），增加了语义感知和多视角全景分割能力，并改进了掩码合并的后处理流程。此外，还提出了一种基于PanSt3R和3DGS的新视角预测方法。

研究结果: PanSt3R在多个基准测试中达到了最先进的性能，且速度比现有方法快几个数量级。

研究结论: PanSt3R是一种简单、快速且可扩展的方法，能够高效地实现3D场景的多视角全景分割，显著优于现有方法。

中文摘要: 3D场景的全景分割涉及对场景密集3D重建中对象实例的分割和分类，尤其是在仅依赖未标定的2D图像时，这是一个具有挑战性的问题。现有方法通常利用现成模型提取每帧2D全景分割，然后优化隐式几何表示（通常基于NeRF）以整合和融合2D预测。我们认为，依赖2D全景分割来解决本质上为3D和多视角的问题可能不够优化，因为它未能充分利用跨视角的空间关系。此外，这些方法不仅需要相机参数，还需要对每个场景进行计算昂贵的测试时优化。相反，本文提出了一种统一且集成的方法PanSt3R，通过单次前向传播联合预测3D几何和多视角全景分割，从而避免了测试时优化。我们的方法基于3D重建的最新进展，特别是MUSt3R（一种可扩展的多视角DUSt3R版本），并通过语义感知和多视角全景分割能力对其进行了增强。我们还重新审视了标准的后处理掩码合并流程，并引入了一种更原则性的多视角分割方法。此外，我们还提出了一种基于PanSt3R和普通3DGS的新视角预测方法。总体而言，PanSt3R概念简单，但快速且可扩展，在多个基准测试中达到了最先进的性能，同时比现有方法快几个数量级。

</details>


### [122] [Generalizable Neural Electromagnetic Inverse Scattering](https://arxiv.org/abs/2506.21349)
**中文标题：通用神经电磁逆散射方法**

*Yizhe Cheng,Chunxun Tian,Haoru Wang,Wentao Zhu,Xiaoxuan Ma,Yizhou Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于物理驱动的通用框架，用于解决电磁逆散射问题（EISP），通过引入感应电流作为中间表示，将非线性散射过程与病态逆问题解耦，显著提升了重建精度、泛化能力和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 电磁逆散射问题（EISP）在医学成像等领域具有重要应用，但其固有的病态性和高度非线性使其极具挑战性。现有方法如Img-Interiors虽取得一定成果，但存在泛化能力不足、依赖特定优化及稀疏发射器条件下性能下降等问题。本文旨在通过物理驱动的视角重新设计EISP解决方案。

研究方法: 本文提出了一种两阶段逆传输-散射过程框架，将EISP问题重新建模为感应电流估计和相对介电常数求解两个部分。具体包括一个感应电流估计器和一个介电常数求解器，二者以端到端方式协同工作。感应电流估计器显式学习入射场与散射场之间的物理桥梁，而介电常数求解器则直接从估计的感应电流计算相对介电常数。

研究结果: 实验表明，该方法在重建精度、泛化能力和鲁棒性方面均优于现有技术，尤其在稀疏发射器条件下表现突出。

研究结论: 本文通过物理驱动的框架为电磁逆散射问题提供了全新的解决视角，显著提升了性能，并为电磁成像的实际应用迈出了重要一步。

中文摘要: 电磁逆散射问题（EISP）的解决在医学成像等应用中至关重要，其目标是从散射电磁场中重建相对介电常数。这一逆过程具有固有的病态性和高度非线性，极具挑战性。近期基于机器学习的方法Img-Interiors通过利用连续隐函数取得了一定成果，但其需要针对特定案例优化，泛化能力不足，且在稀疏发射器（如仅有一个发射器）条件下失效。为解决这些问题，我们从物理驱动的视角重新审视EISP，将其重新建模为一个两阶段的逆传输-散射过程。这一建模揭示了感应电流作为一种可泛化的中间表示，有效解耦了非线性散射过程与病态逆问题。基于这一发现，我们提出了首个物理驱动的通用EISP框架，包含一个电流估计器和一个介电常数求解器，以端到端方式工作。电流估计器显式学习入射场与散射场之间的物理桥梁——感应电流，而介电常数求解器则直接从估计的感应电流计算相对介电常数。这一设计支持数据驱动的训练，并能在未见数据上进行泛化的前馈预测，同时对发射器稀疏性保持强鲁棒性。大量实验表明，我们的方法在重建精度、泛化能力和鲁棒性方面均优于现有技术。这项工作为电磁逆散射问题提供了全新的视角，并为电磁成像的实际应用迈出了重要一步。

</details>


### [123] [ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models](https://arxiv.org/abs/2506.21356)
**中文标题：ShotBench：视觉语言模型中的专家级电影语言理解**

*Hongbo Liu,Jingwen He,Yi Jin,Dian Zheng,Yuhao Dong,Fan Zhang,Ziqi Huang,Yinan He,Yangguang Li,Weichao Chen,Yu Qiao,Wanli Ouyang,Shengjie Zhao,Ziwei Liu*

主要分类: cs.CV

摘要简述: ShotBench是一个专为电影语言理解设计的综合基准测试，揭示了当前视觉语言模型在理解电影镜头细微语法方面的局限性，并提出新模型ShotVL，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 电影摄影是电影的基本视觉语言，但现有视觉语言模型对电影镜头的细微语法理解不足，缺乏有效评估。这一局限影响了AI辅助视频生成的精确性。

研究方法: 研究团队构建了ShotBench基准测试，包含3.5k专家标注的QA对，涵盖8个关键电影摄影维度。随后开发了ShotQA数据集（70k QA对），并通过监督微调和Group Relative Policy Optimization训练出ShotVL模型。

研究结果: 评估24个领先视觉语言模型后发现，即使表现最佳的模型平均准确率也低于60%。ShotVL显著优于所有现有开源和专有模型，实现了新的最优性能。

研究结论: ShotBench填补了电影语言理解评估的空白，ShotVL模型的成功为AI驱动的电影理解和生成领域提供了重要工具。研究团队开源了模型、数据和代码以促进进一步发展。

中文摘要: 电影摄影是电影的基本视觉语言，用于传达叙事、情感和美学质量。尽管当前视觉语言模型（VLMs）展现出强大的通用视觉理解能力，但它们对单个镜头中嵌入的细微电影语法的理解能力仍未充分探索且缺乏稳健评估。这一关键空白限制了细粒度视觉理解和AI辅助视频生成的精确性。为此，我们推出了ShotBench，一个专为电影语言理解设计的综合基准测试。它包含超过3.5k专家标注的QA对，来自200多部备受赞誉（主要是奥斯卡提名）的电影，涵盖8个关键电影摄影维度。我们对24个领先VLMs的评估揭示了它们的显著局限性：即使表现最佳的模型平均准确率也低于60%，尤其在细粒度视觉线索和复杂空间推理方面表现不佳。为推动该领域的发展，我们构建了ShotQA，一个包含约70k电影QA对的大规模多模态数据集。利用ShotQA，我们通过监督微调和Group Relative Policy Optimization开发了ShotVL。ShotVL在ShotBench上显著优于所有现有开源和专有模型，确立了新的最优性能。我们开源了模型、数据和代码，以促进AI驱动的电影理解和生成这一关键领域的快速发展。

</details>


### [124] [CoPa-SG: Dense Scene Graphs with Parametric and Proto-Relations](https://arxiv.org/abs/2506.21357)
**中文标题：CoPa-SG：基于参数化与原型关系的密集场景图**

*Julian Lorenz,Mrunmai Phatak,Robin Schön,Katja Ludwig,Nico Hörmann,Annemarie Friedrich,Rainer Lienhart*

主要分类: cs.CV

摘要简述: 本文提出了CoPa-SG数据集，解决了现有场景图数据不足的问题，并引入了参数化关系和原型关系两种新概念，提升了场景图的精细度和应用潜力。


<details>
  <summary>详细信息</summary>
研究动机: 当前场景图研究面临数据不足和关系标注不精确的问题，限制了场景理解的发展。本文旨在通过合成数据集和新关系类型解决这些问题。

研究方法: 提出CoPa-SG合成数据集，包含高精度标注和详尽的对象间关系；引入参数化关系（如角度、距离）和原型关系（描述假设关系），并验证其在场景图生成模型中的应用。

研究结果: 实验表明，CoPa-SG数据集能够显著提升场景图生成模型的性能，新关系类型增强了规划与推理能力。

研究结论: CoPa-SG为场景图研究提供了高质量数据和新关系类型，推动了场景理解的进一步发展。

中文摘要: 二维场景图为场景理解提供了结构化和可解释的框架。然而，当前研究仍受限于缺乏精确的场景图数据。为解决这一数据瓶颈，我们提出了CoPa-SG，一个包含高精度标注和所有对象间详尽关系注释的合成场景图数据集。此外，我们引入了参数化关系和原型关系这两种场景图的新基础概念。前者通过为关系附加角度或距离等参数，提供了比传统关系更精细的表示；后者编码了场景图中的假设关系，描述了如果新对象被放置在场景中时关系将如何形成。利用CoPa-SG，我们比较了多种场景图生成模型的性能，并展示了如何将新关系类型集成到下游应用中，以增强规划与推理能力。

</details>


### [125] [ToosiCubix: Monocular 3D Cuboid Labeling via Vehicle Part Annotations](https://arxiv.org/abs/2506.21358)
**中文标题：ToosiCubix：基于车辆部件标注的单目3D立方体标注方法**

*Behrooz Nasihatkon,Hossein Resani,Amirreza Mehrzadian*

主要分类: cs.CV

摘要简述: ToosiCubix是一种仅需单目图像和相机内参的3D立方体标注方法，通过用户少量点击和几何优化，实现高效且低成本的车辆3D标注。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D立方体标注方法依赖昂贵的多传感器设备，限制了大规模数据标注的可行性。ToosiCubix旨在提供一种仅需单目图像的低成本解决方案。

研究方法: 通过标注车辆特定部件（如车轮、车标等），结合几何约束和优化问题（PnP与最小二乘交替求解），并引入概率尺寸先验，实现9自由度的立方体标注。

研究结果: 在KITTI和Cityscapes3D数据集上验证，ToosiCubix的标注质量高，且成本低、可扩展性强。

研究结论: ToosiCubix为高质量3D立方体标注提供了一种低成本、易扩展的解决方案，适用于大规模数据标注任务。

中文摘要: 现有许多车辆3D立方体标注方法依赖昂贵且需精确校准的相机-LiDAR或立体设备，限制了其在大规模数据收集中的可用性。我们提出了ToosiCubix，一种仅需单目图像和相机内参的简单而强大的地面真实立方体标注方法。该方法每辆车仅需约10次用户点击，非常适合为原本未使用专用设备收集的现有数据集添加3D标注。通过标注车辆不同部件的特定特征（如车轮、车标、对称性等），我们能够准确估计每辆车的位置、方向和尺寸（存在尺度模糊性，8自由度）。几何约束被表述为一个优化问题，我们采用坐标下降策略交替求解透视n点（PnP）和最小二乘子问题。为处理常见的模糊性问题（如尺度和未观测维度），我们引入了概率尺寸先验，实现9自由度的立方体放置。我们在KITTI和Cityscapes3D数据集上验证了标注结果，表明该方法为高质量3D立方体标注提供了一种经济高效且可扩展的解决方案。

</details>


### [126] [CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection](https://arxiv.org/abs/2506.21364)
**中文标题：CA-I2P：基于全局最优选择的通道自适应配准网络**

*Zhixin Cheng,Jiacheng Deng,Xinjun Li,Xiaotian Yin,Bohao Liao,Baoqun Yin,Wenfei Yang,Tianzhu Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于通道自适应调整模块（CAA）和全局最优选择模块（GOS）的图像到点云配准方法，解决了特征通道注意力差异和冗余对应问题，显著提升了配准精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有检测无关方法在图像和点云特征匹配中，由于特征通道注意力差异和场景中相似结构导致的冗余对应问题，影响了配准精度。本文旨在解决这些问题。

研究方法: 提出通道自适应调整模块（CAA）增强模态内特征并抑制跨模态敏感性，同时引入全局最优选择模块（GOS）替代局部选择，实现全局优化。

研究结果: 在RGB-D Scenes V2和7-Scenes数据集上的实验表明，该方法在图像到点云配准任务中达到了最先进的性能。

研究结论: 通过CAA和GOS模块的结合，本文方法有效解决了跨模态匹配中的特征差异和冗余问题，显著提升了配准精度。

中文摘要: 检测无关方法通常遵循从粗到精的流程，提取图像和点云特征进行块级匹配并细化密集像素到点的对应关系。然而，图像和点云之间特征通道注意力的差异可能导致匹配结果退化，最终影响配准精度。此外，场景中的相似结构可能导致跨模态匹配中的冗余对应。为解决这些问题，我们提出了通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA增强模态内特征并抑制跨模态敏感性，而GOS用全局优化替代局部选择。在RGB-D Scenes V2和7-Scenes上的实验证明了我们方法的优越性，实现了图像到点云配准的最先进性能。

</details>


### [127] [GenFlow: Interactive Modular System for Image Generation](https://arxiv.org/abs/2506.21369)
**中文标题：GenFlow：用于图像生成的交互式模块化系统**

*Duc-Hung Nguyen,Huu-Phuc Huynh,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: GenFlow是一个创新的模块化框架，通过节点编辑器和自然语言处理助手，简化了生成艺术的复杂性，使其对用户更友好。


<details>
  <summary>详细信息</summary>
研究动机: 生成艺术虽然具有无限的创意潜力，但由于需要高级架构概念和计算工作流的技术知识，其潜力未被充分挖掘。GenFlow旨在降低技术门槛，让所有技能水平的用户都能轻松生成图像。

研究方法: GenFlow采用模块化框架，提供基于节点的编辑器用于自定义工作流，并结合自然语言处理智能助手，简化了生成艺术的复杂性。

研究结果: 用户研究表明，GenFlow能够优化工作流、缩短任务完成时间，并通过直观界面和自适应功能提升用户理解。

研究结论: GenFlow通过降低技术门槛和提升效率，重新定义了生成艺术的可访问性和效率，成为一项突破性解决方案。

中文摘要: 生成艺术释放了无限的创意可能性，但由于需要掌握高级架构概念和计算工作流的技术知识，其潜力尚未完全发挥。为了填补这一空白，我们提出了GenFlow，这是一个新颖的模块化框架，使所有技能水平的用户都能轻松精确地生成图像。GenFlow配备了基于节点的编辑器以实现无缝定制，以及由自然语言处理驱动的智能助手，将复杂的工作流创建转化为直观且易于上手的体验。通过自动化部署流程和最小化技术障碍，我们的框架使前沿的生成艺术工具对所有人开放。一项用户研究表明，GenFlow能够优化工作流、缩短任务完成时间，并通过其直观界面和自适应功能提升用户理解。这些结果使GenFlow成为一项突破性解决方案，重新定义了生成艺术领域的可访问性和效率。

</details>


### [128] [FastRef:Fast Prototype Refinement for Few-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.21398)
**中文标题：FastRef：少样本工业异常检测的快速原型细化**

*Long Tian,Yufei Li,Yuyang Dai,Wenchao Chen,Xiyang Liu,Bo Chen*

主要分类: cs.CV

摘要简述: FastRef是一种高效的原型细化框架，用于解决少样本工业异常检测（FS-IAD）中原型代表性问题。通过特征转移和异常抑制两阶段迭代优化，显著提升了检测效果和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有少样本工业异常检测方法主要依赖有限正常样本生成原型，但忽略了查询图像统计信息对原型代表性的提升作用。FastRef旨在通过系统性整合查询特征优化原型，解决这一问题。

研究方法: FastRef采用两阶段迭代优化：1) 通过可优化变换矩阵将查询特征转移至原型；2) 通过原型对齐抑制异常。特征转移通过线性重构实现，异常抑制则利用最优传输（OT）技术减少原型与细化后原型的差距。

研究结果: FastRef在MVTec、ViSA、MPDD和RealIAD四个基准数据集上验证了其有效性，与PatchCore、FastRecon、WinCLIP和AnomalyDINO等方法结合后，在1/2/4-shot设置下均表现出优越性能。

研究结论: FastRef通过高效原型细化显著提升了少样本工业异常检测的性能，为数据稀缺环境下的自动化检测提供了实用解决方案。

中文摘要: 少样本工业异常检测（FS-IAD）是数据稀缺环境下自动化检测系统的关键挑战。现有方法主要从有限正常样本中提取原型，但通常未系统性利用查询图像统计信息提升原型代表性。为此，我们提出FastRef，一种高效的原型细化框架。该方法通过两阶段迭代过程实现：1) 通过可优化变换矩阵将查询特征转移至原型；2) 通过原型对齐抑制异常。特征转移通过原型线性重构查询特征实现，异常抑制则基于FS-IAD中异常重构概率更高的观察，采用最优传输（OT）技术减少原型与细化原型的差距。为全面评估，我们将FastRef与三种原型方法（PatchCore、FastRecon、WinCLIP和AnomalyDINO）结合。在MVTec、ViSA、MPDD和RealIAD四个数据集上的实验表明，FastRef在1/2/4-shot设置下兼具高效性和有效性。

</details>


### [129] [Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction](https://arxiv.org/abs/2506.21401)
**中文标题：面向3D参数曲线重建的曲线感知高斯泼溅方法**

*Zhirui Gao. Renjiao Yi,Yaqiao Dai,Xuening Zhu,Wei Chen,Chenyang Zhu,Kai Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种端到端框架，直接从多视角边缘图中重建3D参数曲线，避免了传统两阶段方法中的误差累积问题。通过引入曲线感知的高斯表示和动态拓扑优化，实现了高效且鲁棒的曲线重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有的两阶段方法（先重建边缘点云再拟合参数曲线）存在误差累积问题，且参数曲线不适合基于渲染的多视角优化。本文旨在提出一种直接优化参数曲线的方法，解决这些问题。

研究方法: 提出了一种双向耦合机制，将参数曲线与边缘导向的高斯组件结合，形成曲线感知的高斯表示（CurveGaussian），支持可微渲染。同时，引入动态自适应拓扑优化框架，通过线性化、合并、分割和修剪操作优化曲线结构。

研究结果: 在ABC数据集和真实场景基准测试中，本文方法优于两阶段方法，实现了更干净、更鲁棒的重建效果，同时显著减少了训练参数数量，提高了效率和性能。

研究结论: 本文提出的单阶段方法通过直接优化参数曲线，避免了误差累积，提升了重建质量和效率，为3D曲线重建提供了一种新的解决方案。

中文摘要: 本文提出了一种端到端框架，用于直接从多视角边缘图中重建3D参数曲线。与现有的两阶段方法（先重建边缘点云再拟合参数曲线）不同，我们的单阶段方法直接从2D边缘图优化3D参数曲线，避免了阶段间优化差距导致的误差累积。然而，参数曲线本身不适合基于渲染的多视角优化，因此需要一种互补表示，既能保留其几何特性，又能支持可微渲染。我们提出了一种参数曲线与边缘导向高斯组件之间的双向耦合机制，形成了一种曲线感知的高斯表示（CurveGaussian），实现了3D曲线的可微渲染，从而支持基于多视角证据的直接优化。此外，我们在训练过程中引入了一种动态自适应拓扑优化框架，通过线性化、合并、分割和修剪操作优化曲线结构。在ABC数据集和真实场景基准测试中的全面评估表明，我们的单阶段方法优于两阶段方法，尤其是在生成更干净、更鲁棒的重建结果方面。此外，通过直接优化参数曲线，我们的方法显著减少了训练参数数量，在效率和性能上均优于现有方法。

</details>


### [130] [XVerse: Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation](https://arxiv.org/abs/2506.21416)
**中文标题：XVerse：通过DiT调制实现身份与语义属性的多主体一致性控制**

*Bowen Chen,Mengyi Zhao,Haomiao Sun,Li Chen,Xu Wang,Kang Du,Xinglong Wu*

主要分类: cs.CV

摘要简述: XVerse提出了一种通过DiT调制实现多主体身份和语义属性精确控制的新方法，解决了现有文本到图像生成中的编辑性和一致性难题。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在多主体控制中常导致编辑性下降和属性纠缠，XVerse旨在解决这些问题，实现高保真、可编辑的多主体图像合成。

研究方法: XVerse将参考图像转化为偏移量，用于特定文本流的调制，从而在不干扰图像潜在特征的情况下，实现对特定主体的精确独立控制。

研究结果: XVerse在多主体图像合成中表现出色，能够高保真地控制每个主体的身份和语义属性，显著提升了复杂场景的生成能力。

研究结论: XVerse通过创新的调制方法，显著提升了多主体图像生成的精确性和编辑性，为个性化复杂场景生成提供了新工具。

中文摘要: 在文本到图像生成中，尤其是多主体场景下，对主体身份和语义属性（如姿势、风格、光照）的精细控制往往会破坏扩散变换器（DiT）的编辑性和一致性。现有方法常引入伪影或面临属性纠缠问题。为解决这些挑战，我们提出了一种新型多主体控制生成模型XVerse。通过将参考图像转化为特定文本流调制的偏移量，XVerse能够在不干扰图像潜在特征的情况下，实现对特定主体的精确独立控制。因此，XVerse提供了高保真、可编辑的多主体图像合成能力，并能够稳健地控制每个主体的特征和语义属性。这一进展显著提升了个性化和复杂场景的生成能力。

</details>


### [131] [EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian Splatting](https://arxiv.org/abs/2506.21420)
**中文标题：EndoFlow-SLAM：基于光流约束高斯泼溅的实时内窥镜SLAM**

*Taoyu Wu,Yiyi Miao,Zhuoxiao Li,Haocheng Zhao,Kang Dang,Jionglong Su,Limin Yu,Haoang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为EndoFlow-SLAM的实时内窥镜SLAM方法，通过引入光流损失作为几何约束，并结合深度正则化策略，解决了内窥镜场景中的光度不一致性和动态运动问题，显著提升了3D重建和相机姿态估计的性能。


<details>
  <summary>详细信息</summary>
研究动机: 内窥镜手术场景中，非朗伯表面引起的光度不一致性和呼吸导致的动态运动对SLAM系统的性能提出了挑战。现有的3D高斯泼溅（3DGS）SLAM方法仅依赖外观约束，难以应对这些问题。

研究方法: 1. 引入光流损失作为几何约束，优化3D场景结构和相机运动；2. 提出深度正则化策略，解决光度不一致性问题；3. 改进3DGS细化策略，专注于渲染质量较差的帧，提升场景表示。

研究结果: 在C3VD静态数据集和StereoMIS动态数据集上的实验表明，该方法在新型视图合成和姿态估计方面优于现有最先进方法，在静态和动态手术场景中均表现优异。

研究结论: EndoFlow-SLAM通过光流约束和深度正则化策略，有效解决了内窥镜SLAM中的关键问题，为实时3D重建和可视化提供了高效解决方案。

中文摘要: 高效的三维重建和实时可视化在内窥镜等手术场景中至关重要。近年来，3D高斯泼溅（3DGS）在高效3D重建和渲染中表现出色。大多数基于3DGS的同步定位与地图构建（SLAM）方法仅依赖外观约束优化3DGS和相机姿态。然而，内窥镜场景中的非朗伯表面引起的光度不一致性和呼吸导致的动态运动影响了SLAM系统的性能。为解决这些问题，我们额外引入了光流损失作为几何约束，有效约束了场景的3D结构和相机运动。此外，我们提出了一种深度正则化策略，以缓解光度不一致性问题，并确保3DGS深度渲染在内窥镜场景中的有效性。同时，为提升SLAM系统的场景表示能力，我们改进了3DGS细化策略，专注于渲染质量较差的帧，从而获得更好的渲染效果。在C3VD静态数据集和StereoMIS动态数据集上的大量实验表明，我们的方法在新型视图合成和姿态估计方面优于现有最先进方法，在静态和动态手术场景中均表现出色。源代码将在论文接受后公开。

</details>


### [132] [HyperSORT: Self-Organising Robust Training with hyper-networks](https://arxiv.org/abs/2506.21430)
**中文标题：HyperSORT：基于超网络的自组织鲁棒训练方法**

*Samuel Joutard,Marijn Stollenga,Marc Balle Sanchez,Mohammad Farid Azampour,Raphael Prevost*

主要分类: cs.CV

摘要简述: HyperSORT是一种利用超网络预测UNet参数的框架，通过潜在向量表示图像和标注的变异性，联合学习超网络参数和训练数据的潜在向量集合，从而识别和应对医学影像数据集中的异质性偏差。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像数据集中常存在异质性偏差（如错误标签或不一致的标注风格），这些偏差会严重影响深度分割网络的性能。然而，识别和表征这些偏差是一项繁琐且具有挑战性的任务。

研究方法: HyperSORT通过超网络预测UNet的参数，这些参数由表示图像和标注变异性的潜在向量生成。超网络参数和每个训练样本的潜在向量集合被联合学习，从而学习UNet参数的复杂分布，低密度区域捕捉噪声模式，而高密度区域则以稳健方式分割器官。

研究结果: 在AMOS数据集（合成扰动版本）和TotalSegmentator数据集（包含真实未知偏差）上的实验表明，HyperSORT能够结构化映射数据集，识别系统性偏差和错误样本。潜在空间聚类生成的UNet参数能够根据学习到的系统性偏差完成分割任务。

研究结论: HyperSORT提供了一种有效的方法来应对医学影像数据集中的异质性偏差，并通过潜在空间的结构化映射识别偏差和错误样本，为分割任务提供了稳健的解决方案。

中文摘要: 医学影像数据集通常包含从错误标签到不一致标注风格的异质性偏差，这些偏差会严重影响深度分割网络的性能。然而，识别和表征这些偏差是一项特别繁琐且具有挑战性的任务。本文提出HyperSORT，这是一种利用超网络预测UNet参数的框架，这些参数由表示图像和标注变异性的潜在向量生成。超网络参数和每个训练样本的潜在向量集合被联合学习。因此，HyperSORT不是优化单一神经网络以拟合数据集，而是学习UNet参数的复杂分布，其中低密度区域可以捕捉噪声特定模式，而较大模式则以稳健且有意义的方式分割器官。我们在两个3D腹部CT公共数据集上验证了该方法：首先是AMOS数据集的合成扰动版本，其次是TotalSegmentator数据集，该数据集包含真实的未知偏差和错误。实验表明，HyperSORT能够结构化映射数据集，识别相关系统性偏差和错误样本。潜在空间聚类生成的UNet参数能够根据学习到的系统性偏差完成分割任务。代码及对TotalSegmentator数据集的分析已公开：https://github.com/ImFusionGmbH/HyperSORT

</details>


### [133] [Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation](https://arxiv.org/abs/2506.21444)
**中文标题：基于跨数据集评估的深度学习与视觉基础模型在非典型与正常有丝分裂分类中的基准测试**

*Sweta Banerjee,Viktoria Weiss,Taryn A. Donovan,Rutger A. Fick,Thomas Conrad,Jonas Ammeling,Nils Porsche,Robert Klopfleisch,Christopher Kaltenecker,Katharina Breininger,Marc Aubreville,Christof A. Bertram*

主要分类: cs.CV

摘要简述: 本研究通过深度学习模型对乳腺癌中的非典型有丝分裂进行分类，比较了基础模型、线性探测和低秩适应（LoRA）等方法，并在多个数据集上验证了效果。结果表明，LoRA优化的Virchow基础模型表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 非典型有丝分裂是肿瘤恶性程度的重要标志，但其识别因低发生率、形态差异细微、病理学家间一致性低以及数据集类别不平衡而具有挑战性。本研究旨在通过深度学习技术解决这一问题。

研究方法: 研究使用了乳腺癌非典型有丝分裂数据集（AMi-Br），并引入了两个新数据集AtNorM-Br和AtNorM-MD。比较了基线模型、线性探测的基础模型和LoRA优化的基础模型。

研究结果: 在AMi-Br、AtNorM-Br和AtNorM-MD数据集上，LoRA优化的Virchow基础模型分别达到0.8135、0.7696和0.7705的平衡准确率，表现最佳。

研究结论: 研究表明，尽管非典型有丝分裂分类具有挑战性，但通过迁移学习和模型微调技术可以有效解决。所有代码和数据已公开。

中文摘要: 非典型有丝分裂标志着细胞分裂过程中的异常，可作为肿瘤恶性程度的独立预后标志。然而，由于其低发生率、与正常有丝分裂的形态差异细微、病理学家间一致性低以及数据集类别不平衡，其识别仍具挑战性。基于乳腺癌非典型有丝分裂数据集（AMi-Br），本研究全面比较了自动化非典型有丝分裂分类的深度学习方法，包括基线模型、线性探测的基础模型和低秩适应（LoRA）优化的基础模型。为严格评估，我们还引入了两个新的保留数据集AtNorM-Br（来自TCGA乳腺癌队列）和AtNorM-MD（来自MIDOG++训练集的多领域数据集）。结果表明，在AMi-Br、AtNorM-Br和AtNorM-MD数据集上，LoRA优化的Virchow基础模型分别达到0.8135、0.7696和0.7705的平均平衡准确率，表现尤为突出。我们的工作表明，尽管非典型有丝分裂分类具有挑战性，但通过迁移学习和模型微调技术可以有效解决。所有代码和数据已在GitHub仓库公开：https://github.com/DeepMicroscopy/AMi-Br_Benchmark。

</details>


### [134] [Controllable 3D Placement of Objects with Scene-Aware Diffusion Models](https://arxiv.org/abs/2506.21446)
**中文标题：基于场景感知扩散模型的可控3D物体放置**

*Mohamed Omran,Dimitris Kalatzis,Jens Petersen,Amirhossein Habibian,Auke Wiggers*

主要分类: cs.CV

摘要简述: 本文提出了一种基于场景感知扩散模型的可控3D物体放置方法，通过精心设计的视觉地图和粗略物体掩码实现高质量物体放置，同时保留背景完整性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于文本条件的生成模型在图像编辑中表现强大，但精确控制物体在场景中的位置和方向仍具挑战性。本文旨在解决这一问题，提供更灵活和准确的物体放置方案。

研究方法: 研究设计了一种条件信号，结合视觉地图和粗略物体掩码，消除歧义并支持形状和方向调整。基于修复模型，确保背景不受干扰。

研究结果: 在汽车场景的实验中，该方法在物体放置任务中表现出色，不仅外观逼真，还能精确控制姿态和位置，甚至支持非平凡的形状变化。

研究结论: 该方法通过结合位置和外观控制，实现了现有物体在场景中的精确放置，为图像编辑提供了更灵活的工具。

中文摘要: 随着强大的文本条件生成模型的出现，图像编辑方法变得更加强大和灵活。然而，在环境中以精确的位置和方向放置物体仍然是一个挑战，因为这通常需要精心设计的修复掩码或提示。在这项工作中，我们表明，精心设计的视觉地图结合粗略的物体掩码足以实现高质量的物体放置。我们设计了一种条件信号，既能消除歧义，又足够灵活以支持形状或物体方向的调整。通过基于修复模型的设计，我们保留了背景的完整性，与那些将物体和背景联合建模的方法形成对比。我们在汽车场景中展示了该方法的有效性，比较了不同条件信号在新型物体放置任务中的表现。这些任务不仅衡量外观的编辑质量，还衡量姿态和位置的准确性，包括需要非平凡形状变化的情况。最后，我们展示了精细的位置控制可以与外观控制结合，将现有物体精确放置在场景中。

</details>


### [135] [A Comprehensive Dataset for Underground Miner Detection in Diverse Scenario](https://arxiv.org/abs/2506.21451)
**中文标题：面向多样化场景的地下矿工检测综合数据集**

*Cyrus Addy,Ajay Kumar Gurumadaiah,Yixiang Gao,Kwame Awuah-Offei*

主要分类: cs.CV

摘要简述: 本文提出了一种专门用于地下矿工检测的热成像数据集，填补了该领域训练数据的空白，并评估了多种先进目标检测算法的性能，为未来应急应用奠定了基础。


<details>
  <summary>详细信息</summary>
研究动机: 地下采矿作业面临重大安全挑战，需要可靠的矿工检测技术以提升应急响应能力。目前缺乏适用于地下环境的热成像数据集，限制了深度学习算法在矿工检测中的应用。

研究方法: 通过系统采集多种采矿活动和场景的热成像数据，构建了一个全面的数据集。并评估了包括YOLOv8、YOLOv10、YOLO11和RT-DETR在内的多种先进目标检测算法。

研究结果: 实验结果表明，热成像技术可用于矿工检测，且所构建的数据集为开发可靠的检测系统提供了重要基础。

研究结论: 本文证明了热成像技术在矿工检测中的可行性，并为未来研究提供了关键数据集和性能基准。

中文摘要: 地下采矿作业面临重大安全挑战，这使得应急响应能力至关重要。尽管机器人在搜救任务中展现出潜力，但其有效性依赖于可靠的矿工检测能力。深度学习算法为自动化矿工检测提供了潜在解决方案，但目前缺乏适用于地下采矿环境的全面训练数据集。本文提出了一种专门设计的热成像数据集，旨在支持矿工检测系统的开发和验证，以应对潜在的应急应用。我们系统性地采集了多种采矿活动和场景的热成像数据，为检测算法提供了坚实的基础。为了建立性能基准，我们在数据集上评估了包括YOLOv8、YOLOv10、YOLO11和RT-DETR在内的多种先进目标检测算法。尽管该数据集未涵盖所有可能的应急场景，但它是开发可靠热成像矿工检测系统的关键第一步，未来有望应用于实际应急场景。本研究证明了热成像技术在矿工检测中的可行性，并为这一关键安全应用的未来研究奠定了基础。

</details>


### [136] [Rethinking Oversaturation in Classifier-Free Guidance via Low Frequency](https://arxiv.org/abs/2506.21452)
**中文标题：基于低频信号重新思考无分类器引导中的过饱和问题**

*Kaiyu Song,Hanjiang Lai*

主要分类: cs.CV

摘要简述: 本文提出了一种基于低频信号的新视角，通过分析低频冗余信息导致的过饱和问题，提出低频改进的无分类器引导（LF-CFG）方法，有效缓解了扩散模型中的过饱和和不真实伪影问题。


<details>
  <summary>详细信息</summary>
研究动机: 无分类器引导（CFG）通过高引导尺度增强条件项性能，但常导致过饱和和不真实伪影。本文旨在从低频信号角度解决这一问题。

研究方法: 提出低频改进的无分类器引导（LF-CFG），通过自适应阈值定位冗余信息，分析低频信息变化率确定合理阈值，并采用降权策略减少冗余信息影响。

研究结果: 实验表明，LF-CFG在多种扩散模型（如Stable Diffusion-XL、Stable Diffusion 2.1等）中有效缓解了过饱和和不真实伪影。

研究结论: 低频信号分析为过饱和问题提供了新视角，LF-CFG方法在多种模型中表现出色，为解决扩散模型中的伪影问题提供了有效方案。

中文摘要: 无分类器引导（CFG）通过引导尺度平衡条件项和无条件项的影响，高引导尺度用于增强条件项性能，但常导致过饱和和不真实伪影。本文从低频信号角度出发，指出低频冗余信息的积累是过饱和和伪影的关键原因，并提出低频改进的无分类器引导（LF-CFG）以缓解这些问题。具体而言，我们引入基于自适应阈值的测量方法定位冗余信息，通过分析低频信息在前后步骤中的变化率确定合理阈值，并采用降权策略减少低频冗余信息的影响。实验结果表明，LF-CFG在多种扩散模型（包括Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5和SiT-XL）中有效缓解了过饱和和不真实伪影。

</details>


### [137] [Evaluation of Traffic Signals for Daily Traffic Pattern](https://arxiv.org/abs/2506.21469)
**中文标题：基于日常交通模式的交通信号评估**

*Mohammad Shokrolah Shirazi,Hung-Fu Chang*

主要分类: cs.CV

摘要简述: 本文提出动态、静态和混合三种基于转向流量计数（TMC）的交通信号配置方法，通过视觉跟踪系统评估六个交叉路口的信号性能，并基于等待时间实验结果表明90和120秒的信号周期效果最佳。混合方法在高峰和非高峰时段表现最优。


<details>
  <summary>详细信息</summary>
研究动机: 转向流量计数数据对交通信号设计、交叉路口规划和拥堵分析至关重要。研究旨在通过实际数据评估不同信号配置方法的性能，以优化交通流管理。

研究方法: 开发了基于视觉的跟踪系统，估计六个交叉路口的TMC，并将数据导入SUMO仿真工具。提出动态、静态和混合信号配置方法，通过4小时仿真（包括高峰时段）评估性能。

研究结果: 实验表明，90和120秒的信号周期效果最佳；动态配置在四个交叉路口表现更好，而混合方法在高峰和非高峰时段适应性更强。区域交通分布影响信号设计选择。

研究结论: 混合信号方法在适应不同交通模式时表现最优，尤其适用于高峰和非高峰时段的交通流管理。区域交通分布对信号设计有显著影响。

中文摘要: 转向流量计数（TMC）数据对交通信号设计、交叉路口几何规划、交通流和拥堵分析至关重要。本研究提出了三种基于TMC的交通信号配置方法：动态、静态和混合。通过交通摄像头开发了视觉跟踪系统，用于估计拉斯维加斯六个交叉路口的TMC。交叉路口设计、车辆移动方向及兼容格式的信号配置文件被整合并导入SUMO仿真工具，以实际数据评估信号性能。基于等待时间的初步实验结果表明，90秒和120秒的信号周期对所有交叉路口效果最佳。此外，四个交叉路口在动态信号配置下表现更好，而另外两个表现较差的交叉路口的总车辆数与车道数比例较低。由于日常交通流通常呈现双峰模式，我们提出了一种混合信号方法，在动态和静态方法之间切换，以适应高峰和非高峰时段的交通条件，从而改善流量管理。内置的交通生成模块为4小时（包括高峰时段）生成车辆路径，信号设计模块根据静态、动态和混合方法生成信号周期。车辆计数分布在不同区域（如西、北、东、南）具有不同权重，以生成多样化的交通模式。对六个交叉路口进行4小时仿真的扩展实验结果表明，基于区域的交通模式分布影响信号设计选择。尽管静态方法在均匀分布的区域交通中表现良好，但混合方法在西-东和北-南区域对交通流量高度集中的交叉路口表现更优。

</details>


### [138] [Global and Local Entailment Learning for Natural World Imagery](https://arxiv.org/abs/2506.21476)
**中文标题：自然世界图像的全局与局部蕴含学习**

*Srikumar Sastry,Aayush Dhakal,Eric Xing,Subash Khanal,Nathan Jacobs*

主要分类: cs.CV

摘要简述: 本文提出了一种名为径向跨模态嵌入（RCME）的框架，通过显式建模传递性强制蕴含关系，优化视觉语言模型中概念的偏序关系，从而提升自然世界图像的分层表示能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉语言模型在数据分层结构学习中未能显式建模蕴含关系的传递性，导致无法有效表示语义和顺序关系。本文旨在解决这一问题，提出一种能够显式建模传递性蕴含关系的框架。

研究方法: 本文提出径向跨模态嵌入（RCME）框架，通过优化视觉语言模型中概念的偏序关系，显式建模传递性强制蕴含关系，并构建了一个能够表示生命之树分层结构的视觉语言基础模型。

研究结果: 实验表明，在分层物种分类和分层检索任务中，RCME框架的性能优于现有最先进模型。

研究结论: RCME框架通过显式建模传递性蕴含关系，显著提升了视觉语言模型的分层表示能力，为自然世界图像的分层学习提供了有效解决方案。

中文摘要: 学习视觉语言模型中数据的分层结构是一个重要挑战。以往研究尝试通过蕴含学习解决这一问题，但这些方法未能显式建模蕴含关系的传递性，从而无法在表示空间中建立顺序与语义的关系。本文提出径向跨模态嵌入（RCME）框架，显式建模传递性强制蕴含关系，优化视觉语言模型中概念的偏序关系。基于该框架，我们开发了一个能够表示生命之树分层结构的视觉语言基础模型。在分层物种分类和分层检索任务中的实验表明，我们的模型性能优于现有最先进模型。代码和模型已在https://vishu26.github.io/RCME/index.html开源。

</details>


### [139] [TITAN: Query-Token based Domain Adaptive Adversarial Learning](https://arxiv.org/abs/2506.21484)
**中文标题：TITAN：基于查询令牌的域自适应对抗学习**

*Tajamul Ashraf,Janibul Bashir*

主要分类: cs.CV

摘要简述: 本文提出了一种基于查询令牌的域自适应对抗网络（TITAN），用于解决源数据不可用时的域自适应目标检测问题。通过将目标图像分为易样本和难样本，并利用方差估计策略生成可靠伪标签，结合对抗模块减少域间差异，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 在源数据不可用的域自适应目标检测（SF-DAOD）问题中，现有方法依赖自监督学习生成伪标签，但伪标签的高噪声导致模型性能急剧下降。本文旨在通过可靠伪标签生成和域间差异减少，提升模型在目标域上的表现。

研究方法: 提出TITAN方法，将目标图像分为易样本和难样本，利用方差估计策略划分目标域。通过查询令牌对抗模块嵌入学生-教师框架，减少特征表示间的域差异，从而生成更可靠的伪标签。

研究结果: 在四个自然图像数据集和两个医学数据集上的实验表明，TITAN显著优于现有方法。在C2F、C2B、S2C和K2C基准上，mAP分别提升了22.7%、22.2%、21.1%和3.7%。

研究结论: TITAN通过可靠伪标签生成和域间差异减少，有效解决了源数据不可用时的域自适应目标检测问题，显著提升了模型性能。

中文摘要: 本文关注源数据不可用时的域自适应目标检测（SF-DAOD）问题，模型需在无标注目标域上自适应。现有方法多采用自监督学习，通过学生-教师框架生成伪标签进行微调。然而，由于域偏差、差异和显著域偏移，伪标签噪声高，导致教师模型崩溃，学生模型性能急剧下降。为获得可靠伪标签，我们提出基于目标的迭代查询令牌对抗网络（TITAN），将目标图像分为与源域相似（易样本）和不相似（难样本）两部分，并提出方差估计策略划分目标域。该方法利用检测方差越高、召回率越高且与源域相似性越强的特点。此外，我们在学生-教师框架中嵌入查询令牌对抗模块，以减少两种特征表示间的域差异。在四个自然图像数据集和两个医学数据集上的实验验证了TITAN的优越性能。在C2F、C2B、S2C和K2C基准上，mAP分别比当前最优方法提升了22.7%、22.2%、21.1%和3.7%。

</details>


### [140] [Towards Reliable Detection of Empty Space: Conditional Marked Point Processes for Object Detection](https://arxiv.org/abs/2506.21486)
**中文标题：面向可靠空区域检测的条件标记点过程目标检测方法**

*Tobias J. Riedlinger,Kira Maag,Hanno Gottschalk*

主要分类: cs.CV

摘要简述: 本文提出了一种基于空间统计学的目标检测模型，通过条件标记点过程量化未检测区域的置信度，解决了传统目标检测模型在空区域不确定性评估上的不足，适用于自动驾驶等安全关键场景。


<details>
  <summary>详细信息</summary>
研究动机: 当前目标检测模型的置信度估计通常不准确，且无法量化未检测区域是否真正无障碍物，这在自动驾驶等应用中存在安全隐患。本文旨在通过空间统计学方法解决这一问题。

研究方法: 提出了一种基于条件标记点过程的目标检测模型，将边界框数据视为空间点事件的实现，通过标记描述边界框的空间扩展和类别，基于似然训练并提供区域无障碍物的明确定义置信度估计。

研究结果: 实验表明，该方法在校准评估和性能表现上均有效，能够提供更可靠的未检测区域置信度估计。

研究结论: 本文提出的统计框架为目标检测提供了更可靠的置信度估计，尤其是在未检测区域的评估上，为安全关键应用提供了重要支持。

中文摘要: 深度神经网络在边界框检测和语义分割等计算机视觉任务中取得了最先进的性能。目标检测和分割模型为预测分配置信度分数，反映模型在目标检测或像素级分类中的不确定性。然而，这些置信度估计通常校准不准确，因为其架构和损失函数更关注任务性能而非概率基础。即使预测校准良好，目标检测器也无法量化未检测边界框区域的不确定性，即模型未评估未检测区域是否真正无障碍物的概率。这在自动驾驶等应用中存在安全隐患，因为空区域的不确定性未被探索。本文提出了一种基于空间统计学的目标检测模型。边界框数据匹配标记点过程的实现，通常用于描述作为边界框中心的空间点事件的概率发生，其中标记用于描述边界框的空间扩展和类别。我们的统计框架支持基于似然的训练，并为区域是否可行驶（即无障碍物）提供明确定义的置信度估计。通过校准评估和性能评估，我们证明了该方法的有效性。

</details>


### [141] [Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration](https://arxiv.org/abs/2506.21509)
**中文标题：通过动态对数校准减轻大型视觉语言模型的幻觉问题**

*Jiahe Chen,Jiaying He,Qian Shao,Qiyuan Chen,Jiahe Ying,Hongxia Xu,Jintai Chen,Jianwei Zheng,Jian Wu*

主要分类: cs.CV

摘要简述: 本文提出动态对数校准（DLC）方法，通过动态调整生成文本与视觉证据的对齐，显著减少大型视觉语言模型（LVLM）的幻觉问题，同时保持高效推理。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型（LVLM）在多模态理解方面取得显著进展，但常因生成与视觉输入矛盾的文本（幻觉）而受限。现有解码策略存在静态约束、效率低下和细节丢失等问题，亟需一种动态且高效的解决方案。

研究方法: 动态对数校准（DLC）在解码阶段逐步使用CLIP评估图像与生成文本的语义对齐，通过相对视觉优势（RVA）动态调整输出对数，优先选择视觉相关的候选词。同时，自适应权重机制平衡视觉引导与文本质量。

研究结果: 在多种基准测试和LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上的实验表明，DLC显著减少幻觉，优于现有方法，且无需多次前向传播，推理效率高。

研究结论: DLC是一种高效且有效的解码时解决方案，可减少LVLM的幻觉问题，提升其在实际应用中的可靠性。代码将在Github上发布。

中文摘要: 大型视觉语言模型（LVLM）在多模态理解方面取得了显著进展，但其常因生成与视觉输入矛盾的文本（幻觉）而受限。现有的无需训练的解码策略存在关键缺陷，包括使用静态约束无法适应生成过程中的语义漂移、因需要多次前向传播而效率低下，以及因干预规则过于僵化而导致细节丢失。为解决这些问题，本文提出动态对数校准（DLC），一种新颖的无需训练的解码框架，旨在推理时动态对齐文本生成与视觉证据。在解码阶段，DLC逐步使用CLIP评估输入图像与生成文本序列的语义对齐。随后，候选词的相对视觉优势（RVA）与动态更新的上下文基线进行比较，自适应调整输出对数以优先选择视觉相关的词。此外，基于实时上下文对齐分数的自适应权重机制，在确保文本整体质量的同时，谨慎平衡视觉引导。在多种基准测试和不同LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上的广泛实验表明，DLC显著减少幻觉，优于现有方法，同时通过避免多次前向传播保持高效推理。总体而言，我们提出了一种高效且有效的解码时解决方案，以减少幻觉问题，从而提升LVLM在实际应用中的可靠性。代码将在Github上发布。

</details>


### [142] [GGTalker: Talking Head Systhesis with Generalizable Gaussian Priors and Identity-Specific Adaptation](https://arxiv.org/abs/2506.21513)
**中文标题：GGTalker：基于通用高斯先验和身份特定适应的说话头合成**

*Wentao Hu,Shunkai Li,Ziqiao Peng,Haoxian Zhang,Fan Shi,Xiaoqiang Liu,Pengfei Wan,Di Zhang,Hui Tian*

主要分类: cs.CV

摘要简述: GGTalker通过结合通用高斯先验和身份特定适应，解决了语音驱动3D说话头合成中的泛化性和训练效率问题，实现了高质量的渲染效果和3D一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在固定视角和小规模音频变化下表现良好，但难以应对头部大旋转和分布外音频，且需要耗时的身份特定训练。GGTalker旨在通过引入3D先验和身份适应机制解决这些问题。

研究方法: GGTalker采用两阶段训练策略：先验学习和身份适应。通过音频-表情和表情-视觉先验捕捉通用唇动和头部纹理分布，再通过颜色MLP和身体修复器生成精细纹理和逼真视频帧。

研究结果: 实验表明，GGTalker在渲染质量、3D一致性、唇同步准确性和训练效率上达到最先进水平。

研究结论: GGTalker通过通用先验和身份适应的结合，显著提升了说话头合成的泛化能力和效率，为高质量3D说话头生成提供了新思路。

中文摘要: 高质量的、可泛化的语音驱动3D说话头合成仍是一个持续挑战。现有方法在固定视角和小规模音频变化下表现良好，但难以应对头部大旋转和分布外音频，且需要耗时的身份特定训练。我们认为核心问题在于缺乏足够的3D先验，限制了合成说话头的泛化能力。为此，我们提出GGTalker，通过结合通用先验和身份适应来合成说话头。我们引入两阶段先验-适应训练策略，学习高斯头部先验并适应个体特征。通过音频-表情和表情-视觉先验捕捉唇动的通用模式和头部纹理的分布。在定制适应阶段，精确建模个体说话风格和纹理细节。此外，我们引入颜色MLP生成细粒度、运动对齐的纹理，以及身体修复器将渲染结果与背景融合，生成难以区分的逼真视频帧。综合实验表明，GGTalker在渲染质量、3D一致性、唇同步准确性和训练效率上达到最先进水平。

</details>


### [143] [G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation](https://arxiv.org/abs/2506.21514)
**中文标题：G$^{2}$D：基于梯度引导蒸馏的多模态学习增强方法**

*Mohammed Rakib,Arunkumar Bagavathi*

主要分类: cs.CV

摘要简述: 本文提出了一种名为G$^{2}$D（梯度引导蒸馏）的多模态学习框架，通过动态调整模态优先级和融合单模态与多模态目标，解决了传统多模态学习中模态不平衡的问题，显著提升了弱模态的利用效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统多模态学习中，某些模态可能主导模型优化，导致弱模态特征表达不足。本文旨在通过梯度引导蒸馏技术，平衡各模态的贡献，提升模型的整体性能。

研究方法: G$^{2}$D框架结合了梯度引导的损失函数和动态顺序模态优先级（SMP）技术，通过交替优化各模态的目标，确保每个模态都能主导学习过程，避免强模态压制弱模态。

研究结果: 实验表明，G$^{2}$D在多个真实数据集上优于现有方法，显著提升了弱模态的贡献，并在分类和回归任务中取得了最优性能。

研究结论: G$^{2}$D通过动态调整模态优先级和融合多模态目标，有效解决了模态不平衡问题，为多模态学习提供了一种高效的优化框架。

中文摘要: 多模态学习旨在利用多种数据模态的信息以实现更全面的性能。然而，传统的多模态模型常面临模态不平衡问题，即某些模态主导模型优化，导致特征表达不充分和弱模态利用不足。为解决这一问题，我们提出了梯度引导蒸馏（G$^{2}$D），这是一种知识蒸馏框架，通过融合单模态和多模态目标的定制损失函数优化多模态模型。G$^{2}$D进一步在学习过程中引入了动态顺序模态优先级（SMP）技术，确保每个模态都能主导学习过程，避免强模态压制弱模态。我们在多个真实数据集上验证了G$^{2}$D的有效性，结果表明G$^{2}$D在训练中显著提升了弱模态的重要性，并在分类和回归任务中优于现有方法。代码已开源：https://github.com/rAIson-Lab/G2D。

</details>


### [144] [MADrive: Memory-Augmented Driving Scene Modeling](https://arxiv.org/abs/2506.21520)
**中文标题：MADrive：基于记忆增强的驾驶场景建模**

*Polina Karpikova,Daniil Selikhanovych,Kirill Struminsky,Ruslan Musaev,Maria Golitsyna,Dmitry Baranchuk*

主要分类: cs.CV

摘要简述: MADrive提出了一种基于记忆增强的驾驶场景建模框架，通过从大规模外部记忆库中检索相似车辆3D资产，替换原始场景中的车辆，从而实现高度逼真的驾驶场景重构和新颖场景合成。


<details>
  <summary>详细信息</summary>
研究动机: 现有的自动驾驶场景重建技术虽然能够实现高度真实的3D高斯散射建模，但其重构结果仍受限于原始观测数据，难以支持对显著改变或全新驾驶场景的逼真合成。MADrive旨在通过记忆增强技术扩展现有方法的潜力。

研究方法: MADrive框架通过以下步骤实现：1) 发布MAD-Cars数据集，包含约70K个360度野外拍摄的汽车视频；2) 设计检索模块，从记忆库中查找最相似的车辆实例；3) 从视频中重建对应的3D资产；4) 通过方向对齐和重新光照将其整合到目标场景中。

研究结果: 实验表明，MADrive能够提供场景中车辆的完整多视角表示，支持对显著改变的配置进行逼真合成，展示了其在实际应用中的潜力。

研究结论: MADrive通过记忆增强技术显著提升了驾驶场景建模的灵活性和逼真度，为自动驾驶环境的重构和新颖场景合成提供了新思路。

中文摘要: 近年来，场景重建技术的进步推动了基于3D高斯散射的自动驾驶（AD）环境高度真实建模的发展。然而，现有的重构结果仍紧密依赖于原始观测数据，难以支持对显著改变或全新驾驶场景的逼真合成。本文提出MADrive，一种记忆增强的重构框架，旨在通过从大规模外部记忆库中检索视觉相似的3D资产替换观测到的车辆，扩展现有场景重建方法的能力。具体而言，我们发布了MAD-Cars数据集，这是一个包含约70K个野外拍摄的360度汽车视频的精选数据集，并提出了一个检索模块，用于从记忆库中查找最相似的车辆实例，从视频中重建对应的3D资产，并通过方向对齐和重新光照将其整合到目标场景中。实验表明，替换后的车辆提供了场景中车辆的完整多视角表示，支持对显著改变的配置进行逼真合成。项目页面：https://yandex-research.github.io/madrive/

</details>


### [145] [WAFT: Warping-Alone Field Transforms for Optical Flow](https://arxiv.org/abs/2506.21526)
**中文标题：WAFT：基于单独变形场变换的光流估计**

*Yihan Wang,Jia Deng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为WAFT的光流估计方法，通过高分辨率变形替代传统成本体积，实现了更高精度和更低内存消耗，挑战了传统观念。


<details>
  <summary>详细信息</summary>
研究动机: 传统光流方法依赖成本体积构建，但这种方式内存消耗大且计算复杂。本文旨在提出一种更高效、更灵活的方法，减少对成本体积的依赖。

研究方法: WAFT方法采用高分辨率变形替代成本体积，简化了架构设计，减少了归纳偏置和定制化需求，同时提升了性能和效率。

研究结果: WAFT在Spring和KITTI基准测试中排名第一，在KITTI上实现了最佳零样本泛化性能，速度比同类方法快4.1倍。

研究结论: WAFT通过高分辨率变形设计，证明了无需成本体积也能实现高性能光流估计，为未来研究提供了新思路。

中文摘要: 我们提出了Warping-Alone Field Transforms（WAFT），一种简单高效的光流估计方法。WAFT与RAFT类似，但用高分辨率变形替代了成本体积，以更低的内存成本实现了更高的精度。这一设计挑战了传统观念，即构建成本体积是实现高性能的必要条件。WAFT是一种简单灵活的元架构，具有最小的归纳偏置和对定制化设计的依赖。与现有方法相比，WAFT在Spring和KITTI基准测试中排名第一，在KITTI上实现了最佳零样本泛化性能，同时速度比性能相近的方法快4.1倍。代码和模型权重可在https://github.com/princeton-vl/WAFT获取。

</details>


### [146] [Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval](https://arxiv.org/abs/2506.21538)
**中文标题：最大匹配的重要性：防止表示坍缩以实现稳健的跨模态检索**

*Hani Alomari,Anushka Sivakumar,Andrew Zhang,Chris Thomas*

主要分类: cs.CV

摘要简述: 跨模态图像-文本检索面临多样关联的挑战。传统单向量嵌入方法难以捕捉细微关系，而基于集合的方法虽能丰富表示，但仍存在稀疏监督和集合坍缩问题。本文提出最大配对分配相似性和两种损失函数，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 跨模态检索中，图像和文本的多样关联难以通过单向量嵌入完全捕捉。基于集合的方法虽能丰富表示，但仍受限于稀疏监督和集合坍缩，限制了其效果。

研究方法: 提出最大配对分配相似性（Maximal Pair Assignment Similarity）优化嵌入集合间的一对一匹配，保持语义多样性；引入全局判别损失和集合内散度损失，增强嵌入区分性和防止集合坍缩。

研究结果: 在MS-COCO和Flickr30k数据集上取得最先进性能，无需依赖外部数据。

研究结论: 通过优化集合间匹配和引入损失函数，有效解决了跨模态检索中的稀疏监督和集合坍缩问题，显著提升了性能。

中文摘要: 跨模态图像-文本检索的挑战在于不同模态内容间多样的关联。传统方法通过学习单向量嵌入表示每个样本的语义，但难以捕捉跨模态的细微和多样关系。基于集合的方法通过多嵌入表示样本，提供了更丰富的关联捕捉能力。然而，这些方法仍面临稀疏监督和集合坍缩问题。为此，我们提出最大配对分配相似性，优化嵌入集合间的一对一匹配以保持语义多样性，并引入全局判别损失和集合内散度损失增强表示。我们的方法在MS-COCO和Flickr30k上无需外部数据即达到最先进性能。

</details>


### [147] [StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning](https://arxiv.org/abs/2506.21541)
**中文标题：StruMamba3D：探索结构Mamba用于自监督点云表示学习**

*Chuxin Wang,Yixin Zha,Wenfei Yang,Tianzhu Zhang*

主要分类: cs.CV

摘要简述: StruMamba3D提出了一种基于Mamba的自监督点云表示学习新范式，通过保留空间依赖性和优化状态更新策略，显著提升了性能，并在多个下游任务中达到SOTA水平。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于Mamba的点云表示学习方法在SSM处理过程中破坏了3D点的邻接关系，且无法随着输入长度增加保留长序列记忆，限制了SSM的潜力。因此，需要一种新方法来解决这些问题。

研究方法: 1. 设计空间状态作为代理以保留点之间的空间依赖性；2. 通过状态更新策略和轻量级卷积增强SSM，促进空间状态交互；3. 引入序列长度自适应策略，减少模型对输入长度的敏感性。

研究结果: 实验结果表明，StruMamba3D在四个下游任务中表现优异，在ModelNet40上达到95.1%的准确率，在ScanObjectNN最具挑战性的分割上达到92.75%的准确率（无需投票策略）。

研究结论: StruMamba3D通过优化空间依赖性和状态更新策略，显著提升了点云表示学习的性能，为自监督学习提供了新的解决方案。

中文摘要: 近年来，基于Mamba的方法通过利用状态空间模型（SSM）的高效上下文建模能力和线性复杂度，在点云表示学习中表现出色。然而，这些方法仍面临两个关键问题：在SSM处理过程中破坏了3D点的邻接关系，以及随着下游任务输入长度的增加无法保留长序列记忆。为解决这些问题，我们提出了StruMamba3D，一种自监督点云表示学习的新范式。其优势包括：首先，我们设计了空间状态作为代理以保留点之间的空间依赖性；其次，我们通过状态更新策略增强SSM，并引入轻量级卷积以促进空间状态交互，实现高效结构建模；第三，通过引入序列长度自适应策略，降低了预训练Mamba模型对输入长度的敏感性。在四个下游任务中的实验结果表明，我们的方法性能优越。此外，我们的方法在ModelNet40上达到了95.1%的准确率，在ScanObjectNN最具挑战性的分割上达到了92.75%的准确率（无需投票策略）。

</details>


### [148] [DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion](https://arxiv.org/abs/2506.21544)
**中文标题：DeOcc-1-to-3：通过自监督多视角扩散从单张图像实现3D去遮挡**

*Yansong Qu,Shaohui Dai,Xinyang Li,Yuze Wang,You Shen,Liujuan Cao,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DeOcc-1-to-3的端到端框架，用于从单张部分遮挡图像生成六张结构一致的新视角图像，从而提升3D重建质量。该方法通过自监督训练和伪真实视角学习，无需人工标注或先验修复。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于扩散的视角合成模型在输入完全可见时表现良好，但在物体部分遮挡时会导致视角不一致和3D重建质量下降。本文旨在解决这一问题，提出一种能够处理遮挡的3D重建方法。

研究方法: 方法包括：1) 构建自监督训练流程，利用遮挡-未遮挡图像对和伪真实视角；2) 在不修改原始架构的情况下，微调视角合成模型以联合学习修复和多视角生成；3) 引入首个遮挡感知重建基准，涵盖多样遮挡水平、物体类别和掩码模式。

研究结果: 实验表明，该方法能够从单张遮挡图像生成六张结构一致的新视角，显著提升3D重建质量。同时，提出的基准为未来方法在部分遮挡下的评估提供了标准化协议。

研究结论: DeOcc-1-to-3通过自监督学习和多视角生成，有效解决了单张遮挡图像的3D重建问题，为遮挡感知重建领域提供了新思路和评估工具。

中文摘要: 从单张图像重建3D物体是一个长期存在的挑战，尤其是在真实世界存在遮挡的情况下。尽管近期基于扩散的视角合成模型可以从单张RGB图像生成一致的新视角，但它们通常假设输入完全可见，在物体部分遮挡时会失败，导致视角不一致和3D重建质量下降。为了克服这一限制，我们提出了一种端到端的遮挡感知多视角生成框架。我们的方法直接从单张部分遮挡图像合成六张结构一致的新视角，无需先验修复或人工标注即可支持下游3D重建。我们利用Pix2Gestalt数据集构建了一个自监督训练流程，通过遮挡-未遮挡图像对和伪真实视角，教会模型结构感知的修复和视角一致性。在不修改原始架构的情况下，我们完全微调了视角合成模型，使其联合学习修复和多视角生成。此外，我们引入了首个遮挡感知重建基准，涵盖多样遮挡水平、物体类别和掩码模式，为未来方法在部分遮挡下的评估提供了标准化协议。代码可在https://github.com/Quyans/DeOcc123获取。

</details>


### [149] [SAM4D: Segment Anything in Camera and LiDAR Streams](https://arxiv.org/abs/2506.21547)
**中文标题：SAM4D：相机与LiDAR流中的任意分割**

*Jianyun Xu,Song Wang,Ziqian Ni,Chunyong Hu,Sheng Yang,Jianke Zhu,Qiang Li*

主要分类: cs.CV

摘要简述: SAM4D是一种多模态时序基础模型，用于相机和LiDAR流的可提示分割。通过统一多模态位置编码（UMPE）和运动感知跨模态记忆注意力（MCMA）实现跨模态交互与时序一致性，并利用自动化数据引擎生成高质量伪标签。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶场景中，相机和LiDAR数据的跨模态分割面临时序一致性和标注效率的挑战。SAM4D旨在解决这些问题，实现高效、鲁棒的跨模态分割。

研究方法: 1. 引入统一多模态位置编码（UMPE）对齐相机和LiDAR特征；2. 提出运动感知跨模态记忆注意力（MCMA）增强时序一致性；3. 开发多模态自动化数据引擎生成伪标签。

研究结果: 在Waymo-4DSeg数据集上的实验表明，SAM4D具有强大的跨模态分割能力，并能高效生成高质量伪标签。

研究结论: SAM4D为跨模态分割提供了一种高效、鲁棒的解决方案，显著提升了数据标注效率和分割性能。

中文摘要: 我们提出了SAM4D，一种多模态时序基础模型，用于相机和LiDAR流的可提示分割。通过引入统一多模态位置编码（UMPE），将相机和LiDAR特征对齐到共享的3D空间中，实现无缝的跨模态提示与交互。此外，我们提出了运动感知跨模态记忆注意力（MCMA），利用自运动补偿增强时序一致性和长时特征检索，确保在动态变化的自动驾驶场景中实现鲁棒分割。为避免标注瓶颈，我们开发了一种多模态自动化数据引擎，结合VFM驱动的视频掩码、时空4D重建和跨模态掩码融合。该框架以比人工标注快多个数量级的速度生成相机-LiDAR对齐的伪标签，同时保持点云表示中VFM衍生的语义保真度。我们在构建的Waymo-4DSeg上进行了大量实验，证明了SAM4D强大的跨模态分割能力以及在数据标注中的巨大潜力。

</details>


### [150] [SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark](https://arxiv.org/abs/2506.21549)
**中文标题：SiM3D：单实例多视角多模态多配置的3D异常检测基准**

*Alex Costanzino,Pierluigi Zama Ramirez,Luigi Lella,Matteo Ragaglia,Alessandro Oliva,Giuseppe Lisanti,Luigi Di Stefano*

主要分类: cs.CV

摘要简述: SiM3D是首个结合多视角和多模态信息的3D异常检测与分割基准，专注于单实例异常检测场景，并首次解决从合成数据到真实数据的泛化挑战。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D异常检测领域缺乏结合多视角和多模态信息的基准，尤其是在单实例训练场景下。SiM3D旨在填补这一空白，并解决从合成数据到真实数据的泛化问题。

研究方法: SiM3D提供了一个多模态多视角数据集，包含高分辨率图像和点云数据，并提供了手动标注的3D分割真值。研究还调整了单视角方法作为基准，并提出了新的评估指标。

研究结果: SiM3D数据集包含333个实例的八类对象数据，并提供了合成与真实数据的对比基准。实验表明，多视角方法在3D异常检测任务中表现优异。

研究结论: SiM3D为多视角多模态3D异常检测提供了首个基准，解决了单实例训练和合成数据泛化的挑战，为未来研究奠定了基础。

中文摘要: 我们提出了SiM3D，这是首个考虑多视角和多模态信息整合的全面3D异常检测与分割（ADS）基准，任务是生成基于体素的异常体积。此外，SiM3D专注于制造业中高度关注的场景：单实例异常检测，其中仅有一个真实或合成对象可用于训练。在这方面，SiM3D作为首个ADS基准，解决了从合成训练数据泛化到真实测试数据的挑战。SiM3D包含一个新颖的多模态多视角数据集，使用顶级工业传感器和机器人采集。该数据集包含333个实例的八类对象的多视角高分辨率图像（1200万像素）和点云（700万点），以及每类对象的CAD模型。我们还为异常测试样本提供了手动标注的3D分割真值。为了为提出的多视角3D ADS任务建立参考基准，我们调整了突出的单视角方法，并使用针对异常体积的新指标评估其性能。

</details>


### [151] [Whole-Body Conditioned Egocentric Video Prediction](https://arxiv.org/abs/2506.21552)
**中文标题：基于全身条件的自我中心视频预测**

*Yutong Bai,Danny Tran,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik*

主要分类: cs.CV

摘要简述: 该论文提出了一种基于人体动作的自我中心视频预测模型（PEVA），通过结合过去视频和3D身体姿态，利用条件扩散变换器模拟人类动作对环境的影响，并在大规模数据集Nymeria上进行了训练和评估。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决从人类第一视角预测复杂真实世界环境和具身行为的挑战，通过结合视频和身体姿态数据，模拟人类动作对环境的动态影响。

研究方法: 采用自回归条件扩散变换器模型，结合人体关节层次结构的运动轨迹，训练于大规模真实世界自我中心视频和身体姿态数据集Nymeria，并设计了分层评估协议以全面分析模型的预测和控制能力。

研究结果: 模型能够有效模拟人类动作对环境的动态影响，并通过分层评估验证了其在具身预测和控制任务中的表现。

研究结论: 该研究为从人类第一视角建模复杂环境和具身行为提供了初步解决方案，展示了视频预测在具身智能中的潜力。

中文摘要: 我们训练了一种模型，用于从人类动作（PEVA）预测自我中心视频，输入为过去视频和由相对3D身体姿态表示的动作。通过以运动姿态轨迹为条件，结合身体的关节层次结构，我们的模型学会了从第一人称视角模拟物理人类动作如何塑造环境。我们在Nymeria（一个大规模真实世界自我中心视频和身体姿态捕捉数据集）上训练了一个自回归条件扩散变换器。此外，我们设计了一个分层评估协议，包含逐渐增加难度的任务，以全面分析模型的具身预测和控制能力。我们的工作代表了从人类视角建模复杂真实世界环境和具身行为视频预测挑战的初步尝试。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [152] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
**中文标题：新加坡共识：全球AI安全研究优先事项**

*Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić*

主要分类: cs.AI

摘要简述: 新加坡共识提出了全球AI安全研究的优先事项，旨在通过开发、评估和控制三个层面的研究，确保AI的可信、可靠与安全。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI能力的快速提升，如何确保其安全、可信和可靠成为重要议题。新加坡AI安全会议旨在通过国际合作，明确AI安全研究的优先方向。

研究方法: 报告基于Yoshua Bengio主持的国际AI安全报告，采用深度防御模型，将AI安全研究分为开发（可信AI系统）、评估（风险）和控制（部署后干预）三个领域。

研究结果: 报告提出了AI安全研究的三大优先领域：开发可信AI系统、评估AI风险以及部署后的监控与干预。

研究结论: 通过国际合作和多层次研究，可以构建一个可信的AI生态系统，促进创新并避免负面影响。

中文摘要: AI能力的快速提升和自主性带来了巨大的变革潜力，但也引发了如何确保AI安全（即可信、可靠和安全的）的激烈讨论。构建一个可信的生态系统至关重要——它帮助人们自信地接受AI，并为创新提供最大空间，同时避免反弹。

“2025年新加坡AI会议（SCAI）：AI安全国际科学交流”旨在通过汇集全球AI科学家，明确并综合AI安全研究的优先事项，支持这一领域的研究。本报告基于由Yoshua Bengio主持、33国政府支持的国际AI安全报告。通过采用深度防御模型，报告将AI安全研究领域分为三类：开发可信AI系统的挑战（开发）、评估其风险的挑战（评估）以及部署后监控和干预的挑战（控制）。

</details>


### [153] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
**中文标题：MAGPIE：多智能体上下文隐私评估数据集**

*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

主要分类: cs.AI

摘要简述: 本文介绍了MAGPIE数据集，用于评估多智能体系统中的上下文隐私保护能力。研究发现，当前最先进的LLM（如GPT-4o和Claude-2.7-Sonnet）在理解上下文隐私方面表现不佳，且在明确隐私指令下仍频繁泄露隐私信息。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于LLM的智能体在多任务协作中的广泛应用，隐私保护成为关键问题。现有评估基准主要针对单轮简单任务，无法反映真实场景中隐私保护的复杂性。本文旨在填补这一空白，评估智能体在多轮对话中保护上下文隐私的能力。

研究方法: 本文提出了MAGPIE数据集，包含158个高风险场景，覆盖15个领域。这些场景设计为完全排除隐私数据会阻碍任务完成，而过度共享则可能导致重大损失。研究评估了当前最先进的LLM在理解隐私数据和协作任务中的表现。

研究结果: 实验表明，当前模型（如GPT-4o和Claude-2.7-Sonnet）对上下文隐私的理解不足，分别有25.2%和43.6%的隐私数据被错误分类为可共享。在多轮对话中，即使有明确隐私指令，模型仍分别有59.9%和50.5%的隐私泄露率。此外，多智能体系统在71%的场景中无法完成任务。

研究结论: 当前模型在上下文隐私保护和协作任务完成方面表现不佳，亟需改进以应对真实场景中的隐私挑战。

中文摘要: 基于LLM的智能体在任务协作（如调度、谈判、资源分配等）中的广泛应用使得隐私保护变得至关重要，因为这些智能体通常需要访问专有工具和领域特定数据库。本文探讨了LLM智能体是否具备上下文隐私理解能力，以及在明确指令下是否能在多轮对话中保护用户隐私。现有评估基准主要针对单轮低复杂度任务，隐私数据易于排除。我们首先提出了MAGPIE基准，包含158个真实高风险场景，覆盖15个领域。这些场景设计为完全排除隐私数据会阻碍任务完成，而过度共享则可能导致重大损失。随后，我们评估了当前最先进LLM在（a）理解上下文隐私数据及（b）协作中保护隐私的能力。实验表明，包括GPT-4o和Claude-2.7-Sonnet在内的当前模型对上下文隐私的理解不足，分别有25.2%和43.6%的隐私数据被错误分类为可共享。在多轮对话中，即使有明确隐私指令，这些模型仍分别有59.9%和50.5%的隐私泄露率。此外，多智能体系统在71%的场景中无法完成任务。这些结果表明，当前模型在上下文隐私保护和协作任务完成方面均未达到理想水平。

</details>


### [154] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
**中文标题：领域特定AI应用的动态上下文感知提示推荐**

*Xinye Tang,Haijun Zhai,Chaitanya Belwal,Vineeth Thayanithi,Philip Baumann,Yogesh K Roy*

主要分类: cs.AI

摘要简述: 本文提出了一种动态上下文感知的提示推荐系统，专为领域特定的AI应用设计，通过结合上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，生成相关且可操作的提示建议。实验证明其高效性和相关性。


<details>
  <summary>详细信息</summary>
研究动机: 由于LLM驱动的应用高度依赖用户提示的质量，而领域特定应用中高质量提示的生成尤为困难，因此需要一种动态且上下文感知的提示推荐系统来提升用户体验。

研究方法: 系统结合了上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，通过行为遥测和两阶段分层推理动态选择和排名相关技能，并使用预定义和自适应模板结合少样本学习生成提示。

研究结果: 在真实数据集上的实验表明，该方法在自动化和专家评估中均表现出高实用性和相关性。

研究结论: 本文提出的动态上下文感知提示推荐系统有效解决了领域特定应用中高质量提示生成的挑战，显著提升了提示的相关性和实用性。

中文摘要: LLM驱动的应用对用户提示质量高度敏感，而领域特定应用中高质量提示的生成尤为困难。本文提出了一种新颖的动态上下文感知提示推荐系统，专为领域特定AI应用设计。我们的解决方案结合了上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，以生成相关且可操作的提示建议。系统利用行为遥测和两阶段分层推理动态选择和排名相关技能，并通过预定义和自适应模板结合少样本学习生成提示。在真实数据集上的实验表明，我们的方法在自动化和专家评估中均表现出高实用性和相关性。

</details>


### [155] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
**中文标题：超越被动安全：通过长期模拟实现风险感知的LLM对齐**

*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

主要分类: cs.AI

摘要简述: 本文提出了一种通过长期模拟评估语言模型长期安全意识的框架，并在新数据集上实现了20%以上的性能提升，同时在现有安全基准测试中平均胜率超过70%。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于语言模型的代理在高风险社会决策（如公共政策和医疗保健）中的影响力增加，确保其建议的长期积极影响变得至关重要。本文旨在通过长期模拟预测模型建议的宏观社会影响，以提升模型的安全性。

研究方法: 提出了一个概念验证框架，通过模拟模型生成建议在宏观社会系统中的长期传播，评估其安全性。同时，引入了一个包含100个间接危害场景的数据集，测试模型对看似无害提示可能导致的非显性负面结果的预见能力。

研究结果: 新数据集上的性能提升超过20%，在现有安全基准测试（AdvBench、SafeRLHF、WildGuardMix）中平均胜率超过70%。

研究结论: 该框架为语言模型的长期安全对齐提供了有前景的方向，表明通过长期模拟可以显著提升模型的安全性。

中文摘要: 随着基于语言模型的代理在高风险社会决策（从公共政策到医疗保健）中的影响力日益增强，确保其有益影响需要理解其建议的深远意义。我们提出了一个概念验证框架，该框架能够预测模型生成的建议在宏观社会系统中的长期传播，从而实现更稳健的对齐。为了评估语言模型的长期安全意识，我们还引入了一个包含100个间接危害场景的数据集，测试模型对看似无害用户提示可能导致的不明显负面结果的预见能力。我们的方法不仅在新数据集上实现了超过20%的性能提升，还在现有安全基准测试（AdvBench、SafeRLHF、WildGuardMix）中平均胜率超过70%，为更安全的代理提供了一条有前景的路径。

</details>


### [156] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
**中文标题：揭示大型语言模型中的因果推理：现实还是幻象？**

*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

主要分类: cs.AI

摘要简述: 研究发现大型语言模型（LLMs）仅能进行浅层（level-1）因果推理，缺乏人类深层（level-2）推理能力。通过新基准测试和提出的G^2-Reasoner方法，论文展示了提升LLMs因果推理能力的新路径。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLMs）在因果推理方面的表现是否真实接近人类水平尚不明确。论文旨在验证LLMs是否具备深层因果推理能力，并提出改进方法。

研究方法: 论文通过分析LLMs的自回归机制，揭示其非因果性；引入新基准CausalProbe-2024测试LLMs表现；提出G^2-Reasoner方法，结合通用知识和目标导向提示以增强因果推理能力。

研究结果: 实验表明，LLMs在新基准CausalProbe-2024上表现显著下降，证实其仅具备浅层因果推理能力；G^2-Reasoner方法显著提升了LLMs在新鲜和反事实语境中的推理能力。

研究结论: LLMs目前仅能进行浅层因果推理，但通过结合通用知识和目标导向提示的方法（如G^2-Reasoner），可显著提升其推理能力，为迈向深层因果推理开辟新路径。

中文摘要: 因果推理能力是推动大型语言模型（LLMs）迈向强人工智能的关键。尽管多功能的LLMs似乎展现了理解上下文因果关系和遵循因果律回应的能力，但其是否具备类似人类的真实因果推理能力仍不明确。然而，现有证据表明事实恰恰相反。具体而言，LLMs仅能进行浅层（level-1）因果推理，主要归因于其参数中嵌入的因果知识，但缺乏人类深层（level-2）因果推理能力。为支持这一假设，方法上，我们深入研究了基于Transformer的LLMs的自回归机制，揭示其本质上不具备因果性。实证上，我们引入了一个新的因果问答基准CausalProbe-2024，其语料对研究的LLMs而言是全新且几乎未见过的。LLMs在CausalProbe-2024上的表现较早期基准显著下降，表明其主要进行的是level-1因果推理。为缩小与level-2因果推理的差距，我们从人类推理通常依赖通用知识和目标导向这一事实中汲取灵感，提出G^2-Reasoner方法，将通用知识和目标导向提示融入LLMs的因果推理过程。实验证明，G^2-Reasoner显著提升了LLMs的因果推理能力，尤其是在新鲜和反事实语境中。这项工作为LLMs超越level-1、迈向level-2的真实因果推理开辟了新路径。

</details>


### [157] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
**中文标题：世界感知规划叙事增强大型视觉语言模型规划器**

*Junhao Shi,Zhaoye Fei,Siyin Wang,Qipeng Guo,Jingjing Gong,Xipeng QIu*

主要分类: cs.AI

摘要简述: 本文提出了一种名为WAP的框架，通过四种认知能力增强大型视觉语言模型（LVLM）的环境理解能力，显著提升了任务成功率，尤其在常识推理和长时规划方面表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型视觉语言模型在复杂场景和多步目标任务中表现不佳，主要依赖与环境无关的模仿学习，导致模型无法处理上下文敏感的指令，且过度依赖辅助线索而非视觉推理。

研究方法: WAP框架通过视觉外观建模、空间推理、功能抽象和语法基础四种认知能力，结合课程学习，仅使用原始视觉观察数据增强模型的环境理解能力。

研究结果: 在EB-ALFRED基准测试中，Qwen2.5-VL模型的任务成功率提升了60.7%，常识推理和长时规划分别提高了60.0%和70.0%，且优于GPT-4o和Claude-3.5-Sonnet等专有系统。

研究结论: WAP框架显著提升了LVLM在复杂任务中的表现，证明了环境感知能力对模型性能的重要性，并为开源模型超越专有系统提供了可能。

中文摘要: 大型视觉语言模型（LVLM）在具身规划任务中展现出潜力，但在涉及陌生环境和多步目标的复杂场景中表现不佳。当前方法依赖于与环境无关的模仿学习，导致指令与环境上下文脱节，使模型难以处理上下文敏感的指令，并在长时交互中依赖辅助线索而非视觉推理。本文提出世界感知规划叙事增强（WAP）框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和语法基础）为LVLM注入全面的环境理解，同时仅通过课程学习使用原始视觉观察数据开发和评估模型。在EB-ALFRED基准测试中，Qwen2.5-VL的任务成功率实现了60.7%的绝对提升，尤其在常识推理（+60.0）和长时规划（+70.0）方面表现突出。值得注意的是，我们增强的开源模型大幅优于GPT-4o和Claude-3.5-Sonnet等专有系统。

</details>


### [158] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
**中文标题：IXAII：一种用于决策支持系统的交互式可解释人工智能界面**

*Pauline Speckmann,Mario Nadj,Christian Janiesch*

主要分类: cs.AI

摘要简述: 本文提出了一种名为IXAII的交互式可解释人工智能界面，通过整合LIME、SHAP、Anchors和DiCE四种方法，为用户提供定制化的解释视图，并通过专家和普通用户的访谈验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的可解释AI方法多为静态且忽视用户视角，限制了其实际效果。因此，本文旨在开发一种交互式系统，以提升AI的透明度和用户参与度。

研究方法: 开发了IXAII系统，整合了四种可解释AI方法（LIME、SHAP、Anchors和DiCE），并为五类用户群体提供定制化解释视图，允许用户控制解释内容和格式。

研究结果: 通过专家和普通用户的访谈评估，IXAII因其多样化的解释和可视化选项，被认为能显著提升AI的透明度。

研究结论: IXAII通过结合可解释AI方法、交互性和实际应用，为AI解释实践和人机交互提供了新视角。

中文摘要: 尽管已经开发了多种可解释AI的事后方法，但大多数是静态的且忽视了用户视角，限制了其对目标受众的有效性。为此，我们开发了一种名为IXAII的交互式可解释智能系统，该系统提供了四种可解释AI方法（LIME、SHAP、Anchors和DiCE）的解释。我们的原型为五类用户群体提供了定制化的视图，并允许用户控制解释的内容和格式。我们通过专家和普通用户的访谈对IXAII进行了评估。结果表明，IXAII因其多样化的解释和可视化选项，被认为有助于提升透明度。通过弥合可解释AI方法、交互性和实际实施之间的差距，我们为AI解释实践和人机交互提供了新的视角。

</details>


### [159] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
**中文标题：用于科学发现的主动推理人工智能系统**

*Karthik Duraisamy*

主要分类: cs.AI

摘要简述: 本文提出了一种基于主动推理的AI系统，旨在通过填补抽象、推理和现实三大鸿沟，推动科学发现。系统结合因果自监督模型、贝叶斯规划器和知识图谱，通过闭环实验验证实现科学推理。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI系统在科学发现中存在局限性，如架构僵化、推理脆弱及与实验现实的脱节。本文旨在通过解决抽象、推理和现实三大鸿沟，推动AI在科学领域的实质性进展。

研究方法: 提出主动推理AI系统，包括：1）基于因果自监督的长期研究记忆；2）配备贝叶斯护栏的符号或神经符号规划器；3）通过推理和实验验证扩展的知识图谱；4）通过高保真模拟器和自动化实验室的闭环交互优化内部表征。

研究结果: 该系统能够通过内部模型的假设推理和外部实验验证，实现科学发现，同时强调人类判断在不确定性和模糊反馈中的不可或缺作用。

研究结论: 主动推理AI系统通过结合内部模型和外部验证，填补了科学推理中的关键鸿沟，为AI驱动的科学发现提供了新方向。人类判断作为系统的永久组成部分，确保了其稳健性。

中文摘要: 人工智能的快速发展引发了其对科学发现变革性影响的期待，然而当前系统仍受限于其操作架构、脆弱的推理机制以及与实验现实的分离。基于前期工作，我们认为AI驱动科学的进展现在取决于填补三大根本鸿沟——抽象鸿沟、推理鸿沟和现实鸿沟——而非模型规模、数据或计算时间。科学推理需要支持行动和响应模拟的内部表征、区分相关性与机制的因果结构，以及持续校准。我们定义用于科学发现的主动推理AI系统为：（i）基于因果自监督基础模型的长期研究记忆；（ii）配备贝叶斯护栏的符号或神经符号规划器；（iii）通过推理生成新概念节点、建立因果边并修剪虚假连接的知识图谱；（iv）通过与高保真模拟器和自动化实验室的闭环交互优化内部表征。本质上，我们提出了一种架构，其中发现源于支持反事实推理的内部模型与将假设扎根于现实的外部验证之间的相互作用。此外，模拟和实验反馈的固有模糊性及潜在不确定性使得人类判断不可或缺，不仅是临时支架，而是永久的架构组成部分。

</details>


### [160] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
**中文标题：TableMoE：多模态表格理解中结构化专家推理的神经符号路由**

*Junwen Zhang,Pu Chen,Yin Zhang*

主要分类: cs.AI

摘要简述: 本文提出TableMoE，一种神经符号混合专家架构，专为多模态表格数据的鲁棒结构化推理设计，通过神经符号路由机制动态分配任务给专家，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态大语言模型在复杂表格理解任务中表现不佳，尤其是在结构复杂、视觉退化的真实场景下。为解决这一问题，本文提出TableMoE，旨在通过神经符号混合专家架构提升多模态表格理解的鲁棒性和泛化能力。

研究方法: TableMoE采用神经符号路由机制，预测表格元素的语义角色（如标题、数据单元格等），并通过置信感知门控策略动态分配给专用专家（如Table-to-HTML、Table-to-JSON等）。此外，引入大规模对齐数据集TableMoE-Align进行预训练。

研究结果: 实验结果表明，TableMoE在四个WildStruct基准测试中显著优于现有模型，并通过消融研究验证了神经符号路由和结构化专家对齐的核心作用。定性分析进一步展示了其可解释性和鲁棒性。

研究结论: TableMoE通过神经符号推理的集成，显著提升了多模态表格理解的性能，证明了其在复杂真实场景中的有效性。

中文摘要: 由于结构复杂性、符号密度和视觉退化（模糊、倾斜、水印、不完整结构或字体、多跨度或分层嵌套布局），真实场景中的多模态表格理解具有挑战性。现有多模态大语言模型（MLLMs）在WildStruct条件下表现不佳，导致性能有限且泛化能力差。为解决这些问题，我们提出TableMoE，一种专为多模态表格数据鲁棒结构化推理设计的神经符号混合连接专家（MoCE）架构。TableMoE采用创新的神经符号路由机制，预测潜在语义标记角色（如标题、数据单元格、轴、公式），并通过符号推理图支持的置信感知门控策略动态将表格元素路由至专用专家（Table-to-HTML、Table-to-JSON、Table-to-Code）。为促进有效的对齐驱动预训练，我们引入大规模TableMoE-Align数据集，包含金融、科学、生物医学和工业领域的120万表-HTML-JSON-代码四元组，专门用于模型预训练。为评估性能，我们策划并发布了四个挑战性WildStruct基准：WMMFinQA、WMMTatQA、WMMTabDialog和WMMFinanceMath，专门用于在真实多模态退化和结构复杂性下测试模型。实验结果表明，TableMoE显著超越现有最先进模型。广泛消融研究验证了每个核心组件，强调了神经符号路由和结构化专家对齐的关键作用。通过定性分析，我们进一步展示了TableMoE的可解释性和增强的鲁棒性，凸显了神经符号推理在多模态表格理解中的有效性。

</details>


### [161] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
**中文标题：从有限视角构建空间心理模型**

*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

主要分类: cs.AI

摘要简述: 本文探讨了视觉语言模型（VLMs）是否能像人类一样从有限视角构建完整的空间心理模型。通过MindCube基准测试，发现现有VLMs表现接近随机水平。提出“先映射后推理”方法，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 人类能够从有限视角构建空间心理模型，而现有视觉语言模型（VLMs）在此能力上存在显著不足。本文旨在填补这一研究空白，探索如何帮助VLMs构建和利用空间心理模型。

研究方法: 提出MindCube基准测试（包含21,154个问题和3,268张图像），系统评估VLMs在空间心理建模中的表现。探索三种方法：生成中间视角、自然语言推理链和认知地图，最终提出“先映射后推理”的协同方法。

研究结果: 通过“先映射后推理”方法，模型准确率从37.8%提升至60.8%（+23.0%）。结合强化学习后，性能进一步提升至70.7%（+32.9%）。

研究结论: 研究表明，通过构建和利用结构化空间表征的灵活推理过程，能够显著提升VLMs对不可见空间的理解能力。

中文摘要: 视觉语言模型（VLMs）能否像人类一样仅凭少量视角想象完整场景？人类通过构建空间心理模型（对不可见空间的内部表征）来推理布局、视角和运动。我们提出的MindCube基准测试包含21,154个问题和3,268张图像，揭示了现有VLMs在此能力上的显著不足，其表现接近随机水平。通过MindCube，我们系统评估了VLMs在构建空间心理模型方面的能力，包括位置表征（认知映射）、方向推理（视角转换）和动态模拟（“假设”运动的心理模拟）。随后，我们探索了三种帮助VLMs近似空间心理模型的方法：生成不可见中间视角、自然语言推理链和认知地图。显著改进来自一种协同方法“先映射后推理”，该方法联合训练模型首先生成认知地图，然后基于地图进行推理。通过训练模型在这些内部地图上推理，准确率从37.8%提升至60.8%（+23.0%）。结合强化学习后，性能进一步提升至70.7%（+32.9%）。我们的核心发现是，这种空间心理模型的“脚手架”方法——主动构建并利用结构化空间表征的灵活推理过程——显著提升了对不可见空间的理解能力。

</details>


### [162] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
**中文标题：Ad-Hoc人类-AI协调挑战**

*Tin Dizdarević,Ravi Hammond,Tobias Gessler,Anisoara Calinescu,Jonathan Cook,Matteo Gallici,Andrei Lupu,Jakob Nicolaus Foerster*

主要分类: cs.AI

摘要简述: 本文提出了Ad-Hoc Human-AI Coordination Challenge（AH2AC2），通过开发人类代理代理解决人类评估成本高且难以复现的问题，为Hanabi游戏中的AI与人类协调提供廉价、可复现的评估方法。


<details>
  <summary>详细信息</summary>
研究动机: 现实应用中，AI与人类的无缝协调至关重要，但现有方法面临人类评估成本高且难以复现的挑战。Hanabi游戏因其复杂性和协调需求成为理想测试平台，但人类评估限制了其应用。

研究方法: 作者开发了基于大规模人类数据集的人类代理代理，作为廉价、可复现的评估伙伴，并开源了3,079局游戏数据以促进数据高效方法的发展。通过受控评估系统确保公平性。

研究结果: 研究提供了两玩家和三玩家Hanabi场景的基线结果，并通过受控系统托管代理代理，避免公开释放带来的潜在问题。

研究结论: AH2AC2为AI与人类协调研究提供了廉价、可复现的评估框架，解决了人类评估的局限性，推动了数据高效方法的发展。

中文摘要: 实现AI代理与人类的无缝协调对实际应用至关重要，但这仍是一个重大开放挑战。Hanabi是一款具有不完全信息、受限通信、心智理论需求和协调行动的合作卡牌游戏，是研究人类-AI协调的理想测试平台。然而，人类评估的挑战限制了其在人类-AI交互中的应用。本文提出了Ad-Hoc Human-AI Coordination Challenge（AH2AC2），以克服昂贵且难以复现的人类评估限制。我们基于大规模人类数据集开发了人类代理代理，作为AH2AC2中稳健、廉价且可复现的人类评估伙伴。为了促进数据高效方法的发展，我们开源了3,079局游戏数据集，并故意限制了可用的人类游戏数据量。我们展示了两玩家和三玩家Hanabi场景的基线结果。为确保公平评估，我们通过受控评估系统托管代理代理，而非公开释放。代码可在https://github.com/FLAIROx/ah2ac2获取。

</details>


### [163] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
**中文标题：Mind2Web 2：基于Agent-as-a-Judge框架的自主搜索评估**

*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

主要分类: cs.AI

摘要简述: 本文介绍了Mind2Web 2，一个包含130个高质量、长周期任务的基准测试，用于评估自主网络搜索系统。作者提出了一种新颖的Agent-as-a-Judge框架，通过任务特定的评委代理自动评估答案正确性和来源标注。实验显示，最佳系统OpenAI Deep Research已达到人类性能的50-70%，展示了巨大潜力。


<details>
  <summary>详细信息</summary>
研究动机: 随着自主网络搜索系统的复杂性增加，现有评估方法无法满足长周期、动态答案的需求。本文旨在填补这一空白，提供一个更全面的评估基准和方法。

研究方法: 作者构建了Mind2Web 2基准测试，包含130个长周期任务，并通过Agent-as-a-Judge框架设计任务特定的评委代理，自动评估答案正确性和来源标注。

研究结果: 实验评估了九种前沿自主搜索系统和人类表现，最佳系统OpenAI Deep Research达到人类性能的50-70%，且耗时仅为人类的一半。

研究结论: Mind2Web 2为下一代自主搜索系统的开发和评估提供了坚实基础，展示了现有系统的潜力与未来发展方向。

中文摘要: 自主搜索（如Deep Research系统）通过大型语言模型自主浏览网络、综合信息并返回引用支持的全面答案，代表了用户与网络规模信息交互方式的重大转变。尽管其有望提高效率和减轻认知负担，但自主搜索的复杂性和开放性已超越现有评估基准和方法，这些方法通常假设短搜索周期和静态答案。本文介绍了Mind2Web 2，一个包含130个高质量、长周期任务的基准测试，需要实时网络浏览和广泛信息综合，耗时超过1,000小时人工构建。为应对评估动态复杂答案的挑战，我们提出了一种新颖的Agent-as-a-Judge框架。该方法基于树状评分标准设计任务特定的评委代理，自动评估答案正确性和来源标注。我们对九种前沿自主搜索系统和人类表现进行了全面评估，并通过详细错误分析为未来发展提供见解。表现最佳的系统OpenAI Deep Research已达到人类性能的50-70%，且耗时仅为一半，展示了巨大潜力。Mind2Web 2为下一代自主搜索系统的开发和评估提供了严谨基础。

</details>


### [164] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
**中文标题：PsyLite技术报告**

*Fangjun Ding,Renyu Zhang,Xinyu Feng,Chengye Xie,Zheng Zhang,Yanting Zhang*

主要分类: cs.AI

摘要简述: 本文提出PsyLite，一种基于InternLM2.5-7B-chat的轻量级心理咨询大语言模型代理，通过两阶段训练策略提升深度推理、心理咨询和对话安全能力，并在资源受限环境中实现高效部署。


<details>
  <summary>详细信息</summary>
研究动机: 随着数字技术的发展，AI驱动的心理咨询成为心理健康领域的重要研究方向，但现有模型在对话安全、场景处理轻量化部署方面存在不足。

研究方法: 采用两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），结合条件RAG引入幽默元素并拒绝危险请求，使用量化技术（GGUF q4_k_m）实现轻量化部署。

研究结果: PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中表现优异，心理咨询专业性提升47.6%，对话安全性提升2.4%，且仅需5GB内存即可运行。

研究结论: PsyLite为资源受限环境下的心理咨询应用提供了可行解决方案，兼具高效性和安全性。

中文摘要: 随着数字技术的快速发展，AI驱动的心理咨询逐渐成为心理健康领域的重要研究方向。然而，现有模型在对话安全、详细场景处理和轻量化部署方面仍存在不足。为解决这些问题，本研究提出PsyLite，一种基于基础模型InternLM2.5-7B-chat开发的轻量级心理咨询大语言模型代理。通过两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），PsyLite提升了模型的深度推理能力、心理咨询能力和安全对话能力。部署时使用Ollama和Open WebUI，并通过Pipelines创建自定义工作流。设计了一种创新的条件RAG，在心理咨询过程中适时引入相声幽默元素以提升用户体验，并拒绝危险请求以增强对话安全性。评估结果显示，PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中均优于基线模型，尤其在心理咨询专业性（CPsyCounE得分提升47.6%）和对话安全性（SafeDialBench得分提升2.4%）方面表现突出。此外，模型通过量化技术（GGUF q4_k_m）实现了低硬件部署（仅需5GB内存即可运行），为资源受限环境下的心理咨询应用提供了可行解决方案。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [165] [Real-time and personalized product recommendations for large e-commerce platforms](https://arxiv.org/abs/2506.21368)
**中文标题：大型电商平台的实时个性化产品推荐**

*Matteo Tolloso,Davide Bacciu,Shahab Mokarizadeh,Marco Varesi*

主要分类: cs.IR

摘要简述: 本文提出了一种基于图神经网络和简约学习方法的实时个性化产品推荐方法，特别针对大型时尚电商平台，实现了高准确性和低延迟的推荐效果。


<details>
  <summary>详细信息</summary>
研究动机: 大型电商平台需要实时且个性化的产品推荐以提升用户满意度，尤其是在时尚零售领域。现有方法在准确性和响应时间上存在挑战，因此需要一种高效且可扩展的解决方案。

研究方法: 采用图神经网络（GNN）和简约学习方法，专注于实时性和个性化推荐。通过分析用户购买序列和多交互场景，优化推荐系统的性能。

研究结果: 在大型电商平台数据集上的实验表明，该方法能够高效预测购买序列并处理多交互场景，实现了在真实约束条件下的个性化推荐。

研究结论: 该方法为大型电商平台提供了一种高效、实时且个性化的推荐解决方案，显著提升了用户体验和平台性能。

中文摘要: 我们提出了一种为大型电商平台（特别是时尚零售领域）提供实时个性化产品推荐的方法。该方法旨在通过图神经网络和简约学习方法，实现高准确性和可扩展性的推荐，同时确保极短的响应时间以提升用户满意度。通过对一家大型电商平台数据集的广泛实验，证明了该方法在预测购买序列和处理多交互场景方面的有效性，能够在真实约束条件下实现高效的个性化推荐。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [166] [Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG](https://arxiv.org/abs/2506.20683)
**中文标题：基于全局和局部对比学习的心脏MRI与ECG联合表征方法**

*Alexander Selivanov,Philip Müller,Özgün Turgut,Nil Stolt-Ansó,Daniel Rückert*

主要分类: eess.IV

摘要简述: 本文提出了一种多模态对比学习框架PTACL，通过结合心脏MRI和ECG的时空信息，增强ECG的表征能力。PTACL使用全局和局部对比损失，提升了ECG在心脏功能预测和患者检索任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 心电图（ECG）是一种经济高效的工具，但无法直接测量心脏功能参数（如心室容积和射血分数）。心脏磁共振（CMR）虽能提供详细的结构和功能信息，但成本高且不易获取。因此，需要一种方法结合两者的优势，提升ECG的诊断能力。

研究方法: PTACL框架通过全局患者级对比损失和局部时间级对比损失，将ECG与CMR的时空信息对齐。全局损失使同一患者的ECG和CMR表征更接近，局部损失则通过对比ECG片段与对应CMR帧实现细粒度对齐。

研究结果: 在UK Biobank的27,951名受试者数据上，PTACL在患者相似性检索和心脏功能参数预测任务中表现优于基线方法，验证了其有效性。

研究结论: PTACL能够通过多模态对比学习提升ECG的诊断能力，为非侵入性心脏诊断提供了新思路。代码已开源。

中文摘要: 心电图（ECG）是一种广泛使用的经济高效工具，用于检测心脏电活动异常，但无法直接测量心室容积和射血分数等功能参数。心脏磁共振（CMR）是这些测量的金标准，但成本高且不易获取。为弥补这一差距，我们提出了PTACL（患者和时间对齐对比学习），一种多模态对比学习框架，通过整合CMR的时空信息增强ECG表征。PTACL使用全局患者级对比损失和局部时间级对比损失。全局损失通过拉近同一患者的ECG和CMR表征并推开不同患者的表征，实现患者级对齐；局部损失通过对比编码的ECG片段与对应CMR帧，实现细粒度时间对齐。这种方法在不引入新可学习参数的情况下，为ECG表征提供了超越电活动的诊断信息，并实现了比全局对齐更丰富的模态间信息传递。我们在UK Biobank的27,951名受试者数据上评估了PTACL。与基线方法相比，PTACL在两项临床相关任务中表现更优：（1）检索具有相似心脏表型的患者；（2）预测CMR衍生的心脏功能参数（如心室容积和射血分数）。我们的结果表明，PTACL有潜力通过ECG提升非侵入性心脏诊断能力。代码已开源：https://github.com/alsalivan/ecgcmr。

</details>


### [167] [U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs](https://arxiv.org/abs/2506.20689)
**中文标题：U-R-VEDA：结合UNet、残差连接、边缘与双重注意力及视觉变换器实现心脏磁共振图像的精确语义分割**

*Racheal Mukisa,Arvind K. Bansal*

主要分类: eess.IV

摘要简述: 本文提出了一种名为U-R-Veda的深度学习模型，结合了UNet、残差连接、边缘和双重注意力机制以及视觉变换器，用于精确分割心脏磁共振图像（CMR），平均准确率达95.2%。


<details>
  <summary>详细信息</summary>
研究动机: 自动化精确分割心脏图像是量化与自动化诊断心脏疾病的关键步骤。现有模型在分割右心室和左心室心肌时表现不足，因此需要一种更高效的模型。

研究方法: U-R-Veda模型整合了卷积变换、视觉变换器、残差连接、通道和空间注意力机制，以及基于边缘检测的跳跃连接。通过卷积块和视觉变换器提取局部特征及其相互关系，并嵌入通道和空间注意力机制以减少信息损失。

研究结果: 模型在DSC指标上达到95.2%的平均准确率，优于其他模型，尤其在右心室和左心室心肌的分割上表现突出。

研究结论: U-R-Veda显著提升了CMR图像的语义分割精度，为医学图像分析提供了更高效的工具。

中文摘要: 人工智能，包括深度学习模型，将在自动化医学图像分析中发挥变革性作用，用于心脏疾病的诊断与管理。自动化精确分割心脏图像是量化与自动化诊断心脏疾病的首要步骤。本文提出了一种基于深度学习的增强UNet模型U-R-Veda，该模型整合了卷积变换、视觉变换器、残差连接、通道和空间注意力机制，以及基于边缘检测的跳跃连接，以实现心脏磁共振（CMR）图像的精确全自动语义分割。模型通过卷积块和视觉变换器提取局部特征及其相互关系，并在卷积块中嵌入通道和空间注意力机制以识别重要特征及其空间定位。结合边缘信息与通道和空间注意力机制的跳跃连接减少了卷积变换中的信息损失。整体模型显著提升了CMR图像的语义分割精度，为医学图像分析提供了改进。文中还提出了双重注意力模块（通道和空间注意力）的算法。性能结果显示，基于DSC指标，U-R-Veda的平均准确率达95.2%。该模型在DSC和HD指标上优于其他模型，尤其在右心室和左心室心肌的分割上表现突出。

</details>


### [168] [A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver Tumour Ablation](https://arxiv.org/abs/2506.21162)
**中文标题：一种将3D超声整合到经皮肝肿瘤消融中的新框架**

*Shuwei Xing,Derek W. Cool,David Tessier,Elvis C. S. Chen,Terry M. Peters,Aaron Fenster*

主要分类: eess.IV

摘要简述: 本文提出了一种将3D超声整合到经皮肝肿瘤消融中的新框架，通过2D超声-CT/MRI配准和直观的多模态图像可视化技术，显著提升了配准精度和效率。


<details>
  <summary>详细信息</summary>
研究动机: 3D超声在肝肿瘤消融中具有显著优势，但由于肿瘤识别的挑战，其临床应用受限。本研究旨在解决这一问题，推动3D超声在治疗领域的应用。

研究方法: 提出了一种新框架，包括2D超声-CT/MRI配准方法，利用3D超声作为中介降低配准复杂度，并开发了多模态图像可视化技术以验证配准流程。

研究结果: 2D超声-CT/MRI配准的标记点距离误差为2-4毫米，运行时间为每对图像0.22秒；非刚性配准比刚性配准平均对齐误差降低约40%。

研究结论: 该框架有效提升了3D超声在肝肿瘤消融中的应用潜力，展示了其在临床干预中的治疗价值。

中文摘要: 3D超声（US）成像在提升经皮肝肿瘤消融效果方面显示出显著优势。其临床整合对于将3D超声引入治疗领域至关重要。然而，超声图像中肿瘤识别的挑战仍阻碍其广泛应用。本研究提出了一种将3D超声整合到标准消融流程中的新框架。我们介绍了一个关键组件，即一种临床可行的2D超声-CT/MRI配准方法，利用3D超声作为中介降低配准复杂度。为高效验证配准流程，我们还提出了一种直观的多模态图像可视化技术。研究中，2D超声-CT/MRI配准的标记点距离误差约为2-4毫米，每对图像运行时间为0.22秒。此外，非刚性配准比刚性配准平均对齐误差降低约40%。结果表明了所提出的2D超声-CT/MRI配准流程的有效性。我们的整合框架提升了3D超声成像在改善经皮肿瘤消融中的能力，展示了其在临床干预中扩展3D超声治疗作用的潜力。

</details>


### [169] [Development of MR spectral analysis method robust against static magnetic field inhomogeneity](https://arxiv.org/abs/2506.20897)
**中文标题：开发一种对静态磁场不均匀性鲁棒的光谱分析方法**

*Shuki Maruyama,Hidenori Takeshima*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的新光谱分析方法，用于提高静态磁场B0不均匀性下的光谱分析准确性。通过使用模拟光谱训练模型，显著降低了代谢物比率的误差。


<details>
  <summary>详细信息</summary>
研究动机: 静态磁场B0不均匀性会显著影响光谱分析的准确性，传统方法对此问题的处理效果有限。本文旨在开发一种新方法，通过深度学习模型提高光谱分析的鲁棒性。

研究方法: 作者提出了一种新方法，利用深度学习模型训练模拟光谱，这些光谱基于健康人脑的B0图和代谢物比率生成。B0图被划分为子区域，分别估计代谢物和基线成分后取平均并整合。模型通过实测、模拟和建模光谱进行训练，并通过均方误差（MSE）和平均绝对百分比误差（MAPE）评估性能。

研究结果: 模拟光谱的谱峰宽度随B0不均匀性变化，且与实测光谱定量接近。使用建模光谱训练的模型比仅使用实测光谱的模型MSE降低了49.89%，比使用模拟光谱的模型降低了26.66%。随着建模光谱数量增加，性能进一步提升。该模型在两种B0不均匀性下的MAPE均显著低于LCModel。

研究结论: 本文成功开发了一种基于建模光谱训练的深度学习模型，能够显著提高光谱分析的准确性。该方法通过增加训练样本数量，为光谱分析提供了新的优化方向。

中文摘要: 目的：开发一种在静态磁场B0不均匀性下提高光谱分析准确性的方法。方法：作者提出了一种新的光谱分析方法，利用深度学习模型训练模拟光谱，这些光谱能够一致地反映B0不均匀性引起的谱变化。模拟光谱基于健康人脑的B0图和代谢物比率生成。B0图被划分为子区域，分别估计代谢物和基线成分后取平均并整合。通过视觉和定量评估模拟光谱与实测光谱的差异。分析模型通过实测、模拟和建模光谱进行训练，并通过代谢物比率的均方误差（MSE）评估性能。同时，在两种B0不均匀性下，比较了该模型与LCModel的平均绝对百分比误差（MAPE）。结果：模拟光谱的谱峰宽度随B0不均匀性变化，且与实测光谱定量接近。使用建模光谱训练的模型比仅使用实测光谱的模型MSE降低了49.89%，比使用模拟光谱的模型降低了26.66%。随着建模光谱数量增加，性能进一步提升。该模型在两种B0不均匀性下的MAPE均显著低于LCModel。结论：本文成功开发了一种基于建模光谱训练的深度学习模型，能够显著提高光谱分析的准确性。该方法通过增加训练样本数量，为光谱分析提供了新的优化方向。

</details>


### [170] [Uncover Treasures in DCT: Advancing JPEG Quality Enhancement by Exploiting Latent Correlations](https://arxiv.org/abs/2506.21171)
**中文标题：挖掘DCT中的宝藏：通过利用潜在相关性提升JPEG质量增强**

*Jing Yang,Qunliang Xing,Mai Xu,Minglang Qiao*

主要分类: eess.IV

摘要简述: 本文提出了一种名为AJQE的DCT域JPEG质量增强方法，通过挖掘DCT系数中的潜在相关性，显著提升了性能并降低了计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: JPEG压缩通过量化DCT系数实现数据压缩，但会引入压缩伪影。现有方法多在像素域操作，计算成本高，而DCT域方法性能有限。本文旨在解决这一问题。

研究方法: 作者识别了JPEG图像DCT系数中的两类关键相关性，并基于此提出AJQE方法，将像素域模型适配到DCT域，充分利用这些相关性。

研究结果: 与像素域方法相比，AJQE方法在PSNR上平均提升0.35 dB，增强吞吐量提高60.5%。

研究结论: AJQE方法通过挖掘DCT域相关性，显著提升了JPEG质量增强的性能和效率，为DCT域方法提供了新思路。

中文摘要: 联合图像专家组（JPEG）通过量化离散余弦变换（DCT）系数实现数据压缩，但不可避免地引入压缩伪影。大多数现有的JPEG质量增强方法在像素域操作，解码计算成本高。因此，直接在DCT域增强JPEG图像受到越来越多的关注。然而，当前的DCT域方法性能有限。为解决这一问题，我们识别了JPEG图像DCT系数中的两类关键相关性。基于这一发现，我们提出了一种先进的DCT域JPEG质量增强（AJQE）方法，充分利用这些相关性。AJQE方法能够将许多成熟的像素域模型适配到DCT域，以更低的计算复杂度实现更优的性能。与像素域方法相比，通过我们的方法衍生的DCT域模型在PSNR上平均提升0.35 dB，增强吞吐量提高60.5%。

</details>


### [171] [GANet-Seg: Adversarial Learning for Brain Tumor Segmentation with Hybrid Generative Models](https://arxiv.org/abs/2506.21245)
**中文标题：GANet-Seg：基于混合生成模型的对抗学习脑肿瘤分割方法**

*Qifei Cui,Xinyu Lu*

主要分类: eess.IV

摘要简述: 本文提出了一种结合预训练GAN和Unet架构的新框架GANet-Seg，用于脑肿瘤分割。通过全局异常检测模块和精细掩码生成网络的结合，该模型能够准确识别肿瘤敏感区域，并利用对抗性损失约束迭代提升分割精度。实验在BraTS数据集上验证了其高效性。


<details>
  <summary>详细信息</summary>
研究动机: 脑肿瘤分割在临床诊断中至关重要，但现有方法依赖大量标注数据且精度有限。本文旨在通过结合生成对抗网络（GAN）和Unet架构，减少对标注数据的依赖，同时提升分割精度。

研究方法: 提出GANet-Seg框架，结合预训练GAN和Unet架构，引入全局异常检测模块和精细掩码生成网络。通过多模态MRI数据和合成图像增强提升鲁棒性，并利用对抗性损失约束优化分割结果。

研究结果: 在BraTS数据集上的实验表明，该方法在病变Dice和HD95指标上均优于基线，具有高灵敏度和准确性。

研究结论: GANet-Seg通过减少对全标注数据的依赖，提升了脑肿瘤分割的精度和实用性，为临床实际应用提供了可行方案。

中文摘要: 本文提出了一种新颖的脑肿瘤分割框架，结合了预训练的生成对抗网络（GAN）和Unet架构。通过将全局异常检测模块与精细掩码生成网络相结合，该模型能够准确识别肿瘤敏感区域，并利用对抗性损失约束迭代提升分割精度。采用多模态MRI数据和合成图像增强技术，提高了模型的鲁棒性，并解决了标注数据有限的挑战。在BraTS数据集上的实验结果表明，该方法在病变Dice和HD95指标上均优于基线模型，具有高灵敏度和准确性。这种可扩展的方法减少了对全标注数据的依赖，为临床实际应用提供了可行的解决方案。

</details>


### [172] [Lightweight Physics-Informed Zero-Shot Ultrasound Plane Wave Denoising](https://arxiv.org/abs/2506.21499)
**中文标题：轻量级物理信息零样本超声平面波去噪**

*Hojat Asgariandehkordi,Mostafa Sharifzadeh,Hassan Rivaz*

主要分类: eess.IV

摘要简述: 本文提出了一种轻量级、基于物理信息的零样本超声平面波去噪框架，通过自监督残差学习抑制噪声并保留解剖结构，无需额外训练数据。


<details>
  <summary>详细信息</summary>
研究动机: 超声相干平面波复合（CPWC）通过多角度传输提升图像对比度，但增加角度会降低帧率并引入模糊伪影，且低角度采集易受噪声影响。传统方法需要大量训练数据，难以适应不同解剖区域和采集设置。

研究方法: 方法将可用传输角度分为两个不相交子集，分别生成含噪声的复合图像，通过自监督残差学习训练轻量级网络（仅含两层卷积），分离噪声与组织信号。

研究结果: 在仿真、体模和活体数据上的实验表明，该方法在对比度增强和结构保留方面优于传统和基于深度学习的去噪方法。

研究结论: 该零样本去噪框架无需领域微调或配对数据，计算成本低，适用于不同解剖区域和采集设置。

中文摘要: 超声相干平面波复合（CPWC）通过组合多角度传输的回波提升图像对比度，但增加角度会显著降低帧率并引入快速运动目标的模糊伪影。此外，低角度采集的复合图像仍易受噪声影响。本文提出一种专为低角度CPWC采集设计的零样本去噪框架，无需依赖额外训练数据即可增强对比度。该方法将可用传输角度分为两个不相交子集，分别生成含噪声的复合图像，并通过自监督残差学习训练深度模型，以抑制非相干噪声并保留解剖结构。由于角度相关伪影在子集间变化而组织响应相似，这种基于物理的配对使网络能够分离不一致的伪影与一致的组织信号。与监督方法不同，该模型无需领域微调或配对数据，可适应不同解剖区域和采集设置。整个流程采用轻量级架构（仅含两层卷积），支持高效低计算成本的训练。仿真、体模和活体数据的评估表明，该方法在对比度增强和结构保留方面优于传统及基于深度学习的去噪方法。

</details>


### [173] [Exploring the Design Space of 3D MLLMs for CT Report Generation](https://arxiv.org/abs/2506.21535)
**中文标题：探索3D多模态大语言模型在CT报告生成中的设计空间**

*Mohammed Baharoon,Jun Ma,Congyu Fang,Augustin Toma,Bo Wang*

主要分类: eess.IV

摘要简述: 本文系统研究了3D多模态大语言模型（MLLMs）在CT报告生成中的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和微调技术，并提出了两种基于知识的报告增强方法，性能提升高达10%。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在自动化放射学报告生成（RRG）中表现出潜力，但3D MLLMs的设计空间尚未充分探索。本文旨在填补这一空白，并提升CT报告生成的性能。

研究方法: 研究包括视觉输入表示、投影器、LLMs选择和微调技术的设计空间分析，并引入两种知识驱动的报告增强方法。实验基于AMOS-MM数据集的1,687例病例。

研究结果: 在相同训练协议下，RRG性能与LLM规模无关；更大的体积尺寸不一定提升性能；结合分割掩模可提升表现。方法在MICCAI 2024 AMOS-MM挑战中排名第二。

研究结论: 3D MLLMs的设计选择对CT报告生成至关重要，知识增强方法显著提升性能，为未来研究提供了实用指导。

中文摘要: 多模态大语言模型（MLLMs）已成为自动化放射学报告生成（RRG）的有前景方法。本文系统研究了3D MLLMs的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和微调技术，用于3D CT报告生成。我们还提出了两种基于知识的报告增强方法，将GREEN分数性能提升高达10%，在MICCAI 2024 AMOS-MM挑战中排名第二。基于AMOS-MM数据集的1,687例病例结果显示，在相同训练协议下，RRG性能与LLM规模无关。此外，若原始ViT预训练体积较小，更大的体积尺寸不一定提升性能。最后，结合分割掩模与CT体积可提升表现。代码公开于https://github.com/bowang-lab/AMOS-MM-Solution。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [174] [Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots](https://arxiv.org/abs/2506.20748)
**中文标题：探索聊天机器人的人形化特征与人类共情对人类对聊天机器人亲社会行为的影响**

*Jingshu Li,Zicheng Zhu,Renwen Zhang,Yi-Chieh Lee*

主要分类: cs.HC

摘要简述: 研究发现，聊天机器人的人形化特征（如人类身份和情感表达）能增强人类对其的共情，从而促进人类对聊天机器人的亲社会行为和意图。


<details>
  <summary>详细信息</summary>
研究动机: 随着聊天机器人在生活中的广泛应用，人类帮助聊天机器人的现象逐渐增多，但相关研究较少。本文旨在探索聊天机器人的人形化特征如何影响人类对其的共情和亲社会行为。

研究方法: 通过在线实验（N=244），让聊天机器人在协作图像标注任务中犯错并向参与者解释原因，随后测量参与者的亲社会行为和意图。

研究结果: 研究发现，聊天机器人的人类身份和情感表达显著提升了人类的亲社会行为和意图，共情在其中起到中介作用。定性分析还揭示了两种亲社会行为的动机：对聊天机器人的共情和将其视为人类。

研究结论: 聊天机器人的人形化特征能有效促进人类的亲社会行为，这对理解和推动人类与聊天机器人的协作具有重要意义。

中文摘要: 聊天机器人越来越多地融入人们的生活，并被广泛用于帮助人类。最近，由于聊天机器人性能提升、人类福祉改善及协作成果等广泛益处，人类帮助聊天机器人的现象也日益受到关注。然而，关于激励人类帮助聊天机器人的因素研究较少。为填补这一空白，我们基于“计算机是社会行为者”（CASA）框架，探讨聊天机器人的人形化特征（包括人类身份、情感表达和非语言表达）如何影响人类对聊天机器人的共情及其后续的亲社会行为和意图。我们还探讨了人类对其亲社会行为的自我解释。通过一项在线实验（N=244），我们让聊天机器人在协作图像标注任务中犯错并向参与者解释原因，随后测量参与者的亲社会行为和意图。研究发现，聊天机器人的人类身份和情感表达显著提升了人类的亲社会行为和意图，共情在其中起到中介作用。定性分析进一步揭示了两种亲社会行为的动机：对聊天机器人的共情和将其视为人类。我们讨论了这些结果对理解和促进人类对聊天机器人亲社会行为的启示。

</details>


### [175] [A Systematic Review of Human-AI Co-Creativity](https://arxiv.org/abs/2506.21333)
**中文标题：人机协同创造的系统性综述**

*Saloni Singh,Koen Hndriks,Drik Heylen,Kim Baraka*

主要分类: cs.HC

摘要简述: 本文通过系统性文献综述分析了62篇关于人机协同创造系统的论文，总结了系统设计的关键维度和24条设计考虑，发现高用户控制权和适应性强的主动系统能提升合作效果。


<details>
  <summary>详细信息</summary>
研究动机: 人机协同创造领域在开发更复杂和定制化的系统以支持人类创造力方面取得进展，但缺乏对系统设计维度的系统性总结。本文旨在填补这一空白，为未来系统设计提供基础。

研究方法: 对62篇关于人机协同创造系统的论文进行系统性文献综述，分析其应用领域、系统设计维度及用户反馈。

研究结果: 识别了系统设计的六个关键维度（如创意阶段、用户控制权等），并提取了24条设计考虑。高用户控制权和适应性强的主动系统能提升用户满意度和信任感。

研究结论: 人机协同创造系统需注重用户控制权和系统适应性，同时增强透明度和社交存在感以建立信任。未来需进一步支持早期创意阶段和用户适应性问题。

中文摘要: 协同创造领域在开发更复杂和定制化的系统以支持和增强人类创造力方面取得了显著进展。先前工作的设计考虑可为未来系统提供高效且有价值的基础。为此，我们对62篇关于协同创造系统的文献进行了系统性综述，涵盖视觉艺术、设计和写作等多样化应用领域，其中AI不仅是工具，更是创意过程中的积极合作者。通过综述，我们识别了与系统设计相关的几个关键维度：创意过程的阶段、创意任务、系统的主动行为、用户控制权、系统体现形式和AI模型类型。研究发现，提供高用户控制权的系统能带来更高的满意度、信任感以及对创意成果的更强拥有感。此外，适应性强且情境敏感的主动系统可增强合作效果。我们还提取了24条设计考虑，强调了鼓励用户外化思维、增强系统的社交存在感和透明度以促进信任的价值。尽管近期有所进展，但仍存在重要空白，如对问题澄清等早期创意阶段的支持不足，以及用户适应AI系统的挑战。

</details>


### [176] [Multimodal LLMs for Visualization Reconstruction and Understanding](https://arxiv.org/abs/2506.21319)
**中文标题：用于可视化重建与理解的多模态大模型**

*Can Liu,Chunlin Da,Xiaoxiao Long,Yuxiao Yang,Yu Zhang,Yong Wang*

主要分类: cs.HC

摘要简述: 本文提出了一种针对可视化理解的多模态大模型，通过结合图表图像及其向量化表示、编码方案和数据特征，显著提升了数据提取准确性和图表重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前的多模态大模型在自然图像理解方面表现良好，但在可视化图表理解方面存在不足，无法解析数据到视觉的映射规则和提取结构化信息。本文旨在解决这一问题。

研究方法: 作者提出了一种新的数据集，并训练了专门用于可视化理解的多模态大模型。方法结合了图表图像及其对应的向量化表示、编码方案和数据特征，通过向量格式实现可视化内容的紧凑且准确重建。

研究结果: 实验结果表明，该方法在数据提取准确性和图表重建质量方面均有显著提升。

研究结论: 本文提出的多模态大模型在可视化理解方面取得了重要进展，为数据通信中的图表理解提供了有效工具。

中文摘要: 可视化在数据通信中至关重要，但理解可视化需要同时理解视觉元素及其底层数据关系。当前的多模态大模型虽然在自然图像理解方面表现良好，但在可视化理解方面存在困难，主要原因是无法解析数据到视觉的映射规则和提取结构化信息。为解决这些问题，我们提出了一种新的数据集，并训练了专门用于可视化理解的多模态大模型。我们的方法结合了图表图像及其对应的向量化表示、编码方案和数据特征。所提出的向量格式能够紧凑且准确地重建可视化内容。实验结果表明，该方法在数据提取准确性和图表重建质量方面均有显著提升。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [177] [DRAGON: Distributional Rewards Optimize Diffusion Generative Models](https://arxiv.org/abs/2504.15217)
**中文标题：DRAGON：分布奖励优化扩散生成模型**

*Yatong Bai,Jonah Casebeer,Somayeh Sojoudi,Nicholas J. Bryan*

主要分类: cs.SD

摘要简述: DRAGON是一种灵活的框架，用于优化生成模型以达成目标结果。相比传统方法，它支持更广泛的奖励函数，包括实例级和分布级评估。实验表明，DRAGON在20种奖励函数上平均胜率达81.45%，且无需人类偏好标注即可提升生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习与人类反馈（RLHF）或直接偏好优化（DPO）方法在优化生成模型时灵活性不足。DRAGON旨在提供一种更通用的框架，支持多种奖励函数，包括实例级和分布级评估，以提升生成模型的性能。

研究方法: DRAGON通过选择编码器和参考样本构建奖励函数，支持跨模态评估（如文本与音频）。它在线收集生成样本，通过对比正负示例集优化奖励。实验中对音频域文本到音乐扩散模型进行了20种奖励函数的微调。

研究结果: DRAGON在20种目标奖励函数上平均胜率达81.45%。基于示例集的奖励函数显著提升生成质量，且无需人类偏好标注即可实现60.95%的人类投票音乐质量胜率。

研究结论: DRAGON展示了设计和优化奖励函数的新方法，显著提升生成模型的人类感知质量，尤其在跨模态和分布级评估中表现优异。

中文摘要: 我们提出了分布奖励生成优化框架（DRAGON），这是一种用于微调媒体生成模型以实现目标结果的通用框架。与传统的人类反馈强化学习（RLHF）或直接偏好优化（DPO）相比，DRAGON更加灵活，能够优化评估单个样本或其分布的奖励函数，兼容实例级、实例到分布和分布到分布的多类奖励。利用这种灵活性，我们通过选择编码器和参考样本构建新颖的奖励函数，生成示例分布。当使用跨模态编码器（如CLAP）时，参考样本可以是不同模态（如文本与音频）。DRAGON在线收集生成样本，通过评分构建正负示例集，并利用对比优化奖励。在评估中，我们对音频域文本到音乐扩散模型进行了20种奖励函数的微调，包括自定义音乐美学模型、CLAP分数、Vendi多样性和Frechet音频距离（FAD）。进一步比较了实例级（单曲）和全数据集FAD设置，并消融了多种FAD编码器和参考集。在所有20种目标奖励中，DRAGON平均胜率达81.45%。此外，基于示例集的奖励函数显著提升了生成质量，与基于模型的奖励相当。通过合适的示例集，DRAGON在未使用人类偏好标注的情况下实现了60.95%的人类投票音乐质量胜率。因此，DRAGON展示了设计和优化奖励函数以提升人类感知质量的新方法。音频示例见https://ml-dragon.github.io/web。

</details>


### [178] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
**中文标题：探索低资源音乐生成中适配器设计的权衡**

*Atharva Mehta,Shivam Chauhan,Monojit Choudhury*

主要分类: cs.SD

摘要简述: 本文研究了在低资源音乐生成任务中，不同适配器设计对模型性能的影响，发现卷积适配器擅长捕捉局部音乐细节，而Transformer适配器更适合处理长程依赖。中等规模的适配器（40M参数）在表达力和质量之间取得最佳平衡。


<details>
  <summary>详细信息</summary>
研究动机: 大型音乐生成模型（如MusicGen和Mustango）的微调计算成本高昂，而参数高效微调（PEFT）技术（如适配器方法）能以较少的可训练参数实现模型适应。然而，适配器的设计选择（如架构、位置和大小）繁多，且缺乏针对低资源音乐类型的最优组合研究。本文旨在填补这一空白。

研究方法: 研究针对两种AI音乐模型（MusicGen和Mustango）和两种音乐类型（印度斯坦古典音乐和土耳其Makam音乐），测试了多种适配器配置，包括卷积和Transformer架构，并分析了不同规模适配器的计算资源需求。

研究结果: 结果显示，卷积适配器擅长捕捉局部音乐细节（如装饰音和短旋律），而Transformer适配器更适合处理长程依赖（如结构化即兴演奏）。中等规模适配器（40M参数）在表达力和质量之间表现最佳。Mustango生成多样性更高但稳定性较差，而MusicGen训练更快且质量更高。

研究结论: 适配器设计对低资源音乐生成任务至关重要，不同架构和规模的适配器各有优劣。中等规模适配器是平衡表达力和质量的理想选择。Mustango和MusicGen在生成多样性和效率上各有特点，需根据任务需求选择。

中文摘要: 微调大型音乐生成模型（如MusicGen和Mustango）是一个计算成本高昂的过程，通常需要更新数十亿参数，因此需要大量硬件资源。参数高效微调（PEFT）技术，尤其是基于适配器的方法，成为一种有前景的替代方案，能够以最少的可训练参数实现模型适应，同时保持性能。然而，适配器的设计选择（如架构、位置和大小）繁多，且尚不清楚哪些组合能为特定低资源音乐类型生成最优适配器及其原因。本文通过研究两种AI音乐模型（MusicGen和Mustango）在两种音乐类型（印度斯坦古典音乐和土耳其Makam音乐）上的多种适配器配置，试图回答这一问题。

我们的研究揭示了明显的权衡：基于卷积的适配器擅长捕捉细粒度的局部音乐细节（如装饰音和短旋律），而基于Transformer的适配器更擅长保留对结构化即兴演奏至关重要的长程依赖。此外，我们分析了不同规模适配器的计算资源需求，证明中等规模适配器（40M参数）在表达力和质量之间实现了最佳平衡。进一步发现，基于扩散的模型Mustango生成更多样化的输出，且更符合输入提示的描述，但在音符稳定性、节奏对齐和美学上表现不足，且训练时间显著更长。相比之下，自回归模型如MusicGen训练更快、效率更高，生成质量更好，但输出冗余略高。

</details>


### [179] [A Hierarchical Deep Learning Approach for Minority Instrument Detection](https://arxiv.org/abs/2506.21167)
**中文标题：一种用于少数乐器检测的分层深度学习方法**

*Dylan Sechet,Francesca Bugiotti,Matthieu Kowalski,Edouard d'Hérouville,Filip Langiewicz*

主要分类: cs.SD

摘要简述: 本文提出了一种分层深度学习方法，用于检测少数乐器活动，通过结合Hornbostel-Sachs分类体系，在MedleyDB数据集上验证了模型的有效性，填补了细粒度乐器识别与组别识别之间的空白。


<details>
  <summary>详细信息</summary>
研究动机: 音乐信息检索中，乐器活动的识别对音乐分类和发现至关重要。然而，现有深度学习方法主要关注数据量充足的乐器类别，而忽略了少数乐器的检测。本文旨在通过分层分类方法解决这一问题。

研究方法: 基于Hornbostel-Sachs分类体系，提出了一种分层深度学习方法，并在MedleyDB数据集上进行评估。研究测试了多种策略，将分层结构整合到模型中，并探索了新的分层音乐预测模型。

研究结果: 实验表明，该方法在粗粒度乐器检测上表现更可靠，同时填补了细粒度乐器识别与组别识别之间的空白。

研究结论: 本研究通过分层分类方法提升了少数乐器检测的可靠性，为音乐信息检索领域的进一步研究奠定了基础。

中文摘要: 识别音频片段中的乐器活动在音乐信息检索中至关重要，对音乐分类和发现具有重要意义。现有的深度学习研究主要集中在数据量充足的乐器类别上。最近的研究表明，分层分类方法可用于检测管弦乐中的乐器活动，即使在乐器级别的细粒度标注有限的情况下。基于Hornbostel-Sachs分类体系，本研究在MedleyDB数据集上评估了这种分层分类系统，该数据集以其多样性和丰富的乐器及音乐类型而闻名。本文提出了多种策略将分层结构整合到模型中，并测试了一类新的分层音乐预测模型。通过填补细粒度乐器识别与组别识别之间的空白，本研究展示了更可靠的粗粒度乐器检测方法，为该领域的进一步发展铺平了道路。

</details>


### [180] [Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou](https://arxiv.org/abs/2506.21269)
**中文标题：整合车辆声学数据以增强城市交通管理：苏州速度分类研究**

*Pengfei Fan,Yuli Zhang,Xinheng Wang,Ruiyuan Jiang,Hankang Gu,Dongyao Jia,Shangbo Wang*

主要分类: cs.SD

摘要简述: 本研究提出并公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并采用双模态特征融合深度卷积神经网络（BMCNN）建模车辆噪声与行驶速度的关联。实验表明，BMCNN在SZUR数据集和公开IDMT-Traffic数据集上分别达到87.56%和96.28%的分类准确率，验证了其在智能交通管理中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 城市交通管理中，车辆速度的实时监测对优化交通流和减少噪声污染至关重要。然而，传统方法依赖视觉或传感器数据，成本高且易受环境影响。本研究旨在通过声学数据开发一种高效、低成本的速度分类方法，为智能城市交通管理提供支持。

研究方法: 研究提出双模态特征融合深度卷积神经网络（BMCNN），通过自适应去噪和归一化预处理抑制环境干扰，并行提取MFCC和小波包能量特征，并利用跨模态注意力机制融合特征，充分利用时频信息。

研究结果: BMCNN在SZUR数据集上分类准确率达87.56%，在IDMT-Traffic数据集上达96.28%。消融实验和鲁棒性测试验证了各模块对性能提升和过拟合抑制的贡献。

研究结论: 基于声学的速度分类方法可集成到智能城市交通管理系统中，实现实时噪声监测和速度估计，优化交通流控制，减少噪声污染，支持可持续城市规划。

中文摘要: 本研究提出并公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），配套全面的数据采集协议和标注指南，以确保实验流程的透明性和可重复性。为建模车辆噪声与行驶速度的耦合关系，我们提出了一种双模态特征融合深度卷积神经网络（BMCNN）。在预处理阶段，采用自适应去噪和归一化策略抑制环境背景干扰；在网络架构中，并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，随后通过跨模态注意力机制在中间特征空间融合，以充分利用时频信息。实验结果表明，BMCNN在SZUR-Acoustic数据集上的分类准确率为87.56%，在公开的IDMT-Traffic数据集上为96.28%。消融研究和苏州数据集的鲁棒性测试进一步验证了各模块对性能提升和过拟合抑制的贡献。所提出的基于声学的速度分类方法可集成到智能城市交通管理系统中，实现实时噪声监测和速度估计，从而优化交通流控制、减少路边噪声污染，并支持可持续城市规划。

</details>


### [181] [SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture](https://arxiv.org/abs/2506.21478)
**中文标题：SmoothSinger：一种基于多分辨率架构的条件扩散模型用于歌唱声音合成**

*Kehan Sui,Jinxu Xiang,Fang Jin*

主要分类: cs.SD

摘要简述: SmoothSinger是一种基于条件扩散模型的歌唱声音合成方法，通过多分辨率架构和参考引导的双分支设计，直接优化低质量音频，避免了传统两阶段流程的失真问题，显著提升了合成声音的自然度和表现力。


<details>
  <summary>详细信息</summary>
研究动机: 歌唱声音合成（SVS）需要精确建模音高、时长和发音，但现有扩散模型在SVS中因复杂的声学和音乐特性而面临挑战，常导致自然度下降。本文旨在通过直接优化低质量音频，避免传统两阶段流程的失真，提升合成质量。

研究方法: SmoothSinger采用参考引导的双分支架构，以低质量音频为参考指导去噪过程，并通过并行低频上采样路径增强U-Net，更好地捕捉音高轮廓和长期频谱依赖。训练时用退化的真实音频替代参考音频，解决时间不匹配问题。

研究结果: 在Opencpop数据集上的实验表明，SmoothSinger在客观和主观评估中均达到最优性能，消融研究证实其有效减少伪影并提升合成声音的自然度。

研究结论: SmoothSinger通过统一框架直接优化低质量音频，结合多分辨率架构和参考引导设计，显著提升了歌唱声音合成的自然度和表现力，为SVS领域提供了新思路。

中文摘要: 歌唱声音合成（SVS）旨在从乐谱中生成富有表现力的高质量人声，需要精确建模音高、时长和发音。尽管扩散模型在图像和视频生成中取得了显著成功，但其在SVS中的应用仍因歌唱的复杂声学和音乐特性而面临挑战，常导致自然度下降的伪影。本文提出SmoothSinger，一种条件扩散模型，用于合成高质量且自然的歌唱声音。与依赖声码器作为最终阶段并常引入失真的传统方法不同，SmoothSinger在统一框架中直接优化低质量合成音频，缓解了两阶段流程的退化问题。该模型采用参考引导的双分支架构，以任何基线系统的低质量音频为参考指导去噪过程，实现更具表现力和上下文感知的合成。此外，它通过并行低频上采样路径增强传统U-Net，使模型更好地捕捉音高轮廓和长期频谱依赖。为提升训练时的对齐性，我们用退化的真实音频替代参考音频，解决参考与目标信号的时间不匹配问题。在Opencpop数据集（大规模中文歌唱语料库）上的实验表明，SmoothSinger在客观和主观评估中均达到最优性能。大量消融研究证实其在减少伪影和提升合成声音自然度方面的有效性。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [182] [IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation](https://arxiv.org/abs/2506.20696)
**中文标题：IMC-PINN-FE：一种基于物理信息神经网络的个性化左心室有限元建模方法，具有图像运动一致性和生物力学参数估计**

*Siyu Mu,Wei Xuan Chan,Choon Hwai Yap*

主要分类: physics.med-ph

摘要简述: 本文提出了一种基于物理信息神经网络（PINN）的框架IMC-PINN-FE，用于快速、个性化且图像一致的心脏生物力学建模。该方法通过结合图像运动一致性和有限元建模，显著提高了计算效率和运动匹配精度。


<details>
  <summary>详细信息</summary>
研究动机: 心肌的生物力学行为对理解心脏生理学至关重要，但传统有限元方法计算成本高且难以准确再现观测到的运动。因此，需要一种高效且精准的建模方法。

研究方法: IMC-PINN-FE首先通过预训练的注意力网络或无监督循环正则化网络从MRI或超声心动图中估计心脏运动，提取运动模式。随后，通过拟合临床压力测量快速估计心肌刚度和主动张力，并基于这些参数进行有限元建模，速度提升75倍。

研究结果: 该方法显著提高了运动匹配精度，平均Dice系数从0.849提升至0.927，同时保持了真实的压力-容积行为。计算时间从传统方法的数小时缩短至数秒。

研究结论: IMC-PINN-FE通过引入材料属性的反向计算和更高的运动保真度，为快速、个性化的心脏生物力学建模提供了高效且稳健的解决方案。

中文摘要: 阐明心肌的生物力学行为对理解心脏生理学至关重要，但无法直接从临床影像中推断，通常需要有限元（FE）模拟。然而，传统有限元方法计算成本高，且难以准确再现观测到的运动。我们提出IMC-PINN-FE，一种结合图像运动一致性（IMC）与有限元建模的物理信息神经网络（PINN）框架，用于个性化左心室（LV）生物力学建模。首先通过预训练的注意力网络或无监督循环正则化网络从MRI或超声心动图中估计心脏运动，并提取运动模式。随后，IMC-PINN-FE通过拟合临床压力测量快速估计心肌刚度和主动张力，计算速度较传统逆向有限元方法从数小时缩短至数秒。基于这些参数，它在整个心动周期内以75倍的速度进行有限元建模。通过运动约束，它更准确地匹配影像位移，平均Dice系数从0.849提升至0.927，同时保持了真实的压力-容积行为。IMC-PINN-FE通过引入材料属性的反向计算和更高的运动保真度，改进了先前的PINN-FE模型。此外，利用单例对象的运动重建形状模式，避免了大数据集的需求，提高了患者特异性。IMC-PINN-FE为快速、个性化且图像一致的心脏生物力学建模提供了一种稳健且高效的方法。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [183] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
**中文标题：基于几何感知扩散和时间视频模型的一致性零样本3D纹理合成**

*Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik*

主要分类: cs.GR

摘要简述: VideoTex是一种新颖的3D纹理合成框架，利用视频生成模型解决空间和时间不一致性问题，结合几何感知条件和UV扩散策略，生成高质量且时间稳定的纹理。


<details>
  <summary>详细信息</summary>
研究动机: 现有纹理合成方法因缺乏全局上下文和几何理解，导致纹理在固定视角下不一致。视频生成模型在时间一致性方面表现优异，因此提出结合两者优势的解决方案。

研究方法: VideoTex框架结合几何感知条件，利用3D网格结构，并提出结构化的UV扩散策略，通过保留语义信息增强遮挡区域的生成，实现更平滑的纹理过渡。

研究结果: 实验表明，VideoTex在纹理保真度、接缝融合和时间稳定性上优于现有方法，适用于动态实时应用。

研究结论: VideoTex通过几何感知和UV扩散策略，显著提升了3D纹理合成的质量和时间一致性，为动态实时应用提供了新可能。

中文摘要: 现有纹理合成方法因缺乏全局上下文和几何理解，导致从固定视角生成的纹理不一致。与此同时，视频生成模型在时间一致性方面取得了显著成功。本文提出VideoTex，一种新颖的无缝纹理合成框架，利用视频生成模型解决3D纹理的空间和时间不一致性问题。我们的方法结合几何感知条件，精确利用3D网格结构，并提出结构化的UV扩散策略，通过保留语义信息增强遮挡区域的生成，从而实现更平滑、更连贯的纹理。VideoTex不仅在UV边界上实现了平滑过渡，还确保了视频帧间高质量、时间稳定的纹理。大量实验表明，VideoTex在纹理保真度、接缝融合和稳定性上优于现有方法，为需要视觉质量和时间一致性的动态实时应用铺平了道路。

</details>


### [184] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
**中文标题：生成块世界：在图片中移动物体**

*Vaibhav Vavilala,Seemandhar Jain,Rahul Vasanth,D. A. Forsyth,Anand Bhattad*

主要分类: cs.GR

摘要简述: 本文提出了一种通过操纵简单几何抽象来编辑生成图像场景的方法，利用3D基元表示场景，支持不同细节层次的编辑，并通过流式生成方法实现高质量的图像生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有技术在编辑生成图像时难以保持纹理一致性和对象身份，且缺乏对不同细节层次编辑的支持。本文旨在解决这些问题，提供更灵活和高质量的图像编辑能力。

研究方法: 方法将场景表示为3D凸基元的组合，支持不同数量的基元表示同一场景。编辑后，通过基于流的生成方法，结合深度和纹理提示生成图像。纹理提示考虑了修改后的3D基元，优于现有技术。

研究结果: 定量和定性实验表明，该方法在视觉保真度、可编辑性和组合泛化能力上优于现有技术，能够准确实现对象和相机移动，并保持对象身份。

研究结论: 本文提出的方法在生成图像的编辑和生成质量上取得了显著提升，为场景编辑提供了更灵活和高效的解决方案。

中文摘要: 我们描述了生成块世界，通过操纵简单的几何抽象来与生成图像的场景交互。我们的方法将场景表示为3D凸基元的组合，同一场景可以用不同数量的基元表示，支持编辑整体结构或小细节。编辑场景几何后，通过基于流的生成方法，结合深度和纹理提示生成图像。我们的纹理提示考虑了修改后的3D基元，优于现有的键值缓存技术提供的纹理一致性。这些纹理提示（a）支持准确的对象和相机移动，（b）在很大程度上保留了对象的身份。定量和定性实验表明，我们的方法在视觉保真度、可编辑性和组合泛化能力上优于现有技术。

</details>


### [185] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
**中文标题：3DGH：具有可组合头发和面部的3D头部生成**

*Chengan He,Junxuan Li,Tobias Kirschstein,Artem Sevastopolsky,Shunsuke Saito,Qingyang Tan,Javier Romero,Chen Cao,Holly Rushmeier,Giljoo Nam*

主要分类: cs.GR

摘要简述: 3DGH是一种无条件生成3D人头模型的生成模型，通过分离头发和面部的建模，实现了可组合的头发和面部组件生成。


<details>
  <summary>详细信息</summary>
研究动机: 以往的研究将头发和面部的建模混为一谈，限制了生成模型的灵活性和编辑能力。3DGH旨在通过分离头发和面部的建模，提供更灵活的可组合性和编辑功能。

研究方法: 3DGH采用基于模板的3D高斯泼溅数据表示，引入可变形头发几何体以捕捉不同发型的几何变化。基于此表示，设计了双生成器的3D GAN架构，并利用交叉注意力机制建模头发与面部的内在关联。通过精心设计的训练目标，在合成渲染数据上进行训练。

研究结果: 实验验证了3DGH的设计选择，并通过定性和定量比较展示了其在无条件全头图像合成和可组合3D发型编辑上的有效性。

研究结论: 3DGH通过分离头发和面部的建模，实现了灵活的可组合性和编辑功能，为3D人头生成提供了新的解决方案。

中文摘要: 我们提出了3DGH，一种无条件生成3D人头的生成模型，具有可组合的头发和面部组件。与以往将头发和面部建模混为一谈的工作不同，我们提出通过基于模板的3D高斯泼溅数据表示分离它们，其中引入了可变形头发几何体以捕捉不同发型的几何变化。基于此数据表示，我们设计了一种基于3D GAN的双生成器架构，并采用交叉注意力机制建模头发与面部的内在关联。模型在合成渲染数据上训练，通过精心设计的训练目标稳定训练并促进头发与面部分离。我们进行了大量实验验证3DGH的设计选择，并通过与多种最先进的3D GAN方法进行定性和定量比较，展示了其在无条件全头图像合成和可组合3D发型编辑上的有效性。更多细节请访问我们的项目页面：https://c-he.github.io/projects/3dgh/。

</details>


### [186] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
**中文标题：FairyGen：从单张儿童绘画生成故事卡通视频**

*Jiayi Zheng,Xiaodong Cun*

主要分类: cs.GR

摘要简述: FairyGen是一个自动系统，能够根据儿童的单张绘画生成故事驱动的卡通视频，并忠实保留其独特的艺术风格。该系统通过解耦角色建模与风格化背景生成，结合电影级镜头设计，实现富有表现力和连贯性的故事叙述。


<details>
  <summary>详细信息</summary>
研究动机: 现有的故事生成方法主要关注角色一致性和基本动作，而FairyGen旨在更全面地解决角色风格保留、背景风格化以及电影级镜头设计的问题，以生成更具表现力和个性化的动画。

研究方法: FairyGen首先使用MLLM生成结构化故事板，描述环境、角色动作和镜头视角。通过风格传播适配器确保视觉一致性，并利用镜头设计模块增强视觉多样性和电影感。角色动画通过3D代理重建和MMDiT图像到视频扩散模型实现，同时采用两阶段运动定制适配器分离身份与运动。

研究结果: 实验表明，FairyGen生成的动画在风格上忠实于原始绘画，叙事结构清晰，动作自然，能够支持个性化和引人入胜的故事动画。

研究结论: FairyGen通过解耦角色与背景风格化、结合电影级镜头设计和运动定制技术，实现了高质量的故事驱动卡通视频生成，为个性化动画创作提供了新工具。

中文摘要: 我们提出了FairyGen，一个从单张儿童绘画自动生成故事驱动卡通视频的系统，同时忠实保留其独特的艺术风格。与以往主要关注角色一致性和基本动作的故事生成方法不同，FairyGen明确解耦了角色建模与风格化背景生成，并融入电影级镜头设计以支持富有表现力和连贯性的故事叙述。给定一张角色草图，我们首先使用MLLM生成结构化故事板，包含环境设置、角色动作和镜头视角的详细描述。为确保视觉一致性，我们引入风格传播适配器，捕捉角色的视觉风格并应用于背景，在合成风格一致的场景时完全保留角色的视觉特征。镜头设计模块通过帧裁剪和多视角合成进一步提升了视觉多样性和电影感。为动画化故事，我们重建角色的3D代理以生成物理合理的动作序列，并用于微调基于MMDiT的图像到视频扩散模型。我们还提出两阶段运动定制适配器：第一阶段从无序帧中学习外观特征，分离身份与运动；第二阶段通过时间步移策略建模时间动态，同时冻结身份权重。训练完成后，FairyGen可直接渲染与故事板对齐的多样且连贯的视频场景。大量实验表明，我们的系统生成的动画在风格上忠实、叙事结构清晰且动作自然，展现了其在个性化和引人入胜的故事动画中的潜力。代码将在https://github.com/GVCLab/FairyGen 提供。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [187] [Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems](https://arxiv.org/abs/2506.20685)
**中文标题：渐进式大小自适应联邦学习：异构多模态数据系统的综合框架**

*Sajid Hussain,Muhammad Sohail,Nauman Ali Khan,Naima Iltaf,Ihtesham ul Islam*

主要分类: cs.LG

摘要简述: 本文提出了一种基于数据集大小特性的渐进式自适应联邦学习框架（SAFL），通过实验揭示了数据集大小对联邦学习效果的影响，并展示了SAFL在多模态数据中的高效性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有联邦学习方法主要关注模型异构性和聚合技术，而忽略了数据集大小特性对训练动态的根本影响。本文旨在填补这一空白，研究数据集大小如何影响联邦学习效果。

研究方法: 提出了一种名为SAFL的渐进式训练框架，根据数据集大小特性组织联邦学习，并在13个多模态数据集上进行实验，涵盖7种数据类型。

研究结果: 实验发现：1）联邦学习的最佳数据集大小为1000-1500样本；2）结构化数据（如时间序列、传感器数据）表现优于非结构化数据（如文本、多模态）；3）超过2000样本的大数据集会导致性能下降。SAFL平均准确率达87.68%，结构化数据准确率超过99%，通信效率高，数据传输量仅为7.38 GB。

研究结论: SAFL填补了数据特性驱动联邦学习策略的研究空白，为实际部署提供了理论和实践指导。

中文摘要: 联邦学习（FL）已成为一种在保护数据隐私的同时实现分布式机器学习的变革性范式。然而，现有方法主要关注模型异构性和聚合技术，很大程度上忽略了数据集大小特性对联邦训练动态的根本影响。本文提出了基于大小的自适应联邦学习（SAFL），这是一种新颖的渐进式训练框架，根据异构多模态数据的数据集大小特性系统地组织联邦学习。我们在涵盖7种模态（视觉、文本、时间序列、音频、传感器、医学视觉和多模态）的13个多样化数据集上进行了全面实验评估，揭示了以下关键发现：1）联邦学习的最佳数据集大小范围为1000-1500样本；2）结构化数据（时间序列、传感器）显著优于非结构化数据（文本、多模态）；3）超过2000样本的大数据集会导致系统性性能下降。SAFL在所有数据集上的平均准确率达到87.68%，结构化数据模态的准确率超过99%。该框架展示了卓越的通信效率，在558次通信中总数据传输量仅为7.38 GB，同时保持高性能。我们的实时监控框架为系统资源利用率、网络效率和训练动态提供了前所未有的洞察。这项工作填补了理解数据特性如何驱动联邦学习策略的关键空白，为神经网络和学习系统中实际联邦学习部署提供了理论见解和实践指导。

</details>


### [188] [Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models](https://arxiv.org/abs/2506.20701)
**中文标题：扩散树采样：扩散模型的可扩展推理时间对齐**

*Vineet Jain,Kusha Sareen,Mohammad Pedramfar,Siamak Ravanbakhsh*

主要分类: cs.LG

摘要简述: 本文提出了一种名为扩散树采样（DTS）的方法，通过将推理时间对齐问题转化为搜索问题，并利用蒙特卡洛树搜索的思想，高效生成奖励对齐的目标分布样本。实验表明，DTS在减少计算量的同时，性能优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的扩散模型在推理时间对齐新目标时存在价值估计不准确和信息未重用的问题，导致计算效率低下。本文旨在解决这些问题，提出一种更高效的推理时间对齐方法。

研究方法: 作者提出扩散树采样（DTS）方法，将推理时间对齐问题转化为搜索问题，通过传播终端奖励并迭代优化价值估计，生成目标分布样本。其贪婪变体DTS$^\star$则用于全局搜索高奖励样本。

研究结果: 在MNIST和CIFAR-10的条件生成任务中，DTS以10倍计算量减少达到最佳基线性能。在文本到图像生成和语言完成任务中，DTS$^\star$以5倍计算量减少匹配最佳样本性能。

研究结论: DTS通过重用历史信息，将额外计算转化为样本质量的持续提升，为扩散模型的推理时间对齐提供了一种可扩展的解决方案。

中文摘要: 在生成建模中，如何将预训练的扩散模型在推理时间对齐新目标仍是一个开放问题。现有方法在高噪声水平下存在价值估计不准确的问题，导致指导偏差，且未重用历史信息以提高样本质量，计算效率低下。受蒙特卡洛树搜索的启发，我们将推理时间对齐问题转化为搜索问题，提出一种基于树的方法，通过传播终端奖励并迭代优化价值估计，生成奖励对齐的目标分布样本。提出的扩散树采样（DTS）方法在无限次生成时渐进精确地采样目标分布，其贪婪变体DTS$^\star$则用于全局搜索高奖励样本。在MNIST和CIFAR-10的条件生成任务中，DTS以10倍计算量减少达到最佳基线性能；在文本到图像生成和语言完成任务中，DTS$^\star$以5倍计算量减少匹配最佳样本性能。通过重用历史信息，我们获得了一种随时可用的算法，将额外计算转化为样本质量的持续提升，为扩散模型的推理时间对齐提供了可扩展的解决方案。

</details>


### [189] [On Convolutions, Intrinsic Dimension, and Diffusion Models](https://arxiv.org/abs/2506.20705)
**中文标题：关于卷积、内在维度和扩散模型**

*Kin Kwan Leung,Rasa Hosseinzadeh,Gabriel Loaiza-Ganem*

主要分类: cs.LG

摘要简述: 本文证明了FLIPD方法在现实假设下的正确性，并扩展了其适用范围，包括均匀卷积的情况。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型（DMs）能够学习低维支撑的分布，但FLIPD方法仅在非现实的仿射子流形假设下被证明正确。本文旨在填补这一理论空白。

研究方法: 通过理论分析，证明了FLIPD方法在现实假设下的正确性，并研究了均匀卷积下的类似结果。

研究结果: FLIPD在现实假设下被证明是正确的，且均匀卷积下也存在类似结果。

研究结论: 本文完善了FLIPD的理论基础，并扩展了其应用范围，为LID估计提供了更全面的支持。

中文摘要: 流形假设认为，高维环境空间中的数据（如图像数据）位于未知的低维子流形上。扩散模型（DMs）通过逐步增加高斯噪声并学习逆转这一过程，成为性能最优的生成模型，并能学习低维支撑的分布。对于这些子流形中的数据，直观上可以认为DMs隐式地学习了其局部内在维度（LID）。Kamkari等人（2024b）最近通过将LID与DM对数边际密度随噪声量的变化率联系起来，证明了这一点，并提出了一种称为FLIPD的LID估计器。LID估计器（如FLIPD）有多种用途，例如量化数据的复杂性，检测异常值、对抗样本和AI生成的文本。FLIPD在LID估计中达到了最先进的性能，但其理论基础不完整，因为Kamkari等人（2024b）仅在高度不现实的仿射子流形假设下证明了其正确性。本文通过在实际假设下正式证明FLIPD的正确性填补了这一空白。此外，我们还证明了在高斯卷积被均匀卷积替代时也存在类似结果，并讨论了这一结果的意义。

</details>


### [190] [Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset](https://arxiv.org/abs/2506.20729)
**中文标题：理论物理中的测试时扩展技术——基于TPBench数据集的方法比较**

*Zhiqi Gao,Tianyi Li,Yurii Kvasiuk,Sai Chaitanya Tadepalli,Maja Rudolph,Daniel J. H. Chung,Frederic Sala,Moritz Münchmeyer*

主要分类: cs.LG

摘要简述: 本文研究了测试时扩展技术在理论物理领域的应用，通过TPBench数据集比较了多种方法的有效性，并提出了一种新型符号弱验证框架，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在复杂推理中表现出色，但测试时扩展技术能否在高级理论物理领域同样有效尚不明确。本文旨在验证这些技术在该领域的适用性，并探索如何利用物理问题的结构提升性能。

研究方法: 在TPBench物理数据集上评估了多种测试时扩展方法，并提出了一种符号弱验证框架，以更好地利用物理问题的结构。同时，在AIME数学数据集上验证了该方法的通用性。

研究结果: 实验结果表明，提出的符号弱验证框架在TPBench上显著优于现有方法，同时在AIME数学问题上也表现出色。

研究结论: 研究证实了逐步符号验证在解决复杂科学问题中的强大能力，为测试时扩展技术在理论物理领域的应用提供了新思路。

中文摘要: 大型语言模型（LLM）在复杂推理中表现出强大的能力，而测试时扩展技术能以较低成本进一步提升其性能。这些方法已在AIME等数学推理基准上得到开发和评估。本文探讨了这些基准的经验是否适用于高级理论物理领域。我们在TPBench物理数据集上评估了一系列常见的测试时扩展方法，并将其效果与AIME上的结果进行了比较。为了更好地利用物理问题的结构，我们开发了一种新型符号弱验证框架，以提升并行扩展效果。实验结果表明，该方法在TPBench上显著优于现有的测试时扩展方法。我们还在AIME上验证了该方法的有效性，证实了其在解决高级数学问题中的优势。研究结果凸显了逐步符号验证在解决复杂科学问题中的潜力。

</details>


### [191] [Stochastic Parameter Decomposition](https://arxiv.org/abs/2506.20790)
**中文标题：随机参数分解**

*Lucius Bushnaq,Dan Braun,Lee Sharkey*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“随机参数分解”（SPD）的新方法，用于解决当前神经网络分解方法中计算成本高和超参数敏感的问题。SPD比现有方法更具可扩展性和鲁棒性，能够分解更大、更复杂的模型，并避免参数收缩等问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前主流的神经网络分解方法（如基于归因的参数分解APD）存在计算成本高和对超参数敏感的问题，限制了其在大规模模型中的应用。本文旨在提出一种更高效、更稳定的分解方法，以推动神经网络机制解释性的研究。

研究方法: 本文提出了随机参数分解（SPD）方法，通过结合因果中介分析和网络分解技术，实现了一种更高效、更鲁棒的参数分解框架。SPD通过随机化技术降低了计算成本，同时提高了对超参数的鲁棒性。

研究结果: 实验表明，SPD能够分解比APD更大、更复杂的模型，并且避免了参数收缩等问题。此外，SPD在玩具模型中更准确地识别了真实机制。

研究结论: SPD通过解决计算成本和超参数敏感性问题，为线性参数分解方法在大规模模型中的应用提供了可能，推动了神经网络机制解释性研究的发展。

中文摘要: 逆向工程神经网络的一个关键步骤是将其分解为可以相对独立研究的更简单部分。线性参数分解是一种被提出的框架，用于解决当前分解方法的若干问题，它将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，当前该框架中的主要方法——基于归因的参数分解（APD）——由于计算成本高和对超参数敏感而不实用。本文提出了随机参数分解（SPD），该方法比APD更具可扩展性和对超参数的鲁棒性。我们通过分解比APD所能处理的更大、更复杂的模型来证明这一点。此外，SPD还避免了其他问题，如学习参数的收缩，并在玩具模型中更好地识别了真实机制。通过将因果中介分析与网络分解方法结合，这一研究为机制解释性领域开辟了新的可能性，消除了线性参数分解方法在大规模模型中应用的障碍。我们在https://github.com/goodfire-ai/spd发布了运行SPD和复现实验的库。

</details>


### [192] [GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization](https://arxiv.org/abs/2506.20807)
**中文标题：GPU内核科学家：一种基于LLM的迭代内核优化框架**

*Martin Andrews,Sam Witteveen*

主要分类: cs.LG

摘要简述: 本文提出了一种基于LLM的自动化方法“GPU Kernel Scientist”，用于迭代优化GPU内核，特别针对缺乏文档的新架构（如AMD MI300），通过多阶段进化过程实现性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 优化GPU内核性能通常需要深厚的架构知识和大量实验，尤其是在新架构或文档不足的硬件上。传统方法效率低下，因此需要一种自动化工具来加速和简化这一过程。

研究方法: 方法分为三阶段：(a) 选择有潜力的旧代码版本作为迭代基础；(b) 基于现有代码和GPU文献生成优化假设；(c) 自动实现实验并通过外部评估系统验证，仅用时序数据作为反馈。

研究结果: 由于性能竞赛的定量结果尚未公开，本文重点介绍了架构设计、工作流程和定性见解，展示了LLM驱动代理在GPU内核优化中的潜力。

研究结论: LLM驱动的自动化方法能够显著加速GPU内核优化，尤其在资源受限或硬件快速演进的场景中，具有广泛的应用前景。

中文摘要: 优化GPU内核以实现高性能是一项复杂的任务，通常需要深入的架构知识、大量分析和迭代实验。这一挑战在针对较新或文档较少的GPU架构时尤为突出，传统开发辅助工具稀缺。本文介绍了一种基于LLM的“GPU内核科学家”，这是一种用于迭代优化加速器内核的自动化方法。

我们的方法采用LLM进行多阶段进化过程：(a) 战略性地选择有潜力的旧代码版本作为新迭代的基础；(b) 基于现有代码和GPU文献生成优化实验假设；(c) 通过代码修改和提交到外部评估系统自主实现这些实验，仅用时序数据作为性能反馈。我们详细说明了该方法如何应对AMD MI300目标架构的挑战，并利用LLM弥补领域特定人类专业知识的不足。

由于性能竞赛的定量结果在提交时尚未公开，我们展示了架构设计、操作流程和定性见解，突出了LLM驱动代理在GPU内核优化中的潜力，特别是在资源受限或硬件快速演进的环境中。

</details>


### [193] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
**中文标题：FINN-GL：用于FPGA加速LSTM的广义混合精度扩展**

*Shashwat Khandelwal,Jakoba Petri-Koenig,Thomas B. Preußer,Michaela Blott,Shreejith Shanker*

主要分类: cs.LG

摘要简述: 本文提出了一种基于FINN框架的广义混合精度扩展方法FINN-GL，用于FPGA加速LSTM部署，解决了现有工具主要针对前馈网络的问题，并通过量化ONNX计算图和硬件映射优化，实现了性能与资源消耗的平衡。


<details>
  <summary>详细信息</summary>
研究动机: LSTM在时间序列任务中表现优异，但其计算复杂度限制了在资源受限环境中的实时部署。FPGA虽为高效AI加速提供了平台，但现有工具主要针对前馈网络，LSTM加速通常需要完全定制实现。本文旨在填补这一空白，通过扩展FINN框架实现LSTM的广义部署。

研究方法: 利用ONNX规范中的Scan算子建模LSTM的循环计算特性，支持混合量化和功能验证；在FINN编译器中引入自定义变换，将量化后的ONNX计算图映射到HLS内核库中的硬件块；通过量化ConvLSTM模型验证工具流程。

研究结果: 生成的量化ConvLSTM加速器在XCZU7EV设备上实现了性能（延迟）与资源消耗的平衡，同时匹配（或优于）现有模型的推理精度。

研究结论: FINN-GL为FPGA上的资源高效RNN加速器设计提供了通用解决方案，有望推动LSTM在资源受限环境中的广泛应用。

中文摘要: 递归神经网络（RNN），尤其是LSTM，在时间序列任务（如情感分析和短期股票预测）中表现优异。然而，其计算复杂度为资源受限环境中的实时部署带来了挑战。尽管FPGA为高效AI加速提供了平台，但现有工具主要针对前馈网络，LSTM加速通常需要完全定制实现。本文通过利用开源且可扩展的FINN框架，填补了这一空白，实现了LSTM在FPGA上的广义部署。具体而言，我们利用ONNX规范中的Scan算子建模LSTM的循环计算特性，支持其内部混合量化和功能验证。此外，我们在FINN编译器中引入自定义变换，将量化后的ONNX计算图映射到FINN编译器和Vitis HLS的HLS内核库中的硬件块。我们通过训练一个用于中期股票预测任务的量化ConvLSTM模型，并使用广泛使用的数据集验证了所提出的工具流程，生成了针对XCZU7EV设备的硬件IP。结果表明，生成的量化ConvLSTM加速器在性能（延迟）与资源消耗之间实现了平衡，同时匹配（或优于）现有模型的推理精度。我们相信，所提出流程的通用性将为FPGA上资源高效的RNN加速器设计铺平道路。

</details>


### [194] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
**中文标题：更精简的训练，更低的泄漏：重新审视LoRA微调中LLM的记忆问题**

*Fei Wang,Baochun Li*

主要分类: cs.LG

摘要简述: 研究发现，LoRA微调显著降低大型语言模型（LLM）的记忆风险，同时保持任务性能，与传统微调方法相比表现出显著差异。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）的记忆行为使其易受数据提取攻击。尽管预训练阶段的记忆问题已被广泛研究，但微调阶段（尤其是LoRA微调）的影响尚未充分探索。

研究方法: 通过重新审视微调中的记忆问题，使用基于相似性的记忆度量标准，比较LoRA微调与传统全参数微调的差异。

研究结果: LoRA微调在减少记忆风险方面表现优于全参数微调，同时任务性能未受影响。模型规模和数据重复等传统影响因素在LoRA微调中表现不同。

研究结论: LoRA微调是一种更安全的参数高效方法，能显著降低记忆风险，为LLM的安全应用提供了新方向。

中文摘要: 大型语言模型（LLM）的记忆行为使其易受数据提取攻击。尽管预训练阶段的记忆问题已被广泛研究，但微调阶段（尤其是LoRA微调）的影响尚未充分探索。本研究重新审视了微调中的记忆问题，并发现不同微调策略之间存在显著差异。模型规模和数据重复等因素在预训练和全参数微调中强烈影响记忆，但在LoRA微调中表现不同。通过使用更宽松的基于相似性的记忆度量标准，我们发现LoRA显著降低了记忆风险，同时仍保持强大的任务性能。

</details>


### [195] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
**中文标题：SharpZO：通过仅前向传播的混合锐度感知视觉语言模型提示调优**

*Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种混合锐度感知零阶优化方法（SharpZO），通过仅使用前向传播优化视觉语言模型（VLM）的提示调优，显著提升了性能和收敛速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型（VLM）微调方法通常依赖反向传播（BP），无法适用于内存受限的仅推理边缘设备。虽然已有一些无需BP的微调方法，但其性能往往不足。本文旨在解决这一问题，提出一种高效的零阶优化方法。

研究方法: SharpZO采用两阶段优化：首先通过锐度感知进化策略（ES）全局探索和平滑损失函数，构建强初始化；随后通过稀疏零阶（ZO）优化进行细粒度局部搜索。整个过程仅需前向传播。

研究结果: 在CLIP模型上的实验表明，SharpZO显著提升了准确性和收敛速度，平均性能比现有仅前向方法高出7%。

研究结论: SharpZO为无需反向传播的视觉语言模型微调提供了一种高效解决方案，显著优于现有方法。

中文摘要: 微调视觉语言模型（VLM）已在多种下游任务中表现出色，但其依赖反向传播（BP）梯度计算，无法适用于内存受限的仅推理边缘设备。为解决这一问题，先前研究探索了多种无需BP的微调方法，但这些方法通常依赖高方差的进化策略（ES）或零阶（ZO）优化，性能往往不佳。本文提出了一种混合锐度感知零阶优化方法（SharpZO），通过锐度感知预热训练提升零阶VLM微调性能。SharpZO采用两阶段优化：首先通过锐度感知ES阶段全局探索和平滑损失函数以构建强初始化，随后通过稀疏ZO优化进行细粒度局部搜索。整个优化过程仅需前向传播。详细的理论分析和在CLIP模型上的广泛实验表明，SharpZO显著提升了准确性和收敛速度，平均性能比现有仅前向方法高出7%。

</details>


### [196] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
**中文标题：利用知识图谱生成高质量指令数据以增强大语言模型的工具使用能力**

*Jingwei Wang,Zai Zhang,Hao Qian,Chunjing Gan,Binbin Hu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Bin Shi,Bo Dong*

主要分类: cs.LG

摘要简述: 本文提出了一种利用知识图谱生成高质量指令数据的新方法，显著提升大语言模型（LLM）的工具使用能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在工具使用上的能力有限，主要由于生成的指令数据质量不足。知识图谱因其丰富的语义信息，成为生成高质量指令数据的理想来源。

研究方法: 通过从知识图谱中提取查询路径，将其转化为多样化的用户查询，并将实体间关系映射为可操作的工具，解析查询路径为详细解决步骤，从而生成高质量指令数据。

研究结果: 实验表明，仅需少量合成数据进行微调，即可显著提升大语言模型的工具使用能力和整体性能。

研究结论: 利用知识图谱生成的高质量指令数据能有效提升大语言模型的工具使用能力，为未来研究提供了新方向。

中文摘要: 教导大语言模型（LLM）使用工具对于提升其问题解决能力和扩展应用场景至关重要。然而，有效使用工具具有挑战性，因其需要对工具功能和用户意图的深入理解。以往方法主要依赖LLM生成指令数据，但这些数据的质量往往不足。本文提出了一种新方法，利用知识图谱为LLM生成高质量指令数据。知识图谱是人工整理的富含语义信息的数据集。我们首先从给定知识图谱中提取多种查询路径，并将其转化为广泛的用户查询。随后，将实体间关系转化为可操作工具，并将每条查询路径解析为详细的解决步骤，从而生成高质量指令数据。实验表明，仅需少量合成数据进行微调，即可显著提升LLM的工具使用能力和整体性能。

</details>


### [197] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
**中文标题：学习跳过Transformer的中间层**

*Tim Lawson,Laurence Aitchison*

主要分类: cs.LG

摘要简述: 本文提出一种动态跳过Transformer中间层的架构，通过门控机制选择性跳过冗余层，旨在提升效率，但实验表明在验证交叉熵与FLOPs的权衡上未优于基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常独立跳过单个模块或层，但研究表明Transformer中间层冗余性较高。本文旨在通过动态跳过中间层块来提升模型效率。

研究方法: 提出一种门控机制，动态跳过对称的中间层块，并采用门控注意力防止后续令牌关注被跳过的位置。通过‘三明治’或‘perilayernorm’方案控制残差范数，并使用自适应正则化损失约束门控稀疏性。

研究结果: 在验证交叉熵与FLOPs的权衡上，该方法未显著优于层数较少的密集基线模型。

研究结论: 尽管动态跳过中间层的设计理论上能提升效率，但在当前实验规模下未能实现预期效果。代码已开源。

中文摘要: 条件计算是提升Transformer效率的常用策略。现有方法通常针对单个模块（如混合专家层）或独立跳过层。然而，可解释性研究表明Transformer中间层冗余性更高，且早期层将信息聚合到令牌位置。基于此，本文提出一种新架构，动态从中间向外跳过可变数量的层。具体而言，学习的门控机制根据输入决定是否绕过对称的中心块，而门控注意力机制防止后续令牌关注被跳过的位置。通过‘三明治’或‘perilayernorm’方案控制残差范数，并通过自适应正则化损失约束门控稀疏性。我们旨在为‘简单’令牌减少计算需求，并可能促进多级表示层次的出现，但在当前实验规模下，该方法在验证交叉熵与估计FLOPs的权衡上未优于层数较少的密集基线。代码发布于https://github.com/tim-lawson/skip-middle。

</details>


### [198] [Omniwise: Predicting GPU Kernels Performance with LLMs](https://arxiv.org/abs/2506.20886)
**中文标题：Omniwise：利用大型语言模型预测GPU内核性能**

*Zixian Wang,Cole Ramos,Muhammad A. Awad,Keith Lowery*

主要分类: cs.LG

摘要简述: Omniwise是一种基于大型语言模型（LLM）的端到端自监督微调管道，用于预测GPU内核性能，无需执行代码或使用分析工具即可预测关键性能指标。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度神经网络（DNN）的快速发展，GPU内核性能预测成为优化AI应用的重要需求。传统方法依赖代码执行或分析工具，效率较低。Omniwise旨在通过LLM实现高效、轻量化的性能预测。

研究方法: Omniwise采用自监督微调管道，利用LLM直接从内核代码预测性能指标（如内存带宽、缓存命中率、GFLOPs等）。该方法模型无关且轻量化，仅需3B参数模型即可实现高精度预测。

研究结果: 在AMD MI250和MI300X架构上，Omniwise的预测结果相对误差在10%以内的比例超过90%。此外，还开发了在线推理服务器和Visual Studio Code插件，方便开发者集成。

研究结论: Omniwise展示了LLM在GPU内核性能预测中的潜力，提供了一种无需代码执行的高效解决方案，显著提升了开发效率。

中文摘要: 近年来，深度神经网络（DNN）的快速发展彻底改变了人工智能，使模型在理解、生成和处理复杂数据方面具备了前所未有的能力。这些强大的架构广泛应用于下游任务，解决了人类难以企及的问题。本文介绍了Omniwise，这是首个端到端、自监督的微调管道，将大型语言模型（LLM）应用于GPU内核性能预测——性能分析中的一项新颖用例。Omniwise与模型无关且轻量化，即使使用仅3B参数的小型模型也能取得优异结果。它可以直接从内核代码预测关键性能指标（如内存带宽、缓存命中率、GFLOPs和算术强度），而无需执行代码或使用分析工具。我们的方法在AMD MI250和MI300X架构上执行的GPU内核中，超过90%的预测相对误差在10%以内。除管道外，我们还开发了在线推理服务器和Visual Studio Code插件，将基于LLM的性能预测无缝集成到开发者工作流程中。

</details>


### [199] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
**中文标题：复杂性感知微调**

*Andrey Goncharov,Daniil Vyazhev,Petr Sychev,Edvard Khalafyan,Alexey Zaytsev*

主要分类: cs.LG

摘要简述: 本文提出了一种基于熵的复杂性感知微调方法，通过将训练数据按复杂性分类，结合监督微调和蒸馏技术，显著提升了小型开源模型的性能，同时减少了数据需求。


<details>
  <summary>详细信息</summary>
研究动机: 通用大型语言模型（LLMs）通常通过监督微调（SFT）提升特定领域性能，但更好的结果需要从更大模型中提取思维链，代价高昂且数据需求大。本文旨在提出一种高效微调方法，仅对复杂性数据使用推理，以降低成本。

研究方法: 通过单标记答案熵将训练数据分为复杂性类别（ROC AUC 0.73），结合监督微调和蒸馏技术对小型开源模型（约30亿参数）进行微调。

研究结果: 该方法显著优于标准监督微调（平均准确率0.55 vs 0.43），与蒸馏性能相当，同时减少62%的数据需求（两者平均准确率均为0.55）。

研究结论: 复杂性感知微调方法在提升性能的同时显著降低了数据需求，为高效微调提供了新思路。代码和数据已公开以促进进一步研究。

中文摘要: 通用大型语言模型（LLMs）通常通过监督微调（SFT）提升特定领域性能。通过从更大模型中提取思维链可以获得更好的结果，但代价是大量昂贵的调用和数据需求。本文提出了一种高效的微调蓝图，仅对通过熵识别的复杂性数据使用推理。具体而言，我们在两个小型开源模型（约30亿参数）上，通过单标记答案熵（ROC AUC 0.73）将训练数据分为复杂性类别，结合监督微调和蒸馏技术进行微调。结果表明，我们的方法显著优于标准监督微调（平均准确率0.55 vs 0.43），并与蒸馏性能相当，同时减少62%的数据需求（两者平均准确率均为0.55）。我们公开了代码和数据，以促进这一方向的进一步研究。

</details>


### [200] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
**中文标题：DiLoCoX：一种低通信的大规模去中心化集群训练框架**

*Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich*

主要分类: cs.LG

摘要简述: DiLoCoX是一种低通信的大规模去中心化集群训练框架，通过结合流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案，显著提升了模型预训练的参数规模和速度。实验证明，DiLoCoX能在1Gbps网络上预训练107B参数的基础模型，相比传统AllReduce方法提速357倍，且模型收敛性能几乎无损。


<details>
  <summary>详细信息</summary>
研究动机: 当前基础模型（尤其是大语言模型）的分布式训练对高通信需求依赖严重，通常需要集中式集群和高速互联网络。然而，这种依赖限制了在慢速网络或去中心化集群上的训练能力。本文旨在解决这一问题，提出一种能够在慢速网络上高效训练超大规模模型（如超过1000亿参数）的去中心化框架。

研究方法: DiLoCoX结合了流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案。通过理论分析，验证了一步延迟重叠和自适应梯度压缩对收敛性的益处。

研究结果: 实验表明，DiLoCoX能够在1Gbps网络上预训练107B参数的基础模型，相比传统AllReduce方法提速357倍，且模型收敛性能几乎无损。这是首个成功应用于超过1000亿参数模型的去中心化训练框架。

研究结论: DiLoCoX通过创新的低通信设计，成功实现了在慢速网络上高效训练超大规模模型的目标，为去中心化集群的大规模模型训练提供了可行方案。

中文摘要: 基础模型（尤其是大语言模型）的分布式训练对通信需求极高，因此高度依赖具有快速可靠互联的集中式集群。我们能否在慢速网络上进行训练，从而释放去中心化集群在处理超过1000亿参数模型时的潜力？本文提出DiLoCoX，一种低通信的大规模去中心化集群训练框架。它结合了流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案，显著提升了模型预训练的参数规模和速度。通过理论分析，我们验证了一步延迟重叠和自适应梯度压缩对收敛性的益处。实验证明，DiLoCoX能够在1Gbps网络上预训练107B参数的基础模型，相比传统AllReduce方法提速357倍，且模型收敛性能几乎无损。据我们所知，这是首个成功应用于超过1000亿参数模型的去中心化训练框架。

</details>


### [201] [LLM-guided Chemical Process Optimization with a Multi-Agent Approach](https://arxiv.org/abs/2506.20921)
**中文标题：基于多智能体框架的LLM引导化学过程优化**

*Tong Zeng,Srivathsan Badrinarayanan,Janghoon Ock,Cheng-Kai Lai,Amir Barati Farimani*

主要分类: cs.LG

摘要简述: 本文提出了一种基于多智能体框架的化学过程优化方法，利用大型语言模型（LLM）智能体自主推断操作约束，并通过协作优化提升效率。该方法在氢化脱烷基化过程中验证了其性能，显著提升了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统化学过程优化方法在操作约束不明确或不可用时效率低下，依赖主观启发式方法。本文旨在通过多智能体框架解决这一瓶颈，实现自主约束推断和高效优化。

研究方法: 采用基于AutoGen的多智能体框架，包括约束生成、参数验证、模拟执行和优化指导等智能体。通过两阶段（自主约束生成和迭代多智能体优化）实现无需预定义操作边界的优化。

研究结果: 在氢化脱烷基化过程中，该方法在成本、产量和产量-成本比等指标上表现优异，计算效率显著提升，收敛速度比网格搜索快31倍，仅需20分钟即可完成。

研究结论: 该方法在操作约束不明确或不可用的场景下具有显著潜力，尤其适用于新兴工艺和改造应用，展现了基于推理的搜索和领域启发式方法的优势。

中文摘要: 化学过程优化对于最大化生产效率和经济效益至关重要。传统方法（如基于梯度的求解器、进化算法和参数网格搜索）在操作约束不明确或不可用时变得不切实际，工程师需依赖主观启发式方法估计可行参数范围。为解决这一约束定义瓶颈，我们提出了一种基于大型语言模型（LLM）智能体的多智能体框架，能够从最小化过程描述中自主推断操作约束，并协作指导优化。我们的AutoGen框架采用OpenAI的o3模型，包含约束生成、参数验证、模拟执行和优化指导等专用智能体。通过两阶段（基于嵌入领域知识的自主约束生成和迭代多智能体优化），该框架无需预定义操作边界。在氢化脱烷基化过程中验证了成本、产量和产量-成本比等指标，结果表明该方法与传统优化方法性能相当，同时计算效率更高，收敛所需迭代次数更少。我们的方法在20分钟内收敛，比网格搜索快31倍。除了计算效率，该框架的推理引导搜索展现了复杂过程理解能力，正确识别了效用权衡并应用了领域启发式方法。这一方法在操作约束不明确或不可用的优化场景中具有显著潜力，尤其适用于新兴工艺和改造应用。

</details>


### [202] [Interpretable Representation Learning for Additive Rule Ensembles](https://arxiv.org/abs/2506.20927)
**中文标题：可加性规则集成的可解释表示学习**

*Shahrzad Behzadimanesh,Pierre Le Bodic,Geoffrey I. Webb,Mario Boley*

主要分类: cs.LG

摘要简述: 本文提出了一种可解释的表示学习方法，通过引入可学习的稀疏线性变换扩展了传统规则集成，提高了模型的表达能力和可解释性。实验表明，该方法在保持测试风险的同时显著降低了模型复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 传统的符号规则集成虽然具有高可解释性，但其依赖于精心设计的输入特征，否则需要增加规则数量和复杂性，从而降低可解释性。本文旨在通过引入可学习的稀疏线性变换，提升模型的表达能力，同时保持可解释性。

研究方法: 本文扩展了经典规则集成，引入了可学习的稀疏线性变换（如$\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$），并基于迭代加权逻辑回归的序列贪婪优化方法进行学习。

研究结果: 实验结果表明，该方法在十个基准数据集上能够高效构建规则集成，其测试风险与现有最优方法相当，同时显著降低了模型复杂度。

研究结论: 通过引入可学习的稀疏线性变换，本文方法在保持模型可解释性的同时提升了表达能力，为可解释的预测模型提供了新的思路。

中文摘要: 小型符号规则的可加性集成提供了可解释的预测模型。传统上，这些集成使用基于单个输入变量$x$和阈值$t$的简单阈值命题$x \geq t$的合取规则条件，几何上表现为轴平行多面体的决策区域。虽然这种形式确保了单个规则的高可解释性，并且可以通过梯度提升方法高效学习，但它依赖于一组精心设计的表达性和理想独立的输入特征，以便少量轴平行区域能够很好地描述目标变量。若缺乏此类特征，要达到足够的准确性需要增加规则数量和复杂性，从而降低模型的可解释性。本文通过引入可学习的稀疏线性变换（如$\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$）扩展了经典规则集成，使得决策区域成为具有斜面的通用多面体。我们提出了一种基于迭代加权逻辑回归的序列贪婪优化学习方法。实验结果表明，该方法在十个基准数据集上高效构建的规则集成，其测试风险与现有最优方法相当，同时显著降低了模型复杂度。

</details>


### [203] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
**中文标题：潜在原型路由：在混合专家中实现近乎完美的负载均衡**

*Jiajie Yang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为潜在原型路由（LPR）的新框架，通过聚类视角重新设计专家路由，显著改善了混合专家（MoE）架构中的负载不平衡问题，实现了近乎完美的负载均衡。


<details>
  <summary>详细信息</summary>
研究动机: 当前混合专家（MoE）系统存在严重的负载不平衡问题，仅有少数专家在训练和推理中被持续激活，导致模型容量和计算资源的严重浪费。本文旨在解决这一问题。

研究方法: 通过聚类视角重新设计专家路由，提出潜在原型路由（LPR）框架，该框架在推广现有方法的同时，促进专家负载的均衡利用，且不影响下游任务性能。

研究结果: 实验表明，LPR将专家负载的基尼系数从0.70降至0.035，最小-最大专家负载比从1e-6提升至0.70，实现了近乎完美的负载均衡。

研究结论: LPR是一种有效的路由框架，显著改善了MoE系统中的负载不平衡问题，为大规模语言模型的高效扩展提供了新思路。

中文摘要: 混合专家（MoE）架构已成为高效扩展大型语言模型（LLM）的关键策略。然而，当前的MoE系统存在严重的负载不平衡问题，仅有少数专家在训练和推理中被持续激活，导致模型容量和计算资源的严重浪费。本文通过聚类视角重新审视专家路由，提出潜在原型路由（LPR），这是一种新型路由框架，既能推广现有方法，又能促进专家负载的均衡利用，且不影响下游任务性能。在多个开源MoE模型（包括DeepSeek-V3、Qwen3-MoE和Mixtral）上的广泛实验表明，LPR将专家负载的基尼系数从0.70降至0.035，最小-最大专家负载比从1e-6提升至0.70，实现了近乎完美的负载均衡。

</details>


### [204] [Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding](https://arxiv.org/abs/2506.20957)
**中文标题：基于多尺度等变图扩散模型的抗体设计与优化以实现精准复合抗原结合**

*Jiameng Chen,Xiantao Cai,Jia Wu,Wenbin Hu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为AbMEGD的端到端框架，通过多尺度等变图扩散模型实现抗体序列与结构的协同设计，显著提升了抗体设计的准确性和功能优化。


<details>
  <summary>详细信息</summary>
研究动机: 当前抗体设计方法在捕捉几何特征和泛化新型抗原界面方面存在不足，导致分子相互作用和结构完整性难以准确维持。本文旨在解决这些问题。

研究方法: AbMEGD结合了多尺度等变图扩散技术，利用几何深度学习整合原子级几何特征和残基级嵌入，确保几何精度和计算效率。

研究结果: 实验表明，AbMEGD在SAbDab数据库中实现了10.13%的氨基酸恢复率提升、3.32%的改进百分比提升，以及CDR-H3区域的均方根偏差减少0.062Å。

研究结论: AbMEGD在抗体序列与结构协同设计中取得了显著成果，为功能优化和结构完整性平衡设立了新基准。

中文摘要: 抗体设计在治疗和诊断开发中仍是一项关键挑战，尤其是针对具有多样化结合界面的复杂抗原。当前计算方法存在两大局限：(1) 捕捉几何特征的同时保持对称性，(2) 泛化新型抗原界面。尽管近期有所进展，这些方法仍难以准确捕捉分子相互作用并维持结构完整性。为解决这些问题，我们提出了AbMEGD，一种端到端框架，整合了多尺度等变图扩散技术以实现抗体序列与结构的协同设计。通过先进的几何深度学习，AbMEGD结合了原子级几何特征与残基级嵌入，捕捉局部原子细节和全局序列-结构相互作用。其E(3)-等变扩散方法确保了几何精度、计算效率以及对复杂抗原的强泛化能力。此外，基于SAbDab数据库的实验表明，与领先的抗体设计模型DiffAb相比，AbMEGD在关键CDR-H3区域的氨基酸恢复率提升了10.13%，改进百分比提高了3.32%，均方根偏差减少了0.062Å。这些结果凸显了AbMEGD在平衡结构完整性与功能优化方面的能力，为序列-结构协同设计和亲和力优化设立了新基准。代码发布于：https://github.com/Patrick221215/AbMEGD。

</details>


### [205] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
**中文标题：通过随机变分子空间推理实现大型语言模型的可扩展贝叶斯低秩适应**

*Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ScalaBL的可扩展贝叶斯低秩适应方法，通过随机变分子空间推理，解决了大型语言模型（LLMs）在不确定性量化中的可扩展性问题。该方法仅需少量额外参数，即可实现与现有技术竞争的性能，并成功应用于迄今为止最大的贝叶斯LLM。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）存在幻觉和校准不足的问题，在高风险领域（如自主系统和医疗）中，不确定性量化至关重要。现有基于贝叶斯深度学习的方法虽然有效，但在扩展到更大的LLMs时面临参数过多的挑战。

研究方法: 本文提出ScalaBL方法，通过在低秩适应（LoRA）参数的r维子空间中进行贝叶斯推理，并利用LoRA参数作为投影矩阵，将子空间样本映射到LLM的完整权重空间。所有参数通过随机变分推断学习。

研究结果: ScalaBL仅需约1000个额外参数，即可实现与现有技术竞争的性能，并成功应用于迄今为止最大的贝叶斯LLM，其基础参数规模是先前工作的四倍。

研究结论: ScalaBL通过低维子空间推理和随机变分推断，显著提升了贝叶斯LLM的可扩展性和效率，为高风险领域的不确定性量化提供了实用解决方案。

中文摘要: 尽管大型语言模型（LLMs）被广泛使用，但它们存在幻觉错误信息和校准不足的问题，这使得对其不确定性量化尤为重要，尤其是在高风险领域（如自主系统和医疗）。先前的研究通过低秩适应（LoRA）参数进行贝叶斯推理，使这一问题更具可行性。然而，这些方法在扩展到更大的LLMs时因需要额外参数而面临挑战。本文提出了一种名为ScalaBL（可扩展贝叶斯低秩适应）的方法，通过在LoRA秩r的r维子空间中进行贝叶斯推理，并将LoRA参数重新用作投影矩阵，将子空间样本映射到LLM的完整权重空间。通过随机变分推断学习所有参数，尽管子空间维度较低，ScalaBL仅需约1000个额外参数即可实现与现有技术竞争的性能。此外，该方法成功应用于迄今为止最大的贝叶斯LLM，其基础参数规模是先前工作的四倍。

</details>


### [206] [Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2506.21039)
**中文标题：严格子目标执行：分层强化学习中可靠的长视野规划**

*Jaebak Hwang,Sanghyeon Lee,Jeongmo Kim,Seungyul Han*

主要分类: cs.LG

摘要简述: 本文提出了一种严格的子目标执行（SSE）框架，通过结构化的高层决策约束和动态路径优化，解决了长视野任务中子目标不可行和规划效率低的问题。


<details>
  <summary>详细信息</summary>
研究动机: 长视野目标导向任务在强化学习中面临奖励稀疏和目标遥远的挑战，现有分层和图基方法存在子目标不可行和规划效率低的缺陷。

研究方法: SSE框架通过结构化约束确保子目标可达性，采用解耦探索策略系统遍历未探索目标区域，并通过动态调整边成本的路径优化提高子目标可靠性。

研究结果: 实验表明，SSE在多种长视野任务中均优于现有目标导向和分层强化学习方法，效率和成功率显著提升。

研究结论: SSE通过严格的子目标执行和动态优化，为长视野任务提供了一种高效可靠的解决方案。

中文摘要: 长视野目标导向任务对强化学习（RL）提出了根本性挑战，尤其是当目标遥远且奖励稀疏时。尽管分层和图基方法提供了部分解决方案，但它们常受限于子目标不可行和规划效率低下。我们提出了严格子目标执行（SSE），一种基于图的分层RL框架，通过结构化约束高层决策来强制单步子目标可达性。为增强探索，SSE采用解耦探索策略，系统遍历目标空间中未充分探索的区域。此外，通过动态调整边成本的失败感知路径优化，根据观察到的低层成功率改进子目标可靠性。在多种长视野基准测试中，SSE在效率和成功率上均优于现有目标导向RL和分层RL方法。

</details>


### [207] [Efficient Skill Discovery via Regret-Aware Optimization](https://arxiv.org/abs/2506.21044)
**中文标题：基于遗憾感知优化的高效技能发现**

*He Zhang,Ming Zhou,Shaopeng Zhai,Ying Sun,Hui Xiong*

主要分类: cs.LG

摘要简述: 本文提出了一种基于遗憾感知优化的高效技能发现方法，通过将技能发现建模为技能生成与策略学习的极小极大博弈，提升了高维环境下的效率和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 现有无监督技能发现方法虽在探索多样性上表现良好，但在高维环境中效率较低。本文旨在通过遗憾感知优化，提升技能发现的效率和多样性。

研究方法: 将技能发现建模为技能生成与策略学习的极小极大博弈，利用遗憾评分衡量策略强度的收敛程度，并通过可学习的技能生成器引导技能发现。为避免退化，技能生成来自可升级的技能生成器群体。

研究结果: 实验表明，该方法在高维环境中效率与多样性均优于基线方法，并在零样本任务中实现了15%的性能提升。

研究结论: 本文提出的遗憾感知优化方法显著提升了技能发现的效率和多样性，尤其适用于高维复杂环境。

中文摘要: 无监督技能发现的目标是在开放式强化学习中学习多样且可区分的行为。现有方法通过纯探索、互信息优化和时间表征学习提升多样性，但在高维环境中效率有限。本文提出将技能发现建模为技能生成与策略学习的极小极大博弈，在时间表征学习基础上引入遗憾感知方法，沿可升级策略强度方向扩展技能空间。核心思想是技能发现与策略学习具有对抗性：策略强度弱的技能需进一步探索，而强度收敛的技能则减少探索。具体实现中，通过遗憾评分策略强度的收敛程度，并用可学习的技能生成器引导技能发现。为避免退化，技能生成来自可升级的技能生成器群体。实验表明，该方法在复杂度和维度各异的环境中均优于基线方法，且在高维环境中实现了15%的零样本性能提升。

</details>


### [208] [FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation](https://arxiv.org/abs/2506.21095)
**中文标题：FeDa4Fair：用于公平性评估的客户端级联邦数据集**

*Xenia Heilmann,Luca Corbucci,Mattia Cerrato,Anna Monreale*

主要分类: cs.LG

摘要简述: 本文介绍了FeDa4Fair，一个用于生成定制化表格数据集的库，旨在评估联邦学习中的公平性方法，并提供了四个具有异质偏见的基准数据集和评估工具。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习（FL）允许多个客户端在不共享私有数据的情况下协作训练模型，但公平性仍是一个关键问题。由于客户端本地数据集的偏见可能影响整个联邦系统，且现有公平性解决方案多关注单一敏感属性，忽略了不同客户端的多样化需求，因此需要更全面的公平性评估工具。

研究方法: 本文提出FeDa4Fair库，用于生成适合评估公平性联邦学习方法的表格数据集；发布了四个具有异质偏见的基准数据集；提供了现成的公平性评估函数。

研究结果: FeDa4Fair库及其配套数据集和工具为公平性联邦学习方法提供了可控的评估环境，支持全局和客户端级别的公平性研究。

研究结论: FeDa4Fair为联邦学习中的公平性研究提供了标准化工具和数据集，填补了现有方法的不足，促进了更全面和可复现的公平性评估。

中文摘要: 联邦学习（FL）允许多个客户端在不共享私有数据的情况下协作训练模型。然而，公平性仍是一个关键问题，因为客户端本地数据集的偏见可能影响整个联邦系统。客户端间异质的数据分布可能导致模型对某些客户端更公平。尽管文献中有多种公平性增强解决方案，但大多数关注单一敏感属性（通常是二元的），忽略了不同客户端的多样化甚至冲突的公平性需求。这种局限性可能影响公平性干预措施对不同客户端的有效性。为了支持更稳健和可复现的联邦学习公平性研究，我们旨在为公平性感知的联邦学习方法提供全局和客户端级别的一致性基准测试。本文的贡献包括：（1）介绍FeDa4Fair，一个用于生成适合评估异质客户端偏见下公平性联邦学习方法的表格数据集的库；（2）发布四个具有异质偏见的基准数据集及相应的公平性缓解方法比较；（3）提供现成的函数用于评估这些数据集的公平性结果。

</details>


### [209] [Interpretable Hierarchical Concept Reasoning through Attention-Guided Graph Learning](https://arxiv.org/abs/2506.21102)
**中文标题：基于注意力引导图学习的可解释分层概念推理**

*David Debot,Pietro Barbiero,Gabriele Dominici,Giuseppe Marra*

主要分类: cs.LG

摘要简述: 本文提出了一种新型概念推理模型H-CMR，通过注意力机制和图学习实现概念和任务预测的可解释性，同时保持高性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前概念模型（CBMs）仅对最终任务预测提供可解释性，而概念预测本身仍依赖黑箱神经网络。为解决这一问题，本文旨在开发一种同时支持概念和任务预测可解释性的模型。

研究方法: 提出H-CMR模型，利用有向无环图建模概念间关系，并通过注意力机制选择逻辑规则，分层预测概念和任务。

研究结果: 实验表明，H-CMR在保持高性能的同时，支持通过概念和模型干预增强人机交互，显著提升推理准确性和训练数据效率。

研究结论: H-CMR通过图学习和注意力机制实现了概念和任务预测的双重可解释性，为可解释AI提供了新思路。

中文摘要: 概念模型（CBMs）是一类通过高层概念解释预测结果的可解释深度学习模型。这些模型首先预测概念，然后利用概念执行下游任务。然而，当前的CBMs仅对最终任务预测提供可解释性，而概念预测本身通常由黑箱神经网络完成。为解决这一局限性，我们提出分层概念记忆推理器（H-CMR），一种新型CBM，为概念和任务预测均提供可解释性。H-CMR通过有向无环图建模概念间关系，其中边表示定义概念的逻辑规则。在推理过程中，H-CMR利用注意力机制选择部分规则，并分层应用于预测所有概念和最终任务。实验结果表明，H-CMR在保持先进性能的同时，支持通过概念和模型干预实现强人机交互。前者可显著提升推理准确性，后者在具备背景知识时可增强训练数据效率。

</details>


### [210] [Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments](https://arxiv.org/abs/2506.21127)
**中文标题：对抗环境中无人机冲突解决的抗脆弱强化学习鲁棒策略切换方法**

*Deepak Kumar Panda,Weisi Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种抗脆弱的强化学习框架，通过动态切换策略应对无人机在对抗环境中的导航冲突，显著提升了适应性和性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着无人机导航自动化的增加，对抗攻击通过传感器操纵利用强化学习的漏洞。现有鲁棒强化学习方法对分布外变化的泛化能力有限，本文旨在解决这一问题。

研究方法: 提出了一种基于折扣汤普森采样（DTS）的动态策略切换机制，通过多臂老虎机模型选择最优策略，以最小化对抗性引起的状态-动作-值分布偏移。

研究结果: 在复杂导航环境中，该方法相比传统鲁棒强化学习方法，表现出更短的导航路径和更高的无冲突轨迹率。

研究结论: 抗脆弱强化学习框架通过动态策略切换有效应对对抗攻击，显著提升了无人机导航的鲁棒性和适应性。

中文摘要: 无人机（UAV）导航自动化的增加使其面临通过传感器操纵利用强化学习（RL）漏洞的对抗攻击。尽管现有鲁棒RL方法旨在缓解此类威胁，但其对最优值分布外变化的泛化能力有限，主要设计用于处理固定扰动。为解决这一局限，本文提出了一种抗脆弱RL框架，通过基于折扣汤普森采样（DTS）的切换机制增强对更广泛分布变化的适应性。该机制动态选择多种鲁棒策略，以最小化对抗性引起的状态-动作-值分布偏移。所提方法首先通过考虑策略空间中的一系列扰动，导出一组多样化的动作鲁棒策略。这些策略随后被建模为多臂老虎机（MAB）问题，其中DTS根据非平稳伯努利奖励最优选择策略，有效适应演化的对抗策略。理论框架还通过优化DTS以最小化分布偏移导致的总体遗憾，实现了对未见对抗攻击的有效适应，从而诱导抗脆弱性。大量数值模拟验证了该框架在复杂导航环境中的有效性，包括多动态三维障碍物和更强的投影梯度下降（PGD）与欺骗攻击。与传统鲁棒非自适应RL方法相比，抗脆弱方法表现出更优的性能，导航路径更短，无冲突导航轨迹率更高。

</details>


### [211] [Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks](https://arxiv.org/abs/2506.21129)
**中文标题：课程引导的抗脆弱强化学习用于观察空间攻击下的安全无人机冲突避免**

*Deepak Kumar Panda,Adolfo Perrusquia,Weisi Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种抗脆弱的强化学习框架，通过逐步增加的对抗性扰动训练无人机导航策略，使其能够适应和抵御观察空间攻击，显著提升了安全性和性能。


<details>
  <summary>详细信息</summary>
研究动机: 在无人机动态空域导航等安全关键系统中，强化学习策略容易受到观察空间中的分布外对抗攻击，导致性能下降或决策不安全。现有策略对此类攻击表现脆弱，亟需一种能够适应和抵御攻击的方法。

研究方法: 提出了一种抗脆弱的强化学习框架，通过模拟攻击者逐步增加观察空间的扰动强度，训练强化学习代理适应更广泛的分布外观察。理论分析了脆弱性，定义了抗脆弱性，并通过Wasserstein距离最小化实现专家指导的批评器对齐。

研究结果: 在无人机冲突避免场景中，抗脆弱策略在投影梯度下降和GPS欺骗攻击下表现优于标准和鲁棒强化学习基线，累积奖励提高15%，冲突事件减少30%。

研究结论: 抗脆弱强化学习在动态威胁环境中具有理论和实践可行性，能够提升决策的安全性和鲁棒性。

中文摘要: 在安全关键系统（如动态空域中的无人机导航）中部署的强化学习策略容易受到观察空间中分布外对抗攻击的影响。这些攻击导致分布偏移，显著降低价值估计，使现有策略变得脆弱。为解决这一问题，我们提出了一种抗脆弱强化学习框架，旨在适应逐步增加的对抗性扰动课程。该框架引入了一个模拟攻击者，逐步增加观察空间的扰动强度，使强化学习代理能够适应更广泛的分布外观察并预测未见过的攻击。我们从理论上描述了脆弱性，将灾难性遗忘定义为随着扰动强度增加而单调发散的价值函数分布。在此基础上，我们将抗脆弱性定义为这种价值偏移的有界性，并推导出稳定遗忘的适应条件。我们的方法通过Wasserstein距离最小化在逐步扰动的观察中迭代实现专家指导的批评器对齐。我们在涉及动态三维障碍物的无人机冲突避免场景中进行了实证评估。结果表明，抗脆弱策略在投影梯度下降和GPS欺骗攻击下始终优于标准和鲁棒强化学习基线，累积奖励提高15%，冲突事件减少30%。这些发现证明了抗脆弱强化学习在动态威胁环境中实现安全和弹性决策的理论和实践可行性。

</details>


### [212] [DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding](https://arxiv.org/abs/2506.21140)
**中文标题：DBConformer：用于EEG解码的双分支卷积Transformer**

*Ziwei Wang,Hongbin Wang,Tianwang Jia,Xingyi He,Siyang Li,Dongrui Wu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DBConformer的双分支卷积Transformer网络，用于EEG信号解码，通过结合时间和空间特征建模，显著提升了性能，同时具有较少的参数量和良好的可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的CNN-Transformer混合模型在EEG解码中通常采用串行设计，导致局部和全局特征整合不足，且缺乏显式的通道建模。本文旨在解决这些问题，提出一种更优的双分支结构。

研究方法: DBConformer采用双分支设计：一个时间分支用于建模长程时间依赖，一个空间分支用于提取通道间交互。此外，引入轻量级通道注意力模块，动态分配通道重要性。

研究结果: 在五个运动想象数据集和两个癫痫检测数据集上的实验表明，DBConformer在三种评估设置下均优于10个基线模型，且参数量仅为EEG Conformer的八分之一。可视化结果验证了其生理可解释性。

研究结论: DBConformer在性能和可解释性上均表现出色，为EEG解码提供了可靠且高效的解决方案。代码已开源。

中文摘要: 基于脑电图（EEG）的脑机接口（BCIs）将自发/诱发的神经活动转化为外部通信的控制命令。尽管卷积神经网络（CNNs）仍是EEG解码的主流架构，但其固有的短感受野难以捕捉长程时间依赖和全局通道间关系。近期提出的CNN-Transformer混合模型（Conformers）部分解决了这一问题，但多数采用串行设计，导致局部和全局特征整合不足，且常忽略显式的通道建模。为解决这些限制，我们提出DBConformer，一种专为EEG解码设计的双分支卷积Transformer网络。它集成了一个时间Conformer以建模长程时间依赖，和一个空间Conformer以提取通道间交互，从而同时捕捉EEG信号的时间和空间模式。一个轻量级通道注意力模块通过数据驱动的方式分配通道重要性，进一步优化空间表征。在五个运动想象（MI）数据集和两个癫痫检测数据集上的大量实验表明，DBConformer在三种评估设置下均优于10个竞争性基线模型，且参数量仅为高容量EEG Conformer基线的八分之一。此外，可视化结果证实DBConformer提取的特征具有生理可解释性，并与MI中的感觉运动先验一致。DBConformer的卓越性能和可解释性使其成为稳健且可解释的EEG解码的理想选择。代码已公开于https://github.com/wzwvv/DBConformer。

</details>


### [213] [Linearity-based neural network compression](https://arxiv.org/abs/2506.21146)
**中文标题：基于线性度的神经网络压缩**

*Silas Dobler,Florian Lemmerich*

主要分类: cs.LG

摘要简述: 本文提出了一种基于线性度的神经网络压缩方法，通过合并行为接近线性的神经元层，实现了模型大小的无损压缩，多数情况下可缩减至原模型的1/4。


<details>
  <summary>详细信息</summary>
研究动机: 当前神经网络压缩方法主要通过衡量参数重要性和冗余性来减少不必要的参数。为了进一步提升现有方法的优化效果，本文提出了一种新的压缩思路——基于线性度的压缩，旨在通过合并行为接近线性的神经元层来减少权重。

研究方法: 该方法基于ReLU类激活函数的特性，认为那些几乎总是被激活的神经元行为接近线性，从而可以合并后续层。文中介绍了这种压缩的理论基础，并通过实验验证了其有效性。

研究结果: 实验表明，该方法在多数测试模型上实现了无损压缩，模型大小可缩减至原模型的1/4。此外，该方法与基于重要性的剪枝方法结合时干扰极小，展示了多种压缩技术的成功结合。

研究结论: 本文为一种新型神经网络压缩方法奠定了基础，能够实现更小、更高效的模型。

中文摘要: 在神经网络压缩领域，当前大多数方法通过衡量参数的重要性和冗余性来减少不必要的参数。为了进一步提升已高度优化的现有解决方案，我们提出了一种基于线性度的压缩方法，作为一种新颖的减少神经网络权重的方式。该方法基于以下直觉：对于ReLU类激活函数，那些几乎总是被激活的神经元行为接近线性，从而可以合并后续层。我们介绍了这种压缩的理论基础，并通过实验评估了我们的方法。我们的新方法在多数测试模型上实现了无损压缩，模型大小可缩减至原模型的1/4。将我们的方法应用于已基于重要性剪枝的模型时，发现不同类型的压缩之间干扰极小，展示了多种技术成功结合的可能性。总的来说，我们的工作为一种新型压缩方法奠定了基础，能够实现更小、最终更高效的神经网络模型。

</details>


### [214] [rQdia: Regularizing Q-Value Distributions With Image Augmentation](https://arxiv.org/abs/2506.21367)
**中文标题：rQdia：通过图像增强正则化Q值分布**

*Sam Lerman,Jing Bi*

主要分类: cs.LG

摘要简述: rQdia通过图像增强正则化Q值分布，显著提升了基于像素的深度强化学习性能，在多个任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 在基于像素的深度强化学习中，Q值分布的不稳定性限制了性能。rQdia旨在通过图像增强正则化Q值分布，提升模型的样本效率和长期训练效果。

研究方法: rQdia引入了一个简单的辅助损失函数，通过均方误差（MSE）均衡增强图像的Q值分布，从而正则化Q值分布。该方法适用于多种强化学习算法。

研究结果: 在MuJoCo连续控制任务中，rQdia分别提升了DrQ和SAC在9/12和10/12任务中的性能；在Atari Arcade环境中，提升了Data-Efficient Rainbow在18/26任务中的表现。此外，rQdia首次使基于像素的无模型连续控制性能超过了状态编码基线。

研究结论: rQdia通过图像增强正则化Q值分布，显著提升了强化学习算法的性能，尤其是在样本效率和长期训练方面，为基于像素的强化学习提供了新的解决方案。

中文摘要: rQdia通过增强图像对基于像素的深度强化学习中的Q值分布进行正则化。通过一个简单的辅助损失函数，使用均方误差（MSE）均衡这些分布，rQdia在MuJoCo连续控制套件中分别提升了DrQ和SAC在9/12和10/12任务中的性能，并在Atari Arcade环境中提升了Data-Efficient Rainbow在18/26任务中的表现。改进体现在样本效率和长期训练中。此外，rQdia首次使基于像素的无模型连续控制性能超过了状态编码基线。

</details>


### [215] [Pay Attention to Small Weights](https://arxiv.org/abs/2506.21374)
**中文标题：关注小权重**

*Chao Zhou,Tom Jacobs,Advait Gadhikar,Rebekka Burkholz*

主要分类: cs.LG

摘要简述: 论文提出NANOADAM方法，通过动态更新小权重来优化微调过程，减少资源消耗并提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 微调大型预训练神经网络通常需要大量资源，而传统方法通过限制参数子集进行训练。研究发现，小权重往往与大的梯度相关，尤其在微调场景中更为显著，这启发了动态更新小权重的思路。

研究方法: 提出NANOADAM方法，动态更新小权重，无需梯度计算即可确定参数子集，保留大权重以减少灾难性遗忘风险，并支持更大学习率。

研究结果: 实验表明，NANOADAM在NLP和视觉任务中均能提升泛化性能，同时减少资源消耗。

研究结论: NANOADAM通过动态更新小权重，有效平衡了微调的资源效率和性能，为预训练模型的微调提供了新思路。

中文摘要: 微调大型预训练神经网络通常需要大量内存和计算资源。为缓解这一问题，常见方法是限制训练参数子集。通过分析微调过程中梯度与权重的关系，我们发现一个显著模式：大梯度通常与小权重相关，这种现象在微调场景中比从头训练更为明显。基于此观察，我们提出NANOADAM，动态更新微调过程中的小权重，并具有以下优势：首先，此标准无需梯度计算即可确定参数子集；其次，它保留大权重（这些权重可能编码预训练中学到的关键特征），从而降低灾难性遗忘风险；第三，它支持更大学习率，并在实验中一致表现出更好的泛化性能。我们在NLP和视觉任务中验证了这一点。

</details>


### [216] [Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection](https://arxiv.org/abs/2506.21382)
**中文标题：时间感知图注意力网络在加密货币交易欺诈检测中的应用**

*Zhi Zheng,Bochuan Zhou,Yuping Song*

主要分类: cs.LG

摘要简述: 本文提出了一种增强型时间感知图注意力网络（ATGAT），用于加密货币交易欺诈检测，通过融合多尺度时间差特征和周期性位置编码、构建时间感知三重注意力机制以及使用加权BCE损失解决类别不平衡问题，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 加密货币交易欺诈检测面临交易模式日益复杂和类别严重不平衡的双重挑战，传统方法依赖人工特征工程且难以捕捉交易网络中的时间和结构依赖关系。

研究方法: 本文设计了三个模块：(1) 高级时间嵌入模块，融合多尺度时间差特征与周期性位置编码；(2) 时间感知三重注意力机制，联合优化结构、时间和全局上下文注意力；(3) 使用加权BCE损失解决类别不平衡问题。

研究结果: 在Elliptic++加密货币数据集上的实验表明，ATGAT的AUC达到0.9130，比传统方法XGBoost提升9.2%，比GCN提升12.0%，比标准GAT提升10.0%。

研究结论: 该方法不仅验证了时间感知和三重注意力机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广至其他时间图异常检测任务。

中文摘要: 加密货币交易欺诈检测面临交易模式日益复杂和类别严重不平衡的双重挑战。传统方法依赖人工特征工程，难以捕捉交易网络中的时间和结构依赖关系。本文提出了一种增强型时间感知图注意力网络（ATGAT），通过三个模块提升检测性能：(1) 设计高级时间嵌入模块，融合多尺度时间差特征与周期性位置编码；(2) 构建时间感知三重注意力机制，联合优化结构、时间和全局上下文注意力；(3) 使用加权BCE损失解决类别不平衡问题。在Elliptic++加密货币数据集上的实验表明，ATGAT的AUC达到0.9130，比传统方法XGBoost提升9.2%，比GCN提升12.0%，比标准GAT提升10.0%。该方法不仅验证了时间感知和三重注意力机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广至其他时间图异常检测任务。

</details>


### [217] [Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach for Efficiency and Low Storage](https://arxiv.org/abs/2506.21465)
**中文标题：优化四阶龙格-库塔方法：一种动态启发式方法以实现高效和低存储**

*Gavin Lee Goodship,Luis Miralles-Pechuan,Stephen O'Sullivan*

主要分类: cs.LG

摘要简述: 本文提出了一种结合遗传算法（GA）和强化学习（RL）的动态启发式方法，用于优化低存储的扩展稳定性龙格-库塔（ESRK）方法，显著提高了计算效率并保持了数值稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 扩展稳定性龙格-库塔（ESRK）方法在科学和工程中的大规模计算问题中至关重要，但传统方法在平衡精度、稳定性和计算效率方面存在挑战，尤其是对于高阶低存储方案。

研究方法: 研究采用了一种混合遗传算法（GA）和强化学习（RL）的方法，通过GA驱动的突变进行搜索空间探索，并结合RL启发的状态转移机制动态优化启发式选择，从而系统性地减少参数，同时保持四阶精度。

研究结果: 在基准问题（如1D和2D Brusselator系统及稳态Navier-Stokes方程）上的测试表明，最优启发式方法比传统ESRK优化过程减少了25%的IPOPT运行时间，同时保持了数值稳定性和精度。

研究结论: 该研究展示了自适应启发式发现在高保真模拟中提高资源效率的潜力，并为低存储龙格-库塔方法在计算流体动力学等领域的应用开辟了新途径。

中文摘要: 扩展稳定性龙格-库塔（ESRK）方法在科学和工程中的大规模计算问题（如天气预报、空气动力学分析和复杂生物建模）中至关重要。然而，平衡精度、稳定性和计算效率仍然具有挑战性，尤其是对于高阶低存储方案。本研究引入了一种结合遗传算法（GA）和强化学习（RL）的混合方法，用于自动发现启发式，优化低存储ESRK方法。与传统依赖手动设计启发式或穷举数值搜索的方法不同，我们的方法利用GA驱动的突变进行搜索空间探索，并通过RL启发的状态转移机制动态优化启发式选择。这实现了参数的系统性减少，同时保持了四阶精度并显著提高了计算效率。提出的GA-RL启发式优化框架在基准问题（包括1D和2D Brusselator系统及稳态Navier-Stokes方程）上进行了严格测试。最优启发式方法比传统ESRK优化过程减少了25%的IPOPT运行时间，同时保持了数值稳定性和精度。这些发现表明，自适应启发式发现能够提高高保真模拟中的资源效率，并拓宽低存储龙格-库塔方法在计算流体动力学、物理模拟等领域的适用性。这项工作为数值方法的启发式优化建立了新范式，为基于深度强化学习和自动机器学习的启发式搜索开辟了进一步探索的途径。

</details>


### [218] [Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems](https://arxiv.org/abs/2506.21502)
**中文标题：过程挖掘驱动的建模与模拟提升信息物理系统的故障诊断能力**

*Francesco Vitale,Nicola Dall'Ora,Sebastiano Gaiardelli,Enrico Fraccaroli,Nicola Mazzocca,Franco Fummi*

主要分类: cs.LG

摘要简述: 本文提出了一种结合多变量时间序列分析、过程挖掘和随机模拟的无监督故障诊断方法，用于提升信息物理系统的故障诊断能力。通过实验验证，该方法在建模、模拟和分类故障行为方面表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 信息物理系统（CPS）的故障诊断对系统可靠性和运行效率至关重要，但传统手动建模方法需要大量领域知识且模型复杂、易出错。因此，需要一种更高效、自动化的故障诊断方法。

研究方法: 方法包括：1）通过多变量时间序列分析检测集体异常；2）将异常转化为结构化事件日志；3）利用过程挖掘提取可解释的过程模型；4）在提取的Petri网中加入时间分布，支持故障行为的随机模拟。

研究结果: 实验使用智能制造领域的Robotic Arm Dataset（RoAD）验证了方法的有效性，成功建模、模拟和分类了CPS中的故障行为，并支持了预测性维护和数字孪生开发。

研究结论: 该方法通过结合多种技术，显著提升了故障诊断的效率和准确性，为工业环境中的预测性维护和数字孪生提供了有力支持。

中文摘要: 信息物理系统（CPS）的故障诊断对于确保系统可靠性和运行效率至关重要，能够准确检测异常并识别其根本原因。然而，手动建模故障行为通常需要大量领域知识，且生成的模型复杂、易出错且难以解释。为解决这一问题，本文提出了一种新颖的无监督故障诊断方法，结合了多变量时间序列中的集体异常检测、过程挖掘和随机模拟。首先，通过多变量时间序列分析从低级传感器数据中检测集体异常；随后，将这些异常转化为结构化事件日志，通过过程挖掘发现可解释的过程模型；最后，在提取的Petri网中加入时间分布，支持故障行为的随机模拟，从而增强根本原因分析和行为理解。该方法在智能制造领域广泛认可的基准数据集Robotic Arm Dataset（RoAD）上进行了验证。实验结果表明，该方法在建模、模拟和分类CPS中的故障行为方面具有显著效果，能够支持预测性维护和工业环境中的数字孪生开发。

</details>


### [219] [mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale](https://arxiv.org/abs/2506.21550)
**中文标题：mTSBench：大规模多变量时间序列异常检测与模型选择基准**

*Xiaona Zhou,Constantin Brif,Ismini Lourentzou*

主要分类: cs.LG

摘要简述: mTSBench是迄今为止最大的多变量时间序列异常检测（MTS-AD）和无监督模型选择基准，涵盖19个数据集中的344个标记时间序列，评估了24种异常检测方法，并揭示了模型选择的重要性及其现有方法的不足。


<details>
  <summary>详细信息</summary>
研究动机: 多变量时间序列异常检测在医疗、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖关系、时间动态性和稀疏的异常标签，仍具挑战性。mTSBench旨在提供一个统一的评估框架，推动自适应异常检测和稳健模型选择的研究。

研究方法: mTSBench构建了一个包含19个数据集、344个标记时间序列的基准，评估了24种异常检测方法，包括基于大语言模型（LLM）的检测器，并系统性地测试了无监督模型选择技术在标准化条件下的表现。

研究结果: 结果表明，没有单一检测器在所有数据集上表现优异，强调了模型选择的重要性。然而，即使是最先进的模型选择方法也远未达到最优，揭示了关键的技术差距。

研究结论: mTSBench为多变量时间序列异常检测和无监督模型选择提供了统一的评估工具，有助于推动未来研究的严谨性和可重复性。

中文摘要: 多变量时间序列异常检测（MTS-AD）在医疗、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖关系、时间动态性和稀疏的异常标签，仍具挑战性。我们推出了mTSBench，这是迄今为止最大的MTS-AD和无监督模型选择基准，涵盖19个数据集中的344个标记时间序列，涉及12个不同的应用领域。mTSBench评估了24种异常检测方法，包括基于大语言模型（LLM）的多变量时间序列检测器，并在标准化条件下系统性地测试了无监督模型选择技术。与先前研究一致，我们的结果证实没有单一检测器在所有数据集上表现优异，凸显了模型选择的重要性。然而，即使是最先进的模型选择方法也远未达到最优，揭示了关键的技术差距。mTSBench提供了一个统一的评估套件，以支持严谨、可重复的比较，并推动自适应异常检测和稳健模型选择的未来发展。

</details>


### [220] [Universal and Efficient Detection of Adversarial Data through Nonuniform Impact on Network Layers](https://arxiv.org/abs/2506.20816)
**中文标题：通过非均匀影响网络层实现对抗数据的通用高效检测**

*Furkan Mumcu,Yasin Yilmaz*

主要分类: cs.LG

摘要简述: 本文提出了一种通用且高效的方法，通过分析对抗样本对不同神经网络层的影响程度来检测对抗数据，该方法轻量且适用于实时处理。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络（DNNs）对对抗性输入设计非常脆弱，现有防御方法要么效果不佳，要么计算效率低。本文旨在提出一种更实用的对抗样本检测方法。

研究方法: 通过训练一个轻量级回归模型，预测深层特征与早期层特征的差异，并利用预测误差检测对抗样本。

研究结果: 实验表明，该方法高效、实时兼容，适用于多种DNN架构和不同领域（如图像、视频和音频）。

研究结论: 该方法在对抗样本检测中表现出高效性和通用性，为实际应用提供了可行的解决方案。

中文摘要: 深度神经网络（DNNs）对有限噪声预算的对抗性输入设计非常脆弱。尽管已有许多通过细微修改原始输入的成功攻击方法，但针对这些攻击的防御技术研究相对不足。现有防御方法要么通过消除扰动影响来提高DNN鲁棒性，要么使用辅助模型检测对抗数据。本研究专注于攻击检测方法，相比鲁棒性方法更具实用性。我们发现现有检测方法要么对最新攻击技术无效，要么计算效率不足以支持实时处理。我们提出了一种新颖的通用高效方法，通过分析攻击对不同DNN层的非均匀影响来检测对抗样本。{我们的方法训练了一个轻量级回归模型，从早期层特征预测深层特征，并利用预测误差检测对抗样本。}通过理论论证和大量实验，我们证明该检测方法高效、实时兼容，适用于任何DNN架构，并可跨领域（如图像、视频和音频）应用。

</details>


### [221] [RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment](https://arxiv.org/abs/2506.21037)
**中文标题：RL-Selector：基于强化学习的冗余评估数据选择方法**

*Suorong Yang,Peijia Li,Furao Shen,Jian Zhao*

主要分类: cs.LG

摘要简述: 本文提出RL-Selector，一种基于强化学习的数据选择方法，通过量化样本冗余性优化训练效率，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代深度学习依赖大规模数据集，但训练成本高且数据冗余严重。现有数据选择方法多为静态评分或预训练模型，忽略了样本选择和训练动态的协同效应。

研究方法: 提出epsilon-sample cover概念量化样本冗余性，将数据选择建模为强化学习过程，通过轻量级RL代理优化选择策略，利用动态数据集分布生成奖励信号。

研究结果: 在多个基准数据集和架构上的实验表明，RL-Selector优于现有方法，所选数据集训练的模型泛化性能更强且训练效率更高。

研究结论: RL-Selector通过动态评估冗余性优化数据选择，显著降低训练成本同时提升模型性能，为高效训练提供新思路。

中文摘要: 现代深度学习架构通常依赖大规模数据集，但训练这些数据集会带来高昂的计算和存储开销。现实数据集往往包含大量冗余，因此需要更高效的数据训练范式。数据选择通过识别最具代表性的样本减少冗余，从而在不影响性能的情况下降低训练成本。现有方法通常依赖静态评分指标或预训练模型，忽略了样本选择及其在训练过程中动态变化的协同效应。我们提出epsilon-sample cover概念，基于样本间关系量化冗余性，捕捉数据集的内在结构。在此基础上，我们将数据选择重新建模为强化学习（RL）过程，并提出RL-Selector，其中轻量级RL代理通过利用从动态数据集分布中衍生的epsilon-sample cover作为奖励信号来优化选择策略。在多个基准数据集和不同架构上的广泛实验表明，我们的方法始终优于现有最先进的基线方法。使用我们选择的数据集训练的模型表现出更强的泛化性能和更高的训练效率。

</details>


### [222] [Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion](https://arxiv.org/abs/2506.21144)
**中文标题：基于双提示优化与交叉融合的个性化联邦学习**

*Yuguang Zhang,Kuangpu Guo,Zhihe Lu,Yunbo Wang,Jian Liang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于双提示学习和交叉融合的个性化联邦学习框架pFedDC，通过全局和局部提示捕捉共享知识和客户端特定语义，解决了数据、计算和通信异构性问题。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在分散客户端上进行协作模型训练时面临数据、计算和通信的异构性挑战，现有方法仅依赖文本提示且忽略了联合标签-域分布变化。

研究方法: 提出pFedDC框架，每个客户端维护视觉和语言模态的全局与局部提示：全局提示捕捉联邦共享知识，局部提示编码客户端特定语义和域特征；设计交叉融合模块自适应整合不同级别提示，生成与客户端数据分布对齐的个性化表示。

研究结果: 在九种异构数据集上的实验表明，pFedDC始终优于现有最优方法。

研究结论: pFedDC通过双提示学习和交叉融合有效解决了联邦学习中的异构性问题，显著提升了模型性能。

中文摘要: 联邦学习（FL）支持在不共享本地数据的情况下跨分散客户端进行协作模型训练，但面临数据、计算和通信的异构性挑战。预训练的视觉语言模型（VLM）凭借其强大的泛化能力和通过提示的轻量级调优，提供了一种有前景的解决方案。然而，现有的联邦提示学习方法仅依赖文本提示，忽略了联合标签-域分布变化。本文提出了一种基于双提示学习和交叉融合的个性化FL框架pFedDC。具体而言，每个客户端在视觉和语言模态上维护全局和局部提示：全局提示捕捉联邦共享的通用知识，而局部提示编码客户端特定的语义和域特征。同时，设计了一个交叉融合模块，自适应地整合不同级别的提示，使模型能够生成与每个客户端独特数据分布对齐的个性化表示。在九种异构数据集上的广泛实验表明，pFedDC始终优于现有最优方法。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [223] [ResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers](https://arxiv.org/abs/2506.21537)
**中文标题：ResQ：一种在模拟里德堡原子量子计算机上实现残差神经网络的新框架**

*Nicholas S. DiBrita,Jason Han,Tirthak Patel*

主要分类: quant-ph

摘要简述: 本文提出了一种名为ResQ的新框架，用于在模拟里德堡原子量子计算机上实现残差神经网络（ResNets），并探讨了量子计算如何加速机器学习中的分类问题。


<details>
  <summary>详细信息</summary>
研究动机: 量子机器学习的研究因量子计算加速机器学习的潜力而迅速发展。然而，基于神经常微分方程（神经ODE）的残差神经网络（ResNets）尚未在量子计算领域得到探索。本文旨在填补这一空白，并展示模拟里德堡原子量子计算机在实现ResNets方面的独特优势。

研究方法: 作者提出ResQ框架，通过优化里德堡原子量子计算机的动力学特性，利用模拟量子神经ODE来解决机器学习中的分类问题。该方法结合了量子计算和神经ODE的优势。

研究结果: 研究结果表明，模拟里德堡原子量子计算机特别适合实现ResNets，ResQ框架能够有效优化量子计算机的动力学特性，从而解决分类问题。

研究结论: 本文展示了量子计算在实现残差神经网络方面的潜力，ResQ框架为量子机器学习提供了一种新的研究方向。

中文摘要: 量子机器学习的研究近期因量子计算加速机器学习的潜力而迅速发展。一个尚未探索的领域是基于神经常微分方程（神经ODE）的残差神经网络（ResNets），其目标是通过常微分方程原理提升神经网络的有效性。本文探讨了模拟里德堡原子量子计算机特别适合ResNets的原因，并介绍了ResQ框架，该框架通过优化里德堡原子量子计算机的动力学特性，利用模拟量子神经ODE解决机器学习中的分类问题。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [224] [Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution](https://arxiv.org/abs/2506.21278)
**中文标题：基于高效球面柯西分布的超球面变分自编码器**

*Lukas Sablica,Kurt Hornik*

主要分类: stat.ML

摘要简述: 本文提出了一种新型变分自编码器（VAE）架构，采用球面柯西（spCauchy）潜在分布，相比传统高斯或von Mises-Fisher（vMF）分布，能更自然地表示方向性数据，避免过正则化，并解决vMF的数值不稳定性问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统VAE使用高斯或vMF潜在分布存在过正则化和数值不稳定性问题，spCauchy分布因其重尾特性和高效参数化，能更好地表示方向性数据并提升训练稳定性。

研究方法: 提出基于球面柯西分布的VAE架构，利用Möbius变换实现高效可微分的重参数化技巧，并通过快速收敛的幂级数计算KL散度，避免数值不稳定问题。

研究结果: spCauchy分布在高维生成建模中表现出色，提供了更灵活的潜在空间表示，同时显著提升了训练的稳定性和效率。

研究结论: 球面柯西分布为VAE提供了一种理论优越且实际高效的潜在分布选择，特别适用于方向性数据的建模。

中文摘要: 我们提出了一种新型变分自编码器（VAE）架构，采用球面柯西（spCauchy）潜在分布。与传统的潜在空间高斯分布或广泛使用的von Mises-Fisher（vMF）分布不同，spCauchy提供了更自然的超球面潜在变量表示，能更好地捕捉方向性数据，同时保持灵活性。其重尾特性避免了过正则化，确保了潜在空间的高效利用，并提供了更具表达力的表示。此外，spCauchy规避了vMF固有的数值不稳定性问题（这些问题源于涉及贝塞尔函数的归一化常数计算），而是通过Möbius变换实现了完全可微分且高效的重参数化技巧，从而实现稳定且可扩展的训练。KL散度可通过快速收敛的幂级数计算，消除了与超几何函数比值评估相关的下溢或溢出问题。这些特性使spCauchy成为VAE的一种引人注目的替代方案，在高维生成建模中兼具理论优势和实际效率。

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [225] [From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting](https://arxiv.org/abs/2506.21246)
**中文标题：从链上到宏观：评估数据源多样性在加密货币市场预测中的重要性**

*Giorgos Demosthenous,Chryssis Georgiou,Eliada Polydorou*

主要分类: q-fin.PM

摘要简述: 本研究探讨了数据源多样性对加密货币市场预测模型性能的影响，通过整合技术指标、链上指标、情感与兴趣指标、传统市场指数及宏观经济指标等多种数据类别，提出了一种新的特征降维算法，显著提升了预测模型的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 加密货币市场的复杂性和波动性使得预测模型需要多样化的数据源以提高准确性。本研究旨在通过整合不同类别的数据，揭示数据源多样性对预测性能的影响，并为开发更精准的预测模型提供理论基础。

研究方法: 研究引入了代表市值前100的加密货币的Crypto100指数，并提出了一种新的特征降维算法，从多样化的数据源中筛选出最具影响力和鲁棒性的特征。通过综合实验，评估了不同数据源对预测模型性能的贡献。

研究结果: 实验结果表明，数据源多样性显著提升了预测模型的性能，尤其是在不同时间尺度上。链上指标对短期和长期预测均至关重要，而传统市场指数和宏观经济指标对长期预测的重要性逐渐增加。

研究结论: 研究揭示了加密货币市场短期和长期驱动因素的重要性，并证明了数据源多样性对提升预测模型准确性的关键作用，为未来开发更精准和鲁棒的预测模型奠定了基础。

中文摘要: 本研究通过整合技术指标、链上指标、情感与兴趣指标、传统市场指数及宏观经济指标等多种数据类别，探讨了数据源多样性对加密货币预测模型性能的影响。我们引入了代表市值前100的加密货币的Crypto100指数，并提出了一种新的特征降维算法，以从多样化的数据源中识别最具影响力和鲁棒性的特征。综合实验表明，数据源多样性显著提升了预测模型在不同时间尺度上的性能。关键发现包括链上指标对短期和长期预测的至关重要性、传统市场指数和宏观经济指标对长期预测的日益重要性，以及利用多样化数据源对模型准确性的显著提升。这些发现有助于揭示加密货币市场的短期和长期驱动因素，并为开发更准确和鲁棒的预测模型奠定了基础。

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [226] [Automatic Reviewers Assignment to a Research Paper Based on Allied References and Publications Weight](https://arxiv.org/abs/2506.21331)
**中文标题：基于相关参考文献和发表权重的科研论文自动评审分配**

*Tamim Al Mahmud,B M Mainul Hossain,Dilshad Ara*

主要分类: cs.DL

摘要简述: 本文提出了一种基于参考文献和作者权重的自动评审分配方法，旨在解决研究论文评审中专家匹配的难题。


<details>
  <summary>详细信息</summary>
研究动机: 随着研究领域的扩展和论文数量的激增，传统人工选择评审专家的方式效率低下且难以确保专业性。本文旨在通过自动化方法高效匹配最佳评审专家。

研究方法: 通过提取论文参考文献中的作者信息，结合网络搜索获取研究关键词，筛选高影响力研究者（基于h指数、i10指数和引用数），并通过排名和筛选确定最佳评审候选人。

研究结果: 该方法能够自动识别并推荐高匹配度的评审专家，显著提升评审效率和质量。

研究结论: 提出的自动化评审分配策略有效解决了评审专家匹配问题，为学术出版提供了高效支持。

中文摘要: 每天有大量研究文档提交至会议、期刊、通讯等各类出版物。这些出版物通常依赖外部专家进行评审，即同行评审，但选择最佳评审专家并非易事。随着新兴领域的涌现和论文数量的剧增，期刊往往只能分配少量评审专家，而这些专家可能无法覆盖所有领域。例如，通信技术领域的论文应由同领域专家评审。因此，高效选择最佳评审专家成为一大挑战。本研究提出并实现了一种新策略，通过自动化程序选择最佳评审专家。每篇论文末尾的参考文献通常来自同一领域。我们首先收集参考文献并统计至少有一篇论文被引用的作者，然后自动从网络提取研究关键词，搜索特定主题的顶尖研究者，统计其h指数、i10指数和引用数，对前n名作者进行排名，并自动访问其主页获取邮箱地址。同时，我们在线检查其合著者和同事，并将其从列表中剔除。最终剩余的n名作者（通常是教授）即为论文的最佳评审候选人。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [227] [CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions](https://arxiv.org/abs/2506.21085)
**中文标题：CovDocker：通过任务、数据集和解决方案对共价药物设计进行基准测试**

*Yangzhe Peng,Kaiyuan Gao,Liang He,Yuheng Cong,Haiguang Liu,Kun He,Lijun Wu*

主要分类: q-bio.BM

摘要简述: CovDocker是一个用于共价药物设计的综合基准，通过分解共价对接过程为三个任务，并利用先进模型建立基线性能，展示了其在预测相互作用位点和分子转化中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有分子对接方法和深度学习模型很少考虑共价键的形成及其相关结构变化，因此需要建立一个更全面的共价对接基准以填补这一空白。

研究方法: 研究将共价对接过程分解为反应位点预测、共价反应预测和共价对接三个任务，并采用Uni-Mol和Chemformer等先进模型建立基线性能。

研究结果: 基准测试表明，CovDocker能准确预测相互作用位点并建模共价结合中的分子转化，验证了其作为共价药物设计研究严格框架的潜力。

研究结论: CovDocker为共价药物设计提供了数据驱动的研究框架，有望加速选择性共价抑制剂的发现，并解决治疗开发中的关键挑战。

中文摘要: 分子对接在预测配体与靶蛋白结合模式中起关键作用，而共价相互作用因形成配体与靶点间的共价键而具有强且持久的结合特性，尤为珍贵。然而，现有对接方法和深度学习模型很少考虑共价键的形成及其相关结构变化。为填补这一空白，我们提出了一个全面的共价对接基准CovDocker，旨在更好地捕捉共价结合的复杂性。我们将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过采用Uni-Mol和Chemformer等先进模型，我们建立了基线性能，并展示了基准在准确预测相互作用位点和建模共价结合中分子转化的有效性。这些结果证实了该基准作为推动共价药物设计研究的严格框架的作用。它强调了数据驱动方法在加速选择性共价抑制剂发现中的潜力，并解决了治疗开发中的关键挑战。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [228] [Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends](https://arxiv.org/abs/2506.20966)
**中文标题：VLA模型后训练与人类运动学习的平行性：进展、挑战与趋势**

*Tian-Yu Xiang,Ao-Qun Jin,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Sheng-Bin Duan,Fu-Chao Xie,Wen-Kai Wang,Si-Cheng Wang,Ling-Yun Li,Tian Tu,Zeng-Guang Hou*

主要分类: cs.RO

摘要简述: 本文从人类运动学习的角度，综述了视觉-语言-动作（VLA）模型的后训练策略，提出了基于环境、任务和体现的三维分类法，并总结了关键挑战与未来趋势。


<details>
  <summary>详细信息</summary>
研究动机: VLA模型在机器人操作任务中展现出广泛泛化能力，但在高精度任务中存在性能差距。本文旨在通过类比人类运动学习，探索后训练策略以提升模型性能。

研究方法: 通过人类运动学习视角，提出三维分类法：增强环境感知、提升体现意识、深化任务理解及多组件整合，系统梳理VLA模型后训练方法。

研究结果: 提出了基于人类学习机制的结构化分类法，总结了当前后训练方法，并指出了未来研究方向的关键挑战与趋势。

研究结论: 本文为VLA模型后训练提供了全面的综述和实用见解，为未来研究建立了概念框架。

中文摘要: 视觉-语言-动作（VLA）模型通过整合动作生成模块扩展了视觉-语言模型（VLM），在机器人操作任务中展现出广泛的泛化能力。然而，高精度应用场景揭示了未经进一步适应的性能差距。多领域证据表明，后训练对基础模型与下游应用的适配至关重要，推动了VLA模型后训练的广泛研究。VLA模型后训练旨在提升模型在特定任务中与环境交互的能力，类似于人类运动技能的习得过程。因此，本文从人类运动学习的视角，围绕环境、体现和任务三个维度，综述了VLA模型的后训练策略。提出了一种结构化分类法，与人类学习机制对应：（1）增强环境感知，（2）提升体现意识，（3）深化任务理解，（4）多组件整合。最后，总结了VLA模型后训练的关键挑战与趋势，为未来研究建立了概念框架。本研究不仅从人类运动学习角度全面概述了当前VLA模型后训练方法，还为VLA模型开发提供了实用见解。（项目网站：https://github.com/AoqunJin/Awesome-VLA-Post-Training）

</details>


### [229] [V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling](https://arxiv.org/abs/2506.21041)
**中文标题：V2X-REALM：基于视觉语言模型的鲁棒端到端协作自动驾驶与自适应长尾建模**

*Junwei You,Pei Li,Zhuoyu Jiang,Zilin Huang,Rui Gan,Haotian Shi,Bin Ran*

主要分类: cs.RO

摘要简述: V2X-REALM提出了一种基于视觉语言模型的框架，通过自适应多模态学习和长尾场景建模，提升协作自动驾驶在复杂环境中的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 在协作自动驾驶中，面对罕见、多样且视觉退化的长尾场景时，确保鲁棒的规划和决策仍是一个关键挑战。

研究方法: V2X-REALM包含三个核心创新：(i) 基于提示的长尾场景生成与评估管道；(ii) 门控多场景自适应注意力模块；(iii) 多任务场景感知对比学习目标。

研究结果: 实验表明，V2X-REALM在复杂驾驶条件下显著优于现有基线，提升了鲁棒性、语义推理、安全性和规划准确性。

研究结论: V2X-REALM通过自适应长尾建模和多模态学习，推动了端到端协作自动驾驶的可扩展性。

中文摘要: 在城市场景中，自动驾驶系统在罕见、多样且视觉退化的长尾场景下实现鲁棒的规划和决策仍是一个根本性挑战。这一问题在协作环境中更为关键，因为车辆和基础设施需要共同感知和推理复杂环境。为解决这一挑战，我们提出了V2X-REALM，这是一个基于视觉语言模型（VLM）的框架，通过自适应多模态学习实现长尾场景下的鲁棒协作自动驾驶。V2X-REALM引入了三项核心创新：(i) 基于提示的长尾场景生成与评估管道，利用基础模型合成车辆和基础设施视角下的真实长尾条件（如雪和雾），高效丰富训练多样性；(ii) 门控多场景自适应注意力模块，利用场景先验调整视觉流以重新校准模糊或损坏的特征；(iii) 多任务场景感知对比学习目标，提升多模态对齐并促进跨场景特征分离性。大量实验表明，V2X-REALM在复杂、挑战性驾驶条件下显著优于现有基线，在鲁棒性、语义推理、安全性和规划准确性方面取得突破，推动了端到端协作自动驾驶的可扩展性。

</details>


### [230] [WorldVLA: Towards Autoregressive Action World Model](https://arxiv.org/abs/2506.21539)
**中文标题：WorldVLA：迈向自回归动作世界模型**

*Jun Cen,Chaohui Yu,Hangjie Yuan,Yuming Jiang,Siteng Huang,Jiayan Guo,Xin Li,Yibing Song,Hao Luo,Fan Wang,Deli Zhao,Hao Chen*

主要分类: cs.RO

摘要简述: WorldVLA是一种自回归动作世界模型，结合了视觉-语言-动作（VLA）模型与世界模型，通过联合优化动作生成与图像预测来提升环境物理学习能力。研究发现自回归动作生成存在误差累积问题，并提出注意力掩码策略以显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有动作模型与世界模型各自独立，缺乏联合优化，限制了动作生成与图像预测的相互增强。WorldVLA旨在通过统一框架解决这一问题，同时探索自回归动作生成中的误差传播问题。

研究方法: WorldVLA整合VLA模型与世界模型，通过动作与图像理解的联合训练预测未来图像并生成动作。针对自回归动作生成的误差累积，提出选择性掩码先前动作的注意力掩码策略。

研究结果: WorldVLA在动作生成与图像预测任务上优于独立模型，验证了联合优化的有效性。注意力掩码策略显著改善了自回归动作生成的性能。

研究结论: WorldVLA展示了动作模型与世界模型联合优化的潜力，注意力掩码策略为自回归动作生成中的误差传播问题提供了有效解决方案。

中文摘要: 我们提出了WorldVLA，一种自回归动作世界模型，将动作与图像的理解和生成统一起来。WorldVLA将视觉-语言-动作（VLA）模型与世界模型整合到一个框架中。世界模型通过结合动作与图像理解预测未来图像，旨在学习环境的物理规律以优化动作生成。同时，动作模型基于图像观察生成后续动作，辅助视觉理解并反过来促进世界模型的图像生成。实验表明，WorldVLA优于独立的动作与世界模型，凸显了两者的相互增强作用。此外，我们发现自回归生成动作序列时，动作模型的性能会下降，这是由于动作预测的泛化能力有限，导致早期动作误差传播至后续动作。为解决这一问题，我们提出了一种注意力掩码策略，在生成当前动作时选择性掩码先前动作，显著提升了动作块生成任务的性能。

</details>


### [231] [Model-Based Real-Time Pose and Sag Estimation of Overhead Power Lines Using LiDAR for Drone Inspection](https://arxiv.org/abs/2506.20812)
**中文标题：基于模型的LiDAR无人机电力线实时姿态与弧垂估计**

*Alexandre Girard,Steven A. Parkison,Philippe Hamelin*

主要分类: cs.RO

摘要简述: 本文提出了一种基于模型的实时姿态和弧垂估计方法，利用LiDAR进行无人机电力线巡检，通过单一几何模型最小化误差，解决了导体点少、检测不稳定和干扰物区分难的问题。


<details>
  <summary>详细信息</summary>
研究动机: 无人机巡检带电电力线简化了流程，但LiDAR检测导体面临挑战：导体点少、检测不稳定、干扰物区分难。本文旨在解决这些问题。

研究方法: 提出一种估计方法，通过单一几何模型表示整个导体阵列，最小化LiDAR测量误差，而非单独跟踪导体。实验验证了其高效性。

研究结果: 实验表明，该方法在部分观测、噪声和异常点下仍能准确跟踪，求解器每帧收敛时间低于50毫秒，且能容忍两倍于有效测量点的异常点。

研究结论: 该方法在复杂环境下表现优异，为无人机电力线巡检提供了高效可靠的解决方案。

中文摘要: 无人机可在电力线带电状态下进行巡检，显著简化了流程。然而，利用机载LiDAR传感器定位所有导体存在挑战：(1)导体表面小，LiDAR光束捕获点少；(2)导体检测不稳定；(3)需区分导体点与树木、塔架等干扰物。本文提出一种估计方法，通过单一几何模型表示整个导体阵列，最小化LiDAR测量误差，而非单独跟踪导体。实验使用电力线无人机巡检数据，表明该方法能准确跟踪，求解器每帧收敛时间低于50毫秒，即使存在部分观测、噪声和异常点。敏感性分析显示，该方法能容忍的异常点数量是有效测量点的两倍。

</details>


### [232] [ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation](https://arxiv.org/abs/2506.20969)
**中文标题：ThermalDiffusion：用于自主导航的视觉到热成像图像转换**

*Shruti Bansal,Wenshan Wang,Yifei Liu,Parv Maheshwari*

主要分类: cs.RO

摘要简述: 本文提出了一种利用条件扩散模型将RGB图像转换为热成像图像的方法，以解决自主导航中热成像数据不足的问题。


<details>
  <summary>详细信息</summary>
研究动机: 自主系统在夜间或恶劣环境（如雾、尘）中依赖热成像相机检测目标，但现有数据集缺乏热成像数据，限制了其应用。本文旨在通过合成热成像数据填补这一空白。

研究方法: 采用条件扩散模型，结合自注意力机制，学习真实物体的热特性，将现有RGB图像转换为热成像图像。

研究结果: 提出的方法能够有效生成合成热成像数据，为自主系统的多模态任务（如场景分割、目标检测）提供支持。

研究结论: 通过合成热成像数据，本文为热成像相机的快速广泛应用提供了可行方案，推动了自主导航技术的发展。

中文摘要: 自主系统依赖传感器感知周围环境，但相机、激光雷达和雷达在夜间或恶劣环境（如雾、尘）中存在局限性。热成像相机通过目标的热特征提供有价值的信息，便于识别温度较高的目标（如人类和车辆）。本文聚焦于热成像相机在机器人学和自动化中的应用，主要障碍是数据不足。尽管已有多种多模态数据集支持自主系统的场景分割、目标检测和深度估计等任务，但热成像数据仍然匮乏。本文提出了一种解决方案，通过合成热成像数据扩充现有数据集，以促进热成像相机的快速广泛应用。我们探索了条件扩散模型的使用，通过自注意力机制学习真实物体的热特性，将现有RGB图像转换为热成像图像。

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [233] [Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation](https://arxiv.org/abs/2506.21154)
**中文标题：基于Transformer的时空反事实结果估计**

*He Li,Haoang Chi,Mingyu Liu,Wanrong Huang,Liyang Xu,Wenjing Yang*

主要分类: stat.ME

摘要简述: 本文提出了一种基于Transformer的时空反事实结果估计框架，相比传统统计模型具有更强的估计能力和泛化性，并通过仿真和真实数据实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界具有时间和空间的维度，而现有的基于经典统计模型的反事实结果估计方法在性能和泛化性上存在局限，因此需要一种更强大的估计框架。

研究方法: 本文提出了一种基于Transformer的时空反事实结果估计框架，该框架在温和假设下具有一致性和渐近正态性。通过仿真实验和真实数据实验验证了方法的有效性。

研究结果: 仿真实验表明，所提出的估计器比基线方法具有更强的估计能力。真实数据实验揭示了哥伦比亚冲突对森林损失的因果效应。

研究结论: 基于Transformer的时空反事实结果估计框架在性能和泛化性上优于传统方法，为因果推断提供了新的工具。

中文摘要: 现实世界天然具有时间和空间的维度，因此估计具有时空属性的反事实结果是一个关键问题。然而，现有方法基于经典统计模型，在性能和泛化性上仍存在局限。本文提出了一种基于Transformer的时空反事实结果估计框架，表现出更强的估计能力。在温和假设下，该框架内的估计器具有一致性和渐近正态性。为验证方法的有效性，我们进行了仿真实验和真实数据实验。仿真实验表明，我们的估计器比基线方法具有更强的估计能力。真实数据实验为哥伦比亚冲突对森林损失的因果效应提供了有价值的结论。源代码可在https://github.com/lihe-maxsize/DeppSTCI_Release_Version-master获取。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [234] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
**中文标题：机器学习的敏捷管理：一项系统映射研究**

*Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski*

主要分类: cs.SE

摘要简述: 本文通过系统映射研究总结了机器学习（ML）敏捷管理的现状，识别了8个关键主题和主要挑战，并指出需要更多实证研究验证现有成果。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习（ML）驱动的系统具有动态性和实验性，传统项目管理方法难以应对。敏捷方法因其灵活性和增量交付特性可能更适合ML开发，但如何有效应用尚不明确。本文旨在梳理ML敏捷管理的最新研究进展。

研究方法: 采用混合搜索策略，结合数据库检索和前后向雪球迭代法，对2008年至2024年间发表的27篇论文进行系统映射研究。

研究结果: 研究识别了8个框架，并将建议和实践分为8个关键主题，如迭代灵活性、创新的ML特定工件和最小可行模型。主要挑战是ML任务的工作量估算。

研究结论: 本研究总结了ML敏捷管理的现状并指出研究空白。尽管已有相关成果，仍需更多实证评估验证其有效性。

中文摘要: [背景] 机器学习（ML）驱动的系统正推动社会数字化转型，但其开发的动态性和实验性对传统项目管理提出了挑战。敏捷方法因其灵活性和增量交付特性可能适合ML开发，但如何有效应用尚不明确。[目标] 本文旨在梳理ML敏捷管理的最新研究进展。[方法] 采用混合搜索策略，结合数据库检索和前后向雪球迭代法，对2008年至2024年间发表的27篇论文进行系统映射研究。[结果] 研究识别了8个框架，并将建议和实践分为8个关键主题，如迭代灵活性、创新的ML特定工件和最小可行模型。主要挑战是ML任务的工作量估算。[结论] 本研究总结了ML敏捷管理的现状并指出研究空白。尽管已有相关成果，仍需更多实证评估验证其有效性。

</details>


### [235] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
**中文标题：通过自动化集成数据生成可靠的健康不良事件图谱（GRAPH-AID）：一种半自动化的本体构建方法**

*Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty*

主要分类: cs.SE

摘要简述: 本文提出了一种用户友好的方法，利用Python和rdflib库支持本体开发，解决了Neo4j数据库与OWL语言无缝集成的挑战，并通过FDA不良事件报告系统数据库展示了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据和知识的快速扩展，采用系统化的本体生成方法变得至关重要。然而，现有方法需要熟悉描述逻辑语法，对许多用户不友好。因此，需要一种更易用的方法来填补这一空白。

研究方法: 本文提出了一种基于Python和rdflib库的半自动化方法，通过自动生成所需的类和公理，实现Neo4j数据库与OWL语言的集成。该方法以FDA不良事件报告系统数据库为例进行了验证。

研究结果: 研究开发了一个Python脚本，能够自动生成本体所需的类和公理，显著简化了集成过程，为药物不良事件数据集的快速增长提供了实用解决方案。

研究结论: 本文提出的方法为快速增长的药物不良事件数据集的本体生成提供了实用工具，支持药物安全监测和公共卫生决策的改进。

中文摘要: 随着数据和知识的迅速扩展，采用系统化的本体生成方法变得至关重要。数据量的每日增长和内容的频繁变化使得存储和检索信息以创建知识图谱的需求日益迫切。先前提出的知识获取与表示方法（KNARM）为解决这些挑战和创建知识图谱提供了系统化途径。然而，遵循该方法凸显了将Neo4j数据库与Web本体语言（OWL）无缝集成的现有挑战。尽管已有尝试将Neo4j数据集成到本体中，但这些方法通常需要理解描述逻辑（DL）语法，这对许多用户来说并不熟悉。因此，需要一种更易用的方法来填补这一空白。本文提出了一种用户友好的方法，利用Python及其rdflib库支持本体开发。我们通过整合美国食品药品监督管理局（FDA）不良事件报告系统（FAERS）数据库创建的Neo4j数据库展示了这一新方法。利用该数据集，我们开发了一个Python脚本，能够自动生成所需的类及其公理，从而简化了集成过程。这一方法为快速增长的不良药物事件数据集的本体生成提供了实用解决方案，支持药物安全监测和公共卫生决策的改进。

</details>


### [236] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
**中文标题：面向实际应用的RAG系统工程：设计、开发与评估**

*Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson*

主要分类: cs.SE

摘要简述: 本文介绍了五种针对真实场景的RAG系统应用，涵盖多个领域，并通过用户评估总结了十二个关键经验教训。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏基于真实用例的RAG系统实证研究，本文旨在填补这一空白，提供实际开发经验和用户评估结果。

研究方法: 开发了五个领域特定的RAG系统，结合多语言OCR、语义检索和领域适配LLM，并通过100名参与者的网络评估验证系统性能。

研究结果: 用户评估显示系统在易用性、相关性、透明度等方面表现良好，同时总结了影响RAG系统可靠性和可用性的十二个关键挑战。

研究结论: RAG系统在真实应用中具有潜力，但仍需解决技术、操作和伦理挑战以提高其可靠性和用户体验。

中文摘要: 检索增强生成（RAG）系统正成为将大型语言模型（LLM）与外部知识结合的关键方法，以解决事实准确性和上下文相关性的问题。然而，目前缺乏基于真实用例的RAG系统实证研究，这些研究应通过用户参与评估并系统记录经验教训。本文介绍了五种针对治理、网络安全、农业、工业研究和医疗诊断等真实场景的RAG应用。每个系统结合了多语言OCR、基于向量嵌入的语义检索和领域适配的LLM，并通过本地服务器或云API部署以满足不同用户需求。基于100名参与者的网络评估，系统在六个维度（易用性、相关性、透明度、响应性、准确性和推荐可能性）上进行了评估。根据用户反馈和开发经验，我们总结了十二个关键经验教训，突出了影响RAG系统可靠性和可用性的技术、操作和伦理挑战。

</details>


### [237] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
**中文标题：基于不确定人类指导的强化学习复杂模型转换方法**

*Kyanna Dagenais,Istvan David*

主要分类: cs.SE

摘要简述: 本文提出了一种基于强化学习（RL）和不确定人类指导的复杂模型转换（MT）开发方法，通过将用户定义的MT映射到RL原语并执行RL程序，显著提高了RL性能，实现了更高效的复杂MT序列开发。


<details>
  <summary>详细信息</summary>
研究动机: 模型驱动工程中的复杂模型转换（如模型同步、自动修复和设计空间探索）通常需要大量串联的MT序列，手动开发既易出错又不可行。强化学习虽能缓解这一问题，但在复杂问题中表现不佳，因此需要引入人类指导以提升性能。

研究方法: 本文提出了一种技术框架，将用户定义的MT映射到RL原语，并通过执行RL程序来寻找最优MT序列。该方法结合了不确定的人类建议，通过权衡建议的确定性和及时性，优化RL驱动的工程方法。

研究结果: 评估表明，即使人类建议存在不确定性，也能显著提升RL性能，并更高效地开发复杂MT序列。

研究结论: 本文方法为RL驱动的人机协同工程方法迈出了重要一步，通过结合人类指导与RL，实现了复杂MT序列的高效开发。

中文摘要: 模型驱动工程问题通常需要复杂的模型转换（MT），即需要串联大量MT序列。典型的例子包括模型同步、自动模型修复和设计空间探索。手动开发复杂MT既易出错又往往不可行。强化学习（RL）是缓解这些问题的合适方法。在RL中，自主代理通过试错探索状态空间，以识别有益的动作序列（如MT）。然而，RL方法在复杂问题中表现不佳。在这种情况下，人类指导具有很高的实用性。本文提出了一种方法和技术框架，通过RL开发复杂MT序列，并结合可能不确定的人类建议。我们的框架允许将用户定义的MT映射到RL原语，并作为RL程序执行以寻找最优MT序列。评估表明，即使人类建议不确定，也能显著提升RL性能，并更高效地开发复杂MT。通过权衡人类建议的确定性和及时性，我们的方法为RL驱动的人机协同工程方法迈出了一步。

</details>


### [238] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
**中文标题：合成需求的质量如何？评估LLM生成的数据集在AI4RE中的应用**

*Abdelkarim El-Hajjami,Camille Salinesi*

主要分类: cs.SE

摘要简述: 本文提出Synthline v1方法，通过优化提示策略和生成后处理技术提升合成需求数据的质量，评估其在多个分类任务中的表现，结果显示合成数据在某些任务中优于人工数据。


<details>
  <summary>详细信息</summary>
研究动机: 公开标记的需求数据集稀缺阻碍了人工智能在需求工程（AI4RE）中的发展。尽管大语言模型在合成数据生成方面具有潜力，但如何系统控制和优化生成需求质量的研究仍不足。

研究方法: 本文提出Synthline v1方法，扩展了早期版本，采用多样本提示、自动提示优化（PACE）和生成后相似性筛选技术，评估其在缺陷检测、功能与非功能分类、质量与非质量分类及安全与非安全分类任务中的表现。

研究结果: 多样本提示显著提升数据的实用性和多样性（F1分数提高6至44分）；PACE优化在功能分类任务中表现突出（提升32.5分），但在其他任务中效果不佳；相似性筛选增加多样性但可能降低分类性能。合成数据在安全和缺陷分类任务中优于人工数据（分别提升7.8和15.4分）。

研究结论: 合成需求数据在特定任务中可媲美或超越人工数据，为AI4RE提供了缓解数据集稀缺的可行路径，并揭示了优化生成策略的重要性。

中文摘要: 公开可用的标记需求数据集的短缺是推动人工智能在需求工程（AI4RE）中发展的主要障碍。尽管大语言模型在合成数据生成方面展现出潜力，但如何系统控制和优化生成需求质量的方法仍未充分探索。本文提出Synthline v1，一种改进的产品线方法，用于生成合成需求数据，通过高级生成策略和筛选技术扩展了早期版本。我们研究了四个研究问题，评估提示策略、自动提示优化和生成后筛选如何影响四种分类任务（缺陷检测、功能与非功能、质量与非质量、安全与非安全）的数据质量。评估显示，多样本提示显著提升了实用性和多样性（F1分数提高6至44分）；使用PACE（提示演员-评论家编辑）进行自动提示优化结果因任务而异，功能分类表现大幅提升（+32.5分），但其他任务表现下降。有趣的是，基于相似性的筛选提高了多样性，但常损害分类性能，表明一定冗余可能有助于机器学习模型。最重要的是，结果显示合成需求在特定任务中可媲美或超越人工数据，合成数据在安全（+7.8分）和缺陷分类（+15.4分）任务中优于人工数据。这些发现为AI4RE提供了实用见解，并通过系统合成生成缓解数据集稀缺问题开辟了可行路径。

</details>


### [239] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
**中文标题：$T^3$：基于多层次树形结构的大型语言模型自动程序修复框架**

*Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li*

主要分类: cs.SE

摘要简述: 本文提出了一种名为$T^3$的多层次树形自动程序修复框架，结合大型语言模型（LLMs）和树搜索技术，显著提升了自动程序修复（APR）任务的精度和效率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）和思维链（CoT）技术在推理能力上有显著进步，但在自动程序修复（APR）领域的应用仍显不足，尤其是面对复杂逻辑和多步推理需求时。因此，本文旨在通过系统评估CoT技术在APR任务中的表现，并提出一种创新框架$T^3$，以优化修复解决方案的生成。

研究方法: 本文提出了一种名为$T^3$的框架，将大型语言模型（LLMs）的强大推理能力与树搜索技术相结合，通过多层次树形结构生成候选修复方案，并优化样本选择和修复策略。

研究结果: 实验表明，$T^3$框架显著提高了自动程序修复（APR）任务的精度，同时为样本选择和修复策略的优化提供了有效指导。

研究结论: $T^3$框架不仅提升了自动程序修复（APR）的效率，还为未来研究提供了一个强大的基础框架，推动了自动化调试技术的发展。

中文摘要: 自动程序修复（APR）是软件开发和维护中的核心技术，旨在通过最小化人工干预实现缺陷的自动化修复。近年来，大型语言模型（LLMs）和思维链（CoT）技术的显著进步极大提升了模型的推理能力。然而，由于APR任务需要复杂的逻辑和多步推理能力，CoT技术在该领域的应用仍显不足。本研究系统评估了多种常见CoT技术在APR任务中的表现，并提出了一种创新框架$T^3$，该框架将LLMs的强大推理能力与树搜索技术相结合，有效提升了生成候选修复方案的精度。此外，$T^3$还为APR任务中的样本选择和修复策略优化提供了宝贵指导，为实现高效自动化调试建立了稳健的框架。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [240] [ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data](https://arxiv.org/abs/2506.20673)
**中文标题：ClusterRCA：基于多模态数据的高性能计算系统网络故障诊断**

*Yongqian Sun,Xijie Pan,Xiao Xiong,Lei Tao,Jiaju Wang,Shenglin Zhang,Yuan Yuan,Yuqi Li,Kunlin Jian*

主要分类: cs.DC

摘要简述: 本文提出ClusterRCA框架，通过多模态数据定位高性能计算系统中的网络故障节点和类型，结合分类器和图方法，实验证明其高准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 高性能计算（HPC）系统中的网络故障诊断因数据异构性和准确性不足而具有挑战性，现有方法难以直接适用，亟需新解决方案。

研究方法: ClusterRCA从拓扑连接的NIC对中提取特征，结合分类器和图方法，构建故障图并通过定制随机游走定位根因。

研究结果: 实验表明，ClusterRCA在HPC系统中诊断网络故障的准确性高，且在不同应用场景下表现稳健。

研究结论: ClusterRCA为HPC系统提供了一种高效、准确的网络故障诊断方法，具有广泛适用性。

中文摘要: 网络故障诊断对高性能计算（HPC）系统至关重要，但由于数据异构性和准确性不足，现有方法难以直接应用于HPC场景。本文提出了一种名为ClusterRCA的新框架，通过利用多模态数据定位故障节点并确定故障类型。ClusterRCA从拓扑连接的网络接口控制器（NIC）对中提取特征，以分析HPC系统中的多样化多模态数据。为了准确定位故障节点和确定故障类型，ClusterRCA结合了基于分类器和基于图的方法。根据状态分类器的输出构建故障图，然后通过定制随机游走定位根因。在顶级全球HPC设备供应商收集的数据集上的实验表明，ClusterRCA在HPC系统网络故障诊断中具有高准确性，且在不同应用场景下保持稳健性能。

</details>


### [241] [Utility-Driven Speculative Decoding for Mixture-of-Experts](https://arxiv.org/abs/2506.20675)
**中文标题：基于效用驱动的混合专家推测解码**

*Anish Saxena,Po-An Tsai,Hritvik Taneja,Aamer Jaleel,Moinuddin Qureshi*

主要分类: cs.DC

摘要简述: GPU内存带宽是低延迟大型语言模型（LLM）推理的主要瓶颈。传统密集LLM中，推测解码通过轻量级草稿器提出K个令牌并由LLM并行验证，提升令牌吞吐量。然而，混合专家（MoE）模型中，推测解码因激活更多权重导致数据移动和验证时间增加2-3倍，甚至可能造成1.5倍的减速。本文提出Cascade框架，动态选择推测解码并调整K值，避免减速并提升吞吐量7-14%。


<details>
  <summary>详细信息</summary>
研究动机: GPU内存带宽限制了低延迟LLM推理的性能。推测解码在密集LLM中有效，但在MoE模型中因激活更多权重而效率低下，甚至导致减速。因此，需要一种方法在MoE中动态启用和优化推测解码。

研究方法: 提出Cascade框架，通过轻量级指标“推测效用”（令牌增益与验证成本的比率）动态决策是否启用推测解码，并选择最优K值。框架分为测试和设置阶段，根据效用值调整策略。

研究结果: 在五种流行MoE模型上的实验表明，Cascade将减速限制在5%（对比1.5倍），吞吐量提升7-14%，优于静态K值方法。

研究结论: Cascade框架通过动态调整推测解码策略，解决了MoE模型中推测解码的实用性难题，显著提升了性能。

中文摘要: GPU内存带宽是低延迟大型语言模型（LLM）推理的主要瓶颈。推测解码利用空闲GPU计算，通过轻量级草稿器提出K个令牌，并由LLM并行验证，从而提升令牌吞吐量。在传统密集LLM中，每次迭代都会加载所有模型权重，因此推测解码不会增加延迟开销。新兴的混合专家（MoE）模型每令牌仅激活部分权重，大幅减少数据移动。然而，我们发现推测解码对MoE无效：草稿令牌共同激活更多权重，使数据移动和验证时间增加2-3倍。当令牌吞吐量增益无法抵消这一开销时，推测解码会导致高达1.5倍的减速，使其不可行。即使有效，最优K值也因任务、模型甚至请求和迭代而异。因此，尽管推测解码在密集LLM中广泛应用，但在主流MoE中仍不实用。
  我们提出Cascade，一种基于效用的框架，选择性启用推测解码以避免减速，并动态调整K值以加速MoE服务。Cascade使用轻量级指标“推测效用”（令牌增益与验证成本的比率），该指标具有迭代级局部性，支持通过短测试和长设置阶段进行周期性决策。对于每个请求，若测试阶段效用低于1，Cascade禁用推测解码；若效用超过1，则测试多个K值以选择效用最大化的K值用于设置阶段。我们在vLLM中实现Cascade，并在五种流行MoE模型上评估其性能，涵盖代码、数学、提取和混合任务。Cascade将减速限制在5%（对比1.5倍），吞吐量提升7-14%，优于静态K值方法，使推测解码在MoE中变得实用。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [242] [Evaluating PDE discovery methods for multiscale modeling of biological signals](https://arxiv.org/abs/2506.20694)
**中文标题：评估PDE发现方法在生物信号多尺度建模中的应用**

*Andréa Ducos,Audrey Denizot,Thomas Guyet,Hugues Berry*

主要分类: q-bio.QM

摘要简述: 本文评估了五种先进的偏微分方程（PDE）发现方法，用于从微观数据中推断生物信号的多尺度建模，重点关注钙扩散模拟。结果显示，部分方法能准确恢复扩散项，展示了PDE发现方法在生物系统宏观动态建模中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 生物系统具有非线性、包含未观测变量且动力学原理部分未知的特点，其行为表征极具挑战性。此外，生物活动发生在多尺度上，需要跨尺度的机制链接。本文旨在通过PDE发现方法填补微观与宏观尺度之间的空白。

研究方法: 本文结合基于粒子的模拟和PDE发现方法，评估了五种先进的PDE发现方法在星形胶质细胞钙扩散模拟中的表现。实验在受控环境中进行，重点评估了发现方程的准确性及其对钙浓度时间变化的预测能力。

研究结果: 实验结果表明，部分PDE发现方法能够准确恢复扩散项，验证了这些方法在从微观数据中捕捉生物系统宏观动态方面的有效性。

研究结论: PDE发现方法在生物系统多尺度建模中具有潜力，尤其是能够从微观数据中推断宏观动态。未来的研究可以进一步优化这些方法以提高其适用性。

中文摘要: 生物系统具有非线性、包含未观测变量且动力学原理部分未知的特点，这使得其行为表征极具挑战性。尤其是其活动发生在多尺度上，需要跨尺度的机制链接。为填补尺度间的空白，我们利用偏微分方程（PDE）发现方法，从微观数据中推断介观尺度动态特征。本文提出了一种结合基于粒子的模拟和PDE发现的框架，并在受控环境中进行了初步实验以评估方程发现的性能。我们评估了五种先进的PDE发现方法在星形胶质细胞钙扩散模拟中的表现，重点关注发现方程的形式及其对钙浓度时间变化的预测能力。结果表明，部分方法能够准确恢复扩散项，展示了PDE发现方法在从微观数据中捕捉生物系统宏观动态方面的潜力。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [243] [Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs](https://arxiv.org/abs/2506.20980)
**中文标题：增强同质-异质分离：异质图中的关系感知学习**

*Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu*

主要分类: cs.SI

摘要简述: 本文提出了一种名为RASH的新型对比学习框架，用于在异质图中显式建模高阶语义并自适应分离同质和异质模式，解决了异质性和异质性问题。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的网络通常具有节点异质性，即连接的节点具有不同的特征或标签。这一问题在同质图中已被广泛研究，但在包含多种节点和边类型的异质图中仍待深入探索。现有方法通常将异质图转换为同质图以学习节点异质性，但会丢失异质关系中的潜在异质性。

研究方法: 本文提出RASH框架，通过引入双重异质超图编码多关系二分子图，并基于关系重要性动态构建同质图和异质图。设计了多关系对比损失，通过最大化互信息对齐异质和同质/异质视图。

研究结果: 在多个基准数据集上的实验表明，RASH在各种下游任务中表现优异，验证了其有效性。

研究结论: RASH成功解决了异质图中的异质性和异质性问题，为相关研究提供了新思路。

中文摘要: 现实世界中的网络通常具有节点异质性，即连接的节点通常具有不同的特征或标签。这一问题在同质图中已被广泛研究，但在包含多种节点和边类型的异质图中仍待深入探索。在异质图中捕捉节点异质性非常具有挑战性，因为需要同时考虑节点/边的异质性和节点异质性。现有方法通常将异质图转换为同质图以学习节点异质性，但这会不可避免地丢失异质关系中潜在的异质性。为了填补这一空白，我们提出了关系感知的同质与异质分离（RASH），这是一种新型对比学习框架，显式建模异质交互的高阶语义并自适应分离同质和异质模式。具体而言，RASH引入双重异质超图编码多关系二分子图，并基于关系重要性动态构建同质图和异质图。设计了一种多关系对比损失，通过最大化互信息对齐异质和同质/异质视图。通过这种方式，RASH同时解决了异质图中的异质性和异质性问题。在多个基准数据集上的实验证明了RASH在各种下游任务中的有效性。代码可在以下网址获取：https://github.com/zhengziyu77/RASH。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [244] [Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis](https://arxiv.org/abs/2506.20806)
**中文标题：海报：通过基于代理的分析增强图神经网络在网络入侵检测中的鲁棒性**

*Zhonghao Zhan,Huichi Zhou,Hamed Haddadi*

主要分类: cs.CR

摘要简述: 本文提出了一种通过基于代理的分析增强图神经网络（GNN）在网络入侵检测中的鲁棒性的方法，利用大型语言模型（LLM）模拟网络安全专家，显著提升了GNN在对抗攻击下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前GNN在网络入侵检测系统（NIDS）中表现优异，但在分布漂移和对抗攻击下性能下降。现有鲁棒性评估多依赖不现实的合成扰动，缺乏对多种对抗攻击的系统分析。本文旨在通过LLM代理提升GNN的鲁棒性和泛化能力。

研究方法: 提出了一种基于LLM代理的管道方法，模拟网络安全专家分析网络流数据生成的图结构，识别并缓解可疑或对抗性扰动元素，再交由GNN处理。实验采用包含物理测试床数据的多样化对抗攻击框架进行验证。

研究结果: 实验表明，引入LLM分析显著提升了GNN在对抗攻击下的鲁棒性，展示了LLM代理作为入侵检测架构补充层的潜力。

研究结论: LLM代理可有效增强GNN在网络入侵检测中的鲁棒性，为未来入侵检测系统设计提供了新思路。

中文摘要: 图神经网络（GNN）在网络入侵检测系统（NIDS）中表现出巨大潜力，尤其是在物联网环境中，但由于分布漂移和对抗攻击的鲁棒性不足，其性能会下降。当前的鲁棒性评估多依赖不现实的合成扰动，缺乏对包括黑盒和白盒场景在内的多种对抗攻击的系统分析。本文提出了一种新颖方法，通过将大型语言模型（LLM）作为模拟网络安全专家代理，增强GNN的鲁棒性和泛化能力。这些代理会分析网络流数据生成的图结构，在GNN处理前识别并缓解可疑或对抗性扰动元素。实验采用专为多样化对抗攻击设计的框架，包括物理测试床数据集，结果表明LLM分析显著提升了GNN在挑战中的鲁棒性，展示了LLM代理作为入侵检测架构补充层的潜力。

</details>


### [245] [ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models](https://arxiv.org/abs/2506.20915)
**中文标题：ZKPROV：一种用于大型语言模型数据集来源的零知识方法**

*Mina Namazi,Alexander Nemecek,Erman Ayday*

主要分类: cs.CR

摘要简述: ZKPROV是一种新型加密框架，通过零知识证明技术验证大型语言模型的数据来源，确保模型训练数据的可靠性，同时保护敏感信息。


<details>
  <summary>详细信息</summary>
研究动机: 在敏感领域（如医疗）部署大型语言模型时，确保其数据来源的完整性至关重要。现有方法要么计算成本高，要么依赖可信执行环境，ZKPROV旨在提供一种高效且隐私保护的解决方案。

研究方法: ZKPROV通过零知识证明技术将训练模型与授权数据集绑定，利用数据集签名元数据和紧凑模型参数承诺，避免验证每一步训练过程。

研究结果: 实验证明ZKPROV在生成和验证证明时高效且可扩展，适用于实际部署，同时提供正式的安全保证。

研究结论: ZKPROV为大型语言模型的数据来源提供了一种隐私保护且可靠的验证方法，适用于敏感领域的实际应用。

中文摘要: 随着大型语言模型（LLMs）在敏感领域的广泛应用，确保其计算来源的完整性成为关键挑战，尤其是在医疗等受监管领域，对数据集使用有严格要求。我们提出ZKPROV，一种新型加密框架，通过零知识证明技术验证LLM的数据来源，允许用户确认模型基于可靠数据集训练，同时不泄露敏感信息或模型参数。与现有方法不同，ZKPROV既不依赖完整训练过程验证（计算成本高），也不依赖可信执行环境，而是通过零知识证明将训练模型与授权数据集绑定，避免验证每一步训练。通过利用数据集签名元数据和紧凑模型参数承诺，ZKPROV提供了一种隐私保护且可靠的验证方法，确保LLM结果源于声称的授权数据集。实验结果表明，ZKPROV在生成和验证证明时高效且可扩展，适用于实际部署。我们还提供了正式的安全保证，证明该方法在保护数据集机密性的同时，确保了可信的数据来源。

</details>


### [246] [PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction](https://arxiv.org/abs/2506.21106)
**中文标题：PhishKey：一种基于质心的自适应HTML组件提取增强钓鱼检测新方法**

*Felipe Castaño,Eduardo Fidalgo,Enrique Alegre,Rocio Alaiz-Rodríguez,Raul Orduna,Francesco Zola*

主要分类: cs.CR

摘要简述: PhishKey是一种新型钓鱼检测方法，结合URL分类和HTML内容提取，通过软投票集成实现高精度分类，实验显示其F1分数高达98.70%。


<details>
  <summary>详细信息</summary>
研究动机: 钓鱼攻击对网络安全构成重大威胁，传统检测方法难以适应其快速演变的特性。PhishKey旨在解决适应性、鲁棒性和效率问题。

研究方法: PhishKey结合字符级处理的CNN用于URL分类，以及基于质心的HTML关键组件提取器（CAPE）用于内容分析，通过软投票集成两种模块的预测结果。

研究结果: 在四个先进数据集上的实验表明，PhishKey的F1分数高达98.70%，且对注入攻击等对抗性操作表现出强抵抗力。

研究结论: PhishKey通过自适应特征提取和集成学习，显著提升了钓鱼检测的准确性和鲁棒性，为网络安全提供了有效解决方案。

中文摘要: 钓鱼攻击是网络安全的重要威胁，其快速演变以绕过检测机制并利用人类弱点。本文提出PhishKey，以解决适应性、鲁棒性和效率问题。PhishKey是一种新型钓鱼检测方法，通过从混合源自动提取特征实现。它结合字符级处理的卷积神经网络（CNN）用于URL分类，以及基于质心的关键组件钓鱼提取器（CAPE）用于HTML内容分析。CAPE减少噪声并确保完整样本处理，避免对输入数据的裁剪操作。两种模块的预测结果通过软投票集成，实现更准确可靠的分类。在四个先进数据集上的实验评估证明了PhishKey的有效性，其F1分数高达98.70%，并对注入攻击等对抗性操作表现出强抵抗力，性能下降极小。

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [247] [On Uniform Weighted Deep Polynomial approximation](https://arxiv.org/abs/2506.21306)
**中文标题：关于均匀加权深度多项式逼近的研究**

*Kingsley Yeon,Steven B. Damelin*

主要分类: math.NA

摘要简述: 本文提出了一种加权深度多项式逼近方法，用于高效逼近具有不对称行为的函数，优于传统多项式逼近方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统多项式逼近方法对于非光滑或奇异函数（如$|x|$和$x^{1/p}$）的逼近效率较低，而本文旨在通过加权深度多项式逼近方法解决这一问题。

研究方法: 通过将可学习的深度多项式与单侧权重相乘，捕捉局部非光滑性和全局增长性，并提出基于图的稳定参数化策略进行优化。

研究结果: 数值实验表明，该方法在相同参数数量下优于泰勒、切比雪夫和标准深度多项式逼近方法。

研究结论: 加权深度多项式逼近方法在逼近具有不对称行为的函数时表现出色，为相关领域提供了新的工具。

中文摘要: 有理逼近理论中的经典结果表明，某些非光滑或奇异函数（如$|x|$和$x^{1/p}$）可以通过有理函数以根指数收敛速度高效逼近。相比之下，多项式逼近仅能通过Jackson定理实现代数收敛。最近的研究表明，复合多项式结构即使在没有光滑性的情况下也能恢复指数逼近速率。本文提出并分析了一类加权深度多项式逼近方法，专门用于处理具有不对称行为的函数——在一侧无界增长而在另一侧衰减。通过将可学习的深度多项式与单侧权重相乘，我们同时捕捉了局部非光滑性和全局增长性。数值实验表明，该方法在相同参数数量下优于泰勒、切比雪夫和标准深度多项式逼近方法。为了在实践中优化这些逼近方法，我们提出了一种基于图的稳定参数化策略。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [248] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
**中文标题：混合深度学习和信号处理在低资源环境下的阿拉伯方言识别**

*Ghazal Al-Shwayyat,Omer Nezih Gerek*

主要分类: eess.AS

摘要简述: 本文研究了在低资源环境下，结合信号处理技术和深度学习模型的混合方法用于阿拉伯方言识别。实验表明，MFCC + CNN模型表现最佳，准确率达91.2%，显著优于Wavelet + RNN模型。


<details>
  <summary>详细信息</summary>
研究动机: 阿拉伯方言识别面临语言多样性和标注数据稀缺的挑战，尤其是在低资源场景下。本文旨在通过结合传统信号处理和深度学习技术，提升方言识别的性能。

研究方法: 开发了两种混合模型：(1) MFCC特征与CNN结合，(2) DWT特征与RNN结合。使用Common Voice阿拉伯语数据集的方言标注子集进行训练和评估。

研究结果: MFCC + CNN模型表现最优，准确率为91.2%，而Wavelet + RNN模型准确率仅为66.5%。MFCC + CNN在精确率、召回率和F1分数上也显著优于后者。

研究结论: 研究证实了在低资源环境下，结合频谱特征和卷积模型对阿拉伯方言识别的有效性。未来可通过扩大标注数据集、引入自监督学习和探索Transformer等架构进一步提升性能。

中文摘要: 阿拉伯方言识别在语音技术中面临重大挑战，主要源于阿拉伯语的多样性以及标注数据集的稀缺性，尤其是对于少数方言。本研究探讨了结合传统信号处理技术和深度学习架构的混合建模策略，以解决低资源场景下的这一问题。开发并评估了两种混合模型：(1) 梅尔频率倒谱系数（MFCC）与卷积神经网络（CNN）结合，(2) 离散小波变换（DWT）特征与循环神经网络（RNN）结合。模型在Common Voice阿拉伯语数据集的方言标注子集上训练，方言标签基于说话者元数据分配。实验结果表明，MFCC + CNN架构表现最佳，准确率达91.2%，且精确率、召回率和F1分数均显著优于Wavelet + RNN配置（准确率66.5%）。这些发现凸显了在有限标注数据下，结合频谱特征和卷积模型对阿拉伯方言识别的有效性。研究还指出了数据集规模、标签区域重叠和模型优化等方面的局限性，为未来研究提供了方向。进一步改进的建议包括采用更大的标注语料库、整合自监督学习技术以及探索Transformer等先进神经网络架构。总体而言，本研究为资源受限环境下的阿拉伯方言识别奠定了坚实基础。

</details>


### [249] [ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing](https://arxiv.org/abs/2506.21448)
**中文标题：ThinkSound：多模态大语言模型中的链式思维推理用于音频生成与编辑**

*Huadai Liu,Jialei Wang,Kaicheng Luo,Wen Wang,Qian Chen,Zhou Zhao,Wei Xue*

主要分类: eess.AS

摘要简述: ThinkSound 是一种利用链式思维（CoT）推理的多模态大语言模型框架，用于视频到音频的生成和编辑。它通过分阶段处理和交互式优化，结合 AudioCoT 数据集，实现了高质量的音频生成和编辑。


<details>
  <summary>详细信息</summary>
研究动机: 尽管端到端的视频到音频生成技术已有显著进步，但生成高保真且真实反映视觉内容的音频仍具挑战性。本文旨在通过链式思维推理，模拟专业人士的创作过程，提升音频生成和编辑的质量。

研究方法: ThinkSound 将音频生成和编辑分为三个阶段：基础音效生成、交互式对象中心优化和自然语言指导的针对性编辑。多模态大语言模型生成上下文对齐的 CoT 推理，指导统一的音频基础模型。同时，引入了 AudioCoT 数据集，连接视觉内容、文本描述和声音合成。

研究结果: 实验表明，ThinkSound 在视频到音频生成任务中表现优异，不仅在音频指标上达到先进水平，还在 CoT 指标和 Movie Gen Audio 基准测试中表现出色。

研究结论: ThinkSound 通过分阶段推理和交互式优化，显著提升了视频到音频生成和编辑的质量，为多模态任务提供了新的解决方案。

中文摘要: 尽管端到端的视频到音频生成技术已取得显著进展，但生成高保真且真实反映视觉内容的音频仍具挑战性。与创意行业的专业人士类似，这种生成需要对视觉动态、声学环境和时间关系等进行复杂推理。我们提出了 ThinkSound，一种新颖的框架，利用链式思维（CoT）推理实现逐步、交互式的视频音频生成和编辑。我们的方法将过程分解为三个互补阶段：基础音效生成（创建语义连贯的音景）、通过精确用户交互实现的交互式对象中心优化，以及自然语言指导的针对性编辑。在每个阶段，多模态大语言模型生成上下文对齐的 CoT 推理，指导统一的音频基础模型。此外，我们引入了 AudioCoT，一个包含结构化推理注释的综合数据集，建立了视觉内容、文本描述和声音合成之间的联系。实验表明，ThinkSound 在视频到音频生成任务中表现优异，不仅在音频指标上达到先进水平，还在 CoT 指标和 Movie Gen Audio 基准测试中表现出色。演示页面请访问 https://ThinkSound-Demo.github.io。

</details>
