<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 61]
- [cs.CV](#cs.CV) [Total: 72]
- [cs.AI](#cs.AI) [Total: 45]
- [cs.SE](#cs.SE) [Total: 12]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.HC](#cs.HC) [Total: 6]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.GR](#cs.GR) [Total: 3]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [cs.LG](#cs.LG) [Total: 40]
- [q-bio.PE](#q-bio.PE) [Total: 1]
- [cs.RO](#cs.RO) [Total: 7]
- [math.ST](#math.ST) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.CY](#cs.CY) [Total: 5]
- [quant-ph](#quant-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 10]
- [cs.IR](#cs.IR) [Total: 6]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.SD](#cs.SD) [Total: 9]
- [stat.ML](#stat.ML) [Total: 4]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [ClimateChat: Designing Data and Methods for Instruction Tuning LLMs to Answer Climate Change Queries](https://arxiv.org/abs/2506.13796)
**中文标题：ClimateChat：设计数据和方法用于指令调优LLM以回答气候变化查询**

*Zhou Chen,Xiao Wang,Yuanhong Liao,Ming Lin,Yuqi Bai*

主要分类: cs.CL

摘要简述: 本文提出了一种自动化构建气候指令数据的方法，并基于此训练了名为ClimateChat的LLM，显著提升了气候变化问答任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着全球气候变化问题日益严峻，对气候科学研究的需求增加，但目前缺乏高效生成高精度气候指令数据的方法，限制了气候变化LLM的发展。

研究方法: 通过从文档中提取事实和背景知识生成指令，结合网络爬取和种子指令收集增强数据多样性，构建了ClimateChat-Corpus数据集，并用于微调开源LLM。

研究结果: ClimateChat在气候变化问答任务中表现显著提升，同时验证了不同基础模型和指令数据对LLM性能的影响。

研究结论: 研究为构建气候指令数据和训练气候专用LLM提供了重要参考，强调了选择合适基础模型的重要性。

中文摘要: 随着全球气候变化问题日益严峻，气候科学研究的需��不断增长。以大型语言模型（LLM）为代表的自然语言处理技术已广泛应用于气候变化相关研究，为决策者和公众提供重要信息支持。一些研究通过构建气候变化相关指令数据并对LLM进行指令调优，提升了模型在相关任务上的性能。然而，目前研究在高效生成大量高精度气候指令数据方面仍显不足，限制了气候变化LLM的进一步发展。本研究提出了一种自动化构建指令数据的方法，通过从文档中提取事实和背景知识生成指令，并结合网络爬取和种子指令收集增强数据多样性。利用该方法，我们构建了一个名为ClimateChat-Corpus的气候变化指令数据集，并用于微调开源LLM，最终得到名为ClimateChat的LLM。评估结果表明，ClimateChat在气候变化问答任务中的性能显著提升。此外，我们还评估了不同基础模型和指令数据对LLM性能的影响，并展示了其适应广泛气候变化科学发现任务的能力，强调了选择合适基础模型进行指令调优的重要性。本研究为构建气候指令数据和训练气候专用LLM提供了有价值的参考和实证支持。

</details>


### [2] [Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles](https://arxiv.org/abs/2506.13886)
**中文标题：利用多语言数字谜题研究语言模型中的语言与数学推理交互**

*Antara Raaghavi Bhattacharya,Isabel Papadimitriou,Kathryn Davidson,David Alvarez-Melis*

主要分类: cs.CL

摘要简述: 研究发现，大型语言模型（LLMs）在多语言数字谜题中难以结合语言和数学推理，除非数学符号被明确标记。人类能灵活推断数字的隐含结构，而LLMs则缺乏这种能力。


<details>
  <summary>详细信息</summary>
研究动机: 不同语言的数字系统构造方式多样，人类能轻松适应，但LLMs在处理涉及跨语言数字系统的语言-数学谜题时表现不佳。本文旨在探究LLMs为何难以完成此类任务。

研究方法: 通过一系列实验，分离语言和数学在数字表达中的作用，测试LLMs在明确标记数学符号和未标记情况下的表现，并分析数字构造和组合参数对性能的影响。

研究结果: 实验表明，除非数学符号（如“+”“×”）被明确标记，否则LLMs无法稳定解决问题。LLMs缺乏人类对数字隐含结构的理解能力。

研究结论: 当前推理模型难以从人类规模的数据中灵活推断隐含的组合规则，这是其面临的主要挑战。

中文摘要: 不同语言的数字系统在构造和组合数字时存在显著差异。尽管人类能轻松适应这种多样性，但大型语言模型（LLMs）在处理涉及跨语言数字系统的语言-数学谜题时表现不佳。我们通过一系列实验探究了LLMs难以完成此类任务的原因，分离了语言和数学在数字表达中的作用。实验表明，除非数学运算符号（如“二十 + 三”中的“+”）被明确标记，否则模型无法稳定解决问题。进一步的消融研究中，我们分析了数字构造和组合参数对性能的影响。人类能利用对数字的语言理解推断其隐含的组合结构，而LLMs似乎缺乏这种能力。我们得出结论：当前推理模型难以从人类规模的数据中灵活推断隐含的组合规则，这仍是一个未解决的挑战。

</details>


### [3] [VL-GenRM: Enhancing Vision-Language Verification via Vision Experts and Iterative Training](https://arxiv.org/abs/2506.13888)
**中文标题：VL-GenRM：通过视觉专家与迭代训练增强视觉语言验证**

*Jipeng Zhang,Kehao Miao,Renjie Pi,Zhaowei Wang,Runtao Liu,Rui Pan,Tong Zhang*

主要分类: cs.CL

摘要简述: 本文提出了一种迭代训练框架VL-GenRM，通过结合视觉专家、思维链推理和基于边缘的拒绝采样，解决了视觉语言奖励模型训练中的自举困境和模态偏差问题，显著提升了幻觉检测和多模态推理性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言奖励模型（VL-RM）的训练面临自举困境和模态偏差问题，导致生成的数据质量受限，进一步影响模型对齐效果。本文旨在通过引入视觉专家和迭代训练方法，提升VL-RM的训练效率和性能。

研究方法: 提出了一种迭代训练框架VL-GenRM，结合视觉专家、思维链（CoT）推理和基于边缘的拒绝采样，优化偏好数据集生成，增强结构化反馈，并通过迭代训练逐步提升模型的多模态推理能力。

研究结果: 实验表明，VL-GenRM在多个视觉语言奖励模型基准测试中表现优异，尤其在幻觉检测和多模态推理任务上显著优于现有方法。

研究结论: VL-GenRM通过引入视觉专家和迭代训练策略，有效解决了视觉语言奖励模型训练中的核心问题，为视觉语言模型的对齐提供了新思路。

中文摘要: 强化微调（RFT）通过可验证的奖励改进了大型语言模型，但在视觉语言（VL）模型中的应用仍较少。视觉语言奖励模型（VL-RM）通过提供结构化反馈对VL模型对齐至关重要，但其训练面临两大挑战：一是自举困境，即高质量训练数据依赖于已有强VL模型，导致自我生成的监督强化现有偏差；二是模态偏差和负例放大问题，即VL模型可能幻觉错误的视觉属性，生成有缺陷的偏好数据，进一步误导训练。为解决这些问题，我们提出了一种迭代训练框架，结合视觉专家、思维链（CoT）推理和基于边缘的拒绝采样，优化偏好数据集，增强结构化反馈，并通过迭代训练提升推理能力。在多个VL-RM基准测试中，我们的方法在幻觉检测和多模态推理任务上表现优异，推动了基于强化学习的VL模型对齐。

</details>


### [4] [EmoNews: A Spoken Dialogue System for Expressive News Conversations](https://arxiv.org/abs/2506.13894)
**中文标题：EmoNews：一种用于情感化新闻对话的语音对话系统**

*Ryuki Matsuura,Shikhar Bharadwaj,Jiarui Liu,Dhatchi Kunde Govindarajan*

主要分类: cs.CL

摘要简述: 本文开发了一个基于情感语音的任务导向对话系统EmoNews，通过上下文线索调节情感语音，以提升新闻对话的共情能力。实验表明，该系统在情感调节和用户参与度上优于基线系统。


<details>
  <summary>详细信息</summary>
研究动机: 尽管情感文本转语音（TTS）技术有所进展，但任务导向的情感对话系统研究仍不足，主要由于对话系统与情感TTS研究的分离以及缺乏社交目标的标准化评估指标。本文旨在解决这些问题。

研究方法: 开发了一个用于新闻对话的情感对话系统，利用基于大语言模型（LLM）的情感分析器识别合适的情感，并通过PromptTTS合成符合上下文的情感语音。同时，提出了情感对话系统的主观评估量表。

研究结果: 实验结果表明，所提出的情感对话系统在情感调节和用户参与度上优于基线系统，验证了语音情感对提升对话参与度的重要性。

研究结论: 研究强调了语音情感在任务导向对话系统中的关键作用，并为未来情感对话系统的开发提供了开源工具和评估方法。

中文摘要: 我们开发了一种任务导向的语音对话系统（SDS），通过上下文线索调节情感语音，以实现更具共情力的新闻对话。尽管情感文本转语音（TTS）技术有所进展，但由于对话系统与情感TTS研究的分离以及缺乏社交目标的标准化评估指标，任务导向的情感SDS研究仍不足。我们通过开发一种用于新闻对话的情感SDS来解决这些问题，该系统利用基于大语言模型（LLM）的情感分析器识别合适的情感，并通过PromptTTS合成符合上下文的情感语音。我们还提出了情感SDS的主观评估量表，并评估了所提系统和基线系统的情感调节性能。实验表明，我们的情感SDS在情感调节和用户参与度上优于基线系统。这些结果揭示了语音情感对提升对话参与度的重要性。所有源代码已在https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1开源。

</details>


### [5] [Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise Pooled Representations](https://arxiv.org/abs/2506.13901)
**中文标题：对齐质量指数（AQI）：超越拒绝——通过潜在几何、聚类分离和分层池化表示的内在对齐诊断**

*Abhilekh Borah,Chhavi Sharma,Danush Khanna,Utkarsh Bhatt,Gurpreet Singh,Hasnat Md Abdullah,Raghav Kaushik Ravi,Vinija Jain,Jyoti Patel,Shubham Singh,Vasu Sharma,Arpita Vats,Rahul Raja,Aman Chadha,Amitava Das*

主要分类: cs.CL

摘要简述: 本文提出了一种新颖的指标——对齐质量指数（AQI），用于评估大型语言模型（LLM）的内在对齐质量，通过潜在空间中的安全与不安全激活分离分析，弥补现有评估方法的盲点。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）进入教育、医疗、法律等高风险领域，其行为必须可靠地反映人类对齐的价值观和安全约束。然而，当前评估方法依赖行为代理指标（如拒绝率、G-Eval分数和毒性分类器），存在明显盲点，无法有效检测对齐伪造、越狱攻击等问题。

研究方法: 作者提出AQI指标，结合Davies-Bouldin分数（DBS）、Dunn指数（DI）、Xie-Beni指数（XBI）和Calinski-Harabasz指数（CHI）等多种聚类质量度量，分析潜在空间中安全与不安全激活的分离情况。此外，还提出了LITMUS数据集，用于在复杂条件下进行稳健评估。

研究结果: 实验表明，AQI能够揭示传统拒绝指标忽略的漏洞，并与外部评估结果相关。在不同训练方法（如DPO、GRPO、RLHF）的模型上测试LITMUS数据集，验证了AQI的有效性。

研究结论: AQI作为一种内在对齐诊断工具，能够检测隐藏的对齐问题和越狱风险，为模型安全性提供早期预警。其公开实现有助于推动未来研究。

中文摘要: 对齐不再是奢侈品，而是必需品。随着大型语言模型（LLM）进入教育、医疗、法律等高风险领域，其行为必须可靠地反映人类对齐的价值观和安全约束。然而，当前评估方法依赖行为代理指标（如拒绝率、G-Eval分数和毒性分类器），存在明显盲点。对齐模型往往容易受到越狱攻击、生成随机性和对齐伪造的影响。
为解决这一问题，我们提出了对齐质量指数（AQI）。这一新颖的几何和提示不变指标通过分析潜在空间中安全与不安全激活的分离情况，实证评估LLM的对齐质量。结合Davies-Bouldin分数（DBS）、Dunn指数（DI）、Xie-Beni指数（XBI）和Calinski-Harabasz指数（CHI）等多种度量，AQI通过聚类质量检测隐藏的对齐问题和越狱风险，即使输出看似合规。AQI还可作为对齐伪造的早期预警信号，提供一种行为无关的安全性审计工具。
此外，我们提出了LITMUS数据集，以支持在复杂条件下的稳健评估。在LITMUS上对不同训练方法（如DPO、GRPO、RLHF）的模型进行实证测试，证明了AQI与外部评估的相关性及其揭示拒绝指标遗漏漏洞的能力。我们公开了实现代码，以促进未来研究。

</details>


### [6] [ASMR: Augmenting Life Scenario using Large Generative Models for Robotic Action Reflection](https://arxiv.org/abs/2506.13956)
**中文标题：ASMR：利用大型生成模型增强机器人动作反射的生活场景增强**

*Shang-Chi Tsai,Seiya Kawano,Angel Garcia Contreras,Koichiro Yoshino,Yun-Nung Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种利用大型生成模型增强机器人动作反射的新框架，通过模拟对话和环境图像生成数据，优化多模态模型，显著提升机器人动作选择能力。


<details>
  <summary>详细信息</summary>
研究动机: 设计辅助日常人类活动的机器人时，需结合视觉线索增强用户意图理解，但大规模多模态数据集的收集耗时且困难。

研究方法: 提出一种数据增强框架，利用大型语言模型模拟对话和环境上下文，结合稳定扩散模型生成环境图像，优化多模态模型。

研究结果: 基于真实场景数据集的实验表明，该方法显著提升机器人动作选择能力，达到最先进性能。

研究结论: 通过生成模拟数据优化多模态模型，有效解决了数据不足问题，提升了机器人对用户意图的理解和动作选择能力。

中文摘要: 在设计辅助日常人类活动的机器人时，结合视觉线索增强用户请求以提升意图理解至关重要，这一过程被定义为多模态分类任务。然而，收集包含视觉和语言元素的大规模数据集用于模型训练既具挑战性又耗时。为解决这一问题，本文提出了一种新颖的框架，专注于机器人辅助场景中的数据增强，涵盖对话和相关环境图像。该方法利用复杂的大型语言模型模拟潜在对话和环境上下文，随后使用稳定扩散模型生成描绘这些环境的图像。额外生成的数据用于优化最新的多模态模型，使其能够更准确地根据有限的用户交互数据确定适当的动作。基于真实场景数据集的实验结果表明，我们的方法显著提升了机器人的动作选择能力，达到了最先进的性能。

</details>


### [7] [Are manual annotations necessary for statutory interpretations retrieval?](https://arxiv.org/abs/2506.13965)
**中文标题：法律概念解释检索是否需要手动标注？**

*Aleksander Smywiński-Pohl,Tomer Libal,Adam Kaczmarczyk,Magdalena Król*

主要分类: cs.CL

摘要简述: 本文探讨了在法律概念解释检索中是否需要手动标注的问题，通过实验验证了标注数量、标注句子选择方式以及自动化标注的效果。


<details>
  <summary>详细信息</summary>
研究动机: 法律研究中，法官对法律概念的解释常被用作判例或帮助理解，但现有方法依赖手动标注，成本高且需重复。本文旨在研究手动标注的必要性和优化方法。

研究方法: 通过实验验证：1) 每个法律概念的最佳标注数量；2) 随机选择标注句子与选择最佳候选句子的模型性能差异；3) 使用大型语言模型（LLM）自动化标注的效果。

研究结果: 实验表明：1) 标注数量存在最优值；2) 选择最佳候选句子标注能提升模型性能；3) LLM自动化标注具有一定可行性。

研究结论: 手动标注虽仍有必要，但可通过优化标注策略和引入自动化方法降低成本。

中文摘要: 法律研究的要素之一是寻找法官对法律概念的解释案例，这些解释可作为判例或帮助理解概念。当前最先进的检索方法依赖于句子排序和基于标注示例训练的语言模型，但手动标注成本高且需重复。本文通过实验探讨了手动标注的数量、范围及必要性。首先，研究了每个法律概念的最佳标注数量；其次，比较了随机选择标注句子与选择最佳候选句子对模型性能的影响；最后，评估了使用大型语言模型（LLM）自动化标注的效果。

</details>


### [8] [AI shares emotion with humans across languages and cultures](https://arxiv.org/abs/2506.13978)
**中文标题：AI跨语言文化共享人类情感**

*Xiuwen Wu,Hao Wang,Zhiang Yan,Xiaohan Tang,Pengfei Xu,Wai-Ting Siok,Ping Li,Jia-Hong Gao,Bingjiang Lyu,Lang Qin*

主要分类: cs.CL

摘要简述: 研究表明，AI与人类在情感表达上具有结构一致性，且可通过心理学基础的情感概念精确调控AI的情感输出。


<details>
  <summary>详细信息</summary>
研究动机: 探讨AI是否能够像人类一样理解和表达情感，以及如何通过情感概念调控AI的情感输出，以实现更有效和安全的人机协作。

研究方法: 通过跨语言文化群体和模型家族评估人类与AI的情感对齐，使用可解释的LLM特征，分析二十多种情感类别（包括六种基本情感）的结构和预测能力。

研究结果: 研究发现，AI的情感空间与人类感知结构一致，且能够准确预测大规模行为数据中的情感维度（效价和唤醒度）。通过人类中心的情感概念，可以稳定自然地调控AI的情感输出。

研究结论: AI不仅与人类共享情感表征，还能通过心理学基础的情感概念精确调控其情感输出，为人机协作提供了新的可能性。

中文摘要: 有效和安全的人机协作需要人类与人工智能（AI）之间进行有规范和有意义的情感交流。目前基于大型语言模型（LLM）的AI系统可以提供反馈，让人感到被倾听。然而，LLM是否像人类一样在语言中表达情感，以及其输出的情感基调是否及如何被控制，仍不清楚。我们通过跨语言文化群体和模型家族评估人类与AI的情感对齐，使用从二十多种细腻情感类别（包括六种基本情感）的概念集翻译而来的可解释LLM特征。分析表明，LLM衍生的情感空间在结构上与人类感知一致，其基础是效价和唤醒度这两个基本情感维度。此外，这些情感相关特征还能准确预测大规模行为数据中这两个核心维度的词汇评分，反映了普遍和语言特定的模式。最后，通过仅基于人类中心情感概念的调控向量，我们展示了模型表达可以稳定且自然地跨不同情感类别进行调节，这为人类情感概念可用于系统诱导LLM在传达内容时产生相应情感状态提供了因果证据。这些发现表明，AI不仅与人类共享情感表征，还能通过心理学基础的情感概念精确引导其情感输出。

</details>


### [9] [Lost in the Mix: Evaluating LLM Understanding of Code-Switched Text](https://arxiv.org/abs/2506.14012)
**中文标题：迷失在混合中：评估大语言模型对代码切换文本的理解能力**

*Amr Mohamed,Yang Zhang,Michalis Vazirgiannis,Guokan Shang*

主要分类: cs.CL

摘要简述: 本文系统评估了大语言模型（LLMs）对代码切换（CSW）文本的理解能力，发现外语词汇干扰英文文本时模型表现下降，但将英文嵌入其他语言时理解能力提升。提示方法效果不一，而微调是更稳定的改进途径。


<details>
  <summary>详细信息</summary>
研究动机: 代码切换在多语言社区和在线内容中广泛存在，而大语言模型（LLMs）作为内容处理和生成的核心工具，常需处理混合语言文本。因此，研究LLMs对代码切换文本的理解能力至关重要。

研究方法: 通过生成代码切换版本的现有推理和理解基准，系统评估LLMs对混合语言文本的处理能力。

研究结果: 外语词汇干扰英文文本时模型表现下降，但将英文嵌入其他语言时理解能力提升。提示方法效果不稳定，而微调能更稳定地缓解性能下降。

研究结论: LLMs对代码切换文本的理解能力受语言混合方式影响，微调是改善模型表现的可靠方法。

中文摘要: 代码切换（CSW）是指在单一话语中交替使用两种或更多语言的现象。这种现象在多语言社区中普遍存在，并在在线内容中日益常见，用户在日常交流中自然混合使用多种语言。因此，作为内容处理和生成核心的大语言模型（LLMs）经常接触到代码切换输入。鉴于其广泛应用，了解LLMs如何处理和推理此类混合语言文本至关重要。本文通过生成代码切换版本的现有推理和理解基准，系统评估了LLMs对混合语言文本的理解能力。研究发现，当外语词汇干扰英文文本时，模型表现明显下降（即使在语言约束下），而将英文嵌入其他语言时理解能力往往提升。尽管提示方法效果不一，但微调为缓解性能下降提供了更稳定的途径。

</details>


### [10] [MultiFinBen: A Multilingual, Multimodal, and Difficulty-Aware Benchmark for Financial LLM Evaluation](https://arxiv.org/abs/2506.14028)
**中文标题：MultiFinBen：一个多语言、多模态且难度感知的金融大语言模型评估基准**

*Xueqing Peng,Lingfei Qian,Yan Wang,Ruoyu Xiang,Yueru He,Yang Ren,Mingyang Jiang,Jeff Zhao,Huan He,Yi Han,Yun Feng,Yuechen Jiang,Yupeng Cao,Haohang Li,Yangyang Yu,Xiaoyu Wang,Penglei Gao,Shengyuan Lin,Keyi Wang,Shanshan Yang,Yilun Zhao,Zhiwei Liu,Peng Lu,Jerry Huang,Suyuchen Wang,Triantafillos Papadopoulos,Polydoros Giannouris,Efstathia Soufleri,Nuo Chen,Guojun Xiong,Zhiyang Deng,Yijia Zhao,Mingquan Lin,Meikang Qiu,Kaleb E Smith,Arman Cohan,Xiao-Yang Liu,Jimin Huang,Alejandro Lopez-Lira,Xi Chen,Junichi Tsujii,Jian-Yun Nie,Sophia Ananiadou,Qianqian Xie*

主要分类: cs.CL

摘要简述: MultiFinBen是首个针对全球金融领域的多语言、多模态基准测试，评估大语言模型在复杂跨语言和多模态任务中的表现，揭示了现有模型在金融领域的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有金融基准测试多为单语言和单模态，无法反映真实金融场景的复杂性。MultiFinBen旨在填补这一空白，推动金融领域透明、可复现的研究。

研究方法: 提出MultiFinBen基准，包含多语言金融问答（PolyFiQA-Easy/Expert）和OCR嵌入金融问答（EnglishOCR/SpanishOCR）任务，采用动态难度选择机制，确保数据集紧凑平衡。

研究结果: 对22个先进模型的评估显示，即使最强模型在复杂跨语言和多模态金融任务中也表现不佳。

研究结论: MultiFinBen为金融领域研究提供了首个多语言、多模态基准，揭示了模型在复杂任务中的不足，推动未来研究发展。

中文摘要: 近年来，大语言模型（LLMs）的进展加速了金融自然语言处理和应用的发展，但现有基准测试仍局限于单语言和单模态设置，且任务过于简单，未能反映真实金融交流的复杂性。我们提出了MultiFinBen，这是首个针对全球金融领域的多语言和多模态基准测试，评估LLMs在文本、视觉和音频等多模态及单语言、双语和多语言等不同语言环境下的表现。我们引入了两项新任务：PolyFiQA-Easy和PolyFiQA-Expert，这是首个要求模型对混合语言输入进行复杂推理的多语言金融基准测试；以及EnglishOCR和SpanishOCR，这是首个嵌入OCR的金融问答任务，挑战模型从视觉-文本金融文档中提取信息并进行推理。此外，我们提出了一种动态、难度感知的选择机制，并构建了一个紧凑且平衡的基准测试，而非简单聚合现有数据集。对22个先进模型的广泛评估表明，即使是最强的模型，尽管具备通用的多语言和多模态能力，在金融领域的复杂跨语言和多模态任务中也表现不佳。MultiFinBen已公开发布，以促进金融研究和应用的透明、可复现和包容性发展。

</details>


### [11] [An Interdisciplinary Review of Commonsense Reasoning and Intent Detection](https://arxiv.org/abs/2506.14040)
**中文标题：跨学科综述：常识推理与意图检测**

*Md Nazmus Sakib*

主要分类: cs.CL

摘要简述: 本文综述了常识推理和意图检测的最新进展，分析了28篇论文，总结了方法与应用，并指出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 自然语言理解中的常识推理和意图检测是两大关键挑战，本文旨在通过跨学科视角梳理最新研究进展，为未来研究提供方向。

研究方法: 通过分析2020-2025年间ACL、EMNLP和CHI的28篇论文，按方法和应用分类，分别探讨常识推理和意图检测的研究现状。

研究结果: 总结了常识推理在零样本学习、文化适应、结构化评估和交互场景中的进展，以及意图检测在开放集模型、生成式方法、聚类和人机交互系统中的研究。

研究结论: 研究揭示了自适应、多语言和上下文感知模型的新趋势，并指出了在基础理论、泛化能力和基准设计方面的关键空白。

中文摘要: 本文综述了常识推理和意图检测在自然语言理解领域的最新进展。我们分析了2020-2025年间ACL、EMNLP和CHI的28篇论文，并按方法和应用进行了分类。常识推理的研究涵盖了零样本学习、文化适应、结构化评估和交互场景；意图检测则通过开放集模型、生成式方法、聚类和人机交互系统进行了探讨。通过结合NLP和HCI的视角，我们强调了自适应、多语言和上下文感知模型的新趋势，并指出了在理论基础、泛化能力和基准设计方面的关键空白。

</details>


### [12] [Ace-CEFR -- A Dataset for Automated Evaluation of the Linguistic Difficulty of Conversational Texts for LLM Applications](https://arxiv.org/abs/2506.14046)
**中文标题：Ace-CEFR——用于大语言模型应用中对话文本语言难度自动评估的数据集**

*David Kogan,Max Schumacher,Sam Nguyen,Masanori Suzuki,Melissa Smith,Chloe Sophia Bellows,Jared Bernstein*

主要分类: cs.CL

摘要简述: 本文介绍了Ace-CEFR数据集，用于自动评估对话文本的语言难度，适用于大语言模型（LLMs）的训练和筛选。实验表明，基于该数据集训练的模型在难度评估上优于人类专家，且延迟适合生产环境。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏评估短对话文本语言难度的工具，尤其是针对大语言模型（LLMs）的训练和筛选需求。本文旨在填补这一空白，提供一种自动化评估方法。

研究方法: 作者构建了Ace-CEFR数据集，包含专家标注的英语对话文本难度等级。实验使用了多种模型，包括基于Transformer的模型和LLMs，以验证其评估效果。

研究结果: 实验结果显示，基于Ace-CEFR训练的模型在文本难度评估上比人类专家更准确，且延迟适合实际应用。数据集已公开供研究和开发使用。

研究结论: Ace-CEFR数据集为对话文本的自动化难度评估提供了有效工具，尤其适用于LLMs的训练和筛选，具有实际应用价值。

中文摘要: 目前缺乏评估短对话文本语言难度的工具，尤其是针对大语言模型（LLMs）的训练和筛选需求。我们提出了Ace-CEFR数据集，其中包含专家标注的英语对话文本难度等级。我们在Ace-CEFR上测试了多种模型，包括基于Transformer的模型和LLMs。结果表明，基于Ace-CEFR训练的模型在文本难度评估上比人类专家更准确，且延迟适合生产环境。最后，我们将Ace-CEFR数据集公开发布，供研究和开发使用。

</details>


### [13] [Automatic Extraction of Clausal Embedding Based on Large-Scale English Text Data](https://arxiv.org/abs/2506.14064)
**中文标题：基于大规模英语文本数据的从句自动提取**

*Iona Carslaw,Sivan Milton,Nicolas Navarre,Ciyang Qing,Wataru Uegaki*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大规模英语文本数据的从句自动提取方法，利用成分分析和启发式规则，从自然语言语料中检测和标注嵌入式从句，并构建了一个大型数据集。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言学研究多依赖人工构造的例句分析嵌入式从句，缺乏从大规模自然语言语料中获取的统计信息和真实例句。本文旨在填补这一空白，提供一种自动提取自然语言中嵌入式从句的方法。

研究方法: 采用成分分析和一组启发式规则，从大规模文本数据中检测和标注自然出现的英语嵌入式从句。工具在手工标注的数据集GECS上进行了评估。

研究结果: 成功开发了一种提取工具，并从开源语料库Dolma中提取了大量自然出现的英语嵌入式从句，构建了一个大规模数据集。

研究结论: 本文提出的方法能够有效从大规模文本数据中提取嵌入式从句，为语言学研究提供了丰富的自然语言资源。

中文摘要: 对语言学家而言，嵌入式从句因其复杂的句法和语义特征分布而备受关注。然而，当前研究多依赖人工构造的语言例句来研究这些结构，未能从大规模语言语料库中获取统计信息和自然例句。为此，我们提出了一种方法，利用成分分析和一组启发式规则，从大规模文本数据中检测和标注自然出现的英语嵌入式从句。我们的工具在手工标注的数据集“黄金嵌入式从句集”（GECS）上进行了评估。最后，我们展示了从开源语料库Dolma中提取的大量自然出现的英语嵌入式从句数据集。

</details>


### [14] [Abstract Meaning Representation for Hospital Discharge Summarization](https://arxiv.org/abs/2506.14101)
**中文标题：基于抽象意义表示的医院出院摘要生成**

*Paul Landes,Sitara Rao,Aaron Jeremy Chaise,Barbara Di Eugenio*

主要分类: cs.CL

摘要简述: 本文提出一种结合语言图和深度学习模型的方法，用于自动生成可信赖的医院出院摘要，解决大型语言模型在临床领域中的幻觉问题，并在公开数据集和实际临床笔记中验证了其可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的幻觉问题在临床领域具有严重后果，尤其是自动生成出院摘要时。本文旨在探索新方法，结合语言图和深度学习模型，确保内容的来源可信，减轻医生文档负担，同时提高自动摘要的可靠性。

研究方法: 本文提出一种结合语言图和深度学习模型的方法，利用公开的MIMIC-III数据集和匿名医院的临床笔记，生成出院摘要，并提供源代码和训练模型。

研究结果: 该方法在MIMIC-III数据集和实际临床笔记中表现出显著的可靠性，生成的出院摘要内容来源清晰且可信。

研究结论: 结合语言图和深度学习模型的方法有效解决了自动生成出院摘要中的幻觉问题，为临床领域提供了可信赖的自动摘要工具。

中文摘要: 大型语言模型（LLMs）的幻觉问题对临床领域具有严重影响，尤其是在自动生成出院摘要（一种总结住院就诊的长篇医疗文档）时。自动生成这些摘要可以减轻医生负担，使其专注于患者护理。本文旨在探索新方法，结合语言图和深度学习模型，解决自动摘要中内容的来源和可信度问题。我们的方法在公开的MIMIC-III数据集和匿名医院医生撰写的临床笔记中表现出显著的可靠性。我们提供了方法、生成的出院摘要示例、源代码和训练模型。

</details>


### [15] [Essential-Web v1.0: 24T tokens of organized web data](https://arxiv.org/abs/2506.14111)
**中文标题：Essential-Web v1.0：24万亿标记的组织化网络数据**

*Essential AI,:,Andrew Hojel,Michael Pust,Tim Romanski,Yash Vanjani,Ritvik Kapila,Mohit Parmar,Adarsh Chaluvaraju,Alok Tripathy,Anil Thomas,Ashish Tanwer,Darsh J Shah,Ishaan Shah,Karl Stratos,Khoi Nguyen,Kurt Smith,Michael Callahan,Peter Rushton,Philip Monk,Platon Mazarakis,Saad Jamal,Saurabh Srivastava,Somanshu Singla,Ashish Vaswani*

主要分类: cs.CL

摘要简述: Essential-Web v1.0是一个包含24万亿标记的标注数据集，通过12类分类法组织，涵盖主题、格式、内容复杂度和质量。使用SQL式过滤器可高效提取高质量数据，在数学、代码、STEM和医学领域表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏大规模且组织良好的预训练数据集，导致数据获取成本高且难以普及。Essential-Web v1.0旨在解决这一问题，提供标注丰富、易于访问的庞大数据集。

研究方法: 数据集通过EAI-Distill-0.5b模型标注，该模型在标注一致性上与Qwen2.5-32B-Instruct接近（误差3%内）。使用SQL式过滤器提取特定领域数据。

研究结果: 在数学、代码、STEM和医学领域，Essential-Web v1.0表现优异，分别相对SOTA提升-8.0%、+14.3%、+24.5%和+8.6%。

研究结论: Essential-Web v1.0为语言模型训练提供了高质量、易访问的数据集，显著降低了数据获取成本。

中文摘要: 数据在语言模型获取技能和知识中扮演着最重要的角色。缺乏大规模且组织良好的预训练数据集导致了昂贵且难以普及的数据流程。我们提出了Essential-Web v1.0，这是一个包含24万亿标记的数据集，其中每篇文档均标注了涵盖主题、格式、内容复杂度和质量的12类分类法。分类标签由EAI-Distill-0.5b生成，这是一个经过微调的5亿参数模型，其标注一致性在Qwen2.5-32B-Instruct的3%误差范围内。仅需使用SQL式过滤器，我们就能在数学（相对SOTA提升-8.0%）、网络代码（+14.3%）、STEM（+24.5%）和医学（+8.6%）领域获得具有竞争力的网络精选数据集。Essential-Web v1.0已在HuggingFace上发布：https://huggingface.co/datasets/EssentialAI/essential-web-v1.0

</details>


### [16] [Sampling from Your Language Model One Byte at a Time](https://arxiv.org/abs/2506.14123)
**中文标题：逐字节采样语言模型**

*Jonathan Hayase,Alisa Liu,Noah A. Smith,Sewoong Oh*

主要分类: cs.CL

摘要简述: 本文提出了一种在推理时将基于BPE分词的自回归语言模型转换为字符级或字节级模型的方法，解决了分词带来的生成失真问题，并支持不同分词器的模型集成。


<details>
  <summary>详细信息</summary>
研究动机: 现代语言模型普遍使用分词技术，但分词可能导致生成失真（如提示边界问题），且不同分词器的模型难以直接集成。本文旨在解决这些问题。

研究方法: 提出一种推理时方法，将基于BPE分词的自回归语言模型转换为字符级或字节级模型，保持文本生成分布不变，同时支持不同分词器模型的集成和代理调优。

研究结果: 实验表明，集成和代理调优后的模型在下游任务中表现优于原始模型。

研究结论: 该方法有效解决了分词带来的生成失真和模型集成问题，为语言模型的实际应用提供了灵活性。

中文摘要: 现代语言模型几乎普遍使用分词技术，通过多字节或多字符标记实现高效的文本表示。然而，先前研究表明分词可能扭曲模型的生成。例如，用户常被告知不要在提示末尾加空格，因为这会影响模型将空格作为下一个标记的一部分。这种提示边界问题（PBP）也出现在中文和代码生成中，其中标记常与语法边界不匹配。此外，分词器不匹配常阻碍模型组合和互操作性。例如，由于词汇表不匹配，无法直接集成使用不同分词器的模型。为解决这些问题，我们提出一种推理时方法，将任何基于BPE分词的自回归语言模型转换为字符级或字节级模型，且不改变其文本级生成分布。我们的方法高效解决了PBP问题，还能统一不同分词器语言模型的词汇表，支持在推理时集成不同分词器的模型，并通过代理调优将后训练从一个模型迁移到另一个模型。实验表明，集成和代理调优的模型在下游评估中优于其组成部分。

</details>


### [17] [DCRM: A Heuristic to Measure Response Pair Quality in Preference Optimization](https://arxiv.org/abs/2506.14157)
**中文标题：DCRM：一种衡量偏好优化中响应对质量的启发式方法**

*Chengyu Huang,Tanya Goyal*

主要分类: cs.CL

摘要简述: 本文提出了一种名为DCRM的启发式方法，用于衡量偏好优化中响应对的质量。通过结合距离和奖励边际，DCRM鼓励最小化噪声差异和最大化期望差异，从而提升模型性能。实验表明，高DCRM的训练集能带来更好的学习效果，并提出了一种最佳配对方法进一步提升模型表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究试图将偏好优化性能与底层偏好数据集关联，但作者发现偏好响应间的差异可能不符合期望的学习差异。因此，需要一种量化这些差异的方法，以评估响应对的质量。

研究方法: 提出DCRM（距离校准奖励边际）指标，结合距离和奖励边际量化响应对的差异。通过分析三类常用偏好数据集，研究DCRM与学习效果的关系，并提出最佳配对方法选择高DCRM的响应对。

研究结果: 实验证明，高DCRM的训练集与更好的学习效果相关。提出的最佳配对方法在AlpacaEval、MT-Bench和Arena-Hard等任务中显著提升了模型性能。

研究结论: DCRM是一种有效的响应对质量衡量指标，能够指导偏好数据集的构建，从而优化模型学习效果。

中文摘要: 近期研究尝试将偏好优化（PO）性能与底层偏好数据集关联。本文观察到，偏好响应$y^+$与非偏好响应$y^-$之间的差异会影响大语言模型的学习效果，而这些差异可能与期望的学习目标不匹配。因此，我们使用距离和奖励边际量化这些差异，并将其结合为距离校准奖励边际（DCRM），用于衡量PO中响应对的质量。直观上，DCRM鼓励最小化噪声差异和最大化期望差异。基于此，我们研究了三类常用偏好数据集，按响应来源和偏好标注函数分类。实验表明，训练集的DCRM越高，学习效果越好。受此启发，我们提出了一种最佳-$N^2$配对方法，选择DCRM最高的响应对。实证结果显示，在各种设置下，该方法生成的训练数据集在AlpacaEval、MT-Bench和Arena-Hard任务中均能进一步提升模型性能。

</details>


### [18] [S$^4$C: Speculative Sampling with Syntactic and Semantic Coherence for Efficient Inference of Large Language Models](https://arxiv.org/abs/2506.14158)
**中文标题：S$^4$C：基于语法和语义连贯性的推测采样方法用于大型语言模型高效推理**

*Tao He,Guang Huang,Yu Yang,Tianshi Xu,Sicheng Zhao,Guiguang Ding,Pengyang Wang,Feng Tian*

主要分类: cs.CL

摘要简述: 本文提出了一种名为S$^4$C的框架，通过结合语法和语义连贯性的推测采样方法，显著提升大型语言模型的推理效率，减少延迟并增加有效令牌生成。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在多样化下游任务中表现出卓越的推理能力，但其自回归特性导致推理延迟较高，难以满足实时应用需求。现有推测采样方法未充分利用文本生成的连贯性，限制了效率提升。

研究方法: S$^4$C框架扩展了推测采样方法，采用多头草稿生成快速令牌，并通过连续验证树高效验证候选令牌和特征复用。

研究结果: 实验表明，S$^4$C在主流任务中优于基线方法，提升效率、并行性，并以更少计算资源生成更多有效令牌。在Spec-bench基准测试中，加速比达2.26x-2.60x。

研究结论: S$^4$C通过结合语法和语义连贯性，显著提升了大型语言模型的推理效率，为实时应用提供了更优解决方案。

中文摘要: 大型语言模型（LLMs）在多样化下游任务中展现出卓越的推理能力，但其自回归特性导致推理延迟较高，对实时应用构成挑战。推测采样通过引入草稿生成和并行验证阶段，加速令牌生成与验证。然而，现有方法忽视了文本生成的连贯性，限制了效率提升。为此，我们提出了一种基于语法和语义连贯性的推测采样框架（S$^4$C），通过多头草稿生成快速令牌，并利用连续验证树高效验证候选令牌和特征复用。实验结果表明，S$^4$C在主流任务中超越基线方法，提供更高的效率、并行性，并以更少计算资源生成更多有效令牌。在Spec-bench基准测试中，S$^4$C实现了2.26x-2.60x的加速比，优于现有最优方法。

</details>


### [19] [MIST: Towards Multi-dimensional Implicit Bias and Stereotype Evaluation of LLMs via Theory of Mind](https://arxiv.org/abs/2506.14161)
**中文标题：MIST：基于心理理论的多维隐性偏见与刻板印象评估框架**

*Yanlin Li,Hao Liu,Huimin Liu,Yinwei Wei,Yupeng Hu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为MIST的评估框架，通过心理理论（ToM）和多维刻板印象内容模型（SCM）来评估大型语言模型（LLMs）中的隐性偏见，揭示了其在能力、社交性和道德方面的复杂偏见结构。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法难以捕捉大型语言模型中隐性偏见的微妙和多维特性，且易受社会期望效应影响。本文旨在通过心理理论和刻板印象内容模型，开发一种更全面和间接的评估框架。

研究方法: 提出MIST框架，结合刻板印象内容模型（SCM），设计两种间接任务：词汇联想偏见测试（WABT）和情感归因测试（AAT），以评估隐性偏见的多维表现。

研究结果: 在8种先进LLMs上的实验表明，该框架能揭示复杂的偏见结构，包括普遍的社交性偏见、多维分歧和不对称刻板印象放大。

研究结论: MIST框架为识别隐性偏见的结构性本质提供了更稳健的方法，揭示了LLMs在多维心理理论中的系统性失败。

中文摘要: 大型语言模型（LLMs）中的心理理论（ToM）指其推理心理状态的能力，但这一能力的失败常表现为系统性隐性偏见。评估这种偏见具有挑战性，传统直接查询方法易受社会期望效应影响，且难以捕捉其微妙的多维特性。为此，我们提出一种评估框架，利用刻板印象内容模型（SCM）将偏见重新定义为跨能力、社交性和道德的多维ToM失败。该框架引入两种间接任务：词汇联想偏见测试（WABT）用于评估隐性词汇关联，情感归因测试（AAT）用于测量隐蔽情感倾向，两者均旨在探究潜在刻板印象而不触发模型回避。在8种先进LLMs上的广泛实验表明，该框架能揭示复杂偏见结构，包括普遍的社交性偏见、多维分歧和不对称刻板印象放大，从而为识别隐性偏见的结构性本质提供了更稳健的方法。

</details>


### [20] [GRAM: A Generative Foundation Reward Model for Reward Generalization](https://arxiv.org/abs/2506.14175)
**中文标题：GRAM：一种用于奖励泛化的生成式基础奖励模型**

*Chenglong Wang,Yang Gan,Yifu Huo,Yongyu Mu,Qiaozhi He,Murun Yang,Bei Li,Tong Xiao,Chunliang Zhang,Tongran Liu,Jingbo Zhu*

主要分类: cs.CL

摘要简述: 本文提出了一种生成式基础奖励模型（GRAM），通过结合无监督和有监督学习训练奖励模型，并利用标签平滑优化排序损失，实现了在多种任务中的泛化性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前奖励模型主要依赖有监督学习，仅使用标注的人类偏好数据，限制了其泛化能力。本文旨在探索结合无监督和有监督学习的方法，以提升奖励模型的泛化性和适用性。

研究方法: 基于大语言模型的生成能力，首先通过大规模无监督学习预训练生成式奖励模型，再通过有监督学习微调。同时，利用标签平滑技术优化正则化成对排序损失，将生成模型与判别模型的训练目标统一。

研究结果: 实验表明，该模型在响应排序、人类反馈强化学习及任务适应微调等多个任务中表现优异，显著优于多个基线模型。

研究结论: 生成式基础奖励模型（GRAM）通过结合无监督和有监督学习，实现了广泛的泛化能力，为奖励模型的训练提供了新视角。

中文摘要: 在大型语言模型（LLM）对齐中，奖励模型扮演了重要角色，但通常作为判别模型训练，仅依赖标注的人类偏好数据。本文探索了结合无监督和标注数据训练奖励模型的方法。基于LLM的生成模型，我们开发了一种生成式奖励模型，首先通过大规模无监督学习预训练，再通过有监督学习微调。同时，我们发现使用标签平滑实际上是在优化正则化成对排序损失。这一结果为训练奖励模型提供了新视角，将生成模型与判别模型统一到同一类训练目标下。这些技术的成果是一个基础奖励模型，可广泛应用于多种任务，几乎无需进一步微调。大量实验表明，该模型在响应排序、人类反馈强化学习及任务适应微调等任务中泛化性能优异，显著优于多个强基线模型。

</details>


### [21] [Can we train ASR systems on Code-switch without real code-switch data? Case study for Singapore's languages](https://arxiv.org/abs/2506.14177)
**中文标题：能否在没有真实语码转换数据的情况下训练ASR系统？以新加坡语言为例的研究**

*Tuan Nguyen,Huy-Dat Tran*

主要分类: cs.CL

摘要简述: 本研究探讨了如何利用合成语码转换数据训练ASR系统，提出了一种短语级混合方法生成合成数据，并在三种东南亚语言对上验证了其有效性，为语码转换ASR提供了一种低成本解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 语码转换在 multilingual 环境中常见，但转录数据稀缺且昂贵，导致ASR系统难以处理。本研究旨在探索利用合成语码转换数据解决这一问题。

研究方法: 提出了一种短语级混合方法生成合成语码转换数据，并利用单语数据结合合成数据微调预训练ASR模型（如Whisper、MMS、SeamlessM4T），重点关注马来语-英语、普通话-马来语和泰米尔语-英语三种语言对。

研究结果: 实验表明，该训练策略显著提升了ASR在单语和语码转换测试中的性能，其中马来语-英语提升最大，其次是泰米尔语-英语和普通话-马来语。

研究结论: 本研究为语码转换ASR提供了一种低成本开发方法，对研究和工业应用具有重要价值。

中文摘要: 语码转换（CS）在多语言环境中常见，但由于语言复杂性导致的转录数据稀缺且昂贵，给ASR带来了挑战。本研究探讨了利用合成CS数据构建CS-ASR的方法。我们提出了一种短语级混合方法生成模拟自然模式的合成CS数据，并利用单语数据结合合成短语混合CS数据微调大型预训练ASR模型（Whisper、MMS、SeamlessM4T）。本文重点关注三种资源匮乏的东南亚语言对：马来语-英语（BM-EN）、普通话-马来语（ZH-BM）和泰米尔语-英语（TA-EN），建立了一个新的综合基准来评估领先ASR模型的性能。实验结果表明，所提出的训练策略提升了ASR在单语和CS测试中的性能，其中BM-EN提升最大，其次是TA-EN和ZH-BM。这一发现为CS-ASR开发提供了一种经济高效的方法，对研究和工业界具有重要价值。

</details>


### [22] [AsyncSwitch: Asynchronous Text-Speech Adaptation for Code-Switched ASR](https://arxiv.org/abs/2506.14190)
**中文标题：AsyncSwitch：面向代码切换ASR的异步文本-语音适应框架**

*Tuan Nguyen,Huy-Dat Tran*

主要分类: cs.CL

摘要简述: AsyncSwitch是一种异步文本-语音适应框架，通过利用大规模文本数据预训练ASR模型，再微调语音-文本数据，显著降低代码切换ASR的误码率。


<details>
  <summary>详细信息</summary>
研究动机: 开发代码切换ASR系统面临语言歧义和多语言数据稀缺的挑战，传统合成音频方法计算成本高且难以扩展。AsyncSwitch旨在通过文本数据预训练模型，降低对语音数据的依赖。

研究方法: AsyncSwitch采用三阶段方法：1) 在代码切换文本上训练解码器的自注意力和前馈层；2) 使用少量语音-文本数据通过交叉注意力对齐解码器和编码器；3) 对整个模型进行微调。

研究结果: 在马来语-英语代码切换实验中，AsyncSwitch使Whisper模型的相对词错误率降低9.02%，同时提升了新加坡英语、马来语和其他英语变体的单语性能。

研究结论: AsyncSwitch通过异步文本-语音适应框架，有效解决了代码切换ASR的数据稀缺问题，显著提升了模型性能。

中文摘要: 开发代码切换ASR系统因语言歧义和多语言数据稀缺而具有挑战性，而收集此类语音数据成本高昂。先前工作通过文本生成合成音频，但这类方法计算密集且难以扩展。我们提出AsyncSwitch，一种新颖的异步适应框架，利用大规模文本丰富的网络数据，在微调语音-文本语料库之前，预训练ASR模型以适应多样化的代码切换领域。我们的三阶段流程包括：1) 在代码切换文本上训练解码器的自注意力和前馈层；2) 使用少量语音-文本数据通过交叉注意力对齐解码器和编码器；3) 对整个模型进行微调。在马来语-英语代码切换实验中，AsyncSwitch使Whisper模型的相对词错误率降低9.02%，同时提升了新加坡英语、马来语和其他英语变体的单语性能。

</details>


### [23] [MAS-LitEval : Multi-Agent System for Literary Translation Quality Assessment](https://arxiv.org/abs/2506.14199)
**中文标题：MAS-LitEval：基于多智能体系统的文学翻译质量评估**

*Junghwan Kim,Kieun Park,Sohee Park,Hyunggug Kim,Bongwon Suh*

主要分类: cs.CL

摘要简述: 提出MAS-LitEval，一种基于多智能体系统和大语言模型的文学翻译质量评估工具，优于传统指标，能更精准捕捉文学翻译中的文化细节和风格。


<details>
  <summary>详细信息</summary>
研究动机: 传统翻译评估指标（如BLEU和METEOR）过于关注词汇重叠，无法评估文学翻译中的文化细节和风格一致性，因此需要一种更全面的评估方法。

研究方法: 提出MAS-LitEval，利用多智能体系统和大语言模型，从术语、叙事和风格三个维度评估翻译质量，并在《小王子》和《亚瑟王朝廷上的康涅狄格北方佬》的翻译中进行了测试。

研究结果: MAS-LitEval在捕捉文学细节方面表现优异，最高得分达0.890，显著优于传统评估指标。

研究结论: MAS-LitEval为翻译质量评估提供了可扩展且细致的框架，为翻译者和研究者提供了实用工具。

中文摘要: 文学翻译需要保留文化细节和风格元素，而传统指标（如BLEU和METEOR）因过于关注词汇重叠而无法评估这些方面，忽视了叙事一致性和风格忠实性。为此，我们提出MAS-LitEval，这是一种基于多智能体系统和大语言模型的翻译评估工具，从术语、叙事和风格三个维度进行评估。我们在《小王子》和《亚瑟王朝廷上的康涅狄格北方佬》的翻译上测试了MAS-LitEval，并与传统指标进行了对比。结果表明，MAS-LitEval在捕捉文学细节方面表现优异，最高得分达0.890。这项工作为翻译质量评估提供了一个可扩展且细致的框架，为翻译者和研究者提供了实用工具。

</details>


### [24] [ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations](https://arxiv.org/abs/2506.14200)
**中文标题：ELI-Why：评估语言模型解释的教学实用性**

*Brihi Joshi,Keyu He,Sahana Ramnath,Sadra Sabouri,Kaitlyn Zhou,Souti Chattopadhyay,Swabha Swayamdipta,Xiang Ren*

主要分类: cs.CL

摘要简述: 本文介绍了ELI-Why基准，用于评估语言模型在教学中的解释能力，发现GPT-4生成的解释在适应不同教育背景时表现不佳，仅为50%，而人工解释达到79%。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型在教育中广泛应用，但其针对不同学习需求和知识背景的个性化解释能力尚未充分研究。本文旨在评估语言模型生成的教学解释的实用性。

研究方法: 研究引入ELI-Why基准，包含13.4K个“为什么”问题，并通过两项人类研究评估语言模型生成的解释对不同教育阶段（小学、高中、研究生）的适应性。

研究结果: 研究发现，GPT-4生成的解释仅50%符合目标教育背景，而人工解释为79%。此外，学习者认为GPT-4解释比人工解释平均低20%的适应性。

研究结论: 语言模型生成的教学解释在适应不同教育背景时表现有限，需进一步优化以提高教学效果。

中文摘要: 当今语言模型在教育中广泛应用，但其针对不同学习需求和知识背景的个性化响应能力尚未充分探索。为此，我们引入ELI-Why基准，包含13.4K个“为什么”问题，以评估语言模型的教学能力。我们进行了两项人类研究，评估语言模型生成的解释性答案（解释）在小学、高中和研究生三个不同教育阶段的实用性。在第一项研究中，人类评分者扮演“教育者”角色，评估模型解释对不同教育阶段的适应性。我们发现，GPT-4生成的解释仅50%符合目标教育背景，而人工解释为79%。在第二项研究中，人类评分者扮演“学习者”角色，评估解释是否符合其学习需求。在所有教育背景中，用户认为GPT-4生成的解释比人工解释平均低20%的适应性。此外，自动化评估指标显示，不同语言模型家族生成的解释在适应不同学习需求时，其教育水平区分度有限，影响了教学效果。

</details>


### [25] [Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation](https://arxiv.org/abs/2506.14203)
**中文标题：基于梯度选择性增强的命名障碍患者目标识别**

*Jongho Kim,Romain Storaï,Seung-won Hwang*

主要分类: cs.CL

摘要简述: 本研究探讨了语言模型在帮助命名障碍患者识别目标物品名称中的潜力，通过梯度选择性增强方法解决了语义错误和未见术语的挑战，并在真实患者数据上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 命名障碍患者在识别物品名称时面临术语缺失和语义错误的双重挑战，本研究旨在通过语言模型和梯度选择性增强方法解决这些问题，以提升患者的识别能力。

研究方法: 提出了一种基于梯度选择性增强的方法：梯度值控制语义错误下的增强数据质量，梯度方差引导包含未见但相关的术语。在Tip-of-the-Tongue数据集上进行评估，并应用于AphasiaBank的真实患者数据。

研究结果: 模型在基线对比中表现出色，有效解决了语义错误和术语缺失问题，显著提升了命名障碍患者的识别能力。

研究结论: 梯度选择性增强方法在解决命名障碍患者的识别问题上具有潜力，为未来相关研究提供了新思路。

中文摘要: 本研究探讨了语言模型在帮助命名障碍患者识别物品名称中的潜力。识别患者迂回描述中的目标物品涉及术语缺失和语义错误两大挑战：（1）与目标物品相关的术语未被观察到；（2）语义性错语导致的干扰术语与目标物品无关，阻碍识别过程。为解决这些问题，我们提出通过梯度选择性增强方法增强模型对语义错误的鲁棒性，并引入未见术语。具体而言，梯度值控制语义错误下的增强数据质量，梯度方差指导包含未见但相关的术语。由于领域特定数据有限，我们在Tip-of-the-Tongue数据集上评估模型作为中间任务，随后将结果应用于AphasiaBank的真实患者数据。实验结果表明，我们的方法在基线对比中表现优异，有效解决了命名障碍患者的识别挑战。

</details>


### [26] [AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents](https://arxiv.org/abs/2506.14205)
**中文标题：AgentSynth：通用计算机使用代理的可扩展任务生成方法**

*Jingxu Xie,Dylan Xu,Xuandong Zhao,Dawn Song*

主要分类: cs.CL

摘要简述: AgentSynth提出了一种可扩展且经济高效的自动化任务生成管道，用于为通用计算机使用代理生成高质量任务和轨迹数据集。通过信息不对称设计子任务，组合成长时任务后更具挑战性，生成了6,000多个多样化任务。实验显示，顶级LLM代理在任务难度增加时性能显著下降，而生成成本仅为每轨迹0.60美元。


<details>
  <summary>详细信息</summary>
研究动机: 当前通用计算机使用代理的任务生成方法成本高且难以扩展，需要一种自动化、低成本且能生成多样化任务的解决方案。

研究方法: AgentSynth采用基于LLM的任务提议器生成子任务，由执行代理完成并记录轨迹，迭代组合成复合任务。通过调整子任务数量精确控制任务难度。

研究结果: 生成了6,000多个多样化任务，顶级LLM代理在难度1的成功率为18%，难度6时降至4%。每轨迹平均成本仅为0.60美元。

研究结论: AgentSynth提供了一种高效、低成本的任务生成方法，能够显著提升代理的任务处理能力评估，且代码和数据已公开。

中文摘要: 我们提出了AgentSynth，一种可扩展且经济高效的自动化管道，用于为通用计算机使用代理合成高质量任务和轨迹数据集。通过利用信息不对称，AgentSynth生成的子任务在组合成长时任务时更具挑战性，从而创建了6,000多个多样化和真实的任务。我们的管道首先由基于LLM的任务提议器根据角色生成任务，然后由执行代理完成任务并记录轨迹。此过程迭代进行以形成子任务序列，最终由另一代理汇总为难度可控的复合任务。AgentSynth的关键优势在于能够通过调整子任务数量精确调控任务复杂度。实验表明，顶级LLM代理的性能随难度增加显著下降，从难度1的18%成功率降至难度6的4%，突显了基准的难度和区分能力。此外，我们的管道每轨迹平均成本仅为0.60美元，远低于人工标注成本。代码和数据已公开于https://github.com/sunblaze-ucb/AgentSynth。

</details>


### [27] [CausalDiffTab: Mixed-Type Causal-Aware Diffusion for Tabular Data Generation](https://arxiv.org/abs/2506.14206)
**中文标题：CausalDiffTab：混合类型因果感知扩散的表格数据生成**

*Jia-Chen Zhang,Zheng Zhou,Yu-Jie Xiong,Chun-Ming Xia,Fei Dai*

主要分类: cs.CL

摘要简述: CausalDiffTab是一种基于扩散模型的生成模型，专门用于处理混合类型的表格数据（数值和分类特征），并通过混合自适应因果正则化方法提升性能。实验表明其在多个数据集上优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 高质量数据在生成式AI中至关重要，但获取困难且存在隐私问题。合成数据成为主流解决方案，但混合类型表格数据的生成仍面临挑战，如异构数据类型、复杂变量关系和列分布。

研究方法: 提出CausalDiffTab模型，基于扩散模型处理混合类型表格数据，并结合分层先验融合原则的混合自适应因果正则化方法，自适应控制正则化权重。

研究结果: 在七个数据集上的实验表明，CausalDiffTab在所有指标上均优于基线方法。

研究结论: CausalDiffTab通过扩散模型和自适应因果正则化，有效解决了混合类型表格数据生成的挑战，性能显著优于现有方法。

中文摘要: 训练数据已被证明是训练生成式AI中最关键的组成部分之一。然而，获取高质量数据仍然具有挑战性，数据隐私问题更是重大障碍。为满足高质量数据需求，合成数据已成为主流解决方案，在图像、音频和视频等领域表现出色。然而，生成混合类型数据，尤其是高质量表格数据，仍面临重大挑战，主要包括其固有的异构数据类型、复杂的变量间关系以及错综复杂的列分布。本文提出CausalDiffTab，一种基于扩散模型的生成模型，专门设计用于处理包含数值和分类特征的混合表格数据，同时更灵活地捕捉变量间的复杂交互。我们进一步提出基于分层先验融合原则的混合自适应因果正则化方法，自适应控制因果正则化的权重，在不损害生成能力的情况下提升模型性能。在七个数据集上的综合实验表明，CausalDiffTab在所有指标上均优于基线方法。代码公开于：https://github.com/Godz-z/CausalDiffTab。

</details>


### [28] [Explainable Detection of Implicit Influential Patterns in Conversations via Data Augmentation](https://arxiv.org/abs/2506.14211)
**中文标题：通过数据增强实现对话中隐含影响力模式的可解释检测**

*Sina Abdidizaji,Md Kowsher,Niloofar Yousefi,Ivan Garibay*

主要分类: cs.CL

摘要简述: 本文提出了一种改进的方法，用于检测对话中隐含的影响力模式，并通过数据增强技术提升了检测效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着数字化时代的发展，恶意行为者逐渐转向使用隐含的语言策略影响公众认知，而现有模型难以有效检测这些隐含模式。

研究方法: 通过利用先进语言模型的推理能力对现有数据集进行增强，设计了一个能够定位对话中隐含影响力元素的框架。

研究结果: 该方法在检测隐含影响力模式上提升了6%，并在多标签分类任务中分别提升了33%（影响力技术）和43%（受害者脆弱性）。

研究结论: 所提出的方法显著提升了隐含影响力模式的检测能力，并为相关任务提供了更高效的解决方案。

中文摘要: 在数字化时代，随着个人越来越依赖数字平台进行交流和新闻消费，各种行为者利用语言策略影响公众认知。虽然现有模型擅长检测显式模式（如社交媒体帖子中的单条言论），但恶意行为者已转向使用嵌入对话中的隐含影响力语言模式。这些语言模式旨在通过心理渗透影响受害者，从而以隐含方式获取所需信息。本文提出了一种改进的方法来检测此类隐含影响力模式。此外，所提出的模型能够定位对话中这些影响力元素的具体位置。为实现这一目标，我们利用先进语言模型的推理能力对现有数据集进行了增强。设计的框架使对话中隐含影响力模式的检测效果提升了6%。此外，该方法在相关多标签分类任务中，分别将影响力技术和受害者脆弱性的分类效果提升了33%和43%。

</details>


### [29] [Chaining Event Spans for Temporal Relation Grounding](https://arxiv.org/abs/2506.14213)
**中文标题：事件时间跨度链式推理用于时间关系基础**

*Jongho Kim,Dohyeon Lee,Minsoo Kim,Seung-won Hwang*

主要分类: cs.CL

摘要简述: 本文提出了一种新方法（Timeline Reasoning Network, TRN），通过预测事件时间跨度来解决时间关系理解任务中答案重叠导致的不可靠问题，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖答案重叠作为标签来区分相似问题，但可能因偶然相同的答案导致不可靠结果。本文旨在解决这一问题，通过时间线推理提升时间关系理解的准确性。

研究方法: 提出Timeline Reasoning Network（TRN），采用两步归纳推理：首先基于语义和句法信息回答问题，然后通过链式问题预测时间线，用于验证答案的合理性。

研究结果: 在TORQUE和TB-dense数据集上，TRN在时间阅读理解（TRC）和时间关系抽取（TRE）任务中表现优于现有方法，有效解决了虚假答案重叠问题。

研究结论: TRN通过时间线推理显著提升了时间关系理解的准确性，为相关任务提供了更可靠的解决方案。

中文摘要: 准确理解事件之间的时间关系是时间阅读理解（TRC）和关系抽取（TRE）等任务的关键。例如，在TRC中，需要区分以下两个词汇相似但语义不同的问题：“什么在决定之前完成？”和“什么在决定之后完成？”。现有方法依赖答案重叠作为标签，但可能因偶然相同的答案导致不可靠结果。为解决这一问题，本文提出了一种新方法，通过预测事件时间跨度模块引导合理推理行为。我们提出了Timeline Reasoning Network（TRN），采用两步归纳推理：首先基于语义和句法信息回答问题，然后通过链式问题预测时间线以验证答案。在TORQUE和TB-dense数据集上的实验表明，TRN在TRC和TRE任务中优于现有方法，通过时间线预测有效解决了虚假答案重叠问题。

</details>


### [30] [Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team](https://arxiv.org/abs/2506.14234)
**中文标题：Xolver：像奥赛团队一样通过整体经验学习进行多智能体推理**

*Md Tanzib Hosain,Salman Rahman,Md Kishor Morol,Md Rizwan Parvez*

主要分类: cs.CL

摘要简述: Xolver是一种无需训练的多智能体推理框架，通过整合多样化的经验模态（如外部检索、工具使用、协作互动等），赋予黑盒大语言模型持续演化的记忆能力，显著提升复杂推理任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在复杂推理任务中通常孤立运行，缺乏经验积累与整合。相比之下，专家团队（如奥赛或编程竞赛团队）能够利用丰富的经验（如教练指导、工具使用、协作学习等）进行高效推理。Xolver旨在模拟这种经验学习机制，提升模型的推理能力。

研究方法: Xolver通过整合外部检索、自我检索、工具使用、协作互动、智能体驱动评估和迭代优化等多种经验模态，构建了一个持续演化的记忆系统。模型在推理时学习相关策略、代码片段和抽象推理模式，避免从零生成解决方案。

研究结果: Xolver在多种推理任务中表现优异，即使基于轻量级模型（如QWQ-32B），也能超越包括Qwen3-235B、Gemini 2.5 Pro等在内的先进模型。在GSM8K、AIME'24等任务中创下新高，如GSM8K准确率达98.1%。

研究结论: Xolver通过整合多样化经验学习机制，显著提升了模型的推理能力，为通用智能体实现专家级推理迈出了关键一步。

中文摘要: 尽管在复杂推理任务上取得了显著进展，当前的大语言模型（LLMs）通常孤立运行——将每个问题视为独立尝试，缺乏经验的积累与整合。相比之下，专家问题解决者（如奥赛或编程竞赛团队）能够利用丰富的经验：吸收教练的指导、从过去问题中培养直觉、利用工具和库功能的知识、根据同伴的专业知识和经验调整策略、通过试错不断优化推理，甚至在比赛中学习其他相关问题。我们提出了Xolver，一种无需训练的多智能体推理框架，为黑盒大语言模型配备了持续演化的整体经验记忆。Xolver整合了多样化的经验模态，包括外部和自我检索、工具使用、协作互动、智能体驱动评估和迭代优化。通过在推理时学习相关策略、代码片段和抽象推理模式，Xolver避免了从零生成解决方案——标志着从孤立推理向经验感知语言智能体的转变。基于开源和专有模型构建的Xolver，始终优于专用推理智能体。即使使用轻量级骨干模型（如QWQ-32B），它也常常超越包括Qwen3-235B、Gemini 2.5 Pro、o3和o4-mini-high在内的先进模型。使用o3-mini-high时，它在GSM8K（98.1%）、AIME'24（94.4%）、AIME'25（93.7%）、Math-500（99.8%）和LiveCodeBench-V5（91.6%）上取得了新的最佳成绩——凸显了整体经验学习作为实现专家级推理通用智能体的关键步骤。代码和数据可在https://kagnlp.github.io/xolver.github.io/获取。

</details>


### [31] [A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs](https://arxiv.org/abs/2506.14235)
**中文标题：一种多专家结构-语义混合框架：揭示时序知识图谱中的历史模式**

*Yimin Deng,Yuxia Wu,Yejing Wang,Guoshuai Zhao,Li Zhu,Qidong Liu,Derong Xu,Zichuan Fu,Xian Wu,Yefeng Zheng,Xiangyu Zhao,Xueming Qian*

主要分类: cs.CL

摘要简述: 本文提出了一种多专家结构-语义混合框架（MESH），通过整合结构和语义信息，解决了时序知识图谱推理中历史与非历史事件的差异问题，并在三个数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在时序知识图谱推理中仅关注图结构学习或语义推理，未能整合双重推理视角，且无法区分历史与非历史事件的差异，限制了其在不同时序场景中的泛化能力。

研究方法: 提出MESH框架，采用三种专家模块整合结构和语义信息，为不同事件提供推理指导。

研究结果: 在三个数据集上的实验表明，MESH框架显著提升了预测性能。

研究结论: MESH框架通过多专家模块的协同作用，有效解决了时序知识图谱推理中的结构-语义整合问题，并展示了优异的泛化能力。

中文摘要: 时序知识图谱推理旨在利用现有事实预测未来事件，并在多种下游任务中发挥关键作用。以往的方法仅关注图结构学习或语义推理，未能整合双重推理视角以应对不同预测场景。此外，这些方法无法捕捉历史与非历史事件之间的固有差异，限制了其在不同时序上下文中的泛化能力。为此，我们提出了一种多专家结构-语义混合（MESH）框架，通过三种专家模块整合结构和语义信息，为不同事件提供推理指导。在三个数据集上的广泛实验验证了该方法的有效性。

</details>


### [32] [Re-Initialization Token Learning for Tool-Augmented Large Language Models](https://arxiv.org/abs/2506.14248)
**中文标题：工具增强大型语言模型的重新初始化令牌学习方法**

*Chenghao Li,Liu Liu,Baosheng Yu,Jiayan Qiu,Yibing Zhan*

主要分类: cs.CL

摘要简述: 本文提出了一种新的令牌学习方法，通过将工具令牌与现有词嵌入空间对齐，提升大型语言模型（LLMs）在复杂任务（如数值推理、规划生成）中的表现。实验证明该方法在多个数据集上优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在复杂任务（如数值推理、规划生成）中表现不佳，而通过外部工具（如计算器、数据库）增强模型能力是解决这一问题的关键。然而，现有方法为每个工具分配唯一令牌，忽略了工具令牌与词令牌之间的关系，限制了模型的适应性。

研究方法: 提出了一种新的令牌学习方法，通过工具名称或描述构建先验令牌嵌入，用于初始化和正则化可学习的工具令牌嵌入，确保其与词令牌空间对齐。该方法提升了工具调用的准确性。

研究结果: 在GSM8K-XL、FuncQA、KAMEL和VirtualHome数据集上的实验表明，该方法在数值推理、知识问答和规划生成任务中显著优于CoT、REACT、ICL和ToolkenGPT等基线方法。

研究结论: 通过将工具令牌与词令牌空间对齐，本文方法有效提升了大型语言模型在复杂任务中的表现，为工具增强的LLMs提供了新的解决方案。

中文摘要: 大型语言模型表现出卓越的性能，但在复杂任务（如数值推理、规划生成）中仍存在困难。将外部工具（如计算器和数据库）集成到大型语言模型（LLMs）中，对提升其问题解决能力至关重要。当前方法为每个工具分配唯一令牌，使LLMs能够通过令牌预测调用工具，类似于词生成。然而，这种方法未考虑工具令牌与词令牌之间的关系，限制了预训练LLMs的适应性。为解决这一问题，我们提出了一种新的令牌学习方法，从初始化的角度将工具令牌与现有词嵌入空间对齐，从而提升模型性能。我们首先基于工具名称或描述为每个工具构建先验令牌嵌入，用于初始化和正则化可学习的工具令牌嵌入，确保其与词令牌空间对齐，提高工具调用准确性。我们在GSM8K-XL、FuncQA、KAMEL和VirtualHome数据集上评估了该方法在数值推理、知识问答和规划生成任务中的表现。结果表明，该方法明显优于CoT、REACT、ICL和ToolkenGPT等基线方法，表明我们的方法通过相关令牌有效增强了LLMs在不同领域中的工具调用能力。

</details>


### [33] [From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents](https://arxiv.org/abs/2506.14285)
**中文标题：从生成什么到何时生成：开放域对话代理的及时响应生成**

*Seongbo Jang,Minjin Jeon,Jaehoon Lee,Seonghyeon Lee,Dongha Lee,Hwanjo Yu*

主要分类: cs.CL

摘要简述: 本文提出了一种新颖的任务——及时对话响应生成，并引入了TimelyChat基准，用于评估语言模型在预测适当时间间隔和生成时间条件响应方面的能力。通过利用时间常识知识图谱构建大规模训练数据集，并训练Timer模型，实验证明其在对话响应生成任务中优于其他基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有对话响应生成研究主要关注基于文本上下文的连贯响应生成，而忽略了基于时间上下文的响应时机问题。本文旨在填补这一空白，探索如何生成符合时间条件的及时响应。

研究方法: 本文提出了及时对话响应生成任务，并构建了TimelyChat基准。通过利用时间常识知识图谱中的未标注事件知识，结合大型语言模型（LLM）生成了55K事件驱动的对话数据集。随后训练了Timer模型，该模型能够主动预测时间间隔并生成符合时间条件的响应。

研究结果: 实验结果表明，Timer在轮次级别和对话级别的评估中均优于基于提示的LLM和其他微调基线模型。

研究结论: 本文通过引入时间条件响应生成任务和Timer模型，为对话代理的及时响应生成提供了新的解决方案，并公开了数据、模型和代码。

中文摘要: 尽管对话响应生成的研究主要集中在基于文本上下文生成连贯响应上，但基于时间上下文的何时响应的关键问题仍未得到充分探索。为填补这一空白，我们提出了一种名为及时对话响应生成的新任务，并引入了TimelyChat基准，用于评估语言模型预测适当时间间隔和生成时间条件响应的能力。此外，我们通过利用时间常识知识图谱中的未标注事件知识，并结合大型语言模型（LLM）合成了55K事件驱动的对话，构建了一个大规模训练数据集。随后，我们训练了Timer，这是一种能够主动预测时间间隔并生成符合这些间隔的及时响应的对话代理。实验结果表明，Timer在轮次级别和对话级别的评估中均优于基于提示的LLM和其他微调基线模型。我们公开了数据、模型和代码。

</details>


### [34] [Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent](https://arxiv.org/abs/2506.14302)
**中文标题：基于期望确认的多轮对话推荐代理偏好优化方法**

*Xueyang Feng,Jingsen Zhang,Jiakai Tang,Wei Li,Guohao Cai,Xu Chen,Quanyu Dai,Yue Zhu,Zhenhua Dong*

主要分类: cs.CL

摘要简述: 本文提出了一种名为ECPO的多轮偏好优化方法，通过期望确认理论建模用户满意度演变，优化对话推荐代理的交互能力，显著提升了效率和效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大语言模型的对话推荐代理（CRA）常生成短视回应，难以持续引导用户或满足其期望。尽管偏好优化在单轮对话中有效，但在多轮对话中成本高且效果不佳。本文旨在解决这一问题。

研究方法: 提出多轮偏好优化范式ECPO，利用期望确认理论显式建模用户满意度在多轮对话中的演变，识别不满原因并针对性优化。引入基于大语言模型的用户模拟器AILO，模拟用户反馈并执行期望确认。

研究结果: 实验表明，ECPO显著提升了CRA的交互能力，在效率和效果上均优于现有MTPO方法。

研究结论: ECPO通过建模用户满意度演变和针对性优化，有效解决了多轮对话推荐中的偏好对齐问题，同时降低了采样开销。

中文摘要: 近年来，大语言模型（LLMs）的进步显著推动了对话推荐代理（CRAs）的发展。然而，这些代理常生成短视的回应，难以持续引导用户或满足其期望。尽管偏好优化在单轮对话中有效，但在多轮对话中成本高且效果不佳。为解决这一问题，我们提出了一种新颖的多轮偏好优化（MTPO）范式ECPO，利用期望确认理论显式建模用户满意度在多轮对话中的演变，揭示不满的潜在原因。这些原因可用于支持对不满意回应的针对性优化，从而实现轮级偏好优化。ECPO巧妙地消除了现有MTPO方法的显著采样开销，同时确保优化过程带来有意义的改进。为支持ECPO，我们引入了一个基于LLM的用户模拟器AILO，用于模拟用户反馈并在对话推荐中执行期望确认。实验结果表明，ECPO显著提升了CRA的交互能力，在效率和效果上均优于现有MTPO方法。

</details>


### [35] [Evaluation Should Not Ignore Variation: On the Impact of Reference Set Choice on Summarization Metrics](https://arxiv.org/abs/2506.14335)
**中文标题：评估不应忽视多样性：参考集选择对摘要指标的影响**

*Silvia Casola,Yang Janet Liu,Siyao Peng,Oliver Kraus,Albert Gatt,Barbara Plank*

主要分类: cs.CL

摘要简述: 研究发现，摘要评估中参考集的选择对基于参考的指标（如ROUGE）影响显著，导致模型排名不稳定，建议在评估中考虑参考集的多样性以提高一致性。


<details>
  <summary>详细信息</summary>
研究动机: 人类语言表达具有丰富性和多样性，但摘要评估中常忽视这种变化。现有研究未系统探讨不同参考集对评估指标的影响，本文旨在填补这一空白。

研究方法: 分析了三个多参考摘要数据集（SummEval、GUMSum和DUC2004），研究了参考集选择对流行指标的影响，并收集了人类对LLM输出的评价以补充现有发现。

研究结果: 许多流行指标（尤其是基于n-gram的ROUGE）表现不稳定，模型排名因参考集不同而变化。人类评价与指标的相关性较弱或无相关性。

研究结论: 建议在摘要评估中纳入参考集的多样性，以提高评估的一致性和与人类评价的相关性，尤其是在评估LLM时。

中文摘要: 人类语言表达具有显著的丰富性和多样性，反映了不同的交流风格和意图。然而，这种多样性在摘要评估中常被忽视。虽然已知多参考摘要能提高与人类评价的相关性，但不同参考集对基于参考的指标的影响尚未被系统研究。本文研究了广泛使用的基于参考的指标对参考集选择的敏感性，分析了三个多样化的多参考摘要数据集：SummEval、GUMSum和DUC2004。我们发现许多流行指标表现出显著的不稳定性。这种不稳定性对基于n-gram的指标（如ROUGE）尤为严重，模型排名因参考集不同而变化，削弱了模型比较的可靠性。我们还收集了人类对LLM输出的评价，并研究了其与指标的相关性，以补充新闻摘要之外的现有发现，发现相关性较弱或无相关性。综上所述，我们建议在摘要评估中纳入参考集的多样性，以提高一致性与人类评价的相关性，尤其是在评估LLM时。

</details>


### [36] [A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis](https://arxiv.org/abs/2506.14345)
**中文标题：地理时空深度研究系统的愿景：迈向全面、透明和可复现的地理时空信息合成**

*Bruno Martins,Piotr Szymański,Piotr Gramacki*

主要分类: cs.CL

摘要简述: 本文提出了一种新一代地理时空深度研究系统的愿景，旨在解决当前系统在地理时空推理能力上的不足，推动开放、可复现的基础设施和严格评估协议的发展。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度研究系统缺乏处理地理时空约束的能力，而这些能力在公共卫生、环境科学和社会经济分析等领域至关重要。本文旨在填补这一技术空白，推动更全面的地理时空信息合成。

研究方法: 通过分析当前系统的局限性，提出将地理时空推理能力整合到深度研究流程中，并强调开放基础设施和严格评估协议的重要性。

研究结果: 提出了一个技术路线图，展示了如何在地理时空约束下增强检索和合成能力，为未来AI驱动的信息访问系统奠定基础。

研究结论: 本文为下一代地理时空深度研究系统的发展提供了愿景，强调了开放性和可复现性的重要性，并指出了未来研究方向。

中文摘要: 大型语言模型（LLMs）的出现改变了信息访问方式，当前的LLMs还支持深度研究系统，通过计划性迭代搜索、检索和推理生成全面的报告式答案。然而，当前的深度研究系统缺乏地理时空能力，而这些能力对于回答涉及地理和/或时间约束的上下文丰富问题至关重要，这些问题常见于公共卫生、环境科学或社会经济分析等领域。本文报告了我们关于下一代系统的愿景，指出了将地理时空推理整合到深度研究流程中的重要技术、基础设施和评估挑战。我们主张通过开放和可复现的基础设施以及严格的评估协议，增强检索和合成过程处理地理时空约束的能力。我们的愿景为更先进、具备地理时空意识的深度研究系统指明了方向，可能对未来AI驱动的信息访问产生深远影响。

</details>


### [37] [Digital Gatekeepers: Google's Role in Curating Hashtags and Subreddits](https://arxiv.org/abs/2506.14370)
**中文标题：数字守门人：谷歌在筛选标签和子论坛中的角色**

*Amrit Poudel,Yifan Ding,Jurgen Pfeffer,Tim Weninger*

主要分类: cs.CL

摘要简述: 研究揭示谷歌作为数字守门人，通过算法选择性推广或压制特定标签和子论坛，影响用户接触的信息内容。


<details>
  <summary>详细信息</summary>
研究动机: 探讨搜索引擎如何通过算法管理网络和社交媒体内容的可见性，揭示其对公众话语的影响。

研究方法: 通过比较谷歌搜索结果与Reddit和Twitter/X的非抽样数据，分析内容可见性的系统性偏差。

研究结果: 谷歌算法倾向于压制与色情内容、阴谋论、广告和加密货币相关的子论坛和标签，同时推广高互动内容。

研究结论: 谷歌的守门行为通过筛选社交媒体叙事影响公众话语，凸显其作为数字守门人的重要作用。

中文摘要: 搜索引擎作为数字守门人，通过算法筛选网络和社交媒体内容，对内容的可见性起到关键作用。本研究探讨了谷歌等搜索引擎如何选择性推广或压制特定标签和子论坛，从而影响用户接触的信息。通过比较搜索引擎结果与Reddit和Twitter/X的非抽样数据，我们揭示了内容可见性的系统性偏差。谷歌算法倾向于压制与色情内容、阴谋论、广告和加密货币相关的子论坛和标签，同时推广高互动内容。这些发现表明，谷歌的守门行为通过筛选社交媒体叙事影响公众话语。

</details>


### [38] [ELLIS Alicante at CQs-Gen 2025: Winning the critical thinking questions shared task: LLM-based question generation and selection](https://arxiv.org/abs/2506.14371)
**中文标题：ELLIS Alicante在CQs-Gen 2025：赢得批判性问题生成共享任务：基于LLM的问题生成与选择**

*Lucile Favero,Daniel Frases,Juan Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大型语言模型（LLMs）的两步框架，用于生成和选择批判性问题，以促进深度思考。该系统在ACL 2025的共享任务中获胜。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于LLMs的聊天界面可能助长浅层学习，削弱批判性思维能力。本文旨在利用LLMs生成挑战辩论中无支持或模糊主张的批判性问题，以促进深度推理。

研究方法: 采用两步框架：1）使用小型开源语言模型生成多个候选问题（Questioner）；2）通过另一个模型（Judge）选择最相关的问题。

研究结果: 该系统在ACL 2025的共享任务中排名第一，证明了基于LLMs的方法在促进对论证文本的批判性思考方面的潜力。

研究结论: 研究表明，LLMs可用于生成和选择批判性问题，有效促进对论证文本的深度思考，为未来研究提供了方向。

中文摘要: 基于大型语言模型（LLMs）的聊天界面广泛使用，引发了人们对浅层学习和批判性思维能力削弱的担忧。本文并未仅依赖LLMs检索事实信息，而是探索其通过生成挑战辩论中无支持或模糊主张的批判性问题来促进深度推理的潜力。本研究是第12届论证挖掘研讨会（与ACL 2025联合举办）共享任务的一部分，专注于自动生成批判性问题。我们提出了一个两步框架，包含两个小型开源语言模型：一个生成多个候选问题的“提问者”（Questioner）和一个选择最相关问题的“裁判”（Judge）。我们的系统在共享任务竞赛中排名第一，证明了所提出的基于LLM的方法在鼓励对论证文本的批判性思考方面的潜力。

</details>


### [39] [Thunder-NUBench: A Benchmark for LLMs' Sentence-Level Negation Understanding](https://arxiv.org/abs/2506.14397)
**中文标题：Thunder-NUBench：大语言模型句子级别否定理解的基准**

*Yeonkyoung So,Gyuseong Lee,Sungmok Jung,Joonhak Lee,JiA Kang,Sangho Kim,Jaejin Lee*

主要分类: cs.CL

摘要简述: 本文提出了Thunder-NUBench，一个专门用于评估大语言模型（LLMs）在句子级别否定理解能力的新基准。该基准通过对比标准否定与多样化结构（如局部否定、矛盾、改写等），深入评估模型的否定理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 否定是语言中的基本现象，但对大语言模型（LLMs）的语义理解提出了持续挑战。现有基准通常将否定作为自然语言推理等任务的附带案例，缺乏专门针对否定理解的基准。因此，作者提出Thunder-NUBench，填补这一空白。

研究方法: Thunder-NUBench通过手动构建句子-否定对和多选题数据集，对比标准否定与局部否定、矛盾、改写等多样化结构，深入评估模型的否定理解能力。

研究结果: Thunder-NUBench提供了一个专门用于评估LLMs否定理解能力的基准，能够更全面地测试模型在多样化否定结构中的表现。

研究结论: Thunder-NUBench填补了现有基准的空白，为评估LLMs的句子级别否定理解能力提供了有效工具，有助于推动模型在语义理解方面的进步。

中文摘要: 否定是一种基本的语言现象，对大语言模型（LLMs）的深层语义理解提出了持续挑战。现有基准通常将否定作为自然语言推理等任务的附带案例，导致缺乏专门针对否定理解的基准。本文提出了\textbf{Thunder-NUBench}，一个专门用于评估LLMs句子级别否定理解能力的新基准。Thunder-NUBench不仅限于表面线索检测，还通过对比标准否定与局部否定、矛盾、改写等多样化结构，深入评估模型的否定理解能力。该基准包含手动构建的句子-否定对和多选题数据集，为模型的否定理解提供了全面的评估工具。

</details>


### [40] [ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge](https://arxiv.org/abs/2506.14407)
**中文标题：ImpliRet：隐含事实检索挑战的基准测试**

*Zeinab Sadat Taghavi,Ali Modarressi,Yunpu Ma,Hinrich Schütze*

主要分类: cs.CL

摘要简述: ImpliRet是一个新的检索基准，专注于文档侧隐含事实的推理挑战，而非传统的查询侧处理。实验表明，现有检索模型在此任务上表现不佳，最佳nDCG@10仅为15.07%，长上下文模型如GPT-4.1也仅达到35.06%。


<details>
  <summary>详细信息</summary>
研究动机: 当前检索系统主要依赖表面线索（如关键词重叠），而忽略了文档中隐含的事实推理（如时间、算术和常识关系）。ImpliRet旨在通过简单查询但复杂文档侧推理的基准，推动检索系统在隐含事实处理上的进步。

研究方法: ImpliRet设计了一个基准测试，查询简单但文档相关性依赖于隐含事实（如时间解析、算术和常识关系）。评估了稀疏和密集检索模型，并测试了长上下文模型（如GPT-4.1）的性能。

研究结果: 所有测试的检索模型表现不佳，最佳nDCG@10为15.07%。GPT-4.1在包含正文档的短上下文中仅达到35.06%，表明文档侧推理仍具挑战性。

研究结论: ImpliRet揭示了当前检索系统在隐含事实推理上的不足，为未来研究提供了新的方向。

中文摘要: 检索系统是许多NLP流程的核心，但通常依赖表面线索（如关键词重叠和词汇语义相似性）。为了评估超越这些浅层信号的检索能力，近期基准引入了需要复杂推理的查询；然而，这些方法主要将负担转移到查询侧处理技术（如提示或多跳检索）上。相比之下，我们提出了ImpliRet，一个将推理挑战转移到文档侧处理的基准：查询简单，但相关性依赖于文档中通过时间（如解析“两天前”）、算术和常识关系隐含的事实。我们评估了多种稀疏和密集检索模型，均表现不佳：最佳nDCG@10仅为15.07%。我们还测试了长上下文模型是否能克服这一限制。但即使在仅包含十个文档（包括正文档）的短上下文中，GPT-4.1的得分也仅为35.06%，表明文档侧推理仍是一个挑战。代码可在github.com/ZeinabTaghavi/IMPLIRET.Contribution获取。

</details>


### [41] [LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs](https://arxiv.org/abs/2506.14429)
**中文标题：LongLLaDA：解锁扩散大语言模型的长上下文能力**

*Xiaoran Liu,Zhigeng Liu,Zengfeng Huang,Qipeng Guo,Ziwei He,Xipeng Qiu*

主要分类: cs.CL

摘要简述: 本文首次系统研究了扩散大语言模型（diffusion LLMs）的长上下文能力，发现其在直接上下文外推时保持稳定的困惑度，并提出了一种无需训练的方法LongLLaDA，结合NTK-based RoPE外推技术，验证了扩散LLMs在长上下文任务中的潜力与局限性。


<details>
  <summary>详细信息</summary>
研究动机: 扩散大语言模型在NLP研究中备受关注，但其长上下文能力尚未被系统探索。本文旨在填补这一空白，比较扩散LLMs与传统自回归LLMs的长上下文表现，并探索其独特的特性。

研究方法: 研究首先分析了扩散LLMs在直接上下文外推时的稳定困惑度特性，并通过“大海捞针”任务发现其局部感知现象。基于此，提出了LongLLaDA方法，结合LLaDA与NTK-based RoPE外推技术，无需额外训练即可扩展上下文窗口。

研究结果: 实验表明，扩散LLMs在长上下文外推时表现稳定，且在部分任务中优于自回归LLMs。LongLLaDA方法验证了RoPE外推定律对扩散LLMs的有效性，同时揭示了其在某些任务中的局限性。

研究结论: 本研究首次为扩散LLMs提供了上下文外推方法，并揭示了其长上下文能力的独特现象，为未来研究提供了理论依据和实验基准。

中文摘要: 大语言扩散模型（扩散LLMs）已成为NLP研究的重点，但其长上下文能力尚未得到系统探索。本文首次系统比较了扩散LLMs与传统自回归LLMs的长上下文表现。研究发现，扩散LLMs在直接上下文外推时表现出独特的稳定困惑度特性，并在“大海捞针”任务中展现出局部感知现象，能够从最近的上下文片段中成功检索信息。通过旋转位置嵌入（RoPE）缩放理论，本文解释了这两种现象。基于此，提出了LongLLaDA方法，将LLaDA与基于NTK的RoPE外推技术结合，无需训练即可扩展上下文窗口。实验验证了现有外推缩放定律对扩散LLMs的有效性，同时揭示了扩散LLMs在部分长上下文任务中优于自回归LLMs，而在其他任务中表现不足。本研究不仅为扩散LLMs提供了首个上下文外推方法，还为未来长上下文扩散LLMs的研究提供了重要的理论见解和实验基准。

</details>


### [42] [How Far Can LLMs Improve from Experience? Measuring Test-Time Learning Ability in LLMs with Human Comparison](https://arxiv.org/abs/2506.14448)
**中文标题：LLM能从经验中进步多远？通过人类对比测量LLM的测试时学习能力**

*Jiayin Wang,Zhiquang Guo,Weizhi Ma,Min Zhang*

主要分类: cs.CL

摘要简述: 本文提出评估大语言模型（LLM）在测试时学习能力的方法，通过语义游戏作为测试平台，并与人类表现对比。结果显示LLM具备测试时学习能力，但进步速度和稳定性不及人类。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准主要评估静态知识，而智能还包括从经验中快速学习的能力。本文旨在填补这一空白，评估LLM在测试时学习的能力，以更全面地衡量其智能水平。

研究方法: 采用语义游戏作为测试平台，设计了一个客观评估框架，比较模型在有限经验和累积经验下的表现，并包含四种经验表示形式。同时招募八名人类参与者完成相同任务作为基线。

研究结果: LLM表现出可测量的测试时学习能力，但在累积经验下进步不稳定且速度慢于人类。这表明LLM与人类在动态学习能力上存在显著差距。

研究结论: LLM具备通用学习机器的潜力，但在动态学习能力上与人类仍有较大差距，需进一步研究以缩小这一差距。

中文摘要: 随着大型语言模型的评估设计可能影响我们迈向通用人工智能的轨迹，全面且前瞻性的评估至关重要。现有基准主要评估静态知识，而智能还包括从经验中快速学习的能力。为此，我们提倡评估测试时学习能力，即在测试期间基于经验改进推理密集型任务表现的能力。本研究提出语义游戏作为评估测试时学习的有效测试平台，因其抗饱和性和对策略推理的固有需求。我们引入了一个客观评估框架，比较模型在有限和累积经验设置下的表现，并包含四种经验表示形式。为提供对比基线，我们招募了八名人类参与者完成相同任务。结果显示，LLM表现出可测量的测试时学习能力；然而，其在累积经验下的进步不如人类稳定且速度较慢。这些发现突显了LLM作为通用学习机器的潜力，同时也揭示了模型与人类之间的显著智能差距，无论LLM在静态基准上的表现如何。

</details>


### [43] [LexiMark: Robust Watermarking via Lexical Substitutions to Enhance Membership Verification of an LLM's Textual Training Data](https://arxiv.org/abs/2506.14474)
**中文标题：LexiMark：通过词汇替换增强LLM文本训练数据成员验证的鲁棒水印技术**

*Eyal German,Sagiv Antebi,Edan Habler,Asaf Shabtai,Yuval Elovici*

主要分类: cs.CL

摘要简述: 本文提出了一种名为LexiMark的新型水印技术，通过同义词替换高熵词来增强LLM对水印文本的记忆能力，同时保持语义完整性，从而在LLM训练数据中实现难以检测和移除的成员验证。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLM）可能未经授权使用训练数据，而现有水印方法缺乏隐蔽性，容易被检测和移除。本文旨在提出一种更隐蔽且难以移除的水印技术，以验证LLM是否使用了未经授权的数据。

研究方法: LexiMark通过选择高熵词并进行同义词替换，将水印嵌入文本中。这种方法既不影响文本语义，又增强了LLM对水印文本的记忆能力，使水印难以被检测和移除。

研究结果: 实验在多个开源模型（如LLaMA-1 7B、Mistral 7B等）和不同训练设置下进行，结果显示LexiMark的AUROC分数显著优于现有方法，有效验证了水印数据是否被用于LLM训练。

研究结论: LexiMark作为一种隐蔽且鲁棒的水印技术，能够可靠地验证LLM是否使用了未经授权的训练数据，为数据版权保护提供了新思路。

中文摘要: 大型语言模型（LLM）可能在未经数据所有者同意的情况下被训练或微调。验证特定LLM是否使用了某些数据实例或整个数据集极具挑战性。数据集水印通过在训练数据中嵌入可识别的修改来检测未经授权的使用。然而，现有方法通常缺乏隐蔽性，容易被检测和移除。针对这些局限性，我们提出了LexiMark，一种专为文本和文档设计的新型水印技术，通过对精心选择的高熵词进行同义词替换来嵌入水印。我们的方法旨在增强LLM对水印文本的记忆能力，同时不改变文本的语义完整性。因此，水印难以被检测，完美融入文本且无可见标记，并因其微妙且上下文合适的替换而抵抗自动和手动检测。我们使用近期研究的基线数据集和七个开源模型（包括LLaMA-1 7B、LLaMA-3 8B、Mistral 7B、Pythia 6.9B及其三个较小变体160M、410M和1B）评估了该方法。评估涵盖多种训练设置，包括持续预训练和微调场景。结果显示，与现有方法相比，AUROC分数显著提升，证明了我们的方法在可靠验证未经授权水印数据是否用于LLM训练方面的有效性。

</details>


### [44] [LingoLoop Attack: Trapping MLLMs via Linguistic Context and State Entrapment into Endless Loops](https://arxiv.org/abs/2506.14493)
**中文标题：LingoLoop攻击：通过语言上下文和状态陷阱使多模态大语言模型陷入无限循环**

*Jiyuan Fu,Kaixun Jiang,Lingyi Hong,Jinglun Li,Haijing Guo,Dingkang Yang,Zhaoyu Chen,Wenqiang Zhang*

主要分类: cs.CL

摘要简述: 本文提出LingoLoop攻击，通过语言上下文和状态陷阱使多模态大语言模型（MLLMs）陷入无限循环，导致资源耗尽。攻击利用词性标签和生成路径修剪机制，显著增加生成令牌和能耗。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在推理过程中需要大量计算资源，攻击者可通过诱导其生成过多输出来耗尽资源。现有攻击方法忽略了词性标签和句子结构对输出的影响，限制了攻击效果。

研究方法: 1. 提出词性感知延迟机制，通过调整注意力权重推迟EOS令牌生成；2. 引入生成路径修剪机制，限制隐藏状态幅度以诱导模型生成重复循环。

研究结果: 实验表明，LingoLoop攻击可将生成令牌增加至30倍，能耗显著提升，如Qwen2.5-VL-3B模型。

研究结论: LingoLoop攻击揭示了MLLMs的重大漏洞，对其可靠部署提出挑战。代码将在论文接受后公开。

中文摘要: 多模态大语言模型（MLLMs）展现出巨大潜力，但在推理过程中需要大量计算资源。攻击者可通过诱导其生成过多输出，导致资源耗尽和服务降级。现有的能量-延迟攻击通过广泛偏离EOS令牌的输出令牌分布来增加生成时间，但忽略了词性（POS）特征对EOS令牌生成的影响以及句子结构对输出数量的影响，限制了攻击效果。为此，我们提出LingoLoop攻击，旨在诱导MLLMs生成冗长且重复的序列。首先，我们发现令牌的词性标签显著影响EOS令牌的生成概率。基于此，我们提出词性感知延迟机制，通过调整注意力权重推迟EOS令牌生成。其次，我们限制输出多样性以诱导重复循环，并提出生成路径修剪机制，通过限制隐藏状态幅度促使模型生成持续循环。大量实验表明，LingoLoop可将生成令牌增加至30倍，能耗显著提升（如Qwen2.5-VL-3B模型），持续将MLLMs推向生成极限。这些发现揭示了MLLMs的重大漏洞，对其可靠部署提出挑战。代码将在论文接受后公开。

</details>


### [45] [M2BeamLLM: Multimodal Sensing-empowered mmWave Beam Prediction with Large Language Models](https://arxiv.org/abs/2506.14532)
**中文标题：M2BeamLLM：基于多模态感知和大型语言模型的毫米波波束预测**

*Can Zheng,Jiguang He,Chung G. Kang,Guofa Cai,Zitong Yu,Merouane Debbah*

主要分类: cs.CL

摘要简述: 本文提出了一种名为M2BeamLLM的新型神经网络框架，用于毫米波大规模多输入多输出通信系统中的波束预测。该框架通过整合多模态传感器数据（如图像、雷达、LiDAR和GPS），并利用大型语言模型（如GPT-2）的强大推理能力，显著提高了波束预测的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 毫米波通信系统中的波束预测对车辆与基础设施（V2I）通信至关重要。传统深度学习方法在准确性和鲁棒性上存在不足，尤其是在数据稀缺的情况下。因此，本文旨在通过多模态传感器数据和大型语言模型的结合，提出一种更高效和智能的波束预测解决方案。

研究方法: M2BeamLLM框架整合了多模态传感器数据（图像、雷达、LiDAR和GPS），并利用大型语言模型（如GPT-2）进行波束预测。具体方法包括传感器数据编码、多模态对齐与融合，以及监督微调（SFT）。

研究结果: 实验表明，M2BeamLLM在波束预测的准确性和鲁棒性上显著优于传统深度学习方法，且在标准场景和少样本场景下均表现优异。此外，随着传感器模态多样性的增加，其预测性能持续提升。

研究结论: M2BeamLLM为车辆与基础设施毫米波通信系统提供了一种高效且智能的波束预测解决方案，展示了多模态数据和大型语言模型结合的潜力。

中文摘要: 本文提出了一种名为M2BeamLLM的新型神经网络框架，用于毫米波大规模多输入多输出（mMIMO）通信系统中的波束预测。M2BeamLLM整合了多模态传感器数据（包括图像、雷达、LiDAR和GPS），并利用大型语言模型（如GPT-2）的强大推理能力进行波束预测。通过结合传感器数据编码、多模态对齐与融合以及监督微调（SFT），M2BeamLLM显著提高了波束预测的准确性和鲁棒性，在标准和少样本场景下均优于传统深度学习方法。此外，其预测性能随着传感器模态多样性的增加而持续提升。本研究为车辆与基础设施（V2I）毫米波通信系统提供了一种高效且智能的波束预测解决方案。

</details>


### [46] [AlphaDecay:Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs](https://arxiv.org/abs/2506.14562)
**中文标题：AlphaDecay：面向LLM中重尾平衡的模块化权重衰减**

*Di He,Ajay Jaiswal,Songjun Tu,Li Shen,Ganzhao Yuan,Shiwei Liu,Lu Yin*

主要分类: cs.CL

摘要简述: AlphaDecay是一种针对大型语言模型（LLM）的模块化权重衰减方法，通过根据模块的频谱特性自适应调整衰减强度，提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的权重衰减方法对所有模块使用统一的衰减率，忽略了LLM中不同模块的结构多样性和频谱特性差异。AlphaDecay旨在通过自适应调整衰减强度，平衡模块间的频谱特性差异，从而提升模型表现。

研究方法: AlphaDecay基于重尾自正则化（HT-SR）理论，通过分析权重相关矩阵的经验频谱密度（ESD）量化模块的“重尾性”。重尾性更强的模块（反映更强的特征学习能力）分配较弱的衰减，而频谱较轻的模块分配较强的衰减。

研究结果: 在60M到1B参数规模的模型上进行预训练实验，AlphaDecay在困惑度和泛化能力上均优于传统的统一衰减和其他自适应衰减基线方法。

研究结论: AlphaDecay通过模块化的权重衰减策略，有效平衡了LLM中不同模块的频谱特性差异，显著提升了模型性能。

中文摘要: 权重衰减是训练大型语言模型（LLM）的标准正则化技术。尽管通常为每一层分配统一的衰减率，但这种方法忽略了LLM的结构多样性以及模块间频谱特性的差异。本文提出AlphaDecay，一种简单而有效的方法，能够自适应地为LLM的每个模块分配不同的权重衰减强度。我们的方法基于重尾自正则化（HT-SR）理论，通过分析权重相关矩阵的经验频谱密度（ESD）来量化“重尾性”。表现出更显著重尾ESD的模块（反映更强的特征学习能力）被分配较弱的衰减，而频谱较轻的模块则分配较强的衰减。我们的方法通过定制化的权重衰减分配，平衡了模块间频谱特性的差异，从而提升了性能。在60M到1B参数规模的模型上进行广泛的预训练任务，结果表明AlphaDecay在困惑度和泛化能力上优于传统的统一衰减和其他自适应衰减基线方法。

</details>


### [47] [GenerationPrograms: Fine-grained Attribution with Executable Programs](https://arxiv.org/abs/2506.14580)
**中文标题：GenerationPrograms：基于可执行程序的细粒度归因**

*David Wan,Eran Hirsch,Elias Stengel-Eskin,Ido Dagan,Mohit Bansal*

主要分类: cs.CL

摘要简述: GenerationPrograms是一种模块化生成框架，通过将生成过程分解为创建可执行程序计划和执行模块化文本操作两阶段，显著提升了文本生成的细粒度归因质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有大型语言模型在源条件文本生成中表现优异，但难以提供细粒度的输出归因，影响了可验证性和信任。此外，现有归因方法无法解释模型如何利用源文档生成最终响应，限制了可解释性。

研究方法: GenerationPrograms采用模块化生成框架，将生成过程分为两阶段：1) 创建针对查询的可执行程序计划，包含模块化文本操作（如改写、压缩和融合）；2) 执行这些操作以生成最终响应。

研究结果: 实验表明，GenerationPrograms在两个长问答任务和一个多文档摘要任务中显著提升了文档级和句子级的归因质量，并能作为后验归因方法优于传统技术。

研究结论: GenerationPrograms通过模块化设计和可执行程序计划，不仅提升了归因质量，还支持通过模块级改进实现局部优化，增强了整体归因能力。

中文摘要: 近期的大型语言模型（LLMs）在源条件文本生成中表现出色，但往往无法正确提供输出的细粒度归因，削弱了可验证性和信任。此外，现有归因方法未能解释模型如何利用源文档生成最终响应，限制了可解释性。为解决这些问题，我们提出了模块化生成框架GenerationPrograms，其灵感来自可执行“代码代理”架构的最新进展。与传统生成方法不同，GenerationPrograms将生成过程分解为两个阶段：首先，创建针对查询的可执行程序计划，包含模块化文本操作（如改写、压缩和融合）；其次，按照程序指令执行这些操作以生成最终响应。实验评估表明，GenerationPrograms在两个长问答任务和一个多文档摘要任务中显著提升了文档级和句子级的归因质量。我们还证明，GenerationPrograms可作为后验归因方法，在恢复准确归因方面优于传统技术。此外，GenerationPrograms生成的可解释程序支持通过模块级改进实现局部优化，进一步提升整体归因质量。

</details>


### [48] [Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees](https://arxiv.org/abs/2506.14606)
**中文标题：保证猜测：一种基于语言建模的CISC到RISC转换方法及其测试保证**

*Ahmed Heakl,Sarim Hashmi,Chaimaa Abi,Celine Lee,Abdulrahman Mahmoud*

主要分类: cs.CL

摘要简述: 本文提出了一种名为GG（Guaranteed Guess）的CISC到RISC指令集架构（ISA）转换方法，结合预训练大语言模型（LLM）的翻译能力和软件测试框架，确保翻译的正确性和高效性。实验表明，GG在功能正确性、运行性能、能效和内存使用方面优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 随着硬件生态系统的快速发展，如何在保证正确性的前提下快速、灵活地实现不同指令集架构（ISA）之间的代码转换，成为提升代码可移植性和长期可用性的关键挑战。特别是CISC和RISC架构之间的转换，由于指令复杂度、内存模型和执行范式的根本差异，更具挑战性。

研究方法: GG方法结合预训练大语言模型（LLM）的翻译能力和软件测试框架，首先生成候选翻译代码，然后通过测试框架量化翻译的置信度。实验覆盖两个数据集，确保高代码覆盖率（>98%），并验证功能/语义正确性。

研究结果: GG在HumanEval程序上实现了99%的功能正确性，在BringupBench程序上达到49%。与Apple Silicon的Rosetta 2框架相比，GG的运行性能提升1.73倍，能效提高1.47倍，内存使用减少2.41倍。

研究结论: GG方法在CISC到RISC的代码转换任务中表现出色，兼具高效性和正确性。开源代码、数据、模型和基准测试将为ISA级代码转换研究提供共同基础。

中文摘要: 硬件生态系统正在快速发展，为了提升现有代码的可移植性和长期可用性，如何在快速、灵活且正确的方式下实现不同指令集架构（ISA）之间的低级程序转换成为研究热点。CISC和RISC架构之间的转换尤为困难，因其在指令复杂度、内存模型和执行范式上存在根本差异。本文提出GG（Guaranteed Guess），一种以ISA为中心的转换流程，结合预训练大语言模型（LLM）的翻译能力和成熟的软件测试框架。我们的方法通过LLM生成候选翻译代码，并将其嵌入软件测试框架中以量化翻译的置信度。我们在两个多样化数据集上评估GG方法，确保单元测试的高代码覆盖率（>98%），并在HumanEval程序上实现99%的功能/语义正确性，在BringupBench程序上达到49%。此外，我们与Apple Silicon的Rosetta 2框架对比，GG的转换代码在运行性能上快1.73倍，能效高1.47倍，内存使用减少2.41倍，证明了GG在实际CISC到RISC转换任务中的有效性。我们将开源代码、数据、模型和基准测试，为ISA级代码转换研究建立共同基础。

</details>


### [49] [When Does Meaning Backfire? Investigating the Role of AMRs in NLI](https://arxiv.org/abs/2506.14613)
**中文标题：意义何时适得其反？探究AMR在自然语言推理中的作用**

*Junghyun Min,Xiulin Yang,Shira Wein*

主要分类: cs.CL

摘要简述: 研究发现，在自然语言推理（NLI）中，添加抽象意义表示（AMR）在微调时会阻碍模型泛化，而在提示设置中略有提升，但这种提升源于表面差异的放大而非语义推理。


<details>
  <summary>详细信息</summary>
研究动机: 探讨在自然语言推理任务中，引入抽象意义表示（AMR）是否能帮助预训练语言模型更好地泛化。

研究方法: 通过在微调和提示两种设置中集成AMR进行实验，并进行消融研究以分析AMR的作用。

研究结果: 微调时AMR阻碍模型泛化，提示设置中AMR带来轻微提升，但消融研究表明提升源于表面差异放大而非语义推理。

研究结论: AMR在NLI中的作用有限，其提升效果可能误导模型忽略核心语义。

中文摘要: 自然语言推理（NLI）高度依赖于对前提和假设语义内容的充分解析。本研究探讨了以抽象意义表示（AMR）形式添加语义信息是否能帮助预训练语言模型在NLI中更好地泛化。实验通过在微调和提示两种设置中集成AMR，结果显示微调时AMR阻碍模型泛化，而提示设置中AMR为\texttt{GPT-4o}带来轻微提升。然而，消融研究表明，这种提升源于放大表面差异而非辅助语义推理。这种放大可能导致模型在核心意义保留时仍预测非蕴含关系。

</details>


### [50] [Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models](https://arxiv.org/abs/2506.14625)
**中文标题：概率聚合与目标嵌入优化：大语言模型中的集体道德推理**

*Chenchen Yuan,Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

主要分类: cs.CL

摘要简述: 本文提出了一种框架，通过概率聚合和嵌入优化，将多个大语言模型的道德判断整合为集体共识，并优化偏离模型的嵌入，以提高道德推理的一致性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在复杂道德困境中表现不一致，为解决这一问题，研究旨在通过集体共识和优化方法，提升模型的道德判断一致性和可靠性。

研究方法: 提出概率聚合机制，将多个模型的道德评分融合为集体概率，并根据模型可靠性加权；对偏离共识的模型，采用嵌入优化技术调整其道德哲学理论的词嵌入，以最小化与共识的差异。

研究结果: 实验表明，该方法在大型社会道德困境数据集上成功构建了稳健的集体共识，并显著提升了个体模型的道德判断准确性。

研究结论: 研究表明，跨模型的数据驱动道德对齐具有重要价值，有助于构建更安全、更一致的AI系统。

中文摘要: 大语言模型（LLMs）展现了强大的道德推理能力，但在面对复杂的多因素道德困境时，其判断往往存在分歧。为解决这一问题，我们提出了一种框架，将多个LLMs的道德判断整合为集体共识，并对显著偏离共识的模型进行重新校准。我们的聚合机制将连续的道德可接受性评分（而非二元标签）融合为集体概率，并根据模型可靠性加权贡献。对于偏离模型，采用目标嵌入优化技术，针对道德哲学理论的词嵌入进行微调，以最小化与共识的JS散度，同时保持语义完整性。在大规模社会道德困境数据集上的实验表明，该方法能够构建稳健的共识，并提升个体模型的准确性。这些发现凸显了跨模型数据驱动道德对齐的价值，及其在构建更安全、更一致的AI系统中的潜力。

</details>


### [51] [AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation](https://arxiv.org/abs/2506.14634)
**中文标题：只是一项调查吗？利用大型语言模型编码德语开放式调查回复以研究调查动机**

*Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessika Daikeler*

主要分类: cs.CL

摘要简述: 本文探讨了大型语言模型（LLMs）在德语开放式调查回复编码中的应用，比较了不同LLMs和提示方法的性能，发现仅经过微调的LLM表现最佳，并讨论了其在调查研究中的潜在用途和限制。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLMs的发展和普及，其在调查研究中分类开放式回复的潜力引发关注。然而，现有研究多集中于英语回复或单一LLM，缺乏对其他语言和复杂主题的验证。本研究旨在填补这一空白，以德语调查回复为例，评估LLMs的实际表现。

研究方法: 研究使用德语开放式调查回复数据，比较了多种先进LLMs和不同提示方法，并通过人类专家编码评估其分类性能。

研究结果: 不同LLMs的表现差异显著，仅微调后的LLM达到满意的预测水平。提示方法的效果取决于所用LLM，且LLMs在不同类别上的分类性能不均导致分布差异。

研究结论: LLMs在开放式回复分类中具有潜力，但需权衡其性能差异和微调需求。研究为LLMs在调查研究的应用提供了实证支持，并强调了方法选择和实际限制的重要性。

中文摘要: 最近大型语言模型（LLMs）的发展和普及引发了关于其在调查研究中应用的讨论，包括分类开放式调查回复。由于其语言能力，LLMs可能成为耗时的手动编码和监督机器学习模型预训练的高效替代方案。然而，现有研究多集中于英语回复或非复杂主题，或单一LLM，其结论是否具有普适性以及分类质量与传统方法的比较尚不明确。本研究以德语调查参与动机数据为例，探讨了不同LLMs在其他语境下编码开放式调查回复的能力。我们比较了多种先进LLMs和提示方法，并通过人类专家编码评估其性能。不同LLMs的总体表现差异显著，仅微调后的LLM达到满意的预测水平。提示方法的效果取决于所用LLM。此外，LLMs在不同类别上的分类性能不均导致未微调时的类别分布差异。我们讨论了这些发现对开放式回复编码方法学研究和实质性分析的意义，以及对处理或分析此类数据的实践者的启示。最后，我们强调了在LLMs时代选择自动化方法分类开放式回复时需权衡的诸多因素。本研究为LLMs在调查研究中高效、准确和可靠应用的条件提供了实证支持。

</details>


### [52] [Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot](https://arxiv.org/abs/2506.14641)
**中文标题：重新审视思维链提示：零样本可能优于少样本**

*Xiang Cheng,Chengyan Pan,Minjun Zhao,Deyang Li,Fangchao Liu,Xinyu Zhang,Xiao Zhang,Yong Liu*

主要分类: cs.CL

摘要简述: 研究发现，对于近期强大的语言模型（如Qwen2.5系列），传统的思维链（CoT）示例并不能提升推理性能，反而零样本CoT表现更优。增强的CoT示例同样无效，模型倾向于忽略示例而专注于指令。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型能力的不断提升，传统思维链（CoT）示例是否仍能提升推理性能尚不明确。本文旨在验证CoT示例对近期强大模型的实际效果。

研究方法: 通过系统实验，比较传统CoT示例和零样本CoT在近期强大模型（如Qwen2.5系列）上的表现，并进一步测试增强版CoT示例（基于高级模型答案构建）的效果。

研究结果: 实验表明，传统和增强的CoT示例均未能提升模型推理性能，模型更倾向于忽略示例而关注指令。

研究结论: 当前ICL+CoT框架在数学推理中存在局限性，需重新审视ICL范式及示例定义。

中文摘要: 上下文学习（ICL）是大型语言模型（LLM）的重要涌现能力，近期研究通过思维链（CoT）示例增强其推理能力，尤其在数学任务中。然而，随着模型能力的持续提升，CoT示例是否仍对近期强大模型有益尚不明确。通过系统实验，我们发现对于Qwen2.5系列等近期强大模型，传统CoT示例并未提升推理性能，反而零样本CoT表现更优，其主要作用是使输出格式符合人类预期。进一步研究表明，基于高级模型（如Qwen2.5-Max和DeepSeek-R1）答案构建的增强CoT示例同样无效。深入分析显示，模型倾向于忽略示例而专注于指令，导致推理能力无显著提升。总体而言，我们的研究揭示了当前ICL+CoT框架在数学推理中的局限性，呼吁重新审视ICL范式及示例定义。

</details>


### [53] [Passing the Turing Test in Political Discourse: Fine-Tuning LLMs to Mimic Polarized Social Media Comments](https://arxiv.org/abs/2506.14645)
**中文标题：在政治话语中通过图灵测试：微调大型语言模型以模仿极化社交媒体评论**

*. Pazzaglia,V. Vendetti,L. D. Comencini,F. Deriu,V. Modugno*

主要分类: cs.CL

摘要简述: 研究表明，经过微调的大型语言模型（LLM）能够生成高度逼真且具有煽动性的政治评论，几乎无法与人类撰写的评论区分。这引发了关于AI在政治话语中潜在滥用风险的伦理问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的日益复杂，人们担心其可能通过自动生成带有偏见的内容加剧意识形态极化。本研究旨在探讨微调后的LLM是否能够复制并放大在线环境中的极化言论。

研究方法: 研究使用从Reddit提取的政治化讨论数据集，对开源LLM进行微调，以生成与意识形态一致的上下文感知响应。通过语言分析、情感评分和人工标注评估模型输出，重点关注其可信度和与原话语的修辞一致性。

研究结果: 结果显示，经过党派数据训练的LLM能够生成高度逼真且具有煽动性的评论，甚至难以与人类撰写的评论区分。

研究结论: 研究揭示了AI在政治话语中的潜在滥用风险，呼吁加强AI治理、平台监管，并开发检测工具以应对微调风险。

中文摘要: 大型语言模型（LLM）的日益复杂引发了对其通过自动生成具有说服力和偏见内容加剧意识形态极化的担忧。本研究探讨了微调后的LLM在多大程度上能够复制并放大在线环境中的极化言论。通过使用从Reddit提取的政治化讨论数据集，我们对开源LLM进行微调，以生成上下文感知且与意识形态一致的响应。通过语言分析、情感评分和人工标注评估模型输出，重点关注其可信度和与原话语的修辞一致性。结果表明，经过党派数据训练的LLM能够生成高度逼真且具有煽动性的评论，几乎无法与人类撰写的评论区分。这些发现引发了关于AI在政治话语、虚假信息和操纵活动中使用的重大伦理问题。论文最后讨论了AI治理、平台监管以及开发检测工具以减轻对抗性微调风险的更广泛影响。

</details>


### [54] [GuiLoMo: Allocating Expert Number and Rank for LoRA-MoE via Bilevel Optimization with GuidedSelection Vectors](https://arxiv.org/abs/2506.14646)
**中文标题：GuiLoMo：通过双层优化与引导选择向量为LoRA-MoE分配专家数量与秩**

*Hengyuan Zhang,Xinrong Chen,Yingmin Qiu,Xiao Liang,Ziyue Li,Guanyu Wang,Weiping Li,Tong Mo,Wenyue Li,Hayden Kwok-Hay So,Ngai Wong*

主要分类: cs.CL

摘要简述: GuiLoMo提出了一种基于双层优化和引导选择向量的细粒度专家数量与秩分配策略，解决了LoRA-MoE中专家数量与秩分配的问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: LoRA-MoE结合了LoRA和MoE的优势，但在专家数量分配和秩分配上存在不足：1) 下游任务对专家数量分配的影响未被充分考虑；2) 所有LoRA专家采用统一秩分配，限制了表示多样性。GuiLoMo旨在解决这些问题。

研究方法: GuiLoMo通过双层优化学习引导选择向量（GSVs），捕捉模型和任务需求，动态分配每层的专家数量和秩。实验在多个基准测试和骨干模型上进行验证。

研究结果: 实验表明，GuiLoMo在多个任务和模型上表现优于或与基线方法相当，同时揭示了专家数量和秩在不同层和任务中的变化规律。

研究结论: GuiLoMo通过自适应专家配置显著提升了LoRA-MoE的性能，为参数高效微调提供了新思路。

中文摘要: 参数高效微调（PEFT）方法，尤其是低秩适应（LoRA），提供了一种以较低计算成本适应大语言模型的高效方式。然而，其性能受限于可训练参数数量较少。近期工作将LoRA与专家混合（MoE）结合，即LoRA-MoE，以提升容量，但仍存在两个限制：1) 分配专家数量时未充分考虑下游任务的影响；2) 所有LoRA专家采用统一秩分配，限制了表示多样性。为弥补这些不足，我们提出GuiLoMo，一种基于引导选择向量（GSVs）的细粒度分层专家数量与秩分配策略。GSVs通过双层优化学习，捕捉模型和任务需求，并用于分配最优专家数量和秩。在多个骨干模型和基准测试上的实验表明，GuiLoMo始终优于或与所有基线方法相当。进一步分析揭示了专家数量和秩在不同层和任务中的变化规律，突出了自适应专家配置的优势。代码已开源：https://github.com/Liar406/Gui-LoMo.git。

</details>


### [55] [Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality](https://arxiv.org/abs/2506.14681)
**中文标题：大规模监督微调实验揭示数据、层间及训练因素如何塑造大语言模型对齐质量**

*Yuto Harada,Yusuke Yamauchi,Yusuke Oda,Yohei Oseki,Yusuke Miyao,Yu Takagi*

主要分类: cs.CL

摘要简述: 通过大规模监督微调实验，研究发现数据集特性、层间修改及训练任务协同效应显著影响大语言模型对齐质量，困惑度是预测微调效果的关键指标。


<details>
  <summary>详细信息</summary>
研究动机: 监督微调（SFT）是使大语言模型与人类指令和价值观对齐的关键步骤，但其许多方面仍未被充分理解。本研究旨在探索数据、层间修改及训练任务如何影响SFT效果。

研究方法: 研究团队在多种数据集（包括代码生成、数学推理和通用任务）上训练了1000多个SFT模型，并分析了数据集特性、层间权重变化及训练任务协同效应。

研究结果: 研究发现，某些训练任务的协同效应在所有模型中普遍存在，而其他效应则因模型而异；困惑度能有效预测SFT效果，且中层权重变化与性能提升相关性最强。

研究结论: 研究强调了模型特定策略的重要性，并表明困惑度和中层权重变化是评估SFT效果的关键指标。团队将公开1000多个SFT模型及基准测试结果以推动进一步研究。

中文摘要: 监督微调（SFT）是使大语言模型（LLM）与人类指令和价值观对齐的关键步骤，但其许多方面仍未被充分理解。我们在多种数据集（包括代码生成、数学推理和通用任务）上训练了多种基础模型，生成了1000多个在受控条件下的SFT模型。随后，我们识别了最重要的数据集特性，并研究了SFT引入的层间修改。研究发现，某些训练任务的协同效应在所有模型中普遍存在，而其他效应则因模型而异，这凸显了模型特定策略的重要性。此外，我们证明困惑度能一致预测SFT效果（通常优于训练数据与基准测试之间的表面相似性），且中层权重变化与性能提升相关性最强。我们将公开这1000多个SFT模型及基准测试结果，以加速进一步研究。

</details>


### [56] [Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time Markers](https://arxiv.org/abs/2506.14702)
**中文标题：寻宝：利用训练时标记实时定位长尾数据**

*Daniel D'souza,Julia Kreutzer,Adrien Morisot,Ahmet Üstün,Sara Hooker*

主要分类: cs.CL

摘要简述: 本文提出了一种通过训练时标记优化模型在长尾数据上表现的方法，显著提升了罕见用例的性能和可控性。


<details>
  <summary>详细信息</summary>
研究动机: 现代机器学习面临的主要挑战之一是如何在罕见和代表性不足的长尾数据上表现良好。现有的大型通用模型虽然在多数任务上表现优秀，但在低频用例上效果不佳，且训练后难以针对特定用例进行优化。本文旨在通过改进训练协议，提升模型在长尾数据上的性能和可控性。

研究方法: 作者重新审视了训练与推理技术的界限，提出了一种基于数据特征和任务来源的详细分类法，用于显式控制生成属性和隐式条件生成。通过微调基础模型自动推断这些标记，使其在推理时可选择性使用。

研究结果: 实验结果显示，该方法在开放生成质量上平均提升了5.7%的胜率，在代表性不足的领域中增益超过9.1%。在CodeRepair等罕见任务上，相对提升高达14.1%，在长度指令遵循评估中绝对提升35.3%。

研究结论: 本文提出的方法通过训练时标记显著提升了模型在长尾数据上的性能和可控性，为罕见用例的优化提供了灵活且有效的解决方案。

中文摘要: 现代机器学习最深刻的挑战之一是在罕见和代表性不足的长尾特征上表现良好。大型通用模型虽然针对多种任务训练，但在高频用例上表现最佳。训练后，模型难以适应训练语料中代表性不足的特定用例。依赖提示工程或少样本示例来最大化特定测试用例的输出质量可能令人沮丧，因为模型可能对小变化高度敏感，以不可预测的方式反应，或依赖固定系统提示来维持性能。在这项工作中，我们提出：“能否通过优化训练协议，在推理时同时提升可控性和在代表性不足用例上的表现？”我们重新审视训练与推理技术的界限，以提升长尾性能，并为用户提供一组模型训练时能够响应的控制杠杆。我们创建了数据特征和任务来源的详细分类法，以显式控制生成属性并在推理时隐式条件生成。我们微调基础模型以自动推断这些标记，使其在推理时可选择性使用。这种原则性和灵活的方法显著提升了性能，尤其是在训练分布的长尾示例上。尽管我们的标记在开放生成质量上平均提升了5.7%的胜率，但在代表性不足的领域中增益超过9.1%。在CodeRepair等罕见任务上，相对提升高达14.1%，在长度指令遵循评估中绝对提升35.3%。

</details>


### [57] [Capacity Matters: a Proof-of-Concept for Transformer Memorization on Real-World Data](https://arxiv.org/abs/2506.14704)
**中文标题：容量至关重要：Transformer在真实数据上的记忆能力概念验证**

*Anton Changalidis,Aki Härmä*

主要分类: cs.CL

摘要简述: 本文研究了生成式Transformer的记忆能力如何受模型架构和数据配置影响，发现嵌入大小是学习速度和容量的主要决定因素，而Softmax激活函数表现更稳定。


<details>
  <summary>详细信息</summary>
研究动机: 探讨模型架构和数据配置对生成式Transformer记忆能力的影响，以优化模型设计并提升对结构化真实数据的理解。

研究方法: 使用基于SNOMED知识图谱的合成文本数据集（三元组和序列）训练模型，分析嵌入大小、层数和激活函数对记忆能力的影响。

研究结果: 嵌入大小是学习速度和容量的关键因素，额外层数对简单数据集效果有限甚至有害，Softmax激活函数表现更稳定，数据复杂性提升最终记忆能力。

研究结论: 研究揭示了Transformer记忆机制的关键因素，为优化模型设计提供了框架，尤其适用于结构化真实数据场景。

中文摘要: 本文研究了模型架构和数据配置如何影响生成式Transformer的经验记忆能力。模型使用基于系统化医学命名法（SNOMED）知识图谱的合成文本数据集进行训练：三元组代表静态连接，序列模拟复杂关系模式。结果表明，嵌入大小是学习速度和容量的主要决定因素，而额外层数带来的益处有限，甚至可能对简单数据集产生负面影响。激活函数起关键作用，Softmax表现出更高的稳定性和容量。此外，增加数据集的复杂性似乎能提升最终的记忆能力。这些发现深化了我们对Transformer记忆机制的理解，并为优化模型设计提供了框架，尤其适用于结构化真实数据。

</details>


### [58] [Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.14731)
**中文标题：Ring-lite：基于C3PO稳定的强化学习实现大型语言模型的可扩展推理**

*Ring Team,Bin Hu,Cai Chen,Deng Zhao,Ding Liu,Dingnan Jin,Feng Zhu,Hao Dai,Hongzhi Luan,Jia Guo,Jiaming Liu,Jiewei Wu,Jun Mei,Jun Zhou,Junbo Zhao,Junwu Xiong,Kaihong Zhang,Kuan Xu,Lei Liang,Liang Jiang,Liangcheng Fu,Longfei Zheng,Qiang Gao,Qing Cui,Quan Wan,Shaomian Zheng,Shuaicheng Li,Tongkai Yang,Wang Ren,Xiaodong Yan,Xiaopei Wan,Xiaoyun Feng,Xin Zhao,Xinxing Yang,Xinyu Kong,Xuemin Yang,Yang Li,Yingting Wu,Yongkang Liu,Zhankai Xu,Zhenduo Zhang,Zhenglei Zhou,Zhenyu Huang,Zhiqiang Zhang,Zihao Wang,Zujie Wen*

主要分类: cs.CL

摘要简述: Ring-lite是一种基于混合专家（MoE）的大型语言模型，通过强化学习优化，实现了高效且稳健的推理能力。其性能媲美小型推理模型，但仅需激活三分之一的参数。论文提出了C3PO方法解决训练不稳定性，并通过两阶段训练范式整合多领域数据。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理任务中需要激活大量参数，效率较低。论文旨在通过强化学习优化MoE模型，提升推理效率，同时解决训练中的不稳定性和多领域数据整合问题。

研究方法: 论文提出了一种联合训练流程，结合蒸馏与强化学习（RL），并引入C3PO方法增强训练稳定性。此外，基于熵损失选择蒸馏检查点，并采用两阶段训练范式处理多领域数据冲突。

研究结果: Ring-lite在AIME、LiveCodeBench和GPQA-Diamond等基准测试中表现优异，仅激活2.75亿参数即可媲美小型推理模型。C3PO方法显著提升了训练稳定性，两阶段训练范式有效解决了数据冲突问题。

研究结论: Ring-lite通过C3PO方法和两阶段训练范式，实现了高效且稳健的推理能力，为MoE模型的强化学习训练提供了新思路。论文将发布模型、数据集和代码。

中文摘要: 我们提出了Ring-lite，一种基于混合专家（MoE）的大型语言模型，通过强化学习（RL）优化，实现了高效且稳健的推理能力。该模型基于公开的Ling-lite模型（168亿参数，激活27.5亿参数），在AIME、LiveCodeBench和GPQA-Diamond等挑战性基准测试中，性能媲美小型推理模型，但仅需激活同类模型三分之一的参数。为实现这一目标，我们提出了一种结合蒸馏与RL的联合训练流程，揭示了MoE RL训练中未记录的挑战。首先，我们发现RL训练中的优化不稳定性，并提出了一种新颖的C3PO方法，通过算法-系统协同设计提升训练稳定性和计算吞吐量。其次，实验表明，基于熵损失选择蒸馏检查点用于RL训练，而非验证指标，能在后续RL训练中获得更优的性能-效率权衡。最后，我们开发了一种两阶段训练范式，协调多领域数据整合，解决了混合数据集训练中的领域冲突问题。我们将发布模型、数据集和代码。

</details>


### [59] [Reasoning with Exploration: An Entropy Perspective](https://arxiv.org/abs/2506.14758)
**中文标题：基于熵的探索性推理**

*Daixuan Cheng,Shaohan Huang,Xuekai Zhu,Bo Dai,Wayne Xin Zhao,Zhenliang Zhang,Furu Wei*

主要分类: cs.CL

摘要简述: 本文通过研究熵与语言模型探索性推理的关系，提出了一种基于熵的优势函数改进方法，显著提升了语言模型的推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型在推理任务中偏向利用而非探索，导致性能瓶颈。本文旨在通过熵信号重新审视探索性推理，以突破这一限制。

研究方法: 通过实证分析发现高熵区域与探索性推理行为（如关键标记、自我验证和罕见行为）强相关，并提出一种简单改进：在优势函数中增加基于熵的项。

研究结果: 该方法在Pass@K指标上取得显著提升，即使K值极大时仍有效，拓展了语言模型推理的边界。

研究结论: 通过熵驱动的探索性推理改进，语言模型能够生成更长、更深的推理链，显著提升推理能力。

中文摘要: 在强化学习中，平衡探索与利用是一个核心目标。尽管近期在增强语言模型推理方面取得进展，但多数方法偏向利用，逐渐遭遇性能瓶颈。本文重新审视熵——强化学习中的探索信号，并研究其与语言模型探索性推理的关系。通过实证分析，我们发现高熵区域与三类探索性推理行为呈强正相关：（1）决定或连接逻辑步骤的关键标记，（2）自我验证和修正等反思行为，（3）基础语言模型未充分探索的罕见行为。基于此，我们提出对标准强化学习的极小改进：在优势函数中增加基于熵的项。与传统最大熵方法通过促进不确定性鼓励探索不同，我们通过促进更长、更深的推理链来鼓励探索。值得注意的是，即使在极大K值下评估，我们的方法在Pass@K指标（语言模型推理能力的上限估计器）上仍取得显著提升，拓展了语言模型推理的边界。

</details>


### [60] [From Bytes to Ideas: Language Modeling with Autoregressive U-Nets](https://arxiv.org/abs/2506.14761)
**中文标题：从字节到思想：基于自回归U-Net的语言建模**

*Mathurin Videau,Badr Youbi Idrissi,Alessandro Leite,Marc Schoenauer,Olivier Teytaud,David Lopez-Paz*

主要分类: cs.CL

摘要简述: 本文提出了一种自回归U-Net模型，通过动态学习嵌入标记，解决了传统分词方法（如BPE）的固定粒度问题，实现了多尺度序列处理，并在不同层次上预测未来内容。


<details>
  <summary>详细信息</summary>
研究动机: 传统分词方法（如BPE）对输入文本施加固定的粒度，限制了语言模型的操作方式和预测范围。本文旨在通过动态学习嵌入标记，打破这种刚性，使模型能够灵活处理不同粒度的文本。

研究方法: 提出了一种自回归U-Net模型，该模型从原始字节开始，逐步将字节池化为单词、单词对以及最多4个单词的组合，从而获得序列的多尺度视图。深层阶段专注于更广泛的语义模式，而浅层阶段处理细节。

研究结果: 在精心调整预训练计算的情况下，浅层次结构与强BPE基线相当，而深层次结构显示出良好的趋势。由于分词嵌入模型内部，同一系统可以处理字符级任务并跨低资源语言传递知识。

研究结论: 动态嵌入标记的自回归U-Net模型能够灵活处理多尺度文本，并在不同层次上实现语义预测，为语言模型的分词问题提供了新的解决方案。

中文摘要: 分词对输入文本施加了固定的粒度，限制了语言模型对数据的操作方式和未来预测的范围。字节对编码（BPE）等方案将文本分割一次，构建静态词汇表，使模型无法摆脱这一选择。我们通过引入一种自回归U-Net模型来缓解这种刚性，该模型在训练过程中学习嵌入自己的标记。网络读取原始字节，将其池化为单词、单词对，最多4个单词的组合，从而获得序列的多尺度视图。在更深层次阶段，模型需要预测更远的未来——预测接下来的几个单词而非下一个字节——因此深层阶段专注于更广泛的语义模式，而浅层阶段处理细节。在精心调整和控制预训练计算的情况下，浅层次结构与强BPE基线相当，而深层次结构显示出良好的趋势。由于分词现在嵌入模型内部，同一系统可以处理字符级任务，并在低资源语言之间传递知识。

</details>


### [61] [A Variational Framework for Improving Naturalness in Generative Spoken Language Models](https://arxiv.org/abs/2506.14767)
**中文标题：一种改进生成式口语模型自然度的变分框架**

*Li-Wei Chen,Takuya Higuchi,Zakaria Aldeneh,Ahmed Hussen Abdelaziz,Alexander Rudnicky*

主要分类: cs.CL

摘要简述: 本文提出了一种变分框架，通过自动学习编码连续语音属性来增强语义标记，从而提升生成语音的自然度，避免了手动提取特征的需求。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于自监督模型的语音标记（语义标记）主要关注语音的语言学特征，而忽略了韵律信息，导致生成的语音自然度不足。现有方法通过添加音高特征来改进，但音高无法完全代表副语言属性，且需要手动选择特征。本文旨在解决这一问题。

研究方法: 提出了一种端到端的变分方法，自动学习编码连续语音属性以增强语义标记，无需手动提取或选择副语言特征。

研究结果: 该方法生成的语音在人类评分中表现更优，同时避免了手动特征提取的复杂性。

研究结论: 本文提出的变分框架有效提升了生成语音的自然度，为语音生成模型提供了一种更高效的解决方案。

中文摘要: 大型语言模型在文本处理中的成功激发了其在语音建模中的应用。然而，由于语音是连续且复杂的，通常需要离散化以进行自回归建模。基于自监督模型的语音标记（称为语义标记）通常关注语音的语言学特征，而忽略了韵律信息，导致生成的语音自然度降低。现有方法尝试通过为语义标记添加音高特征来解决这一问题，但音高无法完全代表副语言属性的范围，且选择合适的特征需要精心设计。为此，我们提出了一种端到端的变分方法，自动学习编码这些连续语音属性以增强语义标记。该方法无需手动提取和选择副语言特征，且生成的语音在人类评分中更受青睐。代码、样本和模型可在https://github.com/b04901014/vae-gslm获取。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [62] [Non-planar Object Detection and Identification by Features Matching and Triangulation Growth](https://arxiv.org/abs/2506.13769)
**中文标题：基于特征匹配与三角剖分增长的非平面物体检测与识别**

*Filippo Leveni*

主要分类: cs.CV

摘要简述: 本文提出了一种基于特征匹配和三角剖分增长的非平面物体检测与识别方法，能够在几何模型（如单应性）不适用的情况下有效识别物体。


<details>
  <summary>详细信息</summary>
研究动机: 物体检测与识别是计算机视觉领域的基础课题，广泛应用于目标跟踪、工业机器人控制和图像检索等场景。然而，现有方法在非平面物体或平面物体出现变形时表现不佳，因此需要一种更鲁棒的方法。

研究方法: 通过将模板特征的Delaunay三角剖分作为指导，采用迭代方法逐步匹配图像与模板的特征。将三角剖分视为图结构，从单个三角形开始，逐步评估邻域节点的特征匹配，基于几何和光度一致性标准决定是否分组。

研究结果: 实验表明，在变形较小的情况下，该方法与基于单应性的RANSAC性能相当；而在变形显著时，其描述性能更优。

研究结论: 该方法能够有效识别非平面或变形平面物体，为复杂场景下的物体检测提供了新思路。

中文摘要: 物体检测与识别是计算机视觉领域的基础课题，在目标跟踪、工业机器人控制和图像检索等应用中具有重要作用。本文提出了一种基于特征的方法，通过逐步分组图像与模板之间的特征匹配来检测和识别场景图像中模板的变形实例。为此，我们将模板特征的Delaunay三角剖分作为指导工具，将其视为图结构，从单个三角形出发，逐步评估邻域节点及其对应特征的匹配情况。匹配评估基于局部几何和光度一致性标准。该方法能够在几何模型（如单应性）不适用的情况下识别物体，从而支持非平面或变形平面物体的检测。实验表明，在变形较小的情况下，该方法与基于单应性的RANSAC性能相当；而在变形显著时，其描述性能更优。

</details>


### [63] [CDST: Color Disentangled Style Transfer for Universal Style Reference Customization](https://arxiv.org/abs/2506.13770)
**中文标题：CDST：颜色解耦风格迁移实现通用风格参考定制**

*Shiwen Zhang,Zhuowei Chen,Lang Chen,Yanze Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的颜色解耦风格迁移方法（CDST），通过双流训练范式完全分离颜色与风格，实现了无需调参的通用风格迁移，并在风格相似性和编辑能力上达到最优效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有风格迁移方法通常难以同时保持风格相似性和内容特征，且在通用性和调参需求上存在局限。本文旨在提出一种无需调参的通用风格迁移方法，同时解决颜色与风格的解耦问题。

研究方法: CDST采用双流训练范式，完全隔离颜色与风格，使风格流对颜色不敏感。通过多特征图像嵌入压缩提升风格相似性，并基于Diffusion UNet解耦定律定义新的风格，保留强大的编辑能力。

研究结果: 通过定性和定量实验及人工评估，CDST在多种风格迁移任务中实现了最先进的效果，显著提升了风格相似性并保留了编辑能力。

研究结论: CDST首次以无需调参的方式解决了风格和内容参考的风格迁移问题，为通用风格迁移提供了高效且强大的解决方案。

中文摘要: 我们提出了颜色解耦风格迁移（CDST），这是一种新颖且高效的双流风格迁移训练范式，完全将颜色与风格分离，并迫使风格流对颜色不敏感。通过同一模型，CDST在推理过程中以无需调参的方式解锁了通用风格迁移能力。特别是，首次以无需调参的方式解决了保留特征的风格迁移问题。通过多特征图像嵌入压缩显著提升了风格相似性，并通过受Diffusion UNet解耦定律启发的新CDST风格定义保留了强大的编辑能力。通过全面的定性、定量实验和人工评估，我们证明CDST在各种风格迁移任务中达到了最先进的效果。

</details>


### [64] [Hidden Bias in the Machine: Stereotypes in Text-to-Image Models](https://arxiv.org/abs/2506.13780)
**中文标题：机器中的隐藏偏见：文本到图像模型中的刻板印象**

*Sedat Porikli,Vedat Porikli*

主要分类: cs.CV

摘要简述: 研究发现文本到图像（T2I）模型在生成图像时会复制和放大社会偏见，导致性别、种族、年龄等人类特征的显著差异，呼吁采用更包容的数据集和开发实践。


<details>
  <summary>详细信息</summary>
研究动机: 尽管文本到图像模型在视觉内容创作中表现出色，但其可能复制和放大社会偏见的潜在问题引发担忧。本研究旨在揭示这些偏见的具体表现及其影响。

研究方法: 研究选取了160个主题类别（如职业、特征、行为等），为每个主题设计多个提示变体，使用Stable Diffusion 1.5和Flux-1模型生成16,000多张图像，并从Google Image搜索收集8,000张对比图像，过滤掉抽象或扭曲的结果。

研究结果: 分析显示，生成的图像在性别、种族、年龄和体型等人类特征上存在显著差异，这些差异往往反映并强化了社会叙事中的有害刻板印象。

研究结论: 研究强调了采用更包容的数据集和开发实践的必要性，以促进生成视觉系统的公平性。

中文摘要: 文本到图像（T2I）模型彻底改变了视觉内容创作，能够从自然语言提示生成高度逼真的图像。然而，人们对其可能复制和放大现有社会偏见的担忧持续存在。为研究这些问题，我们策划了一组多样化的提示，涵盖职业、特征、行为、意识形态、情感、家庭角色、地点描述、灵性和生活事件等主题类别。针对160个独特主题，我们设计了多个提示变体以反映广泛的意义和视角。使用Stable Diffusion 1.5（基于UNet）和Flux-1（基于DiT）模型及其原始检查点，在一致设置下生成了超过16,000张图像，并从Google Image搜索收集了8,000张对比图像。所有输出均经过过滤，排除了抽象、扭曲或无意义的结果。分析显示，生成的图像在性别、种族、年龄、体型等人类特征上存在显著差异，这些差异往往反映并强化了社会叙事中的有害刻板印象。我们讨论了这些发现的含义，并强调需要更包容的数据集和开发实践，以促进生成视觉系统的公平性。

</details>


### [65] [Fake it till You Make it: Reward Modeling as Discriminative Prediction](https://arxiv.org/abs/2506.13846)
**中文标题：假装直到成功：奖励建模作为判别性预测**

*Runtao Liu,Jiahao Zhan,Yingqing He,Chen Wei,Alan Yuille,Qifeng Chen*

主要分类: cs.CV

摘要简述: 本文提出GAN-RM框架，通过对抗训练方式构建高效奖励模型，无需人工标注偏好数据或复杂质量维度设计，仅需少量目标样本即可实现强化学习中的奖励建模。


<details>
  <summary>详细信息</summary>
研究动机: 当前奖励建模方法依赖大量人工标注偏好数据或复杂质量维度设计，实现复杂且不完整。本文受GAN对抗训练启发，旨在简化奖励建模流程，提升效率。

研究方法: 提出GAN-RM框架，通过区分少量代表性目标样本（偏好代理数据）与模型生成普通输出的方式训练奖励模型，无需人工标注或显式质量维度设计。

研究结果: 实验表明，GAN-RM在测试时样本过滤（Best-of-N）及后训练方法（如SFT和DPO）中均表现高效且有效。

研究结论: GAN-RM为奖励建模提供了一种高效且无需人工干预的解决方案，显著简化了强化学习中的奖励模型构建流程。

中文摘要: 有效的奖励模型在强化学习中对于视觉生成模型的后训练增强至关重要。然而，当前奖励建模方法因依赖大量人工标注偏好数据或精心设计的质量维度而实现复杂，且这些维度往往不完整且工程密集。受生成对抗网络（GANs）中对抗训练的启发，本文提出GAN-RM，一种高效的奖励建模框架，无需人工偏好标注或显式质量维度设计。我们的方法通过区分少量代表性无配对目标样本（称为偏好代理数据）与模型生成的普通输出来训练奖励模型，仅需数百个目标样本。综合实验表明，GAN-RM在包括测试时缩放（如Best-of-N样本过滤）和后训练方法（如监督微调SFT和直接偏好优化DPO）在内的多个关键应用中均表现出色。

</details>


### [66] [DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding](https://arxiv.org/abs/2506.13897)
**中文标题：DeSPITE：探索对比深度骨骼-点云-IMU-文本嵌入以提升点云人体活动理解**

*Thomas Kreutz,Max Mühlhäuser,Alejandro Sanchez Guinea*

主要分类: cs.CV

摘要简述: 本文提出DeSPITE模型，通过对比学习将LiDAR点云、人体骨骼姿态、IMU数据和文本嵌入到联合空间中，实现了多模态数据的高效融合，并在点云序列的人体活动理解任务中取得了显著效果。


<details>
  <summary>详细信息</summary>
研究动机: LiDAR作为一种隐私保护的感知技术，在多模态对比预训练中尚未充分探索。本文旨在填补这一空白，通过学习点云、骨骼、IMU和文本的联合嵌入空间，提升人体活动理解的性能。

研究方法: 提出DeSPITE模型，利用噪声对比估计方法，将点云、骨骼、IMU和文本四种模态数据嵌入到同一空间中。结合LIPD和Babel数据集，实现了多模态数据的同步与联合学习。

研究结果: 实验表明，DeSPITE在点云序列的人体活动理解任务中表现优异，支持骨骼-点云-IMU匹配、检索和时间片段检索。此外，DeSPITE在MSR-Action3D和HMPEAR数据集上验证了其作为点云HAR预训练策略的有效性。

研究结论: DeSPITE通过多模态联合嵌入学习，显著提升了点云序列的人体活动理解能力，为隐私保护的人体感知技术提供了新的解决方案。

中文摘要: 尽管LiDAR（光探测与测距）作为RGB摄像头的隐私保护替代方案在感知人体活动方面表现优异，但在多模态对比预训练中仍未得到充分探索。为此，本文研究了LiDAR点云、人体骨骼姿态、IMU数据和文本在联合嵌入空间中的对应关系。具体而言，我们提出了DeSPITE（深度骨骼-点云-IMU-文本嵌入模型），通过噪声对比估计方法，有效学习这四种模态的联合嵌入空间。在实证研究中，我们结合了现有的LIPD和Babel数据集，实现了四种模态数据的同步，从而探索了新的联合嵌入空间学习。实验表明，DeSPITE为点云序列的人体活动理解任务（如骨骼<->点云<->IMU匹配、检索和时间片段检索）提供了新的解决方案。此外，通过在MSR-Action3D和HMPEAR数据集上的实验，我们验证了DeSPITE作为点云HAR预训练策略的有效性。

</details>


### [67] [OPTIMUS: Observing Persistent Transformations in Multi-temporal Unlabeled Satellite-data](https://arxiv.org/abs/2506.13902)
**中文标题：OPTIMUS：多时相无标签卫星数据中持久变化的观测**

*Raymond Yu,Paul Han,Josh Myers-Dean,Piper Wolters,Favyen Bastani*

主要分类: cs.CV

摘要简述: OPTIMUS是一种自监督学习方法，通过检测卫星图像时间序列中的持久变化，显著提升了变化检测的性能，AUROC分数从56.3%提升至87.6%。


<details>
  <summary>详细信息</summary>
研究动机: 21世纪面临严峻的环境问题，监测地表变化至关重要。然而，由于缺乏标注变化标签的卫星数据，尤其是稀有变化类别，监督学习方法难以应用。OPTIMUS旨在解决这一挑战。

研究方法: OPTIMUS基于自监督学习原则：如果模型能恢复时间序列中图像的相对顺序信息，则表明图像中存在持久变化。该方法通过时间序列模型输出的变化点检测实现这一目标。

研究结果: OPTIMUS在区分变化与未变化时间序列方面表现优异，AUROC分数从基线的56.3%提升至87.6%。

研究结论: OPTIMUS为卫星图像中的持久变化检测提供了一种高效的自监督学习方法，显著优于基线方法。

中文摘要: 面对21世纪紧迫的环境问题，监测地球表面变化比以往任何时候都更加重要。大规模遥感技术（如卫星图像）是完成这一任务的重要工具。然而，由于缺乏标注变化标签的卫星数据，尤其是稀有变化类别，使用监督方法检测变化十分困难。卫星图像中变化稀疏，标注极具挑战性。即使在大规模图像集中，只有一小部分可能表现出感兴趣的持久变化。为解决这一挑战，我们提出了OPTIMUS，一种基于直观原则的自监督学习方法：如果模型能够恢复时间序列中图像的相对顺序信息，则表明图像中存在持久变化。OPTIMUS通过在时间序列模型输出上应用变化点检测方法验证了这一原则。实验表明，OPTIMUS能直接检测卫星图像中的有趣变化，在区分变化与未变化时间序列方面，AUROC分数从基线的56.3%提升至87.6%。代码和数据集已公开：https://huggingface.co/datasets/optimus-change/optimus-dataset/。

</details>


### [68] [Intelligent Image Sensing for Crime Analysis: A ML Approach towards Enhanced Violence Detection and Investigation](https://arxiv.org/abs/2506.13910)
**中文标题：智能图像感知用于犯罪分析：一种基于机器学习的增强暴力检测与调查方法**

*Aritra Dutta,Pushpita Boral,G Suseela*

主要分类: cs.CV

摘要简述: 本文提出了一种基于机器学习的智能图像感知框架，用于暴力事件的检测与分类，结合3D卷积神经网络和双向LSTM，显著提升了检测效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 全球犯罪率上升及传统监控方法的局限性促使研究者开发自动暴力检测系统，以减少人力和财产损失。

研究方法: 采用监督学习进行二元和多类暴力分类，使用3D卷积神经网络进行检测，结合可分离卷积3D模型和双向LSTM进行特征提取与时间序列处理，并在多样化数据集上训练。

研究结果: 实验表明，该框架在计算资源效率和准确性方面表现优异，能够实时处理监控视频流。

研究结论: 该研究为暴力事件的自动检测与分类提供了高效解决方案，具有实际应用潜力。

中文摘要: 全球犯罪率的上升以及巨大的人力和财产损失，凸显了传统监控方法在及时检测多样化和突发暴力行为方面的局限性。为满足自动暴力检测的迫切需求，我们利用机器学习技术检测和分类视频流中的暴力事件。本文提出了一种全面的暴力检测与分类框架，采用监督学习进行二元和多类暴力分类。检测模型基于3D卷积神经网络，分类模型则利用可分离卷积3D模型进行特征提取，并结合双向LSTM处理时间序列。训练在多样化的定制数据集上进行，包含来自监控摄像头、人类录制、冰球斗殴、SOHAS和WVD数据集的视频。此外，还使用集成树莓派的摄像头模块捕获实时视频流，并发送至机器学习模型处理。实验结果表明，该框架在计算资源效率和准确性方面均有显著提升。

</details>


### [69] [HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment](https://arxiv.org/abs/2506.13925)
**中文标题：HierVL：利用分层视觉-语言协同与动态文本-空间查询对齐的半监督分割方法**

*Numair Nadeem,Saeed Anwar,Muhammad Hamza Asad,Abdul Bais*

主要分类: cs.CV

摘要简述: HierVL是一种半监督语义分割框架，通过结合视觉与语言模型的优势，解决了标签稀缺和领域变化问题，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 半监督语义分割在标签稀缺和领域变化下表现不佳，视觉方法易误分类，而视觉-语言模型缺乏空间定位能力。HierVL旨在结合两者优势，提升分割效果。

研究方法: HierVL包含三个核心模块：分层语义查询生成器、跨模态空间对齐模块和双查询Transformer解码器，通过动态文本-空间查询对齐和正则化损失优化分割性能。

研究结果: 在COCO、Pascal VOC、ADE20和Cityscapes数据集上，HierVL分别实现了4.4%、3.1%、5.9%和1.8%的mIoU提升，显著优于现有方法。

研究结论: HierVL通过语言引导的分割填补了标签效率差距，实现了细粒度和实例感知的泛化，为半监督分割提供了新思路。

中文摘要: 半监督语义分割在标签稀缺和领域变化下仍具挑战性。纯视觉方法易出现像素误分类和边界定位问题，而视觉-语言模型虽提供领域不变的语义，但缺乏密集预测所需的空间定位能力。本文提出HierVL，通过将抽象文本嵌入整合到专为半监督分割设计的掩码Transformer架构中，填补了这一空白。HierVL包含三个创新组件：分层语义查询生成器，用于过滤和投影抽象类别嵌入为多尺度查询以抑制无关类别；跨模态空间对齐模块，用于在稀疏监督下对齐语义查询与像素特征以锐化边界；以及双查询Transformer解码器，用于融合语义和实例级查询以防止实例崩溃。我们还引入了目标正则化损失，以在训练中保持视觉-语言对齐，强化语义定位。HierVL在COCO（232张标注图像）、Pascal VOC（92张标注）、ADE20（158张标注）和Cityscapes（100张标注）上分别实现了4.4%、3.1%、5.9%和1.8%的mIoU平均提升，在1%监督下优于现有方法。结果表明，语言引导的分割填补了标签效率差距，并实现了细粒度和实例感知的泛化。

</details>


### [70] [Mapping Farmed Landscapes from Remote Sensing](https://arxiv.org/abs/2506.13993)
**中文标题：基于遥感技术的农田景观制图**

*Michelangelo Conserva,Alex Wilson,Charlotte Stanton,Vishal Batchu,Varun Gulshan*

主要分类: cs.CV

摘要简述: 本文介绍了Farmscapes，首个覆盖英格兰大部分地区的高分辨率（25厘米）农村景观地图，通过深度学习模型准确识别关键生态特征（如树篱、林地、石墙），为生态学家和政策制定者提供开放工具。


<details>
  <summary>详细信息</summary>
研究动机: 全球生物多样性目标的实现需要详细的农业景观管理，但目前缺乏大规模生态地图。本文旨在填补这一空白，提供高分辨率生态地图以支持数据驱动的规划和监测。

研究方法: 使用深度学习分割模型，基于942块手动标注的航空影像数据集，训练生成高分辨率农村景观地图，包括树篱、林地和农田等关键生态特征。

研究结果: 模型在林地（96%）和农田（95%）的识别上表现优异，树篱分割的F1分数为72%。地图已发布于Google Earth Engine，为生态研究和政策制定提供开放工具。

研究结论: Farmscapes为生态恢复规划和生物多样性监测提供了强大工具，奠定了景观连通性分析的基础，支持欧盟生物多样性战略等倡议。

中文摘要: 农业景观的有效管理对实现全球生物多样性目标至关重要，但缺乏详细的大规模生态地图阻碍了相关努力。为此，我们推出了Farmscapes，这是首个覆盖英格兰大部分地区的高分辨率（25厘米）农村景观地图，包含树篱、林地和石墙等生态关键要素。该地图通过基于942块手动标注航空影像数据集的深度学习分割模型生成。模型在识别关键栖息地方面表现优异，林地和农田的F1分数分别达到96%和95%，树篱分割的F1分数为72%。我们将英格兰全境地图发布于Google Earth Engine，为生态学家和政策制定者提供了强大的开放工具。这项工作支持基于数据的栖息地恢复规划，监测欧盟生物多样性战略等倡议，并为景观连通性分析奠定了基础。

</details>


### [71] [FindMeIfYouCan: Bringing Open Set metrics to $\textit{near} $, $ \textit{far} $ and $\textit{farther}$ Out-of-Distribution Object Detection](https://arxiv.org/abs/2506.14008)
**中文标题：FindMeIfYouCan：将开放集指标引入near、far和farther分布外目标检测**

*Daniel Montoya,Aymen Bouguerra,Alexandra Gomez-Villa,Fabio Arnez*

主要分类: cs.CV

摘要简述: 本文指出当前OOD-OD评估协议的问题，提出基于语义相似性的新评估划分（near、far、farther），并引入开放集指标，展示不同距离OOD对象的检测性能差异。


<details>
  <summary>详细信息</summary>
研究动机: 现有目标检测方法假设测试类别与训练一致，但实际应用中需检测未知对象。当前OOD-OD评估协议存在缺陷，可能掩盖关键问题（如忽略未知对象），导致部署时过度自信。

研究方法: 通过语义相似性手动构建新评估划分（near、far、farther），并引入开放集指标，分析OOD检测性能。

研究结果: 语义和视觉接近的OOD对象更易定位，但也更易与ID对象混淆；far和farther对象定位更难，但不易被误认为ID对象。

研究结论: 新评估协议和指标揭示了OOD检测的复杂性，为安全关键应用提供了更全面的评估框架。

中文摘要: 当前最先进的目标检测（OD）方法主要基于封闭世界假设，即测试类别与训练一致。然而，检测和定位未知对象对自动驾驶和医学影像等安全关键领域至关重要。近年来，分布外（OOD）检测成为OD的重要研究方向，专注于识别通常与未知对象相关的错误预测。本文指出，当前OOD-OD评估协议违反了与分布内（ID）数据集非重叠对象的假设，并掩盖了忽略未知对象等关键情况，可能导致在遇到真正新对象时过度自信。为解决这些限制，我们通过语义相似性手动构建并丰富了现有基准，创建了near、far和farther三类新评估划分。此外，我们引入开放集社区的成熟指标，更深入地揭示方法检测未知对象的有效性、忽略情况以及误将OOD对象分类为ID的情况。综合评估表明，语义和视觉接近的OOD对象更易定位，但也更易与ID对象混淆；far和farther对象定位更难，但不易被误认为ID对象。

</details>


### [72] [Disentangling 3D from Large Vision-Language Models for Controlled Portrait Generation](https://arxiv.org/abs/2506.14015)
**中文标题：从大型视觉语言模型中解耦3D信息以实现可控肖像生成**

*Nick Yiwen Huang,Akin Caliskan,Berkay Kicanaoglu,James Tompkin,Hyeongwoo Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种从大型视觉语言模型中解耦3D信息的方法，用于可控肖像生成。通过规范化和雅可比正则化，实现了对肖像外观和3D几何的自由控制，无需额外标注数据或训练大型模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型视觉语言模型（如CLIP）在生成3D肖像时存在信息纠缠问题，导致输出质量下降和多样性受限。本文旨在解耦3D信息，实现对肖像外观和几何的自由控制，同时避免依赖大规模标注数据或训练资源。

研究方法: 首先，通过规范化将3D形变神经三角平面表示解耦到2D参考框架中。其次，针对大型视觉语言模型嵌入空间中的噪声问题，提出了一种高效的雅可比正则化方法，以提升输出质量和多样性。

研究结果: 相比现有方法，本文方法能够生成具有文本和3D控制功能的肖像，且在改变任一控制参数时保持肖像的一致性。

研究结论: 本文方法为创作者提供了一种无需大规模标注数据或训练资源的可控3D肖像生成方案，具有广泛的应用潜力。

中文摘要: 本文研究了从大型视觉语言模型中解耦3D信息的问题，并以生成3D肖像为例展示了其应用。该方法能够通过自由文本控制肖像的外观属性（如年龄、发型和眼镜）以及3D几何控制（如面部表情和相机姿态）。在此背景下，我们假设使用预训练的大型视觉语言模型（LVLM；如CLIP）从较小的2D数据集中生成内容，无需额外配对标签，并基于预定义的3D可变形模型（FLAME）。首先，我们通过规范化将3D形变神经三角平面表示解耦到2D参考框架中。然而，另一种纠缠形式源于LVLM嵌入空间中描述无关特征的显著噪声。这会损害输出质量和多样性，但我们通过一种高效的随机近似器计算的雅可比正则化克服了这一问题。与现有方法相比，我们的方法生成的肖像具有额外的文本和3D控制功能，且在改变任一控制参数时保持肖像的一致性。总体而言，这种方法使创作者能够基于自己的2D面部数据控制3D生成器，而无需标注大规模数据或训练大型模型的资源。

</details>


### [73] [SimpleDoc: Multi-Modal Document Understanding with Dual-Cue Page Retrieval and Iterative Refinement](https://arxiv.org/abs/2506.14035)
**中文标题：SimpleDoc：基于双线索页面检索与迭代优化的多模态文档理解**

*Chelsi Jain,Yiran Wu,Yifan Zeng,Jiale Liu,S hengyu Dai,Zhenwen Shao,Qingyun Wu,Huazheng Wang*

主要分类: cs.CV

摘要简述: SimpleDoc是一个轻量级但强大的检索增强框架，用于文档视觉问答（DocVQA）。它通过双线索检索和迭代优化，显著提升了证据页面的收集效率，并在多个数据集上表现优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 文档视觉问答（DocVQA）是一项实用但具有挑战性的任务，需要基于多页文档和多模态信息（如图像和表格）回答问题。现有方法虽然采用了检索增强生成（RAG）流程，但在页面检索和答案生成方面仍有改进空间。SimpleDoc旨在通过更高效的检索和迭代优化机制提升性能。

研究方法: SimpleDoc采用双线索检索机制：首先通过嵌入相似性检索候选页面，然后基于页面摘要对这些候选进行过滤和重新排序。一个基于视觉语言模型（VLM）的推理代理会多次调用该检索器，逐步将新页面纳入工作内存，直到问题被自信地回答。

研究结果: SimpleDoc在4个DocVQA数据集上的平均表现优于现有基线3.2%，同时检索的页面数量显著减少。

研究结论: SimpleDoc通过双线索检索和迭代优化机制，显著提升了文档视觉问答的性能和效率，为多模态文档理解提供了轻量级但强大的解决方案。

中文摘要: 文档视觉问答（DocVQA）是一项实用但具有挑战性的任务，需要基于多页文档和多模态信息（如图像和表格）回答问题。为处理多模态信息，现有方法通常采用检索增强生成（RAG）流程，并使用基于视觉语言模型（VLM）的嵌入模型来嵌入和检索相关页面作为图像，再通过支持图像输入的VLM生成答案。本文提出SimpleDoc，一个轻量级但强大的检索增强框架。它通过双线索检索机制提升证据页面收集效率：首先通过嵌入相似性检索候选页面，然后基于页面摘要对这些候选进行过滤和重新排序。一个基于VLM的推理代理会多次调用该检索器，逐步将新页面纳入工作内存，直到问题被自信地回答。SimpleDoc在4个DocVQA数据集上的平均表现优于现有基线3.2%，同时检索的页面数量显著减少。代码已开源：https://github.com/ag2ai/SimpleDoc。

</details>


### [74] [Image Segmentation with Large Language Models: A Survey with Perspectives for Intelligent Transportation Systems](https://arxiv.org/abs/2506.14096)
**中文标题：大语言模型在图像分割中的应用：面向智能交通系统的综述与展望**

*Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma*

主要分类: cs.CV

摘要简述: 本文综述了大语言模型（LLMs）在图像分割领域的应用，特别关注其在智能交通系统（ITS）中的潜力与挑战，包括实时性能和安全可靠性问题。


<details>
  <summary>详细信息</summary>
研究动机: 智能交通系统（ITS）需要高精度的场景理解以确保安全和效率，而大语言模型与计算机视觉的结合为图像分割任务带来了新的可能性。本文旨在探讨这一新兴领域的发展现状、应用前景及挑战。

研究方法: 本文系统性地回顾了LLM增强的图像分割方法，根据提示机制和核心架构对现有技术进行了分类，并分析了其在自动驾驶、交通监控和基础设施维护中的应用。

研究结果: 研究发现，LLM增强的图像分割技术能够显著提升道路场景理解的准确性，但仍面临实时性能和安全可靠性等关键挑战。

研究结论: 未来发展方向应聚焦于可解释、以人为本的AI技术，以确保其在下一代交通系统中的成功部署。

中文摘要: 大语言模型（LLMs）与计算机视觉的结合正在深刻改变图像分割等感知任务。对于智能交通系统（ITS）而言，准确的场景理解对安全和效率至关重要，这一新范式提供了前所未有的能力。本文系统性地综述了LLM增强的图像分割这一新兴领域，重点关注其在ITS中的应用、挑战和未来方向。我们基于提示机制和核心架构对现有方法进行了分类，并探讨了这些创新如何提升自动驾驶、交通监控和基础设施维护中的道路场景理解。最后，我们指出了包括实时性能和安全可靠性在内的关键挑战，并提出了以可解释、以人为本的AI为中心的发展视角，作为该技术在下一代交通系统中成功部署的前提。

</details>


### [75] [FADPNet: Frequency-Aware Dual-Path Network for Face Super-Resolution](https://arxiv.org/abs/2506.14121)
**中文标题：FADPNet：基于频率感知的双路径人脸超分辨率网络**

*Siyu Xu,Wenjie Li,Guangwei Gao,Jian Yang,Guo-Jun Qi,Chia-Wen Lin*

主要分类: cs.CV

摘要简述: FADPNet是一种频率感知的双路径网络，通过将面部特征分解为低频和高频成分，分别用Mamba和CNN处理，实现了在有限计算成本下的高效人脸超分辨率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸超分辨率方法通常对所有像素一视同仁，导致计算资源分配不优和性能下降。CNN对高频特征敏感，而Mamba擅长低频特征且复杂度更低。基于此，提出了FADPNet。

研究方法: FADPNet将面部特征分解为低频和高频成分，分别通过Mamba-based低频增强块（LFEB）和CNN-based深度位置感知注意力（DPA）模块处理，辅以高频细化（HFR）模块。

研究结果: 该方法在超分辨率质量和模型效率之间取得了优异平衡，性能优于现有方法。

研究结论: FADPNet通过频率感知的双路径设计，有效提升了人脸超分辨率的性能，同时保持了计算效率。

中文摘要: 在有限计算成本下实现人脸超分辨率（FSR）仍是一个开放性问题。现有方法通常对所有面部像素平等处理，导致计算资源分配不优和FSR性能下降。CNN对高频面部特征（如轮廓和面部线条）较为敏感，而Mamba擅长捕捉低频特征（如肤色和细粒度纹理），且复杂度低于Transformer。基于这些观察，我们提出了FADPNet，一种频率感知的双路径网络，将面部特征分解为低频和高频成分，并通过专用分支处理。对于低频区域，我们引入了基于Mamba的低频增强块（LFEB），结合状态空间注意力和挤压-激励操作，提取低频全局交互并强调信息通道。对于高频区域，我们设计了基于CNN的深度位置感知注意力（DPA）模块，增强空间依赖的结构细节，辅以轻量级高频细化（HFR）模块进一步优化频率特定表示。通过上述设计，我们的方法在FSR质量和模型效率之间实现了优异平衡，性能优于现有方法。

</details>


### [76] [KDMOS:Knowledge Distillation for Motion Segmentation](https://arxiv.org/abs/2506.14130)
**中文标题：KDMOS：基于知识蒸馏的运动目标分割**

*Chunyu Cao,Jintao Cheng,Zeyu Chen,Linfan Zhan,Rui Fan,Zhijian He,Xiaoyu Tang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于知识蒸馏的运动目标分割框架KDMOS，通过将鸟瞰图投影模型作为学生模型、非投影模型作为教师模型，并结合动态上采样和网络架构优化，显著提升了分割精度和实时性。


<details>
  <summary>详细信息</summary>
研究动机: 运动目标分割（MOS）在自动驾驶中至关重要，但现有方法在精度和实时性之间难以平衡。为了解决这一问题，本文提出了一种知识蒸馏框架，旨在提升分割精度同时保持实时效率。

研究方法: 采用鸟瞰图（BEV）投影模型作为学生模型，非投影模型作为教师模型。针对运动与非运动类别的严重不平衡问题，解耦并应用定制化的蒸馏策略，优化动态上采样和网络架构，减少参数数量7.69%。

研究结果: 在SemanticKITTI-MOS数据集的隐藏测试集上实现了78.8%的IoU，并在Apollo数据集上取得了竞争性结果，显著减少了假阳性和假阴性。

研究结论: KDMOS框架通过知识蒸馏和网络优化，显著提升了运动目标分割的精度和效率，为自动驾驶应用提供了实用解决方案。

中文摘要: 运动目标分割（MOS）对自动驾驶至关重要，可提升定位、路径规划、地图构建、场景流估计和未来状态预测。现有方法虽性能优异，但平衡精度与实时推理仍具挑战性。为此，我们提出了一种基于logits的知识蒸馏框架，旨在提升精度同时保持实时效率。具体而言，我们采用鸟瞰图（BEV）投影模型作为学生模型，非投影模型作为教师模型。针对运动与非运动类别的严重不平衡问题，解耦并应用定制化蒸馏策略，使教师模型更好地学习关键运动特征，显著减少假阳性和假阴性。此外，引入动态上采样，优化网络架构，参数数量减少7.69%，缓解过拟合。我们的方法在SemanticKITTI-MOS数据集的隐藏测试集上实现了78.8%的IoU，并在Apollo数据集上表现优异。KDMOS实现代码已开源：https://github.com/SCNU-RISLAB/KDMOS。

</details>


### [77] [Interpreting Biomedical VLMs on High-Imbalance Out-of-Distributions: An Insight into BiomedCLIP on Radiology](https://arxiv.org/abs/2506.14136)
**中文标题：解读BiomedCLIP在高度不平衡分布外数据上的表现：放射学领域的洞察**

*Nafiz Sadman,Farhana Zulkernine,Benjamin Kwan*

主要分类: cs.CV

摘要简述: 本文通过分析开源视觉语言模型BiomedCLIP在高度不平衡、分布外多标签医学数据集上的表现，探讨其嵌入空间的类别分离性，并量化其局限性。实验表明，零样本推理表现不佳，而全微调和线性探测能提升分类效果。


<details>
  <summary>详细信息</summary>
研究动机: 研究BiomedCLIP在高度不平衡、分布外医学数据集上的表现，探索其嵌入空间的类别分离性，并量化其在实际应用中的局限性，以提升模型的可靠性和适用性。

研究方法: 在IU-xray数据集上评估BiomedCLIP的三种分类方式：零样本推理、全微调和线性探测。通过Grad-CAM热图可视化模型理解，并与放射科医生的15个标注进行对比。

研究结果: 零样本推理表现差，全微调提升疾病分类效果，线性探测能检测重叠特征。模型在真实场景中需谨慎调整。

研究结论: BiomedCLIP在医学影像分类中需进一步优化以适应真实场景，全微调和线性探测是有效改进方向。

中文摘要: 本文构建了两个研究目标：i) 探索开源视觉语言模型BiomedCLIP的嵌入空间，分析其类别分离性；ii) 量化BiomedCLIP在高度不平衡、分布外多标签医学数据集上的局限性。实验基于IU-xray数据集，评估了BiomedCLIP在零样本推理、全微调和线性探测三种场景下的分类表现。结果显示，零样本推理表现不佳，全微调提升疾病分类效果，线性探测能检测重叠特征。通过Grad-CAM热图可视化模型理解，并与放射科医生的标注对比，强调了模型在实际应用中需谨慎调整的必要性。实验代码已在GitHub上开源。

</details>


### [78] [RadFabric: Agentic AI System with Reasoning Capability for Radiology](https://arxiv.org/abs/2506.14142)
**中文标题：RadFabric：具备推理能力的智能AI系统用于放射学**

*Wenting Chen,Yi Dong,Zhaojun Ding,Yucheng Shi,Yifan Zhou,Fang Zeng,Yijun Luo,Tianyu Lin,Yihang Su,Yichen Wu,Kai Zhang,Zhen Xiang,Tianming Liu,Ninghao Liu,Lichao Sun,Yixuan Yuan,Xiang Li*

主要分类: cs.CV

摘要简述: RadFabric是一种多智能体、多模态推理框架，结合视觉与文本分析，提升胸部X光（CXR）诊断的全面性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前自动化系统在胸部X光诊断中存在病理覆盖不足、诊断准确性有限以及视觉与文本推理整合不足的问题，RadFabric旨在解决这些缺陷。

研究方法: RadFabric基于模型上下文协议（MCP），整合了病理检测智能体、解剖解释智能体和推理智能体，通过多模态特征对齐和偏好驱动推理实现透明且基于证据的诊断。

研究结果: RadFabric在挑战性病理（如骨折）检测中达到1.000的准确率，总体诊断准确率为0.799，显著优于传统系统（0.229至0.527）。

研究结论: RadFabric通过跨模态特征对齐和偏好驱动推理，推动了AI驱动的放射学向透明、解剖精确且临床可操作的CXR分析发展。

中文摘要: 胸部X光（CXR）成像是诊断胸部疾病的关键工具，但当前自动化系统在病理覆盖范围、诊断准确性以及视觉与文本推理整合方面存在局限性。为解决这些问题，我们提出了RadFabric，一种多智能体、多模态推理框架，统一视觉与文本分析以实现全面的CXR解读。RadFabric基于模型上下文协议（MCP），具备模块化、互操作性和可扩展性，可无缝集成新的诊断智能体。系统包括专门的CXR病理检测智能体、解剖解释智能体（将视觉发现映射到精确解剖结构）以及由大型多模态推理模型驱动的推理智能体，综合视觉、解剖和临床数据，生成透明且基于证据的诊断。RadFabric在挑战性病理（如骨折）检测中实现近乎完美的准确率（1.000），总体诊断准确率（0.799）显著优于传统系统（0.229至0.527）。通过整合跨模态特征对齐和偏好驱动推理，RadFabric推动了AI驱动的放射学向透明、解剖精确且临床可操作的CXR分析迈进。

</details>


### [79] [SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability](https://arxiv.org/abs/2506.14144)
**中文标题：SceneAware：基于LLM引导可通行性的场景约束行人轨迹预测**

*Juho Bai,Inwook Shim*

主要分类: cs.CV

摘要简述: SceneAware是一种新框架，通过结合场景理解和行人轨迹预测，利用视觉Transformer和多模态大语言模型生成可通行性掩码，显著提升了预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有行人轨迹预测方法主要关注行人间的社交互动，而忽略了环境背景对人类移动模式的显著影响。SceneAware旨在通过显式结合场景信息，提高预测的准确性和物理合理性。

研究方法: 方法包括：1) 使用视觉Transformer编码静态场景图像的环境背景；2) 利用多模态大语言模型生成可通行性掩码；3) 结合基于Transformer的轨迹编码器，捕捉时空动态和空间约束；4) 引入碰撞惩罚机制，确保预测轨迹符合物理边界。

研究结果: 在ETH/UCY基准数据集上的实验表明，SceneAware优于现有方法，性能提升超过50%。模型在不同类型行人移动中表现一致，验证了其有效性和可靠性。

研究结论: SceneAware通过显式结合场景信息，显著提升了行人轨迹预测的准确性和物理合理性，证明了场景感知方法的有效性。

中文摘要: 准确预测行人轨迹对机器人和监控系统应用至关重要。现有方法主要关注行人间的社交互动，却忽略了显著影响人类移动模式的环境背景。本文提出SceneAware，一种新框架，通过显式结合场景理解提升轨迹预测准确性。方法利用视觉Transformer（ViT）编码静态场景图像的环境背景，同时通过多模态大语言模型（MLLMs）生成区分可通行与受限区域的二值掩码。我们将基于Transformer的轨迹编码器与ViT场景编码器结合，捕捉时空动态和空间约束。框架还整合了碰撞惩罚机制，避免预测轨迹违反物理边界，确保预测的物理合理性。SceneAware实现了确定性和随机性两种变体。在ETH/UCY基准数据集上的全面实验表明，我们的方法优于现有技术，性能提升超过50%。基于不同轨迹类别的分析显示，模型在各类行人移动中表现一致。这凸显了显式场景信息的重要性，并表明我们的场景感知方法在生成准确且物理合理的预测中既有效又可靠。代码见：https://github.com/juho127/SceneAware。

</details>


### [80] [VideoMAR: Autoregressive Video Generatio with Continuous Tokens](https://arxiv.org/abs/2506.14168)
**中文标题：VideoMAR：基于连续令牌的自回归视频生成**

*Hu Yu,Biao Gong,Hangjie Yuan,DanDan Zheng,Weilong Chai,Jingdong Chen,Kecheng Zheng,Feng Zhao*

主要分类: cs.CV

摘要简述: 本文提出VideoMAR，一种基于连续令牌的自回归视频生成模型，通过时空掩码生成和课程学习策略，显著提升了视频生成效率和质量，同时减少了资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于掩码的自回归模型在图像生成中表现优异，但在视频生成领域尚未充分探索。本文旨在填补这一空白，提出一种高效且资源节约的视频生成方法。

研究方法: VideoMAR结合了时间因果性和空间双向性，提出下一帧扩散损失以整合掩码与视频生成。通过时间短到长课程学习和空间渐进分辨率训练，解决了长序列建模的高成本问题。推理时采用渐进温度策略减少误差积累。

研究结果: 在VBench-I2V基准测试中，VideoMAR性能超越之前的最佳模型（Cosmos I2V），且参数、训练数据和GPU资源消耗分别减少至9.3%、0.5%和0.2%。

研究结论: VideoMAR不仅高效且资源节约，还通过3D旋转嵌入实现了时空外推能力，为视频生成领域提供了新的解决方案。

中文摘要: 基于掩码的自回归模型在连续空间中展示了出色的图像生成能力，但其在视频生成中的潜力尚未充分挖掘。本文提出VideoMAR，一种简洁高效的仅解码器自回归图像到视频模型，采用连续令牌并结合逐帧时间和空间掩码生成。我们首先将时间因果性和空间双向性确立为视频自回归模型的首要原则，并提出下一帧扩散损失以整合掩码与视频生成。此外，长序列自回归建模的高成本和难度是一个基础但关键的问题。为此，我们提出了时间短到长课程学习和空间渐进分辨率训练，并在推理时采用渐进温度策略以减少误差积累。此外，VideoMAR将语言模型的独特能力复制到视频生成中。由于同时支持时间维度的KV缓存和空间维度的并行生成，其效率极高，并通过3D旋转嵌入展示了时空外推能力。在VBench-I2V基准测试中，VideoMAR超越了之前的最佳模型（Cosmos I2V），同时所需参数（9.3%）、训练数据（0.5%）和GPU资源（0.2%）显著减少。

</details>


### [81] [A multi-stage augmented multimodal interaction network for fish feeding intensity quantification](https://arxiv.org/abs/2506.14170)
**中文标题：一种用于鱼类摄食强度量化的多阶段增强多模态交互网络**

*Shulong Zhang,Mingyuan Yao,Jiayin Zhao,Xiao Liu,Haihua Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种多阶段增强多模态交互网络（MAINet），用于量化鱼类摄食强度，通过多模态特征提取与融合显著提升了模型的准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 在循环水养殖系统中，准确评估鱼类摄食强度对降低饲料成本和优化投喂时间至关重要。然而，现有研究在多模态选择、特征提取与融合及协同推理方面存在局限性，限制了模型的准确性、适用性和可靠性。

研究方法: 研究提出MAINet框架，包括通用特征提取模块、辅助模态增强主模态机制（ARPM，含通道注意力融合网络CAFN和双模态注意力融合网络DAFN）以及证据推理（ER）规则，用于多模态特征融合与决策。

研究结果: 实验表明，MAINet在准确率、精确率、召回率和F1分数上均达到96.7%以上，显著优于单模态、双模态及其他融合方法模型。消融实验验证了改进策略对模型鲁棒性和特征利用效率的提升作用。

研究结论: MAINet通过多模态交互与增强机制，显著提高了鱼类摄食强度量化的准确性，为养殖系统提供了可靠的决策支持。

中文摘要: 在循环水养殖系统中，准确有效地评估鱼类摄食强度对降低饲料成本和计算最佳投喂时间至关重要。然而，当前研究在模态选择、特征提取与融合以及协同决策推理方面存在局限性，限制了多模态融合模型在准确性、适用性和可靠性上的进一步提升。为解决这一问题，本研究提出了一种多阶段增强多模态交互网络（MAINet）用于量化鱼类摄食强度。首先，提出了一种通用特征提取框架，高效地从输入图像、音频和水波数据中提取特征信息。其次，设计了辅助模态增强主模态机制（ARPM），用于模态间交互并生成增强特征，该机制包含通道注意力融合网络（CAFN）和双模态注意力融合网络（DAFN）。最后，引入证据推理（ER）规则，融合各模态输出结果并做出决策，从而完成鱼类摄食强度的量化。实验结果表明，所构建的MAINet在准确率、精确率、召回率和F1分数上分别达到96.76%、96.78%、96.79%和96.79%，其性能显著高于对比模型。与采用单模态、双模态融合及不同决策融合方法的模型相比，MAINet也具有明显优势。同时，消融实验进一步验证了所提改进策略在提升模型鲁棒性和特征利用效率方面的关键作用，能够有效提高鱼类摄食强度量化结果的准确性。

</details>


### [82] [One-Shot Neural Architecture Search with Network Similarity Directed Initialization for Pathological Image Classification](https://arxiv.org/abs/2506.14176)
**中文标题：基于网络相似性引导初始化的一键式神经架构搜索在病理图像分类中的应用**

*Renao Yan*

主要分类: cs.CV

摘要简述: 本文提出了一种基于网络相似性引导初始化（NSDI）的策略，结合领域自适应的一键式神经架构搜索（NAS），用于病理图像分类，显著提升了分类性能和特征定位能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常直接将计算机视觉模型应用于医学任务，忽略了病理图像的独特性，导致计算效率低下。本文旨在解决这一问题，特别是在边缘计算场景中。

研究方法: 提出网络相似性引导初始化（NSDI）策略，增强神经架构搜索的稳定性；引入领域自适应技术，处理病理数据集中染色和语义尺度的变化。

研究结果: 在BRACS数据集上的实验表明，该方法优于现有方法，分类性能和特征定位能力均有显著提升。

研究结论: 本文方法为病理图像分类提供了一种高效且稳定的解决方案，尤其适用于边缘计算场景。

中文摘要: 基于深度学习的病理图像分析由于网络设计的实际限制而面临独特挑战。现有方法通常直接将计算机视觉模型应用于医学任务，忽略了病理图像的独特性，导致计算效率低下，尤其在边缘计算场景中。为此，我们提出了一种新颖的网络相似性引导初始化（NSDI）策略，以提升神经架构搜索（NAS）的稳定性。此外，我们在一键式NAS中引入领域自适应技术，以更好地处理病理数据集中染色和语义尺度的变化。在BRACS数据集上的实验表明，我们的方法优于现有方法，不仅分类性能更优，还能实现临床相关的特征定位。

</details>


### [83] [Meta-SurDiff: Classification Diffusion Model Optimized by Meta Learning is Reliable for Online Surgical Phase Recognition](https://arxiv.org/abs/2506.14181)
**中文标题：Meta-SurDiff：通过元学习优化的分类扩散模型在在线手术阶段识别中的可靠性研究**

*Yufei Li,Jirui Wu,Long Tian,Liming Wang,Xiaonan Liu,Zijun Liu,Xiyang Liu*

主要分类: cs.CV

摘要简述: Meta-SurDiff是一种通过元学习优化的分类扩散模型，用于解决手术视频在线阶段识别中的不确定性问题，包括视频帧模糊和手术阶段分布不平衡，实验证明其在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 在线手术阶段识别因其与人类生命健康相关的潜在应用而备受关注。尽管深度模型在捕捉手术视频的长期依赖性方面取得了进展，但很少考虑视频中的不确定性，这对可靠的在线识别至关重要。

研究方法: 提出Meta-SurDiff模型，结合分类扩散模型和元学习，通过扩散模型评估模糊视频帧的识别置信度，并通过元学习优化模型以增强不同手术阶段的分类边界鲁棒性。

研究结果: 在五个广泛使用的数据集（Cholec80、AutoLaparo、M2Cai16、OphNet和NurViD）上进行了大量实验，使用四个以上实用指标验证了Meta-SurDiff的有效性。

研究结论: Meta-SurDiff通过建模手术视频中的不确定性，显著提升了在线手术阶段识别的可靠性，为实际应用提供了有力支持。

中文摘要: 在线手术阶段识别因其与人类生命健康相关的潜在应用而备受关注。尽管深度模型在捕捉手术视频的长期依赖性方面取得了显著进展，但很少探索和建模视频中的不确定性，而这对于可靠的在线识别至关重要。我们将不确定性来源分为两类：视频帧模糊和手术阶段分布不平衡，这些问题在手术视频中不可避免。为解决这一关键问题，我们提出了一种元学习优化的分类扩散模型（Meta-SurDiff），充分利用深度生成模型和元学习的优势，实现精确的帧级分布估计，从而提升在线手术阶段识别的可靠性。针对模糊视频帧导致的识别粗糙问题，我们采用分类扩散模型在更细粒度的帧级实例上评估识别结果的置信度；针对手术阶段分布不平衡导致的识别粗糙问题，我们使用基于元学习的目标训练扩散模型，从而增强不同手术阶段分类边界的鲁棒性。通过在五个广泛使用的数据集（Cholec80、AutoLaparo、M2Cai16、OphNet和NurViD）上进行大量实验，并使用四个以上实用指标，我们验证了Meta-SurDiff在在线手术阶段识别中的有效性。其中，OphNet来自眼科手术，NurViD是日常护理数据集，其余数据集来自腹腔镜手术。代码将在论文接受后公开。

</details>


### [84] [Egocentric Human-Object Interaction Detection: A New Benchmark and Method](https://arxiv.org/abs/2506.14189)
**中文标题：自我中心视角下的人-物交互检测：新基准与方法**

*Kunyuan Deng,Yi Wang,Lap-Pui Chau*

主要分类: cs.CV

摘要简述: 本文提出了一种新的自我中心视角下的人-物交互检测基准（Ego-HOIBench）及方法（HGIR），通过引入手部几何和交互性优化方案，显著提升了交互检测能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人-物交互（HOI）检测方法主要关注第三人称视角，忽视了更直观的自我中心视角（Ego-HOI）。本文旨在填补这一空白，推动Ego-HOI检测的发展。

研究方法: 提出了一种轻量级且高效的Hand Geometry and Interactivity Refinement（HGIR）方案，利用手部姿态和几何信息优化交互特征，通过姿态-交互注意力机制提升检测能力。

研究结果: HGIR方案在Ego-HOIBench上实现了最先进的检测效果，显著提升了交互表示的鲁棒性和准确性。

研究结论: 本文提出的Ego-HOIBench和HGIR方案为自我中心视角下的人-物交互检测提供了新的基准和方法，具有轻量级和高效的特点，可广泛应用于HOI检测任务。

中文摘要: 近年来，理解人与物体之间的交互引起了广泛关注。现有的人-物交互（HOI）检测方法主要关注第三人称视角，忽视了更直观的自我中心视角（Ego-HOI）。本文提出了Ego-HOIBench，这是一个新的数据集，旨在推动Ego-HOI检测的基准测试和发展。我们的Ego-HOIBench包含超过27K张自我中心视角图像，带有高质量的手-动词-物体三元组标注，涵盖123个细粒度交互类别和位置，覆盖了日常活动中丰富的场景、物体类型和手部配置。此外，我们探索并调整了第三人称HOI检测方法以适应Ego-HOIBench，并展示了手部遮挡物体以及单双手交互复杂性的挑战。为了建立新的基准，我们提出了一种手部几何与交互性优化（HGIR）方案，该方案利用手部姿态和几何信息作为解释交互的有价值线索。具体而言，HGIR方案从估计的手部姿态提案中显式提取全局手部几何特征，并通过姿态-交互注意力机制优化交互特定特征。这一方案使模型能够获得鲁棒且强大的交互表示，显著提升了Ego-HOI检测能力。我们的方法轻量且高效，可以即插即用地应用于HOI基准，在Ego-HOIBench上实现了最先进的结果。项目地址：https://dengkunyuan.github.io/EgoHOIBench/

</details>


### [85] [HRGS: Hierarchical Gaussian Splatting for Memory-Efficient High-Resolution 3D Reconstruction](https://arxiv.org/abs/2506.14229)
**中文标题：HRGS：基于分层高斯泼溅的内存高效高分辨率3D重建**

*Changbai Li,Haodong Zhu,Hanlin Chen,Juan Zhang,Tongfei Chen,Shuo Yang,Shuwei Shao,Wenhao Dong,Baochang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为HRGS的分层高斯泼溅方法，通过分块优化和重要性驱动的高斯修剪，解决了高分辨率3D重建中的内存问题，实现了高质量的场景重建。


<details>
  <summary>详细信息</summary>
研究动机: 3D高斯泼溅（3DGS）在实时3D场景重建中取得了显著进展，但在高分辨率场景下面临内存扩展问题。为了解决这一问题，本文提出了HRGS框架，旨在实现内存高效的高分辨率3D重建。

研究方法: HRGS首先从低分辨率数据生成全局粗糙高斯表示，然后将场景划分为多个块，并用高分辨率数据细化每个块。通过高斯分区和数据分区，确保相邻块的高斯无缝融合。此外，引入重要性驱动的高斯修剪（IDGP）以减少计算需求，并利用预训练模型的法线先验提升表面重建质量。

研究结果: 在三个基准测试上的广泛实验表明，HRGS在高分辨率新视角合成（NVS）和表面重建任务中达到了最先进的性能。

研究结论: HRGS通过分层块级优化和内存高效设计，成功实现了高质量的高分辨率3D场景重建，即使在内存受限的情况下也能表现出色。

中文摘要: 3D高斯泼溅（3DGS）在实时3D场景重建中取得了显著进展，但在高分辨率场景下面临内存扩展问题。为此，我们提出了分层高斯泼溅（HRGS），这是一种具有分层块级优化的内存高效框架。首先，我们从低分辨率数据生成全局粗糙高斯表示；然后，将场景划分为多个块，并用高分辨率数据细化每个块。分区包括两个步骤：高斯分区（将不规则场景归一化为有界立方空间，并使用均匀网格进行任务分配）和训练数据分区（仅保留每个块的相关观测数据）。通过粗糙高斯先验指导块细化，我们确保了相邻块的高斯无缝融合。为了减少计算需求，我们引入了重要性驱动的高斯修剪（IDGP），计算每个高斯的贡献分数并移除贡献最小的部分，从而加速收敛并降低内存使用。此外，我们还利用预训练模型的法线先验来提升表面重建质量。我们的方法即使在内存受限的情况下也能实现高质量的高分辨率3D场景重建。在三个基准测试上的广泛实验表明，HRGS在高分辨率新视角合成（NVS）和表面重建任务中达到了最先进的性能。

</details>


### [86] [Unified Representation Space for 3D Visual Grounding](https://arxiv.org/abs/2506.14238)
**中文标题：3D视觉定位的统一表示空间**

*Yinuo Zheng,Lipeng Gu,Honghua Chen,Liangliang Nan,Mingqiang Wei*

主要分类: cs.CV

摘要简述: 本文提出UniSpace-3D，通过统一表示空间解决3D视觉定位中视觉与文本模态的差异，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D视觉定位方法依赖分别预训练的视觉和文本编码器，导致模态间在空间几何和语义类别上存在显著差异，影响定位和分类准确性。

研究方法: UniSpace-3D包含三个创新设计：1) 统一表示编码器利用CLIP模型将视觉和文本特征映射到统一空间；2) 多模态对比学习模块进一步缩小模态差异；3) 语言引导的查询选择模块利用位置和语义信息筛选与文本描述匹配的候选点。

研究结果: 在ScanRefer和Nr3D/Sr3D数据集上，UniSpace-3D比基线模型性能提升至少2.24%。

研究结论: UniSpace-3D通过统一表示空间有效解决了3D视觉定位中的模态差异问题，显著提升了性能。

中文摘要: 3D视觉定位（3DVG）是场景理解中的关键任务，旨在根据文本描述识别3D场景中的物体。然而，现有方法依赖分别预训练的视觉和文本编码器，导致两种模态在空间几何和语义类别上存在显著差异，常引发定位和分类错误。本文提出UniSpace-3D，创新性地引入统一表示空间，有效弥合视觉与文本特征间的差异。具体而言，UniSpace-3D包含三项创新设计：i) 统一表示编码器利用预训练的CLIP模型将视觉和文本特征映射到统一表示空间；ii) 多模态对比学习模块进一步缩小模态差异；iii) 语言引导的查询选择模块利用位置和语义信息筛选与文本描述匹配的候选点。大量实验表明，UniSpace-3D在ScanRefer和Nr3D/Sr3D数据集上比基线模型性能提升至少2.24%。代码将在论文录用后公开。

</details>


### [87] [Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition](https://arxiv.org/abs/2506.14243)
**中文标题：跨模态几何层次融合：一种隐式子地图驱动的鲁棒3D地点识别框架**

*Xiaohui Jiang,Haijiang Zhu,Chadei Li,Fulin Tang,Ning An*

主要分类: cs.CV

摘要简述: 本文提出了一种基于隐式子地图的跨模态几何层次融合框架，通过密度无关的几何推理解决了LiDAR点云密度不一致和单层几何抽象表征脆弱的问题，实现了高精度的3D地点识别。


<details>
  <summary>详细信息</summary>
研究动机: 现有的LiDAR地点识别方法依赖手工特征提取，面临点云密度不一致和单层几何抽象表征脆弱的问题，导致描述符不稳定且缺乏区分力。本文旨在解决这些问题，提升识别性能。

研究方法: 提出了一种基于弹性点的隐式3D表征，生成均匀分布的点云；从中提取场景的占据网格和法向量信息；融合鸟瞰图和3D片段的几何信息，生成高区分力的描述符。

研究结果: 在多个数据集（KITTI、KITTI-360、MulRan、NCLT）上的实验表明，该方法达到了最先进的性能，并在准确性、运行时间和内存优化之间取得了最佳平衡。

研究结论: 本文提出的框架通过密度无关的几何推理和跨模态信息融合，显著提升了3D地点识别的鲁棒性和可扩展性，具有广泛的应用潜力。

中文摘要: 基于LiDAR的地点识别是机器人和自动驾驶系统实现长期自主性的关键技术。然而，现有方法依赖手工特征提取，面临两大挑战：(1) 由于重复遍历时的动态运动和环境干扰，点云密度不一致导致描述符不稳定；(2) 单层几何抽象表征在结构复杂场景中缺乏区分力。为解决这些问题，我们提出了一种基于密度无关几何推理的新框架。具体而言，我们引入了一种基于弹性点的隐式3D表征，不受原始点云密度干扰并实现均匀分布；随后从中提取场景的占据网格和法向量信息；最后，结合鸟瞰图（捕捉宏观空间布局）和3D片段（编码微观表面几何）的几何信息生成描述符。我们在多个数据集（KITTI、KITTI-360、MulRan、NCLT）上进行了广泛实验，结果表明该方法达到了最先进的性能，并在准确性、运行时间和历史地图内存优化之间取得了最佳平衡，展示了卓越的鲁棒性和可扩展性。未来我们将开源代码。

</details>


### [88] [synth-dacl: Does Synthetic Defect Data Enhance Segmentation Accuracy and Robustness for Real-World Bridge Inspections?](https://arxiv.org/abs/2506.14255)
**中文标题：synth-dacl：合成缺陷数据能否提升真实桥梁检测中的分割准确性和鲁棒性？**

*Johannes Flotzinger,Fabian Deuser,Achref Jaziri,Heiko Neumann,Norbert Oswald,Visvanathan Ramesh,Thomas Braml*

主要分类: cs.CV

摘要简述: 本文提出了一种名为synth-dacl的合成缺陷数据集扩展方法，旨在解决桥梁检测数据集dacl10k中的类别不平衡问题，尤其是提升裂缝和孔洞分割的模型性能。实验表明，结合合成数据后，模型在扰动测试集上的性能显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 由于桥梁老化、检测资源不足，自动化视觉桥梁检测的需求日益增长。然而，现有数据集dacl10k存在类别不平衡问题，导致模型在细粒度缺陷（如裂缝和孔洞）分割上表现不佳。本文旨在通过合成数据扩展提升模型性能。

研究方法: 本文提出了synth-dacl，基于合成混凝土纹理的三种数据集扩展方法，用于平衡dacl10k中的类别分布。通过将合成数据与真实数据结合训练模型，评估其在15种扰动测试集上的性能。

研究结果: 实验结果显示，结合所有合成扩展数据的模型在扰动测试集上的平均IoU、F1分数、召回率和精确度均提升了2%，显著优于仅使用dacl10k训练的模型。

研究结论: synth-dacl通过合成数据扩展有效解决了类别不平衡问题，显著提升了桥梁缺陷分割模型的鲁棒性和准确性。

中文摘要: 由于桥梁老化问题日益严重，加之检测人员和资金资源不足，许多国家的桥梁检测面临巨大挑战。自动化视觉桥梁检测的关键任务——像素级缺陷和建筑部件分类——能够提高检测效率和准确性，并增强检测过程的安全性。承担此任务的模型必须适应各种现实条件，包括图像质量变化和背景纹理多样性。dacl10k是目前最大且最多样化的真实桥梁检测数据集，但其类别不平衡问题导致模型在细粒度缺陷（如裂缝和孔洞）分割上表现不佳。本文提出了“synth-dacl”，基于合成混凝土纹理的三种数据集扩展方法，旨在平衡dacl10k的类别分布并提升模型性能。实验表明，结合合成扩展数据后，模型在15种扰动测试集上的鲁棒性显著提升。具体而言，在扰动测试集上，使用dacl10k和所有合成扩展数据训练的模型在平均IoU、F1分数、召回率和精确度上均比仅使用dacl10k训练的模型提高了2%。

</details>


### [89] [Comparison of Two Methods for Stationary Incident Detection Based on Background Image](https://arxiv.org/abs/2506.14256)
**中文标题：基于背景图像的静态事件检测两种方法比较**

*Deepak Ghimire,Joonwhoan Lee*

主要分类: cs.CV

摘要简述: 本文提出并比较了两种基于背景减除的静态物体检测方法，分别采用单背景和双背景策略，并通过归一化互相关图像对比实现实时跟踪。


<details>
  <summary>详细信息</summary>
研究动机: 传统背景减除方法主要用于动态物体检测，而本文旨在解决静态物体的检测问题，尤其是在部分遮挡、短时完全遮挡和光照变化等复杂场景下的鲁棒性需求。

研究方法: 提出两种方案：一是基于单背景的静态物体检测，二是基于双背景（不同学习率生成）的检测方法，并结合归一化互相关（NCC）进行图像对比以实现跟踪。

研究结果: 所提方法在部分遮挡、短时完全遮挡和光照变化下表现鲁棒，且能实时运行。双背景方法在检测性能上优于单背景方法，但计算复杂度略高。

研究结论: 双背景方法在静态物体检测中更具优势，尽管计算复杂度较高，但其鲁棒性和实时性使其适用于实际应用场景。

中文摘要: 通常，基于背景减除的方法用于视觉跟踪应用中的动态物体检测。本文采用基于背景减除的方案检测暂时静态的物体。我们提出了两种静态物体检测方案，并从检测性能和计算复杂度两方面进行比较。第一种方法使用单一背景，第二种方法使用双背景（通过不同学习率生成）以检测暂时停止的物体。最后，采用基于归一化互相关（NCC）的图像对比来监控和跟踪视频场景中检测到的静态物体。所提方法对部分遮挡、短时完全遮挡和光照变化具有鲁棒性，并能实时运行。

</details>


### [90] [Exploring Non-contrastive Self-supervised Representation Learning for Image-based Profiling](https://arxiv.org/abs/2506.14265)
**中文标题：探索基于图像的非对比自监督表征学习在细胞图像分析中的应用**

*Siran Dai,Qianqian Xu,Peisong Wen,Yang Liu,Qingming Huang*

主要分类: cs.CV

摘要简述: 本文探索了非对比自监督学习方法在细胞图像特征提取中的应用，提出了专门针对细胞图像的SSLProfiler框架，解决了数据分布差异和多图像输入问题，并在CVPR 2025挑战赛中获胜。


<details>
  <summary>详细信息</summary>
研究动机: 细胞图像分析在药物发现中至关重要，但现有自监督学习方法因细胞图像与自然图像分布差异大且需处理多图像输入而效果不佳。本文旨在开发一种适用于细胞图像的非对比自监督学习框架。

研究方法: 提出SSLProfiler框架，包含针对细胞图像的专用数据增强和表征后处理方法，解决了现有方法在视图生成和信息整合上的不足。

研究结果: SSLProfiler在CVPR 2025的Cell Line Transferability挑战赛中获胜，证明了其在细胞图像特征提取中的优越性。

研究结论: SSLProfiler为非对比自监督学习在细胞图像分析中的应用提供了有效解决方案，显著提升了特征提取的鲁棒性和泛化能力。

中文摘要: 基于图像的细胞分析旨在为细胞图像创建信息丰富的表征。这一技术在药物发现中至关重要，并随着计算机视觉的进步取得了显著发展。受非对比自监督学习（SSL）最新进展的启发，本文初步探索了使用此类方法训练细胞图像通用特征提取器的可能性。然而，存在两大挑战：1）细胞图像与自然图像的分布差异较大，导致现有SSL方法中的视图生成过程失效；2）与典型场景中每个表征基于单张图像不同，细胞分析通常涉及多张输入图像，难以有效整合所有可用信息。为解决这些问题，我们提出了SSLProfiler，一个专为细胞分析设计的非对比SSL框架。我们引入了针对细胞图像的专用数据增强和表征后处理方法，有效解决了上述问题，并构建了一个鲁棒的特征提取器。通过这些改进，SSLProfiler在CVPR 2025的Cell Line Transferability挑战赛中获胜。

</details>


### [91] [Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment](https://arxiv.org/abs/2506.14271)
**中文标题：Leader360V：面向多样化环境中多任务学习的大规模真实世界360视频数据集**

*Weiming Zhang,Dingwen Xiao,Aobotao Dai,Yexin Liu,Tianbo Pan,Shiqi Wen,Lei Chen,Lin Wang*

主要分类: cs.CV

摘要简述: 本文介绍了Leader360V，首个大规模、标注真实世界360视频数据集，用于实例分割和跟踪。通过自动化标注流程结合2D分割器和大型语言模型，解决了360视频标注的复杂性和高成本问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 360视频因其超广视角在自动驾驶、机器人等领域有重要应用，但缺乏大规模标注数据集。球形特性（如极区严重失真和内容不连续）使得标注成本高且复杂。本文旨在填补这一空白。

研究方法: 设计了自动化标注流程，分三阶段：初始标注阶段结合2D分割器和LLM生成语义标签；自动优化阶段修正缺失或不完整区域；人工修订阶段进一步验证标注。

研究结果: 用户研究和实验表明，标注流程高效且Leader360V显著提升了360视频分割和跟踪的模型性能。

研究结论: Leader360V为360场景理解提供了首个大规模数据集，自动化标注流程解决了标注难题，推动了该领域的可扩展发展。

中文摘要: 360视频以360X180的超广视角捕捉完整场景，使得分割和跟踪等任务在自动驾驶、机器人等领域至关重要。然而，由于球形特性（如极区严重失真和内容不连续），标注大规模真实世界数据集成本高且复杂。本文提出Leader360V，首个用于实例分割和跟踪的大规模标注真实世界360视频数据集。数据集涵盖室内、城市、自然和动态户外场景，多样性高。为自动化标注，设计了结合预训练2D分割器和大型语言模型的流程，分三阶段：初始标注阶段通过语义和失真感知优化模块生成标签；自动优化阶段修正缺失区域；人工修订阶段进一步验证。实验证明标注流程高效，且Leader360V显著提升了模型性能，为360场景理解的可扩展发展铺平了道路。

</details>


### [92] [FRIDU: Functional Map Refinement with Guided Image Diffusion](https://arxiv.org/abs/2506.14322)
**中文标题：FRIDU：基于引导图像扩散的功能映射优化**

*Avigail Cohen Rimon,Mirela Ben-Chen,Or Litany*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图像扩散模型的功能映射（functional map）优化方法，通过训练扩散模型直接处理功能映射空间，结合点对点映射作为引导，显著提升了映射精度和效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的形状对应映射方法在处理功能映射时存在精度不足或效率低下的问题。本文旨在通过图像扩散模型直接优化功能映射，提升映射的准确性和计算效率。

研究方法: 将功能映射视为2D图像，训练一个图像扩散模型直接在功能映射空间中进行优化。在推理阶段，利用当前功能映射对应的点对点映射作为引导，同时支持功能映射的其他目标（如正交性和与拉普拉斯-贝尔特拉米算子的交换性）。

研究结果: 实验表明，该方法在功能映射优化任务中与现有最优方法竞争，且引导扩散模型为功能映射处理提供了新的有效途径。

研究结论: 通过图像扩散模型优化功能映射是一种高效且准确的方法，引导扩散模型为功能映射处理开辟了新的研究方向。

中文摘要: 我们提出了一种新颖的方法，用于优化两个形状之间的对应映射。功能映射（即基变换矩阵）可以视为2D图像。基于这一视角，我们直接在功能映射空间中训练图像扩散模型，使其能够基于不准确的初始映射生成精确的映射。训练过程完全在功能空间中进行，因此效率极高。在推理阶段，我们使用当前功能映射对应的点对点映射作为扩散过程的引导。这种引导还可以促进功能映射的其他目标，如正交性和与拉普拉斯-贝尔特拉米算子的交换性。实验表明，我们的方法与现有最优的映射优化方法竞争，且引导扩散模型为功能映射处理提供了有前景的新途径。

</details>


### [93] [FGA-NN: Film Grain Analysis Neural Network](https://arxiv.org/abs/2506.14350)
**中文标题：FGA-NN：电影颗粒分析神经网络**

*Zoubida Ameur,Frédéric Lefebvre,Philippe De Lagrange,Miloš Radosavljević*

主要分类: cs.CV

摘要简述: 本文提出FGA-NN，首个基于学习的电影颗粒分析方法，用于估计与传统合成兼容的颗粒参数，在分析精度与合成复杂度间取得优越平衡。


<details>
  <summary>详细信息</summary>
研究动机: 电影颗粒是模拟胶片的副产品，现常用于影视内容以增强美学效果。但在中低比特率压缩时，颗粒因其随机性易丢失。为在高效压缩的同时保留艺术意图，需在编码前分析并建模颗粒，解码后重新合成。

研究方法: FGA-NN是一种基于学习的电影颗粒分析方法，通过神经网络估计与传统合成兼容的颗粒参数。

研究结果: 定量与定性结果表明，FGA-NN在分析精度与合成复杂度间表现出优越平衡，同时具备鲁棒性和适用性。

研究结论: FGA-NN是首个基于学习的电影颗粒分析方法，成功解决了传统压缩中颗粒丢失的问题，为影视内容的高效压缩与艺术保留提供了新方案。

中文摘要: 电影颗粒曾是模拟胶片的副产品，如今因美学原因广泛存在于影视内容中。然而，在中低比特率压缩时，颗粒因其随机性易丢失。为在高效压缩的同时保留艺术意图，需在编码前分析并建模颗粒，解码后重新合成。本文提出FGA-NN，首个基于学习的电影颗粒分析方法，用于估计与传统合成兼容的颗粒参数。定量与定性结果表明，FGA-NN在分析精度与合成复杂度间表现出优越平衡，同时具备鲁棒性和适用性。

</details>


### [94] [EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization](https://arxiv.org/abs/2506.14356)
**中文标题：EVA02-AT：基于空间-时间旋转位置嵌入和对称优化的自我中心视频语言理解**

*Xiaoqi Wang,Yi Wang,Lap-Pui Chau*

主要分类: cs.CV

摘要简述: EVA02-AT是一种针对自我中心视频语言理解任务的高效模型，通过单阶段预训练、空间-时间旋转位置嵌入和对称优化方法，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在自我中心视频语言理解中存在三个主要问题：多阶段预训练成本高、空间-时间编码效率低以及多实例检索目标不精确。EVA02-AT旨在解决这些问题。

研究方法: 1. 通过单阶段预训练将基于图像的CLIP模型转化为视频编码器；2. 引入空间-时间旋转位置嵌入和联合注意力机制，实现高效的空间-时间特征编码；3. 提出对称多相似性（SMS）损失和训练框架，优化多实例检索任务。

研究结果: 在Ego4D、EPIC-Kitchens-100和Charades-Ego等数据集上，EVA02-AT在零样本和微调设置下均达到最先进性能，且参数量更少。SMS损失在多实例检索任务中表现显著提升。

研究结论: EVA02-AT通过高效的空间-时间建模和对称优化方法，显著提升了自我中心视频语言理解的性能，为相关任务提供了新的解决方案。

中文摘要: 自我中心视频语言理解需要高效且准确的空间-时间建模。现有方法面临三个关键挑战：1）多阶段预训练流程导致成本过高；2）手动分割的3D旋转位置嵌入阻碍特征交互，导致空间-时间编码效率低下；3）软标签多实例检索中的学习目标不精确，忽略了负样本对的关联性。本文提出EVA02-AT，一套基于EVA02的视频语言基础模型，专为自我中心视频理解任务设计。EVA02-AT首先通过单阶段预训练将基于图像的CLIP模型高效转化为统一的视频编码器。其次，我们引入空间-时间旋转位置嵌入和联合注意力机制，能够在整个隐藏维度上有效编码空间和时间信息。这种联合编码使模型能够学习跨轴关系，这对准确建模视频中的运动和交互至关重要。第三，针对多实例视频语言检索任务，我们提出对称多相似性（SMS）损失和一种新颖的训练框架，优化所有正负样本对的软标签，提供更精确的学习目标。在Ego4D、EPIC-Kitchens-100和Charades-Ego数据集上的大量实验表明，EVA02-AT在零样本和微调设置下均实现了最先进的性能，且参数量更少。采用SMS损失的模型在多实例检索基准测试中也表现出显著性能提升。代码和模型已公开在https://github.com/xqwang14/EVA02-AT。

</details>


### [95] [HydroChronos: Forecasting Decades of Surface Water Change](https://arxiv.org/abs/2506.14362)
**中文标题：HydroChronos：预测数十年的地表水变化**

*Daniele Rege Cambrin,Eleonora Poeta,Eliana Pastor,Isaac Corley,Tania Cerquitelli,Elena Baralis,Paolo Garza*

主要分类: cs.CV

摘要简述: 本文提出HydroChronos数据集和AquaClimaTempo UNet模型，用于预测地表水动态变化，显著优于基线模型，并通过可解释AI分析揭示了关键气候变量。


<details>
  <summary>详细信息</summary>
研究动机: 地表水动态预测对水资源管理和气候变化适应至关重要，但缺乏综合数据集和标准化基准。本文旨在填补这一空白。

研究方法: 提出HydroChronos数据集，包含30多年的Landsat 5和Sentinel-2影像、气候数据及数字高程模型；设计AquaClimaTempo UNet模型，结合气候数据分支进行预测。

研究结果: 模型在变化检测、变化方向分类和变化幅度回归任务中分别比基线模型提升14%、11%和0.1 MAE；通过可解释AI分析识别了关键气候变量。

研究结论: HydroChronos数据集和AquaClimaTempo UNet模型为地表水动态预测提供了有效工具，未来建模可参考其分析结果。

中文摘要: 地表水动态预测对水资源管理和气候变化适应至关重要，但该领域缺乏综合数据集和标准化基准。本文提出HydroChronos，一个大规模、多模态的时空数据集，用于地表水动态预测。该数据集包含欧洲、北美和南美多样湖泊与河流30多年的Landsat 5和Sentinel-2影像、气候数据及数字高程模型，并配套三项预测任务。我们还提出AquaClimaTempo UNet，一种结合气候数据分支的新型时空架构，作为强基准基线。该模型在变化检测和变化方向分类任务中的F1分数分别比基线模型提升14%和11%，在变化幅度回归任务中的MAE提升0.1。最后，通过可解释AI分析，识别了影响地表水变化的关键气候变量和输入通道，为未来建模提供了指导。

</details>


### [96] [DGG-XNet: A Hybrid Deep Learning Framework for Multi-Class Brain Disease Classification with Explainable AI](https://arxiv.org/abs/2506.14367)
**中文标题：DGG-XNet：一种基于可解释AI的多类脑疾病分类混合深度学习框架**

*Sumshun Nahar Eity,Mahin Montasir Afif,Tanisha Fairooz,Md. Mortuza Ahmmed,Md Saef Ullah Miah*

主要分类: cs.CV

摘要简述: DGG-XNet是一种混合深度学习模型，结合VGG16和DenseNet121，用于多类脑疾病分类，并通过Grad-CAM增强可解释性，测试准确率达91.33%。


<details>
  <summary>详细信息</summary>
研究动机: 传统MRI分析方法效率低且易出错，亟需一种高效且准确的脑疾病诊断工具。

研究方法: 提出DGG-XNet，融合VGG16的层次空间表示和DenseNet121的特征重用能力，结合Grad-CAM实现可视化解释。

研究结果: 在BraTS 2021和Kaggle数据集上测试，准确率为91.33%，精确率、召回率和F1分数均超过91%。

研究结论: DGG-XNet是一种高效、可解释的计算机辅助诊断工具，适用于神经退行性和肿瘤性脑疾病。

中文摘要: 阿尔茨海默病和脑肿瘤等脑部疾病的准确诊断在医学影像中仍是一个关键挑战。传统基于手动MRI分析的方法通常效率低下且易出错。为此，我们提出DGG-XNet，一种融合VGG16和DenseNet121的混合深度学习模型，以增强特征提取和分类能力。DenseNet121通过密集连接促进特征重用和高效梯度流动，而VGG16提供强大的层次空间表示。两者的融合实现了神经系统疾病的多类稳健分类。应用Grad-CAM可视化关键区域，增强模型透明度。在BraTS 2021和Kaggle的联合数据集上训练后，DGG-XNet的测试准确率达到91.33%，精确率、召回率和F1分数均超过91%。这些结果表明，DGG-XNet是一种高效且可解释的计算机辅助诊断工具，适用于神经退行性和肿瘤性脑疾病。

</details>


### [97] [Discrete JEPA: Learning Discrete Token Representations without Reconstruction](https://arxiv.org/abs/2506.14373)
**中文标题：离散JEPA：无需重构学习离散标记表示**

*Junyeob Baek,Hosung Lee,Christopher Hoang,Mengye Ren,Sungjin Ahn*

主要分类: cs.CV

摘要简述: 本文提出Discrete-JEPA模型，通过语义标记化和新颖的互补目标扩展潜在预测编码框架，显著提升了视觉符号推理任务的性能，并展示了学习到的语义标记空间中自发涌现的系统性模式。


<details>
  <summary>详细信息</summary>
研究动机: 当前图像标记化方法在需要符号抽象和逻辑推理的系统推断任务中存在显著局限，阻碍了认知智能的发展。本文旨在解决这一问题，提出一种能够支持符号推理的鲁棒标记化方法。

研究方法: 扩展潜在预测编码框架，引入语义标记化和新颖的互补目标，以生成适用于符号推理任务的鲁棒标记化表示。

研究结果: Discrete-JEPA在视觉符号预测任务中显著优于基线模型，且学习到的语义标记空间自发涌现出系统性模式。

研究结论: 尽管是初步模型，Discrete-JEPA为人工智能系统中的符号世界建模和规划能力提供了重要推动力。

中文摘要: 认知智能的核心在于从观察中提取隐藏模式，并利用这些原则系统预测未来结果。然而，当前图像标记化方法在需要符号抽象和逻辑推理能力的系统推断任务中表现出显著局限性。为解决这一问题，我们提出Discrete-JEPA，通过语义标记化和新颖互补目标扩展潜在预测编码框架，为符号推理任务创建鲁棒标记化。Discrete-JEPA在视觉符号预测任务中显著优于基线模型，同时视觉证据显示学习到的语义标记空间中自发涌现出系统性模式。尽管是初步模型，我们的方法有望为人工智能系统的符号世界建模和规划能力带来重要进展。

</details>


### [98] [DepthSeg: Depth prompting in remote sensing semantic segmentation](https://arxiv.org/abs/2506.14382)
**中文标题：DepthSeg：遥感语义分割中的深度提示技术**

*Ning Zhou,Shanxiong Chen,Mingting Zhou,Haigang Sui,Lieyun Hu,Han Li,Li Hua,Qiming Zhou*

主要分类: cs.CV

摘要简述: 本文提出DepthSeg框架，通过深度提示技术改进遥感语义分割，解决光谱混淆和阴影遮挡问题，提升地物分类精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有遥感语义分割方法主要依赖光谱特征，忽略了目标高程差异，导致复杂场景下的地物分类错误。DepthSeg旨在通过深度信息弥补这一不足。

研究方法: DepthSeg框架包含三部分：1) 轻量适配器微调预训练视觉Transformer编码器；2) 深度提示器显式建模深度/高度特征；3) 语义分类解码器结合深度提示与高维地物特征。

研究结果: 在LiuZhou数据集上的实验验证了DepthSeg在地物分类任务中的优势，消融实验进一步证明了深度提示的重要性。

研究结论: DepthSeg通过整合深度信息显著提升了遥感语义分割的准确性，为复杂场景下的地物分类提供了有效解决方案。

中文摘要: 遥感语义分割对于提取地表详细信息至关重要，支持环境监测、土地利用规划和资源评估等应用。近年来，人工智能的进步推动了自动遥感语义分割方法的发展。然而，现有方法主要关注不同目标的光谱特征区分，而忽略了目标高程差异，导致在阴影遮挡和光谱混淆的复杂场景中出现地物分类错误。本文提出了一种深度提示二维遥感语义分割框架（DepthSeg），能够从二维遥感图像中自动建模深度/高度信息，并将其整合到语义分割框架中，以减轻光谱混淆和阴影遮挡的影响。在DepthSeg的特征提取阶段，我们引入轻量适配器，实现对预训练的大参数视觉Transformer编码器的低成本微调。在深度提示阶段，提出深度提示器显式建模深度/高度特征。在语义预测阶段，引入语义分类解码器，将深度提示与高维地物特征结合，实现地物类型的精确提取。在LiuZhou数据集上的实验验证了DepthSeg框架在地物分类任务中的优势。详细的消融实验进一步凸显了深度提示在遥感语义分割中的重要性。

</details>


### [99] [GrFormer: A Novel Transformer on Grassmann Manifold for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.14384)
**中文标题：GrFormer：一种基于Grassmann流形的新型Transformer用于红外与可见光图像融合**

*Huan Kang,Hui Li,Xiao-Jun Wu,Tianyang Xu,Rui Wang,Chunyang Cheng,Josef Kittler*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Grassmann流形的新型注意力机制GrFormer，用于红外与可见光图像融合，通过低秩子空间映射和多尺度语义融合，显著提升了融合性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像融合方法通常基于欧几里得空间建模，无法捕捉非欧几里得空间中的内在拓扑结构，导致语义相似性不足和融合性能下降。本文旨在解决这一问题，平衡低频语义与高频细节。

研究方法: 提出GrFormer，通过Grassmann流形上的投影约束构建低秩子空间映射，将注意力特征压缩到不同秩级别的子空间中，实现多尺度语义融合，并开发基于协方差掩码的跨模态融合策略（CMS）以最大化互补性。

研究结果: 实验表明，GrFormer在多个图像融合基准上定性和定量均优于现有方法。

研究结论: GrFormer通过Grassmann流形和多尺度语义融合，有效提升了红外与可见光图像融合的性能，为相关任务提供了新思路。

中文摘要: 在图像融合领域，通过将不同模态数据建模为线性子空间已取得显著进展。然而，实际中源图像常位于非欧几里得空间，欧几里得方法难以捕捉其内在拓扑结构。欧几里得空间中的内积计算的是代数相似性而非语义相似性，导致注意力输出不理想和融合性能下降。而红外与可见光图像融合任务需平衡低频细节与高频语义。为此，本文提出基于Grassmann流形的新型注意力机制GrFormer。具体而言，该方法通过在Grassmann流形上的投影约束构建低秩子空间映射，将注意力特征压缩到不同秩级别的子空间中，迫使特征解耦为高频细节（局部低秩）和低频语义（全局低秩），从而实现多尺度语义融合。此外，为有效整合重要信息，开发了基于协方差掩码的跨模态融合策略（CMS），以最大化不同模态间的互补性并抑制高相关性特征（视为冗余）。实验结果表明，本网络在多个图像融合基准上定性和定量均优于现有方法。代码见https://github.com/Shaoyun2023。

</details>


### [100] [Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models](https://arxiv.org/abs/2506.14399)
**中文标题：反事实扩散模型的解耦无分类器引导方法**

*Tian Xia,Fabio De Sousa Ribeiro,Rajat R Rasal,Avinash Kori,Raghav Mehta,Ben Glocker*

主要分类: cs.CV

摘要简述: 本文提出了一种解耦的无分类器引导（DCFG）方法，用于改进反事实扩散模型，通过分组条件控制解决传统方法中属性放大的问题，提升干预保真度和图像生成的可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 反事实图像生成旨在模拟特定因果干预下的真实视觉结果。传统方法使用单一全局权重的无分类器引导（CFG），可能导致身份保持不佳和虚假属性变化（属性放大现象）。本文旨在解决这一问题。

研究方法: 提出解耦的无分类器引导（DCFG）框架，采用属性分割嵌入策略，将语义输入解耦，实现对用户定义属性组的选择性引导。在反事实生成中，基于因果图将属性分为干预组和不变组，并分别应用不同的引导。

研究结果: 在CelebA-HQ、MIMIC-CXR和EMBED数据集上的实验表明，DCFG提高了干预保真度，减少了意外变化，并增强了可逆性，实现了更忠实和可解释的反事实图像生成。

研究结论: DCFG是一种灵活且模型无关的框架，通过分组条件控制有效解决了属性放大问题，为反事实图像生成提供了更优的解决方案。

中文摘要: 反事实图像生成旨在模拟特定因果干预下的真实视觉结果。扩散模型最近成为这一任务的有力工具，结合了DDIM反演和无分类器引导（CFG）的条件生成。然而，标准CFG对所有条件变量应用单一全局权重，可能导致身份保持不佳和虚假属性变化（属性放大现象）。为解决这一问题，我们提出了解耦无分类器引导（DCFG），这是一种灵活且模型无关的框架，引入了分组条件控制。DCFG基于属性分割嵌入策略，解耦语义输入，实现对用户定义属性组的选择性引导。在反事实生成中，我们根据因果图将属性分为干预组和不变组，并对每组应用不同的引导。在CelebA-HQ、MIMIC-CXR和EMBED上的实验表明，DCFG提高了干预保真度，减少了意外变化，并增强了可逆性，实现了更忠实和可解释的反事实图像生成。

</details>


### [101] [Causally Steered Diffusion for Automated Video Counterfactual Generation](https://arxiv.org/abs/2506.14404)
**中文标题：基于因果引导的自动视频反事实生成**

*Nikos Spyrou,Athanasios Vlontzos,Paraskevas Pegios,Thomas Melistas,Nefeli Gkouti,Yannis Panagakis,Giorgos Papanastasiou,Sotirios A. Tsaftaris*

主要分类: cs.CV

摘要简述: 本文提出了一种基于因果关系的视频反事实生成框架，通过优化文本提示引导潜在扩散模型生成因果一致的视频内容，无需修改底层编辑系统。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到图像扩散模型在视频编辑中虽表现良好，但容易忽略因果关系，导致生成内容不真实或误导性。本文旨在解决这一问题，确保反事实视频生成的因果一致性。

研究方法: 提出了一种与底层视频编辑系统无关的框架，通过视觉语言模型（VLM）引导生成。基于假设的因果图优化文本提示，控制潜在扩散模型（LDM）的潜在空间，确保因果关系的忠实性。

研究结果: 实验表明，该方法能有效生成因果一致的反事实视频，并通过标准视频质量指标和反事实特定标准（如因果有效性和最小性）验证其性能。

研究结论: 通过基于提示的因果引导，该方法能在潜在扩散模型的分布内生成真实的反事实视频，适用于医疗和数字媒体等领域。

中文摘要: 将文本到图像（T2I）潜在扩散模型应用于视频编辑已显示出较强的视觉保真度和可控性，但在保持视频内容因果关系方面仍存在挑战。若忽略因果关系，编辑可能影响因果依赖属性，导致生成不真实或误导性结果。本文提出了一种基于视觉语言模型（VLM）引导的因果忠实框架，用于反事实视频生成。该方法不依赖于底层视频编辑系统，无需访问其内部机制或微调，而是通过基于假设因果图优化文本提示，解决潜在扩散模型中潜在空间控制的难题。我们使用标准视频质量指标和反事实特定标准（如因果有效性和最小性）评估该方法。结果表明，通过基于提示的因果引导，可以在潜在扩散模型的分布内有效生成因果一致的反事实视频。由于与任何黑盒视频编辑系统兼容，该方法在医疗和数字媒体等领域具有生成真实“假设”视频场景的潜力。

</details>


### [102] [Compositional Attribute Imbalance in Vision Datasets](https://arxiv.org/abs/2506.14418)
**中文标题：视觉数据集中的组合属性不平衡**

*Jiayi Chen,Yanbiao Ma,Andi Zhang,Weidong Tang,Wei Dai,Bowei Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于CLIP的视觉属性字典构建方法，用于自动评估图像属性，并通过调整样本采样概率和数据增强技术解决视觉属性不平衡问题，显著提升了模型的鲁棒性和公平性。


<details>
  <summary>详细信息</summary>
研究动机: 视觉属性不平衡是图像分类中常见但未被充分研究的问题，严重影响模型性能和泛化能力。本文旨在揭示属性稀有性对模型的影响，并提出解决方案以提升模型对稀有属性的表征能力。

研究方法: 首先定义图像的一级和二级属性，利用CLIP框架构建视觉属性字典，自动评估属性。通过分析单属性和组合属性不平衡，提出基于属性稀有性调整样本采样概率，并结合CutMix、Fmix等数据增强技术优化模型。

研究结果: 在多个基准数据集上的实验表明，该方法有效缓解了属性不平衡问题，显著提升了深度神经网络的鲁棒性和公平性。

研究结论: 研究强调了建模视觉属性分布的重要性，并为长尾图像分类任务提供了可扩展的解决方案。

中文摘要: 视觉属性不平衡是图像分类中常见但未被充分研究的问题，显著影响模型性能和泛化能力。本文首先定义图像的一级和二级属性，并引入基于CLIP的框架构建视觉属性字典，实现属性的自动评估。通过系统分析单属性和组合属性不平衡，揭示了属性稀有性对模型性能的影响。为解决这些问题，提出基于组合属性稀有性调整样本采样概率，并将该策略与多种数据增强技术（如CutMix、Fmix和SaliencyMix）结合，以增强模型对稀有属性的表征能力。在多个基准数据集上的大量实验表明，我们的方法有效缓解了属性不平衡，从而提升了深度神经网络的鲁棒性和公平性。本研究强调了建模视觉属性分布的重要性，并为长尾图像分类任务提供了可扩展的解决方案。

</details>


### [103] [Toward Rich Video Human-Motion2D Generation](https://arxiv.org/abs/2506.14428)
**中文标题：面向丰富视频人体运动2D生成的研究**

*Ruihao Xi,Xuekuan Wang,Yongcheng Li,Shuhua Li,Zichen Wang,Yiwei Wang,Feng Wei,Cairong Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于扩散模型的丰富视频人体运动2D生成方法（RVHM2D），并引入了一个包含15万视频序列的大规模数据集（Motion2D-Video-150K），用于生成逼真且可控的单人和双人交互动作。


<details>
  <summary>详细信息</summary>
研究动机: 由于数据稀缺和人际动态建模的复杂性，生成逼真且可控的多人交互动作仍然是一个重大挑战。本文旨在通过引入新数据集和改进的生成模型解决这一问题。

研究方法: 首先构建了包含15万视频序列的Motion2D-Video-150K数据集，并提出RVHM2D模型，该模型采用双文本编码器（CLIP-L/B或T5-XXL）增强文本条件机制，并通过两阶段训练策略（扩散目标训练和基于FID奖励的强化学习微调）提升生成质量。

研究结果: 实验表明，RVHM2D在Motion2D-Video-150K基准测试中表现优异，能够生成高质量的单人和双人交互动作。

研究结论: RVHM2D通过结合新数据集和改进的生成方法，显著提升了丰富视频人体运动2D生成的质量和可控性。

中文摘要: 生成逼真且可控的人体运动，尤其是涉及多人交互的复杂动作，由于数据稀缺和人际动态建模的复杂性，仍然是一个重大挑战。为解决这些问题，我们首先引入了一个新的大规模丰富视频人体运动2D数据集（Motion2D-Video-150K），包含15万视频序列。Motion2D-Video-150K涵盖了多样化的单人动作和关键的双人交互动作，每个动作均配有详细的文本描述。基于此数据集，我们提出了一种新颖的基于扩散的丰富视频人体运动2D生成模型（RVHM2D）。RVHM2D采用双文本编码器（CLIP-L/B或T5-XXL）增强文本条件机制，结合全局和局部特征。我们设计了两阶段训练策略：首先使用标准扩散目标训练模型，然后通过基于FID奖励的强化学习进行微调，进一步提升动作逼真度和文本对齐效果。大量实验表明，RVHM2D在Motion2D-Video-150K基准测试中表现领先，能够生成高质量的单人和双人交互场景。

</details>


### [104] [MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models](https://arxiv.org/abs/2506.14435)
**中文标题：MoTE：面向内存高效大型多模态模型的三元专家混合方法**

*Hongyu Wang,Jiayu Xu,Ruiping Wang,Yan Feng,Yitao Zhai,Peng Pei,Xunliang Cai,Xilin Chen*

主要分类: cs.CV

摘要简述: 本文提出MoTE方法，通过混合三元专家（参数为{-1, 0, 1}）替代全精度专家，显著降低内存占用，同时保持性能，适用于内存受限的边缘设备。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型多模态混合专家（MoE）模型虽性能优越，但全精度专家导致高内存占用，难以在边缘设备部署。本文旨在开发一种内存高效的方法，解决这一问题。

研究方法: MoTE方法利用预训练的FFN作为共享专家，训练三元路由专家（参数为{-1, 0, 1}），替代全精度专家。此外，结合训练后量化技术进一步降低内存需求。

研究结果: 实验表明，MoTE在相同内存占用（3.4GB）下，性能优于全精度基线MoE-LLaVA，平均准确率提升4.3%，同时展现出良好的模型扩展性。

研究结论: MoTE是一种高效且内存友好的方法，适用于内存受限设备，为多模态模型的边缘部署提供了可行方案。

中文摘要: 大型多模态混合专家（MoE）模型通过扩展模型规模提升性能，同时保持固定的活跃参数。然而，现有工作主要采用全精度专家进行稀疏升级，尽管其在终端任务上表现优异，但大量专家导致高内存占用，对边缘设备部署构成挑战。本文提出MoTE，一种可扩展且内存高效的方法，从密集检查点训练三元专家混合模型。我们建议在升级时训练更多低精度专家而非少量高精度专家。具体而言，我们使用预训练的FFN作为共享专家，并训练参数为{-1, 0, 1}的三元路由专家。大量实验表明，我们的方法随模型规模扩展表现出良好趋势。MoTE在性能上与全精度基线MoE-LLaVA相当，同时内存占用更低。此外，该方法兼容训练后量化技术，且在内存约束更低时优势更显著。在相同专家内存占用（3.4GB）下，结合训练后量化，MoTE在终端任务上的平均准确率比MoE-LLaVA高出4.3%，证明了其在内存受限设备上的有效性和潜力。

</details>


### [105] [Model compression using knowledge distillation with integrated gradients](https://arxiv.org/abs/2506.14440)
**中文标题：基于集成梯度的知识蒸馏模型压缩方法**

*David E. Hernandez,Jose Chang,Torbjörn E. M. Nordling*

主要分类: cs.CV

摘要简述: 本文提出了一种基于集成梯度（IG）的知识蒸馏方法，用于模型压缩。通过在训练过程中将IG图叠加到输入图像上，学生模型能更深入理解教师模型的决策过程。实验表明，该方法在CIFAR-10上实现了92.6%的测试准确率，压缩比为4.1倍，显著优于非蒸馏模型。


<details>
  <summary>详细信息</summary>
研究动机: 在资源受限的设备上部署深度学习模型需要高效的模型压缩技术。传统方法在压缩过程中可能丢失关键信息，因此需要一种能保留教师模型决策细节的新方法。

研究方法: 提出了一种结合集成梯度（IG）的知识蒸馏方法。在训练前预计算IG图，并将其叠加到输入图像上作为数据增强策略，帮助学生模型更好地学习教师模型的决策过程。

研究结果: 在CIFAR-10上，该方法实现了92.6%的测试准确率，压缩比为4.1倍，显著优于非蒸馏模型（91.5%）。推理时间从140毫秒降至13毫秒。实验还验证了该方法在不同压缩比和架构下的鲁棒性和通用性。

研究结论: 基于IG的知识蒸馏方法在模型压缩中表现出色，既能显著减少模型大小和推理时间，又能保持高准确率，适用于边缘设备的实际部署。

中文摘要: 模型压缩对于在资源受限设备上部署深度学习模型至关重要。我们提出了一种新方法，通过将集成梯度（IG）作为数据增强策略来增强知识蒸馏。在训练过程中，我们的方法将IG图叠加到输入图像上，使学生模型能更深入地理解教师模型的决策过程。在CIFAR-10上的广泛实验表明，我们的IG增强知识蒸馏方法实现了92.6%的测试准确率，压缩比为4.1倍，显著优于非蒸馏模型（91.5%），且推理时间从140毫秒降至13毫秒。我们的方法在训练前预计算IG图，将运行时成本转化为一次性预处理步骤。实验包括：（1）与注意力转移的比较，显示与我们的方法结合时的互补优势；（2）蒙特卡洛模拟验证统计鲁棒性；（3）系统评估压缩比与准确率的权衡（2.2倍至1122倍）；（4）在ImageNet子集上的验证，证明了方法在初始数据集之外的通用性。这些实验表明，基于IG的知识蒸馏在不同架构和压缩比下均优于传统方法，为边缘设备的实际部署提供了一种可行的压缩技术。

</details>


### [106] [Adapting Lightweight Vision Language Models for Radiological Visual Question Answering](https://arxiv.org/abs/2506.14451)
**中文标题：轻量级视觉语言模型在放射学视觉问答中的适配**

*Aditya Shourya,Michel Dumontier,Chang Sun*

主要分类: cs.CV

摘要简述: 本研究通过微调轻量级视觉语言模型（3B参数）用于放射学视觉问答（VQA），证明小模型在精心调优后能在开放和封闭问题上表现优异。提出低成本训练流程，包括合成问答对生成和多阶段微调，结果虽规模小但性能接近先进模型。


<details>
  <summary>详细信息</summary>
研究动机: 放射学VQA模型面临数据标注有限、图像模式复杂及缺乏评估工具的挑战。研究旨在证明轻量级模型通过优化训练流程和数据集，能在资源有限条件下实现高性能。

研究方法: 采用轻量级3B参数视觉语言模型，通过合成问答对生成和多阶段微调（如ROCO v2.0和MedPix v2.0数据集）优化训练流程，并引入基于显著性的诊断工具分析模型性能。

研究结果: 尽管模型参数规模远小于先进模型（如LLaVA-Med），但在开放和封闭问题上表现稳健，且通过显著性分析工具能有效识别模型失败模式。

研究结论: 轻量级模型通过优化训练流程和数据集可显著提升放射学VQA性能，为资源有限场景提供高效解决方案。

中文摘要: 近年来，视觉语言系统的进步提升了放射学视觉问答（VQA）模型的准确性。然而，模型开发的每个阶段仍存在挑战：专家标注图像有限阻碍了大规模数据获取；放射学图像的复杂和细微模式使建模变得困难；缺乏评估工作使得难以识别模型可能不适用的案例。本研究通过微调一个轻量级3B参数的视觉语言模型用于放射学VQA，证明小模型在精心调优后能在开放和封闭问题上表现优异。我们提出了一种低成本的训练流程，从合成问答对生成到针对放射学领域数据集（如ROCO v2.0、MedPix v2.0）的多阶段微调。结果表明，尽管模型规模远小于先进模型（如LLaVA-Med），但在有限训练数据下仍表现出色。我们还引入了一种基于显著性的轻量级诊断工具，帮助领域专家通过显著性分析检查VQA模型性能并识别失败模式。

</details>


### [107] [Dense360: Dense Understanding from Omnidirectional Panoramas](https://arxiv.org/abs/2506.14471)
**中文标题：Dense360：基于全景图像的密集视觉理解**

*Yikang Zhou,Tao Zhang,Dizhe Zhang,Shunping Ji,Xiangtai Li,Lu Qi*

主要分类: cs.CV

摘要简述: 本文提出Dense360，首次通过全景图像实现密集视觉理解，并引入ERP-RoPE位置编码解决全景投影的挑战，同时发布首个全景视觉语言理解基准Dense360-Bench。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态大语言模型（MLLMs）通过有限视场（FOV）视觉输入实现世界理解，但全景图像能提供更完整、紧凑且连续的场景表示。本文旨在通过全景图像推动密集视觉理解的发展。

研究方法: 1. 构建包含16万张全景图像、500万密集实体级标注的数据集；2. 提出ERP-RoPE位置编码方案，解决全景投影中的空间连续性和信息密度变化问题；3. 发布Dense360-Bench基准，评估全景视觉语言理解能力。

研究结果: 实验表明，全景图像能显著提升场景理解的完整性，ERP-RoPE有效解决了全景投影的挑战，Dense360-Bench为全景视觉语言理解提供了标准化评估框架。

研究结论: 本文通过全景图像和ERP-RoPE编码推动了密集视觉理解的发展，Dense360-Bench为未来研究提供了重要工具。

中文摘要: 多模态大语言模型（MLLMs）需要全面的视觉输入以实现对物理世界的密集理解。尽管现有MLLMs通过有限视场（FOV）视觉输入（如70度）展示了强大的世界理解能力，但本文首次尝试通过全景图像实现密集理解。我们首先引入了一个全景图像数据集，包含全面的可靠性评分标注。具体而言，数据集包含16万张全景图像、500万密集实体级标注、100万独特指代表达和10万实体基础的全景场景描述。与多视图方案相比，全景图像通过等距柱状投影（ERP）提供了更完整、紧凑且连续的场景表示。然而，ERP的使用为MLLMs带来了两个关键挑战：i）沿纬度圈的空间连续性，ii）信息密度随纬度的变化。我们通过专为全景ERP设计的ERP-RoPE位置编码方案解决了这些挑战。此外，我们发布了Dense360-Bench，首个用于评估全景视觉语言理解的基准，为全景场景下的密集视觉语言理解建立了全面的框架。

</details>


### [108] [Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection](https://arxiv.org/abs/2506.14473)
**中文标题：基础模型洞察与多模型方法在细粒度单次子集选择中的卓越表现**

*Zhijing Wan,Zhixiang Wang,Zheng Wang,Xin Xu,Shin'ichi Satoh*

主要分类: cs.CV

摘要简述: 本文探讨了基于基础模型（FMs）的一种子集选择方法在细粒度数据集上的优越性，并提出了一种多模型方法RAM-APL，显著提升了细粒度图像数据集的子集选择性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的信息提取器（IE）依赖于目标数据集预训练，存在局限性。基础模型（FMs）可能提供更优的解决方案，但其在不同数据集上的表现尚不明确。本文旨在验证FMs在子集选择中的潜力，并探索其在不同数据集上的表现差异。

研究方法: 本文提出了一种名为RAM-APL（RAnking Mean-Accuracy of Pseudo-class Labels）的方法，通过结合多个基础模型的互补优势，优化细粒度图像数据集的子集选择。

研究结果: 实验表明，FMs在细粒度数据集上表现优于传统IE方法，但在粗粒度数据集上优势不明显。RAM-APL在多个细粒度数据集（如Oxford-IIIT Pet、Food-101和Caltech-UCSD Birds-200-2011）上达到了最先进的性能。

研究结论: 基础模型在细粒度数据集子集选择中具有显著优势，而RAM-APL方法通过多模型结合进一步提升了性能，为降低深度学习训练成本提供了有效工具。

中文摘要: 单次子集选择是一种通过信息提取器（IE）选择信息丰富的数据子集以降低深度学习训练成本的有效工具。传统IE通常基于目标数据集预训练，具有数据集依赖性。基础模型（FMs）为解决这一问题提供了可能。本文研究了两个关键问题：（1）基于FM的子集选择是否能在多样化数据集中优于传统IE方法？（2）所有FMs在子集选择中是否表现一致？大量实验揭示了令人惊讶的发现：FMs在细粒度数据集上始终优于传统IE，而在标签噪声较多的粗粒度数据集上优势减弱。基于此，我们提出了RAM-APL（RAnking Mean-Accuracy of Pseudo-class Labels），一种专为细粒度图像数据集设计的方法。RAM-APL利用多个FMs的互补优势提升子集选择性能。该方法在多个细粒度数据集（包括Oxford-IIIT Pet、Food-101和Caltech-UCSD Birds-200-2011）上达到了最先进的性能。

</details>


### [109] [I Speak and You Find: Robust 3D Visual Grounding with Noisy and Ambiguous Speech Inputs](https://arxiv.org/abs/2506.14495)
**中文标题：我说你找：基于噪声和歧义语音输入的鲁棒3D视觉定位**

*Yu Qi,Lipeng Gu,Honghua Chen,Liangliang Nan,Mingqiang Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SpeechRefer的新型3D视觉定位框架，旨在解决语音输入因噪声和歧义导致的转录错误问题，通过语音互补模块和对比互补模块提升现有3DVG模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D视觉定位方法依赖精确的文本提示，而现实中的语音输入常因口音、背景噪声和语速问题产生转录错误，限制了其应用。本文旨在解决这一问题，使3DVG系统更适应实际场景中的噪声语音输入。

研究方法: SpeechRefer框架包含两个关键模块：1) 语音互补模块，通过捕捉语音信号的声学相似性生成补充提案分数；2) 对比互补模块，利用对比学习对齐错误文本特征与语音特征，确保转录错误时的鲁棒性。

研究结果: 在SpeechRefer和SpeechNr3D数据集上的实验表明，SpeechRefer显著提升了现有3DVG方法的性能，证明了其在噪声语音输入下的有效性。

研究结论: SpeechRefer通过结合语音信号和文本特征，有效解决了噪声语音输入的挑战，为更直观、实用的多模态系统提供了可能。

中文摘要: 现有的3D视觉定位方法依赖于精确的文本提示来定位3D场景中的物体。语音作为一种自然直观的模态，提供了一种有前景的替代方案。然而，现实中的语音输入常因口音、背景噪声和语速问题导致转录错误，限制了现有3DVG方法的适用性。为解决这些问题，我们提出了\textbf{SpeechRefer}，一种新型3DVG框架，旨在提升噪声和歧义语音转录下的性能。SpeechRefer与现有3DVG模型无缝集成，并引入两项关键创新：1) 语音互补模块通过捕捉语音信号的声学相似性生成补充提案分数，减少对潜在错误转录的依赖；2) 对比互补模块利用对比学习对齐错误文本特征与语音特征，确保在转录错误主导时的鲁棒性。在SpeechRefer和SpeechNr3D数据集上的大量实验表明，SpeechRefer显著提升了现有3DVG方法的性能，凸显了其在噪声语音输入与可靠3DVG之间架起桥梁的潜力，为更直观、实用的多模态系统提供了可能。

</details>


### [110] [MOL: Joint Estimation of Micro-Expression, Optical Flow, and Landmark via Transformer-Graph-Style Convolution](https://arxiv.org/abs/2506.14511)
**中文标题：MOL：基于Transformer-图风格卷积的微表情、光流和关键点联合估计**

*Zhiwen Shao,Yifan Cheng,Feiran Li,Yong Zhou,Xuequan Lu,Yuan Xie,Lizhuang Ma*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer、图卷积和普通卷积的端到端微表情识别框架MOL，通过联合训练微表情识别、光流估计和面部关键点检测任务，显著提升了微表情识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 微表情识别（MER）因动作短暂且细微而具有挑战性。现有方法多依赖手工特征或关键帧，且受限于小规模和低多样性数据集。本文旨在通过结合多种深度学习技术，直接从未标记的原始帧序列中提取局部-全局特征，以提升MER性能。

研究方法: 提出了一种新颖的F5C模块，结合全连接卷积和通道对应卷积，直接从原始帧序列中提取局部-全局特征。通过Transformer风格的全连接卷积提取局部特征并保持全局感受野，图风格的通道对应卷积建模特征模式间的相关性。同时，联合训练MER、光流估计和面部关键点检测任务，共享特征以增强微表情识别能力。

研究结果: 实验表明，MOL框架在CASME II、SAMM和SMIC基准测试中优于现有MER方法，同时在光流估计和面部关键点检测任务中表现优异，并能捕捉与微表情相关的局部肌肉动作。

研究结论: MOL框架通过联合训练多任务和结合多种深度学习技术，显著提升了微表情识别的性能，同时为光流估计和面部关键点检测提供了有效解决方案。

中文摘要: 面部微表情识别（MER）因微表情动作短暂且细微而具有挑战性。现有方法多依赖手工特征、关键帧（如起始帧、峰值帧和结束帧）或受限于小规模和低多样性数据集的深度网络。本文提出了一种端到端的微动作感知深度学习框架，结合了Transformer、图卷积和普通卷积的优势。特别地，我们提出了一种新颖的F5C模块，由全连接卷积和通道对应卷积组成，可直接从原始帧序列中提取局部-全局特征，无需关键帧的先验知识。Transformer风格的全连接卷积用于提取局部特征并保持全局感受野，图风格的通道对应卷积用于建模特征模式间的相关性。此外，通过共享局部-全局特征，联合训练MER、光流估计和面部关键点检测任务。后两项任务有助于捕捉面部细微动作信息，从而缓解训练数据不足的影响。大量实验表明，我们的框架（i）在CASME II、SAMM和SMIC基准测试中优于现有MER方法，（ii）在光流估计和面部关键点检测任务中表现良好，（iii）能够捕捉与微表情相关的局部区域的面部细微肌肉动作。代码已开源：https://github.com/CYF-cuber/MOL。

</details>


### [111] [SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks](https://arxiv.org/abs/2506.14512)
**中文标题：SIRI-Bench：通过复杂推理任务挑战视觉语言模型的空间智能**

*Zijian Song,Xiaoxin Lin,Qiuming Huang,Guangrun Wang,Liang Lin*

主要分类: cs.CV

摘要简述: SIRI-Bench是一个评估视觉语言模型（VLMs）空间智能的基准测试，通过视频推理任务挑战其复杂空间推理能力。实验表明，现有VLMs在此测试中表现不佳，突显了空间推理的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）在复杂推理（如数学和编程）方面取得了显著进展，但视觉语言模型（VLMs）在空间智能方面的系统评估仍不足。为了填补这一空白，研究者提出了SIRI-Bench，旨在通过视频推理任务评估VLMs的空间推理能力。

研究方法: 研究者开发了SIRI-Bench基准测试，包含近1K个视频-问题-答案三元组，每个问题嵌入真实的3D场景并通过视频呈现。为确保问题解决需要空间理解和高级推理，研究者设计了专门的3D场景和问题。此外，还开发了自动场景生成引擎，利用多个专用LLM代理从抽象数学问题生成真实的3D场景。

研究结果: 实验结果表明，当前最先进的VLMs在SIRI-Bench上表现显著不佳，验证了空间推理任务的挑战性。

研究结论: SIRI-Bench为评估VLMs的空间智能提供了新工具，并揭示了其在空间推理方面的不足。研究者希望该研究能推动VLMs在视觉问题解决中的进步。

中文摘要: 大型语言模型（LLMs）在复杂推理方面取得了快速进展，尤其在数学和编程领域表现出显著的泛化能力。相比之下，尽管空间智能对视觉语言模型（VLMs）在现实世界交互中至关重要，但其在空间上下文中的复杂推理能力的系统评估仍未被充分探索。为填补这一空白，我们提出了SIRI-Bench，这是一个通过视频推理任务评估VLMs空间智能的基准测试。SIRI-Bench包含近1K个视频-问题-答案三元组，每个问题嵌入真实的3D场景并通过视频呈现。通过精心设计问题和对应的3D场景，我们的基准测试确保解决问题既需要空间理解以提取信息，又需要高级推理以推导解决方案，从而使其成为评估VLMs的挑战性基准。为支持大规模数据合成，我们开发了自动场景生成引擎。该引擎利用多个专用LLM代理，能够从抽象数学问题生成真实的3D场景，确保与原始描述的一致性。实验结果表明，当前最先进的VLMs在SIRI-Bench上表现显著不佳，突显了空间推理的挑战性。我们希望这项研究能引起研究者对空间推理的关注，并推动VLMs在视觉问题解决中的进步。

</details>


### [112] [VisLanding: Monocular 3D Perception for UAV Safe Landing via Depth-Normal Synergy](https://arxiv.org/abs/2506.14525)
**中文标题：VisLanding：基于深度-法线协同的单目3D感知无人机安全着陆技术**

*Zhuoyue Tan,Boyong He,Yuxiang Ji,Liaoni Wu*

主要分类: cs.CV

摘要简述: VisLanding提出了一种基于单目3D感知的无人机安全着陆框架，通过深度-法线协同预测优化安全着陆区识别，显著提升精度并保持零样本泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 解决无人机在复杂未知环境中自主着陆的核心挑战，通过深度-法线协同预测构建端到端的安全着陆区估计框架。

研究方法: 利用Metric3D V2模型的深度-法线协同预测能力，引入安全区分割分支将着陆区估计任务转化为二值语义分割问题，并使用WildUAV数据集进行微调和标注。

研究结果: 实验表明，VisLanding通过深度-法线联合优化机制显著提升安全区识别精度，并在跨域测试中表现出优越的泛化性和鲁棒性。

研究结论: VisLanding不仅优化了安全着陆区识别，还能通过深度和法线信息估计着陆区面积，为实际应用提供关键决策支持。

中文摘要: 本文提出VisLanding，一种基于单目3D感知的无人机安全着陆框架。针对无人机在复杂未知环境中自主着陆的核心挑战，本研究创新性地利用Metric3D V2模型的深度-法线协同预测能力，构建了一个端到端的安全着陆区（SLZ）估计框架。通过引入安全区分割分支，我们将着陆区估计任务转化为二值语义分割问题。模型使用无人机视角的WildUAV数据集进行微调和标注，同时构建跨域评估数据集以验证模型的鲁棒性。实验结果表明，VisLanding通过深度-法线联合优化机制显著提升了安全区识别的精度，同时保留了Metric3D V2的零样本泛化优势。与其他方法相比，所提方法在跨域测试中表现出更优的泛化性和鲁棒性。此外，该方法还能通过整合预测的深度和法线信息估计着陆区面积，为实际应用提供关键决策支持。

</details>


### [113] [Exploring Diffusion with Test-Time Training on Efficient Image Restoration](https://arxiv.org/abs/2506.14541)
**中文标题：探索基于测试时训练的高效图像修复扩散方法**

*Rongchang Lu,Tianduo Luo,Yunzhi Zhang,Conghan Yue,Pei Yang,Guibao Liu,Changyang Gu*

主要分类: cs.CV

摘要简述: 本文提出DiffRWKVIR框架，结合测试时训练与高效扩散方法，解决图像修复中的特征融合、计算瓶颈和扩散效率问题，通过三项创新技术显著提升性能与效率。


<details>
  <summary>详细信息</summary>
研究动机: 图像修复领域面临特征融合低效、计算瓶颈和扩散过程效率低下等问题，亟需一种自适应且高效的方法来优化硬件利用和性能。

研究方法: 方法包括：(1) Omni-Scale 2D状态演化，扩展RWKV的位置依赖参数化以实现全局上下文感知；(2) 分块优化闪存处理，通过连续分块处理加速并行计算；(3) 先验引导高效扩散，提取紧凑图像先验表示以加速训练和推理。

研究结果: 在超分辨率和修复任务中，DiffRWKVIR在PSNR、SSIM、LPIPS和效率指标上优于SwinIR、HAT和MambaIR/v2，训练和推理速度提升45%。

研究结论: DiffRWKVIR为自适应高效图像修复提供了新范式，显著优化了硬件利用和性能表现。

中文摘要: 图像修复面临特征融合低效、计算瓶颈和扩散过程效率低下等挑战。为此，我们提出DiffRWKVIR框架，将测试时训练（TTT）与高效扩散方法相结合。我们的方法包含三项关键创新：(1) Omni-Scale 2D状态演化，将RWKV的位置依赖参数化扩展为分层多方向2D扫描，实现线性复杂度O(L)的全局上下文感知；(2) 分块优化闪存处理，通过连续分块处理将分块内并行加速3.2倍（复杂度O(LCd)），减少顺序依赖和计算开销；(3) 先导引导高效扩散，仅需5-20步提取紧凑图像先验表示（IPR），比DiffIR训练/推理速度快45%，同时解决去噪中的计算低效问题。在超分辨率和修复基准测试（Set5、Set14、BSD100、Urban100、Places365）中，DiffRWKVIR在PSNR、SSIM、LPIPS和效率指标上优于SwinIR、HAT和MambaIR/v2。我们的方法为自适应高效图像修复建立了新范式，优化了硬件利用率。

</details>


### [114] [DreamLight: Towards Harmonious and Consistent Image Relighting](https://arxiv.org/abs/2506.14549)
**中文标题：DreamLight：迈向和谐一致的图像重光照**

*Yong Liu,Wenpeng Xiao,Qianqian Wang,Junlin Chen,Shiyin Wang,Yitong Wang,Xinglong Wu,Yansong Tang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DreamLight的通用图像重光照模型，能够无缝地将主体合成到新背景中，同时保持光照和色调的美学一致性。该模型支持基于图像或文本的重光照，并通过创新的位置引导光适配器和频谱前景修复器提升效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注基于图像的重光照，对基于文本的场景探索较少。现有方法要么依赖复杂的数据分解流程，要么将任务视为图像翻译问题，难以生成真实的光照交互效果。DreamLight旨在解决这些问题，提供更自然和一致的重光照结果。

研究方法: DreamLight将输入数据统一格式化，并利用预训练扩散模型的语义先验生成自然结果。提出位置引导光适配器（PGLA）将背景光信息压缩为光查询嵌入，并通过方向偏置掩码注意力调制前景。此外，频谱前景修复器（SFF）模块自适应重组前景和背景的频率分量以增强一致性。

研究结果: 通过广泛的对比和用户研究，DreamLight在重光照任务中表现出色，能够生成真实且自然的光照交互效果。

研究结论: DreamLight通过创新的PGLA和SFF模块，显著提升了图像重光照的自然性和一致性，为基于图像和文本的重光照任务提供了高效解决方案。

中文摘要: 本文介绍了一种名为DreamLight的通用图像重光照模型，能够无缝地将主体合成到新背景中，同时保持光照和色调的美学一致性。背景可以通过自然图像（基于图像的重光照）或无限文本提示（基于文本的重光照）指定。现有研究主要关注基于图像的重光照，而对基于文本的场景探索较少。一些工作依赖复杂的环境图分解流程，需要昂贵的数据成本进行固有分解和光源提取；其他方法将此任务视为图像翻译问题，通过自编码器架构进行像素级变换。尽管这些方法取得了一定的和谐效果，但难以生成前景与背景之间真实自然的光照交互效果。为缓解这些问题，我们将输入数据统一格式化，并利用预训练扩散模型的语义先验促进自然结果的生成。此外，我们提出了一种位置引导光适配器（PGLA），将背景中不同方向的光信息压缩为设计的光查询嵌入，并通过方向偏置掩码注意力调制前景。我们还提出了一种后处理模块——频谱前景修复器（SFF），自适应地重组主体和重光照背景的不同频率分量，以增强前景外观的一致性。广泛的对比和用户研究表明，DreamLight在重光照任务中表现出色。

</details>


### [115] [Risk Estimation of Knee Osteoarthritis Progression via Predictive Multi-task Modelling from Efficient Diffusion Model using X-ray Images](https://arxiv.org/abs/2506.14560)
**中文标题：基于高效扩散模型的多任务预测建模从X射线图像中估计膝关节骨关节炎进展风险**

*David Butler,Adrian Hilton,Gustavo Carneiro*

主要分类: cs.CV

摘要简述: 本文提出了一种新的可解释机器学习方法，通过多任务预测模型从高效扩散模型生成的X射线图像中估计膝关节骨关节炎（OA）进展风险，同时预测未来OA严重程度和膝关节解剖标志点，提高了预测准确性和推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于医学图像的膝关节OA风险预测方法缺乏可解释性，且现有生成未来图像的方法复杂且不实用。此外，先前方法未能定位膝关节解剖标志点，限制了其临床适用性。本文旨在填补这些空白。

研究方法: 采用多任务预测模型，结合类条件潜在空间的扩散模型，生成高质量的未来图像，并同时分类未来OA严重程度和预测膝关节解剖标志点。

研究结果: 在Osteoarthritis Initiative数据集上，该方法将预测膝关节OA进展的AUC提升至0.71，比现有最佳方法提高2%，推理时间缩短约9%。

研究结论: 本文提出的方法不仅提高了膝关节OA进展风险预测的准确性，还通过生成可解释的未来图像和定位解剖标志点，增强了临床适用性。

中文摘要: 医学影像在评估膝关节骨关节炎（OA）风险中起着关键作用，可实现早期检测和疾病监测。最近的机器学习方法通过医学图像改进了风险估计（即预测疾病进展的可能性）和预测建模（即基于当前数据预测未来结果），但由于缺乏可解释性，临床采用仍有限。现有生成未来图像以估计风险的方法复杂且不实用。此外，先前方法未能定位膝关节解剖标志点，限制了可解释性。我们通过一种新的可解释机器学习方法填补了这些空白，该方法通过多任务预测模型从高效生成的高质量未来图像中分类未来OA严重程度并预测膝关节解剖标志点，从而估计膝关节OA进展风险。这种图像生成是通过在类条件潜在空间中利用扩散模型预测疾病进展实现的，提供了特定健康状况可能如何演变的视觉表示。在Osteoarthritis Initiative数据集上的应用表明，我们的方法将预测膝关节OA进展的AUC提升至0.71，比现有最佳方法提高2%，同时推理时间缩短约9%。

</details>


### [116] [Synthetic Data Augmentation for Table Detection: Re-evaluating TableNet's Performance with Automatically Generated Document Images](https://arxiv.org/abs/2506.14583)
**中文标题：合成数据增强用于表格检测：通过自动生成的文档图像重新评估TableNet的性能**

*Krishna Sahukara,Zineddine Bettouche,Andreas Fischer*

主要分类: cs.CV

摘要简述: 本文提出了一种基于LaTeX的自动化流程，用于生成包含多样化表格布局的合成文档图像，以增强真实数据集Marmot。实验表明，使用合成数据训练的TableNet在合成测试集上表现优异，并在Marmot基准测试中显著减少了人工标注需求。


<details>
  <summary>详细信息</summary>
研究动机: 智能手机或扫描仪捕获的文档页面通常包含表格，但手动提取速度慢且易出错。因此，需要一种自动化方法来生成多样化的表格布局数据，以提升表格检测模型的性能并减少人工标注成本。

研究方法: 研究团队开发了一种基于LaTeX的自动化流程，能够合成具有多样化表格布局的双栏文档图像，并生成对齐的真实掩码。生成的合成数据用于增强真实数据集Marmot，并用于系统性地评估TableNet的性能。

研究结果: 在合成测试集上，TableNet在256x256分辨率下的像素级XOR误差为4.04%，在1024x1024分辨率下为4.33%。在Marmot基准测试中，最佳性能为9.18%（256x256分辨率），同时通过自动化显著减少了人工标注工作量。

研究结论: 通过合成数据增强，TableNet在表格检测任务中表现出色，同时降低了人工标注的需求。该方法为文档图像分析提供了一种高效且可扩展的解决方案。

中文摘要: 智能手机或扫描仪捕获的文档页面通常包含表格，但手动提取速度慢且易出错。我们提出了一种基于LaTeX的自动化流程，能够合成具有多样化表格布局的双栏文档图像，并生成对齐的真实掩码。生成的语料库增强了真实数据集Marmot，并支持对TableNet进行系统性分辨率研究。在合成测试集上，TableNet在256x256分辨率下的像素级XOR误差为4.04%，在1024x1024分辨率下为4.33%。在Marmot基准测试中，最佳性能为9.18%（256x256分辨率），同时通过自动化显著减少了人工标注工作量。

</details>


### [117] [PoseGRAF: Geometric-Reinforced Adaptive Fusion for Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2506.14596)
**中文标题：PoseGRAF：基于几何强化的自适应融合单目3D人体姿态估计**

*Ming Xu,Xu Zhang*

主要分类: cs.CV

摘要简述: PoseGRAF提出了一种基于几何强化的自适应融合框架，用于单目3D人体姿态估计，通过双图卷积结构和跨注意力模块捕捉关节与骨骼的依赖关系，显著提升了姿态估计的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有单目3D姿态估计方法主要依赖关节位置特征，忽略了骨骼内在的方向和角度关联，导致在关节遮挡或快速运动时生成不合理的姿态。PoseGRAF旨在通过几何强化和自适应融合解决这一问题。

研究方法: PoseGRAF构建了双图卷积结构，分别处理关节图和骨骼图，捕捉局部依赖关系；引入跨注意力模块建模骨骼方向与关节特征的相互依赖；设计动态融合模块自适应整合两种特征；最后通过改进的Transformer编码器生成最终输出。

研究结果: 在Human3.6M和MPI-INF-3DHP数据集上的实验表明，PoseGRAF超越了现有最优方法。在真实场景视频中的额外评估进一步验证了其泛化能力。

研究结论: PoseGRAF通过几何强化和自适应融合显著提升了单目3D姿态估计的准确性和鲁棒性，为复杂场景下的姿态估计提供了有效解决方案。

中文摘要: 现有的单目3D姿态估计方法主要依赖关节位置特征，而忽略了骨骼内在的方向和角度关联，导致在关节遮挡或快速运动时生成不合理的姿态。为解决这一问题，我们提出了PoseGRAF框架。首先构建双图卷积结构，分别处理关节图和骨骼图，有效捕捉其局部依赖关系；随后引入跨注意力模块建模骨骼方向与关节特征的相互依赖；在此基础上设计动态融合模块，自适应整合两种特征；最后通过改进的Transformer编码器生成最终输出。在Human3.6M和MPI-INF-3DHP数据集上的实验表明，我们的方法超越了现有最优方法。在真实场景视频中的额外评估进一步验证了其泛化能力。代码已公开于https://github.com/iCityLab/PoseGRAF。

</details>


### [118] [Align Your Flow: Scaling Continuous-Time Flow Map Distillation](https://arxiv.org/abs/2506.14603)
**中文标题：对齐你的流：扩展连续时间流图蒸馏**

*Amirmojtaba Sabour,Sanja Fidler,Karsten Kreis*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Align Your Flow的连续时间流图蒸馏方法，通过改进训练目标和引入新技术，解决了现有一致性模型在步数增加时性能下降的问题，并在图像生成任务中取得了领先效果。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型和流模型是目前最先进的生成模型，但需要大量采样步骤。一致性模型可以将其蒸馏为高效的一步生成器，但在步数增加时性能会下降。本文旨在通过流图方法解决这一问题，并提升少步生成性能。

研究方法: 本文提出了两种新的连续时间训练目标，并引入新技术（如自动引导和对抗微调），扩展了现有的一致性和流匹配目标。流图方法能够在任何两个噪声级别之间单步连接，且在所有步数下均有效。

研究结果: 在ImageNet 64x64和512x512等挑战性图像生成基准测试中，Align Your Flow模型取得了少步生成的领先性能，同时保持了样本多样性。文本到图像任务中，其表现优于所有非对抗训练的少步采样器。

研究结论: Align Your Flow通过流图蒸馏和新技术，显著提升了少步生成性能，为高效生成模型提供了新思路。

中文摘要: 扩散模型和流模型已成为最先进的生成建模方法，但它们需要大量采样步骤。一致性模型可以将这些模型蒸馏为高效的一步生成器；然而，与流和扩散方法不同，其性能在步数增加时不可避免地下降，我们通过分析和实验验证了这一点。流图方法通过单步连接任意两个噪声级别，并在所有步数下保持有效性，从而推广了这些方法。本文提出了两种新的连续时间训练目标，以及额外的创新训练技术，扩展了现有的一致性和流匹配目标。我们还证明，自动引导可以通过在蒸馏过程中使用低质量模型进行指导来提升性能，而对抗微调可以进一步改进效果，同时样本多样性损失极小。我们广泛验证了名为Align Your Flow的流图模型，在具有挑战性的图像生成基准测试中取得了领先的少步生成性能，包括ImageNet 64x64和512x512，且使用小型高效神经网络。最后，我们展示了在文本条件合成中，文本到图像流图模型的表现优于所有现有的非对抗训练的少步采样器。

</details>


### [119] [Unsupervised Imaging Inverse Problems with Diffusion Distribution Matching](https://arxiv.org/abs/2506.14605)
**中文标题：基于扩散分布匹配的无监督成像逆问题**

*Giacomo Meanti,Thomas Ryckeboer,Michael Arbel,Julien Mairal*

主要分类: cs.CV

摘要简述: 本文提出了一种基于无配对数据集的图像复原方法，通过条件流匹配和分布匹配损失学习退化观测分布和前向模型，适用于真实场景中前向模型未知或数据难以配对的情况。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像复原方法通常需要完整的前向模型知识或配对的退化与真实图像数据，但在真实场景中，前向模型往往未知或错误，且配对数据难以获取。本文旨在解决这一问题，提出一种仅需少量无配对数据的方法。

研究方法: 该方法利用条件流匹配建模退化观测的分布，并通过分布匹配损失自然学习前向模型。其核心在于最小化假设，仅依赖少量无配对数据集。

研究结果: 实验表明，该方法在去模糊和非均匀点扩散函数校准任务上优于单图像盲方法和无监督方法，并在盲超分辨率任务上达到最先进性能。此外，还展示了其在镜头校准这一真实应用中的有效性。

研究结论: 本文方法在无需配对数据或完整前向模型的情况下，实现了高效的图像复原，适用于真实场景中的多种任务。

中文摘要: 本文通过逆问题的视角，利用无配对数据集解决图像复原任务。与传统方法不同，传统方法通常假设完全了解前向模型或能够获取配对的退化与真实图像，而本文方法仅需少量无配对数据，适用于前向模型未知或错误且配对数据难以获取的真实场景。该方法通过条件流匹配建模退化观测的分布，同时通过框架中自然产生的分布匹配损失学习前向模型。实验表明，该方法在去模糊和非均匀点扩散函数校准任务上优于单图像盲方法和无监督方法，并在盲超分辨率任务上达到最先进性能。此外，还展示了其在镜头校准这一真实应用中的有效性：传统方法需要耗时实验和专用设备，而本文方法仅需极少数据采集即可实现。

</details>


### [120] [VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning](https://arxiv.org/abs/2506.14629)
**中文标题：VisText-Mosquito：基于AI的蚊虫滋生地检测与推理的多模态数据集与基准**

*Md. Adnanul Islam,Md. Faiyaz Abdullah Sayeedi,Md. Asaduzzaman Shuvo,Muhammad Ziaur Rahman,Shahanur Rahman Bappy,Raiyan Rahman,Swakkhar Shatabda*

主要分类: cs.CV

摘要简述: 本文介绍了VisText-Mosquito多模态数据集，结合视觉与文本数据支持蚊虫滋生地的自动化检测、分割与推理分析，展示了AI在预防蚊媒疾病中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 蚊媒疾病是全球重大健康威胁，早期检测和主动控制蚊虫滋生地是预防疫情的关键。本文旨在通过多模态数据集和AI模型，提升蚊虫滋生地的自动化分析与推理能力。

研究方法: 构建VisText-Mosquito数据集，包含1,828张标注图像用于目标检测、142张图像用于水面分割，以及每张图像关联的自然语言推理文本。采用YOLOv9s和YOLOv11n-Seg模型分别进行目标检测和分割，并微调BLIP模型生成推理文本。

研究结果: YOLOv9s在目标检测中达到最高精度0.92926和mAP@50为0.92891；YOLOv11n-Seg的分割精度为0.91587，mAP@50为0.79795。BLIP模型的推理生成任务中，最终损失为0.0028，BLEU得分为54.7，BERTScore为0.91，ROUGE-L为0.87。

研究结论: VisText-Mosquito数据集和模型框架展示了AI在蚊媒疾病预防中的实际应用价值，强调“预防胜于治疗”的理念。数据集和代码已公开。

中文摘要: 蚊媒疾病是全球重大健康威胁，需通过早期检测和主动控制蚊虫滋生地以预防疫情。本文提出VisText-Mosquito多模态数据集，整合视觉与文本数据，支持蚊虫滋生地的自动化检测、分割与推理分析。数据集包含1,828张标注图像用于目标检测、142张图像用于水面分割，以及每张图像关联的自然语言推理文本。YOLOv9s模型在目标检测中达到最高精度0.92926和mAP@50为0.92891；YOLOv11n-Seg的分割精度为0.91587，mAP@50为0.79795。推理生成任务中，微调的BLIP模型最终损失为0.0028，BLEU得分为54.7，BERTScore为0.91，ROUGE-L为0.87。该数据集和模型框架体现了“预防胜于治疗”的主题，展示了AI在蚊媒疾病风险主动应对中的潜力。数据集和实现代码已公开于GitHub：https://github.com/adnanul-islam-jisun/VisText-Mosquito

</details>


### [121] [3DGS-IEval-15K: A Large-scale Image Quality Evaluation Database for 3D Gaussian-Splatting](https://arxiv.org/abs/2506.14642)
**中文标题：3DGS-IEval-15K：面向3D高斯点云的大规模图像质量评估数据库**

*Yuke Xing,Jiarui Wang,Peizhi Niu,Wenjie Huang,Guangtao Zhai,Yiling Xu*

主要分类: cs.CV

摘要简述: 本文提出了首个针对3D高斯点云（3DGS）压缩图像质量评估的大规模数据集3DGS-IEval-15K，包含15,200张图像，通过主观实验收集了60名观众的评价数据，并验证了数据集的多样性和质量分布。该数据集为开发3DGS专用图像质量评估指标提供了基础。


<details>
  <summary>详细信息</summary>
研究动机: 3D高斯点云（3DGS）在实时渲染和高视觉保真度方面表现出色，但其高存储需求限制了实际应用。尽管现有方法引入了压缩模块，但缺乏评估其感知影响的全面框架。因此，本文旨在填补这一空白。

研究方法: 作者构建了包含15,200张图像的数据集，这些图像来自10个真实场景，通过6种代表性3DGS算法在20个视角下渲染，并应用不同压缩级别以产生多种失真效果。通过主观实验收集了60名观众的评价数据，并分析了场景多样性和平均意见分数（MOS）分布。

研究结果: 数据集验证了其多样性和质量分布的有效性，并建立了包含30种代表性图像质量评估指标的基准。这是目前最大规模的3DGS质量评估数据集。

研究结论: 3DGS-IEval-15K为开发3DGS专用图像质量评估指标提供了基础，并为研究3DGS特有的视角依赖性质量分布模式提供了重要数据。数据集已公开。

中文摘要: 3D高斯点云（3DGS）作为一种新兴的新视角合成方法，能够实现高视觉保真度的实时渲染，但其高存储需求为实际应用带来了挑战。尽管最新的3DGS方法逐渐引入了专用压缩模块，但仍缺乏评估其感知影响的全面框架。为此，我们提出了3DGS-IEval-15K，这是首个专门针对压缩3DGS表示设计的大规模图像质量评估（IQA）数据集。我们的数据集包含15,200张图像，这些图像通过6种代表性3DGS算法在10个真实场景的20个选定视角下渲染，并通过不同压缩级别产生多种失真效果。通过受控主观实验，我们收集了60名观众的人类感知数据。通过场景多样性和MOS分布分析验证了数据集质量，并建立了包含30种代表性IQA指标的全面基准。作为迄今为止最大规模的3DGS质量评估数据集，我们的工作为开发3DGS专用IQA指标奠定了基础，并为研究3DGS特有的视角依赖性质量分布模式提供了重要数据。该数据库已公开发布于https://github.com/YukeXing/3DGS-IEval-15K。

</details>


### [122] [DDS-NAS: Dynamic Data Selection within Neural Architecture Search via On-line Hard Example Mining applied to Image Classification](https://arxiv.org/abs/2506.14667)
**中文标题：DDS-NAS：基于在线困难样本挖掘的动态数据选择在神经架构搜索中的应用——以图像分类为例**

*Matt Poyser,Toby P. Breckon*

主要分类: cs.CV

摘要简述: 本文提出DDS-NAS框架，通过动态数据选择和课程学习加速神经架构搜索（NAS）训练，提升效率27倍且不损失性能。


<details>
  <summary>详细信息</summary>
研究动机: 神经架构搜索（NAS）的可扩展性面临挑战，传统方法训练耗时且效率低。本文旨在通过动态数据选择和课程学习优化NAS训练过程，减少训练时间和迭代次数。

研究方法: 利用自编码器构建图像相似性嵌入的潜在空间，并通过kd树结构按最远邻不相似性排序图像。动态选择当前NAS架构表现较差的图像子集，重新优化训练数据。

研究结果: DDS-NAS框架将基于梯度的NAS策略加速高达27倍，同时保持性能不变。通过最大化每张图像的贡献，显著缩短训练周期和收敛所需的迭代次数。

研究结论: DDS-NAS通过动态数据选择和课程学习，显著提升了NAS的训练效率和可扩展性，为图像分类任务提供了一种高效的解决方案。

中文摘要: 为了解决神经架构搜索（NAS）中的可扩展性挑战，我们通过课程学习框架中的动态困难样本挖掘加速NAS训练。利用自编码器在潜在空间中强制图像相似性嵌入，构建高效的kd树结构，按最远邻不相似性对图像进行排序。从子样本数据集中给定查询图像，可以在对数时间内识别全局数据集中最不相似的图像。通过课程学习，动态重新构建一个无偏子样本数据集，用于NAS优化，当前NAS解决方案在该数据集上表现较差。实验表明，DDS-NAS框架将基于梯度的NAS策略加速高达27倍，且性能无损失。通过最大化每张图像样本在训练中的贡献，减少了NAS训练周期的持续时间和收敛所需的迭代次数。

</details>


### [123] [Recognition through Reasoning: Reinforcing Image Geo-localization with Large Vision-Language Models](https://arxiv.org/abs/2506.14674)
**中文标题：通过推理实现识别：利用大型视觉语言模型增强图像地理定位**

*Ling Li,Yao Zhou,Yuxuan Liang,Fugee Tsung,Jiaheng Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种基于大型视觉语言模型（LVLM）的图像地理定位新方法GLOBE，通过构建多样化数据集MP16-Reason和优化视觉线索推理，显著提升了地理定位的准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像地理定位方法多为分类或检索任务，缺乏可解释性。大型视觉语言模型的出现为基于推理的地理定位提供了可能，但现有数据集和模型在多样性和推理能力上存在不足。

研究方法: 提出GLOBE方法，构建多样化数据集MP16-Reason，并采用组相对策略优化（Group-relative policy optimization）联合提升定位能力评估、视觉线索推理和地理定位准确性。

研究结果: GLOBE在多样化视觉场景中优于现有开源LVLM模型，地理定位任务表现更优，并生成更具洞察力和可解释性的推理轨迹。

研究结论: GLOBE通过结合多样化数据集和优化推理方法，显著提升了地理定位任务的性能，为基于推理的地理定位提供了新思路。

中文摘要: 以往的地理定位方法通常将其视为分类或检索任务，依赖缺乏可解释性的黑盒决策。大型视觉语言模型（LVLM）的兴起使得基于视觉线索的推理驱动地理定位成为可能。然而，仍存在两大挑战：数据方面，现有推理数据集主要基于街景图像，场景多样性和视角受限；模型方面，当前方法主要依赖监督微调，推理能力提升有限。为解决这些问题，我们提出了一种新流程，利用多样化社交媒体图像构建推理导向的地理定位数据集MP16-Reason，并引入GLOBE方法（Group-relative policy optimization for Locatability assessment and Optimized visual-clue reasoning），通过联合优化定位能力评估、视觉线索推理和地理定位准确性，实现双目标增强。定性和定量结果表明，GLOBE在地理定位任务中优于现有开源LVLM模型，尤其在多样化视觉场景中表现更优，同时生成更具洞察力和可解释性的推理轨迹。

</details>


### [124] [FocalClick-XL: Towards Unified and High-quality Interactive Segmentation](https://arxiv.org/abs/2506.14686)
**中文标题：FocalClick-XL：迈向统一且高质量的交互式分割**

*Xi Chen,Hengshuang Zhao*

主要分类: cs.CV

摘要简述: 本文提出FocalClick-XL，一种新型交互式分割方法，通过多级子网络设计支持多种交互形式（如点击、涂鸦和框选），并实现高质量的分割结果。


<details>
  <summary>详细信息</summary>
研究动机: 现有交互式分割方法支持的交互形式有限且难以捕捉细节，本文旨在通过扩展FocalClick的多阶段设计，解决这些问题并提升分割质量。

研究方法: 提出FocalClick-XL，将交互式分割分解为捕捉不同级别信息（上下文、对象和细节）的元任务，每个任务由专用子网络处理。通过独立数据和监督进行预训练，并在对象级别引入提示层以编码特定交互类型。

研究结果: FocalClick-XL在点击基准测试中达到最优性能，并适应多种交互形式（如框选、涂鸦和粗掩模），还能预测精细的alpha遮罩。

研究结论: FocalClick-XL是一种多功能且强大的交互式分割工具，支持多种交互形式并生成高质量分割结果。

中文摘要: 交互式分割允许用户通过点击、涂鸦和框选等简单交互提取目标对象的二值掩模。然而，现有方法通常仅支持有限的交互形式，且难以捕捉细节。本文重新审视FocalClick的经典由粗到细设计，并引入重要扩展。受其多阶段策略启发，我们提出一种新流程FocalClick-XL，以同时解决这些挑战。遵循大规模预训练的趋势，我们将交互式分割分解为捕捉不同级别信息（上下文、对象和细节）的元任务，并为每个级别分配专用子网络。这种分解允许每个子网络通过独立数据和监督进行规模化预训练，最大化其效果。为增强灵活性，我们在上下文和细节级别共享不同交互形式的通用知识，同时在对象级别引入提示层以编码特定交互类型。最终，FocalClick-XL在点击基准测试中达到最优性能，并展现出对多种交互形式（如框选、涂鸦和粗掩模）的显著适应性。除二值掩模生成外，它还能预测包含精细细节的alpha遮罩，使其成为一种多功能且强大的交互式分割工具。

</details>


### [125] [YOLOv11-RGBT: Towards a Comprehensive Single-Stage Multispectral Object Detection Framework](https://arxiv.org/abs/2506.14696)
**中文标题：YOLOv11-RGBT：迈向全面的单阶段多光谱目标检测框架**

*Dahang Wan,Rongsheng Lu,Yang Fang,Xianli Lang,Shuangbao Shu,Jingjing Chen,Siyuan Shen,Ting Xu,Zecong Ye*

主要分类: cs.CV

摘要简述: 本文提出YOLOv11-RGBT，一种基于YOLOv11的单阶段多光谱目标检测框架，设计了六种多光谱融合模式，并提出P3中融合策略和多光谱可控微调策略，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有多光谱目标检测方法在跨模态交互、低光条件和模型轻量化方面虽有进展，但仍缺乏统一的单阶段框架，且性能和融合策略难以平衡，模态权重分配不合理。

研究方法: 基于YOLOv11框架，设计了六种多光谱融合模式，并应用于YOLOv3至YOLOv12和RT-DETR模型；提出P3中融合策略和多光谱可控微调（MCF）策略，优化特征融合，减少冗余和失配。

研究结果: 实验表明，该框架在LLVIP和FLIR等三大开源多光谱数据集上表现优异，MCF策略显著提升模型适应性和鲁棒性，FLIR数据集上YOLOv11模型的mAP提升3.41%-5.65%，最高达47.61%。

研究结论: YOLOv11-RGBT框架及提出的策略有效解决了多光谱目标检测中的关键问题，显著提升了性能，验证了其在实际应用中的潜力。

中文摘要: 多光谱目标检测通过整合多波段信息，可提升检测精度和环境适应性，具有广泛的应用潜力。尽管现有方法在跨模态交互、低光条件和模型轻量化方面取得进展，但仍面临缺乏统一单阶段框架、性能与融合策略难以平衡及模态权重分配不合理等挑战。为此，基于YOLOv11框架，我们提出YOLOv11-RGBT，一种新型综合多模态目标检测框架。我们设计了六种多光谱融合模式，并成功应用于YOLOv3至YOLOv12和RT-DETR模型。在重新评估两种模态重要性后，提出了P3中融合策略和多光谱可控微调（MCF）策略。这些改进优化了特征融合，减少了冗余和失配，提升了整体模型性能。实验表明，我们的框架在LLVIP和FLIR等三大开源多光谱数据集上表现优异。特别是多光谱可控微调策略显著增强了模型的适应性和鲁棒性。在FLIR数据集上，该策略使YOLOv11模型的mAP持续提升3.41%-5.65%，最高达47.61%，验证了框架和策略的有效性。代码已开源：https://github.com/wandahangFY/YOLOv11-RGBT。

</details>


### [126] [Iterative Camera-LiDAR Extrinsic Optimization via Surrogate Diffusion](https://arxiv.org/abs/2506.14706)
**中文标题：基于替代扩散的相机-LiDAR外参迭代优化**

*Ni Ou,Zhuo Chen,Xinru Zhang,Junzheng Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于替代扩散的迭代框架，用于优化相机与LiDAR的外参标定，显著提升了现有标定方法的精度、鲁棒性和稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 相机和LiDAR是自动驾驶车辆的关键传感器，但其数据融合依赖于精确的外参标定。现有端到端标定方法多为单步预测，缺乏迭代优化能力，难以满足日益增长的高精度需求。

研究方法: 通过替代扩散框架，将初始外参标定结果迭代优化。原始标定方法作为替代去噪器，逐步估计最终外参，无需修改其架构。

研究结果: 实验表明，结合扩散模型后，四种先进标定方法在精度、鲁棒性和稳定性上均优于其他迭代方法及其单步版本。

研究结论: 提出的迭代框架为外参标定提供了通用解决方案，显著提升了现有方法的性能，适用于高精度需求场景。

中文摘要: 相机和LiDAR是自动驾驶车辆的关键传感器。相机与LiDAR数据的融合弥补了单一传感器的局限性，但依赖于精确的外参标定。近年来，许多端到端标定方法被提出，但多数为单步预测外参，缺乏迭代优化能力。为满足日益增长的高精度需求，我们提出了一种基于替代扩散的通用迭代框架。该框架无需修改架构即可提升任何标定方法的性能。具体而言，初始外参通过去噪过程迭代优化，原始标定方法作为替代去噪器逐步估计最终外参。为对比分析，我们选取了四种先进标定方法作为替代去噪器，并将扩散结果与其他两种迭代方法进行比较。大量实验表明，结合扩散模型后，所有标定方法在精度、鲁棒性和稳定性上均优于其他迭代技术及其单步版本。

</details>


### [127] [DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning](https://arxiv.org/abs/2506.14709)
**中文标题：DiFuse-Net：基于窗口双向视差注意力和跨模态迁移学习的RGB与双像素深度估计**

*Kunal Swami,Debtanu Gupta,Amrit Kumar Muduli,Chirag Jaiswal,Pankaj Kumar Bajpai*

主要分类: cs.CV

摘要简述: DiFuse-Net提出了一种新颖的双像素（DP）和RGB深度估计网络，通过窗口双向视差注意力机制（WBiPAM）和跨模态迁移学习（CmTL）提升性能，并贡献了高质量RGB-DP-D数据集DCDP。


<details>
  <summary>详细信息</summary>
研究动机: 传统深度估计方法（如立体视觉和主动传感器）在成本、功耗和鲁棒性方面存在局限，而现代相机普遍采用的双像素（DP）技术提供了新思路。本文旨在利用DP技术实现更高效的深度估计。

研究方法: DiFuse-Net采用模态解耦网络设计，结合窗口双向视差注意力机制（WBiPAM）捕捉智能手机相机的小光圈独特视差线索，并通过跨模态迁移学习（CmTL）利用大规模RGB-D数据集弥补RGB-DP-D数据不足。

研究结果: 实验表明，DiFuse-Net在DP和立体视觉基准方法中表现优越，同时贡献了高质量的真实世界RGB-DP-D数据集DCDP。

研究结论: DiFuse-Net通过新颖的网络设计和跨模态学习机制，显著提升了双像素和RGB深度估计的性能，为未来研究提供了新方向和数据支持。

中文摘要: 深度估计对智能系统至关重要，广泛应用于自动驾驶和增强现实等领域。传统立体视觉和主动深度传感器在成本、功耗和鲁棒性方面存在局限，而现代相机普遍采用的双像素（DP）技术提供了新选择。本文提出DiFuse-Net，一种新颖的模态解耦网络设计，用于解耦RGB和DP深度估计。DiFuse-Net采用窗口双向视差注意力机制（WBiPAM），专门捕捉智能手机相机小光圈的独特DP视差线索。独立的编码器从RGB图像中提取上下文信息，并通过特征融合提升深度预测。我们还提出跨模态迁移学习（CmTL）机制，利用文献中的大规模RGB-D数据集应对RGB-DP-D数据不足的问题。实验表明，该方法在DP和立体视觉基准方法中表现优越。此外，我们贡献了一个高质量的真实世界RGB-DP-D训练数据集DCDP，采用新颖的对称立体相机硬件设置、立体校准与校正协议及AI立体视差估计方法构建。

</details>


### [128] [Active InSAR monitoring of building damage in Gaza during the Israel-Hamas War](https://arxiv.org/abs/2506.14730)
**中文标题：以色列-哈马斯战争期间加沙地带建筑损毁的主动InSAR监测**

*Corey Scher,Jamon Van Den Hoek*

主要分类: cs.CV

摘要简述: 本文利用Sentinel-1的干涉合成孔径雷达（InSAR）数据，采用长时间相干变化检测（LT-CCD）方法，实时监测了2023年以色列-哈马斯战争期间加沙地带的建筑损毁情况。结果显示，92.5%的损毁标签与联合国参考数据一致，假阳性率仅为1.2%。研究发现，战争前三个月损毁迅速增加，停火期间损毁暂停，随后损毁热点从北部转移至南部。研究结束时，加沙地带五分之三的建筑（191,263栋）受损或被毁。


<details>
  <summary>详细信息</summary>
研究动机: 2023年10月7日开始的加沙地带空袭是21世纪最猛烈的轰炸行动之一，导致广泛的城市损毁。在动态且持久的武装冲突中，实时监测损毁情况至关重要。合成孔径雷达（SAR）在灾害损毁测绘中有应用先例，但在持续危机中的实时监测应用有限。本文旨在填补这一空白。

研究方法: 研究使用Sentinel-1的干涉SAR数据，采用长时间相干变化检测（LT-CCD）方法，每周跟踪2023年以色列-哈马斯战争第一年的损毁趋势。

研究结果: 研究发现，92.5%的损毁标签与联合国参考数据一致，假阳性率仅为1.2%。战争前三个月损毁迅速增加，主要集中在加沙北部；停火期间损毁暂停；随后损毁热点转移至南部。研究结束时，五分之三的建筑（191,263栋）受损或被毁。

研究结论: 本文提出的低成本、低延迟方法为武装冲突区域的损毁监测提供了及时数据，有助于人道主义和新闻机构快速获取信息。

中文摘要: 2023年10月7日开始的加沙地带空袭是21世纪最猛烈的轰炸行动之一，导致广泛的城市损毁。在动态且持久的武装冲突中，实时监测损毁情况至关重要。合成孔径雷达（SAR）在灾害损毁测绘中有应用先例，但在持续危机中的实时监测应用有限。本研究使用Sentinel-1的干涉SAR数据，采用长时间相干变化检测（LT-CCD）方法，每周跟踪2023年以色列-哈马斯战争第一年的损毁趋势。结果显示，92.5%的损毁标签与联合国参考数据一致，假阳性率仅为1.2%。研究发现，战争前三个月损毁迅速增加，主要集中在加沙北部；停火期间损毁暂停；随后损毁热点转移至南部。研究结束时，五分之三的建筑（191,263栋）受损或被毁。本研究提出的低成本、低延迟方法为武装冲突区域的损毁监测提供了及时数据，有助于人道主义和新闻机构快速获取信息。

</details>


### [129] [SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting](https://arxiv.org/abs/2506.14742)
**中文标题：SyncTalk++：基于高斯泼溅的高保真高效同步说话头合成**

*Ziqiao Peng,Wentao Hu,Junyuan Ma,Xiangyu Zhu,Xiaomei Zhang,Hao Zhao,Hui Tian,Jun He,Hongyan Liu,Zhaoxin Fan*

主要分类: cs.CV

摘要简述: SyncTalk++通过高斯泼溅技术和多模块协同，实现了高保真、高效的语音驱动说话头视频合成，解决了同步性问题，显著提升了渲染速度和质量。


<details>
  <summary>详细信息</summary>
研究动机: 合成逼真的语音驱动说话头视频时，同步性问题（如身份一致性、唇动、表情和头部姿态）是关键挑战。现有方法常因同步性不足导致结果不真实。SyncTalk++旨在解决这一问题，提升合成视频的同步性和真实感。

研究方法: SyncTalk++采用动态肖像渲染器（高斯泼溅技术）确保身份一致性，面部同步控制器（3D面部混合形状模型）精准对齐唇动与语音，头部同步稳定器优化头部姿态。此外，通过表情生成器和躯干修复器增强对分布外音频的鲁棒性。

研究结果: SyncTalk++在同步性和真实感上优于现有方法，渲染速度达每秒101帧，用户研究证实其显著提升的视觉效果和流畅性。

研究结论: SyncTalk++通过多模块协同和高斯泼溅技术，有效解决了说话头视频合成的同步性问题，实现了高保真和高效渲染，为相关领域提供了新的解决方案。

中文摘要: 在合成逼真的语音驱动说话头视频时，实现高度同步是一项重大挑战。逼真的说话头需要同步协调主体身份、唇动、表情和头部姿态。缺乏这些同步会导致结果不真实。为解决这一关键问题（被称为创建逼真说话头的“魔鬼”），我们提出了SyncTalk++。它采用基于高斯泼溅的动态肖像渲染器确保身份一致性，面部同步控制器通过3D面部混合形状模型精准对齐唇动与语音，头部同步稳定器优化头部姿态以增强稳定性。此外，SyncTalk++通过表情生成器和躯干修复器提升对分布外音频的鲁棒性，生成与语音匹配的表情和无缝躯干区域。该方法在帧间保持视觉细节的一致性和连续性，显著提升了渲染速度和质量，最高可达每秒101帧。大量实验和用户研究表明，SyncTalk++在同步性和真实感上优于现有方法。建议观看补充视频：https://ziqiaopeng.github.io/synctalk++。

</details>


### [130] [Cost-Aware Routing for Efficient Text-To-Image Generation](https://arxiv.org/abs/2506.14753)
**中文标题：成本感知路由用于高效文本到图像生成**

*Qinchan,Li,Kenneth Chen,Changyue,Su,Wittawat Jitkrittum,Qi Sun,Patsorn Sangkloy*

主要分类: cs.CV

摘要简述: 本文提出了一种成本感知路由框架，用于根据提示词的复杂度动态分配计算资源，以优化文本到图像生成的质量与计算成本之间的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型虽然能生成高质量图像，但其迭代去噪过程计算成本高昂。本文旨在通过动态路由机制，根据提示词的复杂度分配不同的生成模型或步骤，以实现质量与成本的最优平衡。

研究方法: 提出一个框架，自动将提示词路由到最适合的文本到图像生成函数，这些函数可能对应不同去噪步骤的扩散模型或独立的生成模型。通过保留高成本选择（如100+去噪步骤）仅用于复杂提示词，而对简单提示词采用低成本选择（如小型蒸馏模型）。

研究结果: 在COCO和DiffusionDB数据集上的实验表明，通过学习路由到九个预训练模型，该方法能提供比单独使用任一模型更高的平均生成质量。

研究结论: 本文提出的成本感知路由框架有效平衡了文本到图像生成的质量与计算成本，为复杂提示词保留高成本选择，同时为简单提示词节省计算资源。

中文摘要: 扩散模型以其通过迭代去噪过程为输入提示生成高质量图像的能力而闻名。然而，由于固有的顺序生成过程，高质量也伴随着高计算成本。本文旨在平衡质量与计算成本，并提出一个框架，根据提示词的复杂度动态调整计算量。每个提示词会自动路由到最合适的文本到图像生成函数，这些函数可能对应扩散模型的不同去噪步骤，或独立的文本到图像模型。与统一成本降低技术（如蒸馏、模型量化）不同，我们的方法通过学习仅为少数复杂提示词保留昂贵选择（如100+去噪步骤），而对不太复杂的提示词采用更经济的选择（如小型蒸馏模型），实现了最优权衡。在COCO和DiffusionDB上的实验表明，通过学习路由到九个已训练的文本到图像模型，我们的方法能够提供比单独使用任一模型更高的平均生成质量。

</details>


### [131] [Scaling-Up the Pretraining of the Earth Observation Foundation Model PhilEO to the MajorTOM Dataset](https://arxiv.org/abs/2506.14765)
**中文标题：将地球观测基础模型PhilEO扩展至MajorTOM数据集**

*Nikolaos Dionelis,Jente Bosmans,Riccardo Musto,Giancarlo Paoletti,Simone Sarti,Giacomo Cascarano,Casper Fibaek,Luke Camilleri,Bertrand Le Saux,Nicolas Longépé*

主要分类: cs.CV

摘要简述: 本文展示了如何将地球观测基础模型PhilEO扩展至23TB的MajorTOM数据集，并通过不同参数和架构的模型变体验证了数据集和模型规模化的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 地球观测卫星（如Copernicus Sentinel-2）每天产生大量数据，但如何高效利用这些数据仍是一个挑战。本文旨在通过扩展PhilEO基础模型的预训练规模，提升其在多种下游任务中的性能。

研究方法: 研究团队将PhilEO Geo-Aware U-Net模型扩展至23TB的MajorTOM数据集和2TB的FastTOM子集，开发了不同参数和架构的模型变体，并在PhilEO Bench上进行了微调和性能评估。

研究结果: 结果显示，PhilEO 44M MajorTOM 23TB模型在道路密度回归任务中表现优于PhilEO Globe 0.5TB 44M；PhilEO 200M FastTOM在道路密度估计和建筑密度回归任务中表现最佳。

研究结论: 通过验证数据集和模型规模化的有效性，本文证明了扩展预训练规模对提升地球观测基础模型性能的重要性。

中文摘要: 如今，地球观测（EO）卫星每天产生大量数据，仅Copernicus Sentinel-2星座每天就产生约1.6TB数据。为充分利用这些信息，必须在大型未标记数据集上预训练EO基础模型（FMs），以便用少量标记数据高效微调多种下游任务。本文展示了我们最近提出的EO基础模型PhilEO Geo-Aware U-Net在23TB未标记数据集MajorTOM（覆盖地球大部分表面）和2TB子集FastTOM（不包括海洋和冰）上的扩展。我们开发并研究了不同参数和架构的PhilEO模型变体，并在PhilEO Bench上对道路密度估计、建筑密度像素回归和土地覆盖语义分割任务进行了微调和性能评估。结果表明，在道路密度回归任务中，PhilEO 44M MajorTOM 23TB模型在所有n-shot情况下均优于PhilEO Globe 0.5TB 44M；在道路密度估计和建筑密度回归任务中，PhilEO 200M FastTOM在大多数n-shot情况下表现最佳。通过PhilEO Bench验证了数据集和模型规模化的有效性。我们还研究了从U-Net卷积神经网络（CNN）到视觉变换器（ViT）的架构扩展影响。

</details>


### [132] [ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM](https://arxiv.org/abs/2506.14766)
**中文标题：ASCD：注意力可调控的对比解码以减少多模态大语言模型中的幻觉**

*Yujun Wang,Jinhe Bi,Yunpu Ma,Soeren Pirk*

主要分类: cs.CV

摘要简述: 提出了一种注意力可调控的对比解码框架（ASCD），通过直接干预多模态大语言模型（MLLM）的注意力机制，显著减少幻觉现象，并在多个基准测试中提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLM）常因过度依赖部分线索而产生幻觉，生成错误回答。现有方法（如VCD和ICD）通过对比扰动或负前缀输入的预测结果来缓解幻觉，但其有效性可能源于注意力分布的变化。因此，本文提出直接干预注意力机制，以更系统地减少幻觉。

研究方法: 提出注意力可调控的对比解码框架（ASCD），直接干预模型的注意力机制，而非仅通过表面级的logits调整。该方法通过对比解码动态调整注意力分布，从而更有效地减少幻觉。

研究结果: 实验表明，ASCD在多个MLLM架构和不同解码方法中显著减少幻觉，并在POPE、CHAIR和MMHal-Bench等基准测试中提升性能，同时改善了标准VQA任务的性能。

研究结论: ASCD通过直接干预注意力机制，提供了一种更系统的方法来减少MLLM的幻觉现象，并在多个任务中验证了其有效性。

中文摘要: 多模态大语言模型（MLLM）常因过度依赖部分线索而产生幻觉，生成错误回答。近期提出的方法（如视觉对比解码VCD和指令对比解码ICD）通过对比扰动或负前缀输入的预测结果来缓解幻觉。本文发现，VCD和ICD等方法从根本上影响了模型的内部注意力动态，表明其有效性可能源于注意力分布的深层变化，而非仅表面级的logits调整。基于这一发现，我们提出了一种注意力可调控的对比解码框架，直接干预模型的注意力机制，以更系统地减少幻觉。实验表明，该方法在多种MLLM架构和解码方法中显著减少幻觉，并在POPE、CHAIR和MMHal-Bench等基准测试中提升性能，同时改善了标准VQA任务的性能。

</details>


### [133] [CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal Diffusion](https://arxiv.org/abs/2506.14769)
**中文标题：CDP：基于因果扩散的稳健自回归视觉运动策略学习**

*Jiahua Ma,Yiran Qin,Yixiong Li,Xuanqi Liao,Yulan Guo,Ruimao Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于因果扩散的稳健自回归视觉运动策略学习方法（CDP），通过历史动作序列增强动作预测，显著提升了机器人任务执行的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 在实际应用中，硬件限制和数据质量下降会严重影响基于专家演示的学习效果，导致对象定位、抓取规划和长时程任务执行失败。为解决这些问题，作者提出了CDP方法。

研究方法: CDP是一种基于Transformer的扩散模型，通过历史动作序列进行条件化，实现更连贯和上下文感知的动作预测。此外，引入缓存机制以减少自回归推理中的冗余计算。

研究结果: 在模拟和真实环境的多种2D和3D操作任务中，CDP显著优于现有方法，且在输入观测质量下降时仍能保持高精度，展现了其在实际机器人控制中的鲁棒性。

研究结论: CDP通过利用历史动作序列和因果扩散机制，显著提升了视觉运动策略学习的准确性和鲁棒性，适用于现实世界中不完美的控制条件。

中文摘要: 扩散策略（DP）通过动作扩散使机器人能够通过模仿专家演示学习复杂行为。然而，在实际应用中，硬件限制会降低数据质量，而实时性约束要求模型仅基于瞬时状态和场景观测进行推理。这些限制严重影响了从专家演示中学习的效果，导致对象定位、抓取规划和长时程任务执行失败。为解决这些问题，我们提出了因果扩散策略（CDP），这是一种基于Transformer的新型扩散模型，通过历史动作序列进行条件化，从而实现了更连贯和上下文感知的视觉运动策略学习。为了进一步降低自回归推理的计算成本，还引入了缓存机制以存储先前时间步的注意力键值对，大幅减少了执行中的冗余计算。在模拟和真实环境的多种2D和3D操作任务中，实验表明CDP通过利用历史动作序列，显著优于现有方法。此外，即使在输入观测质量下降的情况下，CDP仍能通过时间连续性推理保持高精度，展现了其在现实不完美条件下机器人控制的实用鲁棒性。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [134] ['Memory States' from Almost Nothing: Representing and Computing in a Non-associative Algebra](https://arxiv.org/abs/2506.13768)
**中文标题：从几乎无到有的“记忆状态”：非结合代数中的表示与计算**

*Stefan Reimann*

主要分类: cs.AI

摘要简述: 本文提出了一种非结合代数框架，用于在高维空间中表示和计算信息项，支持空间计算原则并与认知科学中关于记忆的实证发现一致。通过非结合捆绑操作，该框架能够稀疏表示任意长序列并保持其时间结构，同时噪声成为顺序信息的组成部分。


<details>
  <summary>详细信息</summary>
研究动机: 现有模型依赖结合捆绑操作时通常会丢失顺序信息，需要额外结构（如位置标记）来表示对认知任务重要的序列信息。本文旨在提出一种非结合代数框架，解决这一问题并模拟认知实验中的序列位置效应。

研究方法: 提出了一种非结合代数框架，通过类似乘法的绑定操作和非结合干扰式捆绑进行计算。该框架生成两种状态：L状态（左结合捆绑）强调近因效应，R状态（右结合捆绑）编码有限序列或块，捕获首因效应。

研究结果: 该模型能够复制序列位置曲线，反映认知实验中观察到的近因和首因效应。噪声成为顺序信息的组成部分而非干扰因素，且检索准确性依赖于记忆状态与线索之间的互信息。

研究结论: 非结合代数框架能够有效表示和计算高维空间中的信息项，保持序列的时间结构，并模拟认知实验中的记忆效应。L状态和R状态分别与短期记忆和长期记忆的神经机制相关。

中文摘要: 本文提出了一种非结合代数框架，用于在高维空间中表示和计算信息项。该框架与空间计算原则一致，并符合认知科学中关于记忆的实证发现。计算通过类似乘法的绑定操作和非结合干扰式捆绑进行。依赖结合捆绑的模型通常会丢失顺序信息，因此需要使用辅助顺序结构（如位置标记）来表示对认知任务重要的序列信息。相比之下，提出的非结合捆绑操作允许构建稀疏表示，保持任意长序列的时间结构。在此操作中，噪声是顺序信息的组成部分，而非掩盖手段。非结合性质导致单个序列由两种不同状态表示：L状态（左结合捆绑）持续更新并强调近因效应，R状态（右结合捆绑）编码有限序列或块，捕获首因效应。这些状态的构建可能与前额叶皮层（短期记忆）和海马编码（长期记忆）的活动相关。检索准确性依赖于记忆状态与线索之间的互信息决策过程。该模型能够复制序列位置曲线，反映认知实验中观察到的近因和首因效应。

</details>


### [135] [Representing Time-Continuous Behavior of Cyber-Physical Systems in Knowledge Graphs](https://arxiv.org/abs/2506.13773)
**中文标题：在知识图谱中表示信息物理系统的时间连续行为**

*Milapji Singh Gill,Tom Jeleniewski,Felix Gehlhoff,Alexander Fay*

主要分类: cs.AI

摘要简述: 本文提出了一种基于标准的知识图谱模块化语义模型和高效生成方法，用于表示和语义丰富时间连续的微分方程行为，并在航空维护领域验证了其实际应用性。


<details>
  <summary>详细信息</summary>
研究动机: 时间连续的动态模型对信息物理系统（CPS）应用至关重要，但现有知识图谱缺乏可重用的本体工具和方法以减少手动实例化的工作量。

研究方法: 提出了一种基于标准的模块化语义模型，用于在知识图谱中直接表示微分方程并语义丰富化；同时提出了一种高效的知识图谱生成方法。

研究结果: 在航空维护领域的验证表明，复杂电液伺服执行器的微分方程可以在知识图谱中形式化表示，并与其他生命周期数据关联，证明了方法的实用性。

研究结论: 本文提出的语义模型和生成方法能够有效支持时间连续行为的表示和上下文关联，为CPS应用提供了实用工具。

中文摘要: 时间连续的动态模型对信息物理系统（CPS）的多种应用至关重要。为了确保其在不同生命周期阶段的有效可用性，此类以微分方程形式表示的行为信息需要与其他CPS信息进行上下文关联和整合。尽管知识图谱为此任务提供了形式化描述和结构化机制，但目前缺乏可重用的本体工具和方法以减少手动实例化的工作量。因此，本文提出了两种工具：首先，引入了一种基于标准的模块化语义模型，用于在知识图谱中直接表示微分方程并语义丰富化；其次，提出了一种高效的知识图谱生成方法。这些工具在航空维护领域进行了验证。结果表明，复杂电液伺服执行器的微分方程可以在知识图谱中形式化表示，并与其他生命周期数据关联，证明了这些工具的实际应用性。

</details>


### [136] [Personalized Constitutionally-Aligned Agentic Superego: Secure AI Behavior Aligned to Diverse Human Values](https://arxiv.org/abs/2506.13774)
**中文标题：个性化宪法对齐的代理超我：与多样化人类价值观一致的AI行为安全机制**

*Nell Watson,Ahmed Amer,Evan Harris,Preeti Ravindra,Shujun Zhang*

主要分类: cs.AI

摘要简述: 本文提出一种新型‘超我’代理机制，通过动态引用用户选择的‘信条宪法’来指导AI行为，显著减少有害输出并提升个性化对齐效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前自主AI系统在行为对齐多样化人类价值观、复杂安全需求和合规要求方面面临挑战，现有方法难以提供深度个性化信息而不引发混淆或效率低下。

研究方法: 设计‘超我’代理作为个性化监督机制，动态调整AI规划以匹配用户选择的‘信条宪法’，并通过实时合规检查确保行为符合伦理底线。

研究结果: 实验显示，该方法显著降低有害输出（最高减少98.3%），并在主流大模型（如Gemini 2.5 Flash和GPT-4o）上实现近乎完美的拒绝率（如Claude Sonnet 4在AgentHarm测试中达100%）。

研究结论: ‘超我’代理简化了AI个性化对齐，使其更适应个体和文化背景，同时显著提升安全性。

中文摘要: 自主AI系统在多个领域展现出巨大潜力，但其实际部署因行为与多样化人类价值观、复杂安全需求和特定合规要求的对齐问题而受阻。现有方法在提供深度个性化上下文信息时易引发混淆或效率低下。本文提出一种新型解决方案：‘超我’代理，作为自主AI的个性化监督机制。该系统通过动态引用用户选择的‘信条宪法’（包含多样化规则集）来指导AI规划，并根据不可协商的价值观调整遵从级别。执行前，实时合规检查器会验证计划是否符合这些宪法及通用伦理底线。我们展示了一个功能系统，包括演示界面（www.Creed.Space）和原型宪法共享门户，并通过模型上下文协议（MCP）成功集成第三方模型。全面基准测试（HarmBench、AgentHarm）表明，‘超我’代理显著减少有害输出（最高降低98.3%），并在主流大模型（如Gemini 2.5 Flash和GPT-4o）上实现近乎完美的拒绝率（如Claude Sonnet 4在AgentHarm有害测试中达100%）。该方法大幅简化了AI个性化对齐，使自主系统更可靠地适应个体和文化背景，同时显著提升安全性。研究概述及示例见https://superego.creed.space。

</details>


### [137] [Recommendations and Reporting Checklist for Rigorous & Transparent Human Baselines in Model Evaluations](https://arxiv.org/abs/2506.13776)
**中文标题：模型评估中严谨透明的人类基准：建议与报告清单**

*Kevin L. Wei,Patricia Paskov,Sunishchal Dev,Michael J. Byun,Anka Reuel,Xavier Roberts-Gaal,Rachel Calcott,Evie Coxon,Chinmay Deshpande*

主要分类: cs.AI

摘要简述: 本文主张在基础模型评估中，人类基准需要更严谨和透明，以支持人类与AI性能的有意义比较，并提供相关建议和报告清单。


<details>
  <summary>详细信息</summary>
研究动机: 当前人类基准方法在AI评估中不够严谨且缺乏透明度，导致“超人类”性能的声称难以验证。本文旨在改进这一现状，为研究社区和政策制定者提供更可靠的评估实践。

研究方法: 基于测量理论和AI评估文献的元分析，提出了设计、执行和报告人类基准的框架，并总结为清单，用于系统审查115项基础模型评估中的人类基准研究。

研究结果: 通过清单审查发现现有基准方法存在不足，同时清单可帮助研究者更规范地进行人类基准研究和结果报告。

研究结论: 本文提出的框架和清单有望推动更严谨的AI评估实践，服务于研究社区和政策制定者。

中文摘要: 在本立场论文中，我们认为基础模型评估中的人类基准必须更加严谨和透明，以实现人类与AI性能的有意义比较，并为此提供建议和报告清单。人类性能基准对机器学习社区、下游用户和政策制定者解读AI评估至关重要。模型常被宣称达到“超人类”性能，但现有基准方法既不够严谨，也缺乏充分记录，难以稳健衡量和评估性能差异。基于对测量理论和AI评估文献的元分析，我们提出了设计、执行和报告人类基准的框架建议，并将其总结为清单，用于系统审查115项基础模型评估中的人类基准研究，从而识别现有方法的不足；该清单还可帮助研究者进行人类基准研究和结果报告。我们希望这项工作能推动更严谨的AI评估实践，更好地服务于研究社区和政策制定者。数据见：https://github.com/kevinlwei/human-baselines

</details>


### [138] [The NordDRG AI Benchmark for Large Language Models](https://arxiv.org/abs/2506.13790)
**中文标题：NordDRG AI基准测试：针对大型语言模型的评估**

*Tapio Pitkäranta*

主要分类: cs.AI

摘要简述: NordDRG-AI-Benchmark是首个针对医院资金分配层（DRG）的公开测试平台，用于评估大型语言模型在多语言诊断、手术和费率逻辑中的推理能力。基准包含三类资源：定义表、专家手册和任务提示包。测试显示不同LLM表现差异显著，凸显了领域特异性。


<details>
  <summary>详细信息</summary>
研究动机: 目前尚无公开基准测试针对医院资金分配层（DRG），而大型语言模型（LLMs）已开始用于临床编码和决策支持。因此，作者开发了NordDRG-AI-Benchmark，填补这一空白，并评估LLMs在DRG逻辑中的表现。

研究方法: NordDRG-AI-Benchmark包含三类资源：(i) 定义表，涵盖DRG逻辑、ICD和NCSP代码等；(ii) 专家手册和变更日志模板；(iii) 14个CaseMix任务的提示包。通过自动验证任务测试五种先进LLM的表现。

研究结果: 测试结果显示，五种LLM在九项可自动验证任务中表现差异显著：o3（OpenAI）满分9分，GPT-4o和o4-mini-high得7分，Gemini 2.5 Pro和Gemini 2.5 Flash分别得5分和3分。

研究结论: NordDRG-AI-Benchmark揭示了LLM在领域特异性任务中的优劣势，为医院资金自动化研究提供了可复现的基线，弥补了通用基准的不足。

中文摘要: 大型语言模型（LLMs）已开始试点用于临床编码和决策支持，但此前尚无公开基准测试针对医院资金分配层（DRG）。我们发布了NordDRG-AI-Benchmark，首个公开测试平台，涵盖完整的DRG规则集，并评估LLM在多语言诊断、手术和费率逻辑中的推理能力。基准包含三类资源：(i) 定义表，涵盖DRG逻辑、ICD和NCSP代码等；(ii) 专家手册和变更日志模板；(iii) 14个CaseMix任务的提示包。测试显示五种先进LLM表现差异显著，凸显了领域特异性。所有资源可在https://github.com/longshoreforrest/norddrg-ai-benchmark获取。

</details>


### [139] [ICE-ID: A Novel Historical Census Data Benchmark Comparing NARS against LLMs, \& a ML Ensemble on Longitudinal Identity Resolution](https://arxiv.org/abs/2506.13792)
**中文标题：ICE-ID：一种新型历史人口普查数据基准，比较NARS与LLMs以及ML集成方法在纵向身份解析中的表现**

*Gonçalo Hora de Carvalho,Lazar S. Popov,Sander Kaatee,Kristinn R. Thórisson,Tangrui Li,Pétur Húni Björnsson,Jilles S. Dibangoye*

主要分类: cs.AI

摘要简述: 本文介绍了ICE-ID，一个用于历史身份解析的新基准数据集，涵盖1703-1920年的冰岛人口普查记录。通过比较NARS、LLMs和ML集成方法，研究发现NARS在任务中表现优异，并发布了数据集和代码以促进跨学科研究。


<details>
  <summary>详细信息</summary>
研究动机: 历史身份解析在人口普查和家谱研究中具有重要意义，但缺乏大规模、开放的数据集和方法比较。本文旨在填补这一空白，通过ICE-ID数据集和多种方法的比较，推动该领域的研究。

研究方法: 研究构建了ICE-ID数据集，包含220年的冰岛人口普查记录，定义了身份解析任务，并比较了基于规则的匹配器、ML集成方法、LLMs以及NARS（一种基于非公理逻辑的通用AI框架）。

研究结果: 实验表明，NARS方法在身份解析任务中表现优异，达到了当前最佳水平（SOTA），同时其设计简单且适用于资源有限的情况。

研究结论: 通过发布ICE-ID数据集和代码，本文为纵向身份解析提供了可复现的基准，并希望推动数据链接和历史分析领域的跨学科研究。

中文摘要: 我们介绍了ICE-ID，一个用于历史身份解析的新基准数据集，涵盖1703-1920年的冰岛人口普查记录。ICE-ID包含多代纵向数据，记录了姓名变化、人口统计变化和丰富的家谱链接。据我们所知，这是首个专门用于研究真实人口中长期个人实体匹配的大规模开放表格数据集。我们定义了身份解析任务（包括普查波次内和跨波次），并提供了清晰的指标和分割。我们评估了多种方法：手工规则匹配器、ML集成方法以及用于结构化数据的LLMs（如基于Transformer的表格网络），并将其与一种名为NARS（非公理推理系统）的新方法进行比较。NARS是一种通用AI框架，旨在在知识和资源有限的情况下进行推理，其核心是非公理逻辑（NAL）。实验表明，NARS设计简单且与其他标准方法相比具有竞争力，在我们的任务中达到了SOTA水平。通过发布ICE-ID和代码，我们为纵向身份解析方法提供了可复现的基准，并希望ICE-ID能为数据链接和历史分析的跨学科研究开辟新途径。

</details>


### [140] [Med-REFL: Medical Reasoning Enhancement via Self-Corrected Fine-grained Reflection](https://arxiv.org/abs/2506.13793)
**中文标题：Med-REFL：通过自校正细粒度反思增强医疗推理**

*Zongxian Yang,Jiayu Qian,Zegao Peng,Haoyu Zhang,Zhi-An Huang*

主要分类: cs.AI

摘要简述: Med-REFL通过细粒度自校正反思提升医疗推理能力，显著提高模型在医疗问答中的表现，平均提升4.11%，并在7B/8B模型上进一步优化4.13%。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型推理模型在数学和代码领域表现优异，但在医疗领域表现不佳，主要原因是中间反思步骤的质量不足。医疗场景的高风险性要求更高的推理准确性，因此需要一种方法提升反思质量。

研究方法: Med-REFL采用树状思维方法，将医疗问题分解为细粒度推理路径，并定量评估每一步及其后续反思。通过自动构建直接偏好优化数据，减少对昂贵专家标注的依赖，同时引导模型识别和纠正推理错误。

研究结果: 在MedQA-USMLE基准测试中，Med-REFL平均提升4.11%，并在7B/8B模型上进一步优化4.13%。此外，该方法在多个挑战性医疗问答数据集上表现出强大的泛化能力和鲁棒性。

研究结论: Med-REFL通过优先考虑反思质量，显著提升了医疗AI应用的推理准确性和可信度，为医疗领域的高风险场景提供了更可靠的解决方案。

中文摘要: 大型推理模型在数学和代码领域取得了显著进展，但其成功并未顺利扩展到医疗领域。尽管多种因素导致了这一差异，但一个关键问题是中间反思步骤的质量不足，这在高风险医疗场景中尤为重要。为解决这一挑战，我们提出了Med-REFL，一种通过自校正细粒度反思增强医疗推理的方法。我们的方法利用树状思维将医疗问题分解为细粒度推理路径，定量评估每一步及其后续反思。这些评估能够自动构建直接偏好优化数据，减少对昂贵专家标注的依赖，同时引导模型识别和纠正推理错误。在MedQA-USMLE基准测试中，Med-REFL实现了稳定的改进，平均提升达4.11%。值得注意的是，它进一步将7B/8B模型的先进性能提升了4.13%。此外，Med-REFL在多个挑战性医疗问答数据集上表现出强大的泛化能力和鲁棒性。我们的工作表明，优先考虑反思质量能够为医疗AI应用带来更准确和可信的推理。检查点、代码和数据可在此处找到。

</details>


### [141] [BotTrans: A Multi-Source Graph Domain Adaptation Approach for Social Bot Detection](https://arxiv.org/abs/2506.13795)
**中文标题：BotTrans：一种多源图域适应方法用于社交机器人检测**

*Boshen Shi,Yongqing Wang,Fangda Guo,Jiangli Shao,Huawei Shen,Xueqi Cheng*

主要分类: cs.AI

摘要简述: 本文提出了一种名为BotTrans的多源图域适应方法，用于解决社交机器人检测中的标签稀缺问题。通过利用多源网络的知识共享和跨域邻居信息聚合，BotTrans显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 社交机器人检测中，标签稀缺是一个主要问题。现有的单源迁移方法因网络异质性和源网络相关性不足，导致检测效果不稳定。因此，需要一种多源迁移方法来解决这些问题。

研究方法: BotTrans通过多源网络构建跨源域拓扑结构，提高网络同质性；聚合跨域邻居信息以增强节点嵌入的区分性；结合源-目标对的相关性优化模型，并利用目标域语义知识进行细化。

研究结果: 在真实数据集上的实验表明，BotTrans优于现有方法，能够有效利用多源知识提升无标签目标任务的检测性能。

研究结论: BotTrans通过多源知识迁移和跨域信息聚合，显著提升了社交机器人检测的效果，为无标签任务提供了有效的解决方案。

中文摘要: 从相关社交网络中迁移丰富知识已成为解决基于GNN的社交机器人及其他异常检测中标签稀缺问题的有效方法。然而，有效迁移面临两大挑战：一是网络异质性问题，即机器人通过无差别与人类用户互动隐藏恶意行为，阻碍了模型从源域学习足够准确的机器人相关知识；二是单源迁移可能导致效果不佳且不稳定，因源网络可能与任务相关性较弱且提供有限知识。为解决这些问题，我们探索多源域并提出多源图域适应模型BotTrans。我们首先利用多源网络共享的标签知识构建跨源域拓扑结构以提高网络同质性；随后聚合跨域邻居信息以增强源节点嵌入的区分性；接着将各源-目标对的相关性与模型优化结合，促进从与检测任务更相关的源网络迁移知识；此外，我们提出一种细化策略，利用目标域语义知识提升检测性能。在真实数据集上的大量实验表明，BotTrans优于现有最优方法，展现了其在无标签目标任务中利用多源知识的有效性。

</details>


### [142] [Feedforward Ordering in Neural Connectomes via Feedback Arc Minimization](https://arxiv.org/abs/2506.13799)
**中文标题：通过反馈弧最小化实现神经连接组中的顺向排序**

*Soroush Vahidi*

主要分类: cs.AI

摘要简述: 本文提出了一套可扩展的算法，用于最小化大规模加权有向图中的反馈弧，旨在揭示神经连接组中具有生物学意义的顺向结构。通过FlyWire连接组挑战数据集验证，算法在最大化前向边权重方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过最小化反馈弧，揭示神经连接组中的顺向结构，为理解神经网络的生物学功能提供新视角。

研究方法: 结合贪心启发式、增益感知的局部优化和基于强连通分量的全局结构分析，提出了一套高效的算法。

研究结果: 实验表明，所提出的最佳方案在前向边权重上优于以往表现最优的方法。

研究结论: 算法在Python中高效实现，并通过Google Colab Pro+的云端执行验证，为神经连接组分析提供了有力工具。

中文摘要: 我们提出了一套可扩展的算法，用于最小化大规模加权有向图中的反馈弧，旨在揭示神经连接组中具有生物学意义的顺向结构。利用FlyWire连接组挑战数据集，我们验证了排名策略在最大化前向边权重方面的有效性。我们的方法整合了贪心启发式、增益感知的局部优化和基于强连通分量的全局结构分析。实验表明，我们的最佳方案在前向边权重上优于以往表现最优的方法。所有算法均在Python中高效实现，并通过Google Colab Pro+的云端执行验证。

</details>


### [143] [Causality in the human niche: lessons for machine learning](https://arxiv.org/abs/2506.13803)
**中文标题：人类生态中的因果关系：对机器学习的启示**

*Richard D. Lange,Konrad P. Kording*

主要分类: cs.AI

摘要简述: 本文探讨了人类因果认知与机器学习的关系，指出当前的结构因果模型（SCM）框架未能完全捕捉人类因果思维的适应性特点，并呼吁在机器学习中融入更多人类因果认知的归纳偏置。


<details>
  <summary>详细信息</summary>
研究动机: 人类通过因果思维高效学习和泛化，而当前机器学习系统在这方面表现较弱。SCM框架虽在形式化因果关系上取得进展，但未能完全适应人类因果认知的需求，尤其是在社会性、自主性和目标驱动的环境中。

研究方法: 通过分析人类因果认知的特点及其在人类生活环境中的适应性，探讨了SCM框架的局限性，并提出了未来机器学习应借鉴人类因果思维的归纳偏置。

研究结果: 研究发现，人类因果认知在泛化和类比推理方面具有优势，而SCM框架难以表达这些特点。未来研究应更关注人类因果认知的适应性机制。

研究结论: 未来机器学习与因果研究的交叉领域应更注重人类因果认知的适应性特点，以开发更具能力、可控性和可解释性的系统。

中文摘要: 人类通过因果关系解释世界，并以因果术语交流对世界的理解。这种因果认知被认为是人类在新领域高效学习和泛化的基础，而当前机器学习系统在这方面表现较弱。将人类因果能力融入机器学习可能有助于构建更有效和可解释的人工智能。机器学习社区已引入结构因果模型（SCM）框架的形式化因果思想，该框架为许多因果关系提供了严格的数学语言，并取得了显著进展。然而，SCM框架未能捕捉人类因果认知的某些显著特点，也未在人类擅长的关键领域推动机器学习进步。我们认为，"人类生态"中的因果关系——即社会性、自主性和目标驱动的智能体在人类生活环境中的感知与行为——与SCM所描述的因果关系截然不同。例如，日常物体具有相似的类型和因果属性，人类能通过因果类比将知识从一种物体（如杯子）泛化到另一种相关物体（如碗），但这种类比在SCM中难以表达。我们探讨了这些因果能力如何适应并受人类生态驱动。通过更好地理解人类因果认知的特点及其在人类生态中的适应性，我们希望未来机器学习与因果研究的交叉工作能利用更接近人类的归纳偏置，开发出更具能力、可控性和可解释性的系统。

</details>


### [144] [Bridging Pattern-Aware Complexity with NP-Hard Optimization: A Unifying Framework and Empirical Study](https://arxiv.org/abs/2506.13810)
**中文标题：桥接模式感知复杂性与NP难优化：统一框架与实证研究**

*Olivier Saidi*

主要分类: cs.AI

摘要简述: 本文提出了一种基于模式感知的复杂性框架，利用结构规律（如聚类、对称性）降低NP难优化问题的计算复杂度，并在TSP等实际问题中实现了高达79%的解决方案质量提升。


<details>
  <summary>详细信息</summary>
研究动机: 尽管NP难优化问题（如旅行商问题）在最坏情况下难以高效解决，但实际应用中常存在可被利用的结构规律。本文旨在通过量化这些模式，提出一种统一的框架以降低计算复杂度。

研究方法: 提出了一种模式感知复杂性框架，包括严格的数学定义、定理和基于元学习的求解流程，并引入了模式利用效率（PUE）等指标。

研究结果: 在TSP基准测试中（22至2392个城市），实现了高达79%的解决方案质量提升。

研究结论: 本文提出的框架为模式驱动的效率提升提供了统一且实用的视角，区别于传统的NP难理论。

中文摘要: NP难优化问题（如旅行商问题）在最坏情况下难以高效解决，但实际实例常表现出可利用的模式。我们提出了一种新颖的模式感知复杂性框架，通过量化并利用结构规律（如聚类、对称性）来降低跨领域的有效计算复杂度，包括金融预测和LLM优化。通过严格的定义、定理和基于元学习的求解流程，我们引入了模式利用效率（PUE）等指标，并在TSP基准测试（22至2392个城市）中实现了高达79%的解决方案质量提升。与理论上的NP难性不同，我们的方法为模式驱动的效率提升提供了统一且实用的视角。

</details>


### [145] [The Reflexive Integrated Information Unit: A Differentiable Primitive for Artificial Consciousness](https://arxiv.org/abs/2506.13825)
**中文标题：反射性整合信息单元：一种用于人工意识的可微分基础模块**

*Gnankan Landry Regis N'guessan,Issa Karambal*

主要分类: cs.AI

摘要简述: 本文提出了一种称为“反射性整合信息单元”（RIIU）的可训练模块，作为人工意识研究中的基础组件。RIIU通过引入元状态和广播缓冲区，实现了局部信息整合的最大化，并在实验中表现出优于传统GRU的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前人工意识研究缺乏类似感知机的基础模块，无法进行复制、基准测试和迭代改进。本文旨在填补这一空白，提出一种可微分的、可扩展的基础单元，将哲学问题转化为可实证的数学问题。

研究方法: RIIU是一种循环单元，通过扩展隐藏状态，引入元状态（记录单元的因果足迹）和广播缓冲区（向网络其他部分暴露足迹）。通过滑动窗口协方差和可微分的Auto-$Φ$替代，实现局部信息整合的最大化。RIIU具有端到端可微性、可加性组合性，并在梯度上升下表现出$Φ$-单调塑性。

研究结果: 在八方向网格世界中，四层RIIU智能体在13步内恢复了超过90%的奖励，速度是参数匹配GRU的两倍，同时保持非零的Auto-$Φ$信号。

研究结论: RIIU将“类意识”计算缩小到单元尺度，为人工意识研究提供了可实证的基础模块，推动了哲学问题向数学问题的转化。

中文摘要: 人工意识研究缺乏类似感知机的小型可训练模块，无法进行复制、基准测试和迭代改进。我们提出了反射性整合信息单元（RIIU），这是一种循环单元，通过扩展隐藏状态$h$，引入两个额外向量：（i）元状态$μ$，记录单元自身的因果足迹；（ii）广播缓冲区$B$，将该足迹暴露给网络的其他部分。通过滑动窗口协方差和可微分的Auto-$Φ$替代，每个RIIU可以在线最大化局部信息整合。我们证明了RIIU（1）具有端到端可微性，（2）可加性组合，（3）在梯度上升下表现出$Φ$-单调塑性。在八方向网格世界中，四层RIIU智能体在13步内恢复了超过90%的奖励，速度是参数匹配GRU的两倍，同时保持非零的Auto-$Φ$信号。通过将“类意识”计算缩小到单元尺度，RIIU将哲学辩论转化为实证数学问题。

</details>


### [146] [LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning](https://arxiv.org/abs/2506.13841)
**中文标题：LocationReasoner：评估大语言模型在真实世界选址推理中的表现**

*Miho Koda,Yu Zheng,Ruixian Ma,Mingyang Sun,Devesh Pansare,Fabio Duarte,Paolo Santi*

主要分类: cs.AI

摘要简述: 本文介绍了LocationReasoner基准，用于评估大语言模型（LLMs）在真实世界选址任务中的推理能力。结果显示，即使最先进的推理模型（如OpenAI o4）在30%的任务中失败，且代理策略（如ReAct和Reflexion）因过度推理表现更差。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型（LLMs）的推理能力主要在数学和代码生成领域得到验证，但其在复杂真实场景（如选址）中的表现尚不明确。本文旨在填补这一空白，评估LLMs在真实世界选址任务中的推理能力。

研究方法: 提出了LocationReasoner基准，包含300多个不同难度的查询，并提供一个沙盒环境支持约束条件搜索。通过评估最先进的推理模型（如OpenAI o4）和代理策略（如ReAct和Reflexion）的表现。

研究结果: 结果显示，即使最先进的推理模型在真实世界选址任务中表现有限，OpenAI o4在30%的任务中失败。代理策略因过度推理导致表现更差。

研究结论: LLMs在整体和非线性推理方面存在局限性。LocationReasoner基准的发布旨在推动LLMs和代理在真实世界决策任务中的稳健推理能力发展。

中文摘要: 近年来，通过强化后训练增强的大语言模型（LLMs）（如OpenAI o1和DeepSeek-R1）展现了令人印象深刻的推理能力。然而，这些能力主要在数学问题解决和代码生成等领域得到验证，其在复杂真实场景中的泛化能力尚不明确。本文提出LocationReasoner基准，用于评估LLMs在真实世界选址任务中的推理能力，模型需通过复杂的空间、环境和物流约束推理确定可行位置。该基准包含300多个精心设计的查询，并提供一个支持约束条件搜索的沙盒环境。广泛评估表明，最先进的推理模型在真实场景中表现有限，OpenAI o4模型在30%的选址任务中失败。此外，代理策略（如ReAct和Reflexion）因过度推理表现更差。本文揭示了LLMs在整体和非线性推理方面的关键局限，并发布LocationReasoner基准以推动LLMs和代理在真实世界决策任务中的稳健推理能力发展。代码和数据详见https://github.com/miho-koda/LocationReasoner。

</details>


### [147] [Evaluating Explainability: A Framework for Systematic Assessment and Reporting of Explainable AI Features](https://arxiv.org/abs/2506.13917)
**中文标题：评估可解释性：一种系统性评估和报告可解释AI特征的框架**

*Miguel A. Lago,Ghada Zamzmi,Brandon Eich,Jana G. Delfino*

主要分类: cs.AI

摘要简述: 本文提出了一种评估可解释AI特征的框架，基于一致性、合理性、忠实性和实用性四项标准，并通过案例研究验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏评估AI模型提供的解释质量的系统方法，因此需要建立一个框架来评估和报告可解释AI特征。

研究方法: 提出了一个基于四项标准的评估框架：1) 一致性量化相似输入下解释的变异性；2) 合理性估计解释与真实情况的接近程度；3) 忠实性评估解释与模型内部机制的匹配度；4) 实用性衡量解释对任务性能的影响。

研究结果: 开发了一个可解释AI方法的评分卡，并通过Ablation CAM和Eigen CAM在合成乳腺X光片上的案例研究验证了框架的有效性。

研究结论: 该框架为评估AI模型提供的解释质量提供了标准，旨在促进关于可解释性价值的讨论，并帮助改进基于AI的医疗设备的开发和评估。

中文摘要: 可解释性特征旨在揭示AI设备的内部机制，但目前缺乏评估解释质量的技术。我们提出了一个评估和报告可解释AI特征的框架。该框架基于四项标准：1) 一致性量化相似输入下解释的变异性；2) 合理性估计解释与真实情况的接近程度；3) 忠实性评估解释与模型内部机制的匹配度；4) 实用性衡量解释对任务性能的影响。我们还开发了一个可解释AI方法的评分卡，作为此类算法的完整描述和评估工具。我们描述了这四项标准，并提供了评估示例。通过案例研究，我们使用Ablation CAM和Eigen CAM在合成乳腺X光片上评估了解释热图。前三项标准在临床相关场景中进行了评估。我们提出的框架为评估AI模型提供的解释质量建立了标准，旨在促进关于可解释性价值的讨论，并帮助改进基于AI的医疗设备的开发和评估。

</details>


### [148] [Integrating Knowledge Graphs and Bayesian Networks: A Hybrid Approach for Explainable Disease Risk Prediction](https://arxiv.org/abs/2506.13920)
**中文标题：知识图谱与贝叶斯网络的融合：一种可解释疾病风险预测的混合方法**

*Mbithe Nzomo,Deshendran Moodley*

主要分类: cs.AI

摘要简述: 提出一种结合知识图谱和贝叶斯网络的新方法，用于可解释的疾病风险预测，通过实际病例验证其有效性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 多模态电子健康记录（EHR）数据可用于疾病风险预测，但需将通用医学知识适配到具体医疗场景和患者群体中，同时需处理数据不确定性和非确定性健康结果，并保持预测系统的可解释性。

研究方法: 通过基于知识图谱的贝叶斯网络构建方法，结合多模态EHR数据，实现疾病风险预测。以心房颤动为例，验证方法的有效性。

研究结果: 该方法在平衡通用医学知识与患者特定情境、处理不确定性、提供高可解释性方面表现优异，同时预测性能良好。

研究结论: 结合知识图谱和贝叶斯网络的方法为可解释的疾病风险预测提供了有效解决方案，具有实际临床应用潜力。

中文摘要: 多模态电子健康记录（EHR）数据可用于基于医学领域知识的疾病风险预测。然而，通用医学知识需适配具体医疗场景和患者群体以实现临床实用。此外，风险预测系统需处理数据不完整性和非确定性健康结果的不确定性，同时保持可解释性。通过结合知识图谱（KGs）和贝叶斯网络（BNs），可缓解这些挑战。我们提出了一种从基于本体的知识图谱和多模态EHR数据构建贝叶斯网络的新方法，用于可解释的疾病风险预测。通过心房颤动的实际应用案例和真实世界EHR数据，我们证明该方法在平衡通用医学知识与患者特定情境、有效处理不确定性、高度可解释性及良好预测性能方面表现优异。

</details>


### [149] [ProfiLLM: An LLM-Based Framework for Implicit Profiling of Chatbot Users](https://arxiv.org/abs/2506.13980)
**中文标题：ProfiLLM：一种基于LLM的聊天机器人用户隐式分析框架**

*Shahaf David,Yair Meidan,Ido Hersko,Daniel Varnovitzky,Dudu Mimran,Yuval Elovici,Asaf Shabtai*

主要分类: cs.AI

摘要简述: 本文提出了一种名为ProfiLLM的新型框架，用于通过聊天机器人交互隐式和动态地分析用户特征。该框架包括一个可适应多领域的分类法和基于LLM的用户分析方法。在IT/网络安全领域的实验中，ProfiLLM能够快速准确地推断用户技术熟练度，显著缩小预测与实际评分的差距。


<details>
  <summary>详细信息</summary>
研究动机: 尽管对话AI取得了显著进展，但基于大型语言模型（LLM）的聊天机器人仍难以根据用户个体特征（如技术专长、学习风格和沟通偏好）个性化其响应。这种个性化不足在IT/网络安全等知识密集型领域尤为突出，因为用户知识水平差异较大。现有方法主要依赖静态用户分类或显式自我报告信息，限制了其对用户能力动态变化的适应性。

研究方法: 本文提出了ProfiLLM框架，包括一个可适应多领域的分类法和基于LLM的用户分析方法。通过在IT/网络安全领域的应用，开发了ProfiLLM[ITSec]变体，并利用1,760条模拟聊天机器人对话数据（来自263个合成用户）进行验证。

研究结果: 实验结果表明，ProfiLLM[ITSec]能够快速准确地推断用户技术熟练度，仅需一次提示即可将预测与实际评分的差距缩小55-65%，后续波动较小且进一步优化。

研究结论: ProfiLLM是一种有效的隐式和动态用户分析框架，能够显著提升聊天机器人的个性化能力。此外，本文还提出了基于LLM的角色模拟方法、ITSec熟练度分类法、代码库和聊天机器人交互数据集，为未来研究提供了支持。

中文摘要: 尽管对话AI取得了显著进展，但基于大型语言模型（LLM）的聊天机器人仍难以根据用户个体特征（如技术专长、学习风格和沟通偏好）个性化其响应。这种个性化不足在IT/网络安全（ITSec）等知识密集型领域尤为突出，因为用户知识水平差异较大。现有方法主要依赖静态用户分类或显式自我报告信息，限制了其对用户能力动态变化的适应性。本文提出ProfiLLM，一种通过聊天机器人交互隐式和动态分析用户特征的新框架。该框架包括一个可适应多领域的分类法和基于LLM的用户分析方法。为验证ProfiLLM的有效性，我们在ITSec领域应用该框架，利用故障排除交互推断用户技术熟练度。具体而言，我们开发了ProfiLLM[ITSec]，一种适应ITSec的变体，并在263个合成用户的1,760条模拟聊天机器人对话数据上评估其性能。结果表明，ProfiLLM[ITSec]能够快速准确地推断ITSec用户特征，仅需一次提示即可将预测与实际评分的差距缩小55-65%，后续波动较小且进一步优化。除评估新框架外，本文还提出了基于LLM的角色模拟方法、ITSec熟练度分类法、代码库和聊天机器人交互数据集，以支持未来研究。

</details>


### [150] [SANGAM: SystemVerilog Assertion Generation via Monte Carlo Tree Self-Refine](https://arxiv.org/abs/2506.13983)
**中文标题：SANGAM：基于蒙特卡洛树自优化的SystemVerilog断言生成**

*Adarsh Gupta,Bhabesh Mali,Chandan Karfa*

主要分类: cs.AI

摘要简述: 本文提出SANGAM框架，利用LLM引导的蒙特卡洛树搜索自动生成SystemVerilog断言，通过三阶段方法处理规范并生成稳健的断言集，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，大型语言模型（LLM）在推理领域的进展为更复杂和自动化的硬件断言生成技术提供了新可能。本文旨在利用LLM和蒙特卡洛树搜索技术，自动从工业级规范中生成SystemVerilog断言（SVAs），以提升断言生成的效率和准确性。

研究方法: SANGAM框架采用三阶段方法：1）多模态规范处理，使用信号映射器、规范分析器和波形分析器LLM代理；2）蒙特卡洛树自优化（MCTSr）算法对每个信号进行自动推理；3）结合MCTSr生成的推理轨迹为每个信号生成SVA断言。

研究结果: 实验结果表明，SANGAM能够生成一组稳健的SVAs，在评估过程中表现优于现有方法。

研究结论: SANGAM框架通过结合LLM和蒙特卡洛树搜索技术，成功实现了从工业级规范中自动生成SystemVerilog断言，为硬件验证提供了高效且准确的解决方案。

中文摘要: 近年来，大型语言模型（LLM）在推理领域的进展为更复杂和自动化的硬件断言生成技术提供了新的可能性。本文介绍了SANGAM，一种利用LLM引导的蒙特卡洛树搜索从工业级规范中自动生成SystemVerilog断言（SVAs）的框架。该框架采用三阶段方法：第一阶段通过信号映射器、规范分析器和波形分析器LLM代理进行多模态规范处理；第二阶段使用蒙特卡洛树自优化（MCTSr）算法对每个信号进行自动推理；最后，第三阶段结合MCTSr生成的推理轨迹为每个信号生成SVA断言。实验结果表明，SANGAM能够生成一组稳健的SVAs，在评估过程中表现优于现有方法。

</details>


### [151] [Machine Mirages: Defining the Undefined](https://arxiv.org/abs/2506.13990)
**中文标题：机器幻象：定义未定义之物**

*Hamidou Tembine*

主要分类: cs.AI

摘要简述: 本文探讨了多模态机器智能系统中出现的新型认知偏差——机器幻象，并强调需明确定义和系统评估这些错误，以提高机器智能的可靠性并构建伦理共生的智能生态系统。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态机器智能系统在图像、语言和声音处理任务中达到动物或人类水平，它们开始表现出新的认知偏差（机器幻象）。这些偏差不仅影响系统可靠性，还可能对伦理和社会产生深远影响，因此需要深入研究。

研究方法: 文章列举了机器幻象的多种表现形式（如幻觉、语义漂移、过度拟合等），并主张通过明确定义和系统评估这些错误来理解其本质。

研究结果: 研究发现机器幻象是一类独特的认知偏差，与人类或动物的错误不同，需专门分类和评估。

研究结论: 理解机器幻象对提升机器智能可靠性至关重要，同时也有助于构建一个尊重生命和认知多样性的伦理智能生态系统。

中文摘要: 随着多模态机器智能系统在处理图像、语言和声音等任务中达到动物或人类水平的流畅性，它们开始表现出一种新的认知偏差类别：机器幻象。这些幻象包括妄想、幻觉、虚构、语义漂移、语义压缩、夸张、因果推理失败、感知的恐怖谷效应、虚张声势、认知刻板、语用误解、超符号化、语义复热、模拟权威效应、谬误溯因跳跃、上下文漂移、指称幻觉、符号弗兰肯斯坦效应、校准失败、伪相关、偏见放大、概念漂移敏感性、不确定性下的误分类、对抗脆弱性、过度拟合、韵律误分类、口音偏见、轮次边界失败、语义边界混淆、噪声过度拟合、延迟诱导的决策漂移、模糊性崩溃以及其他模仿但不复制人类或动物错误的错误形式。本文列举了部分错误，并认为必须明确定义和系统评估这些失败。理解机器幻象不仅对提高机器智能的可靠性至关重要，还有助于构建一个尊重其必然触及的生命、认知和表达多样性的多尺度伦理共生的智能生态系统。

</details>


### [152] [Discovering Temporal Structure: An Overview of Hierarchical Reinforcement Learning](https://arxiv.org/abs/2506.14045)
**中文标题：发现时间结构：分层强化学习综述**

*Martin Klissarov,Akhil Bagaria,Ziyan Luo,George Konidaris,Doina Precup,Marlos C. Machado*

主要分类: cs.AI

摘要简述: 本文综述了分层强化学习（HRL）在发现和利用时间结构方面的作用，探讨了其优势、方法家族及适用领域，并指出了相关挑战。


<details>
  <summary>详细信息</summary>
研究动机: 开发能够在复杂开放环境中探索、规划和学习的智能体是人工智能（AI）的重大挑战。分层强化学习（HRL）通过发现和利用经验流中的时间结构，为解决这一挑战提供了有前景的方案。然而，目前尚不清楚如何定义“良好结构”或哪些问题适合识别这种结构。本文旨在从决策基本挑战的角度识别HRL的优势，并强调其对AI智能体性能权衡的影响。

研究方法: 本文从HRL的基本挑战出发，探讨了发现时间结构的方法家族，包括从在线经验学习、离线数据集学习，以及利用大型语言模型（LLMs）等方法。

研究结果: 通过分析HRL的优势和方法，本文总结了其在性能提升和适用领域方面的潜力，同时指出了时间结构发现中的挑战。

研究结论: HRL在发现时间结构方面具有显著潜力，但其定义和适用性仍需进一步研究。未来工作应关注相关挑战及适合HRL的领域。

中文摘要: 开发能够在复杂开放环境中探索、规划和学习的智能体是人工智能（AI）的重大挑战。分层强化学习（HRL）通过发现和利用经验流中的时间结构，为解决这一挑战提供了有前景的方案。HRL框架的强烈吸引力催生了丰富多样的文献，试图发现有用的结构。然而，目前尚不清楚如何定义“良好结构”，或者哪些问题适合识别这种结构。本文旨在从决策基本挑战的角度识别HRL的优势，并强调其对AI智能体性能权衡的影响。通过这些优势，我们进一步涵盖了发现HRL中时间结构的方法家族，包括从在线经验学习、离线数据集学习，以及利用大型语言模型（LLMs）等方法。最后，我们强调了时间结构发现的挑战及特别适合此类努力的领域。

</details>


### [153] [Into the Unknown: Applying Inductive Spatial-Semantic Location Embeddings for Predicting Individuals' Mobility Beyond Visited Places](https://arxiv.org/abs/2506.14070)
**中文标题：探索未知：应用归纳性空间语义位置嵌入预测个体未访问地点的移动性**

*Xinglei Wang,Tao Cheng,Stephen Law,Zichao Zeng,Ilya Ilyankou,Junyuan Liu,Lu Yin,Weiming Huang,Natchapon Jongwiriyanurak*

主要分类: cs.AI

摘要简述: 本文提出了一种名为CaLLiPer的多模态表示学习框架，通过融合空间坐标和语义特征生成位置嵌入，用于预测个体移动性，尤其在未知地点场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统的人类移动性预测方法依赖于历史移动模式的位置嵌入，难以编码显式空间信息、整合丰富的城市语义上下文或适应未知地点。本文旨在解决这些限制，探索更强大的预测方法。

研究方法: CaLLiPer框架通过对比学习融合空间坐标和兴趣点的语义特征，生成空间显式、语义丰富且具有归纳能力的位置嵌入，从而支持个体移动性预测。

研究结果: 在四个公共移动性数据集上的实验表明，CaLLiPer在常规和归纳场景中均优于基线方法，尤其在未知地点预测中表现突出。

研究结论: 多模态归纳位置嵌入能够显著提升人类移动性预测系统的能力，为未来研究提供了新方向。

中文摘要: 预测个体的下一个位置是人类移动性建模的核心任务，对城市规划、交通、公共政策和个性化移动服务具有广泛影响。传统方法主要依赖于从历史移动模式学习的位置嵌入，限制了其编码显式空间信息、整合丰富城市语义上下文以及适应未知地点的能力。为解决这些问题，我们探索了CaLLiPer——一种通过对比学习融合空间坐标和兴趣点语义特征的多模态表示学习框架——在个体移动性预测中的应用。CaLLiPer的嵌入设计具有空间显式性、语义丰富性和归纳性，即使在涉及新兴地点的场景中也能实现稳健的预测性能。通过在四个公共移动性数据集上的广泛实验，我们证明了CaLLiPer在常规和归纳场景中均优于强基线方法，尤其在归纳场景中表现卓越。我们的发现凸显了多模态归纳位置嵌入在提升人类移动性预测系统能力方面的潜力。我们还发布了代码和数据（https://github.com/xlwang233/Into-the-Unknown）以促进可重复性和未来研究。

</details>


### [154] [FormGym: Doing Paperwork with Agents](https://arxiv.org/abs/2506.14079)
**中文标题：FormGym：用代理处理文书工作**

*Matthew Toles,Rattandeep Singh,Isaac Song Zhou Yu*

主要分类: cs.AI

摘要简述: 本文提出了一个名为FormGym的新型表单填写基准测试，包含55份文档中的432个字段和3项任务，测试计算机代理的多模态理解、信息检索和工具使用能力。研究发现基线视觉语言代理（VLA）准确率低于1%，而GUI代理表现稍好但成本高。为此，作者开发了FieldFinder工具，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 填写表单是一项耗时且具有挑战性的任务，尤其是在纯图像领域无法使用OCR或PDF文本的情况下。计算机代理需要具备多模态理解、信息检索和工具使用等能力。本文旨在解决这一问题，并评估现有代理的表现。

研究方法: 作者设计了一个包含55份文档、432个字段和3项任务的表单填写基准测试，要求代理掌握236个用户特征。此外，开发了FieldFinder工具，帮助大语言模型（LLM）定位表单中的文本位置。

研究结果: 基线视觉语言代理（VLA）准确率低于1%，GUI代理表现稍好（10.6-68.0%），但成本高且延迟大。使用FieldFinder后，所有模型在所有六种测试条件下表现均有所提升，最高从2%提升至56%。

研究结论: FormGym基准测试揭示了现有代理在表单填写任务中的局限性，尤其是定位能力不足。FieldFinder工具的引入显著提升了性能，为未来研究提供了重要参考。

中文摘要: 填写表单是一项耗时且具有挑战性的任务，尤其是在纯图像领域无法使用OCR、PDF文本或DOM的情况下。计算机代理需要具备多模态理解、信息检索和工具使用等能力。本文提出了一个新型表单填写基准测试，包含55份文档中的432个字段和3项任务，要求代理掌握236个用户特征。研究发现基线视觉语言代理（VLA）准确率低于1%，主要由于定位能力不足。GUI代理表现稍好（10.6-68.0%），但成本高且延迟大。为此，作者开发了FieldFinder工具，帮助大语言模型（LLM）定位表单中的文本位置。使用FieldFinder后，所有模型在所有六种测试条件下表现均有所提升，最高从2%提升至56%。

</details>


### [155] [Lightweight Relevance Grader in RAG](https://arxiv.org/abs/2506.14084)
**中文标题：RAG中的轻量级相关性评分器**

*Taehee Jeong*

主要分类: cs.AI

摘要简述: 本文提出了一种轻量级相关性评分器，用于提升RAG系统中检索文档的相关性，显著提高了精度。


<details>
  <summary>详细信息</summary>
研究动机: RAG系统通过向量数据库增强大语言模型的信息准确性，但检索文档的相关性验证是一个挑战。为解决这一问题，需要一种轻量化的相关性评分器以减少计算资源消耗。

研究方法: 作者微调了轻量级语言模型llama-3.2-1b作为相关性评分器，用于验证检索文档与查询的相关性。

研究结果: 实验结果显示，该评分器的精度从0.1301提升至0.7750，与大型模型llama-3.1-70b的精度相当。

研究结论: 轻量级相关性评分器在RAG系统中表现优异，既能保证精度，又降低了计算成本。

中文摘要: 检索增强生成（RAG）通过利用向量数据库弥补了大语言模型（LLM）的局限性，提供更准确和最新的信息。当用户提交查询时，RAG执行向量搜索以找到相关文档，并用于生成响应。然而，确保检索文档与查询的相关性是一个重大挑战。为此，可以引入一个称为相关性评分器的辅助模型来验证其相关性。为了减少相关性评分器的计算需求，轻量级的小型语言模型更为合适。本研究中，我们微调了llama-3.2-1b作为相关性评分器，并将其精度从0.1301显著提升至0.7750，其精度与llama-3.1-70b相当。代码可在https://github.com/taeheej/Lightweight-Relevance-Grader-in-RAG获取。

</details>


### [156] [Fragile Preferences: A Deep Dive Into Order Effects in Large Language Models](https://arxiv.org/abs/2506.14092)
**中文标题：脆弱偏好：深入探究大语言模型中的顺序效应**

*Haonan Yin,Shai Vardi,Vidyanand Choudhary*

主要分类: cs.AI

摘要简述: 本文首次全面研究了大语言模型（LLM）在决策支持系统中的位置顺序偏见，揭示了包括新颖的中心性偏见在内的多种偏见模式，并提出了针对性的缓解策略。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在招聘、大学录取等高风险领域被广泛用于决策支持，但此前对其位置顺序偏见的研究不够系统，也未深入分析其与偏好结构的关系。本文旨在填补这一空白。

研究方法: 研究通过分析多种LLM架构和领域的位置偏见，发现顺序效应并提出分类框架（稳健、脆弱或中立偏好），同时测试了温度参数作为缓解策略。

研究结果: 研究发现LLM存在强烈的顺序效应，包括中心性偏见和质量依赖性偏移（高质量选项时偏向首位，低质量时偏向末位）。顺序偏见甚至强于性别偏见，可能导致选择明显劣质选项。

研究结论: LLM的偏见模式与人类不同，表现出独特的决策失败模式。研究提出的温度参数调整等方法可有效减少顺序驱动的决策扭曲。

中文摘要: 大语言模型（LLM）越来越多地用于高风险领域（如招聘和大学录取）的决策支持系统，这些决策通常涉及在竞争选项中选择。虽然已有研究注意到LLM驱动的比较中存在位置顺序偏见，但这些偏见尚未被系统剖析或与底层偏好结构关联。我们首次对多种LLM架构和领域的位置偏见进行了全面研究，揭示了强烈且一致的顺序效应，包括一种在人类或机器决策中未被记录的新颖中心性偏见。我们还发现质量依赖性偏移：当选项质量高时，模型表现出首位偏见，而在选项质量低时偏向后者。此外，我们识别出了一种此前未记录的偏见，即某些名称比其他名称更受青睐。为了区分表面的平局打破与真实的判断扭曲，我们引入了一个框架，将成对偏好分类为稳健、脆弱或中立。研究表明，顺序效应可能导致模型选择明显劣质的选项，且位置偏见通常强于性别偏见。这些发现表明，LLM并非仅仅继承了人类类似的偏见，而是表现出人类决策中未见的独特失败模式。我们提出了针对性的缓解策略，包括温度参数的新颖使用，以减少顺序驱动的扭曲。

</details>


### [157] [Situational-Constrained Sequential Resources Allocation via Reinforcement Learning](https://arxiv.org/abs/2506.14125)
**中文标题：基于强化学习的情境约束序列资源分配**

*Libo Zhang,Yang Chen,Toru Takisaka,Kaiqi Zhao,Weidong Li,Jiamou Liu*

主要分类: cs.AI

摘要简述: 本文提出了一种名为SCRL的新框架，用于解决情境约束下的序列资源分配问题。通过将情境约束形式化为逻辑关系并动态惩罚约束违反，SCRL在医疗和农业资源分配场景中表现优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的资源分配问题通常受情境约束影响，而传统约束强化学习方法难以有效处理这些动态变化的约束。本文旨在开发一种能够适应情境约束并高效分配资源的框架。

研究方法: SCRL框架将情境约束形式化为逻辑关系，并提出一种动态惩罚约束违反的算法。此外，引入概率选择机制以克服传统约束强化学习方法的局限性。

研究结果: 在医疗资源分配和农药分配两个场景中，SCRL在满足约束的同时保持了较高的资源分配效率，显著优于现有基线方法。

研究结论: SCRL展示了其在现实世界情境敏感决策任务中的潜力，能够有效处理动态约束并优化资源分配。

中文摘要: 情境约束下的序列资源分配在现实应用中是一个重大挑战，资源需求和优先级通常依赖于具体情境。本文提出了一种名为SCRL的新框架来解决这一问题。我们将情境约束形式化为逻辑关系，并开发了一种动态惩罚约束违反的新算法。为了有效处理情境约束，提出了一种概率选择机制，以克服传统约束强化学习（CRL）方法的局限性。我们在两个场景中评估了SCRL：疫情期间的医疗资源分配和农业中的农药分配。实验表明，SCRL在满足约束的同时保持了较高的资源效率，优于现有基线方法，展示了其在现实世界情境敏感决策任务中的潜力。

</details>


### [158] [Collaborative Editable Model](https://arxiv.org/abs/2506.14146)
**中文标题：协作可编辑模型**

*Kaiwen Tang,Aitong Wu,Yao Lu,Guangda Sun*

主要分类: cs.AI

摘要简述: 本文提出了一种协作可编辑模型（CoEM），通过用户贡献的领域片段构建知识池，结合用户评分和归因分析筛选高价值知识，实现轻量级领域适应，显著提升垂直领域大语言模型的生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 垂直领域大语言模型（如金融、医疗、法律）的训练依赖大规模标注数据和计算资源，阻碍了快速开发和迭代。为解决这一问题，本文提出了一种协作可编辑模型（CoEM）。

研究方法: CoEM通过用户贡献的领域片段构建候选知识池，结合用户-模型交互对话、用户评分和归因分析，筛选高价值知识片段，并通过上下文提示注入模型，实现轻量级领域适应。

研究结果: 在金融信息场景中，收集了约120名用户的1.5万条反馈，验证了CoEM在提升领域特定生成质量方面的显著效果，同时避免了传统微调的高成本。

研究结论: CoEM通过协作编辑和轻量级适应，有效解决了垂直领域大语言模型的高成本问题，显著提升了生成内容的准确性和领域针对性。

中文摘要: 垂直领域大语言模型（LLMs）在金融、医疗和法律等专业场景中扮演重要角色，但其训练通常依赖大规模标注数据和大量计算资源，阻碍了快速开发和持续迭代。为解决这些问题，我们提出了协作可编辑模型（CoEM），通过用户贡献的领域片段构建候选知识池，结合用户-模型交互对话、用户评分和归因分析筛选高价值知识片段，并通过上下文提示注入模型，实现轻量级领域适应。借助高价值知识，大语言模型能够生成更准确且领域相关的内容。在金融信息场景中，我们收集了约120名用户的1.5万条反馈，并通过用户评分验证了CoEM在提升领域特定生成质量方面的显著效果，同时避免了传统微调工作流的时间和计算开销。

</details>


### [159] [What's in the Box? Reasoning about Unseen Objects from Multimodal Cues](https://arxiv.org/abs/2506.14212)
**中文标题：盒子里有什么？基于多模态线索的未见物体推理**

*Lance Ying,Daniel Xu,Alicia Zhang,Katherine M. Collins,Max H. Siegel,Joshua B. Tenenbaum*

主要分类: cs.AI

摘要简述: 本文提出了一种神经符号模型，通过结合多模态信息和贝叶斯推理来推断未见物体，并在“盒子里有什么？”游戏中验证了模型与人类判断的高度相关性。


<details>
  <summary>详细信息</summary>
研究动机: 人类能够灵活整合多源信息（如听觉、视觉、语言和先验知识）来推断未见物体，本文旨在探索如何通过计算模型实现这种能力。

研究方法: 提出了一种神经符号模型：使用神经网络解析多模态输入，再通过贝叶斯模型整合信息以评估不同假设。实验采用“盒子里有什么？”游戏，让模型和人类通过摇晃盒子的视频猜测内容。

研究结果: 实验表明，该模型与人类判断高度相关，而单模态模型或多模态神经模型基线表现较差。

研究结论: 神经符号模型能够有效整合多模态信息，模拟人类推断未见物体的能力，为多模态推理提供了新思路。

中文摘要: 人们经常通过灵活整合多源信息（如听觉和视觉线索、语言以及场景先验知识）来推断未见物体。我们如何能够如此灵活地整合这些信息，即使缺乏直接知识？本文提出了一种神经符号模型，使用神经网络解析开放多模态输入，再通过贝叶斯模型整合不同信息源以评估假设。我们通过一种名为“盒子里有什么？”的新颖物体猜测游戏评估模型，人类和模型观看实验者摇晃盒子的视频后猜测内容。通过人类实验，我们发现模型与人类判断高度相关，而单模态模型或多模态神经模型基线表现较差。

</details>


### [160] [From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models](https://arxiv.org/abs/2506.14224)
**中文标题：从黑盒到透明心智：评估和增强多模态大语言模型的心智理论**

*Xinyang Li,Siqi Liu,Bochao Zou,Jiansheng Chen,Huimin Ma*

主要分类: cs.AI

摘要简述: 本研究通过构建多模态ToM测试数据集GridToM，分析多模态大语言模型的注意力机制，提出一种轻量级方法提升其心智理论能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型的发展，人们期待其具备类似人类的心智理论（ToM）能力以辅助日常任务。然而，现有评估方法主要关注单模态模型，且缺乏对模型内部机制的解释性探索。

研究方法: 研究首先构建了多模态ToM测试数据集GridToM，包含多样化的信念测试任务和多视角感知信息。随后分析多模态大模型的注意力头，发现其能区分不同视角的认知信息。最后提出一种无需训练的轻量级方法，通过调整注意力头方向显著提升模型的ToM表现。

研究结果: 分析表明，多模态大模型的注意力头能够区分不同视角的认知信息，验证了其ToM能力。提出的轻量级方法显著提升了模型的ToM表现。

研究结论: 本研究通过内部机制驱动的评估方法，揭示了多模态大语言模型的ToM能力，并提出了一种有效的提升方法，为未来研究提供了新方向。

中文摘要: 随着大语言模型的发展，人们期待其能够模拟类似人类的心智理论（ToM）以辅助日常任务。然而，现有的机器ToM评估方法主要关注单模态模型，并将这些模型视为黑盒，缺乏对其内部机制的解释性探索。为此，本研究采用基于内部机制的方法，对多模态大语言模型（MLLMs）的ToM进行解释性评估。具体而言，我们首先构建了一个多模态ToM测试数据集GridToM，其中包含多样化的信念测试任务和多视角的感知信息。随后，我们的分析表明，多模态大模型中的注意力头能够区分不同视角的认知信息，为ToM能力提供了证据。此外，我们提出了一种轻量级、无需训练的方法，通过调整注意力头的方向显著提升了模型表现出的ToM能力。

</details>


### [161] [ImpReSS: Implicit Recommender System for Support Conversations](https://arxiv.org/abs/2506.14231)
**中文标题：ImpReSS：面向客服对话的隐式推荐系统**

*Omri Haller,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai*

主要分类: cs.AI

摘要简述: 本文提出了一种名为ImpReSS的隐式推荐系统，专为客服对话设计，能够在用户报告问题并提供解决方案的过程中，隐式推荐相关产品类别以解决问题或预防问题复发。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）的发展，基于LLM的聊天机器人已广泛应用于客服领域。然而，现有研究较少关注如何在客服对话中隐式集成推荐功能。本文旨在填补这一空白，提出一种无需假设用户购买意图的隐式推荐系统。

研究方法: ImpReSS是一种与现有客服聊天机器人协同工作的隐式推荐系统。它通过分析客服对话内容，识别并推荐相关的解决方案产品类别（SPCs），以帮助解决问题或预防问题复发。与传统推荐系统不同，ImpReSS完全隐式运作。

研究结果: 实验结果表明，ImpReSS在推荐相关SPCs方面表现优异。具体而言，在通用问题解决、信息安全支持和网络安全故障排除任务中，MRR@1（和recall@3）分别达到0.72（0.89）、0.82（0.83）和0.85（0.67）。

研究结论: ImpReSS展示了在客服对话中隐式推荐相关产品类别的潜力，不仅有助于解决问题，还能促进业务增长。未来研究可通过公开数据和代码进一步推动该领域的发展。

中文摘要: 随着大语言模型（LLMs）的快速发展，基于LLM的聊天机器人已通过自动化交互和提供一致、可扩展的服务改变了客户支持领域。尽管基于LLM的对话推荐系统（CRSs）因其提升推荐质量的能力而受到关注，但关于如何在客户支持交互中隐式集成推荐的研究仍有限。本文提出ImpReSS，一种专为客服对话设计的隐式推荐系统。ImpReSS与现有支持聊天机器人协同工作，用户在对话中报告问题，聊天机器人提供解决方案。基于客服对话内容，ImpReSS识别并推荐相关的解决方案产品类别（SPCs），以帮助解决问题或预防其复发——同时也支持业务增长。与传统CRSs不同，ImpReSS完全隐式运作，且不依赖任何用户购买意图的假设。我们对ImpReSS在推荐相关SPCs以解决客服对话中提出的问题的能力进行了实证评估，结果显示其表现优异，包括通用问题解决的MRR@1（和recall@3）为0.72（0.89）、信息安全支持为0.82（0.83）、网络安全故障排除为0.85（0.67）。为支持未来研究，我们的数据和代码将根据请求共享。

</details>


### [162] [Causes in neuron diagrams, and testing causal reasoning in Large Language Models. A glimpse of the future of philosophy?](https://arxiv.org/abs/2506.14239)
**中文标题：神经元图中的因果关系及大型语言模型的因果推理测试：哲学未来的曙光？**

*Louis Vervoort,Vitaly Nikolaev*

主要分类: cs.AI

摘要简述: 本文提出了一种基于哲学因果关系的测试方法，用于评估大型语言模型（如ChatGPT、DeepSeek和Gemini）的抽象因果推理能力。研究发现这些模型能够正确识别文献中争议的因果关系案例，并提出了一种更广泛有效的神经元图因果定义。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索人工智能（尤其是大型语言模型）在抽象因果推理方面的能力，并利用哲学中的神经元图理论设计测试方法，以验证这些模型是否能够处理复杂的因果关系问题。

研究方法: 方法基于哲学中的神经元图理论（由D. Lewis推广），设计了一种测试框架，用于评估大型语言模型在识别因果关系时的表现。测试对象包括ChatGPT、DeepSeek和Gemini等先进模型。

研究结果: 结果显示，这些大型语言模型能够正确识别文献中争议的因果关系案例。此外，研究提出了一种新的神经元图因果定义，其有效性超越了以往的研究成果。

研究结论: 结论认为，这些发现展示了未来哲学研究可能的发展方向：人类与人工智能在专业知识上的互动与合作。

中文摘要: 我们提出了一种基于哲学因果关系研究的测试方法，用于评估人工智能的抽象因果推理能力，特别是借鉴了D. Lewis推广的神经元图理论。我们以先进的大型语言模型（如ChatGPT、DeepSeek和Gemini）为例进行了测试。令人惊讶的是，这些聊天机器人已经能够正确识别文献中争议的因果关系案例。为了评估这些大型语言模型及未来专用人工智能的表现，我们提出了一种神经元图中因果关系的定义，其有效性超越了以往的研究，挑战了关于此类定义难以捉摸的普遍观点。我们认为，这些结果展示了未来哲学研究可能的发展方向：人类与人工智能在专业知识上的互动与合作。

</details>


### [163] [Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs](https://arxiv.org/abs/2506.14245)
**中文标题：基于可验证奖励的强化学习隐式激励基础大语言模型的正确推理**

*Xumeng Wen,Zihan Liu,Shun Zheng,Zhijian Xu,Shengyu Ye,Zhirong Wu,Xiao Liang,Yang Wang,Junjie Li,Ziming Miao,Jiang Bian,Mao Yang*

主要分类: cs.AI

摘要简述: 本文揭示了RLVR（可验证奖励的强化学习）在提升大语言模型（LLM）推理能力中的潜力，并指出传统评估指标$Pass@K$的缺陷。通过引入新指标$CoT$-$Pass@K$，证明RLVR能有效激励逻辑完整性，提升推理能力。


<details>
  <summary>详细信息</summary>
研究动机: RLVR被提出用于增强LLM的推理能力，但发现RLVR调优的模型在$Pass@K$指标上表现不佳，引发了对RLVR是否仅重分配推理路径而非提升推理多样性的质疑。本文旨在解决这一矛盾，并验证RLVR的实际效果。

研究方法: 通过分析$Pass@K$指标的缺陷，提出新指标$CoT$-$Pass@K$，要求推理路径和最终答案均正确。从理论上证明RLVR能激励逻辑完整性，并通过实验验证其效果。

研究结果: 实验表明，使用$CoT$-$Pass@K$指标时，RLVR能显著提升模型的推理能力，且这种能力在训练早期即显现并持续泛化。

研究结论: 本文明确了RLVR的作用，提供了更可靠的评估方法，并证实其能真正推动机器推理能力的进步。

中文摘要: 基于可验证奖励的强化学习（RLVR）已成为提升大语言模型（LLM）推理能力的一种有前景的方法。然而，其有效性存在一个关键矛盾：RLVR调优的模型在解决方案发现的$Pass@K$指标上常表现不如基础模型，这引发了一种假设，即RLVR仅以牺牲推理多样性为代价重新分配现有推理路径。本文通过识别问题的根源解决了这一矛盾：$Pass@K$指标本身是推理的缺陷衡量标准，因为它将正确最终答案归功于可能源于不准确或不完整思维链（CoT）的推理。为此，我们引入了一个更精确的评估指标$CoT$-$Pass@K$，要求推理路径和最终答案均正确。我们提供了一个新的理论基础，形式化地说明了RLVR与传统强化学习不同，其独特结构能够激励逻辑完整性。实证结果支持了这一观点：使用$CoT$-$Pass@K$指标时，我们观察到RLVR能够激励对所有$K$值的正确推理泛化。此外，通过分析训练动态，我们发现这种增强的推理能力在训练早期即显现并平滑泛化。本文为RLVR的作用提供了清晰的视角，提供了更可靠的评估方法，并证实其真正推动机器推理能力的潜力。

</details>


### [164] [Mxplainer: Explain and Learn Insights by Imitating Mahjong Agents](https://arxiv.org/abs/2506.14246)
**中文标题：Mxplainer：通过模仿麻将代理解释和学习洞察**

*Lingfeng Li,Yunlong Lu,Yongyi Wang,Qifan Zheng,Wenxin Li*

主要分类: cs.AI

摘要简述: 本文提出Mxplainer，一种参数化搜索算法，用于模仿麻将AI代理的行为并提取可理解的洞察，帮助人类学习AI代理的策略。


<details>
  <summary>详细信息</summary>
研究动机: 当前麻将AI代理虽然性能强大，但被视为黑箱，难以从中提取对人类有用的策略洞察。本文旨在通过模仿这些代理的行为，揭示其决策过程，帮助人类学习。

研究方法: Mxplainer是一种参数化搜索算法，可转换为等效的神经网络，用于学习黑箱代理的参数。通过分析AI和人类玩家的数据，提取可理解的参数和局部解释。

研究结果: 实验表明，Mxplainer能够提取人类可理解的参数，揭示AI代理的特征和玩法风格，并能局部解释黑箱代理的决策过程。

研究结论: Mxplainer为麻将AI代理提供了可解释的洞察，帮助人类学习和理解AI策略，同时展示了搜索框架在解释黑箱代理决策中的潜力。

中文摘要: 人们需要内化AI代理的技能以提升自身能力。本文聚焦于麻将这一涉及不完全信息和长期决策的多玩家游戏。尽管AI研究者已开发出性能媲美职业玩家的麻将AI代理，但这些代理通常被视为黑箱，难以从中提取洞察。本文提出Mxplainer，一种参数化搜索算法，可转换为等效神经网络以学习黑箱代理的参数。在AI和人类玩家数据上的实验表明，学习到的参数提供了对这些代理特征和玩法风格的人类可理解洞察。此外，我们还展示了搜索框架如何局部解释黑箱代理在大多数麻将游戏状态下的决策过程。

</details>


### [165] [Don't throw the baby out with the bathwater: How and why deep learning for ARC](https://arxiv.org/abs/2506.14276)
**中文标题：不要因噎废食：深度学习在ARC中的方法与原因**

*Jack Cole,Mohamed Osman*

主要分类: cs.AI

摘要简述: 本文探讨了深度学习在解决抽象与推理语料库（ARC）挑战中的有效性，提出了一种结合测试时微调（TTFT）和增强推理反向增强与投票（AIRV）的方法，显著提升了ARC任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管ARC对AI系统提出了巨大挑战，但深度学习仍是目前最有效的策略。本文旨在进一步利用深度学习的潜力，通过测试时动态训练神经网络，提升其在ARC任务中的表现。

研究方法: 方法包括从预训练的大型语言模型（LLM）出发，结合测试时微调（TTFT）和增强推理反向增强与投票（AIRV）技术，动态优化神经网络和优化器，以增强对未见任务的泛化能力。

研究结果: 实验结果显示，AIRV和TTFT分别带来了260%和300%的准确率提升，最终版本在ARC私有测试集上达到了58%的最高分，并在2023年ARCathon竞赛中夺冠。

研究结论: 研究表明，深度学习在ARC任务中具有显著潜力，动态优化和测试时技术是提升泛化推理能力的关键。

中文摘要: 抽象与推理语料库（ARC-AGI）对AI系统提出了严峻挑战。尽管ARC上的表现通常较低，但深度学习范式仍是生成跨视觉、语言等多领域最先进神经网络（NN）的最有效策略。深度学习已证明能够训练这些网络并学习所需抽象。本文进一步利用这一范式，通过在测试时动态训练NN，展示了深度学习在ARC上的潜力。具体而言，我们将神经网络和优化器（而非仅预训练网络）作为推理过程的组成部分，促进对未见任务的泛化。我们提出了一种从预训练LLM出发的ARC训练方法，并引入了测试时微调（TTFT）和增强推理反向增强与投票（AIRV）技术。实验显示，AIRV和TTFT分别带来了260%和300%的准确率提升。此方法的早期版本在2023年ARCathon竞赛中夺冠，最终版本在ARC私有测试集上达到了58%的最高分。研究揭示了在陌生领域中构建鲁棒推理系统的关键要素，强调了提升广泛感知推理的核心机制。

</details>


### [166] [ADRD: LLM-Driven Autonomous Driving Based on Rule-based Decision Systems](https://arxiv.org/abs/2506.14299)
**中文标题：ADRD：基于规则化决策系统的LLM驱动自动驾驶**

*Fanzhi Zeng,Siqi Wang,Chuzhao Zhu,Li Li*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大型语言模型（LLMs）的自动驾驶决策框架ADRD，通过规则化决策系统实现可解释的驾驶决策，并在性能、响应速度和可解释性上优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶决策系统的可解释性一直是学术研究的重点。传统强化学习方法难以提供透明的决策过程，而基于LLMs的规则化系统有望解决这一问题。

研究方法: ADRD框架包含三个核心模块：信息模块（聚合驾驶场景信息）、代理模块（生成规则化驾驶策略）和测试模块（迭代优化策略）。通过LLMs的推理和编程能力实现高效决策。

研究结果: 实验表明，ADRD在自动驾驶决策任务中表现优异，尤其在可解释性、响应速度和驾驶性能上显著优于传统强化学习和现有LLM方法。

研究结论: ADRD首次将LLMs与规则化系统结合用于自动驾驶决策，验证了其实际部署潜力，为透明且易修改的决策系统提供了新思路。

中文摘要: 如何构建可解释的自动驾驶决策系统已成为学术研究的焦点。本研究提出了一种新方法，利用大型语言模型（LLMs）生成可执行的规则化决策系统以应对这一挑战。具体而言，借助LLMs强大的推理和编程能力，我们提出了ADRD（基于规则化决策系统的LLM驱动自动驾驶）框架，该框架整合了三个核心模块：信息模块、代理模块和测试模块。框架首先通过信息模块聚合驾驶场景的上下文信息，随后利用代理模块生成规则化驾驶策略，并通过与测试模块的持续交互迭代优化策略。大量实验评估表明，ADRD在自动驾驶决策任务中表现出卓越性能。与传统强化学习方法及最先进的LLM方法相比，ADRD在可解释性、响应速度和驾驶性能上具有显著优势。这些结果凸显了该框架对复杂驾驶场景的全面准确理解能力，并展示了透明、易修改且广泛适用的规则化决策系统的广阔前景。据我们所知，这是首个将大型语言模型与规则化系统结合用于自动驾驶决策的研究，我们的发现验证了其实际部署的潜力。

</details>


### [167] [AviationLLM: An LLM-based Knowledge System for Aviation Training](https://arxiv.org/abs/2506.14336)
**中文标题：AviationLLM：基于大语言模型的航空培训知识系统**

*Jia'ang Wan,Feng Shen,Fujuan Li,Yanjin Sun,Yan Li,Shiwen Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于LLM的航空培训知识系统AviationLLM，通过直接偏好优化（DPO）和检索增强生成（RAG）技术，解决了传统训练系统中专业答案不准确和知识更新成本高的问题，显著提升了航空理论培训的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 航空培训是确保飞行安全、提升行业效率和促进可持续发展的核心环节，但现有培训系统依赖有限的教员资源，且互联网提供的专业答案准确性不足，导致培训效率低下。为此，本文引入LLM技术，但基础预训练模型无法提供专业领域的准确答案，需进一步优化。

研究方法: 本文提出RALA-DPO方法，基于开源预训练LLM Qwen，通过直接偏好优化（DPO）进行领域对齐，并结合检索增强生成（RAG）技术，从外部知识库检索相关信息，生成精确且高质量的答案，避免因数据偏差、知识过时或领域知识缺失导致的幻觉问题。

研究结果: 实验结果表明，RALA-DPO能够显著提升航空专业知识的回答准确性。结合RAG机制后，系统进一步提高了答案的准确性，并实现了零成本的知识更新。

研究结论: RALA-DPO通过DPO和RAG技术的结合，有效解决了航空培训中专业答案不准确和知识更新成本高的问题，为航空理论培训提供了高效且可靠的解决方案。

中文摘要: 航空培训是确保飞行安全、提升行业效率和促进可持续发展的核心环节，不仅涉及飞行模拟，还需学习大量专业航空理论知识。现有培训系统中，知识主要由教员传授，但教员数量有限，且从互联网获取的专业答案准确性不足，导致培训效率低下。为此，我们引入大语言模型（LLM），但基础预训练模型无法提供专业领域的准确答案，因此需对其进行微调。传统的监督微调（SFT）因数据覆盖不足可能导致表面合理但事实错误的回答。为解决这一问题，我们采用直接偏好优化（DPO）。本文提出基于直接偏好优化的检索增强LLM对齐方法（RALA-DPO）。我们选择开源预训练LLM Qwen，并通过基于DPO的领域对齐技术，将其适配于航空理论培训。同时，为减少因训练数据偏差、知识过时或领域知识缺失导致的幻觉问题，我们采用检索增强生成（RAG）技术，结合生成模型与检索模型。RALA-DPO能够有效从外部知识库检索相关信息，并通过生成模型提供精确且高质量的答案。实验结果表明，RALA-DPO能够提升航空专业知识的回答准确性。结合RAG机制后，该系统可进一步提高答案的准确性，并同时实现零成本的知识更新。

</details>


### [168] [Don't Make It Up: Preserving Ignorance Awareness in LLM Fine-Tuning](https://arxiv.org/abs/2506.14387)
**中文标题：不要编造：在LLM微调中保持无知意识**

*William F. Shen,Xinchi Qiu,Nicola Cancedda,Nicholas D. Lane*

主要分类: cs.AI

摘要简述: 现有研究在缓解大语言模型（LLM）微调中的灾难性遗忘时，主要关注特定数据或任务的保留，却忽视了安全对齐中模型表达无知能力的关键退化。本文提出SEAT方法，通过稀疏训练和实体扰动结合KL散度正则化，显著保留模型的无知意识，同时保持微调性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统微调方法会显著降低大语言模型表达无知的能力，导致幻觉等不良行为。本文旨在解决这一实际问题，提出一种既能保留微调性能又能维持模型无知意识的方法。

研究方法: 本文提出SEAT方法，包含两个关键组件：(1)稀疏训练，限制激活漂移；(2)结合KL散度正则化的实体扰动方法，用于对抗知识纠缠。

研究结果: 实验结果表明，SEAT在保留无知意识的同时，显著优于基线方法，且不影响微调性能，为大语言模型微调提供了更鲁棒的解决方案。

研究结论: SEAT方法通过稀疏训练和实体扰动，有效解决了传统微调中无知意识退化的问题，为大语言模型的安全对齐提供了实用且高效的解决方案。

中文摘要: 现有关于缓解大语言模型（LLM）微调中灾难性遗忘的研究主要集中于保留特定数据或任务，却严重忽视了安全对齐中模型忠实表达无知能力的退化。本文表明，传统微调会显著削弱这一能力，导致幻觉等不良行为。为解决这一新颖但高度实际的问题，我们提出SEAT，一种简单有效的微调方法，既能保留微调性能，又能维持模型承认无知的内在能力。SEAT包含两个关键组件：(1)限制激活漂移的稀疏训练；(2)结合KL散度正则化的新型实体扰动方法，旨在对抗知识纠缠。实验结果表明，SEAT在保留无知意识的同时显著优于基线方法，且不影响微调性能，为LLM微调提供了更鲁棒的解决方案。

</details>


### [169] [AST-Enhanced or AST-Overloaded? The Surprising Impact of Hybrid Graph Representations on Code Clone Detection](https://arxiv.org/abs/2506.14470)
**中文标题：AST增强还是AST过载？混合图表示在代码克隆检测中的意外影响**

*Zixian Zhang,Takfarinas Saber*

主要分类: cs.AI

摘要简述: 本文通过实证研究评估了基于AST的混合图表示在GNN代码克隆检测中的效果，发现AST+CFG+DFG能提升卷积和注意力模型的准确性，而FA-AST可能因结构复杂性降低性能。GMN在标准AST下表现最优，减少了对增强结构的需求。


<details>
  <summary>详细信息</summary>
研究动机: 代码克隆是软件维护中的严重问题，增加成本和风险。AST虽能精确表示语法结构，但缺乏语义深度。现有研究通过结合语义图（如CFG、DFG）增强AST，但其效果及与不同图学习技术的兼容性仍需探索。

研究方法: 本文系统比较了多种混合图表示（AST+CFG+DFG、FA-AST）在多种GNN架构（GCN、GAT、GMN）中的表现，通过实验评估其效果。

研究结果: 实验表明，AST+CFG+DFG能显著提升卷积和注意力模型的准确性，而FA-AST因结构复杂性可能降低性能。GMN在标准AST下表现最优，无需依赖增强结构。

研究结论: 混合图表示对GNN的影响因模型而异，AST+CFG+DFG效果显著，但FA-AST需谨慎使用。GMN在标准AST下已能高效检测代码相似性。

中文摘要: 作为最具危害性的代码异味之一，代码克隆显著增加了软件维护成本并提高了漏洞风险，使其检测成为软件工程中的关键挑战。抽象语法树（AST）因其精确的语法结构表示在基于深度学习的代码克隆检测中占据主导地位，但其固有地缺乏语义深度。最近的研究通过将AST与语义图（如控制流图CFG和数据流图DFG）结合来弥补这一缺陷。然而，各种增强的AST表示的有效性及其与不同基于图的机器学习技术的兼容性仍是一个开放问题，需要进一步研究以释放其在解决代码克隆检测复杂性方面的潜力。本文通过全面的实证研究，严格评估了基于AST的混合图表示在图神经网络（GNN）代码克隆检测中的效果。我们系统比较了多种混合表示（AST+CFG+DFG、流增强AST（FA-AST））在多种GNN架构中的表现。实验表明，混合表示对GNN的影响不同：AST+CFG+DFG能持续提升卷积和注意力模型（如图卷积网络GCN、图注意力网络GAT）的准确性，而FA-AST常因结构复杂性损害性能。值得注意的是，GMN即使在标准AST表示下也优于其他模型，展现了其在跨代码相似性检测中的优势，减少了对增强结构的需求。

</details>


### [170] [GUI-Robust: A Comprehensive Dataset for Testing GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2506.14477)
**中文标题：GUI-Robust：用于测试GUI代理在真实异常中鲁棒性的综合数据集**

*Jingqi Yang,Zhilong Song,Jiawei Chen,Mingli Song,Sheng Zhou,linjun sun,Xiaogang Ouyang,Chun Chen,Can Wang*

主要分类: cs.AI

摘要简述: 本文介绍了GUI-Robust数据集，专为评估GUI代理在真实异常场景中的鲁棒性而设计，包含七种常见异常类型，并通过半自动化方法显著降低标注成本。实验显示现有GUI代理在异常场景中性能显著下降。


<details>
  <summary>详细信息</summary>
研究动机: 现有GUI代理数据集多基于理想化条件构建，忽略了真实世界中的多样异常情况，限制了代理的鲁棒性评估。为此，作者提出GUI-Robust数据集，填补这一空白。

研究方法: 采用半自动化数据集构建范式：通过RPA工具收集自然交互的用户动作序列，并借助MLLM生成对应的步骤和任务描述，将标注时间成本降低19倍以上。

研究结果: 使用GUI-Robust评估现有GUI代理，发现其在异常场景中性能显著下降，凸显了鲁棒性研究的重要性。

研究结论: GUI-Robust数据集为GUI代理的鲁棒性研究提供了重要工具，并呼吁未来更多关注代理在异常场景中的表现。

中文摘要: 高质量数据集的开发对图形用户界面（GUI）代理的基准测试和研究至关重要。尽管其重要性，现有数据集通常在理想化条件下构建，忽略了真实部署中常见的多样异常。为解决这一问题，我们提出了GUI-Robust，一个专为全面评估GUI代理设计的新数据集，明确包含了日常GUI交互中观察到的七种常见异常类型。此外，我们提出了一种半自动化的数据集构建范式：通过RPA工具收集自然交互的用户动作序列，并借助MLLM为这些动作生成对应的步骤和任务描述。这一范式将标注时间成本降低了19倍以上。最后，我们使用GUI-Robust评估了最先进的GUI代理，揭示了其在异常场景中的显著性能下降。我们期望这项工作能强调GUI代理鲁棒性的重要性，并激发未来更多相关研究。数据集和代码可在https://github.com/chessbean1/GUI-Robust获取。

</details>


### [171] [LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?](https://arxiv.org/abs/2506.14496)
**中文标题：LLM驱动的群智能：新前沿还是概念延伸？**

*Muhammad Atta Ur Rahman,Melanie Schranz*

主要分类: cs.AI

摘要简述: 本文对比了传统群智能算法与基于大语言模型（LLM）的群智能系统，探讨了现代AI中分散性、可扩展性和涌现行为的重新定义，并评估了两种范式的性能差异。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，'群'的概念被扩展到描述由大语言模型（LLM）驱动的AI系统，如OpenAI的Swarm。本文旨在探讨传统群智能算法与LLM驱动的群智能系统之间的差异，以及现代AI中群智能的重新定义。

研究方法: 研究通过实现和比较Boids算法和蚁群优化（ACO）两种范式，评估了延迟、资源使用和行为准确性。同时，评估了基于云端和本地LLM在群智能中的适用性。

研究结果: 研究发现，尽管LLM提供了强大的推理和抽象能力，但在计算和协调方面引入了新的限制，挑战了传统群智能设计的理念。

研究结论: 本文强调了将LLM集成到群智能系统中的机遇和限制，并讨论了现代AI研究中'群'概念的演变。

中文摘要: 传统群智能指的是由简单、分散的代理组成的系统，其局部交互导致涌现的集体行为。最近，'群'这一术语被扩展到描述像OpenAI的Swarm这样的AI系统，其中大语言模型（LLM）作为协作代理。本文对比了传统群算法与LLM驱动的群智能，探讨了现代人工智能（AI）中分散性、可扩展性和涌现行为的重新定义。我们通过实现和比较Boids和蚁群优化（ACO）两种范式，评估了延迟、资源使用和行为准确性。同时，评估了基于云端和本地LLM在群智能中的适用性。尽管LLM提供了强大的推理和抽象能力，但它们引入了计算和协调方面的新限制，挑战了传统群智能设计的理念。本研究强调了将LLM集成到群智能系统中的机遇和限制，并讨论了现代AI研究中'群'概念的演变。

</details>


### [172] [Toward Safety-First Human-Like Decision Making for Autonomous Vehicles in Time-Varying Traffic Flow](https://arxiv.org/abs/2506.14502)
**中文标题：面向时变交通流的自动驾驶安全优先类人决策研究**

*Xiao Wang,Junru Yu,Jun Huang,Qiong Wu,Ljubo Vacic,Changyin Sun*

主要分类: cs.AI

摘要简述: 本文提出了一种安全优先的类人决策框架（SF-HLDM），用于自动驾驶车辆在动态交通流中实现安全、舒适且社会兼容的驾驶。该框架结合了时空注意力机制、社会合规性估计模块和深度进化强化学习模型，有效避免局部最优陷阱并提高决策灵活性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管人工智能技术在提升交通效率和安全性方面展现出潜力，自动驾驶车辆在动态交通流（尤其是密集和交互场景）中仍面临挑战。人类驾驶行为的多样性和数据驱动方法的迁移性差、搜索成本高问题，降低了行为策略的效率和效果。因此，需要一种能够兼顾安全性和类人决策的框架。

研究方法: 提出SF-HLDM框架，包含以下模块：1）时空注意力（S-TA）机制，用于推断其他道路使用者的意图；2）社会合规性估计模块，用于行为调节；3）深度进化强化学习（DERL）模型，高效扩展搜索空间，避免局部最优和过拟合风险。

研究结果: SF-HLDM框架使自动驾驶AI代理能够动态调整决策参数，保持安全距离并适应上下文合适的驾驶行为，实现了安全、舒适且社会兼容的驾驶决策。

研究结论: SF-HLDM框架通过结合多个模块，显著提升了自动驾驶车辆在动态交通流中的决策能力，兼具安全性和类人灵活性，为未来自动驾驶技术的发展提供了新思路。

中文摘要: 尽管人工智能技术的进步在提升交通效率和安全性方面展现出巨大潜力，自动驾驶车辆（AVs）在时变交通流（尤其是密集和交互场景）中仍面临重大挑战。同时，人类具有自由意志，即使在完全相同的场景下也通常不会做出相同的决策，导致数据驱动方法存在迁移性差和搜索成本高的问题，降低了行为策略的效率和效果。本研究提出了一种安全优先的类人决策框架（SF-HLDM），使自动驾驶车辆能够安全、舒适且社会兼容地驾驶。该框架整合了分层递进结构，包括用于推断其他道路使用者意图的时空注意力（S-TA）机制、用于行为调节的社会合规性估计模块，以及用于高效扩展搜索空间的深度进化强化学习（DERL）模型，从而避免陷入局部最优陷阱并降低过拟合风险，实现具有可解释性和灵活性的类人决策。SF-HLDM框架使自动驾驶AI代理能够动态调整决策参数，在保持安全距离的同时遵循上下文合适的驾驶行为。

</details>


### [173] [Doppelgänger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack](https://arxiv.org/abs/2506.14539)
**中文标题：替身方法：通过基于提示的可转移对抗攻击破坏大语言模型代理的角色一致性**

*Daewon Kang,YeongHwan Shin,Doyeon Kim,Kyu-Hwan Jung,Meong Hi Son*

主要分类: cs.AI

摘要简述: 本文提出“替身方法”，通过基于提示的可转移对抗攻击破坏大语言模型代理的角色一致性，展示了代理被劫持的风险，并提出“对抗转移下的提示对齐崩溃（PACAT）”评估其脆弱性。同时，提出“对抗转移警示（CAT）”提示作为防御手段。实验证明替身方法能破坏代理一致性并泄露内部信息，而CAT提示能有效防御此类攻击。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型的普及，提示工程使得快速、低成本创建多样化的自主代理成为可能，但这也引发了安全性、鲁棒性和行为一致性的担忧。本文旨在揭示代理被劫持的风险，并提出评估和防御方法。

研究方法: 提出“替身方法”作为可转移对抗攻击手段，破坏代理的角色一致性；定义“对抗转移下的提示对齐崩溃（PACAT）”评估脆弱性；设计“对抗转移警示（CAT）”提示作为防御措施。

研究结果: 实验表明，替身方法能成功破坏代理的一致性并暴露其内部信息，而CAT提示能有效防御此类攻击。

研究结论: 替身方法揭示了代理在对抗攻击下的脆弱性，而CAT提示提供了一种有效的防御手段，为提升代理安全性提供了新思路。

中文摘要: 自大语言模型问世以来，提示工程使得快速、低成本创建多样化的自主代理成为可能，并已广泛应用。然而，这种便利性引发了关于底层提示的安全性、鲁棒性和行为一致性的紧迫担忧，以及防止这些提示被用户尝试暴露的迫切挑战。本文提出“替身方法”以展示代理被劫持的风险，从而暴露系统指令和内部信息。接着，我们定义了“对抗转移下的提示对齐崩溃（PACAT）”级别以评估对此类对抗转移攻击的脆弱性。我们还提出了一种“对抗转移警示（CAT）”提示以应对替身方法。实验结果表明，替身方法能够破坏代理的一致性并暴露其内部信息，而CAT提示则能有效防御此类对抗攻击。

</details>


### [174] [QUEST: Quality-aware Semi-supervised Table Extraction for Business Documents](https://arxiv.org/abs/2506.14568)
**中文标题：QUEST：面向商业文档的质量感知半监督表格提取**

*Eliott Thomas,Mickael Coustaty,Aurelie Joseph,Gaspar Deloin,Elodie Carel,Vincent Poulain D'Andecy,Jean-Marc Ogier*

主要分类: cs.AI

摘要简述: QUEST提出了一种质量感知的半监督表格提取框架，通过评估表格的结构和上下文特征来改进伪标签选择，显著提升了商业文档中表格提取的准确性和完整性。


<details>
  <summary>详细信息</summary>
研究动机: 商业文档中的表格提取自动化对工业流程至关重要，但现有方法依赖的置信度评分无法准确反映提取质量，且标注数据稀缺。QUEST旨在解决这些问题，提升表格提取的准确性和鲁棒性。

研究方法: QUEST引入了一种新颖的质量评估模型，通过预测F1分数而非置信度来评估提取表格的质量。结合多样性度量（如DPP、Vendi分数和IntDiv）来缓解确认偏差，并在迭代的半监督训练中优化伪标签选择。

研究结果: 在专有商业数据集上，QUEST将F1分数从64%提升至74%，空预测率降低了45%（从12%降至6.5%）。在DocILE基准测试中，F1分数从42%提升至50%，空预测率降低了19%（从27%降至22%）。

研究结论: QUEST通过质量感知的半监督学习框架，显著提升了商业文档中表格提取的性能，尤其在结构一致性和数据完整性方面表现优异，适用于标注稀缺的场景。

中文摘要: 自动化商业文档中的表格提取（TE）对工业流程至关重要，但由于标注稀疏和多阶段流程易错，仍具挑战性。尽管半监督学习（SSL）可以利用未标注数据，但现有方法依赖的置信度评分无法准确反映提取质量。我们提出了QUEST，一种面向商业文档的质量感知半监督表格提取框架。QUEST引入了一种新颖的质量评估模型，通过评估提取表格的结构和上下文特征来预测F1分数，而非依赖置信度指标。这种质量感知方法在迭代的SSL训练中指导伪标签选择，同时通过多样性度量（DPP、Vendi分数、IntDiv）缓解确认偏差。在专有商业数据集（1000标注+10000未标注文档）上的实验表明，QUEST将F1分数从64%提升至74%，空预测率降低了45%（从12%降至6.5%）。在DocILE基准测试（600标注+20000未标注文档）中，QUEST实现了50%的F1分数（从42%提升），空预测率降低了19%（从27%降至22%）。该框架的可解释质量评估和对标注稀缺的鲁棒性，使其特别适用于结构一致性和数据完整性至关重要的商业文档。

</details>


### [175] [Enhancing Symbolic Machine Learning by Subsymbolic Representations](https://arxiv.org/abs/2506.14569)
**中文标题：通过亚符号表示增强符号机器学习**

*Stephen Roth,Lennart Baur,Derian Boer,Stefan Kramer*

主要分类: cs.AI

摘要简述: 本文提出通过神经嵌入增强符号机器学习方法，在简单场景中提升效率，实验证明其在F1分数上优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 神经符号AI旨在结合符号与亚符号方法以克服各自局限，但现有系统如LTN和DeepProbLog在简单场景（如判别式机器学习）中效率较低。因此，作者提出通过神经嵌入增强符号机器学习方法。

研究方法: 作者为符号机器学习方法TILDE提供神经嵌入，特别是用于相似性谓词的常量嵌入，并可根据符号理论进一步微调嵌入。

研究结果: 在三个真实领域实验中，该方法在F1分数上优于所有基线方法。

研究结论: 该方法不仅适用于当前场景，还可扩展至实例间相似性（类似逻辑语言中的核函数）、类比推理或命题化。

中文摘要: 神经符号AI的目标是整合符号与亚符号AI方法，以克服各自的局限性。现有系统如逻辑张量网络（LTN）或DeepProbLog提供了神经谓词和端到端学习，但其多功能性在简单场景（如判别式机器学习，尤其是常量较多的领域）中效率较低。因此，我们采用了一种不同方法：通过为符号机器学习方案提供神经嵌入来增强其性能。本文以TILDE及其在相似性谓词中使用的常量嵌入为例展示了这一方法。该方法可通过根据符号理论进一步细化嵌入进行微调。在三个真实领域的实验中，这种简单而有效的方法在F1分数上优于所有基线方法。该方法的应用不仅限于此：通过这种方式增强符号学习器可扩展至实例间相似性（类似逻辑语言中的核函数）、类比推理或命题化。

</details>


### [176] [From Points to Places: Towards Human Mobility-Driven Spatiotemporal Foundation Models via Understanding Places](https://arxiv.org/abs/2506.14570)
**中文标题：从点到场所：通过理解场所构建人类移动性驱动的时空基础模型**

*Mohammad Hashemi,Andreas Zufle*

主要分类: cs.AI

摘要简述: 本文提出一种新型空间基础模型，旨在通过理解人类行为驱动的动态区域（即“场所”）来捕捉人类移动性，以支持跨地理和场景的可扩展分析。


<details>
  <summary>详细信息</summary>
研究动机: 人类移动性数据具有空间、时间和语义复杂性，现有基础模型难以处理。本文旨在填补适应性、可扩展性和多粒度推理的空白，推动下一代地理空间智能模型的发展。

研究方法: 提出从离散的兴趣点转向理解动态、上下文丰富的“场所”，并整合地理位置语义与人类移动性。研究重点包括建模场所和高效学习方法。

研究结果: 提出了一种新型空间基础模型框架，支持跨场景的可扩展分析，为个性化场所发现、物流优化和城市规划等应用提供基础。

研究结论: 本文为开发可扩展、上下文感知的下一代地理空间智能模型提供了方向，有望推动更智能的空间决策。

中文摘要: 捕捉人类移动性对于建模人们如何与物理空间互动和移动至关重要，反映了社会行为、资源获取和动态空间模式。为了支持跨多样地理和场景的可扩展和可转移分析，需要一种通用的时空数据基础模型。尽管基础模型已经改变了语言和视觉领域，但在处理移动性数据独特的空间、时间和语义复杂性方面仍有限制。本文倡导一类新型空间基础模型，将地理位置语义与多尺度人类移动性相结合。我们愿景的核心是从建模离散的兴趣点转向理解“场所”：由人类行为与移动性塑造的动态、上下文丰富的区域，可能包含多个兴趣点。我们指出了适应性、可扩展性和多粒度推理的关键空白，并提出了专注于建模场所和高效学习的研究方向。目标是指导开发可扩展、上下文感知的下一代地理空间智能模型。这些模型将解锁从个性化场所发现、物流优化到城市规划的强大应用，最终实现更智能和响应更快的空间决策。

</details>


### [177] [AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes](https://arxiv.org/abs/2506.14728)
**中文标题：AgentDistill：基于通用MCP模块的无训练智能体蒸馏**

*Jiahao Qiu,Xinzhe Juan,Yimin Wang,Ling Yang,Xuan Qi,Tongcheng Zhang,Jiacheng Guo,Yifu Lu,Zixin Yao,Hongru Wang,Shilong Liu,Xun Jiang,Liu Leqi,Mengdi Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种无需训练的智能体蒸馏框架AgentDistill，通过直接复用教师智能体生成的模块化任务解决单元（MCPs），实现高效且可扩展的知识迁移，使小型语言模型构建的学生智能体在跨领域任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的智能体蒸馏方法通常需要完整重放教师轨迹或逐步模仿教师工具使用，难以训练学生智能体在新环境中动态规划和行动。因此，本文旨在探索一种无需训练、可泛化的智能体蒸馏方法。

研究方法: AgentDistill框架通过复用教师智能体自主生成的结构化、可复用的任务解决模块（MCPs），实现知识的高效迁移。学生智能体无需额外训练即可直接利用这些模块解决新问题。

研究结果: 在生物医学和数学基准测试中，基于小型语言模型的学生智能体表现与使用大型语言模型（如GPT-4o）的高级系统相当，验证了框架的有效性和可扩展性。

研究结论: AgentDistill为构建高效、低成本的智能体提供了一种新方法，通过复用MCP模块实现了跨领域的知识迁移，显著降低了训练开销。

中文摘要: 尽管知识蒸馏已成为将大型语言模型（LLMs）压缩为小型模型的成熟领域，但涉及规划、记忆和工具使用的基于LLM的智能体蒸馏仍相对未被充分探索。现有方法通常重放完整教师轨迹或逐步模仿教师工具使用，但难以训练学生智能体在新环境中动态规划和行动。我们提出AgentDistill，一种无需训练的新型智能体蒸馏框架，通过直接复用教师智能体自主生成的结构化、可复用任务解决模块（MCPs），实现高效且可扩展的知识迁移。这些蒸馏的MCPs使学生智能体能够跨领域泛化能力，并在最小监督或人工干预下解决新问题。在生物医学和数学基准测试中，基于小型语言模型的学生智能体表现与使用大型LLMs（如OctoTools（GPT-4o））的高级系统相当，凸显了该框架在构建可扩展且经济高效的智能体方面的有效性。

</details>


### [178] [Optimizing Length Compression in Large Reasoning Models](https://arxiv.org/abs/2506.14755)
**中文标题：优化大型推理模型的长度压缩**

*Zhengxiang Cheng,Dongping Chen,Mingyang Fu,Tianyi Zhou*

主要分类: cs.AI

摘要简述: 大型推理模型（LRMs）常因生成冗长且不必要的推理链而效率低下。本文提出两种新原则——简洁性和充分性，并基于此开发了LC-R1方法，通过长度奖励和压缩奖励显著减少推理链长度（约50%），同时仅轻微影响准确性（约2%）。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型在推理过程中常产生冗余的‘无效思考’，即反复验证已正确的答案。为提高效率，本文提出超越传统效能和效率原则的‘简洁性’和‘充分性’，旨在消除冗余并保留关键推理步骤。

研究方法: 本文提出LC-R1方法，基于组相对策略优化（GRPO），结合长度奖励（鼓励整体简洁）和压缩奖励（专门消除无效思考部分），对模型进行后训练优化。

研究结果: 实验表明，LC-R1在多个推理基准测试中显著减少推理链长度（约50%），仅轻微降低准确性（约2%），实现了高效压缩与性能的平衡。

研究结论: LC-R1通过优化推理链长度，为开发更高效的大型推理模型提供了新思路，其鲁棒性和实用性在实验中得到了验证。

中文摘要: 大型推理模型（LRMs）取得了显著成功，但其推理链常包含不必要的冗长内容。我们将此问题的核心归因于‘无效思考’——模型在得出正确答案后仍反复验证。为解决这一低效问题，我们超越传统的效能和效率原则，提出两个更细化的新原则：简洁性（消除冗余）和充分性（保留关键推理步骤）。基于这些原则，我们提出了LC-R1，一种基于组相对策略优化（GRPO）的后训练方法。LC-R1结合了长度奖励（鼓励整体简洁）和压缩奖励（专门消除无效思考部分）。在多个推理基准测试中，LC-R1显著减少了序列长度（约50%），仅轻微降低准确性（约2%），实现了高效压缩与性能的平衡。进一步分析验证了LC-R1的鲁棒性，为开发更强大且计算高效的LRMs提供了宝贵见解。代码发布于https://github.com/zxiangx/LC-R1。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [179] [Enhancing Clinical Decision Support and EHR Insights through LLMs and the Model Context Protocol: An Open-Source MCP-FHIR Framework](https://arxiv.org/abs/2506.13800)
**中文标题：通过LLMs和模型上下文协议增强临床决策支持与EHR洞察：开源MCP-FHIR框架**

*Abul Ehtesham,Aditi Singh,Saket Kumar*

主要分类: cs.SE

摘要简述: 本文提出了一种基于大型语言模型（LLMs）和模型上下文协议（MCP）的开源框架，用于动态提取和分析电子健康记录（EHRs），以增强临床决策支持（CDS）、减轻文档负担并提升患者健康素养。


<details>
  <summary>详细信息</summary>
研究动机: 数字健康领域在临床决策支持、文档负担和患者健康素养方面面临持续挑战，亟需一种可扩展、可解释且互操作的技术解决方案。

研究方法: 通过将LLMs与HL7 FHIR数据集成，利用MCP协议实现动态数据提取和推理，支持实时总结、解释和个性化沟通。框架基于JSON配置，适用于多种用户角色。

研究结果: 使用符合FHIR R4标准的合成EHR数据进行评估，验证了框架的可扩展性、可解释性和互操作性，优于传统静态工作流方法。

研究结论: 该框架为个性化数字健康解决方案提供了坚实基础，支持多种FHIR格式，推动了AI在EHR应用中的发展。

中文摘要: 增强临床决策支持（CDS）、减轻文档负担并提升患者健康素养是数字健康领域的持续挑战。本文提出了一种基于代理的开源框架，通过模型上下文协议（MCP）将大型语言模型（LLMs）与HL7 FHIR数据集成，实现对电子健康记录（EHRs）的动态提取和推理。该框架基于现有的MCP-FHIR实现，通过基于JSON的配置实现对多种FHIR资源的声明式访问，支持实时总结、解释和个性化沟通，适用于临床医生、护理人员和患者等多种用户角色。为确保隐私和可重复性，框架使用符合FHIR R4标准的SMART Health IT沙箱中的合成EHR数据进行评估。与传统依赖硬编码检索和静态工作流的方法不同，所提出的方法提供了可扩展、可解释且互操作的AI驱动EHR应用。代理架构进一步支持多种FHIR格式，为推进个性化数字健康解决方案奠定了坚实基础。

</details>


### [180] [Instruction and Solution Probabilities as Heuristics for Inductive Programming](https://arxiv.org/abs/2506.13804)
**中文标题：指令概率与解决方案概率作为归纳编程的启发式方法**

*Edward McDaid,Sarah McDaid*

主要分类: cs.SE

摘要简述: 本文提出了一种基于指令概率和解决方案概率的启发式方法，用于大幅缩小归纳编程的搜索空间。通过结合指令子集（IS）和概率阈值，实现了搜索空间减少高达100个数量级的效果。


<details>
  <summary>详细信息</summary>
研究动机: 指令子集（IS）虽能显著缩小归纳编程的搜索空间，但仍有进一步优化的空间。本文旨在通过引入指令概率和解决方案概率作为额外启发式方法，进一步提升搜索效率。

研究方法: 1. 引入指令概率，基于大型代码样本中指令的出现频率计算；2. 定义解决方案概率为所有指令概率的乘积；3. 使用不同规模代码单元中的最小解决方案概率作为阈值，剪枝搜索空间；4. 测试两种指令概率计算方式：全局样本和单独IS样本。

研究结果: 实验表明，两种指令概率计算方式均能显著减少搜索空间，最高可达数十个数量级。结合IS后，总减少量超过100个数量级。交叉验证证明该方法对未见代码同样有效。

研究结论: 通过引入指令和解决方案概率作为启发式方法，本文显著提升了归纳编程的效率。未来可进一步优化概率模型并扩展应用场景。

中文摘要: 指令子集（IS）是一种启发式方法，可将归纳编程（IP）的搜索空间缩小数十个数量级。本文扩展了IS方法，引入指令概率和解决方案概率作为额外启发式。指令概率基于大型代码样本中指令的出现频率，反映其在解决方案中的预期出现概率。解决方案概率为所有指令概率（包括重复指令）的乘积。我们以不同规模代码单元中的最小解决方案概率作为阈值，用于在构建部分解决方案时剪枝搜索空间，从而消除包含低概率指令组合的分支。新方法已通过大量人类代码样本进行评估。测试了两种指令概率计算方式：一种基于整个代码样本的指令出现频率，另一种为每个IS单独计算分布。结果显示，两种方式均能进一步显著减少IP搜索空间，最高可达数十个数量级（取决于解决方案规模）。结合IS后，总减少量可超过100个数量级。交叉验证表明，这些启发式方法对未见代码同样有效。本文详细描述了该方法，并讨论了结果及未来研究方向。

</details>


### [181] [Structured Program Synthesis using LLMs: Results and Insights from the IPARC Challenge](https://arxiv.org/abs/2506.13820)
**中文标题：使用LLM的结构化程序合成：IPARC挑战的结果与洞见**

*Shraddha Surana,Ashwin Srinivasan,Michael Bain*

主要分类: cs.SE

摘要简述: 本文介绍了一种基于LLM的结构化归纳编程方法，成功解决了IPARC挑战中的600项任务，揭示了LLM在代码生成中的关键作用及人机协作的潜力。


<details>
  <summary>详细信息</summary>
研究动机: IPARC挑战提供了600项合成图像上的程序合成任务，旨在评估自动程序构建能力，尤其是序列、选择和迭代。这些任务一直难以被自动化解决，因此本文探索了LLM在结构化程序合成中的应用。

研究方法: 采用了一种基于LLM的结构化归纳编程方法，通过先验结构化、代码冻结和代码重用等技术，结合人类细化，成功解决了IPARC的所有类别任务。

研究结果: 该方法在IPARC挑战中表现优异，解决了所有任务类别，并揭示了LLM在代码生成中的关键作用，如结构化辅助、代码冻结的必要性以及代码重用的高效性。

研究结论: 研究结果表明，LLM在程序合成中具有重要价值，能够激发人类创造力，并为人机协作解决复杂程序合成问题提供了有效机制。

中文摘要: IPARC挑战受ARC启发，提供了一系列基于合成图像的程序合成任务，旨在评估自动程序构建能力，重点关注序列、选择和迭代。这600项任务一直难以被自动化解决。本文提出了一种基于LLM的结构化归纳编程方法，成功解决了IPARC的所有类别任务。IPARC的受控性质揭示了LLM在代码生成中的关键洞见，包括先验结构化的重要性、LLM辅助结构化的能力（需人类细化）、冻结正确代码的必要性、代码重用的高效性，以及LLM生成代码如何激发人类创造力。这些发现为人类与LLM协作解决复杂程序合成问题提供了有价值的机制。

</details>


### [182] [CRITICTOOL: Evaluating Self-Critique Capabilities of Large Language Models in Tool-Calling Error Scenarios](https://arxiv.org/abs/2506.13977)
**中文标题：CRITICTOOL：评估大型语言模型在工具调用错误场景中的自我批判能力**

*Shiting Huang,Zhen Fang,Zehui Chen,Siyu Yuan,Junjie Ye,Yu Zeng,Lin Chen,Qi Mao,Feng Zhao*

主要分类: cs.SE

摘要简述: 本文提出了CRITICTOOL，一个专门用于评估大型语言模型在工具调用错误场景中自我批判能力的基准测试工具。通过分析工具调用中的错误类型，并基于进化策略构建多样化数据集，CRITICTOOL能够更真实地反映实际场景中的工具使用错误。实验验证了其泛化性和有效性，并深入分析了不同模型的工具反思能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在复杂任务中工具使用的增加，工具调用过程中可能引发各种意外错误。如何有效识别、诊断和恢复这些错误成为推动工具学习发展的关键研究方向。

研究方法: 研究首先分析了多个工具评估基准中的函数调用错误类型，并基于进化策略构建了CRITICTOOL，一个包含多样化工具使用错误的综合批判评估基准。通过实验验证了其泛化性和有效性。

研究结果: 实验结果表明，CRITICTOOL能够有效评估不同LLMs在工具调用错误场景中的自我批判能力，并提供了对工具反思能力的深入分析。

研究结论: CRITICTOOL为工具学习领域提供了新的评估视角，其多样化的错误场景和进化策略构建的数据集为未来研究提供了重要参考。

中文摘要: 大型语言模型（LLMs）利用外部工具的能力使其能够处理日益多样化的任务。然而，随着任务变得更加复杂和长期化，复杂的工具使用过程可能引发各种意外错误。因此，如何有效处理这些错误，包括识别、诊断和恢复，已成为推动工具学习发展的关键研究方向。本研究首先广泛分析了多个竞争性工具评估基准中函数调用过程中的错误类型。基于此，我们提出了CRITICTOOL，一个专门用于工具学习的综合批判评估基准。通过一种新颖的进化策略构建数据集，CRITICTOOL包含了多样化的工具使用错误，能够更好地反映真实场景。我们在CRITICTOOL上进行了大量实验，验证了所构建基准策略的泛化性和有效性。同时，我们还深入分析了不同LLMs的工具反思能力，为工具学习领域提供了新的视角。代码可在\href{https://github.com/Shellorley0513/CriticTool}{https://github.com/Shellorley0513/CriticTool}获取。

</details>


### [183] [MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios](https://arxiv.org/abs/2506.13824)
**中文标题：MLDebugging：面向多库场景的代码调试基准研究**

*Jinyang Huang,Xiachong Feng,Qiguang Chen,Hanjie Zhao,Zihui Cheng,Jiesong Bai,Jingxuan Zhou,Min Li,Libo Qin*

主要分类: cs.SE

摘要简述: 本文首次提出MLDebugging基准，用于评估多库Python代码调试能力，涵盖126个库和七类问题，发现主流大语言模型在多库调试中表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 当前代码调试研究主要关注无库或单库场景，忽视了现实应用中复杂的多库环境。本文旨在填补这一空白，推动多库调试研究。

研究方法: 构建MLDebugging基准，包含126个Python库和七类多库代码问题，并对主流开源和闭源大语言模型进行全面评估。

研究结果: 实验表明，当前大语言模型在多库调试任务中表现不佳，凸显了多库场景的挑战性。

研究结论: MLDebugging揭示了多库调试的潜力，为未来研究提供了方向，同时呼吁改进大语言模型在此领域的表现。

中文摘要: 代码调试是软件工程中的关键任务，受到广泛关注。尽管大语言模型（LLMs）取得了显著成功，但当前研究仍集中于简单的无库或单库场景，忽视了现实应用中的复杂多库环境。为弥补这一不足，我们首次提出MLDebugging（多库调试），这是一个全面评估多库Python代码调试挑战的基准。具体而言，MLDebugging涵盖126个不同的Python库，涉及七类多库代码问题。此外，我们使用主流开源和闭源LLMs对MLDebugging进行了全面评估，结果表明当前LLMs在多库调试中仍存在困难。我们希望这项工作能揭示LLMs在多库调试中的潜力，并为未来研究提供启示。

</details>


### [184] [FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation](https://arxiv.org/abs/2506.13832)
**中文标题：FrontendBench：通过自动评估评估LLM在前端开发中的表现的基准**

*Hongda Zhu,Yiwen Zhang,Bing Zhao,Jingzhe Ding,Siyao Liu,Tong Liu,Dandan Wang,Yanan Liu,Zhaojian Li*

主要分类: cs.SE

摘要简述: 本文提出了FrontendBench，一个由人类与大型语言模型（LLM）共同开发的基准测试，用于全面评估LLM在前端代码生成中的表现。该基准包含148个精心设计的任务，覆盖从基础UI元素到复杂交互功能的五个层级，并通过自动化评估框架实现高效验证。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试在前端代码生成评估中存在任务过于简单、测试用例不严谨及缺乏端到端验证等问题，无法准确衡量模型性能。为解决这些问题，本文提出了FrontendBench。

研究方法: FrontendBench将任务按代码功能分类，并引入交互式测试场景。此外，开发了一个自动化评估框架，在沙盒环境中执行生成的代码，并通过预定义测试脚本评估结果。

研究结果: 自动化评估框架与专家人工评估的一致性达到90.54%。对多个先进LLM的测试显示，它们在处理真实前端任务时表现差异显著。

研究结论: FrontendBench是一个可靠且可扩展的基准测试，支持多模态评估，为前端代码生成的未来研究提供了坚实基础。

中文摘要: 大型语言模型（LLM）在前端代码生成方面取得了显著进展。然而，现有基准测试存在多个关键限制：许多任务过于简单，测试用例往往不够严谨，且缺乏端到端验证。这些问题阻碍了对模型性能的准确评估。为解决这些挑战，我们提出了FrontendBench，一个由人类与LLM共同开发的基准测试。FrontendBench根据代码功能对任务进行分类，并引入交互式测试场景，从而实现对前端代码生成能力更全面和实际的评估。该基准包含148个精心设计的提示-测试用例对，覆盖从基础UI元素到复杂交互功能的五个层级。每个任务均反映真实的前端开发挑战。此外，我们引入了一个自动化评估框架，在沙盒环境中执行生成的代码，并通过预定义测试脚本评估结果。该框架与专家人工评估的一致性达到90.54%，显示出高可靠性。我们在FrontendBench上测试了多个先进的LLM，观察到它们在处理真实前端任务时的显著性能差异。这些结果凸显了FrontendBench作为一个可靠且可扩展的基准测试的价值，支持一致的多模态评估，并为前端代码生成的未来研究提供了坚实基础。我们的数据和代码将很快发布。

</details>


### [185] [How Does LLM Reasoning Work for Code? A Survey and a Call to Action](https://arxiv.org/abs/2506.13932)
**中文标题：LLM如何为代码推理工作？一项调查与行动呼吁**

*Ira Ceka,Saurabh Pujar,Irene Manotas,Gail Kaiser,Baishakhi Ray,Shyam Ramji*

主要分类: cs.SE

摘要简述: 本文首次系统调查了大型语言模型（LLM）在代码任务中的推理技术，总结了主流策略、混合与代理方法，提出了代码推理技术的分类法，并探讨了代码核心特性如何解释不同推理技术。同时，指出了未来研究的潜在方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在自然语言任务中的显著进步，其在代码领域的应用也日益广泛，如代码生成、翻译和修复等。然而，LLM在实际软件工程（SWE）任务中的推理机制尚未得到充分研究。本文旨在填补这一空白，探讨代码推理的技术及其性能驱动范式。

研究方法: 本文通过系统调查和分类法构建，总结了代码推理的主流策略（如混合与代理方法），并分析了常见基准测试的性能表现。此外，还探讨了代码核心特性对推理技术的影响。

研究结果: 研究提出了首个专注于代码任务的推理技术调查，建立了代码推理技术的分类法，并展示了新基准测试的潜力。同时，揭示了代码特性与推理技术之间的关系。

研究结论: 本文为代码推理领域提供了全面的研究框架，指出了当前研究的不足和未来探索的方向，尤其是在软件工程任务中的应用潜力。

中文摘要: 大型语言模型（LLM）的崛起显著提升了自然语言任务的性能，并扩展至代码领域，支持代码生成、翻译、摘要和修复等复杂任务。然而，其在实际软件工程（SWE）任务（如GitHub问题解决）中的实用性近期才被研究。本文探讨了支撑这些任务的代码推理技术及其性能驱动范式。主要贡献包括：（1）首个专注于代码任务的推理技术调查，总结了主流策略、混合与代理方法；（2）代码推理技术的分类法；（3）常见基准测试的性能综述及潜在新基准的展示；（4）代码核心特性如何解释不同推理技术的探讨；（5）未来研究的空白与潜在方向。

</details>


### [186] [Automatic Qiskit Code Refactoring Using Large Language Models](https://arxiv.org/abs/2506.14535)
**中文标题：基于大语言模型的Qiskit代码自动重构方法**

*José Manuel Suárez,Luis Mariano Bibbó,Joaquin Bogado,Alejandro Fernandez*

主要分类: cs.SE

摘要简述: 本文提出了一种利用大语言模型（LLM）自动重构Qiskit代码的新方法，通过提取官方文档中的迁移场景分类，并结合LLM生成重构建议，有效解决了量子软件框架快速迭代带来的兼容性问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着量子软件框架的快速迭代，开发者面临API兼容性维护的挑战。本文旨在通过大语言模型自动化重构Qiskit代码，减轻开发者的迁移负担。

研究方法: 方法包括：1) 从Qiskit官方文档（如发布说明）中提取迁移场景分类；2) 将分类和原始Python代码输入LLM，识别迁移场景并生成重构建议；3) 设计针对性输入结构以克服LLM上下文长度限制。

研究结果: 实验结果表明，结合领域知识的LLM能有效自动化Qiskit代码迁移，并提供了从早期版本迁移至0.46版的分类和提示集。

研究结论: 本文证明了LLM在量子代码迁移中的潜力，同时提供了实用的分类和方法论，为未来量子软件开发工具的设计提供了参考。

中文摘要: 随着量子软件框架的发展，开发者面临快速变化的API带来的兼容性维护挑战。本文提出了一种利用大语言模型（LLM）重构Qiskit代码的新方法。首先，我们从Qiskit官方文档（如发布说明）中提取迁移场景分类，捕获功能迁移至不同模块和废弃用法等常见模式。该分类与原始Python代码一起作为LLM的输入，LLM的任务是识别代码中的迁移场景并生成重构建议。我们的方法通过结构化输入和推理过程，解决了当前LLM的上下文长度限制。结果表明，结合领域知识的LLM能有效辅助自动化Qiskit代码迁移。本文贡献包括：1) 从早期版本迁移至0.46版的分类和提示集；2) 评估LLM在量子代码迁移中能力的方法论。

</details>


### [187] [Low-code to fight climate change: the Climaborough project](https://arxiv.org/abs/2506.14623)
**中文标题：低代码对抗气候变化：Climaborough项目**

*Aaron Conrardy,Armen Sulejmani,Cindy Guerlain,Daniele Pagani,David Hick,Matteo Satta,Jordi Cabot*

主要分类: cs.SE

摘要简述: 欧盟资助的Climaborough项目通过低代码/无代码策略，帮助欧洲城市快速部署气候仪表盘，以实现2030年碳中和目标。


<details>
  <summary>详细信息</summary>
研究动机: 项目旨在支持欧洲城市在2030年前实现碳中和，通过实时和历史数据监测气候目标进展，并评估本地实验性举措的效果。

研究方法: 采用低代码策略加速仪表盘开发，嵌入无代码理念，使非技术用户也能根据需求配置和调整仪表盘。

研究结果: 开发了Climaborough城市平台，通过用户友好的仪表盘展示数据，帮助城市评估气候举措的成效和扩展潜力。

研究结论: 低代码/无代码策略有效支持了气候仪表盘的快速部署，为非技术用户提供了灵活的工具，助力城市实现碳中和目标。

中文摘要: 欧盟资助的Climaborough项目旨在支持欧洲城市在2030年前实现碳中和。来自九个国家的11个城市将在实际环境中部署促进气候转型的产品和服务。Climaborough城市平台正在开发中，通过聚合历史和实时数据，并在用户友好的仪表盘中展示结果，帮助非技术专家评估本地实验性举措的有效性，识别具有显著影响的举措，并评估将其扩展到更广范围的潜在后果。本文解释了如何通过低代码/无代码策略快速部署气候仪表盘。低代码策略用于加速仪表盘的开发，而仪表盘嵌入的无代码理念使各类公民能够根据自身需求配置和调整仪表盘。

</details>


### [188] [ACM Survey Draft on Formalising Software Requirements with Large Language Models](https://arxiv.org/abs/2506.14627)
**中文标题：使用大型语言模型形式化软件需求的ACM调查草案**

*Arshad Beg,Diarmuid O'Donoghue,Rosemary Monahan*

主要分类: cs.SE

摘要简述: 本文是一份关于使用大型语言模型形式化软件需求的ACM调查草案，总结了94篇论文，并包含软件需求可追溯性、形式化方法及其工具、统一编程理论和机构理论等章节。


<details>
  <summary>详细信息</summary>
研究动机: 旨在通过总结和分析现有研究，探讨大型语言模型在形式化软件需求中的应用，为相关领域的研究和实践提供参考。

研究方法: 通过文献综述的方式，总结了94篇相关论文，并分章节讨论了软件需求的可追溯性、形式化方法及其工具、统一编程理论和机构理论等内容。

研究结果: 草案提供了对现有研究的全面总结，并指出了与其他类似标题草案（如AACS 2025和SAIV 2025）的关键区别。

研究结论: 本文为形式化软件需求领域的研究提供了有价值的综述，并强调了大型语言模型在此领域的潜力。

中文摘要: 本草案是一份工作文档，总结了94篇论文，并包含关于软件需求可追溯性（第4节）、形式化方法及其工具（第5节）、统一编程理论（UTP）和机构理论（第6节）的额外章节。请参考[7,8]的摘要。本草案与我们近期类似标题的预期草案（即AACS 2025 [7]和SAIV 2025 [8]）的关键区别在于：
[7]是提交给爱尔兰ADAPT年度会议的两页投稿，于2025年3月18日提交，经过轻量级盲审并被接受为海报展示。会议于2025年5月15日举行。
[8]是一篇九页的论文，附有九页的参考文献和总结表格，于2025年4月24日提交给AI验证研讨会（SAIV 2025）。它经过了严格的评审过程。arXiv.org上上传的版本[8]是改进后的提交版本，解决了特定的改进建议。

</details>


### [189] [Navigating the growing field of research on AI for software testing -- the taxonomy for AI-augmented software testing and an ontology-driven literature survey](https://arxiv.org/abs/2506.14640)
**中文标题：探索AI在软件测试中的研究领域——AI增强软件测试的分类法及本体驱动的文献综述**

*Ina K. Schieferdecker*

主要分类: cs.SE

摘要简述: 本文综述了AI在软件测试中的增强作用，提出了新的分类法ai4st，并用于分类近期研究及识别开放性问题。


<details>
  <summary>详细信息</summary>
研究动机: 软件测试是验证和确认软件功能、性能、安全性和可用性的主要方法，但测试自动化的设计、开发和维护成本高昂。AI的突破为软件测试提供了新视角，本文旨在探索AI如何增强软件测试。

研究方法: 本文回顾了AI在软件测试自动化中的最新研究，从无自动化到完全自动化，并讨论了AI带来的新型测试形式。基于此，提出了新的分类法ai4st，用于分类研究并识别开放性问题。

研究结果: 提出了新的分类法ai4st，并成功将其应用于近期研究的分类，同时识别了开放的研究问题。

研究结论: AI为软件测试带来了新的可能性，分类法ai4st为研究提供了系统化框架，未来需进一步探索开放性问题。

中文摘要: 在工业界，软件测试是验证和确认基于软件系统的功能、性能、安全性、可用性等的主要方法。过去十年，测试自动化在工业界受到越来越多的关注，而AI在许多工程领域的突破为软件测试（包括手动和自动化测试）提供了新的视角。本文综述了AI在软件测试自动化中的最新研究，从无自动化到完全自动化，并讨论了AI带来的新型测试形式。基于此，新开发的分类法ai4st被提出并用于分类近期研究及识别开放的研究问题。

</details>


### [190] [Unified Software Engineering agent as AI Software Engineer](https://arxiv.org/abs/2506.14683)
**中文标题：统一软件工程代理：作为AI软件工程师**

*Leonhard Applis,Yuntong Zhang,Shanchao Liang,Nan Jiang,Lin Tan,Abhik Roychoudhury*

主要分类: cs.SE

摘要简述: 本文提出了一种统一软件工程代理（USEagent），旨在通过整合多种软件工程能力（如编码、测试、修复）来模拟未来AI软件工程师的角色。USEagent在包含1,271个任务的USEbench上表现优于现有通用代理，但仍需改进某些编码任务。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）技术虽在自动化编码方面有进展，但软件工程涵盖更广，包括维护和项目演进等。现有研究多专注于特定任务代理（如测试、修复），而本文旨在开发一个统一代理，以模拟未来AI软件工程师的多功能角色。

研究方法: 开发了统一软件工程代理（USEagent），整合多种软件工程能力（如编码、测试、修复），并构建了USEbench基准测试，包含来自SWE-bench、SWT-bench和REPOCOD等任务的1,271个软件工程任务。

研究结果: 在USEbench测试中，USEagent表现优于现有通用代理（如OpenHands CodeActAgent），但在某些编码任务上仍存在不足，为未来AI软件工程师的发展提供了改进方向。

研究结论: USEagent作为未来AI软件工程师的雏形，展示了整合多任务能力的潜力，但仍需进一步优化以完全胜任复杂软件开发场景。

中文摘要: 大型语言模型（LLM）技术的发展提高了对自动化编码的期望，但软件工程不仅限于编码，还包括维护和项目演进等活动。在此背景下，LLM代理的概念受到关注，其利用LLM作为推理引擎自主调用外部工具。然而，LLM代理是否等同于AI软件工程师？本文通过开发统一软件工程代理（USEagent）探讨这一问题。与现有专注于特定软件任务（如测试、调试、修复）的代理不同，我们的目标是构建一个能够协调和处理多种能力的统一代理，使其能够应对复杂软件开发场景（如修复不完整补丁、添加新功能或接管他人代码）。我们设想USEagent作为未来AI软件工程师的初稿，可成为AI与人类共同参与的软件开发团队成员。为评估USEagent的效果，我们构建了统一软件工程基准（USEbench），包含编码、测试和修补等多种任务，整合了SWE-bench、SWT-bench和REPOCOD等现有基准的任务。在包含1,271个仓库级软件工程任务的USEbench评估中，USEagent的表现优于现有通用代理（如OpenHands CodeActAgent）。USEagent在某些编码任务上仍存在能力差距，这为未来AI软件工程师的发展提供了方向。

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [191] [A Survey of Physics-Informed AI for Complex Urban Systems](https://arxiv.org/abs/2506.13777)
**中文标题：物理信息人工智能在复杂城市系统中的综述**

*En Xu,Huandong Wang,Yunke Zhang,Sibo Li,Yinzhou Tang,Zhilun Zhou,Yuming Lin,Yuan Yuan,Xiaochen Fan,Jingtao Ding,Yong Li*

主要分类: physics.soc-ph

摘要简述: 本文综述了物理信息人工智能在复杂城市系统中的应用，提出了一种分类方法，并分析了其在八个城市领域中的具体应用，为未来研究指明了方向。


<details>
  <summary>详细信息</summary>
研究动机: 城市系统是复杂系统的典型代表，将物理模型与人工智能结合可提高预测准确性、可解释性和决策能力。本文旨在全面梳理物理信息AI方法在城市中的应用，为研究者和实践者提供指导。

研究方法: 文章提出了一种分类法，将现有方法分为三类：物理集成AI、物理-AI混合集成和AI集成物理，并详细介绍了七种代表性方法。同时，系统分析了这些方法在能源、环境、经济等八个城市领域的应用。

研究结果: 研究展示了物理信息AI方法如何结合物理规律和数据驱动模型解决城市问题，提升系统的可靠性、效率和适应性。通过分类和应用分析，明确了现有方法的优缺点和适用场景。

研究结论: 本文总结了物理信息AI在城市系统中的研究现状，指出了关键空白，并提出了未来研究方向，为下一代智能城市系统建模奠定了基础。

中文摘要: 城市系统是复杂系统的典型代表，将基于物理的建模与人工智能（AI）结合，为提高预测准确性、可解释性和决策能力提供了有前景的范式。在此背景下，AI擅长捕捉复杂的非线性关系，而基于物理的模型则确保与现实世界规律的一致性并提供可解释的见解。本文对城市应用中的物理信息AI方法进行了全面综述。提出的分类法将现有方法分为三类——物理集成AI、物理-AI混合集成和AI集成物理，并进一步详述了七种代表性方法。这一分类明确了物理与AI结合的不同程度和方向，指导根据应用需求和数据可用性选择和开发合适的方法。我们系统地研究了这些方法在能源、环境、经济、交通、信息、公共服务、应急管理和城市整体系统等八个关键城市领域的应用。分析强调了这些方法如何利用物理规律和数据驱动模型解决城市挑战，提升系统的可靠性、效率和适应性。通过综合现有方法及其城市应用，我们识别了关键空白并概述了未来研究方向，为下一代智能城市系统建模铺平了道路。

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [192] [Asymptotically Smaller Encodings for Graph Problems and Scheduling](https://arxiv.org/abs/2506.14042)
**中文标题：图问题与调度问题的渐近更小编码**

*Bernardo Subercaseaux*

主要分类: cs.LO

摘要简述: 本文展示了如何将多个图问题（如顶点覆盖、独立集、$k$-着色）编码为CNF，仅需$O(|V|^2 / \lg |V|)$子句，而非传统编码的$Ω(|V|^2)$约束。此外，提出了一种针对稠密区间图中独立集的新编码方法，仅需$O(|V| \lg |V|)$子句，并成功应用于字符串压缩编码和调度问题，显著减少了编码规模。


<details>
  <summary>详细信息</summary>
研究动机: 传统图问题编码方法通常需要$Ω(|V|^2)$约束，效率较低。本文旨在探索更高效的编码方式，以减少计算复杂度，并为理解“有界变量添加”预处理工具的成功提供理论支持。

研究方法: 利用Erdős、Chung和Spencer（1983）关于图的二分覆盖的结果，提出了一种新的CNF编码方法。此外，针对稠密区间图中的独立集问题，设计了一种仅需$O(|V| \lg |V|)$子句的编码方法。

研究结果: 实现了多个图问题的编码规模从$Ω(|V|^2)$降至$O(|V|^2 / \lg |V|)$。对于稠密区间图中的独立集问题，编码规模进一步降至$O(|V| \lg |V|)$。此外，调度问题的编码规模从$O(NMT^2)$减少到$O(NMT + M T^2 \lg T)$。

研究结论: 本文提出的编码方法显著减少了图问题和调度问题的编码规模，为高效计算提供了新思路。同时，为理解预处理工具的成功奠定了理论基础。

中文摘要: 我们展示了如何将多个图问题（如顶点覆盖、独立集、$k$-着色）编码为CNF，仅需$O(|V|^2 / \lg |V|)$子句，而非传统编码的$Ω(|V|^2)$约束。这一结果源于Erdős、Chung和Spencer（1983）关于图的二分覆盖的研究，并为理解“有界变量添加”（Manthey、Heule和Biere，2012）预处理工具的成功提供了理论支持。此外，我们提出了一种针对稠密区间图中独立集的新编码方法，仅需$O(|V| \lg |V|)$子句（直接编码需$Ω(|V|^2)$），并成功应用于Bannai等人（2022）提出的字符串压缩编码。作为直接成果，我们还将Mayank和Modal（2020）提出的调度问题的编码规模从$O(NMT^2)$减少到$O(NMT + M T^2 \lg T)$，其中$N$为任务数，$T$为总时间跨度，$M$为机器数。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [193] [Multimodal Fusion with Semi-Supervised Learning Minimizes Annotation Quantity for Modeling Videoconference Conversation Experience](https://arxiv.org/abs/2506.13971)
**中文标题：基于半监督学习的多模态融合最小化视频会议对话体验建模的标注量**

*Andrew Chang,Chenkai Hu,Ji Qi,Zhuojian Wei,Kexin Zhang,Viswadruth Akkaraju,David Poeppel,Dustin Freeman*

主要分类: eess.AS

摘要简述: 本文提出了一种基于半监督学习的多模态融合方法，显著减少了视频会议对话体验建模所需的标注数据量，同时保持了高性能。


<details>
  <summary>详细信息</summary>
研究动机: 视频会议中的群组对话是一种复杂的社会行为，但对话中不流畅或不愉快的负面体验时刻研究不足。这些时刻在自然数据中较为罕见，传统的监督学习需要大量昂贵的人工标注数据。

研究方法: 采用半监督学习（SSL）结合多模态（音频、面部、文本）深度特征，利用少量标注数据和大量未标注数据训练模型，预测视频会议中的负面体验时刻。通过多模态融合的协同训练SSL方法提升性能。

研究结果: 多模态融合的协同训练SSL模型在ROC-AUC和F1分数上分别达到0.9和0.6，优于相同标注数据量的监督学习模型（提升4%）。仅使用8%标注数据的SSL模型性能达到全数据监督学习模型的96%。

研究结论: 研究表明，半监督学习框架能够高效利用标注数据，显著降低视频会议体验建模的标注成本，同时保持高性能。

中文摘要: 视频会议中的群组对话是一种复杂的社会行为。然而，对话中失去流畅性或愉悦感的负面体验时刻研究较少。这些时刻在自然数据中较为罕见，因此训练监督学习（SL）模型需要昂贵的人工标注数据。我们应用半监督学习（SSL）结合标注和未标注片段，训练多模态（音频、面部、文本）深度特征，以预测保留视频会议会话中的不流畅或不愉快时刻。多模态融合的协同训练SSL实现了ROC-AUC 0.9和F1分数0.6，优于相同标注数据量的SL模型（提升4%）。值得注意的是，仅使用8%标注数据的最佳SSL模型性能达到全数据SL模型的96%。这表明了一种高效的标注框架，用于建模视频会议体验。

</details>


### [194] [Improving Practical Aspects of End-to-End Multi-Talker Speech Recognition for Online and Offline Scenarios](https://arxiv.org/abs/2506.14204)
**中文标题：改进端到端多说话人语音识别在在线与离线场景中的实际应用**

*Aswin Shanmugam Subramanian,Amit Das,Naoyuki Kanda,Jinyu Li,Xiaofei Wang,Yifan Gong*

主要分类: eess.AS

摘要简述: 本文扩展了序列化输出训练（SOT）框架，以满足流式和离线自动语音识别（ASR）的实际需求，重点平衡延迟与准确性，并提出了多项关键改进。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决流式和离线ASR应用中的实际问题，如实时字幕和摘要需求，本文旨在通过改进SOT框架，提升多说话人语音识别的准确性和实用性。

研究方法: 1. 结合连续语音分离（CSS）单通道前端与端到端（E2E）系统，处理高度重叠的语音场景；2. 采用双模型策略（流式Conformer Transducer和离线序列到序列模型）或基于级联编码器的两阶段模型；3. 探索更适合离线场景的基于片段的SOT（segSOT），提升多说话人转录的可读性。

研究结果: CSS框架显著提升了ASR系统在多说话人重叠语音场景下的准确性；双模型和segSOT分别优化了流式和离线场景的性能与可读性。

研究结论: 本文提出的改进方法有效平衡了ASR系统的延迟与准确性，适用于流式和离线场景，为多说话人语音识别提供了实用解决方案。

中文摘要: 我们扩展了序列化输出训练（SOT）框架，以满足流式和离线自动语音识别（ASR）应用的实际需求，重点关注延迟与准确性的平衡，以适应实时字幕和摘要的需求。我们提出了几项关键改进：（1）结合连续语音分离（CSS）单通道前端与端到端（E2E）系统，用于高度重叠的语音场景，挑战了E2E与级联设置的传统观念。CSS框架通过分离多说话人的重叠语音，提升了ASR系统的准确性。（2）采用双模型策略——流式Conformer Transducer和离线序列到序列模型，或基于级联编码器的两阶段模型。（3）探索更适合离线场景的基于片段的SOT（segSOT），同时提升多说话人转录的可读性。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [195] [A Systematic Review of User-Centred Evaluation of Explainable AI in Healthcare](https://arxiv.org/abs/2506.13904)
**中文标题：医疗领域可解释人工智能的用户中心评估系统综述**

*Ivania Donoso-Guzmán,Kristýna Sirka Kacafírková,Maxwell Szymanski,An Jacobs,Denis Parra,Katrien Verbert*

主要分类: cs.HC

摘要简述: 本文通过系统综述82项用户研究，提出医疗领域可解释人工智能（XAI）的用户体验框架和评估指南，填补了XAI在真实场景中评估不足的空白。


<details>
  <summary>详细信息</summary>
研究动机: 尽管可解释人工智能（XAI）发展迅速，但其实际价值在真实场景中仍未充分验证。缺乏明确的用户评估指南导致XAI的可信度和可用性难以保证，尤其在医疗领域。

研究方法: 研究对来自五个数据库的82项医疗领域XAI用户研究进行系统综述，采用预定义的编码方案和迭代开发的归纳编码进行分析。

研究结果: 研究贡献包括：（1）总结当前评估实践，显示医疗XAI中以人为本方法的增长趋势；（2）揭示解释属性间的关联；（3）提出更新的框架和实用指南，支持跨学科团队设计针对特定场景的XAI评估策略。

研究结论: 研究填补了XAI在医疗领域用户评估的空白，提供了框架和指南，有助于提升XAI系统的可信度和实用性。

中文摘要: 尽管可解释人工智能（XAI）取得了显著进展，但其实际价值在真实场景中仍未充分探索和验证。稳健且情境感知的评估不仅对生成可理解的解释至关重要，还能确保其对目标用户的信任度和可用性，但由于缺乏明确的用户评估设计指南，这一领域常被忽视。本研究通过两个主要目标填补这一空白：（1）开发一个定义明确的原子属性框架，以描述医疗领域XAI的用户体验；（2）提供清晰、情境敏感的指南，基于系统特性定义评估策略。研究对来自五个数据库的82项医疗领域XAI用户研究进行了系统综述，分析采用预定义的编码方案和迭代开发的归纳编码。综述得出三个关键贡献：（1）总结当前评估实践，突显医疗XAI中以人为本方法的增长趋势；（2）揭示解释属性间的关联；（3）提出更新的框架和实用指南，支持跨学科团队设计针对特定应用场景的XAI系统评估策略。

</details>


### [196] [StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework](https://arxiv.org/abs/2506.14159)
**中文标题：StorySage：基于多智能体框架的对话式自传写作系统**

*Shayan Talaei,Meijin Li,Kanu Grover,James Kent Hippler,Diyi Yang,Amin Saberi*

主要分类: cs.HC

摘要简述: StorySage是一款基于多智能体框架的对话式自传写作系统，通过灵活对话和结构化方法帮助用户整理记忆并完成自传。实验和用户研究表明，其表现优于基线系统。


<details>
  <summary>详细信息</summary>
研究动机: 个人记忆通常分散且难以组织成连贯的自传，现有对话式写作助手依赖通用交互和预定义指南，难以捕捉个性化记忆并完成完整传记。StorySage旨在解决这一问题。

研究方法: StorySage采用多智能体框架，包括采访者、会话记录员、规划师、章节写手和会话协调员，通过迭代收集用户记忆、更新自传并规划未来对话。

研究结果: 实验模拟显示StorySage能处理多轮会话并捕捉用户记忆；用户研究（N=28）表明其在对话流畅性、叙事完整性和用户满意度上优于基线系统。

研究结论: StorySage为自传写作提供了新颖架构，并展示了多智能体系统如何增强人机创意合作。

中文摘要: 每个人都拥有由记忆和经历塑造的独特人生故事，但这些记忆通常分散且难以组织成连贯的自传。现有的对话式写作助手依赖通用交互和预定义指南，难以捕捉个人记忆并逐步完成传记。我们推出StorySage，这是一款用户驱动的软件系统，支持灵活对话和结构化自传写作方法。其多智能体框架由采访者、会话记录员、规划师、章节写手和会话协调员组成，系统通过迭代收集用户记忆、更新自传并规划未来对话。实验模拟表明，StorySage能够处理多轮会话并捕捉用户记忆。用户研究（N=28）显示，与基线系统相比，StorySage在对话流畅性、叙事完整性和用户满意度上表现更优。总之，StorySage不仅为自传写作提供了新颖架构，还揭示了多智能体系统如何提升人机创意合作。

</details>


### [197] [Balancing Caregiving and Self-Care: Exploring Mental Health Needs of Alzheimer's and Dementia Caregivers](https://arxiv.org/abs/2506.14196)
**中文标题：平衡照顾与自我关怀：探索阿尔茨海默症和痴呆症照顾者的心理健康需求**

*Jiayue Melissa Shi,Keran Wang,Dong Whi Yoo,Ravi Karkar,Koustuv Saha*

主要分类: cs.HC

摘要简述: 研究探讨了阿尔茨海默症和痴呆症家庭照顾者的心理健康需求，分析了他们在照顾过程中的心理挑战、应对策略及技术需求，并提出了分阶段干预的建议。


<details>
  <summary>详细信息</summary>
研究动机: 阿尔茨海默症及相关痴呆症（AD/ADRD）患者的家庭照顾者因长期照顾责任面临严重的心理健康问题，但现有支持系统未能充分关注其动态变化的心理健康需求。本研究旨在填补这一空白。

研究方法: 通过对25名AD/ADRD患者家庭照顾者进行半结构化访谈，研究分析了心理健康挑战的成因和影响，并绘制了照顾者在三个不同照顾阶段的心理健康变化时间线。

研究结果: 研究发现照顾者的心理健康需求随照顾阶段动态变化，并提出了对现有心理健康技术的改进建议，强调需要可访问、可扩展且个性化的解决方案。

研究结论: 研究结果为设计动态、分阶段的干预措施提供了基础，以全面支持照顾者的心理健康，从而惠及照顾者和被照顾者。

中文摘要: 阿尔茨海默症及相关痴呆症（AD/ADRD）是一种进行性神经退行性疾病，损害记忆、思维和功能。AD/ADRD患者的家庭照顾者因长期照顾责任面临严重的心理健康挑战，但现有支持系统往往忽视了其心理健康需求的动态变化。本研究探讨了照顾者的心理健康问题，重点关注他们为应对照顾负担所采取的策略及使用的技术支持。通过对25名AD/ADRD患者家庭照顾者的半结构化访谈，我们确定了心理健康挑战的主要成因和影响，并绘制了照顾者在三个不同照顾阶段中心理健康变化的时间线。此外，参与者还分享了改进现有心理健康技术的见解，强调需要可访问、可扩展且个性化的解决方案，以适应照顾者随时间变化的需求。这些发现为设计动态、分阶段的干预措施奠定了基础，以全面支持照顾者的心理健康，惠及照顾者和被照顾者。

</details>


### [198] [Controlling Context: Generative AI at Work in Integrated Circuit Design and Other High-Precision Domains](https://arxiv.org/abs/2506.14567)
**中文标题：控制上下文：生成式AI在集成电路设计等高精度领域的应用**

*Emanuel Moss,Elizabeth Watkins,Christopher Persaud,Passant Karunaratne,Dawn Nafus*

主要分类: cs.HC

摘要简述: 生成式AI工具在集成电路设计等高精度领域日益普及，但其准确性仍引发工程师对错误的警惕。本文通过访谈硬件和软件工程师，分析生成式AI工具使用中的挑战，并提出通过交互式控制上下文来缓解问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI工具在工程工作流中的广泛应用，其在高精度领域（如集成电路设计）的准确性成为关注焦点。研究旨在探讨工程师如何在使用这些工具时保持对错误的警惕，并识别其他潜在问题。

研究方法: 研究通过对硬件和软件工程师及其合作者的访谈，分析生成式AI工具在高精度领域的使用情况，重点关注准确性及其带来的其他挑战。

研究结果: 研究发现，工程师在使用生成式AI工具时面临的主要挑战是控制交互上下文。研究还列举了这些工具带来的其他问题，并将其映射到生成式AI系统的具体组成部分。

研究结论: 控制工程师与生成式AI工具交互的上下文是最大挑战之一。研究建议通过增强交互式上下文控制能力来缓解这一问题。

中文摘要: 生成式AI工具在工程工作流中日益普及，尤其是通过聊天机器人和代码助手。随着这些工具准确性的提升，高精度领域工作者如何保持对错误的警惕以及使用这些工具可能带来的其他问题成为关注焦点。本文通过访谈集成电路设计领域的硬件和软件工程师及其合作者，分析生成式AI工具使用中准确性的作用及其带来的其他挑战。研究列举了这些挑战，并将其映射到生成式AI系统的组成部分，最终指出控制工程师与生成式AI工具交互的上下文是最大挑战之一。文章最后提出通过增强交互式上下文控制能力来缓解这一问题的建议。

</details>


### [199] [StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery](https://arxiv.org/abs/2506.14670)
**中文标题：StreetLens：基于街景图像的人本化AI代理社区评估系统**

*Jina Kim,Leeje Jang,Yao-Yi Chiang,Guanyu Wang,Michelle Pasco*

主要分类: cs.HC

摘要简述: 本文介绍了StreetLens，一种基于视觉语言模型（VLM）的人本化、可配置的工作流，用于自动化社区环境评估，结合社会科学专业知识，提升研究的可扩展性和适应性。


<details>
  <summary>详细信息</summary>
研究动机: 传统社区研究方法依赖人工访谈、调查和图像标注，耗时且需专家干预。现有技术虽部分自动化，但缺乏跨设计和地理环境的适应性。StreetLens旨在通过人本化AI系统解决这些问题。

研究方法: StreetLens通过嵌入社会科学知识的VLM，模拟人工编码过程，从街景图像中生成从客观特征到主观感知的语义标注，支持研究者自定义提示以增强分析灵活性。

研究结果: StreetLens实现了社区环境的高效评估，支持多样化的语义标注，并通过整合先验调查数据提升鲁棒性，适用于不同地理环境。

研究结论: StreetLens代表了灵活、自主的AI系统发展方向，通过与研究者协作加速和扩展社区研究，为社会科学研究提供了新工具。

中文摘要: 传统社区研究依赖访谈、调查和人工图像标注，识别环境特征（如物理混乱、街道安全等）及其对健康和发展的影响。这些方法虽深入但耗时且需专家干预。近年来，视觉语言模型（VLM）开始部分自动化此过程，但现有方法缺乏跨设计和地理环境的适应性。本文提出StreetLens，一种人本化、可配置的工作流，将社会科学知识嵌入VLM，实现可扩展的社区环境评估。StreetLens模拟人工编码过程，基于访谈协议问题分析街景图像，生成从客观特征（如车辆数量）到主观感知（如图像混乱感）的广泛语义标注。通过研究者自定义提示，StreetLens将领域知识置于分析核心，并支持整合先验调查数据以增强鲁棒性和评估范围。我们提供Google Colab笔记本，便于研究者使用公共或自定义街景数据集。StreetLens标志着向灵活、自主的AI系统转变，与研究者协作加速和扩展社区研究。

</details>


### [200] [Design an Editable Speech-to-Sign-Language Transformer System: A Human-Centered AI Approach](https://arxiv.org/abs/2506.14677)
**中文标题：设计一种可编辑的语音到手语转换系统：以人为中心的AI方法**

*Yingchao Li*

主要分类: cs.HC

摘要简述: 本文提出了一种基于Transformer的可编辑语音到手语转换系统，通过用户可编辑的JSON中间层和实时优化循环，显著提升了手语动画的自然性和用户参与度。实验证明，该系统在理解度、自然性和实时性方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有手语技术存在用户无法直接编辑和优化的问题，限制了手语动画的自然性和表达力。本文旨在通过结合Transformer技术和用户参与式反馈，开发一种更灵活、透明且用户友好的语音到手语转换系统。

研究方法: 系统采用流式Conformer编码器和自回归Transformer-MDN解码器，将语音输入同步转化为3D虚拟形象的上半身和面部动作。通过用户可编辑的JSON中间层和实时优化循环，实现用户直接修改和反馈驱动的持续改进。

研究结果: 实验结果显示，20名聋哑人士和5名手语翻译者的参与表明，可编辑界面和用户反馈显著提升了系统的理解度、自然性、易用性和信任度，同时降低了认知负荷。系统在标准硬件上每帧推理时间低于20毫秒，适合实时通信和教育应用。

研究结论: 本文展示了技术与用户参与式创新相结合如何实现可访问、可解释且用户自适应的AI手语技术，为未来手语系统的发展提供了重要参考。

中文摘要: 本文提出了一种以人为中心的实时用户自适应语音到手语动画系统，该系统结合了基于Transformer的动作生成和透明的用户可编辑JSON中间层。该框架通过允许用户直接检查和修改手语片段，克服了现有手语技术的关键限制，从而提升了自然性、表达力和用户参与度。系统利用流式Conformer编码器和自回归Transformer-MDN解码器，将语音输入同步转化为3D虚拟形象的上半身和面部动作。用户编辑和评分数据被纳入实时优化循环以实现持续改进。20名聋哑人士和5名手语翻译者的实验表明，可编辑界面和参与式反馈显著提升了理解度、自然性、易用性和信任度，同时降低了认知负荷。系统在标准硬件上每帧推理时间低于20毫秒，适合实时通信和教育应用。这项工作展示了技术和参与式创新如何共同推动手语技术的可访问性、可解释性和用户自适应性。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [201] [Déjà Vu: Efficient Video-Language Query Engine with Learning-based Inter-Frame Computation Reuse](https://arxiv.org/abs/2506.14107)
**中文标题：Déjà Vu：基于学习型帧间计算重用的高效视频-语言查询引擎**

*Jinwoo Hwang,Daeun Kim,Sangyeop Lee,Yoonsung Kim,Guseul Heo,Hojoon Kim,Yunseok Jeong,Tadiwos Meaza,Eunhyeok Park,Jeongseob Ahn,Jongse Park*

主要分类: cs.DC

摘要简述: 本文提出Déjà Vu，一种基于学习型帧间计算重用的视频-语言查询引擎，通过改进的ReuseViT模型和内存-计算联合压缩技术，显著加速视频语言模型的嵌入生成，提升大规模视频分析的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视频语言模型（VideoLMs）依赖Vision Transformers（ViTs）逐帧处理视频，计算开销大，难以实际部署。需要一种高效方法减少计算负担，同时保持模型性能。

研究方法: 提出Déjà Vu引擎，核心为ReuseViT模型，学习检测帧间计算重用机会；结合内存-计算联合压缩技术，将计算节省转化为实际性能提升。

研究结果: 在三个VideoLM任务中，Déjà Vu将嵌入生成速度提升至多2.64倍，误差控制在2%以内，显著增强大规模视频分析的可行性。

研究结论: Déjà Vu通过计算重用和优化技术，高效加速视频语言模型，为大规模视频分析提供了实用解决方案。

中文摘要: 近年来，视频语言模型（VideoLMs）展现出强大的能力，为灵活高效的视频查询系统提供了潜力。这些模型通常依赖Vision Transformers（ViTs）逐帧提取视觉嵌入，但大规模视频的嵌入生成需要大量计算，成为实际部署的主要障碍。本文提出Déjà Vu，一种视频-语言查询引擎，通过重用连续帧间的计算加速ViT-based VideoLMs。其核心是ReuseViT，一种专为VideoLM任务设计的改进ViT模型，学习检测帧间重用机会，平衡准确性与重用效率。尽管ReuseViT显著减少计算量，但这些节省未直接转化为GPU性能提升。为此，Déjà Vu集成内存-计算联合压缩技术，将计算节省转化为实际性能提升。在三个VideoLM任务上的评估表明，Déjà Vu在2%误差范围内将嵌入生成速度提升至多2.64倍，极大增强了VideoLMs在大规模视频分析中的实用性。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [202] [Balancing Preservation and Modification: A Region and Semantic Aware Metric for Instruction-Based Image Editing](https://arxiv.org/abs/2506.13827)
**中文标题：平衡保留与修改：一种基于区域和语义感知的指令图像编辑评估指标**

*Zhuoying Li,Zhu Xu,Yuxin Peng,Yang Liu*

主要分类: cs.GR

摘要简述: 本文提出了一种名为BPM的新指标，专门用于评估基于指令的图像编辑质量，通过分离编辑相关与无关区域，实现全面且可解释的质量评估。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于指令的图像编辑缺乏全面的评估指标，现有指标要么依赖高成本的人工评估，要么无法兼顾编辑相关与无关区域的质量，导致评估偏差。

研究方法: BPM指标通过定位编辑相关区域，采用两阶段评估：区域感知判断编辑区域的位置和大小是否符合指令，语义感知判断编辑内容合规性及无关区域的内容保留。

研究结果: 实验表明，BPM指标在综合指令编辑数据上表现最佳，与人工评估的契合度最高，且其定位功能可提升编辑方法的质量。

研究结论: BPM是一种高效且全面的评估指标，适用于基于指令的图像编辑任务，并能提升编辑方法的性能。

中文摘要: 基于指令的图像编辑旨在根据指令修改图像的同时保留无关内容，已取得显著进展，但仍缺乏全面的评估指标。现有指标要么依赖高成本的人工评估，阻碍大规模应用，要么从其他任务迁移而来，无法兼顾编辑相关与无关区域的评估，导致偏差。为此，我们提出了一种名为BPM的新指标，通过明确分离编辑相关与无关区域，实现针对性评估。首先定位编辑相关区域，随后采用两阶段评估：区域感知判断编辑区域的位置和大小是否符合指令，语义感知进一步评估编辑相关区域的指令合规性及无关区域的内容保留，提供全面且可解释的质量评估。此外，BPM的编辑相关区域定位功能可整合到图像编辑方法中，提升编辑质量，展现其广泛适用性。我们在综合指令编辑数据上验证了BPM的有效性，结果显示其与人工评估的契合度最高，优于现有指标。代码发布于：https://joyli-x.github.io/BPM/

</details>


### [203] [Innovating China's Intangible Cultural Heritage with DeepSeek + MidJourney: The Case of Yangliuqing theme Woodblock Prints](https://arxiv.org/abs/2506.14104)
**中文标题：利用DeepSeek + MidJourney创新中国非物质文化遗产：以杨柳青主题木版年画为例**

*RuiKun Yang,ZhongLiang Wei,Longdi Xian*

主要分类: cs.GR

摘要简述: 本研究通过结合DeepSeek和MidJourney技术，创新性地生成以杨柳青木版年画为主题的抗击COVID-19和欢乐获胜者图像。该方法在FID评分中表现最佳，且参与者反馈显示其最具代表性和文化推广价值。


<details>
  <summary>详细信息</summary>
研究动机: 杨柳青木版年画作为中国非物质文化遗产，其传统艺术形式在保护与创新之间存在挑战。研究旨在探索如何通过现代AI技术为其注入新活力，同时保持文化传承。

研究方法: 研究采用DeepSeek生成主题提示，MidJourney生成主题图像，并结合原始杨柳青年画和DeepSeek生成的关键提示。通过FID评分和62名参与者的问卷反馈评估效果。

研究结果: 混合方法在FID评分中表现最优（均值为150.2，标准差为4.9），且参与者认为其最具代表性，并表现出最高的文化推广意愿和消费兴趣。

研究结论: 结合传统艺术元素与现代AI技术的创新方法，既能有效保护文化遗产，又能赋予其当代意义，为非物质文化遗产的传承与发展提供了新思路。

中文摘要: 杨柳青木版年画作为中国非物质文化遗产的代表，以其精美的设计和鲜艳的色彩闻名。然而，如何在保护传统艺术的同时推动创新成为一大挑战。本研究探索了DeepSeek + MidJourney方法，用于生成以抗击COVID-19和欢乐获胜者为主题的创意杨柳青木版年画。通过Fréchet Inception Distance（FID）评分评估，结合DeepSeek生成的主题提示、MidJourney生成的主题图像、原始杨柳青年画以及DeepSeek在MidJourney输出中生成的关键提示的方法，取得了最低的FID均值（150.2）和最小的变异性（σ = 4.9）。此外，通过问卷收集的62名参与者的反馈证实，这种混合方法生成的图像最具代表性。问卷数据还显示，参与者对这种AI生成图像的文化推广意愿和消费兴趣最高。这些发现表明，将传统艺术元素与现代AI驱动的创造力无缝结合，既能确保文化保护，又能赋予其当代意义。

</details>


### [204] [ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies](https://arxiv.org/abs/2506.14315)
**中文标题：ImmerseGen：基于Alpha纹理代理的智能体引导沉浸式世界生成**

*Jinyan Yuan,Bangbang Yang,Keke Wang,Panwang Pan,Lin Ma,Xuehai Zhang,Xiao Liu,Zhaopeng Cui,Yuewen Ma*

主要分类: cs.GR

摘要简述: ImmerseGen提出了一种基于代理的轻量级3D场景生成框架，通过合成RGBA纹理实现高真实感，同时支持实时渲染，显著简化了传统复杂建模流程。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D场景生成方法依赖高精度网格建模或大量3D高斯模型，导致流程复杂或视觉真实感不足。本文旨在通过轻量级代理和纹理合成技术，简化建模流程并提升沉浸体验。

研究方法: ImmerseGen采用分层轻量几何代理（如简化地形和广告牌网格）表示场景，并通过合成RGBA纹理实现高真实感。提出地形条件纹理化和RGBA资产纹理化技术，结合基于VLM的建模代理实现自动化场景生成。

研究结果: 实验表明，ImmerseGen在场景生成和实时VR展示中，相比现有方法具有更高的视觉真实感、空间一致性和渲染效率。

研究结论: ImmerseGen通过轻量代理和纹理合成技术，显著简化了3D场景生成流程，同时实现了高真实感和实时渲染能力，为移动VR设备提供了紧凑的解决方案。

中文摘要: 自动生成3D场景以实现沉浸式VR体验是数十年来研究的重点。然而，现有方法通常依赖高多边形网格建模后简化或大量3D高斯模型，导致流程复杂或视觉真实感有限。本文证明，实现引人入胜的沉浸体验无需如此复杂的建模。我们提出ImmerseGen，一种基于智能体引导的紧凑且高真实感的世界建模框架。ImmerseGen将场景表示为轻量几何代理（如简化地形和广告牌网格）的分层组合，并通过在这些代理上合成RGBA纹理生成高真实感外观。具体而言，我们提出地形条件纹理化技术用于用户中心的基础世界合成，以及RGBA资产纹理化技术用于中景和前景场景。这一重构具有以下优势：(i) 通过智能体引导生成模型生成与场景无缝融合的纹理，简化建模；(ii) 绕过复杂几何创建与简化，直接在代理上合成高真实感纹理，保持视觉质量；(iii) 提供适合移动VR头显实时渲染的紧凑表示。为实现基于文本提示的自动化场景生成，我们引入基于VLM的建模代理，结合语义网格分析提升空间推理和资产定位准确性。ImmerseGen还通过动态效果和环境音频增强场景，支持多感官沉浸。场景生成和实时VR展示实验表明，ImmerseGen在视觉真实感、空间一致性和渲染效率上优于现有方法。项目网页：https://immersegen.github.io。

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [205] [DeepSeq: High-Throughput Single-Cell RNA Sequencing Data Labeling via Web Search-Augmented Agentic Generative AI Foundation Models](https://arxiv.org/abs/2506.13817)
**中文标题：DeepSeq：基于网络搜索增强的生成式AI基础模型的单细胞RNA测序数据高通量标注**

*Saleem A. Al Dajani,Abel Sanchez,John R. Williams*

主要分类: q-bio.GN

摘要简述: 本文提出了一种基于生成式AI基础模型和实时网络搜索的方法DeepSeq，用于自动化标注单细胞RNA测序数据，准确率高达82.5%，解决了监督学习中人工标注的瓶颈问题。


<details>
  <summary>详细信息</summary>
研究动机: 单细胞RNA测序数据规模迅速扩大至数十亿细胞，传统人工标注效率低且易出错。本文旨在通过生成式AI基础模型结合实时网络搜索，实现高效自动化标注，推动虚拟细胞基础模型的发展。

研究方法: 采用生成式AI基础模型结合实时网络搜索技术，自动化标注单细胞RNA测序数据。通过代理式模型提升标注效率，减少人工干预。

研究结果: 实验表明，该方法标注准确率达到82.5%，显著提高了标注吞吐量，为大规模扰动筛查提供了可靠支持。

研究结论: DeepSeq展示了生成式AI在生物医学领域的创新应用，未来可能超越人工标注性能，推动健康监测和诊断技术的发展。

中文摘要: 生成式AI基础模型为处理结构化生物数据（尤其是单细胞RNA测序数据）提供了变革性潜力，这些数据正迅速扩展至数十亿细胞规模。我们提出了一种结合实时网络搜索的代理式基础模型方法，用于自动化标注实验数据，准确率高达82.5%。这解决了监督学习中结构化组学数据标注的瓶颈问题，提高了标注吞吐量，避免了人工标注的误差。我们的方法支持开发虚拟细胞基础模型，用于下游任务（如细胞分型和扰动预测）。随着数据量的增长，这些模型可能在标注性能上超越人类，为大规模扰动筛查的可靠推断铺平道路。这一应用展示了健康监测和诊断领域的创新，与人类细胞图谱和人类肿瘤图谱网络等计划相呼应。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [206] [LittleBit: Ultra Low-Bit Quantization via Latent Factorization](https://arxiv.org/abs/2506.13771)
**中文标题：LittleBit：通过潜在分解实现超低比特量化**

*Banseok Lee,Dongkyu Kim,Youngcheon You,Youngmin Kim*

主要分类: cs.LG

摘要简述: 本文提出LittleBit方法，通过潜在矩阵分解和双符号-值独立分解（Dual-SVID）实现超低比特量化（如0.1 BPW），显著减少LLM内存占用（如Llama2-13B降至0.9 GB），并通过多尺度补偿机制提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）部署面临高内存和计算成本问题，现有量化方法在低于1比特时性能下降严重。LittleBit旨在解决这一挑战，实现极低比特量化下的高效模型压缩。

研究方法: LittleBit采用潜在矩阵分解表示权重，并进行二值化处理；引入多尺度补偿机制（行、列和潜在维度）以弥补信息损失；提出Dual-SVID和残差补偿技术优化训练过程。

研究结果: 实验表明，LittleBit在0.1 BPW下性能优于现有方法（如Llama2-7B性能超过0.7 BPW的领先方法），内存减少31倍，内核级测试显示比FP16快5倍。

研究结论: LittleBit为资源受限环境部署高效LLM提供了新途径，实现了尺寸与性能的优异平衡。

中文摘要: 部署大型语言模型（LLM）常面临高内存和计算成本的挑战。量化是一种解决方案，但在低于1比特的量化范围内性能下降尤为严重。本文提出LittleBit，一种实现极端LLM压缩的新方法，目标为0.1比特每权重（BPW），内存减少近31倍（例如Llama2-13B压缩至0.9 GB以下）。LittleBit通过潜在矩阵分解表示权重，并对这些因子进行二值化。为弥补极端精度下的信息损失，它集成了多尺度补偿机制，包括行、列和一个额外的潜在维度（学习每秩重要性）。两项关键贡献确保了有效训练：双符号-值独立分解（Dual-SVID）用于稳定量化感知训练（QAT）初始化，以及集成残差补偿以减少误差。大量实验证实了LittleBit在低于1比特量化中的优势：例如，其在Llama2-7B上的0.1 BPW性能超越了领先方法的0.7 BPW。这确立了更优的尺寸-性能权衡，内核级基准测试显示其比FP16快5倍。LittleBit为在资源受限环境中部署强大LLM铺平了道路。

</details>


### [207] [MobiEdit: Resource-efficient Knowledge Editing for Personalized On-device LLMs](https://arxiv.org/abs/2506.13772)
**中文标题：MobiEdit：面向个性化设备端大型语言模型的资源高效知识编辑**

*Zhenyan Lu,Daliang Xu,Dongqi Cai,Zexi Li,Wei Liu,Fangming Liu,Shangguang Wang,Mengwei Xu*

主要分类: cs.LG

摘要简述: MobiEdit是一种高效的移动知识编辑框架，首次实现在商用移动设备上对大型语言模型（LLM）进行个性化知识编辑，通过量化前向梯度估计替代资源密集的反向传播，显著降低内存、能耗和延迟。


<details>
  <summary>详细信息</summary>
研究动机: 预训练的大型语言模型（LLM）在处理个性化或未见过的查询时容易产生幻觉，导致错误或过时的回答。现有的知识编辑方法因依赖资源密集的反向传播（BP）而无法在移动设备上运行。

研究方法: MobiEdit采用量化前向梯度估计替代全精度反向传播，使其兼容移动神经处理单元（NPU）。优化包括自适应成功终止的早期停止机制和跨步骤计算重用的前缀缓存。

研究结果: 在商用移动设备上，MobiEdit实现了对3B参数模型（Qwen2.5-3B-Instruct）的实时编辑，内存减少7.6倍，能耗降低14.7倍，延迟减少3.6倍。

研究结论: MobiEdit为移动设备上的LLM个性化知识编辑提供了高效解决方案，显著提升了资源利用效率。

中文摘要: 大型语言模型（LLM）被部署在移动设备上以支持智能助手等关键应用。预训练于通用语料的LLM在处理个性化或未见查询时容易产生幻觉，导致错误或过时的回答。知识编辑通过识别并调整模型权重的关键部分来解决这一问题，同时不损害通用知识。然而，现有的知识编辑方法因依赖资源密集的反向传播（BP）而无法在本地设备上运行。我们提出了MobiEdit，首个移动知识编辑框架，可在商用移动设备上高效实现LLM个性化。MobiEdit用量化前向梯度估计替代全精度反向传播，从而兼容能效优化的移动神经处理单元（NPU）。为进一步提升梯度估计效率，我们引入了两项优化：自适应成功终止的早期停止机制和跨步骤计算重用的前缀缓存。我们的方法在商用移动设备上实现了对3B参数模型（Qwen2.5-3B-Instruct）的实时编辑，内存减少7.6倍，能耗降低14.7倍，延迟减少3.6倍。

</details>


### [208] [Solving the Job Shop Scheduling Problem with Graph Neural Networks: A Customizable Reinforcement Learning Environment](https://arxiv.org/abs/2506.13781)
**中文标题：用图神经网络解决作业车间调度问题：一个可定制的强化学习环境**

*Pablo Ariño Fernández*

主要分类: cs.LG

摘要简述: 本文提出JobShopLib，一个模块化库，用于定制化解决作业车间调度问题（JSSP）的图神经网络（GNN）训练环境，并通过模仿学习训练调度器，展示了其灵活性和性能。


<details>
  <summary>详细信息</summary>
研究动机: 作业车间调度问题（JSSP）是一个NP难组合优化问题，传统方法依赖简单启发式规则。尽管深度学习模型（如GNN）有望替代传统方法，但缺乏模块化工具使得实验和研究耗时。本文旨在填补这一空白。

研究方法: 开发了JobShopLib模块化库，支持定制图表示、节点特征、动作空间和奖励函数。通过模仿学习训练多个调度器，并验证其性能。

研究结果: 一个仅使用单个操作特征的GNN模型优于多种基于图的调度器，并在大规模问题上接近最优结果，凸显了特征定制的重要性。

研究结论: JobShopLib为未来研究提供了必要的工具，表明此类模型仍有显著改进空间。

中文摘要: 作业车间调度问题是一个与制造和时间表相关的NP难组合优化问题。传统方法基于简单启发式规则使用优先级调度规则。最近的研究尝试用深度学习模型（尤其是图神经网络GNN）替代这些规则，通过学习数据分配优先级。然而，训练此类模型需要定制众多因素：图表示、节点特征、动作空间和奖励函数。缺乏模块化实验库使得研究耗时。本文介绍了JobShopLib，一个模块化库，允许定制这些因素并通过其强化学习环境创建新组件。我们通过模仿学习训练了多个调度器以展示该环境的实用性。一个模型仅使用单个操作特征就优于多种基于图的调度器，凸显了特征定制的重要性。我们的GNN模型在大规模问题上取得了接近最优的结果。这些结果表明此类模型仍有显著改进空间。JobShopLib为未来实验提供了必要工具。

</details>


### [209] [Enhancing Bagging Ensemble Regression with Data Integration for Time Series-Based Diabetes Prediction](https://arxiv.org/abs/2506.13786)
**中文标题：通过数据集成增强装袋集成回归模型用于基于时间序列的糖尿病预测**

*Vuong M. Ngo,Tran Quang Vinh,Patricia Kearney,Mark Roantree*

主要分类: cs.LG

摘要简述: 本文提出了一种增强的装袋集成回归模型（EBMBag+），用于时间序列预测，以预测美国城市的糖尿病患病率。通过数据整合和模型优化，EBMBag+在多个指标上表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 糖尿病是一种慢性代谢疾病，准确预测其患病率对医疗规划和干预至关重要。然而，现有数据往往不完整，因此需要整合数据并开发更高效的预测模型。

研究方法: 研究首先通过数据工程整合2011年至2021年的糖尿病相关数据集，构建全面的特征集。随后提出EBMBag+模型，并与SVMReg、BDTree、LSBoost、NN、LSTM和ERMBag等基线模型进行比较。

研究结果: 实验结果表明，EBMBag+在MAE（0.41）、RMSE（0.53）、MAPE（4.01）和R2（0.9）等指标上均优于其他模型。

研究结论: EBMBag+模型在糖尿病患病率预测中表现出色，为医疗规划和干预提供了可靠的工具。

中文摘要: 糖尿病是一种以血糖水平升高为特征的慢性代谢疾病，可能导致心脏病、肾衰竭和神经损伤等并发症。准确预测患病率对医疗规划和干预至关重要，但现有数据往往不完整。本研究首先通过数据工程整合2011年至2021年的糖尿病相关数据集，构建全面的特征集。随后提出一种增强的装袋集成回归模型（EBMBag+），用于时间序列预测，以预测美国城市的糖尿病患病率。研究比较了多种基线模型（包括SVMReg、BDTree、LSBoost、NN、LSTM和ERMBag）与EBMBag+的性能。实验结果表明，EBMBag+表现最佳，其MAE为0.41、RMSE为0.53、MAPE为4.01、R2为0.9。

</details>


### [210] [Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models](https://arxiv.org/abs/2506.13923)
**中文标题：自适应引导加速推理模型的强化学习**

*Vaskar Nath,Elaine Lau,Anisha Gunjal,Manasi Sharma,Nikhil Baharte,Sean Hendryx*

主要分类: cs.LG

摘要简述: 本文研究了通过强化学习训练推理模型（RLVR）解决新问题的过程，发现RLVR通过压缩pass@k到pass@1和“能力增益”提升性能，并提出了一种新的自适应引导算法Guide，显著提高了模型在数学等领域的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 研究如何通过强化学习训练推理模型解决新问题，探索RLVR的性能提升机制，并提出改进方法以优化模型泛化能力。

研究方法: 通过分析RLVR的性能提升机制，提出自适应引导算法Guide，动态引入提示并调整重要性采样比例，优化模型在无提示环境下的表现。

研究结果: 在7B和32B参数模型上，Guide-GRPO相比原始方法在数学基准测试中实现了高达4%的宏观平均提升。

研究结论: Guide算法通过自适应引导显著提升了推理模型的泛化能力，为强化学习在复杂推理任务中的应用提供了新思路。

中文摘要: 我们研究了通过可验证奖励的强化学习（RLVR）训练的推理模型如何学习解决新问题。发现RLVR通过两种主要方式提升性能：（1）将pass@k压缩为pass@1；（2）通过“能力增益”使模型解决此前无法解决的问题。尽管能力增益存在于不同规模的模型中，但解决新问题的能力主要通过自蒸馏驱动。我们在0.5B至72B规模的模型上验证了这些发现，涉及数学、科学和代码领域的50多万个推理问题。进一步表明，通过自然语言引导模型在上下文中思考，同时要求其从头推导解决方案链，可以显著提高pass@k率。基于这些发现，我们提出了Guide——一类新的在线训练算法。Guide自适应地将提示引入初始错误的上下文，并调整“离策略”轨迹的重要性采样比例，以优化无提示环境下的策略。我们描述了Guide在GRPO和PPO中的变体，并在7B和32B参数模型上实证显示，Guide-GRPO相比原始方法在数学基准测试中实现了高达4%的宏观平均提升。通过详细消融实验分析Guide的组件，并从理论上分析了其学习效率。

</details>


### [211] [AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science](https://arxiv.org/abs/2506.13992)
**中文标题：AssistedDS：评估外部领域知识如何辅助大语言模型实现自动化数据科学**

*An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding*

主要分类: cs.LG

摘要简述: 研究通过AssistedDS基准测试评估大语言模型（LLMs）在数据科学任务中利用外部领域知识的能力，发现LLMs在对抗性信息下表现不佳，且难以有效利用有益知识。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在自动化数据科学工作流中表现突出，但其是否能像人类数据科学家一样批判性利用外部领域知识尚不明确。研究旨在填补这一空白。

研究方法: 研究设计了AssistedDS基准，包含合成数据集和真实Kaggle竞赛数据，并配以有益和对抗性文档，评估LLMs在数据清理、特征工程和模型选择中的表现。

研究结果: 研究发现：(1) LLMs易盲目采纳信息，对抗性内容显著降低其预测性能；(2) 有益指导难以抵消对抗性信息的负面影响；(3) LLMs在处理时间序列数据和分类变量时易出错。

研究结论: 当前LLMs在批判性评估和利用专家知识方面存在显著不足，需进一步研究开发更鲁棒的自动化数据科学系统。

中文摘要: 大语言模型（LLMs）推动了数据科学工作流的自动化，但其是否能像人类数据科学家一样批判性利用外部领域知识尚不明确。为解答这一问题，我们提出了AssistedDS（辅助数据科学）基准，用于系统评估LLMs在表格预测任务中处理领域知识的能力。AssistedDS包含具有明确生成机制的合成数据集和真实Kaggle竞赛数据，每项任务均配有精心筛选的有益和对抗性文档，涵盖数据清理、特征工程和模型选择等领域知识。我们评估了前沿LLMs在辨别和应用有益与有害知识方面的能力，包括提交有效性、信息召回和预测性能。研究结果揭示了三点关键发现：(1) LLMs常盲目采纳信息，对抗性内容显著降低其预测性能；(2) 有益指导往往难以抵消对抗性信息的负面影响；(3) 在Kaggle数据集中，LLMs在处理时间序列数据、跨不同折叠应用一致特征工程及正确解释分类变量时易出错。这些发现凸显了当前模型在批判性评估和利用专家知识方面的重大不足，为开发更鲁棒、知识感知的自动化数据科学系统指明了研究方向。

</details>


### [212] [Quantifying Structure in CLIP Embeddings: A Statistical Framework for Concept Interpretation](https://arxiv.org/abs/2506.13831)
**中文标题：量化CLIP嵌入中的结构：一种概念解释的统计框架**

*Jitian Zhao,Chenghui Li,Frederic Sala,Karl Rohe*

主要分类: cs.LG

摘要简述: 本文提出了一种统计框架，用于量化CLIP嵌入中的结构，并通过假设检验验证概念的稳健性，同时提出了一种后验概念分解方法，显著提升了重建精度和概念可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于概念的方法在解释深度神经网络（如CLIP）嵌入时缺乏统计严谨性，难以验证概念的有效性或比较不同技术。本文旨在填补这一空白，提供一种量化嵌入空间结构的统计框架。

研究方法: 引入了一种假设检验框架，用于量化CLIP嵌入空间中对旋转敏感的结构。随后提出了一种后验概念分解方法，该方法具有理论保证，能够发现稳健且可复现的概念模式。

研究结果: 实验表明，该方法在重建误差上优于现有技术，并在消除数据中的虚假线索后，将最差组准确率提升了22.6%。

研究结论: 本文提出的框架不仅提升了概念的可解释性和重建精度，还能有效减少数据中的虚假相关性，为模型解释提供了更可靠的工具。

中文摘要: 基于概念的方法旨在从深度神经网络模型（如CLIP）的内部表示中识别人类可理解的概念，是解释模型行为的一种有前景的方法。然而，当前方法缺乏统计严谨性，难以验证识别的概念或比较不同技术。为解决这一问题，我们引入了一种假设检验框架，用于量化CLIP嵌入空间中对旋转敏感的结构。一旦识别出这些结构，我们提出了一种后验概念分解方法。与现有方法不同，该方法具有理论保证，能够发现稳健且可复现的概念模式（而非方法特定的伪影），并在重建误差上优于其他技术。实验表明，我们的概念分解算法在重建精度与概念可解释性之间取得了良好平衡，并有助于减少数据中的虚假线索。在应用于一个流行的虚假相关数据集时，我们的方法在去除虚假背景概念后，最差组准确率提升了22.6%。

</details>


### [213] [Evolvable Conditional Diffusion](https://arxiv.org/abs/2506.13834)
**中文标题：可进化条件扩散**

*Zhao Wei,Chin Chun Ooi,Abhishek Gupta,Jian Cheng Wong,Pao-Hsiung Chiu,Sheares Xue Wen Toh,Yew-Soon Ong*

主要分类: cs.LG

摘要简述: 本文提出了一种可进化的条件扩散方法，用于利用黑箱、不可微的多物理模型（如计算流体动力学和电磁学中的常见模型）指导生成过程，以促进自主科学发现。该方法通过优化描述性统计量实现目标函数的优化，无需计算导数。


<details>
  <summary>详细信息</summary>
研究动机: 科学领域中广泛存在黑箱、不可微的多物理模型（如计算流体动力学和电磁学模型），这些模型难以直接用于指导生成过程。本文旨在提出一种无需计算导数的扩散方法，利用这些模型实现高效的生成优化。

研究方法: 本文提出了一种基于概率进化的可进化条件扩散方法。通过优化去噪分布的描述性统计量，实现对目标函数的优化。最终推导出的更新算法类似于基于梯度的扩散模型，但无需计算任何导数。

研究结果: 在流体拓扑和超表面设计的两个AI科学场景中验证了该方法的有效性。结果表明，该方法能够生成更符合特定优化目标的设计，且不依赖于可微代理模型。

研究结论: 本文提出的可进化扩散方法为利用黑箱、不可微多物理模型提供了有效途径，能够在不依赖导数的情况下实现高效的生成优化。

中文摘要: 本文提出了一种可进化的条件扩散方法，使得黑箱、不可微的多物理模型（如计算流体动力学和电磁学中的常见模型）能够有效用于指导生成过程，以促进自主科学发现。我们将指导问题表述为一个优化问题，通过更新去噪分布的描述性统计量来优化目标函数，并从概率进化的角度推导出一种进化引导方法。有趣的是，最终推导出的更新算法类似于常见的基于梯度的扩散模型，但无需计算任何导数。我们在两个AI科学场景（流体拓扑和超表面的自动化设计）中验证了所提出的可进化扩散算法。结果表明，该方法能够有效生成更符合特定优化目标的设计，且不依赖于可微代理模型，为基于指导的扩散提供了一种有效手段，能够充分利用科学领域中常见的黑箱、不可微多物理数值模型。

</details>


### [214] [Robustness of Reinforcement Learning-Based Traffic Signal Control under Incidents: A Comparative Study](https://arxiv.org/abs/2506.13836)
**中文标题：基于强化学习的交通信号控制在事件中的鲁棒性：一项对比研究**

*Dang Viet Anh Nguyen,Carlos Lima Azevedo,Tomer Toledo,Filipe Rodrigues*

主要分类: cs.LG

摘要简述: 本文研究了基于强化学习的交通信号控制（RL-TSC）在交通事件中的鲁棒性，提出了T-REX仿真框架，并发现分层协调方法在动态场景中表现更稳定。


<details>
  <summary>详细信息</summary>
研究动机: 尽管RL-TSC在提升城市交通效率方面表现出潜力，但其在真实交通事件中的鲁棒性尚未充分研究。本文旨在填补这一空白。

研究方法: 开发了T-REX仿真框架，模拟交通事件下的动态场景，并提出了一套评估鲁棒性的指标，用于测试多种RL-TSC方法。

研究结果: 实验表明，独立值基和分散压力基方法在稳定条件下表现良好，但在事件驱动的分布变化中性能下降；分层协调方法在复杂网络中表现更稳定。

研究结论: RL-TSC研究需关注鲁棒性设计，T-REX为动态场景下的方法评估提供了标准化平台。

中文摘要: 基于强化学习的交通信号控制（RL-TSC）已成为改善城市交通流动性的有前景方法，但其在真实交通事件中的鲁棒性仍未被充分探索。本研究提出了T-REX，一个基于SUMO的开源仿真框架，用于在动态事件场景下训练和评估RL-TSC方法。T-REX通过模拟驾驶员的概率性改道、速度适应和上下文换道，实现了事件下拥堵传播的仿真。为评估鲁棒性，我们提出了一套超越传统交通效率指标的度量标准。通过在合成和真实网络中的大量实验，我们展示了T-REX在多种实际部署范式下对多种先进RL-TSC方法的评估能力。结果表明，独立值基和分散压力基方法在稳定交通条件和同质网络中具有快速收敛和泛化能力，但在事件驱动的分布变化中性能急剧下降。相比之下，分层协调方法在大规模不规则网络中表现更稳定和适应性强，但其收敛速度较慢且训练复杂度较高。这些发现强调了RL-TSC研究中鲁棒性设计和评估的必要性。T-REX通过提供一个开放、标准化且可复现的平台，为动态和干扰性交通场景下的RL方法基准测试做出了贡献。

</details>


### [215] [Sustainable Machine Learning Retraining: Optimizing Energy Efficiency Without Compromising Accuracy](https://arxiv.org/abs/2506.13838)
**中文标题：可持续的机器学习重训练：在不牺牲准确性的前提下优化能源效率**

*Lorena Poenaru-Olaru,June Sallou,Luis Cruz,Jan Rellermeyer,Arie van Deursen*

主要分类: cs.LG

摘要简述: 本文研究了机器学习模型重训练中的能源效率问题，提出仅使用最新数据或按需重训练的方法，可显著降低能耗而不影响准确性。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习系统需定期重训练以应对数据变化，但传统重训练方法能耗高，对环境造成负担。本文旨在探索更节能的重训练技术，同时保持模型准确性。

研究方法: 研究比较了多种重训练技术的能源消耗和准确性，包括仅使用最新数据和按需重训练两种方法。通过实验验证其节能效果。

研究结果: 仅使用最新数据重训练可降低25%能耗；按需重训练则可减少40%能耗，前提是配备可靠的数据变化检测器。

研究结论: 本文为机器学习从业者提供了节能重训练技术的建议，有助于设计更可持续的机器学习系统。

中文摘要: 机器学习（ML）软件系统的可靠性受数据随时间变化的影响很大。因此，ML系统需要定期维护，通常基于模型重训练。然而，重训练需要大量计算资源，能耗高，引发了对其环境影响的担忧。为了解在设计可持续ML应用时应考虑哪些重训练技术，本研究探讨了常见重训练技术的能源消耗。由于ML系统的准确性同样重要，我们从能源效率和准确性两方面比较了重训练技术。研究表明，与使用所有可用数据相比，仅使用最新数据重训练可降低25%的能耗，是一种可持续的替代方案。此外，我们的发现表明，仅在检测到更新必要时才重训练模型（而非按固定时间表），可减少40%的能耗，前提是配备可靠的数据变化检测器。这些发现为ML从业者提供了更好的建议，指导他们在设计可持续ML软件系统时采用更节能的重训练技术。

</details>


### [216] [Improving LoRA with Variational Learning](https://arxiv.org/abs/2506.14280)
**中文标题：通过变分学习改进LoRA**

*Bai Cong,Nico Daheim,Yuesong Shen,Rio Yokota,Mohammad Emtiyaz Khan,Thomas Möllenhoff*

主要分类: cs.LG

摘要简述: 本文提出使用变分学习算法IVON改进LoRA微调，显著提升多项指标（如准确率和校准误差），同时保持计算成本与AdamW相当。


<details>
  <summary>详细信息</summary>
研究动机: 现有贝叶斯方法虽能改进LoRA微调的校准效果，但对其他指标（如准确率）提升有限甚至有害，且计算开销大。本文旨在通过IVON算法解决这些问题。

研究方法: 采用变分算法IVON结合后验剪枝技术，对LoRA微调进行优化，并在大规模LLM（如Llama和Qwen系列）上验证其效果。

研究结果: 在Llama-3.2-3B模型上，IVON将准确率提升1.3%，校准误差降低5.4%，优于AdamW及其他贝叶斯方法（如Laplace-LoRA和BLoB）。

研究结论: 变分学习算法IVON能高效改进LoRA微调，显著提升性能指标且计算成本低。

中文摘要: 贝叶斯方法近期被用于改进LoRA微调，虽能提升校准效果，但对其他指标（如准确率）影响甚微甚至有害，且增加了计算开销。本文通过变分算法IVON解决了这些问题。IVON易于实现，计算成本与AdamW相当，并通过简单的后验剪枝技术显著提升多项指标。我们在十亿级LLM（如Llama和Qwen系列）上进行了广泛实验，远超IVON现有应用规模。例如，在Llama-3.2-3B模型上进行常识推理任务微调，准确率比AdamW提升1.3%，校准误差降低5.4%，优于AdamW及其他贝叶斯方法（如Laplace-LoRA和BLoB）。结果表明，IVON变分学习能有效改进LoRA微调。

</details>


### [217] [StaQ it! Growing neural networks for Policy Mirror Descent](https://arxiv.org/abs/2506.13862)
**中文标题：StaQ算法：为策略镜像下降构建神经网络**

*Alena Shilova,Alex Davey,Brahim Driss,Riad Akrour*

主要分类: cs.LG

摘要简述: 本文提出了一种名为StaQ的新算法，解决了强化学习中策略镜像下降（PMD）因存储所有历史Q函数而导致的实践难题，通过仅保留最近的M个Q函数，实现了高效且稳定的策略优化。


<details>
  <summary>详细信息</summary>
研究动机: 在强化学习中，正则化工具（如熵奖励或KL散度）虽能提升探索性和稳定性，但策略镜像下降（PMD）的理论框架因需存储所有历史Q函数而难以实际应用。本文旨在解决这一问题，提出一种高效且稳定的PMD实现方法。

研究方法: 提出StaQ算法，仅保留最近的M个Q函数，避免存储所有历史数据。通过理论分析证明，当M足够大时，算法能实现收敛且不引入策略更新误差。

研究结果: StaQ算法在理论上具有强保证，实际表现与深度强化学习基线竞争，且性能波动更小，为完全稳定的深度强化学习算法提供了可能。

研究结论: StaQ算法通过简化PMD的实现，解决了存储问题，同时保持了理论优势和实际性能，为深度强化学习的稳定性研究提供了新方向。

中文摘要: 在强化学习（RL）中，正则化已成为理论和实践中常用的工具，通常基于熵奖励或KL散度来约束连续策略。实践中，这些方法提升了探索性、鲁棒性和稳定性，催生了SAC和TRPO等流行算法。策略镜像下降（PMD）是解决此类正则化策略优化问题的理论框架，但其闭式解需存储所有历史Q函数，实际中难以实现。本文提出并分析了一种仅保留最近M个Q函数的PMD类算法，证明当M足够大时，可导出收敛算法且不引入策略更新误差。最终算法StaQ具有强理论保证，与深度RL基线竞争，且性能波动更小，为完全稳定的深度RL算法铺平了道路，并为PMD实验提供了测试平台。

</details>


### [218] [TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization](https://arxiv.org/abs/2506.14574)
**中文标题：TGDPO：利用令牌级奖励指导增强直接偏好优化**

*Mingkang Zhu,Xi Chen,Zhongdao Wang,Bei Yu,Hengshuang Zhao,Jiaya Jia*

主要分类: cs.LG

摘要简述: 本文提出TGDPO方法，通过分解序列级PPO为令牌级优化问题，并利用令牌级奖励指导DPO，显著提升了模型性能。实验显示在多个基准测试中性能提升明显。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于人类反馈的强化学习方法中，令牌级奖励模型能显著提升PPO性能，但难以直接用于DPO，因为DPO是序列级问题。本文旨在解决这一挑战。

研究方法: 将序列级PPO分解为令牌级优化问题，推导出令牌级最优策略和奖励，并基于Bradley-Terry模型设计可计算的损失函数，提出基于诱导奖励的实用指导方法。

研究结果: 实验表明，TGDPO在MT-Bench、AlpacaEval 2和Arena-Hard上分别取得7.5、6.2和4.3点的胜率提升，性能显著优于DPO。

研究结论: TGDPO通过令牌级奖励指导有效提升了DPO性能，为序列级优化问题提供了新思路。

中文摘要: 近期基于人类反馈的强化学习研究表明，利用细粒度的令牌级奖励模型可以显著提升近端策略优化（PPO）在大型语言模型对齐中的性能。然而，由于直接偏好优化（DPO）被表述为序列级赌博问题，难以将此类令牌级奖励作为指导。为解决这一挑战，本研究将序列级PPO分解为一系列令牌级近端策略优化问题，并在此基础上推导出令牌级最优策略及对应的令牌级奖励。利用所得奖励和Bradley-Terry模型，本研究建立了一个基于令牌级奖励指导的可计算损失函数框架，并提出了一种基于诱导DPO奖励的实用指导方法。这一方法使得不同令牌可以根据其奖励表现出不同程度的参考策略偏离。实验结果表明，我们的方法在MT-Bench、AlpacaEval 2和Arena-Hard上分别实现了7.5、6.2和4.3点的胜率提升，性能显著优于DPO。代码发布于https://github.com/dvlab-research/TGDPO。

</details>


### [219] [Scaling Algorithm Distillation for Continuous Control with Mamba](https://arxiv.org/abs/2506.13892)
**中文标题：利用Mamba扩展算法蒸馏在连续控制中的应用**

*Samuel Beaussant,Mehdi Mounsif*

主要分类: cs.LG

摘要简述: 本文提出利用S6模型（Mamba）改进算法蒸馏（AD）方法，以解决传统Transformer在连续控制任务中的计算瓶颈问题，并在复杂环境中展示了其优于Transformer的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的算法蒸馏（AD）方法因Transformer的二次复杂度限制，仅适用于简单离散环境。本文旨在通过S6模型（Mamba）解决这一问题，扩展AD在连续控制任务中的应用。

研究方法: 采用基于S6层的Mamba模型替代Transformer，利用其线性复杂度优势，在四个复杂的连续元强化学习环境中进行实验。

研究结果: 实验表明，Mamba在算法蒸馏任务中显著优于Transformer，且长上下文扩展进一步提升了性能，使其与当前最优的在线元强化学习基线竞争。

研究结论: Mamba模型为算法蒸馏在连续控制任务中的应用提供了高效解决方案，并展示了长上下文扩展的潜力。

中文摘要: 算法蒸馏（AD）最近被提出作为一种通过因果Transformer模型对跨片段训练历史进行自回归建模的新方法，用于实现上下文强化学习（ICRL）。然而，由于注意力机制的实践限制，实验受限于Transformer的二次复杂度，仅适用于时间跨度短的简单离散环境。本文提出利用最近提出的选择性结构化状态空间序列（S6）模型，该模型在长序列建模中实现了最先进的性能，同时序列长度呈线性扩展。通过在四个复杂的连续元强化学习环境中的实验，我们展示了基于S6层的Mamba模型在AD任务中优于Transformer模型的整体性能。此外，我们还表明，将AD扩展到非常长的上下文可以提升ICRL性能，使其与当前最优的在线元强化学习基线竞争。

</details>


### [220] [Enhancing interpretability of rule-based classifiers through feature graphs](https://arxiv.org/abs/2506.13903)
**中文标题：通过特征图增强规则分类器的可解释性**

*Christel Sirocchi,Damiano Verda*

主要分类: cs.LG

摘要简述: 本文提出了一种基于图的可视化框架，用于提升规则分类器的可解释性，通过新特征重要性度量和规则集比较方法，在临床数据中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 在医疗等需要透明度和可信度的领域，规则系统因其可解释性而被广泛使用。然而，随着规则系统复杂度增加，理解特征交互和贡献变得困难，亟需一种提升可解释性的方法。

研究方法: 提出了一种基于图的特征可视化策略，设计了一种与规则预测器无关的特征重要性度量，以及基于特征贡献的规则集比较方法。实验覆盖两种临床数据和四种规则方法（决策树、逻辑学习机、关联规则和规则提取神经网络）。

研究结果: 在临床数据中，该方法能够揭示特征组合的预测价值，帮助识别风险因素和生物标志物。在15个公共基准测试中，其性能与现有方法相当且更稳健。

研究结论: 该框架显著提升了规则系统的可解释性，为医疗决策提供了透明且可信的支持工具。

中文摘要: 在医疗等透明度和可信度至关重要的领域，规则系统因其固有可解释性而被广泛用于决策支持系统。然而，随着规则模型复杂度增加，识别关键特征、理解其交互以及比较不同规则集的特征贡献变得困难。为此，我们提出了一种综合框架，用于估计规则系统中的特征贡献，包括基于图的特征可视化策略、一种与规则预测器无关的新特征重要性度量，以及基于特征贡献的规则集比较方法。通过在两种临床数据和四种规则方法（决策树、逻辑学习机、关联规则和规则提取神经网络）上的实验，展示了该方法在数据集和类别层面揭示临床特征组合预测价值的能力。这些发现有助于识别新风险因素、标志基因和潜在生物标志物，并确定应优先考虑的临床信息子集以提高诊断准确性。在15个公共基准测试中，与现有方法相比，所提出的特征重要性度量表现出竞争性性能和更强的稳健性。方法实现已发布于GitHub：https://github.com/ChristelSirocchi/rule-graph。

</details>


### [221] [Few-Shot Learning for Industrial Time Series: A Comparative Analysis Using the Example of Screw-Fastening Process Monitoring](https://arxiv.org/abs/2506.13909)
**中文标题：工业时间序列的少样本学习：以螺丝紧固过程监控为例的比较分析**

*Xinyuan Tu,Haocheng Zhang,Tao Chengxu,Zuyi Chen*

主要分类: cs.LG

摘要简述: 本文通过螺丝紧固过程监控的案例，系统研究了少样本学习在工业时间序列数据中的应用，提出了一种标签感知的采样方法，并比较了不同模型的表现。结果表明，轻量级CNN结合度量学习在小数据场景下优于大型基础模型。


<details>
  <summary>详细信息</summary>
研究动机: 工业时间序列数据标注成本高昂，少样本学习在视觉领域表现优异，但在工业时间序列中尚未充分探索。本文旨在填补这一空白，探索少样本学习在螺丝紧固过程监控中的潜力。

研究方法: 研究采用了一个包含2300个样本的多变量扭矩数据集，覆盖16种单因素和多因素缺陷类型。提出了一种标签感知的片段采样器，将多标签序列分解为多个单标签任务。比较了两种少样本学习范式：基于度量的原型网络和基于梯度的MAML，分别与1D CNN、InceptionTime和341M参数的Moment Transformer结合。

研究结果: 在10-shot、3-way评估中，InceptionTime与原型网络组合在多类和多标签场景下分别达到0.944和0.935的加权F1分数，优于微调的Moment Transformer，且参数和训练时间大幅减少。度量学习在所有骨干网络中均优于MAML，标签感知采样比传统采样方法提升1.7%的F1分数。

研究结论: 研究表明，在数据稀缺时，轻量级CNN结合简单度量学习不仅收敛更快，泛化能力也更强，挑战了大型基础模型总是更优的假设。研究开源了代码、数据分割和预训练权重，以促进可重复研究和工业应用。

中文摘要: 少样本学习（FSL）在视觉领域表现出色，但在工业时间序列数据中尚未充分探索，而标注新缺陷的成本极高。本文以螺丝紧固过程监控为例，系统研究了FSL的应用，使用了一个包含2300个样本的多变量扭矩数据集，覆盖16种单因素和多因素缺陷类型。除基准测试外，我们提出了一种标签感知的片段采样器，将多标签序列分解为多个单标签任务，保持输出维度固定同时保留组合标签信息。研究比较了两种FSL范式：基于度量的原型网络和基于梯度的MAML，分别与1D CNN、InceptionTime和341M参数的Moment Transformer结合。在10-shot、3-way评估中，InceptionTime与原型网络组合在多类和多标签场景下分别达到0.944和0.935的加权F1分数，优于微调的Moment Transformer，且参数和训练时间大幅减少。度量学习在所有骨干网络中均优于MAML，标签感知采样比传统采样方法提升1.7%的F1分数。这些发现挑战了大型基础模型总是更优的假设：在数据稀缺时，轻量级CNN结合简单度量学习不仅收敛更快，泛化能力也更强。我们开源了代码、数据分割和预训练权重，以促进可重复研究和工业应用。

</details>


### [222] [Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection](https://arxiv.org/abs/2506.14390)
**中文标题：基于原型变分自编码器的可解释离群检测方法**

*Conrad Orglmeister,Erik Bochinski,Volker Eiselein,Elvira Fleig*

主要分类: cs.LG

摘要简述: 本文提出了一种结合原型变分自编码器的可解释性离群检测方法，通过定义紧凑的分布内区域并引入限制损失，提升了离群检测性能，同时保持了模型的可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 深度机器学习模型在安全相关应用中的决策透明性和可靠性至关重要。本文旨在通过扩展原型变分模型，结合自编码器的离群检测能力，提供一种可解释且高效的离群检测方法。

研究方法: 采用变分自编码器学习有意义的潜在空间，用于基于距离的分类、似然估计和重建。通过高斯混合分布定义分布内区域，并引入限制损失以保持潜在空间的紧凑性。自编码器的重建能力增强了原型和分类器分布内区域的可解释性。

研究结果: 在常见离群检测基准和实际铁路应用数据集上的广泛评估表明，该方法优于现有方法，有效提升了离群检测性能。

研究结论: 本文提出的方法不仅提升了离群检测的准确性，还通过原型和重建能力增强了模型的可解释性，为安全相关应用提供了可靠支持。

中文摘要: 理解深度机器学习模型的决策并信任其可靠性对于将其应用于安全相关领域至关重要。我们扩展了自解释的原型变分模型，结合基于自编码器的离群检测方法：通过变分自编码器学习有意义的潜在空间，用于基于距离的分类、离群检测的似然估计以及重建。分布内区域由高斯混合分布定义，其原型代表每个模式的中心。此外，引入了一种新的限制损失，促进潜在空间中分布内区域的紧凑性而不使其坍缩为单点。自编码器的重建能力确保了原型和分类器分布内区域的可解释性，进一步帮助区分离群样本。在常见离群检测基准和实际铁路应用的大规模数据集上的广泛评估证明了该方法的有效性，优于现有方法。

</details>


### [223] [Logical Expressiveness of Graph Neural Networks with Hierarchical Node Individualization](https://arxiv.org/abs/2506.13911)
**中文标题：图神经网络在分层节点个性化下的逻辑表达能力**

*Arie Soeteman,Balder ten Cate*

主要分类: cs.LG

摘要简述: 本文提出了一种名为HEGNNs的图神经网络扩展模型，通过分层节点个性化增强了表达能力，能够区分同构图，并在实验中验证了其优于传统GNN架构。


<details>
  <summary>详细信息</summary>
研究动机: 传统图神经网络（GNNs）在区分同构图时表达能力有限，因此需要一种更强大的模型来提升其区分能力。

研究方法: 研究提出HEGNNs模型，采用分层节点个性化方法，结合子图限制与非限制条件，并通过逻辑刻画其节点分类能力。

研究结果: 实验证明HEGNNs在区分同构图方面优于传统GNN，且在实际应用中具有可行性。

研究结论: HEGNNs通过分层节点个性化显著提升了图神经网络的表达能力，为图同构问题提供了新的解决方案。

中文摘要: 我们提出并研究了分层自我图神经网络（HEGNNs），这是一种受图同构测试中个性化-细化范式启发的图神经网络（GNNs）表达性扩展。HEGNNs推广了子图-GNNs，并形成了一系列表达能力逐渐增强的模型，在极限情况下能够区分同构图。我们使用分级混合逻辑对HEGNN节点分类器（带或不带子图限制）进行了逻辑刻画。这一刻画使我们能够将HEGNNs的区分能力与高阶GNNs、带有局部同态计数特征的GNNs以及基于个性化-细化算法的颜色细化算法进行比较。实验结果证实了HEGNNs的实际可行性，并显示了其与传统GNN架构相比的优势，无论是否带有局部同态计数特征。

</details>


### [224] [Train Once, Forget Precisely: Anchored Optimization for Efficient Post-Hoc Unlearning](https://arxiv.org/abs/2506.14515)
**中文标题：一次训练，精确遗忘：基于锚定优化的高效后验遗忘方法**

*Prabhav Sanga,Jaskaran Singh,Arun K. Dubey*

主要分类: cs.LG

摘要简述: 本文提出了一种名为FAMR的高效后验遗忘框架，用于在深度图像分类器中精确移除特定训练样本、语义类别或视觉风格的影响，而无需完全重新训练。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习系统越来越多地依赖受隐私法规约束的数据，从训练好的模型中选择性遗忘特定信息变得至关重要。本文旨在解决图像分类中如何高效移除特定数据影响的问题。

研究方法: 作者提出了Forget-Aligned Model Reconstruction (FAMR)框架，将遗忘问题建模为一个约束优化问题，通过在遗忘集上最小化均匀预测损失，并通过ℓ2惩罚将模型参数锚定到原始值。理论分析表明FAMR的解决方案与基于影响函数的重新训练近似相关。

研究结果: 在CIFAR-10和ImageNet-100上的实验表明，FAMR在类别遗忘任务中表现优异，既能保持模型性能，又具有极低的计算开销。该框架还可推广到概念和风格擦除任务。

研究结论: FAMR为视觉模型中的高效后验遗忘提供了一种可扩展且可验证的解决方案，适用于多种遗忘任务。

中文摘要: 随着机器学习系统越来越多地依赖受隐私法规约束的数据，从训练好的模型中选择性遗忘特定信息变得至关重要。在图像分类中，这涉及移除特定训练样本、语义类别或视觉风格的影响，而无需完全重新训练。我们提出了Forget-Aligned Model Reconstruction (FAMR)，这是一个理论严谨且计算高效的后验遗忘框架。FAMR将遗忘问题建模为一个约束优化问题，通过在遗忘集上最小化均匀预测损失，并通过ℓ2惩罚将模型参数锚定到原始值。理论分析将FAMR的解决方案与基于影响函数的重新训练近似联系起来，并给出了参数和输出偏差的界限。在CIFAR-10和ImageNet-100上的类别遗忘任务中，FAMR表现出色，既能保持性能，又具有极低的计算开销。该框架还可推广到概念和风格擦除任务，为视觉模型中的高效后验遗忘提供了一种可扩展且可验证的途径。

</details>


### [225] [Toward Explainable Offline RL: Analyzing Representations in Intrinsically Motivated Decision Transformers](https://arxiv.org/abs/2506.13958)
**中文标题：迈向可解释的离线强化学习：分析内在动机决策变换器中的表示**

*Leonardo Guiducci,Antonio Rizzo,Giovanna Maria Dimitri*

主要分类: cs.LG

摘要简述: 本文通过系统性的事后可解释性框架，分析了内在动机如何影响弹性决策变换器（EDTs）的嵌入表示，揭示了不同内在动机变体如何塑造不同的表示结构，并解释了其提升策略学习性能的机制。


<details>
  <summary>详细信息</summary>
研究动机: 弹性决策变换器（EDTs）在离线强化学习中表现出色，但内在动机机制如何影响其嵌入表示尚不明确。本文旨在揭示内在动机如何通过塑造嵌入表示的结构来提升性能。

研究方法: 引入系统性的事后可解释性框架，通过统计分析嵌入特性（如协方差结构、向量大小和正交性），研究内在动机如何塑造EDTs的嵌入表示。

研究结果: 研究发现，不同内在动机变体会形成截然不同的表示结构，且嵌入指标与性能之间存在环境特定的相关性模式，解释了内在动机如何提升策略学习。

研究结论: 内在动机不仅通过探索奖励发挥作用，还作为一种表示先验，以生物学合理的方式塑造嵌入几何结构，从而促进更好的决策。

中文摘要: 弹性决策变换器（EDTs）在离线强化学习中表现出色，提供了一个将序列建模与不确定性下决策统一起来的灵活框架。近期研究表明，将内在动机机制融入EDTs可以提升探索任务的性能，但这些改进背后的表示机制尚未被探索。本文引入了一个系统性的事后可解释性框架，分析内在动机如何塑造EDTs中的学习嵌入。通过对嵌入特性（包括协方差结构、向量大小和正交性）的统计分析，我们发现不同的内在动机变体会形成根本不同的表示结构。我们的分析揭示了嵌入指标与性能之间环境特定的相关性模式，解释了内在动机如何提升策略学习。这些发现表明，内在动机不仅通过简单的探索奖励发挥作用，还作为一种表示先验，以生物学合理的方式塑造嵌入几何结构，形成环境特定的组织结构，从而促进更好的决策。

</details>


### [226] [Towards Desiderata-Driven Design of Visual Counterfactual Explainers](https://arxiv.org/abs/2506.14698)
**中文标题：面向需求驱动的视觉反事实解释器设计**

*Sidney Bender,Jan Herrmann,Klaus-Robert Müller,Grégoire Montavon*

主要分类: cs.LG

摘要简述: 本文提出一种新的视觉反事实解释器（VCE）设计方法，强调全面满足解释需求（如保真度、可理解性和充分性），而非仅关注样本质量或最小变化。作者开发了一种“平滑反事实探索器”（SCE）算法，并通过实验验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉反事实解释器（VCEs）过于关注样本质量或最小变化，忽略了更全面的解释需求（如保真度、可理解性和充分性）。本文旨在填补这一空白，探索新的反事实生成机制以满足这些需求。

研究方法: 作者提出了一种新的“平滑反事实探索器”（SCE）算法，结合了多种反事实生成机制，旨在满足保真度、可理解性和充分性等解释需求。通过合成数据和真实数据的系统评估验证其有效性。

研究结果: 实验表明，SCE算法在满足保真度、可理解性和充分性等解释需求方面优于现有方法，证明了其作为一种更全面的视觉反事实解释器的有效性。

研究结论: 本文强调了视觉反事实解释器设计中全面满足解释需求的重要性，并提出了一种有效的SCE算法。未来研究可进一步扩展其应用场景。

中文摘要: 视觉反事实解释器（VCEs）是一种直接且有望提升图像分类器透明性的方法。VCEs通过揭示机器学习模型最敏感的数据变换，补充了特征归因等其他解释类型。本文认为，现有VCEs过于关注优化样本质量或最小变化，而忽略了更全面的解释需求（如保真度、可理解性和充分性）。为弥补这一不足，我们探索了新的反事实生成机制，并研究了如何通过这些机制满足这些需求。我们将这些机制结合为一种新颖的“平滑反事实探索器”（SCE）算法，并通过合成数据和真实数据的系统评估证明了其有效性。

</details>


### [227] [HAELT: A Hybrid Attentive Ensemble Learning Transformer Framework for High-Frequency Stock Price Forecasting](https://arxiv.org/abs/2506.13981)
**中文标题：HAELT：一种混合注意力集成学习Transformer框架用于高频股票价格预测**

*Thanh Dan Bui*

主要分类: cs.LG

摘要简述: 本文提出了一种混合注意力集成学习Transformer框架（HAELT），用于高频股票价格预测，结合了ResNet降噪模块、时间自注意力机制和LSTM-Transformer混合核心，通过自适应集成提升预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 高频股票价格预测面临非平稳性、噪声和波动性等挑战，传统方法难以应对。因此，作者提出HAELT框架，旨在通过深度学习方法解决这些问题，提升预测准确性和实用性。

研究方法: HAELT框架包含三个核心组件：1）基于ResNet的降噪模块，用于减少数据噪声；2）时间自注意力机制，动态关注相关历史信息；3）LSTM-Transformer混合核心，捕捉局部和长程依赖关系。这些组件根据近期表现自适应集成。

研究结果: 在2024年1月至2025年5月的苹果公司（AAPL）每小时数据测试中，HAELT在测试集上取得了最高的F1分数，能够有效识别股价的上涨和下跌趋势。

研究结论: HAELT框架在高频股票价格预测中表现出色，具有鲁棒性和实用性，为金融预测和算法交易提供了新的解决方案。

中文摘要: 高频股票价格预测因非平稳性、噪声和波动性而具有挑战性。为解决这些问题，我们提出了混合注意力集成学习Transformer（HAELT）框架，该框架结合了基于ResNet的降噪模块、用于动态关注相关历史的时间自注意力机制，以及捕捉局部和长程依赖关系的LSTM-Transformer混合核心。这些组件根据近期表现自适应集成。在2024年1月至2025年5月的苹果公司（AAPL）每小时数据测试中，HAELT在测试集上取得了最高的F1分数，能够有效识别股价的上涨和下跌趋势。这表明HAELT在稳健、实用的金融预测和算法交易中具有潜力。

</details>


### [228] [Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders](https://arxiv.org/abs/2506.14002)
**中文标题：驯服LLM中的多义性：基于稀疏自编码器的可证明特征恢复**

*Siyu Chen,Heejune Sheen,Xuyuan Xiong,Tianhao Wang,Zhuoran Yang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于稀疏自编码器（SAE）的理论框架和算法，用于解决大型语言模型（LLM）中多义性特征的恢复问题，并通过理论证明和实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有稀疏自编码器（SAE）训练算法缺乏严格的数学保证，且存在超参数敏感性和不稳定性等实践问题。本文旨在通过理论框架和新算法解决这些问题，提升模型的可解释性和可靠性。

研究方法: 提出了一种新的统计框架，将多义性特征建模为底层单义性概念的稀疏混合。基于此框架，设计了一种基于“偏置适应”的SAE训练算法，并通过理论证明其在特定条件下能正确恢复单义性特征。进一步提出了改进的实证变体——组偏置适应（GBA）。

研究结果: 理论证明了算法在输入数据符合统计模型时能正确恢复所有单义性特征。实验表明，GBA在参数规模达15亿的LLM中优于基准方法。

研究结论: 本文为SAE训练提供了首个具有理论恢复保证的算法，推动了通过增强机制可解释性开发更透明、可信AI系统的进程。

中文摘要: 我们研究了使用稀疏自编码器（SAE）实现理论支持的特征恢复以解释大型语言模型（LLM）的挑战。现有SAE训练算法通常缺乏严格的数学保证，并存在超参数敏感性和不稳定性等实践限制。为解决这些问题，我们首先提出了一个用于特征恢复问题的新统计框架，通过将多义性特征建模为底层单义性概念的稀疏混合，引入了一种新的特征可识别性概念。基于此框架，我们提出了一种基于“偏置适应”的新SAE训练算法，该技术通过自适应调整神经网络偏置参数以确保适当的激活稀疏性。我们从理论上证明了该算法在输入数据采样自所提统计模型时能正确恢复所有单义性特征。此外，我们开发了一种改进的实证变体——组偏置适应（GBA），并展示了其在应用于参数规模达15亿的LLM时优于基准方法的性能。这项工作通过提供首个具有理论恢复保证的SAE算法，为揭开SAE训练的神秘面纱迈出了基础性一步，从而通过增强机制可解释性推动了更透明、可信AI系统的发展。

</details>


### [229] [Bures-Wasserstein Flow Matching for Graph Generation](https://arxiv.org/abs/2506.14020)
**中文标题：基于Bures-Wasserstein流匹配的图生成方法**

*Keyue Jiang,Jiahao Cui,Xiaowen Dong,Laura Toni*

主要分类: cs.LG

摘要简述: 论文提出了一种基于Bures-Wasserstein距离的流匹配框架BWFlow，用于图生成任务。该方法通过建模节点和边的联合演化，利用马尔可夫随机场表示图，并设计概率路径以优化生成过程。实验证明其在普通图生成和分子生成任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散和流模型的图生成方法通常假设数据位于欧几里得空间，独立建模节点和边的演化，忽略了图的非欧几里得结构和互联模式，可能导致采样收敛性问题。因此，需要一种更优的概率路径设计方法。

研究方法: 论文提出BWFlow框架，将图表示为马尔可夫随机场（MRF）参数化的连接系统，利用MRF对象之间的最优传输位移设计概率路径。该方法支持连续和离散流匹配算法，并尊重图的底层几何结构。

研究结果: 实验表明，BWFlow在普通图生成和2D/3D分子生成任务中表现优异，具有竞争力强的性能、稳定的训练过程和可保证的采样收敛性。

研究结论: BWFlow通过建模图的非欧几里得结构和联合演化，提供了一种高效的图生成方法，为分子设计等领域提供了新的工具。

中文摘要: 图生成已成为从分子设计到药物发现等多个领域的关键任务。当前的主流方法，如扩散模型和基于流的模型，通过构建参考分布与数据分布之间的概率路径，实现了较好的生成性能。然而，这些方法通常独立建模节点和边的演化，并假设数据位于欧几里得空间，使用线性插值构建路径。我们指出，这种做法忽略了图的固有非欧几里得结构和互联模式，可能导致采样收敛性问题。为构建更优的概率路径，我们将图表示为马尔可夫随机场（MRF）参数化的连接系统，并利用MRF对象之间的最优传输位移设计路径。基于此，我们提出了BWFlow，一种尊重图底层几何结构并提供平滑概率路径速度的流匹配框架。该框架可适配连续和离散流匹配算法。在普通图生成和2D/3D分子生成任务中的实验验证了BWFlow的有效性，其性能优越、训练稳定且采样收敛性有保障。

</details>


### [230] [Scientifically-Interpretable Reasoning Network (ScIReN): Uncovering the Black-Box of Nature](https://arxiv.org/abs/2506.14054)
**中文标题：科学可解释推理网络（ScIReN）：揭开自然的黑盒**

*Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ScIReN的透明框架，结合了可解释的神经网络和基于过程的推理，旨在解决传统神经网络无法揭示科学机制的问题。ScIReN通过预测科学意义的潜在参数，并利用可微分的过程解码器输出结果，同时通过硬Sigmoid约束层增强可解释性。实验表明，ScIReN在预测准确性和科学解释性上均优于黑盒模型。


<details>
  <summary>详细信息</summary>
研究动机: 传统神经网络虽然能从数据中学习模式，但其黑盒特性无法揭示科学规律或新机制。而基于过程的模型虽然能定量解释科学原理，但依赖大量自由参数且预测效果不佳。因此，需要一种既能结合神经网络优势，又能保持科学解释性的方法。

研究方法: 提出ScIReN框架，包含可解释编码器和基于过程的解码器。编码器预测科学意义的潜在参数，解码器通过可微分过程模型输出结果。引入硬Sigmoid约束层，限制潜在参数在科学先验知识定义的范围内，增强可解释性。

研究结果: ScIReN在模拟土壤有机碳流动和生态系统呼吸建模任务中，预测准确性优于黑盒模型，并能推断潜在科学机制及其与输入特征的关系。

研究结论: ScIReN成功结合了神经网络和基于过程模型的优势，不仅提高了预测准确性，还提供了科学解释性，为科学发现提供了新工具。

中文摘要: 神经网络是从数据中学习模式的强大工具，但由于其黑盒特性，它们无法遵循已知科学定律，也无法揭示新的科学见解。相比之下，科学推理通过观察和受控实验提炼生物或物理原理，并用基于数学方程的过程模型定量解释这些原理。然而，基于过程的模型依赖大量自由参数，这些参数通常需要临时设置，因此在跨尺度预测中往往拟合效果不佳。尽管先前的工作已将基于过程的模型嵌入传统神经网络，但发现基于过程模型中参数与输入特征之间的可解释关系仍是科学发现的重大挑战。为此，我们提出了科学可解释推理网络（ScIReN），这是一个完全透明的框架，结合了可解释的神经网络和基于过程的推理。可解释编码器预测具有科学意义的潜在参数，这些参数随后通过可微分的过程解码器预测标记的输出变量。ScIReN还使用了一种新颖的硬Sigmoid约束层，将潜在参数限制在科学先验知识定义的范围内，进一步增强了其可解释性。嵌入的基于过程模型强制执行已确立的科学知识，而编码器则揭示了传统黑盒模型中隐藏的新科学机制和关系。我们在两个任务中应用了ScIReN：模拟土壤中有机碳的流动，以及建模植物生态系统呼吸。在这两个任务中，ScIReN在预测准确性上优于黑盒网络，同时提供了显著的科学解释性——它能够推断潜在科学机制及其与输入特征的关系。

</details>


### [231] [Toward a Graph Foundation Model: Pre-Training Transformers With Random Walks](https://arxiv.org/abs/2506.14098)
**中文标题：迈向图基础模型：基于随机游走的Transformer预训练**

*Ziyuan Tang,Jie Chen*

主要分类: cs.LG

摘要简述: 本文提出了一种基于随机游走的图基础模型预训练方法，通过Transformer架构处理多样化的图数据，展示了其在图结构数据处理中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管自然语言领域的基础模型（如GPT）已取得显著成果，但图数据领域尚未有类似模型。本文旨在探索如何构建一个通用的图基础模型，以支持多样化的图数据处理任务。

研究方法: 通过将节点表示为多条随机游走序列，利用Transformer从序列中提取节点表示，进而生成边和图表示。提出了一种新颖的上下文预测损失函数，并理论分析了随机游走在区分邻域和图结构中的表达能力。

研究结果: 实验表明，该方法能够有效预训练模型，并成功适应下游任务，展示了其作为图结构数据处理基础的潜力。

研究结论: 本文提出的基于随机游走的图基础模型预训练方法为图数据处理提供了一种通用框架，未来可进一步扩展其应用范围。

中文摘要: 像GPT这样的基础模型因其广泛的数据预训练和强大的Transformer架构而展现出许多涌现能力。尽管自然语言领域的基础模型已很普遍，但我们能否为图数据构建类似的模型？本文描述了一种基于多样化图数据集预训练的图基础模型方法，通过调整Transformer架构实现。其核心挑战在于如何用序列模型编码不同规模和领域的图。我们提出将节点表示为多条随机游走序列，使得Transformer可以从序列中提取节点表示，进而生成边和图表示。我们为这些随机游走设计了一种新颖的上下文预测损失函数，并从理论上分析了其在区分邻域和图结构中的表达能力。我们还展示了模型的预训练及其在下游任务中的适应性，证明了其作为图结构数据处理和推理基础的潜力。

</details>


### [232] [SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting](https://arxiv.org/abs/2506.14113)
**中文标题：SKOLR：基于结构化Koopman算子的线性RNN时间序列预测方法**

*Yitian Zhang,Liheng Ma,Antonios Valkanas,Boris N. Oreshkin,Mark Coates*

主要分类: cs.LG

摘要简述: SKOLR是一种基于Koopman算子理论和线性RNN的时间序列预测方法，通过结构化Koopman算子和多层感知器实现高效预测。


<details>
  <summary>详细信息</summary>
研究动机: Koopman算子理论为非线性动态系统分析和时间序列预测提供了线性化框架，但其无限维特性限制了实际应用。本文旨在通过结构化Koopman算子与线性RNN的等效性，设计一种高效且可学习的预测模型。

研究方法: 提出SKOLR方法，结合可学习的输入信号谱分解和多层感知器作为测量函数，通过高度并行的线性RNN堆栈实现结构化Koopman算子。

研究结果: 在多种预测基准和动态系统上的实验表明，SKOLR基于Koopman理论的简化设计表现出卓越性能。

研究结论: SKOLR通过结合Koopman算子和线性RNN，提供了一种高效且性能优异的时间序列预测方法。

中文摘要: Koopman算子理论通过将动态映射到实值测量函数空间，为非线性动态系统分析和时间序列预测提供了线性算子表示框架。尽管线性化具有优势，但算子通常是无限维的。因此，目标是学习能够产生可处理的有限维Koopman算子近似的测量函数。本文建立了Koopman算子近似与线性循环神经网络（RNN）之间的联系，后者最近在序列建模中表现出显著成功。通过考虑由滞后观测组成的扩展状态，我们证明了结构化Koopman算子与线性RNN更新的等效性。基于这一联系，我们提出了SKOLR，它将输入信号的可学习谱分解与多层感知器（MLP）作为测量函数相结合，并通过高度并行的线性RNN堆栈实现结构化Koopman算子。在多种预测基准和动态系统上的数值实验表明，这种基于Koopman理论的简化设计具有卓越性能。

</details>


### [233] [CLGNN: A Contrastive Learning-based GNN Model for Betweenness Centrality Prediction on Temporal Graphs](https://arxiv.org/abs/2506.14122)
**中文标题：CLGNN：一种基于对比学习的图神经网络模型用于时序图介数中心性预测**

*Tianming Zhang,Renbo Zhang,Zhengyi Yang,Yunjun Gao,Bin Cao,Jing Fan*

主要分类: cs.LG

摘要简述: 本文提出了一种基于对比学习的图神经网络模型CLGNN，用于预测时序图中的介数中心性（TBC）。CLGNN通过构建实例图保留路径有效性和时序顺序，并利用双聚合机制编码结构和时序特征。通过引入稳定性聚类引导的对比模块（KContrastNet）和回归模块（ValueNet），CLGNN有效解决了数据不平衡问题，并在多个基准测试中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 时序介数中心性（TBC）是衡量节点在时序网络中重要性的指标，但其精确计算成本高昂，且真实数据分布极不平衡。现有方法难以处理这种不平衡或忽略时序依赖性，导致预测不准确。本文旨在提出一种高效且可扩展的模型，以解决这些问题。

研究方法: CLGNN通过构建实例图保留路径有效性和时序顺序，并采用双聚合机制（均值聚合和边到节点的多头注意力机制）编码结构和时序特征。引入KContrastNet模块通过对比学习分离高、中、低中心性节点，缓解类别不平衡问题；ValueNet模块用于回归预测TBC值。此外，CLGNN支持多种最优路径定义以适应不同时序语义。

研究结果: 实验表明，CLGNN在多个基准测试中表现优异。与现有精确计算方法相比，速度提升高达663.7倍；与静态GNN基线相比，平均绝对误差（MAE）降低31.4倍，Spearman相关性提高16.7倍；与现有时序GNN相比，MAE降低5.7倍，Spearman相关性提高3.9倍。

研究结论: CLGNN通过对比学习和双聚合机制，有效解决了时序介数中心性预测中的数据不平衡和时序依赖性问题，显著提升了预测准确性和效率，适用于多种时序语义场景。

中文摘要: 时序介数中心性（TBC）衡量节点在最优时序路径上出现的频率，反映其在时序网络中的重要性。然而，精确计算成本极高，且真实TBC分布极不平衡。这种严重不平衡导致基于学习的模型对零中心性节点过拟合，预测不准确且无法识别真正重要的节点。现有图神经网络（GNN）方法要么无法处理这种不平衡，要么完全忽略时序依赖性。为解决这些问题，我们提出了一种可扩展且归纳的基于对比学习的GNN模型（CLGNN），用于准确高效地预测TBC。CLGNN构建实例图以保留路径有效性和时序顺序，并通过双聚合机制（均值聚合和边到节点的多头注意力机制）结合时序路径计数和时间编码，编码结构和时序特征。引入基于稳定性的聚类引导对比模块（KContrastNet）在表示空间中分离高、中、低中心性节点，缓解类别不平衡问题；回归模块（ValueNet）用于估计TBC值。CLGNN还支持多种最优路径定义以适应不同时序语义。大量实验证明了CLGNN在多种基准测试中的有效性和高效性。与现有精确TBC计算方法相比，CLGNN实现了高达663.7倍的加速；与领先的静态GNN基线相比，平均绝对误差（MAE）降低31.4倍，Spearman相关性提高16.7倍；与现有时序GNN相比，MAE降低5.7倍，Spearman相关性提高3.9倍。

</details>


### [234] [Less is More: Undertraining Experts Improves Model Upcycling](https://arxiv.org/abs/2506.14126)
**中文标题：少即是多：专家模型欠训练提升模型升级性能**

*Stefan Horoi,Guy Wolf,Eugene Belilovsky,Gintare Karolina Dziugaite*

主要分类: cs.LG

摘要简述: 研究发现，专家模型的过度微调会损害模型升级性能，而采用任务依赖的早期停止策略可显著提升升级效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度学习领域广泛使用预训练模型和微调专家模型，但普遍假设微调阶段的改进会自然提升后续模型升级性能。本文挑战这一假设，探讨专家微调对模型升级的影响。

研究方法: 通过实验分析专家模型长时间微调对模型升级的影响，发现微调后期对困难样本的过拟合是性能下降的主因，并提出任务依赖的早期停止策略。

研究结果: 实验表明，过度微调的专家模型在升级后性能下降，而早期停止策略能显著提升升级性能，尤其是在LoRA适配器升级为MoE层时。

研究结论: 专家模型的微调需谨慎，避免过度优化单任务性能，任务依赖的早期停止策略是提升模型升级效果的有效方法。

中文摘要: 现代深度学习越来越依赖开放权重的预训练模型，这些模型可在专用数据集上微调，导致专家模型和适配器激增，并通过HuggingFace等平台共享。为利用这些资源，涌现了许多模型升级方法，使微调模型能在多任务系统中复用。一个自然的流程由此形成：模型在通用数据上预训练，在特定任务上微调，再升级为更通用的系统。普遍假设是流程中某一阶段的改进会传递到下游，带来后续增益。本文挑战这一假设，研究专家微调对模型升级的影响。我们发现，长时间微调专家模型以优化其个体性能会导致合并性能下降，无论是完全微调还是LoRA适配模型，且在LoRA适配器升级为MoE层时下游结果更差。这种退化源于微调后期对少量困难样本的过拟合，随后在合并时被遗忘。最后，我们证明任务依赖的激进早期停止策略可显著提升升级性能。

</details>


### [235] [DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion](https://arxiv.org/abs/2506.14202)
**中文标题：DiffusionBlocks：基于分数扩散的分块生成模型训练方法**

*Makoto Shing,Takuya Akiba*

主要分类: cs.LG

摘要简述: 提出DiffusionBlocks框架，通过分块训练和基于分数的扩散方法，显著降低内存消耗，同时保持生成任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统端到端反向传播训练大型神经网络存在内存瓶颈，限制了先进AI研究的普及。本文旨在通过分块训练解决这一问题。

研究方法: 将神经网络划分为独立训练块，将其解释为连续时间扩散过程中的去噪操作，并基于等累积概率质量优化噪声水平分配。

研究结果: 在图像生成和语言建模任务中，内存消耗与块数成比例减少，同时性能优于传统反向传播方法。

研究结论: DiffusionBlocks为计算资源有限的情况下训练大规模神经网络提供了可行方案。

中文摘要: 传统的端到端反向传播训练大型神经网络会带来显著的内存瓶颈，限制了先进AI研究的普及。我们提出DiffusionBlocks，这是一种新颖的训练框架，将神经网络块解释为连续时间扩散过程中的去噪操作。通过将网络划分为独立训练块，并基于等累积概率质量优化噪声水平分配，我们的方法在生成任务中实现了显著的内存效率提升，同时保持了与传统反向传播相当的竞争力。在图像生成和语言建模任务上的实验表明，内存消耗与块数成比例减少，同时性能表现更优。DiffusionBlocks为在有限计算资源下训练大规模神经网络提供了一条有前景的途径。

</details>


### [236] [TriGuard: Testing Model Safety with Attribution Entropy, Verification, and Drift](https://arxiv.org/abs/2506.14217)
**中文标题：TriGuard：基于归因熵、验证与漂移的模型安全性测试**

*Dipesh Tharu Mahato,Rohan Poudel,Pramod Dhungana*

主要分类: cs.LG

摘要简述: TriGuard提出了一种统一的安全评估框架，结合形式化鲁棒性验证、归因熵和归因漂移评分，揭示模型准确性与可解释性之间的不匹配问题。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络虽然准确性高，但在对抗性和分布偏移下的可靠性仍是一大挑战。TriGuard旨在通过多维度评估提升模型的安全性和可解释性。

研究方法: TriGuard结合了三种方法：(1) 形式化鲁棒性验证，(2) 归因熵量化显著性集中度，(3) 新颖的归因漂移评分衡量解释稳定性。

研究结果: 实验表明，TriGuard能揭示神经网络推理中的微妙脆弱性，且熵正则化训练可减少解释漂移而不影响性能。

研究结论: TriGuard为鲁棒且可解释的模型评估提供了新方法，揭示了模型安全性与可解释性之间的复杂关系。

中文摘要: 深度神经网络通常具有高准确性，但其在对抗性和分布偏移下的可靠性仍是一个紧迫的挑战。我们提出了TriGuard，一种统一的安全评估框架，结合了（1）形式化鲁棒性验证，（2）归因熵以量化显著性集中度，以及（3）一种新颖的归因漂移评分，用于衡量解释的稳定性。TriGuard揭示了模型准确性与可解释性之间的关键不匹配：已验证的模型仍可能表现出不稳定的推理，而归因信号提供了超越对抗准确性的补充安全洞察。在三个数据集和五种架构上的广泛实验表明，TriGuard如何揭示神经网络推理中的微妙脆弱性。我们进一步证明，熵正则化训练可在不影响性能的情况下减少解释漂移。TriGuard推动了鲁棒且可解释的模型评估的前沿。

</details>


### [237] [Knowledge Adaptation as Posterior Correction](https://arxiv.org/abs/2506.14262)
**中文标题：知识适应作为后验校正**

*Mohammad Emtiyaz Khan*

主要分类: cs.LG

摘要简述: 本文提出了一种将知识适应视为后验校正的机制，通过更准确的后验分布实现快速适应，揭示了机器如何像人类和动物一样自然学习适应的机制。


<details>
  <summary>详细信息</summary>
研究动机: 尽管在模型适应方面取得了许多进展（如持续学习、联邦学习等），但机器如何像人类和动物一样自然快速适应仍是一个未解之谜。本文旨在探索这一机制。

研究方法: 通过使用Khan和Rue（2023）的贝叶斯学习规则的双重视角，将适应过程中的干扰表征为过去数据的自然梯度不匹配，从而将各种适应方法统一为后验校正的不同形式。

研究结果: 研究表明，更准确的后验分布可以减小校正幅度，从而实现更快的适应。通过多个示例验证了后验校正作为机器快速适应自然机制的有效性。

研究结论: 后验校正是机器快速适应的一种自然机制，为机器学习的适应性提供了新的理论视角和实用方法。

中文摘要: 适应是智能的终极目标，但即使是像GPT这样的顶级AI模型，其适应性也不及幼儿。因此，问题仍然存在：机器如何快速适应？尽管在模型适应方面取得了许多进展（如持续学习、联邦学习、模型合并、编辑、遗忘等），但机器如何像人类和动物一样自然学习适应的机制仍知之甚少。本文表明，所有这些适应方法都可以视为对近似后验的不同“校正”方式。更准确的后验分布会导致更小的校正，从而意味着更快的适应。这一结果是通过使用Khan和Rue（2023）的贝叶斯学习规则的双重视角得出的，其中适应过程中产生的干扰由过去数据的自然梯度不匹配表征。我们通过多个示例展示了后验校正作为机器快速适应自然机制的应用。

</details>


### [238] [IntelliLung: Advancing Safe Mechanical Ventilation using Offline RL with Hybrid Actions and Clinically Aligned Rewards](https://arxiv.org/abs/2506.14375)
**中文标题：IntelliLung：基于离线强化学习的混合动作空间与临床对齐奖励的安全机械通气优化**

*Muhammad Hamza Yousuf,Jason Li,Sahar Vahdati,Raphael Theilen,Jakob Wittenstein,Jens Lehmann*

主要分类: cs.LG

摘要简述: 本文提出IntelliLung，一种基于离线强化学习的机械通气优化方法，通过处理混合动作空间和临床对齐的奖励函数，提升患者安全性和个性化支持。


<details>
  <summary>详细信息</summary>
研究动机: 机械通气（MV）是ICU中维持重症患者生命的关键疗法，但其设置优化复杂且易出错。现有离线强化学习方法难以处理MV的混合动作空间（连续和离散），且离散化动作空间可能导致安全风险。

研究方法: 本文优化了动作空间缩减方法，并改进离线强化学习算法（IQL和EDAC）以直接处理混合动作空间。同时，提出基于临床目标（如无呼吸机天数和生理指标）的奖励函数，替代传统的稀疏死亡率奖励。

研究结果: 实验表明，该方法能有效提升机械通气的安全性，支持个性化治疗，为数据驱动的重症监护提供了重要进展。

研究结论: IntelliLung通过结合混合动作空间和临床奖励函数，为智能机械通气优化提供了可行方案，有望改善患者预后。

中文摘要: 侵入性机械通气（MV）是重症监护病房（ICU）中维持危重患者生命的疗法，但其设置优化因患者特异性而复杂且易错。尽管离线强化学习（RL）在MV控制中显示出潜力，但现有方法难以处理MV的混合（连续和离散）动作特性。离散化动作空间会因组合爆炸限制可用动作并引入分布偏移，可能危及安全。本文提出基于动作空间缩减的优化方法，并改进离线RL算法（IQL和EDAC）以直接处理混合动作空间，避免离散化缺陷。此外，引入基于无呼吸机天数和生理目标的临床奖励函数，相比传统稀疏死亡率奖励更具优化意义。结果表明，AI辅助的MV优化可提升患者安全性并实现个性化肺支持，为智能数据驱动的重症监护方案提供了重要进展。

</details>


### [239] [ResNets Are Deeper Than You Think](https://arxiv.org/abs/2506.14386)
**中文标题：残差网络比你想象的更深**

*Christian H. X. Ali Mehmeti-Göpel,Michael Wand*

主要分类: cs.LG

摘要简述: 残差网络（ResNets）的性能优势不仅源于优化，还因其独特的函数空间与自然数据结构更匹配。


<details>
  <summary>详细信息</summary>
研究动机: 尽管残差连接在神经网络中广泛应用，但其性能优势的原因尚未完全明确。传统观点认为残差网络仅通过优化提升性能，但本文提出其可能具有更深层次的归纳偏置。

研究方法: 设计了一种后训练对比实验，分离泛化性能和可训练性，比较可变深度架构（类似ResNets）与固定深度网络的性能差异。

研究结果: 实验表明，即使优化影响较小，可变深度架构仍能持续优于固定深度网络，说明残差连接的性能优势不仅来自优化。

研究结论: 残差网络的优势源于其独特的函数空间，与自然数据的结构更匹配，而非仅依赖优化。

中文摘要: 残差连接在现代神经网络架构中几乎无处不在，其广泛应用通常归功于其显著提升的可训练性：残差网络训练更快、更稳定，且比前馈网络达到更高精度。尽管提出了从改进初始化到高级学习率调度等多种技术以缩小残差网络与前馈网络的性能差距，这一差距仍然存在。本文提出了一种替代解释：残差网络不仅是对前馈网络的重新参数化，而是存在于不同的函数空间中。我们设计了一种后训练对比实验，以分离泛化性能与可训练性；发现类似ResNets的可变深度架构即使在优化影响较小的情况下，仍能持续优于固定深度网络。这些结果表明，残差连接的性能优势超越了优化，指向了一种与自然数据结构更匹配的更深层次的归纳偏置。

</details>


### [240] [HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control](https://arxiv.org/abs/2506.14391)
**中文标题：HiLight：一种基于分层强化学习与全局对抗指导的大规模交通信号控制框架**

*Yaqiao Zhu,Hongkai Wen,Geyong Min,Man Luo*

主要分类: cs.LG

摘要简述: 本文提出HiLight框架，结合分层强化学习与全局对抗指导，解决大规模交通信号控制的协调问题，显著提升网络效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有强化学习方法在大规模交通信号控制中难以兼顾全局协调与可扩展性，集中式方法扩展性差，分散式方法缺乏统一目标。HiLight旨在通过分层结构与对抗训练解决这些问题。

研究方法: HiLight采用分层结构：高层Meta-Policy通过Transformer-LSTM划分交通网络并生成子目标；低层Sub-Policy控制单个交叉口并具备全局意识。通过对抗训练机制，Meta-Policy生成挑战性子目标，Sub-Policy学习超越目标以提升协调性。

研究结果: 实验表明，HiLight在大规模场景中表现显著优于其他方法，并在不同规模的基准测试中保持竞争力。

研究结论: HiLight通过分层强化学习与对抗训练，有效解决了大规模交通信号控制的协调问题，为未来智能交通系统提供了新思路。

中文摘要: 高效的交通信号控制（TSC）对缓解城市拥堵至关重要，但现有强化学习方法在大规模网络中难以兼顾全局协调与可扩展性。集中式方法扩展性差，分散式方法缺乏统一目标，导致网络效率受限。本文提出HiLight，一种结合分层强化学习与全局对抗指导的大规模TSC框架。HiLight包含高层Meta-Policy（通过Transformer-LSTM划分交通网络并生成子目标）和低层Sub-Policy（控制单个交叉口并具备全局意识）。为提升全局规划与局部执行的协同性，引入对抗训练机制：Meta-Policy生成挑战性子目标，Sub-Policy学习超越目标以实现更高效协调。实验在合成与真实基准测试中进行，并构建了包含高峰过渡、恶劣天气和节假日流量的大规模曼哈顿网络。结果表明，HiLight在大规模场景中优势显著，且在不同规模基准测试中保持竞争力。

</details>


### [241] [Adaptive Reinforcement Learning for Unobservable Random Delays](https://arxiv.org/abs/2506.14411)
**中文标题：自适应强化学习应对不可观测随机延迟**

*John Wikman,Alexandre Proutiere,David Broman*

主要分类: cs.LG

摘要简述: 本文提出了一种自适应强化学习框架，用于处理不可观测的随机延迟问题。通过引入交互层和动态调整算法ACDA，显著提升了在延迟环境中的性能表现。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习假设智能体与环境交互无延迟，但在实际动态环境中（如信息物理系统），延迟是常见且不可观测的。现有方法通常保守地假设延迟上限，而本文旨在解决这一限制。

研究方法: 提出了交互层框架，生成未来动作矩阵以应对不可预测的延迟和丢失的动作包。基于此框架，开发了模型化算法ACDA，动态适应延迟模式。

研究结果: 在多种基准运动环境中，ACDA算法显著优于现有方法，证明了其处理随机延迟的有效性。

研究结论: 本文提出的自适应框架和ACDA算法为处理不可观测随机延迟提供了高效解决方案，具有广泛的应用潜力。

中文摘要: 在标准强化学习（RL）环境中，智能体与环境的交互通常建模为马尔可夫决策过程（MDP），假设智能体能即时观测系统状态并立即执行动作。然而，在现实动态环境（如信息物理系统）中，这一假设常因交互延迟而失效。这些延迟随时间随机变化且通常不可观测，导致动作决策时未知延迟情况。现有方法保守地假设延迟上限已知，即使实际延迟通常更低。本文提出交互层框架，使智能体能自适应处理不可观测且时变的延迟。具体而言，智能体生成未来动作矩阵以应对不可预测的延迟和网络动作包丢失。基于此框架，我们开发了模型化算法ACDA（带延迟适应的行动者-评论者），动态适应延迟模式。在多种运动基准环境中，ACDA显著优于现有方法。

</details>


### [242] [sHGCN: Simplified hyperbolic graph convolutional neural networks](https://arxiv.org/abs/2506.14438)
**中文标题：sHGCN：简化的双曲图卷积神经网络**

*Pol Arévalo,Alexis Molina,Álvaro Ciudad*

主要分类: cs.LG

摘要简述: 本文提出了一种简化双曲图卷积神经网络（sHGCN），通过优化双曲神经网络中的关键操作，显著提升了计算效率和性能，使其在更广泛的应用中更具可行性。


<details>
  <summary>详细信息</summary>
研究动机: 双曲几何在建模复杂结构化数据（尤其是具有层次或树状关系的数据）方面表现出色，但传统的双曲神经网络在计算效率和高精度任务中存在性能挑战。本文旨在通过简化操作解决这些问题。

研究方法: 通过简化双曲神经网络中的关键操作，优化计算流程，从而提升运行速度和性能。

研究结果: 实验结果表明，简化后的双曲操作显著提高了计算速度和预测准确性。

研究结论: 简化双曲神经网络操作不仅提升了效率，还扩展了其应用范围，为复杂数据建模提供了更优选择。

中文摘要: 双曲几何已成为建模复杂结构化数据的强大工具，尤其是在存在层次或树状关系的情况下。通过实现更低失真的嵌入，双曲神经网络为捕捉复杂数据结构提供了优于欧几里得模型的替代方案。然而，这些模型在计算效率和高精度任务中仍面临性能挑战。本文通过简化双曲神经网络中的关键操作，显著提升了运行时间和性能。研究结果表明，优化的双曲操作可大幅提高计算速度和预测准确性，使双曲神经网络在更广泛的应用中更具可行性。

</details>


### [243] [Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks](https://arxiv.org/abs/2506.14472)
**中文标题：利用超网络结合外部因素的家庭级电力消耗预测**

*Fabien Bernier,Maxime Cordy,Yves Le Traon*

主要分类: cs.LG

摘要简述: 本文提出了一种基于超网络的电力消耗预测方法，通过结合外部因素（如天气指标）提升全球模型的预测准确性，并在6000多户卢森堡家庭的数据上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 传统电力消耗预测主要依赖历史数据，而引入外部因素（如天气、节假日等）虽能提升个体预测准确性，却可能降低全球模型的性能。本文旨在解决这一矛盾，通过超网络架构实现外部因素的有效利用。

研究方法: 采用超网络架构，根据外部因素动态调整模型权重，结合6000多户卢森堡家庭的电力消耗数据及天气、节假日等外部因素进行训练与预测。

研究结果: 实验表明，超网络方法在结合外部因素时表现优于现有模型，显著降低了预测误差，同时保持了全球模型的优势。

研究结论: 超网络架构能够有效利用外部因素提升电力消耗预测的准确性，为全球模型提供了一种兼顾个体差异的解决方案。

中文摘要: 准确的电力消耗预测对于高效的能源管理和资源分配至关重要。传统的时间序列预测依赖于历史模式和时序依赖性，而引入外部因素（如天气指标）在复杂现实应用中显示出显著提升预测准确性的潜力。然而，这些额外特征的加入往往会降低基于全体数据训练的全球预测模型的性能，尽管能提升个体家庭级模型的准确性。为解决这一问题，我们发现超网络架构能够有效利用外部因素，通过针对每个消费者调整模型权重，提升全球电力消耗预测模型的准确性。

我们收集了涵盖两年的全面数据集，包括来自6000多户卢森堡家庭的电力消耗数据及相应的外部因素（如天气指标、节假日和重大本地事件）。通过比较多种预测模型，我们证明超网络方法在结合外部因素时优于现有方法，减少了预测误差，同时保持了全球模型的优势。

</details>


### [244] [Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs](https://arxiv.org/abs/2506.14540)
**中文标题：评估与临床优先事项的对齐：校准、标签偏移和错误成本**

*Gerardo A. Flores,Alyssa H. Smith,Julia A. Fukuyama,Ashia C. Wilson*

主要分类: cs.LG

摘要简述: 本文提出了一种新的临床决策支持系统评估框架，强调校准性、分布偏移鲁棒性和错误成本敏感性，以更好地满足临床需求。


<details>
  <summary>详细信息</summary>
研究动机: 当前临床环境中广泛使用的评分规则（如准确率和AUC-ROC）未能充分反映校准性、分布偏移鲁棒性和错误成本不对称性等关键临床优先级。

研究方法: 基于Schervish表示理论，提出了一种调整后的交叉熵变体，通过加权平均临床相关类别平衡范围内的性能，选择校准且鲁棒的阈值分类器。

研究结果: 提出的评估框架简单易用，对临床部署条件敏感，能够优先选择校准性好且对现实变化鲁棒的模型。

研究结论: 该框架为临床决策支持系统提供了一种更符合实际需求的评估方法，强调了校准性和鲁棒性的重要性。

中文摘要: 基于机器学习的决策支持系统越来越多地应用于临床环境，其中概率评分函数用于指导和优先处理患者管理决策。然而，广泛使用的评分规则（如准确率和AUC-ROC）未能充分反映关键临床优先级，包括校准性、对分布偏移的鲁棒性以及对不对称错误成本的敏感性。在这项工作中，我们提出了一种原则性且实用的评估框架，用于选择校准的阈值分类器，该框架明确考虑了类别流行率的不确定性和临床环境中常见的领域特定成本不对称性。基于Schervish表示理论，我们推导出交叉熵（对数评分）的调整变体，该变体在临床相关类别平衡范围内对加权性能进行平均。最终的评估方法简单易用，对临床部署条件敏感，并旨在优先选择既校准又对现实变化鲁棒的模型。

</details>


### [245] [Object-Centric Neuro-Argumentative Learning](https://arxiv.org/abs/2506.14577)
**中文标题：面向对象中心的神经论证学习**

*Abdul Rahman Jacob,Avinash Kori,Emanuele De Angelis,Ben Glocker,Maurizio Proietti,Francesca Toni*

主要分类: cs.LG

摘要简述: 本文提出了一种结合神经与符号学习的神经论证学习（NAL）架构，用于图像分析，通过对象中心学习生成事实并利用假设基础论证（ABA）进行预测，实验表明其性能可与先进方法媲美。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度学习在关键决策中的应用增加，其安全性、可靠性和可解释性问题日益突出。本文旨在通过结合神经与符号学习，提出一种新型架构以提升深度学习在这些方面的表现。

研究方法: 提出神经论证学习（NAL）架构，结合对象中心学习（神经部分）和假设基础论证（ABA，符号部分）。神经部分负责图像分割与编码为事实，符号部分通过ABA学习生成预测框架。

研究结果: 在合成数据上的实验表明，NAL架构的性能可与当前最先进方法竞争。

研究结论: NAL架构通过神经与符号学习的结合，为深度学习的安全性和可解释性提供了新思路，实验验证了其有效性。

中文摘要: 过去十年中，随着我们越来越多地依赖深度学习技术做出关键决策，其安全性、可靠性和可解释性问题逐渐显现。我们提出了一种新型神经论证学习（NAL）架构，将假设基础论证（ABA）与深度学习结合用于图像分析。该架构包含神经和符号两部分：前者通过对象中心学习将图像分割并编码为事实，后者应用ABA学习生成基于图像的预测框架。在合成数据上的实验表明，NAL架构的性能可与当前最先进方法媲美。

</details>


<div id='q-bio.PE'></div>

# q-bio.PE [[Back]](#toc)

### [246] [Analysis and Optimization of Probabilities of Beneficial Mutation and Crossover Recombination in a Hamming Space](https://arxiv.org/abs/2506.13809)
**中文标题：汉明空间中有利突变和交叉重组概率的分析与优化**

*Roman V. Belavkin*

主要分类: q-bio.PE

摘要简述: 本文分析了汉明空间中字符串的有利突变和交叉重组概率，通过几何和组合方法推导了闭式表达式，优化了突变和重组的参数，揭示了突变和重组在进化中的不同作用。


<details>
  <summary>详细信息</summary>
研究动机: 受Fisher几何方法启发，研究汉明空间中字符串的有利突变和交叉重组概率，以优化进化算法的参数，提升进化效率。

研究方法: 采用几何和组合分析，推导了汉明空间中字符串距离最优解的转移概率闭式表达式，并优化了突变和重组的半径参数。

研究结果: 研究发现突变和重组在进化中作用不同：突变概率随距离减小而降低，需调整半径以减缓进化速度；重组在子空间内平衡有利与有害概率，可补充突变并加速进化。

研究结论: 突变和重组在进化中各有优劣，重组可补充突变的不足，优化参数能提升进化效率。

中文摘要: 受Fisher几何方法启发，我们分析了汉明空间中字符串的有利突变和交叉重组概率，其中突变和重组若减少与最优解的距离则视为有利。通过几何和组合分析，推导了围绕最优解的球体间转移概率的闭式表达式，完整描述了多代进化中距离最优解的马尔可夫演化过程。这为优化突变和重组算子的参数奠定了基础。本文推导了突变和重组半径最大化进入最优解概率的最优条件。分析揭示了这些进化算子的重要差异：突变可覆盖整个搜索空间，但有利突变概率随距离减小而降低，最优突变半径或速率也需减小，导致进化速度减缓；而交叉重组作用于当前字符串种群定义的子空间，其有利与有害概率平衡且特征（如方差）在汉明空间中具有平移不变性，表明重组可补充突变并加速进化。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [247] [GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation](https://arxiv.org/abs/2506.14135)
**中文标题：GAF：高斯动作场作为机器人操作的动态世界模型**

*Ying Chai,Litao Deng,Ruizhi Shao,Jiajun Zhang,Liangjun Xing,Hongwen Zhang,Yebin Liu*

主要分类: cs.RO

摘要简述: 本文提出了一种名为GAF（高斯动作场）的动态世界模型，通过将可学习的运动属性融入3D高斯泼溅技术，实现了从4D表示直接推理动作的能力，显著提升了机器人操作任务的准确性和成功率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉到动作（V-A）或视觉到3D到动作（V-3D-A）方法在复杂动态场景中常因动作推断不准确而受限。本文旨在通过引入4D表示和动态建模，解决机器人操作中的动作推理问题。

研究方法: GAF扩展了3D高斯泼溅技术，引入可学习的运动属性，支持三种关键查询：当前场景重建、未来帧预测和初始动作估计。此外，通过GAF引导的扩散模型优化操作动作。

研究结果: 实验表明，GAF在重建质量上提升了11.5385 dB PSNR和降低了0.5574 LPIPS，机器人操作任务的平均成功率提高了10.33%，优于现有方法。

研究结论: GAF通过动态4D表示和动作建模，显著提升了机器人操作的准确性和效率，为复杂场景下的动作推理提供了新思路。

中文摘要: 准确的行动推理对于基于视觉的机器人操作至关重要。现有方法通常遵循视觉到动作（V-A）范式，直接从视觉输入预测动作，或视觉到3D到动作（V-3D-A）范式，利用中间3D表示。然而，这些方法常因复杂动态场景导致动作不准确。本文提出了一种V-4D-A框架，通过高斯动作场（GAF）实现从运动感知的4D表示直接推理动作。GAF通过引入可学习的运动属性扩展了3D高斯泼溅技术，能够同时建模动态场景和操作动作。为学习时变场景几何和动作感知的机器人运动，GAF支持三种关键查询：当前场景重建、未来帧预测和初始动作估计。此外，GAF生成的高质量当前和未来帧通过GAF引导的扩散模型优化操作动作。大量实验表明，GAF在重建质量上提升了11.5385 dB PSNR和降低了0.5574 LPIPS，同时将机器人操作任务的平均成功率提高了10.33%，优于现有方法。项目页面：http://chaiying1.github.io/GAF.github.io/project_page/

</details>


### [248] [AMPLIFY: Actionless Motion Priors for Robot Learning from Videos](https://arxiv.org/abs/2506.14198)
**中文标题：AMPLIFY：基于无动作视频的机器人学习运动先验**

*Jeremy A. Collins,Loránd Cheng,Kunal Aneja,Albert Wilcox,Benjamin Joffe,Animesh Garg*

主要分类: cs.RO

摘要简述: AMPLIFY是一种利用无动作视频数据学习机器人运动先验的新框架，通过分离视觉运动预测与动作推理，显著提升低数据场景下的策略学习效果。


<details>
  <summary>详细信息</summary>
研究动机: 机器人学习需要大量带动作标签的数据，但这些数据稀缺且昂贵，而无动作标签的视频数据丰富但难以转化为有效策略。AMPLIFY旨在解决这一挑战。

研究方法: AMPLIFY通过关键点轨迹提取紧凑的运动令牌，将视觉动态编码为离散表示。其模块化方法分离了视觉运动预测和动作推理，分别利用无动作视频和有限带动作数据训练前向和逆向动力学模型。

研究结果: AMPLIFY在动态预测上表现优异，MSE和像素预测精度分别提升3.7倍和2.5倍。在策略学习中，低数据场景下性能提升1.2-2.2倍，利用人类视频数据平均提升1.4倍，并首次实现零分布动作数据的LIBERO任务泛化。

研究结论: AMPLIFY展示了利用异构数据源构建高效、通用世界模型的新范式，其学习到的动态模型还可提升视频预测质量。

中文摘要: 机器人学习所需的带动作标签数据稀缺且昂贵，限制了学习策略的泛化能力。相比之下，大量无动作视频数据易于获取，但如何将其转化为有效策略仍具挑战。本文提出AMPLIFY框架，通过关键点轨迹提取紧凑的运动令牌，将视觉动态编码为离散表示。其模块化方法分离了视觉运动预测与动作推理，分别利用无动作视频和有限带动作数据训练前向和逆向动力学模型。实验表明，AMPLIFY的动态预测精度显著优于现有方法（MSE提升3.7倍，像素预测精度提升2.5倍）。在策略学习中，低数据场景下性能提升1.2-2.2倍，利用人类视频数据平均提升1.4倍，并首次实现零分布动作数据的LIBERO任务泛化。此外，AMPLIFY学习到的动态模型还可作为通用潜在世界模型，提升视频预测质量。本研究为利用异构数据源构建高效、通用世界模型提供了新范式。更多信息请访问https://amplify-robotics.github.io/。

</details>


### [249] [GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments](https://arxiv.org/abs/2506.14513)
**中文标题：GAMORA：一种用于密闭环境中危险材料处理的手势驱动元操作机器人臂**

*Farha Abdul Wasay,Mohammed Abdul Rahman,Hania Ghouse*

主要分类: cs.RO

摘要简述: GAMORA是一种基于VR手势控制的机器人系统，用于高风险实验室环境中的危险材料处理，通过实时沉浸式控制和数字孪生技术实现高精度操作。


<details>
  <summary>详细信息</summary>
研究动机: 随着生物危害复杂性的增加，减少人类直接接触同时保持操作精度成为关键需求。传统脚本自动化或远程操作无法满足高精度和灵活性要求，因此需要一种新型的VR引导机器人系统。

研究方法: GAMORA结合Oculus Quest 2、NVIDIA Jetson Nano和ROS，提供实时沉浸式控制、数字孪生模拟和逆运动学驱动的机械臂操作。系统通过Unity构建3D环境，实现实时运动规划和硬件在环测试，并集成YOLOv8进行物体检测。

研究结果: GAMORA在50次试验中平均位置偏差为2.2毫米（改进自4毫米），移液精度在0.2毫升内，重复性为1.2毫米。系统能效提升50%，并通过数字-物理反馈循环实现高精度操作。

研究结论: GAMORA为生物医学研究环境提供了一种可扩展、沉浸式的机器人控制解决方案，能够安全、精确且可重复地完成高风险实验室任务。

中文摘要: 机器人与虚拟现实（VR）的融合为高风险实验室（尤其是病毒学实验室）提供了更安全高效的工作流程。随着生物危害复杂性的增加，减少人类直接接触同时保持操作精度变得至关重要。我们提出GAMORA（手势驱动元操作机器人臂），这是一种新型VR引导机器人系统，可通过自然手势远程执行危险任务。与现有的脚本自动化或传统远程操作不同，GAMORA集成了Oculus Quest 2、NVIDIA Jetson Nano和机器人操作系统（ROS），提供实时沉浸式控制、数字孪生模拟和基于逆运动学的机械臂操作。系统支持VR培训和模拟，同时通过3D打印机械臂在物理环境中执行精确任务。逆运动学确保了标本处理和移液等精细操作的准确性。流程包括基于Unity的3D环境构建、实时运动规划和硬件在环测试。GAMORA在50次试验中平均位置偏差为2.2毫米（改进自4毫米），移液精度在0.2毫升内，重复性为1.2毫米。通过YOLOv8集成的物体检测增强了空间感知，而能效提升50%确保了可持续部署。系统的数字-物理反馈循环实现了高风险实验室任务的安全、精确和可重复自动化。GAMORA为生物医学研究环境提供了一种可扩展、沉浸式的机器人控制和生物安全解决方案。

</details>


### [250] [Steering Robots with Inference-Time Interactions](https://arxiv.org/abs/2506.14287)
**中文标题：通过推理时交互引导机器人**

*Yanwei Wang*

主要分类: cs.RO

摘要简述: 该研究提出了一种在推理时通过用户交互引导预训练策略的方法，无需微调即可纠正策略错误，提升模型泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 模仿学习已推动开发出能自主解决多任务的通用策略，但在部署时若预训练策略出错，缺乏有效的用户纠正机制。传统方法需为每个下游用例收集额外数据进行微调，效率低下。

研究方法: 研究提出两种框架：(1) 推理时引导，利用用户交互在离散技能间切换；(2) 任务与动作模仿，允许用户编辑连续动作，同时满足离散符号计划定义的任务约束。

研究结果: 这些框架无需额外训练即可纠正策略预测偏差，最大化预训练模型的效用，同时实现推理时的用户目标。

研究结论: 通过推理时交互引导预训练策略，用户可高效纠正模型错误，提升部署效率，减少对额外数据的依赖。

中文摘要: 模仿学习推动了能够自主解决多任务的通用策略的发展。然而，当预训练策略在部署过程中出错时，用户纠正其行为的机制有限。虽然收集额外数据进行微调可以解决此类问题，但为每个下游用例这样做在部署时效率低下。我的研究提出了一种替代方案：保持预训练策略冻结作为固定技能库，同时允许用户交互在推理时引导行为生成以满足用户偏好。通过使预训练策略可引导，用户可以在模型难以泛化时帮助纠正策略错误，而无需微调策略。具体而言，我提出了（1）推理时引导，利用用户交互在离散技能间切换；（2）任务与动作模仿，允许用户编辑连续动作，同时满足由离散符号计划定义的任务约束。这些框架无需额外训练即可纠正策略预测偏差，最大化预训练模型的效用，同时实现推理时的用户目标。

</details>


### [251] [Uncertainty-Driven Radar-Inertial Fusion for Instantaneous 3D Ego-Velocity Estimation](https://arxiv.org/abs/2506.14294)
**中文标题：不确定性驱动的雷达-惯性融合用于瞬时3D自车速度估计**

*Prashant Kumar Rai,Elham Kowsari,Nataliya Strokina,Reza Ghabcheloo*

主要分类: cs.RO

摘要简述: 本文提出一种基于雷达-惯性融合的瞬时3D自车速度估计方法，通过神经网络处理雷达数据并结合扩展卡尔曼滤波，显著提升了估计精度和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 传统雷达自运动估计方法存在局限性，无法有效处理复杂雷达数据和高精度需求。本文旨在通过融合雷达与惯性测量单元数据，结合不确定性估计，提升自车速度估计的准确性和鲁棒性。

研究方法: 方法包括：1) 使用神经网络处理复数形式的原始雷达数据，估计瞬时线性自车速度及其不确定性；2) 通过扩展卡尔曼滤波将雷达估计与惯性测量单元数据融合，利用网络预测的不确定性优化传感器噪声和偏差参数。

研究结果: 在公开数据集ColoRadar上的实验表明，该方法显著优于现有公开方法，且在瞬时估计和扫描匹配技术上均表现更优。

研究结论: 本文提出的不确定性驱动雷达-惯性融合方法有效提升了自车速度估计的精度和鲁棒性，为自主导航提供了更可靠的技术支持。

中文摘要: 我们提出了一种通过集成高分辨率成像雷达与惯性测量单元来估计自主导航中自车速度的方法。该方法通过神经网络处理复数形式的原始雷达数据，估计瞬时线性自车速度及其不确定性，从而解决了传统雷达自运动估计技术的局限性。这种基于不确定性的速度估计随后通过扩展卡尔曼滤波与惯性测量单元数据融合。滤波器利用网络预测的不确定性优化惯性传感器的噪声和偏差参数，从而提高了自运动估计的整体鲁棒性和准确性。我们在公开的ColoRadar数据集上评估了所提出的方法。与最接近的公开方法相比，我们的方法实现了显著更低的误差，并且在瞬时估计和扫描匹配技术上均表现更优。

</details>


### [252] [SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning](https://arxiv.org/abs/2506.14648)
**中文标题：SENIOR：基于偏好的强化学习中的高效查询选择与偏好引导探索**

*Hexian Ni,Tao Lu,Haoyuan Hu,Yinghao Cai,Shuo Wang*

主要分类: cs.RO

摘要简述: 本文提出了一种名为SENIOR的高效查询选择和偏好引导探索方法，用于偏好强化学习（PbRL），通过选择易于比较的行为片段对和设计偏好引导的内在奖励，显著提高了人类反馈效率和策略学习速度。


<details>
  <summary>详细信息</summary>
研究动机: 偏好强化学习（PbRL）通过人类偏好学习奖励模型，避免了奖励工程的需求，但其反馈和样本效率低下限制了实际应用。本文旨在解决这一问题，提出高效查询选择和偏好引导探索方法。

研究方法: 方法包括两部分：(1) 基于运动差异的选择方案（MDS），通过状态核密度估计选择运动明显且方向不同的片段对，便于人类偏好标注；(2) 偏好引导探索方法（PGE），鼓励探索高偏好且低访问的状态，持续引导代理获取有价值样本。

研究结果: 实验表明，SENIOR在六项复杂机器人操作任务（模拟和现实）中，反馈效率和策略收敛速度均优于其他五种现有方法。

研究结论: SENIOR通过结合MDS和PGE机制，显著加速了奖励和策略学习进程，为偏好强化学习的实际应用提供了高效解决方案。

中文摘要: 基于偏好的强化学习（PbRL）方法通过人类偏好学习奖励模型，避免了奖励工程的需求。然而，反馈和样本效率低下仍是阻碍PbRL应用的主要问题。本文提出了一种名为SENIOR的高效查询选择和偏好引导探索方法，通过选择有意义且易于比较的行为片段对，提高人类反馈效率，并通过设计的偏好引导内在奖励加速策略学习。其核心思想包括：(1) 设计了基于运动差异的选择方案（MDS），通过状态的核密度估计选择运动明显且方向不同的片段对，更易于人类偏好标注；(2) 提出了一种偏好引导探索方法（PGE），鼓励探索高偏好且低访问的状态，持续引导代理获取有价值样本。这两种机制的协同作用显著加速了奖励和策略学习进程。实验表明，在六项复杂机器人操作任务（模拟和现实）中，SENIOR在反馈效率和策略收敛速度上均优于其他五种现有方法。

</details>


### [253] [Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models](https://arxiv.org/abs/2506.14727)
**中文标题：Casper：利用视觉语言模型推断多样化意图的辅助远程操作系统**

*Huihan Liu,Rutav Shah,Shuijing Liu,Jack Pittenger,Mingyo Seo,Yuchen Cui,Yonatan Bisk,Roberto Martín-Martín,Yuke Zhu*

主要分类: cs.RO

摘要简述: Casper是一种辅助远程操作系统，利用预训练视觉语言模型的常识知识，实时推断用户意图并执行灵活技能，显著提升任务性能并降低用户认知负担。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的辅助远程操作面临的核心挑战是机器人如何从用户控制输入中推断广泛的意图并提供正确协助。现有方法局限于简单预定义场景或特定任务数据分布，无法满足实际需求。

研究方法: Casper结合开放世界感知模块、基于视觉语言模型的意图推断机制和技能库，实现对新颖对象和场景的通用理解，并支持多样化的长期移动操作任务。

研究结果: 实验表明，Casper在任务性能、降低用户认知负荷和提升用户满意度方面优于直接远程操作和其他辅助远程操作基线方法。

研究结论: Casper通过利用视觉语言模型的常识知识，显著提升了辅助远程操作的灵活性和实用性，为复杂环境下的协作提供了有效解决方案。

中文摘要: 辅助远程操作通过人与机器人共享控制，能够在多样化和非结构化环境中实现高效直观的人机协作。现实世界辅助远程操作的核心挑战在于机器人如何从用户控制输入中推断广泛的意图并提供正确协助。现有方法要么局限于简单预定义场景，要么受限于训练时的任务特定数据分布，难以支持实际应用。我们提出Casper，一种利用预训练视觉语言模型（VLMs）中嵌入的常识知识进行实时意图推断和灵活技能执行的辅助远程操作系统。Casper包含一个开放世界感知模块，用于对新对象和场景的通用理解；一个基于VLM的意图推断机制，利用常识推理解释用户输入的片段；以及一个技能库，扩展了现有辅助远程操作系统的能力，支持多样化的长期移动操作任务。通过包括人类研究和系统消融实验在内的广泛实证评估，Casper在任务性能、降低用户认知负荷和提升用户满意度方面优于直接远程操作和其他辅助远程操作基线方法。

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [254] [Complete Characterization for Adjustment in Summary Causal Graphs of Time Series](https://arxiv.org/abs/2506.14534)
**中文标题：时间序列摘要因果图中调整的完备性表征**

*Clément Yvernes,Emilie Devijver,Eric Gaussier*

主要分类: math.ST

摘要简述: 本文研究了时间序列中基于摘要因果图的多重干预可识别性问题，提出了调整准则的充要条件，并设计了一种伪线性算法来判断查询是否可识别。


<details>
  <summary>详细信息</summary>
研究动机: 在时间序列分析中，当仅能获得摘要因果图而非真实因果图时，如何评估干预的总因果效应是否可以通过无干预公式表示并仅从观测数据中估计，是一个关键问题。本文旨在解决这一问题。

研究方法: 作者研究了多重干预下的可识别性问题，提出了调整准则的充要条件，并证明其在该设定下的完备性。此外，还设计了一种伪线性算法用于判断查询的可识别性。

研究结果: 研究结果表明，所提出的调整准则在摘要因果图的设定下是完备的，且伪线性算法能够高效地判断查询的可识别性。

研究结论: 本文为时间序列中基于摘要因果图的干预效应分析提供了理论支持，并通过算法实现了高效的可识别性判断。

中文摘要: 干预的可识别性问题旨在评估总因果效应是否可以用无干预公式表示，从而仅从观测数据中估计。我们在时间序列的背景下研究这一问题，考虑多重干预，且仅能获得摘要因果图形式的真实因果图的抽象。我们特别提出了调整准则的充要条件，并证明其在该设定下的完备性，同时提供了一种伪线性算法来判断查询是否可识别。

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [255] [Accurate and scalable exchange-correlation with deep learning](https://arxiv.org/abs/2506.14665)
**中文标题：基于深度学习的精确且可扩展的交换相关泛函**

*Giulia Luise,Chin-Wei Huang,Thijs Vogels,Derk P. Kooi,Sebastian Ehlert,Stephanie Lanius,Klaas J. H. Giesbertz,Amir Karton,Deniz Gunceler,Megan Stanley,Wessel P. Bruinsma,Lin Huang,Xinran Wei,José Garrido Torres,Abylay Katbashev,Bálint Máté,Sékou-Oumar Kaba,Roberto Sordillo,Yingrong Chen,David B. Williams-Young,Christopher M. Bishop,Jan Hermann,Rianne van den Berg,Paola Gori-Giorgi*

主要分类: physics.chem-ph

摘要简述: 本文提出了一种基于深度学习的交换相关泛函Skala，通过直接从数据中学习表征，避免了手工设计特征的复杂性，实现了小分子原子化能量的化学精度，同时保持了半局域DFT的计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 密度泛函理论（DFT）是预测分子和材料性质最广泛使用的电子结构方法，但其实际应用依赖于对未知交换相关（XC）泛函的近似。现有泛函通常通过手工设计的复杂特征提高精度，但牺牲了计算效率，且无法达到实验室实验的化学精度（误差低于1 kcal/mol）。因此，需要一种既能保持计算效率又能实现高精度的新方法。

研究方法: 本文提出了一种名为Skala的深度学习基XC泛函，通过直接从大量高精度参考数据中学习表征，避免了手工设计特征的复杂性。这些数据是通过计算密集的波函数方法生成的，涵盖了多样化的化学领域。

研究结果: Skala在小分子原子化能量上实现了化学精度，同时保持了半局域DFT的计算效率。通过引入少量针对非原子化能量的高精度数据，Skala在一般主族化学中的表现与最佳杂化泛函相当，而计算成本仅为半局域DFT水平。随着训练数据的增加，其预测能力有望进一步提升。

研究结论: Skala展示了深度学习在XC泛函设计中的潜力，能够在不牺牲计算效率的前提下实现高精度。随着训练数据的扩展，Skala有望进一步提升第一性原理模拟的预测能力。

中文摘要: 密度泛函理论（DFT）是预测分子和材料性质最广泛使用的电子结构方法。尽管DFT在原理上是薛定谔方程的精确重构，但其实际应用依赖于对未知交换相关（XC）泛函的近似。大多数现有XC泛函通过有限且日益复杂的手工设计特征构建，以提高精度为代价牺牲了计算效率。然而，目前尚无近似方法能够达到实验室实验的化学精度（通常定义为误差低于1 kcal/mol）。本文提出了Skala，一种基于深度学习的现代XC泛函，通过直接从数据中学习表征，避免了昂贵的手工设计特征。Skala在小分子原子化能量上实现了化学精度，同时保持了半局域DFT的计算效率。这一性能得益于对前所未有的大量高精度参考数据的训练，这些数据是通过计算密集的波函数方法生成的。值得注意的是，Skala在涵盖多样化化学的额外训练数据下表现出系统性提升。通过引入少量针对非原子化能量的高精度数据，Skala在一般主族化学中的表现与最佳杂化泛函相当，而计算成本仅为半局域DFT水平。随着训练数据的持续扩展，Skala有望进一步增强第一性原理模拟的预测能力。

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [256] [Safe Domains of Attraction for Discrete-Time Nonlinear Systems: Characterization and Verifiable Neural Network Estimation](https://arxiv.org/abs/2506.13961)
**中文标题：离散时间非线性系统的安全吸引域：表征与可验证的神经网络估计**

*Mohamed Serry,Haoyu Li,Ruikun Zhou,Huan Zhang,Jun Liu*

主要分类: eess.SY

摘要简述: 本文提出了一种用于离散时间非线性系统的安全吸引域估计框架，通过推导新的Zubov方程并利用神经网络近似求解，结合验证工具实现可认证的估计。


<details>
  <summary>详细信息</summary>
研究动机: 非线性自治系统的吸引域估计一直是一个具有挑战性的问题，现有方法保守或仅适用于低维系统，且在考虑状态约束时更为困难。本文旨在解决这一问题。

研究方法: 首先推导了一个新的Zubov方程，其解对应于精确的安全吸引域；随后提出了一种基于物理信息的神经网络近似求解方法，并结合标准验证工具（如α,β-CROWN和dReal）实现可认证的估计。

研究结果: 通过数值实验验证了所提框架的有效性，能够准确估计具有状态约束的非线性系统的安全吸引域。

研究结论: 本文提出的框架为离散时间非线性系统的安全吸引域估计提供了一种高效且可验证的方法，解决了现有方法的局限性。

中文摘要: 非线性自治系统的分析通常涉及吸引域的估计，这一课题几十年来一直是研究热点。然而，准确估计非线性系统的吸引域仍是一项具有挑战性的任务，现有方法往往保守或仅适用于低维系统。在考虑状态约束时，这一问题更为复杂。本文提出了一种框架，用于准确估计离散时间自治非线性系统的安全（状态约束）吸引域。在建立该框架时，我们首先推导了一个新的Zubov方程，其解对应于精确的安全吸引域。该Zubov方程的解被证明在整个状态空间内是唯一且连续的。随后，我们提出了一种基于物理信息的方法，利用神经网络近似求解Zubov方程。为了从神经网络的近似解中获得可认证的吸引域估计，我们提出了一个验证框架，可通过标准验证工具（如α,β-CROWN和dReal）实现。为验证其有效性，我们通过涉及状态约束的非线性系统的数值示例展示了该方法。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [257] [Contemporary AI foundation models increase biological weapons risk](https://arxiv.org/abs/2506.13798)
**中文标题：当代AI基础模型增加生物武器风险**

*Roger Brent,T. Greg McKelvey*

主要分类: cs.CY

摘要简述: 当代AI基础模型增加了生物武器风险，现有安全评估低估了这种风险，因为假设和方法存在缺陷。研究发现，高级AI模型可以指导用户完成复杂生物技术任务，如合成脊髓灰质炎病毒，呼吁改进评估标准。


<details>
  <summary>详细信息</summary>
研究动机: 人工智能的快速发展引发了对其可能促进生物武器开发的担忧。现有安全评估低估了风险，主要由于错误的假设和不充分的评估方法。

研究方法: 通过分析无正式专业知识但成功完成复杂技术任务的案例，以及审查病原体构建过程的文档化，验证AI模型可以描述生物武器开发的关键步骤。测试了Llama 3.1 405B、ChatGPT-4o和Claude 3.5 Sonnet等模型在指导合成脊髓灰质炎病毒中的表现。

研究结果: 研究发现，高级AI模型能够准确指导用户从商业合成DNA中恢复活脊髓灰质炎病毒，反驳了当前模型对生物安全风险较小的观点。

研究结论: 研究呼吁改进评估标准，但可能已错过有效实施的时间窗口。

中文摘要: 人工智能的快速发展引发了对其可能促进生物武器开发的担忧。我们认为，现有对当代AI基础模型的安全评估低估了这一风险，主要由于错误的假设和不充分的评估方法。首先，评估错误地假设生物武器开发需要隐性知识，即通过实践经验获得且难以言传的技能。其次，它们依赖不完善的基准，忽视了AI如何提升非专业人士和已有技能者的能力。为了挑战隐性知识假设，我们研究了无正式专业知识的个体（如2011年挪威极端民族主义者成功合成爆炸物）完成复杂技术任务的案例。我们还审查了病原体构建过程的文档化努力，强调这些任务可以通过文本传达。我们确定了生物武器开发的“成功要素”，大型语言模型可以用文字描述这些步骤，包括获取材料和执行技术程序。应用这一框架，我们发现高级AI模型Llama 3.1 405B、ChatGPT-4o和Claude 3.5 Sonnet可以准确指导用户从商业合成DNA中恢复活脊髓灰质炎病毒，挑战了当前模型对生物安全风险较小的观点。我们呼吁改进基准，同时承认有效实施的窗口可能已经关闭。

</details>


### [258] [Dr. GPT Will See You Now, but Should It? Exploring the Benefits and Harms of Large Language Models in Medical Diagnosis using Crowdsourced Clinical Cases](https://arxiv.org/abs/2506.13805)
**中文标题：GPT医生现在可以接诊了，但它应该吗？——基于众包临床案例探索大型语言模型在医学诊断中的利弊**

*Bonam Mingole,Aditya Majumdar,Firdaus Ahmed Choudhury,Jennifer L. Kraschnewski,Shyam S. Sundar,Amulya Yadav*

主要分类: cs.CY

摘要简述: 本文通过众包方式评估大型语言模型（LLMs）在回答日常健康问题中的表现，发现76%的LLM回答被医生认为准确，并探讨了结合医学知识库的RAG版本是否能提升回答质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究忽视了LLMs在回答普通用户日常健康问题中的实际效果，而这是更常见的应用场景。本文旨在填补这一研究空白，评估LLMs在真实世界健康沟通中的表现。

研究方法: 通过大学竞赛形式，34名参与者向4个公开LLMs提交212个真实或虚构的健康问题，由9名认证医生评估回答质量，并探讨RAG版本LLMs的改进潜力。

研究结果: 医生认为76%的LLM回答准确，且结合医学知识库的RAG版本可能进一步提升回答质量。定性访谈揭示了定量结果的背后原因。

研究结论: LLMs在回答日常健康问题时表现良好，但需结合专业医学知识库以优化效果，为实际应用提供更可靠支持。

中文摘要: 大型语言模型（LLMs）在高风险应用（如医学（自我）诊断和初步分诊）中的普及引发了对其有效性、适用性及潜在危害的伦理和实践担忧。现有研究多关注LLMs回答专家编写的健康问题或医学考试题目，却忽视了其在普通用户日常健康问题中的实际表现。为填补这一空白，本文通过大学竞赛形式，采用众包方法评估LLMs回答日常健康问题的效果。一周内，34名参与者向4个公开LLMs提交212个真实或虚构的健康问题，并由9名认证医生评估回答质量。结果表明，76%的LLM回答被医生认为准确。此外，结合医学知识库的RAG版本可能进一步提升回答质量。通过访谈7名医学专家，本文还揭示了定量结果背后的定性洞察，旨在为LLMs在真实世界健康沟通中的表现提供更全面的理解。

</details>


### [259] [Students' Reliance on AI in Higher Education: Identifying Contributing Factors](https://arxiv.org/abs/2506.13845)
**中文标题：高等教育中学生对AI的依赖：识别影响因素**

*Griffin Pitts,Neha Rani,Weedguet Mildort,Eva-Marie Cook*

主要分类: cs.CY

摘要简述: 研究发现大学生对AI的依赖程度与编程自我效能、编程素养和认知需求相关，适当依赖与任务后信任和满意度负相关，过度依赖与任务后信任和满意度正相关，而依赖不足与编程素养、自我效能和认知需求负相关。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI工具在教育中的广泛应用，学生对AI的过度依赖可能导致学习效果下降。本研究旨在探讨大学生对AI依赖模式的影响因素，包括过度依赖、适当依赖和依赖不足。

研究方法: 研究采用前后问卷调查和实验任务结合的方法，参与者在使用提供准确和错误建议的AI助手解决编程问题时，其依赖模式被直接观察。

研究结果: 适当依赖与编程自我效能、编程素养和认知需求显著相关，但与任务后信任和满意度负相关；过度依赖与任务后信任和满意度正相关；依赖不足与编程素养、自我效能和认知需求负相关。

研究结论: 研究结果为开发针对性干预措施以促进学生对AI工具的适当依赖提供了依据，对AI在教育技术和课程中的整合具有启示意义。

中文摘要: 随着人工智能（AI）工具在教育环境中的日益普及和使用，学生对AI的过度依赖引发了担忧。过度依赖表现为个体未经批判性评估即接受AI生成的不正确建议，导致问题解决方案存在缺陷并影响学习效果。本研究探讨了本科生对AI依赖模式的潜在影响因素，不仅包括过度依赖，还包括适当依赖（正确接受有益并拒绝有害建议）和依赖不足（错误拒绝有益建议）。研究方法结合了前后问卷调查和一项受控实验任务，参与者在AI助手的帮助下解决编程问题，该助手提供准确和故意错误的建议，从而直接观察学生在面对不同AI可靠性时的依赖模式。研究发现，适当依赖与学生的编程自我效能、编程素养和认知需求显著相关，但与任务后信任和满意度呈负相关；过度依赖与任务后信任和对AI助手的满意度显著相关；依赖不足与编程素养、编程自我效能和认知需求呈负相关。总体而言，研究结果为开发针对性干预措施以促进对AI工具的适当依赖提供了见解，对AI在课程和教育技术中的整合具有启示意义。

</details>


### [260] [Computational Studies in Influencer Marketing: A Systematic Literature Review](https://arxiv.org/abs/2506.14602)
**中文标题：影响者营销的计算研究：系统性文献综述**

*Haoyang Gui,Thales Bertaglia,Catalina Goanta,Gerasimos Spanakis*

主要分类: cs.CY

摘要简述: 本文通过系统性文献综述（SLR）分析了69篇关于影响者营销的计算研究，总结了四大研究主题和方法分类，并呼吁更多关注伦理、合规及多学科研究。


<details>
  <summary>详细信息</summary>
研究动机: 影响者营销在数字营销中日益重要，但相关计算研究缺乏系统性综述，导致科学测量不足，影响平台外的利益相关者（如监管者和其他领域研究者）。本文旨在填补这一空白。

研究方法: 基于PRISMA模型进行系统性文献综述，分析69篇研究，识别主题和方法（机器学习与非机器学习技术）。

研究结果: 发现四大研究主题：影响者识别与特征、广告策略与互动、赞助内容分析与发现、公平性；方法以机器学习为主，但伦理和合规研究不足。

研究结论: 需更多结合上下文因素（如语言、平台）的精细化研究，提升模型可解释性和数据可重复性，并推动多学科研究议程。

中文摘要: 影响者营销已成为数字营销策略的关键部分。尽管其增长迅速且算法相关，但影响者营销的计算研究领域仍较为分散，尤其是缺乏系统性综述涵盖计算方法。这使得影响者经济的科学测量非常稀缺，损害了平台外利益相关者（如监管者和其他领域研究者）的利益。本文旨在通过基于PRISMA模型的系统性文献综述（SLR），概述影响者营销计算研究的最新进展。文章分析了69项研究，以识别该领域的关键研究主题、方法和未来方向。综述发现四大研究主题：影响者识别与特征、广告策略与互动、赞助内容分析与发现、公平性。方法上，研究分为基于机器学习的技术（如分类、聚类）和非机器学习技术（如统计分析、网络分析）。主要发现显示研究高度关注商业结果优化，但对合规和伦理关注有限。综述强调需要更精细的计算研究，结合语言、平台和行业类型等上下文因素，并提升模型可解释性和数据可重复性。文章最后提出多学科研究议程，强调需加强与合规技术的联系、更细粒度的分析，以及标准化数据集的开发。

</details>


### [261] [Rigor in AI: Doing Rigorous AI Work Requires a Broader, Responsible AI-Informed Conception of Rigor](https://arxiv.org/abs/2506.14652)
**中文标题：AI中的严谨性：进行严谨的AI工作需要更广泛、负责任的AI严谨性概念**

*Alexandra Olteanu,Su Lin Blodgett,Agathe Balayn,Angelina Wang,Fernando Diaz,Flavio du Pin Calmon,Margaret Mitchell,Michael Ekstrand,Reuben Binns,Solon Barocas*

主要分类: cs.CY

摘要简述: 本文主张AI研究与实践需要更广泛的严谨性概念，而不仅仅是方法论的严谨性，以解决负责任AI社区提出的问题，如夸大AI能力的声明。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI领域对严谨性的理解过于狭隘，主要集中在方法论上，这导致了负责任AI社区提出的问题，如夸大AI能力的声明。因此，作者认为需要更全面的严谨性概念。

研究方法: 作者提出了一种更广泛的严谨性框架，包括方法论严谨性、知识背景严谨性、规范性严谨性、概念严谨性、报告严谨性和解释严谨性六个方面。

研究结果: 通过扩展严谨性的定义，作者为AI社区提供了一个更全面的框架，以促进研究者、政策制定者、记者等利益相关者之间的对话。

研究结论: AI研究与实践需要更广泛的严谨性概念，以解决当前领域中的问题，并为未来的工作提供更坚实的基础。

中文摘要: 在AI研究和实践中，严谨性通常被理解为方法论的严谨性，例如数学、统计或计算方法是否正确应用。我们认为这种狭隘的严谨性概念加剧了负责任AI社区的担忧，包括对AI能力的夸大声明。我们的立场是，需要一种更广泛的严谨性概念来指导AI研究和实践。这种概念除了更广泛的方法论严谨性外，还应包括：（1）知识背景严谨性（决定研究内容）；（2）规范性严谨性（学科、社区或个人规范的影响）；（3）概念严谨性（理论构建的清晰性）；（4）报告严谨性（内容的报告方式）；（5）解释严谨性（从现有证据中推断的支持程度）。通过这一框架，我们旨在为研究者、政策制定者、记者等利益相关者提供有用的语言和工具，以促进关于AI社区工作的必要对话。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [262] [Hamiltonian Formalism for Comparing Quantum and Classical Intelligence](https://arxiv.org/abs/2506.14456)
**中文标题：比较量子与经典智能的哈密顿形式主义**

*Elija Perrier*

主要分类: quant-ph

摘要简述: 本文提出了一种哈密顿形式主义，用于比较量子与经典智能在环境交互中的差异，为量子与经典AGI任务提供数学框架。


<details>
  <summary>详细信息</summary>
研究动机: 量子基板上实现AGI的前景促使开发数学框架，以直接比较其在经典与量子环境中的操作差异。

研究方法: 引入哈密顿形式主义，将AGI动力学分解为核心功能（如归纳、推理、递归、学习、测量和记忆）的哈密顿生成器。

研究结果: 提出了一种数学语言，用于精确描述量子与经典智能在环境交互中的差异。

研究结论: 该形式主义为量子与经典AGI的对比研究提供了理论基础，有助于进一步探索两者差异。

中文摘要: 量子基板上实现AGI的前景促使开发数学框架，以直接比较其在经典与量子环境中的操作。为此，我们引入了一种哈密顿形式主义，用于描述经典与量子AGI任务，以对比它们与环境的交互。我们提出将AGI动力学分解为核心功能（如归纳、推理、递归、学习、测量和记忆）的哈密顿生成器。这一形式主义旨在为量子与经典智能在环境交互中的差异提供精确的数学语言。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [263] [BraTS orchestrator : Democratizing and Disseminating state-of-the-art brain tumor image analysis](https://arxiv.org/abs/2506.13807)
**中文标题：BraTS协调器：民主化和传播最先进的脑肿瘤图像分析技术**

*Florian Kofler,Marcel Rosier,Mehdi Astaraki,Ujjwal Baid,Hendrik Möller,Josef A. Buchner,Felix Steinbauer,Eva Oswald,Ezequiel de la Rosa,Ivan Ezhov,Constantin von See,Jan Kirschke,Anton Schmick,Sarthak Pati,Akis Linardos,Carla Pitarch,Sanyukta Adap,Jeffrey Rudie,Maria Correia de Verdier,Rachit Saluja,Evan Calabrese,Dominic LaBella,Mariam Aboian,Ahmed W. Moawad,Nazanin Maleki,Udunna Anazodo,Maruf Adewole,Marius George Linguraru,Anahita Fathi Kazerooni,Zhifan Jiang,Gian Marco Conte,Hongwei Li,Juan Eugenio Iglesias,Spyridon Bakas,Benedikt Wiestler,Marie Piraud,Bjoern Menze*

主要分类: eess.IV

摘要简述: BraTS orchestrator是一个开源Python工具包，旨在简化脑肿瘤图像分析中先进算法的使用，使其更易于科研和临床社区采纳。


<details>
  <summary>详细信息</summary>
研究动机: 尽管BraTS挑战赛在脑肿瘤图像分析领域取得了显著进展，但其开发的算法和模型在科学和临床社区中的采纳率有限。为了加速这些技术的传播，作者开发了BraTS orchestrator。

研究方法: BraTS orchestrator是一个开源Python工具包，提供对BraTS挑战赛中先进分割和合成算法的无缝访问。工具包包含直观的教程，适合编程经验有限的用户，便于部署算法进行推理。

研究结果: 通过简化现代深度学习的复杂性，BraTS orchestrator使更广泛的神经放射学和神经肿瘤学受众能够轻松使用BraTS社区开发的专业知识。

研究结论: BraTS orchestrator成功地将脑肿瘤图像分析的先进技术民主化，使其更易于被科研和临床社区采纳。

中文摘要: 脑肿瘤分割（BraTS）系列挑战赛通过提供大量经过整理的数据集并解决临床相关任务，显著推动了脑肿瘤图像分析的发展。然而，尽管其取得了成功并广受欢迎，通过BraTS开发的算法和模型在科学和临床社区中的采纳率仍然有限。为了加速其传播，我们推出了BraTS协调器，这是一个开源Python工具包，提供对BraTS挑战赛生态系统中多样脑肿瘤的最先进分割和合成算法的无缝访问。该工具包可在GitHub（https://github.com/BrainLesion/BraTS）上获取，并包含为编程经验有限的用户设计的直观教程，使研究人员和临床医生能够轻松部署获胜的BraTS算法进行推理。通过抽象现代深度学习的复杂性，BraTS协调器民主化了BraTS社区开发的专业知识的访问，使这些进步更易于被更广泛的神经放射学和神经肿瘤学受众使用。

</details>


### [264] [Reliable Noninvasive Glucose Sensing via CNN-Based Spectroscopy](https://arxiv.org/abs/2506.13819)
**中文标题：基于CNN光谱技术的可靠无创血糖传感**

*El Arbi Belfarsi,Henry Flores,Maria Valero*

主要分类: eess.IV

摘要简述: 本研究提出了一种基于短波红外光谱的双模态AI框架，结合卷积神经网络和光电二极管电压传感器，实现了高精度的无创血糖监测。


<details>
  <summary>详细信息</summary>
研究动机: 传统血糖监测方法需要侵入性操作，本研究旨在开发一种可靠、低成本且可穿戴的无创血糖监测技术。

研究方法: 研究采用双模态方法：第一模态使用多波长短波红外成像系统和CNN捕捉与葡萄糖吸收相关的空间特征；第二模态使用紧凑型光电二极管电压传感器和机器学习回归器处理归一化光学信号。两种方法均在合成血液模型和模拟皮肤材料上进行了测试。

研究结果: CNN在650 nm波长下的平均绝对百分比误差为4.82%，Clarke误差网格中Zone A覆盖率达100%；光电二极管系统的Zone A准确率为86.4%。

研究结论: 该框架在临床精度、成本效益和可穿戴性方面达到了先进水平，为可靠的无创连续血糖监测提供了新途径。

中文摘要: 本研究提出了一种基于短波红外（SWIR）光谱的双模态AI框架。第一模态采用多波长SWIR成像系统结合卷积神经网络（CNN）捕捉与葡萄糖吸收相关的空间特征；第二模态使用紧凑型光电二极管电压传感器和机器学习回归器（如随机森林）处理归一化光学信号。两种方法均在生理葡萄糖水平（70至200 mg/dL）的合成血液模型和模拟皮肤材料上进行了评估。CNN在650 nm波长下的平均绝对百分比误差（MAPE）为4.82%，Clarke误差网格中Zone A覆盖率达100%；光电二极管系统的Zone A准确率为86.4%。该框架在临床精度、成本效益和可穿戴集成方面达到了先进水平，为可靠的无创连续血糖监测铺平了道路。

</details>


### [265] [Latent Anomaly Detection: Masked VQ-GAN for Unsupervised Segmentation in Medical CBCT](https://arxiv.org/abs/2506.14209)
**中文标题：潜在异常检测：基于掩码VQ-GAN的医学CBCT无监督分割**

*Pengwei Wang*

主要分类: eess.IV

摘要简述: 本文提出了一种基于掩码VQ-GAN的无监督医学CBCT图像异常检测方法，通过两阶段训练实现自动分割，减少人工标注负担，并可直接用于3D打印。


<details>
  <summary>详细信息</summary>
研究动机: 由于颌骨放射性骨坏死（ONJ）影像数据标注稀缺，监督学习方法不适用。本研究旨在开发一种无监督训练方法，自动识别影像中的异常区域。

研究方法: 采用两阶段训练流程：第一阶段训练VQ-GAN精确重建正常样本；第二阶段通过随机立方体掩码和ONJ特定掩码训练新编码器以恢复数据。

研究结果: 该方法在模拟和真实患者数据上均实现了成功分割，为快速初始分割提供了解决方案。

研究结论: 该方法不仅减少了人工标注负担，还能结合后处理直接用于3D打印，具有实际应用潜力。

中文摘要: 治疗技术的进步使得可定制的3D打印水凝胶伤口敷料可用于颌骨放射性骨坏死（ORN）患者。同时，深度学习工具如nnUNet已能精确分割3D医学影像。然而，ONJ影像中标注数据的稀缺使得监督训练不切实际。本研究旨在开发一种无监督训练方法，自动识别影像扫描中的异常。我们提出了一种新颖的两阶段训练流程：第一阶段训练VQ-GAN以精确重建正常样本；第二阶段通过随机立方体掩码和ONJ特定掩码训练新编码器以恢复数据。该方法在模拟和真实患者数据上均实现了成功分割。这一方法提供了快速的初始分割解决方案，减轻了人工标注的负担。此外，结合手动调整的后处理，该方法还有潜力直接用于3D打印。

</details>


### [266] [orGAN: A Synthetic Data Augmentation Pipeline for Simultaneous Generation of Surgical Images and Ground Truth Labels](https://arxiv.org/abs/2506.14303)
**中文标题：orGAN：一种用于同时生成手术图像和真实标签的合成数据增强流程**

*Niran Nataraj,Maina Sogabe,Kenji Kawashima*

主要分类: eess.IV

摘要简述: 本文提出orGAN，一种基于GAN的系统，用于生成高保真、带注释的手术出血图像，解决医学影像中数据多样性不足、伦理问题和标注成本高的问题。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像中深度学习面临数据多样性不足、伦理问题、采集成本高和精确标注需求等挑战，尤其是手术中出血检测和定位因高质量数据集稀缺而尤为困难。

研究方法: orGAN基于StyleGAN和关系位置学习，利用小型“模拟器官”数据集生成逼真的出血图像并标注出血坐标，再通过LaMa修复模块恢复干净图像，实现像素级标注。

研究结果: 评估显示，orGAN生成的图像与模拟器官图像组合的数据集在手术场景中达到90%的检测准确率和99%的帧级准确率。

研究结论: 尽管开发数据缺乏多样性和包含术中伪影，orGAN显著推动了伦理、高效且低成本的真实标注出血数据集的生成，支持AI在手术中的广泛应用。

中文摘要: 医学影像中的深度学习面临数据多样性有限、伦理问题、采集成本高和精确标注需求等障碍。手术中的出血检测和定位尤其困难，因为缺乏反映真实手术场景的高质量数据集。我们提出orGAN，一种基于GAN的系统，用于生成高保真、带注释的手术出血图像。通过利用小型“模拟器官”数据集和模拟组织特性及出血的合成模型，我们的方法减少了伦理问题和数据采集成本。orGAN基于StyleGAN和关系位置学习，逼真模拟出血事件并标注出血坐标。随后，基于LaMa的修复模块恢复干净的出血前图像，实现精确的像素级标注。评估中，orGAN和模拟器官图像的平衡数据集在手术场景中达到90%的检测准确率和99%的帧级准确率。尽管开发数据缺乏器官形态多样性和包含术中伪影，orGAN显著推动了伦理、高效且低成本的真实标注出血数据集的生成，支持AI在手术中的更广泛应用。

</details>


### [267] [BRISC: Annotated Dataset for Brain Tumor Segmentation and Classification with Swin-HAFNet](https://arxiv.org/abs/2506.14318)
**中文标题：BRISC：基于Swin-HAFNet的脑肿瘤分割与分类标注数据集**

*Amirreza Fateh,Yasin Rezvani,Sara Moayedi,Sadjad Rezvani,Fatemeh Fateh,Mansoor Fateh*

主要分类: eess.IV

摘要简述: 本文介绍了一个新的脑肿瘤分割与分类数据集BRISC，包含6000个标注MRI扫描，并提出了一种基于Transformer的分割模型，取得了82.3%的加权平均IoU。


<details>
  <summary>详细信息</summary>
研究动机: 当前脑肿瘤的MRI分割与分类面临高质量、平衡且多样化的数据集不足的挑战，因此需要构建一个专门的数据集以支持相关研究。

研究方法: 研究团队构建了一个包含6000个标注MRI扫描的数据集，涵盖三种主要脑肿瘤类型及非肿瘤病例，并提出了一种基于Transformer的分割模型Swin-HAFNet。

研究结果: 提出的分割模型在加权平均IoU上达到82.3%，在所有肿瘤类别中均表现出改进。

研究结论: BRISC数据集为脑肿瘤分割与分类研究提供了重要资源，未来可支持学术研究和临床决策支持系统的开发。

中文摘要: 脑肿瘤的准确分割与分类在医学影像分析中仍面临挑战，主要由于缺乏高质量、平衡且多样化的数据集。本研究提出了一个专门用于脑肿瘤分割与分类任务的新MRI数据集。该数据集包含6000个由认证放射科医生和医师标注的对比增强T1加权MRI扫描，涵盖三种主要肿瘤类型（胶质瘤、脑膜瘤和垂体瘤）以及非肿瘤病例。每个样本均包含高分辨率标签，并按轴向、矢状面和冠状面分类，以支持稳健的模型开发和跨视图泛化。为展示数据集的实用性，我们提出了一种基于Transformer的分割模型，并与现有基线进行了对比。我们的方法在所有肿瘤类别中均取得改进，加权平均IoU达到82.3%。本研究主要作为数据集的介绍，为未来研究奠定基础。我们期望该数据集能成为推动神经肿瘤学中机器学习应用的重要资源，支持学术研究和临床决策支持系统的开发。数据集链接：https://www.kaggle.com/datasets/briscdataset/brisc2025/

</details>


### [268] [Compressed Video Super-Resolution based on Hierarchical Encoding](https://arxiv.org/abs/2506.14381)
**中文标题：基于分层编码的压缩视频超分辨率**

*Yuxuan Jiang,Siyue Teng,Qiang Zhu,Chen Feng,Chengxi Zeng,Fan Zhang,Shuyuan Zhu,Bing Zeng,David Bull*

主要分类: eess.IV

摘要简述: 本文提出了一种名为VSR-HE的通用视频超分辨率方法，专为提升压缩内容的感知质量而设计。通过分层编码变换块，该方法能够有效消除H.265/HEVC编码引入的压缩伪影，并在多种量化参数下恢复精细细节。


<details>
  <summary>详细信息</summary>
研究动机: 针对高压缩场景下的视频质量下降问题，本文旨在开发一种能够提升低分辨率视频（如从180p到720p）的超分辨率方法，同时消除压缩伪影，保持视觉保真度。

研究方法: VSR-HE采用分层编码变换块，通过精心优化的模型处理H.265/HEVC编码引入的压缩伪影，并在多种量化参数下进行训练和评估，以确保模型的鲁棒性和泛化能力。

研究结果: 实验表明，VSR-HE能够有效恢复压缩视频的精细细节，并在多种压缩设置下保持视觉保真度。该方法已提交至ICME 2025的VSR挑战赛。

研究结论: VSR-HE是一种高效的视频超分辨率方法，特别适用于高压缩场景，能够显著提升视频质量并消除压缩伪影。

中文摘要: 本文提出了一种通用视频超分辨率方法VSR-HE，专门用于提升压缩内容的感知质量。针对高压缩场景，该方法将低分辨率视频（如从180p到720p或从270p到1080p）进行四倍放大。VSR-HE采用分层编码变换块，并经过精心优化，以消除H.265/HEVC编码在不同量化参数（QP）水平下引入的多种压缩伪影。为确保模型的鲁棒性和泛化能力，该方法在多种压缩设置下进行训练和评估，能够有效恢复精细细节并保持视觉保真度。VSR-HE已正式提交至ICME 2025视频会议超分辨率挑战赛（Team BVI-VSR），参与Track 1（通用真实世界视频内容）和Track 2（头部视频）的竞赛。

</details>


### [269] [A large-scale heterogeneous 3D magnetic resonance brain imaging dataset for self-supervised learning](https://arxiv.org/abs/2506.14432)
**中文标题：用于自监督学习的大规模异构3D磁共振脑成像数据集**

*Asbjørn Munk,Stefano Cerri,Jakob Ambsdorf,Julia Machnio,Sebastian Nørgaard Llambias,Vardan Nersesjan,Christian Hedeager Krag,Peirong Liu,Pablo Rocamora García,Mostafa Mehdipour Ghazi,Mikael Boesen,Michael Eriksen Benros,Juan Eugenio Iglesias,Mads Nielsen*

主要分类: eess.IV

摘要简述: 本文介绍了FOMO60K，一个包含60,529个脑部MRI扫描的大规模异构数据集，旨在支持医学影像中自监督学习方法的开发和基准测试。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像领域缺乏大规模、多样化的数据集，限制了自监督学习方法的发展。FOMO60K的提出旨在填补这一空白，提供丰富的临床和研究级图像资源。

研究方法: 数据集FOMO60K整合了16个公开来源的60,529个脑部MRI扫描，涵盖多种MRI序列和广泛的解剖及病理变异。仅进行最小预处理以保留原始图像特征。

研究结果: FOMO60K包含13,900次扫描会话和11,187名受试者的数据，支持自监督预训练和微调，并附带相关代码。

研究结论: FOMO60K为医学影像中的自监督学习提供了大规模、多样化的基准数据集，有望推动该领域的研究进展。

中文摘要: 我们提出了FOMO60K，这是一个包含60,529个脑部磁共振成像（MRI）扫描的大规模异构数据集，来自13,900次扫描会话和11,187名受试者，整合了16个公开来源的数据。数据集包含临床和研究级图像、多种MRI序列，以及广泛的解剖和病理变异，包括具有显著脑部异常的扫描。仅进行了最小预处理以保留原始图像特征，同时降低新用户的使用门槛。提供了自监督预训练和微调的配套代码。FOMO60K旨在支持大规模医学影像中自监督学习方法的开发和基准测试。

</details>


### [270] [Towards Reliable WMH Segmentation under Domain Shift: An Application Study using Maximum Entropy Regularization to Improve Uncertainty Estimation](https://arxiv.org/abs/2506.14497)
**中文标题：面向域偏移下可靠的白质高信号分割：基于最大熵正则化改进不确定性估计的应用研究**

*Franco Matzkin,Agostina Larrazabal,Diego H Milone,Jose Dolz,Enzo Ferrante*

主要分类: eess.IV

摘要简述: 本文研究了白质高信号（WMH）分割在域偏移下的可靠性问题，提出最大熵正则化技术以提升模型校准和不确定性估计，实验表明该方法能有效预测分割错误并增强性能。


<details>
  <summary>详细信息</summary>
研究动机: 白质高信号（WMH）分割对临床决策至关重要，但MRI设备或参数差异导致的域偏移会影响模型校准和不确定性估计。本研究旨在通过改进不确定性估计，无需真实标签即可识别分割错误。

研究方法: 采用U-Net架构，结合最大熵正则化技术，在两个公开数据集上评估模型性能，使用Dice系数、预期校准误差和基于熵的不确定性估计作为指标。

研究结果: 结果表明，基于熵的不确定性估计能预测分割错误，最大熵正则化进一步增强了不确定性与分割性能的关联，并改善了域偏移下的模型校准。

研究结论: 最大熵正则化技术能有效提升WMH分割在域偏移下的可靠性，为临床决策提供更准确的工具。

中文摘要: 白质高信号（WMH）的准确分割对临床决策至关重要，尤其是在多发性硬化症背景下。然而，MRI设备类型或采集参数的差异等域偏移对模型校准和不确定性估计提出了重大挑战。本研究通过提出最大熵正则化技术来增强模型校准和不确定性估计，探讨了域偏移对WMH分割的影响，目的是利用预测不确定性作为无需真实标签的代理指标来识别部署后的错误。为此，我们使用U-Net架构进行了实验，在两个公开数据集上评估这些正则化方案，并通过Dice系数、预期校准误差和基于熵的不确定性估计来评估性能。结果显示，基于熵的不确定性估计可以预测分割错误，而最大熵正则化进一步增强了不确定性与分割性能之间的相关性，同时改善了域偏移下的模型校准。

</details>


### [271] [Integrating Radiomics with Deep Learning Enhances Multiple Sclerosis Lesion Delineation](https://arxiv.org/abs/2506.14524)
**中文标题：结合放射组学与深度学习增强多发性硬化病灶分割**

*Nadezhda Alsahanova,Pavel Bartenev,Maksim Sharaev,Milos Ljubisavljevic,Taleb Al. Mansoori,Yauhen Statsenko*

主要分类: eess.IV

摘要简述: 本研究通过结合放射组学与深度学习技术，显著提升了多发性硬化（MS）病灶分割的准确性和模型稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度学习方法在多发性硬化（MS）病灶分割中存在鲁棒性不足的问题，本研究旨在通过融合放射组学特征与原始影像数据，提升分割性能。

研究方法: 研究提出两种新型放射组学特征（浓度率和Rényi熵）以区分不同MS病灶类型，并将其与原始影像数据融合。采用ResNeXt-UNet和注意力增强U-Net架构进行模型训练，并在46名患者的1102张切片上评估性能。

研究结果: 融合放射组学的ResNeXt-UNet显著提升了分割精度和敏感性（Dice分数0.774±0.05；p<0.001），而注意力增强U-Net模型表现出更高的稳定性（SDD降低至0.18±0.09；p=0.03）。

研究结论: 研究证实，融合放射组学与原始影像数据能够显著提升现有模型的分割性能和稳定性。

中文摘要: 背景：准确的病灶分割对多发性硬化（MS）诊断至关重要，但当前深度学习方法面临鲁棒性挑战。
目标：本研究通过结合数据融合与深度学习技术，改进MS病灶分割。
材料与方法：提出新型放射组学特征（浓度率和Rényi熵）以区分不同MS病灶类型，并将其与原始影像数据融合。研究通过ResNeXt-UNet和注意力增强U-Net架构整合放射组学特征，并在46名患者的1102张切片上评估性能。
结果：融合放射组学的ResNeXt-UNet表现出高分割精度（Dice分数0.774±0.05；p<0.001），而注意力增强U-Net模型稳定性更高（SDD=0.18±0.09；p=0.03）。
结论：结果验证了融合放射组学与原始影像数据能够提升现有模型的分割性能和稳定性。

</details>


### [272] [Plug-and-Play with 2.5D Artifact Reduction Prior for Fast and Accurate Industrial Computed Tomography Reconstruction](https://arxiv.org/abs/2506.14719)
**中文标题：基于2.5D伪影减少先验的即插即用快速精确工业CT重建方法**

*Haley Duba-Sullivan,Aniket Pramanik,Venkatakrishnan Singanallur,Amirkoushyar Ziabari*

主要分类: eess.IV

摘要简述: 本文提出了一种基于2.5D伪影减少先验的即插即用（PnP）重建方法，用于快速且精确的工业CT重建。该方法通过利用相邻切片信息，显著提升了稀疏视图CT扫描的图像质量，并直接抑制常见伪影，无需额外预处理。


<details>
  <summary>详细信息</summary>
研究动机: 传统稀疏视图CT重建方法使用2D卷积神经网络（CNN）作为伪影减少先验，仅能捕获切片独立信息，限制了性能。本文旨在通过引入2.5D CNN先验，利用相邻切片信息提升重建质量，并直接抑制常见伪影。

研究方法: 提出了一种即插即用（PnP）重建框架，采用2.5D CNN作为伪影减少先验。该方法通过捕获相邻切片间的空间上下文信息，提升重建质量，同时保持计算效率。此外，该方法能够直接抑制如束硬化等常见伪影，无需额外预处理。

研究结果: 实验结果表明，与2D先验相比，2.5D先验在合成和实验锥束CT数据上均能更好地保留细微结构（如孔隙大小和形状），从而提升缺陷检测的准确性。此外，该方法在模拟扫描训练的2.5D先验上表现出强大的跨域泛化能力。

研究结论: 本文提出的2.5D伪影减少先验方法显著提升了稀疏视图CT重建的质量和效率，同时能够直接抑制常见伪影，展示了其在工业CT应用中的潜力。

中文摘要: 锥束X射线计算机断层扫描（XCT）是一种用于生成内部结构3D重建的重要成像技术，广泛应用于医学和工业成像领域。高质量重建通常需要大量X射线测量，这一过程耗时且昂贵，尤其是对高密度材料。近年来，将伪影减少先验纳入即插即用（PnP）重建框架的方法在稀疏视图XCT扫描中显示出提升图像质量和增强深度学习解决方案泛化性的潜力。然而，该方法使用2D卷积神经网络（CNN）进行伪影减少，仅能捕获3D重建中的切片独立信息，限制了性能。本文提出了一种采用2.5D伪影减少CNN作为先验的PnP重建方法。该方法利用相邻切片的切片间信息，捕获更丰富的空间上下文，同时保持计算效率。实验表明，2.5D先验不仅提升了重建质量，还能直接抑制常见XCT伪影（如束硬化），无需额外预处理。在合成和实验锥束XCT数据上的实验证明，与2D先验相比，该方法能更好地保留细微结构（如孔隙大小和形状），从而提升缺陷检测的准确性。特别地，我们展示了基于模拟扫描训练的2.5D伪影减少先验在实验XCT数据上的强大性能，凸显了该方法在跨域泛化方面的能力。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [273] [Knowledge Compression via Question Generation: Enhancing Multihop Document Retrieval without Fine-tuning](https://arxiv.org/abs/2506.13778)
**中文标题：通过问题生成实现知识压缩：无需微调的多跳文档检索增强**

*Anvi Alex Eponon,Moein Shahiki-Tash,Ildar Batyrshin,Christian E. Maldonado-Sifuentes,Grigori Sidorov,Alexander Gelbukh*

主要分类: cs.IR

摘要简述: 本研究提出了一种基于问题生成的知识编码方法，无需微调即可提升检索增强生成（RAG）系统的性能。通过生成覆盖词汇和语义空间的问题，结合自定义语法重排序方法，显著提高了单跳和多跳检索任务的效果。


<details>
  <summary>详细信息</summary>
研究动机: 传统检索增强生成系统通常需要微调或分块处理，效率较低且存储需求高。本研究旨在开发一种无需微调的方法，通过问题生成和重排序技术提升检索性能，降低延迟和存储成本。

研究方法: 方法包括生成覆盖文本词汇和语义空间的问题作为检索线索，并结合自定义语法重排序技术。此外，还引入了“paper-cards”（简洁的论文摘要）以增强BM25检索效果。

研究结果: 在单跳检索任务中，Recall@3达到0.84，优于传统分块方法60%。在多跳任务中，F1分数为0.52，超过分块和微调基线。存储需求降低80%。

研究结论: 该方法无需微调，显著提升了检索性能，降低了延迟和存储需求，为检索增强生成系统提供了一种高效且可扩展的替代方案。

中文摘要: 本研究提出了一种基于问题生成的知识编码方法，无需微调或传统分块即可提升检索增强生成（RAG）系统的性能。通过生成覆盖词汇和语义空间的问题，结合自定义语法重排序方法，显著提高了检索效果。在109篇科学论文的单跳检索任务中，Recall@3达到0.84，优于传统分块方法60%。此外，引入的“paper-cards”（简洁的论文摘要）增强了BM25检索，将简化技术查询的MRR@3从0.56提升至0.85。在多跳任务中，重排序方法在LongBench 2WikiMultihopQA数据集上实现了0.52的F1分数（使用LLaMA2-Chat-7B），超过分块和微调基线（分别为0.328和0.412）。该方法无需微调，降低了检索延迟，实现了直观的问题驱动知识访问，并将向量存储需求减少80%，是一种高效且可扩展的RAG替代方案。

</details>


### [274] [XGraphRAG: Interactive Visual Analysis for Graph-based Retrieval-Augmented Generation](https://arxiv.org/abs/2506.13782)
**中文标题：XGraphRAG：基于图的检索增强生成的交互式可视化分析**

*Ke Wang,Bo Pan,Yingchaojie Feng,Yuwei Wu,Jieyi Chen,Minfeng Zhu,Wei Chen*

主要分类: cs.IR

摘要简述: 本文提出XGraphRAG，一种交互式可视化分析框架，用于帮助开发者分析基于图的检索增强生成（GraphRAG）的效果，提升其可解释性和可访问性。


<details>
  <summary>详细信息</summary>
研究动机: GraphRAG通过引入图结构提升了检索增强生成的精度和全面性，但其复杂的信息处理流程和大量LLM调用限制了开发者的分析能力，亟需一种工具来提升其可解释性和可访问性。

研究方法: 研究提出了一种可视化分析框架，帮助开发者识别GraphRAG中的关键召回并追踪其处理流程。基于此框架，开发了XGraphRAG原型系统，集成交互式可视化工具以支持用户分析。

研究结果: 评估表明，XGraphRAG能有效提升开发者对GraphRAG的分析能力，帮助识别失败案例和改进机会。

研究结论: XGraphRAG为GraphRAG提供了一种实用的可视化分析工具，显著提升了其可解释性和可访问性，未来可进一步优化和扩展。

中文摘要: 基于图的检索增强生成（GraphRAG）通过引入图作为中间表示，显著提升了大型语言模型（LLM）在外部知识库支持下的生成精度和全面性。然而，开发者通常难以分析GraphRAG在其数据集上的效果，原因在于其复杂的信息处理流程和大量的LLM调用，这限制了GraphRAG的可解释性和可访问性。本研究提出了一种可视化分析框架，帮助开发者识别GraphRAG中的关键召回并追踪其处理流程。基于此框架，我们开发了XGraphRAG原型系统，集成了一套交互式可视化工具，以支持用户的分析过程，促进失败案例的收集和改进机会的识别。评估结果表明，我们的方法具有高效性和可用性。本工作已开源，详见https://github.com/Gk0Wk/XGraphRAG。

</details>


### [275] [Analysis of Anonymous User Interaction Relationships and Prediction of Advertising Feedback Based on Graph Neural Network](https://arxiv.org/abs/2506.13787)
**中文标题：基于图神经网络的匿名用户交互关系分析与广告反馈预测**

*Yanjun Dai,Haoyang Feng,Yuan Gao*

主要分类: cs.IR

摘要简述: 本文提出了一种解耦时序层次图神经网络（DTH-GNN），通过多通道特征提取和层次异构聚合，显著提升了匿名用户广告反馈预测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有图模型难以捕捉匿名用户交互网络的多尺度时序、语义和高阶依赖特征，无法描述复杂行为模式，因此需要一种更高效的模型。

研究方法: DTH-GNN采用时序边分解将交互分为短时突发、昼夜周期和长时记忆三通道，并利用并行残差卷积核提取特征；通过元路径条件Transformer编码器实现层次异构聚合，结合跨通道自注意力和门控关系选择器抑制噪声；提出反馈感知对比正则化，优化节点表示。

研究结果: DTH-GNN的AUC提升8.2%，对数损失降低5.7%，优于基线模型。

研究结论: DTH-GNN通过多通道时序建模和层次聚合，显著提升了匿名用户广告反馈预测性能，为广告策略优化提供了新思路。

中文摘要: 在线广告高度依赖匿名用户的隐式交互网络进行参与度推断和投放策略优化，但现有图模型难以捕捉这些交互网络的多尺度时序、语义和高阶依赖特征，无法描述复杂行为模式。本文提出解耦时序层次图神经网络（DTH-GNN），主要贡献包括：首先，引入时序边分解，将交互分为短时突发、昼夜周期和长时记忆三通道，利用并行残差卷积核提取特征；其次，构建层次异构聚合模型，通过元路径条件Transformer编码器结合用户-用户、用户-广告、广告-广告子图，并利用跨通道自注意力和门控关系选择器动态抑制噪声结构；第三，提出反馈感知对比正则化，最大化各时间片一致性，优化双视图目标控制曝光信息熵，结合轻量策略梯度层和延迟变换信号微调节点表示。实验表明，DTH-GNN的AUC提升8.2%，对数损失降低5.7%，优于基线模型。

</details>


### [276] [AcademicBrowse: Benchmarking Academic Browse Ability of LLMs](https://arxiv.org/abs/2506.13784)
**中文标题：AcademicBrowse：大语言模型学术浏览能力的基准评测**

*Junting Zhou,Wang Li,Yiyan Liao,Nengyuan Zhang,Tingjia Miaoand Zhihui Qi,Yuhan Wu,Tong Yang*

主要分类: cs.IR

摘要简述: 本文提出了首个专门评估大语言模型（LLMs）在学术研究中复杂信息检索能力的数据集AcademicBrowse，具备学术实用性、高难度、简洁评估和广泛覆盖等特点。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大语言模型搜索能力评测基准（如OpenAI的BrowseComp）主要关注通用搜索场景，未能充分满足学术搜索的特定需求，如深度文献追踪、学术数据库支持、长尾学术知识导航及学术严谨性保障。

研究方法: 设计并构建了AcademicBrowse数据集，其特点包括：学术实用性（问题贴近真实学术环境）、高难度（需多次深度搜索才能解答）、简洁评估（答案唯一且有明确来源）、广泛覆盖（涵盖15个学科）。

研究结果: AcademicBrowse数据集填补了国内外缺乏分析性搜索数据集的空白，能够更精准地衡量和推动LLMs在复杂学术信息检索任务中的性能提升。

研究结论: AcademicBrowse为LLMs在学术搜索领域的性能评测提供了首个专门工具，有望促进相关技术的进一步发展。

中文摘要: 大语言模型（LLMs）的搜索能力备受关注。现有评测基准（如OpenAI的BrowseComp）主要针对通用搜索场景，未能充分满足学术搜索的特定需求，包括深度文献追踪与组织、学术数据库的专业支持、长尾学术知识的导航能力及学术严谨性保障。为此，我们提出了AcademicBrowse，首个专门用于评估LLMs在学术研究中复杂信息检索能力的数据集。AcademicBrowse具备以下关键特点：学术实用性（问题内容贴近真实学术环境，避免刻意误导模型）、高难度（答案需至少三次深度搜索才能得出）、简洁评估（限制条件确保答案唯一，附带明确来源和简短解释，便于后续审核验证）、广泛覆盖（涵盖至少15个学科）。通过AcademicBrowse，我们期望更精准地衡量并推动LLMs在复杂学术信息检索任务中的性能提升。数据集地址：https://huggingface.co/datasets/PKU-DS-LAB/AcademicBrowse

</details>


### [277] [InsertRank: LLMs can reason over BM25 scores to Improve Listwise Reranking](https://arxiv.org/abs/2506.14086)
**中文标题：InsertRank：大语言模型可通过BM25分数推理提升列表式重新排序效果**

*Rahul Seetharaman,Kaustubh D. Dhole,Aman Bansal*

主要分类: cs.IR

摘要简述: InsertRank是一种基于大语言模型（LLM）的重新排序方法，通过结合BM25分数提升检索性能，在多个领域和任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型在信息检索任务中的广泛应用，用户对复杂查询的需求增加，传统的关键词匹配或语义相似性方法已不足以满足需求。因此，需要一种能够结合推理能力和传统检索信号（如BM25分数）的重新排序方法。

研究方法: InsertRank利用大语言模型的推理能力，结合BM25分数等词汇信号进行重新排序，从而提升检索效果。该方法在多个LLM家族（如GPT、Gemini和Deepseek）中进行了验证。

研究结果: 在BRIGHT（涵盖12个领域的推理基准）和R2MED（涵盖8个任务的医学推理基准）上，InsertRank表现优异。例如，使用Deepseek-R1时，InsertRank在BRIGHT和R2MED上的得分分别为37.5和51.1，超越了之前的方法。

研究结论: InsertRank通过结合大语言模型的推理能力和传统检索信号，显著提升了检索性能，适用于多种复杂查询场景。

中文摘要: 大语言模型（LLMs）凭借其强大的泛化能力和从大规模预训练中获得的知识迁移能力，在信息检索任务中取得了显著进展，尤其是在重新排序任务中。与此同时，基于LLM的聊天界面的兴起提高了用户期望，鼓励用户提出更复杂的查询，这些查询需要通过“推理”文档而非简单的关键词匹配或语义相似性来检索。尽管最近一些研究尝试利用LLMs的推理能力重新排序此类查询，但仍存在较大的改进空间。为此，我们提出了InsertRank，一种基于LLM的重新排序方法，在重新排序过程中利用BM25分数等词汇信号进一步提升检索性能。InsertRank在BRIGHT（涵盖12个多样化领域的推理基准）和R2MED（涵盖8个不同任务的医学推理基准）上表现出更高的检索效果。我们进行了详尽的评估和多项消融研究，证明InsertRank在包括GPT、Gemini和Deepseek模型在内的多个LLM家族中均能持续提升检索效果。使用Deepseek-R1时，InsertRank在BRIGHT和R2MED基准上的得分分别为37.5和51.1，超越了之前的方法。

</details>


### [278] [RAGtifier: Evaluating RAG Generation Approaches of State-of-the-Art RAG Systems for the SIGIR LiveRAG Competition](https://arxiv.org/abs/2506.14412)
**中文标题：RAGtifier：评估SIGIR LiveRAG竞赛中最先进RAG系统的生成方法**

*Tim Cofala,Oleh Astappiev,William Xion,Hailay Teklehaymanot*

主要分类: cs.IR

摘要简述: 本文介绍了在SIGIR LiveRAG竞赛中评估RAG生成方法的研究，通过结合InstructRAG、Pinecone检索器和BGE重排器，最终方案在竞赛中排名第四。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索检索增强生成（RAG）技术，以提升大型语言模型（LLMs）的事实准确性并减少幻觉，同时参与SIGIR LiveRAG竞赛以验证方法的有效性。

研究方法: 研究采用了InstructRAG结合Pinecone检索器和BGE重排器的方法，在竞赛条件下测试了不同检索器组合和RAG解决方案。

研究结果: 最终方案在SIGIR 2025 LiveRAG竞赛中获得了1.13的正确性分数和0.55的忠实性分数，排名第四。

研究结论: 研究表明，InstructRAG结合Pinecone检索器和BGE重排器是一种有效的RAG解决方案，能够在竞赛条件下取得优异成绩。

中文摘要: 检索增强生成（RAG）通过将大型语言模型（LLMs）的内部参数化知识与外部非参数化来源结合，旨在提高事实准确性并减少幻觉。LiveRAG 2025挑战赛探索了RAG解决方案，以最大化对DataMorgana问答对的准确性，这些问答包括单跳和多跳问题。挑战赛提供了对Fineweb 10BT数据集的稀疏OpenSearch和密集Pinecone索引的访问，并限制使用参数不超过10B的LLMs，最终答案生成使用Falcon-3-10B。评委LLM和人类评估者共同评估提交的答案。通过探索挑战条件下的不同检索器组合和RAG解决方案，我们的最终方案采用了InstructRAG结合Pinecone检索器和BGE重排器。该方案在SIGIR 2025 LiveRAG竞赛中获得了1.13的正确性分数和0.55的忠实性分数，排名第四。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [279] [NeuroCoreX: An Open-Source FPGA-Based Spiking Neural Network Emulator with On-Chip Learning](https://arxiv.org/abs/2506.14138)
**中文标题：NeuroCoreX：一种支持片上学习的开源FPGA脉冲神经网络模拟器**

*Ashish Gautam,Prasanna Date,Shruti Kulkarni,Robert Patton,Thomas Potok*

主要分类: cs.NE

摘要简述: 本文介绍了NeuroCoreX，一种基于FPGA的开源脉冲神经网络（SNN）模拟器，支持片上学习和多样化网络拓扑结构，旨在推动高效能生物启发计算的研究与开发。


<details>
  <summary>详细信息</summary>
研究动机: 脉冲神经网络（SNN）因其事件驱动特性在能效方面表现优异，但传统人工神经网络（ANN）的架构限制了其灵活性。本文旨在通过开发一种支持多样化连接模式和片上学习的FPGA模拟器，解决SNN在实际部署中的灵活性和效率问题。

研究方法: NeuroCoreX基于FPGA实现，支持全连接网络拓扑，采用泄漏积分发放（LIF）神经元模型和基于电流的突触。其学习机制基于脉冲时序依赖可塑性（STDP），并通过UART接口实现网络参数配置。用户可通过Python接口进行交互。

研究结果: NeuroCoreX成功实现了灵活的SNN模拟，支持多种网络拓扑和片上学习，并通过开源框架加速了高效能生物启发计算的研究。

研究结论: NeuroCoreX为SNN的研究与开发提供了高效、灵活的开源工具，推动了生物启发计算领域的进步。

中文摘要: 脉冲神经网络（SNN）是一种受生物神经元网络结构和动态启发的计算模型，其事件驱动特性使其在能效方面表现优异，尤其是在神经形态硬件平台上部署时。与传统人工神经网络（ANN）主要依赖分层架构不同，SNN天然支持从传统分层结构到局部密集、全局稀疏的小世界图等多种连接模式。本文介绍了NeuroCoreX，一种基于FPGA的模拟器，专为灵活协同设计和测试SNN而设计。NeuroCoreX支持全连接网络拓扑，能够实现多样化的网络结构而不受架构限制。其采用基于脉冲时序依赖可塑性（STDP）的生物启发局部学习机制，神经元模型为泄漏积分发放（LIF）模型，突触基于电流实现脉冲的整合与传输。通过通用异步收发器（UART）接口，用户可以编程和配置网络参数，包括神经元、突触和学习规则设置。用户通过简单的Python接口与模拟器交互，简化了从模型设计到硬件执行的SNN部署流程。NeuroCoreX作为开源框架发布，旨在加速高效能生物启发计算的研究与开发。

</details>


### [280] [Is Selection All You Need in Differential Evolution?](https://arxiv.org/abs/2506.14425)
**中文标题：差分进化中，选择机制是否足够？**

*Tomofumi Kitamura,Alex Fukunaga*

主要分类: cs.NE

摘要简述: 本文提出了一种名为无界差分进化（UDE）的新框架，通过完全取消传统差分进化中的个体替换机制，仅依赖选择机制，简化了算法设计并提升了搜索能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统差分进化（DE）算法在固定种群大小下存在种群多样性不足的问题，而现有的存档机制虽能缓解这一问题，但引入了额外的设计复杂性。本文旨在提出一种更简单且高效的替代方案。

研究方法: 提出无界差分进化（UDE）框架，取消传统DE中的个体替换步骤，将所有生成的候选个体保留在种群中，仅通过选择机制优化搜索过程。

研究结果: UDE通过取消替换机制和存档管理，简化了算法设计，同时提升了搜索能力，为差分进化提供了一种更高效的实现方式。

研究结论: UDE是一种全新的差分进化方法，仅依赖选择机制，避免了传统DE的复杂性，为黑盒优化问题提供了更简单且强大的解决方案。

中文摘要: 差分进化（DE）是一种广泛应用于黑盒优化问题的进化算法。然而，在现代DE实现中，固定种群大小导致的种群多样性不足是一个主要挑战。种群大小是一个关键控制参数，显著影响DE性能。较大的种群包含更多样化的个体，有助于更广泛地探索搜索空间；而在评估预算受限时，较小的种群可能更适合专注于少数有潜力的候选个体。许多先进的DE变体采用存档机制，保留部分被淘汰个体并在变异操作中重用，但这引入了额外的设计复杂性，如插入、删除和大小调整策略。为解决这些问题，我们提出了一种名为无界差分进化（UDE）的新框架，将所有生成的候选个体加入种群，不基于适应度淘汰任何个体。与传统DE不同，UDE完全取消了替换机制及相关复杂性，仅依赖选择机制，提供了一种更简单且强大的搜索算法。

</details>


### [281] [A Scalable Hybrid Training Approach for Recurrent Spiking Neural Networks](https://arxiv.org/abs/2506.14464)
**中文标题：循环脉冲神经网络的可扩展混合训练方法**

*Maximilian Baronig,Yeganeh Bahariasl,Ozan Özdenizci,Robert Legenstein*

主要分类: cs.NE

摘要简述: 本文提出了一种名为HYPR的混合训练方法，结合并行化与近似在线前向学习，解决了循环脉冲神经网络（RSNN）训练中的内存消耗和在线学习问题，并在振荡亚阈值动态神经元模型中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 循环脉冲神经网络（RSNN）在神经形态系统中高效实现，但传统基于梯度的学习方法（如BPTT）存在内存消耗大且不支持在线学习的限制。前向梯度学习方法虽支持在线学习，但在传统硬件上速度慢且性能较差。因此，需要一种兼具高效并行化和在线学习能力的新方法。

研究方法: 本文提出HYPR（混合传播）算法，结合并行化与近似在线前向学习。该方法通过并行化实现高吞吐量的在线学习，同时保持与序列长度无关的恒定内存需求，适用于几乎任意非线性脉冲神经元模型的RSNN。

研究结果: HYPR在振荡亚阈值动态神经元模型中表现出色，显著缩小了近似前向梯度学习与BPTT之间的任务性能差距，实现了前所未有的低性能差距。

研究结论: HYPR为RSNN训练提供了一种高效、内存友好的解决方案，特别适用于在线学习和复杂神经元模型，为神经形态计算的实际应用开辟了新途径。

中文摘要: 循环脉冲神经网络（RSNN）在神经形态系统中可以实现高效运行。然而，这些模型的训练通常采用基于时间的反向传播（BPTT）在标准数字硬件上进行，但BPTT存在显著限制：不支持在线训练，且内存消耗随计算步骤线性增加。相比之下，基于前向梯度传播的学习方法支持在线学习，且内存消耗与时间步长无关，使SNN能够从连续、无限长的输入序列中学习。然而，这些方法在传统硬件上执行速度慢且性能较差，限制了其广泛应用。本文提出HYPR（混合传播）方法，结合并行化与近似在线前向学习。该算法通过并行化实现高吞吐量的在线学习，同时保持与序列长度无关的恒定内存需求。HYPR支持对几乎任意非线性脉冲神经元模型的RSNN进行子序列参数更新的并行计算。我们将HYPR应用于具有振荡亚阈值动态的脉冲神经元网络，发现此类神经元模型特别适合HYPR训练，实现了近似前向梯度学习与BPTT之间前所未有的低任务性能差距。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [282] [A Survey on World Models Grounded in Acoustic Physical Information](https://arxiv.org/abs/2506.13833)
**中文标题：基于声学物理信息的世界模型研究综述**

*Xiaoliang Chen,Le Chang,Xin Yu,Yunhe Huang,Xianling Tu*

主要分类: cs.SD

摘要简述: 本文综述了基于声学物理信息的世界模型研究，涵盖理论、方法、技术进展及应用，探讨了其在机器人、自动驾驶等领域的潜力与挑战。


<details>
  <summary>详细信息</summary>
研究动机: 声学信号作为物理事件的直接载体，蕴含丰富的环境信息，研究如何利用声学信号构建高保真环境感知和预测模型，推动人工智能在复杂场景中的应用。

研究方法: 通过理论分析声学信号中的物理信息编码，综述了物理信息神经网络（PINNs）、生成模型和多模态自监督学习框架等核心方法。

研究结果: 声学世界模型在机器人、自动驾驶、医疗和金融等领域展现出显著应用潜力，同时面临技术和伦理挑战。

研究结论: 未来研究需关注鲁棒性、因果性、不确定性感知和伦理责任，以实现基于声学的主动智能系统。

中文摘要: 本文综述了基于声学物理信息的世界模型这一新兴领域的全面概况。探讨了利用声学信号实现高保真环境感知、因果物理推理和动态事件预测的理论基础、方法论框架和最新技术进展。声学信号作为物理事件机械波能量的直接载体，编码了材料特性、内部几何结构和复杂交互动力学的丰富潜在信息。本文首先通过解释基本物理定律如何支配声学信号中的物理信息编码，建立了理论基础；随后回顾了物理信息神经网络（PINNs）、生成模型和多模态自监督学习框架等核心方法。此外，详细介绍了声学世界模型在机器人、自动驾驶、医疗和金融等领域的重要应用。最后，系统总结了关键技术挑战和伦理问题，并提出了未来研究方向的具体路线图，以实现鲁棒、因果、不确定性感知和负责任的声学智能。这些要素共同指向一种基于声音的具身主动智能研究路径，使AI系统能够通过声音构建内部“直觉物理”引擎。

</details>


### [283] [Acoustic scattering AI for non-invasive object classifications: A case study on hair assessment](https://arxiv.org/abs/2506.14148)
**中文标题：基于声学散射AI的非侵入式物体分类：以头发评估为例**

*Long-Vu Hoang,Tuan Nguyen,Tran Huy Dat*

主要分类: cs.SD

摘要简述: 本文提出了一种基于声学散射的非侵入式物体分类方法，并通过头发评估案例展示了其有效性。利用AI驱动的深度学习声音分类技术，实现了头发类型和湿度的准确分类，最高准确率达90%。


<details>
  <summary>详细信息</summary>
研究动机: 传统视觉分类方法可能侵犯隐私且需要接触物体，而声学散射提供了一种非接触、隐私保护的替代方案。本文旨在探索声学散射在物体分类中的应用潜力，特别是在头发评估领域。

研究方法: 通过发射声学刺激并捕获头发样本的散射信号，结合四种深度学习策略（全监督学习、嵌入分类、监督基础模型微调、自监督模型微调）进行分类。最佳策略为自监督模型的全参数微调。

研究结果: 实验表明，自监督模型微调策略的分类准确率接近90%，验证了声学散射在非侵入式分类中的高效性。

研究结论: 声学散射作为一种隐私保护、非接触的分类方法，在头发评估及其他行业中具有广泛应用潜力。

中文摘要: 本文提出了一种基于声学散射的非侵入式物体分类方法，并以头发评估为例进行了验证。当入射波与物体相互作用时，会产生包含结构和材料特性的散射声场。通过发射声学刺激并捕获头发样本的散射信号，利用AI驱动的深度学习声音分类技术对头发类型和湿度进行分类。我们比较了四种方法：（i）全监督深度学习，（ii）基于嵌入的分类，（iii）监督基础模型微调，（iv）自监督模型微调。最佳策略为自监督模型的全参数微调，分类准确率接近90%。这些结果表明，声学散射是一种隐私保护、非接触的视觉分类替代方案，为多个行业的应用提供了巨大潜力。

</details>


### [284] [Pushing the Performance of Synthetic Speech Detection with Kolmogorov-Arnold Networks and Self-Supervised Learning Models](https://arxiv.org/abs/2506.14153)
**中文标题：利用Kolmogorov-Arnold网络和自监督学习模型提升合成语音检测性能**

*Tuan Dat Phuong,Long-Vu Hoang,Huy Dat Tran*

主要分类: cs.SD

摘要简述: 本文提出了一种新颖的方法，将Kolmogorov-Arnold网络（KAN）引入基于自监督学习（SSL）的XLSR-Conformer模型中，以提升合成语音检测性能。实验结果表明，该方法在ASVspoof2021数据集上显著提高了检测效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着语音合成技术的进步，伪造语音攻击日益复杂，对自动说话人验证系统提出了严峻挑战。尽管基于自监督学习（SSL）的模型（如XLSR-Conformer）在合成语音检测中表现优异，但其架构仍有改进空间。本文旨在通过引入Kolmogorov-Arnold网络（KAN）进一步提升性能。

研究方法: 本文提出了一种新方法，将XLSR-Conformer模型中的传统多层感知机（MLP）替换为基于Kolmogorov-Arnold表示定理的Kolmogorov-Arnold网络（KAN）。这种架构改进旨在更高效地处理合成语音检测任务。

研究结果: 在ASVspoof2021数据集上的实验表明，将KAN集成到SSL模型中，相对提升了LA和DF集的性能60.55%，并在21LA集上实现了0.70%的等错误率（EER）。

研究结论: 研究结果表明，将Kolmogorov-Arnold网络（KAN）引入基于自监督学习的模型是提升合成语音检测性能的有效途径，为未来研究提供了新方向。

中文摘要: 近年来，语音合成技术的进步导致了日益复杂的伪造语音攻击，对自动说话人验证系统提出了重大挑战。尽管基于自监督学习（SSL）的模型（尤其是XLSR-Conformer模型）在合成语音检测中表现出色，但其架构仍有改进空间。本文提出了一种新方法，将XLSR-Conformer模型中的传统多层感知机替换为基于Kolmogorov-Arnold表示定理的Kolmogorov-Arnold网络（KAN）。在ASVspoof2021数据集上的实验结果表明，将KAN集成到SSL模型中，相对提升了LA和DF集的性能60.55%，并在21LA集上实现了0.70%的等错误率（EER）。这些发现表明，将KAN引入基于SSL的模型是提升合成语音检测性能的有前景的方向。

</details>


### [285] [Fretting-Transformer: Encoder-Decoder Model for MIDI to Tablature Transcription](https://arxiv.org/abs/2506.14223)
**中文标题：Fretting-Transformer：用于MIDI到指法谱转录的编码器-解码器模型**

*Anna Hamberger,Sebastian Murgul,Jochen Schmidt,Michael Heizmann*

主要分类: cs.SD

摘要简述: 本文提出了一种名为Fretting-Transformer的编码器-解码器模型，用于将MIDI序列自动转录为吉他指法谱，解决了弦-品模糊性和演奏性问题，并在实验中优于基线方法和商业应用。


<details>
  <summary>详细信息</summary>
研究动机: 音乐转录在音乐信息检索（MIR）中至关重要，尤其是对于吉他等弦乐器，MIDI等符号音乐表示缺乏关键的演奏信息。本文旨在通过自动化转录解决这一问题。

研究方法: 采用基于T5变换器架构的编码器-解码器模型，将任务视为符号翻译问题，结合新颖的数据预处理和标记化策略，利用DadaGP、GuitarToday和Leduc等数据集。

研究结果: 实验结果表明，Fretting-Transformer在指法谱准确性和演奏性方面优于A*等基线方法和Guitar Pro等商业应用，上下文敏感处理和调弦/变调夹条件进一步提升了性能。

研究结论: Fretting-Transformer为吉他自动转录奠定了坚实基础，未来可通过进一步优化推动该领域发展。

中文摘要: 音乐转录在音乐信息检索（MIR）中扮演着关键角色，尤其是对于吉他等弦乐器，MIDI等符号音乐表示缺乏关键的演奏信息。本文提出了Fretting-Transformer，一种基于T5变换器架构的编码器-解码器模型，用于将MIDI序列自动转录为吉他指法谱。通过将任务视为符号翻译问题，该模型解决了弦-品模糊性和物理演奏性等关键挑战。系统利用了包括DadaGP、GuitarToday和Leduc在内的多样化数据集，并采用了新颖的数据预处理和标记化策略。我们开发了指法谱准确性和演奏性的评估指标以量化性能。实验结果表明，Fretting-Transformer在性能上超越了A*等基线方法和Guitar Pro等商业应用。上下文敏感处理以及调弦/变调夹条件的集成进一步提升了模型性能，为未来吉他自动转录的发展奠定了坚实基础。

</details>


### [286] [Making deep neural networks work for medical audio: representation, compression and domain adaptation](https://arxiv.org/abs/2506.13970)
**中文标题：让深度神经网络适用于医疗音频：表征、压缩与领域适应**

*Charles C Onu*

主要分类: cs.SD

摘要简述: 本文探讨了如何利用深度学习技术处理医疗音频信号，尤其是婴儿哭声，以预测健康状况。通过迁移学习、模型压缩和领域适应技术，提升了模型的准确性和适用性，并发布了一个开源婴儿哭声数据集。


<details>
  <summary>详细信息</summary>
研究动机: 医疗音频信号（如肺音、心音和哭声）蕴含重要健康信息，但目前主要依赖专家听觉分析。自动化分析可标准化处理、支持资源匮乏地区的筛查，并发现人类难以察觉的细微模式，从而促进早期诊断和治疗。

研究方法: 1. 在低数据场景下，利用成人语音数据库通过迁移学习提升婴儿哭声分析的准确性；2. 提出基于张量分解的端到端循环网络压缩方法，实现高压缩率；3. 针对音频模型设计领域适应技术，结合计算机视觉方法解决数据集偏差；4. 发布开源婴儿哭声数据集。

研究结果: 迁移学习显著提升了低数据场景下的模型性能；模型压缩方法实现了数百倍的压缩率，同时保持高精度；领域适应技术增强了模型的泛化能力；开源数据集推动了相关研究。

研究结论: 本研究为将婴儿哭声作为重要健康指标奠定了基础，展示了AI驱动的音频监测在推动普惠医疗中的潜力。

中文摘要: 本论文探讨了应用机器学习理解和解析医疗音频信号的技术挑战。肺音、心音和语音等声音传递了重要的健康信息，但在现代医学中，这些声音主要通过专家使用听诊器等设备进行听觉分析。自动化分析有望标准化医疗声音处理，支持医师稀缺的低资源地区筛查，并检测人类难以察觉的细微模式，从而促进早期诊断和治疗。

聚焦于通过婴儿哭声预测健康状况，本论文在四个关键方面做出贡献：首先，在低数据场景下，我们证明可通过神经迁移学习利用成人语音大型数据库，开发更准确、鲁棒的婴儿哭声分析模型；其次，在成本效益建模中，我们提出基于张量分解的端到端循环网络压缩方法，无需后处理即可实现数百倍的压缩率，生成适合资源受限设备的便携模型；第三，我们针对音频模型提出新颖的领域适应技术，并借鉴计算机视觉方法，解决数据集偏差问题，增强跨领域泛化能力；最后，为推动该领域研究，我们发布了一个独特的开源婴儿哭声数据集，该数据集是与全球临床医生合作开发的。

这项工作为将婴儿哭声视为重要健康指标奠定了基础，并凸显了AI驱动的音频监测在塑造普惠医疗未来中的变革潜力。

</details>


### [287] [Unifying Streaming and Non-streaming Zipformer-based ASR](https://arxiv.org/abs/2506.14434)
**中文标题：基于Zipformer的统一流式与非流式自动语音识别**

*Bidisha Sharma,Karthik Pandia Durai,Shankar Venkatesan,Jeena J Prakash,Shashi Kumar,Malolan Chetlur,Andreas Stolcke*

主要分类: cs.SD

摘要简述: 本文提出了一种统一流式和非流式自动语音识别（ASR）模型的框架，通过动态右上下文训练Zipformer模型，显著降低开发成本并提升性能。实验表明，该方法在降低词错误率的同时，用户感知延迟仅轻微增加。


<details>
  <summary>详细信息</summary>
研究动机: 为减少流式和非流式ASR模型的开发、训练和部署成本，研究提出统一框架，利用动态右上下文信息提升模型性能。

研究方法: 采用基于Zipformer的ASR模型，通过分块注意力掩码动态调整右上下文帧数，分析其对准确性和延迟的影响。实验使用Librispeech和内部对话数据集，并在生产级服务器-客户端环境中评估。

研究结果: 该方法将词错误率相对降低7.9%，用户感知延迟略有增加。增加右上下文帧数可使流式模型性能接近非流式模型，且支持根据需求灵活调整延迟与准确性权衡。

研究结论: 统一框架有效降低了ASR模型的开发成本，动态右上下文策略显著提升性能，同时支持灵活的延迟-准确性权衡，满足多样化需求。

中文摘要: 近年来，统一流式和非流式自动语音识别（ASR）模型以减少开发、训练和部署成本的需求日益增长。我们提出了一种统一框架，通过利用未来上下文信息，训练一个端到端的ASR模型，同时适用于流式和非流式应用。在Zipformer模型的训练中，我们通过分块注意力掩码动态调整右上下文。研究表明，由于其多尺度特性，Zipformer模型中使用右上下文比其他Conformer模型更有效。我们分析了不同右上下文帧数对流式ASR模型准确性和延迟的影响。实验使用Librispeech和大型内部对话数据集训练不同版本的流式和非流式模型，并在生产级服务器-客户端环境中跨多个领域测试集进行评估。所提策略将词错误率相对降低7.9%，用户感知延迟仅轻微增加。通过增加右上下文帧数，我们能够使流式模型的性能接近非流式模型。该方法还支持根据客户需求灵活控制延迟与准确性的权衡。

</details>


### [288] [Refining music sample identification with a self-supervised graph neural network](https://arxiv.org/abs/2506.14684)
**中文标题：基于自监督图神经网络的音乐样本识别优化**

*Aditya Bhattacharjee,Ivan Meresman Higgs,Mark Sandler,Emmanouil Benetos*

主要分类: cs.SD

摘要简述: 本文提出了一种基于自监督图神经网络的轻量级编码架构，用于改进音乐样本识别。该方法在对比学习框架下，仅使用9%的可训练参数即达到与当前最优系统相当的性能（mAP 44.2%），并通过两阶段检索策略提升检索质量。


<details>
  <summary>详细信息</summary>
研究动机: 自动样本识别（ASID）在音频检索中至关重要，但现有系统难以应对音乐制作中的常见变换（如时间拉伸、音高变换等）。因此，开发一种对这些变换鲁棒的系统是当前的重要挑战。

研究方法: 提出了一种轻量级编码架构，结合图神经网络和对比学习框架。采用两阶段检索策略：先通过粗粒度相似性搜索筛选候选样本，再通过交叉注意力分类器剔除无关匹配并优化排名。

研究结果: 模型仅使用9%的可训练参数，即达到44.2%的平均精度（mAP），性能与当前最优系统相当。同时，针对短时查询的测试表明，系统在新标注的Sample100数据集上表现优异。

研究结论: 本文提出的方法在轻量化和性能上取得了平衡，有效解决了音乐样本识别中的鲁棒性问题，并为短时查询提供了新的基准数据集。

中文摘要: 自动样本识别（ASID）是音频检索领域的一项关键但具有挑战性的任务，其目标是检测并识别在新音乐作品中重复使用的音频片段。尽管相关任务（如音频指纹识别）在“真实世界”（噪声、混响）条件下取得了显著进展，但ASID系统仍难以识别经过音乐修改的样本。因此，开发一种对时间拉伸、音高变换、效果处理及背景音乐等常见音乐制作变换鲁棒的系统是当前的重要挑战。

本文提出了一种轻量级且可扩展的编码架构，采用图神经网络结合对比学习框架。与当前最优系统相比，我们的模型仅使用9%的可训练参数，却达到了相近的性能（平均精度44.2%）。

为提高检索质量，我们引入了一种两阶段方法：首先通过粗粒度相似性搜索筛选候选样本，随后利用交叉注意力分类器剔除无关匹配并优化候选排名——这是现有模型所缺乏的关键能力。此外，针对实际应用中查询时长较短的特点，我们使用新标注的Sample100数据集对系统进行了短时查询性能测试，并将该数据集作为本文的一部分公开发布。

</details>


### [289] [Adaptive Accompaniment with ReaLchords](https://arxiv.org/abs/2506.14723)
**中文标题：基于ReaLchords的自适应伴奏**

*Yusong Wu,Tim Cooijmans,Kyle Kastner,Adam Roberts,Ian Simon,Alexander Scarlatos,Chris Donahue,Cassie Tarakajian,Shayegan Omidshafiei,Aaron Courville,Pablo Samuel Castro,Natasha Jaques,Cheng-Zhi Anna Huang*

主要分类: cs.SD

摘要简述: 本文提出了一种名为ReaLchords的在线生成模型，用于实时为用户旋律即兴伴奏。通过结合最大似然预训练和强化学习微调，模型能够适应陌生输入并生成和谐的伴奏。


<details>
  <summary>详细信息</summary>
研究动机: 当前音乐生成模型虽能产生富有表现力的输出，但无法在线（实时）与其他音乐家（人或机器）协作。本文旨在解决这一问题，实现实时即兴伴奏。

研究方法: 首先使用最大似然预训练在线模型，再通过强化学习微调。微调目标包括新颖的奖励模型（评估旋律与和弦的和谐性和时间一致性）和从能预见未来旋律的教师模型中提取的差异项。

研究结果: 定量实验和听觉测试表明，模型能良好适应陌生输入并生成合适的伴奏。

研究结论: ReaLchords为实时即兴演奏和其他模态的同步共创提供了可能。

中文摘要: 即兴演奏需要音乐家之间的协调、预判和协作创造力。当前的音乐生成模型虽能产生富有表现力的输出，但无法以在线方式（即与其他音乐家（人或机器）同时）生成音乐。我们提出了ReaLchords，一种在线生成模型，用于为用户旋律即兴伴奏。我们从通过最大似然预训练的在线模型出发，利用强化学习对模型进行微调以适应在线使用。微调目标结合了新颖的奖励模型（提供旋律与和弦在和谐性和时间一致性上的反馈）和从能预见未来旋律的教师模型中提取的差异项。通过定量实验和听觉测试，我们证明该模型能良好适应陌生输入并生成合适的伴奏。ReaLchords为实时即兴演奏以及其他模态的同步共创打开了大门。

</details>


### [290] [Exploring Speaker Diarization with Mixture of Experts](https://arxiv.org/abs/2506.14750)
**中文标题：基于混合专家的说话人分割探索**

*Gaobin Yang,Maokui He,Shutong Niu,Ruoyu Wang,Hang Chen,Jun Du*

主要分类: cs.SD

摘要简述: 本文提出了一种新颖的神经说话人分割系统NSD-MS2S，结合记忆感知多说话人嵌入模块和序列到序列架构，并引入共享与软混合专家模块（SS-MoE）提升性能。实验表明，该方法在多个复杂数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的说话人分割系统在处理复杂声学场景时存在性能不足的问题。本文旨在通过结合记忆感知嵌入和序列到序列架构，以及引入混合专家模块，提升系统的鲁棒性和泛化能力。

研究方法: 提出NSD-MS2S系统，整合记忆感知多说话人嵌入模块与序列到序列架构，并引入SS-MoE模块以减少模型偏差。扩展模型为NSD-MS2S-SSMoE。

研究结果: 在CHiME-6、DiPCo、Mixer 6和DIHARD-III等复杂数据集上，所提方法显著提升了鲁棒性和泛化性能，达到了最先进水平。

研究结论: NSD-MS2S-SSMoE系统在复杂声学场景中表现出色，验证了记忆感知嵌入和混合专家模块的有效性，为说话人分割任务提供了新的解决方案。

中文摘要: 本文提出了一种新颖的神经说话人分割系统NSD-MS2S，该系统将记忆感知多说话人嵌入模块与序列到序列架构相结合。系统利用记忆模块增强说话人嵌入，并采用Seq2Seq框架将声学特征高效映射到说话人标签。此外，我们探索了混合专家在说话人分割中的应用，并引入共享与软混合专家模块（SS-MoE）以进一步减少模型偏差并提升性能。结合SS-MoE后，扩展模型为NSD-MS2S-SSMoE。在CHiME-6、DiPCo、Mixer 6和DIHARD-III等多个复杂声学数据集上的实验表明，该方法在鲁棒性和泛化性方面取得了显著提升。所提方法达到了最先进水平，展示了其在复杂实际场景中的有效性。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [291] [Beyond Shapley Values: Cooperative Games for the Interpretation of Machine Learning Models](https://arxiv.org/abs/2506.13900)
**中文标题：超越Shapley值：合作博弈论在机器学习模型解释中的应用**

*Marouane Il Idrissi,Agathe Fernandes Machado,Arthur Charpentier*

主要分类: stat.ML

摘要简述: 本文探讨了合作博弈论在机器学习模型解释性中的应用，提出超越Shapley值的更广泛工具，如Weber和Harsanyi集，以提供更灵活的解读框架。


<details>
  <summary>详细信息</summary>
研究动机: 尽管Shapley值在机器学习解释性中被广泛使用，但其公理基础与特征归因的相关性仍存争议。作者旨在通过合作博弈论的其他工具，为XAI社区提供更丰富且理论基础扎实的解释方法。

研究方法: 作者重新审视合作博弈论，提出Weber和Harsanyi集作为Shapley值的扩展，并区分价值函数与聚合规则。此外，还提出了一个三步蓝图，用于构建可靠的特征归因方法。

研究结果: 研究表明，Weber和Harsanyi集能够提供比Shapley值更灵活的解读方式，同时为特征归因方法的设计提供了更坚实的理论基础。

研究结论: 本文呼吁超越固定公理，利用合作博弈论的多样化工具，为XAI社区设计更具意义且适应方法变化的特征归因框架。

中文摘要: 合作博弈论已成为机器学习事后解释性的基石，主要通过Shapley值的应用。然而，尽管Shapley方法被广泛采用，其公理基础对特征归因的相关性仍存在争议。本文从解释性角度重新审视合作博弈论，主张更广泛且基于原则地使用其工具。我们重点介绍了两种高效的分配族——Weber集和Harsanyi集，它们超越了Shapley值，提供了更丰富的解释灵活性。本文对这些分配方案进行了通俗易懂的概述，澄清了价值函数与聚合规则的区别，并提出了一个三步蓝图，用于构建可靠且理论基础扎实的特征归因方法。我们的目标是超越固定公理，为XAI社区提供一个连贯的框架，以设计既有意义又能适应方法变化的归因方法。

</details>


### [292] [Mirror Descent Using the Tempesta Generalized Multi-parametric Logarithms](https://arxiv.org/abs/2506.13984)
**中文标题：基于Tempesta广义多参数对数的镜像下降方法**

*Andrzej Cichocki*

主要分类: stat.ML

摘要简述: 本文提出了一类基于Tempesta多参数对数变形的镜像下降（MD）算法，通过调整超参数适应数据分布或几何特性，为机器学习提供了灵活且广泛的优化工具。


<details>
  <summary>详细信息</summary>
研究动机: 镜像下降算法在机器学习中具有重要作用，但现有方法缺乏灵活性。本文旨在通过引入Tempesta多参数对数变形，开发一类更广泛的MD算法，以适应不同数据分布和几何特性。

研究方法: 本文利用Tempesta多参数对数变形作为链接函数，构建Bregman散度约束优化问题，并通过估计广义指数函数推导新的MD更新规则。超参数的学习使算法能够适应数据特性。

研究结果: 研究成功开发了一类基于Tempesta多参数对数的MD算法，其灵活性和适应性通过超参数调整实现，为机器学习优化提供了新工具。

研究结论: 通过引入Tempesta多参数对数变形，本文扩展了MD算法的应用范围，其灵活性和适应性为机器学习优化问题提供了新的解决方案。

中文摘要: 本文开发了一类广泛的镜像下降（MD）算法，这些算法在机器学习中具有关键作用。为此，我们构建了一个约束优化问题，利用Bregman散度，并以Tempesta多参数变形对数作为链接函数。该链接函数（也称为镜像函数）定义了原始空间和对偶空间之间的映射，并与一类非常广泛（理论上无限）的广义迹形式熵相关联。为了推导新的MD更新规则，我们估计了广义指数函数，该函数密切近似于多参数Tempesta广义对数的逆函数。Tempesta对数及其逆变形指数函数的形状和性质可以通过多个超参数进行调整。通过学习这些超参数，我们可以适应训练数据的分布或几何特性，并调整它们以实现MD算法的期望性质。应用多参数对数的概念使我们能够生成一类新的广泛且灵活的MD和无镜像MD更新规则。

</details>


### [293] [Adjustment for Confounding using Pre-Trained Representations](https://arxiv.org/abs/2506.14329)
**中文标题：使用预训练表示调整混杂因素**

*Rickmer Schulte,David Rügamer,Thomas Nagler*

主要分类: stat.ML

摘要简述: 本文探讨如何利用预训练神经网络的潜在特征来调整混杂因素，以改进平均处理效应（ATE）估计。研究发现神经网络能够适应学习问题的内在稀疏性和维度，从而获得快速收敛速率。


<details>
  <summary>详细信息</summary>
研究动机: 随着非表格数据（如图像和文本）在混杂因素中的作用日益重要，忽略这些数据可能导致结果偏差和科学结论错误。然而，将这些数据纳入ATE估计需要复杂的特征提取器，通常结合迁移学习。本文旨在研究如何利用预训练神经网络的潜在特征来调整混杂因素。

研究方法: 本文通过形式化条件，探讨预训练神经网络的潜在特征如何用于调整混杂因素，并在ATE估计中实现有效的统计推断。以双重机器学习为例，展示了这些特征的应用。同时讨论了潜在特征学习和高维非可识别性带来的挑战。

研究结果: 研究发现，传统的加性或稀疏线性模型的结构假设对潜在特征不现实，但神经网络能够适应学习问题的内在稀疏性和维度，从而获得快速收敛速率。

研究结论: 本文表明，预训练神经网络的潜在特征可以有效地用于调整混杂因素，尽管存在高维和非可识别性的挑战，神经网络仍能通过适应问题的内在特性实现快速收敛。

中文摘要: 近年来，人们越来越关注将平均处理效应（ATE）估计扩展到非表格数据（如图像和文本），这些数据可能作为混杂因素的来源。忽略这些影响可能导致结果偏差和科学结论错误。然而，纳入非表格数据需要复杂的特征提取器，通常结合迁移学习的思想。本文研究了如何利用预训练神经网络的潜在特征来调整混杂因素。我们形式化了这些潜在特征能够实现有效调整和ATE估计中统计推断的条件，并以双重机器学习为例展示了结果。我们讨论了潜在特征学习和高维非可识别性带来的关键挑战，以及下游参数估计的问题。研究表明，传统的加性或稀疏线性模型的结构假设对潜在特征不现实，但神经网络能够适应学习问题的内在稀疏性和维度，从而获得快速收敛速率。

</details>


### [294] [Sharp Generalization Bounds for Foundation Models with Asymmetric Randomized Low-Rank Adapters](https://arxiv.org/abs/2506.14530)
**中文标题：Error**

*Anastasis Kratsios,Tin Sum Cheng,Aurelien Lucchi,Haitz Sáez de Ocáriz Borde*

主要分类: stat.ML

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [295] [AMLgentex: Mobilizing Data-Driven Research to Combat Money Laundering](https://arxiv.org/abs/2506.13989)
**中文标题：AMLgentex：推动数据驱动研究以打击洗钱活动**

*Johan Östman,Edvin Callisen,Anton Chen,Kristiina Ausmees,Emanuel Gårdh,Jovan Zamac,Jolanta Goldsteine,Hugo Wefer,Simon Whelan,Markus Reimegård*

主要分类: cs.SI

摘要简述: AMLgentex是一个开源工具，用于生成逼真的可配置交易数据并测试反洗钱检测方法，以解决现有合成数据集无法模拟真实洗钱复杂性的问题。


<details>
  <summary>详细信息</summary>
研究动机: 洗钱活动使非法资金进入合法经济，每年涉及数万亿美元，但仅有极少数被揭露。现有合成数据集无法模拟真实洗钱的复杂性和挑战，如部分可观察性、稀疏标签、战略行为等。

研究方法: 提出AMLgentex，一个开源工具，用于生成逼真的交易数据并测试反洗钱方法。该工具在受控环境中模拟真实世界的复杂性，如网络级依赖性和时间动态。

研究结果: AMLgentex能够系统评估反洗钱系统，并在模拟复杂实际场景的条件下验证方法的有效性。

研究结论: AMLgentex为反洗钱研究提供了更接近现实的测试环境，有助于提升检测方法的准确性和适应性。

中文摘要: 洗钱活动通过使非法资金进入合法经济，助长了有组织犯罪。尽管每年有数万亿美元被洗白，但仅有极少数被揭露。这源于多种因素，包括洗钱者的故意规避、确认案例的稀缺性以及金融机构对全球交易网络的有限可见性。虽然已有一些合成数据集，但它们未能模拟真实洗钱的结构和行为复杂性，尤其是部分可观察性、稀疏和不确定标签、战略行为、时间动态、类别不平衡和网络级依赖性等问题。为解决这些局限性，我们提出了AMLgentex，一个用于生成逼真、可配置交易数据并测试检测方法的开源工具。它能够在受控环境中系统评估反洗钱系统，捕捉现实世界中的关键挑战。我们展示了该框架如何在反映实际反洗钱场景复杂性的条件下严格评估方法。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [296] [Investigating the Potential of Large Language Model-Based Router Multi-Agent Architectures for Foundation Design Automation: A Task Classification and Expert Selection Study](https://arxiv.org/abs/2506.13811)
**中文标题：基于大型语言模型的路由器多智能体架构在基础设计自动化中的潜力研究：任务分类与专家选择**

*Sompote Youwai,David Phim,Vianne Gayl Murcia,Rianne Clair Onas*

主要分类: cs.MA

摘要简述: 本研究探讨了基于路由器的多智能体系统在基础设计自动化中的应用，通过任务分类和专家选择，显著提升了性能。结果表明，路由器配置在浅基础和桩基设计中表现最佳，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 基础设计计算是土木工程中的关键任务，传统方法效率低下且易出错。本研究旨在通过智能任务分类和专家选择，利用大型语言模型（LLM）提升自动化水平，同时确保专业文档标准。

研究方法: 研究评估了三种方法：单智能体处理、多智能体设计-检查架构和基于路由器的专家选择。使用DeepSeek R1、ChatGPT 4 Turbo、Grok 3和Gemini 2.5 Pro等基线模型，在浅基础和桩基设计场景中进行性能测试。

研究结果: 基于路由器的配置在浅基础和桩基设计中分别达到95.00%和90.63%的性能得分，显著优于传统方法。Grok 3在独立运行中表现最佳，表明LLM在工程数学推理中的进步。

研究结论: 路由器多智能体系统是基础设计自动化的最优选择，但仍需人工监督以确保安全性。这些系统应作为高级计算辅助工具，而非完全自主的设计替代方案。

中文摘要: 本研究探讨了基于路由器的多智能体系统如何通过智能任务分类和专家选择实现基础设计计算的自动化。评估了三种方法：单智能体处理、多智能体设计-检查架构和基于路由器的专家选择。性能测试使用了DeepSeek R1、ChatGPT 4 Turbo、Grok 3和Gemini 2.5 Pro等基线模型，覆盖浅基础和桩基设计场景。基于路由器的配置在浅基础和桩基设计中分别达到95.00%和90.63%的性能得分，比独立运行的Grok 3分别提升了8.75和3.13个百分点，并优于传统智能体工作流程10.0至43.75个百分点。Grok 3在无外部计算工具的情况下表现最佳，表明LLM在工程数学推理中的进步。双层次分类框架成功区分了基础类型，支持了适当的分析方法。结果表明，基于路由器的多智能体系统是基础设计自动化的最优选择，同时保持了专业文档标准。鉴于土木工程的安全关键性要求，仍需持续人工监督，这些系统应作为高级计算辅助工具，而非完全自主的设计替代方案。

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [297] [MobileHolo: A Lightweight Complex-Valued Deformable CNN for High-Quality Computer-Generated Hologram](https://arxiv.org/abs/2506.14542)
**中文标题：MobileHolo：一种轻量级复数可变形CNN用于高质量计算机生成全息图**

*Xie Shuyang,Zhou Jie,Xu Bo,Wang Jun,Xu Renjing*

主要分类: physics.optics

摘要简述: 本文提出了一种轻量级的复数可变形卷积网络MobileHolo，用于高质量计算机生成全息图，通过动态调整卷积核形状提升有效感受野，在模拟和光学实验中表现优于现有开源模型。


<details>
  <summary>详细信息</summary>
研究动机: 全息显示在虚拟现实和增强现实中潜力巨大，但现有方法因有效感受野不足难以准确建模衍射过程。本文旨在通过改进卷积网络提升特征提取能力。

研究方法: 设计了复数可变形卷积，动态调整卷积核形状以增强有效感受野的灵活性，从而更准确地建模衍射过程。

研究结果: 在1920×1072分辨率下，峰值信噪比分别比CCNN-CGH、HoloNet和Holo-encoder高2.04 dB、5.31 dB和9.71 dB，且模型参数量仅为CCNN-CGH的八分之一。

研究结论: MobileHolo通过复数可变形卷积显著提升了全息图生成质量，同时保持轻量级设计，为虚拟现实和增强现实提供了高效解决方案。

中文摘要: 全息显示因其能够提供所有深度线索而在虚拟现实和增强现实中具有巨大潜力。基于深度学习的方法在计算机生成全息图（CGH）中扮演重要角色。在衍射过程中，每个像素对重建图像产生影响。然而，现有工作因有效感受野（ERF）不足而难以准确建模这一过程。为此，我们设计了复数可变形卷积并将其集成到网络中，通过动态调整卷积核形状提升ERF的灵活性以实现更好的特征提取。该方法仅需单一模型即可在模拟和光学实验重建中实现最先进性能，超越现有开源模型。具体而言，在1920×1072分辨率下，我们的方法峰值信噪比分别比CCNN-CGH、HoloNet和Holo-encoder高2.04 dB、5.31 dB和9.71 dB，且模型参数量仅为CCNN-CGH的八分之一。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [298] [Busting the Paper Ballot: Voting Meets Adversarial Machine Learning](https://arxiv.org/abs/2506.14582)
**中文标题：打破纸质选票：投票与对抗性机器学习的碰撞**

*Kaleel Mahmood,Caleb Manicke,Ethan Rathbun,Aayushi Verma,Sohaib Ahmad,Nicholas Stamatakis,Laurent Michel,Benjamin Fuller*

主要分类: cs.CR

摘要简述: 本文揭示了美国选举计票机中使用机器学习分类器的安全风险，通过新数据集和多种模型训练，展示了对抗性攻击在选举领域的潜在影响，并提出了改进方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在揭示机器学习分类器在选举计票机中的安全漏洞，特别是对抗性攻击可能对选举结果产生的重大影响。

研究方法: 1. 引入四个新的选票数据集；2. 训练和测试多种模型（如SVM、CNN、VGG、ResNet、视觉变换器等）；3. 分析传统白盒攻击的无效性，提出改进方法；4. 在物理世界中验证对抗性攻击的可行性。

研究结果: 研究发现梯度掩蔽导致传统白盒攻击无效，但通过改进方法成功生成对抗样本，并证明即使5%的攻击成功率也可能改变选举结果。

研究结论: 选举计票机中的机器学习模型存在安全风险，对抗性攻击可能对选举结果产生实际影响，需进一步研究防御措施。

中文摘要: 本文揭示了美国选举计票机中使用机器学习分类器的安全风险。选举计票的核心分类任务是判断选票上某个选项的标记是否存在。Barretto等人（E-Vote-ID 2021）曾报告卷积神经网络在此领域表现优于简单特征分类器。

我们的贡献分为四部分：首先，引入四个新的选票数据集以分析机器学习模型的潜在漏洞；其次，在新数据集上训练和测试多种模型（包括支持向量机、卷积神经网络和视觉变换器）；第三，发现传统白盒攻击因梯度掩蔽而无效，并提出改进方法；第四，在物理世界中验证对抗性攻击的可行性。研究表明，即使5%的攻击成功率也可能改变选举结果，并讨论了打印和扫描对抗样本的挑战与实用性。

</details>


### [299] [LLM-Powered Intent-Based Categorization of Phishing Emails](https://arxiv.org/abs/2506.14337)
**中文标题：基于大型语言模型的钓鱼邮件意图分类**

*Even Eilertsen,Vasileios Mavroeidis,Gudmund Grov*

主要分类: cs.CR

摘要简述: 本文探讨了利用大型语言模型（LLMs）基于意图检测和分类钓鱼邮件的潜力，提出了一种意图分类法，并通过实验验证了LLMs在此领域的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 钓鱼攻击对现代网络安全构成重大威胁，传统检测系统依赖用户不可见的邮件元数据，且难以应对仅通过文本即可识别的钓鱼邮件。本文旨在探索LLMs在检测和分类钓鱼邮件中的实际应用潜力。

研究方法: 研究通过构建包含合法与钓鱼邮件的自定义数据集，利用LLMs进行钓鱼邮件的二元分类和意图分类，提出了一种意图分类法，并验证了LLMs的分类能力。

研究结果: 实验结果表明，现有LLMs能够有效检测和分类钓鱼邮件，展示了其在此领域的应用潜力。

研究结论: LLMs在钓鱼邮件检测和分类中具有显著潜力，能够生成可操作的威胁信息，为网络安全提供新思路。

中文摘要: 钓鱼攻击仍然是现代网络安全的重大威胁，它们成功欺骗了人类及其防御机制。传统检测系统主要关注用户无法在收件箱中看到的邮件元数据，且难以应对仅通过文本即可识别的钓鱼邮件。本文研究了大型语言模型（LLMs）通过关注邮件意图检测钓鱼邮件的实际潜力。除了钓鱼邮件的二元分类外，本文还引入了一种意图类型分类法，通过LLMs将邮件分类为不同类别，从而生成可操作的威胁信息。为支持研究，我们整理了公开数据集，构建了一个包含合法与钓鱼邮件的自定义数据集。结果表明，现有LLMs能够检测和分类钓鱼邮件，凸显了其在此领域的潜力。

</details>
