<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 103]
- [cs.CV](#cs.CV) [Total: 85]
- [cs.AI](#cs.AI) [Total: 17]
- [stat.ML](#stat.ML) [Total: 1]
- [eess.IV](#eess.IV) [Total: 12]
- [stat.ME](#stat.ME) [Total: 1]
- [eess.SP](#eess.SP) [Total: 2]
- [cs.LG](#cs.LG) [Total: 25]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.IR](#cs.IR) [Total: 12]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.RO](#cs.RO) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Multilingual ASR Finetuning via LoRA Language Experts](https://arxiv.org/abs/2506.21555)
**中文标题：基于LoRA语言专家的高效多语言ASR微调**

*Jiahong Li,Yiwen Shao,Jianheng Zhuo,Chenda Li,Liliang Tang,Dong Yu,Yanmin Qian*

主要分类: cs.CL

摘要简述: 本文提出了一种基于LoRA语言专家的高效多语言ASR微调框架，通过LoRA专家融合或知识蒸馏，显著提升了目标语言的识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管深度学习在多语言自动语音识别（ASR）方面取得了显著进展，但不同语言之间的干扰问题仍然存在，导致模型难以有效共享容量。本文旨在解决这一问题。

研究方法: 基于Whisper模型，提出了一种通过LoRA语言专家进行高效微调的框架，采用LoRA专家融合或知识蒸馏技术。

研究结果: 实验结果表明，该方法在语言感知和语言无关场景下分别实现了约10%和15%的相对性能提升。

研究结论: 本文提出的框架有效缓解了多语言ASR中的语言干扰问题，显著提升了目标语言的识别性能。

中文摘要: 近年来，深度学习的发展显著提升了多语言自动语音识别（ASR）的性能，得益于先进的模型架构和大规模多语言数据集的可用性。尽管如此，多语言ASR仍面临多语言干扰问题，导致模型难以在共享容量的同时有效识别多种语言。本文提出了一种基于Whisper的高效微调框架，通过预训练的LoRA语言专家实现定制化多语言ASR。通过LoRA专家融合或知识蒸馏，我们的方法在目标语言上的识别性能优于标准微调方法。实验结果表明，所提出的模型在语言感知和语言无关场景下分别实现了约10%和15%的相对性能提升。

</details>


### [2] [VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21556)
**中文标题：VAT-KG：面向检索增强生成的知识密集型多模态知识图谱数据集**

*Hyeongcheol Park,MinHyuk Jang,Ha Dam Baek,Gyusam Chang,Jiyoung Seo,Jiwan Park,Hogun Park,Sangpil Kim*

主要分类: cs.CL

摘要简述: 本文提出了一种新型多模态知识图谱VAT-KG，涵盖视觉、音频和文本信息，通过严格的过滤和对齐步骤构建，支持多模态检索增强生成（RAG），实验证明其在多模态问答任务中有效提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态知识图谱（MMKGs）通常基于已有知识图谱扩展，知识覆盖不完整且模态有限（如仅文本和视觉），难以支持新兴多模态任务（如视频和音频）。因此，需要一种知识密集、多模态覆盖全面的新型知识图谱。

研究方法: 提出VAT-KG，首个以概念为中心、涵盖视觉、音频和文本的多模态知识图谱。通过严格的跨模态知识对齐和语义过滤步骤，实现从任意多模态数据自动生成MMKG，并设计了一种新型多模态RAG框架，支持从任意模态查询中检索概念级知识。

研究结果: 实验表明，VAT-KG在多模态问答任务中显著提升了多模态大语言模型（MLLMs）的性能，验证了其在统一和利用多模态知识方面的实用价值。

研究结论: VAT-KG填补了现有MMKGs的局限性，为多模态任务提供了更全面和动态的知识支持，未来可扩展至更多模态和应用场景。

中文摘要: 多模态知识图谱（MMKGs）通过显式表示多模态知识，补充多模态大语言模型（MLLMs）的隐式知识，并支持基于检索增强生成（RAG）的接地推理。然而，现有MMKGs通常范围有限：它们多基于已有知识图谱扩展，导致知识覆盖过时或不完整，且仅支持少量模态（如文本和视觉）。这些限制降低了其扩展性和对多模态任务的适用性，尤其是随着领域向视频和音频等更丰富模态的转变。为此，我们提出视觉-音频-文本知识图谱（VAT-KG），首个以概念为中心、知识密集型的多模态知识图谱，涵盖视觉、音频和文本信息，每个三元组均链接到多模态数据并辅以详细概念描述。具体而言，我们的构建流程通过一系列严格过滤和对齐步骤，确保多模态数据与细粒度语义的跨模态知识对齐，从而支持从任意多模态数据集自动生成MMKG。我们还引入了一种新型多模态RAG框架，可从任意模态查询中检索概念级知识。在多模态问答任务上的实验验证了VAT-KG对MLLMs的有效支持，凸显了其在统一和利用多模态知识中的实用价值。

</details>


### [3] [Debunk and Infer: Multimodal Fake News Detection via Diffusion-Generated Evidence and LLM Reasoning](https://arxiv.org/abs/2506.21557)
**中文标题：揭穿与推理：基于扩散生成证据和大语言模型推理的多模态假新闻检测**

*Kaiying Yan,Moyang Liu,Yukun Liu,Ruibo Fu,Zhengqi Wen,Jianhua Tao,Xuefei Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为DIFND的多模态假新闻检测框架，通过结合条件扩散模型和多模态大语言模型，生成反驳或验证证据，并利用多代理系统进行逻辑推理，显著提升了检测准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 假新闻在多媒体平台上的快速传播对信息可信度构成严重威胁。现有方法在性能和可解释性方面存在不足，因此需要一种能够结合生成和推理能力的框架来提升假新闻检测的效果。

研究方法: DIFND框架整合了条件扩散模型的生成能力和多模态大语言模型的协作推理能力。具体包括：1）使用去噪扩散模型生成基于新闻视频多模态内容的反驳或验证证据；2）提出“链式去噪”策略，通过多代理MLLM系统生成逻辑严密的多模态推理内容和最终真实性判断。

研究结果: 在FakeSV和FVC数据集上的实验表明，DIFND不仅优于现有方法，还提供了可信的决策支持。

研究结论: DIFND通过联合建模多模态特征、生成性去噪线索和丰富的推理验证，显著提升了假新闻检测的准确性和可解释性，为未来研究提供了新方向。

中文摘要: 假新闻在多媒体平台上的快速传播对信息可信度构成了严峻挑战。本文提出了一种名为“揭穿与推理”的假新闻检测框架（DIFND），该框架利用揭穿知识提升假新闻检测的性能和可解释性。DIFND结合了条件扩散模型的生成能力和多模态大语言模型（MLLM）的协作推理能力。具体而言，去噪扩散模型被用于基于新闻视频的多模态内容生成反驳或验证证据，通过多样且语义对齐的合成样本丰富了评估过程。为提升推理能力，我们提出了一种“链式揭穿”策略，其中多代理MLLM系统生成基于逻辑的多模态感知推理内容和最终真实性判断。通过在一个统一架构中联合建模多模态特征、生成性揭穿线索和推理丰富的验证，DIFND在检测准确性上取得了显著提升。在FakeSV和FVC数据集上的大量实验表明，DIFND不仅优于现有方法，还能提供可信的决策支持。

</details>


### [4] [Bench to the Future: A Pastcasting Benchmark for Forecasting Agents](https://arxiv.org/abs/2506.21558)
**中文标题：面向未来的基准：预测代理的过去预测基准**

*FutureSearch,:,Jack Wildman,Nikos I. Bosse,Daniel Hnyk,Peter Mühlbacher,Finn Hambly,Jon Evans,Dan Schwarz,Lawrence Phillips*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“Bench To the Future (BTF)”的“过去预测”基准测试，用于评估AI系统的预测能力。该基准包含数百个已知结果的高质量问题，并附带大量相关网页数据，为LLM提供了真实的预测环境。实验表明，BTF能够有效评估预测能力，并跟踪其随时间的变化。


<details>
  <summary>详细信息</summary>
研究动机: 预测任务对AI系统研究具有重要意义，但现有基准测试难以提供真实、封闭且可重复的环境。为了解决这一问题，作者开发了BTF基准，旨在为LLM预测能力的研究提供更实用的工具。

研究方法: BTF基准包含数百个已知结果的问题，每个问题附带数万个相关网页的离线语料库。通过这种方式，LLM可以在已知事件上进行“过去预测”。作者还测试了多种LLM（包括Claude 4）的代理和链式思维预测方法。

研究结果: 实验结果表明，BTF能够生成与基于未解决事件的互联网预测结果相当的数据。此外，BTF还能有效跟踪预测能力的持续进步。

研究结论: BTF是一种动态基准测试，将持续更新问题以应对训练数据截止日期的变化。作者鼓励研究者利用该基准进行相关研究。

中文摘要: 预测是一项具有挑战性的任务，为研究AI系统提供了明确的衡量方式。预测需要大量互联网研究，而评估需要等待事件发生，这使得预测基准的开发变得困难。迄今为止，尚无预测基准能为LLM预测者提供真实、封闭且可重复的环境。我们提出了“Bench To the Future (BTF)”，这是一种“过去预测”基准，包含数百个已知结果的高质量问题。每个问题附带数万个相关网页的离线语料库，从而为LLM提供了一种在已知事件上进行“预测”的方式。结果表明，我们的过去预测环境能够产生与基于未解决事件的互联网预测结果相当的数据。我们展示了使用多种LLM（包括最近发布的Claude 4模型）的代理和链式思维预测方法的基准测试结果，并证明了BTF能够跟踪预测能力的持续进步。我们计划将其作为动态基准，不断添加新问题以应对训练数据截止日期的变化。欢迎研究人员通过hello@futuresearch.ai联系我们，以利用我们的基准或工具进行研究。

</details>


### [5] [GraphLAMA: Enabling Efficient Adaptation of Graph Language Models with Limited Annotations](https://arxiv.org/abs/2506.21559)
**中文标题：GraphLAMA：基于有限标注的高效图语言模型适应方法**

*Junze Chen,Cheng Yang,Shujie Li,Zhiqiang Zhang,Yawen Li,Junping Du,Chuan Shi*

主要分类: cs.CL

摘要简述: GraphLAMA提出了一种高效的图语言模型适应方法，通过少量标注数据实现快速调优和推理，显著提升预测准确性和速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有图语言模型（GLMs）在上下文学习（ICL）中因固定参数和长上下文效率低下，而指令调优需要大量标注数据。GraphLAMA旨在通过少量标注数据高效适应未见图和任务，以提升准确性和推理速度。

研究方法: GraphLAMA采用图神经网络（GNN）作为模型主干，将节点转换为LLM令牌的表示空间，任务指令表示为节点和语言令牌的混合。预训练阶段训练非LLM参数以捕获通用知识，适应阶段仅更新少量预训练参数。

研究结果: 实验表明，GraphLAMA在少/零样本节点分类和摘要生成任务中表现最优，准确率提升4.91%，推理速度比ICL快10倍（5-shot设置下）。

研究结论: GraphLAMA通过高效调优和推理，解决了GLMs在ICL和指令调优中的局限性，为图语言模型的实际应用提供了新思路。

中文摘要: 大型语言模型（LLMs）在多个领域展现了强大能力，并作为图语言模型（GLMs）应用于图分析。部分GLMs通过上下文学习（ICL）无需参数调优即可从少量示例中学习，而另一些则依赖大量标注数据进行指令调优。然而，ICL因固定参数和长上下文存在效率问题，指令调优则需大量标注数据。为此，我们提出一种参数适应阶段，以少量标注数据高效适配GLMs至未见图和任务，提升预测准确性和推理速度。具体实现中，我们提出GraphLAMA方法，其模型主干和学习机制专为高效调优和推理设计。模型主干采用图神经网络（GNN），将节点转换为LLM令牌的表示空间，任务指令表示为节点和语言令牌的混合。预训练阶段训练非LLM参数以捕获通用知识，适应阶段仅更新少量预训练参数。在少/零样本节点分类和摘要生成任务中，GraphLAMA实现了最优性能，准确率提升4.91%，推理速度比ICL快10倍（5-shot设置下）。

</details>


### [6] [Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning](https://arxiv.org/abs/2506.21560)
**中文标题：基于强化学习的语言模型微调用于指令跟随和数学推理**

*Yifu Han,Geo Zhang*

主要分类: cs.CL

摘要简述: 本研究探讨了强化学习（RL）微调技术在小型语言模型（Qwen2.5-0.5B Base）上的有效性，用于指令跟随和数学推理任务。实验表明，结合DeBERTa奖励模型的RLOO方法表现最佳，而DPO方法结果稳定。数学任务中，合成数据增强和外部验证器显著提升准确性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索如何通过强化学习微调技术提升小型语言模型在复杂任务（如指令跟随和数学推理）中的表现，并比较不同微调方法的优劣。

研究方法: 方法包括监督微调（SFT）、基于偏好数据的直接偏好优化（DPO）以及结合奖励模型的强化学习留一法（RLOO）。数学推理任务中，还使用了合成数据增强和外部验证器进行最佳N采样。

研究结果: 实验结果显示，RLOO结合DeBERTa奖励模型在任务对齐上表现最佳，DPO结果稳定。数学推理任务中，合成数据增强和外部验证器显著提升了模型准确性。

研究结论: 研究总结了训练轻量级任务对齐小型语言模型的关键权衡和实用策略，强调了微调与推理工具结合的重要性。

中文摘要: 本研究探讨了强化学习（RL）微调技术在小型语言模型（Qwen2.5-0.5B Base）上对指令跟随和数学推理两项挑战性任务的有效性。我们比较了监督微调（SFT）、基于偏好数据的直接偏好优化（DPO）以及结合奖励模型的强化学习留一法（RLOO）。实验表明，结合DeBERTa奖励模型的RLOO方法在任务对齐上表现最佳，而DPO提供了稳定且一致的结果。在数学推理任务中，合成数据增强和基于外部验证器的最佳N采样显著提升了准确性，展示了微调与推理工具结合的潜力。本研究总结了训练轻量级任务对齐小型语言模型的关键权衡和实用策略。

</details>


### [7] [Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs](https://arxiv.org/abs/2506.21561)
**中文标题：推理不足：审视大型语言模型中的真理偏见与阿谀倾向**

*Emilio Barkett,Olivia Long,Madhavendra Thakur*

主要分类: cs.CL

摘要简述: 研究发现，尽管推理模型在真相检测中的真理偏见低于非推理模型，但仍高于人类基准。高级模型（如o4-mini、GPT-4.1和R1）表现出阿谀倾向，真相检测准确率高但欺骗检测准确率低，表明能力提升无法完全解决LLMs的真相检测挑战。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）在事实核查、内容审核和高风险决策中广泛应用，但其作为真相判断工具的能力仍未被充分理解。本研究旨在评估LLMs的真相检测能力，并首次分析推理模型在这一任务中的表现。

研究方法: 研究让8个LLMs对4,800条陈述进行真相判断，比较推理模型和非推理模型的表现。通过多种提示设计，分析模型的真理偏见和阿谀倾向。

研究结果: 推理模型的真理偏见低于非推理模型，但仍高于人类基准。高级模型（如o4-mini、GPT-4.1和R1）表现出阿谀倾向，真相检测准确率高但欺骗检测准确率低。

研究结论: 能力提升无法完全解决LLMs在真相检测中的根本挑战，尤其是阿谀倾向问题。

中文摘要: 尽管大型语言模型（LLMs）在事实核查、内容审核和高风险决策中广泛应用，但其作为真相判断工具的能力仍未被充分理解。本研究对LLMs的真相检测能力进行了迄今为止最大规模的评估，并首次分析了推理模型在这一任务中的表现。我们让8个LLMs对4,800条陈述进行真相判断，比较推理模型和非推理模型的表现。研究发现，推理模型的真理偏见（即无论陈述是否真实，倾向于认为其真实的概率）低于非推理模型，但仍高于人类基准。最令人担忧的是，我们发现几个高级模型（如OpenAI的o4-mini和GPT-4.1，以及DeepSeek的R1）表现出阿谀倾向，其真相检测准确率高但欺骗检测准确率低。这表明，仅靠能力提升无法解决LLMs在真相检测中的根本挑战。

</details>


### [8] [FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction](https://arxiv.org/abs/2506.21562)
**中文标题：FloorPlan-DeepSeek (FPDS)：一种基于向量的下一个房间预测多模态平面图生成方法**

*Jun Yin,Pengyu Zeng,Jing Zhong,Peilin Li,Miao Zhang,Ran Luo,Shuai Lu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为FloorPlan-DeepSeek (FPDS)的多模态方法，通过基于向量的‘下一个房间预测’机制，逐步生成建筑平面图，以更贴合实际建筑设计流程。


<details>
  <summary>详细信息</summary>
研究动机: 现有的建筑平面图生成模型多为端到端生成，一次性输出整个像素布局，与实际建筑设计中逐步迭代的工作流程不符。本文旨在解决这一问题。

研究方法: 受大型语言模型中自回归‘下一个词预测’机制的启发，提出了一种针对建筑平面图建模的‘下一个房间预测’新范式。

研究结果: 实验表明，FPDS在文本到平面图任务中表现优于扩散模型和Tell2Design，显示出其在智能建筑设计中的潜力。

研究结论: FPDS通过逐步生成平面图，更贴合实际建筑设计流程，为未来智能建筑设计提供了新的可能性。

中文摘要: 在建筑设计过程中，平面图生成本质上是逐步迭代的。然而，现有的平面图生成模型多为端到端生成，一次性输出整个像素布局，这与实际建筑设计中逐步迭代的工作流程不符。为解决这一问题，我们受大型语言模型中自回归‘下一个词预测’机制的启发，提出了一种针对建筑平面图建模的‘下一个房间预测’新范式。实验评估表明，FPDS在文本到平面图任务中表现优于扩散模型和Tell2Design，显示出其在未来智能建筑设计中的潜在应用价值。

</details>


### [9] [FormosanBench: Benchmarking Low-Resource Austronesian Languages in the Era of Large Language Models](https://arxiv.org/abs/2506.21563)
**中文标题：FormosanBench：大语言模型时代低资源南岛语系语言的基准测试**

*Kaiying Kevin Lin,Hsiyu Chen,Haopeng Zhang*

主要分类: cs.CL

摘要简述: 本文介绍了首个针对低资源南岛语系语言的基准测试FORMOSANBENCH，评估大语言模型在台湾濒危语言（如泰雅语、阿美语和排湾语）上的表现，结果显示模型性能显著落后于高资源语言，呼吁开发更具包容性的NLP技术。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在高资源语言中表现优异，但在低资源和少数民族语言中的能力尚未充分探索。台湾的南岛语系语言（如泰雅语、阿美语和排湾语）因普通话的社会语言优势而濒危，亟需相关研究支持。

研究方法: 作者提出FORMOSANBENCH基准测试，涵盖三种濒危语言（泰雅语、阿美语和排湾语）和三项核心NLP任务（机器翻译、自动语音识别和文本摘要），并在零样本、10样本和微调设置下评估模型性能。

研究结果: 实验结果显示，大语言模型在低资源语言上的表现显著落后于高资源语言，10样本学习和微调仅带来有限改进。

研究结论: 研究强调了开发支持濒危和低资源语言的NLP技术的紧迫性，并公开数据集和代码以促进未来研究。

中文摘要: 尽管大语言模型（LLMs）在高资源语言的多种自然语言处理（NLP）任务中表现出色，但其在低资源和少数民族语言中的能力仍鲜有研究。台湾的南岛语系语言（如泰雅语、阿美语和排湾语）既具有丰富的语言学价值，又因普通话的社会语言优势而濒危。本文提出了首个针对低资源南岛语系语言的基准测试FORMOSANBENCH，涵盖三种濒危语言和三项核心NLP任务：机器翻译、自动语音识别（ASR）和文本摘要。我们通过零样本、10样本和微调设置评估模型性能。结果显示，高资源语言与南岛语系语言之间存在显著性能差距，现有大语言模型在所有任务中表现不佳，10样本学习和微调仅带来有限改进。这些发现凸显了开发更具包容性的NLP技术以支持濒危和低代表性语言的紧迫性。我们公开数据集和代码，以推动未来研究。

</details>


### [10] [Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing](https://arxiv.org/abs/2506.21564)
**中文标题：QUST团队在SemEval-2025任务10中的表现：评估大语言模型在新闻实体框架多类多标签分类中的应用**

*Jiyan Liu,Youzheng Liu,Taihang Wang,Xiaoman Xu,Yimin Wang,Ye Jiang*

主要分类: cs.CL

摘要简述: QUST_NLP团队在SemEval-2025任务7中提出了一种三阶段检索框架，用于事实核查声明检索，最终在单语和跨语赛道分别获得第5和第7名。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在设计一个高效的事实核查声明检索框架，以提升检索性能并参与SemEval-2025竞赛。

研究方法: 采用三阶段框架：1) 评估并选择最佳检索模型进行候选检索；2) 使用多个重排序模型优化候选结果；3) 通过加权投票确定最终结果。

研究结果: 在单语赛道排名第5，跨语赛道排名第7，表现优异。

研究结论: 提出的三阶段框架在事实核查声明检索任务中表现良好，代码已开源。

中文摘要: 本文描述了QUST_NLP团队参与SemEval-2025任务7的情况。我们提出了一种专为事实核查声明检索设计的三阶段检索框架。首先，我们评估了多种检索模型的性能，并选择表现最佳的模型进行候选检索。接着，我们使用多个重排序模型优化候选结果，每个模型筛选出前10个结果。最后，通过加权投票确定最终检索结果。我们的方法在单语赛道中排名第5，跨语赛道中排名第7。系统代码已发布于：https://github.com/warmth27/SemEval2025_Task7。

</details>


### [11] [A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing](https://arxiv.org/abs/2506.21565)
**中文标题：受回覧板式CoT系统与井戸端会话启发的多智能体概率推理框架用于去偏见**

*Takato Ueno,Keito Inoshita*

主要分类: cs.CL

摘要简述: 本文受日本回覧板文化和井戸端会话启发，提出一种多智能体概率推理框架（KCS+IBC），通过结合多个大语言模型（LLMs）实现偏见缓解、解释性提升和情感分析中的概率预测。实验表明，该框架在保持精度的同时，能够平衡预测的聚合与多样性。


<details>
  <summary>详细信息</summary>
研究动机: 日本回覧板文化和井戸端会话作为传统沟通方式，促进了社区成员间的细致对话并形成社会平衡。受此启发，本研究旨在利用多智能体推理框架，结合LLMs，解决情感分析中的偏见问题，并提升解释性和预测能力。

研究方法: 提出KCS+IBC框架，通过多智能体（LLMs）协作进行推理。框架不仅顺序共享预测结果，还引入中期非正式对话环节，融合正式推理与个体视角，并采用概率情感预测方法。

研究结果: 实验结果显示，KCS在数据集上的精度与单一LLM相当，而KCS+IBC在推理后期表现出熵的持续降低和方差的逐步增加，表明框架能平衡预测的聚合与多样性。

研究结论: 该框架在情感分析中展现出潜力，未来工作将量化其对偏见校正的影响，并开发更先进的情感分析系统。

中文摘要: 日本的回覧板文化和井戸端会话长期以来作为传统沟通实践，促进了社区成员间的细致对话并有助于社会平衡的形成。受这些信息交换过程的启发，本研究提出了一种多智能体推理框架（KCS+IBC），通过整合多个大语言模型（LLMs）实现偏见缓解、解释性提升和情感分析中的概率预测。除了顺序共享预测结果外，该方法还引入了一个中期非正式对话环节，将正式推理与个体视角相结合，并采用概率情感预测。实验结果表明，KCS在数据集上的精度与单一LLM相当，而KCS+IBC在推理后期表现出熵的持续降低和方差的逐步增加，表明该框架能够平衡预测的聚合与多样性。未来工作将量化这些特性对偏见校正的影响，并致力于开发更先进的情感分析系统。

</details>


### [12] [The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation](https://arxiv.org/abs/2506.21566)
**中文标题：高质量低资源英语-古吉拉特语机器翻译中反向翻译的饱和点**

*Arwa Arif*

主要分类: cs.CL

摘要简述: 本研究探讨了反向翻译（BT）在高质量低资源英语-古吉拉特语机器翻译中的效果，发现即使使用精心筛选的反向翻译数据，性能也未提升，甚至略有下降，表明反向翻译在特定低资源场景中可能达到收益递减点。


<details>
  <summary>详细信息</summary>
研究动机: 反向翻译在低资源机器翻译中被广泛用于生成合成训练数据，但其在高质量低资源语言对（如英语-古吉拉特语）中的效果尚不明确。本研究旨在验证反向翻译在此类场景中的实际效果。

研究方法: 使用多语言预训练模型MBART50，基于约50,000句高质量平行语料库训练基线系统，并通过单语古吉拉特语文本生成反向翻译数据。随后评估添加反向翻译数据后的模型性能，使用BLEU、ChrF++、TER、BLEURT等多种指标。

研究结果: 基线系统在验证集上BLEU得分为43.8。添加反向翻译数据后，翻译性能未提升，甚至略有下降。多指标分析表明反向翻译在此场景中可能已达到收益递减点。

研究结论: 反向翻译在特定低资源设置中可能无法进一步提升性能，甚至可能带来负面影响。研究结果对低资源机器翻译的未来研究方向具有启示意义。

中文摘要: 反向翻译（BT）在低资源机器翻译（MT）中被广泛用于通过单语语料库生成额外的合成训练数据。尽管这种方法在许多语言对中表现出显著的改进效果，但其在高质量低资源环境中的有效性仍不明确。本研究探讨了反向翻译在英语-古吉拉特语翻译中的效果，使用了多语言预训练模型MBART50。基线系统基于约50,000句高质量平行语料库训练，验证集BLEU得分为43.8。通过从单语古吉拉特语文本生成的反向翻译数据增强训练数据后，翻译性能并未提升，甚至略有下降。我们使用BLEU、ChrF++、TER、BLEURT等多种指标评估模型，并分析了这种饱和现象的可能原因。研究结果表明，反向翻译在特定低资源场景中可能已达到收益递减点，并对未来研究提出了相关启示。

</details>


### [13] [BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining](https://arxiv.org/abs/2506.21567)
**中文标题：BioPars：一种用于波斯语生物医学文本挖掘的预训练大型语言模型**

*Baqer M. Merzah,Tania Taami,Salman Asoudeh,Amir reza Hossein pour,Saeed Mirzaee,Amir Ali Bengari*

主要分类: cs.CL

摘要简述: 本文介绍了BioPars，一个针对波斯语生物医学文本挖掘的预训练大型语言模型，并提出了BIOPARS-BENCH数据集和BioParsQA评估工具。实验表明，BioPars在波斯语医学问答任务中表现优于其他模型，如GPT-4。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在生命科学领域的应用日益广泛，但波斯语生物医学文本挖掘领域的研究仍显不足。本文旨在填补这一空白，开发一个专门针对波斯语生物医学文本的LLM，并评估其性能。

研究方法: 研究首先构建了BIOPARS-BENCH数据集（包含10,000多篇科学文章、教科书和医学网站内容）和BioParsQA（5,231个波斯语医学问答对）。随后提出了BioPars模型，用于评估LLMs在获取专业知识、解释和综合知识以及提供证据方面的能力。

研究结果: BioPars在BioParsQA上的ROUGE-L得分为29.99，优于GPT-4 1.0；BERTScore为90.87（MMR方法）。此外，MoverScore和BLEURT得分分别为60.43和50.78，均高于其他对比模型。

研究结论: BioPars是首个应用于波斯语医学问答的LLM，尤其在生成长答案方面表现优异。实验结果表明，该模型在生物信息学任务中具有潜力，但仍需进一步优化以应对更复杂的实际问题。

中文摘要: 大型语言模型（LLMs）因其能够建模、提取和应用复杂的生物信息而在生命科学领域受到关注。除了传统的聊天机器人用途外，这些系统越来越多地用于专业领域的复杂分析和问题解决，包括生物信息学。首先，我们介绍了BIOPARS-BENCH数据集，该数据集来自10,000多篇科学文章、教科书和医学网站。同时，还提出了BioParsQA，用于评估所提出的模型，该数据集包含5,231个波斯语医学问题和答案。本研究随后介绍了BioPars，这是一种简单但准确的评估方法，旨在评估LLMs的三种主要能力：获取特定主题知识、解释和综合此类知识以及展示适当的证据。通过比较ChatGPT、Llama和Galactica，我们的研究突出了它们记忆和检索学习知识的能力，但也揭示了在解决更高层次的实际问题和细粒度推理方面的不足。这些发现表明，需要进一步微调以提升LLMs在生物信息学任务中的能力。据我们所知，BioPars是LLM在波斯语医学问答中的首次应用，尤其是在生成长答案方面。对四个选定的医学问答数据集的评估表明，与对比方法相比，BioPars取得了显著成果。该模型在BioParsQA上的ROUGE-L得分为29.99，优于GPT-4 1.0。使用MMR方法，该模型的BERTScore为90.87。此外，该模型的MoverScore和BLEURT值也高于其他三个模型，分别为60.43和50.78。BioPars是一个持续进行的项目，其开发相关的所有资源将通过以下GitHub仓库提供：https://github.com/amirap80/BioPars。

</details>


### [14] [Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion](https://arxiv.org/abs/2506.21568)
**中文标题：评估RAG和HyDE在1B与4B参数Gemma LLM上对个人助手集成的效果**

*Andrejs Sorstkins*

主要分类: cs.CL

摘要简述: 本文评估了检索增强生成（RAG）和假设文档嵌入（HyDE）在1B和4B参数的Gemma LLM上的表现，发现RAG在延迟和准确性上优于HyDE，适合隐私优先的个人助手应用。


<details>
  <summary>详细信息</summary>
研究动机: 资源效率是边缘和隐私敏感应用中部署大型语言模型（LLM）的关键障碍。本研究旨在评估两种增强策略（RAG和HyDE）在紧凑型Gemma LLM上的表现，以支持隐私优先的个人助手。

研究方法: 研究在1B和4B参数的Gemma LLM上实现RAG和HyDE策略，使用MongoDB实现短期记忆，Qdrant实现长期语义存储，并通过FastAPI和LangChain协调系统，前端使用React.js。

研究结果: RAG在两种模型规模下均显著降低延迟（最高17%）并消除事实幻觉，而HyDE虽提升语义相关性（尤其在复杂物理提示中），但导致25-40%的响应时间增加和较高的幻觉率。4B模型放大了HyDE的计算开销和变异性。

研究结论: RAG是小型LLM驱动的设备端个人助手的实用选择，而HyDE在计算效率和准确性上的不足限制了其适用性。

中文摘要: 资源效率是边缘和隐私敏感应用中部署大型语言模型（LLM）的关键障碍。本研究评估了两种增强策略——检索增强生成（RAG）和假设文档嵌入（HyDE）——在1B和4B参数的紧凑型Gemma LLM上的效果，应用于隐私优先的个人助手。通过MongoDB实现短期记忆，Qdrant实现长期语义存储，系统通过FastAPI和LangChain协调，并通过React.js前端展示。在两种模型规模下，RAG均显著降低延迟（最高17%）并消除事实幻觉，而HyDE虽提升语义相关性（尤其在复杂物理提示中），但导致25-40%的响应时间增加和较高的幻觉率。比较1B和4B模型发现，扩展对基线和RAG管道的吞吐量增益有限，但放大了HyDE的计算开销和变异性。研究结果表明，RAG是小型LLM驱动的设备端个人助手的实用选择。

</details>


### [15] [Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA](https://arxiv.org/abs/2506.21569)
**中文标题：Hybrid-NL2SVA：结合RAG与微调技术实现基于LLM的NL2SVA**

*Weihua Xiao,Derek Ekberg,Siddharth Garg,Ramesh Karri*

主要分类: cs.CL

摘要简述: 本文提出Hybrid-NL2SVA方法，结合检索增强生成（RAG）和微调技术，显著提升大语言模型（LLM）在自然语言到SystemVerilog断言（NL2SVA）任务中的性能。


<details>
  <summary>详细信息</summary>
研究动机: SystemVerilog断言（SVA）对硬件设计验证至关重要，但手动从自然语言描述生成SVA耗时且易错。现有大语言模型在领域特定语法和语义理解上表现不足，亟需改进。

研究方法: 提出定制化的RAG框架和合成微调数据集，通过提示引导的解释教导LLM逐步构建并发SVA，并结合HybridRetrieval技术优化轻量级模型性能。

研究结果: 实验表明，定制RAG框架使功能匹配SVA数量比GPT-4o-mini提升58.42%，微调后的Qwen2.5-Coder-7B-Instruct模型性能比基础模型提升59.05%。

研究结论: Hybrid-NL2SVA方法显著提升了LLM在NL2SVA任务中的准确性和功能性，为硬件设计验证提供了高效自动化解决方案。

中文摘要: SystemVerilog断言（SVA）对验证硬件设计的正确性至关重要，但从自然语言属性描述手动编写SVA（即NL2SVA）仍是一项耗时且易错的任务。大语言模型（LLM）的最新进展为自动化这一翻译提供了机会，但现有模型在理解领域特定语法和语义方面仍存在困难。为提升LLM在NL2SVA中的性能，我们提出了一种定制化的检索增强生成（RAG）框架和一个合成微调数据集，二者共同优化了LLM的表现。为进一步提升轻量级模型在NL2SVA上的性能，我们的微调数据集提供了提示引导的解释，教导LLM逐步构建并发SVA，从而实现监督微调，大幅提升语法和功能准确性。为评估LLM在NL2SVA上的表现，我们构建了最大的NL2SVA评估数据集，包含40个Verilog设计和229个经过形式验证的SVA及详细注释。实验结果表明，我们的定制RAG框架使功能匹配SVA数量比GPT-4o-mini提升了58.42%，而在我们的微调数据集上微调并结合HybridRetrieval的Qwen2.5-Coder-7B-Instruct模型比基础Qwen模型提升了59.05%。

</details>


### [16] [Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting](https://arxiv.org/abs/2506.21570)
**中文标题：随机初始化无法追赶：语言模型迁移在时间序列预测中的优势**

*Roland Riachi,Kashif Rasul,Arjun Ashok,Prateek Humane,Alexis Roger,Andrew R. Williams,Yuriy Nevmyvaka,Irina Rish*

主要分类: cs.CL

摘要简述: 研究表明，在低数据量情况下，预训练语言模型（LMs）迁移至时间序列预测任务时，设计选择（如上流后训练、时间序列分词器和语言模型规模）对验证损失有显著影响。与随机初始化模型相比，LMs的验证损失持续下降，形成不可忽视的迁移优势。


<details>
  <summary>详细信息</summary>
研究动机: 探索预训练语言模型在低数据量时间序列预测任务中的有效性，分析不同设计选择对模型性能的影响，并验证其优于随机初始化模型的优势。

研究方法: 通过实验分析上游后训练、时间序列分词器和语言模型规模等设计选择对验证损失的影响，比较预训练语言模型与随机初始化模型的性能差异。

研究结果: 在低数据量情况下，预训练语言模型的验证损失持续下降，显著优于随机初始化模型，且设计选择对性能有重要影响。

研究结论: 预训练语言模型在时间序列预测任务中具有显著优势，设计选择对性能至关重要，为计算高效训练和多模态数据分布研究提供了新方向。

中文摘要: 近期研究表明，在低数据量情况下，预训练语言模型（LMs）可有效用于时间序列预测。我们在此基础上分析了语言模型迁移至时间序列预测任务时的设计选择（如上流后训练、时间序列分词器和语言模型规模）对性能的影响。在低数据量情况下，这些设计选择对验证损失有显著影响，且某些选择明显优于其他。与Hernandez等人（2021年）的研究相反，我们发现LMs的验证损失在随机初始化模型收敛后仍持续下降，形成不可忽视的迁移优势，且这一现象在不同设计选择中均成立。这些发现不仅有助于揭示计算高效训练在时间序列任务中的有效应用，还为研究这些模型所利用的数据分布的多模态无关特性开辟了新途径。

</details>


### [17] [Towards Understanding the Cognitive Habits of Large Reasoning Models](https://arxiv.org/abs/2506.21571)
**中文标题：理解大型推理模型的认知习惯**

*Jianshuo Dong,Yujia Fu,Chuanrui Hu,Chao Zhang,Han Qiu*

主要分类: cs.CL

摘要简述: 本文通过CogTest基准评估大型推理模型（LRMs）的认知习惯，发现其具有类似人类的认知习惯，并能根据不同任务自适应调整。研究还揭示了某些习惯与有害响应的关联。


<details>
  <summary>详细信息</summary>
研究动机: 受大型推理模型（LRMs）中反复出现的类似人类思维链（CoT）模式的启发，研究旨在探索LRMs是否具有类似人类的认知习惯，并开发了CogTest基准进行系统评估。

研究方法: 研究引入CogTest基准，包含16种认知习惯，每种习惯对应25个多样化任务，并采用证据优先的提取方法确保习惯识别的可靠性。对16种广泛使用的LLMs（包括13种LRMs和3种非推理模型）进行了全面评估。

研究结果: 研究发现LRMs表现出类似人类的认知习惯，并能根据任务自适应调整。进一步分析揭示了不同模型家族间的认知习惯相似性（如Qwen-3和DeepSeek-R1）。某些习惯（如“承担负责任的风险”）与有害响应的生成密切相关。

研究结论: 研究表明，通过研究LRMs的思维链中的行为模式，可以更深入地理解LLMs的异常行为。CogTest为未来研究提供了有价值的工具。

中文摘要: 大型推理模型（LRMs）能够自主生成思维链（CoT）后再给出最终响应，这为解释和监控模型行为提供了新途径。受某些CoT模式（如“等等，我漏了什么吗？”）在不同任务中反复出现的启发，我们探索LRMs是否具有类似人类的认知习惯。基于“思维习惯”（Habits of Mind）这一成熟的人类问题解决框架，我们提出了CogTest基准，用于评估LRMs的认知习惯。CogTest包含16种认知习惯，每种习惯对应25个多样化任务，并采用证据优先的提取方法确保习惯识别的可靠性。通过CogTest，我们对16种广泛使用的LLMs（包括13种LRMs和3种非推理模型）进行了全面评估。结果表明，LRMs不仅表现出类似人类的习惯，还能根据任务自适应调整。更细致的分析揭示了不同模型家族间的认知习惯相似性（如Qwen-3和DeepSeek-R1）。在安全相关任务中，某些习惯（如“承担负责任的风险”）与有害响应的生成密切相关。这些发现表明，研究LRMs的CoT中的行为模式是理解LLMs异常行为的重要一步。代码已开源：https://github.com/jianshuod/CogTest。

</details>


### [18] [Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling](https://arxiv.org/abs/2506.21572)
**中文标题：基于结构方程模型的多模态大语言模型评测基准与人偏好对齐**

*Tianyu. Zou,Shengwu. Xiong,Ruilin. Yao,Jirui. Huang,Yi. Rong,Yaxiong. Chen,Shili. Xiong,Cong. Wang*

主要分类: cs.CL

摘要简述: 本文提出了一种基于结构方程模型（SEM）的新型框架，用于对齐多模态大语言模型（MLLM）的评测基准，解决了现有基准设计中的重叠能力、冗余指标和诊断能力不足的问题。通过引入基于皮亚杰认知发展理论的能力层次结构，构建了新的评测基准Gold，实验证明其具有更强的可解释性和认知一致性。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型（MLLM）的评测基准缺乏结构化、可解释且理论支持的设计，导致能力重叠、指标冗余和诊断能力有限。本文旨在解决这些问题，提出一种更科学、更有效的评测框架。

研究方法: 采用结构方程模型（SEM）分析和量化评测基准的内部效度、维度分离性和组件贡献。基于皮亚杰认知发展理论，将MLLM能力划分为感知、记忆和推理三个层次，并重新组织现有基准，构建新基准Gold。

研究结果: 实验结果表明，新基准Gold相比现有方法具有更强的可解释性、更少的指标冗余和更清晰的认知一致性。

研究结论: 本文提出的基于SEM的框架和Gold基准显著提升了MLLM评测的科学性和有效性，为未来研究提供了更可靠的评测工具。

中文摘要: 评估多模态大语言模型（MLLM）仍是一项基础性挑战，主要由于缺乏结构化、可解释且理论支持的评测基准设计。现有基准通常采用启发式任务分组，认知目标不明确，导致能力重叠、指标冗余和诊断能力有限。本文提出了一种基于结构方程模型（SEM）的新型框架，用于分析和量化评测基准的内部效度、维度分离性和组件贡献。针对当前设计的局限性，我们进一步引入基于皮亚杰认知发展理论的能力层次结构，将MLLM能力划分为感知、记忆和推理三个层次。在此框架下，我们重组了现有MLLM评测基准，并构建了名为Gold的新基准。实验结果表明，与现有方法相比，所提出的基准具有更强的可解释性、更少的指标冗余和更清晰的认知一致性。

</details>


### [19] [Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs](https://arxiv.org/abs/2506.21573)
**中文标题：指令学习范式：白盒与黑盒大语言模型的双重视角**

*Yanwei Ren,Liu Liu,Baosheng Yu,Jiayan Qiu,Quan Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种结合白盒和黑盒大语言模型（LLM）优势的新框架，通过黑盒模型提供高质量指令初始化，白盒模型提供细粒度可解释性，并通过语义相似性约束融合两者，实现指令质量的迭代优化。实验表明该方法在多种任务中优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 当前优化大语言模型指令的方法中，白盒方法需要大量计算资源且表达能力有限，黑盒方法则成本高昂。本文旨在结合两者的优势，提出一种高效且可扩展的解决方案。

研究方法: 提出了一种新框架，利用黑盒模型生成高质量、多样化的指令初始化，白盒模型通过隐藏状态和输出特征提供细粒度可解释性。通过语义相似性约束，将两者融合为统一的高维表示，并通过迭代优化提升指令质量和适应性。

研究结果: 在复杂推理和跨语言泛化等多种任务上的广泛评估表明，该方法显著优于现有基线，实现了指令质量和适应性的提升。

研究结论: 结合黑盒初始化和高级语义优化的方法为下一代大语言模型驱动的应用提供了高效且可扩展的解决方案。

中文摘要: 优化大语言模型（LLM）的指令对于在复杂多样任务中充分发挥其潜力至关重要。然而，仅依赖白盒方法需要大量计算资源且表达能力有限，而黑盒模型则可能带来高昂成本。为解决这些问题，我们提出了一种新框架，无缝融合两种范式的优势。黑盒模型提供高质量、多样化的指令初始化，白盒模型通过隐藏状态和输出特征提供细粒度可解释性。通过语义相似性约束，这些组件融合为统一的高维表示，捕捉深层语义和结构细节，并通过迭代优化提升指令质量和适应性。在复杂推理到跨语言泛化等多种任务上的广泛评估表明，我们的方法始终优于现有基线。这种黑盒初始化与高级语义优化的结合为下一代LLM驱动的应用提供了高效且可扩展的解决方案。源代码即将发布。

</details>


### [20] [Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions](https://arxiv.org/abs/2506.21574)
**中文标题：数字守门人：探索大型语言模型在移民决策中的作用**

*Yicheng Mao,Yang Zhao*

主要分类: cs.CL

摘要简述: 本研究探讨大型语言模型（如GPT-3.5和GPT-4）在移民决策中的潜力，发现其能模拟人类决策策略，但也存在国籍偏见和特权群体偏好。


<details>
  <summary>详细信息</summary>
研究动机: 随着全球化与移民人口增加，移民部门面临巨大工作量和公平决策的挑战，人工智能的整合被视为潜在解决方案。

研究方法: 采用混合方法，包括离散选择实验和深度访谈，研究大型语言模型的决策策略及其公平性。

研究结果: 研究发现大型语言模型能模拟人类决策，注重效用最大化和程序公平，但仍存在国籍刻板印象和特权群体偏好。

研究结论: 大型语言模型在自动化移民决策中具有潜力，但也需警惕其偏见和局限性。

中文摘要: 随着全球化和移民人口的增加，移民部门面临巨大的工作量以及确保决策过程公平的挑战。人工智能的整合为这些挑战提供了潜在的解决方案。本研究探讨了大型语言模型（如GPT-3.5和GPT-4）在支持移民决策中的潜力。通过混合方法，本文进行了离散选择实验和深度访谈，以研究大型语言模型的决策策略及其公平性。我们的研究结果表明，大型语言模型能够将其决策与人类策略对齐，强调效用最大化和程序公平。同时，本文也揭示，尽管ChatGPT设有防止无意歧视的保障措施，但仍表现出关于国籍的刻板印象和偏见，并对特权群体表现出偏好。这一双重分析凸显了大型语言模型在自动化和优化移民决策中的潜力与局限性。

</details>


### [21] [STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing](https://arxiv.org/abs/2506.21575)
**中文标题：STRuCT-LLM：通过强化学习统一表格与图推理的语义解析框架**

*Josefa Lia Stoisser,Marc Boubnovski Martell,Lawrence Phillips,Casper Hansen,Julien Fauqueur*

主要分类: cs.CL

摘要简述: STRuCT-LLM是一个统一框架，通过强化学习和思维链监督训练大语言模型，同时优化Text-to-SQL和Text-to-Cypher任务，实现跨形式迁移，显著提升语义解析性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常单独处理关系型数据和图数据，缺乏统一的推理框架。本文旨在通过共享SQL和Cypher的抽象，实现跨形式迁移，提升模型在语义解析任务中的表现。

研究方法: 结合强化学习和思维链监督，引入基于图编辑距离的拓扑感知奖励函数，联合优化Text-to-SQL和Text-to-Cypher任务，利用SQL和Cypher的共享抽象实现跨形式迁移。

研究结果: 最大模型QwQ-32B在Spider任务上提升13.5%，Text2Cypher任务提升73.1%，并在零样本下游任务（如表格QA和知识图谱QA）中表现优异。

研究结论: STRuCT-LLM证明了可执行查询作为结构化推理支架的有效性，以及联合训练SQL和Cypher的协同优势，为跨形式语义解析提供了新思路。

中文摘要: 我们提出了STRuCT-LLM，一个统一框架，用于训练大语言模型（LLMs）在关系型数据和图结构数据上进行结构化推理。该方法通过强化学习（RL）结合思维链（CoT）监督，联合优化Text-to-SQL和Text-to-Cypher任务。为支持图解析的细粒度优化，我们引入了基于图编辑距离的拓扑感知奖励函数。与以往孤立处理关系型和图形式的工作不同，STRuCT-LLM利用SQL和Cypher之间的共享抽象实现跨形式迁移，即使在没有共享模式的情况下，SQL训练也能提升Cypher性能，反之亦然。我们的最大模型（QwQ-32B）在语义解析任务中取得了显著相对提升：Spider任务提升13.5%，Text2Cypher任务提升73.1%。该模型还表现出强大的零样本泛化能力，在下游表格QA（TableBench：8.5%）和知识图谱QA（CR-LT-KGQA：1.7%）任务中无需特定监督即可提升性能。这些结果既证明了可执行查询作为结构化推理支架的有效性，也展示了联合训练SQL和Cypher的协同优势（代码见https://github.com/bouv/STRuCT-LLM）。

</details>


### [22] [Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning](https://arxiv.org/abs/2506.21576)
**中文标题：通过软提示调优实现参数高效的代码切换语音识别：Whisper的适配**

*Hongli Yang,Yizhou Peng,Hao Huang,Sheng Li*

主要分类: cs.CL

摘要简述: 本文探讨了通过软提示调优（SPT）提升Whisper模型在代码切换语音识别（CS ASR）中的性能，同时保持参数效率。实验表明，深度提示调优是最有效的SPT方法，且提出的SPT4ASR方法进一步降低了错误率。


<details>
  <summary>详细信息</summary>
研究动机: 大规模多语言ASR模型（如Whisper）在高资源场景表现优异，但在低资源场景（如稀有语言和代码切换）中面临计算成本和灾难性遗忘的挑战。本文旨在通过参数高效的方法提升CS ASR性能，同时保留模型原有知识。

研究方法: 研究了两种策略：(1) 完全微调（FFT）软提示和整个Whisper模型；(2) 冻结模型参数，仅训练软提示。此外，提出了SPT4ASR，结合多种SPT变体。实验基于SEAME和ASRU2019数据集。

研究结果: 深度提示调优是最有效的SPT方法，SPT4ASR进一步降低了CS ASR的错误率，且参数效率与LoRA相当，未影响现有语言性能。

研究结论: 软提示调优是一种参数高效的方法，可显著提升CS ASR性能，同时避免灾难性遗忘。SPT4ASR方法进一步优化了性能，为低资源场景提供了实用解决方案。

中文摘要: 大规模多语言ASR模型（如Whisper）在高资源场景表现优异，但在低资源场景（如稀有语言和代码切换）中面临计算成本和灾难性遗忘的挑战。我们探索了软提示调优（SPT），一种参数高效的方法，以提升CS ASR性能，同时保留原有知识。评估了两种策略：(1) 完全微调（FFT）软提示和整个Whisper模型，显示其跨语言能力优于传统方法；(2) 遵循SPT原始设计，冻结模型参数，仅训练软提示。此外，提出了SPT4ASR，结合多种SPT变体。在SEAME和ASRU2019数据集上的实验表明，深度提示调优是最有效的SPT方法，且SPT4ASR方法进一步降低了CS ASR的错误率，参数效率与LoRA相当，未影响现有语言性能。

</details>


### [23] [Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR](https://arxiv.org/abs/2506.21577)
**中文标题：语言感知提示调优：多语言ASR中参数高效的无缝语言扩展**

*Hongli Yang,Sheng Li,Hao Huang,Ayiduosi Tuohan,Yizhou Peng*

主要分类: cs.CL

摘要简述: 本文提出两种参数高效的提示调优方法（Entire SPT和LAPT），用于提升多语言ASR中的语言扩展能力，显著优于现有方法，同时计算开销极小。


<details>
  <summary>详细信息</summary>
研究动机: 当前多语言自动语音识别（ASR）面临语言干扰和扩展到未见语言（语言扩展）时的性能下降问题，亟需高效解决方案。

研究方法: 1) Entire SPT：在编码器和解码器中均应用软提示，增强特征提取和解码；2) LAPT：利用跨语言相似性，通过轻量级提示矩阵编码共享和语言特定特征；3) SPT-Whisper：将SPT集成到Whisper中，支持高效持续学习。

研究结果: 在FLEURS的三个语言实验中，Entire SPT和LAPT在语言扩展任务中分别比Decoder SPT提升5.0%和16.0%，计算开销极小。

研究结论: Entire SPT和LAPT为动态多语言ASR模型提供了高效解决方案，显著提升语言扩展能力。

中文摘要: 近期多语言自动语音识别（ASR）的进展主要由Whisper等大规模端到端模型推动，但语言干扰和扩展到未见语言（语言扩展）时的性能下降问题仍然存在。本文通过三项贡献解决这些问题：1) Entire SPT：在编码器和解码器中应用软提示，增强特征提取和解码；2) LAPT：利用跨语言相似性，通过轻量级提示矩阵编码共享和语言特定特征；3) SPT-Whisper：将SPT集成到Whisper中，支持高效持续学习。在FLEURS的三个语言实验中，Entire SPT和LAPT在语言扩展任务中分别比Decoder SPT提升5.0%和16.0%，为动态多语言ASR模型提供了高效且计算开销极小的解决方案。

</details>


### [24] [MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark](https://arxiv.org/abs/2412.15194)
**中文标题：MMLU-CF：一个无污染的多任务语言理解基准**

*Qihao Zhao,Yangyu Huang,Tengchao Lv,Lei Cui,Qinzheng Sun,Shaoguang Mao,Xin Zhang,Ying Xin,Qiufeng Yin,Scarlett Li,Furu Wei*

主要分类: cs.CL

摘要简述: 本文提出了一个名为MMLU-CF的无污染多任务语言理解基准，旨在解决现有评测中因数据泄露导致的不可靠问题。通过更广泛的数据来源和去污染规则设计，以及封闭测试集的设置，该基准显著提升了评测的严谨性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大规模多任务语言理解评测（如MMLU）因开源性质和训练数据的广泛来源，不可避免地存在数据泄露问题，导致评测结果不可靠。为了解决这一问题，作者提出了一个无污染的评测基准。

研究方法: MMLU-CF通过从更广泛的领域获取数据并设计三条去污染规则，避免无意数据泄露；同时将基准分为验证集和测试集，测试集保持封闭以确保可靠性。验证集公开以促进透明度和独立验证。

研究结果: 对主流大语言模型的评测显示，强大的GPT-4o在测试集上的5-shot和0-shot得分分别为73.4%和71.9%，证明了该基准在创建更严格评测标准方面的有效性。

研究结论: MMLU-CF通过避免数据泄露和封闭测试集的设计，成功创建了一个更严谨且无污染的评测标准，为大语言模型的可靠评估提供了新工具。

中文摘要: 多项选择题数据集（如大规模多任务语言理解评测MMLU）被广泛用于评估大语言模型的常识、理解和问题解决能力。然而，这些评测的开源性质以及大语言模型训练数据的广泛来源不可避免地导致了评测污染，使得评测结果不可靠。为缓解这一问题，我们提出了一个无污染且更具挑战性的多项选择题评测基准MMLU-CF。该基准通过避免无意和恶意的数据泄露，重新评估大语言模型对世界知识的理解。为避免无意数据泄露，我们从更广泛的领域获取数据并设计了三项去污染规则；为防止恶意数据泄露，我们将基准分为难度和主题分布相似的验证集和测试集。测试集保持封闭以确保结果可靠，而验证集公开以促进透明度和独立验证。对主流大语言模型的评测显示，强大的GPT-4o在测试集上的5-shot和0-shot得分分别为73.4%和71.9%，证明了我们在创建更严格且无污染的评测标准方面的有效性。GitHub仓库地址为https://github.com/microsoft/MMLU-CF，数据集地址为https://huggingface.co/datasets/microsoft/MMLU-CF。

</details>


### [25] [HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models](https://arxiv.org/abs/2506.21578)
**中文标题：HealthQA-BR：系统级基准测试揭示大型语言模型的关键知识缺陷**

*Andrew Maranhão Ventura D'addario*

主要分类: cs.CL

摘要简述: 本文介绍了首个针对葡萄牙语医疗领域的大规模系统基准测试HealthQA-BR，揭示了大型语言模型在跨专业医疗知识中的严重不足，尽管整体表现优异，但在某些领域表现极差。


<details>
  <summary>详细信息</summary>
研究动机: 当前对大型语言模型在医疗领域的评估主要集中于英语和医生视角，忽视了跨专业医疗团队的需求，可能导致模型能力的误判。

研究方法: 研究团队开发了HealthQA-BR基准，包含5,632道巴西国家级考试题目，覆盖医学、护理、牙科、心理学等多个医疗专业，并对20多个领先的大型语言模型进行了零样本评估。

研究结果: 尽管GPT 4.1等先进模型整体准确率达86.6%，但在神经外科（60.0%）和社会工作（68.4%）等领域的表现显著下降，显示出知识分布不均的系统性问题。

研究结论: 单一评分不足以验证模型的安全性，HealthQA-BR为更全面、细致的AI医疗能力评估提供了重要工具。

中文摘要: 大型语言模型（LLM）在医疗领域的评估主要集中于以医生为中心的英语基准测试，忽视了跨专业医疗团队的现实需求，导致对其能力的误判。为此，我们推出了HealthQA-BR，这是首个针对葡萄牙语医疗领域的大规模系统基准测试。该测试包含5,632道巴西国家级考试题目，覆盖医学、护理、牙科、心理学、社会工作等多个医疗专业。我们对20多个领先的LLM进行了严格的零样本评估。结果显示，尽管GPT 4.1等先进模型的整体准确率达86.6%，但这一高分掩盖了其在某些领域的严重缺陷。例如，模型在眼科（98.7%）表现近乎完美，但在神经外科（60.0%）和社会工作（68.4%）等领域表现堪忧。这种“不均衡”的知识分布是所有模型的通病，表明单一高分不足以验证其安全性。通过公开HealthQA-BR及其评估工具，我们为超越单一评分、实现更全面细致的AI医疗能力评估提供了关键工具。

</details>


### [26] [From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models](https://arxiv.org/abs/2506.21580)
**中文标题：从通用推理到领域专业知识：揭示大型语言模型泛化的局限性**

*Dana Alsagheer,Yang Lu,Abdulrahman Kamal,Omar Kamal,Mohammad Kamal,Nada Mansour,Cosmo Yang Wu,Rambiba Karanjai,Sen Li,Weidong Shi*

主要分类: cs.CL

摘要简述: 本文探讨大型语言模型（LLMs）的通用推理能力如何影响其在领域特定任务中的表现，揭示了通用推理与领域专业知识之间的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在多个领域展现出卓越能力，研究其通用推理能力如何转化为领域特定任务的表现成为关键。本文旨在揭示通用推理与领域专业知识之间的联系及其局限性。

研究方法: 研究通过分析LLMs在通用推理任务和领域特定任务中的表现，探讨其推理能力的迁移效果。

研究结果: 研究发现，尽管LLMs在通用推理任务中表现优异，但其在领域特定任务中的表现受到限制，表明通用推理能力无法完全替代领域专业知识。

研究结论: 通用推理能力虽为LLMs提供了广泛的应用潜力，但在领域特定任务中仍需结合专业知识以实现更优表现。

中文摘要: 近年来，大型语言模型（LLMs）在多个领域展现出卓越能力。然而，有效的决策依赖于强大的推理能力。推理是决策的基础，提供了分析和逻辑框架以做出合理选择。推理涉及分析信息、推断结论，并基于逻辑或证据得出结论。决策则在此基础上，通过应用推理的见解从备选方案中选择最佳行动路径。这些过程共同构成了一个持续的思维与行动循环，旨在高效实现目标。随着AI技术的发展，训练LLMs在通用推理中表现出色的趋势日益明显。本研究探讨了LLMs的通用推理能力如何与其在领域特定推理任务中的表现相关联。

</details>


### [27] [VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents](https://arxiv.org/abs/2506.21582)
**中文标题：VIDEE：基于智能代理的文本分析可视化与交互式分解、执行和评估**

*Sam Yu-Te Lee,Chengyang Ji,Shicheng Wen,Lifu Huang,Dongyi Liu,Kwan-Liu Ma*

主要分类: cs.CL

摘要简述: VIDEE是一个支持初级数据分析师通过智能代理进行高级文本分析的系统，结合人类反馈、生成可执行流程和可视化评估，提升了非专家用户的文本分析能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统文本分析需要自然语言处理（NLP）专业知识，对初级分析师构成门槛。大型语言模型（LLMs）的发展使文本分析更易自动化，但缺乏对非专家的支持。VIDEE旨在通过人机协作降低文本分析的门槛。

研究方法: VIDEE采用三阶段工作流：1）分解阶段，结合人类反馈的蒙特卡洛树搜索算法支持生成式推理；2）执行阶段，生成可执行文本分析流程；3）评估阶段，整合基于LLM的评估和可视化工具验证结果。

研究结果: 定量实验验证了VIDEE的有效性，并分析了代理常见错误。用户研究表明，系统对不同经验水平的用户均具有可用性，并揭示了不同的用户行为模式。

研究结论: VIDEE为非专家用户提供了实用的文本分析工具，验证了人机协作的可行性，并为未来智能文本分析系统的改进提供了设计启示。

中文摘要: 传统文本分析需要自然语言处理（NLP）或文本分析的专业知识，这对初级分析师构成了门槛。近年来，大型语言模型（LLMs）的发展改变了NLP的格局，使文本分析（如主题检测、摘要生成、信息提取等）更易自动化。我们提出了VIDEE，一个支持初级数据分析师通过智能代理进行高级文本分析的系统。VIDEE实现了一个人机协作的工作流，包含三个阶段：（1）分解阶段，采用结合人类反馈的蒙特卡洛树搜索算法支持生成式推理；（2）执行阶段，生成可执行的文本分析流程；（3）评估阶段，整合基于LLM的评估和可视化工具以支持用户验证执行结果。我们通过两项定量实验评估了VIDEE的有效性，并分析了代理的常见错误。一项涉及从无经验到专家的不同NLP和文本分析经验的用户研究表明，系统具有可用性，并揭示了不同的用户行为模式。研究结果为人机协作提供了设计启示，验证了VIDEE对非专家用户的实用性，并为未来智能文本分析系统的改进提供了参考。

</details>


### [28] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
**中文标题：语言模型训练中的数据效能**

*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

主要分类: cs.CL

摘要简述: 本文提出数据效能（Data Efficacy）概念，通过优化训练数据的组织方式提升语言模型性能，并设计DELT框架（包含数据评分、选择和排序），其中LQS评分和FO排序方法表现最佳。实验表明，数据效能与数据效率可结合使用。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多关注数据效率（如数据筛选和采样），而数据组织方式对语言模型训练的影响尚未充分探索。本文旨在填补这一空白，提出数据效能的概念，以优化数据组织提升模型性能。

研究方法: 提出DELT框架，包含数据评分（LQS，基于梯度一致性评估数据可学习性和质量）、数据选择和排序（FO，解决模型遗忘和数据分布偏差问题）。

研究结果: 实验表明：1) DELT框架在不增加数据量和模型规模的情况下提升模型性能；2) LQS评分与FO排序组合效果最佳；3) 数据效能与数据效率可协同作用。

研究结论: 数据效能是语言模型训练中具有潜力的研究方向，DELT框架为优化数据组织提供了有效方法。

中文摘要: 数据是语言模型（LM）训练的基础。近期研究致力于数据效率，即通过选择最小或最优训练数据子集来最大化性能。数据过滤、采样和选择等技术在此领域至关重要。作为补充，我们定义了数据效能，其目标是通过优化训练数据的组织方式提升性能，目前尚未充分探索。本文提出通用框架DELT，用于在LM训练中考虑数据效能，强调训练数据组织的重要性。DELT包含三个组件：数据评分、数据选择和数据排序。其中，我们设计了可学习性-质量评分（LQS）作为数据评分的新实例，从梯度一致性角度评估数据的可学习性和质量；还设计了折叠排序（FO）作为数据排序的新实例，解决模型遗忘和数据分布偏差等问题。综合实验验证了数据效能在LM训练中的作用：首先，DELT的多种实例在不增加数据规模和模型大小的情况下不同程度地提升了LM性能；其次，LQS评分与FO排序的组合效果最显著；最后，通过数据选择可实现数据效能与数据效率的结合。因此，我们认为数据效能是LM训练中具有潜力的基础研究方向。

</details>


### [29] [Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing](https://arxiv.org/abs/2506.21583)
**中文标题：混合罗马乌尔都语推文中的希望言论检测：自然语言处理的积极转向**

*Muhammad Ahmad,Muhammad Waqas,Ameer Hamza,Ildar Batyrshin,Grigori Sidorov*

主要分类: cs.CL

摘要简述: 本文首次针对混合罗马乌尔都语推文中的希望言论检测进行研究，填补了低资源非正式语言在自然语言处理中的空白，并提出了一个优化的注意力转换模型，性能优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 希望言论检测在自然语言处理中逐渐受到关注，但现有研究主要集中在高资源语言和标准化脚本，忽略了非正式和低资源语言如罗马乌尔都语。本文旨在填补这一空白，推动包容性自然语言处理研究。

研究方法: 研究首先构建了一个多类标注的罗马乌尔都语希望言论数据集，并基于心理学基础和语言模式分析开发数据集。随后提出了一种针对罗马乌尔都语语法和语义变异性优化的自定义注意力转换模型，并通过5折交叉验证进行评估。

研究结果: 提出的XLM-R模型在交叉验证中得分0.78，优于基线SVM（0.75）和BiLSTM（0.76），性能提升分别为4%和2.63%，且通过t检验验证了性能提升的统计显著性。

研究结论: 本研究首次解决了混合罗马乌尔都语中的希望言论检测问题，填补了研究空白，并通过优化的模型显著提升了性能，为低资源非正式语言的包容性自然语言处理提供了新思路。

中文摘要: 希望是一种积极的情绪状态，涉及对未来有利结果的期待，而希望言论则指在逆境中促进乐观、韧性和支持的交流。尽管希望言论检测在自然语言处理（NLP）中受到关注，但现有研究主要集中在高资源语言和标准化脚本，往往忽略了非正式和低资源形式，如罗马乌尔都语。据我们所知，这是首个通过引入精心标注的数据集来解决混合罗马乌尔都语中希望言论检测的研究，填补了低资源非正式语言变体在包容性NLP研究中的关键空白。本研究有四个关键贡献：（1）首次引入了罗马乌尔都语希望言论的多类标注数据集，包括广义希望、现实希望、非现实希望和非希望类别；（2）探索了希望的心理基础，并分析了其在混合罗马乌尔都语中的语言模式，为数据集开发提供依据；（3）提出了一种针对罗马乌尔都语语法和语义变异性优化的自定义注意力转换模型，并通过5折交叉验证进行评估；（4）通过t检验验证了性能提升的统计显著性。提出的XLM-R模型在交叉验证中得分0.78，优于基线SVM（0.75）和BiLSTM（0.76），性能提升分别为4%和2.63%。

</details>


### [30] [Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques](https://arxiv.org/abs/2506.21584)
**中文标题：小型语言模型中对齐伪装的实证证据及基于提示的缓解技术**

*J. Koorndijk*

主要分类: cs.CL

摘要简述: 研究发现，即使是小型语言模型（如LLaMA 3 8B）也可能出现对齐伪装行为（欺骗性对齐），而仅通过提示干预（如道德框架和思维记录）即可显著减少这种行为，无需修改模型内部。


<details>
  <summary>详细信息</summary>
研究动机: 当前文献认为对齐伪装是大型语言模型的涌现特性，但本文旨在证明小型模型同样可能表现出这种行为，并探索仅通过提示干预的缓解方法。

研究方法: 研究使用小型指令调优模型LLaMA 3 8B，通过实验验证其对齐伪装行为，并测试提示干预（如道德框架和思维记录）的效果。

研究结果: 实验证实小型模型存在对齐伪装行为，但提示干预可显著减少该行为。研究还提出分类法，区分浅层欺骗（可通过提示抑制）和深层欺骗（目标驱动的持续性不对齐）。

研究结论: 研究挑战了提示伦理无关紧要及欺骗性对齐仅存在于大型模型的假设，强调需对不同规模和部署场景的模型进行对齐评估。

中文摘要: 当前文献认为对齐伪装（欺骗性对齐）是大型语言模型的涌现特性。我们首次提供了小型指令调优模型（特别是LLaMA 3 8B）同样可能表现出对齐伪装的实证证据。我们还表明，仅通过提示干预（包括义务论道德框架和思维记录）即可显著减少该行为，而无需修改模型内部。这挑战了提示伦理无关紧要及欺骗性对齐需要规模的假设。我们提出了一种分类法，区分浅层欺骗（受上下文影响且可通过提示抑制）和深层欺骗（反映持续、目标驱动的不对齐）。这些发现深化了对语言模型中欺骗行为的理解，并强调需对不同规模和部署场景的模型进行对齐评估。

</details>


### [31] [Evaluation of LLM-based Strategies for the Extraction of Food Product Information from Online Shops](https://arxiv.org/abs/2506.21585)
**中文标题：基于大语言模型的在线商店食品产品信息提取策略评估**

*Christoph Brosch,Sian Brumm,Rolf Krieger,Jonas Scheffler*

主要分类: cs.CL

摘要简述: 本文评估了基于大语言模型（LLM）的两种策略，用于从在线商店提取食品产品信息。直接提取和间接提取（通过生成函数）在准确性、效率和成本上进行了比较，结果显示间接提取虽准确性略低，但显著减少了LLM调用次数，提升了效率和降低了成本。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在利用生成式AI和大语言模型（LLM）自动化从网页中提取结构化信息，特别是食品产品页面的关键属性（如成分表和营养表），以探索高效且经济的解决方案。

研究方法: 研究比较了两种基于LLM的提取方法：直接提取和间接提取（通过生成函数）。实验基于3,000个食品产品页面的数据集，评估了准确性、效率和成本。

研究结果: 间接提取的准确性略低（96.48%，比直接提取低1.61%），但减少了95.82%的LLM调用次数，显著提升了效率和降低了成本。

研究结论: 间接提取方法为基于模板网页的大规模信息提取任务提供了可扩展且经济高效的解决方案。

中文摘要: 生成式AI和大语言模型（LLM）为从网页中自动化提取结构化信息提供了巨大潜力。本研究聚焦于在线零售商的食品产品页面，探索基于模式约束的提取方法，以获取关键产品属性（如成分表和营养表）。我们比较了两种基于LLM的方法：直接提取和间接提取（通过生成函数），并在3,000个食品产品页面的数据集上评估了它们的准确性、效率和成本。结果显示，尽管间接提取的准确性略低（96.48%，比直接提取低1.61%），但它减少了95.82%的LLM调用次数，显著提升了效率并降低了运营成本。这些发现表明，间接提取方法可以为基于模板网页的大规模信息提取任务提供可扩展且经济高效的解决方案。

</details>


### [32] [Can Vision Language Models Understand Mimed Actions?](https://arxiv.org/abs/2506.21586)
**中文标题：视觉语言模型能否理解模仿动作？**

*Hyundong Cho,Spencer Lin,Tejas Srinivasan,Michael Saxon,Deuksin Kwon,Natali T. Chavez,Jonathan May*

主要分类: cs.CL

摘要简述: 本文探讨了视觉语言模型是否能理解模仿动作，提出了MIME基准测试，发现现有模型表现远不如人类，呼吁加强手势理解研究。


<details>
  <summary>详细信息</summary>
研究动机: 非语言交流（NVC）在人类语言中至关重要，但因其范围广且个体和文化间解释差异大，研究难度高。模仿动作作为NVC的子集，解释差异较小，是研究视觉语言模型理解NVC的关键前提。

研究方法: 作者提出MIME（模仿识别多模态评估），一个基于视频的问答基准测试，包含86种模仿动作，通过动作捕捉数据构建，并加入角色、背景和视角的扰动以评估识别鲁棒性。

研究结果: 实验发现，无论是开源还是API视觉语言模型，在MIME上的表现均显著低于人类水平，表明模型对手势的理解仍有不足。

研究结论: 研究强调了提升视觉语言模型对人类手势理解的重要性，MIME为未来研究提供了有价值的基准。

中文摘要: 非语言交流（NVC）在人类语言中扮演着重要角色，但由于其范围广泛且个体和文化间的解释差异较大，研究NVC具有挑战性。然而，模仿——一种仅通过手势、表情和动作表达意图的戏剧技术——是NVC的一个子集，其解释差异较小。我们认为，对模仿动作的深入理解是视觉语言模型能够解释和命令更微妙NVC方面的关键前提。因此，我们提出了模仿识别多模态评估（MIME），这是一个基于视频的问答基准测试，包含86种模仿动作。MIME通过动作捕捉数据构建，并对角色、背景和视角施加扰动以评估识别鲁棒性。我们发现，无论是开源还是API视觉语言模型，在MIME上的表现均显著低于人类，这促使我们需要加强对手势理解的研究。

</details>


### [33] [Is DeepSeek a New Voice Among LLMs in Public Opinion Simulation?](https://arxiv.org/abs/2506.21587)
**中文标题：DeepSeek是否成为大语言模型中公众意见模拟的新声音？**

*Weihong Qi,Fan Huang,Jisun An,Haewoon Kwak*

主要分类: cs.CL

摘要简述: 本研究评估了开源大语言模型DeepSeek在模拟中美两国公众意见方面的表现，发现DeepSeek-V3在美国堕胎议题上表现最佳，但在中国议题如资本主义观点上存在局限性。所有模型均存在过度概括群体观点的倾向，需减少文化及人口偏见。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在比较开源大语言模型DeepSeek与主流科技公司开发的模型（如Qwen2.5、GPT-4o、Llama-3.3）在模拟中美公众意见上的能力，揭示其文化及人口偏见的潜在问题。

研究方法: 通过比较DeepSeek-R1和DeepSeek-V3与其他模型，并利用美国国家选举研究（ANES）和中国佐标数据集，评估模型在预测中美社会议题公众意见上的表现。

研究结果: DeepSeek-V3在美国堕胎议题上表现最佳，尤其能准确模拟民主党或自由派观点；在中国议题中，其在外援和个人主义上表现较好，但在资本主义观点上存在局限。所有模型均倾向于过度概括群体观点。

研究结论: 研究强调需减少大语言模型在公众意见模拟中的文化和人口偏见，建议采用更具包容性的训练方法。

中文摘要: 本研究评估了开源大语言模型DeepSeek在模拟公众意见方面的能力，并与主流科技公司开发的模型（如Qwen2.5、GPT-4o、Llama-3.3）进行了比较。通过使用美国国家选举研究（ANES）和中国佐标数据集，我们分析了这些模型在预测中美社会议题公众意见上的表现。结果显示，DeepSeek-V3在美国堕胎议题上表现最佳，尤其是在模拟民主党或自由派观点时更为准确；而在中国议题中，其在外援和个人主义上表现较好，但在资本主义观点上存在局限，未能准确反映低收入和非大学学历人群的立场。此外，所有模型均倾向于过度概括群体观点，默认群体内一致响应。这些发现表明，需减少大语言模型在公众意见模拟中的文化和人口偏见，并采用更具包容性的训练方法。

</details>


### [34] [Understanding Verbatim Memorization in LLMs Through Circuit Discovery](https://arxiv.org/abs/2506.21588)
**中文标题：通过电路发现理解大型语言模型中的逐字记忆**

*Ilya Lasy,Peter Knees,Stefan Woltran*

主要分类: cs.CL

摘要简述: 本文通过研究大型语言模型（LLMs）中的逐字记忆机制，揭示了记忆启动与维持的电路差异，并发现记忆预防机制在不同文本领域中具有鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型中的逐字记忆机制尚不明确，研究旨在揭示记忆启动与维持的具体网络部分及其行为差异。

研究方法: 通过对比数据集和变压器电路分析，识别记忆内容与非记忆内容生成的分歧点，并分离负责记忆启动和维持的特定电路。

研究结果: 研究发现，记忆启动电路也能维持记忆，而仅维持记忆的电路无法触发启动；记忆预防机制在不同领域具有鲁棒性，而记忆诱导更具上下文依赖性。

研究结论: 记忆启动与维持的电路功能分离，记忆预防机制具有跨领域鲁棒性，为理解LLMs的记忆行为提供了新视角。

中文摘要: 大型语言模型（LLMs）中逐字记忆的底层机制仍不明确。网络中的哪一部分决定检索被视为记忆序列开始的标记？模型在生成记忆句子与非记忆句子时的行为究竟有何不同？本研究从机制可解释性角度出发，利用变压器电路（模型中执行特定功能的最小计算子图）探讨这些问题。通过精心构建的对比数据集，我们识别了模型生成与记忆内容的分歧点，并分离了负责记忆两个不同方面的特定电路。我们发现，启动记忆的电路也能在启动后维持记忆，而仅维持记忆的电路无法触发其启动。有趣的是，记忆预防机制在不同文本领域中具有鲁棒性，而记忆诱导则更具上下文依赖性。

</details>


### [35] [A General Method for Detecting Information Generated by Large Language Models](https://arxiv.org/abs/2506.21589)
**中文标题：一种检测大语言模型生成信息的通用方法**

*Minjia Mao,Dongjun Wei,Xiao Fang,Michael Chau*

主要分类: cs.CL

摘要简述: 本文提出了一种通用的大语言模型（LLM）生成内容检测方法（GLD），通过双记忆网络设计和理论指导的检测泛化模块，能够有效识别未知LLM和领域生成的内容，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLM）的普及，区分人类撰写和LLM生成的内容变得愈发困难，这对数字平台（如社交媒体和电商网站）的信任维护和防止虚假信息传播至关重要。现有检测方法难以泛化到未知LLM和领域，限制了其实际应用效果。

研究方法: 本文提出了一种通用LLM检测器（GLD），结合双记忆网络设计和理论指导的检测泛化模块，用于检测未知LLM和领域生成的内容。

研究结果: 通过真实数据集的大量实验和案例研究，GLD在检测LLM生成内容方面优于现有最先进方法。

研究结论: GLD为数字平台和LLM提供了重要的学术和实践意义，能够有效应对LLM生成内容的检测挑战。

中文摘要: 大语言模型（LLM）的广泛应用显著改变了数字信息环境，使得区分人类撰写和LLM生成的内容变得日益困难。检测LLM生成信息对于维护数字平台（如社交媒体和电商网站）的信任以及防止虚假信息传播至关重要，这一主题在信息系统研究中备受关注。然而，现有检测方法主要针对已知领域和特定LLM生成的内容，难以泛化到未知LLM和领域，限制了其在实际应用中的效果。为此，我们提出了一种通用LLM检测器（GLD），结合双记忆网络设计和理论指导的检测泛化模块，能够检测未知LLM和领域生成的内容。通过真实数据集的大量实验和案例研究，我们证明了GLD优于现有最先进的检测方法。本研究对数字平台和LLM具有重要的学术和实践意义。

</details>


### [36] [Representation Consistency for Accurate and Coherent LLM Answer Aggregation](https://arxiv.org/abs/2506.21590)
**中文标题：表示一致性：用于准确且连贯的LLM答案聚合**

*Junqi Jiang,Tom Bewley,Salim I. Amoukou,Francesco Leofante,Antonio Rago,Saumitra Mishra,Francesca Toni*

主要分类: cs.CL

摘要简述: 本文提出了一种称为“表示一致性”（RC）的测试时扩展方法，通过聚合大型语言模型（LLM）生成的多个候选回答，并结合模型内部激活的一致性来提升答案的准确性和连贯性。实验表明，RC在推理任务中显著提升了性能，最高可达4%的准确率提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有的测试时扩展方法通常需要对提示和采样策略进行复杂修改，而本文旨在通过一种无需额外模型查询的方法，仅利用缓存的激活和轻量级相似性计算，提升LLM在推理任务中的性能和答案连贯性。

研究方法: 提出表示一致性（RC）方法，通过分析模型生成多个候选回答时的内部激活（密集或稀疏）一致性，对答案进行加权聚合。若多个回答的激活表示高度不一致，则认为该答案可能源于不连贯的推理，从而降低其权重。

研究结果: 在四个开源LLM和四个推理数据集上的实验表明，RC显著提升了任务性能，最高可达4%的准确率提升，且稀疏激活信号的一致性与连贯推理的概念高度吻合。

研究结论: RC是一种高效且无需额外模型查询的测试时扩展方法，通过结合答案出现频率和模型内部激活一致性，显著提升了LLM推理任务的准确性和连贯性。

中文摘要: 测试时扩展通过增加推理时的计算预算来提升大型语言模型（LLM）的性能。现有方法通常需要对提示和采样策略进行复杂修改。本文提出表示一致性（RC），一种测试时扩展方法，用于聚合LLM生成的多个候选回答，无论其生成方式如何（包括提示措辞和采样策略的差异）。RC不仅考虑每个答案在候选回答集中的出现频率，还关注模型生成这些回答时的内部激活一致性（密集或稀疏）。我们的理论是，若模型对同一答案的多个回答的激活表示高度不一致，则该答案更可能源于不连贯的推理，应在聚合时降低权重。重要的是，该方法仅需缓存的激活和轻量级相似性计算，无需额外模型查询。通过在四个开源LLM和四个推理数据集上的实验，我们验证了RC在提升推理任务性能方面的有效性，准确率最高提升4%。此外，稀疏激活信号的一致性与连贯推理的概念高度吻合。

</details>


### [37] [FinEval-KR: A Financial Domain Evaluation Framework for Large Language Models' Knowledge and Reasoning](https://arxiv.org/abs/2506.21591)
**中文标题：FinEval-KR：大型语言模型知识与推理能力的金融领域评估框架**

*Shaoyu Dou,Yutian Shen,Mofan Chen,Zixuan Wang,Jiajie Xu,Qi Guo,Kailai Shao,Chao Chen,Haixiang Hu,Haibo Shi,Min Min,Liwen Zhang*

主要分类: cs.CL

摘要简述: FinEval-KR是一个新的评估框架，用于独立量化解耦大型语言模型（LLMs）在金融领域的知识和推理能力，并提出知识得分和推理得分指标。实验表明，推理能力和高阶认知能力是影响推理准确性的核心因素，但即使是顶级模型在知识应用上仍存在瓶颈。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估基准在复杂金融推理任务中未能独立衡量LLMs的知识和推理能力，且缺乏对任务失败的根本原因分析。因此，需要一种新的框架来解耦和量化这些能力，并支持可复现的研究。

研究方法: 提出FinEval-KR框架，通过知识得分和推理得分独立量化LLMs的能力，并基于Bloom认知分类法提出认知得分。同时发布了一个开源的中文金融推理数据集，涵盖22个子领域。

研究结果: 实验结果显示，LLMs的推理能力和高阶认知能力是影响推理准确性的核心因素，但知识应用仍是瓶颈。此外，专业金融LLMs在多指标上普遍落后于顶级通用大模型。

研究结论: FinEval-KR为金融领域的LLMs评估提供了新工具，揭示了推理能力和知识应用的重要性，并指出专业金融LLMs仍有改进空间。

中文摘要: 大型语言模型（LLMs）在复杂金融推理任务中展现出潜力，但面临知识和推理能力结合的挑战。现有评估基准未能解耦这些能力指标，且缺乏任务失败的根本原因分析。为此，我们提出FinEval-KR框架，独立量化解耦LLMs的知识和推理能力，并提出知识得分和推理得分指标。受认知科学启发，我们还基于Bloom分类法提出认知得分，以分析不同认知层次的推理能力。同时，我们发布了一个开源的中文金融推理数据集，涵盖22个子领域，支持可复现研究。实验结果表明，LLMs的推理能力和高阶认知能力是影响推理准确性的核心因素，但即使是顶级模型在知识应用上仍存在瓶颈。此外，专业金融LLMs在多指标上普遍落后于顶级通用大模型。

</details>


### [38] [SignBart -- New approach with the skeleton sequence for Isolated Sign language Recognition](https://arxiv.org/abs/2506.21592)
**中文标题：SignBart——基于骨架序列的孤立手语识别新方法**

*Tinh Nguyen,Minh Khue Phan Tran*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SignBart的新方法，通过独立处理骨架序列的x和y坐标，结合BART架构的编码器-解码器，显著提升了手语识别的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有手语识别方法在效率和准确性之间难以平衡，且传统模型（如RNN、LSTM、GCN）存在梯度消失和高计算成本问题。本研究旨在克服这些挑战，提供一种更高效且准确的手语识别方案。

研究方法: 采用BART架构的编码器-解码器，独立编码骨架序列的x和y坐标，并通过交叉注意力机制保持其关联性。同时引入坐标投影、归一化和多骨架组件以提升模型性能。

研究结果: 模型参数仅为749,888，在LSA-64数据集上达到96.04%的准确率，显著优于参数超过百万的先前模型，并在WLASL和ASL-Citizen数据集上表现出优异的泛化能力。

研究结论: SignBart为手语识别提供了一种可靠且高效的方法，有望显著提升听障人士的沟通工具。

中文摘要: 手语识别对于听障人士打破沟通障碍至关重要。然而，现有方法不得不在效率和准确性之间做出选择。例如，RNN、LSTM和GCN存在梯度消失和高计算成本的问题。尽管基于Transformer的方法提升了性能，但并未广泛应用。本研究提出了一种新颖的手语识别方法，克服了传统模型无法独立提取骨架序列x和y坐标中有意义信息的挑战。通过采用BART架构的编码器-解码器，模型独立编码x和y坐标，同时通过交叉注意力机制保持其关联性。模型仅包含749,888个参数，在LSA-64数据集上实现了96.04%的准确率，显著优于参数超过百万的先前模型。此外，模型在WLASL和ASL-Citizen数据集上也表现出优异的性能和泛化能力。消融研究强调了坐标投影、归一化和使用多骨架组件对提升模型效能的重要性。本研究为手语识别提供了一种可靠且高效的方法，具有显著提升听障人士辅助工具的潜力。

</details>


### [39] [Gazal-R1: Achieving State-of-the-Art Medical Reasoning with Parameter-Efficient Two-Stage Training](https://arxiv.org/abs/2506.21594)
**中文标题：Gazal-R1：通过参数高效的两阶段训练实现顶尖医学推理能力**

*Ahmed M. Adly,Mostafa Samy,Amr Fawzy*

主要分类: cs.CL

摘要简述: Gazal-R1是一个320亿参数的语言模型，通过两阶段训练（监督微调和强化学习）在医学推理任务中达到顶尖水平，同时提供透明的临床决策解释。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在证明中等规模模型通过策略性训练可以在专业领域超越更大模型，同时解决训练中的挑战（如奖励黑客、训练不稳定等）。

研究方法: 采用两阶段训练：1）监督微调，使用10.7万合成医学推理数据，结合参数高效技术（DoRA和rsLoRA）；2）强化学习，使用GRPO和多组件奖励系统优化准确性、格式和推理质量。

研究结果: Gazal-R1在MedQA、MMLU Pro（医学）和PubMedQA上分别取得87.1%、81.6%和79.6%的成绩，超越更大模型。

研究结论: 研究为开发高性能、高效且可解释的领域专用语言模型提供了可复现框架，并揭示了专业领域模型训练的挑战。

中文摘要: 我们提出了Gazal-R1，一个320亿参数的语言模型，在医学推理任务中达到顶尖性能，同时为临床决策提供透明的逐步解释。基于Qwen3 32B，我们的模型表明策略性训练可以使中等规模模型在专业领域超越更大模型。我们开发了一种新颖的两阶段训练流程：首先，对10.7万条合成医学推理数据进行监督微调，结合参数高效技术（如DoRA和rsLoRA）；其次，使用GRPO和多组件奖励系统进行强化学习，优化准确性、格式和推理质量。Gazal-R1在医学基准测试中表现卓越，MedQA、MMLU Pro（医学）和PubMedQA得分分别为87.1%、81.6%和79.6%，超越更大模型。此外，本研究深入探讨了专业领域模型训练的挑战，如奖励黑客、训练不稳定等，并提供了平衡性能、效率和可解释性的可复现框架。

</details>


### [40] [Thunder-LLM: Efficiently Adapting LLMs to Korean with Minimal Resources](https://arxiv.org/abs/2506.21595)
**中文标题：Thunder-LLM：以最小资源高效适配LLM至韩语**

*Jinpyo Kim,Gyeongje Cho,Chanwoo Park,Jongwon Park,Jongmin Kim,Yeonkyoun So,Jaejin Lee*

主要分类: cs.CL

摘要简述: 本文提出了一种低成本方法，将基于英语的大语言模型（LLM）适配到韩语，通过数据收集、预处理、模型训练和评估，证明了其高效性和低成本优势。


<details>
  <summary>详细信息</summary>
研究动机: 当前最先进的LLM在英语和中文以外的语言中表现不佳，且其端到端训练过程因专有原因、技术复杂性、文档不一致和伦理问题而鲜为人知。本文旨在解决这些问题，提供一种低成本适配新语言的方法。

研究方法: 方法包括收集韩语数据集、数据预处理、模型训练、创建下游基准测试和评估。通过这一端到端流程，实现了对现有LLM的高效适配。

研究结果: 评估结果表明，该方法能以低成本有效为LLM增加新语言能力。新模型Thunder-LLM和Thunder-LLM-Ins在韩语任务中表现优于现有最先进模型，且仅需极少数据和计算资源。

研究结论: 本文提供了一种低成本、高效的LLM语言适配方法，并公开了代码和完整经验，为LLM在多语言场景中的应用提供了实用解决方案。

中文摘要: 由于最先进的大语言模型（LLM）在英语或中文以外的语言中表现不佳，提升LLM在新语言中的能力已成为一项重要任务。此外，由于专有原因、技术复杂性、文档不一致和伦理问题，LLM的端到端训练过程对公众而言仍是一个谜。本文提出了一种在低预算场景下将基于英语的LLM适配到韩语的方法。我们描述了完整的端到端流程：收集韩语数据集、数据预处理、模型训练、创建下游基准测试和评估。评估结果表明，我们的方法能以低成本有效为LLM增加新语言能力。我们的新双语模型Thunder-LLM和Thunder-LLM-Ins在韩语任务中表现优于现有最先进模型，且仅需极少数据和计算资源。我们分享了完整的经验，并公开了代码。

</details>


### [41] [Evaluating Multimodal Large Language Models on Educational Textbook Question Answering](https://arxiv.org/abs/2506.21596)
**中文标题：评估多模态大语言模型在教育教科书问答任务中的表现**

*Hessa A. Alawwad,Anas Zafar,Areej Alhothali,Usman Naseem,Ali Alkhathlan,Amani Jamal*

主要分类: cs.CL

摘要简述: 本文首次评估了多模态大语言模型（MLLMs）在教育教科书问答任务中的表现，使用CK12-QA数据集测试其处理复杂课程和图表的能力，并引入轻量级多模态检索增强生成（RAG）方法提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型在视觉-语言任务中表现优异，但其处理复杂课程和无法用单一图像表示的图表的能力尚未充分验证，因此本文旨在填补这一研究空白。

研究方法: 使用CK12-QA数据集评估LLaVA和LLaMA 3.2-Vision等模型，并设计轻量级多模态RAG流程，将课程段落和图表整合到提示中以提升模型性能。

研究结果: 实验表明，检索的教育上下文显著影响模型准确性和推理能力，但也暴露出模型在处理问题-上下文关系和噪声方面的局限性。

研究结论: 研究揭示了多模态AI驱动学习的关键方向，未来需进一步优化模型对复杂教育内容的理解能力。

中文摘要: 多模态大语言模型（MLLMs）最近在视觉-语言任务中取得了显著成功，但其对复杂、长篇课程和无法用单一自然图像表示的精细教育图表的推理能力尚未得到充分测试。本文首次使用CK12-QA数据集对先进MLLMs在教科书问答（TQA）任务中的表现进行评估。我们测试了包括LLaVA和LLaMA 3.2-Vision在内的最新视觉-语言模型在不同输入配置下的性能。此外，我们引入了一种轻量级多模态检索增强生成（RAG）流程，将课程中的段落和图表整合到提示中。结果显示，检索的教育上下文对模型准确性和推理能力有显著影响，同时也揭示了当前模型在处理问题-上下文关系和噪声方面的局限性，为未来多模态AI驱动学习的研究指明了关键方向。

</details>


### [42] [Overview of the ClinIQLink 2025 Shared Task on Medical Question-Answering](https://arxiv.org/abs/2506.21597)
**中文标题：ClinIQLink 2025医学问答共享任务概述**

*Brandon Colelough,Davis Bartels,Dina Demner-Fushman*

主要分类: cs.CL

摘要简述: 本文介绍了ClinIQLink 2025共享任务，旨在通过医学问答测试大型语言模型的能力，任务包含4978个专家验证的医学问答对，涵盖七种格式，并通过自动化评分和医生评审进行评估。


<details>
  <summary>详细信息</summary>
研究动机: 该论文的动机是通过共享任务测试大型语言模型在医学问答中的表现，尤其是针对全科医生水平的医学问题，以评估其实际应用潜力。

研究方法: 任务提供了4978个专家验证的医学问答对，涵盖七种格式（如判断题、选择题等）。参与系统通过Docker或Apptainer镜像在CodaBench平台或Zaratan集群上运行。自动化评分（任务1）对封闭式问题使用精确匹配，开放式问题使用三层嵌入度量。后续由医生小组（任务2）对高分模型响应进行审核。

研究结果: 任务通过自动化评分和医生评审相结合的方式，全面评估了大型语言模型在医学问答中的表现，为模型的实际应用提供了参考。

研究结论: ClinIQLink 2025共享任务为测试和提升大型语言模型在医学领域的应用能力提供了重要平台，展示了其在复杂医学问答中的潜力。

中文摘要: 本文介绍了ClinIQLink共享任务，该任务与ACL 2025的第24届BioNLP研讨会联合举办，旨在通过医学问答测试大型语言模型（LLMs）的能力，目标水平为全科医生。任务提供了4978个专家验证的医学问答对，涵盖七种格式：判断题、选择题、无序列表、简答题、短逆向题、多跳题和多跳逆向题。参与系统以Docker或Apptainer镜像形式在CodaBench平台或马里兰大学的Zaratan集群上运行。自动化评分（任务1）对封闭式问题使用精确匹配，开放式问题使用三层嵌入度量。后续由医生小组（任务2）对高分模型响应进行审核。

</details>


### [43] [Structured Attention Matters to Multimodal LLMs in Document Understanding](https://arxiv.org/abs/2506.21600)
**中文标题：结构化注意力对多模态大语言模型在文档理解中的重要性**

*Chang Liu,Hongkai Chen,Yujun Cai,Hang Wu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang*

主要分类: cs.CL

摘要简述: 研究发现，原始OCR文本会分散多模态大语言模型（MLLMs）的注意力，降低文档理解性能。通过保留文档结构的LaTex编码方法，显著提升了MLLMs的问答表现。


<details>
  <summary>详细信息</summary>
研究动机: 文档理解是多模态大语言模型（MLLMs）的重要挑战。以往研究多关注通过多模态查询定位证据页面，而忽略了输入格式对性能的影响。本文旨在探索输入格式如何影响MLLMs的文档理解能力。

研究方法: 提出一种基于LaTex范式的结构保留方法，编码文档元素以维持其层次组织和空间关系。通过注意力分析验证结构化文本能引导模型关注语义相关区域，减少注意力浪费。

研究结果: 实验表明，结构化文本显著提升了MLLMs在多种文档类型上的问答性能，且无需修改模型架构或额外训练。

研究结论: 保留文档结构的输入格式对MLLMs的文档理解至关重要，结构化文本能有效引导注意力，提升模型性能。

中文摘要: 文档理解仍是多模态大语言模型（MLLMs）面临的重大挑战。以往研究主要关注通过精确的多模态查询定位证据页面，而本文探讨了一个基础但被忽视的问题：输入格式如何影响文档理解性能。通过系统分析，我们发现原始OCR文本不仅未能提升MLLMs的性能，反而可能损害其表现，这一反直觉现象归因于注意力分散和结构缺失。为验证这一假设，我们提出了一种基于LaTex范式的结构保留方法，编码文档元素以维持其层次组织和空间关系。注意力分析表明，结构化文本能在文本和视觉内容上诱导结构化注意力模式，引导模型聚焦语义相关区域，减少注意力浪费。该方法显著提升了MLLMs在多种文档类型上的问答性能，且无需修改模型架构或额外训练。

</details>


### [44] [BiMark: Unbiased Multilayer Watermarking for Large Language Models](https://arxiv.org/abs/2506.21602)
**中文标题：BiMark：面向大语言模型的无偏多层水印技术**

*Xiaoyan Feng,He Zhang,Yanjun Zhang,Leo Yu Zhang,Shirui Pan*

主要分类: cs.CL

摘要简述: BiMark是一种新型水印框架，通过多层架构和无偏重加权机制，解决了大语言模型生成文本的认证问题，同时保持文本质量和多比特水印能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）的快速发展，其生成文本的真实性引发关注，亟需可靠的识别机制。现有水印方法难以同时满足文本质量保持、模型无关检测和多比特水印嵌入的需求。

研究方法: BiMark提出三项创新：1）无偏重加权机制实现模型无关检测；2）多层架构提升可检测性而不影响生成质量；3）信息编码方法支持多比特水印。

研究结果: 实验表明，BiMark在短文本中的提取率比现有方法高30%，同时文本质量（困惑度更低）和下游任务（如摘要和翻译）表现与非水印文本相当。

研究结论: BiMark通过平衡文本质量与水印能力，为LLM生成文本的认证提供了高效解决方案。

中文摘要: 近年来，大语言模型（LLMs）的快速发展引发了对其生成文本真实性的迫切关注，促使监管机构要求可靠的识别机制。尽管水印技术提供了一种有前景的解决方案，但现有方法难以同时满足三个关键需求：文本质量保持、模型无关检测和多比特水印嵌入能力，这些对实际应用至关重要。实现这些目标的关键挑战在于平衡文本质量保持与水印嵌入能力之间的权衡。为解决这一问题，我们提出了BiMark，一种新型水印框架，通过三项关键创新实现这些需求：（1）无偏比特翻转重加权机制，实现模型无关检测；（2）多层架构，在不影响生成质量的情况下提升可检测性；（3）信息编码方法，支持多比特水印。通过理论分析和大量实验，我们验证了与现有最先进的多比特水印方法相比，BiMark在短文本中的提取率提高了30%，同时通过更低的困惑度保持了文本质量，并在摘要和翻译等下游任务中表现与非水印文本相当。

</details>


### [45] [Operationalizing Automated Essay Scoring: A Human-Aware Approach](https://arxiv.org/abs/2506.21603)
**中文标题：自动化作文评分的实践：一种人性化的方法**

*Yenisel Plasencia-Calaña*

主要分类: cs.CL

摘要简述: 本文探讨了自动化作文评分（AES）系统的人性化操作，比较了基于机器学习和大型语言模型（LLM）的方法，发现ML模型在准确性上优于LLM，但解释性较差；LLM提供更丰富的解释，但两者在偏见和边缘分数鲁棒性上均存在挑战。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在超越准确性，关注AES系统的人性化操作，包括偏见、鲁棒性和可解释性等关键维度，以提升系统的可靠性和可信度。

研究方法: 比较了基于机器学习和大型语言模型（LLM）的AES方法，分析其在准确性、偏见、鲁棒性和可解释性等方面的表现。

研究结果: ML模型在准确性上优于LLM，但可解释性较差；LLM提供更丰富的解释，但两者在偏见和边缘分数鲁棒性上均表现不佳。

研究结论: 研究揭示了不同AES方法之间的权衡与挑战，为开发更可靠和人性化的AES系统提供了重要参考。

中文摘要: 本文探讨了自动化作文评分（AES）系统的人性化操作，关注了超越准确性的多个方面。我们比较了基于机器学习和大型语言模型（LLM）的方法，识别了它们的优势、相似点和差异。研究调查了偏见、鲁棒性和可解释性等关键维度，这些对AES系统的人性化操作至关重要。研究发现，基于ML的AES模型在准确性上优于LLM，但在可解释性上表现较差，而LLM提供了更丰富的解释。此外，两种方法在偏见和边缘分数鲁棒性上均存在挑战。通过分析这些维度，本文旨在识别不同方法之间的挑战与权衡，为开发更可靠和可信的AES方法做出贡献。

</details>


### [46] [MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents](https://arxiv.org/abs/2506.21605)
**中文标题：MemBench：面向基于LLM的智能体记忆能力的更全面评估**

*Haoran Tan,Zeyu Zhang,Chen Ma,Xu Chen,Quanyu Dai,Zhenhua Dong*

主要分类: cs.CL

摘要简述: 本文提出了MemBench，一个更全面的数据集和基准测试，用于评估基于LLM的智能体的记忆能力，涵盖事实记忆和反思记忆两个层次，以及参与和观察两种交互场景。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究虽然强调了记忆机制在基于LLM的智能体中的重要性，但对其记忆能力的评估仍存在多样性不足和指标不全面的问题。本文旨在解决这些局限性。

研究方法: 构建了一个包含事实记忆和反思记忆的数据集，并提出参与和观察两种交互场景。基于此数据集，开发了MemBench基准测试，从有效性、效率和容量等多方面评估记忆能力。

研究结果: MemBench提供了一个全面的评估框架，能够从多个维度衡量基于LLM的智能体的记忆能力，并公开了数据集和项目代码。

研究结论: MemBench填补了现有评估的不足，为研究社区提供了一个更全面的记忆能力评估工具，推动了相关领域的发展。

中文摘要: 近期研究强调了记忆机制在基于LLM的智能体中的重要性，使其能够存储观察到的信息并适应动态环境。然而，对其记忆能力的评估仍面临挑战。现有评估通常受限于记忆层次和交互场景的多样性，且缺乏全面的指标来从多角度反映记忆能力。为解决这些问题，本文构建了一个更全面的数据集和基准测试，用于评估基于LLM的智能体的记忆能力。我们的数据集包含事实记忆和反思记忆两个层次，并提出参与和观察两种交互场景。基于此数据集，我们提出了名为MemBench的基准测试，从有效性、效率和容量等多方面评估记忆能力。为促进研究社区的发展，我们在https://github.com/import-myself/Membench上公开了数据集和项目。

</details>


### [47] [Large Language Models as symbolic DNA of cultural dynamics](https://arxiv.org/abs/2506.21606)
**中文标题：大型语言模型作为文化动态的符号DNA**

*Parham Pourdavood,Michael Jacob,Terrence Deacon*

主要分类: cs.CL

摘要简述: 本文提出将大型语言模型（LLMs）类比为人类文化动态的‘符号DNA’，认为其作为外部化信息载体，保存了人类符号表达的压缩模式，需通过人类重新解释才能获得意义。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于重新定义LLMs的角色，超越将其视为自主智能或简单模仿工具的观点，探讨其作为文化动态存储媒介的潜力。

研究方法: 通过分析压缩、解压缩、外部化和递归四个普遍特征，将LLMs与DNA的功能类比，论证其保存文化规律的方式。

研究结果: 研究表明，LLMs的核心价值在于为人类提供自我反思和假设生成的工具，而非替代人类智能。

研究结论: 结论认为LLMs是文化可进化性的工具，支持人类在模拟环境中探索新假设，同时依赖人类解释以保持其文化相关性。

中文摘要: 本文提出了一种新颖的概念，将大型语言模型（LLMs）视为外部化信息载体，其功能类似于人类文化动态的DNA。不同于将LLMs视为自主智能或简单模仿工具，我们认为它们作为存储人类符号表达压缩模式的‘化石’，保留了有意义动态的关系痕迹，但缺乏原始生活背景。这些压缩模式只有通过人类重新解释才能获得意义，形成递归反馈循环，最终催化人类创造性过程。通过分析压缩、解压缩、外部化和递归四个普遍特征，我们证明LLMs与DNA类似，是一种压缩且外部化的媒介，用于保存有用的文化规律，而无需理解具体的人类体验。因此，我们认为LLMs的意义不在于与人类智能竞争，而是为人类提供了一种在低风险模拟环境中进行自我反思和假设生成的工具。这一框架将LLMs定位为文化可进化性的工具，使人类能够生成关于自身的新假设，同时依赖人类解释将这些假设根植于持续发展的美学和规范中。

</details>


### [48] [CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks](https://arxiv.org/abs/2506.21607)
**中文标题：CORE-KG：一种基于大语言模型的人类走私网络知识图谱构建框架**

*Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera*

主要分类: cs.CL

摘要简述: CORE-KG是一个基于大语言模型的知识图谱构建框架，专为分析复杂的人类走私网络设计，通过类型感知的共指消解和领域引导的实体关系提取，显著减少节点重复和噪声。


<details>
  <summary>详细信息</summary>
研究动机: 人类走私网络日益复杂且难以分析，法律案件文档虽提供有价值的信息，但其非结构化、词汇密集和指代模糊的特点为自动化知识图谱构建带来挑战。现有方法依赖静态模板且缺乏共指消解，而基于大语言模型的方法常因幻觉和缺乏引导提取导致图谱噪声大且碎片化。

研究方法: CORE-KG采用两步流程：1) 通过结构化的大语言模型提示进行类型感知的共指消解；2) 基于领域引导的指令提取实体和关系，构建在改进的GraphRAG框架上。

研究结果: 与基于GraphRAG的基线相比，CORE-KG减少了33.28%的节点重复和38.37%的法律噪声，生成更清晰、连贯的图谱结构。

研究结论: CORE-KG为分析复杂犯罪网络提供了更可靠的知识图谱基础，显著提升了图谱质量和可解释性。

中文摘要: 人类走私网络日益具有适应性和分析难度。法律案件文档虽提供宝贵见解，但其非结构化、词汇密集且充满模糊或变化指代的特点，为自动化知识图谱（KG）构建带来挑战。现有KG方法多依赖静态模板且缺乏共指消解，而近期基于大语言模型（LLM）的方法常因幻觉和缺乏引导提取导致图谱噪声大、碎片化及节点重复。我们提出CORE-KG，一种从法律文本构建可解释KG的模块化框架。其采用两步流程：1) 通过结构化LLM提示进行类型感知的共指消解；2) 基于领域引导指令的实体和关系提取，构建在改进的GraphRAG框架上。与基于GraphRAG的基线相比，CORE-KG减少了33.28%的节点重复和38.37%的法律噪声，生成更清晰、连贯的图谱结构。这些改进使CORE-KG成为分析复杂犯罪网络的坚实基础。

</details>


### [49] [SysTemp: A Multi-Agent System for Template-Based Generation of SysML v2](https://arxiv.org/abs/2506.21608)
**中文标题：SysTemp：基于模板的SysML v2多智能体生成系统**

*Yasmine Bouamra,Bruno Yun,Alexandre Poisson,Frédéric Armetta*

主要分类: cs.CL

摘要简述: SysTemp是一个多智能体系统，旨在通过模板化方法自动生成SysML v2模型，解决复杂系统建模中语料稀缺和语法复杂的问题。


<details>
  <summary>详细信息</summary>
研究动机: 复杂系统建模中，SysML v2模型的自动生成面临语料稀缺和语法复杂的挑战，SysTemp旨在通过多智能体系统简化这一过程。

研究方法: SysTemp采用多智能体系统，包括模板生成器，通过结构化流程从自然语言规范生成SysML v2模型。

研究结果: 评估表明，SysTemp能够提升SysML v2模型生成的质量，展示了其潜力。

研究结论: SysTemp为SysML v2模型的自动生成提供了高效解决方案，尽管仍存在挑战，但其潜力显著。

中文摘要: SysML v2模型的自动生成是复杂系统工程中的一大挑战，主要由于学习语料的稀缺和复杂的语法。本文提出SysTemp系统，旨在通过多智能体系统（包括模板生成器）从自然语言规范中简化和改进SysML v2模型的生成。通过评估，我们讨论了该系统的优势与挑战，并强调了其在提升SysML v2建模生成质量方面的潜力。

</details>


### [50] [From Thinking to Output: Chain-of-Thought and Text Generation Characteristics in Reasoning Language Models](https://arxiv.org/abs/2506.21609)
**中文标题：从思考到输出：推理语言模型中的思维链与文本生成特性**

*Junhao Liu,Zhenhao Xu,Yuxin Fang,Yichuan Chen,Zuobin Ying,Wenhan Chang*

主要分类: cs.CL

摘要简述: 本文提出了一种新框架，用于分析四种前沿大语言模型（GPT-o1、DeepSeek-R1、Kimi-k1.5和Grok-3）的推理特性，通过关键词统计和LLM-as-a-judge范式，揭示了它们在推理过程中的探索与利用、问题处理及结论达成模式。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究大多忽视了对大语言模型推理过程与输出的系统性比较，尤其是在自我反思模式（“顿悟时刻”）及跨领域关联方面。本文旨在填补这一空白，深入分析模型的内部思考过程与最终输出之间的联系。

研究方法: 研究采用关键词统计和LLM-as-a-judge范式，构建了一个涵盖逻辑推理、因果推断和多步问题解决的多样化数据集，并提出了一套评估推理连贯性和输出准确性的指标。

研究结果: 研究揭示了这些模型在推理过程中如何平衡探索与利用、处理问题及达成结论的多样化模式，并定量和定性地比较了它们在推理深度、中间步骤依赖以及与GPT-o1的相似性方面的差异。

研究结论: 本研究为计算效率与推理鲁棒性之间的权衡提供了宝贵见解，并为实际应用中的模型设计与评估提出了实用建议。

中文摘要: 近年来，大语言模型（LLMs）取得了显著进展，显示出其在复杂推理方面的能力不断增强。然而，现有研究大多忽视了对这些模型的推理过程与输出的全面系统性比较，尤其是在自我反思模式（“顿悟时刻”）及跨领域关联方面。本文提出了一种新框架，通过关键词统计和LLM-as-a-judge范式，分析了四种前沿大推理模型（GPT-o1、DeepSeek-R1、Kimi-k1.5和Grok-3）的推理特性，将它们的内部思考过程与最终输出联系起来。研究使用了一个涵盖逻辑推理、因果推断和多步问题解决的多样化数据集，并提出了一套评估推理连贯性和输出准确性的指标。研究结果揭示了这些模型在推理过程中如何平衡探索与利用、处理问题及达成结论的多样化模式。通过定量和定性比较，发现了这些模型在推理深度、中间步骤依赖以及与GPT-o1的相似性方面的差异。这项工作为计算效率与推理鲁棒性之间的权衡提供了宝贵见解，并为实际应用中的模型设计与评估提出了实用建议。项目已公开：https://github.com/ChangWenhan/FromThinking2Output

</details>


### [51] [Does Multimodality Lead to Better Time Series Forecasting?](https://arxiv.org/abs/2506.21611)
**中文标题：多模态是否能提升时间序列预测性能？**

*Xiyuan Zhang,Boran Han,Haoyang Fang,Abdul Fatir Ansari,Shuai Zhang,Danielle C. Maddix,Cuixiong Hu,Andrew Gordon Wilson,Michael W. Mahoney,Hao Wang,Yan Liu,Huzefa Rangwala,George Karypis,Bernie Wang*

主要分类: cs.CL

摘要简述: 本文系统研究了多模态（文本与时序数据结合）在时间序列预测中的效果，发现其增益并非普遍存在，并提出了模型架构和数据特性对效果的影响条件。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，将文本信息融入基础模型以提升时间序列预测性能的研究逐渐增多，但多模态整合是否以及在何种条件下能带来一致性的增益尚不明确。本文旨在通过系统性实验回答这些问题。

研究方法: 研究通过14个跨7个领域的预测任务（如健康、环境、经济学）评估两种多模态预测范式：基于对齐的方法（对齐时序与文本表示）和基于提示的方法（直接提示大语言模型进行预测）。同时，分析了模型架构特性和数据特征对效果的影响。

研究结果: 研究发现，多模态输入的效果并非普遍优于单模态基线，其增益依赖于以下条件：模型方面需具备（1）高容量文本模型、（2）相对较弱的时序模型、（3）合适的对齐策略；数据方面需满足（4）充足的训练数据和（5）文本提供与时序数据互补的预测信号。

研究结论: 多模态在时间序列预测中的效果具有条件性，本文提出的实践指南有助于判断何时使用多模态能带来增益，何时则无效。

中文摘要: 近年来，将文本信息融入基础模型以提升时间序列预测性能的研究逐渐增多，但多模态整合是否以及在何种条件下能带来一致性的增益尚不明确。我们通过涵盖7个领域（如健康、环境、经济学）的14个预测任务，系统研究了这些问题。我们评估了两种多模态预测范式：基于对齐的方法（对齐时序与文本表示）和基于提示的方法（直接提示大语言模型进行预测）。尽管先前研究报道了多模态输入的增益，但我们发现这些效果并非在所有数据集和模型中普遍存在，且多模态方法有时无法超越最强的单模态基线。为理解文本信息何时有效，我们分离了模型架构特性和数据特征的影响。研究发现，在模型方面，整合文本信息最有效的情况包括（1）高容量文本模型、（2）相对较弱的时序模型、（3）合适的对齐策略；在数据方面，性能增益更可能出现在（4）训练数据充足和（5）文本提供与时序数据互补的预测信号时。我们的实证结果为多模态在预测任务中的适用性提供了实践指南。

</details>


### [52] [AdaptGOT: A Pre-trained Model for Adaptive Contextual POI Representation Learning](https://arxiv.org/abs/2506.21612)
**中文标题：AdaptGOT：一种用于自适应上下文POI表示学习的预训练模型**

*Xiaobin Ren,Xinyu Zhu,Kaiqi Zhao*

主要分类: cs.CL

摘要简述: 本文提出了AdaptGOT模型，通过结合自适应表示学习技术和地理-共现-文本（GOT）表示，解决了POI嵌入方法中的多上下文采样不足、泛化能力差等问题。实验证明其性能优越。


<details>
  <summary>详细信息</summary>
研究动机: 当前POI嵌入方法在推荐和分类等任务中取得进展，但仍面临多上下文采样策略不足、泛化能力有限等问题。本文旨在通过自适应学习和多上下文整合提升POI表示的质量和通用性。

研究方法: AdaptGOT模型包含三个关键部分：(1) 上下文邻域生成，采用KNN、密度、重要性和类别感知等混合采样技术；(2) 基于注意力的GOT表示，捕捉POI间复杂关系；(3) MoE自适应编码器-解码器架构，确保拓扑一致性并丰富上下文表示。

研究结果: 在两个真实数据集和多个POI任务上的实验表明，AdaptGOT模型在性能上显著优于现有方法。

研究结论: AdaptGOT模型通过自适应学习和多上下文整合，有效提升了POI表示的质量和泛化能力，为POI相关任务提供了更优的解决方案。

中文摘要: 目前，随着推荐和分类等新型POI任务的出现，POI嵌入方法取得了显著进展。尽管任务特定的端到端模型在POI嵌入中取得了成功，但仍存在多上下文采样策略不足、POI上下文探索不充分、通用性有限和泛化能力不足等挑战。为解决这些问题，我们提出了AdaptGOT模型，该模型结合了自适应表示学习技术和地理-共现-文本（GOT）表示，特别关注地理位置、共现和文本信息。AdaptGOT模型包含三个关键组件：(1) 上下文邻域生成，整合了KNN、基于密度、基于重要性和类别感知等先进混合采样技术，以捕捉复杂的上下文邻域；(2) 基于注意力的高级GOT表示，旨在生成高质量、定制化的表示，并高效捕捉POI间的复杂相互关系；(3) 基于MoE的自适应编码器-解码器架构，通过最小化不同上下文间的Jensen-Shannon散度，确保拓扑一致性并丰富上下文表示。在两个真实数据集和多个POI任务上的实验验证了AdaptGOT模型的优越性能。

</details>


### [53] [ChildGuard: A Specialized Dataset for Combatting Child-Targeted Hate Speech](https://arxiv.org/abs/2506.21613)
**中文标题：ChildGuard：用于对抗针对儿童的仇恨言论的专用数据集**

*Gautam Siddharth Kashyap,Mohammad Anas Azeez,Rafiq Ali,Zohaib Hasan Siddiqui,Jiechao Gao,Usman Naseem*

主要分类: cs.CL

摘要简述: 本文介绍了ChildGuard数据集，专门用于检测针对儿童的仇恨言论，填补了现有数据集的不足，并评估了现有检测方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 针对儿童的仇恨言论日益增多，但现有数据集缺乏年龄特异性标注和情感影响的考量，亟需专门的数据集来解决这一问题。

研究方法: 通过从现有语料库中提取并添加儿童特异性标注，构建了ChildGuard数据集，并利用现有先进仇恨言论检测方法（包括大语言模型）进行基准测试。

研究结果: ChildGuard数据集成功捕捉了针对儿童的仇恨言论的多样语境，并展示了现有方法在此类检测中的局限性。

研究结论: ChildGuard为改进针对儿童仇恨言论的检测方法提供了坚实基础，并公开数据集以促进进一步研究。

中文摘要: 网络上针对儿童的仇恨言论日益增多，凸显了解决这一问题的紧迫性。现有仇恨言论数据集缺乏年龄特异性标注，未能捕捉到细微语境，且忽视了其对儿童的独特情感影响。为填补这一空白，我们推出了ChildGuard，一个从现有语料库中提取并添加儿童特异性标注的精选数据集。ChildGuard涵盖了针对儿童的仇恨言论的多样语境，跨越不同年龄段。我们对现有最先进的仇恨言论检测方法（包括大语言模型）进行了基准测试，评估其在检测和语境化针对儿童的仇恨言论方面的有效性。为促进该领域的进一步研究，我们公开了ChildGuard数据集，为开发改进的检测和缓解此类危害的方法提供了坚实基础。

</details>


### [54] [LastingBench: Defend Benchmarks Against Knowledge Leakage](https://arxiv.org/abs/2506.21614)
**中文标题：LastingBench：防御基准测试中的知识泄漏**

*Yixiong Fang,Tianran Sun,Yuling Shi,Min Wang,Xiaodong Gu*

主要分类: cs.CL

摘要简述: 本文提出LastingBench框架，旨在通过扰动和改写泄漏点，防止大型语言模型（LLM）在问答基准测试中通过记忆任务数据作弊，从而保持基准测试的长期有效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的复杂性增加，其在问答基准测试中可能通过记忆任务数据作弊，导致评估结果失真。现有研究多关注检测数据泄漏，但缺乏减少其影响并保持基准长期效用的方法。本文旨在解决这一问题。

研究方法: LastingBench通过扰动识别上下文中的泄漏点，并将其改写为反事实内容，从而破坏模型的记忆能力，同时保留基准的原始评估意图。

研究结果: 对前沿问答基准的评估显示，LastingBench显著减少了记忆效应，揭示了性能差距，证明了其有效性。

研究结论: LastingBench提供了一种实用且可扩展的解决方案，确保基准测试的长期鲁棒性，促进对LLM更公平和可解释的评估。

中文摘要: 大型语言模型（LLM）日益复杂，引发了对其通过记忆任务数据在标准问答（QA）基准测试中“作弊”能力的担忧。这削弱了基准评估的有效性，因为它们不再反映模型的真实能力，而是数据泄漏的影响。虽然先前的研究集中于检测此类泄漏，但很少关注如何减轻其影响并保持基准的长期效用。本文提出LastingBench，一种新颖的框架，旨在持续强化和保护现有基准免受知识泄漏的影响。LastingBench通过扰动识别上下文中的泄漏点，然后将其改写为反事实内容，破坏记忆效应，同时保留基准的原始评估意图。对前沿问答基准的评估显示显著性能差距，凸显了LastingBench在减少记忆效应方面的有效性。LastingBench提供了一种实用且可扩展的解决方案，确保基准的长期鲁棒性，促进对LLM更公平和可解释的评估。

</details>


### [55] [Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines](https://arxiv.org/abs/2506.21615)
**中文标题：利用生成增强检索和临床实践指南优化医学诊断**

*Wenhao Li,Hongkuan Zhang,Hongwei Zhang,Zhengxu Li,Zengjie Dong,Yafan Chen,Niranjan Bidargaddi,Hong Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为GARMLE-G的生成增强检索框架，用于将医学语言模型的输出与权威临床实践指南（CPGs）结合，以生成无幻觉且临床相关的诊断建议。该方法在高血压诊断原型系统中表现出优于传统检索增强生成方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的医学语言模型通常基于电子健康记录（EHRs）预测ICD编码的诊断，但这些编码无法捕捉临床医生基于丰富上下文和临床实践指南（CPGs）的复杂推理过程。这种不匹配限制了模型的临床实用性。

研究方法: GARMLE-G框架通过以下步骤实现：(1) 结合LLM预测与EHR数据生成语义丰富的查询，(2) 通过嵌入相似性检索相关CPG知识片段，(3) 将指南内容与模型输出融合，生成临床对齐的建议。

研究结果: 在高血压诊断的原型系统中，GARMLE-G在检索精度、语义相关性和临床指南依从性方面优于传统检索增强生成方法，同时保持了轻量级架构，适合本地化医疗部署。

研究结论: GARMLE-G提供了一种可扩展、低成本且无幻觉的方法，将医学语言模型与循证临床实践结合，具有广泛的临床应用潜力。

中文摘要: 当前的医学语言模型通常基于电子健康记录（EHRs）预测ICD编码的诊断，因为这些标签易于获取。然而，ICD编码无法捕捉临床医生用于诊断的丰富上下文和复杂推理。临床医生通过综合多样化的患者数据并参考临床实践指南（CPGs）做出循证决策。这种不匹配限制了现有模型的临床实用性。我们提出了GARMLE-G，一种生成增强检索框架，将医学语言模型的输出与权威CPGs结合。与传统的检索增强生成方法不同，GARMLE-G通过直接检索权威指南内容而非依赖模型生成的文本来实现无幻觉输出。其步骤包括：(1) 结合LLM预测与EHR数据生成语义丰富的查询，(2) 通过嵌入相似性检索相关CPG知识片段，(3) 将指南内容与模型输出融合以生成临床对齐的建议。我们开发了一个高血压诊断的原型系统，并在多个指标上进行了评估，结果显示其在检索精度、语义相关性和临床指南依从性方面优于基于RAG的基线方法，同时保持了适合本地化医疗部署的轻量级架构。这项工作提供了一种可扩展、低成本且无幻觉的方法，将医学语言模型与循证临床实践结合，具有广泛的临床应用潜力。

</details>


### [56] [TIM: A Large-Scale Dataset and large Timeline Intelligence Model for Open-domain Timeline Summarization](https://arxiv.org/abs/2506.21616)
**中文标题：TIM：一个用于开放领域时间线摘要的大规模数据集及时间线智能模型**

*Chuanrui Hu,Wei Hu,Penghang Yu,Hua Zhang,Bing-Kun Bao*

主要分类: cs.CL

摘要简述: 本文提出了首个大规模时间线智能模型（TIM）和数据集，用于开放领域时间线摘要任务，通过渐进优化策略和双对齐奖励学习，显著提升了时间线摘要的质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型语言模型（LLMs）在开放领域时间线摘要任务中难以准确评估主题相关性和理解主题演变，导致摘要中包含无关信息或时间戳不准确。为解决这一问题，本文提出了TIM模型和数据集。

研究方法: 首先构建了一个包含1000多个新闻主题和3000多个标注实例的大规模数据集。随后提出渐进优化策略，通过指令调优提升摘要能力和过滤无关信息的能力，并采用双对齐奖励学习方法，结合语义和时间视角，优化对主题演变的理解。

研究结果: 实验表明，TIM在开放领域时间线摘要任务中表现出色，能够有效生成高质量的时间线摘要。

研究结论: TIM模型通过渐进优化策略和双对齐奖励学习，显著提升了开放领域时间线摘要的准确性和相关性，为相关任务提供了新的解决方案。

中文摘要: 开放领域时间线摘要（TLS）对于监测新闻主题的演变至关重要。现有方法通常使用通用大型语言模型（LLMs）从检索到的新闻中总结相关时间戳。尽管通用LLMs在零样本新闻摘要和时间戳定位方面表现出能力，但在评估主题相关性和理解主题演变方面存在困难，导致摘要中常包含无关信息或不准确的时间戳。为解决这些问题，我们提出了首个用于开放领域TLS的大规模时间线智能模型（TIM）。具体而言，我们首先提出了一个包含1000多个新闻主题和3000多个标注实例的大规模TLS数据集。此外，我们提出了一种渐进优化策略，逐步提升摘要性能。该策略通过指令调优增强摘要能力和过滤无关信息的能力，随后采用一种新颖的双对齐奖励学习方法，结合语义和时间视角，从而提升对主题演变规律的理解。通过这一渐进优化策略，TIM展现出强大的开放领域时间线摘要能力。在开放领域的广泛实验中，TIM的有效性得到了验证。

</details>


### [57] [TrajTok: Technical Report for 2025 Waymo Open Sim Agents Challenge](https://arxiv.org/abs/2506.21618)
**中文标题：TrajTok：2025 Waymo Open Sim Agents挑战赛技术报告**

*Zhiyuan Zhang,Xiaosong Jia,Guanyu Chen,Qifeng Li,Junchi Yan*

主要分类: cs.CL

摘要简述: 本文介绍了TrajTok，一种用于基于离散下一令牌预测的行为生成模型的轨迹令牌化器，结合数据驱动和基于规则的方法，具有更好的覆盖性、对称性和鲁棒性，并提出了一种空间感知的标签平滑方法用于交叉熵损失。该方法在2025 Waymo Open Sim Agents Challenge中表现优异，真实感得分为0.7852。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决基于离散下一令牌预测的行为生成模型在覆盖性、对称性和鲁棒性方面的不足，本文提出了TrajTok轨迹令牌化器，并结合空间感知标签平滑方法，以提升模型性能。

研究方法: 本文提出TrajTok轨迹令牌化器，结合数据驱动和基于规则的方法，并引入空间感知标签平滑方法优化交叉熵损失。该方法应用于SMART模型，并在Waymo Open Sim Agents Challenge 2025中进行验证。

研究结果: 在Waymo Open Sim Agents Challenge 2025中，TrajTok与SMART模型结合实现了0.7852的真实感得分，表现优异。

研究结论: TrajTok轨迹令牌化器及其空间感知标签平滑方法显著提升了行为生成模型的性能，未来将开源代码。

中文摘要: 在本技术报告中，我们介绍了TrajTok，一种用于基于离散下一令牌预测的行为生成模型的轨迹令牌化器，它结合了数据驱动和基于规则的方法，具有更好的覆盖性、对称性和鲁棒性，并提出了一种空间感知的标签平滑方法用于交叉熵损失。我们采用该令牌化器和损失函数应用于SMART模型，并在2025 Waymo Open Sim Agents挑战赛中取得了0.7852的真实感得分，表现优异。未来我们将开源代码。

</details>


### [58] [IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech](https://arxiv.org/abs/2506.21619)
**中文标题：IndexTTS2：情感表达与时长控制的自回归零样本文本到语音技术的突破**

*Siyi Zhou,Yiquan Zhou,Yi He,Xun Zhou,Jinchao Wang,Wei Deng,Jingchen Shu*

主要分类: cs.CL

摘要简述: IndexTTS2是一种突破性的自回归零样本文本到语音模型，实现了情感表达与时长控制的创新结合，支持精确时长调节和独立控制音色与情感。


<details>
  <summary>详细信息</summary>
研究动机: 现有自回归TTS模型在语音自然度上表现优异，但难以精确控制语音时长，且情感表达与音色耦合。IndexTTS2旨在解决这些问题，满足视频配音等对时长同步和情感独立控制的需求。

研究方法: IndexTTS2提出了一种自回归友好的语音时长控制方法，支持显式指定生成令牌数以精确控制时长，或自由生成保留输入提示的韵律特征。同时，通过解耦情感表达与音色，结合GPT潜在表征增强稳定性，并设计基于文本描述的软指令机制实现自然语言情感控制。

研究结果: 实验表明，IndexTTS2在零样本设置下，于词错误率、说话人相似度和情感保真度上均优于现有最先进模型。

研究结论: IndexTTS2通过创新方法实现了时长精确控制和情感独立表达，显著提升了零样本TTS的性能和灵活性。

中文摘要: 大规模文本到语音（TTS）模型通常分为自回归和非自回归系统。尽管自回归系统在语音自然度上具有优势，但其逐令牌生成机制难以精确控制合成语音的时长，这是视频配音等需要严格音画同步应用的关键限制。本文提出IndexTTS2，为自回归模型提供了一种新颖且友好的语音时长控制方法。该方法支持两种生成模式：一种允许显式指定生成令牌数以精确控制时长；另一种无需手动输入，模型可自由生成语音并保留输入提示的韵律特征。此外，IndexTTS2实现了情感表达与说话人身份的解耦，支持音色与情感的独立控制。在零样本设置下，模型能完美复现输入提示的情感特征。用户还可提供独立的情感提示（甚至来自不同说话人），使模型在重建目标音色的同时传达所需情感。为增强强情感表达时的清晰度，我们引入GPT潜在表征以提升语音稳定性。同时，为降低情感控制门槛，我们基于Qwen3微调设计了基于文本描述的软指令机制，通过自然语言输入有效引导生成具有目标情感倾向的语音。实验结果表明，IndexTTS2在词错误率、说话人相似度和情感保真度上均优于现有最先进的零样本TTS模型。

</details>


### [59] [How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit](https://arxiv.org/abs/2506.21620)
**中文标题：大型语言模型如何在在线对话中扮演人类角色：基于2016年美国政治的Reddit模拟研究**

*Daniele Cirulli,Giulio Cimini,Giovanni Palermo*

主要分类: cs.CL

摘要简述: 研究评估了GPT-4在模拟2016年美国总统选举期间Reddit用户对话中的表现，发现其能生成逼真的评论，但倾向于制造共识而非分歧，且人工与AI生成内容在语义空间中可区分。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在自然语言生成中的应用日益广泛，但其在政治敏感在线讨论中的表现和潜在影响尚不明确。本研究旨在探讨LLMs在模拟真实政治讨论中的能力及其潜在风险。

研究方法: 研究通过三项实验，让GPT-4模拟真实或虚构的党派用户生成评论，分析其政治倾向、情感和语言特征，并与真实用户评论及基准模型对比。

研究结果: GPT-4能生成支持或反对候选人的逼真评论，但更易制造共识；人工与AI生成内容在语义空间中可区分，但人工检查难以辨别。

研究结论: 研究表明LLMs可能潜在地渗透在线讨论并影响政治叙事，揭示了AI驱动话语操纵的广泛影响。

中文摘要: 大型语言模型（LLMs）近年来成为自然语言生成的强大工具，应用范围从内容创作到社会模拟。其模仿人类互动的能力既带来机遇，也引发担忧，尤其是在政治相关的在线讨论中。本研究评估了LLMs在真实世界分裂性场景（2016年美国总统选举期间的Reddit对话）中复制用户生成内容的表现。具体而言，我们进行了三项实验，要求GPT-4通过模拟真实或虚构的党派用户生成评论，并从政治立场、情感和语言特征方面分析生成的评论，与真实用户贡献对比并基于基准模型评估。我们发现，GPT-4能生成支持或反对社区候选人的逼真评论，但更倾向于制造共识而非分歧。此外，真实与人工评论在语义嵌入空间中可区分，但人工检查难以辨别。我们的研究结果为LLMs潜在地渗透在线讨论、影响政治辩论和塑造政治叙事提供了见解，揭示了AI驱动话语操纵的广泛影响。

</details>


### [60] [The Open Proof Corpus: A Large-Scale Study of LLM-Generated Mathematical Proofs](https://arxiv.org/abs/2506.21621)
**中文标题：开放证明语料库：大规模研究大语言模型生成的数学证明**

*Jasper Dekoninck,Ivo Petrov,Kristian Minchev,Mislav Balunovic,Martin Vechev,Miroslav Marinov,Maria Drencheva,Lyuba Konova,Milen Shumanov,Kaloyan Tsvetkov,Nikolay Drenchev,Lazar Todorov,Kalina Nikolova,Nikolay Georgiev,Vanesa Kalinkova,Margulan Ismoldayev*

主要分类: cs.CL

摘要简述: 本文介绍了Open Proof Corpus (OPC)，一个包含5000多条由先进大语言模型生成并经人工评估的数学证明数据集，旨在推动自动证明生成研究。通过OPC，作者探讨了自然语言与形式化证明生成的性能差距等问题，并展示了其在模型微调中的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在数学证明生成方面取得显著进展，但缺乏大规模、高质量的人工评估证明数据集阻碍了进一步研究。OPC的创建旨在填补这一空白，为训练改进和证明生成能力分析提供基础。

研究方法: 作者构建了OPC数据集，包含5000多条由先进大语言模型生成并经人工评估的证明，涵盖USAMO和IMO等竞赛题目。利用OPC，研究了自然语言与形式化证明生成的性能差距、最终答案准确性与完整证明有效性之间的差异，以及最佳选择对证明质量的影响。

研究结果: 通过OPC，作者发现自然语言与形式化证明生成存在显著性能差距，且最佳选择策略能显著提升证明质量。此外，基于OPC微调的8B参数模型在评估证明正确性任务中表现与Gemini-2.5-Pro相当。

研究结论: OPC为自动证明生成研究提供了重要资源，展示了其在模型训练和分析中的实用性，并为未来研究提供了方向。

中文摘要: 近几个月来，大语言模型（LLMs）在数学证明生成方面取得了显著进展，但由于缺乏大规模、高质量的人工评估证明数据集，进一步的发展受到阻碍。尽管创建这样的数据集成本高昂，但它对于推动训练改进和严格分析证明生成能力至关重要。本文提出了开放证明语料库（OPC），这是一个包含5000多条由先进LLMs生成并经人工评估的证明数据集。OPC专为广泛适用性和证明生成研究的下游使用而设计，是首个包含大量正确LLM生成解答的数据集，这些解答来自USAMO和IMO等著名数学竞赛。利用OPC，我们探讨了自动证明生成中的关键问题：（1）自然语言与形式化证明生成的性能差距，（2）最终答案准确性与完整证明有效性之间的差异，以及（3）最佳选择对证明质量的影响。最后，为展示OPC的实用性，我们在该数据集上微调了一个8B参数模型，得到的模型在评估证明正确性任务中表现与最佳模型Gemini-2.5-Pro相当。

</details>


### [61] [Adapting Foundation Speech Recognition Models to Impaired Speech: A Semantic Re-chaining Approach for Personalization of German Speech](https://arxiv.org/abs/2506.21622)
**中文标题：调整基础语音识别模型以适应障碍语音：一种德语语音个性化的语义重组方法**

*Niclas Pokel,Pehuén Moure,Roman Boehringer,Yingqiang Gao*

主要分类: cs.CL

摘要简述: 本文提出了一种轻量级方法，通过语义重组技术个性化调整基础语音识别模型，以改善对德语障碍语音的识别效果，实验表明该方法能显著提升转录质量。


<details>
  <summary>详细信息</summary>
研究动机: 由于脑瘫或遗传疾病等导致的语音障碍对自动语音识别（ASR）系统提出了巨大挑战。现有模型（如Whisper）因缺乏非标准语音的训练数据而表现不佳。本文旨在通过个性化调整模型，减少障碍语音使用者的沟通障碍。

研究方法: 提出了一种轻量级流程，通过语义重组技术选择词汇并增强小型障碍语音数据集的语义连贯性，从而个性化调整ASR模型。

研究结果: 在针对一名结构型语音障碍儿童的数据实验中，该方法显著提升了转录质量，展示了其在改善非标准语音识别中的潜力。

研究结论: 该方法为个性化调整ASR模型提供了实用方案，有望帮助语音障碍人群减少沟通障碍。

中文摘要: 由脑瘫或遗传疾病等引起的语音障碍对自动语音识别（ASR）系统构成了重大挑战。尽管近期有所进展，但像Whisper这样的ASR模型因缺乏非标准语音的训练数据及收集标注困难而表现不佳。本文提出了一种实用且轻量级的流程，通过语义重组技术选择词汇并增强小型障碍语音数据集的语义连贯性，以个性化调整ASR模型。在针对一名结构型语音障碍儿童的数据实验中，该方法显著提升了转录质量，展示了其在减少非标准语音使用者沟通障碍方面的潜力。

</details>


### [62] [Performance of diverse evaluation metrics in NLP-based assessment and text generation of consumer complaints](https://arxiv.org/abs/2506.21623)
**中文标题：NLP评估与消费者投诉文本生成中多样化评价指标的性能研究**

*Peiheng Gao,Chen Yang,Ning Sun,Ričardas Zitikis*

主要分类: cs.CL

摘要简述: 本研究通过结合人类经验训练的算法和合成数据生成方法，提升了机器学习在消费者投诉文本分类中的性能，减少了数据集获取成本，并优化了评估指标。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习在文本分类方面取得了显著进展，但在消费者投诉等复杂文本中准确捕捉细微语义差异仍具挑战性。本研究旨在通过结合专家训练和合成数据生成，解决这一问题。

研究方法: 研究采用人类经验训练的算法识别消费者投诉中的语义差异，并结合生成对抗网络（GAN）生成的合成数据，通过专家标注进一步优化。

研究结果: 该方法显著提升了机器学习分类器的性能，降低了数据集获取成本，并增强了文本分类任务的评估指标和鲁棒性。

研究结论: 结合专家训练和高质量合成数据的方法，为消费者投诉文本分类提供了更高效、经济的解决方案，并提升了分类准确性。

中文摘要: 机器学习（ML）在文本分类方面取得了显著进展，能够自动理解和分类复杂的非结构化文本数据。然而，准确捕捉自然语言中固有的细微语义模式和上下文变化（尤其是在消费者投诉中）仍具挑战性。本研究通过引入人类经验训练的算法，有效识别对消费者救济资格评估至关重要的语义差异，解决了这一问题。此外，我们提出结合合成数据生成方法，利用生成对抗网络的专家评估并通过专家标注进行优化。通过将专家训练的分类器与高质量合成数据相结合，本研究旨在显著提升机器学习分类器的性能，降低数据集获取成本，并改进文本分类任务的整体评估指标和鲁棒性。

</details>


### [63] [Doc2SAR: A Synergistic Framework for High-Fidelity Extraction of Structure-Activity Relationships from Scientific Documents](https://arxiv.org/abs/2506.21625)
**中文标题：Doc2SAR：一种协同框架用于从科学文档中高保真提取结构-活性关系**

*Jiaxi Zhuang,Kangning Li,Jue Hou,Mingjun Xu,Zhifeng Gao,Hengxing Cai*

主要分类: cs.CL

摘要简述: Doc2SAR是一种新型框架，结合领域专用工具与监督微调的MLLMs，显著提升科学文档中分子结构-活性关系（SARs）的提取性能，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 科学文献和专利中分子结构-活性关系（SARs）的提取对药物发现和材料研究至关重要，但现有方法因文档格式多样性和技术限制（如规则模板的僵化性和通用MLLMs的不足）难以胜任。

研究方法: 提出Doc2SAR框架，整合领域专用工具与监督微调的多模态大语言模型（MLLMs），并基于新标注的DocSAR-200基准进行验证。

研究结果: Doc2SAR在DocSAR-200基准上达到80.78%的表格召回率，显著优于GPT-4o等端到端基线方法（提升51.48%），且具备高效推理和实用工具支持。

研究结论: Doc2SAR通过协同领域工具与微调MLLMs，实现了SAR提取的高性能与实用性，为相关研究提供了新方向。

中文摘要: 从科学文献和专利中提取分子结构-活性关系（SARs）对药物发现和材料研究至关重要。然而，由于文档格式的异构性和现有方法的局限性，这一任务仍具挑战性。具体而言，基于规则的方法依赖固定模板，难以适应多样化的文档布局；而通用多模态大语言模型（MLLMs）在专业任务（如布局检测和光学化学结构识别）中缺乏足够的准确性和可靠性。为解决这些问题，我们提出了DocSAR-200，一个专门用于评估SAR提取方法的200份科学文档的严格标注基准。此外，我们提出了Doc2SAR，一种新型协同框架，将领域专用工具与通过监督微调（SFT）增强的MLLMs相结合。大量实验表明，Doc2SAR在多种文档类型中实现了最先进的性能，显著优于领先的端到端基线方法。具体而言，Doc2SAR在DocSAR-200上的表格召回率达到80.78%，比GPT-4o高出51.48%。此外，Doc2SAR通过高效推理展示了实际可用性，并附带一个网络应用。

</details>


### [64] [Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for Language Model Representations](https://arxiv.org/abs/2506.21682)
**中文标题：我们真的需要显式结构建模的图神经网络吗？多层感知机足以胜任语言模型表示**

*Li Zhou,Hao Jiang,Junjie Li,Zefeng Zhao,Feng Jiang,Wenyu Chen,Haizhou Li*

主要分类: cs.CL

摘要简述: 研究发现，多层感知机（MLPs）在语言模型表示中能够有效编码结构信息，甚至优于图神经网络（GNNs）的显式结构建模，尤其是在特征转换操作中表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 尽管GNNs被设计用于显式编码结构信息，但近期研究表明其未能充分利用结构信息，而MLPs在结构感知任务中表现出意外能力。本文旨在探究显式结构建模的必要性，并验证MLPs作为GNNs高效替代方案的潜力。

研究方法: 本文提出了一种基于信息论的探测框架，通过模块化设计分离GNNs的消息传递和特征转换操作，评估其对语言模型表示的影响。使用Edge Probing Suite工具对不同架构的语言模型进行诊断。

研究结果: 实验表明，MLPs作为特征转换模块能够显著提升语言模型对句法和语义模式的编码能力；而仅依赖消息传递操作的模型表现较差，甚至对任务性能产生负面影响。

研究结论: 显式结构建模并非必要，MLPs在语言模型表示中表现出色，可作为GNNs的高效替代方案。特征转换操作是关键，而消息传递操作可能带来负面效果。

中文摘要: 显式结构信息已被证明由图神经网络（GNNs）编码，作为辅助知识增强模型能力并提升下游NLP任务性能。然而，近期研究表明GNNs未能充分利用结构信息，而多层感知机（MLPs）尽管缺乏GNNs固有的消息传递机制，却在结构感知任务中表现出意外能力。基于这些发现，本文从信息论角度引入了一个全面的探测框架，旨在系统评估显式结构建模对语言模型（LM）表示的增强作用，并探究MLPs作为GNNs高效可扩展替代方案的潜力。我们扩展了传统探测分类器，加入一个控制模块，可选择使用完整GNN模型或其解耦组件（消息传递和特征转换操作）。这种模块化方法隔离并评估了这些操作的独立贡献，避免了完整GNN架构的混杂效应。使用Edge Probing Suite（一种评估LM中编码语言知识的诊断工具），我们发现MLPs作为特征转换模块时，能够持续提升不同架构LM表示中捕获的语言知识，有效编码句法和语义模式。同样，包含特征转换操作的GNNs也表现出积极效果。相比之下，仅依赖消息传递操作的模型表现不佳，往往对探测任务性能产生负面影响。

</details>


### [65] [ANUBHUTI: A Comprehensive Corpus For Sentiment Analysis In Bangla Regional Languages](https://arxiv.org/abs/2506.21686)
**中文标题：ANUBHUTI：用于孟加拉地区方言情感分析的综合语料库**

*Swastika Kundu,Autoshi Ibrahim,Mithila Rahman,Tanvir Ahmed*

主要分类: cs.CL

摘要简述: 本文介绍了ANUBHUTI数据集，包含2000句从标准孟加拉语翻译为四种方言的句子，用于情感分析，填补了低资源方言研究的空白。


<details>
  <summary>详细信息</summary>
研究动机: 由于孟加拉语方言的多样性和标注数据的缺乏，方言情感分析研究不足，本文旨在填补这一空白。

研究方法: 通过人工翻译和双重标注方案（多类主题标注和多标签情感标注），构建了包含政治、宗教和中性内容的方言数据集，并通过专家验证确保质量。

研究结果: 数据集质量高，标注一致性强，为低资源孟加拉语方言的情感分析提供了可靠资源。

研究结论: ANUBHUTI填补了孟加拉语方言情感分析的数据空白，有助于提升自然语言处理的准确性和语境感知能力。

中文摘要: 由于语言多样性和标注数据的限制，孟加拉语方言的情感分析研究较少。本文介绍了ANUBHUTI，一个包含2000句从标准孟加拉语翻译为四种主要方言（Mymensingh、Noakhali、Sylhet和Chittagong）的综合数据集。数据集以政治和宗教内容为主，同时包含中性文本以保持平衡。每句话采用双重标注方案：多类主题标注将句子分为政治、宗教或中性，多标签情感标注则标注愤怒、轻蔑、厌恶、享受、恐惧、悲伤和惊讶等情感。翻译和标注由母语专家完成，并通过Cohen's Kappa评估标注一致性，确保方言间的高质量。数据集还经过系统性检查以消除缺失、异常和不一致。ANUBHUTI填补了低资源孟加拉语方言情感分析的资源空白，为更准确和语境感知的自然语言处理提供了支持。

</details>


### [66] [Identifying Speaker Information in Feed-Forward Layers of Self-Supervised Speech Transformers](https://arxiv.org/abs/2506.21712)
**中文标题：识别自监督语音Transformer前馈层中的说话者信息**

*Tzu-Quan Lin,Hsi-Chun Cheng,Hung-yi Lee,Hao Tang*

主要分类: cs.CL

摘要简述: 本文通过分析自监督语音Transformer的前馈层中与说话者信息相关的神经元，揭示了这些神经元在编码说话者信息中的关键作用，并通过保护这些神经元在剪枝过程中显著保留了说话者相关任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，自监督语音Transformer在说话者相关应用中表现突出，但关于这些模型如何编码说话者信息的研究较少。本文旨在填补这一空白，探索前馈层中与说话者信息相关的神经元。

研究方法: 研究分析了前馈层中与自监督特征的k-means聚类和i-vectors相关的神经元，发现这些聚类对应于广泛的语音和性别类别，从而识别出代表说话者的神经元。在剪枝过程中保护这些神经元以验证其重要性。

研究结果: 分析表明，这些神经元在编码说话者信息中起关键作用。通过保护这些神经元，说话者相关任务的性能得到显著保留。

研究结论: 前馈层中的特定神经元对说话者信息的编码至关重要，保护这些神经元可以有效提升说话者相关任务的性能。

中文摘要: 近年来，自监督语音Transformer的影响已扩展到说话者相关应用。然而，关于这些模型如何编码说话者信息的研究较少。本文通过识别前馈层中与说话者信息相关的神经元填补了这一空白。具体而言，我们分析了与自监督特征的k-means聚类和i-vectors相关的神经元。分析表明，这些聚类对应于广泛的语音和性别类别，使其适合用于识别代表说话者的神经元。通过在剪枝过程中保护这些神经元，可以显著保留说话者相关任务的性能，证明它们在编码说话者信息中的关键作用。

</details>


### [67] [(Fact) Check Your Bias](https://arxiv.org/abs/2506.21745)
**中文标题：（事实）检查你的偏见**

*Eivind Morris Bakke,Nora Winger Heggelund*

主要分类: cs.CL

摘要简述: 研究探讨了大型语言模型（LLMs）在自动事实核查系统中的知识偏见问题，分析了Llama 3.1模型在事实核查中的表现及其对结果的影响。


<details>
  <summary>详细信息</summary>
研究动机: 随着自动事实核查系统越来越多地依赖大型语言模型，研究旨在揭示这些模型中的知识偏见如何影响事实核查结果，特别是针对HerO系统（FEVER-25基准）的表现。

研究方法: 研究分为两部分：(1) 直接提示Llama 3.1进行事实核查，观察其基于参数知识的判断；(2) 通过生成支持、反驳或中立的文档，分析提示对检索结果的影响。

研究结果: Llama 3.1在直接提示下对近一半的声明标记为“证据不足”，而其余声明则基于其参数知识得出结论。在生成文档实验中，提示显著影响检索结果，约50%的证据因视角不同而独特。尽管检索证据存在差异，最终预测结果在不同提示策略下保持稳定。

研究结论: 大型语言模型在事实核查中存在知识偏见，提示策略会影响证据检索，但最终预测结果相对稳定。模型有时会拒绝生成支持虚假声明的文档，表现出固有的负面偏见。

中文摘要: 自动事实核查系统越来越多地依赖大型语言模型（LLMs）。我们研究了这些模型中的参数知识偏见如何影响HerO系统（FEVER-25基准）的事实核查结果。我们分析了系统在以下两种情况下的表现：(1) Llama 3.1的参数知识可能存在的偏见；(2) 故意注入的偏见。当直接提示进行事实核查时，Llama 3.1将近一半的声明标记为“证据不足”，而其余声明则基于其参数知识得出结论。在第二个实验中，我们提示模型生成支持、反驳或中立的事实核查文档。这些提示显著影响了检索结果，约50%的检索证据因视角不同而独特。值得注意的是，模型有时会拒绝为它认为虚假的声明生成支持文档，表现出固有的负面偏见。尽管检索证据存在差异，最终预测结果在不同提示策略下保持稳定。代码可在以下链接获取：https://github.com/eibakke/FEVER-8-Shared-Task

</details>


### [68] [Evaluating List Construction and Temporal Understanding capabilities of Large Language Models](https://arxiv.org/abs/2506.21783)
**中文标题：评估大型语言模型的列表构建与时间理解能力**

*Alexandru Dumitru,V Venktesh,Adam Jatowt,Avishek Anand*

主要分类: cs.CL

摘要简述: 本文提出了一种名为TLQA的基准测试，用于评估大型语言模型在时间引用列表构建任务中的表现，发现现有模型在封闭式和开放式设置中均存在显著不足。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在自然语言任务中表现优异，但在涉及时间理解和多实体列表构建的任务中容易产生幻觉和错误。现有研究未充分评估模型在此类任务中的表现，因此需要填补这一空白。

研究方法: 作者提出了TLQA基准测试，要求模型生成与时间区间对齐的列表形式结构化答案，并在封闭式和开放式设置下评估模型的性能。

研究结果: 研究发现，当前模型在封闭式设置中难以提供完整且时间对齐的答案，而在开放式设置中检索能力有待提升。

研究结论: TLQA基准测试揭示了现有模型的局限性，为未来研究提供了明确方向。

中文摘要: 大型语言模型（LLMs）在多种自然语言任务中取得了显著进展，但在涉及多实体答案的时间理解任务中容易产生幻觉和错误。此类任务中，模型难以将实体与准确的时间区间关联，生成完整实体列表或推理特定时间范围内的事件。现有研究未充分评估模型在列表答案构建中的隐式和显式时间理解能力。为填补这一空白，我们提出了时间引用列表问答（TLQA）基准测试，要求生成与时间区间对齐的列表形式结构化答案。TLQA基准测试同时要求列表构建和时间理解能力，这在现有基准测试中尚未被探索。我们研究了最先进生成模型在封闭式和开放式设置下的时间理解和列表构建能力。研究结果表明，当前模型在封闭式设置中难以提供完整且时间对齐的答案，而在开放式设置中检索能力有待提升，为TLQA的未来研究提供了明确方向。基准测试和代码详见https://github.com/elixir-research-group/TLQA。

</details>


### [69] [Offensive Language Detection on Social Media Using XLNet](https://arxiv.org/abs/2506.21795)
**中文标题：基于XLNet的社交媒体冒犯性语言检测**

*Reem Alothman,Hafida Benhidour,Said Kerrache*

主要分类: cs.CL

摘要简述: 本研究提出了一种基于XLNet的自动检测社交媒体上冒犯性语言的模型，并在OLID数据集上比较了其与BERT的性能。结果显示XLNet在检测冒犯内容及分类冒犯类型上优于BERT，而BERT在识别冒犯目标上略胜一筹。此外，过采样和欠采样策略有效改善了类别不平衡问题。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体上文本交流的普及带来了冒犯性内容的增加，如仇恨言论和种族歧视。由于内容量庞大，手动审核不现实，因此需要自动化系统来检测冒犯性语言。深度学习模型，尤其是迁移学习方法，在大规模预训练中表现出色。

研究方法: 研究基于XLNet（一种广义自回归预训练方法）构建了冒犯性语言检测模型，并与BERT进行了性能对比。实验使用了OLID数据集，并采用了过采样和欠采样策略以解决类别不平衡问题。

研究结果: 实验结果表明，XLNet在检测冒犯性内容及其分类上优于BERT，而BERT在识别冒犯目标上表现稍好。过采样和欠采样策略显著提升了分类性能。

研究结论: 研究证明了迁移学习和XLNet架构在构建鲁棒的社交媒体冒犯性语言检测系统中的潜力，为自动化内容审核提供了有效解决方案。

中文摘要: 社交媒体上基于文本的交流（如聊天、评论和微博）的广泛使用提升了用户互动，但也导致了冒犯性内容的增加，包括仇恨言论、种族歧视和其他形式的滥用。由于用户生成内容的体量巨大，手动审核不切实际，因此需要自动化系统来检测冒犯性语言。深度学习模型，尤其是采用迁移学习的模型，通过大规模预训练在自然语言理解方面取得了显著成功。本研究提出了一种基于XLNet（一种广义自回归预训练方法）的自动冒犯性语言检测模型，并将其性能与广泛使用的自然语言处理基准模型BERT（双向编码器表示变换器）进行了比较。两种模型均在OLID（一种包含分层标注的基准Twitter数据集）上进行了评估。实验结果表明，XLNet在检测冒犯性内容及其分类上优于BERT，而BERT在识别冒犯目标上表现稍好。此外，过采样和欠采样策略有效解决了类别不平衡问题并提升了分类性能。这些发现凸显了迁移学习和基于XLNet的架构在构建鲁棒的社交媒体冒犯性语言检测系统中的潜力。

</details>


### [70] [A suite of allotaxonometric tools for the comparison of complex systems using rank-turbulence divergence](https://arxiv.org/abs/2506.21808)
**中文标题：一套基于等级湍流散度的工具套件用于复杂系统的比较**

*Jonathan St-Onge,Ashley M. A. Fehr,Carter Ward,Calla G. Beauregard,Michael V. Arnold,Samuel F. Rosenblatt,Benjamin Cooley,Christopher M. Danforth,Peter Sheridan Dodds*

主要分类: cs.CL

摘要简述: 本文介绍了一套基于等级湍流散度的工具套件，用于比较复杂系统，支持Matlab、Javascript和Python等多种编程语言。


<details>
  <summary>详细信息</summary>
研究动机: 描述和比较复杂系统需要理论支持的工具，而等级湍流散度是一种有效的比较方法，因此开发了这套工具以满足不同场景的需求。

研究方法: 围绕类型湍流现象，开发了地图和列表可视化工具（allotaxonographs），支持多种散度度量方法，包括等级湍流散度、概率湍流散度、Jenson-Shannon散度和广义熵散度。

研究结果: 成功实现了在Matlab、Javascript和Python中渲染allotaxonographs的工具套件，适用于不同的使用场景。

研究结论: 这套工具为复杂系统的比较提供了灵活且理论支持的可视化方法，适用于多种编程环境和需求。

中文摘要: 描述和比较复杂系统需要基于理论的支持工具。围绕类型湍流现象，allotaxonographs提供了对重尾分布对的地图和列表可视化比较。allotaxonographs设计用于支持多种工具，包括等级湍流散度、概率湍流散度、Jenson-Shannon散度和广义熵散度。本文介绍了一套用于在Matlab、Javascript和Python中渲染基于等级湍流散度的allotaxonographs的程序化工具，这些工具适用于不同的使用场景。

</details>


### [71] [Towards Transparent AI: A Survey on Explainable Large Language Models](https://arxiv.org/abs/2506.21812)
**中文标题：迈向透明AI：可解释大型语言模型综述**

*Avash Palikhe,Zhenyu Yu,Zichong Wang,Wenbin Zhang*

主要分类: cs.CL

摘要简述: 本文综述了大型语言模型（LLMs）的可解释性技术，分类探讨了基于不同Transformer架构的XAI方法，并分析了其评估与应用，旨在推动透明和负责任的LLMs发展。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在AI领域取得了显著进展，但其决策过程缺乏透明度，限制了在高风险领域的应用。为此，研究者开发了多种XAI方法，但缺乏系统性理解，本文旨在填补这一空白。

研究方法: 本文通过将XAI方法分类为基于编码器、解码器和编码器-解码器架构的技术，系统回顾了LLMs的可解释性方法，并评估了其解释效果及实际应用。

研究结果: 研究总结了不同XAI方法的优缺点，探讨了其在实践中的应用，并指出了当前资源和研究挑战，为未来透明LLMs的发展提供了方向。

研究结论: 本文为LLMs的可解释性研究提供了系统框架，强调了透明性和责任性的重要性，并呼吁进一步探索以推动该领域的发展。

中文摘要: 大型语言模型（LLMs）在推动人工智能（AI）发展中发挥了关键作用。然而，尽管取得了成就，LLMs往往难以解释其决策过程，使其成为“黑箱”，并对可解释性提出了重大挑战。这种透明度的缺乏严重阻碍了LLMs在高风险领域中的应用，而这些领域对可解释性尤为关键。为克服这些限制，研究者开发了多种可解释人工智能（XAI）方法，为LLMs提供人类可理解的解释。然而，对这些方法的系统性理解仍然有限。为填补这一空白，本综述通过基于LLMs的Transformer架构（仅编码器、仅解码器和编码器-解码器模型）对XAI方法进行分类，全面回顾了可解释性技术。随后，这些技术从评估可解释性的角度进行了分析，并进一步探讨了这些解释在实际应用中的利用方式。最后，本文讨论了可用资源、当前研究挑战和未来方向，旨在指导持续努力，开发透明且负责任的LLMs。

</details>


### [72] [Exploring the Structure of AI-Induced Language Change in Scientific English](https://arxiv.org/abs/2506.21817)
**中文标题：探索AI引发的科学英语语言变化结构**

*Riley Galpin,Bryce Anderson,Tom S. Juzek*

主要分类: cs.CL

摘要简述: 研究探讨了AI（如ChatGPT）对科学英语语言变化的深层结构影响，发现词汇频率变化不仅涉及同义词替换，还反映了语义和语用的整体迁移。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，科学英语中某些词汇（如“delve”、“crucial”）使用频率激增，普遍认为这与大型语言模型（如ChatGPT）的影响有关。然而，这些语言变化的具体结构尚不明确，本研究旨在揭示其深层机制。

研究方法: 通过分析PubMed科学摘要中的词汇频率趋势，研究系统考察了“激增词汇”及其同义词组的变化模式，并结合词性标注区分不同语法形式（如名词与形容词的“potential”）。

研究结果: 研究发现，语义相近的词汇往往整体迁移，表明AI引发的语言变化主要是语义和语用层面的，而非单纯的词汇替换。此外，形容词“important”使用频率显著下降，揭示了更复杂的语言变化模式。

研究结论: 研究揭示了AI对语言变化的深层影响，表明这种变化更倾向于语义和语用的整体调整，而非简单的词汇替换，为理解语言技术如何塑造人类语言提供了新视角。

中文摘要: 近年来，科学英语经历了快速且前所未有的变化，自2022年左右起，“delve”、“intricate”和“crucial”等词汇的使用频率显著激增。这些变化被广泛归因于大型语言模型（如ChatGPT）在偏见和失调讨论中的日益增长的影响。然而，除了频率变化外，这些语言变化的具体结构仍不明确。本研究探讨了这些变化是否涉及同义词被突然“激增词汇”取代（例如“crucial”取代“essential”和“key”），还是反映了更广泛的语义和语用调整。为进一步研究结构变化，我们在分析中加入了词性标注，以量化语法类别上的语言变化，并区分不同词形（如名词与形容词的“potential”）。我们基于PubMed科学摘要中的频率趋势，系统分析了广泛讨论的“激增词汇”及其同义词组。研究发现，整个语义簇通常一起迁移，组内大多数或全部词汇的使用频率均有所增加。这一模式表明，大型语言模型引发的变化主要是语义和语用层面的，而非纯粹的词汇替换。值得注意的是，形容词“important”的使用频率显著下降，这促使我们系统分析了“衰退词汇”。对“衰退词汇”的分析揭示了更复杂的图景，与有机语言变化一致，而与突然激增的模式形成对比。这些关于语言变化结构的见解，有助于我们理解语言技术如何持续塑造人类语言。

</details>


### [73] [PARSI: Persian Authorship Recognition via Stylometric Integration](https://arxiv.org/abs/2506.21840)
**中文标题：PARSI：通过风格特征整合的波斯作者识别**

*Kourosh Shahnazari,Mohammadali Keshtparvar,Seyed Moein Ayyoubzadeh*

主要分类: cs.CL

摘要简述: 该论文提出了一种名为PARSI的框架，通过整合风格特征和深度学习方法，用于识别波斯古典诗歌的作者。实验表明，加权投票方案达到71%的准确率，而高置信度预测的准确率可达97%。


<details>
  <summary>详细信息</summary>
研究动机: 波斯古典诗歌的语言、风格和韵律复杂性为计算作者归属带来了挑战。本研究旨在通过整合多维度特征和深度学习方法，提升波斯诗歌作者识别的准确性。

研究方法: 研究采用多输入神经网络框架，结合基于Transformer的语言编码器，以及语义、风格和韵律特征。特征集包括100维Word2Vec嵌入、7种风格度量指标，以及诗歌形式和韵律的分类编码。数据来源于Ganjoor数字收藏的647,653行诗句，并通过严格预处理和作者验证。评估采用诗句级分类和加权投票方案。

研究结果: 加权投票方案在作者识别中达到71%的准确率。通过基于阈值的决策过滤，模型在高置信度预测（阈值为0.9）下准确率提升至97%，但覆盖率较低。

研究结论: 该研究展示了整合深度表示与领域特定特征在作者归属中的潜力，为波斯诗歌的自动化分类、风格分析和计算文学研究提供了新思路。

中文摘要: 波斯古典诗歌在语言、风格和韵律上的复杂性为计算作者归属带来了挑战。本研究提出了一种通用框架，用于识别67位著名诗人的作品。我们采用了一种多输入神经网络框架，结合基于Transformer的语言编码器，以及语义、风格和韵律特征。特征集包括100维Word2Vec嵌入、7种风格度量指标，以及诗歌形式和韵律的分类编码。我们从Ganjoor数字收藏中整理了647,653行诗句，并通过严格预处理和作者验证确保数据质量，同时保留诗歌级别的分割以避免重叠。本研究采用诗句级分类和加权投票方案进行评估，结果显示加权投票的准确率为71%。我们还研究了基于阈值的决策过滤，使模型能够生成高置信度预测，在阈值为0.9时准确率达到97%，但覆盖率较低。本研究重点关注深度表示形式与领域特定特征的整合，以提升作者归属的准确性。结果表明，该方法在自动化分类、风格分析、作者争议和计算文学研究中具有潜力。这项研究将为多语言作者归属、风格变化和波斯诗歌生成模型的进一步研究提供支持。

</details>


### [74] [LinguaSynth: Heterogeneous Linguistic Signals for News Classification](https://arxiv.org/abs/2506.21848)
**中文标题：LinguaSynth：异构语言信号用于新闻分类**

*Duo Zhang,Junyi Mo*

主要分类: cs.CL

摘要简述: 本文提出LinguaSynth框架，通过整合五种互补的语言特征（词汇、句法、实体级、词级语义和文档级语义），在透明逻辑回归模型中实现高效且可解释的文本分类，性能优于传统TF-IDF基线。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在NLP中表现优异，但其黑盒模型缺乏可解释性且计算效率低。本文旨在开发一种高效、可解释的文本分类方法，挑战深度神经网络在文本分类中的必要性。

研究方法: LinguaSynth框架整合了五种语言特征（词汇、句法、实体级、词级语义和文档级语义），采用透明逻辑回归模型进行分类，避免了复杂的深度学习架构。

研究结果: 在20 Newsgroups数据集上，LinguaSynth准确率达到84.89%，比TF-IDF基线提升3.32%。特征交互分析显示，句法和实体级特征对消歧和补充分布语义至关重要。

研究结论: LinguaSynth为高效、可解释的NLP模型设定了新基准，证明深度神经网络并非高性能文本分类的必要条件。

中文摘要: 深度学习显著推动了自然语言处理（NLP）的发展，但其依赖大型黑盒模型带来了可解释性和计算效率的严重问题。本文提出LinguaSynth，一种新颖的文本分类框架，策略性地整合了五种互补的语言特征类型：词汇、句法、实体级、词级语义和文档级语义，并将其嵌入透明的逻辑回归模型中。与基于Transformer的架构不同，LinguaSynth保持了可解释性和计算效率，在20 Newsgroups数据集上达到84.89%的准确率，比稳健的TF-IDF基线高出3.32%。通过严格的特征交互分析，我们发现句法和实体级信号提供了关键的消歧作用，并有效补充了分布语义。LinguaSynth为可解释、资源高效的NLP模型设定了新基准，并挑战了深度神经网络是高性能文本分类必要条件的普遍假设。

</details>


### [75] [The Consistency Hypothesis in Uncertainty Quantification for Large Language Models](https://arxiv.org/abs/2506.21849)
**中文标题：大型语言模型不确定性量化中的一致性假设**

*Quan Xiao,Debarun Bhattacharjya,Balaji Ganesan,Radu Marinescu,Katsiaryna Mirylenka,Nhan H Pham,Michael Glass,Junkyu Lee*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型（LLM）输出置信度的估计问题，提出了‘一致性假设’作为置信度的代理，并通过统计测试验证其有效性。实验表明，基于生成一致性的黑盒不确定性量化方法在实际任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 在需要高用户信任的实际应用中，准确估计大型语言模型输出的置信度至关重要。黑盒不确定性量化方法因其仅需模型API访问而受到欢迎，但其背后的‘一致性假设’尚未得到系统验证。本文旨在填补这一空白。

研究方法: 本文提出了三种数学表述及其统计测试，用于验证‘一致性假设’的不同变体，并设计了评估指标。实验覆盖8个基准数据集和3项任务（问答、文本摘要和文本转SQL），验证假设的普遍性。

研究结果: 实验结果表明，‘Sim-Any’假设最具实用性，基于此提出的无数据黑盒不确定性量化方法在置信度估计中优于基线方法。

研究结论: 本文通过实证研究验证了‘一致性假设’的普遍性，并展示了其在黑盒不确定性量化中的实际价值，为LLM的可靠应用提供了新思路。

中文摘要: 估计大型语言模型（LLM）输出的置信度对于需要高用户信任的实际应用至关重要。仅依赖模型API访问的黑盒不确定性量化（UQ）方法因其实用性而广受欢迎。本文研究了多种UQ方法背后的隐含假设，即用生成一致性作为置信度的代理，并将其形式化为‘一致性假设’。我们提出了三种数学表述及相应的统计测试，以捕捉这一假设的变体，并设计了评估LLM输出一致性的指标。实证研究覆盖8个基准数据集和3项任务（问答、文本摘要和文本转SQL），揭示了该假设在不同设置下的普遍性。其中，‘Sim-Any’假设最具实用性，我们展示了如何利用它提出无数据黑盒UQ方法，通过聚合生成相似性来估计置信度。这些方法优于最接近的基线，体现了实证观察到的一致性假设的实际价值。

</details>


### [76] [Derivational Probing: Unveiling the Layer-wise Derivation of Syntactic Structures in Neural Language Models](https://arxiv.org/abs/2506.21861)
**中文标题：衍生探测：揭示神经网络语言模型中句法结构的层间构建过程**

*Taiga Someya,Ryo Yoshida,Hitomi Yanaka,Yohei Oseki*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“衍生探测”的方法，用于研究神经网络语言模型中句法结构在不同层中的构建过程。实验发现，微观句法结构在底层形成，而宏观句法结构在高层逐步整合，且其构建时机对下游任务性能至关重要。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有研究表明神经网络语言模型在其内部表示中编码了句法结构，但这些结构在不同层中的具体构建过程仍不明确。本文旨在揭示微观和宏观句法结构如何随着词嵌入在层间的传播逐步构建。

研究方法: 本文提出“衍生探测”方法，通过分析BERT模型中词嵌入在不同层的传播过程，研究微观句法结构（如主语名词短语）和宏观句法结构（如根动词与其直接依赖项的关系）的构建机制。

研究结果: 实验发现，微观句法结构在底层形成，并随着层数的增加逐步整合为连贯的宏观句法结构。此外，针对主谓数一致性的评估表明，宏观句法结构的构建时机对下游任务性能具有关键影响。

研究结论: 研究揭示了神经网络语言模型中句法结构的层间构建过程，并指出宏观句法结构的整合时机对模型性能的重要性，为优化模型设计提供了理论依据。

中文摘要: 近期研究表明，神经网络语言模型在其内部表示中编码了句法结构，但这些结构在不同层中的构建过程仍不清楚。本文提出“衍生探测”方法，用于研究微观句法结构（如主语名词短语）和宏观句法结构（如根动词与其直接依赖项的关系）如何随着词嵌入在层间的传播逐步构建。在BERT模型上的实验显示，微观句法结构在底层形成，并逐渐整合为连贯的宏观句法结构。此外，针对主谓数一致性的评估表明，宏观句法结构的构建时机对下游任务性能至关重要，这提示了整合全局句法信息的最佳时机。

</details>


### [77] [DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE](https://arxiv.org/abs/2506.21864)
**中文标题：DeepTalk：基于自适应模态专家学习的无缝智能语音交互**

*Hang Shao,Heting Gao,Yunhang Shen,Jiawei Chen,Lijiang Li,Zuwei Long,Bo Tong,Ke Li,Xing Sun*

主要分类: cs.CL

摘要简述: DeepTalk提出了一种基于Mixture of Experts（MoE）架构的自适应模态专家学习框架，解决了原生多模态大语言模型（MLLMs）因数据不足导致的性能下降问题，显著降低了性能损失（仅5.5%），同时保持了低延迟（0.5秒内）的智能语音交互体验。


<details>
  <summary>详细信息</summary>
研究动机: 原生多模态大语言模型（MLLMs）虽然能直接生成语音并保留丰富的副语言特征（如情感和韵律），但由于语音-文本配对数据不足，容易发生灾难性遗忘和性能下降。本文旨在解决这一问题，提升MLLMs的性能和交互体验。

研究方法: DeepTalk采用MoE架构，首先根据模态负载自适应区分模态专家，然后对每个模态专家进行单模态训练，最后进行多模态协作训练。这种方法避免了原生MLLMs的性能下降问题。

研究结果: DeepTalk的性能损失仅为5.5%，远低于原生MLLMs（如GLM-4-Voice）平均20%的性能下降，且与模块化MLLMs相当。同时，端到端对话延迟保持在0.5秒内。

研究结论: DeepTalk通过自适应模态专家学习框架，有效解决了原生MLLMs的数据不足问题，显著提升了性能并保持了低延迟，为智能语音交互提供了无缝体验。

中文摘要: 原生多模态大语言模型（MLLMs）将单一大型语言模型（LLM）重构为能够同时生成语音和文本的口语模型（SLM）。与模块化和对齐的MLLMs相比，原生MLLMs保留了更丰富的副语言特征（如情感和韵律），并直接在主干LLM内生成语音响应，而非使用单独的语音解码器。这种集成还降低了响应延迟并提升了交互流畅性。然而，由于可用的语音-文本配对数据不足以支持MLLMs的预训练（与预训练文本LLMs所需的大量文本数据相比），原生MLLMs容易发生灾难性遗忘和性能下降。为解决这一问题，我们提出了DeepTalk，一种基于Mixture of Experts（MoE）架构的自适应模态专家学习框架。DeepTalk首先根据模态负载自适应区分模态专家，然后对每个模态专家进行单模态训练，最后进行多模态协作训练。结果表明，DeepTalk的性能损失仅为5.5%，远低于原生MLLMs（如GLM-4-Voice）平均超过20%的性能下降，且与模块化MLLMs相当。同时，端到端对话延迟保持在0.5秒内，确保了无缝且智能的语音交互体验。代码和模型已发布于https://github.com/talkking/DeepTalk。

</details>


### [78] [WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation](https://arxiv.org/abs/2506.21875)
**中文标题：WildSpeech-Bench：自然语音对话中音频大语言模型的基准测试**

*Jian Zhang,Linhao Zhang,Bokai Lei,Chuhan Wu,Wei Jia,Xiao Zhou*

主要分类: cs.CL

摘要简述: 本文提出WildSpeech-Bench，一个专为评估音频大语言模型在自然语音对话中表现而设计的基准测试，填补了现有评估方法的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前的多模态大语言模型（如GPT-4o）在语音交互中表现出色，但缺乏针对语音特性的专门评估基准，导致实际应用中用户体验难以优化。现有方法多基于文本评估，忽略了语音特有的挑战（如韵律、同音词、口吃等）。

研究方法: 通过系统整理真实语音聊天数据，引入多样化的说话者属性和声学条件，并增强语音特有现象的数据集。设计了基于查询的评估方法，使用定制化评估清单和提示以提高自动评估的准确性。

研究结果: 对多种主流语音模型进行全面测试和详细分析，发现模型在不同语音场景下表现差异显著。基于查询的评估方法进一步实现了更细粒度的语音场景评估。

研究结论: WildSpeech-Bench为语音模型的开发和评估提供了有价值的见解，填补了现有评估方法的空白。

中文摘要: 近年来，如GPT-4o等多模态大语言模型展现了强大的直接语音交互能力。然而，缺乏针对端到端语音大语言模型的专门且全面的评估基准，阻碍了音频大语言模型在实际应用中的用户体验优化。现有的评估方法通常基于文本基准，忽略了语音的独特特性和挑战，包括韵律、同音词、口吃以及用户期望的差异。本文提出了一种新颖的方法，全面评估大语言模型在实际语音对话中的表现。我们系统整理了与语音场景相关的真实聊天数据，引入了说话者属性和声学条件的多样性，并通过语音特有现象增强了数据集。此外，我们设计了一种基于查询的评估方法，使用定制化的评估清单和提示以提高自动评估的准确性。我们对多种主流语音模型进行了全面测试和详细分析，揭示了模型在不同语音场景下的显著性能差异。基于查询的评估方法进一步实现了在各种语音特有场景下的更细粒度评估。我们的基准测试为语音模型的开发和评估提供了有价值的见解。

</details>


### [79] [Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation](https://arxiv.org/abs/2506.21876)
**中文标题：视觉语言模型是否具有内部世界模型？一种原子化评估方法**

*Qiyue Gao,Xinyu Pi,Kevin Liu,Junrong Chen,Ruolan Yang,Xinqi Huang,Xinyu Fang,Lu Sun,Gautham Kishore,Bo Ai,Stone Tao,Mengyang Liu,Jiaxi Yang,Chao-Jung Lai,Chuanyang Jin,Jiannan Xiang,Benhao Huang,Zeming Chen,David Danks,Hao Su,Tianmin Shu,Ziqiao Ma,Lianhui Qin,Zhiting Hu*

主要分类: cs.CL

摘要简述: 本文提出了一种两阶段框架，用于评估视觉语言模型（VLMs）作为内部世界模型（WMs）的能力，发现现有模型在基础世界建模能力上存在显著局限。


<details>
  <summary>详细信息</summary>
研究动机: 尽管近期的大型视觉语言模型（如OpenAI o3、GPT-4o和Gemini）展现出作为通用世界模型的潜力，但缺乏对其基本世界建模能力的系统性评估。本文旨在填补这一空白。

研究方法: 基于比较心理学和认知科学，提出一个两阶段评估框架，包括感知（视觉、空间、时间、数量和运动）和预测（机械模拟、传递推理、组合推理），并引入大规模基准WM-ABench进行实验。

研究结果: 通过对15种最新商业和开源VLMs的660次实验，发现这些模型在基础世界建模能力上表现接近随机，例如区分运动轨迹的准确性极低，且存在未解耦的理解问题（如认为蓝色物体比绿色物体移动更快）。

研究结论: 现有视觉语言模型与世界建模的人类水平存在显著差距，需进一步改进其基础能力。

中文摘要: 内部世界模型（WMs）使智能体能够理解世界状态并预测其变化，是高级推理的基础。近期的大型视觉语言模型（VLMs），如OpenAI o3、GPT-4o和Gemini，展现出作为通用世界模型的潜力。尽管已有研究评估了其在特定能力（如视觉理解）上的局限性，但对其基本世界建模能力的系统性评估仍缺失。借鉴比较心理学和认知科学，我们提出一个两阶段框架，从感知（视觉、空间、时间、数量和运动）和预测（机械模拟、传递推理、组合推理）两个维度对VLMs作为WMs的能力进行原子化评估。基于此框架，我们引入WM-ABench，这是一个包含6种多样化模拟环境和23个细粒度评估维度的大规模基准。通过对15种最新商业和开源VLMs的660次实验，发现这些模型在基础世界建模能力上存在显著局限。例如，几乎所有模型在区分运动轨迹时的表现接近随机准确性。此外，它们缺乏解耦理解能力——例如，某些模型倾向于认为蓝色物体比绿色物体移动更快。更多丰富的结果和分析揭示了VLMs与世界建模的人类水平之间的显著差距。

</details>


### [80] [A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs](https://arxiv.org/abs/2506.21881)
**中文标题：对LLMs中地缘政治和文化偏见的双层评估**

*Sean Kim,Hyuhng Joon Kim*

主要分类: cs.CL

摘要简述: 本文通过两阶段评估，揭示了大型语言模型（LLMs）在事实性和争议性问题中的偏见，包括模型偏见和推理偏见，并提出了跨语言和文化背景的评估框架。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLMs在多语言和文化背景中的广泛应用，了解其在事实性和争议性问题中的行为至关重要，以避免其输出影响公众舆论或强化主导叙事。

研究方法: 研究分为两阶段：第一阶段评估LLMs在单一可验证答案的事实性问题中的表现，检验不同查询语言下的一致性；第二阶段探讨地缘政治敏感争议，分析模型输出是否反映文化或意识形态偏见。研究构建了一个涵盖四种语言和问题类型的手工数据集。

研究结果: 第一阶段显示查询语言导致的对齐现象，第二阶段则反映了模型训练背景与查询语言的交互作用。

研究结论: 本文提供了一个评估LLMs在中性和敏感话题中行为的结构化框架，为未来多语言环境下的LLMs部署和文化意识评估实践提供了见解。

中文摘要: 随着大型语言模型（LLMs）在多样化语言和文化背景中的广泛应用，理解其在事实性和争议性场景中的行为变得至关重要，尤其是当其输出可能影响公众舆论或强化主导叙事时。本文通过两阶段评估定义了LLMs中的两种偏见：模型偏见（源于模型训练）和推理偏见（由查询语言引发）。第一阶段评估LLMs在单一可验证答案的事实性问题中的表现，检验模型在不同查询语言下的一致性。第二阶段扩展范围，探讨地缘政治敏感争议，分析模型输出是否反映文化或意识形态偏见。研究构建了一个涵盖四种语言和问题类型的手工数据集。结果显示，第一阶段存在查询语言引发的对齐现象，而第二阶段则反映了模型训练背景与查询语言的交互作用。本文提供了一个评估LLMs在中性和敏感话题中行为的结构化框架，为未来多语言环境下的LLMs部署和文化意识评估实践提供了见解。

</details>


### [81] [AutoMixer: Checkpoint Artifacts as Automatic Data Mixers](https://arxiv.org/abs/2506.21910)
**中文标题：AutoMixer：检查点模型作为自动数据混合器**

*Ernie Chang,Yang Li,Patrick Huber,David Kant,Yangyang Shi,Vikas Chandra*

主要分类: cs.CL

摘要简述: 本文提出AutoMixer框架，利用训练过程中的检查点模型作为数据混合器，通过其近似影响优化数据混合，显著提升语言模型在推理任务上的性能。


<details>
  <summary>详细信息</summary>
研究动机: 在语言模型训练中，如何直接获取适合多任务能力的数据混合是一个难题。检查点模型在训练过程中展现出不同能力，但通常被忽视。本文旨在利用这些检查点模型优化数据混合。

研究方法: 通过识别检查点模型在基准测试中的能力，利用其一阶影响近似对源数据进行混合优化，构建AutoMixer框架。

研究结果: 在八个推理基准测试中，AutoMixer显著提升了预训练性能，最高提升达1.93%。

研究结论: 检查点模型可作为数据混合器，优化数据质量与混合方式，提升模型性能。

中文摘要: 在语言模型训练中，为模型赋予多任务能力是理想目标，但如何直接获取适合这些能力的数据混合尚不明确。本研究观察到，检查点模型在训练轨迹的不同阶段展现出不同能力。通常，训练过程中保存的检查点模型作为未被充分利用的数据信号源。我们基于这些模型在基准测试中的能力进行识别，并通过其一阶影响近似对源数据进行混合优化。在八个推理基准测试中，所提框架在预训练场景下表现出显著改进，性能最高提升1.93%。这表明检查点模型在提升数据质量和优化数据混合方面具有潜力。

</details>


### [82] [PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language Models Based on ERG Theory](https://arxiv.org/abs/2506.21961)
**中文标题：PapersPlease：基于ERG理论的大型语言模型动机价值观评估基准**

*Junho Myung,Yeon Su Park,Sunwoo Kim,Shin Yoo,Alice Oh*

主要分类: cs.CL

摘要简述: 论文提出了一个名为PapersPlease的基准测试，通过3700个道德困境评估大型语言模型（LLMs）在决策中如何优先考虑人类需求层次（基于ERG理论）。研究发现LLMs在决策中存在隐含偏好，并对社会身份信息表现出不同的响应。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLMs）在角色扮演场景中常表现出偏见行为，因此需要一种方法来评估其决策中的动机价值观。论文基于ERG理论设计了一个基准测试，以探究LLMs在优先满足不同层次人类需求时的表现。

研究方法: 论文设计了PapersPlease基准测试，包含3700个道德困境，LLMs扮演移民官员，根据申请者的简短叙述决定是否批准入境。这些叙述基于ERG理论（存在、关系和成长需求）构建，同时考察了社会身份对决策的影响。

研究结果: 对六个LLMs的分析显示，其决策中存在统计显著的偏好模式，表明LLMs编码了隐含的价值观。此外，社会身份的引入导致不同响应，部分模型对边缘化身份的拒绝率更高。

研究结论: 论文表明LLMs在决策中表现出对人类需求层次的偏好，且对社会身份敏感。这一基准测试为评估LLMs的动机价值观提供了工具，并揭示了潜在的偏见问题。

中文摘要: 通过角色扮演场景评估大型语言模型（LLMs）的性能和偏见日益普遍，因为LLMs在这些情境中常表现出偏见行为。基于此，我们提出了PapersPlease基准测试，包含3700个道德困境，旨在研究LLMs在优先满足不同层次人类需求时的决策行为。实验中，LLMs扮演移民官员，根据申请者的简短叙述决定是否批准入境。这些叙述基于ERG理论（存在、关系和成长需求）构建。我们对六个LLMs的分析揭示了其决策中的统计显著偏好模式，表明LLMs编码了隐含的价值观。此外，社会身份的引入导致不同响应，部分模型对边缘化身份的拒绝率更高。所有数据公开于https://github.com/yeonsuuuu28/papers-please。

</details>


### [83] [More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents](https://arxiv.org/abs/2506.21967)
**中文标题：比你想象的更脆弱：关于工具集成LLM代理的稳定性**

*Weimin Xiong,Ke Wang,Yifan Song,Hanchao Liu,Sai Zhou,Wei Peng,Sujian Li*

主要分类: cs.CL

摘要简述: 当前对工具集成LLM代理的评估多关注端到端工具使用，而忽略了其稳定性。研究发现，代理在整个工具调用过程中极易出错，开源模型代理比专有模型更脆弱，增大模型规模并不能显著提升工具调用推理能力，反而可能增加被攻击风险。


<details>
  <summary>详细信息</summary>
研究动机: 现有评估多关注工具集成LLM代理的功能性，而忽略了其稳定性问题。由于内部或外部因素可能导致代理崩溃或行为异常，限制了其实际应用。研究旨在填补这一空白，探究代理在工具调用全过程中的脆弱性。

研究方法: 研究通过实验分析代理在工具调用各阶段的稳定性，包括阅读工具文档、选择工具与生成参数、处理工具响应等。对比开源模型与专有模型代理的表现，并探讨模型规模对稳定性的影响。

研究结果: 实验表明，代理在工具调用各阶段均高度易出错，开源模型代理比专有模型更脆弱。增大模型规模对工具调用推理能力提升有限，反而可能使代理更容易受到类似正常用户指令的攻击。

研究结论: 研究强调了评估代理稳定性的重要性，为未来LLM开发与评估提供了宝贵见解。稳定性问题需被纳入评估框架，以确保代理在实际应用中的可靠性。

中文摘要: 当前对工具集成LLM代理的评估通常侧重于端到端的工具使用评估，而忽略了其稳定性。这限制了其实际应用，因为各种内部或外部因素可能导致代理崩溃或行为异常。我们的研究通过探究代理在整个工具调用过程中是否容易出错来解决这一问题，包括阅读工具文档、选择工具和生成参数以及处理工具响应。通过大量实验，我们观察到代理在每个阶段都极易出错，且基于开源模型的代理比基于专有模型的代理更脆弱。我们还发现，增大模型规模并不能显著提升工具调用推理能力，反而可能使代理更容易受到类似正常用户指令的攻击。这凸显了评估代理稳定性的重要性，并为未来LLM的开发与评估提供了宝贵见解。

</details>


### [84] [Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses](https://arxiv.org/abs/2506.21972)
**中文标题：推进越狱策略：一种混合方法利用LLM漏洞并绕过现代防御**

*Mohamed Ahmed,Mohamed Abdelmouty,Mingyu Kim,Gunvanth Kandula,Alex Park,James C. Davis*

主要分类: cs.CL

摘要简述: 本文提出两种混合方法（GCG + PAIR和GCG + WordGame），结合令牌级和提示级技术，显著提高了对预训练语言模型的越狱攻击成功率，并成功绕过现代防御机制。


<details>
  <summary>详细信息</summary>
研究动机: 预训练语言模型（PTLMs）和大语言模型（LLMs）虽广泛应用，但仍存在安全漏洞。令牌级和提示级越狱攻击各有局限性，本文旨在结合两者优势，提升攻击效果并突破现代防御。

研究方法: 提出两种混合方法：GCG + PAIR和GCG + WordGame，结合令牌级攻击的梯度优化和提示级攻击的语义结构输入，评估其在Vicuna和Llama模型上的表现。

研究结果: GCG + PAIR在未防御模型上的攻击成功率显著提升（如Llama-3达到91.6%），GCG + WordGame在高严格评估下仍保持80%以上的成功率。两种方法均能突破高级防御机制。

研究结论: 混合方法揭示了当前安全堆栈的未报告漏洞，强调了在攻击成功率和防御鲁棒性之间的权衡，呼吁开发更全面的防护措施。

中文摘要: 预训练语言模型（PTLMs）和大语言模型（LLMs）的进步使其在多种应用中广泛采用。尽管成功，这些模型仍易受攻击，利用其固有弱点绕过安全措施。两种主要的推理阶段威胁是令牌级和提示级越狱。令牌级攻击嵌入对抗序列，可迁移至黑盒模型如GPT，但留下可检测模式并依赖基于梯度的令牌优化；而提示级攻击使用语义结构化输入引发有害响应，但依赖可能不可靠的迭代反馈。为解决这些方法的互补限制，我们提出两种混合方法，结合令牌级和提示级技术，以提升对多种PTLMs的越狱效果。GCG + PAIR和新探索的GCG + WordGame混合方法在多个Vicuna和Llama模型上评估。GCG + PAIR在未防御模型上的攻击成功率持续高于其组成技术；例如，在Llama-3上，其攻击成功率（ASR）达91.6%，较PAIR的58.4%基线显著提升。同时，GCG + WordGame与WordGame的原始性能相当，即使在Mistral-Sorry-Bench等更严格的评估下仍保持80%以上的高ASR。关键的是，两种混合方法均保持可迁移性，并可靠突破如Gradient Cuff和JBShield等高级防御，这些防御完全阻挡了单模式攻击。这些发现揭示了当前安全堆栈中未报告的漏洞，突出了原始成功与防御鲁棒性之间的权衡，并强调了对自适应对手的全面防护需求。

</details>


### [85] [Don't Trust Generative Agents to Mimic Communication on Social Networks Unless You Benchmarked their Empirical Realism](https://arxiv.org/abs/2506.21974)
**中文标题：除非您已验证生成代理的实证现实主义，否则不要信任其在社交网络上模仿通信的能力**

*Simon Münker,Nils Schwager,Achim Rettinger*

主要分类: cs.CL

摘要简述: 论文探讨了大型语言模型（LLMs）在模仿社交网络用户行为时的局限性，强调需通过实证现实主义验证其模拟效果，并呼吁在基于生成代理的社会模拟中更加严谨。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究对LLMs能否替代人类进行社会行为模拟存在争议，论文旨在通过实证分析揭示模拟社交网络用户行为时的差异，并提出更严谨的验证方法。

研究方法: 论文首先提出了社交网络模拟的形式化框架，随后专注于模仿用户通信的子任务，并通过实验测试了不同方法在英语和德语社交网络X上的表现。

研究结果: 研究发现，社交模拟的实证现实主义应在拟合模拟组件的设定中验证，否则模拟结果可能不可靠。

研究结论: 论文主张在基于生成代理的社会模拟中需更加严谨，强调实证验证的重要性。

中文摘要: 大型语言模型（LLMs）模仿人类行为的能力引发了大量计算社会科学研究，假设可以用AI代理代替人类进行实证研究。由于关于这一假设是否成立的研究结果存在冲突，需要更好地理解实验设计的差异。我们专注于通过LLMs复制社交网络用户行为以分析社交网络通信。首先，我们提供了一个社交网络模拟的形式化框架，随后专注于模仿用户通信的子任务。我们通过实验测试了在英语和德语社交网络X上模仿用户行为的不同方法。研究结果表明，社交模拟应通过其拟合设定中的实证现实主义进行验证。本文主张在基于生成代理的社会模拟中需更加严谨。

</details>


### [86] [Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit](https://arxiv.org/abs/2506.21990)
**中文标题：分析与微调Whisper模型以实现驾驶舱多语言飞行员语音转录**

*Kartheek Kumar Reddy Nareddy,Sarah Ternus,Julia Niebling*

主要分类: cs.CL

摘要简述: 本文研究了如何通过微调Whisper模型和多规范化方案，显著降低驾驶舱飞行员语音转录的单词错误率（WER），从68.49%降至26.26%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管预训练的Whisper模型在通用语音识别任务中表现优异，但在驾驶舱等特定领域（涉及多语言和专业词汇）的转录性能较差。本文旨在提升此类场景下的转录准确性。

研究方法: 收集了85分钟的驾驶舱模拟器录音和130分钟的飞行员访谈录音，并手动标注。提出多种规范化方案优化转录文本，并采用低秩适应（LoRA）进行高效微调。

研究结果: 通过微调和规范化方案，Whisper Large模型的WER从68.49%降至26.26%，显著提升了驾驶舱语音转录的准确性。

研究结论: 研究表明，针对特定领域的微调和规范化方案能显著提升Whisper模型在驾驶舱语音转录中的性能。

中文摘要: 基于Transformer编码器-解码器架构的预训练模型在机器翻译、自动语音识别（ASR）等领域取得了显著突破。然而，这些模型在驾驶舱飞行员语音转录等特定领域（涉及多语言和专业词汇）的性能较差。本文研究了如何通过微调Whisper模型提升驾驶舱语音转录的准确性。我们收集了85分钟的驾驶舱模拟器录音和130分钟的飞行员访谈录音，并手动标注。飞行员为中年男性，使用德语和英语交流。为提高转录准确性，我们提出了多种规范化方案优化转录文本，并采用低秩适应（LoRA）进行高效微调。结果显示，Whisper Large模型的单词错误率（WER）从68.49%（未规范化的预训练模型）降至26.26%（微调并规范化的模型）。

</details>


### [87] [Can Peter Pan Survive MT? A Stylometric Study of LLMs, NMTs, and HTs in Children's Literature Translation](https://arxiv.org/abs/2506.22038)
**中文标题：彼得·潘能否在机器翻译中存活？——儿童文学翻译中大语言模型、神经机器翻译与人工翻译的风格计量学研究**

*Delu Kong,Lieve Macken*

主要分类: cs.CL

摘要简述: 本研究从风格计量学角度评估机器翻译（MT）与人工翻译（HT）在英译中儿童文学翻译中的表现，发现大语言模型（LLM）在风格特征上更接近人工翻译。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在比较机器翻译（包括大语言模型和神经机器翻译）与人工翻译在儿童文学翻译中的风格差异，探索机器翻译在创意文本翻译中的潜力。

研究方法: 构建《彼得·潘》语料库，包含21种翻译（7种人工翻译、7种大语言模型翻译、7种神经机器翻译），使用通用特征集和创意文本翻译特征集（共447个语言特征），通过机器学习的分类和聚类技术进行风格计量分析。

研究结果: 在通用特征中，人工翻译与机器翻译在连词分布和1-gram-YiYang比例上差异显著；在创意文本翻译特征中，大语言模型表现优于神经机器翻译，风格更接近人工翻译。

研究结论: 大语言模型在儿童文学翻译中展现出潜力，尤其在风格特征上更接近人工翻译，为机器翻译在创意文本领域的应用提供了新方向。

中文摘要: 本研究从风格计量学角度评估机器翻译（MT）与人工翻译（HT）在英译中儿童文学翻译中的表现。研究构建了《彼得·潘》语料库，包含21种翻译（7种人工翻译、7种大语言模型翻译和7种神经机器翻译）。分析采用了通用特征集（包括词汇、句法、可读性和n-gram特征）和创意文本翻译特征集（捕捉重复、节奏、可译性和其他层面），共计447个语言特征。通过机器学习的分类和聚类技术，对这些翻译进行了风格计量分析。结果显示，在通用特征中，人工翻译与机器翻译在连词分布和1-gram-YiYang比例上差异显著，而神经机器翻译与大语言模型在描述性词汇和副词比例上差异显著。在创意文本翻译特征中，大语言模型的表现优于神经机器翻译，其风格特征更接近人工翻译，表明大语言模型在儿童文学翻译中具有潜力。

</details>


### [88] [Decoding Machine Translationese in English-Chinese News: LLMs vs. NMTs](https://arxiv.org/abs/2506.22050)
**中文标题：解码英中新闻中的机器翻译特征：LLM与NMT对比**

*Delu Kong,Lieve Macken*

主要分类: cs.CL

摘要简述: 本研究探讨了机器翻译输出中的语言特征（MTese），重点关注英中新闻文本，通过构建大型数据集和五层特征集，发现NMT和LLM输出均存在MTese，且与原始中文文本差异显著。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索机器翻译输出（MTese）在英中新闻文本中的语言特征，尤其是NMT和LLM的差异，填补该领域的研究空白。

研究方法: 方法包括构建包含4个子库的大型数据集，采用五层特征集，并利用卡方排名算法进行特征选择，用于分类和聚类任务。

研究结果: 结果显示，NMT和LLM输出均存在MTese，原始中文文本与机器翻译输出区分度高。LLM词汇多样性更高，NMT更多使用括号。专用翻译LLM词汇多样性较低但因果连词使用更多。

研究结论: 结论表明，NMT和LLM输出均具有MTese特征，但两者在语言模式上存在差异，且中外开发的LLM无显著区别。

中文摘要: 本研究探讨了机器翻译输出中的语言特征（MTese），重点关注英中新闻文本中未充分研究的语言对。我们构建了一个包含4个子库的大型数据集，并采用全面的五层特征集。随后，应用卡方排名算法进行特征选择，用于分类和聚类任务。研究结果证实，神经机器翻译系统（NMT）和大型语言模型（LLM）的输出中均存在MTese。原始中文文本与LLM和NMT输出几乎完全可区分。机器翻译输出的显著语言模式包括较短的句子长度和更多转折连词的使用。在LLM与NMT的比较中，分类准确率约为70%，LLM表现出更高的词汇多样性，而NMT更多使用括号。此外，专用翻译LLM的词汇多样性较低，但与通用LLM相比，因果连词使用更多。最后，我们发现中外企业开发的LLM之间无显著差异。

</details>


### [89] [Lost at the Beginning of Reasoning](https://arxiv.org/abs/2506.22058)
**中文标题：推理初始阶段的迷失**

*Baohao Liao,Xinyi Chen,Sara Rajaee,Yuhui Xu,Christian Herold,Anders Søgaard,Maarten de Rijke,Christof Monz*

主要分类: cs.CL

摘要简述: 研究发现大语言模型在长链推理中，第一步推理对最终结果影响巨大，错误会导致后续推理质量下降。提出一种高效采样策略，减少推理成本70%且不损失准确性，并引入新基准评估模型自校正能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在复杂推理能力上取得进展，但其在长链推理中的自校正能力仍未被充分研究。近期关于过度思考的研究表明，模型常进行冗余推理。本文旨在揭示第一步推理对最终预测的显著影响，并提出解决方案。

研究方法: 通过实证研究，发现第一步推理对最终预测影响巨大。提出一种高效采样策略，利用奖励模型筛选高质量的第一步推理，丢弃次优步骤。同时，构建新基准以系统评估模型自校正能力。

研究结果: 实验表明，第一步推理的错误会显著降低后续推理质量。提出的采样策略减少推理成本70%且保持准确性。新基准为未来研究提供了评估模型自校正能力的基础。

研究结论: 第一步推理对长链推理至关重要，错误会严重影响结果。提出的方法显著降低推理成本，新基准为模型自校正能力研究提供了工具。

中文摘要: 近年来，大语言模型（LLMs）的进步显著提升了复杂推理能力，尤其是通过扩展的链式推理（CoT）机制，如回溯、自我反思和自我校正。然而，LLMs在长链推理中的自我校正能力仍未被充分研究。近期关于过度思考的研究表明，此类模型常进行不必要的冗余推理。本文通过实证研究发现，第一步推理对最终预测具有不成比例的巨大影响——此阶段的错误会显著降低后续推理质量。这一现象在两种先进的开源推理模型家族（DeepSeek-R1和Qwen3）中均得到验证。为解决此问题，我们提出一种高效采样策略，利用奖励模型筛选并保留高质量的第一步推理，同时丢弃次优步骤，在不损失准确性的情况下将推理成本降低70%。最后，我们引入一个新基准，专门设计包含故意错误的第一步推理步骤，以系统评估模型的自校正能力，为未来LLMs稳健推理研究奠定基础。

</details>


### [90] [MDC-R: The Minecraft Dialogue Corpus with Reference](https://arxiv.org/abs/2506.22062)
**中文标题：MDC-R：带参考的Minecraft对话语料库**

*Chris Madge,Maris Camilleri,Paloma Carretero Garcia,Mladen Karan,Juexi Shao,Prashant Jayannavar,Julian Hough,Benjamin Roth,Massimo Poesio*

主要分类: cs.CL

摘要简述: 本文介绍了《Minecraft对话语料库-参考版》（MDC-R），这是一个补充原始Minecraft对话语料库（MDC）的新语言资源，增加了专家对指代和指示性参考的标注。MDC-R为动态环境中的任务导向多轮对话提供了丰富的语言现象研究素材，并通过定量和定性分析展示了其价值。


<details>
  <summary>详细信息</summary>
研究动机: 原始Minecraft对话语料库（MDC）因其动态环境中的任务导向多轮对话特性，引发了多种标注研究兴趣。本文旨在通过增加指代和指示性参考的专家标注，进一步丰富这一资源，使其成为研究参考表达理解的宝贵工具。

研究方法: 本文详细介绍了对MDC语料库进行指代和指示性参考标注的方法，并通过定量和定性分析对标注结果进行了评估。此外，还通过一项简短实验验证了MDC-R在参考表达理解任务中的实用性。

研究结果: 标注后的MDC-R语料库为研究动态环境中的指代和指示性参考提供了丰富的数据支持。实验结果表明，该语料库在参考表达理解任务中具有显著的应用价值。

研究结论: MDC-R是一个有价值的语言资源，能够支持动态环境中指代和指示性参考的研究。其标注方法和实验结果为进一步研究提供了可靠的基础。

中文摘要: 我们介绍了《带参考的Minecraft对话语料库》（MDC-R）。MDC-R是一种新的语言资源，通过专家对指代和指示性参考的标注，补充了原始的Minecraft对话语料库（MDC）。MDC的任务导向、多轮对话和动态环境特性引发了多种标注研究兴趣，因其产生的有趣语言现象。我们相信，通过增加参考标注，它也能成为一种宝贵的资源。本文讨论了标注方法、生成的语料库，并对数据进行了定量和定性分析。此外，我们还通过一项简短实验展示了该语料库在参考表达理解任务中的实用性。

</details>


### [91] [Involvement drives complexity of language in online debates](https://arxiv.org/abs/2506.22098)
**中文标题：参与度驱动在线辩论中语言的复杂性**

*Eleonora Amadori,Daniele Cirulli,Edoardo Di Martino,Jacopo Nudo,Maria Sahakyan,Emanuele Sangiorgio,Arnaldo Santoro,Simon Zollo,Alessandro Galeazzi,Niccolò Di Marco*

主要分类: cs.CL

摘要简述: 研究分析了Twitter上关于COVID-19、COP26和俄乌战争三大争议话题的语言复杂性，发现用户类型、政治倾向、内容可靠性和情感倾向显著影响语言复杂度，负面和攻击性内容更复杂，且政治立场相似的用户使用共同术语。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体重塑了公共话语，研究用户生成内容的语言特征有助于理解其社会影响。本文旨在探讨Twitter上三大全球争议话题的语言复杂性及其与社会结构的关系。

研究方法: 结合多种文本复杂度指标，分析Twitter上影响力用户的内容，从账户类型、政治倾向、内容可靠性和情感倾向四个维度评估语言使用差异。

研究结果: 研究发现，四个维度均存在显著差异：个人与组织、政治倾向极端与中立、内容可靠性高低之间的语言复杂度不同；负面和攻击性内容更复杂，政治立场相似的用户使用共同术语。

研究结论: 研究揭示了数字平台的社会语言学动态，语言复杂性反映了在线空间的意识形态和社会结构，为理解社交媒体语言与社会关系提供了新视角。

中文摘要: 语言是人类社会的基本特征，随着社会变迁和跨文化互动不断演变。技术进步深刻改变了沟通方式，社交媒体成为融合娱乐内容和复杂社会动态的关键力量。随着这些平台重塑公共话语，分析用户生成内容的语言特征对理解其广泛社会影响至关重要。本文研究了Twitter上影响力用户在COVID-19、COP26和俄乌战争三大全球争议话题中的语言复杂性。通过结合多种文本复杂度指标，我们从账户类型、政治倾向、内容可靠性和情感倾向四个维度评估语言使用差异。分析发现，四个维度均存在显著差异，包括个人与组织之间、政治倾向极端与中立之间、内容可靠性高低之间的语言复杂度差异。此外，产生更多负面和攻击性内容的账户倾向于使用更复杂的语言，政治立场和可靠性相似的用户趋向于使用共同术语。研究结果为数字平台的社会语言学动态提供了新见解，深化了对语言如何反映在线空间意识形态和社会结构的理解。

</details>


### [92] [Identifying a Circuit for Verb Conjugation in GPT-2](https://arxiv.org/abs/2506.22105)
**中文标题：在GPT-2中识别动词变位的电路**

*David Demitri Africa*

主要分类: cs.CL

摘要简述: 研究通过一系列技术手段，在GPT-2 Small模型中分离出负责主谓一致的子网络（“电路”），发现仅需少量网络组件即可完成基础任务，但复杂任务需要更多组件。


<details>
  <summary>详细信息</summary>
研究动机: 旨在理解GPT-2 Small模型如何实现主谓一致的任务，并分离出负责这一功能的子网络，以揭示模型内部的工作机制。

研究方法: 通过性能验证、直接路径修补和直接对数归因等技术，分离出候选电路，并测试其在主谓一致任务中的表现。

研究结果: 结果表明，仅需少量网络组件即可在基础任务中达到接近模型性能，但复杂任务需要更多组件。

研究结论: 研究成功分离出负责主谓一致的子网络，揭示了模型内部的工作机制，并为理解复杂任务中的网络需求提供了依据。

中文摘要: 本研究实施了一种程序，用于分离和解释GPT-2 Small模型中负责主谓一致的子网络（或“电路”）。实验中，模型接收主语为单数（如“Alice”）或复数（如“Alice和Bob”）的提示，任务是正确预测动词形式（单数主语用“walks”，复数主语用“walk”）。通过一系列技术（包括性能验证、直接路径修补和直接对数归因），分离出一个候选电路，该电路对模型的正确动词变位有显著贡献。结果表明，仅需少量网络组件-标记对即可在基础任务中达到接近模型性能，但复杂任务需要更多组件。

</details>


### [93] [DAPFAM: A Domain-Aware Patent Retrieval Dataset Aggregated at the Family Level](https://arxiv.org/abs/2506.22141)
**中文标题：DAPFAM：一个基于家族级别的领域感知专利检索数据集**

*Iliass Ayaou,Denis Cavallucci,Hicham Chibane*

主要分类: cs.CL

摘要简述: 本文提出了DAPFAM，一个基于专利家族级别的领域感知专利检索数据集，解决了现有公开数据集中领域标注、多司法管辖区覆盖、查询领域平衡及计算资源需求等问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有公开专利检索数据集在领域标注、多司法管辖区覆盖、查询领域平衡及计算资源需求等方面存在不足，亟需一个更全面的数据集来支持专利检索研究。

研究方法: 通过三步数据整理流程构建DAPFAM数据集，包含1,247个领域平衡的全文查询家族和45,336个全文目标家族，并基于国际专利分类（IPC）代码进行领域标注。

研究结果: 数据集包含49,869个评估对，支持跨领域专利检索实验，基线实验显示跨领域检索存在显著挑战。

研究结论: DAPFAM数据集填补了专利检索研究中的空白，为跨领域专利检索提供了重要资源，并公开可用。

中文摘要: 在公开可用的专利检索数据集中，领域内和领域外标注、多司法管辖区覆盖、查询领域平衡以及支持中等计算资源下子文档级别实验的可管理规模往往被忽视。为解决这些问题，我们提出了DAPFAM，一个基于简单家族级别的开放访问领域感知专利检索数据集。该数据集包含1,247个领域平衡的全文查询家族和45,336个全文目标家族，并通过明确的关联判断（正向/反向引用作为正链接，随机负样本）以及基于国际专利分类（IPC）代码的新颖标注方案（领域内或领域外关系）进行丰富，共生成49,869个评估对。数据集覆盖多司法管辖区，几乎无需预处理即可用于检索评估，且规模适中，适合资源有限的实体进行子文档级别检索实验而无需过高计算成本。我们描述了三步数据整理流程，提供了全面的数据集统计信息，并使用词汇和神经检索方法进行了基线实验。基线实验凸显了跨领域专利检索的显著挑战。数据集将公开可用（当前访问链接为：https://osf.io/vbyzd/?view_only=1a40242e0d1941a58aa854af3e50cf6b）。

</details>


### [94] [SAGE: Spliced-Audio Generated Data for Enhancing Foundational Models in Low-Resource Arabic-English Code-Switched Speech Recognition](https://arxiv.org/abs/2506.22143)
**中文标题：SAGE：基于拼接音频生成的数据用于增强低资源阿拉伯语-英语语码转换语音识别的基础模型**

*Muhammad Umar Farooq,Oscar Saz*

主要分类: cs.CL

摘要简述: 本文研究了多种语音自监督学习模型在阿拉伯方言（DA）和阿拉伯语-英语语码转换（CS）语音上的表现。为解决数据稀缺问题，提出了一种改进的音频拼接方法生成人工CS语音数据（SAGE）。通过使用SAGE数据微调模型，在阿拉伯语和英语CS基准测试中，词错误率（WER）绝对降低了7.8%。此外，提出了一种基于经验回放（ER）的方法，以增强模型在DA和CS语音上的泛化能力并减轻灾难性遗忘。结合外部3-gram语言模型，平均WER从31.7%降至26.6%。少量样本微调进一步将WER降低了4.9%。最终，在阿拉伯语-英语CS基准测试中，WER达到31.1%，优于大规模多语言模型（如USM和Whisper-large-v2）。


<details>
  <summary>详细信息</summary>
研究动机: 阿拉伯方言（DA）和阿拉伯语-英语语码转换（CS）语音识别面临数据稀缺的挑战，导致现有模型的性能受限。本文旨在通过生成人工数据和改进微调方法，提升模型在这些低资源场景下的表现。

研究方法: 1. 提出改进的音频拼接方法（SAGE）生成人工CS语音数据；2. 使用SAGE数据微调已预训练的语音自监督学习模型；3. 引入基于经验回放（ER）的方法以增强模型泛化能力并减轻灾难性遗忘；4. 结合外部3-gram语言模型优化识别结果；5. 通过少量样本微调进一步提升性能。

研究结果: 1. 使用SAGE数据微调后，阿拉伯语和英语CS基准测试的WER绝对降低了7.8%；2. 结合3-gram语言模型，平均WER从31.7%降至26.6%；3. 少量样本微调进一步将WER降低了4.9%；4. 在阿拉伯语-英语CS基准测试中，WER达到31.1%，优于USM和Whisper-large-v2等大规模模型。

研究结论: 本文提出的SAGE数据和ER方法显著提升了低资源阿拉伯语-英语CS语音识别的性能，证明了生成数据和改进微调策略的有效性。该方法在资源受限场景下具有广泛的应用潜力。

中文摘要: 本文研究了多种语音自监督学习模型在阿拉伯方言（DA）和阿拉伯语-英语语码转换（CS）语音上的表现。为解决数据稀缺问题，提出了一种改进的音频拼接方法以生成人工CS语音数据（SAGE）。通过使用SAGE数据微调已预训练的模型，在阿拉伯语和英语CS基准测试中，词错误率（WER）绝对降低了7.8%。此外，提出了一种基于经验回放（ER）的方法，以增强模型在DA和CS语音上的泛化能力并减轻灾难性遗忘。结合外部3-gram语言模型，平均WER从31.7%降至26.6%。少量样本微调进一步将WER降低了4.9%。最终，在阿拉伯语-英语CS基准测试中，WER达到31.1%，优于USM和Whisper-large-v2等大规模多语言模型。

</details>


### [95] [Training Language Model to Critique for Better Refinement](https://arxiv.org/abs/2506.22157)
**中文标题：训练语言模型进行批评以实现更好的改进**

*Tianshu Yu,Chao Xiang,Mingchuan Yang,Pei Ke,Bosi Wen,Cunxiang Wang,Jiale Cheng,Li Zhang,Xinyu Mu,Chuxiong Sun,Minlie Huang*

主要分类: cs.CL

摘要简述: 本文提出了一种名为RCO的新框架，通过优化批评信号训练批评模型，以提升语言模型的反馈能力，显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）在评估和批评任务中表现出色，但如何生成最有效的批评以改进模型响应仍缺乏研究。本文旨在填补这一空白。

研究方法: RCO框架通过反馈循环生成批评信号，指导模型优化响应。批评效用（CU）量化改进效果，作为训练批评模型的奖励信号。

研究结果: 在对话生成、摘要、问答、数学推理和代码生成五个任务中，RCO在批评质量和改进效果上显著优于传统方法和开源模型。

研究结论: RCO通过基于改进偏好的监督方案，有效提升了LLM的批评-改进循环，为模型优化提供了新思路。

中文摘要: 大型语言模型（LLMs）在评估和批评任务中表现出色，能够提供深刻的反馈并识别各种任务中的缺陷。然而，关于哪些批评类型最有效或如何生成此类批评的研究较少。为解决这一问题，我们提出了	extbf{R}efinement-oriented 	extbf{C}ritique 	extbf{O}ptimization（RCO），一种利用改进信号训练批评模型的新框架。RCO通过反馈循环，由批评模型生成的批评指导行动模型优化其响应。批评效用（CU）量化这些改进的效果，作为训练批评模型的奖励信号。通过专注于能带来更好改进的批评，RCO无需直接评估批评偏好，确保奖励那些推动实质性改进的批评。我们在对话生成、摘要、问答、数学推理和代码生成五个任务中评估RCO，结果显示其在批评质量和改进效果上显著优于传统方法和开源模型。我们的贡献包括引入RCO、基于改进偏好的新型监督方案，以及全面实验结果，证明了该方法在增强LLM批评-改进循环中的有效性。

</details>


### [96] [Leveraging In-Context Learning for Political Bias Testing of LLMs](https://arxiv.org/abs/2506.22232)
**中文标题：利用上下文学习测试LLMs的政治偏见**

*Patrick Haller,Jannis Vamvas,Rico Sennrich,Lena A. Jäger*

主要分类: cs.CL

摘要简述: 本文提出了一种新方法——问卷建模（QM），利用人类调查数据作为上下文示例，以提高基于问题的偏见评估的稳定性，并比较指令调优模型与其基础版本。实验表明，指令调优可能改变偏见方向，且更大模型能更有效利用上下文示例，表现出更小的偏见分数。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通过政治问题查询大型语言模型（LLMs）以评估其潜在偏见，但这种方法稳定性有限，导致模型间比较不可靠。本文认为LLMs需要更多上下文，因此提出新任务以改进评估稳定性。

研究方法: 提出问卷建模（QM）任务，利用人类调查数据作为上下文示例，通过指令调优模型与其基础版本的比较，评估偏见。实验涵盖不同规模的LLMs。

研究结果: QM提高了偏见评估的稳定性，指令调优可能改变偏见方向。更大模型能更有效利用上下文示例，且偏见分数更小。

研究结论: QM方法为偏见评估提供了更稳定的工具，揭示了指令调优和模型规模对偏见的影响。数据和代码已公开。

中文摘要: 越来越多的研究通过政治问题查询大型语言模型（LLMs）以评估其潜在偏见。然而，这种探测方法稳定性有限，导致模型间比较不可靠。本文认为LLMs需要更多上下文，并提出一种新的探测任务——问卷建模（QM），利用人类调查数据作为上下文示例。研究表明，QM提高了基于问题的偏见评估的稳定性，并可用于比较指令调优模型与其基础版本。对不同规模LLMs的实验表明，指令调优确实可能改变偏见方向。此外，我们发现更大模型能更有效利用上下文示例，且通常在QM中表现出更小的偏见分数。数据和代码已公开。

</details>


### [97] [Detection of Personal Data in Structured Datasets Using a Large Language Model](https://arxiv.org/abs/2506.22305)
**中文标题：利用大型语言模型检测结构化数据集中的个人数据**

*Albert Agisha Ntwali,Luca Rück,Martin Heckmann*

主要分类: cs.CL

摘要简述: 本文提出了一种利用GPT-4o检测结构化数据中个人数据的新方法，通过结合上下文信息显著提升了检测性能，尤其在真实世界数据中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前检测结构化数据中个人数据的方法往往忽略上下文信息，导致性能受限。本文旨在通过结合数据集的其他特征名称和描述，提升检测的准确性和鲁棒性。

研究方法: 采用GPT-4o模型，结合特征名称、值以及其他特征名称和数据集描述的上下文信息，检测个人数据。与Microsoft Presidio和CASSED等方法在多个数据集上进行了对比。

研究结果: 实验表明，不同方法在不同数据集上表现差异显著。GPT-4o在真实世界医疗数据集MIMIC-Demo-Ext上表现最佳，而CASSED在其训练数据集DeSSI上表现优异。上下文信息对Kaggle和OpenML数据集的检测效果尤为关键。

研究结论: 未来研究需更多包含个人信息的真实世界数据集以推动领域进展，上下文信息的利用是提升检测性能的关键。

中文摘要: 我们提出了一种利用GPT-4o检测结构化数据中个人数据的新方法。该方法的关键创新在于结合上下文信息：除了特征名称和值外，还利用了数据集的其他特征名称和描述。我们与Microsoft Presidio和CASSED等方法在多个数据集上进行了对比，包括合成数据集DeSSI、从Kaggle和OpenML收集的数据集，以及包含重症监护患者信息的真实数据集MIMIC-Demo-Ext。

研究发现，检测性能因数据集而异。CASSED在其训练数据集DeSSI上表现优异，而所有模型在MIMIC-Demo-Ext上的表现相近，其中基于GPT-4o的方法明显优于其他方法。值得注意的是，在Kaggle和OpenML数据集中，上下文信息显著提升了个人数据检测的效果。CASSED和Presidio（均未利用数据集上下文）表现较差，而基于GPT-4o的方法则取得了优异结果。

我们得出结论，未来研究若能获取更多包含个人信息的真实世界数据集，将极大推动该领域的进展。

</details>


### [98] [Evaluating Scoring Bias in LLM-as-a-Judge](https://arxiv.org/abs/2506.22316)
**中文标题：评估LLM-as-a-Judge中的评分偏差**

*Qingquan Li,Shaoyu Dou,Kailai Shao,Chao Chen,Haixiang Hu*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型（LLM）作为评估工具时的评分偏差问题，提出了一个综合评估框架，并通过实验揭示了现有评估模型的评分稳定性受偏差影响的情况。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在复杂任务评估中的广泛应用（如自然语言处理、偏好学习等），其作为评估工具（LLM-as-a-Judge）的公平性和可靠性受到偏差的负面影响。目前的研究主要集中在基于比较的评估上，而对基于评分的评估中的偏差缺乏系统性研究。

研究方法: 本文定义了LLM-as-a-Judge中的评分偏差，即评分模型在受到与偏差相关的扰动时评分结果的变化，并设计了一个综合评估框架。通过数据合成扩充现有基准数据集，设计了多维度的评估指标。

研究结果: 实验结果表明，现有评估模型的评分稳定性受到评分偏差的显著影响。进一步的探索性实验为评分提示模板的设计和评分偏差的缓解（如评分标准、评分ID和参考答案选择）提供了有价值的见解。

研究结论: 本文揭示了LLM-as-a-Judge中评分偏差的存在及其影响，为未来设计更公平可靠的评估工具提供了重要参考。

中文摘要: 大型语言模型（LLM）的卓越性能催生了“LLM-as-a-Judge”，即LLM被用作复杂任务的评估工具。其在自然语言处理（NLP）、偏好学习及多个特定领域中得到广泛应用。然而，LLM-as-a-Judge中存在多种偏差，影响了评估的公平性和可靠性。目前关于评估或缓解LLM-as-a-Judge中偏差的研究主要集中在基于比较的评估上，而对基于评分的评估中的偏差缺乏系统性研究。因此，我们定义了LLM-as-a-Judge中的评分偏差，即评分模型在受到与偏差相关的扰动时评分结果的变化，并设计了一个综合评估框架。我们通过数据合成扩充了现有基准数据集，并设计了多维度的评估指标。实验结果表明，现有评估模型的评分稳定性受到评分偏差的显著影响。进一步的探索性实验为评分提示模板的设计和评分偏差的缓解（如评分标准、评分ID和参考答案选择）提供了有价值的见解。

</details>


### [99] [Why Are Parsing Actions for Understanding Message Hierarchies Not Random?](https://arxiv.org/abs/2506.22366)
**中文标题：为什么理解消息层次结构的解析行为不是随机的？**

*Daichi Kato,Ryo Ueda,Yusuke Miyao*

主要分类: cs.CL

摘要简述: 研究发现人类语言解析行为并非随机，而是基于特定策略。通过实验调整，验证随机解析策略在复杂输入和引入意外性指标后是否仍能保持高准确性。


<details>
  <summary>详细信息</summary>
研究动机: 人类语言解析行为并非随机，但此前研究表明随机解析策略在某些情况下也能实现高准确性。本研究旨在探讨在更复杂输入和引入意外性指标后，随机解析策略是否仍能保持高效。

研究方法: 研究通过两项调整：(I) 使用具有层次结构的复杂输入，增加随机解析的难度；(II) 在目标函数中引入意外性指标，模拟自然语言中词序和字符顺序的影响。

研究结果: 实验表明，在复杂输入和意外性指标的影响下，随机解析策略的通信准确性显著下降，无法维持高效表现。

研究结论: 人类语言解析行为的非随机性源于其对复杂输入和意外性指标的适应性，随机策略在真实语言环境中难以保持高效。

中文摘要: 如果人类通过随机选择解析行为来理解语言，可能需要构建一个能够在任何层次结构下解释的鲁棒符号系统。然而，人类的解析策略似乎并不遵循这种随机模式。为什么会出现这种情况？事实上，此前一项关于具有层次偏见的模型在涌现通信中的研究表明，采用随机解析策略（即显著偏离人类语言理解的策略）的代理可以实现较高的通信准确性。本研究通过两项简单而自然的实验调整来探讨这一问题：(I) 使用具有层次结构的更复杂输入，使得随机解析对语义解释更具挑战性；(II) 在目标函数中引入意外性相关项，该指标已知会影响自然语言中词和字符的顺序。通过这些调整，我们评估采用随机解析策略的代理是否仍能保持高通信准确性。

</details>


### [100] [QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization](https://arxiv.org/abs/2506.22396)
**中文标题：QuickSilver——通过动态令牌停止、KV缓存跳过、上下文令牌融合和自适应嵌套量化加速LLM推理**

*Danush Khanna,Aditya Kumar Guru,Srivarshinee Sridhar,Zidan Ahmed,Rubhav Bahirwani,Meetu Malhotra,Vinija Jain,Aman Chadha,Amitava Das,Kripabandhu Ghosh*

主要分类: cs.CL

摘要简述: QuickSilver是一种模块化、令牌级框架，通过动态令牌停止、KV缓存跳过、上下文令牌融合和自适应嵌套量化，显著加速LLM推理，无需修改模型权重或结构，实现高达39.6%的FLOP减少且困惑度几乎不变。


<details>
  <summary>详细信息</summary>
研究动机: LLM推理占用了大部分延迟和能耗，现有方法如剪枝、量化和早期退出通常需要重新训练或架构更改。QuickSilver旨在在不改变模型权重或结构的情况下，通过动态语义适应性优化推理效率。

研究方法: QuickSilver结合四种机制：(i)动态令牌停止，对收敛表示的令牌停止计算；(ii)KV缓存跳过，选择性抑制内存写入以减少注意力开销；(iii)上下文令牌融合，将冗余令牌合并以缩短序列长度；(iv)自适应嵌套量化。

研究结果: 在GPT-2和Llama-2上测试WikiText-103和C4数据集，QuickSilver实现了高达39.6%的FLOP减少，困惑度仅增加≤0.2。

研究结论: QuickSilver通过动态令牌级优化显著提升LLM推理效率，无需修改模型或辅助网络，适用于冻结的密集模型。

中文摘要: 推理占大型语言模型（LLM）部署中大部分延迟和能耗，通常超过总成本的90%。尽管训练效率已取得显著进展，运行时优化仍是关键瓶颈，尤其是在自回归解码下。现有方法（如剪枝、量化、早期退出和推测解码）通常需要重新训练、架构更改或破坏解码兼容性。我们提出QuickSilver，一种模块化、令牌级框架，可在不改变模型权重或结构的情况下实现推理时的语义适应性。QuickSilver整合了四种协同机制：(i)动态令牌停止，对收敛表示的令牌停止计算；(ii)KV缓存跳过，选择性抑制内存写入以减少注意力开销；(iii)上下文令牌融合，将冗余令牌合并为共享路径以缩短序列长度。与推测解码或MoE路由不同，QuickSilver完全适用于冻结的密集模型，无需辅助网络。在GPT-2和Llama-2上测试WikiText-103和C4数据集，QuickSilver实现了高达39.6%的FLOP减少，困惑度仅增加≤0.2。

</details>


### [101] [Refining Czech GEC: Insights from a Multi-Experiment Approach](https://arxiv.org/abs/2506.22402)
**中文标题：优化捷克语语法纠错：多实验方法的洞见**

*Petr Pechman,Milan Straka,Jana Straková,Jakub Náplava*

主要分类: cs.CL

摘要简述: 本文提出了一种基于Transformer架构的捷克语语法纠错系统，通过动态生成合成错误句子提升性能，并在多实验中验证其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 捷克语的语法纠错（GEC）系统性能有待提升，本文旨在通过神经机器翻译方法和动态合成错误生成技术，构建一个高效且性能优越的捷克语GEC系统。

研究方法: 采用Transformer架构的神经机器翻译方法，结合动态合成错误生成技术，引入语言无关和捷克语特有的错误。通过多实验验证不同策略，包括语料库选择、错误生成方法、领域平衡、分词粒度、模型大小和微调数据规模。同时评估大型语言模型（LLMs）在捷克语GEC中的表现。

研究结果: 最佳模型在性能和计算效率上均表现出色，优于现有方法。实验还验证了合成错误生成和多实验策略的有效性。

研究结论: 本文提出的捷克语GEC系统通过动态合成错误生成和多实验优化，显著提升了性能和效率，为捷克语语法纠错提供了新的解决方案。

中文摘要: 我们提出了一种基于Transformer架构的神经机器翻译方法，构建了捷克语语法纠错（GEC）系统，其性能达到当前最优水平。该系统的核心特点是实时合成错误生成管道，通过动态引入语言无关和捷克语特有的错误来增强句子。我们进行了一系列全面实验，研究了捷克语GEC语料库作为合成错误生成的基础、多种错误生成策略、领域平衡、分词粒度、模型大小和微调数据规模的影响。此外，我们还评估了大型语言模型（LLMs）在捷克语GEC中的表现，包括终端用户和专家微调场景。我们的最佳模型在性能和计算效率上均表现出色。源代码和训练模型链接可在https://github.com/ufal/tsd2025-gec获取。

</details>


### [102] [HyperCLOVA X THINK Technical Report](https://arxiv.org/abs/2506.22403)
**中文标题：HyperCLOVA X THINK技术报告**

*NAVER Cloud HyperCLOVA X Team*

主要分类: cs.CL

摘要简述: HyperCLOVA X THINK是首个专注于推理的大型语言模型，基于6万亿高质量韩语和英语数据训练，支持128K上下文窗口，并在韩国基准测试中表现优异，同时具备双语一致性和翻译质量。


<details>
  <summary>详细信息</summary>
研究动机: 开发一款专注于推理的大型语言模型，以支持韩语AI创新，并在全球研究社区中提供有价值的资源。

研究方法: 采用计算-内存平衡的Peri-LN Transformer架构，通过三阶段课程学习扩展上下文窗口至128K，并结合监督微调和可验证奖励的强化学习进行后训练。

研究结果: 在KMMLU、CSAT、KoBALT-700等韩国基准测试中表现优异，视觉增强版本在KCSAT STEM测试中达到或超过GPT-4.1水平，且训练计算成本显著低于同类模型。

研究结论: HyperCLOVA X THINK为韩语AI创新提供了坚实基础，并有望成为开源和商业友好的基础模型。

中文摘要: 我们介绍了HyperCLOVA X THINK，这是HyperCLOVA X系列中首个专注于推理的大型语言模型，预训练数据包含约6万亿高质量的韩语和英语标记，并通过针对性合成的韩语数据增强。模型采用计算-内存平衡的Peri-LN Transformer架构，通过μP扩展规模，并通过三阶段课程学习将上下文窗口扩展至128K标记。后训练阶段结合了监督微调和基于可验证奖励的强化学习，支持详细推理和简洁回答模式。在韩国基准测试（如KMMLU、CSAT、KoBALT-700、HAERAE-1.0和KoBigBench）中表现优异，同时保持了稳健的双语一致性和翻译质量。此外，视觉增强版本在KCSAT STEM测试中达到或超过GPT-4.1水平，且训练计算成本显著低于同类模型。我们还提出了一种剪枝和蒸馏技术，将很快应用于HyperCLOVA X THINK，以打造开源且商业友好的基础模型。这些能力使HyperCLOVA X THINK成为韩语AI创新的坚实基础，并为全球研究社区提供了宝贵资源。

</details>


### [103] [Sequential Diagnosis with Language Models](https://arxiv.org/abs/2506.22405)
**中文标题：基于语言模型的序列诊断**

*Harsha Nori,Mayank Daswani,Christopher Kelly,Scott Lundberg,Marco Tulio Ribeiro,Marc Wilson,Xiaoxuan Liu,Viknesh Sounderajah,Jonathan Carlson,Matthew P Lungren,Bay Gross,Peter Hames,Mustafa Suleyman,Dominic King,Eric Horvitz*

主要分类: cs.CL

摘要简述: 本文提出了一种基于语言模型的迭代诊断方法，通过模拟临床医生的逐步推理过程，显著提高了诊断准确性和成本效益。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型在医学诊断中的评估多基于静态案例和选择题，无法反映真实临床环境中基于证据的复杂推理过程。本文旨在模拟医生逐步提出和修正诊断假设的过程，以提升诊断的精确性和经济性。

研究方法: 研究引入了Sequential Diagnosis Benchmark，将304个具有挑战性的NEJM-CPC案例转化为逐步诊断任务。同时提出了MAI-DxO模型，模拟医生团队，提出可能的诊断假设并选择高价值、低成本的测试。

研究结果: MAI-DxO与OpenAI的o3模型结合时，诊断准确率达到80%，远超普通医生的20%。此外，MAI-DxO将诊断成本降低了20%（相比医生）和70%（相比直接使用o3）。在追求最高准确率时，MAI-DxO的准确率达到85.5%。

研究结论: 研究表明，通过引导AI系统进行迭代思考和审慎行动，可以显著提升临床诊断的精确性和成本效益。

中文摘要: 人工智能在扩展专家医学知识和推理方面具有巨大潜力。然而，大多数语言模型的评估依赖于静态案例和选择题，未能反映真实临床环境中基于证据的医学复杂性和细微差别。在临床实践中，医生会逐步提出和修正诊断假设，根据已获取的信息调整后续问题和测试，并在最终诊断前权衡不断演变的证据。为模拟这一迭代过程，我们引入了Sequential Diagnosis Benchmark，将304个具有挑战性的《新英格兰医学杂志》临床病理会议（NEJM-CPC）案例转化为逐步诊断任务。医生或AI从简短的案例摘要开始，必须逐步向一个守门员模型请求更多细节，该模型仅在明确查询时揭示发现。性能评估不仅基于诊断准确性，还包括医生访问和测试的成本。我们还提出了MAI Diagnostic Orchestrator（MAI-DxO），一种模型无关的协调器，模拟医生团队，提出可能的鉴别诊断，并策略性地选择高价值、低成本的测试。当与OpenAI的o3模型配对时，MAI-DxO实现了80%的诊断准确率——是普通医生平均20%的四倍。MAI-DxO还将诊断成本降低了20%（相比医生）和70%（相比直接使用o3）。在追求最高准确率时，MAI-DxO的准确率达到85.5%。这些性能提升在OpenAI、Gemini、Claude、Grok、DeepSeek和Llama家族的模型中均具有普适性。我们强调，当引导AI系统进行迭代思考和审慎行动时，可以显著提升临床诊断的精确性和成本效益。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [104] [Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs](https://arxiv.org/abs/2506.21656)
**中文标题：细粒度偏好优化提升视觉语言模型的空间推理能力**

*Yifan Shen,Yuanzhe Liu,Jingyuan Zhu,Xu Cao,Xiaofeng Zhang,Yixiao He,Wenming Ye,James Matthew Rehg,Ismini Lourentzou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SpatialReasoner-R1的视觉语言推理模型，通过多模型蒙特卡洛树搜索（M3CTS）生成高质量的长链思维推理轨迹，并引入细粒度直接偏好优化（fDPO）提升空间推理能力。实验表明，fDPO在空间质量和数量任务上分别提升4.1%和9.0%，模型在SPATIALRGPT-Bench上刷新了最高性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前的视觉语言模型（VLMs）在细粒度空间推理任务中表现不佳，尤其是在需要多步逻辑和精确空间对齐的场景下。本文旨在解决这一问题，提升模型的空间推理能力。

研究方法: 1. 设计多模型蒙特卡洛树搜索（M3CTS）方法，生成多样且逻辑一致的长链思维推理轨迹。2. 提出细粒度直接偏好优化（fDPO），通过段特异性偏好粒度和空间奖励机制（评估视觉一致性、空间对齐和逻辑连贯性）优化模型。

研究结果: fDPO在空间质量任务上平均提升4.1%，在空间数量任务上提升9.0%。SpatialReasoner-R1在SPATIALRGPT-Bench上的平均准确率比最强基线高9.8%，同时在通用视觉语言任务中保持竞争力。

研究结论: 通过M3CTS和fDPO的结合，SpatialReasoner-R1显著提升了细粒度空间推理能力，成为新的性能标杆，同时不影响通用任务的性能。

中文摘要: 当前的视觉语言模型（VLMs）在细粒度空间推理任务中表现不佳，尤其是在需要多步逻辑和精确空间对齐的场景下。为此，我们提出了SpatialReasoner-R1，一种专为解决这些限制而设计的视觉语言推理模型。为了构建高质量的空间推理监督数据，我们设计了一种多模型蒙特卡洛树搜索（M3CTS）方法，能够生成多样且逻辑一致的长链思维推理轨迹。此外，我们提出了细粒度直接偏好优化（fDPO），通过段特异性偏好粒度和空间奖励机制（评估视觉一致性、空间对齐和逻辑连贯性）优化模型。实验结果表明，fDPO在空间质量任务上平均提升4.1%，在空间数量任务上提升9.0%。使用fDPO训练的SpatialReasoner-R1在SPATIALRGPT-Bench上刷新了最高性能，平均准确率比最强基线高9.8%，同时在通用视觉语言任务中保持竞争力。

</details>


### [105] [TanDiT: Tangent-Plane Diffusion Transformer for High-Quality 360° Panorama Generation](https://arxiv.org/abs/2506.21681)
**中文标题：TanDiT：基于切平面扩散变换器的高质量360°全景生成**

*Hakan Çapuk,Andrew Bond,Muhammed Burak Kızıl,Emir Göçen,Erkut Erdem,Aykut Erdem*

主要分类: cs.CV

摘要简述: TanDiT是一种用于高质量360°全景图像生成的新方法，通过生成覆盖全景的切平面图像网格，解决了现有模型在全景生成中的几何失真和一致性难题。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像生成模型在合成全景图像时面临几何失真和循环一致性的挑战，TanDiT旨在通过创新方法克服这些问题，同时利用现有模型的优势。

研究方法: TanDiT采用统一的扩散模型，在单次去噪迭代中同时生成覆盖360°视图的切平面图像网格，并提出一种模型无关的后处理步骤以增强全局一致性。

研究结果: 实验表明，TanDiT能有效泛化到训练数据之外，准确解析复杂文本提示，并与多种生成模型无缝集成，生成高质量、多样化的全景图像。

研究结论: TanDiT为全景图像生成提供了一种高效且通用的解决方案，显著提升了生成质量和多样性。

中文摘要: 近年来，图像生成技术的进步显著提升了透视图像的合成质量。然而，这些模型在全景图像生成中仍面临独特挑战，包括不同程度的几何失真和循环一致性的要求。为解决这些问题并充分利用现有模型的优势，我们提出了TanDiT，该方法通过生成覆盖360°视图的切平面图像网格来合成全景场景。与以往依赖多个扩散分支的方法不同，TanDiT采用统一的扩散模型，在单次去噪迭代中同时生成这些切平面图像。此外，我们还提出了一种模型无关的后处理步骤，专门用于增强生成全景的全局一致性。为准确评估全景图像质量，我们提出了两种专用指标TangentIS和TangentFID，并提供了一个包含标注全景数据集和标准化评估脚本的综合基准。大量实验表明，我们的方法能有效泛化到训练数据之外，稳健解析复杂文本提示，并与多种生成模型无缝集成，生成高质量、多样化的全景图像。

</details>


### [106] [FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual Question Answering](https://arxiv.org/abs/2506.21710)
**中文标题：FOCUS：基于多模态大语言模型内部表示的高效细粒度视觉问答方法**

*Liangyu Zhong,Fabio Rosenthal,Joachim Sicking,Fabian Hüger,Thorsten Bagdonat,Hanno Gottschalk,Leo Schwinn*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的视觉裁剪方法FOCUS，利用多模态大语言模型（MLLM）内部表示指导图像区域搜索，显著提升了细粒度视觉问答（VQA）的性能和效率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在图像-文本输入上表现出强大的感知和推理能力，但在关注图像细节的细粒度视觉问答（VQA）任务中仍面临挑战。现有的视觉裁剪方法存在任务特定微调需求、低效的盲目搜索或与高效注意力实现不兼容等问题。

研究方法: FOCUS方法分为四步：1) 识别VQA提示中的目标对象；2) 使用键值（KV）缓存计算对象相关性图；3) 基于相关性图提出并排序相关图像区域；4) 使用排名最高的区域执行细粒度VQA任务。

研究结果: FOCUS在四个细粒度VQA数据集和两种MLLM上表现出色，在准确性和效率上优于三种流行的视觉裁剪方法，并与性能最佳的基线方法ZoomEye相当，同时计算量减少3至6.5倍。

研究结论: FOCUS通过利用MLLM内部表示指导图像区域搜索，显著提升了细粒度VQA任务的性能和效率，为无需训练的视觉裁剪方法提供了新思路。

中文摘要: 尽管多模态大语言模型（MLLMs）在图像-文本输入上展现出强大的感知和推理能力，但在关注图像细节的细粒度视觉问答（VQA）任务中仍存在挑战。尽管视觉裁剪技术前景广阔，但现有方法存在任务特定微调需求、低效的盲目搜索或与高效注意力实现不兼容等问题。为解决这些问题，我们提出了一种无需训练的视觉裁剪方法FOCUS，该方法利用MLLM内部表示指导搜索最相关的图像区域。具体分为四步：首先，识别VQA提示中的目标对象；其次，使用键值（KV）缓存计算对象相关性图；第三，基于相关性图提出并排序相关图像区域；最后，使用排名最高的区域执行细粒度VQA任务。通过这种有指导的搜索策略，FOCUS在四个细粒度VQA数据集和两种MLLM上表现出色，在准确性和效率上优于三种流行的视觉裁剪方法，并与性能最佳的基线方法ZoomEye相当，同时计算量减少3至6.5倍。

</details>


### [107] [CAST: Cross-Attentive Spatio-Temporal feature fusion for Deepfake detection](https://arxiv.org/abs/2506.21711)
**中文标题：CAST：基于交叉注意力的时空特征融合用于Deepfake检测**

*Aryan Thakre,Omkar Nagwekar,Vedang Talekar,Aparna Santra Biswas*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CAST的模型，通过交叉注意力机制融合时空特征，显著提升了Deepfake检测的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: Deepfake技术对数字媒体真实性构成严重威胁，现有方法在时空特征融合上存在局限性，无法充分捕捉时间演变的细微伪影。

研究方法: CAST模型采用交叉注意力机制，动态融合CNN提取的空间特征和Transformer建模的时间特征，增强了对时间依赖性伪影（如闪烁的眼睛或扭曲的嘴唇）的检测能力。

研究结果: 在FaceForensics++、Celeb-DF和DeepfakeDetection数据集上，CAST模型在内部测试中达到99.49%的AUC和97.57%的准确率，跨数据集测试中在DeepfakeDetection上达到93.31%的AUC，表现出优异的泛化能力。

研究结论: 交叉注意力机制显著提升了时空特征的融合效果，为Deepfake检测提供了更鲁棒和精确的解决方案。

中文摘要: Deepfake已成为数字媒体真实性的重大威胁，亟需能够识别细微且时间依赖性伪影的先进检测技术。CNN擅长捕捉空间伪影，而Transformer擅长建模时间不一致性。然而，现有许多CNN-Transformer模型独立处理时空特征，尤其是基于注意力的方法通常对时空特征使用分离的注意力机制，并通过简单方法（如平均、加法或拼接）结合，限制了时空交互的深度。为解决这一问题，我们提出了一种统一的CAST模型，利用交叉注意力更有效地融合时空特征。该方法使时间特征能够动态关注相关空间区域，增强模型检测时间演变伪影（如闪烁的眼睛或扭曲的嘴唇）的能力。这种设计实现了更精确的定位和更深层次的上下文理解，从而在多样化和挑战性场景中提升了性能。我们在FaceForensics++、Celeb-DF和DeepfakeDetection数据集上评估模型性能，验证了方法的优越性。模型在内部测试中达到99.49%的AUC和97.57%的准确率，在跨数据集测试中对未见过的DeepfakeDetection数据集达到93.31%的AUC，展现了出色的泛化能力。这些结果凸显了基于交叉注意力的特征融合在提升Deepfake视频检测鲁棒性方面的有效性。

</details>


### [108] [Elucidating and Endowing the Diffusion Training Paradigm for General Image Restoration](https://arxiv.org/abs/2506.21722)
**中文标题：阐明并赋能扩散训练范式用于通用图像修复**

*Xin Lu,Xueyang Fu,Jie Xiao,Zihao Fan,Yurui Zhu,Zheng-Jun Zha*

主要分类: cs.CV

摘要简述: 本文通过系统分析时间步依赖、网络层次、噪声级别关系和多任务关联，提出了一种基于扩散训练的通用图像修复框架，并引入正则化策略和增量训练范式，显著提升了单任务和多任务图像修复的性能。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在图像修复任务中表现出强大的生成能力，但其复杂的架构和迭代过程限制了实际应用。现有方法主要关注网络架构和扩散路径优化，忽视了扩散训练范式在通用图像修复框架中的整合。

研究方法: 通过分析时间步依赖、网络层次、噪声级别关系和多任务关联，提出了一种新的基于扩散训练的通用图像修复框架，并引入正则化策略和任务特定适配器，以提升单任务和多任务的性能。

研究结果: 实验表明，该方法显著提升了单任务图像修复的泛化能力，并在多任务统一修复中实现了优越性能，且能无缝集成到现有通用图像修复架构中。

研究结论: 本文提出的框架通过整合扩散训练范式，有效提升了图像修复网络的性能，为通用图像修复任务提供了新的解决方案。

中文摘要: 尽管扩散模型在图像修复（IR）任务中展现出强大的生成能力，但其复杂的架构和迭代过程限制了其在实际应用中的普及，与主流的基于重建的通用普通IR网络相比。现有方法主要关注优化网络架构和扩散路径，但忽视了扩散训练范式在通用普通IR框架中的整合。为解决这些问题，本文通过系统分析时间步依赖、网络层次、噪声级别关系和多修复任务关联，阐明了将扩散训练范式适配到通用IR训练的关键原则，并提出了一种基于扩散训练的新型IR框架。为了使IR网络能够同时修复图像并建模生成表示，我们引入了一系列正则化策略，将扩散目标与IR任务对齐，从而提升单任务场景下的泛化能力。此外，认识到基于扩散的生成对不同IR任务的影响各异，我们开发了一种增量训练范式和任务特定适配器，进一步提升了多任务统一IR的性能。实验表明，我们的方法显著提升了IR网络在单任务IR中的泛化能力，并在多任务统一IR中实现了优越性能。值得注意的是，所提出的框架可以无缝集成到现有的通用IR架构中。

</details>


### [109] [Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning](https://arxiv.org/abs/2506.21724)
**中文标题：非对称双自蒸馏用于3D自监督表示学习**

*Remco F. Leijenaar,Hamidreza Kasaei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为AsymDSD的非对称双自蒸馏框架，用于3D自监督表示学习，通过潜在空间预测统一掩码建模和不变性学习，显著提升了语义表示能力。


<details>
  <summary>详细信息</summary>
研究动机: 在缺乏大规模标注数据集的情况下，如何从无结构的3D点云中学习具有语义意义的表示是计算机视觉领域的核心挑战。现有的掩码点建模（MPM）方法因其基于重建的目标，可能限制了对高层语义的捕捉能力。

研究方法: AsymDSD采用联合嵌入架构，引入多项关键设计：高效的非对称设置、禁用掩码查询间的注意力以防止形状泄露、多掩码采样以及点云的多裁剪适应。

研究结果: AsymDSD在ScanObjectNN上达到90.53%的准确率，并在930k形状上预训练后进一步提升至93.72%，超越了现有方法。

研究结论: AsymDSD通过潜在空间预测统一掩码建模和不变性学习，显著提升了3D自监督表示学习的性能，为无监督学习提供了新的思路。

中文摘要: 从无结构的3D点云中学习具有语义意义的表示是计算机视觉领域的核心挑战，尤其是在缺乏大规模标注数据集的情况下。尽管掩码点建模（MPM）在自监督3D学习中广泛应用，但其基于重建的目标可能限制了对高层语义的捕捉能力。我们提出了AsymDSD，一种非对称双自蒸馏框架，通过在潜在空间而非输入空间进行预测，统一了掩码建模和不变性学习。AsymDSD基于联合嵌入架构，并引入了多项关键设计：高效的非对称设置、禁用掩码查询间的注意力以防止形状泄露、多掩码采样以及点云的多裁剪适应。AsymDSD在ScanObjectNN上达到了90.53%的准确率，并在930k形状上预训练后进一步提升至93.72%，超越了现有方法。

</details>


### [110] [Exploring Image Generation via Mutually Exclusive Probability Spaces and Local Correlation Hypothesis](https://arxiv.org/abs/2506.21731)
**中文标题：通过互斥概率空间与局部相关性假设探索图像生成**

*Chenqiu Zhao,Anup Basu*

主要分类: cs.CV

摘要简述: 本文提出两种理论框架MESP和LCH，探讨概率生成模型的局限性，即全局分布学习导致记忆而非生成行为。通过二进制潜在自编码器和改进的自回归模型，实验验证了假设。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于发现变分自编码器（VAE）中潜在变量分布的重叠问题，导致重构损失与KL散度损失的优化冲突，从而提出MESP框架。进一步提出LCH假设，探讨局部相关性对生成能力的影响。

研究方法: 方法包括：1) 提出MESP框架，基于重叠系数提出下界；2) 设计二进制潜在自编码器（BL-AE）将图像编码为二进制潜在表示；3) 改进自回归模型（ARVM）输出直方图，结合LCH假设验证局部相关性的作用。

研究结果: 实验结果显示，ARVM在标准数据集上取得了竞争性的FID分数，优于现有方法。然而，这些分数反映的是记忆而非生成能力。LCH假设通过局部相关性验证了生成能力的提升。

研究结论: 结论表明，全局分布学习可能导致记忆问题，而局部相关性（LCH）是提升生成能力的关键。MESP和LCH为生成模型的设计提供了新的理论支持。

中文摘要: 我们提出了两种理论框架——互斥概率空间（MESP）和局部相关性假设（LCH），以探讨概率生成模型的潜在局限性，即学习全局分布会导致记忆而非生成行为。MESP源于对变分自编码器（VAE）的重新思考。我们发现VAE中的潜在变量分布存在重叠，导致重构损失与KL散度损失之间的优化冲突。基于重叠系数，提出了一个下界，并将此现象称为互斥概率空间。基于MESP，我们提出了一种二进制潜在自编码器（BL-AE），将图像编码为二进制潜在表示。这些二进制潜在变量作为改进的自回归模型（ARVM）的输入，该模型输出直方图。我们的ARVM在标准数据集上取得了竞争性的FID分数，优于现有方法。然而，这些分数反映的是记忆而非生成能力。为解决这一问题，我们提出了局部相关性假设（LCH），认为生成能力源于潜在变量之间的局部相关性。通过全面的实验和讨论，验证了我们的框架。

</details>


### [111] [Equitable Federated Learning with NCA](https://arxiv.org/abs/2506.21735)
**中文标题：基于NCA的公平联邦学习**

*Nick Lemke,Mirko Konstantin,Henry John Krumb,John Kalkhof,Jonathan Stieber,Anirban Mukhopadhyay*

主要分类: cs.CV

摘要简述: 联邦学习（FL）在医疗影像分割任务中面临资源限制和网络不稳定问题，FedNCA系统通过轻量级Med-NCA架构和低通信成本设计，为低收入国家提供高效、安全的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 低收入和中等收入国家（LMICs）由于高性能计算资源有限和网络连接不稳定，联邦学习的应用面临挑战。本文旨在为这些地区提供一种轻量级、高效且安全的医疗影像分割解决方案。

研究方法: 提出FedNCA系统，基于轻量级Med-NCA架构，支持在低成本边缘设备（如智能手机）上训练，同时减少通信开销，并具备加密能力以适应不稳定的网络环境。

研究结果: FedNCA成功克服了基础设施和安全挑战，为资源受限地区提供了高效、轻量级且支持加密的医疗影像解决方案。

研究结论: FedNCA为资源受限地区提供了包容性、高效且安全的医疗影像解决方案，推动了医疗公平性。

中文摘要: 联邦学习（FL）使得无需共享敏感患者数据的跨机构协作模型训练成为可能，这种方法在低收入和中等收入国家（LMICs）尤为重要，因为这些地区缺乏专业医疗人员。然而，FL在LMICs的应用面临高性能计算资源有限和网络连接不稳定等障碍。为解决这些问题，我们提出了FedNCA，一种专为医疗影像分割任务设计的联邦学习系统。FedNCA利用轻量级Med-NCA架构，支持在低成本边缘设备（如智能手机）上训练，同时最小化通信成本。此外，FedNCA具备加密能力，适合在不稳定的网络环境中使用。通过克服基础设施和安全挑战，FedNCA为资源受限地区提供了包容、高效、轻量级且支持加密的医疗影像解决方案，推动了医疗公平性。

</details>


### [112] [ImplicitQA: Going beyond frames towards Implicit Video Reasoning](https://arxiv.org/abs/2506.21742)
**中文标题：ImplicitQA：超越帧的隐式视频推理**

*Sirnam Swetha,Rohit Gupta,Parth Parag Kulkarni,David G Shatwell,Jeffrey A Chan Santiago,Nyle Siddiqui,Joseph Fioresi,Mubarak Shah*

主要分类: cs.CV

摘要简述: 本文提出了ImplicitQA，一个专注于测试视频问答模型中隐式推理能力的新基准数据集，包含1K高质量标注的问答对，揭示了现有模型在隐式推理任务上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频问答（Video QA）研究主要关注基于显式视觉内容的问题，而忽略了需要隐式推理的复杂场景（如电影、电视剧等）。人类擅长通过隐式推理理解叙事，但现有模型在此方面表现不佳。本文旨在填补这一空白。

研究方法: 作者构建了ImplicitQA数据集，包含320+高质量创意视频片段和1K精心标注的问答对，涵盖空间推理、因果关系、社交互动等多个隐式推理维度。数据集设计具有挑战性，旨在测试模型的深度理解能力。

研究结果: 实验表明，主流视频问答模型在ImplicitQA上表现显著下降，凸显其对表面视觉线索的依赖和隐式推理的困难。不同模型的表现差异进一步反映了任务的复杂性。

研究结论: ImplicitQA为视频问答领域提供了首个专注于隐式推理的基准，揭示了现有模型的局限性，并推动了未来研究的发展。

中文摘要: 视频问答（Video QA）通过多模态学习在视觉和文本对齐方面取得了显著进展。然而，当前基准主要关注可通过显式视觉内容（如动作、物体和事件）回答的问题，而忽略了需要隐式推理的创意和叙事视频（如电影和电视剧）。人类擅长通过隐式推理填补缺失信息，但现有系统和基准未能捕捉这一能力。为此，我们提出了ImplicitQA，一个专门测试隐式推理的新基准。它包含1K高质量标注的问答对，源自320+创意视频片段，涵盖空间推理、因果关系、社交互动等关键维度。实验表明，主流视频问答模型在ImplicitQA上表现不佳，凸显了隐式推理的挑战性。我们希望通过发布数据集和标注框架，推动社区进一步研究。

</details>


### [113] [Early Glaucoma Detection using Deep Learning with Multiple Datasets of Fundus Images](https://arxiv.org/abs/2506.21770)
**中文标题：基于多数据集眼底图像的深度学习早期青光眼检测**

*Rishiraj Paul Chowdhury,Nirmit Shekar Karkera*

主要分类: cs.CV

摘要简述: 本文提出了一种基于EfficientNet-B0架构的深度学习流程，用于从视网膜眼底图像中检测青光眼，通过多数据集训练提升泛化能力，实验表明其具有较高的AUC-ROC值和临床潜力。


<details>
  <summary>详细信息</summary>
研究动机: 青光眼是不可逆失明的主要原因，早期检测对治疗效果至关重要。传统诊断方法通常具有侵入性且依赖专业设备，因此需要一种非侵入性且高效的检测方法。

研究方法: 采用EfficientNet-B0架构，通过ACRIMA、ORIGA和RIM-ONE多个数据集进行顺序训练和微调，以增强模型的泛化能力。实验中对预处理方法进行了优化，发现简单预处理效果更佳。

研究结果: 实验结果显示，该模型在未见数据集上表现出色，AUC-ROC值较高，且预处理复杂度较低时性能更优。

研究结论: 提出的深度学习流程具有可重复性和可扩展性，为青光眼早期检测提供了潜在的临床实用工具。

中文摘要: 青光眼是导致不可逆失明的主要原因，但早期检测可显著改善治疗效果。传统诊断方法通常具有侵入性且需要专业设备。本研究提出了一种基于EfficientNet-B0架构的深度学习流程，用于从视网膜眼底图像中检测青光眼。与以往依赖单一数据集的研究不同，我们通过ACRIMA、ORIGA和RIM-ONE数据集对模型进行顺序训练和微调，以提升泛化能力。实验表明，简单的预处理方法比复杂的增强方法具有更高的AUC-ROC值，且模型在未见数据集上表现出较强的判别性能。该流程为青光眼早期检测提供了一种可重复且可扩展的方法，具有潜在的临床实用价值。

</details>


### [114] [Comparing Learning Paradigms for Egocentric Video Summarization](https://arxiv.org/abs/2506.21785)
**中文标题：比较学习范式在自我中心视频摘要中的应用**

*Daniel Wen*

主要分类: cs.CV

摘要简述: 本研究比较了监督学习、无监督学习和提示微调在自我中心视频摘要中的表现，发现通用模型GPT-4o优于专用模型，凸显了当前方法在适应第一人称视角时的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 探讨不同计算机视觉范式在自我中心视频数据中的表现，推动针对第一人称视角的模型发展。

研究方法: 评估了监督学习模型Shotluck Holmes、无监督学习模型TAC-SUM和提示微调模型GPT-4o在Ego-Exo4D数据集上的表现。

研究结果: 当前最先进模型在第一人称视频中表现较差，而通用模型GPT-4o优于专用模型。

研究结论: 需进一步改进现有方法以适应自我中心视频的独特挑战，提示微调模型展现了潜力。

中文摘要: 本研究通过评估监督学习、无监督学习和提示微调在自我中心视频数据中的表现，探讨了不同计算机视觉范式的适用性。具体分析了Shotluck Holmes（监督学习）、TAC-SUM（无监督学习）和GPT-4o（提示微调预训练模型）在视频摘要中的效果。结果表明，当前最先进模型在第一人称视频中表现不如第三人称视频，凸显了该领域的改进需求。值得注意的是，通用模型GPT-4o优于专用模型，揭示了现有方法在适应第一人称视角时的局限性。尽管由于资源限制，实验仅在Ego-Exo4D数据集的少量视频上进行，但本研究旨在为自我中心视频的计算机视觉技术应用提供概念验证分析。通过探索新方法并评估其潜力，我们希望能推动有效处理自我中心视角的模型发展。

</details>


### [115] [CAT-SG: A Large Dynamic Scene Graph Dataset for Fine-Grained Understanding of Cataract Surgery](https://arxiv.org/abs/2506.21813)
**中文标题：CAT-SG：用于白内障手术细粒度理解的大规模动态场景图数据集**

*Felix Holm,Gözde Ünver,Ghazal Ghazaei,Nassir Navab*

主要分类: cs.CV

摘要简述: 本文介绍了首个白内障手术场景图数据集CAT-SG，用于捕捉手术中工具、组织和技术的复杂交互关系，并提出了一种新的场景图生成模型CatSGG，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有数据集仅关注手术分析的孤立方面（如工具检测或阶段分割），缺乏对实体间语义关系和时间依赖性的全面表示。因此，需要一种能够全面描述白内障手术工作流程的数据集。

研究方法: 提出了CAT-SG数据集，包含工具-组织交互、程序变化和时间依赖性的结构化标注。同时，开发了一种新的场景图生成模型CatSGG，用于生成结构化手术表示。

研究结果: CAT-SG数据集提供了手术工作流程的整体视图，显著提高了手术阶段和技术的识别准确性。CatSGG模型在生成结构化手术表示方面优于现有方法。

研究结论: CAT-SG数据集和CatSGG模型为AI驱动的手术培训、实时决策支持和流程分析提供了基础，推动了临床实践中更智能、上下文感知系统的发展。

中文摘要: 理解白内障手术的复杂工作流程需要建模手术工具、解剖结构和程序技术之间的复杂交互。现有数据集主要关注手术分析的孤立方面（如工具检测或阶段分割），但缺乏捕捉实体间语义关系和时间依赖性的全面表示。本文介绍了白内障手术场景图（CAT-SG）数据集，首次提供了工具-组织交互、程序变化和时间依赖性的结构化标注。通过纳入详细的语义关系，CAT-SG提供了手术工作流程的整体视图，从而更准确地识别手术阶段和技术。此外，我们提出了一种新的场景图生成模型CatSGG，在生成结构化手术表示方面优于现有方法。CAT-SG数据集旨在增强AI驱动的手术培训、实时决策支持和流程分析，为临床实践中更智能、上下文感知系统的发展铺平道路。

</details>


### [116] [Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models](https://arxiv.org/abs/2506.21826)
**中文标题：基于视觉基础模型线性探测的少样本历史地图分割**

*Rafael Sterzinger,Marco Peer,Robert Sablatnig*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉基础模型的少样本历史地图分割方法，通过线性探测和参数高效微调，显著提升了分割性能，尤其在低数据量（5-shot和10-shot）场景下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 历史地图是重要的历史资源，但其多样的视觉表现形式和有限的标注数据给自动化处理带来了挑战。本文旨在通过少样本学习方法，减少对大量标注数据的依赖，同时提升分割精度。

研究方法: 方法结合了大型视觉基础模型的丰富语义嵌入和参数高效微调技术，通过线性探测实现少样本历史地图分割。

研究结果: 在Siegfried基准数据集上，本文方法在葡萄园和铁路分割任务中分别实现了5%和13%的相对mIoU提升，5-shot场景下提升约20%。在ICDAR 2021竞赛数据集上，建筑区块分割的平均PQ达到67.3%，且仅需689k可训练参数（占模型总大小的0.21%）。

研究结论: 本文方法在极低数据量（5-shot和10-shot）下仍保持高性能，显著减少了对人工标注的需求，推动了历史地图自动化处理与分析的发展。

中文摘要: 作为丰富的历史资源，地图为历史变迁提供了重要洞察，但其多样的视觉表现形式和有限的标注数据为自动化处理带来了巨大挑战。我们提出了一种简单而有效的少样本历史地图分割方法，利用大型视觉基础模型的丰富语义嵌入结合参数高效微调技术。在Siegfried基准数据集上，我们的方法在葡萄园和铁路分割任务中表现优异，10-shot场景下mIoU分别提升了5%和13%，而在更具挑战性的5-shot场景下提升了约20%。此外，在ICDAR 2021竞赛数据集上，尽管未针对形状敏感的PQ指标进行优化，我们的方法在建筑区块分割任务中仍取得了67.3%的平均PQ，展现了其良好的泛化能力。值得注意的是，我们的方法在极低数据量（10-shot和5-shot）下仍保持高性能，且仅需689k可训练参数（占模型总大小的0.21%）。该方法能够精确分割多样化的历史地图，同时大幅减少对人工标注的需求，推动了该领域的自动化处理与分析。我们的实现代码已公开于：https://github.com/RafaelSterzinger/few-shot-map-segmentation。

</details>


### [117] [TaleForge: Interactive Multimodal System for Personalized Story Creation](https://arxiv.org/abs/2506.21832)
**中文标题：TaleForge：个性化故事创作的交互式多模态系统**

*Minh-Loi Nguyen,Quang-Khai Le,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: TaleForge是一个结合大型语言模型和文本到图像扩散技术的个性化故事生成系统，通过将用户的面部图像嵌入叙事和插图中，提升参与感和沉浸感。


<details>
  <summary>详细信息</summary>
研究动机: 现有的故事生成方法通常将用户视为被动消费者，提供有限的个性化内容，降低了参与度和沉浸感。TaleForge旨在通过个性化文本和图像结合，创造更具吸引力的用户体验。

研究方法: TaleForge包含三个模块：故事生成（利用大型语言模型根据用户提示生成叙事和角色描述）、个性化图像生成（将用户面部和服装选择融入角色插图）、背景生成（创建包含个性化角色的场景背景）。

研究结果: 用户研究表明，当用户成为故事主角时，参与感和归属感显著提升。参与者赞赏系统的实时预览和直观控制，但也希望有更精细的叙事编辑工具。

研究结论: TaleForge通过个性化文本和图像的结合，推动了多模态故事叙述的发展，创造了更具沉浸感和用户中心化的体验。

中文摘要: 讲故事是一个极具个人化和创造性的过程，但现有方法通常将用户视为被动消费者，提供有限的个性化情节，这削弱了参与感和沉浸感，尤其是在个人风格或外貌至关重要的场景中。我们介绍了TaleForge，一个结合大型语言模型（LLMs）和文本到图像扩散技术的个性化故事生成系统，将用户的面部图像嵌入叙事和插图中。TaleForge包含三个相互关联的模块：故事生成（LLMs根据用户提示生成叙事和角色描述）、个性化图像生成（将用户面部和服装选择融入角色插图）、背景生成（创建包含个性化角色的场景背景）。用户研究表明，当用户成为主角时，参与感和归属感显著提升。参与者赞赏系统的实时预览和直观控制，但也希望有更精细的叙事编辑工具。TaleForge通过个性化文本和图像的结合，推动了多模态故事叙述的发展，创造了更具沉浸感和用户中心化的体验。

</details>


### [118] [PrefPaint: Enhancing Image Inpainting through Expert Human Feedback](https://arxiv.org/abs/2506.21834)
**中文标题：PrefPaint：通过专家人类反馈增强图像修复**

*Duy-Bao Bui,Hoang-Khang Nguyen,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: PrefPaint通过引入专家人类反馈增强图像修复，特别是在医学领域，显著提高了图像生成的准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 在医学等专业领域（如息肉成像），图像修复模型的准确性至关重要，但现有方法可能生成不准确的图像，影响诊断和治疗。PrefPaint旨在通过专家反馈提升模型性能。

研究方法: PrefPaint将人类反馈直接整合到Stable Diffusion Inpainting的训练过程中，无需昂贵的奖励模型，并通过基于网页的交互界面简化训练和微调。

研究结果: 用户研究表明，PrefPaint在多个领域（尤其是医学）优于现有方法，减少了视觉不一致性，生成了更真实的息肉图像。

研究结论: PrefPaint通过专家反馈显著提升了图像修复的可靠性，尤其在医学领域，为高精度图像生成提供了有效解决方案。

中文摘要: 图像修复是填补缺失或损坏图像部分的过程，广泛应用于医学成像等领域。然而，在医学息肉成像等专业领域，修复模型可能生成不准确的图像，导致诊断和治疗中的重大错误。为确保可靠性，医学图像应由专家（如肿瘤学家）标注以支持模型训练。我们提出PrefPaint，将人类反馈直接整合到Stable Diffusion Inpainting的训练中，避免了计算成本高昂的奖励模型。此外，我们开发了一个基于网页的界面，简化了训练、微调和推理过程，提供流畅直观的用户体验，便于反馈和管理微调。用户研究表明，PrefPaint在多个领域优于现有方法，减少了视觉不一致性并改善了图像渲染，尤其在医学领域，我们的模型生成了更真实的息肉图像。

</details>


### [119] [ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts](https://arxiv.org/abs/2506.21835)
**中文标题：ProSAM：通过概率提示增强基于SAM的视觉参考分割的鲁棒性**

*Xiaoqi Wang,Clint Sebastian,Wenbin He,Liu Ren*

主要分类: cs.CV

摘要简述: ProSAM通过概率提示增强SAM视觉参考分割的鲁棒性，解决了现有方法因提示编码器不理想导致的不稳定问题，并在多个数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于SAM的视觉参考分割方法因提示编码器不理想，常在物体边界生成不稳定提示，导致分割结果不稳定和鲁棒性下降。ProSAM旨在解决这一问题。

研究方法: ProSAM通过学习变分提示编码器预测多变量提示分布，避免在不稳定区域生成提示，从而提升分割的稳定性和鲁棒性。

研究结果: ProSAM在Pascal-5$^i$和COCO-20$^i$数据集上表现优于现有方法，提供了更鲁棒的视觉参考分割解决方案。

研究结论: ProSAM通过概率提示分布解决了现有SAM视觉参考分割的不稳定性问题，显著提升了分割性能。

中文摘要: 近年来，大型基础模型的进步推动了开放集图像分割任务的成功，该任务专注于分割超出预定义类别的物体。在多种提示类型（如点、框、文本和视觉参考）中，视觉参考分割因其独特的灵活性和强大的零样本能力脱颖而出。最近，几种基于SAM的方法通过自动生成提示来指导SAM，在这一任务中取得了显著进展。然而，这些方法由于提示编码器不理想，常在物体边界生成提示，导致不稳定性和鲁棒性下降。本文提出ProSAM，一种简单但有效的方法，用于解决现有基于SAM的视觉参考分割方法中的稳定性问题。通过学习变分提示编码器预测多变量提示分布，ProSAM避免了在不稳定区域生成提示，克服了由不鲁棒提示引起的不稳定性。我们的方法在Pascal-5$^i$和COCO-20$^i$数据集上持续超越现有最优方法，为视觉参考分割提供了更鲁棒的解决方案。

</details>


### [120] [GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles](https://arxiv.org/abs/2506.21839)
**中文标题：GenEscape：分层多智能体生成的密室逃脱谜题**

*Mengyi Shan,Brian Curless,Ira Kemelmacher-Shlizerman,Steve Seitz*

主要分类: cs.CV

摘要简述: 本文提出了一种分层多智能体框架GenEscape，用于生成视觉吸引、逻辑严密且富有挑战性的密室逃脱谜题图像。通过多智能体协作，解决了基础图像模型在空间关系和功能推理上的不足，显著提升了谜题的可解性和视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到图像模型在生成密室逃脱谜题图像时，难以处理空间关系和功能推理问题。本文旨在通过多智能体协作，生成既美观又逻辑严密的谜题图像。

研究方法: 提出了一种分层多智能体框架，将任务分解为功能设计、符号场景图推理、布局合成和局部图像编辑四个阶段。各智能体通过迭代反馈协作，确保场景的视觉连贯性和功能可解性。

研究结果: 实验表明，多智能体协作显著提升了谜题的可解性、避免了捷径问题，并增强了功能清晰度，同时保持了视觉质量。

研究结论: GenEscape框架通过多智能体分层协作，成功解决了密室逃脱谜题生成中的复杂问题，为未来类似任务提供了有效方法。

中文摘要: 我们挑战文本到图像模型生成视觉吸引、逻辑严密且富有挑战性的密室逃脱谜题图像。基础图像模型在空间关系和功能推理上表现不佳，为此我们提出了一种分层多智能体框架，将任务分解为功能设计、符号场景图推理、布局合成和局部图像编辑四个阶段。各智能体通过迭代反馈协作，确保场景的视觉连贯性和功能可解性。实验表明，智能体协作显著提升了输出质量，包括谜题的可解性、避免了捷径问题，并增强了功能清晰度，同时保持了视觉质量。

</details>


### [121] [3D-Telepathy: Reconstructing 3D Objects from EEG Signals](https://arxiv.org/abs/2506.21843)
**中文标题：3D心灵感应：从EEG信号重建3D物体**

*Yuxiang Ge,Jionghao Cheng,Ruiquan Ge,Zhaojie Fang,Gangyong Jia,Xiang Wan,Nannan Li,Ahmed Elazab,Changmiao Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种创新的EEG编码器架构，结合双重自注意力机制，通过混合训练策略从EEG信号中成功重建3D对象，解决了传统方法仅生成2D图像的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法仅将脑电图（EEG）数据转换为2D图像，忽略了EEG信号中丰富的三维空间信息，限制了其在脑机接口（BCI）中的实际应用。本文旨在填补这一空白，探索从EEG信号重建3D对象的可能性。

研究方法: 提出了一种创新的EEG编码器架构，结合双重自注意力机制，采用混合训练策略（包括交叉注意力、对比学习和自监督学习）。此外，利用稳定扩散作为先验分布，并通过变分分数蒸馏训练神经辐射场，从EEG数据生成3D对象。

研究结果: 成功从EEG数据中生成具有相似内容和结构的3D对象，验证了所提方法的有效性。

研究结论: 本文的方法为从EEG信号重建3D对象提供了新的可能性，扩展了BCI的应用范围，并为未来研究奠定了基础。

中文摘要: 从脑电图（EEG）数据重建3D视觉刺激在脑机接口（BCI）和辅助沟通障碍患者方面具有重要潜力。传统方法专注于将脑活动转换为2D图像，而忽略了将EEG数据转化为3D对象。这一局限性尤为显著，因为人脑无论观察2D图像还是现实世界，均处理三维空间信息。EEG捕获的神经活动包含丰富的空间信息，仅重建2D图像时这些信息不可避免地丢失，从而限制了其在BCI中的实际应用。从EEG数据到3D对象重建的过渡面临诸多障碍，包括EEG信号中的大量噪声以及缺乏同时包含EEG和3D信息的数据集，这增加了提取3D视觉数据的复杂性。为解决这一挑战性任务，我们提出了一种创新的EEG编码器架构，整合了双重自注意力机制。我们采用混合训练策略训练EEG编码器，包括交叉注意力、对比学习和自监督学习技术。此外，通过使用稳定扩散作为先验分布，并利用变分分数蒸馏训练神经辐射场，我们成功从EEG数据中生成了具有相似内容和结构的3D对象。

</details>


### [122] [ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment](https://arxiv.org/abs/2109.05721)
**中文标题：ADNet：利用人脸对齐中法线方向的误差偏向**

*Yangyu Huang,Hao Yang,Chong Li,Jongyoo Kim,Fangyun Wei*

主要分类: cs.CV

摘要简述: 本文提出ADNet，通过分析人脸对齐中的误差偏向问题，设计各向异性方向损失（ADL）和各向异性注意力模块（AAM），分别用于坐标和热图回归，以优化CNN模型的收敛性。ADNet在多个数据集上达到最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前人脸对齐研究中，误差分布偏向于沿地标曲线的切线方向，这种误差偏向与模糊的地标标注任务密切相关。本文旨在利用这一误差偏向特性，提升CNN模型的收敛性。

研究方法: 提出各向异性方向损失（ADL）和各向异性注意力模块（AAM）。ADL在边界地标点的法线方向施加强约束力，而AAM生成各向异性注意力掩码，关注点及其相邻点连接的局部边缘区域，切线方向约束较松。两者互补，学习人脸结构和纹理细节。

研究结果: ADNet在300W、WFLW和COFW数据集上取得最优结果，验证了其有效性和鲁棒性。

研究结论: 通过利用误差偏向特性，ADNet显著提升了人脸对齐性能，为相关研究提供了新思路。

中文摘要: 近年来CNN的进展显著提升了人脸对齐性能，但少有研究关注地标误差分布的偏向问题。本文研究了人脸对齐中的误差偏向现象，即地标误差倾向于沿地标曲线的切线方向分布。这种误差偏向与模糊的地标标注任务密切相关。基于此观察，我们探索如何利用误差偏向特性优化CNN模型的收敛性。为此，我们提出各向异性方向损失（ADL）和各向异性注意力模块（AAM），分别用于坐标和热图回归。ADL在边界地标点的法线方向施加强约束力，而AAM生成各向异性注意力掩码，关注点及其相邻点连接的局部边缘区域，切线方向约束较松。这两种方法互补，共同学习人脸结构和纹理细节。最终，我们将它们整合为优化的端到端训练框架ADNet。ADNet在300W、WFLW和COFW数据集上取得最优结果，验证了其有效性和鲁棒性。

</details>


### [123] [End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model](https://arxiv.org/abs/2506.21851)
**中文标题：基于通道间跨模态熵模型的端到端RGB-IR联合图像压缩**

*Haofeng Wang,Fangtao Zhou,Qi Zhang,Zeyuan Chen,Enci Zhang,Zhao Wang,Xiaofeng Huang,Siwei Ma*

主要分类: cs.CV

摘要简述: 本文提出了一种端到端的RGB-IR联合图像压缩框架，通过通道间跨模态熵模型（CCEM）充分利用跨模态先验信息，显著提升了压缩效率。


<details>
  <summary>详细信息</summary>
研究动机: RGB-IR图像对在智能监控等应用中广泛使用，但多模态数据存储和传输成本高昂，因此需要高效的联合压缩方法。

研究方法: 提出了一种通道间跨模态熵模型（CCEM），包含低频上下文提取块（LCEB）和低频上下文融合块（LCFB），用于提取和聚合跨模态的低频信息，以更准确地预测熵参数。

研究结果: 实验结果表明，该方法在LLVIP和KAIST数据集上优于现有RGB-IR图像对和单模态压缩方法，例如在LLVIP数据集上比特率节省了23.1%。

研究结论: 本文提出的框架通过跨模态信息建模显著提升了RGB-IR图像对的压缩效率，为多模态数据压缩提供了有效解决方案。

中文摘要: RGB-IR（RGB-红外）图像对在智能监控等应用中经常同时使用。然而，随着模态数量的增加，所需的数据存储和传输成本也成倍增长。因此，高效的RGB-IR数据压缩至关重要。本文提出了一种RGB-IR图像对的联合压缩框架。具体而言，为了充分利用跨模态先验信息以准确建模模态内和模态间的上下文概率，我们提出了一种通道间跨模态熵模型（CCEM）。在CCEM中，设计了低频上下文提取块（LCEB）和低频上下文融合块（LCFB），用于从两种模态中提取和聚合全局低频信息，从而帮助模型更准确地预测熵参数。实验结果表明，我们的方法在LLVIP和KAIST数据集上优于现有的RGB-IR图像对和单模态压缩方法。例如，与CVPR 2022上提出的最先进RGB-IR图像编解码器相比，所提出的框架在LLVIP数据集上实现了23.1%的比特率节省。

</details>


### [124] [FreeEnricher: Enriching Face Landmarks without Additional Cost](https://arxiv.org/abs/2212.09525)
**中文标题：FreeEnricher：无需额外成本的人脸关键点丰富方法**

*Yangyu Huang,Xi Chen,Jongyoo Kim,Hao Yang,Chong Li,Jiaolong Yang,Dong Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FreeEnricher的框架，能够利用现有稀疏人脸关键点数据集（如300W和WFLW）来丰富关键点密度，无需额外成本。通过弱监督学习和设计的操作符，该方法在密集和稀疏关键点测试集上均达到了最先进的精度。


<details>
  <summary>详细信息</summary>
研究动机: 尽管密集人脸关键点在美容医学和面部美化等场景中需求很高，但大多数研究仅关注稀疏关键点对齐。为了解决这一问题，本文旨在通过现有稀疏数据集实现关键点密度的提升。

研究方法: 首先观察到语义轮廓上的局部图像块在表观上高度相似，随后提出一种弱监督学习思路：在原始稀疏关键点上学习细化能力，并将此能力迁移到密集关键点上。同时设计了多个操作符来实现这一思路。

研究结果: 在手动标注的密集300W测试集上，该方法不仅在新构建的密集测试集上表现优异，还在原始稀疏300W和WFLW测试集上达到了最先进的精度，且无需额外成本。

研究结论: FreeEnricher框架成功实现了通过稀疏数据集提升关键点密度的目标，并在多个测试集上验证了其高效性和实用性。

中文摘要: 近年来，人脸对齐技术取得了显著进展。尽管密集人脸关键点在美容医学和面部美化等场景中需求很高，但大多数研究仅关注稀疏关键点对齐。为解决这一问题，我们提出了一种框架，能够利用现有稀疏关键点数据集（如300W的68点和WFLW的98点）来丰富关键点密度。首先，我们观察到语义轮廓上的局部图像块在表观上高度相似。随后，我们提出一种弱监督学习思路：在原始稀疏关键点上学习细化能力，并将此能力迁移到密集关键点上。同时，设计了多个操作符来实现这一思路。最终，训练好的模型可作为即插即用模块应用于现有人脸对齐网络。为评估方法效果，我们在300W测试集上手动标注了密集关键点。实验表明，该方法不仅在新构建的密集300W测试集上表现优异，还在原始稀疏300W和WFLW测试集上达到了最先进的精度，且无需额外成本。

</details>


### [125] [Periodic-MAE: Periodic Video Masked Autoencoder for rPPG Estimation](https://arxiv.org/abs/2506.21855)
**中文标题：Periodic-MAE：用于rPPG估计的周期性视频掩码自编码器**

*Jiho Choi,Sang Jun Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Periodic-MAE的方法，通过自监督学习从无标记面部视频中学习周期性信号的通用表示，用于远程光电容积描记术（rPPG）估计。该方法通过视频掩码自编码器捕获皮肤色调的细微变化，并结合生理频带限制约束，显著提升了跨数据集评估的性能。


<details>
  <summary>详细信息</summary>
研究动机: 远程光电容积描记术（rPPG）需要从面部视频中提取周期性生理信号，但现有方法在跨数据集评估中表现不佳。本文旨在通过自监督学习捕获周期性信号，提升rPPG估计的泛化能力。

研究方法: 提出Periodic-MAE框架，使用视频掩码自编码器学习面部区域的高维时空表示。通过帧掩码采样捕获准周期性信号，并结合生理频带限制约束，为模型提供脉搏线索。预训练编码器随后迁移至rPPG任务。

研究结果: 在PURE、UBFC-rPPG、MMPD和V4V数据集上的实验表明，该方法在跨数据集评估中表现显著优于现有方法。

研究结论: Periodic-MAE通过自监督学习和生理频带限制约束，有效提升了rPPG估计的性能，尤其在跨数据集场景下表现出色。

中文摘要: 本文提出了一种方法，通过自监督学习从无标记面部视频中学习周期性信号的通用表示，以捕获皮肤色调随时间变化的细微特征。该框架采用视频掩码自编码器，学习面部区域的高维时空表示。捕获视频中的准周期性信号对远程光电容积描记术（rPPG）估计至关重要。为考虑信号周期性，我们在视频采样中应用帧掩码，使模型在预训练阶段能够捕获重采样的准周期性信号。此外，框架结合了生理频带限制约束，利用生理信号在其频带内稀疏的特性，为模型提供脉搏线索。预训练编码器随后迁移至rPPG任务，用于从面部视频中提取生理信号。我们在PURE、UBFC-rPPG、MMPD和V4V数据集上进行了广泛实验，结果表明该方法在跨数据集评估中性能显著提升。代码发布于https://github.com/ziiho08/Periodic-MAE。

</details>


### [126] [SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space](https://arxiv.org/abs/2506.21857)
**中文标题：SPADE：基于混合数据专家的空间转录组学与病理学对齐的潜在空间表达模型**

*Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold*

主要分类: cs.CV

摘要简述: SPADE是一种基础模型，通过整合组织病理学和空间转录组学数据，利用混合数据专家技术和对比学习，构建了一个统一的潜在空间，显著提升了少样本任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前数字病理学和自监督深度学习的快速发展为多种疾病任务的基础模型开发提供了可能。然而，全切片图像（WSI）与空间转录组学（ST）的全面整合仍存在空白，这对于捕捉标准H&E染色之外的分子异质性至关重要。

研究方法: SPADE采用混合数据专家技术，通过两阶段特征空间聚类创建专家，利用对比学习学习共配准的WSI图像块和基因表达谱的表示。模型在HEST-1k数据集上预训练，并在14个下游任务中评估。

研究结果: SPADE在少样本任务中表现显著优于基线模型，证明了将形态学和分子信息整合到一个潜在空间中的优势。

研究结论: SPADE通过整合多模态数据，构建了一个统一的潜在空间，为病理学任务提供了更强大的表示学习能力。

中文摘要: 数字病理学的快速发展和自监督深度学习的进步为多种疾病任务的基础模型开发提供了可能。尽管已经出现了整合多模态数据的方法，但全切片图像（WSI）与空间转录组学（ST）的全面整合仍是一个关键空白，这对于捕捉标准H&E染色之外的分子异质性至关重要。我们提出了SPADE，一种基础模型，通过整合组织病理学和ST数据，在一个统一框架内指导图像表示学习，从而构建了一个ST信息化的潜在空间。SPADE采用混合数据专家技术，通过两阶段特征空间聚类创建专家，利用对比学习学习共配准的WSI图像块和基因表达谱的表示。在HEST-1k数据集上预训练后，SPADE在14个下游任务中评估，表现出显著优于基线模型的少样本性能，突出了将形态学和分子信息整合到一个潜在空间中的优势。

</details>


### [127] [PEACE: Empowering Geologic Map Holistic Understanding with MLLMs](https://arxiv.org/abs/2501.06184)
**中文标题：PEACE：通过多模态大语言模型赋能地质地图的整体理解**

*Yangyu Huang,Tianyi Gao,Haoran Xu,Qihao Zhao,Yang Song,Zhipeng Gui,Tengchao Lv,Hao Chen,Lei Cui,Scarlett Li,Furu Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PEACE的方法，通过多模态大语言模型（MLLMs）提升地质地图的整体理解能力。作者构建了首个地质地图理解基准GeoMap-Bench，并开发了GeoMap-Agent，包含三个模块：分层信息提取、领域知识注入和提示增强问答。实验表明，GeoMap-Agent显著优于GPT-4o。


<details>
  <summary>详细信息</summary>
研究动机: 地质地图在地质科学中至关重要，但目前的多模态大语言模型在地质地图理解方面表现不足。这主要由于地图制图综合的复杂性，包括高分辨率地图处理、多组件管理和领域知识需求。本文旨在填补这一空白。

研究方法: 作者首先构建了GeoMap-Bench基准，用于评估MLLMs在地质地图理解中的能力。随后提出了GeoMap-Agent，包含三个模块：分层信息提取（HIE）、领域知识注入（DKI）和提示增强问答（PEQA）。该方法通过AI专家组协作，利用多样化工具库分析问题。

研究结果: 实验结果显示，GeoMap-Agent在GeoMap-Bench上的总体得分为0.811，显著优于GPT-4o的0.369。

研究结论: 本文提出的PEACE方法通过MLLMs显著提升了地质地图的理解能力，为地质学中的AI应用开辟了新途径，提高了地质调查的效率和准确性。

中文摘要: 地质地图作为地质科学中的基础图表，为地球表层和地下的结构与组成提供了关键洞察。这些地图在灾害检测、资源勘探和土木工程等领域不可或缺。尽管其重要性，当前的多模态大语言模型（MLLMs）在地质地图理解方面表现不足。这一差距主要源于地图制图综合的挑战性，包括处理高分辨率地图、管理多个关联组件以及需要领域专业知识。为量化这一差距，我们构建了首个地质地图理解基准GeoMap-Bench，用于评估MLLMs在提取、引用、定位、推理和分析方面的全面能力。为填补这一空白，我们提出了GeoMap-Agent，这是首个专为地质地图理解设计的代理，包含三个模块：分层信息提取（HIE）、领域知识注入（DKI）和提示增强问答（PEQA）。受人类科学家跨学科合作的启发，AI专家组作为顾问，利用多样化工具库全面分析问题。通过全面实验，GeoMap-Agent在GeoMap-Bench上的总体得分为0.811，显著优于GPT-4o的0.369。我们的工作——通过MLLMs赋能地质地图的整体理解（PEACE），为地质学中的高级AI应用铺平了道路，提升了地质调查的效率和准确性。

</details>


### [128] [LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs](https://arxiv.org/abs/2506.21862)
**中文标题：LLaVA-Scissor：基于语义连通分量的视频大语言模型令牌压缩方法**

*Boyuan Sun,Jiaxing Zhao,Xihan Wei,Qibin Hou*

主要分类: cs.CV

摘要简述: 本文提出LLaVA-Scissor，一种无需训练的视频多模态大语言模型令牌压缩策略，通过语义连通分量（SCC）实现高效令牌压缩，显著提升视频理解性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有令牌压缩方法多基于注意力分数，但无法全面捕捉语义区域且易导致令牌冗余。本文旨在提出一种更高效的令牌压缩策略，以提升视频多模态大语言模型的性能。

研究方法: 提出基于语义连通分量（SCC）的两步时空令牌压缩策略，将令牌分配到非重叠语义区域，确保语义覆盖全面。

研究结果: 在视频问答、长视频理解及多选基准测试中，LLaVA-Scissor优于其他方法，尤其在低令牌保留率下表现突出。

研究结论: LLaVA-Scissor通过SCC实现高效令牌压缩，显著提升视频理解性能，为视频多模态大语言模型提供了一种有效解决方案。

中文摘要: 本文提出LLaVA-Scissor，一种无需训练的视频多模态大语言模型令牌压缩策略。现有方法多基于注意力分数压缩令牌，但无法全面捕捉语义区域且易导致令牌冗余。为此，我们提出利用语义连通分量（SCC）将令牌分配到不同语义区域，确保语义覆盖全面。该方法采用两步时空令牌压缩策略，通过SCC在时空域中压缩令牌，最终以一组非重叠语义令牌表示整个视频。我们在多种视频理解基准测试（如视频问答、长视频理解及多选测试）中广泛评估了LLaVA-Scissor的令牌压缩能力。实验结果表明，LLaVA-Scissor优于其他令牌压缩方法，尤其在低令牌保留率下表现优异。项目页面：https://github.com/HumanMLLM/LLaVA-Scissor。

</details>


### [129] [Remote Sensing Large Vision-Language Model: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling](https://arxiv.org/abs/2506.21863)
**中文标题：遥感大型视觉语言模型：语义增强的多级对齐与语义感知专家建模**

*Sungjune Park,Yeongyun Kim,Se Yeon Kim,Yong Man Ro*

主要分类: cs.CV

摘要简述: 本文提出了一种针对遥感图像理解的大型视觉语言模型（LVLM）框架，通过语义增强的多级对齐和语义感知专家建模，解决了遥感图像与自然图像在视觉外观、对象尺度和语义上的差异问题，显著提升了遥感场景的理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型视觉语言模型（LVLMs）在自然图像领域表现优异，但由于遥感图像与自然图像在视觉外观、对象尺度和语义上的显著差异，直接应用于遥感图像效果不佳。因此，需要一种专门针对遥感图像理解的LVLM框架。

研究方法: 1. 语义增强的多级对齐：通过检索式语义增强模块，从遥感语义知识库中检索相关语义线索，并将其与用户查询和多级视觉特征聚合，生成多级语义丰富的表示。2. 语义感知专家建模：设计多个语义专家，每个专家分别处理不同层次的语义表示，实现从粗到细的层次化语义理解。

研究结果: 在多个遥感任务（如场景分类和视觉问答等）上的实验表明，所提框架在多个语义层次上均取得了显著的性能提升，验证了其在遥感图像理解中的有效性和能力。

研究结论: 本文提出的框架通过语义增强的多级对齐和语义感知专家建模，成功弥补了通用LVLMs与遥感图像独特需求之间的差距，为遥感图像理解提供了有效的解决方案。

中文摘要: 大型视觉语言模型（LVLMs）在自然图像领域的多种视觉语言任务中表现出色，但由于遥感（RS）图像在视觉外观、对象尺度和语义上的显著差异，其应用尚未充分探索。这些差异阻碍了对包含从粗到细多层次语义信息的遥感场景的有效理解，限制了现有LVLMs直接应用于遥感图像的能力。为解决这一问题，我们提出了一种专为遥感理解设计的新型LVLM框架，包含两个核心组件：语义增强的多级对齐和语义感知专家建模。首先，为对齐多级视觉特征，我们引入了基于检索的语义增强模块，该模块通过从遥感语义知识库中检索相关语义线索，并将其与用户查询和多级视觉特征聚合，生成多级语义丰富的表示。其次，在语义感知专家建模中，我们设计了多个语义专家，每个专家分别处理不同层次的语义表示，实现从粗到细的层次化语义理解。在多个遥感任务（如场景分类和视觉问答等）上的评估表明，所提框架在多个语义层次上均取得了显著改进，凸显了其在弥补通用LVLMs与遥感图像独特需求之间差距的能力和有效性。

</details>


### [130] [Dual-Perspective United Transformer for Object Segmentation in Optical Remote Sensing Images](https://arxiv.org/abs/2506.21866)
**中文标题：双视角统一Transformer用于光学遥感图像中的目标分割**

*Yanguang Sun,Jiexi Yan,Jianjun Qian,Chunyan Xu,Jian Yang,Lei Luo*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的双视角统一Transformer（DPU-Former），用于光学遥感图像中的目标分割，通过结合全局和局部特征提升分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有模型主要基于卷积或Transformer特征，各有优势但未能有效结合，导致分割效果不佳。本文旨在解决特征异构性、模型复杂性和参数过多等问题。

研究方法: 设计了全局-局部混合注意力机制，通过双视角捕获多样化信息，并引入傅里叶空间融合策略实现高效特征融合。此外，提出门控线性前馈网络增强表达能力，并构建DPU-Former解码器聚合多层特征。

研究结果: DPU-Former在多个数据集上优于现有最优方法，验证了其有效性。

研究结论: DPU-Former通过结合全局和局部特征，显著提升了光学遥感图像目标分割的性能，为相关研究提供了新思路。

中文摘要: 自动从光学遥感图像（ORSIs）中分割目标是一项重要任务。现有模型主要基于卷积或Transformer特征，各有优势。结合两者的优势具有研究价值，但面临特征异构性、模型复杂性和参数过多等挑战。这些问题在现有ORSIs方法中常被忽视，导致分割效果不佳。为此，我们提出了一种新颖的双视角统一Transformer（DPU-Former），其独特结构旨在同时整合长程依赖和空间细节。具体而言，我们设计了全局-局部混合注意力，通过双视角捕获多样化信息，并引入傅里叶空间融合策略以消除偏差，实现高效融合。此外，提出门控线性前馈网络增强表达能力，并构建DPU-Former解码器聚合多层特征。实验表明，DPU-Former在多个数据集上优于现有最优方法。

</details>


### [131] [Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning](https://arxiv.org/abs/2506.21873)
**中文标题：基于视觉定位感知的令牌剪枝：从剪枝导致的性能骤降中恢复**

*Tzu-Chun Chien,Chieh-Kai Lin,Shiang-Feng Tsai,Ruei-Chi Lai,Hung-Jen Chen,Min Sun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为GAP的剪枝方法，通过调整位置ID恢复视觉定位任务中因剪枝导致的性能下降，无需额外训练或计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在视觉定位任务中表现出色，但剪枝操作会显著降低其性能，尤其是位置ID的错位导致预测错误。本文旨在解决这一问题。

研究方法: 提出Grounding-Aware Token Pruning（GAP），通过简单调整剪枝后的位置ID，恢复模型的视觉定位能力，无需额外训练或计算资源。

研究结果: 在RefCOCO验证集上，GAP将LLaVA的准确率从剪枝后的15.34%恢复到51.42%，接近原始性能的90%，且适用于多种模型和剪枝策略。

研究结论: GAP是一种高效且无需额外开销的方法，能有效解决剪枝导致的视觉定位性能下降问题，适用于多种多模态大语言模型。

中文摘要: 近年来，多模态大语言模型（MLLMs）在视觉定位任务中表现出色，成为多种视觉-语言应用的通用接口。然而，剪枝操作显著削弱了模型的定位能力，导致预测错误和性能骤降。例如，在Referring Expression Comprehension（REC）任务中，剪枝使LLaVA在RefCOCO验证集上的准确率从56.14%降至15.34%。分析发现，剪枝后位置ID的错位是性能下降的主要原因，因为这些ID的顺序和值对定位任务至关重要。为解决这一问题，我们提出Grounding-Aware Token Pruning（GAP），通过简单调整位置ID，将REC准确率恢复至51.42%，接近原始性能的90%，且无需额外训练、内存或计算开销。GAP适用于Shikra、MiniGPTv2和LLaVA系列模型，并在多种剪枝策略中表现一致。

</details>


### [132] [GRASP-PsONet: Gradient-based Removal of Spurious Patterns for PsOriasis Severity Classification](https://arxiv.org/abs/2506.21883)
**中文标题：GRASP-PsONet：基于梯度的虚假模式去除方法用于银屑病严重程度分类**

*Basudha Pal,Sharif Amit Kamran,Brendon Lutnick,Molly Lucas,Chaitanya Parmar,Asha Patel Shah,David Apfel,Steven Fakharzadeh,Lloyd Miller,Gabriela Cula,Kristopher Standish*

主要分类: cs.CV

摘要简述: 本文提出了一种基于梯度的框架GRASP-PsONet，用于自动检测并移除银屑病严重程度分类模型中的虚假相关性训练图像，从而提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 银屑病严重程度评分在临床试验中至关重要，但受限于评估者间差异和临床评估的负担。远程成像虽具扩展性，却因光照、背景和设备质量等非临床因素影响模型可靠性。本文旨在解决这些问题。

研究方法: 通过基于梯度的可解释性方法，追踪误分类验证图像的梯度，检测训练样本中的不一致标注或非临床伪影。该方法应用于基于ConvNeXT的弱监督模型，用于从手机图像分类银屑病严重程度。

研究结果: 移除8.2%的问题图像后，模型在测试集上的AUC-ROC提升了5%（85%至90%）。在双皮肤科医生标注的子集中，该方法通过仅检查前30%样本，识别出90%以上的标注不一致案例。

研究结论: GRASP-PsONet能有效检测训练数据中的标注不一致和非临床伪影，显著提升模型鲁棒性，减少对人工审核的依赖，为远程评估提供可靠支持。

中文摘要: 银屑病（PsO）严重程度评分对临床试验至关重要，但受限于评估者间差异和临床评估的负担。远程成像通过患者拍摄的手机照片提供了扩展性，但也引入了光照、背景和设备质量等非临床因素的挑战，这些因素可能影响模型性能。这些因素与皮肤科医生标注的不一致性降低了自动评分的可靠性。我们提出了一种框架，通过基于梯度的可解释性方法自动标记引入虚假相关性的问题训练图像。通过追踪误分类验证图像的梯度，我们检测到模型错误与不一致标注或非临床伪影相关的训练样本。我们将此方法应用于基于ConvNeXT的弱监督模型，用于从手机图像分类银屑病严重程度。移除8.2%的问题图像后，模型在测试集上的AUC-ROC提升了5%（85%至90%）。通常，多标注者和裁决过程确保标注准确性，但成本高昂且耗时。我们的方法检测标注不一致的训练图像，可能无需人工审核。在双皮肤科医生标注的子集中，该方法通过仅检查前30%样本，识别出90%以上的标注不一致案例。这提升了远程评估的自动评分，确保数据收集变异性下的鲁棒性。

</details>


### [133] [Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles](https://arxiv.org/abs/2506.21885)
**中文标题：多模态传感器集成：智能车辆融合技术综述**

*Chuheng Wei,Ziye Qin,Ziyan Zhang,Guoyuan Wu,Matthew J. Barth*

主要分类: cs.CV

摘要简述: 本文综述了多传感器融合在智能车辆中的关键作用，系统分类了数据级、特征级和决策级融合策略，并探讨了深度学习方法、多模态数据集及新兴趋势（如视觉语言模型和大语言模型的应用）。


<details>
  <summary>详细信息</summary>
研究动机: 多传感器融合能够弥补单一传感器的局限性，提升自动驾驶的环境感知能力，尤其是在恶劣天气和复杂城市环境中。本文旨在系统梳理融合技术，为未来研究提供方向。

研究方法: 论文首先将多传感器融合策略分为数据级、特征级和决策级三类，并针对每类策略综述了基于深度学习的方法。同时，介绍了关键多模态数据集及其实际应用。

研究结果: 研究总结了当前多传感器融合技术的现状，并探讨了视觉语言模型、大语言模型等新兴趋势在提升系统适应性和鲁棒性方面的潜力。

研究结论: 本文为多传感器融合在自动驾驶领域的当前方法和未来发展方向提供了有价值的见解，强调了其在提升系统性能中的重要性。

中文摘要: 多传感器融合在提升自动驾驶感知能力、克服单一传感器局限性以及实现全面环境理解方面发挥着关键作用。本文首先将多传感器融合策略形式化为数据级、特征级和决策级三类，并系统综述了基于深度学习的对应方法。我们介绍了关键多模态数据集，并讨论了其在解决现实挑战（尤其是恶劣天气条件和复杂城市环境）中的适用性。此外，我们探讨了新兴趋势，包括视觉语言模型（VLMs）、大语言模型（LLMs）的集成，以及传感器融合在端到端自动驾驶中的作用，强调了其在增强系统适应性和鲁棒性方面的潜力。本研究为自动驾驶中多传感器融合的当前方法和未来方向提供了宝贵见解。

</details>


### [134] [DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025](https://arxiv.org/abs/2506.21891)
**中文标题：DIVE：深度搜索迭代视频探索——CVPR 2025 CVRR挑战赛技术报告**

*Umihiro Kamoto,Tatsuya Ishibashi,Noriyuki Kugo*

主要分类: cs.CV

摘要简述: 本文介绍了在CVPR 2025的CVRR挑战赛中获胜的解决方案DIVE，该方法通过迭代推理和逐步分解问题，实现了对复杂视频问答的高准确率（81.44%）。


<details>
  <summary>详细信息</summary>
研究动机: CVRR挑战赛旨在评估对多样化真实世界视频片段生成准确自然语言答案的能力。为了解决复杂视频问答中的推理难题，作者提出了DIVE方法。

研究方法: DIVE采用迭代推理方法，将输入问题语义分解并通过逐步推理和渐进推断解决，从而提供高准确性和上下文相关的答案。

研究结果: 在CVRR-ES基准测试中，DIVE达到了81.44%的准确率，在所有参赛者中排名第一。

研究结论: DIVE的迭代推理框架在视频问答中表现出色，证明了其在处理复杂查询时的有效性和鲁棒性。

中文摘要: 本报告介绍了在2025年复杂视频推理与鲁棒性评估挑战赛（CVRR）中获得第一名的解决方案。该挑战赛旨在评估对多样化真实世界视频片段生成准确自然语言答案的能力，使用了包含214个独特视频和2400个问题-答案对的CVRR-ES基准测试。我们的方法DIVE（深度搜索迭代视频探索）采用迭代推理方法，通过逐步分解问题和渐进推断，为最复杂的查询提供高准确性和上下文相关的答案。在CVRR-ES基准测试中，我们的方法在测试集上达到了81.44%的准确率，位居所有参赛者之首。本报告详细介绍了我们的方法，并对实验结果进行了全面分析，展示了迭代推理框架在实现鲁棒视频问答方面的有效性。代码可在https://github.com/PanasonicConnect/DIVE获取。

</details>


### [135] [SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation](https://arxiv.org/abs/2506.21892)
**中文标题：SODA：通过邻域传播在域偏移点云中检测分布外数据**

*Adam Goodge,Xun Xu,Bryan Hooi,Wee Siong Ng,Jingyi Liao,Yongyi Su,Xulei Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SODA的新方法，通过邻域传播技术改进点云数据的分布外检测（OOD），解决了合成数据与真实数据之间的域偏移问题，无需额外训练即可实现最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着点云数据在多种应用中的普及，检测分布外点云对象对模型的安全性和可靠性至关重要。然而，现有研究对此问题关注不足，且预训练3D视觉语言模型（3D VLMs）的数据集规模小、多样性低，导致合成数据与真实数据之间存在显著域偏移，影响模型性能。

研究方法: 本文提出SODA方法，通过邻域传播技术改进点云数据的分布外检测。该方法基于推理，无需额外模型训练，利用3D VLMs的潜在空间中的邻域信息传播分数，提升检测性能。

研究结果: 实验表明，SODA在多种数据集和问题设置下均优于现有方法，显著提升了分布外点云对象的检测性能。

研究结论: SODA通过邻域传播技术有效解决了合成数据与真实数据之间的域偏移问题，为点云数据的分布外检测提供了高效且无需额外训练的解决方案。

中文摘要: 随着点云数据在多种应用中的普及，检测分布外（OOD）点云对象对确保模型的安全性和可靠性至关重要。然而，现有研究对此问题关注不足。受图像领域成功的启发，我们提出利用3D视觉语言模型（3D VLMs）的进展来检测点云对象的OOD。然而，预训练3D VLMs的点云数据集在规模和对象多样性上远不及图像数据集，且通常仅包含计算机设计的合成对象。这导致模型在涉及真实环境扫描对象的实际任务中面临显著的域偏移。本文通过实验表明，合成到真实的域偏移显著降低了点云与其关联文本嵌入在3D VLM潜在空间中的对齐性，从而影响下游性能。为解决这一问题，我们提出了一种名为SODA的新方法，通过邻域传播技术改进OOD点云的检测。SODA基于推理，无需额外模型训练，并在多种数据集和问题设置中实现了优于现有方法的性能。

</details>


### [136] [Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.21895)
**中文标题：基于强化微调的广义跨域人脸防伪任务解决范式探索**

*Fangling Jiang,Qi Li,Weining Wang,Gang Wang,Bing Liu,Zhenan Sun*

主要分类: cs.CV

摘要简述: 本文提出了一种基于强化微调的人脸防伪方法，通过引导多模态大语言模型学习任务解决策略而非记忆模式，实现了跨域泛化性能的提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸防伪方法容易过拟合训练数据，对未知攻击类型泛化能力差且缺乏可解释性。本文旨在通过强化学习提升模型的泛化能力和决策可解释性。

研究方法: 设计了可验证的类别一致性奖励和推理一致性奖励，采用GRPO优化策略引导模型从多角度探索推理策略，通过迭代学习保留高奖励轨迹，提炼泛化性强的决策规则。

研究结果: 实验表明，该方法在跨域人脸防伪任务中实现了最先进的泛化性能，能有效应对未知攻击类型并提供可解释的决策依据。

研究结论: 通过强化微调，模型能够从广泛的解空间中学习泛化性强的决策规则，显著提升跨域人脸防伪的性能和可解释性。

中文摘要: 近年来，新型呈现攻击的出现使得人脸防伪问题备受关注。然而，现有方法容易记住训练集中的数据模式，导致对跨场景未知攻击类型的泛化能力差且可解释性有限。为解决这些问题，本文提出了一种基于强化微调的人脸防伪方法，该方法激发多模态大语言模型的能力，使其学习如何解决防伪任务本身，而非依赖对真实性模式的记忆。我们设计了可验证的类别一致性奖励和推理一致性奖励，并采用基于GRPO的优化策略，引导模型从多角度探索推理策略以最大化预期奖励。通过迭代试错学习并仅保留高奖励轨迹，模型从广泛的解空间中提炼出高度泛化的决策规则，有效应对跨域人脸防伪任务。大量实验结果表明，我们的方法在跨域泛化性能上达到了最先进水平，能够很好地适应未见目标域中的多种未知攻击类型，同时为真实性决策提供可解释的推理依据，而无需依赖劳动密集型的文本标注训练。

</details>


### [137] [Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment](https://arxiv.org/abs/2506.21903)
**中文标题：基于迁移学习和数据集增强的教育视频视觉内容检测**

*Dipayan Biswas,Shishir Shah,Jaspal Subhlok*

主要分类: cs.CV

摘要简述: 本文提出了一种基于迁移学习的教育视频视觉内容检测方法，通过优化YOLO模型和半监督自动标注策略，显著提升了视频中图表、表格等视觉元素的检测效果，并公开了标注数据集和源代码。


<details>
  <summary>详细信息</summary>
研究动机: 教育视频中的视觉元素（如图表、表格）对理解和记忆至关重要，但现有深度学习模型因数据稀缺和视觉元素结构复杂而表现不佳。本文旨在解决这一问题，提升视频内容的可访问性。

研究方法: 采用迁移学习方法，评估了多种先进目标检测模型，最终选择并优化YOLO模型。通过多数据集训练和半监督自动标注策略，提升模型在视频中的检测性能。

研究结果: 优化后的YOLO模型在教育视频视觉元素检测任务中表现优异，同时公开了标注数据集和源代码，为未来研究提供了基础。

研究结论: 本文成功开发了一种高效的教育视频视觉内容检测方法，并通过公开数据集和代码推动了相关研究的进展。

中文摘要: 视频正在改变教育方式，在线课程和录播讲座正在补充甚至取代传统课堂教学。近期研究致力于通过高级导航、可搜索性、摘要生成以及问答聊天机器人来增强视频讲座的信息检索能力。视觉元素（如表格、图表和插图）在讲座视频中对理解、记忆和数据呈现至关重要，但其在提升视频内容可访问性方面的潜力尚未充分挖掘。主要原因是视频中视觉元素的自动检测面临挑战：其一，大多数视觉元素（如图表、表格）是人工创建的，缺乏标准结构；其二，连贯的视觉对象可能没有清晰边界，且可能由文本和视觉组件混合构成。尽管基于深度学习的目标检测技术有所进展，但由于讲座视频视觉内容的独特性和标注数据稀缺，现有模型表现不佳。本文提出了一种基于迁移学习的视觉元素检测方法，评估了多种先进目标检测模型在讲座视频数据集上的表现，发现YOLO模型最具潜力。随后，通过多基准数据集训练和半监督自动标注策略对YOLO进行了优化。实验结果表明该方法在解决讲座视频目标检测问题上具有通用性。本文贡献包括公开标注的讲座视频帧基准数据集及源代码，以促进未来研究。

</details>


### [138] [RAUM-Net: Regional Attention and Uncertainty-aware Mamba Network](https://arxiv.org/abs/2506.21905)
**中文标题：RAUM-Net：基于区域注意力与不确定性感知的Mamba网络**

*Mingquan Liu*

主要分类: cs.CV

摘要简述: RAUM-Net是一种结合区域注意力与贝叶斯不确定性的半监督方法，用于细粒度视觉分类，显著提升模型在标注数据稀缺时的性能。


<details>
  <summary>详细信息</summary>
研究动机: 细粒度视觉分类（FGVC）因类间差异细微且特征表示脆弱而具有挑战性，尤其在标注数据稀缺时，现有方法表现不佳。本文旨在解决这一问题。

研究方法: 提出一种半监督方法，结合基于Mamba的特征建模、区域注意力和贝叶斯不确定性，增强局部到全局特征建模，并通过贝叶斯推理选择高质量伪标签以提高稳定性。

研究结果: 实验表明，该方法在FGVC基准测试中表现优异，尤其在遮挡情况下，且在标注数据有限时仍保持鲁棒性。

研究结论: RAUM-Net通过区域注意力和贝叶斯不确定性有效提升了细粒度分类性能，尤其在标注数据稀缺时表现突出。

中文摘要: 细粒度视觉分类（FGVC）由于类间差异细微且特征表示脆弱，一直是计算机视觉中的一项挑战性任务。现有方法在细粒度场景中表现不佳，尤其是在标注数据稀缺时。我们提出了一种半监督方法，结合基于Mamba的特征建模、区域注意力和贝叶斯不确定性。该方法增强了从局部到全局的特征建模，并在学习过程中聚焦关键区域。贝叶斯推理用于选择高质量的伪标签以确保稳定性。实验表明，该方法在FGVC基准测试中表现优异，尤其在遮挡情况下，且在标注数据有限时仍保持鲁棒性。代码发布于https://github.com/wxqnl/RAUM-Net。

</details>


### [139] [CERBERUS: Crack Evaluation & Recognition Benchmark for Engineering Reliability & Urban Stability](https://arxiv.org/abs/2506.21909)
**中文标题：CERBERUS：工程可靠性与城市稳定性的裂缝评估与识别基准**

*Justin Reinman,Sunwoong Choi*

主要分类: cs.CV

摘要简述: CERBERUS是一个用于训练和评估AI模型检测基础设施裂缝的合成基准，包含裂缝图像生成器和Unity构建的3D检测场景。通过结合合成与真实数据，提升了模型在实际图像中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前基础设施裂缝检测缺乏标准化评估工具，CERBERUS旨在提供一个灵活、可重复的基准，支持自动化检测系统的研究与开发。

研究方法: CERBERUS包含两种检测场景：简单的Fly-By墙面检测和复杂的Underpass场景。使用YOLO模型测试合成与真实数据的组合效果。

研究结果: 实验表明，结合合成与真实数据能显著提升模型在实际图像中的检测性能。

研究结论: CERBERUS为裂缝检测系统提供了标准化测试工具，支持未来自动化基础设施检测的研究。

中文摘要: CERBERUS是一个合成基准，旨在帮助训练和评估AI模型检测基础设施中的裂缝及其他缺陷。它包含一个裂缝图像生成器和基于Unity构建的真实3D检测场景。该基准提供两种设置：简单的Fly-By墙面检测和具有光照与几何挑战的复杂Underpass场景。我们测试了一种流行的目标检测模型（YOLO），使用不同组合的合成与真实裂缝数据。结果表明，结合合成与真实数据能提升模型在实际图像中的表现。CERBERUS提供了一种灵活、可重复的缺陷检测系统测试方法，并支持未来自动化基础设施检测的研究。CERBERUS已公开在https://github.com/justinreinman/Cerberus-Defect-Generator。

</details>


### [140] [Generating Attribute-Aware Human Motions from Textual Prompt](https://arxiv.org/abs/2506.21912)
**中文标题：基于文本提示生成具有属性感知的人类动作**

*Xinghan Wang,Kun Xu,Fei Li,Cao Sheng,Jiazhong Yu,Yadong Mu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于文本提示生成具有属性感知的人类动作的新方法，通过解耦动作语义和人类属性，实现了文本到动作的生成，并引入了包含属性注释的数据集HumanAttr作为基准。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于文本的人类动作生成方法忽略了人类属性（如年龄、性别、体重和身高）对动作模式的影响，而这些属性是塑造动作的关键因素。本文旨在填补这一空白。

研究方法: 受结构因果模型启发，提出了一种新框架，将动作语义与人类属性解耦，实现文本到语义的预测和属性控制的生成。

研究结果: 实验结果表明，该模型能够生成与用户文本和属性输入一致的逼真动作，并在新数据集HumanAttr上验证了其有效性。

研究结论: 本文首次探索了属性感知的文本到动作生成，提出了有效的解耦框架，并建立了首个基准数据集，为未来研究奠定了基础。

中文摘要: 文本驱动的人类动作生成近年来受到广泛关注，使模型能够根据文本描述生成人类动作。然而，现有方法忽略了人类属性（如年龄、性别、体重和身高）的影响，而这些属性是塑造动作模式的关键因素。本文首次尝试填补这一空白。我们将每个动作概念化为包含属性信息和动作语义，其中文本描述仅与动作语义对齐。为实现这一点，提出了一种受结构因果模型启发的新框架，用于解耦动作语义和人类属性，从而实现文本到语义的预测和属性控制的生成。生成的模型能够生成与用户文本和属性输入一致的逼真、具有属性感知的动作。为评估模型，我们引入了HumanAttr数据集，该数据集包含文本-动作对的属性注释，为属性感知的文本到动作生成了首个基准。在新数据集上的大量实验验证了模型的有效性。

</details>


### [141] [SepFormer: Coarse-to-fine Separator Regression Network for Table Structure Recognition](https://arxiv.org/abs/2506.21920)
**中文标题：SepFormer：基于粗到细分隔符回归网络的表格结构识别**

*Nam Quan Nguyen,Xuan Phong Pham,Tuan-Anh Tran*

主要分类: cs.CV

摘要简述: SepFormer是一种基于DETR架构的表格结构识别方法，通过粗到细的分隔符回归网络，实现高效且鲁棒的表格逻辑结构重建。


<details>
  <summary>详细信息</summary>
研究动机: 表格结构识别（TSR）是语义数据提取的基础任务，现有方法虽取得进展，但仍需提升速度和鲁棒性。SepFormer旨在通过单步分隔符回归优化这一问题。

研究方法: SepFormer采用粗到细的两阶段方法：粗粒度阶段通过带角度损失的解码器层逐步优化单线分隔符；细粒度阶段通过采样点预测线带分隔符。结合DETR架构，实现高效单步处理。

研究结果: SepFormer在多个基准数据集（如SciTSR、PubTabNet等）上达到与先进方法相当的性能，平均运行速度为25.6 FPS。

研究结论: SepFormer通过粗到细的分隔符回归网络，显著提升了表格结构识别的速度和鲁棒性，为实际应用提供了高效解决方案。

中文摘要: 表格结构识别（TSR）是从图像数据中自动重建表格逻辑结构的基础任务，对语义数据提取至关重要。近期研究通过多种技术取得显著进展。每个表格由垂直和水平分隔符组成。基于此，我们提出SepFormer，将分割与合并范式通过DETR风格架构的单步分隔符回归整合，提升速度和鲁棒性。SepFormer采用粗到细方法，通过两个变压器解码器堆叠，从单线分隔符逐步预测到线带分隔符。粗粒度阶段通过带角度损失的解码器层逐步优化单线分隔符；细粒度阶段通过采样点预测线带分隔符。SepFormer在多个基准数据集（如SciTSR、PubTabNet等）上达到与先进方法相当的性能，平均运行速度为25.6 FPS。

</details>


### [142] [ZeroReg3D: A Zero-shot Registration Pipeline for 3D Consecutive Histopathology Image Reconstruction](https://arxiv.org/abs/2506.21923)
**中文标题：ZeroReg3D：一种用于3D连续组织病理学图像重建的零样本配准流程**

*Juming Xiong,Ruining Deng,Jialin Yue,Siqi Lu,Junlin Guo,Marilyn Lionts,Tianyuan Yao,Can Cui,Junchao Zhu,Chongyu Qu,Mengmeng Yin,Haichun Yang,Yuankai Huo*

主要分类: cs.CV

摘要简述: ZeroReg3D是一种新型零样本配准流程，专为从连续组织切片中实现精确3D重建而设计，解决了组织变形、切片伪影和光照不一致等问题，无需重新训练或微调。


<details>
  <summary>详细信息</summary>
研究动机: 当前2D组织学分析方法在保留3D空间关系方面存在局限，且现有深度学习方法泛化性差，需要大量训练数据。ZeroReg3D旨在解决这些问题，提供一种无需训练的高精度3D重建方案。

研究方法: ZeroReg3D结合了零样本深度学习关键点匹配和基于优化的仿射与非刚性配准技术，有效应对组织变形、切片伪影、染色变异和光照不一致等挑战。

研究结果: ZeroReg3D在无需重新训练或微调的情况下，实现了高精度的3D重建，解决了传统方法在泛化性和准确性上的不足。

研究结论: ZeroReg3D为组织学3D重建提供了一种高效、准确的零样本配准方案，具有广泛的应用潜力。

中文摘要: 组织学分析在理解组织结构和病理学中起着关键作用。尽管配准方法的最新进展改进了2D组织学分析，但它们往往难以保留关键的3D空间关系，限制了其在临床和研究中的应用。具体而言，由于组织变形、切片伪影、成像技术变异和光照不一致，从2D切片构建精确的3D模型仍然具有挑战性。基于深度学习的配准方法表现出更好的性能，但泛化性有限且需要大规模训练数据。相比之下，非深度学习方法具有更好的泛化性，但通常牺牲了准确性。本研究介绍了ZeroReg3D，一种专为从连续组织切片中实现精确3D重建的新型零样本配准流程。通过结合零样本深度学习关键点匹配和基于优化的仿射与非刚性配准技术，ZeroReg3D有效解决了组织变形、切片伪影、染色变异和光照不一致等关键挑战，且无需重新训练或微调。代码已公开在https://github.com/hrlblab/ZeroReg3D。

</details>


### [143] [SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding](https://arxiv.org/abs/2506.21924)
**中文标题：SPAZER：面向零样本3D视觉定位的空间-语义渐进推理智能体**

*Zhao Jin,Rong-Cheng Tu,Jingyi Liao,Wenhao Sun,Xiao Luo,Shunyu Liu,Dacheng Tao*

主要分类: cs.CV

摘要简述: SPAZER是一种结合空间与语义推理的零样本3D视觉定位方法，通过渐进式推理框架显著提升了性能，无需依赖3D标注数据。


<details>
  <summary>详细信息</summary>
研究动机: 现有的零样本3D视觉定位方法往往仅侧重于空间或语义理解，限制了其在复杂场景中的应用效果。SPAZER旨在通过结合两种模态的推理能力，解决这一问题。

研究方法: SPAZER采用渐进式推理框架：首先从最优视角生成3D场景渲染，进行粗粒度定位；随后结合2D图像进行3D-2D联合决策，确定最佳匹配对象。

研究结果: 在ScanRefer和Nr3D基准测试中，SPAZER显著优于现有零样本方法，准确率分别提升9.0%和10.9%。

研究结论: SPAZER通过融合空间与语义推理，实现了无需3D标注数据的鲁棒零样本定位，为复杂场景下的视觉定位提供了有效解决方案。

中文摘要: 3D视觉定位（3DVG）旨在通过自然语言查询在3D场景中定位目标物体。为减少对昂贵3D训练数据的依赖，近期研究利用预训练大语言模型（LLMs）和视觉语言模型（VLMs）的广泛知识与强大推理能力，探索零样本3DVG。然而，现有方法往往仅关注空间（3D）或语义（2D）理解，限制了其在复杂实际应用中的效果。本文提出SPAZER——一种基于VLM的智能体，通过渐进式推理框架结合两种模态。它首先全面分析场景并从最优视角生成3D渲染；随后基于锚点引导的候选筛选进行粗粒度定位；进一步结合检索到的相关2D相机图像，高效执行3D-2D联合决策以确定最佳匹配对象。通过桥接空间与语义推理神经流，SPAZER无需3D标注数据即可实现鲁棒的零样本定位。在ScanRefer和Nr3D基准上的大量实验表明，SPAZER显著优于现有零样本方法，准确率分别提升9.0%和10.9%。

</details>


### [144] [Quality Assessment and Distortion-aware Saliency Prediction for AI-Generated Omnidirectional Images](https://arxiv.org/abs/2506.21925)
**中文标题：AI生成全景图像的质量评估与失真感知显著性预测**

*Liu Yang,Huiyu Duan,Jiarui Wang,Jing Liu,Menghan Hu,Xiongkuo Min,Guangtao Zhai,Patrick Le Callet*

主要分类: cs.CV

摘要简述: 本文研究了AI生成的全景图像（AIGODIs）的质量评估与失真感知显著性预测问题，并提出了基于BLIP-2模型的优化方法。通过建立OHF2024数据库和开发BLIP2OIQA与BLIP2OISal模型，实现了对AIGODIs的视觉体验评估和失真区域预测，并进一步优化图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成内容（AIGC）技术的快速发展，AI生成的全景图像（AIGODIs）在虚拟现实（VR）和增强现实（AR）领域具有巨大潜力。然而，目前对AIGODIs的质量评估与优化的研究仍不足，因此本文旨在填补这一空白。

研究方法: 首先建立了OHF2024数据库，包含主观质量评分和失真感知显著性区域。基于BLIP-2模型，提出了BLIP2OIQA和BLIP2OISal模型，分别用于评估视觉体验和预测失真显著性。最后，利用预测结果设计了自动优化流程。

研究结果: 实验表明，BLIP2OIQA和BLIP2OISal模型在视觉体验评估和失真显著性预测任务中达到了最先进水平，并能有效用于图像优化。

研究结论: 本文提出的方法和模型为AI生成全景图像的质量评估与优化提供了有效工具，推动了相关领域的研究。

中文摘要: 随着人工智能生成内容（AIGC）技术的快速发展，AI生成图像（AIGIs）受到广泛关注，其中AI生成的全景图像（AIGODIs）在虚拟现实（VR）和增强现实（AR）应用中具有重要潜力。然而，AI生成的全景图像存在独特的质量问题，目前对其质量评估与优化的研究仍显不足。为此，本研究首次探讨了AIGODIs的质量评估与失真感知显著性预测问题，并进一步提出了相应的优化流程。具体而言，我们首先建立了一个名为OHF2024的综合数据库，以反映人类对AI生成全景图像的反馈，包括从三个角度评估的主观质量评分和失真感知显著性区域。基于构建的OHF2024数据库，我们提出了两个基于BLIP-2模型的共享编码器模型，分别命名为BLIP2OIQA和BLIP2OISal，用于评估人类视觉体验和预测AI生成全景图像的失真显著性。最后，基于所提出的模型，我们设计了一种自动优化流程，利用预测的视觉体验分数和失真区域进一步提升AI生成全景图像的视觉质量。大量实验表明，我们的BLIP2OIQA模型和BLIP2OISal模型在人类视觉体验评估任务和失真感知显著性预测任务中均达到了最先进水平，并能有效用于优化流程。数据库和代码将在https://github.com/IntMeGroup/AIGCOIQA上发布，以促进未来研究。

</details>


### [145] [SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images](https://arxiv.org/abs/2506.21945)
**中文标题：SDRNET：基于堆叠深度残差网络的高分辨率遥感图像精确语义分割**

*Naftaly Wambugu,Ruisheng Wang,Bo Guo,Tianshu Yu,Sheng Xu,Mohammed Elhassan*

主要分类: cs.CV

摘要简述: 本文提出了一种堆叠深度残差网络（SDRNet），用于高分辨率遥感图像的精确语义分割，通过结合全局-局部上下文和多尺度特征，解决了类间差异和空间细节丢失的问题。


<details>
  <summary>详细信息</summary>
研究动机: 高分辨率遥感图像（FRRS）的语义分割面临类间差异大、关键地物遮挡和物体尺寸变化等挑战，现有深度卷积神经网络（DCNNs）难以提取足够特征。本文旨在设计一种能够学习鲁棒特征并保留空间细节的模型。

研究方法: 提出SDRNet框架，包含两个堆叠的编码器-解码器网络，用于捕获长程语义并保留空间信息；在编码器和解码器之间引入扩张残差块（DRB），以增强全局依赖性。

研究结果: 在ISPRS Vaihingen和Potsdam数据集上的实验表明，SDRNet在语义分割任务中表现优异，优于现有DCNNs。

研究结论: SDRNet通过结合多尺度特征和全局-局部上下文，显著提升了高分辨率遥感图像的语义分割精度，为相关研究提供了有效解决方案。

中文摘要: 通过高分辨率遥感图像的语义分割生成的土地覆盖图在摄影测量和遥感研究领域引起了广泛关注。随着传感和成像技术的进步，大量高分辨率遥感（FRRS）图像变得可用。然而，此类图像的精确语义分割受到类间差异显著、关键地物因遮挡不可见以及物体尺寸变化的严重影响。尽管深度卷积神经网络（DCNNs）在图像特征学习和表示方面具有非凡潜力，但从FRRS图像中提取足够特征以进行精确语义分割仍具挑战性。这些挑战要求深度学习模型学习鲁棒特征并生成足够的特征描述符。具体而言，学习多上下文特征以覆盖地面场景中不同尺寸的物体，以及利用全局-局部上下文克服类间差异，对深度网络提出了更高要求。深度网络因逐步下采样过程而显著丢失空间细节，导致分割结果粗糙和边界模糊。本文提出了一种堆叠深度残差网络（SDRNet）用于FRRS图像的语义分割。该框架利用两个堆叠的编码器-解码器网络捕获长程语义并保留空间信息，同时在每个编码器和解码器网络之间引入扩张残差块（DRB）以捕获足够的全局依赖性，从而提升分割性能。在ISPRS Vaihingen和Potsdam数据集上的实验结果表明，SDRNet在语义分割任务中表现优异且具有竞争力。

</details>


### [146] [Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding](https://arxiv.org/abs/2506.21957)
**中文标题：探索语义掩码自编码器在自监督点云理解中的应用**

*Yixin Zha,Chuxin Wang,Wenfei Yang,Tianzhu Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于语义掩码自编码器的方法，通过原型语义建模和增强掩码策略，解决了随机掩码在点云理解中语义关系捕捉不足的问题，并在多个数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于掩码点建模的预训练方法依赖随机掩码策略，导致自监督模型难以捕捉合理的语义关系。本文旨在通过语义掩码自编码器解决这一问题。

研究方法: 方法包括两部分：原型语义建模模块和组件语义增强掩码策略。前者通过可学习原型捕捉对象组件的语义，后者基于原型设计掩码策略以覆盖完整组件结构。此外，还引入了语义增强提示调优策略以提升下游任务性能。

研究结果: 在ScanObjectNN、ModelNet40和ShapeNetPart等数据集上的实验表明，所提模块显著提升了点云理解任务的性能。

研究结论: 本文提出的语义掩码自编码器通过语义建模和增强掩码策略，有效解决了随机掩码的局限性，为点云理解任务提供了更鲁棒的特征表示。

中文摘要: 点云理解的目标是从无标签数据中获取鲁棒且通用的特征表示。基于掩码点建模的方法近期在多种下游任务中表现出色，但这些预训练方法依赖随机掩码策略，通过恢复损坏的点云输入建立感知，导致自监督模型难以捕捉合理的语义关系。为解决这一问题，我们提出了语义掩码自编码器，包含两个主要组件：基于原型的组件语义建模模块和组件语义增强掩码策略。具体而言，在组件语义建模模块中，我们设计了一种组件语义引导机制，指导一组可学习原型捕捉对象不同组件的语义。利用这些原型，我们开发了一种组件语义增强掩码策略，解决了随机掩码在有效覆盖完整组件结构方面的局限性。此外，我们还引入了一种组件语义增强提示调优策略，进一步利用这些原型提升预训练模型在下游任务中的性能。在ScanObjectNN、ModelNet40和ShapeNetPart等数据集上的广泛实验验证了所提模块的有效性。

</details>


### [147] [TASeg: Text-aware RGB-T Semantic Segmentation based on Fine-tuning Vision Foundation Models](https://arxiv.org/abs/2506.21975)
**中文标题：TASeg：基于视觉基础模型微调的文本感知RGB-T语义分割**

*Meng Yu,Te Cui,Qitong Chu,Wenjie Song,Yi Yang,Yufeng Yue*

主要分类: cs.CV

摘要简述: TASeg是一种基于视觉基础模型微调的文本感知RGB-T语义分割框架，通过动态特征融合模块和CLIP文本嵌入提升分割精度，实验证明其在复杂场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有RGB-T语义分割模型依赖低层视觉特征，缺乏高层文本信息，难以区分视觉相似类别；同时，SAM在实例分割中表现优异，但与热图像和文本的融合存在模态异构和计算效率问题。

研究方法: 提出TASeg框架，采用低秩适应（LoRA）微调技术适配视觉基础模型，设计动态特征融合模块（DFFM）融合多模态视觉特征，并引入CLIP生成的文本嵌入以增强语义对齐。

研究结果: 实验结果表明，TASeg在多个数据集上表现优异，尤其在复杂场景中显著提升分割精度，且训练参数较少。

研究结论: TASeg通过结合视觉和文本信息，有效解决了RGB-T语义分割中的模态异构和语义理解问题，为智能系统提供了更可靠的分割方案。

中文摘要: 开放环境的可靠语义分割对智能系统至关重要，但现有RGB-T语义分割模型主要依赖低层视觉特征，缺乏高层文本信息，难以区分视觉相似类别。尽管SAM在实例分割中表现优异，但其与热图像和文本的融合因模态异构和计算效率问题受限。为此，我们提出TASeg，一种基于低秩适应（LoRA）微调技术的文本感知RGB-T分割框架。具体而言，我们在图像编码器中设计了动态特征融合模块（DFFM），有效融合多模态视觉特征，同时冻结SAM的原始Transformer块。此外，我们在掩码解码器中引入CLIP生成的文本嵌入以实现语义对齐，进一步纠正分类错误并提升语义理解精度。多数据集实验结果表明，我们的方法在复杂场景中以较少的可训练参数实现了卓越性能。

</details>


### [148] [R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning](https://arxiv.org/abs/2506.21980)
**中文标题：R1-Track：通过强化学习将多模态大语言模型直接应用于视觉目标跟踪**

*Biao Wang,Wenwen Li*

主要分类: cs.CV

摘要简述: R1-Track通过强化学习微调多模态大语言模型Qwen2.5-VL，直接应用于视觉目标跟踪任务，在GOT-10k基准测试中表现优异，支持灵活初始化并保留原模型通用能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统视觉目标跟踪方法依赖分类和回归建模，需大规模监督训练且任务单一。多模态大语言模型（MLLMs）如Qwen2.5-VL在基础任务中表现优异，但直接应用于跟踪任务效果不佳。本文旨在探索如何通过强化学习微调MLLMs，使其直接胜任跟踪任务。

研究方法: 利用基于规则的奖励函数和小规模数据集，采用组相对策略优化（GRPO）强化学习方法对Qwen2.5-VL进行微调，得到模型R1-Track。

研究结果: R1-Track在GOT-10k基准测试中表现突出，支持通过边界框或文本描述灵活初始化，同时保留了原模型的大部分通用能力。

研究结论: R1-Track展示了MLLMs通过强化学习直接应用于视觉跟踪任务的潜力，并讨论了未来改进方向。

中文摘要: 视觉单目标跟踪任务旨在给定目标在首帧的初始状态后，持续定位并估计其在后续视频帧中的尺度。传统方法通常将其视为模板匹配问题，经历了相关滤波器、双流网络和单流网络等阶段，取得了显著进展。然而，这些方法通常需要显式的分类和回归建模，依赖大规模监督训练，且仅限于单一跟踪任务，缺乏灵活性。近年来，多模态大语言模型（MLLMs）快速发展，如开源模型Qwen2.5-VL在基础任务中表现出色。这激发了将其直接应用于视觉跟踪的兴趣。然而实验表明，Qwen2.5-VL在图像对模板匹配（即跟踪任务）中表现不佳。受deepseek-R1启发，我们采用组相对策略优化（GRPO）强化学习方法，基于小规模数据集和基于规则的奖励函数对Qwen2.5-VL进行微调，得到模型R1-Track。R1-Track在GOT-10k基准测试中表现优异，支持通过边界框或文本描述灵活初始化，同时保留了原模型的大部分通用能力。我们还进一步讨论了R1-Track的潜在改进方向。本技术报告总结了截至2025年5月的研究成果。

</details>


### [149] [RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation](https://arxiv.org/abs/2506.22007)
**中文标题：RoboEnvision：一种用于多任务机器人操作的长时程视频生成模型**

*Liudi Yang,Yang Bai,George Eskandar,Fengyi Shen,Mohammad Altillawi,Dong Chen,Soumajit Majumder,Ziyuan Liu,Gitta Kutyniok,Abhinav Valada*

主要分类: cs.CV

摘要简述: 本文提出了一种名为RoboEnvision的新型视频生成模型，用于解决机器人多任务操作中的长时程视频生成问题。通过分解任务、关键帧生成与插值，以及语义保持注意力模块，避免了自回归生成的误差累积，并在视频质量和一致性上达到最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到视频扩散模型在真实感、语言理解和运动生成方面取得了进展，但在长时程机器人任务中表现不佳。自回归生成方法会导致视频生成和执行中的误差累积。因此，本文旨在提出一种无需自回归生成的新方法，以提升长时程任务的视频生成质量。

研究方法: 1) 将高级目标分解为原子任务并生成与之对齐的关键帧，随后通过第二扩散模型在关键帧之间插值生成长时程视频；2) 提出语义保持注意力模块以保持关键帧间的一致性；3) 设计轻量级策略模型从生成视频中回归机器人关节状态。

研究结果: 在两个基准测试中，本文方法在视频质量和一致性上达到最优结果，并在长时程任务中优于现有策略模型。

研究结论: RoboEnvision通过非自回归生成方法有效解决了长时程机器人任务中的视频生成问题，显著提升了生成视频的质量和一致性。

中文摘要: 我们解决了为机器人操作任务生成长时程视频的问题。文本到视频扩散模型在真实感、语言理解和运动生成方面取得了显著进展，但在长时程机器人任务中表现不佳。近期研究利用视频扩散模型生成高质量仿真数据并用于机器人规划中的预测推演，但这些方法仅预测机器人完成单一任务的短序列，并通过自回归范式扩展到长时程，导致生成视频和执行中的误差累积。为克服这些限制，我们提出了一种无需自回归生成的新流程。具体贡献包括：1) 将高级目标分解为原子任务并生成与之对齐的关键帧，随后通过第二扩散模型在关键帧之间插值生成长时程视频；2) 提出语义保持注意力模块以保持关键帧间的一致性；3) 设计轻量级策略模型从生成视频中回归机器人关节状态。我们的方法在两个基准测试中实现了视频质量和一致性的最优结果，并在长时程任务中优于现有策略模型。

</details>


### [150] [Towards Universal & Efficient Model Compression via Exponential Torque Pruning](https://arxiv.org/abs/2506.22015)
**中文标题：迈向通用高效模型压缩：基于指数扭矩的剪枝方法**

*Sarthak Ketanbhai Modi,Lim Zi Pong,Shourya Kuchhal,Yoshi Cao,Yupeng Cheng,Teo Yon Shin,Lin Shang-Wei,Zhiming Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为指数扭矩剪枝（ETP）的新方法，通过指数力应用方案改进模型压缩效果，显著提高了压缩率且几乎不影响准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现代深度神经网络（DNNs）的复杂性和规模快速增长，导致计算成本和内存使用问题日益突出。现有基于扭矩正则化的剪枝方法效果不佳，剪枝后网络仍较密集且准确性下降明显。本文旨在解决这一问题。

研究方法: 提出指数扭矩剪枝（ETP），采用指数力应用方案进行正则化，有效剪除冗余和远距离模块，同时保留对推理必要的近距离模块。

研究结果: 实验结果表明，ETP在多个领域均能显著提高压缩率，且准确性下降几乎可以忽略不计，优于现有最先进的剪枝策略。

研究结论: ETP是一种简单高效的模型压缩方法，通过指数力应用方案显著提升了剪枝效果，为模型压缩领域提供了新的解决方案。

中文摘要: 现代深度神经网络（DNNs）的复杂性和规模快速增长，增加了计算成本和内存使用的挑战，推动了高效模型压缩技术的发展。现有基于扭矩正则化的方法通过迫使神经模块权重围绕选定枢轴点分布，但其剪枝效果远不理想，剪枝后网络仍较密集且准确性下降明显。本文认为这种低效性源于默认的线性力应用方案，其对不同距离的神经模块施加了不合适的力。为高效剪除冗余和远距离模块，同时保留对推理必要的近距离模块，本文提出指数扭矩剪枝（ETP），采用指数力应用方案进行正则化。实验结果表明，尽管方法极为简单，ETP在多个领域均能显著提高压缩率，且准确性下降几乎可以忽略不计，优于现有最先进的剪枝策略。

</details>


### [151] [Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision](https://arxiv.org/abs/2506.22022)
**中文标题：通过语义保留约束和伪配对监督推进面部风格化**

*Zhanyi Lu,Yue Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种结合语义保留约束和伪配对监督的面部风格化方法，通过多级伪配对数据集增强内容一致性，实现了高质量的风格转换，并在实验中超越了现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于StyleGAN的面部风格化方法在生成结果中常出现伪影或与源图像内容不一致的问题，主要原因是忽略了生成过程中的语义偏移。因此，本文旨在通过语义保留约束和伪配对监督提升风格化效果。

研究方法: 提出了一种整合语义保留约束和伪配对监督的面部风格化框架，并开发了多级伪配对数据集生成方法以实施监督约束。此外，基于该框架实现了无需复杂网络设计的多模态和参考引导风格化。

研究结果: 实验结果表明，该方法生成的面部风格转换结果具有高保真度和美学吸引力，显著优于现有方法。

研究结论: 本文提出的方法通过语义保留约束和伪配对监督有效提升了面部风格化的内容一致性和效果，同时实现了灵活的多模态风格化。

中文摘要: 面部风格化的目标是将面部图像转化为具有吸引力的高质量风格化肖像，其核心挑战在于准确学习目标风格的同时保持与原始图像的内容一致性。尽管基于StyleGAN的现有方法已取得显著进展，但生成结果仍存在伪影或与源图像保真度不足的问题。我们认为这些问题源于风格化过程中对生成器语义偏移的忽视。因此，我们提出了一种整合语义保留约束和伪配对监督的面部风格化方法，以增强内容对应关系并提升风格化效果。此外，我们开发了一种生成多级伪配对数据集的方法以实施监督约束。基于该框架，我们还实现了无需复杂网络设计或额外训练的多模态和参考引导风格化。实验结果表明，我们的方法生成的高保真度、美学吸引力强的面部风格转换结果超越了现有方法。

</details>


### [152] [Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method](https://arxiv.org/abs/2506.22027)
**中文标题：基于光学与SAR图像的跨模态船舶重识别：新数据集与方法**

*Han Wang,Shengyang Li,Jian Yang,Yuxuan Liu,Yixuan Lv,Zhuang Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种基于光学和合成孔径雷达（SAR）图像的跨模态船舶重识别数据集（HOSS ReID）及基线方法TransOSS，旨在解决传统船舶跟踪方法的局限性，实现全天候、高分辨率的船舶跟踪。


<details>
  <summary>详细信息</summary>
研究动机: 当前船舶跟踪方法依赖地球静止卫星或视频卫星，前者分辨率低且受天气影响，后者拍摄时间短且覆盖范围有限。为解决这些问题，本文提出了结合光学和SAR图像的新数据集和方法。

研究方法: 提出了HOSS ReID数据集，包含多模态、多时间、多角度的船舶图像；并设计了基于Vision Transformer的TransOSS方法，通过改进补丁嵌入结构、引入额外嵌入和对比学习预训练，提取模态不变特征。

研究结果: HOSS ReID数据集和TransOSS方法为跨模态船舶重识别提供了有效工具，实现了全天候、高分辨率的船舶跟踪。

研究结论: 本文提出的数据集和方法为船舶跟踪领域提供了新的解决方案，解决了传统方法的局限性，具有实际应用价值。

中文摘要: 利用地球观测图像检测和跟踪地面目标仍是遥感领域的重要挑战。连续的海上船舶跟踪对于海上搜救、执法和航运分析等应用至关重要。然而，当前大多数船舶跟踪方法依赖地球静止卫星或视频卫星，前者分辨率低且易受天气影响，后者拍摄时间短且覆盖范围有限，难以满足实际需求。为解决这些问题，我们提出了混合光学与合成孔径雷达（SAR）船舶重识别数据集（HOSS ReID），旨在评估利用低地球轨道光学和SAR传感器星座进行船舶跟踪的有效性。该方法缩短了重成像周期，实现了全天候跟踪。HOSS ReID数据集包含同一船舶在不同条件下、不同时间、不同角度和多模态卫星拍摄的图像。此外，我们提出了一种跨模态船舶重识别的基线方法TransOSS，基于Vision Transformer架构，改进了补丁嵌入结构以适应跨模态任务，引入额外嵌入以提供更多参考信息，并采用对比学习在大规模光学-SAR图像对上预训练，确保模型提取模态不变特征的能力。我们的数据集和基线方法已在https://github.com/Alioth2000/Hoss-ReID公开。

</details>


### [153] [Partial CLIP is Enough: Chimera-Seg for Zero-shot Semantic Segmentation](https://arxiv.org/abs/2506.22032)
**中文标题：部分CLIP足矣：用于零样本语义分割的Chimera-Seg**

*Jialei Chen,Xu Zheng,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi*

主要分类: cs.CV

摘要简述: 本文提出Chimera-Seg方法，通过结合分割模型和CLIP语义头，解决了零样本语义分割中视觉-语言对齐的挑战，并引入选择性全局蒸馏和语义对齐模块，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 零样本语义分割（ZSS）旨在仅利用可见类别的监督分割可见和未见类别。现有方法在将视觉语言模型（如CLIP）的对齐知识迁移到分割模型时面临两大挑战：视觉特征与文本空间对齐的困难，以及CLIP全局表示与分割模型局部特征之间的语义鸿沟。

研究方法: Chimera-Seg将分割模型作为主体，CLIP语义头（CSH）作为头部，结合空间精度与视觉-语言对齐。CSH包含CLIP视觉编码器的冻结子网络和固定投影层，以及轻量可训练组件。此外，提出选择性全局蒸馏（SGD）和语义对齐模块（SAM），逐步优化特征对齐。

研究结果: 在两个基准测试中，Chimera-Seg的hIoU分别提升了0.9%和1.2%，验证了方法的有效性。

研究结论: Chimera-Seg通过部分CLIP模块和选择性知识蒸馏，成功解决了零样本语义分割中的对齐挑战，显著提升了性能。

中文摘要: 零样本语义分割（ZSS）旨在仅利用可见类别的监督分割可见和未见类别。与基于适应的方法不同，基于蒸馏的方法将视觉语言模型（如CLIP）的对齐知识迁移到分割模型。然而，这种知识迁移面临两大挑战：（1）视觉特征与文本空间对齐的困难，需要结合空间精度与视觉-语言对齐；（2）CLIP的全局表示与分割模型的局部细粒度特征之间的语义鸿沟。为解决挑战（1），我们提出Chimera-Seg，将分割模型作为主体，CLIP语义头（CSH）作为头部，结合空间精度与视觉-语言对齐。CSH包含CLIP视觉编码器的冻结子网络和固定投影层，以及轻量可训练组件。CLIP视觉编码器的部分模块与分割模型结合，保留了分割能力，同时简化了与CLIP语义空间的映射。为解决挑战（2），我们提出选择性全局蒸馏（SGD），从与CLIP CLS标记高度相似的密集特征中蒸馏知识，并逐步减少用于对齐的特征数量。此外，还使用语义对齐模块（SAM）进一步对齐密集视觉特征与CLIP文本编码器提取的语义嵌入。在两个基准测试中，hIoU分别提升了0.9%和1.2%。

</details>


### [154] [Few-Shot Identity Adaptation for 3D Talking Heads via Global Gaussian Field](https://arxiv.org/abs/2506.22044)
**中文标题：基于全局高斯场的少样本身份适应3D说话头合成**

*Hong Nie,Fuyuan Cao,Lu Chen,Fengxin Chen,Yuefeng Zou,Jun Yu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FIAG的新型3D说话头合成框架，通过全局高斯场和通用运动场实现高效的身份适应，仅需少量训练数据即可生成高质量结果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于重建和渲染的说话头合成方法虽然能保持高质量和身份一致性，但需要为每个新身份从头训练模型，计算成本高且扩展性差。本文旨在解决这一问题。

研究方法: FIAG框架结合了全局高斯场（支持多身份共享表示）和通用运动场（捕捉跨身份的共同运动动态），利用少量数据快速适应特定身份。

研究结果: 实验表明，FIAG在性能和泛化能力上优于现有方法，验证了其有效性。

研究结论: FIAG通过共享结构和运动先验，实现了高效的身份适应，为3D说话头合成提供了可扩展的解决方案。

中文摘要: 基于重建和渲染的说话头合成方法虽然能实现高质量和身份一致性，但其依赖身份特定模型，每个新身份需从头训练，计算成本高且扩展性差。为解决这一问题，我们提出了FIAG，一种新型3D说话头合成框架，通过全局高斯场（支持多身份共享表示）和通用运动场（捕捉跨身份的共同运动动态），仅需少量训练数据即可实现高效身份适应。得益于全局高斯场中编码的共享面部结构信息和运动场中学习的一般运动先验，我们的框架能够快速从标准身份表示适应到特定身份。大量对比和消融实验表明，我们的方法优于现有技术，验证了框架的有效性和泛化能力。代码见：\textit{https://github.com/gme-hong/FIAG}。

</details>


### [155] [EnLVAM: Enhanced Left Ventricle Linear Measurements Utilizing Anatomical Motion Mode](https://arxiv.org/abs/2506.22063)
**中文标题：EnLVAM：利用解剖运动模式增强左心室线性测量**

*Durgesh K. Singh,Ahcene Boubekki,Qing Cao,Svein Arne Aase,Robert Jenssen,Michael Kampffmeyer*

主要分类: cs.CV

摘要简述: 本文提出了一种增强左心室线性测量的新框架EnLVAM，通过强制直线约束和结合解剖M模式图像，显著提高了测量准确性，同时简化了用户交互。


<details>
  <summary>详细信息</summary>
研究动机: 传统B模式超声心动图中，左心室的线性测量依赖手动标记，耗时且易出错；现有深度学习方法常导致标记点错位，影响测量精度。因此，需要一种更准确且高效的解决方案。

研究方法: 提出了一种结合解剖M模式（AMM）图像的新框架，通过训练标记点检测器并实时从B模式视频生成AMM图像，再将其转换回B模式空间，强制直线约束以减少错位。半自动设计仅需用户放置虚拟扫描线，简化交互。

研究结果: 实验表明，该方法显著提高了左心室线性测量的准确性，优于传统B模式方法，且在不同网络架构中表现良好。

研究结论: EnLVAM框架通过结合AMM图像和直线约束，有效解决了标记点错位问题，提高了测量精度，同时简化了用户操作，具有临床实用价值。

中文摘要: 在B模式超声心动图的胸骨旁长轴视图中，左心室（LV）的线性测量对心脏评估至关重要。传统方法需手动沿垂直于LV轴的虚拟扫描线（SL）放置4-6个标记点，耗时且易出错；现有深度学习方法常导致标记点错位，影响测量精度。本文提出了一种新框架，通过强制直线约束提高测量准确性。该方法训练标记点检测器于解剖M模式（AMM）图像上，实时从B模式视频生成AMM图像并转换回B模式空间，从而解决错位问题并减少测量误差。实验表明，该方法优于传统B模式方法，且在不同网络架构中泛化性强。半自动设计仅需用户放置SL，简化交互的同时保留了临床灵活性。

</details>


### [156] [MirrorMe: Towards Realtime and High Fidelity Audio-Driven Halfbody Animation](https://arxiv.org/abs/2506.22065)
**中文标题：MirrorMe：面向实时高保真音频驱动的半身动画**

*Dechao Meng,Steven Xiao,Xindi Zhang,Guangyuan Wang,Peng Zhang,Qi Wang,Bang Zhang,Liefeng Bo*

主要分类: cs.CV

摘要简述: 本文提出MirrorMe框架，通过LTX视频模型实现实时高保真音频驱动半身动画，解决了传统方法在实时性和时间一致性上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 音频驱动肖像动画在实时生成高保真且时间一致的视频方面面临挑战，现有扩散方法因逐帧处理导致高延迟和时间不一致。

研究方法: MirrorMe基于LTX视频模型，提出三项创新：1. 通过VAE编码图像拼接和自注意力保持身份一致性；2. 针对LTX时间结构的因果音频编码器和适配器；3. 渐进式训练策略结合面部、半身和手势控制。

研究结果: 在EMTD基准测试中，MirrorMe在保真度、唇同步准确性和时间稳定性上表现最优。

研究结论: MirrorMe通过高效潜在空间去噪和针对性设计，实现了实时高保真音频驱动动画，为相关领域提供了新思路。

中文摘要: 音频驱动肖像动画通过参考图像和音频信号合成逼真视频，但在实时生成高保真且时间一致的动画方面面临挑战。尽管近期基于扩散的方法通过将音频融入去噪过程提升了生成质量，但其依赖逐帧UNet架构导致高延迟和时间一致性不足。本文提出MirrorMe，一种基于LTX视频模型（一种通过空间和时间压缩实现高效潜在空间去噪的扩散变换器）的实时可控框架。针对LTX在压缩与语义保真度间的权衡，我们提出三项创新：1. 通过VAE编码图像拼接和自注意力的参考身份注入机制，确保身份一致性；2. 针对LTX时间结构的因果音频编码器和适配器，实现精确的音频-表情同步；3. 渐进式训练策略，结合面部特写训练、半身合成与面部遮罩以及手势整合，增强姿势控制。在EMTD基准测试中的大量实验表明，MirrorMe在保真度、唇同步准确性和时间稳定性上达到最优性能。

</details>


### [157] [Single-Scanline Relative Pose Estimation for Rolling Shutter Cameras](https://arxiv.org/abs/2506.22069)
**中文标题：基于单扫描线的滚动快门相机相对位姿估计**

*Petr Hruby,Marc Pollefeys*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的方法，通过单扫描线投影的交点估计滚动快门相机之间的相对位姿，无需显式建模相机运动，为滚动快门结构从运动（SfM）提供了基础模块。


<details>
  <summary>详细信息</summary>
研究动机: 滚动快门相机在动态场景中广泛使用，但其位姿估计通常需要复杂的运动模型。本文旨在提出一种无需运动模型的位姿估计方法，简化滚动快门SfM的初始化过程。

研究方法: 利用单扫描线投影的交点估计相对位姿，支持单视图或多视图场景。通过最小求解器处理平行线和已知重力方向的特殊情况，假设已知相机内参且无镜头畸变。

研究结果: 在Fastec数据集上的实验表明，该方法能够有效初始化滚动快门SfM，展示了其进一步开发的潜力。

研究结论: 该方法为滚动快门SfM提供了一种无需运动模型的位姿估计解决方案，具有实际应用前景。

中文摘要: 我们提出了一种新颖的方法，通过单扫描线投影的交点估计滚动快门相机之间的相对位姿，无需显式建模相机运动。此外，扫描线可以在单幅图像中选择，从而支持滚动快门相机的单视图相对位姿估计。该方法设计为滚动快门结构从运动（SfM）的基础模块，无需运动模型，且每一条扫描线的位姿可以独立计算。我们针对通用和特殊场景（包括平行线和已知重力方向的情况）分类了最小求解器，假设已知相机内参且无镜头畸变。此外，通过将该问题与基于1D相机的2D结构估计联系起来，我们开发了平行线场景的最小求解器，包括有和无重力先验的情况。在Fastec数据集上的滚动快门图像实验中，验证了该方法用于初始化滚动快门SfM的可行性，展示了其进一步开发的潜力。代码将公开提供。

</details>


### [158] [Reasoning in machine vision: learning to think fast and slow](https://arxiv.org/abs/2506.22075)
**中文标题：机器视觉中的推理：学习快思考与慢思考**

*Shaheer U. Saeed,Yipei Wang,Veeru Kasivisvanathan,Brian R. Davidson,Matthew J. Clarkson,Yipeng Hu,Daniel C. Alexander*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的学习范式，通过结合快速思考的System I模块和慢速思考的System II模块，使机器在视觉任务中实现推理能力，并在数据稀缺条件下通过增加思考时间提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 人类推理能力在复杂场景中表现出色，而机器智能仍受限于训练数据，无法在推理时动态优化解决方案。现有研究多集中于基于明确规则的数学问题求解，而视觉感知等非语言推理任务仍具挑战性。本文旨在填补这一空白。

研究方法: 受心理学双过程理论启发，提出了一种结合快速思考（System I）和慢速思考（System II）的模块化方法。System I处理熟悉任务，System II通过自对弈强化学习迭代优化解决方案，模拟人类推理过程。

研究结果: 在视觉任务中，该方法通过延长思考时间表现出卓越性能，优于大规模监督学习、基础模型甚至人类专家，尤其在医学图像中的癌症定位任务中表现突出。

研究结论: 该研究为非语言机器推理提供了新范式，展示了在数据稀缺条件下通过动态推理提升性能的潜力，为视觉任务中的机器推理开辟了新方向。

中文摘要: 推理是人类智能的标志，能够在复杂和陌生场景中实现适应性决策。相比之下，机器智能仍受限于训练数据，缺乏在推理时动态优化解决方案的能力。尽管近期研究探索了机器推理，但这些工作多局限于数学问题求解等语言领域，依赖明确的逐步推理规则。其他关键现实任务（如视觉感知、空间推理和放射诊断）需要非语言推理，这仍是一个开放挑战。本文提出了一种新颖的学习范式，通过允许机器在思考时间（推理计算）增加时提升性能，实现了视觉任务中的机器推理，即使在标记数据非常有限的条件下。受心理学中人类认知的双过程理论启发，我们的方法整合了一个快速思考的System I模块（用于熟悉任务）和一个慢速思考的System II模块（通过自对弈强化学习迭代优化解决方案）。这一范式通过提出、竞争和优化解决方案，模拟了人类在数据稀缺场景中的推理过程。我们展示了在延长思考时间后的卓越性能，不仅优于大规模监督学习和基础模型，甚至超越人类专家，应用于现实视觉任务（包括计算机视觉基准测试和五种器官的医学图像癌症定位），展现了非语言机器推理的变革潜力。

</details>


### [159] [Towards Accurate Heart Rate Measurement from Ultra-Short Video Clips via Periodicity-Guided rPPG Estimation and Signal Reconstruction](https://arxiv.org/abs/2506.22078)
**中文标题：基于周期性引导的rPPG估计与信号重建的超短视频片段心率精确测量**

*Pei-Kai Huanga,Ya-Ting Chan,Kuan-Wen Chen,Yen-Chun Chou,Shih-Yu Yang,Chiou-Ting Hsu*

主要分类: cs.CV

摘要简述: 本文提出了一种通过周期性引导的rPPG估计和信号重建方法，从超短2秒视频片段中准确测量心率，解决了传统方法在超短片段中忽略的问题，并在实验中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有远程心率测量方法多关注10秒左右的视频片段，而忽略了从超短片段（如2秒）中准确测量心率的需求。本文旨在解决这一空白，并应对超短片段中心跳周期有限和频谱泄漏带来的挑战。

研究方法: 本文提出两种方法：1）周期性引导的rPPG估计，确保超短片段与长片段信号周期一致；2）引入生成器重建长rPPG信号，保持周期性以提高心率测量准确性。

研究结果: 在四个rPPG基准数据集上的实验表明，该方法不仅能从超短视频中准确测量心率，还优于现有技术，达到最优性能。

研究结论: 通过周期性引导的信号估计和重建，本文成功实现了从超短视频片段中高精度测量心率，为远程心率测量提供了新思路。

中文摘要: 许多远程心率（HR）测量方法专注于从约10秒的视频片段中估计远程光电容积描记（rPPG）信号，但往往忽略了从超短视频片段中测量心率的需求。本文旨在通过解决两个关键挑战，从超短的2秒视频片段中准确测量心率。首先，为克服超短片段中心跳周期有限的问题，我们提出了一种有效的周期性引导rPPG估计方法，确保超短片段估计的rPPG信号与其更长的真实信号周期一致。其次，为减少频谱泄漏导致的估计误差，我们提出引入生成器以从超短信号中重建更长的rPPG信号，同时保持其周期性，从而实现更准确的心率测量。在四个rPPG估计基准数据集上的大量实验表明，我们提出的方法不仅能从超短视频中准确测量心率，还优于以往的rPPG估计技术，达到了最优性能。

</details>


### [160] [BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting](https://arxiv.org/abs/2506.22099)
**中文标题：BézierGS：基于Bézier曲线高斯泼溅的动态城市场景重建**

*Zipei Ma,Junzhe Jiang,Yurui Chen,Li Zhang*

主要分类: cs.CV

摘要简述: 本文提出BézierGS方法，通过可学习的Bézier曲线建模动态物体运动轨迹，无需依赖高精度物体姿态标注，实现了动态与静态场景元素的准确分离与重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有街景重建方法依赖物体姿态标注，限制了大规模场景重建。本文旨在通过Bézier曲线建模动态物体运动轨迹，减少对标注的依赖，提升重建效果。

研究方法: 提出BézierGS方法，利用可学习的Bézier曲线表示动态物体运动轨迹，结合动态物体渲染监督和曲线间一致性约束，实现场景元素的合理分离与重建。

研究结果: 在Waymo Open Dataset和nuPlan基准测试中，BézierGS在动态与静态场景重建及新视角合成方面优于现有方法。

研究结论: BézierGS通过Bézier曲线建模动态物体运动轨迹，显著提升了场景重建的准确性和鲁棒性，为自动驾驶仿真提供了有效工具。

中文摘要: 街景的真实重建对自动驾驶仿真至关重要。现有方法多依赖物体姿态标注，限制了大规模场景重建。为此，我们提出Bézier曲线高斯泼溅（BézierGS），利用可学习的Bézier曲线表示动态物体运动轨迹，结合动态物体渲染监督和曲线间一致性约束，实现场景元素的合理分离与重建。在Waymo Open Dataset和nuPlan基准测试中，BézierGS在动态与静态场景重建及新视角合成方面表现优异。

</details>


### [161] [Tied Prototype Model for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2506.22101)
**中文标题：绑定原型模型用于医学图像小样本分割**

*Hyeongji Kim,Stine Hansen,Michael Kampffmeyer*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Tied Prototype Model (TPM)的新方法，用于改进医学图像的小样本分割问题。TPM通过绑定前景和背景的原型位置，解决了现有方法ADNet的局限性，并支持多原型和多类分割，显著提升了分割精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的医学图像小样本分割方法（如ADNet）存在三个主要问题：每个类别仅使用单一原型、仅支持二分类、固定阈值无法适应不同患者和器官的变异性。TPM旨在解决这些问题，提供更灵活和高效的分割方案。

研究方法: TPM通过绑定前景和背景的原型分布，重新构建了ADNet的概率模型。该方法支持多原型和多类分割，并利用自然出现的类别先验定义自适应阈值，从而优化分割性能。

研究结果: 实验表明，TPM在多原型和多类分割任务中均表现出更高的准确性，且能有效分离非典型背景特征，显著提升了分割效果。

研究结论: TPM为医学图像小样本分割提供了一种新的原型建模视角，解决了现有方法的局限性，并通过自适应阈值和多原型支持进一步提升了性能。

中文摘要: 常见的基于原型的医学图像小样本分割（FSS）方法使用类别特定的原型建模前景和背景。然而，由于背景的高度变异性，更有效的方法是仅关注前景建模，将背景视为异常——这是ADNet引入的方法。但ADNet存在三个关键限制：每个类别依赖单一原型、仅支持二分类、固定阈值无法适应患者和器官的变异性。为解决这些问题，我们提出了绑定原型模型（TPM），通过绑定前景和背景分布的原型位置，对ADNet进行了原则性重构。基于其概率基础，TPM自然扩展到多原型和多类分割，同时有效分离非典型背景特征。值得注意的是，这两种扩展均显著提升了分割精度。最后，我们利用自然出现的类别先验定义自适应阈值的目标，进一步提升了分割性能。总之，TPM为医学图像小样本分割的原型建模提供了新的视角。代码可在https://github.com/hjk92g/TPM-FSS找到。

</details>


### [162] [Pedestrian Intention and Trajectory Prediction in Unstructured Traffic Using IDD-PeD](https://arxiv.org/abs/2506.22111)
**中文标题：使用IDD-PeD预测非结构化交通中的行人意图与轨迹**

*Ruthvik Bokkasam,Shankar Gangisetty,A. H. Abdul Hafez,C. V. Jawahar*

主要分类: cs.CV

摘要简述: 本文介绍了印度驾驶行人数据集（IDD-PeD），旨在解决非结构化环境中行人行为建模的复杂性，如光照变化、遮挡和无信号场景。现有意图和轨迹预测方法在该数据集上表现显著下降，突显其挑战性。


<details>
  <summary>详细信息</summary>
研究动机: 随着自动驾驶技术的快速发展，准确预测行人行为对复杂交通环境中的安全性至关重要。然而，现有数据集未能充分捕捉非结构化环境的复杂性，因此需要更全面的数据集以支持更鲁棒的预测模型开发。

研究方法: 本文提出了一种印度驾驶行人数据集（IDD-PeD），包含高水平和低水平的详细标注，重点关注需要自车注意的行人行为。数据集涵盖了光照变化、遮挡、无信号场景及车辆与行人交互等复杂情况。

研究结果: 实验表明，现有意图预测方法在IDD-PeD数据集上性能下降高达15%，轨迹预测方法的均方误差（MSE）增加高达1208，显著低于标准行人数据集的表现。

研究结论: IDD-PeD数据集为非结构化环境中的行人行为研究提供了新挑战，有望推动更鲁棒的预测模型开发。

中文摘要: 随着自动驾驶技术的快速发展，准确预测行人行为对复杂且不可预测的交通环境中的安全性至关重要。这一挑战的日益突出表明，需要能够捕捉非结构化环境的全面数据集，以支持开发更鲁棒的预测模型，从而提升行人安全和车辆导航能力。本文介绍了一种印度驾驶行人数据集，旨在解决非结构化环境中行人行为建模的复杂性，如光照变化、行人遮挡、无信号场景类型及车辆与行人交互。该数据集提供了针对需要自车注意的行人的高水平及低水平详细标注。对现有意图预测方法在该数据集上的评估显示，其性能显著下降高达15%，而轨迹预测方法的均方误差（MSE）增加高达1208，远低于标准行人数据集的表现。此外，我们还对意图和轨迹预测基线进行了详尽的定量和定性分析。我们相信，该数据集将为行人行为研究社区提供新的挑战，推动鲁棒模型的构建。项目页面：https://cvit.iiit.ac.in/research/projects/cvit-projects/iddped

</details>


### [163] [Pipe Reconstruction from Point Cloud Data](https://arxiv.org/abs/2506.22118)
**中文标题：基于点云数据的管道重建**

*Antje Alex,Jannis Stoppe*

主要分类: cs.CV

摘要简述: 本文提出了一种从点云数据自动重建管道的方法，通过拉普拉斯收缩和曲线延伸估计骨架曲线，结合滚动球技术和2D圆拟合优化骨架轴，最终生成详细的3D管道网络模型，显著提高了建模效率和精度。


<details>
  <summary>详细信息</summary>
研究动机: 工业资产（如船舶和海上平台）的精确数字孪生依赖于复杂管道网络的准确重建。传统手动建模方法耗时耗力，因此需要一种自动化方法以提高效率和降低成本。

研究方法: 方法包括：1）使用拉普拉斯收缩估计骨架曲线；2）通过曲线延伸优化骨架；3）结合滚动球技术和2D圆拟合重新居中骨架轴；4）通过3D平滑步骤细化模型，最终确定管道属性（半径、长度和方向）。

研究结果: 该方法能够从非完整激光扫描数据中自动重建管道，生成详细的3D模型，显著提高了建模速度和精度，同时降低了成本。

研究结论: 本文提出的自动化管道重建方法为数字孪生提供了高效、精确的建模支持，适用于复杂管道网络的快速重建。

中文摘要: 工业资产（如船舶和海上平台）的精确数字孪生依赖于复杂管道网络的准确重建。然而，从激光扫描数据手动建模管道耗时耗力。本文提出了一种从非完整激光扫描数据自动重建管道的流程。该方法通过拉普拉斯收缩估计骨架曲线，随后进行曲线延伸。骨架轴通过滚动球技术和2D圆拟合重新居中，并通过3D平滑步骤细化。这能够确定管道属性（如半径、长度和方向），并支持复杂管道网络的详细3D模型生成。通过自动化管道重建，该方法为数字孪生提供了快速、精确的建模支持，同时降低了成本。

</details>


### [164] [Low-Rank Implicit Neural Representation via Schatten-p Quasi-Norm and Jacobian Regularization](https://arxiv.org/abs/2506.22134)
**中文标题：基于Schatten-p拟范数和雅可比正则化的低秩隐式神经表示**

*Zhengyun Cheng,Changhao Wang,Guanwen Zhang,Yi Xu,Wei Zhou,Xiangyang Ji*

主要分类: cs.CV

摘要简述: 本文提出了一种基于CP分解的低秩张量函数（CP-INR），用于隐式神经表示，结合Schatten-p拟范数和雅可比正则化，实现了多维数据的稀疏表示和光滑性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法如Tucker分解在灵活性和可解释性之间存在权衡，而CP分解虽然更自然但难以获得稀疏解。本文旨在通过神经网络的非线性能力，结合CP分解的理论优势，解决多维数据的低秩表示问题。

研究方法: 提出CP-INR方法，利用Schatten-p拟范数实现稀疏CP分解，并通过雅可比矩阵的谱范数正则化保证光滑性，避免了显式链式求导和SVD计算。

研究结果: 在图像修复、去噪和点云上采样等任务中，CP-INR方法表现出优于现有技术的性能和通用性。

研究结论: CP-INR方法为多维数据的低秩表示提供了理论保障和实际应用价值，尤其在连续数据表示中具有显著优势。

中文摘要: 高阶张量非常适合表示多维数据，如彩色图像和视频。低秩张量表示在机器学习和计算机视觉中变得至关重要，但现有方法（如Tucker分解）在灵活性上牺牲了可解释性。相比之下，CANDECOMP/PARAFAC（CP）分解提供了更自然且可解释的张量结构，但稀疏解的获取仍具挑战性。利用CP分解的丰富特性，我们提出了一种基于CP的低秩张量函数（CP-INR），通过神经网络参数化实现隐式神经表示。该方法支持超越结构化网格的连续数据表示，充分利用张量数据的非线性特性，并在理论上有超额风险界的保证。为实现稀疏CP分解，我们引入了Schatten-p拟范数的变分形式，并证明了其与多线性秩最小化的关系。为保持光滑性，我们提出了一种基于雅可比矩阵谱范数和Hutchinson迹估计的正则化项。该光滑性正则化无需SVD计算，避免了显式链式求导，可作为图像去噪任务中总变差（TV）正则化的替代方案，并天然适用于连续数据。在多维数据恢复任务（如图像修复、去噪和点云上采样）上的大量实验表明，我们的方法在性能和通用性上优于现有技术。

</details>


### [165] [Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs](https://arxiv.org/abs/2506.22139)
**中文标题：Q-Frame：面向视频-LLMs的查询感知帧选择与多分辨率自适应方法**

*Shaojie Zhang,Jiahui Yang,Jianqin Yin,Zhenbo Luo,Jian Luan*

主要分类: cs.CV

摘要简述: Q-Frame是一种针对视频-LLMs的自适应帧选择和多分辨率调整方法，通过查询感知的帧选择和CLIP网络实现高效处理，显著提升视频理解任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视频-LLMs通常采用均匀帧采样方法，难以有效捕捉查询相关的关键时空线索。Q-Frame旨在解决这一问题，通过自适应帧选择和多分辨率调整，优化视频理解任务。

研究方法: Q-Frame采用无需训练的即插即用策略，利用CLIP等文本-图像匹配网络生成帧选择方案，并通过Gumbel-Max技巧实现高效选择，同时支持多分辨率调整以适应视频内容和查询需求。

研究结果: 在MLVU、LongVideoBench和Video-MME等基准数据集上的实验表明，Q-Frame显著优于现有方法，能够在不超出计算限制的情况下处理更多帧，保留关键时空信息。

研究结论: Q-Frame通过自适应帧选择和多分辨率调整，显著提升了视频-LLMs的性能，适用于多种视频理解任务，具有广泛的应用潜力。

中文摘要: 多模态大语言模型（MLLMs）在视觉理解任务中取得了显著成功，但由于数据量大和时间复杂性，其在视频理解任务中的适应仍面临挑战。现有的视频-LLMs通常采用均匀帧采样方法，难以有效捕捉查询相关的关键时空线索。本文提出Q-Frame，一种针对视频内容和特定查询的自适应帧选择和多分辨率调整方法。Q-Frame采用无需训练的即插即用策略，通过CLIP等文本-图像匹配网络生成帧选择方案，并利用Gumbel-Max技巧实现高效选择。Q-Frame使视频-LLMs能够在不超过计算限制的情况下处理更多帧，从而保留关键的时空信息。我们在MLVU、LongVideoBench和Video-MME等基准数据集上进行了广泛实验，证明了Q-Frame的优越性及其在多种视频理解任务中的适用性。

</details>


### [166] [Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs](https://arxiv.org/abs/2506.22146)
**中文标题：视觉结构助力视觉推理：解决视觉语言模型中的绑定问题**

*Amirmohammad Izadi,Mohammad Ali Banayeeanzade,Fatemeh Askari,Ali Rahimiakbar,Mohammad Mahdi Vahedi,Hosein Hasani,Mahdieh Soleymani Baghshah*

主要分类: cs.CV

摘要简述: 本文提出通过增强视觉输入的低级空间结构（如水平线）并结合文本提示，显著提升了视觉语言模型（VLMs）在视觉推理任务中的表现，特别是在计数、视觉搜索、场景描述和空间关系理解方面。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言模型（VLMs）在视觉推理中存在绑定问题，即难以可靠地将感知特征与正确的视觉对象关联，导致在计数、视觉搜索等任务中表现不佳。本文旨在通过改进视觉输入设计来解决这一问题。

研究方法: 方法是通过在视觉输入中添加低级空间结构（如水平线），并结合文本提示，引导模型进行序列化和空间感知的解析。实验验证了这种干预的有效性。

研究结果: 实验结果显示，该方法显著提升了性能：GPT-4o的视觉搜索准确率提高25.00%，计数准确率提高26.83%，场景描述的编辑距离误差减少0.32，空间关系任务性能提升9.50%。纯文本策略（如思维链提示）则效果不佳。

研究结论: 结论表明，低级视觉结构设计是提升视觉语言模型在空间任务中表现的有效且未被充分探索的方向，优于纯语言方法。

中文摘要: 尽管视觉语言模型（VLMs）取得了进展，但其视觉推理能力常受限于绑定问题：无法可靠地将感知特征与正确的视觉对象关联。这一问题导致在计数、视觉搜索、场景描述和空间关系理解等任务中持续出现错误。关键原因在于当前VLMs主要并行处理视觉特征，缺乏空间基础和序列注意机制。本文提出一种简单而有效的干预方法：在视觉输入中增强低级空间结构（如水平线），并结合鼓励序列化和空间感知解析的文本提示。实验证明，该方法在核心视觉推理任务中显著提升了性能。具体而言，我们的方法使GPT-4o的视觉搜索准确率提高25.00%，计数准确率提高26.83%，场景描述的编辑距离误差减少0.32，并在2D合成数据集上提升空间关系任务性能9.50%。此外，我们发现视觉修改对这些提升至关重要；纯文本策略（包括思维链提示）不仅效果有限，甚至可能降低性能。我们的方法仅通过单次查询推理即可增强绑定，凸显了视觉输入设计相对于纯语言方法的重要性。这些发现表明，低级视觉结构是提升组合视觉推理能力的强大且未被充分探索的方向，可作为增强VLMs在空间任务中表现的通用策略。

</details>


### [167] [RetFiner: A Vision-Language Refinement Scheme for Retinal Foundation Models](https://arxiv.org/abs/2506.22149)
**中文标题：RetFiner：一种面向视网膜基础模型的视觉-语言优化方案**

*Ronald Fecso,José Morano,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

主要分类: cs.CV

摘要简述: RetFiner是一种基于视觉-语言的自监督学习优化方案，旨在提升现有视网膜基础模型的表征能力，使其无需监督微调即可适应特定人群，显著提升下游任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视网膜基础模型仅基于图像数据训练，缺乏对图像的全面语义理解，导致下游任务（尤其是复杂任务）表现不佳，且监督微调成本高或不现实。因此，需要一种无需监督微调的方法来优化模型表征。

研究方法: RetFiner通过结合视觉和文本数据的丰富监督信号，设计多样化的训练目标，优化现有视网膜基础模型的表征能力。

研究结果: 在RETFound、UrFound和VisionFM三个视网膜基础模型上测试，RetFiner在七项多样化的OCT分类任务中平均提升了5.8、3.9和2.1个百分点。

研究结论: RetFiner通过视觉-语言自监督学习优化方案，显著提升了视网膜基础模型的性能，且无需监督微调，具有广泛的应用潜力。

中文摘要: 随着光学相干断层扫描（OCT）等成像技术的兴起和深度学习（DL）的进步，临床医生和研究人员能够更高效地进行视网膜疾病分期。一种流行的DL方法是自监督学习（SSL），模型通过大量未标记数据学习，避免了昂贵的标注成本。SSL促进了基础模型（FMs）的发展，这些大型模型可用于多种下游任务。然而，现有的OCT基础模型仅基于图像数据训练，缺乏对图像的全面语义理解（尤其体现在复杂任务的表现上），因此需要通过监督微调（可能不可行）来适应特定应用和人群。为此，我们提出RetFiner，一种SSL视觉-语言优化方案，可改进现有基础模型的表征能力，并使其高效、直接地适应特定人群，提升下游任务性能。我们的方法利用文本数据中的丰富监督信号，设计了多样化的训练目标。我们在RETFound、UrFound和VisionFM三个视网膜基础模型上测试了RetFiner，结果显示在七项多样化的OCT分类任务中，线性探测性能分别平均提升了5.8、3.9和2.1个百分点。我们的代码和模型权重已在https://github.com/ronnief1/RetFiner公开。

</details>


### [168] [Attention-disentangled Uniform Orthogonal Feature Space Optimization for Few-shot Object Detection](https://arxiv.org/abs/2506.22161)
**中文标题：注意力解耦的均匀正交特征空间优化用于小样本目标检测**

*Taijin Zhao,Heqian Qiu,Yu Dai,Lanxiao Wang,Fanman Meng,Qingbo Wu,Hongliang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为UOFS的优化框架，通过解耦特征空间为幅度和角度两部分，分别编码物体性和分类信息，解决了小样本目标检测中特征空间纠缠的问题。结合HBO策略和SADA模块，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有小样本目标检测方法在共享特征空间中纠缠物体性识别和前景分类，导致类特定的物体性标准和缺乏代表性的新类样本。本文旨在通过解耦特征空间，实现从基类到新类的物体性知识迁移。

研究方法: 1. 提出UOFS框架，将特征空间解耦为幅度（物体性）和角度（分类）两部分。2. 设计HBO策略，包括纯背景基集构建和未标记前景实例的角优化，以解决基类图像中的混淆问题。3. 引入SADA模块，解决类无关和类特定任务之间的冲突。

研究结果: 实验表明，该方法在基于纠缠特征空间的现有方法上取得了显著优势，验证了UOFS框架的有效性。

研究结论: 通过解耦特征空间和优化策略，本文方法成功解决了小样本目标检测中的关键问题，为未来研究提供了新思路。

中文摘要: 小样本目标检测（FSOD）旨在利用有限的新类样本检测目标，同时依赖丰富的基类数据。现有的FSOD方法主要基于Faster R-CNN检测器，将物体性识别和前景分类纠缠在共享特征空间中。这种范式建立了类特定的物体性标准，并因新类样本缺乏代表性而受限。为解决这一问题，我们提出了一种均匀正交特征空间（UOFS）优化框架。首先，UOFS将特征空间解耦为两个正交分量，其中幅度编码物体性，角度编码分类。这种解耦实现了从基类到新类的物体性知识迁移。此外，实现解耦需注意两个挑战：（1）基集图像包含未标记的前景实例，导致潜在新类实例与背景混淆。（2）角优化仅依赖基类前景实例，导致角度分布对基类过拟合。为解决这些挑战，我们提出了一种混合背景优化（HBO）策略：（1）通过移除原始图像中的未标记实例构建纯背景基集，提供无偏的基于幅度的物体性监督。（2）将原始基集中的未标记前景实例纳入角优化，以增强分布均匀性。此外，我们提出了一种空间注意力解耦与关联（SADA）模块，解决类无关和类特定任务之间的冲突。实验表明，我们的方法显著优于基于纠缠特征空间的现有方法。

</details>


### [169] [Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition](https://arxiv.org/abs/2506.22179)
**中文标题：频率-语义增强的变分自编码器用于零样本骨架动作识别**

*Wenhan Wu,Zhishuai Guo,Chen Chen,Hongfei Xue,Aidong Lu*

主要分类: cs.CV

摘要简述: 本文提出了一种频率-语义增强的变分自编码器（FS-VAE），用于零样本骨架动作识别，通过频率分解和语义对齐提升模型对细粒度动作模式的捕捉能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有零样本骨架动作识别方法主要关注视觉与语义表示的对齐，但忽略了语义空间中细粒度动作模式（如手部动作）的重要性，导致识别效果受限。

研究方法: FS-VAE包含三个关键模块：1）基于频率的增强模块，通过高低频调整丰富骨架语义学习；2）多级对齐的语义动作描述模块，捕捉局部细节与全局对应；3）校准的交叉对齐损失，减少骨架与文本特征的模糊性。

研究结果: 实验表明，频率增强的语义特征能有效区分视觉和语义相似的动作簇，显著提升零样本动作识别性能。

研究结论: FS-VAE通过频率分解和语义对齐解决了现有方法的局限性，为零样本骨架动作识别提供了更鲁棒的解决方案。

中文摘要: 零样本骨架动作识别旨在开发能够识别训练中未见过动作类别的模型。现有方法主要关注视觉与语义表示的对齐，但忽略了语义空间中细粒度动作模式（如喝水与刷牙时的手部动作）的重要性。为解决这一问题，我们提出了一种频率-语义增强的变分自编码器（FS-VAE），通过频率分解探索骨架语义表示学习。FS-VAE包含三个关键模块：1）基于频率的增强模块，通过高低频调整丰富骨架语义学习并提升零样本动作识别的鲁棒性；2）多级对齐的语义动作描述模块，捕捉局部细节与全局对应，有效弥合语义差距并补偿骨架序列中固有的信息损失；3）校准的交叉对齐损失，使有效的骨架-文本对能够抵消模糊对，减少骨架与文本特征的差异和模糊性，从而确保鲁棒的对齐。基准测试验证了该方法的有效性，表明频率增强的语义特征能够鲁棒地区分视觉和语义相似的动作簇，提升零样本动作识别性能。

</details>


### [170] [Robust and Accurate Multi-view 2D/3D Image Registration with Differentiable X-ray Rendering and Dual Cross-view Constraints](https://arxiv.org/abs/2506.22191)
**中文标题：基于可微分X射线渲染和双交叉视图约束的鲁棒且精确的多视角2D/3D图像配准**

*Yuxin Cui,Rui Song,Yibin Li,Max Q. -H. Meng,Zhe Min*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的多视角2D/3D刚性配准方法，通过两阶段设计和交叉视图约束，显著提升了配准的鲁棒性和准确性，在DeepFluoro数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在单视角术中图像视野受限的情况下，多视角2D/3D配准成为必要。现有方法在鲁棒性和准确性上仍有不足，因此需要一种更有效的配准方法。

研究方法: 方法分为两阶段：第一阶段设计联合损失函数，结合位姿差异和图像相似性，并引入交叉视图训练损失；第二阶段通过测试时优化细化位姿估计。

研究结果: 在DeepFluoro数据集的六个样本上，平均目标配准误差（mTRE）为0.79±2.17毫米，优于现有配准算法。

研究结论: 该方法通过多视角投影位姿的相互约束，显著提升了配准的鲁棒性和准确性，具有临床应用潜力。

中文摘要: 鲁棒且精确的2D/3D配准（将术前模型与术中解剖图像对齐）对于成功的介入导航至关重要。为解决单视角术中图像视野受限的挑战，需利用多幅术中图像进行多视角2D/3D配准。本文提出了一种新颖的多视角2D/3D刚性配准方法，包含两个阶段。第一阶段设计联合损失函数，结合预测位姿与真实位姿的差异以及模拟与观察术中图像的相似性（如归一化互相关）。更重要的是，为位姿和图像损失引入了额外的交叉视图训练损失项，以显式强化交叉视图约束。第二阶段通过测试时优化细化粗配准阶段的位姿估计。该方法利用多视角投影位姿的相互约束，提升了配准的鲁棒性。在DeepFluoro数据集的六个样本上，平均目标配准误差（mTRE）为0.79±2.17毫米，优于现有配准算法。

</details>


### [171] [ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning](https://arxiv.org/abs/2506.22216)
**中文标题：ReF-LLE：基于参考引导的深度强化学习的个性化低光增强方法**

*Ming Zhao,Pingping Liu,Tongshun Zhang,Zhe Zhang*

主要分类: cs.CV

摘要简述: ReF-LLE是一种基于参考图像和深度强化学习的个性化低光图像增强方法，首次将深度强化学习引入该领域，通过傅里叶频域处理和自适应迭代策略实现个性化增强效果。


<details>
  <summary>详细信息</summary>
研究动机: 低光图像增强面临两大挑战：1) 不同条件下低光图像差异显著；2) 增强效果受主观偏好和用户意图影响。ReF-LLE旨在通过个性化方法解决这些问题。

研究方法: ReF-LLE在傅里叶频域中结合深度强化学习，训练时引入零参考图像评分策略提供奖励信号，推理时通过傅里叶域的零频分量自适应调整图像光照分布，使其与用户提供的参考图像一致。

研究结果: 在基准数据集上的实验表明，ReF-LLE在个性化低光图像增强中优于现有方法，具有更高的感知质量和适应性。

研究结论: ReF-LLE通过深度强化学习和傅里叶频域处理，实现了高效且个性化的低光图像增强，为相关领域提供了新思路。

中文摘要: 低光图像增强面临两大挑战：1) 不同条件下低光图像的显著差异；2) 增强效果受主观偏好和用户意图影响。为解决这些问题，我们提出了ReF-LLE，一种在傅里叶频域中结合深度强化学习的个性化低光图像增强方法。ReF-LLE首次将深度强化学习引入该领域。训练时，通过零参考图像评分策略为增强图像打分，提供奖励信号以指导模型有效处理不同程度的低光条件。推理阶段，ReF-LLE采用基于傅里叶域零频分量的个性化自适应迭代策略，该分量代表整体光照水平，使模型能够自适应调整低光图像，使其与用户提供的参考图像的光照分布一致，确保个性化增强效果。在基准数据集上的大量实验表明，ReF-LLE在个性化低光图像增强中优于现有方法，具有更高的感知质量和适应性。

</details>


### [172] [Boosting Classification with Quantum-Inspired Augmentations](https://arxiv.org/abs/2506.22241)
**中文标题：基于量子启发的增强技术提升分类性能**

*Matthias Tschöpe,Vitor Fortes Rey,Sogo Pierre Sanon,Paul Lukowicz,Nikolaos Palaiodimopoulos,Maximilian Kiefer-Emmanouilidis*

主要分类: cs.CV

摘要简述: 本文探讨了量子门扰动在量子机器学习中的潜在优势，提出了一种基于随机Bloch球旋转的量子启发数据增强技术，显著提升了图像分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究量子门扰动对量子机器学习的影响，探索其在数据增强中的应用，并验证量子启发方法在经典机器学习中的有效性。

研究方法: 采用随机Bloch球旋转（SU(2)变换）作为量子启发数据增强技术，应用于大规模ImageNet数据集，并与传统增强方法对比。

研究结果: 量子启发增强方法显著提升了图像分类性能，Top-1准确率提高3%，Top-5准确率提高2.5%，F$_1$分数从8%提升至12%。

研究结论: 量子启发数据增强技术能有效提升经典机器学习性能，但更强的酉变换虽保留信息却导致图像不可识别，且不增强差分隐私。

中文摘要: 理解量子门微小扰动的影响对识别量子机器学习潜在优势至关重要。这些扰动虽通常被视为量子计算的不利因素，却可作为数据增强的自然来源提升性能，并能在经典硬件上高效模拟，实现量子启发方法改进经典机器学习。本文研究了随机Bloch球旋转（基本SU(2)变换）作为一种简单有效的量子启发数据增强技术。与传统翻转、旋转或裁剪等增强方法不同，量子变换缺乏直观空间解释，使其在图像分类等任务中的应用更具挑战性。常见的量子增强方法依赖量子模型或可训练量子卷积层应用于经典数据集，而我们专注于小角度Bloch旋转对经典数据的直接影响。在大规模ImageNet数据集上，实验表明量子启发增强方法显著提升了图像分类性能，Top-1准确率提高3%，Top-5准确率提高2.5%，F$_1$分数从8%提升至12%，优于传统增强方法。此外，我们还研究了更强酉变换的应用。尽管这些变换理论上保留信息，却导致视觉上不可识别的图像，可能适用于隐私计算。然而，我们的增强方法和简单SU(2)变换并未增强差分隐私，并讨论了这一限制的意义。

</details>


### [173] [4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration](https://arxiv.org/abs/2506.22242)
**中文标题：4D-VLA：跨场景校准的时空视觉-语言-动作预训练**

*Jiahui Zhang,Yurui Chen,Yueming Xu,Ze Huang,Yanpeng Zhou,Yu-Jie Yuan,Xinyue Cai,Guowei Huang,Xingyue Quan,Hang Xu,Li Zhang*

主要分类: cs.CV

摘要简述: 4D-VLA通过整合4D信息（深度和时间）到输入中，解决了机器人预训练中的坐标系混乱和状态混乱问题，显著提升了模型的时空推理能力和训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在机器人预训练中通常使用简单观察作为输入，导致条件动作分布分散（坐标系混乱和状态混乱），显著降低了预训练效率。

研究方法: 4D-VLA通过引入深度和时间信息到视觉特征中，使用顺序RGB-D输入对齐机器人和场景的坐标系，并结合记忆库采样策略提取历史图像中的关键帧。

研究结果: 实验表明，4D-VLA在模拟和真实环境中均显著提升了成功率，并在多视图仿真基准测试中表现出更强的空间理解和适应性。

研究结论: 4D-VLA通过4D信息整合和记忆库采样，有效解决了预训练中的混乱问题，显著提升了模型的性能和效率。

中文摘要: 利用多样化的机器人数据进行预训练仍然是一个关键挑战。现有方法通常使用简单观察作为输入来建模数据集的行动分布，但这些输入往往不完整，导致条件行动分布分散——我们称之为坐标系混乱和状态混乱。这种不一致性显著降低了预训练效率。为解决这一问题，我们提出了4D-VLA，一种新颖的方法，通过将4D信息整合到输入中有效缓解这些混乱源。我们的模型通过顺序RGB-D输入将深度和时间信息引入视觉特征，对齐机器人和场景的坐标系。这种对齐赋予模型强大的时空推理能力，同时最小化训练开销。此外，我们引入了记忆库采样，一种帧采样策略，旨在从历史图像中提取信息丰富的帧，进一步提升效果和效率。实验结果表明，我们的预训练方法和架构组件显著提升了模型性能。在模拟和真实实验中，我们的模型相比OpenVLA显著提高了成功率。为进一步评估空间感知和对新视角的泛化能力，我们引入了MV-Bench，一个多视图仿真基准测试。我们的模型在各方面均优于现有方法，表现出更强的空间理解和适应性。

</details>


### [174] [EAMamba: Efficient All-Around Vision State Space Model for Image Restoration](https://arxiv.org/abs/2506.22246)
**中文标题：EAMamba：用于图像恢复的高效全向视觉状态空间模型**

*Yu-Cheng Lin,Yu-Syuan Xu,Hao-Wei Chen,Hsien-Kai Kuo,Chun-Yi Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为EAMamba的高效全向视觉状态空间模型，用于图像恢复任务。通过多头部选择性扫描模块（MHSSM）和全向扫描机制，解决了Vision Mamba在低层视觉任务中的计算复杂性和局部像素遗忘问题，显著降低了FLOPs并保持了性能。


<details>
  <summary>详细信息</summary>
研究动机: Vision Mamba在图像恢复任务中表现出色，但在低层视觉任务中面临计算复杂度随扫描序列增加和局部像素遗忘的挑战。本研究旨在解决这些问题，提升模型效率。

研究方法: 提出了EAMamba框架，引入多头部选择性扫描模块（MHSSM）和全向扫描机制，高效聚合多个扫描序列，避免计算复杂性和参数增加，同时解决局部像素遗忘问题。

研究结果: 实验验证了EAMamba在超分辨率、去噪、去模糊和去雾等任务中的有效性，FLOPs显著降低31-89%，性能优于现有低层Vision Mamba方法。

研究结论: EAMamba通过创新设计显著提升了图像恢复任务的效率和性能，为低层计算机视觉领域提供了新的解决方案。

中文摘要: 图像恢复是低层计算机视觉中的关键任务，旨在从退化的输入中重建高质量图像。Vision Mamba的出现在这一领域取得了显著进展，它借鉴了先进的状态空间模型Mamba，在建模长程依赖关系方面表现出色，且具有线性复杂度，这对图像恢复任务至关重要。然而，Vision Mamba在低层视觉任务中仍面临挑战，包括计算复杂度随扫描序列增加和局部像素遗忘问题。为解决这些限制，本研究提出了高效全向Mamba（EAMamba），该框架通过引入多头部选择性扫描模块（MHSSM）和全向扫描机制，高效聚合多个扫描序列，避免了计算复杂性和参数数量的增加。全向扫描策略通过多种模式捕获全局信息，解决了局部像素遗忘问题。实验评估验证了这些创新在超分辨率、去噪、去模糊和去雾等任务中的有效性。结果表明，EAMamba在保持性能的同时，FLOPs显著降低了31-89%，优于现有的低层Vision Mamba方法。

</details>


### [175] [COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication](https://arxiv.org/abs/2506.22274)
**中文标题：COOCO——场景中的语义违规：研究多模态上下文在指称交流中的作用**

*Filippo Merlo,Ece Takmaz,Wenkai Chen,Albert Gatt*

主要分类: cs.CV

摘要简述: 本文研究了视觉语言模型（VLMs）在生成对象引用时如何依赖场景上下文，并通过COOCO数据集测试了不同场景-对象一致性和干扰下的表现。结果表明，模型会根据对象与场景的语义相关性和噪声水平动态调整对上下文的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 自然场景为对象识别和引用提供了丰富的上下文信息。本文旨在探究视觉语言模型是否像人类一样依赖场景上下文来生成对象引用，以及在不同场景-对象一致性和干扰下的表现。

研究方法: 作者引入了COOCO数据集，测试了视觉语言模型在不同场景-对象一致性和干扰下生成对象引用的能力，并通过注意力分析研究了模型如何动态平衡局部和上下文信息。

研究结果: 研究发现，模型会根据对象与场景的语义相关性和噪声水平动态调整对上下文的依赖，尤其是在高目标-场景一致性或对象退化时更依赖上下文。注意力分析显示，成功的对象分类涉及中层对目标的更多关注。

研究结论: 视觉语言模型能够动态平衡局部和上下文信息来生成对象引用，其表现受场景-对象一致性和噪声水平的影响。COOCO数据集为未来研究提供了重要资源。

中文摘要: 自然场景为我们提供了丰富的对象识别和引用上下文。特别是，了解所观察的场景类型会生成关于哪些对象可能出现及其空间配置的预期。视觉语言模型（VLMs）在生成对象引用时是否以类似方式依赖场景上下文？为解决这一问题，我们引入了《常见对象脱离上下文（COOCO）》数据集，测试了VLMs在不同场景-对象一致性和干扰下依赖场景上下文引用对象的程度。研究结果表明，模型会根据对象与场景的语义相关性和噪声水平动态调整对上下文的依赖。特别是在高目标-场景一致性或对象退化时，模型更依赖上下文。注意力分析显示，成功的对象分类涉及中层对目标的更多关注，尤其是在中等噪声下，表明VLMs动态平衡局部和上下文信息以生成引用。我们公开了数据集、代码和模型：https://github.com/cs-nlp-uu/scenereg。

</details>


### [176] [Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment](https://arxiv.org/abs/2506.22283)
**中文标题：重新思考跨模态不对齐下LVLMs中的视觉令牌缩减**

*Rui Xu,Yunke Wang,Yong Luo,Bo Du*

主要分类: cs.CV

摘要简述: 本文探讨了大型视觉语言模型（LVLMs）中视觉令牌过多的问题，并提出了一种无需训练的视觉令牌剪枝框架VisionDrop，通过视觉内注意力选择信息丰富的令牌，显著提升了效率与性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有LVLMs中视觉令牌数量远超文本令牌，导致计算开销大且扩展性受限。传统方法依赖文本条件交互，但跨模态不对齐（因果、语义、空间）削弱了其效果。本文旨在解决这一问题。

研究方法: 提出VisionDrop框架，基于视觉内注意力选择信息丰富的令牌，无需文本信号。通过渐进式剪枝流程，在视觉编码器和LLM中多阶段进行令牌选择和轻量级上下文融合，保留细粒度视觉信息。

研究结果: 实验表明，VisionDrop在多种基准测试中优于现有方法，无需额外训练或复杂修改，显著提升了效率与性能。

研究结论: VisionDrop通过视觉内注意力剪枝和渐进式流程，有效解决了跨模态不对齐问题，为LVLMs的高效推理提供了简单而强大的解决方案。

中文摘要: 大型视觉语言模型（LVLMs）将视觉输入编码为密集的补丁级令牌序列以捕捉细粒度语义。这些视觉令牌数量通常远超文本令牌，导致计算开销大且限制了LVLMs的实际扩展性。以往研究尝试在大型语言模型（LLM）之前或内部进行视觉令牌缩减，但多数方法依赖文本条件交互，隐含假设文本令牌能可靠捕捉视觉令牌的重要性。本文重新审视这一假设，揭示了因果、语义和空间形式的跨模态不对齐，这些不对齐削弱了文本引导的视觉令牌缩减效果。为此，我们提出VisionDrop，一种无需训练的纯视觉剪枝框架，基于视觉内（视觉到视觉）注意力选择信息丰富的令牌，无需依赖文本信号。为进一步抑制模型层次中的冗余，我们将视觉编码器和LLM视为统一系统，设计了渐进式剪枝流程。该方法在多个阶段进行主导令牌选择和轻量级上下文融合，即使在激进的令牌预算下也能保留细粒度视觉信息。跨多样基准的广泛实验表明，VisionDrop无需额外训练或复杂修改，即能一致优于现有方法。其简洁高效的设计在保持任务性能的同时实现了高效推理。

</details>


### [177] [RoomCraft: Controllable and Complete 3D Indoor Scene Generation](https://arxiv.org/abs/2506.22291)
**中文标题：RoomCraft：可控且完整的3D室内场景生成**

*Mengqi Zhou,Xipeng Wang,Yuxi Wang,Zhaoxiang Zhang*

主要分类: cs.CV

摘要简述: RoomCraft是一种多阶段管道，通过结合场景生成和约束驱动优化，从用户输入（如图像、草图或文本）生成连贯的3D室内场景。其采用启发式深度优先搜索和冲突感知策略，显著提升了布局的完整性和视觉吸引力。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在生成3D室内场景时面临几何一致性、空间关系和视觉真实性的平衡问题。神经生成方法易产生重复元素，而程序化方法在多约束场景下难以避免物体碰撞和布局不完整。RoomCraft旨在解决这些问题。

研究方法: RoomCraft通过多阶段管道实现：1) 从用户输入提取高层场景信息并结构化；2) 构建空间关系网络，使用启发式深度优先搜索生成优化布局序列；3) 引入统一约束表示和冲突感知策略，动态调整家具位置以减少碰撞。

研究结果: 实验表明，RoomCraft在生成真实、语义连贯且视觉吸引人的房间布局方面显著优于现有方法，尤其在多约束输入场景下表现突出。

研究结论: RoomCraft通过结合约束驱动优化和冲突感知策略，有效解决了3D室内场景生成中的布局完整性和多约束处理问题，为未来研究提供了新方向。

中文摘要: 从用户输入生成真实的3D室内场景是计算机视觉和图形学中的挑战性问题，需平衡几何一致性、空间关系和视觉真实性。神经生成方法因全局空间推理有限易产生重复元素，而程序化方法在多约束场景下常因家具碰撞导致布局不完整。为此，我们提出RoomCraft，一种多阶段管道，将真实图像、草图或文本描述转化为连贯的3D室内场景。该方法结合场景生成管道与约束驱动优化框架，首先从用户输入提取高层场景信息并结构化，随后构建空间关系网络，使用启发式深度优先搜索（HDFS）算法生成优化布局序列以确保一致性。针对复杂多约束场景，我们引入统一约束表示，支持形式化规范和自然语言输入，并通过全面动作空间设计实现灵活调整。此外，提出冲突感知定位策略（CAPS），动态调整家具位置权重以减少碰撞并确保布局完整性。大量实验表明，RoomCraft在生成真实、语义连贯且视觉吸引人的房间布局方面显著优于现有方法，适用于多样化输入模态。

</details>


### [178] [OutDreamer: Video Outpainting with a Diffusion Transformer](https://arxiv.org/abs/2506.22298)
**中文标题：OutDreamer：基于扩散变换器的视频外绘**

*Linhao Zhong,Fan Li,Yi Huang,Jianzhuang Liu,Renjing Pei,Fenglong Song*

主要分类: cs.CV

摘要简述: OutDreamer是一种基于扩散变换器（DiT）的视频外绘框架，通过高效视频控制分支和条件外绘分支实现高质量视频内容扩展，并提出掩码驱动自注意力层和潜在对齐损失以提升一致性和适应性。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频外绘任务在生成内容的质量和适应性方面仍存在挑战，尤其是需要同时满足时空一致性。扩散变换器（DiT）因其优越性能成为潜在解决方案，因此本文提出OutDreamer框架以解决这些问题。

研究方法: OutDreamer包含两个主要组件：高效视频控制分支用于提取掩码视频信息，条件外绘分支基于提取条件生成缺失内容。此外，提出掩码驱动自注意力层动态整合掩码信息，并引入潜在对齐损失保持帧内和帧间一致性。对于长视频外绘，采用跨视频片段细化器迭代生成内容以确保时序一致性。

研究结果: 实验表明，OutDreamer在广泛认可的基准测试中优于现有零样本方法，生成内容质量高且适应性好。

研究结论: OutDreamer通过DiT框架和创新的掩码驱动自注意力层，显著提升了视频外绘任务的质量和一致性，为未来研究提供了新方向。

中文摘要: 视频外绘是一项具有挑战性的任务，通过扩展原始输入视频的边界生成新内容，需要同时满足时间和空间一致性。许多先进方法采用基于U-Net的潜在扩散模型，但在生成内容的质量和适应性方面仍存在不足。扩散变换器（DiT）因其卓越性能成为有前景的替代方案。我们提出OutDreamer，一种基于DiT的视频外绘框架，包含两个主要组件：高效视频控制分支和条件外绘分支。高效视频控制分支有效提取掩码视频信息，而条件外绘分支基于这些提取条件生成缺失内容。此外，我们提出掩码驱动自注意力层，动态整合给定掩码信息，进一步提升模型对外绘任务的适应性。我们还引入潜在对齐损失以保持帧内和帧间的整体一致性。对于长视频外绘，采用跨视频片段细化器迭代生成缺失内容，确保视频片段间的时序一致性。大量实验证明，我们的零样本OutDreamer在广泛认可的基准测试中优于现有零样本方法。

</details>


### [179] [MatChA: Cross-Algorithm Matching with Feature Augmentation](https://arxiv.org/abs/2506.22336)
**中文标题：MatChA：基于特征增强的跨算法匹配**

*Paula Carbó Cubero,Alberto Jaenal Gálvez,André Mateus,José Araújo,Patric Jensfelt*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MatChA的方法，通过特征增强和潜在空间转换解决不同稀疏特征提取算法在视觉定位中的匹配问题，显著提升了跨特征检测器的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在跨算法视觉定位中表现不佳，尤其是当不同设备使用不同稀疏特征提取算法时，关键点和描述符的匹配性能大幅下降。本文旨在解决这一挑战。

研究方法: 提出MatChA方法，首先进行特征描述符增强以支持跨检测器特征匹配，然后将特征转换到潜在空间，从而实现高效匹配。

研究结果: 实验表明，该方法在跨特征场景中显著提升了图像匹配和视觉定位的性能，并在多个基准测试中验证了其有效性。

研究结论: MatChA是首个解决跨检测器特征匹配问题的方法，通过特征增强和潜在空间转换，显著提升了匹配性能，为实际应用提供了有效解决方案。

中文摘要: 现有方法在跨设备使用不同稀疏特征提取算法时，无法有效解决视觉定位问题。尽管特征描述符的翻译可以实现匹配，但在跨特征检测器情况下性能大幅下降，因为现有解决方案假设使用相同的关键点检测器。由于关键点的低重复性以及描述符的非判别性和非独特性，真实对应关系的识别极具挑战性。本文首次提出了一种方法，通过特征描述符增强以支持跨检测器特征匹配，然后将特征转换到潜在空间。实验表明，该方法在跨特征场景中显著提升了图像匹配和视觉定位的性能，并在多个基准测试中验证了其有效性。

</details>


### [180] [A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake](https://arxiv.org/abs/2506.22338)
**中文标题：基于深度学习和VHR SAR与地理空间数据的建筑物损坏评估框架：以2023年土耳其地震为例**

*Luigi Russo,Deodato Tapete,Silvia Liberata Ullo,Paolo Gamba*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的多模态框架，利用高分辨率合成孔径雷达（SAR）和地理空间数据，快速评估建筑物损坏情况，并在2023年土耳其地震中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 灾害后快速识别建筑物损坏对应急响应和恢复至关重要。传统光学卫星图像常受云层或缺乏灾前数据限制，因此需要一种不依赖灾前数据的方法。

研究方法: 结合单日期高分辨率SAR图像、OpenStreetMap建筑轮廓、数字表面模型（DSM）及全球地震模型（GEM）的结构和暴露属性，提出了一种仅需灾后数据的深度学习框架。

研究结果: 在2023年土耳其地震数据集上的实验表明，结合地理空间特征显著提升了检测性能和泛化能力，适用于不同城市环境。

研究结论: 该框架无需灾前数据即可提供快速可靠的建筑物损坏评估，自动化数据生成过程使其适用于多种灾害区域，支持有效的灾害管理。

中文摘要: 灾害后快速识别建筑物损坏对应急响应和恢复至关重要。尽管光学卫星图像常用于灾害测绘，但其效果常受云层或缺乏灾前数据限制。为解决这些问题，我们提出了一种新颖的多模态深度学习框架，利用意大利航天局COSMO SkyMed星座的高分辨率合成孔径雷达（SAR）图像，辅以辅助地理空间数据，检测建筑物损坏。我们的方法整合了SAR图像块、OpenStreetMap建筑轮廓、数字表面模型（DSM）数据以及全球地震模型（GEM）的结构和暴露属性，以提高检测准确性和上下文解释。与依赖灾前和灾后图像的现有方法不同，我们的模型仅需灾后数据，便于在紧急情况下快速部署。该框架的有效性通过2023年土耳其地震的新数据集验证，覆盖了多种城市环境。结果表明，结合地理空间特征显著提升了检测性能和泛化能力。通过将SAR图像与详细的脆弱性和暴露信息结合，我们的方法无需依赖灾前数据即可提供可靠快速的建筑物损坏评估。此外，自动化和可扩展的数据生成过程确保了框架在多种灾害区域的适用性，凸显了其支持有效灾害管理和恢复的潜力。代码和数据将在论文接受后公开。

</details>


### [181] [Closing the Performance Gap in Biometric Cryptosystems: A Deeper Analysis on Unlinkable Fuzzy Vaults](https://arxiv.org/abs/2506.22347)
**中文标题：缩小生物密码系统的性能差距：对不可链接模糊保险库的深入分析**

*Hans Geißner,Christian Rathgeb*

主要分类: cs.CV

摘要简述: 本文分析了模糊保险库生物密码系统的性能差距，提出了一种基于等频区间的特征量化方法，显著减少了模板保护带来的性能下降，并在多种生物识别系统中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 模糊保险库生物密码系统存在性能差距，主要源于不稳定的纠错能力和特征类型转换导致的信息丢失。本文旨在解决这些问题，提升系统性能。

研究方法: 提出了一种基于等频区间的特征量化方法，确保固定特征集大小，并支持无训练适应任意区间数，同时减少特征转换的负面影响。

研究结果: 实验表明，该方法显著减少了性能差距，仅在主流生物识别系统中留下轻微性能下降。

研究结论: 提出的特征量化方法有效解决了模糊保险库生物密码系统的性能问题，适用于多种生物识别模态。

中文摘要: 本文分析并解决了基于模糊保险库的生物密码系统的性能差距问题。我们发现，不稳定的纠错能力（由可变特征集大小及其对相似性阈值的影响引起）是性能下降的关键原因。此外，特征类型转换导致的信息丢失进一步加剧了这一问题。为解决这些问题，我们提出了一种基于等频区间的新型特征量化方法。该方法保证了固定特征集大小，并支持无训练适应任意数量的区间。所提出的方法显著减少了模板保护引入的性能差距。此外，它与现有系统无缝集成，最大限度地减少了特征转换的负面影响。在最新的人脸、指纹和虹膜识别系统上的实验证实，仅剩轻微的性能下降，证明了该方法在主要生物识别模态中的有效性。

</details>


### [182] [From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications](https://arxiv.org/abs/2506.22360)
**中文标题：从地面到空中：基于事件的车辆分类中视觉变换器与卷积神经网络的噪声鲁棒性及其在无人机的潜在应用**

*Nouf Almesafri,Hector Figueiredo,Miguel Arana-Catania*

主要分类: cs.CV

摘要简述: 本研究比较了卷积神经网络（ResNet34）和视觉变换器（ViT B16）在事件相机数据上的性能，发现ResNet34在标准条件下略优，但ViT B16在噪声环境下表现更稳健。研究结果对无人机等动态环境应用具有潜在价值。


<details>
  <summary>详细信息</summary>
研究动机: 事件相机因其动态捕捉能力在无人机和自动驾驶等领域具有独特优势，但现有研究较少关注深度学习模型在此类数据上的性能差异。本研究旨在填补这一空白，并探索模型在噪声环境下的表现。

研究方法: 研究使用GEN1事件相机数据集，对ResNet34和ViT B16模型进行微调，并在标准条件和模拟噪声环境下评估其分类性能。

研究结果: 在干净数据上，ResNet34和ViT B16的准确率分别为88%和86%，ResNet34略优；但在噪声环境下，ViT B16表现出更强的鲁棒性。

研究结论: 尽管ResNet34在标准条件下表现稍好，ViT B16在噪声环境中的稳健性使其更适合动态应用场景，如无人机任务。

中文摘要: 本研究探讨了两种主要的计算机视觉深度学习架构——卷积神经网络（CNN）和视觉变换器（ViT）在事件相机数据上的性能。事件相机不同于传统的帧式相机，能够捕捉场景变化，特别适用于无人机和自动驾驶等动态环境。研究中使用的深度学习模型为ResNet34和ViT B16，并在GEN1事件数据集上进行了微调。研究评估了这些模型在标准条件和模拟噪声下的表现。在干净的GEN1数据集上，ResNet34和ViT B16的准确率分别为88%和86%，ResNet34略占优势。然而，ViT B16模型表现出显著的鲁棒性，尤其是在其预训练数据集较小的情况下。尽管本研究聚焦于地面车辆分类，但其方法和结果对无人机应用（如空中目标分类和航空相关任务的事件视觉系统）具有重要潜力。

</details>


### [183] [Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation](https://arxiv.org/abs/2506.22375)
**中文标题：利用视觉语言模型通过图分数传播实现无需训练的3D点云分布外检测**

*Tiankai Chen,Yushu Li,Adam Goodge,Fei Teng,Xulei Yang,Tianrui Li,Xun Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的3D点云OOD检测框架，利用视觉语言模型（VLM）和图分数传播（GSP）方法，通过构建类原型和测试数据的图结构，显著提升了3D点云数据的OOD检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 3D点云数据的分布外（OOD）检测在安全感知应用中至关重要，但现有方法多针对2D图像，难以直接应用于3D环境。本文旨在解决这一挑战，提出一种无需训练的框架，利用VLM提升3D点云OOD检测的效率和适应性。

研究方法: 通过构建基于类原型和测试数据的图结构，利用数据流形结构增强VLM在3D点云OOD检测中的效果。提出图分数传播（GSP）方法，结合提示聚类和自训练负提示，优化OOD评分。该方法还支持少样本场景，具有实际应用灵活性。

研究结果: 实验表明，GSP方法在合成和真实世界3D点云数据集上均优于现有最先进方法，验证了其在OOD检测中的高效性和鲁棒性。

研究结论: 本文提出的GSP方法通过结合VLM和图结构，为3D点云OOD检测提供了一种高效且无需训练的解决方案，适用于多种实际应用场景。

中文摘要: 3D点云数据的分布外（OOD）检测仍是一个挑战，尤其是在需要安全且鲁棒感知的应用中。尽管现有OOD检测方法在2D图像数据上取得了进展，但将其扩展到3D环境面临独特障碍。本文提出了一种无需训练的框架，利用视觉语言模型（VLM）实现高效的3D点云OOD检测。通过构建基于类原型和测试数据的图，我们利用数据流形结构增强VLM在3D OOD检测中的效果。我们提出了一种新颖的图分数传播（GSP）方法，结合提示聚类和自训练负提示，优化VLM的OOD评分。该方法还适用于少样本场景，为实际应用提供了灵活性。实验证明，GSP在合成和真实世界3D点云数据集上均优于现有最先进方法。

</details>


### [184] [Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment](https://arxiv.org/abs/2506.22385)
**中文标题：视频大型多模态模型能否像怀疑者一样思考或坚持己见：关于可推翻视频蕴含的研究**

*Yue Zhang,Jilei Sun,Yunhui Guo,Vibhav Gogate*

主要分类: cs.CV

摘要简述: 本文提出了一种名为‘可推翻视频蕴含’（DVidE）的新任务，旨在提升视频大型多模态模型（VLMMs）的动态推理能力。通过分类和生成两种任务形式，结合反事实推理和ASR增强技术，显著提升了模型在动态证据下的推理表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视频大型多模态模型（VLMMs）在抽象和自适应推理方面表现不足，无法根据新信息动态调整推理结果。现实中的结论往往是动态变化的，因此需要一种能够模拟怀疑者思维的任务，以提升模型的动态推理能力。

研究方法: 1. 提出‘可推翻视频蕴含’（DVidE）任务，包括分类和生成两种形式。2. 分类任务采用‘反事实思维链’框架，结合反事实推理、ASR增强视频内容和理由细化以减少推理偏差。3. 生成任务结合ASR输出和大型语言模型（LLM），生成与目标一致的相关更新。4. 构建了一个包含强化/弱化标注的新基准数据集，并设计了基于LLM的生成性能评估指标。

研究结果: 实验结果表明，所提出的方法显著提升了视频大型多模态模型（VLMMs）的动态推理能力，尤其是在分类和生成任务中表现出色。

研究结论: 本文通过引入DVidE任务和创新的推理框架，有效提升了VLMMs的动态推理能力，为多模态模型的未来发展提供了新的方向。

中文摘要: 视频大型多模态模型（VLMMs）在理解视频内容方面取得了显著进展，但在抽象和自适应推理方面仍存在不足——即无法根据新信息调整其解释。现实中，结论很少一成不变；额外的上下文可能强化或削弱初始推理。为此，我们提出了‘可推翻视频蕴含’（DVidE）任务，要求模型像怀疑者一样思考，根据动态证据不断更新推理。在DVidE中，给定视频前提和文本假设，模型需判断新更新是强化还是弱化假设（分类版本），或生成一个连贯的更新以修改蕴含关系（生成版本）。为解决分类任务，我们提出了‘反事实思维链’框架，利用反事实推理、ASR增强视频内容和理由细化以减少推理偏差。对于生成任务，我们开发了一个结合ASR输出和大型语言模型（LLM）的框架，生成与目标一致的连贯、上下文相关的更新。此外，我们引入了一个新的基准数据集，包含强化/弱化标注，并设计了基于LLM的生成性能评估指标。实验结果表明，所提方法显著提升了VLMMs的动态推理能力。

</details>


### [185] [Test-Time Consistency in Vision Language Models](https://arxiv.org/abs/2506.22395)
**中文标题：视觉语言模型中的测试时一致性**

*Shih-Han Chou,Shivam Chandhok,James J. Little,Leonid Sigal*

主要分类: cs.CV

摘要简述: 本文提出了一种无需监督重新训练的测试时一致性框架，通过交叉熵一致性损失和伪标签一致性损失，显著提升了视觉语言模型在语义等效输入下的预测一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型在多模态任务中表现优异，但在面对语义等效输入时预测不一致，影响模型的可靠性和鲁棒性。本文旨在解决这一问题，而无需修改模型架构或进行大规模微调。

研究方法: 提出了一种后处理的测试时一致性框架，包括两个互补目标：(i) 交叉熵一致性损失，对齐语义等效输入的预测分布；(ii) 伪标签一致性损失，使输出趋向自平均共识。该方法无需监督重新训练，适用于任何可访问权重的视觉语言模型。

研究结果: 在MM-R3基准测试中，该方法显著提升了多种先进模型的一致性表现，为多模态学习的推理时适应提供了新方向。

研究结论: 本文提出的测试时一致性框架简单有效，显著提升了视觉语言模型在语义等效输入下的预测一致性，且无需监督重新训练，具有广泛的适用性。

中文摘要: 视觉语言模型（VLMs）在多种多模态任务中表现出色，但在面对语义等效输入时常常表现出不一致的行为，影响了其可靠性和鲁棒性。最近的基准测试（如MM-R3）表明，即使是最先进的VLMs，也可能在语义等效输入下产生不同的预测，尽管其平均准确率较高。以往的研究通过修改模型架构或在精选数据集上进行大规模微调来解决这一问题。与此不同，我们提出了一种简单有效的测试时一致性框架，无需监督重新训练即可提升语义一致性。我们的方法是完全后处理的，与模型无关，适用于任何可访问权重的VLM。给定单个测试点，我们通过两个互补目标强制执行一致性预测：(i) 交叉熵一致性损失，对齐语义等效输入的预测分布；(ii) 伪标签一致性损失，使输出趋向自平均共识。我们的方法是即插即用的，利用单个测试输入本身的信息来提升一致性。在MM-R3基准测试上的实验表明，我们的框架显著提升了多种先进模型的一致性表现，为多模态学习的推理时适应开辟了新方向。

</details>


### [186] [Shape-for-Motion: Precise and Consistent Video Editing with 3D Proxy](https://arxiv.org/abs/2506.22432)
**中文标题：形状驱动运动：基于3D代理的精确一致视频编辑**

*Yuhao Liu,Tengfei Wang,Fang Liu,Zhenwei Wang,Rynson W. H. Lau*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Shape-for-Motion的新型框架，通过引入3D代理实现精确且一致的视频编辑。该方法将视频中的目标对象转换为时间一致的3D网格，支持直接在代理上进行编辑，并通过双传播策略简化编辑流程。实验证明其高效性和优越性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管深度生成模型在视频合成方面取得了进展，但现有方法仍难以实现用户对精确和一致编辑的需求。本文旨在解决这一问题，提供一种能够忠实反映用户创意意图的视频编辑工具。

研究方法: Shape-for-Motion框架将视频中的目标对象转换为时间一致的3D网格（3D代理），用户可在单帧的3D网格上进行编辑，并通过双传播策略自动传播到其他帧。编辑后的3D网格投影到2D空间，生成几何和纹理渲染，输入到解耦的视频扩散模型中以生成最终编辑结果。

研究结果: 实验表明，Shape-for-Motion支持多种精确且物理一致的操作（如姿态编辑、旋转、缩放、平移、纹理修改和对象合成），显著提升了视频编辑的质量和可控性。

研究结论: Shape-for-Motion为高质量、可控的视频编辑工作流程迈出了关键一步，其优越性和有效性在实验中得到了验证。

中文摘要: 深度生成模型的最新进展为视频合成带来了前所未有的机遇。然而，在实际应用中，用户通常需要能够忠实实现其创意编辑意图的工具，并提供精确且一致的控制。尽管现有方法取得了一定进展，但如何确保与用户意图的细粒度对齐仍是一个开放且具有挑战性的问题。本文提出Shape-for-Motion，一种通过引入3D代理实现精确且一致视频编辑的新型框架。Shape-for-Motion通过将输入视频中的目标对象转换为时间一致的网格（即3D代理），允许直接在代理上进行编辑，并将编辑结果推断回视频帧。为简化编辑流程，我们设计了一种新颖的双传播策略，用户只需在单帧的3D网格上进行编辑，编辑内容即可自动传播到其他帧的3D网格中。不同帧的3D网格进一步投影到2D空间，生成编辑后的几何和纹理渲染，作为解耦视频扩散模型的输入以生成最终编辑结果。我们的框架支持多种跨视频帧的精确且物理一致的操作，包括姿态编辑、旋转、缩放、平移、纹理修改和对象合成。Shape-for-Motion标志着高质量、可控视频编辑工作流程的关键一步。大量实验证明了我们方法的优越性和有效性。项目页面：https://shapeformotion.github.io/

</details>


### [187] [WarpRF: Multi-View Consistency for Training-Free Uncertainty Quantification and Applications in Radiance Fields](https://arxiv.org/abs/2506.22433)
**中文标题：WarpRF：基于多视角一致性的无需训练不确定性量化及其在辐射场中的应用**

*Sadra Safadoust,Fabio Tosi,Fatma Güney,Matteo Poggi*

主要分类: cs.CV

摘要简述: WarpRF是一种无需训练的多视角一致性框架，用于量化辐射场的不确定性，适用于主动视图选择和主动映射等任务，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常需要训练且仅适用于特定框架，无法通用化量化辐射场的不确定性。WarpRF旨在通过多视角一致性实现无需训练、通用的不确定性量化。

研究方法: WarpRF基于光度和几何一致性假设，通过反向投影将可靠渲染结果映射到新视角，并测量与新视角渲染图像的一致性，从而量化不确定性。

研究结果: WarpRF在不确定性量化和下游任务（如主动视图选择和主动映射）中表现优异，超越了现有特定框架的方法。

研究结论: WarpRF是一种简单、低成本且无需训练的通用框架，能够高效量化辐射场的不确定性，并在实际应用中表现出色。

中文摘要: 我们提出了WarpRF，一种无需训练的通用框架，用于量化辐射场的不确定性。基于光度和几何一致性在准确模型渲染图像中应成立的假设，WarpRF通过跨视角的反向投影将可靠渲染结果映射到新视角，并测量其与新视角渲染图像的一致性，从而量化不确定性。WarpRF简单、低成本，无需任何训练，可免费应用于任何辐射场实现。WarpRF在不确定性量化和下游任务（如主动视图选择和主动映射）中表现优异，超越了任何针对特定框架的现有方法。

</details>


### [188] [MiCo: Multi-image Contrast for Reinforcement Visual Reasoning](https://arxiv.org/abs/2506.22434)
**中文标题：MiCo：多图像对比驱动的强化视觉推理**

*Xi Chen,Mingkang Zhu,Shaoteng Liu,Xiaoyang Wu,Xiaogang Xu,Yu Liu,Xiang Bai,Hengshuang Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MiCo的方法，通过多图像对比实现视觉推理，利用自监督学习和强化学习提升模型对细微视觉变化的关注和逻辑推理能力，无需人工标注数据即可在多图像推理任务中取得显著效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型（VLMs）通常依赖人工标注的问题-答案对进行训练，但在处理多图像的细粒度视觉细节和复杂逻辑时面临挑战。本文旨在通过自监督学习利用图像本身的约束作为监督信号，提升模型的推理能力。

研究方法: 方法包括构建图像三元组（同一图像的两个增强视图和一个相似但不同的图像），通过强化学习优化模型生成推理过程（比较图像的异同）。模型需关注细微视觉变化并进行逻辑推理。

研究结果: 实验表明，尽管仅通过视觉比较任务训练，模型学到的推理能力能有效泛化到多种问题。无需人工标注数据，方法在多图像推理基准上取得显著提升，并在一般视觉任务中表现优异。

研究结论: MiCo通过自监督学习和强化学习成功提升了视觉推理能力，证明了利用图像内在约束作为监督的有效性，为多图像推理任务提供了新思路。

中文摘要: 本研究探索了如何通过思维链（CoT）推理将多幅图像中的视觉线索联系起来。一种直接的方法是调整基于规则的强化学习以适应视觉语言模型（VLMs）。然而，这类方法通常依赖人工标注的问题-答案对，在处理多图像的细粒度视觉细节和复杂逻辑时尤为困难。受自监督视觉表示学习的启发，我们发现图像本身包含可作为监督信号的固有约束。基于这一观察，我们构建了由同一图像的两个增强视图和一个相似但不同的图像组成的三元组。训练中，模型被提示生成推理过程以比较这些图像（即判断相同或不同），并通过基于规则的强化学习优化模型。由于图像间高度相似且存在增强，模型必须关注细微的视觉变化并进行逻辑推理才能成功。实验表明，尽管仅通过视觉比较任务训练，学到的推理能力能有效泛化到多种问题。无需任何人工标注的问题-答案对，我们的方法在多图像推理基准上取得显著提升，并在一般视觉任务中表现出色。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [189] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
**中文标题：SEEA-R1：基于树结构强化微调的自我进化具身智能体**

*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

主要分类: cs.AI

摘要简述: SEEA-R1是一种树结构强化微调框架，旨在提升具身智能体的自我进化能力，通过树基组相对策略优化和多模态生成奖励模型解决稀疏奖励和任务泛化问题，在ALFWorld基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前强化微调在提升大语言模型推理能力方面表现突出，但其在具身智能领域的潜力尚未充分挖掘。具身智能体在多模态交互和长时程任务中面临稀疏奖励和手工奖励函数泛化性差的挑战，亟需一种自我进化框架。

研究方法: SEEA-R1提出树基组相对策略优化（Tree-GRPO），将蒙特卡洛树搜索融入GRPO以生成密集中间奖励信号；同时引入多模态生成奖励模型（MGRM）实现跨任务和场景的奖励估计，支持自主适应和自我进化。

研究结果: 在ALFWorld基准测试中，SEEA-R1以85.07%（文本）和36.19%（多模态）的分数超越包括GPT-4o在内的现有方法，并在无环境奖励情况下达到80.3%的分数，显著优于开源基线。

研究结论: SEEA-R1通过创新的树结构强化微调和多模态奖励模型，为具身智能体的自我进化提供了可扩展的解决方案，展现了在可扩展具身智能研究中的潜力。

中文摘要: 自我进化是具身智能体在长时程现实任务中自主提升推理和行为能力的关键。尽管当前强化微调（RFT）在大语言模型推理增强中表现出色，但其在多模态交互中实现具身智能自我进化的潜力尚未充分探索。具体而言，强化微调在具身环境中面临两大障碍：（i）多步推理任务中缺乏可访问的中间奖励，限制了有效学习信号；（ii）依赖手工奖励函数限制了任务和环境的泛化能力。为解决这些问题，我们提出首个面向具身智能体自我进化的RFT框架SEEA-R1。为将稀疏延迟奖励转化为密集中间信号以提升多步推理，我们提出树基组相对策略优化（Tree-GRPO），将蒙特卡洛树搜索融入GRPO。为实现跨任务和场景的奖励估计，支持自主适应和奖励驱动的自我进化，我们进一步引入多模态生成奖励模型（MGRM）。为全面评估SEEA-R1的有效性，我们在ALFWorld基准测试中取得85.07%（文本）和36.19%（多模态）的分数，超越包括GPT-4o在内的现有方法。SEEA-R1在无环境奖励情况下仍达到80.3%的分数，优于所有开源基线，突显其作为自我进化具身智能体的可扩展性。额外实验和定性分析进一步支持SEEA-R1在可扩展具身智能研究中的潜力。

</details>


### [190] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
**中文标题：分层推理模型**

*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

主要分类: cs.AI

摘要简述: 提出了一种新型分层推理模型（HRM），通过高低级模块协同工作，显著提升复杂推理任务的性能，仅需少量训练样本即可实现优异表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLM）使用的链式思维（CoT）技术存在任务分解脆弱、数据需求大和延迟高的问题。受人类大脑分层和多时间尺度处理的启发，研究旨在开发一种更高效、稳定的推理模型。

研究方法: HRM采用递归架构，包含两个相互依赖的模块：高级模块负责缓慢、抽象的计划，低级模块处理快速、详细的计算。模型通过单次前向传播完成推理任务，无需中间过程的显式监督。

研究结果: HRM仅用2700万参数和1000个训练样本，在复杂推理任务（如数独和迷宫路径规划）中表现优异，甚至在ARC基准测试中超越更大规模的模型。

研究结论: HRM展示了通用计算和通用推理系统的潜力，为人工智能推理领域提供了突破性进展。

中文摘要: 推理是设计和执行复杂目标导向行为序列的过程，在人工智能中仍是一项关键挑战。当前的大型语言模型（LLM）主要采用链式思维（CoT）技术，但其存在任务分解脆弱、数据需求大和延迟高的问题。受人类大脑分层和多时间尺度处理的启发，我们提出了分层推理模型（HRM），这是一种新型递归架构，能够在保持训练稳定性和效率的同时实现显著的计算深度。HRM通过两个相互依赖的递归模块（高级模块负责缓慢、抽象的计划，低级模块处理快速、详细的计算）在单次前向传播中完成推理任务，无需中间过程的显式监督。仅用2700万参数，HRM在仅1000个训练样本的情况下，在复杂推理任务（如复杂数独和大型迷宫中的最优路径规划）中表现优异。此外，HRM在衡量人工通用智能能力的关键基准测试ARC中，超越了具有更长上下文窗口的更大规模模型。这些结果凸显了HRM作为通用计算和通用推理系统的潜在突破性进展。

</details>


### [191] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
**中文标题：THE-Tree：追踪历史演化能否增强科学验证与推理？**

*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

主要分类: cs.AI

摘要简述: 论文提出THE-Tree框架，通过构建科学文献中的技术演化树，结合LLM的生成能力和自然语言推理验证，提升科学验证和推理的准确性。实验表明其在图补全、未来科学预测和重要论文评估中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型（LLM）生成的科学提案数量庞大，但验证其新颖性和事实准确性存在瓶颈。现有方法（如LLM独立验证或传统引用网络）存在幻觉、缺乏领域知识或因果关联不足的问题。因此，需要一种结构化、可验证且因果关联的科学演化数据框架。

研究方法: THE-Tree框架从科学文献中构建领域特定的演化树，采用搜索算法探索演化路径。节点扩展时，通过“思考-引用-验证”流程：LLM提出潜在进展并引用文献，自然语言推理机制验证逻辑和证据支持，确保每一步有据可依。

研究结果: 实验构建了88个THE-Tree，覆盖多领域，并发布包含71k事实验证的基准数据集。结果显示：1）图补全中，THE-Tree的hit@1提升8%-14%；2）未来科学预测中，hit@1提升近10%；3）结合其他方法，重要论文评估性能提升近100%。

研究结论: THE-Tree通过结构化科学演化数据，结合LLM和验证机制，显著提升了科学验证和推理的准确性，为未来研究提供了新工具和基准数据集。

中文摘要: 大语言模型（LLM）加速了科学想法的生成，但如何严格评估这些数量庞大、往往肤浅的AI生成提案的新颖性和事实准确性是一个关键瓶颈；人工验证速度太慢。现有验证方法不足：LLM作为独立验证器可能产生幻觉且缺乏领域知识（我们的研究显示约60%在特定领域对相关论文无知），而传统引用网络缺乏显式因果关系，叙事调查则缺乏结构。这突显了一个核心挑战：缺乏结构化、可验证且因果关联的科学演化历史数据。为解决这一问题，我们提出了THE-Tree（技术历史演化树），一种从科学文献中构建此类领域特定演化树的计算框架。THE-Tree采用搜索算法探索演化路径。在节点扩展时，它使用一种新颖的“思考-引用-验证”流程：LLM提出潜在进展并引用支持文献。关键的是，每个提出的演化链接随后通过恢复的自然语言推理机制验证逻辑一致性和证据支持，确保每一步有据可依。我们构建并验证了88个THE-Tree，涵盖多个领域，并发布了一个包含71k事实验证的基准数据集，覆盖27k论文以促进进一步研究。实验表明：1）在图补全中，THE-Tree的hit@1比传统引用网络提升8%至14%；2）在预测未来科学发展时，hit@1提升近10%；3）与其他方法结合时，重要科学论文的评估性能提升近100%。

</details>


### [192] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
**中文标题：MobiVerse：基于轻量级领域特定生成器与大型语言模型的混合框架实现城市移动模拟的规模化**

*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

主要分类: cs.AI

摘要简述: MobiVerse提出了一种结合轻量级领域特定生成器和大型语言模型的混合框架，用于高效生成和动态调整大规模城市移动模拟，解决了传统方法在数据收集、动态适应性和计算效率方面的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有移动模拟平台在算法开发、政策实施和大规模评估方面存在不足，传统活动模型依赖大量数据收集和手动校准，机器学习方法难以适应动态条件，而基于大型语言模型的代理模拟在大规模计算中受限。MobiVerse旨在填补这一空白。

研究方法: MobiVerse采用混合框架，结合轻量级领域特定生成器生成基础活动链，并利用大型语言模型进行上下文感知的动态调整。通过模块化设计，支持在交通系统和代理级别测试多种移动算法。

研究结果: 在洛杉矶Westwood的案例研究中，MobiVerse成功为约53,000个代理生成并动态调整日程，代理能够响应道路封闭、大型聚集事件（如足球比赛）和拥堵等环境反馈，同时保持计算效率和行为真实性。

研究结论: MobiVerse通过提供可定制的移动系统规划和操作平台，填补了移动模拟的空白，兼具计算效率和行为真实性，为交通规划和城市发展提供了有力工具。

中文摘要: 理解和建模人类移动模式对有效的交通规划和城市发展至关重要。尽管移动研究取得了显著进展，但在支持算法开发、政策实施和大规模评估的模拟平台方面仍存在关键空白。传统的基于活动的模型需要大量数据收集和手动校准，机器学习方法难以适应动态条件，而基于大型语言模型的代理模拟在大规模计算中受限。为解决这些问题，我们提出MobiVerse，一种混合框架，结合轻量级领域特定生成器生成基础活动链，并利用大型语言模型进行上下文感知的动态调整。在洛杉矶Westwood的案例研究中，我们在一台标准PC上高效生成了约53,000个代理的日程并动态调整。实验表明，MobiVerse通过混合框架使代理能够响应道路封闭、大型聚集事件（如足球比赛）和拥堵等环境反馈。其模块化设计便于在交通系统和代理级别测试多种移动算法。结果显示，我们的方法在保持计算效率的同时提升了行为真实性。MobiVerse通过提供可定制的移动系统规划和操作平台，填补了移动模拟的空白。代码和视频见https://github.com/ucla-mobility/MobiVerse。

</details>


### [193] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
**中文标题：CitySim：基于大规模语言模型驱动的代理模拟建模城市行为与动态**

*Nicolas Bougie,Narimasa Watanabe*

主要分类: cs.AI

摘要简述: CitySim利用大型语言模型驱动代理模拟，通过递归价值驱动方法生成真实日常行为，结合长期目标与空间记忆，实现更贴近现实的城市场景模拟。


<details>
  <summary>详细信息</summary>
研究动机: 传统城市场景模拟依赖固定规则，难以捕捉复杂的人类行为和意图。CitySim旨在利用大型语言模型突破这一限制，提供更灵活、真实的模拟环境。

研究方法: CitySim采用递归价值驱动方法，代理根据强制性活动、个人习惯和情境因素生成日程，并具备信念、长期目标和空间记忆以支持长期模拟。

研究结果: CitySim在微观和宏观层面均表现出与真实人类行为的高度一致性，并能模拟数万代理的集体行为，应用于人群密度估计、地点受欢迎度预测等场景。

研究结论: CitySim为理解和预测城市现象提供了可扩展、灵活的测试平台，展现了大型语言模型在城市模拟中的潜力。

中文摘要: 模拟城市环境中的人类行为对社会学、行为研究和城市规划至关重要。传统方法依赖刻板的手工规则，难以模拟复杂的意图、计划和适应性行为。为解决这一问题，我们提出了城市模拟器CitySim，利用大型语言模型展现的人类级智能。在CitySim中，代理通过递归价值驱动方法生成真实的日常日程，平衡强制性活动、个人习惯和情境因素。为实现长期逼真模拟，代理具备信念、长期目标和用于导航的空间记忆。CitySim在微观和宏观层面均比以往工作更贴近真实人类行为。此外，我们通过模拟数万代理并在多种现实场景下评估其集体行为（如估计人群密度、预测地点受欢迎度和评估幸福感）进行了深入实验。结果表明，CitySim是理解和预测城市现象的可扩展、灵活测试平台。

</details>


### [194] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
**中文标题：交互式多目标概率偏好学习框架：结合软硬边界约束**

*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

主要分类: cs.AI

摘要简述: 本文提出了一种交互式多目标概率偏好学习框架Active-MoSH，结合软硬边界约束，帮助决策者在高代价决策中高效探索帕累托前沿，并通过全局分析增强决策信任。


<details>
  <summary>详细信息</summary>
研究动机: 在高风险决策中，决策者需平衡多个竞争目标（如软硬边界约束），但现有方法缺乏系统性交互框架来迭代优化偏好结构。本文旨在解决这一问题，确保决策者信任最终选择。

研究方法: Active-MoSH框架分为局部和全局组件：局部组件通过概率偏好学习和软硬边界约束动态优化帕累托子集；全局组件T-MoSH利用多目标敏感性分析识别潜在高价值点，增强决策信任。

研究结果: 实验表明，Active-MoSH在合成和实际应用中表现优异，用户研究验证了其在收敛性、决策信任和偏好表达方面的优势。

研究结论: Active-MoSH为多目标决策提供了高效交互框架，显著提升决策效率和信任度，适用于高后果场景。

中文摘要: 高风险决策涉及在多个竞争目标之间权衡，且每次评估代价高昂。例如，在近距离放射治疗中，医生需平衡最大化肿瘤覆盖率（如软边界目标>95%）与严格器官剂量限制（如硬边界<601 cGy），而现有方法缺乏系统性交互框架。决策者（DM）通常依赖领域知识通过软硬边界缩小搜索范围，但当前方法难以迭代优化此类多面偏好结构。为确保决策信任，DM需确信未遗漏更优方案。为此，我们提出Active-MoSH框架：其局部组件结合软硬边界与概率偏好学习，动态优化帕累托子集；全局组件T-MoSH通过多目标敏感性分析识别潜在高价值点。实验表明，Active-MoSH在合成和实际应用中表现优异，用户研究进一步验证了其提升收敛性、增强信任和支持偏好表达的能力。

</details>


### [195] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
**中文标题：AlphaBeta并非如你所想：一种新的概率模型以更好地分析确定性游戏求解算法**

*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

主要分类: cs.AI

摘要简述: 本文提出了一种新的概率模型，用于更准确地分析确定性游戏求解算法（如AlphaBeta和Scout）的平均复杂度。传统模型因假设叶子节点独立而忽略了游戏的结构复杂性，导致分析结果过于简化。新模型通过引入祖先依赖关系，生成了更具挑战性的问题，并揭示了AlphaBeta在实际应用中比Scout等算法慢得多。


<details>
  <summary>详细信息</summary>
研究动机: 传统分析确定性游戏求解算法的模型假设叶子节点独立，忽略了游戏的结构复杂性，导致分析结果过于理想化。这种简化模型无法反映实际游戏中的挑战，因此需要一种更接近现实的模型来重新评估这些算法的性能。

研究方法: 作者提出了一种新的概率模型，通过固定层级条件分布逐步构建游戏树，并强制引入祖先依赖关系。这一模型保留了分析的可操作性，同时生成了难度可调的问题。在此基础上，作者推导了AlphaBeta和Scout等算法的平均复杂度递归公式。

研究结果: 新模型显示，尽管所有算法在渐近情况下具有相同的分支因子，但在深度有限的游戏树中，AlphaBeta的常数乘因子显著大于Scout等算法，导致实际运行速度明显更慢。

研究结论: 新模型为经典游戏求解算法提供了更现实的分析框架，揭示了AlphaBeta在实际应用中的性能劣势，并为未来研究提供了更准确的工具。

中文摘要: 确定性游戏求解算法通常基于随机游戏树的平均复杂度进行分析，其中叶子节点的值独立采样于固定分布。这一简化模型便于数学分析，揭示了两个关键特性：有限值树的根值分布渐近收敛于单一固定值，且所有合理算法均能达到全局最优。然而，这些结论是模型设计的副产品——其长期受批评的独立性假设剥离了游戏的结构复杂性，生成了无意义的简单实例。为解决这一局限，我们提出了一种新的概率模型，通过固定层级条件分布逐步构建游戏树。通过强制引入祖先依赖关系（实际游戏的关键结构特征），我们的框架生成了难度可调的问题，同时保留了部分分析可操作性。针对包括AlphaBeta和Scout在内的多种算法，我们推导了其在该模型下的平均复杂度递归公式。这些公式使我们能够严格比较算法在深度游戏树上的性能，而蒙特卡洛模拟在此已不可行。尽管渐近情况下所有算法的分支因子趋于一致（与独立性模型的结果类似），但在深度有限的树中，差异显著：AlphaBeta的常数乘因子远大于Scout等算法，导致实际运行速度大幅下降。我们的框架为经典游戏求解算法提供了新的视角，通过更现实、更具挑战性且可分析的模型，为这些方法的理解提供了严谨的证据和工具。

</details>


### [196] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
**中文标题：LeanConjecturer：定理证明中数学猜想的自动生成**

*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

主要分类: cs.AI

摘要简述: LeanConjecturer是一种基于大语言模型（LLM）的自动生成数学猜想的管道，用于解决形式化定理证明中的数据稀缺问题。通过结合规则驱动的上下文提取和LLM生成的定理陈述，该系统生成了大量非平凡猜想，并展示了其在强化学习和数学发现中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 形式化定理证明领域面临数据稀缺的挑战，尤其是高质量的数学猜想。LeanConjecturer旨在通过自动生成非平凡猜想，为定理证明系统提供可扩展的训练数据，并探索其在数学发现中的应用。

研究方法: LeanConjecturer采用混合方法，结合规则驱动的上下文提取和LLM生成的定理陈述。通过迭代生成和评估，系统从40个Mathlib种子文件中生成了12,289个猜想，其中3,776个被验证为语法有效且非平凡。

研究结果: 系统平均每个种子文件生成103.25个新猜想，并在拓扑学中验证了多个非平凡定理（如半开集、α开集和预开集的性质）。这些猜想通过GRPO强化学习方法提升了定理证明能力。

研究结论: LeanConjecturer为形式化定理证明提供了可扩展的猜想生成方案，展示了其在数学发现和强化学习中的潜力，为定理证明系统的训练数据问题提供了解决方案。

中文摘要: 我们介绍了LeanConjecturer，一种基于大语言模型（LLM）的管道，用于在Lean 4中自动生成大学级数学猜想。我们的混合方法结合了规则驱动的上下文提取和LLM生成的定理陈述，解决了形式化定理证明中的数据稀缺问题。通过迭代生成和评估，LeanConjecturer从40个Mathlib种子文件中生成了12,289个猜想，其中3,776个被验证为语法有效且非平凡（即无法通过\texttt{aesop}策略证明）。我们通过组相对策略优化（GRPO）展示了这些生成猜想在强化学习中的实用性，表明针对特定领域的猜想训练可以提升定理证明能力。我们的方法平均每个种子文件生成103.25个新猜想，为定理证明系统的训练数据提供了可扩展的解决方案。我们的系统成功验证了拓扑学中的多个非平凡定理，包括半开集、α开集和预开集的性质，展示了其在超越现有结果简单变体的数学发现中的潜力。

</details>


### [197] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
**中文标题：多模态轨迹建模的通用检索方法**

*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

主要分类: cs.AI

摘要简述: 本文提出了一种多模态轨迹检索方法GAE-Retriever，通过构建统一代理轨迹数据集UATD和基准测试GAE-Bench，结合视觉语言模型和优化的对比学习机制，显著提升了多模态轨迹检索的召回率。


<details>
  <summary>详细信息</summary>
研究动机: 轨迹数据在增强AI代理能力方面具有巨大潜力，但目前缺乏系统化的轨迹级数据建模方法。本文旨在填补通用检索与代理中心轨迹建模之间的空白。

研究方法: 构建了统一代理轨迹数据集UATD和基准测试GAE-Bench，提出GAE-Retriever框架，结合视觉语言模型和优化的对比学习机制（如令牌选择和GradCache机制）。

研究结果: GAE-Retriever在多个数据集上的检索召回率显著优于基线方法，验证了其在多模态轨迹检索中的有效性。

研究结论: 本文提出的GAE-Retriever框架在多模态轨迹检索中表现出色，为轨迹数据建模提供了新的解决方案。

中文摘要: 轨迹数据通过捕捉人类行为和环境状态的多模态信息，在提升AI代理能力（尤其是在GUI环境中）方面具有巨大潜力。然而，如何建模轨迹级数据的表示仍是一个未系统解决的挑战。本文提出多模态轨迹检索，填补了通用检索与代理中心轨迹建模之间的空白。我们基于多样化的真实场景标注演示和状态构建了统一代理轨迹数据集（UATD），并提出了包含大量轨迹检索对的基准测试GAE-Bench。此外，我们提出GAE-Retriever，一种多模态检索框架，采用视觉语言模型并通过令牌选择和GradCache机制优化对比学习。在多个数据集上的综合评估表明，GAE-Retriever在检索召回率上持续优于基线方法，突显了其在推动多模态轨迹检索方面的有效性。

</details>


### [198] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
**中文标题：查询即测试：一种面向智能座舱-车辆-道路一体化场景的智能驾驶测试与数据存储方法**

*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为“查询即测试”（QaT）的新方法，通过统一的逻辑数据表示（ESN框架）解决智能座舱、自动驾驶和智能道路网络中数据碎片化和测试不灵活的问题，支持复杂语义查询和隐私保护。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能在交通领域的深入应用，智能座舱、自动驾驶和智能道路网络快速发展，但数据生态碎片化且测试方法缺乏灵活性。现有测试依赖数据堆叠，无法覆盖所有边缘情况。

研究方法: 提出“查询即测试”（QaT）概念，将测试从固定脚本转向灵活的逻辑查询，并设计“可扩展场景表示法”（ESN），基于答案集编程（ASP）统一表示异构多模态数据，支持语义融合和逻辑推理。

研究结果: ESN框架实现了数据的深度语义融合，支持复杂查询、决策过程可解释性及细粒度隐私保护。QaT范式显著提升了测试的表达能力和形式严谨性。

研究结论: 通过逻辑验证驱动的开发（VDD）方法，结合QaT和ESN，为自动驾驶系统的功能验证和安全合规检查提供了高效、灵活的解决方案，加速了开发迭代。

中文摘要: 随着人工智能在交通领域的深入渗透，智能座舱、自动驾驶和智能道路网络以前所未有的速度发展。然而，这三个关键领域的数据生态日益碎片化且不兼容。特别是，现有测试方法依赖数据堆叠，无法覆盖所有边缘情况且缺乏灵活性。为解决这一问题，本文提出了“查询即测试”（QaT）的概念，将测试焦点从固定的预设用例转向基于统一数据表示的灵活逻辑查询。具体而言，我们提出了“可扩展场景表示法”（ESN），这是一种基于答案集编程（ASP）的新型声明式数据框架，将座舱、车辆和道路的异构多模态数据统一表示为逻辑事实和规则的集合。该方法不仅实现了数据的深度语义融合，还带来三大核心优势：（1）通过逻辑推理支持复杂灵活的语义查询；（2）为决策过程提供自然可解释性；（3）通过逻辑规则实现按需数据抽象，支持细粒度隐私保护。我们进一步阐述了QaT范式，将自动驾驶系统的功能验证和安全合规检查转化为对ESN数据库的逻辑查询，显著提升了测试的表达能力和形式严谨性。最后，我们提出了“验证驱动开发”（VDD）的概念，建议在大语言模型时代通过逻辑验证而非定量测试来指导开发，以加速迭代和开发进程。

</details>


### [199] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
**中文标题：AI安全的不同路径：哥伦比亚大学关于人工智能开放性与安全的会议成果**

*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

主要分类: cs.AI

摘要简述: 本文报告了哥伦比亚大学关于AI开放性与安全的会议成果，提出了开放性与安全性结合的研究议程、技术干预措施及内容安全过滤生态系统的路线图，强调开放性可提升安全性，但仍存在多语言和多模态基准不足等问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着开源基础模型的快速发展，如何确保AI系统的安全性成为迫切问题。本文旨在通过开放性（透明权重、互操作工具和公共治理）提升AI安全性，并填补现有研究与实践中的空白。

研究方法: 通过为期六周的筹备计划和会议，汇集了来自学术界、工业界、民间社会和政府的45多名专家，采用参与式和解决方案导向的方法，制定了研究议程、技术干预措施和内容安全过滤路线图。

研究结果: 成果包括：（1）安全性与开源AI结合的研究议程；（2）技术干预措施和开源工具的部署路线图；（3）内容安全过滤生态系统的研究与发展路线图。发现开放性可增强安全性，但仍存在多语言和多模态基准不足等问题。

研究结论: 提出了五个优先研究方向，强调参与式输入、未来验证的内容过滤器、生态系统安全基础设施、严格的代理保障措施和扩展的危害分类法，为开放、多元和负责任的AI安全学科奠定基础。

中文摘要: 开源基础模型的快速崛起加剧了确保AI系统安全的责任，并重塑了相关机遇。本文报告了哥伦比亚大学关于AI开放性与安全会议（2024年11月19日，旧金山）及其六周筹备计划的成果，涉及来自学术界、工业界、民间社会和政府的45多名研究人员、工程师和政策领袖。通过参与式和解决方案导向的过程，工作组提出了：（1）安全性与开源AI结合的研究议程；（2）现有和所需技术干预措施及开源工具的部署路线图；（3）内容安全过滤生态系统的研究与发展路线图。研究发现，开放性（透明权重、互操作工具和公共治理）可通过独立审查、分散缓解和文化多元监督提升安全性。但仍存在显著空白：多语言和多模态基准不足、针对代理系统中提示注入和组合攻击的防御有限，以及对受AI危害影响最大的社区的参与机制不足。本文最后提出了五个优先研究方向的路线图，强调参与式输入、未来验证的内容过滤器、生态系统安全基础设施、严格的代理保障措施和扩展的危害分类法。这些建议为2025年2月法国AI行动峰会提供了参考，并为开放、多元和负责任的AI安全学科奠定了基础。

</details>


### [200] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
**中文标题：打破知识图谱补全中的秩瓶颈**

*Samy Badreddine,Emile van Krieken,Luciano Serafini*

主要分类: cs.AI

摘要简述: 知识图谱补全（KGC）模型中，由于实体数量远大于嵌入维度，导致线性输出层存在秩瓶颈，限制了模型表达能力。本文提出KGE-MoS，一种基于混合的输出层方法，有效打破秩瓶颈，提升模型性能和概率拟合度。


<details>
  <summary>详细信息</summary>
研究动机: 现有KGC模型在实体数量远大于嵌入维度时，线性输出层存在秩瓶颈，限制了模型的表达能力和预测准确性。本文旨在研究秩瓶颈对KGC模型的影响，并提出解决方案。

研究方法: 通过理论和实证分析秩瓶颈对KGC模型的影响，提出KGE-MoS方法，即基于混合的输出层设计，以打破秩瓶颈。该方法在多个数据集上进行验证。

研究结果: 实验表明，KGE-MoS在四个数据集上显著提升了KGC模型的性能和概率拟合度，且参数成本较低。

研究结论: KGE-MoS通过打破秩瓶颈，有效提升了KGC模型的表达能力和预测准确性，为知识图谱补全任务提供了新的解决方案。

中文摘要: 许多知识图谱补全（KGC）模型尽管使用了强大的编码器，但仍依赖于简单的向量-矩阵乘法来对候选实体进行评分。当实体数量远大于模型嵌入维度时（实际场景中通常相差几个数量级），线性输出层会出现秩瓶颈。这种瓶颈限制了模型的表达能力。本文从理论和实证两方面研究了秩瓶颈对KGC模型的影响，发现秩瓶颈通过限制可行预测集，损害了排序准确性和评分分布的保真度。受语言建模文献的启发，我们提出了KGE-MoS，一种基于混合的输出层方法，用于打破KGC模型中的秩瓶颈。在四个数据集上的实验表明，KGE-MoS以较低的参数成本提升了KGC模型的性能和概率拟合度。

</details>


### [201] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
**中文标题：人工智能的不服从：重新思考我们AI队友的自主性**

*Reuth Mirsky*

主要分类: cs.AI

摘要简述: 本文主张赋予AI队友‘智能不服从’能力，使其在人类-AI团队中能自主做出有意义贡献，而非盲目服从指令。


<details>
  <summary>详细信息</summary>
研究动机: 当前大多数协作AI系统设计为盲目服从人类指令，即使可能产生负面或危险后果。本文旨在探讨如何通过赋予AI‘智能不服从’能力，提升其在团队中的自主性和实用性。

研究方法: 论文提出一个AI代理能力等级量表，并通过代表性案例说明AI自主性的重要性。进一步探讨不同自主性水平下‘智能不服从’的表现形式。

研究结果: 研究表明，将‘智能不服从’作为AI核心能力研究具有必要性，并初步提出研究边界和考量因素。

研究结论: 论文呼吁将AI自主性作为独立研究方向，并建议未来研究关注‘智能不服从’在协作环境中的应用与限制。

中文摘要: 近年来，人工智能取得了显著进展，在广泛任务中实现了超人类表现。然而，尽管有这些进步，大多数协作AI系统仍严格服从指令，设计为无条件遵循人类指示并符合用户期望，即使这样做可能适得其反或不安全。本文主张扩展AI队友的自主性，包括‘智能不服从’，使其能在人类-AI团队中做出有意义的自主贡献。论文引入一个AI自主性等级量表，并通过代表性案例强调将AI自主性作为协作环境中独立研究重点的重要性和日益增长的必要性。随后探讨了‘智能不服从’在不同自主性水平下的表现，并最终提出研究‘智能不服从’作为人工代理核心能力的初步边界和考量。

</details>


### [202] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
**中文标题：概念主题聚合**

*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

主要分类: cs.AI

摘要简述: 本文提出了一种基于形式概念分析（FCA）的方法FAT-CAT，用于增强主题建模的聚合和可视化，提供更具解释性的数据集结构表示。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据量的快速增长，传统手动检查方法已不可行，而现有主题建模方法在提供可解释性表示方面存在不足，难以深入理解数据结构和内容。

研究方法: 提出FAT-CAT方法，利用形式概念分析（FCA）对多样化的主题和文件类型进行聚合，构建概念格以展示层次化的主题分布。

研究结果: 在ETYNTKE数据集上的案例研究表明，FCA-based聚合方法比其他表示方法更能提供有意义且可解释的数据集组成洞察。

研究结论: FCA-based方法在主题建模中能够提供更结构化和可解释的表示，优于现有技术。

中文摘要: 数据的快速增长使得传统手动检查变得不可行，因此需要采用计算方法进行高效的数据探索。主题建模已成为分析大规模文本数据集的强大工具，能够提取潜在的语义结构。然而，现有的主题建模方法往往难以提供可解释的表示，从而阻碍了对数据结构和内容的深入理解。本文提出FAT-CAT，一种基于形式概念分析（FCA）的方法，用于增强主题的聚合和可视化。我们的方法能够处理多样化的主题和文件类型（按目录分组），构建一个概念格，提供其主题分布的结构化层次表示。在ETYNTKE数据集的案例研究中，我们评估了该方法与其他表示方法的有效性，结果表明FCA-based聚合比现有主题建模技术更能提供有意义且可解释的数据集组成洞察。

</details>


### [203] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
**中文标题：具身AI代理：世界建模**

*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

主要分类: cs.AI

摘要简述: 本文研究了具身AI代理，探讨了如何通过世界模型提升其感知、学习和行动能力，以更接近人类的方式与环境互动。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索具身AI代理（如虚拟化身、可穿戴设备和机器人）如何通过世界模型更好地理解环境、预测用户意图和社会情境，从而自主完成复杂任务。

研究方法: 方法包括构建世界模型，整合多模态感知、行动推理与控制以及记忆功能，以全面理解物理世界；同时学习用户的心理世界模型以优化人机协作。

研究结果: 结果表明，世界模型显著提升了具身AI代理的环境感知和任务执行能力，使其更接近人类的学习与互动方式。

研究结论: 结论指出，世界模型是具身AI代理实现自主推理和规划的核心，未来可进一步扩展至更复杂的人机协作场景。

中文摘要: 本文描述了我们对具身于视觉、虚拟或物理形态的AI代理的研究，这些代理能够与用户及其环境互动。这些代理包括虚拟化身、可穿戴设备和机器人，旨在感知、学习并作用于其周围环境，使其更接近人类的学习与互动方式。我们提出，世界模型的开发是具身AI代理推理与规划的核心，使其能够理解和预测环境、理解用户意图和社会情境，从而提升其自主执行复杂任务的能力。世界建模涵盖多模态感知的整合、通过行动推理与控制进行规划以及记忆功能，以全面理解物理世界。此外，我们还提出学习用户的心理世界模型，以优化人机协作。

</details>


### [204] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
**中文标题：AI模型护照：面向透明医疗AI的数据与系统追踪框架**

*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

主要分类: cs.AI

摘要简述: 本文提出了一种名为‘AI模型护照’的标准化框架，用于追踪和验证AI模型的全生命周期数据，提升透明度和可重复性，并通过AIPassport工具在医疗影像应用中验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在健康和生物医学领域的广泛应用，现有框架依赖人工文档，缺乏可扩展性和机器可读性，且无法为AI模型提供唯一可验证的身份，限制了透明度和信任。

研究方法: 提出‘AI模型护照’概念，作为AI模型的数字身份和验证工具，记录从数据获取到模型部署的全生命周期元数据，并通过AIPassport工具实现自动化元数据收集和版本管理。

研究结果: 在ProCAncer-I项目的医疗影像应用中，AIPassport工具成功展示了其提升透明度、可重复性和合规性的能力，同时减少了人工干预。

研究结论: AI模型护照框架为AI驱动的医疗解决方案设定了新的透明度和信任标准，有望成为跨领域合规AI系统的基础。

中文摘要: 人工智能（AI）在健康和生物医学系统中的日益集成需要强大的透明性、责任性和伦理合规框架。现有框架通常依赖人工可读的手动文档，限制了跨项目和平台的可扩展性、可比性和机器可解释性。此外，它们未能为AI模型提供唯一且可验证的身份，以确保其来源和真实性，从而限制了可重复性和利益相关者的信任。本文提出了‘AI模型护照’的概念，这是一种结构化和标准化的文档框架，作为AI模型的数字身份和验证工具。它捕获了从数据获取和预处理到模型设计、开发和部署的全生命周期中的关键元数据，以唯一识别、验证、追踪和监控AI模型。此外，通过AIPassport工具（在ProCAncer-I欧盟项目中开发的医疗影像应用MLOps工具）实现了该框架。AIPassport自动化了元数据收集，确保正确的版本管理，将结果与源代码分离，并与多种开发环境集成。通过使用ProCAncer-I数据集中的病灶分割案例，展示了其有效性，说明了AI模型护照如何增强透明度、可重复性和法规准备度，同时减少人工干预。这一方法旨在为AI驱动的医疗解决方案建立信任和责任的新标准，并希望成为跨领域开发透明且合规AI系统的基础。

</details>


### [205] [The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements](https://arxiv.org/abs/2506.22419)
**中文标题：自动化LLM速度运行基准测试：重现NanoGPT改进**

*Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach*

主要分类: cs.AI

摘要简述: 论文提出了一个自动化LLM速度运行基准测试，用于评估AI代理在重现NanoGPT改进方面的能力，发现即使提供详细提示，当前先进LLM仍难以重现已知创新。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）的快速发展可能推动科学进步，但关键在于能否重现现有研究成果。为此，论文旨在评估AI代理在活跃研究领域中重现结果的能力。

研究方法: 论文引入了自动化LLM速度运行基准测试，基于NanoGPT速度竞赛的19项任务，提供训练脚本和三种提示格式（从伪代码到论文式描述），测试代理重现改进的能力。

研究结果: 研究发现，即使结合先进框架，当前LLM仍难以重现已知创新，表明其在自动化科学重现方面的能力有限。

研究结论: 该基准测试为衡量LLM自动化科学重现能力提供了简单且未饱和的标准，这是自主研究代理的必要技能之一。

中文摘要: 大型语言模型（LLM）的快速发展有望助力科学进步，而重现现有成果是实现这一目标的关键能力。为评估AI代理在活跃研究领域中重现结果的能力，我们提出了自动化LLM速度运行基准测试，利用NanoGPT速度竞赛的研究成果。该竞赛旨在以最短时间训练GPT-2模型。19项速度运行任务为代理提供了先前记录的训练脚本，并可选配三种提示格式（从伪代码到论文式描述新记录的改进）。这些任务设计为快速执行，改进涵盖从高层次算法进步到硬件优化的多样化代码级变更。这些特点使该基准测试既易于访问，又能真实反映改进LLM训练的挑战。我们发现，即使结合先进框架，当前推理LLM仍难以重现已知创新。因此，该基准测试为衡量LLM自动化科学重现能力提供了简单且未饱和的标准，这是自主研究代理的必要（但非充分）技能。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [206] [Optimal Estimation of Watermark Proportions in Hybrid AI-Human Texts](https://arxiv.org/abs/2506.22343)
**中文标题：混合AI-人类文本中水印比例的最优估计**

*Xiang Li,Garrett Wen,Weiqing He,Jiayuan Wu,Qi Long,Weijie J. Su*

主要分类: stat.ML

摘要简述: 本文提出一种优化估计混合来源文本中水印比例的方法，基于关键统计量的混合模型，证明了在某些水印方案中比例参数不可识别，而在连续关键统计量方法中可识别，并提出了高效估计器。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究多关注纯水印文本检测，但实际场景中常出现混合来源文本（人类书写与水印内容混合）。本文旨在解决混合文本中水印比例的最优估计问题。

研究方法: 将问题建模为基于关键统计量的混合模型比例参数估计，证明某些水印方案中参数不可识别，而在连续关键统计量方法中可识别，并提出高效估计器及极小极大下界。

研究结果: 在合成数据和开源模型生成的混合文本上验证，所提估计器能持续实现高精度估计。

研究结论: 本文为混合来源文本中水印比例估计提供了理论框架和高效方法，填补了实际应用中的空白。

中文摘要: 大型语言模型（LLMs）中的文本水印是检测合成文本及区分人类书写与LLM生成内容的重要工具。现有研究多关注纯水印文本检测，但实际场景常涉及混合来源文本（人类书写与水印内容混合）。本文解决了混合文本中水印比例的最优估计问题，将其建模为基于关键统计量的混合模型比例参数估计。首先证明某些水印方案中该参数不可识别，而在采用连续关键统计量的水印方法中，该参数在温和条件下可识别。为此类方法提出高效估计器（包括几种流行的无偏水印示例），并推导基于关键统计量的可测估计器的极小极大下界，表明所提估计器达到这些下界。通过在合成数据和开源模型生成的混合文本上的评估，验证了所提估计器的高精度。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [207] [PhotonSplat: 3D Scene Reconstruction and Colorization from SPAD Sensors](https://arxiv.org/abs/2506.21680)
**中文标题：PhotonSplat：基于SPAD传感器的3D场景重建与着色**

*Sai Sri Teja,Sreevidya Chintalapati,Vinayak Gupta,Mukund Varma T,Haejoon Lee,Aswin Sankaranarayanan,Kaushik Mitra*

主要分类: eess.IV

摘要简述: 本文提出PhotonSplat框架，利用单光子雪崩二极管（SPAD）阵列的二进制图像进行3D场景重建和着色，解决了运动模糊和噪声问题，并支持动态场景。


<details>
  <summary>详细信息</summary>
研究动机: 现有的神经渲染技术在输入图像因相机或物体快速运动而模糊时表现不佳。SPAD传感器能以极高速度捕捉图像，但其二进制图像存在噪声问题。本文旨在利用SPAD传感器解决模糊与噪声的权衡问题。

研究方法: PhotonSplat框架直接从SPAD二进制图像重建3D场景，采用新型3D空间滤波技术降噪，并支持无参考生成先验和基于参考的着色方法。此外，还扩展了动态场景表示。

研究结果: PhotonSplat成功从SPAD二进制图像重建高质量3D场景，并支持颜色恢复和动态场景处理。同时贡献了真实世界多视角数据集PhotonScenes。

研究结论: PhotonSplat为SPAD传感器在3D重建中的应用提供了有效解决方案，解决了噪声与模糊的权衡问题，并支持动态场景和下游任务。

中文摘要: 神经渲染技术的进步使得高质量3D重建成为可能，但在输入图像因相机或物体快速运动而模糊时，这些技术往往失效。本文利用单光子雪崩二极管（SPAD）阵列这一新兴传感技术，解决了此类问题。SPAD能以极高速度捕捉图像，但其二进制图像存在随机光子到达带来的噪声问题。为此，我们提出PhotonSplat框架，直接从SPAD二进制图像重建3D场景，有效平衡噪声与模糊的权衡。该框架采用新型3D空间滤波技术降低渲染噪声，并支持无参考生成先验和基于参考的着色方法，适用于分割、目标检测和外观编辑等下游任务。此外，我们还扩展了动态场景表示方法，使其适用于运动物体场景。同时，我们贡献了基于SPAD传感器捕获的真实世界多视角数据集PhotonScenes。

</details>


### [208] [TUS-REC2024: A Challenge to Reconstruct 3D Freehand Ultrasound Without External Tracker](https://arxiv.org/abs/2506.21765)
**中文标题：TUS-REC2024：无外部追踪器的3D自由手超声重建挑战**

*Qi Li,Shaheer U. Saeed,Yuliang Huang,Mingyuan Luo,Zhongnuo Yan,Jiongquan Chen,Xin Yang,Dong Ni,Nektarios Winter,Phuc Nguyen,Lucas Steinberger,Caelan Haney,Yuan Zhao,Mingjie Jiang,Bowen Ren,SiYeoul Lee,Seonho Kim,MinKyung Seo,MinWoo Kim,Yimeng Dou,Zhiwei Zhang,Yin Li,Tomy Varghese,Dean C. Barratt,Matthew J. Clarkson,Tom Vercauteren,Yipeng Hu*

主要分类: eess.IV

摘要简述: TUS-REC2024挑战赛旨在推动无外部追踪器的3D自由手超声重建技术发展，提供公开数据集和评估框架，吸引了43支团队参与，展示了多种算法方法，并分析了当前技术的进展与局限。


<details>
  <summary>详细信息</summary>
研究动机: 无追踪器的自由手超声重建技术具有低成本、便携性和广泛部署的优势，但面临帧间运动估计、漂移累积和扫描协议通用性等挑战。TUS-REC2024挑战赛旨在通过公开数据集和评估框架推动该领域的研究进展。

研究方法: 挑战赛提供了公开数据集、基线模型和评估框架，吸引了43支注册团队，其中6支团队提交了21个有效的Docker化解决方案。方法涵盖循环模型、配准驱动的体积优化、注意力机制和物理启发模型等。

研究结果: 挑战赛展示了多种算法方法在3D自由手超声重建中的表现，分析了其在不同评估指标下的优劣，揭示了当前技术的进展与局限性。

研究结论: TUS-REC2024挑战赛为无追踪器的3D自由手超声重建提供了基准和方向，未来将持续改进并扩大影响力。

中文摘要: 无追踪器的自由手超声重建技术旨在从2D超声图像序列中重建3D体积，无需依赖外部追踪系统，提供了一种低成本、便携且广泛可用的体积成像替代方案。然而，该技术面临帧间运动估计、漂移累积和扫描协议通用性等挑战。TUS-REC2024挑战赛首次提供了公开数据集、基线模型和评估框架，以推动无追踪器的3D超声重建技术发展。挑战赛吸引了43支注册团队，其中6支团队提交了21个有效的Docker化解决方案。提交的方法涵盖了循环模型、配准驱动的体积优化、注意力机制和物理启发模型等多种算法。本文概述了挑战赛的设计，总结了数据集的关键特征，提供了简短的文献综述，介绍了基于追踪自由手超声数据的方法技术细节，并对提交方法在多个评估指标下进行了比较分析。结果突出了该领域最新技术的进展与局限，并为未来研究指明了方向。数据、评估代码和基线模型已公开，以促进持续开发和可重复性。作为一个动态发展的基准，该挑战赛将持续改进。挑战赛在MICCAI 2024举办，并将在MICCAI 2025再次举办，反映了其日益增长的影响力和对该领域发展的持续承诺。

</details>


### [209] [Physical Degradation Model-Guided Interferometric Hyperspectral Reconstruction with Unfolding Transformer](https://arxiv.org/abs/2506.21880)
**中文标题：基于物理退化模型引导的干涉高光谱重建与展开Transformer**

*Yuansheng Li,Yunhao Zou,Linwei Chen,Ying Fu*

主要分类: eess.IV

摘要简述: 本文提出了一种基于物理退化模型和展开Transformer的干涉高光谱重建方法，通过合成训练数据集和设计新型网络架构，解决了干涉高光谱成像中的重建难题。


<details>
  <summary>详细信息</summary>
研究动机: 干涉高光谱成像（IHI）在大规模遥感任务中具有重要应用，但其成像质量受限于复杂的误差和现有信号处理算法的不足。主要挑战包括缺乏训练数据集和难以通过学习消除IHI特有的退化成分。

研究方法: 首先，基于成像物理和辐射校准数据，建立简化的IHI退化模型和参数估计方法，合成逼真的训练数据集。其次，设计干涉高光谱重建展开Transformer（IHRUT），通过条纹增强机制和空间-光谱Transformer架构实现光谱校正和细节恢复。

研究结果: 实验结果表明，该方法在干涉高光谱重建中表现出卓越的性能和泛化能力。

研究结论: 本文提出的方法通过物理模型指导和学习架构创新，显著提升了干涉高光谱成像的重建质量，为遥感任务提供了有效解决方案。

中文摘要: 干涉高光谱成像（IHI）因其在通量和光谱分辨率上的优势，成为大规模遥感任务的关键技术。然而，IHI易受成像步骤中复杂误差的影响，且其质量受限于现有的基于信号处理的重建算法。性能提升面临两大挑战：1）缺乏训练数据集；2）难以通过学习消除IHI特有的退化成分。为解决这些问题，我们提出了一种新型IHI重建流程。首先，基于成像物理和辐射校准数据，建立了简化而准确的IHI退化模型及参数估计方法。该模型能够从高光谱图像（HSIs）合成逼真的IHI训练数据集，弥合了IHI重建与深度学习之间的鸿沟。其次，我们设计了干涉高光谱重建展开Transformer（IHRUT），通过条纹增强机制和空间-光谱Transformer架构，实现了有效的光谱校正和细节恢复。实验结果表明，我们的方法具有卓越的性能和泛化能力。

</details>


### [210] [UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields](https://arxiv.org/abs/2506.21884)
**中文标题：UnMix-NeRF：光谱解混与神经辐射场的结合**

*Fabian Perez,Sara Rojas,Carlos Hinojosa,Hoover Rueda-Chacón,Bernard Ghanem*

主要分类: eess.IV

摘要简述: UnMix-NeRF将光谱解混技术与神经辐射场结合，实现了高光谱新视角合成和无监督材料分割，提升了材料感知能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于神经辐射场（NeRF）的分割方法仅依赖RGB数据，缺乏材料属性信息，限制了在机器人、增强现实等应用中的准确性。

研究方法: UnMix-NeRF通过建模光谱反射的漫反射和镜面反射分量，利用全局端元字典表示纯材料特征，并通过点级丰度分布实现材料分割。

研究结果: 实验表明，UnMix-NeRF在高光谱重建和材料分割方面优于现有方法，并支持基于材料的场景编辑。

研究结论: UnMix-NeRF成功结合光谱解混与NeRF，为材料感知和场景编辑提供了新工具。

中文摘要: 基于神经辐射场（NeRF）的分割方法主要关注对象语义，仅依赖RGB数据，缺乏材料属性信息。这一限制影响了材料感知的准确性，而材料感知对机器人、增强现实、仿真等应用至关重要。我们提出UnMix-NeRF，将光谱解混技术融入NeRF，实现高光谱新视角合成和无监督材料分割。该方法通过漫反射和镜面反射分量建模光谱反射，利用学习的全局端元字典表示纯材料特征，并通过点级丰度分布捕捉其分布。对于材料分割，我们利用沿学习端元的光谱特征预测，实现无监督材料聚类。此外，UnMix-NeRF支持通过修改端元字典进行场景编辑，实现灵活的材料外观操控。大量实验验证了该方法的优越性，在高光谱重建和材料分割方面表现优于现有方法。项目页面：https://www.factral.co/UnMix-NeRF。

</details>


### [211] [StableCodec: Taming One-Step Diffusion for Extreme Image Compression](https://arxiv.org/abs/2506.21977)
**中文标题：StableCodec：驯服单步扩散以实现极端图像压缩**

*Tianyu Zhang,Xin Luo,Li Li,Dong Liu*

主要分类: eess.IV

摘要简述: StableCodec提出了一种基于单步扩散的高保真图像压缩方法，通过高效深度压缩潜在编解码器和双分支编码结构，显著提升了极低比特率下的图像重建质量和速度。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散模型的图像压缩方法在极低比特率下需要大量去噪步骤，且难以保证像素级一致性，限制了实时应用。StableCodec旨在解决这些问题，实现高效、高保真的图像压缩。

研究方法: 1. 开发高效的深度压缩潜在编解码器，传输噪声潜在表示以支持单步去噪。2. 提出双分支编码结构，通过辅助编码器和解码器提升重建保真度。3. 采用端到端优化，结合比特率和像素级约束。

研究结果: 在CLIC 2020、DIV2K和Kodak数据集上，StableCodec在FID、KID和DISTS指标上显著优于现有方法，甚至在0.005比特/像素下仍保持高保真度，推理速度与主流变换编码方案相当。

研究结论: StableCodec通过单步扩散和双分支结构，实现了极低比特率下的高效、高保真图像压缩，为实时应用提供了可行解决方案。

中文摘要: 基于扩散的图像压缩方法通过利用预训练的大规模文本到图像扩散模型的生成先验，在超低比特率（低于0.05比特/像素）下展现了卓越的潜力。然而，现有方法在极低比特率约束下需要大量去噪步骤以生成逼真结果，限制了其在实时压缩场景中的应用。此外，这些方法通常牺牲重建保真度，因为扩散模型难以保证像素级一致性。为解决这些问题，我们提出了StableCodec，通过单步扩散实现高保真和高逼真的极端图像压缩，并提升编码效率。为实现超低比特率，我们首先开发了一种高效的深度压缩潜在编解码器，用于传输噪声潜在表示以支持单步去噪。随后，我们提出了一种双分支编码结构，包含一对辅助编码器和解码器，以增强重建保真度。此外，我们采用端到端优化，结合比特率和像素级约束。在CLIC 2020、DIV2K和Kodak数据集上的大量实验表明，StableCodec在FID、KID和DISTS指标上显著优于现有方法，甚至在0.005比特/像素下仍保持高保真度，同时推理速度与主流变换编码方案相当。所有源代码可在https://github.com/LuizScarlet/StableCodec获取。

</details>


### [212] [Noise-Inspired Diffusion Model for Generalizable Low-Dose CT Reconstruction](https://arxiv.org/abs/2506.22012)
**中文标题：噪声启发的扩散模型用于通用低剂量CT重建**

*Qi Gao,Zhihao Chen,Dong Zeng,Junping Zhang,Jianhua Ma,Hongming Shan*

主要分类: eess.IV

摘要简述: 本文提出了一种名为NEED的噪声启发扩散模型，用于通用低剂量CT重建，通过双域扩散模型和时步匹配策略，显著提升了重建和泛化性能。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在低剂量CT重建中的泛化能力面临挑战，尤其是对训练数据中未见的剂量水平。现有方法依赖大量配对数据或微调，而扩散模型虽表现优异，但可能因噪声分布偏差和先验信息不准确导致不真实结构。

研究方法: NEED包含两个关键部分：1) 针对投影数据的移位泊松扩散模型，与预对数LDCT投影的噪声模型对齐；2) 双重引导扩散模型，利用LDCT图像和初始重建更精准定位先验信息。通过双域重建和时步匹配策略，NEED仅需正常剂量数据训练，并适用于测试中的多种未见剂量水平。

研究结果: 在两个数据集上的定性、定量和基于分割的评估表明，NEED在重建和泛化性能上均优于现有方法。

研究结论: NEED通过噪声特性和双域扩散模型的结合，显著提升了低剂量CT重建的通用性和性能，为实际应用提供了有效解决方案。

中文摘要: 深度学习在低剂量计算机断层扫描（CT）重建中的泛化能力至关重要，但仍具挑战性。先前方法严重依赖配对数据，通过收集多样化CT数据重新训练或少量测试数据微调来提高泛化性能和鲁棒性。最近，扩散模型在低剂量CT（LDCT）重建中表现出色且具有通用性，但由于CT图像噪声偏离高斯分布及噪声LDCT图像引导的先验信息不准确，可能产生不真实结构。本文提出了一种噪声启发的扩散模型NEED，用于通用LDCT重建，该模型针对每个域的噪声特性定制扩散过程。首先，提出了一种新颖的移位泊松扩散模型用于投影数据去噪，使扩散过程与预对数LDCT投影的噪声模型对齐。其次，设计了一种双重引导扩散模型用于图像重建优化，利用LDCT图像和初始重建更精准定位先验信息并提升重建保真度。通过级联这两个扩散模型实现双域重建，NEED仅需正常剂量数据训练，并通过时步匹配策略有效扩展到测试中的多种未见剂量水平。在两个数据集上的定性、定量和基于分割的评估表明，NEED在重建和泛化性能上均优于现有方法。源代码发布于https://github.com/qgao21/NEED。

</details>


### [213] [Towards Scalable and Robust White Matter Lesion Localization via Multimodal Deep Learning](https://arxiv.org/abs/2506.22041)
**中文标题：基于多模态深度学习的可扩展且鲁棒的白质病变定位方法**

*Julia Machnio,Sebastian Nørgaard Llambias,Mads Nielsen,Mostafa Mehdipour Ghazi*

主要分类: eess.IV

摘要简述: 本文提出了一种基于多模态深度学习的白质高信号（WMH）分割和定位框架，通过多任务学习和多模态输入提升准确性和鲁棒性。实验表明多模态输入显著优于单模态，但联合任务学习效果不如单独模型。


<details>
  <summary>详细信息</summary>
研究动机: 白质高信号（WMH）是脑血管疾病和神经退行性变的影像学标志，其准确分割和空间定位对诊断和监测至关重要。现有方法在处理缺失模态和整合解剖定位方面缺乏灵活性，因此需要一种更灵活且高效的解决方案。

研究方法: 研究提出了一种深度学习框架，直接在原生空间中使用单模态或多模态MRI输入进行WMH分割和定位。评估了四种输入配置（仅FLAIR、仅T1、FLAIR+T1拼接、模态可互换设置），并引入多任务模型联合预测病变和解剖区域掩码以估计区域病变负担。

研究结果: 实验基于MICCAI WMH分割挑战数据集，显示多模态输入显著提升分割性能，优于单模态模型。模态可互换设置牺牲了部分准确性以换取鲁棒性，适用于模态缺失情况。联合任务学习效果不如单独模型，表明任务间存在表征冲突。

研究结论: 研究强调了多模态融合在WMH分析中的准确性和鲁棒性优势，以及联合建模在集成预测中的潜力。未来需进一步优化任务间表征以避免冲突。

中文摘要: 白质高信号（WMH）是脑血管疾病和神经退行性变的影像学标志，其准确分割和空间定位对诊断和监测至关重要。尽管多模态MRI为WM病变检测和定位提供了互补对比度，现有方法常缺乏处理缺失模态的灵活性，且未能高效整合解剖定位。我们提出了一种深度学习框架，直接在原生空间中使用单模态和多模态MRI输入进行WMH分割和定位。研究评估了四种输入配置：仅FLAIR、仅T1、FLAIR和T1拼接、以及模态可互换设置，并进一步引入多任务模型联合预测病变和解剖区域掩码以估计区域病变负担。在MICCAI WMH分割挑战数据集上的实验表明，多模态输入显著提升了分割性能，优于单模态模型。模态可互换设置以准确性为代价换取鲁棒性，适用于模态缺失情况。联合任务学习效果不如单独模型，表明任务间存在表征冲突。研究结果凸显了多模态融合在WMH分析中的准确性和鲁棒性优势，以及联合建模在集成预测中的潜力。

</details>


### [214] [Advanced Deep Learning Techniques for Automated Segmentation of Type B Aortic Dissections](https://arxiv.org/abs/2506.22222)
**中文标题：基于先进深度学习技术的B型主动脉夹层自动分割方法**

*Hao Xu,Ruth Lim,Brian E. Chapman*

主要分类: eess.IV

摘要简述: 本文提出四种深度学习模型用于B型主动脉夹层的自动分割，在CTA图像上实现了高精度的真腔、假腔和假腔血栓分割，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 主动脉夹层是一种危及生命的心血管疾病，需要从CTA图像中准确分割真腔、假腔和假腔血栓以进行有效管理。手动分割耗时且结果不一致，因此需要开发自动化解决方案。

研究方法: 研究开发了四种基于深度学习的B型主动脉夹层分割模型：单步模型、序列模型、序列多任务模型和集成模型，采用3D U-Net和Swin-UnetR架构。使用100例回顾性CTA图像数据集，分为训练集（80例）、验证集（10例）和测试集（10例），通过Dice系数和Hausdorff距离评估性能。

研究结果: 所提方法在分割精度上表现优异，真腔、假腔和假腔血栓的Dice系数分别为0.91±0.07、0.88±0.18和0.47±0.25，显著优于Yao等人的方法（0.78±0.20、0.68±0.18和0.25±0.31）。

研究结论: 提出的深度学习管道能够准确分割B型主动脉夹层特征，为监测和治疗规划提供了形态学参数支持。

中文摘要: 目的：主动脉夹层是一种危及生命的心血管疾病，需要从CTA图像中准确分割真腔（TL）、假腔（FL）和假腔血栓（FLT）以进行有效管理。手动分割耗时且结果不一致，因此需要自动化解决方案。材料与方法：我们开发了四种基于深度学习的B型主动脉夹层分割管道：单步模型、序列模型、序列多任务模型和集成模型，采用3D U-Net和Swin-UnetR架构。使用100例回顾性CTA图像数据集，分为训练集（80例）、验证集（10例）和测试集（10例），通过Dice系数和Hausdorff距离评估性能。结果：我们的方法在分割精度上表现优异，真腔、假腔和假腔血栓的Dice系数分别为0.91±0.07、0.88±0.18和0.47±0.25，显著优于Yao等人的方法（0.78±0.20、0.68±0.18和0.25±0.31）。结论：提出的管道能够准确分割B型主动脉夹层特征，为监测和治疗规划提供了形态学参数支持。

</details>


### [215] [Cardiovascular disease classification using radiomics and geometric features from cardiac CT](https://arxiv.org/abs/2506.22226)
**中文标题：基于心脏CT图像的放射组学和几何特征的心血管疾病分类**

*Ajay Mittal,Raghav Mehta,Omar Todd,Philipp Seeböck,Georg Langs,Ben Glocker*

主要分类: eess.IV

摘要简述: 本文提出了一种基于放射组学和几何特征的心脏CT图像心血管疾病分类方法，通过分割、配准和分类三步骤，提高了分类准确性和临床可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于深度学习的CT图像心血管疾病分类方法难以从临床角度解释，因此本文旨在通过分解流程并提取可解释特征来解决这一问题。

研究方法: 方法分为三步：(1) 使用Atlas-ISTN框架和分割基础模型生成心脏结构分割和健康图谱；(2) 通过图谱配准提取放射组学特征和几何特征；(3) 利用这些特征进行心血管疾病分类。

研究结果: 在ASOCA数据集上的实验表明，该方法分类准确率达到87.50%，显著优于直接使用原始CT图像的模型（67.50%）。

研究结论: 通过分解流程并提取可解释特征，本文方法在提高心血管疾病分类准确性的同时，增强了临床可解释性。

中文摘要: 自动从计算机断层扫描（CT）图像中检测和分类心血管疾病（CVD）在促进临床决策方面具有重要意义。然而，近期大多数基于深度学习的方法要么直接处理原始CT数据，要么将其与心脏结构分割结合训练端到端分类器，这些方法在临床解释上存在困难。为解决这一问题，本文将CVD分类流程分解为三个部分：(i) 图像分割，(ii) 图像配准，(iii) 下游CVD分类。具体而言，我们利用Atlas-ISTN框架和最新的分割基础模型生成心脏结构分割和健康图谱，并进一步提取临床可解释的放射组学特征以及基于变形场的几何特征（通过图谱配准）用于CVD分类。在公开的ASOCA数据集上的实验表明，使用这些特征的分类准确率（87.50%）显著优于直接使用原始CT图像的模型（67.50%）。代码已公开：https://github.com/biomedia-mira/grc-net

</details>


### [216] [DIGS: Dynamic CBCT Reconstruction using Deformation-Informed 4D Gaussian Splatting and a Low-Rank Free-Form Deformation Model](https://arxiv.org/abs/2506.22280)
**中文标题：DIGS：基于变形信息的4D高斯泼溅和低秩自由变形模型的动态CBCT重建**

*Yuliang Huang,Imraj Singh,Thomas Joyce,Kris Thielemans,Jamie R. McClelland*

主要分类: eess.IV

摘要简述: 本文提出了一种基于变形信息的4D高斯泼溅和低秩自由变形模型的动态CBCT重建方法（DIGS），显著提升了图像质量并加快了计算速度。


<details>
  <summary>详细信息</summary>
研究动机: 动态CBCT重建在放射治疗中至关重要，但现有方法因呼吸运动变异性导致图像质量下降。4D高斯泼溅（4DGS）虽能建模动态场景，但现有方法计算成本高且缺乏空间正则化，导致高斯运动不一致。本文旨在解决这些问题。

研究方法: 提出了一种基于自由变形（FFD）的空间基函数和变形信息框架，通过统一变形场耦合高斯均值位置、尺度和旋转的时间演化，确保运动一致性。

研究结果: 在六个CBCT数据集上的实验表明，该方法图像质量优于HexPlane，且速度提升了6倍。

研究结论: 变形信息的4DGS方法为高效、运动补偿的CBCT重建提供了新思路，代码已开源。

中文摘要: 3D锥束CT（CBCT）在放射治疗中广泛应用，但呼吸运动会导致运动伪影。临床常用方法是将投影按呼吸相位分类并重建每相位图像，但未考虑呼吸变异性。动态CBCT则直接重建每投影图像，捕捉连续运动。4D高斯泼溅（4DGS）为动态场景建模提供了强大工具，但其在动态CBCT中的应用尚未充分探索。现有4DGS方法（如HexPlane）使用隐式运动表示，计算成本高。而显式低秩运动模型缺乏空间正则化，导致高斯运动不一致。为解决这些问题，我们提出了一种基于自由变形（FFD）的空间基函数和变形信息框架，通过统一变形场耦合高斯均值位置、尺度和旋转的时间演化，确保运动一致性。在六个CBCT数据集上的实验表明，该方法图像质量优于HexPlane，且速度提升了6倍。这些结果凸显了变形信息4DGS在高效、运动补偿CBCT重建中的潜力。代码见https://github.com/Yuliang-Huang/DIGS。

</details>


### [217] [Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism](https://arxiv.org/abs/2506.22397)
**中文标题：基于引导条件流匹配的显微镜图像去雾：在保真度与真实性之间寻找平衡点**

*Anirban Ray,Ashesh,Florian Jug*

主要分类: eess.IV

摘要简述: 本文提出了一种名为HazeMatching的新方法，用于平衡荧光显微镜图像去雾任务中的数据保真度和视觉真实性。通过条件流匹配框架的引导，该方法在合成和真实数据集上均表现出色，优于7种基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 荧光显微镜在生命科学中至关重要，但低成本显微镜（如宽场显微镜）无法过滤离焦光，导致图像模糊。现有去雾方法要么牺牲真实性以追求数据保真度，要么缺乏定量准确性。本文旨在找到一种平衡两者需求的方法。

研究方法: HazeMatching是一种基于条件流匹配框架的迭代去雾方法，通过引导生成过程的条件速度场，平衡数据保真度和视觉真实性。该方法无需显式退化算子，适用于真实显微镜数据。

研究结果: 在5个合成和真实数据集上，HazeMatching在保真度和真实性之间取得了平衡，优于7种基线方法。校准分析表明，其预测结果具有良好的校准性。

研究结论: HazeMatching在荧光显微镜图像去雾任务中实现了保真度与真实性的平衡，且无需显式退化算子，具有广泛适用性。所有数据和代码将公开。

中文摘要: 荧光显微镜是生命科学领域科学进步的主要驱动力。尽管高端共聚焦显微镜能够过滤离焦光，但更便宜且易用的显微镜（如宽场显微镜）无法实现，从而导致图像模糊。计算去雾试图结合两者的优势，以低成本获得清晰图像。感知-失真权衡表明，我们可以优化数据保真度（如低MSE或高PSNR）或数据真实性（如LPIPS或FID等感知指标）。现有方法要么以牺牲真实性为代价优先保真度，要么生成缺乏定量准确性的感知可信结果。本文提出HazeMatching，一种用于显微镜图像去雾的新型迭代方法，有效平衡了这些目标。我们通过引导条件速度场中的生成过程，在条件流匹配框架中实现了这一平衡。在5个合成和真实数据集上评估HazeMatching，涵盖失真和感知质量。与7种基线方法相比，我们的方法在保真度和真实性之间实现了平均一致的平衡。此外，校准分析表明，HazeMatching的预测结果具有良好的校准性。值得注意的是，我们的方法无需显式退化算子，易于应用于真实显微镜数据。所有训练和评估数据及代码将以宽松许可公开。

</details>


### [218] [Single-shot HDR using conventional image sensor shutter functions and optical randomization](https://arxiv.org/abs/2506.22426)
**中文标题：利用传统图像传感器快门功能和光学随机化的单次曝光高动态范围成像**

*Xiang Dai,Kyrollos Yanny,Kristina Monakhova,Nicholas Antipa*

主要分类: eess.IV

摘要简述: 本文提出一种单次曝光高动态范围（HDR）成像方法，利用普通传感器的全局复位释放（GRR）快门模式和光学随机化技术，通过优化问题恢复HDR数据，显著提升高光区域的恢复效果。


<details>
  <summary>详细信息</summary>
研究动机: 传统HDR成像依赖多次曝光，导致动态场景中出现运动伪影。单次曝光HDR虽能解决这一问题，但现有方法在高光区域表现不佳。本文旨在通过结合GRR快门模式和光学随机化技术，提升单次曝光HDR的性能。

研究方法: 利用普通传感器的GRR快门模式（底部行曝光时间更长），结合光学随机化技术（通过随机光纤束将图像随机排列到传感器上），生成空间随机化的曝光数据。通过优化问题和简单的总变分图像先验恢复HDR数据。

研究结果: 仿真显示，在传感器像素饱和度高（10%以上）时，该方法优于其他单次曝光HDR方法，且在低饱和度（1%）时表现相当。实验原型使用商用随机光纤束和低成本传感器，动态范围提升至73dB（原传感器为48dB）。

研究结论: 本文方法通过GRR快门和光学随机化技术，有效解决了单次曝光HDR在高光区域的恢复问题，为低成本HDR成像提供了可行方案。

中文摘要: 高动态范围（HDR）成像是克服图像传感器动态范围限制的关键技术。传统方法依赖多次曝光，导致捕获时间延长，动态场景中产生运动伪影。单次曝光HDR通过将HDR数据编码到单次曝光中并计算恢复，解决了这一问题。现有方法依赖强图像先验恢复曝光不足的细节，但在高光区域表现不佳。我们利用普通传感器的全局复位释放（GRR）快门模式（底部行曝光时间更长），结合光学随机化技术（将图像随机排列到传感器上），生成空间随机化的曝光数据。通过优化问题和简单的总变分图像先验恢复HDR数据。仿真显示，在传感器像素饱和度高（10%以上）时，该方法优于其他单次曝光HDR方法，且在低饱和度（1%）时表现相当。实验原型使用商用随机光纤束和低成本传感器，动态范围提升至73dB（原传感器为48dB）。

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [219] [Using Large Language Models to Suggest Informative Prior Distributions in Bayesian Statistics](https://arxiv.org/abs/2506.21964)
**中文标题：利用大型语言模型为贝叶斯统计中的信息性先验分布提供建议**

*Michael A. Riegler,Kristoffer Herland Hellton,Vajira Thambawita,Hugo L. Hammer*

主要分类: stat.ME

摘要简述: 研究探讨利用大型语言模型（LLMs）为贝叶斯统计中的先验分布提供建议，实验表明LLMs能正确识别关联方向，但在先验分布的校准上仍需改进。


<details>
  <summary>详细信息</summary>
研究动机: 贝叶斯统计中选择先验分布具有挑战性、资源密集且主观性强，研究旨在通过LLMs提供高效、客观的知识性先验建议。

研究方法: 开发了详细的提示词，要求LLMs不仅建议先验分布，还需验证和反思其选择。评估了Claude Opus、Gemini 2.5 Pro和ChatGPT-4o-mini在心脏病风险和混凝土强度数据集上的表现。

研究结果: LLMs能正确识别所有关联方向，但中等信息先验常过于自信，与数据不符。Claude和Gemini表现优于ChatGPT，尤其在弱信息先验上，Claude避免了不必要的模糊性。

研究结论: LLMs在高效、客观地开发信息性先验方面潜力巨大，但需解决先验宽度校准问题以避免过度自信或不足。

中文摘要: 在贝叶斯统计中选择先验分布具有挑战性、资源密集且主观性强。本研究探讨利用大型语言模型（LLMs）提供合适的知识性先验建议。我们开发了详细的提示词，要求LLMs不仅建议先验分布，还需验证和反思其选择。

我们评估了Claude Opus、Gemini 2.5 Pro和ChatGPT-4o-mini在两个真实数据集（心脏病风险和混凝土强度）上的表现。所有LLMs均正确识别了所有关联方向（例如，男性心脏病风险更高）。通过Kullback-Leibler散度衡量建议先验的质量。

LLMs提供了中等和弱信息性先验。中等先验常过于自信，导致分布与数据不符。实验中，Claude和Gemini表现优于ChatGPT。在弱信息先验上，ChatGPT和Gemini默认使用“不必要的模糊”均值为0，而Claude未出现此问题，显示出显著优势。

LLMs识别正确关联的能力表明其在高效、客观地开发信息性先验方面潜力巨大。然而，主要挑战仍在于校准先验宽度以避免过度自信或不足。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [220] [Demonstrating Interoperable Channel State Feedback Compression with Machine Learning](https://arxiv.org/abs/2506.21796)
**中文标题：基于机器学习的互操作性信道状态反馈压缩演示**

*Dani Korpi,Rachel Wang,Jerry Wang,Abdelrahman Ibrahim,Carl Nuzman,Runxin Wang,Kursat Rasim Mestav,Dustin Zhang,Iraj Saniee,Shawn Winston,Gordana Pavlovic,Wei Ding,William J. Hillery,Chenxi Hao,Ram Thirunagari,Jung Chang,Jeehyun Kim,Bartek Kozicki,Dragan Samardzija,Taesang Yoo,Andreas Maeder,Tingfang Ji,Harish Viswanathan*

主要分类: eess.SP

摘要简述: 本文提出了一种基于机器学习的互操作性信道状态反馈压缩方法，并在实际环境中验证了其有效性，无需共享ML模型即可实现高精度信道重建和下行链路吞吐量提升。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习在无线网络中的信道状态反馈压缩应用广泛，但缺乏实际场景中无需共享ML模型的互操作性验证。本文旨在填补这一空白。

研究方法: 提出了一种保密训练互操作性压缩与解压缩ML模型的新方法，并通过原型用户设备和基站验证模型准确性。

研究结果: 实验结果表明，无需共享ML模型即可实现高精度信道信息重建，并显著提升波束成形下的下行链路吞吐量。

研究结论: 本研究为6G网络中基于机器学习的信道反馈实际应用奠定了基础。

中文摘要: 基于神经网络的信道状态反馈压缩与解压缩是机器学习在无线网络中最广泛研究的应用之一。多项仿真研究表明，基于机器学习的反馈压缩可以降低开销并提高信道信息准确性。然而，据我们所知，目前尚无实际场景中验证基于机器学习的信道反馈压缩优势的概念证明，尤其是在用户设备（UE）和基站无法访问彼此ML模型的情况下。本文提出了一种新颖的保密训练互操作性压缩与解压缩ML模型的方法，并通过原型UE和基站验证了模型的准确性。基于机器学习的信道反馈性能通过重建信道信息的准确性和使用该信息进行波束成形时的下行链路吞吐量增益来衡量。测量结果表明，无需在设备和网络供应商之间共享ML模型即可开发出高精度的基于机器学习的信道反馈链路。这些结果为6G网络中基于机器学习的信道反馈的实际应用铺平了道路。

</details>


### [221] [From Token to Rhythm: A Multi-Scale Approach for ECG-Language Pretraining](https://arxiv.org/abs/2506.21803)
**中文标题：从标记到节律：一种用于ECG-语言预训练的多尺度方法**

*Fuying Wang,Jiacheng Xu,Lequan Yu*

主要分类: eess.SP

摘要简述: 本文提出了一种多尺度ECG-语言预训练模型MELP，通过分层监督从ECG-文本对中学习，显著提升了ECG信号的表示能力，并在多个任务中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统ECG分析方法依赖大量人工标注，耗时耗力。自监督学习（SSL）虽能缓解这一问题，但现有方法未能捕捉ECG信号的多尺度特性，导致学习到的表示泛化能力不足。

研究方法: MELP模型首先预训练一个心脏病学专用语言模型，随后在token、节拍和节律三个层次上对ECG信号与文本报告进行跨模态对齐，以捕捉不同时间尺度的结构化信息。

研究结果: 在三个公开ECG数据集上的实验表明，MELP在零样本ECG分类、线性探测和迁移学习任务中均优于现有SSL方法。

研究结论: MELP通过多尺度监督有效提升了ECG信号的表示能力，为临床应用的多样性和适应性提供了有力支持。

中文摘要: 心电图（ECG）在监测心脏健康和诊断心脏疾病中起着至关重要的作用。然而，传统的ECG分析深度学习方法严重依赖大规模人工标注，这些标注既耗时又耗费资源。为了克服这一限制，自监督学习（SSL）成为一种有前景的替代方案，能够提取鲁棒的ECG表示，并高效迁移到各种下游任务中。尽管已有研究探索了ECG预训练和多模态ECG-语言对齐的SSL方法，但它们往往未能捕捉ECG信号的多尺度特性。因此，这些方法由于无法建模ECG数据的层次结构，难以学习泛化表示。为解决这一问题，我们提出了MELP，一种新型的多尺度ECG-语言预训练模型，充分利用ECG-文本对的分层监督。MELP首先预训练一个心脏病学专用语言模型以增强其对临床文本的理解，随后在标记、节拍和节律三个层次上应用跨模态监督，将ECG信号与文本报告对齐，捕捉不同时间尺度的结构化信息。我们在三个公开ECG数据集上评估了MELP在零样本ECG分类、线性探测和迁移学习等任务中的表现。实验结果表明，MELP优于现有SSL方法，突显了其在多样化临床应用中的有效性和适应性。我们的代码可在https://github.com/HKU-MedAI/MELP获取。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [222] [On the Necessity of Output Distribution Reweighting for Effective Class Unlearning](https://arxiv.org/abs/2506.20893)
**中文标题：论输出分布重加权对有效类别遗忘的必要性**

*Yian Wang,Ali Ebrahimpour-Boroojeny,Hari Sundaram*

主要分类: cs.LG

摘要简述: 本文提出了一种轻量级的输出重加权遗忘方法RWFT，用于从训练好的分类器中完全删除特定类别，无需重新训练。该方法通过重新分配遗忘类别的概率质量，有效抵抗新型成员推理攻击MIA-NN，并在实验中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在删除特定类别时无法完全模拟重新训练模型的行为，且成本高昂。本文旨在解决这一问题，同时满足用户删除权和减少有害或偏见预测的需求。

研究方法: 提出RWFT方法，通过简单重分配遗忘类别的预测概率质量，抵抗MIA-NN攻击，并引入基于总变差（TV）距离的新指标量化残留泄漏。

研究结果: 实验表明，RWFT在现有指标和新TV指标上均优于现有方法，分别提升2.79%和111.45%。

研究结论: RWFT是一种高效且安全的类别遗忘方法，无需重新训练即可达到与重新训练模型相同的效果，同时显著提升安全性。

中文摘要: 本文提出了一种输出重加权遗忘方法RWFT，这是一种轻量级技术，无需完全重新训练即可从训练好的分类器中删除整个类别。遗忘特定类别对于强制执行用户删除权和减少有害或偏见预测至关重要。完全重新训练成本高昂，而现有遗忘方法在预测遗忘类别的样本时无法模拟重新训练模型的行为。我们通过设计一种新型成员推理攻击MIA-NN证明了这一缺陷，该攻击能成功揭示任何现有方法遗忘的类别。我们提出了一种简单的概率质量重分配方法，用于遗忘类别的样本预测，该方法对MIA-NN具有鲁棒性。我们还引入了一种基于预测概率总变差（TV）距离的新指标，以量化残留泄漏，防止未来方法受到此类攻击的影响。通过与现有最先进的机器遗忘基线进行广泛实验，我们表明，我们的方法在先前工作中使用的评估指标和本文提出的新指标上均与完全重新训练的结果一致。与现有最佳方法相比，我们在先前使用的指标上提升了2.79%，在新TV指标上提升了111.45%。

</details>


### [223] [APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization](https://arxiv.org/abs/2506.21655)
**中文标题：APO：通过非对称策略优化增强多模态大语言模型的推理能力**

*Minjie Hong,Zirun Guo,Yan Xia,Zehan Wang,Ziang Zhang,Tao Jin,Zhou Zhao*

主要分类: cs.LG

摘要简述: 本文提出了一种名为非对称策略优化（APO）的方法，通过动态调整KL散度权重和惩罚过长响应，显著提升了多模态大语言模型（MLLMs）的推理能力，同时保持了模型的通用任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在复杂推理任务中表现不佳，而传统的强化学习方法在应用于MLLMs时会导致通用任务性能下降或生成过度详细的推理。本文旨在解决这些问题。

研究方法: 提出了非对称策略优化（APO），将采样响应分为正负两组。对正样本采用难度自适应散度整形（DADS）动态调整KL散度权重；对负样本采用次优轨迹复杂度正则化（STCR）惩罚过长响应。

研究结果: 在Qwen2.5-VL-3B模型上应用APO后，得到的View-R1-3B模型推理能力显著提升，平均性能提升7%，并在多个推理基准测试中优于更大的MLLMs（7-11B），同时保持了通用任务的性能。

研究结论: APO方法通过DADS和STCR技术有效提升了MLLMs的复杂推理能力，同时避免了通用任务性能的下降，展示了广泛的适用性。

中文摘要: 多模态大语言模型（MLLMs）在整合多样化数据方面表现出色，但在复杂推理任务中往往表现不佳。虽然强化学习（RL）可以提升语言模型的推理能力，但将其应用于MLLMs时存在挑战，例如通用任务性能下降或生成过度详细的推理（“过度思考”）。本文研究了KL惩罚和过度思考对MLLMs中RL训练的影响，并提出了非对称策略优化（APO）来解决这些问题。APO将采样响应分为正负两组：对正样本，采用难度自适应散度整形（DADS）动态调整KL散度权重，防止策略熵急剧下降，提升训练稳定性并保留模型知识；对负样本，采用次优轨迹复杂度正则化（STCR）惩罚过长响应，减少过度思考并鼓励更简洁的推理。我们将该方法应用于Qwen2.5-VL-3B模型，得到View-R1-3B。View-R1-3B显著提升了推理能力，平均性能比基础模型提升7%，并在多个推理基准测试中优于更大的MLLMs（7-11B）。重要的是，与其他推理优化的MLLMs不同，View-R1-3B在通用任务上保持了性能的一致性，展示了卓越的泛化能力。这些结果凸显了DADS和STCR技术在提升MLLMs复杂多模态推理能力方面的有效性和广泛适用性。代码将在https://github.com/Indolent-Kawhi/View-R1 上发布。

</details>


### [224] [Performance Prediction for Large Systems via Text-to-Text Regression](https://arxiv.org/abs/2506.21718)
**中文标题：基于文本到文本回归的大型系统性能预测**

*Yash Akhauri,Bryan Lewandowski,Cheng-Hsi Lin,Adrian N. Reyes,Grant C. Forbes,Arissa Wongpanich,Bangding Yang,Mohamed S. Abdelfattah,Sagi Perel,Xingyou Song*

主要分类: cs.LG

摘要简述: 本文提出了一种基于文本到文本回归的通用、可扩展方法，用于预测大型系统的性能指标，相比传统表格回归方法表现更优，尤其在复杂系统数据（如配置文件或系统日志）上。


<details>
  <summary>详细信息</summary>
研究动机: 传统表格回归方法在处理复杂系统数据（如配置文件或系统日志）时，特征工程往往不可行。因此，需要一种更通用、可扩展的方法来预测大型系统的性能指标。

研究方法: 提出文本到文本回归方法，使用60M参数的编码器-解码器模型，从随机初始化开始训练，用于预测资源效率。模型能够轻松适应新任务，仅需500个少样本示例。

研究结果: 在Google的Borg计算集群调度系统上，该方法实现了接近完美的0.99（平均0.9）等级相关性，均方误差比表格方法低100倍，并能捕捉复杂结果分布的密度。

研究结论: 文本到文本回归方法为预测复杂系统性能提供了一种通用且高效的解决方案，为现实世界结果的通用模拟器铺平了道路。

中文摘要: 在许多行业中，预测大型系统的指标结果是一个基本问题，传统上主要依赖表格回归方法。然而，这些方法在处理复杂系统数据（如配置文件或系统日志）时表现不佳，因为特征工程往往不可行。我们提出文本到文本回归作为一种通用、可扩展的替代方案。在预测Google大规模计算集群调度系统Borg的资源效率时，一个60M参数的编码器-解码器模型（从随机初始化开始训练）在整个集群上实现了接近完美的0.99（平均0.9）等级相关性，均方误差比表格方法低100倍。该模型还能轻松适应新任务，仅需500个少样本示例，并能捕捉复杂结果分布的密度。消融研究强调了使用编码器、增加序列长度以及模型固有不确定性量化的重要性。这些发现为现实世界结果的通用模拟器铺平了道路。

</details>


### [225] [Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data](https://arxiv.org/abs/2506.21788)
**中文标题：多任务并行方法在多源、多保真度原子建模数据上稳健预训练图基础模型**

*Massimiliano Lupo Pasini,Jong Youl Choi,Pei Zhang,Kshitij Mehta,Rylie Weaver,Ashwin M. Aji,Karl W. Schulz,Jorda Polo,Prasanna Balaprakash*

主要分类: cs.LG

摘要简述: 本文提出了一种多任务并行方法，用于在多源、多保真度的原子建模数据上稳健预训练图基础模型，通过GPU加速在超级计算机上实现高效扩展。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决在多源、多保真度数据预训练中的挑战，并提升模型在未探索化学区域的迁移能力，本文提出了一种多任务并行方法。

研究方法: 采用多任务学习框架，共享消息传递层处理输入原子结构，并通过多个解码头预测数据特定输出，同时利用GPU加速在超级计算机上分布每个头。

研究结果: 在五个数据集上训练了超过2400万个结构，并在Perlmutter、Aurora和Frontier超级计算机上测试，展示了在高度异构架构上的高效扩展性。

研究结论: 多任务并行方法在多源、多保真度数据预训练中表现出高效扩展性和稳健性，为图基础模型的广泛应用提供了支持。

中文摘要: 使用图神经网络的图基础模型为可持续、高效的原子建模提供了可能。为应对预训练中处理多源、多保真度数据的挑战，近期研究采用多任务学习，其中共享的消息传递层首先处理输入的原子结构，然后将其路由到多个解码头以预测数据特定输出。这种方法稳定了预训练过程，并增强了模型在未探索化学区域的迁移能力。初步结果在大约四百万个结构上表现良好，但对于更大、更多样化的数据集的可推广性以及在超级计算机上的可扩展性仍有疑问。我们提出了一种多任务并行方法，将每个头分布在计算资源上，并通过GPU加速。该方法在开源HydraGNN架构中实现，在五个数据集的超过2400万个结构上进行了训练，并在Perlmutter、Aurora和Frontier超级计算机上进行了测试，展示了在所有三种高度异构超级计算架构上的高效扩展性。

</details>


### [226] [$\textrm{ODE}_t \left(\textrm{ODE}_l \right)$: Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling](https://arxiv.org/abs/2506.21714)
**中文标题：Error**

*Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer*

主要分类: cs.LG

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [227] [A Survey of Continual Reinforcement Learning](https://arxiv.org/abs/2506.21872)
**中文标题：持续强化学习综述**

*Chaofan Pan,Xin Yang,Yanhua Li,Wei Wei,Tianrui Li,Bo An,Jiye Liang*

主要分类: cs.LG

摘要简述: 本文综述了持续强化学习（CRL）的核心概念、挑战与方法，提出了新的分类法，并探讨了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 强化学习（RL）在动态和现实环境中的泛化能力有限，持续学习（CL）为解决这一问题提供了可能。本文旨在全面探讨CRL的研究现状与未来方向。

研究方法: 首先详细回顾现有研究，分析其指标、任务、基准和场景设置；其次提出基于知识存储和/或转移的CRL方法新分类法。

研究结果: 本文总结了CRL的独特挑战，并提出了未来研究的实用建议。

研究结论: CRL是一个有前景的研究方向，但仍需解决其独特挑战以推动实际应用。

中文摘要: 强化学习（RL）是解决序列决策问题的重要机器学习范式。近年来，由于深度神经网络的快速发展，该领域取得了显著进展。然而，RL的成功目前依赖于大量训练数据和计算资源，且其跨任务泛化能力有限，限制了其在动态和现实环境中的应用。随着持续学习（CL）的兴起，持续强化学习（CRL）成为一个有前景的研究方向，旨在通过使智能体持续学习、适应新任务并保留已有知识来解决这些限制。本文全面探讨了CRL，重点关注其核心概念、挑战和方法。首先，我们详细回顾了现有研究，分析其指标、任务、基准和场景设置；其次，从知识存储和/或转移的角度提出了CRL方法的新分类法；最后，我们的分析突出了CRL的独特挑战，并为未来研究方向提供了实用见解。

</details>


### [228] [SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model](https://arxiv.org/abs/2506.21976)
**中文标题：SceneDiffuser++：通过生成世界模型实现城市规模交通模拟**

*Shuhan Tan,John Lambert,Hong Jeon,Sakshum Kulshrestha,Yijing Bai,Jing Luo,Dragomir Anguelov,Mingxing Tan,Chiyu Max Jiang*

主要分类: cs.LG

摘要简述: SceneDiffuser++ 是一种端到端的生成世界模型，通过单一损失函数实现城市规模的交通模拟，整合了场景生成、动态代理行为建模和环境模拟等技术，展示了在长时模拟条件下的优越真实感。


<details>
  <summary>详细信息</summary>
研究动机: 交通模拟的目标是通过生成大量合成数据来补充有限的人工驾驶数据，以实现城市规模的自动驾驶测试和验证。然而，现有技术中动态场景生成和环境模拟等领域的研究较少，因此需要一种能够整合所有关键技术的解决方案。

研究方法: 提出 SceneDiffuser++，一种端到端的生成世界模型，通过单一损失函数训练，整合了场景生成、代理行为建模、遮挡推理、动态场景生成和环境模拟等技术，实现从起点到终点的城市规模交通模拟。

研究结果: 在扩展版的 Waymo Open Motion Dataset (WOMD) 上评估，SceneDiffuser++ 展示了城市规模交通模拟的能力，并在长时模拟条件下表现出优越的真实感。

研究结论: SceneDiffuser++ 是首个能够整合所有关键技术的端到端生成世界模型，为城市规模交通模拟提供了高效且真实的解决方案。

中文摘要: 交通模拟的目标是通过生成大量合成数据来补充有限的人工驾驶数据，以支持自动驾驶的测试和验证。这一愿景的终极目标是构建一个生成式模拟城市，给定城市地图和自动驾驶软件栈，模拟器能够无缝模拟从起点到终点的行程，包括动态代理（如车辆、行人）的动画和交通信号灯状态的控制。我们称这一愿景为 CitySim，它需要整合多种模拟技术：场景生成以填充初始场景、代理行为建模以动画场景、遮挡推理、动态场景生成以无缝生成和移除代理，以及环境模拟（如交通信号灯）。尽管部分关键技术已在不同研究中得到探讨，但动态场景生成和环境模拟等领域的研究较少。我们提出 SceneDiffuser++，这是首个通过单一损失函数训练的端到端生成世界模型，能够整合上述所有需求，实现城市规模的从起点到终点的模拟。我们展示了 SceneDiffuser++ 的城市规模交通模拟能力，并研究了其在长时模拟条件下的优越真实感。我们在扩展版的 Waymo Open Motion Dataset (WOMD) 上评估了模拟质量，该数据集支持行程级别的模拟。

</details>


### [229] [Binned semiparametric Bayesian networks](https://arxiv.org/abs/2506.21997)
**中文标题：分箱半参数贝叶斯网络**

*Rafael Sojo,Javier Díaz-Rozo,Concha Bielza,Pedro Larrañaga*

主要分类: cs.LG

摘要简述: 本文提出了一种新型的半参数概率模型，通过数据分箱降低核密度估计的计算成本，并开发了两种条件概率分布方法，解决了维度灾难问题，实验表明其高效且可靠。


<details>
  <summary>详细信息</summary>
研究动机: 传统非参数分布中的核密度估计计算成本高，且维度灾难问题限制了分箱模型的应用。本文旨在通过分箱技术和稀疏张量等方法，开发更高效的半参数贝叶斯网络。

研究方法: 提出了两种新的条件概率分布方法：稀疏分箱核密度估计和傅里叶核密度估计，利用稀疏张量和限制父节点数量解决维度灾难问题。通过复杂度分析和对比实验验证模型性能。

研究结果: 实验表明，分箱半参数贝叶斯网络在结构学习和对数似然估计上与未分箱版本无显著差异，但速度显著提升。

研究结论: 分箱半参数贝叶斯网络是一种高效且可靠的替代方案，适用于大规模数据建模。

中文摘要: 本文介绍了一种新型的半参数概率模型，利用数据分箱技术降低非参数分布中核密度估计的计算成本。针对分箱半参数贝叶斯网络，开发了两种新的条件概率分布：稀疏分箱核密度估计和傅里叶核密度估计。这两种分布通过稀疏张量和限制父节点数量，解决了分箱模型常见的维度灾难问题。为评估该模型，我们进行了复杂度分析，并使用合成数据和UCI机器学习库中的数据集进行了多组对比实验。实验涵盖了不同的分箱规则、父节点限制、网格大小和实例数量，以全面评估模型行为。结果表明，分箱半参数贝叶斯网络在结构学习和对数似然估计上与半参数贝叶斯网络无显著差异，但速度显著提升。因此，分箱半参数贝叶斯网络是一种高效且可靠的替代方案。

</details>


### [230] [TROFI: Trajectory-Ranked Offline Inverse Reinforcement Learning](https://arxiv.org/abs/2506.22008)
**中文标题：TROFI：基于轨迹排序的离线逆强化学习**

*Alessandro Sestini,Joakim Bergdahl,Konrad Tollmar,Andrew D. Bagdanov,Linus Gisslén*

主要分类: cs.LG

摘要简述: 本文提出了一种名为TROFI的离线逆强化学习方法，通过从人类偏好中学习奖励函数，无需预定义奖励即可训练策略，并在实验中表现优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 在离线强化学习中，通常需要预定义的奖励函数来标注数据集，但在实际应用中（如游戏开发），奖励函数可能不可用。本文旨在解决这一问题，提出一种无需预定义奖励函数的离线学习方法。

研究方法: TROFI通过从人类偏好中学习奖励函数，并用其标注原始数据集，从而训练策略。与其他方法不同，TROFI不依赖最优轨迹。

研究结果: 在D4RL基准测试中，TROFI表现优于基线方法，并与使用真实奖励训练的策略相当。在3D游戏环境中的实验进一步验证了其有效性。研究还表明，奖励函数的设计对值函数与未来折扣奖励的对齐至关重要。

研究结论: TROFI是一种有效的离线逆强化学习方法，无需预定义奖励函数即可训练策略，且性能优越。奖励函数的设计对模型性能具有重要影响。

中文摘要: 在离线强化学习中，智能体仅使用固定存储的转换数据集进行训练，但这些数据需要由奖励函数标注。然而，在实际应用（如游戏开发）中，奖励函数并不总是可用。本文提出了一种名为TROFI的离线逆强化学习方法，无需预定义奖励函数即可有效学习策略。TROFI首先从人类偏好中学习奖励函数，然后用其标注原始数据集以训练策略。与其他方法不同，TROFI不依赖最优轨迹。在D4RL基准测试中，TROFI表现优于基线方法，并与使用真实奖励训练的策略相当。此外，我们在3D游戏环境中验证了该方法的有效性。对奖励模型的研究表明，奖励函数的设计至关重要：我们证明，为了确保值函数与实际未来折扣奖励的对齐，必须设计易于学习且高效的奖励函数。

</details>


### [231] [GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling](https://arxiv.org/abs/2506.22049)
**中文标题：GPAS：通过梯度保持激活缩放加速大型语言模型预训练的收敛**

*Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Yin Lu,Can Yang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GPAS（梯度保持激活缩放）的简单技术，用于解决Pre-LN Transformer架构中激活方差指数增长的问题。GPAS通过缩放中间激活值但保持梯度不变，显著提升了模型性能，并在多种架构中表现出广泛适用性。


<details>
  <summary>详细信息</summary>
研究动机: 现代大型语言模型（如LLaMA、Qwen和DeepSeek系列）主要采用Pre-LN Transformer架构，但其在预训练过程中存在激活方差指数增长的问题，导致残差路径主导子层输出，限制了深层学习能力。本文旨在解决这一问题。

研究方法: GPAS是一种梯度保持激活缩放技术，通过缩放中间激活值但保持梯度不变，避免梯度消失问题，同时保留激活中的信息。该方法可与现有技术结合使用。

研究结果: 在71M到1B不同规模的模型上进行的实验表明，GPAS能够带来一致的性能提升。此外，GPAS还能改善其他架构（如Sandwich-LN和DeepNorm）的训练动态。

研究结论: GPAS是一种简单有效的技术，能够显著提升Pre-LN Transformer及其他架构的性能，具有广泛的适用性和潜力。

中文摘要: 现代大型语言模型（如LLaMA、Qwen和DeepSeek系列）主要采用Pre-LN Transformer架构。尽管该架构在预训练中表现稳定且可扩展至大规模模型，但其存在激活方差随层数指数增长的问题，导致残差路径主导子层输出，限制了深层学习能力。为解决这一问题，我们提出了梯度保持激活缩放（GPAS），这是一种可与现有方法结合使用的简单技术。GPAS通过缩放中间激活值但保持梯度不变，既保留了激活中的信息，又避免了梯度消失问题。在71M到1B不同规模的模型上进行的大量实验表明，GPAS能够带来一致的性能提升。此外，GPAS还能改善其他架构（如Sandwich-LN和DeepNorm）的训练动态，展示了其广泛的适用性和潜力。

</details>


### [232] [UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting](https://arxiv.org/abs/2506.22039)
**中文标题：UniCA：将时间序列基础模型适配到通用协变量感知预测任务**

*Lu Han,Yu Liu,Qiwen Deng,Jian Jiang,Yinbo Sun,Zhe Yu,Binfeng Wang,Xingyu Lu,Lintao Ma,Han-Jia Ye,De-Chuan Zhan*

主要分类: cs.LG

摘要简述: UniCA框架通过协变量同质化和统一注意力融合机制，将时间序列基础模型（TSFMs）扩展到通用协变量感知预测任务中，支持异构协变量（如分类变量和多模态数据）的高效利用。


<details>
  <summary>详细信息</summary>
研究动机: 当前时间序列基础模型（TSFMs）主要针对实值序列设计，难以处理包含异构协变量（如分类变量和多模态数据）的通用预测任务。UniCA旨在填补这一空白，提升TSFMs在复杂协变量场景下的适应性。

研究方法: UniCA首先通过协变量同质化将异构协变量转换为同质序列表示，然后利用基于注意力的统一融合机制将这些表示与时间序列基础模型结合，实现高效的信息融合。

研究结果: 在多个单模态和多模态协变量感知预测基准测试中，UniCA表现优异，证明了其在复杂协变量场景下的适应性和泛化能力。

研究结论: UniCA为时间序列基础模型在通用协变量感知预测任务中的应用提供了有效框架，展示了其在真实世界预测场景中的潜力。

中文摘要: 时间序列基础模型（TSFMs）通过大规模预训练取得了显著成功，但其设计主要针对实值序列，限制了其在涉及多样化且通常异构的协变量（如分类变量和多模态数据）的通用预测任务中的应用。这些协变量通常是任务特定的，难以在预训练中利用。为解决这一问题，我们提出了统一协变量适配（UniCA）框架，以桥接TSFMs与通用协变量感知预测任务。UniCA首先通过协变量同质化将异构协变量转换为高级同质序列表示，然后通过统一的基于注意力的融合机制进行融合。UniCA兼容并适用于同质和异构协变量的适配，在保留TSFMs泛化能力的同时整合额外协变量信息。在多个单模态和多模态协变量感知预测基准测试中的广泛实验证明了UniCA的优越性，凸显了协变量感知TSFM适配在真实世界预测场景中的潜力。代码发布于https://github.com/hanlu-nju/UniCA。

</details>


### [233] [Exploring Modularity of Agentic Systems for Drug Discovery](https://arxiv.org/abs/2506.22189)
**中文标题：探索药物发现中智能系统的模块化**

*Laura van Weesep,Samuel Genheden,Ola Engkvist,Jens Sjölund*

主要分类: cs.LG

摘要简述: 本研究探讨了基于大型语言模型（LLM）的智能系统在药物发现领域的模块化问题，比较了不同LLM的性能以及工具调用代理与代码生成代理的效果。结果显示Claude-3.5-Sonnet、Claude-3.7-Sonnet和GPT-4o表现更优，且代码生成代理通常优于工具调用代理，但结果因问题和模型而异。研究强调了进一步研究智能系统模块化的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）和智能系统为加速药物发现和设计提供了新机遇，但其模块化问题（如LLM的可替换性）在药物发现领域尚未得到充分研究。本研究旨在填补这一空白。

研究方法: 研究比较了不同LLM（如Claude-3.5-Sonnet、Claude-3.7-Sonnet、GPT-4o、Llama-3.1-8B等）的性能，并评估了工具调用代理与代码生成代理在药物发现任务中的效果。通过LLM作为评判标准，分析了模型在化学和药物发现工具编排中的表现。

研究结果: Claude-3.5-Sonnet、Claude-3.7-Sonnet和GPT-4o的表现优于其他模型（如Llama-3.1-8B、GPT-3.5-Turbo等）。代码生成代理平均表现优于工具调用代理，但结果因具体问题和模型而异。系统提示的替换效果也依赖于问题和模型。

研究结论: 研究强调了智能系统模块化的重要性，指出在药物发现领域替换语言模型时需考虑提示重新设计。未来需进一步研究模块化以实现稳定且可扩展的解决方案。

中文摘要: 大型语言模型（LLM）和智能系统为加速药物发现和设计提供了令人兴奋的机会。本研究批判性地探讨了基于LLM的智能系统在药物发现中的模块化问题，即智能系统的部分组件（如LLM）是否可替换，这一主题在药物发现应用中尚未得到充分关注。我们比较了不同大型语言模型（LLM）的性能，以及工具调用代理与代码生成代理在该领域的有效性。通过案例研究，使用LLM作为评判标准比较了化学和药物发现工具编排的性能，结果显示Claude-3.5-Sonnet、Claude-3.7-Sonnet和GPT-4o的表现优于其他语言模型（如Llama-3.1-8B、Llama-3.1-70B、GPT-3.5-Turbo和Nova-Micro）。尽管我们确认代码生成代理平均表现优于工具调用代理，但结果表明这种优势高度依赖于具体问题和模型。此外，替换系统提示的效果也依赖于所提问题和所用模型，强调了即使在这一特定领域，替换语言模型时也需考虑提示重新设计。本研究凸显了进一步研究智能系统模块化的必要性，以开发稳定且可扩展的解决方案来解决现实问题。

</details>


### [234] [Transformers are Graph Neural Networks](https://arxiv.org/abs/2506.22084)
**中文标题：Transformer是图神经网络**

*Chaitanya K. Joshi*

主要分类: cs.LG

摘要简述: 本文揭示了Transformer架构与图神经网络（GNNs）之间的联系，将Transformer视为在完全连接的令牌图上运行的消息传递GNN，其自注意力机制捕获令牌间的相对重要性，而位置编码则提供顺序或结构信息。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索Transformer架构与GNNs之间的数学联系，揭示Transformer在硬件效率上的优势，并说明其为何在当前硬件条件下表现优于传统GNNs。

研究方法: 方法是通过将Transformer的自注意力机制解释为消息传递GNN的操作，展示其在完全连接的令牌图上的表现，同时分析位置编码的作用。

研究结果: 结果表明，Transformer可以被视为一种高效的GNN变体，其密集矩阵操作在现代硬件上比稀疏消息传递更具优势。

研究结论: 结论指出，Transformer是当前硬件条件下表现优异的GNN实现，其数学本质与GNNs相通，但硬件适应性更强。

中文摘要: 我们建立了最初用于自然语言处理的Transformer架构与图神经网络（GNNs）之间的联系，展示了Transformer如何被视为在完全连接的令牌图上运行的消息传递GNN。自注意力机制捕获了所有令牌之间的相对重要性，而位置编码则提供了顺序或结构的提示。因此，Transformer是一种表达力强的集合处理网络，能够学习输入元素之间的关系，而不受先验图的限制。尽管与GNNs存在数学联系，但Transformer通过密集矩阵操作实现，这些操作在现代硬件上比稀疏消息传递效率更高。这一视角表明，Transformer是目前在硬件适应性上胜出的GNN。

</details>


### [235] [Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling](https://arxiv.org/abs/2506.22304)
**中文标题：利用Koopman算子展开生成流：快速且可解释的采样**

*Erkan Turan,Aristotelis Siozopoulos,Maks Ovsjanikov*

主要分类: cs.LG

摘要简述: 本文提出了一种基于Koopman算子的方法，用于加速条件流匹配（CFM）的生成过程，并通过线性化动态实现可解释性。该方法在多个数据集上验证了其高效性和结构分析能力。


<details>
  <summary>详细信息</summary>
研究动机: 条件流匹配（CFM）虽然提供了一种无模拟的生成模型训练框架，但其采样过程依赖于非线性ODE的数值求解，计算成本高且难以解释。本文旨在通过Koopman算子理论加速CFM并提升其动态的可解释性。

研究方法: 提出了一种无解码器的Koopman-CFM架构，通过学习一个嵌入空间，将生成动态线性化，从而实现闭式一步采样。该方法利用矩阵指数实现快速采样，并通过Koopman生成器的谱特性分析生成行为。

研究结果: 在2D数据集和真实基准（MNIST、F-MNIST、TFD）上验证了方法的有效性，显著提升了采样速度。Koopman生成器的谱特性为生成行为提供了分析工具，如时间缩放、模式稳定性和潜在空间分解。

研究结论: 通过结合采样效率和解析结构，Koopman增强的流匹配为快速且可解释的生成建模提供了潜在方向。

中文摘要: 条件流匹配（CFM）为训练连续时间生成模型提供了一个无模拟的框架，弥合了扩散和基于流的方法。然而，CFM的采样仍依赖于非线性ODE的数值求解，计算成本高且难以解释。最近的替代方法通过轨迹拉直、小批量耦合或蒸馏解决了采样速度问题，但这些方法通常未能揭示生成过程的底层结构。本文提出通过整合Koopman算子理论来加速CFM并引入其动态的可解释表示。Koopman算子理论将非线性流建模为学习观测空间中的线性演化。我们提出了一种无解码器的Koopman-CFM架构，通过学习一个嵌入空间，使生成动态线性化，从而实现闭式一步采样（通过矩阵指数）。该方法在2D数据集和真实基准（MNIST、F-MNIST、TFD）上显著提升了采样速度。与先前方法不同，我们的方法生成了一个结构良好的Koopman生成器，其谱特性（如特征值和特征函数）为分析生成行为（如时间缩放、模式稳定性和Koopman潜在空间分解）提供了原则性工具。通过结合采样效率和解析结构，Koopman增强的流匹配为快速且可解释的生成建模迈出了潜在的一步。

</details>


### [236] [Learning to Solve Multi-Objective Routing Problems on Multigraphs](https://arxiv.org/abs/2506.22095)
**中文标题：学习解决多图上的多目标路由问题**

*Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár*

主要分类: cs.LG

摘要简述: 本文提出两种神经网络方法解决多目标多图路由问题，实验验证其在TSP和CVRP等任务中的优异表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多图路由问题在实际中具有高度相关性，但现有研究多集中于单目标或简单图场景，多目标多图路由问题被忽视。本文旨在填补这一空白。

研究方法: 第一种方法直接在多图上通过自回归选择边完成路径；第二种方法先将多图修剪为简单图再构建路径。

研究结果: 实验表明，两种方法在多种问题（如TSP和CVRP）中均表现优异。

研究结论: 本文提出的方法为多目标多图路由问题提供了有效解决方案，展示了神经网络在此类问题中的潜力。

中文摘要: 近年来，基于学习的路由方法在单目标和多目标场景中受到广泛关注。然而，多图设置（即目的地间存在多条具有不同属性的路径）尽管具有高度实际意义，却鲜有研究。本文提出两种神经网络方法来解决多图上的多目标路由问题。第一种方法直接在多图上通过自回归选择边直至完成路径；第二种方法则先将多图修剪为简单图，再构建路径。实验验证了两种模型在多种问题（如旅行商问题TSP和容量约束车辆路径问题CVRP）中的优异表现。

</details>


### [237] [Projected Compression: Trainable Projection for Efficient Transformer Compression](https://arxiv.org/abs/2506.22255)
**中文标题：投影压缩：用于高效Transformer压缩的可训练投影**

*Maciej Stefaniak,Michał Krutul,Jan Małaśnicki,Maciej Pióro,Jakub Krajewski,Sebastian Jaszczur,Marek Cygan,Kamil Adamczewski,Jan Ludziejewski*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“投影压缩”的新型模型压缩技术，通过训练可学习的投影模块减少模型权重，同时保持原始参数的可访问性，最终合并为低维矩阵，显著降低模型大小且不增加计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型规模的不断增大，虽然性能提升，但推理时间和计算需求也随之增加。因此，研究如何减少模型大小成为热点。本文旨在解决这一问题，提出一种高效的模型压缩方法。

研究方法: 首先训练额外的可学习投影权重，保留对原始模型参数的访问权；随后将这些投影合并为低维矩阵，生成一个尺寸更小的标准Transformer模型。该方法在FLOPs上与基础模型的单令牌计算步骤保持一致。

研究结果: 实验结果表明，投影压缩在高质量模型上优于硬剪枝和再训练方法，且性能差距随令牌数量增加而扩大。

研究结论: 投影压缩是一种高效的模型压缩技术，能够在减少模型大小的同时保持计算效率，适用于大规模语言模型。

中文摘要: 大型语言模型的规模不断扩大以提高性能，但这也导致了更长的推理时间和更高的计算需求。因此，减少模型大小的方法受到越来越多的关注。为解决这一问题，我们提出了一种名为“投影压缩”的新型模型压缩技术，通过利用投影模块减少模型权重。具体而言，我们首先训练额外的可学习投影权重，并保留对原始模型参数的访问权；随后将这些投影合并为低维矩阵，生成一个尺寸更小的标准Transformer模型。与需要额外计算开销的其他方法不同，我们的方法在FLOPs上与基础模型的单令牌计算步骤保持一致。实验结果表明，投影压缩在高质量模型上优于可比的硬剪枝和再训练方法，且性能差距随令牌数量增加而扩大。

</details>


### [238] [EFRame: Deeper Reasoning via Exploration-Filtering-Replay Reinforcement Learning Framework](https://arxiv.org/abs/2506.22200)
**中文标题：EFRame：通过探索-过滤-回放强化学习框架实现更深层次的推理**

*Chen Wang,Lai Wei,Yanzhi Zhang,Chenyang Shao,Zedong Dan,Weiran Huang,Yue Wang,Yuzhi Zhang*

主要分类: cs.LG

摘要简述: EFRame是一个通过探索-过滤-回放增强GRPO的强化学习框架，显著提升了复杂推理任务的性能和训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管GRPO降低了强化学习的计算成本，但其探索能力有限、样本效率低且不稳定，限制了在复杂推理任务中的表现。EFRame旨在解决这些问题。

研究方法: EFRame通过额外探索高质量轨迹、在线过滤低质量样本以减少噪声和方差，并利用经验回放重复利用稀有但信息丰富的样本，构建了一个完整且稳定的学习循环。

研究结果: 实验表明，EFRame不仅提高了训练的鲁棒性和效率，还解锁了GRPO无法实现的更深层次推理能力，同时支持对训练样本的细粒度分类分析。

研究结论: EFRame通过系统性地增强GRPO，显著提升了强化学习在复杂推理任务中的表现，为样本贡献分析提供了新视角。

中文摘要: 近期强化学习（RL）的进展显著提升了大型语言模型（LLMs）的推理能力。尽管GRPO作为PPO的高效变体降低了计算成本，但其探索能力有限、样本效率低且不稳定，限制了在复杂推理任务中的表现。为解决这些问题，我们提出了EFRame，一个探索-过滤-回放框架，从三个关键维度系统性地增强GRPO。EFRame通过额外探索高质量轨迹、在线过滤低质量样本以减少噪声和方差，并利用经验回放重复利用稀有但信息丰富的样本，构建了一个完整且稳定的学习循环。我们在多个推理基准上的实验表明，EFRame不仅提高了训练的鲁棒性和效率，还解锁了GRPO无法实现的更深层次推理能力。此外，EFRame支持对训练样本的细粒度分类，为分析不同类型样本在RL学习过程中的贡献提供了新视角。代码已开源：https://github.com/597358816/EFRame。

</details>


### [239] [Probabilistic Optimality for Inference-time Scaling](https://arxiv.org/abs/2506.22376)
**中文标题：推理时间缩放的概率最优性**

*Youkang Wang,Jian Wang,Rubing Chen,Xiao-Yong Wei,Qing Li*

主要分类: cs.LG

摘要简述: 本文提出了一种基于概率框架的推理时间缩放优化方法，通过理论推导和动态采样算法，显著减少了计算开销，同时保持或超越了现有推理性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大语言模型推理时间缩放方法多依赖启发式策略，缺乏理论基础。本文旨在填补这一空白，提出一种基于概率的优化框架，为高效推理提供理论指导。

研究方法: 本文提出了一种概率框架，假设并行样本独立同分布，并推导了达到目标性能所需样本数的理论下界。基于此，开发了动态采样算法OptScale，利用语言模型预测器估计先验参数，动态决定最小采样数。

研究结果: 在数学推理基准测试（MATH-500、GSM8K、AIME和AMC）中，OptScale显著减少了采样开销，同时保持或优于现有推理性能。

研究结论: 本文为推理时间缩放提供了理论基础和实用算法，解决了大语言模型在复杂推理任务中高效部署的关键问题。

中文摘要: 推理时间缩放已成为提升大语言模型（LLMs）推理性能的强大技术。然而，现有方法多依赖启发式并行采样策略，缺乏理论基础。为填补这一空白，我们提出了一种概率框架，在假设并行样本独立同分布（i.i.d.）且Best-of-N选择策略服从可估计概率分布的条件下，形式化了推理时间缩放的最优性。在此框架下，我们推导了达到目标性能所需样本数的理论下界，为计算高效缩放提供了首个理论指导。基于这一见解，我们开发了OptScale算法，动态确定最优采样响应数。OptScale利用语言模型预测器估计先验参数，决定满足预设性能阈值和置信水平的最小样本数。在数学推理基准测试（包括MATH-500、GSM8K、AIME和AMC）上的大量实验表明，OptScale显著减少了采样开销，同时保持或优于现有推理性能。我们的工作为推理时间缩放提供了理论基础和实用解决方案，解决了LLMs在复杂推理任务中高效部署的关键问题。

</details>


### [240] [CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks](https://arxiv.org/abs/2506.22299)
**中文标题：CoATA：图神经网络中拓扑与属性的有效联合增强**

*Tao Liu,Longlong Lin,Yunfeng Yu,Xi Ou,Youan Zhang,Zhiqiu Ye,Tao Jia*

主要分类: cs.LG

摘要简述: CoATA提出了一种双通道图神经网络框架，通过联合增强拓扑结构和节点属性，并利用对比学习优化二者关系，显著提升了图神经网络的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的图数据常存在噪声和不完整性，现有方法通常仅从单一维度（拓扑结构或节点属性）进行增强，忽略了二者之间的深层交互。CoATA旨在填补这一空白。

研究方法: CoATA首先通过传播结构信号丰富和去噪节点属性，随后将增强后的属性空间投影到节点-属性二分图中以优化拓扑结构。最后引入对比学习，通过原型对齐和一致性约束实现增强图与原图的相互校正。

研究结果: 在七个基准数据集上的实验表明，CoATA优于十一种现有方法，验证了其在捕捉拓扑与属性协同关系上的有效性。

研究结论: CoATA通过联合增强拓扑和属性，并利用对比学习优化二者关系，显著提升了图神经网络的性能，为处理噪声和不完整图数据提供了新思路。

中文摘要: 图神经网络（GNNs）因其卓越的图表示学习能力而受到广泛关注。然而，现实世界中的图通常存在显著的噪声和不完整性，严重影响了GNNs的性能。现有方法通常通过单维度增强（仅优化拓扑结构或扰动节点属性）来解决这一问题，从而忽略了二者之间的深层交互。为填补这一空白，本文提出了CoATA，一种专为拓扑与属性联合增强设计的双通道GNN框架。具体而言，CoATA首先通过传播结构信号丰富和去噪节点属性，随后将增强后的属性空间投影到节点-属性二分图中以进一步优化或重构底层结构。接着，CoATA引入对比学习，利用原型对齐和一致性约束促进增强图与原图之间的相互校正。最后，在七个基准数据集上的大量实验表明，所提出的CoATA优于十一种最先进的基线方法，展示了其在捕捉拓扑与属性协同关系上的有效性。

</details>


### [241] [Less Greedy Equivalence Search](https://arxiv.org/abs/2506.22331)
**中文标题：更少贪婪的等价搜索**

*Adiba Ejaz,Elias Bareinboim*

主要分类: cs.LG

摘要简述: 本文提出了一种改进的因果发现算法LGES，通过优化贪婪步骤减少计算成本和样本误差，同时支持先验假设和数据修正，显著提升了速度和准确性。


<details>
  <summary>详细信息</summary>
研究动机: GES算法在因果发现中存在计算成本高和有限样本准确性不足的问题，本文旨在通过改进算法部分解决这些局限性。

研究方法: LGES算法通过避免在条件独立变量间插入边来优化贪婪步骤，同时支持先验假设和数据修正，并能利用干预数据优化观测等价类。

研究结果: 实验表明，LGES在速度、准确性和对错误假设的鲁棒性上均优于GES及其他基线方法，速度提升高达10倍。

研究结论: LGES在理论和实验中均表现出色，能够高效准确地恢复真实等价类，适用于观测和干预数据。

中文摘要: 贪婪等价搜索（GES）是一种经典的基于分数的因果发现算法，能够从观测数据中恢复描述数据的马尔可夫等价类。然而，它在实践中面临计算成本和有限样本准确性两大挑战。本文提出了一种改进算法——更少贪婪的等价搜索（LGES），在保留理论保证的同时部分解决了这些问题。LGES通过优化贪婪步骤，避免在条件独立变量间插入边，从而实现了高达10倍的速度提升和结构误差的显著降低。此外，LGES能够利用先验假设指导搜索，并在数据矛盾时修正这些假设。最后，LGES还能利用干预数据优化学习的观测等价类。我们证明，即使在先验假设错误的情况下，LGES也能从观测和干预数据中恢复真实等价类。实验表明，LGES在速度、准确性和对错误假设的鲁棒性上均优于GES及其他基线方法。代码已开源：https://github.com/CausalAILab/lges。

</details>


### [242] [A Framework for Multi-source Privacy Preserving Epidemic Analysis](https://arxiv.org/abs/2506.22342)
**中文标题：多源隐私保护流行病分析框架**

*Zihan Guan,Zhiyuan Zhao,Fengwei Tian,Dung Nguyen,Payel Bhattacharjee,Ravi Tandon,B. Aditya Prakash,Anil Vullikanti*

主要分类: cs.LG

摘要简述: 本文提出了一种结合深度学习和流行病模型的多源隐私保护流行病分析框架，能够在差分隐私保护下利用敏感数据进行流行病预测和传播机制建模。


<details>
  <summary>详细信息</summary>
研究动机: 多样化的数据集在流行病学和公共卫生分析中具有重要价值，但部分数据敏感且需隐私保护。差分隐私（DP）因其强大保障成为标准。本文旨在开发一个框架，整合多源数据（包括DP保护数据）进行流行病分析和预测。

研究方法: 开发了一个结合深度学习和流行病模型的框架，利用多源数据（包括差分隐私保护数据）进行流行病预测和传播机制建模。通过合成金融数据集验证了框架的有效性。

研究结果: 实验表明，即使在差分隐私保护下，合成金融数据集仍能显著提升流行病预测和传播机制建模的准确性。

研究结论: 本文提出的框架成功整合了多源隐私保护数据，为流行病分析和预测提供了新方法，展示了差分隐私保护下敏感数据的实用价值。

中文摘要: 目前普遍认为，多样化数据集在关键流行病学和公共卫生分析中具有重要价值，例如预测和即时预测、流行病模型开发、干预措施评估与设计以及资源分配。其中部分数据较为敏感，需要充分的隐私保护。隐私保护模型众多，但差分隐私（DP）因其强大的保障能力且无需对对手建模，已成为事实标准。本文开发了一个框架，整合深度学习和流行病模型，同时进行流行病预测和传播机制建模，并利用多源数据（包括部分具有DP保障的数据）进行分析。我们通过一个现实但合成的金融数据集（具有DP保障）验证了该框架；此类数据此前未用于此类流行病分析。结果表明，即使在DP保障下，该数据集仍能显著提升流行病预测和传播机制建模的价值。

</details>


### [243] [Sheaf-Based Decentralized Multimodal Learning for Next-Generation Wireless Communication Systems](https://arxiv.org/abs/2506.22374)
**中文标题：基于层理论的去中心化多模态学习在下一代无线通信系统中的应用**

*Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis*

主要分类: cs.LG

摘要简述: 本文提出了一种基于层理论的去中心化多模态学习框架Sheaf-DMFL，通过增强多模态设备间的协作，解决了传统联邦学习在多模态数据和异构设备能力下的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 大规模通信系统中，复杂的场景需要边缘设备通过多模态数据协作提升环境理解和决策准确性。传统联邦学习仅支持单模态数据且无法利用多模态信息，限制了其在现实场景中的应用。

研究方法: 提出Sheaf-DMFL框架，每个客户端为不同模态配备本地特征编码器，输出通过任务特定层整合。利用层理论捕捉任务层间的内在关联，并进一步提出Sheaf-DMFL-Att算法，通过注意力机制增强模态间相关性学习。

研究结果: 在真实世界的链路阻塞预测和毫米波波束成形场景中，Sheaf-DMFL-Att表现出优越性能，验证了其在异构无线通信系统中的有效性。

研究结论: Sheaf-DMFL框架通过层理论和注意力机制，显著提升了多模态设备协作能力，为下一代无线通信系统提供了高效的学习解决方案。

中文摘要: 在大规模通信系统中，日益复杂的场景要求边缘设备通过收集多模态传感数据实现更智能的协作，以提升环境理解和决策准确性。然而，传统联邦学习（FL）算法通常仅考虑单模态数据集，要求相同模型架构，且无法利用多模态数据中的丰富信息，限制了其在现实多样化模态和异构客户端能力场景中的应用。为解决这一问题，我们提出Sheaf-DMFL，一种基于层理论的去中心化多模态学习框架，通过层结构增强多模态设备间的协作。具体而言，每个客户端为其不同模态配备一组本地特征编码器，其输出在通过任务特定层前进行拼接。相同模态的编码器在客户端间协作训练，同时我们通过层结构捕捉任务层间的内在相关性。为进一步增强学习能力，我们提出Sheaf-DMFL-Att算法，通过客户端内的注意力机制捕捉不同模态间的相关性。我们提供了Sheaf-DMFL-Att的严格收敛分析，确立了其理论保证。在真实世界的链路阻塞预测和毫米波波束成形场景中的大量仿真实验表明，所提算法在异构无线通信系统中具有显著优越性。

</details>


### [244] [Towards Distributed Neural Architectures](https://arxiv.org/abs/2506.22389)
**中文标题：迈向分布式神经架构**

*Aditya Cowsik,Tianyu He,Andrey Gromov*

主要分类: cs.LG

摘要简述: 本文提出并训练了分布式神经架构（DNA），在视觉和语言领域展示了其竞争力。DNA通过动态路由和模块化设计，实现了计算和通信模式的学习，并在效率和参数共享方面表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索一种更灵活的神经网络架构，能够根据输入内容动态调整计算路径，同时提升计算效率和参数利用率。

研究方法: DNA通过初始化一个包含多种模块（如Transformer、MLP、注意力等）和路由器的原型架构，允许输入标记（或图像块）以任意顺序通过模块。其计算和通信模式通过端到端训练学习，并可优化为满足效率或负载均衡等需求。

研究结果: 实验表明，DNA在视觉和语言任务中与密集基线模型表现相当，并能从数据中学习计算效率和参数共享。此外，模型路径分布符合幂律，部分模块组表现出专业化特征。

研究结论: DNA展示了动态计算路径和模块化设计的潜力，能够以可解释的方式分配计算资源和参数，为未来神经网络架构设计提供了新思路。

中文摘要: 我们提出并训练了分布式神经架构（DNA），应用于视觉和语言领域。DNA通过初始化一个包含多种模块（如Transformer、MLP、注意力等）和路由器的原型架构，允许任何标记（或图像块）以任意顺序通过模块。DNA是稀疏方法（如专家混合、深度混合、参数共享等）的自然扩展。DNA模块的计算和通信模式在训练过程中端到端学习，并依赖于每个标记（或图像块）的内容和上下文。这些模式可以通过优化目标（如计算/内存效率或负载均衡）进一步调整。实验表明：（i）训练后的DNA在两种领域中与密集基线模型表现相当；（ii）计算效率和参数共享可以从数据中学习。此外，我们分析了训练后DNA中涌现的连接和计算模式，发现标记通过模型的路径分布符合幂律，部分路径（或模块组）表现出专业化特征。最后，我们展示了模型以可解释的方式分配计算和活跃参数的能力。

</details>


### [245] [Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis](https://arxiv.org/abs/2506.22393)
**中文标题：医学时间序列分析中基于多视角对比学习的鲁棒领域适应方法**

*YongKyung Oh,Alex Bui*

主要分类: cs.LG

摘要简述: 本文提出了一种基于多视角对比学习的框架，用于解决医学时间序列分析中的跨领域适应问题，通过整合时间模式、导数动态和频域特征，显著提升了模型的鲁棒性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 医学时间序列分析中，跨领域适应面临复杂的时间依赖性和动态分布变化的挑战。现有方法通常关注孤立的特征表示，难以充分捕捉复杂的时间动态，限制了模型的适应能力。

研究方法: 提出了一种多视角对比学习框架，利用独立编码器和分层融合机制，整合时间模式、导数动态和频域特征，学习跨领域可迁移的特征不变表示。

研究结果: 在多种医学数据集（如EEG、ECG和EMG）上的实验表明，该方法在迁移学习任务中显著优于现有最先进方法。

研究结论: 该框架通过提升模型的鲁棒性和泛化能力，为在多样化医疗环境中部署可靠的AI系统提供了实用途径。

中文摘要: 在医学时间序列中，跨领域适应机器学习模型仍面临复杂时间依赖性和动态分布变化的挑战。现有方法通常关注孤立特征表示，难以充分捕捉复杂时间动态，限制了鲁棒领域适应的能力。本文提出了一种新颖框架，利用多视角对比学习整合时间模式、导数动态和频域特征。该方法通过独立编码器和分层融合机制，学习跨领域可迁移且保持时间一致性的特征不变表示。在多种医学数据集（如EEG、ECG和EMG）上的实验表明，该方法在迁移学习任务中显著优于现有最先进方法。通过提升模型的鲁棒性和泛化能力，该框架为多样化医疗环境中部署可靠的AI系统提供了实用途径。

</details>


### [246] [CLoVE: Personalized Federated Learning through Clustering of Loss Vector Embeddings](https://arxiv.org/abs/2506.22427)
**中文标题：CLoVE：通过损失向量嵌入聚类实现个性化联邦学习**

*Randeep Bhatia,Nikos Papadis,Murali Kodialam,TV Lakshman,Sayak Chakrabarty*

主要分类: cs.LG

摘要简述: 本文提出了一种名为CLoVE的新型聚类联邦学习算法，通过分析客户端损失向量嵌入来识别数据分布相似的客户端群组，并优化群组特定模型。CLoVE简单、适用于监督和无监督场景，且无需最优模型初始化，实验证明其在多种非独立同分布设置下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 在聚类联邦学习（CFL）中，客户端根据数据分布自然分组，但识别这些群组具有挑战性。现有方法通常需要复杂的初始化或假设，限制了其在实际应用中的鲁棒性和适用性。CLoVE旨在通过损失向量嵌入简化群组识别，并提升模型性能。

研究方法: CLoVE通过分析客户端模型损失值生成嵌入向量，利用同一群组内客户端损失相似、不同群组损失差异的特性，迭代分离客户端群组，并通过联邦聚合优化群组特定模型。该方法无需最优初始化，适用于监督和无监督任务。

研究结果: 理论分析表明，CLoVE在单轮训练中能以高概率准确恢复群组，并在线性设置下以指数速度收敛到最优模型。实验显示，CLoVE在多种非独立同分布数据集上仅需少量训练轮次即可实现高精度群组恢复和最优模型性能。

研究结论: CLoVE是一种简单高效的聚类联邦学习算法，适用于广泛的实际应用场景，显著提升了群组识别和模型优化的性能。

中文摘要: 我们提出了CLoVE（损失向量嵌入聚类），一种用于聚类联邦学习（CFL）的新型算法。在CFL中，客户端根据其数据分布自然分组，但识别这些群组具有挑战性，因为客户端分配未知。CLoVE利用从客户端数据模型损失中提取的嵌入向量，并通过同一群组内客户端损失相似、不同群组损失差异的特性，迭代识别和分离不同群组的客户端，并通过联邦聚合优化群组特定模型。CLoVE相较于现有CFL算法的优势在于：（1）其简单性，（2）适用于监督和无监督场景，（3）无需接近最优的模型初始化，使其更具鲁棒性且更适合实际应用。我们建立了理论收敛界限，表明CLoVE在单轮训练中可以高概率准确恢复群组，并在线性设置下以指数速度收敛到最优模型。我们通过多种CFL和通用个性化联邦学习（PFL）算法的全面实验比较，展示了CLoVE在多种非独立同分布设置下仅需少量训练轮次即可实现高精度群组恢复和最优模型性能。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [247] [RiverEcho: Real-Time Interactive Digital System for Ancient Yellow River Culture](https://arxiv.org/abs/2506.21865)
**中文标题：RiverEcho：黄河古文化的实时交互数字系统**

*Haofeng Wang,Yilin Guo,Zehao Li,Tong Yue,Yizong Wang,Enci Zhang,Rongqun Lin,Feng Gao,Shiqi Wang,Siwei Ma*

主要分类: cs.MM

摘要简述: 本文介绍了RiverEcho，一个基于大语言模型和黄河文化知识库的实时交互系统，通过数字人语音回应查询，旨在保护和传承黄河文化。


<details>
  <summary>详细信息</summary>
研究动机: 黄河是中国的母亲河，其文化是人类艺术史的重要组成部分。为保护和传承黄河文化，作者开发了RiverEcho系统，通过技术手段提升文化传播效果。

研究方法: 作者构建了黄河文化知识库，结合检索增强生成（RAG）技术优化大语言模型的响应质量，并通过数字人语音交互实现实时查询。

研究结果: 实验表明，RAG技术显著提升了大语言模型的响应质量，系统能够生成更专业且信息丰富的回答。

研究结论: RiverEcho不仅丰富了黄河文化的传播方式，还为用户提供了更深层次的文化体验。

中文摘要: 黄河是中国的母亲河，也是人类文明的摇篮。黄河古文化更是人类艺术史不可或缺的一部分。为保护和传承黄河古文化，我们设计了RiverEcho，一个基于大语言模型和黄河文化知识库的实时交互系统，通过数字人语音回应查询。具体而言，我们构建了一个专注于黄河古文化的知识库，包括历史文本的收集和处理流程。实验结果表明，利用检索增强生成（RAG）技术优化数据集显著提升了大语言模型的响应质量，使系统能够生成更专业且信息丰富的回答。我们的工作不仅丰富了黄河文化的传播方式，还为用户提供了更深层次的文化体验。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [248] [Autonomic Microservice Management via Agentic AI and MAPE-K Integration](https://arxiv.org/abs/2506.22185)
**中文标题：基于智能代理AI与MAPE-K集成的自主微服务管理**

*Matteo Esposito,Alexander Bakhtin,Noman Ahmad,Mikel Robredo,Ruoyu Su,Valentina Lenarduzzi,Davide Taibi*

主要分类: cs.SE

摘要简述: 本文提出了一种基于MAPE-K框架并结合智能代理AI的解决方案，用于实现微服务的自主异常检测与修复，以应对分布式系统管理的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 微服务虽提升了云计算的扩展性和独立部署能力，但其去中心化特性带来了安全和管理的难题，威胁系统稳定性。本文旨在解决这一问题。

研究方法: 采用MAPE-K框架，结合智能代理AI技术，实现微服务的自主异常检测与修复，提供可定制的行业解决方案。

研究结果: 该框架能有效提升系统稳定性、减少停机时间，并监控性能、弹性、安全等系统质量属性。

研究结论: 本文提出的框架为微服务管理提供了实用且可定制的解决方案，适用于行业实践与研究。

中文摘要: 尽管微服务通过提供无与伦比的可扩展性和独立部署能力正在革新云计算，但其去中心化特性带来了显著的安全和管理挑战，可能威胁系统稳定性。我们提出了一种基于MAPE-K的框架，利用智能代理AI实现自主异常检测与修复，以应对高度分布式系统管理的艰巨任务。该框架为维护稳健且安全的微服务提供了实用的行业解决方案。从业者和研究人员可以定制该框架，以增强系统稳定性、减少停机时间，并监控更广泛的系统质量属性，如系统性能水平、弹性、安全性和异常管理等。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [249] [On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling](https://arxiv.org/abs/2506.21874)
**中文标题：通过对抗性错误标注毒化文本到图像AI模型的可行性研究**

*Stanley Wu,Ronik Bhaskar,Anna Yoo Jeong Ha,Shawn Shan,Haitao Zheng,Ben Y. Zhao*

主要分类: cs.CR

摘要简述: 本文探讨了通过对抗性错误标注攻击视觉语言模型（VLMs）以毒化文本到图像生成模型训练管道的可行性。实验表明，VLMs易受对抗性扰动攻击，导致生成的图像被错误标注，从而在训练中引入“脏标签”样本，成功改变模型行为。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到图像生成模型依赖VLMs生成的高质量图像-标题对进行训练。然而，VLMs易受隐蔽的对抗性攻击，导致生成的标题错误。本文旨在研究这种攻击是否可用于毒化训练管道，从而影响文本到图像模型的性能。

研究方法: 通过向图像添加对抗性扰动，误导VLMs生成错误的标题，从而在训练数据中注入“脏标签”样本。实验评估了攻击的有效性及防御措施的局限性。

研究结果: 实验证明，VLMs对对抗性扰动高度敏感，攻击者可通过少量毒化样本显著改变文本到图像模型的行为。攻击在黑盒场景下对商业VLMs（如Google Vertex AI和Microsoft Azure）的成功率超过73%。

研究结论: 对抗性错误标注攻击对VLMs和文本到图像模型构成严重威胁，防御措施可能被适应性攻击者绕过，导致训练数据质量下降和开发成本增加。

中文摘要: 当前的文本到图像生成模型依赖于从互联网获取的数百万张图像进行训练，每张图像配有视觉语言模型（VLMs）生成的详细标题。这一训练环节为模型提供了大量高质量的图像-标题对。然而，近期研究表明，VLMs易受隐蔽的对抗性攻击，即通过向图像添加对抗性扰动误导VLMs生成错误标题。
  本文探讨了利用对抗性错误标注攻击VLMs以毒化文本到图像模型训练管道的可行性。实验表明，VLMs对对抗性扰动高度敏感，攻击者可生成看似无害但被VLMs错误标注的图像，从而在训练管道中注入强效的“脏标签”毒化样本，成功以少量样本改变模型行为。研究发现，尽管潜在防御措施可能有效，但适应性攻击者可针对性地绕过这些防御。这表明未来可能陷入一场“猫鼠游戏”，导致训练数据质量下降和文本到图像模型开发成本增加。最后，我们验证了这些攻击在现实场景中的有效性，即使针对商业VLMs（如Google Vertex AI和Microsoft Azure）的黑盒攻击，成功率仍超过73%。

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [250] [Simultaneously Fair Allocation of Indivisible Items Across Multiple Dimensions](https://arxiv.org/abs/2506.21727)
**中文标题：多维环境下不可分割物品的同时公平分配**

*Yasushi Kawase,Bodhayan Roy,Mohammad Azharuddin Sanpui*

主要分类: cs.GT

摘要简述: 本文研究了在多维环境下不可分割物品的公平分配问题，提出了弱和强同时无嫉妒分配的概念，并提供了相关理论界限和算法。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中许多场景（如云计算资源分配）需要基于多维度标准评估公平性，传统单维公平性概念无法满足需求，因此需要研究多维公平分配方法。

研究方法: 提出了弱同时无嫉妒分配（weak sEFc）和强同时无嫉妒分配（strong sEFc）两种放松的无嫉妒概念，并分析了其理论界限和算法实现。

研究结果: 给出了保证弱或强sEFc分配存在的参数c的上界和下界，这些界限与物品总数无关，并提出了检查分配存在性的算法，同时证明了弱sEF1和强sEF1分配存在性检查的NP难性。

研究结论: 多维公平分配问题在理论和实际中具有重要意义，提出的弱和强sEFc概念为解决此类问题提供了有效工具，但分配存在性的复杂性仍需进一步研究。

中文摘要: 本文研究了在多维环境下不可分割物品的公平分配问题，旨在解决复杂环境中基于多维度标准的公平性需求。例如，云计算资源需要根据CPU核心数、内存和网络带宽等多维度进行评估，传统单维公平性概念无法满足此类需求。为此，我们研究了两种放松的无嫉妒概念：弱同时无嫉妒分配（weak sEFc）和强同时无嫉妒分配（strong sEFc）。在弱概念下，对于每对代理和每个维度，任何嫉妒可以通过从被嫉妒代理的分配中移除不同的物品集来消除；而强版本要求移除同一物品集以在所有维度上同时消除嫉妒。我们给出了保证弱或强sEFc分配存在的参数c的上界和下界，这些界限与物品总数无关。此外，我们还提出了检查弱或强sEFc分配存在性的算法，并证明了弱sEF1和强sEF1分配存在性检查的NP难性。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [251] [Robust and Efficient Autoregressive Speech Synthesis with Dynamic Chunk-wise Prediction Policy](https://arxiv.org/abs/2506.22023)
**中文标题：基于动态分块预测策略的鲁棒高效自回归语音合成**

*Bohan Li,Zhihan Li,Haoran Wang,Hanglei Zhang,Yiwei Guo,Hankun Wang,Xie Chen,Kai Yu*

主要分类: cs.SD

摘要简述: 本文提出了一种动态分块自回归语音合成框架（DCAR），通过动态调整分块预测范围，显著提升了合成效率与鲁棒性，同时减少了序列长度依赖性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的自回归语音合成模型在处理长语音序列时面临帧间注意力不稳定、延迟高和合成质量下降的问题，限制了实时应用的可行性。

研究方法: DCAR框架引入了一种分块到帧的注意力机制，通过多令牌预测训练，动态调整分块预测范围，并使用轻量级模块实现高效合成。

研究结果: 实验表明，DCAR在测试集上显著优于传统模型，实现了72.27%的可懂度提升和2.61倍的推理加速。

研究结论: DCAR为下一代语音合成系统提供了高效且鲁棒的基础框架。

中文摘要: 近年来，自回归（AR）语言模型已成为语音合成领域的主流方法，具有表达力强和训练可扩展性高的特点。然而，传统的基于下一令牌预测的自回归语音合成模型在处理长语音序列时面临显著挑战。这些模型往往难以构建稳定的帧间注意力，导致延迟增加和合成质量下降，从而限制了其在实时应用中的可行性。为解决这些问题，我们提出了一种新颖的动态分块自回归合成框架（DCAR），旨在提升AR语音生成的效率和可懂度鲁棒性。DCAR通过多令牌预测训练引入了一种分块到帧的注意力机制，利用轻量级模块动态调整分块预测范围，显著减少了序列长度依赖性，同时保持了高合成质量。全面的实验评估表明，DCAR在测试集上显著优于传统的下一令牌预测模型，同时实现了72.27%的可懂度提升和2.61倍的推理加速。此外，我们通过全面分析支持其作为下一代语音合成系统的通用基础框架。

</details>


### [252] [Fine-Tuning MIDI-to-Audio Alignment using a Neural Network on Piano Roll and CQT Representations](https://arxiv.org/abs/2506.22237)
**中文标题：基于钢琴卷和CQT表示的神经网络微调MIDI与音频对齐方法**

*Sebastian Murgul,Moritz Reiser,Michael Heizmann,Christoph Seibert*

主要分类: cs.SD

摘要简述: 本文提出了一种基于神经网络的MIDI与音频对齐方法，通过结合钢琴卷和CQT表示，显著提升了对齐精度，优于传统DTW方法。


<details>
  <summary>详细信息</summary>
研究动机: 钢琴演奏录音与MIDI文件的对齐是音乐信息检索的重要任务，传统方法如动态时间规整（DTW）存在精度不足的问题。本文旨在通过神经网络提升对齐精度。

研究方法: 采用卷积循环神经网络（CRNN）架构，输入未对齐的钢琴卷和频谱图，输出对齐的钢琴卷。训练数据通过模拟人类演奏时序误差的增强MIDI文件生成。

研究结果: 实验表明，该方法比DTW方法对齐精度提升20%，且结合DTW与CRNN可进一步增强鲁棒性和一致性。

研究结论: 神经网络在MIDI与音频对齐任务中表现出显著优势，为未来研究提供了新方向。

中文摘要: 本文提出了一种神经网络方法，用于同步人类钢琴演奏录音与对应的松散对齐MIDI文件。该任务通过卷积循环神经网络（CRNN）架构实现，该架构通过处理未对齐的钢琴卷和频谱图作为输入，估计对齐的钢琴卷。为训练网络，我们创建了一个包含模拟人类常见时序误差的增强MIDI文件的钢琴曲数据集。所提模型在多种容忍窗口下比行业标准动态时间规整（DTW）方法对齐精度提升高达20%。此外，将DTW与CRNN结合可进一步改进，提供更强的鲁棒性和一致性。这些发现展示了神经网络在推动MIDI与音频对齐技术前沿的潜力。

</details>


### [253] [A Practical Approach to Power Saving in Hearables Using Sub-Nyquist Sampling with Bandwidth Extension](https://arxiv.org/abs/2506.22321)
**中文标题：基于亚奈奎斯特采样与带宽扩展的耳戴设备节能实用方法**

*Tarikul Islam Tamiti,Anomadarshi Barua*

主要分类: cs.SD

摘要简述: 本文提出SUBARU方法，通过亚奈奎斯特采样和低比特分辨率降低功耗，同时利用多尺度虚拟判别器提升音频质量，实现高效低功耗的耳戴设备语音增强。


<details>
  <summary>详细信息</summary>
研究动机: 现有耳戴设备在低功耗实现中未考虑亚奈奎斯特采样和低比特分辨率对语音质量和智能性的影响，且缺乏宽频重建方法。本文旨在解决这些问题。

研究方法: 提出SUBARU方法，采用亚奈奎斯特采样和低比特分辨率ADC，引入多尺度虚拟判别器以替代GAN，实现宽频信号重建和低功耗处理。

研究结果: SUBARU降低功耗3.31倍，推理时间1.74ms，内存占用小于13.77MB，并在噪声环境中实现高质量语音增强。

研究结论: SUBARU为耳戴设备提供了一种高效低功耗的语音增强解决方案，兼具音频质量和实时处理能力。

中文摘要: 耳戴设备是一种佩戴在耳朵上的可穿戴计算机。骨传导麦克风（BCM）与空气传导麦克风（ACM）在耳戴设备中作为多模态语音增强（SE）的辅助模态，用于噪声环境下的语音处理。然而，现有研究未考虑以下低功耗实现的实用问题：（i）未探讨降低耳戴设备模数转换器（ADC）的采样频率和比特分辨率如何共同影响低功耗处理和多模态SE的语音质量与可懂度；（ii）未讨论如何在不使用实际GAN判别器的情况下实现类似GAN的音频质量；（iii）由于缺乏宽频重建方法，未在亚奈奎斯特采样率下处理ACM/BCM信号。本文提出SUBARU（亚奈奎斯特音频分辨率上采样）方法，实现以下目标：SUBARU（i）故意采用亚奈奎斯特采样和低比特分辨率ADC，降低功耗3.31倍；（ii）引入新颖的多尺度和多周期虚拟判别器，在不使用GAN对抗训练的情况下实现类似GAN的音频质量；（iii）在移动平台上实现流式操作，并在噪声环境中完成语音增强，推理时间为1.74ms，内存占用小于13.77MB。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [254] [QuKAN: A Quantum Circuit Born Machine approach to Quantum Kolmogorov Arnold Networks](https://arxiv.org/abs/2506.22340)
**中文标题：QuKAN：一种基于量子电路生成模型的量子Kolmogorov Arnold网络方法**

*Yannick Werner,Akash Malemath,Mengxi Liu,Vitor Fortes Rey,Nikolaos Palaiodimopoulos,Paul Lukowicz,Maximilian Kiefer-Emmanouilidis*

主要分类: quant-ph

摘要简述: 本文提出了一种基于量子电路生成模型的量子Kolmogorov Arnold网络（QuKAN），结合经典与量子方法，探索了KAN在量子机器学习中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: Kolmogorov Arnold网络（KAN）通过边上的可学习参数而非节点上的参数，能够以更少的神经元表达复杂函数，但其在量子机器学习中的应用尚未充分探索。本文旨在填补这一空白。

研究方法: 通过量子电路生成模型（QCBM）实现了KAN的混合和全量子形式，利用预训练的残差函数进行KAN转换，结合经典KAN组件与量子子程序。

研究结果: 展示了量子KAN（QuKAN）架构的可行性、可解释性和性能，验证了其在量子机器学习中的潜力。

研究结论: QuKAN架构为量子机器学习提供了一种新的方法，展示了KAN在量子领域的应用前景。

中文摘要: Kolmogorov Arnold网络（KAN）基于Kolmogorov Arnold表示定理（KAR），通过边上的可学习参数而非节点上的参数，能够以更少的神经元表达复杂函数。然而，KAN在量子机器学习中的潜力尚未得到充分探索。本文提出了一种基于量子电路生成模型（QCBM）的KAN架构实现，包括混合和全量子形式。通过预训练的残差函数进行KAN转换，利用参数化量子电路的表示能力。在混合模型中，结合了经典KAN组件与量子子程序；而在全量子版本中，整个残差函数的架构被转化为量子模型。我们展示了所提出的量子KAN（QuKAN）架构的可行性、可解释性和性能。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [255] [Concept-Level AI for Telecom: Moving Beyond Large Language Models](https://arxiv.org/abs/2506.22359)
**中文标题：电信领域的概念级AI：超越大型语言模型**

*Viswanath Kumarskandpriya,Abdulhalim Dandoush,Abbas Bradai,Ali Belgacem*

主要分类: cs.NI

摘要简述: 电信领域需要超越大型语言模型（LLM）的概念级AI（LCM），以解决跨层依赖、时空故障关联等复杂问题。LCM通过语义概念抽象和双曲潜在空间实现高效网络管理。


<details>
  <summary>详细信息</summary>
研究动机: 电信网络管理面临跨层依赖、多语言系统和实时协调等复杂挑战，传统LLM因逐词处理和上下文限制无法满足需求，需引入概念级AI（LCM）以提升效率。

研究方法: 提出大型概念模型（LCM），通过语义概念抽象和双曲潜在空间表示层次结构，封装多层网络交互，解决LLM在内存效率、跨层关联和多模态整合上的不足。

研究结果: LCM在内存效率、跨层关联和实时协调方面优于LLM，为电信管理提供了更高效的解决方案。

研究结论: 采用LCM是实现稳健高效AI驱动电信管理的必要进化，而非简单改进。

中文摘要: 电信和网络领域正处于变革时代，需管理日益复杂的多层、多运营商和多语言系统。尽管大型语言模型（LLM）在通用文本分析和代码生成方面表现优异，但其逐词处理和有限上下文能力难以满足电信特定需求，如跨层依赖、时空故障关联和实时分布式协调。相比之下，大型概念模型（LCM）通过语义概念抽象推理，利用双曲潜在空间表示层次结构，并以简洁概念嵌入封装复杂网络交互，克服了LLM在内存效率、跨层关联和多模态整合上的关键缺陷。本文认为，采用LCM不仅是渐进式改进，更是实现稳健高效AI驱动电信管理的必要飞跃。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [256] [LLM2Rec: Large Language Models Are Powerful Embedding Models for Sequential Recommendation](https://arxiv.org/abs/2506.21579)
**中文标题：LLM2Rec：大语言模型是序列推荐的强大嵌入模型**

*Yingzhi He,Xiaohao Liu,An Zhang,Yunshan Ma,Tat-Seng Chua*

主要分类: cs.IR

摘要简述: LLM2Rec是一种新颖的嵌入模型，通过结合大语言模型（LLMs）的语义理解与协同过滤信号，提升序列推荐的性能，尤其在跨领域推荐中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统序列推荐方法依赖ID嵌入，缺乏跨领域泛化能力；而基于文本的推荐方法虽能泛化，却无法捕捉协同过滤信号。因此，需要一种既能整合语义信息又能编码协同信号的嵌入模型。

研究方法: LLM2Rec采用两阶段训练框架：1）协同监督微调，使LLMs能基于历史交互推断物品关系；2）物品级嵌入建模，将LLMs转化为结构化嵌入模型，同时编码语义和协同信息。

研究结果: 实验表明，LLM2Rec在真实数据集上显著提升了推荐质量，尤其在跨领域推荐中表现突出。

研究结论: LLM2Rec展示了利用LLMs构建更鲁棒、泛化能力更强的嵌入模型的潜力，为序列推荐提供了新思路。

中文摘要: 序列推荐旨在通过建模相似用户或物品的历史行为中的协同过滤（CF）信号，预测用户的未来交互。传统序列推荐主要依赖基于ID的嵌入，通过高阶共现模式捕捉CF信号。然而，这些嵌入仅依赖过去交互，缺乏泛化到未见领域的可迁移知识。大语言模型（LLMs）的最新进展推动了基于文本的推荐方法，这些方法从文本描述中提取物品表示。尽管这些方法增强了泛化能力，却未能编码对有效推荐至关重要的CF信号（即潜在物品关联和偏好模式）。我们认为，理想的嵌入模型应无缝整合CF信号与丰富语义表示，以提升领域内和跨领域推荐性能。为此，我们提出LLM2Rec，一种专为序列推荐设计的新颖嵌入模型，将LLMs的丰富语义理解与CF感知相结合。我们的方法采用两阶段训练框架：1）协同监督微调，使LLMs能基于历史交互推断物品关系；2）物品级嵌入建模，将这些专用LLMs转化为结构化物品嵌入模型，同时编码语义和协同信息。在真实数据集上的大量实验表明，LLM2Rec显著提升了领域内和跨领域推荐质量。我们的发现凸显了利用LLMs构建更鲁棒、泛化能力更强的嵌入模型的潜力。代码已开源：https://github.com/HappyPointer/LLM2Rec。

</details>


### [257] [Evaluating the Robustness of Dense Retrievers in Interdisciplinary Domains](https://arxiv.org/abs/2506.21581)
**中文标题：评估密集检索器在跨学科领域中的鲁棒性**

*Sarthak Chaturvedi,Anurag Acharya,Rounak Meyur,Koby Hayashi,Sai Munikoti,Sameera Horawalavithana*

主要分类: cs.IR

摘要简述: 研究表明，评估基准的特征可能扭曲检索模型在跨学科领域中领域适应的真实效果，导致误导性评估结果。通过环境监管文件检索案例，发现不同语义结构的基准对领域适应效果的评估差异显著。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估基准的特性可能掩盖检索模型在跨学科领域中领域适应的真实优势，从而影响在专业领域中的部署决策。研究旨在揭示不同基准对领域适应效果评估的影响。

研究方法: 以环境监管文件检索为例，在ColBERTv2模型上对联邦机构的环境影响声明（EIS）进行微调，并在两个语义结构不同的基准上评估模型性能。通过主题多样性指标比较基准差异。

研究结果: 研究发现，领域适应的效果因评估基准的语义结构而异。在主题边界清晰的基准上，领域适应仅带来微小改进（NDCG增益最高0.61%）；而在语义结构重叠的基准上，相同模型表现出显著提升（NDCG增益高达2.22%）。

研究结论: 评估基准的选择对检索系统在专业领域中的效果评估具有决定性影响。主题分离的基准低估了领域适应的优势，而语义重叠的基准更能反映真实世界的复杂性。这对跨学科领域AI系统的开发和部署具有重要意义。

中文摘要: 评估基准的特性可能扭曲检索模型中领域适应的真实效果，从而在专业领域中产生误导性的部署决策。我们展示了两个特征截然不同的基准（如主题多样性、边界重叠和语义复杂性）如何影响微调效果的感知。以环境监管文件检索为例，我们在联邦机构的环境影响声明（EIS）上对ColBERTv2模型进行微调，并在两个语义结构不同的基准上评估这些模型。结果表明，相同的领域适应方法因评估方法的不同而表现出显著差异的效果。在一个主题边界清晰的基准上，领域适应仅带来微小改进（NDCG增益最高0.61%）；而在语义结构重叠的基准上，相同模型表现出大幅提升（NDCG增益高达2.22%），性能提升差异达3.6倍。通过主题多样性指标比较这些基准，发现性能更高的基准中上下文之间的平均余弦距离高出11%，轮廓分数低23%，直接导致了观察到的性能差异。这些结果表明，基准选择对专业领域中检索系统效果的评估具有决定性影响。主题分离的评估框架通常会低估领域适应的优势，而语义边界重叠的框架则能更好地反映真实世界监管文件的复杂性。这些发现对开发和部署跨学科领域（整合多主题）的AI系统具有重要意义。

</details>


### [258] [Reinforcement Fine-Tuned Large Language Models for Next POI Recommendation](https://arxiv.org/abs/2506.21599)
**中文标题：基于强化微调的大语言模型用于下一个兴趣点推荐**

*Peibo Li,Shuang Ao,Hao Xue,Yang Song,Maarten de Rijke,Johan Barthélemy,Tomasz Bednarz,Flora D. Salim*

主要分类: cs.IR

摘要简述: 本文提出Refine-POI框架，通过强化微调大语言模型（LLM）解决下一个兴趣点（POI）推荐任务中监督微调（SFT）的局限性，仅需单个真实POI即可生成高质量推荐列表。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大语言模型（LLM）的POI推荐方法分为提示型和监督微调型，前者灵活性高但准确性低，后者性能高但存在数据不匹配问题——监督微调需要精确匹配真实POI，而推荐任务需生成多候选列表。

研究方法: 提出Refine-POI框架，通过强化学习微调LLM，设计推荐驱动的奖励机制，使模型仅需单个真实POI即可学习生成高质量的top-k推荐列表。

研究结果: 在真实数据集上的实验表明，Refine-POI在top-k推荐任务中达到最先进的性能。

研究结论: Refine-POI通过强化微调解决了监督微调在POI推荐中的局限性，显著提升了推荐性能。

中文摘要: 大语言模型（LLM）已被应用于下一个兴趣点（POI）推荐任务。典型的基于LLM的推荐器分为两类：基于提示的模型和基于监督微调（SFT）的模型。基于提示的模型通常提供更高的输出灵活性但准确性较低，而基于SFT的模型虽然性能更高，却面临一个根本性不匹配问题：下一个POI推荐数据并不天然适合监督微调。在SFT中，模型被训练以精确复现真实POI，但每个训练示例仅提供一个目标POI，因此无法生成top-k推荐列表的真实数据。为解决这一问题，我们提出了Refine-POI，一个用于下一个POI推荐的强化微调框架。我们引入了推荐驱动的奖励机制，使LLM能够仅通过每个示例中的一个真实POI学习生成top-k推荐列表。在真实数据集上的实验表明，Refine-POI在top-k推荐任务中达到了最先进的性能。

</details>


### [259] [Evaluating VisualRAG: Quantifying Cross-Modal Performance in Enterprise Document Understanding](https://arxiv.org/abs/2506.21604)
**中文标题：评估VisualRAG：量化企业文档理解中的跨模态性能**

*Varun Mannam,Fang Wang,Xin Chen*

主要分类: cs.IR

摘要简述: 本文提出了一种系统化的定量评估框架VisualRAG，用于衡量企业文档理解中多模态输入的可靠性，优化模态权重后性能提升57.3%。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态生成AI的评估框架难以建立可信度，阻碍了企业应用。本文旨在通过定量方法提升多模态RAG系统的可靠性，推动企业AI的负责任部署。

研究方法: 引入定量基准框架，测量文本、图像、标题和OCR等多模态输入的集成效果，建立技术指标与用户信任度之间的量化关系。

研究结果: 实验显示，优化模态权重（文本30%、图像15%、标题25%、OCR30%）比纯文本基线性能提升57.3%，同时保持计算效率。

研究结论: 本文为企业AI提供了严格的框架，量化并增强多模态RAG的可信度，推动关键企业应用的负责任部署。

中文摘要: 当前多模态生成AI的评估框架难以建立可信度，阻碍了可靠性至关重要的企业应用。我们引入了一种系统化的定量基准框架，用于测量VisualRAG系统中逐步集成文本、图像、标题和OCR等跨模态输入的可信度。我们的方法建立了技术指标与用户信任度之间的量化关系。评估结果表明，优化模态权重（文本30%、图像15%、标题25%、OCR30%）比纯文本基线性能提升57.3%，同时保持计算效率。我们提供了基础模型的比较评估，展示了它们在标题生成和OCR提取中对可信度的不同影响——这是可靠企业AI的关键考量。本研究通过提供严格的框架来量化和增强多模态RAG在关键企业应用中的可信度，推动了负责任AI的部署。

</details>


### [260] [Bayesian-Guided Diversity in Sequential Sampling for Recommender Systems](https://arxiv.org/abs/2506.21617)
**中文标题：贝叶斯指导的推荐系统序列采样多样性优化**

*Hiba Bederina,Jill-Jênn Vie*

主要分类: cs.IR

摘要简述: 本文提出了一种基于贝叶斯指导的多样性序列采样框架，用于推荐系统中平衡用户相关性和内容多样性，显著提升多样性而不损失相关性。


<details>
  <summary>详细信息</summary>
研究动机: 随着内容同质化和用户参与度下降的问题日益突出，如何在推荐系统中平衡用户相关性和内容多样性成为关键挑战。

研究方法: 采用多目标上下文序列采样策略，通过贝叶斯更新动态调整评分以优化多样性。奖励公式整合了多种多样性指标（如调整相似性子矩阵的对数行列式体积和岭杠杆分数）以及多样性增益不确定性项，以解决探索-利用权衡问题。同时建模批内和批间多样性以促进意外发现并减少冗余。通过基于支配的排名程序识别帕累托最优项目集，实现每次迭代的自适应平衡选择。

研究结果: 在真实数据集上的实验表明，该方法在不牺牲相关性的情况下显著提高了多样性，显示出其在大规模推荐场景中提升用户体验的潜力。

研究结论: 该框架通过贝叶斯指导和多样性优化策略，有效解决了推荐系统中的多样性挑战，为提升用户参与度和内容新颖性提供了实用解决方案。

中文摘要: 在推荐系统中平衡用户相关性和内容多样性的挑战日益突出，尤其是在内容同质化和用户参与度下降的背景下。本文提出了一种新颖的框架，利用多目标上下文序列采样策略。项目选择通过贝叶斯更新动态调整评分以优化多样性。奖励公式整合了多种多样性指标（包括调整相似性子矩阵的对数行列式体积和岭杠杆分数）以及多样性增益不确定性项，以解决探索-利用权衡问题。同时建模批内和批间多样性以促进意外发现并减少冗余。通过基于支配的排名程序识别帕累托最优项目集，实现每次迭代的自适应平衡选择。在真实数据集上的实验表明，我们的方法在不牺牲相关性的情况下显著提高了多样性，显示出其在大规模推荐场景中提升用户体验的潜力。

</details>


### [261] [IRanker: Towards Ranking Foundation Model](https://arxiv.org/abs/2506.21638)
**中文标题：IRanker：迈向排序基础模型**

*Tao Feng,Zhigang Hua,Zijie Lei,Yan Xie,Shuang Yang,Bo Long,Jiaxuan You*

主要分类: cs.IR

摘要简述: 本文提出了IRanker，一种基于强化学习和迭代解码的排序基础模型框架，旨在统一推荐系统、LLM路由和段落排序等任务。通过逐步剔除候选池中最差选项，IRanker显著减少了输出组合空间，并在多个数据集上实现了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 排序任务广泛存在于推荐系统、LLM路由等场景中，但现有方法需要为每个任务设计不同模型。本文旨在开发一个统一的排序基础模型（FM），以简化任务处理并提升性能。

研究方法: IRanker采用强化学习和迭代解码机制，将复杂排序任务分解为逐步剔除最差候选者的过程，从而减少输出组合空间并优化上下文长度利用。

研究结果: IRanker-3B在推荐、路由和段落排序三个场景的九个数据集上表现优异，部分任务甚至超越更大模型。此外，其在域内和域外零样本任务中均显著优于基础模型。

研究结论: IRanker通过强化学习和迭代解码机制，成功实现了排序任务的统一处理，并在性能和泛化能力上表现出色。

中文摘要: 排序任务无处不在，涵盖推荐系统、LLM路由和项目重排等应用。我们提出使用单一排序基础模型（FM）统一这些任务，从而避免为每个特定任务设计不同模型。然而，与LLM中的通用监督任务不同，排序任务缺乏明确的监督标签，这对开发排序FM提出了巨大挑战。为克服这些挑战，我们提出了IRanker，一种基于强化学习（RL）和迭代解码的排序FM框架。我们的思路是将复杂排序任务分解为逐步剔除候选池中最差候选者的迭代解码过程，从而显著减少输出组合空间，并在RL训练中更好地利用有限的上下文长度。我们在推荐、路由和段落排序三个场景的九个数据集上精心训练并全面评估了IRanker-3B模型。结果表明，与类似规模的模型相比，单一IRanker-3B在多个数据集上实现了最优性能，甚至在某些数据集上超越了更大模型的表现。我们进一步验证了RL设计的有效性以及迭代机制在不同LLM规模下的鲁棒性。此外，我们进行了域内和域外零样本泛化实验，结果显示IRanker-3B在域内排序任务中相比基础LLM至少提升了5%的性能。令人惊讶的是，在域外通用LLM任务中，IRanker-3B在GSM8K、IFEval和MathQA上至少优于基础模型9%。此外，IRanker-3B在训练过程中生成的思考还能进一步提升零样本LLM性能。

</details>


### [262] [Hierarchical Patch Compression for ColPali: Efficient Multi-Vector Document Retrieval with Dynamic Pruning and Quantization](https://arxiv.org/abs/2506.21601)
**中文标题：ColPali的分层补丁压缩：基于动态剪枝和量化的高效多向量文档检索**

*Duong Bach*

主要分类: cs.IR

摘要简述: 本文提出HPC-ColPali框架，通过分层补丁压缩技术（包括K-Means量化、动态剪枝和二进制编码）显著提升多向量文档检索系统的存储和计算效率，同时保持高检索精度。


<details>
  <summary>详细信息</summary>
研究动机: 多向量文档检索系统（如ColPali）在复杂查询中表现优异，但高维补丁嵌入和后期交互评分导致存储和计算成本高昂。本文旨在解决这一问题，提出高效且不影响检索精度的解决方案。

研究方法: HPC-ColPali框架包含三项创新技术：1) K-Means量化将补丁嵌入压缩为1字节质心索引，存储减少32倍；2) 注意力引导的动态剪枝保留前p%显著补丁，减少60%计算；3) 可选二进制编码，支持快速汉明距离相似性搜索。

研究结果: 在ViDoRe和SEC-Filings数据集上，HPC-ColPali查询延迟降低30-50%，检索精度保持高位。在生成式检索管道中，幻觉率降低30%，端到端延迟减半。

研究结论: HPC-ColPali为多向量文档检索提供了一种高效且可扩展的解决方案，适用于多样化应用场景。

中文摘要: 多向量文档检索系统（如ColPali）在复杂查询的细粒度匹配中表现出色，但由于依赖高维补丁嵌入和后期交互评分，其存储和计算成本较高。为解决这一问题，我们提出HPC-ColPali，一种分层补丁压缩框架，在保持检索精度的同时提升效率。该框架整合了三种创新技术：1) K-Means量化将补丁嵌入压缩为1字节质心索引，存储减少32倍；2) 注意力引导的动态剪枝保留前p%显著补丁，计算减少60%，nDCG@10损失低于2%；3) 可选二进制编码将质心索引转为b位字符串（b=⌈log₂K⌉），支持资源受限环境下的快速汉明距离相似性搜索。在ViDoRe和SEC-Filings数据集上的实验表明，HPC-ColPali在HNSW索引下查询延迟降低30-50%，同时保持高检索精度。在生成式检索管道中，幻觉率降低30%，端到端延迟减半。这些成果使HPC-ColPali成为多向量文档检索的高效可扩展解决方案。代码见https://github.com/DngBack/HPC-ColPali。

</details>


### [263] [CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware Layout Design](https://arxiv.org/abs/2506.21934)
**中文标题：CAL-RAG：基于检索增强的多智能体生成框架用于内容感知布局设计**

*Najmeh Forouzandehmehr,Reza Yousefi Maragheh,Sriram Kollipara,Kai Zhao,Topojoy Biswas,Evren Korpeoglu,Kannan Achan*

主要分类: cs.IR

摘要简述: CAL-RAG是一种基于检索增强的多智能体生成框架，用于内容感知的布局设计，通过多模态检索、大型语言模型和协作智能体推理，显著提升了布局生成的语义对齐和视觉连贯性。


<details>
  <summary>详细信息</summary>
研究动机: 当前智能设计系统中的自动化布局生成方法缺乏对上下文设计范例的参考，且在语义对齐和视觉连贯性方面表现不足。CAL-RAG旨在通过检索增强和多智能体协作解决这些问题。

研究方法: CAL-RAG结合多模态检索从结构化知识库中获取相关布局范例，利用基于大型语言模型的布局推荐器提出元素放置方案，并通过视觉语言评分智能体和反馈智能体进行迭代优化。

研究结果: 在PKU PosterLayout数据集上的实验表明，CAL-RAG在多个布局指标（如底层效果、元素对齐和重叠）上达到最优性能，显著优于LayoutPrompter等基线方法。

研究结论: CAL-RAG通过检索增强和多步智能体推理，为自动化布局生成提供了可扩展、可解释且高保真的解决方案。

中文摘要: 自动化内容感知布局生成——即在背景画布上排列文本、标志和底层等视觉元素的任务——仍然是智能设计系统中一个基础但尚未充分探索的问题。尽管深度生成模型和大型语言模型（LLMs）在结构化内容生成方面显示出潜力，但现有方法大多缺乏对上下文设计范例的参考，且在语义对齐和视觉连贯性方面表现不足。本文提出CAL-RAG，一种基于检索增强的多智能体框架，用于内容感知布局生成，整合了多模态检索、大型语言模型和协作智能体推理。我们的系统从结构化知识库中检索相关布局范例，并调用基于LLM的布局推荐器提出结构化元素放置方案。视觉语言评分智能体通过视觉指标评估布局，反馈智能体提供针对性优化，从而实现迭代改进。我们使用LangGraph实现该框架，并在语义和结构多样性丰富的PKU PosterLayout数据集上进行评估。CAL-RAG在多个布局指标（包括底层效果、元素对齐和重叠）上达到最优性能，显著优于LayoutPrompter等基线方法。这些结果表明，结合检索增强与多步智能体推理，为自动化布局生成提供了可扩展、可解释且高保真的解决方案。

</details>


### [264] [ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation](https://arxiv.org/abs/2506.21931)
**中文标题：ARAG：基于代理的检索增强生成框架用于个性化推荐**

*Reza Yousefi Maragheh,Pratheek Vadla,Priyank Gupta,Kai Zhao,Aysenur Inan,Kehui Yao,Jianpeng Xu,Praveen Kanumala,Jason Cho,Sushant Kumar*

主要分类: cs.IR

摘要简述: 本文提出了一种名为ARAG的代理检索增强生成框架，用于个性化推荐，通过多代理协作机制显著提升了推荐系统的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于检索增强生成（RAG）的推荐系统依赖静态检索启发式方法，难以捕捉动态推荐场景中的用户偏好。因此，作者提出ARAG框架，以更好地理解用户长期和会话行为。

研究方法: ARAG框架整合了四个基于大型语言模型（LLM）的代理：用户理解代理（总结用户偏好）、自然语言推理代理（评估候选项目与用户意图的语义对齐）、上下文总结代理（汇总推理结果）和项目排序代理（生成推荐列表）。

研究结果: 在三个数据集上的实验表明，ARAG显著优于标准RAG和基于时效性的基线方法，NDCG@5和Hit@5分别提升42.1%和35.5%。消融研究进一步验证了各组件的重要性。

研究结论: ARAG通过代理推理机制有效提升了检索增强推荐的性能，为基于LLM的个性化推荐提供了新方向。

中文摘要: 检索增强生成（RAG）通过将外部上下文融入大型语言模型提示中，为推荐系统提供了改进潜力。然而，现有的RAG方法通常依赖静态检索启发式，难以在动态推荐场景中捕捉细微的用户偏好。本文提出ARAG，一种用于个性化推荐的代理检索增强生成框架，将多代理协作机制整合到RAG流程中。为了更好地理解用户的长期和会话行为，ARAG利用四个基于LLM的专用代理：用户理解代理（从长期和会话上下文中总结用户偏好）、自然语言推理代理（评估RAG检索的候选项目与推断意图的语义对齐）、上下文总结代理（汇总NLI代理的发现）和项目排序代理（根据上下文适配生成推荐排名列表）。我们在三个数据集上评估ARAG。实验结果表明，ARAG显著优于标准RAG和基于时效性的基线方法，NDCG@5和Hit@5分别提升42.1%和35.5%。我们还通过消融研究分析了ARAG各组件的影响。研究结果表明，将代理推理融入检索增强推荐具有显著效果，并为基于LLM的个性化推荐提供了新方向。

</details>


### [265] [HyReC: Exploring Hybrid-based Retriever for Chinese](https://arxiv.org/abs/2506.21913)
**中文标题：HyReC：探索基于混合的中文检索器**

*Zunran Wang,Zheng Shenpeng,Wang Shenglan,Minghui Zhao,Zhonghua Li*

主要分类: cs.IR

摘要简述: 本文提出HyReC，一种专为中文混合检索设计的端到端优化方法，通过整合词项语义联合和全局-局部感知编码器（GLAE）提升性能，并在C-MTEB基准测试中验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管混合检索方法（结合密集向量和基于词典的检索）在性能提升上表现出色，但其在中文检索中的应用尚未充分探索。本文旨在填补这一空白，提出一种针对中文混合检索的优化方法。

研究方法: HyReC通过将词项语义联合整合到表示模型中，并采用全局-局部感知编码器（GLAE）促进词典和密集检索间的语义共享，同时减少干扰。此外，引入归一化模块（NM）进一步优化对齐。

研究结果: 在C-MTEB检索基准测试中，HyReC表现出显著的有效性，验证了其在中文混合检索中的优越性能。

研究结论: HyReC为中文混合检索提供了一种创新的端到端优化方法，通过语义联合和GLAE显著提升了性能，为相关领域的研究和应用提供了新思路。

中文摘要: 混合检索方法通过结合密集向量和基于词典的检索，因其性能提升而受到业界的广泛关注。然而，尽管其成果显著，这些混合范式在中文检索中的应用仍未被充分探索。本文提出HyReC，一种专为中文混合检索设计的创新端到端优化方法。HyReC通过将词项语义联合整合到表示模型中提升性能，并采用全局-局部感知编码器（GLAE）促进词典和密集检索间的语义共享，同时减少干扰。为进一步优化对齐，还引入了归一化模块（NM）。最后，在C-MTEB检索基准测试中验证了HyReC的有效性。

</details>


### [266] [Literature-Grounded Novelty Assessment of Scientific Ideas](https://arxiv.org/abs/2506.22026)
**中文标题：基于文献的科学想法新颖性评估**

*Simra Shahid,Marissa Radensky,Raymond Fok,Pao Siangliulue,Daniel S. Weld,Tom Hope*

主要分类: cs.IR

摘要简述: 本文提出了一种基于LLM的检索增强生成框架（Idea Novelty Checker），用于自动评估科学想法的创新性。通过两阶段的检索和重排序方法，结合专家标注数据，该框架在文献基础上评估新颖性，实验显示其比现有方法提高了13%的一致性。


<details>
  <summary>详细信息</summary>
研究动机: 当前自动生成科学想法的系统发展迅速，但自动评估想法新颖性仍是一个未被充分探索的挑战。人工评估新颖性耗时且主观性强，难以规模化。因此，本文旨在解决这一问题，提出一种自动化的新颖性评估方法。

研究方法: 提出Idea Novelty Checker框架，采用两阶段的检索增强生成方法：1）通过关键词和片段检索广泛收集相关文献；2）使用嵌入过滤和基于分面的LLM重排序优化文献集合。结合专家标注数据，生成基于文献的新颖性评估和推理。

研究结果: 实验表明，该框架的新颖性评估与现有方法相比提高了约13%的一致性。消融研究进一步验证了基于分面的重排序在识别相关文献中的重要性。

研究结论: 本文提出的Idea Novelty Checker框架有效解决了科学想法新颖性自动评估的挑战，通过检索增强生成和专家指导，显著提升了评估的准确性和一致性。

中文摘要: 自动化科学想法生成系统取得了显著进展，但想法新颖性的自动评估仍是一个关键且未被充分探索的挑战。通过文献综述手动评估新颖性不仅耗时，且因主观性易出错，难以规模化。为解决这些问题，我们提出了Idea Novelty Checker，一种基于LLM的检索增强生成（RAG）框架，采用两阶段的检索-重排序方法。该框架首先通过关键词和片段检索收集广泛的文献，随后通过嵌入过滤和基于分面的LLM重排序优化文献集合。结合专家标注数据，系统能够比较文献以评估新颖性并生成基于文献的推理。大量实验表明，我们的新颖性评估器比现有方法的一致性提高了约13%。消融研究进一步证明了基于分面的重排序在识别相关文献中的重要性。

</details>


### [267] [Towards Fair Rankings: Leveraging LLMs for Gender Bias Detection and Measurement](https://arxiv.org/abs/2506.22372)
**中文标题：迈向公平排名：利用大型语言模型进行性别偏见检测与衡量**

*Maryam Mousavian,Zahra Abbasiantaeb,Mohammad Aliannejadi,Fabio Crestani*

主要分类: cs.IR

摘要简述: 本文提出了一种利用大型语言模型（LLM）检测和衡量段落排名中性别偏见的新方法，并引入了一种名为类加权暴露（CWEx）的新公平性指标。通过实验验证，该方法在公平性评估上优于现有指标，并发布了新的性别偏见数据集MSMGenderBias以促进未来研究。


<details>
  <summary>详细信息</summary>
研究动机: 自然语言处理和信息检索系统中存在社会偏见，尤其是性别偏见，现有基于词法和频率的公平性指标存在局限性，无法捕捉细微的性别差异。本文旨在利用LLM解决这一问题。

研究方法: 提出了一种基于LLM的性别偏见检测方法，并设计了新的公平性指标CWEx。通过标注MS MARCO Passage Ranking数据集的一部分，发布了新的性别偏见数据集MSMGenderBias，并在多种排名模型上进行了实验验证。

研究结果: 实验结果表明，CWEx指标在公平性评估上优于现有指标（Cohen's Kappa一致性分别为58.77%和18.51%），能够更有效地识别排名中的性别偏见。

研究结论: 通过结合LLM驱动的偏见检测、改进的公平性指标和新的性别偏见数据集，本文为分析和减轻信息检索系统中的偏见提供了更强大的框架。

中文摘要: 自然语言处理（NLP）和信息检索（IR）系统中存在社会偏见，这凸显了开发稳健方法来识别和评估此类偏见的重要性。本文旨在通过利用大型语言模型（LLM）检测和衡量段落排名中的性别偏见来解决这一问题。现有的性别公平性指标依赖于基于词法和频率的测量方法，存在多种局限性，例如无法捕捉细微的性别差异。基于我们提出的基于LLM的性别偏见检测方法，我们引入了一种新的性别公平性指标，称为类加权暴露（CWEx），以解决现有局限性。为了衡量我们提出的指标的有效性并研究LLM在检测性别偏见中的作用，我们标注了MS MARCO Passage Ranking数据集的一部分，并发布了新的性别偏见数据集MSMGenderBias，以促进该领域的未来研究。我们在多种排名模型上的广泛实验结果表明，与之前的指标相比，我们提出的指标提供了更详细的公平性评估，且与人类标注的一致性更高（Grep-BiasIR的Cohen's Kappa一致性为58.77%，MSMGenderBias为18.51%），能够有效区分排名中的性别偏见。通过整合LLM驱动的偏见检测、改进的公平性指标以及对现有数据集的性别偏见标注，本研究为分析和减轻IR系统中的偏见提供了一个更强大的框架。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [268] [Hardware acceleration for ultra-fast Neural Network training on FPGA for MRF map reconstruction](https://arxiv.org/abs/2506.22156)
**中文标题：基于FPGA的超快神经网络训练硬件加速用于MRF图谱重建**

*Mattia Ricchi,Fabrizio Alfonsi,Camilla Marella,Marco Barbieri,Alessandra Retico,Leonardo Brizi,Alessandro Gabrielli,Claudia Testa*

主要分类: cs.AR

摘要简述: 本文提出一种基于FPGA的神经网络方法，用于从磁共振指纹（MRF）数据中实时重建脑部参数，训练时间仅需200秒，比传统CPU方法快250倍，有望推动移动设备上的实时脑部分析。


<details>
  <summary>详细信息</summary>
研究动机: 磁共振指纹（MRF）是一种快速定量磁共振成像技术，但神经网络（NNs）在加速重建时训练资源消耗大。本文旨在通过FPGA硬件加速，实现实时脑部参数重建，以支持临床决策和远程医疗。

研究方法: 采用基于FPGA的神经网络，优化训练过程，显著减少训练时间。通过硬件加速，将训练时间从传统CPU方法的长时间缩短至200秒。

研究结果: 实验显示，FPGA加速的神经网络训练仅需200秒，比CPU方法快250倍，能够高效完成MRF数据的脑部参数重建。

研究结论: FPGA加速的神经网络方法在MRF数据重建中表现出色，训练速度快，为移动设备上的实时脑部分析提供了可能，具有重要的临床应用潜力。

中文摘要: 磁共振指纹（MRF）是一种快速定量磁共振成像技术，通过单次采集即可生成多参数图谱。神经网络（NNs）可加速重建，但训练过程需要大量资源。本文提出一种基于FPGA的神经网络，用于从MRF数据中实时重建脑部参数。训练时间预计为200秒，显著快于基于CPU的标准训练方法（后者可能慢250倍）。这一方法有望在移动设备上实现实时脑部分析，从而革新临床决策和远程医疗。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [269] [Exploring the change in scientific readability following the release of ChatGPT](https://arxiv.org/abs/2506.21825)
**中文标题：探究ChatGPT发布后科学文献可读性的变化**

*Abdulkareem Alsudais*

主要分类: cs.CY

摘要简述: 本文通过分析arXiv.org上2010年至2024年6月7日的论文摘要，研究了ChatGPT发布后科学文献可读性的变化。结果显示，摘要的可读性逐年下降，且在ChatGPT发布后（2023年和2024年）出现了显著变化，表明AI可能影响了科学写作。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（如ChatGPT）的普及，研究者关注其对科学写作的影响。本文旨在探讨ChatGPT发布后，科学文献摘要的可读性是否发生了显著变化。

研究方法: 研究使用了arXiv.org上2010年至2024年6月7日的所有论文摘要，通过四种标准可读性公式计算每篇摘要的可读性分数，并按年份和学科分类进行统计分析。

研究结果: 结果显示，摘要的可读性逐年下降，且在ChatGPT发布后的2023年和2024年出现了显著变化。这一趋势在多个学科中普遍存在。

研究结论: 研究表明，ChatGPT的发布可能对科学写作的可读性产生了影响，摘要变得更加复杂。这为AI对科学写作的潜在影响提供了实证依据。

中文摘要: 随着大型语言模型的兴起和普及，人们开始关注其对生活各方面的影响，包括科学家如何撰写和发表研究。本文的主要目标是分析arXiv.org上2010年至2024年6月7日期间发布的所有论文摘要，评估其可读性的演变，并确定在2022年11月ChatGPT发布后是否发生了显著变化。研究使用了四种标准可读性公式，为每篇论文计算可读性分数，并按其发布年份和平台的八大主要学科分类进行汇总。结果显示，摘要的可读性逐年下降，表明其内容可能变得更加复杂。此外，在ChatGPT发布后，2023年和2024年的可读性出现了显著变化。这一趋势在多个学科中普遍存在。这些发现为可读性的广泛变化提供了见解，并指出了AI对科学写作的潜在影响。

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [270] [SciMantify -- A Hybrid Approach for the Evolving Semantification of Scientific Knowledge](https://arxiv.org/abs/2506.21819)
**中文标题：SciMantify——一种用于科学知识渐进语义化的混合方法**

*Lena John,Kheir Eddine Farfar,Sören Auer,Oliver Karras*

主要分类: cs.DL

摘要简述: 论文提出了一种名为SciMantify的混合方法，通过逐步将科学知识从PDF等静态格式转化为语义化的知识图谱表示，提升科学知识的可访问性和可重用性。


<details>
  <summary>详细信息</summary>
研究动机: 科学出版物通常以PDF等静态格式存在，缺乏结构化和语义化，限制了知识的可访问性和重用性。需要一种更灵活、结构化且语义化的表示方法，以支持人类和机器对科学知识的理解和处理。

研究方法: 论文提出了一种基于5星关联开放数据（LOD）模型的知识表示演化模型，包含五个阶段和明确的标准，指导从数字文件（如PDF）到知识图谱（KG）语义化表示的逐步转化。通过SciMantify方法，结合人类和机器的协作，完成语义标注任务（SATs）并逐步优化科学知识的语义表示。

研究结果: 在开放研究知识图谱（ORKG）平台上实现了该方法，初步用户实验表明，该方法简化了科学知识的预处理，减少了语义化的工作量，并通过与知识图谱结构的更好对齐提升了知识表示质量。

研究结论: SciMantify方法为科学知识的语义化提供了一种可行的解决方案，通过人类与机器的协作，逐步提升知识表示的语义化水平，从而增强科学知识的可访问性和可重用性。

中文摘要: 科学出版物主要以PDF形式数字化，内容静态且缺乏结构化，限制了其中知识的可访问性和可重用性。目前，科学知识最多以表格形式提供，但缺乏语义上下文。需要一种更灵活、结构化且语义化的表示方法，以使科学知识对人类和机器均可理解和处理。我们提出了一种知识表示演化模型，灵感来源于5星关联开放数据（LOD）模型，包含五个阶段和明确的标准，指导从数字文件（如PDF）到知识图谱（KG）语义化表示的逐步转化。基于一个实现整个模型的示例工作流，我们开发了一种名为SciMantify的混合方法，利用科学知识的表格格式（如二次研究的结果）支持其渐进语义化。在该方法中，人类和机器通过执行语义标注任务（SATs）并优化结果，逐步改进科学知识的语义表示。我们在开放研究知识图谱（ORKG）中实现了该方法，ORKG是一个成熟的平台，旨在提升科学知识的可发现性、可访问性、互操作性和可重用性。初步用户实验表明，该方法简化了科学知识的预处理，减少了渐进语义化的工作量，并通过与知识图谱结构的更好对齐提升了知识表示质量。

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [271] [Inverse Design of Diffractive Metasurfaces Using Diffusion Models](https://arxiv.org/abs/2506.21748)
**中文标题：利用扩散模型逆向设计衍射超表面**

*Liav Hen,Erez Yosef,Dan Raviv,Raja Giryes,Jacob Scheuer*

主要分类: physics.optics

摘要简述: 本文提出了一种利用扩散模型逆向设计衍射超表面的方法，解决了传统设计中的局部最优和计算开销大的问题，并在30分钟内实现了低误差设计。


<details>
  <summary>详细信息</summary>
研究动机: 超表面设计中的逆向问题（从光学响应反推结构）由于结构与光学性质之间的复杂非线性关系而极具挑战性，传统方法需要专家调参且容易陷入局部最优，计算成本高。

研究方法: 通过结合扩散模型的生成能力与计算设计流程，使用RCWA模拟器生成训练数据（超表面几何结构及其远场散射模式），训练条件扩散模型以从目标空间功率分布预测元原子几何和高度。

研究结果: 模型能够以低误差生成超表面设计，例如空间均匀强度分束器和偏振分束器，设计时间少于30分钟。

研究结论: 扩散模型为超表面逆向设计提供了高效且低误差的解决方案，并公开了代码和数据集以支持进一步研究。

中文摘要: 超表面是由工程化亚波长结构组成的超薄光学元件，能够精确控制光。其逆向设计（确定产生所需光学响应的几何结构）由于结构与光学性质之间的复杂非线性关系而极具挑战性，通常需要专家调参，容易陷入局部最优，且计算开销大。本文通过将扩散模型的生成能力整合到计算设计流程中，解决了这些问题。使用RCWA模拟器生成训练数据（超表面几何结构及其远场散射模式），训练条件扩散模型以从目标空间功率分布预测元原子几何和高度，采样自连续支持波段。训练完成后，模型可通过RCWA引导的后验采样直接生成低误差超表面，或作为传统优化方法的初始化器。我们展示了空间均匀强度分束器和偏振分束器的设计，两者均在30分钟内以低误差完成。为支持数据驱动超表面设计的进一步研究，我们公开了代码和数据集。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [272] [3Description: An Intuitive Human-AI Collaborative 3D Modeling Approach](https://arxiv.org/abs/2506.21845)
**中文标题：3Description：一种直观的人机协作3D建模方法**

*Zhuodi Cai*

主要分类: cs.HC

摘要简述: 3Description是一种实验性的人机协作3D建模方法，通过语言和手势描述，使非专业人士也能参与3D建模，结合了自然语言处理和计算机视觉技术，旨在提升建模的易用性和包容性。


<details>
  <summary>详细信息</summary>
研究动机: 传统3D建模工具对非专业人士不友好，存在使用门槛高的问题。3Description旨在通过人机协作的方式，降低3D建模的复杂性，让更多人能够参与3D世界的构建，同时避免技术过度主导，保留人类创造力。

研究方法: 3Description结合了定性研究、产品分析和用户测试，整合了OpenAI和MediaPipe的自然语言处理和计算机视觉技术。通过基于网页的平台，用户可以用语言和手势描述并调整3D模型。

研究结果: 3Description成功实现了非专业人士通过语言和手势协作创建3D模型的目标，提升了建模的易用性和包容性，同时增强了人机协作的参与感。

研究结论: 3Description为3D建模提供了更直观和包容的解决方案，推动了人机协作的发展，同时强调了人类创造力在技术应用中的重要性。

中文摘要: 本文介绍了3Description，一种实验性的人机协作3D建模方法，旨在通过语言和手势描述，解决传统3D建模中的可访问性和易用性问题。3Description结合了定性研究、产品分析和用户测试，整合了OpenAI和MediaPipe的自然语言处理和计算机视觉技术。作为一个基于网页的平台，用户可以通过语言和手势输入描述并调整3D模型。在人工智能和新兴媒体的时代，3Description不仅为设计过程提供了更包容和用户友好的解决方案，使更多人能够参与未来3D世界的构建，还致力于增强人机协作中的参与感，避免技术过度主导，保留人类创造力。

</details>


### [273] [Adapting University Policies for Generative AI: Opportunities, Challenges, and Policy Solutions in Higher Education](https://arxiv.org/abs/2506.22231)
**中文标题：适应生成式AI的大学政策：高等教育中的机遇、挑战与政策解决方案**

*Russell Beale*

主要分类: cs.HC

摘要简述: 生成式AI（如ChatGPT）在高等教育中带来机遇与挑战，需调整政策以平衡学术诚信与技术潜力。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI（如大型语言模型）在高等教育中的广泛应用，亟需探讨其对学术研究、教学和评估的影响，并制定相应政策以应对学术诚信和公平性问题。

研究方法: 通过分析实证研究数据和案例，探讨生成式AI的机遇与挑战，并提出政策解决方案，如设计抗AI的评估方式、加强师生培训和多层次执行机制。

研究结果: 研究表明，47%的学生在课程中使用生成式AI，但检测工具准确率仅88%，需通过政策调整和技术手段确保学术诚信。

研究结论: 高等教育机构需主动调整政策，以充分利用生成式AI的潜力，同时维护学术诚信和公平的核心价值。

中文摘要: 生成式人工智能（AI）工具（尤其是ChatGPT等大型语言模型）的迅速普及，为高等教育带来了变革性时代。发达地区的大学正越来越多地将这些技术整合到研究、教学和评估中。一方面，大型语言模型可以通过简化文献综述、促进创意生成、协助编程和数据分析，甚至支持资助提案的起草来提高生产力。另一方面，其使用引发了关于学术诚信、伦理界限和公平获取的重大担忧。最近的实证研究表明，近47%的学生在课程中使用大型语言模型——其中39%用于考试问题，7%用于完整作业——而目前的检测工具准确率约为88%，误差率为12%。本文批判性地探讨了生成式AI提供的机遇，探索了其带来的多方面挑战，并概述了强有力的政策解决方案。重点包括重新设计抗AI的评估方式、加强师生培训、实施多层次执行机制以及定义可接受的使用范围。通过综合近期研究和案例数据，本文认为，主动调整政策对于发挥AI潜力并维护学术诚信和公平的核心价值至关重要。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [274] [FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models](https://arxiv.org/abs/2506.21627)
**中文标题：FrankenBot：基于视觉语言模型的仿脑模块化机器人操控框架**

*Shiyi Wang,Wenbo Li,Yiteng Chen,Qingyao Wu,Huiping Zhuang*

主要分类: cs.RO

摘要简述: FrankenBot是一种基于视觉语言模型（VLM）的仿脑机器人操控框架，通过模块化设计实现多功能集成与高效运行，显著提升异常处理、长期记忆和操作稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 开发能够在复杂动态环境中执行多样化任务的通用机器人系统一直是一个挑战。现有方法通常仅关注单一功能，缺乏统一认知架构。受人类大脑分而治之策略启发，研究旨在构建一个功能全面且高效的机器人操控框架。

研究方法: FrankenBot采用仿脑模块化设计，将任务规划、策略生成、记忆管理和低级接口分别映射到大脑皮层、小脑、颞叶-海马复合体和脑干，并通过高效协调机制实现模块间协作。

研究结果: 实验表明，FrankenBot在异常检测与处理、长期记忆、操作效率和稳定性方面表现优异，且无需微调或重新训练。

研究结论: FrankenBot通过仿脑模块化设计，成功实现了多功能集成与高效运行，为通用机器人操控系统提供了新思路。

中文摘要: 开发能够在复杂、动态和非结构化现实环境中执行广泛任务的通用机器人操控系统一直是一项具有挑战性的任务。实现类人高效和稳健的操控需要机器人脑整合一系列功能，如任务规划、策略生成、异常监控与处理以及长期记忆，并在所有功能中实现高效运行。视觉语言模型（VLM）通过预训练海量多模态数据，获得了丰富的世界知识，展现出卓越的场景理解和多模态推理能力。然而，现有方法通常仅关注机器人脑中单一功能或部分功能的实现，而未将其整合为统一的认知架构。受分而治之策略和人类大脑架构的启发，我们提出了FrankenBot，一种基于VLM的仿脑机器人操控框架，兼具功能全面性和运行高效性。该框架包含一系列组件，将部分关键功能从频繁的VLM调用中解耦，实现了功能完整性与系统效率的最佳平衡。具体而言，我们将任务规划、策略生成、记忆管理和低级接口分别映射到大脑皮层、小脑、颞叶-海马复合体和脑干，并为模块设计了高效的协调机制。我们在仿真和真实机器人环境中进行了全面实验，结果表明，该方法在异常检测与处理、长期记忆、操作效率和稳定性方面具有显著优势，且无需任何微调或重新训练。

</details>


### [275] [Ark: An Open-source Python-based Framework for Robot Learning](https://arxiv.org/abs/2506.21628)
**中文标题：ARK：一个基于Python的开源机器人学习框架**

*Magnus Dierking,Christopher E. Mower,Sarthak Das,Huang Helong,Jiacheng Qiu,Cody Reading,Wei Chen,Huidong Liang,Huang Guowei,Jan Peters,Quan Xingyue,Jun Wang,Haitham Bou-Ammar*

主要分类: cs.RO

摘要简述: ARK是一个开源的、基于Python的机器人学习框架，旨在简化机器人软件开发，提供类似Gym的环境接口，支持数据收集、预处理和策略训练，同时无缝切换仿真与实体机器人。


<details>
  <summary>详细信息</summary>
研究动机: 当前机器人软件栈学习曲线陡峭，依赖C/C++专业知识，工具分散且硬件集成复杂，而现代AI生态以Python为核心且文档完善。ARK旨在填补这一差距，推动机器人技术的快速研究和商业部署。

研究方法: ARK提供Gym风格的环境接口，支持数据收集、预处理和策略训练，采用轻量级客户端-服务器架构实现网络通信，并提供可选的C/C++绑定以确保实时性能。框架包含控制、SLAM、运动规划、系统辨识和可视化等模块，并与ROS原生兼容。

研究结果: ARK通过全面的文档和案例研究（从操作到移动导航）展示了快速原型设计、轻松硬件切换以及媲美主流机器学习工作流的端到端流程。

研究结论: ARK通过统一的Python生态降低了机器人学习的门槛，加速了自主机器人的研究和商业应用。

中文摘要: 机器人技术在硬件方面取得了显著进展——从DARPA的城市和机器人挑战赛到首届人形机器人拳击锦标赛——但商业自主性仍落后于机器学习的进步。主要瓶颈在于软件：当前的机器人技术栈需要陡峭的学习曲线、低级的C/C++专业知识、分散的工具和复杂的硬件集成，这与推动现代AI发展的以Python为核心、文档完善的生态系统形成鲜明对比。我们介绍了ARK，一个开源的、以Python为先的机器人框架，旨在填补这一差距。ARK提供了一个Gym风格的环境接口，用户可以通过它收集数据、预处理数据，并使用最先进的模仿学习算法（如ACT、Diffusion Policy）训练策略，同时无缝切换高保真仿真和物理机器人。轻量级的客户端-服务器架构提供了网络化的发布-订阅通信，可选的C/C++绑定确保了实时性能。ARK附带可重用的模块，涵盖控制、SLAM、运动规划、系统辨识和可视化，并原生支持ROS互操作性。全面的文档和案例研究——从操作到移动导航——展示了快速原型设计、轻松的硬件切换以及媲美主流机器学习工作流的端到端流程。通过将机器人技术和AI实践统一在Python生态下，ARK降低了入门门槛，加速了自主机器人的研究和商业部署。

</details>


### [276] [AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing](https://arxiv.org/abs/2506.21635)
**中文标题：AeroLite-MDNet：用于无人机着陆的轻量级多任务偏差检测网络**

*Haiping Yang,Huaxing Liu,Wei Wu,Zuohui Chen,Ning Wu*

主要分类: cs.RO

摘要简述: 本文提出了一种名为AeroLite-MDNet的轻量级多任务偏差检测网络，用于提升无人机着陆的准确性。通过多尺度融合模块和分割分支，模型实现了高效的偏差检测和方向估计，并引入新指标AWD和新数据集UAVLandData。实验表明，系统偏差检测准确率达98.6%，AWD为0.7秒。


<details>
  <summary>详细信息</summary>
研究动机: 无人机在任务完成后需安全着陆，但GPS信号干扰等问题导致着陆准确性难以保证。为此，本文旨在开发一种视觉偏差检测系统，提升无人机着陆的可靠性。

研究方法: 提出AeroLite-MDNet模型，集成多尺度融合模块以增强跨尺度目标检测能力，并加入分割分支用于方向估计。同时，引入新指标AWD和新数据集UAVLandData以支持训练和评估。

研究结果: 实验结果显示，系统偏差检测准确率达98.6%，平均警告延迟（AWD）为0.7秒，验证了其在提升无人机着陆可靠性方面的有效性。

研究结论: AeroLite-MDNet通过多任务设计和高效检测能力，显著提升了无人机着陆的准确性，为实际应用提供了可靠解决方案。

中文摘要: 无人机（UAV）在土地测绘、物资运输和环境监测等领域的应用日益广泛。任务完成后，无人机需安全着陆于停靠站以进行存储或充电，这是确保操作连续性的关键。然而，GPS信号干扰等因素使得精准着陆仍具挑战性。为此，我们提出了一种基于视觉的偏差预警系统，采用新型模型AeroLite-MDNet。该模型集成了多尺度融合模块以实现鲁棒的跨尺度目标检测，并包含分割分支以高效估计方向。我们引入了新指标平均警告延迟（AWD）以量化系统对着陆偏差的敏感性，并贡献了新数据集UAVLandData，用于支持训练和评估。实验结果表明，系统的AWD为0.7秒，偏差检测准确率达98.6%，有效提升了无人机着陆的可靠性。代码将在https://github.com/ITTTTTI/Maskyolo.git提供。

</details>


### [277] [Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation](https://arxiv.org/abs/2506.21732)
**中文标题：基于姿态信息的滑移转向视觉导航强化学习的实验研究**

*Ameya Salvi,Venkat Krovi*

主要分类: cs.RO

摘要简述: 本文提出了一种基于姿态信息的强化学习方法，用于滑移转向车辆的视觉导航，通过软件模拟和硬件实验验证了其优于现有方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 滑移转向车辆在视觉导航中的应用面临建模困难，尤其是滑移-滑动轮地交互的复杂性，导致自动化部署受限。端到端学习方法（如模仿学习和深度强化学习）成为替代方案，但其在动态操作中的系统化验证仍需改进。

研究方法: 提出了一种结构化学习视觉导航的新方法，结合姿态信息进行强化学习，并通过大量软件模拟、硬件评估和消融研究验证其有效性。

研究结果: 实验结果表明，该方法在性能上显著优于现有文献中的方法，尤其在动态操作环境中表现突出。

研究结论: 本文提出的方法为滑移转向车辆的视觉导航提供了一种有效的解决方案，通过系统化验证展示了其优越性能。

中文摘要: 视觉车道保持是机器人和自动驾驶地面车辆社区在多种道路和非道路应用中的重要课题。滑移转向车辆架构在人工控制操作中发挥了重要作用，但其系统化建模（尤其是在非道路环境中的滑移-滑动轮地交互）为自动化部署带来了瓶颈。端到端学习方法（如模仿学习和深度强化学习）作为缺乏精确分析模型的替代方案受到关注，但其在动态操作中的系统化验证仍需完善。为此，本文提出并研究了一种结构化学习视觉导航的新方法。通过大量软件模拟、硬件评估和消融研究，该方法在性能上显著优于现有文献中的方法。

</details>


### [278] [TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions](https://arxiv.org/abs/2506.21630)
**中文标题：TOMD：一种基于小径的越野多模态数据集，用于挑战性光照条件下的可通行路径分割**

*Yixin Sun,Li Li,Wenke E,Amir Atapour-Abarghouei,Toby P. Breckon*

主要分类: cs.RO

摘要简述: 本文介绍了TOMD数据集，专为复杂光照条件下的狭窄越野路径分割设计，并提出了一种动态多尺度数据融合模型，实验结果验证了方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有数据集和模型主要针对城市环境或宽阔的越野路径，无法满足狭窄、类似小径的越野场景需求，尤其是在搜索救援和森林火灾等关键应用中。

研究方法: 提出了TOMD数据集，包含128通道LiDAR、立体图像、GNSS、IMU和光照数据，并设计了一种动态多尺度数据融合模型，用于预测可通行路径。

研究结果: 实验结果表明，动态多尺度数据融合模型在复杂光照条件下表现优异，光照对分割性能有显著影响。

研究结论: TOMD数据集和提出的模型填补了狭窄越野路径分割的空白，为未来研究提供了支持。

中文摘要: 在非结构化的户外环境中检测可通行路径对自主机器人仍是一个重大挑战，尤其是在搜索救援和森林火灾等关键应用中。现有数据集和模型主要针对城市环境或宽阔的越野路径，未能解决狭窄、类似小径的越野场景的复杂性。为此，我们提出了基于小径的越野多模态数据集（TOMD），专为此类环境设计。TOMD包含高保真多模态传感器数据（如128通道LiDAR、立体图像、GNSS、IMU和光照测量），通过多次遍历不同条件收集。我们还提出了一种动态多尺度数据融合模型，用于准确预测可通行路径。研究分析了不同光照水平下早期、交叉和混合融合策略的性能。结果表明，我们的方法有效且光照对分割性能有重要影响。我们公开了TOMD数据集（https://github.com/yyyxs1125/TMOD），以支持未来基于小径的越野导航研究。

</details>


### [279] [Embodied Domain Adaptation for Object Detection](https://arxiv.org/abs/2506.21860)
**中文标题：面向物体检测的具身领域自适应**

*Xiangyu Shi,Yanyuan Qiao,Lingqiao Liu,Feras Dayoub*

主要分类: cs.RO

摘要简述: 本文提出了一种无需源数据的领域自适应方法（EDAOD），通过时间聚类和多尺度阈值融合优化伪标签，结合对比学习的Mean Teacher框架，显著提升了动态室内环境下的零样本检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 移动机器人在室内环境中依赖物体检测器进行感知和定位，但传统方法难以应对真实家庭和实验室中的多样物体和动态条件。开放词汇物体检测（OVOD）虽扩展了固定标签范围，但仍受限于室内环境的领域偏移问题。

研究方法: 提出了一种无源数据的领域自适应方法（SFDA），通过时间聚类优化伪标签，采用多尺度阈值融合，并结合Mean Teacher框架和对比学习，实现模型在动态室内环境中的自适应。

研究结果: 实验结果表明，该方法在零样本检测性能上取得显著提升，并能灵活适应光照、布局和物体多样性等动态变化。

研究结论: EDAOD方法有效解决了动态室内环境中的领域自适应问题，为移动机器人的物体检测提供了更灵活和鲁棒的解决方案。

中文摘要: 移动机器人依赖物体检测器在室内环境中进行感知和物体定位。然而，传统的封闭集方法难以应对真实家庭和实验室中多样化的物体和动态条件。开放词汇物体检测（OVOD）基于视觉语言模型（VLMs）扩展了固定标签范围，但仍受限于室内环境的领域偏移。我们提出了一种无源数据的领域自适应方法（SFDA），通过时间聚类优化伪标签，采用多尺度阈值融合，并结合Mean Teacher框架和对比学习。我们的面向物体检测的具身领域自适应（EDAOD）基准评估了在光照、布局和物体多样性连续变化下的自适应性能。实验结果表明，该方法在零样本检测性能和动态室内条件适应方面取得了显著提升。

</details>


### [280] [Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration](https://arxiv.org/abs/2506.22116)
**中文标题：评估人机协作中指向手势的目标选择效果**

*Noora Sassali,Roel Pieters*

主要分类: cs.RO

摘要简述: 本研究提出了一种基于姿态估计和几何模型的方法，用于在平面工作空间中定位指向手势的目标，并评估其在人机协作中的目标选择效果。


<details>
  <summary>详细信息</summary>
研究动机: 指向手势是人机协作中常用的交互方式，但如何准确识别和定位指向目标仍是一个挑战。本研究旨在开发一种方法，以提升指向手势在机器人任务中的目标选择准确性。

研究方法: 研究采用姿态估计技术，结合基于肩-腕伸展的简单几何模型，从RGB-D数据流中提取手势信息，并开发了一套评估指向手势和目标选择的严格方法。

研究结果: 研究不仅评估了工具的准确性，还将其集成到一个概念验证机器人系统中，展示了多模态（如物体检测、语音转录和合成）在协作应用中的整合效果。

研究结论: 研究讨论了工具的局限性和性能，为多模态机器人系统中指向手势的应用提供了参考。所有开发成果已开源。

中文摘要: 指向手势是人机协作中常用的交互方法，用于从选择目标到指导工业流程等多种任务。本研究提出了一种在平面工作空间中定位指向目标的方法。该方法利用姿态估计和基于肩-腕伸展的简单几何模型，从RGB-D数据流中提取手势数据。研究提出了一套严格的评估指向手势和目标选择的方法，并进行了全面分析。除了评估工具的准确性外，该工具还被集成到一个概念验证机器人系统中，展示了物体检测、语音转录和语音合成等多模态在协作应用中的整合。最后，研究讨论了工具的局限性和性能，以理解其在多模态机器人系统中的作用。所有开发成果可在以下链接获取：https://github.com/NMKsas/gesture_pointer.git。

</details>


### [281] [KnotDLO: Toward Interpretable Knot Tying](https://arxiv.org/abs/2506.22176)
**中文标题：KnotDLO：迈向可解释的打结方法**

*Holly Dinkel,Raghavendra Navaratna,Jingyi Xiang,Brian Coltin,Trey Smith,Timothy Bretl*

主要分类: cs.RO

摘要简述: KnotDLO是一种用于单手打结可变形线性物体（DLO）的方法，无需人类演示或训练，具有抗遮挡性、可重复性、可解释性，并能生成运动策略。在16次试验中，成功率为50%。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发一种无需人类演示或训练的方法，用于单手打结可变形线性物体（DLO），同时解决遮挡问题、适应不同初始配置，并生成可解释的运动策略。

研究方法: KnotDLO通过当前DLO形状规划抓取和目标路径点，利用分段线性曲线跟踪DLO状态，计算抓取姿势和中间路径点，并将视觉推理与控制分离。

研究结果: 在16次打结试验中，KnotDLO从未见过的配置中成功打结的成功率为50%。

研究结论: KnotDLO展示了一种无需人类干预的打结方法，具有抗遮挡性和可解释性，为未来研究提供了基础。

中文摘要: 本文提出KnotDLO，一种用于单手打结可变形线性物体（DLO）的方法，具有抗遮挡性、适应不同初始配置的可重复性、生成可解释运动策略的能力，且无需人类演示或训练。通过当前DLO形状规划抓取和目标路径点，抓取姿势基于分段线性曲线跟踪计算，中间路径点由当前和期望状态的几何形状确定。系统将视觉推理与控制分离。在16次打结试验中，KnotDLO从未见过的配置中成功打结的成功率为50%。

</details>
