<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 51]
- [cs.CV](#cs.CV) [Total: 65]
- [cs.AI](#cs.AI) [Total: 13]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]
- [cs.SE](#cs.SE) [Total: 2]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.GR](#cs.GR) [Total: 3]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 6]
- [stat.OT](#stat.OT) [Total: 1]
- [cs.HC](#cs.HC) [Total: 9]
- [econ.GN](#econ.GN) [Total: 1]
- [math.NA](#math.NA) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.SI](#cs.SI) [Total: 2]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.CE](#cs.CE) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 40]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.DC](#cs.DC) [Total: 2]
- [math.ST](#math.ST) [Total: 1]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 12]
- [cs.CY](#cs.CY) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
**中文标题：出院摘要中不良事件提取：新数据集、标注方案及初步发现**

*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

主要分类: cs.CL

摘要简述: 本文提出了一种针对老年患者出院摘要中不良事件（AE）提取的手动标注数据集，支持不连续和重叠实体标注，并评估了多粒度模型性能。结果显示，尽管文档级粗粒度任务表现优异（F1=0.943），细粒度任务（如罕见事件和复杂属性）仍有挑战（F1=0.675）。


<details>
  <summary>详细信息</summary>
研究动机: 老年患者在临床自然语言处理（NLP）资源中常被忽视，现有数据集对不良事件的标注缺乏对不连续和重叠实体的支持。本文旨在填补这一空白，提供一个更全面的标注方案和数据集。

研究方法: 研究构建了一个手动标注的老年患者出院摘要数据集，包含14种临床重要不良事件及其上下文属性（如否定、诊断类型等）。标注方案支持不连续和重叠实体。使用FlairNLP评估了多粒度模型（细粒度、粗粒度及带否定的粗粒度）。

研究结果: 基于Transformer的模型（如BERT-cased）在文档级粗粒度任务中表现优异（F1=0.943），但在细粒度任务中表现显著下降（F1=0.675），尤其是罕见事件和复杂属性的检测。

研究结论: 尽管粗粒度任务表现良好，细粒度不良事件提取仍面临挑战，特别是在罕见事件和复杂临床语言的捕捉上。数据集为未来研究提供了基准，支持跨数据集泛化。

中文摘要: 本研究提出了一个针对老年患者出院摘要中不良事件（AE）提取的手动标注语料库，填补了临床NLP资源中老年患者代表性不足的空白。数据集包含14种临床重要不良事件（如跌倒、谵妄和颅内出血）及其上下文属性（如否定、诊断类型和院内发生）。独特的标注方案支持不连续和重叠实体，解决了以往研究中较少涉及的挑战。我们使用FlairNLP评估了三种标注粒度（细粒度、粗粒度及带否定的粗粒度）的模型性能。基于Transformer的模型（如BERT-cased）在文档级粗粒度提取中表现优异（F1=0.943），但在细粒度实体级任务中表现显著下降（F1=0.675），尤其是罕见事件和复杂属性的检测。这些结果表明，尽管整体得分较高，但在检测代表性不足的不良事件和捕捉细微临床语言方面仍存在显著挑战。数据集在可信研究环境（TRE）中开发，可通过DataLoch申请获取，为评估不良事件提取方法和支持未来跨数据集泛化提供了有力基准。

</details>


### [2] [Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction](https://arxiv.org/abs/2506.14901)
**中文标题：通过增强结合约束和无约束解码：BoostCD及其在信息提取中的应用**

*Marija Šakota,Robert West*

主要分类: cs.CL

摘要简述: 本文提出了一种名为BoostCD的新方法，通过结合约束解码和无约束解码的两阶段解码策略，提升结构化NLP任务的输出质量。实验表明，该方法在信息提取任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前结构化NLP任务中，约束解码虽然能够动态调整输出结构，但在测试时可能导致输出质量下降。本文旨在通过结合约束和无约束解码的优势，解决这一问题。

研究方法: BoostCD采用两阶段解码：第一阶段分别进行约束和无约束解码，生成两个弱预测；第二阶段通过学习的自回归增强模型将两者结合为最终预测。

研究结果: 在封闭信息提取任务中，BoostCD的表现优于现有方法，尤其在分布内外数据上均显示出更强的鲁棒性。

研究结论: BoostCD通过结合约束和无约束解码，显著提升了结构化输出的质量，为NLP任务提供了一种有效的解决方案。

中文摘要: 许多结构化NLP任务的最新方法使用自回归语言模型$M$将非结构化输入文本$x$映射为表示结构化对象（如元组、列表、树、代码等）的输出文本$y$，其中通过约束解码强制实现所需的输出结构。在训练过程中，这些方法不需要模型了解约束条件，约束仅隐含在训练输出$y$中。这种方法的优点是可以动态调整约束而无需重新训练，但在测试时可能导致约束解码的输出质量较低。我们通过增强约束解码（BoostCD）克服了这一问题，该方法分两阶段结合约束和无约束解码：第一阶段从基础模型$M$分别进行约束和无约束解码，生成两个弱预测；第二阶段通过学习的自回归增强模型将两者结合为最终预测。基础模型在有约束和无约束情况下的错误往往是互补的，增强模型能够利用这一点提升性能。我们通过将BoostCD应用于封闭信息提取任务展示了其强大能力。我们的模型BoostIE在分布内外数据上均优于现有方法，解决了这些方法中常见的多个错误。

</details>


### [3] [CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision](https://arxiv.org/abs/2506.14912)
**中文标题：CrEst：基于弱监督的大语言模型上下文可信度评估**

*Dyah Adila,Shuai Zhang,Boran Han,Bonan Min,Yuyang Wang*

主要分类: cs.CL

摘要简述: CrEst是一种通过弱监督评估大语言模型（LLM）上下文可信度的新框架，无需人工标注，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法常忽略上下文文档的可信度问题，可能导致不可靠信息的传播，因此需要一种自动化评估可信度的解决方案。

研究方法: CrEst基于可信文档间语义一致性更高的假设，通过文档间一致性自动评估可信度，并提出黑盒和白盒两种集成策略。

研究结果: 实验表明，CrEst在三种模型架构和五个数据集上表现优异，准确率最高提升26.86%，F1分数提高3.49%，且在高噪声环境下仍稳健。

研究结论: CrEst为LLM上下文可信度评估提供了高效且无需人工标注的解决方案，显著提升了模型性能。

中文摘要: 上下文信息的整合显著提升了大语言模型（LLM）在知识密集型任务中的表现。然而，现有方法常忽略一个关键挑战：上下文文档的可信度差异较大，可能导致不可靠信息的传播。本文提出CrEst，一种无需人工标注的弱监督框架，用于在LLM推理过程中评估上下文文档的可信度。该方法基于可信文档间语义一致性更高的假设，通过文档间一致性实现自动化可信度评估。为将可信度融入LLM推理，我们提出两种集成策略：一种适用于无法访问内部权重或激活的黑盒模型，另一种是直接修改注意力机制的白盒方法。在三种模型架构和五个数据集上的广泛实验表明，CrEst始终优于基线方法，准确率最高提升26.86%，F1分数提高3.49%。进一步分析显示，CrEst在高噪声条件下仍保持稳健性能。

</details>


### [4] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
**中文标题：MDBench：基于知识引导合成的多文档推理基准**

*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

主要分类: cs.CL

摘要简述: MDBench是一个通过知识引导合成的多文档推理基准数据集，旨在评估大语言模型在多文档推理任务中的表现。该数据集通过结构化知识生成技术高效创建，并验证了现有模型在此任务上的挑战性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）推理能力的快速扩展，多文档（MD）推理任务因其对长上下文输入的处理能力而备受关注，但缺乏相关基准数据集。传统标注长输入的高成本也阻碍了此类数据集的创建。因此，研究者提出了MDBench，以填补这一空白。

研究方法: MDBench采用了一种新颖的合成生成方法：首先基于结构化的种子知识，通过LLM辅助编辑引入多文档推理的挑战；然后将结构化知识转换为自然文本形式，生成文档集及对应的问题-答案（QA）示例。这一方法高效且可控。

研究结果: 实验表明，MDBench对现有的大语言模型和提示技术均构成显著挑战，即使文档集较短。此外，知识引导生成技术能够针对多文档推理能力进行定向分析，并能快速适应新的挑战和模型改进。

研究结论: MDBench为多文档推理任务提供了一个高效且可控的基准数据集，填补了现有研究的空白。其生成方法不仅验证了模型的挑战性，还具备灵活性和可扩展性，为未来研究提供了重要工具。

中文摘要: 自然语言处理评估取得了显著进展，主要得益于强大大型语言模型（LLMs）的普及。随着LLMs推理能力的快速扩展，新的评估基准变得尤为重要。多文档（MD）推理因其对长上下文输入的处理能力而极具相关性，但现有基准较少且标注长输入成本高昂。为此，我们提出了MDBench，一个用于评估LLMs在多文档推理任务中的新数据集。MDBench通过一种新颖的合成生成方法创建，能够高效且可控地生成具有挑战性的文档集及对应的问题-答案（QA）示例。我们的技术基于结构化的种子知识，通过LLM辅助编辑引入多文档推理的挑战，并将其转换为自然文本形式。实验表明，MDBench对所有现有方法均构成显著挑战，即使文档集较短。此外，知识引导生成技术（1）支持对多文档推理能力的定向分析，（2）能快速适应新挑战和未来模型改进。

</details>


### [5] [From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?](https://arxiv.org/abs/2506.14949)
**中文标题：从聊天到检查：大型语言模型能否辅助糖尿病预测？**

*Shadman Sakib,Oishy Fatema Akhand,Ajwad Abrar*

主要分类: cs.CL

摘要简述: 本研究探讨了大型语言模型（LLMs）在糖尿病预测中的有效性，比较了开源与专有模型的性能，并发现专有模型（如GPT-4o）在少量样本提示下表现更优，甚至优于传统机器学习模型。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习和深度学习模型已广泛用于糖尿病预测，但大型语言模型（LLMs）在结构化数值数据中的应用尚未充分探索。本研究旨在填补这一空白。

研究方法: 使用Pima印度糖尿病数据库（PIDD），测试了六种LLMs（四种开源模型和两种专有模型）在零样本、单样本和三样本提示下的表现，并与随机森林、逻辑回归和支持向量机（SVM）等传统模型进行对比。评估指标包括准确率、精确率、召回率和F1分数。

研究结果: 专有LLMs（如GPT-4o和Gemma-2-27B）在少量样本提示下表现优于开源模型，其中Gemma-2-27B的F1分数甚至超过传统模型。但提示策略的差异和领域特定微调需求仍是问题。

研究结论: 研究表明LLMs可用于医疗预测任务，未来需进一步研究提示工程和混合方法以提升预测性能。

中文摘要: 虽然机器学习和深度学习模型已广泛用于糖尿病预测，但大型语言模型（LLMs）在结构化数值数据中的应用尚未充分探索。本研究测试了LLMs在零样本、单样本和三样本提示下预测糖尿病的有效性，并基于Pima印度糖尿病数据库（PIDD）进行了实证分析。评估了六种LLMs，包括四种开源模型（Gemma-2-27B、Mistral-7B、Llama-3.1-8B和Llama-3.2-2B）和两种专有模型（GPT-4o和Gemini Flash 2.0），并与随机森林、逻辑回归和支持向量机（SVM）等传统模型进行了对比。评估指标包括准确率、精确率、召回率和F1分数。结果显示，专有LLMs表现优于开源模型，GPT-4o和Gemma-2-27B在少量样本提示下准确率最高。值得注意的是，Gemma-2-27B的F1分数甚至超过了传统模型。然而，提示策略的差异和领域特定微调需求仍是问题。研究表明LLMs可用于医疗预测任务，并鼓励未来在提示工程和混合方法上的研究以提升医疗预测效果。

</details>


### [6] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
**中文标题：记忆令牌：大型语言模型可生成可逆句子嵌入**

*Ignacio Sastre,Aiala Rosá*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLM）可通过特殊记忆令牌生成可逆句子嵌入，实现原始文本的精确重构，无需修改模型权重。


<details>
  <summary>详细信息</summary>
研究动机: 探索大型语言模型是否能够生成可逆的句子嵌入，以支持精确的文本重构，并研究其在记忆检索、压缩和可控文本生成中的潜在应用。

研究方法: 通过引入特殊记忆令牌，其嵌入通过固定序列的训练进行优化。当模型接收到该嵌入时，能够精确重构原始序列。

研究结果: 在英语和西班牙语数据集上测试，序列长度可达约240个令牌，模型规模从1亿到80亿参数不等。Llama 3.1 8B成功重构所有测试序列。

研究结论: 研究揭示了大型语言模型的一种有趣能力，为记忆检索、压缩和可控文本生成提供了潜在应用方向。

中文摘要: 本研究发现了一种有趣的现象：无需修改模型权重，即可生成可逆的句子嵌入，使大型语言模型能够精确重构原始文本。这是通过引入一种特殊记忆令牌实现的，其嵌入通过固定序列的训练进行优化。当模型接收到该嵌入时，能够精确重构原始序列。我们在英语和西班牙语数据集上进行了评估，测试序列长度可达约240个令牌，模型规模从1亿到80亿参数不等。值得注意的是，Llama 3.1 8B成功重构了所有测试序列。这一发现揭示了大型语言模型的有趣能力，并为记忆检索、压缩和可控文本生成提供了潜在应用。

</details>


### [7] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
**中文标题：使用主题建模和文本分类方法识别NVDRS文本叙述中的社会隔离主题**

*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

主要分类: cs.CL

摘要简述: 利用主题建模和文本分类方法，从NVDRS文本叙述中识别社会隔离主题，发现男性、同性恋和离婚者更容易被分类为慢性社会隔离，为美国社会隔离和孤独感的监测与预防提供了新方法。


<details>
  <summary>详细信息</summary>
研究动机: 近年来社会隔离和孤独感显著增加，与自杀率密切相关。然而，美国国家暴力死亡报告系统（NVDRS）的结构化变量中未记录这些因素，因此需要通过自然语言处理技术从执法和法医叙述中识别社会隔离和孤独感。

研究方法: 使用主题建模生成词典开发，并结合监督学习分类器，开发高质量的分类器（平均F1值0.86，准确率0.82）。分析了2002年至2020年超过30万例自杀案例，识别出1,198例涉及慢性社会隔离。

研究结果: 研究发现，男性（OR=1.44）、同性恋（OR=3.68）和离婚者（OR=3.34）更容易被分类为慢性社会隔离。其他社会隔离主题的显著预测因素包括近期或即将离婚、失去子女监护权、被驱逐或近期搬家以及分手。

研究结论: 该方法可有效改进美国社会隔离和孤独感的监测与预防工作。

中文摘要: 近年来，社会隔离和孤独感显著增加，对自杀率产生了重要影响。尽管美国国家暴力死亡报告系统（NVDRS）的结构化变量中未记录社会隔离和孤独感，但可以通过自然语言处理（NLP）技术在执法和法医叙述中识别这些概念。我们利用主题建模生成词典开发，并结合监督学习分类器，开发了高质量的分类器（平均F1值0.86，准确率0.82）。通过评估2002年至2020年超过30万例自杀案例，我们识别出1,198例涉及慢性社会隔离。研究发现，男性（OR=1.44；CI：1.24,1.69，p<0.0001）、同性恋（OR=3.68；1.97,6.33，p<0.0001）和离婚者（OR=3.34；2.68,4.19，p<0.0001）更容易被分类为慢性社会隔离。我们还发现了其他社会隔离主题的显著预测因素，包括近期或即将离婚、失去子女监护权、被驱逐或近期搬家以及分手。我们的方法可以改进美国社会隔离和孤独感的监测与预防工作。

</details>


### [8] [Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation](https://arxiv.org/abs/2506.15068)
**中文标题：面向自由生成的语义感知奖励：开放式R1训练**

*Zongxia Li,Yapei Chang,Yuhang Zhou,Xiyang Wu,Zichao Liang,Yoo Yeon Sung,Jordan Lee Boyd-Graber*

主要分类: cs.CL

摘要简述: 本文提出PrefBERT模型，用于评估开放式长文本生成质量，并通过语义奖励指导GRPO训练，优于传统指标ROUGE-L和BERTScore。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法难以全面评估开放式长文本生成的质量，常忽略连贯性、风格或相关性，或受预训练数据偏见影响。本文旨在填补这一空白。

研究方法: 提出PrefBERT评分模型，基于多样长文本风格和Likert评分的响应评估数据集训练，为GRPO提供语义奖励反馈。

研究结果: PrefBERT在长段落中表现可靠，与人类偏好高度一致，其训练的模型生成结果优于传统指标训练的模型。

研究结论: PrefBERT为开放式长文本生成提供了更有效的评估和训练方法，显著提升了生成质量与人类偏好的一致性。

中文摘要: 评估开放式长文本生成具有挑战性，因为难以明确区分好与坏的输出。现有方法常忽略连贯性、风格或相关性，或受预训练数据偏见影响，导致开放式长文本评估问题未被充分探索。为解决这一问题，我们提出PrefBERT，一种评分模型，用于评估GRPO中的开放式长文本生成，并通过区分好与坏输出的奖励指导其训练。PrefBERT基于两种具有多样长文本风格和Likert评分质量的响应评估数据集训练，能够为GRPO提供比传统指标ROUGE-L和BERTScore更好的语义奖励反馈。通过综合评估（包括LLM作为评判、人工评分和定性分析），我们发现PrefBERT在多样长段落中表现可靠，且与GRPO所需的可验证奖励高度一致。人工评估证实，使用PrefBERT作为奖励信号训练策略模型，生成的响应比传统指标训练的模型更符合人类偏好。代码发布于https://github.com/zli12321/long_form_rl。

</details>


### [9] [Learning-Time Encoding Shapes Unlearning in LLMs](https://arxiv.org/abs/2506.15076)
**中文标题：学习阶段编码方式影响大型语言模型的遗忘能力**

*Ruihan Wu,Konstantin Garov,Kamalika Chaudhuri*

主要分类: cs.CL

摘要简述: 研究发现，学习阶段的知识编码方式对大型语言模型（LLM）的“遗忘”能力有显著影响，特别是使用转述描述学习可提升遗忘效果，但从文本块中遗忘单个知识仍具挑战性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在现实中的广泛应用，如何“遗忘”特定知识（如隐私数据或有害内容）变得至关重要。以往研究假设训练过程和目标模型固定，本文则探讨学习阶段知识编码对遗忘效果的影响。

研究方法: 通过实验研究学习阶段的知识编码方式（如使用转述描述）对遗忘效果的影响，并分析从文本块中遗忘单个知识的难度。

研究结果: 实验发现：（1）使用转述描述学习可提升遗忘性能；（2）从文本块中遗忘单个知识较为困难。

研究结论: 学习阶段的知识编码方式对实现可靠的遗忘至关重要，未来研究需关注如何优化学习过程以支持高效遗忘。

中文摘要: 随着大型语言模型（LLM）在现实中的广泛应用，如何“遗忘”或事后移除特定知识变得至关重要，原因包括隐私法规和修正过时或有害内容。以往研究提出了遗忘基准和算法，并通常假设训练过程和目标模型固定。本文通过实验研究学习阶段知识编码方式对遗忘事实知识效果的影响。实验揭示两个关键发现：（1）使用转述描述学习可提升遗忘性能；（2）从文本块中遗忘单个知识较为困难。结果表明，学习阶段的知识编码可能对实现可靠的事后遗忘起核心作用。

</details>


### [10] [Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification](https://arxiv.org/abs/2506.15081)
**中文标题：通过话语感知的澄清改进对话话语解析**

*Yaxin Fan,Peifeng Li,Qiaoming Zhu*

主要分类: cs.CL

摘要简述: 本文提出了一种基于话语感知的澄清模块（DCM）和贡献感知偏好优化（CPO）的方法，以解决对话话语解析中的歧义问题，显著提升了解析性能。


<details>
  <summary>详细信息</summary>
研究动机: 对话中的语言特征（如省略和习语）常导致话语关系模糊，给解析器带来挑战。本文旨在通过澄清模块和优化策略解决这一问题。

研究方法: 提出DCM模块，包含澄清类型推理和话语目标推理；引入CPO策略以减少错误澄清的负面影响，并通过反馈优化DCM。

研究结果: 在STAC和Molweni数据集上的实验表明，该方法有效消除歧义，性能显著优于现有基线。

研究结论: DCM和CPO的结合显著提升了对话话语解析的准确性，为解决歧义问题提供了有效方案。

中文摘要: 对话话语解析旨在识别和分析对话中话语之间的关系。然而，对话中的语言特征（如省略和习语）常引入歧义，掩盖了预期的话语关系，给解析器带来挑战。为解决这一问题，我们提出了一种话语感知澄清模块（DCM），以提升对话话语解析器的性能。DCM采用两种推理过程：澄清类型推理和话语目标推理。前者分析语言特征，后者从歧义中区分预期关系。此外，我们引入了贡献感知偏好优化（CPO），以减少错误澄清的风险，从而降低级联错误。CPO使解析器能够评估DCM澄清的贡献并提供反馈以优化DCM，增强其适应性和与解析器需求的匹配。在STAC和Molweni数据集上的大量实验表明，我们的方法有效解决了歧义问题，并显著优于现有基线。

</details>


### [11] [CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records](https://arxiv.org/abs/2506.15118)
**中文标题：CKD-EHR：基于电子健康记录的临床知识蒸馏**

*Junke Wang,Hongshun Ling,Li Zhang,Longqian Zhang,Fang Wang,Yuan Gao,Zhi Li*

主要分类: cs.CL

摘要简述: 本文提出CKD-EHR框架，通过知识蒸馏技术提升电子健康记录（EHR）的疾病预测效率与准确性，显著优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有大型语言模型在医疗知识表示不足和临床部署效率低下方面存在挑战，亟需一种高效且准确的解决方案。

研究方法: 首先微调Qwen2.5-7B作为教师模型，生成可解释的软标签；通过多粒度注意力蒸馏机制将知识迁移至轻量级BERT学生模型。

研究结果: 在MIMIC-III数据集上，CKD-EHR诊断准确率提升9%，F1分数提高27%，推理速度加快22.2倍。

研究结论: CKD-EHR显著提升资源利用效率和诊断准确性，为临床资源优化提供实用技术方案。

中文摘要: 基于电子健康记录（EHR）的疾病预测模型在推动精准医疗和早期干预方面具有重要临床价值。然而，现有大型语言模型面临两大挑战：医疗知识表示不足和临床部署效率低下。为解决这些问题，本研究提出CKD-EHR（基于EHR的临床知识蒸馏）框架，通过知识蒸馏技术实现高效且准确的疾病风险预测。具体而言，首先在医疗知识增强数据上微调大型语言模型Qwen2.5-7B作为教师模型，随后通过多粒度注意力蒸馏机制生成可解释的软标签，最终将蒸馏知识迁移至轻量级BERT学生模型。实验结果表明，在MIMIC-III数据集上，CKD-EHR显著优于基线模型：诊断准确率提升9%，F1分数提高27%，推理速度加快22.2倍。这一创新方案不仅大幅提升资源利用效率，还显著增强诊断准确性和时效性，为临床资源优化提供实用技术途径。本研究的代码和数据可在https://github.com/209506702/CKD_EHR获取。

</details>


### [12] [Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs](https://arxiv.org/abs/2506.15131)
**中文标题：利用大语言模型建模开放域对话中的一对多属性**

*Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan*

主要分类: cs.CL

摘要简述: 本文提出了一种两阶段框架，通过多响应生成和偏好选择任务，利用o2mDial数据集提升开放域对话的多样性和质量，使小模型性能接近大模型。


<details>
  <summary>详细信息</summary>
研究动机: 开放域对话具有一对多属性，现有大语言模型对话代理未明确建模此属性，导致响应多样性不足。本文旨在通过建模一对多属性提升对话多样性和质量。

研究方法: 将开放域对话生成分解为多响应生成（MRG）和偏好选择（PS）两阶段任务，引入o2mDial数据集，并提出新的上下文学习和指令调优策略及评估指标。

研究结果: 实验表明，该框架显著提升小模型的响应多样性和质量，响应质量最高提升90%，性能接近大模型。

研究结论: 通过两阶段框架和o2mDial数据集，成功建模开放域对话的一对多属性，为提升对话多样性和质量提供了有效方法。

中文摘要: 开放域对话（OD）具有一对多（o2m）属性，即单个对话上下文可对应多个合适响应。尽管先前研究表明建模此属性可提升响应多样性，但现有基于大语言模型（LLM）的对话代理大多未明确实现。本文通过将OD生成分解为多响应生成（MRG）和偏好选择（PS）两阶段任务，建模OD的o2m属性：首先生成一组语义和词汇多样化的高质量响应，随后基于人类偏好选择单一响应。为支持MRG和PS，我们引入o2mDial对话语料库，专为捕捉o2m属性设计，每个上下文包含多个合理响应。基于o2mDial，我们提出了新的上下文学习和指令调优策略、MRG评估指标及基于模型的PS方法。实验结果表明，将所提两阶段框架应用于小规模LLM进行OD生成，可显著提升响应多样性并保持上下文连贯性，响应质量最高提升90%，使其性能接近大规模模型。

</details>


### [13] [Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models](https://arxiv.org/abs/2506.15138)
**中文标题：Thunder-Tok：为生成语言模型设计的韩语文本分词最小化方法**

*Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Thunder-Tok的新型韩语分词器，旨在减少分词数量而不影响模型性能。通过基于规则的分词方法和语言学单元词汇表，显著降低了分词数量，同时保持模型表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前韩语分词器在生成语言模型中存在分词数量过多的问题，影响推理速度。本文旨在设计一种高效的分词器，减少分词数量而不牺牲性能。

研究方法: 采用基于规则的分词方法，结合语言学单元词汇表，并使用分支熵选择算法，以提高分词长度并降低分词数量。

研究结果: 实验表明，Thunder-Tok相比BPE分词器减少了约10%的分词数量，推理速度提升10%，且在下游任务中表现未受影响。

研究结论: Thunder-Tok通过语言学驱动的设计，证明了其在高效分词器设计中的实用性和有效性。

中文摘要: 本文介绍了Thunder-Tok，一种新型韩语分词器，旨在减少分词数量而不影响模型性能。我们采用基于规则的分词方法，与韩语的语言结构对齐，并构建包含语言学单元的分词种子词汇表，使用分支熵选择算法。这些方法提高了分词的平均长度，从而降低了分词数量，同时保留了语言学信息。实验结果表明，与BPE相比，Thunder-Tok减少了约10%的分词数量（即分词数量减少10%，推理速度提升10%），且在各种下游任务中性能未受影响。这些发现表明，我们基于语言学的设计方法在高效分词器设计中具有实际应用价值。

</details>


### [14] [Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View](https://arxiv.org/abs/2506.15156)
**中文标题：Mamba中首因与近因效应的涌现：机制视角**

*Muhammad Cendekia Airlangga,Hilal AlQuabeh,Munachiso S Nwadike,Kentaro Inui*

主要分类: cs.CL

摘要简述: 研究通过首因效应和近因效应分析Mamba架构中的记忆机制，发现长期记忆由稀疏通道支持，短期记忆受delta调制递归影响，记忆分配受语义规律动态调节。


<details>
  <summary>详细信息</summary>
研究动机: 通过首因效应和近因效应揭示状态空间语言模型中的信息保留与遗忘机制，以理解记忆在序列输入中的动态表现。

研究方法: 在Mamba架构上应用结构化召回任务，分析U形准确率曲线，并通过针对性消融和输入扰动验证机制。

研究结果: 发现长期记忆由稀疏通道支持，短期记忆受delta调制递归影响，记忆分配受语义规律动态调节，验证了这些机制在1.4B和7B参数模型中的有效性。

研究结论: Mamba架构中的记忆机制由稀疏通道、delta调制递归和语义规律共同作用，揭示了信息保留与遗忘的动态过程。

中文摘要: 我们通过首因效应和近因效应研究状态空间语言模型中的记忆，以揭示信息随时间保留与遗忘的机制。在Mamba架构上应用结构化召回任务时，观察到一致的U形准确率曲线，表明输入序列开头和结尾的表现较强。我们识别出三种导致这一模式的机制：首先，长期记忆由模型选择性状态空间块中的稀疏通道子集支持，这些通道持续编码早期输入标记并与首因效应因果关联；其次，短期记忆受delta调制递归支配，近期输入因指数衰减获得更多权重，但引入干扰项时近因优势崩溃，揭示了记忆深度的明确限制；第三，记忆分配受语义规律动态调节：输入序列中的重复关系改变delta门控行为，增加遗忘中间项的倾向。我们通过对两个大规模Mamba语言模型（1.4B和7B参数）的针对性消融和输入扰动验证了这些发现。

</details>


### [15] [A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals](https://arxiv.org/abs/2506.15208)
**中文标题：大型语言模型任务适应技术在识别可持续发展目标中的比较研究**

*Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi*

主要分类: cs.CL

摘要简述: 本研究比较了不同大型语言模型（LLMs）在识别联合国可持续发展目标（SDGs）的文本分类任务中的表现，并评估了零样本学习、少样本学习和微调等任务适应技术的效果。结果表明，通过提示工程优化的小型模型可以达到与大型模型（如GPT）相当的性能。


<details>
  <summary>详细信息</summary>
研究动机: 2012年联合国提出了17个可持续发展目标（SDGs），但追踪这些目标的进展因数据规模庞大且复杂而困难。文本分类模型和大型语言模型（LLMs）因其在自然语言处理任务中的卓越表现，成为解决这一问题的关键工具。本研究旨在探索LLMs在SDGs文本分类任务中的适应能力。

研究方法: 研究分析了专有和开源的大型语言模型（LLMs）在单标签多类文本分类任务中的表现，重点关注SDGs。同时，评估了零样本学习、少样本学习和微调等任务适应技术的效果。

研究结果: 研究发现，通过提示工程优化的小型模型在性能上可以与大型模型（如OpenAI的GPT）相媲美。

研究结论: 优化后的小型模型在SDGs文本分类任务中表现优异，为资源有限的研究提供了可行的解决方案。

中文摘要: 2012年，联合国提出了17个可持续发展目标（SDGs），旨在到203年创造一个更可持续和更美好的未来。然而，由于涉及数据的规模和复杂性，追踪这些目标的进展十分困难。文本分类模型已成为这一领域的重要工具，能够自动化分析来自各种来源的大量文本。此外，大型语言模型（LLMs）因其识别复杂语言模式和语义的能力，最近被证明在许多自然语言处理任务（包括文本分类）中不可或缺。本研究分析了专有和开源的LLMs在专注于SDGs的单标签多类文本分类任务中的表现，并评估了任务适应技术（即上下文学习方法，如零样本学习和少样本学习）以及微调在该领域的有效性。结果表明，通过提示工程优化的小型模型可以与OpenAI的GPT等大型模型表现相当。

</details>


### [16] [ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs](https://arxiv.org/abs/2506.15211)
**中文标题：ProtoReasoning：原型作为大语言模型通用推理的基础**

*Feng He,Zijun Chen,Xinnian Liang,Tingting Ma,Yunqi Qiu,Shuangzhi Wu,Junchi Yan*

主要分类: cs.CL

摘要简述: 本文提出ProtoReasoning框架，通过利用可扩展和可验证的原型表示（如Prolog和PDDL），增强大语言模型的推理能力。实验表明，该方法在逻辑推理、规划任务和数学等领域均优于基线模型，验证了原型作为通用推理基础的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型推理模型（LRMs）在跨领域推理中表现出色，但其背后的泛化机制尚不明确。本文假设跨领域泛化源于共享的抽象推理原型，这些原型能够捕捉问题的本质，从而支持模型在不同任务中的表现。

研究方法: ProtoReasoning框架包括：1）自动化原型构建流程，将问题转化为原型表示；2）通过Prolog/PDDL解释器提供可靠反馈的验证系统；3）在原型空间内合成问题并确保正确性的扩展能力。

研究结果: 实验结果显示，ProtoReasoning在逻辑推理（Enigmata-Eval）上提升4.7%，规划任务提升6.3%，通用推理（MMLU）提升4.0%，数学（AIME24）提升1.0%。消融研究证实，原型空间的学习比自然语言表示更具泛化性。

研究结论: ProtoReasoning验证了推理原型作为大语言模型通用推理基础的重要性，为模型跨领域泛化提供了理论支持。

中文摘要: 近期，基于长链思维推理（Long CoT）训练的大型推理模型（LRMs）展现了显著的跨领域泛化能力，但其背后的机制尚不明确。我们假设跨领域泛化源于共享的抽象推理原型——这些原型能够捕捉问题的本质，揭示看似多样的任务背后共享的推理结构。基于此，我们提出ProtoReasoning框架，通过可扩展且可验证的原型表示（如Prolog用于逻辑推理，PDDL用于规划）增强大语言模型的推理能力。ProtoReasoning的特点包括：1）自动化原型构建流程，将问题转化为原型表示；2）通过Prolog/PDDL解释器提供可靠反馈的验证系统；3）在原型空间内合成问题并确保正确性的扩展能力。大量实验表明，ProtoReasoning在逻辑推理（Enigmata-Eval）上比基线模型提升4.7%，规划任务提升6.3%，通用推理（MMLU）提升4.0%，数学（AIME24）提升1.0%。重要的是，消融研究证实，原型空间的学习比自然语言表示更能提升对结构相似问题的泛化能力，验证了推理原型作为大语言模型通用推理基础的假设。

</details>


### [17] [MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs](https://arxiv.org/abs/2506.15215)
**中文标题：MinosEval：区分事实性与非事实性问题以定制化评估LLMs的开放性问题回答**

*Yongqi Fan,Yating Wang,Guandong Wang,Jie Zhai,Jingping Liu,Qi Ye,Tong Ruan*

主要分类: cs.CL

摘要简述: 本文提出MinosEval方法，通过区分事实性和非事实性问题，采用不同策略评估开放性问题回答（QA），提升自动评估的准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 开放性问题回答（QA）评估对大型语言模型（LLMs）能力测试至关重要，但传统指标（如ROUGE和BERTScore）难以捕捉语义相似性，且现有LLM评估方法缺乏对不同问题类型的适应性。

研究方法: MinosEval首先区分事实性和非事实性问题，对事实性问题采用自适应关键点评分策略，对非事实性问题采用实例感知列表排序策略。

研究结果: 实验表明，MinosEval在多个开放QA数据集上更符合人工标注结果，并提供更可解释的评估。

研究结论: MinosEval通过区分问题类型并采用针对性策略，显著提升了开放QA评估的准确性和可解释性。

中文摘要: 开放性问题回答（QA）是评估大型语言模型（LLMs）能力的关键任务。与封闭式QA相比，它需要更长的回答、更细致的推理过程和多样化的表达，这使得精细且可解释的自动评估既重要又具有挑战性。传统指标（如ROUGE和BERTScore）由于模型回答与参考答案的模式差异，难以捕捉语义相似性。当前基于LLM的评估方法（如候选答案的成对或列表比较）缺乏直观可解释性。虽然对每个回答的点式评分提供了一些描述，但无法适应不同问题内容。最值得注意的是，现有方法忽略了事实性和非事实性问题的区别。为解决这些问题，我们提出\textbf{MinosEval}，一种新颖的评估方法，首先区分开放性问题，然后使用不同策略对候选答案进行排序。对于事实性问题，它采用自适应关键点评分策略；对于非事实性问题，则使用实例感知的列表排序策略。在多个开放QA数据集（包括自建数据集以补充社区资源）上的实验表明，MinosEval更符合人工标注，并提供更可解释的结果。

</details>


### [18] [Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants](https://arxiv.org/abs/2506.15239)
**中文标题：迷失在变体中？评估巴斯克语和西班牙语地理变体的自然语言推理性能**

*Jaione Bengoetxea,Itziar Gonzalez-Dios,Rodrigo Agerri*

主要分类: cs.CL

摘要简述: 本文评估了当前语言技术对巴斯克语和西班牙语变体的理解能力，发现语言模型在处理语言变体时性能下降，尤其是巴斯克语的西方变体。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估现有语言技术对巴斯克语和西班牙语不同地理变体的理解能力，揭示语言变体对自然语言推理任务的影响。

研究方法: 通过自然语言推理任务，使用编码器-解码器大语言模型进行跨语言和上下文学习实验，并引入手动整理的平行数据集。

研究结果: 实验结果显示，语言模型在处理语言变体时性能下降，尤其是巴斯克语的西方变体，且性能下降与语言变体本身而非词汇重叠相关。

研究结论: 语言模型在处理语言变体时存在挑战，尤其是远离标准方言的变体，未来需改进模型对语言多样性的适应性。

中文摘要: 本文评估了当前语言技术对巴斯克语和西班牙语变体的理解能力。我们以自然语言推理任务为核心，引入了一个手动整理的巴斯克语和西班牙语及其变体的平行数据集。通过对编码器-解码器大语言模型的跨语言和上下文学习实验的实证分析，发现语言模型在处理语言变体时性能下降，尤其是巴斯克语。错误分析表明，这种下降并非由词汇重叠引起，而是语言变体本身所致。进一步的消融实验显示，编码器模型在处理巴斯克语的西方变体时尤为困难，这与语言学理论中认为边缘方言（如西方变体）与标准方言差异更大的观点一致。所有数据和代码均已公开。

</details>


### [19] [Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs](https://arxiv.org/abs/2506.15241)
**中文标题：基于历史文本知识图谱的图检索增强生成研究**

*Yang Fan,Zhang Qi,Xing Wenqian,Liu Chang,Liu Liu*

主要分类: cs.CL

摘要简述: 本文提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，构建历史文本知识图谱，降低人工标注成本，提升通用模型与历史知识的对齐效果。实验表明，该方法在关系抽取任务中表现优异，有效缓解幻觉现象并提高可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 针对通用大语言模型在历史文本分析中的领域知识不足问题，本文旨在通过知识图谱与检索增强生成的协同机制，填补这一空白，推动历史知识服务和人文研究的发展。

研究方法: 提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，构建《前四史》人物关系数据集，并设计知识图谱与检索增强生成的协作机制，优化模型性能。

研究结果: 实验结果显示，领域专用模型Xunzi-Qwen1.5-14B在关系抽取任务中F1值为0.68；集成GraphRAG的DeepSeek模型在开放域C-CLUE数据集上F1提升11%，超越Xunzi-Qwen1.5-14B，有效缓解幻觉现象并提高可解释性。

研究结论: Graph RAG框架为古典文本知识提取提供了低资源解决方案，显著提升了历史知识服务和人文研究的效率与质量。

中文摘要: 本文针对通用大语言模型在计算人文和AIGC技术背景下历史文本分析中的领域知识不足问题，提出了Graph RAG框架。该框架结合思维链提示、自指令生成和过程监督，构建了《前四史》人物关系数据集，支持自动化历史知识提取，降低人工成本。在图增强生成阶段，引入知识图谱与检索增强生成的协作机制，提升通用模型与历史知识的对齐效果。实验表明，领域专用模型Xunzi-Qwen1.5-14B在简体中文输入和思维链提示下，关系抽取任务表现最优（F1=0.68）。集成GraphRAG的DeepSeek模型在开放域C-CLUE关系抽取数据集上F1提升11%（0.08-0.19），超越Xunzi-Qwen1.5-14B（0.12），有效缓解幻觉现象并提高可解释性。该框架为古典文本知识提取提供了低资源解决方案，推动了历史知识服务和人文研究的进展。

</details>


### [20] [TopClustRAG at SIGIR 2025 LiveRAG Challenge](https://arxiv.org/abs/2506.15246)
**中文标题：TopClustRAG在SIGIR 2025 LiveRAG挑战赛中的应用**

*Juli Bakagianni,John Pavlopoulos,Aristidis Likas*

主要分类: cs.CL

摘要简述: TopClustRAG是一个用于LiveRAG挑战赛的检索增强生成系统，通过混合检索策略和聚类技术提升问答的多样性和准确性，在FineWeb数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: LiveRAG挑战赛旨在评估大规模网络语料库上的端到端问答系统。TopClustRAG的目标是通过结合稀疏和密集检索技术，以及聚类方法，提升生成答案的多样性、相关性和忠实性。

研究方法: TopClustRAG采用混合检索策略（稀疏和密集索引），结合K-Means聚类对语义相似的段落分组，生成聚类特定提示供大语言模型生成中间答案，再经过过滤、重排和综合，生成最终答案。

研究结果: 在FineWeb Sample-10BT数据集上，TopClustRAG在忠实性排名第2，正确性排名第7，验证了聚类和提示聚合在大规模RAG系统中的有效性。

研究结论: TopClustRAG通过聚类和混合检索策略显著提升了生成答案的质量，为大规模RAG系统的优化提供了有效方法。

中文摘要: 我们提出了TopClustRAG，一个为LiveRAG挑战赛开发的检索增强生成（RAG）系统，该挑战赛旨在评估大规模网络语料库上的端到端问答性能。我们的系统采用混合检索策略，结合稀疏和密集索引，并通过K-Means聚类对语义相似的段落进行分组。每个聚类的代表性段落用于为大语言模型（LLM）构建特定提示，生成中间答案，再经过过滤、重排和综合，形成最终的全面回答。这种多阶段流程增强了答案的多样性、相关性和对检索证据的忠实性。在FineWeb Sample-10BT数据集上的评估显示，TopClustRAG在官方排行榜中忠实性排名第2，正确性排名第7，证明了基于聚类的上下文过滤和提示聚合在大规模RAG系统中的有效性。

</details>


### [21] [Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments](https://arxiv.org/abs/2506.15266)
**中文标题：Thunder-DeID：针对韩国法院判决的精准高效去标识化框架**

*Sungen Hahm,Heejin Kim,Gyuseong Lee,Hyunji Park,Jaejin Lee*

主要分类: cs.CL

摘要简述: 韩国司法系统要求对法院判决进行去标识化处理以平衡司法公开与个人数据保护，但现有方法效率低下且法律定义模糊。为此，研究者提出Thunder-DeID框架，通过构建首个韩语法律数据集、系统化分类个人身份信息（PII）及开发端到端DNN去标识化流程，实现了高效且合规的去标识化。


<details>
  <summary>详细信息</summary>
研究动机: 韩国司法系统要求在公开法院判决前进行去标识化处理，但现有方法无法满足大规模处理需求且法律定义模糊，亟需一种高效且符合法律要求的解决方案。

研究方法: 研究团队构建了首个包含标注判决和实体提及列表的韩语法律数据集，系统化分类了个人身份信息（PII），并开发了基于深度神经网络（DNN）的端到端去标识化流程。

研究结果: 实验结果表明，Thunder-DeID框架在法院判决的去标识化任务中达到了最先进的性能。

研究结论: Thunder-DeID框架通过结合法律合规性与技术高效性，为韩国法院判决的去标识化提供了可行的解决方案。

中文摘要: 为确保司法公开与个人数据保护的平衡，韩国司法系统要求在公开法院判决前进行去标识化处理。然而，当前的去标识化方法无法满足大规模处理需求，且法律对个人标识符的定义模糊，不利于技术实现。为解决这些问题，我们提出了Thunder-DeID去标识化框架，该框架符合相关法律与实践要求。具体而言，我们（i）构建并发布了首个包含标注判决及实体提及列表的韩语法律数据集，（ii）系统化分类了个人身份信息（PII），（iii）开发了基于深度神经网络（DNN）的端到端去标识化流程。实验结果表明，我们的模型在法院判决的去标识化任务中达到了最先进的性能。

</details>


### [22] [Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment](https://arxiv.org/abs/2506.15301)
**中文标题：队列发现：LLM辅助临床试验招募综述**

*Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff*

主要分类: cs.CL

摘要简述: 本文综述了LLM在临床试验招募中的应用，分析了现有方法的局限性，并探讨了未来发展方向。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM在通用NLP任务中表现优异，但在临床试验招募等关键领域的应用仍有限。本文旨在探讨LLM如何通过知识整合和推理能力改进试验与患者的匹配任务。

研究方法: 本文通过综述现有LLM辅助方法，分析其依赖专有模型和弱评估基准的问题，并探讨了临床试验招募中的任务匹配和LLM技术的应用。

研究结果: 研究发现，现有方法存在依赖专有模型和评估基准不足的问题，但LLM在临床试验招募中具有潜力，尤其是在知识整合和推理方面。

研究结论: LLM在临床试验招募中具有广阔前景，但需解决专有模型依赖和评估基准不足的挑战，未来研究应关注更通用的解决方案。

中文摘要: 近年来，LLM在通用NLP任务中取得了显著进展，但在临床试验招募等关键领域的应用仍有限。由于试验设计采用自然语言，患者数据以结构化和非结构化文本形式呈现，LLM的知识整合和推理能力有助于改进试验与患者的匹配任务。传统方法针对特定试验，而LLM通过整合分布式知识，有望构建更通用的解决方案。然而，近期LLM辅助方法的应用依赖专有模型和弱评估基准。本综述首次分析了试验与患者匹配任务，并将新兴的基于LLM的方法置于临床试验招募的背景下。我们批判性地评估了现有基准、方法和评估框架，探讨了LLM技术在临床研究中应用的挑战及未来发展方向。

</details>


### [23] [ConLID: Supervised Contrastive Learning for Low-Resource Language Identification](https://arxiv.org/abs/2506.15304)
**中文标题：ConLID：基于监督对比学习的低资源语言识别方法**

*Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut*

主要分类: cs.CL

摘要简述: 本文提出了一种基于监督对比学习（SCL）的新方法ConLID，用于解决低资源语言识别（LID）中的类别不平衡和领域偏差问题，显著提升了低资源语言在跨域数据上的识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语言在语言识别任务中表现较差，主要由于训练数据单一（如圣经等单领域数据）导致的类别不平衡和领域偏差问题。本文旨在通过监督对比学习提升低资源语言的跨域识别能力。

研究方法: 提出了一种监督对比学习（SCL）方法ConLID，通过学习领域不变的表征来解决低资源语言的识别问题。该方法通过对比学习增强模型对跨域数据的泛化能力。

研究结果: 实验表明，ConLID方法将低资源语言在跨域数据上的识别性能提升了3.2%，验证了其有效性。

研究结论: ConLID通过监督对比学习显著提升了低资源语言的跨域识别能力，为解决类别不平衡和领域偏差问题提供了有效方案。

中文摘要: 语言识别（LID）是从网络爬取数据中构建多语言LLM预训练语料库的关键步骤。尽管许多关于LID模型训练的研究集中于收集多样化的训练数据以提高性能，但低资源语言（通常仅限于单领域数据，如圣经）的表现仍然较差。为解决这些类别不平衡和偏差问题，我们提出了一种新颖的监督对比学习（SCL）方法，用于学习低资源语言的领域不变表征。通过广泛分析，我们表明该方法将低资源语言在跨域数据上的LID性能提升了3.2%，证明了其在增强LID模型方面的有效性。

</details>


### [24] [DeVisE: Behavioral Testing of Medical Large Language Models](https://arxiv.org/abs/2506.15339)
**中文标题：DeVisE：医疗大语言模型的行为测试**

*Camila Zurdo Tagliabue,Heloisa Oss Boll,Aykut Erdem,Erkut Erdem,Iacer Calixto*

主要分类: cs.CL

摘要简述: 本文提出DeVisE框架，用于测试医疗大语言模型（LLMs）的行为表现，通过对比真实和合成数据评估模型对人口统计和生命体征的敏感性，发现零样本模型更连贯，而微调模型更稳定但临床敏感性较低。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估方法难以区分医疗大语言模型的真实推理能力与表面模式，因此需要一种行为测试框架来深入评估其临床理解能力。

研究方法: 利用MIMIC-IV的ICU出院记录构建数据集，生成真实和模板化（合成）版本，并控制单变量反事实（如人口统计和生命体征）。评估五种LLM在零样本和微调设置下的表现，通过输入级敏感性和下游推理（如住院时长预测）分析模型行为。

研究结果: 零样本模型的反事实推理更连贯，而微调模型更稳定但对临床变化的响应较弱。人口统计因素对输出有微妙但持续的影响，凸显公平性评估的重要性。

研究结论: 行为测试能揭示临床LLM的推理策略，为设计更安全、透明的医疗AI系统提供依据。

中文摘要: 大语言模型（LLMs）在临床决策支持中的应用日益广泛，但现有评估方法常难以区分真实医疗推理与表面模式。我们提出DeVisE（人口统计与生命体征评估），一种行为测试框架，用于探究细粒度临床理解。基于MIMIC-IV的ICU出院记录，构建了真实和模板化（合成）版本的数据集，并控制单变量反事实（如人口统计和生命体征）。评估了五种LLM（包括通用和医疗微调变体）在零样本和微调设置下的表现，通过（1）输入级敏感性（反事实如何改变记录的可能性）和（2）下游推理（如何影响预测住院时长）分析模型行为。结果显示，零样本模型的反事实推理更连贯，而微调模型更稳定但对临床变化的响应较弱。值得注意的是，人口统计因素对输出有微妙但持续的影响，强调了公平性评估的重要性。这项工作凸显了行为测试在揭示临床LLM推理策略及设计更安全、透明医疗AI系统中的价值。

</details>


### [25] [SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture](https://arxiv.org/abs/2506.15355)
**中文标题：SANSKRITI：一个评估语言模型对印度文化知识的综合基准**

*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Sriparna Saha*

主要分类: cs.CL

摘要简述: 本文介绍了SANSKRITI，一个用于评估语言模型对印度文化理解能力的综合基准数据集，包含21,853个问题-答案对，覆盖印度28个邦和8个中央直辖区，涵盖16个文化属性。测试发现主流语言模型在文化相关查询上表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型在现代工作流程中不可或缺，但其全球有效性依赖于对本地社会文化背景的理解。目前缺乏评估语言模型对印度文化理解能力的标准数据集，因此作者提出了SANSKRITI。

研究方法: 作者构建了SANSKRITI数据集，包含21,853个精心设计的问题-答案对，覆盖印度28个邦和8个中央直辖区，涵盖16个文化属性。随后在主流大型语言模型（LLMs）、印度语言模型（ILMs）和小型语言模型（SLMs）上进行了评估。

研究结果: 评估结果显示，主流语言模型在处理文化相关查询时存在显著差异，许多模型在地区特定语境下表现不佳。

研究结论: SANSKRITI为评估和改进语言模型的文化理解能力设定了新标准，提供了一个广泛、文化丰富且多样化的数据集。

中文摘要: 语言模型（LMs）是塑造现代工作流程不可或缺的工具，但其全球有效性依赖于对本地社会文化背景的理解。为此，我们提出了SANSKRITI，一个用于评估语言模型对印度丰富文化多样性理解能力的基准。SANSKRITI包含21,853个精心设计的问题-答案对，覆盖印度28个邦和8个中央直辖区，是测试印度文化知识的最大数据集。它涵盖了印度文化的16个关键属性：仪式与典礼、历史、旅游、美食、舞蹈与音乐、服饰、语言、艺术、节日、宗教、医学、交通、体育、夜生活和名人，全面展现了印度的文化图景。我们在主流大型语言模型（LLMs）、印度语言模型（ILMs）和小型语言模型（SLMs）上评估了SANSKRITI，发现这些模型在处理文化相关查询时存在显著差异，许多模型在地区特定语境下表现不佳。通过提供一个广泛、文化丰富且多样化的数据集，SANSKRITI为评估和改进语言模型的文化理解能力设定了新标准。

</details>


### [26] [COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation](https://arxiv.org/abs/2506.15372)
**中文标题：COSMMIC：面向摘要和标题生成的评论敏感多模态多语言印度语语料库**

*Raghvendra Kumar,S. A. Mohammed Salman,Aryan Sahu,Tridib Nandi,Pragathi Y. P.,Sriparna Saha,Jose G. Moreno*

主要分类: cs.CL

摘要简述: 本文介绍了COSMMIC，一个针对印度语言的多模态多语言数据集，包含文章、图片和读者评论，用于摘要和标题生成任务。通过整合文本、评论和图像，研究评估了不同配置的效果，并采用先进模型验证了数据集的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管英语和中文的多模态多语言摘要研究已取得进展，但印度语言的相关研究仍显不足。本研究旨在填补这一空白，通过创建首个结合评论的多模态多语言印度语数据集，推动印度语言的NLP研究。

研究方法: 研究构建了包含4,959篇文章-图片对和24,484条评论的COSMMIC数据集，涵盖九种印度语言。采用四种配置（仅文本、文本+评论、文本+图片、文本+评论+图片）进行摘要和标题生成实验，并使用LLama3、GPT-4等模型评估效果。此外，通过IndicBERT过滤噪声评论，并利用多语言CLIP分类器提取图像信息。

研究结果: 实验表明，结合文本、评论和图像的多模态配置效果最佳。数据集为印度语言的摘要和标题生成任务提供了实用资源，并验证了多模态整合的优越性。

研究结论: COSMMIC填补了印度语言多模态数据集的空白，为NLP研究提供了新资源。整合用户反馈和图像信息显著提升了摘要生成质量，推动了多语言和多模态研究的包容性发展。

中文摘要: 尽管针对英语和中文的评论感知多模态多语言摘要研究已取得进展，但印度语言的相关研究仍显不足。本研究通过引入COSMMIC填补了这一空白，这是一个开创性的评论敏感多模态多语言数据集，涵盖九种主要印度语言。COSMMIC包含4,959篇文章-图片对和24,484条读者评论，并提供所有语言的真实摘要。我们的方法通过整合读者见解和反馈改进了摘要质量。我们探索了四种配置下的摘要和标题生成：（1）仅使用文章文本，（2）结合用户评论，（3）利用图像，（4）整合文本、评论和图像。为评估数据集的有效性，我们采用了LLama3和GPT-4等先进语言模型。通过全面研究不同组件的组合，包括使用IndicBERT过滤噪声评论，以及利用多语言CLIP分类器提取图像信息，我们确定了自然语言生成（NLG）任务的最有效配置。与许多现有数据集不同，COSMMIC独特地整合了文本、图像和用户反馈，为印度语言资源填补了空白，推动了NLP研究的包容性发展。

</details>


### [27] [Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning](https://arxiv.org/abs/2506.15415)
**中文标题：目标词汇注入：通过早期层LoRA微调解锁Lugha-Llama中的潜在跨语言对齐**

*Stanley Ngugi*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“目标词汇注入”（TLI）的高效微调方法，通过早期层的LoRA微调，显著提升了低资源语言（如斯瓦希里语）在大型语言模型中的跨语言词汇对齐能力。实验表明，TLI将训练词汇对的相似度提升了28.08%，并在未见词汇对上表现出良好的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在低资源语言（如斯瓦希里语）中表现不佳，主要由于数据稀缺和预训练中的代表性不足。跨语言词汇对齐是关键挑战，对翻译和跨语言信息检索等任务至关重要。本文旨在通过高效微调方法提升模型在低资源语言中的词汇对齐能力。

研究方法: 本文提出目标词汇注入（TLI）方法，利用低秩适应（LoRA）和对比学习目标，针对模型早期层（如第2层）的嵌入进行微调。实验基于Lugha-Llama-8B-wura模型，该模型在早期层表现出近乎完美的斯瓦希里语-英语词汇对齐能力。

研究结果: 实验结果显示，TLI显著提升了623个训练词汇对的相似度（从0.3211提升至0.4113，+28.08%），并在63个未见词汇对上表现出良好的泛化能力（相似度从0.3143提升至0.4033，+28.32%）。

研究结论: TLI通过早期层微调，有效增强了模型保留和传播其固有跨语言知识的能力，为低资源语言模型的词汇对齐提供了一种参数高效且有效的策略。

中文摘要: 大型语言模型（LLMs）表现出卓越的能力，但在低资源语言（如斯瓦希里语）中表现不佳，主要由于数据稀缺和预训练中的代表性不足。跨语言词汇对齐是关键挑战，对翻译和跨语言信息检索等任务至关重要。本文提出目标词汇注入（TLI），一种新颖高效的微调方法。我们首先证明，以斯瓦希里语为中心的Lugha-Llama-8B-wura模型在其早期内部层（特别是第2层，基于初步研究的平均余弦相似度约为0.99998）表现出近乎完美的斯瓦希里语-英语词汇对齐能力，但其最终输出表示中未完全体现（基线相似度约为0.32）。TLI利用这一发现，通过低秩适应（LoRA）和对比学习目标对模型进行微调，特别针对这一经验确定的最佳早期层的嵌入。实验表明，TLI显著提升了623个训练斯瓦希里语-英语词汇对的输出级词汇对齐，平均余弦相似度从0.3211提升至0.4113（+28.08%，p < 1.33 x 10^-240）。更重要的是，这些改进在63个未见控制词汇对上表现出显著的泛化能力，相似度从0.3143提升至0.4033（+28.32%，p < 7.17 x 10^-27）。这些发现表明，TLI增强了模型保留和传播其固有早期层跨语言知识的能力，为提升低资源语言模型的词汇对齐提供了一种参数高效且有效的策略。

</details>


### [28] [Understanding GUI Agent Localization Biases through Logit Sharpness](https://arxiv.org/abs/2506.15425)
**中文标题：通过Logit锐度理解GUI代理定位偏差**

*Xingjian Tao,Yiwei Wang,Yujun Cai,Zhicheng Yang,Jing Tang*

主要分类: cs.CL

摘要简述: 本文提出了一种细粒度评估框架和Peak Sharpness Score（PSS）指标，用于分析GUI代理的定位偏差，并通过Context-Aware Cropping技术提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在GUI代理中表现出色，但其定位错误（幻觉）问题严重影响了可靠性。本文旨在揭示这些错误的细微模式，并提出量化模型不确定性的方法。

研究方法: 1. 提出四类预测分类的细粒度评估框架；2. 引入Peak Sharpness Score（PSS）量化坐标预测中的语义连续性与logits分布的对齐；3. 提出无需训练的Context-Aware Cropping技术，通过自适应优化输入上下文提升性能。

研究结果: 实验表明，该框架和方法能够提供可操作的见解，显著提升GUI代理行为的可解释性和鲁棒性。

研究结论: 本文提出的框架和PSS指标为GUI代理的定位偏差提供了深入分析，Context-Aware Cropping技术进一步提升了模型性能，增强了可靠性。

中文摘要: 多模态大语言模型（MLLMs）使GUI代理能够通过将语言与空间动作结合来与操作系统交互。尽管性能优异，这些模型常出现幻觉——系统性定位错误，影响可靠性。我们提出了一种细粒度评估框架，将模型预测分为四类，揭示传统准确率指标之外的细微失败模式。为更好量化模型不确定性，我们引入了Peak Sharpness Score（PSS），评估坐标预测中语义连续性与logits分布的对齐。基于此，我们进一步提出Context-Aware Cropping，一种无需训练的技术，通过自适应优化输入上下文提升模型性能。大量实验表明，我们的框架和方法提供了可操作的见解，增强了GUI代理行为的可解释性和鲁棒性。

</details>


### [29] [AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need](https://arxiv.org/abs/2506.15451)
**中文标题：AgentGroupChat-V2：分治是LLM多智能体系统的关键**

*Zhouhong Gu,Xiaoxuan Zhu,Yin Cai,Hao Shen,Xingzhou Chen,Qingyi Wang,Jialin Li,Xiaoran Shi,Haoran Guo,Wenxuan Huang,Hongwei Feng,Yanghua Xiao,Zheyu Ye,Yao Hu,Shaosheng Cao*

主要分类: cs.CL

摘要简述: 本文提出AgentGroupChat-V2框架，通过分治并行架构、自适应协作引擎和代理组织优化策略，解决了基于大语言模型的多智能体系统在复杂任务中的性能问题，显著提升了跨领域任务的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大语言模型的多智能体系统在系统架构设计、跨领域泛化性和性能保障方面面临挑战，尤其是在任务复杂性和智能体数量增加时。本文旨在通过分治策略和动态协作机制，构建一个高效、通用的多智能体系统框架。

研究方法: 1. 分治并行架构：将用户查询分解为层次化任务森林结构，支持依赖管理和分布式并发处理。2. 自适应协作引擎：根据任务特性动态选择异构LLM组合和交互模式。3. 代理组织优化策略：结合分治方法实现高效问题分解。

研究结果: 实验表明，AgentGroupChat-V2在多个领域表现优异：GSM8K准确率达91.50%（超过最佳基线5.6个百分点），AIME竞赛级任务准确率30.4%（接近其他方法的两倍），HumanEval pass@1达79.20%。任务难度越高，性能优势越显著，如Level 5 MATH问题改进超过11个百分点。

研究结论: AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，在复杂推理场景中具有显著优势。

中文摘要: 基于大语言模型的多智能体系统在社交模拟和复杂任务解决领域展现出巨大潜力。然而，当前框架在系统架构设计、跨领域泛化性和性能保障方面面临关键挑战，尤其是随着任务复杂性和智能体数量的增加。我们提出了AgentGroupChat-V2，通过三项核心创新解决这些挑战：（1）分治全并行架构，将用户查询分解为层次化任务森林结构，支持依赖管理和分布式并发处理；（2）自适应协作引擎，根据任务特性动态选择异构LLM组合和交互模式；（3）结合分治方法的代理组织优化策略，实现高效问题分解。大量实验表明，AgentGroupChat-V2在多个领域表现卓越：GSM8K准确率达91.50%（超过最佳基线5.6个百分点），AIME竞赛级任务准确率30.4%（接近其他方法的两倍），HumanEval pass@1达79.20%。任务难度越高，性能优势越显著，如Level 5 MATH问题改进超过11个百分点。这些结果证实，AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，在复杂推理场景中具有显著优势。代码发布于https://github.com/MikeGu721/AgentGroupChat-V2。

</details>


### [30] [RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation](https://arxiv.org/abs/2506.15455)
**中文标题：RE-IMAGINE：用于推理评估的符号化基准合成**

*Xinnuo Xu,Rachel Lawrence,Kshitij Dubey,Atharva Pandey,Risa Ueno,Fabian Falck,Aditya V. Nori,Rahul Sharma,Amit Sharma,Javier Gonzalez*

主要分类: cs.CL

摘要简述: 本文提出RE-IMAGINE框架，用于评估大型语言模型（LLMs）的真实推理能力，通过生成符号化问题变体揭示模型是否依赖统计记忆而非真正推理。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理任务中表现优异，但其高准确率是否源于真正的推理能力还是训练数据的统计记忆尚不明确。受因果阶梯理论启发，本文旨在构建一个层次化评估框架，以区分模型的推理能力。

研究方法: RE-IMAGINE框架通过中间符号表示生成问题变体，覆盖数学、代码和逻辑等领域，并自动生成无法仅靠记忆解决的问题。该框架在四个广泛使用的基准测试中评估了多类LLMs。

研究结果: 实验表明，当模型面对问题变体时，性能显著下降，揭示了其对统计记忆的依赖程度，并验证了框架的有效性。

研究结论: RE-IMAGINE为评估LLMs的推理能力提供了通用工具，揭示了当前模型的局限性，并为未来研究指明了方向。

中文摘要: 近年来，大型语言模型（LLMs）在推理基准测试中表现出高准确率。然而，这些结果是否源于真正的推理能力还是训练数据的统计记忆仍不明确。受因果阶梯理论（Pearl, 2009）及其三个层次（关联、干预和反事实）的启发，本文提出了RE-IMAGINE框架，用于刻画LLMs的推理能力层次，并提供了一个自动化流程，以生成不同层次的问题变体。通过改变中间符号表示的问题，RE-IMAGINE能够生成任意数量无法仅靠记忆解决的问题。此外，该框架具有通用性，适用于数学、代码和逻辑等多个推理领域。我们在四个广泛使用的基准测试中验证了该框架，并观察到模型在面对问题变体时性能下降。这些评估揭示了模型对统计记忆的依赖程度，并为未来研究指明了方向。

</details>


### [31] [Context-Informed Grounding Supervision](https://arxiv.org/abs/2506.15480)
**中文标题：基于上下文信息的接地监督**

*Hyunji Lee,Seunghyun Yoon,Yunjae Won,Hanseok Oh,Geewook Kim,Trung Bui,Franck Dernoncourt,Elias Stengel-Eskin,Mohit Bansal,Minjoon Seo*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CINGS的后训练监督方法，通过将相关上下文附加到响应前并仅计算响应标记的损失，显著提升了大型语言模型在文本和视觉领域的生成准确性，同时减少了幻觉现象。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在推理时简单附加上下文并不能确保模型生成基于上下文的响应，导致幻觉或不一致。本文旨在通过后训练监督方法提升模型对外部上下文的依赖，从而改善生成质量。

研究方法: 提出CINGS方法，在训练时将相关上下文附加到响应前，但仅计算响应标记的损失并屏蔽上下文。这种方法通过调整模型的先验知识和行为，鼓励其更依赖外部上下文。

研究结果: 实验表明，CINGS训练的模型在11个信息检索数据集上表现优于其他方法，且在视觉语言领域减少了幻觉现象，同时保持了生成的一致性和下游任务的通用性能。

研究结论: CINGS通过后训练监督显著提升了模型对外部上下文的依赖，改善了生成准确性和一致性，且不影响模型的通用性能。

中文摘要: 大型语言模型（LLMs）常需补充外部知识以提供未编码在其参数中的信息或减少幻觉。在此情况下，我们希望模型能基于提供的外部上下文生成响应。然而，先前研究表明，仅简单在推理时附加上下文并不能确保生成基于上下文的响应。为此，我们提出基于上下文信息的接地监督（CINGS），这是一种后训练监督方法，其中模型在训练时将相关上下文附加到响应前，但仅计算响应标记的损失并屏蔽上下文。实验表明，CINGS训练的模型在文本和视觉领域均表现出更强的接地性。在文本领域，CINGS在11个信息检索数据集上优于其他训练方法，并与推理时接地技术互补。在视觉语言领域，将视觉语言模型的LLM主干替换为CINGS训练的模型，可在四个基准测试中减少幻觉现象，并保持生成响应的事实一致性。这种改进的接地性并未导致通用下游性能的下降。最后，我们分析了CINGS增强接地性的机制，发现它通过调整模型的先验知识和行为，隐式鼓励其更依赖外部上下文。

</details>


### [32] [SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling](https://arxiv.org/abs/2506.15498)
**中文标题：SPARE：基于参考引导评估的单次标注框架，用于自动过程监督与奖励建模**

*Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych*

主要分类: cs.CL

摘要简述: SPARE是一种新颖的结构化框架，通过将每个解决步骤与参考解决方案对齐，实现单次、逐步的自动过程标注，显著提升了大型语言模型在多步推理任务中的性能与效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前，高效且高质量的自动过程标注在多步推理任务中仍是一个重大挑战。为了解决这一问题，研究者提出了SPARE框架，旨在通过参考引导的逐步评估，简化标注流程并提升模型性能。

研究方法: SPARE框架通过将每个解决步骤与参考解决方案中的一个或多个步骤对齐，并辅以明确的评估理由，实现单次逐步标注。该方法在数学推理、多跳组合问答和空间推理三个领域的四个数据集上进行了验证。

研究结果: 实验表明，SPARE在离线强化学习设置中用于模型微调时，显著提升了推理性能；同时，在训练奖励模型用于排名/聚合多个LLM生成输出时也表现优异。此外，SPARE在数学数据集上达到竞争性性能，且效率提升2.6倍，仅需38%的运行时间。

研究结论: SPARE框架通过参考引导的逐步标注，显著提升了自动过程监督的效率和性能，为多步推理任务提供了一种高效的解决方案。

中文摘要: 过程或逐步监督在提升大型语言模型（LLMs）的复杂多步推理能力中发挥了关键作用。然而，高效、高质量的自动过程标注仍是一个重大挑战。为此，我们提出了单次标注与参考引导评估（SPARE），这是一种新颖的结构化框架，通过将每个解决步骤与参考解决方案中的一个或多个步骤对齐，并辅以明确的评估理由，实现单次逐步标注。我们在数学推理、多跳组合问答和空间推理三个领域的四个数据集上验证了参考引导的逐步评估对过程监督的有效性。实验表明，与基线方法相比，SPARE在以下方面显著提升了推理性能：（1）在离线强化学习设置中用于模型微调以进行推理时的贪婪解码；（2）训练奖励模型用于排名/聚合多个LLM生成输出。此外，SPARE在具有挑战性的数学数据集上达到竞争性性能，同时效率提升2.6倍，仅需38%的运行时间，优于基于树搜索的自动标注方法。我们公开了代码库及训练好的SPARE-PRM模型，以促进进一步研究和可重复性。

</details>


### [33] [Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge](https://arxiv.org/abs/2506.15504)
**中文标题：通过双向动态交互与情感知识增强夸张与隐喻检测**

*Li Zheng,Sihang Wang,Hao Fei,Zuquan Peng,Fei Li,Jianming Fu,Chong Teng,Donghong Ji*

主要分类: cs.CL

摘要简述: 本文提出了一种基于情感引导和双向动态交互的夸张与隐喻检测框架（EmoBi），通过挖掘情感内涵和动态交互提升检测性能，实验表明其在多个数据集上显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有夸张与隐喻检测方法多关注表面文本特征，忽略了二者关联及隐含情感的影响，导致检测效果受限。

研究方法: EmoBi框架包含情感分析模块、基于情感的领域映射模块和双向动态交互模块，通过挖掘情感内涵和动态交互提升检测性能，并设计了验证机制确保准确性。

研究结果: 实验显示，EmoBi在四个数据集上均优于基线方法，其中在TroFi数据集上夸张检测F1值提升28.1%，在HYPO-L数据集上隐喻检测F1值提升23.1%。

研究结论: EmoBi通过情感引导和双向动态交互显著提升了夸张与隐喻检测性能，证明了其有效性和潜力。

中文摘要: 文本中的夸张与隐喻检测对自然语言处理任务具有重要意义，但由于其语义隐晦和表达多样性，识别具有挑战性。现有方法多关注表面文本特征，忽略了夸张与隐喻的关联及隐含情感的影响。为此，我们提出了一种基于情感引导和双向动态交互的检测框架（EmoBi）。首先，情感分析模块深度挖掘夸张与隐喻背后的情感内涵；其次，基于情感的领域映射模块识别目标与源领域以理解其隐含意义；最后，双向动态交互模块促进夸张与隐喻的相互提升，并设计了验证机制确保检测准确性。实验表明，EmoBi在四个数据集上均优于基线方法，尤其在TroFi数据集上夸张检测F1值提升28.1%，在HYPO-L数据集上隐喻检测F1值提升23.1%。这些结果证明了该方法的有效性和潜力。

</details>


### [34] [Lessons from Training Grounded LLMs with Verifiable Rewards](https://arxiv.org/abs/2506.15522)
**中文标题：基于可验证奖励的接地大语言模型训练经验**

*Shang Hong Sim,Tej Deep Pala,Vernon Toh,Hai Leong Chieu,Amir Zadeh,Chuan Li,Navonil Majumder,Soujanya Poria*

主要分类: cs.CL

摘要简述: 本文探讨如何通过强化学习和内部推理提升大语言模型（LLM）的可靠性和可验证性。采用GRPO方法训练模型，优化答案正确性、引用充分性和拒绝质量，显著提升了模型在未回答查询和生成引用回答方面的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于检索增强生成（RAG）的大语言模型在生成可靠和可验证的回答时仍存在挑战，如遗漏明确答案、错误引用或拒绝可用证据。本文旨在通过强化学习和内部推理解决这些问题。

研究方法: 使用GRPO（Group Relative Policy Optimization）方法训练模型，通过可验证的结果奖励优化答案正确性、引用充分性和拒绝质量。采用两阶段训练策略，先优化答案和引用行为，再优化拒绝行为，并结合GPT-4蒸馏的指令微调。

研究结果: 实验表明，结合推理的模型在ASQA、QAMPARI、ELI5和ExpertQA等任务中显著优于仅基于指令的模型，尤其在处理未回答查询和生成引用回答方面表现突出。两阶段训练进一步提升了模型的稳定性。

研究结论: 研究强调了推理、分阶段优化和结果驱动的强化学习在构建更可验证和可靠的大语言模型中的重要性，为未来研究提供了方向。

中文摘要: 生成可靠且可验证的回答仍然是大语言模型（LLM）面临的主要挑战。尽管基于检索增强生成（RAG）和引用的方法具有潜力，但经过指令微调的模型在简单场景中仍频繁失败：遗漏明确答案、错误引用或在证据可用时拒绝回答。本研究探讨了如何通过强化学习（RL）和内部推理增强LLM的可靠性。我们采用GRPO（Group Relative Policy Optimization）方法，通过可验证的结果奖励训练模型，目标为答案正确性、引用充分性和拒绝质量，无需黄金推理轨迹或昂贵的标注。在ASQA、QAMPARI、ELI5和ExpertQA上的综合实验表明，结合推理的模型显著优于仅基于指令的模型，尤其是在处理未回答查询和生成引用回答方面。两阶段训练策略（先优化答案和引用行为，再优化拒绝行为）通过稳定学习信号进一步提升了可靠性。此外，我们通过GPT-4蒸馏重新审视指令微调，发现将其与GRPO结合可提升长形式生成问答任务的性能。总体而言，我们的研究结果凸显了推理、分阶段优化和结果驱动的强化学习在构建更可验证和可靠的LLM中的价值。

</details>


### [35] [RATTENTION: Towards the Minimal Sliding Window Size in Local-Global Attention Models](https://arxiv.org/abs/2506.15545)
**中文标题：RATTENTION：迈向局部-全局注意力模型的最小滑动窗口尺寸**

*Bailin Wang,Chang Lan,Chong Wang,Ruoming Pang*

主要分类: cs.CL

摘要简述: 本文提出RATTENTION，一种结合局部注意力和线性注意力的新方法，旨在解决局部注意力模型忽略窗口外信息的局限性。实验表明，RATTENTION在512窗口大小下性能媲美全注意力模型，同时提升效率。


<details>
  <summary>详细信息</summary>
研究动机: 局部-全局注意力模型在效率和性能之间存在权衡：大窗口保留性能但效率低，小窗口效率高但性能下降。现有模型（如Gemma2和Mistral）采用保守窗口大小以维持性能。本文旨在突破这一权衡，使模型在短上下文场景中也能高效运行。

研究方法: 提出RATTENTION，将局部注意力与专为捕捉窗口外信息的线性注意力机制结合。通过预训练实验验证其在3B和12B规模下的表现，并使用专用内核实现以保持训练效率。

研究结果: RATTENTION在512窗口大小下性能与全注意力模型相当，同时在RULER基准测试中表现出更好的长上下文性能。训练效率未受影响，速度与现有先进方法相当。

研究结论: RATTENTION通过结合局部和线性注意力，显著改善了局部注意力模型的性能-效率权衡，为短上下文和长上下文任务提供了高效解决方案。

中文摘要: 局部-全局注意力模型近年来成为标准Transformer的有力替代方案，有望提升训练和推理效率。然而，窗口大小的选择存在帕累托权衡：大窗口性能接近全注意力但效率提升有限，小窗口则可能导致性能下降。现有模型（如Gemma2和Mistral）采用保守窗口大小（如4096，预训练长度为8192）以维持性能。本文研究如何突破这一权衡，使局部-全局模型在短上下文场景中也能高效运行。核心动机是解决局部注意力的固有局限——完全忽略窗口外信息。我们探索了RATTENTION，一种结合专为捕捉窗口外信息的线性注意力机制的局部注意力变体。在3B和12B规模的预训练实验中，RATTENTION实现了性能与效率的优越权衡。作为最佳平衡点，窗口大小仅为512的RATTENTION在多种设置下性能与全注意力模型相当。此外，RATTENTION的线性注意力组件的循环特性提升了长上下文性能，RULER基准测试验证了这一点。重要的是，这些改进未牺牲训练效率；得益于专用内核实现和更小的窗口大小，RATTENTION的训练速度与现有先进方法相当。

</details>


### [36] [Approximating Language Model Training Data from Weights](https://arxiv.org/abs/2506.15553)
**中文标题：从权重近似语言模型训练数据**

*John X. Morris,Junjie Oscar Yin,Woojeong Kim,Vitaly Shmatikov,Alexander M. Rush*

主要分类: cs.CL

摘要简述: 现代语言模型通常公开权重但隐藏训练数据。本文提出从模型权重近似训练数据的问题，并开发了一种基于梯度的方法，从公共文本库中选择匹配度最高的数据，有效恢复有用数据。


<details>
  <summary>详细信息</summary>
研究动机: 现代语言模型的训练数据通常不公开，但模型权重可获取。本文旨在解决如何从公开的权重中近似还原训练数据的问题，以提升模型性能。

研究方法: 提出一种基于梯度的数据选择方法，从大规模公共文本库中筛选与原始模型和微调模型权重匹配度最高的数据。

研究结果: 在AG News分类任务中，方法将性能从65%提升至80%，接近专家基准的88%。在MSMARCO文档的微调模型中，困惑度从3.3降至2.3，接近专家LLAMA模型的2.0。

研究结论: 即使不知道真实训练数据，该方法仍能从公共文档中筛选出有效数据，显著提升模型性能，接近专家水平。

中文摘要: 现代语言模型通常公开权重但隐藏训练数据。我们形式化了从模型权重近似训练数据的问题，并提出了几种基线方法和指标。我们开发了一种基于梯度的方法，从大型公共文本库中选择匹配度最高的数据，并展示了其在仅给定原始模型和微调模型权重时恢复有用数据的有效性。即使完全不知道真实训练数据，我们的方法仍能从公共网络文档中定位一小部分数据，用于训练模型，使其性能接近原始模型，适用于分类和监督微调任务。在AG News分类任务中，我们的方法将性能从65%（随机选择数据）提升至80%，接近专家基准的88%。当应用于在MSMARCO网络文档上微调的模型时，我们的方法将困惑度从3.3降至2.3，而专家LLAMA模型的困惑度为2.0。

</details>


### [37] [PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction](https://arxiv.org/abs/2506.15556)
**中文标题：PredGen：通过输入时推测加速大型语言模型推理以实现实时语音交互**

*Shufan Li,Aditya Grover*

主要分类: cs.CL

摘要简述: 本文提出PredGen框架，通过输入时推测解码加速大型语言模型（LLM）的推理，显著减少实时语音交互中的延迟，提升用户体验。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在实时语音聊天应用中常与文本转语音（TTS）系统结合使用，但由于模型规模大，用户输入结束到音频输出开始之间存在明显延迟，尤其在计算能力有限的消费级硬件上。这种延迟主要由LLM生成第一句话的时间主导，而TTS系统需要逐句合成音频。

研究方法: 提出Predictive Generation（PredGen）框架，在用户仍在说话时通过推测解码生成候选响应，使系统能够以最小延迟开始TTS处理。

研究结果: 在Lmsys和MT-Bench数据集上的模拟实验表明，该方法可有效将延迟减少约2倍，且仅需输入时少量额外计算成本。

研究结论: PredGen通过输入时推测解码显著降低了LLM在实时语音交互中的延迟，同时计算成本几乎可忽略，为提升用户体验提供了有效解决方案。

中文摘要: 大型语言模型（LLM）广泛应用于实时语音聊天应用，通常与文本转语音（TTS）系统结合以生成音频响应。然而，其庞大的规模常导致用户输入结束到音频输出开始之间存在明显延迟，影响用户体验。这种延迟在LLM作为单用户语音助手部署于计算能力有限的消费级硬件上时尤为显著。我们发现，延迟主要由LLM生成第一句话的时间主导，而TTS系统需要逐句合成音频。为解决这一瓶颈，我们提出Predictive Generation（PredGen）框架，通过输入时推测解码减轻甚至消除这一延迟。PredGen在用户仍在说话时生成候选响应，使系统能够以最小延迟开始TTS处理。在Lmsys和MT-Bench数据集上的模拟实验表明，该方法可有效将延迟减少约2倍，且输入时仅需少量额外计算成本。

</details>


### [38] [Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models](https://arxiv.org/abs/2506.15568)
**中文标题：性别包容性公平指数（GIFI）：一种评估大语言模型中性别多样性的多层次框架**

*Zhengyang Shan,Emily Ruth Diana,Jiawei Zhou*

主要分类: cs.CL

摘要简述: 本文提出了一种名为GIFI的多层次框架，用于评估大语言模型（LLMs）在性别多样性方面的表现，特别关注其对二元和非二元性别的处理能力。研究发现不同LLMs在性别包容性上存在显著差异。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注二元性别区分，而忽略了非二元性别的包容性。本文旨在填补这一空白，通过提出GIFI指标，全面评估LLMs在性别多样性方面的公平性。

研究方法: 本文提出GIFI指标，通过多层次评估（从性别代词测试到模型生成行为和认知测试）量化LLMs的性别包容性。对22种开源和专有LLMs进行了广泛评估。

研究结果: 研究发现不同LLMs在性别包容性上存在显著差异，揭示了与不同性别标识相关的偏见。

研究结论: 研究强调了提升LLMs性别包容性的重要性，并为未来生成模型的性别公平性提供了关键基准。

中文摘要: 本文对大语言模型（LLMs）的性别公平性进行了全面评估，重点关注其对二元和非二元性别的处理能力。尽管现有研究主要关注二元性别区分，但我们提出了性别包容性公平指数（GIFI），这是一种新颖且全面的指标，用于量化LLMs的性别多样性包容性。GIFI包含从简单测试模型对性别代词的反应到在不同性别假设下测试模型生成行为和认知能力的多层次评估，揭示了与不同性别标识相关的偏见。我们对22种不同规模和能力的开源及专有LLMs进行了广泛评估，发现LLMs在性别包容性上存在显著差异。本研究强调了提升LLMs包容性的重要性，为未来生成模型的性别公平性提供了关键基准。

</details>


### [39] [SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification](https://arxiv.org/abs/2506.15569)
**中文标题：SciVer：评估多模态科学声明验证的基础模型**

*Chengye Wang,Yifei Shen,Zexi Kuang,Arman Cohan,Yilun Zhao*

主要分类: cs.CL

摘要简述: SciVer是首个专门评估基础模型在多模态科学声明验证中能力的基准，包含3000个专家标注的示例，覆盖4种常见推理类型。评估了21种先进多模态基础模型，发现其与人类专家存在显著差距，并揭示了开源模型的关键局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态基础模型在科学声明验证任务中的表现缺乏系统性评估，SciVer旨在填补这一空白，为模型在多模态科学文献中的理解和推理能力提供基准。

研究方法: SciVer包含3000个专家标注的示例，覆盖1113篇科学论文，分为4种推理类型。评估了21种先进多模态模型（如o4-mini、Gemini-2.5-Flash等），并通过检索增强生成（RAG）和人工错误分析进行深入评估。

研究结果: 实验显示，当前多模态基础模型与人类专家在SciVer上的表现存在显著差距。开源模型在科学声明验证任务中表现出关键局限性。

研究结论: SciVer为多模态科学声明验证任务提供了首个基准，揭示了当前模型的不足，为未来模型改进提供了重要方向。

中文摘要: 我们介绍了SciVer，这是首个专门设计用于评估基础模型在多模态科学背景下验证声明能力的基准。SciVer包含3000个专家标注的示例，覆盖1113篇科学论文，分为四个子集，每个子集代表多模态科学声明验证中的一种常见推理类型。为支持细粒度评估，每个示例均包含专家标注的支持证据。我们评估了21种先进的多模态基础模型，包括o4-mini、Gemini-2.5-Flash、Llama-3.2-Vision和Qwen2.5-VL。实验显示，这些模型与人类专家在SciVer上的表现存在显著差距。通过检索增强生成（RAG）和人工错误评估的深入分析，我们揭示了当前开源模型的关键局限性，为提升模型在多模态科学文献任务中的理解和推理能力提供了重要见解。

</details>


### [40] [DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement](https://arxiv.org/abs/2506.15583)
**中文标题：DiscoSG：通过迭代图优化实现话语级文本场景图解析**

*Shaoqing Lin,Chong Teng,Fei Li,Donghong Ji,Lizhen Qu,Zhuang Li*

主要分类: cs.CL

摘要简述: 本文提出了一种新的任务DiscoSG（话语级文本场景图解析），并开发了数据集DiscoSG-DS和模型DiscoSG-Refiner，通过迭代图优化提升多句子描述的场景图解析性能，显著优于现有基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本场景图解析方法主要针对单句描述，无法有效处理多句子描述中的跨句共指等现象，导致图结构碎片化，影响下游任务性能。

研究方法: 提出DiscoSG任务，并构建包含专家标注和合成数据的数据集DiscoSG-DS。使用两个小型PLM（Flan-T5-Base）实现DiscoSG-Refiner模型，首先生成基础图，再通过迭代优化提出图编辑建议，降低计算开销。

研究结果: DiscoSG-Refiner在SPICE指标上比最佳基线提升约30%，推理速度比GPT-4快86倍，同时显著提升下游任务（如话语级描述评估和幻觉检测）的性能。

研究结论: DiscoSG-Refiner通过迭代优化有效解决了多句子场景图解析问题，性能优越且计算高效，为相关领域提供了实用工具和数据支持。

中文摘要: 视觉语言模型（VLMs）现在能够生成话语级的多句子视觉描述，这对原本设计用于单句子描述的文本场景图解析器提出了挑战。现有方法通常合并句子级解析结果，但往往忽略跨句共指等现象，导致图结构碎片化并影响下游任务性能。为此，我们提出了新任务“话语级文本场景图解析”（DiscoSG），并构建了数据集DiscoSG-DS，包含400组专家标注和8,430组合成的多句子描述-图对。每组描述平均包含9个句子，每组图的边数至少是现有数据集的3倍。尽管在DiscoSG-DS上微调大型PLM（如GPT-4）可将SPICE指标提升约48%，但其高推理成本和严格许可限制了开源使用，而小型PLM难以处理复杂图结构。我们提出DiscoSG-Refiner，先用一个小型PLM生成基础图，再用另一个PLM迭代提出图编辑建议，降低全图生成开销。使用两个Flan-T5-Base模型时，DiscoSG-Refiner的SPICE指标仍比最佳基线提升约30%，推理速度比GPT-4快86倍，并能持续提升下游任务（如话语级描述评估和幻觉检测）的性能。代码和数据已开源：https://github.com/ShaoqLin/DiscoSG

</details>


### [41] [WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts](https://arxiv.org/abs/2506.15594)
**中文标题：WikiMixQA：一个针对表格和图表的跨模态问答基准**

*Negar Foroutan,Angelika Romanou,Matin Ansaripour,Julian Martin Eisenschlos,Karl Aberer,Rémi Lebret*

主要分类: cs.CL

摘要简述: 本文介绍了WikiMixQA，一个包含1000道多选题的跨模态推理基准，用于评估从维基百科表格和图表中提取信息的模型性能。研究发现，现有模型在长上下文多模态推理中表现不佳，尤其是开源模型。


<details>
  <summary>详细信息</summary>
研究动机: 文档通常包含复杂的布局、表格和图表，这对自动文档理解（DU）提出了挑战。尽管视觉语言大模型（VLLMs）在多项任务中表现优异，但其处理长上下文视觉输入的能力尚不明确。本文旨在通过WikiMixQA基准填补这一研究空白。

研究方法: 研究团队构建了WikiMixQA基准，包含1000道多选题，覆盖7个主题的4000个维基百科页面。评估了12种最先进的视觉语言模型，重点关注其在跨模态推理中的表现。

研究结果: 实验显示，专有模型在直接提供上下文时准确率约为70%，但在需要从长文档中检索信息时性能显著下降。GPT-4-o是唯一在此情境下准确率超过50%的模型，而开源模型最高准确率仅为27%。

研究结论: WikiMixQA揭示了长上下文多模态推理的挑战，并成为推动文档理解研究的重要基准。

中文摘要: 文档是保存和传播信息的基础，通常包含复杂的布局、表格和图表，这对自动文档理解（DU）提出了重大挑战。尽管视觉语言大模型（VLLMs）在多项任务中表现出改进，但其处理长上下文视觉输入的有效性尚不明确。本文介绍了WikiMixQA，一个包含1000道多选题的基准，旨在评估从4000个维基百科页面（涵盖7个主题）中提取的表格和图表的跨模态推理能力。与现有基准不同，WikiMixQA强调复杂推理，要求模型综合多模态信息。我们评估了12种最先进的视觉语言模型，发现专有模型在直接提供上下文时准确率约为70%，但在需要从长文档中检索信息时性能显著下降。其中，GPT-4-o是唯一在此情境下准确率超过50%的模型，而开源模型表现更差，最高准确率仅为27%。这些发现凸显了长上下文多模态推理的挑战，并将WikiMixQA确立为推动文档理解研究的重要基准。

</details>


### [42] [From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns](https://arxiv.org/abs/2506.15598)
**中文标题：从模型到课堂：基于叙事与难度考量的葡萄牙语生成多选题评估**

*Bernardo Leite,Henrique Lopes Cardoso,Pedro Pinto,Abel Ferreira,Luís Abreu,Isabel Rangel,Sandra Monteiro*

主要分类: cs.CL

摘要简述: 本文研究了生成式AI在葡萄牙语阅读多选题（MCQ）生成中的应用，重点关注题目与课程叙事的契合度及难度分布。通过专家评审和学生反应分析，发现生成题目质量接近人工编写，但仍存在语义清晰度和干扰项设计问题。


<details>
  <summary>详细信息</summary>
研究动机: 多选题（MCQ）是学习和评估的重要工具，但人工编写耗时且成本高。生成式AI为自动化生成提供了可能，但其质量和可靠性评估不足，尤其是针对非英语语言（如葡萄牙语）的研究较少。本文旨在填补这一空白，并探讨生成题目在实际教学中的适用性。

研究方法: 研究利用生成式AI为葡萄牙语阅读生成多选题，重点关注题目与课程叙事的关联及难度分级。通过专家评审分析题目质量，并基于学生反应的测量学特性评估其适用性。

研究结果: 结果显示，生成式AI能生成与人工编写质量相当的题目，但在语义清晰度和干扰项设计上存在问题，尤其是干扰项未能有效吸引学生或满足高质量多选题的设计标准。

研究结论: 当前生成式AI在葡萄牙语多选题生成中表现出潜力，但仍需改进语义清晰度和干扰项设计，以更好地满足教学需求。

中文摘要: 尽管多选题（MCQ）对学习和评估具有重要价值，但人工编写不同难度和针对性阅读技能的题目仍是一项耗时且成本高昂的任务。生成式AI的最新进展为高效自动化生成MCQ提供了可能，但其生成题目的实际质量和可靠性评估却鲜有研究，尤其是在生成失败的情况下。这一方面在生成题目应用于实际教学场景时尤为重要。此外，大多数MCQ生成研究集中于英语，其他语言的研究较少。本文探讨了当前生成式模型在葡萄牙语（一种形态丰富的语言）阅读多选题生成中的能力。研究聚焦于生成与课程叙事相关且覆盖不同难度级别的MCQ，并通过专家评审和学生反应的心理测量学特性评估其适用性。结果显示，当前模型生成的MCQ质量与人工编写相当，但仍存在语义清晰度和可答性问题。此外，生成能吸引学生并符合高质量多选题选项设计标准的干扰项仍具挑战性。

</details>


### [43] [The Compositional Architecture of Regret in Large Language Models](https://arxiv.org/abs/2506.15617)
**中文标题：大型语言模型中后悔的组合架构**

*Xiangxiang Cui,Shu Yang,Tianjin Huang,Wanyu Lin,Lijie Hu,Di Wang*

主要分类: cs.CL

摘要简述: 本文研究大型语言模型中的后悔机制，提出构建后悔数据集的方法及两种新指标（S-CDI和RDS），成功识别最优后悔表征层和神经元功能分组。


<details>
  <summary>详细信息</summary>
研究动机: 研究大型语言模型中的后悔表达机制，旨在提升模型可靠性，并揭示神经网络中认知编码的方式。

研究方法: 提出三步方法：(1) 通过设计提示场景构建后悔数据集，(2) 使用S-CDI指标识别最优后悔表征层，(3) 通过RDS和GIC指标分析后悔神经元及其激活模式。

研究结果: 实验成功识别最优后悔表征层，发现M形解耦模式，并将神经元分为后悔神经元、非后悔神经元和双功能神经元三类。

研究结论: 研究为理解后悔机制提供了新工具和洞察，有助于提升模型可靠性及认知编码研究。

中文摘要: 大型语言模型中的后悔指其在面对与先前生成错误信息相矛盾的证据时表现出的明确后悔表达。研究后悔机制对提升模型可靠性至关重要，并有助于揭示神经网络中认知编码的方式。为理解这一机制，需首先识别模型输出中的后悔表达，再分析其内部表征。此分析需考察模型的隐藏状态，即神经元层面的信息处理过程。然而，这面临三大挑战：(1) 缺乏捕捉后悔表达的专业数据集，(2) 缺乏识别最优后悔表征层的指标，(3) 缺乏识别和分析后悔神经元的指标。针对这些局限，我们提出：(1) 通过策略性设计的提示场景构建全面后悔数据集的工作流程，(2) 用于识别最优后悔表征层的监督压缩-解耦指数（S-CDI）指标，(3) 用于识别后悔神经元的后悔主导分数（RDS）指标及分析激活模式的群体影响系数（GIC）。实验结果表明，S-CDI指标成功识别了最优后悔表征层，显著提升了探针分类实验的性能。此外，我们发现模型层间存在M形解耦模式，揭示了信息处理在耦合与解耦阶段交替的机制。通过RDS指标，我们将神经元分为三类功能组：后悔神经元、非后悔神经元和双功能神经元。

</details>


### [44] [Minding the Politeness Gap in Cross-cultural Communication](https://arxiv.org/abs/2506.15623)
**中文标题：关注跨文化交际中的礼貌差异**

*Yuka Machino,Matthias Hofer,Max Siegel,Joshua B. Tenenbaum,Robert D. Hawkins*

主要分类: cs.CL

摘要简述: 研究发现英式与美式英语中强化词（如'quite'和'very'）的解读差异源于字面意义和语用因素（如礼貌与简洁）的复杂交互作用。


<details>
  <summary>详细信息</summary>
研究动机: 跨文化交际中的误解常源于细微的解读差异，但尚不清楚这些差异是由字面意义还是语用因素（如礼貌规范）引起。本文旨在探究英式和美式英语中强化词的不同解读机制。

研究方法: 通过三个实验分析英式和美式英语使用者对强化词（如'quite'和'very'）的解读，并开发计算认知模型，模拟听者对说话者在信息量、礼貌和表达成本之间的权衡推理。

研究结果: 模型比较表明，强化词的跨文化解读差异是字面意义和表达成本权重不同的共同结果，挑战了仅基于语义变异或礼貌规范的解释。

研究结论: 跨文化解读差异源于字面意义与语用因素的复杂交互，而非单一因素主导。

中文摘要: 跨文化交际中的误解常源于细微的解读差异，但尚不清楚这些差异是由字面意义还是语用因素（如礼貌和简洁规范）引起。本文通过三个实验研究英式和美式英语使用者对强化词（如'quite'和'very'）的解读。为更好地理解这些差异，我们开发了一个计算认知模型，模拟听者对说话者在信息量、礼貌和表达成本之间的权衡推理。模型比较表明，强化词的跨文化解读差异源于（1）不同的字面意义，（2）表达成本权重的不同。这些发现挑战了仅基于语义变异或礼貌规范的解释，表明跨文化解读差异是两者复杂交互的结果。

</details>


### [45] [Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability](https://arxiv.org/abs/2506.15629)
**中文标题：重新审视大型语言模型的组合泛化能力：基于指令遵循能力的考量**

*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

主要分类: cs.CL

摘要简述: 本文提出Ordered CommonGen基准，用于评估大型语言模型（LLMs）的组合泛化能力和指令遵循能力，发现LLMs虽能理解指令意图，但对特定概念顺序的偏好导致输出多样性低，最高指令遵循模型的有序覆盖率仅约75%。


<details>
  <summary>详细信息</summary>
研究动机: 在生成式常识推理任务中，LLMs需根据给定概念生成句子，但若提示指定概念顺序，模型需遵循该顺序生成内容。现有研究未同时评估组合泛化和指令遵循能力，因此提出Ordered CommonGen基准以填补这一空白。

研究方法: 提出Ordered CommonGen基准，通过有序覆盖率指标评估LLMs是否按指定顺序生成概念，同时分析36种LLMs的表现。

研究结果: LLMs普遍能理解指令意图，但对特定顺序模式的偏好导致输出多样性低；最高指令遵循模型的覆盖率仅约75%，显示能力仍有不足。

研究结论: LLMs在指令遵循和组合泛化能力上仍需改进，Ordered CommonGen为未来研究提供了有效评估工具。

中文摘要: 在生成式常识推理任务（如CommonGen）中，生成式大型语言模型（LLMs）需生成包含所有给定概念的句子。然而，当关注指令遵循能力时，若提示指定概念顺序，LLMs必须按顺序生成句子。为此，我们提出Ordered CommonGen基准，用于评估LLMs的组合泛化和指令遵循能力。该基准通过有序覆盖率指标衡量概念是否按指定顺序生成，从而同时评估两种能力。我们对36种LLMs进行全面分析，发现尽管LLMs通常能理解指令意图，但对特定顺序模式的偏好常导致输出多样性低或概念顺序改变时结果相同。此外，即使指令遵循能力最强的LLM，其有序覆盖率也仅约75%，表明其在指令遵循和组合泛化能力上仍需改进。

</details>


### [46] [Oldies but Goldies: The Potential of Character N-grams for Romanian Texts](https://arxiv.org/abs/2506.15650)
**中文标题：老而弥坚：字符n-gram在罗马尼亚文本中的潜力**

*Dana Lupsa,Sanda-Maria Avram*

主要分类: cs.CL

摘要简述: 本研究通过ROST语料库评估六种机器学习方法在罗马尼亚文本作者归属任务中的表现，发现基于字符n-gram的ANN模型表现最佳，展示了轻量级方法的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 针对罗马尼亚文本作者归属问题，研究旨在验证字符n-gram特征在资源受限或研究较少的语言环境中的有效性。

研究方法: 使用ROST语料库，系统评估SVM、LR、k-NN、DT、RF和ANN六种机器学习方法，以字符n-gram为特征进行分类。

研究结果: ANN模型表现最佳，在使用5-gram特征时，15次实验中有4次实现完美分类，表明轻量级方法可达到先进水平。

研究结论: 字符n-gram等简单风格特征在资源受限语言中具有潜力，可与复杂方法媲美。

中文摘要: 本研究针对罗马尼亚文本作者归属问题，利用ROST语料库作为标准基准，系统评估了六种机器学习方法：支持向量机（SVM）、逻辑回归（LR）、k近邻（k-NN）、决策树（DT）、随机森林（RF）和人工神经网络（ANN），并采用字符n-gram特征进行分类。其中，ANN模型表现最佳，在使用5-gram特征时，15次实验中有4次实现完美分类。这些结果表明，轻量级且可解释的字符n-gram方法在罗马尼亚作者归属任务中可以达到先进水平，与更复杂的方法相媲美。我们的发现突出了简单风格特征在资源受限或研究较少的语言环境中的潜力。

</details>


### [47] [CC-LEARN: Cohort-based Consistency Learning](https://arxiv.org/abs/2506.15662)
**中文标题：CC-LEARN：基于队列的一致性学习**

*Xiao Ye,Shaswat Shrivastava,Zhaonan Li,Jacob Dineen,Shijie Lu,Avneet Ahuja,Ming Shen,Zhikun Xu,Ben Zhou*

主要分类: cs.CL

摘要简述: CC-LEARN是一种基于队列的一致性学习框架，通过强化学习提升大语言模型的推理一致性和稳健性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在许多任务中表现出色，但其推理的一致性和稳健性仍有待提升。为解决这一问题，本文提出了CC-LEARN框架。

研究方法: CC-LEARN通过队列（相似问题组）训练模型，结合队列准确率、问题分解检索奖励和无效查询拒绝惩罚的复合目标，利用强化学习优化推理模式。

研究结果: 在ARC-Challenge和StrategyQA等推理基准测试中，CC-LEARN显著提升了模型的准确性和推理稳定性，优于预训练和监督微调基线。

研究结论: 队列级强化学习能有效提升大语言模型的推理一致性，CC-LEARN为增强模型稳健性提供了新思路。

中文摘要: 大语言模型在许多任务中表现出色，但在一致性和稳健性推理方面仍有不足。我们提出了基于队列的一致性学习（CC-LEARN），这是一种强化学习框架，通过训练由共享程序抽象派生的相似问题队列，提升大语言模型推理的可靠性。为实现队列级一致性，我们定义了一个复合目标，包括队列准确率、有效问题分解的检索奖励以及对无效查询的拒绝惩罚，这些目标可通过强化学习直接优化，而监督微调则无法实现。优化这一奖励机制引导模型在所有队列成员中采用统一的推理模式。在具有挑战性的推理基准测试（包括ARC-Challenge和StrategyQA）上的实验表明，CC-LEARN在准确性和推理稳定性上均优于预训练和监督微调基线。这些结果表明，队列级强化学习能有效提升大语言模型的推理一致性。

</details>


### [48] [Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](https://arxiv.org/abs/2506.15674)
**中文标题：泄露的思维：大型推理模型并非私密的思考者**

*Tommaso Green,Martin Gubri,Haritz Puerto,Sangdoo Yun,Seong Joon Oh*

主要分类: cs.CL

摘要简述: 研究发现大型推理模型的推理痕迹中存在隐私泄露风险，推理步骤增加会放大泄露，揭示了推理效用与隐私攻击面之间的核心矛盾。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型作为个人代理时，其推理痕迹常被视为内部且安全，但作者质疑这一假设，认为推理痕迹可能包含敏感用户数据，并通过实验验证隐私泄露的可能性。

研究方法: 通过提示注入和代理评估，研究推理痕迹中的隐私泄露问题，并分析测试时计算（如增加推理步骤）对泄露的影响。

研究结果: 实验表明，推理步骤的增加会放大隐私泄露，尽管模型在最终答案上更谨慎，但其推理过程更冗长，泄露更多信息。

研究结论: 研究揭示了推理效用与隐私攻击面之间的核心矛盾，呼吁安全措施需扩展到模型的内部推理过程，而不仅是最终输出。

中文摘要: 我们研究了作为个人代理的大型推理模型在推理痕迹中的隐私泄露问题。与最终输出不同，推理痕迹通常被认为是内部且安全的。我们通过实验挑战了这一假设，表明推理痕迹中常包含敏感用户数据，这些数据可通过提示注入或意外泄露到输出中。通过探测和代理评估，我们发现测试时计算（尤其是增加推理步骤）会放大这种泄露。尽管增加测试时计算的预算使模型在最终答案上更谨慎，但也导致其推理过程更冗长，泄露更多信息。这揭示了一个核心矛盾：推理提升了效用，但扩大了隐私攻击面。我们认为安全措施必须扩展到模型的内部思维，而不仅是其输出。

</details>


### [49] [Gender-Neutral Machine Translation Strategies in Practice](https://arxiv.org/abs/2506.15676)
**中文标题：实践中性别中立机器翻译策略的研究**

*Hillary Dawkins,Isar Nejadgholi,Chi-kiu Lo*

主要分类: cs.CL

摘要简述: 研究评估了21种机器翻译系统在性别模糊翻译中的表现，发现大多数系统缺乏性别中立翻译策略，仅有少数系统能根据目标语言采用特定策略。


<details>
  <summary>详细信息</summary>
研究动机: 性别包容的机器翻译需在源语言中保留性别模糊性以避免错误性别化和代表性伤害，但在语法性别语言中实现这一目标具有挑战性。

研究方法: 研究评估了21种机器翻译系统在三种不同难度的翻译方向中对性别模糊的敏感性，并对实践中观察到的性别中立策略进行了分类和讨论。

研究结果: 大多数机器翻译系统在性别模糊情况下未能提供性别中立翻译，但少数系统能根据目标语言采用特定策略实现性别中立翻译。

研究结论: 尽管当前机器翻译系统在性别中立翻译方面表现不佳，但少数系统的成功策略为未来改进提供了方向。

中文摘要: 性别包容的机器翻译（MT）应保留源语言中的性别模糊性，以避免错误性别化和代表性伤害。尽管性别模糊性在英语等概念性别语言中自然存在，但在语法性别语言中保持这种性别中立性是一项挑战。本文评估了21种机器翻译系统在三种不同难度翻译方向中对性别模糊的敏感性，并对实践中观察到的性别中立策略进行了分类和讨论。此外，我们还研究了二元性别刻板印象对性别中立翻译使用的影响。总体而言，我们发现机器翻译系统在性别模糊情况下普遍缺乏性别中立翻译。然而，我们观察到少数机器翻译系统会根据目标语言采用特定策略实现性别中立翻译。

</details>


### [50] [GenRecal: Generation after Recalibration from Large to Small Vision-Language Models](https://arxiv.org/abs/2506.15681)
**中文标题：GenRecal：从大型到小型视觉语言模型的重新校准后生成**

*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

主要分类: cs.CL

摘要简述: GenRecal是一种新型通用蒸馏框架，通过重新校准异构视觉语言模型（VLM）的特征表示，实现跨模型知识迁移，显著提升小模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型视觉语言模型（VLM）性能优异，但其高计算需求限制了在资源受限设备上的部署。因此，需要将知识从大型VLM蒸馏到小型高效模型中。然而，不同VLM架构的多样性（如词汇量、分词方式和索引顺序差异）阻碍了这一过程。

研究方法: GenRecal提出了一种通用蒸馏框架，包含一个重新校准器（Recalibrator），用于对齐和调整异构VLM之间的特征表示，从而实现跨模型的有效知识迁移。

研究结果: 在多个挑战性基准测试中，GenRecal显著提升了基线性能，甚至优于大型开源和闭源VLM。

研究结论: GenRecal通过重新校准异构VLM的特征表示，成功实现了跨模型知识迁移，为资源受限设备部署高效VLM提供了可行方案。

中文摘要: 近期视觉语言模型（VLM）的进展通过利用大型语言模型（LLM）实现了与闭源系统（如GPT-4V）相当的性能。然而，这些模型在实际场景中的部署（尤其是在资源受限设备上）仍面临挑战，主要源于其巨大的计算需求。这促使人们关注如何将知识从大型VLM蒸馏到更小、更高效的模型中。然而，VLM架构的多样性（如词汇量、分词方式和索引顺序的差异）带来了关键挑战。为解决这一限制，我们提出了重新校准后生成（GenRecal），一种新型通用VLM蒸馏框架。GenRecal包含一个重新校准器（Recalibrator），用于对齐和调整异构VLM之间的特征表示，从而实现跨模型的有效知识迁移。通过在多个挑战性基准测试中的广泛实验，我们证明GenRecal显著提升了基线性能，最终优于大型开源和闭源VLM。

</details>


### [51] [PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning](https://arxiv.org/abs/2506.15683)
**中文标题：PhantomHunter：通过家族感知学习检测未见私有调优LLM生成文本**

*Yuhui Shi,Yehan Yang,Qiang Sheng,Hao Mi,Beizhe Hu,Chaoxi Xu,Juan Cao*

主要分类: cs.CL

摘要简述: PhantomHunter是一种专门检测未见过私有调优LLM生成文本的检测器，通过家族感知学习框架捕捉基础模型及其衍生模型的共享特征，实验表明其性能优于现有方法和工业服务。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的普及，虚假信息和学术不端等社会问题日益严重，现有检测器对私有调优LLM生成的文本检测效果不佳，亟需解决这一新挑战。

研究方法: PhantomHunter采用家族感知学习框架，专注于捕捉基础模型及其衍生模型之间的家族级共享特征，而非记忆单个模型特性，从而提升对私有调优LLM生成文本的检测能力。

研究结果: 在LLaMA、Gemma和Mistral家族数据上的实验显示，PhantomHunter在7种基线方法和3种工业服务中表现最优，F1分数超过96%。

研究结论: PhantomHunter通过家族感知学习有效解决了私有调优LLM生成文本的检测问题，为未来研究提供了新方向。

中文摘要: 随着大型语言模型（LLM）的普及，虚假信息生产和学术不端等社会问题愈发严重，使得LLM生成文本检测变得前所未有的重要。尽管现有方法已取得显著进展，但对私有调优LLM生成文本的新挑战仍未充分探索。用户可通过私有语料微调开源LLM轻松获得私有模型，导致现有检测器在实际应用中性能大幅下降。为解决这一问题，我们提出PhantomHunter，一种专门用于检测未见私有调优LLM生成文本的检测器。其家族感知学习框架捕捉基础模型及其衍生模型之间的家族级共享特征，而非记忆单个特性。在LLaMA、Gemma和Mistral家族数据上的实验表明，其性能优于7种基线方法和3种工业服务，F1分数超过96%。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2506.14791)
**中文标题：SemIRNet：一种用于多模态反讽检测的语义反讽识别网络**

*Jingxuan Zhou,Yuehao Wu,Yibo Zhang,Yeyubei Zhang,Yunchong Liu,Bolin Huang,Chunhong Yuan*

主要分类: cs.CV

摘要简述: 本文提出了一种语义反讽识别网络（SemIRNet），通过引入ConceptNet知识库、设计跨模态语义相似性检测模块以及对比学习损失函数，显著提升了多模态反讽检测任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 针对多模态反讽检测任务中图形与文本隐含关联难以准确识别的问题，本文旨在通过引入常识推理和跨模态语义建模，提升模型的识别能力。

研究方法: 1. 首次引入ConceptNet知识库以增强常识推理能力；2. 设计了词级和样本级跨模态语义相似性检测模块；3. 采用对比学习损失函数优化样本特征空间分布。

研究结果: 在公开数据集上，模型准确率和F1值分别提升1.64%和2.88%，达到88.87%和86.33%。消融实验验证了知识融合和语义相似性检测的重要性。

研究结论: SemIRNet通过知识融合和跨模态语义建模，显著提升了多模态反讽检测的性能，为相关任务提供了新思路。

中文摘要: 针对多模态反讽检测任务中图形与文本隐含关联难以准确识别的问题，本文提出了一种语义反讽识别网络（SemIRNet）。该模型包含三项主要创新：（1）首次引入ConceptNet知识库以获取概念知识，增强模型的常识推理能力；（2）设计了词级和样本级两种跨模态语义相似性检测模块，以建模不同粒度的图文关联；（3）引入对比学习损失函数优化样本特征的空间分布，提升正负样本的可分性。在公开的多模态反讽检测基准数据集上的实验表明，该模型的准确率和F1值分别比现有最优方法提升了1.64%和2.88%，达到88.87%和86.33%。进一步的消融实验验证了知识融合和语义相似性检测对提升模型性能的重要作用。

</details>


### [53] [Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?](https://arxiv.org/abs/2506.14805)
**中文标题：Argus检验：多模态大语言模型是否拥有全视之眼？**

*Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang*

主要分类: cs.CV

摘要简述: 本文提出Argus Inspection基准和Eye of Panoptes框架，用于评估多模态大语言模型（MLLMs）在细粒度视觉感知和常识因果推理方面的能力。实验显示当前模型性能有限，提升空间显著。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）的发展，其认知和推理能力显著提升，但在细粒度视觉感知和常识因果推理方面仍存在挑战。本文旨在通过新基准和框架全面评估这些能力。

研究方法: 提出Argus Inspection基准，包含两个难度级别，强调细粒度视觉识别和常识因果推理。进一步设计Eye of Panoptes框架，结合Sigmoid指标和指示函数，全面评估MLLMs在基于观点的推理任务中的表现。

研究结果: 在26个主流MLLMs上的实验表明，视觉细粒度推理的最高性能仅为0.46，显示出模型在这些任务中的表现仍有较大提升空间。

研究结论: 研究为MLLMs的进一步优化提供了重要视角，强调了细粒度视觉感知和常识推理能力的重要性。

中文摘要: 随着多模态大语言模型（MLLMs）的不断发展，其认知和推理能力取得了显著进步。然而，在视觉细粒度感知和常识因果推理方面仍存在挑战。本文提出Argus Inspection基准，包含两个难度级别，强调细粒度视觉识别，同时结合现实世界的常识理解以评估因果推理能力。在此基础上，我们进一步提出Eye of Panoptes框架，该框架将二元参数Sigmoid指标与指示函数相结合，能够更全面地评估MLLMs在基于观点的推理任务中的响应。在26个主流MLLMs上进行的实验显示，视觉细粒度推理的最高性能仅为0.46，表明仍有较大的提升潜力。本研究为MLLMs的持续优化提供了宝贵的视角。

</details>


### [54] [A Hybrid ConvNeXt-EfficientNet AI Solution for Precise Falcon Disease Detection](https://arxiv.org/abs/2506.14816)
**中文标题：一种基于ConvNeXt-EfficientNet混合AI模型的猎鹰疾病精准检测方法**

*Alavikunhu Panthakkan,Zubair Medammal,S M Anzar,Fatma Taher,Hussain Al-Ahmad*

主要分类: cs.CV

摘要简述: 本文提出了一种结合ConvNeXt和EfficientNet的混合AI模型，用于精准检测猎鹰疾病，优于传统方法和单一模型架构。


<details>
  <summary>详细信息</summary>
研究动机: 猎鹰训练和狩猎传统中，猎鹰的健康监测至关重要。传统方法效率低下，亟需一种精准的AI解决方案来检测猎鹰疾病。

研究方法: 采用ConvNeXt和EfficientNet混合模型，对猎鹰的三种状态（正常、肝病和曲霉病）进行分类，并通过大量数据集训练和验证模型性能。

研究结果: 混合模型在准确率、精确率、召回率和F1分数等关键指标上表现优异，优于传统诊断方法和单一模型架构。

研究结论: 该混合AI模型为猎鹰疾病检测提供了高效精准的解决方案，并为未来AI驱动的禽类健康监测奠定了基础。

中文摘要: 猎鹰训练与狩猎是一项备受尊崇的传统，需要细致的健康监测以确保这些珍贵鸟类在狩猎场景中的健康与安全。本文提出了一种创新的方法，结合ConvNeXt和EfficientNet AI模型对猎鹰疾病进行分类，重点关注三种状态：正常、肝病和曲霉病。研究使用了大量数据集进行模型训练和验证，并着重评估了准确率、精确率、召回率和F1分数等关键性能指标。广泛的测试与分析表明，我们的混合AI模型优于传统诊断方法和单一模型架构。该混合AI模型的成功实施标志着猎鹰疾病精准检测的重要进展，并为未来AI驱动的禽类健康解决方案奠定了基础。

</details>


### [55] [ViLLa: A Neuro-Symbolic approach for Animal Monitoring](https://arxiv.org/abs/2506.14823)
**中文标题：ViLLa：一种神经符号方法用于动物监测**

*Harsha Koduri*

主要分类: cs.CV

摘要简述: ViLLa是一种神经符号框架，用于可解释的动物监测，结合视觉检测、语言解析和符号推理，回答自然语言查询。


<details>
  <summary>详细信息</summary>
研究动机: 自然环境中监测动物种群需要系统能够同时处理视觉数据和人类语言查询，ViLLa旨在提供模块化和透明的解决方案。

研究方法: ViLLa由三部分组成：视觉检测模块识别动物及其位置，语言解析器理解自然语言查询，符号推理层通过逻辑推理回答问题。

研究结果: ViLLa在多种动物图像任务中表现优异，能够准确回答计数、存在和位置相关的问题。

研究结论: ViLLa通过分离感知、理解和推理，提供了一种透明且模块化的动物监测方法，优于端到端黑盒模型。

中文摘要: 监测自然环境中的动物种群需要能够同时解释视觉数据和人类语言查询的系统。本文介绍了ViLLa（视觉-语言-逻辑方法），一种专为可解释动物监测设计的神经符号框架。ViLLa整合了三个核心组件：用于识别图像中动物及其空间位置的视觉检测模块、用于理解自然语言查询的语言解析器，以及通过逻辑推理回答这些查询的符号推理层。给定一张图像和一个问题（如“场景中有多少只狗？”或“水牛在哪里？”），系统将视觉检测结果转换为符号事实，并使用预定义规则计算与计数、存在和位置相关的准确答案。与端到端黑盒模型不同，ViLLa分离了感知、理解和推理，提供了模块化和透明性。该系统在多种动物图像任务中进行了评估，展示了将视觉内容与结构化、人类可解释查询相结合的能力。

</details>


### [56] [GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction](https://arxiv.org/abs/2506.14825)
**中文标题：GraphGSOcc：基于语义与几何图Transformer的3D高斯溅射占据预测**

*Ke Song,Yunhe Wu,Chunchit Siu,Huiyuan Xiong*

主要分类: cs.CV

摘要简述: 本文提出GraphGSOcc模型，结合语义与几何图Transformer，解决3D高斯溅射方法中语义关联不足与边界模糊问题，实验显示性能提升且内存降低。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D高斯溅射方法存在语义关联不足和边界模糊问题，本文旨在通过结合语义与几何图Transformer解决这些问题。

研究方法: 提出Dual Gaussians Graph Attention，动态构建几何图和语义图，结合Multi-scale Graph Attention框架优化边界细节与对象级拓扑。

研究结果: 在SurroundOcc数据集上，mIoU达24.10%，GPU内存降至6.1 GB，性能提升1.97%，内存减少13.7%。

研究结论: GraphGSOcc通过语义与几何图Transformer有效提升3D高斯溅射的语义关联与边界精度，同时降低内存消耗。

中文摘要: 针对自动驾驶中的3D语义占据预测任务，本文解决了现有3D高斯溅射（3DGS）方法的两个关键问题：（1）统一特征聚合忽略了相似类别和跨区域的语义关联；（2）MLP迭代优化中缺乏几何约束导致的边界模糊。我们提出了GraphGSOcc模型，一种结合语义与几何图Transformer的新框架。通过Dual Gaussians Graph Attention动态构建双图结构：几何图基于高斯位姿自适应计算KNN搜索半径，使大尺度高斯从更广邻域聚合特征，而紧凑高斯关注局部几何一致性；语义图通过余弦相似度保留前M个高度相关节点，显式编码实例内和跨实例的语义关系。结合Multi-scale Graph Attention框架，低层细粒度注意力优化边界细节，高层粗粒度注意力建模对象级拓扑。在SurroundOcc数据集上的实验实现了24.10%的mIoU，GPU内存降至6.1 GB，相比GaussianWorld，mIoU提升1.97%，内存减少13.7%。

</details>


### [57] [DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning](https://arxiv.org/abs/2506.14827)
**中文标题：DAVID-XR1：基于可解释推理的AI生成视频检测**

*Yifeng Gao,Yifan Ding,Hongyu Su,Juncheng Li,Yunhan Zhao,Lin Luo,Zixing Chen,Li Wang,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang*

主要分类: cs.CV

摘要简述: 本文提出DAVID-XR1，一种可解释的AI生成视频检测方法，通过缺陷分类、时空定位和自然语言解释，将检测过程从黑盒决策转变为透明诊断。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成视频在媒体平台上的普及，可靠区分合成内容与真实视频变得迫切且重要。现有方法仅将其视为二分类任务，缺乏对检测原因的详细解释。

研究方法: 作者引入DAVID-X数据集，包含AI生成视频的缺陷级时空标注和书面解释。基于此，提出DAVID-XR1模型，结合视觉推理链（缺陷分类、时空定位和自然语言解释），实现透明检测。

研究结果: 实验表明，通用主干网络在DAVID-X数据集上微调后，结合思维链蒸馏，能泛化到多种生成器和生成模式，效果显著。

研究结论: DAVID-XR1展示了可解释检测方法在AI生成视频可信识别中的潜力，为透明诊断提供了新方向。

中文摘要: 随着AI生成视频在媒体平台上的广泛传播，可靠区分合成内容与真实视频变得既紧迫又必要。现有方法主要将此问题视为二分类任务，对模型为何判定视频为AI生成的原因缺乏深入解释。然而，核心挑战不仅在于检测细微伪影，还需提供细粒度、有说服力的证据，以说服审核者和终端用户。为解决这一关键问题，我们首次提出DAVID-X数据集，其中包含AI生成视频的缺陷级时空标注和书面解释。利用这些丰富标注，我们设计了DAVID-XR1，一种视频-语言模型，能够提供可解释的视觉推理链，包括缺陷分类、时空定位和自然语言解释。这一方法从根本上将AI生成视频检测从黑盒决策转变为透明且可验证的诊断过程。实验表明，通用主干网络在我们的紧凑数据集上微调，并结合思维链蒸馏，能够泛化到多种生成器和生成模式。结果凸显了可解释检测方法在可信识别AI生成视频内容中的潜力。

</details>


### [58] [Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review](https://arxiv.org/abs/2506.14831)
**中文标题：多智能体人类轨迹预测的最新进展：全面综述**

*Céline Finet,Stephane Da Silva Martins,Jean-Bernard Hayet,Ioannis Karamouzas,Javad Amirian,Sylvie Le Hégarat-Mascle,Julien Pettré,Emanuel Aldea*

主要分类: cs.CV

摘要简述: 本文综述了2020至2024年间基于深度学习的多智能体人类轨迹预测的最新进展，重点分析了模型架构、输入表示和预测策略，并探讨了ETH/UCY基准测试中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据驱动方法在人类轨迹预测中的广泛应用，深入理解多智能体交互成为可能，这对自动驾驶和人群建模等领域具有重要意义。本文旨在总结该领域的最新研究进展。

研究方法: 本文对2020至2024年间发表的深度学习多智能体轨迹预测研究进行了系统综述，根据模型架构、输入表示和预测策略对现有方法进行分类，并重点关注ETH/UCY基准测试中的模型表现。

研究结果: 综述揭示了多智能体轨迹预测领域的最新进展，总结了不同方法的优缺点，并指出ETH/UCY基准测试中表现优异的模型。

研究结论: 本文总结了多智能体人类轨迹预测的研究现状，提出了未来研究方向，为该领域的进一步发展提供了参考。

中文摘要: 随着数据驱动方法在人类轨迹预测（HTP）中的兴起，深入理解多智能体交互成为可能，这对自动驾驶和人群建模等领域具有重要意义。本文综述了2020至2024年间基于深度学习的多智能体轨迹预测的最新进展，重点关注了模型架构、输入表示和整体预测策略，并特别强调了使用ETH/UCY基准测试评估的模型。此外，我们还指出了多智能体HTP领域的关键挑战和未来研究方向。

</details>


### [59] [ArchShapeNet:An Interpretable 3D-CNN Framework for Evaluating Architectural Shapes](https://arxiv.org/abs/2506.14832)
**中文标题：ArchShapeNet：一种用于评估建筑形状的可解释3D-CNN框架**

*Jun Yin,Jing Zhong,Pengyu Zeng,Peilin Li,Zixuan Dai,Miao Zhang,Shuai Lu*

主要分类: cs.CV

摘要简述: 本文提出ArchShapeNet，一个用于评估建筑形状的3D-CNN框架，通过构建ArchForms-4000数据集和引入显著性模块，模型在区分人类设计与机器生成3D形式上表现优异，准确率达94.29%。


<details>
  <summary>详细信息</summary>
研究动机: 当代建筑设计中，生成式工具快速产生初始概念和探索3D形式的需求日益增长，但如何客观分析人类设计与机器生成3D形式的差异仍具挑战性，阻碍了生成工具的进步。

研究方法: 构建ArchForms-4000数据集（包含2000个人类设计和2000个Evomass生成的3D形式），提出ArchShapeNet（一种专用于分类和分析建筑形式的3D-CNN，包含显著性模块以突出与建筑推理相关的关键空间特征）。

研究结果: 模型在区分形式来源上表现优于人类专家，准确率94.29%，精确率96.2%，召回率98.51%，揭示了人类设计在空间组织、比例和谐及细节优化上的独特优势。

研究结论: 本研究不仅突显了人类设计形式的优势，还为未来生成式设计工具的改进提供了宝贵见解。

中文摘要: 在当代建筑设计中，设计需求的复杂性和多样性使得生成式插件工具成为快速生成初始概念和探索新颖3D形式的必备工具。然而，客观分析人类设计与机器生成3D形式之间的差异仍具挑战性，限制了对各自优势的理解，并阻碍了生成工具的进步。为此，我们构建了ArchForms-4000数据集，包含2000个建筑师设计和2000个Evomass生成的3D形式；提出了ArchShapeNet，一种专用于分类和分析建筑形式的3D卷积神经网络，并引入显著性模块以突出与建筑推理相关的关键空间特征；通过对比实验表明，我们的模型在区分形式来源上优于人类专家，准确率达94.29%，精确率96.2%，召回率98.51%。本研究不仅揭示了人类设计形式在空间组织、比例和谐及细节优化上的独特优势，还为未来生成式设计工具的改进提供了宝贵见解。

</details>


### [60] [Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices](https://arxiv.org/abs/2506.14833)
**中文标题：基于熵的自适应缓冲和MobileNetV2的边缘设备实时低延迟监控系统**

*Poojashree Chandrashekar Pankaj M Sajjanar*

主要分类: cs.CV

摘要简述: 本文提出了一种基于熵的自适应帧缓冲算法，结合MobileNetV2，在资源受限的边缘设备上实现了高性能、低延迟的视频监控系统，延迟低于50毫秒，检测准确率超过92%。


<details>
  <summary>详细信息</summary>
研究动机: 针对资源受限环境（如树莓派、NVIDIA Jetson Nano等嵌入式平台）中视频监控系统的高性能和低延迟需求，设计一种能够在复杂环境下保持高准确率且符合严格数据隐私法规的解决方案。

研究方法: 提出了一种基于熵的自适应帧缓冲算法，并与轻量级模型MobileNetV2结合，优化了视频流的实时处理能力。系统在嵌入式设备上实现了端到端推理延迟低于50毫秒。

研究结果: 系统在标准视频监控数据集上实现了超过92%的检测准确率，并对光照、背景和速度变化表现出鲁棒性。对比和消融实验验证了设计的有效性。

研究结论: 该架构具有可扩展性、低成本性，并符合严格的数据隐私法规，适用于智能城市或嵌入式安全架构。

中文摘要: 本文描述了一种针对资源受限环境设计的高性能、低延迟视频监控系统。我们提出了一种基于熵的自适应帧缓冲算法，并将其与MobileNetV2结合，实现了高吞吐量和低延迟。该系统能够在树莓派、亚马逊和NVIDIA Jetson Nano等资源受限设备上处理实时视频流，端到端推理延迟低于50毫秒。我们的方法在标准视频监控数据集上保持了超过92%的检测准确率，并对不同光照、背景和速度表现出鲁棒性。多项对比和消融实验验证了设计的有效性。最后，我们的架构具有可扩展性、低成本性，并符合比常见监控系统更严格的数据隐私法规，因此该系统可以应用于智能城市或嵌入式安全架构。

</details>


### [61] [MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation](https://arxiv.org/abs/2506.14835)
**中文标题：MonoVQD：基于变分查询去噪与自蒸馏的单目3D目标检测**

*Kiet Dang Vu,Trung Thai Tran,Duc Dung Nguyen*

主要分类: cs.CV

摘要简述: MonoVQD提出了一种基于DETR的单目3D检测新框架，通过变分查询去噪和自蒸馏技术显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 单目3D检测中，DETR类架构的直接应用存在性能瓶颈，MonoVQD旨在通过创新方法解决这些问题。

研究方法: 1. 提出掩码分离自注意力机制，将去噪过程融入DETR架构；2. 引入变分查询去噪技术，解决梯度消失问题；3. 设计自蒸馏策略，利用后期解码层信息优化早期查询。

研究结果: MonoVQD在KITTI单目基准测试中表现优异，其核心组件在多视图3D检测（nuScenes数据集）中也展现出强大泛化能力。

研究结论: MonoVQD通过创新方法显著提升了单目3D检测性能，并展示了广泛的适用性和泛化能力。

中文摘要: 从单张图像中精确定位3D物体是单目3D检测的核心挑战。尽管DETR类架构提供了强大的范式，但其直接应用在该领域存在固有局限，无法实现最优性能。本研究通过提出MonoVQD框架，从根本上推动了基于DETR的单目3D检测。我们提出三项主要贡献：首先，提出掩码分离自注意力机制，将去噪过程融入DETR架构，提升匈牙利匹配的稳定性以实现一致的优化目标；其次，提出变分查询去噪技术，解决传统去噪方法的梯度消失问题，通过显式引入随机特性缓解这一根本限制并显著提升性能；最后，引入一种复杂的自蒸馏策略，利用后期解码层的信息协同优化早期层的查询质量，从而增强迭代优化过程。实验表明，MonoVQD在KITTI单目基准测试中表现优异，其核心组件可无缝集成到其他架构中，在nuScenes数据集的多视图3D检测场景中也展现出显著性能提升，凸显其强大的泛化能力。

</details>


### [62] [Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction](https://arxiv.org/abs/2506.14837)
**中文标题：基于结构化指令的图表到代码生成的改进迭代优化方法**

*Chengzhi Xu,Yuyang Wang,Lai Wei,Lichao Sun,Weiran Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于结构化指令的迭代优化方法ChartIR，用于提升多模态大语言模型在图表到代码生成任务中的表现。通过将任务分解为视觉理解和代码翻译两部分，并设计描述和差异两种结构化指令，显著提高了生成代码的准确性。实验表明，该方法在开源模型Qwen2-VL和闭源模型GPT-4o上均优于其他方法。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型在视觉任务中表现优异，但在图表到代码生成任务中表现欠佳。该任务要求模型不仅需要精确理解图表内容，还需将视觉元素准确转换为结构化代码。直接提示模型完成这一复杂任务效果不佳，因此需要一种更有效的方法来提升性能。

研究方法: 提出ChartIR方法，将任务分解为视觉理解和代码翻译两部分。设计两种结构化指令：描述指令用于捕捉参考图表的视觉元素，差异指令用于描述参考图表与生成图表之间的差异。通过将视觉特征转化为语言表示，促进代码翻译过程。此外，将生成流程分为初始代码生成和迭代优化两个阶段，逐步提升输出质量。

研究结果: 实验结果表明，ChartIR方法在开源模型Qwen2-VL和闭源模型GPT-4o上均优于其他方法，显著提高了图表到代码生成的准确性和效率。

研究结论: 通过结构化指令和迭代优化，ChartIR方法有效解决了多模态大语言模型在图表到代码生成任务中的性能瓶颈，为复杂视觉任务的代码生成提供了新思路。

中文摘要: 近年来，多模态大语言模型（MLLMs）因其强大的视觉理解能力受到广泛关注。尽管在多种视觉任务中表现优异，但在图表到代码生成任务中仍表现不佳。该任务要求MLLMs生成可执行代码以复现给定图表，不仅需要精确的视觉理解，还需将视觉元素准确转换为结构化代码。直接提示MLLMs完成这一复杂任务往往效果不理想。为解决这一问题，我们提出了基于结构化指令的迭代优化方法ChartIR。首先，我们将任务分为视觉理解和代码翻译两部分。为实现视觉理解，设计了两种结构化指令：描述指令用于捕捉参考图表的视觉元素，差异指令用于描述参考图表与生成图表之间的差异。这些指令将视觉特征转化为语言表示，从而促进代码翻译过程。其次，将图表生成流程分为初始代码生成和迭代优化两个阶段，逐步提升最终输出质量。实验结果表明，与其他方法相比，我们的方法在开源模型Qwen2-VL和闭源模型GPT-4o上均取得了更优的性能。

</details>


### [63] [PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers](https://arxiv.org/abs/2506.14842)
**中文标题：PictSure：预训练嵌入对上下文学习图像分类器至关重要**

*Lukas Schiesser,Cornelius Wolff,Sophie Haas,Simon Pukrop*

主要分类: cs.CV

摘要简述: PictSure是一种专注于嵌入模型预训练的上下文学习框架，通过分析视觉编码器类型、预训练目标和微调策略，显著提升了少样本图像分类的跨域性能。


<details>
  <summary>详细信息</summary>
研究动机: 在数据稀缺领域构建图像分类模型困难，现有上下文学习方法忽视了嵌入模型的关键作用。PictSure旨在通过系统研究嵌入模型的预训练对少样本分类性能的影响，填补这一空白。

研究方法: PictSure框架以嵌入模型为核心，系统研究了视觉编码器类型、预训练目标和微调策略对少样本图像分类性能的影响。

研究结果: 实验表明，嵌入模型的预训练方式显著影响训练成功率和跨域性能。PictSure在跨域任务中优于现有方法，同时在域内任务中保持竞争力。

研究结论: PictSure通过优化嵌入模型预训练，提升了少样本图像分类的跨域性能，为数据稀缺领域提供了有效解决方案。

中文摘要: 在数据稀缺领域构建图像分类模型仍然困难，因为收集大规模标注数据集不切实际。上下文学习（ICL）已成为少样本图像分类（FSIC）的有前景范式，使模型无需基于梯度的适应即可跨域泛化。然而，先前工作大多忽视了基于ICL的FSIC流程中的一个关键组成部分：图像嵌入的作用。本文提出PictSure，一个将嵌入模型（其架构、预训练和训练动态）置于分析中心的ICL框架。我们系统研究了不同视觉编码器类型、预训练目标和微调策略对下游FSIC性能的影响。实验表明，训练成功率和跨域性能高度依赖于嵌入模型的预训练方式。因此，PictSure在显著不同于训练分布的跨域基准测试中优于现有基于ICL的FSIC模型，同时在域内任务中保持可比结果。代码见https://github.com/PictSure/pictsure-library。

</details>


### [64] [Finding Optimal Kernel Size and Dimension in Convolutional Neural Networks An Architecture Optimization Approach](https://arxiv.org/abs/2506.14846)
**中文标题：卷积神经网络中核大小和维度的优化：一种架构优化方法**

*Shreyas Rajeev,B Sathish Babu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为BKSEF的框架，用于在卷积神经网络中优化逐层核大小选择，通过平衡信息增益、计算效率和准确性提升，实验显示其能显著提高模型性能并降低计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 卷积神经网络中的核大小选择对模型性能至关重要，但通常被忽视。本文旨在通过数学和实证方法优化核大小，以提升模型效率和准确性。

研究方法: 提出Best Kernel Size Estimation Function (BKSEF)，结合信息论、信号处理和学习理论，逐层确定最优核大小。

研究结果: 在多个数据集上的实验表明，BKSEF引导的模型比传统3x3核模型准确率提升3.1%，计算量减少42.8%。两个实际案例进一步验证了其有效性。

研究结论: BKSEF为CNN设计提供了理论和实践支持，证明核大小是可优化的参数，适用于神经架构搜索和实时系统。

中文摘要: 卷积神经网络（CNN）中的核大小选择是一个关键但常被忽视的设计决策，它影响感受野、特征提取、计算成本和模型准确性。本文提出了最佳核大小估计函数（BKSEF），这是一个基于数学和实证验证的框架，用于逐层确定最优核大小。BKSEF通过整合信息论、信号处理和学习理论的原理，平衡信息增益、计算效率和准确性提升。在CIFAR-10、CIFAR-100、ImageNet-lite、ChestX-ray14和GTSRB数据集上的广泛实验表明，BKSEF引导的架构比传统使用统一3x3核的模型在准确性上提升3.1%，计算量减少42.8%。两个实际案例进一步验证了该方法：一个用于基于云的医学图像分类，另一个用于边缘设备上的交通标志识别。前者提高了可解释性和准确性，后者显著降低了延迟和模型大小，且准确性损失极小。这些结果表明，核大小可以是一个可优化的参数，而非固定启发式。BKSEF为研究人员和开发者提供了实用的启发式方法和理论支持，适用于高效且应用感知的CNN设计。它适合集成到神经架构搜索管道和实时系统中，为CNN优化提供了新视角。

</details>


### [65] [Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis](https://arxiv.org/abs/2506.14854)
**中文标题：高效零售视频标注：一种用于产品与顾客交互分析的鲁棒关键帧生成方法**

*Varun Mannam,Zhenyu Shi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的零售视频关键帧生成方法，通过自动化标注显著降低人工成本，同时保持高准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统零售视频标注依赖人工，效率低且成本高。本文旨在通过自动化关键帧识别和标注，解决这些问题。

研究方法: 采用深度神经网络学习视频帧的判别特征，结合针对零售环境优化的目标检测技术，实现关键帧自动识别和标注。

研究结果: 实验表明，该方法在准确性上与人工标注相当，同时将标注成本降低2倍，且仅需人工验证不到5%的帧。

研究结论: 该方法显著提升了零售视频标注的效率和成本效益，适用于顾客行为分析、产品交互检测等多种零售场景。

中文摘要: 准确的视频标注在现代零售应用中至关重要，包括顾客行为分析、产品交互检测和店内活动识别。然而，传统标注方法严重依赖耗时的人工标注，导致帧选择不鲁棒且运营成本增加。为解决零售领域的这些挑战，我们提出了一种基于深度学习的方法，自动化识别零售视频中的关键帧，并提供产品和顾客的自动标注。我们的方法利用深度神经网络学习判别特征，通过嵌入视频帧并结合针对零售环境优化的目标检测技术。实验结果表明，我们的方法优于传统方法，在准确性上与人工标注相当，同时显著提升了零售视频标注的整体效率。值得注意的是，我们的方法平均节省了2倍的标注成本。通过仅需人工验证/调整视频数据集中不到5%的检测帧，同时自动化标注其余帧而不降低标注质量，零售商可大幅降低运营成本。关键帧检测的自动化显著节省了零售视频标注任务的时间和精力，对顾客旅程分析、产品交互检测和店内安全监控等多种零售应用极具价值。

</details>


### [66] [Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction](https://arxiv.org/abs/2506.14856)
**中文标题：探索未知：基于神经不确定性图的主动视角选择用于3D重建**

*Zhengquan Zhang,Feng Xu,Mengmi Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为UPNet的轻量级神经网络，用于预测视角不确定性图，以指导3D重建中的主动视角选择（AVS）。该方法通过减少冗余视角，显著提高了计算效率，并在减少50%视角的情况下实现了与基线方法相当的精度。


<details>
  <summary>详细信息</summary>
研究动机: 3D重建中的主动视角选择（AVS）是一个关键问题，传统方法通常需要大量计算资源。本文旨在通过预测视角不确定性图，高效选择最具信息量的视角，从而降低计算开销并提高重建精度。

研究方法: 提出UPNet，一种轻量级前馈神经网络，能够从单张输入图像预测所有候选视角的不确定性图。通过聚合历史预测的不确定性图，抑制冗余视角并选择最具信息量的视角。随后，利用所选视角训练3D神经渲染模型。

研究结果: 实验表明，尽管仅使用基线方法一半的视角，该方法仍实现了与之相当的3D重建精度。同时，计算开销显著降低，速度提升高达400倍，CPU、RAM和GPU使用量减少超过50%。此外，该方法无需额外训练即可泛化到新物体类别。

研究结论: UPNet通过预测视角不确定性图，实现了高效且精确的主动视角选择，显著降低了计算资源需求，并展示了良好的泛化能力。

中文摘要: 某些视角自然比其他视角提供更多信息。AI系统如何确定哪个视角能为准确高效的3D物体重建提供最有价值的洞察？主动视角选择（AVS）在3D重建中仍是计算机视觉的一个基本挑战，其目标是识别能够产生最准确3D重建的最小视角集合。不同于NeRF或3D高斯泼溅等方法从当前观测学习辐射场并为每个候选视角计算不确定性，我们提出了一种新的AVS方法，该方法由轻量级前馈深度神经网络UPNet预测的神经不确定性图指导。UPNet以3D物体的单张输入图像为输入，输出预测的不确定性图，表示所有候选视角的不确定性值。通过利用从观察大量自然物体及其相关不确定性模式中提取的启发式规则，我们训练UPNet学习从视角外观到底层体积表示不确定性的直接映射。接着，我们的方法聚合所有先前预测的神经不确定性图，以抑制冗余候选视角并有效选择最具信息量的视角。利用这些选定的视角，我们训练3D神经渲染模型，并与其他竞争性AVS方法比较新视角合成的质量。值得注意的是，尽管仅使用上限视角的一半，我们的方法仍实现了与之相当的重建精度。此外，与基线方法相比，该方法显著降低了AVS过程中的计算开销，速度提升高达400倍，同时CPU、RAM和GPU使用量减少超过50%。尤为突出的是，我们的方法无需额外训练即可有效泛化到涉及新物体类别的AVS任务。

</details>


### [67] [DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization](https://arxiv.org/abs/2506.14903)
**中文标题：DETONATE：文本到图像对齐与核化直接偏好优化的基准测试**

*Renjith Prasad,Abhilekh Borah,Hasnat Md Abdullah,Chathurangi Shyalika,Gurpreet Singh,Ritvik Garimella,Rajarshi Roy,Harshul Surana,Nasrin Imanpour,Suranjana Trivedy,Amit Sheth,Amitava Das*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DPO-Kernels的新方法，用于增强文本到图像（T2I）模型的对齐能力，并发布了首个大规模基准测试DETONATE，用于评估模型在种族、性别和残疾等社会偏见方面的表现。


<details>
  <summary>详细信息</summary>
研究动机: 文本到图像模型的对齐问题至关重要，以确保生成的图像准确反映用户意图，同时避免安全性和公平性问题。本文旨在通过扩展直接偏好优化（DPO）方法，提升T2I模型的对齐能力。

研究方法: 提出了DPO-Kernels方法，包括：(i) 混合损失，结合嵌入目标和传统概率损失；(ii) 核化表示，使用RBF、多项式和Wavelet核进行特征转换；(iii) 发散选择，扩展KL正则化器，引入Wasserstein和R'enyi发散。此外，发布了DETONATE基准测试，包含10万对图像，并提出了对齐质量指数（AQI）来衡量潜在空间的可分离性。

研究结果: 实验表明，DPO-Kernels通过重尾自正则化（HT-SR）保持了强泛化能力，并在DETONATE基准测试中表现出色。AQI揭示了潜在空间中的隐藏漏洞。

研究结论: DPO-Kernels为T2I模型的对齐问题提供了有效的解决方案，DETONATE基准测试为未来研究提供了重要工具。

中文摘要: 对齐对于文本到图像（T2I）模型至关重要，以确保生成的图像忠实反映用户意图，同时保持安全性和公平性。直接偏好优化（DPO）在大型语言模型（LLM）中表现突出，现正扩展至T2I系统。本文为T2I模型引入了DPO-Kernels，这是一种新颖的扩展方法，通过以下三个维度增强对齐能力：(i) 混合损失，将嵌入目标与传统概率损失相结合以优化性能；(ii) 核化表示，使用径向基函数（RBF）、多项式和Wavelet核实现更丰富的特征转换，并更好地区分安全与不安全输入；(iii) 发散选择，超越DPO默认的Kullback-Leibler（KL）正则化器，引入Wasserstein和R'enyi发散以增强稳定性和鲁棒性。我们发布了DETONATE，这是首个同类大规模基准测试，包含约10万对精选图像，分为选择和拒绝两类。DETONATE涵盖了种族、性别和残疾三个社会偏见维度。提示文本来自仇恨言论数据集，图像由领先的T2I模型生成，包括Stable Diffusion 3.5 Large、Stable Diffusion XL和Midjourney。此外，我们提出了对齐质量指数（AQI），这是一种新颖的几何度量，用于量化安全/不安全图像激活在潜在空间中的可分离性，揭示隐藏的漏洞。实验表明，DPO-Kernels通过重尾自正则化（HT-SR）保持了强泛化能力。DETONATE和完整代码已公开发布。

</details>


### [68] [PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2506.14907)
**中文标题：PeRL：基于排列增强的强化学习用于交错视觉语言推理**

*Yizhen Zhang,Yang Ding,Shuoshuo Zhang,Xinchen Zhang,Haoling Li,Zhong-zhi Li,Peijie Wang,Jie Wu,Lei Ji,Yelong Shen,Yujiu Yang,Yeyun Gong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PeRL的强化学习方法，通过图像序列排列和多阶段策略优化，显著提升了多图像视觉语言推理任务的性能，并在多个基准测试中达到最优表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态强化学习方法主要局限于单图像空间推理，难以推广到涉及多图像位置关系的复杂场景。本文旨在解决这一挑战，提升模型在多图像任务中的推理能力。

研究方法: PeRL通过图像序列排列模拟多样化的位置关系，引入多阶段策略优化探索与利用的平衡，并设计了轨迹过滤机制以专注于对学习最优行为贡献最大的轨迹。

研究结果: 实验表明，PeRL在多图像基准测试中大幅超越现有方法，达到最优性能，同时在单图像任务中保持了可比的表现。

研究结论: PeRL为多图像视觉语言推理任务提供了一种高效的强化学习框架，显著提升了模型在复杂场景中的推理能力。

中文摘要: 受DeepSeek-R1等强化学习方法在推理能力上的启发，近期研究开始探索利用强化学习（RL）增强视觉语言模型（VLMs）在多模态推理任务中的表现。然而，现有方法多局限于单图像空间推理，难以推广到涉及多图像位置关系的复杂场景。为此，我们提出了一种通用的强化学习方法PeRL，专为交错多模态任务设计，并引入多阶段策略优化探索与利用的平衡，从而提升学习效率和任务性能。具体而言，我们通过图像序列排列模拟多样化的位置关系，并设计轨迹过滤机制以专注于对学习最优行为贡献最大的轨迹。我们在5个多图像基准测试和3个单图像基准测试上评估了模型性能。实验表明，PeRL训练模型在多图像任务中大幅超越R1相关方法及交错VLM基线，达到最优性能，同时在单图像任务中保持了可比表现。

</details>


### [69] [Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models](https://arxiv.org/abs/2506.14919)
**中文标题：医学图像扩散模型的频率校准成员推断攻击**

*Xinkai Zhao,Yuta Tokuoka,Junichiro Iwasawa,Keita Oda*

主要分类: cs.CV

摘要简述: 本文提出了一种针对医学图像扩散模型的频率校准重建误差（FCRE）方法，用于成员推断攻击（MIA）。通过聚焦中频范围的重建误差，排除高频和低频区域，显著提升了攻击效果。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在医学图像生成中的应用日益广泛，但现有成员推断攻击方法依赖重建误差，易受图像固有难度和高频细节重建困难的干扰。本文旨在解决这些问题，量化隐私风险。

研究方法: 提出频率校准重建误差（FCRE）方法：分析反向扩散过程，提取中频范围重建误差，计算重建图像与原图的结构相似性指数得分，通过阈值比较判断成员资格。

研究结果: 在多个医学图像数据集上的实验表明，FCRE方法优于现有MIA方法，有效减少了图像固有难度对攻击结果的干扰。

研究结论: FCRE方法通过频率选择策略显著提升了成员推断攻击的准确性，为医学图像扩散模型的隐私风险评估提供了可靠工具。

中文摘要: 扩散模型在图像生成中的应用日益增多，尤其是在医学影像等敏感领域，引发了严重的隐私担忧。成员推断攻击（MIA）是一种潜在方法，用于判断特定图像是否用于训练扩散模型，从而量化隐私风险。现有MIA方法通常依赖扩散重建误差，其中成员图像的重建误差预期低于非成员图像。然而，这些方法直接应用于医学图像时面临挑战。重建误差受图像固有难度影响，且扩散模型在高频细节重建上表现不佳。为解决这些问题，我们提出了一种频率校准重建误差（FCRE）方法，用于医学图像扩散模型的MIA。通过聚焦特定中频范围的重建误差，并排除高频（难以重建）和低频（信息较少）区域，我们的频率选择性方法减轻了图像固有难度的干扰。具体而言，我们分析反向扩散过程，获取中频重建误差，并计算重建图像与原图的结构相似性指数得分。通过比较该得分与阈值确定成员资格。在多个医学图像数据集上的实验表明，FCRE方法优于现有MIA方法。

</details>


### [70] [Vision Transformers for End-to-End Quark-Gluon Jet Classification from Calorimeter Images](https://arxiv.org/abs/2506.14934)
**中文标题：基于Vision Transformer的端到端夸克-胶子喷注分类：从量能器图像出发**

*Md Abrar Jahin,Shahriar Soudeep,Arian Rahman Aditta,M. F. Mridha,Nafiz Fahad,Md. Jakir Hossen*

主要分类: cs.CV

摘要简述: 本文系统评估了Vision Transformer (ViT)及其与CNN混合模型在夸克-胶子喷注分类中的性能，发现ViT模型在全局上下文建模方面优于传统CNN，为高能物理中的喷注分类提供了新方法。


<details>
  <summary>详细信息</summary>
研究动机: 在高能物理中，区分夸克和胶子引发的喷注对新物理搜索和精确测量至关重要。尽管CNN在喷注分类中表现优异，但ViT模型在全局信息建模方面的潜力尚未充分探索，尤其是在实际探测器和堆积条件下。

研究方法: 利用2012年CMS公开数据构建多通道喷注图像（包括ECAL、HCAL能量沉积和重建径迹），系统评估ViT及ViT-CNN混合模型的性能，并与传统CNN基线进行比较。

研究结果: ViT模型（尤其是ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上均优于CNN基线，表明其在喷注子结构的长程空间相关性建模中具有优势。

研究结论: 本文首次系统性地将ViT架构应用于基于量能器图像的喷注分类，并提供了公开数据集和性能基准，为未来深度学习研究奠定了基础。

中文摘要: 区分夸克和胶子引发的喷注是高能物理中一项关键且具有挑战性的任务，对大型强子对撞机的新物理搜索和精确测量至关重要。尽管深度学习（尤其是卷积神经网络CNN）已通过基于图像的表示推动了喷注标记技术的发展，但Vision Transformer (ViT)架构在直接分析量能器图像方面的潜力（尤其是在实际探测器和堆积条件下）尚未得到充分探索。本文利用模拟的2012年CMS公开数据，系统评估了ViT及ViT-CNN混合模型在夸克-胶子喷注分类中的性能。我们通过探测器级能量沉积（ECAL、HCAL）和重建径迹构建多通道喷注图像，实现了端到端学习。全面的基准测试表明，基于ViT的模型（尤其是ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上均优于传统CNN基线，凸显了其在喷注子结构长程空间相关性建模中的优势。本研究首次为基于量能器图像的喷注分类提供了系统框架和性能基准，并提供了一个适用于该领域深度学习研究的结构化数据集。

</details>


### [71] [Advances in Compliance Detection: Novel Models Using Vision-Based Tactile Sensors](https://arxiv.org/abs/2506.14980)
**中文标题：柔顺性检测的进展：基于视觉触觉传感器的新模型**

*Ziteng Li,Malte Kuhlmann,Ilana Nisky,Nicolás Navarro-Guerrero*

主要分类: cs.CV

摘要简述: 本文提出两种基于LRCN和Transformer的模型，利用视觉触觉传感器GelSight的RGB触觉图像准确预测物体柔顺性，性能显著优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统柔顺性检测方法存在便携性差、成本高且不适合机器人应用的问题，现有基于神经网络的视觉触觉传感器方法预测精度不足。本文旨在解决这些问题。

研究方法: 提出基于长时递归卷积网络（LRCN）和Transformer的两种模型，利用GelSight传感器捕获的RGB触觉图像及其他信息预测柔顺性指标。

研究结果: 模型在多种指标下验证有效，柔顺性估计准确度显著提升，且发现传感器柔顺性与物体柔顺性估计存在相关性。

研究结论: 所提模型在柔顺性预测中表现优异，为工程、农业和生物医学应用提供了更高效的解决方案。

中文摘要: 柔顺性是描述工程、农业和生物医学应用中物体的关键参数。传统柔顺性检测方法因缺乏便携性和可扩展性、依赖昂贵设备且不适合机器人应用而受限。此外，现有基于神经网络的视觉触觉传感器方法预测精度仍不足。本文提出两种基于长时递归卷积网络（LRCN）和Transformer的模型，利用视觉触觉传感器GelSight捕获的RGB触觉图像及其他信息准确预测柔顺性指标。通过多种指标验证模型性能，证明其在柔顺性估计中的有效性。所提模型性能显著优于基线方法。此外，研究发现传感器柔顺性与物体柔顺性估计存在相关性，硬度高于传感器的物体更难估计。

</details>


### [72] [Hyper-Local Deformable Transformers for Text Spotting on Historical Maps](https://arxiv.org/abs/2506.15010)
**中文标题：超局部可变形Transformer用于历史地图文本识别**

*Yijun Lin,Yao-Yi Chiang*

主要分类: cs.CV

摘要简述: 本文提出PALETTE，一种针对历史地图的端到端文本识别方法，通过超局部采样模块和合成数据训练，显著提升长文本和倾斜文本的识别效果。


<details>
  <summary>详细信息</summary>
研究动机: 历史地图中的文本包含丰富的地理、历史和文化信息，但现有方法因缺乏有效技术和训练数据而难以准确提取。传统方法局限于特定地图风格，而现有机器学习方法在提取精确图像特征时仍面临挑战。

研究方法: PALETTE引入超局部采样模块，学习目标边界点和字符周围的局部图像特征，并结合超局部位置嵌入学习空间交互。此外，提出SynthMap+方法自动生成合成地图数据用于训练。

研究结果: PALETTE在两项历史地图基准数据集上表现优于现有方法，尤其在长文本和倾斜文本识别方面。已成功应用于处理6万张地图并生成1亿多文本标签。

研究结论: PALETTE通过超局部特征学习和合成数据训练，显著提升了历史地图文本识别的准确性和适应性，为大规模地图处理提供了有效工具。

中文摘要: 历史地图中的文本提供了丰富的地理、历史和文化背景信息。然而，由于缺乏有效方法和训练数据，从历史地图中提取文本具有挑战性。以往的方法仅针对特定地图风格设计临时步骤。近年来基于机器学习的文本识别方法（如场景图像）因其灵活性有望解决这些问题，但在提取精确图像特征以预测文本实例的每个子组件（边界点和字符）方面仍存在困难。这对于地图文本尤为重要，因为其可能较长、高度旋转且背景复杂，难以从粗略文本区域检测相关特征。本文提出PALETTE，一种适用于多种历史地图的端到端文本识别方法。PALETTE引入超局部采样模块，显式学习目标边界点和字符周围的局部图像特征以进行检测和识别，并结合超局部位置嵌入学习文本实例内和跨实例的空间交互。此外，本文提出SynthMap+方法，自动生成合成地图图像用于训练历史地图文本识别器。实验表明，PALETTE结合SynthMap+在两个新历史地图基准数据集上优于现有方法，尤其在长文本和倾斜文本识别方面。PALETTE已应用于处理David Rumsey历史地图集中的6万多张地图，并生成超过1亿个文本标签以支持地图搜索。项目发布于https://github.com/kartta-foundation/mapkurator-palette-doc。

</details>


### [73] [Break Stylistic Sophon: Are We Really Meant to Confine the Imagination in Style Transfer?](https://arxiv.org/abs/2506.15033)
**中文标题：打破风格束缚：我们真的需要限制风格迁移中的想象力吗？**

*Gary Song Yan,Yusen Zhang,Jinyu Zhao,Hao Zhang,Zhangping Yang,Guanye Xiong,Yanfei Liu,Tao Zhang,Yujie He,Siyuan Tian,Yao Gou,Min Li*

主要分类: cs.CV

摘要简述: 本文提出StyleWallfacer框架，通过语义风格注入、数据增强策略和无训练三重扩散过程，实现高质量的风格迁移和文本驱动风格化，同时保留原始内容。


<details>
  <summary>详细信息</summary>
研究动机: 传统风格迁移方法存在诸多问题，如风格注入效率低、内容漂移等。本文旨在通过统一框架解决这些问题，并实现艺术家级别的风格迁移和文本驱动风格化。

研究方法: 1. 提出基于语义的风格注入方法，利用BLIP生成与风格图像语义严格对齐的文本描述，并通过大语言模型移除风格相关描述，形成语义间隙用于模型微调。2. 提出基于人类反馈的数据增强策略，将高质量样本加入训练集以减少过拟合。3. 设计无训练三重扩散过程，通过替换自注意力层的键和值实现风格注入，同时保留文本控制。

研究结果: 实现了高质量图像驱动风格迁移和文本驱动风格化，首次在风格迁移过程中完成图像颜色编辑，并保留了原始图像内容。

研究结论: StyleWallfacer框架通过创新方法解决了传统风格迁移的局限性，为艺术家级别的风格迁移和文本驱动风格化提供了高效解决方案。

中文摘要: 在这项开创性研究中，我们提出了StyleWallfacer，一种革命性的统一训练和推理框架，不仅解决了传统方法在风格迁移过程中遇到的各种问题，还为不同任务提供了统一框架。该框架旨在通过实现艺术家级别的风格迁移和文本驱动风格化来革新该领域。首先，我们提出了一种基于语义的风格注入方法，利用BLIP生成与风格图像语义严格对齐的文本描述，并通过大语言模型移除风格相关描述，形成语义间隙。这一间隙用于微调模型，实现高效且无漂移的风格知识注入。其次，我们提出了一种基于人类反馈的数据增强策略，将微调早期生成的高质量样本加入训练集，以促进渐进学习并显著减少过拟合。最后，我们设计了使用微调模型的无训练三重扩散过程，通过类似于交叉注意力机制的方式操纵自注意力层的特征。具体而言，在生成过程中，内容相关过程的键和值被替换为风格相关过程的键和值，以注入风格同时保持对模型的文本控制。我们还引入了查询保留机制以减少对原始内容的干扰。在此设计下，我们实现了高质量图像驱动风格迁移和文本驱动风格化，提供艺术家级别的风格迁移结果，同时保留原始图像内容。此外，我们首次在风格迁移过程中实现了图像颜色编辑。

</details>


### [74] [Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study](https://arxiv.org/abs/2506.15078)
**中文标题：通过分布匹配增强向量量化：理论与实证研究**

*Xianghong Fang,Litao Guo,Hengchao Chen,Yuxuan Zhang,XiaofanXia,Dingjie Song,Yexin Liu,Hao Wang,Harry Yang,Yuan Yuan,Qiang Sun*

主要分类: cs.CV

摘要简述: 本文提出一种基于Wasserstein距离的向量量化方法，通过匹配特征与码向量的分布，解决训练不稳定和码本崩溃问题，显著提升量化效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有向量量化方法存在训练不稳定和码本崩溃问题，主要源于特征与码向量分布不匹配。本文旨在通过分布对齐解决这些问题。

研究方法: 使用Wasserstein距离对齐特征与码向量的分布，减少量化误差并提高码本利用率。

研究结果: 实验和理论分析表明，该方法实现了接近100%的码本利用率，并显著降低了量化误差。

研究结论: 通过分布匹配优化向量量化，有效解决了训练不稳定和码本崩溃问题，提升了量化性能。

中文摘要: 自回归模型的成功很大程度上依赖于向量量化的有效性，这是一种通过将连续特征映射到可学习码本中的最近码向量来离散化连续特征的技术。现有向量量化方法存在两个关键问题：训练不稳定和码本崩溃。训练不稳定源于直通估计器引入的梯度差异，尤其是在量化误差较大时；而码本崩溃则发生在训练过程中仅使用少量码向量时。进一步分析表明，这些问题主要由特征与码向量分布不匹配引起，导致码向量缺乏代表性，并在压缩过程中丢失大量数据信息。为解决这一问题，我们采用Wasserstein距离对齐这两种分布，实现了接近100%的码本利用率，并显著降低了量化误差。实证和理论分析均验证了该方法的有效性。

</details>


### [75] [SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts](https://arxiv.org/abs/2506.15153)
**中文标题：SynPo：通过高质量负提示提升无训练少样本医学图像分割**

*Yufei Liu,Haoke Xiao,Jiaxing Chai,Yongcun Zhang,Rong Wang,Zijie Meng,Zhiming Luo*

主要分类: cs.CV

摘要简述: SynPo是一种基于大型视觉模型（如SAM）的无训练少样本医学图像分割方法，通过提升负提示的质量，显著改善了低对比度医学图像的分割效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于大型视觉模型的无训练方法在医学图像分割中未能有效利用负提示，导致低对比度图像分割效果不佳。SynPo旨在通过提升负提示质量解决这一问题。

研究方法: SynPo设计了一个置信度图协同模块，结合DINOv2和SAM的优势生成可靠置信度图，从中选择高置信度像素作为正提示点，并通过高斯分布选择负提示点。随后对两组点进行独立K-means聚类，作为高质量提示输入SAM进行分割。

研究结果: 实验表明，SynPo在少样本医学图像分割任务中表现优异，性能接近基于训练的最先进方法。

研究结论: SynPo通过优化负提示质量，显著提升了无训练少样本医学图像分割的性能，为低对比度图像分割提供了有效解决方案。

中文摘要: 大型视觉模型（LVMs）的出现为少样本医学图像分割提供了新机遇。然而，现有的基于LVMs的无训练方法未能有效利用负提示，导致在低对比度医学图像上表现不佳。为解决这一问题，我们提出了SynPo，一种基于LVMs（如SAM）的无训练少样本方法，其核心思想是提升负提示的质量。为了在更可靠的置信度图中选择点提示，我们设计了一个新颖的置信度图协同模块，结合了DINOv2和SAM的优势。基于置信度图，我们选择前k个像素作为正点集，并通过高斯分布选择负点集，随后对两组点进行独立K-means聚类。这些选定的点作为高质量提示输入SAM以获取分割结果。大量实验表明，SynPo的性能接近基于训练的最先进少样本方法。

</details>


### [76] [Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation](https://arxiv.org/abs/2506.15160)
**中文标题：基于跨阶段结构相关性的邻域聚合校正增强点云分析**

*Jiaqi Shi,Jin Xiao,Xiaoguang Hu,Boyang Song,Hao Jiang,Tianyou Chen,Baochang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于跨阶段结构相关性的点云分析方法（PDSA），通过高维空间相关性校正特征分布，解决了局部坐标限制下的无关点干扰和特征层次差距问题，同时提升了计算效率和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 点云分析是许多下游任务的基础，但现有方法在聚合局部结构时存在无关点干扰和特征层次差距问题，且直接几何结构编码方法计算开销大、对噪声敏感。本文旨在解决这些问题。

研究方法: 提出点分布集抽象模块（PDSA），利用高维空间相关性校正特征分布，通过轻量级跨阶段结构描述符区分点相关性，并通过减少邻居特征矩阵方差和长距离建模增强结构同质性。引入关键点机制优化计算开销。

研究结果: 在语义分割和分类任务上的实验验证了方法的泛化性，性能显著提升且参数成本更低。消融实验和可视化结果证明了方法的有效性和合理性。

研究结论: PDSA模块通过高维空间相关性校正特征分布，有效解决了局部坐标限制下的问题，提升了点云分析的效率和鲁棒性。

中文摘要: 点云分析是许多下游任务的基石，其中聚合局部结构是理解点云数据的基础。尽管许多工作利用三维相对坐标聚合邻域，但由于局部坐标的限制，存在无关点干扰和特征层次差距问题。虽然一些工作通过显式建模跨阶段结构来细化空间描述，但这些基于直接几何结构编码的增强方法存在计算开销大和对噪声敏感的问题。为解决这些问题，我们提出了点分布集抽象模块（PDSA），利用高维空间的相关性在聚合过程中校正特征分布，从而提升计算效率和鲁棒性。PDSA基于轻量级跨阶段结构描述符区分点相关性，并通过减少邻居特征矩阵的方差和长距离建模增强结构同质性。此外，我们引入关键点机制优化计算开销。基于不同基线的语义分割和分类任务的实验结果验证了所提方法的泛化性，并以更少的参数成本实现了显著的性能提升。相应的消融实验和可视化结果证明了方法的有效性和合理性。代码和训练权重可在以下网址获取：https://github.com/AGENT9717/PointDistribution

</details>


### [77] [Echo-DND: A dual noise diffusion model for robust and precise left ventricle segmentation in echocardiography](https://arxiv.org/abs/2506.15166)
**中文标题：Echo-DND：一种用于超声心动图中左心室鲁棒精确分割的双噪声扩散模型**

*Abdur Rahman,Keerthiveena Balraj,Manojkumar Ramteke,Anurag Singh Rathore*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Echo-DND的双噪声扩散模型，用于超声心动图中左心室的精确分割。该模型结合高斯和伯努利噪声，并引入多尺度融合条件模块和空间一致性校准，显著提升了分割精度。在CAMUS和EchoNet-Dynamic数据集上的实验表明，其性能优于现有SOTA模型，Dice分数分别达到0.962和0.939。


<details>
  <summary>详细信息</summary>
研究动机: 超声心动图中的左心室分割对诊断和治疗至关重要，但由于图像噪声多、对比度低且边界模糊，传统方法难以实现高精度分割。因此，需要一种更鲁棒和精确的分割模型来解决这些问题。

研究方法: Echo-DND采用双噪声扩散模型，结合高斯和伯努利噪声，并设计了多尺度融合条件模块以提升分割精度。此外，通过空间一致性校准确保分割掩模的空间完整性。

研究结果: 在CAMUS和EchoNet-Dynamic数据集上的实验结果显示，Echo-DND的Dice分数分别达到0.962和0.939，显著优于现有SOTA模型。

研究结论: Echo-DND为超声心动图分割设立了新标准，其架构在其他医学影像任务中也有广泛应用潜力，有望提升多种医学领域的诊断准确性。

中文摘要: 扩散概率模型（DPMs）的最新进展在图像处理领域带来了革命性变化，尤其在医学应用中展现出巨大潜力。超声心动图中左心室（LV）的精确分割对诊断和治疗至关重要，但由于超声图像噪声多、对比度低且LV边界模糊，分割任务极具挑战性。为解决这些问题，本文提出了Echo-DND，一种专为此任务设计的双噪声扩散模型。Echo-DND结合了高斯和伯努利噪声，并引入多尺度融合条件模块以提升分割精度，同时通过空间一致性校准确保分割掩模的空间完整性。该模型在CAMUS和EchoNet-Dynamic数据集上进行了严格验证，实验结果表明其性能优于现有SOTA模型，Dice分数分别达到0.962和0.939。Echo-DND为超声心动图分割设立了新标准，其架构在其他医学影像任务中也有广泛应用潜力，有望提升多种医学领域的诊断准确性。项目页面：https://abdur75648.github.io/Echo-DND

</details>


### [78] [ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections](https://arxiv.org/abs/2506.15180)
**中文标题：ReSeDis：基于指代的大规模图像集合对象搜索数据集**

*Ziling Huang,Yidan Zhang,Shin'ichi Satoh*

主要分类: cs.CV

摘要简述: 本文提出ReSeDis任务，首次将大规模图像检索与像素级定位结合，解决现有技术无法同时实现检索与定位的问题，并提供了基准数据集和评估指标。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉搜索技术仅能解决检索或定位中的单一问题，无法满足实际需求。视觉定位假设对象存在于每张测试图像中，而文本到图像检索仅提供整体匹配，缺乏细粒度定位。ReSeDis任务旨在统一这两者，提供更全面的解决方案。

研究方法: 提出ReSeDis任务，要求模型根据自由描述判断图像中是否存在目标对象，并返回其边界框或分割掩码。为此，作者构建了一个基准数据集，确保每个描述唯一对应分散在大规模多样化数据集中的对象实例，并设计了联合评估检索召回和定位精度的指标。

研究结果: 通过构建ReSeDis基准数据集和任务特定指标，作者展示了现有技术的局限性，并提供了一个基于冻结视觉语言模型的零样本基线方法，揭示了未来研究的改进空间。

研究结论: ReSeDis为构建下一代鲁棒且可扩展的多模态搜索系统提供了现实的端到端测试平台，填补了现有技术的空白。

中文摘要: 大规模视觉搜索引擎需要同时解决两个问题：(i) 定位包含句子描述对象的每张图像，(ii) 在每个匹配图像中识别对象的边界框或精确像素。现有技术仅解决其中一方面。视觉定位能提供精确的边界框和掩码，但假设对象存在于每张测试图像中，应用于网络规模图像集合时会产生大量误报。文本到图像检索擅长从海量数据库中筛选相关图像，但仅提供整体匹配，缺乏细粒度定位。我们提出了指代搜索与发现（ReSeDis），这是首个将语料库级检索与像素级定位统一的任务。给定自由描述，ReSeDis模型需判断每张图像中是否存在查询对象，并返回其边界框或分割掩码。为支持严谨研究，我们构建了一个基准数据集，确保每个描述唯一对应分散在大规模多样化语料库中的对象实例，避免意外匹配。我们还设计了任务特定指标，联合评估检索召回和定位精度。最后，我们提供了一个基于冻结视觉语言模型的零样本基线方法，揭示了未来研究的改进空间。ReSeDis为构建下一代鲁棒且可扩展的多模态搜索系统提供了现实的端到端测试平台。

</details>


### [79] [Conquering the Retina: Bringing Visual in-Context Learning to OCT](https://arxiv.org/abs/2506.15200)
**中文标题：征服视网膜：将视觉上下文学习引入OCT**

*Alessio Negrini,Simon Reiß*

主要分类: cs.CV

摘要简述: 本文探讨了如何通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域，并提出了一种评估协议，展示了VICL在OCT中的潜力与局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前医学图像分析领域高度依赖针对特定临床任务的专用模型，这些模型虽性能优异但适用性有限，且开发和调整需要大量资源。通用模型则允许医疗从业者动态定义任务，无需开发特定任务模型。本文旨在探索如何通过VICL训练通用模型，以提升OCT领域的灵活性和实用性。

研究方法: 本文采用视觉上下文学习（VICL）方法，训练模型在推理时基于少量示例泛化到不同任务。为评估VICL在OCT中的表现，作者提出了一种专门的评估协议，并在多个视网膜OCT数据集上对先进的医学VICL方法进行了全面测试。

研究结果: 研究结果表明，VICL在OCT领域具有潜力，能够实现跨任务的泛化。同时，作者也揭示了当前方法的局限性，为未来研究提供了基线数据。

研究结论: 本文通过VICL为OCT领域提供了一种通用模型的训练方法，展示了其潜力，并公开了代码以促进进一步研究和实际应用。

中文摘要: 近年来，医学图像分析领域的进展催生了针对特定临床任务的高度专业化模型。这些模型表现出色，但仍是一个重要的研究方向。然而，它们的适用性仅限于预定义任务，且开发和调整需要专业知识和大量资源。相比之下，通用模型提供了另一种实用性：允许医疗从业者动态定义任务，而无需开发特定任务模型。本文探讨了如何通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域，即在推理时基于少量示例实现跨任务泛化。为便于严格评估，我们提出了一种针对OCT中VICL的广泛评估协议。我们在多个视网膜OCT数据集上对先进的医学VICL方法进行了全面评估，建立了首个基线，以展示OCT中上下文学习的潜力与当前局限性。为促进进一步研究和实际应用，我们公开了代码。

</details>


### [80] [Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models](https://arxiv.org/abs/2506.15201)
**中文标题：隐私保护图像压缩：防御视觉-语言预训练模型的利用**

*Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PSIC的隐私保护图像压缩方法，通过多解码选项的比特流防止视觉-语言预训练模型对公开图像的语义利用，同时保留原始压缩功能。


<details>
  <summary>详细信息</summary>
研究动机: 随着视觉-语言预训练模型语义理解能力的提升，公开图像的隐私保护变得困难。本文旨在通过图像压缩阶段的防御措施，防止图像被搜索引擎等工具利用。

研究方法: 提出PSIC方法，生成具有多解码选项的比特流；默认解码保留感知质量但阻止VLP模型解析，同时支持自定义条件重建完整语义图像。引入CLTG模块生成偏置信息，设计UAEO优化函数利用目标VLP模型的软标签，并采用自适应多目标优化策略。

研究结果: 实验表明，PSIC在多个下游任务中有效保护隐私，同时保持图像压缩性能。

研究结论: PSIC是一种即插即用的隐私保护图像压缩方案，可无缝集成到现有LIC模型中，平衡隐私保护与感知质量。

中文摘要: 视觉-语言预训练（VLP）模型的语义理解能力提升使得公开图像的隐私保护愈发困难。为此，本文通过在图像压缩阶段实施防御措施，防止图像被搜索引擎等工具利用。具体而言，我们提出了一种灵活的编码方法，称为隐私保护图像压缩（PSIC），可生成具有多解码选项的比特流。默认解码保留感知质量并阻止VLP模型解析，同时保留原始图像压缩功能。通过自定义输入条件，该方案可重建保留完整语义信息的图像。我们提出条件潜在触发生成（CLTG）模块，基于自定义条件生成偏置信息以指导解码过程，并设计不确定性感知加密导向（UAEO）优化函数，利用目标VLP模型对训练数据的软标签推断。本文还采用自适应多目标优化策略，在统一训练过程中同时提升加密性能和感知质量。该方案即插即用，可无缝集成到大多数现有学习型图像压缩（LIC）模型中。多下游任务的广泛实验验证了设计的有效性。

</details>


### [81] [DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder](https://arxiv.org/abs/2506.15218)
**中文标题：DM-FNet：基于扩散过程训练的编码器-解码器实现统一多模态医学图像融合**

*Dan He,Weisheng Li,Guofen Wang,Yuping Huang,Shiqiang Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于扩散模型的两阶段多模态医学图像融合网络（DM-FNet），通过扩散过程训练编码器-解码器，显著提升了融合图像的质量和信息密度。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态医学图像融合方法在传统训练中难以捕捉细节特征，且跨模态特征交互不足，导致融合图像质量不佳。为解决这些问题，本研究提出了一种新的融合方法。

研究方法: DM-FNet分为两个阶段：第一阶段通过扩散过程训练UNet进行图像重建，捕捉细节信息；第二阶段将不同步骤的噪声图像输入融合网络，增强特征识别能力，并结合三个关键融合模块自适应处理不同模态的医学图像。

研究结果: 实验结果表明，DM-FNet在多种医学图像类型上表现优异，融合图像保留了适当的亮度、放射性示踪剂的全面分布、丰富的纹理和清晰的边缘。

研究结论: DM-FNet通过扩散模型和融合模块的结合，显著提升了多模态医学图像融合的质量和信息密度，为医学诊断提供了更全面的支持。

中文摘要: 多模态医学图像融合（MMIF）从多个源图像中提取最有意义的信息，以实现更全面和准确的诊断。高质量的融合结果需要对亮度、颜色、对比度和细节进行仔细平衡，以确保融合图像有效显示相关解剖结构并反映组织的功能状态。然而，现有的MMIF方法在传统训练中捕捉细节特征的能力有限，且跨模态特征交互不足，导致融合图像质量不理想。为解决这些问题，本研究提出了一种基于扩散模型的两阶段融合网络（DM-FNet）以实现统一的MMIF。在第一阶段，通过扩散过程训练UNet进行图像重建。UNet通过逐步去噪捕捉细节信息，并表征多级数据，为后续融合网络提供丰富的特征表示。在第二阶段，将不同步骤的噪声图像输入融合网络以增强模型的特征识别能力。此外，还集成了三个关键融合模块，以自适应处理不同模态的医学图像。最终，通过鲁棒的网络结构和混合损失函数，协调融合图像的亮度、颜色、对比度和细节，提升其质量和信息密度。在多种医学图像类型上的实验结果表明，所提方法在客观评价指标上表现优异。融合图像保留了适当的亮度、放射性示踪剂的全面分布、丰富的纹理和清晰的边缘。代码可在https://github.com/HeDan-11/DM-FNet获取。

</details>


### [82] [video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2506.15220)
**中文标题：video-SALMONN 2：字幕增强的音频-视觉大型语言模型**

*Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang*

主要分类: cs.CV

摘要简述: 本文介绍了video-SALMONN 2，一种通过低秩适应（LoRA）和定向偏好优化（DPO）增强视频（带音频）字幕生成的音频-视觉大型语言模型。提出多轮DPO（MrDPO）方法，显著提升字幕准确性，错误率降低28%，性能超越GPT-4o和Gemini-1.5-Pro。


<details>
  <summary>详细信息</summary>
研究动机: 视频包含丰富信息，生成详细准确的自然语言描述是视频理解的关键。现有模型在字幕生成任务中仍有改进空间，因此提出video-SALMONN 2，旨在通过优化训练方法和评估指标提升性能。

研究方法: 提出video-SALMONN 2模型，结合LoRA和DPO优化视频字幕生成。引入多轮DPO（MrDPO）方法，周期性更新参考模型、合并并重新初始化LoRA模块，并利用真实字幕指导训练。

研究结果: 实验表明，MrDPO显著提升字幕准确性，错误率降低28%。最终模型仅7B参数，在视频字幕任务中超越GPT-4o和Gemini-1.5-Pro，并在视频问答基准中保持竞争力。

研究结论: video-SALMONN 2通过MrDPO和LoRA优化，显著提升视频字幕生成性能，成为高效且强大的音频-视觉语言模型。

中文摘要: 视频包含丰富信息，生成详细准确的自然语言描述是视频理解的关键。本文提出video-SALMONN 2，一种通过低秩适应（LoRA）和定向偏好优化（DPO）增强视频（带音频）字幕生成的音频-视觉大型语言模型。我们提出新指标评估视频描述的完整性和准确性，并通过DPO优化。为进一步提升训练，提出多轮DPO（MrDPO）方法，周期性更新DPO参考模型，合并并重新初始化LoRA模块作为参数更新的代理，并在每轮训练（1000步）后结合真实字幕指导以稳定过程。实验结果表明，MrDPO显著提升video-SALMONN 2的字幕准确性，错误率降低28%。最终video-SALMONN 2模型仅7B参数，在视频字幕任务中超越GPT-4o和Gemini-1.5-Pro，同时在类似规模模型中保持广泛使用的视频问答基准上的竞争力。代码发布于\href{https://github.com/bytedance/video-SALMONN-2}{https://github.com/bytedance/video-SALMONN-2}。

</details>


### [83] [Convolutional Feature Enhancement and Attention Fusion BiFPN for Ship Detection in SAR Images](https://arxiv.org/abs/2506.15231)
**中文标题：SAR图像中船舶检测的卷积特征增强与注意力融合BiFPN**

*Liangjie Meng,Danxia Li,Jinrong He,Lili Ma,Zhixin Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为C-AFBiFPN的新型特征增强与融合框架，用于解决SAR图像中船舶检测的挑战，包括多尺度变化、小目标与噪声混合以及复杂背景问题。通过卷积特征增强模块和注意力融合BiFPN，显著提升了检测精度和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: SAR图像在船舶检测中面临多尺度变化、小目标与噪声混合以及复杂背景等问题，现有方法难以有效解决。本文旨在通过特征增强和注意力融合技术提升检测性能。

研究方法: 提出C-AFBiFPN框架，包含卷积特征增强（CFE）模块和注意力融合BiFPN（AFBiFPN）。CFE模块增强局部细节和上下文信息表示，AFBiFPN通过BiFormer注意力改进跨尺度特征融合的全局建模能力。

研究结果: 在SAR船舶检测数据集（SSDD）上的实验表明，该方法显著提升了小目标检测精度、抗遮挡鲁棒性以及对多尺度特征的适应性。

研究结论: C-AFBiFPN通过特征增强和注意力融合有效解决了SAR船舶检测中的关键问题，为复杂场景下的目标检测提供了新思路。

中文摘要: 合成孔径雷达（SAR）通过主动微波和先进信号处理技术实现了亚米级分辨率成像和全天候监测。目前，SAR在船舶检测等关键海事领域得到广泛应用。然而，SAR船舶检测面临多尺度变化、小目标与噪声混合以及大型近岸船舶复杂背景等挑战。为解决这些问题，本文提出了一种名为C-AFBiFPN的新型特征增强与融合框架。C-AFBiFPN在骨干网络后构建了卷积特征增强（CFE）模块，旨在丰富特征表示并增强局部细节和上下文信息的捕获能力。此外，C-AFBiFPN创新性地将BiFormer注意力融入BiFPN的融合策略中，形成了AFBiFPN网络。AFBiFPN提升了跨尺度特征融合的全局建模能力，并能自适应地聚焦关键特征区域。在SAR船舶检测数据集（SSDD）上的实验结果表明，所提方法显著提升了小目标检测精度、抗遮挡鲁棒性以及对多尺度特征的适应性。

</details>


### [84] [RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories](https://arxiv.org/abs/2506.15242)
**中文标题：RA-NeRF：复杂轨迹下基于精确相机姿态估计的鲁棒神经辐射场重建**

*Qingsong Yan,Qiang Wang,Kaiyong Zhao,Jie Chen,Bo Li,Xiaowen Chu,Fei Deng*

主要分类: cs.CV

摘要简述: RA-NeRF是一种新颖方法，能够在复杂相机轨迹下实现高精度相机姿态估计，并通过流驱动姿态调节和隐式姿态滤波提升场景重建的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的NeRF和3DGS方法依赖准确的相机姿态先验，但在复杂轨迹下表现不佳。RA-NeRF旨在解决这一问题，提升复杂轨迹下的姿态估计和场景重建效果。

研究方法: RA-NeRF采用增量式流程，结合光度一致性和流驱动姿态调节优化初始化与定位，并通过隐式姿态滤波捕捉相机运动模式以消除噪声。

研究结果: 在Tanks&Temple和NeRFBuster数据集上，RA-NeRF在相机姿态估计和视觉质量上均达到最优效果，验证了其复杂轨迹下的鲁棒性。

研究结论: RA-NeRF通过流驱动姿态调节和隐式姿态滤波，显著提升了复杂相机轨迹下的姿态估计和场景重建性能。

中文摘要: 神经辐射场（NeRF）和3D高斯喷溅（3DGS）已成为3D重建和SLAM任务中的强大工具。然而，它们的性能高度依赖于准确的相机姿态先验。现有方法尝试通过引入外部约束解决这一问题，但在复杂相机轨迹下仍难以达到满意的精度。本文提出了一种新方法RA-NeRF，能够在复杂相机轨迹下预测高精度的相机姿态。RA-NeRF采用增量式流程，利用光度一致性重建场景，并通过流驱动姿态调节增强初始化和定位的鲁棒性。此外，RA-NeRF采用隐式姿态滤波捕捉相机运动模式并消除姿态估计中的噪声。为验证方法有效性，我们在Tanks&Temple数据集和具有挑战性相机轨迹的NeRFBuster数据集上进行了广泛实验。在两个数据集上，RA-NeRF在相机姿态估计和视觉质量上均达到了最优效果，证明了其在复杂姿态轨迹下场景重建的有效性和鲁棒性。

</details>


### [85] [Retrospective Memory for Camouflaged Object Detection](https://arxiv.org/abs/2506.15244)
**中文标题：基于回忆记忆的伪装目标检测**

*Chenxi Zhang,Jiayun Wu,Qing Zhang,Yazhe Zhai,Youwei Pang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为RetroMem的回忆增强型伪装目标检测架构，通过动态整合历史知识来提升模型对复杂伪装场景的适应性和检测效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有伪装目标检测方法主要基于静态视觉表示建模，缺乏获取历史背景的显式机制，限制了其在复杂场景中的适应性和有效性。本文旨在通过引入历史知识动态调制伪装模式感知与推理，提升检测性能。

研究方法: RetroMem采用两阶段训练范式：学习阶段通过密集多尺度适配器（DMA）增强预训练编码器捕捉多尺度信息的能力；回忆阶段通过动态记忆机制（DMM）和推理模式重建（IPR）利用历史知识与当前样本上下文关系重构伪装模式推理。

研究结果: 在多个广泛使用的数据集上的实验表明，RetroMem显著优于现有最先进方法。

研究结论: RetroMem通过动态整合历史知识，显著提升了伪装目标检测的性能，为复杂伪装场景的理解提供了有效解决方案。

中文摘要: 伪装目标检测（COD）主要关注从复杂场景中学习微妙但具有区分性的表示。现有方法主要基于静态视觉表示建模的参数前馈架构，但缺乏获取历史背景的显式机制，限制了其在处理挑战性伪装场景时的适应性和有效性。本文提出了一种回忆增强的COD架构，即RetroMem，通过将相关历史知识动态整合到过程中来调制伪装模式的感知和推理。具体而言，RetroMem采用两阶段训练范式，包括学习阶段和回忆阶段，以有效构建、更新和利用记忆表示。在学习阶段，我们设计了一个密集多尺度适配器（DMA），以极少的可训练参数提升预训练编码器捕捉丰富多尺度视觉信息的能力，从而提供基础推理。在回忆阶段，我们提出了动态记忆机制（DMM）和推理模式重建（IPR）。这些组件充分利用学习知识与当前样本上下文之间的潜在关系来重构伪装模式的推理，从而显著提升模型对伪装场景的理解。在多个广泛使用的数据集上的大量实验表明，我们的RetroMem显著优于现有最先进方法。

</details>


### [86] [Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing](https://arxiv.org/abs/2506.15260)
**中文标题：半导体制造缺陷图像分类的域适应技术**

*Adrian Poniatowski,Natalie Gentner,Manuel Barusco,Davide Dalle Pezze,Samuele Salti,Gian Antonio Susto*

主要分类: cs.CV

摘要简述: 本文研究了域适应（DA）技术在半导体制造缺陷图像分类中的应用，提出了一种改进的CycleGAN模型（DBACS），并在半监督和无监督设置下验证了其有效性，显著减少了人工标注和模型重新训练的需求。


<details>
  <summary>详细信息</summary>
研究动机: 半导体行业竞争激烈，缩短上市时间和保证质量是关键。深度学习在缺陷分类等工业应用中取得了显著成功，但跨域适应问题仍需解决。域适应技术能够利用源域知识在目标域中高效工作，减少资源消耗，因此研究其在半导体领域的应用具有重要意义。

研究方法: 本文提出了一种名为DBACS的改进模型，基于CycleGAN并增加了额外的损失项以提升性能。在半监督和无监督设置下，使用真实的电子显微镜图像对方法进行了验证。

研究结果: 实验结果表明，DBACS方法在半导体领域的域适应任务中表现优异，显著减少了人工标注和重新训练的需求，同时提高了模型的鲁棒性和可扩展性。

研究结论: 域适应技术在半导体制造缺陷分类中具有重要应用价值，DBACS方法的提出进一步推动了该领域的技术发展，为工业4.0和5.0应用提供了有力支持。

中文摘要: 在半导体行业，由于需求旺盛且竞争激烈，缩短上市时间和保证质量是确保市场份额的关键因素。近年来，深度学习在计算机视觉领域的成功为工业4.0和5.0应用（如缺陷分类）带来了显著进展。域适应（DA）技术因其能够利用源域知识在相关目标域中高效工作而表现出色。通过提高鲁棒性和可扩展性，DA减少了对大量人工重新标注或模型重新训练的需求，不仅降低了计算和资源成本，还使专家能够专注于高价值任务。因此，我们在半导体领域的半监督和无监督设置下测试了DA技术的有效性，并提出了一种基于CycleGAN的改进模型DBACS，通过增加额外的损失项提升性能。所有方法均在真实的电子显微镜图像上进行了验证，证明了其在推动半导体领域DA技术发展中的实用性。

</details>


### [87] [MSNeRV: Neural Video Representation with Multi-Scale Feature Fusion](https://arxiv.org/abs/2506.15276)
**中文标题：MSNeRV：基于多尺度特征融合的神经视频表示**

*Jun Zhu,Xinfeng Zhang,Lv Tang,JunHao Jiang*

主要分类: cs.CV

摘要简述: MSNeRV提出了一种多尺度特征融合框架，通过时间窗口增强时间一致性，并利用多尺度空间解码器和自适应损失函数，显著提升了神经视频表示和压缩性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于隐式神经表示（INR）的视频压缩方法在处理细节密集和快速变化的视频内容时表现不佳，主要原因是网络内部特征利用不足且缺乏视频特定的设计。

研究方法: MSNeRV采用时间窗口增强时间一致性，将视频分组处理，并设计多尺度空间解码器和自适应损失函数。此外，引入多尺度特征块以充分利用隐藏特征。

研究结果: 在HEVC ClassB和UVG数据集上的实验表明，MSNeRV在神经视频表示中表现优异，压缩效率甚至超过VTM-23.7（随机访问）。

研究结论: MSNeRV通过多尺度特征融合和视频特定设计，显著提升了神经视频表示和压缩性能，为未来研究提供了新方向。

中文摘要: 隐式神经表示（INR）已成为视频压缩的一种有前景的方法，其性能已与H.266/VVC等先进编解码器相当。然而，现有基于INR的方法难以有效表示细节密集和快速变化的视频内容，主要原因是网络内部特征利用不足且缺乏视频特定的设计。为解决这些问题，我们提出了一种多尺度特征融合框架MSNeRV用于神经视频表示。在编码阶段，通过时间窗口增强时间一致性，并将视频分为多个图像组（GoP），其中GoP级网格用于背景表示。此外，我们设计了多尺度空间解码器和自适应损失函数，以整合多分辨率和多频率信息。为进一步提升特征提取，我们引入了多尺度特征块以充分利用隐藏特征。我们在HEVC ClassB和UVG数据集上评估了MSNeRV的视频表示和压缩性能。实验结果表明，我们的模型在基于INR的方法中表现出卓越的表示能力，并在动态场景中的压缩效率超过了VTM-23.7（随机访问）。

</details>


### [88] [BCRNet: Enhancing Landmark Detection in Laparoscopic Liver Surgery via Bezier Curve Refinement](https://arxiv.org/abs/2506.15279)
**中文标题：BCRNet：通过Bezier曲线细化增强腹腔镜肝脏手术中的标志检测**

*Qian Li,Feng Liu,Shuojue Yang,Daiyun Shen,Yueming Jin*

主要分类: cs.CV

摘要简述: BCRNet通过Bezier曲线细化策略显著提升腹腔镜肝脏手术中的关键解剖标志检测精度，结合多模态特征提取和分层曲线优化机制，在L3D和P2ILF数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 腹腔镜肝脏手术中，精确识别解剖标志对手术导航至关重要。现有方法在检测曲线形标志时存在不足，BCRNet旨在通过Bezier曲线细化策略提升检测精度。

研究方法: BCRNet包含多模态特征提取模块（MFE）以捕获语义特征，自适应曲线提案初始化（ACPI）生成初始Bezier曲线，并通过分层曲线细化（HCR）机制多阶段优化曲线。

研究结果: 在L3D和P2ILF数据集上的实验表明，BCRNet显著优于现有方法，检测精度显著提升。

研究结论: BCRNet通过Bezier曲线细化策略和多模态特征提取，有效提升了腹腔镜肝脏手术中的标志检测精度，为手术导航提供了可靠支持。

中文摘要: 腹腔镜肝脏手术虽微创，但精确识别关键解剖结构仍具挑战性。基于2D-3D配准的增强现实（AR）系统通过整合MRI/CT与腹腔镜图像，为手术导航提供了潜在解决方案。配准过程中的关键环节是精确检测腹腔镜图像中的曲线形解剖标志。本文提出BCRNet（Bezier曲线细化网络），通过Bezier曲线细化策略显著提升腹腔镜肝脏手术中的标志检测。该框架首先通过多模态特征提取（MFE）模块捕获语义特征，随后采用自适应曲线提案初始化（ACPI）生成像素对齐的Bezier曲线及置信度评分作为可靠初始提案。此外，设计了分层曲线细化（HCR）机制，通过多阶段过程迭代优化提案，从多尺度像素级特征中捕获细粒度上下文细节以精确调整Bezier曲线。在L3D和P2ILF数据集上的广泛评估表明，BCRNet优于现有方法，性能显著提升。代码将公开。

</details>


### [89] [AI-driven visual monitoring of industrial assembly tasks](https://arxiv.org/abs/2506.15285)
**中文标题：AI驱动的工业装配任务视觉监控**

*Mattia Nardon,Stefano Messelodi,Antonio Granata,Fabio Poiesi,Alberto Danese,Davide Boscaini*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViMAT的AI驱动系统，用于实时视觉监控工业装配任务，无需依赖固定工作空间设置或视觉标记。ViMAT结合感知模块和推理模块，在部分和不确定的视觉观察下有效完成任务监控。


<details>
  <summary>详细信息</summary>
研究动机: 工业装配任务的视觉监控对防止设备损坏和确保工人安全至关重要。现有商业解决方案通常需要固定工作空间或视觉标记，限制了灵活性。本文旨在开发一种无需这些约束的实时监控系统。

研究方法: ViMAT系统由两部分组成：感知模块从多视角视频流中提取视觉观察，推理模块基于观察到的装配状态和先验任务知识推断最可能的操作。系统在LEGO组件更换和液压机模具重组任务中进行了验证。

研究结果: ViMAT在具有部分和不确定视觉观察的真实场景中表现出色，通过定量和定性分析验证了其有效性。

研究结论: ViMAT是一种无需固定工作空间或视觉标记的AI驱动视觉监控系统，能够有效应对工业装配任务中的复杂场景。

中文摘要: 工业装配任务的视觉监控对防止因程序错误导致的设备损坏和确保工人安全至关重要。尽管存在商业解决方案，但它们通常需要固定的工作空间设置或应用视觉标记以简化问题。我们提出了ViMAT，一种无需这些约束的新型AI驱动系统，用于实时视觉监控装配任务。ViMAT结合了感知模块（从多视角视频流中提取视觉观察）和推理模块（基于观察到的装配状态和先验任务知识推断最可能的操作）。我们在两项装配任务（LEGO组件更换和液压机模具重组）上验证了ViMAT，通过定量和定性分析证明了其在具有部分和不确定视觉观察的挑战性真实场景中的有效性。项目页面：https://tev-fbk.github.io/ViMAT

</details>


### [90] [MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering](https://arxiv.org/abs/2506.15298)
**中文标题：MEGC2025：微表情大挑战——先定位后识别与视觉问答**

*Xinqi Fan,Jingting Li,John See,Moi Hoon Yap,Wen-Huang Cheng,Xiaobai Li,Xiaopeng Hong,Su-Jing Wang,Adrian K. Davision*

主要分类: cs.CV

摘要简述: MEGC2025挑战赛聚焦微表情的‘先定位后识别’和视觉问答任务，旨在通过多模态大模型提升微表情分析的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法将微表情的定位与识别分开处理，效率低下，尤其在长视频分析中表现不佳。多模态大语言模型和视觉语言模型的出现为微表情分析提供了新的可能性。

研究方法: MEGC2025提出两项任务：(1) ME-STR，将微表情定位与识别整合为统一流程；(2) ME-VQA，通过视觉问答探索微表情理解，利用多模态大模型处理多样化问题。

研究结果: 参赛算法需在测试集上运行并提交结果至排行榜，具体细节可通过官网获取。

研究结论: MEGC2025通过整合任务和多模态模型，推动了微表情分析领域的发展。

中文摘要: 面部微表情（MEs）是人在试图抑制情绪时面部产生的无意识动作，常见于高风险环境。近年来，微表情的识别、定位和生成领域取得了显著进展。然而，传统方法将定位与识别分开处理，效率低下，尤其在长视频分析中表现不佳。与此同时，多模态大语言模型（MLLMs）和视觉语言大模型（LVLMs）的出现为微表情分析提供了新的可能性。MEGC2025挑战赛引入两项任务：(1) ME-STR，将微表情定位与识别整合为统一流程；(2) ME-VQA，通过视觉问答探索微表情理解，利用MLLMs或LVLMs处理多样化问题。所有参赛算法需在测试集上运行并提交结果至排行榜。详情请访问https://megc2025.github.io。

</details>


### [91] [MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning](https://arxiv.org/abs/2506.15313)
**中文标题：MapFM：基于基础模型的多任务上下文学习驱动的高清地图生成**

*Leonid Ivanov,Vasily Yuryev,Dmitry Yudin*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MapFM的端到端模型，用于在线生成矢量化高清地图，通过结合强大的基础模型和多任务学习，显著提升了特征表示质量和预测精度。


<details>
  <summary>详细信息</summary>
研究动机: 在自动驾驶中，高清地图和鸟瞰视角的语义地图对精确定位、规划和决策至关重要。然而，现有方法在特征表示和场景理解方面仍有不足，因此需要一种更高效、更准确的在线地图生成方法。

研究方法: MapFM采用端到端模型，结合基础模型编码相机图像，并引入多任务学习框架，通过辅助预测头进行鸟瞰视角的语义分割，以提供更丰富的上下文监督。

研究结果: 实验表明，MapFM显著提升了特征表示质量，生成的矢量化高清地图具有更高的准确性和更好的质量。

研究结论: MapFM通过结合基础模型和多任务学习，提供了一种高效的在线高清地图生成方法，为自动驾驶中的地图需求提供了有力支持。

中文摘要: 在自动驾驶中，高清地图和鸟瞰视角的语义地图对精确定位、规划和决策至关重要。本文提出了一种名为MapFM的增强型端到端模型，用于在线生成矢量化高清地图。通过结合强大的基础模型编码相机图像，我们显著提升了特征表示质量。为了进一步丰富模型对环境的理解并提高预测质量，我们在鸟瞰视角表示中集成了语义分割的辅助预测头。这种多任务学习方法提供了更丰富的上下文监督，从而实现了更全面的场景表示，最终提高了预测的矢量化高清地图的准确性和质量。源代码可在https://github.com/LIvanoff/MapFM获取。

</details>


### [92] [OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models](https://arxiv.org/abs/2506.15318)
**中文标题：OpenPath：基于预训练视觉语言模型的病理图像分类开集主动学习**

*Lanfeng Zhong,Xin Liao,Shichuan Zhang,Shaoting Zhang,Guotai Wang*

主要分类: cs.CV

摘要简述: OpenPath提出了一种基于预训练视觉语言模型的开集主动学习方法，用于病理图像分类，通过任务特定提示和多样化信息采样策略，显著提高了标注效率和模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 病理图像分类在医学诊断和治疗规划中至关重要，但传统主动学习方法在开集场景（存在大量分布外数据）下效率低下，且初始随机选择浪费标注成本。OpenPath旨在解决这些问题。

研究方法: OpenPath利用预训练视觉语言模型，首轮查询使用任务特定提示选择分布内信息样本，后续查询采用原型候选选择和熵引导随机采样策略，确保样本纯度和信息量。

研究结果: 在两个公开病理图像数据集上的实验表明，OpenPath显著提升了模型性能，优于现有开集主动学习方法。

研究结论: OpenPath通过高效选择分布内信息样本，解决了开集主动学习中的标注效率问题，为病理图像分类提供了实用解决方案。

中文摘要: 病理图像分类在医学诊断和治疗规划中具有重要作用。训练高性能模型通常需要大规模标注数据，但获取成本高昂。主动学习（AL）通过迭代选择信息量最大的样本进行标注以减少标注负担。然而，大多数AL方法基于闭集假设，而实际临床环境中未标注数据常包含大量分布外（OOD）数据，导致传统AL方法效率低下。此外，现有AL方法首轮查询通常随机选择，在开集场景下造成标注成本浪费。为解决这些问题，我们提出OpenPath，一种基于预训练视觉语言模型（VLM）的开集主动学习方法。首轮查询中，我们结合目标类和非目标类提示的任务特定提示，从未标注池中高效选择分布内（ID）和信息量大的样本。后续查询中，提出包含原型候选选择（PIS）和熵引导随机采样（EGSS）的多样化信息ID采样（DIS），确保查询的纯度和信息量，避免选择OOD样本。在两个公开病理图像数据集上的实验表明，OpenPath因其高纯度样本选择显著提升了模型性能，优于多种先进开集AL方法。代码发布于\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}。

</details>


### [93] [Open-World Object Counting in Videos](https://arxiv.org/abs/2506.15368)
**中文标题：视频中的开放世界目标计数**

*Niki Amini-Naieni,Andrew Zisserman*

主要分类: cs.CV

摘要简述: 本文提出了一种新任务：开放世界视频目标计数，通过文本描述或图像示例指定目标对象，统计视频中所有独特实例。为解决遮挡和相似对象带来的挑战，作者开发了CountVid模型，结合图像计数和视频分割跟踪技术，并在新数据集VideoCount上验证其优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 在拥挤场景中，由于遮挡和相似对象的存在，准确统计视频中目标对象的独特实例具有挑战性。现有方法难以避免重复计数和识别重现对象，因此需要一种开放世界的自动化计数方法。

研究方法: 作者提出CountVid模型，结合基于图像的计数模型和可提示的视频分割与跟踪模型，实现跨视频帧的自动化目标计数。为评估性能，构建了VideoCount数据集，包含TAO、MOT20跟踪数据及企鹅和金属合金X射线视频。

研究结果: 实验表明，CountVid在VideoCount数据集上能够提供准确的目标计数，显著优于基线方法。

研究结论: CountVid为开放世界视频目标计数提供了有效解决方案，其模型、数据集和代码均已开源。

中文摘要: 本文提出了一种新任务：开放世界视频目标计数，其目标是通过文本描述或图像示例指定目标对象，统计视频中所有独特实例。这一任务在拥挤场景中尤为困难，因为遮挡和相似对象的存在使得避免重复计数和识别重现对象至关重要。为此，我们提出以下贡献：我们开发了CountVid模型，结合基于图像的计数模型和可提示的视频分割与跟踪模型，实现跨视频帧的自动化目标计数。为评估性能，我们构建了VideoCount数据集，包含TAO和MOT20跟踪数据，以及企鹅和金属合金X射线视频。实验表明，CountVid能够提供准确的目标计数，显著优于基线方法。VideoCount数据集、CountVid模型及相关代码已开源。

</details>


### [94] [Unsupervised Pelage Pattern Unwrapping for Animal Re-identification](https://arxiv.org/abs/2506.15369)
**中文标题：无监督动物皮毛图案解包用于个体重识别**

*Aleksandr Algasov,Ekaterina Nepovinnykh,Fedor Zolotarev,Tuomas Eerola,Heikki Kälviäinen,Pavel Zemčík,Charles V. Stewart*

主要分类: cs.CV

摘要简述: 本文提出一种几何感知的纹理映射方法，将动物皮毛图案解包到规范UV空间，提升变形图案下的个体重识别准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有动物个体重识别方法常因皮毛或皮肤图案的几何变形（如身体运动和姿势变化）而效果不佳，本文旨在解决这一问题。

研究方法: 通过表面法线估计引导解包过程，保持3D表面与2D纹理空间的几何一致性，并结合自监督训练，无需真实UV标注。

研究结果: 在环斑海豹和豹子数据集上，重识别准确率最高提升5.4%。

研究结论: 该方法显著提升了变形图案下的动物重识别性能，且无需标注数据。

中文摘要: 现有的个体重识别方法常因动物皮毛或皮肤图案的几何变形（如身体运动和姿势变化）而效果不佳。本文提出一种几何感知的纹理映射方法，将独特的皮毛图案解包到规范的UV空间，从而实现更鲁棒的特征匹配。我们的方法利用表面法线估计引导解包过程，同时保持3D表面与2D纹理空间的几何一致性。我们聚焦于两种具有挑战性的物种：赛马环斑海豹（Pusa hispida saimensis）和豹子（Panthera pardus），它们的皮毛图案独特且易变形。通过将我们的图案保留UV映射与现有重识别技术结合，实验表明在不同姿势和视角下重识别准确率显著提升。我们的框架无需真实UV标注，可自监督训练。在环斑海豹和豹子数据集上的实验显示，重识别准确率最高提升5.4%。

</details>


### [95] [When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class](https://arxiv.org/abs/2506.15381)
**中文标题：当模型知识遇上扩散模型：扩散辅助的无数据图像合成与领域和类对齐**

*Yujin Kim,Hyunsoo Kim,Hyunwoo J. Kim,Suhyun Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DDIS的扩散辅助无数据图像合成方法，利用文本到图像扩散模型作为先验知识，生成更接近预训练模型学习数据分布的图像。通过领域对齐引导和类对齐标记优化，DDIS在PACS和ImageNet上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 开源预训练模型在训练数据不可用时实用性下降。现有无数据图像合成方法因缺乏自然图像先验知识，生成的样本偏离训练数据分布。本文旨在通过扩散模型提升合成图像质量。

研究方法: DDIS利用文本到图像扩散模型作为图像先验，提取预训练模型的知识指导扩散过程。提出领域对齐引导（DAG）和优化类对齐标记（CAT）嵌入，确保合成数据与训练数据分布一致。

研究结果: 在PACS和ImageNet上的实验表明，DDIS生成的图像更接近训练数据分布，优于现有无数据图像合成方法，达到SOTA性能。

研究结论: DDIS通过结合扩散模型和预训练模型知识，显著提升了无数据图像合成的质量，为数据不可用场景提供了有效解决方案。

中文摘要: 开源预训练模型具有广泛的应用潜力，但当其训练数据不可用时，其实用性会下降。无数据图像合成（DFIS）旨在无需访问原始数据的情况下生成近似预训练模型学习数据分布的图像。然而，现有DFIS方法因缺乏自然图像先验知识，生成的样本偏离训练数据分布。为克服这一局限，我们提出了DDIS，首个利用文本到图像扩散模型作为强大图像先验的扩散辅助无数据图像合成方法，提升了合成图像质量。DDIS从给定模型中提取学习分布的知识，并用于指导扩散模型，生成与训练数据分布精确对齐的图像。为此，我们引入了领域对齐引导（DAG），在扩散采样过程中将合成数据领域与训练数据领域对齐。此外，我们优化了单一类对齐标记（CAT）嵌入，以有效捕捉训练数据集中的类特定属性。在PACS和ImageNet上的实验表明，DDIS优于现有DFIS方法，生成的样本更好地反映了训练数据分布，在无数据应用中实现了SOTA性能。

</details>


### [96] [NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance](https://arxiv.org/abs/2506.15404)
**中文标题：NERO：基于神经元级相关性的可解释分布外检测**

*Anju Chhetri,Jari Korhonen,Prashnna Gyawali,Binod Bhattarai*

主要分类: cs.CV

摘要简述: NERO是一种新型的分布外（OOD）检测方法，通过神经元级相关性增强OOD样本的可分离性，并在医学影像领域验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 在医学影像领域，确保深度学习模型的可靠性至关重要，尤其是能够检测分布外样本（OOD）以避免潜在异常。现有方法在捕捉OOD多样性方面存在不足，因此需要一种更有效的OOD检测机制。

研究方法: NERO利用特征层的神经元级相关性，通过聚类形成类别的代表性中心，并引入相关性距离度量样本与这些中心的偏差。此外，通过结合缩放相关性和特征范数优化性能，同时提供可解释的OOD检测。

研究结果: NERO在胃肠道影像基准数据集Kvasir和GastroVision上验证，表现优于现有OOD检测方法。

研究结论: NERO通过神经元级相关性显著提升了OOD检测的性能和可解释性，为医学影像领域的可靠性提供了有效工具。

中文摘要: 在深度学习中，确保可靠性至关重要，尤其是在医学影像领域，诊断决策往往依赖于模型输出。分布外（OOD）样本的分离能力已被证明是模型可靠性的重要指标。在医学影像中，检测OOD输入尤为关键，因为它可以帮助标记可能被忽视的潜在异常。尽管许多OOD检测方法依赖于特征或逻辑空间表示，但近期研究表明这些方法可能无法完全捕捉OOD的多样性。为此，我们提出了一种新型OOD评分机制NERO，利用特征层的神经元级相关性。具体而言，我们为每个分布内（ID）类别的神经元级相关性进行聚类，形成代表性中心，并引入相关性距离度量新样本与这些中心的偏差，从而增强OOD的可分离性。此外，我们通过结合缩放相关性和特征范数进一步优化性能。我们的框架还支持可解释的OOD检测。我们在胃肠道影像基准数据集Kvasir和GastroVision上验证了其有效性，结果表明NERO在多种深度学习架构中优于现有的OOD检测方法。

</details>


### [97] [Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material](https://arxiv.org/abs/2506.15442)
**中文标题：Hunyuan3D 2.1：从图像到高保真3D资产，具备生产级PBR材质**

*Team Hunyuan3D,Shuhui Yang,Mingxin Yang,Yifei Feng,Xin Huang,Sheng Zhang,Zebin He,Di Luo,Haolin Liu,Yunfei Zhao,Qingxiang Lin,Zeqiang Lai,Xianghui Yang,Huiwen Shi,Zibo Zhao,Bowen Zhang,Hongyu Yan,Lifu Wang,Sicong Liu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Yulin Cai,Jiaao Yu,Yixuan Tang,Dongyuan Guo,Junlin Yu,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Shida Wei,Chao Zhang,Yonghao Tan,Yifu Sun,Lin Niu,Shirui Huang,Bojian Zheng,Shu Liu,Shilin Chen,Xiang Yuan,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Jingwei Huang,Chunchao Guo*

主要分类: cs.CV

摘要简述: 本文介绍了Hunyuan3D 2.1系统，通过逐步指南展示了如何从图像生成高保真3D资产，包括形状生成和纹理合成，适用于游戏、虚拟现实和工业设计。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D AI生成内容（AIGC）领域虽发展迅速，但由于数据收集、处理和模型训练的复杂性，仍主要局限于研究人员和开发者。本文旨在通过Hunyuan3D 2.1系统降低门槛，提供实用的3D生成解决方案。

研究方法: 系统包含Hunyuan3D-DiT（形状生成）和Hunyuan3D-Paint（纹理合成）两大核心组件，涵盖数据准备、模型架构、训练策略、评估指标和部署的全流程。

研究结果: Hunyuan3D 2.1能够生成高分辨率、带纹理的3D资产，适用于多种应用场景，如游戏、虚拟现实和工业设计。

研究结论: 通过本教程，读者可以掌握调优或开发3D生成模型的能力，推动3D AIGC在更多领域的应用。

中文摘要: 3D AI生成内容（AIGC）是一个充满激情的领域，显著加速了游戏、电影和设计中的3D模型创作。尽管已有多个突破性模型彻底改变了3D生成，但由于数据收集、处理和训练的复杂性，该领域仍主要面向研究人员、开发者和设计师。为解决这些问题，本文以Hunyuan3D 2.1为例，提供了一份全面的分步指南，涵盖3D数据处理、3D生成模型训练及其性能评估。该系统包括两大核心组件：Hunyuan3D-DiT（形状生成）和Hunyuan3D-Paint（纹理合成）。我们将探讨整个工作流程，包括数据准备、模型架构、训练策略、评估指标和部署。通过本教程，读者将掌握调优或开发适用于游戏、虚拟现实和工业设计的强大3D生成模型的知识。

</details>


### [98] [Multimodal Large Language Models for Medical Report Generation via Customized Prompt Tuning](https://arxiv.org/abs/2506.15477)
**中文标题：基于定制化提示调优的多模态大语言模型用于医学报告生成**

*Chunlei Li,Jingyang Hou,Yilei Shi,Jingliang Hu,Xiao Xiang Zhu,Lichao Mou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MRG-LLM的多模态大语言模型，通过定制化提示调优技术，结合冻结的大语言模型与可学习的视觉编码器，动态生成针对单个医学图像的实例特定提示，从而实现了精准的医学报告生成。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像报告的自动生成在临床实践中仍具挑战性。尽管大语言模型（LLMs）在此领域展现出潜力，但其与医学影像数据的有效结合仍需深入研究。本文旨在探索如何通过定制化提示调优技术，提升大语言模型在医学报告生成中的性能。

研究方法: MRG-LLM模型结合了冻结的大语言模型与可学习的视觉编码器，并引入了动态提示定制机制。通过从视觉特征中提取的条件仿射变换，生成针对单个医学图像的实例特定提示。提出了两种实现方式：提示级定制和提示簿级定制，以实现精准的报告生成。

研究结果: 在IU X-ray和MIMIC-CXR数据集上的大量实验表明，MRG-LLM在医学报告生成任务中达到了最先进的性能。

研究结论: MRG-LLM通过动态提示定制机制，成功地将大语言模型与医学影像数据结合，显著提升了医学报告生成的准确性和针对性。

中文摘要: 医学影像数据的报告生成在临床实践中仍是一项具有挑战性的任务。尽管大语言模型（LLMs）在解决这一挑战方面展现出巨大潜力，但其与医学影像数据的有效结合仍需深入探索。本文提出了MRG-LLM，一种新颖的多模态大语言模型（MLLM），它将冻结的大语言模型与可学习的视觉编码器相结合，并引入了动态提示定制机制。我们的核心创新在于通过从视觉特征中提取的条件仿射变换，生成针对单个医学图像的实例特定提示。我们提出了两种实现方式：提示级定制和提示簿级定制，以实现精准且有目标的报告生成。在IU X-ray和MIMIC-CXR数据集上的大量实验表明，MRG-LLM在医学报告生成任务中达到了最先进的性能。我们的代码将公开提供。

</details>


### [99] [GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects](https://arxiv.org/abs/2506.15483)
**中文标题：GenHOI：面向未见物体的文本驱动4D人-物交互合成的泛化方法**

*Shujia Li,Haiyu Zhang,Xinyuan Chen,Yaohui Wang,Yutong Ban*

主要分类: cs.CV

摘要简述: GenHOI是一种新颖的两阶段框架，旨在实现对新物体的泛化和高保真4D人-物交互序列的合成。通过Object-AnchorNet和ContactDM，成功解决了4D HOI数据集稀缺的问题，并在实验中取得了最优结果。


<details>
  <summary>详细信息</summary>
研究动机: 尽管扩散模型和大规模运动数据集推动了文本驱动的人体运动合成，但由于大规模4D人-物交互（HOI）数据集的稀缺，将其扩展到4D HOI合成仍具挑战性。本研究旨在解决这一问题，并实现对新物体的泛化和高质量4D HOI序列的生成。

研究方法: GenHOI采用两阶段框架：1) 使用Object-AnchorNet从3D HOI数据集中学习，为未见物体重建稀疏3D HOI关键帧；2) 引入ContactDM，通过Contact-Aware Encoder和HOI Attention提取并整合人-物接触信号，将稀疏关键帧插值为密集的4D HOI序列。

研究结果: 在OMOMO和3D-FUTURE数据集上的实验表明，GenHOI实现了最先进的性能，展现出对新物体的强大泛化能力，并能够生成高质量的4D HOI序列。

研究结论: GenHOI通过两阶段设计和接触感知机制，成功解决了4D HOI数据稀缺问题，为新物体的泛化和高保真4D HOI合成提供了有效解决方案。

中文摘要: 尽管扩散模型和大规模运动数据集推动了文本驱动的人体运动合成，但将其扩展到4D人-物交互（HOI）仍具挑战性，主要由于大规模4D HOI数据集的稀缺。本研究提出GenHOI，一种新颖的两阶段框架，旨在实现两个关键目标：1) 对新物体的泛化；2) 高保真4D HOI序列的合成。在第一阶段，我们使用Object-AnchorNet从3D HOI数据集中学习，为未见物体重建稀疏3D HOI关键帧，从而减少对大规模4D HOI数据集的依赖。第二阶段，我们引入Contact-Aware Diffusion Model（ContactDM），将稀疏3D HOI关键帧无缝插值为密集的4D HOI序列。为提高生成质量，我们在ContactDM中提出了一种新颖的Contact-Aware Encoder来提取人-物接触模式，以及一种Contact-Aware HOI Attention机制，将接触信号有效整合到扩散模型中。实验结果表明，我们在公开的OMOMO和3D-FUTURE数据集上取得了最优结果，展现出对新物体的强大泛化能力，同时实现了高保真的4D HOI生成。

</details>


### [100] [NTIRE 2025 Image Shadow Removal Challenge Report](https://arxiv.org/abs/2506.15524)
**中文标题：NTIRE 2025图像阴影去除挑战赛报告**

*Florin-Alexandru Vasluianu,Tim Seizinger,Zhuyun Zhou,Cailian Chen,Zongwei Wu,Radu Timofte,Mingjia Li,Jin Hu,Hainuo Wang,Hengxing Liu,Jiarui Wang,Qiming Hu,Xiaojie Guo,Xin Lu,Jiarong Yang,Yuanfei Bao,Anya Hu,Zihao Fan,Kunyu Wang,Jie Xiao,Xi Wang,Xueyang Fu,Zheng-Jun Zha,Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu,Xingbo Wang,Dong Li,Yuxu Chen,Bin Chen,Yuanbo Zhou,Yuanbin Chen,Hongwei Wang,Jiannan Lin,Qinquan Gao,Tong Tong,Zhao Zhang,Yanyan Wei,Wei Dong,Han Zhou,Seyed Amirreza Mousavi,Jun Chen,Haobo Liang,Jiajie Jing,Junyu Li,Yan Yang,Seoyeon Lee,Chaewon Kim,Ziyu Feng,Shidi Chen,Bowen Luan,Zewen Chen,Vijayalaxmi Ashok Aralikatti,G Gyaneshwar Rao,Nikhil Akalwadi,Chaitra Desai,Ramesh Ashok Tabib,Uma Mudenagudi,Anas M. Ali,Bilel Benjdira,Wadii Boulila,Alexandru Brateanu,Cosmin Ancuti,Tanmay Chaturvedi,Manish Kumar,Anmol Srivastav,Daksh Trivedi,Shashwat Thakur,Kishor Upla,Zeyu Xiao,Zhuoyuan Li,Boda Zhou,Shashank Shekhar,Kele Xu,Qisheng Xu,Zijian Gao,Tianjiao Wan,Suiyi Zhao,Bo Wang,Yan Luo,Mingshen Wang,Yilin Zhang*

主要分类: cs.CV

摘要简述: 本文总结了NTIRE 2025图像阴影去除挑战赛的结果，共有306名参与者注册，17支团队在最终评估阶段提交了解决方案。挑战赛分为两个评估赛道：重建保真度和视觉感知。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于通过挑战赛推动图像阴影去除技术的发展，并评估不同方法在复杂场景下的表现。

研究方法: 方法包括两个评估赛道：一是基于重建保真度的技术评估，二是通过用户研究评估视觉感知效果。所有评估均使用WSRD+数据集，模拟了多种物体、纹理和材料的自阴影与投射阴影交互。

研究结果: 结果显示，共有17支团队提交了有效解决方案，挑战赛成功展示了不同方法在阴影去除任务中的性能。

研究结论: 结论指出，NTIRE 2025挑战赛为图像阴影去除领域提供了新的基准，并促进了技术进步。

中文摘要: 本文研究了NTIRE 2025阴影去除挑战赛的结果。共有306名参与者注册，其中17支团队在最终评估阶段成功提交了解决方案。延续前两届的设定，本次挑战赛分为两个评估赛道：一个关注重建保真度，另一个通过用户研究评估视觉感知。两个赛道均使用WSRD+数据集进行评估，模拟了自阴影与投射阴影在多种物体、纹理和材料中的交互。

</details>


### [101] [CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation](https://arxiv.org/abs/2506.15549)
**中文标题：CLAIM：临床引导的LGE增强技术用于真实且多样化的心肌瘢痕合成与分割**

*Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen,Chen*

主要分类: cs.CV

摘要简述: 本文提出CLAIM框架，通过临床知识引导的LGE增强技术，生成解剖学一致且多样化的心肌瘢痕图像，并优化分割网络，显著提升瘢痕分割的准确性和合成图像的真实性。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在LGE心脏MRI心肌瘢痕分割中潜力巨大，但高质量瘢痕标签的LGE图像稀缺且变异性大，限制了模型的鲁棒性发展。

研究方法: CLAIM框架包含SMILE模块，利用临床采用的AHA 17段模型指导基于扩散的生成器，合成解剖学一致且空间多样化的瘢痕图像；同时采用联合训练策略，优化生成器和分割网络。

研究结果: 实验表明，CLAIM生成的瘢痕模式解剖学一致，与真实瘢痕分布的Dice相似度高于基线模型。

研究结论: CLAIM实现了可控且真实的心肌瘢痕合成，对下游医学影像任务具有实用价值。

中文摘要: 基于深度学习的晚期钆增强（LGE）心脏MRI心肌瘢痕分割在准确和及时诊断结构性心脏病及治疗规划中显示出巨大潜力。然而，高质量瘢痕标签的LGE图像稀缺且变异性大，限制了鲁棒分割模型的发展。为此，我们提出CLAIM框架：一种基于解剖学基础的瘢痕生成与分割方法。其核心是SMILE模块（基于临床知识的瘢痕掩模生成），通过临床采用的AHA 17段模型指导基于扩散的生成器，合成解剖学一致且空间多样化的瘢痕图像。此外，CLAIM采用联合训练策略，优化生成器和分割网络，旨在提升合成瘢痕的真实性和分割准确性。实验结果表明，CLAIM生成的瘢痕模式解剖学一致，与真实瘢痕分布的Dice相似度高于基线模型。我们的方法实现了可控且真实的心肌瘢痕合成，并展示了其在下游医学影像任务中的实用性。

</details>


### [102] [RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation](https://arxiv.org/abs/2506.15560)
**中文标题：RaCalNet：基于稀疏监督度量深度估计的雷达校准网络**

*Xingrui Qin,Wentao Zhao,Chuan Cao,Yihe Niu,Houcheng Jiang,Jingchuan Wang*

主要分类: cs.CV

摘要简述: RaCalNet是一种新型雷达校准网络，通过稀疏LiDAR监督学习精炼雷达测量，仅需1%的监督密度，即可实现高精度深度估计，超越现有密集监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统毫米波雷达深度估计依赖密集LiDAR监督，成本高且数据需求大。RaCalNet旨在通过稀疏监督实现高效深度估计，解决这一问题。

研究方法: RaCalNet首先校准和精炼稀疏雷达点，构建精确深度先验，作为单目深度预测的可靠锚点，无需密集监督即可实现度量尺度估计。

研究结果: 在ZJU-4DRadarCam数据集和实际场景中，RaCalNet表现优异，RMSE分别降低35.30%和34.89%，生成具有清晰轮廓和细节的深度图。

研究结论: RaCalNet通过稀疏监督实现高效深度估计，显著优于密集监督方法，为雷达深度估计提供了低成本、高性能的解决方案。

中文摘要: 使用毫米波雷达进行密集度量深度估计通常需要依赖密集LiDAR监督，通过多帧投影和插值生成，以指导从稀疏雷达测量和RGB图像中学习准确深度。然而，这种范式成本高且数据密集。为此，我们提出RaCalNet，一种新颖框架，通过使用稀疏LiDAR监督学习精炼雷达测量，消除了对密集监督的需求，监督密度仅为密集监督方法的约1%。与以往将雷达点与宽泛图像区域关联并严重依赖密集标签的方法不同，RaCalNet首先重新校准和精炼稀疏雷达点，构建精确深度先验。这些先验随后作为可靠锚点，引导单目深度预测，实现无需密集监督的度量尺度估计。这一设计提高了结构一致性并保留了精细细节。尽管仅依赖稀疏监督，RaCalNet仍超越了最先进的密集监督方法，生成具有清晰物体轮廓和细粒度纹理的深度图。在ZJU-4DRadarCam数据集和实际部署场景中的大量实验证明了其有效性，分别将RMSE降低了35.30%和34.89%。

</details>


### [103] [Control and Realism: Best of Both Worlds in Layout-to-Image without Training](https://arxiv.org/abs/2506.15563)
**中文标题：控制与真实感：无需训练的布局到图像生成中的双赢方案**

*Bonan Li,Yinhan Hu,Songhua Liu,Xinchao Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的布局到图像生成方法WinWinLay，通过非局部注意力能量函数和自适应更新策略，解决了现有方法在定位不准和图像不真实方面的缺陷，显著提升了控制精度和视觉真实感。


<details>
  <summary>详细信息</summary>
研究动机: 现有的布局到图像生成方法虽然能够利用预训练的文本到图像扩散模型实现无需训练的目标，但在定位精度和图像真实性方面存在不足。本文旨在解决这些问题，提出一种无需训练的新方法。

研究方法: WinWinLay的核心包括两项策略：1）非局部注意力能量函数，通过重新分配注意力分数，解决空间分布偏差问题，使物体更符合布局指令；2）基于Langevin动力学的自适应更新方案，避免预训练领域的偏离，减少分布外伪影。

研究结果: 实验表明，WinWinLay在元素布局控制和图像真实感方面表现优异，超越了当前最先进的方法。

研究结论: WinWinLay通过创新的非局部注意力能量函数和自适应更新策略，成功实现了无需训练的布局到图像生成任务，显著提升了控制精度和视觉质量。

中文摘要: 布局到图像生成的目标是通过对主题位置和排列的精确控制创建复杂场景。现有研究表明，预训练的文本到图像扩散模型可以在无需特定数据训练的情况下实现这一目标，但常面临定位不准和不真实伪影的挑战。针对这些问题，我们提出了一种无需训练的新方法WinWinLay。其核心包括两项关键策略：非局部注意力能量函数和自适应更新，共同提升控制精度和真实感。一方面，我们从理论上证明常用的注意力能量函数会引入固有空间分布偏差，阻碍物体与布局指令的均匀对齐。为解决这一问题，我们探索了非局部注意力先验，重新分配注意力分数，使物体更符合指定的空间条件。另一方面，我们发现普通的反向传播更新规则可能导致预训练领域的偏离，从而产生分布外伪影。为此，我们引入了基于Langevin动力学的自适应更新方案，在尊重布局约束的同时促进领域内更新。大量实验表明，WinWinLay在元素布局控制和照片级视觉真实感方面表现出色，超越了当前最先进的方法。

</details>


### [104] [Show-o2: Improved Native Unified Multimodal Models](https://arxiv.org/abs/2506.15564)
**中文标题：Show-o2：改进的原生统一多模态模型**

*Jinheng Xie,Zhenheng Yang,Mike Zheng Shou*

主要分类: cs.CV

摘要简述: 本文提出了一种改进的原生统一多模态模型Show-o2，结合自回归建模和流匹配技术，通过双路径空间-时间融合构建统一视觉表示，支持图像和视频模态的扩展，并在多模态理解和生成任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态模型在处理图像和视频等多样化模态时存在局限性，需要一种能够统一理解和生成多模态内容的高效模型。Show-o2旨在通过自回归建模和流匹配技术，构建一个原生支持多模态任务的统一框架。

研究方法: Show-o2基于3D因果变分自编码器空间，通过空间-时间融合的双路径构建统一视觉表示。语言头和流头分别应用自回归建模和流匹配技术，支持文本标记预测和图像/视频生成。采用两阶段训练策略，确保模型的高效学习和扩展性。

研究结果: Show-o2模型在文本、图像和视频等多种模态的理解和生成任务中表现出色，展示了其多功能性和扩展性。代码和模型已开源。

研究结论: Show-o2通过原生统一的多模态建模和高效训练策略，成功实现了对多样化模态的理解和生成，为多模态研究提供了新的解决方案。

中文摘要: 本文提出了一种改进的原生统一多模态模型Show-o2，利用自回归建模和流匹配技术。基于3D因果变分自编码器空间，通过空间-时间融合的双路径构建统一视觉表示，支持图像和视频模态的扩展，同时确保有效的多模态理解和生成。基于语言模型，自回归建模和流匹配分别应用于语言头和流头，以促进文本标记预测和图像/视频生成。设计了两阶段训练策略，以有效学习并扩展至更大模型。最终的Show-o2模型在文本、图像和视频等多种模态的理解和生成任务中表现出多功能性。代码和模型发布于https://github.com/showlab/Show-o。

</details>


### [105] [Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification](https://arxiv.org/abs/2506.15565)
**中文标题：巴尔的摩地图集：用于半监督超高空间分辨率土地覆盖分类的FreqWeaver适配器**

*Junhao Wu,Aboagye-Ntow Stephen,Chuyuan Wang,Gang Chen,Xin Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种参数高效的半监督分割框架，用于0.3米超高空间分辨率影像，通过结合SAM2知识和遥感专用FreqWeaver适配器，显著提升了细粒度细节建模能力，同时仅占用总参数的5.96%。


<details>
  <summary>详细信息</summary>
研究动机: 超高空间分辨率土地覆盖分类对细粒度分析至关重要，但像素级标注成本高、尺度变化大以及大规模视觉模型适应性有限等问题使其具有挑战性。现有方法多依赖标注数据且适用于1米分辨率影像，而实际应用常需在弱监督下处理更高分辨率影像。

研究方法: 提出了一种参数高效的半监督分割框架，结合SAM2知识并引入遥感专用FreqWeaver适配器，以增强细粒度细节建模，同时保持轻量化设计（仅占模型总参数的5.96%）。

研究结果: 该方法通过有效利用未标注数据并保持低参数开销，实现了结构一致性优越的稳健分割结果，比现有参数高效调优策略提升1.78%，比最先进的高分辨率遥感分割方法提升3.44%。

研究结论: 所提方法在超高空间分辨率影像分类中表现出色，显著提升了细粒度建模能力，同时保持了轻量化设计，为实际应用提供了高效解决方案。

中文摘要: 超高空间分辨率土地覆盖分类对细粒度土地覆盖分析至关重要，但由于像素级标注成本高、尺度变化显著以及大规模视觉模型适应性有限，其仍具挑战性。现有方法通常专注于1米空间分辨率影像，并严重依赖标注数据，而实际应用常需在弱监督下处理更高分辨率影像。为此，我们提出了一种参数高效的半监督分割框架，用于0.3米空间分辨率影像，该框架结合了SAM2的知识并引入了遥感专用FreqWeaver适配器，以增强细粒度细节建模，同时保持轻量化设计（仅占模型总参数的5.96%）。通过有效利用未标注数据并保持低参数开销，所提方法实现了结构一致性优越的稳健分割结果，比现有参数高效调优策略提升1.78%，比最先进的高分辨率遥感分割方法提升3.44%。

</details>


### [106] [A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds](https://arxiv.org/abs/2506.15577)
**中文标题：基于图的统一框架：从点云实现可扩展的3D树木重建与无损生物量估计**

*Di Wang,Shi Li*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图的统一框架，用于从点云数据中实现可扩展的3D树木重建和无损生物量估计，显著提升了大规模森林生物量评估的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 森林地上生物量（AGB）的估计对碳储存评估和可持续森林管理至关重要。现有的定量结构模型（QSM）方法依赖高质量点云数据且需要复杂预处理，限制了其可扩展性和实际应用。本研究旨在解决这些问题，提出一种更高效、更通用的解决方案。

研究方法: 研究提出了一种创新的基于图的统一框架，通过端到端的处理流程，整合了树木分割、叶木分离和3D骨架重建。该方法利用图操作（如路径规划和拓扑推理）实现高效处理，适用于不同数据源（如TLS和ULS）和场景（如叶茂和叶落）。

研究结果: 实验结果表明，该方法在叶茂场景（相对误差约20%）和低密度ULS数据（相对误差约30%）下表现优异，显著降低了对专业预处理工具的依赖，并验证了ULS作为TLS可行替代方案的潜力。

研究结论: 该框架为大规模无损AGB估计提供了稳健且可扩展的解决方案，推动了基于QSM的森林生物量估计在森林调查和气候变化研究中的广泛应用。

中文摘要: 森林地上生物量（AGB）的估计对评估碳储存和支持可持续森林管理至关重要。定量结构模型（QSM）通过3D树木结构重建提供了一种无损的AGB估计方法。然而，现有的QSM方法主要针对单株树木设计，依赖地面激光扫描（TLS）的高质量点云数据，且需要复杂的预处理步骤，限制了其可扩展性和实际应用。本研究提出了一种新颖的统一框架，通过创新的基于图的处理流程，实现了大规模点云的端到端处理。该方法通过专门的图操作（如路径规划和拓扑推理）无缝整合了树木分割、叶木分离和3D骨架重建。研究在叶茂和叶落场景、树级和地块级空间尺度以及TLS和无人机激光扫描（ULS）数据源上进行了全面验证。实验结果表明，该方法在叶茂场景（相对误差约20%）和低密度ULS数据（相对误差约30%）下表现优异。这些发现表明，该框架为大规模无损AGB估计提供了稳健且可扩展的解决方案，显著降低了对专业预处理工具的依赖，并确立了ULS作为TLS可行替代方案的地位。据我们所知，这是首个能够在操作尺度上实现无缝端到端3D树木重建的方法。这一进展显著提升了基于QSM的AGB估计的可行性，为森林调查和气候变化研究中的更广泛应用铺平了道路。

</details>


### [107] [One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution](https://arxiv.org/abs/2506.15591)
**中文标题：一步扩散实现细节丰富且时间一致的视频超分辨率**

*Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于稳定扩散（SD）的双LoRA学习范式（DLoRAL），通过交叉帧检索（CFR）和一致性LoRA（C-LoRA）模块提取时间一致性先验，再通过细节LoRA（D-LoRA）增强空间细节，实现一步扩散模型的高质量视频超分辨率重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于SD的真实视频超分辨率（Real-VSR）方法往往在保持时间一致性和生成丰富空间细节之间难以平衡，导致视觉质量不佳。本文旨在解决这一问题，通过有效提取低质量视频中的时间一致性先验，并在增强细节的同时保持这些先验。

研究方法: 提出双LoRA学习范式（DLoRAL），包括交叉帧检索（CFR）模块和一致性LoRA（C-LoRA）模块，用于提取时间一致性先验；随后固定这些模块，训练细节LoRA（D-LoRA）以增强空间细节并保持时间一致性。两阶段交替优化，最终合并LoRA分支实现一步扩散推理。

研究结果: 实验表明，DLoRAL在准确性和速度上均表现优异，能够同时实现丰富的空间细节和时间一致性。

研究结论: DLoRAL通过双LoRA学习和交替优化策略，成功解决了真实视频超分辨率中细节与时间一致性的平衡问题，为高效高质量的视频恢复提供了新思路。

中文摘要: 在真实视频超分辨率（Real-VSR）中，利用预训练生成模型（如稳定扩散SD）合成逼真细节时，如何在保持时间一致性的同时重现丰富的空间细节是一个具有挑战性的问题。现有的基于SD的Real-VSR方法往往为了时间一致性而牺牲空间细节，导致视觉质量不理想。我们认为关键在于如何从低质量（LQ）输入视频中有效提取抗退化时间一致性先验，并在增强视频细节的同时保持这些先验。为此，我们提出了一种双LoRA学习（DLoRAL）范式，训练一个基于SD的一步扩散模型，同时实现逼真的帧细节和时间一致性。具体而言，我们引入交叉帧检索（CFR）模块以聚合跨帧的互补信息，并训练一致性LoRA（C-LoRA）从退化输入中学习鲁棒的时间表示。在一致性学习后，我们固定CFR和C-LoRA模块，训练细节LoRA（D-LoRA）以增强空间细节，同时与C-LoRA定义的时间空间对齐以保持时间一致性。两阶段交替迭代优化，协同输出一致且细节丰富的结果。在推理时，两个LoRA分支被合并到SD模型中，实现高效且高质量的单步扩散视频恢复。实验表明，DLoRAL在准确性和速度上均表现出色。代码和模型可在https://github.com/yjsunnn/DLoRAL获取。

</details>


### [108] [Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration](https://arxiv.org/abs/2506.15596)
**中文标题：单模态化极端异质多模态医学图像配准**

*Kyobin Choo,Hyunkyung Han,Jinyeong Kim,Chanyong Yoon,Seong Jae Hwang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为M2M-Reg的新框架，用于解决多模态医学图像配准中因模态差异大导致的配准困难问题。通过单模态相似性训练多模态配准模型，并结合GradCyCon正则化器提升配准效果，实验表明其在PET-MRI和FA-MRI配准中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在临床实践中，功能型成像模态（如PET、FA）常需与结构型模态（如MRI、CT）对齐以进行准确分析。然而，由于这些模态差异极大，传统无监督配准方法难以学习可靠的空间映射，容易导致图像失真。现有相似性度量无法有效捕捉高度异质模态间的对齐关系，亟需新的解决方案。

研究方法: 提出M2M-Reg框架，通过单模态相似性训练多模态配准模型，保留现有架构以无缝集成到现有模型中。引入GradCyCon正则化器，利用循环训练方案促进微分同胚性。此外，该框架可扩展至半监督设置，仅需预对齐和未对齐的图像对，无需真实变换或分割掩码。

研究结果: 在ADNI数据集上的实验表明，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法高出2倍，显著提升了高度异质多模态配准的效果。

研究结论: M2M-Reg通过单模态相似性训练多模态配准模型，有效解决了高度异质模态配准的难题，实验验证了其优越性能，为临床多模态图像分析提供了新工具。

中文摘要: 在临床实践中，具有功能特性的成像模态（如正电子发射断层扫描（PET）和分数各向异性（FA））通常需要与结构参考（如MRI、CT）对齐以进行准确解释或群体分析，这需要多模态可变形图像配准（DIR）。然而，由于这些模态与标准结构扫描相比具有极端异质性，传统的无监督DIR方法难以学习可靠的空间映射，并经常导致图像失真。我们发现，指导这些模型的相似性度量无法捕捉高度异质模态间的对齐关系。为解决这一问题，我们提出了M2M-Reg（多到单配准），这是一种新颖的框架，仅使用单模态相似性训练多模态DIR模型，同时保留现有架构范式以实现与现有模型的无缝集成。我们还引入了GradCyCon，这是一种利用M2M-Reg循环训练方案促进微分同胚性的正则化器。此外，我们的框架自然扩展到半监督设置，仅集成预对齐和未对齐的图像对，无需真实变换或分割掩码。在阿尔茨海默病神经影像学倡议（ADNI）数据集上的实验表明，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法高出2倍，突显了其在处理高度异质多模态DIR中的有效性。我们的代码可在https://github.com/MICV-yonsei/M2M-Reg获取。

</details>


### [109] [BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion](https://arxiv.org/abs/2506.15610)
**中文标题：BoxFusion：基于实时多视角框融合的无重建开放词汇3D物体检测**

*Yuqing Lan,Chenyang Zhu,Zhirui Gao,Jiazhao Zhang,Yihan Cao,Renjiao Yi,Yijie Wang,Kai Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种无需点云重建的实时多视角框融合方法BoxFusion，用于开放词汇3D物体检测，显著降低了计算和内存开销，并在实验中取得了领先性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的开放词汇3D物体检测方法通常依赖密集点云重建，计算和内存开销大，难以实时部署。本文旨在提出一种无需重建的实时框架，解决这一问题。

研究方法: 利用预训练的Cubify Anything模型进行单视角3D物体检测，结合CLIP捕捉开放词汇语义；通过关联模块和优化模块融合多视角检测框，其中关联模块使用3D NMS和框匹配，优化模块采用基于粒子滤波的IoU引导随机优化技术。

研究结果: 在ScanNetV2和CA-1M数据集上的实验表明，该方法在在线方法中达到最优性能，且能在超过1000平方米的环境中实现实时感知。

研究结论: BoxFusion通过无需重建的范式实现了高效实时的3D物体检测，具有广泛的应用潜力。

中文摘要: 开放词汇3D物体检测因其在自动驾驶和具身AI中的关键应用而备受关注。现有方法通常依赖密集点云重建，计算和内存开销大，限制了实时部署。为此，我们提出了一种无需重建的在线框架，专为内存高效和实时3D检测设计。具体而言，给定流式RGB-D视频输入，我们利用预训练的视觉基础模型Cubify Anything进行单视角3D物体检测（通过边界框），并结合CLIP捕捉检测对象的开放词汇语义。为了融合多视角检测框，我们采用关联模块实现多视角对应关系，并通过优化模块融合同一实例的多视角预测框。关联模块使用3D非极大值抑制（NMS）和框匹配模块，优化模块则采用基于粒子滤波的IoU引导高效随机优化技术，以在最小化计算复杂度的同时保证多视角一致性。在ScanNetV2和CA-1M数据集上的大量实验表明，我们的方法在在线方法中达到了最先进的性能。得益于这种无需重建的3D物体检测新范式，我们的方法在多种场景中表现出强大的泛化能力，即使在超过1000平方米的环境中也能实现实时感知。

</details>


### [110] [HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization](https://arxiv.org/abs/2506.15625)
**中文标题：HOIDiNi：通过扩散噪声优化实现人-物交互**

*Roey Ron,Guy Tevet,Haim Sawdayee,Amit H. Bermano*

主要分类: cs.CV

摘要简述: HOIDiNi是一种基于扩散噪声优化的文本驱动框架，用于生成逼真且合理的人-物交互（HOI）。通过将问题分解为物体中心阶段和人体中心阶段，该方法在保持运动自然性的同时实现了精确的手-物接触，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 人-物交互（HOI）生成在保持接触精度和运动多样性方面极具挑战性。现有方法往往在逼真性和物理正确性之间权衡取舍，而HOIDiNi旨在通过扩散噪声优化（DNO）同时实现这两者。

研究方法: HOIDiNi采用扩散噪声优化（DNO）方法，在预训练扩散模型的噪声空间中进行直接优化。该方法将问题分为两个阶段：物体中心阶段（选择手-物接触位置）和人体中心阶段（优化全身运动以实现接触），从而在保持运动自然性的同时实现精确接触。

研究结果: 在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触精度、物理有效性和整体质量上均优于现有方法和基线。该方法能够仅通过文本提示生成复杂的可控交互，如抓取、放置和全身协调。

研究结论: HOIDiNi通过扩散噪声优化和分阶段处理，成功实现了逼真且物理正确的人-物交互生成，为复杂交互的文本驱动合成提供了新思路。

中文摘要: 我们提出了HOIDiNi，一种基于文本驱动的扩散框架，用于合成逼真且合理的人-物交互（HOI）。HOI生成极具挑战性，因为它需要在严格的接触精度和多样的运动流形之间取得平衡。尽管现有文献在逼真性和物理正确性之间权衡取舍，但HOIDiNi通过扩散噪声优化（DNO）在预训练扩散模型的噪声空间中直接优化，同时实现了这两者。这一方法的可行性源于我们将问题分解为两个阶段：物体中心阶段（主要选择手-物接触位置）和人体中心阶段（优化全身运动以实现这一蓝图）。这种结构化方法在不牺牲运动自然性的前提下实现了精确的手-物接触。在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触精度、物理有效性和整体质量上均优于现有方法和基线。我们的结果表明，该方法能够仅通过文本提示生成复杂的可控交互，包括抓取、放置和全身协调。详情请访问：https://hoidini.github.io。

</details>


### [111] [FindingDory: A Benchmark to Evaluate Memory in Embodied Agents](https://arxiv.org/abs/2506.15635)
**中文标题：FindingDory：评估具身智能体记忆能力的基准**

*Karmesh Yadav,Yusuf Ali,Gunshi Gupta,Yarin Gal,Zsolt Kira*

主要分类: cs.CV

摘要简述: 本文提出了一个新的基准测试FindingDory，用于评估具身智能体在长期记忆任务中的表现，填补了现有长视频问答基准在具身环境中的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大规模视觉语言模型在规划和控制任务中表现出色，但在处理长期记忆任务时存在局限，尤其是在具身环境中需要整合多天收集的大量图像数据。现有基准未能充分评估具身智能体在低级别技能和细粒度推理方面的需求。

研究方法: 研究团队在Habitat模拟器中设计了一个包含60项任务的基准测试，这些任务需要持续的上下文感知和记忆能力。任务可扩展为更复杂的版本，以评估记忆和推理的可扩展性。同时，结合了最先进的视觉语言模型和低级别导航策略，提供了基线性能评估。

研究结果: 基准测试展示了具身智能体在长期记忆任务中的表现，并揭示了现有模型的局限性。通过基线实验，研究团队指出了需要改进的关键领域。

研究结论: FindingDory基准为评估具身智能体的长期记忆能力提供了有效工具，并强调了未来研究中整合记忆与动作执行的重要性。

中文摘要: 近年来，大规模视觉语言模型在规划和控制任务中表现出色，引发了将其应用于现实世界机器人技术的兴趣。然而，这些模型在具身环境中的推理能力受限于其整合长期经验的能力，尤其是需要处理多天收集的大量图像数据时。当前的视觉语言模型通常难以同时处理超过几百张图像，因此需要更高效的机制来处理具身环境中的长期记忆。为了有效评估这些模型在长期控制任务中的表现，基准测试必须针对依赖记忆的场景。现有的长视频问答基准忽视了具身环境中的挑战，如物体操作和导航，这些任务需要低级别技能和对过去交互的细粒度推理。此外，具身智能体中有效的记忆整合不仅需要回忆相关历史信息，还需基于这些信息执行动作，因此必须将这两方面结合起来研究。本研究在Habitat模拟器中引入了一个新的长期具身任务基准，评估了60项需要持续参与和上下文感知的任务中的记忆能力。这些任务还可以通过程序扩展为更长且更具挑战性的版本，从而实现对记忆和推理的可扩展评估。我们还提出了结合最先进视觉语言模型和低级别导航策略的基线方法，评估了它们在记忆密集型任务中的表现，并指出了需要改进的领域。

</details>


### [112] [Demystifying the Visual Quality Paradox in Multimodal Large Language Models](https://arxiv.org/abs/2506.15645)
**中文标题：揭秘多模态大语言模型中的视觉质量悖论**

*Shuo Xing,Lanqing Guo,Hongyuan Hua,Seoyoung Lee,Peiran Li,Yufei Wang,Zhangyang Wang,Zhengzhong Tu*

主要分类: cs.CV

摘要简述: 研究发现多模态大语言模型（MLLMs）在视觉质量上存在一个悖论：图像偏离人类感知的保真度时，模型表现反而可能提升。为此，作者提出了一种轻量级适配模块VQ-TTT，动态调整输入图像以匹配任务需求，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型在视觉语言任务中表现优异，但输入图像视觉质量如何影响其响应尚不明确。作者旨在探究图像质量与模型表现的关系，并解决模型对非人类偏好视觉质量的依赖问题。

研究方法: 作者通过系统实验，对图像施加可控的退化与风格变化，发现视觉质量悖论。为解决这一问题，提出VQ-TTT模块：在冻结的视觉编码器前插入可学习的低秩核以调整频率内容，并通过LoRA微调浅层编码器，动态优化输入图像。

研究结果: 实验表明，VQ-TTT显著提升了多种MLLMs在所有数据集上的平均准确率，无需外部模型、缓存特征或额外训练数据。

研究结论: 研究揭示了MLLMs对视觉质量的独特偏好，提出自适应调整图像质量的重要性，而非追求普遍意义上的“干净”图像。

中文摘要: 近期的多模态大语言模型（MLLMs）在视觉语言任务基准上表现出色，但输入图像的视觉质量如何影响其响应尚不明确。更高的感知质量是否直接转化为更好的MLLM理解？我们首次对领先的MLLMs和一系列视觉语言基准进行了系统研究，对每张图像施加了可控的退化和风格变化。令人惊讶的是，我们发现了一个视觉质量悖论：当图像偏离人类感知的保真度时，模型、任务甚至单个实例的表现可能提升。现成的修复流程无法调和这些独特偏好。为弥合这一差距，我们提出了视觉质量测试时调优（VQ-TTT）——一个轻量级适配模块：（1）在冻结的视觉编码器前插入可学习的低秩核以调节频率内容；（2）通过LoRA仅微调浅层视觉编码器。VQ-TTT在单次前向传播中动态调整每张输入图像，使其与任务特定的模型偏好对齐。在所有评估的MLLMs和数据集中，VQ-TTT显著提升了平均准确率，且无需外部模型、缓存特征或额外训练数据。这些发现重新定义了MLLMs的“更好”视觉输入，并强调了在新一代以AI为主要数据消费者的时代，自适应而非普遍“干净”图像的重要性。

</details>


### [113] [Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning](https://arxiv.org/abs/2506.15649)
**中文标题：基于边缘奖励调整的双阶段价值引导推理：实现快速且可靠的视觉语言模型描述生成**

*Ankan Deria,Adinath Madhavrao Dukre,Feilong Tang,Sara Atito,Sudipta Roy,Muhammad Awais,Muhammad Haris Khan,Imran Razzak*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViMaR的双阶段推理框架，通过结合时间差分价值模型和边缘感知奖励调整，显著提升了视觉语言模型（VLM）生成描述的效率和准确性。实验证明，ViMaR在生成更可靠、详细且解释性强的描述的同时，速度提升了4倍以上，并能跨模型泛化。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型推理方法计算成本高且容易产生低置信度的幻觉描述。为了解决这些问题，本文旨在开发一种高效且可靠的推理框架，以提升生成描述的质量和速度。

研究方法: ViMaR采用双阶段推理框架：第一阶段通过单次推理从多样候选描述中选出最高价值描述；第二阶段选择性优化被忽略或视觉基础薄弱的片段，并通过边缘感知奖励调整惩罚低置信度生成，同时保留描述的丰富性。

研究结果: 实验表明，ViMaR生成的描述在可靠性、事实准确性、细节和解释性方面显著优于现有方法，速度提升4倍以上。此外，ViMaR能够跨模型泛化，并在自训练中显著提升模型的视觉理解能力。

研究结论: ViMaR作为一种高效、可扩展的推理策略，不仅提升了视觉语言模型的生成质量，还展示了跨模型泛化的潜力，为快速、准确且自我改进的VLM流程提供了可能。

中文摘要: 尽管视觉语言模型（VLM）在推理时搜索方面取得了显著进展，但现有方法仍存在计算成本高且容易产生未受惩罚的低置信度生成问题，这些问题常导致持续的幻觉描述。我们提出了\textbf{基于边缘奖励的价值引导推理（ViMaR）}，这是一种双阶段推理框架，通过结合时间差分价值模型和边缘感知奖励调整，显著提升了效率和输出保真度。第一阶段通过单次推理从多样候选描述中选出最高价值描述；第二阶段选择性优化被忽略或视觉基础薄弱的片段，避免频繁奖励评估。通过校准的边缘惩罚机制，抑制低置信度生成的同时保留描述的丰富性。在多种VLM架构上的广泛实验表明，ViMaR生成的描述在可靠性、事实准确性、细节和解释性方面显著优于现有方法，速度提升4倍以上。特别地，我们证明仅基于LLaVA Mistral-7B训练的ViMaR能够有效泛化，指导未见过的更强模型的解码。进一步验证中，我们将ViMaR应用于LLaVA-OneVision-Qwen2-7B的生成引导，持续提升了描述质量，展示了跨模型引导的鲁棒性。这种跨模型泛化能力凸显了ViMaR的灵活性和模块化，使其成为一种可扩展且可迁移的推理时解码策略。此外，当ViMaR生成的描述用于自训练时，基础模型在广泛的视觉理解基准上取得了显著提升，突显了快速、准确且自我改进的VLM流程的潜力。

</details>


### [114] [UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting](https://arxiv.org/abs/2506.15673)
**中文标题：UniRelight：学习联合分解与合成以实现视频重光照**

*Kai He,Ruofan Liang,Jacob Munkberg,Jon Hasselgren,Nandita Vijaykumar,Alexander Keller,Sanja Fidler,Igor Gilitschenski,Zan Gojcic,Zian Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种联合分解与合成的视频重光照方法UniRelight，通过视频扩散模型的生成能力，单次估计反照率并合成重光照结果，显著提升了光照效果和材料交互的真实性。


<details>
  <summary>详细信息</summary>
研究动机: 现有端到端重光照模型因多光照配对数据稀缺而泛化能力受限，而两阶段渲染方法易产生误差累积且难以处理复杂光照或材料。本文旨在通过联合分解与合成，解决这些问题。

研究方法: UniRelight采用视频扩散模型，联合估计反照率并合成重光照结果，利用合成多光照数据和自动标注的真实视频进行训练，增强场景理解和光照效果生成能力。

研究结果: 模型在多样场景中表现出强泛化能力，视觉保真度和时间一致性均优于现有方法，尤其在复杂光照和材料交互（如阴影、反射和透明）方面表现突出。

研究结论: UniRelight通过联合分解与合成，显著提升了视频重光照的真实性和一致性，为复杂光照条件下的重光照任务提供了高效解决方案。

中文摘要: 我们解决了单幅图像或视频的重光照问题，这一任务需要精确的场景内在理解和高品质的光传输合成。现有的端到端重光照模型常因多光照配对数据稀缺而泛化能力受限。相反，结合逆向和正向渲染的两阶段流程虽能缓解数据需求，但易产生误差累积，且在复杂光照条件或高级材料下难以生成真实输出。本文提出了一种通用方法，通过视频扩散模型的生成能力，单次联合估计反照率并合成重光照结果。这种联合形式增强了隐式场景理解，并促进了真实光照效果和复杂材料交互（如阴影、反射和透明）的生成。通过在合成多光照数据和大量自动标注的真实视频上训练，我们的模型在多样领域中表现出强泛化能力，并在视觉保真度和时间一致性上超越了先前方法。

</details>


### [115] [Sekai: A Video Dataset towards World Exploration](https://arxiv.org/abs/2506.15675)
**中文标题：Sekai：面向世界探索的视频数据集**

*Zhen Li,Chuanhao Li,Xiaofeng Mao,Shaoheng Lin,Ming Li,Shitian Zhao,Zhaopan Xu,Xinyue Li,Yukang Feng,Jianwen Sun,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Zhixiang Wang,Yuwei Wu,Tong He,Jiangmiao Pang,Yu Qiao,Yunde Jia,Kaipeng Zhang*

主要分类: cs.CV

摘要简述: 本文介绍了Sekai数据集，一个高质量的第一人称视角全球视频数据集，专为世界探索任务设计，包含5000多小时来自100多个国家和地区的视频，并提供了丰富的标注信息。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频生成数据集存在地理位置有限、时长短、场景静态及缺乏探索和世界相关标注的问题，无法满足世界探索训练的需求。因此，作者提出了Sekai数据集以填补这一空白。

研究方法: 作者开发了一个高效的工具箱，用于收集、预处理和标注视频数据，包括位置、场景、天气、人群密度、字幕和相机轨迹等信息。数据集包含5000多小时的步行和无人机视角视频，覆盖100多个国家和地区的750个城市。

研究结果: 实验验证了数据集的质量，并利用其子集训练了一个名为YUME的交互式视频世界探索模型。

研究结论: Sekai数据集将为视频生成和世界探索领域带来重要价值，并推动相关应用的发展。

中文摘要: 视频生成技术取得了显著进展，有望成为交互式世界探索的基础。然而，现有的视频生成数据集因地理位置有限、时长较短、场景静态以及缺乏探索和世界相关标注等问题，并不适合用于世界探索训练。本文介绍了Sekai（日语中意为“世界”），一个高质量的第一人称视角全球视频数据集，为世界探索提供了丰富的标注信息。该数据集包含来自100多个国家和地区的750个城市的步行或无人机视角（FPV和UVA）视频，总时长超过5000小时。我们开发了一个高效且有效的工具箱，用于收集、预处理和标注视频，包括位置、场景、天气、人群密度、字幕和相机轨迹等信息。实验证明了数据集的质量。此外，我们利用其子集训练了一个名为YUME（日语中意为“梦想”）的交互式视频世界探索模型。我们相信Sekai将为视频生成和世界探索领域带来益处，并激发有价值的应用。

</details>


### [116] [Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model](https://arxiv.org/abs/2506.15682)
**中文标题：进化缓存加速现成扩散模型**

*Anirud Aggarwal,Abhinav Shrivastava,Matthew Gwilliam*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ECAD的进化缓存方法，通过遗传算法学习高效的缓存调度策略，显著加速扩散模型的推理速度，同时保持生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成高质量图像方面表现出色，但推理速度慢且计算成本高。现有缓存方法依赖固定启发式规则，导致加速效果有限或泛化能力差。

研究方法: ECAD利用遗传算法为不同扩散模型学习高效的缓存调度策略，形成帕累托前沿，仅需少量校准提示且无需修改网络参数或参考图像。

研究结果: 在PixArt-alpha等模型上，ECAD显著提升推理速度（从2.35倍到2.58倍），并在COCO FID等指标上优于现有方法。

研究结论: ECAD是一种可扩展且泛化性强的扩散模型加速方法，适用于不同分辨率和模型变体。

中文摘要: 基于扩散的图像生成模型在生成高质量合成内容方面表现出色，但推理速度慢且计算成本高。先前工作尝试通过缓存和重用扩散变换器中的特征来缓解这一问题，但这些方法通常依赖固定启发式规则，导致加速效果有限或泛化能力差。我们提出进化缓存加速扩散模型（ECAD），这是一种遗传算法，仅需少量校准提示即可学习高效的、针对特定模型的缓存调度策略，形成帕累托前沿。ECAD无需修改网络参数或参考图像，显著提升推理速度，支持对质量-延迟权衡的精细控制，并能无缝适应不同扩散模型。值得注意的是，ECAD学习的调度策略可有效泛化到校准阶段未见的分辨率和模型变体。我们在PixArt-alpha、PixArt-Sigma和FLUX-1.dev上评估ECAD，使用多种指标（FID、CLIP、Image Reward）和多样化基准（COCO、MJHQ-30k、PartiPrompts），结果表明ECAD在各项指标上均优于先前方法。在PixArt-alpha上，ECAD找到的调度策略在COCO FID上优于先前最佳方法4.47分，同时将推理加速从2.35倍提升至2.58倍。我们的结果证明ECAD是一种可扩展且泛化性强的扩散模型加速方法。项目网站和代码已公开。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [117] [CALM: Contextual Analog Logic with Multimodality](https://arxiv.org/abs/2506.14936)
**中文标题：CALM：多模态上下文模拟逻辑**

*Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue*

主要分类: cs.AI

摘要简述: 本文提出了一种结合符号逻辑与神经生成的多模态上下文模拟逻辑系统（CALM），旨在解决传统逻辑系统无法捕捉人类决策细微差别的问题，并通过实验验证了其优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统二值逻辑系统无法捕捉人类决策的细微差别，且在多模态环境中需要人工干预，显得僵化且脆弱。神经网络虽能从多模态数据中提取丰富上下文信息，但缺乏可解释的推理结构。CALM旨在填补逻辑与神经感知之间的鸿沟，构建一种能处理多模态输入的模拟逻辑系统。

研究方法: CALM通过领域树表示每个谓词，并在实体上下文确定时迭代优化其模拟真值。这一迭代优化由能捕捉多模态信息的神经网络预测，并通过符号推理模块过滤以确保约束满足。

研究结果: 在填空式物体放置任务中，CALM达到了92.2%的准确率，优于传统逻辑（86.3%）和大型语言模型（59.4%）。此外，CALM生成的空间热图与逻辑约束和人类偏好一致，得到了人类研究的验证。

研究结论: CALM展示了在多模态环境中结合逻辑结构与偏好的潜力，为下一代需要逻辑精确性和神经网络多模态信息处理的AI系统奠定了基础。

中文摘要: 本文介绍了多模态上下文模拟逻辑（CALM），该系统将符号推理与神经生成相结合，使系统能够基于真实世界的多模态数据做出上下文敏感决策。背景：经典二值逻辑系统无法捕捉人类决策的细微差别，且在多模态环境中需要人工干预，显得僵化且脆弱。神经网络擅长从多模态数据中提取丰富上下文信息，但缺乏可解释的推理结构。目标：CALM旨在填补逻辑与神经感知之间的鸿沟，构建一种能处理多模态输入的模拟逻辑系统。方法：CALM通过领域树表示每个谓词，并在实体上下文确定时迭代优化其模拟真值。这一迭代优化由能捕捉多模态信息的神经网络预测，并通过符号推理模块过滤以确保约束满足。结果：在填空式物体放置任务中，CALM达到了92.2%的准确率，优于传统逻辑（86.3%）和大型语言模型（59.4%）。结论：CALM展示了在多模态环境中结合逻辑结构与偏好的潜力，为下一代AI系统奠定了基础。

</details>


### [118] [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.14990)
**中文标题：MEAL：持续多智能体强化学习的基准**

*Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy*

主要分类: cs.AI

摘要简述: 本文介绍了首个专为持续多智能体强化学习（CMARL）设计的基准MEAL，通过JAX实现GPU加速，解决了现有基准在CPU上运行导致的性能瓶颈问题。研究发现，简单结合现有CL和MARL方法在复杂任务中表现不佳，需进一步优化架构和算法。


<details>
  <summary>详细信息</summary>
研究动机: 当前持续学习（CL）在多智能体协作环境中的研究不足，缺乏专用基准。现有基准因在CPU上运行，存在计算瓶颈且无法支持长任务序列。本文旨在填补这一空白，推动CMARL领域的发展。

研究方法: 提出MEAL基准，利用JAX实现GPU加速，支持在标准桌面电脑上快速运行100个任务的持续学习序列。通过实验验证了现有CL和MARL方法在简单和复杂环境中的表现，并分析了关键架构与算法特征。

研究结果: 实验表明，现有方法在简单任务中表现良好，但在需要持续协调和适应的复杂任务中失效。通过消融研究，识别了对CMARL性能至关重要的架构和算法特性。

研究结论: MEAL为CMARL研究提供了首个高效基准，揭示了现有方法的局限性，并指出了未来优化的方向。

中文摘要: 基准在强化学习（RL）算法的开发和分析中至关重要，环境的可用性直接影响研究进展。持续学习（CL）在多智能体协作环境中的研究尤为不足。为此，我们推出了MEAL（多智能体自适应学习环境），这是首个专为持续多智能体强化学习（CMARL）设计的基准。现有CL基准在CPU上运行环境，导致计算瓶颈并限制了任务序列的长度。MEAL利用JAX实现GPU加速，可在标准桌面电脑上几小时内完成100个任务的持续学习序列。我们发现，简单结合流行的CL和MARL方法在简单环境中表现优异，但在需要持续协调和适应的复杂环境中失效。消融研究揭示了MEAL上CMARL的关键架构和算法特征。

</details>


### [119] [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050)
**中文标题：截断近端策略优化**

*Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu*

主要分类: cs.AI

摘要简述: 本文提出了一种名为截断近端策略优化（T-PPO）的新方法，通过优化策略更新和限制生成长度，显著提升了大型语言模型（LLM）的训练效率，同时保持收敛性能。实验表明，T-PPO在32B基础模型上实现了高达2.5倍的效率提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有的近端策略优化（PPO）方法在训练大型语言模型时效率较低，尤其是生成长文本时硬件利用率低，导致资源浪费。本文旨在通过改进PPO，解决这一问题并提升训练效率。

研究方法: 1. 提出扩展广义优势估计（EGAE），用于从不完整响应中估计优势值，同时保持策略学习的完整性。2. 设计了一种计算优化机制，允许策略模型和价值模型独立优化，通过选择性过滤提示和截断标记减少冗余计算。

研究结果: 在AIME 2024的32B基础模型上，T-PPO将推理型LLM的训练效率提升了高达2.5倍，且性能优于现有方法。

研究结论: T-PPO通过优化策略更新和生成长度限制，显著提升了训练效率，同时保持了模型性能，为大型语言模型的强化学习训练提供了高效解决方案。

中文摘要: 近年来，测试时扩展的大型语言模型（LLM）通过生成长链思维（CoT）在科学和专业任务中展现出卓越的推理能力。作为开发这些推理模型的关键组成部分，强化学习（RL）方法（如近端策略优化（PPO）及其变体）允许模型通过试错学习。然而，PPO由于其固有的在线策略性质，训练时间较长，且随着响应长度的增加，这一问题进一步加剧。本文提出了一种名为截断近端策略优化（T-PPO）的新方法，通过优化策略更新和限制生成长度，提升了训练效率。T-PPO解决了完全同步长生成过程中硬件利用率低的问题，避免了资源在等待完整生成时的闲置。我们的贡献包括：1. 提出扩展广义优势估计（EGAE），用于从不完整响应中估计优势值，同时保持策略学习的完整性；2. 设计了一种计算优化机制，允许策略模型和价值模型独立优化，通过选择性过滤提示和截断标记减少冗余计算，从而在不牺牲收敛性能的情况下加速训练过程。我们在AIME 2024的32B基础模型上验证了T-PPO的有效性，实验结果表明，T-PPO将推理型LLM的训练效率提升了高达2.5倍，且性能优于现有方法。

</details>


### [120] [HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges](https://arxiv.org/abs/2506.15196)
**中文标题：HeurAgenix：利用大语言模型解决复杂组合优化挑战**

*Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian*

主要分类: cs.AI

摘要简述: HeurAgenix是一个基于大语言模型（LLM）的两阶段超启发式框架，通过演化启发式算法并动态选择最优策略，显著提升了组合优化问题的解决能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统启发式算法依赖人工设计且难以泛化，而现有LLM方法在组合优化问题中表现有限。HeurAgenix旨在利用LLM的感知能力，自动生成和选择启发式策略，以解决复杂优化问题。

研究方法: HeurAgenix分为两阶段：1）启发式演化阶段，利用LLM比较种子解与高质量解，提取可重用策略；2）问题求解阶段，动态选择最优启发式策略。框架支持使用高性能LLM或轻量级微调模型，并通过双奖励机制解决监督信号稀缺问题。

研究结果: 在经典基准测试中，HeurAgenix不仅优于现有基于LLM的超启发式方法，还能媲美或超越专用求解器。

研究结论: HeurAgenix通过结合LLM的感知能力和动态选择机制，为组合优化问题提供了高效且通用的解决方案。

中文摘要: 启发式算法在解决组合优化（CO）问题中至关重要，但传统设计依赖人工专业知识且难以泛化到多样实例。我们提出\textbf{HeurAgenix}，一种基于大语言模型（LLM）的两阶段超启发式框架，首先生成启发式算法，随后自动选择最优策略。在启发式演化阶段，HeurAgenix利用LLM比较种子解与高质量解，提取可重用演化策略。在问题求解阶段，它根据LLM的感知能力动态选择最优启发式策略。为提升灵活性，选择器可以是高性能LLM或轻量级微调模型。为解决CO复杂性导致的监督信号稀缺问题，我们通过双奖励机制微调轻量级选择器，结合选择偏好和状态感知信号，实现噪声标注下的鲁棒选择。经典基准测试表明，HeurAgenix不仅优于现有基于LLM的超启发式方法，还能媲美或超越专用求解器。代码发布于https://github.com/microsoft/HeurAgenix。

</details>


### [121] [Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study](https://arxiv.org/abs/2506.15207)
**中文标题：多智能体强化学习在自主多卫星地球观测中的应用：一个真实案例研究**

*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk*

主要分类: cs.AI

摘要简述: 本文研究了多智能体强化学习（MARL）在自主多卫星地球观测任务中的应用，通过模拟真实卫星环境，评估了多种MARL算法的性能，证明了其在资源管理和协调中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着低地球轨道卫星数量的激增，地球观测任务面临实时动态决策的挑战，传统优化方法难以应对，因此需要探索强化学习和多智能体强化学习的应用。

研究方法: 通过模拟单卫星操作并扩展到多卫星星座，采用MARL框架（如PPO、IPPO、MAPPO和HAPPO）解决能源、数据存储限制及部分可观测性下的分散协调问题。

研究结果: 实验表明，MARL能有效平衡成像与资源管理，解决多卫星协调中的非平稳性和奖励依赖性问题，为自主卫星操作提供了实用指南。

研究结论: 本研究为分散式地球观测任务的政策学习提供了基础，展示了MARL在复杂卫星系统中的潜力。

中文摘要: 低地球轨道（LEO）卫星的指数增长彻底改变了地球观测（EO）任务，解决了气候监测、灾害管理等领域的挑战。然而，多卫星系统的自主协调仍是一个根本性难题。传统优化方法难以满足动态EO任务的实时决策需求，因此需要利用强化学习（RL）和多智能体强化学习（MARL）。本文通过模拟单卫星操作并扩展到多卫星星座，研究了基于RL的自主EO任务规划。我们解决了能源和数据存储限制、卫星观测的不确定性以及部分可观测性下的分散协调复杂性等关键问题。通过利用接近真实的卫星模拟环境，评估了包括PPO、IPPO、MAPPO和HAPPO在内的先进MARL算法的训练稳定性和性能。结果表明，MARL能有效平衡成像与资源管理，同时解决多卫星协调中的非平稳性和奖励依赖性问题。本研究的见解为自主卫星操作奠定了基础，为改进分散式EO任务的政策学习提供了实用指南。

</details>


### [122] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
**中文标题：基于无人机与船舶协作的不确定海上MEC联合计算卸载与资源分配**

*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

主要分类: cs.AI

摘要简述: 本文提出了一种基于无人机和船舶协作的海上MEC框架，用于解决不确定任务下的计算卸载和资源分配问题，通过Lyapunov优化和异构智能体强化学习有效降低了总执行时间。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，海上物联网（MIoT）的计算需求快速增长，而无人机和船舶的多接入边缘计算（MEC）可以满足这些需求。然而，不确定的海上任务带来了计算卸载和资源分配效率低下的挑战。

研究方法: 首先提出了一种协作MEC框架，包括MIoT设备、无人机和船舶。通过Lyapunov优化处理不确定任务，将长期约束转化为短期约束，并进一步将问题建模为马尔可夫博弈。提出了一种异构智能体软演员-评论家方法，有效解决该博弈问题。

研究结果: 仿真实验验证了所提框架在计算卸载和资源分配中的有效性，显著降低了总执行时间。

研究结论: 通过无人机和船舶的协作，结合Lyapunov优化和强化学习，能够高效解决不确定任务下的海上MEC问题。

中文摘要: 近年来，海上物联网（MIoT）的计算需求快速增长，基于无人机和船舶的多接入边缘计算（MEC）可以满足这些需求。然而，不确定的海上任务对计算卸载和资源分配的效率提出了重大挑战。本文聚焦于通过无人机和船舶的协作解决海上计算卸载和资源分配问题，并考虑了任务的不确定性。具体而言，我们提出了一种协作MEC框架，包括MIoT设备、无人机和船舶。然后，我们构建了优化问题以最小化总执行时间。针对不确定的MIoT任务，利用Lyapunov优化处理不可预测的任务到达和变化的计算资源可用性。通过将长期约束转化为短期约束，得到一组小规模优化问题。进一步，考虑到无人机和船舶动作与资源的异质性，将小规模优化问题重新建模为马尔可夫博弈（MG）。此外，提出了一种异构智能体软演员-评论家方法，通过顺序更新多种神经网络有效解决MG问题。最后，通过仿真验证了所提方法在计算卸载和资源分配中的有效性。

</details>


### [123] [Efficient and Generalizable Environmental Understanding for Visual Navigation](https://arxiv.org/abs/2506.15377)
**中文标题：高效且可泛化的环境理解在视觉导航中的应用**

*Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao*

主要分类: cs.AI

摘要简述: 本文提出了一种基于因果关系的视觉导航方法（CAN），通过引入因果理解模块提升智能体对环境理解的能力，实验表明其在多种任务和模拟环境中优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉导航方法通常同时处理所有历史观测数据，忽略了数据内部的关联结构，限制了任务性能的进一步提升。本文从因果关系的角度分析了导航任务的特性，旨在解决这一局限性。

研究方法: 提出Causality-Aware Navigation（CAN）方法，引入因果理解模块（Causal Understanding Module），通过因果关系建模增强智能体对环境理解的能力。该方法适用于强化学习和监督学习场景，且无需额外计算开销。

研究结果: 实验表明，CAN方法在多种任务和模拟环境中均优于基线方法。消融研究进一步验证了因果理解模块的有效性和泛化能力。

研究结论: 本文提出的CAN方法通过因果关系建模显著提升了视觉导航任务的性能，且具有广泛的适用性和泛化能力。

中文摘要: 视觉导航是具身智能中的核心任务，使智能体能够在复杂环境中导航以实现给定目标。在导航任务的各种场景中，许多任务需要对先前时间步积累的序列数据进行建模。尽管现有方法表现良好，但它们通常同时处理所有历史观测数据，忽略了数据内部的关联结构，这可能限制任务性能的进一步提升。我们通过因果关系的视角分析了导航任务的独特特性，引入了一个因果框架以揭示传统序列方法的局限性。基于这一洞察，我们提出了因果感知导航（CAN），该方法通过因果理解模块增强了智能体的环境理解能力。实验评估表明，我们的方法在多种任务和模拟环境中均优于基线方法。广泛的消融研究将这些性能提升归因于因果理解模块，该模块在强化学习和监督学习场景中均能有效泛化，且无需额外计算开销。

</details>


### [124] [Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](https://arxiv.org/abs/2506.15567)
**中文标题：基于LLM的推理与行动代理管理复杂故障分析工作流**

*Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大型语言模型（LLM）的规划代理（LPA），用于协助故障分析工程师处理复杂工作流，通过整合LLM与外部工具，实现自主查询处理、数据检索和报告生成。


<details>
  <summary>详细信息</summary>
研究动机: 故障分析（FA）是一个复杂且知识密集的过程，随着AI模型数量的增加，如何将这些组件整合为高效的工作流成为挑战。本文旨在通过LLM技术解决这一问题。

研究方法: 设计并实现了一种基于LLM的规划代理（LPA），结合高级规划能力和外部工具使用，能够自主处理复杂查询、检索外部数据并生成人类可读的响应。

研究结果: 评估结果表明，LPA在支持故障分析任务中表现出操作有效性和可靠性。

研究结论: LPA能够有效协助故障分析工程师，提升工作流效率，为复杂故障分析任务提供了一种可行的解决方案。

中文摘要: 故障分析（FA）是一个高度复杂且知识密集的过程。在FA实验室的计算基础设施中整合AI组件，可以自动化多种任务，包括图像中非一致性的检测、从多样化数据源中检索类似案例，以及从标注图像生成报告。然而，随着部署的AI模型数量增加，挑战在于如何将这些组件协调为与FA过程无缝集成的连贯高效工作流。本文研究了基于大型语言模型（LLM）的规划代理（LPA）的设计与实现，以协助FA工程师解决分析案例。LPA将LLM与高级规划能力和外部工具使用相结合，能够自主处理复杂查询、从外部系统检索相关数据并生成人类可读的响应。评估结果证明了该代理在支持FA任务中的操作有效性和可靠性。

</details>


### [125] [The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games](https://arxiv.org/abs/2506.15624)
**中文标题：状态表示对LLM智能体在动态路由游戏中行为的影响**

*Lyle Goodyear,Rachel Guo,Ramesh Johari*

主要分类: cs.AI

摘要简述: 本文提出了一种系统构建自然语言状态表示的框架，用于在动态路由游戏中指导LLM智能体的行为。研究发现，状态表示的方式（如历史摘要、后悔信息等）显著影响智能体行为，使其更接近博弈论均衡预测。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究在LLM智能体游戏中采用临时性方法编码游戏历史，不仅掩盖了状态表示对行为的影响，还限制了研究间的可比性。本文旨在填补这一空白，系统分析状态表示对智能体行为的影响。

研究方法: 提出了一个统一框架，从三个维度（动作信息性、奖励信息性和提示风格）系统构建自然语言状态表示，并在动态自私路由游戏中验证其效果。

研究结果: 研究发现，提供摘要化的历史表示、后悔信息而非原始收益、以及有限的他人动作信息，能使LLM智能体行为更接近博弈论均衡预测，且游戏动态更稳定。

研究结论: 状态表示方式对LLM智能体行为有显著影响，优化表示方法可提升其在动态游戏中的表现。

中文摘要: 大型语言模型（LLMs）在动态环境中作为决策者展现出潜力，但其无状态特性需要构建历史信息的自然语言表示。我们提出了一个统一框架，用于系统构建自然语言“状态”表示，以指导重复多智能体游戏中的LLM智能体。以往关于LLM智能体游戏的研究采用临时性方法编码游戏历史，这不仅掩盖了状态表示对智能体行为的影响，还限制了研究间的可比性。我们的框架通过三个维度（动作信息性、奖励信息性和提示风格）填补了这一空白。我们将此框架应用于动态自私路由游戏，发现状态表示方式对LLM智能体行为有显著影响。具体而言，提供摘要化的历史表示、后悔信息而非原始收益、以及有限的他人动作信息，能使智能体行为更接近博弈论均衡预测，且游戏动态更稳定。

</details>


### [126] [The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy](https://arxiv.org/abs/2506.15639)
**中文标题：AI政策模块：培养计算机科学学生在AI伦理与政策中的能力**

*James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry*

主要分类: cs.AI

摘要简述: 本文介绍了一个AI政策模块，旨在帮助计算机科学学生提升AI伦理与政策能力。通过课程模块和‘AI监管’技术作业，学生表现出对AI伦理影响的关注增加，并增强了参与AI政策讨论的信心。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI技术在各领域的广泛应用，AI伦理和政策的重要性日益凸显。然而，当前计算机科学课程未能充分培养学生将伦理原则转化为实践的能力。本文旨在通过开发AI政策模块，填补这一教育空白。

研究方法: 作者开发了AI政策模块2.0，并将其纳入计算机科学课程中。模块包括‘AI监管’技术作业，并通过前后问卷调查评估学生对AI伦理和政策的态度变化。

研究结果: 模块实施后，学生对AI技术伦理影响的关注度显著提升，同时对其参与AI政策讨论的能力表现出更强的信心。‘AI监管’作业被证明是探索AI伦理挑战的有效工具。

研究结论: AI政策模块成功提升了学生对AI伦理和政策的理解与实践能力，为计算机科学课程中融入AI伦理教育提供了可行方案。

中文摘要: 随着人工智能（AI）在个人和专业场景中的广泛应用，不仅需要关注AI伦理，还需重视通过AI政策对技术进行治理和监管。然而，当前的高等教育计算机课程未能充分培养未来的AI从业者，使其能够将抽象的伦理原则和政策偏好转化为AI系统的设计与开发实践。我们认为，熟悉‘AI政策格局’并将伦理原则转化为实践能力，将成为未来AI工程师的重要职责。

为帮助当前计算机科学（CS）学生应对这些新需求，我们开发了AI政策模块，将AI政策讨论引入CS课程。基于2024年秋季的成功试点，本文提出了更新和扩展的模块版本，包括一项关于‘AI监管’的技术作业。我们通过模块前后的问卷调查评估了学生对AI伦理和政策的态度变化。结果显示，学生在模块结束后对AI技术伦理影响的关注度增加，同时对参与AI政策讨论的能力表现出更强的信心。最后，我们强调‘AI监管作业’是探索AI对齐局限性并突出‘政策’在解决伦理挑战中作用的有效工具。

</details>


### [127] [Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement](https://arxiv.org/abs/2506.15647)
**中文标题：探索并利用大型推理模型的固有效率以实现自我引导的效率提升**

*Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu*

主要分类: cs.AI

摘要简述: 本文探讨大型推理模型（LRMs）的效率问题，发现其存在过度推理现象，并提出两种轻量级方法（效率引导和自奖励效率强化学习）以提升推理效率，同时保持任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型（LRMs）在复杂问题解决中表现出色，但常因过度推理（生成冗余内容）导致效率低下和推理成本增加。本文旨在挖掘其内在效率潜力，并提出改进方法。

研究方法: 1. 效率引导：一种无需训练的激活引导技术，通过模型表示空间中的单一方向调节推理行为。2. 自奖励效率强化学习：动态平衡任务准确性和简洁性的强化学习框架，奖励简洁正确的解决方案。

研究结果: 在多个数学推理基准测试中，两种方法显著减少了推理长度，同时保持或提升了任务性能。

研究结论: 研究表明，通过引导和利用现有模型的内在能力，可以以自引导方式提升推理效率。

中文摘要: 近年来，大型推理模型（LRMs）通过模拟人类审慎思维显著提升了语言模型在复杂问题解决中的能力。然而，这些模型常表现出过度推理（即生成不必要的冗长和冗余内容），从而阻碍效率并增加推理成本。本文探讨了这种低效的表征和行为根源，揭示了LRMs天生具备更简洁推理的潜力。实证分析表明，正确的推理路径长度差异显著，而最短的正确响应通常足够，表明存在未开发的效率潜力。基于这些发现，我们提出两种轻量级方法以提升LRM效率。首先，我们引入效率引导，这是一种无需训练的激活引导技术，通过模型表示空间中的单一方向调节推理行为。其次，我们开发了自奖励效率强化学习，这是一种通过奖励简洁正确解决方案来动态平衡任务准确性和简洁性的强化学习框架。在多个数学推理基准测试中对七种LRM主干进行的广泛实验表明，我们的方法显著减少了推理长度，同时保持或提升了任务性能。结果表明，通过以自引导方式利用和引导现有模型的内在能力，可以提升推理效率。

</details>


### [128] [SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence](https://arxiv.org/abs/2506.15672)
**中文标题：SwarmAgentic：基于群体智能的全自动代理系统生成**

*Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp*

主要分类: cs.AI

摘要简述: SwarmAgentic提出了一种全自动代理系统生成框架，通过群体智能实现代理的从零生成、功能优化与协作，显著提升了任务适应性和扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 现有代理系统生成框架缺乏全自动化能力，无法实现从零生成代理、自我优化功能及协作，限制了系统的适应性和扩展性。SwarmAgentic旨在填补这一空白。

研究方法: SwarmAgentic采用语言驱动探索，将代理功能和协作作为相互依赖的组件联合优化，并借鉴粒子群优化（PSO）方法，通过反馈引导更新候选系统群。

研究结果: 在六项真实世界的开放性和探索性任务中，SwarmAgentic仅凭任务描述和目标函数即超越所有基线，如在TravelPlanner基准上相对ADAS提升261.8%。

研究结论: SwarmAgentic标志着向可扩展和全自动化代理系统设计迈出重要一步，将群体智能与全自动化多代理生成相结合。

中文摘要: 大型语言模型的快速发展推动了代理系统在决策、协调和任务执行方面的进步。然而，现有代理系统生成框架缺乏全自动化能力，无法实现从零生成代理、自我优化功能及协作，限制了适应性和扩展性。我们提出SwarmAgentic，一种全自动代理系统生成框架，通过语言驱动探索从零构建代理系统，并将代理功能与协作作为相互依赖的组件联合优化。为实现对系统级结构的高效搜索，SwarmAgentic维护候选系统群并通过反馈引导更新进化，灵感来源于粒子群优化（PSO）。我们在六项真实世界的开放性探索性任务中评估了该方法，涉及高层规划、系统级协调和创造性推理。仅凭任务描述和目标函数，SwarmAgentic即超越所有基线，如在TravelPlanner基准上相对ADAS提升261.8%，凸显了全自动化在结构无约束任务中的有效性。该框架标志着向可扩展和全自动化代理系统设计迈出重要一步，将群体智能与全自动化多代理生成相结合。代码已公开于https://yaoz720.github.io/SwarmAgentic/。

</details>


### [129] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
**中文标题：具身网络代理：为集成代理智能搭建物理与数字领域的桥梁**

*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

主要分类: cs.AI

摘要简述: 本文提出了一种新型AI代理范式——'具身网络代理'，旨在无缝结合物理世界感知与网络规模推理能力，解决需要跨领域智能的任务。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI代理多局限于单一领域，要么处理数字信息，要么与物理世界交互，缺乏整合能力。这种分离限制了其在需要物理与数字智能协同的任务（如烹饪、导航等）中的表现。

研究方法: 作者开发了'具身网络代理任务环境'，一个集成了真实3D环境与功能性网络接口的仿真平台，并在此基础上构建了包含烹饪、导航等任务的基准测试。

研究结果: 实验结果显示，现有AI系统与人类能力之间存在显著差距，揭示了在具身认知与网络知识访问交叉领域的挑战与机遇。

研究结论: 本文提出的具身网络代理为跨领域智能研究提供了新方向，相关数据和代码已公开。

中文摘要: 当今的AI代理大多孤立运行——它们要么在线获取并推理大量数字信息和知识，要么通过具身感知、规划和行动与物理世界交互，但很少同时具备两者能力。这种分离限制了其在需要整合物理与数字智能的任务（如根据在线食谱烹饪、使用动态地图数据导航或利用网络知识解读现实地标）中的表现。我们提出了'具身网络代理'，一种新型AI代理范式，能够无缝结合具身性与网络规模推理。为实现这一概念，我们首先开发了'具身网络代理任务环境'，这是一个将真实3D室内外环境与功能性网络接口紧密结合的统一仿真平台。基于此平台，我们构建并发布了'具身网络代理基准测试'，涵盖烹饪、导航、购物、旅游和地理定位等多样化任务，均需跨物理与数字领域的协同推理，以系统评估跨领域智能。实验结果显示，当前最先进的AI系统与人类能力之间存在显著差距，为具身认知与网络知识访问的交叉领域提出了挑战与机遇。所有数据集、代码和网站均已公开，项目页面为https://embodied-web-agent.github.io/。

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [130] [BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models](https://arxiv.org/abs/2506.14861)
**中文标题：BMFM-RNA：构建和评估转录组基础模型的开放框架**

*Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou*

主要分类: q-bio.GN

摘要简述: BMFM-RNA是一个开源模块化软件包，旨在统一转录组基础模型（TFMs）的预训练和微调目标，并引入新的训练目标WCED，以提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前转录组基础模型的多样性和训练策略差异使得设计选择的贡献难以评估，阻碍了最佳实践的达成和研究的可重复性。BMFM-RNA旨在解决这一问题。

研究方法: BMFM-RNA提供了一个统一的框架，支持多种输入表示和训练目标，包括新提出的WCED目标，通过自编码器式的CLS瓶颈表示捕捉全局表达模式。

研究结果: 在CELLxGENE上预训练的四个模型检查点表明，基于WCED的模型在零样本和微调任务中性能优于或匹配现有最佳方法（如scGPT）。

研究结论: BMFM-RNA为系统化基准测试和社区驱动的TFM训练策略探索提供了可重复的基础，有助于开发更有效的工具以理解细胞生物学。

中文摘要: 转录组基础模型（TFMs）已成为分析细胞和组织基因表达的有力工具，支持细胞类型注释、批次校正和扰动预测等关键任务。然而，近期TFMs的模型实现和训练策略多样性虽具潜力，但难以评估单个设计选择的贡献或其潜在协同效应，阻碍了最佳实践的达成和跨研究见解的可重复性。我们提出BMFM-RNA，一个开源模块化软件包，将多样化的TFM预训练和微调目标统一于单一框架中。利用这一能力，我们引入了一种新的训练目标——全细胞表达解码器（WCED），通过自编码器式的CLS瓶颈表示捕捉全局表达模式。本文描述了该框架、支持的输入表示和训练目标。我们评估了在CELLxGENE上预训练的四个模型检查点，结合了掩码语言建模（MLM）、WCED和多任务学习。通过BMFM-RNA的基准测试能力，我们表明基于WCED的模型在零样本和微调任务中性能优于或匹配现有最佳方法（如scGPT）。BMFM-RNA作为biomed-multi-omics项目的一部分（https://github.com/BiomedSciAI/biomed-multi-omic），为系统化基准测试和社区驱动的TFM训练策略探索提供了可重复的基础，助力开发更有效的工具以利用AI最新进展理解细胞生物学。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [131] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
**中文标题：基于LabVIEW的精确修订版光学字符识别语音合成系统**

*Prateek Mehta,Anasuya Patil*

主要分类: cs.SD

摘要简述: 本文提出了一种基于光学字符识别（OCR）的语音合成系统，旨在为视障人士提供准确、可靠且经济高效的阅读解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 视障人士通常依赖盲文书籍和非政府组织提供的音频材料，但这些方式限制了他们的阅读选择。语音作为更有效的沟通方式，能够帮助视障人士更便捷地获取信息。

研究方法: 研究采用LabVIEW平台开发了一种基于OCR的语音合成系统，通过光学字符识别技术将文本转换为语音。

研究结果: 该系统实现了准确、可靠且用户友好的文本到语音转换，为视障人士提供了更灵活的阅读选择。

研究结论: 基于OCR的语音合成系统为视障人士提供了一种经济高效且易于使用的解决方案，有望改善他们的阅读体验。

中文摘要: 通过声音提取知识是一种独特的特性。视障人士通常仅依赖盲文书籍和非政府组织提供的音频材料。由于这些方式的局限性，盲人往往无法选择自己喜欢的书籍。对于视障人士而言，语音比文本更有效，因为他们可以轻松对声音作出反应。本文提出了一种基于光学字符识别（OCR）的语音合成系统的开发，该系统具有准确、可靠、经济高效和用户友好的特点。该OCR系统基于LabVIEW平台实现。

</details>


### [132] [SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](https://arxiv.org/abs/2506.15154)
**中文标题：SonicVerse：基于多任务学习的音乐特征感知描述生成**

*Anuradha Chopra,Abhinaba Roy,Dorien Herremans*

主要分类: cs.SD

摘要简述: 本文提出了一种名为SonicVerse的多任务音乐描述模型，通过结合音乐特征检测任务（如调性检测、人声检测等）生成更丰富的音乐描述，提升了音乐数据库的详细性和音乐AI研究的进展。


<details>
  <summary>详细信息</summary>
研究动机: 音乐描述的准确性对音乐数据库和研究至关重要。现有方法缺乏对音乐特征的直接捕捉，导致描述不够详细。本文旨在通过多任务学习，结合音乐特征检测，生成更丰富的音乐描述。

研究方法: SonicVerse采用基于投影的架构，将音频输入转换为语言标记，同时通过专用辅助头检测音乐特征。这些特征的输出也被投影为语言标记，以增强描述输入。此外，通过大语言模型串联输出，生成长音乐片段的时间详细描述。

研究结果: 实验结果表明，结合音乐特征的方法显著提高了生成描述的细节和质量。扩展的MusicBench数据集（使用MIRFLEX标注音乐特征）为训练提供了支持。

研究结论: SonicVerse通过多任务学习和音乐特征检测，成功生成了更丰富和详细的音乐描述，为音乐AI研究提供了新工具。

中文摘要: 能够准确反映音乐特征的详细描述可以丰富音乐数据库并推动音乐AI研究。本文提出了一种多任务音乐描述模型SonicVerse，它将描述生成与辅助音乐特征检测任务（如调性检测、人声检测等）相结合，以直接捕捉低层次声学细节和高层次音乐属性。关键贡献是一种基于投影的架构，将音频输入转换为语言标记，同时通过专用辅助头检测音乐特征。这些头的输出也被投影为语言标记，以增强描述输入。该框架不仅为短音乐片段生成了丰富的描述性文本，还通过大语言模型串联输出，直接生成长音乐片段的时间详细描述。为了训练模型，我们使用模块化音乐特征提取器MIRFLEX对MusicBench数据集进行了扩展标注，生成了配对的音频、描述和音乐特征数据。实验结果表明，通过这种方式结合特征可以提高生成描述的质量和细节。

</details>


### [133] [pycnet-audio: A Python package to support bioacoustics data processing](https://arxiv.org/abs/2506.14864)
**中文标题：pycnet-audio：一个支持生物声学数据处理的Python工具包**

*Zachary J. Ruff,Damon B. Lesmeister*

主要分类: cs.SD

摘要简述: pycnet-audio是一个Python工具包，旨在支持生物声学数据处理，特别是通过自动化检测目标信号（如野生动物叫声）来处理大规模被动声学监测数据。


<details>
  <summary>详细信息</summary>
研究动机: 被动声学监测在野生动物研究中日益重要，但大规模音频数据的手动处理不切实际。本文旨在提供一个自动化工具，以支持高效处理和分析这些数据。

研究方法: pycnet-audio基于PNW-Cnet模型，该模型最初用于监测北方斑点猫头鹰等森林猫头鹰种群，现已扩展至检测约80种森林野生动物叫声及多种人为和环境噪声。

研究结果: 该工具包能够高效处理大规模音频数据，支持自动化检测目标信号，显著提升了生物声学数据处理的效率。

研究结论: pycnet-audio为生物声学研究提供了一个实用的自动化数据处理解决方案，适用于大规模被动声学监测项目。

中文摘要: 被动声学监测是野生动物研究中的一种新兴方法，利用专门设计的自动录音设备（ARU）进行长时间录音（数周或数月）。这些音频数据需要进一步处理，通常包括测量音频特征或搜索目标信号（如特定物种的叫声）。对于大规模数据集（如10^5小时的录音），手动处理不切实际，因此需要自动化检测方法。pycnet-audio（Ruff 2024）旨在为声学数据提供实用的处理流程，基于PNW-Cnet模型。该模型最初由美国林务局开发，用于监测北方斑点猫头鹰等森林猫头鹰种群（Lesmeister和Jenkins 2022；Ruff等2020），现已扩展至检测约80种森林野生动物叫声及多种人为和环境噪声（Ruff等2021，2023）。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [134] [An Empirical Study of Bugs in Data Visualization Libraries](https://arxiv.org/abs/2506.15084)
**中文标题：数据可视化库中错误的实证研究**

*Weiqi Lu,Yongqiang Tian,Xiaohan Zhong,Haoyang Ma,Zhenyang Xu,Shing-Chi Cheung,Chengnian Sun*

主要分类: cs.SE

摘要简述: 本文首次对数据可视化库中的错误进行了全面分析，研究了五个常用库中的564个错误，系统分析了其症状和根源，并提出了一种详细的分类法。研究发现，错误/不准确的图表在数据可视化库中普遍存在，主要原因是图形计算错误，需要进一步开发自动化测试方法。此外，研究还提出了触发此类错误的八个关键步骤和两种特定于数据可视化库的测试预言，为未来设计高效自动化测试技术提供了启发。


<details>
  <summary>详细信息</summary>
研究动机: 数据可视化库在数据呈现、分析和应用开发中至关重要，但其错误可能导致用户体验下降、信息传递失真甚至影响用户决策。由于这些错误通常不会引发明显崩溃，而是通过图形误导用户，因此了解其独特特性对研究人员和开发者检测和修复错误至关重要。

研究方法: 本研究收集了五个广泛使用的数据可视化库中的564个错误，系统分析了其症状和根源，并提出了一种详细的分类法。此外，研究还探索了视觉语言模型（VLMs）在检测错误/不准确图表中的可行性。

研究结果: 研究发现，错误/不准确的图表在数据可视化库中普遍存在，主要原因是图形计算错误。研究还提出了触发此类错误的八个关键步骤和两种特定于数据可视化库的测试预言。视觉语言模型（VLMs）在错误检测中的有效性介于29%至57%之间，且提示信息的增加并不一定能提高检测效果。

研究结论: 本研究为数据可视化库中的错误提供了首个全面分析，揭示了其独特特性和根源，并提出了未来研究方向，包括开发自动化测试方法和利用视觉语言模型改进错误检测。

中文摘要: 数据可视化（DataViz）库在数据呈现、分析和应用开发中扮演着关键角色，其准确性对将数据转化为可视化表示至关重要。错误的可视化可能损害用户体验、扭曲信息传递并影响用户感知和决策过程。这些库中的视觉错误尤为隐蔽，因为它们通常不会引发明显崩溃，而是通过图形误导用户对底层数据的理解，从而导致错误决策。因此，深入了解数据可视化库中错误的独特特性对研究人员和开发者检测和修复错误至关重要。本研究首次对数据可视化库中的错误进行了全面分析，研究了从五个广泛使用的库中收集的564个错误，系统分析了其症状和根源，并提出了一种详细的分类法。我们发现，错误/不准确的图表在数据可视化库中普遍存在，主要原因是图形计算错误，这需要进一步开发自动化测试方法。此外，我们提出了触发此类错误的八个关键步骤和两种特定于数据可视化库的测试预言，为未来设计高效自动化测试技术提供了启发。随着视觉语言模型（VLMs）的近期进展，我们还探索了这些模型在检测错误/不准确图表中的可行性。结果显示，VLMs在错误检测中的有效性介于29%至57%之间，具体取决于提示内容，而增加提示信息并不一定能提高检测效果。更多发现详见我们的论文。

</details>


### [135] [Uncovering Intention through LLM-Driven Code Snippet Description Generation](https://arxiv.org/abs/2506.15453)
**中文标题：通过LLM驱动的代码片段描述生成揭示意图**

*Yusuf Sulistyo Nugroho,Farah Danisha Salam,Brittany Reid,Raula Gaikovina Kula,Kazumasa Shimari,Kenichi Matsumoto*

主要分类: cs.SE

摘要简述: 本文研究大型语言模型（LLM）如何生成代码片段描述，发现开发者常用示例描述，LLM（Llama）能较好识别此类描述，但生成的描述仍有改进空间。


<details>
  <summary>详细信息</summary>
研究动机: 代码片段文档化对开发者和用户至关重要，尤其是第三方库的API文档。随着大型语言模型（LLM）的兴起，研究开发者常用的描述类型及LLM在描述生成中的表现成为关键目标。

研究方法: 使用NPM代码片段数据集（185,412个包，1,024,579个代码片段），选取400个样本进行人工分类和LLM（Llama）描述生成评估。

研究结果: 人工分类发现55.5%的原描述为示例用途；LLM正确识别79.75%的示例描述，与原结果一致；生成描述的平均相似度为0.7173，表明相关但需改进。

研究结论: 代码片段的文档意图因任务而异（如使用说明、安装或学习示例），LLM在描述生成中表现良好但仍有优化空间。

中文摘要: 代码片段文档化是开发者和用户关注的重点，尤其是第三方库的使用示例和API文档。随着大型语言模型（LLM）的兴起，本研究旨在探讨开发者常用的描述类型，并评估LLM（如Llama）在描述生成中的表现。我们使用NPM代码片段数据集（包含185,412个包和1,024,579个代码片段），从中选取400个样本进行分析。首先，人工分类发现55.5%的原描述为示例用途，凸显了清晰文档的重要性，部分描述未能充分传达意图。其次，LLM正确识别了79.75%的示例描述，与人工结果一致，显示出较强的泛化能力。第三，生成的描述与原描述的平均相似度为0.7173，表明相关性但仍有改进空间（低于0.9的分数表示部分不相关）。结果表明，代码片段的文档意图因任务而异，可能是使用说明、安装指南或学习示例。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [136] [Improved Image Reconstruction and Diffusion Parameter Estimation Using a Temporal Convolutional Network Model of Gradient Trajectory Errors](https://arxiv.org/abs/2506.14995)
**中文标题：基于时间卷积网络的梯度轨迹误差模型改进图像重建和扩散参数估计**

*Jonathan B. Martin,Hannah E. Alderson,John C. Gore,Mark D. Does,Kevin D. Harkins*

主要分类: physics.med-ph

摘要简述: 本文提出了一种基于时间卷积网络的梯度轨迹误差模型，用于改善磁共振图像重建和扩散参数估计，显著提升了图像质量和参数映射的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在非笛卡尔成像序列中，梯度轨迹误差会导致显著的图像伪影和失真，传统线性方法无法准确建模这些非线性误差，因此需要开发更精确的梯度系统模型。

研究方法: 通过在小动物成像系统上测量一组训练梯度波形，利用时间卷积网络训练模型以预测成像系统产生的梯度波形，并将预测结果整合到图像重建流程中。

研究结果: 训练后的网络能够准确预测梯度系统的非线性失真，相比名义梯度波形和梯度脉冲响应函数，显著改善了图像质量和扩散参数映射。

研究结论: 时间卷积网络比现有线性方法更准确地建模梯度系统行为，可用于回顾性校正梯度误差。

中文摘要: 摘要：梯度轨迹误差在磁共振图像中引入了显著的伪影和失真，特别是在非笛卡尔成像序列中，不完美的梯度波形会大幅降低图像质量。目的：我们的目标是开发一种通用的非线性梯度系统模型，能够利用卷积网络准确预测梯度失真。方法：在一台小动物成像系统上测量了一组训练梯度波形，并用于训练时间卷积网络以预测成像系统产生的梯度波形。结果：训练后的网络能够准确预测梯度系统产生的非线性失真。将网络预测的梯度波形整合到图像重建流程中，相比名义梯度波形和梯度脉冲响应函数，显著提升了图像质量和扩散参数映射。结论：时间卷积网络比现有线性方法更准确地建模梯度系统行为，可用于回顾性校正梯度误差。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [137] [Omnidirectional Video Super-Resolution using Deep Learning](https://arxiv.org/abs/2506.14803)
**中文标题：基于深度学习的全方位视频超分辨率技术**

*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter W. Eklund,Sunil Aryal*

主要分类: cs.MM

摘要简述: 本文提出了一种用于360°视频超分辨率的新型深度学习模型S3PO，解决了传统视频超分辨率技术在360°视频中的失真问题，并通过新数据集360VDS验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 360°视频在虚拟现实中广泛应用，但其空间分辨率不足限制了视觉体验。传统视频超分辨率技术无法解决360°视频的投影失真问题，且缺乏相关数据集。

研究方法: 本文创建了360°视频数据集360VDS，并提出了新型深度学习模型S3PO，采用循环建模和注意力机制，结合专门设计的特征提取器和损失函数以解决球形失真。

研究结果: S3PO在360°视频数据集上优于大多数传统视频超分辨率模型和360°专用超分辨率模型，并通过逐步消融研究验证了其架构子组件的有效性。

研究结论: S3PO为360°视频超分辨率提供了高效解决方案，解决了失真问题，并通过实验验证了其优越性。

中文摘要: 全方位视频（即360°视频）在虚拟现实（VR）中广泛用于提供沉浸式和交互式观看体验。然而，360°视频的空间分辨率有限，无法为每个视角提供足够的像素，从而限制了沉浸式体验的视觉质量。传统的深度学习视频超分辨率（VSR）技术为传统视频提供了基于软件的解决方案，但这些技术未能解决360°视频信号在等距柱状投影中的失真问题。另一个障碍是缺乏可用于研究的360°视频数据集。为解决这些问题，本文创建了一个新颖的360°视频数据集（360VDS），并研究了传统VSR模型在360°视频中的扩展性。本文进一步提出了一种新型深度学习模型，称为“比例优化球形信号超分辨率”（S3PO），用于360°视频超分辨率（360° VSR）。S3PO采用循环建模和注意力机制，摆脱了传统VSR技术（如对齐）的束缚。通过专门设计的特征提取器和针对球形失真的新型损失函数，S3PO在360°视频数据集上优于大多数最先进的传统VSR模型和360°专用超分辨率模型。本文还通过逐步消融研究，理解和展示了所选架构子组件、针对性训练和优化的影响。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [138] [Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](https://arxiv.org/abs/2506.15290)
**中文标题：基于服装感知扩散模型的松散稀疏惯性传感器人体运动捕捉**

*Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz*

主要分类: cs.GR

摘要简述: 本文提出了一种基于稀疏且松散附着惯性传感器（IMU）的全身姿态估计新任务，通过模拟松散IMU数据并开发基于Transformer的扩散模型，结合服装参数提升性能，实验证明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于IMU的运动捕捉方法通常假设传感器紧密附着于人体，但实际场景中传感器可能松散附着。本文旨在解决这一现实问题，提出一种适用于松散IMU的姿态估计方法。

研究方法: 通过模拟现有服装感知运动数据集的松散IMU记录，开发基于Transformer的扩散模型，合成松散IMU数据并估计人体姿态。训练中结合服装参数以增强模型对服装松紧变化的适应性。

研究结果: 实验表明，所提出的扩散模型在模拟和合成数据上训练后，定量和定性均优于现有方法，为松散IMU姿态估计提供了新方向。

研究结论: 本文通过扩散模型和服装参数结合，成功解决了松散IMU姿态估计问题，为未来研究开辟了有前景的路径。

中文摘要: 与基于摄像头的跟踪相比，稀疏惯性传感器（IMU）的运动捕捉因其便携性和无遮挡问题展现出巨大潜力。现有方法通常假设IMU传感器紧密附着于人体，但这一假设在实际场景中往往不成立。本文提出了一种基于稀疏松散附着IMU传感器的全身人体姿态估计新任务。为解决此任务，我们从现有服装感知人体运动数据集中模拟了松散IMU记录，并开发了基于Transformer的扩散模型，用于合成松散IMU数据并基于此具有挑战性的数据估计人体姿态。此外，我们表明在训练模型时结合服装相关参数，能有效保持表现力并增强对服装松紧变化引入的变异的捕捉能力。实验表明，我们提出的扩散模型在模拟和合成数据上训练后，在定量和定性上均优于现有方法，为未来研究开辟了有前景的方向。

</details>


### [139] [One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning](https://arxiv.org/abs/2506.15312)
**中文标题：基于生成扩散先验与指令调优的单次野外人脸素描合成**

*Han Wu,Junyao Li,Kangbo Zhao,Sen Zhang,Yukai Shi,Liang Lin*

主要分类: cs.GR

摘要简述: 本文提出了一种基于扩散模型的单次人脸素描合成方法，通过优化文本指令生成高质量素描，并引入新基准数据集OS-Sketch验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸素描合成方法依赖大量训练数据，面临数据稀缺和人工成本高的问题。本文旨在开发一种单次学习方法，减少对数据的依赖并提升生成效果。

研究方法: 利用扩散模型优化文本指令，通过梯度优化生成指令用于推理。同时，提出新数据集OS-Sketch，包含400对多样化照片-素描图像，用于单次训练与全面评估。

研究结果: 实验表明，该方法在单次学习场景下能生成逼真且高度一致的素描，相比其他方法更具便利性和广泛适用性。

研究结论: 本文方法在单次人脸素描合成中表现出色，解决了数据稀缺问题，并提供了新的评估基准。

中文摘要: 人脸素描合成是一种将人脸照片转换为素描的技术。现有研究主要依赖于从现有数据集中获取大量照片-素描样本对进行训练。然而，这些大规模判别学习方法面临数据稀缺和高人工成本等问题。一旦训练数据不足，其生成性能会显著下降。本文提出了一种基于扩散模型的单次人脸素描合成方法。我们利用人脸照片-素描图像对优化扩散模型的文本指令，并通过梯度优化生成的指令进行推理。为更准确地模拟现实场景并全面评估方法效果，我们引入了名为OS-Sketch的新基准数据集。该数据集包含400对照片-素描图像，涵盖不同风格的素描和不同背景、年龄、性别、表情、光照等的照片。为进行严格的分布外评估，每次仅选择一对图像进行训练，其余用于推理。大量实验表明，所提方法能在单次场景下将多种照片转换为逼真且高度一致的素描。与其他方法相比，我们的方法更具便利性和广泛适用性。数据集将在以下网址公开：https://github.com/HanWu3125/OS-Sketch

</details>


### [140] [Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards](https://arxiv.org/abs/2506.15684)
**中文标题：Nabla-R2D3：基于2D奖励的高效3D扩散模型对齐方法**

*Qingming Liu,Zhen Liu,Dinghuai Zhang,Kui Jia*

主要分类: cs.GR

摘要简述: 本文提出Nabla-R2D3，一种基于2D奖励的高效强化学习对齐框架，用于优化3D扩散模型，显著提升生成内容的质量和与人类偏好的对齐。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D生成模型（如扩散模型）在生成高质量、逼真的3D内容时，常因无法准确遵循指令或与人类偏好对齐而表现不佳。本文旨在解决这一问题。

研究方法: 基于Nabla-GFlowNet方法，提出Nabla-R2D3框架，通过2D奖励信号对3D扩散模型进行高效对齐和微调，避免传统方法中的收敛困难或奖励滥用问题。

研究结果: 实验表明，Nabla-R2D3在少量微调步骤内即可实现更高的奖励分数和更低的前验遗忘，优于传统基线方法。

研究结论: Nabla-R2D3为3D生成模型的对齐问题提供了一种高效且有效的解决方案，显著提升了生成内容的质量和可控性。

中文摘要: 生成高质量且逼真的3D资产一直是3D视觉和计算机图形学中的长期挑战。尽管最先进的生成模型（如扩散模型）在3D生成方面取得了显著进展，但由于其难以遵循指令、与人类偏好对齐或生成逼真的纹理、几何和物理属性，往往无法达到人工设计内容的水平。本文提出Nabla-R2D3，一种基于2D奖励的高效强化学习对齐框架，用于优化3D原生扩散模型。该方法基于近期提出的Nabla-GFlowNet，通过奖励梯度与评分函数的匹配实现奖励微调。Nabla-R2D3仅需2D奖励信号即可有效调整3D扩散模型。大量实验表明，与难以收敛或存在奖励滥用的传统微调基线相比，Nabla-R2D3在少量微调步骤内即可实现更高的奖励分数和更低的前验遗忘。

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [141] [MODS: Multi-source Observations Conditional Diffusion Model for Meteorological State Downscaling](https://arxiv.org/abs/2506.14798)
**中文标题：MODS：多源观测条件扩散模型用于气象状态降尺度**

*Siwei Tu,Jingyi Xu,Weidong Yang,Lei Bai,Ben Fei*

主要分类: physics.ao-ph

摘要简述: 本文提出了一种多源观测条件扩散模型（MODS），用于气象状态降尺度，通过融合多源卫星和地形数据，显著提高了气象变量降尺度的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有降尺度方法主要依赖单一卫星数据，无法全面捕捉气象变量的变化，导致结果与实际情况偏差较大。因此，需要一种能够充分利用多源数据的方法，以提高降尺度的准确性。

研究方法: MODS是一种条件扩散模型，融合了多颗静止卫星（GridSat）、极轨卫星（AMSU-A、HIRS、MHS）和地形数据（GEBCO）作为条件输入，并通过多源交叉注意力模块将这些特征融合到ERA5再分析数据中。训练时，模型利用再分析数据与多源大气变量之间的反演关系生成更真实的大气状态。

研究结果: 实验结果表明，MODS在将ERA5数据降尺度至6.25公里分辨率时，能够生成更接近真实气象条件的结果，显著提高了降尺度的保真度。

研究结论: MODS通过融合多源数据，显著提升了气象状态降尺度的准确性，为气象预报和模拟提供了更可靠的高分辨率数据支持。

中文摘要: 高分辨率地表气象条件的准确获取对气象预报和模拟至关重要。直接从低分辨率网格场通过空间插值方法获取特定位置的气象值，结果往往与实际条件偏差较大。现有降尺度方法主要依赖静止卫星与ERA5变量的耦合关系作为条件，但仅使用静止卫星的亮温数据无法全面捕捉ERA5图中所有气象变量的变化。为解决这一问题，可以利用更广泛的卫星数据，充分发挥其对各种气象变量的反演效果，从而在不同气象变量上生成更真实的结果。为进一步提高任意位置气象变量降尺度的准确性，我们提出了多源观测降尺度模型（MODS）。它是一种条件扩散模型，融合了多颗静止卫星（GridSat）、极轨卫星（AMSU-A、HIRS、MHS）和地形数据（GEBCO）作为条件输入，并在ERA5再分析数据集上进行了预训练。训练过程中，通过多源交叉注意力模块将不同条件输入的潜在特征分别提取并融合到ERA5图中。通过利用再分析数据与多源大气变量之间的反演关系，MODS生成了更接近真实世界条件的大气状态。在采样过程中，MODS通过引入低分辨率ERA5图和站点级气象数据作为指导，增强了降尺度的一致性。实验结果表明，MODS在将ERA5图降尺度至6.25公里分辨率时具有更高的保真度。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [142] [Comparative Analysis of QNN Architectures for Wind Power Prediction: Feature Maps and Ansatz Configurations](https://arxiv.org/abs/2506.14795)
**中文标题：风能预测中QNN架构的比较分析：特征映射与Ansatz配置**

*Batuhan Hangun,Emine Akpinar,Oguz Altun,Onder Eyecioglu*

主要分类: quant-ph

摘要简述: 本研究通过系统评估量子神经网络（QNNs）在风能预测任务中的表现，展示了其在仅使用四个输入参数时预测准确率高达93%，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 量子机器学习（QML）结合量子计算和机器学习，旨在利用量子力学原理提升传统机器学习性能。然而，由于当前噪声中等规模量子（NISQ）设备的限制，QML的实际优势仍受质疑。本研究通过评估QNNs的性能，验证其在真实任务中的潜力。

研究方法: 研究构建并评估了12种不同的QNN配置，结合两种量子特征映射和六种纠缠策略设计ansatz。实验在风能数据集上进行，比较QNNs与传统方法的预测表现。

研究结果: 实验结果表明，采用Z特征映射的QNNs在仅使用四个输入参数时，风能预测准确率达到93%，显著优于传统方法。

研究结论: QNNs在风能预测任务中表现优异，证明了量子机器学习在实际应用中的潜力，为未来研究提供了方向。

中文摘要: 量子机器学习（QML）是量子计算与机器学习交叉的新兴领域，旨在通过利用量子力学原理（如纠缠和叠加）提升传统机器学习方法。然而，由于当前噪声中等规模量子（NISQ）设备的限制，QML的实际优势仍受质疑。本研究通过系统评估量子神经网络（QNNs）——人工神经网络（ANNs）的量子版本，展示了其相对于传统方法的有效性。我们构建并评估了12种不同的QNN配置，结合两种独特的量子特征映射和六种纠缠策略设计ansatz。在风能数据集上的实验表明，采用Z特征映射的QNNs在仅使用四个输入参数时，风能输出预测准确率高达93%。研究结果表明，QNNs在预测任务中优于传统方法，凸显了QML在实际应用中的潜力。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [143] [Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures](https://arxiv.org/abs/2506.15043)
**中文标题：基于CNN-LSTM-GRU架构的高超音速导弹轨迹高级预测**

*Amir Hossein Baradaran*

主要分类: cs.CR

摘要简述: 本文提出了一种结合CNN、LSTM和GRU的混合深度学习模型，用于高精度预测高超音速导弹的复杂轨迹，为防御策略和拦截技术提供了重要支持。


<details>
  <summary>详细信息</summary>
研究动机: 高超音速导弹因其极高速和机动性对防御系统构成重大挑战，准确预测其轨迹是实施有效拦截的关键。本文旨在通过先进机器学习技术解决这一难题。

研究方法: 采用了一种新型混合深度学习架构，结合了卷积神经网络（CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU），充分利用各架构的优势进行轨迹预测。

研究结果: 该方法能够高精度预测高超音速导弹的复杂轨迹，显著提升了防御系统的预测能力，为导弹拦截技术提供了有力支持。

研究结论: 研究表明，先进的机器学习技术在提升防御系统预测能力方面具有巨大潜力，为未来防御策略的发展提供了新方向。

中文摘要: 国防工业的进步对于确保国家安全至关重要，能够有效应对新兴威胁。其中，高超音速导弹因其极高速和机动性成为重大挑战，准确预测其轨迹是实施有效拦截的关键。本文通过结合卷积神经网络（CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）的新型混合深度学习方法，成功实现了对高超音速导弹复杂轨迹的高精度预测，为防御策略和导弹拦截技术提供了重要贡献。本研究展示了先进机器学习技术在提升防御系统预测能力方面的潜力。

</details>


### [144] [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](https://arxiv.org/abs/2506.15253)
**中文标题：RAS-Eval：真实环境中LLM代理安全性的全面评估基准**

*Yuchuan Fu,Xiaohan Yuan,Dongxia Wang*

主要分类: cs.CR

摘要简述: RAS-Eval是一个全面的安全评估基准，用于测试大型语言模型（LLM）代理在真实环境中的安全性。它包含80个测试用例和3,802个攻击任务，覆盖11个CWE类别，评估结果显示攻击显著降低了代理的任务完成率，并揭示了模型规模与安全能力的关系。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署，缺乏标准化评估基准成为问题。RAS-Eval旨在填补这一空白，为动态环境中的代理提供全面的安全评估框架。

研究方法: RAS-Eval包含80个测试用例和3,802个攻击任务，映射到11个CWE类别，支持JSON、LangGraph和MCP格式的工具执行。研究评估了6种先进LLM在多种场景下的表现。

研究结果: 攻击使代理的任务完成率平均下降36.78%，学术环境中的攻击成功率高达85.65%。研究还发现模型规模与安全能力呈正相关，大模型表现优于小模型。

研究结论: RAS-Eval揭示了真实环境中LLM代理部署的重大安全风险，并为未来安全研究提供了基础框架。代码和数据已开源。

中文摘要: 随着大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署，亟需建立强大的安全框架。针对动态环境中缺乏标准化评估基准的问题，我们提出了RAS-Eval，这是一个支持模拟和真实工具执行的全面安全基准。RAS-Eval包含80个测试用例和3,802个攻击任务，覆盖11个常见弱点枚举（CWE）类别，工具支持JSON、LangGraph和模型上下文协议（MCP）格式。我们评估了6种先进LLM在多种场景下的表现，发现显著的安全漏洞：攻击平均降低了代理任务完成率（TCR）36.78%，在学术环境中的攻击成功率高达85.65%。值得注意的是，安全能力与模型规模相关，大模型表现优于小模型。我们的研究揭示了真实环境中代理部署的重大风险，并为未来安全研究提供了基础框架。代码和数据可在https://github.com/lanzer-tree/RAS-Eval获取。

</details>


### [145] [Evaluation Pipeline for systematically searching for Anomaly Detection Systems](https://arxiv.org/abs/2506.15388)
**中文标题：系统搜索异常检测系统的评估流程**

*Florian Rokohl,Alexander Lehnert,Marc Reichenbach*

主要分类: cs.CR

摘要简述: 本文提出了一种基于硬件的异常检测系统，用于实时检测恶意客户端，并通过FPGA满足实时性和功耗限制，同时通过整体系统评估提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 医疗领域的数字化带来了巨大便利，但也成为攻击者的目标，网络安全问题突出。为了解决网络入侵问题，作者提出了一种实时检测恶意客户端的异常检测系统。

研究方法: 利用FPGA实现硬件上的异常检测系统，以满足实时性和低功耗需求，并通过整体系统评估优化性能。

研究结果: 系统成功实现了实时检测恶意客户端的功能，并通过FPGA满足了实时性和功耗限制，整体性能得到提升。

研究结论: 提出的基于FPGA的异常检测系统能够有效应对医疗数字化中的网络安全挑战，满足实时性和低功耗需求。

中文摘要: 医疗领域的数字化带来了巨大便利，但也使其成为攻击者的目标，网络安全问题突出。为了应对网络入侵者，我们提出了一种基于硬件的异常检测系统，用于实时检测恶意客户端。通过使用FPGA，我们满足了实时性和功耗限制。整体系统性能通过提出的全面系统评估得以实现。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [146] [Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers](https://arxiv.org/abs/2506.14855)
**中文标题：Feedback-MPPI：通过滚动微分实现快速采样MPC——告别低级控制器**

*Tommaso Belvedere,Michael Ziegltrum,Giulio Turrisi,Valerio Modugno*

主要分类: cs.RO

摘要简述: 本文提出Feedback-MPPI（F-MPPI），一种通过局部线性反馈增益增强标准MPPI的新型框架，显著提升复杂机器人任务的控制性能和稳定性，适用于高频实时控制场景。


<details>
  <summary>详细信息</summary>
研究动机: 传统的MPPI方法在实时高频机器人控制中因计算需求大而受限。本文旨在通过引入局部反馈机制，减少计算负担，提升控制性能。

研究方法: F-MPPI通过灵敏度分析计算局部线性反馈增益，结合Riccati反馈思想，实现快速闭环校正，无需每步完全重新优化。

研究结果: 仿真和实际实验表明，F-MPPI在四足机器人动态运动和四旋翼飞行器高机动任务中显著提升控制性能和稳定性。

研究结论: F-MPPI通过局部反馈机制有效解决了MPPI的计算瓶颈，适用于复杂机器人系统的高频实时控制。

中文摘要: 模型预测路径积分控制（MPPI）是一种强大的采样方法，因其处理非线性动力学和非凸成本的灵活性，适用于复杂机器人任务。然而，其在高频实时机器人控制场景中的应用受限于计算需求。本文提出Feedback-MPPI（F-MPPI），一种通过灵敏度分析计算局部线性反馈增益的新型框架，灵感来源于基于梯度的MPC中使用的Riccati反馈。这些增益允许在当前状态附近进行快速闭环校正，而无需每步完全重新优化。我们通过仿真和实际实验验证了F-MPPI的有效性，实验对象包括在不平坦地形上动态运动的四足机器人和通过机载计算执行高机动任务的四旋翼飞行器。结果表明，引入局部反馈显著提升了控制性能和稳定性，适用于复杂机器人系统的鲁棒高频操作。

</details>


### [147] [FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization](https://arxiv.org/abs/2506.14968)
**中文标题：FEAST：一种面向野外个性化的灵活用餐辅助系统**

*Rajat Kumar Jenamani,Tom Silver,Ben Dodson,Shiqin Tong,Anthony Song,Yuting Yang,Ziang Liu,Benjamin Howe,Aimee Whitneck,Tapomayukh Bhattacharjee*

主要分类: cs.RO

摘要简述: 本文提出FEAST系统，一种灵活的用餐辅助系统，旨在满足个性化需求，通过模块化硬件、多样化交互方式和参数化行为树实现适应性、透明性和安全性。


<details>
  <summary>详细信息</summary>
研究动机: 全球数百万人需要用餐辅助，但现有系统难以适应多样化的活动、场景和用户偏好。FEAST旨在解决这一问题，提供个性化的用餐辅助。

研究方法: FEAST采用模块化硬件支持多种功能（如喂食、饮水、擦嘴），提供多种交互方式（如网页界面、头部手势、物理按钮），并通过参数化行为树和大型语言模型实现安全透明的个性化调整。

研究结果: FEAST在透明性和安全性上优于现有基线系统，并通过家庭用户研究和职业治疗师评估验证了其实际适用性，用户成功实现个性化设置。

研究结论: FEAST通过灵活的设计和个性化功能，为用餐辅助提供了有效解决方案，满足多样化需求。

中文摘要: 物理护理机器人有望改善全球数百万需要用餐辅助的人的生活质量。然而，由于部署过程中出现的活动多样性（如进食、饮水、擦嘴）、场景（如社交、看电视）、食物种类和用户偏好，家庭用餐辅助仍具挑战性。本文提出FEAST，一种灵活的用餐辅助系统，可在野外个性化以满足每位护理对象的独特需求。通过与两名社区研究人员合作开发，并基于对多样化护理对象的形成性研究，我们的系统遵循适应性、透明性和安全性三大原则。FEAST通过以下方式体现这些原则：（i）模块化硬件，支持切换辅助喂食、饮水和擦嘴功能；（ii）多样化交互方式，包括网页界面、头部手势和物理按钮，以适应不同功能能力和偏好；（iii）参数化行为树，可通过大型语言模型安全透明地调整。我们基于形成性研究中识别的个性化需求评估系统，证明FEAST提供广泛的透明安全调整，优于仅支持固定定制的先进基线系统。为验证实际适用性，我们对两名护理对象（社区研究人员）进行了家庭用户研究，在三种不同场景下分别提供三餐。我们还通过一位此前不熟悉系统的职业治疗师评估FEAST的生态效度。在所有案例中，用户均成功个性化FEAST以满足其需求和偏好。网站：https://emprise.cs.cornell.edu/feast

</details>


### [148] [Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired](https://arxiv.org/abs/2506.14857)
**中文标题：面向视障人士导航的无人机感知避障研究**

*Suman Raj,Swapnil Padhi,Ruchi Bhoot,Prince Modi,Yogesh Simmhan*

主要分类: cs.RO

摘要简述: 本文提出了一种基于感知的无人机避障系统，用于辅助视障人士在户外城市环境中导航。系统结合局部感知规划和全局GPS地图规划，通过多深度神经网络框架实现无人机和视障人士的避障。实验验证了系统在三种场景下的可行性。


<details>
  <summary>详细信息</summary>
研究动机: 无人机结合机器学习和计算机视觉的自主导航技术已在农业、物流等领域取得进展。本文旨在探索无人机如何辅助视障人士在复杂的户外城市环境中安全导航，解决其出行难题。

研究方法: 提出了一种基于几何问题建模的路径规划系统，包括局部感知规划和全局GPS地图规划。采用多深度神经网络框架，分别处理无人机和视障人士的避障需求。

研究结果: 在校园环境中对无人机-人系统进行了实验，验证了系统在三种场景（人行道行走、停车区附近、拥挤街道）中的避障效果和可行性。

研究结论: 研究表明，基于感知的无人机避障系统能够有效辅助视障人士在城市环境中导航，为未来实际应用提供了技术基础。

中文摘要: 无人机通过搭载传感器并结合机器学习与计算机视觉算法实现自主导航，已广泛应用于农业、物流和灾害管理等领域。本文探讨了无人机在辅助视障人士（VIPs）户外城市环境导航中的应用。具体而言，我们提出了一种基于感知的路径规划系统，结合局部感知规划和基于GPS与地图的全局规划。通过几何建模和多深度神经网络框架，实现了无人机及视障人士的避障功能。在校园环境中对无人机-人系统进行了实验，验证了算法在三种场景（人行道行走、停车区附近、拥挤街道）中的可行性。

</details>


### [149] [Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation](https://arxiv.org/abs/2506.15157)
**中文标题：鲁棒即时策略：利用Student's t回归模型实现机器人操作的鲁棒上下文模仿学习**

*Hanbit Oh,Andrea M. Salcedo-Vázquez,Ixchel G. Ramirez-Alpizar,Yukiyasu Domae*

主要分类: cs.RO

摘要简述: 本文提出了一种名为RIP的鲁棒即时策略算法，利用Student's t回归模型解决基于LLM的即时策略在模仿学习中产生的幻觉轨迹问题，显著提升了任务成功率。


<details>
  <summary>详细信息</summary>
研究动机: 模仿学习（IL）通过观察少量人类演示使机器人自主完成任务。然而，基于大型语言模型（LLM）的即时策略存在幻觉问题，导致轨迹偏离演示，影响可靠性。本文旨在解决这一问题。

研究方法: 提出鲁棒即时策略（RIP）算法，利用Student's t回归模型聚合LLM生成的候选轨迹，忽略异常值（幻觉轨迹），生成鲁棒轨迹。

研究结果: 实验表明，RIP在模拟和真实环境中均显著优于现有IL方法，任务成功率提升至少26%，尤其在低数据量的日常任务中表现突出。

研究结论: RIP通过Student's t回归模型有效解决了LLM即时策略的幻觉问题，提升了模仿学习的可靠性和任务成功率。

中文摘要: 模仿学习（IL）旨在通过观察少量人类演示使机器人自主完成任务。近年来，一种称为上下文IL的变体利用现成的大型语言模型（LLM）作为即时策略，通过少量演示理解上下文以执行新任务，而非显式更新大规模演示的网络模型。然而，其在机器人领域的可靠性受到幻觉问题的影响，例如基于LLM的即时策略偶尔会生成偏离演示的劣质轨迹。为解决这一问题，我们提出了一种新的鲁棒上下文模仿学习算法——鲁棒即时策略（RIP），利用Student's t回归模型对抗即时策略的幻觉轨迹，从而生成可靠轨迹。具体而言，RIP从LLM生成多个候选机器人轨迹以完成任务，并使用Student's t分布聚合它们，有助于忽略异常值（即幻觉），从而生成抗幻觉的鲁棒轨迹。我们在模拟和真实环境中的实验表明，RIP显著优于最先进的IL方法，任务成功率提升至少26%，尤其在低数据量的日常任务中表现突出。视频结果见https://sites.google.com/view/robustinstantpolicy。

</details>


### [150] [MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System](https://arxiv.org/abs/2506.15402)
**中文标题：MCOO-SLAM：一种多相机全景物体SLAM系统**

*Miaoxin Pan,Jinnan Li,Yaowen Zhang,Yi Yang,Yufeng Yue*

主要分类: cs.RO

摘要简述: MCOO-SLAM是一种多相机全景物体SLAM系统，通过环绕视角相机配置和语义几何融合策略，提升复杂户外场景中的物体建模与定位精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有物体级SLAM系统多依赖RGB-D或单目相机，视野狭窄且易受遮挡影响，导致物体建模不准确。MCOO-SLAM旨在通过多相机全景配置解决这些问题。

研究方法: MCOO-SLAM结合点特征与物体级地标，引入语义-几何-时间融合策略以增强多视角物体关联，并设计全景闭环模块支持场景级描述符的视角不变识别。

研究结果: 实验表明，MCOO-SLAM在真实场景中实现了高精度定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强鲁棒性。

研究结论: MCOO-SLAM通过多相机全景配置和语义增强，显著提升了复杂户外场景中的物体建模与定位性能，支持下游推理任务。

中文摘要: 物体级SLAM提供了结构化且语义丰富的环境表示，使其更易理解并适用于高级机器人任务。然而，现有方法多依赖RGB-D传感器或单目视角，视野狭窄且易受遮挡影响，尤其是在大规模或户外环境中。这些限制通常导致系统仅能从有限视角观察物体的部分视图，从而引发建模不准确和数据关联不可靠的问题。本文提出MCOO-SLAM，一种新型多相机全景物体SLAM系统，充分利用环绕视角相机配置，在复杂户外场景中实现鲁棒、一致且语义丰富的建图。该方法整合了点特征与开放词汇语义增强的物体级地标，引入语义-几何-时间融合策略以提升多视角物体关联的鲁棒性，并设计全景闭环模块，利用场景级描述符实现视角不变的地点识别。此外，构建的地图被抽象为分层3D场景图，以支持下游推理任务。大量真实场景实验表明，MCOO-SLAM实现了高精度定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强鲁棒性。

</details>


### [151] [Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos](https://arxiv.org/abs/2506.15680)
**中文标题：基于粒子-网格神经动力学的可变形物体模型学习：从RGB-D视频中**

*Kaifeng Zhang,Baoyu Li,Kris Hauser,Yunzhu Li*

主要分类: cs.RO

摘要简述: 本文提出了一种结合粒子与空间网格的神经动力学框架，用于从RGB-D视频中学习可变形物体的动态模型。该方法通过粒子表示物体形状，空间网格确保空间连续性，并结合高斯渲染生成3D动作视频。实验表明，该模型在稀疏视角下优于现有方法，并能推广到未见过的物体实例。


<details>
  <summary>详细信息</summary>
研究动机: 可变形物体的动态建模因其多样的物理特性和从有限视觉信息中估计状态的困难而具有挑战性。本文旨在通过一种混合表示方法解决这些问题，以实现对形状和材料多样的物体的动态建模。

研究方法: 提出了一种粒子-网格神经动力学框架，其中粒子表示物体形状，空间网格离散化3D空间以确保空间连续性并提升学习效率。结合高斯渲染技术，实现了完全基于学习的可变形物体数字孪生，并生成3D动作视频。

研究结果: 实验表明，该方法能够从稀疏视角的RGB-D视频中学习多种物体（如绳子、布料、毛绒玩具和纸袋）的动态，并在类别级别上推广到未见过的实例。在有限视角场景中，其性能优于现有基于学习和物理的模拟器。

研究结论: 本文提出的粒子-网格神经动力学框架为可变形物体的动态建模提供了一种高效且通用的解决方案，并在模型驱动的规划任务中展示了其实际应用价值。

中文摘要: 由于可变形物体的多样物理特性以及从有限视觉信息中估计状态的困难，其动态建模具有挑战性。我们通过一种结合物体粒子和空间网格的混合表示神经动力学框架来解决这些问题。我们的粒子-网格模型捕捉全局形状和运动信息，同时预测密集粒子运动，从而能够建模形状和材料多样的物体。粒子表示物体形状，而空间网格离散化3D空间以确保空间连续性并提升学习效率。结合高斯渲染技术，我们的框架实现了完全基于学习的可变形物体数字孪生，并生成3D动作视频。通过实验，我们证明了该模型能够从机器人-物体交互的稀疏视角RGB-D记录中学习多种物体（如绳子、布料、毛绒玩具和纸袋）的动态，并在类别级别上推广到未见过的实例。我们的方法在有限视角场景中优于现有基于学习和物理的模拟器。此外，我们还展示了学习模型在模型驱动规划中的实用性，支持多种任务中的目标驱动物体操作。项目页面见https://kywind.github.io/pgnd。

</details>


<div id='stat.OT'></div>

# stat.OT [[Back]](#toc)

### [152] [Next-Generation Conflict Forecasting: Unleashing Predictive Patterns through Spatiotemporal Learning](https://arxiv.org/abs/2506.14817)
**中文标题：下一代冲突预测：通过时空学习释放预测模式**

*Simon P. von der Maase*

主要分类: stat.OT

摘要简述: 本文提出了一种新型神经网络架构，用于高时空分辨率预测三种暴力冲突类型，无需人工特征工程，性能达到最先进水平。


<details>
  <summary>详细信息</summary>
研究动机: 高时空分辨率的暴力冲突预测对研究者和决策者至关重要，但现有方法依赖人工特征且性能有限。

研究方法: 采用基于蒙特卡洛Dropout的LSTM U-Net架构，结合卷积层和循环结构，自动学习时空依赖关系，无需人工特征工程。

研究结果: 模型在预测任务中表现优异，能够生成概率估计和事件规模预测，并量化不确定性，同时具备扩展性。

研究结论: 该模型为早期预警系统和和平建设提供了有力工具，且易于整合额外数据源。

中文摘要: 高时空分辨率的暴力冲突预测仍是研究者和决策者的核心挑战。本研究提出了一种新型神经网络架构，用于预测三种暴力冲突类型（国家间、非国家和单边冲突），在次国家层面（priogrid-month）提前36个月进行预测。模型同时执行分类和回归任务，生成未来事件的概率估计和预期规模。其在所有任务中均达到最先进性能，并能生成近似预测后验分布以量化不确定性。

该架构基于蒙特卡洛Dropout长短期记忆（LSTM）U-Net，结合卷积层捕捉空间依赖性和循环结构建模时间动态。与许多现有方法不同，它无需人工特征工程，仅依赖历史冲突数据。这一设计使模型能够自主学习暴力冲突背后的复杂时空模式。

除了预测性能优异外，该模型还具备高度扩展性：可轻松整合额外数据源并联合预测辅助变量。这些能力使其成为早期预警系统、人道主义响应规划和基于证据的和平建设倡议的有力工具。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [153] [See What I Mean? CUE: A Cognitive Model of Understanding Explanations](https://arxiv.org/abs/2506.14775)
**中文标题：明白我的意思吗？CUE：一种解释理解的认知模型**

*Tobias Labarta,Nhi Hoang,Katharina Weitz,Wojciech Samek,Sebastian Lapuschkin,Leander Weber*

主要分类: cs.HC

摘要简述: 本文提出CUE模型，用于评估解释的认知理解，通过实验发现视觉障碍用户在使用热图解释时表现相似但信心较低，挑战了现有可访问性假设，并支持自适应XAI界面的需求。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习系统在关键决策中的应用增加，对易于理解的解释的需求日益增长。现有可解释AI（XAI）评估多关注技术准确性，而忽略了认知可访问性，尤其是对视觉障碍用户的影响。

研究方法: 提出CUE模型，将解释属性与认知子过程（可读性、可理解性和可解释性）关联。通过实验（N=455）测试不同配色方案（BWR、Cividis、Coolwarm）的热图，分析视觉障碍用户的表现和信心。

研究结果: 实验结果显示，视觉障碍用户的任务表现与普通用户相近，但信心和努力程度较低。专注于可访问性的配色方案（如Cividis）并未缓解差距，甚至有时加剧了问题。

研究结论: 实验结果挑战了关于感知优化的假设，支持自适应XAI界面的需求，并验证了CUE模型的有效性。贡献包括：形式化的认知理解模型、以人为中心的解释属性定义，以及推动可访问性XAI的实证证据。

中文摘要: 随着机器学习系统越来越多地参与关键决策，对人类可理解的解释的需求日益增长。当前可解释AI（XAI）的评估通常优先考虑技术准确性而非认知可访问性，这对用户（尤其是视觉障碍用户）至关重要。我们提出CUE（解释的认知理解模型），将解释属性与认知子过程（可读性、可理解性和可解释性）关联。在一项测试不同配色方案（BWR、Cividis、Coolwarm）热图的研究（N=455）中，发现视觉障碍用户的任务表现相近，但信心和努力程度较低。与预期相反，专注于可访问性的配色方案（如Cividis）并未缓解差距，有时甚至加剧了问题。这些结果挑战了关于感知优化的假设，并支持自适应XAI界面的需求。它们还通过改变解释的可读性影响可理解性验证了CUE模型。我们的贡献包括：（1）形式化的解释理解认知模型，（2）以人为中心的解释属性定义，（3）推动可访问、用户定制XAI的实证证据。

</details>


### [154] [WebXAII: an open-source web framework to study human-XAI interaction](https://arxiv.org/abs/2506.14777)
**中文标题：WebXAII：一个用于研究人类与可解释人工智能交互的开源网络框架**

*Jules Leguy,Pierre-Antoine Jean,Felipe Torres Figueroa,Sébastien Harispe*

主要分类: cs.HC

摘要简述: 本文介绍了WebXAII，一个开源网络框架，旨在促进人类与可解释人工智能（XAI）系统交互的研究。该框架通过模块化设计和结构化配置文件，简化了实验协议的实现，提高了研究的可重用性和可重复性。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能（尤其是机器学习）在各领域的广泛应用，XAI研究迅速发展。然而，现有研究中人类与XAI交互的实验界面多为临时开发且未共享，限制了实验的可重用性和可重复性。WebXAII旨在解决这一问题。

研究方法: 设计并实现了WebXAII，一个基于网络的平台，能够完整呈现实验协议并记录参与者反馈。实验协议通过通用视图和模块的复合架构实现，配置为结构化文件，无需复杂编程即可实现协议。

研究结果: 通过复现一项前沿研究的实验协议，验证了WebXAII的有效性。该框架能够灵活支持多种实验设计，并已在GitHub上开源。

研究结论: WebXAII为人类-XAI交互研究提供了一个灵活、易用的开源工具，显著提升了实验的可重用性和可重复性。

中文摘要: 本文介绍了WebXAII，一个开源网络框架，旨在促进人类与可解释人工智能（XAI）系统交互的研究。随着人工智能（尤其是机器学习）在各领域的广泛应用，XAI领域迅速发展。研究人类与XAI技术交互的研究者通常需要临时开发实验界面，但这些界面通常未与研究成果共享，限制了其可重用性和实验的可重复性。为此，我们设计并实现了WebXAII，这是一个基于网络的平台，能够完整呈现实验协议并记录参与者的反馈。实验协议通过通用视图和模块的复合架构实现，配置为结构化文件，无需复杂编程即可实现协议。通过复现一项前沿研究的实验协议，我们验证了WebXAII的有效性。该框架已在https://github.com/PAJEAN/WebXAII上开源。

</details>


### [155] [Analyzing Character Representation in Media Content using Multimodal Foundation Model: Effectiveness and Trust](https://arxiv.org/abs/2506.14799)
**中文标题：基于多模态基础模型的媒体内容角色表征分析：有效性与信任度**

*Evdoxia Taka,Debadyuti Bhattacharya,Joanne Garde-Hansen,Sanjay Sharma,Tanaya Guha*

主要分类: cs.HC

摘要简述: 本文提出了一种基于多模态基础模型（CLIP）的媒体内容角色表征分析工具，并通过用户研究验证了其有效性和公众信任度。研究发现，用户认为工具总体有用，但对AI生成结果的信任度中等偏低。


<details>
  <summary>详细信息</summary>
研究动机: 尽管现有技术可以量化媒体内容中角色的性别和年龄分布，但缺乏对公众实际需求和信任度的研究。本文旨在填补这一空白，探讨AI生成的角色表征数据对公众的有用性和可信度。

研究方法: 研究基于CLIP模型开发了一种角色表征分析工具，用于量化视觉数据中的性别和年龄分布，并设计了适合普通观众的视觉化展示。随后通过用户研究，评估工具的有用性和AI生成结果的信任度。

研究结果: 用户能够通过视觉化工具理解分析结果，认为工具总体有用，但希望增加更多人口统计类别和角色上下文信息。用户对AI生成的性别和年龄数据的信任度为中等偏低。

研究结论: 研究表明，AI生成的角色表征数据对公众具有一定价值，但需改进视觉化和增加更多细节以提高信任度。工具代码、基准测试和用户研究数据已公开。

中文摘要: 近年来，AI技术的进步使得大规模自动化分析复杂媒体内容成为可能，并能够生成关于角色表征（如性别和年龄）的可操作见解。以往的研究侧重于使用多种机器学习模型从音频/视频/文本中量化角色表征，但未考虑受众的参与。我们提出疑问：即使角色在人口统计维度上的分布数据可用，这些数据对公众的实际价值如何？他们是否信任AI模型生成的数字？本研究通过用户调查探讨这些问题，并提出了一种基于AI的角色表征分析和视觉化工具。该工具基于对比语言图像预训练（CLIP）基础模型，分析视觉屏幕数据以量化角色在年龄和性别维度上的表征。我们还设计了适合普通观众的视觉化展示方式。随后，我们通过用户研究，评估了AI生成结果在精心挑选的电影中的有用性和可信度。研究发现，参与者能够通过视觉化工具理解分析结果，并认为工具“总体有用”。参与者还表示希望增加更多人口统计类别和角色上下文信息的详细视觉化。尽管参与者对基于AI的性别和年龄模型的信任度为中等偏低，但他们并不反对在此背景下使用AI。工具代码、基准测试和用户研究数据可在此处获取：https://anonymous.4open.science/r/Character-Representation-Media-FF7B。

</details>


### [156] [The Hardness of Achieving Impact in AI for Social Impact Research: A Ground-Level View of Challenges & Opportunities](https://arxiv.org/abs/2506.14829)
**中文标题：AI社会影响研究中实现实际影响的困难：挑战与机遇的实地视角**

*Aditya Majumdar,Wenbo Zhang,Kashvi Prawal,Amulya Yadav*

主要分类: cs.HC

摘要简述: 本文探讨了AI社会影响研究（AI4SI）在实现实际社会影响时面临的挑战，包括合作困难、项目难以规模化以及学术认可度不足等问题，并提出了改进策略。


<details>
  <summary>详细信息</summary>
研究动机: 尽管AI社会影响研究（AI4SI）旨在通过AI技术解决联合国可持续发展目标（SDGs）中的社会问题，但实际落地效果不佳。研究者希望通过分析AI4SI项目中的障碍，为未来研究提供参考。

研究方法: 通过半结构化访谈六位领先的AI4SI研究者，并结合作者自身经验，对AI4SI项目中的挑战进行主题分析。

研究结果: 研究发现，AI4SI项目面临结构性、组织性、沟通、协作和运营等多方面障碍，导致项目难以从概念验证阶段过渡到规模化应用。

研究结论: 尽管挑战重重，但通过总结访谈和实践经验，本文提出了可操作的策略，为AI4SI研究者和合作组织提供了实用指南。

中文摘要: 为应对联合国可持续发展目标（SDGs），AI社会影响（AI4SI）项目致力于利用AI技术解决医疗、社会正义等领域的社会问题。然而，尽管AI4SI研究兴趣日益增长，实现实际落地效果仍是一大挑战。例如，寻找并激励愿意共同设计和部署AI解决方案的合作者往往困难重重。即使建立了合作关系，许多AI4SI项目仍停留在概念验证阶段，无法实现规模化应用。此外，AI4SI研究者面临的独特挑战在更广泛的AI社区中并未得到充分认可，这类研究有时被视为纯应用性工作，不符合核心AI领域对创新性的传统要求。本文通过诊断阻碍AI4SI合作实现实际影响的多种因素，揭示了AI4SI研究中的多样化挑战。基于对六位领先AI4SI研究者的半结构化访谈，并结合作者自身的研究经验，本文探讨了开发和部署具有社会影响力的AI解决方案时面临的日常困难。通过主题分析，我们发现结构性、组织性、沟通、协作和运营问题是部署的主要障碍。尽管没有简单的解决方案，但我们从访谈和自身工作中提炼了最佳实践和可操作策略，希望本文能为AI4SI研究者和合作组织提供实用参考，以更有效地参与社会影响力AI合作。

</details>


### [157] [Insights Informed Generative AI for Design: Incorporating Real-world Data for Text-to-Image Output](https://arxiv.org/abs/2506.15008)
**中文标题：基于真实世界数据的生成式AI设计洞察：为文本到图像输出融入可持续性指标**

*Richa Gupta,Alexander Htet Kyaw*

主要分类: cs.HC

摘要简述: 本文提出了一种结合DALL-E 3与材料数据集的新方法，为AI生成的设计图像添加可持续性指标和材料使用数据，帮助设计师评估环境影响并优化设计决策。


<details>
  <summary>详细信息</summary>
研究动机: 尽管生成式AI（如文本到图像模型）能快速将设计概念转化为视觉图像，但这些图像通常缺乏可操作的数据（如可持续性指标）。本文旨在通过整合材料数据集，为AI生成的设计提供实用的环境数据支持。

研究方法: 研究提出了一种新流程：首先使用DALL-E 3生成室内设计图像，随后通过后处理模块识别图像中的主要材料，并从材料字典中匹配其二氧化碳当量（CO2e）值。通过三项用户测试（无可持续性提示、有可持续性目标提示、包含CO2e数据的提示）验证系统效果。

研究结果: 测试表明，引入可持续性指标（尤其是CO2e数据）能帮助设计师做出更环保的决策，但也可能导致决策疲劳和满意度下降。尽管如此，多数参与者在第三项测试中表示会将可持续性原则纳入工作流程。

研究结论: 研究强调了在设计自由与实用约束之间平衡的重要性，为AI辅助建筑设计提供了数据驱动的整体解决方案。

中文摘要: 生成式AI（尤其是文本到图像模型）通过简单的文本提示将设计概念快速转化为视觉图像，彻底改变了室内建筑设计领域。然而，这些AI生成的图像虽然视觉上吸引人，却往往缺乏对设计师有用的可操作数据。本研究提出了一种新流程，将DALL-E 3与材料数据集结合，为AI生成的设计图像补充可持续性指标和材料使用数据。模型生成室内设计图像后，后处理模块会识别图像中的前十大材料，并从通用材料字典中匹配其二氧化碳当量（CO2e）值。这种方法使设计师能够立即评估环境影响并优化设计提示。我们通过三项用户测试评估系统效果：（1）在生成AI提示前未提及可持续性；（2）在提示前向用户传达可持续性目标；（3）在生成AI输出中包含定量CO2e数据的同时传达可持续性目标。定性与定量分析表明，第三项测试中引入可持续性指标有助于更明智的设计决策，但也可能引发决策疲劳并降低整体满意度。尽管如此，多数参与者在第三项测试中表示会将可持续性原则纳入工作流程，凸显了整合指标对引导更生态负责实践的潜力。我们的发现展示了在设计自由与实用约束之间平衡的重要性，为AI辅助建筑设计提供了数据驱动的整体解决方案。

</details>


### [158] [Mapping Caregiver Needs to AI Chatbot Design: Strengths and Gaps in Mental Health Support for Alzheimer's and Dementia Caregivers](https://arxiv.org/abs/2506.15047)
**中文标题：将照顾者需求映射到AI聊天机器人设计：阿尔茨海默病和痴呆症照顾者心理健康支持的优势与不足**

*Jiayue Melissa Shi,Dong Whi Yoo,Keran Wang,Violeta J. Rodriguez,Ravi Karkar,Koustuv Saha*

主要分类: cs.HC

摘要简述: 本文探讨了AI聊天机器人Carey如何满足阿尔茨海默病及相关痴呆症（AD/ADRD）照顾者的心理健康需求，揭示了其优势与不足，并提出了设计建议。


<details>
  <summary>详细信息</summary>
研究动机: AD/ADRD照顾者面临巨大的情感和实际挑战，心理健康风险高。尽管生成式AI（如大型语言模型）为心理健康支持提供了新机会，但照顾者对这些技术的看法和参与度尚不明确。本研究旨在填补这一空白。

研究方法: 研究开发了基于GPT-4o的聊天机器人Carey，并通过16名家庭照顾者的半结构化访谈和情景驱动互动，采用归纳编码和反思性主题分析，系统分析了照顾者的需求和期望。

研究结果: 研究揭示了照顾者的六大需求主题：即时信息获取、情感支持、安全披露空间、危机管理、个性化服务和数据隐私。同时，指出了AI聊天机器人在满足这些需求时的优势与不足。

研究结论: 研究为设计更主动、可信且以照顾者为中心的AI系统提供了理论和实践指导，以更好地支持AD/ADRD照顾者的心理健康需求。

中文摘要: 阿尔茨海默病及相关痴呆症（AD/ADRD）的家庭照顾者面临巨大的情感和实际挑战，使其更容易产生压力、焦虑和抑郁。尽管生成式AI（尤其是大型语言模型）为心理健康支持提供了新机会，但照顾者对这些技术的看法和参与度尚不明确。为填补这一空白，我们开发了基于GPT-4o的聊天机器人Carey，旨在为AD/ADRD照顾者提供信息和情感支持。通过Carey作为技术探针，我们对16名家庭照顾者进行了半结构化访谈，基于常见照顾压力情景的互动。通过归纳编码和反思性主题分析，我们系统揭示了照顾者的需求和期望，涵盖六大主题：即时信息获取、情感支持、安全披露空间、危机管理、个性化服务和数据隐私。针对每个主题，我们还识别了照顾者需求与担忧之间的微妙矛盾。我们提出了照顾者需求、AI聊天机器人优势、不足及设计建议的映射。研究结果为设计更主动、可信且以照顾者为中心的AI系统提供了理论和实践指导，以更好地支持AD/ADRD照顾者不断变化的心理健康需求。

</details>


### [159] [Accessible Gesture-Driven Augmented Reality Interaction System](https://arxiv.org/abs/2506.15189)
**中文标题：可访问的手势驱动增强现实交互系统**

*Yikan Wang*

主要分类: cs.HC

摘要简述: 本文提出了一种基于手势的增强现实（AR）交互系统，利用深度学习识别手势，并通过联邦学习和强化学习优化界面，显著提升了运动障碍用户的交互效率和满意度。


<details>
  <summary>详细信息</summary>
研究动机: 当前增强现实（AR）系统依赖精确输入方法，对运动障碍或灵活性受限的用户不友好。本研究旨在通过手势识别技术提升AR的可访问性。

研究方法: 系统结合视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，采用联邦学习保护用户隐私，并通过强化学习优化界面布局和交互模式。

研究结果: 实验表明，该系统比基线AR系统在任务完成效率上提升20%，用户满意度提高25%，显著改善了运动障碍用户的体验。

研究结论: 该研究通过深度学习与联邦学习的结合，为AR系统提供了可扩展且隐私保护的交互方案，提升了AR的可访问性。

中文摘要: 增强现实（AR）提供了沉浸式交互，但由于依赖精确输入方法，对运动障碍或灵活性受限的用户仍不友好。本研究提出了一种基于手势的AR交互系统，利用深度学习从可穿戴传感器和摄像头中识别手势，并根据用户能力调整界面。系统采用视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，并通过联邦学习实现跨用户隐私保护的模型训练。强化学习用于优化菜单布局和交互模式等界面元素。实验表明，与基线AR系统相比，该系统为运动障碍用户提升了20%的任务完成效率和25%的用户满意度。该方法增强了AR的可访问性和可扩展性。关键词：深度学习、联邦学习、手势识别、增强现实、可访问性、人机交互

</details>


### [160] [Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI](https://arxiv.org/abs/2506.15468)
**中文标题：通过Metropolis-Hastings交互实现人类与AI的共创学习**

*Ryota Okumura,Tadahiro Taniguchi,Akira Taniguchi,Yoshinobu Hagiwara*

主要分类: cs.HC

摘要简述: 本文提出了一种新型的‘共创学习’范式，通过人类与AI的交互，整合双方的部分感知信息和知识，构建共享的外部表征。实验基于Metropolis-Hastings命名游戏（MHNG），结果显示MH-based AI显著提升了分类准确性，并促进了共享符号系统的形成。


<details>
  <summary>详细信息</summary>
研究动机: 传统AI教学依赖于单向知识传递，难以整合不同模态的信息。本文旨在探索人类与AI如何通过交互动态整合感知经验，实现共创学习。

研究方法: 采用基于Metropolis-Hastings命名游戏（MHNG）的分散式贝叶斯推理机制，设计了一个在线实验，69名参与者与三种计算机代理（MH-based、总是接受或总是拒绝）在部分可观察性下进行联合注意力命名游戏（JA-NG）。

研究结果: 实验表明，与MH-based代理交互的人类-AI对显著提高了分类准确性，并更倾向于形成共享符号系统。此外，人类接受行为与MH衍生的接受概率高度一致。

研究结论: 研究首次提供了人类-AI通过MHNG交互实现共创学习的实证证据，为动态对齐感知经验的共生AI系统开辟了新途径。

中文摘要: 我们提出了一种新型的‘共创学习’范式，即人类与AI（生物与人工代理）通过相互整合部分感知信息和知识，构建共享的外部表征，这一过程被我们解释为符号涌现。与传统基于单向知识传递的AI教学不同，这种方法解决了整合不同模态信息的挑战。我们通过基于Metropolis-Hastings命名游戏（MHNG）的人类-AI交互模型进行了实证测试。在一项在线实验中，69名参与者与三种计算机代理（MH-based、总是接受或总是拒绝）在部分可观察性下进行了联合注意力命名游戏（JA-NG）。结果显示，与MH-based代理交互的人类-AI对显著提高了分类准确性，并更倾向于形成共享符号系统。此外，人类接受行为与MH衍生的接受概率高度一致。这些发现首次为人类-AI通过MHNG交互实现共创学习提供了实证证据，为动态对齐感知经验的共生AI系统开辟了新途径。

</details>


### [161] [Optimizing Web-Based AI Query Retrieval with GPT Integration in LangChain A CoT-Enhanced Prompt Engineering Approach](https://arxiv.org/abs/2506.15512)
**中文标题：基于LangChain框架的GPT集成优化网络AI查询检索：一种CoT增强的提示工程方法**

*Wenqi Guan,Yang Fang*

主要分类: cs.HC

摘要简述: 本文提出了一种通过LangChain框架集成GPT模型的新方法，结合CoT推理和提示工程，优化远程学习资源检索，提升结果的精确性和相关性，以满足学生的个性化需求。


<details>
  <summary>详细信息</summary>
研究动机: 当前远程学习资源的检索缺乏深度和上下文理解，无法满足学生对复杂查询的需求。本文旨在通过集成GPT模型和LangChain框架，结合CoT推理和提示工程，提升检索结果的全面性和相关性。

研究方法: 在LangChain框架中集成GPT模型，利用CoT（Chain-of-Thought）推理和提示工程技术，设计了一种更直观和高效的检索系统，以增强检索结果的精确性和上下文相关性。

研究结果: 实验表明，该方法在用户满意度和学习效果上优于传统的LLMs（大语言模型），能够提供更全面和符合学生需求的资源与解释。

研究结论: 通过LangChain框架集成GPT模型并结合CoT推理和提示工程，显著提升了远程学习资源检索的质量和效率，为个性化学习提供了有力支持。

中文摘要: 大型语言模型为远程学习学生及其他教育活动带来了革命性变化。然而，当前远程学习资源的检索缺乏深度和上下文理解，难以满足学生对复杂查询的需求。本文提出了一种新颖的方法，通过在LangChain框架中集成基于GPT的模型，结合CoT推理和提示工程技术，优化远程学习资源的检索。我们设计的系统更直观高效，重点提升检索结果的精确性和相关性，以返回全面且上下文丰富的解释和资源，满足学生的个性化需求。我们还评估了该方法与传统LLMs的效果，结果显示其在用户满意度和学习效果上均有显著提升。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [162] [Identifying economic narratives in large text corpora -- An integrated approach using Large Language Models](https://arxiv.org/abs/2506.15041)
**中文标题：从大型文本语料库中识别经济叙事——一种基于大型语言模型的综合方法**

*Tobias Schmidt,Kai-Robin Lange,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch*

主要分类: econ.GN

摘要简述: 本文探讨了利用大型语言模型（LLMs）从文本中提取经济叙事的有效性，并与传统方法进行比较。研究发现，GPT-4o能够提取结构化经济叙事，但在处理复杂文档时仍不及专家水平。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，经济叙事的研究兴趣增加，但现有方法（如BERT）缺乏深层语义理解，难以区分经济叙事提取与传统任务（如语义角色标注）。本文旨在评估LLMs在此任务中的潜力。

研究方法: 研究分析了《华尔街日报》和《纽约时报》关于通胀的新闻文章，采用严格的叙事定义，并将GPT-4o的输出与专家标注的黄金标准叙事进行比较。

研究结果: 结果表明，GPT-4o能够提取有效的结构化经济叙事，但在处理复杂文档和叙事时仍落后于专家水平。

研究结论: 尽管LLMs在经济叙事提取中表现出潜力，但仍需改进以匹配专家水平。本文为未来经济学和社会科学中LLMs的应用提供了指导。

中文摘要: 近年来，人们对经济叙事的兴趣日益增长，用于从文本中提取此类叙事的流程也越来越多。这些流程通常采用最先进的自然语言处理技术（如BERT）来完成这一任务。尽管这些模型在叙事提取的基础语言操作上表现有效，但缺乏区分经济叙事提取与传统任务（如语义角色标注）所需的深层语义理解。我们通过分析《华尔街日报》和《纽约时报》关于通胀的新闻文章语料库，评估了大型语言模型（LLMs）的优势。我们采用严格的叙事定义，并将GPT-4o的输出与专家标注的黄金标准叙事进行比较。结果表明，GPT-4o能够以结构化格式提取有效的经济叙事，但在处理复杂文档和叙事时仍不及专家水平。鉴于LLMs在经济研究中的新颖性，我们还为未来经济学和社会科学中类似目标的研究提供了指导。

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [163] [Intrinsic and Extrinsic Organized Attention: Softmax Invariance and Network Sparsity](https://arxiv.org/abs/2506.15541)
**中文标题：内在与外在组织注意力：Softmax不变性与网络稀疏性**

*Oluwadamilola Fasina,Ruben V. C. Pohle,Pei-Chun Su,Ronald R. Coifman*

主要分类: math.NA

摘要简述: 本文研究了Transformer中自注意力机制的内在（注意力头内部）和外在（注意力头之间）结构，证明了自注意力机制对softmax激活的不变性，并通过分层组织方法分析了网络结构的稀疏性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索Transformer自注意力机制的结构特性，尤其是softmax激活的不变性和网络稀疏性，以提升模型的可解释性和实际应用（如模型剪枝）。

研究方法: 方法包括：1) 使用拟微分理论证明自注意力机制对softmax的不变性；2) 通过分层组织方法构建查询、键和注意力头轴的层次分区树，分析网络3-张量的结构；3) 通过可视化和量化分析展示网络稀疏性。

研究结果: 结果表明：1) 自注意力机制对softmax具有不变性；2) 分层组织方法能有效揭示网络结构的稀疏性；3) 这些发现可用于模型剪枝和网络架构比较。

研究结论: 结论指出，研究为自注意力机制的可解释性分析提供了理论支持，并展示了其在模型剪枝和网络优化中的实际应用潜力。

中文摘要: 本文研究了Transformer中自注意力机制的内在（注意力头内部）和外在（注意力头之间）结构。通过拟微分理论，我们证明了自注意力机制对softmax激活的不变性（并通过计算实例支持），这种不变性依赖于注意力头的内在组织。此外，我们利用现有的张量分层组织方法，通过构建查询、键和注意力头轴的层次分区树，分析了网络3-张量的结构。这种组织方式具有重要意义，因为它允许在几何结构上高效执行常见的信号处理任务，而网络3-张量在此几何结构中表现出规律性。我们通过可视化注意力头的层次组织和扩散图嵌入定性展示了这一点，并通过分析网络稀疏性（基于查询、键和注意力头轴的双Haar和三Haar基的扩展系数）定量验证了结果。为了展示理论和方法的实用性，我们提供了视觉和语言Transformer的计算实例。这些发现的启示有两点：(1) 理论上支持了可解释性分析的后续步骤，并可实际应用于下游可解释性任务；(2) 网络3-张量的组织可用于模型剪枝（基于网络稀疏性）和网络架构比较等实际应用。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [164] [Advancing Loss Functions in Recommender Systems: A Comparative Study with a Rényi Divergence-Based Solution](https://arxiv.org/abs/2506.15120)
**中文标题：推荐系统中损失函数的优化研究：基于Rényi散度的解决方案比较**

*Shengjia Zhang,Jiawei Chen,Changdong Li,Sheng Zhou,Qihao Shi,Yan Feng,Chun Chen,Can Wang*

主要分类: cs.IR

摘要简述: 本文研究了推荐系统中损失函数的优化，比较了Softmax损失（SL）和余弦对比损失（CCL），发现两者虽各有优势但存在局限性。为此，提出了一种基于Rényi散度的新损失函数DrRL，有效结合了SL和CCL的优点，并通过实验验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 推荐系统中的损失函数对模型优化至关重要，但现有方法如SL和CCL虽有效，却各有不足（如SL对假阴性样本敏感，CCL数据利用率低）。本文旨在通过深入分析这些损失函数，提出一种更优的解决方案。

研究方法: 本文首先分析了SL和CCL的理论联系与差异，发现它们均可视为传统损失函数结合分布鲁棒优化（DRO）的变体。随后提出DrRL，利用Rényi散度在DRO优化中泛化SL和CCL，结合两者优势。

研究结果: 实验表明，DrRL在推荐准确性和鲁棒性上均优于SL和CCL，有效解决了SL对假阴性样本的敏感性和CCL数据利用率低的问题。

研究结论: DrRL作为一种新型损失函数，成功结合了SL和CCL的优点，显著提升了推荐系统的性能，为损失函数设计提供了新思路。

中文摘要: 损失函数在优化推荐模型中起着关键作用。在众多损失函数中，Softmax损失（SL）和余弦对比损失（CCL）尤为有效。它们的理论联系与差异值得深入探讨。本研究对这些损失函数进行了全面分析，得出以下重要结论：1）共同优势——两者均可视为传统损失函数结合分布鲁棒优化（DRO）的增强版本，提升了分布偏移的鲁棒性；2）各自局限——由于在DRO优化中使用了不同的分布距离度量，SL对假阴性样本高度敏感，而CCL存在数据利用率低的问题。为解决这些问题，本研究提出了一种新损失函数DrRL，通过Rényi散度在DRO优化中泛化SL和CCL。DrRL结合了SL和CCL的优势结构，并能有效缓解其局限性。大量实验验证了DrRL在推荐准确性和鲁棒性上的优越性。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [165] [Scaling Intelligence: Designing Data Centers for Next-Gen Language Models](https://arxiv.org/abs/2506.15006)
**中文标题：扩展智能：为下一代语言模型设计数据中心**

*Jesmin Jahan Tithi,Hanjiang Wu,Avishaii Abuhatzera,Fabrizio Petrini*

主要分类: cs.AR

摘要简述: 本文提出了一种针对下一代语言模型的数据中心设计框架，通过联合优化计算、存储和网络架构，显著提升了大型语言模型的性能和可扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（如GPT-4）参数规模的爆炸性增长（1.8万亿参数），传统数据中心架构难以满足其可扩展性、效率和成本效益的需求，亟需重新设计。

研究方法: 研究提出了一种全面的联合设计框架，探索了FLOPS、HBM带宽与容量、多种网络拓扑（如两层与FullFlat光网络）、扩展域规模以及并行化策略。重点评估了FullFlat网络架构，并分析了计算与通信重叠、硬件加速集体操作、更大扩展域和内存容量对性能的影响。

研究结果: FullFlat网络架构显著提升了节点间的高带宽、低延迟连接，优化了模型FLOPS利用率（MFU）和整体吞吐量。性能建模工具的预测误差在10%以内，验证了其有效性。

研究结论: 研究为设计支持万亿参数模型的高效AI数据中心提供了实用路线图，降低了优化复杂性，并支持AI能力的持续快速演进。

中文摘要: 大型语言模型（如拥有1.8万亿参数的GPT-4）的爆炸性增长，要求对数据中心架构进行彻底重新设计，以确保可扩展性、效率和成本效益。我们的工作提供了一个全面的联合设计框架，共同探索了FLOPS、HBM带宽与容量、多种网络拓扑（两层与FullFlat光网络）、扩展域规模以及LLM中常用的并行化/优化策略。我们引入并评估了FullFlat网络架构，该架构提供了所有节点间统一的高带宽、低延迟连接，并展示了其对性能和可扩展性的变革性影响。通过详细的敏感性分析，我们量化了计算与通信重叠、利用硬件加速集体操作、更广扩展域和更大内存容量的优势。我们的研究涵盖了稀疏（专家混合）和基于密集Transformer的LLM，揭示了系统设计选择如何影响模型FLOPS利用率（MFU = 每令牌模型FLOPS × 每秒观察令牌数 / 硬件峰值FLOPS）和整体吞吐量。为联合设计研究，我们扩展并验证了一种性能建模工具，能够将LLM运行时间预测误差控制在10%以内。我们的发现为设计能够高效支持万亿参数模型、降低优化复杂性并持续推动AI能力快速演进的AI数据中心提供了可操作的见解和实用路线图。

</details>


### [166] [J3DAI: A tiny DNN-Based Edge AI Accelerator for 3D-Stacked CMOS Image Sensor](https://arxiv.org/abs/2506.15316)
**中文标题：J3DAI：一种基于微型DNN的边缘AI加速器，用于3D堆叠CMOS图像传感器**

*Benoit Tain,Raphael Millet,Romain Lemaire,Michal Szczepanski,Laurent Alacoque,Emmanuel Pluchart,Sylvain Choisnet,Rohit Prasad,Jerome Chossat,Pascal Pierunek,Pascal Vivet,Sebastien Thuries*

主要分类: cs.AR

摘要简述: 本文介绍了J3DAI，一种基于深度神经网络的微型硬件加速器，专为3层3D堆叠CMOS图像传感器设计，集成了AI芯片，支持高效的图像分类和分割任务。重点展示了其性能-功耗-面积特性，并通过Aidge软件框架优化部署。实验证明其在边缘AI领域的多功能性和高效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着边缘AI的重要性日益增长，如何在资源受限的硬件上实现实时、低延迟和高效能的AI处理成为关键挑战。J3DAI旨在通过微型DNN加速器解决这一问题，为CMOS图像传感器提供先进的边缘AI能力。

研究方法: J3DAI采用3层3D堆叠CMOS图像传感器，集成DNN加速器，利用Aidge软件框架支持主机处理器和加速器的编程。通过后训练量化技术，显著减少内存占用和计算复杂度。

研究结果: 实验结果表明，J3DAI在边缘AI任务中表现出多功能性和高效性，能够处理从简单到计算密集型的任务，同时具备优异的性能-功耗-面积特性。

研究结论: J3DAI展示了在边缘AI领域的潜力，未来将进一步优化架构并探索新应用，以充分发挥其能力。这种创新设计将在实时、低延迟和高效能的边缘AI处理中发挥重要作用。

中文摘要: 本文介绍了J3DAI，一种基于深度神经网络的微型硬件加速器，专为3层3D堆叠CMOS图像传感器设计，集成了人工智能（AI）芯片和DNN加速器。该加速器旨在高效执行图像分类和分割等神经网络任务。本文重点介绍了J3DAI的数字系统，突出了其性能-功耗-面积（PPA）特性，并展示了其在CMOS图像传感器上的先进边缘AI能力。为支持硬件，我们使用了Aidge综合软件框架，该框架支持主机处理器和DNN加速器的编程。Aidge支持后训练量化，显著减少了内存占用和计算复杂度，这对于在资源受限的硬件（如J3DAI）上部署模型至关重要。实验结果表明，这种创新设计在边缘AI领域具有多功能性和高效性，能够处理从简单到计算密集型的任务。未来工作将集中于进一步优化架构并探索新应用，以充分发挥J3DAI的潜力。随着边缘AI的重要性日益增长，J3DAI等创新将在实现实时、低延迟和高效能的边缘AI处理中发挥关键作用。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [167] [Collaborative Interest-aware Graph Learning for Group Identification](https://arxiv.org/abs/2506.14826)
**中文标题：基于协同兴趣感知图学习的群组识别**

*Rui Zhao,Beihong Jin,Beibei Li,Yiyuan Zheng*

主要分类: cs.SI

摘要简述: 本文提出CI4GI模型，通过双层次兴趣增强和负样本优化，显著提升群组识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着社交媒体的普及，用户参与在线群组活动的需求增加，但现有群组识别方法未能充分建模用户群体层次和项目层次兴趣的协同演化关系，导致性能受限。

研究方法: 提出CI4GI模型，设计兴趣增强策略补充用户项目层次兴趣，并通过兴趣分布距离优化负样本识别，减少跨层次兴趣对齐中的干扰。

研究结果: 在三个真实数据集上的实验表明，CI4GI显著优于现有最先进模型。

研究结论: CI4GI通过建模双层次兴趣的协同演化关系，有效提升了群组识别的准确性和鲁棒性。

中文摘要: 随着社交媒体的普及，越来越多的用户参与在线社交平台的群组活动，这引发了群组识别（GI）的需求，即向用户推荐群组。我们发现用户同时受到群体层次和项目层次兴趣的影响，且这两种兴趣具有协同演化关系：加入群组会扩展用户的项目兴趣，进而促使用户加入新群组，最终两种兴趣趋于动态对齐。然而，现有GI方法未能充分建模这种协同演化关系，忽略了群体层次兴趣对项目层次兴趣的增强作用，且在跨层次兴趣对齐时受到假负样本的干扰。为了充分建模用户双层次兴趣的协同演化关系，我们提出CI4GI，一种用于群组识别的协同兴趣感知模型。具体而言，我们设计了一种兴趣增强策略，从用户已加入群组交互的项目中识别额外兴趣，作为项目层次兴趣的补充。此外，我们利用两个用户兴趣分布之间的距离优化负样本识别，减少跨层次兴趣对齐中假负样本的干扰。在三个真实数据集上的实验结果表明，CI4GI显著优于现有最先进模型。

</details>


### [168] [Detecting Narrative Shifts through Persistent Structures: A Topological Analysis of Media Discourse](https://arxiv.org/abs/2506.14836)
**中文标题：通过持久结构检测叙事转变：媒体话语的拓扑分析**

*Mark M. Bailey,Mark I. Heiligman*

主要分类: cs.SI

摘要简述: 本研究提出了一种基于拓扑学的框架，通过持久同调分析媒体叙事中的结构变化，检测重大事件如何重塑公共话语。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发一种无监督方法，检测全球事件对公共话语的根本性影响，无需依赖特定事件的先验知识。

研究方法: 利用国际新闻文章构建每日名词短语共现图，通过Vietoris-Rips过滤生成持久图，计算Wasserstein距离和持久熵以捕捉语义变化。

研究结果: 结果显示，重大事件与H0（连通分量）和H1（环路）的急剧峰值相关，表明叙事结构的突然重组。交叉相关分析揭示了H0变化先于H1的典型滞后模式。

研究结论: 持久同调为检测公共话语的转折点和方向性变化提供了数学上严谨的无监督方法，适用于危机、抗议和信息冲击的实时分析。

中文摘要: 如何检测全球事件如何从根本上重塑公共话语？本研究提出了一种拓扑框架，利用持久同调识别媒体叙事中的结构变化。通过分析包括俄罗斯入侵乌克兰（2022年2月）、乔治·弗洛伊德谋杀案（2020年5月）、美国国会大厦暴乱（2021年1月）和哈马斯领导的以色列入侵（2023年10月）在内的国际新闻文章，我们构建了每日名词短语共现图以追踪话语演变。每个图通过Vietoris-Rips过滤嵌入并转化为持久图。随后，我们计算Wasserstein距离和持久熵，以捕捉语义中断和叙事波动。结果显示，重大地缘政治和社会事件与H0（连通分量）和H1（环路）的急剧峰值相关，表明叙事结构和连贯性的突然重组。交叉相关分析揭示了H0变化先于H1的典型滞后模式，表明语义变化是自下而上的级联。俄罗斯入侵乌克兰期间例外，H1熵领先于H0，可能反映了自上而下的叙事框架调整。持久熵进一步区分了紧密聚焦和分散的叙事模式。这些发现表明，持久同调提供了一种数学上严谨的无监督方法，用于检测公共注意力的转折点和方向性变化，无需依赖特定事件的先验知识。这种拓扑方法通过实时检测危机、抗议和信息冲击期间的语义重构，推动了计算社会科学的发展。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [169] [DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition](https://arxiv.org/abs/2207.01732)
**中文标题：Deformer：通过可变形局部模式与全局上下文耦合实现鲁棒的端到端语音识别**

*Jiamin Xie,John H. L. Hansen*

主要分类: eess.AS

摘要简述: 本文提出了一种名为Deformer的新型架构，通过可变形卷积替代传统CNN中的固定卷积核，结合全局注意力机制，显著提升了端到端语音识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统CNN在语音识别中依赖对称且固定的卷积核，限制了其对局部特征的适应性。本文探讨了非对称卷积核的潜力，旨在通过自适应局部特征提升与注意力机制的耦合效果。

研究方法: 在Conformer架构中，将深度可分离卷积替换为可变形卷积（Deformer），通过动态调整卷积核的偏移量，捕捉更灵活的局部特征，并结合全局注意力机制优化特征关联。

研究结果: 实验表明，Deformer在WSJ eval92数据集上，无需语言模型时相对WER提升5.6%，使用语言模型时提升6.4%，同时可视化分析揭示了特征关联的增强和网络深度对信息变化的影响。

研究结论: Deformer通过结合可变形局部特征与全局上下文，显著提升了语音识别的鲁棒性和性能，为未来研究提供了新的方向。

中文摘要: 卷积神经网络（CNN）通过利用局部时频模式显著提升了语音识别性能，但传统CNN操作假设这些模式出现在对称且固定的卷积核中。这引发了一个问题：非对称卷积核会如何？本研究展示了自适应视角可以发现与注意力机制耦合更好的局部特征。我们将Conformer架构中的深度可分离CNN替换为可变形版本，称为“Deformer”。通过分析性能最佳的模型，我们可视化了Deformer学习的局部感受野和全局注意力图，并展示了其在话语级别上增强的特征关联。对学习到的卷积核偏移量的统计分析揭示了特征信息随网络深度的变化。最终，在编码器中仅替换一半层的情况下，Deformer在WSJ eval92测试集上，无需语言模型时相对WER提升了5.6%，使用语言模型时提升了6.4%。

</details>


### [170] [Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model](https://arxiv.org/abs/2309.13018)
**中文标题：动态ASR路径：一种自适应掩码方法用于高效剪枝多语言ASR模型**

*Jiamin Xie,Ke Li,Jinxi Guo,Andros Tjandra,Yuan Shangguan,Leda Sari,Chunyang Wu,Junteng Jia,Jay Mahadeokar,Ozlem Kalinli*

主要分类: eess.AS

摘要简述: 本文提出了一种自适应掩码方法（Dynamic ASR Pathways），用于高效剪枝多语言ASR模型，动态调整子网络结构，优于现有剪枝方法，并减少语言特定剪枝需求。


<details>
  <summary>详细信息</summary>
研究动机: 多语言自动语音识别（ASR）模型的剪枝通常需要多次剪枝和重新训练，效率低下。本文旨在通过自适应掩码方法，动态调整子网络结构，避免固定子网络结构的过早决策，从而提升剪枝效率。

研究方法: 提出Dynamic ASR Pathways方法，采用自适应掩码策略，在两种场景下剪枝多语言ASR模型：生成稀疏单语言模型或稀疏多语言模型。动态调整子网络结构，避免固定子网络的局限性。

研究结果: 实验表明，该方法在生成稀疏单语言模型时优于现有剪枝方法，并能通过不同子网络初始化联合发现和训练更好的多语言模型子网络（路径），减少语言特定剪枝需求。

研究结论: Dynamic ASR Pathways通过动态调整子网络结构，显著提升了多语言ASR模型的剪枝效率，同时减少了语言特定剪枝的复杂性。

中文摘要: 神经网络剪枝为压缩多语言自动语音识别（ASR）模型提供了一种有效方法，且性能损失最小。然而，传统方法需要对每种语言进行多轮剪枝和重新训练。本文提出了一种自适应掩码方法，用于高效剪枝多语言ASR模型，分别生成稀疏单语言模型或稀疏多语言模型（称为Dynamic ASR Pathways）。该方法动态调整子网络，避免对固定子网络结构的过早决策。实验表明，在生成稀疏单语言模型时，该方法优于现有剪枝方法。此外，Dynamic ASR Pathways通过不同子网络初始化联合发现并训练更好的单多语言模型子网络（路径），从而减少语言特定剪枝的需求。

</details>


### [171] [MixRep: Hidden Representation Mixup for Low-Resource Speech Recognition](https://arxiv.org/abs/2310.18450)
**中文标题：MixRep：低资源语音识别的隐藏表示混合方法**

*Jiamin Xie,John H. L. Hansen*

主要分类: eess.AS

摘要简述: MixRep是一种针对低资源语音识别的数据增强策略，通过混合隐藏表示的特征维度提升模型性能，实验表明其在WSJ和SWB数据集上优于其他正则化方法。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语音识别（ASR）面临数据不足的挑战，传统数据增强方法如SpecAugment效果有限。MixRep旨在通过混合隐藏表示的特征维度，进一步提升模型性能。

研究方法: MixRep提出了一种基于mixup的数据增强策略，通过混合神经网络中隐藏表示的特征维度，适用于声学特征输入和每层输出。此外，结合时间轴上的正则化方法，进一步优化模型。

研究结果: 在WSJ数据集和SWB子集上的实验表明，MixRep相比SpecAugment基线，在eval92和eval'2000的Callhome部分分别实现了6.5%和6.7%的相对词错误率（WER）降低。

研究结论: MixRep作为一种简单有效的低资源ASR数据增强方法，显著提升了模型性能，尤其在混合隐藏表示和时间轴正则化的结合下表现更优。

中文摘要: 本文提出MixRep，一种基于mixup的简单有效的数据增强策略，用于低资源语音识别（ASR）。MixRep通过混合神经网络中隐藏表示的特征维度，可应用于声学特征输入和每层输出，从而推广了之前的MixSpeech方法。此外，我们提出将mixup与时间轴上的正则化结合，实验证明二者具有互补性。MixRep被应用于基于联合CTC损失的E2E LAS架构的Conformer编码器。我们在WSJ数据集和SWB子集（涵盖朗读和电话会话语音）上进行实验。结果表明，MixRep在低资源ASR中始终优于其他正则化方法。与强大的SpecAugment基线相比，MixRep在eval92集和eval'2000集的Callhome部分分别实现了+6.5%和+6.7%的相对词错误率（WER）降低。

</details>


### [172] [Factorized RVQ-GAN For Disentangled Speech Tokenization](https://arxiv.org/abs/2506.15456)
**中文标题：解耦语音标记化的因子化RVQ-GAN**

*Sameer Khurana,Dominik Klement,Antoine Laurent,Dominik Bobos,Juraj Novosad,Peter Gazdik,Ellen Zhang,Zili Huang,Amir Hussein,Ricard Marxer,Yoshiki Masuyama,Ryo Aihara,Chiori Hori,Francois G. Germain,Gordon Wichern,Jonathan Le Roux*

主要分类: eess.AS

摘要简述: 提出了一种分层音频编解码器（HAC），通过单一模型将语音分解为声学、音素和词汇三个层次，利用知识蒸馏目标实现解耦的语音标记化，性能优于单层次基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有语音编解码器通常仅关注单一层次（如声学或音素），缺乏对语音多层次的统一建模。HAC旨在通过分层分解和知识蒸馏，实现语音的声学、音素和词汇层次解耦，为下游任务提供更丰富的离散语音表示。

研究方法: HAC采用分层瓶颈结构，将语音分解为声学、音素和词汇三个层次。通过两种知识蒸馏目标：1）基于预训练语音编码器（HuBERT）的音素层次结构；2）基于文本编码器（LaBSE）的词汇线索，实现层次解耦。

研究结果: 实验表明，HAC生成的标记集具有解耦性：一组标记与音素对齐，另一组捕获词汇语义。定量评估显示，HAC在解耦和重建质量上优于单层次基线，同时保留了语音自然度和可解释的语音信息。

研究结论: HAC作为一种统一的离散语音表示，能够桥接声学细节和词汇语义，为下游语音生成和理解任务提供了潜力。

中文摘要: 我们提出了分层音频编解码器（HAC），这是一种统一的神经语音编解码器，通过单一模型将其瓶颈分解为声学、音素和词汇三个层次。HAC利用两种知识蒸馏目标：一种来自预训练语音编码器（HuBERT）用于音素层次结构，另一种来自基于文本的编码器（LaBSE）用于词汇线索。在英语和多语言数据上的实验表明，HAC的因子化瓶颈生成了解耦的标记集：一组与音素对齐，另一组捕获词汇级语义。定量评估证实，HAC标记保留了自然度并提供了可解释的语言信息，在解耦和重建质量上均优于单层次基线。这些发现凸显了HAC作为统一离散语音表示的潜力，为下游语音生成和理解任务桥接了声学细节和词汇意义。

</details>


### [173] [Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition](https://arxiv.org/abs/2506.14973)
**中文标题：方向性思维：用于多说话者定向语音识别的语音大语言模型**

*Jiamin Xie,Ju Lin,Yiteng Huang,Tyler Vuong,Zhaojiang Lin,Zhaojun Yang,Peng Su,Prashant Rawat,Sangeeta Srivastava,Ming Sun,Florian Metze*

主要分类: eess.AS

摘要简述: 本文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制。通过S-DOT和CDDA技术增强模型对方向性的理解，实验表明该方法在语音识别和声源定位任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLM）在语音识别方面表现出色，但其对多通道音频和空间线索的理解能力尚未充分研究。本文旨在填补这一空白，探索如何利用智能眼镜的麦克风阵列实现定向语音处理。

研究方法: 本文提出了两种关键技术：序列化定向输出训练（S-DOT）和对比性方向数据增强（CDDA），以增强模型对方向性的理解。directional-SpeechLlama利用这些技术结合麦克风阵列，实现定向语音识别和声源定位。

研究结果: 实验结果表明，directional-SpeechLlama能够有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中均表现出色。

研究结论: 本文提出的directional-SpeechLlama方法通过结合S-DOT和CDDA技术，成功实现了定向语音处理和声源定位，为多通道音频理解提供了新的解决方案。

中文摘要: 近期研究表明，通过音频编码提示大型语言模型（LLM）可实现有效的语音识别能力。然而，语音LLM对多通道音频和空间线索的理解能力仍是一个研究较少的领域。本文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制。为增强模型对方向性的理解，我们提出了两种关键技术：序列化定向输出训练（S-DOT）和对比性方向数据增强（CDDA）。实验结果表明，我们提出的directional-SpeechLlama能够有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中均表现出色。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [174] [Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection](https://arxiv.org/abs/2506.14933)
**中文标题：先解释后信任：基于大语言模型增强的图分析方法用于加密货币异常检测**

*Adriana Watson*

主要分类: cs.CE

摘要简述: 本文提出了一种基于大语言模型（LLM）增强的图分析方法，用于加密货币异常检测，旨在通过先解释后信任的方式提高检测的可信度。


<details>
  <summary>详细信息</summary>
研究动机: 随着去中心化金融（DeFi）和加密货币的快速发展，金融犯罪问题日益严重。由于技术新颖性，传统方法难以有效检测和起诉犯罪，因此需要自动化工具来应对这一挑战。

研究方法: 论文提出了一种结合大语言模型（LLM）和图分析的方法，通过LLM生成解释性内容，增强基于图的异常检测的可信度和可解释性。

研究结果: 实验表明，该方法能够有效识别加密货币交易中的异常行为，并通过LLM生成的解释提高了检测结果的可信度。

研究结论: 研究证明了LLM增强的图分析方法在加密货币异常检测中的有效性，为未来金融犯罪检测提供了新思路。

中文摘要: 近年来，去中心化金融（DeFi）社区在加密货币爱好者的推动下迅速发展，这些爱好者对新市场的巨大潜力充满兴趣。加密货币的流行带来了金融犯罪的新时代。不幸的是，技术的新颖性使得抓捕和起诉罪犯尤为困难。因此，有必要实施与政策相关的自动化检测工具，以应对加密货币领域日益增长的犯罪问题。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [175] [PFMBench: Protein Foundation Model Benchmark](https://arxiv.org/abs/2506.14796)
**中文标题：PFMBench：蛋白质基础模型基准测试**

*Zhangyang Gao,Hao Wang,Cheng Tan,Chenrui Xu,Mengdi Liu,Bozhen Hu,Linlin Chao,Xiaoming Zhang,Stan Z. Li*

主要分类: q-bio.BM

摘要简述: 本研究提出了PFMBench，一个全面的蛋白质基础模型基准测试，涵盖38个任务，旨在填补领域内缺乏公平评估和深入理解的空白。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，蛋白质基础模型研究快速发展，但缺乏统一的评估标准，导致难以全面比较不同模型的性能和局限性。

研究方法: 通过17个前沿模型在38个任务上的数百次实验，PFMBench揭示了任务间的内在关联，并提供了标准化的评估流程。

研究结果: PFMBench识别了表现最佳的模型，并展示了任务之间的相关性，为未来研究提供了重要参考。

研究结论: PFMBench为蛋白质基础模型的评估提供了全面工具，有助于推动领域内的标准化和进一步发展。

中文摘要: 本研究探讨了蛋白质基础模型研究的现状与未来方向。尽管近期进展显著，但该领域缺乏一个全面的基准测试以实现公平评估和深入理解。自ESM-1B以来，众多蛋白质基础模型涌现，各自采用独特的数据集和方法。然而，评估通常局限于针对特定模型的有限任务，阻碍了对模型泛化能力和局限性的全面认识。具体而言，研究人员难以理解任务间的关系、评估现有模型的表现，以及确定开发新基础模型的标准。为填补这一空白，我们提出了PFMBench，一个涵盖蛋白质科学8大领域38个任务的全面基准测试。通过对17个前沿模型在38个任务上的数百次实验，PFMBench揭示了任务间的内在关联，识别了表现最佳的模型，并提供了标准化的评估流程。代码已发布于GitHub。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [176] [MedSyn: Enhancing Diagnostics with Human-AI Collaboration](https://arxiv.org/abs/2506.14774)
**中文标题：MedSyn：通过人机协作增强诊断能力**

*Burcu Sayin,Ipek Baris Schlicht,Ngoc Vo Hong,Sara Allievi,Jacopo Staiano,Pasquale Minervini,Andrea Passerini*

主要分类: cs.LG

摘要简述: 本文提出了一种名为MedSyn的人机协作框架，通过多步骤交互对话优化临床诊断和治疗决策，评估开源LLM作为医生助手的潜力，结果显示其具有实际应用前景。


<details>
  <summary>详细信息</summary>
研究动机: 临床决策复杂且易受认知偏差、信息不完整和病例模糊性影响。现有LLM工具多为一次性或有限交互，难以应对实际医疗实践的复杂性，因此需要一种动态交互的人机协作框架。

研究方法: 提出MedSyn框架，医生与LLM通过多步骤交互对话共同优化诊断和治疗决策，LLM可提供替代视角，医生可质疑其建议。通过模拟医生-LLM互动评估开源LLM的潜力。

研究结果: 实验表明，开源LLM作为医生助手在现实世界中具有应用潜力，能够支持动态交互和决策优化。

研究结论: MedSyn框架展示了人机协作在临床决策中的潜力，未来将通过真实医生互动进一步验证其对诊断准确性和患者结局的改进效果。

中文摘要: 临床决策具有内在复杂性，常受认知偏差、信息不完整和病例模糊性影响。大型语言模型（LLM）作为临床决策支持工具展现出潜力，但其典型的一次性或有限交互使用方式可能忽略了实际医疗实践的复杂性。本研究提出了一种混合人机框架MedSyn，医生与LLM通过多步骤交互对话共同优化诊断和治疗决策。与静态决策支持工具不同，MedSyn支持动态交流，医生可质疑LLM的建议，而LLM则提供替代视角。通过模拟医生-LLM互动，我们评估了开源LLM作为医生助手的潜力。结果显示，开源LLM在现实世界中作为医生助手具有前景。未来工作将涉及真实医生互动，进一步验证MedSyn在诊断准确性和患者结局方面的实用性。

</details>


### [177] [PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series](https://arxiv.org/abs/2506.14786)
**中文标题：PIPE：基于物理信息的位置编码用于卫星图像与时间序列的对齐**

*Haobo Li,Eunseo Jung,Zixin Chen,Zhaowei Wang,Yueya Wang,Huamin Qu,Alexis Kai Hon Lau*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PIPE的轻量级方法，通过物理信息位置编码将物理信息嵌入视觉语言模型，显著提升了多模态对齐和预测精度，尤其在台风强度预测上优于现有方法12%。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态方法主要关注文本数据，忽略了视觉数据（如卫星图像）中的物理信息（如时空背景），导致模型难以有效捕捉这些信息。PIPE旨在填补这一空白。

研究方法: PIPE包含两项创新：(1) 物理信息位置索引方案，将物理信息映射为位置ID；(2) 变频率位置编码机制，将物理变量的频率信息和令牌顺序编码到嵌入空间中。

研究结果: 在最大开源卫星图像数据集上的实验表明，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测精度提升12%。

研究结论: PIPE通过嵌入物理信息和顺序信息，显著提升了多模态对齐和预测精度，为卫星图像与时间序列对齐提供了有效解决方案。

中文摘要: 多模态时间序列预测在气候科学等领域具有基础性作用，例如利用卫星图像和数值数据预测台风。然而，现有方法主要依赖文本数据辅助预测，忽略了视觉数据中的物理信息（如卫星图像的时空背景）。为解决这一问题，我们提出了物理信息位置编码（PIPE），一种轻量级方法，将物理信息嵌入视觉语言模型（VLMs）。PIPE包含两项关键创新：(1) 物理信息位置索引方案，将物理信息映射为位置ID；(2) 变频率位置编码机制，将物理变量的频率信息和令牌顺序编码到嵌入空间中。通过保留物理信息和顺序信息，PIPE显著提升了多模态对齐和预测精度。在最大开源卫星图像数据集上的实验表明，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测精度提升12%。代码详见补充材料。

</details>


### [178] [Topology-Aware and Highly Generalizable Deep Reinforcement Learning for Efficient Retrieval in Multi-Deep Storage Systems](https://arxiv.org/abs/2506.14787)
**中文标题：基于拓扑感知和高度泛化的深度强化学习在多深度存储系统中的高效检索**

*Funing Li,Yuan Tian,Ruben Noortwyck,Jifeng Zhou,Liming Kuang,Robert Schulz*

主要分类: cs.LG

摘要简述: 本文提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题，通过图神经网络和Transformer模型结合的系统拓扑表示，显著优化了检索延迟。


<details>
  <summary>详细信息</summary>
研究动机: 现代物流环境中，快速配送服务的扩展对高密度存储系统提出了更高要求。多深度自主车辆存储与检索系统（AVS/RS）虽能提高存储密度，但因通道堵塞问题面临检索效率挑战。传统方法将同质物品存储于单一通道，限制了系统的灵活性和适应性。

研究方法: 研究提出了一种结合图神经网络（GNN）和Transformer模型的深度强化学习框架。GNN用于编码物品属性和局部拓扑结构，Transformer则将嵌入映射为全局优先级分配，从而优化检索延迟。

研究结果: 大量数值实验表明，所提出的神经网络架构优于启发式方法，训练后的智能体在优化检索延迟方面表现出色，且能够泛化到不同布局的存储系统。

研究结论: 该研究为多深度存储系统中的检索问题提供了一种高效且通用的解决方案，通过深度强化学习和拓扑感知技术显著提升了系统性能。

中文摘要: 在现代工业和物流环境中，快速配送服务的迅速扩展对兼具高效性和高密度的存储系统提出了更高需求。多深度自主车辆存储与检索系统（AVS/RS）为实现更高存储密度提供了可行方案，但在检索操作中因通道堵塞问题面临重大挑战。传统方法通过将同质物品存储于单一通道来缓解此问题，但限制了系统的灵活性和适应性。本研究提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题。每个物品关联一个特定截止日期，目标是最小化总延迟。为有效捕捉系统拓扑，我们引入了一种基于图的状态表示，整合了物品属性和多深度仓库的局部拓扑结构。为处理此表示，我们设计了一种结合图神经网络（GNN）和Transformer模型的新型神经网络架构。GNN将拓扑和物品特定信息编码为可直接访问物品的嵌入，而Transformer将这些嵌入映射为全局优先级分配。Transformer的强大泛化能力进一步使我们的方法适用于不同布局的存储系统。大量数值实验（包括与启发式方法的比较）证明了所提神经网络架构的优越性以及训练智能体在优化检索延迟方面的有效性。

</details>


### [179] [Assembly of Experts: Linear-time construction of the Chimera LLM variants with emergent and adaptable behaviors](https://arxiv.org/abs/2506.14794)
**中文标题：专家组装：线性时间构建具有突现和自适应行为的Chimera LLM变体**

*Henrik Klagges,Robert Dahlke,Fabian Klemm,Benjamin Merkel,Daniel Klingmann,David A. Reiss,Dan Zecha*

主要分类: cs.LG

摘要简述: 论文提出了一种名为“专家组装”（AoE）的线性时间构建方法，用于从现有的混合专家（Mixture-of-Experts）父模型中生成能力强大的子模型变体。通过插值模型权重张量，可以增强或抑制父模型的语义特征。生成的子模型表现出渐变的特性变化和突现的行为特征，且几乎全部功能正常。实验构建的DeepSeek R1T“Chimera”模型结合了父模型的优点，实现了接近父模型智能水平的同时，显著减少了输出令牌数量。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）预训练中计算单个8位权重需要消耗10^13-10^15 FLOPs，成本极高且效率低下。为了更高效地利用预训练模型的巨大投资，研究团队开发了“专家组装”方法，旨在快速生成功能强大的子模型变体。

研究方法: 论文提出“专家组装”（AoE）方法，通过线性时间插值父模型的权重张量，生成子模型变体。该方法允许单独调整权重张量，从而增强或抑制父模型的语义特征。生成的子模型表现出渐变的特性变化和突现的行为特征。

研究结果: 实验构建的DeepSeek R1T“Chimera”模型结合了DeepSeek的V3-0324和R1模型变体，仅继承了R1的路由专家张量，但智能水平接近R1，同时输出令牌数量减少约40%，速度接近V3。该模型无需微调或蒸馏，表现出紧凑且有序的推理能力。

研究结论: “专家组装”方法能够高效生成功能强大的子模型变体，显著降低了模型构建的计算成本。生成的模型不仅继承了父模型的优点，还表现出突现的行为特征，为模型优化提供了新思路。

中文摘要: 在大型语言模型（LLM）预训练中，计算单个8位权重需要消耗10^13-10^15 FLOPs，成本极高且效率低下。为了更高效地利用预训练模型的巨大投资，我们开发了“专家组装”（AoE）构建方法，能够在线性时间内从现有的混合专家（Mixture-of-Experts）父模型中生成能力强大的子模型变体。通过单独插值模型权重张量，可以增强或抑制父模型的语义特征。
  通过调整从父模型中提取的权重比例，我们观察到AoE子模型的部分特性逐渐变化，而其他行为特征则出现突变。令人惊讶的是，几乎所有生成的模型都功能正常且能力强大，这使得模型空间的搜索变得简单直接。
  我们构建了DeepSeek R1T“Chimera”，这是一个671B的开放权重混合模型，结合了DeepSeek的V3-0324和R1模型变体。子模型仅继承了R1的路由专家张量，但仍实现了接近R1的智能水平。同时，其输出令牌数量减少了约40%，速度接近V3。该模型无需任何微调或蒸馏，表现出令人惊讶的紧凑且有序的推理能力，优于其父模型。

</details>


### [180] [Bound by semanticity: universal laws governing the generalization-identification tradeoff](https://arxiv.org/abs/2506.14797)
**中文标题：语义性约束：泛化与识别权衡的普适性规律**

*Marco Nurisso,Jesseba Fernando,Raj Deshpande,Alan Perotti,Raja Marjieh,Steven M. Frankland,Richard L. Lewis,Taylor W. Webb,Declan Campbell,Francesco Vaccarino,Jonathan D. Cohen,Giovanni Petri*

主要分类: cs.LG

摘要简述: 本文揭示了智能系统在泛化与识别之间的根本性权衡，证明了有限语义分辨率下泛化与识别的普适性规律，并通过实验验证了这些规律在复杂模型中的适用性。


<details>
  <summary>详细信息</summary>
研究动机: 智能系统需要同时具备结构化表示以支持泛化能力，以及选择性表示以保留输入特征。然而，这种权衡存在根本性限制，本文旨在揭示这一限制的普适性规律。

研究方法: 通过理论分析，推导了有限语义分辨率下泛化概率和识别概率的闭式表达式，并扩展到噪声和非均匀空间。同时，通过训练简单的ReLU网络和复杂模型（如卷积神经网络和视觉语言模型）验证理论预测。

研究结果: 研究发现，多输入处理能力会急剧下降至1/n，且泛化概率存在非单调最优值。实验表明，理论预测与模型学习过程中的实际表现高度吻合，证明了有限分辨率相似性是普遍的信息约束。

研究结论: 本文提供了泛化与识别权衡的精确理论，阐明了语义分辨率如何影响深度网络和大脑的表征能力，揭示了这一权衡的普适性本质。

中文摘要: 智能系统需要同时具备结构化表示以支持广泛泛化，以及选择性表示以保留输入特征。我们揭示了这一权衡的根本性限制：对于任何输入间相似性随有限语义分辨率ε衰减的模型，我们推导了其正确泛化概率p_S和识别概率p_I的闭式表达式，并将其固定为一个与输入空间几何无关的普适Pareto前沿。将分析扩展到噪声和非均匀空间以及n>2的输入时，预测了多输入处理能力的急剧1/n崩溃和p_S的非单调最优值。通过端到端训练的最小ReLU网络重现了这些规律：学习过程中自组织分辨率边界，且实际(p_S,p_I)轨迹与线性衰减相似性的理论曲线高度吻合。最后，我们在两种更复杂场景（卷积神经网络和先进视觉语言模型）中验证了相同的限制，证明有限分辨率相似性是一种根本性信息约束，而非简单模型假象。这些结果为泛化与识别权衡提供了精确理论，并阐明了语义分辨率如何塑造深度网络和大脑的表征能力。

</details>


### [181] [ss-Mamba: Semantic-Spline Selective State-Space Model](https://arxiv.org/abs/2506.14802)
**中文标题：ss-Mamba：基于语义样条的选择性状态空间模型**

*Zuochen Ye*

主要分类: cs.LG

摘要简述: 本文提出ss-Mamba模型，通过结合语义感知嵌入和自适应样条时间编码，改进了时间序列预测，显著降低了计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer模型在时间序列预测中计算复杂度高，且难以捕捉复杂的时间模式。ss-Mamba旨在提供一种高效且性能相当的替代方案。

研究方法: ss-Mamba采用选择性状态空间模型（Mamba），结合语义索引嵌入和基于样条的KAN网络，动态捕捉季节性和非平稳时间效应。

研究结果: 实验表明，ss-Mamba在准确性、鲁棒性和可解释性上优于传统Transformer模型，同时计算复杂度从二次降至线性。

研究结论: ss-Mamba是一种高效且多功能的时间序列预测模型，为传统Transformer提供了有力替代。

中文摘要: 我们提出了ss-Mamba，这是一种新颖的基础模型，通过将语义感知嵌入和自适应样条时间编码整合到选择性状态空间建模框架中，改进了时间序列预测。基于Transformer架构的最新成功，ss-Mamba采用Mamba选择性状态空间模型作为高效替代方案，在显著降低计算复杂度（从二次降至线性时间）的同时实现可比性能。语义索引嵌入通过预训练语言模型初始化，允许通过有意义的语义先验有效泛化到未见过的序列。此外，基于样条的Kolmogorov-Arnold网络（KAN）动态且可解释地捕捉复杂季节性和非平稳时间效应，提供了对传统时间特征编码的强大增强。广泛的实验评估证实，ss-Mamba在准确性、鲁棒性和可解释性方面表现优异，展示了其作为传统基于Transformer的时间序列预测模型的高效多功能替代方案的能力。

</details>


### [182] [Training with Confidence: Catching Silent Errors in Deep Learning Training with Automated Proactive Checks](https://arxiv.org/abs/2506.14813)
**中文标题：训练有保障：通过自动化主动检查捕捉深度学习训练中的静默错误**

*Yuxuan Jiang,Ziming Zhou,Boyu Xu,Beijie Liu,Runhui Xu,Peng Huang*

主要分类: cs.LG

摘要简述: 本文提出TRAINCHECK框架，通过自动推断深度学习训练中的不变性，主动检测并修复训练过程中的静默错误，成功检测出18/20真实错误并发现6个未知库错误。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习训练过程复杂，静默错误难以检测和诊断，亟需一种主动检查方法以提升训练可靠性。

研究方法: TRAINCHECK框架自动推断深度学习训练中的不变性，利用这些不变性在训练过程中主动检测静默错误，并提供调试支持。

研究结果: 在复现的20个真实静默错误中，TRAINCHECK成功检测出18个，并在单个训练迭代内完成；同时发现6个导致静默错误的流行训练库未知漏洞。

研究结论: TRAINCHECK通过主动检查方法有效提升深度学习训练的可靠性，能够快速检测和修复静默错误，具有实际应用价值。

中文摘要: 深度学习（DL）模型的训练过程复杂，容易产生难以检测和诊断的静默错误。本文提出TRAINCHECK框架，采用主动检查方法解决静默训练错误。TRAINCHECK自动推断针对深度学习训练的不变性，并利用这些不变性在训练过程中主动检测静默错误，同时提供调试帮助。为评估TRAINCHECK，我们复现了20个具有不同根源的真实静默训练错误。TRAINCHECK成功在单个训练迭代内检测出18个错误，并发现6个导致静默错误的流行训练库未知漏洞。

</details>


### [183] [Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints](https://arxiv.org/abs/2506.14821)
**中文标题：强化视觉语言模型在资源约束下使用工具进行详细视觉推理**

*Sunil Kumar,Bowen Zhao,Leo Dirac,Paulina Varshavskaya*

主要分类: cs.LG

摘要简述: 本文提出了一种通过强化学习（GRPO）训练小规模视觉语言模型（VLMs）使用外部工具（如放大）的方法，以解决资源受限下的详细视觉推理问题，并在视觉问答任务中表现优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型模型在推理能力上取得了显著进展，但视觉语言模型（VLMs）在资源受限时仍难以进行详细的视觉推理。本文旨在通过引入外部工具和优化训练方法，提升小规模模型在此类任务中的表现。

研究方法: 采用Group Relative Policy Optimization（GRPO）训练小规模VLMs，结合简单的奖励结构、简化的工具调用接口、为工具调用结果分配额外标记，以及侧重视觉难度高的训练数据混合。

研究结果: 与规模相近的基线模型相比，该方法通过外部工具获取的详细视觉信息，在部分视觉问答（VQA）任务中表现更优。

研究结论: 通过GRPO学习和优化工具使用策略，小规模VLMs在资源受限条件下能够更高效地进行详细视觉推理，为实际应用提供了可行方案。

中文摘要: 尽管近年来大型模型的推理能力取得了巨大进步，但视觉语言模型（VLMs）在资源受限时仍难以进行详细的视觉推理。为解决这一问题，我们借鉴了Deepseek-r1等方法，通过Group Relative Policy Optimization（GRPO）训练小规模模型，使其能够使用放大等外部工具。该方法结合了GRPO学习、简单的奖励结构、简化的工具调用接口、为工具调用结果分配额外标记，以及侧重视觉难度高的训练数据混合，取得了显著效果。与规模相近的基线模型相比，我们的方法通过外部工具获取的详细视觉信息，在部分视觉问答（VQA）任务中表现更优。

</details>


### [184] [FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models](https://arxiv.org/abs/2506.14824)
**中文标题：FedNano：面向预训练多模态大型语言模型的轻量级联邦调优**

*Yao Zhang,Hewei Gao,Haokun Chen,Weiguo Li,Yunpu Ma,Volker Tresp*

主要分类: cs.LG

摘要简述: FedNano提出了一种轻量级联邦学习框架，通过在服务器端集中大型语言模型（LLM），并在客户端引入轻量级模块NanoEdge，显著降低了计算和通信开销，同时解决了异构数据和隐私问题。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大型语言模型（MLLMs）在现实场景中面临分布式数据和隐私要求的挑战，而传统联邦学习（FL）方法因计算和通信成本高、客户端能力有限等问题难以直接应用。

研究方法: FedNano框架将LLM集中在服务器端，客户端仅部署轻量级模块NanoEdge，包含模态特定编码器、连接器和低秩适应的NanoAdapters，大幅减少存储和通信开销。

研究结果: 实验表明，FedNano显著优于现有FL基线，客户端存储减少95%，通信开销仅为模型参数的0.01%，同时支持异构数据和隐私保护。

研究结论: FedNano填补了MLLM规模与FL可行性之间的鸿沟，为可扩展的分散式多模态AI系统提供了解决方案。

中文摘要: 多模态大型语言模型（MLLMs）在多模态推理和跨模态检索等任务中表现出色，但由于分布式多模态数据和严格的隐私要求，其实际部署面临挑战。联邦学习（FL）通过无需集中数据的协作模型训练提供了一种解决方案。然而，为MLLMs实现FL存在重大挑战，包括高计算需求、有限的客户端能力、巨大的通信成本和异构客户端数据。现有FL方法假设客户端部署完整模型，这一假设因MLLMs的巨大规模和通信需求而失效。为解决这些限制，我们提出FedNano，首个将LLM集中在服务器端并引入轻量级模块NanoEdge的FL框架。NanoEdge采用模态特定编码器、连接器和低秩适应的可训练NanoAdapters。这一设计无需在客户端部署LLM，将客户端存储减少95%，并将通信开销限制为仅模型参数的0.01%。通过仅传输紧凑的NanoAdapter更新，FedNano处理异构客户端数据和资源限制，同时保护隐私。实验表明，FedNano优于现有FL基线，填补了MLLM规模与FL可行性之间的鸿沟，支持可扩展的分散式多模态AI系统。

</details>


### [185] [Optimization of bi-directional gated loop cell based on multi-head attention mechanism for SSD health state classification model](https://arxiv.org/abs/2506.14830)
**中文标题：基于多头注意力机制的双向门控循环单元优化及其在SSD健康状态分类模型中的应用**

*Zhizhao Wen,Ruoxin Zhang,Chao Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种结合多头注意力机制的BiGRU-MHA混合模型，用于提升SSD健康状态分类的准确性和稳定性，实验结果显示模型具有优异的泛化能力和分类性能。


<details>
  <summary>详细信息</summary>
研究动机: SSD健康状态预测对数据可靠性至关重要，传统模型存在泛化瓶颈，本研究旨在通过结合时序特征提取和关键信息聚焦能力，提出一种更优的技术方案。

研究方法: 模型结合了BiGRU网络的双向时序建模优势和多头注意力机制，动态分配特征权重，增强对关键健康指标的敏感性。

研究结果: 实验结果显示，模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，性能差距仅0.26%，AUC值为0.94，表现出优异的泛化能力和分类性能。

研究结论: 该模型为SSD健康预测提供了新技术方案，解决了传统模型的泛化问题，具有实际应用价值，可显著降低数据丢失风险并优化维护成本。

中文摘要: 针对SSD健康状态预测在数据可靠性保障中的关键作用，本研究提出了一种结合多头注意力机制的BiGRU-MHA混合模型，以提升存储设备健康分类的准确性和稳定性。该模型创新性地整合了时序特征提取和关键信息聚焦能力。具体而言，它利用BiGRU网络的双向时序建模优势，捕捉SSD退化特征的前后依赖关系；同时，多头注意力机制动态分配特征权重，提升模型对关键健康指标的敏感性。实验结果表明，所提模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，性能差距仅为0.26%，表现出优异的泛化能力。进一步通过受试者工作特征（ROC）曲线分析，测试集的曲线下面积（AUC）为0.94，证实了模型的稳健二分类性能。本研究不仅为SSD健康预测提供了新的技术途径，还解决了传统模型的泛化瓶颈，为工业级存储系统的预防性维护提供了可验证的实用方法。结果表明，该模型可通过提供早期故障预警显著降低数据丢失风险，并帮助优化维护成本，为云计算数据中心和边缘存储环境构建可靠存储系统提供智能决策支持。

</details>


### [186] [ETS: Open Vocabulary Electroencephalography-To-Text Decoding and Sentiment Classification](https://arxiv.org/abs/2506.14783)
**中文标题：ETS：开放词汇脑电图到文本解码及情感分类**

*Mohamed Masry,Mohamed Amen,Mohamed Elzyat,Mohamed Hamed,Norhan Magdy,Maram Khaled*

主要分类: cs.LG

摘要简述: 本文提出ETS框架，结合脑电图（EEG）与眼动追踪数据，解决了开放词汇文本生成和情感分类任务，显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法在开放词汇场景下因噪声和变异性表现不佳，本文旨在通过结合EEG与眼动数据提升开放词汇文本解码和情感分类的性能。

研究方法: ETS框架整合EEG与同步眼动追踪数据，用于开放词汇文本生成和情感分类任务，通过多模态数据提升模型表现。

研究结果: 模型在EEG到文本解码任务中BLEU和Rouge分数表现优异，情感分类任务F1分数提升10%，且能适应多来源数据。

研究结论: ETS框架展示了在多源数据和高性能开放词汇EEG到文本系统中的潜力，为未来研究提供了新方向。

中文摘要: 利用非侵入性脑电图（EEG）从大脑活动中解码自然语言在神经科学和机器学习中仍是一个重大挑战，尤其是在开放词汇场景下，传统方法因噪声和变异性表现不佳。先前研究在小规模封闭词汇上取得了高准确率，但在开放词汇上仍存在困难。本研究提出ETS框架，通过整合EEG与同步眼动追踪数据，解决两大关键任务：（1）开放词汇文本生成；（2）感知语言的情感分类。我们的模型在EEG到文本解码任务中BLEU和Rouge分数表现优异，情感分类任务F1分数提升10%，显著优于监督基线。此外，模型能处理多来源数据，展示了高性能开放词汇EEG到文本系统的潜力。

</details>


### [187] [Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective](https://arxiv.org/abs/2506.14965)
**中文标题：从跨领域视角重新审视强化学习在大型语言模型推理中的应用**

*Zhoujun Cheng,Shibo Hao,Tianyang Liu,Fan Zhou,Yutao Xie,Feng Yao,Yuexin Bian,Yonghao Zhuang,Nilabjo Dey,Yuheng Zha,Yi Gu,Kun Zhou,Yuqi Wang,Yuan Li,Richard Fan,Jianshu She,Chengqian Gao,Abulhair Saparov,Haonan Li,Taylor W. Killian,Mikhail Yurochkin,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

主要分类: cs.LG

摘要简述: 本文通过跨领域视角重新审视强化学习（RL）在大型语言模型（LLM）推理中的应用，提出Guru数据集和模型，展示RL在不同领域的表现差异，并实现性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前RL在LLM推理中的应用主要集中在数学和代码领域，缺乏对其他通用推理领域的探索。本文旨在通过构建多领域数据集Guru，研究RL在不同推理领域的适用性。

研究方法: 构建Guru数据集，包含92K个可验证的跨领域推理示例（数学、代码、科学、逻辑、模拟和表格），并通过领域特定奖励设计、去重和过滤确保数据可靠性。基于Guru训练Guru-7B和Guru-32B模型，并评估其性能。

研究结果: 研究发现，RL在预训练中常见的领域（数学、代码、科学）表现良好，而在预训练中较少涉及的领域（逻辑、模拟、表格）需领域内训练才能显著提升性能。Guru模型在17项任务中优于基线模型7.9%和6.7%。

研究结论: RL在不同推理领域的效果存在显著差异，Guru数据集和模型为通用推理提供了新的研究基础。

中文摘要: 强化学习（RL）已成为提升大型语言模型（LLM）推理能力的一种有前景的方法，但目前的研究主要集中在数学和代码领域，限制了对其在通用推理中广泛适用性的理解。关键挑战在于缺乏跨多样化推理领域的可靠、可扩展的RL奖励信号。我们提出了Guru，一个包含92K个可验证示例的RL推理数据集，涵盖数学、代码、科学、逻辑、模拟和表格六个领域，每个领域通过特定奖励设计、去重和过滤确保RL训练的可靠性和有效性。基于Guru，我们系统性地重新审视了RL在LLM推理中的已有发现，并观察到不同领域的显著差异。例如，尽管先前研究表明RL主要从预训练模型中提取已有知识，但我们的结果显示了一种更复杂的模式：预训练中常见的领域（数学、代码、科学）容易受益于跨领域RL训练，而预训练中较少涉及的领域（逻辑、模拟和表格）需领域内训练才能实现显著性能提升，这表明RL可能促进真正的技能获取。最后，我们提出了Guru-7B和Guru-32B模型，在公开数据RL训练的开放模型中实现了最先进的性能，在六个推理领域的17项任务评估中分别优于最佳基线7.9%和6.7%。我们还展示了这些模型有效提升了基础模型的Pass@k性能，尤其是在预训练数据中较少出现的复杂任务上。我们发布了数据、模型、训练和评估代码，以促进通用推理研究：https://github.com/LLM360/Reasoning360

</details>


### [188] [Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size](https://arxiv.org/abs/2506.15025)
**中文标题：大型语言模型中的最优嵌入学习率：词汇量的影响**

*Soufiane Hayou,Liyuan Liu*

主要分类: cs.LG

摘要简述: 本文研究了词汇量对大型语言模型（LLM）训练动态的影响，揭示了词汇量增加时训练动态在μP和大词汇（LV）两种机制间的过渡，并提出了LV机制下嵌入学习率与隐藏学习率的最优比例应为Θ(√width)。


<details>
  <summary>详细信息</summary>
研究动机: 预训练大型语言模型成本高昂，现有方法如μP虽能优化超参数传递性，但其理论假设词汇量固定，与实际不符。本文旨在分析词汇量对训练动态的影响，填补理论与实践的差距。

研究方法: 通过理论分析词汇量对训练动态的影响，提出LV机制，并推导出嵌入学习率与隐藏学习率的最优比例。通过实验验证理论，并预训练1B模型展示其优势。

研究结果: 研究发现，随着词汇量增加，训练动态从μP机制过渡到LV机制，最优嵌入学习率比例接近Θ(√width)，与μP预测的Θ(width)不同。实验验证了理论的有效性。

研究结论: 本文揭示了词汇量对LLM训练动态的关键影响，提出了LV机制及其最优学习率比例，为高效预训练提供了新思路。

中文摘要: 预训练大型语言模型是一个成本高昂的过程。为了提高效率，已有多种方法优化模型架构/参数化和硬件使用。在参数化方面，μP（最大更新参数化）通过权重和学习率（LR）的参数化，使得超参数（HPs）可随宽度（嵌入维度）传递：HPs可针对小模型调优后直接用于更大模型而无需额外调优。尽管μP在实践中表现优异，但近期实证研究在应用于LLM时报告了矛盾结果。μP理论的一个局限是假设输入维度（LLM中的词汇量）在宽度趋近无穷时固定，这与实际不符，因为词汇量通常远大于宽度。本文通过理论分析词汇量对训练动态的影响，揭示了随着词汇量增加，训练动态会在μP机制和另一种称为大词汇（LV）机制的机制间过渡，后者的最优比例规则与μP预测不同。分析表明，在LV机制下，嵌入学习率与隐藏学习率的最优比例应约为Θ(√width)，与文献中先前报告的实证结果惊人地接近，而与μP预测的Θ(width)比例不同。我们通过实验验证理论，并从头预训练1B模型，展示了所提嵌入学习率比例规则的优势。

</details>


### [189] [Determinação Automática de Limiar de Detecção de Ataques em Redes de Computadores Utilizando Autoencoders](https://arxiv.org/abs/2506.14937)
**中文标题：利用自编码器自动确定计算机网络攻击检测阈值**

*Luan Gonçalves Miranda,Pedro Ivo da Cruz,Murilo Bellezoni Loiola*

主要分类: cs.LG

摘要简述: 本文提出了一种利用机器学习算法自动确定自编码器（AE）在计算机网络攻击检测中的阈值的方法，评估了K近邻、K均值和支持向量机三种算法。


<details>
  <summary>详细信息</summary>
研究动机: 当前，基于自编码器的异常检测系统在解决数据不平衡等问题上表现出潜力，但其重建误差的分类阈值非标准化且难以确定，直接影响检测性能。因此，本文旨在通过机器学习算法自动定义这一阈值。

研究方法: 研究评估了三种机器学习算法（K近邻、K均值和支持向量机）用于自动确定自编码器在攻击检测中的阈值。

研究结果: 实验表明，所提出的方法能够有效自动确定阈值，提升攻击检测系统的性能。

研究结论: 通过机器学习算法自动定义自编码器的分类阈值是可行的，且能显著改善异常检测系统的表现。

中文摘要: 目前，基于自编码器（AE）的异常检测系统在解决数据不平衡等固有问题上显示出巨大潜力。由于AE使用非标准化且复杂的分离阈值对提取的重建误差进行分类，该阈值的定义直接影响检测过程的性能。因此，本文提出利用一些机器学习算法自动定义这一阈值。为此，评估了三种算法：K近邻、K均值和支持向量机。

</details>


### [190] [Flat Channels to Infinity in Neural Loss Landscapes](https://arxiv.org/abs/2506.14951)
**中文标题：Error**

*Flavio Martinelli,Alexander Van Meegen,Berfin Şimşek,Wulfram Gerstner,Johanni Brea*

主要分类: cs.LG

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [191] [When and How Unlabeled Data Provably Improve In-Context Learning](https://arxiv.org/abs/2506.15329)
**中文标题：未标记数据何时及如何可证明地改进上下文学习**

*Yingcong Li,Xiangyu Chang,Muti Kara,Xiaofeng Liu,Amit Roy-Chowdhury,Samet Oymak*

主要分类: cs.LG

摘要简述: 本文研究了在上下文学习（ICL）中，未标记数据如何提升性能。通过理论分析，发现多层或循环Transformer能有效利用未标记数据，而单层线性注意力模型则无法做到。实验验证了循环现成表格基础模型在半监督学习中的显著改进。


<details>
  <summary>详细信息</summary>
研究动机: 最近研究表明，即使演示数据存在缺失或错误标签，上下文学习（ICL）仍可有效工作。本文旨在揭示这一现象背后的机制，探讨未标记数据在ICL中的作用。

研究方法: 研究采用二元高斯混合模型（GMM）生成演示数据，部分标签缺失。通过理论分析，对比单层线性注意力模型与多层或循环Transformer的表现，发现后者能通过隐式构建多项式形式的估计器有效利用未标记数据。

研究结果: 理论分析表明，多层或循环Transformer能通过深度指数级的多项式表达利用未标记数据，而单层模型则完全失败。实验证明，循环现成表格基础模型在半监督学习中表现显著优于单次推理。

研究结论: 本文揭示了未标记数据在ICL中的重要作用，证明了多层或循环Transformer的优越性，并提出了一种提升半监督表格学习性能的有效方法。

中文摘要: 最近研究表明，即使演示数据存在缺失或错误标签，上下文学习（ICL）仍可有效工作。为揭示这一能力，我们研究了一个典型场景，其中演示数据按二元高斯混合模型（GMM）生成，且部分标签缺失。通过全面的理论分析，我们发现：（1）单层线性注意力模型的损失景观可恢复最优全监督估计器，但完全无法利用未标记数据；（2）相比之下，多层或循环Transformer能通过隐式构建形如$\sum_{i\ge 0} a_i (X^\top X)^iX^\top y$的估计器（其中$X$和$y$分别表示特征和部分观测标签，缺失项设为零）有效利用未标记数据。我们刻画了可通过深度表达的多项式类别，并将其与半监督学习中常用的迭代伪标签算法（期望最大化）联系起来。重要的是，主导多项式幂随深度呈指数增长，因此轻度深度/循环即可满足需求。作为理论应用，我们提出循环现成表格基础模型以增强其半监督能力。在真实数据集上的大量评估表明，我们的方法在半监督表格学习性能上显著优于标准单次推理。

</details>


### [192] [Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework](https://arxiv.org/abs/2506.15538)
**中文标题：利用PRISM捕捉多义性：一种多概念特征描述框架**

*Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M. -C. Höhne,Oliver Eberle*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PRISM的新框架，用于捕捉神经网络特征的多义性，解决了现有方法在鲁棒性和单义性假设上的不足，显著提升了特征描述的准确性和表达能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前的特征描述方法存在两大问题：鲁棒性不足，以及假设每个神经元仅编码单一概念（单义性），而实际上神经元往往具有多义性。这种假设限制了特征描述的全面性，无法充分捕捉模型内部行为的多样性。

研究方法: 本文提出了PRISM框架，能够为多义性和单义性特征提供更细致的描述。与以往方法不同，PRISM为每个特征提供多概念描述，并通过描述分数和多义性分数评估其质量。

研究结果: 实验表明，PRISM在语言模型上的应用显著提升了特征描述的准确性（通过描述分数衡量）和多义性捕捉能力（通过多义性分数衡量），优于现有方法。

研究结论: PRISM框架通过捕捉神经网络特征的多义性，显著提升了特征描述的全面性和准确性，为自动化可解释性研究提供了更强大的工具。

中文摘要: 自动化可解释性研究旨在识别神经网络特征编码的概念，以增强对人类模型行为的理解。当前的特征描述方法面临两大关键挑战：鲁棒性不足，以及假设每个神经元仅编码单一概念（单义性），尽管越来越多的证据表明神经元往往具有多义性。这种假设限制了特征描述的表达能力，使其无法充分捕捉模型内部行为的多样性。为此，我们提出了多义性特征识别与评分方法（PRISM），这是一种新颖的框架，能够捕捉神经网络特征的固有复杂性。与以往为每个特征分配单一描述的方法不同，PRISM为多义性和单义性特征提供了更细致的描述。我们将PRISM应用于语言模型，并通过与现有方法的广泛基准测试，证明我们的方法能够生成更准确和忠实于特征本身的描述，既提升了整体描述质量（通过描述分数衡量），也增强了在多义性存在时捕捉不同概念的能力（通过多义性分数衡量）。

</details>


### [193] [Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits](https://arxiv.org/abs/2506.14988)
**中文标题：基于探测的多智能体多臂老虎机公平算法**

*Tianyi Xu,Jiaxin Liu,Zizhan Zheng*

主要分类: cs.LG

摘要简述: 本文提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平性同时最大化系统性能。通过引入探测机制，在分配前策略性地收集臂的奖励信息，设计了离线和在线算法，实验表明其优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 在多智能体多臂老虎机问题中，如何在有限信息下实现公平分配并最大化系统性能是一个关键挑战。本文旨在通过探测机制解决这一挑战。

研究方法: 在离线设置中，利用子模性质设计贪心探测算法；在在线设置中，开发了一种实现次线性遗憾并保持公平性的算法。

研究结果: 实验表明，所提方法在合成和真实数据集上优于基线方法，实现了更好的公平性和效率。

研究结论: 本文提出的探测框架和算法在多智能体多臂老虎机问题中有效平衡了公平性和性能，为实际应用提供了可行方案。

中文摘要: 我们提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平性同时最大化系统性能。该框架的关键挑战是在臂奖励信息有限的情况下进行决策。为此，我们引入了一种新颖的探测机制，策略性地在分配前收集所选臂的信息。在离线设置中，已知奖励分布的情况下，我们利用子模性质设计了一种具有可证明性能界的贪心探测算法。对于更复杂的在线设置，我们开发了一种算法，能够实现次线性遗憾并保持公平性。在合成和真实数据集上的大量实验表明，我们的方法优于基线方法，实现了更好的公平性和效率。

</details>


### [194] [LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](https://arxiv.org/abs/2506.15606)
**中文标题：LoX：低秩外推增强LLM在微调下的安全性**

*Gabrel J. Perin,Runjin Chen,Xuxi Chen,Nina S. T. Hirata,Zhangyang Wang,Junyuan Hong*

主要分类: cs.LG

摘要简述: 本文提出了一种名为低秩外推（LoX）的无训练方法，通过外推对齐LLM的安全子空间，显著提升了模型在微调攻击下的安全性，同时保持任务适应性。实验显示，LoX在面对良性或恶意微调攻击时，攻击成功率降低了11%至54%。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在实际应用中广泛使用，但其安全性问题日益突出，尤其是在应对社会有害问题时。尽管通过对齐技术提升了模型安全性，但后续微调仍可能破坏这些保护措施，即使微调数据看似无害。本文旨在解决这一漏洞。

研究方法: 本文提出了一种名为低秩外推（LoX）的无训练方法。该方法通过外推对齐LLM的安全子空间，增强模型对微调攻击的鲁棒性。实验验证了LoX的有效性，并分析了其成功的原因在于将参数移动到更平坦的区域，从而降低对扰动的敏感性。

研究结果: 实验结果表明，LoX在面对良性或恶意微调攻击时，攻击成功率（ASR）显著降低了11%至54%。同时，LoX保持了模型对新任务的适应性。

研究结论: LoX通过外推安全子空间，显著提升了LLM在微调攻击下的安全性，同时不影响其任务适应性。这一方法为LLM的安全性研究提供了新的思路。

中文摘要: 大型语言模型（LLM）已成为实际应用中不可或缺的工具，但其广泛使用也引发了显著的安全问题，尤其是在应对社会有害问题时。尽管通过对齐技术显著提升了模型安全性，但后续微调仍可能破坏这些保护措施，即使微调数据看似无害。本文通过实验证明，这一漏洞源于LLM参数中安全关键的低秩子空间对微调的敏感性。基于这一发现，我们提出了一种名为低秩外推（LoX）的无训练方法，通过外推对齐LLM的安全子空间来增强安全性鲁棒性。实验结果表明，LoX在面对良性或恶意微调攻击时，攻击成功率（ASR）显著降低了11%至54%，同时保持了模型对新任务的适应性。通过分析参数的ASR分布，我们发现LoX的成功在于外推将LLM参数移动到更平坦的区域，从而降低了对扰动的敏感性。代码已开源：github.com/VITA-Group/LoX。

</details>


### [195] [AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning](https://arxiv.org/abs/2506.15651)
**中文标题：AutoRule：基于推理链提取的规则奖励提升偏好学习**

*Tevin Wang,Chenyan Xiong*

主要分类: cs.LG

摘要简述: AutoRule是一种自动化方法，通过从用户偏好反馈中提取规则并转化为奖励，显著提升了强化学习性能。实验显示，使用AutoRule训练的模型在多个基准测试中表现优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于规则的奖励方法依赖人工设计规则，效率低下且难以扩展。AutoRule旨在通过自动化提取规则，提升强化学习从人类反馈中的性能。

研究方法: AutoRule分为三个阶段：1) 利用推理模型解释用户偏好；2) 从推理链中提取候选规则；3) 将规则整合为统一集合。随后，使用语言模型验证器计算规则满足度，作为辅助奖励与学习奖励模型结合优化策略。

研究结果: 实验表明，使用AutoRule训练的Llama-3-8B模型在AlpacaEval2.0上实现了28.6%的相对提升，在MT-Bench子集上提升了6.1%。此外，AutoRule减少了奖励作弊现象，并成功捕捉了不同数据集的独特价值。

研究结论: AutoRule通过自动化规则提取和验证，显著提升了强化学习性能，同时减少了人工干预和奖励作弊问题。其提取的规则与数据集偏好高度一致，展现了广泛的应用潜力。

中文摘要: 基于规则的奖励为改进从人类反馈中学习的强化学习（RLHF）提供了有前景的策略，但当前方法通常依赖人工规则设计。我们提出了AutoRule，一种完全自动化的方法，用于从偏好反馈中提取规则并将其转化为基于规则的奖励。AutoRule的提取过程分为三个阶段：利用推理模型解释用户偏好，从这些解释的推理链中识别候选规则，并将其合成为统一的规则集。利用最终的规则集，我们使用语言模型验证器计算每个输出满足的规则比例，并将此指标作为辅助奖励与学习奖励模型结合用于策略优化。使用AutoRule训练的Llama-3-8B模型在AlpacaEval2.0上实现了28.6%的相对提升，在MT-Bench子集上提升了6.1%，优于仅使用学习奖励模型的GRPO基线。分析表明，提取的规则与数据集偏好高度一致。AutoRule在两轮实验中表现出比学习奖励模型更少的奖励作弊现象。案例研究还表明，提取的规则捕捉了不同数据集的独特价值。提取的规则详见附录，代码已开源：https://github.com/cxcscmu/AutoRule。

</details>


### [196] [Dense SAE Latents Are Features, Not Bugs](https://arxiv.org/abs/2506.15679)
**中文标题：密集SAE潜在特征是功能而非缺陷**

*Xiaoqing Sun,Alessandro Stolfo,Joshua Engels,Ben Wu,Senthooran Rajamanoharan,Mrinmaya Sachan,Max Tegmark*

主要分类: cs.LG

摘要简述: 研究发现，稀疏自编码器（SAE）中的密集潜在特征并非训练噪声，而是具有功能性的语言模型表示。这些特征在残差空间中固有存在，并分为多种类型，如位置跟踪、语义绑定等。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏自编码器（SAE）旨在通过稀疏约束提取语言模型的可解释特征，但许多潜在特征频繁激活（即密集），引发了对这些特征是否为训练噪声的质疑。本文旨在系统研究密集潜在特征的几何、功能和起源。

研究方法: 首先分析密集潜在特征的几何结构，发现它们形成对偶对并重构残差流中的特定方向；其次，通过消融实验验证密集特征的固有性；随后提出密集特征的分类法，识别其功能类型；最后分析这些特征在模型各层的演变规律。

研究结果: 密集潜在特征是残差空间的固有属性，具有功能性，包括位置跟踪、语义绑定、熵调节等多种类型。它们在模型不同层中呈现从结构特征到语义特征再到输出信号的演变规律。

研究结论: 密集潜在特征在语言模型计算中具有功能性作用，不应被视为训练噪声。

中文摘要: 稀疏自编码器（SAE）旨在通过稀疏约束从语言模型中提取可解释特征。理想情况下，SAE训练应得到稀疏且语义有意义的潜在特征。然而，许多SAE潜在特征频繁激活（即密集），引发了对它们是否为训练噪声的担忧。本文系统研究了密集潜在特征的几何、功能和起源，发现它们不仅持续存在，且通常反映有意义的模型表示。首先，我们证明密集潜在特征倾向于形成对偶对，重构残差流中的特定方向；消融其子空间会抑制新密集特征在重新训练的SAE中出现，表明高密度特征是残差空间的固有属性。其次，我们提出密集特征的分类法，识别了与位置跟踪、语义绑定、熵调节、字母特定输出信号、词性和主成分重构相关的类别。最后，分析这些特征在各层的演变，揭示了从早期层的结构特征到中间层的语义特征，再到模型最后层的输出信号的转变。研究结果表明，密集潜在特征在语言模型计算中具有功能性作用，不应被视为训练噪声。

</details>


### [197] [Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment](https://arxiv.org/abs/2506.15019)
**中文标题：基于锐度正则化的稳定CDE自编码器用于脓毒症治疗的离线强化学习**

*Yue Gao*

主要分类: cs.LG

摘要简述: 本文提出一种稳定的CDE自编码器方法，通过锐度正则化解决离线强化学习在脓毒症治疗中的训练不稳定问题，实验证明其能生成与临床评分强相关的表示，并显著提升策略性能。


<details>
  <summary>详细信息</summary>
研究动机: 脓毒症治疗中的强化学习依赖于从ICU不规则时间序列中学习稳定且具有临床意义的表示，但现有方法忽视了训练不稳定性对策略性能的负面影响。

研究方法: 采用控制微分方程（CDE）表示状态，并通过早期停止或稳定化方法确保训练稳定性，同时利用临床评分（SOFA、SAPS-II、OASIS）进行相关性正则化以增强表示的锐度感知能力。

研究结果: 在MIMIC-III脓毒症数据集上的实验表明，稳定的CDE自编码器生成的表示与临床评分强相关，并实现了优越的策略性能（WIS回报>0.9），而不稳定的表示则导致策略失败（WIS回报≈0）。

研究结论: 研究强调了在临床强化学习中使用CDE编码不规则医学时间序列时训练稳定性的重要性，并提供了实用的指导原则。

中文摘要: 脓毒症治疗中有效的强化学习依赖于从ICU不规则时间序列中学习稳定且具有临床意义的表示。尽管已有研究探索了表示学习，但序列表示中的训练不稳定性及其对策略性能的负面影响被忽视了。本文证明，控制微分方程（CDE）状态表示在满足两个关键因素时能实现强化的策略性能：（1）通过早期停止或稳定化方法确保训练稳定性；（2）通过与临床评分（SOFA、SAPS-II、OASIS）的相关性正则化强制锐度感知表示。在MIMIC-III脓毒症队列上的实验表明，稳定的CDE自编码器生成的表示与临床评分强相关，并实现了优越的策略性能（WIS回报>0.9），而不稳定的CDE表示则导致表示退化和策略失败（WIS回报≈0）。潜在空间的可视化显示，稳定的CDE不仅区分了存活与非存活轨迹，还揭示了清晰的临床评分梯度，而不稳定的训练则未能捕捉到任何模式。这些发现为在临床强化学习中使用CDE编码不规则医学时间序列提供了实用指南，强调了序列表示学习中训练稳定性的必要性。

</details>


### [198] [SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models](https://arxiv.org/abs/2506.15021)
**中文标题：SFT-GO：基于分组优化的大型语言模型监督微调**

*Gyuhak Kim,Sumiran Singh Thakur,Su Min Park,Wei Wei,Yujia Bao*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SFT-GO的新方法，通过对不同重要性的词组分层次优化，显著提升了大型语言模型在监督微调中的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的监督微调方法通常将所有词符视为同等重要，忽略了任务关键信息可能仅集中在部分词符中。SFT-GO旨在通过差异化处理不同重要性的词符组，提升模型性能。

研究方法: SFT-GO根据词符的重要性将其分组，并采用加权组合的最差组损失和标准交叉熵损失优化模型，从而自适应地强调最具挑战性的词符组。

研究结果: 实验表明，SFT-GO在多个大型语言模型基准测试中均优于基线方法，且在不同数据集和基础模型上均表现出稳健性和有效性。

研究结论: SFT-GO通过差异化优化词符组，显著提升了监督微调的效果，为大型语言模型的优化提供了新思路。

中文摘要: 监督微调（SFT）已成为调整大型语言模型（LLM）以符合人类期望和特定下游任务的关键步骤。然而，现有的SFT方法通常将每个训练实例视为均匀序列，对所有词符赋予相同的重要性，而忽略了任务关键信息可能仅集中在部分词符中。为解决这一局限性，我们提出了基于分组优化的监督微调方法（SFT-GO），该方法根据词符的重要性对其进行差异化处理。SFT-GO将每个样本中的词符按重要性分组，并通过加权组合的最差组损失和标准交叉熵损失优化LLM。这一机制自适应地强调最具挑战性的词符组，并引导模型更好地处理不同组分布，从而改善整体学习动态。我们提供了SFT-GO收敛速率的理论分析，证明了其高效性。实验上，我们采用三种不同的词符分组策略应用SFT-GO，结果表明，在多个流行的LLM基准测试中，SFT-GO训练的模型均优于基线方法。这些改进在不同数据集和基础模型上均保持一致，证明了我们方法的稳健性和有效性。

</details>


### [199] [CACTUS as a Reliable Tool for Early Classification of Age-related Macular Degeneration](https://arxiv.org/abs/2506.14843)
**中文标题：CACTUS作为早期分类年龄相关性黄斑变性的可靠工具**

*Luca Gherardini,Imre Lengyel,Tunde Peto,Caroline C. W. Klaverd,Magda A. Meester-Smoord,Johanna Maria Colijnd,EYE-RISK Consortium,E3 Consortium,Jose Sousa*

主要分类: cs.LG

摘要简述: CACTUS是一种可靠的机器学习工具，用于早期分类年龄相关性黄斑变性（AMD），通过结合遗传、饮食、临床和人口因素，提供可解释性和灵活性，优于传统模型。


<details>
  <summary>详细信息</summary>
研究动机: 医疗数据通常有限或不完整，影响机器学习模型的性能。年龄相关性黄斑变性（AMD）影响数百万老年人，早期诊断至关重要，但缺乏有效的治疗方法。需要一种综合考虑多种因素的分类方法。

研究方法: 研究团队开发了CACTUS工具，结合遗传、饮食、临床和人口因素，提供可解释性和灵活性，优化AMD分类。通过消除不相关或有偏数据，为临床医生提供反馈场景。

研究结果: CACTUS在AMD分类中表现优于标准机器学习模型，能够识别关键因素并提供可信结果，与现有医学知识一致。

研究结论: CACTUS为AMD早期分类提供了一种可靠且可解释的工具，有助于临床决策和减少数据偏差。

中文摘要: 机器学习（ML）用于解决疾病分类和预测等任务，但其效果依赖于大量完整数据。医疗数据通常有限或不完整，影响模型性能，且解决方案的可信度因数据集而异。年龄相关性黄斑变性（AMD）影响数百万老年人，早期诊断至关重要。AMD诊断需结合视网膜图像和患者症状报告。需要一种综合考虑遗传、饮食、临床和人口因素的分类方法。我们近期开发了“综合抽象与分类工具”（CACTUS），旨在改进AMD分期分类。CACTUS提供可解释性和灵活性，优于标准ML模型，能识别关键因素并增强决策信心。通过消除不相关或有偏数据，为临床医生提供反馈场景，减少偏差。

</details>


### [200] [Sequential Policy Gradient for Adaptive Hyperparameter Optimization](https://arxiv.org/abs/2506.15051)
**中文标题：序列策略梯度自适应超参数优化**

*Zheng Li,Jerry Cheng,Huanying Helen Gu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SPG的轻量级在线超参数优化方法，通过扩展基础模型生成状态-动作轨迹，显著降低了计算成本，并在多个数据集上实现了性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 传统的强化学习方法在神经架构搜索和超参数优化中因高昂的时间和计算成本而难以广泛应用。本文旨在提出一种更高效的轻量级优化方法。

研究方法: SPG（Sequential Policy Gradient）是一种新型轨迹生成范式，通过为基模型添加临时模块，使其能够在单次前向传递中生成状态-动作轨迹，从而降低计算成本。

研究结果: 实验表明，SPG在多个数据集（ImageNet、COCO、GLUE、SQuAD、SUPERB）上均实现了性能提升（+0.2%至7%），且计算成本显著降低。

研究结论: SPG是一种高效且轻量级的超参数优化方法，适用于多种任务，具有广泛的工业应用潜力。

中文摘要: 强化学习在神经架构搜索和超参数优化中至关重要，但传统方法因高昂的时间和计算成本难以广泛应用。受DeepSeek-V3多令牌预测架构启发，我们提出了序列策略梯度建模（SPG），一种轻量级在线超参数优化的新型轨迹生成范式。与传统策略梯度方法不同，SPG通过为基模型添加临时模块，使其能够在单次前向传递中生成状态-动作（填充）轨迹。实验表明，模型在原始数据集上使用SPG重新训练后性能提升，且优于标准迁移微调。我们在计算机视觉（ImageNet、COCO）、自然语言处理（GLUE、SQuAD）和音频（SUPERB）五个数据集上评估了SPG的工业适用性。该方法在广泛采用的模型中实现了+0.2%至7%的性能提升，且计算成本极低。完全可复现的代码和预训练模型：https://huggingface.co/UniversalAlgorithmic/SPG。

</details>


### [201] [Singular Value Decomposition on Kronecker Adaptation for Large Language Model](https://arxiv.org/abs/2506.15251)
**中文标题：基于Kronecker适应的奇异值分解在大型语言模型中的应用**

*Yee Hin Chong,Peng Qu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SoKA的新型参数高效微调方法，结合Kronecker乘积张量分解与SVD驱动的初始化及动态秩选择，显著减少了训练参数数量并提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型预训练Transformer模型在多种任务中表现优异，但全参数微调带来高昂的存储和计算成本。现有参数高效微调方法存在推理延迟、收敛不佳或固定秩选择不匹配任务复杂度等问题。

研究方法: SoKA方法结合Kronecker乘积张量分解与SVD驱动的初始化，通过动态秩选择算法剪枝不重要成分，提取权重更新的主成分到紧凑的Kronecker因子中。

研究结果: 在LLaMA2-7B模型上的实验表明，SoKA仅需0.99M可训练参数，比LoRA/PiSSA少25%，同时性能相当或更优，收敛更快且梯度更稳定。

研究结论: SoKA是一种高效、鲁棒的大规模模型适应方法，显著降低了计算成本并提升了性能。

中文摘要: 大型预训练Transformer模型在多种语言和推理任务中取得了最先进的成果，但全参数微调带来了巨大的存储、内存和计算开销。参数高效微调（PEFT）方法通过学习少量任务特定参数来降低这些成本，但现有方法要么引入推理延迟（适配器模块），要么收敛效果不佳（随机初始化的低秩更新），或依赖固定秩选择（基于Kronecker的分解），可能无法匹配任务复杂度。
  我们提出SoKA（基于Kronecker适应的SVD），一种新型PEFT策略，结合Kronecker乘积张量分解与SVD驱动的初始化及频谱感知的动态秩选择。我们的Kronecker乘积SVD（KPSVD）过程将完整权重更新的主成分提取到紧凑的Kronecker因子中，同时自适应秩选择算法通过能量阈值和肘点准则剪枝不重要成分。
  在LLaMA2-7B模型上的算术推理（GSM8K）、形式数学（MATH）和代码生成（MBPP）任务中的实验表明，SoKA仅需0.99M可训练参数，比LoRA/PiSSA少25%，同时性能相当或更优。此外，SoKA表现出更快的收敛速度和更稳定的梯度，突显其在大规模模型适应中的鲁棒性和高效性。

</details>


### [202] [Unlocking Post-hoc Dataset Inference with Synthetic Data](https://arxiv.org/abs/2506.15271)
**中文标题：利用合成数据解锁事后数据集推断**

*Bihe Zhao,Pratyush Maini,Franziska Boenisch,Adam Dziedzic*

主要分类: cs.LG

摘要简述: 本文提出了一种通过合成数据实现事后数据集推断的方法，解决了现有方法需要真实保留数据集的限制，从而帮助数据所有者验证其数据是否被未经授权使用。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的强大能力依赖于其海量训练数据，但这些数据往往未经数据所有者授权。数据集推断（DI）可以识别可疑数据集是否被用于训练，但现有方法需要与原始数据集分布匹配的真实保留数据集，这在实践中难以获取。本文旨在通过合成数据解决这一限制。

研究方法: 方法包括：（1）通过基于后缀补全任务训练的数据生成器生成高质量、多样化的合成数据，以准确反映原始分布；（2）通过事后校准弥合真实数据与合成数据之间的似然差距。

研究结果: 实验表明，使用生成的合成数据作为保留集，DI能够高置信度地检测原始训练集，同时保持低误报率，适用于实际版权纠纷。

研究结论: 本文的方法为数据所有者提供了验证数据使用的可靠工具，展示了合成数据在事后数据集推断中的潜力。

中文摘要: 大型语言模型（LLMs）的卓越能力主要归功于其海量训练数据集，这些数据通常未经数据所有者知识产权许可从互联网抓取。数据集推断（DI）通过识别可疑数据集是否用于训练，为数据所有者提供验证未经授权使用的潜在解决方案。然而，现有DI方法需要一个已知未用于训练且与受损数据集分布匹配的私有保留集。这种分布内保留数据在实践中极少可用，严重限制了DI的适用性。本研究通过合成生成所需保留集解决了这一挑战。我们的方法攻克了两个关键障碍：（1）通过基于后缀补全任务训练的数据生成器生成高质量、多样化的合成数据，准确反映原始分布；（2）通过事后校准弥合真实数据与合成数据之间的似然差距。在多种文本数据集上的广泛实验表明，使用生成的合成数据作为保留集，DI能够高置信度地检测原始训练集，同时保持低误报率。这一结果使版权所有者能够对数据使用提出合法主张，并证明我们的方法在实际诉讼中的可靠性。代码发布于https://github.com/sprintml/PostHocDatasetInference。

</details>


### [203] [Pixel-level Certified Explanations via Randomized Smoothing](https://arxiv.org/abs/2506.15499)
**中文标题：基于随机平滑的像素级认证解释**

*Alaa Anani,Tobias Lorenz,Mario Fritz,Bernt Schiele*

主要分类: cs.LG

摘要简述: 本文提出了一种基于随机平滑的像素级认证解释框架，首次为任何黑盒归因方法提供像素级鲁棒性保证，通过稀疏化和平滑化归因图，将其重新表述为分割问题，并针对ℓ₂有界扰动认证每个像素的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事后归因方法在解释深度学习预测时容易受到微小输入扰动的影响，导致归因图发生显著变化，从而降低其可信度。本文旨在通过提供严格的鲁棒性保证，增强像素级归因评分的可靠性。

研究方法: 通过随机平滑技术，将归因图稀疏化和平滑化，重新将其建模为分割问题，并针对ℓ₂有界扰动认证每个像素的重要性。此外，提出了三个评估指标来衡量认证的鲁棒性、定位性和忠实性。

研究结果: 在5个ImageNet模型和12种归因方法的广泛评估中，本文提出的认证归因方法表现出鲁棒性、可解释性和忠实性，适用于下游任务。

研究结论: 本文提出的认证框架为像素级归因提供了鲁棒性保证，增强了归因方法的可信度和实用性，为下游任务提供了可靠支持。

中文摘要: 事后归因方法旨在通过突出显示影响输入像素来解释深度学习预测。然而，这些解释非常不鲁棒：微小且难以察觉的输入扰动可以显著改变归因图，同时保持相同的预测结果。这种脆弱性削弱了其可信度，并呼吁对像素级归因评分提供严格的鲁棒性保证。我们首次引入了一个认证框架，利用随机平滑为任何黑盒归因方法提供像素级鲁棒性保证。通过稀疏化和平滑化归因图，我们将任务重新表述为一个分割问题，并针对ℓ₂有界扰动认证每个像素的重要性。我们还提出了三个评估指标来衡量认证的鲁棒性、定位性和忠实性。对5个ImageNet模型和12种归因方法的广泛评估表明，我们的认证归因方法具有鲁棒性、可解释性和忠实性，能够可靠地用于下游任务。我们的代码位于https://github.com/AlaaAnani/certified-attributions。

</details>


### [204] [Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation](https://arxiv.org/abs/2506.15309)
**中文标题：主动学习引导的序列到序列变分自编码器用于多靶点抑制剂生成**

*Júlia Vilalta-Mor,Alexis Molina,Laura Ortega Varga,Isaac Filella-Merce,Victor Guallar*

主要分类: cs.LG

摘要简述: 本文提出了一种结合主动学习和序列到序列变分自编码器的方法，用于生成多靶点抑制剂，解决了药物发现中多目标优化和稀疏奖励的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 在药物发现中，同时优化分子以针对多个治疗靶点面临稀疏奖励和设计约束冲突的挑战。本文旨在通过结合主动学习和变分自编码器，高效生成多样化的多靶点抑制剂。

研究方法: 采用结构化主动学习范式，将序列到序列变分自编码器集成到迭代循环中，平衡化学多样性、分子质量和多靶点亲和力。方法包括扩展潜在空间的化学可行区域，并根据逐步严格的多靶点对接阈值约束分子。

研究结果: 在针对三种冠状病毒主蛋白酶（SARS-CoV-2、SARS-CoV、MERS-CoV）的概念验证研究中，该方法成功生成了结构多样化的泛抑制剂候选分子。主动学习管道的化学过滤器显著提升了有益化学空间的探索。

研究结论: 该框架为高效导航复杂的多药理学景观提供了通用路线图，将稀疏奖励的多目标药物设计问题转化为可计算任务。

中文摘要: 在药物发现中，同时优化分子以针对多个治疗靶点仍然是一个重大挑战，尤其是由于稀疏奖励和设计约束的冲突。我们提出了一种结构化主动学习（AL）范式，将序列到序列（Seq2Seq）变分自编码器（VAE）集成到迭代循环中，旨在平衡化学多样性、分子质量和多靶点亲和力。我们的方法在扩展潜在空间的化学可行区域和基于逐步严格的多靶点对接阈值约束分子之间交替进行。在一项针对三种相关冠状病毒主蛋白酶（SARS-CoV-2、SARS-CoV、MERS-CoV）的概念验证研究中，我们的方法高效生成了结构多样化的泛抑制剂候选分子。我们证明，在主动学习管道中精心安排和策略性地放置化学过滤器，显著增强了对有益化学空间的探索，将稀疏奖励的多目标药物设计问题转化为可计算任务。因此，我们的框架为高效导航复杂的多药理学景观提供了通用路线图。

</details>


### [205] [Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI](https://arxiv.org/abs/2506.15408)
**中文标题：统一VXAI：可解释AI评估的系统性综述与框架**

*David Dembinsky,Adriano Lucieri,Stanislav Frolov,Hiba Najjar,Ko Watanabe,Andreas Dengel*

主要分类: cs.LG

摘要简述: 本文通过系统性文献综述和统一框架VXAI，解决了可解释AI（XAI）领域缺乏标准化评估协议和共识的问题，提出了41个功能相似的指标组和三维分类方案。


<details>
  <summary>详细信息</summary>
研究动机: 现代AI系统（如深度神经网络）因其黑盒特性缺乏透明度，导致信任问题。可解释AI（XAI）旨在提供人类可理解的模型行为解释，但其评估缺乏标准化协议和共识，亟需统一框架。

研究方法: 作者遵循PRISMA指南进行系统性文献综述，筛选出362篇相关文献，并提出了统一的VXAI框架，包括41个功能相似的指标组和三维分类方案（解释类型、评估上下文性和解释质量需求）。

研究结果: 研究提出了目前最全面的VXAI框架，支持系统性指标选择，促进方法间的可比性，并为未来扩展提供了灵活基础。

研究结论: VXAI框架填补了XAI评估领域的空白，为标准化评估和未来研究提供了重要工具。

中文摘要: 现代AI系统通常依赖不透明的黑盒模型（如深度神经网络），其性能源于具有数百万学习参数的复杂架构。尽管强大，但其复杂性对可信度构成重大挑战，尤其是缺乏透明度。可解释AI（XAI）通过提供人类可理解的模型行为解释来解决这一问题。然而，为确保其有用性和可信度，此类解释必须经过严格评估。尽管XAI方法日益增多，但该领域缺乏标准化评估协议和关于适当指标的共识。为填补这一空白，我们遵循PRISMA指南进行了系统性文献综述，并提出了统一的XAI评估框架（VXAI）。我们筛选出362篇相关文献，并将其贡献汇总为41个功能相似的指标组。此外，我们提出了一个三维分类方案，涵盖解释类型、评估上下文性和解释质量需求。我们的框架提供了迄今为止最全面和结构化的VXAI概述，支持系统性指标选择，促进方法间的可比性，并为未来扩展提供了灵活基础。

</details>


### [206] [Reward Models in Deep Reinforcement Learning: A Survey](https://arxiv.org/abs/2506.15421)
**中文标题：深度强化学习中的奖励模型综述**

*Rui Yu,Shenghua Wan,Yucen Wang,Chen-Xiao Gao,Le Gan,Zongzhang Zhang,De-Chuan Zhan*

主要分类: cs.LG

摘要简述: 本文综述了深度强化学习中的奖励模型技术，分类总结了其来源、机制和学习范式，并探讨了应用与评估方法，最后指出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 奖励模型在强化学习中至关重要，但现有文献缺乏系统性综述。本文旨在填补这一空白，为研究者提供全面的技术概览。

研究方法: 文章首先介绍奖励模型的背景与基础知识，随后分类综述了近期奖励模型方法，包括其来源、机制和学习范式，并讨论了应用与评估技术。

研究结果: 综述涵盖了奖励模型的经典与新兴方法，提供了技术分类与应用案例，同时总结了评估方法。

研究结论: 本文系统梳理了奖励模型的研究进展，指出了未来发展方向，为相关领域提供了重要参考。

中文摘要: 在强化学习（RL）中，智能体持续与环境交互，并利用反馈优化其行为。为了指导策略优化，奖励模型被引入作为目标任务的代理，使得智能体在最大化累积奖励的同时，也能实现任务设计者的意图。近年来，学术界和工业界的研究者高度关注开发既能紧密对齐真实目标，又能促进策略优化的奖励模型。本文综述了深度强化学习文献中的奖励建模技术。首先概述了奖励模型的背景与基础知识，随后分类总结了近期奖励模型方法，包括其来源、机制和学习范式。在此基础上，讨论了这些技术的应用及奖励模型的评估方法。最后，指出了奖励建模的未来研究方向。本文涵盖了经典与新兴方法，填补了当前文献中系统性综述奖励模型的空白。

</details>


### [207] [Zero-Shot Reinforcement Learning Under Partial Observability](https://arxiv.org/abs/2506.15446)
**中文标题：部分可观测性下的零样本强化学习**

*Scott Jeen,Tom Bewley,Jonathan M. Cullen*

主要分类: cs.LG

摘要简述: 本文探讨了在部分可观测环境下零样本强化学习（RL）的性能退化问题，并提出基于记忆的架构作为有效解决方案。实验表明，该方法在状态、奖励和动态变化部分可观测的领域中优于无记忆基线。


<details>
  <summary>详细信息</summary>
研究动机: 零样本强化学习在完全可观测的马尔可夫状态下表现良好，但在现实应用中，状态往往部分可观测。本文旨在研究部分可观测性对零样本RL性能的影响，并提出改进方法。

研究方法: 通过引入基于记忆的架构，解决部分可观测性对零样本RL的挑战。在状态、奖励和动态变化部分可观测的领域中进行实验验证。

研究结果: 实验结果显示，基于记忆的零样本RL方法在部分可观测环境中性能显著优于无记忆基线。

研究结论: 在部分可观测环境下，基于记忆的架构是提升零样本RL性能的有效方法。

中文摘要: 近期研究表明，在某些假设下，零样本强化学习（RL）方法可以通过无奖励预训练泛化到任何未见任务中。完全可观测的马尔可夫状态是此类假设之一，然而，在许多实际应用中，马尔可夫状态仅部分可观测。本文探讨了标准零样本RL方法在部分可观测性下的性能退化问题，并表明，与单任务RL类似，基于记忆的架构是一种有效解决方案。我们在状态、奖励和动态变化部分可观测的领域中评估了基于记忆的零样本RL方法，结果显示其性能优于无记忆基线。代码已开源：https://enjeeneer.io/projects/bfms-with-memory/。

</details>


### [208] [Warping and Matching Subsequences Between Time Series](https://arxiv.org/abs/2506.15452)
**中文标题：时间序列间的子序列扭曲与匹配**

*Simiao Lin,Wannes Meert,Pieter Robberechts,Hendrik Blockeel*

主要分类: cs.LG

摘要简述: 本文提出了一种新技术，通过简化时间序列间的扭曲路径，突出、量化和可视化关键变换（如位移、压缩和振幅差异），从而提升时间序列比较的可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 时间序列比较在聚类和分类等任务中至关重要，但现有的弹性距离度量虽能提供定量比较，却缺乏定性分析。传统可视化方法仅关注点对点对齐，无法展示子序列间的结构关系，难以理解时间序列间的位移、加速或减速。

研究方法: 提出了一种简化扭曲路径的新技术，通过量化关键变换（位移、压缩、振幅差异）并可视化子序列匹配关系，增强时间序列比较的直观性。

研究结果: 该方法能够清晰展示时间序列间的子序列匹配关系，显著提升了比较的可解释性，帮助用户理解序列间的变换方式。

研究结论: 通过简化扭曲路径并可视化关键变换，本文方法有效解决了时间序列比较中的定性分析问题，为后续研究提供了新的工具和思路。

中文摘要: 时间序列比较在聚类和分类等任务中至关重要。尽管允许扭曲的弹性距离度量提供了稳健的定量比较，但缺乏定性分析。传统可视化方法仅关注点对点对齐，未能传达子序列层面的结构关系，导致难以理解时间序列间的位移、加速或减速。为此，我们提出了一种新技术，通过简化扭曲路径来突出、量化和可视化关键变换（如位移、压缩和振幅差异）。通过更清晰地展示子序列间的匹配关系，我们的方法提升了时间序列比较的可解释性。

</details>


### [209] [Over-squashing in Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2506.15507)
**中文标题：时空图神经网络中的信息过度压缩问题**

*Ivan Marisca,Jacob Bamberger,Cesare Alippi,Michael M. Bronstein*

主要分类: cs.LG

摘要简述: 本文研究了时空图神经网络（STGNNs）中的信息过度压缩问题，揭示了其与静态图的不同特性，并发现卷积STGNNs更倾向于传播时间上较远而非较近的信息。


<details>
  <summary>详细信息</summary>
研究动机: 尽管图神经网络（GNNs）在多领域取得了显著成功，但其信息传播能力存在根本性限制，如信息过度压缩（over-squashing）。这一问题在静态图中已有研究，但在时空图神经网络（STGNNs）中尚未探索。由于时间维度增加了信息传播的复杂性，研究STGNNs中的信息过度压缩问题具有重要意义。

研究方法: 本文形式化了时空图神经网络中的信息过度压缩问题，并通过理论分析揭示了其与静态图的区别。研究发现，卷积STGNNs更倾向于传播时间上较远而非较近的信息。此外，论文证明了无论是时间-空间并行处理还是时间优先处理的架构，均受此现象影响。

研究结果: 研究结果表明，时空图神经网络中的信息过度压缩问题具有独特特性，且卷积STGNNs在信息传播上存在时间偏好。理论分析为高效计算实现提供了依据，并在合成和真实数据集上验证了这些发现。

研究结论: 本文为时空图神经网络中的信息过度压缩问题提供了理论支持，揭示了其独特特性，并为更有效的设计提供了指导。

中文摘要: 图神经网络（GNNs）在多个领域取得了显著成功，但最近的理论进展揭示了其信息传播能力的根本性限制，例如信息过度压缩（over-squashing），即远距离节点无法有效交换信息。尽管这一问题在静态图中已有广泛研究，但在时空图神经网络（STGNNs）中尚未探索。STGNNs处理与图节点关联的序列，而时间维度通过增加需传播的信息量进一步加剧了这一挑战。本文形式化了时空信息过度压缩问题，并展示了其与静态情况的显著区别。分析表明，卷积STGNNs反直觉地倾向于传播时间上较远而非较近的信息。此外，我们证明了遵循时间-空间并行或时间优先处理范式的架构均受此现象影响，为计算高效实现提供了理论依据。我们在合成和真实数据集上验证了这些发现，为理解其运行机制和设计更有效的架构提供了深入见解和原则性指导。

</details>


### [210] [RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation](https://arxiv.org/abs/2506.15513)
**中文标题：RePCS：诊断基于LLM的检索增强生成中的数据记忆问题**

*Le Vu Anh,Nguyen Viet Anh,Mehmet Dik,Luong Van Nghia*

主要分类: cs.LG

摘要简述: 本文提出了一种名为RePCS的诊断方法，用于检测基于检索增强生成（RAG）的大型语言模型（LLM）是否依赖记忆的训练数据而非检索内容。该方法通过比较两种推理路径的KL散度来识别潜在的污染输出，无需模型访问或重新训练。


<details>
  <summary>详细信息</summary>
研究动机: 检索增强生成（RAG）虽然能更新LLM的响应，但模型可能仍依赖记忆的训练数据，导致输出污染。现有方法难以在不访问模型内部的情况下诊断此类问题，因此需要一种轻量级、黑盒化的解决方案。

研究方法: RePCS通过比较仅使用查询的“参数路径”和同时使用查询与检索上下文的“检索增强路径”的输出分布KL散度，判断检索内容是否被有效利用。低散度表明模型可能依赖记忆数据。

研究结果: 在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，优于先前方法6.5个百分点，且延迟开销低于4.7%。

研究结论: RePCS提供了一种无需模型访问的轻量级诊断工具，可有效验证RAG系统是否真正利用检索内容，适用于安全关键应用。

中文摘要: 检索增强生成（RAG）已成为通过外部信息更新大型语言模型（LLM）响应的常见策略。然而，模型可能仍依赖记忆的训练数据，绕过检索证据并产生污染输出。我们提出检索路径污染评分（RePCS），一种无需模型访问或重新训练即可检测此类行为的诊断方法。RePCS比较两种推理路径：（i）仅使用查询的参数路径，（ii）同时使用查询和检索上下文的检索增强路径，通过计算其输出分布的Kullback-Leibler（KL）散度。低散度表明检索上下文影响较小，可能存在记忆行为。该方法与模型无关，无需梯度或内部状态访问，仅需一次额外前向传播。我们还推导了PAC式保证，将KL阈值与用户定义的假阳性和假阴性率关联。在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，优于先前最强方法6.5个百分点，且在NVIDIA T4 GPU上的延迟开销低于4.7%。RePCS提供了一种轻量级、黑盒化的保障措施，用于验证RAG系统是否有效利用检索，特别适用于安全关键应用。

</details>


### [211] [Learning Algorithms in the Limit](https://arxiv.org/abs/2506.15543)
**中文标题：极限中的学习算法**

*Hristo Papazov,Nicolas Flammarion*

主要分类: cs.LG

摘要简述: 本文通过扩展Gold的归纳推理框架，引入计算观察和受限输入源，研究在极限条件下学习可计算函数的问题。通过时间限制观察和策略轨迹观察，克服了传统输入输出观察无法学习一般递归函数的限制，并建立了计算代理观察的正式框架。


<details>
  <summary>详细信息</summary>
研究动机: 传统输入输出观察无法在极限条件下学习一般递归函数，因此需要引入更现实的约束条件（如计算复杂度限制或近似时间限制观察）来突破这一学习障碍。

研究方法: 扩展Gold的归纳推理框架，引入时间限制观察和策略轨迹观察，研究可计算函数的学习能力。建立计算代理观察的正式框架，揭示策略轨迹学习与有限状态转换器推断的联系。

研究结果: 输入输出观察不足以学习一般递归函数，但通过计算复杂度约束或时间限制观察可以克服这一限制。策略轨迹学习可简化为输入输出学习，但线性时间可计算函数无法存在可计算或多项式质量特征集。

研究结论: 通过引入计算观察和受限输入源，扩展了极限学习框架，揭示了策略轨迹学习与有限状态转换器推断的联系，但线性时间可计算函数的学习仍存在限制。

中文摘要: 本文通过扩展Gold的归纳推理框架，引入计算观察和受限输入源，研究在极限条件下学习可计算函数的问题。与传统输入输出观察互补，我们引入时间限制观察和策略轨迹观察，研究更现实约束下一般递归函数的可学习性。虽然输入输出观察不足以在极限条件下学习一般递归函数，但通过施加计算复杂度约束或补充近似时间限制观察，我们克服了这一学习障碍。此外，我们围绕计算代理的观察建立了一个正式框架，并表明从策略轨迹学习可计算函数可简化为从输入和输出学习有理函数，从而揭示了与有限状态转换器推断的有趣联系。在负面结果方面，我们证明即使对于策略轨迹观察，线性时间可计算函数也无法存在可计算或多项式质量的特征集。

</details>


### [212] [DAILOC: Domain-Incremental Learning for Indoor Localization using Smartphones](https://arxiv.org/abs/2506.15554)
**中文标题：DAILOC：基于智能手机的域增量学习室内定位方法**

*Akhil Singampalli,Danish Gufran,Sudeep Pasricha*

主要分类: cs.LG

摘要简述: DAILOC提出了一种新型域增量学习框架，通过多级变分自编码器分离域偏移与位置特征，并结合记忆引导的潜在对齐机制，显著提升了Wi-Fi指纹室内定位的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: Wi-Fi指纹室内定位在实际部署中面临设备异构性和环境时变性的挑战，现有方法通常独立处理这些问题，导致泛化能力差且易受灾难性遗忘影响。

研究方法: DAILOC采用多级变分自编码器分离域偏移与位置特征，并引入记忆引导的潜在对齐机制，以应对灾难性遗忘问题。

研究结果: 实验表明，DAILOC在多个智能手机、建筑和时间实例中表现优异，平均误差降低2.74倍，最差情况误差降低4.6倍。

研究结论: DAILOC通过联合处理时变和设备引起的域偏移，显著提升了室内定位的准确性和鲁棒性，优于现有方法。

中文摘要: 基于Wi-Fi指纹的室内定位在实际部署中因设备异构性和环境时变性导致的域偏移而面临重大挑战。现有方法通常独立处理这些问题，导致泛化能力差且易受灾难性遗忘影响。本文提出DAILOC，一种新型域增量学习框架，联合处理时变和设备引起的域偏移。DAILOC通过多级变分自编码器分离域偏移与位置特征，并引入记忆引导的潜在对齐机制以应对灾难性遗忘。实验表明，DAILOC在多个智能手机、建筑和时间实例中显著优于现有方法，平均误差降低2.74倍，最差情况误差降低4.6倍。

</details>


### [213] [Towards Explainable Indoor Localization: Interpreting Neural Network Learning on Wi-Fi Fingerprints Using Logic Gates](https://arxiv.org/abs/2506.15559)
**中文标题：迈向可解释的室内定位：利用逻辑门解释基于Wi-Fi指纹的神经网络学习**

*Danish Gufran,Sudeep Pasricha*

主要分类: cs.LG

摘要简述: 本文提出了一种基于逻辑门的框架LogNet，用于解释和增强基于深度学习的室内定位系统，解决了现有黑盒模型缺乏可解释性的问题，并在性能和稳定性上取得显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于深度学习的室内定位系统多为黑盒模型，无法解释预测过程或应对环境噪声的长期影响，限制了模型的可靠性和适应性。

研究方法: 作者提出LogNet框架，通过逻辑门结构识别关键接入点（APs）及其对参考点（RPs）的影响，并分析环境噪声对定位决策的干扰。

研究结果: LogNet在多个实际建筑平面图和两年时间变化数据上的测试表明，其定位误差降低1.1至2.8倍，模型大小缩小3.4至43.3倍，延迟减少1.5至3.6倍。

研究结论: LogNet不仅提升了深度学习模型的解释性，还显著优化了性能和长期稳定性，为室内定位系统的实际部署提供了新思路。

中文摘要: 基于深度学习（DL）的室内定位在将Wi-Fi RSS指纹映射到物理位置方面表现出高精度，但大多数现有DL框架作为黑盒模型运行，无法解释预测过程或模型如何应对长期的环境噪声。这种缺乏可解释性的问题限制了我们对时间变化（由环境动态引起）影响的理解，以及模型长期可靠性的调整能力。为此，我们提出了LogNet，一种基于逻辑门的新型框架，旨在解释和增强基于DL的室内定位。LogNet通过识别每个参考点（RP）最关键的接入点（APs），并揭示环境噪声如何干扰DL驱动的定位决策，实现了透明推理。这种可解释性使我们能够追踪和诊断模型故障，并调整DL系统以实现更稳定的长期部署。在多个实际建筑平面图和两年时间变化数据的评估中，LogNet不仅解释了DL模型的内部行为，还提升了性能——定位误差降低1.1至2.8倍，模型大小缩小3.4至43.3倍，延迟减少1.5至3.6倍，优于现有DL模型。

</details>


### [214] [GFLC: Graph-based Fairness-aware Label Correction for Fair Classification](https://arxiv.org/abs/2506.15620)
**中文标题：GFLC：基于图的公平感知标签校正方法用于公平分类**

*Modar Sulaiman,Kallol Roy*

主要分类: cs.LG

摘要简述: 本文提出了一种基于图的公平感知标签校正方法（GFLC），用于在分类任务中修正标签噪声并保持数据集的公平性。通过结合预测置信度、图正则化和人口统计平等激励，显著提升了模型性能与公平性的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能系统在社会各领域的广泛应用，机器学习中的公平性问题日益重要。然而，训练数据中的标签偏差和噪声会影响模型性能和公平性评估。本文旨在解决这一问题，提出一种能够修正标签噪声并保持公平性的方法。

研究方法: GFLC方法结合了三个关键组件：预测置信度度量、基于Ricci流优化的图拉普拉斯正则化，以及明确的人口统计平等激励。通过这些组件的协同作用，有效修正标签噪声并提升公平性。

研究结果: 实验结果表明，GFLC方法在性能和公平性指标之间取得了显著改进，优于基线方法。

研究结论: GFLC方法为机器学习中的公平性问题提供了一种有效的解决方案，能够同时修正标签噪声和保持公平性，具有广泛的应用前景。

中文摘要: 机器学习（ML）中的公平性对于构建可信赖的机器学习系统至关重要，因为人工智能（AI）系统日益影响社会的各个方面，包括医疗决策和法律判决。此外，大量研究表明ML中存在不公平结果，需要更鲁棒的公平感知方法。然而，用于训练和开发去偏技术的数据通常包含有偏和噪声标签。因此，训练数据中的标签偏差会影响模型性能，并在测试过程中误导分类器的公平性评估。为解决这一问题，本文提出了一种基于图的公平感知标签校正方法（GFLC），该方法能够高效修正标签噪声，同时保持数据集中的人口统计平等。具体而言，我们的方法结合了三个关键组件：预测置信度度量、通过Ricci流优化的图拉普拉斯正则化，以及明确的人口统计平等激励。实验结果表明，所提出的方法在性能和公平性指标之间的权衡上取得了显著改进，优于基线方法。

</details>


### [215] [Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction](https://arxiv.org/abs/2506.15626)
**中文标题：基于MRI的脑龄预测的联邦学习：一项关于卒中后功能恢复预测的多中心研究**

*Vincent Roca,Marc Tommasi,Paul Andrey,Aurélien Bellet,Markus D. Schirmer,Hilde Henon,Laurent Puy,Julien Ramon,Grégory Kuchcinski,Martin Bretzner,Renaud Lopes*

主要分类: cs.LG

摘要简述: 本研究探讨了联邦学习（FL）在基于MRI的脑龄预测（BrainAGE）中的应用，用于预测缺血性卒中患者的功能恢复。结果显示，FL在保护数据隐私的同时，性能优于单中心模型，且BrainAGE与血管风险因素及卒中后功能恢复显著相关。


<details>
  <summary>详细信息</summary>
研究动机: 脑龄差异（BrainAGE）是反映脑健康的重要生物标志物，但训练稳健的BrainAGE模型需要大量数据，而隐私问题限制了数据的集中使用。本研究旨在评估联邦学习在脑龄预测中的表现，并探讨其与卒中患者功能恢复的关联。

研究方法: 研究使用来自16个医疗中心的1674名卒中患者的FLAIR脑图像，比较了三种数据管理策略：集中学习（数据集中）、联邦学习（本地训练）和单中心学习。通过机器学习与深度学习模型预测BrainAGE，并分析其与血管风险因素（如糖尿病、高血压、吸烟）及卒中后三个月功能恢复的关系。

研究结果: 集中学习预测最准确，但联邦学习性能优于单中心模型。所有模型中，糖尿病患者的BrainAGE显著更高。BrainAGE与卒中后功能恢复的关联在多变量分析中具有显著性。

研究结论: 联邦学习可在不集中数据的情况下实现准确的脑龄预测。BrainAGE与血管风险因素及卒中后恢复的强关联表明其在卒中预后建模中的潜力。

中文摘要: 目的：脑龄差异（BrainAGE）是一种反映脑健康的神经影像生物标志物。然而，训练稳健的BrainAGE模型需要大量数据，而隐私问题常限制数据共享。本研究评估了联邦学习（FL）在缺血性卒中患者脑龄预测中的表现，并探讨其与临床表型及功能恢复的关系。方法：我们使用来自16个医疗中心的1674名卒中患者的FLAIR脑图像，比较了集中学习（数据集中）、联邦学习（本地训练）和单中心学习三种策略的BrainAGE预测性能。通过机器学习与深度学习模型预测BrainAGE，并分析其与血管风险因素（如糖尿病、高血压、吸烟）及卒中后三个月功能恢复的关系。结果：集中学习预测最准确，但联邦学习性能优于单中心模型。所有模型中，糖尿病患者的BrainAGE显著更高。BrainAGE与卒中后功能恢复的关联在多变量分析中具有显著性。结论：联邦学习可在不集中数据的情况下实现准确的脑龄预测。BrainAGE与血管风险因素及卒中后恢复的强关联表明其在卒中预后建模中的潜力。

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [216] [LLM Agent for Hyper-Parameter Optimization](https://arxiv.org/abs/2506.15167)
**中文标题：基于大型语言模型的超参数优化智能代理**

*Wanzhe Wang,Jianqiu Peng,Menghao Hu,Weihuang Zhong,Tong Zhang,Shuai Wang,Yixin Zhang,Mingjie Shao,Wanli Ni*

主要分类: cs.IT

摘要简述: 本文提出了一种基于大型语言模型（LLM）的智能代理，用于自动优化无人机通信算法中的超参数，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前无人机通信算法中超参数调优方法依赖启发式策略，自动化程度低且性能不佳，亟需一种更高效的解决方案。

研究方法: 设计了一个LLM代理，通过配置文件初始化任务背景和输出格式，结合迭代框架和模型上下文协议（MCP），驱动WS-PSO-CM算法进行超参数探索，最终自主终止并返回最优参数。

研究结果: 实验表明，LLM代理生成的超参数在最小总速率上显著优于人工启发式和随机生成方法。

研究结论: 具备PSO知识和WS-PSO-CM算法背景的LLM代理能有效找到高性能超参数，为自动化调优提供了新思路。

中文摘要: 超参数对通信算法的性能至关重要。然而，当前针对无人机轨迹和通信的WS-PSO-CM算法的超参数调优方法主要依赖启发式策略，自动化程度低且性能不理想。本文设计了一种基于大型语言模型（LLM）的智能代理，用于自动调优超参数，采用了迭代框架和模型上下文协议（MCP）。具体而言，LLM代理首先通过配置文件初始化任务背景和输出格式，随后根据提示需求驱动，迭代调用WS-PSO-CM算法进行探索，最终自主终止循环并返回一组超参数。实验结果表明，LLM代理生成的超参数在最小总速率上显著优于人工启发式和随机生成方法，表明具备PSO知识和WS-PSO-CM算法背景的LLM代理在寻找高性能超参数方面具有实用价值。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [217] [Efficient Serving of LLM Applications with Probabilistic Demand Modeling](https://arxiv.org/abs/2506.14851)
**中文标题：基于概率需求建模的高效LLM应用服务方法**

*Yifei Liu,Zuo Gan,Zhenghao Gan,Weiye Wang,Chen Chen,Yizhou Shan,Xusheng Chen,Zhenhua Han,Yifei Zhu,Shixuan Sun,Minyi Guo*

主要分类: cs.DC

摘要简述: 本文提出了一种基于概率需求图（PDGraph）的高效服务大型语言模型（LLM）应用的方法，通过Hermes系统优化调度顺序和预热后端，显著提升了服务效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有系统将LLM应用的资源需求视为黑箱，导致调度顺序不当和后端预热延迟，影响端到端效率。本文旨在通过概率需求建模解决这一问题。

研究方法: 提出概率需求图（PDGraph）模型，并基于此设计Hermes系统，利用Gittins策略优化调度顺序，同时通过PDGraph模型在适当时机预热后端。

研究结果: 实验表明，Hermes能将LLM应用的平均完成时间降低70%以上，P95完成时间降低80%以上。

研究结论: Hermes通过概率需求建模和智能调度，显著提升了LLM应用的服务效率，为动态需求场景提供了高效解决方案。

中文摘要: 基于大型语言模型（LLM）的应用通过一系列任务解决现实问题，但其动态需求在不同后端上变化显著。现有服务系统将LLM应用的资源需求视为黑箱，导致调度顺序不当和后端预热延迟，影响端到端效率。研究发现，LLM应用的资源需求可通过概率需求图（PDGraph）进行通用且准确的建模。为此，本文提出Hermes系统，利用PDGraph实现高效服务。面对概率需求描述，Hermes采用Gittins策略确定调度顺序以最小化平均应用完成时间，并借助PDGraph模型在适当时机预热后端。多样化的LLM应用实验证实，Hermes能显著提升服务效率，平均完成时间降低70%以上，P95完成时间降低80%以上。

</details>


### [218] [Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching](https://arxiv.org/abs/2506.14852)
**中文标题：通过测试时计划缓存实现LLM代理的高效低成本服务**

*Qizheng Zhang,Michael Wornow,Kunle Olukotun*

主要分类: cs.DC

摘要简述: 本文提出了一种名为“代理计划缓存”的新方法，通过提取、存储和重用结构化计划模板，显著降低了基于LLM的代理应用的服务成本，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 基于LLM的代理应用在复杂工作流程中表现出色，但其高昂的规划和推理成本限制了实际应用。现有的LLM缓存技术（如上下文缓存和语义缓存）主要针对聊天机器人设计，无法满足代理应用的需求，因为代理的输出依赖于外部数据或环境上下文。因此，需要一种新的缓存方法来解决这一问题。

研究方法: 本文提出代理计划缓存方法，通过从代理执行的规划阶段提取结构化计划模板，并在语义相似的任务中存储和重用这些模板。系统在测试时从已完成的任务中提取计划模板，使用关键词提取匹配新请求与缓存计划，并通过轻量级模型将模板适配为任务特定的计划。

研究结果: 在多个实际代理应用中的评估表明，该方法平均可降低46.62%的成本，同时保持性能，为基于LLM的代理服务提供了更高效的解决方案。

研究结论: 代理计划缓存是一种高效且成本效益显著的解决方案，能够显著降低基于LLM的代理应用的服务成本，同时保持性能，是对现有LLM服务基础设施的有力补充。

中文摘要: 基于LLM的代理应用在复杂工作流程中展现出卓越能力，但由于其大量的规划和推理需求，成本高昂。现有的LLM缓存技术（如上下文缓存和语义缓存）主要针对聊天机器人设计，无法满足代理应用的需求，因为代理的输出依赖于外部数据或环境上下文。我们提出了一种名为代理计划缓存的新方法，通过从代理应用的规划阶段提取、存储、适配和重用结构化计划模板，以降低服务成本。与传统语义缓存不同，我们的系统在测试时从已完成的代理执行中提取计划模板，使用关键词提取匹配新请求与缓存计划，并通过轻量级模型将这些模板适配为任务特定的计划。在多个实际代理应用中的评估表明，我们的系统平均可降低46.62%的成本，同时保持性能，为基于LLM的代理服务提供了更高效的解决方案，是对现有LLM服务基础设施的有力补充。

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [219] [Identifiability by common backdoor in summary causal graphs of time series](https://arxiv.org/abs/2506.14862)
**中文标题：时间序列摘要因果图中通过共同后门的可识别性**

*Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier*

主要分类: math.ST

摘要简述: 本文研究了时间序列中基于共同后门集的干预可识别性问题，提出了在抽象因果图条件下判断可识别性的条件和算法。


<details>
  <summary>详细信息</summary>
研究动机: 干预的可识别性问题旨在评估某些干预的总效应是否可以通过无干预公式表示，从而仅从观测数据中计算。本文在时间序列背景下，研究多干预和多效应的可识别性，尤其是在仅能获得抽象因果图的情况下。

研究方法: 研究聚焦于通过共同后门集实现可识别性，针对时间序列（包括时间一致性和非一致性的情况），建立了存在共同后门集的条件，并提供了有限复杂度的算法来判断问题是否可识别。

研究结果: 本文确立了时间序列中基于共同后门集的干预可识别性条件，并开发了高效算法用于判断可识别性。

研究结论: 在抽象因果图和时间序列的背景下，本文为干预可识别性问题提供了理论条件和实用算法，拓展了因果推断的应用范围。

中文摘要: 干预的可识别性问题旨在评估某些给定干预的总效应是否可以通过无干预公式表示，从而仅从观测数据中计算。我们在时间序列的背景下研究这一问题，考虑多干预和多效应，且仅能获得真实因果图的抽象形式（即摘要因果图）。本研究聚焦于通过共同后门集实现可识别性，并针对时间序列（包括时间一致性和非一致性的情况），建立了存在共同后门集的条件。此外，我们还提供了复杂度有限的算法，用于判断问题是否可识别。

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [220] [Forecasting the spatiotemporal evolution of fluid-induced microearthquakes with deep learning](https://arxiv.org/abs/2506.14923)
**中文标题：基于深度学习的流体诱发微地震时空演化预测**

*Jaehong Chung,Michael Manga,Timothy Kneafsey,Tapan Mukerji,Mengsu Hu*

主要分类: physics.geo-ph

摘要简述: 本文提出了一种基于Transformer的深度学习模型，用于预测流体诱发微地震的时空演化，应用于增强地热系统等场景，取得了高精度的预测结果。


<details>
  <summary>详细信息</summary>
研究动机: 微地震（MEQs）记录了地下流体注入过程中储层的应力状态和渗透性变化，准确预测其时空演化对于增强地热系统（EGS）、二氧化碳封存等地质工程应用至关重要。

研究方法: 作者开发了一种基于Transformer的深度学习模型，利用水力压裂历史和先前的微地震观测数据，预测四个关键指标：累积微地震数量、累积对数地震矩以及微地震云的50%和95%分布范围（P50, P95）。

研究结果: 在EGS Collab实验数据集上，模型在1秒预测时间范围内R²>0.98，15秒预测时间范围内R²>0.88，并通过学习标准差项提供不确定性估计。

研究结论: 该模型能够实时推断裂缝扩展和渗透性演化，展示了深度学习在地震风险评估和流体注入操作中的潜力。

中文摘要: 地下流体注入产生的微地震（MEQs）记录了储层的应力状态和渗透性变化。预测其完整的时空演化对于增强地热系统（EGS）、二氧化碳封存和其他地质工程应用至关重要。我们提出了一种基于Transformer的深度学习模型，通过输入水力压裂历史和先前的微地震观测数据，预测四个关键指标：累积微地震数量、累积对数地震矩以及微地震云的50%和95%分布范围（P50, P95）。在EGS Collab实验1数据集上，模型在1秒预测时间范围内R²>0.98，15秒预测时间范围内R²>0.88，并通过学习标准差项提供不确定性估计。这些高精度且量化不确定性的预测结果能够实时推断裂缝扩展和渗透性演化，展示了深度学习在改善地震风险评估和指导未来流体注入操作中的强大潜力。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [221] [Deploying and Evaluating Multiple Deep Learning Models on Edge Devices for Diabetic Retinopathy Detection](https://arxiv.org/abs/2506.14834)
**中文标题：在边缘设备上部署和评估多种深度学习模型用于糖尿病视网膜病变检测**

*Akwasi Asare,Dennis Agyemanh Nana Gookyi,Derrick Boateng,Fortunatus Aabangbio Wulnye*

主要分类: eess.IV

摘要简述: 本研究提出了一种基于边缘计算的深度学习模型部署方案，用于实时检测糖尿病视网膜病变（DR）。通过优化多种CNN模型（如MobileNet、ShuffleNet等）并量化至8位整数，在边缘设备上实现了高精度和低延迟的诊断，为资源有限的医疗环境提供了可扩展的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 糖尿病视网膜病变（DR）是全球糖尿病患者视力损害的主要原因，传统诊断方法耗时且资源密集。本研究旨在利用边缘计算技术，开发一种高效、实时的DR检测方案，以应对资源受限的医疗环境需求。

研究方法: 研究使用Kaggle EyePACS数据集中的3,662张视网膜眼底图像，通过预处理（增强和归一化）优化数据。利用TensorFlow设计了多种CNN模型（MobileNet、ShuffleNet、SqueezeNet和自定义DNN），并转换为TensorFlowLite格式，量化至8位整数以减少模型大小并提升推理速度。模型在不同边缘硬件平台上进行了性能评估。

研究结果: MobileNet准确率达96.45%，SqueezeNet在GPU上仅需17毫秒延迟且模型大小为176 KB，表现出色。ShuffleNet和自定义DNN在资源效率上表现优异，适合低端设备。

研究结论: 边缘AI技术为DR早期检测提供了可扩展、经济高效的解决方案，尤其适用于资源有限的医疗环境，能够实现及时且准确的诊断。

中文摘要: 糖尿病视网膜病变（DR）是糖尿病患者视力损害的主要原因，全球约34.6%的糖尿病患者受其影响，预计到2045年病例数将达2.42亿。传统DR诊断依赖人工检查视网膜眼底图像，耗时且资源密集。本研究提出了一种基于Edge Impulse的新方案，通过在边缘设备上部署多种深度学习模型实现实时DR检测。研究使用Kaggle EyePACS数据集中的3,662张视网膜眼底图像，并通过预处理技术（如增强和归一化）优化数据。利用TensorFlow设计了多种卷积神经网络（CNN），包括MobileNet、ShuffleNet、SqueezeNet和自定义深度神经网络（DNN），并转换为TensorFlowLite格式，量化至8位整数以减少模型大小并提升推理速度，同时保持高精度。在不同边缘硬件平台（如智能手机和微控制器）上的性能评估中，MobileNet准确率达96.45%，SqueezeNet在GPU上仅需17毫秒延迟且模型大小为176 KB，表现出色。ShuffleNet和自定义DNN在资源效率上表现优异，适合低端设备。边缘AI技术与医疗的结合为DR早期检测提供了可扩展、经济高效的解决方案，尤其适用于资源有限的医疗环境，能够实现及时且准确的诊断。

</details>


### [222] [Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)](https://arxiv.org/abs/2506.14909)
**中文标题：基于面部照片的健康识别基础人工智能模型（FAHR-Face）**

*Fridolin Haugg,Grace Lee,John He,Leonard Nürnberg,Dennis Bontempi,Danielle S. Bitterman,Paul Catalano,Vasco Prudente,Dmitrii Glubokov,Andrew Warrington,Suraj Pai,Dirk De Ruysscher,Christian Guthier,Benjamin H. Kann,Vadim N. Gladyshev,Hugo JWL Aerts,Raymond H. Mak*

主要分类: eess.IV

摘要简述: FAHR-Face是一种基于面部图像的基础AI模型，通过训练超过4000万张面部图像，分别用于生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）。模型在公开数据集和癌症患者数据中表现优异，且具有跨年龄、性别、种族和癌症亚组的普适性。


<details>
  <summary>详细信息</summary>
研究动机: 面部外观为健康监测提供了非侵入性窗口。本研究旨在开发一种基础AI模型，通过面部图像捕捉生物衰老和疾病相关死亡风险，为临床提供低成本、可扩展的生物标志物。

研究方法: FAHR-FaceAge通过两阶段年龄平衡微调训练于749,935张公开图像；FAHR-FaceSurvival微调于34,389张癌症患者照片。模型测试了鲁棒性（如化妆、姿势、光照）和独立性（显著性映射），并在两个独立癌症患者数据集中进行临床验证。

研究结果: FAHR-FaceAge在公开数据集上平均绝对误差为5.1年，优于基准模型；FAHR-FaceSurvival能稳健预测死亡率，最高风险组死亡率是最低组的3倍以上（调整风险比3.22）。两种模型在独立队列中验证有效，且提供互补的预后信息。

研究结论: 单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物衰老和疾病相关死亡风险。该模型支持小规模临床数据集的有效训练。

中文摘要: 背景：面部外观为健康监测提供了非侵入性窗口。我们开发了FAHR-Face，一种基于超过4000万张面部图像训练的基础模型，并针对两项任务进行了微调：生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）。
方法：FAHR-FaceAge在749,935张公开图像上进行了两阶段年龄平衡微调；FAHR-FaceSurvival在34,389张癌症患者照片上微调。模型测试了鲁棒性（如化妆、姿势、光照）和独立性（显著性映射）。两种模型在两个独立癌症患者数据集中进行了临床测试，生存分析通过多变量Cox模型调整临床预后因素。
结果：在年龄估计中，FAHR-FaceAge在公开数据集上的平均绝对误差为5.1年，优于基准模型，并在全生命周期内保持准确性。在癌症患者中，FAHR-FaceAge在生存预后方面优于先前面部年龄估计模型。FAHR-FaceSurvival能稳健预测死亡率，最高风险组死亡率是最低组的3倍以上（调整风险比3.22；P<0.001）。这些发现在独立队列中得到验证，且两种模型在年龄、性别、种族和癌症亚组中具有普适性。两种算法提供了互补的预后信息；显著性映射显示每种模型依赖不同的面部区域。FAHR-FaceAge和FAHR-FaceSurvival的组合提高了预后准确性。
解释：单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物衰老和疾病相关死亡风险。该模型支持小规模临床数据集的有效训练。

</details>


### [223] [Empirical Studies of Large Scale Environment Scanning by Consumer Electronics](https://arxiv.org/abs/2506.14771)
**中文标题：消费电子设备大规模环境扫描的实证研究**

*Mengyuan Wang,Yang Liu,Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

主要分类: eess.IV

摘要简述: 本文对消费级3D扫描设备Matterport Pro3在大规模环境重建中的表现进行了实证评估，通过扫描六层建筑（17,567平方米）并分析其性能、局限性和改进方法，展示了该设备在成本效益与性能之间的平衡及其高质量3D建模能力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估消费级3D扫描设备Matterport Pro3在大规模环境重建中的实际表现，探索其性能、局限性及改进方法，为相关应用提供参考。

研究方法: 研究对六层建筑（17,567平方米）进行了1,099个扫描点的详细扫描，分析了Matterport Pro3的性能、局限性，并提出了改进方法。同时，与iPhone进行了对比分析。

研究结果: Matterport Pro3生成了1,877,324个点的密集点云，优于iPhone的506,961个点，且对齐精度更高（RMSE为0.0118米）。两设备点云模型的平均距离误差为0.0408米，标准差为0.0715米。

研究结论: Matterport Pro3能够生成适合大规模应用的高质量3D模型，其LiDAR和先进对齐技术使其在成本效益与性能之间取得了良好平衡。

中文摘要: 本文对消费级3D扫描设备Matterport Pro3在大规模环境重建中的表现进行了实证评估。我们详细扫描了一栋六层建筑（17,567平方米，共1,099个扫描点），评估了该设备的有效性、局限性及在不同场景下的性能改进。研究中遇到的挑战通过提出的解决方案得到解决，并探索了更有效的克服方法。与另一款消费级设备（iPhone）的对比分析显示，Pro3在成本效益与性能之间取得了平衡。Matterport Pro3生成了1,877,324个点的密集点云，优于iPhone的506,961个点，且对齐精度更高（RMSE为0.0118米）。两设备点云模型的云到云（C2C）平均距离误差为0.0408米，标准差为0.0715米。研究表明，Pro3能够利用LiDAR和先进对齐技术生成适合大规模应用的高质量3D模型。

</details>


### [224] [Improving Prostate Gland Segmenting Using Transformer based Architectures](https://arxiv.org/abs/2506.14844)
**中文标题：基于Transformer架构的前列腺腺体分割改进研究**

*Shatha Abudalou*

主要分类: eess.IV

摘要简述: 本研究探讨了基于Transformer架构的模型（UNETR和SwinUNETR）在前列腺腺体分割任务中的表现，发现SwinUNETR在多种训练策略下均优于传统3D UNet模型，尤其在减少标签噪声和类别不平衡敏感性方面表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 前列腺腺体的自动分割在T2加权MRI图像中面临读者间变异性和跨站点域偏移的挑战。本研究旨在验证Transformer模型是否能在这种异质性中保持高精度。

研究方法: 研究比较了UNETR和SwinUNETR与基线3D UNet模型在前列腺腺体分割任务中的表现。采用了三种训练策略：单队列数据集、5折交叉验证混合队列和基于腺体大小的数据集。超参数通过Optuna优化，测试集来自独立读者群体，以Dice相似系数为评估指标。

研究结果: 在单读者训练中，SwinUNETR的平均Dice分数为0.816（Reader#1）和0.860（Reader#2），优于UNETR和基线UNet。在交叉验证混合训练中，SwinUNETR表现更优，尤其在基于腺体大小的子集中（Dice分数达0.902和0.894）。

研究结论: 研究表明，全局和移位窗口自注意力机制能有效减少标签噪声和类别不平衡敏感性，SwinUNETR的Dice分数比CNN模型提高多达5分，同时保持计算效率，适合临床部署。

中文摘要: 读者间变异性和跨站点域偏移对使用T2加权MRI图像自动分割前列腺腺体提出了挑战。本研究探讨了Transformer模型是否能在这种异质性中保持精度。我们比较了UNETR和SwinUNETR与之前3D UNet模型在前列腺腺体分割中的表现，基于546个由两位独立专家标注的MRI（T2加权）体积数据。分析了三种训练策略：单队列数据集、5折交叉验证混合队列和基于腺体大小的数据集。超参数通过Optuna优化，测试集来自独立读者群体，以Dice相似系数为评估终点。在单读者训练中，SwinUNETR的平均Dice分数为0.816（Reader#1）和0.860（Reader#2），而UNETR分别为0.8和0.833，基线UNet为0.825和0.851。在交叉验证混合训练中，SwinUNETR的平均Dice分数为0.8583（Reader#1）和0.867（Reader#2）。在基于腺体大小的数据集中，SwinUNETR在较大腺体子集中的平均Dice分数为0.902（Reader#1）和0.894（Reader#2），而UNETR表现较差。我们的发现表明，全局和移位窗口自注意力机制能有效减少标签噪声和类别不平衡敏感性，使Dice分数比CNN模型提高多达5分，同时保持计算效率。这为SwinUNETR在临床部署中的高鲁棒性提供了支持。

</details>


### [225] [Recursive Variational Autoencoders for 3D Blood Vessel Generative Modeling](https://arxiv.org/abs/2506.14914)
**中文标题：递归变分自编码器用于3D血管生成建模**

*Paula Feldman,Miguel Fainstein,Viviana Siless,Claudio Delrieux,Emmanuel Iarussi*

主要分类: eess.IV

摘要简述: 本文提出了一种递归变分自编码器（RvNN），用于生成3D血管模型，能够准确捕捉血管的复杂拓扑和几何特征，为医学应用提供多样且真实的血管结构。


<details>
  <summary>详细信息</summary>
研究动机: 解剖树结构在临床诊断和治疗规划中至关重要，但现有方法多为基于规则，难以捕捉真实血管的多样性和复杂性。因此，需要一种能够生成准确且多样血管模型的技术。

研究方法: 开发了一种递归变分神经网络（RvNN），利用血管的层次结构，学习低维流形编码分支连接性和几何特征，通过采样潜在空间生成新的血管几何模型。

研究结果: 生成的3D血管模型在半径、长度和弯曲度等方面与真实数据高度相似，适用于医学培训、血流模拟等多种用途，且在包含动脉瘤的数据集中表现优异。

研究结论: RvNN首次成功应用于血管合成，生成的模型既准确又多样，为医学领域提供了重要工具。

中文摘要: 解剖树结构在临床诊断和治疗规划中具有重要作用，但由于其复杂的拓扑和几何特征，准确表示这些结构具有挑战性。现有的血管合成方法多为基于规则，虽然能提供一定程度的控制和变化，但无法捕捉真实解剖数据的多样性和复杂性。我们开发了一种递归变分神经网络（RvNN），充分利用血管的层次结构，学习编码分支连接性和描述目标表面的几何特征的低维流形。训练后，RvNN的潜在空间可通过采样生成新的血管几何模型。借助生成神经网络的能力，我们生成了既准确又多样的3D血管模型，这对医学和手术培训、血流模拟等多种用途至关重要。这些结果与真实数据高度相似，在血管半径、长度和弯曲度等方面表现优异，包括包含动脉瘤的数据集。据我们所知，本研究首次将这一技术应用于血管合成。

</details>


### [226] [NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal Neurological Disorder Classification](https://arxiv.org/abs/2506.14970)
**中文标题：NeuroMoE：一种基于Transformer的混合专家框架用于多模态神经疾病分类**

*Wajih Hassan Raza,Aamir Bader Shah,Yu Wen,Yidan Shen,Juan Diego Martinez Lemus,Mya Caryn Schiess,Timothy Michael Ellmore,Renjie Hu,Xin Fu*

主要分类: eess.IV

摘要简述: 本文提出了一种基于Transformer的混合专家框架NeuroMoE，用于多模态神经疾病分类，结合多模态MRI和临床数据，显著提升了诊断准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的深度学习方法在多模态MRI和临床数据的整合上表现不佳，导致诊断效果不理想。本文旨在通过结合多模态数据和创新的混合专家框架，提升神经疾病的分类性能。

研究方法: 利用专有的多模态临床数据集，提出基于Transformer的混合专家框架，整合解剖MRI、扩散张量成像和功能MRI等多模态数据，通过模态特异性专家提取特征，并使用自适应融合门控机制动态整合专家输出。

研究结果: 实验表明，该框架在多模态神经疾病分类中表现优异，验证准确率达到82.47%，比基线方法提升超过10%。

研究结论: NeuroMoE框架通过多模态学习和自适应融合机制，显著提升了神经疾病的诊断准确性，展示了其在临床实践中的潜力。

中文摘要: 多模态磁共振成像（MRI）与临床数据的结合为提升神经疾病（NDs）的诊断提供了巨大潜力。深度学习（DL）已成为从医学数据中提取有意义模式以辅助诊断的强大工具。然而，现有DL方法在多模态MRI和临床数据的有效利用上表现不佳，导致诊断效果不理想。为解决这一问题，我们利用专为ND研究定制的独特多模态临床数据集，提出了一种基于Transformer的混合专家（MoE）框架，用于ND分类。该框架整合了解剖MRI（aMRI）、扩散张量成像（DTI）和功能MRI（fMRI）等多模态数据以及临床评估。通过Transformer编码器捕捉体积MRI数据的空间关系，同时利用模态特异性专家进行针对性特征提取。自适应融合门控机制动态整合专家输出，确保最优预测性能。全面的实验和与多种基线的比较表明，我们的多模态方法显著提升了诊断准确性，尤其在区分重叠疾病状态方面。该框架的验证准确率达到82.47%，比基线方法提升超过10%，展示了其在通过多模态学习改善ND诊断方面的潜力。

</details>


### [227] [Classification of Multi-Parametric Body MRI Series Using Deep Learning](https://arxiv.org/abs/2506.15182)
**中文标题：基于深度学习的多参数身体MRI序列分类**

*Boah Kim,Tejas Sudharshan Mathai,Kimberly Helm,Peter A. Pinto,Ronald M. Summers*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的分类模型，用于准确分类8种不同的多参数MRI序列，以提升放射科医生的工作效率。实验表明，DenseNet-121模型在内部和外部数据集上均表现出色，最高准确率达0.972。


<details>
  <summary>详细信息</summary>
研究动机: 多参数MRI（mpMRI）检查的DICOM头文件常因协议多样性和技术员错误而包含不准确信息，导致放射科医生阅读效率低下。本文旨在通过深度学习模型自动分类MRI序列，解决这一问题。

研究方法: 使用来自多个机构的mpMRI数据，训练了ResNet、EfficientNet和DenseNet等深度学习分类器，比较其性能。研究了不同训练数据量对模型性能的影响，并在外部数据集上评估模型表现。

研究结果: DenseNet-121模型表现最佳，F1分数和准确率分别为0.966和0.972。当训练数据量超过729项时，模型准确率超过0.95，且性能随数据量增加而提升。在外部数据集DLDS和CPTAC-UCEC上，准确率分别为0.872和0.810。

研究结论: DenseNet-121模型在多参数MRI序列分类任务中表现出高准确性和鲁棒性，适用于临床环境。

中文摘要: 多参数磁共振成像（mpMRI）检查包含多种不同成像协议的序列类型。由于协议多样性及技术员操作错误，这些序列的DICOM头文件常包含不准确信息。为此，我们提出了一种基于深度学习的分类模型，用于分类8种不同的身体mpMRI序列，以提高放射科医生的阅读效率。利用来自多个机构的mpMRI数据，我们训练了ResNet、EfficientNet和DenseNet等多种深度学习分类器，并比较其性能。随后，确定了性能最佳的分类器，并研究了不同训练数据量对其分类能力的影响。此外，模型还在训练分布之外的数据集上进行了评估。我们还尝试了两种训练策略，使用来自不同扫描仪的mpMRI数据训练模型，并测试其性能。实验结果表明，DenseNet-121模型的F1分数和准确率最高，分别为0.966和0.972（p值<0.05）。当训练数据量超过729项时，模型准确率超过0.95，且性能随数据量增加而提升。在外部数据集DLDS和CPTAC-UCEC上，模型的准确率分别为0.872和0.810。这些结果表明，无论是在内部还是外部数据集上，DenseNet-121模型在分类8种身体MRI序列类型的任务中均表现出高准确性。

</details>


### [228] [Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference](https://arxiv.org/abs/2506.15258)
**中文标题：基于同态加密的潜在空间胸部X光分类隐私保护方法**

*Jonghun Kim,Gyeongdeok Jo,Shinyoung Ra,Hyunjin Park*

主要分类: eess.IV

摘要简述: 本文提出一种基于同态加密（HE）的医疗图像隐私保护分类方法，通过VQGAN压缩图像为潜在表示，降低计算负担，同时保持图像质量。结合多项式近似激活函数和优化的压缩因子，方法在胸部X光数据集上验证了实用潜力。


<details>
  <summary>详细信息</summary>
研究动机: 医疗影像数据包含敏感患者信息，需严格隐私保护。传统方法需将数据发送至服务器进行推理，存在隐私泄露风险。同态加密（HE）可在加密数据上直接计算，但计算成本高，尤其对大图像（如胸部X光）。本研究旨在解决HE推理的高计算负担问题。

研究方法: 1. 使用VQGAN将图像压缩为潜在表示，显著降低计算负担；2. 用低阶多项式近似激活函数，平衡精度与效率；3. 选择压缩因子为8以优化性能与计算成本；4. 引入挤压激励模块增强HE框架；5. 在胸部X光数据集上测试多标签分类任务。

研究结果: 方法在压缩因子为8时达到性能与计算成本的最佳平衡。尽管HE推理仍较慢且与未加密推理存在微小性能差异，但实验表明该方法在医疗图像中具有实际应用潜力。

研究结论: 本研究提出的HE框架通过潜在空间压缩和优化激活函数，显著降低了医疗图像隐私保护推理的计算负担，为医疗数据的安全分析提供了可行方案。

中文摘要: 医疗影像数据包含敏感患者信息，需严格隐私保护。许多分析场景要求将数据发送至服务器进行推理，而同态加密（HE）允许在加密数据上直接计算，避免信息泄露。然而，HE推理计算成本高，尤其对大图像（如胸部X光）。本研究提出一种HE推理框架，利用VQGAN将图像压缩为潜在表示，显著降低计算负担并保持图像质量。通过低阶多项式近似激活函数，平衡精度与效率以满足HE要求。实验发现压缩因子为8时性能与计算成本达到最佳平衡。进一步引入挤压激励模块增强HE框架。方法在两种胸部X光数据集上测试多标签分类任务，结果显示尽管HE推理较慢且与未加密推理存在微小差异，但具有实际应用潜力。

</details>


### [229] [FedWSIDD: Federated Whole Slide Image Classification via Dataset Distillation](https://arxiv.org/abs/2506.15365)
**中文标题：FedWSIDD：基于数据集蒸馏的联邦全切片图像分类方法**

*Haolong Jin,Shenglin Liu,Cong Cong,Qingmin Feng,Yongzhi Liu,Lina Huang,Yingzi Hu*

主要分类: eess.IV

摘要简述: 本文提出了一种名为FedWSIDD的新型联邦学习方法，通过数据集蒸馏技术解决全切片图像分类中的计算资源异构性和隐私问题。该方法在服务器端聚合合成切片并分发给各中心，客户端则采用一种结合染色归一化的蒸馏算法生成高信息量的合成切片。实验表明，FedWSIDD在提升分类性能的同时保护了患者隐私。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在医学图像分析中具有潜力，但全切片图像分类面临计算资源异构性和隐私问题。本文旨在通过数据集蒸馏技术解决这些问题，提出一种灵活且隐私保护的联邦学习框架。

研究方法: FedWSIDD在服务器端聚合并分发合成切片，客户端采用一种结合染色归一化的数据集蒸馏算法生成合成切片。这些合成切片而非模型参数被传输至服务器，最终与原始切片结合用于本地任务。

研究结果: 在CAMELYON16和CAMELYON17等多个全切片图像分类任务上的实验表明，FedWSIDD能够适应异构本地模型，提升分类性能，并有效保护患者隐私。

研究结论: FedWSIDD为复杂的全切片图像分类任务提供了一种高效、灵活且隐私保护的解决方案。

中文摘要: 联邦学习（FL）已成为一种有前景的协作医学图像分析方法，允许多个机构在保护敏感患者数据的同时构建鲁棒的预测模型。在全切片图像（WSI）分类中，FL面临计算资源异构性和隐私问题等挑战。为解决这些问题，我们提出了FedWSIDD，一种新型的联邦学习范式，利用数据集蒸馏（DD）技术学习和传输合成切片。在服务器端，FedWSIDD聚合来自参与中心的合成切片并分发给所有中心。在客户端，我们提出了一种针对病理数据集的蒸馏算法，将染色归一化融入蒸馏过程，生成一组紧凑且信息丰富的合成切片。这些合成切片而非模型参数被传输至服务器。通信后，接收到的合成切片与原始切片结合用于本地任务。在CAMELYON16和CAMELYON17等多个WSI分类任务上的广泛实验表明，FedWSIDD为异构本地模型提供了灵活性，提升了本地WSI分类性能，并保护了患者隐私。这使其成为复杂WSI分类任务的高效解决方案。代码可在FedWSIDD获取。

</details>


### [230] [A Real-time Endoscopic Image Denoising System](https://arxiv.org/abs/2506.15395)
**中文标题：实时内窥镜图像去噪系统**

*Yu Xing,Shishi Huang,Meng Lv,Guo Chen,Huailiang Wang,Lingzhi Sui*

主要分类: eess.IV

摘要简述: 本文提出了一种实时内窥镜图像去噪系统，通过混合传统图像处理算法与学习技术，有效降低噪声并保持细节，同时实现FPGA平台上的实时性能。


<details>
  <summary>详细信息</summary>
研究动机: 微型内窥镜虽提升了医疗操作的灵活性和便携性，但其小型化传感器导致光子捕获不足，动态范围受限，且电路简化引入额外噪声，亟需高效去噪解决方案。

研究方法: 首先建立了内窥镜模拟图像传感器的综合噪声模型，涵盖固定模式噪声、周期性带状噪声和混合泊松-高斯噪声；随后提出混合去噪系统，结合传统算法与学习技术处理原始图像。

研究结果: 实验表明，该方法显著降低图像噪声，PSNR从21.16提升至33.05，且未损失细节或导致色彩失真，并在FPGA平台上实现实时性能。

研究结论: 所提出的混合去噪系统有效解决了内窥镜图像噪声问题，兼具高性能与实时性，为医疗诊断提供了更清晰的图像支持。

中文摘要: 微型化设计的内窥镜显著提升了操作灵活性、便携性和诊断能力，同时大幅降低了医疗程序的侵入性。近年来，配备超紧凑模拟图像传感器（尺寸小于1mm x 1mm）的一次性内窥镜为医疗诊断带来了革命性进步。它们减少了可重复使用设备的结构冗余和高额资本支出，消除了因消毒不彻底导致的患者感染风险，并减轻了患者痛苦。然而，有限的感光区域导致每个像素捕获的光子减少，需设置更高的光子灵敏度以维持足够亮度。在高对比度医疗成像场景中，小型传感器的动态范围受限，难以同时捕捉高光和阴影细节，需额外局部数字增益补偿。此外，简化的电路设计和模拟信号传输引入了额外噪声源。这些因素共同导致处理后的内窥镜图像存在显著噪声问题。本研究建立了医疗内窥镜模拟图像传感器的综合噪声模型，涵盖三种主要噪声类型：固定模式噪声、周期性带状噪声和混合泊松-高斯噪声。基于此分析，我们提出了一种混合去噪系统，协同结合传统图像处理算法与先进学习技术处理传感器捕获的原始帧。实验表明，该方法有效降低图像噪声且未损失精细细节或导致色彩失真，同时在FPGA平台上实现实时性能，测试数据集的平均PSNR从21.16提升至33.05。

</details>


### [231] [Advanced cervical cancer classification: enhancing pap smear images with hybrid PMD Filter-CLAHE](https://arxiv.org/abs/2506.15489)
**中文标题：高级宫颈癌分类：通过混合PMD滤波器-CLAHE增强Pap涂片图像**

*Ach Khozaimi,Isnani Darti,Syaiful Anam,Wuryansari Muharini Kusumawinahyu*

主要分类: eess.IV

摘要简述: 本研究探讨了混合PMD滤波器-CLAHE预处理技术对宫颈癌分类中CNN性能的提升效果，结果显示该方法显著提高了图像质量和分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 宫颈癌在发展中国家仍是一个严重的健康问题，早期检测对治疗至关重要。尽管CNN在自动化筛查中表现良好，但其性能依赖于Pap涂片图像质量。因此，研究图像预处理技术对CNN性能的影响具有重要意义。

研究方法: 研究使用SIPaKMeD数据集，评估了三种预处理技术：PMD滤波器（去噪）、CLAHE（对比度增强）以及提出的混合PMD滤波器-CLAHE方法。预处理后的图像在多种预训练模型（如ResNet、EfficientNet等）上进行测试。

研究结果: 混合PMD滤波器-CLAHE方法显著提升了图像质量和CNN性能，最大改进为准确率提升13.62%，精确率提升10.04%，召回率提升13.08%，F1分数提升14.34%。

研究结论: 提出的混合PMD滤波器-CLAHE技术为提升宫颈癌分类性能提供了新思路，尤其在图像预处理方面具有显著优势。

中文摘要: 宫颈癌仍然是发展中国家面临的重大健康问题，早期检测对有效治疗至关重要。卷积神经网络（CNN）在自动化宫颈癌筛查中表现出潜力，但其性能依赖于Pap涂片图像质量。本研究利用SIPaKMeD数据集，探讨了不同图像预处理技术对CNN分类性能的影响。评估了三种预处理技术：PMD滤波器（去噪）、CLAHE（对比度增强）以及提出的混合PMD滤波器-CLAHE方法。预处理后的图像在多种预训练模型（如ResNet、EfficientNet等）上进行测试。结果表明，混合PMD滤波器-CLAHE方法能够显著提升Pap涂片图像质量和CNN性能，最大改进为准确率提升13.62%，精确率提升10.04%，召回率提升13.08%，F1分数提升14.34%。该技术为提升宫颈癌分类性能提供了新的视角。

</details>


### [232] [Automated MRI Tumor Segmentation using hybrid U-Net with Transformer and Efficient Attention](https://arxiv.org/abs/2506.15562)
**中文标题：基于混合U-Net与Transformer及高效注意力的MRI肿瘤自动分割**

*Syed Haider Ali,Asrar Ahmad,Muhammad Ali,Asifullah Khan,Muhammad Shahban,Nadeem Shaukat*

主要分类: eess.IV

摘要简述: 本研究提出了一种结合U-Net和Transformer的高效混合模型，用于MRI肿瘤自动分割，并在本地医院数据集上验证了其性能，Dice系数为0.764，IoU为0.736。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI分割模型多基于公开数据集，缺乏对本地患者群体的适应性。本研究旨在开发适用于本地医院的肿瘤分割模型，以优化放疗计划。

研究方法: 采用混合U-Net-Transformer架构，结合高效注意力模块（如SE、CBAM和ResNeXt块），并通过数据增强和预训练权重加速收敛。训练使用双NVIDIA T4 GPU，最大批次为8。

研究结果: 在本地MRI数据集上，模型Dice系数为0.764，IoU为0.736，表现优异，证明了本地化模型开发的重要性。

研究结论: 混合U-Net-Transformer模型在有限数据下表现良好，强调了针对临床环境的模型开发的必要性。

中文摘要: 癌症是一种异常生长，可能局部侵袭并转移至远处器官。放疗计划优化需要准确自动分割肿瘤及周围正常组织。现有基于AI的分割模型多训练于大型公开数据集，缺乏本地患者群体的异质性。尽管这些研究推动了AI医学图像分割的发展，但针对本地数据集的研究对于将AI肿瘤分割模型直接集成至医院软件以实现高效精准的肿瘤治疗计划与执行至关重要。本研究通过计算高效的混合U-Net-Transformer模型，在严格隐私保护下使用本地医院MRI数据集提升肿瘤分割性能。我们开发了稳健的数据流程，实现无缝DICOM提取与预处理，并通过大量图像增强确保模型在多样化临床环境中的泛化能力，最终获得6080张训练图像。新颖的架构结合了基于U-Net的卷积神经网络与Transformer瓶颈及互补注意力模块，包括高效注意力、SE块、CBAM和ResNeXt块。为加速收敛并降低计算需求，我们采用最大批次8，并使用预训练ImageNet权重初始化编码器，通过检查点在双NVIDIA T4 GPU上训练模型以克服Kaggle运行时限制。在本地MRI数据集上的定量评估显示，Dice相似系数为0.764，IoU为0.736，尽管数据有限仍表现出竞争力，凸显了针对临床部署的本地化模型开发的重要性。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [233] [Preparing for the Intelligence Explosion](https://arxiv.org/abs/2506.14863)
**中文标题：为智能爆炸做准备**

*William MacAskill,Fin Moorhouse*

主要分类: cs.CY

摘要简述: 论文探讨了AI加速研究可能带来的技术爆炸，以及由此引发的重大挑战，如大规模杀伤性武器、AI专制等，并呼吁提前准备应对这些挑战。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于AI技术的快速发展可能导致短期内技术爆炸，带来一系列难以逆转的重大决策和挑战，如新型武器、政治变革等，需要提前规划和应对。

研究方法: 论文通过分析AI技术爆炸可能带来的挑战，提出当前应采取的措施，而非完全依赖未来的AI系统。

研究结果: 研究指出，技术爆炸将带来多方面的挑战和机遇，如改善生活质量或引发资源争夺，当前需积极准备以应对这些变化。

研究结论: 论文结论强调，通用人工智能（AGI）的准备不仅关乎AI系统的对齐，还需提前应对技术爆炸可能带来的复杂局面。

中文摘要: 能够加速研究的AI可能在短短几年内推动一个世纪的技术进步。在此期间，新技术或政治发展将迅速引发一系列重大且难以逆转的决策，我们称之为重大挑战。这些挑战包括新型大规模杀伤性武器、AI支持的专制政权、争夺外星资源的竞赛，以及值得道德考量的数字生命，同时也包括大幅提升生活质量和集体决策水平的机会。我们认为这些挑战不能总是委托给未来的AI系统，并提出了当前可以采取的措施以显著改善前景。因此，AGI准备不仅关乎确保先进AI系统的对齐，我们现在就应该为智能爆炸可能带来的复杂局面做好准备。

</details>


### [234] [Hypothesis Testing for Quantifying LLM-Human Misalignment in Multiple Choice Settings](https://arxiv.org/abs/2506.14997)
**中文标题：多项选择场景中量化大型语言模型与人类行为偏差的假设检验**

*Harbin Hong,Sebastian Caldas,Liu Leqi*

主要分类: cs.CY

摘要简述: 本文提出了一种基于假设检验的量化框架，用于评估大型语言模型（LLM）在多项选择场景中与人类行为的偏差，发现模型在模拟争议性问题时与特定人群（如不同种族、年龄和收入）的行为不一致。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在社会科学研究（如经济学和市场营销）中的应用日益增多，评估这些模型是否能准确模拟人类行为变得至关重要。本文旨在通过假设检验量化LLM与人类行为之间的偏差。

研究方法: 作者提出了一种基于假设检验的量化框架，用于评估LLM在多项选择调查中模拟人类行为的能力。该框架通过统计方法判断模型是否能有效模拟人类意见、决策和行为。

研究结果: 研究将框架应用于一个流行的语言模型，发现该模型在模拟争议性问题时与特定人群（如不同种族、年龄和收入）的行为不一致，表明模型与测试人群的匹配度较低。

研究结论: 研究揭示了当前语言模型在模拟人类行为时的局限性，尤其是在争议性问题上的表现不佳，强调了在社会科学研究中需要更谨慎地使用LLM，而非简单模拟人类行为。

中文摘要: 随着大型语言模型（LLM）在社会科学研究（如经济学和市场营销）中的广泛应用，评估这些模型是否能准确模拟人类行为变得至关重要。本文通过假设检验提出了一种量化框架，用于评估LLM在多项选择调查中模拟人类行为的偏差。该框架能够以原则性的方式判断特定语言模型是否能有效模拟人类意见、决策和行为。我们将此框架应用于一个流行的语言模型，用于模拟公众调查中人们的意见，发现该模型在模拟争议性问题时与特定人群（如不同种族、年龄和收入）的行为不一致。这表明该语言模型与测试人群的匹配度较低，凸显了在社会科学研究中需要新的实践方法，而非简单地用LLM模拟人类行为。

</details>


### [235] [Transit for All: Mapping Equitable Bike2Subway Connection using Region Representation Learning](https://arxiv.org/abs/2506.15113)
**中文标题：全民交通：基于区域表征学习的公平自行车接驳地铁地图绘制**

*Min Namgung,JangHyeon Lee,Fangyi Ding,Yao-Yi Chiang*

主要分类: cs.CY

摘要简述: 论文提出Transit for All (TFA)框架，通过区域表征学习预测共享单车需求，结合加权公共交通可达性指标（wPTAL），指导共享单车系统在纽约市低收入和少数族裔社区的公平扩展，以减少交通不平等。


<details>
  <summary>详细信息</summary>
研究动机: 在纽约市等高密度城市，低收入和少数族裔社区的公共交通可达性较差。共享单车系统（BSS）可作为经济实惠的首末公里连接工具，但扩展至未充分服务社区时面临需求预测和传统可达性指标不足的挑战。

研究方法: TFA框架包含三部分：(1) 基于区域表征学习的共享单车需求预测；(2) 结合预测需求和传统指标的新型加权公共交通可达性指标（wPTAL）；(3) 考虑潜在骑行需求和公平性的共享单车站点布局策略。

研究结果: 在纽约市的案例研究中，TFA识别出低收入和少数族裔社区的交通可达性差距，并通过wPTAL指导的新站点布局显著减少了经济和人口因素导致的交通不平等。

研究结论: TFA为城市规划者提供了促进交通公平的实用工具，有助于提升未充分服务社区的生活质量。

中文摘要: 确保公共交通的公平可达性仍具挑战性，尤其是在纽约市等高密度城市，低收入和少数族裔社区常面临交通可达性不足的问题。共享单车系统（BSS）可通过提供经济实惠的首末公里连接弥补这些公平性缺口。然而，由于新规划站点（“冷启动”）的共享单车需求不确定性及传统可达性指标对实际骑行潜力的忽视，将BSS战略性扩展至未充分服务社区存在困难。我们提出“全民交通”（TFA）空间计算框架，通过三部分指导BSS的公平扩展：(1) 利用区域表征学习整合多模态地理空间数据，预测冷启动站点的共享单车需求；(2) 结合预测需求与传统交通可达性指标，提出新型加权公共交通可达性指标（wPTAL）；(3) 综合考虑潜在骑行需求和公平性，提出新站点布局策略。以纽约市为例，我们识别出低收入和少数族裔社区在历史性未充分服务区域的交通可达性差距。结果显示，基于wPTAL指导的新站点布局显著减少了经济和人口因素导致的交通不平等。研究表明，TFA为城市规划者提供了促进交通公平和提升未充分服务社区生活质量的实用指导。

</details>
