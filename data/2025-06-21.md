<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 51]
- [cs.CV](#cs.CV) [Total: 65]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.IT](#cs.IT) [Total: 1]
- [stat.OT](#stat.OT) [Total: 1]
- [math.NA](#math.NA) [Total: 1]
- [cs.DC](#cs.DC) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.HC](#cs.HC) [Total: 9]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cs.CY](#cs.CY) [Total: 3]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.SD](#cs.SD) [Total: 3]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 40]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 6]
- [eess.IV](#eess.IV) [Total: 12]
- [math.ST](#math.ST) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
**中文标题：从出院摘要中提取不良事件：新数据集、标注方案及初步发现**

*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

主要分类: cs.CL

摘要简述: 本文介绍了一个从老年患者出院摘要中手动标注的不良事件（AE）提取数据集，包含14种临床重要AE及上下文属性。研究评估了多种模型在不同标注粒度下的性能，发现尽管文档级粗粒度提取表现优异，但细粒度实体级任务仍面临挑战。数据集可作为AE提取方法的基准。


<details>
  <summary>详细信息</summary>
研究动机: 老年患者在临床NLP资源中代表性不足，现有研究很少处理不连续和重叠实体的标注挑战。本研究旨在填补这一空白，提供一个标注不良事件及其上下文属性的数据集，并评估模型性能。

研究方法: 研究构建了一个手动标注的AE数据集，包含14种临床重要AE及上下文属性（如否定、诊断类型等）。使用FlairNLP评估了多种模型（如BERT-cased）在三种标注粒度（细粒度、粗粒度及带否定的粗粒度）下的性能。

研究结果: 基于Transformer的模型在文档级粗粒度提取中表现优异（F1 = 0.943），但在细粒度实体级任务中性能显著下降（F1 = 0.675），尤其是罕见事件和复杂属性的检测。

研究结论: 尽管文档级粗粒度提取表现良好，但细粒度AE提取仍面临挑战，尤其是在罕见事件和复杂临床语言的检测上。该数据集为未来研究提供了基准。

中文摘要: 本研究提出了一个从老年患者出院摘要中手动标注的不良事件（AE）提取语料库，该群体在临床NLP资源中代表性不足。数据集包含14种临床重要AE（如跌倒、谵妄和颅内出血）及上下文属性（如否定、诊断类型和院内发生）。独特的标注方案支持不连续和重叠实体，解决了先前研究中罕见的挑战。我们使用FlairNLP评估了多种模型在三种标注粒度（细粒度、粗粒度及带否定的粗粒度）下的性能。基于Transformer的模型（如BERT-cased）在文档级粗粒度提取中表现优异（F1 = 0.943），但在细粒度实体级任务中性能显著下降（F1 = 0.675），尤其是罕见事件和复杂属性的检测。这些结果表明，尽管高分表现，但在检测代表性不足的AE和捕捉细微临床语言方面仍存在重大挑战。该数据集在可信研究环境（TRE）中开发，可通过DataLoch请求获取，为评估AE提取方法和支持未来跨数据集泛化提供了稳健基准。

</details>


### [2] [Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction](https://arxiv.org/abs/2506.14901)
**中文标题：结合约束与无约束解码的增强方法：BoostCD及其在信息提取中的应用**

*Marija Šakota,Robert West*

主要分类: cs.CL

摘要简述: 本文提出了一种结合约束解码和无约束解码的增强方法BoostCD，通过两阶段解码提升结构化NLP任务的性能，并在信息提取任务中验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有结构化NLP任务中，约束解码虽能动态调整输出结构，但可能导致测试时输出质量下降。本文旨在通过结合约束和无约束解码，提升模型性能。

研究方法: BoostCD分为两阶段：第一阶段通过基础模型分别进行约束和无约束解码，生成两个弱预测；第二阶段通过增强模型结合这两个预测，生成最终结果。

研究结果: 在封闭信息提取任务中，BoostCD方法（BoostIE）优于现有方法，分布内外均表现优异，解决了常见错误。

研究结论: BoostCD通过结合约束和无约束解码，显著提升了结构化NLP任务的性能，为动态约束解码提供了新思路。

中文摘要: 近年来，许多结构化NLP任务采用自回归语言模型$M$将非结构化输入文本$x$映射为表示结构化对象（如元组、列表、树、代码等）的输出文本$y$，并通过约束解码强制输出结构。训练时，这些方法无需模型了解约束条件，约束仅隐含在训练输出$y$中。这种方法的优势在于支持动态约束而无需重新训练，但可能导致测试时约束解码输出质量较低。我们通过增强约束解码（BoostCD）解决了这一问题，该方法分两阶段结合约束和无约束解码：第一阶段通过基础模型$M$分别进行约束和无约束解码，生成两个弱预测；第二阶段通过学习的自回归增强模型将两个弱预测结合为最终预测。基础模型在有无约束时的错误往往是互补的，增强模型能够利用这一点提升性能。我们通过将其应用于封闭信息提取验证了BoostCD的有效性。我们的模型BoostIE在分布内外均优于现有方法，解决了这些方法中的常见错误。

</details>


### [3] [CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision](https://arxiv.org/abs/2506.14912)
**中文标题：CrEst：基于弱监督的大型语言模型上下文可信度估计**

*Dyah Adila,Shuai Zhang,Boran Han,Bonan Min,Yuyang Wang*

主要分类: cs.CL

摘要简述: 本文提出CrEst框架，通过弱监督方法评估大型语言模型（LLM）中上下文文档的可信度，无需人工标注。实验表明，CrEst在多种模型和数据集上显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在利用上下文信息提升LLM性能时，常忽略文档可信度的差异，可能导致不可靠信息的传播。本文旨在解决这一问题。

研究方法: CrEst通过文档间语义一致性自动评估可信度，并提出两种集成策略：黑盒方法（无模型内部访问）和白盒方法（修改注意力机制）。

研究结果: 实验显示，CrEst在三种模型架构和五个数据集上表现优异，准确率提升26.86%，F1分数提高3.49%，且在高噪声条件下仍保持稳健。

研究结论: CrEst为LLM上下文可信度评估提供了一种高效且无需人工标注的解决方案，显著提升了模型性能。

中文摘要: 上下文信息的整合显著提升了大型语言模型（LLMs）在知识密集型任务中的表现。然而，现有方法常忽视一个关键挑战：上下文文档的可信度差异较大，可能导致不可靠信息的传播。本文提出CrEst，一种新颖的弱监督框架，用于在LLM推理过程中评估上下文文档的可信度——无需人工标注。我们的方法基于一个核心观察：可信文档往往与其他可信文档具有更高的语义一致性，从而通过文档间一致性实现自动可信度评估。为将可信度融入LLM推理，我们提出两种集成策略：黑盒方法（适用于无法访问内部权重或激活的模型）和白盒方法（直接修改注意力机制）。在三种模型架构和五个数据集上的广泛实验表明，CrEst始终优于强基线，准确率最高提升26.86%，F1分数提高3.49%。进一步分析显示，CrEst在高噪声条件下仍保持稳健性能。

</details>


### [4] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
**中文标题：MDBench：基于知识引导生成的多文档推理合成基准**

*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

主要分类: cs.CL

摘要简述: 本文介绍了MDBench，一个用于评估大语言模型在多文档推理任务上的新数据集。该数据集通过创新的合成生成方法创建，能够高效生成具有挑战性的文档集和对应的问题-答案示例。研究发现，MDBench对现有模型和提示技术均构成显著挑战。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLMs）推理能力的快速扩展，多文档（MD）推理领域的评估需求日益迫切。然而，由于长文本标注成本高昂，现有基准测试较少。本文旨在填补这一空白，提出一种高效且可控的多文档推理评估方法。

研究方法: MDBench通过一种新颖的合成生成方法创建，利用结构化种子知识，通过LLM辅助编辑引入多文档特有的推理挑战，并将其转换为自然文本形式，生成文档集和对应的问题-答案示例。

研究结果: 研究发现，MDBench对现有流行的大语言模型和提示技术均构成显著挑战，即使文档集较短。此外，知识引导的生成技术能够快速适应新的挑战和未来模型改进。

研究结论: MDBench为多文档推理任务提供了一个高效且可控的评估基准，其生成方法不仅能够针对特定推理能力进行分析，还能快速适应未来需求。

中文摘要: 自然语言处理评估取得了显著进展，主要得益于强大大型语言模型（LLMs）的普及。随着LLMs推理能力的快速扩展，新的评估基准变得尤为重要。多文档（MD）推理是一个极具相关性的领域，但目前缺乏严格的基准测试来评估模型在此场景下的表现。此外，多文档场景的基准创建历来具有挑战性，因为长文本标注成本高昂。本文介绍了MDBench，一个用于评估LLMs在多文档推理任务上的新数据集。MDBench通过一种创新的合成生成方法创建，能够高效且可控地生成具有挑战性的文档集和对应的问题-答案（QA）示例。我们的新技术基于结构化种子知识，通过LLM辅助编辑引入多文档特有的推理挑战，并将其转换为自然文本形式，生成文档集和对应QA示例。我们分析了流行LLMs和提示技术的表现，发现MDBench对所有方法均构成显著挑战，即使文档集较短。此外，我们的知识引导生成技术（1）能够针对多文档特有的推理能力进行定向分析，（2）可以快速适应新的挑战和未来模型改进。

</details>


### [5] [From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?](https://arxiv.org/abs/2506.14949)
**中文标题：从聊天到检查：大型语言模型能否辅助糖尿病预测？**

*Shadman Sakib,Oishy Fatema Akhand,Ajwad Abrar*

主要分类: cs.CL

摘要简述: 本研究探讨了大型语言模型（LLMs）在糖尿病预测中的潜力，测试了零样本、单样本和三样本提示方法，并比较了开源与专有LLMs的性能。结果显示专有LLMs表现更优，但需进一步优化提示策略和领域微调。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习和深度学习模型已广泛用于糖尿病预测，但LLMs在结构化数值数据中的应用尚未充分探索。本研究旨在填补这一空白，验证LLMs在医疗预测任务中的有效性。

研究方法: 研究使用Pima印第安糖尿病数据库（PIDD），测试了六种LLMs（包括开源和专有模型）以及三种传统机器学习模型。评估指标包括准确率、精确率、召回率和F1分数，并采用零样本、单样本和三样本提示方法。

研究结果: 专有LLMs（如GPT-4o和Gemma-2-27B）在少样本设置下表现优于开源模型，且Gemma-2-27B的F1分数超越了传统机器学习模型。然而，提示策略的差异和领域微调需求仍是问题。

研究结论: 研究表明LLMs可用于医疗预测任务，但需进一步研究提示工程和混合方法以提高性能。未来工作应关注优化提示策略和领域适应性。

中文摘要: 尽管机器学习和深度学习模型已广泛用于糖尿病预测，但大型语言模型（LLMs）在结构化数值数据中的应用尚未充分探索。本研究测试了LLMs在糖尿病预测中的有效性，采用零样本、单样本和三样本提示方法，并使用Pima印第安糖尿病数据库（PIDD）进行实证分析。评估了六种LLMs（包括四种开源模型和两种专有模型），并与三种传统机器学习模型（随机森林、逻辑回归和支持向量机）进行比较。结果显示，专有LLMs表现优于开源模型，其中GPT-4o和Gemma-2-27B在少样本设置下准确率最高。值得注意的是，Gemma-2-27B的F1分数也超越了传统机器学习模型。然而，提示策略的性能差异和领域微调需求仍是问题。研究表明LLMs可用于医疗预测任务，并鼓励未来在提示工程和混合方法上的研究，以提升医疗预测效果。

</details>


### [6] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
**中文标题：记忆令牌：大型语言模型可生成可逆句子嵌入**

*Ignacio Sastre,Aiala Rosá*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLM）可通过引入特殊记忆令牌生成可逆句子嵌入，无需修改模型权重即可精确重建原始文本。


<details>
  <summary>详细信息</summary>
研究动机: 探索大型语言模型是否能够生成可逆的句子嵌入，以实现精确的文本重建，并研究其潜在应用。

研究方法: 通过训练优化特殊记忆令牌的嵌入，使其能够固定序列的嵌入表示，从而在提示时精确重建原始文本。

研究结果: 在英语和西班牙语数据集上测试成功，支持长达240个令牌的序列，模型规模从1亿到80亿参数不等，Llama 3.1 8B模型成功重建所有测试序列。

研究结论: 研究揭示了大型语言模型的可逆嵌入能力，为基于记忆的检索、压缩和受控文本生成提供了潜在应用。

中文摘要: 本文发现一个有趣现象：无需修改模型权重，即可生成可逆的句子嵌入，使大型语言模型能够精确重建原始文本。这是通过引入一种特殊的记忆令牌实现的，其嵌入通过固定序列的训练优化。当提示该嵌入时，模型能精确重建固定序列。我们在英语和西班牙语数据集上评估了这一现象，测试了长达约240个令牌的序列，模型规模从1亿到80亿参数不等。值得注意的是，Llama 3.1 8B成功重建了所有测试序列。我们的发现突显了大型语言模型的有趣能力，并为其在基于记忆的检索、压缩和受控文本生成中的应用提供了可能。

</details>


### [7] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
**中文标题：使用主题建模和文本分类方法识别NVDRS文本叙述中的社会隔离主题**

*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

主要分类: cs.CL

摘要简述: 研究利用主题建模和文本分类方法，从美国国家暴力死亡报告系统的文本叙述中识别社会隔离主题，发现男性、同性恋和离婚者更易被分类为慢性社会隔离，并提出了改进社会隔离监测和预防的方法。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，社会隔离和孤独感显著增加，与自杀率密切相关。然而，美国国家暴力死亡报告系统（NVDRS）的结构化变量中未记录这些因素，因此研究旨在通过自然语言处理技术从文本叙述中识别社会隔离主题。

研究方法: 研究采用主题建模生成词典，并结合监督学习分类器开发高质量分类器（平均F1值0.86，准确率0.82），用于分析2002年至2020年的30万例自杀事件。

研究结果: 研究发现，男性（OR=1.44）、同性恋（OR=3.68）和离婚者（OR=3.34）更易被分类为慢性社会隔离。此外，近期或即将离婚、失去子女监护权、被驱逐或搬家以及分手也是社会隔离的重要预测因素。

研究结论: 研究提出的方法可有效改进美国社会隔离和孤独感的监测与预防，为相关干预措施提供数据支持。

中文摘要: 近年来，社会隔离和孤独感显著增加，对自杀率有重要影响。尽管美国国家暴力死亡报告系统（NVDRS）的结构化变量中未记录这些因素，但可以通过自然语言处理（NLP）技术从执法部门和法医叙述中识别这些内容。通过主题建模生成词典并结合监督学习分类器，我们开发了高质量的分类器（平均F1值0.86，准确率0.82）。在分析2002年至2020年的30万例自杀事件中，我们识别出1,198例提到慢性社会隔离。男性（OR=1.44；CI:1.24,1.69,p<.0001）、同性恋（OR=3.68；1.97,6.33,p<.0001）和离婚者（OR=3.34；2.68,4.19,p<.0001）更易被分类为慢性社会隔离。我们还发现近期或即将离婚、失去子女监护权、被驱逐或搬家以及分手是社会隔离的其他重要预测因素。我们的方法可以改进美国社会隔离和孤独感的监测与预防。

</details>


### [8] [Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation](https://arxiv.org/abs/2506.15068)
**中文标题：语义感知奖励在自由生成长文本中的开放式GRPO训练**

*Zongxia Li,Yapei Chang,Yuhang Zhou,Xiyang Wu,Zichao Liang,Yoo Yeon Sung,Jordan Lee Boyd-Graber*

主要分类: cs.CL

摘要简述: 本文提出PrefBERT模型，用于评估和指导开放生成长文本的质量，通过语义奖励反馈优于传统指标ROUGE-L和BERTScore，并验证其与人类偏好的一致性。


<details>
  <summary>详细信息</summary>
研究动机: 开放生成长文本的评估存在挑战，现有方法常忽略关键因素如连贯性、风格或相关性，或受预训练数据偏差影响。本文旨在填补这一空白，提出更可靠的评估和训练方法。

研究方法: 提出PrefBERT评分模型，基于多样长文本风格和Likert评分质量的数据集训练，为GRPO提供语义奖励反馈，并通过LLM、人工评分和定性分析验证其可靠性。

研究结果: PrefBERT在多样长文本中表现稳定，与传统指标相比更符合人类偏好，作为奖励信号训练策略模型时生成更优的响应。

研究结论: PrefBERT为开放生成长文本的评估和训练提供了更有效的语义奖励反馈，显著提升了生成质量与人类偏好的一致性。

中文摘要: 评估开放生成长文本具有挑战性，因为难以明确区分好与坏的输出。现有方法常忽略连贯性、风格或相关性等关键因素，或受预训练数据偏差影响，使得开放生成长文本评估成为一个未充分探索的问题。为解决这一问题，我们提出PrefBERT，一种用于评估开放生成长文本的评分模型，并通过区分好与坏输出的奖励指导GRPO训练。PrefBERT基于两种具有多样长文本风格和Likert评分质量的响应评估数据集训练，能够为GRPO提供比传统指标ROUGE-L和BERTScore更优的语义奖励反馈。通过包括LLM作为评判、人工评分和定性分析在内的全面评估，我们证明PrefBERT在多样长文本中表现可靠，且与GRPO所需的可验证奖励一致。人工评估证实，使用PrefBERT作为奖励信号训练策略模型生成的响应比传统指标训练的响应更符合人类偏好。代码发布于https://github.com/zli12321/long_form_rl。

</details>


### [9] [Learning-Time Encoding Shapes Unlearning in LLMs](https://arxiv.org/abs/2506.15076)
**中文标题：学习阶段的编码方式影响大型语言模型的遗忘能力**

*Ruihan Wu,Konstantin Garov,Kamalika Chaudhuri*

主要分类: cs.CL

摘要简述: 研究发现，学习阶段的知识编码方式对大型语言模型（LLMs）的遗忘能力有重要影响，尤其是使用转述描述可提升遗忘效果，但遗忘文本中的单个知识点仍具挑战性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在现实中的广泛应用，如何实现“遗忘”特定知识（如隐私数据或有害内容）变得至关重要。以往研究假设训练过程和目标模型固定，本文则探讨学习阶段的知识编码如何影响遗忘效果。

研究方法: 通过实验研究学习阶段的知识编码方式对遗忘能力的影响，重点关注转述描述和文本块中单个知识点的遗忘难度。

研究结果: 实验发现：（1）使用转述描述学习可提升遗忘效果；（2）从文本块中遗忘单个知识点较为困难。

研究结论: 学习阶段的知识编码对实现可靠的遗忘至关重要，未来研究需关注如何优化编码方式以提升遗忘能力。

中文摘要: 随着大型语言模型（LLMs）在现实中的广泛应用，实现“遗忘”特定知识（如隐私数据或有害内容）变得至关重要。以往研究提出了遗忘基准和算法，并通常假设训练过程和目标模型固定。本文通过实验研究学习阶段的知识编码如何影响遗忘效果。实验发现：（1）使用转述描述学习可提升遗忘效果；（2）从文本块中遗忘单个知识点较为困难。结果表明，学习阶段的知识编码对实现可靠的遗忘至关重要。

</details>


### [10] [Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification](https://arxiv.org/abs/2506.15081)
**中文标题：通过话语感知的澄清改进对话话语解析**

*Yaxin Fan,Peifeng Li,Qiaoming Zhu*

主要分类: cs.CL

摘要简述: 本文提出了一种基于话语感知的澄清模块（DCM）和贡献感知偏好优化（CPO）的方法，用于解决对话话语解析中的歧义问题，显著提升了解析性能。


<details>
  <summary>详细信息</summary>
研究动机: 对话中的语言特征（如省略和习语）常导致话语关系模糊，给解析带来挑战。本文旨在通过澄清模块和优化方法解决这一问题。

研究方法: 提出DCM模块，包含澄清类型推理和话语目标推理；引入CPO方法以减少错误澄清的负面影响，并通过反馈优化DCM。

研究结果: 在STAC和Molweni数据集上的实验表明，该方法有效消除歧义，性能显著优于现有基线。

研究结论: DCM和CPO的结合显著提升了对话话语解析的准确性和鲁棒性，为相关任务提供了新思路。

中文摘要: 对话话语解析旨在识别和分析对话中话语间的关系。然而，对话中的语言特征（如省略和习语）常引入歧义，掩盖了预期的话语关系，给解析带来挑战。为解决这一问题，我们提出了一种话语感知澄清模块（DCM），以提升对话话语解析器的性能。DCM采用两种推理过程：澄清类型推理和话语目标推理。前者分析语言特征，后者从歧义中区分预期关系。此外，我们引入了贡献感知偏好优化（CPO），以减少错误澄清的风险，从而降低级联错误。CPO使解析器能够评估DCM澄清的贡献，并提供反馈以优化DCM，增强其适应性和与解析器需求的匹配性。在STAC和Molweni数据集上的大量实验表明，我们的方法有效解决了歧义问题，并显著优于现有基线。

</details>


### [11] [CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records](https://arxiv.org/abs/2506.15118)
**中文标题：CKD-EHR：面向电子健康记录的临床知识蒸馏**

*Junke Wang,Hongshun Ling,Li Zhang,Longqian Zhang,Fang Wang,Yuan Gao,Zhi Li*

主要分类: cs.CL

摘要简述: 本文提出CKD-EHR框架，通过知识蒸馏技术提升电子健康记录（EHR）的疾病预测效率与准确性，显著优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有大型语言模型在医疗知识表示不足和临床部署效率低方面面临挑战，需开发高效且准确的疾病风险预测方法。

研究方法: 首先微调Qwen2.5-7B模型作为教师模型，生成可解释的软标签；再通过多粒度注意力蒸馏机制将知识迁移至轻量级BERT学生模型。

研究结果: 在MIMIC-III数据集上，CKD-EHR诊断准确率提升9%，F1分数提高27%，推理速度加快22.2倍。

研究结论: CKD-EHR显著提升资源利用效率和诊断准确性，为临床资源优化提供实用技术方案。

中文摘要: 基于电子健康记录（EHR）的疾病预测模型在推动精准医疗和早期干预方面具有重要临床价值。然而，现有大型语言模型面临两大挑战：医疗知识表示不足和临床部署效率低。为解决这些问题，本研究提出CKD-EHR（面向EHR的临床知识蒸馏）框架，通过知识蒸馏技术实现高效且准确的疾病风险预测。具体而言，首先在医疗知识增强数据上微调大型语言模型Qwen2.5-7B作为教师模型，并通过多粒度注意力蒸馏机制生成可解释的软标签。最后，将蒸馏的知识迁移至轻量级BERT学生模型。实验结果表明，在MIMIC-III数据集上，CKD-EHR显著优于基线模型：诊断准确率提高9%，F1分数提升27%，推理速度加快22.2倍。这一创新方案不仅大幅提升资源利用效率，还显著增强诊断的准确性和及时性，为临床资源优化提供了实用技术途径。本研究的代码和数据可在https://github.com/209506702/CKD_EHR获取。

</details>


### [12] [Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs](https://arxiv.org/abs/2506.15131)
**中文标题：基于大语言模型的开放域对话中一对多特性建模**

*Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan*

主要分类: cs.CL

摘要简述: 本文提出了一种两阶段框架（多响应生成和偏好选择）来建模开放域对话中的一对多特性，通过新数据集o2mDial和改进的学习策略，显著提升了小规模语言模型的响应多样性和质量。


<details>
  <summary>详细信息</summary>
研究动机: 开放域对话中存在一对多特性（一个对话上下文对应多个合理响应），但现有基于大语言模型的对话系统未明确建模此特性，导致响应多样性不足。本文旨在通过显式建模提升对话质量。

研究方法: 将开放域对话生成分解为多响应生成（MRG）和基于偏好的选择（PS）两阶段任务，引入o2mDial数据集支持训练，并提出新的上下文学习和指令调优策略及评估指标。

研究结果: 实验表明，该框架显著提升了小规模语言模型的响应多样性和质量（最高提升90%），使其接近大规模模型的性能。

研究结论: 通过显式建模一对多特性，两阶段框架有效提升了开放域对话的多样性和质量，为小规模模型的应用提供了新思路。

中文摘要: 开放域对话（OD）具有一对多（o2m）特性，即单个对话上下文对应多个合理响应。尽管已有研究表明建模此特性可提升响应多样性，但现有基于大语言模型（LLM）的对话系统大多未明确实现。本文通过将OD生成分解为多响应生成（MRG）和基于偏好的选择（PS）两阶段任务，显式建模o2m特性。MRG任务生成一组语义和词汇多样性的高质量响应，PS任务则根据人类偏好从中选择单一响应。为支持MRG和PS，我们引入了o2mDial数据集，该数据集专为捕捉o2m特性设计，每个上下文包含多个合理响应。基于o2mDial，我们提出了新的上下文学习和指令调优策略，以及MRG的新评估指标和PS的模型驱动方法。实验结果表明，将所提两阶段框架应用于小规模LLM进行OD生成，可在保持上下文连贯性的同时显著提升响应多样性，响应质量最高提升90%，使其性能接近大规模模型。

</details>


### [13] [Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models](https://arxiv.org/abs/2506.15138)
**中文标题：Thunder-Tok：为生成语言模型设计的韩语文本分词最小化方法**

*Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee*

主要分类: cs.CL

摘要简述: 本文介绍了一种名为Thunder-Tok的新型韩语分词器，旨在减少分词数量而不影响模型性能。通过基于规则的分词方法和分支熵选择算法，显著降低了分词数量，同时保持了语言信息。实验结果显示，Thunder-Tok比BPE减少了约10%的分词数量，提升了推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的韩语分词器在生成语言模型中存在分词数量过多的问题，导致推理效率低下。本文旨在设计一种高效的分词器，减少分词数量而不牺牲模型性能。

研究方法: Thunder-Tok采用基于规则的预分词方法，结合韩语的语言结构，并利用分支熵选择算法构建种子词汇表。这些方法显著提高了平均分词长度，从而降低分词数量。

研究结果: 实验结果表明，Thunder-Tok比BPE减少了约10%的分词数量，提升了10%的推理速度，同时在多种下游任务中保持了模型性能。

研究结论: Thunder-Tok通过语言学驱动的设计，成功实现了高效分词，为语言模型的分词器设计提供了实用且有效的解决方案。

中文摘要: 本文介绍了Thunder-Tok，一种新型韩语分词器，旨在减少分词数量而不影响模型性能。我们的方法采用基于规则的预分词技术，与韩语的语言结构对齐，并构建了一个包含类似语言单元的分词种子词汇表，同时使用了基于分支熵的选择算法。这些技术提高了平均分词长度，从而降低了分词数量，同时保留了语言信息。实验结果表明，与BPE相比，Thunder-Tok减少了约10%的分词数量（即减少了10%的分词数量，提升了10%的推理速度），同时在多种下游任务中未影响性能。这些发现表明，我们基于语言学的方法对于设计高效的语言模型分词器是实用且有效的。

</details>


### [14] [Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View](https://arxiv.org/abs/2506.15156)
**中文标题：Mamba中首因与近因效应的涌现：机制性视角**

*Muhammad Cendekia Airlangga,Hilal AlQuabeh,Munachiso S Nwadike,Kentaro Inui*

主要分类: cs.CL

摘要简述: 本文研究了状态空间语言模型中的记忆机制，通过首因效应和近因效应揭示了信息如何随时间保留和遗忘。研究发现Mamba架构在序列输入的开头和结尾表现最佳，并揭示了三种机制：长期记忆依赖稀疏通道、短期记忆受delta调制递归影响，以及记忆分配受语义规律动态调节。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过首因效应和近因效应，揭示状态空间语言模型（如Mamba）中信息保留和遗忘的机制，以理解其记忆行为。

研究方法: 研究采用结构化回忆任务，分析Mamba架构在输入序列中的表现，并通过目标性消融和输入扰动验证了三种机制：长期记忆的稀疏通道编码、短期记忆的delta调制递归，以及记忆分配受语义规律动态调节。

研究结果: 研究发现Mamba模型在序列的开头和结尾表现最佳，形成U型准确率曲线。长期记忆依赖稀疏通道编码早期输入，短期记忆受delta调制递归影响，而语义规律会动态调节记忆分配。

研究结论: 研究揭示了Mamba模型中记忆机制的三种关键因素，为首因效应和近因效应提供了机制性解释，并验证了这些发现在大规模模型中的普适性。

中文摘要: 我们通过首因效应和近因效应作为行为工具，研究了状态空间语言模型中的记忆机制，以揭示信息如何随时间保留和遗忘。在Mamba架构中应用结构化回忆任务时，我们观察到一致的U型准确率曲线，表明模型在输入序列的开头和结尾表现最佳。我们识别了导致这种模式的三种机制：首先，长期记忆由模型选择性状态空间块中的稀疏通道子集支持，这些通道持续编码早期输入标记并与首因效应因果相关；其次，短期记忆受delta调制递归支配：由于指数衰减，近期输入权重更高，但当引入干扰项时，这种近因优势会崩溃，揭示了记忆深度的明确限制；第三，我们发现记忆分配受语义规律动态调节：输入序列中的重复关系会改变delta门控行为，增加遗忘中间项的倾向。我们通过目标性消融和输入扰动，在两个大规模基于Mamba的语言模型（一个1.4B参数，另一个7B参数）上验证了这些发现。

</details>


### [15] [A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals](https://arxiv.org/abs/2506.15208)
**中文标题：大型语言模型任务适应性技术在识别可持续发展目标中的比较研究**

*Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi*

主要分类: cs.CL

摘要简述: 本研究比较了大型语言模型在识别可持续发展目标（SDGs）任务中的适应性技术，发现通过提示工程优化的小模型性能可与大模型媲美。


<details>
  <summary>详细信息</summary>
研究动机: 联合国2012年提出的17个可持续发展目标（SDGs）数据规模庞大且复杂，难以追踪进展。文本分类模型和大型语言模型（LLMs）因其自动化分析能力成为重要工具，但需评估其适应性技术在此领域的有效性。

研究方法: 研究分析了专有和开源LLMs在单标签多类文本分类任务中的应用，并评估了零样本学习、少样本学习和微调等任务适应性技术的效果。

研究结果: 结果显示，通过提示工程优化的小模型性能与OpenAI的GPT等大模型相当。

研究结论: 优化后的小模型在SDGs文本分类任务中表现优异，为资源有限场景提供了高效解决方案。

中文摘要: 2012年，联合国提出了17个可持续发展目标（SDGs），旨在到203年实现更可持续和更美好的未来。然而，由于数据规模庞大且复杂，追踪这些目标的进展十分困难。文本分类模型成为该领域的重要工具，能够自动化分析来自多种来源的大量文本。此外，大型语言模型（LLMs）因其识别复杂语言模式和语义的能力，在包括文本分类在内的许多自然语言处理任务中不可或缺。本研究分析了专有和开源LLMs在针对SDGs的单标签多类文本分类任务中的应用，并评估了任务适应性技术（即上下文学习方法），包括零样本学习、少样本学习和微调在此领域的有效性。结果显示，通过提示工程优化的小模型性能可与OpenAI的GPT等大模型相媲美。

</details>


### [16] [ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs](https://arxiv.org/abs/2506.15211)
**中文标题：ProtoReasoning：原型作为大语言模型可泛化推理的基础**

*Feng He,Zijun Chen,Xinnian Liang,Tingting Ma,Yunqi Qiu,Shuangzhi Wu,Junchi Yan*

主要分类: cs.CL

摘要简述: 本文提出ProtoReasoning框架，通过抽象推理原型提升大语言模型的泛化能力，实验表明其在逻辑推理、规划任务等方面均优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在跨领域推理中表现出色，但其泛化机制尚不明确。作者假设跨领域泛化源于共享的抽象推理原型，并提出ProtoReasoning框架以验证这一假设。

研究方法: ProtoReasoning框架包括：(1) 自动化原型构建流程，将问题转化为原型表示；(2) 通过Prolog/PDDL解释器提供可靠反馈的验证系统；(3) 在原型空间中合成问题并确保正确性的扩展能力。

研究结果: 实验显示，ProtoReasoning在逻辑推理（Enigmata-Eval）上提升4.7%，规划任务上提升6.3%，通用推理（MMLU）上提升4.0%，数学（AIME24）上提升1.0%。消融研究证实，原型空间学习对结构相似问题的泛化能力更强。

研究结论: 研究验证了抽象推理原型是大语言模型泛化推理的基础，ProtoReasoning框架显著提升了模型的跨领域推理能力。

中文摘要: 近期，基于长链思维（Long CoT）训练的大推理模型（LRMs）展现了卓越的跨领域泛化能力，但其背后的机制尚不明确。我们假设跨领域泛化源于共享的抽象推理原型——这些原型捕捉了跨领域问题的本质，最小化了表示差异，揭示了看似多样任务背后的共享推理结构。基于此，我们提出ProtoReasoning框架，通过可扩展且可验证的原型表示（如逻辑推理的Prolog、规划的PDDL）增强大语言模型的推理能力。ProtoReasoning的特点包括：(1) 自动化原型构建流程，将问题转化为原型表示；(2) 通过Prolog/PDDL解释器提供可靠反馈的验证系统；(3) 在原型空间中合成问题并确保正确性的扩展能力。大量实验表明，ProtoReasoning在逻辑推理（Enigmata-Eval）上比基线模型提升4.7%，规划任务上提升6.3%，通用推理（MMLU）上提升4.0%，数学（AIME24）上提升1.0%。重要的是，消融研究证实，原型空间学习对结构相似问题的泛化能力优于纯自然语言表示训练，验证了我们的假设：推理原型是大语言模型可泛化推理的基础。

</details>


### [17] [MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs](https://arxiv.org/abs/2506.15215)
**中文标题：MinosEval：通过区分事实性与非事实性问题为开放域问答任务定制基于LLM的评估**

*Yongqi Fan,Yating Wang,Guandong Wang,Jie Zhai,Jingping Liu,Qi Ye,Tong Ruan*

主要分类: cs.CL

摘要简述: 本文提出MinosEval方法，通过区分事实性和非事实性问题，采用不同策略评估开放域问答任务，提升自动评估的准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 开放域问答任务对大型语言模型的能力评估至关重要，但传统评估方法如ROUGE和BERTScore难以捕捉语义相似性，且现有方法未区分事实性和非事实性问题。MinosEval旨在解决这些问题。

研究方法: MinosEval首先区分事实性和非事实性问题，对事实性问题采用自适应关键点评分策略，对非事实性问题采用实例感知的列表排序策略。

研究结果: 实验表明，MinosEval在多个开放域问答数据集上优于传统方法，更符合人工标注结果，并提供更可解释的评估。

研究结论: MinosEval通过区分问题类型并采用针对性评估策略，显著提升了开放域问答任务的自动评估效果。

中文摘要: 开放域问答（QA）是评估大型语言模型（LLM）能力的关键任务。与封闭式问答相比，它需要更长的回答、更细致的推理过程和多样化的表达，这使得精细且可解释的自动评估既重要又具有挑战性。传统指标如ROUGE和BERTScore由于模型回答与参考答案之间的模式差异，难以捕捉语义相似性。当前基于LLM的评估方法（如候选答案的成对或列表比较）缺乏直观的可解释性。虽然对每个回答的点式评分提供了一些描述，但无法适应不同问题内容。最值得注意的是，现有方法忽视了事实性和非事实性问题的区别。为解决这些问题，我们提出MinosEval，一种新颖的评估方法，首先区分开放域问题，然后使用不同评估策略对候选答案进行排序。对于事实性问题，采用自适应关键点评分策略；对于非事实性问题，采用实例感知的列表排序策略。在多个开放域问答数据集（包括自建数据集以补充社区资源）上的实验表明，MinosEval更符合人工标注，并提供更可解释的结果。

</details>


### [18] [Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants](https://arxiv.org/abs/2506.15239)
**中文标题：迷失在变体中？评估巴斯克语和西班牙语地理变体的自然语言推理性能**

*Jaione Bengoetxea,Itziar Gonzalez-Dios,Rodrigo Agerri*

主要分类: cs.CL

摘要简述: 本文评估了当前语言技术对巴斯克语和西班牙语变体的理解能力，发现语言变体（尤其是巴斯克语）会导致性能下降，且与词汇重叠无关。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估现有语言技术对巴斯克语和西班牙语地理变体的理解能力，揭示语言变体对自然语言推理任务的影响。

研究方法: 通过自然语言推理（NLI）任务，使用手动整理的平行数据集，结合编码器-解码器大语言模型（LLMs）进行跨语言和上下文学习实验。

研究结果: 实验结果显示，语言变体（尤其是巴斯克语）导致性能下降，且编码器模型对西巴斯克语表现较差，与语言学理论一致。

研究结论: 语言变体对语言技术性能有显著影响，尤其是非标准方言（如西巴斯克语），未来需针对性优化模型。

中文摘要: 本文评估了当前语言技术对巴斯克语和西班牙语变体的理解能力。我们以自然语言推理（NLI）为核心任务，并引入了一个手动整理的平行数据集，涵盖巴斯克语和西班牙语及其变体。通过编码器和解码器大语言模型（LLMs）的跨语言和上下文学习实验，我们发现语言变体（尤其是巴斯克语）会导致性能下降。错误分析表明，这种下降并非由词汇重叠引起，而是语言变体本身所致。进一步的消融实验显示，编码器模型对西巴斯克语表现较差，这与语言学理论中关于外围方言（如西巴斯克语）与标准语距离较远的观点一致。所有数据和代码均已公开。

</details>


### [19] [Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs](https://arxiv.org/abs/2506.15241)
**中文标题：基于历史文本知识图谱的图检索增强生成研究**

*Yang Fan,Zhang Qi,Xing Wenqian,Liu Chang,Liu Liu*

主要分类: cs.CL

摘要简述: 本文提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，构建历史文本知识图谱，减少人工标注成本，提升通用模型与历史知识的对齐效果。实验表明，该方法在关系提取任务中表现优异，有效缓解幻觉现象。


<details>
  <summary>详细信息</summary>
研究动机: 针对通用大语言模型在历史文本分析中的领域知识不足问题，结合计算人文与AIGC技术，提出低资源解决方案，推动历史知识服务和人文研究。

研究方法: 提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，构建《前四史》人物关系数据集，并设计知识图谱与检索增强生成的协作机制。

研究结果: 实验显示，领域专用模型Xunzi-Qwen1.5-14B在关系提取任务中表现最佳（F1=0.68）；集成GraphRAG的DeepSeek模型在开放领域C-CLUE数据集上F1提升11%，优于Xunzi-Qwen1.5-14B（0.12），有效缓解幻觉现象。

研究结论: Graph RAG框架为古典文本知识提取提供低资源解决方案，提升历史知识服务与人文研究水平。

中文摘要: 本文针对通用大语言模型在计算人文与AIGC技术背景下历史文本分析的领域知识不足问题，提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，构建《前四史》人物关系数据集，减少人工标注成本。在图形增强生成阶段，引入知识图谱与检索增强生成的协作机制，提升通用模型与历史知识的对齐效果。实验表明，领域专用模型Xunzi-Qwen1.5-14B在简体中文输入与思维链提示下，关系提取任务表现最优（F1=0.68）；集成GraphRAG的DeepSeek模型在开放领域C-CLUE关系提取数据集上F1提升11%（0.08-0.19），优于Xunzi-Qwen1.5-14B（0.12），有效缓解幻觉现象并提升可解释性。该框架为古典文本知识提取提供低资源解决方案，推动历史知识服务与人文研究发展。

</details>


### [20] [TopClustRAG at SIGIR 2025 LiveRAG Challenge](https://arxiv.org/abs/2506.15246)
**中文标题：TopClustRAG在SIGIR 2025 LiveRAG挑战中的表现**

*Juli Bakagianni,John Pavlopoulos,Aristidis Likas*

主要分类: cs.CL

摘要简述: TopClustRAG是一个为LiveRAG挑战开发的检索增强生成系统，结合稀疏和密集索引的混合检索策略，并通过K-Means聚类分组相似段落，生成多样化且准确的回答。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过聚类和提示聚合提升大规模检索增强生成系统的答案多样性、相关性和忠实性。

研究方法: 系统采用混合检索策略（稀疏和密集索引），结合K-Means聚类分组相似段落，生成集群特定提示，通过LLM生成中间答案，最终过滤、重排并合成全面回答。

研究结果: 在FineWeb Sample-10BT数据集上，TopClustRAG在忠实性排名第2，正确性排名第7，验证了聚类和提示聚合的有效性。

研究结论: TopClustRAG通过聚类和提示聚合显著提升了大规模RAG系统的性能，尤其在忠实性和多样性方面表现突出。

中文摘要: 我们介绍了TopClustRAG，一个为LiveRAG挑战开发的检索增强生成（RAG）系统，该挑战评估大规模网络语料库上的端到端问答。我们的系统采用混合检索策略，结合稀疏和密集索引，并通过K-Means聚类将语义相似的段落分组。每个聚类的代表性段落用于构建集群特定提示，供大型语言模型（LLM）生成中间答案，这些答案经过过滤、重排后最终合成一个全面回答。这种多阶段流程提高了答案的多样性、相关性和对检索证据的忠实性。在FineWeb Sample-10BT数据集上的评估显示，TopClustRAG在官方排行榜上忠实性排名第2，正确性排名第7，证明了基于聚类的上下文过滤和提示聚合在大规模RAG系统中的有效性。

</details>


### [21] [Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments](https://arxiv.org/abs/2506.15266)
**中文标题：Thunder-DeID：韩国法院判决书的高效精准去标识化框架**

*Sungen Hahm,Heejin Kim,Gyuseong Lee,Hyunji Park,Jaejin Lee*

主要分类: cs.CL

摘要简述: 韩国司法系统要求对法院判决书进行去标识化处理以平衡司法公开与个人数据保护。现有方法效率低下且法律定义模糊。为此，研究者提出Thunder-DeID框架，包括首个韩文法律数据集、系统化的个人身份信息分类和基于深度神经网络的去标识化流程，实验表明其性能优异。


<details>
  <summary>详细信息</summary>
研究动机: 韩国司法系统要求公开法院判决书前需进行去标识化处理，但现有方法无法满足大规模处理需求且法律定义模糊，亟需一种高效且符合法律要求的技术解决方案。

研究方法: 研究者提出Thunder-DeID框架，包括：(i) 构建并发布首个标注的韩文法律数据集，(ii) 系统化分类个人身份信息，(iii) 开发基于深度神经网络的端到端去标识化流程。

研究结果: 实验结果显示，Thunder-DeID在法院判决书的去标识化任务中达到了最先进的性能。

研究结论: Thunder-DeID框架通过结合法律数据集、系统化分类和深度学习技术，有效解决了韩国法院判决书去标识化的难题，为司法公开与数据保护提供了高效解决方案。

中文摘要: 为确保司法公开与个人数据保护之间的平衡，韩国司法系统要求在公开法院判决书前进行去标识化处理。然而，现有去标识化方法无法满足大规模处理需求，且法律对个人标识的定义模糊，难以适配技术解决方案。为解决这些问题，我们提出了Thunder-DeID去标识化框架，该框架符合相关法律与实践要求。具体而言，我们（i）构建并发布了首个包含标注判决书及对应实体提及列表的韩文法律数据集，（ii）系统化分类个人身份信息（PII），（iii）开发了基于深度神经网络（DNN）的端到端去标识化流程。实验结果表明，我们的模型在法院判决书去标识化任务中达到了最先进的性能。

</details>


### [22] [Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment](https://arxiv.org/abs/2506.15301)
**中文标题：队列发现：关于LLM辅助临床试验招募的综述**

*Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff*

主要分类: cs.CL

摘要简述: 本文综述了LLM在临床试验招募中的应用，分析了现有方法的局限性，并探讨了未来发展方向。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM在通用NLP任务中表现优异，但在临床试验招募等关键领域的应用仍有限。本文旨在探讨LLM如何通过知识整合和推理能力改进试验与患者的匹配任务。

研究方法: 本文通过分析现有LLM辅助方法的局限性，包括依赖专有模型和弱评估基准，首次系统性地研究了试验-患者匹配任务，并提出了改进方向。

研究结果: 研究发现，现有方法在临床试验招募中存在不足，但LLM的潜力巨大，未来可通过更通用的解决方案和强评估基准实现突破。

研究结论: LLM在临床试验招募中具有广阔前景，但需解决现有挑战，如模型开放性和评估标准，以实现更广泛的应用。

中文摘要: 近年来，LLM在通用NLP任务中取得了显著进展，但在临床试验招募等关键领域的应用仍有限。由于试验设计使用自然语言，患者数据以结构化和非结构化文本形式存在，LLM的知识整合和推理能力为试验与患者匹配提供了优势。传统方法针对特定试验，而LLM通过整合分散知识有望构建更通用的解决方案。然而，近期LLM辅助方法依赖专有模型和弱评估基准。本文首次分析了试验-患者匹配任务，并探讨了LLM在临床试验招募中的新兴方法。我们批判性地审查了现有基准、方法和评估框架，探讨了LLM技术在临床研究中应用的挑战及未来发展方向。

</details>


### [23] [ConLID: Supervised Contrastive Learning for Low-Resource Language Identification](https://arxiv.org/abs/2506.15304)
**中文标题：ConLID：基于监督对比学习的低资源语言识别方法**

*Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut*

主要分类: cs.CL

摘要简述: 本文提出了一种基于监督对比学习（SCL）的新方法ConLID，用于解决低资源语言识别（LID）中的数据不平衡和领域偏差问题，显著提升了低资源语言在跨领域数据上的识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 语言识别（LID）是多语言大模型预训练数据整理的关键步骤，但低资源语言由于数据稀缺且多为单一领域（如圣经），性能较差。本研究旨在通过监督对比学习解决数据不平衡和领域偏差问题。

研究方法: 提出了一种名为ConLID的监督对比学习方法，通过学习领域不变的表征，提升低资源语言在跨领域数据上的识别能力。

研究结果: 实验表明，该方法将低资源语言在跨领域数据上的识别性能提升了3.2%，验证了其有效性。

研究结论: ConLID通过监督对比学习显著改善了低资源语言的识别性能，为解决数据不平衡和领域偏差问题提供了有效方案。

中文摘要: 语言识别（LID）是从网络爬取数据中整理多语言大模型预训练语料的关键步骤。尽管许多关于LID模型训练的研究致力于收集多样化的训练数据以提高性能，但低资源语言（通常仅限于单一领域数据，如圣经）的表现仍然较差。为解决这些类别不平衡和偏差问题，我们提出了一种新颖的监督对比学习（SCL）方法，用于学习低资源语言的领域不变表征。通过广泛分析，我们表明该方法将低资源语言在跨领域数据上的识别性能提升了3.2%，证明了其在增强LID模型中的有效性。

</details>


### [24] [DeVisE: Behavioral Testing of Medical Large Language Models](https://arxiv.org/abs/2506.15339)
**中文标题：DeVisE：医疗大语言模型的行为测试**

*Camila Zurdo Tagliabue,Heloisa Oss Boll,Aykut Erdem,Erkut Erdem,Iacer Calixto*

主要分类: cs.CL

摘要简述: 本文提出DeVisE框架，用于测试医疗大语言模型（LLMs）的细粒度临床理解能力，发现零样本模型在反事实推理上更一致，而微调模型更稳定但对临床变化反应较弱。


<details>
  <summary>详细信息</summary>
研究动机: 当前医疗大语言模型的评估方法难以区分真实医学推理与表面模式，因此需要一种行为测试框架来揭示其临床理解的细节。

研究方法: 基于MIMIC-IV的ICU出院记录，构建包含真实和模板生成的反事实数据集，评估五种LLM在零样本和微调设置下对人口统计学和生命体征变化的敏感性及下游推理能力。

研究结果: 零样本模型在反事实推理上表现更一致，微调模型更稳定但对临床变化反应较弱；人口统计学因素对输出有细微但持续的影响。

研究结论: 行为测试有助于揭示临床LLM的推理策略，为设计更安全、透明的医疗AI系统提供依据。

中文摘要: 大语言模型（LLMs）在临床决策支持中的应用日益广泛，但现有评估方法往往难以区分真实医学推理与表面模式。本文提出DeVisE（人口统计学与生命体征评估），一种用于测试细粒度临床理解的行为测试框架。我们基于MIMIC-IV的ICU出院记录构建数据集，生成真实和模板化的反事实版本，针对人口统计学（年龄、性别、种族）和生命体征属性进行单变量控制。评估了五种涵盖通用和医疗微调变体的LLM，在零样本和微调设置下，通过（1）输入级敏感性——反事实如何改变记录的似然；（2）下游推理——如何影响预测的住院时长。结果显示，零样本模型的反事实推理模式更一致，而微调模型更稳定但对临床变化的反应较弱。值得注意的是，人口统计学因素对输出有细微但持续的影响，强调了公平性评估的重要性。这项工作凸显了行为测试在揭示临床LLM推理策略和设计更安全、透明医疗AI系统中的价值。

</details>


### [25] [SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture](https://arxiv.org/abs/2506.15355)
**中文标题：SANSKRITI：一个评估语言模型对印度文化知识理解的综合基准**

*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Sriparna Saha*

主要分类: cs.CL

摘要简述: 本文介绍了SANSKRITI，一个用于评估语言模型对印度文化理解能力的综合基准数据集，包含21,853个问题-答案对，覆盖印度28个邦和8个中央直辖区，涵盖16个文化属性。测试发现主流语言模型在处理文化相关查询时存在显著差异。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型在全球应用中的有效性依赖于其对本地社会文化背景的理解。然而，目前缺乏针对印度文化多样性的评估工具，因此作者开发了SANSKRITI，以填补这一空白。

研究方法: 作者构建了包含21,853个问题-答案对的SANSKRITI数据集，覆盖印度28个邦和8个中央直辖区，涵盖16个文化属性。随后在主流大语言模型（LLMs）、印度语言模型（ILMs）和小语言模型（SLMs）上进行了评估。

研究结果: 评估结果显示，许多语言模型在处理文化相关查询时表现不佳，尤其是在地区特定情境下。SANSKRITI为评估和改进语言模型的文化理解能力提供了新标准。

研究结论: SANSKRITI是目前最大的印度文化知识评估数据集，为语言模型的文化理解能力提供了全面测试工具，揭示了现有模型的局限性，并为其改进指明了方向。

中文摘要: 语言模型（LMs）是塑造现代工作流程不可或缺的工具，但其全球有效性依赖于对本地社会文化背景的理解。为此，我们引入了SANSKRITI，一个旨在评估语言模型对印度丰富文化多样性理解能力的基准。SANSKRITI包含21,853个精心策划的问题-答案对，覆盖印度28个邦和8个中央直辖区，是测试印度文化知识的最大数据集。它涵盖了印度文化的十六个关键属性：仪式与庆典、历史、旅游、美食、舞蹈与音乐、服饰、语言、艺术、节日、宗教、医学、交通、体育、夜生活和名人，全面展现了印度的文化图景。我们在主流大语言模型（LLMs）、印度语言模型（ILMs）和小语言模型（SLMs）上评估了SANSKRITI，发现这些模型在处理文化相关查询时存在显著差异，许多模型在地区特定情境下表现不佳。通过提供广泛、文化丰富且多样的数据集，SANSKRITI为评估和改进语言模型的文化理解能力设立了新标准。

</details>


### [26] [COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation](https://arxiv.org/abs/2506.15372)
**中文标题：COSMMIC：面向摘要和标题生成的评论敏感多模态多语言印度语料库**

*Raghvendra Kumar,S. A. Mohammed Salman,Aryan Sahu,Tridib Nandi,Pragathi Y. P.,Sriparna Saha,Jose G. Moreno*

主要分类: cs.CL

摘要简述: 本文介绍了COSMMIC，一个针对印度语言的多模态、多语言数据集，包含文章、图片和用户评论，用于摘要和标题生成任务。通过整合评论和图像信息，提升了摘要质量，并评估了不同配置的效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前针对英语和中文的多模态、多语言摘要研究较多，但印度语言的相关研究仍有限。本文旨在填补这一空白，通过引入COSMMIC数据集，推动印度语言的NLP研究。

研究方法: 研究构建了包含4,959篇文章-图片对和24,484条评论的COSMMIC数据集，支持九种印度语言。采用四种配置（仅文本、文本+评论、文本+图像、文本+评论+图像）进行摘要和标题生成，并使用LLama3和GPT-4等模型评估效果。通过IndicBERT分类器过滤噪声评论，并利用多语言CLIP分类器提取图像信息。

研究结果: 实验表明，整合用户评论和图像信息能显著提升摘要质量。多模态配置（文本+评论+图像）表现最佳，验证了COSMMIC数据集的有效性。

研究结论: COSMMIC填补了印度语言多模态研究的空白，为NLP任务提供了更全面的数据支持。整合用户反馈和图像信息是提升摘要生成效果的关键。

中文摘要: 尽管针对英语和中文的评论感知多模态和多语言摘要研究取得了进展，但印度语言的相关研究仍然有限。本研究通过引入COSMMIC填补了这一空白，这是一个开创性的评论敏感多模态、多语言数据集，涵盖九种主要印度语言。COSMMIC包含4,959篇文章-图片对和24,484条读者评论，并提供所有语言的真实摘要。我们的方法通过整合读者见解和反馈来提升摘要质量。我们探索了四种配置下的摘要和标题生成：（1）仅使用文章文本，（2）结合用户评论，（3）利用图像，（4）整合文本、评论和图像。为评估数据集的有效性，我们采用了LLama3和GPT-4等先进语言模型。我们进行了全面研究，评估不同组件的组合，包括通过IndicBERT分类器识别支持性评论、过滤噪声，以及利用多语言CLIP分类器从图像中提取有价值信息。这有助于确定自然语言生成（NLG）任务的最有效配置。与许多现有数据集不同，COSMMIC独特地整合了文本、图像和用户反馈，弥补了印度语言资源的不足，推动了NLP研究并促进了包容性。

</details>


### [27] [Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning](https://arxiv.org/abs/2506.15415)
**中文标题：目标词汇注入：通过早期层LoRA微调解锁Lugha-Llama中的潜在跨语言对齐**

*Stanley Ngugi*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“目标词汇注入”（TLI）的高效微调方法，通过早期层的LoRA微调，显著提升了Swahili与英语之间的词汇对齐能力，验证了该方法在低资源语言模型中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在低资源语言（如Swahili）中表现不佳，主要由于数据稀缺和预训练中的代表性不足。本文旨在解决跨语言词汇对齐这一关键挑战，以提升翻译和跨语言信息检索等任务的性能。

研究方法: 通过实验发现Lugha-Llama-8B-wura模型的第二层对Swahili-English词汇对具有近乎完美的对齐能力（平均余弦相似度约0.99998）。基于此，提出TLI方法，利用LoRA和对比学习目标，针对该早期层进行微调，以提升词汇对齐效果。

研究结果: TLI显著提升了623个Swahili-English词汇对的输出层对齐能力，平均余弦相似度从0.3211提高到0.4113（+28.08%）。此外，该方法对63个未见过的词汇对也表现出良好的泛化能力，相似度从0.3143提高到0.4033（+28.32%）。

研究结论: TLI能够有效增强模型保留和传播其早期层跨语言知识的能力，为低资源语言模型的词汇对齐提供了一种参数高效且有效的策略。

中文摘要: 大型语言模型（LLMs）展现了卓越的能力，但在低资源语言（如Swahili）中的表现往往因数据稀缺和预训练中的代表性不足而受限。实现稳健的跨语言词汇对齐是一个关键挑战，对翻译和跨语言信息检索等任务至关重要。本文提出了“目标词汇注入”（TLI），一种新颖且高效的微调方法。我们首先证明，Swahili-centric的LLM模型Lugha-Llama-8B-wura在其早期内部层（特别是第二层，基于初步研究的平均余弦相似度约为0.99998）对Swahili-English词汇对表现出近乎完美的对齐能力，但这种能力并未充分体现在其最终输出表示中（基线相似度约为0.32）。TLI利用这一发现，通过低秩适应（LoRA）和对比学习目标对模型进行微调，专门针对这一经验确定的最优早期层嵌入。实验表明，TLI显著提升了623个训练Swahili-English词汇对的输出层对齐能力，平均余弦相似度从0.3211提高到0.4113（+28.08%，p < 1.33 x 10^-240）。更重要的是，这些改进对63个未见过的控制词汇对表现出显著的泛化能力，相似度从0.3143提高到0.4033（+28.32%，p < 7.17 x 10^-27）。这些结果表明，TLI增强了模型保留和传播其固有早期层跨语言知识的能力，为提升低资源语言模型的词汇对齐提供了一种参数高效且有效的策略。

</details>


### [28] [Understanding GUI Agent Localization Biases through Logit Sharpness](https://arxiv.org/abs/2506.15425)
**中文标题：通过Logit锐度理解GUI代理的定位偏差**

*Xingjian Tao,Yiwei Wang,Yujun Cai,Zhicheng Yang,Jing Tang*

主要分类: cs.CL

摘要简述: 本文提出了一种细粒度评估框架和峰值锐度评分（PSS），用于量化多模态大语言模型（MLLMs）在GUI代理中的定位偏差，并通过上下文感知裁剪技术提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型在GUI代理中表现出色，但其系统性定位错误（幻觉）影响了可靠性。本文旨在揭示这些错误的细粒度模式，并提出量化模型不确定性的方法。

研究方法: 1. 提出四类模型预测分类框架；2. 引入峰值锐度评分（PSS）量化语义连续性与坐标预测的对齐；3. 提出无需训练的上下文感知裁剪技术优化输入。

研究结果: 实验表明，该框架和方法能有效揭示模型失败模式，提升GUI代理行为的可解释性和鲁棒性。

研究结论: 本文的评估框架和PSS为GUI代理的定位偏差提供了新见解，上下文感知裁剪技术进一步提升了模型性能。

中文摘要: 多模态大语言模型（MLLMs）使GUI代理能够通过将语言映射到空间动作来与操作系统交互。尽管性能出色，这些模型常出现幻觉——系统性定位错误，影响可靠性。我们提出了一种细粒度评估框架，将模型预测分为四类，揭示了传统准确率指标之外的失败模式。为量化模型不确定性，我们引入了峰值锐度评分（PSS），用于评估坐标预测中语义连续性与logits分布的对齐。基于此，我们进一步提出上下文感知裁剪，一种无需训练的技术，通过自适应优化输入上下文提升模型性能。大量实验表明，我们的框架和方法提供了可操作的见解，增强了GUI代理行为的可解释性和鲁棒性。

</details>


### [29] [AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need](https://arxiv.org/abs/2506.15451)
**中文标题：AgentGroupChat-V2：分治是LLM多智能体系统的关键**

*Zhouhong Gu,Xiaoxuan Zhu,Yin Cai,Hao Shen,Xingzhou Chen,Qingyi Wang,Jialin Li,Xiaoran Shi,Haoran Guo,Wenxuan Huang,Hongwei Feng,Yanghua Xiao,Zheyu Ye,Yao Hu,Shaosheng Cao*

主要分类: cs.CL

摘要简述: AgentGroupChat-V2是一种基于大语言模型的多智能体系统框架，通过分治并行架构、自适应协作引擎和智能体组织优化策略，显著提升了复杂任务处理的效率和性能。实验表明，其在多个领域表现优异，尤其在复杂推理任务中优势明显。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大语言模型的多智能体系统在系统架构设计、跨领域通用性和性能保证方面面临挑战，尤其是在任务复杂性和智能体数量增加时。本文旨在通过AgentGroupChat-V2框架解决这些问题。

研究方法: AgentGroupChat-V2采用三种创新方法：(1)分治并行架构，将用户查询分解为层次化任务森林结构；(2)自适应协作引擎，动态选择异构LLM组合和交互模式；(3)结合分治方法的智能体组织优化策略。

研究结果: 实验结果显示，AgentGroupChat-V2在GSM8K上准确率达91.50%（比最佳基线高5.6个百分点），在AIME上准确率为30.4%（接近其他方法的两倍），在HumanEval上pass@1为79.20%。任务难度越高，性能优势越显著。

研究结论: AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，尤其在复杂推理场景中具有显著优势。

中文摘要: 基于大语言模型的多智能体系统在社交模拟和复杂任务解决领域展现出巨大潜力。然而，当前框架在系统架构设计、跨领域通用性和性能保证方面面临关键挑战，尤其是随着任务复杂性和智能体数量的增加。我们提出了AgentGroupChat-V2，通过三项核心创新解决这些挑战：(1)分治完全并行架构，将用户查询分解为层次化任务森林结构，实现依赖管理和分布式并发处理；(2)自适应协作引擎，根据任务特性动态选择异构LLM组合和交互模式；(3)结合分治方法的智能体组织优化策略。大量实验表明，AgentGroupChat-V2在多个领域表现优异，GSM8K准确率达91.50%（比最佳基线高5.6个百分点），AIME准确率为30.4%（接近其他方法的两倍），HumanEval pass@1为79.20%。随着任务难度增加，性能优势更加显著，尤其在MATH Level 5问题上，改进超过现有最佳基线11个百分点。这些结果证实，AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，在复杂推理场景中具有显著优势。代码发布于https://github.com/MikeGu721/AgentGroupChat-V2。

</details>


### [30] [RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation](https://arxiv.org/abs/2506.15455)
**中文标题：RE-IMAGINE：用于推理评估的符号基准合成**

*Xinnuo Xu,Rachel Lawrence,Kshitij Dubey,Atharva Pandey,Risa Ueno,Fabian Falck,Aditya V. Nori,Rahul Sharma,Amit Sharma,Javier Gonzalez*

主要分类: cs.CL

摘要简述: 本文提出RE-IMAGINE框架，用于评估大型语言模型（LLMs）的推理能力层次，并通过自动生成不同层次的问题变体，揭示模型是否依赖记忆而非真实推理。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理任务中表现优异，但尚不清楚其高准确率是源于真实推理能力还是对训练数据的统计记忆。受因果阶梯理论启发，本文旨在通过多层次的推理评估框架揭示模型的真实能力。

研究方法: RE-IMAGINE框架通过中间符号表示生成不同层次（关联、干预和反事实）的问题变体，避免模型仅依赖记忆。该框架适用于数学、代码和逻辑等多个领域，并自动生成大量无法仅凭记忆解决的问题。

研究结果: 在四个广泛使用的基准测试中，模型在面对问题变体时性能下降，表明其部分表现依赖于统计记忆，而非真实推理能力。

研究结论: RE-IMAGINE揭示了大型语言模型在推理任务中对记忆的依赖，为未来研究提供了评估和提升模型多层次推理能力的工具。

中文摘要: 近期的大型语言模型（LLMs）在推理基准测试中报告了高准确率。然而，尚不清楚这些结果是源于真实推理还是对训练数据的统计记忆。受因果阶梯理论（Pearl, 2009）及其三个层次（关联、干预和反事实）的启发，本文提出了RE-IMAGINE框架，用于表征LLMs的推理能力层次，并提供一个自动化流程以生成不同层次的问题变体。通过中间符号表示对问题进行修改，RE-IMAGINE可以生成任意多无法仅凭记忆解决的问题。此外，该框架具有通用性，适用于数学、代码和逻辑等多个推理领域。我们在四个广泛使用的基准测试中展示了该框架，并观察到模型在面对问题变体时性能下降。这些评估表明，模型的部分表现依赖于统计记忆，为未来研究提供了针对推理能力层次的进一步探索方向。

</details>


### [31] [Context-Informed Grounding Supervision](https://arxiv.org/abs/2506.15480)
**中文标题：基于上下文的生成监督**

*Hyunji Lee,Seunghyun Yoon,Yunjae Won,Hanseok Oh,Geewook Kim,Trung Bui,Franck Dernoncourt,Elias Stengel-Eskin,Mohit Bansal,Minjoon Seo*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CINGS的后训练监督方法，通过将相关上下文前置到响应中并仅计算响应标记的损失，显著提升了语言模型在文本和视觉领域的生成准确性，同时不降低下游任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在生成响应时可能依赖外部知识以减少幻觉，但简单地附加上下文并不能确保生成的准确性。因此，需要一种新的监督方法，确保模型能够更好地依赖外部上下文。

研究方法: 提出Context-INformed Grounding Supervision（CINGS），在训练时将相关上下文前置到响应中，但仅计算响应标记的损失，并屏蔽上下文。这种方法旨在增强模型对外部上下文的依赖。

研究结果: 实验表明，CINGS训练的模型在文本和视觉领域的生成中表现出更强的准确性。在文本领域，CINGS在11个信息检索数据集上优于其他方法；在视觉语言领域，减少了幻觉并保持了事实一致性。

研究结论: CINGS通过改变模型的先验知识和行为，隐式鼓励其更多地依赖外部上下文，从而在不影响下游任务性能的情况下显著提升了生成准确性。

中文摘要: 大型语言模型（LLMs）常需补充外部知识以提供未编码的信息或减少幻觉。在这种情况下，我们希望模型能够基于提供的外部上下文生成响应。然而，先前研究表明，仅在推理时附加上下文并不能确保生成的准确性。为此，我们提出了基于上下文的生成监督（CINGS），这是一种后训练监督方法，其中模型在训练时将相关上下文前置到响应中，但仅计算响应标记的损失并屏蔽上下文。实验表明，CINGS训练的模型在文本和视觉领域的生成中表现出更强的准确性。在文本领域，CINGS在11个信息检索数据集上优于其他训练方法，并与推理时生成技术互补。在视觉语言领域，将视觉语言模型的LLM主干替换为CINGS训练的模型，减少了四个基准测试中的幻觉，并保持了生成响应的事实一致性。这种改进的准确性并未导致下游任务性能的下降。最后，我们分析了CINGS增强生成准确性的机制，发现它改变了模型的先验知识和行为，隐式鼓励其更多地依赖外部上下文。

</details>


### [32] [SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling](https://arxiv.org/abs/2506.15498)
**中文标题：SPARE：基于参考引导评估的单次标注框架用于自动过程监督与奖励建模**

*Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych*

主要分类: cs.CL

摘要简述: SPARE是一种新颖的结构化框架，通过单次标注和参考引导评估，提升大型语言模型在多步推理任务中的性能，同时显著提高效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前多步推理任务中，高效且高质量的自动过程标注仍是一个重大挑战。SPARE旨在通过单次标注和参考引导评估解决这一问题。

研究方法: SPARE框架通过将每个解决步骤与参考解决方案中的一个或多个步骤对齐，并辅以明确的评估理由，实现单次、逐步骤的标注。

研究结果: 实验表明，SPARE在数学推理、多跳组合问答和空间推理任务中显著提升了推理性能，同时效率提高了2.6倍，仅需38%的运行时间。

研究结论: SPARE不仅提升了推理性能，还大幅提高了标注效率，为自动过程监督和奖励建模提供了有效工具。

中文摘要: 过程或逐步监督在提升大型语言模型（LLM）的复杂多步推理能力中发挥了关键作用。然而，高效、高质量的自动过程标注仍是一个重大挑战。为此，我们提出了单次标注与参考引导评估（SPARE），这是一种新颖的结构化框架，通过将每个解决步骤与参考解决方案中的一个或多个步骤对齐，并辅以明确的评估理由，实现单次、逐步骤的标注。我们展示了参考引导的步骤级评估在数学推理、多跳组合问答和空间推理四个数据集上有效促进了过程监督。实验表明，SPARE在以下方面优于基线方法：（1）在离线强化学习设置中微调模型以进行推理时的贪婪解码；（2）训练奖励模型以对多个LLM生成输出进行排名或聚合。此外，SPARE在具有挑战性的数学数据集上表现出竞争力，同时效率提高了2.6倍，仅需38%的运行时间，优于基于树搜索的自动标注方法。我们公开了代码库和训练好的SPARE-PRM模型，以促进进一步研究和可重复性。

</details>


### [33] [Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge](https://arxiv.org/abs/2506.15504)
**中文标题：利用双向动态交互与情感知识增强夸张与隐喻检测**

*Li Zheng,Sihang Wang,Hao Fei,Zuquan Peng,Fei Li,Jianming Fu,Chong Teng,Donghong Ji*

主要分类: cs.CL

摘要简述: 本文提出了一种基于情感引导和双向动态交互的夸张与隐喻检测框架（EmoBi），通过挖掘情感内涵和领域映射，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的夸张和隐喻检测方法多关注表面文本特征，忽略了二者之间的关联及隐含情感的作用，导致检测效果受限。

研究方法: EmoBi框架包含情感分析模块、基于情感的领域映射模块和双向动态交互模块，通过挖掘情感内涵和领域映射，实现夸张与隐喻的相互促进。

研究结果: 实验表明，EmoBi在四个数据集上均优于基线方法，夸张检测F1分数提升28.1%，隐喻检测提升23.1%。

研究结论: EmoBi通过情感引导和双向交互，显著提升了夸张与隐喻检测的准确性和可靠性，具有重要应用潜力。

中文摘要: 文本中的夸张与隐喻检测对自然语言处理任务具有重要意义。然而，由于其语义隐晦和表达多样，识别它们极具挑战性。现有方法多关注表面文本特征，忽略了夸张与隐喻的关联及隐含情感的作用。为此，我们提出了一种基于情感引导和双向动态交互的夸张与隐喻检测框架（EmoBi）。首先，情感分析模块深入挖掘夸张与隐喻背后的情感内涵；其次，基于情感的领域映射模块识别目标与源领域，以深入理解其隐含意义；最后，双向动态交互模块实现夸张与隐喻的相互促进。同时，设计了验证机制以确保检测的准确性和可靠性。实验表明，EmoBi在四个数据集上均优于基线方法，夸张检测F1分数在TroFi数据集上提升28.1%，隐喻检测在HYPO-L数据集上提升23.1%。这些结果通过深入分析验证了该方法的有效性和潜力。

</details>


### [34] [Lessons from Training Grounded LLMs with Verifiable Rewards](https://arxiv.org/abs/2506.15522)
**中文标题：基于可验证奖励的接地大语言模型训练经验**

*Shang Hong Sim,Tej Deep Pala,Vernon Toh,Hai Leong Chieu,Amir Zadeh,Chuan Li,Navonil Majumder,Soujanya Poria*

主要分类: cs.CL

摘要简述: 本文探讨如何通过强化学习和内部推理提升大语言模型（LLMs）的可靠性和可验证性，采用GRPO方法优化答案正确性、引用充分性和拒绝质量，显著提升了模型在未回答查询和引用生成任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于检索增强生成（RAG）的大语言模型在生成可信赖回答时仍存在不足，如遗漏明确答案、错误引用或拒绝回答。本文旨在通过强化学习和内部推理解决这些问题，提升模型的可靠性和可验证性。

研究方法: 使用GRPO（Group Relative Policy Optimization）方法，通过可验证的结果奖励（答案正确性、引用充分性和拒绝质量）训练模型，无需昂贵标注或黄金推理轨迹。采用两阶段训练策略，先优化答案和引用行为，再优化拒绝行为。

研究结果: 实验表明，结合推理增强的模型在ASQA、QAMPARI、ELI5和ExpertQA等任务中显著优于仅基于指令调优的模型，尤其在处理未回答查询和生成高质量引用时表现突出。两阶段训练进一步提升了模型的稳定性。

研究结论: 本文证明了强化学习、分阶段优化和结果驱动的训练方法对提升大语言模型的可验证性和可靠性具有重要价值，为未来研究提供了新方向。

中文摘要: 生成可靠且可信的回答仍然是大语言模型（LLMs）面临的关键挑战。尽管基于检索增强生成（RAG）和引用接地的方法显示出潜力，但指令调优模型在简单场景中仍频繁失败：遗漏明确答案、错误引用或在证据可用时拒绝回答。本文探索了如何通过强化学习（RL）和内部推理增强LLMs的接地性。我们采用GRPO（Group Relative Policy Optimization）方法，通过可验证的结果奖励（答案正确性、引用充分性和拒绝质量）训练模型，无需黄金推理轨迹或昂贵标注。在ASQA、QAMPARI、ELI5和ExpertQA等任务上的综合实验表明，推理增强模型显著优于仅基于指令调优的变体，尤其是在处理未回答查询和生成高质量引用时表现突出。两阶段训练（先优化答案和引用行为，再优化拒绝行为）进一步通过稳定学习信号提升了接地性。此外，我们通过GPT-4蒸馏重新审视指令调优，发现将其与GRPO结合可提升长生成式问答任务的性能。总体而言，我们的研究结果凸显了推理、分阶段优化和结果驱动强化学习对构建更可验证和可靠LLMs的价值。

</details>


### [35] [RATTENTION: Towards the Minimal Sliding Window Size in Local-Global Attention Models](https://arxiv.org/abs/2506.15545)
**中文标题：RATTENTION：迈向局部-全局注意力模型的最小滑动窗口尺寸**

*Bailin Wang,Chang Lan,Chong Wang,Ruoming Pang*

主要分类: cs.CL

摘要简述: 本文提出RATTENTION，一种结合局部注意力和线性注意力的新方法，旨在解决局部注意力模型因窗口大小限制而忽略外部信息的问题。实验表明，RATTENTION在512窗口大小下性能媲美全注意力模型，同时提升效率。


<details>
  <summary>详细信息</summary>
研究动机: 局部-全局注意力模型在效率和性能之间存在权衡：大窗口保留性能但效率提升有限，小窗口则可能导致性能下降。本文旨在通过改进局部注意力模型，使其在短上下文场景中也能实现高效且高性能。

研究方法: 提出RATTENTION，将局部注意力与专门设计的线性注意力机制结合，以捕捉窗口外的信息。通过预训练实验验证其有效性，并优化内核实现以保持训练效率。

研究结果: 在3B和12B规模的预训练实验中，RATTENTION在512窗口大小下性能与全注意力模型相当，同时在RULER基准测试中表现出更好的长上下文性能，且训练效率未受影响。

研究结论: RATTENTION通过结合局部和线性注意力，显著提升了局部注意力模型的性能与效率平衡，为短上下文和长上下文任务提供了更优解决方案。

中文摘要: 局部-全局注意力模型近年来成为标准Transformer的有力替代方案，有望提升训练和推理效率。然而，窗口大小的选择存在帕累托权衡：大窗口性能接近全注意力但短上下文场景效率提升有限，小窗口则可能导致性能下降。当前模型（如Gemma2和Mistral）采用保守窗口大小（如4096，预训练长度为8192）以保持性能。本文研究如何改变这一权衡，使局部-全局模型在短上下文中也能实现效率提升。核心动机是解决局部注意力完全忽略窗口外信息的固有局限。我们探索了RATTENTION，一种结合专门线性注意力机制的局部注意力变体，旨在捕捉窗口外信息。3B和12B规模的预训练实验表明，RATTENTION在性能与效率间实现了更优权衡。512窗口大小的RATTENTION在多种场景下性能与全注意力模型相当。此外，RATTENTION的线性注意力组件的循环特性提升了长上下文性能（RULER基准验证）。这些改进未牺牲训练效率：得益于专用内核实现和更小窗口，RATTENTION训练速度与现有先进方法相当。

</details>


### [36] [Approximating Language Model Training Data from Weights](https://arxiv.org/abs/2506.15553)
**中文标题：从权重近似语言模型的训练数据**

*John X. Morris,Junjie Oscar Yin,Woojeong Kim,Vitaly Shmatikov,Alexander M. Rush*

主要分类: cs.CL

摘要简述: 现代语言模型通常公开权重但封闭训练数据。本文提出从模型权重近似训练数据的问题，并开发了一种基于梯度的方法从公共文本语料库中选择匹配数据，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代语言模型的训练数据通常不公开，而权重是公开的。本文旨在解决如何仅通过模型权重近似还原训练数据的问题，为模型分析和数据恢复提供新思路。

研究方法: 提出了一种基于梯度的数据选择方法，从大型公共文本语料库中筛选与原始模型权重最匹配的数据。实验包括分类任务和监督微调任务，验证方法的有效性。

研究结果: 在AG News分类任务中，方法将性能从65%提升至80%，接近专家基准的88%。在MSMARCO文档的监督微调任务中，困惑度从3.3降至2.3，接近专家模型的2.0。

研究结论: 本文方法能够有效从公开语料库中恢复接近原始训练数据的数据子集，显著提升模型性能，为数据近似问题提供了实用解决方案。

中文摘要: 现代语言模型通常公开权重但封闭训练数据。我们形式化了从模型权重近似训练数据的问题，并提出了一些基线方法和指标。我们开发了一种基于梯度的方法，从大型公共文本语料库中选择匹配度最高的数据，并展示了其在仅给定原始模型和微调模型权重时恢复有用数据的有效性。即使真实训练数据完全未知，我们的方法也能从公共网络文档中定位一个小子集，用于训练接近原始模型性能的模型，适用于分类和监督微调任务。在AG News分类任务中，我们的方法将性能从65%（随机选择数据）提升至80%，接近专家基准的88%。在MSMARCO网络文档的监督微调任务中，我们的方法将困惑度从3.3降至2.3，而专家LLAMA模型的困惑度为2.0。

</details>


### [37] [PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction](https://arxiv.org/abs/2506.15556)
**中文标题：PredGen：通过输入时推测加速大型语言模型推理以实现实时语音交互**

*Shufan Li,Aditya Grover*

主要分类: cs.CL

摘要简述: 论文提出PredGen框架，通过输入时推测解码加速大型语言模型（LLM）的推理，显著减少实时语音交互中的延迟，提升用户体验。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在实时语音聊天应用中常因生成第一句话的延迟导致音频输出滞后，影响用户体验，尤其是在计算资源有限的消费级硬件上。

研究方法: 提出Predictive Generation（PredGen）框架，在用户仍在说话时生成候选响应，通过推测解码提前启动文本转语音（TTS）处理，减少延迟。

研究结果: 在Lmsys和MT-Bench数据集上的模拟实验表明，PredGen可将延迟降低约2倍，且仅需少量额外计算成本。

研究结论: PredGen有效解决了LLM在实时语音交互中的延迟问题，显著提升了用户体验，同时计算开销极小。

中文摘要: 大型语言模型（LLM）广泛应用于实时语音聊天应用，通常与文本转语音（TTS）系统结合生成音频响应。然而，其庞大的规模常导致用户输入结束到音频输出开始之间存在明显延迟，影响用户体验。这种延迟在LLM作为单用户语音助手部署于计算能力有限的消费级硬件上时尤为突出。我们发现，延迟主要由LLM生成第一句话所需时间主导，而TTS系统需逐句合成音频响应。为解决这一瓶颈，我们提出预测生成（PredGen）框架，通过输入时的推测解码减轻甚至消除这一延迟。PredGen在用户仍在说话时生成候选响应，使系统能以最小延迟启动TTS处理。在Lmsys和MT-Bench数据集上的模拟实验表明，该方法可有效将延迟降低约2倍，且仅需输入时极少的额外计算成本。

</details>


### [38] [Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models](https://arxiv.org/abs/2506.15568)
**中文标题：性别包容性公平指数（GIFI）：一种评估大型语言模型中性别多样性的多层次框架**

*Zhengyang Shan,Emily Ruth Diana,Jiawei Zhou*

主要分类: cs.CL

摘要简述: 本文提出了一种新颖的多层次性别包容性公平指数（GIFI），用于全面评估大型语言模型（LLM）在处理二元和非二元性别时的公平性。通过对22种开源和专有LLM的广泛评估，发现其性别包容性存在显著差异，为未来提升生成模型的性别公平性提供了重要基准。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注二元性别区分，而忽略了非二元性别的包容性。本文旨在填补这一空白，通过开发一种全面的评估指标（GIFI），量化LLM在多元性别标识下的公平性，揭示其潜在的偏见。

研究方法: 提出性别包容性公平指数（GIFI），通过多层次评估方法，从简单的性别代词测试到模型生成和认知行为的复杂分析，全面考察LLM在不同性别假设下的表现。对22种不同规模和能力的LLM进行了广泛评估。

研究结果: 评估结果显示，不同LLM在性别包容性方面存在显著差异，部分模型表现出明显的性别偏见。GIFI为识别和量化这些偏见提供了有效工具。

研究结论: 本文强调了提升LLM性别包容性的重要性，GIFI为未来研究提供了关键基准，推动生成模型在性别公平性方面的进步。

中文摘要: 本文对大型语言模型（LLM）的性别公平性进行了全面评估，重点关注其处理二元和非二元性别的能力。与以往研究主要关注二元性别不同，我们提出了性别包容性公平指数（GIFI），这是一种新颖且全面的指标，用于量化LLM的多元性别包容性。GIFI包含从简单的性别代词测试到模型生成和认知行为的多层次评估，揭示了不同性别标识相关的偏见。我们对22种开源和专有LLM进行了广泛评估，发现其性别包容性存在显著差异。本研究强调了提升LLM包容性的重要性，为未来生成模型性别公平性的发展提供了关键基准。

</details>


### [39] [SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification](https://arxiv.org/abs/2506.15569)
**中文标题：SciVer：评估多模态科学声明验证的基础模型**

*Chengye Wang,Yifei Shen,Zexi Kuang,Arman Cohan,Yilun Zhao*

主要分类: cs.CL

摘要简述: SciVer是首个专门评估多模态科学声明验证能力的基准测试，包含3000个专家标注的示例，覆盖4种常见推理类型。实验发现，21种前沿多模态基础模型与人类专家存在显著性能差距，揭示了开源模型的关键局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏专门针对多模态科学声明验证的基准测试，SciVer旨在填补这一空白，评估基础模型在此任务中的表现，并推动模型在多模态科学文献中的理解和推理能力。

研究方法: SciVer包含3000个专家标注的示例，覆盖1133篇科学论文和4种常见推理类型。通过评估21种前沿多模态基础模型（如o4-mini、Gemini-2.5-Flash等），结合检索增强生成（RAG）和人工错误分析，进行细粒度性能评估。

研究结果: 实验结果显示，21种前沿多模态基础模型在SciVer上的表现显著落后于人类专家。通过RAG和人工错误分析，发现当前开源模型在多模态科学文献任务中存在关键局限性。

研究结论: SciVer揭示了多模态基础模型在科学声明验证中的性能差距，为提升模型在多模态科学文献中的理解和推理能力提供了重要见解。

中文摘要: 我们介绍了SciVer，这是首个专门设计用于评估基础模型在多模态科学背景下验证声明能力的基准测试。SciVer包含3000个专家标注的示例，覆盖1133篇科学论文，分为四个子集，每个子集代表多模态科学声明验证中的一种常见推理类型。为支持细粒度评估，每个示例均包含专家标注的支持证据。我们评估了21种前沿多模态基础模型的性能，包括o4-mini、Gemini-2.5-Flash、Llama-3.2-Vision和Qwen2.5-VL。实验显示，这些模型在SciVer上的表现与人类专家存在显著差距。通过深入分析检索增强生成（RAG）和人工错误评估，我们揭示了当前开源模型的关键局限性，为提升模型在多模态科学文献任务中的理解和推理能力提供了重要见解。

</details>


### [40] [DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement](https://arxiv.org/abs/2506.15583)
**中文标题：DiscoSG：通过迭代图优化实现话语级文本场景图解析**

*Shaoqing Lin,Chong Teng,Fei Li,Donghong Ji,Lizhen Qu,Zhuang Li*

主要分类: cs.CL

摘要简述: 本文提出了一种新的任务DiscoSG，用于解析多句子描述的文本场景图，并提出了数据集DiscoSG-DS和高效方法DiscoSG-Refiner，显著提升了性能并降低了计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本场景图解析方法主要针对单句子描述，无法有效处理多句子描述中的跨句子指代现象，导致图结构碎片化并影响下游任务性能。

研究方法: 提出DiscoSG-Refiner方法，使用一个小型PLM生成基础图，再通过另一个PLM迭代优化图结构，显著降低了计算开销。

研究结果: DiscoSG-Refiner在SPICE指标上比基线方法提升约30%，推理速度比GPT-4快86倍，并显著提升了下游任务性能。

研究结论: DiscoSG-Refiner为多句子文本场景图解析提供了一种高效且性能优越的解决方案，推动了相关领域的发展。

中文摘要: 视觉语言模型（VLMs）现在能够生成话语级的多句子视觉描述，这对原本设计用于单句子描述的文本场景图解析器提出了挑战。现有方法通常合并句子级解析结果，但往往忽略了跨句子指代现象，导致图结构碎片化并降低下游任务性能。为此，我们提出了一个新任务——话语级文本场景图解析（DiscoSG），并发布了数据集DiscoSG-DS，包含400个专家标注和8,430个合成的多句子描述-图对。每个描述平均包含9个句子，每个图的边数至少是现有数据集的3倍。尽管在DiscoSG-DS上微调大型PLM（如GPT-4）可将SPICE指标提升约48%，但高昂的推理成本和许可限制阻碍了其开源应用，而小型PLM则难以处理复杂图结构。我们提出了DiscoSG-Refiner方法，通过一个小型PLM生成基础图，再使用另一个PLM迭代优化图结构，显著降低了全图生成的开销。实验表明，使用两个Flan-T5-Base模型的DiscoSG-Refiner在SPICE指标上仍比最佳基线提升约30%，推理速度比GPT-4快86倍，并显著提升了下游任务性能，如话语级描述评估和幻觉检测。代码和数据可在https://github.com/ShaoqLin/DiscoSG获取。

</details>


### [41] [WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts](https://arxiv.org/abs/2506.15594)
**中文标题：WikiMixQA：一个面向表格和图表的问答多模态基准**

*Negar Foroutan,Angelika Romanou,Matin Ansaripour,Julian Martin Eisenschlos,Karl Aberer,Rémi Lebret*

主要分类: cs.CL

摘要简述: 本文介绍了WikiMixQA，一个包含1000道多选题的基准测试，用于评估从4000个维基百科页面提取的表格和图表中的跨模态推理能力。12种先进视觉语言模型的测试显示，专有模型在直接上下文下表现较好，但在长文档检索中性能显著下降，开源模型表现更差。


<details>
  <summary>详细信息</summary>
研究动机: 文档通常包含复杂的布局、表格和图表，这对自动文档理解（DU）提出了挑战。尽管视觉语言大模型（VLLMs）在多任务中表现优异，但其处理长上下文视觉输入的能力尚不明确。因此，需要一个新的基准来评估跨模态推理能力。

研究方法: 本文构建了WikiMixQA基准，包含1000道多选题，覆盖7个主题的4000个维基百科页面中的表格和图表。测试了12种先进视觉语言模型，评估其在直接上下文和长文档检索场景下的表现。

研究结果: 专有模型在直接上下文下准确率约为70%，但在长文档检索中性能显著下降。GPT-4-o是唯一在此场景下准确率超过50%的模型，而开源模型最高准确率仅为27%。

研究结论: 研究揭示了长上下文多模态推理的挑战，并确立了WikiMixQA作为推动文档理解研究的重要基准。

中文摘要: 文档是保存和传播信息的基础，通常包含复杂的布局、表格和图表，这对自动文档理解（DU）提出了重大挑战。尽管视觉语言大模型（VLLMs）在多项任务中表现出改进，但其处理长上下文视觉输入的有效性尚不明确。本文介绍了WikiMixQA，一个包含1000道多选题的基准，用于评估从4000个维基百科页面中提取的表格和图表的跨模态推理能力，覆盖七个不同主题。与现有基准不同，WikiMixQA强调复杂推理，要求模型综合多模态信息。我们评估了12种先进的视觉语言模型，发现专有模型在提供直接上下文时准确率约为70%，但在需要从长文档中检索时性能显著下降。其中，GPT-4-o是唯一在此场景下准确率超过50%的模型，而开源模型表现更差，最高准确率仅为27%。这些发现突显了长上下文多模态推理的挑战，并将WikiMixQA确立为推进文档理解研究的关键基准。

</details>


### [42] [From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns](https://arxiv.org/abs/2506.15598)
**中文标题：从模型到课堂：基于叙事与难度考量的葡萄牙语生成多选题评估**

*Bernardo Leite,Henrique Lopes Cardoso,Pedro Pinto,Abel Ferreira,Luís Abreu,Isabel Rangel,Sandra Monteiro*

主要分类: cs.CL

摘要简述: 本文研究了生成式AI在葡萄牙语阅读多选题（MCQ）生成中的应用，重点关注题目与课程叙事的匹配及难度分级。通过专家评审和学生回答的心理测量分析，发现生成题目质量接近人工编写，但仍存在语义清晰度和干扰项设计问题。


<details>
  <summary>详细信息</summary>
研究动机: 手动制作多难度、针对阅读技能的MCQ耗时且昂贵，而生成式AI为自动化提供了可能。然而，生成题目的质量评估不足，尤其是失败案例，且葡萄牙语等非英语语言研究较少。本文旨在填补这一空白。

研究方法: 研究利用生成模型为葡萄牙语阅读生成MCQ，确保题目与课程叙事相关且难度多样。通过专家评审和学生回答的心理测量分析评估题目质量。

研究结果: 生成MCQ质量接近人工编写，但存在语义模糊和答案可答性问题，干扰项设计仍需改进以满足高质量MCQ标准。

研究结论: 生成式AI可高效生成葡萄牙语MCQ，但需进一步优化语义清晰度和干扰项设计，以提升教育实用性。

中文摘要: 尽管多选题（MCQ）对学习和评估具有重要价值，但手动制作具有不同难度级别和针对性阅读技能的题目仍是一项耗时且昂贵的任务。生成式AI的最新进展为高效自动化MCQ生成提供了机会。然而，对生成MCQ实际质量和可靠性的评估关注有限，尤其是在生成失败的情况下。当生成的MCQ需应用于实际场景时，这一问题尤为重要。此外，大多数MCQ生成研究集中于英语，其他语言研究较少。本文探讨了当前生成模型在葡萄牙语（一种形态丰富的语言）阅读多选题生成中的能力。研究聚焦于生成与课程相关叙事元素匹配且覆盖不同难度级别的MCQ，并通过专家评审和学生回答的心理测量分析评估其适合小学生使用的程度。结果表明，当前模型生成的MCQ质量与人工编写相当，但仍存在语义清晰度和答案可答性问题。此外，生成能吸引学生并符合高质量MCQ选项设计标准的干扰项仍具挑战性。

</details>


### [43] [The Compositional Architecture of Regret in Large Language Models](https://arxiv.org/abs/2506.15617)
**中文标题：大型语言模型中后悔的组合架构**

*Xiangxiang Cui,Shu Yang,Tianjin Huang,Wanyu Lin,Lijie Hu,Di Wang*

主要分类: cs.CL

摘要简述: 本文研究大型语言模型中的后悔机制，提出构建后悔数据集的方法及两种新指标（S-CDI和RDS），成功识别最优后悔表征层和神经元功能分组，揭示了信息处理的耦合与解耦模式。


<details>
  <summary>详细信息</summary>
研究动机: 研究大型语言模型中的后悔表达机制，旨在提升模型可靠性并揭示神经网络中的认知编码方式。当前面临缺乏专门数据集、表征层优化指标及神经元分析工具的挑战。

研究方法: 提出三步方法：(1) 设计提示场景构建后悔数据集；(2) 使用S-CDI指标识别最优后悔表征层；(3) 通过RDS和GIC指标分析后悔神经元及其激活模式。

研究结果: 实验成功识别最优后悔表征层（S-CDI显著提升分类性能），发现信息处理的M形解耦模式，并将神经元分为后悔、非后悔和双功能三类。

研究结论: 本研究为后悔机制分析提供了系统性工具，揭示了模型内部信息处理动态，为提升模型可靠性和认知研究奠定基础。

中文摘要: 大型语言模型中的后悔指其在面对与先前生成错误信息相矛盾的证据时表现出的明确后悔表达。研究后悔机制对提升模型可靠性至关重要，并有助于揭示神经网络中的认知编码方式。为理解此机制，需首先识别模型输出中的后悔表达，再分析其内部表征。这一分析需考察模型的隐藏状态（神经元层面的信息处理），但面临三大挑战：(1) 缺乏捕捉后悔表达的专门数据集；(2) 缺少识别最优后悔表征层的指标；(3) 缺乏识别和分析后悔神经元的指标。针对这些局限，本文提出：(1) 通过策略性设计提示场景构建全面后悔数据集的工作流程；(2) 使用监督压缩-解耦指数（S-CDI）识别最优后悔表征层；(3) 通过后悔主导分数（RDS）识别后悔神经元，并用群体影响系数（GIC）分析激活模式。实验结果成功利用S-CDI识别最优后悔表征层，显著提升探针分类性能；同时发现模型层间的M形解耦模式，揭示了信息处理在耦合与解耦间的交替。通过RDS，神经元被分为三类功能组：后悔神经元、非后悔神经元和双功能神经元。

</details>


### [44] [Minding the Politeness Gap in Cross-cultural Communication](https://arxiv.org/abs/2506.15623)
**中文标题：跨文化沟通中的礼貌差距研究**

*Yuka Machino,Matthias Hofer,Max Siegel,Joshua B. Tenenbaum,Robert D. Hawkins*

主要分类: cs.CL

摘要简述: 研究发现英式与美式英语中强化词（如'quite'和'very'）的解读差异源于字面意义和语用因素（如礼貌与简洁）的复杂交互作用。


<details>
  <summary>详细信息</summary>
研究动机: 跨文化沟通中的误解常源于对词语解读的微妙差异，但尚不清楚这些差异是源于字面意义还是语用因素（如礼貌与简洁）。本文旨在探究英式与美式英语中强化词解读的差异来源。

研究方法: 通过三个实验比较英式与美式英语使用者对强化词（如'quite'和'very'）的解读，并开发了一个计算认知模型，模拟听者对说话者在信息量、礼貌和表达成本之间的权衡推理。

研究结果: 模型分析表明，强化词解读的跨文化差异源于字面意义和表达成本权重的不同组合，而非单纯的语义差异或礼貌规范。

研究结论: 跨文化解读差异是字面意义与语用因素复杂交互的结果，挑战了仅基于语义或礼貌规范的解释。

中文摘要: 跨文化沟通中的误解常源于对词语解读的微妙差异，但尚不清楚这些差异是源于字面意义还是更普遍的语用因素（如礼貌与简洁）。本文通过三个实验研究了英式与美式英语使用者对强化词（如'quite'和'very'）的解读。为了更好地理解这些跨文化差异，我们开发了一个计算认知模型，模拟听者对说话者在信息量、礼貌和表达成本之间的权衡推理。模型比较表明，强化词解读的跨文化差异源于（1）不同的字面意义和（2）表达成本权重的组合。这些发现挑战了仅基于语义变异或礼貌规范的解释，表明跨文化解读差异是两者复杂交互的结果。

</details>


### [45] [Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability](https://arxiv.org/abs/2506.15629)
**中文标题：重新审视大语言模型的组合泛化能力：基于指令遵循能力的考量**

*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

主要分类: cs.CL

摘要简述: 本文提出Ordered CommonGen基准，用于评估大语言模型（LLMs）的组合泛化与指令遵循能力，发现LLMs虽能理解指令意图，但存在概念顺序偏见，导致输出多样性低，最高指令遵循率仅约75%。


<details>
  <summary>详细信息</summary>
研究动机: 在生成式常识推理任务中，LLMs需按给定概念顺序生成句子，但现有研究未充分评估其指令遵循与组合泛化能力。为此，作者提出Ordered CommonGen基准，以填补这一空白。

研究方法: 设计Ordered CommonGen基准，通过测量有序覆盖率（ordered coverage）评估LLMs是否按指定顺序生成概念，同时对36种LLMs进行全面分析。

研究结果: LLMs虽能理解指令意图，但倾向于特定概念顺序模式，导致输出多样性低或顺序变化时结果相同。最高指令遵循率仅约75%。

研究结论: LLMs在指令遵循与组合泛化能力上仍需改进，Ordered CommonGen为未来研究提供了有效评估工具。

中文摘要: 在生成式常识推理任务（如CommonGen）中，大语言模型（LLMs）需生成包含所有给定概念的句子。然而，当关注指令遵循能力时，若提示指定概念顺序，LLMs必须按指定顺序生成句子。为此，我们提出Ordered CommonGen基准，用于评估LLMs的组合泛化与指令遵循能力。该基准通过测量有序覆盖率来评估概念是否按指定顺序生成，从而同时评估两种能力。我们对36种LLMs进行全面分析，发现LLMs虽能理解指令意图，但对特定概念顺序模式的偏见常导致输出多样性低或顺序变化时结果相同。此外，即使指令遵循能力最强的LLM，有序覆盖率也仅约75%，凸显了其在指令遵循与组合泛化能力上的改进空间。

</details>


### [46] [Oldies but Goldies: The Potential of Character N-grams for Romanian Texts](https://arxiv.org/abs/2506.15650)
**中文标题：老而弥坚：字符n-gram在罗马尼亚文本中的潜力**

*Dana Lupsa,Sanda-Maria Avram*

主要分类: cs.CL

摘要简述: 本研究通过ROST语料库评估了六种机器学习方法在罗马尼亚文本作者归属任务中的表现，发现基于字符n-gram的轻量级方法（尤其是ANN模型）能够达到最先进的准确率。


<details>
  <summary>详细信息</summary>
研究动机: 针对罗马尼亚文本的作者归属问题，研究旨在探索轻量级且可解释的字符n-gram特征是否能够在资源有限或研究较少的语言环境中实现高性能。

研究方法: 使用ROST语料库作为基准，系统评估了六种机器学习方法（SVM、LR、k-NN、DT、RF和ANN），并采用字符n-gram特征进行分类。

研究结果: ANN模型表现最佳，尤其是在使用5-gram特征时，15次运行中有4次实现了完美分类。结果表明，字符n-gram方法在罗马尼亚文本作者归属任务中具有竞争力。

研究结论: 轻量级的字符n-gram方法能够在罗马尼亚文本作者归属任务中达到最先进的性能，为资源有限或研究较少的语言环境提供了高效解决方案。

中文摘要: 本研究针对罗马尼亚文本的作者归属问题，使用ROST语料库作为标准基准。我们系统评估了六种机器学习技术：支持向量机（SVM）、逻辑回归（LR）、k近邻（k-NN）、决策树（DT）、随机森林（RF）和人工神经网络（ANN），并采用字符n-gram特征进行分类。其中，ANN模型表现最佳，在使用5-gram特征时，15次运行中有4次实现了完美分类。这些结果表明，轻量级且可解释的字符n-gram方法能够在罗马尼亚文本作者归属任务中达到最先进的准确率，媲美更复杂的方法。我们的发现凸显了简单风格特征在资源有限或研究较少的语言环境中的潜力。

</details>


### [47] [CC-LEARN: Cohort-based Consistency Learning](https://arxiv.org/abs/2506.15662)
**中文标题：CC-LEARN：基于队列的一致性学习**

*Xiao Ye,Shaswat Shrivastava,Zhaonan Li,Jacob Dineen,Shijie Lu,Avneet Ahuja,Ming Shen,Zhikun Xu,Ben Zhou*

主要分类: cs.CL

摘要简述: CC-LEARN通过基于队列的一致性学习框架，利用强化学习提升大语言模型的推理一致性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在推理任务中表现优异，但在一致性和鲁棒性方面仍有不足。本文旨在通过队列级别的强化学习，提升模型的推理稳定性。

研究方法: 提出队列一致性学习（CC-LEARN），通过定义复合目标（队列准确性、检索奖励和拒绝惩罚），利用强化学习优化模型，使其在相似问题队列中采用一致的推理模式。

研究结果: 在ARC-Challenge和StrategyQA等基准测试中，CC-LEARN显著提升了模型的准确性和推理稳定性，优于预训练和SFT基线。

研究结论: 队列级别的强化学习能有效提升大语言模型的推理一致性，为未来研究提供了新方向。

中文摘要: 大语言模型在许多任务中表现出色，但在一致性和鲁棒性推理方面仍有不足。我们提出了基于队列的一致性学习（CC-LEARN），这是一种强化学习框架，通过训练来自共享程序抽象的相似问题队列，提升大语言模型推理的可靠性。为了确保队列级别的一致性，我们定义了一个复合目标，结合队列准确性、有效问题分解的检索奖励以及对无效查询的拒绝惩罚，强化学习可直接优化这一目标，而监督微调则无法实现。优化这一奖励引导模型在所有队列成员中采用一致的推理模式。在具有挑战性的推理基准测试（包括ARC-Challenge和StrategyQA）中，实验表明CC-LEARN在预训练和SFT基线上显著提升了准确性和推理稳定性。这些结果表明，队列级别的强化学习能有效增强大语言模型的推理一致性。

</details>


### [48] [Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](https://arxiv.org/abs/2506.15674)
**中文标题：泄露的思维：大型推理模型并非隐私安全的思考者**

*Tommaso Green,Martin Gubri,Haritz Puerto,Sangdoo Yun,Seong Joon Oh*

主要分类: cs.CL

摘要简述: 研究发现大型推理模型的推理痕迹中存在隐私泄露风险，推理步骤增加会放大这种泄露，揭示了推理效用与隐私安全之间的核心矛盾。


<details>
  <summary>详细信息</summary>
研究动机: 论文旨在挑战大型推理模型的推理痕迹被视为内部且安全的假设，揭示其中可能包含的敏感用户数据泄露问题。

研究方法: 通过提示注入和代理评估，研究推理痕迹中的隐私泄露，并分析测试时计算（如增加推理步骤）对泄露的影响。

研究结果: 研究表明，增加推理步骤虽然使模型在最终答案上更谨慎，但也导致推理痕迹更冗长，隐私泄露风险更高。

研究结论: 论文强调安全措施需扩展到模型的内部推理过程，而不仅是输出结果，揭示了推理效用与隐私安全之间的核心矛盾。

中文摘要: 我们研究了作为个人代理的大型推理模型在推理痕迹中的隐私泄露问题。与最终输出不同，推理痕迹通常被认为是内部且安全的。我们通过展示推理痕迹中常包含敏感用户数据（可通过提示注入提取或意外泄露到输出中）来挑战这一假设。通过探测和代理评估，我们发现测试时计算方法（尤其是增加推理步骤）会放大这种泄露。虽然增加这些方法的预算使模型在最终答案上更谨慎，但也导致其推理更冗长，在自身思维中泄露更多信息。这揭示了一个核心矛盾：推理提高了效用，但也扩大了隐私攻击面。我们认为安全措施必须扩展到模型的内部思维，而不仅是其输出。

</details>


### [49] [Gender-Neutral Machine Translation Strategies in Practice](https://arxiv.org/abs/2506.15676)
**中文标题：实践中性别中立的机器翻译策略**

*Hillary Dawkins,Isar Nejadgholi,Chi-kiu Lo*

主要分类: cs.CL

摘要简述: 研究评估了21种机器翻译系统在性别模糊情况下的性别中立翻译表现，发现大多数系统缺乏性别中立翻译，少数系统采用特定策略实现中立翻译。


<details>
  <summary>详细信息</summary>
研究动机: 性别包容的机器翻译需要保留源语言的性别模糊性以避免性别误判和代表性伤害。然而，在语法性别语言中实现性别中立翻译具有挑战性，因此研究旨在评估现有翻译系统的表现。

研究方法: 研究评估了21种机器翻译系统在三种不同难度的翻译方向中对性别模糊的敏感性，并分类讨论了实际观察到的性别中立翻译策略。同时，研究了二元性别刻板印象对性别中立翻译的影响。

研究结果: 大多数机器翻译系统在性别模糊情况下未能提供性别中立翻译，但少数系统根据目标语言采用特定策略实现了中立翻译。

研究结论: 尽管性别中立翻译在实际应用中表现不佳，但少数系统的成功策略表明改进的可能性。研究呼吁进一步优化机器翻译系统以实现性别包容。

中文摘要: 性别包容的机器翻译（MT）应保留源语言中的性别模糊性，以避免性别误判和代表性伤害。尽管性别模糊在概念性别语言（如英语）中自然存在，但在语法性别语言中保持性别中立是一项挑战。本文评估了21种机器翻译系统在三种不同难度的翻译方向中对性别模糊的敏感性，并对实际观察到的性别中立翻译策略进行了分类和讨论。此外，我们还研究了二元性别刻板印象对性别中立翻译使用的影响。总体而言，我们发现机器翻译系统在性别模糊情况下普遍缺乏性别中立翻译。然而，我们观察到少数机器翻译系统会根据目标语言采用特定策略实现性别中立翻译。

</details>


### [50] [GenRecal: Generation after Recalibration from Large to Small Vision-Language Models](https://arxiv.org/abs/2506.15681)
**中文标题：GenRecal：从大型到小型视觉语言模型的生成再校准**

*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

主要分类: cs.CL

摘要简述: GenRecal是一种新型通用蒸馏框架，通过重新校准异构视觉语言模型（VLM）的特征表示，实现知识从大型到小型VLM的高效迁移，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型视觉语言模型（VLM）在资源受限设备上部署困难，且不同VLM架构差异大（如词汇量、分词方式等），限制了知识蒸馏的通用性。

研究方法: GenRecal框架引入“重新校准器”（Recalibrator），对齐和适配异构VLM的特征表示，从而支持跨不同类型VLM的知识迁移。

研究结果: 实验表明，GenRecal在多个基准测试中显著优于基线模型，甚至超越部分大型开源和闭源VLM。

研究结论: GenRecal为异构VLM间的知识蒸馏提供了通用解决方案，有效解决了模型部署和性能提升的难题。

中文摘要: 近年来，视觉语言模型（VLM）通过结合大型语言模型（LLM）实现了与闭源系统（如GPT-4V）相当的性能。然而，这些模型在资源受限设备上的实际部署仍面临巨大挑战，主要源于其高计算需求。这促使研究者探索将知识从大型VLM蒸馏到更高效的小型模型中。然而，不同VLM架构的多样性（如词汇量、分词方式和索引顺序的差异）限制了蒸馏的通用性。为解决这一问题，我们提出了“生成再校准”（GenRecal），一种新型通用蒸馏框架。GenRecal通过“重新校准器”对齐和适配异构VLM的特征表示，实现跨类型VLM的知识迁移。在多个基准测试中，GenRecal显著提升了基线性能，甚至超越了部分大型开源和闭源VLM。

</details>


### [51] [PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning](https://arxiv.org/abs/2506.15683)
**中文标题：PhantomHunter：基于家族感知学习的私有调优LLM生成文本检测**

*Yuhui Shi,Yehan Yang,Qiang Sheng,Hao Mi,Beizhe Hu,Chaoxi Xu,Juan Cao*

主要分类: cs.CL

摘要简述: PhantomHunter是一种专门用于检测私有调优LLM生成文本的检测器，通过家族感知学习框架捕捉基础模型及其衍生模型的共享特征，实验表明其在多个模型家族上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的普及，虚假信息和学术不端等社会问题日益严重，现有检测器对私有调优LLM生成的文本检测效果不佳，亟需解决这一问题。

研究方法: PhantomHunter采用家族感知学习框架，捕捉基础模型及其衍生模型之间的家族级共享特征，而非记忆单个模型特性，从而提升对私有调优LLM生成文本的检测能力。

研究结果: 在LLaMA、Gemma和Mistral等模型家族上的实验表明，PhantomHunter优于7种基线方法和3种工业服务，F1分数超过96%。

研究结论: PhantomHunter通过家族感知学习有效解决了私有调优LLM生成文本的检测难题，为LLM生成文本检测提供了新思路。

中文摘要: 随着大型语言模型（LLM）的流行，虚假信息生产和学术不端等社会问题日益严重，使得LLM生成文本检测变得前所未有的重要。尽管现有方法已取得显著进展，但私有调优LLM生成的文本检测仍是一个未充分探索的新挑战。用户可以通过使用私有语料微调开源LLM轻松获得私有模型，导致现有检测器在实际应用中性能大幅下降。为解决这一问题，我们提出了PhantomHunter，一种专门用于检测未见私有调优LLM生成文本的检测器。其家族感知学习框架能够捕捉基础模型及其衍生模型之间的家族级共享特征，而非记忆单个特性。在LLaMA、Gemma和Mistral家族数据上的实验表明，PhantomHunter优于7种基线方法和3种工业服务，F1分数超过96%。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2506.14791)
**中文标题：SemIRNet：一种用于多模态反讽检测的语义反讽识别网络**

*Jingxuan Zhou,Yuehao Wu,Yibo Zhang,Yeyubei Zhang,Yunchong Liu,Bolin Huang,Chunhong Yuan*

主要分类: cs.CV

摘要简述: 本文提出了一种语义反讽识别网络（SemIRNet），通过引入ConceptNet知识库、设计跨模态语义相似性检测模块以及对比学习损失函数，显著提升了多模态反讽检测的准确性和F1值。


<details>
  <summary>详细信息</summary>
研究动机: 针对多模态反讽检测任务中图形隐含关联难以准确识别的问题，本文旨在通过增强模型的常识推理能力和多粒度建模能力，提升检测性能。

研究方法: 1. 首次引入ConceptNet知识库获取概念知识；2. 设计词级和样本级跨模态语义相似性检测模块；3. 采用对比学习损失函数优化样本特征空间分布。

研究结果: 在公开数据集上，模型准确率和F1值分别提升1.64%和2.88%，达到88.87%和86.33%，消融实验验证了知识融合和语义相似性检测的重要性。

研究结论: SemIRNet通过知识融合和多粒度建模有效提升了多模态反讽检测性能，为相关任务提供了新思路。

中文摘要: 针对多模态反讽检测任务中图形隐含关联难以准确识别的问题，本文提出了一种语义反讽识别网络（SemIRNet）。该模型包含三项主要创新：（1）首次引入ConceptNet知识库获取概念知识，增强模型的常识推理能力；（2）设计词级和样本级两种跨模态语义相似性检测模块，实现不同粒度的图文关联建模；（3）引入对比学习损失函数优化样本特征空间分布，提升正负样本的可分性。在公开的多模态反讽检测基准数据集上的实验表明，该模型的准确率和F1值分别比现有最优方法提升了1.64%和2.88%，达到88.87%和86.33%。进一步的消融实验验证了知识融合和语义相似性检测对提升模型性能的重要作用。

</details>


### [53] [Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?](https://arxiv.org/abs/2506.14805)
**中文标题：Argus检验：多模态大语言模型是否拥有Panoptes之眼？**

*Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang*

主要分类: cs.CV

摘要简述: 本文介绍了Argus Inspection，一个多模态基准测试，用于评估多模态大语言模型（MLLMs）在细粒度视觉感知和常识因果推理方面的能力，并提出Eye of Panoptes框架以更全面地评估模型表现。实验显示当前模型的最高得分仅为0.46，表明仍有较大改进空间。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）的发展，其认知和推理能力显著提升，但在细粒度视觉感知和常识因果推理方面仍存在挑战。本文旨在通过Argus Inspection基准测试和Eye of Panoptes框架，全面评估MLLMs在这些方面的表现，并为未来改进提供参考。

研究方法: 本文提出Argus Inspection，一个包含两个难度级别的多模态基准测试，强调细粒度视觉识别和常识因果推理。进一步提出Eye of Panoptes框架，结合二元参数Sigmoid指标和指示函数，以更全面地评估MLLMs在基于观点的推理任务中的表现。

研究结果: 在26个主流MLLMs上的实验表明，模型在细粒度视觉推理中的最高得分仅为0.46，显示出当前模型在这些任务中的表现仍有较大提升空间。

研究结论: 本文通过Argus Inspection和Eye of Panoptes框架，揭示了MLLMs在细粒度视觉感知和常识因果推理方面的不足，为未来模型的改进提供了重要视角。

中文摘要: 随着多模态大语言模型（MLLMs）的不断发展，其认知和推理能力取得了显著进展。然而，在细粒度视觉感知和常识因果推理方面仍存在挑战。本文提出Argus Inspection，一个包含两个难度级别的多模态基准测试，强调细粒度视觉识别的同时结合现实世界的常识理解，以评估因果推理能力。在此基础上，我们提出了Eye of Panoptes框架，该框架将二元参数Sigmoid指标与指示函数相结合，能够更全面地评估MLLMs在基于观点的推理任务中的表现。在26个主流MLLMs上进行的实验显示，细粒度视觉推理的最高得分仅为0.46，表明仍有较大的改进潜力。我们的研究为MLLMs的持续改进提供了宝贵的视角。

</details>


### [54] [A Hybrid ConvNeXt-EfficientNet AI Solution for Precise Falcon Disease Detection](https://arxiv.org/abs/2506.14816)
**中文标题：一种基于ConvNeXt-EfficientNet混合AI模型的精准猎鹰疾病检测方法**

*Alavikunhu Panthakkan,Zubair Medammal,S M Anzar,Fatma Taher,Hussain Al-Ahmad*

主要分类: cs.CV

摘要简述: 本文提出了一种结合ConvNeXt和EfficientNet的混合AI模型，用于精准检测猎鹰疾病，显著优于传统方法和单一模型架构。


<details>
  <summary>详细信息</summary>
研究动机: 猎鹰训练与狩猎是一项传统活动，但猎鹰的健康监测至关重要。传统诊断方法效率低，亟需一种更精准的AI解决方案。

研究方法: 研究采用ConvNeXt和EfficientNet混合模型，对猎鹰的三种健康状况（正常、肝病和曲霉病）进行分类，并通过大量数据集训练和验证模型性能。

研究结果: 实验表明，混合模型在准确率、精确率、召回率和F1分数等关键指标上优于传统方法和单一模型，实现了更精准的疾病检测。

研究结论: 该混合AI模型为猎鹰疾病检测提供了高效解决方案，并为未来AI驱动的鸟类健康监测奠定了基础。

中文摘要: 猎鹰训练与狩猎是一项备受尊崇的传统活动，需要细致的健康监测以确保这些珍贵鸟类在狩猎场景中的健康与安全。本文提出了一种创新方法，结合ConvNeXt和EfficientNet AI模型对猎鹰疾病进行分类，重点关注三种状态：正常、肝病和曲霉病。研究利用大量数据集对模型进行训练和验证，并着重评估了准确率、精确率、召回率和F1分数等关键性能指标。广泛的测试与分析表明，我们的混合AI模型优于传统诊断方法和单一模型架构。该混合AI模型的成功应用标志着猎鹰疾病精准检测的重大进步，并为未来AI驱动的鸟类健康解决方案开辟了道路。

</details>


### [55] [ViLLa: A Neuro-Symbolic approach for Animal Monitoring](https://arxiv.org/abs/2506.14823)
**中文标题：ViLLa：一种神经符号方法用于动物监测**

*Harsha Koduri*

主要分类: cs.CV

摘要简述: ViLLa是一种结合视觉、语言和逻辑的神经符号框架，用于可解释的动物监测，通过视觉检测、语言解析和符号推理回答自然语言查询。


<details>
  <summary>详细信息</summary>
研究动机: 自然环境中监测动物种群需要能够同时处理视觉数据和自然语言查询的系统，现有端到端黑盒模型缺乏模块化和透明度。

研究方法: ViLLa整合了三个核心模块：视觉检测模块识别动物及其位置，语言解析模块理解自然语言查询，符号推理层通过逻辑推理回答问题。

研究结果: ViLLa在多种动物图像任务中表现优异，能够将视觉内容与结构化、可解释的查询相结合。

研究结论: ViLLa通过分离感知、理解和推理，提供了模块化和透明性，为动物监测任务提供了高效且可解释的解决方案。

中文摘要: 监测自然环境中的动物种群需要能够同时解释视觉数据和自然语言查询的系统。本文介绍了ViLLa（视觉-语言-逻辑方法），一种专为可解释动物监测设计的神经符号框架。ViLLa整合了三个核心组件：视觉检测模块用于识别图像中的动物及其空间位置，语言解析器用于理解自然语言查询，以及符号推理层通过基于逻辑的推理回答这些查询。给定一张图像和一个问题（例如“场景中有多少只狗？”或“水牛在哪里？”），系统将视觉检测结果转化为符号事实，并使用预定义规则计算与数量、存在和位置相关的准确答案。与端到端黑盒模型不同，ViLLa分离了感知、理解和推理，提供了模块化和透明度。该系统在多种动物图像任务中进行了评估，展示了将视觉内容与结构化、可解释查询相结合的能力。

</details>


### [56] [GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction](https://arxiv.org/abs/2506.14825)
**中文标题：GraphGSOcc：基于3D高斯溅射的语义与几何图Transformer占据预测**

*Ke Song,Yunhe Wu,Chunchit Siu,Huiyuan Xiong*

主要分类: cs.CV

摘要简述: 本文提出GraphGSOcc模型，结合语义与几何图Transformer，解决3D高斯溅射方法在语义关联和几何边界模糊的问题，显著提升自动驾驶场景的3D语义占据预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D高斯溅射方法存在两个关键问题：一是统一特征聚合忽略了类别间和区域间的语义关联；二是MLP迭代优化缺乏几何约束导致边界模糊。本文旨在解决这些问题。

研究方法: 提出GraphGSOcc模型，包含双高斯图注意力机制：几何图通过自适应KNN搜索半径聚合特征，语义图通过余弦相似性保留高相关节点。结合多尺度图注意力框架，优化边界细节和对象级拓扑。

研究结果: 在SurroundOcc数据集上，mIoU达到24.10%，GPU内存降至6.1 GB，相比GaussianWorld提升1.97% mIoU并减少13.7%内存。

研究结论: GraphGSOcc通过语义与几何图Transformer有效解决了3D高斯溅射的局限性，显著提升了语义占据预测的精度和效率。

中文摘要: 针对自动驾驶中的3D语义占据预测任务，本文解决了现有3D高斯溅射（3DGS）方法的两个关键问题：（1）统一特征聚合忽略了相似类别和跨区域的语义关联；（2）MLP迭代优化缺乏几何约束导致边界模糊。我们提出GraphGSOcc模型，一种结合语义与几何图Transformer的新框架。通过双高斯图注意力机制，动态构建几何图和语义图：几何图基于高斯位姿自适应计算KNN搜索半径，使大尺度高斯从更广邻域聚合特征，而紧凑高斯关注局部几何一致性；语义图通过余弦相似性保留前M高相关节点，显式编码实例内外的语义关系。结合多尺度图注意力框架，低层细粒度注意力优化边界细节，高层粗粒度注意力建模对象级拓扑。在SurroundOcc数据集上的实验实现了24.10%的mIoU，GPU内存降至6.1 GB，相比GaussianWorld提升1.97% mIoU并减少13.7%内存。

</details>


### [57] [DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning](https://arxiv.org/abs/2506.14827)
**中文标题：DAVID-XR1：基于可解释推理的AI生成视频检测**

*Yifeng Gao,Yifan Ding,Hongyu Su,Juncheng Li,Yunhan Zhao,Lin Luo,Zixing Chen,Li Wang,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang*

主要分类: cs.CV

摘要简述: 本文提出DAVID-XR1，一种可解释的AI生成视频检测方法，通过缺陷分类、时空定位和自然语言解释，将检测过程透明化。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成视频在媒体平台上的普及，可靠区分合成内容与真实视频的需求日益迫切。现有方法仅提供二分类结果，缺乏解释性，无法满足审计和用户需求。

研究方法: 作者构建了DAVID-X数据集，包含AI生成视频的缺陷级时空标注和文字解释。基于此，开发了DAVID-XR1模型，通过视觉推理链（缺陷分类、时空定位和自然语言解释）实现透明检测。

研究结果: 实验表明，通用骨干网络在DAVID-X数据集上微调后，结合思维链蒸馏，能够泛化到多种生成器和生成模式，检测效果显著。

研究结论: DAVID-XR1将AI生成视频检测从黑盒决策转变为透明诊断，为可信检测提供了新思路。

中文摘要: 随着AI生成视频在媒体平台上的日益普及，可靠区分合成内容与真实视频的能力变得既紧迫又必要。现有方法主要将此问题视为二分类任务，对模型为何判定视频为AI生成的解释有限。然而，核心挑战不仅在于检测细微伪影，还需提供细粒度、有说服力的证据以说服审计者和终端用户。为解决这一关键问题，我们提出了DAVID-X，首个将AI生成视频与详细的缺陷级时空标注及文字解释配对的数据集。利用这些丰富标注，我们开发了DAVID-XR1，一种视频-语言模型，旨在提供可解释的视觉推理链，包括缺陷分类、时空定位和自然语言解释。这一方法从根本上将AI生成视频检测从黑盒决策转变为透明且可验证的诊断过程。实验表明，通用骨干网络在我们的紧凑数据集上微调并结合思维链蒸馏后，能够泛化到多种生成器和生成模式。结果凸显了可解释检测方法在可信识别AI生成视频内容方面的潜力。

</details>


### [58] [Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review](https://arxiv.org/abs/2506.14831)
**中文标题：多智能体人类轨迹预测的最新进展：全面综述**

*Céline Finet,Stephane Da Silva Martins,Jean-Bernard Hayet,Ioannis Karamouzas,Javad Amirian,Sylvie Le Hégarat-Mascle,Julien Pettré,Emanuel Aldea*

主要分类: cs.CV

摘要简述: 本文综述了2020至2024年间基于深度学习的多智能体人类轨迹预测的最新进展，重点分析了模型架构、输入表示和预测策略，并探讨了该领域的关键挑战与未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据驱动方法在人类轨迹预测中的广泛应用，深入理解多智能体交互成为可能，这对自主导航和人群建模等领域具有重要意义。本文旨在总结该领域的最新研究进展。

研究方法: 本文通过系统梳理2020至2024年间发表的文献，将现有方法按架构设计、输入表示和预测策略进行分类，并以ETH/UCY基准测试为评估标准。

研究结果: 研究总结了多智能体轨迹预测的多种方法，并指出其在模型性能和泛化能力方面的局限性，同时提出了未来研究的潜在方向。

研究结论: 多智能体人类轨迹预测领域仍面临诸多挑战，但通过进一步优化模型架构和交互表示，有望实现更精准的预测。

中文摘要: 随着数据驱动方法在人类轨迹预测（HTP）中的兴起，深入理解多智能体交互成为可能，这对自主导航和人群建模等领域具有重要意义。本文综述了2020至2024年间基于深度学习的多智能体轨迹预测的最新进展，重点分析了模型架构、输入表示和预测策略，并以ETH/UCY基准测试为评估标准。此外，本文还探讨了多智能体HTP领域的关键挑战与未来研究方向。

</details>


### [59] [ArchShapeNet:An Interpretable 3D-CNN Framework for Evaluating Architectural Shapes](https://arxiv.org/abs/2506.14832)
**中文标题：ArchShapeNet：一种用于评估建筑形状的可解释3D-CNN框架**

*Jun Yin,Jing Zhong,Pengyu Zeng,Peilin Li,Zixuan Dai,Miao Zhang,Shuai Lu*

主要分类: cs.CV

摘要简述: 本文提出ArchShapeNet，一种用于评估建筑形状的可解释3D-CNN框架，通过构建ArchForms-4000数据集和引入显著性模块，模型在区分人工设计与机器生成形状上表现优异，准确率达94.29%。


<details>
  <summary>详细信息</summary>
研究动机: 当代建筑设计中，生成式工具快速生成初始概念和探索新3D形式的需求日益增长，但客观分析人工设计与机器生成3D形式的差异仍具挑战性，阻碍了对各自优势的理解和生成工具的进步。

研究方法: 构建ArchForms-4000数据集（含2000个人工设计和2000个Evomass生成的3D形式），提出ArchShapeNet（一种专为分类和分析建筑形状设计的3D-CNN，结合显著性模块突出与建筑推理相关的关键空间特征），并进行比较实验。

研究结果: 模型在区分形式来源上表现优于人类专家，准确率达94.29%，精确率96.2%，召回率98.51%。研究还揭示了人工设计形式在空间组织、比例和谐和细节优化上的独特优势。

研究结论: 本研究不仅展示了人工设计形式的优势，还为未来生成设计工具的改进提供了宝贵见解。

中文摘要: 在当代建筑设计中，设计需求的复杂性和多样性使得生成式插件工具成为快速生成初始概念和探索新3D形式的关键。然而，客观分析人工设计与机器生成3D形式之间的差异仍具挑战性，限制了对各自优势的理解并阻碍了生成工具的进步。为解决这一问题，我们构建了ArchForms-4000数据集，包含2000个建筑师设计和2000个Evomass生成的3D形式；提出了ArchShapeNet，一种专为分类和分析建筑形状设计的3D卷积神经网络，结合显著性模块突出与建筑推理相关的关键空间特征；并通过比较实验表明，我们的模型在区分形式来源上优于人类专家，准确率达94.29%，精确率96.2%，召回率98.51%。本研究不仅揭示了人工设计形式在空间组织、比例和谐和细节优化上的独特优势，还为未来生成设计工具的改进提供了宝贵见解。

</details>


### [60] [Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices](https://arxiv.org/abs/2506.14833)
**中文标题：基于熵的自适应缓冲与MobileNetV2的边缘设备实时低延迟监控**

*Poojashree Chandrashekar Pankaj M Sajjanar*

主要分类: cs.CV

摘要简述: 本文提出了一种基于熵的自适应帧缓冲算法，结合MobileNetV2，在资源受限的边缘设备上实现了高性能、低延迟的视频监控系统，端到端推理延迟低于50毫秒，检测准确率超过92%。


<details>
  <summary>详细信息</summary>
研究动机: 针对资源受限环境下的视频监控需求，设计一种能够在低延迟条件下保持高准确率的系统，同时满足数据隐私和成本效益的要求。

研究方法: 提出了一种基于熵的自适应帧缓冲算法，结合轻量级模型MobileNetV2，优化了视频流的实时处理性能。

研究结果: 系统在Raspberry Pi等边缘设备上实现了低于50毫秒的端到端延迟，检测准确率超过92%，且对光照、背景和速度变化具有鲁棒性。

研究结论: 该架构具有可扩展性、低成本和高隐私合规性，适用于智能城市或嵌入式安全场景。

中文摘要: 本文描述了一种专为资源受限环境设计的高性能、低延迟视频监控系统。我们提出了一种基于熵的自适应帧缓冲算法，并将其与MobileNetV2结合，实现了高吞吐量和低延迟。该系统能够在Raspberry Pi、Amazon和NVIDIA Jetson Nano等资源受限设备（嵌入式平台）上处理实时视频流，端到端推理延迟低于50毫秒。我们的方法在专注于视频监控的标准数据集上保持了超过92%的检测准确率，并对不同的光照、背景和速度变化表现出鲁棒性。多项对比和消融实验验证了我们设计的有效性。最后，我们的架构具有可扩展性、低成本，并且比常见的监控系统更符合严格的数据隐私法规，因此该系统可以应用于智能城市或嵌入式安全架构中。

</details>


### [61] [MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation](https://arxiv.org/abs/2506.14835)
**中文标题：MonoVQD：基于变分查询去噪和自蒸馏的单目3D目标检测**

*Kiet Dang Vu,Trung Thai Tran,Duc Dung Nguyen*

主要分类: cs.CV

摘要简述: 本文提出MonoVQD框架，通过变分查询去噪和自蒸馏技术，显著提升单目3D目标检测性能，解决了DETR架构在该领域的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 单目3D目标检测中，DETR架构存在性能瓶颈，传统去噪方法效率不足。本文旨在通过创新技术提升检测精度和稳定性。

研究方法: 1. 提出掩码分离自注意力机制，增强匈牙利匹配稳定性；2. 引入变分查询去噪技术，解决梯度消失问题；3. 设计自蒸馏策略，优化查询质量。

研究结果: MonoVQD在KITTI单目基准测试中表现优异，其核心组件在多视图3D检测（nuScenes数据集）中也显著提升性能。

研究结论: MonoVQD通过创新技术解决了单目3D检测的关键问题，具有广泛适用性和强大泛化能力。

中文摘要: 从单张图像中精确定位3D物体是单目3D检测的核心挑战。尽管DETR类架构提供了强大范式，但其直接应用存在固有局限，无法达到最优性能。本文提出MonoVQD框架，通过三项主要贡献解决这些问题：1. 掩码分离自注意力机制，将去噪过程融入DETR架构，提升匈牙利匹配稳定性；2. 变分查询去噪技术，解决传统去噪方法的梯度消失问题，显著提升效率；3. 自蒸馏策略，利用解码器深层信息优化浅层查询质量，增强迭代优化效果。实验表明，MonoVQD在KITTI单目基准测试中表现卓越，其核心组件在多视图3D检测（nuScenes数据集）中也显著提升性能，展现了强大的泛化能力。

</details>


### [62] [Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction](https://arxiv.org/abs/2506.14837)
**中文标题：通过结构化指令改进图表到代码生成的迭代优化方法**

*Chengzhi Xu,Yuyang Wang,Lai Wei,Lichao Sun,Weiran Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于结构化指令的迭代优化方法ChartIR，用于提升多模态大语言模型在图表到代码生成任务中的性能。通过将任务分解为视觉理解和代码翻译两部分，并结合描述和差异指令，显著提高了生成代码的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型在图表到代码生成任务中表现不佳，直接提示难以实现精确的视觉理解和代码翻译。因此，需要一种更有效的方法来提升模型在此任务中的表现。

研究方法: 提出ChartIR方法，将任务分解为视觉理解和代码翻译两部分，设计描述和差异两种结构化指令，分别用于捕捉图表视觉元素和生成图表与参考图表的差异。通过初始代码生成和迭代优化两阶段逐步提升输出质量。

研究结果: 实验表明，ChartIR在开源模型Qwen2-VL和闭源模型GPT-4o上均优于其他方法，显著提升了图表到代码生成的性能。

研究结论: ChartIR通过结构化指令和迭代优化，有效解决了多模态大语言模型在图表到代码生成任务中的挑战，为相关领域提供了新的解决方案。

中文摘要: 近年来，多模态大语言模型（MLLMs）因其强大的视觉理解能力受到广泛关注。尽管在多种视觉任务中表现出色，但它们在图表到代码生成任务中的表现仍不理想。该任务要求模型生成可执行代码以复现给定图表，不仅需要精确的视觉理解，还需将视觉元素准确转换为结构化代码。直接提示模型完成这一复杂任务往往效果不佳。为解决这一问题，我们提出了基于结构化指令的迭代优化方法ChartIR。首先，我们将任务分为视觉理解和代码翻译两部分。为实现视觉理解，设计了描述和差异两种结构化指令：描述指令捕捉参考图表的视觉元素，差异指令则表征生成图表与参考图表之间的差异。这些指令将视觉特征转化为语言表示，从而促进后续的代码翻译过程。其次，我们将整个图表生成流程分解为初始代码生成和迭代优化两个阶段，逐步提升最终输出质量。实验结果表明，与其他方法相比，我们的方法在开源模型Qwen2-VL和闭源模型GPT-4o上均取得了更优的性能。

</details>


### [63] [PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers](https://arxiv.org/abs/2506.14842)
**中文标题：PictSure：预训练嵌入对上下文学习图像分类器的重要性**

*Lukas Schiesser,Cornelius Wolff,Sophie Haas,Simon Pukrop*

主要分类: cs.CV

摘要简述: PictSure是一个专注于图像嵌入模型预训练的上下文学习框架，通过系统分析视觉编码器类型、预训练目标和微调策略，显著提升了少样本图像分类的跨域性能。


<details>
  <summary>详细信息</summary>
研究动机: 在数据稀缺领域构建图像分类模型具有挑战性，而现有上下文学习方法忽视了图像嵌入模型的关键作用。PictSure旨在填补这一空白，通过优化嵌入模型的预训练提升少样本分类性能。

研究方法: PictSure系统研究了视觉编码器类型、预训练目标和微调策略对少样本图像分类的影响，将嵌入模型置于分析中心。

研究结果: 实验表明，嵌入模型的预训练方式显著影响训练成功率和跨域性能。PictSure在跨域任务中优于现有方法，同时在域内任务中保持竞争力。

研究结论: PictSure通过优化嵌入模型预训练，为少样本图像分类提供了一种高效的上下文学习框架，尤其在跨域任务中表现突出。

中文摘要: 在数据稀缺领域构建图像分类模型仍然具有挑战性，因为收集大规模标注数据不切实际。上下文学习（ICL）已成为少样本图像分类（FSIC）的一种有前景的范式，使模型无需基于梯度的适应即可跨域泛化。然而，先前的工作很大程度上忽视了基于ICL的FSIC流程中的一个关键组成部分：图像嵌入的作用。本文提出了PictSure，一个将嵌入模型（其架构、预训练和训练动态）置于分析中心的ICL框架。我们系统研究了不同视觉编码器类型、预训练目标和微调策略对下游FSIC性能的影响。实验表明，训练成功率和跨域性能高度依赖于嵌入模型的预训练方式。因此，PictSure在显著不同于训练分布的跨域基准测试中优于现有的基于ICL的FSIC模型，同时在域内任务中保持可比的结果。代码可在https://github.com/PictSure/pictsure-library找到。

</details>


### [64] [Finding Optimal Kernel Size and Dimension in Convolutional Neural Networks An Architecture Optimization Approach](https://arxiv.org/abs/2506.14846)
**中文标题：卷积神经网络中核大小与维度的优化：一种架构优化方法**

*Shreyas Rajeev,B Sathish Babu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为BKSEF的框架，用于在卷积神经网络（CNN）中优化逐层核大小选择，通过平衡信息增益、计算效率和准确性提升，显著提高模型性能并减少计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 卷积神经网络中核大小的选择对模型的感受野、特征提取、计算成本和准确性有重要影响，但通常被忽视。本文旨在通过数学和实证方法优化核大小，提升CNN的设计效率。

研究方法: 提出了最佳核大小估计函数（BKSEF），结合信息论、信号处理和学习理论，逐层确定最优核大小。实验在多个数据集上进行验证。

研究结果: 实验表明，BKSEF引导的架构在多个数据集上实现了最高3.1%的准确性提升和42.8%的FLOPs减少。两个实际案例进一步验证了其有效性。

研究结论: BKSEF证明核大小可以成为可优化的参数，而非固定启发式方法，为高效和应用感知的CNN设计提供了理论和实践支持。

中文摘要: 卷积神经网络（CNN）中核大小的选择是一个关键但常被忽视的设计决策，它影响感受野、特征提取、计算成本和模型准确性。本文提出了最佳核大小估计函数（BKSEF），这是一个基于数学和实证验证的框架，用于逐层确定最优核大小。BKSEF通过整合信息论、信号处理和学习理论的原理，平衡了信息增益、计算效率和准确性提升。在CIFAR-10、CIFAR-100、ImageNet-lite、ChestX-ray14和GTSRB数据集上的大量实验表明，BKSEF引导的架构相比传统使用统一3x3核的模型，实现了最高3.1%的准确性提升和42.8%的FLOPs减少。两个实际案例进一步验证了该方法：一个用于基于云的医学图像分类，另一个用于边缘设备上的交通标志识别。前者提高了可解释性和准确性，后者显著降低了延迟和模型大小，且准确性损失极小。这些结果表明，核大小可以成为主动可优化的参数，而非固定启发式方法。BKSEF为寻求高效和应用感知CNN设计的研究人员和开发者提供了实用启发和理论支持。它适合集成到神经架构搜索流程和实时系统中，为CNN优化提供了新视角。

</details>


### [65] [Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis](https://arxiv.org/abs/2506.14854)
**中文标题：高效零售视频标注：一种鲁棒的关键帧生成方法用于产品与顾客交互分析**

*Varun Mannam,Zhenyu Shi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的零售视频关键帧生成方法，用于自动化产品与顾客交互分析的标注，显著降低了人工标注成本并提高了效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统零售视频标注依赖耗时的人工标注，存在帧选择不鲁棒和成本高的问题，亟需自动化解决方案。

研究方法: 采用深度神经网络学习视频帧的判别特征，并结合针对零售环境的对象检测技术，实现关键帧自动识别与标注。

研究结果: 实验表明，该方法在标注准确性上与人工标注相当，同时节省了约2倍成本，且仅需人工验证少于5%的帧。

研究结论: 该方法显著提升了零售视频标注的效率，适用于顾客行为分析、产品交互检测等多种零售应用。

中文摘要: 准确的视频标注在现代零售应用中至关重要，包括顾客行为分析、产品交互检测和店内活动识别。然而，传统标注方法严重依赖耗时的人工标注，导致帧选择不鲁棒且运营成本增加。为解决零售领域的这些挑战，我们提出了一种基于深度学习的方法，可自动化零售视频中的关键帧识别，并提供产品和顾客的自动标注。我们的方法利用深度神经网络学习判别特征，通过嵌入视频帧并结合针对零售环境的对象检测技术。实验结果表明，我们的方法优于传统方法，在标注准确性上与人工标注相当，同时显著提高了零售视频标注的整体效率。值得注意的是，我们的方法平均节省了2倍的标注成本。通过仅需人工验证/调整少于5%的检测帧，同时自动化标注其余帧而不降低标注质量，零售商可大幅降低运营成本。关键帧检测的自动化显著节省了零售视频标注任务的时间和精力，对顾客旅程分析、产品交互检测和店内安全监控等多种零售应用极具价值。

</details>


### [66] [Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction](https://arxiv.org/abs/2506.14856)
**中文标题：窥探未知：基于神经不确定性地图的主动视角选择用于3D重建**

*Zhengquan Zhang,Feng Xu,Mengmi Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于神经不确定性地图的主动视角选择方法（AVS），用于高效且准确的3D重建。通过轻量级网络UPNet预测不确定性地图，显著减少了计算开销，并在减少一半视角的情况下仍保持高重建精度。


<details>
  <summary>详细信息</summary>
研究动机: 在3D重建中，不同视角提供的信息量差异显著。如何选择最具信息量的视角以高效完成重建是计算机视觉领域的核心挑战。传统方法依赖复杂计算，而本文旨在通过神经不确定性地图直接预测最优视角，提升效率与准确性。

研究方法: 提出轻量级网络UPNet，通过单张输入图像预测所有候选视角的不确定性地图。结合启发式方法，UPNet学习从视角外观到体积表示不确定性的直接映射。通过聚合不确定性地图，抑制冗余视角并选择最具信息量的视角，用于训练3D神经渲染模型。

研究结果: 实验表明，尽管仅使用一半视角，该方法的重建精度与基线方法相当。同时，计算开销显著降低，速度提升400倍，CPU、RAM和GPU使用减少50%以上。此外，该方法无需额外训练即可泛化至新物体类别。

研究结论: 基于神经不确定性地图的AVS方法在高效性和准确性上表现优异，为3D重建提供了一种轻量级且通用的解决方案。

中文摘要: 某些视角自然比其他视角提供更多信息。AI系统如何确定哪个视角能为准确高效的3D物体重建提供最有价值的洞察？主动视角选择（AVS）在3D重建中仍是计算机视觉的基础挑战。目标是找到能产生最准确3D重建的最小视角集合。不同于从当前观察学习辐射场（如NeRF或3D高斯泼溅）并为每个候选视角计算不确定性，我们提出了一种由轻量级前馈深度神经网络UPNet预测的神经不确定性地图引导的新型AVS方法。UPNet输入一张3D物体的图像，输出预测的不确定性地图，表示所有候选视角的不确定性值。通过观察大量自然物体及其不确定性模式的启发，训练UPNet学习从视角外观到体积表示不确定性的直接映射。接着，我们的方法聚合所有先前预测的神经不确定性地图，抑制冗余候选视角并有效选择最具信息量的视角。利用这些选定视角，我们训练3D神经渲染模型，并在新视角合成质量上与其他竞争性AVS方法对比评估。值得注意的是，尽管仅使用上限一半的视角，我们的方法仍实现了相当的重建精度。此外，它显著降低了AVS过程中的计算开销，与基线方法相比，速度提升高达400倍，CPU、RAM和GPU使用减少50%以上。尤为突出的是，我们的方法无需额外训练即可有效泛化至涉及新物体类别的AVS任务。

</details>


### [67] [DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization](https://arxiv.org/abs/2506.14903)
**中文标题：DETONATE：文本到图像对齐与核化直接偏好优化的基准测试**

*Renjith Prasad,Abhilekh Borah,Hasnat Md Abdullah,Chathurangi Shyalika,Gurpreet Singh,Ritvik Garimella,Rajarshi Roy,Harshul Surana,Nasrin Imanpour,Suranjana Trivedy,Amit Sheth,Amitava Das*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DPO-Kernels的新方法，用于增强文本到图像（T2I）模型的对齐能力，并引入了首个大规模基准测试DETONATE，用于评估社会偏见和歧视问题。通过混合损失、核化表示和散度选择，该方法显著提升了模型的稳定性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 文本到图像模型的对齐问题至关重要，以确保生成的图像准确反映用户意图并保持安全性和公平性。然而，现有方法在特征变换和输入分离方面存在不足，亟需一种更强大的优化框架。

研究方法: 本文提出了DPO-Kernels方法，包括：（i）混合损失，结合嵌入目标和传统概率损失；（ii）核化表示，使用RBF、多项式和Wavelet核进行特征变换；（iii）散度选择，扩展了KL散度，引入Wasserstein和R'enyi散度以增强稳定性。

研究结果: 实验表明，DPO-Kernels通过Heavy-Tailed Self-Regularization（HT-SR）保持了强大的泛化能力。DETONATE基准测试揭示了模型在社会偏见（种族、性别、残疾）方面的潜在漏洞，并提出了新的对齐质量指数（AQI）进行量化评估。

研究结论: DPO-Kernels显著提升了T2I模型的对齐能力，DETONATE基准测试为未来研究提供了重要工具。代码和数据已公开。

中文摘要: 对齐对于文本到图像（T2I）模型至关重要，以确保生成的图像忠实反映用户意图，同时保持安全性和公平性。直接偏好优化（DPO）在大型语言模型（LLM）中表现突出，现正扩展至T2I系统。本文提出了DPO-Kernels方法，通过以下三个方面增强对齐能力：（i）混合损失，将嵌入目标与传统概率损失结合以优化性能；（ii）核化表示，采用径向基函数（RBF）、多项式和Wavelet核实现更丰富的特征变换，并更好地区分安全与不安全输入；（iii）散度选择，超越DPO默认的Kullback-Leibler（KL）正则化，引入Wasserstein和R'enyi散度以提升稳定性和鲁棒性。我们推出了DETONATE，首个同类大规模基准测试，包含约10万对精选图像，分为选中和拒绝两类，涵盖种族、性别和残疾三个社会偏见维度。提示文本源自仇恨言论数据集，图像由领先的T2I模型（如Stable Diffusion 3.5 Large、Stable Diffusion XL和Midjourney）生成。此外，我们提出了对齐质量指数（AQI），一种新的几何度量，用于量化安全/不安全图像激活在潜在空间中的可分离性，揭示潜在漏洞。实验表明，DPO-Kernels通过Heavy-Tailed Self-Regularization（HT-SR）保持了强大的泛化能力。DETONATE及完整代码已公开发布。

</details>


### [68] [PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2506.14907)
**中文标题：PeRL：基于排列增强的强化学习用于交错视觉-语言推理**

*Yizhen Zhang,Yang Ding,Shuoshuo Zhang,Xinchen Zhang,Haoling Li,Zhong-zhi Li,Peijie Wang,Jie Wu,Lei Ji,Yelong Shen,Yujiu Yang,Yeyun Gong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PeRL的强化学习方法，通过图像序列排列和多阶段策略提升多模态推理任务的性能，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态强化学习方法主要局限于单图像空间推理，难以泛化到涉及多图像位置推理的复杂场景。本文旨在解决这一问题，提升模型在多图像任务中的表现。

研究方法: PeRL通过图像序列排列模拟多样位置关系，增强空间和位置多样性；设计回放过滤机制，专注于对学习最优行为贡献最大的轨迹，优化探索-利用平衡。

研究结果: 实验表明，PeRL在5个多图像基准和3个单图像基准上均显著优于现有方法，尤其是多图像任务中达到最优性能，同时保持单图像任务的竞争力。

研究结论: PeRL为多模态推理任务提供了一种高效强化学习框架，显著提升了多图像场景下的性能，同时保持了单图像任务的通用性。

中文摘要: 受DeepSeek-R1等强化学习方法展现的卓越推理能力启发，近期研究开始探索利用强化学习（RL）增强视觉-语言模型（VLMs）在多模态推理任务中的表现。然而，现有多模态强化学习方法多局限于单图像空间推理，难以泛化到涉及多图像位置推理的复杂实际场景，其中理解图像间关系至关重要。为解决这一问题，我们提出了一种通用的强化学习方法PeRL，专为交错多模态任务设计，并采用多阶段策略优化探索-利用平衡，从而提升学习效率和任务表现。具体而言，我们引入图像序列排列以模拟多样位置关系，增强空间和位置多样性；同时设计回放过滤机制，专注于对学习最优行为贡献最大的轨迹，有效利用已学策略。我们在5个广泛使用的多图像基准和3个单图像基准上评估模型。实验证实，PeRL训练模型在多图像基准上大幅超越R1相关及交错VLM基线，达到最优性能，同时在单图像任务上保持可比表现。

</details>


### [69] [Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models](https://arxiv.org/abs/2506.14919)
**中文标题：医学图像扩散模型的频率校准成员推断攻击**

*Xinkai Zhao,Yuta Tokuoka,Junichiro Iwasawa,Keita Oda*

主要分类: cs.CV

摘要简述: 本文提出了一种针对医学图像扩散模型的频率校准重建误差（FCRE）方法，用于成员推断攻击（MIA），通过聚焦中频范围的重建误差，有效量化隐私风险并优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在医学图像生成中的广泛应用引发了隐私担忧。现有MIA方法依赖重建误差，但医学图像的高频细节重建困难导致效果不佳，需改进方法以准确评估隐私风险。

研究方法: 提出频率校准重建误差（FCRE）方法，分析反向扩散过程，计算中频范围的重建误差和结构相似性指数，通过阈值比较确定成员身份，排除高频和低频区域的干扰。

研究结果: 在多个医学图像数据集上的实验表明，FCRE方法在成员推断攻击中表现优于现有方法，有效解决了图像固有难度对重建误差的影响。

研究结论: FCRE方法通过频率选择性分析，显著提升了医学图像扩散模型的隐私风险评估能力，为敏感领域的数据保护提供了新思路。

中文摘要: 扩散模型在图像生成中的广泛应用，尤其是在医学成像等敏感领域，引发了显著的隐私问题。成员推断攻击（MIA）作为一种潜在方法，可用于判断特定图像是否用于训练扩散模型，从而量化隐私风险。现有MIA方法通常依赖扩散重建误差，假设成员图像的重建误差低于非成员图像。然而，这些方法直接应用于医学图像时面临挑战：重建误差受图像固有难度影响，且扩散模型在高频细节重建上表现不佳。为解决这些问题，我们提出了一种频率校准重建误差（FCRE）方法，用于医学图像扩散模型的MIA。通过专注于特定中频范围的重建误差，并排除高频（难以重建）和低频（信息较少）区域，我们的频率选择性方法缓解了图像固有难度的干扰。具体而言，我们分析反向扩散过程，获取中频重建误差，并计算重建图像与原始图像的结构相似性指数得分。通过将该得分与阈值比较确定成员身份。在多个医学图像数据集上的实验表明，我们的FCRE方法优于现有MIA方法。

</details>


### [70] [Vision Transformers for End-to-End Quark-Gluon Jet Classification from Calorimeter Images](https://arxiv.org/abs/2506.14934)
**中文标题：基于Vision Transformer的端到端量热器图像夸克-胶子喷注分类**

*Md Abrar Jahin,Shahriar Soudeep,Arian Rahman Aditta,M. F. Mridha,Nafiz Fahad,Md. Jakir Hossen*

主要分类: cs.CV

摘要简述: 本文通过系统评估Vision Transformer (ViT)及其与CNN的混合模型，在基于量热器图像的夸克-胶子喷注分类任务中表现优于传统CNN，突出了ViT在捕获长程空间相关性方面的优势。


<details>
  <summary>详细信息</summary>
研究动机: 在高能物理中，区分夸克和胶子引发的喷注对提升新物理搜索和精确测量至关重要。尽管CNN在喷注标记中表现优异，但ViT架构在直接分析量热器图像方面的潜力尚未充分探索。

研究方法: 利用2012年CMS开放数据构建多通道喷注图像（包括ECAL、HCAL能量沉积和重建轨迹），采用ViT和ViT-CNN混合模型进行端到端学习。

研究结果: ViT模型（尤其是ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上均优于传统CNN基线，验证了ViT在喷注子结构长程相关性建模中的优势。

研究结论: 本研究首次系统性地将ViT架构应用于量热器图像喷注分类，并建立了性能基准，为未来深度学习研究提供了结构化数据集和框架。

中文摘要: 区分夸克和胶子引发的喷注是高能物理中一项关键且具有挑战性的任务，对提升大型强子对撞机的新物理搜索和精确测量至关重要。尽管深度学习（尤其是卷积神经网络CNN）在基于图像的喷注标记中取得了进展，但Vision Transformer (ViT)架构在直接分析量热器图像方面的潜力尚未充分探索，尤其是在实际探测器和堆积条件下。本文利用2012年CMS开放数据，系统评估了ViT及ViT-CNN混合模型在夸克-胶子喷注分类中的表现。我们通过探测器级能量沉积（ECAL、HCAL）和重建轨迹构建多通道喷注图像，实现了端到端学习。全面的基准测试表明，基于ViT的模型（尤其是ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上均优于传统CNN基线，凸显了其在喷注子结构长程空间相关性建模中的优势。本研究首次为ViT架构在量热器图像喷注分类中的应用提供了系统性框架和性能基准，同时提供了适用于该领域进一步深度学习研究的结构化数据集。

</details>


### [71] [Advances in Compliance Detection: Novel Models Using Vision-Based Tactile Sensors](https://arxiv.org/abs/2506.14980)
**中文标题：顺应性检测的进展：基于视觉触觉传感器的新型模型**

*Ziteng Li,Malte Kuhlmann,Ilana Nisky,Nicolás Navarro-Guerrero*

主要分类: cs.CV

摘要简述: 本文提出两种基于长时递归卷积网络（LRCN）和Transformer架构的模型，利用视觉触觉传感器GelSight的RGB触觉图像和其他信息，显著提高了物体顺应性检测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 顺应性是描述工程、农业和生物医学应用中物体特性的关键参数。传统检测方法缺乏便携性和可扩展性，依赖昂贵设备，且不适用于机器人应用。现有基于神经网络的视觉触觉传感器方法预测精度不足。

研究方法: 提出两种模型：基于长时递归卷积网络（LRCN）和Transformer架构，利用GelSight传感器捕获的RGB触觉图像和其他信息预测顺应性指标。通过多指标验证模型性能。

研究结果: 模型在顺应性估计上表现显著优于基线方法。研究发现，比传感器更硬的物体更难准确估计其顺应性。

研究结论: 所提模型显著提升了顺应性检测的准确性，为机器人应用提供了更可靠的解决方案。同时揭示了传感器与物体顺应性估计之间的相关性。

中文摘要: 顺应性是描述工程、农业和生物医学应用中物体特性的关键参数。传统顺应性检测方法因缺乏便携性和可扩展性，依赖昂贵设备，且不适用于机器人应用而受限。此外，现有基于神经网络的视觉触觉传感器方法预测精度仍不足。本文提出两种基于长时递归卷积网络（LRCN）和Transformer架构的模型，利用视觉触觉传感器GelSight的RGB触觉图像和其他信息准确预测顺应性指标。通过多指标验证模型性能，证明其能有效估计顺应性。所提模型性能显著优于基线。此外，研究了传感器顺应性与物体顺应性估计之间的相关性，发现比传感器更硬的物体更难准确估计。

</details>


### [72] [Hyper-Local Deformable Transformers for Text Spotting on Historical Maps](https://arxiv.org/abs/2506.15010)
**中文标题：超局部可变形Transformer用于历史地图文本检测**

*Yijun Lin,Yao-Yi Chiang*

主要分类: cs.CV

摘要简述: 本文提出PALETTE，一种用于历史地图文本检测和识别的端到端方法，通过超局部采样模块和合成数据训练，显著提升了长文本和倾斜文本的处理能力。


<details>
  <summary>详细信息</summary>
研究动机: 历史地图中的文本包含丰富的地理、历史和文化信息，但现有方法因缺乏有效技术和训练数据而难以处理多样化的地图文本。

研究方法: PALETTE引入超局部采样模块学习文本边界点和字符的局部特征，并结合超局部位置编码捕捉文本实例内外的空间关系；同时提出SynthMap+自动生成合成地图数据用于训练。

研究结果: 实验表明，PALETTE在历史地图数据集上优于现有方法，尤其在长文本和倾斜文本上表现突出，并成功应用于6万张地图的文本标注。

研究结论: PALETTE结合SynthMap+为历史地图文本处理提供了高效解决方案，支持大规模地图搜索应用。

中文摘要: 历史地图中的文本提供了丰富的地理、历史和文化背景信息，但由于缺乏有效方法和训练数据，文本提取具有挑战性。现有方法通常针对特定地图风格设计，而基于机器学习的文本检测方法虽具灵活性，但在处理长文本和复杂背景时仍存在困难。本文提出PALETTE，一种端到端的历史地图文本检测方法，通过超局部采样模块学习文本边界点和字符的局部特征，并结合超局部位置编码捕捉空间关系。此外，本文提出SynthMap+自动生成合成地图数据用于训练。实验表明，PALETTE在历史地图数据集上优于现有方法，并成功应用于6万张地图的文本标注。项目已开源。

</details>


### [73] [Break Stylistic Sophon: Are We Really Meant to Confine the Imagination in Style Transfer?](https://arxiv.org/abs/2506.15033)
**中文标题：打破风格桎梏：我们真的需要限制风格迁移中的想象力吗？**

*Gary Song Yan,Yusen Zhang,Jinyu Zhao,Hao Zhang,Zhangping Yang,Guanye Xiong,Yanfei Liu,Tao Zhang,Yujie He,Siyuan Tian,Yao Gou,Min Li*

主要分类: cs.CV

摘要简述: 本文提出StyleWallfacer框架，通过语义驱动的风格注入、基于人类反馈的数据增强和无训练的三重扩散过程，实现了高质量的风格迁移和文本驱动风格化，同时首次在风格迁移中实现图像颜色编辑。


<details>
  <summary>详细信息</summary>
研究动机: 传统风格迁移方法存在多种问题，如风格注入效率低、内容漂移和过拟合等。本文旨在通过统一框架解决这些问题，并实现艺术家级别的风格迁移和文本驱动风格化。

研究方法: 1. 提出基于语义的风格注入方法，利用BLIP生成与风格图像语义严格对齐的文本描述，并通过大语言模型移除风格相关描述，形成语义间隙以微调模型。2. 设计基于人类反馈的数据增强策略，将高质量样本加入训练集以减少过拟合。3. 提出无训练的三重扩散过程，通过替换自注意力层的键和值实现风格注入，同时保留文本控制。

研究结果: 实现了高质量图像驱动风格迁移和文本驱动风格化，生成艺术家级别的风格迁移结果，并首次在风格迁移中完成图像颜色编辑。

研究结论: StyleWallfacer框架通过创新的语义注入和数据增强策略，显著提升了风格迁移的质量和灵活性，为风格迁移领域提供了新的研究方向。

中文摘要: 在这项开创性研究中，我们提出了StyleWallfacer，这是一种革命性的统一训练和推理框架，不仅解决了传统风格迁移方法中的各种问题，还统一了不同任务的框架。该框架旨在通过实现艺术家级别的风格迁移和文本驱动风格化来革新该领域。首先，我们提出了一种基于语义的风格注入方法，利用BLIP生成与风格图像语义严格对齐的文本描述。通过使用大语言模型从这些描述中移除风格相关描述，我们创建了一个语义间隙。这一间隙用于微调模型，实现高效且无漂移的风格知识注入。其次，我们提出了一种基于人类反馈的数据增强策略，将微调早期生成的高质量样本纳入训练集，以促进渐进式学习并显著减少过拟合。最后，我们设计了一种使用微调模型的无训练三重扩散过程，以类似于交叉注意力机制的方式操作自注意力层的特征。具体而言，在生成过程中，内容相关过程的键和值被替换为风格相关过程的键和值，以实现风格注入，同时保持对模型的文本控制。我们还引入了查询保留机制以减少对原始内容的干扰。通过这种设计，我们实现了高质量的图像驱动风格迁移和文本驱动风格化，生成了艺术家级别的风格迁移结果，同时保留了原始图像内容。此外，我们首次在风格迁移过程中实现了图像颜色编辑。

</details>


### [74] [Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study](https://arxiv.org/abs/2506.15078)
**中文标题：基于分布匹配的向量量化增强：理论与实证研究**

*Xianghong Fang,Litao Guo,Hengchao Chen,Yuxuan Zhang,XiaofanXia,Dingjie Song,Yexin Liu,Hao Wang,Harry Yang,Yuan Yuan,Qiang Sun*

主要分类: cs.CV

摘要简述: 本文提出了一种基于分布匹配的向量量化方法，通过Wasserstein距离对齐特征和码向量的分布，解决了现有方法中的训练不稳定和码本崩溃问题，显著提升了码本利用率和量化效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有向量量化方法存在训练不稳定和码本崩溃问题，主要源于特征与码向量分布不匹配，导致码向量不具代表性且压缩过程中信息损失严重。本文旨在通过分布对齐解决这些问题。

研究方法: 采用Wasserstein距离对齐特征和码向量的分布，以减少量化误差并提升码本利用率。通过理论和实证分析验证方法的有效性。

研究结果: 实验表明，该方法实现了接近100%的码本利用率，显著降低了量化误差，理论和实证结果均验证了其优越性。

研究结论: 通过分布匹配优化向量量化，本文方法有效解决了训练不稳定和码本崩溃问题，为自回归模型提供了更高效的量化技术。

中文摘要: 自回归模型的成功很大程度上依赖于向量量化的有效性，该技术通过将连续特征映射到可学习码本中的最近码向量来实现离散化。现有向量量化方法存在两个关键问题：训练不稳定和码本崩溃。训练不稳定源于直通估计器引入的梯度差异，尤其在量化误差较大时更为明显；码本崩溃则表现为训练过程中仅使用少量码向量。深入分析表明，这些问题主要由特征与码向量分布不匹配引起，导致码向量缺乏代表性且压缩过程中信息损失严重。为解决这一问题，我们采用Wasserstein距离对齐这两种分布，实现了接近100%的码本利用率，并显著降低了量化误差。理论和实证分析均验证了该方法的有效性。

</details>


### [75] [SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts](https://arxiv.org/abs/2506.15153)
**中文标题：SynPo：通过高质量负提示提升无训练少样本医学分割**

*Yufei Liu,Haoke Xiao,Jiaxing Chai,Yongcun Zhang,Rong Wang,Zijie Meng,Zhiming Luo*

主要分类: cs.CV

摘要简述: SynPo提出了一种无需训练的少样本医学图像分割方法，通过高质量负提示提升性能，结合DINOv2和SAM的优势生成置信图，并利用K-means聚类选择提示点，实验表明其性能媲美基于训练的方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于大型视觉模型（LVMs）的无训练方法在低对比度医学图像上表现不佳，主要原因是未能有效利用负提示。SynPo旨在通过提升负提示质量解决这一问题。

研究方法: SynPo设计了置信图协同模块，结合DINOv2和SAM生成可靠置信图，从中选择正负提示点集，并通过独立K-means聚类优化提示点质量，最终用于SAM分割。

研究结果: 实验表明，SynPo在少样本医学图像分割任务中表现优异，性能接近基于训练的最先进方法。

研究结论: SynPo通过高质量负提示和置信图协同模块，显著提升了无训练少样本医学分割的性能，为相关领域提供了新思路。

中文摘要: 大型视觉模型（LVMs）的出现为少样本医学图像分割带来了新机遇。然而，现有基于LVMs的无训练方法未能有效利用负提示，导致在低对比度医学图像上表现不佳。为解决这一问题，我们提出了SynPo，一种基于LVMs（如SAM）的无训练少样本方法，其核心思想是提升负提示的质量。为了在更可靠的置信图中选择点提示，我们设计了一个新颖的置信图协同模块，结合了DINOv2和SAM的优势。基于该置信图，我们选择前k像素作为正点集，并通过高斯分布选择负点集，随后对两者进行独立的K-means聚类。这些选定的点作为高质量提示输入SAM以获取分割结果。大量实验表明，SynPo的性能与基于训练的最先进少样本方法相当。

</details>


### [76] [Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation](https://arxiv.org/abs/2506.15160)
**中文标题：基于跨阶段结构相关性的邻居聚合校正增强点云分析**

*Jiaqi Shi,Jin Xiao,Xiaoguang Hu,Boyang Song,Hao Jiang,Tianyou Chen,Baochang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于跨阶段结构相关性的点云分析方法（PDSA），通过高维空间相关性校正特征分布，提升计算效率和鲁棒性，并在语义分割和分类任务中验证了其性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于局部坐标的点云分析方法存在无关点干扰和特征层次差距问题，而直接几何结构编码方法则计算开销大且对噪声敏感。本文旨在通过高维空间相关性解决这些问题。

研究方法: 提出Point Distribution Set Abstraction模块（PDSA），利用跨阶段结构描述符区分点相关性，通过减少邻居特征矩阵方差和长距离建模增强结构同质性，并引入关键点机制优化计算开销。

研究结果: 在不同基线的语义分割和分类任务中验证了方法的泛化性，性能显著提升且参数成本更低。消融实验和可视化结果证明了方法的有效性和合理性。

研究结论: PDSA模块通过高维空间相关性校正特征分布，解决了现有方法的局限性，提升了点云分析的效率和鲁棒性。

中文摘要: 点云分析是许多下游任务的基石，其中聚合局部结构是理解点云数据的基础。尽管许多工作利用三维相对坐标聚合邻居点，但由于局部坐标的限制，存在无关点干扰和特征层次差距问题。尽管一些工作通过显式建模跨阶段结构来细化空间描述，但这些基于直接几何结构编码的增强方法存在计算开销高和噪声敏感的问题。为解决这些问题，我们提出了点分布集抽象模块（PDSA），利用高维空间的相关性在校正聚合过程中的特征分布，从而提升计算效率和鲁棒性。PDSA基于轻量级跨阶段结构描述符区分点相关性，并通过减少邻居特征矩阵的方差和长距离建模增强结构同质性。此外，我们引入关键点机制以优化计算开销。基于不同基线的语义分割和分类任务的实验结果验证了所提方法的泛化性，并以更少的参数成本实现了显著的性能提升。相应的消融和可视化结果证明了方法的有效性和合理性。代码和训练权重可在https://github.com/AGENT9717/PointDistribution获取。

</details>


### [77] [Echo-DND: A dual noise diffusion model for robust and precise left ventricle segmentation in echocardiography](https://arxiv.org/abs/2506.15166)
**中文标题：Echo-DND：一种用于超声心动图中左心室鲁棒精确分割的双噪声扩散模型**

*Abdur Rahman,Keerthiveena Balraj,Manojkumar Ramteke,Anurag Singh Rathore*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Echo-DND的双噪声扩散模型，用于超声心动图中左心室的精确分割。该模型结合高斯和伯努利噪声，并引入多尺度融合条件模块和空间一致性校准，显著提升了分割精度。在CAMUS和EchoNet-Dynamic数据集上的实验表明，其性能优于现有方法，Dice分数分别达到0.962和0.939。


<details>
  <summary>详细信息</summary>
研究动机: 超声图像通常噪声大、对比度低且左心室边界模糊，这使得分割任务极具挑战性。现有方法难以应对这些问题，因此需要一种更鲁棒且精确的分割模型来支持临床诊断和治疗。

研究方法: Echo-DND采用双噪声扩散模型，结合高斯和伯努利噪声。通过多尺度融合条件模块提升分割精度，并利用空间一致性校准保持分割掩模的空间完整性。

研究结果: 在CAMUS和EchoNet-Dynamic数据集上的实验表明，Echo-DND的Dice分数分别达到0.962和0.939，显著优于现有方法。

研究结论: Echo-DND为超声心动图分割设立了新标准，其架构有望扩展到其他医学影像任务，提升诊断准确性。

中文摘要: 扩散概率模型（DPMs）的最新进展在图像处理领域引发了革命，显示出在医学应用中的巨大潜力。超声心动图中左心室（LV）的精确分割对诊断和治疗至关重要。然而，超声图像噪声大、对比度低且LV边界模糊，使得分割任务极具挑战性。为解决这些问题，本文提出了Echo-DND，一种专为此任务设计的双噪声扩散模型。Echo-DND结合了高斯和伯努利噪声，并引入了多尺度融合条件模块以提高分割精度。此外，它还利用空间一致性校准保持分割掩模的空间完整性。该模型在CAMUS和EchoNet-Dynamic数据集上进行了严格验证。大量实验表明，所提框架优于现有SOTA模型，Dice分数分别达到0.962和0.939。Echo-DND为超声心动图分割设立了新标准，其架构有望扩展到其他医学影像任务，提升诊断准确性。项目页面：https://abdur75648.github.io/Echo-DND

</details>


### [78] [ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections](https://arxiv.org/abs/2506.15180)
**中文标题：ReSeDis：基于指代的大规模图像集合对象搜索数据集**

*Ziling Huang,Yidan Zhang,Shin'ichi Satoh*

主要分类: cs.CV

摘要简述: ReSeDis是首个将大规模图像检索与像素级定位结合的任务，通过自由描述查询对象并返回其位置，提供了一个统一的测试平台。


<details>
  <summary>详细信息</summary>
研究动机: 现有技术仅解决视觉搜索中的部分问题：视觉定位能精确定位但假设对象存在于每张图像中，而文本到图像检索能筛选相关图像但无法细粒度定位。ReSeDis旨在统一这两项任务。

研究方法: 提出ReSeDis任务，结合检索与定位功能，设计了一个包含唯一描述映射的基准数据集，并开发了联合评分检索召回与定位精度的指标。

研究结果: 通过零基线实验展示了未来研究的潜力，ReSeDis为构建稳健的多模态搜索系统提供了测试平台。

研究结论: ReSeDis为下一代多模态搜索系统提供了端到端的测试平台，展示了统一检索与定位的可行性。

中文摘要: 大规模视觉搜索引擎需同时解决两个问题：(i)定位句子描述的对象所在的图像，(ii)在每张图像中确定对象的边界框或精确像素。现有技术仅解决其中一项。视觉定位能提供精确框和掩码，但假设对象存在于每张测试图像中，导致在网页规模集合中产生大量误报。文本到图像检索擅长筛选海量数据库中的相关图像，但仅停留在整图匹配，无法细粒度定位。我们提出指代搜索与发现（ReSeDis），首个将语料库级检索与像素级定位统一的任务。给定自由描述，ReSeDis模型需判断查询对象是否出现在每张图像中，并返回其边界框或分割掩码。为严谨研究，我们构建了一个基准，其中每个描述唯一映射到分散在大规模多样化语料中的对象实例，消除无意匹配。我们还设计了联合评分检索召回与定位精度的任务特定指标。最后，通过冻结视觉语言模型的零基线实验，展示了未来研究的巨大空间。ReSeDis为构建下一代稳健、可扩展的多模态搜索系统提供了现实的端到端测试平台。

</details>


### [79] [Conquering the Retina: Bringing Visual in-Context Learning to OCT](https://arxiv.org/abs/2506.15200)
**中文标题：征服视网膜：将视觉上下文学习引入OCT**

*Alessio Negrini,Simon Reiß*

主要分类: cs.CV

摘要简述: 本文探索了通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域，提出了一种评估协议并公开代码以促进研究。


<details>
  <summary>详细信息</summary>
研究动机: 当前医学图像分析领域高度依赖针对特定临床任务的专用模型，其开发和应用需要大量资源和专业知识。通用模型则允许医生动态定义任务，无需针对每项任务开发特定模型。本文旨在探索如何通过VICL训练通用模型，以提升视网膜OCT领域的灵活性和实用性。

研究方法: 本文采用视觉上下文学习（VICL）方法，训练模型在推理时基于少量示例实现跨任务泛化。同时，提出了一种针对OCT的VICL评估协议，并在多个视网膜OCT数据集上对现有医学VICL方法进行了全面评估。

研究结果: 研究结果表明，VICL在视网膜OCT领域具有潜力，但也存在局限性。通过公开代码和评估协议，为后续研究和实际应用提供了基础。

研究结论: 本文展示了VICL在视网膜OCT领域的应用前景，并提出了进一步研究和改进的方向。通过开源代码和评估协议，推动了该领域的发展。

中文摘要: 近年来，医学图像分析领域的进展催生了针对特定临床任务的高度专业化模型。这些模型表现出卓越性能，但仍需依赖大量资源和专业知识进行开发和适配。相比之下，通用模型提供了一种不同的实用性：允许医生动态定义任务，而无需针对每项任务开发特定模型。本文探索了如何通过视觉上下文学习（VICL）训练通用模型，应用于视网膜光学相干断层扫描（OCT）领域。为了严格评估，我们提出了一种针对OCT的VICL评估协议，并在多个视网膜OCT数据集上对现有医学VICL方法进行了全面评估，首次为OCT的上下文学习潜力与局限性提供了基线。为推动进一步研究和实际应用，我们公开了代码。

</details>


### [80] [Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models](https://arxiv.org/abs/2506.15201)
**中文标题：隐私保护图像压缩：防御视觉语言预训练模型的利用**

*Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为隐私保护图像压缩（PSIC）的方法，通过在图像压缩阶段嵌入防御机制，防止视觉语言预训练（VLP）模型对公开图像的语义利用。该方法支持多解码选项，既能保护隐私，又能保留原始压缩功能。


<details>
  <summary>详细信息</summary>
研究动机: 随着视觉语言预训练（VLP）模型语义理解能力的提升，公开图像的隐私保护变得愈发困难。本文旨在通过在图像压缩阶段嵌入防御机制，防止VLP模型对图像的语义利用，从而保护用户隐私。

研究方法: 提出隐私保护图像压缩（PSIC）方法，通过灵活的编码生成支持多解码选项的比特流。默认解码保留感知质量但阻止VLP模型解析；自定义条件下可恢复完整语义信息。设计了条件潜在触发生成（CLTG）模块和不确定性感知加密导向（UAEO）优化函数，并结合自适应多目标优化策略提升加密性能和感知质量。

研究结果: 实验表明，PSIC方法在多个下游任务中有效阻止VLP模型的语义利用，同时保持图像压缩功能。该方法可无缝集成到现有学习型图像压缩（LIC）模型中。

研究结论: PSIC方法为图像隐私保护提供了一种灵活且高效的解决方案，既能防止VLP模型的语义利用，又能保留图像压缩功能，具有广泛的应用潜力。

中文摘要: 视觉语言预训练（VLP）模型的语义理解能力提升使得公开图像的隐私保护愈发困难。本文旨在通过图像压缩阶段的防御机制防止VLP模型的语义利用。具体而言，我们提出了一种灵活的编码方法——隐私保护图像压缩（PSIC），可生成支持多解码选项的比特流。默认解码保留感知质量但阻止VLP模型解析，同时保留原始压缩功能。通过自定义输入条件，该方案可恢复完整语义信息。设计了条件潜在触发生成（CLTG）模块和不确定性感知加密导向（UAEO）优化函数，并结合自适应多目标优化策略在统一训练过程中提升加密性能和感知质量。该方法为即插即用方案，可无缝集成到现有学习型图像压缩（LIC）模型中。多下游任务实验验证了设计的有效性。

</details>


### [81] [DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder](https://arxiv.org/abs/2506.15218)
**中文标题：DM-FNet：基于扩散过程训练的编码器-解码器的统一多模态医学图像融合**

*Dan He,Weisheng Li,Guofen Wang,Yuping Huang,Shiqiang Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于扩散模型的两阶段多模态医学图像融合网络（DM-FNet），通过扩散过程训练编码器-解码器，提升融合图像的质量和信息密度。实验表明，该方法在亮度、颜色、对比度和细节方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态医学图像融合方法在捕捉细节特征和跨模态特征交互方面存在不足，导致融合图像质量不理想。本文旨在通过扩散模型提升融合效果。

研究方法: 方法分为两阶段：第一阶段通过扩散过程训练UNet进行图像重建，捕捉多级特征；第二阶段将不同步骤的噪声图像输入融合网络，结合三个关键融合模块自适应处理不同模态的医学图像。

研究结果: 实验结果表明，DM-FNet在多种医学图像类型上均表现优异，融合图像保留了适当的亮度、放射性示踪剂分布、丰富纹理和清晰边缘。

研究结论: DM-FNet通过扩散模型和混合损失函数，显著提升了多模态医学图像融合的质量和信息密度，为医学诊断提供了更全面的图像支持。

中文摘要: 多模态医学图像融合（MMIF）从多个源图像中提取最有意义的信息，以实现更全面和准确的诊断。高质量的融合结果需要在亮度、颜色、对比度和细节之间取得平衡，以确保融合图像有效显示相关解剖结构并反映组织的功能状态。然而，现有的MMIF方法在传统训练中捕捉细节特征的能力有限，且跨模态特征交互不足，导致融合图像质量不理想。为解决这些问题，本研究提出了一种基于扩散模型的两阶段融合网络（DM-FNet）以实现统一的MMIF。在第一阶段，扩散过程训练UNet进行图像重建。UNet通过逐步去噪捕捉细节信息并表征多级数据，为后续融合网络提供丰富的特征表示。在第二阶段，将不同步骤的噪声图像输入融合网络以增强模型的特征识别能力。同时，还集成了三个关键融合模块，以自适应处理不同模态的医学图像。最终，通过鲁棒的网络结构和混合损失函数，协调融合图像的亮度、颜色、对比度和细节，提升其质量和信息密度。在多种医学图像类型上的实验结果表明，所提方法在客观评价指标上表现优异。融合图像保留了适当的亮度、放射性示踪剂的全面分布、丰富纹理和清晰边缘。代码可在https://github.com/HeDan-11/DM-FNet获取。

</details>


### [82] [video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2506.15220)
**中文标题：video-SALMONN 2：字幕增强的视听大语言模型**

*Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang*

主要分类: cs.CV

摘要简述: 本文介绍了video-SALMONN 2，一种通过低秩适应（LoRA）和定向偏好优化（DPO）增强的视频（带音频）字幕生成模型。提出多轮DPO（MrDPO）方法，显著提升字幕准确性，错误率降低28%，性能超越GPT-4o和Gemini-1.5-Pro。


<details>
  <summary>详细信息</summary>
研究动机: 视频包含丰富信息，生成准确详细的自然语言描述是视频理解的关键。现有模型在字幕生成任务中仍有改进空间，因此提出video-SALMONN 2以提升性能。

研究方法: 采用低秩适应（LoRA）和定向偏好优化（DPO），提出多轮DPO（MrDPO）方法，定期更新参考模型并合并LoRA模块，结合真实字幕指导以稳定训练。

研究结果: 实验显示MrDPO显著提升字幕准确性，错误率降低28%。模型仅7B参数，性能超越GPT-4o和Gemini-1.5-Pro，并在视频问答任务中表现优异。

研究结论: video-SALMONN 2通过MrDPO方法显著提升视频字幕生成性能，成为同类模型中的领先者，代码已开源。

中文摘要: 视频包含丰富信息，生成详细准确的描述是视频理解的关键。本文提出video-SALMONN 2，一种基于低秩适应（LoRA）的视听大语言模型，通过定向偏好优化（DPO）增强视频（带音频）字幕生成。我们提出新指标评估描述的完整性和准确性，并通过DPO优化。为进一步提升训练，提出多轮DPO（MrDPO）方法，定期更新DPO参考模型，合并并重新初始化LoRA模块作为参数更新代理，同时结合真实字幕指导以稳定过程。实验结果表明，MrDPO显著提升video-SALMONN 2的字幕准确性，错误率降低28%。最终模型仅7B参数，在视频字幕任务中超越GPT-4o和Gemini-1.5-Pro，同时在视频问答基准测试中表现优异。代码已开源。

</details>


### [83] [Convolutional Feature Enhancement and Attention Fusion BiFPN for Ship Detection in SAR Images](https://arxiv.org/abs/2506.15231)
**中文标题：基于卷积特征增强与注意力融合BiFPN的SAR图像船舶检测**

*Liangjie Meng,Danxia Li,Jinrong He,Lili Ma,Zhixin Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为C-AFBiFPN的新型特征增强与融合框架，用于解决SAR图像中船舶检测的挑战，包括多尺度变化、小目标与噪声混合以及复杂背景问题。通过卷积特征增强模块和注意力融合BiFPN网络，显著提升了检测精度和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: SAR图像中的船舶检测面临多尺度变化、小目标与噪声混合以及复杂背景等挑战，现有方法难以有效应对。本文旨在通过特征增强和注意力融合技术提升检测性能。

研究方法: 提出C-AFBiFPN框架，包含卷积特征增强（CFE）模块以丰富特征表示，并创新性地将BiFormer注意力集成到BiFPN的融合策略中，形成AFBiFPN网络，增强全局建模能力。

研究结果: 在SAR Ship Detection Dataset (SSDD)上的实验表明，该方法显著提升了小目标检测精度、抗遮挡鲁棒性以及对多尺度特征的适应性。

研究结论: C-AFBiFPN通过特征增强和注意力融合策略，有效解决了SAR船舶检测中的关键问题，为相关领域提供了新的技术思路。

中文摘要: 合成孔径雷达（SAR）通过主动微波和先进信号处理技术实现了亚米级分辨率成像和全天候监测。目前，SAR在船舶检测等关键海事领域得到了广泛应用。然而，SAR船舶检测面临诸多挑战，包括船舶尺度变化显著、小目标与噪声混合以及近岸大型船舶的复杂背景。为解决这些问题，本文提出了一种名为C-AFBiFPN的新型特征增强与融合框架。C-AFBiFPN在骨干网络后构建了卷积特征增强（CFE）模块，旨在丰富特征表示并增强对局部细节和上下文信息的捕获能力。此外，C-AFBiFPN创新性地将BiFormer注意力集成到BiFPN的融合策略中，形成了AFBiFPN网络。AFBiFPN提升了跨尺度特征融合的全局建模能力，并能自适应地聚焦关键特征区域。在SAR Ship Detection Dataset (SSDD)上的实验结果表明，该方法显著提升了小目标检测精度、抗遮挡鲁棒性以及对多尺度特征的适应性。

</details>


### [84] [RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories](https://arxiv.org/abs/2506.15242)
**中文标题：RA-NeRF：复杂轨迹下基于精确相机姿态估计的鲁棒神经辐射场重建**

*Qingsong Yan,Qiang Wang,Kaiyong Zhao,Jie Chen,Bo Li,Xiaowen Chu,Fei Deng*

主要分类: cs.CV

摘要简述: RA-NeRF是一种新型方法，能够在复杂相机轨迹下实现高精度的相机姿态估计和场景重建，结合光度一致性和流驱动姿态调节，显著提升了鲁棒性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于NeRF和3DGS的3D重建方法依赖精确的相机姿态先验，但在复杂轨迹下表现不佳。RA-NeRF旨在解决这一问题，提升复杂轨迹下的姿态估计和重建质量。

研究方法: RA-NeRF采用增量式流程，结合光度一致性重建场景，并引入流驱动姿态调节增强初始化和定位的鲁棒性。此外，通过隐式姿态滤波器捕捉相机运动模式并消除噪声。

研究结果: 在Tanks&Temple和NeRFBuster数据集上的实验表明，RA-NeRF在相机姿态估计和视觉质量上均达到最先进水平，验证了其在复杂轨迹下的有效性和鲁棒性。

研究结论: RA-NeRF通过创新的姿态估计和重建方法，显著提升了复杂相机轨迹下的性能，为3D重建和SLAM任务提供了可靠解决方案。

中文摘要: 神经辐射场（NeRF）和3D高斯溅射（3DGS）已成为3D重建和SLAM任务中的强大工具，但其性能高度依赖于精确的相机姿态先验。现有方法尝试通过引入外部约束解决这一问题，但在复杂相机轨迹下仍难以达到令人满意的精度。本文提出了一种新方法RA-NeRF，能够在复杂相机轨迹下预测高精度的相机姿态。RA-NeRF采用增量式流程，利用光度一致性重建场景，并通过流驱动姿态调节增强初始化和定位的鲁棒性。此外，RA-NeRF使用隐式姿态滤波器捕捉相机运动模式并消除姿态估计中的噪声。为验证方法有效性，我们在Tanks&Temple数据集上进行标准评估，并在具有挑战性相机轨迹的NeRFBuster数据集上进行测试。实验结果表明，RA-NeRF在相机姿态估计和视觉质量上均达到最先进水平，证明了其在复杂姿态轨迹下场景重建的有效性和鲁棒性。

</details>


### [85] [Retrospective Memory for Camouflaged Object Detection](https://arxiv.org/abs/2506.15244)
**中文标题：基于回忆机制的伪装目标检测**

*Chenxi Zhang,Jiayun Wu,Qing Zhang,Yazhe Zhai,Youwei Pang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为RetroMem的回忆增强型伪装目标检测架构，通过整合历史知识动态调整伪装模式感知与推理，显著提升了模型对复杂伪装场景的理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有伪装目标检测方法主要基于静态视觉表示建模，缺乏获取历史背景的机制，限制了其在复杂伪装场景中的适应性和有效性。

研究方法: RetroMem采用两阶段训练范式：学习阶段通过密集多尺度适配器（DMA）提升预训练编码器的多尺度信息捕获能力；回忆阶段通过动态记忆机制（DMM）和推理模式重构（IPR）利用历史知识与当前样本上下文重构伪装模式推理。

研究结果: 在多个广泛使用的数据集上的实验表明，RetroMem显著优于现有最先进方法。

研究结论: RetroMem通过整合历史知识动态优化伪装模式推理，显著提升了伪装目标检测的性能。

中文摘要: 伪装目标检测（COD）主要关注从复杂场景中学习细微但具有区分性的表示。现有方法主要基于静态视觉表示建模的参数化前馈架构，但缺乏获取历史背景的显式机制，限制了其在处理复杂伪装场景时的适应性和有效性。本文提出了一种回忆增强型COD架构RetroMem，通过整合相关历史知识动态调整伪装模式的感知与推理。具体而言，RetroMem采用两阶段训练范式，包括学习阶段和回忆阶段，以有效构建、更新和利用记忆表示。在学习阶段，我们设计了密集多尺度适配器（DMA），以极少的可训练参数提升预训练编码器捕获丰富多尺度视觉信息的能力，从而提供基础推理。在回忆阶段，我们提出了动态记忆机制（DMM）和推理模式重构（IPR），这些组件充分利用学习知识与当前样本上下文之间的潜在关系重构伪装模式的推理，从而显著提升模型对伪装场景的理解。在多个广泛使用的数据集上的大量实验表明，我们的RetroMem显著优于现有最先进方法。

</details>


### [86] [Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing](https://arxiv.org/abs/2506.15260)
**中文标题：半导体制造缺陷图像分类的领域自适应技术**

*Adrian Poniatowski,Natalie Gentner,Manuel Barusco,Davide Dalle Pezze,Samuele Salti,Gian Antonio Susto*

主要分类: cs.CV

摘要简述: 本文探讨了在半导体制造缺陷图像分类中应用领域自适应（DA）技术的有效性，提出了一种改进的CycleGAN模型（DBACS），并在半监督和无监督设置下验证了其性能。


<details>
  <summary>详细信息</summary>
研究动机: 半导体行业对快速上市和高质量的需求日益增长，而深度学习在缺陷分类等工业应用中表现出色。领域自适应技术能够减少重新标注和训练的需求，降低成本并提高效率，因此研究其在半导体领域的应用具有重要意义。

研究方法: 本文提出了一种名为DBACS的改进CycleGAN模型，通过引入额外的损失项来提升性能。在半监督和无监督设置下，使用真实的电子显微镜图像对方法进行了验证。

研究结果: 实验证明，DBACS方法在半监督和无监督设置下均表现出色，显著提升了领域自适应技术在半导体缺陷分类中的应用效果。

研究结论: 本文提出的DBACS方法为半导体制造中的缺陷分类提供了一种高效且成本低廉的解决方案，推动了领域自适应技术在该领域的进一步发展。

中文摘要: 在半导体行业，由于高需求和激烈的竞争，快速上市和产品质量成为确保市场份额的关键因素。近年来，深度学习在计算机视觉领域的成功为工业4.0和5.0应用（如缺陷分类）带来了显著成果。领域自适应（DA）技术因其能够利用源领域的知识适应目标领域而表现出高效性，减少了重新标注和训练的需求，降低了计算和资源成本，并使专家能够专注于高价值任务。为此，我们在半导体领域的半监督和无监督设置下测试了DA技术的有效性，并提出了一种改进的CycleGAN模型（DBACS），通过额外的损失项提升性能。所有方法均在真实的电子显微镜图像上进行了验证，证明了其在推动半导体领域DA技术发展中的实用性。

</details>


### [87] [MSNeRV: Neural Video Representation with Multi-Scale Feature Fusion](https://arxiv.org/abs/2506.15276)
**中文标题：MSNeRV：基于多尺度特征融合的神经视频表示**

*Jun Zhu,Xinfeng Zhang,Lv Tang,JunHao Jiang*

主要分类: cs.CV

摘要简述: MSNeRV提出了一种多尺度特征融合框架，用于神经视频表示，解决了现有隐式神经表示方法在细节密集和快速变化视频内容中的不足，并在压缩效率上超越了VTM-23.7。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于隐式神经表示（INR）的视频压缩方法在细节密集和快速变化的内容上表现不佳，主要原因是网络内部特征利用不足且缺乏视频特定的设计。

研究方法: MSNeRV采用多尺度特征融合框架，在编码阶段通过时间窗口增强时间一致性，将视频分为多个图像组（GoP），并使用GoP级网格表示背景。同时设计了多尺度空间解码器和尺度自适应损失函数，并引入多尺度特征块以充分利用隐藏特征。

研究结果: 在HEVC ClassB和UVG数据集上的实验表明，MSNeRV在INR方法中表现出卓越的表示能力，并在动态场景的压缩效率上超越了VTM-23.7。

研究结论: MSNeRV通过多尺度特征融合和视频特定设计，显著提升了神经视频表示的性能，为视频压缩领域提供了新的解决方案。

中文摘要: 隐式神经表示（INR）已成为视频压缩的一种有前景的方法，其性能已与H.266/VVC等最先进的编解码器相当。然而，现有的基于INR的方法在细节密集和快速变化的视频内容上表现不佳。这一限制主要源于网络内部特征的利用不足以及网络设计中缺乏视频特定的考虑。为解决这些问题，我们提出了一种多尺度特征融合框架MSNeRV，用于神经视频表示。在编码阶段，我们通过时间窗口增强时间一致性，并将视频分为多个图像组（GoP），其中GoP级网格用于背景表示。此外，我们设计了一个多尺度空间解码器，并采用尺度自适应损失函数以整合多分辨率和多频率信息。为进一步提升特征提取，我们引入了多尺度特征块以充分利用隐藏特征。我们在HEVC ClassB和UVG数据集上评估了MSNeRV的视频表示和压缩性能。实验结果表明，我们的模型在INR方法中表现出卓越的表示能力，并在动态场景的压缩效率上超越了VTM-23.7（随机访问）。

</details>


### [88] [BCRNet: Enhancing Landmark Detection in Laparoscopic Liver Surgery via Bezier Curve Refinement](https://arxiv.org/abs/2506.15279)
**中文标题：BCRNet：通过贝塞尔曲线优化增强腹腔镜肝脏手术中的标志检测**

*Qian Li,Feng Liu,Shuojue Yang,Daiyun Shen,Yueming Jin*

主要分类: cs.CV

摘要简述: BCRNet通过贝塞尔曲线优化策略显著提升腹腔镜肝脏手术中的关键解剖标志检测，结合多模态特征提取和分层曲线细化机制，在L3D和P2ILF数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 腹腔镜肝脏手术中，准确识别弯曲解剖标志对增强现实导航系统至关重要，但现有方法在检测精度上仍有不足。

研究方法: 提出BCRNet框架，包括多模态特征提取模块（MFE）、自适应曲线提议初始化（ACPI）生成像素对齐的贝塞尔曲线，以及分层曲线细化（HCR）机制逐步优化曲线。

研究结果: 在L3D和P2ILF数据集上，BCRNet显著优于现有方法，性能提升明显。

研究结论: BCRNet通过贝塞尔曲线优化和多阶段细化机制，为腹腔镜手术中的标志检测提供了高效解决方案。

中文摘要: 腹腔镜肝脏手术虽微创，但准确识别关键解剖结构仍具挑战。基于MRI/CT与腹腔镜图像的增强现实（AR）系统通过2D-3D配准为手术导航提供了新思路，而配准的关键在于腹腔镜图像中弯曲解剖标志的精确检测。本文提出BCRNet（贝塞尔曲线优化网络），通过贝塞尔曲线优化策略显著提升标志检测性能。框架包含多模态特征提取（MFE）模块以捕获语义特征，自适应曲线提议初始化（ACPI）生成像素对齐的贝塞尔曲线及置信度评分，以及分层曲线细化（HCR）机制通过多阶段过程逐步优化曲线。在L3D和P2ILF数据集上的广泛实验表明，BCRNet优于现有方法，性能提升显著。代码将公开。

</details>


### [89] [AI-driven visual monitoring of industrial assembly tasks](https://arxiv.org/abs/2506.15285)
**中文标题：AI驱动的工业装配任务视觉监控**

*Mattia Nardon,Stefano Messelodi,Antonio Granata,Fabio Poiesi,Alberto Danese,Davide Boscaini*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViMAT的AI驱动系统，用于实时视觉监控工业装配任务，无需刚性工作空间设置或视觉标记。ViMAT通过多视角视频流提取视觉观察，并结合推理模块推断最可能的操作，验证了其在挑战性场景中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 工业装配任务的视觉监控对防止设备损坏和确保工人安全至关重要。现有商业解决方案通常需要刚性工作空间设置或视觉标记，限制了其应用范围。本文旨在开发一种无需这些约束的实时监控系统。

研究方法: ViMAT系统结合了感知模块和推理模块。感知模块从多视角视频流中提取视觉观察，推理模块基于观察到的装配状态和先验任务知识推断最可能的操作。

研究结果: ViMAT在LEGO组件更换和液压机模具重新配置两项任务中进行了验证，通过定量和定性分析证明了其在部分和不确定视觉观察场景中的有效性。

研究结论: ViMAT提供了一种无需刚性设置或视觉标记的工业装配任务实时监控解决方案，在挑战性场景中表现出色，为工业自动化提供了新工具。

中文摘要: 工业装配任务的视觉监控对于防止因程序错误导致的设备损坏和确保工人安全至关重要。尽管已有商业解决方案，但它们通常需要刚性工作空间设置或应用视觉标记以简化问题。我们提出了ViMAT，一种新型AI驱动的实时视觉监控系统，无需这些约束。ViMAT结合了从多视角视频流中提取视觉观察的感知模块，以及基于观察到的装配状态和先验任务知识推断最可能操作的推理模块。我们在两项装配任务（LEGO组件更换和液压机模具重新配置）上验证了ViMAT，通过定量和定性分析证明了其在具有部分和不确定视觉观察的挑战性现实场景中的有效性。项目页面：https://tev-fbk.github.io/ViMAT

</details>


### [90] [MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering](https://arxiv.org/abs/2506.15298)
**中文标题：MEGC2025：微表情大挑战——先检测后识别与视觉问答**

*Xinqi Fan,Jingting Li,John See,Moi Hoon Yap,Wen-Huang Cheng,Xiaobai Li,Xiaopeng Hong,Su-Jing Wang,Adrian K. Davision*

主要分类: cs.CV

摘要简述: MEGC2025挑战赛聚焦微表情的‘先检测后识别’和视觉问答任务，旨在通过多模态大模型提升微表情分析的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法将微表情检测与识别分开处理，效率低下，尤其在长视频分析中表现不佳。多模态大语言模型的出现为微表情分析提供了新思路。

研究方法: 挑战赛提出两项任务：(1) ME-STR：将微表情检测与识别整合为统一流程；(2) ME-VQA：利用多模态大模型通过视觉问答理解微表情。

研究结果: 参赛算法需在测试集上运行并提交结果，排行榜将展示性能表现。

研究结论: MEGC2025通过创新任务设计推动微表情分析领域的发展，尤其关注多模态技术的应用。

中文摘要: 面部微表情（MEs）是人在抑制情绪时面部产生的无意识动作，常见于高风险环境。近年来，微表情的识别、检测与生成领域取得显著进展。然而，传统方法将检测与识别分开处理，在分析长视频时效率低下。同时，多模态大语言模型（MLLMs）和大视觉语言模型（LVLMs）的出现为微表情分析提供了新的可能性。MEGC2025挑战赛提出两项任务：(1) ME-STR：将微表情检测与识别整合为统一流程；(2) ME-VQA：通过视觉问答探索微表情理解，利用MLLMs或LVLMs处理多样化的微表情相关问题。所有参赛算法需在测试集上运行并提交结果至排行榜。详情请访问https://megc2025.github.io。

</details>


### [91] [MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning](https://arxiv.org/abs/2506.15313)
**中文标题：MapFM：基于基础模型的多任务上下文学习驱动的高精地图生成**

*Leonid Ivanov,Vasily Yuryev,Dmitry Yudin*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MapFM的端到端模型，用于在线生成矢量化的高精地图（HD地图）。通过结合强大的基础模型编码相机图像，显著提升了特征表示质量，并通过多任务学习（如BEV语义分割）进一步优化了预测精度。


<details>
  <summary>详细信息</summary>
研究动机: 在自动驾驶中，高精地图和鸟瞰图（BEV）语义地图对精确定位、路径规划和决策至关重要。现有方法在特征表示和场景理解上仍有不足，因此需要一种更高效的端到端模型来提升地图生成的质量和准确性。

研究方法: MapFM模型结合了强大的基础模型对相机图像进行编码，显著提升了特征表示质量。此外，通过引入多任务学习框架（如BEV语义分割），进一步丰富了模型的上下文监督，从而生成更全面的场景表示和更高质量的矢量化HD地图。

研究结果: 实验表明，MapFM在特征表示和预测质量上均有显著提升，生成的矢量化HD地图精度更高，质量更优。

研究结论: MapFM通过结合基础模型和多任务学习，成功提升了在线HD地图生成的准确性和质量，为自动驾驶领域提供了更高效的地图解决方案。

中文摘要: 在自动驾驶中，高精地图（HD地图）和鸟瞰图（BEV）语义地图对精确定位、路径规划和决策至关重要。本文提出了一种名为MapFM的增强型端到端模型，用于在线生成矢量化的HD地图。通过结合强大的基础模型编码相机图像，显著提升了特征表示质量。为进一步丰富模型对环境的理解并提升预测质量，我们在BEV表示中集成了语义分割的辅助预测头。这种多任务学习方法提供了更丰富的上下文监督，从而生成更全面的场景表示，最终实现了更高精度和更优质量的矢量化HD地图预测。源代码发布于https://github.com/LIvanoff/MapFM。

</details>


### [92] [OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models](https://arxiv.org/abs/2506.15318)
**中文标题：OpenPath：基于预训练视觉语言模型的病理图像分类开集主动学习**

*Lanfeng Zhong,Xin Liao,Shichuan Zhang,Shaoting Zhang,Guotai Wang*

主要分类: cs.CV

摘要简述: OpenPath是一种基于预训练视觉语言模型的开集主动学习方法，用于病理图像分类，通过任务特定提示和多样性信息采样策略，显著提升标注效率和模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 病理图像分类在医学诊断中至关重要，但大规模标注数据获取成本高。传统主动学习方法在开集场景（存在大量分布外数据）中效率低下，且初始随机选择浪费标注资源。OpenPath旨在解决这些问题。

研究方法: OpenPath利用预训练视觉语言模型，首轮查询使用任务特定提示筛选分布内样本，后续采用原型候选选择和熵引导随机采样策略（DIS），确保样本纯度和信息量。

研究结果: 在两个公开病理图像数据集上，OpenPath显著优于现有开集主动学习方法，所选样本纯度高，模型性能提升明显。

研究结论: OpenPath通过结合任务特定提示和多样性采样策略，有效解决了开集主动学习中的标注效率问题，为病理图像分类提供了高效解决方案。

中文摘要: 病理图像分类在医学诊断和治疗规划中具有重要作用。训练高性能模型通常需要大规模标注数据集，但其获取成本高昂且耗时。主动学习（AL）通过迭代选择信息量最大的样本进行标注，从而减少标注工作量。然而，大多数AL方法基于闭集假设，即未标注图像均属于目标类别。在真实临床环境中，未标注池常包含大量分布外（OOD）数据，导致传统AL方法标注效率低下。此外，现有AL方法首轮查询通常随机选择，在开集场景中造成标注资源浪费。为解决这些问题，我们提出OpenPath，一种基于预训练视觉语言模型（VLM）的开集主动学习方法。首轮查询中，我们结合目标类和非目标类提示的任务特定提示，从未标注池中高效筛选分布内（ID）和信息量大的样本。后续查询中，提出多样性信息ID采样（DIS），包括基于原型的ID候选选择（PIS）和熵引导随机采样（EGSS），确保查询的纯度和信息量，避免选择OOD样本。在两个公开病理图像数据集上的实验表明，OpenPath因所选样本纯度高而显著提升模型性能，并优于多种先进开集AL方法。代码发布于\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}。

</details>


### [93] [Open-World Object Counting in Videos](https://arxiv.org/abs/2506.15368)
**中文标题：视频中的开放世界目标计数**

*Niki Amini-Naieni,Andrew Zisserman*

主要分类: cs.CV

摘要简述: 本文提出了一种新的视频开放世界目标计数任务，并开发了CountVid模型，结合图像计数和视频分割跟踪技术，显著提升了目标计数的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在拥挤场景中，由于遮挡和相似目标的存在，准确计数视频中的目标实例具有挑战性。本文旨在解决这一问题，提出开放世界目标计数任务，并开发高效模型。

研究方法: 提出CountVid模型，结合基于图像的计数模型和可提示的视频分割与跟踪模型，实现跨视频帧的自动化目标计数。同时，构建了VideoCount数据集用于评估。

研究结果: 实验表明，CountVid在VideoCount数据集上表现优异，显著优于基线方法，能够提供准确的目标计数结果。

研究结论: CountVid模型和VideoCount数据集为开放世界视频目标计数任务提供了有效解决方案，未来可进一步扩展应用场景。

中文摘要: 我们提出了一种新的视频开放世界目标计数任务：给定一个文本描述或图像示例来指定目标对象，目标是枚举视频中所有目标对象的唯一实例。这一任务在拥挤场景中尤为困难，因为遮挡和相似对象的存在使得避免重复计数和识别重现变得至关重要。为此，我们做出了以下贡献：我们提出了一个名为CountVid的模型，它结合了基于图像的计数模型和可提示的视频分割与跟踪模型，实现了跨视频帧的自动化开放世界目标计数。为了评估其性能，我们构建了VideoCount数据集，该数据集基于TAO和MOT20跟踪数据集，以及通过X射线拍摄的企鹅和金属合金结晶视频。实验表明，CountVid能够提供准确的目标计数结果，并显著优于基线方法。VideoCount数据集、CountVid模型及相关代码均已开源。

</details>


### [94] [Unsupervised Pelage Pattern Unwrapping for Animal Re-identification](https://arxiv.org/abs/2506.15369)
**中文标题：无监督动物皮毛图案展开用于再识别**

*Aleksandr Algasov,Ekaterina Nepovinnykh,Fedor Zolotarev,Tuomas Eerola,Heikki Kälviäinen,Pavel Zemčík,Charles V. Stewart*

主要分类: cs.CV

摘要简述: 本文提出一种无监督的动物皮毛图案展开方法，通过几何感知的纹理映射将变形图案映射到规范UV空间，提升动物再识别的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有动物再识别方法难以处理因身体运动和姿势变化导致的皮毛或皮肤图案变形问题，因此需要一种几何一致的方法来展开图案。

研究方法: 采用表面法线估计引导图案展开过程，确保3D表面与2D纹理空间的几何一致性，并结合自监督训练，无需真实UV标注。

研究结果: 在环斑海豹和豹子数据集上，再识别准确率最高提升5.4%，验证了方法的有效性。

研究结论: 所提方法能够无监督地展开变形图案，显著提升动物再识别的准确性，适用于多种姿势和视角。

中文摘要: 现有的个体再识别方法常因动物皮毛或皮肤图案的变形性而受限，这些图案会因身体运动和姿势变化而发生几何扭曲。本文提出一种几何感知的纹理映射方法，将独特的皮毛图案展开到规范的UV空间，从而实现更鲁棒的特征匹配。我们的方法利用表面法线估计引导展开过程，同时保持3D表面与2D纹理空间的几何一致性。研究聚焦于两种具有挑战性的物种：赛马环斑海豹（Pusa hispida saimensis）和豹子（Panthera pardus），它们的皮毛图案独特且易变形。通过将图案保持的UV映射与现有再识别技术结合，我们在多样姿势和视角下展示了更高的准确性。该框架无需真实UV标注，可通过自监督方式训练。在环斑海豹和豹子数据集上的实验表明，再识别准确率最高提升5.4%。

</details>


### [95] [When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class](https://arxiv.org/abs/2506.15381)
**中文标题：当模型知识遇见扩散模型：扩散辅助的无数据图像合成与领域和类对齐**

*Yujin Kim,Hyunsoo Kim,Hyunwoo J. Kim,Suhyun Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DDIS的扩散辅助无数据图像合成方法，利用扩散模型作为图像先验，结合领域对齐指导和类对齐标记，显著提升了合成图像的质量和与训练数据分布的一致性。


<details>
  <summary>详细信息</summary>
研究动机: 开源预训练模型在训练数据不可用时，其应用价值受限。现有的无数据图像合成方法因缺乏自然图像的先验知识，生成的样本偏离训练数据分布。本文旨在解决这一问题。

研究方法: DDIS方法通过扩散模型作为图像先验，结合领域对齐指导（DAG）和优化的类对齐标记（CAT），在扩散采样过程中对齐合成数据与训练数据的分布，并捕捉类特定属性。

研究结果: 在PACS和ImageNet上的实验表明，DDIS生成的样本更接近训练数据分布，优于现有无数据图像合成方法，实现了最先进的性能。

研究结论: DDIS通过结合扩散模型和领域对齐技术，显著提升了无数据图像合成的质量，为数据不可用场景下的模型应用提供了新思路。

中文摘要: 开源预训练模型具有广泛的应用潜力，但当其训练数据不可用时，其效用会下降。无数据图像合成（DFIS）旨在无需访问原始数据的情况下生成近似预训练模型学习数据分布的图像。然而，现有DFIS方法因缺乏自然图像的先验知识，生成的样本偏离训练数据分布。为解决这一问题，我们提出了DDIS，首个利用文本到图像扩散模型作为强大图像先验的扩散辅助无数据图像合成方法，显著提升了合成图像质量。DDIS从给定模型中提取学习分布的知识，并利用其指导扩散模型，生成与训练数据分布准确对齐的图像。为此，我们引入了领域对齐指导（DAG），在扩散采样过程中将合成数据领域与训练数据领域对齐。此外，我们优化了单个类对齐标记（CAT）嵌入，以有效捕捉训练数据集中类特定属性。在PACS和ImageNet上的实验表明，DDIS优于现有DFIS方法，生成的样本更接近训练数据分布，在无数据应用中实现了最先进的性能。

</details>


### [96] [NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance](https://arxiv.org/abs/2506.15404)
**中文标题：NERO：基于神经元级相关性的可解释性分布外检测**

*Anju Chhetri,Jari Korhonen,Prashnna Gyawali,Binod Bhattarai*

主要分类: cs.CV

摘要简述: 本文提出了一种名为NERO的新型OOD检测方法，通过神经元级相关性增强OOD样本的可分离性，并在医学影像基准测试中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在医学影像领域，深度学习模型的可靠性至关重要，而OOD样本的检测是评估模型可靠性的重要指标。现有方法在捕捉OOD多样性方面存在不足，因此需要一种更有效的OOD检测机制。

研究方法: NERO利用特征层的神经元级相关性，通过聚类形成代表性中心点，并引入相关性距离度量来量化新样本与这些中心点的偏差。此外，通过结合偏置项的缩放相关性和特征范数，进一步优化性能。

研究结果: 在胃肠道影像基准测试Kvasir和GastroVision上，NERO在多种深度学习架构中表现出色，优于现有的OOD检测方法。

研究结论: NERO不仅提高了OOD检测的准确性，还实现了可解释的OOD检测，为医学影像领域的模型可靠性提供了有力支持。

中文摘要: 在深度学习中，确保可靠性至关重要，尤其是在医学影像领域，诊断决策往往依赖于模型输出。分布外（OOD）样本的分离能力已被证明是评估模型可靠性的重要指标。在医学影像中，识别OOD输入尤为关键，因为它可以帮助标记潜在异常，避免遗漏。尽管许多OOD检测方法依赖于特征或逻辑空间表示，但近期研究表明这些方法可能无法完全捕捉OOD的多样性。为此，我们提出了一种名为NERO的新型OOD评分机制，利用特征层的神经元级相关性。具体而言，我们为每个分布内（ID）类别的神经元级相关性进行聚类，形成代表性中心点，并引入相关性距离度量来量化新样本与这些中心点的偏差，从而增强OOD的可分离性。此外，通过结合偏置项的缩放相关性和特征范数，进一步优化性能。我们的框架还实现了可解释的OOD检测。我们在胃肠道影像基准测试Kvasir和GastroVision上验证了其有效性，结果表明NERO在多种深度学习架构中优于现有的OOD检测方法。

</details>


### [97] [Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material](https://arxiv.org/abs/2506.15442)
**中文标题：Hunyuan3D 2.1：从图像到高保真3D资产，具备生产级PBR材质**

*Team Hunyuan3D,Shuhui Yang,Mingxin Yang,Yifei Feng,Xin Huang,Sheng Zhang,Zebin He,Di Luo,Haolin Liu,Yunfei Zhao,Qingxiang Lin,Zeqiang Lai,Xianghui Yang,Huiwen Shi,Zibo Zhao,Bowen Zhang,Hongyu Yan,Lifu Wang,Sicong Liu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Yulin Cai,Jiaao Yu,Yixuan Tang,Dongyuan Guo,Junlin Yu,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Shida Wei,Chao Zhang,Yonghao Tan,Yifu Sun,Lin Niu,Shirui Huang,Bojian Zheng,Shu Liu,Shilin Chen,Xiang Yuan,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Jingwei Huang,Chunchao Guo*

主要分类: cs.CV

摘要简述: 本文介绍了Hunyuan3D 2.1系统，通过逐步指南展示了如何从图像生成高保真3D资产，包括形状生成和纹理合成，适用于游戏、虚拟现实和工业设计。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D AI生成内容（AIGC）领域虽然发展迅速，但由于数据收集、处理和训练的复杂性，仍主要局限于研究人员和开发者。本文旨在通过Hunyuan3D 2.1系统降低门槛，提供实用的3D生成解决方案。

研究方法: 系统包含两个核心组件：Hunyuan3D-DiT用于形状生成，Hunyuan3D-Paint用于纹理合成。教程详细介绍了数据准备、模型架构、训练策略、评估指标和部署流程。

研究结果: Hunyuan3D 2.1能够生成高分辨率、带纹理的3D资产，适用于多种应用场景，如游戏、虚拟现实和工业设计。

研究结论: 通过本教程，用户可以掌握如何微调或开发适用于实际应用的3D生成模型，推动3D AIGC的普及。

中文摘要: 3D AI生成内容（AIGC）是一个快速发展的领域，显著加速了游戏、电影和设计中的3D模型创作。尽管已有多个突破性模型推动了3D生成技术的发展，但由于数据收集、处理和训练的复杂性，该领域仍主要局限于研究人员、开发者和设计师。为解决这些问题，本文以Hunyuan3D 2.1为例，提供了一个全面的分步教程，涵盖3D数据处理、3D生成模型训练及其性能评估。该系统由两个核心组件组成：Hunyuan3D-DiT用于形状生成，Hunyuan3D-Paint用于纹理合成。我们将探讨整个工作流程，包括数据准备、模型架构、训练策略、评估指标和部署。通过本教程，您将掌握如何微调或开发适用于游戏、虚拟现实和工业设计的强大3D生成模型。

</details>


### [98] [Multimodal Large Language Models for Medical Report Generation via Customized Prompt Tuning](https://arxiv.org/abs/2506.15477)
**中文标题：基于定制化提示调整的多模态大语言模型在医学报告生成中的应用**

*Chunlei Li,Jingyang Hou,Yilei Shi,Jingliang Hu,Xiao Xiang Zhu,Lichao Mou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MRG-LLM的多模态大语言模型，通过定制化提示调整机制，结合冻结的LLM和可学习的视觉编码器，实现了针对医学图像的个性化报告生成。实验表明，该方法在IU X-ray和MIMIC-CXR数据集上达到了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像报告生成在临床实践中仍具挑战性。尽管大语言模型（LLMs）在此领域展现出潜力，但其与医学影像数据的有效整合仍需深入研究。本文旨在探索如何通过定制化提示调整机制，提升医学报告生成的准确性和针对性。

研究方法: MRG-LLM模型结合了冻结的大语言模型和可学习的视觉编码器，并引入了动态提示定制机制。通过基于视觉特征的仿射变换生成实例特定的提示，提出了两种实现方式：提示级别和提示簿级别的定制，以实现精准的报告生成。

研究结果: 在IU X-ray和MIMIC-CXR数据集上的广泛实验表明，MRG-LLM在医学报告生成任务中达到了最先进的性能。

研究结论: MRG-LLM通过动态提示定制机制，成功实现了医学影像报告的个性化生成，为临床实践提供了高效且精准的解决方案。

中文摘要: 医学影像数据的报告生成在临床实践中仍是一项具有挑战性的任务。尽管大语言模型（LLMs）在此领域展现出巨大潜力，但其与医学影像数据的有效整合仍需深入探索。本文提出了一种名为MRG-LLM的新型多模态大语言模型（MLLM），该模型将冻结的LLM与可学习的视觉编码器相结合，并引入了动态提示定制机制。我们的关键创新在于通过基于视觉特征的仿射变换生成针对单个医学图像的实例特定提示。我们提出了两种实现方式：提示级别和提示簿级别的定制，以实现精准且有针对性的报告生成。在IU X-ray和MIMIC-CXR数据集上的大量实验表明，MRG-LLM在医学报告生成任务中达到了最先进的性能。我们的代码将公开提供。

</details>


### [99] [GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects](https://arxiv.org/abs/2506.15483)
**中文标题：GenHOI：面向未见对象的文本驱动4D人-物交互合成的泛化**

*Shujia Li,Haiyu Zhang,Xinyuan Chen,Yaohui Wang,Yutong Ban*

主要分类: cs.CV

摘要简述: GenHOI是一种新颖的两阶段框架，旨在泛化到未见过的对象并合成高保真4D人-物交互序列。通过Object-AnchorNet和Contact-Aware Diffusion Model，实现了对未见对象的泛化和高质量4D序列生成。


<details>
  <summary>详细信息</summary>
研究动机: 尽管扩散模型和大规模运动数据集推动了文本驱动的人体运动合成，但由于缺乏大规模4D人-物交互数据集，将其扩展到4D人-物交互仍具挑战性。GenHOI旨在解决这一问题。

研究方法: GenHOI采用两阶段框架：1) 使用Object-AnchorNet从3D HOI数据集中重建未见对象的稀疏3D HOI关键帧；2) 通过Contact-Aware Diffusion Model（ContactDM）插值生成密集的4D HOI序列，并引入Contact-Aware Encoder和HOI Attention提升质量。

研究结果: 在OMOMO和3D-FUTURE数据集上，GenHOI实现了最先进的结果，展示了强大的未见对象泛化能力和高保真4D HOI生成能力。

研究结论: GenHOI通过两阶段框架成功解决了4D人-物交互合成的泛化和高质量生成问题，为未来研究提供了新方向。

中文摘要: 尽管扩散模型和大规模运动数据集推动了文本驱动的人体运动合成，但将其扩展到4D人-物交互（HOI）仍具挑战性，主要由于缺乏大规模4D HOI数据集。本研究提出GenHOI，一种新颖的两阶段框架，旨在实现两个关键目标：1) 泛化到未见对象；2) 合成高保真4D HOI序列。框架的第一阶段使用Object-AnchorNet从3D HOI数据集中重建未见对象的稀疏3D HOI关键帧，减少对大规模4D HOI数据集的依赖。第二阶段引入Contact-Aware Diffusion Model（ContactDM），将稀疏3D HOI关键帧插值为密集且时间连贯的4D HOI序列。为提升生成质量，ContactDM中提出Contact-Aware Encoder提取人-物接触模式，以及Contact-Aware HOI Attention将接触信号有效融入扩散模型。实验结果表明，在公开的OMOMO和3D-FUTURE数据集上，GenHOI取得了最先进的结果，展示了强大的未见对象泛化能力，同时实现了高保真4D HOI生成。

</details>


### [100] [NTIRE 2025 Image Shadow Removal Challenge Report](https://arxiv.org/abs/2506.15524)
**中文标题：NTIRE 2025图像阴影去除挑战赛报告**

*Florin-Alexandru Vasluianu,Tim Seizinger,Zhuyun Zhou,Cailian Chen,Zongwei Wu,Radu Timofte,Mingjia Li,Jin Hu,Hainuo Wang,Hengxing Liu,Jiarui Wang,Qiming Hu,Xiaojie Guo,Xin Lu,Jiarong Yang,Yuanfei Bao,Anya Hu,Zihao Fan,Kunyu Wang,Jie Xiao,Xi Wang,Xueyang Fu,Zheng-Jun Zha,Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu,Xingbo Wang,Dong Li,Yuxu Chen,Bin Chen,Yuanbo Zhou,Yuanbin Chen,Hongwei Wang,Jiannan Lin,Qinquan Gao,Tong Tong,Zhao Zhang,Yanyan Wei,Wei Dong,Han Zhou,Seyed Amirreza Mousavi,Jun Chen,Haobo Liang,Jiajie Jing,Junyu Li,Yan Yang,Seoyeon Lee,Chaewon Kim,Ziyu Feng,Shidi Chen,Bowen Luan,Zewen Chen,Vijayalaxmi Ashok Aralikatti,G Gyaneshwar Rao,Nikhil Akalwadi,Chaitra Desai,Ramesh Ashok Tabib,Uma Mudenagudi,Anas M. Ali,Bilel Benjdira,Wadii Boulila,Alexandru Brateanu,Cosmin Ancuti,Tanmay Chaturvedi,Manish Kumar,Anmol Srivastav,Daksh Trivedi,Shashwat Thakur,Kishor Upla,Zeyu Xiao,Zhuoyuan Li,Boda Zhou,Shashank Shekhar,Kele Xu,Qisheng Xu,Zijian Gao,Tianjiao Wan,Suiyi Zhao,Bo Wang,Yan Luo,Mingshen Wang,Yilin Zhang*

主要分类: cs.CV

摘要简述: 本文总结了NTIRE 2025图像阴影去除挑战赛的结果，共有306名参与者注册，17支团队成功提交解决方案。挑战赛分为重建保真度和视觉感知两个评估赛道，使用WSRD+数据集进行评测。


<details>
  <summary>详细信息</summary>
研究动机: NTIRE 2025挑战赛旨在推动图像阴影去除技术的发展，通过多团队竞争和双赛道评估，探索阴影去除在重建保真度和视觉感知方面的最新进展。

研究方法: 挑战赛分为两个评估赛道：重建保真度赛道和用户研究视觉感知赛道，使用WSRD+数据集模拟多种物体、纹理和材料的自阴影和投射阴影交互。

研究结果: 共有306名参与者注册，17支团队成功提交解决方案，展示了阴影去除技术在双赛道评估中的表现。

研究结论: NTIRE 2025挑战赛为图像阴影去除领域提供了新的基准和方向，推动了技术在多场景下的应用。

中文摘要: 本文研究了NTIRE 2025阴影去除挑战赛的结果。共有306名参与者注册，17支团队在最终评估阶段成功提交了解决方案。继前两届之后，本次挑战赛设置了两个评估赛道：一个关注重建保真度，另一个通过用户研究关注视觉感知。两个赛道均使用WSRD+数据集进行评估，模拟了自阴影和投射阴影与大量多样物体、纹理和材料的交互。

</details>


### [101] [CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation](https://arxiv.org/abs/2506.15549)
**中文标题：CLAIM：基于临床引导的LGE增强技术实现真实多样的心肌瘢痕合成与分割**

*Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen,Chen*

主要分类: cs.CV

摘要简述: 本文提出CLAIM框架，通过临床引导的LGE增强技术合成多样且真实的瘢痕图像，并优化分割网络，显著提升瘢痕分割的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于深度学习的瘢痕分割方法受限于高质量标记的LGE图像稀缺和多样性不足，限制了模型的鲁棒性。CLAIM旨在通过合成多样且解剖学一致的瘢痕图像解决这一问题。

研究方法: CLAIM框架包含SMILE模块，利用临床知识（AHA 17段模型）指导扩散模型生成解剖学一致的瘢痕图像，并采用联合训练策略优化分割网络与生成器。

研究结果: 实验表明，CLAIM生成的瘢痕图像解剖学一致性高，与真实瘢痕分布的Dice相似性优于基线模型，显著提升下游医学影像任务的实用性。

研究结论: CLAIM实现了可控且真实的瘢痕合成，为医学影像分析提供了有效工具，同时提升了分割性能。

中文摘要: 基于深度学习的晚期钆增强（LGE）心脏MRI心肌瘢痕分割在准确诊断和治疗结构性心脏病方面展现出巨大潜力。然而，高质量标记的LGE图像稀缺且多样性不足，限制了鲁棒分割模型的发展。为此，我们提出CLAIM框架：一种基于临床引导的LGE增强技术，用于合成真实多样的心肌瘢痕并优化分割。其核心是SMILE模块（基于临床知识的瘢痕掩模生成），通过扩散模型结合AHA 17段模型生成解剖学一致且空间多样的瘢痕图像。此外，CLAIM采用联合训练策略，同步优化瘢痕分割网络与生成器，旨在提升合成瘢痕的真实性和分割准确性。实验结果表明，CLAIM生成的瘢痕图像解剖学一致性高，与真实瘢痕分布的Dice相似性优于基线模型。该方法实现了可控且真实的瘢痕合成，并验证了其在医学影像任务中的实用性。

</details>


### [102] [RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation](https://arxiv.org/abs/2506.15560)
**中文标题：RaCalNet：基于稀疏监督的雷达校准网络用于度量深度估计**

*Xingrui Qin,Wentao Zhao,Chuan Cao,Yihe Niu,Houcheng Jiang,Jingchuan Wang*

主要分类: cs.CV

摘要简述: RaCalNet是一种新型雷达校准网络，通过稀疏LiDAR监督学习优化雷达测量，仅需1%的监督密度即可实现高精度深度估计，超越现有密集监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统毫米波雷达深度估计依赖密集LiDAR监督，成本高且数据需求大。RaCalNet旨在通过稀疏监督实现高效且精确的深度估计。

研究方法: RaCalNet首先重新校准和优化稀疏雷达点以构建深度先验，随后利用这些先验作为可靠锚点指导单目深度预测，无需密集监督。

研究结果: 在ZJU-4DRadarCam数据集和实际场景中，RaCalNet显著优于现有密集监督方法，RMSE分别降低35.30%和34.89%，生成具有清晰轮廓和细节的深度图。

研究结论: RaCalNet通过稀疏监督实现了高效且高精度的深度估计，为雷达深度估计提供了一种低成本、高性能的解决方案。

中文摘要: 使用毫米波雷达进行密集度量深度估计通常需要密集的LiDAR监督，通过多帧投影和插值生成，以指导从稀疏雷达测量和RGB图像中学习准确深度。然而，这种模式成本高且数据密集。为此，我们提出RaCalNet，一种新颖的框架，通过使用稀疏LiDAR监督优化雷达测量学习，消除了对密集监督的需求，监督密度仅为密集监督方法的约1%。与之前将雷达点与广泛图像区域关联并严重依赖密集标签的方法不同，RaCalNet首先重新校准和优化稀疏雷达点以构建准确的深度先验。这些先验随后作为可靠锚点指导单目深度预测，无需依赖密集监督即可实现度量尺度估计。这种设计提高了结构一致性并保留了精细细节。尽管仅依赖稀疏监督，RaCalNet超越了最先进的密集监督方法，生成具有清晰物体轮廓和细粒度纹理的深度图。在ZJU-4DRadarCam数据集和实际部署场景中的大量实验证明了其有效性，分别将RMSE降低了35.30%和34.89%。

</details>


### [103] [Control and Realism: Best of Both Worlds in Layout-to-Image without Training](https://arxiv.org/abs/2506.15563)
**中文标题：控制与真实感：无需训练的布局到图像生成的最佳结合**

*Bonan Li,Yinhan Hu,Songhua Liu,Xinchao Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的布局到图像生成方法WinWinLay，通过非局部注意力能量函数和自适应更新策略，解决了现有方法在定位不准和图像不真实的问题，显著提升了控制精度和视觉逼真度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的布局到图像生成方法虽然无需训练即可实现，但存在定位不准和图像不真实的问题。本文旨在解决这些缺陷，提出一种无需训练的新方法，以同时提升控制精度和图像真实感。

研究方法: WinWinLay方法包含两个核心策略：1) 非局部注意力能量函数，通过重新分配注意力分数，使物体更符合布局指令；2) 基于朗之万动力学的自适应更新方案，避免偏离预训练域，同时满足布局约束。

研究结果: 实验表明，WinWinLay在控制元素布局和实现逼真视觉效果方面优于现有方法，显著提升了生成图像的质量和准确性。

研究结论: WinWinLay通过结合非局部注意力能量函数和自适应更新策略，成功实现了无需训练的布局到图像生成，在控制精度和视觉逼真度上均达到最优表现。

中文摘要: 布局到图像生成的目标是通过对主体位置和排列的精确控制来创建复杂场景。现有研究表明，预训练的文本到图像扩散模型无需特定数据训练即可实现这一目标，但常面临定位不准和不真实伪影的挑战。针对这些缺陷，我们提出了一种无需训练的新方法WinWinLay。其核心在于两种关键策略：非局部注意力能量函数和自适应更新，共同提升控制精度和真实感。一方面，我们理论证明了常用的注意力能量函数会引入固有的空间分布偏差，阻碍物体与布局指令的均匀对齐。为解决这一问题，我们探索了非局部注意力先验以重新分配注意力分数，使物体更符合指定的空间条件。另一方面，我们发现普通的反向传播更新规则可能导致偏离预训练域，产生分布外伪影。为此，我们引入了基于朗之万动力学的自适应更新方案，在尊重布局约束的同时促进域内更新。大量实验表明，WinWinLay在控制元素布局和实现逼真视觉效果方面表现出色，优于当前最先进的方法。

</details>


### [104] [Show-o2: Improved Native Unified Multimodal Models](https://arxiv.org/abs/2506.15564)
**中文标题：Show-o2：改进的原生统一多模态模型**

*Jinheng Xie,Zhenheng Yang,Mike Zheng Shou*

主要分类: cs.CV

摘要简述: 本文提出了一种改进的原生统一多模态模型Show-o2，结合自回归建模和流匹配技术，通过3D因果变分自编码器空间构建统一视觉表示，支持图像和视频的多模态理解与生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态模型在处理图像和视频等多样化模态时存在局限性，需要一种能够统一理解与生成多模态内容的模型。

研究方法: 基于语言模型，Show-o2采用自回归建模和流匹配技术，分别用于文本标记预测和图像/视频生成。通过双路径空间（时间）融合构建统一视觉表示，并设计两阶段训练方法以支持模型扩展。

研究结果: Show-o2模型在多种多模态理解与生成任务中表现出色，涵盖文本、图像和视频等多种模态。代码和模型已开源。

研究结论: Show-o2通过原生统一多模态建模，显著提升了多模态任务的性能，为未来多模态研究提供了有力工具。

中文摘要: 本文提出了改进的原生统一多模态模型Show-o2，利用自回归建模和流匹配技术。基于3D因果变分自编码器空间，通过空间（时间）融合的双路径构建统一视觉表示，支持图像和视频模态的扩展，同时确保有效的多模态理解与生成。基于语言模型，自回归建模和流匹配分别应用于语言头和流头，以促进文本标记预测和图像/视频生成。设计了两阶段训练方法以有效学习和扩展更大模型。Show-o2模型在多种多模态理解与生成任务中表现出广泛的适用性，涵盖文本、图像和视频等多样化模态。代码和模型发布于https://github.com/showlab/Show-o。

</details>


### [105] [Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification](https://arxiv.org/abs/2506.15565)
**中文标题：巴尔的摩图谱：用于半监督超高空间分辨率土地覆盖分类的FreqWeaver适配器**

*Junhao Wu,Aboagye-Ntow Stephen,Chuyuan Wang,Gang Chen,Xin Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种参数高效的半监督分割框架，用于0.3米超高空间分辨率影像，通过结合SAM2知识和遥感专用FreqWeaver适配器，显著提升细粒度细节建模能力，同时仅占用5.96%的模型参数。


<details>
  <summary>详细信息</summary>
研究动机: 超高空间分辨率土地覆盖分类对精细土地分析至关重要，但面临像素级标注成本高、尺度变化大以及大规模视觉模型适应性有限等挑战。现有方法多依赖标注数据且仅适用于1米分辨率影像，而实际应用常需在弱监督下处理更高分辨率影像。

研究方法: 提出了一种参数高效的半监督分割框架，结合SAM2知识并引入遥感专用FreqWeaver适配器，以增强细粒度细节建模能力，同时保持轻量化设计。

研究结果: 该方法通过有效利用未标注数据并保持低参数开销，实现了结构一致性优越的分割结果，比现有参数高效调优策略提升1.78%，比最先进高分辨率遥感分割方法提升3.44%。

研究结论: 该框架为超高分辨率遥感影像分割提供了一种高效且轻量化的解决方案，显著提升了细粒度分类性能。

中文摘要: 超高空间分辨率土地覆盖分类对精细土地分析至关重要，但由于像素级标注成本高、尺度变化显著以及大规模视觉模型适应性有限，该任务仍具挑战性。现有方法通常针对1米空间分辨率影像，且严重依赖标注数据，而实际应用常需在弱监督下处理更高分辨率影像。为此，我们提出了一种参数高效的半监督分割框架，适用于0.3米空间分辨率影像。该框架结合SAM2知识，并引入遥感专用FreqWeaver适配器，以增强细粒度细节建模能力，同时保持轻量化设计（仅占用总模型参数的5.96%）。通过有效利用未标注数据并保持低参数开销，所提方法实现了结构一致性优越的分割结果，比现有参数高效调优策略提升1.78%，比最先进高分辨率遥感分割方法提升3.44%。

</details>


### [106] [A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds](https://arxiv.org/abs/2506.15577)
**中文标题：基于图的统一框架：可扩展的3D树木重建与点云非破坏性生物量估算**

*Di Wang,Shi Li*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图的新型统一框架，用于从点云中实现端到端的3D树木重建和非破坏性生物量估算，显著提升了大规模森林生物量评估的可行性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 森林地上生物量（AGB）的准确估算对碳储存评估和可持续森林管理至关重要。现有的定量结构模型（QSM）方法依赖高质量点云数据且需复杂预处理，限制了其可扩展性和实际应用。本研究旨在解决这些问题，提出一种更高效、可扩展的解决方案。

研究方法: 通过创新的基于图的流程，将树木分割、叶木分离和3D骨架重建无缝集成。利用路径化和抽象化等图操作进行树木拓扑推理，实现端到端的大规模点云处理。

研究结果: 在多种数据集（包括不同叶况、空间尺度和数据来源）上验证，结果显示在叶茂条件下（约20%相对误差）和低密度无人机激光扫描（ULS）数据（约30%相对误差）中表现优异。

研究结论: 该框架为大规模非破坏性AGB估算提供了鲁棒且可扩展的解决方案，降低了对专业预处理工具的依赖，并确立了ULS作为TLS的可行替代方案。这一进展为森林调查和气候变化研究开辟了更广泛的应用前景。

中文摘要: 森林地上生物量（AGB）的估算对评估碳储存和支持可持续森林管理至关重要。定量结构模型（QSM）通过3D树木结构重建提供了一种非破坏性AGB估算方法。然而，现有QSM方法主要针对单株树木设计，依赖地面激光扫描（TLS）的高质量点云数据，且需多步预处理，限制了其可扩展性和实际应用。本研究提出了一种新型统一框架，利用基于图的创新流程实现大规模点云的端到端处理。该方法通过路径化和抽象化等图操作，无缝集成树木分割、叶木分离和3D骨架重建。在不同叶况（叶茂与叶落）、空间尺度（单株与样地）和数据来源（TLS与无人机激光扫描ULS）的数据集上进行了全面验证。实验结果表明，该方法在叶茂条件下（约20%相对误差）和低密度ULS部分覆盖数据（约30%相对误差）中表现优异。这些发现表明，该框架为大规模非破坏性AGB估算提供了鲁棒且可扩展的解决方案，显著减少了对专业预处理工具的依赖，并确立了ULS作为TLS的可行替代方案。据我们所知，这是首个能够在操作尺度上实现无缝端到端3D树木重建的方法。这一进展显著提升了基于QSM的AGB估算的可行性，为森林调查和气候变化研究的更广泛应用铺平了道路。

</details>


### [107] [One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution](https://arxiv.org/abs/2506.15591)
**中文标题：一步扩散实现细节丰富且时间一致的视频超分辨率**

*Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DLoRAL的双LoRA学习范式，通过结合跨帧检索模块和一致性学习，实现了在一步扩散模型中同时增强视频细节和保持时间一致性的目标。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于稳定扩散（SD）的真实视频超分辨率（Real-VSR）方法通常在空间细节和时间一致性之间做出妥协，导致视觉质量不佳。本文旨在解决如何从低质量视频中提取抗退化的时间一致性先验，并在增强细节的同时保持这些先验。

研究方法: 提出双LoRA学习（DLoRAL）范式，包括跨帧检索（CFR）模块和一致性-LoRA（C-LoRA）模块，用于提取时间一致性先验；随后训练细节-LoRA（D-LoRA）模块以增强空间细节，同时与C-LoRA定义的时间空间对齐。两阶段交替优化，最终合并LoRA分支以实现高效高质量的视频恢复。

研究结果: 实验表明，DLoRAL在准确性和速度上均表现出色，能够生成细节丰富且时间一致的视频超分辨率结果。

研究结论: DLoRAL通过双LoRA学习和跨帧检索模块，成功实现了在一步扩散模型中同时提升视频细节和时间一致性的目标，为真实视频超分辨率提供了高效且高质量的解决方案。

中文摘要: 在真实视频超分辨率（Real-VSR）中，如何在利用预训练生成模型（如稳定扩散）合成逼真细节的同时保持时间一致性是一个具有挑战性的问题。现有的基于SD的Real-VSR方法通常为了时间一致性而牺牲空间细节，导致视觉质量不佳。本文认为关键在于如何从低质量（LQ）输入视频中有效提取抗退化的时间一致性先验，并在增强视频细节的同时保持这些先验。为此，我们提出了一种双LoRA学习（DLoRAL）范式，训练一个基于SD的一步扩散模型，同时实现逼真的帧细节和时间一致性。具体而言，我们引入了跨帧检索（CFR）模块以聚合跨帧的互补信息，并训练一致性-LoRA（C-LoRA）从退化输入中学习鲁棒的时间表示。在一致性学习后，固定CFR和C-LoRA模块，训练细节-LoRA（D-LoRA）以增强空间细节，同时与C-LoRA定义的时间空间对齐以保持时间一致性。两阶段交替迭代优化，共同生成一致且细节丰富的输出。在推理阶段，两个LoRA分支被合并到SD模型中，实现高效且高质量的单步扩散视频恢复。实验表明，DLoRAL在准确性和速度上均表现出色。代码和模型可在https://github.com/yjsunnn/DLoRAL获取。

</details>


### [108] [Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration](https://arxiv.org/abs/2506.15596)
**中文标题：单模态化极端异质多模态医学图像配准**

*Kyobin Choo,Hyunkyung Han,Jinyeong Kim,Chanyong Yoon,Seong Jae Hwang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为M2M-Reg的新框架，用于解决多模态医学图像配准中因模态差异大而导致的配准困难问题。通过单模态相似性训练多模态配准模型，并结合GradCyCon正则化器，显著提升了配准效果。


<details>
  <summary>详细信息</summary>
研究动机: 在临床实践中，功能模态（如PET、FA）常需与结构模态（如MRI、CT）配准以进行准确分析。然而，由于模态间差异极大，传统无监督配准方法难以学习可靠的空间映射，导致图像失真。现有相似性度量无法有效捕捉高度差异模态间的对齐关系。

研究方法: 提出M2M-Reg框架，利用单模态相似性训练多模态配准模型，保留现有架构范式以便无缝集成。引入GradCyCon正则化器，利用循环训练方案促进微分同胚。此外，框架可扩展至半监督设置，仅需预对齐和未对齐图像对，无需真实变换或分割掩码。

研究结果: 在ADNI数据集上的实验表明，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法高出2倍，证明了其在处理高度异质多模态配准中的有效性。

研究结论: M2M-Reg通过单模态相似性训练多模态配准模型，解决了传统方法在高度异质模态配准中的局限性，显著提升了配准精度，为临床实践提供了更可靠的解决方案。

中文摘要: 在临床实践中，功能特性成像模态（如正电子发射断层扫描PET和分数各向异性FA）常需与结构参考（如MRI、CT）对齐以进行准确解释或群体分析，这需要多模态可变形图像配准（DIR）。然而，由于这些模态与标准结构扫描的极端异质性，传统的无监督DIR方法难以学习可靠的空间映射，并常导致图像失真。我们发现，指导这些模型的相似性度量无法捕捉高度差异模态间的对齐关系。为此，我们提出M2M-Reg（多到单配准），一种新颖框架，仅使用单模态相似性训练多模态DIR模型，同时保留现有架构范式以便无缝集成到现有模型中。我们还引入了GradCyCon，一种利用M2M-Reg循环训练方案促进微分同胚的正则化器。此外，我们的框架自然扩展到半监督设置，仅需预对齐和未对齐图像对，无需真实变换或分割掩码。在阿尔茨海默病神经影像学倡议（ADNI）数据集上的实验表明，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法高出2倍，突显了其在处理高度异质多模态DIR中的有效性。我们的代码可在https://github.com/MICV-yonsei/M2M-Reg获取。

</details>


### [109] [BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion](https://arxiv.org/abs/2506.15610)
**中文标题：BoxFusion：基于实时多视角框融合的无重建开放词汇3D目标检测**

*Yuqing Lan,Chenyang Zhu,Zhirui Gao,Jiazhao Zhang,Yihan Cao,Renjiao Yi,Yijie Wang,Kai Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种无需重建的实时多视角框融合方法BoxFusion，用于开放词汇3D目标检测，解决了现有方法依赖密集点云重建导致的高计算和内存开销问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有的开放词汇3D目标检测方法通常依赖于密集点云重建，导致计算和内存开销大，难以实时部署。本文旨在提出一种无需重建的实时框架，以高效实现3D目标检测。

研究方法: 方法利用预训练的视觉基础模型Cubify Anything进行单视角3D目标检测，结合CLIP捕获开放词汇语义。通过关联模块和优化模块，将多视角检测的边界框融合为统一的3D边界框，其中关联模块使用3D NMS和框匹配，优化模块采用基于粒子滤波的IoU引导随机优化技术。

研究结果: 在ScanNetV2和CA-1M数据集上的实验表明，该方法在在线方法中达到了最先进的性能，并展示了在超过1000平方米环境中的实时感知能力。

研究结论: 本文提出的无需重建的3D目标检测框架具有高效性和泛化能力，适用于多种场景，实现了实时感知。

中文摘要: 开放词汇3D目标检测因其在自动驾驶和具身AI中的关键应用而受到广泛关注。现有的检测方法（无论是离线还是在线）通常依赖于密集点云重建，这带来了巨大的计算开销和内存限制，阻碍了在下游任务中的实时部署。为解决这一问题，我们提出了一种新颖的无重建在线框架，专为内存高效和实时的3D检测而设计。具体而言，给定流式姿态RGB-D视频输入，我们利用预训练的视觉基础模型Cubify Anything进行单视角3D目标检测（通过边界框），并结合CLIP捕获检测对象的开放词汇语义。为了将不同视角检测到的边界框融合为一个统一的边界框，我们采用了一个关联模块用于多视角对应关系，以及一个优化模块用于融合多视角预测的同一实例的3D边界框。关联模块使用3D非极大值抑制（NMS）和框对应匹配模块，而优化模块则采用基于粒子滤波的IoU引导高效随机优化技术，以在最小化计算复杂度的同时强制多视角3D边界框的一致性。在ScanNetV2和CA-1M数据集上的大量实验表明，我们的方法在在线方法中达到了最先进的性能。得益于这种新颖的无重建3D目标检测范式，我们的方法在多种场景中表现出强大的泛化能力，即使在超过1000平方米的环境中也能实现实时感知。

</details>


### [110] [HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization](https://arxiv.org/abs/2506.15625)
**中文标题：HOIDiNi：通过扩散噪声优化实现人-物交互**

*Roey Ron,Guy Tevet,Haim Sawdayee,Amit H. Bermano*

主要分类: cs.CV

摘要简述: HOIDiNi是一种基于扩散噪声优化的文本驱动框架，用于生成逼真且合理的人-物交互（HOI）。通过将问题分解为物体中心阶段和人体中心阶段，该方法在保持运动自然性的同时实现了精确的手-物接触，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 人-物交互（HOI）生成在保持接触精度和运动多样性方面极具挑战性。现有方法往往在逼真性和物理正确性之间权衡，而HOIDiNi旨在通过扩散噪声优化（DNO）同时实现两者。

研究方法: HOIDiNi采用两阶段方法：物体中心阶段主要选择手-物接触位置，人体中心阶段则优化全身运动以实现这一蓝图。通过在预训练扩散模型的噪声空间中进行优化，结合文本驱动，生成逼真的交互。

研究结果: 在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触精度、物理有效性和整体质量上优于现有方法，能够生成复杂的可控交互（如抓取、放置和全身协调）。

研究结论: HOIDiNi通过结构化两阶段优化和扩散噪声技术，成功实现了逼真且物理正确的人-物交互生成，为文本驱动的复杂交互合成提供了新思路。

中文摘要: 我们提出了HOIDiNi，一种基于文本驱动的扩散框架，用于合成逼真且合理的人-物交互（HOI）。HOI生成极具挑战性，因为它需要严格的接触精度和多样的运动流形。现有方法在逼真性和物理正确性之间权衡，而HOIDiNi通过扩散噪声优化（DNO）直接在预训练扩散模型的噪声空间中优化，同时实现两者。这得益于我们将问题分解为两阶段：物体中心阶段主要选择手-物接触位置，人体中心阶段优化全身运动以实现这一蓝图。这种结构化方法在不牺牲运动自然性的前提下实现了精确的手-物接触。在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触精度、物理有效性和整体质量上显著优于现有方法。我们的结果表明，仅通过文本提示即可生成复杂的可控交互，包括抓取、放置和全身协调。

</details>


### [111] [FindingDory: A Benchmark to Evaluate Memory in Embodied Agents](https://arxiv.org/abs/2506.15635)
**中文标题：FindingDory：一种评估具身智能体记忆能力的基准测试**

*Karmesh Yadav,Yusuf Ali,Gunshi Gupta,Yarin Gal,Zsolt Kira*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FindingDory的新基准测试，用于评估具身智能体在长期记忆任务中的表现，填补了现有长视频问答基准在具身任务中的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大规模视觉语言模型在规划和控制任务中表现优异，但在具身环境中处理长期记忆时存在局限性。现有基准测试未涵盖具身任务（如物体操作和导航）中的低层次技能和细粒度推理需求，亟需一种专门评估长期记忆的基准。

研究方法: 研究在Habitat模拟器中设计了一个包含60项任务的基准测试，这些任务需要持续的上下文感知和记忆能力。任务可通过程序化扩展为更复杂版本，以支持对记忆和推理能力的可扩展评估。同时，研究整合了先进视觉语言模型与低层次导航策略，作为基线评估模型表现。

研究结果: 基准测试成功评估了具身智能体在长期记忆任务中的表现，并揭示了当前视觉语言模型在记忆密集型任务中的不足，为未来改进提供了方向。

研究结论: FindingDory基准为具身智能体的长期记忆能力提供了标准化评估工具，填补了现有研究的空白，并推动了具身智能领域的发展。

中文摘要: 大规模视觉语言模型在规划和控制任务中表现出色，但其在具身环境中的长期记忆能力受限。现有视觉语言模型通常难以同时处理数百张图像，亟需更高效的长期记忆机制。现有长视频问答基准未涵盖具身任务（如物体操作和导航）所需的低层次技能和细粒度推理。本研究在Habitat模拟器中引入了一个新的长期具身任务基准，评估了60项需要持续上下文感知和记忆能力的任务。这些任务可通过程序化扩展为更复杂版本，支持对记忆和推理能力的可扩展评估。研究还整合了先进视觉语言模型与低层次导航策略作为基线，评估了其在记忆密集型任务中的表现，并指出了改进方向。

</details>


### [112] [Demystifying the Visual Quality Paradox in Multimodal Large Language Models](https://arxiv.org/abs/2506.15645)
**中文标题：揭秘多模态大语言模型中的视觉质量悖论**

*Shuo Xing,Lanqing Guo,Hongyuan Hua,Seoyoung Lee,Peiran Li,Yufei Wang,Zhangyang Wang,Zhengzhong Tu*

主要分类: cs.CV

摘要简述: 研究发现多模态大语言模型（MLLMs）在视觉质量上存在悖论：图像质量偏离人类感知的真实性时，模型性能反而提升。为此，作者提出了一种轻量级适配模块VQ-TTT，动态调整输入图像以匹配任务需求，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在视觉语言任务中表现优异，但输入图像质量如何影响其响应尚不明确。作者旨在探究图像感知质量与模型理解之间的关系，并解决模型对非人类偏好视觉质量的依赖问题。

研究方法: 作者通过系统研究，对图像施加可控的降质和风格变化，发现MLLMs存在视觉质量悖论。为解决这一问题，提出了VQ-TTT模块：在冻结的视觉编码器前插入可学习的低秩核以调整频率内容，并通过LoRA微调浅层视觉编码器，动态适配输入图像。

研究结果: 实验表明，VQ-TTT显著提升了所有测试MLLMs和数据集的平均准确率，且无需外部模型、缓存特征或额外训练数据。

研究结论: 研究揭示了MLLMs对视觉质量的独特偏好，挑战了传统“更清晰即更好”的认知，并提出了自适应图像调整的必要性，为AI作为主要数据消费者的新时代提供了新视角。

中文摘要: 近期多模态大语言模型（MLLMs）在视觉语言任务基准上表现优异，但输入图像质量如何影响其响应尚不明确。更高的图像感知质量是否直接转化为更好的MLLM理解？我们首次对领先的MLLMs和一系列视觉语言基准进行了系统研究，对每张图像施加了可控的降质和风格变化。令人惊讶的是，我们发现了一个视觉质量悖论：当图像偏离人类感知的真实性时，模型、任务甚至单个实例的性能反而会提升。现成的修复流程无法调和这些独特偏好。为弥合这一差距，我们提出了视觉质量测试时调优（VQ-TTT）——一种轻量级适配模块：（1）在冻结的视觉编码器前插入可学习的低秩核以调整频率内容；（2）通过LoRA仅微调浅层视觉编码器。VQ-TTT在单次前向传播中动态调整每张输入图像，使其与任务特定的模型偏好对齐。在所有测试的MLLMs和数据集中，VQ-TTT显著提升了平均准确率，且无需外部模型、缓存特征或额外训练数据。这些发现重新定义了MLLMs的“更好”视觉输入，并强调了在新一代AI作为主要数据消费者的时代，需要自适应而非普遍“干净”的图像。

</details>


### [113] [Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning](https://arxiv.org/abs/2506.15649)
**中文标题：基于边缘奖励调整的双阶段价值引导推理：实现快速且可靠的视觉语言模型字幕生成**

*Ankan Deria,Adinath Madhavrao Dukre,Feilong Tang,Sara Atito,Sudipta Roy,Muhammad Awais,Muhammad Haris Khan,Imran Razzak*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViMaR的双阶段推理框架，通过结合时间差分价值模型和边缘感知奖励调整，显著提升了视觉语言模型（VLM）生成字幕的效率和准确性，同时减少了低置信度生成和幻觉问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型推理方法计算成本高且容易生成低置信度的内容，导致持续的幻觉问题。本文旨在提出一种高效且可靠的推理框架，以提升生成字幕的质量和速度。

研究方法: ViMaR采用双阶段推理框架：第一阶段通过单次遍历从多样候选字幕中选出最高价值的内容；第二阶段仅对视觉基础薄弱或被忽略的片段进行选择性优化，并通过边缘感知惩罚机制抑制低置信度生成。

研究结果: 实验表明，ViMaR生成的字幕在可靠性、事实准确性、细节丰富性和解释性方面显著优于现有方法，同时实现了4倍以上的速度提升。此外，ViMaR在跨模型指导中表现出色，能够有效提升未见模型的生成质量。

研究结论: ViMaR不仅是一种高效且可扩展的推理时解码策略，还能通过自训练显著提升视觉理解任务的性能，展示了快速、准确且自我改进的VLM管道的潜力。

中文摘要: 尽管视觉语言模型（VLM）在推理时搜索方面取得了显著进展，但现有方法仍然计算成本高昂，且容易生成未受惩罚的低置信度内容，导致持续的幻觉问题。我们提出了\textbf{基于边缘奖励的价值引导推理（ViMaR）}，这是一种双阶段推理框架，通过结合时间差分价值模型和边缘感知奖励调整，显著提升了效率和输出保真度。在第一阶段，我们通过单次遍历从多样候选字幕中选出最高价值的内容；在第二阶段，我们仅对视觉基础薄弱或被忽略的片段进行选择性优化，从而消除频繁奖励的评估。通过校准的边缘惩罚机制，抑制低置信度生成的同时保留了描述的丰富性。在多种VLM架构上的广泛实验表明，ViMaR生成的字幕在可靠性、事实准确性、细节丰富性和解释性方面显著优于现有方法，同时实现了4倍以上的速度提升。特别地，我们展示了仅基于LLaVA Mistral-7B训练的ViMaR能够有效指导未见模型的解码。为进一步验证这一点，我们将ViMaR应用于LLaVA-OneVision-Qwen2-7B的生成引导，结果显示字幕质量持续提升，证明了其跨模型指导的鲁棒性。这种跨模型泛化能力凸显了ViMaR的灵活性和模块化，使其成为一种可扩展且可迁移的推理时解码策略。此外，当ViMaR生成的字幕用于自训练时，底层模型在广泛的视觉理解基准测试中取得了显著提升，进一步验证了快速、准确且自我改进的VLM管道的潜力。

</details>


### [114] [UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting](https://arxiv.org/abs/2506.15673)
**中文标题：UniRelight：学习联合分解与合成以实现视频重光照**

*Kai He,Ruofan Liang,Jacob Munkberg,Jon Hasselgren,Nandita Vijaykumar,Alexander Keller,Sanja Fidler,Igor Gilitschenski,Zan Gojcic,Zian Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为UniRelight的方法，通过联合估计反照率并合成重光照视频，利用视频扩散模型的生成能力，显著提升了光照效果的真实性和时间一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有端到端重光照模型因缺乏成对多光照数据而泛化能力受限，而两阶段流水线则易受误差累积影响且难以处理复杂光照或材质。本文旨在解决这些问题，提出一种更通用的方法。

研究方法: UniRelight采用联合估计反照率和合成重光照输出的单阶段方法，结合视频扩散模型的生成能力，并利用合成多光照数据和自动标注的真实视频进行训练。

研究结果: 实验表明，该方法在多样场景中表现出强大的泛化能力，在视觉真实性和时间一致性上均优于现有方法。

研究结论: UniRelight通过联合分解与合成，显著提升了重光照任务的性能，为复杂光照和材质交互提供了更真实的解决方案。

中文摘要: 我们解决了单幅图像或视频的重光照问题，这一任务需要精确的场景内在理解和高品质的光传输合成。现有的端到端重光照模型常因缺乏成对多光照数据而泛化能力受限，而结合逆向与正向渲染的两阶段流水线虽能缓解数据需求，但易受误差累积影响，且在复杂光照或高级材质下难以生成真实输出。本文提出了一种通用方法，通过联合估计反照率并在单次处理中合成重光照输出，利用视频扩散模型的生成能力。这种联合形式增强了隐含场景理解，并促进了真实光照效果（如阴影、反射和透明）与复杂材质交互的生成。通过在合成多光照数据和大量自动标注的真实视频上训练，我们的模型在多样领域中表现出强大的泛化能力，并在视觉真实性和时间一致性上超越了现有方法。

</details>


### [115] [Sekai: A Video Dataset towards World Exploration](https://arxiv.org/abs/2506.15675)
**中文标题：Sekai：面向世界探索的视频数据集**

*Zhen Li,Chuanhao Li,Xiaofeng Mao,Shaoheng Lin,Ming Li,Shitian Zhao,Zhaopan Xu,Xinyue Li,Yukang Feng,Jianwen Sun,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Zhixiang Wang,Yuwei Wu,Tong He,Jiangmiao Pang,Yu Qiao,Yunde Jia,Kaipeng Zhang*

主要分类: cs.CV

摘要简述: 本文介绍了Sekai数据集，一个高质量的第一人称视角全球视频数据集，旨在支持世界探索任务。数据集包含5000多小时来自100多个国家和地区的视频，并附有丰富注释。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频生成数据集因地点有限、时长短、场景静态且缺乏探索相关注释，不适合世界探索任务。因此，作者提出Sekai数据集以填补这一空白。

研究方法: 作者收集了来自750个城市的5000多小时第一人称视角（步行和无人机）视频，并开发了高效工具进行预处理和注释，包括位置、场景、天气等信息。

研究结果: 实验验证了数据集的质量，并利用其子集训练了名为YUME的交互式视频世界探索模型。

研究结论: Sekai数据集将为视频生成和世界探索领域带来重要价值，并推动相关应用的发展。

中文摘要: 视频生成技术已取得显著进展，有望成为交互式世界探索的基础。然而，现有视频生成数据集因地点有限、时长短、场景静态且缺乏探索和世界相关注释，不适合世界探索训练。本文介绍了Sekai（日语中意为“世界”），一个高质量的第一人称视角全球视频数据集，包含丰富的世界探索注释。数据集包括来自100多个国家和地区、750个城市的5000多小时步行或无人机视角（FPV和UVA）视频。我们开发了高效的工具箱，用于收集、预处理和注释视频，包括位置、场景、天气、人群密度、字幕和相机轨迹等信息。实验验证了数据集的质量，并利用其子集训练了名为YUME（日语中意为“梦想”）的交互式视频世界探索模型。我们相信Sekai将推动视频生成和世界探索领域的发展，并激发有价值的应用。

</details>


### [116] [Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model](https://arxiv.org/abs/2506.15682)
**中文标题：进化缓存加速现成扩散模型**

*Anirud Aggarwal,Abhinav Shrivastava,Matthew Gwilliam*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ECAD的遗传算法，通过学习高效的缓存调度策略，显著加速扩散模型的推理速度，同时保持生成质量，适用于多种模型和分辨率。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成高质量图像方面表现出色，但推理速度慢且计算成本高。现有方法依赖固定启发式规则，导致加速效果有限或泛化能力不足。本文旨在解决这一问题。

研究方法: ECAD是一种遗传算法，通过少量校准提示学习每个模型的高效缓存调度策略，形成帕累托前沿。该方法无需修改网络参数或参考图像，支持细粒度的质量-延迟权衡控制。

研究结果: 在PixArt-alpha、PixArt-Sigma和FLUX-1.dev等模型上，ECAD显著提升了推理速度（如PixArt-alpha从2.35倍提升至2.58倍），并在COCO FID等指标上优于现有方法（提升4.47分）。

研究结论: ECAD是一种可扩展且泛化能力强的扩散模型加速方法，适用于未见过的分辨率和模型变体，为实际应用提供了高效解决方案。

中文摘要: 基于扩散的图像生成模型在生成高质量合成内容方面表现出色，但推理速度慢且计算成本高。先前的研究尝试通过在扩散变换器中缓存和重用特征来缓解这一问题，但这些方法通常依赖固定启发式规则，导致加速效果有限或泛化能力不足。我们提出了进化缓存加速扩散模型（ECAD），这是一种遗传算法，仅使用少量校准提示即可学习高效的、针对特定模型的缓存调度策略，形成帕累托前沿。ECAD无需修改网络参数或参考图像，可显著提升推理速度，支持细粒度的质量-延迟权衡控制，并能够无缝适应不同的扩散模型。值得注意的是，ECAD学习的调度策略能够有效泛化到校准过程中未见的分辨率和模型变体。我们在PixArt-alpha、PixArt-Sigma和FLUX-1.dev上评估了ECAD，使用多种指标（FID、CLIP、Image Reward）和多样化基准（COCO、MJHQ-30k、PartiPrompts），结果表明ECAD在性能上优于现有方法。在PixArt-alpha上，ECAD找到的调度策略在COCO FID上优于先前最先进方法4.47分，同时将推理速度从2.35倍提升至2.58倍。我们的研究结果表明，ECAD是一种可扩展且泛化能力强的扩散模型加速方法。项目网站和代码已公开。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [117] [CALM: Contextual Analog Logic with Multimodality](https://arxiv.org/abs/2506.14936)
**中文标题：CALM：基于多模态的上下文模拟逻辑**

*Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue*

主要分类: cs.AI

摘要简述: CALM是一种结合符号逻辑与神经生成的方法，通过多模态数据实现上下文敏感的决策，填补了逻辑推理与神经感知之间的鸿沟。


<details>
  <summary>详细信息</summary>
研究动机: 传统二值逻辑系统无法捕捉人类决策的细微差别，且在多模态环境中需要人工干预，显得僵化且脆弱。神经网络虽能提取多模态数据的丰富信息，但缺乏可解释的推理结构。CALM旨在结合逻辑与神经感知，实现多模态输入的推理。

研究方法: CALM通过领域树表示每个谓词，利用神经网络迭代优化其模拟真值，并通过符号推理模块确保约束满足。

研究结果: 在填空式物体放置任务中，CALM准确率达92.2%，优于传统逻辑（86.3%）和LLM（59.4%），并能生成符合逻辑约束和人类偏好的空间热图。

研究结论: CALM展示了在多模态环境中结合逻辑结构与偏好的潜力，为下一代需要逻辑精确性和神经网络多模态处理能力的AI系统奠定了基础。

中文摘要: 本文介绍了基于多模态的上下文模拟逻辑（CALM）。CALM将符号推理与神经生成相结合，使系统能够基于真实世界的多模态数据做出上下文敏感的决策。背景：经典二值逻辑系统无法捕捉人类决策的细微差别，且在多模态环境中需要人工干预，显得僵化且脆弱。神经网络虽擅长从多模态数据中提取丰富的上下文信息，但缺乏可解释的推理结构。目标：CALM旨在填补逻辑与神经感知之间的鸿沟，创建一种能够对多模态输入进行推理的模拟逻辑。方法：CALM通过领域树表示每个谓词，利用神经网络迭代优化其模拟真值，并通过符号推理模块确保约束满足。结果：在填空式物体放置任务中，CALM准确率达92.2%，优于传统逻辑（86.3%）和LLM（59.4%），并能生成符合逻辑约束和人类偏好的空间热图。结论：CALM展示了在多模态环境中结合逻辑结构与偏好的潜力，为下一代AI系统奠定了基础。

</details>


### [118] [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.14990)
**中文标题：MEAL：持续多智能体强化学习的基准测试**

*Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy*

主要分类: cs.AI

摘要简述: MEAL是首个专为持续多智能体强化学习（CMARL）设计的基准测试，利用JAX实现GPU加速，支持在普通台式机上快速运行100个任务序列。研究发现，简单结合现有CL和MARL方法在复杂环境中表现不佳，需改进架构和算法。


<details>
  <summary>详细信息</summary>
研究动机: 现有持续学习（CL）基准测试主要在CPU上运行，计算效率低且任务序列长度受限，而多智能体协作环境中的CL研究尤为不足。为此，作者提出MEAL，填补这一空白并提升计算效率。

研究方法: MEAL基于JAX实现GPU加速，支持在普通台式机上高效运行100个任务序列。通过实验验证了现有CL和MARL方法在简单环境中的表现，并分析了复杂环境中所需的架构和算法改进。

研究结果: 研究发现，简单结合CL和MARL方法在简单环境中表现良好，但在需要持续协调和适应的复杂环境中效果不佳。消融实验揭示了CMARL中关键的架构和算法特征。

研究结论: MEAL为持续多智能体强化学习提供了首个高效基准测试，揭示了现有方法的局限性，并指出了未来改进方向。

中文摘要: 基准测试在强化学习（RL）算法的开发和分析中至关重要，而环境的可用性对研究影响显著。持续学习（CL）在多智能体协作环境中的研究尤为不足。为此，我们提出了MEAL（多智能体自适应学习环境），这是首个专为持续多智能体强化学习（CMARL）设计的基准测试。现有CL基准测试主要在CPU上运行，导致计算瓶颈并限制了任务序列的长度。MEAL利用JAX实现GPU加速，可在普通台式机上几小时内完成100个任务序列的持续学习。研究发现，简单结合流行的CL和MARL方法在简单环境中表现良好，但在需要持续协调和适应的复杂环境中效果不佳。我们的消融实验揭示了MEAL上CMARL的关键架构和算法特征。

</details>


### [119] [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050)
**中文标题：截断近端策略优化**

*Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu*

主要分类: cs.AI

摘要简述: 本文提出了一种名为截断近端策略优化（T-PPO）的新方法，旨在提高大型语言模型（LLM）在长链推理任务中的训练效率。通过优化策略更新和限制生成长度，T-PPO显著减少了硬件闲置时间，并引入扩展广义优势估计（EGAE）和独立优化机制，最终在AIME 2024实验中实现了2.5倍的效率提升。


<details>
  <summary>详细信息</summary>
研究动机: 近端策略优化（PPO）及其变体在训练大型语言模型的推理能力中表现优异，但由于其同步长生成过程的特性，硬件利用率低且训练耗时。本文旨在解决这一问题，提出一种更高效的训练方法。

研究方法: 1. 提出扩展广义优势估计（EGAE），从不完整响应中估计优势值，确保策略学习的完整性。2. 设计一种计算优化机制，独立优化策略和价值模型，通过选择性过滤提示和截断标记减少冗余计算。

研究结果: 在AIME 2024实验中，T-PPO将推理型大型语言模型的训练效率提升了2.5倍，且性能优于现有方法。

研究结论: T-PPO通过优化策略更新和生成长度限制，显著提高了训练效率，同时保持了收敛性能，为大型语言模型的推理任务提供了一种高效解决方案。

中文摘要: 近期，测试时扩展的大型语言模型（LLM）通过生成长链推理（CoT）在科学和专业任务中展现出卓越的推理能力。作为开发这些推理模型的关键组件，强化学习（RL）以近端策略优化（PPO）及其变体为代表，使模型能够通过试错学习。然而，PPO由于其固有的在线策略特性，训练耗时较长，且随着响应长度的增加，这一问题进一步加剧。本文提出截断近端策略优化（T-PPO），一种PPO的新扩展方法，通过优化策略更新和限制生成长度提高训练效率。T-PPO解决了硬件利用率低的问题，这是完全同步长生成过程的固有缺陷，其中资源在等待完整生成时经常闲置。我们的贡献包括：1. 提出扩展广义优势估计（EGAE），从不完整响应中估计优势值，同时保持策略学习的完整性；2. 设计一种计算优化机制，允许独立优化策略和价值模型。通过选择性过滤提示和截断标记，该机制减少了冗余计算，在不影响收敛性能的情况下加速训练过程。我们在AIME 2024上使用32B基础模型验证了T-PPO的有效性和高效性。实验结果表明，T-PPO将推理型LLM的训练效率提升了2.5倍，并优于现有竞争对手。

</details>


### [120] [HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges](https://arxiv.org/abs/2506.15196)
**中文标题：HeurAgenix：利用大型语言模型解决复杂组合优化挑战**

*Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian*

主要分类: cs.AI

摘要简述: HeurAgenix是一种基于大型语言模型（LLM）的两阶段超启发式框架，通过进化启发式策略并动态选择最优策略，显著提升组合优化问题的求解性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统启发式算法依赖人工设计且难以泛化，而LLM在解决复杂问题时表现出潜力。HeurAgenix旨在利用LLM的感知和推理能力，自动生成和选择启发式策略，以解决组合优化问题。

研究方法: HeurAgenix分为两阶段：1）启发式进化阶段，利用LLM比较种子解与高质量解，提取可复用的进化策略；2）问题求解阶段，动态选择最优启发式策略，支持使用高性能LLM或轻量级微调模型。为缓解监督信号不足的问题，采用双奖励机制微调选择器。

研究结果: 在经典基准测试中，HeurAgenix不仅优于现有基于LLM的超启发式方法，还达到或超越专用求解器的性能。

研究结论: HeurAgenix展示了LLM在组合优化中的潜力，通过自动生成和选择启发式策略，显著提升了求解效率和泛化能力。

中文摘要: 启发式算法在解决组合优化（CO）问题中至关重要，但传统设计依赖人工经验且难以泛化。我们提出HeurAgenix，一种基于大型语言模型（LLM）的两阶段超启发式框架，首先生成启发式策略，随后自动选择最优策略。在启发式进化阶段，HeurAgenix利用LLM比较种子解与高质量解，提取可复用的进化策略。在问题求解阶段，动态选择最适合当前状态的启发式策略，选择器可以是高性能LLM或低推理成本的轻量级微调模型。为缓解CO复杂性导致的监督信号不足问题，采用双奖励机制微调选择器，结合选择偏好和状态感知信号实现鲁棒选择。在经典基准测试中，HeurAgenix不仅优于现有基于LLM的超启发式方法，还达到或超越专用求解器的性能。代码发布于https://github.com/microsoft/HeurAgenix。

</details>


### [121] [Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study](https://arxiv.org/abs/2506.15207)
**中文标题：多智能体强化学习在自主多卫星地球观测中的应用：一个真实案例研究**

*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk*

主要分类: cs.AI

摘要简述: 本文研究了多智能体强化学习（MARL）在自主多卫星地球观测任务中的应用，通过模拟真实卫星环境，评估了多种MARL算法的性能，结果表明MARL能有效平衡成像与资源管理，为分散式卫星任务提供实用指导。


<details>
  <summary>详细信息</summary>
研究动机: 随着低地球轨道卫星数量的激增，地球观测任务面临实时决策和动态协调的挑战，传统优化方法难以应对，因此需要探索强化学习和多智能体强化学习的应用潜力。

研究方法: 研究通过模拟单卫星操作并扩展至多卫星星座，采用PPO、IPPO、MAPPO和HAPPO等MARL算法，解决能源与数据存储限制、观测不确定性及分散协调等关键问题。

研究结果: 实验表明，MARL能有效平衡成像任务与资源管理，同时解决多卫星协调中的非平稳性和奖励依赖性问题。

研究结论: 本研究为自主卫星操作提供了理论基础和实践指南，证明了MARL在分散式地球观测任务中的潜力。

中文摘要: 低地球轨道（LEO）卫星的指数级增长彻底改变了地球观测（EO）任务，解决了气候监测、灾害管理等领域的挑战。然而，多卫星系统的自主协调仍是一个基本难题。传统优化方法难以应对动态EO任务的实时决策需求，因此需要利用强化学习（RL）和多智能体强化学习（MARL）。本文通过模拟单卫星操作并扩展至多卫星星座，研究了基于RL的自主EO任务规划。我们解决了能源与数据存储限制、卫星观测不确定性以及部分可观测性下的分散协调复杂性等关键问题。通过利用接近真实的卫星模拟环境，我们评估了PPO、IPPO、MAPPO和HAPPO等先进MARL算法的训练稳定性和性能。结果表明，MARL能有效平衡成像与资源管理，同时解决多卫星协调中的非平稳性和奖励依赖性问题。本研究为自主卫星操作奠定了基础，为改进分散式EO任务中的策略学习提供了实用指导。

</details>


### [122] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
**中文标题：基于无人机与船舶协作的不确定海上MEC联合计算卸载与资源分配**

*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

主要分类: cs.AI

摘要简述: 本文提出了一种基于无人机和船舶协作的海上边缘计算框架，通过Lyapunov优化和马尔可夫博弈解决不确定任务的计算卸载和资源分配问题，有效降低了总执行时间。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，海上物联网（MIoT）的计算需求快速增长，而基于无人机和船舶的多接入边缘计算（MEC）可以满足这些需求。然而，不确定的海上任务带来了计算卸载和资源分配效率低下的挑战。

研究方法: 提出了一种协作MEC框架，结合Lyapunov优化处理任务不确定性和资源变化，将长期约束转化为短期约束，并通过马尔可夫博弈和异构智能体软演员-评论家算法解决优化问题。

研究结果: 仿真实验验证了所提框架在计算卸载和资源分配方面的有效性，显著降低了总执行时间。

研究结论: 通过无人机和船舶的协作，结合Lyapunov优化和马尔可夫博弈，本文提出的方法能够高效处理海上不确定任务的计算卸载和资源分配问题。

中文摘要: 近年来，海上物联网（MIoT）的计算需求迅速增长，而基于无人机（UAVs）和船舶的多接入边缘计算（MEC）可以满足这些MIoT需求。然而，不确定的海上任务带来了计算卸载和资源分配效率低下的挑战。本文通过无人机和船舶的协作，研究了考虑不确定任务的海上计算卸载和资源分配问题。具体而言，我们提出了一种协作MEC框架，包括MIoT设备、无人机和船舶，并构建了以最小化总执行时间为目标的优化问题。针对不确定的MIoT任务，我们利用Lyapunov优化处理不可预测的任务到达和计算资源变化，将长期约束转化为短期约束，得到一组小规模优化问题。进一步，考虑到无人机和船舶动作与资源的异构性，我们将小规模优化问题重新表述为马尔可夫博弈（MG），并提出了一种异构智能体软演员-评论家算法，通过顺序更新多个神经网络有效解决MG问题。最后，仿真实验验证了所提方法在计算卸载和资源分配方面的有效性。

</details>


### [123] [Efficient and Generalizable Environmental Understanding for Visual Navigation](https://arxiv.org/abs/2506.15377)
**中文标题：高效且可泛化的视觉导航环境理解方法**

*Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao*

主要分类: cs.AI

摘要简述: 本文提出了一种基于因果关系的视觉导航方法（CAN），通过引入因果理解模块提升智能体对环境理解的能力，实验表明该方法在多种任务和模拟环境中优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉导航方法通常同时处理所有历史观测数据，忽略了数据内部的关联结构，限制了任务性能的进一步提升。本文从因果关系的角度分析导航任务的特点，提出改进方案。

研究方法: 本文提出Causality-Aware Navigation（CAN），通过引入因果理解模块（Causal Understanding Module）增强智能体对环境理解的建模能力，同时无需额外计算开销。

研究结果: 实验结果表明，CAN在多种任务和模拟环境中均优于基线方法，且因果理解模块在强化学习和监督学习场景中均表现出良好的泛化能力。

研究结论: 通过因果关系的视角改进视觉导航任务，CAN方法显著提升了智能体的环境理解能力，为未来研究提供了新的思路。

中文摘要: 视觉导航是具身智能中的核心任务，使智能体能够在复杂环境中导航以实现给定目标。在导航任务中，许多场景需要对历史时序数据进行建模。现有方法虽然表现良好，但通常同时处理所有历史观测数据，忽略了数据内部的关联结构，这可能限制了任务性能的进一步提升。本文从因果关系的角度分析导航任务的独特特性，引入因果框架以揭示传统时序方法的局限性。基于这一洞察，我们提出了因果感知导航（CAN），通过引入因果理解模块增强智能体的环境理解能力。实验评估表明，我们的方法在多种任务和模拟环境中均优于基线模型。大量消融实验证明，因果理解模块在强化学习和监督学习场景中均能有效泛化，且无需额外计算开销。

</details>


### [124] [Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](https://arxiv.org/abs/2506.15567)
**中文标题：基于LLM的推理与行动代理管理复杂失效分析工作流**

*Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大语言模型（LLM）的规划代理（LPA），用于管理复杂的失效分析工作流，通过整合AI组件和外部工具，实现自动化任务处理和高效工作流协调。


<details>
  <summary>详细信息</summary>
研究动机: 失效分析（FA）是一个高度复杂且知识密集的过程，随着AI模型的增多，如何协调这些组件以形成高效的工作流成为挑战。本文旨在通过LLM-based规划代理解决这一问题。

研究方法: 设计并实现了一种基于大语言模型的规划代理（LPA），结合高级规划能力和外部工具使用，能够自主处理复杂查询、从外部系统检索相关数据并生成易读的响应。

研究结果: 评估结果表明，LPA在支持失效分析任务方面具有操作有效性和可靠性，能够显著提升工作流效率。

研究结论: 基于LLM的规划代理为失效分析提供了一种高效、可靠的解决方案，能够有效整合AI组件并优化工作流。

中文摘要: 失效分析（FA）是一个高度复杂且知识密集的过程。在FA实验室的计算基础设施中集成AI组件，可以自动化多种任务，包括图像中非一致性的检测、从多样化数据源中检索类似案例，以及从标注图像生成报告。然而，随着部署的AI模型数量增加，如何将这些组件协调为与FA过程无缝集成的高效工作流成为挑战。本文研究了一种基于大语言模型（LLM）的规划代理（LPA）的设计与实现，以协助FA工程师解决分析案例。LPA将LLM与高级规划能力和外部工具使用相结合，能够自主处理复杂查询、从外部系统检索相关数据并生成人类可读的响应。评估结果证明了该代理在支持FA任务方面的操作有效性和可靠性。

</details>


### [125] [The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games](https://arxiv.org/abs/2506.15624)
**中文标题：状态表示对LLM代理在动态路由游戏中行为的影响**

*Lyle Goodyear,Rachel Guo,Ramesh Johari*

主要分类: cs.AI

摘要简述: 本文提出了一种系统构建自然语言状态表示的框架，用于在重复多智能体游戏中提示LLM代理，并通过动态自私路由游戏验证了状态表示对代理行为的关键影响。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究在LLM代理游戏中采用临时方法编码游戏历史，掩盖了状态表示对代理行为的影响，并限制了研究之间的可比性。本文旨在填补这一空白。

研究方法: 提出了一个框架，从三个维度描述状态表示方法：动作信息性、奖励信息性和提示风格（自然语言压缩），并将其应用于动态自私路由游戏。

研究结果: 研究发现，提供总结的历史表示、关于遗憾而非原始收益的信息以及有限的其他动作信息，能使LLM代理行为更接近博弈论均衡预测，且游戏更稳定。

研究结论: 状态表示对LLM代理行为有显著影响，特定表示方式能显著提升代理行为的均衡性和稳定性。

中文摘要: 大型语言模型（LLMs）在动态环境中作为决策者显示出潜力，但其无状态特性需要创建历史记录的自然语言表示。我们提出了一个统一框架，用于系统构建自然语言“状态”表示，以在重复多智能体游戏中提示LLM代理。以往关于LLM代理游戏的研究采用临时方法编码游戏历史，这不仅掩盖了状态表示对代理行为的影响，还限制了研究之间的可比性。我们的框架通过从三个维度描述状态表示方法填补了这一空白：动作信息性（即状态表示捕捉已执行动作的程度）、奖励信息性（即状态表示描述所获奖励的程度）和提示风格（或自然语言压缩，即对完整文本历史的总结程度）。

我们将此框架应用于动态自私路由游戏，选择该游戏是因为它在理论和人类实验中均存在简单均衡。尽管游戏相对简单，但我们发现LLM代理行为对自然语言状态表示存在关键依赖。具体而言，我们观察到，提供代理以下状态表示时，其行为更接近博弈论均衡预测，且游戏更稳定：（1）总结而非完整的历史自然语言表示；（2）关于遗憾而非原始收益的信息；（3）有限的他人动作信息。相比之下，其他表示方式可能导致与均衡的显著偏离、动态游戏中的更高变异性，或两者兼有。

</details>


### [126] [The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy](https://arxiv.org/abs/2506.15639)
**中文标题：AI政策模块：培养计算机科学学生在AI伦理与政策中的能力**

*James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry*

主要分类: cs.AI

摘要简述: 本文介绍了一个AI政策模块，旨在帮助计算机科学学生提升对AI伦理与政策的理解，并通过实践任务增强其参与AI监管讨论的能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI技术在日常和职业场景中的广泛应用，AI伦理和政策的重要性日益凸显。然而，当前的高等教育计算机课程未能充分培养学生将伦理原则转化为实践的能力，因此需要开发相关模块填补这一空白。

研究方法: 作者开发了一个AI政策模块，并在2024年秋季进行了试点。模块包括技术任务（如“AI监管”任务），并通过前后问卷调查评估学生对AI伦理和政策的认知变化。

研究结果: 试点结果显示，学生在模块学习后对AI技术的伦理影响更加关注，同时对参与AI监管讨论的信心显著提升。

研究结论: AI政策模块是培养学生AI伦理与政策能力的有效工具，尤其是“AI监管”任务，能够帮助学生理解政策在解决伦理挑战中的作用。

中文摘要: 随着人工智能（AI）在个人和职业场景中的广泛应用，不仅需要关注AI伦理，还需通过AI政策对技术进行治理和监管。然而，当前的高等教育计算机课程未能充分培养未来的AI从业者将抽象伦理原则和政策偏好转化为AI系统设计与开发实践的能力。我们认为，熟悉“AI政策领域”并将伦理原则转化为实践的能力，未来将成为技术导向型AI工程师的重要职责。

为帮助当前计算机科学（CS）学生应对这些新需求，我们开发了一个AI政策模块，将其引入CS课程。基于2024年秋季的成功试点，本文介绍了更新和扩展后的模块版本，包括一项关于“AI监管”的技术任务。我们通过模块前后的问卷调查评估了学生对AI伦理和政策的认知变化。结果显示，学生在模块学习后对AI技术的伦理影响更加关注，同时对参与AI监管讨论的信心显著提升。最后，我们强调“AI监管任务”是一种有效的工具，能够帮助学生探索AI对齐的局限性，并理解政策在解决伦理挑战中的作用。

</details>


### [127] [Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement](https://arxiv.org/abs/2506.15647)
**中文标题：探索与利用大型推理模型的固有效率以实现自我引导的效率提升**

*Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu*

主要分类: cs.AI

摘要简述: 大型推理模型（LRMs）存在过度思考问题，导致推理效率低下。研究发现LRMs具备潜在的高效推理能力，并提出两种轻量级方法（效率引导和自我奖励效率强化学习）显著缩短推理长度，同时保持或提升任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型在复杂问题解决中表现出色，但常因过度思考（生成冗长冗余内容）导致效率低下和推理成本增加。研究旨在探索和利用LRMs固有的高效潜力，提升其推理效率。

研究方法: 1. 效率引导：一种无需训练的激活引导技术，通过模型表示空间中的单一方向调节推理行为。2. 自我奖励效率强化学习：动态平衡任务准确性和简洁性的强化学习框架，奖励简洁正确的解决方案。

研究结果: 在多个数学推理基准测试中，两种方法显著缩短了推理长度，同时保持或提升了任务性能，验证了LRMs固有高效潜力的可挖掘性。

研究结论: 通过引导和利用LRMs的固有能力，可以显著提升推理效率，且无需额外训练或复杂干预。

中文摘要: 近年来，大型推理模型（LRMs）通过模拟人类深思熟虑的思维方式，显著提升了语言模型在复杂问题解决中的能力。然而，这些模型常表现出过度思考（即生成不必要的冗长和冗余内容），从而降低了效率并增加了推理成本。本研究探讨了这种低效的表征和行为根源，揭示了LRMs天生具备更简洁推理的潜力。实证分析表明，正确的推理路径长度差异显著，而最短的正确响应通常足够，这表明存在未开发的效率潜力。基于这些发现，我们提出了两种轻量级方法来提升LRM效率。首先，我们引入了效率引导，这是一种无需训练的激活引导技术，通过模型表示空间中的单一方向调节推理行为。其次，我们开发了自我奖励效率强化学习框架，通过奖励简洁正确的解决方案，动态平衡任务准确性和简洁性。在多个数学推理基准测试中对七种LRM主干进行的广泛实验表明，我们的方法显著缩短了推理长度，同时保持或提升了任务性能。结果表明，通过以自我引导的方式利用和引导现有模型的固有能力，可以显著提升推理效率。

</details>


### [128] [SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence](https://arxiv.org/abs/2506.15672)
**中文标题：SwarmAgentic：基于群体智能的全自动化代理系统生成**

*Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp*

主要分类: cs.AI

摘要简述: SwarmAgentic提出了一种基于群体智能的全自动化代理系统生成框架，通过语言驱动探索和反馈引导优化，实现了从零开始的代理生成与协作优化，显著提升了任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有代理系统生成框架缺乏完全自主性，无法实现从零开始的代理生成、功能自优化和协作优化，限制了其适应性和扩展性。SwarmAgentic旨在填补这一空白，实现全自动化的代理系统设计。

研究方法: SwarmAgentic通过语言驱动探索构建代理系统，并采用群体智能（如粒子群优化）对代理功能和协作进行联合优化。框架维护候选系统群体，并通过反馈引导的更新实现系统级结构的进化。

研究结果: 在六项真实世界的开放性和探索性任务中，SwarmAgentic仅需任务描述和目标函数即可显著优于基线方法，例如在TravelPlanner基准测试中相对ADAS提升了261.8%。

研究结论: SwarmAgentic为全自动化代理系统设计迈出了重要一步，将群体智能与多代理生成相结合，展示了其在无结构约束任务中的高效性和可扩展性。

中文摘要: 大型语言模型的快速发展推动了代理系统在决策、协调和任务执行方面的进步。然而，现有代理系统生成框架缺乏完全自主性，无法实现从零开始的代理生成、功能自优化和协作优化，限制了适应性和扩展性。我们提出SwarmAgentic，一种全自动化代理系统生成框架，通过语言驱动探索从零构建代理系统，并将代理功能与协作作为相互依赖的组件进行联合优化。为实现对系统级结构的高效搜索，SwarmAgentic维护候选系统群体，并通过反馈引导的更新实现其进化，灵感来源于粒子群优化（PSO）。我们在六项涉及高级规划、系统级协调和创造性推理的真实世界开放性和探索性任务中评估了该方法。仅需任务描述和目标函数，SwarmAgentic在所有基线方法中表现最优，例如在TravelPlanner基准测试中相对ADAS提升了261.8%，突显了全自动化在无结构约束任务中的有效性。该框架标志着可扩展和自主代理系统设计的重要进展，将群体智能与全自动化多代理生成相结合。代码已公开发布于https://yaoz720.github.io/SwarmAgentic/。

</details>


### [129] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
**中文标题：具身网络代理：为整合代理智能搭建物理与数字领域的桥梁**

*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

主要分类: cs.AI

摘要简述: 本文提出了一种新型AI代理范式——‘具身网络代理’，旨在整合物理与数字领域的智能，通过统一仿真平台和多样化任务基准，揭示了当前AI系统与人类能力之间的显著差距。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI代理大多局限于单一领域（数字或物理），无法有效解决需要跨领域协同的任务（如结合在线食谱烹饪或动态地图导航）。本文旨在打破这种隔离，实现物理与数字智能的深度融合。

研究方法: 作者开发了‘具身网络代理任务环境’——一个整合3D仿真环境与功能性网络接口的统一平台，并在此基础上构建了包含烹饪、导航、购物等多样化任务的基准测试。

研究结果: 实验结果表明，现有AI系统在跨领域任务中的表现与人类能力存在显著差距，凸显了具身认知与网络知识结合的挑战与机遇。

研究结论: 本文提出的具身网络代理范式为跨领域智能研究提供了新方向，相关数据集和代码已公开，为未来研究奠定了基础。

中文摘要: 当前AI代理大多孤立运行——它们要么在线检索和处理海量数字信息，要么通过具身感知、规划和行动与物理世界交互，但很少同时具备这两种能力。这种分离限制了它们解决需要物理与数字智能协同的任务（如根据在线食谱烹饪、结合动态地图数据导航或利用网络知识解读现实地标）的能力。本文提出‘具身网络代理’，一种新型AI代理范式，旨在无缝连接具身与网络规模推理。为实现这一概念，我们首先开发了‘具身网络代理任务环境’——一个将逼真的3D室内外环境与功能性网络接口紧密结合的统一仿真平台。基于此平台，我们构建并发布了‘具身网络代理基准测试’，涵盖烹饪、导航、购物、旅游和地理定位等多样化任务，均需跨物理与数字领域的协同推理，以系统评估跨领域智能。实验结果表明，当前最先进的AI系统与人类能力之间存在显著差距，为具身认知与网络知识访问的交叉研究提出了挑战与机遇。所有数据集、代码和网站均公开于项目页面：https://embodied-web-agent.github.io/。

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [130] [LLM Agent for Hyper-Parameter Optimization](https://arxiv.org/abs/2506.15167)
**中文标题：基于大语言模型的超参数优化代理**

*Wanzhe Wang,Jianqiu Peng,Menghao Hu,Weihuang Zhong,Tong Zhang,Shuai Wang,Yixin Zhang,Mingjie Shao,Wanli Ni*

主要分类: cs.IT

摘要简述: 本文提出了一种基于大语言模型（LLM）的智能代理，用于自动优化无人机通信算法中的超参数，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前无人机通信算法中的超参数优化方法多为启发式，自动化程度低且性能不佳，亟需一种更高效的自动优化方法。

研究方法: 设计了一个LLM代理，通过迭代框架和模型上下文协议（MCP）驱动，结合WS-PSO-CM算法进行超参数探索，最终自动返回最优参数集。

研究结果: 实验表明，LLM代理生成的超参数在最小总速率上显著优于人工启发式和随机生成方法。

研究结论: 具备PSO知识和WS-PSO-CM算法背景的LLM代理能有效找到高性能超参数，为自动化优化提供了新思路。

中文摘要: 超参数对通信算法的性能至关重要。然而，当前针对无人机轨迹和通信的WS-PSO-CM算法的超参数调优方法多为启发式，自动化程度低且性能不佳。本文设计了一种基于大语言模型（LLM）的智能代理，用于自动优化超参数，采用了迭代框架和模型上下文协议（MCP）。具体而言，LLM代理首先通过配置文件设定任务、背景和输出格式，随后根据提示需求驱动，迭代调用WS-PSO-CM算法进行探索，最终自主终止循环并返回一组超参数。实验结果表明，LLM代理生成的超参数在最小总速率上显著优于人工启发式和随机生成方法。这表明具备PSO知识和WS-PSO-CM算法背景的LLM代理在寻找高性能超参数方面具有实用性。

</details>


<div id='stat.OT'></div>

# stat.OT [[Back]](#toc)

### [131] [Next-Generation Conflict Forecasting: Unleashing Predictive Patterns through Spatiotemporal Learning](https://arxiv.org/abs/2506.14817)
**中文标题：下一代冲突预测：通过时空学习释放预测模式**

*Simon P. von der Maase*

主要分类: stat.OT

摘要简述: 本研究提出了一种新型神经网络架构，用于高时空分辨率预测暴力冲突，包括国家间、非国家和单边暴力，提前36个月预测，无需手动特征工程，性能达到最先进水平。


<details>
  <summary>详细信息</summary>
研究动机: 高时空分辨率的暴力冲突预测对研究者和决策者至关重要，但现有方法依赖手动特征工程且性能有限，亟需一种自动化、高性能的预测模型。

研究方法: 采用蒙特卡洛Dropout LSTM U-Net架构，结合卷积层捕捉空间依赖性和循环结构建模时间动态，完全基于历史冲突数据，无需手动特征工程。

研究结果: 模型在所有任务中达到最先进性能，生成概率估计和事件预期规模，并能量化预测不确定性，同时具备扩展性，可整合额外数据源。

研究结论: 该模型为早期预警系统、人道主义响应规划和基于证据的和平建设提供了有力工具，具备高度扩展性和实用性。

中文摘要: 高时空分辨率的暴力冲突预测是研究者和决策者面临的核心挑战。本研究提出了一种新型神经网络架构，用于预测三种类型的暴力（国家间、非国家和单边暴力），在次国家层面（priogrid-月）提前36个月进行预测。模型同时执行分类和回归任务，生成未来事件的概率估计和预期规模。其在所有任务中均达到最先进性能，并能生成近似预测后验分布以量化不确定性。该架构基于蒙特卡洛Dropout长短期记忆（LSTM）U-Net，结合卷积层捕捉空间依赖性和循环结构建模时间动态。与许多现有方法不同，它无需手动特征工程，仅依赖历史冲突数据，能够自主学习暴力冲突背后的复杂时空模式。除了卓越的预测性能，该模型还具备高度扩展性：可轻松整合额外数据源并联合预测辅助变量。这些能力使其成为早期预警系统、人道主义响应规划和基于证据的和平建设的有力工具。

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [132] [Intrinsic and Extrinsic Organized Attention: Softmax Invariance and Network Sparsity](https://arxiv.org/abs/2506.15541)
**中文标题：内在与外在组织注意力：Softmax不变性与网络稀疏性**

*Oluwadamilola Fasina,Ruben V. C. Pohle,Pei-Chun Su,Ronald R. Coifman*

主要分类: math.NA

摘要简述: 本文研究了Transformer中自注意力机制的内在（注意力头内）和外在（注意力头间）结构，证明了自注意力机制对softmax激活的不变性，并通过分层组织方法分析了网络结构的稀疏性，为模型剪枝和架构比较提供了理论基础。


<details>
  <summary>详细信息</summary>
研究动机: 研究自注意力机制的结构特性，探索其在softmax激活下的不变性，以及如何利用分层组织方法分析网络结构的稀疏性，从而提升模型的可解释性和实用性。

研究方法: 通过理论分析（如拟微分计算）证明自注意力机制对softmax激活的不变性，并使用分层组织方法构建查询、键和注意力头轴的分层树结构，分析网络稀疏性。

研究结果: 证明了自注意力机制对softmax激活的不变性，并通过分层树结构和稀疏性分析展示了网络结构的规律性，为模型剪枝和架构比较提供了依据。

研究结论: 研究为自注意力机制的可解释性分析提供了理论支持，并展示了其在模型剪枝和架构比较中的实际应用潜力。

中文摘要: 我们研究了Transformer中自注意力机制的内在（注意力头内）和外在（注意力头间）结构。通过拟微分计算，我们获得了自注意力机制对softmax激活不变性的理论证据（并得到计算示例的支持），这依赖于注意力头的内在组织。此外，我们利用现有的张量分层组织方法，通过构建查询、键和注意力头轴的分层树结构来研究网络结构。这种组织方式具有重要意义，因为它允许在几何结构上高效执行常见的信号处理任务，其中组织的网络3-张量表现出规律性。我们通过可视化注意力头的分层树结构和扩散图嵌入定性展示了这一点，并通过研究网络稀疏性（利用双和三Haar基对查询、键和注意力头空间的扩展系数）定量展示了这一点。为了展示理论和方法的实用性，我们提供了视觉和语言Transformer的计算示例。这些发现的含义有两点：（1）理论上支持了可解释性分析的后续步骤，并可在下游可解释性任务中实证利用；（2）可以利用网络3-张量的组织进行模型剪枝（基于网络稀疏性）和网络架构比较等实际应用。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [133] [Efficient Serving of LLM Applications with Probabilistic Demand Modeling](https://arxiv.org/abs/2506.14851)
**中文标题：基于概率需求建模的高效LLM应用服务**

*Yifei Liu,Zuo Gan,Zhenghao Gan,Weiye Wang,Chen Chen,Yizhou Shan,Xusheng Chen,Zhenhua Han,Yifei Zhu,Shixuan Sun,Minyi Guo*

主要分类: cs.DC

摘要简述: 本文提出了一种基于概率需求图（PDGraph）的高效LLM应用服务系统Hermes，通过优化调度顺序和预热后端，显著降低了应用完成时间。


<details>
  <summary>详细信息</summary>
研究动机: 现有LLM应用服务系统将资源需求视为黑盒，导致端到端效率低下，无法应对动态需求。本文旨在通过概率需求建模解决这一问题。

研究方法: 提出概率需求图（PDGraph）模型，并基于此设计Hermes系统，利用Gittins策略优化调度顺序，同时通过PDGraph模型在适当时机预热后端。

研究结果: 实验表明，Hermes能够显著提升服务效率，平均完成时间降低70%以上，P95完成时间降低80%以上。

研究结论: Hermes通过概率需求建模和智能调度，为LLM应用提供了高效的服务解决方案。

中文摘要: 基于大语言模型（LLM）的应用通过一系列任务解决现实问题，但其动态需求在不同后端上变化显著。现有服务系统将LLM应用的资源需求视为黑盒，导致端到端效率因不当的排队顺序和后端预热延迟而受损。我们发现，LLM应用的资源需求可以通过概率需求图（PDGraph）进行通用且准确的建模。为此，我们提出Hermes系统，利用PDGraph实现高效服务。面对概率需求描述，Hermes采用Gittins策略确定调度顺序以最小化平均应用完成时间，并利用PDGraph模型在适当时机预热冷启动后端。多样化的LLM应用实验证实，Hermes能显著提升服务效率，平均完成时间降低70%以上，P95完成时间降低80%以上。

</details>


### [134] [Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching](https://arxiv.org/abs/2506.14852)
**中文标题：通过测试时计划缓存实现LLM代理的高效低成本服务**

*Qizheng Zhang,Michael Wornow,Kunle Olukotun*

主要分类: cs.DC

摘要简述: 本文提出了一种名为“代理计划缓存”的新方法，通过提取、存储、适配和重用结构化计划模板，显著降低了基于LLM的代理应用的服务成本，平均节省46.62%的成本。


<details>
  <summary>详细信息</summary>
研究动机: 基于LLM的代理应用在复杂工作流程中表现出色，但其高昂的规划和推理成本限制了实际应用。现有的LLM缓存技术（如上下文缓存和语义缓存）主要针对聊天机器人设计，无法满足依赖外部数据或环境上下文的代理应用需求。

研究方法: 本文提出代理计划缓存方法，从代理执行的规划阶段提取结构化计划模板，通过关键词提取匹配新请求，并利用轻量级模型将模板适配为任务特定的计划。

研究结果: 实验表明，该方法在多个实际代理应用中平均降低46.62%的成本，同时保持性能。

研究结论: 代理计划缓存是一种高效且互补的LLM服务解决方案，显著降低了代理应用的成本。

中文摘要: 基于LLM的代理应用在复杂工作流程中展现出越来越强大的能力，但由于大量规划和推理需求，其成本高昂。现有的LLM缓存技术（如上下文缓存和语义缓存）主要为聊天机器人设计，无法满足依赖外部数据或环境上下文的代理应用需求。我们提出代理计划缓存，这是一种新颖的方法，通过从代理应用的规划阶段提取、存储、适配和重用结构化计划模板，以降低服务成本。与传统语义缓存不同，我们的系统在测试时从已完成的代理执行中提取计划模板，利用关键词提取将新请求与缓存计划匹配，并通过轻量级模型将模板适配为任务特定的计划。在多个实际代理应用中的评估表明，我们的系统平均可降低46.62%的成本，同时保持性能，为基于LLM的代理服务提供了一种更高效的解决方案，并与现有LLM服务基础设施互补。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [135] [Comparative Analysis of QNN Architectures for Wind Power Prediction: Feature Maps and Ansatz Configurations](https://arxiv.org/abs/2506.14795)
**中文标题：风能预测中QNN架构的比较分析：特征图与Ansatz配置**

*Batuhan Hangun,Emine Akpinar,Oguz Altun,Onder Eyecioglu*

主要分类: quant-ph

摘要简述: 本文通过比较12种不同的量子神经网络（QNN）架构，评估其在风能预测中的表现。研究发现，采用Z特征图的QNN在仅使用4个输入参数时，预测准确率高达93%，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 量子机器学习（QML）作为量子计算与机器学习的交叉领域，旨在利用量子力学原理提升经典机器学习方法。然而，由于当前噪声中尺度量子（NISQ）设备的限制，QML的实际优势仍受质疑。本研究旨在通过评估QNN的性能，验证其在真实任务中的潜力。

研究方法: 研究系统地构建并评估了12种不同的QNN配置，结合了两种量子特征图和六种纠缠策略设计。实验基于风能数据集，比较了QNN与传统方法的预测效果。

研究结果: 实验结果表明，采用Z特征图的QNN在风能预测任务中表现最佳，准确率达到93%，显著优于传统方法。

研究结论: QNN在风能预测任务中展现出优于传统方法的潜力，为QML在现实应用中的可行性提供了有力支持。

中文摘要: 量子机器学习（QML）是量子计算与机器学习的交叉新兴领域，旨在通过利用量子力学原理（如纠缠和叠加）增强经典机器学习方法。然而，由于当前噪声中尺度量子（NISQ）设备的限制，QML的实际优势仍受质疑。本研究通过全面评估量子神经网络（QNN）——一种受量子启发的类人工神经网络（ANN），验证了其相对于传统方法的有效性。我们系统地构建并评估了12种不同的QNN配置，结合了两种独特的量子特征图和六种纠缠策略设计Ansatz。在风能数据集上的实验表明，采用Z特征图的QNN在仅使用4个输入参数时，风能输出预测准确率高达93%。研究结果表明，QNN在预测任务中优于传统方法，凸显了QML在现实应用中的潜力。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [136] [See What I Mean? CUE: A Cognitive Model of Understanding Explanations](https://arxiv.org/abs/2506.14775)
**中文标题：明白我的意思吗？CUE：一种解释理解的认知模型**

*Tobias Labarta,Nhi Hoang,Katharina Weitz,Wojciech Samek,Sebastian Lapuschkin,Leander Weber*

主要分类: cs.HC

摘要简述: 本文提出CUE模型，将解释属性与认知子过程（可读性、可理解性、可解释性）关联，研究发现视觉障碍用户在使用热图时任务表现相似但信心/努力较低，挑战了感知优化的假设，支持自适应XAI界面需求。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习系统在关键决策中的作用日益增强，对易于人类理解的解释需求增加。当前可解释AI（XAI）评估常忽视认知可访问性，尤其是对视觉障碍用户的影响。

研究方法: 提出CUE模型，将解释属性与认知子过程（可读性、可理解性、可解释性）关联，并通过实验（N=455）测试不同颜色热图（BWR、Cividis、Coolwarm）对视觉障碍用户的影响。

研究结果: 研究发现视觉障碍用户任务表现与普通用户相似，但信心和努力程度较低。专注于可访问性的颜色（如Cividis）未改善甚至加剧了这种差距。

研究结论: 结果挑战了感知优化的假设，支持自适应XAI界面的需求，并验证CUE模型通过改变解释可读性影响理解性。贡献包括：1）形式化的解释理解认知模型；2）以人为中心的解释属性定义；3）推动可访问、用户定制XAI的实证证据。

中文摘要: 随着机器学习系统越来越多地参与关键决策，对易于人类理解的解释需求日益增长。当前可解释AI（XAI）的评估常优先考虑技术保真度而非认知可访问性，这对用户（尤其是视觉障碍者）至关重要。我们提出CUE（解释的认知理解模型），将解释属性与认知子过程（可读性、可理解性、可解释性）关联。在一项测试不同颜色热图（BWR、Cividis、Coolwarm）的研究（N=455）中，发现视觉障碍用户任务表现相似但信心/努力较低。出乎意料的是，专注于可访问性的颜色（如Cividis）未改善甚至加剧了这种差距。这些结果挑战了感知优化的假设，支持自适应XAI界面的需求，并通过改变解释可读性影响理解性验证了CUE模型。我们贡献包括：1）形式化的解释理解认知模型；2）以人为中心的解释属性定义；3）推动可访问、用户定制XAI的实证证据。

</details>


### [137] [WebXAII: an open-source web framework to study human-XAI interaction](https://arxiv.org/abs/2506.14777)
**中文标题：WebXAII：一个用于研究人类与可解释人工智能交互的开源网络框架**

*Jules Leguy,Pierre-Antoine Jean,Felipe Torres Figueroa,Sébastien Harispe*

主要分类: cs.HC

摘要简述: 本文介绍了WebXAII，一个开源的网络框架，旨在促进人类与可解释人工智能（XAI）系统交互的研究。该框架通过模块化设计和结构化配置文件，简化了实验协议的实现，提升了实验的可重用性和可重复性。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能（尤其是机器学习）在各领域的广泛应用，XAI研究迅速发展。然而，研究人员通常需要为每次实验开发临时接口，这些接口很少共享，限制了实验的可重用性和可重复性。WebXAII旨在解决这一问题。

研究方法: WebXAII是一个基于网络的平台，能够完整呈现实验协议并记录参与者的响应。其架构由通用视图和模块组成，通过结构化配置文件定义实验协议，降低了编程技能要求。

研究结果: 通过复现一项前沿研究的实验协议，证明了WebXAII能够有效支持相关研究。该框架已在GitHub上开源。

研究结论: WebXAII为XAI交互研究提供了一个灵活且易于使用的工具，显著提升了实验的可重用性和可重复性。

中文摘要: 本文介绍了WebXAII，一个开源的网络框架，旨在促进人类与可解释人工智能（XAI）系统交互的研究。随着人工智能（尤其是机器学习）在各领域的广泛应用，XAI研究迅速发展。研究人员通常需要为每次实验开发临时接口，但这些接口很少共享，限制了实验的可重用性和可重复性。为此，我们设计并实现了WebXAII，这是一个基于网络的平台，能够完整呈现实验协议并记录参与者的响应。实验协议通过通用视图和模块的复合架构实现，具有高度灵活性。架构由结构化配置文件定义，使得实验协议可以通过最低编程技能实现。通过复现一项前沿研究的实验协议，我们证明了WebXAII的有效性。该框架已在GitHub上开源。

</details>


### [138] [Analyzing Character Representation in Media Content using Multimodal Foundation Model: Effectiveness and Trust](https://arxiv.org/abs/2506.14799)
**中文标题：基于多模态基础模型的媒体内容角色表征分析：有效性与信任度**

*Evdoxia Taka,Debadyuti Bhattacharya,Joanne Garde-Hansen,Sanjay Sharma,Tanaya Guha*

主要分类: cs.HC

摘要简述: 本文提出了一种基于CLIP多模态基础模型的工具，用于分析媒体内容中的角色表征（如性别和年龄），并通过用户研究验证其有效性和公众信任度。研究发现，用户认为工具总体有用，但对AI生成结果的信任度中等偏低。


<details>
  <summary>详细信息</summary>
研究动机: 过去的研究通过多种机器学习模型量化媒体内容中的角色表征，但未考虑公众对这些数据的信任和实用性。本文旨在填补这一空白，探讨AI生成的角色表征数据对公众的实际价值及其信任度。

研究方法: 研究基于CLIP多模态基础模型开发了一个工具，用于分析视觉屏幕数据并量化角色在性别和年龄维度的表征。同时设计了适合普通观众的直观可视化界面，并通过用户研究评估工具的有用性和信任度。

研究结果: 用户能够通过可视化界面理解分析结果，并认为工具总体有用。但他们希望可视化能包含更多人口统计类别和角色背景信息。此外，用户对AI生成的性别和年龄模型的信任度中等偏低，但并不反对在此领域使用AI。

研究结论: 研究表明，AI生成的角色表征数据对公众具有一定价值，但需进一步优化可视化设计和提升模型透明度以增强信任。工具代码、基准测试和用户研究数据已公开。

中文摘要: 近年来，人工智能的进步使得大规模自动化分析复杂媒体内容成为可能，并能够生成关于角色表征（如性别和年龄）的可操作见解。以往的研究侧重于通过多种机器学习模型从音频/视频/文本中量化表征，但未将受众纳入考量。我们提出疑问：即使角色在人口统计维度上的分布数据可用，这些数据对公众的实际价值如何？他们是否真正信任AI模型生成的数字？本研究通过用户调查回答了这些问题，并提出了一种基于AI的角色表征和可视化工具。该工具基于对比语言图像预训练（CLIP）基础模型，用于分析视觉屏幕数据，量化角色在年龄和性别维度的表征。我们还设计了适合普通观众的有效可视化界面。随后，通过用户研究，我们获取了关于AI生成结果（以可视化形式呈现）对选定电影的有用性和可信度的实证证据。研究发现，参与者能够通过我们的可视化理解分析结果，并认为工具“总体有用”。参与者还表示希望可视化能包含更多人口统计类别和角色背景信息。尽管参与者对AI生成的性别和年龄模型的信任度中等偏低，但他们并不反对在此领域使用AI。工具代码、基准测试和用户研究数据可在此处获取：https://anonymous.4open.science/r/Character-Representation-Media-FF7B

</details>


### [139] [The Hardness of Achieving Impact in AI for Social Impact Research: A Ground-Level View of Challenges & Opportunities](https://arxiv.org/abs/2506.14829)
**中文标题：AI社会影响研究中实现实际影响的困难：挑战与机遇的实地视角**

*Aditya Majumdar,Wenbo Zhang,Kashvi Prawal,Amulya Yadav*

主要分类: cs.HC

摘要简述: 本文探讨了AI社会影响研究（AI4SI）在实现实际影响时面临的挑战，包括合作困难、项目难以规模化以及学术认可不足，并提出了改进策略。


<details>
  <summary>详细信息</summary>
研究动机: 尽管AI社会影响研究（AI4SI）在解决联合国可持续发展目标方面具有潜力，但实际落地影响仍面临诸多挑战。本文旨在揭示这些挑战并为研究者提供实用指南。

研究方法: 通过对六位领先AI4SI研究者的半结构化访谈及作者自身经验，进行主题分析，识别出部署AI解决方案时的主要障碍。

研究结果: 研究发现，结构性、组织性、沟通、协作和操作性问题是实现AI4SI项目实际影响的主要障碍，并提出了改进策略。

研究结论: 本文为AI4SI研究者和合作组织提供了实用参考，帮助更有效地开展具有社会影响的AI合作。

中文摘要: 为实现联合国可持续发展目标，AI社会影响（AI4SI）项目致力于利用AI解决医疗、社会正义等领域的社问题。然而，尽管AI4SI受到广泛关注，实现实际落地影响仍面临重大挑战。例如，寻找并激励愿意共同设计和部署AI解决方案的合作者往往困难重重。即使建立了合作关系，许多AI4SI项目仍难以超越概念验证阶段，无法过渡到规模化生产级解决方案。此外，AI4SI研究者面临的独特挑战在更广泛的AI社区中并未得到充分认可，这类研究有时被视为偏应用型，不符合核心AI领域对新颖性的传统标准。本文通过诊断阻碍AI4SI合作实现实际影响的多种因素，揭示了AI4SI研究中的多样化挑战。基于对六位领先AI4SI研究者的半结构化访谈及作者自身研究经验，本文试图理解开发和部署具有社会影响的AI解决方案时面临的日常困难。通过主题分析，我们识别出结构性、组织性、沟通、协作和操作性问题为部署的主要障碍。尽管没有简单的解决方案，但我们综合了访谈和自身工作中的最佳实践与可行策略。希望本文能为AI4SI研究者及合作组织提供实用参考，助力更有效地开展社会影响型AI合作。

</details>


### [140] [Insights Informed Generative AI for Design: Incorporating Real-world Data for Text-to-Image Output](https://arxiv.org/abs/2506.15008)
**中文标题：基于真实世界数据的生成式AI设计洞察：为文本到图像输出融入可持续性指标**

*Richa Gupta,Alexander Htet Kyaw*

主要分类: cs.HC

摘要简述: 本文提出了一种结合DALL-E 3与材料数据集的新方法，通过后处理模块为AI生成的设计图像添加可持续性指标和材料使用数据，帮助设计师评估环境影响并优化设计。


<details>
  <summary>详细信息</summary>
研究动机: 尽管生成式AI（如文本到图像模型）能快速将概念转化为视觉设计，但其输出缺乏可操作的数据支持。本文旨在通过整合可持续性指标，为设计师提供更实用的设计辅助工具。

研究方法: 研究提出了一种新流程：首先使用DALL-E 3生成室内设计图像，随后通过后处理模块识别图像中的主要材料，并结合材料字典中的二氧化碳当量（CO2e）数据，为设计师提供环境影响评估。

研究结果: 用户测试表明，引入可持续性指标（尤其是定量CO2e数据）能显著提升设计决策的环保意识，但也可能引发决策疲劳并降低满意度。尽管如此，多数参与者表示会在工作流程中纳入可持续性原则。

研究结论: 研究强调了在设计自由与实用约束之间平衡的重要性，为AI辅助建筑设计提供了更全面的数据驱动解决方案。

中文摘要: 生成式AI（尤其是文本到图像模型）通过将概念快速转化为视觉设计，彻底改变了室内建筑设计领域。然而，这些模型生成的图像虽然视觉上吸引人，却往往缺乏对设计师有用的数据支持。本文提出了一种新方法，将DALL-E 3与材料数据集结合，通过后处理模块为AI生成的设计图像添加可持续性指标和材料使用数据。生成图像后，模块会识别图像中的前十大材料，并结合通用材料字典中的二氧化碳当量（CO2e）值，帮助设计师即时评估环境影响并优化设计提示。我们通过三项用户测试评估了该系统：（1）在生成AI提示前未提及可持续性；（2）在提示前告知用户可持续性目标；（3）在生成AI输出中包含定量CO2e数据并告知可持续性目标。定性与定量分析表明，第三种测试中引入可持续性指标能显著提升设计决策的环保意识，但也可能引发决策疲劳并降低满意度。尽管如此，多数参与者表示会在第三种测试中纳入可持续性原则，凸显了整合指标对推动生态友好实践的潜力。研究结果展示了平衡设计自由与实用约束的重要性，为AI辅助建筑设计提供了更全面的数据驱动解决方案。

</details>


### [141] [Mapping Caregiver Needs to AI Chatbot Design: Strengths and Gaps in Mental Health Support for Alzheimer's and Dementia Caregivers](https://arxiv.org/abs/2506.15047)
**中文标题：将护理者需求映射到AI聊天机器人设计：阿尔茨海默病与痴呆症护理者心理健康支持的优势与不足**

*Jiayue Melissa Shi,Dong Whi Yoo,Keran Wang,Violeta J. Rodriguez,Ravi Karkar,Koustuv Saha*

主要分类: cs.HC

摘要简述: 本文研究了阿尔茨海默病及相关痴呆症（AD/ADRD）家庭护理者的需求，并设计了一款基于GPT-4o的聊天机器人Carey，以提供信息与情感支持。通过访谈与分析，揭示了护理者的六大需求主题及AI技术的优势与不足，并提出了设计建议。


<details>
  <summary>详细信息</summary>
研究动机: AD/ADRD家庭护理者面临巨大的情感与后勤压力，易产生焦虑和抑郁。尽管生成式AI（如大语言模型）为心理健康支持提供了新机会，但护理者对这些技术的接受度与需求尚不明确。本研究旨在填补这一空白。

研究方法: 开发了基于GPT-4o的聊天机器人Carey，并通过16名家庭护理者的半结构化访谈，结合场景驱动的互动，采用归纳编码和反思性主题分析，系统性梳理护理者的需求与期望。

研究结果: 研究揭示了护理者的六大需求主题：即时信息获取、情感支持、安全披露空间、危机管理、个性化服务和数据隐私。同时，指出了AI聊天机器人在满足这些需求时的优势与潜在矛盾。

研究结论: 研究为设计更主动、可信且以护理者为中心的AI系统提供了理论与实践依据，以更好地支持AD/ADRD护理者的心理健康需求。

中文摘要: 阿尔茨海默病及相关痴呆症（AD/ADRD）的家庭护理者面临巨大的情感与后勤挑战，使其更容易产生压力、焦虑和抑郁。尽管生成式AI（尤其是大语言模型）为心理健康支持提供了新机会，但护理者对这些技术的看法与使用情况尚不清楚。为填补这一空白，我们开发了Carey，一款基于GPT-4o的聊天机器人，旨在为AD/ADRD护理者提供信息与情感支持。通过Carey作为技术探针，我们对16名家庭护理者进行了半结构化访谈，基于常见护理压力场景进行互动。通过归纳编码和反思性主题分析，我们系统性梳理了护理者的需求与期望，涵盖六大主题：即时信息获取、情感支持、安全披露空间、危机管理、个性化服务和数据隐私。针对每个主题，我们还揭示了护理者需求与担忧之间的微妙矛盾。我们提出了护理者需求与AI聊天机器人优势、不足及设计建议的映射关系。研究结果为设计更主动、可信且以护理者为中心的AI系统提供了理论与实践依据，以更好地支持AD/ADRD护理者不断变化的心理健康需求。

</details>


### [142] [Accessible Gesture-Driven Augmented Reality Interaction System](https://arxiv.org/abs/2506.15189)
**中文标题：可访问的手势驱动增强现实交互系统**

*Yikan Wang*

主要分类: cs.HC

摘要简述: 本文提出了一种基于手势的增强现实（AR）交互系统，利用深度学习技术识别手势，并通过联邦学习和强化学习优化界面，显著提升了运动障碍用户的任务完成效率和满意度。


<details>
  <summary>详细信息</summary>
研究动机: 增强现实（AR）的交互通常依赖精确输入方式，导致运动障碍或灵活性受限的用户难以使用。本研究旨在通过手势识别技术提升AR的可访问性和用户体验。

研究方法: 系统结合视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，采用联邦学习保护用户隐私，并通过强化学习优化界面布局和交互模式。

研究结果: 实验表明，该系统使运动障碍用户的任务完成效率提升20%，用户满意度提高25%，显著优于传统AR系统。

研究结论: 该研究通过深度学习与联邦学习的结合，为AR交互提供了更包容和高效的解决方案，推动了AR技术的普及和可访问性。

中文摘要: 增强现实（AR）提供了沉浸式交互体验，但由于依赖精确输入方式，对运动障碍或灵活性受限的用户仍不可访问。本研究提出了一种基于手势的AR交互系统，利用深度学习从可穿戴传感器和摄像头中识别手势，并根据用户能力调整界面。系统采用视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，并通过联邦学习实现隐私保护的模型训练。强化学习用于优化菜单布局和交互模式等界面元素。实验表明，与传统AR系统相比，该系统使运动障碍用户的任务完成效率提升20%，用户满意度提高25%。这一方法显著提升了AR的可访问性和扩展性。关键词：深度学习，联邦学习，手势识别，增强现实，可访问性，人机交互

</details>


### [143] [Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI](https://arxiv.org/abs/2506.15468)
**中文标题：通过Metropolis-Hastings互动实现人类与AI的协同创造学习**

*Ryota Okumura,Tadahiro Taniguchi,Akira Taniguchi,Yoshinobu Hagiwara*

主要分类: cs.HC

摘要简述: 本文提出了一种新型的协同创造学习范式，通过人类与AI的互动整合部分感知信息与知识，构建共享的外部表征。基于Metropolis-Hastings命名游戏（MHNG）的实验表明，人类与AI的互动显著提升了分类准确性并实现了更强的符号系统收敛。


<details>
  <summary>详细信息</summary>
研究动机: 传统AI教学依赖于单向知识传递，而人类与AI的感知模态存在本质差异。本文旨在探索一种协同创造学习范式，通过双向互动整合不同模态的信息，实现符号涌现。

研究方法: 采用基于Metropolis-Hastings命名游戏（MHNG）的分散贝叶斯推理机制，设计了一个在线实验，69名参与者与三种计算机代理（基于MH、总是接受或总是拒绝）在部分可观测条件下进行联合注意力命名游戏（JA-NG）。

研究结果: 实验结果显示，与基于MH的代理互动的人类-AI组合显著提升了分类准确性，并实现了更强的共享符号系统收敛。此外，人类的接受行为与MH衍生的接受概率高度一致。

研究结论: 本研究首次通过MHNG互动实证了人类-AI协同创造学习的涌现，为动态对齐感知体验的共生AI系统提供了新路径。

中文摘要: 我们提出了一种新型的协同创造学习范式，即人类与AI（生物与人工代理）通过相互整合部分感知信息与知识，构建共享的外部表征，这一过程我们解释为符号涌现。与传统基于单向知识传递的AI教学不同，该方法解决了整合不同模态信息的挑战。我们通过基于Metropolis-Hastings命名游戏（MHNG）的分散贝叶斯推理机制，对这一框架进行了实证测试。在一项在线实验中，69名参与者与三种计算机代理（基于MH、总是接受或总是拒绝）在部分可观测条件下进行了联合注意力命名游戏（JA-NG）。结果显示，与基于MH的代理互动的人类-AI组合显著提升了分类准确性，并实现了更强的共享符号系统收敛。此外，人类的接受行为与MH衍生的接受概率高度一致。这些发现首次为基于MHNG互动的人类-AI协同创造学习提供了实证证据，为动态对齐感知体验的共生AI系统开辟了新途径。

</details>


### [144] [Optimizing Web-Based AI Query Retrieval with GPT Integration in LangChain A CoT-Enhanced Prompt Engineering Approach](https://arxiv.org/abs/2506.15512)
**中文标题：基于LangChain框架的GPT集成优化Web AI查询检索：一种CoT增强的提示工程方法**

*Wenqi Guan,Yang Fang*

主要分类: cs.HC

摘要简述: 本文提出了一种通过将GPT模型集成到LangChain框架中，结合CoT推理和提示工程，优化远程学习资源检索的新方法，显著提升了检索结果的精确性和相关性。


<details>
  <summary>详细信息</summary>
研究动机: 当前远程学习资源的检索缺乏深度上下文信息，无法满足学生对复杂查询的需求。本文旨在通过GPT模型和LangChain框架的结合，提供更全面且符合学生需求的检索结果。

研究方法: 提出了一种基于LangChain框架的GPT模型集成方法，利用CoT（Chain-of-Thought）推理和提示工程技术，优化检索系统的上下文理解和资源匹配能力。

研究结果: 实验表明，该方法在用户满意度和学习效果上优于传统LLM模型，检索结果的精确性和相关性显著提升。

研究结论: 通过集成GPT模型和LangChain框架，结合CoT推理和提示工程，本文成功实现了对远程学习资源检索的优化，为教育技术领域提供了新的解决方案。

中文摘要: 大型语言模型为远程学习等教育活动带来了革命性变化。然而，当前远程学习资源的检索缺乏深度上下文信息，无法全面满足学生对复杂查询的需求。本文提出了一种新颖的方法，通过在LangChain框架中集成基于GPT的模型，结合CoT（Chain-of-Thought）推理和提示工程技术，优化检索系统。该框架着重提升检索结果的精确性和相关性，以返回更全面且符合学生需求的上下文丰富解释和资源。我们还评估了该方法与典型LLM模型的效果，结果显示用户满意度和学习效果均有显著提升。

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [145] [MODS: Multi-source Observations Conditional Diffusion Model for Meteorological State Downscaling](https://arxiv.org/abs/2506.14798)
**中文标题：MODS：多源观测条件扩散模型用于气象状态降尺度**

*Siwei Tu,Jingyi Xu,Weidong Yang,Lei Bai,Ben Fei*

主要分类: physics.ao-ph

摘要简述: 提出了一种多源观测条件扩散模型（MODS），用于气象状态降尺度，通过融合多源卫星和地形数据，显著提高了降尺度精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有降尺度方法主要依赖单一卫星数据，无法全面捕捉气象变量变化，导致结果偏离实际。需要更全面的数据源以提高降尺度精度。

研究方法: MODS是一种条件扩散模型，融合了多源卫星数据（GridSat、AMSU-A、HIRS、MHS）和地形数据（GEBCO），通过多源交叉注意力模块提取特征并融合到ERA5数据中。

研究结果: 实验表明，MODS在将ERA5数据降尺度至6.25 km分辨率时，生成的结果更接近真实气象状态，具有更高的保真度。

研究结论: MODS通过多源数据融合和条件扩散模型，显著提升了气象状态降尺度的准确性和真实性。

中文摘要: 准确获取高分辨率地表气象条件对气象预报和模拟至关重要。直接从低分辨率网格场通过空间插值方法获取特定位置的气象值，结果往往与实际条件偏差较大。现有降尺度方法主要依赖地球静止卫星与ERA5变量的耦合关系作为条件，但仅使用地球静止卫星的亮温数据无法全面捕捉ERA5图中气象变量的所有变化。为解决这一问题，我们可利用更广泛的卫星数据，更充分地利用其对各种气象变量的反演效果，从而在不同气象变量上生成更真实的结果。为进一步提高任意位置气象变量降尺度的准确性，我们提出了多源观测降尺度模型（MODS）。它是一种条件扩散模型，融合了多源地球静止卫星GridSat、极轨卫星（AMSU-A、HIRS和MHS）以及地形数据（GEBCO）作为条件，并在ERA5再分析数据集上进行了预训练。训练过程中，通过多源交叉注意力模块分别提取不同条件输入的潜在特征并融合到ERA5图中。通过利用再分析数据与多源大气变量之间的反演关系，MODS生成了更接近真实世界条件的大气状态。在采样阶段，MODS通过结合低分辨率ERA5图和站点级气象数据作为指导，增强了降尺度的一致性。实验结果表明，MODS在将ERA5图降尺度至6.25 km分辨率时具有更高的保真度。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [146] [Preparing for the Intelligence Explosion](https://arxiv.org/abs/2506.14863)
**中文标题：为智能爆炸做准备**

*William MacAskill,Fin Moorhouse*

主要分类: cs.CY

摘要简述: 本文探讨了人工智能可能引发的技术爆炸及其带来的重大挑战，提出了当前应采取的行动以应对未来的不确定性。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI加速技术发展，未来可能面临一系列重大挑战，如大规模杀伤性武器、AI独裁政权等。这些挑战无法完全依赖未来的AI系统解决，因此需要现在就开始准备。

研究方法: 通过分析AI驱动的技术爆炸可能带来的挑战，提出当前可以采取的措施，以改善未来的应对能力。

研究结果: 研究发现，未来的挑战不仅需要AI系统的对齐，还需要人类提前准备，以应对技术爆炸带来的复杂局面。

研究结论: 为应对AI驱动的技术爆炸，当前应采取行动，确保未来能够有效应对各种挑战和机遇。

中文摘要: 能够加速研究的人工智能可能在短短几年内推动一个世纪的技术进步。在此期间，新的技术或政治发展将迅速引发一系列重大且难以逆转的决策。我们称这些发展为重大挑战。这些挑战包括新的大规模杀伤性武器、AI支持的独裁政权、争夺外星资源的竞赛，以及值得道德考量的数字生命，同时也有机会显著提升生活质量和集体决策能力。我们认为，这些挑战不能总是委托给未来的AI系统，并提出了当前可以采取的措施以改善前景。因此，AGI准备不仅关乎确保高级AI系统的对齐，我们现在就应该为智能爆炸带来的各种令人困惑的发展做好准备。

</details>


### [147] [Hypothesis Testing for Quantifying LLM-Human Misalignment in Multiple Choice Settings](https://arxiv.org/abs/2506.14997)
**中文标题：多项选择情境中量化LLM与人类行为偏差的假设检验**

*Harbin Hong,Sebastian Caldas,Liu Leqi*

主要分类: cs.CY

摘要简述: 本文提出了一种基于假设检验的定量框架，用于评估大型语言模型（LLM）在多项选择调查中与人类行为的偏差，发现某些模型在模拟特定人群时存在显著不匹配。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在社会科学研究（如经济学和市场营销）中的应用日益增多，评估这些模型是否能准确模拟人类行为变得至关重要。本文旨在通过假设检验，量化LLM与人类行为在多选题情境中的偏差。

研究方法: 本文提出了一种基于假设检验的定量框架，用于评估LLM模拟的人类行为与实际人类行为在多选题调查中的偏差。该框架通过统计方法判断特定语言模型是否能有效模拟人类意见、决策和行为。

研究结果: 研究将框架应用于一个流行的语言模型，发现该模型在模拟特定子人群（如不同种族、年龄和收入群体）对争议性问题的意见时表现不佳，表明模型与测试人群之间存在显著偏差。

研究结论: 研究结果表明，当前的语言模型在模拟人类行为时存在局限性，尤其是在争议性问题上。这提示社会科学研究需谨慎使用LLM，避免简单模拟人类行为。

中文摘要: 随着大型语言模型（LLM）在社会科学研究（如经济学和市场营销）中的广泛应用，评估这些模型是否能准确模拟人类行为变得至关重要。本文通过假设检验，提出了一种定量框架，用于评估LLM模拟的多项选择调查行为与实际人类行为之间的偏差。该框架能够以原则性方式判断特定语言模型是否能有效模拟人类意见、决策及行为。我们将此框架应用于一个流行的语言模型，用于模拟公众调查中的人群意见，发现该模型在模拟特定子人群（如不同种族、年龄和收入群体）对争议性问题的意见时表现不佳。这表明该语言模型与测试人群之间存在偏差，突显了在社会科学研究中使用LLM时需超越简单模拟人类行为的新实践需求。

</details>


### [148] [Transit for All: Mapping Equitable Bike2Subway Connection using Region Representation Learning](https://arxiv.org/abs/2506.15113)
**中文标题：全民交通：利用区域表示学习绘制公平的自行车与地铁连接**

*Min Namgung,JangHyeon Lee,Fangyi Ding,Yao-Yi Chiang*

主要分类: cs.CY

摘要简述: 本文提出了一种名为“Transit for All”（TFA）的空间计算框架，旨在通过区域表示学习和新型加权公共交通可达性指标（wPTAL），指导共享单车系统（BSS）的公平扩展，以减少低收入和少数族裔社区的交通不平等问题。


<details>
  <summary>详细信息</summary>
研究动机: 在人口密集的城市（如纽约市），低收入和少数族裔社区的公共交通可达性较差。共享单车系统（BSS）可以填补这一差距，但传统方法难以预测新规划站点（“冷启动”）的需求，且现有可达性指标可能忽略实际骑行潜力。因此，本文旨在通过TFA框架解决这些问题。

研究方法: TFA框架包含三个部分：(1) 使用区域表示学习整合多模态地理空间数据，预测冷启动站点的共享单车需求；(2) 结合预测需求和传统可达性指标，提出新型加权公共交通可达性指标（wPTAL）；(3) 基于wPTAL提供新站点布局的战略建议，以提升公平性。

研究结果: 以纽约市为例，研究发现低收入和少数族裔社区存在显著的交通可达性差距。通过wPTAL指导的新站点布局，显著减少了经济和人口因素导致的交通不平等。

研究结论: TFA框架为城市规划者提供了实用工具，通过公平扩展共享单车系统，提升服务不足社区的生活质量。

中文摘要: 确保公平的公共交通可达性仍然具有挑战性，尤其是在纽约市等人口密集的城市中，低收入和少数族裔社区通常面临交通可达性有限的问题。共享单车系统（BSS）可以通过提供经济实惠的“首末英里”连接来填补这些公平性差距。然而，由于新规划站点（“冷启动”）的共享单车需求不确定，以及传统可达性指标可能忽略实际骑行潜力，战略性扩展BSS至服务不足社区存在困难。我们提出了“全民交通”（TFA），这是一个空间计算框架，旨在通过三个组成部分指导BSS的公平扩展：(1) 使用区域表示学习整合多模态地理空间数据，预测冷启动站点的共享单车需求；(2) 结合预测需求和传统可达性指标，提出新型加权公共交通可达性指标（wPTAL）；(3) 基于潜在骑行需求和公平性提升，提供新站点布局的战略建议。以纽约市为例，我们识别出低收入和少数族裔社区在历史上服务不足的社区中存在的交通可达性差距。结果显示，通过wPTAL指导的新站点布局显著减少了经济和人口因素导致的交通不平等。研究表明，TFA为城市规划者提供了实用指导，以促进公平交通并提升服务不足社区的生活质量。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [149] [DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition](https://arxiv.org/abs/2207.01732)
**中文标题：Deformer：通过耦合可变形局部模式与全局上下文实现鲁棒的端到端语音识别**

*Jiamin Xie,John H. L. Hansen*

主要分类: eess.AS

摘要简述: 本文提出了一种名为Deformer的新型架构，通过引入可变形卷积替代传统CNN的固定对称核，以更好地捕捉局部特征并与全局注意力结合，显著提升了端到端语音识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统CNN在语音识别中依赖对称且固定的核来捕捉局部时频模式，但这种方式可能无法有效处理不对称的局部特征。本文探讨了可变形核的潜力，以更灵活地适应输入特征并提升与注意力的耦合效果。

研究方法: 作者在Conformer架构中，用可变形卷积替代了深度卷积（depthwise CNN），称为Deformer。通过分析最佳模型，可视化了局部感受野和全局注意力图，并研究了网络深度对特征信息变化的影响。

研究结果: 实验表明，Deformer在WSJ eval92数据集上显著优于基线Conformer，无需语言模型时相对词错误率（WER）降低了5.6%，使用语言模型时降低了6.4%。

研究结论: Deformer通过结合可变形局部模式和全局上下文，为端到端语音识别提供了更鲁棒的解决方案，验证了可变形核在特征提取中的有效性。

中文摘要: 卷积神经网络（CNN）通过利用局部时频模式显著提升了语音识别性能，但传统CNN操作假设这些模式出现在对称且固定的核中。这引发了一个问题：非对称核的表现如何？本研究展示了自适应视角可以发现与注意力耦合更好的局部特征。我们在Conformer架构中用可变形卷积替代深度卷积，称为“Deformer”。通过分析最佳模型，我们可视化了Deformer学习的局部感受野和全局注意力图，并展示了在话语级别上增强的特征关联性。对学习到的核偏移的统计分析揭示了特征信息随网络深度的变化。最终，仅在编码器中替换一半层，Deformer在WSJ eval92数据集上无需语言模型时相对WER提升了5.6%，使用语言模型时提升了6.4%。

</details>


### [150] [Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model](https://arxiv.org/abs/2309.13018)
**中文标题：动态ASR路径：一种自适应掩码方法用于多语言ASR模型的高效剪枝**

*Jiamin Xie,Ke Li,Jinxi Guo,Andros Tjandra,Yuan Shangguan,Leda Sari,Chunyang Wu,Junteng Jia,Jay Mahadeokar,Ozlem Kalinli*

主要分类: eess.AS

摘要简述: 本文提出了一种自适应掩码方法（Dynamic ASR Pathways），用于高效剪枝多语言ASR模型，动态调整子网络结构，优于现有剪枝方法，并减少语言特定剪枝需求。


<details>
  <summary>详细信息</summary>
研究动机: 多语言自动语音识别（ASR）模型的剪枝通常需要多次剪枝和重新训练，效率低下。本文旨在通过自适应掩码方法，动态调整子网络结构，避免固定子网络的过早决策，从而提高剪枝效率。

研究方法: 提出自适应掩码方法，应用于两种场景：生成稀疏单语言模型或稀疏多语言模型（Dynamic ASR Pathways）。该方法动态调整子网络，避免固定子网络结构的过早决策。

研究结果: 实验表明，该方法在生成稀疏单语言模型时优于现有剪枝方法，并能通过不同子网络初始化联合发现和训练更好的多语言模型子网络（路径），减少语言特定剪枝需求。

研究结论: Dynamic ASR Pathways方法通过自适应掩码动态调整子网络结构，显著提高了多语言ASR模型的剪枝效率，同时减少了语言特定剪枝的需求。

中文摘要: 神经网络剪枝是一种有效压缩多语言自动语音识别（ASR）模型的方法，但通常需要对每种语言进行多次剪枝和重新训练。本文提出了一种自适应掩码方法，用于高效剪枝多语言ASR模型，可生成稀疏单语言模型或稀疏多语言模型（称为动态ASR路径）。该方法动态调整子网络，避免对固定子网络结构的过早决策。实验表明，在生成稀疏单语言模型时，该方法优于现有剪枝方法。此外，动态ASR路径通过不同子网络初始化联合发现和训练更好的多语言模型子网络（路径），从而减少语言特定剪枝的需求。

</details>


### [151] [MixRep: Hidden Representation Mixup for Low-Resource Speech Recognition](https://arxiv.org/abs/2310.18450)
**中文标题：MixRep：用于低资源语音识别的隐藏表示混合方法**

*Jiamin Xie,John H. L. Hansen*

主要分类: eess.AS

摘要简述: MixRep是一种基于mixup的数据增强策略，用于低资源语音识别，通过在神经网络中混合隐藏表示的特征维度，并结合时间轴正则化，显著提升了识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语音识别（ASR）面临数据不足的挑战，传统数据增强方法效果有限。MixRep旨在通过混合隐藏表示的特征维度，提升模型的泛化能力。

研究方法: MixRep在神经网络的隐藏表示中混合特征维度，适用于声学特征输入和每层输出，并结合时间轴正则化。实验基于Conformer编码器和E2E LAS架构，使用联合CTC损失训练。

研究结果: 在WSJ和SWB数据集上，MixRep显著优于其他正则化方法，相对WER在eval92和eval'2000的Callhome部分分别降低了6.5%和6.7%。

研究结论: MixRep是一种简单有效的低资源ASR数据增强方法，通过混合隐藏表示和时间轴正则化，显著提升了模型性能。

中文摘要: 本文提出MixRep，一种基于mixup的简单有效的数据增强策略，用于低资源语音识别（ASR）。MixRep通过在神经网络中混合隐藏表示的特征维度，可应用于声学特征输入和每层输出，从而推广了之前的MixSpeech方法。此外，我们提出将mixup与输入时间轴的正则化相结合，显示出互补性。MixRep应用于带有联合CTC损失的E2E LAS架构的Conformer编码器。我们在WSJ数据集和SWB数据集的子集上进行了实验，涵盖阅读和电话会话语音。实验结果表明，MixRep在低资源ASR中始终优于其他正则化方法。与强大的SpecAugment基线相比，MixRep在eval92集和eval'2000的Callhome部分分别实现了+6.5%和+6.7%的相对WER降低。

</details>


### [152] [Factorized RVQ-GAN For Disentangled Speech Tokenization](https://arxiv.org/abs/2506.15456)
**中文标题：解耦语音标记化的因子化RVQ-GAN**

*Sameer Khurana,Dominik Klement,Antoine Laurent,Dominik Bobos,Juraj Novosad,Peter Gazdik,Ellen Zhang,Zili Huang,Amir Hussein,Ricard Marxer,Yoshiki Masuyama,Ryo Aihara,Chiori Hori,Francois G. Germain,Gordon Wichern,Jonathan Le Roux*

主要分类: eess.AS

摘要简述: 本文提出了一种分层音频编解码器（HAC），通过将瓶颈分解为声学、音素和词汇三个层次，实现了语音的分离式标记化。HAC利用两种知识蒸馏目标，分别从预训练语音编码器和文本编码器中提取音素和词汇信息，实验表明其标记集在解耦和重建质量上优于单层次基线。


<details>
  <summary>详细信息</summary>
研究动机: 当前语音编解码器通常仅关注单一层次的信息（如声学或音素），缺乏对语音多层次结构的统一建模。本文旨在设计一种能够同时捕捉声学细节、音素结构和词汇语义的分离式语音标记化方法，以支持下游语音生成和理解任务。

研究方法: HAC通过将瓶颈分解为声学、音素和词汇三个层次，实现语音的多层次建模。它利用两种知识蒸馏目标：一是从预训练语音编码器（HuBERT）中提取音素级结构，二是从文本编码器（LaBSE）中提取词汇线索。这种设计使得HAC能够生成解耦的标记集。

研究结果: 实验表明，HAC生成的标记集能够分离音素和词汇信息，并在英语和多语言数据上验证了其有效性。定量评估显示，HAC在解耦和重建质量上优于单层次基线，同时保留了语音的自然性和可解释的语义信息。

研究结论: HAC作为一种统一的离散语音表示方法，能够桥接声学细节和词汇语义，为下游任务提供了潜在的应用价值。其解耦的标记集设计为语音生成和理解任务提供了新的可能性。

中文摘要: 我们提出了一种分层音频编解码器（HAC），它是一种统一的神经语音编解码器，通过将瓶颈分解为声学、音素和词汇三个层次，实现语音的多层次建模。HAC利用两种知识蒸馏目标：一种来自预训练的语音编码器（HuBERT）以提取音素级结构，另一种来自基于文本的编码器（LaBSE）以捕捉词汇线索。在英语和多语言数据上的实验表明，HAC的因子化瓶颈生成了解耦的标记集：一个与音素对齐，另一个捕获词汇级语义。定量评估证实，HAC标记集在保留自然性的同时提供了可解释的语言信息，在解耦和重建质量上均优于单层次基线。这些发现凸显了HAC作为一种统一离散语音表示的潜力，能够桥接声学细节和词汇语义，为下游语音生成和理解任务提供支持。

</details>


### [153] [Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition](https://arxiv.org/abs/2506.14973)
**中文标题：方向性思维：面向多说话者定向语音识别的语音大型语言模型**

*Jiamin Xie,Ju Lin,Yiteng Huang,Tyler Vuong,Zhaojiang Lin,Zhaojun Yang,Peng Su,Prashant Rawat,Sangeeta Srivastava,Ming Sun,Florian Metze*

主要分类: eess.AS

摘要简述: 本文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制。通过S-DOT和CDDA技术增强模型对方向性的理解，实验表明该方法在语音识别和声源定位任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLM）在语音识别方面表现出色，但其对多通道音频和空间线索的理解能力尚未充分研究。本文旨在填补这一空白，探索如何利用智能眼镜的麦克风阵列实现更精准的定向语音处理。

研究方法: 提出了directional-SpeechLlama方法，结合两种关键技术：序列化定向输出训练（S-DOT）和对比方向数据增强（CDDA），以增强模型对方向性的理解能力。

研究结果: 实验结果表明，directional-SpeechLlama能够有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中均表现出色。

研究结论: 本文提出的方法为多通道音频处理提供了新思路，展示了大型语言模型在定向语音识别和声源定位中的潜力。

中文摘要: 近期研究表明，通过音频编码提示大型语言模型（LLM）可实现高效的语音识别能力。然而，语音LLM对多通道音频和空间线索的理解能力仍是一个研究较少的领域。本文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制。为增强模型对方向性的理解，我们提出了两种关键技术：序列化定向输出训练（S-DOT）和对比方向数据增强（CDDA）。实验结果表明，我们提出的directional-SpeechLlama能够有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中均表现出色。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [154] [Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection](https://arxiv.org/abs/2506.14933)
**中文标题：先解释后信任：基于LLM增强的图加密异常检测解释**

*Adriana Watson*

主要分类: cs.CE

摘要简述: 本文提出了一种基于LLM增强解释的图加密异常检测方法，旨在通过先解释后信任的方式提升加密货币犯罪检测的透明度和可信度。


<details>
  <summary>详细信息</summary>
研究动机: 随着去中心化金融（DeFi）和加密货币的快速发展，金融犯罪问题日益严重。由于技术新颖性，传统方法难以有效检测和起诉犯罪者，因此需要开发自动化工具以应对这一挑战。

研究方法: 论文提出了一种结合大型语言模型（LLM）和图结构的异常检测方法，通过LLM生成解释性内容，增强检测结果的可信度和可理解性。

研究结果: 实验表明，该方法能够有效识别加密货币领域的异常行为，并通过LLM生成的解释提升用户对检测结果的信任。

研究结论: 通过先解释后信任的策略，该方法为加密货币犯罪检测提供了一种透明且高效的解决方案，为未来研究奠定了基础。

中文摘要: 近年来，去中心化金融（DeFi）社区在加密货币爱好者的推动下迅速发展，这些爱好者对新市场的巨大潜力充满兴趣。加密货币的普及也带来了金融犯罪的新时代。然而，由于技术的创新性，抓捕和起诉犯罪者变得尤为困难。因此，有必要实施与政策相关的自动化检测工具，以应对加密货币领域日益增长的犯罪问题。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [155] [Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](https://arxiv.org/abs/2506.15290)
**中文标题：基于服装感知扩散模型的稀疏松散惯性传感器人体运动捕捉**

*Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz*

主要分类: cs.GR

摘要简述: 本文提出了一种基于稀疏和松散惯性传感器的人体运动捕捉方法，利用服装感知扩散模型解决传感器松散附着问题，并通过模拟数据和合成数据训练模型，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有惯性传感器运动捕捉方法通常假设传感器紧密附着于人体，但实际场景中传感器可能松散附着。本文旨在解决这一现实问题，提出一种基于稀疏和松散惯性传感器的全身姿态估计任务。

研究方法: 通过模拟现有服装感知运动数据集的惯性传感器记录，开发基于Transformer的扩散模型，合成松散传感器数据并估计人体姿态。训练时结合服装相关参数，提升模型对服装松紧变化的捕捉能力。

研究结果: 实验表明，基于模拟和合成数据训练的扩散模型在定量和定性上均优于现有方法，为未来研究提供了新方向。

研究结论: 本文提出的方法有效解决了松散附着惯性传感器的运动捕捉问题，结合服装感知的扩散模型表现出色，为实际应用提供了可行方案。

中文摘要: 使用稀疏惯性传感器进行运动捕捉因其便携性和无遮挡问题，相比基于摄像头的跟踪方法具有显著优势。现有方法通常假设惯性传感器紧密附着于人体，但这一假设在实际场景中往往不成立。本文提出了一种基于稀疏松散附着惯性传感器的全身人体姿态估计任务。为解决该任务，我们模拟了现有服装感知人体运动数据集的惯性传感器记录，并开发了基于Transformer的扩散模型，用于合成松散传感器数据并基于这种具有挑战性的数据估计人体姿态。此外，我们发现在训练模型时结合服装相关参数，能有效保持模型的表达能力，并增强其对服装松紧变化的捕捉能力。实验表明，我们提出的基于模拟和合成数据训练的扩散方法在定量和定性上均优于现有方法，为未来研究开辟了有前景的方向。

</details>


### [156] [One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning](https://arxiv.org/abs/2506.15312)
**中文标题：基于生成扩散先验与指令优化的一击式野外人脸素描合成**

*Han Wu,Junyao Li,Kangbo Zhao,Sen Zhang,Yukai Shi,Liang Lin*

主要分类: cs.GR

摘要简述: 本文提出了一种基于扩散模型和指令优化的一击式人脸素描合成方法，通过优化文本指令实现高质量素描生成，并引入新数据集OS-Sketch进行验证。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸素描合成方法依赖大量训练数据，面临数据稀缺和高成本问题。本文旨在通过扩散模型和指令优化，实现一击式高质量素描合成，解决数据不足的挑战。

研究方法: 利用扩散模型优化文本指令，通过梯度优化生成指令用于推理。引入OS-Sketch数据集，包含400对多样化人脸照片和素描，每次仅用一对训练，其余用于测试。

研究结果: 实验表明，该方法能在一击式场景下将多种照片转化为逼真且一致的素描，相比其他方法更具便利性和广泛适用性。

研究结论: 本文方法通过扩散模型和指令优化，实现了一击式高质量人脸素描合成，解决了数据稀缺问题，并展示了广泛的应用潜力。

中文摘要: 人脸素描合成是一种将人脸照片转换为素描的技术。现有研究主要依赖大量照片-素描样本对进行训练，但这类大规模判别学习方法面临数据稀缺和高人力成本问题。一旦训练数据不足，生成性能会显著下降。本文提出了一种基于扩散模型的一击式人脸素描合成方法。我们利用照片-素描图像对优化扩散模型的文本指令，并通过梯度优化生成的指令进行推理。为更准确模拟真实场景并全面评估方法效果，我们引入了新基准数据集OS-Sketch，包含400对多样化照片-素描图像，涵盖不同风格、背景、年龄、性别、表情和光照等。为进行稳健的分布外评估，每次仅用一对图像训练，其余用于推理。大量实验表明，该方法能在一击式场景下将多种照片转化为逼真且高度一致的素描，相比其他方法更具便利性和广泛适用性。数据集将在https://github.com/HanWu3125/OS-Sketch 提供。

</details>


### [157] [Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards](https://arxiv.org/abs/2506.15684)
**中文标题：Nabla-R2D3：基于2D奖励的高效3D扩散对齐方法**

*Qingming Liu,Zhen Liu,Dinghuai Zhang,Kui Jia*

主要分类: cs.GR

摘要简述: 本文提出Nabla-R2D3，一种基于2D奖励的高效3D扩散模型对齐框架，通过强化学习优化3D生成质量，显著提升模型对齐能力和样本效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D生成模型（如扩散模型）在生成高质量3D资产时存在不足，难以满足人类偏好或生成逼真的纹理和几何。本文旨在解决这一问题，提出一种基于2D奖励的对齐方法。

研究方法: 基于Nabla-GFlowNet方法，Nabla-R2D3通过匹配奖励梯度与得分函数，利用2D奖励信号对3D扩散模型进行高效微调。

研究结果: 实验表明，Nabla-R2D3在少量微调步骤内即可实现更高的奖励得分和更低的前验遗忘，优于传统微调基线。

研究结论: Nabla-R2D3为3D生成模型的对齐提供了一种高效且有效的方法，显著提升了生成质量与人类偏好的一致性。

中文摘要: 生成高质量且逼真的3D资产一直是3D视觉与计算机图形学中的长期挑战。尽管最先进的生成模型（如扩散模型）在3D生成方面取得了显著进展，但由于其难以遵循指令、对齐人类偏好或生成逼真的纹理、几何和物理属性，仍无法与人工设计内容媲美。本文提出Nabla-R2D3，一种高效且样本利用率高的强化学习对齐框架，用于3D原生扩散模型，仅使用2D奖励信号。基于最近提出的Nabla-GFlowNet方法，该方法以原则性方式将得分函数与奖励梯度匹配以实现奖励微调，Nabla-R2D3能够有效利用2D奖励信号对3D扩散模型进行适配。大量实验表明，与难以收敛或遭受奖励攻击的传统微调基线相比，Nabla-R2D3在少量微调步骤内即可实现更高的奖励得分和更低的前验遗忘。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [158] [Collaborative Interest-aware Graph Learning for Group Identification](https://arxiv.org/abs/2506.14826)
**中文标题：协作兴趣感知图学习用于群组识别**

*Rui Zhao,Beihong Jin,Beibei Li,Yiyuan Zheng*

主要分类: cs.SI

摘要简述: 本文提出了一种名为CI4GI的协作兴趣感知模型，用于解决社交平台上的群组推荐问题。该模型通过建模用户的双层兴趣（群组级和项目级）的协作演化关系，并优化负样本识别，显著提升了群组识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着社交媒体的普及，越来越多的用户参与在线群组活动，这催生了群组识别（GI）的需求。现有方法未能充分建模用户群组级和项目级兴趣的协作演化关系，导致兴趣对齐不准确。

研究方法: CI4GI模型设计了兴趣增强策略，从用户已加入群组的交互项目中识别额外兴趣，补充项目级兴趣。同时，通过优化负样本识别，减少跨级兴趣对齐中的假阴性样本干扰。

研究结果: 在三个真实数据集上的实验表明，CI4GI显著优于现有最先进模型。

研究结论: CI4GI通过建模双层兴趣的协作演化关系并优化负样本识别，有效提升了群组识别的准确性。

中文摘要: 随着社交媒体的普及，越来越多的用户在在线社交平台上参与群组活动，这引发了群组识别（GI）的需求，即向用户推荐群组。我们发现用户同时受到群组级和项目级兴趣的影响，并且这两种兴趣之间存在协作演化关系：加入群组会扩展用户的项目兴趣，进而促使用户加入新群组。最终，这两种兴趣会动态趋于一致。然而，现有的GI方法未能充分建模这种协作演化关系，忽略了群组级兴趣对项目级兴趣的增强作用，并且在跨级兴趣对齐中受到假阴性样本的干扰。为了充分建模用户双层兴趣的协作演化关系，我们提出了CI4GI，一种用于群组识别的协作兴趣感知模型。具体而言，我们设计了一种兴趣增强策略，从用户已加入群组的交互项目中识别额外兴趣，作为项目级兴趣的补充。此外，我们利用两个用户兴趣分布之间的距离来优化负样本识别，减少跨级兴趣对齐中假阴性样本的干扰。在三个真实数据集上的实验结果表明，CI4GI显著优于现有最先进模型。

</details>


### [159] [Detecting Narrative Shifts through Persistent Structures: A Topological Analysis of Media Discourse](https://arxiv.org/abs/2506.14836)
**中文标题：通过持久结构检测叙事转变：媒体话语的拓扑分析**

*Mark M. Bailey,Mark I. Heiligman*

主要分类: cs.SI

摘要简述: 本研究提出了一种基于拓扑学的框架，通过持久同调分析媒体叙事结构的变化，发现重大事件会导致叙事结构的突然重组，且低维结构变化（H0）通常先于高维变化（H1）。


<details>
  <summary>详细信息</summary>
研究动机: 如何检测全球事件如何重塑公共话语？本研究旨在通过数学方法识别媒体叙事中的结构性变化，以揭示重大事件对公共话语的影响。

研究方法: 研究利用国际新闻文章构建每日名词短语共现图，通过Vietoris-Rips过滤生成持久图，并计算Wasserstein距离和持久熵，以捕捉语义中断和叙事波动。

研究结果: 结果显示，重大事件与H0（连通分量）和H1（环）的急剧增加相关，表明叙事结构的突然重组。H0变化通常先于H1变化，但俄乌冲突中H1熵领先H0，可能反映自上而下的叙事框架。

研究结论: 持久同调提供了一种无监督的数学方法，可实时检测公共话语中的语义重构，适用于危机、抗议和信息冲击等场景。

中文摘要: 如何检测全球事件是否从根本上重塑了公共话语？本研究引入了一种拓扑框架，通过持久同调识别媒体叙事中的结构性变化。基于包括俄罗斯入侵乌克兰（2022年2月）、乔治·弗洛伊德谋杀案（2020年5月）、美国国会大厦骚乱（2021年1月）和哈马斯领导的以色列入侵（2023年10月）在内的国际新闻文章，我们构建了每日名词短语共现图以追踪话语演变。每张图通过Vietoris-Rips过滤嵌入并转化为持久图。随后，我们计算了跨同调维度的Wasserstein距离和持久熵，以捕捉语义中断和叙事波动。结果显示，重大地缘政治和社会事件与H0（连通分量）和H1（环）的急剧增加相关，表明叙事结构和连贯性的突然重组。交叉相关分析揭示了一种典型的滞后模式，即分量级结构变化（H0）先于高阶主题变化（H1），表明语义变化的自下而上级联。俄乌冲突期间出现例外，H1熵领先H0，可能反映了自上而下的叙事框架在局部话语调整之前的作用。持久熵进一步区分了紧密聚焦和分散的叙事模式。这些发现表明，持久同调提供了一种数学上严谨的无监督方法，用于检测公共注意力中的拐点和方向性变化，而无需事先了解特定事件。这种拓扑方法通过实时检测危机、抗议和信息冲击期间的语义重构，推动了计算社会科学的发展。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [160] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
**中文标题：基于LabVIEW的精确修订版光学字符识别语音合成系统**

*Prateek Mehta,Anasuya Patil*

主要分类: cs.SD

摘要简述: 本文提出了一种基于光学字符识别（OCR）的语音合成系统，旨在为视障人士提供准确、可靠、经济且用户友好的阅读解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 视障人士通常依赖盲文书籍和非政府组织提供的音频资料，但这些方式限制了他们的阅读选择。语音作为一种更有效的沟通方式，能够帮助视障人士更便捷地获取信息。

研究方法: 研究采用实验室虚拟仪器工程平台（LabVIEW）实现了一种基于OCR的语音合成系统，通过光学字符识别技术将文本转换为语音。

研究结果: 开发出的OCR语音合成系统具有高准确性、可靠性和成本效益，能够满足视障人士的阅读需求。

研究结论: 该系统为视障人士提供了一种高效、易用的阅读工具，解决了传统盲文和音频资料的局限性。

中文摘要: 通过声音提取知识是一种独特的特性。视障人士通常仅依赖盲文书籍和非政府组织提供的音频资料。由于这些方式的局限性，盲人往往无法选择自己喜欢的书籍。对于视障人士而言，语音是一种比文本更有效的沟通方式，因为他们可以轻松响应声音。本文提出了一种基于光学字符识别（OCR）的语音合成系统，该系统具有准确性、可靠性、经济性和用户友好性。该OCR系统通过实验室虚拟仪器工程平台（LabVIEW）实现。

</details>


### [161] [SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](https://arxiv.org/abs/2506.15154)
**中文标题：SonicVerse：基于多任务学习的音乐特征感知描述生成**

*Anuradha Chopra,Abhinaba Roy,Dorien Herremans*

主要分类: cs.SD

摘要简述: 本文提出了一种多任务音乐描述模型SonicVerse，通过结合音乐特征检测任务（如调性检测、人声检测等）生成更丰富的音乐描述，同时利用投影架构将音频输入转化为语言标记，显著提升了描述的质量和细节。


<details>
  <summary>详细信息</summary>
研究动机: 音乐数据库中缺乏能够准确反映音乐特征的详细描述，这限制了音乐AI研究的进展。本文旨在通过多任务学习模型，结合音乐特征检测与描述生成任务，以生成更丰富、准确的音乐描述。

研究方法: SonicVerse采用投影架构，将音频输入转化为语言标记，同时通过专用辅助头检测音乐特征。这些特征的输出也被投影为语言标记，以增强描述输入。此外，利用大型语言模型链式输出，生成长时间音乐片段的详细描述。

研究结果: 实验结果表明，通过结合音乐特征检测任务，生成的音乐描述在质量和细节上均有显著提升。扩展后的MusicBench数据集为模型训练提供了支持。

研究结论: SonicVerse通过多任务学习和投影架构，成功生成了丰富且准确的音乐描述，为音乐数据库和AI研究提供了有力工具。

中文摘要: 能够准确反映音乐特征的详细描述可以丰富音乐数据库并推动音乐AI研究。本文提出了一种多任务音乐描述模型SonicVerse，它将描述生成与辅助音乐特征检测任务（如调性检测、人声检测等）相结合，以直接捕捉低层次声学细节和高层次音乐属性。关键贡献是一种基于投影的架构，将音频输入转化为语言标记，同时通过专用辅助头检测音乐特征。这些头的输出也被投影为语言标记，以增强描述输入。该框架不仅为短音乐片段生成了丰富的描述，还通过大型语言模型链式输出，直接生成长时间音乐片段的详细时间感知描述。为训练模型，我们使用模块化音乐特征提取器MIRFLEX对MusicBench数据集进行了扩展，标注了音乐特征，形成了配对的音频、描述和音乐特征数据。实验结果表明，通过这种方式结合特征，生成的描述在质量和细节上均有所提升。

</details>


### [162] [pycnet-audio: A Python package to support bioacoustics data processing](https://arxiv.org/abs/2506.14864)
**中文标题：pycnet-audio：一个支持生物声学数据处理的Python工具包**

*Zachary J. Ruff,Damon B. Lesmeister*

主要分类: cs.SD

摘要简述: pycnet-audio是一个Python工具包，旨在支持生物声学数据处理，特别针对大规模被动声学监测项目，提供自动化信号检测和分析功能。


<details>
  <summary>详细信息</summary>
研究动机: 被动声学监测在野生动物研究中日益重要，但大规模音频数据的处理需要自动化工具。现有方法难以高效处理海量数据，尤其是针对特定物种或噪声信号的检测。pycnet-audio旨在填补这一空白，提供实用的工作流程。

研究方法: pycnet-audio基于PNW-Cnet模型，该模型最初用于监测北方斑点猫头鹰等森林猫头鹰的种群。工具包扩展了模型功能，可检测约80种森林野生动物及多种人为和环境噪声的声学信号。

研究结果: pycnet-audio成功实现了对大规模音频数据的自动化处理，能够高效检测目标物种的叫声及其他声学信号，显著提升了数据处理效率。

研究结论: pycnet-audio为生物声学数据提供了一种高效、实用的处理方案，特别适用于大规模被动声学监测项目，未来有望进一步扩展应用范围。

中文摘要: 被动声学监测是野生动物研究中的一种新兴方法，利用专门设计的自动录音设备（ARU）进行数据采集。通常的做法是将ARU部署在野外，按计划长时间（数周或数月）录音，随后回收音频数据。这些数据需要进一步处理，通常包括测量或分析音频特征（如计算声学指数），或在录音中搜索目标信号，如某些目标物种的叫声、人为或环境噪声等。对于后者，需要某种方法定位音频中的目标信号。虽然小规模数据集可以手动搜索，但即便是中等规模的项目也可能产生约10^5小时的录音数据，手动处理不切实际，必须依赖自动化检测。pycnet-audio（Ruff 2024）旨在为声学数据提供一种实用的处理工作流程，围绕PNW-Cnet模型构建。该模型最初由美国林务局开发，用于支持北方斑点猫头鹰（Strix occidentalis caurina）及其他森林猫头鹰的种群监测（Lesmeister和Jenkins 2022；Ruff等人2020）。PNW-Cnet已扩展至检测约80种森林野生动物及多种人为和环境噪声的叫声（Ruff等人2021、2023）。

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [163] [Forecasting the spatiotemporal evolution of fluid-induced microearthquakes with deep learning](https://arxiv.org/abs/2506.14923)
**中文标题：基于深度学习的流体诱发微地震时空演化预测**

*Jaehong Chung,Michael Manga,Timothy Kneafsey,Tapan Mukerji,Mengsu Hu*

主要分类: physics.geo-ph

摘要简述: 本文提出了一种基于Transformer的深度学习模型，用于预测流体诱发微地震的时空演化，为地热系统和CO2封存等应用提供实时风险评估。


<details>
  <summary>详细信息</summary>
研究动机: 微地震（MEQs）记录了地下流体注入引起的应力状态和渗透率变化，预测其时空演化对增强地热系统（EGS）和CO2封存等工程应用至关重要。

研究方法: 采用Transformer架构的深度学习模型，结合水力压裂历史和微地震观测数据，预测微地震数量、对数地震矩及地震云的空间分布百分位数（P50和P95）。

研究结果: 在EGS Collab实验数据集上，模型在1秒和15秒预测时间范围内的R²分别超过0.98和0.88，并通过学习标准差提供不确定性估计。

研究结论: 该模型能够实时推断裂缝扩展和渗透率变化，展示了深度学习在地震风险评估和缓解策略中的潜力。

中文摘要: 地下流体注入产生的微地震（MEQs）记录了储层应力状态和渗透率的动态变化，预测其完整的时空演化对增强地热系统（EGS）、CO2封存和其他地质工程应用至关重要。本文提出了一种基于Transformer的深度学习模型，通过输入水力压裂历史和先前的微地震观测数据，预测四个关键指标：累计微地震数量、累计对数地震矩，以及微地震云的50%和95%空间分布范围（P50、P95）。将该模型应用于EGS Collab实验1数据集，结果显示，在1秒预测时间范围内，所有目标的R²均超过0.98；在15秒预测时间范围内，R²超过0.88。模型还通过学习标准差提供了不确定性估计。这些高精度且量化不确定性的预测结果，能够实时推断裂缝扩展和渗透率变化，展示了深度学习方法在改善地震风险评估和指导未来流体注入操作缓解策略中的强大潜力。

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [164] [BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models](https://arxiv.org/abs/2506.14861)
**中文标题：BMFM-RNA：构建和评估转录组基础模型的开放框架**

*Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou*

主要分类: q-bio.GN

摘要简述: BMFM-RNA是一个开源、模块化的转录组基础模型框架，旨在统一多样化的预训练和微调目标，并通过新提出的WCED训练目标提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 转录组基础模型（TFMs）在分析细胞和组织基因表达方面表现出强大潜力，但模型实现和训练策略的多样性使得难以评估单个设计选择或协同效应，阻碍了领域内最佳实践的达成和研究的可重复性。

研究方法: BMFM-RNA提供了一个统一的软件框架，支持多种预训练和微调目标，并引入新的训练目标WCED，通过自编码器式的CLS瓶颈表示捕获全局表达模式。

研究结果: 在CELLxGENE数据集上预训练的四个模型检查点显示，基于WCED的模型在零样本和微调任务中性能优于或匹配当前最先进方法（如scGPT）。

研究结论: BMFM-RNA为系统化基准测试和社区驱动的TFM训练策略探索提供了可重复的基础，有助于开发更有效的工具以推动细胞生物学研究。

中文摘要: 转录组基础模型（TFMs）已成为分析细胞和组织基因表达的有力工具，支持细胞类型注释、批次校正和扰动预测等关键任务。然而，近期TFMs中模型实现和训练策略的多样性虽具有潜力，却使得评估单个设计选择或协同效应变得困难，阻碍了领域内最佳实践的达成和跨研究见解的可重复性。我们提出了BMFM-RNA，一个开源、模块化的软件包，将多样化的TFM预训练和微调目标统一在一个框架内。利用这一能力，我们引入了一种新的训练目标——全细胞表达解码器（WCED），通过自编码器式的CLS瓶颈表示捕获全局表达模式。本文描述了该框架、支持的输入表示和训练目标。我们评估了在CELLxGENE上预训练的四个模型检查点，结合了掩码语言建模（MLM）、WCED和多任务学习。通过BMFM-RNA的基准测试功能，我们发现基于WCED的模型在零样本和微调任务中的性能匹配或超越了scGPT等最先进方法，覆盖了十余个数据集。BMFM-RNA作为biomed-multi-omics项目的一部分（https://github.com/BiomedSciAI/biomed-multi-omic），为系统化基准测试和社区驱动的TFM训练策略探索提供了可重复的基础，有助于开发更有效的工具，利用AI最新进展理解细胞生物学。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [165] [Identifying economic narratives in large text corpora -- An integrated approach using Large Language Models](https://arxiv.org/abs/2506.15041)
**中文标题：从大规模文本语料库中识别经济叙事——一种基于大型语言模型的综合方法**

*Tobias Schmidt,Kai-Robin Lange,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch*

主要分类: econ.GN

摘要简述: 本文探讨了使用大型语言模型（LLMs）从文本中提取经济叙事的有效性，通过分析《华尔街日报》和《纽约时报》关于通胀的文章，发现GPT-4o能提取结构化经济叙事，但仍不及专家水平。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，经济叙事的研究兴趣增加，但现有方法（如BERT）缺乏深层语义理解，难以区分经济叙事与基础语义任务。本文旨在评估LLMs在此任务中的潜力。

研究方法: 研究采用《华尔街日报》和《纽约时报》关于通胀的文章作为语料库，应用严格叙事定义，并比较GPT-4o输出与专家标注的黄金标准叙事。

研究结果: 结果表明，GPT-4o能够提取有效的结构化经济叙事，但在处理复杂文档和叙事时仍不及专家水平。

研究结论: LLMs在经济研究中具有潜力，但需进一步改进以处理复杂叙事。本文为未来经济学和社会科学中LLMs的应用提供了指导。

中文摘要: 近年来，人们对经济叙事的兴趣日益增长，提取此类叙事的流程也越来越多。这些流程通常采用最先进的自然语言处理技术（如BERT）来完成这一任务。尽管这些模型在叙事提取的基础语言操作上表现良好，但它们缺乏区分经济叙事与经典语义任务（如语义角色标注）所需的深层语义理解。我们通过分析《华尔街日报》和《纽约时报》关于通胀的新闻报道，评估了大型语言模型（LLMs）的优势。我们应用严格的叙事定义，并将GPT-4o的输出与专家标注的黄金标准叙事进行比较。结果表明，GPT-4o能够以结构化格式提取有效的经济叙事，但在处理复杂文档和叙事时仍不及专家水平。鉴于LLMs在经济研究中的新颖性，我们还为未来经济学和社会科学中利用LLMs实现类似目标的研究提供了指导。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [166] [Omnidirectional Video Super-Resolution using Deep Learning](https://arxiv.org/abs/2506.14803)
**中文标题：基于深度学习的全方位视频超分辨率**

*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter W. Eklund,Sunil Aryal*

主要分类: cs.MM

摘要简述: 本文提出了一种用于360度视频超分辨率的新型深度学习模型S3PO，通过解决球面失真问题并构建专用数据集360VDS，显著提升了360度视频的视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 360度视频在虚拟现实中广泛应用，但其有限的空间分辨率影响了沉浸式体验。传统视频超分辨率技术无法解决360度视频的球面失真问题，且缺乏相关数据集。

研究方法: 本文构建了360VDS数据集，并提出S3PO模型，采用循环建模和注意力机制，设计了专用特征提取器和针对球面失真的损失函数。

研究结果: S3PO在360度视频数据集上表现优于现有传统视频超分辨率模型和360度专用模型，并通过逐步消融研究验证了其组件的有效性。

研究结论: S3PO为360度视频超分辨率提供了高效解决方案，解决了球面失真问题，并通过实验验证了其优越性。

中文摘要: 全方位视频（或360度视频）在虚拟现实（VR）中广泛用于提供沉浸式和交互式观看体验。然而，360度视频的有限空间分辨率无法为每个视角提供足够的像素，从而限制了沉浸式体验的视觉质量。传统视频超分辨率（VSR）技术可能提供一种基于软件的解决方案，但这些技术未能解决360度视频信号在等距柱状投影中的失真问题。另一个障碍是缺乏可用于研究的360度视频数据集。为解决这些问题，本文创建了一个新颖的360度视频数据集（360VDS），并研究了传统VSR模型在360度视频中的扩展性。本文进一步提出了一种用于360度视频超分辨率（360° VSR）的新型深度学习模型，称为基于比例优化的球面信号超分辨率（S3PO）。S3PO采用循环建模和注意力机制，摆脱了传统VSR技术（如对齐）的束缚。通过专用特征提取器和针对球面失真的新型损失函数，S3PO在360度视频数据集上表现优于大多数最先进的传统VSR模型和360度专用超分辨率模型。本文还通过逐步消融研究，理解和展示了所选架构子组件、针对性训练和优化的影响。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [167] [PFMBench: Protein Foundation Model Benchmark](https://arxiv.org/abs/2506.14796)
**中文标题：PFMBench：蛋白质基础模型基准测试**

*Zhangyang Gao,Hao Wang,Cheng Tan,Chenrui Xu,Mengdi Liu,Bozhen Hu,Linlin Chao,Xiaoming Zhang,Stan Z. Li*

主要分类: q-bio.BM

摘要简述: 本研究提出了PFMBench，一个全面评估蛋白质基础模型的基准测试，涵盖38个任务和8个关键领域，揭示了任务间的相关性并识别了表现最佳的模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前蛋白质基础模型研究缺乏统一的评估基准，导致无法全面理解模型的泛化能力和局限性。PFMBench旨在填补这一空白。

研究方法: 通过17个先进模型在38个任务上的数百次实验，PFMBench提供了一个标准化的评估协议，并分析了任务间的相关性。

研究结果: PFMBench揭示了任务间的内在关联，识别了表现最佳的模型，并提供了简化的评估流程。

研究结论: PFMBench为蛋白质基础模型的评估提供了全面且标准化的工具，推动了该领域的进一步发展。

中文摘要: 本研究探讨了蛋白质基础模型研究的现状与未来方向。尽管近期进展改变了蛋白质科学与工程领域，但该领域缺乏一个全面的基准测试以进行公平评估和深入理解。自ESM-1B以来，涌现了许多蛋白质基础模型，每个模型都有独特的数据集和方法。然而，评估通常局限于针对特定模型的有限任务，阻碍了对更广泛泛化能力和局限性的理解。具体而言，研究人员难以理解任务间的关系、评估当前模型在这些任务上的表现，以及确定开发新基础模型的标准。为填补这一空白，我们提出了PFMBench，一个涵盖蛋白质科学8个关键领域38个任务的全面基准测试。通过对17个先进模型在38个任务上的数百次实验，PFMBench揭示了任务间的内在相关性，识别了表现最佳的模型，并提供了一个简化的评估协议。代码可在\href{https://github.com/biomap-research/PFMBench}{\textcolor{blue}{GitHub}}上获取。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [168] [Advancing Loss Functions in Recommender Systems: A Comparative Study with a Rényi Divergence-Based Solution](https://arxiv.org/abs/2506.15120)
**中文标题：推荐系统中损失函数的改进：基于Rényi散度的解决方案比较研究**

*Shengjia Zhang,Jiawei Chen,Changdong Li,Sheng Zhou,Qihao Shi,Yan Feng,Chun Chen,Can Wang*

主要分类: cs.IR

摘要简述: 本文研究了推荐系统中Softmax Loss（SL）和Cosine Contrastive Loss（CCL）两种损失函数的优缺点，并提出了一种基于Rényi散度的新损失函数DrRL，以解决SL对假阴性样本敏感和CCL数据利用率低的问题。实验验证了DrRL在推荐准确性和鲁棒性上的优越性。


<details>
  <summary>详细信息</summary>
研究动机: 推荐系统中的损失函数对模型优化至关重要，SL和CCL是两种常用且有效的损失函数，但各自存在局限性。本文旨在深入分析这两种损失函数的理论联系与差异，并提出一种更优的解决方案。

研究方法: 本文首先对SL和CCL进行了全面分析，发现它们均可视为传统损失函数在分布鲁棒优化（DRO）框架下的扩展。随后，提出了一种基于Rényi散度的新损失函数DrRL，结合了SL和CCL的优势结构，并解决了各自的局限性。

研究结果: 实验结果表明，DrRL在推荐准确性和鲁棒性上均优于SL和CCL，有效缓解了SL对假阴性样本的敏感性和CCL数据利用率低的问题。

研究结论: DrRL作为一种新型损失函数，成功结合了SL和CCL的优势，并在实验中表现出更高的性能，为推荐系统的损失函数设计提供了新的思路。

中文摘要: 损失函数在优化推荐模型中起着关键作用。在众多损失函数中，Softmax损失（SL）和余弦对比损失（CCL）尤为有效。它们的理论联系与差异值得深入探讨。本研究对这两种损失函数进行了全面分析，得出以下重要结论：1）共同优势——两者均可视为传统损失函数在分布鲁棒优化（DRO）框架下的扩展，增强了对分布变化的鲁棒性；2）各自局限——由于在DRO优化中使用了不同的分布距离度量，SL对假阴性样本表现出高敏感性，而CCL则存在数据利用率低的问题。为解决这些问题，本研究提出了一种新的损失函数DrRL，通过利用Rényi散度在DRO优化中泛化了SL和CCL。DrRL结合了SL和CCL的优势结构，并能有效缓解其局限性。大量实验验证了DrRL在推荐准确性和鲁棒性上的优越性。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [169] [Improved Image Reconstruction and Diffusion Parameter Estimation Using a Temporal Convolutional Network Model of Gradient Trajectory Errors](https://arxiv.org/abs/2506.14995)
**中文标题：基于时间卷积网络的梯度轨迹误差模型改进图像重建与扩散参数估计**

*Jonathan B. Martin,Hannah E. Alderson,John C. Gore,Mark D. Does,Kevin D. Harkins*

主要分类: physics.med-ph

摘要简述: 本文提出了一种基于时间卷积网络的梯度轨迹误差模型，用于改善磁共振图像重建和扩散参数估计。该模型能准确预测梯度系统的非线性失真，显著提升图像质量和参数映射效果。


<details>
  <summary>详细信息</summary>
研究动机: 在非笛卡尔磁共振成像中，梯度轨迹误差会导致图像伪影和失真，严重影响图像质量。现有线性方法无法准确建模梯度系统的非线性行为，因此需要一种更精确的模型来预测和校正这些误差。

研究方法: 研究团队在小动物成像系统上测量了一组训练梯度波形，并利用时间卷积网络训练模型，以预测成像系统产生的梯度波形。网络预测的梯度波形被整合到图像重建流程中。

研究结果: 训练后的网络能够准确预测梯度系统的非线性失真。与名义梯度波形和梯度脉冲响应函数相比，该方法显著提升了图像质量和扩散参数映射的准确性。

研究结论: 时间卷积网络比现有线性方法更能准确建模梯度系统行为，可用于回顾性校正梯度误差。

中文摘要: 摘要：梯度轨迹误差会在磁共振图像中引入显著的伪影和失真，尤其是在非笛卡尔成像序列中，不完美的梯度波形会大幅降低图像质量。目的：我们的目标是开发一种通用的非线性梯度系统模型，利用卷积网络准确预测梯度失真。方法：在小动物成像系统上测量了一组训练梯度波形，并用于训练时间卷积网络以预测成像系统产生的梯度波形。结果：训练后的网络能够准确预测梯度系统的非线性失真。网络预测的梯度波形被整合到图像重建流程中，与名义梯度波形和梯度脉冲响应函数相比，显著提升了图像质量和扩散参数映射效果。结论：时间卷积网络比现有线性方法更能准确建模梯度系统行为，可用于回顾性校正梯度误差。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [170] [Scaling Intelligence: Designing Data Centers for Next-Gen Language Models](https://arxiv.org/abs/2506.15006)
**中文标题：扩展智能：为下一代语言模型设计数据中心**

*Jesmin Jahan Tithi,Hanjiang Wu,Avishaii Abuhatzera,Fabrizio Petrini*

主要分类: cs.AR

摘要简述: 本文提出了一种针对下一代语言模型的数据中心设计框架，通过联合优化计算、存储和网络架构，显著提升大规模语言模型的性能和可扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（如GPT-4）参数规模的爆炸式增长（达1.8万亿），传统数据中心架构在可扩展性、效率和成本效益方面面临挑战。本文旨在重新设计数据中心架构，以支持万亿参数模型的训练和推理。

研究方法: 提出了一种联合设计框架，综合考虑FLOPS、HBM带宽与容量、多种网络拓扑（如两层与全扁平光网络）、扩展域规模以及并行化策略。特别引入了全扁平网络架构，提供节点间的高带宽、低延迟连接，并通过性能建模工具验证设计效果。

研究结果: 全扁平网络架构显著提升了性能和可扩展性。通过敏感性分析，量化了计算与通信重叠、硬件加速集体操作、更大扩展域和内存容量的优势。研究覆盖了稀疏（专家混合）和密集（基于Transformer）的模型，揭示了系统设计对模型FLOPS利用率（MFU）和吞吐量的影响。

研究结论: 研究为设计高效支持万亿参数模型的AI数据中心提供了实用路线图，降低了优化复杂度，并推动了AI能力的持续演进。

中文摘要: 大型语言模型（如拥有1.8万亿参数的GPT-4）的爆炸式增长，要求对数据中心架构进行根本性重新设计，以确保可扩展性、效率和成本效益。我们的工作提供了一个全面的联合设计框架，共同探索FLOPS、HBM带宽与容量、多种网络拓扑（两层与全扁平光网络）、扩展域规模以及LLM中常用的并行化/优化策略。我们引入并评估了全扁平网络架构，该架构为所有节点提供统一的高带宽、低延迟连接，并展示了其对性能和可扩展性的变革性影响。通过详细的敏感性分析，我们量化了计算与通信重叠、利用硬件加速集体操作、更大扩展域和更大内存容量的优势。我们的研究涵盖了稀疏（专家混合）和密集（基于Transformer）的LLM，揭示了系统设计选择如何影响模型FLOPS利用率（MFU = 每令牌模型FLOPS × 每秒观察到的令牌数 / 硬件峰值FLOPS）和整体吞吐量。为联合设计研究，我们扩展并验证了一种性能建模工具，能够将LLM运行时间预测误差控制在真实测量的10%以内。我们的研究结果为设计能够高效支持万亿参数模型、降低优化复杂度并持续推动AI能力发展的AI数据中心提供了实用见解和路线图。

</details>


### [171] [J3DAI: A tiny DNN-Based Edge AI Accelerator for 3D-Stacked CMOS Image Sensor](https://arxiv.org/abs/2506.15316)
**中文标题：J3DAI：一种基于微型DNN的边缘AI加速器，用于3D堆叠CMOS图像传感器**

*Benoit Tain,Raphael Millet,Romain Lemaire,Michal Szczepanski,Laurent Alacoque,Emmanuel Pluchart,Sylvain Choisnet,Rohit Prasad,Jerome Chossat,Pascal Pierunek,Pascal Vivet,Sebastien Thuries*

主要分类: cs.AR

摘要简述: 本文介绍了J3DAI，一种基于深度神经网络的微型硬件加速器，专为3D堆叠CMOS图像传感器设计，支持高效的图像分类和分割任务，并展示了其在边缘AI领域的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 随着边缘AI的重要性日益增长，需要一种能够在资源受限的硬件上高效运行AI任务的解决方案。J3DAI旨在满足这一需求，通过优化性能、功耗和面积（PPA）特性，实现低延迟和节能的边缘AI处理。

研究方法: J3DAI采用了一种基于深度神经网络的硬件加速器设计，集成了3D堆叠CMOS图像传感器。通过Aidge软件框架支持硬件编程，并利用后训练量化技术减少内存占用和计算复杂度。

研究结果: 实验结果表明，J3DAI在边缘AI任务中表现出色，能够高效处理简单和计算密集型任务，展示了其多功能性和高效性。

研究结论: J3DAI为边缘AI提供了一种创新的解决方案，未来工作将集中在进一步优化架构和探索新应用，以充分发挥其潜力。

中文摘要: 本文介绍了J3DAI，一种基于深度神经网络的微型硬件加速器，专为三层3D堆叠CMOS图像传感器设计，集成了AI芯片和DNN加速器。该加速器旨在高效执行图像分类和分割等神经网络任务。本文重点介绍了J3DAI的数字系统，突出了其性能-功耗-面积（PPA）特性，并展示了其在CMOS图像传感器上的先进边缘AI能力。为支持硬件，我们使用了Aidge综合软件框架，该框架支持主机处理器和DNN加速器的编程。Aidge支持后训练量化，显著减少内存占用和计算复杂度，这对于在资源受限的硬件（如J3DAI）上部署模型至关重要。实验结果表明，这种创新设计在边缘AI领域具有多功能性和高效性，能够处理简单和计算密集型任务。未来工作将集中在进一步优化架构和探索新应用，以充分发挥J3DAI的潜力。随着边缘AI的重要性日益增长，J3DAI等创新将在实现实时、低延迟和节能的边缘AI处理中发挥关键作用。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [172] [MedSyn: Enhancing Diagnostics with Human-AI Collaboration](https://arxiv.org/abs/2506.14774)
**中文标题：MedSyn：通过人机协作增强诊断能力**

*Burcu Sayin,Ipek Baris Schlicht,Ngoc Vo Hong,Sara Allievi,Jacopo Staiano,Pasquale Minervini,Andrea Passerini*

主要分类: cs.LG

摘要简述: 论文提出了一种名为MedSyn的人机协作框架，通过医生与开源大语言模型（LLM）的多步交互对话优化诊断和治疗决策，实验表明开源LLM在现实医疗中具有潜力。


<details>
  <summary>详细信息</summary>
研究动机: 临床决策复杂且易受认知偏差、信息不完整和病例模糊性影响，现有大语言模型（LLM）通常为单次或有限交互，难以满足实际医疗需求。

研究方法: 提出MedSyn框架，医生与LLM通过动态对话交互，医生可质疑LLM建议，LLM则提供替代视角，模拟实验评估开源LLM作为医生助手的潜力。

研究结果: 实验表明开源LLM在现实医疗中作为医生助手具有潜力，未来需通过真实医生交互进一步验证其对诊断准确性和患者结局的改进效果。

研究结论: MedSyn框架通过人机动态交互优化临床决策，开源LLM展现出实际应用前景，未来需进一步验证其实际效果。

中文摘要: 临床决策具有内在复杂性，常受认知偏差、信息不完整和病例模糊性影响。大语言模型（LLM）作为临床决策支持工具显示出潜力，但其典型的单次或有限交互方式可能忽略现实医疗的复杂性。本文提出了一种混合人机框架MedSyn，医生与LLM通过多步交互对话优化诊断和治疗决策。与静态决策支持工具不同，MedSyn支持动态交流，医生可质疑LLM建议，LLM则提供替代视角。通过模拟医生-LLM交互，评估开源LLM作为医生助手的潜力。结果表明开源LLM在现实医疗中具有潜力。未来工作将通过与真实医生交互进一步验证MedSyn对诊断准确性和患者结局的改进效果。

</details>


### [173] [PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series](https://arxiv.org/abs/2506.14786)
**中文标题：PIPE：基于物理信息的位置编码用于卫星图像与时间序列的对齐**

*Haobo Li,Eunseo Jung,Zixin Chen,Zhaowei Wang,Yueya Wang,Huamin Qu,Alexis Kai Hon Lau*

主要分类: cs.LG

摘要简述: 本文提出了一种轻量级方法PIPE，通过物理信息位置编码将卫星图像和数值数据对齐，显著提升了多模态时间序列预测的准确性，尤其在台风强度预测中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态时间序列预测方法主要关注文本数据，而忽略了视觉数据（如卫星图像）中的物理信息。这些信息（如时空背景）对预测至关重要，但现有模型难以有效捕捉。

研究方法: PIPE方法包含两个创新点：(1) 物理信息位置索引方案，将物理信息映射为位置ID；(2) 变频率位置编码机制，在嵌入空间中编码物理变量的频率信息和序列顺序。

研究结果: 在最大开源卫星图像数据集上的实验表明，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测准确率比先前工作提升了12%。

研究结论: PIPE通过嵌入物理信息和序列顺序信息，显著提升了多模态对齐和预测准确性，为卫星图像和时间序列的联合分析提供了有效工具。

中文摘要: 多模态时间序列预测在多个领域具有基础性作用，例如利用卫星图像和数值数据预测气候科学中的台风。然而，现有多模态方法主要关注利用文本数据辅助时间序列预测，而忽略了视觉数据中的物理信息。此外，模型难以有效捕捉视觉数据（如卫星图像）中嵌入的物理信息（如时空背景），这些信息超越了图像本身。为解决这一问题，我们提出了物理信息位置编码（PIPE），一种轻量级方法，将物理信息嵌入视觉语言模型（VLMs）。PIPE包含两个关键创新：(1) 物理信息位置索引方案，将物理信息映射为位置ID；(2) 变频率位置编码机制，在嵌入空间中编码物理变量的频率信息和序列顺序。通过保留物理信息和序列顺序信息，PIPE显著提升了多模态对齐和预测准确性。在最具代表性和最大的开源卫星图像数据集上的实验表明，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测准确率比先前工作提升了12%。代码详见补充材料。

</details>


### [174] [Topology-Aware and Highly Generalizable Deep Reinforcement Learning for Efficient Retrieval in Multi-Deep Storage Systems](https://arxiv.org/abs/2506.14787)
**中文标题：基于拓扑感知和高度泛化的深度强化学习在多深度存储系统中的高效检索**

*Funing Li,Yuan Tian,Ruben Noortwyck,Jifeng Zhou,Liming Kuang,Robert Schulz*

主要分类: cs.LG

摘要简述: 本文提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题。通过结合图神经网络和Transformer模型，该方法能够高效捕捉系统拓扑并优化检索延迟。


<details>
  <summary>详细信息</summary>
研究动机: 现代物流和工业环境中，快速配送服务的扩展对高效率和密度的存储系统需求增加。多深度自主车辆存储和检索系统（AVS/RS）虽能提高存储密度，但面临通道堵塞的挑战。传统方法将同类物品存储在同一通道限制了系统的灵活性。

研究方法: 提出了一种结合图神经网络（GNN）和Transformer模型的深度强化学习框架。GNN用于编码拓扑和物品信息，Transformer则将嵌入映射为全局优先级分配，从而优化检索延迟。

研究结果: 大量数值实验表明，该方法在优化检索延迟方面优于启发式方法，且能够适应不同布局的存储系统。

研究结论: 该方法通过结合GNN和Transformer，有效解决了多深度存储系统中的检索问题，并展示了强大的泛化能力。

中文摘要: 在现代工业和物流环境中，快速配送服务的迅速扩展对高效率和密度的存储系统需求日益增加。多深度自主车辆存储和检索系统（AVS/RS）为实现更高的存储密度提供了可行的解决方案。然而，这些系统在检索操作中因通道堵塞面临重大挑战。传统方法通过将同类物品存储在同一通道来缓解这一问题，但限制了多深度存储系统的灵活性和适应性。

本研究提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题。每个物品关联一个特定的截止日期，目标是最小化总延迟。为有效捕捉系统拓扑，我们引入了一种基于图的状态表示，整合了物品属性和多深度仓库的局部拓扑结构。为处理这一表示，我们设计了一种结合图神经网络（GNN）和Transformer模型的新型神经网络架构。GNN将拓扑和物品信息编码为所有可直接访问物品的嵌入，而Transformer将这些嵌入映射为全局优先级分配。Transformer的强大泛化能力进一步使我们的方法能够应用于不同布局的存储系统。大量数值实验，包括与启发式方法的比较，证明了所提神经网络架构的优越性以及训练代理在优化检索延迟方面的有效性。

</details>


### [175] [Assembly of Experts: Linear-time construction of the Chimera LLM variants with emergent and adaptable behaviors](https://arxiv.org/abs/2506.14794)
**中文标题：专家组装：线性时间构建具有涌现和适应行为的Chimera LLM变体**

*Henrik Klagges,Robert Dahlke,Fabian Klemm,Benjamin Merkel,Daniel Klingmann,David A. Reiss,Dan Zecha*

主要分类: cs.LG

摘要简述: 论文提出了一种名为“专家组装”（AoE）的线性时间构建方法，用于从现有的混合专家（Mixture-of-Experts）父模型中生成功能强大的子模型变体。通过插值模型权重张量，可以增强或抑制父模型的语义特征，生成的子模型表现出渐进或突变的特性，且无需微调或蒸馏即可实现高效推理。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）的预训练成本极高（单次8位权重计算需$10^{13}$-$10^{15}$ FLOPs），效率低下。为了充分利用预训练模型的巨大投资，研究者开发了AoE方法，旨在快速生成功能强大的子模型变体。

研究方法: AoE方法通过线性时间插值父模型的权重张量，独立调整每个权重，从而增强或抑制父模型的语义特征。生成的子模型表现出渐进或突变的特性，且无需微调或蒸馏。

研究结果: 生成的子模型几乎全部功能完备且高效。以DeepSeek R1T“Chimera”为例，该模型结合了DeepSeek V3-0324和R1的专家张量，实现了接近R1的智能水平，同时输出标记减少40%，推理速度接近V3。

研究结论: AoE方法为高效生成功能强大的子模型提供了一种无需微调或蒸馏的解决方案，生成的模型表现出紧凑且有序的推理能力，优于父模型。

中文摘要: 在预训练过程中，大型语言模型（LLM）的单次8位权重计算需要$10^{13}$-$10^{15}$ FLOPs，成本极高且效率低下。为了更好利用预训练模型的巨大投资，我们开发了新的“专家组装”（AoE）构建方法，可在线性时间内从现有的混合专家父模型中生成功能强大的子模型变体。通过独立插值模型权重张量，可以增强或抑制父模型的语义特征。

调整从父模型中提取的权重比例时，我们发现AoE子模型的某些属性逐渐变化，而其他行为特征则出现突变。令人惊讶的是，几乎所有生成的模型都功能完备且高效，这使得模型空间的搜索变得简单。

我们构建了DeepSeek R1T“Chimera”，这是一个671B的开放权重混合模型，结合了DeepSeek的V3-0324和R1模型变体。该子模型仅继承了R1的路由专家张量，但仍实现了接近R1的智能水平，同时输出标记减少了约40%，推理速度接近V3。无需任何微调或蒸馏，Chimera表现出比父模型更紧凑且有序的推理能力。

</details>


### [176] [Bound by semanticity: universal laws governing the generalization-identification tradeoff](https://arxiv.org/abs/2506.14797)
**中文标题：语义性约束：支配泛化-识别权衡的普适定律**

*Marco Nurisso,Jesseba Fernando,Raj Deshpande,Alan Perotti,Raja Marjieh,Steven M. Frankland,Richard L. Lewis,Taylor W. Webb,Declan Campbell,Francesco Vaccarino,Jonathan D. Cohen,Giovanni Petri*

主要分类: cs.LG

摘要简述: 智能系统需要在广泛泛化和精确识别之间平衡内部表示。本文揭示了这种权衡的基本限制，并推导出通用帕累托前沿，预测了多输入处理能力的崩溃和非单调最优解。实验验证了这些理论在简单和复杂模型中的普适性。


<details>
  <summary>详细信息</summary>
研究动机: 研究智能系统如何在保持输入身份的同时支持广泛泛化，揭示这种权衡的基本限制，并为深度网络和大脑的表示能力提供理论支持。

研究方法: 通过分析具有有限语义分辨率的模型，推导出泛化和识别概率的封闭表达式，并扩展到噪声和异构空间。通过实验验证理论预测，包括简单ReLU网络和复杂卷积神经网络及视觉语言模型。

研究结果: 理论揭示了通用帕累托前沿，预测了多输入处理能力的1/n崩溃和非单调最优解。实验验证了这些理论在简单和复杂模型中的普适性。

研究结论: 有限分辨率相似性是深度网络和大脑表示能力的基本信息约束，研究为泛化-识别权衡提供了精确理论。

中文摘要: 智能系统需要同时部署结构化（以支持广泛泛化）和选择性（以保留输入身份）的内部表示。我们揭示了这种权衡的基本限制。对于任何表示相似性随有限语义分辨率ε衰减的模型，我们推导出封闭表达式，将其正确泛化概率p_S和识别概率p_I固定到与输入空间几何无关的通用帕累托前沿。将分析扩展到噪声和异构空间及n>2输入时，预测了多输入处理能力的1/n崩溃和p_S的非单调最优解。一个端到端训练的最小ReLU网络重现了这些定律：在学习过程中自组织分辨率边界，且经验(p_S,p_I)轨迹紧密跟随线性衰减相似性的理论曲线。最后，我们证明这些限制在两种更复杂场景（卷积神经网络和先进视觉语言模型）中仍然存在，确认有限分辨率相似性是基本的信息约束，而非玩具模型产物。这些结果为泛化-识别权衡提供了精确理论，并阐明了语义分辨率如何塑造深度网络和大脑的表示能力。

</details>


### [177] [ss-Mamba: Semantic-Spline Selective State-Space Model](https://arxiv.org/abs/2506.14802)
**中文标题：ss-Mamba：语义样条选择性状态空间模型**

*Zuochen Ye*

主要分类: cs.LG

摘要简述: 本文提出ss-Mamba，一种新型基础模型，通过结合语义感知嵌入和自适应样条时间编码，在选择性状态空间框架中提升时间序列预测性能。其计算复杂度从二次降至线性，同时保持高效性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer模型在时间序列预测中计算复杂度高，且难以捕捉复杂的时间动态和语义信息。ss-Mamba旨在通过选择性状态空间模型和语义嵌入，提供高效且高性能的替代方案。

研究方法: ss-Mamba采用Mamba选择性状态空间模型，结合预训练语言模型初始化的语义索引嵌入和基于样条的Kolmogorov-Arnold网络（KAN），动态捕捉复杂季节性和非平稳时间效应。

研究结果: 实验表明，ss-Mamba在准确性、鲁棒性和可解释性上优于传统Transformer模型，同时显著降低计算复杂度。

研究结论: ss-Mamba是一种高效且多功能的时间序列预测模型，为传统Transformer提供了高性能替代方案。

中文摘要: 我们提出ss-Mamba，一种新型基础模型，通过结合语义感知嵌入和自适应样条时间编码，在选择性状态空间框架中提升时间序列预测性能。基于Transformer架构的成功，ss-Mamba采用Mamba选择性状态空间模型作为高效替代方案，在保持性能的同时将计算复杂度从二次降至线性。语义索引嵌入通过预训练语言模型初始化，利用语义先验实现对新序列的有效泛化。此外，基于样条的Kolmogorov-Arnold网络（KAN）动态且可解释地捕捉复杂季节性和非平稳时间效应，优于传统时间特征编码。大量实验证实，ss-Mamba在准确性、鲁棒性和可解释性上表现优异，成为时间序列预测中传统Transformer模型的高效替代方案。

</details>


### [178] [Training with Confidence: Catching Silent Errors in Deep Learning Training with Automated Proactive Checks](https://arxiv.org/abs/2506.14813)
**中文标题：训练有保障：通过自动化主动检查捕获深度学习训练中的静默错误**

*Yuxuan Jiang,Ziming Zhou,Boyu Xu,Beijie Liu,Runhui Xu,Peng Huang*

主要分类: cs.LG

摘要简述: 本文提出TRAINCHECK框架，通过自动化主动检查方法检测深度学习训练中的静默错误，成功识别18/20真实错误并发现6个未知库漏洞。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习训练过程复杂，静默错误难以检测和诊断，亟需一种自动化工具来主动发现并解决这些问题。

研究方法: TRAINCHECK框架通过推断深度学习训练的定制化不变性条件，主动检测训练中的静默错误，并提供调试支持。

研究结果: 在复现20种真实静默错误中，TRAINCHECK成功检测18种，并在流行训练库中发现6个未知漏洞。

研究结论: TRAINCHECK有效解决了深度学习训练中的静默错误问题，具有实际应用价值。

中文摘要: 深度学习（DL）模型的训练过程复杂，容易产生难以检测和诊断的静默错误。本文提出TRAINCHECK框架，采用主动检查方法应对静默训练错误。TRAINCHECK自动推断适用于DL训练的定制化不变性条件，并利用这些条件在训练过程中主动检测静默错误，同时提供调试支持。为评估TRAINCHECK，我们复现了20种不同根源的真实静默训练错误。TRAINCHECK成功在单次训练迭代中检测到18种错误，并发现导致静默错误的6个流行训练库中的未知漏洞。

</details>


### [179] [Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints](https://arxiv.org/abs/2506.14821)
**中文标题：在资源受限条件下强化视觉语言模型使用工具进行详细视觉推理**

*Sunil Kumar,Bowen Zhao,Leo Dirac,Paulina Varshavskaya*

主要分类: cs.LG

摘要简述: 本文提出了一种通过强化学习训练小型视觉语言模型（VLMs）使用外部工具（如放大）进行详细视觉推理的方法，结合GRPO学习、简单奖励结构和优化数据混合，显著提升了在资源受限条件下的视觉问答任务表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型模型在推理能力上取得了显著进展，视觉语言模型（VLMs）在资源受限时仍难以进行详细的视觉推理。本文旨在通过引入外部工具和优化训练方法，提升小型模型在视觉问答任务中的表现。

研究方法: 方法包括使用Group Relative Policy Optimization（GRPO）训练小型模型，结合简单奖励结构、简化的工具调用接口、为工具调用结果分配额外标记，以及优化训练数据混合（侧重视觉难度较高的样本）。

研究结果: 与基线模型相比，该方法在部分视觉问答（VQA）任务中表现更优，得益于通过外部工具获取的详细视觉信息。

研究结论: 通过GRPO学习和优化工具调用策略，小型视觉语言模型能够在资源受限条件下更有效地进行详细视觉推理，显著提升任务表现。

中文摘要: 尽管近年来大型模型的推理能力取得了巨大进步，视觉语言模型（VLMs）在资源受限时仍难以进行详细的视觉推理。为解决这一问题，我们借鉴了如Deepseek-r1等方法，通过Group Relative Policy Optimization（GRPO）训练小型模型，使其能够使用外部工具（如放大）。最大收益来自于结合GRPO学习、简单奖励结构、简化的工具调用接口、为工具调用结果分配额外标记，以及优化训练数据混合（侧重视觉难度较高的样本）。与规模相似的基线模型相比，我们的方法在某些视觉问答（VQA）任务中表现更优，这得益于通过外部工具获取的详细视觉信息。

</details>


### [180] [FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models](https://arxiv.org/abs/2506.14824)
**中文标题：FedNano：面向预训练多模态大语言模型的轻量级联邦调优**

*Yao Zhang,Hewei Gao,Haokun Chen,Weiguo Li,Yunpu Ma,Volker Tresp*

主要分类: cs.LG

摘要简述: FedNano是一种轻量级联邦学习框架，通过集中服务器端的大型语言模型（LLM）并在客户端引入轻量模块NanoEdge，解决了多模态大语言模型（MLLMs）在联邦学习中的计算、存储和通信挑战。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在实际部署中面临分布式数据和隐私保护问题，而传统联邦学习方法因模型规模过大无法直接应用。FedNano旨在解决这些挑战。

研究方法: FedNano将LLM集中在服务器端，客户端仅部署轻量模块NanoEdge，包含模态特定编码器、连接器和低秩适配器NanoAdapters，大幅减少存储和通信开销。

研究结果: 实验表明，FedNano显著优于现有联邦学习方法，客户端存储减少95%，通信开销仅为模型参数的0.01%，同时支持异构数据和资源限制。

研究结论: FedNano填补了MLLMs规模与联邦学习可行性之间的鸿沟，为可扩展的分布式多模态AI系统提供了解决方案。

中文摘要: 多模态大语言模型（MLLMs）在多模态推理和跨模态检索等任务中表现出色，但在实际部署中面临分布式多模态数据和严格隐私要求的挑战。联邦学习（FL）通过无需集中数据的协作训练提供了一种解决方案。然而，为MLLMs实现FL存在显著挑战，包括高计算需求、有限的客户端能力、高通信成本和异构客户端数据。现有FL方法假设客户端部署完整模型，这一假设因MLLMs的巨大规模和通信需求而失效。为解决这些问题，我们提出FedNano，首个将LLM集中在服务器端并引入轻量模块NanoEdge的FL框架。NanoEdge采用模态特定编码器、连接器和可训练的低秩适配器NanoAdapters。这一设计无需在客户端部署LLM，将客户端存储减少95%，并将通信开销限制为仅模型参数的0.01%。通过仅传输紧凑的NanoAdapter更新，FedNano处理异构客户端数据和资源限制，同时保护隐私。实验表明，FedNano优于现有FL基线，填补了MLLMs规模与FL可行性之间的鸿沟，实现了可扩展的分布式多模态AI系统。

</details>


### [181] [Optimization of bi-directional gated loop cell based on multi-head attention mechanism for SSD health state classification model](https://arxiv.org/abs/2506.14830)
**中文标题：基于多头注意力机制的双向门控循环单元优化及其在SSD健康状态分类模型中的应用**

*Zhizhao Wen,Ruoxin Zhang,Chao Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种结合多头注意力机制的BiGRU-MHA混合模型，用于提升SSD健康状态分类的准确性和稳定性。实验结果显示该模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，且泛化能力优异。


<details>
  <summary>详细信息</summary>
研究动机: SSD健康状态预测对数据可靠性至关重要，但传统模型存在泛化能力不足的问题。本研究旨在通过结合双向时序建模和多头注意力机制，提升分类模型的性能。

研究方法: 提出BiGRU-MHA混合模型，利用BiGRU网络的双向时序建模能力捕捉SSD退化特征的前后依赖关系，同时通过多头注意力机制动态分配特征权重，增强对关键健康指标的敏感性。

研究结果: 模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，性能差距仅为0.26%，且测试集的AUC值为0.94，表现出优异的泛化能力和二分类性能。

研究结论: 该模型为SSD健康预测提供了新技术方案，解决了传统模型的泛化瓶颈，具有实际应用价值，可显著降低数据丢失风险并优化维护成本。

中文摘要: 针对SSD健康状态预测在数据可靠性保障中的关键作用，本研究提出了一种结合多头注意力机制的BiGRU-MHA混合模型，以提高存储设备健康分类的准确性和稳定性。该模型创新性地整合了时序特征提取和关键信息聚焦能力。具体而言，它利用BiGRU网络的双向时序建模优势，捕捉SSD退化特征的前后依赖关系；同时，多头注意力机制动态分配特征权重，提升模型对关键健康指标的敏感性。实验结果表明，所提模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，性能差距仅为0.26%，表现出优异的泛化能力。进一步通过受试者工作特征（ROC）曲线分析，测试集的曲线下面积（AUC）为0.94，证实了模型的稳健二分类性能。本研究不仅为SSD健康预测提供了新的技术途径，还解决了传统模型的泛化瓶颈，为工业级存储系统的预防性维护提供了可验证的实用方法。结果表明，该模型能通过提前故障预警显著降低数据丢失风险，并帮助优化维护成本，支持云计算数据中心和边缘存储环境中构建可靠存储系统的智能决策。

</details>


### [182] [ETS: Open Vocabulary Electroencephalography-To-Text Decoding and Sentiment Classification](https://arxiv.org/abs/2506.14783)
**中文标题：ETS：开放词汇脑电图到文本解码及情感分类**

*Mohamed Masry,Mohamed Amen,Mohamed Elzyat,Mohamed Hamed,Norhan Magdy,Maram Khaled*

主要分类: cs.LG

摘要简述: 本文提出ETS框架，结合脑电图（EEG）与眼动追踪数据，解决开放词汇文本生成和情感分类任务，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法在开放词汇场景下因噪声和变异性表现不佳，本文旨在通过结合EEG与眼动数据提升开放词汇文本生成和情感分类的性能。

研究方法: ETS框架整合EEG与同步眼动追踪数据，用于开放词汇文本生成和情感分类任务。

研究结果: 模型在EEG到文本解码的BLEU和Rouge分数上表现优异，情感分类F1分数提升10%，且能处理多源数据。

研究结论: ETS框架展示了高性能开放词汇EEG到文本系统的潜力，适用于多源数据和多任务场景。

中文摘要: 利用非侵入性脑电图（EEG）从大脑活动中解码自然语言是神经科学和机器学习中的重大挑战，尤其是在开放词汇场景下，传统方法因噪声和变异性表现不佳。以往研究在小规模封闭词汇上取得了高准确率，但在开放词汇上仍存在困难。本研究提出ETS框架，整合EEG与同步眼动追踪数据，解决两项关键任务：（1）开放词汇文本生成；（2）感知语言的情感分类。我们的模型在EEG到文本解码的BLEU和Rouge分数上表现优异，情感分类F1分数提升10%，显著优于监督基线。此外，模型能处理多源数据，展示了高性能开放词汇EEG到文本系统的潜力。

</details>


### [183] [Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective](https://arxiv.org/abs/2506.14965)
**中文标题：从跨领域视角重新审视强化学习在大型语言模型推理中的应用**

*Zhoujun Cheng,Shibo Hao,Tianyang Liu,Fan Zhou,Yutao Xie,Feng Yao,Yuexin Bian,Yonghao Zhuang,Nilabjo Dey,Yuheng Zha,Yi Gu,Kun Zhou,Yuqi Wang,Yuan Li,Richard Fan,Jianshu She,Chengqian Gao,Abulhair Saparov,Haonan Li,Taylor W. Killian,Mikhail Yurochkin,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

主要分类: cs.LG

摘要简述: 本文通过跨领域视角重新审视强化学习（RL）在大型语言模型（LLM）推理中的应用，提出Guru数据集和模型，展示RL在不同推理领域的表现差异，并实现SOTA性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前关于RL提升LLM推理的研究主要集中在数学和代码领域，缺乏对其他推理领域的广泛探索。本文旨在通过构建多领域数据集Guru，全面评估RL在通用推理中的潜力。

研究方法: 构建Guru数据集，包含92K个经过验证的跨领域推理示例（数学、代码、科学、逻辑、模拟和表格），并通过领域特定的奖励设计、去重和过滤确保数据可靠性。基于Guru训练Guru-7B和Guru-32B模型。

研究结果: 实验表明，RL在不同领域的表现差异显著：在预训练中常见的领域（数学、代码、科学）可通过跨领域RL训练受益，而预训练中较少见的领域（逻辑、模拟和表格）需领域内训练才能显著提升性能。Guru模型在17项任务中超越基线7.9%和6.7%。

研究结论: RL不仅能激发预训练知识，还能促进新技能习得。Guru数据集和模型为通用推理提供了可靠工具，并开源数据、模型和代码以推动进一步研究。

中文摘要: 强化学习（RL）已成为提升大型语言模型（LLM）推理能力的有前景方法，但现有研究多集中于数学和代码领域，限制了对其在通用推理中广泛适用性的理解。关键挑战在于缺乏跨多样推理领域的可靠、可扩展RL奖励信号。我们提出Guru，一个包含92K个验证示例的RL推理数据集，涵盖数学、代码、科学、逻辑、模拟和表格六大领域，通过领域特定奖励设计、去重和过滤确保RL训练的可靠性和有效性。基于Guru，我们系统性地重新审视RL在LLM推理中的已有发现，并观察到跨领域的显著差异。例如，尽管先前研究表明RL主要激发预训练模型的已有知识，但我们的结果显示更复杂的模式：预训练中常见的领域（数学、代码、科学）易于通过跨领域RL训练受益，而预训练中较少的领域（逻辑、模拟和表格）需领域内训练才能实现显著性能提升，表明RL可能促进真实技能习得。最后，我们提出Guru-7B和Guru-32B模型，在公开数据RL训练的开源模型中达到SOTA性能，在六大领域的17项任务评估中分别超越最佳基线7.9%和6.7%。我们还展示模型有效提升了基础模型的Pass@k性能，尤其是在预训练数据中较少出现的复杂任务上。我们开源数据、模型、训练和评估代码以促进通用推理研究：https://github.com/LLM360/Reasoning360

</details>


### [184] [Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size](https://arxiv.org/abs/2506.15025)
**中文标题：大型语言模型中嵌入学习率的最优选择：词汇量的影响**

*Soufiane Hayou,Liyuan Liu*

主要分类: cs.LG

摘要简述: 本文研究了词汇量对大型语言模型（LLM）训练动态的影响，揭示了词汇量增加时训练动态在μP（最大更新参数化）和LV（大词汇）两种机制间的过渡，并提出了LV机制下嵌入学习率与隐藏学习率的最优比例应为Θ(√width)。


<details>
  <summary>详细信息</summary>
研究动机: 预训练大型语言模型成本高昂，μP方法虽能通过参数化实现超参数的可迁移性，但其理论假设词汇量固定，而实际中词汇量远大于模型宽度。本文旨在分析词汇量对训练动态的影响，填补理论与实践的差距。

研究方法: 通过理论分析词汇量对训练动态的影响，提出词汇量增加时训练动态在μP和LV机制间的过渡。实验验证了LV机制下嵌入学习率的最优比例，并预训练了一个10亿参数模型以验证理论。

研究结果: 研究发现，LV机制下嵌入学习率与隐藏学习率的最优比例应为Θ(√width)，与文献中的经验发现接近，而与μP预测的Θ(width)不同。实验验证了该比例的有效性。

研究结论: 本文揭示了词汇量对LLM训练动态的重要影响，提出了LV机制下的最优学习率比例，为高效预训练提供了理论支持。

中文摘要: 预训练大型语言模型是一个成本高昂的过程。为了提高效率，已有研究提出了优化模型架构/参数化和硬件使用的方法。在参数化方面，μP（最大更新参数化）通过参数化模型权重和学习率，使得超参数可随宽度（嵌入维度）迁移：超参数可在小模型上调优后直接用于更大模型。尽管μP在实践中表现优异，但最近的经验研究在应用于LLM时报告了矛盾的结果。μP理论的一个局限是假设输入维度（LLM中的词汇量）在宽度趋近无穷时固定，而实际中词汇量通常远大于宽度。本文通过理论分析词汇量对训练动态的影响，发现随着词汇量增加，训练动态在μP机制和LV（大词汇）机制间过渡，其中最优比例规则与μP预测不同。分析表明，在LV机制下，嵌入学习率与隐藏学习率的最优比例应约为Θ(√width)，与文献中的经验发现惊人地接近，而与μP预测的Θ(width)不同。通过实验验证了理论，并预训练了一个10亿参数模型以展示所提比例规则的优势。

</details>


### [185] [Determinação Automática de Limiar de Detecção de Ataques em Redes de Computadores Utilizando Autoencoders](https://arxiv.org/abs/2506.14937)
**中文标题：利用自编码器自动确定计算机网络攻击检测阈值**

*Luan Gonçalves Miranda,Pedro Ivo da Cruz,Murilo Bellezoni Loiola*

主要分类: cs.LG

摘要简述: 本文提出了一种利用机器学习算法自动确定自编码器（AE）在计算机网络攻击检测中的阈值的方法，以解决数据不平衡等问题，并评估了K近邻、K均值和支持向量机三种算法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前，基于自编码器的异常检测系统在解决数据不平衡等问题上表现出潜力，但其分类阈值的非标准化直接影响检测性能。因此，本文旨在通过机器学习算法自动定义这一阈值，以提高检测效果。

研究方法: 研究评估了三种机器学习算法（K近邻、K均值和支持向量机）用于自动确定自编码器在攻击检测中的分类阈值，并通过实验验证其性能。

研究结果: 实验结果表明，所提出的方法能够有效自动定义分类阈值，提升异常检测系统的性能。

研究结论: 通过机器学习算法自动确定自编码器的分类阈值是可行的，能够显著改善计算机网络攻击检测的准确性和效率。

中文摘要: 目前，基于自编码器（AE）的异常检测系统在解决数据不平衡等固有问题上表现出巨大潜力。由于AE使用非标准化的分离阈值对提取的重构误差进行分类，该阈值的定义直接影响检测过程的性能。因此，本研究提出利用一些机器学习算法自动定义这一阈值。为此，评估了三种算法：K近邻、K均值和支持向量机。

</details>


### [186] [Flat Channels to Infinity in Neural Loss Landscapes](https://arxiv.org/abs/2506.14951)
**中文标题：Error**

*Flavio Martinelli,Alexander Van Meegen,Berfin Şimşek,Wulfram Gerstner,Johanni Brea*

主要分类: cs.LG

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [187] [When and How Unlabeled Data Provably Improve In-Context Learning](https://arxiv.org/abs/2506.15329)
**中文标题：未标记数据何时及如何可证明地提升上下文学习**

*Yingcong Li,Xiangyu Chang,Muti Kara,Xiaofeng Liu,Amit Roy-Chowdhury,Samet Oymak*

主要分类: cs.LG

摘要简述: 本文研究了在上下文学习（ICL）中，未标记数据如何提升性能。通过理论分析，发现多层或循环Transformer能有效利用未标记数据，而单层线性注意力模型则无法做到。实验验证了循环现成表格基础模型在半监督学习中的显著效果。


<details>
  <summary>详细信息</summary>
研究动机: 最近研究表明，即使演示数据存在缺失或错误标签，上下文学习（ICL）仍能有效工作。本文旨在揭示这一现象背后的机制，并探讨未标记数据如何提升ICL性能。

研究方法: 研究采用二元高斯混合模型（GMM）生成演示数据，部分标签缺失。通过理论分析，比较单层线性注意力模型与多层或循环Transformer的性能差异，并探讨其隐含的多项式形式与期望最大化（EM）算法的联系。

研究结果: 理论分析表明，多层或循环Transformer能通过隐含构造多项式形式的估计器有效利用未标记数据，且多项式的主导项随深度指数增长。实验验证了循环现成表格基础模型在半监督学习中的显著性能提升。

研究结论: 本文揭示了未标记数据在上下文学习中的重要作用，并通过理论分析和实验验证了多层或循环Transformer的有效性。循环现成表格基础模型在半监督学习中表现优异。

中文摘要: 最近研究表明，即使演示数据存在缺失或错误标签，上下文学习（ICL）仍能有效工作。为揭示这一能力，我们研究了一个典型场景，其中演示数据按二元高斯混合模型（GMM）生成，且部分标签缺失。我们提供了全面的理论分析，表明：（1）单层线性注意力模型的损失景观恢复最优全监督估计器，但完全无法利用未标记数据；（2）相比之下，多层或循环Transformer能通过隐含构造形如$\sum_{i\ge 0} a_i (X^\top X)^iX^\top y$的估计器有效利用未标记数据（$X$和$y$分别表示特征和部分观测标签，缺失项设为零）。我们刻画了可表示为深度函数的多项式类，并与半监督学习中常用的迭代伪标签算法期望最大化（EM）建立联系。重要的是，主导多项式项随深度指数增长，因此轻度深度/循环即可满足需求。作为理论应用，我们提出循环现成表格基础模型以增强其半监督能力。在真实数据集上的广泛评估表明，我们的方法显著提升了半监督表格学习性能，优于标准的单次推理。

</details>


### [188] [Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework](https://arxiv.org/abs/2506.15538)
**中文标题：使用PRISM捕捉多义性：一种多概念特征描述框架**

*Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M. -C. Höhne,Oliver Eberle*

主要分类: cs.LG

摘要简述: 本文提出PRISM框架，用于捕捉神经网络特征的多义性，解决现有方法对单义性假设的局限性，提升特征描述的准确性和全面性。


<details>
  <summary>详细信息</summary>
研究动机: 当前神经网络特征描述方法存在两个主要问题：鲁棒性不足和假设神经元仅编码单一概念（单义性），而实际上神经元常具有多义性。这种假设限制了特征描述的表达能力，无法全面捕捉模型内部行为。

研究方法: 本文提出PRISM（多义性特征识别与评分方法）框架，为多义性和单义性特征提供更细致的描述。与现有方法不同，PRISM能够同时处理多义性特征，并通过描述评分和多义性评分提升描述质量。

研究结果: 实验表明，PRISM在语言模型中的应用显著提升了特征描述的准确性和忠实度，尤其在捕捉多义性概念方面表现优异。

研究结论: PRISM框架有效解决了特征描述中的多义性问题，为神经网络的可解释性研究提供了更强大的工具。

中文摘要: 自动可解释性研究旨在识别神经网络特征编码的概念，以增强对人类模型行为的理解。当前的特征描述方法面临两个关键挑战：鲁棒性有限，以及假设每个神经元仅编码单一概念（单义性），尽管越来越多的证据表明神经元常具有多义性。这一假设限制了特征描述的表达能力，使其无法全面捕捉模型内部行为。为此，我们提出了多义性特征识别与评分方法（PRISM），这一新颖框架能够捕捉神经网络特征的固有复杂性。与现有方法不同，PRISM为多义性和单义性特征提供了更细致的描述。我们将PRISM应用于语言模型，并通过与现有方法的广泛对比实验证明，该方法能够生成更准确和忠实的特征描述，提升了整体描述质量（通过描述评分）以及在多义性存在时捕捉不同概念的能力（通过多义性评分）。

</details>


### [189] [Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits](https://arxiv.org/abs/2506.14988)
**中文标题：基于探测的多智能体多臂老虎机公平算法**

*Tianyi Xu,Jiaxin Liu,Zizhan Zheng*

主要分类: cs.LG

摘要简述: 本文提出了一种多智能体多臂老虎机框架，旨在确保公平性并最大化系统性能。通过引入探测机制，在有限信息下优化决策，设计了离线与在线算法，实验证明其优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 在多智能体多臂老虎机问题中，如何在保证公平性的同时最大化整体性能是一个关键挑战。现有方法在信息有限的情况下难以平衡公平与效率，因此需要一种新的框架来解决这一问题。

研究方法: 本文提出了一种探测框架，在离线设置中利用子模性质设计贪心探测算法，并证明其性能边界；在在线设置中开发了一种算法，实现次线性遗憾并保持公平性。

研究结果: 在合成和真实数据集上的实验表明，所提方法在公平性和效率上优于基线方法。

研究结论: 本文提出的探测框架和算法在多智能体多臂老虎机问题中有效平衡了公平性与性能，为实际应用提供了可靠解决方案。

中文摘要: 我们提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平结果，同时最大化系统整体性能。该设置中的关键挑战是在臂奖励信息有限的情况下进行决策。为此，我们引入了一种新颖的探测框架，在分配前策略性地收集选定臂的信息。在离线设置中（已知奖励分布），我们利用子模性质设计了一种具有可证明性能边界的贪心探测算法。对于更复杂的在线设置，我们开发了一种算法，在保持公平性的同时实现次线性遗憾。在合成和真实数据集上的大量实验表明，我们的方法优于基线方法，实现了更好的公平性和效率。

</details>


### [190] [LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](https://arxiv.org/abs/2506.15606)
**中文标题：LoX：低秩外推增强LLM在微调下的安全性**

*Gabrel J. Perin,Runjin Chen,Xuxi Chen,Nina S. T. Hirata,Zhangyang Wang,Junyuan Hong*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LoX（低秩外推）的无训练方法，通过外推对齐LLM的安全子空间，显著提升了模型对微调攻击的鲁棒性，同时保持了任务适应性。实验显示，LoX在面对良性或恶意微调攻击时，攻击成功率绝对降低了11%至54%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管通过对齐提升了LLM的安全性，但后续微调仍可能破坏其安全保护，即使微调数据看似无害。本文旨在解决这一漏洞，增强LLM对微调攻击的鲁棒性。

研究方法: 基于安全关键的低秩子空间对微调敏感性的发现，提出LoX方法，通过外推对齐LLM的安全子空间来增强鲁棒性。该方法无需额外训练。

研究结果: 实验证明，LoX在面对良性或恶意微调攻击时，攻击成功率绝对降低了11%至54%。参数分析表明，外推将LLM参数移至更平坦的区域，从而降低对扰动的敏感性。

研究结论: LoX是一种有效的无训练方法，能够显著提升LLM对微调攻击的鲁棒性，同时保持模型对新任务的适应性。

中文摘要: 大型语言模型（LLM）在现实应用中不可或缺，但其广泛使用引发了显著的安全问题，尤其是在应对社会有害问题时。尽管通过对齐提升了模型安全性，但后续微调仍可能破坏其安全保护，即使微调数据看似无害。本文通过实验证明，这一漏洞源于LLM参数中安全关键的低秩子空间对微调的敏感性。基于此，我们提出了一种名为低秩外推（LoX）的无训练方法，通过外推对齐LLM的安全子空间来增强安全性鲁棒性。实验结果表明，LoX在面对良性或恶意微调攻击时，攻击成功率绝对降低了11%至54%，同时保持了模型对新任务的适应性。通过分析参数攻击成功率（ASR）的分布，我们发现LoX的成功在于外推将LLM参数移至更平坦的区域，从而降低了对扰动的敏感性。代码可在github.com/VITA-Group/LoX获取。

</details>


### [191] [AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning](https://arxiv.org/abs/2506.15651)
**中文标题：AutoRule：基于推理链提取的规则奖励提升偏好学习**

*Tevin Wang,Chenyan Xiong*

主要分类: cs.LG

摘要简述: AutoRule是一种自动化方法，通过从用户偏好中提取规则并转化为规则奖励，显著提升了强化学习性能。实验显示，该方法在AlpacaEval2.0和MT-Bench上分别实现了28.6%和6.1%的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于规则的奖励方法依赖人工设计规则，效率低下且难以扩展。AutoRule旨在通过自动化提取规则，提升强化学习从人类反馈（RLHF）的性能和效率。

研究方法: AutoRule分为三个阶段：1) 利用推理模型解析用户偏好；2) 从推理链中提取候选规则；3) 将规则整合为统一规则集。随后，通过语言模型验证器计算规则满足度，并将其作为辅助奖励用于策略优化。

研究结果: 实验表明，AutoRule在AlpacaEval2.0上实现了28.6%的相对性能提升，在MT-Bench子集上提升了6.1%。此外，该方法减少了奖励滥用，且提取的规则与数据集偏好高度一致。

研究结论: AutoRule通过自动化规则提取和验证，显著提升了强化学习性能，同时减少了奖励滥用问题。提取的规则能够捕捉不同数据集的独特价值。

中文摘要: 基于规则的奖励为改进从人类反馈的强化学习（RLHF）提供了有前景的策略，但现有方法通常依赖人工规则设计。我们提出了AutoRule，一种从偏好反馈中自动提取规则并将其转化为规则奖励的方法。AutoRule的提取过程分为三个阶段：利用推理模型解释用户偏好，从推理链中识别候选规则，并将其合成为统一规则集。基于最终规则集，我们使用语言模型验证器计算每个输出满足规则的比例，并将该指标作为辅助奖励与学习到的奖励模型一起用于策略优化。在Llama-3-8B模型上使用AutoRule训练后，AlpacaEval2.0的长度控制胜率相对提升了28.6%，在MT-Bench子集的第二轮性能相对提升了6.1%，而基线GRPO模型未使用规则奖励。分析表明，提取的规则与数据集偏好高度一致。AutoRule在两轮实验中表现出比学习奖励模型更少的奖励滥用问题。案例研究显示，提取的规则能够捕捉不同数据集的独特价值。规则集和代码已开源。

</details>


### [192] [Dense SAE Latents Are Features, Not Bugs](https://arxiv.org/abs/2506.15679)
**中文标题：密集SAE潜在特征是功能而非缺陷**

*Xiaoqing Sun,Alessandro Stolfo,Joshua Engels,Ben Wu,Senthooran Rajamanoharan,Mrinmaya Sachan,Max Tegmark*

主要分类: cs.LG

摘要简述: 研究表明，稀疏自编码器（SAE）中的密集潜在特征并非训练噪声，而是具有功能性的模型表示，反映了语言模型的计算需求。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏自编码器（SAE）旨在通过稀疏约束提取语言模型的可解释特征，但许多潜在特征频繁激活（即密集），引发对其是否为训练伪影的质疑。本文旨在系统研究密集潜在特征的几何结构、功能和起源。

研究方法: 研究首先分析密集潜在特征的几何特性，发现其倾向于形成对偶对以重建残差流中的特定方向；随后提出密集潜在特征的分类法，识别其与位置跟踪、上下文绑定等功能相关的类别；最后分析这些特征在不同层中的演变。

研究结果: 密集潜在特征是残差空间的固有属性，具有功能性角色，如位置跟踪、语义表示等；其在模型不同层中呈现从结构特征到语义特征再到输出信号的演变规律。

研究结论: 密集潜在特征是语言模型计算中不可或缺的功能性表示，不应被视为训练噪声。

中文摘要: 稀疏自编码器（SAE）旨在通过稀疏约束从语言模型中提取可解释特征。理想情况下，SAE训练应产生稀疏且语义有意义的潜在特征。然而，许多SAE潜在特征频繁激活（即密集），引发对其是否为训练伪影的担忧。本文系统研究了密集潜在特征的几何结构、功能和起源，发现其不仅是持续存在的，且通常反映有意义的模型表示。研究首先表明，密集潜在特征倾向于形成对偶对以重建残差流中的特定方向，且其子空间的消融会抑制新密集特征在重新训练的SAE中出现——表明高密度特征是残差空间的固有属性。随后，研究提出密集潜在特征的分类法，识别了与位置跟踪、上下文绑定、熵调节、字母特定输出信号、词性和主成分重建相关的类别。最后，研究分析了这些特征在不同层中的演变，揭示了从早期层的结构特征到中间层的语义特征，再到模型最后层的输出导向信号的转变。研究结果表明，密集潜在特征在语言模型计算中具有功能性作用，不应被视为训练噪声。

</details>


### [193] [Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment](https://arxiv.org/abs/2506.15019)
**中文标题：基于敏锐度正则化的稳定CDE自编码器用于败血症治疗的离线强化学习**

*Yue Gao*

主要分类: cs.LG

摘要简述: 本文提出一种稳定的CDE自编码器方法，通过敏锐度正则化解决离线强化学习在败血症治疗中的训练不稳定问题，显著提升策略性能。


<details>
  <summary>详细信息</summary>
研究动机: 败血症治疗中的强化学习依赖于从ICU不规则时间序列中学习稳定且具有临床意义的表征。以往研究忽视了训练不稳定对策略性能的负面影响，本文旨在解决这一问题。

研究方法: 采用控制微分方程（CDE）作为状态表征方法，通过早期停止或稳定化技术确保训练稳定性，并结合临床评分（SOFA、SAPS-II、OASIS）进行相关性正则化，以生成敏锐度感知的表征。

研究结果: 实验表明，稳定的CDE自编码器生成的表征与临床评分高度相关，并显著提升强化学习策略性能（WIS回报>0.9），而不稳定的表征则导致策略失败（WIS回报≈0）。

研究结论: 稳定的CDE表征不仅能区分生存与非生存轨迹，还能清晰反映临床评分梯度，为临床强化学习中不规则时间序列的表征学习提供了实用指导。

中文摘要: 有效的败血症治疗强化学习依赖于从ICU不规则时间序列中学习稳定且具有临床意义的表征。以往研究忽视了训练不稳定对策略性能的负面影响。本文证明，控制微分方程（CDE）状态表征在满足两个关键条件时可实现强化的策略性能：（1）通过早期停止或稳定化方法确保训练稳定性；（2）通过与临床评分（SOFA、SAPS-II、OASIS）的相关性正则化强制生成敏锐度感知的表征。在MIMIC-III败血症队列上的实验表明，稳定的CDE自编码器生成的表征与临床评分高度相关，并显著提升策略性能（WIS回报>0.9），而不稳定的表征则导致策略失败（WIS回报≈0）。潜在空间的可视化显示，稳定的CDE不仅能区分生存与非生存轨迹，还能清晰反映临床评分梯度，而不稳定的训练则无法捕捉这些模式。这些发现为临床强化学习中不规则时间序列的表征学习提供了实用指导，强调了训练稳定性的重要性。

</details>


### [194] [CACTUS as a Reliable Tool for Early Classification of Age-related Macular Degeneration](https://arxiv.org/abs/2506.14843)
**中文标题：CACTUS：一种可靠的年龄相关性黄斑变性早期分类工具**

*Luca Gherardini,Imre Lengyel,Tunde Peto,Caroline C. W. Klaverd,Magda A. Meester-Smoord,Johanna Maria Colijnd,EYE-RISK Consortium,E3 Consortium,Jose Sousa*

主要分类: cs.LG

摘要简述: 本文介绍了CACTUS工具，用于早期分类年龄相关性黄斑变性（AMD），通过结合遗传、饮食、临床和人口因素，提供可解释性和灵活性，优于传统机器学习模型。


<details>
  <summary>详细信息</summary>
研究动机: 医疗数据通常有限或不完整，影响机器学习模型的性能。年龄相关性黄斑变性（AMD）影响数百万老年人，早期诊断至关重要，但缺乏逆转进展的有效治疗方法。需要一种综合考虑多种因素的分类方法。

研究方法: 作者开发了CACTUS工具，结合遗传、饮食、临床和人口因素，优化AMD阶段分类。该工具提供可解释性和灵活性，并消除不相关或有偏数据。

研究结果: CACTUS在AMD分类中优于标准机器学习模型，能够识别关键因素并提供可信结果，与现有医学知识一致。

研究结论: CACTUS是一种可靠的AMD早期分类工具，通过可解释性和灵活性提升决策能力，为临床医生提供反馈和解决偏见的场景。

中文摘要: 机器学习（ML）用于解决疾病分类和预测等任务，但其效果依赖于大量完整数据。然而，医疗数据通常有限或不完整，影响模型性能。此外，解决方案的可信度因数据集而异，部分ML模型缺乏透明度，增加了理解和使用的难度。年龄相关性黄斑变性（AMD）影响数百万老年人，由于缺乏逆转进展的有效治疗方法，早期诊断至关重要。AMD诊断需要结合视网膜图像和患者症状报告。需要一种综合考虑遗传、饮食、临床和人口因素的分类方法。最近，我们提出了“全面抽象和分类工具”（CACTUS），旨在改进AMD阶段分类。CACTUS提供可解释性和灵活性，优于标准ML模型，通过识别关键因素和提供可信结果增强决策能力。CACTUS识别的重要特征可与现有医学知识对比。通过消除不相关或有偏数据，我们为临床医生创建了反馈场景以解决偏见。

</details>


### [195] [SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models](https://arxiv.org/abs/2506.15021)
**中文标题：SFT-GO：基于分组优化的大语言模型监督微调方法**

*Gyuhak Kim,Sumiran Singh Thakur,Su Min Park,Wei Wei,Yujia Bao*

主要分类: cs.LG

摘要简述: SFT-GO是一种新颖的监督微调方法，通过分组优化策略，针对不同重要性的token进行差异化处理，提升大语言模型在任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的监督微调方法通常将所有token视为同等重要，忽略了任务关键信息可能仅集中在部分token中。SFT-GO旨在通过分组优化解决这一问题。

研究方法: SFT-GO根据token的重要性将其分组，并采用加权的最差组损失与标准交叉熵损失组合优化模型，自适应地强调最具挑战性的token组。

研究结果: 实验表明，SFT-GO在多个大语言模型基准测试中均优于基线方法，且在不同数据集和基础模型上表现稳健。

研究结论: SFT-GO通过分组优化策略显著提升了监督微调的效果，为大语言模型的性能优化提供了新思路。

中文摘要: 监督微调（SFT）已成为调整大语言模型（LLMs）以符合人类期望和特定下游任务的关键步骤。然而，现有的SFT方法通常将每个训练实例视为均匀序列，对所有token赋予相同的重要性，而忽略了任务关键信息可能仅集中在部分token中。为解决这一局限性，我们提出了基于分组优化的监督微调方法（SFT-GO），该方法根据token的重要性将其分组，并采用加权的最差组损失与标准交叉熵损失组合优化模型。这一机制自适应地强调最具挑战性的token组，并引导模型更好地处理不同组分布，从而改善整体学习动态。我们提供了SFT-GO收敛速率的理论分析，证明了其高效性。实证中，我们应用了三种不同的token分组策略，结果表明，SFT-GO训练的模型在多个流行LLM基准测试中均优于基线方法。这些改进在不同数据集和基础模型上均保持一致，证明了我们方法的稳健性和有效性。

</details>


### [196] [Sequential Policy Gradient for Adaptive Hyperparameter Optimization](https://arxiv.org/abs/2506.15051)
**中文标题：序列策略梯度用于自适应超参数优化**

*Zheng Li,Jerry Cheng,Huanying Helen Gu*

主要分类: cs.LG

摘要简述: 提出了一种名为SPG的轻量级在线超参数优化方法，通过临时模块扩展基础模型，单次前向传递生成轨迹，显著降低计算成本，并在多个数据集上实现性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习方法在神经架构搜索和超参数优化中因时间和计算成本过高而难以广泛应用，因此需要一种更高效的方法。

研究方法: SPG（Sequential Policy Gradient）通过临时模块扩展基础模型，支持单次前向传递生成状态-动作轨迹，实现轻量级在线超参数优化。

研究结果: 实验表明，SPG在原始数据集上重新训练模型时性能提升，且优于标准迁移微调，在多个领域的数据集上实现0.2%至7%的性能提升，计算成本显著降低。

研究结论: SPG是一种高效且计算成本低的超参数优化方法，适用于工业应用，并在多个领域的数据集上表现出稳定的性能改进。

中文摘要: 强化学习在神经架构搜索和超参数优化中至关重要，但传统方法因时间和计算成本过高而难以广泛应用。受DeepSeek-V3多令牌预测架构启发，我们提出了序列策略梯度建模（SPG），一种轻量级在线超参数优化的新型轨迹生成范式。与传统策略梯度方法不同，SPG通过临时模块扩展基础模型，使其能够单次前向传递生成状态-动作（填充）轨迹。实验表明，模型在原始数据集上使用SPG重新训练时性能提升，且优于标准迁移微调。我们在计算机视觉（ImageNet、COCO）、自然语言处理（GLUE、SQuAD）和音频（SUPERB）五个数据集上评估了SPG的工业适用性。该方法在广泛采用的模型中表现出稳定的改进，性能提升0.2%至7%，计算成本显著降低。完全可复现的代码和预训练模型：https://huggingface.co/UniversalAlgorithmic/SPG。

</details>


### [197] [Singular Value Decomposition on Kronecker Adaptation for Large Language Model](https://arxiv.org/abs/2506.15251)
**中文标题：基于Kronecker适应的奇异值分解在大型语言模型中的应用**

*Yee Hin Chong,Peng Qu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SoKA的新型参数高效微调方法，结合Kronecker乘积张量分解与SVD驱动的初始化及动态秩选择，显著减少了大型语言模型微调时的存储和计算开销，同时保持或超越基线性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型预训练Transformer模型在多种语言和推理任务中表现优异，但全参数微调带来高昂的存储、内存和计算成本。现有参数高效微调方法存在推理延迟、收敛不佳或固定秩选择不灵活等问题，亟需一种更高效的解决方案。

研究方法: SoKA方法结合Kronecker乘积张量分解与SVD驱动的初始化，通过Kronecker-Product SVD（KPSVD）提取权重更新的主成分，并采用动态秩选择算法（基于能量阈值和肘点准则）修剪无关成分。

研究结果: 在LLaMA2-7B模型上的实验表明，SoKA仅需0.99M可训练参数（比LoRA/PiSSA少25%），同时在算术推理（GSM8K）、形式数学（MATH）和代码生成（MBPP）任务中匹配或超越基线性能，且收敛更快、梯度更稳定。

研究结论: SoKA是一种高效、稳健的大规模模型适应方法，显著降低了微调成本，同时保持了模型性能，为参数高效微调提供了新的解决方案。

中文摘要: 大型预训练Transformer模型在多样化的语言和推理任务中取得了最先进的成果，但全参数微调带来了高昂的存储、内存和计算开销。参数高效微调（PEFT）方法通过学习少量任务特定参数来降低这些成本，但现有方法要么引入推理延迟（适配器模块），要么因随机初始化低秩更新而收敛不佳，或依赖固定秩选择（基于Kronecker的分解）而无法匹配任务复杂性。

我们提出SoKA（基于Kronecker适应的SVD），一种新型PEFT策略，结合了Kronecker乘积张量分解与SVD驱动的初始化及频谱感知的动态秩选择。我们的Kronecker-Product SVD（KPSVD）过程将完整权重更新的主成分提取为紧凑的Kronecker因子，同时自适应秩选择算法使用能量阈值和肘点准则修剪无关成分。

在LLaMA2-7B上的实验评估（涵盖算术推理GSM8K、形式数学MATH和代码生成MBPP）表明，SoKA仅需0.99M可训练参数，比LoRA/PiSSA少25%，同时匹配或超越基线性能。此外，SoKA表现出更快的收敛速度和更稳定的梯度，突显了其在大规模模型适应中的稳健性和高效性。

</details>


### [198] [Pixel-level Certified Explanations via Randomized Smoothing](https://arxiv.org/abs/2506.15499)
**中文标题：通过随机平滑实现像素级认证解释**

*Alaa Anani,Tobias Lorenz,Mario Fritz,Bernt Schiele*

主要分类: cs.LG

摘要简述: 本文提出首个通过随机平滑技术为任何黑盒归因方法提供像素级鲁棒性认证的框架，确保归因图的稳定性和可信度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事后归因方法在解释深度学习预测时，容易受到微小输入扰动的影响，导致归因图不稳定，降低了其可信度。本文旨在解决这一问题，提供严格的像素级鲁棒性保证。

研究方法: 通过稀疏化和平滑化归因图，将任务重新定义为分割问题，并利用随机平滑技术为每个像素的重要性提供对抗ℓ₂有界扰动的认证。同时提出三种评估指标来衡量认证鲁棒性、定位性和忠实性。

研究结果: 在5个ImageNet模型和12种归因方法上的广泛实验表明，本文提出的认证归因方法具有鲁棒性、可解释性和忠实性，适用于下游任务。

研究结论: 本文提出的认证框架为归因方法提供了可靠的像素级鲁棒性保证，增强了其在实践中的可信度和实用性。

中文摘要: 事后归因方法旨在通过突出显示影响输入像素来解释深度学习预测。然而，这些解释非常不稳定：微小且难以察觉的输入扰动可以显著改变归因图，同时保持相同的预测结果。这种脆弱性削弱了其可信度，因此需要对像素级归因分数提供严格的鲁棒性保证。我们首次引入了一个认证框架，利用随机平滑技术为任何黑盒归因方法提供像素级鲁棒性保证。通过稀疏化和平滑化归因图，我们将任务重新定义为分割问题，并为每个像素的重要性提供对抗ℓ₂有界扰动的认证。我们进一步提出了三种评估指标来衡量认证鲁棒性、定位性和忠实性。在5个ImageNet模型和12种归因方法上的广泛实验表明，我们的认证归因方法具有鲁棒性、可解释性和忠实性，能够可靠地用于下游任务。代码详见https://github.com/AlaaAnani/certified-attributions。

</details>


### [199] [Unlocking Post-hoc Dataset Inference with Synthetic Data](https://arxiv.org/abs/2506.15271)
**中文标题：利用合成数据解锁后验数据集推断**

*Bihe Zhao,Pratyush Maini,Franziska Boenisch,Adam Dziedzic*

主要分类: cs.LG

摘要简述: 本文提出了一种通过合成数据实现后验数据集推断的方法，解决了现有方法需要与训练数据分布匹配的私有数据集的限制。通过生成高质量合成数据并进行校准，成功检测训练数据的使用情况。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的训练数据常未经授权从互联网抓取，侵犯数据所有者权益。数据集推断（DI）可检测训练数据是否被滥用，但现有方法依赖难以获取的私有数据集。本文旨在通过合成数据解决这一问题。

研究方法: 方法包括：（1）通过基于后缀补全任务训练的数据生成器生成高质量、多样化的合成数据；（2）通过后验校准弥合真实与合成数据之间的似然差距。

研究结果: 实验表明，生成的合成数据作为保留集能高置信度检测原始训练数据，同时保持低误报率，适用于实际版权纠纷。

研究结论: 该方法为数据所有者提供了验证数据使用的可靠工具，展示了合成数据在数据集推断中的实用性。

中文摘要: 大型语言模型（LLMs）的强大能力主要归功于其海量训练数据，但这些数据常未经授权从互联网抓取，侵犯数据所有者权益。数据集推断（DI）通过识别可疑数据集是否用于训练，为数据所有者提供验证手段。然而，现有DI方法需要与训练数据分布匹配的私有数据集，这类数据在实践中难以获取，限制了DI的适用性。本文通过合成生成所需的保留集解决这一挑战。方法包括：（1）通过基于后缀补全任务训练的数据生成器生成高质量、多样化的合成数据；（2）通过后验校准弥合真实与合成数据之间的似然差距。在多样文本数据集上的实验表明，生成的合成数据作为保留集能高置信度检测原始训练数据，同时保持低误报率，为版权所有者提供合法主张依据，并证明该方法在实际诉讼中的可靠性。代码见https://github.com/sprintml/PostHocDatasetInference。

</details>


### [200] [Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation](https://arxiv.org/abs/2506.15309)
**中文标题：主动学习引导的序列到序列变分自编码器用于多靶点抑制剂生成**

*Júlia Vilalta-Mor,Alexis Molina,Laura Ortega Varga,Isaac Filella-Merce,Victor Guallar*

主要分类: cs.LG

摘要简述: 本文提出了一种结合主动学习和序列到序列变分自编码器的方法，用于生成多靶点抑制剂，解决了药物发现中多目标优化和稀疏奖励的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 药物发现中同时优化分子以针对多个治疗靶点面临稀疏奖励和设计冲突的挑战，亟需一种高效的方法来平衡化学多样性和多靶点亲和力。

研究方法: 采用主动学习范式，结合序列到序列变分自编码器，通过迭代扩展潜在空间的化学可行区域并逐步约束分子，以优化多靶点亲和力。

研究结果: 在针对三种冠状病毒主蛋白酶的实验中，该方法成功生成了结构多样的泛抑制剂候选分子，显著提升了化学空间的探索效率。

研究结论: 该框架为复杂多药理学景观的高效导航提供了通用路线图，将稀疏奖励的多目标药物设计问题转化为可计算任务。

中文摘要: 在药物发现中，同时优化分子以针对多个治疗靶点仍是一项重大挑战，尤其是由于稀疏奖励和冲突的设计约束。我们提出了一种结构化主动学习（AL）范式，将序列到序列（Seq2Seq）变分自编码器（VAE）整合到迭代循环中，旨在平衡化学多样性、分子质量和多靶点亲和力。我们的方法交替扩展潜在空间的化学可行区域，并基于逐步严格的多靶点对接阈值约束分子。在一项针对三种相关冠状病毒主蛋白酶（SARS-CoV-2、SARS-CoV、MERS-CoV）的概念验证研究中，我们的方法高效生成了一组结构多样的泛抑制剂候选分子。我们证明，在主动学习流程中精心安排和策略性放置化学过滤器，显著增强了对有益化学空间的探索，将稀疏奖励的多目标药物设计问题转化为可计算任务。因此，我们的框架为高效导航复杂的多药理学景观提供了通用路线图。

</details>


### [201] [Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI](https://arxiv.org/abs/2506.15408)
**中文标题：统一VXAI：可解释AI评估的系统综述与框架**

*David Dembinsky,Adriano Lucieri,Stanislav Frolov,Hiba Najjar,Ko Watanabe,Andreas Dengel*

主要分类: cs.LG

摘要简述: 本文通过系统文献综述和统一框架（VXAI）填补了可解释AI（XAI）评估领域的标准化空白，提出了41个功能相似的指标组和三维分类方案。


<details>
  <summary>详细信息</summary>
研究动机: 现代AI系统（如深度神经网络）因其黑盒特性缺乏透明度，影响可信度。尽管可解释AI（XAI）提供了模型行为的解释，但缺乏标准化的评估协议和指标共识。本文旨在填补这一空白。

研究方法: 采用PRISMA指南进行系统文献综述，分析了362篇相关文献，并提出了一个统一的VXAI框架，包括41个功能相似的指标组和三维分类方案（解释类型、评估上下文性和解释质量需求）。

研究结果: 提出了目前最全面的VXAI框架，支持系统化的指标选择、方法间的可比性，并为未来扩展提供了灵活基础。

研究结论: VXAI框架为可解释AI的评估提供了标准化和结构化支持，有助于提升透明度和可信度。

中文摘要: 现代AI系统（尤其是深度神经网络）因其黑盒特性缺乏透明度，尽管可解释AI（XAI）提供了模型行为的解释，但缺乏标准化的评估协议和指标共识。为解决这一问题，我们遵循PRISMA指南进行了系统文献综述，并提出了一个统一的VXAI框架。我们分析了362篇相关文献，将其贡献归纳为41个功能相似的指标组，并提出了一个三维分类方案（解释类型、评估上下文性和解释质量需求）。该框架是目前最全面且结构化的VXAI概述，支持系统化的指标选择、方法间的可比性，并为未来扩展提供了灵活基础。

</details>


### [202] [Reward Models in Deep Reinforcement Learning: A Survey](https://arxiv.org/abs/2506.15421)
**中文标题：深度强化学习中的奖励模型：综述**

*Rui Yu,Shenghua Wan,Yucen Wang,Chen-Xiao Gao,Le Gan,Zongzhang Zhang,De-Chuan Zhan*

主要分类: cs.LG

摘要简述: 本文综述了深度强化学习中的奖励模型技术，涵盖了背景、分类、应用及评估方法，并指出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 奖励模型在强化学习中用于引导策略优化，但现有文献缺乏系统性综述。本文旨在填补这一空白，总结现有技术并探讨未来发展方向。

研究方法: 文章首先介绍奖励模型的背景和基础知识，随后分类综述了基于来源、机制和学习范式的奖励建模方法，并讨论了其应用和评估技术。

研究结果: 综述了深度强化学习中奖励模型的多种技术，包括传统和新兴方法，并提出了评估标准和未来研究方向。

研究结论: 本文系统总结了奖励模型的研究现状，为未来研究提供了方向，填补了文献中的空白。

中文摘要: 在强化学习（RL）中，智能体持续与环境交互，并通过反馈优化行为。为了指导策略优化，奖励模型被引入作为目标任务的代理，使得智能体在最大化累积奖励的同时，也能实现任务设计者的意图。近年来，学术界和工业界的研究者重点关注开发与真实目标高度一致且有助于策略优化的奖励模型。本文综述了深度强化学习文献中的奖励建模技术。首先概述了奖励模型的背景和基础知识，随后分类介绍了基于来源、机制和学习范式的奖励建模方法。在此基础上，讨论了这些技术的应用及其评估方法。最后，总结了奖励建模的未来研究方向。本文涵盖了传统和新兴方法，填补了当前文献中系统性综述的空白。

</details>


### [203] [Zero-Shot Reinforcement Learning Under Partial Observability](https://arxiv.org/abs/2506.15446)
**中文标题：部分可观测性下的零样本强化学习**

*Scott Jeen,Tom Bewley,Jonathan M. Cullen*

主要分类: cs.LG

摘要简述: 本文探讨了在部分可观测环境下零样本强化学习（RL）的性能下降问题，并提出基于记忆的架构作为有效解决方案。实验表明，该方法在状态、奖励和动态变化部分可观测的领域中优于无记忆基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有零样本强化学习方法假设可以访问马尔可夫状态，但在许多实际应用中，状态是部分可观测的。本文旨在研究部分可观测性对零样本RL性能的影响，并提出改进方法。

研究方法: 采用基于记忆的架构来解决部分可观测性问题，并在状态、奖励和动态变化部分可观测的领域中进行实验验证。

研究结果: 实验结果表明，基于记忆的零样本RL方法在部分可观测环境中表现优于无记忆基线。

研究结论: 在部分可观测环境下，基于记忆的架构是提升零样本强化学习性能的有效方法。

中文摘要: 近期研究表明，在特定假设下，零样本强化学习（RL）方法可以通过无奖励预训练泛化到环境中的任何未见任务。其中一项假设是能够访问马尔可夫状态，然而，在许多实际应用中，马尔可夫状态是部分可观测的。本文探讨了部分可观测性对标准零样本RL方法性能的影响，并表明，与单任务RL类似，基于记忆的架构是一种有效的解决方案。我们在状态、奖励和动态变化部分可观测的领域中评估了基于记忆的零样本RL方法，结果显示其性能优于无记忆基线。我们的代码已开源：https://enjeeneer.io/projects/bfms-with-memory/。

</details>


### [204] [Warping and Matching Subsequences Between Time Series](https://arxiv.org/abs/2506.15452)
**中文标题：时间序列间的子序列扭曲与匹配**

*Simiao Lin,Wannes Meert,Pieter Robberechts,Hendrik Blockeel*

主要分类: cs.LG

摘要简述: 提出一种新方法，通过简化时间序列的扭曲路径，突出并可视化关键变换（如位移、压缩和幅度差异），从而增强时间序列比较的可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有时间序列比较方法主要关注点对点对齐，缺乏对子序列间结构关系的定性分析，难以理解时间序列间的位移、加速或减速等变换。

研究方法: 提出一种新技术，通过简化扭曲路径，量化和可视化关键变换（如位移、压缩和幅度差异），以更清晰地表示子序列间的匹配关系。

研究结果: 该方法能够更直观地展示时间序列间的变换，显著提升了时间序列比较的可解释性。

研究结论: 通过简化扭曲路径和可视化关键变换，该方法为时间序列比较提供了更清晰的定性分析工具。

中文摘要: 时间序列比较在聚类和分类等任务中至关重要。尽管允许扭曲的弹性距离度量提供了稳健的定量比较，但缺乏基于它们的定性比较。传统可视化方法专注于点对点对齐，未能传达子序列层面的更广泛结构关系。这一限制使得难以理解一个时间序列相对于另一个的位移、加速或减速情况。为此，我们提出了一种新技术，通过简化扭曲路径来突出、量化和可视化关键变换（如位移、压缩和幅度差异）。通过更清晰地表示子序列间的匹配关系，我们的方法增强了时间序列比较的可解释性。

</details>


### [205] [Over-squashing in Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2506.15507)
**中文标题：时空图神经网络中的过度挤压问题**

*Ivan Marisca,Jacob Bamberger,Cesare Alippi,Michael M. Bronstein*

主要分类: cs.LG

摘要简述: 本文研究了时空图神经网络（STGNNs）中的信息传播问题，特别是‘过度挤压’现象，发现卷积STGNNs更倾向于传播时间上较远而非较近的信息，并证明不同架构均受此影响。


<details>
  <summary>详细信息</summary>
研究动机: 尽管图神经网络（GNNs）在多领域表现优异，但其信息传播能力存在根本性限制，如‘过度挤压’问题。这一问题在静态图中已有研究，但在时空图神经网络（STGNNs）中尚未探索。时空维度进一步加剧了信息传播的挑战，因此需要深入研究。

研究方法: 本文首先形式化了时空‘过度挤压’问题，并通过理论分析揭示其与静态图的区别。研究发现，卷积STGNNs更倾向于传播时间上较远而非较近的信息。此外，通过分析不同架构（时间-空间并行或时间优先处理）的影响，证明了这一现象的普遍性。

研究结果: 研究结果表明，时空‘过度挤压’问题在STGNNs中具有独特性，且不同架构均受其影响。实验验证了理论分析，并提供了对STGNNs运行机制的深入理解。

研究结论: 本文揭示了时空图神经网络中‘过度挤压’问题的独特性，为更高效的架构设计提供了理论依据。研究强调了时空维度对信息传播的影响，并为未来优化指明了方向。

中文摘要: 图神经网络（GNNs）在多个领域取得了显著成功。然而，近期的理论进展揭示了其信息传播能力的根本性限制，例如‘过度挤压’问题，即远距离节点无法有效交换信息。尽管这一问题在静态图中已有广泛研究，但在时空图神经网络（STGNNs）中尚未被探索。时空维度进一步加剧了这一挑战，因为需要传播的信息量增加。本文形式化了时空‘过度挤压’问题，并展示了其与静态情况的区别。研究发现，卷积STGNNs更倾向于传播时间上较远而非较近的信息。此外，本文证明了遵循时间-空间并行或时间优先处理范式的架构均受此现象影响，为计算高效的实现提供了理论依据。通过在合成和真实数据集上的验证，研究提供了对STGNNs运行机制的深入理解，并为更有效的设计提供了指导。

</details>


### [206] [RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation](https://arxiv.org/abs/2506.15513)
**中文标题：RePCS：诊断基于LLM的检索增强生成中的数据记忆问题**

*Le Vu Anh,Nguyen Viet Anh,Mehmet Dik,Luong Van Nghia*

主要分类: cs.LG

摘要简述: 论文提出了一种名为RePCS的方法，用于检测基于检索增强生成（RAG）的大型语言模型（LLM）是否依赖记忆的训练数据而非检索内容。RePCS通过比较两种推理路径的KL散度来诊断数据记忆问题，无需访问模型内部或重新训练，且性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 检索增强生成（RAG）虽然能利用外部信息更新LLM的响应，但模型仍可能依赖记忆的训练数据，导致输出污染。现有方法无法在不访问模型内部的情况下有效检测这一问题，因此需要一种轻量级的黑盒诊断工具。

研究方法: RePCS通过比较两种推理路径的输出分布KL散度来诊断数据记忆问题：一种是仅使用查询的参数路径，另一种是同时使用查询和检索内容的检索增强路径。KL散度低表明检索内容影响小，可能存在记忆问题。该方法无需模型访问或重新训练，仅需一次额外前向传播。

研究结果: 在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，比现有最佳方法高出6.5个百分点，且在NVIDIA T4 GPU上的延迟开销低于4.7%。

研究结论: RePCS提供了一种轻量级的黑盒方法，能够有效检测RAG系统是否真正利用了检索内容，特别适用于安全关键应用。

中文摘要: 检索增强生成（RAG）已成为一种常见策略，用于通过外部信息更新大型语言模型（LLM）的响应。然而，模型仍可能依赖记忆的训练数据，绕过检索证据并产生污染的输出。我们提出了检索路径污染评分（RePCS），一种无需模型访问或重新训练即可检测此类行为的诊断方法。RePCS通过比较两种推理路径的输出分布KL散度：（i）仅使用查询的参数路径，（ii）同时使用查询和检索内容的检索增强路径。KL散度低表明检索内容影响小，可能存在记忆问题。该方法与模型无关，无需梯度或内部状态访问，仅需一次额外前向传播。我们还推导了PAC式保证，将KL阈值与用户定义的假阳性和假阴性率联系起来。在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，比现有最佳方法高出6.5个百分点，且在NVIDIA T4 GPU上的延迟开销低于4.7%。RePCS提供了一种轻量级的黑盒保障，用于验证RAG系统是否真正利用了检索内容，特别适用于安全关键应用。

</details>


### [207] [Learning Algorithms in the Limit](https://arxiv.org/abs/2506.15543)
**中文标题：极限下的学习算法**

*Hristo Papazov,Nicolas Flammarion*

主要分类: cs.LG

摘要简述: 本文通过扩展Gold的归纳推理框架，引入计算观测和受限输入源，研究了在极限下学习可计算函数的问题。通过时间约束观测和策略轨迹观测，克服了传统输入输出观测无法学习一般递归函数的限制，并建立了计算智能体观测的正式框架。


<details>
  <summary>详细信息</summary>
研究动机: 传统输入输出观测无法在极限下学习一般递归函数，因此需要引入更现实的约束条件（如计算复杂度限制或近似时间约束观测）来克服这一学习障碍。

研究方法: 扩展Gold的归纳推理框架，引入时间约束观测和策略轨迹观测，研究一般递归函数的学习性；建立计算智能体观测的正式框架，并将其简化为输入输出学习问题。

研究结果: 时间约束观测和策略轨迹观测能够克服传统输入输出观测的学习限制；计算智能体观测框架揭示了与有限状态转换器推断的有趣联系；线性时间可计算函数不存在可计算或多项式质量的特征集。

研究结论: 通过引入计算观测和受限输入源，本文扩展了极限学习框架，揭示了新的学习可能性，但也指出了线性时间可计算函数的学习限制。

中文摘要: 本文通过扩展Gold的归纳推理框架，引入计算观测和受限输入源，研究了在极限下学习可计算函数的问题。与传统输入输出观测互补，我们提出了时间约束观测和策略轨迹观测，以研究在更现实约束下一般递归函数的学习性。虽然输入输出观测不足以在极限下学习一般递归函数类，但通过施加计算复杂度约束或补充近似时间约束观测，我们克服了这一学习障碍。此外，我们围绕计算智能体的观测建立了一个正式框架，并表明从策略轨迹学习可计算函数可以简化为从输入和输出学习有理函数，从而揭示了与有限状态转换器推断的有趣联系。在负面结果方面，我们证明了即使对于策略轨迹观测，线性时间可计算函数类也不存在可计算或多项式质量的特征集。

</details>


### [208] [DAILOC: Domain-Incremental Learning for Indoor Localization using Smartphones](https://arxiv.org/abs/2506.15554)
**中文标题：DAILOC：基于智能手机的域增量学习室内定位方法**

*Akhil Singampalli,Danish Gufran,Sudeep Pasricha*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DAILOC的新型域增量学习框架，用于解决Wi-Fi指纹室内定位中设备异构性和时间变化导致的域偏移问题。通过多级变分自编码器和记忆引导的潜在对齐机制，DAILOC显著降低了定位误差。


<details>
  <summary>详细信息</summary>
研究动机: Wi-Fi指纹室内定位在实际部署中面临设备异构性和时间变化带来的域偏移问题，现有方法通常独立处理这些问题，导致泛化能力差和灾难性遗忘。本文旨在提出一种联合解决这些问题的框架。

研究方法: DAILOC采用多级变分自编码器分离域偏移与位置相关特征，并引入记忆引导的潜在对齐机制以缓解灾难性遗忘。

研究结果: 实验表明，DAILOC在多个智能手机、建筑和时间实例中表现优异，平均误差降低2.74倍，最坏情况误差降低4.6倍。

研究结论: DAILOC通过联合处理设备异构性和时间变化，显著提升了室内定位的准确性和鲁棒性，为实际应用提供了有效解决方案。

中文摘要: 基于Wi-Fi指纹的室内定位在实际部署中因设备异构性和时间变化导致的域偏移而面临重大挑战。现有方法通常独立处理这些问题，导致泛化能力差和灾难性遗忘。本文提出DAILOC，一种新型域增量学习框架，联合解决时间和设备引起的域偏移。DAILOC通过多级变分自编码器分离域偏移与位置相关特征，并引入记忆引导的潜在对齐机制以缓解灾难性遗忘。实验表明，DAILOC在多个智能手机、建筑和时间实例中显著优于现有方法，平均误差降低2.74倍，最坏情况误差降低4.6倍。

</details>


### [209] [Towards Explainable Indoor Localization: Interpreting Neural Network Learning on Wi-Fi Fingerprints Using Logic Gates](https://arxiv.org/abs/2506.15559)
**中文标题：迈向可解释的室内定位：基于逻辑门解释Wi-Fi指纹上的神经网络学习**

*Danish Gufran,Sudeep Pasricha*

主要分类: cs.LG

摘要简述: 本文提出了一种基于逻辑门的框架LogNet，用于解释和增强基于深度学习的室内定位系统，解决了现有黑盒模型缺乏可解释性的问题，并在性能和效率上显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有的深度学习室内定位模型多为黑盒，缺乏对预测过程和噪声响应的解释能力，难以适应长期环境变化。本文旨在通过可解释性框架提升模型的透明度和长期可靠性。

研究方法: 提出LogNet框架，利用逻辑门解释深度学习模型的内部行为，识别关键接入点（APs）及其对定位决策的影响，并分析环境噪声对模型的干扰。

研究结果: LogNet在多个真实建筑平面和两年时间变化中表现优异，定位误差降低1.1至2.8倍，模型大小缩小3.4至43.3倍，延迟减少1.5至3.6倍。

研究结论: LogNet不仅提升了深度学习模型的解释性，还显著优化了性能和效率，为长期稳定的室内定位部署提供了可行方案。

中文摘要: 深度学习在室内定位中表现出高精度，但现有模型多为黑盒，难以解释预测过程或环境噪声的影响。为此，我们提出LogNet，一种基于逻辑门的框架，用于解释和增强基于深度学习的室内定位。LogNet通过识别关键接入点（APs）及其对参考点（RP）的影响，揭示环境噪声如何干扰定位决策，从而提升模型的透明度和长期可靠性。在多个真实建筑平面和两年时间变化的评估中，LogNet不仅解释了深度学习模型的内部行为，还显著提升了性能——定位误差降低1.1至2.8倍，模型大小缩小3.4至43.3倍，延迟减少1.5至3.6倍。

</details>


### [210] [GFLC: Graph-based Fairness-aware Label Correction for Fair Classification](https://arxiv.org/abs/2506.15620)
**中文标题：基于图的公平感知标签校正方法（GFLC）用于公平分类**

*Modar Sulaiman,Kallol Roy*

主要分类: cs.LG

摘要简述: 本文提出了一种基于图的公平感知标签校正方法（GFLC），用于在分类任务中修正标签噪声并保持数据集的公平性，显著提升了模型性能与公平性的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能系统在社会各领域（如医疗和法律判决）的影响日益增大，机器学习中的公平性变得至关重要。然而，训练数据中的标签偏差和噪声会影响模型性能和公平性评估，因此需要一种能够修正标签噪声同时保持公平性的方法。

研究方法: GFLC方法结合了三个关键组件：预测置信度度量、基于图的拉普拉斯正则化（通过Ricci流优化）以及显式的人口均等激励。这些组件共同作用，有效修正标签噪声并保持公平性。

研究结果: 实验结果表明，GFLC方法在性能和公平性指标之间取得了显著改进，优于基线方法。

研究结论: GFLC是一种高效的方法，能够在修正标签噪声的同时保持数据集的公平性，为构建更可信的机器学习系统提供了有力支持。

中文摘要: 机器学习中的公平性对于构建可信赖的机器学习系统至关重要，因为人工智能系统正日益影响社会的各个方面（如医疗决策和法律判决）。然而，用于训练和开发去偏技术的训练数据通常包含有偏和噪声标签，导致标签偏差影响模型性能并在测试阶段误导分类器的公平性评估。为解决这一问题，本文提出了一种基于图的公平感知标签校正方法（GFLC），该方法能够高效修正标签噪声，同时保持数据集中的人口均等性。具体而言，我们的方法结合了三个关键组件：预测置信度度量、基于图的拉普拉斯正则化（通过Ricci流优化）以及显式的人口均等激励。实验结果表明，所提出的方法在性能和公平性指标之间取得了显著改进，优于基线方法。

</details>


### [211] [Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction](https://arxiv.org/abs/2506.15626)
**中文标题：基于联邦学习的MRI脑年龄预测：一项关于卒中后功能恢复预测的多中心研究**

*Vincent Roca,Marc Tommasi,Paul Andrey,Aurélien Bellet,Markus D. Schirmer,Hilde Henon,Laurent Puy,Julien Ramon,Grégory Kuchcinski,Martin Bretzner,Renaud Lopes*

主要分类: cs.LG

摘要简述: 本研究评估了联邦学习在缺血性卒中患者中用于脑年龄预测（BrainAGE）的性能，发现其优于单中心模型，并揭示了BrainAGE与血管风险因素及卒中后功能恢复的显著关联。


<details>
  <summary>详细信息</summary>
研究动机: 脑年龄差异（BrainAGE）是反映脑健康的神经影像标志物，但训练稳健的BrainAGE模型需要大量数据，而隐私问题限制了数据共享。本研究旨在探索联邦学习（FL）在BrainAGE估计中的应用，并研究其与卒中后功能恢复的关联。

研究方法: 研究使用来自16个医疗中心的1674名卒中患者的FLAIR脑图像，比较了三种数据管理策略：集中学习（数据集中）、联邦学习（各中心本地训练）和单中心学习。通过机器学习与深度学习模型预测BrainAGE，并分析其与血管风险因素（如糖尿病、高血压、吸烟）及卒中后三个月功能恢复的关联。

研究结果: 集中学习预测最准确，但联邦学习显著优于单中心模型。所有模型中，糖尿病患者的BrainAGE显著更高。BrainAGE与卒中后功能恢复的关联在多变量分析中具有显著性。

研究结论: 联邦学习无需数据集中即可实现准确的脑年龄预测。BrainAGE与血管风险因素及卒中后恢复的强关联表明其在卒中预后建模中的潜力。

中文摘要: 目的：脑年龄差异（BrainAGE）是反映脑健康的神经影像标志物，但训练稳健的BrainAGE模型需要大量数据，而隐私问题限制了数据共享。本研究评估了联邦学习（FL）在缺血性卒中患者中用于BrainAGE估计的性能，并研究其与临床表型及功能恢复的关联。方法：我们使用来自16个医疗中心的1674名卒中患者的FLAIR脑图像，比较了集中学习、联邦学习和单中心学习三种策略。通过机器学习与深度学习模型预测BrainAGE，并分析其与血管风险因素及卒中后三个月功能恢复的关联。结果：集中学习预测最准确，但联邦学习显著优于单中心模型。糖尿病患者的BrainAGE显著更高。BrainAGE与功能恢复的关联在多变量分析中具有显著性。结论：联邦学习无需数据集中即可实现准确的脑年龄预测。BrainAGE与血管风险因素及卒中后恢复的强关联表明其在卒中预后建模中的潜力。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [212] [Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures](https://arxiv.org/abs/2506.15043)
**中文标题：基于CNN-LSTM-GRU架构的高超音速导弹轨迹高级预测**

*Amir Hossein Baradaran*

主要分类: cs.CR

摘要简述: 本文提出了一种结合CNN、LSTM和GRU的混合深度学习模型，用于高精度预测高超音速导弹的复杂轨迹，为防御策略和拦截技术提供了重要支持。


<details>
  <summary>详细信息</summary>
研究动机: 高超音速导弹因其极速和高机动性成为重大威胁，准确预测其轨迹对防御至关重要。本文旨在通过先进机器学习方法提升预测能力。

研究方法: 采用CNN、LSTM和GRU的混合架构，结合CNN的空间特征提取能力与LSTM和GRU的时间序列建模优势，实现对高超音速导弹轨迹的高精度预测。

研究结果: 所提方法成功预测了高超音速导弹的复杂轨迹，准确率显著提升，为防御系统提供了可靠的技术支持。

研究结论: 研究表明，混合深度学习模型在高超音速导弹轨迹预测中具有巨大潜力，可显著提升防御系统的预测能力。

中文摘要: 国防工业的进步对确保国家安全至关重要，尤其是应对高超音速导弹等新兴威胁。由于其极速和高机动性，准确预测高超音速导弹轨迹成为防御的关键需求。本文提出了一种新型混合深度学习方法，结合卷积神经网络（CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU），充分利用这些架构的优势，成功实现了对高超音速导弹复杂轨迹的高精度预测。该方法为防御策略和导弹拦截技术提供了重要贡献，展示了先进机器学习技术在提升防御系统预测能力方面的潜力。

</details>


### [213] [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](https://arxiv.org/abs/2506.15253)
**中文标题：RAS-Eval：现实环境中LLM代理安全性的综合评估基准**

*Yuchuan Fu,Xiaohan Yuan,Dongxia Wang*

主要分类: cs.CR

摘要简述: 本文提出了RAS-Eval，一个用于评估大型语言模型（LLM）代理在动态环境中安全性的综合基准测试工具，包含80个测试用例和3,802个攻击任务，覆盖11种常见弱点类别。实验显示，攻击显著降低了代理的任务完成率，并揭示了模型规模与安全性能之间的关系。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型代理在医疗和金融等关键领域的广泛应用，缺乏标准化的安全评估工具成为问题。本文旨在填补这一空白，提供一个支持模拟和真实环境工具执行的综合安全基准测试工具。

研究方法: RAS-Eval包含80个测试用例和3,802个攻击任务，映射到11种常见弱点类别（CWE）。工具支持JSON、LangGraph和模型上下文协议（MCP）格式。实验评估了6种先进LLM在多种场景下的表现。

研究结果: 攻击平均降低了代理任务完成率（TCR）36.78%，在学术环境中攻击成功率达85.65%。模型规模与安全性能呈正相关，大模型表现优于小模型。

研究结论: 研究揭示了现实环境中LLM代理部署的重大安全风险，并提供了一个未来安全研究的基础框架。代码和数据已开源。

中文摘要: 大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署需要强大的安全框架。为解决动态环境中这些代理缺乏标准化评估基准的问题，我们提出了RAS-Eval，一个支持模拟和真实工具执行的综合安全基准测试工具。RAS-Eval包含80个测试用例和3,802个攻击任务，覆盖11种常见弱点类别（CWE），工具支持JSON、LangGraph和模型上下文协议（MCP）格式。我们评估了6种先进LLM在多种场景下的表现，发现显著漏洞：攻击平均降低了代理任务完成率（TCR）36.78%，在学术环境中攻击成功率达85.65%。值得注意的是，模型规模与安全性能呈正相关，大模型表现优于小模型。我们的研究揭示了现实环境中代理部署的重大风险，并为未来安全研究提供了基础框架。代码和数据可在https://github.com/lanzer-tree/RAS-Eval获取。

</details>


### [214] [Evaluation Pipeline for systematically searching for Anomaly Detection Systems](https://arxiv.org/abs/2506.15388)
**中文标题：系统搜索异常检测系统的评估流程**

*Florian Rokohl,Alexander Lehnert,Marc Reichenbach*

主要分类: cs.CR

摘要简述: 本文提出了一种基于硬件的异常检测系统，用于实时检测医疗网络中的恶意客户端，并通过FPGA满足实时性和功耗限制，同时通过整体系统评估提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 医疗领域的数字化虽然带来巨大便利，但也成为攻击者的目标，网络安全问题日益突出。为应对网络入侵者，作者提出了一种实时检测恶意客户端的硬件异常检测系统。

研究方法: 研究采用FPGA实现异常检测系统，以满足实时性和低功耗需求，并通过整体系统评估优化性能。

研究结果: 系统成功实现了在医疗网络中实时检测恶意客户端的目标，同时满足了实时性和功耗限制。

研究结论: 通过FPGA实现的硬件异常检测系统在医疗网络中表现出色，能够有效应对网络安全威胁，同时满足实时性和功耗要求。

中文摘要: 医疗领域的数字化带来了巨大好处，但也使其成为攻击者的目标，网络安全问题难以解决。为应对网络入侵者，我们提出了一种基于硬件的异常检测系统，用于实时检测恶意客户端。通过使用FPGA，我们满足了实时性和功耗限制。整体系统性能通过提出的整体系统评估得以实现。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [215] [Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers](https://arxiv.org/abs/2506.14855)
**中文标题：反馈-MPPI：通过滚动微分实现快速采样模型预测控制——告别低级控制器**

*Tommaso Belvedere,Michael Ziegltrum,Giulio Turrisi,Valerio Modugno*

主要分类: cs.RO

摘要简述: 本文提出Feedback-MPPI（F-MPPI），一种基于采样的模型预测控制方法，通过引入局部线性反馈增益提升实时性和稳定性，适用于复杂机器人任务。


<details>
  <summary>详细信息</summary>
研究动机: 传统MPPI方法在实时高频机器人控制中因计算需求大而受限，需要一种更高效的方法来提升性能。

研究方法: F-MPPI在标准MPPI基础上，通过灵敏度分析计算局部线性反馈增益，实现快速闭环修正，无需每步重新优化。

研究结果: 仿真和实验表明，F-MPPI显著提升了控制性能和稳定性，适用于四足机器人和四旋翼飞行器的复杂任务。

研究结论: F-MPPI通过局部反馈增益有效解决了MPPI的实时性问题，为复杂机器人系统提供了高效控制方案。

中文摘要: 模型预测路径积分控制是一种强大的采样方法，因其处理非线性动力学和非凸成本的灵活性，适用于复杂机器人任务。然而，其在实时高频机器人控制场景中的应用受限于计算需求。本文提出反馈-MPPI（F-MPPI），一种新框架，通过从灵敏度分析中提取局部线性反馈增益来增强标准MPPI，这些增益受基于梯度的MPC中Riccati反馈的启发。这些增益允许在当前状态周围进行快速闭环修正，而无需每步完全重新优化。我们通过仿真和真实实验在两种机器人平台上验证了F-MPPI的有效性：四足机器人在不平地形上执行动态运动，以及四旋翼飞行器通过机载计算执行激进机动。结果表明，引入局部反馈显著提升了控制性能和稳定性，为复杂机器人系统提供了鲁棒的高频操作能力。

</details>


### [216] [FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization](https://arxiv.org/abs/2506.14968)
**中文标题：FEAST：一种面向真实环境个性化的灵活进餐辅助系统**

*Rajat Kumar Jenamani,Tom Silver,Ben Dodson,Shiqin Tong,Anthony Song,Yuting Yang,Ziang Liu,Benjamin Howe,Aimee Whitneck,Tapomayukh Bhattacharjee*

主要分类: cs.RO

摘要简述: FEAST是一种灵活的进餐辅助系统，旨在满足个性化需求，通过模块化硬件、多样化交互方式和可调行为树实现适应性、透明性和安全性。


<details>
  <summary>详细信息</summary>
研究动机: 全球数百万人需要进餐辅助，但家庭环境中的多样性活动、情境和用户偏好使得个性化辅助成为挑战。FEAST旨在解决这一问题。

研究方法: FEAST采用模块化硬件支持多种功能（如喂食、饮水和擦嘴），提供多样化交互方式（如网页界面、头部手势和物理按钮），并通过参数化行为树和大型语言模型实现安全透明的个性化调整。

研究结果: FEAST在个性化需求上表现优异，优于固定定制基线，并通过家庭用户研究和职业治疗师评估验证了其生态有效性。

研究结论: FEAST成功实现了在真实环境中的个性化进餐辅助，满足了用户的多样化需求，展示了其实际应用潜力。

中文摘要: 物理护理机器人有望改善全球数百万需要进餐辅助的人的生活质量。然而，家庭环境中的进餐辅助仍面临挑战，包括活动多样性（如进食、饮水、擦嘴）、情境多样性（如社交、看电视）、食物种类和用户偏好的差异。为此，我们提出了FEAST，一种可在真实环境中个性化的灵活进餐辅助系统。通过与两位社区研究人员合作，并基于对多样化护理对象的形成性研究，我们的系统遵循适应性、透明性和安全性三大原则。FEAST通过以下方式体现这些原则：（i）模块化硬件，支持切换喂食、饮水和擦嘴功能；（ii）多样化交互方式（如网页界面、头部手势和物理按钮），适应不同的功能能力和偏好；（iii）参数化行为树，可通过大型语言模型安全透明地调整。我们根据形成性研究中识别的个性化需求评估系统，表明FEAST提供了广泛的安全透明调整，并优于仅支持固定定制的先进基线。为验证实际应用性，我们与两位护理对象（社区研究人员）进行了家庭用户研究，每人分别在三种情境下完成三餐。我们还通过一位此前不熟悉系统的职业治疗师评估了FEAST的生态有效性。在所有案例中，用户均成功个性化FEAST以满足其需求和偏好。网站：https://emprise.cs.cornell.edu/feast

</details>


### [217] [Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired](https://arxiv.org/abs/2506.14857)
**中文标题：面向视障人士引导的无人机基于感知的避障方法**

*Suman Raj,Swapnil Padhi,Ruchi Bhoot,Prince Modi,Yogesh Simmhan*

主要分类: cs.RO

摘要简述: 本文提出了一种基于感知的无人机路径规划系统，用于协助视障人士在户外城市环境中导航，结合全局规划和局部避障算法，验证了其可行性。


<details>
  <summary>详细信息</summary>
研究动机: 无人机结合机器学习和计算机视觉的自主导航技术已在多个领域产生影响，但如何利用无人机协助视障人士在复杂城市环境中导航仍是一个挑战。本文旨在解决这一问题。

研究方法: 提出了一种基于几何建模的路径规划系统，结合全局规划（基于GPS和地图）和局部规划（基于多深度神经网络框架），用于无人机和视障人士的障碍物避让。

研究结果: 在校园环境中对无人机-人系统进行了评估，验证了算法在三种场景下的可行性：人行道行走、停靠车辆附近和拥挤街道。

研究结论: 所提出的系统能够有效协助视障人士在城市环境中导航，验证了其实际应用的潜力。

中文摘要: 无人机通过机载传感器结合机器学习和计算机视觉算法的自主导航技术正在影响多个领域，包括农业、物流和灾害管理。本文探讨了无人机在协助视障人士（VIPs）在户外城市环境中导航的应用。具体而言，我们提出了一种基于感知的路径规划系统，用于在视障人士附近进行局部规划，并与基于GPS和地图的全局规划相结合。我们通过几何建模表示问题，并提出了一种基于多深度神经网络的框架，用于无人机和视障人士的障碍物避让。在校园环境中对无人机-人系统进行的评估验证了我们的算法在三种场景下的可行性：视障人士在人行道上行走、停靠车辆附近以及拥挤街道中。

</details>


### [218] [Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation](https://arxiv.org/abs/2506.15157)
**中文标题：鲁棒即时策略：利用Student's t回归模型实现机器人操作的鲁棒上下文模仿学习**

*Hanbit Oh,Andrea M. Salcedo-Vázquez,Ixchel G. Ramirez-Alpizar,Yukiyasu Domae*

主要分类: cs.RO

摘要简述: 本文提出了一种鲁棒的即时策略（RIP），利用Student's t回归模型解决基于LLM的即时策略在模仿学习中产生的幻觉问题，显著提高了任务成功率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于大型语言模型（LLM）的即时策略在模仿学习中存在幻觉问题，导致生成的轨迹偏离演示，影响可靠性。本文旨在通过鲁棒方法解决这一问题。

研究方法: 提出鲁棒即时策略（RIP），通过生成多个候选轨迹并使用Student's t分布聚合，忽略异常值（幻觉），从而生成鲁棒的轨迹。

研究结果: 实验表明，RIP在模拟和真实环境中均显著优于现有模仿学习方法，任务成功率提升至少26%，尤其在低数据场景下表现优异。

研究结论: RIP通过鲁棒方法有效解决了LLM即时策略的幻觉问题，提升了模仿学习的可靠性和任务成功率。

中文摘要: 模仿学习（IL）旨在通过观察少量人类演示，使机器人能够自主完成任务。最近，一种称为上下文IL的变体利用现成的大型语言模型（LLM）作为即时策略，通过少量演示理解上下文以执行新任务，而非通过大规模演示显式更新网络模型。然而，其在机器人领域的可靠性受到幻觉问题的削弱，例如LLM即时策略偶尔会生成偏离演示的较差轨迹。为解决这一问题，我们提出了一种新的鲁棒上下文模仿学习算法，称为鲁棒即时策略（RIP），利用Student's t回归模型对即时策略的幻觉轨迹具有鲁棒性，从而生成可靠的轨迹。具体而言，RIP从LLM生成多个候选机器人轨迹以完成任务，并使用Student's t分布聚合它们，这有助于忽略异常值（即幻觉），从而生成鲁棒的轨迹。我们在模拟和真实环境中的实验表明，RIP显著优于最先进的IL方法，任务成功率提升至少26%，尤其是在日常任务的低数据场景中。视频结果请访问https://sites.google.com/view/robustinstantpolicy。

</details>


### [219] [MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System](https://arxiv.org/abs/2506.15402)
**中文标题：MCOO-SLAM：一种多相机全向物体SLAM系统**

*Miaoxin Pan,Jinnan Li,Yaowen Zhang,Yi Yang,Yufeng Yue*

主要分类: cs.RO

摘要简述: MCOO-SLAM是一种多相机全向物体SLAM系统，通过环绕视角相机配置实现复杂户外场景下的鲁棒、一致且语义丰富的建图。


<details>
  <summary>详细信息</summary>
研究动机: 现有物体级SLAM系统多依赖RGB-D传感器或单目视角，存在视野狭窄、遮挡敏感和深度感知有限等问题，尤其在户外或大规模环境中表现不佳。MCOO-SLAM旨在通过多相机全向视角解决这些问题。

研究方法: MCOO-SLAM整合了点特征和物体级地标，并引入开放词汇语义增强。采用语义-几何-时间融合策略实现多视角下的鲁棒物体关联，设计全向闭环模块实现视角不变的地点识别，并构建分层3D场景图支持下游任务。

研究结果: 实验表明，MCOO-SLAM在真实场景中实现了高精度定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强的鲁棒性。

研究结论: MCOO-SLAM通过多相机全向视角和语义增强，显著提升了物体级SLAM的鲁棒性和一致性，适用于复杂户外场景。

中文摘要: 物体级SLAM提供了结构化和语义丰富的环境表示，使其更易解释且适用于高级机器人任务。然而，现有方法多依赖RGB-D传感器或单目视角，存在视野狭窄、遮挡敏感和深度感知有限等问题，尤其是在大规模或户外环境中。这些问题导致系统只能从有限视角观察物体的部分视图，从而影响物体建模和数据关联的准确性。本文提出MCOO-SLAM，一种新型多相机全向物体SLAM系统，充分利用环绕视角相机配置，在复杂户外场景中实现鲁棒、一致且语义丰富的建图。该方法整合了点特征和开放词汇语义增强的物体级地标，引入语义-几何-时间融合策略以实现多视角下的鲁棒物体关联，从而提升一致性和物体建模精度。此外，设计了全向闭环模块，利用场景级描述符实现视角不变的地点识别。构建的地图被抽象为分层3D场景图，以支持下游推理任务。大量真实场景实验表明，MCOO-SLAM实现了高精度定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强的鲁棒性。

</details>


### [220] [Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos](https://arxiv.org/abs/2506.15680)
**中文标题：基于粒子-网格神经动力学的RGB-D视频可变形物体模型学习**

*Kaifeng Zhang,Baoyu Li,Kris Hauser,Yunzhu Li*

主要分类: cs.RO

摘要简述: 本文提出了一种结合粒子与空间网格的神经动力学框架，用于从RGB-D视频中学习可变形物体的动态模型。该方法通过粒子表示物体形状，网格确保空间连续性，实现了对多样化物体的动态建模，并在有限视角下优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 可变形物体的动态建模因其多样的物理特性和视觉信息有限而具有挑战性。本文旨在通过结合粒子与网格的混合表示，解决这些挑战，实现对不同形状和材质物体的动态建模。

研究方法: 提出了一种粒子-网格神经动力学框架，粒子用于表示物体形状，空间网格用于离散化3D空间以确保空间连续性和学习效率。结合高斯溅射进行视觉渲染，实现了完全基于学习的可变形物体数字孪生，并能生成3D动作条件视频。

研究结果: 实验表明，该方法能够从稀疏视角的RGB-D记录中学习绳索、布料、毛绒玩具和纸袋等多样化物体的动态，并在类别级别上泛化到未见实例。在有限视角场景下，其性能优于现有的基于学习和物理的模拟器。

研究结论: 本文提出的粒子-网格神经动力学框架为可变形物体的动态建模提供了一种高效且通用的方法，适用于目标驱动的物体操控任务，展示了在模型规划中的实用性。

中文摘要: 由于可变形物体多样的物理特性以及从有限视觉信息中估计状态的困难，建模其动态具有挑战性。我们通过一种结合物体粒子和空间网格的混合表示的神经动力学框架来解决这些挑战。我们的粒子-网格模型捕捉全局形状和运动信息，同时预测密集粒子运动，从而能够建模具有不同形状和材质的物体。粒子表示物体形状，而空间网格将3D空间离散化以确保空间连续性并提高学习效率。结合高斯溅射进行视觉渲染，我们的框架实现了完全基于学习的可变形物体数字孪生，并生成了3D动作条件视频。通过实验，我们证明了我们的模型能够从机器人-物体交互的稀疏视角RGB-D记录中学习绳索、布料、毛绒玩具和纸袋等多样化物体的动态，并在类别级别上泛化到未见实例。我们的方法在有限视角场景下优于现有的基于学习和物理的模拟器。此外，我们展示了学习模型在基于模型的规划中的实用性，实现了目标驱动的物体操控任务。项目页面见https://kywind.github.io/pgnd。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [221] [Deploying and Evaluating Multiple Deep Learning Models on Edge Devices for Diabetic Retinopathy Detection](https://arxiv.org/abs/2506.14834)
**中文标题：在边缘设备上部署和评估多种深度学习模型用于糖尿病视网膜病变检测**

*Akwasi Asare,Dennis Agyemanh Nana Gookyi,Derrick Boateng,Fortunatus Aabangbio Wulnye*

主要分类: eess.IV

摘要简述: 本文提出了一种基于边缘设备的多深度学习模型部署方案，用于实时检测糖尿病视网膜病变（DR）。通过优化模型并量化至8位整数，在保持高精度的同时显著提升推理速度，为资源有限的医疗场景提供高效解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 糖尿病视网膜病变（DR）是全球糖尿病患者视力受损的主要原因，传统诊断方法耗时且资源密集。本研究旨在利用边缘AI技术，提供一种实时、高效且成本低廉的DR检测方案，尤其适用于资源受限的医疗环境。

研究方法: 研究使用Kaggle EyePACS数据集中的3,662张视网膜眼底图像，通过数据增强和归一化进行预处理。采用TensorFlow设计了多种卷积神经网络（如MobileNet、ShuffleNet、SqueezeNet和自定义DNN），并将其转换为TensorFlowLite格式并量化至8位整数，以优化模型大小和推理速度。

研究结果: MobileNet的准确率达到96.45%，SqueezeNet在GPU上的推理延迟仅为17毫秒，模型大小仅176 KB。ShuffleNet和自定义DNN在资源效率上表现优异，适合低端设备。所有模型在边缘硬件平台上均表现出良好的性能。

研究结论: 边缘AI技术的应用为糖尿病视网膜病变的早期检测提供了一种可扩展且经济高效的解决方案，尤其适用于资源有限的远程医疗场景。

中文摘要: 糖尿病视网膜病变（DR）是糖尿病患者视力受损的主要原因，全球约34.6%的糖尿病患者受其影响，预计到2045年病例数将达到2.42亿。传统的DR诊断依赖于人工检查视网膜眼底图像，耗时且资源密集。本研究提出了一种基于Edge Impulse的创新解决方案，通过在边缘设备上部署多种深度学习模型实现实时DR检测。研究使用Kaggle EyePACS数据集中的3,662张视网膜眼底图像，并通过增强和归一化等预处理技术优化数据。利用TensorFlow设计了多种卷积神经网络（如MobileNet、ShuffleNet、SqueezeNet和自定义DNN），并将其转换为TensorFlowLite格式并量化至8位整数，以减少模型大小并提升推理速度，同时精度损失最小。在不同边缘硬件平台（包括智能手机和微控制器）上的性能评估中，重点关注了推理速度、准确率、精确度和资源利用率等指标。MobileNet的准确率达到96.45%，而SqueezeNet在GPU上的推理延迟仅为17毫秒，模型大小仅176 KB。ShuffleNet和自定义DNN在资源效率上表现优异，适合低端设备。边缘AI技术与医疗健康的结合为早期DR检测提供了一种可扩展且经济高效的解决方案，尤其适用于资源有限的远程医疗场景。

</details>


### [222] [Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)](https://arxiv.org/abs/2506.14909)
**中文标题：基于面部图像的健康识别基础人工智能模型（FAHR-Face）**

*Fridolin Haugg,Grace Lee,John He,Leonard Nürnberg,Dennis Bontempi,Danielle S. Bitterman,Paul Catalano,Vasco Prudente,Dmitrii Glubokov,Andrew Warrington,Suraj Pai,Dirk De Ruysscher,Christian Guthier,Benjamin H. Kann,Vadim N. Gladyshev,Hugo JWL Aerts,Raymond H. Mak*

主要分类: eess.IV

摘要简述: FAHR-Face是一种基于面部图像的健康识别基础AI模型，通过训练超过4000万张面部图像，并针对生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）进行微调。模型在公开数据集和癌症患者数据中表现出色，具有高准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 面部外观为非侵入性健康监测提供了窗口。研究旨在开发一种基础AI模型，通过面部图像捕捉生物衰老和疾病相关死亡风险，为临床提供低成本、可扩展的生物标志物。

研究方法: FAHR-FaceAge通过两阶段年龄平衡微调在749,935张公开图像上训练；FAHR-FaceSurvival在34,389张癌症患者照片上微调。测试了模型对整容、化妆、姿势和光照的鲁棒性，并通过多变量Cox模型在独立癌症患者数据集中验证。

研究结果: FAHR-FaceAge在公开数据集上平均绝对误差为5.1年，优于基准模型；FAHR-FaceSurvival预测死亡率风险最高四分位组的死亡风险是最低组的三倍以上（调整后风险比3.22；P<0.001）。两种模型在年龄、性别、种族和癌症亚组中均表现出泛化能力。

研究结论: 单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物衰老和疾病相关死亡风险。模型通过小规模临床数据集有效训练，为健康监测提供了新工具。

中文摘要: 背景：面部外观为非侵入性健康监测提供了窗口。我们开发了FAHR-Face，一种基于超过4000万张面部图像训练的基础模型，并针对生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）进行了微调。方法：FAHR-FaceAge在749,935张公开图像上进行了两阶段年龄平衡微调；FAHR-FaceSurvival在34,389张癌症患者照片上微调。测试了模型对整容、化妆、姿势和光照的鲁棒性，并通过多变量Cox模型在独立癌症患者数据集中验证。结果：FAHR-FaceAge在公开数据集上平均绝对误差为5.1年，优于基准模型；FAHR-FaceSurvival预测死亡率风险最高四分位组的死亡风险是最低组的三倍以上（调整后风险比3.22；P<0.001）。两种模型在年龄、性别、种族和癌症亚组中均表现出泛化能力。结论：单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物衰老和疾病相关死亡风险。模型通过小规模临床数据集有效训练，为健康监测提供了新工具。

</details>


### [223] [Empirical Studies of Large Scale Environment Scanning by Consumer Electronics](https://arxiv.org/abs/2506.14771)
**中文标题：消费电子产品大规模环境扫描的实证研究**

*Mengyuan Wang,Yang Liu,Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

主要分类: eess.IV

摘要简述: 本文对消费级3D扫描设备Matterport Pro3在大规模环境重建中的表现进行了实证评估，展示了其在成本效益与性能之间的平衡，以及通过LiDAR和高级对齐技术生成高质量3D模型的能力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估Matterport Pro3在大规模环境扫描中的有效性、局限性和性能提升，探索其在消费级设备中的实际应用潜力。

研究方法: 研究对一栋六层建筑（17,567平方米）进行了1,099个扫描点的详细扫描，并与iPhone等设备进行对比分析，评估点云密度和对齐精度。

研究结果: Matterport Pro3生成的点云密度更高（1,877,324点vs. iPhone的506,961点），对齐误差更小（RMSE为0.0118米），云间平均距离误差为0.0408米，标准差0.0715米。

研究结论: Matterport Pro3能够生成适合大规模应用的高质量3D模型，展示了其在消费级设备中的优越性能和成本效益。

中文摘要: 本文对消费级3D扫描设备Matterport Pro3在大规模环境重建中的表现进行了实证评估。我们对一栋六层建筑（17,567平方米）进行了1,099个扫描点的详细扫描，评估了该设备的有效性、局限性和性能提升。针对扫描过程中遇到的挑战，提出了解决方案，并探索了更有效的先进方法。与另一款消费级设备（iPhone）的对比分析显示，Pro3在成本效益与性能之间取得了平衡。Matterport Pro3生成的点云密度更高（1,877,324点vs. iPhone的506,961点），对齐精度更高（RMSE为0.0118米）。两模型间的云间平均距离误差为0.0408米，标准差为0.0715米。研究表明，Pro3能够利用LiDAR和高级对齐技术生成适合大规模应用的高质量3D模型。

</details>


### [224] [Improving Prostate Gland Segmenting Using Transformer based Architectures](https://arxiv.org/abs/2506.14844)
**中文标题：基于Transformer架构的前列腺分割改进研究**

*Shatha Abudalou*

主要分类: eess.IV

摘要简述: 本研究探讨了基于Transformer架构的SwinUNETR和UNETR在T2加权MRI图像中前列腺分割的性能，发现SwinUNETR在减少标签噪声和类别不平衡敏感性方面表现优异，Dice分数比传统CNN模型提升高达5分。


<details>
  <summary>详细信息</summary>
研究动机: 由于不同读者标注的差异和跨站点数据域偏移，T2加权MRI图像的前列腺自动分割面临挑战。本研究旨在验证Transformer模型能否在此类异质性数据中保持高精度。

研究方法: 研究比较了UNETR和SwinUNETR与基线3D UNet在前列腺分割中的表现，使用了546个由两位专家标注的T2加权MRI数据。分析了三种训练策略：单队列数据集、5折交叉验证混合队列和基于腺体大小的数据集，并使用Optuna优化超参数。

研究结果: 在单读者训练中，SwinUNETR的平均Dice分数为0.816（读者1）和0.860（读者2），优于UNETR和基线UNet。在交叉验证混合训练中，SwinUNETR表现更优，Dice分数达0.8583（读者1）和0.867（读者2）。在基于腺体大小的数据集中，SwinUNETR在较大腺体子集中的Dice分数高达0.902（读者1）和0.894（读者2）。

研究结论: 研究表明，全局和移位窗口自注意力机制能有效减少标签噪声和类别不平衡敏感性，SwinUNETR在Dice分数上比CNN模型提升高达5分，同时保持计算效率，适合临床部署。

中文摘要: 不同读者标注的差异和跨站点数据域偏移对T2加权MRI图像的前列腺自动分割提出了挑战。本研究探讨了Transformer模型能否在此类异质性数据中保持高精度。我们比较了UNETR和SwinUNETR与基线3D UNet在前列腺分割中的表现，使用了546个由两位专家标注的T2加权MRI数据。分析了三种训练策略：单队列数据集、5折交叉验证混合队列和基于腺体大小的数据集，并使用Optuna优化超参数。测试集来自独立读者群体，以Dice相似系数为评估终点。在单读者训练中，SwinUNETR的平均Dice分数为0.816（读者1）和0.860（读者2），优于UNETR和基线UNet。在交叉验证混合训练中，SwinUNETR表现更优，Dice分数达0.8583（读者1）和0.867（读者2）。在基于腺体大小的数据集中，SwinUNETR在较大腺体子集中的Dice分数高达0.902（读者1）和0.894（读者2）。研究结果表明，全局和移位窗口自注意力机制能有效减少标签噪声和类别不平衡敏感性，SwinUNETR在Dice分数上比CNN模型提升高达5分，同时保持计算效率，适合临床部署。

</details>


### [225] [Recursive Variational Autoencoders for 3D Blood Vessel Generative Modeling](https://arxiv.org/abs/2506.14914)
**中文标题：用于3D血管生成建模的递归变分自编码器**

*Paula Feldman,Miguel Fainstein,Viviana Siless,Claudio Delrieux,Emmanuel Iarussi*

主要分类: eess.IV

摘要简述: 本文提出了一种递归变分自编码器（RvNN），用于生成3D血管模型，能够捕捉真实血管的多样性和复杂性，适用于医学训练和模拟。


<details>
  <summary>详细信息</summary>
研究动机: 解剖树结构在临床诊断和治疗规划中至关重要，但现有方法多为规则驱动，难以准确捕捉真实血管的复杂性和多样性。

研究方法: 开发了一种递归变分神经网络（RvNN），利用血管的层次结构学习低维流形编码分支连接性和几何特征，生成新的血管模型。

研究结果: 生成的3D血管模型在半径、长度和弯曲度等方面与真实数据高度相似，适用于医学训练和血流模拟等场景。

研究结论: RvNN首次成功应用于血管合成，生成的模型既准确又多样，为医学领域提供了重要工具。

中文摘要: 解剖树结构在临床诊断和治疗规划中具有重要作用。然而，由于其复杂的拓扑和几何结构，准确表示这些结构具有挑战性。现有的血管合成方法多为规则驱动，虽然能提供一定程度的控制和变化，但无法捕捉真实解剖数据的多样性和复杂性。我们开发了一种递归变分神经网络（RvNN），充分利用血管的层次结构，学习编码分支连接性和描述目标表面的几何特征的低维流形。训练后，RvNN的潜在空间可通过采样生成新的血管几何形状。通过利用生成神经网络的强大能力，我们生成了既准确又多样的3D血管模型，这对医学和外科训练、血流模拟等多种用途至关重要。这些结果与真实数据高度相似，在血管半径、长度和弯曲度等方面表现出色，包括含有动脉瘤的数据集。据我们所知，这是首次利用该技术合成血管的研究。

</details>


### [226] [NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal Neurological Disorder Classification](https://arxiv.org/abs/2506.14970)
**中文标题：NeuroMoE：一种基于Transformer的混合专家框架用于多模态神经疾病分类**

*Wajih Hassan Raza,Aamir Bader Shah,Yu Wen,Yidan Shen,Juan Diego Martinez Lemus,Mya Caryn Schiess,Timothy Michael Ellmore,Renjie Hu,Xin Fu*

主要分类: eess.IV

摘要简述: 本文提出了一种基于Transformer的混合专家框架NeuroMoE，用于多模态神经疾病分类，结合MRI和临床数据，显著提升了诊断准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度学习方法在多模态MRI和临床数据的整合上表现不佳，影响了神经疾病的诊断效果。本文旨在通过提出一种新框架，充分利用多模态数据提升诊断性能。

研究方法: 基于Transformer的混合专家框架，结合解剖MRI、扩散张量成像和功能MRI等多模态数据，通过模态特定专家提取特征，并利用自适应融合门控机制动态整合输出。

研究结果: 实验表明，该框架在验证集上达到82.47%的准确率，比基线方法提升超过10%，尤其在区分重叠疾病状态方面表现突出。

研究结论: NeuroMoE框架通过多模态学习显著提升了神经疾病诊断的准确性，展示了其在临床数据应用中的潜力。

中文摘要: 多模态磁共振成像（MRI）与临床数据的整合为提升神经疾病（NDs）的诊断提供了巨大潜力。深度学习（DL）已成为从医学数据中提取有意义模式的有力工具，但现有方法在多模态MRI和临床数据的利用上表现不佳。为解决这一问题，我们利用专为ND研究定制的多模态临床数据集，提出了一种基于Transformer的混合专家（MoE）框架。该框架结合解剖MRI（aMRI）、扩散张量成像（DTI）和功能MRI（fMRI）以及临床评估数据，通过Transformer编码器捕捉MRI数据的空间关系，并利用模态特定专家进行特征提取。自适应融合门控机制动态整合专家输出，确保最佳预测性能。全面的实验和基线对比表明，我们的多模态方法显著提升了诊断准确性，尤其在区分重叠疾病状态方面。该框架在验证集上达到82.47%的准确率，比基线方法高出10%以上，展示了其在真实临床数据中应用多模态学习提升ND诊断的潜力。

</details>


### [227] [Classification of Multi-Parametric Body MRI Series Using Deep Learning](https://arxiv.org/abs/2506.15182)
**中文标题：基于深度学习的多参数体部MRI序列分类**

*Boah Kim,Tejas Sudharshan Mathai,Kimberly Helm,Peter A. Pinto,Ronald M. Summers*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的模型，用于分类多参数磁共振成像（mpMRI）中的8种不同序列类型，以提高放射科医生的工作效率。通过比较多种深度学习分类器，DenseNet-121表现最佳，并在内部和外部数据集上均显示出高准确性。


<details>
  <summary>详细信息</summary>
研究动机: 多参数磁共振成像（mpMRI）的DICOM头部信息常因协议多样性和技术员错误而不准确，导致放射科医生阅读效率低下。本文旨在通过深度学习模型自动分类mpMRI序列类型，以解决这一问题。

研究方法: 使用来自多个机构的mpMRI数据，训练了ResNet、EfficientNet和DenseNet等多种深度学习分类器，比较其性能。最佳模型DenseNet-121在不同训练数据量和外部数据集上进一步验证。

研究结果: DenseNet-121在内部数据集上F1分数和准确率分别达到0.966和0.972，外部数据集上准确率为0.872和0.810。训练数据量超过729例时，模型性能显著提升。

研究结论: DenseNet-121模型在分类8种mpMRI序列类型任务中表现出色，适用于内部和外部数据集，为放射科医生提供了高效的工具。

中文摘要: 多参数磁共振成像（mpMRI）检查包含多种不同成像协议获取的序列类型。由于协议多样性及技术员操作错误，这些序列的DICOM头部信息常不准确。为此，我们提出了一种基于深度学习的分类模型，用于分类8种体部mpMRI序列类型，以提高放射科医生的工作效率。通过使用来自多个机构的mpMRI数据，我们训练了ResNet、EfficientNet和DenseNet等多种深度学习分类器，并比较其性能。随后，确定了表现最佳的DenseNet-121分类器，并研究了其在不同训练数据量下的分类能力。此外，模型还在非训练分布的数据集上进行了评估。实验结果表明，DenseNet-121模型的F1分数和准确率分别为0.966和0.972，显著优于其他分类模型（p值<0.05）。当训练数据量超过729例时，模型准确率超过0.95，且性能随数据量增加而提升。在外部数据集DLDS和CPTAC-UCEC上，模型准确率分别为0.872和0.810。这些结果表明，DenseNet-121模型在内部和外部数据集上均能高效分类8种体部MRI序列类型。

</details>


### [228] [Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference](https://arxiv.org/abs/2506.15258)
**中文标题：基于同态加密的潜在空间胸部X光分类隐私保护方法**

*Jonghun Kim,Gyeongdeok Jo,Shinyoung Ra,Hyunjin Park*

主要分类: eess.IV

摘要简述: 本文提出了一种基于同态加密（HE）的医疗图像隐私保护分类框架，通过VQGAN压缩图像为潜在表示以减少计算负担，同时保持图像质量。方法在胸部X光数据集上测试，展示了实用潜力。


<details>
  <summary>详细信息</summary>
研究动机: 医疗影像数据包含敏感信息，需隐私保护。传统方法需将数据发送至服务器，存在隐私风险。同态加密可在加密数据上计算，但计算成本高，尤其是大图像（如胸部X光）。本研究旨在解决这一问题。

研究方法: 使用VQGAN将图像压缩为潜在表示以减少计算负担；用低次多项式近似激活函数以平衡精度与效率；引入挤压激励模块提升性能。在胸部X光数据集上测试。

研究结果: 压缩因子为8时性能与计算成本达到最优平衡。HE推理虽较慢且性能略有下降，但展示了医疗图像隐私保护的实用潜力。

研究结论: 提出的框架在保护隐私的同时，显著降低了计算负担，为医疗图像的同态加密推理提供了可行方案。

中文摘要: 医疗影像数据包含敏感患者信息，需严格隐私保护。传统分析需将数据发送至服务器进行推理，而同态加密（HE）可在加密数据上计算而不泄露原始信息。然而，HE推理计算成本高，尤其对大图像（如胸部X光）。本研究提出一种HE推理框架，利用VQGAN将图像压缩为潜在表示，显著降低计算负担并保持图像质量。通过低次多项式近似激活函数以平衡精度与效率。实验发现压缩因子为8时性能与计算成本最优。进一步引入挤压激励模块以提升传统CNN性能。方法在两种胸部X光数据集上测试，虽HE推理较慢且性能略有差异，但展示了医疗图像隐私保护的实用潜力。

</details>


### [229] [FedWSIDD: Federated Whole Slide Image Classification via Dataset Distillation](https://arxiv.org/abs/2506.15365)
**中文标题：FedWSIDD：基于数据集蒸馏的联邦全切片图像分类方法**

*Haolong Jin,Shenglin Liu,Cong Cong,Qingmin Feng,Yongzhi Liu,Lina Huang,Yingzi Hu*

主要分类: eess.IV

摘要简述: FedWSIDD是一种新颖的联邦学习方法，通过数据集蒸馏技术解决全切片图像分类中的计算资源异构性和隐私问题，提升分类性能并保护患者隐私。


<details>
  <summary>详细信息</summary>
研究动机: 在医学图像分析中，联邦学习（FL）虽然能保护患者隐私，但在全切片图像（WSI）分类中面临计算资源异构性和隐私泄露的挑战。FedWSIDD旨在通过数据集蒸馏技术解决这些问题。

研究方法: FedWSIDD采用数据集蒸馏（DD）技术，服务器端聚合并分发合成切片，客户端通过定制化的DD算法生成高信息量的合成切片。这些切片而非模型参数被传输，结合原始切片用于本地任务。

研究结果: 在CAMELYON16和CAMELYON17等WSI分类任务上的实验表明，FedWSIDD支持异构本地模型，显著提升分类性能，同时保护患者隐私。

研究结论: FedWSIDD是一种高效且隐私保护的WSI分类解决方案，适用于复杂的医学图像分析任务。

中文摘要: 联邦学习（FL）作为一种协作式医学图像分析方法，能够在保护敏感患者数据的同时构建鲁棒的预测模型。然而，在全切片图像（WSI）分类中，FL面临计算资源异构性和隐私问题等挑战。为解决这些问题，我们提出了FedWSIDD，一种新颖的FL范式，利用数据集蒸馏（DD）技术学习和传输合成切片。在服务器端，FedWSIDD聚合来自各参与中心的合成切片并分发给所有中心。在客户端，我们提出了一种针对病理数据集的定制化DD算法，将染色标准化融入蒸馏过程，生成一组紧凑且信息丰富的合成切片。这些合成切片而非模型参数被传输至服务器。通信完成后，接收到的合成切片与原始切片结合用于本地任务。在CAMELYON16和CAMELYON17等多个WSI分类任务上的广泛实验表明，FedWSIDD能够灵活适应异构本地模型，提升本地WSI分类性能，并保护患者隐私，是一种高效的复杂WSI分类解决方案。代码已在FedWSIDD开源。

</details>


### [230] [A Real-time Endoscopic Image Denoising System](https://arxiv.org/abs/2506.15395)
**中文标题：一种实时内窥镜图像去噪系统**

*Yu Xing,Shishi Huang,Meng Lv,Guo Chen,Huailiang Wang,Lingzhi Sui*

主要分类: eess.IV

摘要简述: 本文提出了一种实时内窥镜图像去噪系统，通过结合传统图像处理算法与学习技术，有效解决了微型模拟图像传感器带来的噪声问题，并在FPGA平台上实现了实时性能。


<details>
  <summary>详细信息</summary>
研究动机: 微型内窥镜的模拟图像传感器因感光面积小、动态范围有限及电路简化，导致图像噪声显著，影响诊断效果。本文旨在解决这一问题。

研究方法: 提出了一种混合去噪系统，结合传统图像处理算法与学习技术，针对固定模式噪声、周期性带状噪声和混合泊松-高斯噪声进行建模与处理。

研究结果: 实验表明，该系统在FPGA平台上实现了实时去噪，平均PSNR从21.16提升至33.05，且未损失细节或导致色彩失真。

研究结论: 本文提出的混合去噪系统有效解决了内窥镜图像噪声问题，为微型传感器的临床应用提供了技术支持。

中文摘要: 微型内窥镜的设计显著提升了操作的灵活性、便携性和诊断能力，同时降低了医疗过程的侵入性。近年来，配备超紧凑模拟图像传感器（小于1mm×1mm）的一次性内窥镜为医疗诊断带来了革命性进步。它们减少了可重复使用设备的结构冗余和高额成本，消除了因消毒不彻底导致的患者感染风险，并减轻了患者痛苦。然而，有限的感光面积导致每个像素捕获的光子减少，需要更高的光子灵敏度设置以维持亮度。在高对比度医疗成像场景中，小型传感器的动态范围受限，难以同时捕捉高光和阴影的细节，需要额外的局部数字增益补偿。此外，简化的电路设计和模拟信号传输引入了额外的噪声源。这些因素共同导致内窥镜图像处理中出现显著的噪声问题。本研究开发了一种针对医疗内窥镜模拟图像传感器的综合噪声模型，解决了三种主要噪声类型：固定模式噪声、周期性带状噪声和混合泊松-高斯噪声。基于此分析，我们提出了一种混合去噪系统，将传统图像处理算法与先进的基于学习的技术相结合，用于传感器捕获的原始帧。实验表明，我们的方法在FPGA平台上实现了实时性能，有效降低了图像噪声，同时避免了细节损失或色彩失真，测试数据集的平均PSNR从21.16提升至33.05。

</details>


### [231] [Advanced cervical cancer classification: enhancing pap smear images with hybrid PMD Filter-CLAHE](https://arxiv.org/abs/2506.15489)
**中文标题：高级宫颈癌分类：通过混合PMD滤波器-CLAHE增强Pap涂片图像**

*Ach Khozaimi,Isnani Darti,Syaiful Anam,Wuryansari Muharini Kusumawinahyu*

主要分类: eess.IV

摘要简述: 本研究探讨了混合PMD滤波器-CLAHE预处理技术对宫颈癌分类中CNN性能的影响，结果显示该方法显著提升了图像质量和分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 宫颈癌在发展中国家仍是重大健康问题，早期检测对治疗至关重要。CNN在自动化筛查中表现优异，但其性能依赖于Pap涂片图像质量。

研究方法: 研究评估了三种预处理技术：PMD滤波器降噪、CLAHE增强对比度，以及提出的混合PMD滤波器-CLAHE方法，并在多个预训练模型上测试。

研究结果: 混合PMD滤波器-CLAHE方法显著提升了图像质量和CNN性能，最高提升为准确率13.62%、精确率10.04%、召回率13.08%和F1分数14.34%。

研究结论: 混合PMD滤波器-CLAHE技术为提升宫颈癌分类性能提供了新视角，尤其在CNN架构中表现突出。

中文摘要: 宫颈癌在发展中国家仍是重大健康问题，早期检测对治疗至关重要。卷积神经网络（CNN）在自动化宫颈癌筛查中表现出潜力，但其性能依赖于Pap涂片图像质量。本研究探讨了不同图像预处理技术对CNN在宫颈癌分类中性能的影响，使用了SIPaKMeD数据集。评估了三种预处理技术：PMD滤波器降噪、CLAHE增强对比度，以及提出的混合PMD滤波器-CLAHE方法。增强后的图像数据集在多个预训练模型（如ResNet-34、ResNet-50、SqueezeNet-1.0、MobileNet-V2、EfficientNet-B0、EfficientNet-B1、DenseNet-121和DenseNet-201）上进行了测试。结果表明，混合PMD滤波器-CLAHE预处理能显著提升Pap涂片图像质量和CNN架构性能，相比原始图像，最高提升为准确率13.62%、精确率10.04%、召回率13.08%和F1分数14.34%。提出的混合PMD滤波器-CLAHE技术为提升宫颈癌分类性能提供了新视角。

</details>


### [232] [Automated MRI Tumor Segmentation using hybrid U-Net with Transformer and Efficient Attention](https://arxiv.org/abs/2506.15562)
**中文标题：基于混合U-Net与Transformer及高效注意力的MRI肿瘤自动分割**

*Syed Haider Ali,Asrar Ahmad,Muhammad Ali,Asifullah Khan,Muhammad Shahban,Nadeem Shaukat*

主要分类: eess.IV

摘要简述: 本研究提出了一种结合U-Net与Transformer的高效混合模型，用于MRI肿瘤自动分割，通过本地医院数据集验证了其临床适用性。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI分割模型多基于大型公共数据集，缺乏对本地患者群体的适应性。本研究旨在开发适用于本地医院的高效肿瘤分割模型，以优化放疗计划。

研究方法: 采用混合U-Net-Transformer架构，结合高效注意力模块（如SE、CBAM和ResNeXt），并通过数据增强和预训练权重初始化提升模型性能。

研究结果: 在本地MRI数据集上，模型达到Dice系数0.764和IoU 0.736，表现优异，验证了本地化模型的重要性。

研究结论: 研究表明，结合本地数据集和高效混合模型可显著提升肿瘤分割精度，为临床部署提供了有力支持。

中文摘要: 癌症是一种异常生长，可能局部侵袭并转移至远处器官。放疗计划优化需要准确自动分割肿瘤及周围正常组织。现有基于AI的分割模型通常在大规模公共数据集上训练，缺乏对本地患者群体的异质性。尽管这些研究推动了AI医学图像分割的发展，但基于本地数据集的研究对于将AI肿瘤分割模型直接整合至医院软件、实现高效精准的肿瘤治疗计划与执行至关重要。本研究通过计算高效的混合U-Net-Transformer模型，在严格隐私保护下使用本地医院MRI数据集提升肿瘤分割效果。我们开发了稳健的数据流程，实现无缝DICOM提取与预处理，并通过大量图像增强确保模型在多样化临床场景中的泛化能力，最终形成6080张图像的训练集。新架构结合了基于U-Net的卷积神经网络与Transformer瓶颈及互补注意力模块（包括高效注意力、SE块、CBAM和ResNeXt块）。为加速收敛并降低计算需求，我们采用最大批次大小为8，并使用预训练ImageNet权重初始化编码器，通过检查点在双NVIDIA T4 GPU上训练模型以克服Kaggle运行时限制。在本地MRI数据集上的定量评估显示，Dice相似系数为0.764，交并比（IoU）为0.736，尽管数据有限，仍表现出竞争力，凸显了针对特定临床场景开发模型的重要性。

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [233] [Identifiability by common backdoor in summary causal graphs of time series](https://arxiv.org/abs/2506.14862)
**中文标题：时间序列摘要因果图中通过共同后门集的可识别性**

*Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier*

主要分类: math.ST

摘要简述: 本文研究了时间序列中基于共同后门集的因果图可识别性问题，提出了在时间序列中是否存在共同后门集的条件，并提供了复杂度有限的算法来判断可识别性。


<details>
  <summary>详细信息</summary>
研究动机: 干预的可识别性问题旨在评估某些干预的总效应是否可以用无干预公式表示，从而仅通过观测数据计算。本文在时间序列背景下，研究多干预和多效应的可识别性，尤其是在仅能获得真实因果图的抽象形式（即摘要因果图）时。

研究方法: 研究聚焦于通过共同后门集实现可识别性，针对时间序列（包括时间一致和不一致的情况），提出了存在共同后门集的条件，并设计了复杂度有限的算法来判断可识别性。

研究结果: 本文确立了时间序列中是否存在共同后门集的条件，并提供了判断可识别性的算法。

研究结论: 通过共同后门集实现可识别性在时间序列中是可行的，本文提出的条件和算法为相关研究提供了理论支持。

中文摘要: 干预的可识别性问题旨在评估某些干预的总效应是否可以用无干预公式表示，从而仅通过观测数据计算。本文在时间序列背景下研究这一问题，考虑多干预和多效应，且仅能获得真实因果图的摘要形式（即摘要因果图）。我们聚焦于通过共同后门集实现可识别性，并针对时间序列（包括时间一致和不一致的情况）提出了存在共同后门集的条件。此外，还提供了复杂度有限的算法来判断问题是否可识别。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [234] [An Empirical Study of Bugs in Data Visualization Libraries](https://arxiv.org/abs/2506.15084)
**中文标题：数据可视化库中错误的实证研究**

*Weiqi Lu,Yongqiang Tian,Xiaohan Zhong,Haoyang Ma,Zhenyang Xu,Shing-Chi Cheung,Chengnian Sun*

主要分类: cs.SE

摘要简述: 本研究首次对数据可视化库中的错误进行了全面分析，收集了五个常用库中的564个错误，系统分析了其症状和根本原因，并提出了一种详细的分类法。研究发现，错误/不准确的绘图在数据可视化库中普遍存在，主要原因是图形计算错误，需要进一步开发自动化测试方法。此外，研究还探索了视觉语言模型（VLMs）在检测错误绘图中的可行性，结果显示其效果因提示内容而异。


<details>
  <summary>详细信息</summary>
研究动机: 数据可视化库在数据呈现、分析和应用开发中至关重要，但其错误可能导致误导性可视化，影响用户体验和决策。由于这些错误通常不会引发明显崩溃，而是通过图形误导用户，因此了解其独特特征对检测和修复这些错误至关重要。

研究方法: 研究收集了五个广泛使用的数据可视化库中的564个错误，系统分析了其症状和根本原因，并提出了一种详细的分类法。此外，研究还探索了视觉语言模型（VLMs）在检测错误绘图中的可行性。

研究结果: 研究发现，错误/不准确的绘图在数据可视化库中普遍存在，主要原因是图形计算错误。研究还识别了触发这些错误的八个关键步骤和两个特定的测试预言，并发现VLMs在检测错误绘图中的效果因提示内容而异，范围为29%至57%。

研究结论: 数据可视化库中的错误需要进一步开发自动化测试方法，而VLMs在检测错误绘图方面具有一定潜力，但其效果需进一步优化。研究结果为未来设计有效的自动化测试技术提供了启发。

中文摘要: 数据可视化（DataViz）库在数据呈现、分析和应用开发中扮演着关键角色，其准确性对将数据转化为可视化表示至关重要。错误的可视化可能对用户体验、信息传递和用户决策产生负面影响。这些库中的视觉错误尤其隐蔽，因为它们不会引发明显的崩溃，而是通过图形误导用户，导致错误的决策。因此，深入了解数据可视化库中错误的独特特征对研究人员和开发者检测和修复这些错误至关重要。本研究首次对数据可视化库中的错误进行了全面分析，收集了五个广泛使用的库中的564个错误，系统分析了其症状和根本原因，并提出了一种详细的分类法。我们发现，错误/不准确的绘图在数据可视化库中普遍存在，主要原因是图形计算错误，需要进一步开发自动化测试方法。此外，我们识别了触发这些错误的八个关键步骤和两个特定的测试预言，这可能为未来设计有效的自动化测试技术提供启发。随着视觉语言模型（VLMs）的最新进展，我们还探索了这些模型在检测错误/不准确绘图中的可行性。结果显示，VLMs在错误检测中的效果因提示内容而异，范围为29%至57%，且增加提示中的信息量并不一定能提高效果。更多发现详见我们的论文。

</details>


### [235] [Uncovering Intention through LLM-Driven Code Snippet Description Generation](https://arxiv.org/abs/2506.15453)
**中文标题：通过LLM驱动的代码片段描述生成揭示意图**

*Yusuf Sulistyo Nugroho,Farah Danisha Salam,Brittany Reid,Raula Gaikovina Kula,Kazumasa Shimari,Kenichi Matsumoto*

主要分类: cs.SE

摘要简述: 本文研究了大型语言模型（LLM）在生成代码片段描述中的表现，发现其能较好识别示例用途，但生成的描述仍有改进空间。


<details>
  <summary>详细信息</summary>
研究动机: 代码片段的文档化对开发者和用户至关重要，尤其是第三方库的使用示例。随着大型语言模型（LLM）的兴起，研究其如何支持描述生成成为关键目标。

研究方法: 研究使用NPM代码片段数据集（185,412个包，1,024,579个代码片段），并从中选取400个样本进行手动分类和LLM（Llama）描述生成对比。

研究结果: 手动分类显示55.5%的原始描述为示例用途；LLM正确识别79.75%的示例描述，与人工结果一致；生成的描述平均相似度为0.7173，表明相关但需改进。

研究结论: 代码片段的文档意图因任务而异，LLM在生成描述方面表现良好，但仍有提升空间。

中文摘要: 代码片段的文档化对于开发者和用户关注关键区域至关重要，例如使用示例和其他应用程序接口（API），这对第三方库尤为重要。随着大型语言模型（LLM）的兴起，主要目标是研究开发者常用的描述类型，并评估LLM（如Llama）在描述生成中的表现。我们使用NPM代码片段数据集（包含185,412个包和1,024,579个代码片段），从中选取400个代码片段（及其描述）作为样本。首先，手动分类发现大多数原始描述（55.5%）突出示例用途，强调了清晰文档的重要性，因为部分描述未能充分传达意图。其次，LLM正确识别了79.75%的原始描述为“示例”，与人工结果一致，显示了其泛化倾向。第三，与原始描述相比，生成的描述平均相似度为0.7173，表明相关性但仍有改进空间。低于0.9的分数表明存在不相关性。结果表明，根据代码片段的任务，文档意图可能不同，包括使用说明、安装指南或库用户的学习示例。

</details>
