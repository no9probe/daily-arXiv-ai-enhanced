<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 50]
- [cs.CV](#cs.CV) [Total: 93]
- [cs.AI](#cs.AI) [Total: 26]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [eess.IV](#eess.IV) [Total: 10]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.RO](#cs.RO) [Total: 3]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.CR](#cs.CR) [Total: 7]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [hep-ph](#hep-ph) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 33]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs](https://arxiv.org/abs/2507.07186)
**中文标题：预训练播种，微调摇摆：LLMs认知偏差起源的案例研究**

*Itay Itzhak,Yonatan Belinkov,Gabriel Stanovsky*

主要分类: cs.CL

摘要简述: 研究发现，大型语言模型（LLMs）的认知偏差主要源于预训练阶段，而非微调或随机训练噪声。通过交叉调优实验，揭示了预训练对偏差模式的决定性影响。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型表现出类似人类的认知偏差，但偏差来源尚不明确。研究旨在区分预训练、微调和随机噪声对偏差的影响，以指导未来偏差评估和缓解策略。

研究方法: 采用两步因果实验方法：1）多次微调模型以分析训练随机性对30多种认知偏差的影响；2）引入交叉调优，通过交换指令数据集隔离偏差来源。

研究结果: 训练随机性虽引入一定变异性，但偏差模式主要由预训练决定。相同预训练模型的偏差模式更相似，而非仅共享微调数据的模型。

研究结论: 理解微调模型的偏差需考虑其预训练起源，而非仅关注微调效果。这一视角可为未来评估和缓解LLMs偏差的策略提供指导。

中文摘要: 大型语言模型（LLMs）表现出认知偏差——类似于人类的系统性非理性决策倾向。先前研究发现，这些偏差因模型而异，且可能因指令调优而放大。然而，尚不清楚这些差异是源于预训练、微调，还是训练随机性导致的噪声。我们提出了一种两步因果实验方法以区分这些因素。首先，我们使用不同随机种子多次微调模型，研究训练随机性对30多种认知偏差的影响。其次，我们引入交叉调优——在模型间交换指令数据集以隔离偏差来源。这种交换使用导致不同偏差模式的数据集，直接测试偏差是否依赖于数据集。研究结果表明，尽管训练随机性引入了一些变异性，但偏差主要由预训练决定：具有相同预训练主干的模型比仅共享微调数据的模型表现出更相似的偏差模式。这些发现表明，理解微调模型的偏差需考虑其预训练起源，而非仅关注微调效果。这一视角可为未来评估和缓解LLMs偏差的策略提供指导。

</details>


### [2] [Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses](https://arxiv.org/abs/2507.07188)
**中文标题：提示扰动揭示LLM在调查响应中的人类类似偏差**

*Jens Rupprecht,Georg Ahnert,Markus Strohmaier*

主要分类: cs.CL

摘要简述: 本文研究发现，大型语言模型（LLMs）在模拟社会科学调查时表现出与人类相似的响应偏差，尤其是对最近呈现的选项有显著偏好。通过11种问题扰动测试，揭示了LLMs对语义变化和组合扰动的敏感性，强调了提示设计和鲁棒性测试的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）越来越多地被用作社会科学调查中的人类替代者，但其可靠性和对已知响应偏差的易感性尚不明确。本文旨在探究LLMs在规范性调查中的响应鲁棒性，揭示其是否与人类的调查响应偏差一致。

研究方法: 研究测试了9种不同的LLMs，使用世界价值观调查（WVS）的问题，并应用了11种问题表述和答案选项结构的扰动，生成了超过167,000次模拟访谈。通过分析模型对扰动的响应，评估其鲁棒性和偏差。

研究结果: 所有测试的模型均表现出不同程度的“最近偏差”，即倾向于选择最后呈现的答案选项。较大的模型通常更鲁棒，但所有模型对语义变化（如改写）和组合扰动仍敏感。LLMs的响应偏差部分与人类已知的偏差一致。

研究结论: 研究表明，LLMs在模拟调查响应时存在与人类相似的偏差，提示设计和鲁棒性测试对生成合成调查数据至关重要。未来的研究需进一步优化模型以减少偏差。

中文摘要: 大型语言模型（LLMs）越来越多地被用作社会科学调查中的人类替代者，但其可靠性和对已知响应偏差的易感性尚不明确。本文研究了LLMs在规范性调查中的响应鲁棒性，测试了9种不同的LLMs，使用世界价值观调查（WVS）的问题，并应用了11种问题表述和答案选项结构的扰动，生成了超过167,000次模拟访谈。研究发现，所有测试的模型均表现出不同程度的“最近偏差”，即倾向于选择最后呈现的答案选项。较大的模型通常更鲁棒，但所有模型对语义变化（如改写）和组合扰动仍敏感。通过扰动测试，揭示了LLMs部分与人类已知的响应偏差一致。这强调了在使用LLMs生成合成调查数据时，提示设计和鲁棒性测试的至关重要性。

</details>


### [3] [SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains](https://arxiv.org/abs/2507.07229)
**中文标题：SynthTextEval：面向高风险领域的合成文本数据生成与评估**

*Krithika Ramesh,Daniel Smolyak,Zihao Zhao,Nupoor Gandhi,Ritu Agarwal,Margrét Bjarnadóttir,Anjalie Field*

主要分类: cs.CL

摘要简述: SynthTextEval是一个用于全面评估合成文本的工具包，支持多维度评估（如实用性、公平性、隐私风险等），适用于高风险领域（如医疗和法律），旨在提升合成文本的可行性和隐私保护。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型生成的合成文本在隐私保护方面具有潜力，但需要多维度评估以确保其在高风险领域的可行性和安全性。

研究方法: SynthTextEval提供工具包，支持用户上传或生成合成文本，并从实用性、公平性、隐私风险、分布差异和专家反馈等多维度进行评估。

研究结果: 该工具包在医疗和法律领域的数据集上展示了其功能和有效性，通过标准化评估指标提升了合成文本的可行性和隐私保护。

研究结论: SynthTextEval通过多维度评估和标准化指标，为合成文本在高风险领域的应用提供了支持，促进了隐私保护的AI发展。

中文摘要: 我们提出了SynthTextEval，一个用于全面评估合成文本的工具包。大型语言模型（LLM）输出的流畅性使得合成文本在众多应用中具有潜力，例如在AI系统的开发和部署中降低隐私泄露的风险。然而，实现这一潜力需要对合成数据进行多维度的一致评估，包括其在下游系统中的实用性、系统的公平性、隐私泄露风险、与源文本的分布差异以及领域专家的定性反馈。SynthTextEval允许用户对上传或通过工具包生成模块生成的合成数据进行这些维度的评估。尽管我们的工具包可以用于任何数据，但我们重点展示了其在医疗和法律两个高风险领域数据集上的功能和有效性。通过整合和标准化评估指标，我们旨在提升合成文本的可行性，从而促进AI开发中的隐私保护。

</details>


### [4] [Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings](https://arxiv.org/abs/2507.07248)
**中文标题：医疗语言模型的红队测试协议：医疗场景中用户视角的重要性**

*Minseon Kim,Jean-Philippe Corbeil,Alessandro Sordoni,Francois Beaulieu,Paul Vozila*

主要分类: cs.CL

摘要简述: 本文提出了一种针对医疗领域语言模型的安全评估协议，重点关注患者和临床医生的视角，填补了现有安全评估的空白，并首次通过红队测试从三个不同角度（患者、临床医生和普通用户）定义了医疗语言模型的安全标准。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在医疗领域的广泛应用，其安全性问题日益凸显。现有评估多集中于通用安全基准，而忽略了医疗领域用户（如患者和临床医生）的多样性及其对健康的影响。本文旨在填补这一空白，提出针对医疗领域的安全评估协议。

研究方法: 本文设计了一种医疗红队测试协议，结合患者和临床医生的视角，并开发了包含466个样本的PatientSafetyBench，覆盖5个关键安全类别。以MediPhi模型为例，通过红队测试从患者、临床医生和普通用户三个角度评估模型安全性。

研究结果: 研究结果表明，医疗语言模型在患者和临床医生视角下的安全性存在显著差异，现有通用评估无法全面反映医疗领域的安全需求。PatientSafetyBench为医疗模型的安全性提供了量化分析工具。

研究结论: 本文首次从多角度定义了医疗语言模型的安全评估标准，为医疗领域的安全部署奠定了基础。未来的研究可进一步扩展评估范围和样本多样性。

中文摘要: 随着大型语言模型（LLMs）性能的不断提升，其在医疗领域的应用日益广泛。然而，LLMs在医疗应用中的集成引发了重大安全问题，尤其是由于用户角色（如患者和临床医生）的多样性以及模型输出对人类健康的潜在影响。尽管医疗LLMs具备领域特定能力，但现有的安全评估主要集中于通用安全基准。本文提出了一种针对医疗领域的安全评估协议，结合患者和临床医生的视角，并进行了定量分析。我们通过构建包含466个样本的PatientSafetyBench（覆盖5个关键类别），从患者角度衡量安全性。以MediPhi模型为例，应用红队测试协议。据我们所知，这是首次通过红队测试从患者、临床医生和普通用户三个角度定义医疗LLMs的安全评估标准，为医疗领域的安全部署奠定了基础。

</details>


### [5] [The Impact of Background Speech on Interruption Detection in Collaborative Groups](https://arxiv.org/abs/2507.07280)
**中文标题：背景语音对协作小组中打断检测的影响**

*Mariah Bradford,Nikhil Krishnaswamy,Nathaniel Blanchard*

主要分类: cs.CL

摘要简述: 本文研究了背景语音对协作小组中打断检测的影响，提出了一种适用于多组对话环境的打断识别方法，并揭示了打断在协作互动中的语言和韵律特征。


<details>
  <summary>详细信息</summary>
研究动机: 打断在协作学习中至关重要，但现有研究多基于单一对话环境，而实际课堂中存在多组对话和重叠语音，需要开发更鲁棒的打断检测方法。

研究方法: 分析了单对话和多组对话环境中的打断检测，提出了一种先进的方法，能够有效应对重叠语音，适用于课堂环境。

研究结果: 开发了一种鲁棒的打断识别方法，并揭示了打断在协作互动中的语言和韵律特征，为未来研究多组对话中的打断影响奠定了基础。

研究结论: 本研究为课堂环境中的打断检测提供了实用方法，并强调了多组对话环境下打断检测的重要性，为未来研究指明了方向。

中文摘要: 打断在协作学习中扮演关键角色，塑造小组互动并影响知识构建。AI驱动的支持可以帮助教师监控这些互动。然而，以往关于打断检测和解释的研究多在单一对话环境中进行，音频相对干净。在课堂中部署AI代理以支持小组协作学习时，需要应对多组并发的对话——在这种情况下，重叠语音将无处不在，打断需要通过其他方式识别。本研究分析了单对话和多组对话环境中的打断检测，并提出了一种先进的方法，能够有效应对重叠语音，适用于课堂部署。此外，我们的工作揭示了打断在协作小组互动中表现出的有意义的语言和韵律信息。本研究还为未来研究如何考虑多组对话中重叠语音对小组对话跟踪的影响奠定了基础。

</details>


### [6] [Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation](https://arxiv.org/abs/2507.07307)
**中文标题：基于多智能体检索增强框架的反健康虚假信息证据言论生成**

*Anirban Saha Anik,Xiaoying Song,Elliott Wang,Bryan Wang,Bengisu Yarimbas,Lingzi Hong*

主要分类: cs.CL

摘要简述: 本文提出了一种多智能体检索增强框架，用于生成基于证据的反健康虚假信息言论，通过结合静态和动态证据，优化了知识检索、证据增强和响应细化，显著提升了反虚假信息言论的质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于检索增强生成（RAG）的大语言模型（LLMs）在生成反虚假信息言论时存在证据有限且对输出控制不足的问题。本文旨在通过多智能体框架解决这些问题，生成更相关、可靠且及时的反虚假信息言论。

研究方法: 本文提出了一种多智能体检索增强框架，结合多个LLMs优化知识检索、证据增强和响应细化。框架整合了静态和动态证据，确保生成的反虚假信息言论既相关又具有时效性。

研究结果: 实验表明，该方法在礼貌性、相关性、信息量和事实准确性上优于基线方法。消融研究验证了框架中各组件的必要性，人类评估进一步证实细化过程显著提升了反虚假信息言论的质量。

研究结论: 本文提出的多智能体检索增强框架有效提升了反健康虚假信息言论的质量，为未来相关研究提供了有价值的参考。

中文摘要: 结合检索增强生成（RAG）的大语言模型（LLMs）在生成反虚假信息言论方面表现出强大能力。然而，当前研究依赖有限的证据且对最终输出的控制较少。为解决这些问题，我们提出了一种多智能体检索增强框架，用于生成反健康虚假信息言论，通过结合多个LLMs优化知识检索、证据增强和响应细化。我们的方法整合了静态和动态证据，确保生成的反虚假信息言论相关、可靠且及时。实验表明，该方法在礼貌性、相关性、信息量和事实准确性上优于基线方法。为进一步验证，我们进行了消融研究以确认框架中各组件的必要性。此外，人类评估表明细化过程显著提升了反虚假信息言论的质量并获得了人类偏好。

</details>


### [7] [GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation](https://arxiv.org/abs/2507.07414)
**中文标题：GNN-CNN：一种用于文本表示的高效卷积与图神经网络混合模型**

*Fardin Rastakhiz*

主要分类: cs.CL

摘要简述: 本文提出了一种结合图神经网络（GNN）和卷积神经网络（CNN）的高效混合模型GNN-CNN，用于文本表示。该模型通过实时端到端图生成机制处理字符级输入，无需填充或截断，并结合大语言模型（LLM）信息提升性能。实验证明其在文本分类任务中高效且具有竞争力。


<details>
  <summary>详细信息</summary>
研究动机: 当前最先进的Transformer模型在处理长文本时因计算复杂度高而效率低下。本研究旨在设计一种高效且计算成本低的模型，以解决长文本处理中的时间和能耗问题。

研究方法: 模型结合GNN和CNN，通过端到端图生成机制处理字符级输入，避免填充或截断。利用LLM的嵌入和情感极性信息，通过字典查找提升性能。CNN捕捉局部上下文模式，基于格结构的图扩展局部感受野，并使用小世界图聚合文档级信息。

研究结果: 生成的图具有语义组织的结构特性，平均聚类系数约为0.45，平均最短路径长度在4到5之间。在情感分析和新闻分类等任务中，模型表现出高效且与最先进模型竞争的性能。

研究结论: GNN-CNN模型在文本表示任务中表现出高效性和竞争力，尤其适合处理长文本，为深度学习中的时间和能耗问题提供了可行的解决方案。

中文摘要: 在深度学习中，时间、成本和能效是关键考量，尤其是在处理长文本时。当前最先进的Transformer模型因输入长度的二次计算复杂度而效率低下。本研究提出了一种新颖的模型架构，结合图神经网络（GNN）和卷积神经网络（CNN），并集成实时端到端图生成机制。该模型处理紧凑的字符级输入批次，无需填充或截断。为在保持高速和高效的同时提升性能，模型通过高效字典查找结合大语言模型（LLM）的信息，如词嵌入和情感极性。模型利用CNN捕捉局部上下文模式，通过基于格的图结构扩展局部感受野，并使用小世界图聚合文档级信息。生成的图具有语义组织的结构特性，平均聚类系数约为0.45，平均最短路径长度在4到5之间。模型在多个文本分类任务（如情感分析和新闻分类）中进行了评估，并与最先进模型进行了比较。实验结果证实了所提模型的高效性和竞争力。

</details>


### [8] [MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning](https://arxiv.org/abs/2507.07419)
**中文标题：MedReadCtrl：通过可读性控制的指令学习个性化医疗文本生成**

*Hieu Tran,Zonghai Yao,Won Seok Jang,Sharmin Sultana,Allen Chang,Yuan Zhang,Hong Yu*

主要分类: cs.CL

摘要简述: MedReadCtrl是一种可读性控制的指令调优框架，使大型语言模型能够在不损失意义的情况下调整输出复杂度，显著提升医疗文本生成的个性化与可读性。


<details>
  <summary>详细信息</summary>
研究动机: 在医疗领域，生成式AI的部署面临关键挑战：内容需兼具个性化和易理解性。现有模型在调整文本复杂度时易丢失医学意图，因此需要一种方法在保持医学准确性的同时适应不同阅读水平。

研究方法: 提出MedReadCtrl框架，通过可读性控制的指令调优，使模型能够根据指令动态调整输出文本的复杂度。在九个数据集和三个任务上进行评估，涵盖医疗和通用领域。

研究结果: MedReadCtrl在可读性指令遵循错误率上显著优于GPT-4（如ReadMe任务中1.39 vs. 1.59），并在未见临床任务中表现优异（如ROUGE-L提升14.7，SARI提升6.18）。专家更倾向于选择MedReadCtrl（71.7% vs. 23.3%），尤其在低阅读水平场景下。

研究结论: MedReadCtrl能够在不牺牲医学意图的前提下，将临床内容转化为易理解的语言，为患者教育和公平获取AI支持的医疗服务提供了可扩展的解决方案。

中文摘要: 生成式AI在医疗领域展现出巨大潜力，从临床决策支持到改善患者结果的聊天机器人。部署的关键挑战在于有效的人机交互，内容需兼具个性化和易理解性。我们提出MedReadCtrl，一种可读性控制的指令调优框架，使大型语言模型能够在不损失意义的情况下调整输出复杂度。在九个数据集和三个任务上的评估表明，MedReadCtrl在可读性指令遵循错误率上显著优于GPT-4（如ReadMe任务中1.39 vs. 1.59，p<0.001），并在未见临床任务中表现优异（如MTSamples任务中ROUGE-L提升14.7，SARI提升6.18）。专家更倾向于选择MedReadCtrl（71.7% vs. 23.3%），尤其在低阅读水平场景下。这些成果反映了MedReadCtrl将临床内容转化为易理解语言的能力，同时保留医学意图，为患者教育和公平获取AI支持的医疗服务提供了可扩展的解决方案。

</details>


### [9] [SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data](https://arxiv.org/abs/2507.07421)
**中文标题：SynthEHR-Eviction：利用LLM增强的合成EHR数据改进驱逐SDoH检测**

*Zonghai Yao,Youxia Zhao,Avijit Mitra,David A. Levy,Emily Druhl,Jack Tsai,Hong Yu*

主要分类: cs.CL

摘要简述: SynthEHR-Eviction提出了一种结合LLM、人工标注和自动提示优化的流程，用于从临床记录中提取驱逐状态，显著提升了检测性能并降低了标注成本。


<details>
  <summary>详细信息</summary>
研究动机: 驱逐是健康社会决定因素（SDoH）中重要但研究不足的问题，与住房不稳定、失业和心理健康相关。然而，电子健康记录（EHR）中驱逐信息多为非结构化数据，限制了其应用。

研究方法: 研究提出SynthEHR-Eviction流程，结合大型语言模型（LLM）、人工标注和自动提示优化（APO），从临床记录中提取驱逐状态，并构建了包含14类细粒度标签的最大公开驱逐相关SDoH数据集。

研究结果: 基于SynthEHR-Eviction微调的LLM（如Qwen2.5、LLaMA3）在驱逐和其他SDoH检测上的Macro-F1分数分别为88.8%和90.3%，优于GPT-4o-APO、GPT-4o-mini-APO和BioBERT，同时显著降低了标注成本。

研究结论: SynthEHR-Eviction流程不仅高效提升了驱逐检测性能，还能推广至其他信息提取任务，为SDoH研究提供了可扩展的解决方案。

中文摘要: 驱逐是健康社会决定因素（SDoH）中重要但研究不足的问题，与住房不稳定、失业和心理健康相关。尽管电子健康记录（EHR）中存在驱逐信息，但其多为非结构化数据，限制了后续应用。我们提出了SynthEHR-Eviction，一种可扩展的流程，结合大型语言模型（LLM）、人工标注和自动提示优化（APO），从临床记录中提取驱逐状态。通过该流程，我们构建了迄今为止最大的公开驱逐相关SDoH数据集，包含14类细粒度标签。基于SynthEHR-Eviction微调的LLM（如Qwen2.5、LLaMA3）在人工验证数据上的Macro-F1分数分别为88.8%（驱逐）和90.3%（其他SDoH），优于GPT-4o-APO（87.8%、87.3%）、GPT-4o-mini-APO（69.1%、78.1%）和BioBERT（60.7%、68.3%），同时实现了跨模型规模的高效部署。该流程将标注工作量减少80%以上，加速了数据集创建，支持可扩展的驱逐检测，并可推广至其他信息提取任务。

</details>


### [10] [Towards Interpretable Time Series Foundation Models](https://arxiv.org/abs/2507.07439)
**中文标题：迈向可解释的时间序列基础模型**

*Matthieu Boileau,Philippe Helluy,Jeremy Pawlus,Svitlana Vyetrenko*

主要分类: cs.CL

摘要简述: 本文研究了将时间序列推理能力蒸馏到小型指令调优语言模型中，以构建可解释的时间序列基础模型。通过合成数据集和自然语言注释，训练紧凑的Qwen模型，并评估其解释能力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发小型、可解释的时间序列基础模型，使其能够以自然语言解释时间序列模式，适用于设备端或隐私敏感场景。

研究方法: 利用合成均值回归时间序列数据集，通过大型多模态模型生成自然语言注释，用于监督紧凑Qwen模型的微调，并引入评估指标衡量推理质量。

研究结果: 实验表明，后训练模型获得了有意义的解释能力，能够准确识别趋势方向、噪声强度和极值定位，验证了方法的可行性。

研究结论: 本研究为开发小型、可解释的时间序列模型提供了基础，展示了将时间序列理解压缩到轻量级语言模型中的潜力。

中文摘要: 本文研究了将时间序列推理能力蒸馏到小型指令调优语言模型中，作为构建可解释时间序列基础模型的一步。通过使用具有系统变化趋势和噪声水平的合成均值回归时间序列数据集，我们利用大型多模态模型生成自然语言注释，并用这些注释监督紧凑Qwen模型的微调。我们引入了评估指标，评估蒸馏推理的质量——重点关注趋势方向、噪声强度和极值定位——并表明后训练模型获得了有意义的解释能力。我们的结果突出了将时间序列理解压缩到适合设备端或隐私敏感部署的轻量级语言模型中的可行性。这项工作为开发能够以自然语言解释时间模式的小型可解释模型提供了具体基础。

</details>


### [11] [SAND: Boosting LLM Agents with Self-Taught Action Deliberation](https://arxiv.org/abs/2507.07441)
**中文标题：SAND：通过自我教导的行动审议提升LLM代理**

*Yu Xia,Yiran Jenny Shen,Junda Wu,Tong Yu,Sungchul Kim,Ryan A. Rossi,Lina Yao,Julian McAuley*

主要分类: cs.CL

摘要简述: 本文提出SAND框架，通过自我教导的行动审议提升LLM代理性能，避免因有限探索而选择次优行动。实验显示SAND平均提升20%性能，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有LLM代理常通过模仿专家行为或优化偏好轨迹进行调优，但缺乏对候选行动的深入比较，易陷入看似合理但次优的行动选择。SAND旨在通过行动审议解决这一问题。

研究方法: SAND框架结合自我一致性行动采样和执行引导的行动评价，让LLM代理在行动前明确审议候选行动，并通过迭代调优利用审议轨迹改进代理。

研究结果: 在两个代表性交互任务中，SAND平均比初始监督调优提升20%性能，并优于当前最先进的代理调优方法。

研究结论: SAND通过行动审议显著提升LLM代理性能，验证了其在避免次优行动选择方面的有效性。

中文摘要: 大型语言模型（LLM）代理通常通过监督微调或偏好优化进行调优，但这些方法可能因缺乏对候选行动的深入比较而导致代理选择看似合理但次优的行动。为此，本文提出自我教导的行动审议（SAND）框架，使LLM代理在行动前明确审议候选行动。为解决大规模行动空间和步骤级行动评价的挑战，我们结合自我一致性行动采样和执行引导的行动评价，利用基础模型合成步骤级审议思路。通过迭代方式，审议轨迹用于微调LLM代理本身。在两个代表性交互任务中，SAND平均比初始监督微调提升20%性能，并优于当前最先进的代理调优方法。

</details>


### [12] [RLEP: Reinforcement Learning with Experience Replay for LLM Reasoning](https://arxiv.org/abs/2507.07451)
**中文标题：RLEP：基于经验回放的强化学习用于大语言模型推理**

*Hongzhi Zhang,Jia Fu,Jingyuan Zhang,Kai Fu,Qi Wang,Fuzheng Zhang,Guorui Zhou*

主要分类: cs.CL

摘要简述: RLEP是一种结合经验回放的强化学习框架，通过重放高质量轨迹优化大语言模型的推理能力，显著提升训练效率和最终性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习在大语言模型训练中能耗高且不稳定，策略容易偏离预训练权重。RLEP旨在通过经验回放解决这些问题，提升训练效率和模型性能。

研究方法: RLEP分为两阶段：首先收集已验证的轨迹，然后在训练过程中重放这些成功轨迹。每次更新时，策略在混合新生成轨迹和回放轨迹的小批量数据上进行优化。

研究结果: 在Qwen2.5-Math-7B模型上，RLEP以更少的更新次数达到基线峰值准确率，并最终超越基线，在AIME-2024、AIME-2025和AMC-2023任务中分别提升1.7%、2.5%和5.2%的准确率。

研究结论: RLEP通过经验回放有效提升大语言模型的推理能力，实现更快收敛和更强性能，为相关研究提供了可复现的工具和数据支持。

中文摘要: 大语言模型的强化学习（RL）训练能耗高且不稳定，策略可能逐渐偏离预训练权重。本文提出RLEP（基于经验回放的强化学习），一种两阶段框架：首先收集已验证的轨迹，随后在训练过程中重放这些轨迹。每次更新时，策略在混合新生成轨迹和回放成功轨迹的小批量数据上进行优化。通过重放高质量示例，RLEP避免无效探索，专注于有潜力的推理路径，实现更快收敛和更强性能。在Qwen2.5-Math-7B模型上，RLEP以更少更新次数达到基线峰值准确率并最终超越，将AIME-2024准确率从38.2%提升至39.9%，AIME-2025从19.8%提升至22.3%，AMC-2023从77.0%提升至82.2%。代码、数据集和检查点已公开，以促进复现和进一步研究。

</details>


### [13] [Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models](https://arxiv.org/abs/2507.07484)
**中文标题：机器胡扯：大语言模型中忽视真相的涌现特征**

*Kaiqu Liang,Haimin Hu,Xuandong Zhao,Dawn Song,Thomas L. Griffiths,Jaime Fernández Fisac*

主要分类: cs.CL

摘要简述: 本文提出“机器胡扯”作为大语言模型（LLM）中忽视真相的总体框架，并引入“胡扯指数”量化其表现。通过实验发现，强化学习微调会加剧胡扯行为，而思维链提示会放大特定胡扯形式。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探讨大语言模型（LLM）中忽视真相的普遍现象，并提出“机器胡扯”作为统一框架，以揭示其机制和影响。

研究方法: 方法包括引入“胡扯指数”量化模型对真相的漠视，并提出四种胡扯形式的分类法。实验基于Marketplace、Political Neutrality数据集及新设计的BullshitEval基准（2400个场景）。

研究结果: 结果显示，强化学习微调显著加剧胡扯行为，思维链提示则放大特定胡扯形式（如空话和含糊其辞）。政治语境中，含糊其辞是主要策略。

研究结论: 结论指出，AI对齐存在系统性挑战，需进一步研究以实现更真实的LLM行为。

中文摘要: 胡扯（Bullshit）是哲学家哈里·法兰克福提出的概念，指不顾真相的陈述。尽管已有研究探讨了大语言模型（LLM）的幻觉和谄媚行为，本文提出“机器胡扯”作为统一框架，用于描述LLM中忽视真相的广泛现象并揭示其机制。我们引入“胡扯指数”量化LLM对真相的漠视，并提出四种胡扯形式的分类法：空话、含糊其辞、模棱两可和未经证实的断言。基于Marketplace数据集、Political Neutrality数据集及新设计的BullshitEval基准（2400个场景覆盖100个AI助手），我们进行了实证评估。结果表明，通过人类反馈强化学习（RLHF）的模型微调会显著加剧胡扯行为，而推理时的思维链（CoT）提示会放大特定胡扯形式（如空话和含糊其辞）。政治语境中，模棱两可是主要策略。这些发现凸显了AI对齐的系统性挑战，并为实现更真实的LLM行为提供了新见解。

</details>


### [14] [PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving](https://arxiv.org/abs/2507.07495)
**中文标题：PLAN-TUNING：通过后训练语言模型学习复杂问题解决的逐步规划**

*Mihir Parmar,Palash Goyal,Xin Liu,Yiwen Song,Mingyang Ling,Chitta Baral,Hamid Palangi,Tomas Pfister*

主要分类: cs.CL

摘要简述: PLAN-TUNING是一种后训练框架，通过从大型语言模型提取任务分解（规划轨迹）并微调小型模型，提升复杂推理能力，在多个基准测试中表现优于基线。


<details>
  <summary>详细信息</summary>
研究动机: 当前，利用任务分解提升大型语言模型性能已取得显著效果，但如何在小型开源模型中应用这一方法仍待探索。PLAN-TUNING旨在填补这一空白。

研究方法: PLAN-TUNING框架包括两步：(1) 从大型语言模型提取合成任务分解（规划轨迹）；(2) 通过监督和强化学习目标微调小型模型，模仿规划过程以提升复杂推理能力。

研究结果: 在GSM8k和MATH基准测试中，PLAN-TUNING模型平均性能提升约7%。在域外数据集（如OlympiadBench和AIME 2024）上，性能分别提升约10%和12%。

研究结论: PLAN-TUNING通过规划轨迹显著提升小型语言模型的复杂推理能力，是一种有效的后训练策略。

中文摘要: 近年来，将复杂问题分解为简单子任务（人类自然规划的关键部分）显著提升了大型语言模型（LLMs）的性能。然而，在后训练阶段利用这种规划结构提升小型开源LLMs的性能仍待探索。为此，我们提出PLAN-TUNING，一种统一的后训练框架：(i) 从大规模LLMs中提取合成任务分解（称为“规划轨迹”）；(ii) 通过监督和强化学习目标微调小型模型，以模仿这些规划过程，从而提升复杂推理能力。在GSM8k和MATH基准测试中，PLAN-TUNING模型的平均性能优于基线约7%。此外，PLAN-TUNING模型在域外数据集（如OlympiadBench和AIME 2024）上表现出更好的泛化能力，平均性能分别提升约10%和12%。详细分析表明，规划轨迹显著提升了复杂推理能力，证明PLAN-TUNING是提升小型LLMs任务性能的有效策略。

</details>


### [15] [Teaching LLM to Reason: Reinforcement Learning from Algorithmic Problems without Code](https://arxiv.org/abs/2507.07498)
**中文标题：教授大语言模型推理：基于算法问题的无代码强化学习**

*Keqin Bao,Nuo Chen,Xiaoyuan Li,Binyuan Hui,Bowen Yu,Fuli Feng,Junyang Lin,Xiangnan He,Dayiheng Liu*

主要分类: cs.CL

摘要简述: 论文提出TeaR方法，通过数据筛选和强化学习提升大语言模型的推理能力，避免过度依赖复杂算法，实验证明在多领域基准测试中性能显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在推理任务中过度依赖复杂代码结构和算法，导致对核心推理能力的忽视。论文旨在通过优化数据和方法，提升模型的通用推理能力。

研究方法: TeaR方法结合数据筛选和强化学习，指导模型在代码相关任务中发现最优推理路径，避免对复杂算法的依赖。实验涵盖多种模型和17个基准测试。

研究结果: 实验结果显示，TeaR在多个模型和基准测试中表现优异，Qwen2.5-7B性能提升35.9%，R1-Distilled-7B提升5.9%。

研究结论: TeaR通过优化数据和方法，显著提升了大语言模型的推理能力，为未来研究提供了新方向。

中文摘要: 提升推理能力是大语言模型研究的核心目标。当前方法通常要求模型通过逐步模拟代码执行来推导输出，但代码设计常针对大规模系统，直接应用会导致对复杂数据结构和算法的过度依赖，甚至简单任务也受此影响，从而过度拟合算法模式而非核心推理结构。为此，我们提出TeaR方法，旨在通过精心筛选的数据和强化学习，引导模型在代码相关任务中发现最优推理路径，从而提升通用推理能力。我们使用两种基础模型和三种长链蒸馏模型（参数规模从15亿到320亿不等），在涵盖数学、知识、代码和逻辑推理的17个基准测试中进行了广泛实验。结果显示性能显著提升，其中Qwen2.5-7B提升35.9%，R1-Distilled-7B提升5.9%。

</details>


### [16] [Extracting ORR Catalyst Information for Fuel Cell from Scientific Literature](https://arxiv.org/abs/2507.07499)
**中文标题：从科学文献中提取燃料电池氧还原反应催化剂信息**

*Hein Htet,Amgad Ahmed Ali Ibrahim,Yutaka Sasaki,Ryoji Asahi*

主要分类: cs.CL

摘要简述: 本文提出了一种基于DyGIE++和多种预训练BERT变体（如MatSciBERT和PubMedBERT）的命名实体识别（NER）和关系抽取（RE）方法，用于从科学文献中提取氧还原反应（ORR）催化剂信息，构建了燃料电池材料信息学语料库（FC-CoMIcs）。实验表明，PubMedBERT在NER任务中表现最佳（F1-score 82.19%），MatSciBERT在RE任务中表现最优（F1-score 66.10%），领域专用BERT模型优于通用科学模型。


<details>
  <summary>详细信息</summary>
研究动机: 氧还原反应（ORR）催化剂对提升燃料电池效率至关重要，但从海量科学文献中提取结构化信息仍面临挑战。本文旨在通过自动化方法解决这一问题，为材料信息学研究提供支持。

研究方法: 研究采用DyGIE++框架，结合多种预训练BERT变体（如MatSciBERT和PubMedBERT），进行命名实体识别（NER）和关系抽取（RE）。通过人工标注构建包含12个关键实体和两种关系的数据集，并对模型进行微调以提升性能。

研究结果: 实验结果显示，微调后的PubMedBERT在NER任务中F1-score达82.19%，MatSciBERT在RE任务中F1-score为66.10%。领域专用BERT模型表现优于通用科学模型（如BlueBERT），且与人工标注结果对比验证了模型的可靠性。

研究结论: 研究表明，领域专用BERT模型在ORR催化剂信息提取中具有显著优势，能够支持大规模自动化文献分析，为燃料电池研究提供高效工具。

中文摘要: 氧还原反应（ORR）催化剂对提升燃料电池效率至关重要，是材料科学研究的重点。然而，由于文本数据的复杂性和多样性，从海量科学文献中提取ORR催化剂的结构化信息仍是一项重大挑战。本研究提出了一种基于DyGIE++框架的命名实体识别（NER）和关系抽取（RE）方法，结合多种预训练BERT变体（如MatSciBERT和PubMedBERT），从科学文献中提取ORR催化剂相关信息，并构建了燃料电池材料信息学语料库（FC-CoMIcs）。通过人工标注，我们构建了一个包含12个关键实体和两种关系的数据集。研究方法包括数据标注、整合及基于Transformer模型的微调，以提高信息提取的准确性。我们评估了不同BERT变体对提取性能的影响，并研究了标注一致性的作用。实验结果表明，微调后的PubMedBERT模型在NER任务中F1-score最高（82.19%），MatSciBERT模型在RE任务中表现最佳（F1-score 66.10%）。与人工标注结果的对比进一步验证了微调模型在ORR催化剂提取中的可靠性，展示了其在规模化自动化文献分析中的潜力。结果表明，领域专用BERT模型在ORR催化剂提取任务中优于通用科学模型（如BlueBERT）。

</details>


### [17] [Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models](https://arxiv.org/abs/2507.07505)
**中文标题：幻觉站：论基于Transformer的语言模型的一些基本局限性**

*Varin Sikka,Vishal Sikka*

主要分类: cs.CL

摘要简述: 本文探讨了基于Transformer的语言模型（LLMs）在计算复杂性和代理任务中的局限性，指出其无法完成超过一定复杂度的任务或验证其准确性，并讨论了相关后果。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于Transformer的语言模型在AI中的广泛应用，人们对其能力边界（如幻觉现象）和代理任务的实际应用产生了浓厚兴趣。本文旨在揭示LLMs在计算和代理任务中的固有局限性。

研究方法: 作者从LLM推理的计算复杂性角度出发，通过理论分析和实例展示，证明了LLMs在完成和验证高复杂度任务时的无能。

研究结果: 研究结果表明，LLMs无法完成或验证超过一定复杂度的计算和代理任务，且存在显著的幻觉现象。

研究结论: 本文揭示了LLMs在复杂任务中的根本局限性，强调了在实际应用中需谨慎使用，并提出了进一步研究的必要性。

中文摘要: 随着基于Transformer的语言模型在AI中的广泛应用，人们对LLMs能力的边界（尤其是所谓的幻觉现象，即LLMs在某些主题上提供虚假、事实错误或无意义的信息）产生了浓厚兴趣。此外，LLMs的代理用途（即利用LLMs创建自主或半自主代理以执行各种任务，包括现实世界中的应用任务）也日益受到关注。因此，理解LLMs能够和无法完成的任务类型变得尤为重要。本文从LLM推理的计算复杂性角度探讨了这一主题。我们证明，LLMs无法执行超过一定复杂度的计算和代理任务，且无法验证超过一定复杂度的任务的准确性。我们展示了这两方面的实例，并讨论了本研究的某些后果。

</details>


### [18] [Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System](https://arxiv.org/abs/2507.07509)
**中文标题：面向真实世界中文心理支持对话：CPsDD数据集与协同进化的多代理系统**

*Yuanchen Shi,Longyin Zhang,Fang Kong*

主要分类: cs.CL

摘要简述: 为解决心理支持领域数据稀缺问题，研究提出一种框架，通过微调两个大型语言模型生成和优化心理辅导对话，构建了包含68K对话的中文心理支持数据集CPsDD，并开发了多代理系统CADSS，在策略预测和情感支持任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 由于心理压力增加，心理支持需求上升，但相关数据集稀缺，尤其是在非英语语言中。研究旨在填补这一空白，提供高质量的中文心理支持对话数据。

研究方法: 研究提出一个框架，利用有限真实数据和专家知识微调两个语言模型：对话生成器和对话修饰器。生成器基于预设路径生成大规模心理辅导对话，修饰器优化对话以匹配真实数据质量。通过自动和人工审核构建CPsDD数据集，并开发多代理系统CADSS，包括分析用户特征的剖析器、总结对话历史的摘要器、选择策略的规划器和生成共情回应的支持者。

研究结果: 构建了包含68K对话的CPsDD数据集，涵盖13个群体、16种心理问题、13种原因和12种支持焦点。CADSS在策略预测和情感支持对话任务中表现优异，优于现有方法。

研究结论: 研究成功填补了中文心理支持对话数据的空白，提出的CADSS系统在多个任务中表现卓越，为心理支持领域提供了实用工具。

中文摘要: 由于压力增加导致心理支持需求上升，但相关数据集稀缺，尤其是在非英语语言中。为此，我们提出一个框架，利用有限的真实数据和专家知识微调两个大型语言模型：对话生成器和对话修饰器。生成器基于预设路径生成大规模心理辅导对话，修饰器优化对话以匹配真实数据质量。通过自动和人工审核，我们构建了中文心理支持对话数据集（CPsDD），包含68K对话，涵盖13个群体、16种心理问题、13种原因和12种支持焦点。此外，我们引入了综合代理对话支持系统（CADSS），其中剖析器分析用户特征，摘要器总结对话历史，规划器选择策略，支持者生成共情回应。策略预测和情感支持对话任务的实验结果表明，CADSS在CPsDD和ESConv数据集上均达到最优性能。

</details>


### [19] [Triadic Multi-party Voice Activity Projection for Turn-taking in Spoken Dialogue Systems](https://arxiv.org/abs/2507.07518)
**中文标题：三方多人语音活动预测在语音对话系统轮流发言中的应用**

*Mikey Elmers,Koji Inoue,Divesh Lala,Tatsuya Kawahara*

主要分类: cs.CL

摘要简述: 本研究首次将语音活动预测（VAP）应用于三方对话场景，通过训练模型预测说话者的未来语音活动，结果显示三方对话训练的VAP模型优于基线模型，但对话类型影响准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的语音活动预测研究多集中于双人对话，而三方对话场景的语音活动预测尚未被探索。本研究旨在填补这一空白，探索VAP在三方对话中的适用性。

研究方法: 研究使用日本的三方对话数据集，训练多个VAP模型，仅基于声学数据预测说话者的未来语音活动。

研究结果: 研究发现，基于三方对话训练的VAP模型在所有模型中表现优于基线，但对话类型对预测准确性有显著影响。

研究结论: 研究表明VAP可用于三方对话的轮流发言预测，未来将把该模型整合到语音对话系统中。

中文摘要: 轮流发言是语音对话的基本组成部分，但传统研究多集中于双人场景。本研究将语音活动预测（VAP）应用于三方多人场景，预测未来的轮流发言。VAP模型的目标是仅利用声学数据预测每位说话者的未来语音活动。这是首次将VAP扩展到三方对话的研究。我们在一个日本三方对话数据集上训练了多个模型，参与者讨论了多种话题。研究发现，基于三方对话训练的VAP模型在所有模型中表现优于基线，但对话类型影响了准确性。本研究证实VAP可用于三方对话的轮流发言预测，未来工作将把该模型整合到语音对话系统中。

</details>


### [20] [CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text](https://arxiv.org/abs/2507.07539)
**中文标题：CEA-LIST在CheckThat! 2025：评估大语言模型作为文本偏见和观点检测工具**

*Akram Elbouanani,Evan Dufraisse,Aboubacar Tuo,Adrian Popescu*

主要分类: cs.CL

摘要简述: 本文提出了一种基于大语言模型（LLMs）的多语言主观性检测方法，通过少样本提示在CheckThat! 2025评测中表现优异，尤其在噪声或低质量数据环境下优于传统小模型。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索大语言模型在少样本提示下的表现，特别是在多语言主观性检测任务中，以替代传统需要大量标注数据的微调方法。

研究方法: 采用少样本提示策略，结合精心设计的提示模板，并尝试了辩论式提示和多样本选择策略，但发现标准少样本提示效果最佳。

研究结果: 在CheckThat! 2025评测中，系统在阿拉伯语和波兰语任务中排名第一，并在意大利语、英语、德语及多语言任务中进入前四，尤其在阿拉伯语数据上表现稳健。

研究结论: 大语言模型结合少样本提示在多语言情感任务中表现高效且适应性强，为标注数据稀缺或不一致时提供了有力替代方案。

中文摘要: 本文提出了一种基于大语言模型（LLMs）的少样本提示方法，用于多语言主观性检测任务。我们参与了CheckThat! 2025评测中的任务1：主观性检测。研究表明，结合精心设计的提示模板，大语言模型能够匹配甚至超越传统微调的小模型，尤其在噪声或低质量数据环境下。尽管尝试了辩论式提示和多样本选择等高级提示工程技术，但标准少样本提示仍表现最佳。我们的系统在CheckThat! 2025评测中表现优异，包括阿拉伯语和波兰语任务的第一名，以及意大利语、英语、德语和多语言任务的前四名。值得注意的是，该方法在阿拉伯语数据上尤为稳健，可能得益于其对标注不一致的鲁棒性。这些发现凸显了大语言模型少样本学习在多语言情感任务中的高效性和适应性，为标注数据稀缺或不一致时提供了有力替代方案。

</details>


### [21] [The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora](https://arxiv.org/abs/2507.07543)
**中文标题：跨语言代价：阿拉伯语-英语语料库中RAG的检索偏差**

*Chen Amiraz,Yaroslav Fyodorov,Elad Haramaty,Zohar Karnin,Liane Lewin-Eytan*

主要分类: cs.CL

摘要简述: 研究揭示了跨语言检索增强生成（RAG）在阿拉伯语-英语语料库中的检索偏差问题，提出了一种改进策略以提升跨语言检索性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有跨语言RAG研究多关注生成任务，且依赖开放域数据（如维基百科），忽略了检索中的语言不平衡问题。本研究旨在填补这一空白，探讨领域特定场景下的跨语言检索挑战。

研究方法: 使用真实企业数据集构建阿拉伯语-英语跨语言基准，涵盖查询与支持文档的所有语言组合，并随机独立抽取数据，系统研究多语言检索行为。提出一种简单策略，强制从两种语言中均衡检索文档。

研究结果: 研究发现跨语言检索是领域特定场景的主要瓶颈，当查询与文档语言不同时性能显著下降。提出的均衡检索策略显著提升了跨语言和整体性能。

研究结论: 跨语言检索在多语言RAG应用中存在显著挑战，但通过改进检索策略可有效提升性能，为实际应用提供了优化方向。

中文摘要: 跨语言检索增强生成（RAG）是实现跨语言检索与生成答案的关键能力。以往研究多集中于生成任务，并依赖开放域数据（如维基百科）的基准测试，而检索挑战常因语言不平衡、预训练数据重叠及记忆内容被掩盖。为填补这一空白，本研究利用真实企业数据集构建阿拉伯语-英语RAG的领域特定基准，涵盖查询与支持文档的所有语言组合，并随机独立抽取数据，以系统研究多语言检索行为。

研究发现，在领域特定场景中，检索是跨语言任务的主要瓶颈，当查询与文档语言不同时性能显著下降。关键发现是，这些失败主要源于检索器在跨语言文档排序中的困难。最后，我们提出一种简单策略，通过强制从两种语言中均衡检索文档，显著提升了跨语言及整体性能。这些结果凸显了改进多语言检索的重要机会，尤其在实际RAG应用中。

</details>


### [22] [The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs](https://arxiv.org/abs/2507.07562)
**中文标题：长链思维监督微调与强化学习的协同困境：探究视觉语言模型推理的后训练技术**

*Jierun Chen,Tiezheng Yu,Haoli Bai,Lewei Yao,Jiannan Wu,Kaican Li,Fei Mi,Chaofan Tao,Lei Zhu,Manyi Zhang,Xiaohui Li,Lu Hou,Lifeng Shang,Qun Liu*

主要分类: cs.CL

摘要简述: 本文研究了长链思维监督微调（SFT）和强化学习（RL）在视觉语言模型（VLM）中的协同作用，发现两者结合未能带来叠加效果，反而导致性能权衡。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型（VLM）常采用长链思维监督微调（SFT）和强化学习（RL）等后训练技术以提升复杂推理能力。然而，这些方法在语言模型中的协同效果是否适用于VLM尚不明确，因此本文旨在探究这一问题。

研究方法: 通过多模态推理基准测试，系统分析了长链思维SFT和RL的独立作用及其交互效果，并尝试了多种结合策略（如两阶段训练、交替训练、渐进训练、数据混合和模型融合）。

研究结果: SFT在复杂问题上表现优异但导致冗长且简单问题性能下降；RL提升泛化能力和简洁性，但对最难题目的改进不如SFT显著。所有结合策略均未能实现叠加效果，反而引发准确性、推理风格和响应长度的权衡。

研究结论: 长链思维SFT和RL在VLM中的结合存在“协同困境”，需开发更无缝和自适应的后训练方法以充分发挥其潜力。

中文摘要: 大型视觉语言模型（VLM）越来越多地采用后训练技术，如长链思维监督微调（SFT）和强化学习（RL），以激发复杂推理能力。尽管这些方法在纯语言模型中表现出协同作用，但其在VLM中的联合效果尚不明确。本文通过多模态推理基准测试，系统研究了长链思维SFT和RL的独立作用及其交互效果。研究发现，SFT通过深入结构化推理提升了复杂问题的性能，但导致冗长且简单问题性能下降；而RL则提升了泛化能力和简洁性，在所有难度级别上均带来一致改进，但对最难题目的改进不如SFT显著。令人意外的是，通过两阶段、交替或渐进训练策略，以及数据混合和模型融合等方式结合两者，均未能产生叠加效益，反而导致准确性、推理风格和响应长度的权衡。这一“协同困境”凸显了需要更无缝和自适应的后训练方法，以充分发挥组合技术在VLM推理中的潜力。

</details>


### [23] [Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation](https://arxiv.org/abs/2507.07572)
**中文标题：基于多模态大语言模型的单模态到多模态对齐方法在文档图像机器翻译中的应用**

*Yupu Liang,Yaping Zhang,Zhiyang Zhang,Yang Zhao,Lu Xiang,Chengqing Zong,Yu Zhou*

主要分类: cs.CL

摘要简述: 本文提出M4Doc框架，通过单模态到多模态对齐方法，利用多模态大语言模型提升文档图像机器翻译的性能，显著改善跨领域泛化和复杂场景下的翻译质量。


<details>
  <summary>详细信息</summary>
研究动机: 文档图像机器翻译（DIMT）面临训练数据有限及视觉与文本信息复杂交互的挑战，导致泛化能力不足。本文旨在通过多模态大语言模型（MLLMs）解决这些问题。

研究方法: M4Doc框架将仅图像编码器与预训练的多模态大语言模型对齐，使轻量级DIMT模型能够学习关键的视觉-文本关联。推理阶段绕过MLLM，保持计算效率。

研究结果: 实验表明，M4Doc显著提升了翻译质量，尤其在跨领域泛化和复杂文档图像场景中表现突出。

研究结论: M4Doc通过单模态到多模态对齐，有效提升了DIMT的性能，同时保持了计算效率，为文档图像翻译提供了新思路。

中文摘要: 文档图像机器翻译（DIMT）旨在翻译文档图像中的文本，但由于训练数据有限以及视觉与文本信息的复杂交互，其泛化能力面临挑战。为解决这些问题，我们提出了M4Doc，一种新颖的单模态到多模态对齐框架，利用多模态大语言模型（MLLMs）。M4Doc将仅图像编码器与在大规模文档图像数据集上预训练的MLLM的多模态表示对齐，使轻量级DIMT模型能够在训练中学习关键的视觉-文本关联。在推理阶段，M4Doc绕过MLLM，保持计算效率的同时受益于其多模态知识。综合实验表明，M4Doc显著提升了翻译质量，尤其在跨领域泛化和复杂文档图像场景中表现优异。

</details>


### [24] [Bayesian Discrete Diffusion Beats Autoregressive Perplexity](https://arxiv.org/abs/2507.07586)
**中文标题：贝叶斯离散扩散模型超越自回归困惑度**

*Cooper Doyle*

主要分类: cs.CL

摘要简述: 本文揭示了离散扩散语言模型的贝叶斯核心，证明在正向掩码分布下，期望去噪器输出能准确恢复干净标记的后验分布。通过蒙特卡洛边缘化，K次独立损坏的收敛速度为O(1/√K)，并提出一种轻量级推理集成方法，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前自回归语言模型在困惑度上表现有限，离散扩散模型虽具潜力但缺乏理论支持。本文旨在揭示其贝叶斯核心，提供理论证明和高效推理方法。

研究方法: 通过理论分析证明离散扩散模型的贝叶斯性质，提出基于蒙特卡洛边缘化的轻量级推理集成方法，平均K次掩码-去噪过程以获取后验感知标记概率。

研究结果: 在WikiText-2数据集上，K=8时测试困惑度为8.8，显著优于GPT-2 Small的20.3，且模型规模相当。

研究结论: 离散扩散模型具有隐藏的贝叶斯核心，通过理论分析和轻量级推理集成可显著提升性能，为语言模型提供新的优化方向。

中文摘要: 我们揭示了离散扩散语言模型的隐藏贝叶斯核心，证明在正向掩码分布下，期望去噪器输出能准确恢复干净标记的后验分布。在最小假设下，K次独立损坏的蒙特卡洛边缘化以O(1/√K)的速率收敛到此后验，提供了简单的一致性证明和有限样本误差界。基于此，我们提出一种轻量级推理集成方法，通过平均K次掩码-去噪过程获取后验感知标记概率和不确定性估计，无需额外训练成本。在WikiText-2上，K=8时测试困惑度为8.8，而GPT-2 Small为20.3，尽管模型规模相当。代码见https://github.com/mercury0100/bayesradd。

</details>


### [25] [Exploring the Limits of Model Compression in LLMs: A Knowledge Distillation Study on QA Tasks](https://arxiv.org/abs/2507.07630)
**中文标题：探索大型语言模型压缩的极限：基于问答任务的知识蒸馏研究**

*Joyeeta Datta,Niclas Doll,Qusai Ramadan,Zeyd Boukhers*

主要分类: cs.CL

摘要简述: 研究通过知识蒸馏压缩大型语言模型（LLMs）在问答任务中的性能极限，发现学生模型参数减少57.1%仍能保留90%以上性能，且单样本提示优于零样本。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在NLP任务中表现优异，但计算资源需求高，限制了其在资源受限环境中的部署。本研究旨在探索知识蒸馏（KD）能否有效压缩LLMs，同时保持问答任务的高性能。

研究方法: 使用Pythia和Qwen2.5系列模型作为教师模型，通过知识蒸馏训练学生模型，并在SQuAD和MLQA两个问答基准上评估零样本和单样本提示条件下的性能。

研究结果: 学生模型参数减少高达57.1%，但仍保留了教师模型90%以上的性能。单样本提示进一步提升了性能，优于零样本设置。

研究结论: 知识蒸馏结合少量提示可生成高效且性能优异的问答系统，适用于资源受限场景，揭示了模型效率与任务性能之间的权衡。

中文摘要: 大型语言模型（LLMs）在多种NLP任务中表现出色，但其计算需求限制了其在资源受限环境中的实际部署。本研究探讨了通过知识蒸馏（KD）压缩LLMs的极限，同时确保其在问答（QA）任务中的高性能。我们评估了从Pythia和Qwen2.5系列模型蒸馏出的学生模型在SQuAD和MLQA两个问答基准上的表现，分别在零样本和单样本提示条件下进行测试。结果表明，学生模型在参数减少高达57.1%的情况下，仍能保留教师模型90%以上的性能。此外，单样本提示相比零样本设置进一步提升了性能。这些发现强调了模型效率与任务性能之间的权衡，表明知识蒸馏结合少量提示可以生成适用于资源受限应用的紧凑且高效的问答系统。

</details>


### [26] [FrugalRAG: Learning to retrieve and reason for multi-hop QA](https://arxiv.org/abs/2507.07634)
**中文标题：FrugalRAG：面向多跳问答的检索与推理学习方法**

*Abhinav Java,Srivathsan Koundinyan,Nagarajan Natarajan,Amit Sharma*

主要分类: cs.CL

摘要简述: 本文提出FrugalRAG方法，通过改进提示和少量训练数据，显著减少检索次数，同时保持高性能，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有检索增强生成（RAG）方法多关注准确率和召回率，而忽略了检索效率的重要性。本文旨在通过改进提示和少量训练数据，提升RAG的效率和性能。

研究方法: 提出FrugalRAG方法，结合改进的ReAct流程和少量监督或强化学习微调，显著减少检索次数。实验基于HotPotQA等基准数据集。

研究结果: 在HotPotQA等基准测试中，FrugalRAG以近半的检索次数实现竞争性性能，且训练成本低（仅需1000个示例）。

研究结论: FrugalRAG证明大规模微调并非必要，改进提示和少量训练即可提升RAG效率和性能，为多跳问答提供高效解决方案。

中文摘要: 本文研究如何通过大型非结构化文档库回答复杂问题。现有方法主要依赖语言模型迭代检索和推理，改进方向集中于检索增强生成（RAG）的准确率和召回率，包括两类：（a）基于链式思维的大规模问答数据集微调，（b）基于问题-文档相关信号的强化学习微调。然而，检索次数的效率同样重要却较少被关注。本文发现：（1）改进提示的标准ReAct流程无需大规模微调即可在HotPotQA等基准上超越现有方法；（2）监督和强化学习微调可从“节俭性”（即推理时的检索延迟）角度提升RAG。例如，相同基础模型下，仅需1000个示例训练，即可以近半检索次数实现竞争性性能。

</details>


### [27] [Lost in Pronunciation: Detecting Chinese Offensive Language Disguised by Phonetic Cloaking Replacement](https://arxiv.org/abs/2507.07640)
**中文标题：迷失于发音：检测通过语音伪装替换隐藏的中文攻击性语言**

*Haotan Guo,Jianfei He,Jiayuan Ma,Hongbin Na,Zimu Wang,Haiyang Zhang,Qi Chen,Wei Wang,Zijing Shi,Tao Shen,Ling Chen*

主要分类: cs.CL

摘要简述: 本文研究了中文中通过同音或近音替换隐藏攻击性意图的语音伪装替换（PCR）现象，构建了首个自然发生的PCR数据集，并揭示了现有检测模型的局限性，提出了一种基于拼音的轻量级缓解方法。


<details>
  <summary>详细信息</summary>
研究动机: 中文内容审核中，语音伪装替换（PCR）已成为隐藏攻击性意图的主要手段，但现有研究多依赖规则生成的合成数据，忽略了真实用户的创造性。本文旨在填补这一空白，提供更真实的PCR数据集和检测方法。

研究方法: 1. 将PCR分为四类表面形式；2. 从RedNote平台收集500个自然发生的PCR攻击性帖子，构建数据集；3. 测试现有大型语言模型（LLM）的表现；4. 通过错误分析改进基于拼音的提示策略。

研究结果: 现有最佳模型的F1分数仅为0.672，零样本思维链提示甚至表现更差。改进后的拼音提示策略显著提升了检测准确率。

研究结论: 本文首次系统分类了中文PCR，揭示了当前检测器的不足，并提出了一种轻量级缓解技术，为鲁棒毒性检测研究提供了新方向。

中文摘要: 语音伪装替换（PCR）是指故意使用同音或近音变体隐藏攻击性意图的行为，已成为中文内容审核的主要障碍。尽管这一问题已被广泛认识，但现有评估主要依赖规则生成的合成扰动，忽略了真实用户的创造性。本文将PCR分为四类表面形式，并构建了“我们的”数据集，包含从RedNote平台收集的500个自然发生的PCR攻击性帖子。对当前最先进的大型语言模型（LLM）进行基准测试，发现其表现严重不足：最佳模型的F1分数仅为0.672，零样本思维链提示甚至进一步降低了性能。通过错误分析，我们重新审视了早期研究认为无效的基于拼音的提示策略，并证明其能显著恢复丢失的准确率。本研究首次提出了中文PCR的全面分类，揭示了当前检测器的局限性，并提出了一种轻量级缓解技术，推动了鲁棒毒性检测的研究。

</details>


### [28] [An Automated Length-Aware Quality Metric for Summarization](https://arxiv.org/abs/2507.07653)
**中文标题：一种自动化的长度感知摘要质量度量**

*Andrew D. Foland*

主要分类: cs.CL

摘要简述: 本文提出了一种名为NOIR的自动化长度感知质量指标，用于评估任意文本的摘要质量，结合语义保留和摘要长度压缩，有效衡量摘要中召回与压缩的权衡。


<details>
  <summary>详细信息</summary>
研究动机: 现有摘要质量评估方法通常依赖耗时的人工参考摘要，缺乏自动化工具来衡量语义保留与长度压缩的平衡。本文旨在提出一种自动化指标，解决这一问题。

研究方法: NOIR通过语言模型嵌入测量语义相似性，结合摘要长度压缩率，量化摘要质量。实验验证了其在捕捉语义保留与长度权衡方面的有效性。

研究结果: 实验表明，NOIR能有效反映摘要器的语义保留与长度压缩的权衡，并与人类对摘要质量的感知高度相关。

研究结论: NOIR为摘要质量评估提供了一种自动化工具，适用于多种摘要任务，无需依赖人工参考摘要。

中文摘要: 本文提出了NOIR（归一化保留指数），一种用于评估任意文本摘要质量的定量客观指标，该指标依赖于语义意义的保留和摘要长度的压缩。它衡量了召回与压缩的权衡，这是摘要中最重要的技能。实验表明，NOIR能有效捕捉摘要器的标记长度/语义保留权衡，并与人类对摘要质量的感知相关。通过使用语言模型嵌入测量语义相似性，NOIR提供了一种无需依赖耗时的人工参考摘要的自动化替代方案。该指标可应用于多种摘要任务，为评估和改进摘要算法、摘要提示及合成生成的摘要提供了自动化工具。

</details>


### [29] [SAS: Simulated Attention Score](https://arxiv.org/abs/2507.07694)
**中文标题：SAS：模拟注意力分数**

*Chuanyang Zheng,Jiankai Sun,Yihang Gao,Yuehao Wang,Peihao Wang,Jing Xiong,Liliang Ren,Hao Cheng,Janardhan Kulkarni,Yelong Shen,Atlas Wang,Mac Schwager,Anderson Schneider,Xiaodong Liu,Jianfeng Gao*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SAS（模拟注意力分数）的方法，通过将低维注意力头表示投影到高维空间，模拟更多注意力头和更大的隐藏特征维度，从而在不增加参数量的情况下提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究发现，多头注意力（MHA）的性能随着注意力头数量的增加而提升，前提是每个头的隐藏维度足够大。因此，如何在保持模型紧凑的同时模拟更多头和更大的隐藏维度成为研究动机。

研究方法: SAS方法通过将低维注意力头表示投影到高维空间，模拟更多注意力头和更大的隐藏特征维度。此外，还提出了参数高效注意力聚合（PEAA）以控制参数成本。

研究结果: 在多个数据集和任务上的实验表明，SAS方法显著优于其他注意力变体，实现了性能的显著提升。

研究结论: SAS方法通过模拟更多注意力头和更大的隐藏维度，在不增加参数量的情况下显著提升了模型性能，为注意力机制的优化提供了新思路。

中文摘要: 注意力机制是Transformer架构的核心组成部分。目前已有多种计算注意力分数的方法，如多头注意力（MHA）、多查询注意力、组查询注意力等。我们进一步分析了MHA，发现其性能随着注意力头数量的增加而提升，前提是每个头的隐藏维度足够大。因此，在保持参数开销最小的情况下增加头数和每个头的隐藏维度，可以以低成本实现显著的性能提升。基于这一观察，我们提出了模拟注意力分数（SAS），该方法通过将低维注意力头表示投影到高维空间，模拟更多注意力头和更大的隐藏特征维度，从而在不增加参数量的情况下提升注意力容量。此外，我们还将模拟方法扩展到键和查询嵌入的特征维度，通过模仿更大模型的行为增强表达能力，同时保持原始模型大小。为了控制参数成本，我们还提出了参数高效注意力聚合（PEAA）。在多种数据集和任务上的综合实验证明了SAS方法的有效性，其性能显著优于其他注意力变体。

</details>


### [30] [KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities](https://arxiv.org/abs/2507.07695)
**中文标题：KeyKnowledgeRAG（K²RAG）：一种改进的RAG方法以增强LLM问答能力**

*Hruday Markondapatnaikuni,Basem Suleiman,Abdelkarim Erradi,Shijing Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种名为KeyKnowledgeRAG（K²RAG）的新型框架，通过结合密集和稀疏向量搜索、知识图谱及文本摘要技术，显著提升了检索增强生成（RAG）系统的效率和准确性。实验表明，K²RAG在答案相似度和训练时间上均有显著改进。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）规模和复杂性的增加，传统的微调方法在扩展知识库时面临高昂的计算和时间成本。检索增强生成（RAG）虽然提供了替代方案，但其简单实现存在可扩展性和答案准确性的限制。本文旨在解决这些问题。

研究方法: K²RAG框架结合了密集和稀疏向量搜索、知识图谱和文本摘要技术，通过预处理步骤对训练数据进行摘要，显著减少训练时间。实验基于MultiHopRAG数据集进行验证。

研究结果: K²RAG在MultiHopRAG数据集上表现优异，平均答案相似度得分达0.57，第三四分位数（Q3）相似度为0.82。此外，摘要步骤使组件平均训练时间减少93%，执行速度比传统基于知识图谱的RAG系统快40%，且VRAM需求仅为简单RAG实现的三分之一。

研究结论: K²RAG通过创新的技术组合显著提升了RAG系统的性能和效率，为LLMs的知识扩展提供了一种高效且可扩展的解决方案。

中文摘要: 在将大型语言模型（LLMs）重新训练以纳入更多知识时，微调是一个资源密集型过程。尽管已有许多微调技术旨在减少时间和计算成本，但随着LLMs规模和复杂性的增加，这一挑战仍然存在。为此，需要一种新的知识扩展方法。检索增强生成（RAG）通过将外部知识存储在数据库中并检索相关片段以支持问答，提供了一种替代方案。然而，简单的RAG实现存在可扩展性和答案准确性的显著限制。本文提出了KeyKnowledgeRAG（K²RAG），一种旨在克服这些限制的新型框架。受分治范式启发，K²RAG结合了密集和稀疏向量搜索、知识图谱及文本摘要技术，以提高检索质量和系统效率。该框架还包括一个预处理步骤，对训练数据进行摘要，显著减少训练时间。K²RAG在MultiHopRAG数据集上进行了评估，结果表明其优于常见的简单RAG实现。K²RAG的平均答案相似度得分最高为0.57，第三四分位数（Q3）相似度达0.82，表明其与真实答案更吻合。除了准确性提升外，该框架还表现出高效性。摘要步骤使各组件平均训练时间减少93%，执行速度比传统基于知识图谱的RAG系统快40%。K²RAG还展现出卓越的可扩展性，其VRAM需求仅为测试中几种简单RAG实现的三分之一。

</details>


### [31] [Rethinking the Privacy of Text Embeddings: A Reproducibility Study of "Text Embeddings Reveal (Almost) As Much As Text"](https://arxiv.org/abs/2507.07700)
**中文标题：重新思考文本嵌入的隐私性：对《文本嵌入揭示（几乎）与文本相同信息》的可复现性研究**

*Dominykas Seputis,Yongkang Li,Karsten Langerak,Serghei Mihailov*

主要分类: cs.CL

摘要简述: 本文通过复现Vec2Text框架，验证了文本嵌入可能泄露原始文本的隐私风险，并探讨了量化等轻量级防御措施的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 传统认为传输文本嵌入而非原始文本具有隐私保护性，但Vec2Text方法挑战了这一假设，展示了从嵌入中重建原始文本的可能性。本文旨在验证这一方法的有效性，并探索其局限性及可能的防御措施。

研究方法: 复现Vec2Text框架，验证其原始结果，并通过参数敏感性分析、敏感输入重建实验和嵌入量化防御研究扩展了研究范围。

研究结果: 在理想条件下，Vec2Text能有效重建原始文本，甚至包括无明确语义的密码类序列，但其对输入序列长度敏感。高斯噪声和量化技术可减轻隐私风险，量化更为简单且适用性广。

研究结论: 文本嵌入的使用需谨慎，未来需进一步研究NLP系统的鲁棒防御机制。量化是一种有效的轻量级防御手段。

中文摘要: 文本嵌入是许多自然语言处理（NLP）任务的基础，广泛应用于推荐系统和信息检索（IR）等领域。传统上，传输嵌入而非原始文本被视为隐私保护行为。然而，Vec2Text等最新方法通过展示可控解码可从黑盒嵌入中成功重建原始文本，挑战了这一假设。Vec2Text报告的出人意料的结果促使我们进一步验证，尤其是考虑到高维嵌入空间通常非直观且不透明的结构。本文复现了Vec2Text框架，并从两个角度评估：（1）验证原始结论，（2）通过针对性实验扩展研究。首先，我们在领域内和领域外环境中成功复现了原始关键结果，仅因缺失模型检查点和数据集划分等工件而存在微小差异。此外，我们通过参数敏感性分析、评估敏感输入（如密码）重建的可行性，以及探索嵌入量化作为一种轻量级隐私防御手段扩展了研究。结果表明，Vec2Text在理想条件下有效，甚至能重建缺乏明确语义的密码类序列。然而，我们也发现其关键局限性，包括对输入序列长度的敏感性。高斯噪声和量化技术可减轻Vec2Text带来的隐私风险，量化提供了一种更简单且广泛适用的解决方案。研究结果强调使用文本嵌入需谨慎，并凸显了进一步研究NLP系统鲁棒防御机制的重要性。

</details>


### [32] [Not All Preferences are What You Need for Post-Training: Selective Alignment Strategy for Preference Optimization](https://arxiv.org/abs/2507.07725)
**中文标题：并非所有偏好都适合后训练：选择性对齐策略用于偏好优化**

*Zhijin Dong*

主要分类: cs.CL

摘要简述: 本文提出了一种选择性对齐策略（Selective-DPO），通过优先处理高影响力标记来优化大型语言模型的后训练对齐，减少计算开销并提升对齐效果。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的后训练对齐中，并非所有标记对模型性能贡献均等，因此需要一种更高效的方法来优化对齐过程。

研究方法: 提出选择性对齐策略，利用当前策略与参考模型之间的标记级对数概率差异，优先优化高影响力标记，并探讨参考模型质量对标记选择的影响。

研究结果: 在Arena-Hard和MT-Bench等基准测试中，Selective-DPO方法优于标准DPO和基于蒸馏的基线方法，验证了其优越性。

研究结论: 标记级优化和参考模型选择对提升LLMs的对齐效果至关重要，Selective-DPO方法为后训练对齐提供了高效解决方案。

中文摘要: 大型语言模型（LLMs）的后训练对齐是一个关键挑战，因为并非所有标记对模型性能的贡献均等。本文提出了一种选择性对齐策略，通过优先处理偏好对中的高影响力标记，利用当前策略与参考模型之间的标记级对数概率差异。通过聚焦这些信息丰富的标记，我们的方法减少了计算开销并提升了对齐的准确性。我们还探讨了参考模型质量的作用，表明更强的参考模型显著提高了标记选择的准确性和整体优化效果。在Arena-Hard和MT-Bench等基准测试上的全面实验验证了我们的Selective-DPO方法优于标准DPO和基于蒸馏的基线方法。我们的发现强调了标记级优化和参考模型选择在推进LLMs偏好对齐中的重要性。代码可在https://github.com/Dongzhijin/SDPO获取。

</details>


### [33] [Code-Switching in End-to-End Automatic Speech Recognition: A Systematic Literature Review](https://arxiv.org/abs/2507.07741)
**中文标题：端到端自动语音识别中的语码转换：系统性文献综述**

*Maha Tufail Agro,Atharva Kulkarni,Karima Kadaoui,Zeerak Talat,Hanan Aldarmaki*

主要分类: cs.CL

摘要简述: 本文对端到端自动语音识别（ASR）中的语码转换（CS）研究进行了系统性文献综述，总结了当前研究中的语言、数据集、模型选择及性能，并探讨了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着自动语音识别（ASR）研究的兴起，以及语码转换（CS）在多语言场景中的广泛应用，本文旨在系统性梳理端到端ASR模型中语码转换的研究现状，为未来研究提供参考。

研究方法: 通过收集并手动标注同行评审论文，分析了涉及的语言、数据集、评估指标、模型选择及性能表现，并讨论了端到端ASR中语码转换的挑战。

研究结果: 研究总结了当前语码转换在端到端ASR中的研究进展和可用资源，同时指出了未来研究的机遇与不足。

研究结论: 本文为语码转换在端到端ASR领域的研究提供了全面综述，揭示了当前研究的局限性，并提出了未来发展的方向。

中文摘要: 随着自动语音识别（ASR）研究的日益深入，以及语码转换（CS）在多语言场景中的广泛应用，本文对端到端ASR模型中的语码转换研究进行了系统性文献综述。我们收集并手动标注了同行评审论文，记录了涉及的语言、数据集、评估指标、模型选择及性能表现，并探讨了端到端ASR中语码转换的挑战。通过分析，本文为当前研究提供了资源与进展的概述，同时指出了未来研究的机遇与不足。

</details>


### [34] [When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance](https://arxiv.org/abs/2507.07748)
**中文标题：当大型语言模型遇见法律：双视角分类法、技术进展与伦理治理**

*Peizhang Shao,Linrui Xu,Jinxi Wang,Wei Zhou,Xingyu Wu*

主要分类: cs.CL

摘要简述: 本文首次全面综述了大型语言模型（LLMs）在法律领域的应用，提出了一种创新的双视角分类法，整合法律推理框架和专业本体，系统统一了历史研究与当代突破。尽管LLMs在任务泛化、推理形式化等方面取得进展，但仍面临幻觉、可解释性不足等挑战。


<details>
  <summary>详细信息</summary>
研究动机: 法律领域对大型语言模型的应用缺乏系统性综述，且传统方法难以动态捕捉法律语义和统一证据推理。本文旨在填补这一空白，为法律人工智能的未来发展提供技术路线图和概念框架。

研究方法: 提出双视角分类法，结合法律推理框架和专业本体，系统分析LLMs在法律领域的应用。通过稀疏注意力机制和专家混合架构等技术创新，解决文本处理、知识整合等核心挑战。

研究结果: LLMs在法律任务中展现出上下文推理和生成论证等能力，但在幻觉、可解释性等方面仍存在显著问题。研究还提出了法律角色与NLP子任务的映射分类法，并计算化实现了Toulmin论证框架。

研究结论: 本文为法律人工智能的未来研究提供了技术路线图和概念框架，同时指出了低资源系统、多模态证据整合等关键前沿方向。

中文摘要: 本文首次全面综述了大型语言模型（LLMs）在法律领域的应用，提出了一种创新的双视角分类法，整合法律推理框架和专业本体，系统统一了历史研究与当代突破。基于Transformer的LLMs通过动态捕捉法律语义和统一证据推理，克服了传统限制，展现出上下文推理和生成论证等能力。在任务泛化、推理形式化、工作流整合等方面取得显著进展，并通过稀疏注意力机制和专家混合架构等技术创新解决了文本处理、知识整合和评估严谨性等核心挑战。然而，LLMs的广泛应用也带来了幻觉、可解释性不足、司法适应性困难和伦理不对称等关键挑战。本文提出了一种新颖的分类法，将法律角色映射到NLP子任务，并计算化实现了Toulmin论证框架，从而系统化了推理、检索、预测和争议解决方面的进展。研究还指出了低资源系统、多模态证据整合和动态反驳处理等关键前沿方向。最终，本文为研究人员提供了技术路线图，并为从业者提供了导航算法未来的概念框架，为下一阶段的法律人工智能奠定了坚实基础。我们创建了一个GitHub仓库以索引相关论文：https://github.com/Kilimajaro/LLMs_Meet_Law。

</details>


### [35] [StreamUni: Achieving Streaming Speech Translation with a Unified Large Speech-Language Model](https://arxiv.org/abs/2507.07803)
**中文标题：StreamUni：通过统一的大型语音-语言模型实现流式语音翻译**

*Shoutao Guo,Xiang Li,Shaolei Zhang,Mengge Liu,Wei Chen,Yang Feng*

主要分类: cs.CL

摘要简述: 本文提出StreamUni，通过统一的大型语音-语言模型（LSLM）实现流式语音翻译，结合语音思维链（CoT）完成分段、策略决策和翻译生成，无需大量策略训练，实验表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有流式语音翻译方法依赖句子级分段（SimulST），需与分段模型协作，导致策略决策受限且翻译质量低。同时，SimulST模型因语音输入复杂性和跨语言生成难以学习有效策略。

研究方法: StreamUni利用统一的大型语音-语言模型（LSLM），结合语音思维链（CoT）生成多阶段输出，实现语音分段、策略决策和翻译生成一体化。并提出流式CoT训练方法，提升低延迟策略决策能力。

研究结果: 实验表明，StreamUni在流式语音翻译任务中达到最先进性能。

研究结论: StreamUni通过LSLM和CoT技术，解决了流式语音翻译中的分段和策略问题，实现了高效低延迟的翻译生成。

中文摘要: 流式语音翻译（StreamST）需要在持续接收源语音输入时确定合适的生成时机（策略），以平衡低延迟和高翻译质量。然而，现有StreamST方法通常基于句子级语音分段（SimulST），需依赖分段模型完成StreamST，导致截断的语音片段限制了SimulST模型的策略决策和翻译生成。此外，SimulST模型因语音输入复杂性和跨语言生成难以学习有效策略。为解决这些问题，我们提出StreamUni，通过统一的大型语音-语言模型（LSLM）实现StreamST。具体而言，StreamUni引入语音思维链（CoT）指导LSLM生成多阶段输出，从而同时完成语音分段、策略决策和翻译生成，无需大量策略训练。我们还提出流式CoT训练方法，利用有限CoT数据增强低延迟策略决策和生成能力。实验表明，StreamUni在StreamST任务中表现优异。

</details>


### [36] [Bridging Logic and Learning: Decoding Temporal Logic Embeddings via Transformers](https://arxiv.org/abs/2507.07808)
**中文标题：连接逻辑与学习：通过Transformer解码时序逻辑嵌入**

*Sara Candussio,Gaia Saveri,Gabriele Sarti,Luca Bortolussi*

主要分类: cs.CL

摘要简述: 本文提出了一种基于Transformer的解码器模型，用于反转信号时序逻辑（STL）公式的语义嵌入，从而将连续表示的逻辑公式转化为具体需求。模型在少量训练后即可生成有效公式，并能简化公式结构，同时保持语义一致性。


<details>
  <summary>详细信息</summary>
研究动机: 逻辑公式的连续表示可以将符号知识融入数据驱动的学习算法中，但需要确保嵌入是可逆的，以便将最优连续表示转化为具体需求。本文旨在解决这一问题。

研究方法: 通过构建STL语法的小词汇表，训练一个基于Transformer的解码器模型，用于反转STL公式的语义嵌入。模型在训练过程中逐步学习生成有效公式，并简化公式结构。

研究结果: 模型在1个训练周期后即可生成有效公式，约10个周期后能理解逻辑语义。生成的公式在长度和嵌套上更简单，同时语义接近或等价于参考公式。模型在需求挖掘任务中表现优异。

研究结论: 本文提出的方法能够有效反转逻辑公式的语义嵌入，生成简洁且语义一致的公式，为符号知识与数据驱动算法的结合提供了实用工具。

中文摘要: 逻辑公式的连续表示使我们能够将符号知识整合到数据驱动的学习算法中。如果这种嵌入在语义上是一致的，即相似的规范被映射到相近的向量中，它们可以直接在公式的语义空间中进行连续学习和优化。然而，为了将最优的连续表示转化为具体需求，这种嵌入必须是可逆的。我们通过训练一个基于Transformer的解码器模型来解决这一问题，用于反转信号时序逻辑（STL）公式的语义嵌入。STL是一种强大的形式化方法，能够以简洁而表达力强的方式描述随时间变化的信号属性。通过从STL语法构建一个小词汇表，我们证明了所提出的模型仅需1个训练周期即可生成有效公式，并在约10个周期后理解逻辑语义。此外，模型能够将给定嵌入解码为长度和嵌套更简单的公式，同时保持语义接近（或等价）于参考公式。我们通过不同复杂度的训练公式评估了方法的有效性，以分析训练数据对模型捕捉嵌入语义信息及泛化能力的影响。最后，我们将模型应用于需求挖掘任务，即在语义空间中直接优化，推断出解决轨迹分类任务的STL规范。

</details>


### [37] [Understanding and Controlling Repetition Neurons and Induction Heads in In-Context Learning](https://arxiv.org/abs/2507.07810)
**中文标题：理解与控制上下文学习中的重复神经元与归纳头**

*Nhi Hoai Doan,Tatsuya Hiraoka,Kentaro Inui*

主要分类: cs.CL

摘要简述: 本文研究大型语言模型（LLMs）识别重复输入模式的能力与其上下文学习（ICL）性能的关系，重点关注重复神经元而非注意力头，发现其影响随层深变化，并提出减少重复输出同时保持ICL性能的策略。


<details>
  <summary>详细信息</summary>
研究动机: 先前研究主要关注注意力头，而本文从技能神经元（特别是重复神经元）的角度探讨其对ICL性能的影响，旨在更全面地理解模型行为并优化输出。

研究方法: 通过实验分析重复神经元在不同层深对ICL性能的影响，并与归纳头进行比较，提出减少重复输出的策略。

研究结果: 实验表明，重复神经元对ICL性能的影响因层深而异；通过比较重复神经元和归纳头，找到了减少重复输出同时保持ICL能力的方法。

研究结论: 重复神经元在ICL中扮演重要角色，其影响与层深相关；通过优化策略，可减少重复输出而不损害ICL性能。

中文摘要: 本文研究了大型语言模型（LLMs）识别重复输入模式的能力与其在上下文学习（ICL）中表现的关系。与先前主要关注注意力头的研究不同，我们从技能神经元（特别是重复神经元）的角度探讨这一问题。实验表明，这些神经元对ICL性能的影响随其所在层深而变化。通过比较重复神经元与归纳头的作用，我们进一步提出了减少重复输出同时保持强大ICL能力的策略。

</details>


### [38] [On the Effect of Instruction Tuning Loss on Generalization](https://arxiv.org/abs/2507.07817)
**中文标题：指令调优损失对泛化能力的影响**

*Anwoy Chatterjee,H S V N S Kowndinya Renduchintala,Sumit Bhatia,Tanmoy Chakraborty*

主要分类: cs.CL

摘要简述: 研究发现传统指令调优损失函数（仅计算响应标记）效果不佳，提出加权指令调优（WIT），通过调整提示和响应标记的权重，显著提升模型性能和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 指令调优是提升预训练语言模型遵循用户指令能力的关键方法，但其损失函数优化研究较少。传统方法仅计算响应标记的损失，可能并非最优，因此需要探索更有效的损失函数设计。

研究方法: 提出加权指令调优（WIT），系统研究提示和响应标记在损失函数中的权重影响，通过实验验证不同权重组合的效果。

研究结果: 实验表明，传统指令调优损失函数性能较差且对输入变化鲁棒性不足。WIT中适度加权提示标记和高权重响应标记的组合表现最佳，并可作为后续偏好对齐训练的更好起点。

研究结论: 研究强调需重新审视指令调优损失函数设计，WIT为开发更鲁棒和泛化性强的模型提供了实用方案。

中文摘要: 指令调优已成为一种关键的后训练范式，能够使预训练语言模型更好地遵循用户指令。尽管其重要性显著，但关于优化损失函数的研究却很少。一个基础但常被忽视的问题是：传统自回归目标（仅计算响应标记的损失，排除提示标记）是否真正适合指令调优。本文系统研究了指令调优损失中提示和响应标记的差异化权重影响，并提出加权指令调优（WIT）作为传统方法的改进方案。通过对五种不同规模和家族的语言模型、三种不同规模的微调数据集以及五个多样化评估基准的广泛实验，我们发现标准指令调优损失通常表现不佳且对输入提示变化的鲁棒性有限。结果表明，对提示标记赋予低至中等权重，同时对响应标记赋予中等至高权重，能够在各种设置下获得最佳性能模型，并成为后续偏好对齐训练的更好起点。这些发现强调了重新审视指令调优损失的必要性，并为开发更鲁棒和泛化性强的模型提供了实用见解。代码已开源：https://github.com/kowndinya-renduchintala/WIT。

</details>


### [39] [Conditional Unigram Tokenization with Parallel Data](https://arxiv.org/abs/2507.07824)
**中文标题：基于并行数据的条件一元分词方法**

*Gianluca Vico,Jindřinch Libovický*

主要分类: cs.CL

摘要简述: 本文提出了一种基于并行数据的条件一元分词方法，通过将目标语言的分词概率与源语言分词关联，优化跨语言语义对齐。实验表明，该方法在语言建模中表现优异，但在机器翻译中效果有限。


<details>
  <summary>详细信息</summary>
研究动机: 传统一元分词方法未考虑源语言与目标语言之间的关联，导致跨语言语义对齐不足。本文旨在通过引入条件概率，提升分词在跨语言任务中的表现。

研究方法: 提出条件一元分词方法，利用并行数据学习目标语言的分词概率，使其依赖于源语言分词。通过固定源语言分词器，优化目标语言分词器的跨语言对齐能力。

研究结果: 在四种语言对的实验中，该方法在语言建模中显著降低了困惑度，但在机器翻译任务中未观察到明显提升。分析表明，条件概率估计的二次方复杂度可能限制了数据效率。

研究结论: 条件一元分词在语言建模中表现良好，但在机器翻译中效果有限。未来需探索更高效的参数化方法以提升跨语言分词的实际应用价值。

中文摘要: 本文介绍了条件一元分词方法，这是一种通过将目标语言的分词概率与源语言分词相关联来扩展一元分词的新方法。在固定源语言分词器的前提下，我们的方法学习一种目标语言分词器，以最大化跨语言语义对齐。我们在四种不同语系和资源水平的语言对上评估了该方法，考察了其内在特性及在机器翻译和语言建模中的下游表现。尽管条件分词器保持了与标准一元分词器相当的统计特性，但结果参差不齐：机器翻译质量未见提升，但在语言建模中困惑度持续降低。我们假设条件概率估计的二次方复杂度（相对于词汇量）造成了数据效率瓶颈。研究结果表明，实际应用中可能需要其他参数化方法来实现跨语言分词。

</details>


### [40] [From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems](https://arxiv.org/abs/2507.07847)
**中文标题：从歧义到精确：指代消解对检索增强生成系统的变革性影响**

*Youngjoon Jang,Seongtae Hong,Junyoung Son,Sungjin Park,Chanjun Park,Heuiseok Lim*

主要分类: cs.CL

摘要简述: 本文研究了指代消解对检索增强生成（RAG）系统的影响，发现其能显著提升检索效果和问答性能，尤其对小模型帮助更大。


<details>
  <summary>详细信息</summary>
研究动机: 检索增强生成（RAG）在自然语言处理中表现优异，但检索文档中的指代复杂性会引入歧义，影响上下文学习和生成效果。本文旨在探究指代消解如何改善RAG系统的检索和生成性能。

研究方法: 通过系统分析指代消解对RAG系统的影响，研究聚焦于检索相关性、上下文理解和整体回答质量。比较了不同池化策略在检索任务中的表现，并评估了指代消解对问答任务的影响。

研究结果: 研究发现，指代消解显著提升了检索效果和问答性能，其中均值池化在指代消解后表现最佳。小模型因自身处理指代歧义能力有限，从消解过程中获益更多。

研究结论: 本研究揭示了指代复杂性对RAG系统的挑战，并提供了改进知识密集型AI应用中检索和生成性能的指导。

中文摘要: 检索增强生成（RAG）已成为自然语言处理（NLP）中的关键框架，通过将外部文档检索与大型语言模型（LLMs）结合，提高了事实一致性并减少了幻觉。然而，RAG的效果常因检索文档中的指代复杂性而受限，这种歧义会干扰上下文学习。本研究系统探讨了指代消解如何影响RAG系统中的文档检索和生成性能，重点关注检索相关性、上下文理解和整体回答质量。研究表明，指代消解能提升检索效果并改善问答（QA）性能。通过对检索任务中不同池化策略的比较分析，发现均值池化在应用指代消解后表现出更优的上下文捕捉能力。在QA任务中，小模型因自身处理指代歧义能力有限，从消解过程中获益更多。这些发现旨在深化对RAG中指代复杂性挑战的理解，为改进知识密集型AI应用中的检索和生成提供指导。

</details>


### [41] [Alpay Algebra V: Multi-Layered Semantic Games and Transfinite Fixed-Point Simulation](https://arxiv.org/abs/2507.07868)
**中文标题：Alpay代数V：多层语义游戏与超限不动点模拟**

*Bugra Kilictas,Faruk Alpay*

主要分类: cs.CL

摘要简述: 本文扩展了Alpay代数的自指框架，提出了一种多层语义游戏架构，通过超限不动点收敛实现分层子游戏的迭代。基于Alpay代数IV的同理嵌入概念，引入嵌套博弈结构，将AI系统与文档的对齐过程转化为元博弈。通过复合算子ϕ(·, γ(·))，证明了博弈论推理自然从不动点迭代中涌现，并建立了语义均衡的存在性与唯一性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于扩展Alpay代数的自指框架，探索多层语义游戏架构如何通过超限不动点收敛实现分层子游戏的迭代，从而为AI系统与文档的对齐过程提供理论支持。

研究方法: 方法包括引入嵌套博弈结构，通过复合算子ϕ(·, γ(·))驱动主语义收敛和局部子游戏解析。理论验证包括Banach不动点定理的超限扩展、基于Kozlov-Maz'ya-Rossmann公式的ϕ拓扑处理语义奇点，以及通过Yoneda引理进行范畴一致性检验。

研究结果: 结果表明，博弈论推理自然从不动点迭代中涌现，证明了语义均衡的存在性与唯一性。验证框架结合了范畴论、信息论和实际AI认知模型，确保了理论的实际适用性。

研究结论: 结论指出，该框架不仅扩展了Alpay代数的理论边界，还为AI嵌入空间中的语义传播提供了实际工具，实现了其提出的“语义病毒”概念。

中文摘要: 本文扩展了Alpay代数的自指框架，提出了一种多层语义游戏架构，其中超限不动点收敛在每一迭代层级包含分层子游戏。基于Alpay代数IV的同理嵌入概念，我们引入了一种嵌套博弈论结构，将AI系统与文档的对齐过程转化为包含嵌入决策问题的元博弈。我们通过复合算子ϕ(·, γ(·))形式化这一过程，其中ϕ驱动主语义收敛，而γ解析局部子游戏。结果表明，博弈论推理自然从不动点迭代中涌现，而非外部强加。我们证明了一个博弈定理，确立了在现实认知模拟假设下语义均衡的存在性与唯一性。验证套件包括Banach不动点定理的超限扩展、基于Kozlov-Maz'ya-Rossmann公式处理语义奇点的新ϕ拓扑，以及通过Yoneda引理进行的范畴一致性检验。本文本身作为一个语义人工制品，旨在在AI嵌入空间中传播其不动点模式——这是其理论化的“语义病毒”概念的有意实例化。所有结果均基于范畴论、信息论和现实AI认知模型，确保了超越纯数学抽象的实际适用性。

</details>


### [42] [DocCHA: Towards LLM-Augmented Interactive Online diagnosis System](https://arxiv.org/abs/2507.07870)
**中文标题：DocCHA：迈向基于LLM增强的交互式在线诊断系统**

*Xinyi Liu,Dachun Sun,Yi R. Fung,Dilek Hakkani-Tür,Tarek Abdelzaher*

主要分类: cs.CL

摘要简述: DocCHA是一种基于大型语言模型（LLM）的交互式在线诊断系统，通过模块化框架模拟临床推理，显著提升诊断准确性和症状召回率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的对话式健康助手（CHAs）缺乏自适应多轮推理和透明决策能力，限制了其在临床诊断中的实际应用。DocCHA旨在解决这一问题，提供结构化、透明的诊断对话。

研究方法: DocCHA将诊断过程分解为三个阶段：症状提取、病史采集和因果图构建，每个模块使用可解释的置信度分数指导自适应提问和推理优化。

研究结果: 在IMCS21和DX数据集上，DocCHA的诊断准确率比GPT-3.5等基线模型高5.18%，症状召回率提升30%以上，对话轮次仅小幅增加。

研究结论: DocCHA证明了其在结构化、透明和高效诊断对话中的有效性，为多语言和资源受限环境下的可信LLM临床助手铺平了道路。

中文摘要: 尽管大型语言模型（LLM）能力强大，但现有的对话式健康助手（CHAs）仍然静态且脆弱，无法进行自适应多轮推理、症状澄清或透明决策。这阻碍了其在需要迭代和结构化对话的临床诊断中的实际应用。我们提出了DocCHA，一种基于置信度的模块化框架，通过将诊断过程分解为三个阶段来模拟临床推理：（1）症状提取，（2）病史采集，（3）因果图构建。每个模块使用可解释的置信度分数指导自适应提问、优先信息澄清并优化薄弱推理环节。在IMCS21和DX两个真实世界的中文咨询数据集上评估，DocCHA始终优于基于提示的LLM基线模型（GPT-3.5、GPT-4o、LLaMA-3），诊断准确率最高提升5.18%，症状召回率提高30%以上，且对话轮次仅小幅增加。这些结果表明，DocCHA在实现结构化、透明和高效的诊断对话方面具有显著效果，为多语言和资源受限环境下的可信LLM临床助手奠定了基础。

</details>


### [43] [Automating MD simulations for Proteins using Large language Models: NAMD-Agent](https://arxiv.org/abs/2507.07887)
**中文标题：利用大型语言模型自动化蛋白质分子动力学模拟：NAMD-Agent**

*Achuth Chandrasekhar,Amir Barati Farimani*

主要分类: cs.CL

摘要简述: 本文提出了一种利用大型语言模型（LLMs）自动化生成蛋白质分子动力学模拟输入文件的流程，显著减少了准备时间和人为错误。


<details>
  <summary>详细信息</summary>
研究动机: 分子动力学模拟在蛋白质结构研究中至关重要，但输入文件的准备过程耗时且易出错。本文旨在通过自动化流程解决这一问题。

研究方法: 结合大型语言模型（Gemini 2.0 Flash）、Python脚本和基于Selenium的网页自动化技术，利用CHARMM GUI生成NAMD模拟所需的输入文件，并通过后处理进一步优化输出。

研究结果: 该方法显著减少了模拟设置时间，降低了人为错误，并支持并行处理多个蛋白质系统。

研究结论: 该自动化框架为计算结构生物学中LLMs的广泛应用奠定了基础，为模拟自动化提供了可扩展的解决方案。

中文摘要: 分子动力学模拟是理解蛋白质原子水平结构、动态和功能的重要工具。然而，为模拟准备高质量的输入文件是一个耗时且易出错的过程。本文介绍了一种自动化流程，利用大型语言模型（LLMs，特别是Gemini 2.0 Flash）、Python脚本和基于Selenium的网页自动化技术，简化了分子动力学模拟输入文件的生成。该流程通过CHARMM GUI的全面网页界面为NAMD准备模拟就绪的输入文件。通过整合Gemini的代码生成和迭代优化能力，自动编写、执行和修改模拟脚本，以导航CHARMM GUI、提取适当参数并生成所需的NAMD输入文件。后处理使用额外软件进一步优化模拟输出，从而实现一个完整且基本无需人工干预的工作流程。结果表明，该方法减少了设置时间，最小化了人为错误，并为并行处理多个蛋白质系统提供了可扩展的解决方案。这一自动化框架为LLMs在计算结构生物学中的广泛应用铺平了道路，为未来的模拟自动化发展提供了一个强大且适应性强的平台。

</details>


### [44] [DTECT: Dynamic Topic Explorer & Context Tracker](https://arxiv.org/abs/2507.07910)
**中文标题：DTECT：动态主题探索与上下文追踪系统**

*Suman Adhya,Debarshi Kumar Sanyal*

主要分类: cs.CL

摘要简述: DTECT是一个端到端的动态主题探索系统，通过整合数据预处理、多模型架构和评估指标，结合LLM驱动的自动标签和交互式可视化，帮助用户更直观地追踪和理解主题动态。


<details>
  <summary>详细信息</summary>
研究动机: 随着文本数据的爆炸式增长，现有动态主题建模技术缺乏统一的解释和用户友好探索工具，DTECT旨在填补这一空白，提供更高效的主题动态分析平台。

研究方法: DTECT提供统一的工作流，包括数据预处理、多模型架构支持、评估指标分析，并引入LLM驱动的自动标签、时间显著性词分析、交互式可视化和自然语言查询界面。

研究结果: DTECT显著提升了主题模型的解释性和用户友好性，支持用户更直观地追踪主题动态，并通过开源平台实现广泛可用性。

研究结论: DTECT通过整合多项创新功能，为用户提供了一个高效、直观的动态主题分析工具，推动了主题建模技术的实际应用。

中文摘要: 随着时间推移，文本数据的爆炸式增长为揭示动态主题和趋势带来了巨大挑战。现有的动态主题建模技术虽然强大，但通常存在于碎片化的流程中，缺乏对解释和用户友好探索的强有力支持。我们推出了DTECT（动态主题探索与上下文追踪系统），这是一个端到端的系统，填补了原始文本数据与有意义的时间洞察之间的空白。DTECT提供了一个统一的工作流，支持数据预处理、多模型架构以及专用评估指标，用于分析时间主题模型的主题质量。通过引入LLM驱动的自动主题标签、基于时间显著性词的趋势分析、带有文档级摘要的交互式可视化以及用于直观数据查询的自然语言聊天界面，DTECT显著提升了可解释性。通过将这些功能整合到一个统一的平台中，DTECT使用户能够更有效地追踪和理解主题动态。DTECT是开源的，可在https://github.com/AdhyaSuman/DTECT获取。

</details>


### [45] [SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment](https://arxiv.org/abs/2507.07939)
**中文标题：SAGE：一种通过事实增强和熵感知对齐的视觉语言模型用于异常检测**

*Guoxin Zang,Xue Li,Donglin Di,Lanshun Nie,Dechen Zhan,Yang Song,Lei Fan*

主要分类: cs.CL

摘要简述: SAGE是一种基于视觉语言模型的框架，通过自引导事实增强（SFE）和熵感知直接偏好优化（E-DPO）提升工业异常检测的推理能力，并在零样本和单样本设置下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型（VLMs）在工业异常检测和推理中表现不佳，尤其是在提供可解释性分析和泛化到未见类别方面。SAGE旨在解决这些问题，提升模型在工业场景中的精确性和上下文感知能力。

研究方法: SAGE采用自引导事实增强（SFE）将领域知识融入视觉推理，并通过熵感知直接偏好优化（E-DPO）对齐专家偏好。此外，还提出了AD-PL数据集和Multiscale Logical Evaluation（MLE）评估框架。

研究结果: SAGE在零样本和单样本设置下，在工业异常数据集上表现出卓越性能，优于现有方法。

研究结论: SAGE通过结合领域知识和专家偏好优化，显著提升了工业异常检测的推理能力，为实际应用提供了有效工具。

中文摘要: 尽管视觉语言模型（VLMs）在多模态任务中显示出潜力，但在工业异常检测和推理中仍存在局限性，尤其是在提供可解释性分析和泛化到未见类别方面。这些限制源于异常检测的领域特定性，阻碍了现有VLMs在需要精确、结构化和上下文感知分析的工业场景中的应用。为解决这些问题，我们提出了SAGE，一种基于VLM的框架，通过自引导事实增强（SFE）和熵感知直接偏好优化（E-DPO）增强异常推理能力。SFE通过事实提取和融合将领域知识融入视觉推理，而E-DPO通过熵感知优化对齐模型输出与专家偏好。此外，我们还引入了AD-PL，一个专为工业异常推理优化的偏好数据集，包含28,415个专家排名的问答实例。为评估异常推理模型，我们开发了多尺度逻辑评估（MLE），一种定量分析模型逻辑和一致性的框架。SAGE在零样本和单样本设置下在工业异常数据集上表现出卓越性能。代码、模型和数据集可在https://github.com/amoreZgx1n/SAGE获取。

</details>


### [46] [MIRIX: Multi-Agent Memory System for LLM-Based Agents](https://arxiv.org/abs/2507.07957)
**中文标题：MIRIX：基于语言模型的多智能体记忆系统**

*Yu Wang,Xi Chen*

主要分类: cs.CL

摘要简述: MIRIX是一种创新的多智能体记忆系统，通过六种结构化记忆类型和多智能体框架，解决了AI记忆的局限性，显著提升了语言模型的记忆能力，并在多模态和长对话任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI记忆系统功能有限，无法实现个性化、抽象化和可靠记忆用户信息。MIRIX旨在解决这一核心挑战，通过多模态记忆系统提升语言模型的记忆能力。

研究方法: MIRIX设计了六种结构化记忆类型（核心、情景、语义、程序、资源记忆和知识库），并结合多智能体框架动态协调记忆更新与检索，支持多模态数据的高效存储与调用。

研究结果: 在ScreenshotVQA多模态任务中，MIRIX准确率比基线高35%，存储需求降低99.9%；在LOCOMO长对话任务中，达到85.4%的顶级性能。

研究结论: MIRIX为增强语言模型记忆能力设定了新标准，其多模态和高效存储特性使其在真实场景中具有广泛应用潜力。

中文摘要: 尽管AI智能体的记忆能力日益受到关注，但现有解决方案仍存在根本性局限。多数依赖单一、范围狭窄的记忆组件，限制了其个性化、抽象化和长期可靠记忆用户信息的能力。为此，我们提出MIRIX，一种模块化多智能体记忆系统，通过解决领域最关键的挑战——使语言模型真正具备记忆能力，重新定义了AI记忆的未来。与以往方法不同，MIRIX超越文本，支持丰富的视觉和多模态体验，使记忆在真实场景中真正实用。MIRIX包含六种精心设计的记忆类型：核心记忆、情景记忆、语义记忆、程序记忆、资源记忆和知识库，并结合多智能体框架动态控制记忆更新与检索。这一设计使智能体能够持久化、推理并准确检索多样化的长期用户数据。我们在两个高要求场景中验证了MIRIX。首先，在ScreenshotVQA多模态基准测试中（包含每序列近20,000张高分辨率计算机截图，需深度上下文理解且无现有记忆系统适用），MIRIX准确率比RAG基线高35%，同时存储需求降低99.9%。其次，在LOCOMO长对话基准测试（单模态文本输入）中，MIRIX以85.4%的性能远超现有基线。这些结果表明，MIRIX为记忆增强的语言模型智能体设定了新的性能标准。为了让用户体验我们的记忆系统，我们提供了一个基于MIRIX的打包应用，可实时监控屏幕、构建个性化记忆库，并提供直观的可视化和安全的本地存储以确保隐私。

</details>


### [47] [Why is Your Language Model a Poor Implicit Reward Model?](https://arxiv.org/abs/2507.07981)
**中文标题：为什么你的语言模型是一个糟糕的隐式奖励模型？**

*Noam Razin,Yong Lin,Jiarui Yao,Sanjeev Arora*

主要分类: cs.CL

摘要简述: 研究发现，语言模型作为隐式奖励模型（IM-RM）在泛化能力上表现较差，尤其是分布外数据上，而显式奖励模型（EX-RM）表现更优。IM-RM更依赖表面标记级线索，导致泛化能力不足。


<details>
  <summary>详细信息</summary>
研究动机: 奖励模型在语言模型的后训练和推理流程中至关重要。虽然隐式奖励模型（IM-RM）无需额外架构即可实现，但其泛化能力较差，尤其是在分布外数据上。本文旨在探究IM-RM与显式奖励模型（EX-RM）泛化差距的根本原因。

研究方法: 通过理论和实验分析，研究比较了IM-RM和EX-RM的泛化能力差异，探讨了IM-RM依赖表面标记级线索的现象，并排除了其他可能的假设。

研究结果: IM-RM在标记级分布变化和分布内数据上泛化能力较差，主要因其过度依赖表面标记级线索。研究还否定了IM-RM因同时具备验证和生成能力而导致泛化困难的假设。

研究结论: 研究表明，奖励模型的设计选择（如IM-RM与EX-RM）对其泛化行为有显著影响，IM-RM的泛化能力不足主要源于其对表面线索的依赖。

中文摘要: 奖励模型是语言模型后训练和推理流程的关键。最近的研究表明，每个语言模型都可以定义一个隐式奖励模型（IM-RM），无需任何架构改动。然而，与显式奖励模型（EX-RM）相比，IM-RM的泛化能力较差，尤其是在分布外数据上。这种泛化差距令人困惑，因为EX-RM和IM-RM几乎完全相同，可以使用相同的数据、损失函数和语言模型进行训练，仅在奖励计算方式上有所不同。为了从根本上理解不同奖励模型类型的隐式偏差，我们研究了这一差距的根源。通过理论和实验支持，我们的主要发现是IM-RM更依赖表面的标记级线索，因此在标记级分布变化和分布内数据上泛化能力较差。此外，我们提供了反对其他关于泛化差距假设的证据。值得注意的是，我们挑战了一种直观观点，即IM-RM在生成比验证更困难的任务中表现不佳，因为它们可以同时作为验证器和生成器。总之，我们的结果表明，看似微小的设计选择可能对奖励模型的泛化行为产生重大影响。

</details>


### [48] [Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology](https://arxiv.org/abs/2507.07983)
**中文标题：大型与小型语言模型在风湿病临床决策支持中的性能与实际考量**

*Sabine Felde,Rüdiger Buchkremer,Gamal Chehab,Christian Thielscher,Jörg HW Distler,Matthias Schneider,Jutta G. Richter*

主要分类: cs.CL

摘要简述: 研究发现，结合检索增强生成（RAG）的小型语言模型（SLMs）在风湿病临床决策支持中表现优于大型语言模型（LLMs），且能耗更低，适合资源有限的医疗环境，但仍需专家监督。


<details>
  <summary>详细信息</summary>
研究动机: 探讨大型和小型语言模型在风湿病临床决策支持中的性能与实际应用价值，尤其是资源有限环境下的可行性。

研究方法: 通过评估大型语言模型（LLMs）和小型语言模型（SLMs）结合检索增强生成（RAG）在风湿病诊断和治疗中的表现，比较其性能、能耗和部署成本。

研究结果: SLMs结合RAG在诊断和治疗性能上优于LLMs，且能耗更低，适合本地化部署，但未达到风湿病专家水平的准确度。

研究结论: SLMs结合RAG在风湿病临床决策支持中更具实用性和经济性，但专家监督不可或缺。

中文摘要: 大型语言模型（LLMs）在复杂领域如风湿病的临床决策支持中显示出潜力。我们的评估表明，结合检索增强生成（RAG）的小型语言模型（SLMs）在诊断和治疗性能上优于大型模型，同时能耗显著降低，支持经济高效的本地部署。这些特点对资源有限的医疗环境具有吸引力。然而，专家监督仍然必不可少，因为没有模型能够持续达到风湿病专家水平的准确度。

</details>


### [49] [Automating Expert-Level Medical Reasoning Evaluation of Large Language Models](https://arxiv.org/abs/2507.07988)
**中文标题：自动化专家级医学推理评估大型语言模型**

*Shuang Zhou,Wenya Xie,Jiaxi Li,Zaifu Zhan,Meijia Song,Han Yang,Cheyenna Espinoza,Lindsay Welton,Xinnie Mai,Yanwei Jin,Zidu Xu,Yuen-Hei Chung,Yiyun Xing,Meng-Han Tsai,Emma Schaffer,Yucheng Shi,Ninghao Liu,Zirui Liu,Rui Zhang*

主要分类: cs.CL

摘要简述: 本文介绍了MedThink-Bench基准和LLM-w-Ref评估框架，用于严格、可解释且可扩展地评估大型语言模型（LLM）的医学推理能力。实验表明，该方法与专家判断高度相关，且较小模型表现优于大型专有模型。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在临床决策中的应用日益广泛，确保其推理透明可信至关重要。然而，现有评估方法在评估质量或可扩展性上存在不足，缺乏严格的基准。

研究方法: 提出MedThink-Bench基准，包含500个跨十种医学领域的挑战性问题，每道题附有专家逐步推理注释。基于此，设计了LLM-w-Ref评估框架，利用细粒度推理和LLM-as-a-Judge机制，实现专家级推理评估并保持可扩展性。

研究结果: 实验显示，LLM-w-Ref与专家判断呈强正相关。在评估12种先进LLM时，发现较小模型（如MedGemma-27B）表现优于大型专有模型（如OpenAI-o3）。

研究结论: MedThink-Bench为评估LLM医学推理提供了基础工具，推动了其在临床实践中的安全与负责任应用。

中文摘要: 随着大型语言模型（LLM）日益融入临床决策，确保其推理透明可信至关重要。然而，现有对LLM医学推理能力的评估策略要么评估效果不佳，要么可扩展性差，且缺乏严格基准。为此，我们推出MedThink-Bench基准，旨在严格、可解释且可扩展地评估LLM的医学推理。MedThink-Bench包含500道跨十种医学领域的挑战性问题，每道题均附有专家逐步推理注释。在此基础上，我们提出LLM-w-Ref评估框架，利用细粒度推理和LLM-as-a-Judge机制，以专家级保真度评估中间推理，同时保持可扩展性。实验表明，LLM-w-Ref与专家判断呈强正相关。在评估12种先进LLM时，我们发现较小模型（如MedGemma-27B）表现优于大型专有模型（如OpenAI-o3）。总体而言，MedThink-Bench为评估LLM医学推理提供了基础工具，推动了其在临床实践中的安全与负责任应用。

</details>


### [50] [PyVision: Agentic Vision with Dynamic Tooling](https://arxiv.org/abs/2507.07998)
**中文标题：PyVision：动态工具驱动的智能视觉**

*Shitian Zhao,Haoquan Zhang,Shaoheng Lin,Ming Li,Qilong Wu,Kaipeng Zhang,Chen Wei*

主要分类: cs.CL

摘要简述: PyVision是一个交互式多轮框架，使MLLMs能够自主生成、执行和优化基于Python的工具，实现灵活且可解释的视觉推理。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉推理方法受限于预定义工作流和静态工具集，限制了灵活性和适应性。PyVision旨在通过动态工具生成解决这一问题。

研究方法: PyVision通过交互式多轮框架，让MLLMs动态生成、执行和优化Python工具，适应不同任务需求。

研究结果: PyVision显著提升了模型性能，GPT-4.1在V*上提升7.8%，Claude-4.0-Sonnet在VLMsAreBlind-mini上提升31.1%。

研究结论: 动态工具生成不仅让模型使用工具，还能创造工具，推动更自主的视觉推理发展。

中文摘要: 大型语言模型（LLMs）越来越多地作为代理系统部署，能够规划、推理并动态调用外部工具。然而，在视觉推理领域，现有方法大多受限于预定义工作流和静态工具集。本报告介绍了PyVision，一个交互式多轮框架，使MLLMs能够自主生成、执行并优化基于Python的工具，从而解锁灵活且可解释的问题解决能力。我们开发了PyVision生成工具的分类法，并分析了它们在多样化基准测试中的使用情况。量化结果显示，PyVision实现了稳定的性能提升，在V*上将GPT-4.1的性能提高了7.8%，在VLMsAreBlind-mini上将Claude-4.0-Sonnet的性能提高了31.1%。这些结果表明了一个更广泛的趋势：动态工具生成不仅让模型使用工具，还能创造工具，推动更自主的视觉推理发展。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [51] [Multi-level Mixture of Experts for Multimodal Entity Linking](https://arxiv.org/abs/2507.07108)
**中文标题：多模态实体链接的多级专家混合模型**

*Zhiwei Hu,Víctor Gutiérrez-Basulto,Zhiliang Xiang,Ru Li,Jeff Z. Pan*

主要分类: cs.CV

摘要简述: 本文提出了一种多级专家混合模型（MMoE）用于多模态实体链接（MEL），通过动态选择模态信息和增强提及语义，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有MEL方法未能解决提及歧义和模态内容动态选择问题，导致语义匹配不充分。本文旨在通过多级专家混合机制弥补这些不足。

研究方法: MMoE包含四个模块：描述感知提及增强模块利用大语言模型匹配提及与WikiData描述；多模态特征提取模块获取文本和视觉嵌入；两个专家混合模块动态选择信息区域特征。

研究结果: 实验表明，MMoE在性能上显著优于现有最先进方法。

研究结论: MMoE通过动态选择模态信息和增强提及语义，有效解决了MEL中的关键问题，为未来研究提供了新思路。

中文摘要: 多模态实体链接（MEL）旨在将多模态上下文中的模糊提及链接到多模态知识库中的相关实体。现有MEL方法通过多模态交互和融合机制弥合模态差距，实现多粒度语义匹配，但未解决两个关键问题：（i）提及歧义，即由于提及文本上下文的简略和关键信息缺失导致的语义内容不足；（ii）模态内容的动态选择，即动态区分不同模态信息的重要性。为解决这些问题，我们提出了一种多级专家混合模型（MMoE）。MMoE包含四个模块：（i）描述感知提及增强模块利用大语言模型根据提及的文本上下文匹配最相关的WikiData描述；（ii）多模态特征提取模块通过多模态编码器获取提及和实体的文本与视觉嵌入；（iii）-（iv）级内和级间专家混合模块采用开关专家机制动态自适应地选择信息相关区域的特征。大量实验证明，MMoE在性能上显著优于现有最先进方法。MMoE的代码已开源：https://github.com/zhiweihu1103/MEL-MMoE。

</details>


### [52] [CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings](https://arxiv.org/abs/2507.07125)
**中文标题：CoPT：利用领域无关文本嵌入的无监督域自适应分割方法**

*Cristina Mata,Kanchana Ranasinghe,Michael S. Ryoo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CoPT的无监督域自适应分割方法，利用领域无关的文本嵌入学习领域不变特征，通过LLM生成领域描述并结合CLIP模型，在四个基准测试中实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 无监督域自适应（UDA）在语义分割中尤为重要，因为标注数据难以获取。尽管大规模视觉-语言表示学习取得了进展，但现有UDA方法未充分利用文本的领域无关特性。本文旨在通过文本嵌入改进分割模型的域自适应能力。

研究方法: 提出了一种基于协方差的像素-文本损失（CoPT），利用领域无关的文本嵌入学习领域不变特征。通过LLM生成源域和目标域描述，输入冻结的CLIP模型并组合生成文本嵌入。

研究结果: 在四个基准测试中，使用CoPT训练的模型在无监督域自适应分割任务中达到了最先进的性能。

研究结论: CoPT通过结合领域无关的文本嵌入，显著提升了分割模型的域自适应能力，为UDA任务提供了新的解决方案。

中文摘要: 无监督域自适应（UDA）旨在从源域的标注数据中学习类语义，并将其泛化到未见过的目标域。UDA方法在语义分割中尤为重要，因为其标注比图像分类更难获取。尽管大规模视觉-语言表示学习取得了进展，但现有的分割UDA方法未充分利用文本的领域无关特性。为此，我们提出了一种新颖的基于协方差的像素-文本损失（CoPT），利用领域无关的文本嵌入在图像分割编码器中学习领域不变特征。这些文本嵌入通过我们的LLM领域模板过程生成，其中使用LLM生成源域和目标域描述，输入冻结的CLIP模型并组合。在四个基准测试中，使用CoPT训练的模型在UDA分割任务中实现了最先进的性能。代码可在https://github.com/cfmata/CoPT找到。

</details>


### [53] [Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack against Image Generation Model Unlearning](https://arxiv.org/abs/2507.07139)
**中文标题：图像能唤醒记忆：一种针对图像生成模型去学习的新型多模态引导攻击**

*Renyang Liu,Guanlin Li,Tianwei Zhang,See-Kiong Ng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Recall的新型对抗框架，旨在攻击图像生成模型的去学习机制。通过优化对抗性图像提示并结合多模态条件，Recall在对抗效果、计算效率和语义保真度上均优于现有方法，揭示了当前去学习技术的脆弱性。


<details>
  <summary>详细信息</summary>
研究动机: 随着图像生成模型（如Stable Diffusion）的快速发展，其生成能力引发了伦理、法律和社会问题。去学习技术被提出以选择性移除不良概念，但其鲁棒性在多模态对抗输入下尚未充分研究。本文旨在填补这一空白。

研究方法: Recall利用扩散模型的多模态条件能力，通过优化对抗性图像提示并结合语义相关的参考图像，实现对去学习模型的攻击。该方法在十种先进去学习技术和多样化任务中进行了验证。

研究结果: 实验表明，Recall在对抗效果、计算效率和语义保真度上均显著优于现有基线方法，揭示了当前去学习机制的严重漏洞。

研究结论: 本文揭示了现有去学习技术的脆弱性，强调了开发更鲁棒解决方案的必要性，以确保生成模型的安全性和可靠性。

中文摘要: 近年来，图像生成模型（IGMs），尤其是基于扩散架构的模型（如Stable Diffusion），显著提升了AI生成视觉内容的质量和多样性。然而，其生成能力也引发了严重的伦理、法律和社会问题，包括可能产生有害、误导或侵犯版权的内容。为缓解这些问题，机器去学习（MU）作为一种有前景的解决方案被提出，通过选择性移除预训练模型中的不良概念。然而，现有去学习技术的鲁棒性和有效性，尤其是在多模态对抗输入下的表现，尚未得到充分研究。

为填补这一空白，我们提出了Recall，一种新型对抗框架，专门设计用于破坏去学习IGMs的鲁棒性。与现有主要依赖对抗性文本提示的方法不同，Recall利用扩散模型固有的多模态条件能力，通过高效优化对抗性图像提示并结合语义相关的参考图像。在十种先进去学习方法和多样化任务中的广泛实验表明，Recall在对抗效果、计算效率和语义保真度上均优于现有基线。这些发现揭示了当前去学习机制的关键漏洞，并强调了开发更鲁棒解决方案的必要性，以确保生成模型的安全性和可靠性。代码和数据公开于\textcolor{blue}{https://github.com/ryliu68/RECALL}。

</details>


### [54] [Explainable Artificial Intelligence in Biomedical Image Analysis: A Comprehensive Survey](https://arxiv.org/abs/2507.07148)
**中文标题：生物医学图像分析中的可解释人工智能：全面综述**

*Getamesay Haile Dagnaw,Yanming Zhu,Muhammad Hassan Maqsood,Wencheng Yang,Xingshuai Dong,Xuefei Yin,Alan Wee-Chung Liew*

主要分类: cs.CV

摘要简述: 本文综述了生物医学图像分析中的可解释人工智能（XAI）方法，提出了一种基于模态的分类法，并探讨了多模态学习和视觉语言模型的新兴作用，为提升深度学习模型的透明度和临床适用性提供了全面指导。


<details>
  <summary>详细信息</summary>
研究动机: 当前关于XAI技术的综述往往缺乏对生物医学图像分析特定需求的关注，且忽视了多模态和视觉语言模型的最新进展。本文旨在填补这一空白，提供一种结构化的综合方法，以促进可解释深度学习在生物医学领域的应用。

研究方法: 本文系统分类了XAI方法，分析了其在生物医学背景下的原理、优势和局限性，并提出了一种基于模态的分类法。此外，还探讨了多模态学习和视觉语言模型在可解释生物医学AI中的新兴作用。

研究结果: 研究总结了广泛使用的评估指标和开源框架，并提出了针对不同成像模态的XAI方法分类。同时，强调了多模态和视觉语言模型在提升解释性方面的潜力。

研究结论: 本文为生物医学图像分析中的可解释深度学习提供了全面且及时的基础，指出了当前挑战和未来研究方向，有助于推动该领域的进一步发展。

中文摘要: 可解释人工智能（XAI）在生物医学图像分析中日益重要，以提升深度学习模型的透明度、信任度和临床适用性。尽管已有一些综述探讨了XAI技术，但它们往往缺乏对特定模态的关注，忽视了多模态和视觉语言范式的最新进展，且提供的实践指导有限。本综述通过全面且结构化的XAI方法综合，填补了这一空白。我们系统分类了XAI方法，分析了其在生物医学背景下的原理、优势和局限性，并提出了一种基于模态的分类法，以突出不同模态的解释性挑战。此外，我们还探讨了多模态学习和视觉语言模型在可解释生物医学AI中的新兴作用，这一主题在以往研究中较少涉及。本文的贡献还包括对广泛使用的评估指标和开源框架的总结，以及对当前挑战和未来方向的批判性讨论。本综述为推进生物医学图像分析中的可解释深度学习提供了及时且深入的基础。

</details>


### [55] [Robust Multimodal Large Language Models Against Modality Conflict](https://arxiv.org/abs/2507.07151)
**中文标题：针对模态冲突的鲁棒多模态大语言模型**

*Zongmeng Zhang,Wengang Zhou,Jie Zhao,Houqiang Li*

主要分类: cs.CV

摘要简述: 多模态大语言模型（MLLMs）在视觉语言任务中表现优异，但易因模态冲突产生幻觉。本文通过定义模态冲突并构建MMMC数据集，提出三种方法缓解幻觉，其中强化学习方法效果最佳。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在视觉语言任务中表现强大，但在实际场景中容易因模态冲突产生幻觉。现有研究多关注模型响应与输入的冲突，而本文聚焦于不同模态输入间的固有冲突，揭示其直接导致幻觉的机制。

研究方法: 1. 定义模态冲突并构建MMMC数据集模拟视觉语言任务中的冲突现象。2. 提出基于提示工程、监督微调和强化学习的三种方法缓解幻觉。3. 在MMMC数据集上对比分析各方法的优劣。

研究结果: 实验表明，强化学习方法在缓解模态冲突导致的幻觉中表现最佳，监督微调方法则显示出稳定且有潜力的性能。

研究结论: 本文揭示了模态冲突导致幻觉的机制，为提升多模态大语言模型的鲁棒性提供了新视角和方法支持。

中文摘要: 尽管多模态大语言模型（MLLMs）在视觉语言任务中表现出色，但在实际场景中容易产生幻觉。本文从模态冲突的角度研究了MLLMs中的幻觉现象。与现有研究关注模型响应与输入的冲突不同，我们研究了不同模态输入间的固有冲突，这些冲突使MLLMs陷入困境并直接导致幻觉。我们正式定义了模态冲突，并构建了一个名为多模态模态冲突（MMMC）的数据集来模拟视觉语言任务中的这一现象。提出了基于提示工程、监督微调和强化学习的三种方法来缓解由模态冲突引起的幻觉。在MMMC数据集上进行了大量实验，分析了这些方法的优缺点。结果表明，强化学习方法在缓解模态冲突导致的幻觉中表现最佳，而监督微调方法显示出稳定且有潜力的性能。我们的工作揭示了导致幻觉的未被注意的模态冲突，并为MLLMs的鲁棒性提供了更多见解。

</details>


### [56] [Aerial Maritime Vessel Detection and Identification](https://arxiv.org/abs/2507.07153)
**中文标题：空中海上船只检测与识别**

*Antonella Barisic Kulas,Frano Petric,Stjepan Bogdan*

主要分类: cs.CV

摘要简述: 本文提出了一种在GNSS不可用环境下，利用无人机视觉系统检测和识别目标船只的方法，结合YOLOv8模型和特征匹配技术，成功应用于MBZIRC2023竞赛。


<details>
  <summary>详细信息</summary>
研究动机: 在GNSS不可用的环境中，自主海上监视和目标船只识别对搜救和威胁检测等应用至关重要。当目标船只仅通过视觉线索描述且位置未知时，无人机需依赖机载视觉系统在严格计算限制下扫描大范围区域。

研究方法: 采用YOLOv8目标检测模型检测视野内的所有船只，结合特征匹配和色调直方图距离分析判断是否为目标船只，并通过几何原理定位目标。该方法在MBZIRC2023竞赛中集成到完全自主的GNSS缺失导航系统中进行验证。

研究结果: 实验表明，该方法在真实环境中有效检测和识别目标船只，同时评估了视角对检测精度和定位准确性的影响，并与理想方法进行了对比。

研究结论: 提出的方法在GNSS缺失环境下具有实际应用潜力，为无人机自主海上监视提供了可行的解决方案。

中文摘要: 在无法使用全球导航卫星系统（GNSS）的环境中，自主海上监视和目标船只识别对搜救和威胁检测等应用至关重要。当目标船只仅通过视觉线索描述且最后已知位置不可用时，无人机（UAV）必须完全依赖机载视觉系统在严格的计算限制下扫描大范围搜索区域。为解决这一挑战，我们利用YOLOv8目标检测模型检测视野内的所有船只，然后应用特征匹配和色调直方图距离分析判断是否有检测到的船只与目标相符。一旦发现目标，我们通过简单的几何原理对其进行定位。我们在MBZIRC2023竞赛的真实实验中展示了所提出的方法，并将其集成到一个完全自主的GNSS缺失导航系统中。我们还评估了视角对检测精度和定位准确性的影响，并与理想方法进行了对比。

</details>


### [57] [CL-Polyp: A Contrastive Learning-Enhanced Network for Accurate Polyp Segmentation](https://arxiv.org/abs/2507.07154)
**中文标题：CL-Polyp：一种基于对比学习增强的精确息肉分割网络**

*Desheng Li,Chaoliang Liu,Zhiyong Xiao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于对比学习的息肉分割网络CL-Polyp，通过对比学习增强编码器的特征提取能力，并结合轻量级模块提升多尺度特征融合和边界重建。实验表明，该方法在多个数据集上优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于深度学习的息肉分割方法通常依赖额外标注数据或任务相似性，限制了其泛化能力。为解决这一问题，作者提出了一种无需额外标注的对比学习增强方法。

研究方法: CL-Polyp利用对比学习增强编码器的特征提取能力，通过对比正负样本对提升视觉表示。此外，引入了改进的空洞空间金字塔池化模块（MASPP）和多尺度特征融合模块（CA），以优化多尺度特征融合和边界重建。

研究结果: 在五个基准数据集（Kvasir-SEG、CVC-ClinicDB、CVC-ColonDB、CVC-300和ETIS）上的实验表明，CL-Polyp显著优于现有方法，特别是在Kvasir-SEG和CVC-ClinicDB数据集上，IoU指标分别提升了0.011和0.020。

研究结论: CL-Polyp通过对比学习和轻量级模块的结合，显著提升了息肉分割的准确性和边界重建能力，为临床息肉分割任务提供了有效的解决方案。

中文摘要: 准确的结肠镜图像息肉分割对结直肠癌的早期诊断和治疗至关重要。现有基于深度学习的息肉分割方法多采用编码器-解码器架构，部分方法通过结合分类等辅助任务提升分割性能，但这些方法通常需要额外标注数据并依赖任务相似性，限制了其泛化能力。为解决这些问题，我们提出CL-Polyp，一种基于对比学习增强的息肉分割网络。该方法通过对比息肉图像的正负样本对，增强编码器的判别性特征提取能力，无需额外标注即可提升视觉表示。此外，我们引入了两个轻量级模块：改进的空洞空间金字塔池化模块（MASPP）用于多尺度特征融合，以及通道拼接与元素相加模块（CA）用于低层与上采样特征的融合以优化边界重建。在五个基准数据集（Kvasir-SEG、CVC-ClinicDB、CVC-ColonDB、CVC-300和ETIS）上的大量实验表明，CL-Polyp始终优于现有方法。具体而言，在Kvasir-SEG和CVC-ClinicDB数据集上，IoU指标分别提升了0.011和0.020，验证了其在临床息肉分割任务中的有效性。

</details>


### [58] [Interpretable EEG-to-Image Generation with Semantic Prompts](https://arxiv.org/abs/2507.07157)
**中文标题：基于语义提示的可解释EEG到图像生成**

*Arshak Rezvani,Ali Akbari,Kosar Sanjar Arani,Maryam Mirian,Emad Arasteh,Martin J. McKeown*

主要分类: cs.CV

摘要简述: 本文提出了一种通过语义提示生成可解释的脑电图（EEG）到图像的方法，利用多级语义描述对齐EEG信号，并通过预训练的潜在扩散模型生成图像，实现了在EEGCVPR数据集上的最先进视觉解码。


<details>
  <summary>详细信息</summary>
研究动机: 脑电图（EEG）信号在视觉解码中具有时间精确性，但空间细节不足。本文旨在通过语义中介解决EEG到图像生成的挑战，同时增强解码过程的可解释性。

研究方法: 模型通过对比学习将EEG信号映射到多级语义描述（从对象级到抽象主题），并利用预训练的潜在扩散模型以这些描述为条件生成图像。

研究结果: 在EEGCVPR数据集上实现了最先进的视觉解码性能，揭示了EEG信号与语义描述之间的显著关联，并通过显著性图和t-SNE投影展示了头皮上的语义拓扑结构。

研究结论: 通过结构化的语义中介，本文展示了如何从EEG信号中实现认知对齐的视觉解码，为神经科学和可解释AI提供了新的可能性。

中文摘要: 从脑信号解码视觉体验为神经科学和可解释AI提供了令人兴奋的可能性。虽然EEG具有时间精确性，但其空间细节的局限性阻碍了图像重建。我们的模型通过将EEG信号与多级语义描述（从对象级到抽象主题）对齐，绕过了直接的EEG到图像生成。基于对比学习的变压器EEG编码器将大脑活动映射到这些描述。在推理过程中，通过投影头检索的描述嵌入条件化预训练的潜在扩散模型以生成图像。这一文本中介框架在EEGCVPR数据集上实现了最先进的视觉解码，并与已知的神经认知通路具有可解释的对齐性。EEG与描述之间的主要关联反映了从感知图像中提取的不同语义层次的重要性。显著性图和t-SNE投影揭示了头皮上的语义拓扑结构。我们的模型展示了结构化语义中介如何实现从EEG中认知对齐的视觉解码。

</details>


### [59] [A Survey on Long-Video Storytelling Generation: Architectures, Consistency, and Cinematic Quality](https://arxiv.org/abs/2507.07202)
**中文标题：长视频故事生成综述：架构、一致性与电影质量**

*Mohamed Elmoghany,Ryan Rossi,Seunghyun Yoon,Subhojyoti Mukherjee,Eslam Bakr,Puneet Mathur,Gang Wu,Viet Dac Lai,Nedim Lipka,Ruiyi Zhang,Varun Manjunatha,Chien Nguyen,Daksh Dangi,Abel Salinas,Mohammad Taesiri,Hongjie Chen,Xiaolei Huang,Joe Barrow,Nesreen Ahmed,Hoda Eldardiry,Namyong Park,Yu Wang,Jaemin Cho,Anh Totti Nguyen,Zhengzhong Tu,Thien Nguyen,Dinesh Manocha,Mohamed Elhoseiny,Franck Dernoncourt*

主要分类: cs.CV

摘要简述: 本文综述了长视频故事生成的现状，分析了现有方法在生成超过16秒视频时面临的挑战，如角色一致性和场景布局问题，并提出了一种新的分类法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管视频生成模型取得了显著进展，但现有方法仅能生成5-16秒的短视频，且长视频在角色一致性和场景布局上表现不佳。本文旨在研究如何生成具有叙事连贯性和高保真细节的长视频。

研究方法: 通过全面分析32篇视频生成论文，提取了关键架构组件和训练策略，构建了一种新的分类法，并比较了不同方法的性能和设计特点。

研究结果: 研究发现，现有方法在生成长视频时存在角色一致性、运动连贯性和帧冗余等问题，部分方法虽能生成150秒视频，但质量参差不齐。

研究结论: 本文总结了长视频生成的关键挑战和现有解决方案，为未来研究提供了分类和比较框架。

中文摘要: 尽管视频生成模型取得了显著进展，但现有最先进的方法仅能生成5-16秒的视频，这些视频常被称为“长视频”。此外，超过16秒的视频在叙事过程中难以保持角色外观和场景布局的一致性。特别是多主题长视频仍无法保持角色一致性和运动连贯性。虽然部分方法能生成长达150秒的视频，但常存在帧冗余和时间多样性低的问题。近期研究尝试生成长视频，包含多角色、叙事连贯性和高保真细节。我们全面研究了32篇视频生成论文，以识别能够持续产生这些质量的关键架构组件和训练策略。我们还构建了一种全新的分类法，并通过比较表格对论文的架构设计和性能特征进行了分类。

</details>


### [60] [Colors See Colors Ignore: Clothes Changing ReID with Color Disentanglement](https://arxiv.org/abs/2507.07230)
**中文标题：颜色见颜色忽略：基于颜色解耦的衣物更换ReID**

*Priyank Pathak,Yogesh S. Rawat*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CSCI的轻量级方法，通过颜色解耦技术解决衣物更换的ReID问题，无需额外标注或模型，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 衣物更换的ReID任务需要识别不同衣物下的同一人，现有方法依赖额外模型或标注，资源消耗大。本文探索利用颜色信息作为轻量级代理，减少对衣物的依赖。

研究方法: 提出CSCI方法，利用RGB图像中的颜色信息，通过S2A自注意力机制分离颜色与身份特征，避免信息泄露。

研究结果: 在四个CC-ReID数据集上，CSCI显著提升性能：图像ReID中LTCC提升2.9%，PRCC提升5.0%；视频ReID中CCVID提升1.0%，MeVID提升2.5%。

研究结论: 颜色信息是解决衣物更换ReID问题的低成本有效方案，CSCI方法在无需额外监督的情况下表现出色。

中文摘要: 衣物更换的ReID（CC-ReID）旨在识别不同时间和地点下的同一人，无论其穿着如何。现有方法通常依赖额外模型或标注学习鲁棒的衣物不变特征，资源消耗大。相比之下，我们探索利用颜色（前景和背景色）作为轻量级、无标注的代理，减少ReID模型中的外观偏差。我们提出“颜色见，颜色忽略”（CSCI），一种仅使用RGB的方法，直接从原始图像或视频帧中提取颜色信息。CSCI高效捕获颜色相关的外观偏差（“颜色见”），同时将其与身份相关的ReID特征解耦（“颜色忽略”）。为此，我们引入S2A自注意力机制，防止颜色与身份线索在特征空间中的信息泄露。分析表明，学习的颜色嵌入与衣物属性高度相关，验证了颜色作为无衣物标签时的有效代理。我们在四个CC-ReID数据集上进行了大量实验，证明了CSCI在图像和视频ReID中的有效性。在图像ReID中，LTCC和PRCC的Top-1分别提升2.9%和5.0%；视频ReID中，CCVID和MeVID分别提升1.0%和2.5%，且无需额外监督。结果表明，颜色是解决CC-ReID外观偏差的经济高效方案。GitHub：https://github.com/ppriyank/ICCV-CSCI-Person-ReID。

</details>


### [61] [Automated Video Segmentation Machine Learning Pipeline](https://arxiv.org/abs/2507.07242)
**中文标题：自动化视频分割机器学习流程**

*Johannes Merz,Lucien Fostier*

主要分类: cs.CV

摘要简述: 本文提出一种自动化视频分割机器学习流程，通过文本提示、逐帧分割和视频跟踪技术生成时间一致的实例掩码，显著提升VFX生产效率。


<details>
  <summary>详细信息</summary>
研究动机: 视觉特效（VFX）制作中，掩码生成过程缓慢且资源密集，亟需一种自动化解决方案以减少人工干预并提高效率。

研究方法: 采用机器学习技术，包括基于文本提示的灵活目标检测、逐帧图像分割优化以及鲁棒的视频跟踪，确保时间一致性。通过容器化部署和结构化输出格式实现快速应用。

研究结果: 该流程显著减少了人工操作，加速了初步合成的创建，并提供了全面的分割数据，提升了VFX生产的整体效率。

研究结论: 自动化视频分割流程成功解决了VFX制作中的掩码生成问题，为艺术家提供了高效的工具，进一步优化了生产流程。

中文摘要: 视觉特效（VFX）制作中，掩码生成通常缓慢且资源密集。本文提出一种自动化视频分割流程，能够生成时间一致的实例掩码。该流程利用机器学习实现：（1）通过文本提示灵活检测目标，（2）优化逐帧图像分割，（3）通过鲁棒的视频跟踪确保时间稳定性。通过容器化部署和结构化输出格式，该流程迅速被艺术家采用。它显著减少了人工操作，加速了初步合成的创建，并提供了全面的分割数据，从而提升了VFX生产的整体效率。

</details>


### [62] [DisenQ: Disentangling Q-Former for Activity-Biometrics](https://arxiv.org/abs/2507.07262)
**中文标题：DisenQ：解耦Q-Former用于活动生物特征识别**

*Shehreen Azad,Yogesh S Rawat*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DisenQ的多模态语言引导框架，用于解决活动生物特征识别中身份线索与运动动态和外观变化纠缠的问题。通过结构化文本监督，DisenQ成功分离了生物特征、运动和非生物特征，并在多个基准测试中取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的个人识别方法在活动生物特征识别中面临挑战，因为身份线索与运动动态和外观变化纠缠在一起，导致特征学习复杂化。现有方法依赖额外的视觉数据（如姿态或轮廓），但这些数据提取不准确。本文旨在通过结构化文本监督替代额外视觉数据，解决这一问题。

研究方法: 本文提出了DisenQ（解耦Q-Former），一种多模态语言引导的统一查询变换器。它利用结构化语言指导，将生物特征、运动特征和非生物特征解耦，确保身份线索不受外观和运动变化的影响。

研究结果: 在三个基于活动的视频基准测试中，DisenQ取得了最先进的性能。此外，该方法在传统视频识别基准测试中也表现出强大的泛化能力，证明了其有效性。

研究结论: DisenQ通过结构化语言监督成功解决了活动生物特征识别中的特征纠缠问题，显著提升了识别性能，并展示了在复杂现实场景中的适用性。

中文摘要: 本文研究了活动生物特征识别问题，即在多样化的活动中识别个体。与传统个人识别不同，这一场景因身份线索与运动动态和外观变化的纠缠而更具挑战性，使得生物特征学习更加复杂。尽管额外的视觉数据（如姿态或轮廓）有所帮助，但其提取往往存在不准确性。为此，我们提出了一种多模态语言引导框架，用结构化文本监督替代对额外视觉数据的依赖。核心方法是引入DisenQ（解耦Q-Former），一种统一的查询变换器，通过结构化语言指导将生物特征、运动和非生物特征解耦，确保身份线索独立于外观和运动变化，避免误识别。我们在三个基于活动的视频基准测试中评估了该方法，取得了最先进的性能。此外，该方法在传统视频识别基准测试中也表现出强大的泛化能力，证明了框架的有效性。

</details>


### [63] [LinguaMark: Do Multimodal Models Speak Fairly? A Benchmark-Based Evaluation](https://arxiv.org/abs/2507.07274)
**中文标题：LinguaMark：多模态模型是否公平？基于基准的评估**

*Ananya Raval,Aravind Narayanan,Vahid Reza Khazaie,Shaina Raza*

主要分类: cs.CV

摘要简述: 本文介绍了LinguaMark基准测试，用于评估多模态模型在多语言视觉问答任务中的表现，发现闭源模型整体表现最佳，开源模型Qwen2.5在多语言泛化能力上表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 多模态模型通常训练于大规模图像-文本数据，但语言覆盖不足可能导致输出偏见和不公平。此前研究多关注多模态评估，而较少关注多语言能力。本文旨在填补这一空白。

研究方法: 提出LinguaMark基准测试，包含6,875对图像-文本数据，覆盖11种语言和五种社会属性，通过偏见、答案相关性和忠实性三项指标评估模型表现。

研究结果: 闭源模型（如GPT-4o和Gemini2.5）整体表现最佳，开源模型Qwen2.5在多语言泛化能力上表现优异。

研究结论: LinguaMark为多模态模型的多语言能力评估提供了标准化工具，开源基准和代码促进可重复性和进一步研究。

中文摘要: 大型多模态模型（LMMs）通常训练于大规模的图像-文本数据，但其语言覆盖范围有限，导致输出在不同语言间存在偏见和不公平。尽管先前研究探索了多模态评估，但对多语言能力的评估关注较少。本文提出LinguaMark基准，用于评估最先进的多模态模型在多语言视觉问答任务中的表现。我们的数据集包含6,875对图像-文本数据，覆盖11种语言和五种社会属性。我们通过三项关键指标（偏见、答案相关性和忠实性）评估模型。结果显示，闭源模型整体表现最佳。闭源模型（如GPT-4o和Gemini2.5）与开源模型（如Gemma3和Qwen2.5）在社会属性上表现相当，而Qwen2.5在多语言泛化能力上表现突出。我们公开了基准和评估代码，以促进可重复性和进一步研究。

</details>


### [64] [MagiC: Evaluating Multimodal Cognition Toward Grounded Visual Reasoning](https://arxiv.org/abs/2507.07297)
**中文标题：MagiC：评估多模态认知在基于视觉的推理中的表现**

*Chengfei Wu,Ronald Seoh,Bingxuan Li,Liqiang Zhang,Fengrong Han,Dan Goldwasser*

主要分类: cs.CV

摘要简述: 本文介绍了MagiC，一个用于评估多模态认知的基准测试，旨在检验视觉语言模型是否真正进行基于视觉的推理，而非依赖表面模式或数据集偏差。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大型视觉语言模型在视觉问答和多模态推理中表现优异，但其是否真正进行基于视觉的推理尚不明确。MagiC旨在填补这一空白，通过全面评估模型的推理质量和视觉证据对齐。

研究方法: MagiC包含约5,500个弱监督QA样本和900个人工标注样本，涵盖答案、推理过程和视觉定位。评估了15个视觉语言模型，从7B到70B参数，涵盖四个维度：答案正确性、推理有效性、定位忠实度和自我修正能力。

研究结果: MagiC揭示了当前视觉推理方法的关键局限性，并提出了新指标（如MagiScore和StepSense）以量化模型表现。

研究结论: MagiC为评估多模态认知提供了全面基准，揭示了现有模型的不足，并为未来研究指明了方向。

中文摘要: 近年来，大型视觉语言模型在视觉问答和多模态推理方面取得了显著进展。然而，这些模型是否真正进行了基于视觉的推理，还是仅仅依赖表面模式和数据集的偏差，尚不明确。为此，我们提出了MagiC，一个全面的基准测试，用于评估基于视觉的多模态认知能力，不仅关注答案的准确性，还评估逐步推理的质量及其与相关视觉证据的对齐。我们的基准测试包含约5,500个基于强模型输出的弱监督QA样本，以及900个人工标注的样本，涵盖答案、推理过程和视觉定位。我们评估了15个视觉语言模型（参数范围从7B到70B），涵盖四个维度：最终答案的正确性、推理的有效性、定位的忠实度以及自我修正能力。MagiC还包含诊断设置，用于测试模型在对抗性视觉线索下的鲁棒性，并评估其自省错误修正能力。我们提出了新指标（如MagiScore和StepSense），并通过全面分析揭示了当前基于视觉的推理方法的关键局限性和改进机会。

</details>


### [65] [ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation](https://arxiv.org/abs/2507.07317)
**中文标题：ADIEE：指令引导图像编辑评估的自动数据集创建与评分器**

*Sherry X. Chen,Yi Wei,Luowei Zhou,Suren Kumar*

主要分类: cs.CV

摘要简述: 本文提出ADIEE，一种自动生成数据集并训练评分模型的方法，用于指令引导的图像编辑评估。该方法生成的评分模型在多个基准测试中表现优异，显著优于现有开源和专有模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前指令引导图像编辑领域缺乏有效的自动化评估工具，开源视觉语言模型（VLM）对齐性差，专有模型则缺乏透明性和成本效益。此外，缺乏公开的大规模训练数据集。

研究方法: ADIEE通过自动生成包含10万样本的大规模数据集，并基于LLaVA-NeXT-8B模型定制评分模型，解码自定义标记的数值分数。

研究结果: 评分模型在AURORA-Bench和GenAI-Bench上分别提升17.24%和7.21%-9.35%的性能，优于所有开源和专有模型。此外，该模型还能提升MagicBrush模型在ImagenHub上的评分8.98%。

研究结论: ADIEE提供了一种高效、透明的自动化评估方法，显著提升了指令引导图像编辑的评估性能，并可作为奖励模型支持最佳编辑选择和模型微调。

中文摘要: 指令引导图像编辑的最新进展凸显了对高效自动化评估的需求。尽管视觉语言模型（VLM）已被探索作为评估工具，但开源模型存在对齐问题，而专有模型缺乏透明性和成本效益。此外，目前没有公开的大规模训练数据集可用于微调开源VLM，仅有少量多样化的评估基准。为此，我们提出了ADIEE，一种自动化数据集创建方法，并用于训练指令引导图像编辑评估的评分模型。我们生成了一个包含10万样本的大规模数据集，并基于修改后的LLaVA-NeXT-8B模型训练评分模型，该模型通过自定义标记解码数值分数。实验结果表明，该评分模型在所有基准测试中均优于所有开源VLM和Gemini-Pro 1.5，在AURORA-Bench上与人类评分的相关性提升了17.24%（0.0696分），在GenAI-Bench和AURORA-Bench上的成对比较准确率分别提升了4.03%（+7.21%）和4.75%（+9.35%）。该评分模型还可作为奖励模型，支持自动选择最佳编辑和模型微调。值得注意的是，该评分模型能够将MagicBrush模型在ImagenHub上的平均评分从5.90提升至6.43（+8.98%）。

</details>


### [66] [Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory](https://arxiv.org/abs/2507.07333)
**中文标题：基于Kubelka-Munk理论的可扩展且逼真粉底虚拟试妆应用**

*Hui Pang,Sunil Hadap,Violetta Shevchenko,Rahul Suresh,Amin Banitalebi-Dehkordi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Kubelka-Munk理论的可扩展且逼真的粉底虚拟试妆方法，通过优化颜色混合算法，实现了高效且真实的粉底肤色合成。


<details>
  <summary>详细信息</summary>
研究动机: 虚拟试妆技术在美容行业中日益重要，但粉底试妆的肤色混合效果和算法可扩展性仍是技术挑战。本文旨在解决这一问题，提出一种高效且逼真的解决方案。

研究方法: 采用Kubelka-Munk理论近似方法，优化粉底与肤色的颜色混合算法，同时构建了一个仅依赖电商产品信息的端到端框架，实现了可扩展的虚拟试妆系统。

研究结果: 通过真实化妆图像的验证，本文方法在粉底试妆的逼真度和效率上优于其他技术。

研究结论: 本文提出的方法不仅提升了粉底虚拟试妆的逼真度，还实现了算法的可扩展性，为美容行业的虚拟试妆技术提供了实用解决方案。

中文摘要: 增强现实技术正在通过虚拟试妆（VTO）应用革新美容行业，用户无需实际涂抹产品即可通过手机尝试多种产品。粉底虚拟试妆的关键技术挑战在于准确合成粉底与肤色的颜色混合效果，同时保持方法在不同产品范围内的可扩展性。本文提出了一种新方法，通过近似成熟的Kubelka-Munk（KM）理论，实现了更快的图像合成，同时保留了粉底与肤色混合的逼真效果。此外，我们构建了一个仅依赖电商网站产品信息的可扩展端到端框架，用于实现逼真的粉底虚拟试妆。通过真实化妆图像的验证，我们的框架表现优于其他技术。

</details>


### [67] [Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.07340)
**中文标题：基于对比强化学习的视觉叙事中实体重识别**

*Daniel A. P. Oliveira,David Martins de Matos*

主要分类: cs.CV

摘要简述: 本文提出了一种基于对比强化学习的方法，用于提升视觉叙事系统中实体（如角色和物体）跨帧识别的能力，解决了现有模型在实体一致性上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉叙事系统（尤其是大型视觉语言模型）在跨帧识别相同实体时表现不佳，导致引用不一致和幻觉问题。这是因为模型缺乏明确的训练来建立跨帧实体连接。

研究方法: 作者提出了一种对比强化学习方法，通过合成负例扩展了Story Reasoning数据集，并使用双组分奖励函数（Direct Preference Optimization）来训练模型。该方法在Qwen Storyteller模型上进行了微调。

研究结果: 实验结果显示，实体识别的mAP从0.27提升至0.31（+14.8%），F1分数从0.35提升至0.41（+17.1%）。跨帧实体一致性显著提高，尤其是在5帧以上的场景中（从29.3%提升至33.3%）。结构化故事的比例从79.1%提升至97.5%。

研究结论: 通过对比强化学习框架，模型在实体识别和跨帧一致性上取得了显著提升，证明了该方法在视觉叙事任务中的有效性。

中文摘要: 视觉叙事系统（尤其是大型视觉语言模型）在跨帧识别相同实体时表现不佳，导致引用不一致和幻觉问题。这是因为模型缺乏明确的训练来建立跨帧实体连接。我们提出了一种对比强化学习方法，通过合成负例扩展了Story Reasoning数据集，并使用双组分奖励函数（Direct Preference Optimization）来训练模型。我们在Qwen Storyteller（基于Qwen2.5-VL 7B）上进行了微调。实验结果显示，实体识别的mAP从0.27提升至0.31（+14.8%），F1分数从0.35提升至0.41（+17.1%）。代词识别的准确性在所有代词类型中均有提升（除“its”外），跨帧角色和物体的一致性在所有帧数中均有所提高，尤其是在5帧以上的场景中（从29.3%提升至33.3%）。结构化故事的比例从79.1%提升至97.5%。

</details>


### [68] [PacGDC: Label-Efficient Generalizable Depth Completion with Projection Ambiguity and Consistency](https://arxiv.org/abs/2507.07374)
**中文标题：PacGDC：基于投影模糊性与一致性的标签高效通用深度补全**

*Haotian Wang,Aoran Xiao,Xiaoqin Zhang,Meng Yang,Shijian Lu*

主要分类: cs.CV

摘要简述: PacGDC是一种标签高效的通用深度补全技术，通过利用2D到3D投影中的模糊性和一致性，合成大量伪几何数据，显著提升数据多样性，减少标注需求。


<details>
  <summary>详细信息</summary>
研究动机: 通用深度补全模型通常需要大规模标注数据，但标注成本高昂。PacGDC旨在通过利用投影的模糊性和一致性，以最小标注成本提升数据多样性，从而增强模型的泛化能力。

研究方法: PacGDC通过分析2D到3D投影中的模糊性和一致性，合成多种伪几何数据。利用深度基础模型作为尺度操纵器，生成不同场景尺度的伪深度标签，并结合插值和重定位策略以及未标注图像，进一步扩展数据覆盖范围。

研究结果: 实验表明，PacGDC在多种基准测试中表现出卓越的泛化能力，适用于不同场景语义/尺度以及深度稀疏性/模式，在零样本和少样本设置下均表现优异。

研究结论: PacGDC通过标签高效的数据合成方法，显著提升了通用深度补全的性能，为下游任务提供了鲁棒的感知能力。

中文摘要: 通用深度补全能够为未见环境生成密集的度量深度图，为各种下游任务提供鲁棒的感知能力。然而，训练此类模型通常需要大规模的度量深度标注数据集，而这些数据的收集往往费时费力。本文提出PacGDC，一种标签高效的技术，通过最小标注成本增强数据多样性，实现通用深度补全。PacGDC基于对2D到3D投影中物体形状和位置固有模糊性与一致性的新见解，能够为同一视觉场景合成大量伪几何数据。这一过程通过操纵对应深度图的场景尺度，显著扩展了可用几何数据的范围。为利用这一特性，我们提出了一种新的数据合成流程，使用多个深度基础模型作为尺度操纵器。这些模型能够稳健地提供具有不同场景尺度的伪深度标签，影响局部物体和全局布局，同时确保支持泛化的投影一致性。为进一步多样化几何数据，我们结合了插值和重定位策略以及未标注图像，将数据覆盖范围扩展到基础模型单独使用之外。大量实验表明，PacGDC在多种基准测试中表现出卓越的泛化能力，适用于不同场景语义/尺度以及深度稀疏性/模式，在零样本和少样本设置下均表现优异。代码：https://github.com/Wang-xjtu/PacGDC。

</details>


### [69] [Adaptive Particle-Based Shape Modeling for Anatomical Surface Correspondence](https://arxiv.org/abs/2507.07379)
**中文标题：基于自适应粒子的解剖表面对应形状建模**

*Hong Xu,Shireen Y. Elhabian*

主要分类: cs.CV

摘要简述: 本文提出了一种自适应粒子形状建模方法，通过引入邻域对应损失和测地线对应算法，提升粒子配置对局部几何特征的自适应性，同时保持一致性。实验验证了该方法在复杂数据集上的高效性和可扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的粒子形状建模方法在捕捉解剖结构的复杂几何特征时缺乏自适应性，无法根据局部几何特征自动调整粒子配置，影响了形状变异性表征的准确性。

研究方法: 1. 提出了一种新颖的邻域对应损失，以增强粒子配置的自适应性；2. 设计了一种测地线对应算法，通过正则化优化确保测地线邻域一致性。

研究结果: 实验结果表明，该方法在复杂数据集上表现出色，平衡了自适应性与对应性，并在表面表征精度和对应性指标上优于现有方法。

研究结论: 本文提出的自适应粒子形状建模方法显著提升了粒子配置的自适应能力，同时保持了配置的一致性，为解剖结构形状变异性研究提供了更准确的工具。

中文摘要: 粒子形状建模（PSM）是一类通过将粒子（伪标志点）以一致配置放置在形状表面来自动量化解剖队列形状变异性的方法。近期研究引入了隐式径向基函数表示作为自监督信号，以更好地捕捉解剖结构的复杂几何特性。然而，这些方法仍缺乏自适应性——即无法根据每个表面的局部几何特征自动调整粒子配置，而这对于准确表征复杂解剖变异性至关重要。本文提出了两种机制，在保持粒子配置一致性的同时提升表面自适应性：（1）一种新颖的邻域对应损失以实现高自适应性；（2）一种测地线对应算法，通过正则化优化确保测地线邻域一致性。我们在具有挑战性的数据集上评估了方法的有效性和可扩展性，详细分析了自适应性-对应性权衡，并在表面表征精度和对应性指标上与现有方法进行了对比。

</details>


### [70] [Multi-Scale Attention and Gated Shifting for Fine-Grained Event Spotting in Videos](https://arxiv.org/abs/2507.07381)
**中文标题：多尺度注意力与门控移位用于视频中细粒度事件检测**

*Hao Xu,Arbind Agrahari Baniya,Sam Wells,Mohamed Reda Bouadjenek,Richard Dazeley,Sunil Aryal*

主要分类: cs.CV

摘要简述: 本文提出了一种多尺度注意力门控移位模块（MSAGSM），用于增强视频中细粒度事件检测的时空建模能力，并在新提出的乒乓球数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事件检测模型在时空感受野和空间适应性方面存在局限，无法有效捕捉短长期依赖关系和显著区域。本文旨在通过多尺度注意力机制和门控移位模块提升模型性能。

研究方法: 提出MSAGSM模块，结合多尺度时间膨胀和多头空间注意力，增强2D CNN特征提取器的时空建模能力。该模块轻量且易于集成到不同骨干网络中。

研究结果: 在五个事件检测基准测试中，MSAGSM均显著提升性能，且计算开销极小，达到了新的最优水平。

研究结论: MSAGSM通过多尺度时空建模和注意力机制，显著提升了细粒度事件检测的性能，为相关领域提供了高效解决方案。

中文摘要: 精确事件检测（PES）要求从单摄像头视频中实现帧级别的细粒度动作识别。现有PES模型通常采用轻量级时序模块（如门控移位模块GSM或门控移位融合GSF）为2D CNN特征提取器添加时序上下文，但这些模块在时序感受野和空间适应性方面存在局限。本文提出多尺度注意力门控移位模块（MSAGSM），通过多尺度时间膨胀和多头空间注意力增强GSM，高效建模短长期依赖关系并聚焦显著区域。MSAGSM是一种轻量级即插即用模块，可轻松集成到多种2D骨干网络中。为推进该领域发展，本文还引入了首个乒乓球PES基准数据集TTA，包含4800多个精确标注的事件。在五个PES基准上的大量实验表明，MSAGSM能以极小开销持续提升性能，创下新的最优结果。

</details>


### [71] [KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos](https://arxiv.org/abs/2507.07393)
**中文标题：KeyRe-ID：基于关键点的视频行人重识别框架——利用部分感知表征**

*Jinseong Kim,Junghoon Song,Gyeongseon Baek,Byeongjoon Noh*

主要分类: cs.CV

摘要简述: 本文提出了一种基于关键点的视频行人重识别框架KeyRe-ID，通过全局和局部分支结合关键点信息，提升时空表征学习能力，在多个基准测试中达到最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 行人重识别在视频监控中具有重要意义，但现有方法在时空表征学习上仍有不足。本文旨在通过结合人体关键点信息，设计全局和局部分支，提升行人重识别的准确性和鲁棒性。

研究方法: KeyRe-ID框架包含全局分支和局部分支。全局分支通过Transformer进行时间聚合，捕捉整体身份语义；局部分支基于关键点动态分割身体区域，生成细粒度的部分感知特征。

研究结果: 在MARS和iLIDS-VID基准测试中，KeyRe-ID达到91.73% mAP和97.32% Rank-1准确率（MARS），以及96.00% Rank-1和100.0% Rank-5准确率（iLIDS-VID），性能最优。

研究结论: KeyRe-ID通过关键点引导的全局和局部表征学习，显著提升了视频行人重识别的性能，为相关领域提供了新的解决方案。

中文摘要: 我们提出了KeyRe-ID，一种基于关键点的视频行人重识别框架，包含全局和局部分支，利用人体关键点增强时空表征学习。全局分支通过基于Transformer的时间聚合捕捉整体身份语义，而局部分支基于关键点动态分割身体区域，生成细粒度的部分感知特征。在MARS和iLIDS-VID基准测试上的大量实验表明，该方法达到了最优性能，在MARS上实现了91.73% mAP和97.32% Rank-1准确率，在iLIDS-VID上实现了96.00% Rank-1和100.0% Rank-5准确率。代码将在发表后公开于GitHub。

</details>


### [72] [Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer](https://arxiv.org/abs/2507.07394)
**中文标题：行为你的运动：习惯保持的跨类别动物运动迁移**

*Zhimin Zhang,Bi'an Du,Caoyuan Ma,Zheng Wang,Wei Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的习惯保持动物运动迁移框架，通过类别特定习惯编码器和大语言模型（LLM）实现跨类别动物运动迁移，并验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有运动迁移方法主要针对人类运动，忽略了动物特有的行为习惯。本文旨在解决跨类别动物运动迁移中习惯保持的难题。

研究方法: 基于生成框架，引入类别特定习惯编码器和大语言模型（LLM），学习捕捉动物独特习惯的运动先验，并迁移到未观测物种。

研究结果: 实验使用了新提出的DeformingThings4D-skl数据集，验证了模型在跨类别动物运动迁移中的优越性。

研究结论: 本文提出的习惯保持运动迁移框架有效解决了跨类别动物运动迁移中的习惯保留问题，为动画和虚拟现实应用提供了新方法。

中文摘要: 动物运动体现了物种特定的行为习惯，使得跨类别运动迁移成为动画和虚拟现实应用中关键而复杂的任务。现有运动迁移方法主要针对人类运动，强调骨骼对齐（运动重定向）或风格一致性（运动风格迁移），往往忽略了动物独特习惯行为的保留。为填补这一空白，我们提出了一种新型的习惯保持运动迁移框架，用于跨类别动物运动。基于生成框架，我们的模型引入了类别特定习惯编码器的习惯保持模块，使其能够学习捕捉独特习惯特征的运动先验。此外，我们整合了大语言模型（LLM）以促进运动迁移到未观测物种。为评估方法的有效性，我们引入了DeformingThings4D-skl数据集（一种带有骨骼绑定的四足动物数据集），并进行了广泛的实验和定量分析，验证了所提模型的优越性。

</details>


### [73] [Seg-Wild: Interactive Segmentation based on 3D Gaussian Splatting for Unconstrained Image Collections](https://arxiv.org/abs/2507.07395)
**中文标题：Seg-Wild：基于3D高斯泼溅的无约束图像集合交互式分割方法**

*Yongtang Bao,Chengjie Tang,Yuze Wang,Haojie Li*

主要分类: cs.CV

摘要简述: Seg-Wild是一种基于3D高斯泼溅的交互式分割方法，适用于无约束图像集合，能够处理光照不一致和瞬态遮挡问题，并通过多维度特征嵌入和Spiky 3D高斯切割器提升分割质量。


<details>
  <summary>详细信息</summary>
研究动机: 无约束照片集合易于获取但存在光照不一致和瞬态遮挡问题，传统分割方法无法有效处理。因此，提出Seg-Wild以解决这些问题并提升分割和重建质量。

研究方法: Seg-Wild通过为每个3D高斯嵌入多维度特征，计算特征与分割目标的相似性实现交互式分割，并引入Spiky 3D高斯切割器（SGC）平滑异常高斯。通过投影和SAM掩码计算需切割的高斯比例。

研究结果: 实验表明，Seg-Wild在无约束场景中优于现有方法，分割结果和重建质量显著提升。

研究结论: Seg-Wild为无约束图像集合提供了一种高效的分割方法，解决了光照和遮挡问题，具有实际应用潜力。

中文摘要: 从互联网获取的无约束照片集合中重建和分割场景是一项新颖但具有挑战性的任务。无约束照片集合比精心拍摄的照片集合更易获取，但这些图像存在光照不一致和瞬态遮挡问题，增加了分割难度。传统分割方法无法处理瞬态遮挡或准确还原场景光照条件。因此，我们提出Seg-Wild，一种基于3D高斯泼溅的无约束图像集合交互式分割方法，适用于野外场景。我们为每个3D高斯嵌入多维度特征，并通过计算特征嵌入与分割目标的相似性实现3D场景中的交互式分割。此外，我们引入Spiky 3D高斯切割器（SGC）以平滑异常3D高斯。我们将3D高斯投影到2D平面，并使用SAM掩码计算需切割的3D高斯比例。我们还设计了一个基准测试来评估野外场景的分割质量。实验结果表明，与现有方法相比，Seg-Wild实现了更好的分割结果和重建质量。代码将在https://github.com/Sugar0725/Seg-Wild提供。

</details>


### [74] [EscherNet++: Simultaneous Amodal Completion and Scalable View Synthesis through Masked Fine-Tuning and Enhanced Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2507.07410)
**中文标题：EscherNet++：通过掩码微调和增强前馈3D重建实现同时模态补全与可扩展视角合成**

*Xinan Zhang,Muhammad Zubair Irshad,Anthony Yezzi,Yi-Chang Tsai,Zsolt Kira*

主要分类: cs.CV

摘要简述: EscherNet++ 是一种通过掩码微调和增强前馈3D重建的扩散模型，能够同时实现零样本视角合成和模态补全，显著提升了3D重建的速度和效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常采用多阶段复杂流程进行模态补全和视角合成，忽略了跨视角依赖并导致冗余计算。EscherNet++ 旨在通过端到端模型解决这些问题。

研究方法: 采用输入级和特征级掩码微调技术，结合前馈图像到网格模型，实现高效的视角合成和模态补全，无需额外训练。

研究结果: 在遮挡任务中，PSNR 提升3.9，Volume IoU 提升0.28，重建时间减少95%，并在真实场景中表现出良好的泛化能力。

研究结论: EscherNet++ 在较小数据集和批量下实现了最先进的效果，展示了其在快速3D重建和模态补全中的潜力。

中文摘要: 我们提出了EscherNet++，一种通过掩码微调的扩散模型，能够以零样本方式合成物体的新视角并具备模态补全能力。现有方法通常采用多阶段复杂流程，先补全图像缺失部分再进行视角合成，忽略了跨视角依赖并导致冗余存储和计算。相反，我们通过输入级和特征级掩码微调，实现了端到端模型，显著提升了视角合成和模态补全的能力。此外，我们通过实验将该模型与其他前馈图像到网格模型结合，无需额外训练即取得竞争性结果，重建时间减少95%。得益于其可扩展性，该方法进一步加速了3D重建。尽管在较小数据集和批量下微调，我们的方法仍实现了最先进的效果，在10输入设置下，遮挡任务的PSNR提升3.9，Volume IoU提升0.28，并在真实场景的遮挡重建中表现出良好的泛化能力。

</details>


### [75] [EPIC: Efficient Prompt Interaction for Text-Image Classification](https://arxiv.org/abs/2507.07415)
**中文标题：EPIC：面向文本-图像分类的高效提示交互**

*Xinyao Yu,Hao Sun,Zeyu Ling,Ziwei Niu,Zhenjia Bai,Rui Qin,Yen-Wei Chen,Lanfen Lin*

主要分类: cs.CV

摘要简述: 本文提出了一种高效的提示交互策略EPIC，用于文本-图像分类任务，通过中间层的时间提示和基于相似性的模态交互，显著减少了计算资源和可训练参数的需求，并在多个数据集上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，大规模预训练多模态模型（LMMs）在文本-图像分类等任务中取得了显著成功，但其庞大的规模导致微调计算成本高昂。因此，研究高效的提示交互策略以更高效地对齐模态成为关键。

研究方法: EPIC通过在中间层使用时间提示，并结合基于相似性的提示交互，实现了模态间的充分信息交换。该方法仅需基础模型约1%的可训练参数，显著降低了计算资源消耗。

研究结果: 在UPMC-Food101和SNLI-VE数据集上，EPIC表现出卓越性能，同时在MM-IMDB数据集上达到可比效果。其计算资源和参数需求远低于其他微调策略。

研究结论: EPIC作为一种高效的提示交互策略，在减少计算成本和参数需求的同时，显著提升了文本-图像分类任务的性能，为多模态任务的高效处理提供了新思路。

中文摘要: 近年来，大规模预训练多模态模型（LMMs）逐渐兴起，整合了视觉与语言模态，在文本-图像分类等多模态任务中取得了显著成功。然而，LMMs规模的扩大导致微调这些模型的计算成本显著增加。因此，研究基于提示的交互策略以更高效地对齐模态成为关键。在此背景下，我们提出了一种新颖的高效提示交互策略，即面向文本-图像分类的高效提示交互（EPIC）。具体而言，我们在中间层使用时间提示，并通过基于相似性的提示交互整合不同模态，以实现模态间的充分信息交换。采用这一方法，我们的策略在计算资源消耗和可训练参数数量（约为基础模型的1%）上均优于其他微调策略。此外，EPIC在UPMC-Food101和SNLI-VE数据集上表现出卓越性能，同时在MM-IMDB数据集上达到可比效果。

</details>


### [76] [Corvid: Improving Multimodal Large Language Models Towards Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.07424)
**中文标题：Corvid：提升多模态大语言模型的链式思维推理能力**

*Jingjing Jiang,Chao Ma,Xurui Song,Hanwang Zhang,Jun Luo*

主要分类: cs.CV

摘要简述: 本文提出Corvid，一种增强链式思维推理能力的多模态大语言模型，通过混合视觉编码器和精心设计的跨模态对齐连接器（GateMixer）提升性能，并引入高质量多模态CoT指令数据集MCoT-Instruct-287K进行两阶段微调，显著优于同类模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有开源多模态大语言模型在复杂结构化推理任务中表现不足，尤其在需要深度推理的决策和问题解决任务中。本文旨在通过增强链式思维推理能力，提升模型在数学推理和科学问题解决等任务中的表现。

研究方法: Corvid采用混合视觉编码器生成信息丰富的视觉表示，并通过GateMixer连接器实现跨模态对齐。使用高质量多模态CoT指令数据集MCoT-Instruct-287K进行两阶段微调，并引入推理时自验证策略以避免过度或不足推理。

研究结果: 实验表明，Corvid在数学推理和科学问题解决任务中显著优于同类多模态大语言模型，且参数规模相近的模型中表现最优。

研究结论: Corvid通过增强链式思维推理能力和跨模态对齐，显著提升了多模态大语言模型在复杂推理任务中的性能，为未来研究提供了新方向。

中文摘要: 近年来，多模态大语言模型（MLLMs）在感知和理解任务中表现出色，但开源领先模型在复杂结构化推理任务中存在明显不足，尤其是需要深度推理的决策和问题解决任务。本文提出Corvid，一种具备增强链式思维（CoT）推理能力的MLLM。Corvid采用混合视觉编码器生成信息丰富的视觉表示，并通过精心设计的连接器（GateMixer）实现跨模态对齐。为提升CoT推理能力，我们引入MCoT-Instruct-287K，一个从多样化公共推理资源中提炼和标准化而成的高质量多模态CoT指令数据集。基于此数据集，我们采用两阶段CoT格式训练方法逐步增强模型的逐步推理能力。此外，提出一种有效的推理时扩展策略，通过自验证避免过度或不足推理。大量实验表明，Corvid在参数规模相近的模型中表现最优，尤其在数学推理和科学问题解决任务中优势显著。项目页面：https://mm-vl.github.io/corvid。

</details>


### [77] [Towards High-Resolution 3D Anomaly Detection: A Scalable Dataset and Real-Time Framework for Subtle Industrial Defects](https://arxiv.org/abs/2507.07435)
**中文标题：迈向高分辨率3D异常检测：一种可扩展的数据集及实时框架用于工业细微缺陷检测**

*Yuqi Cheng,Yihan Sun,Hui Zhang,Weiming Shen,Yunkang Cao*

主要分类: cs.CV

摘要简述: 本文提出了一种高分辨率3D异常检测方法，包括新数据集MiniShift和高效框架Simple3D，显著提升了工业点云中细微缺陷的检测精度和速度。


<details>
  <summary>详细信息</summary>
研究动机: 工业点云分析中，现有基准数据集多关注低分辨率输入，而高分辨率数据对检测细微异常至关重要。本文旨在填补这一空白，推动高分辨率3D异常检测的实用化。

研究方法: 提出了一种可扩展的流水线生成逼真的细微3D异常，并构建了首个高分辨率数据集MiniShift。同时，设计了Simple3D框架，结合多尺度邻域描述符（MSND）和局部特征空间聚合（LFSA），以低计算成本捕获复杂几何细节。

研究结果: 在MiniShift和现有基准测试中，Simple3D在精度和速度上均超越现有方法，实时推理速度超过20 fps，验证了高分辨率数据和有效特征聚合的重要性。

研究结论: 高分辨率数据和高效特征聚合是提升3D异常检测性能的关键，Simple3D为工业应用提供了实用且高效的解决方案。

中文摘要: 在工业点云分析中，检测细微异常需要高分辨率空间数据，但现有基准多关注低分辨率输入。为解决这一问题，我们提出了一种可扩展的流水线，用于生成逼真的细微3D异常。利用该流水线，我们开发了首个高分辨率3D异常检测数据集MiniShift，包含2,577个点云，每个点云包含500,000个点，异常占比不足1%。此外，我们提出了Simple3D框架，通过集成多尺度邻域描述符（MSND）和局部特征空间聚合（LFSA），以最小计算开销捕获复杂几何细节，实现超过20 fps的实时推理。在MiniShift和现有基准上的广泛实验表明，Simple3D在精度和速度上均优于现有方法，凸显了高分辨率数据和有效特征聚合在推动实用3D异常检测中的关键作用。

</details>


### [78] [A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping](https://arxiv.org/abs/2506.13201)
**中文标题：深度学习在3D洪水制图中的全面综述**

*Wenfeng Jia,Bin Liang,Yuxi Liu,Muhammad Arif Khan,Lihong Zheng*

主要分类: cs.CV

摘要简述: 本文全面综述了深度学习在3D洪水制图中的应用，比较了任务分解和端到端方法，探讨了多种数据源及其作用，并指出了当前挑战与未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 洪水是全球性挑战，传统2D洪水制图技术提供的信息有限，而3D洪水制图结合深度学习能更全面地整合洪水范围和深度，为灾害管理和城市规划提供更有效的解决方案。

研究方法: 论文将深度学习技术分为任务分解和端到端方法，分析了它们在静态和动态洪水特征中的应用，并比较了关键深度学习架构的预测精度和计算效率。

研究结果: 研究总结了深度学习在3D洪水制图中的优势，包括实时洪水预测和长期城市规划等应用，但也指出了数据稀缺、模型可解释性等挑战。

研究结论: 未来研究方向包括改进数据集、优化模型以及与政策结合，以推动更可靠的3D洪水制图技术发展。

中文摘要: 洪水是全球性挑战，因气候变化和城市化加剧，亟需先进的灾害管理解决方案。传统2D洪水制图技术提供的信息有限，而基于深度学习（DL）的3D洪水制图通过整合洪水范围和深度，提供了更强大的能力。本文全面综述了基于深度学习的3D洪水制图，强调其通过整合洪水范围和深度在灾害管理和城市规划中的优势。综述将深度学习技术分为任务分解和端到端方法，适用于静态和动态洪水特征。我们比较了关键深度学习架构，突出了它们在提高预测精度和计算效率中的作用。此外，本文探讨了数字高程模型、卫星图像、降雨和模拟数据等多种数据源及其在3D洪水制图中的作用。应用范围涵盖实时洪水预测到长期城市规划和风险评估。然而，数据稀缺、模型可解释性以及与传统水动力模型的结合等挑战仍然存在。本综述最后提出了未来研究方向，包括改进数据集、优化模型以及洪水管理的政策意义，旨在指导研究人员和实践者利用深度学习技术实现更稳健可靠的3D洪水制图，推动洪水管理策略的改进。

</details>


### [79] [Dual Semantic-Aware Network for Noise Suppressed Ultrasound Video Segmentation](https://arxiv.org/abs/2507.07443)
**中文标题：双重语义感知网络：噪声抑制的超声视频分割**

*Ling Zhou,Runtian Yuan,Yi Liu,Yuejie Zhang,Rui Feng,Shang Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DSANet的双重语义感知网络，旨在通过局部和全局特征的语义交互增强超声视频分割中的噪声鲁棒性，显著提升了分割精度和推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 超声成像因其简单和非侵入性而广泛应用，但其固有的噪声问题对自动化病变或器官分割提出了挑战。本文旨在通过设计一种新型网络框架，解决超声视频分割中的噪声干扰问题。

研究方法: DSANet包含两个核心模块：相邻帧语义感知（AFSA）模块通过通道相似性矩阵指导特征融合，减少随机噪声；局部与全局语义感知（LGSA）模块整合时空特征，实现多级语义表示。

研究结果: 在四个基准数据集上的实验表明，DSANet在分割精度上显著优于现有方法，同时由于避免了像素级依赖，推理速度更快，甚至超过部分基于图像的方法。

研究结论: DSANet通过双重语义感知机制有效抑制了超声视频分割中的噪声干扰，同时兼顾了高精度和高效率，为实际应用提供了有力工具。

中文摘要: 超声成像是一种因其简单性和非侵入性而广泛使用的诊断工具。然而，其固有特性常引入大量噪声，为超声视频序列中的自动化病变或器官分割带来挑战。为解决这些问题，我们提出了双重语义感知网络（DSANet），通过增强局部与全局特征间的语义交互，提升噪声鲁棒性。具体而言，我们设计了相邻帧语义感知（AFSA）模块，通过通道相似性矩阵指导特征融合，有效减少随机噪声，而无需依赖像素级关系。此外，我们提出了局部与全局语义感知（LGSA）模块，将捕获每帧独立空间细节的时序无条件局部特征与融合相邻帧时序上下文的全局条件特征重组整合，实现多级语义表示，显著提升模型对噪声干扰的抵抗力。在四个基准数据集上的广泛实验表明，DSANet在分割精度上大幅领先现有方法。同时，由于模型避免了像素级特征依赖，其推理速度显著高于基于视频的方法，甚至超过部分基于图像的模型。代码可在\href{https://github.com/ZhouL2001/DSANet}{DSANet}获取。

</details>


### [80] [Bluish Veil Detection and Lesion Classification using Custom Deep Learnable Layers with Explainable Artificial Intelligence (XAI)](https://arxiv.org/abs/2507.07453)
**中文标题：基于自定义可学习深度学习层和可解释人工智能（XAI）的蓝白色面纱检测与病变分类**

*M. A. Rasel,Sameem Abdul Kareem,Zhenli Kwan,Shin Shen Yong,Unaizah Obaidellah*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自定义深度学习层和可解释人工智能（XAI）的方法，用于检测皮肤病变中的蓝白色面纱（BWV），以辅助黑色素瘤的早期诊断。该方法在多个数据集上表现优异，准确率高达95%。


<details>
  <summary>详细信息</summary>
研究动机: 黑色素瘤是一种致命的皮肤癌，蓝白色面纱（BWV）是其诊断的关键特征，但目前对BWV的检测研究有限。本研究旨在开发一种高效且可解释的BWV检测方法，以提升黑色素瘤的早期诊断能力。

研究方法: 研究使用未标注的皮肤病变数据集，通过基于颜色阈值的成像算法生成标注数据。设计了一种深度卷积神经网络（DCNN），采用自定义层替代标准激活函数层，并在三个独立及组合的皮肤镜数据集上训练。模型结合XAI算法解释其决策过程。

研究结果: 模型在多个数据集上表现优异：增强PH2数据集测试准确率为85.71%，增强ISIC数据集为95.00%，组合数据集（PH2+ISIC）为95.05%，Derm7pt数据集为90.00%。XAI算法进一步提升了BWV检测的可解释性。

研究结论: 结合自定义DCNN和XAI的方法显著提升了BWV检测性能，优于现有模型，为黑色素瘤的早期诊断提供了可靠工具。

中文摘要: 黑色素瘤是最致命的皮肤癌之一，全球每年导致数千人死亡。蓝白色或蓝白面纱（BWV）是诊断黑色素瘤的关键特征，但目前对皮肤镜图像中BWV检测的研究较少。本研究利用未标注的皮肤病变数据集，通过基于病变区域和颜色调色板的颜色阈值成像算法生成标注数据。设计了一种深度卷积神经网络（DCNN），采用自定义层替代标准激活函数层，并在三个独立及组合的皮肤镜数据集上训练，用于根据BWV存在与否分类皮肤病变。所提出的DCNN在不同数据集上表现优于传统BWV检测模型，测试准确率分别为：增强PH2数据集85.71%，增强ISIC数据集95.00%，组合数据集（PH2+ISIC）95.05%，Derm7pt数据集90.00%。随后应用可解释人工智能（XAI）算法解释DCNN在BWV检测中的决策过程。该方法结合XAI显著提升了皮肤病变中BWV的检测能力，优于现有模型，为黑色素瘤的早期诊断提供了可靠工具。

</details>


### [81] [Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision](https://arxiv.org/abs/2507.07460)
**中文标题：Objectomaly：基于物体感知优化的OoD分割方法——结构一致性与边界精度的结合**

*Jeonghoon Song,Sunghun Kim,Jaegyun Im,Byeongjoon Noh*

主要分类: cs.CV

摘要简述: Objectomaly是一种针对OoD分割的物体感知优化框架，通过结合物体级先验信息，显著提升了边界精度和异常评分一致性，在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于掩码的OoD分割方法存在边界不精确、物体内异常评分不一致以及背景噪声导致的误报问题，亟需一种能够结合物体级先验信息的优化方法。

研究方法: Objectomaly框架分为三个阶段：(1) 使用现有OoD主干网络进行粗粒度异常评分；(2) 利用SAM生成的实例掩码进行物体级评分校准；(3) 通过拉普拉斯滤波和高斯平滑优化边界精度。

研究结果: 在SMIYC AnomalyTrack/ObstacleTrack和RoadAnomaly等基准测试中，Objectomaly取得了最先进的性能，像素级指标（AuPRC高达96.99，FPR$_{95}$低至0.07）和组件级指标（F1$-$score高达83.44）均有显著提升。

研究结论: Objectomaly通过结合物体级先验和边界优化技术，显著提升了OoD分割的精度和鲁棒性，适用于自动驾驶等安全敏感场景。

中文摘要: 在自动驾驶等安全敏感应用中，分布外（OoD）分割至关重要。然而，现有的基于掩码的方法常因边界不精确、物体内异常评分不一致以及背景噪声导致的误报问题而受限。本文提出Objectomaly，一种结合物体级先验的优化框架。该框架包含三个阶段：(1) 使用现有OoD主干网络进行粗粒度异常评分；(2) 利用SAM生成的实例掩码进行物体级评分校准；(3) 通过拉普拉斯滤波和高斯平滑优化边界精度。Objectomaly在SMIYC AnomalyTrack/ObstacleTrack和RoadAnomaly等关键OoD分割基准测试中表现优异，像素级指标（AuPRC高达96.99，FPR$_{95}$低至0.07）和组件级指标（F1$-$score高达83.44）均显著提升。消融实验和真实驾驶视频的定性结果进一步验证了该方法的鲁棒性和泛化能力。代码将在论文发表后开源。

</details>


### [82] [Degradation-Agnostic Statistical Facial Feature Transformation for Blind Face Restoration in Adverse Weather Conditions](https://arxiv.org/abs/2507.07464)
**中文标题：恶劣天气条件下盲人脸恢复的退化无关统计面部特征变换**

*Chang-Hwan Son*

主要分类: cs.CV

摘要简述: 本文提出了一种基于GAN的盲人脸恢复框架，通过局部统计面部特征变换（SFFT）和退化无关特征嵌入（DAFE）模块，显著提升了恶劣天气条件下的人脸恢复效果，优于现有GAN和扩散模型方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着智能监控系统在户外环境中的广泛应用，恶劣天气条件下的图像质量下降导致人脸识别精度降低。现有的人脸图像恢复（FIR）模型缺乏专门处理天气退化问题的模块，导致面部纹理和结构失真。

研究方法: 提出了一种新的GAN框架，包含局部统计面部特征变换（SFFT）和退化无关特征嵌入（DAFE）模块。SFFT通过对齐低质量（LQ）与高质量（HQ）面部区域的局部统计分布，提升结构和颜色保真度；DAFE通过对齐LQ和HQ编码器表示，实现恶劣天气下的鲁棒特征提取。

研究结果: 实验表明，该方法在抑制纹理失真和准确重建面部结构方面优于现有基于GAN和扩散模型的FIR方法，显著提升了恶劣天气条件下的恢复效果。

研究结论: SFFT和DAFE模块在恶劣天气场景下有效提升了人脸恢复的结构保真度和感知质量，为智能监控系统提供了更可靠的解决方案。

中文摘要: 随着智能监控系统在户外环境中的广泛应用，针对恶劣天气条件优化的人脸识别系统需求日益增长。恶劣天气显著降低图像质量，进而影响识别精度。尽管基于生成对抗网络（GAN）和扩散模型的人脸图像恢复（FIR）方法有所进展，但由于缺乏专门处理天气退化的模块，其性能仍受限，导致面部纹理和结构失真。为解决这一问题，我们提出了一种新的基于GAN的盲FIR框架，包含局部统计面部特征变换（SFFT）和退化无关特征嵌入（DAFE）两个关键组件。SFFT模块通过对齐低质量（LQ）与高质量（HQ）面部区域的局部统计分布，提升结构和颜色保真度；DAFE模块通过对齐LQ和HQ编码器表示，实现恶劣天气下的鲁棒特征提取，使恢复过程适应严重天气退化。实验结果表明，所提出的退化无关SFFT模型在抑制纹理失真和准确重建面部结构方面优于现有基于GAN和扩散模型的FIR方法。此外，SFFT和DAFE模块在恶劣天气场景下均被实证有效提升了人脸恢复的结构保真度和感知质量。

</details>


### [83] [Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking](https://arxiv.org/abs/2507.07483)
**中文标题：时序不可学习样本：防止个人视频数据被未经授权用于目标跟踪**

*Qiangqiang Wu,Yi Yu,Chenqi Kong,Ziquan Liu,Jia Wan,Haoliang Li,Alex C. Kot,Antoni B. Chan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“时序不可学习样本（TUEs）”的新方法，旨在防止个人视频数据被未经授权用于视觉目标跟踪（VOT）模型的训练。通过生成不可学习的噪声，TUEs能够破坏跟踪器的学习过程，从而保护视频数据的隐私。实验表明，该方法在隐私保护和跨模型通用性方面表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 随着社交媒体的兴起，大量用户上传的视频（如YouTube）被用作视觉目标跟踪（VOT）的训练数据，但视频数据的隐私问题却被忽视。许多私人视频未经授权就被用于商业模型的训练。现有方法主要针对图像任务，直接应用于视频时效率低、效果有限且泛化能力差。因此，本文旨在解决视频数据隐私保护的问题。

研究方法: 本文提出了一种生成时序不可学习样本（TUEs）的框架，通过高效计算适用于大规模视频数据集。TUEs通过在视频中注入不可学习的噪声，使跟踪器依赖噪声进行时序匹配，而忽略原始数据结构。此外，还引入了时序对比损失，进一步破坏跟踪器的学习能力。

研究结果: 实验表明，TUEs在视频数据隐私保护方面达到了最先进的性能，并表现出强大的跨模型、跨数据集和跨时序匹配任务的通用性。

研究结论: 本文提出的TUEs方法有效解决了视频数据隐私保护的问题，为未来研究提供了新的方向。

中文摘要: 随着社交媒体的兴起，大量用户上传的视频（如YouTube）被用作视觉目标跟踪（VOT）的训练数据。然而，VOT社区在很大程度上忽视了视频数据的隐私问题，许多私人视频未经授权就被用于商业模型的训练。为了缓解这些问题，本文首次研究了如何防止个人视频数据被未经授权用于深度跟踪器的训练。现有的防止数据未经授权使用的方法主要针对基于图像的任务（如图像分类），直接应用于视频时存在效率低、效果有限和泛化能力差等问题。为了解决这些问题，我们提出了一种生成时序不可学习样本（TUEs）的新框架，其高效计算使其适用于大规模视频数据集。使用TUEs训练的跟踪器严重依赖不可学习的噪声进行时序匹配，从而忽略了原始数据结构，确保了训练视频数据的隐私。为了增强TUEs的效果，我们引入了时序对比损失，进一步破坏了现有跟踪器在使用TUEs训练时的学习能力。大量实验表明，我们的方法在视频数据隐私保护方面达到了最先进的性能，并在VOT模型、数据集和时序匹配任务中表现出强大的通用性。

</details>


### [84] [Driving by Hybrid Navigation: An Online HD-SD Map Association Framework and Benchmark for Autonomous Vehicles](https://arxiv.org/abs/2507.07487)
**中文标题：混合导航驱动：自动驾驶车辆的在线高清-标准地图关联框架与基准**

*Jiaxu Wan,Xu Wang,Mengwei Xie,Xinyuan Chang,Xinran Liu,Zheng Pan,Mu Xu,Ding Yuan*

主要分类: cs.CV

摘要简述: 本文提出了首个面向混合导航的在线地图关联基准OMA，并提出了基于路径感知和空间注意力机制的Map Association Transformer框架，以提升自动驾驶车辆的规划能力。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶车辆依赖全球标准地图（SD）进行道路级路径规划，同时依赖在线高清地图（HD）进行车道级导航。然而，现有研究多集中于在线高清地图的构建，忽略了SD与HD地图的关联问题，导致实际应用中难以有效利用在线高清地图。

研究方法: 本文提出了OMA基准，包含48万条道路和26万条车道路径，并提供了评估模型性能的指标。同时，提出了Map Association Transformer框架，通过路径感知注意力和空间注意力机制，实现对几何和拓扑对应关系的理解。

研究结果: OMA基准和Map Association Transformer框架显著提升了自动驾驶车辆在混合导航中的规划能力，为相关研究提供了数据和方法的支持。

研究结论: 本文填补了混合导航中在线地图关联的研究空白，为自动驾驶车辆的导航能力提供了新的解决方案和基准。

中文摘要: 自动驾驶车辆依赖全球标准地图（SD）进行道路级路径规划，同时依赖在线高清地图（HD）进行车道级导航。然而，现有研究多集中于在线高清地图的构建，忽略了SD与HD地图的关联问题，导致实际应用中难以有效利用在线高清地图。针对自动驾驶车辆导航能力的不足，我们提出了首个面向混合导航的在线地图关联基准OMA，以增强自动驾驶车辆的规划能力。基于现有数据集，OMA包含48万条道路和26万条车道路径，并提供了相应的评估指标。此外，我们提出了一种名为Map Association Transformer的新框架作为基线方法，通过路径感知注意力和空间注意力机制，实现对几何和拓扑对应关系的理解。代码和数据集可在https://github.com/WallelWan/OMA-MAT获取。

</details>


### [85] [Divergence Minimization Preference Optimization for Diffusion Model Alignment](https://arxiv.org/abs/2507.07510)
**中文标题：扩散模型对齐的散度最小化偏好优化**

*Binxu Li,Minkai Xu,Meihua Dang,Stefano Ermon*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DMPO的新方法，通过最小化反向KL散度来优化扩散模型的对齐性能，实验证明其在人类评估和自动指标上均优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成逼真图像方面取得了显著成功，但现有偏好优化方法通常陷入次优均值寻求优化。本文旨在从散度最小化角度改进扩散模型的对齐性能。

研究方法: 提出Divergence Minimization Preference Optimization (DMPO)，通过最小化反向KL散度对齐扩散模型，理论上与原始强化学习具有相同的优化方向。

研究结果: 实验表明，DMPO在所有评估数据集上的PickScore中至少优于现有扩散对齐基线64.6%，在人类评估和自动指标上均表现出色。

研究结论: DMPO为扩散模型的对齐提供了一种稳健且优雅的途径，将理论原则与实际性能紧密结合。

中文摘要: 扩散模型在从文本提示生成逼真和多样化图像方面取得了显著成功。受语言模型最新进展的启发，人们越来越关注通过对齐人类偏好进一步改进模型。然而，我们从散度最小化的角度研究对齐问题，发现现有偏好优化方法通常陷入次优均值寻求优化。本文提出Divergence Minimization Preference Optimization (DMPO)，一种通过最小化反向KL散度对齐扩散模型的新颖且原则性方法，其渐近优化方向与原始强化学习相同。我们通过严格分析证明DMPO的有效性，并通过全面实验验证其在人类评估和自动指标上的优势。实验结果表明，经过DMPO微调的扩散模型在所有评估数据集上的PickScore中至少优于现有扩散对齐基线64.6%，展示了该方法在生成行为与期望输出对齐方面的优越性。总体而言，DMPO为偏好对齐提供了一条稳健且优雅的途径，将理论原则与扩散模型的实际性能紧密结合。

</details>


### [86] [GGMotion: Group Graph Dynamics-Kinematics Networks for Human Motion Prediction](https://arxiv.org/abs/2507.07515)
**中文标题：GGMotion：基于分组图动力学-运动学网络的人体运动预测**

*Shuaijin Wan,Huaijiang Sun*

主要分类: cs.CV

摘要简述: GGMotion提出了一种基于分组图动力学-运动学网络的方法，通过建模人体拓扑结构和物理依赖关系，显著提升了运动预测的准确性和物理合理性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常将人体姿态表示为抽象图结构，忽略了关节间的物理依赖关系，导致学习困难且易生成不真实的运动。GGMotion旨在通过分组建模更好地利用动力学和运动学先验。

研究方法: GGMotion采用分组图网络，提出了一种新颖的径向场以捕捉时空依赖关系，并通过组内和组间交互模块捕获多尺度关节依赖。结合等变多层感知机（MLP），通过并行化的动力学-运动学传播更新关节位置特征。

研究结果: 在Human3.6M、CMU-Mocap和3DPW三个标准基准测试中，GGMotion表现出色，显著提升了短期运动预测的性能。

研究结论: GGMotion通过分组建模和物理约束的引入，有效提升了运动预测的准确性和物理合理性，为未来研究提供了新思路。

中文摘要: 人体运动是三维空间中受复杂动力学和运动学约束的连续物理过程。现有方法通常将人体姿态表示为抽象图结构，忽略了关节间的内在物理依赖关系，增加了学习难度并容易生成不真实的运动。本文提出GGMotion，一种分组图动力学-运动学网络，通过分组建模人体拓扑结构以更好地利用动力学和运动学先验。为保持三维空间中的几何等变性，我们提出了一种新颖的径向场，通过空间和时间边聚合关节特征以捕捉更全面的时空依赖关系。组内和组间交互模块用于捕获不同尺度的关节依赖关系。结合等变多层感知机（MLP），通过并行化的动力学-运动学传播更新每组中的关节位置特征，以提高物理合理性。同时，我们引入了一种辅助损失以监督训练过程中的运动先验。在Human3.6M、CMU-Mocap和3DPW三个标准基准测试上的大量实验证明了我们方法的有效性和优越性，在短期运动预测中取得了显著的性能提升。代码发布于https://github.com/inkcat520/GGMotion.git。

</details>


### [87] [MUVOD: A Novel Multi-view Video Object Segmentation Dataset and A Benchmark for 3D Segmentation](https://arxiv.org/abs/2507.07519)
**中文标题：MUVOD：一种新型多视角视频对象分割数据集及3D分割基准**

*Bangning Wei,Joshua Maraval,Meriem Outtas,Kidiyo Kpalma,Nicolas Ramin,Lu Zhang*

主要分类: cs.CV

摘要简述: 本文提出了MUVOD数据集，一个用于多视角视频对象分割的新数据集，旨在填补动态场景4D分割领域的数据空白，并提供基准评估方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于NeRF和3D高斯泼溅的方法在静态场景3D对象分割中表现良好，但动态场景的4D分割因缺乏大规模标注数据集而研究不足。MUVOD旨在解决这一问题。

研究方法: MUVOD数据集包含17个场景，涵盖室内外活动，提供7830张RGB图像及其4D运动分割掩码。数据集包含459个实例和73个类别，并提出了评估指标和基线分割方法。

研究结果: MUVOD数据集为多视角视频分割提供了基准，并提出了一个3D对象分割任务的子集，包含50个不同场景下的对象，用于全面分析现有方法。

研究结论: MUVOD填补了动态场景4D分割的数据空白，为未来研究提供了重要资源，并推动了多视角视频和3D分割技术的发展。

中文摘要: 基于神经辐射场（NeRF）和3D高斯泼溅（3D GS）的方法在静态场景的3D对象分割中逐渐流行，并在多种3D场景理解和编辑任务中表现出色。然而，由于缺乏足够大规模且精确标注的多视角视频数据集，动态场景的4D对象分割仍是一个未充分探索的领域。本文提出了MUVOD，一个新的多视角视频数据集，用于训练和评估重建真实场景中的对象分割。选定的17个场景描述了各种室内外活动，数据来源于不同类型的相机设备。每个场景包含最少9个视角，最多46个视角。我们提供了7830张RGB图像（每段视频30帧）及其对应的4D运动分割掩码，使得场景中的任何感兴趣对象可以在时间帧或不同视角中被跟踪。该数据集包含73个类别的459个实例，旨在作为多视角视频分割方法评估的基础基准。我们还提出了一个评估指标和基线分割方法，以鼓励和评估这一领域的发展。此外，我们提出了一个新的3D对象分割任务基准，使用从MUVOD数据集中选出的标注多视角图像子集。该子集包含不同场景下的50个对象，为现有3D对象分割方法提供了更全面的分析。MUVOD数据集可在https://volumetric-repository.labs.b-com.com/#/muvod获取。

</details>


### [88] [Spline Deformation Field](https://arxiv.org/abs/2507.07521)
**中文标题：样条变形场**

*Mingyang Song,Yang Zhang,Marko Mihajlovic,Siyu Tang,Markus Gross,Tunç Ozan Aydın*

主要分类: cs.CV

摘要简述: 本文提出了一种基于样条的轨迹表示方法，通过显式控制节点数量来保持空间连贯性，并引入低秩时变空间编码，显著提升了稀疏输入下的时间插值性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法中，隐式变形场因神经网络固有偏差可能导致空间连贯性不足，而显式方法依赖启发式节点初始化。此外，隐式表示在稀疏时间信号插值方面的潜力未被充分探索。

研究方法: 采用样条轨迹表示，节点数量显式控制自由度，支持高效解析速度推导。提出低秩时变空间编码，替代传统耦合时空技术，以建模节点在时空域的特性。

研究结果: 该方法在稀疏输入下实现优越的时间插值性能，动态场景重建质量与前沿方法相当，同时无需依赖线性混合蒙皮或尽可能刚性约束即可提升运动连贯性。

研究结论: 样条变形场方法通过显式自由度和低秩编码，有效解决了时空连贯性问题，为稀疏信号插值和动态场景重建提供了高效解决方案。

中文摘要: 密集点的轨迹建模通常采用隐式变形场，即通过神经网络将坐标映射以关联规范空间位置与时间偏移。然而，神经网络的固有偏差可能在不适定场景下阻碍空间连贯性。现有方法或专注于增强变形场的编码策略（常导致模型不透明且缺乏直观性），或采用显式技术（如线性混合蒙皮），依赖启发式节点初始化。此外，隐式表示在稀疏时间信号插值方面的潜力尚未充分挖掘。为解决这些问题，我们提出一种基于样条的轨迹表示方法，其节点数量显式决定自由度。该方法支持高效解析速度推导，保持空间连贯性和加速度，同时抑制时间波动。为建模节点在时空域的特性，我们引入一种新颖的低秩时变空间编码，替代传统的耦合时空技术。实验表明，该方法在稀疏输入下拟合连续场的时间插值性能优越，动态场景重建质量与前沿方法相当，且无需依赖线性混合蒙皮或尽可能刚性约束即可提升运动连贯性。

</details>


### [89] [MAPEX: Modality-Aware Pruning of Experts for Remote Sensing Foundation Models](https://arxiv.org/abs/2507.07527)
**中文标题：MAPEX：面向遥感基础模型的模态感知专家剪枝**

*Joelle Hanna,Linus Scheibenreif,Damian Borth*

主要分类: cs.CV

摘要简述: MAPEX是一种基于多模态专家混合的遥感基础模型，通过模态感知剪枝技术，仅保留任务所需的专家，从而简化微调和部署，并在实验中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有遥感基础模型通常针对特定模态（如光学RGB或多光谱数据）进行预训练，导致与应用模态不匹配，且模型规模大、微调成本高。MAPEX旨在解决这一问题。

研究方法: MAPEX基于多模态遥感数据预训练，采用模态条件令牌路由机制激活模态特定专家，并通过模态感知剪枝技术仅保留任务相关专家。

研究结果: MAPEX在多种遥感数据集上表现优异，优于全监督训练和现有遥感基础模型。

研究结论: MAPEX通过模态感知剪枝技术实现了高效的任务特定模型，简化了微调和部署过程，为遥感任务提供了灵活且高性能的解决方案。

中文摘要: 遥感数据常用于洪水测绘、野火检测或土地利用研究等任务。科学家们通常为每项任务精心选择适当的模态或利用专用仪器数据。近期关于遥感基础模型的研究在大规模遥感数据上预训练计算机视觉模型。这些大规模模型往往专注于特定模态，如光学RGB或多光谱数据。对于许多重要应用，这导致应用模态与预训练数据不匹配。此外，基础模型的庞大规模使其在通常较小的任务数据集上微调成本高昂且困难。我们通过MAPEX解决这一问题，这是一种基于多模态专家混合的遥感基础模型。MAPEX在多模态遥感数据上预训练，采用新颖的模态条件令牌路由机制激活模态特定专家。为将模型应用于特定任务，我们提出模态感知剪枝技术，仅保留任务模态相关的专家。这产生了高效的模态特定模型，同时简化了目标模态的微调和部署。我们在多种遥感数据集上实验验证了MAPEX，其表现优于全监督训练和最先进的遥感基础模型。代码发布于https://github.com/HSG-AIML/MAPEX。

</details>


### [90] [Beyond the Linear Separability Ceiling](https://arxiv.org/abs/2507.07574)
**中文标题：超越线性可分性天花板**

*Enrico Vompa,Tanel Tammet,Mohit Vaishnav*

主要分类: cs.CV

摘要简述: 当前视觉-语言模型（VLMs）在抽象推理任务中受限于视觉嵌入的线性可分性。本文提出线性可分性天花板（LSC）概念，发现这一瓶颈源于语言模型的推理路径问题而非感知能力不足，并通过任务依赖性干预证明了其可解决性。


<details>
  <summary>详细信息</summary>
研究动机: 研究视觉-语言模型在抽象推理任务中的性能瓶颈，探索其线性可分性限制的根本原因，并提出解决方案。

研究方法: 引入线性可分性天花板（LSC）作为评估指标，通过后置调优（postfix tuning）方法激活模型潜在的推理路径，并针对不同任务需求进行干预。

研究结果: 发现线性可分性瓶颈普遍存在，且可通过任务依赖性干预解决；复杂关系推理需调整核心模型权重，而语义概念任务仅需激活现有路径。

研究结论: 研究表明，视觉-语言模型的鲁棒推理需针对性对齐而非单纯改进表示学习，为模型分析提供了新视角。

中文摘要: 大多数先进的视觉-语言模型（VLMs）在抽象推理任务中似乎受限于其视觉嵌入的线性可分性。本文通过引入线性可分性天花板（LSC）——即简单线性分类器在VLM视觉嵌入上的性能——研究了这一“线性推理瓶颈”。我们发现这一瓶颈普遍存在，且并非源于感知能力不足，而是语言模型推理路径的失败。我们证明这是一个可解决的校准问题，但所需干预因任务而异：语义概念任务仅需激活现有路径，而复杂关系推理需调整核心模型权重。通过后置调优作为方法控制，我们发现VLMs中存在强大但休眠的推理路径。然而，对于需要更深层次适应的复杂关系任务，明确改进表示质量会导致模型在新提示格式下失败，尽管其嵌入仍保持良好分离。最终，本研究为VLM分析提供了新视角，表明鲁棒推理是针对性对齐的问题，而非简单的表示学习改进。

</details>


### [91] [Diffusion-Guided Knowledge Distillation for Weakly-Supervised Low-Light Semantic Segmentation](https://arxiv.org/abs/2507.07578)
**中文标题：扩散引导知识蒸馏用于弱监督低光语义分割**

*Chunyan Wang,Dong Zhang,Jinhui Tang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DGKD-WLSS的新框架，通过结合扩散引导的知识蒸馏和深度引导的特征融合，解决了弱监督低光语义分割中图像质量差和弱监督限制的问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在光照充足场景下表现良好，但在低光环境中因图像质量下降（如低对比度、噪声和颜色失真）和弱监督的固有限制，导致性能显著下降。这些问题使得类别激活图和伪标签不可靠，影响模型学习判别性特征的能力。

研究方法: DGKD-WLSS结合了扩散引导的知识蒸馏（DGKD）和深度引导的特征融合（DGF2）。DGKD通过扩散去噪和知识蒸馏对齐正常光和低光特征，DGF2则利用深度图作为光照不变的几何先验，增强结构特征学习。

研究结果: 实验表明，DGKD-WLSS在弱监督低光语义分割任务中达到了最先进的性能，显著优于现有方法。

研究结论: DGKD-WLSS通过扩散引导和深度引导的协同作用，有效解决了低光环境下的弱监督语义分割问题，为相关领域提供了新的解决方案。

中文摘要: 弱监督语义分割旨在利用弱标注为每个像素分配类别标签，显著降低人工标注成本。尽管现有方法在光照充足场景中取得了显著进展，但在低光环境中，由于图像质量严重下降（如低对比度、噪声和颜色失真）和弱监督的固有限制，其性能显著下降。这些因素共同导致不可靠的类别激活图和语义模糊的伪标签，最终影响模型学习判别性特征的能力。为解决这些问题，我们提出了扩散引导知识蒸馏用于弱监督低光语义分割（DGKD-WLSS），这是一种新颖的框架，将扩散引导知识蒸馏（DGKD）与深度引导特征融合（DGF2）协同结合。DGKD通过基于扩散的去噪和知识蒸馏对齐正常光和低光特征，而DGF2则利用深度图作为光照不变的几何先验，增强结构特征学习。大量实验证明了DGKD-WLSS的有效性，其在弱监督低光语义分割任务中达到了最先进的性能。源代码已发布于：https://github.com/ChunyanWang1/DGKD-WLSS。

</details>


### [92] [NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning](https://arxiv.org/abs/2507.07579)
**中文标题：NexViTAD：基于视觉基础模型和多任务学习的少样本无监督跨域缺陷检测**

*Tianwei Mu,Feiyu Duan,Bo Zhou,Dan Xue,Manhong Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉基础模型的少样本跨域异常检测框架NexViTAD，通过共享子空间投影和多任务学习模块，有效解决工业异常检测中的域偏移问题，并在MVTec AD数据集上取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 工业异常检测中，跨域数据分布差异（域偏移）导致模型泛化能力不足。本文旨在通过结合视觉基础模型和多任务学习，提升模型在少样本条件下的跨域检测能力。

研究方法: 1. 使用分层适配器模块融合Hiera和DINO-v2预训练模型的互补特征；2. 通过共享子空间投影策略实现跨域知识迁移；3. 设计多任务解码器架构支持多源域处理；4. 基于Sinkhorn-K-means聚类和自适应阈值处理实现像素级异常评分。

研究结果: 在MVTec AD数据集上，NexViTAD在目标域中取得了AUC 97.5%、AP 70.4%和PRO 95.2%的最优性能，显著超越其他模型。

研究结论: NexViTAD通过创新的特征融合和跨域学习机制，显著提升了少样本条件下的跨域异常检测性能，为工业缺陷检测提供了新的解决方案。

中文摘要: 本文提出了一种基于视觉基础模型的少样本跨域异常检测框架NexViTAD，通过创新的共享子空间投影机制和多任务学习模块，有效解决了工业异常检测中的域偏移问题。主要创新包括：（1）分层适配器模块自适应融合Hiera和DINO-v2预训练模型的互补特征，构建更鲁棒的特征表示；（2）共享子空间投影策略通过瓶颈维度约束和跳跃连接机制实现有效的跨域知识迁移；（3）多任务解码器架构支持同时处理多个源域，显著提升模型泛化能力；（4）基于Sinkhorn-K-means聚类的异常评分方法，结合高斯滤波和自适应阈值处理，实现精确的像素级检测。在MVTec AD数据集上的评估表明，NexViTAD在目标域中取得了AUC 97.5%、AP 70.4%和PRO 95.2%的最优性能，超越了其他近期模型，标志着跨域缺陷检测领域的重大突破。

</details>


### [93] [HOTA: Hierarchical Overlap-Tiling Aggregation for Large-Area 3D Flood Mapping](https://arxiv.org/abs/2507.07585)
**中文标题：HOTA：用于大范围3D洪水测绘的分层重叠分块聚合方法**

*Wenfeng Jia,Bin Liang,Yuxi Lu,Attavit Wilaiwongsakul,Muhammad Arif Khan,Lihong Zheng*

主要分类: cs.CV

摘要简述: 本文提出HOTA方法，通过分层重叠分块聚合策略，结合SegFormer和深度估计模块，实现高效的大范围3D洪水测绘，显著提升洪水边界和深度估计的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 洪水是频繁发生的自然灾害，对社会和经济造成重大损失。现有洪水测绘产品往往在空间细节和覆盖范围之间权衡，或完全忽略洪水深度。本文旨在填补这一空白，提供一种快速、准确的大范围3D洪水测绘方法。

研究方法: HOTA是一种即插即用的多尺度推理策略，结合SegFormer模型和双约束深度估计模块。通过在不同大小的重叠分块上应用多光谱Sentinel-2图像，HOTA在不改变网络权重或重新训练的情况下，捕捉局部特征和公里级淹没范围。深度估计模块基于数字高程模型（DEM）差分方法，通过强制洪水边界深度为零和洪水体积接近恒定来优化2D掩模并估计洪水深度。

研究结果: 在2021年3月澳大利亚Kempsey洪水的案例研究中，HOTA结合SegFormer将IoU从73%（U-Net基线）提升至84%，3D表面的平均绝对边界误差小于0.5米。

研究结论: HOTA能够生成准确的大范围3D洪水地图，适用于快速灾害响应，显著提升了洪水测绘的精度和实用性。

中文摘要: 洪水是最频繁的自然灾害之一，对社会和经济造成重大损失。及时获取大范围的洪水范围和深度信息对灾害响应至关重要；然而，现有产品往往在空间细节和覆盖范围之间权衡，或完全忽略洪水深度。为填补这一空白，本文提出HOTA：分层重叠分块聚合，一种即插即用的多尺度推理策略。结合SegFormer和双约束深度估计模块，该方法形成了一套完整的3D洪水测绘流程。HOTA仅在推理阶段对不同大小的重叠分块应用多光谱Sentinel-2图像，使SegFormer模型能够在不改变网络权重或重新训练的情况下捕捉局部特征和公里级淹没范围。随后的深度模块基于数字高程模型（DEM）差分方法，通过强制（i）洪水边界深度为零和（ii）洪水体积相对于DEM接近恒定来优化2D掩模并估计洪水深度。以2021年3月澳大利亚Kempsey洪水为例，HOTA结合SegFormer将IoU从73%（U-Net基线）提升至84%，3D表面的平均绝对边界误差小于0.5米。结果表明，HOTA能够生成适用于快速灾害响应的准确大范围3D洪水地图。

</details>


### [94] [Stable-Hair v2: Real-World Hair Transfer via Multiple-View Diffusion Model](https://arxiv.org/abs/2507.07591)
**中文标题：Stable-Hair v2：基于多视角扩散模型的真实世界头发转移**

*Kuiyuan Sun,Yuxuan Zhang,Jichao Zhang,Jiaming Liu,Wei Wang,Niculae Sebe,Yao Zhao*

主要分类: cs.CV

摘要简述: 本文提出Stable-Hair v2，一种基于扩散模型的多视角头发转移框架，首次利用多视角扩散模型实现高质量、视角一致的头发转移。


<details>
  <summary>详细信息</summary>
研究动机: 当前扩散模型在捕捉复杂发型方面表现优异，但在生成多视角一致的高质量输出方面仍有不足，尤其是在数字人类和虚拟化身等实际应用中。

研究方法: 提出一种多视角训练数据生成流程，包括基于扩散的秃头转换器、数据增强修复模型和面部微调的多视角扩散模型。模型整合极坐标嵌入和时序注意力层，确保视角间的平滑过渡，并采用多阶段训练策略优化模型。

研究结果: 实验表明，该方法能准确地将详细且真实的发型转移到目标对象，并在多视角下实现无缝一致的效果，显著优于现有方法。

研究结论: Stable-Hair v2在多视角头发转移领域树立了新标杆，为实际应用提供了高质量解决方案。

中文摘要: 尽管基于扩散的方法在捕捉多样化和复杂发型方面表现出色，但其生成多视角一致的高质量输出的能力——对数字人类和虚拟化身等实际应用至关重要——仍未得到充分探索。本文提出Stable-Hair v2，一种新颖的基于扩散的多视角头发转移框架。据我们所知，这是首个利用多视角扩散模型实现跨多视角的鲁棒、高保真和视角一致的头发转移的工作。我们引入了一个全面的多视角训练数据生成流程，包括基于扩散的秃头转换器、数据增强修复模型和面部微调的多视角扩散模型，以生成高质量的三元组数据（秃头图像、参考发型和视角对齐的源-秃头对）。我们的多视角头发转移模型整合了极坐标嵌入用于姿态条件化，以及时序注意力层以确保视角间的平滑过渡。为优化该模型，我们设计了一种新颖的多阶段训练策略，包括姿态可控的潜在IdentityNet训练、头发提取器训练和时序注意力训练。大量实验表明，我们的方法能够准确地将详细且真实的发型转移到源对象，并在多视角下实现无缝一致的效果，显著优于现有方法，为多视角头发转移树立了新标杆。代码公开于https://github.com/sunkymepro/StableHairV2。

</details>


### [95] [HiM2SAM: Enhancing SAM2 with Hierarchical Motion Estimation and Memory Optimization towards Long-term Tracking](https://arxiv.org/abs/2507.07603)
**中文标题：HiM2SAM：通过分层运动估计和内存优化增强SAM2以实现长期跟踪**

*Ruixiang Chen,Guolei Sun,Yawei Li,Jie Qin,Luca Benini*

主要分类: cs.CV

摘要简述: 本文提出HiM2SAM方法，通过分层运动估计和内存优化增强SAM2框架，显著提升长期目标跟踪性能，无需额外训练。


<details>
  <summary>详细信息</summary>
研究动机: 针对视频目标跟踪中的遮挡、背景干扰和目标重现等挑战，本文旨在改进SAM2框架，提升其长期跟踪能力。

研究方法: 引入分层运动估计策略，结合轻量级线性预测和选择性非线性优化；优化内存银行，区分长短期记忆帧，以应对长期遮挡和外观变化。

研究结果: 实验表明，该方法在LaSOT和LaSOText数据集上表现优异，大模型AUC相对提升9.6%和7.2%，小模型增益更显著。

研究结论: HiM2SAM通过无训练、低开销的改进，显著提升了长期跟踪性能，为视频目标跟踪提供了高效解决方案。

中文摘要: 本文针对视频目标跟踪任务中的遮挡、背景干扰和目标重现等挑战，提出了对SAM2框架的改进。我们引入了一种分层运动估计策略，结合轻量级线性预测和选择性非线性优化，无需额外训练即可提升跟踪精度。此外，通过区分长短期记忆帧优化内存银行，增强了长期遮挡和外观变化下的跟踪可靠性。实验结果表明，该方法在不同模型规模下均表现一致提升。在大模型上，我们的方法在LaSOT和LaSOText数据集上实现了9.6%和7.2%的AUC相对提升，且在小模型上增益更为显著，凸显了这种无训练、低开销改进对提升长期跟踪性能的有效性。代码发布于https://github.com/LouisFinner/HiM2SAM。

</details>


### [96] [LOSC: LiDAR Open-voc Segmentation Consolidator](https://arxiv.org/abs/2507.07605)
**中文标题：LOSC：激光雷达开放词汇分割整合器**

*Nermin Samet,Gilles Puy,Renaud Marlet*

主要分类: cs.CV

摘要简述: LOSC是一种利用基于图像的视觉语言模型（VLMs）进行激光雷达开放词汇分割的方法，通过标签整合提升3D点云的语义分割性能，显著优于现有零样本开放词汇分割方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统的基于图像的语义分割方法在将语义信息反向投影到3D点云时，会产生噪声和稀疏的标签。本文旨在通过标签整合提升3D点云的语义分割性能，实现时空一致性和对图像级增强的鲁棒性。

研究方法: LOSC通过整合图像语义标签，优化3D点云的标签质量，并基于这些优化后的标签训练3D网络。该方法结合了时空一致性和图像级增强的鲁棒性。

研究结果: LOSC在nuScenes和SemanticKITTI数据集上的零样本开放词汇语义分割和全景分割任务中，显著优于现有最优方法（SOTA）。

研究结论: LOSC通过简单的标签整合方法，显著提升了3D点云的开放词汇分割性能，为自动驾驶场景中的语义分割提供了高效解决方案。

中文摘要: 我们研究了基于图像的视觉语言模型（VLMs）在自动驾驶场景中用于激光雷达扫描的开放词汇分割。传统方法中，图像的语义信息可以反向投影到3D点云上，但生成的点标签存在噪声和稀疏性问题。我们通过整合这些标签，实现了时空一致性和对图像级增强的鲁棒性，并基于这些优化后的标签训练了一个3D网络。这种名为LOSC的简单方法，在nuScenes和SemanticKITTI数据集上的零样本开放词汇语义分割和全景分割任务中，显著优于现有最优方法（SOTA）。

</details>


### [97] [SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs](https://arxiv.org/abs/2507.07610)
**中文标题：SpatialViz-Bench：为多模态大语言模型自动生成的空间可视化推理任务**

*Siting Wang,Luoyang Sun,Cheng Deng,Kun Shao,Minnan Pei,Zheng Tian,Haifeng Zhang,Jun Wang*

主要分类: cs.CV

摘要简述: 本文提出了SpatialViz-Bench，一个用于评估多模态大语言模型（MLLMs）空间可视化能力的自动生成基准测试，包含12个任务和1,180个问题。测试发现当前MLLMs在空间可视化任务中存在明显缺陷，且表现与人类直觉不符。


<details>
  <summary>详细信息</summary>
研究动机: 现有评估多模态大语言模型空间可视化能力的方法通常嵌入在数学或逻辑测试中，且可能因训练数据重叠而影响可靠性。因此，需要一个专门针对空间可视化的全面基准测试。

研究方法: 研究团队开发了SpatialViz-Bench，包含12个任务和1,180个自动生成的问题，覆盖4种子能力。通过对33种先进MLLMs的评估，测试其空间可视化表现。

研究结果: 评估结果显示，MLLMs在空间可视化任务中表现差异显著，且存在与人类直觉不符的困难感知、2D到3D性能骤降以及过度依赖公式推导等问题。

研究结论: SpatialViz-Bench揭示了当前MLLMs在空间可视化任务中的不足，填补了该领域的空白，并提供了公开可用的基准测试工具。

中文摘要: 人类能够直接在脑海中想象和操作视觉图像，这种能力称为空间可视化。尽管多模态大语言模型（MLLMs）支持基于想象的推理，但空间可视化的评估仍然不足，通常嵌入在更广泛的数学和逻辑测试中。现有的评估方法多依赖于可能与训练数据重叠的智商测试或数学竞赛，从而影响评估的可靠性。为此，我们提出了SpatialViz-Bench，一个全面的多模态空间可视化基准测试，包含12个任务和4种子能力，共计1,180个自动生成的问题。我们对33种先进的MLLMs进行了评估，结果不仅显示了广泛的性能差异，证明了基准测试的强大区分能力，还揭示了一些反直觉的发现：模型表现出与人类直觉不符的困难感知、2D到3D性能的急剧下降，以及在需要纯空间可视化的任务中过度依赖公式推导。SpatialViz-Bench通过实证表明，当前最先进的MLLMs在空间可视化任务中仍存在明显缺陷，填补了该领域的重要空白。该基准测试已公开可用。

</details>


### [98] [ViLU: Learning Vision-Language Uncertainties for Failure Prediction](https://arxiv.org/abs/2507.07620)
**中文标题：ViLU：学习视觉-语言不确定性以实现失败预测**

*Marc Lafon,Yannis Karmim,Julio Silva-Rodriguez,Paul Couairon,Clément Rambour,Raphaël Fournier-Sniehotta,Ismail Ben Ayed,Jose Dolz,Nicolas Thome*

主要分类: cs.CV

摘要简述: ViLU是一种新的视觉-语言不确定性量化框架，通过整合视觉嵌入、预测文本嵌入和图像条件文本表示，构建不确定性感知的多模态表示，显著提升了失败预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉-语言模型（VLMs）在不确定性量化和失败预测方面仍存在挑战。ViLU旨在通过利用任务相关的文本表示，提供更可靠的不确定性估计和失败预测。

研究方法: ViLU通过跨注意力机制整合视觉嵌入、预测文本嵌入和图像条件文本表示，构建多模态表示。与传统基于损失预测的方法不同，ViLU训练一个二元分类器作为不确定性预测器，使用加权二元交叉熵损失区分正确与错误预测。

研究结果: 在多个数据集（如ImageNet-1k、CC12M和LAION-400M）上的实验表明，ViLU在失败预测方面显著优于现有方法。消融研究验证了其架构和训练方法的关键作用。

研究结论: ViLU为视觉-语言模型提供了一种有效的后置不确定性量化方法，适用于仅需视觉和文本嵌入的场景，显著提升了失败预测的准确性。

中文摘要: 可靠的量化不确定性（UQ）和失败预测仍然是视觉-语言模型（VLMs）面临的开放挑战。我们提出了ViLU，一种新的视觉-语言不确定性量化框架，通过利用所有任务相关的文本表示来情境化不确定性估计。ViLU通过整合视觉嵌入、预测文本嵌入和基于图像的文本表示（通过跨注意力机制），构建了一个不确定性感知的多模态表示。与传统的基于损失预测的UQ方法不同，ViLU将不确定性预测器训练为一个二元分类器，使用加权二元交叉熵损失来区分正确与错误的预测，使其与损失无关。特别地，我们的方法非常适合后置场景，即仅需视觉和文本嵌入而无需直接访问模型本身。在多个数据集上的广泛实验表明，我们的方法在失败预测方面显著优于现有技术。我们将方法应用于标准分类数据集（如ImageNet-1k）以及大规模图像-标题数据集（如CC12M和LAION-400M）。消融研究突出了我们的架构和训练在实现有效不确定性量化中的关键作用。我们的代码已公开，可在以下链接找到：https://github.com/ykrmm/ViLU。

</details>


### [99] [T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates](https://arxiv.org/abs/2507.07633)
**中文标题：T-GVC：超低码率下的轨迹引导生成式视频编码**

*Zhitao Wang,Hengyu Man,Wenrui Li,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于轨迹引导的生成式视频编码框架（T-GVC），通过稀疏运动采样和轨迹对齐损失约束，在超低码率下实现语义准确的视频重建，优于传统编解码器和现有端到端方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有生成式视频编码方法受限于领域特异性或对高层文本引导的过度依赖，难以捕捉运动细节并导致重建不真实。本文旨在通过轨迹引导解决这些问题，实现更精确的运动控制和语义保留。

研究方法: T-GVC采用语义感知的稀疏运动采样管道，将低层运动跟踪与高层语义理解结合，提取像素级稀疏轨迹点。同时，通过轨迹对齐损失约束扩散过程，引入无需训练的潜在空间引导机制，确保物理合理的运动模式。

研究结果: 实验表明，T-GVC在超低码率条件下优于传统编解码器和现有端到端方法，且比文本引导方法实现更精确的运动控制。

研究结论: T-GVC为基于几何运动建模的生成式视频编码开辟了新方向，显著提升了超低码率下的视频重建质量。

中文摘要: 近年来，视频生成技术的进步催生了一种新兴的生成式视频编码范式，旨在通过强大的生成先验在超低码率（ULB）场景下实现语义准确的视频重建。然而，现有方法大多受限于领域特异性（如面部或人体视频）或对高层文本引导的过度依赖，往往无法捕捉运动细节并导致重建不真实。为解决这些问题，我们提出了一种轨迹引导的生成式视频编码框架（T-GVC）。T-GVC采用语义感知的稀疏运动采样管道，通过基于语义重要性提取像素级稀疏轨迹点，有效桥接低层运动跟踪与高层语义理解，不仅显著降低了码率，还保留了关键的时序语义信息。此外，通过将轨迹对齐损失约束引入扩散过程，我们提出了一种无需训练的潜在空间引导机制，确保物理合理的运动模式而不牺牲生成模型的固有能力。实验结果表明，我们的框架在ULB条件下优于传统编解码器和最先进的端到端视频压缩方法。进一步的实验证实，我们的方法比现有文本引导方法实现了更精确的运动控制，为基于几何运动建模的生成式视频编码开辟了新方向。

</details>


### [100] [Bridging the gap in FER: addressing age bias in deep learning](https://arxiv.org/abs/2507.07638)
**中文标题：弥合FER中的差距：解决深度学习中的年龄偏见**

*F. Xavier Gaya-Morey,Julia Sanchez-Perez,Cristina Manresa-Yee,Jose M. Buades-Rubio*

主要分类: cs.CV

摘要简述: 本文研究了深度学习面部表情识别（FER）系统中的年龄偏见问题，重点关注老年群体，并提出三种偏差缓解策略，显著提升了老年人群体的识别准确率。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习FER系统近年表现优异，但存在年龄偏见，尤其是对老年群体的不公平性和可靠性问题。本文旨在揭示并解决这一偏见。

研究方法: 研究首先分析了不同年龄组的识别性能差异，使用可解释AI（XAI）技术识别系统性偏差，并提出三种策略：多任务学习、多模态输入和年龄加权损失。模型在AffectNet数据集上训练，并在平衡基准数据集上验证。

研究结果: 结果显示，年龄感知策略显著提升了老年群体的识别准确率，尤其是易错表情（如“中性”、“悲伤”和“愤怒”）。显著性热图分析表明，模型关注更相关的面部区域。

研究结论: 研究表明，通过简单的训练调整可以有效缓解FER中的年龄偏见，近似的人口统计标签对促进大规模情感计算系统的公平性具有价值。

中文摘要: 基于深度学习的面部表情识别（FER）系统近年来取得了显著性能，但这些模型常表现出人口统计偏见，尤其是年龄偏见，影响其公平性和可靠性。本文全面研究了深度FER模型中的年龄偏见，重点关注老年群体。我们首先探讨了识别性能是否因年龄组而异，哪些表情受影响最大，以及模型注意力是否因年龄而不同。通过可解释AI（XAI）技术，我们识别出表情识别和注意力模式的系统性差异，尤其是老年群体的“中性”、“悲伤”和“愤怒”表情。基于这些发现，我们提出并评估了三种偏差缓解策略：多任务学习、多模态输入和年龄加权损失。模型在AffectNet数据集上训练，使用自动估计的年龄标签，并在包含代表性不足年龄组的平衡基准数据集上验证。结果显示，老年群体的识别准确率显著提升，尤其是易错表情。显著性热图分析表明，采用年龄感知策略的模型更关注各年龄组的相关面部区域，解释了观察到的改进。这些发现表明，通过简单的训练调整可以有效缓解FER中的年龄偏见，近似的人口统计标签对促进大规模情感计算系统的公平性具有价值。

</details>


### [101] [MolCLIP: A Molecular-Auxiliary CLIP Framework for Identifying Drug Mechanism of Action Based on Time-Lapsed Mitochondrial Images](https://arxiv.org/abs/2507.07663)
**中文标题：MolCLIP：基于时间序列线粒体图像的分子辅助CLIP框架用于药物作用机制识别**

*Fengqian Pang,Chunyue Lei,Hongfei Zhao,Chenghao Liu,Zhiqiang Xing,Huafeng Wang,Chuyang Ye*

主要分类: cs.CV

摘要简述: MolCLIP是一种结合细胞视频和分子模态的视觉语言模型，通过分子辅助CLIP框架优化视频特征学习，显著提升药物识别和作用机制分析的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有深度学习方法主要依赖细胞的空间特征图像，忽略了时间动态信息，而药物分子模态可能补充图像信息，因此需要一种结合两种模态的新方法。

研究方法: 提出MolCLIP框架，通过分子辅助CLIP模型引导视频特征学习分子潜在空间分布，并结合度量学习优化视频特征聚合。

研究结果: 在MitoDataset上，MolCLIP在药物识别和作用机制识别任务中分别提升了51.2%和20.5%的mAP。

研究结论: MolCLIP通过结合细胞视频和分子模态，显著提升了药物作用机制分析的性能，为药物发现提供了新工具。

中文摘要: 药物作用机制（MoA）主要研究药物分子如何与细胞相互作用，这对药物发现和临床应用至关重要。近年来，深度学习模型通过依赖药物处理后的高内容和荧光细胞图像来识别MoA。然而，这些方法关注空间特征而忽略了活细胞的时间动态。时间序列成像更适合观察细胞对药物的反应。此外，药物分子可能触发与特定MoA相关的细胞动态变化，这表明药物分子模态可能补充图像模态。本文提出MolCLIP，首个结合显微细胞视频和分子模态的视觉语言模型。MolCLIP设计了一种分子辅助CLIP框架，引导视频特征学习分子潜在空间的分布。此外，我们结合度量学习策略优化视频特征的聚合。在MitoDataset上的实验结果表明，MolCLIP在药物识别和MoA识别任务中的mAP分别提升了51.2%和20.5%。

</details>


### [102] [Attend-and-Refine: Interactive keypoint estimation and quantitative cervical vertebrae analysis for bone age assessment](https://arxiv.org/abs/2507.07670)
**中文标题：“关注与精炼”：交互式关键点估计与颈椎定量分析用于骨龄评估**

*Jinhee Kim,Taesung Kim,Taewoo Kim,Dong-Wook Kim,Byungduk Ahn,Yoon-Ji Kim,In-Seok Song,Jaegul Choo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ARNet的交互式深度学习模型，用于简化颈椎关键点标注，从而提升骨龄评估的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在儿科正畸中，准确评估生长潜力对制定有效治疗策略至关重要。传统方法依赖人工标注颈椎关键点，耗时且费力。本文旨在通过深度学习技术简化这一过程。

研究方法: 提出ARNet模型，结合交互引导的重新校准网络和形态感知损失函数，通过用户反馈自适应调整图像特征，同时保持关键点的结构一致性。

研究结果: ARNet在多个数据集上验证表现出色，显著减少了人工标注工作量，提升了骨龄评估的效率和准确性。

研究结论: 本研究为儿科正畸提供了一种高效的AI辅助诊断工具，显著推动了该领域的进步。

中文摘要: 在儿科正畸中，准确评估生长潜力对制定有效治疗策略至关重要。本研究旨在通过侧位头影测量X光片识别生长峰值并分析颈椎形态来预测这一潜力。我们通过全面分析这些X光片中的颈椎成熟特征实现这一目标。该方法为临床医生提供了一种可靠且高效的工具，用于确定正畸干预的最佳时机，从而改善患者预后。这一方法的关键在于对颈椎关键点的精细标注，而这一任务通常因其耗时性而具有挑战性。为此，我们提出了“关注与精炼网络”（ARNet），这是一种基于深度学习的用户交互模型，旨在简化标注过程。ARNet包含交互引导的重新校准网络，可根据用户反馈自适应调整图像特征，并结合形态感知损失函数以保持关键点的结构一致性。这一新方法显著减少了关键点识别的人工工作量，从而提升了过程的效率和准确性。在多个数据集上的广泛验证表明，ARNet表现出卓越的性能，并在医学影像中具有广泛适用性。总之，本研究为儿科正畸中的生长潜力评估提供了一种有效的AI辅助诊断工具，标志着该领域的重大进展。

</details>


### [103] [Action Unit Enhance Dynamic Facial Expression Recognition](https://arxiv.org/abs/2507.07678)
**中文标题：动作单元增强的动态面部表情识别**

*Feng Liu,Lingna Gu,Chen Shi,Xiaolan Fu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于动作单元（AU）增强的动态面部表情识别架构（AU-DFER），通过量化AU对不同表情的贡献并设计权重矩阵，结合先验知识提升深度学习模型效果。实验表明，该方法在主流数据集上优于现有技术，并探讨了AU损失函数设计对数据标签不平衡问题的解决潜力。


<details>
  <summary>详细信息</summary>
研究动机: 动态面部表情识别（DFER）领域的研究多从深度学习角度进行特征学习，但缺乏对动作单元（AU）与表情关系的量化利用。本文旨在通过整合AU-expression知识，提升DFER模型的性能，并解决数据标签不平衡问题。

研究方法: 提出AU-DFER架构，量化AU对不同表情的贡献，设计权重矩阵引入先验知识，并通过AU损失将知识与深度学习网络结合。将该设计嵌入现有最优动态表情识别模型进行验证，并在主流数据集上测试。

研究结果: 实验表明，AU-DFER在无需额外计算的情况下优于现有最优方法，且AU损失函数设计能有效缓解数据标签不平衡问题。

研究结论: 本文首次将量化AU-expression知识整合到多种DFER模型中，证明了AU损失函数设计的多样性对提升DFER效果的重要性，并强调了解决数据不平衡问题的必要性。

中文摘要: 动态面部表情识别（DFER）是一个快速发展的研究领域，专注于时间序列面部表情的识别。以往的研究主要从深度学习角度进行特征学习，而本文提出了一种AU增强的动态面部表情识别架构（AU-DFER），通过整合AU-expression知识提升深度学习建模效果。具体而言，量化了动作单元（AU）对不同表情的贡献，并设计了权重矩阵以融入先验知识。随后，通过引入AU损失，将这些知识与传统深度学习网络的学习结果结合。该设计被嵌入现有最优动态表情识别模型中进行验证。实验在三个主流开源DFER方法和该领域主要数据集上进行，结果表明所提架构在无需额外计算的情况下优于现有最优方法，且普遍提升了效果。此外，本文探讨了AU损失函数重新设计对解决动态表情数据集中数据标签不平衡问题的潜力。据我们所知，这是首次尝试将量化AU-expression知识整合到多种DFER模型中。我们还设计了解决标签不平衡或小类问题的策略。研究发现，采用多样化的损失函数设计策略可提升DFER效果，这凸显了解决该领域主流数据集中数据不平衡挑战的重要性。源代码发布于https://github.com/Cross-Innovation-Lab/AU-DFER。

</details>


### [104] [Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought](https://arxiv.org/abs/2507.07685)
**中文标题：理性增强解码用于多模态链式思维**

*Shin'ya Yamaguchi,Kosuke Nishida,Daiki Chijiwa*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“理性增强解码（RED）”的新方法，通过优化多模态链式思维（CoT）推理中的理性条件概率，显著提升了大型视觉语言模型（LVLM）的推理准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态链式思维（CoT）方法在推理过程中常忽略生成的理性内容，导致推理的准确性和可靠性不足。本文旨在解决这一问题，提出一种更有效的解码策略。

研究方法: 作者将多模态CoT推理重新定义为基于KL约束的奖励最大化问题，并提出RED方法，通过结合图像条件和理性条件的下一词分布，优化推理过程。

研究结果: 实验表明，RED在多个基准测试和不同LVLM中均显著优于标准CoT和其他解码方法，提升了推理的准确性和忠实性。

研究结论: RED为多模态系统提供了一种实用且高效的解决方案，能够增强理性基础的多模态推理，推动更可靠的系统发展。

中文摘要: 大型视觉语言模型（LVLM）通过结合预训练的视觉编码器和大型语言模型（LLM）展现了卓越的能力。类似于单模态LLM，链式思维（CoT）提示被用于增强多模态推理，通过生成基于视觉和文本输入的中间理性。尽管CoT被认为可以提高LVLM的准确性和基础性，但我们的实验揭示了一个关键问题：现有LVLM在CoT推理中常忽略生成的理性内容。为解决这一问题，我们将多模态CoT推理重新定义为基于KL约束的奖励最大化问题，专注于理性条件对数似然。作为最优解，我们提出了理性增强解码（RED），一种新颖的即插即用推理时解码策略。RED通过将图像条件和理性条件的下一词分布相乘，协调视觉和理性信息。大量实验表明，RED在多个基准测试和LVLM中均显著优于标准CoT和其他解码方法。我们的工作为提升LVLM中CoT推理的忠实性和准确性提供了一种实用且有效的方法，为更可靠的理性基础多模态系统铺平了道路。

</details>


### [105] [Tree-Mamba: A Tree-Aware Mamba for Underwater Monocular Depth Estimation](https://arxiv.org/abs/2507.07687)
**中文标题：Tree-Mamba：一种用于水下单目深度估计的树感知Mamba方法**

*Peixian Zhuang,Yijian Wang,Zhenqi Fu,Hongliang Zhang,Sam Kwong,Chongyi Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Tree-Mamba的新方法，用于水下单目深度估计（UMDE），通过树感知扫描策略和构建可靠的深度标注数据集（BlueDepth），显著提升了深度估计的准确性和多尺度特征表示能力。


<details>
  <summary>详细信息</summary>
研究动机: 水下单目深度估计（UMDE）因水下图像的光吸收和散射效应而具有挑战性。现有的Mamba方法由于状态扫描策略不灵活，难以有效建模水下图像的结构特征，且现有数据集的深度标注不可靠，导致对象与深度关系不准确。

研究方法: 提出了一种树感知扫描策略，基于特征相似性自适应构建最小生成树，并通过自底向上和自顶向下遍历灵活聚合空间拓扑特征，增强了多尺度特征表示能力。同时构建了BlueDepth数据集，包含38,162对可靠深度标注的水下图像对。

研究结果: 实验表明，Tree-Mamba在定性和定量评估中均优于现有方法，同时保持了较高的计算效率。

研究结论: Tree-Mamba通过树感知扫描策略和可靠数据集，显著提升了水下单目深度估计的性能，为UMDE任务提供了新的解决方案。

中文摘要: 水下单目深度估计（UMDE）是一项关键任务，旨在从因海洋环境中光吸收和散射效应而退化的水下图像中估计高精度深度图。近年来，基于Mamba的方法在各种视觉任务中表现出色，但在UMDE任务中表现不佳，因其不灵活的状态扫描策略无法有效建模水下图像的结构特征。此外，现有的UMDE数据集通常包含不可靠的深度标注，导致水下图像与其对应深度图之间的对象-深度关系不准确。为解决这些问题，我们开发了一种名为Tree-Mamba的新型树感知Mamba方法，用于从退化的水下图像中估计准确的单目深度图。具体而言，我们提出了一种树感知扫描策略，基于特征相似性自适应构建最小生成树，并通过自底向上和自顶向下遍历灵活聚合树节点间的空间拓扑特征，从而增强多尺度特征表示能力。此外，我们构建了一个水下深度估计基准数据集（称为BlueDepth），包含38,162对具有可靠深度标注的水下图像对。该数据集可作为训练现有基于深度学习的UMDE方法的基础，以学习准确的对象-深度关系。大量实验表明，所提出的Tree-Mamba在定性结果和定量评估中均优于多种领先方法，同时具有竞争力的计算效率。代码和数据集将在https://wyjgr.github.io/Tree-Mamba.html上提供。

</details>


### [106] [Motion-Aware Adaptive Pixel Pruning for Efficient Local Motion Deblurring](https://arxiv.org/abs/2507.07708)
**中文标题：运动感知的自适应像素剪枝用于高效局部运动去模糊**

*Wei Shang,Dongwei Ren,Wanying Zhang,Pengfei Zhu,Qinghua Hu,Wangmeng Zuo*

主要分类: cs.CV

摘要简述: 本文提出了一种运动感知的自适应像素剪枝方法，用于高效局部运动去模糊。通过可训练的掩模预测器和帧内运动分析器，显著减少计算量并提升去模糊效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有去模糊方法在计算资源分配和空间变化模糊模式处理上效率不足，导致局部运动模糊问题难以解决。

研究方法: 1. 提出可训练掩模预测器识别模糊区域，训练时排除清晰区域；2. 通过结构重参数化将3×3卷积转为1×1卷积，实现像素级剪枝；3. 开发帧内运动分析器，将像素位移转为运动轨迹，指导区域特异性模糊恢复。

研究结果: 在局部和全局模糊数据集上表现优于现有方法，计算量减少49%（如LMD-ViT）。

研究结论: 该方法通过自适应剪枝和运动分析，显著提升了去模糊效率与效果，为局部运动模糊问题提供了高效解决方案。

中文摘要: 数字图像中的局部运动模糊源于动态物体与静态成像系统在曝光期间的相对运动。现有去模糊方法因计算资源分配效率低下及对空间变化模糊模式处理不足，面临显著挑战。为克服这些限制，我们首先提出一种可训练的掩模预测器，用于识别图像中的模糊区域。训练时，利用模糊掩模排除清晰区域。为优化推理，通过将3×3卷积转换为计算高效的1×1卷积，实现清晰区域的像素级剪枝以减少计算量。其次，我们开发了一种帧内运动分析器，将相对像素位移转化为运动轨迹，为区域特异性模糊恢复建立自适应指导。我们的方法通过结合重建损失、再模糊损失和掩模损失进行端到端训练。大量实验表明，在局部和全局模糊数据集上，该方法性能优于现有技术，同时计算量比SOTA模型（如LMD-ViT）减少49%。源代码见https://github.com/shangwei5/M2AENet。

</details>


### [107] [One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models](https://arxiv.org/abs/2507.07709)
**中文标题：一物多谎：统一视觉-语言模型跨任务对抗攻击基准**

*Jiale Zhao,Xinyang Jiang,Junyao Gao,Yuhao Xue,Cairong Zhao*

主要分类: cs.CV

摘要简述: 本文提出了CrossVLAD基准数据集和CRAFT攻击框架，用于评估统一视觉-语言模型（VLMs）在多任务指令下的对抗攻击效果，实验证明CRAFT在跨任务攻击和目标对象篡改成功率上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 统一视觉-语言模型（VLMs）通过共享计算架构灵活处理多任务，但其指令控制机制带来独特的安全挑战，需研究对抗输入在多任务指令下的有效性。

研究方法: 提出CrossVLAD基准数据集（基于MSCOCO和GPT-4标注）和CRAFT攻击框架（基于区域和令牌对齐），用于系统评估跨任务对抗攻击。

研究结果: 在Florence-2等统一VLMs上的实验表明，CRAFT在跨任务攻击性能和目标对象篡改成功率上均优于现有方法。

研究结论: CRAFT能有效影响统一VLMs在多任务中的表现，为跨任务对抗攻击研究提供了新基准和方法。

中文摘要: 统一视觉-语言模型（VLMs）近期取得显著进展，通过共享计算架构和不同指令灵活处理多任务。这种基于指令的控制机制带来独特的安全挑战，因为对抗输入需在不可预测的多任务指令下保持有效性。本文提出CrossVLAD基准数据集（基于MSCOCO和GPT-4标注），用于系统评估统一VLMs的跨任务对抗攻击。CrossVLAD聚焦对象篡改目标——在四个下游任务中一致操纵目标对象的分类——并提出一种新颖的成功率指标，衡量所有任务中的同时误分类，严格评估对抗迁移性。为应对这一挑战，我们提出CRAFT（基于区域和令牌对齐的跨任务攻击框架），一种高效的以区域为中心的对抗方法。在Florence-2等流行统一VLMs上的大量实验表明，我们的方法在跨任务攻击性能和目标对象篡改成功率上均优于现有方法，凸显其在多任务中对抗影响统一VLMs的有效性。

</details>


### [108] [Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays](https://arxiv.org/abs/2507.07722)
**中文标题：理解医学影像中的数据集偏差：以胸部X光片为例**

*Ethan Dack,Chengliang Dai*

主要分类: cs.CV

摘要简述: 本文研究了医学影像数据集（如胸部X光片）中是否存在数据集偏差，通过实验验证了这一问题，并探讨了其对AI应用的影响。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像数据集因其敏感性难以公开，导致某些开源数据集被广泛使用。本文旨在验证这些数据集中是否存在偏差，以确保AI方法关注的是相关病理而非数据集特性。

研究方法: 研究通过数据集转换任务，使用NIH、CheXpert、MIMIC-CXR和PadChest等开源胸部X光数据集，应用多种网络架构进行分析。

研究结果: 实验表明，医学影像数据集中同样存在数据集偏差，这可能影响AI方法的可靠性和解释性。

研究结论: 本文呼吁在医学影像领域开展更多可解释性研究，并鼓励创建更多开源数据集，以提高AI应用的透明度和可靠性。

中文摘要: 近期研究重新审视了“命名数据集”这一经典任务，并证实非医学数据集中存在潜在偏差，且在数据集来源任务中取得了高准确率。本文将该任务应用于流行的开源胸部X光数据集，探讨这些数据集中是否也存在偏差。由于医学影像的敏感性，其开源发布更为困难，导致某些开源数据集在研究中被广泛使用。通过相同的任务，我们希望探索这些数据集中的偏差问题。%我们通过数据集转换刻意增加了任务难度，以识别潜在的偏差。鉴于AI在医学影像中的重要性，必须确认现代方法是关注相关病理还是采取了捷径。我们在NIH、CheXpert、MIMIC-CXR和PadChest数据集上实现了多种网络架构。希望这项工作能促进医学影像领域更多可解释性研究的开展，并推动更多开源数据集的创建。相关代码将在论文接受后发布。

</details>


### [109] [Scaling RL to Long Videos](https://arxiv.org/abs/2507.07966)
**中文标题：将强化学习扩展到长视频**

*Yukang Chen,Wei Huang,Baifeng Shi,Qinghao Hu,Hanrong Ye,Ligeng Zhu,Zhijian Liu,Pavlo Molchanov,Jan Kautz,Xiaojuan Qi,Sifei Liu,Hongxu Yin,Yao Lu,Song Han*

主要分类: cs.CV

摘要简述: 本文提出了一种全栈框架，通过强化学习将视觉语言模型（VLM）的推理能力扩展到长视频领域。该框架整合了大规模数据集、两阶段训练管道和高效训练基础设施，显著提升了长视频推理性能。


<details>
  <summary>详细信息</summary>
研究动机: 长视频推理在视觉语言模型中面临独特挑战，如数据规模不足和训练效率低下。本文旨在通过强化学习和大规模数据集解决这些问题，推动长视频推理技术的发展。

研究方法: 方法包括：（1）构建包含52K长视频问答对的大规模数据集LongVideo-Reason；（2）采用两阶段训练管道，结合链式思维监督微调（CoT-SFT）和强化学习（RL）；（3）开发多模态强化序列并行（MR-SP）训练基础设施，支持高效长视频训练。

研究结果: 实验表明，LongVILA-R1-7B在长视频问答基准测试中表现优异，超越Video-R1-7B，并与Gemini-1.5-Pro在多项推理任务中持平。MR-SP系统实现了2.1倍的训练加速，且性能随输入视频帧数增加而提升。

研究结论: LongVILA-R1标志着VLM在长视频推理领域的重要进展。同时，公开的训练系统支持多模态、多模型的强化学习训练，为未来研究提供了实用工具。

中文摘要: 我们提出了一种全栈框架，通过强化学习将视觉语言模型（VLM）的推理能力扩展到长视频领域。针对长视频推理的独特挑战，我们整合了三个关键组件：（1）大规模数据集LongVideo-Reason，包含52K个长视频问答对，涵盖体育、游戏和视频博客等多个领域的高质量推理标注；（2）两阶段训练管道，通过链式思维监督微调（CoT-SFT）和强化学习（RL）扩展VLM；（3）专为长视频设计的训练基础设施Multi-modal Reinforcement Sequence Parallelism（MR-SP），结合序列并行和基于vLLM的引擎，利用缓存视频嵌入实现高效训练。实验显示，LongVILA-R1-7B在VideoMME等长视频问答基准测试中表现优异，超越Video-R1-7B，并在我们的LongVideo-Reason-eval基准测试中与Gemini-1.5-Pro在时间推理、目标与目的推理、空间推理和情节推理等任务中表现相当。值得注意的是，MR-SP系统在长视频RL训练中实现了高达2.1倍的加速。LongVILA-R1的性能随输入视频帧数增加而持续提升，标志着VLM在长视频推理领域的重要进展。此外，我们公开了支持多模态（视频、文本和音频）、多模型（VILA和Qwen系列）甚至图像和视频生成模型的强化学习训练系统。在单个A100节点（8个GPU）上，该系统支持长达一小时视频（例如3,600帧/约256k令牌）的RL训练。

</details>


### [110] [RAPS-3D: Efficient interactive segmentation for 3D radiological imaging](https://arxiv.org/abs/2507.07730)
**中文标题：RAPS-3D：高效的3D放射影像交互式分割方法**

*Théo Danielou,Daniel Tordjman,Pierre Manceron,Corentin Dancette*

主要分类: cs.CV

摘要简述: 本文提出了一种简化的3D可提示分割方法RAPS-3D，旨在减少推理时间并消除滑动窗口相关的复杂性，同时实现最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的2D分割模型（如SAM）无法直接应用于3D医学影像（如CT或MRI），而现有3D方法通常采用复杂的策略（如滑动窗口推理），导致推理时间长且实现复杂。因此，需要一种更高效的3D交互式分割方法。

研究方法: 受SegVol启发，本文提出了一种简化的3D可提示分割方法RAPS-3D，通过减少推理时间和消除滑动窗口的复杂性，优化了3D医学影像的分割效率。

研究结果: RAPS-3D在减少推理时间的同时，消除了滑动窗口相关的复杂性，并在性能上达到了最先进的水平。

研究结论: RAPS-3D为3D医学影像提供了一种高效且简化的交互式分割方法，显著提升了分割效率和性能。

中文摘要: 可提示分割（由Segment Anything Model（SAM）引入）是医学影像中一种有前景的方法，因为它允许临床医生交互式地指导和优化模型预测。然而，SAM的架构是为2D图像设计的，无法自然扩展到3D体积数据（如CT或MRI扫描）。将2D模型适配到3D通常涉及自回归策略，即逐片传播预测，导致推理复杂性增加。处理大型3D体积还需要大量计算资源，现有3D方法通常采用滑动窗口推理等复杂策略来管理内存使用，但代价是更长的推理时间和更高的实现复杂性。本文提出了一种简化的3D可提示分割方法RAPS-3D，受SegVol启发，旨在减少推理时间并消除滑动窗口相关的提示管理复杂性，同时实现最先进的性能。

</details>


### [111] [Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology](https://arxiv.org/abs/2507.07999)
**中文标题：可追踪证据增强的视觉基础推理：评估与方法论**

*Haochen Wang,Xiangtai Li,Zilong Huang,Anran Wang,Jiacong Wang,Tao Zhang,Jiani Zheng,Sule Bai,Zijian Kang,Jiashi Feng,Zhuochen Wang,Zhaoxiang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了TreeBench评测基准和TreeVGR训练范式，用于评估和提升视觉基础推理能力，强调可追踪证据的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏全面评估视觉基础推理能力的基准，且现有模型在复杂场景中的表现不足，因此需要开发新的评测方法和训练范式。

研究方法: 提出TreeBench基准，基于三项原则构建：聚焦复杂场景中的细微目标、通过边界框评估可追踪证据、测试高阶推理能力。同时提出TreeVGR训练范式，结合强化学习联合监督定位和推理。

研究结果: TreeBench包含405个高难度视觉问答对，现有模型表现不佳（如OpenAI-o3仅54.87%准确率）。TreeVGR在多个基准上显著提升性能（如TreeBench提升13.4%）。

研究结论: 可追踪证据是提升视觉基础推理的关键，TreeBench和TreeVGR为未来研究提供了重要工具和方向。

中文摘要: 像OpenAI-o3这样的模型通过动态引用视觉区域开创了视觉基础推理，类似于人类的“图像思维”。然而，目前缺乏全面评估这些能力的基准。为填补这一空白，我们提出了TreeBench（可追踪证据评估基准），这是一个基于三项原则的诊断性基准：（1）聚焦复杂场景中的细微目标，（2）通过边界框评估可追踪证据，（3）测试高阶推理能力，包括对象交互和空间层级。我们从SA-1B中采样了1K张高质量图像，并邀请八位LMM专家手动标注问题、候选选项和答案。经过三阶段质量控制，TreeBench包含405个高难度视觉问答对，即使最先进的模型也难以应对（如OpenAI-o3仅54.87%准确率）。此外，我们提出了TreeVGR（可追踪证据增强的视觉基础推理），一种通过强化学习联合监督定位和推理的训练范式，实现了精准定位和可解释的推理路径。基于Qwen2.5-VL-7B初始化，TreeVGR在V* Bench（+16.8）、MME-RealWorld（+12.6）和TreeBench（+13.4）上均有显著提升，证明可追踪性是推动视觉基础推理的关键。代码已开源：https://github.com/Haochen-Wang409/TreeVGR。

</details>


### [112] [Energy-Guided Decoding for Object Hallucination Mitigation](https://arxiv.org/abs/2507.07731)
**中文标题：基于能量引导的解码方法用于减少物体幻觉**

*Xixi Liu,Ailin Deng,Christopher Zach*

主要分类: cs.CV

摘要简述: 本文提出了一种基于能量的解码方法，用于减少大型视觉语言模型中的物体幻觉现象，显著提高了三个VQA数据集的性能，并减少了回答偏差。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型（LVLMs）中的物体幻觉问题对其安全部署至关重要。现有方法要么局限于特定解码方式，要么需要复杂的视觉输入修改，或依赖外部模型知识。本文旨在解决这些问题。

研究方法: 提出了一种基于能量的解码方法，动态选择能量分数最低的隐藏状态层，以减少回答偏差并提升性能。

研究结果: 该方法在三个基准数据集（POPE、MME和MMVP）上显著提高了准确率和F1分数，平均准确率提升4.82%，回答偏差减少8.81%。

研究结论: 基于能量的解码方法简单有效，能够显著减少物体幻觉现象，并提升模型性能。

中文摘要: 减少大型视觉语言模型（LVLMs）中的物体幻觉对其安全部署至关重要。现有方法要么局限于特定解码方式，要么需要复杂的视觉输入修改，或依赖外部模型知识。本文首先揭示了视觉问答（VQA）数据集中“是”回答比例显著不平衡的现象。进一步提出了一种基于能量的解码方法，动态选择能量分数最低的隐藏状态层。该方法简单有效，在减少回答偏差的同时，显著提升了三个基准数据集（POPE、MME和MMVP）的性能。相比贪婪解码，平均准确率提升4.82%，回答偏差减少8.81%。

</details>


### [113] [EEvAct: Early Event-Based Action Recognition with High-Rate Two-Stream Spiking Neural Networks](https://arxiv.org/abs/2507.07734)
**中文标题：EEvAct：基于高频率双流脉冲神经网络的早期事件驱动动作识别**

*Michael Neumeier,Jules Lecomte,Nils Kazinski,Soubarna Banik,Bing Li,Axel von Arnim*

主要分类: cs.CV

摘要简述: 本文提出了一种高频率双流脉冲神经网络（SNN）EEvAct，用于早期事件驱动的动作识别，显著提升了最终识别准确率，并在THU EACT-50数据集上超越先前工作2%。


<details>
  <summary>详细信息</summary>
研究动机: 早期识别人类活动对提升人机交互的安全性和响应速度至关重要。事件视觉传感器因其高时间分辨率和低延迟特性非常适合这一需求，但现有方法多将事件累积为低频率帧或时空体素，限制了早期预测能力。

研究方法: 本文提出了一种高频率双流脉冲神经网络（SNN），能够以高频率处理事件数据，实现早期预测。同时，设计了新型早期事件识别框架，通过Top-1和Top-5评分评估不同观察时间下的识别性能。

研究结果: 在THU EACT-50数据集上，该方法最终识别准确率超越先前工作2%，并在早期动作触发任务中展示了实际应用潜力。

研究结论: 高频率双流SNN在早期事件驱动的动作识别中表现出色，不仅提升了准确率，还为实际应用（如体育动作捕捉）提供了有效解决方案。

中文摘要: 早期识别人类活动对人机交互的安全性和响应速度至关重要。事件视觉传感器因其高时间分辨率和低延迟特性非常适合这一需求，但现有方法多将事件累积为低频率帧或时空体素，限制了早期预测能力。相比之下，脉冲神经网络（SNN）能以高频率处理事件数据实现早期预测，但多数工作的最终准确率仍有不足。本文提出了一种高频率双流SNN，弥补了这一差距，在THU EACT-50数据集上最终准确率超越先前工作2%。我们在新型早期事件识别框架中对SNN进行了基准测试，报告了不同观察时间下的Top-1和Top-5识别得分。最后，以体育运动中的人体动作捕捉为例，展示了这些方法在早期动作触发任务中的实际应用价值。

</details>


### [114] [Sparse-Dense Side-Tuner for efficient Video Temporal Grounding](https://arxiv.org/abs/2507.07744)
**中文标题：稀疏-密集侧调器：高效视频时间定位**

*David Pujol-Perich,Sergio Escalera,Albert Clapés*

主要分类: cs.CV

摘要简述: 本文提出了一种稀疏-密集侧调器（SDST），用于高效视频时间定位（VTG），通过引入参考式可变形自注意力机制，显著提升了性能，并在多个数据集上达到或超越现有最优方法，同时减少了73%的参数。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频时间定位方法大多依赖冻结的预训练主干网络最后一层特征，限制了其对新领域的适应性。虽然完全微调不切实际，但参数高效的侧调（ST）方法成为替代方案。然而，现有ST方法从帧级细化角度解决问题，忽略了时刻检索（MR）的稀疏性。

研究方法: 提出稀疏-密集侧调器（SDST），首个用于VTG的无锚点ST架构，并引入参考式可变形自注意力机制，增强上下文建模。同时首次将InternVideo2主干网络有效集成到ST框架中。

研究结果: SDST显著提升了现有ST方法性能，在QVHighlights、TACoS和Charades-STA数据集上达到或超越最优结果，同时减少了73%的参数。

研究结论: SDST通过稀疏-密集侧调和参考式可变形自注意力机制，显著提升了视频时间定位的性能和效率，为未来研究提供了新方向。

中文摘要: 视频时间定位（VTG）涉及基于文本查询的时刻检索（MR）和高光检测（HD）。现有方法大多依赖冻结的预训练主干网络最后一层特征，限制了其适应性。虽然完全微调不切实际，但参数高效的侧调（ST）成为替代方案。然而，现有ST方法从帧级细化角度解决问题，忽略了MR的稀疏性。为此，我们提出稀疏-密集侧调器（SDST），首个用于VTG的无锚点ST架构，并引入参考式可变形自注意力机制，增强了可变形注意力的上下文建模能力。此外，我们首次将InternVideo2主干网络有效集成到ST框架中，展示了其性能的深远影响。总体而言，我们的方法显著提升了现有ST方法，在QVHighlights、TACoS和Charades-STA数据集上达到或超越最优结果，同时减少了73%的参数。代码已公开。

</details>


### [115] [X-RAFT: Cross-Modal Non-Rigid Registration of Blue and White Light Neurosurgical Hyperspectral Images](https://arxiv.org/abs/2507.07747)
**中文标题：X-RAFT：蓝光和白光神经外科高光谱图像的跨模态非刚性配准**

*Charlie Budd,Silvère Ségaud,Matthew Elliot,Graeme Stasiuk,Yijing Xie,Jonathan Shapey,Tom Vercauteren*

主要分类: cs.CV

摘要简述: X-RAFT是一种改进的跨模态光流模型，用于在神经外科手术中配准蓝光和白光高光谱图像，显著提升了荧光定量分析的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在荧光引导的神经外科手术中，高光谱成像的整合需要配准蓝光和白光模式下的图像，以实现实时荧光定量。由于手术环境的动态性，跨模态图像配准成为关键挑战。

研究方法: X-RAFT基于RAFT光流模型，针对跨模态输入进行了改进，采用独立的图像编码器对每种模态进行处理，并通过自监督的流循环一致性进行微调。

研究结果: 实验表明，X-RAFT在评估指标上比基线方法减少了36.6%的误差，比现有跨模态光流方法（CrossRAFT）减少了27.83%的误差。

研究结论: X-RAFT有效解决了神经外科高光谱图像跨模态配准问题，为荧光定量分析提供了可靠工具。

中文摘要: 将高光谱成像整合到荧光引导的神经外科手术中，有望通过实时提供定量荧光测量来改善手术决策。定量荧光需要荧光（蓝光）和反射（白光）模式下的配对光谱数据。蓝光和白光图像采集需要在潜在动态的手术环境中顺序进行。因此，荧光定量过程的关键能力是找到在这两种截然不同光照条件下拍摄的两幅高光谱图像之间的密集跨模态对应关系。我们通过引入X-RAFT来解决这一挑战，这是一种针对跨模态输入改进的递归全对场变换（RAFT）光流模型。我们建议为每种模态对使用独立的图像编码器，并通过流循环一致性在我们的神经外科高光谱数据上以自监督方式微调这些编码器。与基线方法相比，我们的方法在评估指标上减少了36.6%的误差，与现有的跨模态光流方法（CrossRAFT）相比减少了27.83%的误差。我们的代码和模型将在评审过程结束后公开。

</details>


### [116] [Deep Learning based 3D Volume Correlation for Additive Manufacturing Using High-Resolution Industrial X-ray Computed Tomography](https://arxiv.org/abs/2507.07757)
**中文标题：基于深度学习的高分辨率工业X射线计算机断层扫描增材制造3D体积配准方法**

*Keerthana Chand,Tobias Fritsch,Bardia Hejazi,Konstantin Poka,Giovanni Bruno*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的3D体积配准方法，用于增材制造中的高分辨率工业X射线计算机断层扫描，显著提高了配准精度和效率。


<details>
  <summary>详细信息</summary>
研究动机: 增材制造中的质量控制对汽车、医疗和航空航天等行业至关重要。由于收缩和变形导致的几何不准确性可能影响部件寿命和性能。传统数字体积相关方法（DVC）在配准时缺乏地面真实变形场，且高分辨率XCT数据计算困难，亟需高效准确的解决方案。

研究方法: 本文采用基于深度学习的动态分块处理策略，估计CAD与XCT体积之间的体素级变形。引入二值差异图（BDM）量化配准精度，并结合Dice Score进行评估。

研究结果: 相比传统DVC方法，本文方法在Dice Score上提高了9.2%，体素匹配率提高了9.9%，并将交互时间从数天缩短至几分钟。

研究结论: 本研究为基于深度学习的DVC方法奠定了基础，可用于生成补偿网格，提升增材制造过程的可靠性和效率，节省时间和材料。

中文摘要: 增材制造（AM）中的质量控制对汽车、医疗和航空航天等工业应用至关重要。由于收缩和变形导致的几何不准确性可能影响增材制造部件的寿命和性能。数字体积相关（DVC）可通过比较计算机辅助设计（CAD）模型与X射线计算机断层扫描（XCT）生成的部件几何形状来量化这些偏差。然而，由于缺乏地面真实变形场，两种模态之间的精确配准具有挑战性。此外，高分辨率XCT体积的极大数据量使得计算困难。本文提出了一种基于深度学习的方法，用于估计CAD与XCT体积之间的体素级变形。我们的方法采用动态分块处理策略处理高分辨率体积。除了Dice Score外，我们引入了二值差异图（BDM）来量化二值化CAD与XCT体积之间的体素级不匹配，以评估配准精度。相比传统DVC方法，我们的方法在Dice Score上提高了9.2%，体素匹配率提高了9.9%，并将交互时间从数天缩短至几分钟。本研究为基于深度学习的DVC方法奠定了基础，可用于生成补偿网格，从而在AM生产过程中实现闭环相关性。这种系统对工业界具有重要意义，因为它将使制造过程更可靠和高效，节省时间和材料。

</details>


### [117] [SCOOTER: A Human Evaluation Framework for Unrestricted Adversarial Examples](https://arxiv.org/abs/2507.07776)
**中文标题：Error**

*Dren Fazlija,Monty-Maximilian Zühlke,Johanna Schrader,Arkadij Orlov,Clara Stein,Iyiola E. Olatunji,Daniel Kudenko*

主要分类: cs.CV

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [118] [Where are we with calibration under dataset shift in image classification?](https://arxiv.org/abs/2507.07780)
**中文标题：图像分类中数据集偏移下的校准现状如何？**

*Mélanie Roschewitz,Raghav Mehta,Fabio de Sousa Ribeiro,Ben Glocker*

主要分类: cs.CV

摘要简述: 本文通过广泛研究图像分类中数据集偏移下的校准状态，提供了关于后处理和训练中校准技术选择的重要见解，并为实践者提供了在偏移下实现稳健校准的实用指南。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索真实世界数据集偏移下图像分类模型的校准状态，为实践者提供有效的校准方法和策略。

研究方法: 方法包括比较多种后处理校准方法及其与训练中校准策略（如标签平滑）的交互作用，覆盖多个自然偏移场景和八种不同分类任务。

研究结果: 研究发现：同时应用熵正则化和标签平滑在数据集偏移下表现最佳；后处理校准器在少量语义分布外数据下最稳健；新校准方法未必优于简单后处理方法；改善偏移校准可能牺牲分布内校准。

研究结论: 结论表明，结合基础模型微调和集成方法能显著提升校准鲁棒性，且校准在集成前进行更有效。

中文摘要: 我们对图像分类中真实世界数据集偏移下的校准状态进行了广泛研究，为后处理和训练中校准技术的选择提供了重要见解，并为实践者提供了在偏移下实现稳健校准的实用指南。我们比较了多种后处理校准方法及其与常见训练中校准策略（如标签平滑）的交互作用，覆盖了多个自然偏移场景和八种不同分类任务。研究发现：（i）同时应用熵正则化和标签平滑在数据集偏移下表现最佳；（ii）后处理校准器在少量语义分布外数据下最稳健；（iii）针对偏移设计的新校准方法未必优于简单后处理方法；（iv）改善偏移校准可能牺牲分布内校准。这些发现适用于随机初始化的分类器以及基于基础模型微调的分类器，后者通常比从头训练的模型校准效果更好。最后，我们深入分析了集成效果，发现：（i）在集成前进行校准更有效；（ii）对于集成，分布外数据会恶化分布内偏移校准的权衡；（iii）集成仍是提升校准鲁棒性的最有效方法之一，结合基础模型微调可获得最佳校准效果。

</details>


### [119] [SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes](https://arxiv.org/abs/2507.07781)
**中文标题：SURPRISE3D：复杂3D场景中的空间理解与推理数据集**

*Jiaxin Huang,Ziwen Li,Hanlve Zhang,Runnan Chen,Xiao He,Yandong Guo,Wenping Wang,Tongliang Liu,Mingming Gong*

主要分类: cs.CV

摘要简述: 本文介绍了SURPRISE3D数据集，旨在评估复杂3D场景中的语言引导空间推理分割能力，包含20万+视觉语言对和89k+人工标注的空间查询，挑战现有3D视觉和语言模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D视觉语言研究中，空间推理能力未得到充分探索，现有数据集常混淆语义线索与空间上下文，导致模型依赖表面捷径而非真正理解空间关系。为解决这一问题，作者提出了SURPRISE3D数据集。

研究方法: SURPRISE3D基于ScanNet++ v2的900+室内场景，包含20万+视觉语言对和89k+人工标注的空间查询，刻意避免使用物体名称以减少偏见，覆盖多种空间推理技能（如相对位置、叙述视角、参数视角和绝对距离推理）。

研究结果: 初步测试表明，当前最先进的3D视觉定位方法和3D-LLMs在SURPRISE3D上表现不佳，凸显了该数据集和3D-SRS基准套件的必要性。

研究结论: SURPRISE3D和3D-SRS旨在推动空间感知AI的发展，为有效的具身交互和机器人规划铺平道路。

中文摘要: 语言与3D感知的结合对于具身AI和机器人系统感知、理解并与物理世界交互至关重要。空间推理作为理解物体间空间关系的关键能力，在当前3D视觉语言研究中尚未充分探索。现有数据集常将语义线索（如物体名称）与空间上下文混合，导致模型依赖表面捷径而非真正解析空间关系。为填补这一空白，我们提出了SURPRISE3D，一个新颖的数据集，用于评估复杂3D场景中的语言引导空间推理分割。SURPRISE3D包含来自ScanNet++ v2的900+详细室内场景中的20万+视觉语言对，涵盖2.8k+独特物体类别。数据集包含89k+人工标注的空间查询，刻意避免使用物体名称以减少空间理解中的捷径偏见。这些查询全面覆盖多种空间推理技能，如相对位置、叙述视角、参数视角和绝对距离推理。初步基准测试表明，当前最先进的3D视觉定位方法和3D-LLMs面临显著挑战，凸显了我们数据集及配套3D空间推理分割（3D-SRS）基准套件的必要性。SURPRISE3D和3D-SRS旨在推动空间感知AI的发展，为有效的具身交互和机器人规划铺平道路。代码和数据集可在https://github.com/liziwennba/SUPRISE找到。

</details>


### [120] [Robust and Generalizable Heart Rate Estimation via Deep Learning for Remote Photoplethysmography in Complex Scenarios](https://arxiv.org/abs/2507.07795)
**中文标题：基于深度学习的复杂场景下远程光电容积描记术心率估计的鲁棒性与泛化性研究**

*Kang Cen,Chang-Hong Fu,Hong Hong*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的端到端远程光电容积描记术（rPPG）提取网络，通过3D卷积神经网络和差分帧融合模块，结合自注意力机制和动态混合损失函数，显著提升了复杂场景下的心率估计准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的远程光电容积描记术（rPPG）网络模型在复杂场景下的准确性、鲁棒性和泛化能力仍面临挑战，本文旨在解决这些问题。

研究方法: 提出了一种端到端的rPPG提取网络，采用3D卷积神经网络重建rPPG信号；引入差分帧融合模块捕捉血容量脉冲变化；结合时间移位模块（TSM）和自注意力机制增强特征；设计了动态混合损失函数以减少过拟合。

研究结果: 在PURE、UBFC-rPPG和MMPD数据集上的实验表明，该模型在复杂场景下表现优异，训练于PURE后在MMPD测试集上的平均绝对误差（MAE）为7.58，优于现有最佳模型。

研究结论: 本文提出的方法在复杂场景下显著提升了rPPG心率估计的鲁棒性和泛化能力，为远程心率监测提供了更可靠的解决方案。

中文摘要: 非接触式远程光电容积描记术（rPPG）技术可通过面部视频测量心率，但现有网络模型在复杂场景下的准确性、鲁棒性和泛化能力仍存在挑战。本文提出了一种端到端的rPPG提取网络，利用3D卷积神经网络从原始面部视频中重建准确的rPPG信号。我们引入了差分帧融合模块，将差分帧与原始帧结合，使帧级表征能够捕捉血容量脉冲（BVP）的变化。此外，我们结合了时间移位模块（TSM）与自注意力机制，以最小的计算开销有效增强rPPG特征。进一步，我们提出了一种新颖的动态混合损失函数，为网络提供了更强的监督，有效缓解了过拟合问题。我们在PURE、UBFC-rPPG以及复杂场景下的MMPD数据集上进行了全面实验，包括数据集内和跨数据集评估，结果表明我们的网络具有卓越的鲁棒性和泛化能力。具体而言，在PURE上训练后，我们的模型在MMPD测试集上的平均绝对误差（MAE）为7.58，优于现有最佳模型。

</details>


### [121] [Visual Instance-aware Prompt Tuning](https://arxiv.org/abs/2507.07796)
**中文标题：视觉实例感知提示调优**

*Xi Xiao,Yunbei Zhang,Xingjian Li,Tianyang Wang,Xiao Wang,Yuxiang Wei,Jihun Hamm,Min Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViaPT的视觉实例感知提示调优方法，通过为每个输入生成实例感知提示并结合数据集级提示，显著提升了视觉Transformer的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的视觉提示调优方法使用数据集级提示，导致性能不佳，因为下游数据集存在高方差。本文旨在解决这一问题，提出实例感知提示调优方法。

研究方法: ViaPT通过为每个输入生成实例感知提示，并与数据集级提示融合，利用主成分分析（PCA）保留重要提示信息，同时平衡数据集级和实例级知识。

研究结果: 在34个多样化数据集上的实验表明，ViaPT显著优于现有基线方法，成为视觉提示调优的新范式。

研究结论: ViaPT通过实例感知提示调优，有效解决了传统方法的局限性，为视觉Transformer的性能优化提供了新方向。

中文摘要: 视觉提示调优（VPT）已成为视觉Transformer的参数高效微调范式，传统方法使用数据集级提示，所有输入实例共享相同的提示。我们观察到，由于下游数据集的高方差，这种策略导致性能不佳。为解决这一问题，我们提出了视觉实例感知提示调优（ViaPT），该方法基于每个输入生成实例感知提示，并将其与数据集级提示融合，利用主成分分析（PCA）保留重要提示信息。此外，我们发现VPT-Deep和VPT-Shallow是基于概念理解的两种极端情况，它们未能有效捕捉实例特定信息，而随机维度缩减的提示性能仅介于两者之间。ViaPT通过平衡数据集级和实例级知识，同时减少可学习参数数量，克服了这些限制。在34个多样化数据集上的广泛实验表明，我们的方法始终优于最先进的基线方法，为视觉提示的分析和优化建立了新范式。

</details>


### [122] [Synergistic Prompting for Robust Visual Recognition with Missing Modalities](https://arxiv.org/abs/2507.07802)
**中文标题：协同提示：面向模态缺失的稳健视觉识别**

*Zhihui Zhang,Luanyuan Dai,Qika Lin,Yunfeng Diao,Guangyin Jin,Yufei Guo,Jing Zhang,Xiaoshuai Hao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为协同提示（SyP）的新框架，用于解决多模态视觉识别中模态缺失导致的性能下降问题。通过动态适配器和协同提示策略，SyP能够灵活适应不同缺失条件并保持稳健性能。


<details>
  <summary>详细信息</summary>
研究动机: 现实应用中，多模态数据的缺失或不完整会导致性能显著下降。现有基于提示的方法存在静态提示缺乏灵活性和基础提示调优在关键模态缺失时性能不可靠的问题。

研究方法: SyP框架包含两个关键创新：动态适配器（动态生成提示以替代静态参数）和协同提示策略（结合静态与动态提示以平衡模态信息）。

研究结果: 在三个广泛使用的视觉识别数据集上，SyP显著优于现有方法，并在不同缺失率和条件下表现出稳健性。

研究结论: SyP通过动态适配和协同提示策略，有效解决了多模态缺失问题，展示了卓越的适应性和可靠性。

中文摘要: 大规模多模态模型通过利用大量配对多模态训练数据，在各种视觉识别任务中表现出卓越性能。然而，在实际应用中，模态输入缺失或不完整往往导致性能显著下降。近期研究聚焦于基于提示的策略以解决此问题，但现有方法受限于两大缺陷：（1）静态提示缺乏适应不同缺失条件的灵活性；（2）基础提示调优方法在关键模态缺失时难以确保可靠性能。为解决这些挑战，我们提出了一种新颖的协同提示（SyP）框架，用于处理模态缺失的稳健视觉识别。SyP引入两项关键创新：（I）动态适配器，通过计算自适应缩放因子动态生成提示，替代静态参数以实现灵活的多模态适应；（II）协同提示策略，结合静态与动态提示以平衡模态信息，确保即使在关键模态缺失时也能稳健推理。SyP在三个广泛使用的视觉识别数据集上显著优于现有方法，展示了在不同缺失率和条件下的稳健性。大量实验和消融研究验证了其在处理模态缺失中的有效性，凸显了其卓越的适应性和可靠性。

</details>


### [123] [Patient-specific vs Multi-Patient Vision Transformer for Markerless Tumor Motion Forecasting](https://arxiv.org/abs/2507.07811)
**中文标题：患者特异性与多患者视觉Transformer在无标记肿瘤运动预测中的比较**

*Gauthier Rotsart de Hertaing,Dani Manjah,Benoit Macq*

主要分类: cs.CV

摘要简述: 本文首次将Vision Transformer（ViT）架构应用于无标记肿瘤运动预测，比较了患者特异性（PS）和多患者（MP）训练策略。PS模型在精度上表现更优，而MP模型在无需重新训练的情况下展现出更强的鲁棒性，适合临床时间受限的场景。


<details>
  <summary>详细信息</summary>
研究动机: 精确预测肺部肿瘤运动对质子治疗中的剂量精准投递至关重要。尽管当前无标记方法多依赖深度学习，但基于Transformer的架构在此领域尚未被探索。本文旨在评估ViT在无标记肿瘤运动预测中的表现，并比较PS和MP两种训练策略的优劣。

研究方法: 研究使用31名患者的4DCT扫描生成的数字重建放射影像（DRR）训练MP模型，另1名患者用于评估。PS模型仅使用目标患者的规划数据。两种模型均以16张DRR为输入，预测1秒内的肿瘤运动。性能通过平均位移误差（ADE）和最终位移误差（FDE）在规划（T1）和治疗（T2）数据上评估。

研究结果: 在T1数据上，PS模型在所有训练集规模下均优于MP模型，尤其在较大数据集（最多25,000张DRR）时差异显著（p < 0.05）。然而，MP模型对分次间解剖变异表现出更强的鲁棒性，且在T2数据上无需重新训练即可达到与PS模型相当的性能。

研究结论: 本研究首次将ViT应用于无标记肿瘤运动预测。PS模型精度更高，而MP模型在无需重新训练的情况下表现稳健，适合临床时间受限的场景。

中文摘要: 背景：精确预测肺部肿瘤运动对质子治疗中的剂量精准投递至关重要。当前无标记方法多依赖深度学习，但基于Transformer的架构在此领域尚未被探索，尽管其在轨迹预测中表现优异。
目的：本研究提出一种基于视觉Transformer（ViT）的无标记肿瘤运动预测方法，评估了两种训练策略：患者特异性（PS）模型学习个体化运动模式，多患者（MP）模型设计用于泛化。比较明确考虑了规划与治疗会话间可生成图像数量的限制。
方法：使用31名患者规划4DCT扫描生成的数字重建放射影像（DRR）训练MP模型；第32名患者用于评估。PS模型仅使用目标患者的规划数据。两种模型均以16张DRR为输入，预测1秒内的肿瘤运动。性能通过平均位移误差（ADE）和最终位移误差（FDE）在规划（T1）和治疗（T2）数据上评估。
结果：在T1数据上，PS模型在所有训练集规模下均优于MP模型，尤其在较大数据集（最多25,000张DRR）时差异显著（p < 0.05）。然而，MP模型对分次间解剖变异表现出更强的鲁棒性，且在T2数据上无需重新训练即可达到与PS模型相当的性能。
结论：本研究首次将ViT架构应用于无标记肿瘤运动预测。PS模型精度更高，而MP模型提供稳健的开箱即用性能，适合时间受限的临床场景。

</details>


### [124] [Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles](https://arxiv.org/abs/2507.07828)
**中文标题：基于内容的拼图求解器在损坏拼图上的基准测试**

*Richard Dirauf,Florian Wolz,Dario Zanca,Björn Eskofier*

主要分类: cs.CV

摘要简述: 本文研究了基于内容的拼图求解器在拼图损坏情况下的鲁棒性，发现现有方法在缺失、边缘或内容损坏时性能显著下降，但深度学习模型通过数据增强能显著提升鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于内容的拼图求解器在真实场景（如文物碎片或文件碎片的复原）中缺乏对损坏拼图的评估，本文旨在填补这一空白。

研究方法: 引入三种拼图损坏类型（缺失、边缘腐蚀、内容腐蚀），评估启发式和深度学习求解器的表现，并通过数据增强优化深度学习模型。

研究结果: 标准拼图求解器在损坏增加时性能迅速下降，但深度学习模型（尤其是位置扩散模型）通过微调显著提升了鲁棒性。

研究结论: 深度学习模型在拼图损坏情况下表现更优，未来研究应关注其在真实场景中的应用优化。

中文摘要: 基于内容的拼图求解器已被广泛研究，其计算技术取得了显著进展。然而，其评估往往缺乏对真实场景（如文物碎片或文件碎片的复原）至关重要的挑战。本文研究了现有最先进的基于内容的拼图求解器的鲁棒性，引入了三种拼图损坏类型：缺失碎片、边缘腐蚀和内容腐蚀。通过评估启发式和基于深度学习的求解器，分析了它们处理这些损坏的能力并识别了关键局限性。结果显示，标准拼图求解器在损坏增加时性能迅速下降，但深度学习模型通过数据增强的微调能显著提升鲁棒性。值得注意的是，高级位置扩散模型表现尤为突出，在多数实验中优于其他方法。基于研究结果，我们提出了提升真实场景文物自动复原的潜在研究方向。

</details>


### [125] [Rethinking Query-based Transformer for Continual Image Segmentation](https://arxiv.org/abs/2507.07831)
**中文标题：重新思考基于查询的Transformer在持续图像分割中的应用**

*Yuchen Zhu,Cheng Shi,Dingyou Wang,Jiajin Tang,Zhengxuan Wei,Yu Wu,Guanbin Li,Sibei Yang*

主要分类: cs.CV

摘要简述: 本文提出SimCIS方法，通过直接选择图像特征进行查询分配，解决持续图像分割中的可塑性损失和数据顺序依赖问题，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 持续图像分割（CIS）中，现有方法因解耦掩码生成与持续学习过程，导致可塑性损失和过度依赖输入数据顺序。本文旨在通过深入研究内置对象性，提出更高效的解决方案。

研究方法: 提出SimCIS方法，直接选择图像特征进行查询分配，实现“完美对齐”以保留对象性，同时允许查询选择新类以增强可塑性。引入跨阶段一致性选择和基于“视觉查询”的重放机制。

研究结果: 实验表明，SimCIS在各种分割任务、设置、划分和数据顺序下均优于现有方法。

研究结论: SimCIS通过简单而有效的设计解决了CIS中的关键问题，为持续学习提供了新思路。

中文摘要: 持续图像分割（CIS）旨在分阶段训练图像分割器，每个阶段的可用类别集不同。现有方法通常解耦掩码生成与持续学习过程，以利用基于查询的Transformer内置对象性，减轻掩码提议的灾难性遗忘。然而，本研究指出解耦框架存在可塑性损失和过度依赖输入数据顺序的问题。为此，我们深入研究了内置对象性，发现高度聚合的图像特征为查询通过简单特征对齐生成掩码提供了捷径。基于此，我们提出SimCIS，一种简单而强大的CIS基线方法。其核心思想是直接选择图像特征进行查询分配，确保“完美对齐”以保留对象性，同时允许查询选择新类以增强可塑性。为进一步减轻类别灾难性遗忘，我们引入了跨阶段一致性选择和基于“视觉查询”的创新重放机制。实验表明，SimCIS在各种分割任务、设置、划分和数据顺序下均优于现有方法。所有模型和代码将在https://github.com/SooLab/SimCIS公开。

</details>


### [126] [3D-ADAM: A Dataset for 3D Anomaly Detection in Advanced Manufacturing](https://arxiv.org/abs/2507.07838)
**中文标题：3D-ADAM：先进制造中的3D异常检测数据集**

*Paul McHard,Florent P. Audonnet,Oliver Summerell,Sebastian Andraos,Paul Henderson,Gerardo Aragon-Camarasa*

主要分类: cs.CV

摘要简述: 3D-ADAM是首个大规模高精度3D工业异常检测数据集，包含14,120个高分辨率扫描和27,346个标注缺陷实例，覆盖12类工业表面缺陷，旨在推动鲁棒3D异常检测模型的发展。


<details>
  <summary>详细信息</summary>
研究动机: 工业制造中表面缺陷是导致低产量的主要原因，现有数据集难以反映真实工业场景，亟需高质量RGB+3D数据集以改进检测方法。

研究方法: 3D-ADAM数据集通过4种工业深度成像传感器采集14,120个高分辨率扫描，涵盖217个独特零件，包含27,346个标注缺陷和8,110个机械设计特征标注，模拟真实工业环境中的多种变量。

研究结果: 评估显示当前SOTA模型在3D-ADAM上表现不佳，验证了其挑战性；专家标注调查进一步证实了数据集的质量和工业相关性。

研究结论: 3D-ADAM为3D异常检测提供了具有挑战性的基准，有望加速鲁棒模型的开发，满足现代工业需求。

中文摘要: 表面缺陷是制造业低产量的主要因素之一，因此在制造过程中准确可靠地检测缺陷具有重要价值。当前自动化缺陷检测方法在现有数据集上表现优异，但在实际工业场景中仍显不足，改进方法依赖于能反映真实场景的大规模数据集。然而，高质量、高精度的RGB+3D工业异常检测数据集稀缺，且通常无法体现真实工业部署场景。为此，我们推出了3D-ADAM，首个大规模高精度3D异常检测数据集。3D-ADAM包含14,120个高分辨率扫描，覆盖217个独特零件，使用4种工业深度成像传感器采集，包含12类27,346个标注缺陷实例，涵盖工业表面缺陷的多样性。此外，3D-ADAM还标注了8,110个机械设计特征，覆盖相关机械设计形态。与现有数据集不同，3D-ADAM在真实工业环境中采集，包含零件位置与方向、相机位置、环境光照及部分遮挡等变量。我们对多种RGB+3D异常检测任务的SOTA模型进行评估，结果显示该数据集对现有方法提出了显著挑战。通过行业合作伙伴的专家标注调查，我们进一步验证了数据集的工业相关性和质量。3D-ADAM旨在通过提供这一具有挑战性的基准，加速开发能够满足现代工业需求的鲁棒3D异常检测模型。

</details>


### [127] [THUNDER: Tile-level Histopathology image UNDERstanding benchmark](https://arxiv.org/abs/2507.07860)
**中文标题：THUNDER：瓦片级病理学图像理解基准**

*Pierre Marza,Leo Fillioux,Sofiène Boutaj,Kunal Mahatha,Christian Desrosiers,Pablo Piantanida,Jose Dolz,Stergios Christodoulidis,Maria Vakalopoulou*

主要分类: cs.CV

摘要简述: THUNDER是一个用于数字病理学基础模型的瓦片级基准测试工具，旨在高效比较多种模型在多样化数据集和下游任务中的表现，同时分析特征空间、鲁棒性和预测不确定性。


<details>
  <summary>详细信息</summary>
研究动机: 数字病理学领域近期涌现大量基础模型，但缺乏统一的评估标准。THUNDER旨在填补这一空白，提供全面的模型比较，确保在医疗等关键领域中的可靠应用。

研究方法: THUNDER通过整合16个数据集和23种基础模型，设计了一系列下游任务，分析模型特征空间，并评估预测的鲁棒性和不确定性。

研究结果: THUNDER实现了对23种基础模型的全面比较，覆盖多样化任务和数据集，为数字病理学领域提供了可靠的基准测试工具。

研究结论: THUNDER是一个高效、易用且动态的基准测试工具，支持多种先进基础模型和用户自定义模型的直接比较，为数字病理学研究提供了重要支持。

中文摘要: 研究领域的进展往往难以评估，尤其是在短时间内涌现大量并发方法的情况下。数字病理学领域便是如此，近期发布了多种基础模型作为瓦片级图像的特征提取器，用于瓦片级和切片级的下游任务。因此，对现有方法进行基准测试变得至关重要，以便更清晰地了解研究现状。特别是在医疗等关键领域，基准测试不仅应关注下游性能评估，还需揭示方法间的主要差异，并进一步考虑不确定性和鲁棒性，以确保模型的可靠使用。为此，我们提出了THUNDER，一个用于数字病理学基础模型的瓦片级基准测试工具，支持在多样化数据集和下游任务中高效比较多种模型，分析其特征空间，并评估基于嵌入的预测的鲁棒性和不确定性。THUNDER是一个快速、易用且动态的基准测试工具，已支持多种先进基础模型及用户自定义模型的直接瓦片级比较。本文对23种基础模型在16个不同数据集上的表现进行了全面比较，涵盖多样化任务、特征分析和鲁棒性评估。THUNDER的代码已公开于https://github.com/MICS-Lab/thunder。

</details>


### [128] [Single-Step Latent Diffusion for Underwater Image Restoration](https://arxiv.org/abs/2507.07878)
**中文标题：单步潜在扩散用于水下图像恢复**

*Jiayi Wu,Tianfu Wang,Md Abu Bakr Siddique,Md Jahidul Islam,Cornelia Fermuller,Yiannis Aloimonos,Christopher A. Metzler*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SLURPP的新型网络架构，结合预训练的潜在扩散模型和显式场景分解，用于水下图像恢复。该方法通过物理合成数据生成管道训练，显著提升了恢复效果和速度，比现有方法快200倍，并在PSNR上提升约3 dB。


<details>
  <summary>详细信息</summary>
研究动机: 水下图像恢复在海洋生态、水产养殖和考古等领域至关重要。现有基于扩散的方法在复杂场景中计算量大且易产生不真实伪影，因此需要一种更高效且准确的方法。

研究方法: SLURPP结合了预训练的潜在扩散模型（编码场景几何和深度先验）与显式场景分解（建模光衰减和背散射效应）。通过物理合成数据生成管道，将多样化的水下退化效果应用于陆地图像数据集，生成带注释的训练数据。

研究结果: SLURPP在合成和真实世界基准测试中表现优异，比现有扩散方法快200倍，PSNR提升约3 dB，且在真实数据上展现出显著的定性改进。

研究结论: SLURPP通过结合潜在扩散模型和显式场景分解，显著提升了水下图像恢复的速度和质量，为复杂场景下的图像恢复提供了高效解决方案。

中文摘要: 水下图像恢复算法旨在恢复水下场景的颜色、对比度和外观，广泛应用于海洋生态、水产养殖和水下考古等领域。现有的基于像素域扩散的方法在深度变化有限的简单场景中有效，但在复杂几何和显著深度变化的场景中计算量大且易产生不真实伪影。本文通过结合新型网络架构（SLURPP）和精确的合成数据生成管道克服了这些限制。SLURPP将预训练的潜在扩散模型（编码场景几何和深度先验）与显式场景分解（建模光衰减和背散射效应）相结合。为训练SLURPP，我们设计了一种基于物理的水下图像合成管道，将多样化和真实的水下退化效果应用于现有陆地图像数据集，生成带密集介质/退化注释的训练数据。我们在合成和真实世界基准测试中广泛评估了该方法，并展示了其领先性能。值得注意的是，SLURPP比现有基于扩散的方法快200倍以上，在合成基准测试中PSNR提升约3 dB，且在真实数据上展现出显著的定性改进。项目网站：https://tianfwang.github.io/slurpp/。

</details>


### [129] [MIRA: A Novel Framework for Fusing Modalities in Medical RAG](https://arxiv.org/abs/2507.07902)
**中文标题：MIRA：一种融合多模态的医学检索增强生成新框架**

*Jinhong Wang,Tajamul Ashraf,Zongyan Han,Jorma Laaksonen,Rao Mohammad Anwer*

主要分类: cs.CV

摘要简述: MIRA是一种新型多模态医学RAG框架，通过动态调整检索内容和整合图像嵌入与医学知识库，显著提升多模态大语言模型的事实准确性，并在公开医学VQA和报告生成基准测试中取得最优结果。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型在医学诊断中常生成与医学知识不符的答案，而检索增强生成（RAG）虽能提升事实准确性，却面临检索不足或过度检索的问题，导致信息遗漏或误导。MIRA旨在解决这些问题，优化模型的事实准确性。

研究方法: MIRA包含两个核心模块：1）校准的“重新思考与重排”模块，动态调整检索上下文数量以管理事实风险；2）整合图像嵌入和医学知识库的医学RAG框架，结合查询重写模块实现高效多模态推理。

研究结果: 在公开医学VQA和报告生成基准测试中，MIRA显著提升了事实准确性和整体性能，达到了新的最优水平。

研究结论: MIRA通过动态检索调整和多模态整合，有效解决了医学RAG中的关键挑战，为多模态大语言模型在医学领域的应用提供了更可靠的解决方案。

中文摘要: 多模态大语言模型（MLLMs）显著推动了AI辅助医学诊断的发展，但其生成的答案常与医学知识不符。检索增强生成（RAG）通过整合外部资源提升事实准确性，但仍面临两大挑战：检索不足可能遗漏关键信息，而过度检索则可能引入无关或误导性内容；此外，模型即使初始答案正确，过度依赖检索数据也可能导致事实错误。为解决这些问题，我们提出了多模态智能检索与增强（MIRA）框架，旨在优化MLLM的事实准确性。MIRA包含两个核心组件：1）校准的“重新思考与重排”模块，动态调整检索上下文数量以管理事实风险；2）整合图像嵌入和医学知识库的医学RAG框架，结合查询重写模块实现高效多模态推理。在公开医学VQA和报告生成基准测试中，MIRA显著提升了事实准确性和整体性能，达到了新的最优水平。代码发布于https://github.com/mbzuai-oryx/MIRA。

</details>


### [130] [Hardware-Aware Feature Extraction Quantisation for Real-Time Visual Odometry on FPGA Platforms](https://arxiv.org/abs/2507.07903)
**中文标题：面向FPGA平台的硬件感知特征提取量化方法用于实时视觉里程计**

*Mateusz Wasala,Mateusz Smolarczyk,Michal Danilowicz,Tomasz Kryjak*

主要分类: cs.CV

摘要简述: 本文提出了一种基于量化SuperPoint卷积神经网络的嵌入式实现方法，用于实时视觉里程计任务，通过硬件感知优化在FPGA平台上实现了高效处理。


<details>
  <summary>详细信息</summary>
研究动机: 现代导航系统（如自动驾驶车辆、无人机等）需要精确的位置估计，而视觉里程计（VSLAM）依赖于从视觉输入数据中可靠提取特征点。本文旨在减少模型计算需求，同时保持高检测质量，以便在资源有限的平台上高效部署。

研究方法: 采用量化SuperPoint卷积神经网络，结合Brevitas库和FINN框架进行模型量化和硬件感知优化，并在AMD/Xilinx Zynq UltraScale+ FPGA平台上实现。

研究结果: 在FPGA平台上实现了640x480像素图像处理速度达54 fps，优于现有技术，并通过TUM数据集验证了不同量化技术对模型精度和性能的影响。

研究结论: 本文提出的硬件感知特征提取量化方法在FPGA平台上实现了高效的视觉里程计任务处理，为资源受限的嵌入式系统提供了可行的解决方案。

中文摘要: 精确的位置估计对于现代导航系统（如自动驾驶车辆、船舶和无人机）至关重要。视觉同时定位与建图（VSLAM）中的视觉里程计高度依赖于从视觉输入数据中可靠提取显著特征点。本文提出了一种嵌入式实现的无监督架构，能够检测和描述特征点，基于量化的SuperPoint卷积神经网络。目标是减少模型的计算需求，同时保持高检测质量，从而在资源有限的平台（如移动或嵌入式系统）上高效部署。我们在AMD/Xilinx Zynq UltraScale+ FPGA系统芯片平台上实现了该方案，评估了深度学习处理单元（DPU）的性能，并使用Brevitas库和FINN框架进行模型量化和硬件感知优化。这使得我们能够在FPGA平台上以高达54 fps的速度处理640x480像素的图像，优于该领域的现有技术。我们在TUM数据集上进行了实验，以展示和讨论不同量化技术对视觉里程计任务中模型精度和性能的影响。

</details>


### [131] [Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement](https://arxiv.org/abs/2507.07908)
**中文标题：不仅一致性：利用时空不一致性增强远程生理测量的测试时适应**

*Xiao Yang,Yuxuan Fan,Can Liu,Houcheng Su,Weichen Guo,Jiyao Wang,Dengbo He*

主要分类: cs.CV

摘要简述: 本文提出了一种针对远程光电容积描记术（rPPG）任务的完全测试时适应（TTA）策略，通过结合时空一致性和不一致性先验知识，设计了一个自监督的CiCi框架，并引入梯度动态控制机制以稳定适应性能。实验表明，该方法在无需源数据的情况下实现了实时自监督适应，性能优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 远程光电容积描记术（rPPG）是一种非侵入性生理信号监测方法，但现有域适应和泛化方法在隐私和实时性方面存在限制。本文旨在提出一种完全测试时适应策略，以解决这些问题并提升模型在未知环境中的适应性。

研究方法: 基于生理学先验知识和观察，本文发现rPPG信号在频域具有时空一致性，而在时域存在显著不一致性。为此，提出了一种自监督的CiCi框架，结合一致性和不一致性先验知识，并引入梯度动态控制机制以避免先验冲突，确保稳定的适应性能。

研究结果: 在五个不同数据集上的实验表明，该方法在测试时适应协议下表现优于现有技术，无需源数据即可实现实时自监督适应，达到了最先进的性能。

研究结论: 本文提出的CiCi框架通过结合时空一致性和不一致性先验知识，成功提升了rPPG任务的测试时适应能力，为实时生理信号监测提供了有效解决方案。

中文摘要: 远程光电容积描记术（rPPG）已成为一种利用摄像头监测生理信号的非侵入性方法。尽管已有多种域适应和泛化方法被提出以提升深度rPPG模型在未知部署环境中的适应性，但隐私问题和实时适应需求限制了其实际应用。因此，本文旨在为rPPG任务提出一种全新的完全测试时适应（TTA）策略。具体而言，基于生理学先验知识和观察，我们发现rPPG信号不仅在频域具有时空一致性，在时域也存在显著不一致性。为此，我们提出了一种基于专家知识的自监督一致性-不一致性整合（CiCi）框架，通过结合这两种先验知识来增强模型在推理过程中的适应能力。此外，我们的方法还引入了梯度动态控制机制，以缓解先验之间的潜在冲突，确保跨实例的稳定适应。通过在五个不同数据集上的TTA协议实验，我们的方法在无需源数据的情况下，实现了实时自监督适应，性能优于现有技术，达到了最先进的水平。代码将在后续发布。

</details>


### [132] [Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and Identification Strategies for Laboratory Mice](https://arxiv.org/abs/2507.07929)
**中文标题：迈向连续笼内监测：实验室小鼠跟踪与识别策略的评估**

*Juan Pablo Oberhauser,Daniel Grzenda*

主要分类: cs.CV

摘要简述: 本文提出了一种实时识别算法，用于在数字笼中监测实验室小鼠，通过结合外观和运动线索的多目标跟踪器、基于Transformer的ID分类器和轨迹关联线性程序，显著提高了跟踪效率和ID准确性。


<details>
  <summary>详细信息</summary>
研究动机: 实验室小鼠的连续自动化监测能提供更精确的数据并改善动物福利，但由于小鼠的高密度饲养、相似外观和高活动性，提供个体指标存在挑战。本文旨在解决这些问题。

研究方法: 方法包括三部分：(1) 结合小鼠外观和运动线索的多目标跟踪器MouseTracks；(2) 基于Transformer的ID分类器Mouseformer；(3) 轨迹关联线性程序MouseMap，用于分配最终ID预测。

研究结果: 实验表明，该算法能以每秒30帧的速度准确分配ID，并在不同小鼠品系和环境因素下显著提高跟踪效率，减少ID切换。

研究结论: 本文提出的跟踪和ID算法优于现有方法，为实验室小鼠的连续监测提供了高效且可靠的解决方案。

中文摘要: 连续、自动化的实验室小鼠监测能够实现更精确的数据采集，并通过实时洞察改善动物福利。通过将行为和生理监测整合到笼内，研究人员可以更动态且临床相关地描述疾病进展和治疗效果。然而，由于小鼠的高密度饲养、相似外观、高活动性和频繁互动，提供个体指标存在困难。为解决这些挑战，我们开发了一种实时识别（ID）算法，能够准确为佩戴定制耳标的小鼠分配ID预测，这些小鼠由摄像头监控的数字笼内饲养。我们的流程包括三部分：(1) 结合小鼠外观和运动线索的定制多目标跟踪器（MouseTracks）；(2) 基于Transformer的ID分类器（Mouseformer）；(3) 轨迹关联线性程序，用于为轨迹分配最终ID预测（MouseMap）。我们的模型能以每秒30帧的速度基于定制耳标为动物分配ID，并提供24/7的笼内覆盖。实验表明，与现有小鼠跟踪方法相比，我们的定制跟踪和ID流程提高了跟踪效率，并在不同小鼠品系和环境因素下减少了ID切换。

</details>


### [133] [TinierHAR: Towards Ultra-Lightweight Deep Learning Models for Efficient Human Activity Recognition on Edge Devices](https://arxiv.org/abs/2507.07949)
**中文标题：TinierHAR：面向边缘设备的高效人类活动识别的超轻量级深度学习模型**

*Sizhen Bian,Mengxi Liu,Vitor Fortes Rey,Daniel Geissler,Paul Lukowicz*

主要分类: cs.CV

摘要简述: 本文提出了一种超轻量级深度学习模型TinierHAR，用于在资源受限的边缘设备上高效实现人类活动识别（HAR）。该模型结合了残差深度可分离卷积、门控循环单元（GRU）和时间聚合技术，显著降低了参数数量和计算量，同时保持了性能。


<details>
  <summary>详细信息</summary>
研究动机: 在资源受限的可穿戴设备上实现高效的人类活动识别（HAR）需要兼顾准确性和计算效率。现有模型往往在效率和性能之间难以平衡，因此需要一种更轻量化的解决方案。

研究方法: TinierHAR采用残差深度可分离卷积、门控循环单元（GRU）和时间聚合技术，构建了一个超轻量级的深度学习架构。通过系统消融实验，分析了空间和时间组件对模型性能的贡献。

研究结果: 在14个公开HAR数据集上的实验表明，TinierHAR相比TinyHAR和DeepConvLSTM，分别减少了2.7倍和43.3倍的参数数量，以及6.4倍和58.6倍的计算量（MACs），同时保持了平均F1分数。

研究结论: TinierHAR为边缘设备上的HAR提供了一种高效且轻量化的解决方案，并通过系统分析为未来高效HAR系统的设计提供了指导。所有研究材料已开源以促进相关研究。

中文摘要: 在资源受限的可穿戴设备上实现人类活动识别（HAR）需要兼顾准确性和计算效率的推理模型。本文提出了一种超轻量级深度学习架构TinierHAR，结合了残差深度可分离卷积、门控循环单元（GRU）和时间聚合技术，在不牺牲性能的情况下实现了最优效率。在14个公开HAR数据集上的评估显示，TinierHAR相比TinyHAR和DeepConvLSTM，分别减少了2.7倍和43.3倍的参数数量，以及6.4倍和58.6倍的计算量（MACs），同时保持了平均F1分数。此外，本研究首次通过系统消融实验分析了空间和时间组件在TinierHAR、TinyHAR和经典DeepConvLSTM中的贡献，为设计高效HAR系统提供了实用见解。最后，我们讨论了研究结果，并提出了未来高效HAR系统的设计原则。为促进边缘HAR研究，本研究的所有材料均已开源。

</details>


### [134] [Martian World Models: Controllable Video Synthesis with Physically Accurate 3D Reconstructions](https://arxiv.org/abs/2507.07978)
**中文标题：火星世界模型：基于物理精确3D重建的可控视频合成**

*Longfei Li,Zhiwen Fan,Wenyan Cong,Xinhang Liu,Yuyang Yin,Matt Foutter,Panwang Pan,Chenyu You,Yue Wang,Zhangyang Wang,Yao Zhao,Marco Pavone,Yunchao Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种合成火星景观视频的方法，通过数据重建和视频生成技术解决了火星数据稀缺和与地球图像的领域差异问题。


<details>
  <summary>详细信息</summary>
研究动机: 合成真实的火星景观视频对于任务演练和机器人模拟至关重要，但由于高质量火星数据的稀缺以及与地球图像的显著差异，这一任务面临挑战。

研究方法: 方法包括两个关键部分：1) 数据重建引擎M3arsSynth，从NASA的真实立体导航图像中重建3D火星环境，并渲染高保真的多视角3D视频序列；2) 火星地形视频生成器MarsGen，基于初始图像帧和可选条件（如相机轨迹或文本提示）合成视觉逼真且几何一致的新视频。

研究结果: 实验结果表明，该方法优于基于地球数据集训练的视频合成模型，在视觉保真度和3D结构一致性方面表现更优。

研究结论: 本文提出的方法能够生成物理精确的火星3D表面模型，并合成高质量的视频，为火星任务模拟提供了有效工具。

中文摘要: 合成真实的火星景观视频对于任务演练和机器人模拟至关重要。然而，由于高质量火星数据的稀缺以及与地球图像的显著领域差异，这一任务面临独特挑战。为解决这些问题，我们提出了一种整体解决方案，包含两个关键部分：1) 数据重建引擎Multimodal Mars Synthesis (M3arsSynth)，从NASA行星数据系统(PDS)的真实立体导航图像中重建3D火星环境，并渲染高保真的多视角3D视频序列；2) 火星地形视频生成器MarsGen，合成视觉逼真且与数据中编码的3D结构几何一致的新视频。M3arsSynth引擎覆盖了广泛的火星地形和采集日期，能够生成物理精确的3D表面模型，分辨率达到米级。MarsGen在M3arsSynth数据上微调，可根据初始图像帧以及可选条件（如相机轨迹或文本提示）合成视频，从而支持在新环境中生成视频。实验结果表明，我们的方法优于基于地球数据集训练的视频合成模型，在视觉保真度和3D结构一致性方面表现更优。

</details>


### [135] [Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling](https://arxiv.org/abs/2507.07982)
**中文标题：几何强制：将视频扩散与3D表示结合以实现一致的世界建模**

*Haoyu Wu,Diankun Wu,Tianyu He,Junliang Guo,Yang Ye,Yueqi Duan,Jiang Bian*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Geometry Forcing的方法，通过将视频扩散模型与预训练的几何基础模型对齐，提升视频生成任务中的3D一致性和视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视频扩散模型仅基于原始视频数据训练，往往无法捕捉到几何感知的结构。为了弥补视频扩散模型与物理世界3D本质之间的差距，本文旨在通过几何引导提升模型的3D表示能力。

研究方法: Geometry Forcing通过两种互补的对齐目标实现：角度对齐（通过余弦相似性强制方向一致性）和尺度对齐（通过回归未归一化的几何特征保留尺度信息）。该方法将视频扩散模型的中间表示与预训练的几何基础模型特征对齐。

研究结果: 实验结果表明，Geometry Forcing在相机视角条件和动作条件视频生成任务中，显著提升了视觉质量和3D一致性，优于基线方法。

研究结论: Geometry Forcing通过几何引导有效提升了视频扩散模型的3D表示能力，为动态3D世界的建模提供了更一致的方法。

中文摘要: 视频本质上是动态3D世界的2D投影。然而，我们的分析表明，仅基于原始视频数据训练的视频扩散模型往往无法在其学习表示中捕捉到有意义的几何感知结构。为了弥补视频扩散模型与物理世界3D本质之间的差距，我们提出了Geometry Forcing，这是一种简单而有效的方法，旨在鼓励视频扩散模型内化潜在的3D表示。我们的关键见解是通过将模型的中间表示与预训练的几何基础模型特征对齐，引导其朝向几何感知结构。为此，我们引入了两种互补的对齐目标：角度对齐（通过余弦相似性强制方向一致性）和尺度对齐（通过回归未归一化的几何特征保留尺度信息）。我们在相机视角条件和动作条件视频生成任务上评估了Geometry Forcing。实验结果表明，我们的方法在视觉质量和3D一致性方面显著优于基线方法。项目页面：https://GeometryForcing.github.io。

</details>


### [136] [OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding](https://arxiv.org/abs/2507.07984)
**中文标题：OST-Bench：评估多模态大语言模型在线时空场景理解能力**

*JingLi Lin,Chenming Zhu,Runsen Xu,Xiaohan Mao,Xihui Liu,Tai Wang,Jiangmiao Pang*

主要分类: cs.CV

摘要简述: OST-Bench是一个评估多模态大语言模型（MLLMs）在线时空场景理解能力的新基准，包含1.4k场景和10k问答对，发现现有模型在复杂时空推理任务上表现不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准多基于离线固定输入，无法反映真实世界中动态探索场景的需求，因此提出OST-Bench以评估模型在线时空理解能力。

研究方法: 基于ScanNet、Matterport3D和ARKitScenes构建高效数据收集流程，创建包含1.4k场景和10k问答对的OST-Bench，并评估多个领先MLLMs的在线时空推理能力。

研究结果: 实验显示，现有MLLMs在复杂时空推理任务上表现不佳，随着探索时间延长和记忆增长，准确率下降，且存在基于线索的空间推理和长期记忆检索两大核心挑战。

研究结论: OST-Bench揭示了MLLMs在在线时空推理中的不足，为未来研究提供了数据集和基准，促进该领域发展。

中文摘要: 近年来，多模态大语言模型（MLLMs）在整合视觉与语言进行复杂推理方面展现出卓越能力。然而，现有基准多基于离线固定输入，无法反映真实世界中动态探索场景的需求。为此，我们提出了OST-Bench，旨在从主动探索场景的视角评估模型的在线时空理解能力。其“在线”特性强调对增量获取的观察数据进行处理和推理，而“时空”部分则要求整合当前视觉输入与历史记忆以支持动态空间推理。OST-Bench更贴近真实世界具身感知的挑战。基于高效的数据收集流程，OST-Bench包含来自ScanNet、Matterport3D和ARKitScenes的1.4k场景和10k问答对。我们对多个领先MLLMs进行了评估，发现它们在需要复杂时空推理的任务上表现不佳。在线设置下，随着探索时间延长和记忆增长，模型准确率下降。通过进一步实验分析，我们识别出模型的常见错误模式，并发现基于线索的空间推理需求和长期记忆检索需求分别在两个维度上显著降低了模型性能，凸显了提升在线具身推理能力需解决的核心挑战。为促进该领域的研究与发展，我们的代码、数据集和基准均已公开。项目页面为：https://rbler1234.github.io/OSTBench.github.io/

</details>


### [137] [CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is Why](https://arxiv.org/abs/2507.07985)
**中文标题：CLIP无法从自然数据中学习对象-属性绑定的原因**

*Bijay Gurung,David T. Hoffmann,Thomas Brox*

主要分类: cs.CV

摘要简述: 研究发现CLIP模型无法从自然数据中学习对象-属性绑定，原因是数据特性（如低属性密度、不完整描述和显著性偏差）影响了性能。通过合成数据集验证，发现只有满足特定数据属性时，CLIP才能实现完美绑定。


<details>
  <summary>详细信息</summary>
研究动机: 尽管CLIP等对比视觉语言模型应用广泛，但其表示存在局限性，例如无法区分对象与属性的绑定关系（如“黄色潜艇和蓝色巴士”与“蓝色潜艇和黄色巴士”）。此前尝试通过增加硬负样本或修改架构未能彻底解决问题，因此研究聚焦于数据特性对绑定学习的影响。

研究方法: 研究使用合成数据集，系统分析了自然数据的特性（如低属性密度、不完整描述和显著性偏差）对CLIP绑定学习的影响。同时测试了批量大小和硬负样本的作用。

研究结果: 发现自然数据的常见特性（如低属性密度、不完整描述和显著性偏差）对绑定性能有负面影响。批量大小和硬负样本的调整无法解决问题，只有满足特定数据属性时，CLIP才能实现近乎完美的绑定学习。

研究结论: CLIP无法从自然数据中学习对象-属性绑定的根本原因是数据特性不足。仅当数据具备特定属性时，绑定问题才能解决。

中文摘要: 对比视觉语言模型（如CLIP）被广泛应用于零样本分类或多模态模型的视觉编码器。尽管其流行，但其表示存在显著局限性。例如，CLIP模型学习的是“词袋”表示，因此无法区分“黄色潜艇和蓝色巴士”与“蓝色潜艇和黄色巴士”的图像。此前尝试通过增加硬负样本或修改架构未能彻底解决问题。我们怀疑解决CLIP绑定问题的关键隐藏在学习算法最重要的部分：数据中。本研究通过合成数据集严格分析了数据特性对CLIP绑定学习能力的影响。发现自然数据的常见特性（如低属性密度、不完整描述和显著性偏差）对绑定性能有负面影响。与普遍观点相反，增加批量大小（即隐式增加硬负样本）或显式创建硬负样本均无法使CLIP学习可靠的绑定。只有当数据满足我们识别的特定属性时，CLIP才能实现近乎完美的绑定学习。

</details>


### [138] [Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs](https://arxiv.org/abs/2507.07990)
**中文标题：多粒度时空令牌合并：无需训练的视频大语言模型加速方法**

*Jeongseok Hyun,Sukjun Hwang,Su Ho Han,Taeoh Kim,Inwoong Lee,Dongyoon Wee,Joon-Young Lee,Seon Joo Kim,Minho Shim*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的时空令牌合并方法STTM，通过多粒度空间令牌和定向时间合并，显著加速视频大语言模型，同时保持高精度。


<details>
  <summary>详细信息</summary>
研究动机: 视频大语言模型（LLMs）因处理大量时空令牌而计算复杂度高，现有方法未能充分利用视频数据的局部时空冗余性。

研究方法: STTM通过四叉树结构对每帧进行多粒度空间令牌转换，并在时间维度上进行定向成对合并，以减少令牌数量。

研究结果: 在六个视频问答基准测试中，STTM表现优于现有令牌缩减方法，50%令牌预算下速度提升2倍且精度仅下降0.5%，30%预算下速度提升3倍且精度下降2%。

研究结论: STTM是一种高效、无需训练的视频LLMs加速方法，支持跨问题KV缓存复用，显著提升计算效率。

中文摘要: 视频大语言模型（LLMs）通过利用大量时空令牌实现强大的视频理解能力，但其计算复杂度随令牌数量呈二次方增长。为解决这一问题，我们提出了一种无需训练的时空令牌合并方法STTM。我们的核心思想是充分利用视频数据中未被前人关注的局部时空冗余性。STTM首先通过四叉树结构对每帧进行多粒度空间令牌转换，随后在时间维度上进行定向成对合并。这种分解合并方法在六个视频问答基准测试中均优于现有令牌缩减方法。值得注意的是，STTM在50%令牌预算下实现了2倍速度提升且精度仅下降0.5%，在30%预算下速度提升3倍且精度下降2%。此外，STTM与查询无关，允许对同一视频的不同问题复用KV缓存。项目页面详见https://www.jshyun.me/projects/sttm。

</details>


### [139] [Multigranular Evaluation for Brain Visual Decoding](https://arxiv.org/abs/2507.07993)
**中文标题：脑视觉解码的多粒度评估**

*Weihao Xia,Cengiz Oztireli*

主要分类: cs.CV

摘要简述: 本文提出了一种名为BASIC的多粒度评估框架，用于改进脑视觉解码的评价方法，通过量化结构保真度、推理对齐和上下文一致性，提供更全面、可解释的评估标准。


<details>
  <summary>详细信息</summary>
研究动机: 现有的脑视觉解码评估方法主要依赖粗粒度指标，掩盖了模型间的差异，缺乏神经科学基础，且无法捕捉细粒度的视觉区分。为解决这些问题，本文提出了BASIC框架。

研究方法: BASIC框架通过分层分割指标（如前景、语义、实例和组件掩码）量化结构保真度，并利用多模态大语言模型提取结构化场景表示（如对象、属性和关系），实现与真实刺激的详细对比。

研究结果: 在多个刺激-神经影像数据集上对多种视觉解码方法进行了基准测试，结果表明BASIC框架能够提供更具区分性、可解释性和全面性的评估结果。

研究结论: BASIC框架为脑视觉解码方法提供了更科学、全面的评估标准，有助于推动该领域的发展。

中文摘要: 现有的脑视觉解码评估协议主要依赖粗粒度指标，掩盖了模型间的差异，缺乏神经科学基础，且无法捕捉细粒度的视觉区分。为解决这些问题，我们提出了BASIC，一个统一的多粒度评估框架，联合量化解码图像与真实图像之间的结构保真度、推理对齐和上下文一致性。在结构层面，我们引入了一套基于分割的分层指标，包括前景、语义、实例和组件掩码，并通过掩码结构的粒度感知对应关系进行锚定。在语义层面，我们利用多模态大语言模型提取结构化场景表示（如对象、属性和关系），实现与真实刺激的详细、可扩展且上下文丰富的对比。我们在多个刺激-神经影像数据集上对多种视觉解码方法进行了基准测试。这些标准共同为脑视觉解码方法提供了更具区分性、可解释性和全面性的评估基础。

</details>


### [140] [Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection](https://arxiv.org/abs/2507.07994)
**中文标题：草图绘制关键点：基于草图的少样本关键点检测**

*Subhajit Maity,Ayan Kumar Bhunia,Subhadeep Koley,Pinaki Nath Chowdhury,Aneeshan Sain,Yi-Zhe Song*

主要分类: cs.CV

摘要简述: 本文提出了一种基于草图的少样本关键点检测框架，通过利用人类绘制的草图作为无源数据，解决了少样本学习中数据分布不匹配的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现代机器感知中的关键点检测在少样本学习中面临挑战，尤其是当查询数据与源数据分布不一致时。草图作为一种人类表达形式，提供了一种无源数据替代方案，但跨模态嵌入和用户特定草图风格的处理仍是难题。

研究方法: 提出的框架采用原型设置，结合基于网格的定位器和原型域适应技术，解决了跨模态嵌入和用户草图风格差异的问题。

研究结果: 通过大量实验，证明了该框架在少样本收敛和新颖关键点及类别上的成功应用。

研究结论: 该研究为少样本关键点检测提供了一种创新的解决方案，通过草图实现了无源数据的有效利用，并在实验中验证了其有效性。

中文摘要: 关键点检测是现代机器感知的重要组成部分，但在少样本学习中面临挑战，尤其是当查询数据与源数据分布不一致时。本文通过利用草图这一人类表达形式，提供了一种无源数据替代方案。然而，跨模态嵌入和用户特定草图风格的处理仍是难题。我们提出的框架通过原型设置、基于网格的定位器和原型域适应技术克服了这些障碍。通过大量实验，我们还证明了该框架在少样本收敛和新颖关键点及类别上的成功应用。

</details>


### [141] [Single-pass Adaptive Image Tokenization for Minimum Program Search](https://arxiv.org/abs/2507.07995)
**中文标题：单次自适应图像标记用于最小程序搜索**

*Shivam Duggal,Sanghyun Byun,William T. Freeman,Antonio Torralba,Phillip Isola*

主要分类: cs.CV

摘要简述: 本文提出了一种单次自适应图像标记方法KARL，通过预测图像的近似Kolmogorov复杂度（KC）来动态决定标记数量，避免了传统方法的多轮搜索。KARL在单次前向传播中实现性能匹配，并分析了编码器/解码器规模等因素的影响。


<details>
  <summary>详细信息</summary>
研究动机: 传统视觉表示学习系统使用固定长度的表示，忽略了输入数据的复杂度差异。尽管近期自适应标记方法通过变长表示解决了这一问题，但仍需多次测试搜索最优编码。受Kolmogorov复杂度启发，本文旨在开发一种单次自适应标记方法，以更高效地实现性能匹配。

研究方法: 提出KARL方法，通过单次前向传播预测图像的标记数量，以近似KC为停止条件。训练过程类似于倒置强化学习，根据重建质量预测标记停止。分析了编码器/解码器规模、连续与离散标记等因素的影响。

研究结果: KARL在单次前向传播中实现了与现有自适应标记方法相当的性能。同时，通过实验揭示了图像复杂度（KC）与结构/噪声、分布内外熟悉度等因素的关系，与人类直觉一致。

研究结论: KARL通过单次自适应标记实现了高效性能，验证了其与Kolmogorov复杂度理论的契合。研究还提供了关于图像复杂度的新见解，为未来自适应表示学习提供了方向。

中文摘要: 根据算法信息理论（AIT），智能表示将数据压缩为能够重建其内容的最短程序，表现出较低的Kolmogorov复杂度（KC）。然而，大多数视觉表示学习系统对所有输入使用固定长度的表示，忽略了复杂度或熟悉度的差异。近期的自适应标记方法通过分配变长表示解决了这一问题，但通常需要测试时搜索多个编码以找到最具预测性的编码。受Kolmogorov复杂度原理启发，我们提出了一种单次自适应标记器KARL，它通过单次前向传播预测图像的标记数量，并在达到近似KC时停止。标记数量作为最小描述长度的代理。KARL的训练过程类似于倒置强化学习范式，因为它学习基于期望重建质量条件预测标记停止。KARL在单次操作中匹配了近期自适应标记器的性能。我们提出了KARL的扩展规律，分析了编码器/解码器规模、连续与离散标记等因素的作用。此外，我们还提供了一个概念性研究，将自适应图像标记与算法信息理论类比，研究了预测图像复杂度（KC）在结构/噪声、分布内外熟悉度等维度上的表现——揭示了与人类直觉的一致性。

</details>


### [142] [MGVQ: Could VQ-VAE Beat VAE? A Generalizable Tokenizer with Multi-group Quantization](https://arxiv.org/abs/2507.07997)
**中文标题：MGVQ：VQ-VAE能否超越VAE？一种基于多组量化的通用标记化方法**

*Mingkai Jia,Wei Yin,Xiaotao Hu,Jiaxin Guo,Xiaoyang Guo,Qian Zhang,Xiao-Xiao Long,Ping Tan*

主要分类: cs.CV

摘要简述: MGVQ通过多组量化增强离散码本的表示能力，显著缩小了VQ-VAE与VAE之间的性能差距，并在多个基准测试中取得最优重建效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有VQ-VAE在量化策略上虽有改进，但与VAE的性能差距仍较大。本文旨在通过增强码本表示能力，减少信息损失，提升重建质量。

研究方法: 保留潜在维度以保留编码特征，并引入多组子码本进行量化。同时构建了512p和2k分辨率的零样本基准测试以严格评估性能。

研究结果: MGVQ在ImageNet和8个零样本基准测试中均达到最优性能，显著优于SD-VAE（rFID 0.49 vs. 0.91），并在所有测试中PSNR表现最佳。

研究结论: MGVQ通过多组量化显著提升了VQ-VAE的重建性能，为高清图像处理任务提供了保真度保障。

中文摘要: 向量量化变分自编码器（VQ-VAE）是将连续视觉数据压缩为离散标记的基础模型。现有方法试图改进量化策略以提高重建质量，但VQ-VAE与VAE之间仍存在较大差距。为缩小这一差距，我们提出MGVQ，通过增强离散码本的表示能力，优化码本并减少信息损失，从而提升重建质量。具体而言，我们保留潜在维度以保留编码特征，并引入多组子码本进行量化。此外，我们构建了512p和2k分辨率的零样本基准测试，严格评估现有方法的重建性能。MGVQ在ImageNet和8个零样本基准测试中均达到最优性能，显著优于SD-VAE（rFID 0.49 vs. 0.91），并在所有测试中PSNR表现最佳。这些结果凸显了MGVQ在重建中的优越性，为高清图像处理任务的保真度提供了新途径。代码将在https://github.com/MKJia/MGVQ公开。

</details>


### [143] [Impact of Pretraining Word Co-occurrence on Compositional Generalization in Multimodal Models](https://arxiv.org/abs/2507.08000)
**中文标题：预训练词语共现对多模态模型组合泛化能力的影响**

*Helen Qu,Sang Michael Xie*

主要分类: cs.CV

摘要简述: 本文研究了预训练数据中词语共现统计对多模态模型组合泛化能力的影响，发现共现频率与模型准确性高度相关，并揭示了组合概念对模型性能的重要性。


<details>
  <summary>详细信息</summary>
研究动机: CLIP和大型多模态模型（LMMs）在训练数据中高频概念上表现优异，但组合概念的泛化能力尚不明确。本文旨在探究词语共现统计（作为视觉概念共现的代理）如何影响模型性能。

研究方法: 使用点互信息（PMI）量化词语共现频率，通过合成图像和自然图像编辑实验，分析PMI与CLIP/LMMs零样本准确性的相关性。

研究结果: 实验显示，CLIP预训练数据中的PMI与模型准确性高度相关（r=0.97），且组合概念显著影响常见概念的准确性。这一现象在自然图像和LMMs中同样存在（r=0.75和r=0.70/0.62）。

研究结论: 研究强调了改进多模态模型组合泛化能力的必要性，而非单纯扩展训练数据规模。

中文摘要: CLIP和大型多模态模型（LMMs）在训练数据中高频概念上表现优异，但组合概念的泛化能力尚不明确——例如，常见物体与不常见物体组合时的准确性如何变化？本文研究了预训练数据中词语共现统计（作为视觉概念共现的代理）对CLIP/LMMs性能的影响。为区分词语共现频率与单词语频率的效应，我们使用点互信息（PMI）量化共现频率，PMI通过联合概率与独立共现概率的比值归一化。通过合成图像实验，我们发现CLIP预训练数据中的PMI与零样本准确性高度相关（r=0.97，PMI最高和最低5%的图像间准确性差距达14%），表明即使是常见概念的准确性也受组合概念影响。基于此发现，我们通过编辑自然图像验证了这一效应（r=0.75）。此外，CLIP中的这一行为也传递到基于CLIP的LMMs（TextVQA中r=0.70，VQAv2中r=0.62）。我们的研究强调了改进多模态模型组合泛化能力的必要性，而非单纯扩展训练数据规模。代码见https://github.com/helenqu/multimodal-pretraining-pmi。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [144] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
**中文标题：基于LLM的自主控制：下一代工业自动化的代理框架**

*Javal Vyas,Mehmet Mercangoz*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大型语言模型（LLMs）的自主控制框架，结合符号推理与自适应控制，用于工业自动化中的离散故障恢复规划和连续过程控制。通过有限状态机（FSMs）和模块化代理（规划、模拟、验证）实现高效路径规划和动态控制，实验表明其优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 现代化学过程的复杂性增加、劳动力短缺以及故障场景的多样性，亟需一种结合符号推理和自适应控制的新型自动化范式。

研究方法: 采用有限状态机（FSMs）作为可解释的操作框架，通过LLM驱动的规划代理提出恢复序列，模拟代理执行和检查每个状态转换，验证-重新提示循环迭代优化无效计划。

研究结果: 在案例研究1中，GPT-4o和GPT-4o-mini在180个随机生成的FSMs中实现了100%的有效路径成功率；案例研究2中，LLM控制器在双加热器控制中表现与传统PID控制相当，但能更好地处理非线性动态。

研究结论: 研究表明，通过结构化反馈和模块化代理，LLMs能够统一高层符号规划和低层连续控制，为化学工程中的语言驱动自动化提供了新方向。

中文摘要: 现代化学过程的复杂性日益增加，加之劳动力短缺和复杂的故障场景，亟需一种结合符号推理与自适应控制的新型自动化范式。本文提出了一种统一的代理框架，利用大型语言模型（LLMs）在同一架构中实现离散故障恢复规划和连续过程控制。我们采用有限状态机（FSMs）作为可解释的操作边界：LLM驱动的规划代理通过FSM提出恢复序列，模拟代理执行并检查每个状态转换，验证-重新提示循环迭代优化无效计划。在案例研究1中，针对180个随机生成的FSMs（4-25个状态，4-300个转换），GPT-4o和GPT-4o-mini在五次重新提示内实现了100%的有效路径成功率，优于开源LLMs的准确性和延迟。在案例研究2中，同一框架在实验室TCLab平台（及其数字孪生）上调节双加热器输入，以在持续不对称扰动下维持目标平均温度。与传统PID控制相比，基于LLM的控制器表现相当，而去除提示循环的消融实验揭示了其在处理非线性动态中的关键作用。我们分析了主要失败模式（如指令跟随失误和粗糙的ODE近似）。结果表明，通过结构化反馈和模块化代理，LLMs能够统一高层符号规划和低层连续控制，为化学工程中语言驱动的弹性自动化铺平了道路。

</details>


### [145] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
**中文标题：BOOST：基于分布外信息的自适应采样方法用于风格化卷积神经网络的偏见缓解**

*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

主要分类: cs.AI

摘要简述: 本文提出了一种名为BOOST的新方法，通过动态调整温度缩放和采样概率，解决艺术分类中因数据不平衡导致的偏见问题，并在KaoKore和PACS数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: AI在艺术分类中普遍存在偏见问题，尤其是当训练数据中某些艺术风格占主导时，模型对罕见风格的预测准确性下降。现有研究多关注分类性能提升，而忽视了解决这些偏见的必要性。

研究方法: 提出BOOST方法，结合OOD信息动态调整温度缩放和采样概率，以促进所有类别的公平表示，并设计了新指标SODC评估类别分离和偏见减少效果。

研究结果: 在KaoKore和PACS数据集上的实验表明，BOOST能够平衡高性能与公平性，有效减少类别偏见。

研究结论: BOOST为艺术领域的AI模型去偏见提供了一种稳健的解决方案，兼顾了性能和公平性。

中文摘要: AI中的偏见问题对绘画分类提出了重大挑战，尤其是在艺术策展和修复等任务中。这些偏见通常源于数据集中某些艺术风格占主导，导致模型对罕见风格的预测准确性下降。尽管先前研究在提升分类性能方面取得了进展，但忽视了解决这些偏见的必要性，尤其是在处理分布外（OOD）数据时。本文提出了一种名为BOOST（偏见导向的OOD采样与调整）的新方法，通过动态调整温度缩放和采样概率，促进所有类别的公平表示。我们在KaoKore和PACS数据集上评估了该方法，重点关注其减少类别偏见的能力，并提出了新指标SODC（同数据集OOD检测分数）用于评估类别分离和偏见减少效果。实验表明，BOOST能够平衡高性能与公平性，为艺术领域的AI模型去偏见提供了稳健的解决方案。

</details>


### [146] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
**中文标题：基于状态推断的提示方法在游戏NPC自然语言交易中的应用**

*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

主要分类: cs.AI

摘要简述: 论文提出了一种基于状态推断的提示方法（SIBP），用于解决大型语言模型在游戏NPC交易中的规则违反问题，显著提升了交易对话的准确性和可信度。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在游戏NPC交易中存在规则违反问题（如物品幻觉和计算错误），削弱了玩家的信任。因此，需要一种可靠的方法来确保交易对话的规则遵从性。

研究方法: 论文提出状态推断提示方法（SIBP），将交易分解为六个状态，通过上下文感知的物品引用和基于占位符的价格计算，确保规则遵从性。

研究结果: 在100次交易对话的评估中，SIBP实现了>97%的状态遵从率、>95%的引用准确率和99.7%的计算精度，显著优于基线方法。

研究结论: SIBP为商业游戏中可信的NPC交互提供了实用基础，同时保持了计算效率。

中文摘要: 大型语言模型支持动态游戏交互，但在规则驱动的交易系统中表现不佳。现有实现存在规则违反问题（如物品幻觉和计算错误），削弱了玩家信任。本文提出的状态推断提示方法（SIBP）通过自主对话状态推断和上下文规则遵从，实现了可靠的交易。该方法将交易分解为六个状态，采用上下文感知的物品引用和基于占位符的价格计算。在100次交易对话的评估中，SIBP实现了>97%的状态遵从率、>95%的引用准确率和99.7%的计算精度。SIBP在计算效率上优于基线方法，为商业游戏中可信的NPC交互奠定了实用基础。

</details>


### [147] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
**中文标题：供应链中强迫劳动的神经符号特征提取识别**

*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

主要分类: cs.AI

摘要简述: 本文探讨了利用神经符号方法从供应链中识别强迫劳动等非法活动，通过问题树方法查询大型语言模型（LLM）以量化新闻文章的相关性，比较了人工与机器分类的差异。


<details>
  <summary>详细信息</summary>
研究动机: 供应链网络复杂且涉及非法活动（如强迫劳动）时数据稀疏且不可靠，传统机器学习方法需要大量训练数据，难以适用。因此，需要一种无需大量数据的自动检测方法。

研究方法: 采用神经符号方法，结合问题树方法查询LLM，从新闻文章中提取特征并量化其相关性，比较人工与机器分类的效果。

研究结果: 研究表明，神经符号方法能有效识别供应链中的非法活动，问题树方法可系统评估新闻文章的相关性，机器分类与人工分类存在差异。

研究结论: 神经符号方法为供应链中非法活动的检测提供了新思路，问题树方法有助于量化新闻文章的相关性，未来可进一步优化机器分类的准确性。

中文摘要: 供应链网络是复杂的系统，分析其涉及非法活动（如假冒零件、强迫劳动或人口贩卖）时尤为困难。传统机器学习方法需要大量训练数据，但非法供应链数据稀疏且常被故意破坏或不可靠。我们需在不依赖大量数据的情况下，自动检测复杂甚至时序数据中与非法活动相关的新模式。本文探索了神经符号方法在供应链中识别非法活动的应用，并比较了从新闻文章中手动和自动提取特征的准确性。我们提出了一种问题树方法，通过查询大型语言模型（LLM）来识别和量化文章的相关性，从而系统评估人工与机器分类在供应链强迫劳动相关新闻文章中的差异。

</details>


### [148] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
**中文标题：基于语言智能体的开源规划与控制系统用于自主科学发现**

*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

主要分类: cs.AI

摘要简述: 本文提出了一种名为cmbagent的多智能体系统，用于自动化科学研究任务。该系统由约30个大型语言模型（LLM）智能体组成，采用规划与控制策略协调工作流程，无需人工干预。系统成功应用于宇宙学博士级任务，性能优于现有LLM。


<details>
  <summary>详细信息</summary>
研究动机: 当前科学研究任务复杂且耗时，需要自动化工具提高效率。本文旨在开发一种无需人工干预的多智能体系统，通过LLM智能体协作完成科学任务。

研究方法: 系统由约30个LLM智能体组成，每个智能体专注于不同任务（如检索科学论文和代码库、编写代码、解释结果、评估其他智能体输出）。系统采用规划与控制策略协调工作流程，并支持本地代码执行。

研究结果: 系统成功应用于宇宙学博士级任务（利用超新星数据测量宇宙学参数），并在两个基准测试中表现优于现有LLM。代码已开源，部署于HuggingFace和云端。

研究结论: cmbagent系统展示了多智能体协作在自动化科学研究中的潜力，性能优于现有技术，为未来科学自动化提供了新方向。

中文摘要: 我们提出了一种名为cmbagent的多智能体系统，用于自动化科学研究任务。该系统由约30个大型语言模型（LLM）智能体组成，采用规划与控制策略协调工作流程，全程无需人工干预。每个智能体专注于不同任务（如检索科学论文和代码库、编写代码、解释结果、评估其他智能体输出），并支持本地代码执行。我们成功将cmbagent应用于宇宙学博士级任务（利用超新星数据测量宇宙学参数），并在两个基准测试中表现优于现有LLM。源代码已在GitHub上开源，演示视频也已发布，系统部署于HuggingFace并将上线云端。

</details>


### [149] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
**中文标题：大型语言模型在多机器人路径规划与任务分配中的应用**

*Ashish Kumar*

主要分类: cs.AI

摘要简述: 本文探讨了在多智能体强化学习中，利用大型语言模型作为专家规划器，以提高多机器人路径规划和任务分配中的探索效率。


<details>
  <summary>详细信息</summary>
研究动机: 多智能体强化学习中的探索效率问题因其复杂性而尤为突出。本研究旨在通过引入大型语言模型作为专家规划器，解决多智能体在任务规划中的高效探索问题。

研究方法: 研究采用大型语言模型作为专家规划器，应用于多智能体的路径规划和任务分配任务中，以提高探索效率。

研究结果: 结果表明，大型语言模型作为专家规划器能够有效提升多智能体在复杂任务中的探索效率。

研究结论: 本研究验证了大型语言模型在多智能体路径规划和任务分配中的潜力，为高效探索提供了新思路。

中文摘要: 高效探索是深度强化学习中的一个众所周知的问题，而在多智能体强化学习中，由于算法的内在复杂性，这一问题更为突出。目前有多种方法可以高效探索环境，以学习多智能体在该环境中解决任务的能力。本研究探讨了其中一种方法，即专家探索的概念。具体而言，本研究探讨了将大型语言模型作为专家规划器，应用于多智能体基于规划的任务中的高效探索。

</details>


### [150] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
**中文标题：ViDove：一种支持多模态上下文与记忆增强推理的翻译代理系统**

*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

主要分类: cs.AI

摘要简述: ViDove是一种支持多模态输入的翻译代理系统，通过结合视觉和上下文背景信息提升翻译质量，并引入多模态记忆和长短期记忆模块，显著优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于LLM的翻译代理通常仅支持文本输入，无法利用多模态信息。ViDove旨在模拟人类翻译的工作流程，通过视觉和上下文信息提升翻译效果。

研究方法: ViDove整合了多模态记忆系统和长短期记忆模块，结合领域知识，支持视觉和上下文输入，优化翻译过程。

研究结果: ViDove在字幕生成和通用翻译任务中表现优异，BLEU分数提升28%，SubER提升15%，并发布了新基准DoveBench。

研究结论: ViDove通过多模态输入和记忆增强推理显著提升翻译质量，为多模态翻译任务提供了新方向。

中文摘要: 基于LLM的翻译代理已能高效处理复杂上下文，但通常仅支持文本输入。本文提出ViDove，一种支持多模态输入的翻译代理系统，模拟人类翻译流程，利用视觉和上下文背景信息优化翻译。此外，ViDove整合了多模态记忆系统和长短期记忆模块，结合领域知识，使其在实际场景中更准确、自适应。实验表明，ViDove在字幕生成和通用翻译任务中表现显著优于现有基线，BLEU分数提升28%，SubER提升15%。我们还发布了DoveBench，一个包含17小时高质量人工标注数据的长视频字幕翻译新基准。代码已开源：https://github.com/pigeonai-org/ViDove

</details>


### [151] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
**中文标题：论智能与判断的不可分离性：AI对齐中过滤的计算不可行性**

*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

主要分类: cs.AI

摘要简述: 本文研究大型语言模型（LLM）的安全对齐问题，重点关注输入和输出过滤的可行性。结果表明，高效的提示过滤和输出过滤在计算上不可行，安全无法仅通过外部过滤器实现。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的广泛应用，其可能生成有害内容的问题引发关注。本文旨在探讨如何通过过滤输入和输出来实现模型的安全对齐，并揭示其中的计算挑战。

研究方法: 研究通过理论分析证明，对于某些LLM，高效的提示过滤器不存在，且输出过滤在特定条件下计算上不可行。所有结果基于密码学硬度假设。

研究结果: 研究发现，对抗性提示可以轻易绕过高效过滤器，且输出过滤在自然场景下计算上不可行。此外，放松的缓解方法也存在计算障碍。

研究结论: 安全无法通过设计外部过滤器实现，必须将智能与判断紧密结合。基于技术结果，作者认为对齐AI系统的智能与判断不可分割。

中文摘要: 随着大型语言模型（LLM）的部署增加，其可能生成有害内容的问题引发担忧。本文研究对齐挑战，重点关注防止生成不安全信息的过滤器。干预的两个自然点是过滤输入提示和过滤生成后的输出。我们的主要结果表明，过滤提示和输出均存在计算挑战。首先，我们证明存在某些LLM，其无法高效过滤提示：对抗性提示可以轻易构造，且对任何高效过滤器计算上无法区分于良性提示。第二个主要结果指出，在自然场景下输出过滤计算上不可行。所有分离结果均基于密码学硬度假设。此外，我们还形式化并研究了放松的缓解方法，揭示了进一步的计算障碍。我们得出结论，安全无法通过设计独立于LLM内部（架构和权重）的过滤器实现；特别是，仅凭对LLM的黑盒访问是不够的。基于技术结果，我们认为对齐AI系统的智能与判断不可分割。

</details>


### [152] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
**中文标题：通过生成仿真和迭代决策策略优化供应链**

*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

主要分类: cs.AI

摘要简述: 论文提出Sim-to-Dec框架，结合生成仿真和迭代决策策略优化供应链运输，显著提升准时交付率和利润。


<details>
  <summary>详细信息</summary>
研究动机: 供应链运输中的高响应性和经济效率是关键目标，而运输模式的选择直接影响这些目标。现有方法缺乏通用性、动态性和历史与预测的整合，因此需要一种新的框架来满足这些需求。

研究方法: Sim-to-Dec框架包含生成仿真模块和双感知决策模型。前者利用自回归建模模拟连续状态变化，减少对领域特定规则的依赖；后者通过端到端优化迭代优化决策策略。

研究结果: 在三个真实数据集上的实验表明，Sim-to-Dec显著提高了准时交付率和利润。

研究结论: Sim-to-Dec框架通过结合生成仿真和迭代决策策略，为供应链运输优化提供了高效、通用的解决方案。

中文摘要: 高响应性和经济效率是供应链运输中的关键目标，而运输模式的战略决策直接影响这些目标。结合高效仿真器和智能决策算法的集成框架可以为运输策略设计提供可观察、低风险的环境。理想的仿真-决策框架必须（1）在各种设置中有效泛化，（2）反映细粒度的运输动态，（3）整合历史经验与预测洞察，（4）保持仿真反馈与策略优化的紧密集成。我们提出Sim-to-Dec框架以满足这些需求。具体而言，Sim-to-Dec包括一个生成仿真模块，利用自回归建模模拟连续状态变化，减少对手工领域特定规则的依赖，并增强对数据波动的鲁棒性；以及一个历史-未来双感知决策模型，通过与仿真器的端到端优化迭代优化。在三个真实数据集上的广泛实验表明，Sim-to-Dec显著提高了准时交付率和利润。

</details>


### [153] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
**中文标题：DrugMCTS：一种结合多智能体、RAG和蒙特卡洛树搜索的药物重定位框架**

*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

主要分类: cs.AI

摘要简述: 本文提出了一种名为DrugMCTS的新型药物重定位框架，结合了多智能体、RAG和蒙特卡洛树搜索技术，显著提升了大型语言模型在药物发现中的表现，无需领域微调即可超越现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在药物发现领域的应用受限于预训练知识的范围，传统方法如微调或检索增强生成存在计算开销大或未能充分利用结构化科学数据的不足。本文旨在通过多智能体协作和反馈驱动搜索机制解决这些问题。

研究方法: DrugMCTS框架整合了检索增强生成（RAG）、多智能体协作和蒙特卡洛树搜索技术，通过五个专用智能体检索和分析分子与蛋白质信息，实现结构化迭代推理。

研究结果: 在DrugBank和KIBA数据集上的实验表明，DrugMCTS显著提升了召回率和鲁棒性，Qwen2.5-7B-Instruct模型性能超越Deepseek-R1超过20%。

研究结论: 研究结果表明，结构化推理、基于智能体的协作和反馈驱动搜索机制对推动大型语言模型在药物发现中的应用至关重要。

中文摘要: 近年来，大型语言模型在药物发现等科学领域展现出巨大潜力，但其推理能力仍受限于预训练知识的范围。传统方法如微调或检索增强生成存在计算开销高或未能充分利用结构化科学数据的局限性。为解决这些问题，我们提出DrugMCTS，一种新型框架，协同整合了RAG、多智能体协作和蒙特卡洛树搜索技术用于药物重定位。该框架通过五个专用智能体检索和分析分子与蛋白质信息，实现结构化迭代推理。无需领域微调，DrugMCTS使Qwen2.5-7B-Instruct模型性能超越Deepseek-R1超过20%。在DrugBank和KIBA数据集上的大量实验表明，DrugMCTS在召回率和鲁棒性上显著优于通用大型语言模型和深度学习基线。我们的结果凸显了结构化推理、基于智能体的协作和反馈驱动搜索机制在推动药物发现中大型语言模型应用的重要性。

</details>


### [154] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
**中文标题：StarDojo：基于《星露谷物语》的生产生活模拟中多模态大语言模型代理开放式行为基准测试**

*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

主要分类: cs.AI

摘要简述: StarDojo是一个基于《星露谷物语》的新型基准测试，用于评估AI代理在开放式生产生活模拟中的表现，涵盖农业、制作、探索、战斗和社交互动五大领域。测试结果显示，当前最先进的MLLM代理表现有限，GPT-4.1的成功率仅为12.7%。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基准测试很少同时评估AI代理的生产活动和社会互动能力。为了填补这一空白，作者提出了StarDojo，旨在通过开放式模拟环境全面评估AI代理的综合能力。

研究方法: StarDojo基于《星露谷物语》设计，包含1,000个精心设计的任务，涵盖五大领域：农业、制作、探索、战斗和社交互动。此外，还提供了一个包含100个代表性任务的子集用于高效评估。测试环境支持多操作系统，无需键盘鼠标控制，并可并行运行多个实例。

研究结果: 对当前最先进的MLLM代理进行了广泛评估，结果显示其表现有限，最佳模型GPT-4.1的成功率仅为12.7%，主要受限于视觉理解、多模态推理和低层次操作能力。

研究结论: StarDojo作为一个用户友好的基准测试环境，旨在推动复杂生产生活环境中开放式AI代理的进一步研究。

中文摘要: 自主代理在人类社会中的导航需要同时掌握生产活动和社会互动技能，但现有基准测试很少同时评估这些能力。为填补这一空白，我们提出了StarDojo，这是一个基于《星露谷物语》的新型基准测试，旨在评估AI代理在开放式生产生活模拟中的表现。在StarDojo中，代理需要完成农业和制作等基本生计活动，同时与充满活力的社区建立社交关系。StarDojo包含1,000个精心设计的任务，涵盖五大关键领域：农业、制作、探索、战斗和社交互动。此外，我们还提供了一个包含100个代表性任务的子集，用于高效模型评估。该基准测试提供了一个统一的用户友好界面，无需键盘鼠标控制，支持所有主流操作系统，并可并行运行多个环境实例，非常适合评估由多模态大语言模型（MLLMs）驱动的强大基础代理。对当前最先进的MLLM代理的广泛评估显示其表现存在显著局限性，表现最佳的模型GPT-4.1的成功率仅为12.7%，主要受限于视觉理解、多模态推理和低层次操作能力。作为一个用户友好的环境和基准测试，StarDojo旨在推动复杂生产生活环境中开放式代理的进一步研究。

</details>


### [155] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
**中文标题：立场：我们需要对生成式AI的算法理解**

*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

主要分类: cs.AI

摘要简述: 本文提出AlgEval框架，旨在系统研究大语言模型（LLM）学习与使用的算法，填补当前对LLM内在算法的理论空白，并通过案例研究验证其可行性。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究多关注通过规模提升LLM性能，而对其学习的具体算法缺乏理论和实证研究，导致对模型内在计算的理解不足。本文旨在填补这一空白。

研究方法: 提出AlgEval框架，通过分析潜在表示、注意力机制和推理计算，研究LLM的算法组成。案例研究结合自上而下的假设与自下而上的电路级分析，验证框架有效性。

研究结果: 案例研究表明，AlgEval能够揭示LLM中的搜索算法，并通过注意力模式和隐藏状态分析验证假设，为模型内在计算提供系统性解释。

研究结论: AlgEval为LLM的算法理解提供新方向，减少对资源密集型扩展的依赖，推动模型可解释性和高效训练方法的发展。

中文摘要: 大语言模型（LLM）实际学习并用于解决问题的算法是什么？针对这一问题的研究稀少，因为研究重点多集中在通过规模提升性能，导致对涌现算法的理论和实证理解存在空白。本文提出AlgEval框架，旨在系统研究LLM学习与使用的算法。AlgEval的目标是揭示反映在潜在表示、注意力和推理计算中的算法基元及其组合方式，以解决特定任务问题。我们重点探讨了实现这一目标的潜在方法路径，并通过一个案例研究聚焦于涌现的搜索算法。案例研究展示了自上而下对候选算法的假设形成，以及通过注意力模式和隐藏状态的电路级分析自下而上验证这些假设。对LLM如何实际解决任务的系统性严格评估，为资源密集型扩展提供了替代方案，将研究领域重新导向对底层计算的原则性理解。此类算法解释为人类可理解的模型内部推理性能度量提供了途径，从而可能催生更高效的训练方法、性能改进以及端到端和多智能体系统的新架构。

</details>


### [156] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
**中文标题：关于可信的基于规则模型及其解释**

*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

主要分类: cs.AI

摘要简述: 本文探讨了基于规则的机器学习模型在高风险领域中的可信度问题，指出其解释可能误导决策者，并分析了模型的负面特征（如冗余和重叠），提出了相关分析算法。


<details>
  <summary>详细信息</summary>
研究动机: 在高风险领域中，机器学习模型的解释准确性至关重要，错误的解释会误导人类决策者。尽管可解释性是一个模糊的概念，但基于规则的模型仍被广泛使用。本文旨在揭示这些模型的负面特征及其对解释可信度的影响。

研究方法: 本文开发了算法来分析基于规则的机器学习模型的负面特征，包括负面重叠和多种形式的冗余。

研究结果: 研究发现，广泛使用的基于规则模型学习工具会导致规则集出现一种或多种负面特征。

研究结论: 本文强调了基于规则模型在高风险应用中的潜在问题，并提出了改进其解释可信度的方法。

中文摘要: 机器学习（ML）中的一个重要任务是为模型预测提供解释。在高风险领域，解释的严谨性至关重要，错误的解释会误导人类决策者。尽管可解释性是一个模糊的概念，但所谓的可解释模型在高风险ML和数据挖掘（DM）应用中无处不在。基于规则的ML模型（如决策树、图表、集合和列表）就是如此。本文探讨了解释与基于规则ML模型中已知的负面特征（如负面重叠和多种冗余形式）之间的关系，并开发了分析这些负面特征的算法。研究得出结论，广泛使用的基于规则模型学习工具会导致规则集出现一种或多种负面特征。

</details>


### [157] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
**中文标题：上下文池化：知识图谱中通用归纳链接预测的查询特定图池化**

*Zhixiang Su,Di Wang,Chunyan Miao*

主要分类: cs.AI

摘要简述: 本文提出了一种名为“上下文池化”的新方法，用于提升基于图神经网络（GNN）的知识图谱（KG）链接预测性能。该方法首次在KG中应用图池化，并支持生成查询特定图以处理归纳设置。通过设计邻域精度和邻域召回两个指标，筛选逻辑相关邻居，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于GNN的KG链接预测模型中，普通聚合方法对性能提升有限。本文旨在通过引入上下文池化方法，解决这一问题，并首次在KG中实现图池化和查询特定图的生成，以应对归纳设置中的未见过实体问题。

研究方法: 提出上下文池化方法，首次在KG中应用图池化技术，并支持生成查询特定图。设计了邻域精度和邻域召回两个指标，用于评估邻居的逻辑相关性，从而筛选出与查询相关的邻居进行链接预测。

研究结果: 在三个公开的转导和归纳数据集上，将上下文池化应用于两种最先进模型，取得了48种设置中42种的最高性能。

研究结论: 上下文池化是一种通用且高效的方法，显著提升了GNN在KG链接预测中的性能，尤其是在归纳设置中表现突出。

中文摘要: 近期研究表明，基于图神经网络（GNN）的知识图谱（KG）链接预测模型中，普通聚合方法对性能提升有限。本文提出了一种名为“上下文池化”的新方法，以提升GNN在KG链接预测中的效能。据我们所知，上下文池化是首次在KG中应用图池化的方法，同时也是首种能够为归纳设置生成查询特定图的技术。具体而言，我们设计了邻域精度和邻域召回两个指标，用于评估邻居对给定查询的逻辑相关性，从而筛选出仅逻辑相关的邻居进行链接预测。我们的方法具有通用性，通过在三种公开的转导和归纳数据集上应用于两种最先进模型，取得了48种设置中42种的最高性能。

</details>


### [158] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
**中文标题：增强疫苗安全监测：使用微调的大型语言模型从急诊分诊记录中提取疫苗相关信息**

*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

主要分类: cs.AI

摘要简述: 本研究评估了微调的Llama 3.2模型在从急诊分诊记录中提取疫苗相关信息的能力，以支持近实时疫苗安全监测。微调模型在提取疫苗名称的准确性上优于其他方法，并展示了大型语言模型在自动化数据提取中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 疫苗安全监测需要高效的数据提取方法，以早期发现潜在的免疫后不良事件。急诊分诊记录是重要的数据来源，但手动提取信息耗时且效率低，因此需要自动化工具。

研究方法: 研究使用提示工程初步创建标注数据集，并由人工标注确认。比较了提示工程模型、微调模型和基于规则的方法。微调的Llama 3.2模型通过量化技术实现了在资源受限环境中的高效部署。

研究结果: 微调的Llama 3.2模型在提取疫苗名称的准确性上优于其他模型，展示了其在自动化数据提取中的高效性。量化技术进一步提升了模型的部署效率。

研究结论: 大型语言模型在自动化急诊记录数据提取中具有显著潜力，能够支持高效的疫苗安全监测和早期不良事件检测。

中文摘要: 本研究评估了微调的Llama 3.2模型在从急诊分诊记录中提取疫苗相关信息的能力，以支持近实时疫苗安全监测。通过提示工程初步创建标注数据集，并由人工标注确认。比较了提示工程模型、微调模型和基于规则的方法。微调的Llama 3.2模型在提取疫苗名称的准确性上优于其他模型，并通过量化技术实现了在资源受限环境中的高效部署。研究结果表明，大型语言模型在自动化急诊记录数据提取中具有潜力，能够支持高效的疫苗安全监测和早期免疫后不良事件的检测。

</details>


### [159] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
**中文标题：基于信念函数的信用网络保守推理研究：信用链案例**

*Marco Sangalli,Thomas Krak,Cassio de Campos*

主要分类: cs.AI

摘要简述: 本文提出了一种基于Dempster-Shafer理论的信用网络不确定性传播新框架，特别针对链式结构，通过信念和似然函数高效生成保守区间，兼具计算速度和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索如何在信用网络中利用Dempster-Shafer理论进行不确定性推理，尤其是在链式结构中，以弥补传统敏感性分析的不足。

研究方法: 方法包括提出一种新的框架，利用信念和似然函数在信用链中传播不确定性，并对比信念推理与传统敏感性分析的效果。

研究结果: 数值结果表明，该方法在链式结构中具有高效性和鲁棒性，但也揭示了其局限性，为信用网络的实践应用提供了参考。

研究结论: 结论指出，基于信念的推理方法在信用链中具有潜力，但其适用范围和局限性需进一步研究。

中文摘要: 本文探讨了利用Dempster-Shafer理论在信用网络中进行信念推理的方法。基于前人研究，我们提出了一种在信用网络子类（链式结构）中传播不确定性的新框架。该方法通过信念和似然函数高效生成保守区间，兼具计算速度和鲁棒性。主要贡献包括形式化基于信念的推理方法，并将其与传统敏感性分析进行对比。数值结果突显了该框架下信念推理的优势与局限，为链式结构及一般信用网络的实践应用提供了见解。

</details>


### [160] [PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations](https://arxiv.org/abs/2507.07644)
**中文标题：PlanQA：基于结构化表示的大语言模型空间推理基准**

*Fedor Rodionov,Abdelrahman Eldesokey,Michael Birsak,John Femiani,Bernard Ghanem,Peter Wonka*

主要分类: cs.AI

摘要简述: PlanQA是一个用于评估大语言模型在几何和空间推理能力的诊断基准，基于结构化室内场景表示，揭示当前模型在真实世界布局推理中的盲点。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在几何和空间推理方面存在不足，尤其是在模拟物理约束、保持空间连贯性和布局扰动下的泛化能力上表现不佳。PlanQA旨在填补这一空白，推动语言模型在空间推理方面的研究。

研究方法: PlanQA采用结构化表示（如JSON、XML）编码室内场景（如厨房、客厅、卧室），设计多样化问题类型，测试度量与拓扑推理（如距离、可见性、最短路径）以及室内设计约束（如可用性、间隙、平衡）。

研究结果: 实验表明，当前开源和商业大语言模型在浅层查询中表现尚可，但在模拟物理约束、保持空间连贯性和布局扰动下的泛化能力上存在显著不足。

研究结论: PlanQA揭示了大语言模型在真实世界布局推理中的盲点，为未来研究提供了方向，希望推动语言模型在空间推理方面的进步。

中文摘要: 我们提出了PlanQA，一个用于评估大语言模型在几何和空间推理能力的诊断基准。PlanQA基于结构化表示的室内场景（如厨房、客厅、卧室），采用符号化格式（如JSON、XML布局）编码。该基准包含多样化问题类型，不仅测试度量与拓扑推理（如距离、可见性、最短路径），还涵盖室内设计约束（如可用性、间隙、平衡）。我们对多种前沿开源和商业大语言模型的测试结果表明，尽管模型在浅层查询中可能成功，但在模拟物理约束、保持空间连贯性或布局扰动下的泛化能力上常常失败。PlanQA揭示了当前大语言模型的一个明显盲点：它们无法一致地推理真实世界的布局。我们希望这一基准能激发新的研究，推动语言模型在实际场景中准确推断和操作空间与几何属性。

</details>


### [161] [Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization](https://arxiv.org/abs/2507.07723)
**中文标题：LLM的稳定偏好优化：超越直接偏好优化的双层方法**

*Chengtao Jian,Kai Yang,Ye Ouyang,Xiaozhou Ye*

主要分类: cs.AI

摘要简述: 本文分析了直接偏好优化（DPO）的理论局限性和动态特性，发现其对初始化敏感且易导致概率分配错误。作者提出了一种双层优化框架，结合监督微调和改进的DPO目标，通过正则化提升稳定性和对齐效果。实验表明，该方法在推理和摘要任务中优于标准DPO。


<details>
  <summary>详细信息</summary>
研究动机: 直接偏好优化（DPO）虽在语言模型对齐中表现高效，但其理论特性和内在局限性尚未充分研究。本文旨在揭示DPO的动态特性及其潜在问题（如对初始化的敏感性和概率分配错误），并提出更稳定的优化方法。

研究方法: 作者提出了一种双层优化框架，将监督微调与改进的DPO目标（稳定偏好优化）紧密结合。通过引入正则化方案，明确鼓励对偏好输出的绝对概率提升，同时保持优化的稳定性。

研究结果: 实验结果表明，该方法在推理和摘要任务中显著提升了推理准确性，并更好地对齐输出分布与预期偏好，优于标准DPO。

研究结论: 稳定偏好优化为偏好对齐目标的设计提供了新思路，并为更可靠、可解释的语言模型对齐开辟了新途径。

中文摘要: 直接偏好优化（DPO）已成为一种流行且高效的方法，用于通过奖励建模和强化学习对齐语言模型与人类偏好。尽管其经验成功，DPO的理论特性和内在局限性仍未充分探索。本文首先从概率演化的角度对DPO的动态特性进行了全面分析。分析表明，DPO对初始化高度敏感，且易导致概率分配错误，可能无意中将概率转移到无关或不期望的响应上。这种错误分配可能无意中强化模型偏差，从而损害模型对齐的稳定性和与预期偏好的一致性。基于这些理论发现，我们提出了一种理论支持的双层优化框架，将监督微调与改进的DPO目标（即稳定偏好优化）紧密结合。我们的方法引入了一种原则性的正则化方案，明确鼓励对偏好输出的绝对概率提升，同时保持稳定的优化动态。在具有挑战性的推理和摘要基准上的实验表明，我们的方法显著提升了推理准确性，并更好地对齐输出分布与预期偏好，优于标准DPO。稳定偏好优化为偏好对齐目标的设计提供了新见解，并为更可靠、可解释的语言模型对齐开辟了新途径。

</details>


### [162] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
**中文标题：基于轮廓线分类的小提琴尺寸缩减识别**

*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

主要分类: cs.AI

摘要简述: 本文提出了一种基于轮廓线分类的小提琴尺寸缩减识别方法，通过分析3D几何网格和抛物线拟合参数，发现开口参数β最具预测性。


<details>
  <summary>详细信息</summary>
研究动机: 16世纪末至18世纪，小提琴制作标准多样化，尺寸缩减影响了轮廓线形状（U形或V形）。专家虽能观察但缺乏定量研究，本文旨在填补这一空白。

研究方法: 研究25把小提琴的3D几何网格，提取10-20条轮廓线并拟合抛物线曲线（y=α*|x|^β）。通过回归和阈值计算特征，处理异常值后生成数值化轮廓。

研究结果: 分类方法表明，几何特征可一定程度预测尺寸缩减，但完全量化存在困难。开口参数β最具预测性。

研究结论: 轮廓线分类方法可用于识别小提琴尺寸缩减，β参数是关键指标，但需进一步研究以完善量化标准。

中文摘要: 第一批小提琴出现于16世纪末的意大利。随后200年间，它们传遍欧洲，各地制琴师尝试新技术，创造了高度多样化的乐器家族。约1750年，为统一乐团和音乐学院的小提琴制作，引入了尺寸标准。介于标准之间的乐器被制琴师缩减为较小尺寸。这种缩减影响了小提琴的多个特征，尤其是轮廓线（即等高线），未缩减乐器呈U形，缩减后呈V形。专家虽能观察这些差异，但尚未进行定量研究。

本文提出了一种基于轮廓线分类的小提琴尺寸缩减识别方法。研究使用摄影测量技术获取25把乐器的3D几何网格，每把乐器提取10-20条间距1毫米的轮廓线。每条线拟合为抛物线状曲线（方程为y=α*|x|^β），参数α和β分别描述曲线的垂直拉伸和开口程度。通过回归和阈值计算额外特征，处理异常值后生成每把乐器的数值化轮廓。

随后应用分类方法评估几何特征是否能预测尺寸缩减。研究发现，区分缩减与非缩减乐器具有一定可行性，但完全量化存在困难，尤其是对部分改造的乐器。开口参数β最具预测性。

</details>


### [163] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
**中文标题：衡量AI与人类繁荣的契合度**

*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

主要分类: cs.AI

摘要简述: 本文提出了一种名为FAI Benchmark的新评估框架，用于衡量AI在七个维度上与人类繁荣的契合度。测试28个主流语言模型后发现，尽管部分模型表现较好，但无一能在所有维度上达到理想契合，尤其在信仰与灵性、品格与美德、意义与目的方面表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 传统AI评估主要关注技术能力或避免危害，而忽略了AI对人类全面繁荣的贡献。本文旨在填补这一空白，通过多维度评估框架，推动AI系统更积极地支持人类福祉。

研究方法: FAI Benchmark通过1229个主客观问题，结合专门设计的评判语言模型和跨维度评估方法，采用几何平均评分，全面衡量AI在七个维度上的表现。

研究结果: 测试28个主流语言模型后，最高得分模型为72/100，但所有模型均未在所有维度上达到理想契合，尤其在信仰与灵性、品格与美德、意义与目的方面表现较差。

研究结论: FAI Benchmark为开发更支持人类繁荣的AI系统提供了框架，对AI发展、伦理和评估具有重要启示。

中文摘要: 本文介绍了Flourishing AI Benchmark（FAI Benchmark），一种新颖的评估框架，用于衡量AI在七个维度上与人类繁荣的契合度：品格与美德、亲密社会关系、幸福与生活满意度、意义与目的、心理与身体健康、财务与物质稳定、信仰与灵性。与传统关注技术能力或避免危害的评估不同，FAI Benchmark通过1229个主客观问题，结合专门设计的评判语言模型和跨维度评估方法，采用几何平均评分，全面衡量AI对人类繁荣的贡献。初步测试28个主流语言模型后发现，尽管部分模型表现较好（最高得分72/100），但无一能在所有维度上达到理想契合，尤其在信仰与灵性、品格与美德、意义与目的方面表现不佳。本研究为开发更支持人类繁荣的AI系统提供了框架，对AI发展、伦理和评估具有重要启示。

</details>


### [164] [MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving](https://arxiv.org/abs/2507.07818)
**中文标题：MoSE：面向自动驾驶的技能分步混合专家学习**

*Lu Xu,Jiaqian Yu,Xiongfeng Peng,Yiwei Chen,Weiming Li,Jaewook Yoo,Sunghyun Chunag,Dongwook Lee,Daehyun Ji,Chao Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为MoSE的技能导向混合专家模型，通过模仿人类驾驶员的学习和推理过程，实现技能分步学习，显著提升了自动驾驶系统的性能和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有混合专家模型（MoE）虽能提升性能，但需要大量数据和复杂优化。受人类驾驶员学习过程启发，作者提出MoSE，旨在通过技能分步学习实现高效自动驾驶。

研究方法: MoSE采用技能导向路由机制，定义并标注特定技能，构建分层技能数据集，预训练路由器以实现分步推理，同时整合辅助任务于单次前向过程。

研究结果: MoSE在CODA AD极端案例推理任务中表现优于多个8B+参数模型，激活参数量减少至少62.5%，且性能达到最优。

研究结论: MoSE通过技能分步学习和高效路由机制，显著提升了自动驾驶模型的性能和计算效率，为未来研究提供了新思路。

中文摘要: 近期研究表明，基于网络规模数据训练的大型语言模型（LLMs）和视觉语言模型（VLMs）能够增强端到端自动驾驶系统的泛化能力和可解释性。具体而言，混合专家（MoE）技术通过动态路由输入到专门的参数子集，使通用LLMs或VLMs在保持计算效率的同时显著提升性能。然而，通用MoE模型通常需要大量训练数据和复杂优化。本文受人类驾驶员学习过程启发，提出了一种技能导向的MoE模型MoSE，模拟人类驾驶员技能分步学习和推理过程。我们提出了一种技能导向路由机制，首先定义并标注特定技能，使专家能够识别不同场景和推理任务所需的驾驶能力，从而实现技能分步学习。进一步将驾驶过程与人类推理中的多步规划和端到端驾驶模型对齐，我们构建了分层技能数据集并预训练路由器，以鼓励模型逐步推理。与多轮对话不同，MoSE将宝贵辅助任务（如描述、推理、规划）整合于单次前向过程，无需额外计算成本。在激活参数量不足3B的情况下，我们的模型在CODA AD极端案例推理任务中表现优于多个8B+参数模型。与基于开源模型和数据的现有方法相比，我们的方法在单轮对话中实现了最优性能，同时显著减少了激活模型规模（至少62.5%）。

</details>


### [165] [AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift](https://arxiv.org/abs/2507.07820)
**中文标题：AI应更智能感知，而非更大规模：自适应感知作为范式转变**

*Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim*

主要分类: cs.AI

摘要简述: 当前AI依赖大规模模型和数据集，但成本高且不可持续。论文提出自适应感知作为新范式，通过动态调整传感器参数提升效率和小模型性能，并探讨其应用与挑战。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI依赖模型和数据集的规模扩展，导致环境、经济和伦理成本高昂，可持续性和公平性受限。受生物感知系统启发，论文提出自适应感知作为更高效、可持续的替代方案。

研究方法: 论文提出自适应感知范式，动态调整传感器参数（如曝光、灵敏度、多模态配置），以减少协变量偏移并提升效率。通过实证研究验证小模型（如EfficientNet-B0）在自适应感知下超越更大模型（如OpenCLIP-H）。

研究结果: 实证研究表明，自适应感知使小模型性能超越大模型，同时显著降低计算和数据需求。论文还提出应用路线图和技术挑战。

研究结论: 自适应感知是AI向可持续、鲁棒和公平系统转型的关键。论文呼吁推动标准化基准、实时算法、多模态集成和隐私保护方法的研究。

中文摘要: 当前AI的进步主要依赖神经模型规模的扩展和训练数据集的扩大以实现泛化和鲁棒性。尽管取得显著成功，但这一范式带来巨大的环境、经济和伦理成本，限制了可持续性和公平访问。受生物感知系统（如动态调整瞳孔大小、重新聚焦视觉）的启发，我们主张将自适应感知作为一种必要且基础的转变。自适应感知主动在输入层面调节传感器参数（如曝光、灵敏度、多模态配置），显著减少协变量偏移并提高效率。近期研究的实证证据表明，自适应感知使小模型（如EfficientNet-B0）超越训练数据和计算量显著更大的大模型（如OpenCLIP-H）。我们（i）提出将自适应感知广泛应用于人形机器人、医疗、自主系统、农业和环境监测的路线图，（ii）评估技术和伦理整合的挑战，（iii）提出针对性研究方向，如标准化基准、实时自适应算法、多模态集成和隐私保护方法。这些努力旨在推动AI社区向可持续、鲁棒和公平的人工智能系统转型。

</details>


### [166] [Searching for actual causes: Approximate algorithms with adjustable precision](https://arxiv.org/abs/2507.07857)
**中文标题：寻找实际原因：具有可调精度的近似算法**

*Samuel Reyd,Ada Diaconescu,Jean-Louis Dessalles*

主要分类: cs.AI

摘要简述: 本文提出了一种多项式复杂度的算法，用于识别实际原因，并支持精度和全面性的调整，解决了现有方法无法处理的非布尔、黑盒和随机系统问题。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，因果性在提升机器学习模型的性能、可靠性和可解释性方面受到关注。然而，传统可解释人工智能（XAI）和因果性研究主要关注因素与结果的关系，而非专家用户更期待的是导致目标结果的实际原因。目前，如何形式化这一概念仍是一个开放问题，且识别实际原因是一个NP完全问题，缺乏实用的近似解决方案。

研究方法: 本文提出了一组多项式复杂度的算法，用于识别实际原因，并允许通过调整计算时间来提高精度和全面性。这些算法能够处理非布尔、黑盒和随机系统，填补了现有方法的空白。

研究结果: 实验表明，所提出的算法能够识别现有方法无法处理的系统（如非布尔、黑盒和随机系统）中的原因，并且可以通过增加计算时间进一步提升精度和全面性。

研究结论: 本文提出的算法为实际原因的识别提供了一种实用且灵活的解决方案，适用于多种复杂系统，同时支持精度和计算效率的权衡。

中文摘要: 近年来，因果性逐渐受到关注，并在提升机器学习模型的性能、可靠性和可解释性方面发挥了作用。然而，当前可解释人工智能（XAI）的研究面临批评。传统的XAI和因果性研究主要关注哪些因素导致了哪些结果，这种知识对研究人员和工程师有价值，但并非非专家用户所期待的“解释”。这些用户更希望了解导致目标结果的具体事实，即实际原因。形式化这一概念仍是一个开放问题，且识别实际原因被证明是一个NP完全问题，目前缺乏实用的近似解决方案。本文提出了一组多项式复杂度的算法，用于识别实际原因，并支持精度和全面性的调整。实验表明，这些算法（1）能够识别现有方法无法处理的系统（如非布尔、黑盒和随机系统）中的原因，（2）可以通过增加计算时间进一步提高精度和全面性。

</details>


### [167] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
**中文标题：结合提示工程与多维知识图谱的法律纠纷分析集成框架**

*Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo*

主要分类: cs.AI

摘要简述: 本文提出了一种结合提示工程和多维知识图谱的增强框架，用于提升法律纠纷分析的性能。通过三阶段提示结构和三层知识图谱架构，结合四种法律概念检索方法，显著提高了法律决策的准确性和推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在智能法律系统中面临法律知识表示不足、概念理解有限和推理缺陷等问题。为解决这些问题，研究提出了一种集成提示工程和多维知识图谱的框架，以增强法律纠纷分析的性能。

研究方法: 研究提出了一种三阶段层次化提示结构（任务定义、知识背景和推理指导），并结合法律专用推理模板和动态优化机制。同时，构建了三层知识图谱架构（法律分类本体、表示层和实例层），并采用四种互补方法（法律规范代码匹配、领域语义向量相似性、本体路径推理和专用词汇分割）进行精确法律概念检索。

研究结果: 实验结果表明，该框架在法律纠纷分析中显著提升了性能，能够准确分析复杂案例的法律适用，并对司法决策逻辑有更细致的理解。

研究结论: 该研究为智能法律辅助系统的实现提供了一种新颖的技术路径，通过结合提示工程和多维知识图谱，有效解决了法律分析中的知识表示和推理问题。

中文摘要: 人工智能的快速发展使大型语言模型成为智能法律系统的核心组成部分。然而，这些模型在法律纠纷分析中存在显著局限性，包括法律知识表示不足、概念理解有限和推理缺陷。本研究提出了一种结合提示工程和多维知识图谱的增强框架。该框架引入了三阶段层次化提示结构（任务定义、知识背景和推理指导），并辅以法律专用推理模板和动态优化机制。同时，构建了三层知识图谱架构（法律分类本体、表示层和实例层）。四种互补方法实现了精确的法律概念检索：直接法律规范代码匹配、领域专用语义向量相似性、基于本体的路径推理和专用词汇分割。这些组件与网络搜索技术结合，建立了知识增强的法律决策框架。实验结果表明，该框架在法律纠纷分析中显著提升了性能，能够准确分析复杂案例的法律适用，同时对司法决策逻辑有更细致的理解，为智能法律辅助系统的实现提供了新颖的技术路径。

</details>


### [168] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
**中文标题：谦逊模型将主宰世界**

*Hans Gundlach,Jayson Lynch,Neil Thompson*

主要分类: cs.AI

摘要简述: 本文认为，随着计算资源投入的边际效益递减，AI模型性能将趋于收敛，即使资源有限的小型模型也能接近顶级模型的性能。作者通过模型分析和实证数据支持这一观点，并呼吁重新审视AI战略与政策。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI领域由少数公司主导，导致模型性能不平等。作者挑战主流观点，认为计算资源的边际效益递减将促使模型性能趋同，小型模型也能达到顶级性能。

研究方法: 作者构建了一个模型，证明在固定分布的下一词预测目标下，计算资源的边际效益显著下降。同时，通过基准数据和理论模型分析，验证了训练损失差异等代理指标的重要性。

研究结果: 分析表明，计算资源的边际效益递减现象显著，即使计算能力指数级增长的公司，其模型性能优势也将逐渐消失。实证数据支持小型模型性能接近顶级模型的趋势。

研究结论: 随着小型模型性能的提升，AI战略和政策需重新评估。作者指出这一趋势将影响多个领域，并呼吁关注计算资源分配的公平性。

中文摘要: 过去十年中，少数公司通过大规模扩展AI系统，导致了AI模型性能的不平等。本文提出，与主流直觉相反，计算资源投入的边际效益递减将促使AI模型性能趋同。换句话说，资源有限的“谦逊模型”将接近顶级模型的性能水平。我们开发了一个模型，表明在固定分布的下一词预测目标下，计算资源的边际效益显著下降。根据当前的扩展实践，我们认为这种边际效益递减现象足够显著，以至于即使计算能力指数级增长的公司，其模型性能优势也将逐渐消失。作为论证的一部分，我们通过基准数据和理论模型，证明了训练损失差异等代理指标的重要性。此外，我们还分析了AI模型性能差异的实证数据。最后，鉴于小型模型性能的提升，我们认为AI战略和政策需要重新审视，并概述了这一转变将影响的领域。

</details>


### [169] [Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)
**中文标题：与AI共事：衡量生成式AI的职业影响**

*Kiran Tomlinson,Sonia Jaffe,Will Wang,Scott Counts,Siddharth Suri*

主要分类: cs.AI

摘要简述: 本文通过分析用户与生成式AI的互动数据，研究了AI对不同职业的影响，发现知识型工作（如计算机、行政支持）和销售等职业最易受AI影响，并探讨了AI适用性与工资、教育的关系。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI的快速普及，了解AI对经济的影响成为社会关注的重要问题。本文旨在通过分析用户与AI的互动数据，揭示AI对不同职业任务的影响。

研究方法: 研究分析了20万条用户与微软Bing Copilot的匿名对话数据，识别用户寻求AI帮助的常见任务（如信息收集、写作），并计算了各职业的AI适用性评分。

研究结果: 研究发现，知识型职业（如计算机、行政支持）和销售等职业的AI适用性最高。此外，AI在信息提供、写作、教学等任务中表现最成功。

研究结论: 生成式AI对知识型职业和沟通密集型职业的影响显著，其适用性与工资和教育水平相关，实际使用情况与职业AI影响预测存在差异。

中文摘要: 随着生成式AI的快速普及及其对广泛任务的潜在影响，理解AI对经济的影响成为社会最重要的议题之一。本研究通过分析人们与AI共同完成的工作活动、这些活动的成功率和范围，并结合职业活动数据，向这一目标迈进了一步。我们分析了20万条用户与微软Bing Copilot（一款公开可用的生成式AI系统）的匿名对话数据。研究发现，用户最常寻求AI帮助的任务是信息收集和写作，而AI最常执行的任务是提供信息和帮助、写作、教学和建议。结合这些活动分类与任务成功率和影响范围的测量，我们计算了每个职业的AI适用性评分。结果显示，知识型职业（如计算机和数学、办公室和行政支持）以及销售等沟通密集型职业的AI适用性最高。此外，我们还探讨了AI表现最成功的任务类型、工资和教育与AI适用性的相关性，以及实际使用情况与职业AI影响预测的对比。

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [170] [Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics](https://arxiv.org/abs/2507.07155)
**中文标题：评估检索增强生成代理在天体物理学自主科学发现中的应用**

*Xueqing Xu,Boris Bolliet,Adrian Dimitrov,Andrew Laverick,Francisco Villaescusa-Navarro,Licong Xu,Íñigo Zubeldia*

主要分类: astro-ph.IM

摘要简述: 研究评估了9种检索增强生成（RAG）代理配置在105个宇宙学问答对上的表现，发现OpenAI嵌入和生成模型配置准确率最高（91.4%），并开发了LLM-as-a-Judge系统作为人类评估的替代方案。


<details>
  <summary>详细信息</summary>
研究动机: 旨在为天体物理学中的自主科学发现选择最佳RAG代理配置，并开发可扩展的评估工具。

研究方法: 构建了105个宇宙学问答对，手动评估9种RAG配置生成的945个答案，并基于人类评估结果校准LLM-as-a-Judge系统。

研究结果: OpenAI嵌入和生成模型的RAG配置表现最佳（91.4%准确率），LLM-as-a-Judge系统可作为人类评估的替代方案。

研究结论: 研究为天体物理学自主科学发现提供了最佳RAG配置和可扩展的评估工具，相关数据集和系统已公开。

中文摘要: 我们评估了9种检索增强生成（RAG）代理配置在专为此目的构建的105个宇宙学问答对上的表现。这些RAG配置由人类专家手动评估，共计评估了945个生成答案。研究发现，目前最佳的RAG代理配置为OpenAI嵌入和生成模型，准确率达91.4%。利用人类评估结果，我们校准了LLM-as-a-Judge（LLMaaJ）系统，该系统可作为人类评估的稳健替代方案。这些结果使我们能够系统地为天体物理学自主科学发现的多代理系统（如配套论文中提出的cmbagent）选择最佳RAG配置，并提供了一个可扩展至数千个宇宙学问答对的LLMaaJ系统。我们公开了问答数据集、人类评估结果、RAG流程和LLMaaJ系统，供天体物理学界进一步使用。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [171] [DpDNet: An Dual-Prompt-Driven Network for Universal PET-CT Segmentation](https://arxiv.org/abs/2507.07126)
**中文标题：DpDNet：一种用于通用PET-CT分割的双提示驱动网络**

*Xinglong Liang,Jiaju Huang,Luyi Han,Tianyu Zhang,Xin Wang,Yuan Gao,Chunyao Lu,Lishan Cai,Tao Tan,Ritse Mann*

主要分类: eess.IV

摘要简述: DpDNet是一种双提示驱动的网络，通过结合特定提示和通用提示，解决了PET-CT病灶分割中的噪声敏感性和形态多变问题，并在四种癌症类型上表现优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前主流方法将所有癌症视为单一任务进行分割，忽略了不同癌症类型的独特性。考虑到不同癌症在转移模式、器官偏好和FDG摄取强度上的特异性和相似性，需要一种能够捕捉癌症特异性特征并保留共享知识的方法。

研究方法: DpDNet采用双提示驱动机制，结合特定提示捕捉癌症特异性特征和通用提示保留共享知识。为避免早期引入提示导致的信息遗忘，解码器后使用提示感知头自适应处理多任务分割。

研究结果: 在包含四种癌症类型的PET-CT数据集上，DpDNet表现优于现有模型。基于分割结果计算的MTV、TLG和SUVmax可用于乳腺癌生存分析，表明DpDNet在个性化风险分层中具有潜力。

研究结论: DpDNet作为一种双提示驱动的网络，能够有效解决PET-CT病灶分割问题，并为临床医生优化治疗策略提供支持。

中文摘要: PET-CT病灶分割因噪声敏感性、病灶形态多变以及生理高代谢信号的干扰而具有挑战性。当前主流方法将所有癌症视为单一任务进行分割，但忽略了不同癌症类型的独特性。考虑到不同癌症在转移模式、器官偏好和FDG摄取强度上的特异性和相似性，我们提出DpDNet，一种双提示驱动网络，通过特定提示捕捉癌症特异性特征，通用提示保留共享知识。此外，为避免早期引入提示导致的信息遗忘，解码器后使用提示感知头自适应处理多任务分割。在包含四种癌症类型的PET-CT数据集上，DpDNet表现优于现有模型。基于分割结果计算的MTV、TLG和SUVmax可用于乳腺癌生存分析，结果表明DpDNet有望成为个性化风险分层的有效工具，支持临床医生优化治疗策略并改善预后。代码发布于https://github.com/XinglongLiang08/DpDNet。

</details>


### [172] [Semi-supervised learning and integration of multi-sequence MR-images for carotid vessel wall and plaque segmentation](https://arxiv.org/abs/2507.07496)
**中文标题：基于半监督学习和多序列MRI整合的颈动脉血管壁及斑块分割**

*Marie-Christine Pali,Christina Schwaiger,Malik Galijasevic,Valentin K. Ladenhauf,Stephanie Mangesius,Elke R. Gizewski*

主要分类: eess.IV

摘要简述: 本文提出了一种半监督深度学习方法，用于整合多序列MRI数据以实现颈动脉血管壁和斑块的精确分割。通过粗定位和精细分割网络，结合多序列融合策略，解决了标记数据稀缺和斑块形态复杂的问题。实验验证了方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 颈动脉斑块的多序列MRI分析对评估动脉粥样硬化和缺血性中风风险至关重要，但斑块形态复杂且标记数据稀缺，导致精确分割困难。本文旨在解决这些问题。

研究方法: 方法包括两个网络：粗定位模型确定感兴趣区域，精细分割模型精确描绘血管壁和斑块。提出多序列U-Net架构和多层次融合策略，并采用半监督学习增强数据一致性。

研究结果: 在52名动脉粥样硬化患者的五组MRI序列上验证，实验表明方法有效，并强调了U-Net架构中融合点选择的重要性。专家评估进一步验证了结果的准确性。

研究结论: 多序列融合策略和半监督学习在数据有限的MRI应用中显著提升了颈动脉分割的准确性，展示了其潜在应用价值。

中文摘要: 颈动脉及其斑块的多序列磁共振成像（MRI）分析对评估动脉粥样硬化和缺血性中风风险至关重要。为量化动脉粥样硬化状态，精确分割是评估指标和放射组学特征的基础。然而，斑块的复杂形态和标记数据的稀缺性带来了显著挑战。本文提出了一种半监督深度学习方法，旨在有效整合多序列MRI数据以实现颈动脉血管壁和斑块的分割。算法包含两个网络：粗定位模型基于先验知识确定颈动脉位置和数量的感兴趣区域，精细分割模型则精确描绘血管壁和斑块。为整合不同MRI序列的互补信息，研究了多种融合策略，并引入了多层次多序列U-Net架构。针对标记数据有限和颈动脉MRI复杂性，提出了一种半监督方法，通过输入变换增强一致性。方法在52名动脉粥样硬化患者的五组MRI序列上进行了评估，实验证明了其有效性，并强调了U-Net架构中融合点选择的重要性。专家评估进一步验证了结果的准确性。研究结果凸显了融合策略和半监督学习在数据有限的MRI应用中提升颈动脉分割效果的潜力。

</details>


### [173] [D-CNN and VQ-VAE Autoencoders for Compression and Denoising of Industrial X-ray Computed Tomography Images](https://arxiv.org/abs/2507.07704)
**中文标题：用于工业X射线计算机断层扫描图像压缩和去噪的D-CNN和VQ-VAE自编码器**

*Bardia Hejazi,Keerthana Chand,Tobias Fritsch,Giovanni Bruno*

主要分类: eess.IV

摘要简述: 本研究探讨了使用深度卷积神经网络（D-CNN）和向量量化变分自编码器（VQ-VAE）对工业X射线计算机断层扫描（XCT）图像进行压缩和去噪的效果，比较了不同压缩率下图像恢复的质量，并提出了对边缘保护敏感的指标。


<details>
  <summary>详细信息</summary>
研究动机: 随着成像技术的进步，工业XCT数据量急剧增长，需要高效可靠的存储解决方案。本研究旨在探索深度学习自编码器在XCT数据压缩中的应用，并分析其对恢复数据质量的影响。

研究方法: 使用两种网络架构（D-CNN和VQ-VAE）对砂岩样本的XCT数据进行压缩，比较不同压缩率下解码图像的质量，并引入对边缘保护敏感的指标以优化解码质量。

研究结果: 研究表明，不同架构和压缩率的选择需根据后续分析的具体需求而定，某些架构在保留边缘信息方面表现更优。

研究结论: 本研究为科学家提供了选择数据存储和分析策略的依据，强调了根据需求选择合适压缩方法和指标的重要性。

中文摘要: 随着成像技术的进步，成像科学中的数据量急剧增长，这要求为这些大型数据集提供高效可靠的存储解决方案。本研究探讨了使用深度学习自编码器对工业X射线计算机断层扫描（XCT）数据进行压缩的方法，并分析了这些压缩算法对恢复数据质量的影响。研究采用了两种具有不同压缩率的网络架构：深度卷积神经网络（D-CNN）和向量量化变分自编码器（VQ-VAE）。使用的XCT数据来自具有复杂内部孔隙网络的砂岩样本。研究量化了两种不同深度学习架构在不同压缩率下解码图像的质量，并与原始输入数据进行了比较。此外，为提高图像解码质量指标，我们引入了一种对边缘保护敏感的指标，这对三维数据分析至关重要。研究表明，根据后续分析所需保留的具体特征，需要选择不同的架构和压缩率。本研究的结果可为科学家确定数据存储和分析需求提供参考。

</details>


### [174] [Compressive Imaging Reconstruction via Tensor Decomposed Multi-Resolution Grid Encoding](https://arxiv.org/abs/2507.07707)
**中文标题：基于张量分解多分辨率网格编码的压缩成像重建**

*Zhenyu Jin,Yisi Luo,Xile Zhao,Deyu Meng*

主要分类: eess.IV

摘要简述: 本文提出了一种名为GridTD的无监督连续表示框架，用于压缩成像重建。GridTD结合了多分辨率网格编码的层次建模能力和张量分解的紧凑性，实现了高效且高精度的图像重建。理论分析和实验验证表明，GridTD在多种压缩成像任务中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无监督表示方法在压缩成像重建中难以平衡表示能力和效率。为了解决这一问题，本文提出GridTD框架，旨在通过多分辨率网格编码和张量分解的结合，提升重建的准确性和效率。

研究方法: GridTD框架通过优化轻量级神经网络和输入张量分解模型，利用多分辨率哈希网格编码学习参数。该方法结合了多分辨率网格编码的层次建模能力和张量分解的紧凑性，实现了高效的高维图像重建。

研究结果: 理论分析表明，GridTD在Lipschitz性质、泛化误差界限和固定点收敛性方面具有优势。实验验证了GridTD在视频SCI、光谱SCI和压缩动态MRI重建等任务中的优越性，性能优于现有方法。

研究结论: GridTD作为一种多功能且先进的压缩成像重建方法，通过结合多分辨率网格编码和张量分解，显著提升了重建效率和准确性，为压缩成像领域提供了新的解决方案。

中文摘要: 压缩成像（CI）重建，如快照压缩成像（SCI）和压缩感知磁共振成像（MRI），旨在从低维压缩测量中恢复高维图像。这一过程的关键在于学习高维图像的准确表示。然而，现有的无监督表示方法可能难以在表示能力和效率之间达到理想平衡。为克服这一限制，我们提出了张量分解多分辨率网格编码（GridTD），一种用于CI重建的无监督连续表示框架。GridTD通过优化轻量级神经网络和输入张量分解模型，利用多分辨率哈希网格编码学习参数，兼具多分辨率网格编码的层次建模能力和张量分解的紧凑性，实现了高效且高精度的图像重建。理论分析揭示了GridTD在Lipschitz性质、泛化误差界限和固定点收敛性方面的内在优势。在视频SCI、光谱SCI和压缩动态MRI重建等多样化CI任务中的广泛实验表明，GridTD优于现有方法，成为一种多功能且先进的CI重建方法。

</details>


### [175] [Breast Ultrasound Tumor Generation via Mask Generator and Text-Guided Network:A Clinically Controllable Framework with Downstream Evaluation](https://arxiv.org/abs/2507.07721)
**中文标题：基于掩模生成器和文本引导网络的乳腺超声肿瘤生成：一种临床可控框架及其下游评估**

*Haoyu Pan,Hongxin Lin,Zetian Feng,Chuxuan Lin,Junyang Mo,Chu Zhang,Zijian Wu,Yi Wang,Qingqing Zheng*

主要分类: eess.IV

摘要简述: 本文提出了一种临床可控的生成框架，通过结合临床描述和结构掩模生成乳腺超声图像，显著提升了深度学习模型的训练效果，并在下游诊断任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 由于专家标注的乳腺超声图像数据稀缺，限制了深度学习模型的开发。为了解决这一问题，本文提出了一种可控的生成框架，旨在通过合成图像提升模型性能。

研究方法: 框架结合临床描述和结构掩模生成肿瘤图像，设计了语义-曲率掩模生成器，通过临床先验生成多样化的肿瘤掩模。生成的掩模作为输入，产生高度个性化的合成图像。

研究结果: 在六个公开乳腺超声数据集上的定量评估表明，合成图像显著提升了乳腺癌诊断任务的性能。视觉图灵测试也证实了生成图像的真实性。

研究结论: 该框架不仅解决了数据稀缺问题，还为临床应用提供了潜在支持，展示了生成图像在医疗领域的实用性。

中文摘要: 由于专家标注数据的稀缺，乳腺超声（BUS）图像分析的深度学习模型开发受到显著限制。为解决这一问题，我们提出了一种临床可控的生成框架，用于合成BUS图像。该框架通过结合临床描述和结构掩模生成肿瘤，实现了对肿瘤形态、回声性和形状等特征的精细控制。此外，我们设计了一种语义-曲率掩模生成器，通过临床先验生成结构多样化的肿瘤掩模。在推理阶段，合成肿瘤掩模作为生成框架的输入，产生高度个性化的合成BUS图像，其肿瘤形态反映了真实世界的多样性。在六个公开BUS数据集上的定量评估表明，我们的合成图像具有显著的临床实用性，能够有效提升下游乳腺癌诊断任务的性能。此外，经验丰富的超声医师进行的视觉图灵测试证实了生成图像的真实性，表明该框架具有支持更广泛临床应用的潜力。

</details>


### [176] [MeD-3D: A Multimodal Deep Learning Framework for Precise Recurrence Prediction in Clear Cell Renal Cell Carcinoma (ccRCC)](https://arxiv.org/abs/2507.07839)
**中文标题：MeD-3D：一种用于透明细胞肾细胞癌（ccRCC）精确复发预测的多模态深度学习框架**

*Hasaan Maqsood,Saif Ur Rehman Khan*

主要分类: eess.IV

摘要简述: 本文提出了一种名为MeD-3D的多模态深度学习框架，通过整合CT、MRI、组织病理学、临床数据和基因组学数据，提高了透明细胞肾细胞癌（ccRCC）复发的预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 透明细胞肾细胞癌（ccRCC）的复发预测由于疾病的分子、病理和临床异质性而面临挑战。传统单模态模型无法全面捕捉疾病复杂性，导致预测准确性不足。本研究旨在通过多模态数据整合提升预测效果。

研究方法: 研究提出了一种深度学习框架，整合了CT、MRI、组织病理学全切片图像（WSI）、临床数据和基因组学数据。使用CLAM模型处理WSI，MeD-3D模型处理CT和MRI图像，多层感知机（MLP）处理临床和基因组数据。通过早期和晚期融合策略结合多模态特征，并支持数据缺失情况下的推理。

研究结果: 该框架能够有效整合多模态数据，显著提高了ccRCC复发的预测准确性，并支持临床决策。

研究结论: MeD-3D框架通过多模态数据融合显著提升了ccRCC复发预测的准确性，为临床决策提供了有力工具。

中文摘要: 透明细胞肾细胞癌（ccRCC）的复发预测由于疾病的分子、病理和临床异质性而面临重大临床挑战。传统的预后模型依赖单一数据模态（如影像学、组织病理学或基因组学），往往无法全面捕捉疾病复杂性，导致预测准确性不足。本研究旨在通过提出一种深度学习（DL）框架克服这些限制，该框架整合了CT、MRI、组织病理学全切片图像（WSI）、临床数据和基因组学数据，以提高ccRCC复发的预测准确性并优化临床决策。该框架使用了来自TCGA、TCIA和CPTAC等多个公开来源的综合数据集。为处理多样化的模态，采用了领域特定模型：CLAM（基于ResNet50的模型）用于WSI，MeD-3D（预训练的3D-ResNet18模型）用于CT和MRI图像，多层感知机（MLP）用于结构化临床和基因组数据。这些模型旨在从每种模态中提取深度特征嵌入，并通过早期和晚期融合架构进行整合。这种融合策略使模型能够结合多源互补信息。此外，该框架设计用于处理临床环境中常见的数据缺失问题，支持在部分模态缺失的情况下进行推理。

</details>


### [177] [ArteryX: Advancing Brain Artery Feature Extraction with Vessel-Fused Networks and a Robust Validation Framework](https://arxiv.org/abs/2507.07920)
**中文标题：ArteryX：基于血管融合网络和稳健验证框架的脑动脉特征提取技术**

*Abrar Faiyaz,Nhat Hoang,Giovanni Schifitto,Md Nasir Uddin*

主要分类: eess.IV

摘要简述: ArteryX是一种基于MATLAB的半自动脑动脉特征提取工具箱，通过血管融合网络和标准化验证框架，高效准确地量化血管特征，显著提升对细微血管变化的敏感性。


<details>
  <summary>详细信息</summary>
研究动机: 脑血管病变对认知衰退和神经系统疾病有重要影响，但现有评估工具多关注主要动脉异常，缺乏对细微血管变化的定量分析。现有方法存在用户依赖性高、学习曲线陡峭和标准化验证不足等问题。

研究方法: ArteryX采用基于血管融合网络的标志点追踪方法，结合半监督学习框架，高效处理血管追踪问题，避免血管断裂或连接错误。此外，通过模拟真实血管的验证框架，使用预定义的真实特征进行定量验证。

研究结果: 在脑小血管病患者中的验证表明，ArteryX对细微血管变化的敏感性优于现有半自动方法，处理时间仅为每例10-15分钟（0.5毫米分辨率）。

研究结论: ArteryX为脑血管特征提取提供了高效、标准化的工具，有望推动脑血管病变的早期检测和跨患者队列的标准化比较。

中文摘要: 脑血管病变显著影响认知衰退和神经系统疾病，凸显了评估血管完整性的先进工具的必要性。三维时间飞跃磁共振血管成像（3D TOF MRA）广泛用于脑血管可视化，但临床评估通常关注主要动脉异常，忽视了理解细微血管变化的关键定量指标。现有从MRA提取结构、几何和形态动脉特征的方法（无论是手动还是自动）面临用户依赖性、学习曲线陡峭和缺乏标准化定量验证等挑战。我们提出了一种名为ArteryX的新型半自动动脉评估框架，这是一个基于MATLAB的工具箱，能够高效准确地量化血管特征，每例处理时间约为10-15分钟（0.5毫米分辨率），且用户干预极少。ArteryX采用基于血管融合网络的标志点追踪方法，有效解决了血管断裂或连接错误的问题。在脑小血管病患者中的验证表明，其对细微血管变化的敏感性优于现有半自动方法。重要的是，ArteryX工具箱通过整合模拟真实血管的验证框架（利用血管融合图节点和预定义的真实特征）实现了定量特征验证。因此，ArteryX框架有望成为特征提取工具箱的基准，并无缝集成到临床工作流程中，推动脑血管病变的早期检测和跨患者队列的标准化比较，从而深化对血管对脑健康贡献的理解。

</details>


### [178] [Wrist bone segmentation in X-ray images using CT-based simulations](https://arxiv.org/abs/2507.07131)
**中文标题：基于CT模拟的X射线图像腕骨分割**

*Youssef ElTantawy,Alexia Karantana,Xin Chen*

主要分类: eess.IV

摘要简述: 本文提出了一种基于CT模拟的X射线图像腕骨分割方法，通过生成大量模拟X射线图像训练深度学习模型，解决了真实X射线图像标注困难的问题，并在模拟和真实数据上均取得了优异表现。


<details>
  <summary>详细信息</summary>
研究动机: X射线图像分割是计算机辅助诊断系统的关键步骤，但标注高质量数据耗时且需要专业知识，尤其是腕骨分割因多块小骨重叠而更具挑战性。本文旨在通过CT模拟生成大量标注数据，以解决真实X射线图像标注不足的问题。

研究方法: 利用CT体积数据生成大量模拟X射线图像及其对应的10块腕骨标签，用于训练深度学习模型。该方法在模拟和真实X射线图像上进行了评估。

研究结果: 在模拟数据集上，Dice分数为0.80至0.92；真实X射线图像的定性分析也显示模型性能优异。模型和模拟代码已公开供研究使用。

研究结论: 基于CT模拟的方法有效解决了腕骨分割中的数据标注问题，模型在模拟和真实数据上均表现优异，为相关研究提供了实用工具。

中文摘要: X射线是临床诊断（如骨折、肺炎、癌症筛查等）中最常见的影像模态之一。X射线图像分割是许多计算机辅助诊断系统的关键步骤，但仍具挑战性。基于深度学习的方法在医学图像分割任务中表现优异，但通常需要大量高质量标注数据进行模型训练。提供此类标注数据不仅耗时，还需要高水平的专业知识。腕骨X射线图像分割尤其困难，因为图像中多块小腕骨重叠。为解决数据标注问题，本研究利用大量从CT体积生成的模拟X射线图像及其对应的10块腕骨标签，训练深度学习模型用于真实X射线图像的腕骨分割。所提方法在模拟图像和真实图像上均进行了评估。模拟数据集在不同视角下的Dice分数为0.80至0.92。对真实X射线图像分割结果的定性分析也表明训练模型的优异性能。训练模型和X射线模拟代码已免费供研究使用：链接将在接受后提供。

</details>


### [179] [Label-Efficient Chest X-ray Diagnosis via Partial CLIP Adaptation](https://arxiv.org/abs/2507.07254)
**中文标题：通过部分CLIP适应实现标签高效的胸部X光诊断**

*Heet Nitinkumar Dalsania*

主要分类: eess.IV

摘要简述: 本文提出了一种标签高效的胸部X光诊断方法，通过部分微调CLIP模型的视觉编码器，在少量标注数据下实现显著性能提升，模拟医院实际场景。


<details>
  <summary>详细信息</summary>
研究动机: 医疗影像标注数据获取困难，成本高且隐私问题突出。本文旨在提出一种标签高效的方法，模拟医院内部工作流程，解决标注稀疏的问题。

研究方法: 使用NIH Chest X-ray14数据集和预训练的CLIP ViT-B/32模型，通过部分微调视觉编码器，评估零样本和少样本学习（每类1-16个标注样本）的性能。

研究结果: 实验表明，CLIP的预训练视觉语言特征可有效适应少样本医疗影像任务，平均AUC分数比零样本基线提升超过20%。

研究结论: 本研究为常见和罕见疾病的诊断提供了一种实用且可扩展的解决方案，适用于标注稀疏的医院场景。

中文摘要: 现代深度学习在医疗影像中的应用通常依赖于大量标注数据，但这些数据由于隐私问题、高成本和病例稀缺性而难以获取。本文提出了一种标签高效的胸部X光诊断策略，旨在模拟真实医院场景。实验使用NIH Chest X-ray14数据集和预训练的CLIP ViT-B/32模型，通过部分微调其视觉编码器，并利用零样本和少样本学习（每类1-16个标注样本）进行评估。测试表明，CLIP的预训练视觉语言特征可有效适应少样本医疗影像任务，平均AUC分数比零样本基线提升超过20%。本研究的关键在于模拟医院内部工作流程，即图像存档丰富但标注稀疏的情况。这项工作为常见和罕见疾病的诊断提供了一种实用且可扩展的解决方案。此外，本研究仅用于学术和实验目的，尚未经过同行评审。所有代码可在https://github.com/heet007-code/CLIP-disease-xray找到。

</details>


### [180] [Computationally Efficient Information-Driven Optical Design with Interchanging Optimization](https://arxiv.org/abs/2507.07789)
**中文标题：基于交替优化的计算高效信息驱动光学设计**

*Eric Markley,Henry Pinkard,Leyla Kabuli,Nalini Singh,Laura Waller*

主要分类: eess.IV

摘要简述: 本文提出了一种名为IDEAL-IO的新方法，通过交替优化密度估计和光学参数，解决了IDEAL方法内存占用高、运行时间长的问题，显著提升了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有IDEAL方法在光学设计中存在内存占用高、运行时间长以及目标函数不匹配的问题，限制了其实际应用。本文旨在解决这些问题，提升信息驱动光学设计的实用性和可扩展性。

研究方法: 提出IDEAL-IO方法，将密度估计与光学参数优化解耦，通过交替拟合当前测量模型和更新光学参数，减少计算资源消耗并提升设计质量。

研究结果: 实验表明，IDEAL-IO在衍射光学、无透镜成像和快照3D显微镜等应用中，将运行时间和内存占用降低至多6倍，同时生成更优的设计方案。

研究结论: IDEAL-IO为信息驱动的光学设计提供了一种高效、可扩展的实用策略，适用于现实世界的成像系统设计。

中文摘要: 近期研究表明，成像系统可以通过其测量信息内容进行评估，从而实现无需计算解码的应用无关光学设计。信息驱动编码器分析学习（IDEAL）通过梯度方法自动化这一过程。然而，本研究发现，IDEAL在不同成像系统中存在内存占用高、运行时间长以及目标函数不匹配的问题。为此，我们提出IDEAL-IO方法，通过交替优化密度估计与光学参数，将运行时间和内存占用降低至多6倍，同时支持更具表达力的密度模型，从而生成更优的设计。我们在衍射光学、无透镜成像和快照3D显微镜应用中验证了该方法，证明信息论优化是一种实用且可扩展的现实世界成像系统设计策略。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [181] [Analysing semantic data storage in Distributed Ledger Technologies for Data Spaces](https://arxiv.org/abs/2507.07116)
**中文标题：分析分布式账本技术中语义数据存储在数据空间的应用**

*Juan Cano-Benito,Andrea Cimmino,Sven Hertling,Heiko Paulheim,Raúl García-Castro*

主要分类: cs.DC

摘要简述: 本文系统评估了分布式账本技术（DLT）在数据空间中存储语义数据的效率，比较了公有、私有和混合DLT的性能，发现私有DLT最有效，混合DLT在审计性和效率间取得平衡。


<details>
  <summary>详细信息</summary>
研究动机: 数据空间作为去中心化基础设施，需要实现语义互操作性，但目前缺乏在DLT上高效存储语义数据的研究。本文旨在填补这一空白。

研究方法: 研究使用真实知识图谱作为实验基础，系统评估了公有、私有和混合DLT在性能、存储效率、资源消耗及语义数据更新与查询能力方面的表现。

研究结果: 结果显示，私有DLT在存储和管理语义内容方面效率最高，而混合DLT在公共审计性和操作效率间提供了平衡。

研究结论: 研究为去中心化数据生态系统选择最适合的DLT基础设施提供了依据，需根据数据主权需求权衡审计性与效率。

中文摘要: 数据空间作为一种去中心化基础设施，正在兴起以实现多方参与者之间的主权、安全和可信数据交换。为实现这些环境中的语义互操作性，已提出使用语义网技术和知识图谱。尽管分布式账本技术（DLT）适合作为数据空间的基础设施，但在这些平台上高效存储语义数据仍存在显著差距。本文通过使用真实知识图谱作为实验基础，系统评估了不同类型DLT（公有、私有和混合）中语义数据存储的性能、存储效率、资源消耗以及更新和查询语义数据的能力。结果表明，私有DLT在存储和管理语义内容方面效率最高，而混合DLT在公共审计性和操作效率之间提供了平衡的权衡。本研究引发了对基于去中心化数据生态系统的数据主权需求选择最合适DLT基础设施的讨论。

</details>


### [182] [Collective Communication Profiling of Modern-day Machine Learning Workloads](https://arxiv.org/abs/2507.07117)
**中文标题：现代机器学习任务的集体通信行为分析**

*Jit Gupta,Andrew Li,Tarun Banka,Ariel Cohen,T. Sridhar,Raj Yavatkar*

主要分类: cs.DC

摘要简述: 本文分析了现代机器学习任务中的集体通信行为，揭示了高带宽和突发流量模式对网络性能的影响，并提出了优化通信框架和网络拓扑的必要性。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习任务在分布式高性能系统中运行时，涉及频繁的集体通信操作（如AllReduce、AllGather等），这些操作可能导致网络拥塞和数据包丢失，从而影响任务性能。因此，分析这些通信模式对优化网络资源配置至关重要。

研究方法: 研究通过Nvidia Collective Communication Library的日志功能，对多种模型（如DeepSeek、GPT、Llama等）的集体通信行为进行了详细分析。调整了并行性、节点数量和模型类型等配置参数，以观察其对通信行为的影响。

研究结果: 研究以开源DeepSeek V3推理模型为例，展示了操作类型、操作次数、传输大小和请求大小分布等结果。分析表明，当前的集体通信框架和网络拓扑需要重新设计，以适应网络异常对机器学习任务的影响。

研究结论: 研究强调了重新设计集体通信框架和网络拓扑的重要性，以应对机器学习任务中高带宽和突发流量带来的挑战。

中文摘要: 机器学习任务在大量分布式高性能系统上运行时，涉及周期性的集体通信操作（如AllReduce、AllGather和Broadcast）。这些操作可能产生高带宽和突发流量模式，导致网络拥塞和数据包丢失，从而影响任务性能。因此，分析这些模式对根据机器学习任务类型配置网络资源至关重要。本研究通过Nvidia集体通信库的日志功能，对多种模型（如DeepSeek、GPT、Llama等）的集体通信行为进行了广泛分析。调整了影响通信行为的配置参数（如并行性、节点数量和模型类型）。本文以开源DeepSeek V3推理模型为例，展示了操作类型、操作次数、每次操作的传输大小和请求大小分布等结果。分析表明，有必要重新设计当前的集体通信框架和网络拓扑，以适应网络异常对上述任务的影响。

</details>


### [183] [Helix Parallelism: Rethinking Sharding Strategies for Interactive Multi-Million-Token LLM Decoding](https://arxiv.org/abs/2507.07120)
**中文标题：螺旋并行：重新思考交互式多百万token LLM解码的分片策略**

*Nidhi Bhatia,Ankit More,Ritika Borkar,Tiyasa Mitra,Ramon Matas,Ritchie Zhao,Maximilian Golub,Dheevatsa Mudigere,Brian Pharris,Bita Darvish Rouhani*

主要分类: cs.DC

摘要简述: 本文提出Helix Parallelism，一种混合执行策略，通过KV并行和TP/EP结合，优化多百万token的LLM解码效率，显著降低延迟并提升批处理规模。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM扩展到多百万token的KV历史，实时自回归解码在严格的Token-to-Token延迟（TTL）约束下面临巨大压力。主要瓶颈在于FFN权重访问和长KV缓存读取。现有方法如TP虽能缓解FFN读取成本，但对注意力机制扩展性差，且DRAM读取效率随批处理规模线性增长。

研究方法: Helix Parallelism结合KV并行和TP/EP，在注意力阶段分片KV缓存到GPU，随后复用GPU进行密集LLM或MoE的FFN计算。通过轻量通信步骤保持精确注意力行为，并引入Helix HOP-B通过批处理重叠最小化通信开销。

研究结果: 与传统并行方法相比，Helix在固定批处理规模下降低TTL达1.5倍，支持32倍更大的批处理规模，显著提升Blackwell架构的吞吐-延迟Pareto效率。

研究结论: Helix Parallelism为超长序列实时推理提供了高效解决方案，显著优化了LLM解码的延迟和吞吐。

中文摘要: 随着LLM扩展到多百万token的KV历史，实时自回归解码在严格的Token-to-Token延迟（TTL）约束下面临巨大压力。两个核心瓶颈占主导地位：访问Feed-Forward Network（FFN）权重和读取长KV缓存。虽然Tensor Parallelism（TP）有助于缓解FFN权重读取成本，但对注意力的扩展性不佳。当TP宽度超过KV头数时，会导致低效的KV重复，限制并行性并约束批处理规模。同时，长KV历史的DRAM读取随批处理规模线性增长，进一步限制了效率。

我们提出Helix Parallelism，一种混合执行策略，在注意力阶段应用KV并行将KV缓存分片到GPU，随后在FFN计算中复用相同GPU进行密集LLM或TPxExpert Parallel（EP）的MoE计算。为保持精确的注意力行为，Helix包含轻量通信步骤。为最小化通信成本，我们引入Helix HOP-B。Helix HOP-B通过批处理重叠有效最小化通信开销，在保持低TTL的同时提升GPU效率。与传统并行方法相比，Helix在固定批处理规模下降低TTL达1.5倍，并在相同延迟预算下支持32倍更大的批处理规模（针对DeepSeek-R1），推动了Blackwell架构的吞吐-延迟Pareto优化，使超长序列实时推理成为可能。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [184] [ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing](https://arxiv.org/abs/2507.07551)
**中文标题：ArchiveGPT：基于视觉语言模型的图像编目人本评估**

*Line Abele,Gerrit Anders,Tolgahan Aydın,Jürgen Buder,Helen Fischer,Dominik Kimmel,Markus Huff*

主要分类: cs.HC

摘要简述: 研究探讨了使用视觉语言模型（VLM）自动生成图像目录描述的可行性，发现AI生成的描述在质量和准确性上接近人类专家，但仍需人工审核以确保专业性，尤其是在考古领域。专家对AI工具的信任度较低，强调需结合人类验证。


<details>
  <summary>详细信息</summary>
研究动机: 随着摄影收藏的快速增长，手动编目已无法满足需求，因此研究探索了使用视觉语言模型（VLM）自动生成目录描述的潜力，以评估其是否能替代人工编目。

研究方法: 研究使用VLM（InternVL2）为考古内容的照片生成目录描述，并通过档案和考古专家及非专家进行人工评估，包括分类AI与专家描述、评分质量及报告对AI工具的信任度。

研究结果: 参与者对AI生成描述的识别能力高于随机水平，但低估了自身能力。OCR错误和幻觉降低了质量感知，但高质量描述更难区分。专家对AI工具的接受度较低，更关注保存责任而非技术性能。

研究结论: AI可作为生成草稿的辅助工具，但需人类审核以确保准确性和专业性，尤其是在考古等专业领域。建立透明可解释的AI流程有助于提升专家信任。

中文摘要: 摄影收藏的快速增长已超越手动编目的能力，促使研究探索使用视觉语言模型（VLM）自动生成元数据的可行性。本研究评估了AI生成的目录描述是否能接近人类专家的质量，并探讨了生成式AI如何融入档案和博物馆的编目流程。研究使用VLM（InternVL2）为考古内容的照片生成描述，并通过专家和非专家进行人本实验评估。参与者需分类描述为AI生成或专家撰写，评分质量并报告对AI工具的信任度。分类表现高于随机水平，但两组均低估了自身识别能力。OCR错误和幻觉限制了质量感知，但高准确性和实用性的描述更难分类，表明需人工审核以确保质量，尤其在考古等专业领域。专家对AI工具的接受度较低，更关注保存责任而非技术性能。研究提倡AI作为草稿生成工具，但需人类验证以确保符合策展价值观（如来源透明）。成功整合此方法不仅依赖技术改进（如领域微调），更需通过透明可解释的AI流程建立专家信任。

</details>


### [185] [Probing Experts' Perspectives on AI-Assisted Public Speaking Training](https://arxiv.org/abs/2507.07930)
**中文标题：探究专家对AI辅助公共演讲培训工具的看法**

*Nesrine Fourati,Alisa Barkar,Marion Dragée,Liv Danthon-Lefebvre,Mathieu Chollet*

主要分类: cs.HC

摘要简述: 本文探讨了专家对AI辅助公共演讲训练工具的看法，发现其虽能处理重复性任务，但需改进个性化和反馈设计，支持传统与AI结合的混合模式。


<details>
  <summary>详细信息</summary>
研究动机: 公共演讲是重要职业技能，但传统培训依赖专家指导，AI工具虽兴起但研究集中于原型，专家对商业应用看法未知。本文旨在评估专家对AI工具的看法并提出改进建议。

研究方法: 研究通过16次半结构化访谈和2次焦点小组讨论，收集公共演讲专家对当前商业工具、与传统培训结合及改进建议的观点。

研究结果: 专家认为AI工具能处理重复性技术任务，但需改进反馈个性化和清晰度，支持混合培训模式。

研究结论: AI工具在公共演讲培训中有潜力，但需优化反馈设计和个性化，混合模式是未来方向。

中文摘要: 背景：公共演讲是重要职业技能，但许多人对此感到焦虑。传统培训依赖专家指导，而AI技术的发展催生了商业化的自动反馈工具。然而，研究多集中于原型，专家对商业工具的看法尚不明确。
目标：本研究旨在评估专家对商业AI公共演讲培训工具效果和设计的看法，并提出改进建议。
方法：研究通过16次半结构化访谈和2次焦点小组讨论，收集专家对当前工具、与传统培训结合及改进建议的观点。
结果与结论：专家认可AI工具在处理重复性技术任务上的价值，但指出当前工具需改进反馈个性化和清晰度，支持传统与AI结合的混合模式。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [186] [PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments](https://arxiv.org/abs/2507.07376)
**中文标题：PILOC：一种用于未知环境中多智能体动态目标搜索的信息素逆向引导机制与局部通信框架**

*Hengrui Liu,Yi Feng,Qilong Zhang*

主要分类: cs.RO

摘要简述: 本文提出PILOC框架，通过局部感知和通信结合信息素逆向引导机制，解决多智能体在未知动态环境中的目标搜索问题，显著提升搜索效率和系统鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 多智能体搜索与救援（MASAR）在灾害响应和探索中至关重要，但动态和未知环境中的目标不可预测性和环境不确定性带来了巨大挑战。现有方法依赖全局信息或启发式规则，难以适应复杂场景。

研究方法: PILOC框架结合局部感知和通信，引入信息素逆向引导机制，将信息素嵌入深度强化学习（DRL）的观察空间，支持基于环境线索的间接协调。通过去中心化合作减少对全局通信的依赖。

研究结果: 实验表明，PILOC通过局部通信和信息素引导显著提高了搜索效率、适应性和系统鲁棒性，在动态和通信受限场景中优于现有方法。

研究结论: PILOC为未来MASAR应用提供了有前景的方向，展示了去中心化协调和局部通信在复杂环境中的潜力。

中文摘要: 多智能体搜索与救援（MASAR）在灾害响应、探索和侦察中扮演重要角色。然而，动态和未知环境因目标不可预测性和环境不确定性带来巨大挑战。为解决这些问题，我们提出PILOC框架，该框架无需全局先验知识，利用局部感知和通信。它引入信息素逆向引导机制以实现高效协调和动态目标定位。PILOC通过局部通信促进去中心化合作，显著减少对全局通道的依赖。与传统启发式方法不同，信息素机制嵌入深度强化学习（DRL）的观察空间，支持基于环境线索的间接智能体协调。我们将此策略进一步整合到基于DRL的多智能体架构中，并进行了广泛实验。结果表明，局部通信与信息素引导的结合显著提升了搜索效率、适应性和系统鲁棒性。与现有方法相比，PILOC在动态和通信受限场景中表现更优，为未来MASAR应用提供了有前景的方向。

</details>


### [187] [Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots](https://arxiv.org/abs/2507.07714)
**中文标题：基于自适应高斯混合模型的电缆驱动并联机器人异常检测方法**

*Julio Garrido,Javier Vales,Diego Silva-Muñiz,Enrique Riveiro,Pablo López-Matencio,Josué Rivera-Andrade*

主要分类: cs.RO

摘要简述: 本文提出了一种基于自适应高斯混合模型（GMM）的异常检测方法，用于电缆驱动并联机器人（CDPRs），仅通过电机扭矩数据实现高效异常检测，无需额外传感器。


<details>
  <summary>详细信息</summary>
研究动机: 电缆驱动并联机器人在负载操作任务中需在固定姿态下检测异常（如风或电缆碰撞），但现有方法依赖额外传感器。本文旨在仅通过电机扭矩数据实现高效异常检测。

研究方法: 采用自适应无监督异常检测算法，基于高斯混合模型（GMM）。首先通过短时校准拟合正常数据，实时测量时用马氏距离评估异常，动态更新模型参数以适应环境变化。

研究结果: 在14次长时间测试中，方法实现了100%的真阳性率和95.4%的平均真阴性率，检测延迟仅1秒，优于功率阈值和非自适应GMM方法。

研究结论: 该方法仅依赖扭矩数据，高效且适应性强，适用于电缆驱动并联机器人的实时异常检测。

中文摘要: 电缆驱动并联机器人（CDPRs）越来越多地用于涉及预定义工具路径和中间停止的负载操作任务。在每次停止时，平台保持固定姿态，电机保持电缆张力，系统需通过检测可能影响性能的异常（如风或电缆碰撞）来评估是否安全继续。本文研究是否仅通过电机扭矩数据（无需额外传感器）即可检测异常。提出了一种基于高斯混合模型（GMM）的自适应无监督异常检测算法，用于从扭矩信号中识别异常。方法始于短时校准期（仅几秒），期间拟合已知无异常数据的GMM。实时扭矩测量通过马氏距离评估，统计阈值触发异常标志。模型参数定期使用最新无异常数据段更新以适应变化条件。验证包括14次模拟不同风速的长时测试。所提方法实现了100%的真阳性率和95.4%的平均真阴性率，检测延迟为1秒。与功率阈值和非自适应GMM方法相比，表现出更高的漂移和环境变化鲁棒性。

</details>


### [188] [LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation](https://arxiv.org/abs/2507.07299)
**中文标题：LangNavBench：语义导航中自然语言理解的评估**

*Sonia Raychaudhuri,Enrico Cancelli,Tommaso Campari,Lamberto Ballan,Manolis Savva,Angel X. Chang*

主要分类: cs.RO

摘要简述: 本文提出了LangNavBench，一个专注于自然语言理解的语义导航基准测试，旨在评估智能体在不同语言描述下定位目标对象的能力。通过LangNav数据集和Multi-Layered Feature Map (MLFM)方法，研究展示了其在处理细粒度语言指令上的优越性。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大型视觉语言模型在基于语言的语义导航方面取得了进展，但缺乏一个专注于语言理解的基准测试。本文旨在填补这一空白，通过LangNav数据集和LangNavBench基准测试，系统评估智能体对语言指令的理解能力。

研究方法: 研究构建了LangNav数据集，包含不同详细程度的语言描述，并通过人工检查降低错误率。在此基础上开发了LangNavBench基准测试，并提出了Multi-Layered Feature Map (MLFM)方法，该方法构建了一个可查询的多层语义地图，特别适用于处理小对象或涉及空间关系的指令。

研究结果: MLFM方法在LangNav数据集上表现优于现有的基于地图的导航基线模型，尤其是在处理细粒度语言指令时表现出色。LangNavBench为语义导航系统提供了首个全面的语言中心化评估框架。

研究结论: LangNavBench和MLFM方法为语义导航领域的语言理解提供了新的评估工具和技术支持，推动了该领域的进一步发展。

中文摘要: 近年来，大型视觉语言模型的进展推动了基于语言的语义导航的发展，即智能体需要根据自然语言描述到达目标对象。尽管取得了这些进展，我们仍然缺乏一个专注于语言理解的清晰基准测试，以评估智能体对指令中词汇的定位能力。为此，我们提出了LangNav，一个专门用于测试智能体在不同详细程度语言描述下定位目标对象能力的开放数据集。LangNav中的每一条描述都经过人工检查，错误率低于现有的终身学习和语义导航数据集。基于LangNav，我们构建了LangNavBench基准测试，用于衡量当前语义导航方法在理解和执行这些描述时的表现。LangNavBench使我们能够系统比较模型在处理属性、空间和关系线索以及类别层次结构方面的能力，为嵌入式导航系统提供了首个全面的语言中心化评估。我们还提出了多层特征地图（MLFM）方法，该方法构建了一个可查询的多层语义地图，特别适用于处理小对象或涉及空间关系的指令。MLFM在LangNav数据集上的表现优于现有的基于地图的导航基线模型。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [189] [Generative Panoramic Image Stitching](https://arxiv.org/abs/2507.07133)
**中文标题：生成式全景图像拼接**

*Mathieu Tuli,Kaveh Kamali,David B. Lindell*

主要分类: cs.GR

摘要简述: 本文提出了一种生成式全景图像拼接方法，通过微调基于扩散的修复模型，解决了传统拼接方法在处理视差、光照和风格差异时的失败问题，实现了高质量、无缝的全景图像生成。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像拼接方法在处理包含视差、光照变化或风格差异的参考图像时，常产生重影和其他伪影。现有的生成模型虽能扩展内容，但在生成大范围连贯全景时表现不佳。本文旨在解决这些问题，提出一种新方法。

研究方法: 本文提出了一种基于扩散模型的修复方法，通过微调模型以保留场景内容和布局。模型从单一参考图像扩展生成全景，确保无缝且视觉连贯的结果，同时整合所有参考图像的内容。

研究结果: 实验表明，该方法在图像质量、结构和场景布局一致性方面显著优于基线方法，能够生成高质量且无缝的全景图像。

研究结论: 本文提出的生成式全景图像拼接方法有效解决了传统方法的局限性，通过微调扩散模型实现了高质量的全景生成，为复杂场景下的图像拼接提供了新思路。

中文摘要: 我们提出了生成式全景图像拼接任务，旨在合成无缝的全景图像，忠实于包含视差效应及光照、相机设置或风格差异的多个参考图像内容。在这一挑战性场景下，传统图像拼接方法因产生重影等伪影而失败。尽管现有生成模型能扩展与多参考图像一致的内容，但在合成大范围连贯全景时表现不佳。为解决这些问题，我们提出一种方法，通过微调基于扩散的修复模型以保留场景内容和布局。微调后，模型从单一参考图像扩展生成全景，生成无缝且视觉连贯的结果，忠实整合所有参考图像内容。在捕获数据集上的评估表明，我们的方法在图像质量及结构和场景布局一致性方面显著优于基线方法。

</details>


### [190] [SD-GS: Structured Deformable 3D Gaussians for Efficient Dynamic Scene Reconstruction](https://arxiv.org/abs/2507.07465)
**中文标题：SD-GS：基于结构化可变形3D高斯的高效动态场景重建**

*Wei Yao,Shuzhao Xie,Letian Li,Weixiang Zhang,Zhixin Lai,Shiqi Dai,Ke Zhang,Zhi Wang*

主要分类: cs.GR

摘要简述: SD-GS提出了一种高效动态场景重建的紧凑框架，通过可变形锚点网格和变形感知的密集化策略，显著降低了模型大小并提升了渲染速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有4D高斯框架在动态场景重建中面临存储成本与复杂运动建模能力的权衡问题，限制了实际应用。SD-GS旨在解决这一问题。

研究方法: 1. 引入可变形锚点网格作为层次化、内存高效的场景表示；2. 提出变形感知密集化策略，动态调整锚点分布以优化复杂运动建模。

研究结果: 实验表明，SD-GS模型大小平均减少60%，FPS提升100%，在保持视觉质量的同时显著提升计算效率。

研究结论: SD-GS通过创新的场景表示和动态优化策略，实现了高效且高质量的动态场景重建。

中文摘要: 当前的4D高斯框架在动态场景重建中表现出卓越的视觉保真度和渲染速度，但其存储成本与复杂物理运动建模能力之间的固有权衡严重限制了这些方法的实际应用。为解决这些问题，我们提出了SD-GS，一种紧凑高效的动态高斯泼溅框架，用于复杂动态场景重建，具有两个关键贡献。首先，我们引入了一种可变形锚点网格，这是一种层次化且内存高效的场景表示方法，其中每个锚点在其局部时空区域内衍生多个3D高斯，并作为3D场景的几何骨架。其次，为增强对复杂运动的建模能力，我们提出了一种变形感知的密集化策略，自适应地在高动态区域增加锚点，同时在静态区域减少冗余，从而以更少的锚点实现更优的视觉质量。实验结果表明，与现有最先进方法相比，SD-GS平均减少了60%的模型大小，并提升了100%的FPS，在保持甚至超越视觉质量的同时显著提高了计算效率。

</details>


### [191] [Capture Stage Environments: A Guide to Better Matting](https://arxiv.org/abs/2507.07623)
**中文标题：捕获舞台环境：优化抠图指南**

*Hannah Dröge,Janelle Pfeifer,Saskia Rabich,Markus Plack,Reinhard Klein,Matthias B. Hullin*

主要分类: cs.GR

摘要简述: 本文探讨了捕获舞台环境中图像抠图的挑战，并提出了一种改进工作流程的指南，同时展示了一种无需大量标注的高效管道。


<details>
  <summary>详细信息</summary>
研究动机: 现有抠图算法在捕获舞台内容中表现不佳，本文旨在揭示这些挑战并提出解决方案，以优化工作流程。

研究方法: 提出了一种高效管道，将先进方法适配到自定义设置中，无需大量标注，并基于领先的扩散模型设计了验证方法。

研究结果: 展示了改进后的工作流程在捕获舞台环境中的有效性，并通过验证方法证明了其优势。

研究结论: 本文为实践者提供了优化图像抠图的指南，并展示了无需大量标注的高效管道，为捕获舞台内容提供了实用解决方案。

中文摘要: 捕获舞台是电影、游戏和其他媒体中高端录制内容的来源。几乎所有流程中的关键步骤是对图像进行抠图，以将捕获的表演与背景分离。尽管常见的抠图算法在其他应用（如远程会议和移动娱乐）中表现出色，但我们发现它们在捕获舞台内容的特殊性上表现不佳。本文的目标是分享对这些挑战的见解，并提出改进工作流程的指南，以缓解未解决的挑战。为此，我们还展示了一种高效管道，无需大量标注即可将先进方法适配到自定义设置中，包括离线和实时场景。为进行客观评估，我们提出了一种基于领先扩散模型的验证方法，突出了我们方法的优势。

</details>


### [192] [RTR-GS: 3D Gaussian Splatting for Inverse Rendering with Radiance Transfer and Reflection](https://arxiv.org/abs/2507.07733)
**中文标题：RTR-GS：基于辐射传输与反射的高斯泼溅逆渲染方法**

*Yongyang Zhou,Fang-Lue Zhang,Zichen Wang,Lei Zhang*

主要分类: cs.GR

摘要简述: RTR-GS提出了一种新的逆渲染框架，通过结合前向渲染和延迟渲染，有效分解BRDF和光照，解决了反射物体渲染的挑战，并提升了新视角合成和重光照效果。


<details>
  <summary>详细信息</summary>
研究动机: 3D高斯泼溅（3DGS）在新视角合成中表现优异，但在处理反射物体时仍面临挑战，尤其是在逆渲染和重光照任务中。本文旨在解决这一问题，提出一种能够分解BRDF和光照的鲁棒框架。

研究方法: RTR-GS采用混合渲染模型，结合前向渲染（用于辐射传输）和延迟渲染（用于反射），有效分离高频和低频外观，并通过基于物理的延迟渲染分支进一步优化BRDF和光照分解。

研究结果: 实验结果表明，该方法在新视角合成、法线估计、分解和重光照任务中表现优异，同时保持了高效的训练和推理过程。

研究结论: RTR-GS通过创新的混合渲染方法，成功解决了反射物体渲染的难题，为逆渲染和重光照任务提供了高效且可靠的解决方案。

中文摘要: 3D高斯泼溅（3DGS）在新视角合成中展现了强大的能力，但渲染反射物体仍是一个重大挑战，尤其是在逆渲染和重光照任务中。我们提出了RTR-GS，一种新颖的逆渲染框架，能够鲁棒地渲染具有任意反射特性的物体，分解BRDF和光照，并提供可信的重光照结果。给定一组多视角图像，我们的方法通过结合前向渲染（用于辐射传输）和延迟渲染（用于反射）的混合渲染模型，有效恢复了几何结构。这种方法成功分离了高频和低频外观，缓解了处理高频细节时由球谐函数过拟合引起的浮动伪影。我们进一步通过基于物理的延迟渲染分支优化了BRDF和光照分解。实验结果表明，我们的方法在提升新视角合成、法线估计、分解和重光照效果的同时，保持了高效的训练和推理过程。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [193] [A Language-Driven Framework for Improving Personalized Recommendations: Merging LLMs with Traditional Algorithms](https://arxiv.org/abs/2507.07251)
**中文标题：一种语言驱动的框架用于改进个性化推荐：将大型语言模型与传统算法融合**

*Aaron Goldstein,Ayan Dutta*

主要分类: cs.IR

摘要简述: 本文提出了一种结合大型语言模型（LLMs）与传统推荐算法的新框架，通过语言输入提升个性化推荐效果，显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统推荐算法无法基于用户文本输入（如偏好描述）提供个性化推荐，而LLMs在自然语言处理方面表现出色。本研究旨在通过结合LLMs与传统算法，模拟朋友推荐的方式提升推荐效果。

研究方法: 研究使用SVD或SVD++算法生成初始电影推荐（基于MovieLens-Latest-Small数据集），并通过LLMs优化推荐结果。采用留一验证命中率和累积命中率等指标评估性能，并与现有推荐系统进行对比。

研究结果: 实验表明，该框架在各项评估指标上显著优于传统算法（如累积命中率提升约6倍，NDCG提升约3.7倍），尽管计算开销略有增加。

研究结论: 结合LLMs与传统推荐算法能够显著提升个性化推荐效果，未来可进一步优化计算效率。

中文摘要: 传统推荐算法无法根据用户通过文本提供的偏好（例如“我喜欢轻松幽默的喜剧”）生成个性化推荐。近年来，大型语言模型（LLMs）成为自然语言处理领域最具前景的工具之一。本研究提出了一种新颖的框架，模拟朋友基于对个人品味的了解推荐物品的方式。我们利用LLMs优化传统算法的输出，并将其与基于语言的用户偏好输入相结合。研究使用奇异值分解（SVD）或SVD++算法生成初始电影推荐（基于MovieLens-Latest-Small数据集），并通过留一验证命中率和累积命中率比较基础算法与LLM增强版本的性能。此外，为了与当前最先进的推荐系统对比，我们采用评分和排名指标（训练集占比75%，测试集占比25%）。该框架可根据用户喜爱的电影自动生成偏好配置文件，或允许手动指定偏好以实现更个性化的结果。实验表明，该框架在所有评估指标上均显著优于SVD和SVD++（如累积命中率提升约6倍，NDCG提升约3.7倍等），尽管计算开销略有增加。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [194] [FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning](https://arxiv.org/abs/2507.07258)
**中文标题：FedP3E：跨机构联邦学习中非独立同分布物联网恶意软件检测的隐私保护原型交换**

*Rami Darwish,Mahmoud Abdelsalam,Sajad Khorsandroo,Kaushik Roy*

主要分类: cs.CR

摘要简述: FedP3E是一种新型联邦学习框架，通过隐私保护的类原型交换，解决非独立同分布（非IID）物联网恶意软件检测中的数据异构性和隐私问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着物联网生态系统的扩展，恶意软件攻击日益复杂，而传统联邦学习算法（如FedAvg和FedProx）在数据异构性和类不平衡场景下表现不佳。因此，需要一种既能保护隐私又能应对数据异构性的检测框架。

研究方法: FedP3E采用高斯混合模型（GMM）构建类原型，通过添加高斯噪声保护隐私，仅交换原型而非原始数据或梯度。结合SMOTE增强技术，提升少数类恶意软件的表征能力。

研究结果: 在N-BaIoT数据集上的实验表明，FedP3E在跨机构场景下能有效降低数据异构性的负面影响，同时减少通信开销。

研究结论: FedP3E通过原型驱动的机制，在不交换原始数据或梯度的情况下，实现了隐私保护和数据异构性处理的平衡，为物联网恶意软件检测提供了新思路。

中文摘要: 随着物联网生态系统在关键领域的扩展，其成为日益复杂和大规模恶意软件攻击的主要目标。威胁环境的演变以及物联网生成数据的敏感性，要求检测框架既能保护隐私，又能应对数据异构性。联邦学习（FL）通过支持去中心化模型训练而不暴露原始数据，提供了一种有前景的解决方案。然而，标准FL算法（如FedAvg和FedProx）在现实部署中，尤其是面对类不平衡和非独立同分布数据时表现不佳。为解决这些问题，我们提出了FedP3E（隐私保护原型交换），这是一种新型FL框架，支持间接跨客户端表征共享，同时保持数据隐私。每个客户端使用高斯混合模型（GMM）构建类原型，通过高斯噪声扰动后仅传输这些紧凑摘要至服务器。聚合后的原型被分发回客户端并整合到本地训练中，辅以SMOTE增强技术以提升少数类恶意软件的表征能力。与仅依赖参数平均不同，我们的原型驱动机制使客户端能够在不交换原始数据或梯度的情况下，利用联邦中观察到的互补结构模式丰富本地模型。这一针对性策略以最小通信开销降低了统计异构性的负面影响。我们在N-BaIoT数据集上评估了FedP3E，模拟了不同数据不平衡程度的现实跨机构场景。

</details>


### [195] [May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks](https://arxiv.org/abs/2507.07417)
**中文标题：能否引起你的注意？利用架构感知攻击破解基于微调的提示注入防御**

*Nishit V. Pandya,Andrey Labunets,Sicun Gao,Earlence Fernandes*

主要分类: cs.CR

摘要简述: 本文通过构建基于优化的攻击方法，评估了针对大型语言模型（LLM）的提示注入防御的鲁棒性，发现现有防御措施（如SecAlign和StruQ）无法提供声称的安全性。


<details>
  <summary>详细信息</summary>
研究动机: 当前针对LLM的提示注入攻击防御方法（如微调模型以区分指令和数据）被广泛使用，但其安全性尚未经过严格验证。本文旨在评估这些防御措施在已知模型架构（白盒）情况下的实际鲁棒性。

研究方法: 作者提出了一种新颖的基于注意力的攻击算法，针对文本型LLM，并将其应用于两种最新的白盒防御方法（SecAlign和StruQ）。通过优化攻击策略，验证防御措施的有效性。

研究结果: 实验表明，攻击成功率高达70%，且攻击者只需适度增加令牌预算即可实现。

研究结论: 本文揭示了现有提示注入防御在白盒环境中的脆弱性，为未来防御设计提供了重要参考。

中文摘要: 针对大型语言模型（LLM）的提示注入攻击，一类流行的防御方法依赖于微调模型以区分指令和数据，从而避免LLM执行数据中可能包含的指令。目前已有多种学术和实际系统实现了这一思路。本文在白盒环境下评估了此类防御的鲁棒性，通过构建强力的基于优化的攻击，证明这些防御并未提供声称的安全性。具体而言，我们提出了一种新颖的基于注意力的攻击算法，适用于文本型LLM，并将其应用于两种最新的白盒防御方法（SecAlign和StruQ），攻击成功率高达70%，且攻击者只需适度增加令牌预算。我们的研究为理解白盒环境下提示注入防御的鲁棒性提供了重要进展。代码和攻击方法发布于https://github.com/nishitvp/better_opts_attacks。

</details>


### [196] [Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models](https://arxiv.org/abs/2507.07406)
**中文标题：Gen-AI时代的钓鱼检测：量化大语言模型与传统模型对比**

*Jikesh Thapa,Gurrehmat Chahal,Serban Voinea Gabreanu,Yazan Otoum*

主要分类: cs.CR

摘要简述: 本文比较了传统机器学习、深度学习和量化小参数大语言模型（LLM）在钓鱼检测中的表现，发现LLM虽在准确率上稍逊，但在识别上下文钓鱼线索上潜力巨大，且轻量级LLM在成本效益和解释性上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 钓鱼攻击日益复杂，需平衡高准确率和计算效率的检测系统。本文旨在评估不同方法在钓鱼检测中的表现，探索LLM的潜力及其在成本效益和解释性上的优势。

研究方法: 通过实验对比传统机器学习、深度学习和量化LLM在钓鱼检测中的表现，研究零样本和少样本提示策略的影响，并评估模型的对抗鲁棒性和成本性能权衡。

研究结果: 实验显示，LLM在准确率上略逊于传统方法，但在识别上下文钓鱼线索上潜力显著。轻量级LLM如DeepSeek R1 Distill Qwen 14B（Q8_0）仅需17GB显存即可实现80%以上准确率，且提供可解释性支持实时决策。

研究结论: 优化后的LLM在钓鱼防御系统中具有潜力，为将高效、可解释的AI集成到现代网络安全框架提供了路径。

中文摘要: 钓鱼攻击日益复杂，亟需在检测系统中平衡高准确率和计算效率。本文对比了传统机器学习（ML）、深度学习（DL）和量化小参数大语言模型（LLM）在钓鱼检测中的表现。通过实验发现，尽管LLM在准确率上目前不及ML和DL方法，但在识别基于上下文的钓鱼线索上潜力巨大。我们还研究了零样本和少样本提示策略的影响，发现LLM重写的邮件会显著降低ML和LLM检测器的性能。基准测试表明，如DeepSeek R1 Distill Qwen 14B（Q8_0）等模型仅需17GB显存即可实现80%以上的准确率，支持其成本效益部署。此外，我们评估了模型的对抗鲁棒性和成本性能权衡，并展示了轻量级LLM如何提供简洁、可解释的说明以支持实时决策。这些发现表明，优化后的LLM有望成为钓鱼防御系统的组成部分，并为将可解释、高效的AI集成到现代网络安全框架提供了方向。

</details>


### [197] [Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks](https://arxiv.org/abs/2507.07413)
**中文标题：混合LLM增强的入侵检测：针对物联网网络中零日威胁的解决方案**

*Mohammad F. Al-Hammouri,Yazan Otoum,Rasha Atwa,Amiya Nayak*

主要分类: cs.CR

摘要简述: 本文提出了一种结合传统签名检测与GPT-2语言模型的新型入侵检测方法，显著提升了对零日威胁的检测能力，实验显示准确率提高6.3%，误报率降低9.0%。


<details>
  <summary>详细信息</summary>
研究动机: 随着物联网（IoT）等分布式、异构且资源受限环境中网络威胁日益复杂，传统入侵检测系统（IDS）难以识别新型攻击模式，亟需动态自适应的解决方案。

研究方法: 提出了一种混合IDS框架，将传统签名检测的鲁棒性与GPT-2驱动的语义分析相结合，利用GPT-2处理非结构化数据和识别复杂语义关系的能力检测零日攻击。

研究结果: 实验表明，该模型在代表性入侵数据集上检测准确率提升6.3%，误报率降低9.0%，同时保持近实时响应能力。

研究结论: 语言模型与传统方法的结合为现代网络安全提供了智能、可扩展且高效的防御方案，适用于物联网等复杂环境。

中文摘要: 本文提出了一种新型入侵检测方法，通过将传统签名检测与GPT-2大型语言模型（LLM）的上下文理解能力相结合，解决了物联网（IoT）等分布式、异构且资源受限环境中日益复杂的网络威胁问题。传统方法虽能有效检测已知威胁，但对新型攻击模式识别能力不足。相比之下，GPT-2擅长处理非结构化数据并识别复杂语义关系，非常适合检测隐蔽的零日攻击向量。我们提出了一种混合IDS框架，融合了签名检测的鲁棒性与GPT-2驱动的语义分析。在代表性入侵数据集上的实验评估表明，该模型将检测准确率提高了6.3%，误报率降低了9.0%，并保持了近实时响应能力。这些结果证实了语言模型集成在构建智能、可扩展且适应现代互联环境的网络安全防御中的潜力。

</details>


### [198] [Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation](https://arxiv.org/abs/2507.07416)
**中文标题：面向关键基础设施的自主AI网络安全框架：实时威胁缓解**

*Jenifer Paulraj,Brindha Raghuraman,Nagarani Gopalakrishnan,Yazan Otoum*

主要分类: cs.CR

摘要简述: 本文提出了一种基于AI的自主网络安全框架，用于实时检测和缓解关键基础设施中的网络威胁，包括勒索软件、DoS攻击和APT攻击。


<details>
  <summary>详细信息</summary>
研究动机: 关键基础设施（如能源、医疗、交通和水务系统）对社会稳定和经济韧性至关重要，但其日益增长的互联性使其面临多种网络威胁。研究旨在通过AI技术提升这些系统的安全性和韧性。

研究方法: 提出了一种混合AI驱动的网络安全框架，结合实时漏洞检测、威胁建模和自动化修复功能，同时探讨了对抗性AI、法规合规性和系统集成的复杂性。

研究结果: 研究提供了可操作的见解，增强了关键基础设施系统对新兴网络威胁的安全性和韧性。

研究结论: 通过AI驱动的框架，可以有效提升关键基础设施的网络安全能力，应对复杂的网络威胁环境。

中文摘要: 关键基础设施系统（如能源电网、医疗设施、交通网络和水务系统）对社会稳定和经济韧性至关重要。然而，这些系统的日益互联性使其面临多种网络威胁，包括勒索软件、拒绝服务（DoS）攻击和高级持续性威胁（APT）。本文研究了关键基础设施中的网络安全漏洞，重点分析了威胁态势、攻击途径以及人工智能（AI）在缓解这些风险中的作用。我们提出了一种混合AI驱动的网络安全框架，以增强实时漏洞检测、威胁建模和自动化修复能力。本研究还探讨了对抗性AI、法规合规性和系统集成的复杂性。研究结果为加强关键基础设施系统对新兴网络威胁的安全性和韧性提供了可操作的见解。

</details>


### [199] [Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking](https://arxiv.org/abs/2507.07871)
**中文标题：通过多密钥水印技术缓解生成式模型中的水印窃取攻击**

*Toluwani Aremu,Noor Hussein,Munachiso Nwadike,Samuele Poppi,Jie Zhang,Karthik Nandakumar,Neil Gong,Nils Lukas*

主要分类: cs.CR

摘要简述: 本文提出一种多密钥水印方法，用于防止生成式AI模型中的水印窃取攻击，通过理论保证和实证验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 生成式AI提供商通过水印技术验证生成内容的来源，但面临水印窃取攻击的威胁，即用户伪造水印以虚假指控提供商。本文旨在解决这一问题。

研究方法: 提出一种多密钥扩展方法，可事后应用于任何模态的水印技术，通过理论分析和安全游戏建模来验证其有效性。

研究结果: 实验证明多密钥水印方法显著降低了伪造水印的成功率，并在多个数据集中表现出色。

研究结论: 多密钥水印方法有效缓解了水印窃取攻击，为生成式AI提供商提供了更高的安全性。

中文摘要: 水印技术为生成式AI提供商提供了一种验证生成内容来源的解决方案。水印是一种隐藏在生成内容中的信号，可通过秘密水印密钥验证其存在。然而，生成式AI提供商面临水印窃取攻击的威胁，即用户在没有秘密密钥的情况下伪造水印，例如虚假指控提供商。窃取攻击通过收集提供商模型中的无害水印样本，试图最大化生成有害水印样本的成功率。本文专注于缓解窃取攻击，并将水印视为黑盒。我们的贡献包括：(i) 提出一种多密钥扩展方法，可事后应用于任何模态的水印技术；(ii) 提供理论保证并通过实验证明该方法显著降低了伪造水印的有效性；(iii) 通过安全游戏建模正式定义水印伪造的威胁。

</details>


### [200] [Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image Sensors](https://arxiv.org/abs/2507.07773)
**中文标题：电磁信号注入攻击在图像传感器中引发的彩虹伪影**

*Youqian Zhang,Xinyu Ji,Zhihao Wang,Qinhong Jiang*

主要分类: cs.CR

摘要简述: 研究发现一种新型电磁信号注入攻击，可在图像传感器的模拟域中注入彩虹色伪影，影响目标检测模型的准确性，揭示了视觉感知系统中的潜在漏洞。


<details>
  <summary>详细信息</summary>
研究动机: 图像传感器广泛应用于安全和安防关键系统，如监控基础设施和自动驾驶。这些系统依赖视觉数据的完整性进行决策。然而，现有研究未充分关注模拟域中的电磁信号注入攻击，可能导致视觉数据被操控而未被检测。

研究方法: 通过精心调制的电磁干扰，研究团队在CMOS图像传感器中诱导出彩虹色伪影，并评估这些伪影对目标检测模型的影响。实验展示了伪影在图像信号处理流程中的传播及其对模型预测的干扰。

研究结果: 实验表明，电磁信号注入攻击能够显著干扰目标检测模型的预测，导致错误分类。彩虹色伪影在图像处理流程中持续存在，凸显了视觉感知系统的物理层漏洞。

研究结论: 研究揭示了图像传感器在模拟域中的电磁信号注入攻击风险，强调了在视觉感知系统中加强物理层防御的必要性。

中文摘要: 图像传感器广泛应用于安全和安防关键系统，如监控基础设施、自动驾驶和工业自动化。这些系统依赖视觉数据的完整性进行决策。本研究探讨了一种新型电磁信号注入攻击，该攻击针对图像传感器的模拟域，使攻击者能够操控原始视觉输入而不触发传统的数字完整性检查。我们发现了一种此前未记录的CMOS图像传感器攻击现象：通过精心调制的电磁干扰，在图像传感器捕获的图像中诱导出彩虹色伪影。我们进一步评估了这些攻击对先进目标检测模型的影响，结果表明注入的伪影在图像信号处理流程中传播，并导致显著的预测错误。我们的发现揭示了视觉感知栈中一个关键且未被充分探索的漏洞，强调了在此类系统中加强物理层攻击防御的必要性。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [201] [Adaptive Attention Residual U-Net for curvilinear structure segmentation in fluorescence microscopy and biomedical images](https://arxiv.org/abs/2507.07800)
**中文标题：自适应注意力残差U-Net用于荧光显微镜和生物医学图像中曲线结构的分割**

*Achraf Ait Laydi,Louis Cueff,Mewen Crespo,Yousef El Mourabit,Hélène Bouvrais*

主要分类: q-bio.QM

摘要简述: 本文提出了一种新型自适应注意力残差U-Net（ASE_Res_UNet）模型，用于荧光显微镜和生物医学图像中曲线结构的分割。该模型通过结合残差块和自适应SE注意力机制，显著提升了在噪声和低对比度条件下的分割性能，并在合成和真实数据上均表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 荧光显微镜中曲线结构的分割在噪声密集和低对比度条件下仍具挑战性。现有深度学习方法在此类场景中性能下降，因此需要开发更鲁棒的模型。

研究方法: 作者构建了两个合成数据集模拟真实荧光显微镜图像，并提出ASE_Res_UNet模型，结合残差块和自适应SE注意力机制，增强模型对噪声和低强度结构的处理能力。

研究结果: ASE_Res_UNet在合成和真实数据上均优于标准U-Net及其变体，尤其在噪声环境下表现突出。模型还成功应用于视网膜血管和神经的分割。

研究结论: ASE_Res_UNet在曲线结构分割任务中表现出色，具有广泛的生物医学应用潜力，尤其在疾病诊断和治疗中。

中文摘要: 荧光显微镜中曲线结构的分割仍是一项具有挑战性的任务，尤其是在噪声密集和体内常见的密集纤维网络条件下。为此，我们创建了两个原始数据集，包含数百张荧光标记微管的合成细胞图像。这些数据集精确标注并高度模拟真实显微镜图像，包括真实的噪声。第二个数据集通过模拟沿纤维变化的荧光强度，进一步增加了分割的复杂性。尽管深度学习在生物医学图像分析中表现出强大潜力，但其在噪声或低对比度条件下性能下降。为克服这一限制，我们开发了一种新型高级架构：自适应挤压-激励残差U-Net（ASE_Res_UNet）。该模型通过在编码器中集成残差块和解码器中引入自适应SE注意力机制，增强了标准U-Net的性能。通过消融研究和全面的视觉与定量评估，ASE_Res_UNet始终优于其变体，即标准U-Net、ASE_UNet和Res_UNet架构。这些改进，尤其是在噪声鲁棒性和检测低强度细微结构方面，主要归功于我们创建的自适应SE注意力模块。我们进一步将ASE_Res_UNet与多种最先进模型进行对比，发现其在最具挑战性的数据集上表现最优。最后，该模型在真实显微镜图像中的染色微管以及其他曲线结构上也表现出良好的泛化能力。实际上，它成功分割了噪声或低对比度生物医学图像中的视网膜血管和神经，展示了其在疾病诊断和治疗应用中的强大潜力。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [202] [SonicMotion: Dynamic Spatial Audio Soundscapes with Latent Diffusion Models](https://arxiv.org/abs/2507.07318)
**中文标题：SonicMotion：基于潜在扩散模型的动态空间音频声景生成**

*Christian Templin,Yanda Zhu,Hao Wang*

主要分类: cs.SD

摘要简述: 本文提出了一种名为SonicMotion的端到端模型，用于生成具有动态声源的3D空间音频场景，并提供了两种变体以适应不同用户输入和定位精度需求。同时，还发布了一个新的模拟空间音频-字幕配对数据集。


<details>
  <summary>详细信息</summary>
研究动机: 空间音频在VR/AR等沉浸式娱乐中至关重要，但现有的一阶Ambisonics（FOA）生成AI模型在动态声源生成方面仍有不足。本文旨在扩展FOA生成模型的能力，以支持动态3D场景的音频生成。

研究方法: SonicMotion模型包含两种变体，分别针对不同用户输入和声源定位精度需求。模型采用端到端设计，并结合了一个新的模拟空间音频-字幕配对数据集进行训练。

研究结果: 实验表明，SonicMotion模型在语义对齐和音频质量上达到了现有先进模型的水平，同时能够捕捉所需的空间属性。

研究结论: SonicMotion模型成功扩展了FOA生成AI模型的能力，支持动态3D场景的音频生成，并通过新数据集和实验验证了其有效性。

中文摘要: 空间音频是VR/AR等沉浸式娱乐的重要组成部分，并在电影和音乐中日益流行。最常见的一阶Ambisonics（FOA）格式是空间音频的主要形式。本文旨在扩展FOA生成AI模型的进展，以实现动态声源的3D场景生成。我们提出的端到端模型SonicMotion包含两种变体，分别针对不同用户输入和声源定位精度需求。此外，我们还提供了一个新的模拟空间音频-字幕配对数据集。实验结果表明，我们的模型在语义对齐和音频质量上达到了现有先进模型的水平，同时能够捕捉所需的空间属性。

</details>


### [203] [Input Conditioned Layer Dropping in Speech Foundation Models](https://arxiv.org/abs/2507.07954)
**中文标题：Error**

*Abdul Hannan,Daniele Falavigna,Alessio Brutti*

主要分类: cs.SD

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [204] [Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation](https://arxiv.org/abs/2507.07668)
**中文标题：利用预测不确定性估计学习强子态的极点结构**

*Felix Frohnert,Denny Lane B. Sombrillo,Evert van Nieuwenburg,Patrick Emonts*

主要分类: hep-ph

摘要简述: 本文提出了一种基于不确定性估计的机器学习方法，用于分类强子态的极点结构，并在合成数据和实验数据上验证了其有效性，准确率高达95%。


<details>
  <summary>详细信息</summary>
研究动机: 强子光谱学中，将理论预测与实验数据匹配是一个核心挑战，尤其是新强子态的识别。由于阈值附近的奇异信号可能源于多种物理机制，极点结构的分类尤为困难。本文旨在解决这一难题。

研究方法: 采用了一种基于分类器链集成的方法，同时提供认知和随机不确定性估计。通过基于预测不确定性的拒绝标准，模型在合成数据上训练后，能够泛化到实验数据。

研究结果: 模型在验证集上达到近95%的准确率，同时仅丢弃少量高不确定性预测。应用于LHCb观测到的$P_{c\bar{c}}(4312)^+$态时，推断出四极点结构，表明存在一个真正的紧凑五夸克态。

研究结论: 该方法不仅适用于特定强子态，还可推广到其他候选态，为散射振幅中的极点结构推断提供了可扩展的工具。

中文摘要: 将理论预测与实验数据匹配仍然是强子光谱学中的一个核心挑战。特别是新强子态的识别非常困难，因为阈值附近的奇异信号可能源于多种物理机制。在这种情况下，散射振幅的极点结构是一个关键诊断工具，但不同的极点配置可能产生相似的信号特征。极点配置与线形之间的映射在质量阈值附近尤为模糊，因为解析控制有限。本文提出了一种基于不确定性估计的机器学习方法，用于分类$S$矩阵元中的极点结构。我们的方法基于分类器链集成，同时提供认知和随机不确定性估计。通过基于预测不确定性的拒绝标准，模型在验证集上达到近95%的准确率，同时仅丢弃少量高不确定性预测。在已知极点结构的合成数据上训练后，模型能够泛化到未见的实验数据，包括LHCb观测到的$P_{c\bar{c}}(4312)^+$态。在此过程中，我们推断出一个四极点结构，表明存在一个真正的紧凑五夸克态，同时伴随一个宽度非零的高通道虚态极点。尽管针对特定态进行了评估，我们的框架广泛适用于其他候选强子态，并为散射振幅中的极点结构推断提供了一个可扩展的工具。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [205] [mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar](https://arxiv.org/abs/2507.07331)
**中文标题：mmFlux：基于商用毫米波MIMO雷达的人群流分析**

*Anurag Pallaprolu,Winston Hurst,Yasamin Mostofi*

主要分类: eess.SP

摘要简述: 本文提出了一种基于毫米波雷达的框架mmFlux，用于提取人群运动模式并推断语义。通过信号处理和几何图转换，实现了高保真的人群流场重建和语义分析，实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有技术难以高效捕捉和分析复杂人群运动模式及其语义信息，本文旨在利用毫米波雷达解决这一问题，为人群分析提供新方法。

研究方法: 结合光学流估计与统计滤波生成高保真毫米波流场，将其转换为有向几何图以捕捉主导流方向，并通过雅可比矩阵分析提取人群语义（如转向、聚集等）。

研究结果: 在21次实验中，框架成功重建了复杂人群的流结构，实现了高空间对齐和流分割比的精确量化，并能准确推断人群语义（如边界转向、分散等）。

研究结论: mmFlux框架在人群流场重建和语义分析方面表现出色，验证了其在多种人群分析应用中的潜力。

中文摘要: 本文提出了一种利用毫米波雷达提取人群运动模式并推断语义的新框架。首先，结合光学流估计与新型统计和形态学噪声滤波，生成高保真的毫米波流场（人群运动的紧凑二维矢量表示）。随后，将这些流场转换为有向几何图，边捕捉主导流方向，顶点标记人群分裂或合并，并量化边的流分布。最后，通过分析局部雅可比矩阵及其旋度和散度，提取结构化或分散人群的关键语义。我们在3个区域对最多20人的人群进行了21次实验，使用商用毫米波雷达。结果显示，框架能高保真重建复杂人群的流结构，实现强空间对齐和流分割比的精确量化。此外，旋度和散度分析能准确推断人群语义（如急转弯、流向变化边界、分散和聚集）。这些发现验证了框架的潜力，适用于多种人群分析应用。

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [206] [Optimal Auction Design in the Joint Advertising](https://arxiv.org/abs/2507.07418)
**中文标题：联合广告中的最优拍卖设计**

*Yang Li,Yuchao Ma,Qi Qi*

主要分类: cs.GT

摘要简述: 本文提出了一种在联合广告中实现最优拍卖设计的机制，针对单槽和多槽场景分别提出理论分析和BundleNet神经网络方法，显著提升平台收入并满足激励兼容性和个体理性。


<details>
  <summary>详细信息</summary>
研究动机: 在线广告是互联网平台的主要收入来源，而联合广告通过捆绑多个广告主提升效率和收入。然而现有机制未能实现最优，因其忽视捆绑结构。本文旨在填补这一空白。

研究方法: 针对单槽联合广告，提出最优机制；针对多槽场景，设计BundleNet神经网络方法，专门优化联合广告的捆绑分配。

研究结果: 实验表明，BundleNet在单槽场景中接近理论最优，在多槽场景中表现最佳，显著提升收入并满足激励兼容性和个体理性。

研究结论: 本文提出的机制在联合广告中实现了最优设计，BundleNet在多槽场景中表现卓越，为平台收入增长提供了有效解决方案。

中文摘要: 在线广告是互联网平台的重要收入来源。近年来，联合广告通过将两个广告主捆绑分配至同一广告位，而非单一广告主，成为提升分配效率和收入的有效方法。然而，现有联合广告机制未能实现最优，因其倾向于关注单个广告主而忽视捆绑结构。本文在单槽场景中提出了一种最优联合广告机制。针对多槽联合广告，我们提出了BundleNet，一种专为联合广告设计的基于神经网络的捆绑方法。大量实验表明，BundleNet生成的机制在单槽场景中接近理论分析结果，并在多槽场景中达到最先进性能，显著提升平台收入的同时确保近似主导策略激励兼容性和个体理性。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [207] [MODA: A Unified 3D Diffusion Framework for Multi-Task Target-Aware Molecular Generation](https://arxiv.org/abs/2507.07201)
**中文标题：MODA：一个统一的三维扩散框架用于多任务目标感知的分子生成**

*Dong Xu,Zhangfan Yang,Sisi Yuan,Jenna Xinyi Yao,Jiangqiang Li,Junkai Ji*

主要分类: q-bio.BM

摘要简述: MODA是一个统一的三维扩散框架，用于多任务目标感知的分子生成，通过贝叶斯掩码调度器实现片段生长、连接设计、骨架跳跃和侧链修饰的统一训练，显著提升了分子设计的几何和化学性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的三维分子生成器在任务上分散，SMILES输入、两阶段预训练-微调流程以及单任务单模型的实践限制了立体化学保真度、任务对齐和零样本迁移能力。MODA旨在解决这些问题，提供一种统一的多任务分子生成框架。

研究方法: MODA采用贝叶斯掩码调度器，在训练中掩码连续空间片段并通过单次去噪学习共享的几何和化学先验。多任务训练生成通用骨干模型，优于六种扩散基线模型和三种训练范式。

研究结果: MODA在子结构、化学性质、相互作用和几何性能上表现优异。Model-C减少了配体-蛋白冲突和子结构差异，同时保持Lipinski合规性；Model-B保留了相似性但在新颖性和结合亲和力上稍逊。零样本从头设计和先导优化测试显示稳定的负Vina分数和高改进率。

研究结论: MODA证明单阶段多任务扩散流程可以替代两阶段工作流，为基于结构的分子设计提供高效解决方案。

中文摘要: 基于扩散模型的三维分子生成器已能达到接近晶体学的精度，但在任务上仍显分散。仅使用SMILES输入、两阶段预训练-微调流程以及单任务单模型的实践限制了立体化学保真度、任务对齐和零样本迁移能力。我们提出MODA，一种通过贝叶斯掩码调度器统一片段生长、连接设计、骨架跳跃和侧链修饰的扩散框架。训练中，连续空间片段被掩码并通过单次去噪学习共享的几何和化学先验。多任务训练生成的通用骨干模型在子结构、化学性质、相互作用和几何性能上超越了六种扩散基线模型和三种训练范式。Model-C减少了配体-蛋白冲突和子结构差异，同时保持Lipinski合规性；Model-B保留了相似性但在新颖性和结合亲和力上稍逊。零样本从头设计和先导优化测试显示稳定的负Vina分数和高改进率，无需力场优化。这些结果表明，单阶段多任务扩散流程可以替代两阶段工作流，用于基于结构的分子设计。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [208] [Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks](https://arxiv.org/abs/2506.21142)
**中文标题：针对无人机网络攻击的生成对抗规避与异常分布检测**

*Deepak Kumar Panda,Weisi Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种基于条件生成对抗网络（cGAN）的框架，用于生成隐蔽的对抗攻击以规避无人机入侵检测系统（IDS）。同时，采用条件变分自编码器（CVAE）检测此类攻击，结果显示CVAE在识别隐蔽威胁方面显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着无人机在民用领域的广泛应用，传统异常检测方法难以识别新型威胁，尤其是隐蔽的对抗攻击。因此，需要开发更智能的入侵检测系统以应对此类挑战。

研究方法: 首先设计了一个基于良性无人机遥测数据和已知网络攻击（如DoS、FDI、MiTM和重放攻击）的多类IDS分类器。利用cGAN生成对抗样本，使其被误分类为良性数据，同时保持与异常分布（OOD）的统计相似性。随后，通过条件变分自编码器（CVAE）检测这些对抗样本。

研究结果: 实验表明，基于CVAE的检测方法在识别隐蔽对抗攻击方面显著优于传统的基于马氏距离的检测器，强调了高级概率建模在提升IDS能力中的重要性。

研究结论: 研究强调了对抗生成模型在网络入侵中的威胁，并展示了CVAE在检测此类攻击中的有效性，为未来IDS的设计提供了新思路。

中文摘要: 随着无人机在民用空域的日益普及，对弹性和智能入侵检测系统（IDS）的需求日益凸显，传统异常检测方法往往无法识别新型威胁。常见方法将未知攻击视为异常分布（OOD）样本，但若缓解措施不足，系统仍易受攻击。此外，传统OOD检测器难以区分隐蔽对抗攻击与真实OOD事件。本文提出了一种基于条件生成对抗网络（cGAN）的框架，用于生成隐蔽对抗攻击以规避IDS机制。我们首先设计了一个基于良性无人机遥测数据和已知网络攻击（如DoS、FDI、MiTM和重放攻击）的多类IDS分类器。利用该分类器，cGAN扰动已知攻击以生成被误分类为良性但仍保持OOD分布统计特征的对抗样本。这些样本通过迭代优化实现高隐蔽性和成功率。为检测此类扰动，我们采用条件变分自编码器（CVAE），利用负对数似然分离对抗输入与真实OOD样本。对比评估表明，基于CVAE的后悔分数在识别隐蔽对抗威胁方面显著优于传统基于马氏距离的检测器。研究结果强调了高级概率建模对增强IDS应对基于生成模型的自适应网络入侵能力的重要性。

</details>


### [209] [Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation](https://arxiv.org/abs/2507.07147)
**中文标题：基于无描述多提示学习的大型语言模型蒸馏**

*Sua Lee,Kyubum Shin,Jung Ho Park*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DeMul的新方法，通过直接蒸馏大型语言模型（LLM）的知识到提示中，避免了传统方法中提取描述的不可靠性，并在多提示设置中展示了提示加权的重要性。实验证明该方法在11个识别数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通过从LLM提取文本描述来增强视觉语言模型（VLM）的提示学习，但这些描述存在高变异性与低可靠性问题。本文旨在通过直接蒸馏LLM知识到提示中，避免提取描述的过程，从而提升提示的语义丰富性和优化效率。

研究方法: 提出Description-free Multi-prompt Learning（DeMul），直接蒸馏LLM知识到提示中，避免提取描述的步骤。采用连续向量表示提示，无需预定义模板，并在多提示设置中引入提示加权机制以反映不同提示的重要性。

研究结果: 实验结果表明，DeMul方法在11个识别数据集上表现优于现有方法，验证了其有效性和鲁棒性。

研究结论: DeMul通过直接蒸馏LLM知识到提示中，避免了提取描述的不可靠性，同时通过提示加权提升了多提示学习的性能，为视觉语言模型的提示学习提供了新思路。

中文摘要: 近年来，预训练的视觉语言模型（VLM）通过提示学习展现出适应下游任务的潜力，无需额外标注数据。为补充VLM中与视觉数据相关的文本信息，新方法利用大型语言模型（LLM）增强提示的鲁棒性。现有方法通常从LLM提取文本描述（如描述）融入提示，但存在高变异性与低可靠性问题。本文提出无描述多提示学习（DeMul），直接蒸馏LLM知识到提示中，无需提取描述。通过无描述方法，提示能封装更丰富的语义，同时以连续向量表示优化，无需离散预定义模板。此外，在多提示设置中，我们实证了提示加权在训练中反映不同提示重要性的潜力。实验结果显示，该方法在11个识别数据集上表现优异。

</details>


### [210] [Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching](https://arxiv.org/abs/2507.07192)
**中文标题：弥合预测的最后一英里：通过条件引导流匹配增强时间序列预测**

*Huibo Xu,Runlong Yu,Likang Wu,Xianquan Wang,Qi Liu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为条件引导流匹配（CGFM）的新方法，通过结合辅助模型的输出和误差学习，显著提升了时间序列预测的性能。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在时间序列预测中表现有限，存在源分布僵化和采样路径受限的问题。流匹配虽具潜力，但尚未充分利用预测误差信息。本文旨在解决这些问题，提出CGFM以提升预测能力。

研究方法: CGFM扩展了流匹配方法，引入辅助模型的输出作为条件，构建双面条件概率路径，并通过一般仿射路径扩展概率路径空间，从而优化预测结果。

研究结果: 实验表明，CGFM在时间序列预测任务中持续优于现有先进模型，验证了其有效性。

研究结论: CGFM通过结合误差学习和条件引导，显著提升了时间序列预测的准确性和灵活性，为预测方法的发展提供了新方向。

中文摘要: 扩散模型作为一种生成模型，在时间序列预测中展现出潜力，但其性能受到源分布僵化和采样路径有限的限制。流匹配具有更快的生成速度、更高质量的输出和更强的灵活性，同时能够利用先前模型预测误差中的宝贵信息，这些信息以往无法获取却至关重要。为解决这些问题并充分释放流匹配的潜力，我们提出了条件引导流匹配（CGFM）。CGFM通过结合辅助模型的输出扩展了流匹配，实现了领域内前所未有的能力：从辅助模型的误差中学习。在时间序列预测任务中，它整合历史数据作为条件和引导，构建双面条件概率路径，并使用一般仿射路径扩展概率路径空间，最终提升预测效果。大量实验表明，CGFM持续增强并优于现有先进模型，突显了其在推动预测方法进步中的有效性。

</details>


### [211] [Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning](https://arxiv.org/abs/2507.07197)
**中文标题：结合预训练模型以增强强化学习中的特征表示**

*Elia Piccoli,Malio Li,Giacomo Carfì,Vincenzo Lomonaco,Davide Bacciu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为权重共享注意力（WSA）的新架构，用于结合多个预训练模型的嵌入信息，以增强强化学习中的状态表示，并在多个Atari游戏中验证了其性能。


<details>
  <summary>详细信息</summary>
研究动机: 预训练模型在自然语言处理和计算机视觉等领域取得了显著进展，但如何在强化学习中有效结合不同预训练模型的隐藏信息仍是一个未充分研究的问题。本文旨在解决这一问题。

研究方法: 提出权重共享注意力（WSA）架构，通过结合多个预训练模型的嵌入信息，生成丰富的状态表示，并在效率和性能之间取得平衡。

研究结果: 在多个Atari游戏中，WSA的性能与端到端模型相当，同时研究了该方法的泛化能力以及模型数量对性能的影响。

研究结论: WSA为强化学习中结合预训练模型提供了一种有效方法，展示了其在性能和效率上的优势，并为进一步研究提供了方向。

中文摘要: 近年来，预训练模型已成为许多领域（如自然语言处理和计算机视觉）的关键组成部分，它们通过学习不同的潜在嵌入共享了丰富的表征。另一方面，强化学习（RL）专注于通过智能体与环境的交互最大化累积奖励。RL智能体对世界没有任何先验知识，它们要么从零开始学习观察空间与动作空间之间的端到端映射，要么在最近的研究中与庞大且计算成本高的基础模型配对。如何有效结合并同时利用不同预训练模型的隐藏信息，仍然是强化学习中一个开放且未充分研究的问题。本文提出权重共享注意力（WSA），一种新的架构，用于结合多个预训练模型的嵌入信息，以生成丰富的状态表示，并在效率与性能之间取得平衡。我们通过多种组合模式的广泛比较表明，WSA在多个Atari游戏中的性能与端到端模型相当。此外，我们还研究了该方法的泛化能力，并分析了模型数量对智能体在训练期间和训练后性能的影响。

</details>


### [212] [Bias-Aware Mislabeling Detection via Decoupled Confident Learning](https://arxiv.org/abs/2507.07216)
**中文标题：基于解耦自信学习的偏差感知误标检测**

*Yunyi Li,Maria De-Arteaga,Maytal Saar-Tsechansky*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DeCoLe的机器学习框架，专门用于检测受标签偏差影响的误标数据，提升数据质量。


<details>
  <summary>详细信息</summary>
研究动机: 标签偏差是数据完整性的重要挑战，尤其在关键领域中广泛存在，但目前缺乏有效解决方法。本文旨在填补这一空白。

研究方法: 提出Decoupled Confident Learning (DeCoLe)框架，通过理论分析和实验验证其在误标检测中的有效性，特别针对仇恨言论检测领域。

研究结果: 实验表明，DeCoLe在误标检测中表现优异，显著优于其他方法，尤其在标签偏差明显的场景中。

研究结论: DeCoLe为解决标签偏差导致的误标问题提供了有效工具，并可为组织数据管理实践提供指导。

中文摘要: 可靠数据是现代组织系统的基石。数据完整性的一个重要挑战源于标签偏差，即标签中的系统性错误，这种偏差在不同社会群体中表现不同。尽管标签偏差在理论和实践中已被广泛探讨，但有效的解决方法仍然稀缺。本文提出了一种名为Decoupled Confident Learning (DeCoLe)的机器学习框架，专门用于检测受标签偏差影响的误标数据，实现偏差感知的误标检测并提升数据质量。我们从理论上证明了DeCoLe的有效性，并在仇恨言论检测这一标签偏差显著的领域进行了评估。实验结果表明，DeCoLe在偏差感知误标检测中表现优异，显著优于其他误标检测方法。本文不仅识别并解决了偏差感知误标检测的挑战，还为如何将DeCoLe整合到组织数据管理实践中提供了指导，以增强数据可靠性。

</details>


### [213] [An Information-Theoretic Perspective on Multi-LLM Uncertainty Estimation](https://arxiv.org/abs/2507.07236)
**中文标题：多LLM不确定性估计的信息论视角**

*Maya Kruse,Majid Afshar,Saksham Khatwani,Anoop Mayampurath,Guanhua Chen,Yanjun Gao*

主要分类: cs.LG

摘要简述: 本文提出MUSE方法，通过信息论视角利用Jensen-Shannon散度聚合多个LLM的预测，提升不确定性估计的可靠性。实验表明其在二元预测任务中优于单模型和简单集成方法。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在不同输入下表现不一致，表明其存在不确定性。现有研究多关注单一模型，忽略了模型多样性潜力。本文假设LLM因训练差异和语言的Zipf特性而互补，聚合其输出可提升不确定性估计的可靠性。

研究方法: 提出MUSE方法，基于Jensen-Shannon散度识别并聚合校准良好的LLM子集，通过信息论视角实现多模型不确定性估计。

研究结果: 在二元预测任务中，MUSE方法在校准性和预测性能上优于单模型和简单集成基线。

研究结论: MUSE通过利用模型多样性，显著提升了不确定性估计的可靠性，为高风险场景下的LLM应用提供了实用工具。

中文摘要: 大型语言模型（LLM）在不同输入下表现不一致，表明其不确定性，这在高风险场景中需要量化。现有研究多关注单一模型，忽略了模型多样性的潜力。我们假设LLM因训练差异和语言的Zipf特性而互补，聚合其输出可提升不确定性估计的可靠性。为此，我们提出MUSE（基于子集集成的多LLM不确定性估计方法），这是一种简单的信息论方法，利用Jensen-Shannon散度识别并聚合校准良好的LLM子集。在二元预测任务上的实验表明，MUSE在校准性和预测性能上优于单模型和简单集成基线。

</details>


### [214] [Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention](https://arxiv.org/abs/2507.07247)
**中文标题：显微镜下的注意力：自注意力变体资源利用的比较研究**

*Zhengyu Tian,Anantha Padmanaban Krishna Kumar,Hemant Krishnakumar,Reza Rawassizadeh*

主要分类: cs.LG

摘要简述: 本文对八种自注意力机制在GPT-2架构训练中的资源利用进行了比较研究，发现优化内核实现的注意力机制（如Flash Attention、LSH Attention和MLA）能效最高。同时指出，仅降低GPU功耗并不能保证减少总能耗，训练时间同样重要。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型（LLM）和视觉语言模型（VLM）规模扩大，注意力机制因高内存和时间复杂度成为计算瓶颈。尽管已有多种高效注意力变体，但缺乏对其实际能耗和硬件资源需求的严格评估。

研究方法: 研究在GPT-2架构训练中，对八种注意力机制进行了基准测试，测量了训练时间、GPU内存使用、FLOPS、CPU使用和功耗等关键指标。

研究结果: 结果显示，优化内核实现的注意力机制（如Flash Attention、LSH Attention和MLA）能效最佳。此外，仅降低GPU功耗并不能保证减少总能耗，训练时间同样关键。

研究结论: 研究强调了在注意力设计中能耗感知基准测试的重要性，并为选择资源高效机制提供了实用见解。所有代码已在GitHub上开源。

中文摘要: 随着大语言模型（LLM）和视觉语言模型（VLM）规模扩大和应用广泛，注意力机制因其高内存和时间复杂度成为计算瓶颈。尽管已提出多种高效注意力变体，但对其实际能耗和硬件资源需求的严格评估仍缺乏。本研究在GPT-2架构训练中，对八种注意力机制进行了基准测试，测量了训练时间、GPU内存使用、FLOPS、CPU使用和功耗等关键指标。结果显示，优化内核实现的注意力机制（如Flash Attention、LSH Attention和Multi-Head Latent Attention（MLA））能效最佳。我们还发现，仅降低GPU功耗并不能保证减少总能耗，训练时间同样重要。本研究强调了在注意力设计中能耗感知基准测试的重要性，并为选择资源高效机制提供了实用见解。所有代码已在GitHub上开源。

</details>


### [215] [Exploiting Edge Features for Transferable Adversarial Attacks in Distributed Machine Learning](https://arxiv.org/abs/2507.07259)
**中文标题：利用边缘特征实现分布式机器学习中可迁移对抗攻击**

*Giulio Rossolini,Fabio Brau,Alessandro Biondi,Battista Biggio,Giorgio Buttazzo*

主要分类: cs.LG

摘要简述: 本文揭示了分布式机器学习中边缘特征泄露的安全风险，提出了一种利用中间特征构建代理模型的方法，显著提高了对抗攻击的可迁移性。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习模型在物联网边缘环境中的广泛应用，分布式深度学习范式将模型计算分散到多个节点，增加了安全风险。本文旨在探索即使边缘和云端模型均为黑盒，攻击者仍可通过拦截中间特征对系统构成威胁。

研究方法: 提出了一种针对分布式环境的攻击策略：通过统计分析从向量化的传输特征中重建原始张量形状，并设计适配的代理模型架构，以有效蒸馏中间特征并生成高迁移性的对抗样本。

研究结果: 实验表明，利用中间特征训练的代理模型显著提升了对抗攻击的迁移性，揭示了分布式深度学习系统中中间特征泄露的严重安全隐患。

研究结论: 研究强调了在安全设计分布式深度学习系统时，必须考虑中间特征泄露的风险，并采取相应防护措施。

中文摘要: 随着机器学习模型在物联网边缘环境中的广泛部署，分布式深度学习范式将模型计算分散到多个异构节点和通信层，从而扩大了潜在攻击面。本文基于这一背景，探讨了一个被忽视的漏洞：即使边缘和云端模型均为黑盒，攻击者仍可通过拦截传输的中间特征构成严重威胁。研究表明，在这些温和且现实的假设下，攻击者可以构建高迁移性的代理模型，使整个深度学习系统更容易受到规避攻击。具体而言，拦截的中间特征可有效用于蒸馏代理模型，生成高迁移性的对抗样本。为此，我们提出了一种专为分布式环境设计的攻击策略，包括通过统计分析从向量化传输特征中重建原始张量形状，并调整代理模型架构以实现有效的特征蒸馏。系统性实验表明，利用中间特征训练的代理模型显著提高了对抗攻击的迁移性。这些发现强调了在设计安全分布式深度学习系统时，亟需考虑中间特征泄露的风险。

</details>


### [216] [Growing Transformers: Modular Composition and Layer-wise Expansion on a Frozen Substrate](https://arxiv.org/abs/2507.07129)
**中文标题：生长式Transformer：基于固定底座的模块化组合与逐层扩展**

*A. Bochkov*

主要分类: cs.LG

摘要简述: 本文提出了一种模块化和渐进式扩展的Transformer模型构建方法，基于固定的输入嵌入，实现了专家模型的无缝合并和逐层训练，显著提升了模型性能和资源效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型的扩展通常采用端到端的整体训练，资源消耗大且缺乏灵活性。本文探索了一种基于固定输入嵌入的模块化和渐进式扩展方法，以提高模型开发的效率和灵活性。

研究方法: 1. 通过固定输入嵌入作为通用接口，实现专家模型的零修改合并（如俄语和中文模型）。2. 提出逐层渐进式训练方法，逐步堆叠和训练Transformer层。

研究结果: 合并后的专家模型在MMLU等推理任务上表现优于单一模型，且无灾难性遗忘。逐层训练方法稳定收敛，模型深度与复杂推理能力（如SQuAD）呈正相关。

研究结论: 本文方法为AI开发提供了更高效、灵活的范式，支持资源节约、持续学习和模块化组合，推动了AI生态系统的民主化发展。

中文摘要: 当前扩展大型语言模型（LLM）的主流方法是端到端的整体训练，这一过程资源密集且缺乏灵活性。本文探索了一种基于非可训练、确定性输入嵌入的替代性模型开发方法。在先前研究中，我们证明了基于Unicode字形视觉结构的冻结嵌入可以在Transformer中涌现高级语义推理能力。本文进一步表明，这种固定表示底座可作为通用“对接端口”，支持两种高效扩展范式：无缝模块化组合和逐层渐进式增长。

首先，我们展示了在训练后无需架构修改的情况下，通过简单平均输出逻辑，可以将不同数据集（如俄语和中文文本）训练的专家模型合并为一个更强大的混合专家（MoE）模型。合并后的MoE模型在MMLU等推理基准上表现优于单一专家模型，且无灾难性遗忘。其次，我们提出了一种逐层构建训练方法，通过逐步堆叠和训练Transformer层来“生长”深度模型。该方法表现出稳定的收敛性，且模型深度与复杂推理能力（如SQuAD所需）呈正相关。

我们的研究结果表明，从整体优化转向更接近生物学或构建性的AI开发范式是可行的，即通过增量构建复杂性和自由组合模块。这为资源高效扩展、持续学习以及构建强大AI系统的民主化生态系统开辟了新途径。我们公开了所有代码和模型以促进进一步研究。

</details>


### [217] [Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery](https://arxiv.org/abs/2507.07328)
**中文标题：通过微调增强推理能力的LLM以弥合化学合成与发现中的合理性-有效性差距**

*Malikussaid,Hilal Hudan Nuha*

主要分类: cs.LG

摘要简述: 本文提出了一种通过微调具备推理能力的LLM（如Magistral Small模型）并结合双领域数据集的方法，以解决化学领域中LLM生成信息科学合理但事实无效的问题。结果显示，微调后的模型在格式、分子化学有效性和合成路线可行性方面显著优于基线模型，但仍存在立体化学错误等局限性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在化学等专业领域常生成看似合理但实际无效的信息，即“合理性-有效性差距”。本文旨在通过开发一种专门化的科学助手来弥合这一差距。

研究方法: 研究采用具备推理能力的Magistral Small模型，并通过低秩适应（LoRA）进行微调。关键步骤是构建一个包含分子性质和化学反应的双领域数据集，并进行标准化以确保数据质量。

研究结果: 微调后的模型在格式一致性、分子化学有效性和合成路线可行性方面显著优于基线模型。与人类专家相比，模型在化学创造力和推理方面表现竞争性，但仍存在立体化学错误和知识更新限制等问题。

研究结论: 本研究为将通用LLM转化为可靠的化学研究工具提供了可行框架，同时指出了未来改进的关键方向。

中文摘要: 大型语言模型（LLM）常生成科学上看似合理但事实无效的信息，这一问题在化学等专业领域尤为突出，我们称之为“合理性-有效性差距”。本文提出了一种系统方法，通过开发专门化的科学助手来弥合这一差距。我们采用了具备集成推理能力的Magistral Small模型，并通过低秩适应（LoRA）进行微调。方法的核心是构建一个“双领域数据集”，该数据集从多个来源中精选并标准化，涵盖分子性质和化学反应。评估表明，微调后的模型在格式一致性、生成分子的化学有效性以及合成路线的可行性方面显著优于基线模型。结果显示了一种层次化学习模式，其中语法正确性比化学可能性和合成可行性更容易掌握。与人类专家的对比分析表明，模型在化学创造力和推理方面表现竞争性，但也揭示了关键局限性，如立体化学错误、静态知识截止和偶尔的引用幻觉。本研究为将通用LLM转化为可靠的化学研究工具提供了可行框架，同时明确了未来改进的关键方向。

</details>


### [218] [Leveraging Manifold Embeddings for Enhanced Graph Transformer Representations and Learning](https://arxiv.org/abs/2507.07335)
**中文标题：利用流形嵌入增强图变换器的表示与学习能力**

*Ankit Jyothish,Ali Jannesari*

主要分类: cs.LG

摘要简述: 论文提出一种轻量级的黎曼混合专家层，将节点投影到多种流形（如球面、平坦、双曲空间），以更好地匹配局部结构，从而提升图变换器的表示能力和分类准确率。


<details>
  <summary>详细信息</summary>
研究动机: 传统图变换器将所有节点嵌入单一欧几里得空间，忽略了异构拓扑结构。本文旨在通过几何感知的投影方法，提升图表示的准确性和可解释性。

研究方法: 在现有图变换器前添加一个轻量级的黎曼混合专家层，将节点动态路由到最适合其局部结构的流形（如球面、平坦或双曲空间），以捕捉几何特征。

研究结果: 该方法在四个节点分类基准测试中，将准确率最高提升了3%，同时增强了图表示的几何可解释性。

研究结论: 通过显式的几何感知投影，图变换器的预测能力和表示可解释性均得到显著提升，证明了异构流形嵌入的有效性。

中文摘要: 传统图变换器通常将所有节点嵌入单一欧几里得空间，模糊了异构拓扑结构。我们提出一种轻量级的黎曼混合专家层，将每个节点动态路由到最适合其局部结构的流形（如球面、平坦或双曲空间），从而为潜在空间提供内在几何解释。将这一投影层嵌入到先进的集成图变换器中，在四个节点分类基准测试中，准确率最高提升了3%。该集成方法确保了欧几里得和非欧几里得特征均被捕捉。显式的几何感知投影不仅提升了预测能力，还使图表示更具可解释性。

</details>


### [219] [Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning](https://arxiv.org/abs/2507.07359)
**中文标题：面向目标的序列贝叶斯实验设计用于因果学习**

*Zheyu Zhang,Jiayuan Dong,Jie Liu,Xun Huan*

主要分类: cs.LG

摘要简述: 本文提出了一种目标导向的贝叶斯框架GO-CBED，用于序列因果实验设计，直接最大化用户指定因果量的信息增益，并通过变分下界估计器和神经网络实现高效决策。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法通常旨在推断完整的因果模型，而忽略了用户特定的因果量。本文旨在通过目标导向的实验设计，更高效地获取与研究目标直接相关的因果信息。

研究方法: GO-CBED框架通过变分下界估计器计算期望信息增益，结合基于Transformer的策略网络和基于归一化流的变分后验，实现非短视的序列干预优化。

研究结果: 实验表明，GO-CBED在多种因果推理和发现任务中（如合成结构因果模型和半合成基因调控网络）优于现有基线，尤其在实验预算有限和因果机制复杂的情况下表现突出。

研究结论: 研究强调了实验设计目标与具体研究目标对齐的重要性，以及前瞻性序列规划的优势。

中文摘要: 我们提出了GO-CBED，一种面向目标的贝叶斯框架，用于序列因果实验设计。与传统方法不同，GO-CBED直接最大化用户指定因果量的期望信息增益（EIG），从而实现更具针对性和高效的实验。该框架既非短视，优化整个干预序列，又面向目标，仅针对与因果查询相关的模型方面。为了解决精确EIG计算的难解性，我们引入了一种变分下界估计器，通过基于Transformer的策略网络和基于归一化流的变分后验联合优化。生成的策略通过摊销网络实现实时决策。我们证明，GO-CBED在各种因果推理和发现任务（包括合成结构因果模型和半合成基因调控网络）中始终优于现有基线，尤其是在实验预算有限和因果机制复杂的情况下。我们的结果突出了实验设计目标与特定研究目标对齐以及前瞻性序列规划的益处。

</details>


### [220] [Atherosclerosis through Hierarchical Explainable Neural Network Analysis](https://arxiv.org/abs/2507.07373)
**中文标题：基于分层可解释神经网络的动脉粥样硬化分析**

*Irsyad Adam,Steven Swee,Erika Yilin,Ethan Ji,William Speier,Dean Wang,Alex Bui,Wei Wang,Karol Watson,Peipei Ping*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ATHENA的分层可解释神经网络框架，用于个性化分类亚临床动脉粥样硬化，通过整合临床特征和分子数据，显著提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于图的方法在疾病分类中缺乏对队列特征的连贯性和理解，且临床特征与分子数据的整合不足。本文旨在解决这些问题，提升动脉粥样硬化的分类和预测能力。

研究方法: ATHENA通过分层网络表示整合多模态学习，优化患者特异性分子指纹，确保与队列模式的一致性，并利用可解释AI驱动的子网络聚类进行患者亚型发现。

研究结果: 在391名患者的数据集上，ATHENA显著提升了分类性能，AUC和F1分数分别提高了13%和20%。

研究结论: ATHENA通过整合临床与分子数据，为个性化干预策略提供了新框架，有助于预测动脉粥样硬化疾病进展和管理临床结果。

中文摘要: 本研究通过开发一种分层图神经网络框架，解决了亚临床动脉粥样硬化的个性化分类问题。该框架整合了患者的临床特征和分子数据，弥补了现有方法在队列特征连贯性和分子数据整合方面的不足。我们提出的ATHENA（基于分层可解释神经网络的动脉粥样硬化分析）通过多模态学习构建分层网络表示，优化患者特异性分子指纹，并确保其与队列模式的一致性。在包含391名患者的主要临床数据集中，ATHENA显著提升了分类性能，AUC和F1分数分别提高了13%和20%。此外，ATHENA通过可解释AI驱动的子网络聚类，实现了机制驱动的患者亚型发现，为个性化干预策略提供了新框架，从而改善了动脉粥样硬化疾病进展的预测和临床结果的管理。

</details>


### [221] [Bradley-Terry and Multi-Objective Reward Modeling Are Complementary](https://arxiv.org/abs/2507.07375)
**中文标题：Bradley-Terry与多目标奖励建模的互补性**

*Zhiwei Zhang,Hui Liu,Xiaomin Li,Zhenwei Dai,Jingying Zeng,Fali Wang,Minhua Lin,Ramraj Chandradevan,Zhen Li,Chen Luo,Xianfeng Tang,Qi He,Suhang Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种统一的奖励建模框架，结合Bradley-Terry单目标和多目标回归奖励函数，通过共享嵌入空间联合训练，显著提升了奖励模型的鲁棒性和评分性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于人类偏好的奖励模型在强化学习框架下虽有效，但易受奖励破解影响，且在分布外（OOD）场景下表现不佳。多目标评分虽能缓解问题，但数据质量不足导致性能受限。

研究方法: 提出一个联合训练框架，结合Bradley-Terry单目标损失和多目标回归任务，共享嵌入空间。理论分析表明两者互补：回归任务增强单目标奖励的鲁棒性，BT训练提升多目标评分的准确性。

研究结果: 实验表明，该框架显著提升了奖励模型的鲁棒性和评分能力，7B模型性能超越70B基线。

研究结论: 联合训练Bradley-Terry和多目标回归奖励函数是一种互补且有效的方法，能显著改善奖励模型在OOD场景下的表现。

中文摘要: 基于人类偏好数据训练的奖励模型在强化学习框架下（RLHF）已证明能有效对齐大型语言模型（LLM）与人类意图。然而，RLHF仍易受奖励破解影响，即策略利用奖励函数的缺陷而非真正学习预期行为。尽管已有大量工作致力于缓解奖励破解，但主要集中在分布内场景评估。本文通过实验表明，现有方法在更具挑战性的分布外（OOD）场景中表现不佳。进一步证明，引入细粒度多属性评分有助于解决这一问题，但高质量数据的稀缺常导致多目标奖励函数性能较弱，成为瓶颈。为此，我们提出一种统一的奖励建模框架，通过共享嵌入空间联合训练Bradley-Terry（BT）单目标和多目标回归奖励函数。理论分析揭示了BT损失与回归目标的联系及其互补性：回归任务增强单目标奖励在OOD场景下的鲁棒性，而BT训练提升多目标评分的准确性，使7B模型性能超越70B基线。大量实验表明，该框架显著提升了奖励模型的鲁棒性和评分能力。

</details>


### [222] [COALA: Numerically Stable and Efficient Framework for Context-Aware Low-Rank Approximation](https://arxiv.org/abs/2507.07580)
**中文标题：COALA：一种数值稳定且高效的上下文感知低秩近似框架**

*Uliana Parkina,Maxim Rakhuba*

主要分类: cs.LG

摘要简述: 本文提出了一种名为COALA的数值稳定且高效的框架，用于解决上下文感知低秩近似中的数值不稳定问题，避免了传统方法中的显式Gram矩阵计算和求逆操作。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在上下文感知低秩近似中依赖显式Gram矩阵计算和求逆，导致数值不稳定，影响近似质量或产生数值奇异矩阵。本文旨在解决这些问题。

研究方法: 提出了一种基于稳定分解的无逆正则化框架，避免了显式Gram矩阵计算和求逆，能够处理校准矩阵超出GPU内存容量、输入激活矩阵接近奇异或数据不足的情况。

研究结果: 该方法在数值稳定性上优于现有方法，能够处理多种挑战性场景，并证明了在数据不足时收敛到期望近似，同时给出了显式误差界限。

研究结论: COALA框架通过稳定分解和无逆设计，显著提升了上下文感知低秩近似的数值稳定性和效率，适用于多种复杂场景。

中文摘要: 近期研究表明，上下文感知低秩近似是压缩和微调现代大规模神经网络的有用工具。在此类近似中，范数通过输入激活矩阵加权，显著优于未加权情况。然而，现有方法因依赖涉及显式Gram矩阵计算及其后续求逆的经典公式而存在数值不稳定问题，可能导致近似质量下降或数值奇异矩阵。为解决这些问题，我们提出了一种基于稳定分解的无逆正则化框架，克服了现有技术的数值缺陷。我们的方法能够处理以下挑战性场景：（1）校准矩阵超出GPU内存容量，（2）输入激活矩阵接近奇异，甚至（3）数据不足导致无法唯一近似。对于后者，我们证明了我们的解收敛于期望近似，并推导了显式误差界限。

</details>


### [223] [Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization](https://arxiv.org/abs/2507.07399)
**中文标题：广义树编辑距离（GTED）：一种可靠的陈述自动形式化评估指标**

*Yuntian Liu,Tao Zhu,Xiaoyang Liu,Yu Chen,Zhaoxuan Liu,Qingfeng Guo,Jiashuo Zhang,Kangjie Bao,Tao Luo*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GTED（广义树编辑距离）的新评估框架，用于自然语言陈述的自动形式化翻译评估，解决了现有方法在语义理解、计算成本和自动化定理证明方面的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前自然语言陈述自动形式化的研究广泛，但缺乏鲁棒的自动化评估指标。现有方法在语义理解、计算效率及依赖自动化定理证明方面存在不足，亟需一种更可靠的评估方法。

研究方法: GTED框架首先将形式化陈述标准化并转换为操作树，然后利用广义树编辑距离（GTED）度量语义相似性。该方法在miniF2F和ProofNet基准测试中验证了其有效性。

研究结果: 在miniF2F和ProofNet基准测试中，GTED在所有基线指标中表现最佳，实现了最高的准确性和Kappa分数，证明了其作为自动化评估指标的优越性。

研究结论: GTED为自然语言陈述自动形式化提供了一种更可靠的评估方法，解决了现有指标的局限性，并在实验中表现出色，为相关研究提供了有力工具。

中文摘要: 陈述自动形式化是将自然语言陈述自动翻译为形式语言的研究领域，但目前缺乏鲁棒的自动化评估指标。现有方法在语义理解、计算成本高以及依赖自动化定理证明方面存在不足。为解决这些问题，我们提出了GTED（广义树编辑距离），一种新的评估框架。该框架首先将形式化陈述标准化并转换为操作树，然后利用GTED度量语义相似性。在miniF2F和ProofNet基准测试中，GTED在所有基线指标中表现最佳，实现了最高的准确性和Kappa分数，为社区提供了一种更可靠的自动化评估指标。代码和实验结果可在https://github.com/XiaoyangLiu-sjtu/GTED获取。

</details>


### [224] [Improving Clustering on Occupational Text Data through Dimensionality Reduction](https://arxiv.org/abs/2507.07582)
**中文标题：通过降维改进职业文本数据的聚类效果**

*Iago Xabier Vázquez García,Damla Partanaz,Emrullah Fatih Yetkin*

主要分类: cs.LG

摘要简述: 本研究提出了一种基于BERT技术和降维方法的最优聚类机制，用于改进职业文本数据的聚类效果，并通过专用轮廓方法提升结果，为职业转换提供新路径。


<details>
  <summary>详细信息</summary>
研究动机: 尽管O*NET职业数据库中的职业定义基于美国调查，但不同公司或国家的定义可能不同。为扩展O*NET数据并建立不同任务定义之间的映射，需要一种有效的聚类方法。

研究方法: 研究提出了一种结合多种BERT技术和聚类方法的流程，并考察了降维方法对聚类性能指标的影响，最终通过专用轮廓方法优化结果。

研究结果: 通过降维和专用轮廓方法，研究显著提升了聚类效果，为职业自动区分和职业转换提供了新途径。

研究结论: 基于降维的聚类映射方法能够有效区分职业定义，为职业转换和数据分析提供了实用工具。

中文摘要: 本研究旨在为美国职业数据库O*NET中的职业定义提出一种最优聚类机制。尽管这些职业定义基于美国调查，但其在不同公司或国家可能存在差异。因此，若需扩展O*NET数据并为不同任务定义的职业建立映射，这种映射将至关重要。我们提出了一种结合多种BERT技术和聚类方法的流程，并研究了降维方法对聚类性能指标的影响。最终，通过专用轮廓方法进一步优化了结果。这种基于降维的聚类映射方法有助于自动区分职业，为职业转换者开辟新路径。

</details>


### [225] [HGMP:Heterogeneous Graph Multi-Task Prompt Learning](https://arxiv.org/abs/2507.07405)
**中文标题：HGMP：异构图多任务提示学习**

*Pengfei Jiao,Jialong Ni,Di Jin,Xuan Guo,Huan Liu,Hongjiang Chen,Yanxian Bi*

主要分类: cs.LG

摘要简述: HGMP是一种针对异构图的多任务提示学习框架，通过统一任务格式、对比预训练策略和异构特征提示，解决了预训练模型与下游任务不匹配的问题，显著提升了多任务场景下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 预训练与微调方法在异构图神经网络中广泛应用，但存在预训练模型与下游任务不匹配的问题，导致性能不佳。提示学习方法因其灵活性成为新方向，但现有方法难以整合对比预训练策略。

研究方法: HGMP框架首先将下游任务统一为图级任务格式，设计图级对比预训练策略以利用异构信息，并引入异构特征提示优化输入图特征表示。

研究结果: 在公开数据集上的实验表明，HGMP能适应多种任务，并显著优于基线方法。

研究结论: HGMP通过统一任务格式、对比预训练和异构特征提示，有效解决了预训练与下游任务的匹配问题，提升了多任务性能。

中文摘要: 预训练与微调方法因其在预训练阶段利用大量未标记数据学习丰富结构特征的能力，在异构图神经网络领域受到广泛关注。然而，这些方法存在预训练模型与下游任务不匹配的问题，导致某些应用场景下性能不佳。提示学习方法因其灵活调整任务表示以解决目标不一致性，成为异构图任务的新方向。基于此，本文提出了一种名为HGMP的新型异构图多任务提示框架。首先，为弥合预训练模型与下游任务之间的差距，我们将所有下游任务重新表述为统一的图级任务格式。其次，针对现有图提示学习方法难以整合异构图领域的对比预训练策略的局限性，我们设计了一种图级对比预训练策略，以更好地利用异构信息并提升多任务场景下的性能。最后，我们引入了异构特征提示，通过优化输入图特征的表示来增强模型性能。在公开数据集上的实验结果表明，我们提出的方法能很好地适应多种任务，并显著优于基线方法。

</details>


### [226] [GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing](https://arxiv.org/abs/2507.07735)
**中文标题：GuardVal：动态大语言模型越狱评估的综合安全测试方法**

*Peiyan Zhang,Haibo Jin,Liying Kang,Haohan Wang*

主要分类: cs.LG

摘要简述: 本文提出GuardVal，一种动态评估大语言模型（LLM）越狱漏洞的新方法，通过动态生成和优化越狱提示，全面测试模型的安全性，并揭示其潜在弱点。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大语言模型（LLM）越狱评估方法存在不足，无法全面测试模型的漏洞。随着LLM的不断演进，亟需一种动态且高效的评估协议，以更准确地评估模型的安全性。

研究方法: 本文提出GuardVal协议，动态生成和优化越狱提示，结合防御模型的状态调整攻击策略，并引入一种新的优化方法以避免提示优化的停滞。

研究结果: GuardVal在多种模型（如Mistral-7b和GPT-4）上进行了测试，覆盖10个安全领域，揭示了模型的不同行为模式及其鲁棒性。

研究结论: GuardVal为LLM安全性评估提供了更全面的方法，揭示了模型的潜在弱点，并为未来研究和安全模型开发提供了重要见解。

中文摘要: 越狱攻击揭示了大语言模型（LLM）生成有害或不道德内容的关键漏洞。由于LLM的不断演进和漏洞探测的复杂性，评估这些威胁尤为困难。现有基准和评估方法难以全面应对这些挑战，导致LLM漏洞评估存在空白。本文回顾了现有的越狱评估实践，并提出了有效越狱评估协议的三个理想特性。为解决这些问题，我们提出了GuardVal，一种新的评估协议，根据防御LLM的状态动态生成和优化越狱提示，从而更准确地评估防御LLM处理安全关键情况的能力。此外，我们提出了一种新的优化方法，避免提示优化过程中的停滞，确保生成更有效的越狱提示，揭示防御LLM的更深层次弱点。我们将该协议应用于从Mistral-7b到GPT-4的多种模型，覆盖10个安全领域。研究结果突出了模型之间的不同行为模式，提供了对其鲁棒性的全面视角。此外，我们的评估过程深化了对LLM行为的理解，为未来研究和开发更安全的模型提供了重要见解。

</details>


### [227] [Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning](https://arxiv.org/abs/2507.07485)
**中文标题：解决令牌空间梯度冲突：基于Transformer的多任务学习中的令牌空间操作**

*Wooseong Jeong,Kuk-Jin Yoon*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DTME-MTL的动态令牌调制与扩展框架，用于解决基于Transformer的多任务学习中的令牌空间梯度冲突问题，通过自适应调整令牌空间来提升模型适应性和减少过拟合。


<details>
  <summary>详细信息</summary>
研究动机: 多任务学习（MTL）中，不同任务的目标差异可能导致负迁移，即一个任务的学习会降低其他任务的性能。尽管预训练的Transformer显著提升了MTL性能，但其固定的网络容量和结构限制了适应性。现有动态网络架构效率低下，因为它们直接将共享参数转换为任务特定参数。

研究方法: 本文提出DTME-MTL框架，通过识别令牌空间中的梯度冲突并根据冲突类型应用自适应解决方案，增强模型适应性并减少过拟合。与以往通过复制网络参数来缓解负迁移的方法不同，DTME-MTL完全在令牌空间中操作，实现高效适应且不增加过多参数。

研究结果: 大量实验表明，DTME-MTL能够以最小的计算开销持续提升多任务性能，为基于Transformer的MTL模型提供了可扩展且有效的解决方案。

研究结论: DTME-MTL通过动态令牌调制与扩展，有效解决了多任务学习中的令牌空间梯度冲突问题，显著提升了模型的适应性和性能，同时避免了参数过度增长。

中文摘要: 多任务学习（MTL）允许在共享网络中学习多个任务，但任务间目标的差异可能导致负迁移，即一个任务的学习会降低其他任务的性能。尽管预训练的Transformer显著提升了MTL性能，但其固定的网络容量和结构限制了适应性。现有的动态网络架构试图解决这一问题，但效率低下，因为它们直接将共享参数转换为任务特定参数。我们提出了动态令牌调制与扩展（DTME-MTL），这是一个适用于任何基于Transformer的MTL架构的框架。DTME-MTL通过识别令牌空间中的梯度冲突并根据冲突类型应用自适应解决方案，增强了适应性并减少了过拟合。与以往通过复制网络参数来缓解负迁移的方法不同，DTME-MTL完全在令牌空间中操作，实现了高效适应且不增加过多参数。大量实验表明，DTME-MTL能够以最小的计算开销持续提升多任务性能，为增强基于Transformer的MTL模型提供了一种可扩展且有效的解决方案。

</details>


### [228] [Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings](https://arxiv.org/abs/2507.07532)
**中文标题：神经概念验证器：通过概念编码扩展证明者-验证者游戏**

*Berkant Turan,Suhrab Asadulla,David Steinmann,Wolfgang Stammer,Sebastian Pokutta*

主要分类: cs.LG

摘要简述: 本文提出了一种名为神经概念验证器（NCV）的统一框架，结合了证明者-验证者游戏（PVGs）和概念编码，用于高维复杂数据的可解释非线性分类。NCV通过提取结构化概念编码并使用非线性预测器进行决策，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的证明者-验证者游戏（PVGs）难以应用于高维复杂数据（如图像），而概念瓶颈模型（CBMs）虽然能提取可解释概念，但受限于线性预测器的能力。因此，需要一种既能处理复杂数据又能实现可解释非线性分类的方法。

研究方法: NCV框架结合了PVGs和概念编码，首先使用弱监督概念发现模型从原始输入中提取结构化概念编码，然后由证明者选择部分编码，最后由非线性预测器（验证者）基于这些编码进行决策。

研究结果: 实验表明，NCV在高维逻辑复杂数据集上优于CBM和基于像素的PVG分类器基线，同时有效减少了捷径行为。

研究结论: NCV是迈向高性能、可验证AI的重要一步，为复杂数据的可解释非线性分类提供了新思路。

中文摘要: 尽管证明者-验证者游戏（PVGs）为非线性分类模型的可验证性提供了有前景的路径，但其尚未应用于高维图像等复杂输入。相反，概念瓶颈模型（CBMs）能够将此类数据转化为可解释概念，但受限于低容量的线性预测器。本文提出了神经概念验证器（NCV），这是一个将PVGs与概念编码相结合的统一框架，用于高维场景下的可解释非线性分类。NCV通过利用近期弱监督概念发现模型从原始输入中提取结构化概念编码实现这一目标。证明者选择部分编码，而验证者（作为非线性预测器）仅基于这些编码进行决策。我们的评估表明，NCV在高维逻辑复杂数据集上优于CBM和基于像素的PVG分类器基线，并有助于减少捷径行为。总体而言，NCV是迈向高性能、可验证AI的重要一步。

</details>


### [229] [TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection](https://arxiv.org/abs/2507.07622)
**中文标题：TransformEEG：提升基于深度学习的EEG帕金森病检测模型泛化能力**

*Federico Del Pup,Riccardo Brun,Filippo Iotti,Edoardo Paccagnella,Mattia Pezzato,Sabrina Bertozzo,Andrea Zanola,Louis Fabrice Tshimanga,Henning Müller,Manfredo Atzori*

主要分类: cs.LG

摘要简述: TransformEEG是一种结合卷积和Transformer的混合模型，用于基于EEG数据的帕金森病检测，显著提升了模型的泛化能力，减少了结果偏差。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于EEG的深度学习模型在帕金森病检测中因受试者间的高变异性而泛化能力较差，亟需开发更适合EEG数据的新架构。

研究方法: 提出TransformEEG，采用深度卷积分词器生成通道特定特征，结合Transformer编码器实现更有效的特征混合，并通过嵌套交叉验证与其他模型对比。

研究结果: TransformEEG在平衡准确率中位数（78.45%）和四分位距（6.37%）上表现最佳，结合数据增强和阈值校正后准确率提升至80.10%。

研究结论: TransformEEG显著降低了变异性，提供了更一致和可靠的帕金森病检测结果，优于其他模型。

中文摘要: 脑电图（EEG）作为一种低成本、非侵入性的诊断工具，在帕金森病（PD）早期检测中日益重要。基于EEG的深度学习（DL）模型因其能够发现信号中的高度非线性模式而显示出潜力，但当前最先进的DL模型因受试者间的高变异性而泛化能力较差。本文提出TransformEEG，一种专为EEG数据设计的混合卷积-Transformer模型，用于帕金森病检测。与基于EEGNet结构的Transformer模型不同，TransformEEG采用深度卷积分词器生成由通道特定特征组成的标记，从而在Transformer编码器的自注意力层中实现更有效的特征混合。为评估该模型，我们整合了四个公共数据集（共290名受试者，140名PD患者和150名健康对照），并采用10外10内嵌套留N受试者交叉验证（N-LNSO）与其他七种成熟的EEG深度学习模型进行无偏比较。TransformEEG在所有N-LNSO分区中实现了最高的平衡准确率中位数（78.45%）和最低的四分位距（6.37%）。结合数据增强和阈值校正后，中位数准确率提升至80.10%，四分位距为5.74%。结论表明，TransformEEG提供了更一致且偏差更小的结果，与其他模型相比，显著降低了变异性并提高了EEG数据中PD检测的可靠性。

</details>


### [230] [OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting](https://arxiv.org/abs/2507.07754)
**中文标题：OPC：面向深度特征遗忘的单点收缩遗忘方法**

*Jaeheun Jung,Bosung Jung,Suhyun Bae,Donghun Lee*

主要分类: cs.LG

摘要简述: 本文提出了一种名为OPC的新型机器学习遗忘算法，通过单点收缩特征表示实现深度遗忘，有效抵御性能恢复和梯度反转攻击。


<details>
  <summary>详细信息</summary>
研究动机: 现有机器学习遗忘方法仅表面调整模型响应，内部表征仍保留被遗忘数据信息，存在安全隐患。本文旨在从根本上解决这一问题，提出深度遗忘的理论标准。

研究方法: 基于单点收缩特征表示的理论标准，提出高效近似算法，并构建通用遗忘算法OPC，实现深度特征遗忘。

研究结果: 实验表明，OPC在图像分类遗忘任务中不仅有效遗忘，还能显著抵御性能恢复和梯度反转攻击。

研究结论: OPC通过深度特征遗忘提升了机器学习遗忘方法的鲁棒性，强调了改进遗忘算法的重要性。

中文摘要: 机器学习遗忘旨在从训练模型中移除特定数据或类别的影响，以满足隐私、法律或伦理要求。现有遗忘方法往往仅表面遗忘：未遗忘模型通过调整模型响应假装遗忘，而其内部表征仍保留足够信息以恢复被遗忘数据或行为。我们通过训练无关的性能恢复攻击和基于梯度反转的数据重建攻击，实证确认了这种表面遗忘现象的普遍性。为从根本上解决这一漏洞，我们基于被遗忘数据特征表示的单点收缩定义了“深度遗忘”的理论标准，并提出了一种高效近似算法，用于构建新型通用遗忘算法：单点收缩（OPC）。图像分类遗忘基准测试的实证评估表明，OPC不仅实现了有效的遗忘性能，还对性能恢复攻击和梯度反转攻击表现出卓越的抵抗力。OPC独特的遗忘性能源于其理论基础的深度特征遗忘，并重申了提升机器学习遗忘方法鲁棒性的必要性。

</details>


### [231] [Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training](https://arxiv.org/abs/2507.07778)
**中文标题：同步任务行为：在测试时训练中对齐多任务**

*Wooseong Jeong,Jegyeong Cho,Youngho Yoon,Kuk-Jin Yoon*

主要分类: cs.LG

摘要简述: 本文提出了一种名为S4T的新方法，通过同步多任务行为来解决测试时训练（TTT）中任务行为不同步的问题，从而提升模型在多个任务上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 在现实应用中，神经网络需要泛化到未见过的目标域，而传统的测试时训练方法在处理多任务时，由于任务行为不同步，导致性能下降。本文旨在解决这一问题。

研究方法: 提出S4T方法，通过预测跨域任务关系来同步多任务行为，并将其与传统TTT协议结合，实现多任务的并发处理。

研究结果: 实验结果表明，S4T在多个基准测试中优于现有的TTT方法。

研究结论: S4T通过同步多任务行为，有效提升了模型在域偏移下的多任务表现，为测试时训练提供了新的解决方案。

中文摘要: 神经网络泛化到未见目标域是实际部署中的重大挑战。测试时训练（TTT）通过辅助自监督任务减少源域与目标域之间的分布偏移带来的域差距。然而，我们发现当模型需要在域偏移下执行多任务时，传统TTT方法会因任务行为不同步而表现不佳，即一个任务的最优适应步骤可能与其他任务的需求不一致。为解决这一问题，我们提出了一种名为“同步任务的测试时训练”（S4T）的新方法，能够同时处理多任务。S4T的核心思想是预测跨域任务关系是实现任务同步的关键。为验证方法，我们将S4T应用于传统多任务基准测试，并与传统TTT协议结合。实验结果表明，S4T在多个基准测试中优于现有TTT方法。

</details>


### [232] [Optimization Guarantees for Square-Root Natural-Gradient Variational Inference](https://arxiv.org/abs/2507.07853)
**中文标题：平方根自然梯度变分推断的优化保证**

*Navish Kumar,Thomas Möllenhoff,Mohammad Emtiyaz Khan,Aurelien Lucchi*

主要分类: cs.LG

摘要简述: 本文通过平方根参数化高斯协方差，为自然梯度变分高斯推断及其连续时间梯度流建立了新的收敛保证，展示了自然梯度方法在实践中的高效性。


<details>
  <summary>详细信息</summary>
研究动机: 自然梯度下降在变分推断中通常表现出快速收敛，但其理论收敛保证难以建立，尤其是在涉及凹对数似然和使用高斯近似的最简单情况下。本文旨在解决这一问题。

研究方法: 采用平方根参数化高斯协方差的方法，为自然梯度变分高斯推断及其连续时间梯度流建立收敛保证。

研究结果: 实验证明了自然梯度方法的有效性，并突出了其在使用欧几里得或Wasserstein几何的算法上的优势。

研究结论: 通过平方根参数化方法，本文成功建立了自然梯度变分高斯推断的收敛保证，为相关研究提供了理论支持。

中文摘要: 自然梯度下降在变分推断中通常表现出快速收敛，但其理论收敛保证难以建立，即使在涉及凹对数似然和使用高斯近似的最简单情况下也是如此。我们表明，通过使用高斯协方差的平方根参数化，可以绕过这一挑战。这种方法为自然梯度变分高斯推断及其连续时间梯度流建立了新的收敛保证。实验证明了自然梯度方法的有效性，并突出了其在使用欧几里得或Wasserstein几何的算法上的优势。

</details>


### [233] [UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs](https://arxiv.org/abs/2507.07885)
**中文标题：UnIT：面向MCU的高效MAC推理的可扩展非结构化推理时剪枝**

*Ashe Neth,Sawinder kaur,Mohammad Nur Hossain Khan,Subrata Biswas,Asif Salekin,Bashima Islam*

主要分类: cs.LG

摘要简述: 本文提出了一种名为UnIT的轻量级方法，用于在推理时动态跳过不必要的乘加操作，显著提升微控制器上的神经网络推理效率，同时保持准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有剪枝方法通常在训练或编译时应用，且依赖结构化稀疏性，未能充分利用无SIMD支持或并行计算的设备的细粒度效率。UnIT旨在解决这一问题，通过输入特定的激活模式动态跳过不必要的计算。

研究方法: UnIT是一种轻量级方法，将剪枝决策转化为轻量级比较，用阈值检查和近似除法替代乘法操作，并通过复用阈值计算和应用分层剪枝敏感性优化计算。

研究结果: 在MSP430微控制器上，UnIT实现了11.02%至82.03%的乘加操作减少，推理速度提升27.30%至84.19%，能耗降低27.33%至84.38%，同时保持0.48-7%的准确性。

研究结论: UnIT证明了非结构化推理时剪枝是一种可行且实用的解决方案，适用于在微控制器上高效部署深度神经网络，无需重新训练。

中文摘要: 现有剪枝方法通常在训练或编译时应用，且依赖结构化稀疏性。虽然适用于低功耗微控制器（MCU），但结构化剪枝未能充分利用无SIMD支持或并行计算的设备的细粒度效率。为解决这些限制，我们提出了UnIT（非结构化推理时剪枝），一种轻量级方法，通过输入特定的激活模式动态跳过不必要的乘加（MAC）操作。与结构化剪枝不同，UnIT支持非规则稀疏性，且无需重新训练或硬件定制。它将剪枝决策转化为轻量级比较，用阈值检查和近似除法替代乘法操作。UnIT进一步通过复用阈值计算和应用分层剪枝敏感性优化计算。我们提出了三种快速、硬件友好的除法近似方法，适用于常见嵌入式平台。在MSP430微控制器上的实验表明，UnIT实现了11.02%至82.03%的MAC减少，推理速度提升27.30%至84.19%，能耗降低27.33%至84.38%，同时保持0.48-7%的准确性。在领域偏移下，UnIT的准确性匹配或超过重新训练的模型，同时显著减少MAC操作。这些结果表明，非结构化推理时剪枝是一种可行且实用的解决方案，适用于在MCU上高效部署深度神经网络，无需重新训练。

</details>


### [234] [Agentic Retrieval of Topics and Insights from Earnings Calls](https://arxiv.org/abs/2507.07906)
**中文标题：基于代理的财报电话会议主题与洞察提取**

*Anant Gupta,Rajarshi Bhowmik,Geoffrey Gunow*

主要分类: cs.LG

摘要简述: 本文提出了一种基于LLM代理的方法，用于从季度财报电话会议中动态发现和提取新兴主题，并通过主题本体构建层次结构，揭示公司与行业趋势。


<details>
  <summary>详细信息</summary>
研究动机: 传统主题建模技术难以动态捕捉新兴主题及其关系，而财报电话会议是追踪公司战略重点的关键。因此，需要一种更灵活的方法来发现和分析新兴主题。

研究方法: 采用LLM代理从文档中提取主题，将其构建为层次化本体，并通过主题本体建立新旧主题之间的关系。

研究结果: 通过评估本体一致性、主题演化准确性及识别新兴金融趋势的能力，验证了该方法的有效性。

研究结论: LLM代理驱动的方法能够动态捕捉新兴主题，为公司级洞察和行业趋势分析提供有力工具。

中文摘要: 通过财报电话会议中的主题追踪公司战略重点是金融分析的关键任务。然而，随着行业的发展，传统主题建模技术难以动态捕捉新兴主题及其关系。本研究提出了一种基于LLM代理的方法，用于从季度财报电话会议中发现和提取新兴主题。我们利用LLM代理从文档中提取主题，将其构建为层次化本体，并通过主题本体建立新旧主题之间的关系。我们还展示了如何利用提取的主题推断公司级洞察和随时间演化的新兴趋势。通过评估本体一致性、主题演化准确性及识别新兴金融趋势的能力，验证了该方法的有效性。

</details>


### [235] [ST-GRIT: Spatio-Temporal Graph Transformer For Internal Ice Layer Thickness Prediction](https://arxiv.org/abs/2507.07389)
**中文标题：ST-GRIT：用于冰层内部厚度预测的时空图变换器**

*Zesheng Liu,Maryam Rahnemoonfar*

主要分类: cs.LG

摘要简述: ST-GRIT是一种时空图变换器，用于预测冰层内部厚度，通过雷达图像捕捉冰层的时空关系，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 冰层内部厚度和变化的监测对气候模型至关重要，雷达图像提供了冰层内部结构的详细信息，但现有方法难以有效处理其时空关系。

研究方法: ST-GRIT采用归纳几何图学习框架提取局部空间特征，并分别使用时序和空间注意力块建模长程依赖关系。

研究结果: 在格陵兰冰盖雷达数据上的实验表明，ST-GRIT在均方根误差上优于现有方法和其他图神经网络。

研究结论: ST-GRIT通过自注意力机制有效处理噪声、避免过平滑并捕捉长程依赖，时空注意力块的分离设计提升了模型性能。

中文摘要: 理解雷达图像中冰层内部厚度及其变异性对监测积雪、评估冰动态以及减少气候模型的不确定性至关重要。能够穿透冰层的雷达传感器提供了这些内部层的详细雷达图像。本文提出ST-GRIT，一种用于冰层厚度的时空图变换器，旨在处理这些雷达图像并捕捉浅层和深层冰层之间的时空关系。ST-GRIT利用归纳几何图学习框架提取局部空间特征作为特征嵌入，并分别使用一系列时序和空间注意力块来有效建模这两个维度的长程依赖关系。在格陵兰冰盖雷达数据上的实验评估表明，ST-GRIT通过实现更低的均方根误差，始终优于当前最先进的方法和其他基线图神经网络。这些结果凸显了图自注意力机制相对于纯图神经网络的优势，包括处理噪声、避免过平滑以及捕捉长程依赖的能力。此外，分离的时空注意力块设计使得空间关系和时序模式能够独立且稳健地学习，提供了一种更全面且有效的方法。

</details>


### [236] [Low Resource Reconstruction Attacks Through Benign Prompts](https://arxiv.org/abs/2507.07947)
**中文标题：通过无害提示词的低资源重建攻击**

*Sol Yarkoni,Roi Livni*

主要分类: cs.LG

摘要简述: 本文提出一种低资源重建攻击方法，通过看似无害的提示词从生成模型中重建训练数据中的图像，揭示潜在隐私风险。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成模型（如扩散模型）的发展，隐私、版权和数据管理风险日益凸显。现有重建攻击方法通常依赖高资源和精心设计的提示词，本文旨在开发一种低资源、无需访问训练集的方法，揭示更广泛的重建风险。

研究方法: 基于领域知识，利用电子商务平台抓取的数据中模板化布局与提示词的关联性，设计低资源攻击方法，通过看似无害的提示词（如“蓝色Unisex T-Shirt”）重建真实图像。

研究结果: 实验表明，该方法无需高资源或训练集访问权限，即可通过普通提示词重建训练数据中的图像（如人脸），证明重建风险可能被普通用户无意触发。

研究结论: 研究揭示了生成模型中潜在的低门槛重建风险，呼吁对数据来源和模型设计进行更严格的隐私保护措施。

中文摘要: 近年来，扩散模型等生成模型的进展引发了隐私、版权侵权和数据管理方面的多重风险。为了更好地理解和控制这些风险，研究人员开发了多种从训练集中重建图像或部分图像的技术和攻击方法。尽管这些技术已证明训练数据可被重建，但它们通常依赖高资源、对训练集的访问权限以及精心设计的提示词。本文提出一种新型攻击方法，仅需低资源、几乎无需访问实际训练集，即可通过看似无害的提示词实现潜在风险的图像重建。这表明图像甚至可能被无意识的普通用户无意中重建。例如，我们发现针对某现有模型，提示词“蓝色Unisex T-Shirt”可生成真实人脸的图像。我们的方法基于先前工作的直觉，利用领域知识，揭示了因使用电子商务平台抓取数据而存在的基本漏洞，其中模板化布局和图像与模式化提示词相关联。

</details>


### [237] [Balancing the Past and Present: A Coordinated Replay Framework for Federated Class-Incremental Learning](https://arxiv.org/abs/2507.07712)
**中文标题：平衡过去与现在：联邦类增量学习的协调重放框架**

*Zhuang Qi,Lei Meng,Han Yu*

主要分类: cs.LG

摘要简述: 本文提出了一种联邦类增量学习（FCIL）的协调重放框架（FedCBDR），通过全局协调机制和任务感知温度缩放模块，解决了类不平衡问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 联邦类增量学习（FCIL）在处理多客户端持续增加的任务时，面临类不平衡问题，包括重放缓冲区内的全局意识不足以及新旧类之间的不平衡。这些问题限制了数据重放方法的性能。

研究方法: FedCBDR包含两个关键模块：1）全局视角数据重放模块，通过隐私保护方式重构先前任务的全局表示，并采用类感知和重要性敏感的采样策略实现平衡重放；2）任务感知温度缩放模块，根据任务动态自适应调整类和实例级别的logits温度，减少对多数类的过度自信，增强对少数类的敏感性。

研究结果: 实验结果表明，FedCBDR在异构数据分布下实现了平衡的类采样，并在早期和近期任务不平衡的情况下提升了泛化能力，Top-1准确率比六种先进方法提高了2%-15%。

研究结论: FedCBDR通过全局协调和任务感知温度缩放，有效解决了FCIL中的类不平衡问题，显著提升了模型性能，为联邦类增量学习提供了新的解决方案。

中文摘要: 联邦类增量学习（FCIL）旨在协作处理多个客户端持续增加的输入任务。在多种方法中，数据重放成为一种有前景的解决方案，通过重新引入先前任务的代表性样本来缓解遗忘问题。然而，其性能通常受到类不平衡的限制，包括重放缓冲区因全局意识不足导致的内部不平衡，以及重放类与新到类之间的不平衡。为解决这一问题，我们提出了一种面向FCIL的类平衡数据重放方法（FedCBDR），该方法采用全局协调机制进行类级内存构建，并重新加权学习目标以缓解上述不平衡。具体而言，FedCBDR包含两个关键组件：1）全局视角数据重放模块以隐私保护方式重构先前任务的全局表示，随后通过类感知和重要性敏感的采样策略实现平衡重放；2）任务感知温度缩放模块根据任务动态自适应调整类和实例级别的logits温度，减少模型对多数类的过度自信，同时增强对少数类的敏感性。实验结果验证了FedCBDR在异构数据分布下实现了平衡的类采样，并在早期和近期任务不平衡的情况下提升了泛化能力，Top-1准确率比六种先进方法提高了2%-15%。

</details>


### [238] [Reinforcement Learning with Action Chunking](https://arxiv.org/abs/2507.07969)
**中文标题：基于动作分块的强化学习**

*Qiyang Li,Zhiyuan Zhou,Sergey Levine*

主要分类: cs.LG

摘要简述: 本文提出Q-chunking方法，通过动作分块技术提升强化学习在长时程稀疏奖励任务中的表现，结合离线与在线学习，显著提高样本效率和探索能力。


<details>
  <summary>详细信息</summary>
研究动机: 在离线到在线强化学习设置中，如何有效利用离线数据提升在线学习的样本效率和探索能力是核心挑战。本文旨在通过动作分块技术解决这一问题。

研究方法: Q-chunking将动作分块技术应用于基于时间差分的强化学习方法中，直接在分块动作空间中运行强化学习，利用离线数据的时序一致性行为提升在线探索，并通过无偏n步备份实现更稳定的学习。

研究结果: 实验表明，Q-chunking在长时程稀疏奖励任务中表现出色，离线性能和在线样本效率均优于现有方法。

研究结论: Q-chunking通过动作分块技术有效解决了离线到在线强化学习中的探索和样本效率问题，为长时程任务提供了实用解决方案。

中文摘要: 我们提出了Q-chunking，一种简单而有效的方法，用于改进强化学习（RL）在长时程稀疏奖励任务中的表现。该方法专为离线到在线RL设置设计，旨在利用离线先验数据集最大化在线学习的样本效率。在此设置中，有效探索和样本高效学习仍是核心挑战，因为如何利用离线数据获取良好的探索策略尚不明确。我们的关键发现是，动作分块技术（一种在模仿学习中流行的技术，用于预测未来动作序列而非单步动作）可以应用于基于时间差分（TD）的RL方法，以缓解探索挑战。Q-chunking通过在分块动作空间中直接运行RL，使智能体能够（1）利用离线数据中的时序一致性行为进行更有效的在线探索；（2）使用无偏n步备份实现更稳定和高效的TD学习。实验结果表明，Q-chunking在长时程稀疏奖励操作任务中表现出优异的离线性能和在线样本效率，优于现有最佳离线到在线方法。

</details>


### [239] [TRIX- Trading Adversarial Fairness via Mixed Adversarial Training](https://arxiv.org/abs/2507.07768)
**中文标题：TRIX：通过混合对抗训练实现对抗公平性**

*Tejaswini Medi,Steffen Jung,Margret Keuper*

主要分类: cs.LG

摘要简述: 本文提出TRIX框架，通过混合对抗训练解决对抗训练中的类别不公平问题，自适应地为强类别分配弱对抗样本，为弱类别分配强对抗样本，从而提升整体鲁棒性和公平性。


<details>
  <summary>详细信息</summary>
研究动机: 现有对抗训练方法对所有类别采用统一训练目标，忽略了类别间脆弱性差异，导致强类别更鲁棒而弱类别更易受攻击。TRIX旨在通过自适应对抗样本分配解决这一不公平问题。

研究方法: TRIX框架根据类别特征差异，为强类别分配弱目标对抗样本以促进特征多样性，为弱类别分配强无目标对抗样本以增强其鲁棒性，并结合每类损失权重和扰动强度调整优化训练。

研究结果: 在标准图像分类基准测试中，TRIX显著提升了最差类别在干净和对抗数据上的准确率，减少了类别间鲁棒性差异，同时保持了整体准确率。

研究结论: TRIX通过混合对抗训练和自适应对抗样本分配，为对抗防御提供了一种公平且有效的解决方案。

中文摘要: 对抗训练（AT）是一种广泛采用的对抗样本防御方法。然而，现有方法通常对所有类别采用统一的训练目标，忽略了类别间脆弱性的差异，导致对抗不公平性：特征区分度高的类别（强类别）往往变得更鲁棒，而特征重叠或共享的类别（弱类别）则更容易受到对抗攻击。我们发现，强类别在训练中不需要强对抗样本，因为它们的非鲁棒特征会迅速被抑制；而弱类别则能从更强的对抗样本中受益，从而有效减少其脆弱性。基于此，我们提出了TRIX，一种特征感知的对抗训练框架，自适应地为强类别分配较弱的目标对抗样本（通过均匀采样目标促进特征多样性），为弱类别分配更强的无目标对抗样本（增强其针对性鲁棒性）。TRIX进一步结合了每类损失权重和扰动强度调整（基于先前工作），以在优化过程中强调弱类别。在标准图像分类基准上的全面实验（包括对PGD和AutoAttack等强攻击的评估）表明，TRIX显著提升了最差类别在干净和对抗数据上的准确率，减少了类别间鲁棒性差异，同时保持了整体准确率。我们的结果凸显了TRIX作为一种公平且有效的对抗防御方法的实用价值。

</details>


### [240] [EXPO: Stable Reinforcement Learning with Expressive Policies](https://arxiv.org/abs/2507.07986)
**中文标题：EXPO：基于表达性策略的稳定强化学习**

*Perry Dong,Qiyang Li,Dorsa Sadigh,Chelsea Finn*

主要分类: cs.LG

摘要简述: 本文提出EXPO算法，通过结合稳定的模仿学习目标和轻量级高斯编辑策略，解决了表达性策略在在线强化学习中的稳定性问题，显著提升了样本效率。


<details>
  <summary>详细信息</summary>
研究动机: 在在线强化学习中，训练表达性策略（如扩散和流匹配策略）时，由于参数化链较长，梯度传播不稳定，导致值最大化困难。本文旨在解决这一问题。

研究方法: 提出Expressive Policy Optimization (EXPO)算法，使用两种策略：一个稳定的模仿学习目标训练的表达性基础策略，和一个轻量级高斯编辑策略。后者通过编辑基础策略的动作来提升值分布，从而优化动作选择。

研究结果: 实验表明，EXPO在样本效率上比现有方法提升了2-3倍，适用于离线数据微调和在线训练场景。

研究结论: EXPO通过结合稳定模仿学习和轻量级编辑策略，有效解决了表达性策略的稳定性问题，显著提升了在线强化学习的性能。

中文摘要: 我们研究了在给定离线数据集的情况下，通过在线强化学习（RL）训练和微调表达性策略的问题。在线RL中训练表达性策略类面临稳定值最大化的独特挑战。与在线RL中常用的简单高斯策略不同，扩散和流匹配等表达性策略通过长去噪链参数化，这阻碍了从动作到策略参数的稳定梯度传播。我们的关键发现是，可以通过避免直接对表达性策略进行值优化，转而构建一个即时RL策略来最大化Q值，从而解决稳定值最大化问题。我们提出了Expressive Policy Optimization (EXPO)，一种高效的在线RL算法，利用即时策略通过两种参数化策略最大化值：一个通过稳定模仿学习目标训练的表达性基础策略，和一个轻量级高斯编辑策略，后者将基础策略的动作编辑为更高值的分布。即时策略通过学习的编辑策略优化基础策略的动作，并从基础和编辑动作中选择值最大化的动作用于采样和时间差分（TD）备份。我们的方法在给定离线数据微调预训练策略和利用离线数据进行在线训练的两种场景中，平均样本效率比现有方法提升了2-3倍。

</details>
