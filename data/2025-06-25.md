<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.CV](#cs.CV) [Total: 87]
- [cs.AI](#cs.AI) [Total: 36]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.ET](#cs.ET) [Total: 2]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.GR](#cs.GR) [Total: 3]
- [math.ST](#math.ST) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [eess.IV](#eess.IV) [Total: 16]
- [cs.CY](#cs.CY) [Total: 5]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.IR](#cs.IR) [Total: 3]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 27]
- [cs.RO](#cs.RO) [Total: 6]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]
- [cs.DC](#cs.DC) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 3]
- [cs.SE](#cs.SE) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MemeMind: A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection](https://arxiv.org/abs/2506.18919)
**中文标题：MemeMind：一个基于思维链推理的大规模多模态有害表情包检测数据集**

*Hexiang Gu,Qifan Yu,Saihui Hou,Zhiqin Fang,Huijia Wu,Zhaofeng He*

主要分类: cs.CL

摘要简述: 本文介绍了MemeMind数据集和MemeGuard框架，用于有害表情包检测。MemeMind提供了大规模、多样化、双语支持及详细推理标注的数据，而MemeGuard通过多模态信息与推理建模显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体中有害表情包的传播日益严重，但其隐含语义和多模态交互复杂性使得自动检测面临挑战。现有数据集缺乏系统性、大规模和可解释性，阻碍了该领域的进一步发展。

研究方法: 提出MemeMind数据集，具备科学严谨性、大规模、多样性和双语支持，并包含详细的推理标注。同时，开发了MemeGuard框架，整合多模态信息与推理过程建模。

研究结果: 在MemeMind数据集上的实验表明，MemeGuard在有害表情包检测任务中显著优于现有最先进方法。

研究结论: MemeMind填补了当前数据集的空白，MemeGuard为有害表情包检测提供了高效解决方案，推动了该领域的发展。

中文摘要: 社交媒体的快速发展加剧了有害内容的传播。有害表情包结合了图像和文本，由于其隐含语义和复杂的多模态交互，为自动检测带来了巨大挑战。尽管现有研究在检测准确性和可解释性方面取得了进展，但缺乏系统性、大规模、多样化且高度可解释的数据集仍阻碍了该领域的进一步发展。为填补这一空白，我们提出了MemeMind数据集，其具备科学严谨性、大规模、多样性、双语支持（中文和英文）以及详细的思维链（CoT）标注。MemeMind通过全面的标签和显式推理痕迹填补了当前数据集的关键空白，为提升有害表情包检测提供了坚实基础。此外，我们提出了一种创新的检测框架MemeGuard，有效整合多模态信息与推理过程建模，显著提升了模型理解和识别有害表情包的能力。在MemeMind数据集上进行的大量实验表明，MemeGuard在有害表情包检测任务中始终优于现有最先进方法。

</details>


### [2] [Mirage of Mastery: Memorization Tricks LLMs into Artificially Inflated Self-Knowledge](https://arxiv.org/abs/2506.18998)
**中文标题：掌握幻象：记忆使LLMs陷入虚假自我认知膨胀**

*Sahil Kale,Vijaykant Nadadur*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLMs）将记忆误认为推理能力，导致其自我认知虚高，尤其在STEM领域表现显著，显示出45%以上的可行性评估不一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究将记忆与自我认知缺陷视为独立问题，忽视了它们之间的关联如何降低LLMs回答的可信度。本文旨在揭示LLMs是否真正学习推理模式，还是仅通过记忆假装具备能力。

研究方法: 采用新框架分析LLMs是否从训练数据中学习推理模式，或仅记忆类似复杂度的STEM问题解决方案，并通过逻辑一致的任务扰动验证其自我认知。

研究结果: LLMs因记忆解决方案而高估自身推理能力，在科学和医学领域尤为明显，可行性评估不一致性超过45%。

研究结论: 当前LLMs架构和训练模式存在缺陷，需开发技术确保模型对其知识的认知平衡一致，以提高AI的可解释性和可信度。

中文摘要: 当人工智能将记忆误认为智能时，会产生危险的推理幻象。现有研究将LLMs的记忆与自我认知缺陷视为独立问题，未认识到其交织关系会降低LLMs回答的可信度。本研究采用新框架，验证LLMs是否真正从训练数据中学习推理模式，或仅通过记忆假装具备类似复杂度问题的能力（聚焦STEM领域）。分析显示显著泛化问题：LLMs因记忆解决方案而高估自身推理能力，在面对逻辑一致的任务扰动时，可行性评估不一致性超过45%。此效应在科学和医学领域最明显，这些领域标准化术语和问题最多，进一步验证了方法。LLMs自我认知的显著波动揭示了当前架构和训练模式的缺陷，强调需开发技术确保模型对其知识的认知平衡一致，以实现最大AI可解释性和可信度。代码与结果公开于https://github.com/knowledge-verse-ai/LLM-Memorization_SK_Eval-。

</details>


### [3] [Broken Tokens? Your Language Model can Secretly Handle Non-Canonical Tokenizations](https://arxiv.org/abs/2506.19004)
**中文标题：分词断裂？你的语言模型能秘密处理非标准分词**

*Brian Siyuan Zheng,Alisa Liu,Orevaoghene Ahia,Jonathan Hayase,Yejin Choi,Noah A. Smith*

主要分类: cs.CL

摘要简述: 研究发现，语言模型对非标准分词方式具有惊人的鲁棒性，即使训练中未见过，仍能保留高达93.4%的性能。某些非标准分词甚至能提升特定任务表现，如字符级分词提升字符串操作和代码理解任务14%。


<details>
  <summary>详细信息</summary>
研究动机: 现代分词器通常将文本映射为单一“标准”分词序列，但同一字符串可通过分词器词汇表编码为多种非标准分词。本文探讨语言模型对未见过的非标准分词的鲁棒性，并探索其潜在应用。

研究方法: 研究通过20个基准测试评估指令调优模型对随机采样分词和字符级分词的性能保留情况，并分析不同分词方式对任务表现的影响。同时，探究鲁棒性来源，比较基础模型和调优模型的行为差异。

研究结果: 指令调优模型对随机分词保留93.4%性能，字符级分词保留90.8%。字符级分词提升字符串操作和代码理解任务14%，右对齐数字分组提升大数算术33%。鲁棒性源于指令调优阶段，调优模型能生成流畅响应，而基础模型输出无意义内容。

研究结论: 语言模型对分词器的依赖低于预期，推理时干预分词方式可提升性能。非标准分词在某些任务中表现更优，为模型优化提供新思路。

中文摘要: 现代分词器采用确定性算法将文本映射为单一“标准”分词序列，但同一字符串可通过分词器词汇表编码为多种非标准分词。本文研究语言模型对训练中完全未见的非标准分词的鲁棒性。令人惊讶的是，在20个基准测试中，指令调优模型对随机采样的分词保留高达93.4%的原始性能，字符级分词保留90.8%。整体更强的模型通常更鲁棒，且鲁棒性随分词偏离标准形式而降低。基于这些结果，我们进一步发现非标准分词在某些场景下能提升性能：字符级分词使字符串操作和代码理解任务提升14%，右对齐数字分组使大数算术提升33%。最后，我们探究鲁棒性来源，发现其源于指令调优阶段。基础模型和后训练模型均能理解非标准分词的语义（视其为拼写错误），但基础模型试图模仿想象中的错误并输出无意义内容，而后训练模型致力于生成流畅响应。总体而言，我们的发现表明模型对分词器的依赖低于预期，并展示了推理时干预分词以提升性能的潜力。

</details>


### [4] [Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective](https://arxiv.org/abs/2506.19028)
**中文标题：超越词符：从语义和统计视角量化大语言模型的公平性**

*Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy*

主要分类: cs.CL

摘要简述: 本文提出FiSCo框架，通过语义和统计方法评估大语言模型（LLM）的群体公平性，超越传统基于词符的分析，检测长文本中的细微偏见。


<details>
  <summary>详细信息</summary>
研究动机: 现有评估方法忽视长文本偏见和LLM输出的内在变异性，导致公平性评估不全面。本文旨在解决这一问题。

研究方法: 提出FiSCo框架，将模型输出分解为语义独立的声明，利用蕴含检查和统计假设检验比较群体间和群体内相似性，检测细微偏见。

研究结果: 实验表明，FiSCo能更可靠地识别复杂偏见，减少LLM随机变异的影响，优于其他评估指标。

研究结论: FiSCo为LLM公平性评估提供了一种更精细、更可靠的统计框架，适用于性别、种族和年龄等多维度分析。

中文摘要: 大语言模型（LLM）生成的响应常带有固有偏见，影响其在实际应用中的可靠性。现有评估方法往往忽略长文本偏见和LLM输出的内在变异性。为解决这些问题，我们提出FiSCo（细粒度语义计算），一种新颖的统计框架，通过检测不同人口群体长文本响应的细微语义差异来评估LLM的群体公平性。与以往关注情感或词符级比较的研究不同，FiSCo在声明级别操作，利用蕴含检查评估响应间意义的一致性。我们将模型输出分解为语义独立的声明，并应用统计假设检验比较群体间和群体内相似性，从而稳健检测细微偏见。我们形式化了一种新的群体反事实公平定义，并在性别、种族和年龄的合成及人工标注数据集上验证了FiSCo。实验表明，FiSCo能更可靠地识别复杂偏见，同时减少LLM随机变异的影响，优于多种评估指标。

</details>


### [5] [Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models](https://arxiv.org/abs/2506.19037)
**中文标题：速度规划——掩码扩散语言模型的扩张调度策略**

*Omer Luxembourg,Haim Permuter,Eliya Nachmani*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Dilated-scheduled Unmasking Strategy (DUS)的无训练规划方法，用于提升掩码扩散语言模型（MDLM）的推理速度。通过将序列位置划分为非相邻的扩张组，DUS实现了并行解掩码，显著减少了推理时间，并在数学和代码生成任务中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的掩码扩散语言模型（MDLM）在非自回归文本生成中表现优异，但其推理速度受限于传统的自回归模型。现有的解掩码启发式方法无法处理并行解掩码时的依赖关系，限制了模型的效率。本文旨在提出一种无需额外训练的规划方法，以提升推理速度。

研究方法: 本文提出Dilated-scheduled Unmasking Strategy (DUS)，一种基于扩张分组的并行解掩码策略。DUS将序列位置划分为非相邻的扩张组，每组独立解掩码，从而减少对去噪器的调用次数（从O(B)降至O(log B)）。该方法无需额外训练，仅依赖一阶马尔可夫假设。

研究结果: 在数学（GSM8K）和代码生成（Humaneval, MBPP）任务中，DUS显著提升了推理速度，同时保持了生成质量，优于现有的并行置信度规划方法。

研究结论: DUS为掩码扩散语言模型提供了一种轻量级、高效的推理方法，无需修改模型即可显著提升速度，展现了MDLM在非顺序生成任务中的潜力。

中文摘要: 掩码扩散语言模型（MDLM）在非自回归文本生成中表现出色，但现有采样器通过去噪器置信度或熵分数选择解掩码的标记，作为隐式规划器。这种启发式方法在并行解掩码时表现不佳——它们忽略了标记间的成对交互，无法处理多位置解掩码时的依赖关系，导致推理时间与传统自回归（AR）模型相当。我们提出了扩张调度解掩码策略（DUS），一种仅用于推理、无需规划模型的无需额外训练的方法。DUS利用一阶马尔可夫假设将序列位置划分为基于扩张的非相邻标记组，实现独立的并行解掩码步骤，同时尊重局部上下文以最小化每步的联合熵。与仍需每块调用去噪器的半自回归块方法（如LLADA和Dream）不同，DUS将对去噪器的调用次数减少到每生成块的O(log B)，显著优于最先进扩散模型的O(B)运行时间（B为半自回归推理过程中的块大小）。在数学（GSM8K）和代码补全（Humaneval, MBPP）基准测试中（这些领域适合非顺序生成），DUS在不修改底层去噪器的情况下，优于基于并行置信度的规划方法。DUS提供了一种轻量级、预算感知的高效高质量文本生成方法，为释放MDLM的真正潜力铺平了道路。

</details>


### [6] [NLPnorth @ TalentCLEF 2025: Comparing Discriminative, Contrastive, and Prompt-Based Methods for Job Title and Skill Matching](https://arxiv.org/abs/2506.19058)
**中文标题：NLPnorth @ TalentCLEF 2025：比较判别式、对比式和基于提示的方法在职位与技能匹配中的应用**

*Mike Zhang,Rob van der Goot*

主要分类: cs.CL

摘要简述: 本文介绍了NLPnorth团队在TalentCLEF 2025中的参赛成果，比较了分类、对比和提示方法在职位匹配和技能预测任务中的表现，发现提示方法在任务A中表现最佳，分类方法在任务B中表现较好。


<details>
  <summary>详细信息</summary>
研究动机: 职位匹配和技能预测在计算就业市场领域具有重要意义，例如自动候选人匹配、职业路径预测和就业市场分析。本文旨在比较不同方法在这些任务中的表现。

研究方法: 团队使用了三种方法：基于分类的微调、基于对比的微调和提示方法，并在多语言职位匹配和基于职位的技能预测任务中进行了测试。此外，还利用了ESCO提供的额外数据。

研究结果: 在任务A中，提示方法表现最佳，测试数据的平均精度（MAP）为0.492；在任务B中，分类方法的MAP为0.290。团队在任务A中排名第5/20，任务B中排名第3/14。

研究结论: 多语言大模型在两项任务中表现最佳，提示方法在职位匹配任务中效果显著，而分类方法在技能预测任务中更优。

中文摘要: 职位匹配是计算就业市场领域的一项重要任务，能够提升自动候选人匹配、职业路径预测和就业市场分析等应用的性能。此外，将职位与技能对齐可视为该任务的扩展，对相同的下游任务具有类似的重要性。本报告概述了NLPnorth团队在TalentCLEF 2025中的参赛内容，包括多语言职位匹配和基于职位的技能预测两项任务。针对这两项任务，我们比较了基于分类的微调、基于对比的微调和提示方法。结果显示，在任务A中，提示方法表现最佳，测试数据的平均精度（MAP）为0.492（英语、西班牙语和德语的平均值）；在任务B中，基于分类的微调方法的MAP为0.290。我们还利用ESCO提供的额外数据，提取了每种职位和技能的语言特定标题及描述。总体而言，我们发现最大的多语言模型在两项任务中表现最佳。根据初步结果且仅统计唯一团队，任务A的排名为第5/20，任务B为第3/14。

</details>


### [7] [MFTCXplain: A Multilingual Benchmark Dataset for Evaluating the Moral Reasoning of LLMs through Hate Speech Multi-hop Explanation](https://arxiv.org/abs/2506.19073)
**中文标题：MFTCXplain：通过仇恨言论多跳解释评估大语言模型道德推理的多语言基准数据集**

*Jackson Trager,Francielle Vargas,Diego Alves,Matteo Guida,Mikel K. Ngueajio,Ameeta Agrawal,Flor Plaza-del-Arco,Yalda Daryanai,Farzan Karimi-Malekabadi*

主要分类: cs.CL

摘要简述: 本文介绍了MFTCXplain数据集，用于评估大语言模型（LLMs）在仇恨言论多跳解释中的道德推理能力，发现LLMs在道德情感预测和跨语言理性对齐方面表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估大语言模型道德推理能力的基准存在两大不足：缺乏道德分类的注释（影响透明度和可解释性）以及主要关注英语（限制了跨文化道德推理的评估）。本文旨在解决这些问题。

研究方法: 提出MFTCXplain数据集，包含葡萄牙语、意大利语、波斯语和英语的3000条推文，标注了仇恨言论标签、道德类别和文本片段级理性。基于道德基础理论（MFT）进行多跳解释评估。

研究结果: LLMs在仇恨言论检测上表现良好（F1最高0.836），但在道德情感预测上表现较弱（F1<0.35），且在少数语言中的理性对齐有限。

研究结论: 当前LLMs在理解和反映人类道德推理方面能力有限，尤其是在跨语言和道德情感预测任务中。

中文摘要: 随着大语言模型（LLMs）在社会敏感任务中的应用日益广泛，确保其道德推理能力成为一个重要问题。然而，当前的评估基准存在两大不足：缺乏道德分类的注释（限制了透明度和可解释性）以及主要关注英语（限制了跨文化道德推理的评估）。本文提出MFTCXplain，一个基于道德基础理论（MFT）的多语言基准数据集，用于通过仇恨言论多跳解释评估LLMs的道德推理能力。该数据集包含葡萄牙语、意大利语、波斯语和英语的3000条推文，标注了二元仇恨言论标签、道德类别和文本片段级理性。实验结果表明，LLMs在道德推理任务中的输出与人类注释存在偏差。尽管LLMs在仇恨言论检测上表现良好（F1最高0.836），但其道德情感预测能力较弱（F1<0.35）。此外，理性对齐在少数语言中表现有限。这些发现表明，当前LLMs在理解和反映人类道德推理方面的能力仍有不足。

</details>


### [8] [Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting](https://arxiv.org/abs/2506.19089)
**中文标题：语言模型可能不理解你：通过故事提示评估心智理论**

*Nathaniel Getachew,Abulhair Saparov*

主要分类: cs.CL

摘要简述: 本文介绍了$	exttt{StorySim}$框架，用于评估大型语言模型（LLMs）的心智理论（ToM）和世界建模（WM）能力。实验发现，大多数模型在WM任务上表现优于ToM任务，且对人类推理优于无生命物体。


<details>
  <summary>详细信息</summary>
研究动机: 现有评估方法可能因预训练数据污染而受限，因此需要一种可控且可编程的框架，以生成新颖的故事提示，精确操纵角色视角和事件，从而更准确地评估LLMs的ToM和WM能力。

研究方法: 作者提出$	exttt{StorySim}$框架，通过高度可控的$	exttt{Storyboard}$生成合成故事，设计了一阶和二阶ToM任务及WM任务，以测试模型对心理状态的追踪和建模能力。

研究结果: 实验表明，多数LLMs在WM任务上表现优于ToM任务，且对人类推理更准确。此外，模型表现出启发式行为，如近因偏差和过度依赖早期事件。

研究结论: $	exttt{StorySim}$为评估LLMs的ToM和WM能力提供了有效工具，揭示了模型在心理状态推理上的局限性。

中文摘要: 我们介绍了$	exttt{StorySim}$，一个可编程框架，用于通过合成生成的故事评估大型语言模型（LLMs）的心智理论（ToM）和世界建模（WM）能力。与以往可能受预训练数据污染的基准不同，$	exttt{StorySim}$通过高度可控的$	exttt{Storyboard}$生成新颖且组合性的故事提示，能够精确操纵角色视角和事件。我们利用该框架设计了一阶和二阶ToM任务及WM任务，以控制对心理状态的追踪和建模能力。实验结果表明，大多数模型在WM任务上表现优于ToM任务，且对人类推理优于无生命物体。此外，我们的框架还揭示了启发式行为，如近因偏差和过度依赖早期事件。所有用于生成数据和评估的代码均已公开。

</details>


### [9] [Human-Aligned Faithfulness in Toxicity Explanations of LLMs](https://arxiv.org/abs/2506.19113)
**中文标题：大型语言模型毒性解释中的人类对齐忠实性**

*Ramaravind K. Mothilal,Joanna Roy,Syed Ishtiaque Ahmed,Shion Guha*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“人类对齐忠实性”（HAF）的新标准，用于评估大型语言模型（LLM）在毒性解释中的表现，并通过六种无人工参与的指标量化其与人类理性解释的偏差。实验表明，LLM在简单提示下能生成合理的解释，但在复杂关系推理中表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 当前关于毒性和LLM的研究主要集中在检测任务上，而缺乏对其解释能力的评估。本文旨在填补这一空白，通过评估LLM的毒性解释能力，提升其在下游任务中的可信度。

研究方法: 本文提出了一种多维度标准HAF，通过六种基于不确定性量化的指标，全面评估LLM的毒性解释是否与人类理性解释对齐。实验在多个LLM模型和毒性数据集上进行。

研究结果: 实验结果显示，LLM在简单提示下能生成看似合理的毒性解释，但在涉及复杂关系推理时，其解释往往不一致或无意义。

研究结论: 本文提出的HAF标准为评估LLM的毒性解释能力提供了新方法，揭示了其在复杂推理中的局限性，为未来研究提供了方向。

中文摘要: 自然语言处理中关于毒性和大型语言模型（LLM）的讨论主要集中在检测任务上。本研究将重点转向评估LLM对毒性的推理能力——从其解释中判断立场——以增强其在下游任务中的可信度。尽管关于可解释性的研究很多，但由于现有方法过度依赖输入文本扰动等问题，难以直接用于评估自由形式的毒性解释。为此，我们提出了一种基于理论的多维度标准“人类对齐忠实性”（HAF），用于衡量LLM的自由形式毒性解释在理想条件下与人类理性解释的对齐程度。我们开发了六种基于不确定性量化的指标，全面评估LLM毒性解释的HAF，无需人工参与，并揭示其解释的“非理想”程度。我们在三个Llama模型（最大70B参数）和一个8B参数的Ministral模型上进行了多项实验，覆盖五个不同的毒性数据集。结果显示，尽管LLM能对简单提示生成看似合理的解释，但在涉及完整原因集、单个原因及其毒性立场之间复杂关系的推理时，其解释往往不一致或无意义。我们的代码和LLM生成的解释已开源：https://github.com/uofthcdslab/HAF。

</details>


### [10] [Enhanced Hybrid Transducer and Attention Encoder Decoder with Text Data](https://arxiv.org/abs/2506.19159)
**中文标题：基于文本数据增强的混合转换器与注意力编码解码器**

*Yun Tang,Eesung Kim,Vijendra Raj Apsingekar*

主要分类: cs.CL

摘要简述: 本文提出了一种联合语音和文本优化的混合转换器与注意力编码解码器（TAED）方法，通过整合大量文本语料提升ASR准确性。实验表明，该方法在Librispeech数据集上降低了5.8%~12.8%的词错误率（WER），并在金融和命名实体领域的外域数据集上分别实现了15.3%和17.8%的WER降低。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决语音识别（ASR）任务中数据稀缺和领域不匹配的问题，本文提出了一种联合语音和文本优化的方法，旨在通过整合文本语料库提升模型性能，同时支持基于文本的领域适应。

研究方法: 本文提出了一种联合TAED（J-TAED）模型，该模型在训练时同时使用语音和文本输入，但在推理时仅需语音输入。通过统一不同模态的内部表示，模型能够有效整合语音和语言信息，并支持基于文本的领域适应。

研究结果: 实验结果显示，J-TAED在Librispeech数据集上降低了5.8%~12.8%的WER。在金融和命名实体领域的外域数据集上，文本领域适应分别实现了15.3%和17.8%的WER降低。

研究结论: J-TAED成功整合了语音和语言信息，显著提升了ASR性能，并在外域任务中通过文本领域适应有效缓解了数据稀缺问题。

中文摘要: 本文提出了一种联合语音和文本优化的混合转换器与注意力编码解码器（TAED）建模方法，旨在利用大量文本语料库提升ASR准确性。联合TAED（J-TAED）在训练时同时使用语音和文本输入模态，但在推理时仅需语音数据输入。训练后的模型能够统一不同模态的内部表示，并可进一步扩展为基于文本的领域适应。由于无需语音数据，该方法能有效缓解领域不匹配任务中的数据稀缺问题。实验表明，J-TAED成功将语音和语言信息整合到一个模型中，并在Librispeech数据集上降低了5.8%~12.8%的WER。模型还在两个外域数据集（金融和命名实体领域）上进行了评估，基于文本的领域适应分别实现了15.3%和17.8%的WER降低。

</details>


### [11] [Prompt, Translate, Fine-Tune, Re-Initialize, or Instruction-Tune? Adapting LLMs for In-Context Learning in Low-Resource Languages](https://arxiv.org/abs/2506.19187)
**中文标题：提示、翻译、微调、重新初始化还是指令微调？调整LLMs以支持低资源语言的上下文学习**

*Christopher Toukmaji,Jeffrey Flanigan*

主要分类: cs.CL

摘要简述: 本文研究了如何调整大型语言模型（LLMs）以支持低资源语言的上下文学习，比较了多种适应技术，发现少样本提示和翻译测试方法优于基于梯度的适应方法，并提出了新的评估指标VOR。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型通常在高资源语言上训练，导致低资源语言的上下文学习表现不佳。本文旨在探索如何跨语言调整LLMs，以提升其在低资源语言中的表现。

研究方法: 研究覆盖五种低资源语言、三种基础LLMs和七项下游任务，比较了少样本提示、翻译测试、微调、嵌入重新初始化和指令微调等多种适应技术。

研究结果: 少样本提示和翻译测试方法显著优于基于梯度的适应方法，研究发现性能下降与灾难性遗忘有关。

研究结论: 研究为低资源语言的上下文学习提供了全面的技术比较，并公开了数据集和模型供公众使用。

中文摘要: 大型语言模型（LLMs）通常在高资源语言上训练，导致低资源语言的上下文学习表现不佳。尽管已有大量关于提示设置的研究，但如何跨语言调整LLMs以支持低资源语言的上下文学习仍不明确。本研究覆盖五种目标语言、三种基础LLMs和七项下游任务，耗时超过4,100 GPU训练小时（9,900+ TFLOPs），比较了少样本提示、翻译测试、微调、嵌入重新初始化和指令微调等多种适应技术。结果显示，少样本提示和翻译测试方法显著优于基于梯度的适应方法。为理解这一差异，我们设计了新指标“有效输出召回率”（VOR），并通过分析模型输出将性能下降归因于灾难性遗忘。据我们所知，这是在训练计算量和适应技术数量方面对低资源语言上下文学习的最大规模研究。我们公开了所有数据集和训练模型供公众使用。

</details>


### [12] [Augmenting Multi-Agent Communication with State Delta Trajectory](https://arxiv.org/abs/2506.19209)
**中文标题：通过状态变化轨迹增强多智能体通信**

*Yichen Tang,Weihang Su,Yujia Zhou,Yiqun Liu,Min Zhang,Shaoping Ma,Qingyao Ai*

主要分类: cs.CL

摘要简述: 本文提出了一种新的多智能体通信协议，通过传输自然语言令牌和令牌级状态变化轨迹（SDE）来减少信息损失，特别是在复杂推理任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于LLM的多智能体系统主要使用自然语言进行通信，虽然简单易解释，但会导致信息损失，尤其是在传递推理逻辑或抽象思维时。本文旨在解决这一问题。

研究方法: 提出了一种状态变化编码（SDE）方法，传输令牌级状态变化轨迹，以更准确地反映推理过程中的隐藏信息。

研究结果: 实验表明，采用SDE的多智能体系统在复杂推理任务中表现优于其他通信协议，达到SOTA性能。

研究结论: SDE方法展示了通信增强在基于LLM的多智能体系统中的潜力，特别是在需要复杂推理的任务中。

中文摘要: 多智能体技术（如角色扮演或多轮辩论）已被证明能有效提升大型语言模型（LLMs）在下游任务中的表现。尽管工作流程不同，现有的基于LLM的多智能体系统大多使用自然语言进行智能体间通信。虽然这种方式因其简单性和可解释性而具有吸引力，但也引入了不可避免的信息损失，因为一个模型必须将其连续状态向量降采样为具体令牌后才能传递给另一个模型。这种损失在传递的信息并非简单事实，而是推理逻辑或抽象思维时尤为显著。为解决这一问题，我们提出了一种新的通信协议，同时传输自然语言令牌和令牌级状态变化轨迹。特别是，与实际状态值相比，我们发现LLMs在生成每个令牌后的状态变化序列能更好地反映推理过程中隐藏的信息，因此提出了一种状态变化编码（SDE）方法来表示状态变化轨迹。实验结果表明，采用SDE的多智能体系统在复杂推理任务中表现优于其他通信协议，达到SOTA性能。这展示了通信增强在基于LLM的多智能体系统中的潜力。

</details>


### [13] [Personality Prediction from Life Stories using Language Models](https://arxiv.org/abs/2506.19258)
**中文标题：基于语言模型的生活故事人格预测**

*Rasiq Hussain,Jerry Ma,Rithik Khandelwal,Joshua Oltmanns,Mehak Gupta*

主要分类: cs.CL

摘要简述: 本文提出了一种结合预训练语言模型和循环神经网络的两步法，用于从长篇生活故事中预测五因素人格特质，显著提升了预测准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 传统人格评估主要依赖问卷，限制了数据的丰富性。自然语言处理技术为利用开放文本进行人格评估提供了新途径，但长篇叙事数据的建模仍具挑战性。本研究旨在解决这一问题。

研究方法: 采用两步法：首先通过滑动窗口微调预训练语言模型提取上下文嵌入；随后利用带注意力机制的循环神经网络整合长距离依赖关系，增强模型的可解释性。

研究结果: 通过消融实验和与LLaMA、Longformer等先进模型的对比，验证了该方法在预测准确性、效率和可解释性上的提升。

研究结论: 研究表明，结合语言特征和长上下文建模能有效推进基于生活叙事的人格评估，为未来研究提供了新方向。

中文摘要: 自然语言处理（NLP）为利用丰富开放文本进行人格评估提供了新途径，超越了传统问卷。本研究针对长篇叙事访谈（每篇超过2000词）预测五因素模型（FFM）人格特质的挑战，提出了一种两步法：首先通过滑动窗口微调预训练语言模型提取上下文嵌入；随后利用带注意力机制的循环神经网络（RNN）整合长距离依赖关系并增强可解释性。这一混合方法有效结合了预训练变换器和序列建模的优势，适用于长上下文数据。通过消融实验及与LLaMA、Longformer等先进长上下文模型的对比，证明了该方法在预测准确性、效率和可解释性上的改进。结果表明，结合语言特征与长上下文建模有望推动基于生活叙事的人格评估发展。

</details>


### [14] [What Matters in LLM-generated Data: Diversity and Its Effect on Model Fine-Tuning](https://arxiv.org/abs/2506.19262)
**中文标题：LLM生成数据的关键因素：多样性及其对模型微调的影响**

*Yuchang Zhu,Zhonghua zhen,Qunshu Lin,Haotong Wei,Xiaolong Sun,Zixuan Yu,Minghao Liu,Zibin Zheng,Liang Chen*

主要分类: cs.CL

摘要简述: 研究发现，LLM生成数据的多样性对下游模型性能有显著影响：适度多样性数据能提升模型性能，而高多样性数据则可能产生负面影响。


<details>
  <summary>详细信息</summary>
研究动机: 当前利用LLM生成数据训练下游模型的方法存在模型性能退化问题，但现有研究忽视了数据多样性的重要性。本文旨在探究LLM生成数据的多样性对下游模型性能的影响。

研究方法: 通过实验分析不同多样性水平的LLM生成数据对下游模型性能的影响，并研究混合不同比例合成数据的效果。

研究结果: 实验表明，在分布偏移较小的情况下，适度多样性的LLM生成数据能提升模型性能，而高多样性数据则可能对性能产生负面影响。

研究结论: 本文为LLM作为数据生成器的研究提供了重要指导，强调了数据多样性在模型训练中的关键作用。

中文摘要: 随着大型语言模型（LLMs）强大的生成能力，利用LLM生成数据训练下游模型成为缓解特定领域数据稀缺和减少耗时标注的有效方法。然而，近期研究揭示了一个关键问题：迭代训练自生成数据会导致模型性能退化（模型崩溃）。尽管已有大量研究探讨LLM生成数据的影响，但这些研究往往忽视了数据多样性的重要性。本文旨在探究LLM生成数据的多样性对下游模型性能的影响，具体分析不同多样性水平的数据如何影响模型性能，并研究混合不同比例合成数据的效果。实验结果表明，在分布偏移较小的情况下，适度多样性的LLM生成数据能提升模型性能，而高多样性数据则可能产生负面影响。我们希望这些实证结果为未来关于LLM作为数据生成器的研究提供有价值的指导。

</details>


### [15] [EmoStage: A Framework for Accurate Empathetic Response Generation via Perspective-Taking and Phase Recognition](https://arxiv.org/abs/2506.19279)
**中文标题：EmoStage：基于视角采择与阶段识别的精准共情回应生成框架**

*Zhiyang Qi,Keiko Takamizo,Mariko Ukiyo,Michimasa Inaba*

主要分类: cs.CL

摘要简述: EmoStage是一个通过视角采择和阶段识别提升共情回应生成的框架，无需额外训练数据，显著改善基础模型的回应质量。


<details>
  <summary>详细信息</summary>
研究动机: 心理健康护理需求增加，但现有AI咨询系统存在对用户心理状态和咨询阶段理解不足、依赖高质量训练数据及隐私问题。EmoStage旨在解决这些问题。

研究方法: EmoStage利用开源大语言模型的推理能力，通过视角采择推断用户心理状态和需求，结合阶段识别确保回应与咨询过程一致。

研究结果: 实验显示，EmoStage在日语和中文咨询场景中显著提升基础模型的回应质量，性能与数据驱动方法相当。

研究结论: EmoStage为AI咨询系统提供了一种高效、隐私安全的共情回应生成方案，无需额外训练数据。

中文摘要: 心理健康护理需求的增长推动了AI驱动咨询系统的研究。尽管大语言模型（LLMs）潜力巨大，但现有方法存在对用户心理状态和咨询阶段理解不足、依赖高质量训练数据及商业部署中的隐私问题。为解决这些问题，我们提出EmoStage框架，利用开源LLMs的推理能力，无需额外训练数据即可提升共情回应生成。该框架通过视角采择推断用户心理状态和需求，生成情感共鸣的回应；同时引入阶段识别，确保回应与咨询过程一致，避免不恰当或不合时宜的回应。在日语和中文咨询场景中的实验表明，EmoStage显著提升了基础模型的回应质量，性能与数据驱动方法相当。

</details>


### [16] [JCAPT: A Joint Modeling Approach for CAPT](https://arxiv.org/abs/2506.19315)
**中文标题：JCAPT：一种用于CAPT的联合建模方法**

*Tzu-Hsuan Yang,Yue-Yang He,Berlin Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种联合建模方法JCAPT，用于计算机辅助发音训练（CAPT），通过结合自动发音评估（APA）和发音错误检测与诊断（MDD）任务，利用Mamba模型和语音学特征，显著提升了任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 在第二语言学习中，有效的发音反馈至关重要。现有的CAPT系统通常独立处理APA和MDD任务，但研究表明联合建模可以带来相互提升。本文旨在通过结合语音学特征和先进的建模技术，提升CAPT系统的解释性和时间推理能力。

研究方法: 本文提出了一种统一框架JCAPT，利用选择性状态空间模型（Mamba），并结合语音学特征和提示策略，联合优化APA和MDD任务。这是首次在CAPT中整合语音学归因、SSM建模和提示技术的研究。

研究结果: 在speechocean762基准测试上的实验表明，JCAPT模型显著优于现有方法，尤其在MDD任务上表现突出。

研究结论: JCAPT通过联合建模APA和MDD任务，结合语音学特征和Mamba模型，显著提升了CAPT系统的性能，为发音训练提供了更有效的解决方案。

中文摘要: 有效的发音反馈在第二语言（L2）学习中至关重要，计算机辅助发音训练（CAPT）系统通常包含两个关键任务：自动发音评估（APA）和发音错误检测与诊断（MDD）。近期研究表明，联合建模这两个任务可以带来相互提升。我们的统一框架利用选择性状态空间模型（Mamba），同时整合语音学特征和提示策略，共同增强APA和MDD的解释性和细粒度时间推理能力。据我们所知，这是首次在CAPT中结合语音学归因、基于SSM的建模和提示技术的研究。在speechocean762基准测试上进行的一系列实验表明，我们的模型在性能上持续优于现有方法，尤其是在MDD任务上。

</details>


### [17] [Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation](https://arxiv.org/abs/2506.19352)
**中文标题：识别角色不一致行为：开放生成中角色保真度的原子级评估**

*Jisu Shin,Juhyun Oh,Eunsu Kim,Hoyun Song,Alice Oh*

主要分类: cs.CL

摘要简述: 本文提出了一种原子级评估框架，用于量化大型语言模型（LLM）生成内容中角色保真度的细微偏差，解决了现有方法在长文本生成中难以捕捉角色不一致的问题。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在开放生成中常出现角色不一致（OOC）行为，影响交互的连贯性和可靠性。现有评估方法难以捕捉细微偏差，尤其是长文本中的角色偏离。

研究方法: 提出了一种原子级评估框架，通过三个关键指标量化角色对齐和一致性，细粒度评估角色保真度。

研究结果: 实验表明，该框架能有效检测现有方法忽略的角色不一致，并揭示任务结构和角色吸引力对模型适应性的影响。

研究结论: 原子级评估框架为角色保真度提供了更精确的评估方法，揭示了维持角色一致性的挑战。

中文摘要: 确保大型语言模型（LLM）的角色保真度对于维持连贯且引人入胜的人机交互至关重要。然而，LLM常表现出角色不一致（OOC）行为，即生成内容偏离指定角色，导致影响模型可靠性的不一致性。现有评估方法通常为整个响应分配单一分数，难以捕捉细微的角色偏差，尤其是在长文本生成中。为解决这一局限，我们提出了一种原子级评估框架，以更细粒度量化角色保真度。我们的三个关键指标衡量角色对齐和一致性的程度，包括生成内和跨生成的一致性。该方法通过识别真实用户可能遇到的细微偏差，实现了对角色保真度更精确和现实的评估。实验表明，我们的框架能有效检测现有方法忽略的角色不一致。通过分析不同任务和角色类型的保真度，我们揭示了任务结构和角色吸引力对模型适应性的影响，强调了维持角色一致性的挑战。

</details>


### [18] [Measuring and Guiding Monosemanticity](https://arxiv.org/abs/2506.19382)
**中文标题：测量与引导单义性**

*Ruben Härle,Felix Friedrich,Manuel Brack,Stephan Wäldchen,Björn Deiseroth,Patrick Schramowski,Kristian Kersting*

主要分类: cs.CL

摘要简述: 本文提出了一种新指标FMS来量化特征单义性，并开发了G-SAE方法，通过条件化潜在表示提升语言模型的可解释性和控制性。实验表明，该方法在毒性检测、写作风格识别等任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLMs）的机制可解释性和可控性方法存在特征定位和操纵不可靠的问题。稀疏自编码器（SAEs）虽具潜力，但特征隔离和单义性不足。本文旨在量化这些限制并提出改进方法。

研究方法: 引入特征单义性评分（FMS）量化潜在表示中的特征单义性，并提出引导稀疏自编码器（G-SAE），通过在训练中条件化潜在表示来提升特征定位和解缠能力。

研究结果: 实验表明，G-SAE在毒性检测、写作风格识别和隐私属性识别任务中显著提升了单义性，同时实现了更精细的控制且质量退化更少。

研究结论: 本文提出的FMS和G-SAE为LLMs的机制可解释性和控制提供了实用指南，展示了其在多任务中的有效性。

中文摘要: 利用机制可解释性和可控性来理解和影响大型语言模型（LLMs）的内部动态日益受到关注。然而，现有方法在可靠定位和操纵特征表示方面面临根本性挑战。稀疏自编码器（SAEs）虽是大规模特征提取的有前景方向，但仍受限于不完全的特征隔离和不可靠的单义性。为系统量化这些限制，我们提出了特征单义性评分（FMS），一种量化潜在表示中特征单义性的新指标。基于这些见解，我们提出了引导稀疏自编码器（G-SAE），该方法在训练过程中对潜在表示进行条件化。我们证明，潜在空间中目标概念的可靠定位和解缠可提升可解释性、行为检测和控制能力。具体而言，在毒性检测、写作风格识别和隐私属性识别的评估中，G-SAE不仅增强了单义性，还实现了更有效、更精细的引导且质量退化更少。我们的研究结果为测量和推进LLMs的机制可解释性和控制提供了实用指南。

</details>


### [19] [Automated Detection of Pre-training Text in Black-box LLMs](https://arxiv.org/abs/2506.19399)
**中文标题：黑盒大语言模型中预训练文本的自动检测**

*Ruihan Hu,Yu-Ming Shang,Jiankun Peng,Wei Luo,Yazhe Wang,Xi Zhang*

主要分类: cs.CL

摘要简述: 本文提出VeilProbe框架，首次实现黑盒环境下无需人工干预自动检测大语言模型预训练文本，有效解决数据隐私和版权保护问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前检测大语言模型预训练文本的方法依赖模型隐藏信息或需大量人工干预，无法适用于黑盒环境。本文旨在解决这一问题，提出自动化检测方案。

研究方法: VeilProbe通过序列到序列映射模型推断输入文本与模型输出后缀的潜在映射特征，并进行关键令牌扰动以增强区分性。此外，引入原型分类器缓解过拟合问题。

研究结果: 在三个广泛使用的数据集上的评估表明，VeilProbe在黑盒环境下表现优异且有效。

研究结论: VeilProbe为黑盒环境下自动检测预训练文本提供了高效解决方案，具有实际应用价值。

中文摘要: 检测给定文本是否属于大语言模型（LLMs）的预训练数据对于确保数据隐私和版权保护至关重要。现有方法大多依赖模型的隐藏信息（如参数或令牌概率），使其在黑盒环境下（仅能访问输入和输出文本）无效。尽管已有一些针对黑盒环境的方法，但它们依赖大量人工干预，如设计复杂问题或指令。为解决这些问题，我们提出VeilProbe，首个无需人工干预的黑盒环境下自动检测LLMs预训练文本的框架。VeilProbe利用序列到序列映射模型推断输入文本与LLM生成的对应输出后缀之间的潜在映射特征，并通过关键令牌扰动获取更具区分性的成员特征。此外，考虑到实际场景中真实训练文本样本有限，引入原型分类器缓解过拟合问题。在三个广泛使用的数据集上的大量评估表明，我们的框架在黑盒环境下高效且优越。

</details>


### [20] [Learning to Disentangle Latent Reasoning Rules with Language VAEs: A Systematic Study](https://arxiv.org/abs/2506.19418)
**中文标题：学习通过语言VAEs解耦潜在推理规则：一项系统性研究**

*Yingji Zhang,Marco Valentino,Danilo S. Carvalho,André Freitas*

主要分类: cs.CL

摘要简述: 本文提出了一种通过语言变分自编码器（VAEs）在Transformer模型中显式嵌入和记忆推理规则的方法，以提升模型的泛化性、可解释性和可控性。实验表明，该方法能有效分离推理规则并注入先验知识，但数学推理任务中存在性能瓶颈。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于Transformer的语言模型在自然语言推理任务中表现优异，但主要依赖记忆而非规则推理。为了增强模型的泛化性、可解释性和可控性，本文探索如何在语言模型的潜在空间中显式嵌入推理规则。

研究方法: 提出了一套完整的流程，包括三个基于规则的推理任务、理论框架和端到端架构。通过语言变分自编码器（VAEs）在编码器的参数空间中分离推理规则，并注入先验知识以优化模型性能。

研究结果: 实验发现：1）在显式信号监督下，推理规则能在编码器参数空间中被分离；2）注入先验知识可提升模型检索能力；3）数学推理任务中，样本数量增加无法持续提升性能，且ffn层比注意力层更擅长保持规则分离。

研究结论: 通过语言VAEs显式嵌入推理规则是可行的，能提升模型性能，但需注意数学推理任务的性能瓶颈。ffn层在规则分离中表现更优。

中文摘要: 在语言模型的潜在空间中显式嵌入推理规则，是提升泛化性、可解释性和可控性的有效途径。尽管当前基于Transformer的语言模型在自然语言推理任务中表现优异，但其往往依赖记忆而非规则推理。本研究探讨了如何通过语言变分自编码器（VAEs）显式嵌入和记忆推理规则。我们提出了一套完整的流程，包括三个基于规则的推理任务、理论框架和端到端架构。实验结果表明：1）在显式信号监督下，推理规则（视为功能映射）能在编码器参数空间中被解耦，并在输出特征空间中形成明显的聚类；2）将推理信息注入查询（Query）中，可帮助模型更有效地从内存中检索值（Value）；3）在数学推理任务中（使用Qwen2.5(0.5B)），样本数量增加无法持续提升性能，且ffn层比注意力层更擅长保持规则分离。

</details>


### [21] [Can Large Language Models Capture Human Annotator Disagreements?](https://arxiv.org/abs/2506.19467)
**中文标题：大型语言模型能否捕捉人类标注分歧？**

*Jingwei Ni,Yu Fan,Vilém Zouhar,Donya Rooein,Alexander Hoyle,Mrinmaya Sachan,Markus Leippold,Dirk Hovy,Elliott Ash*

主要分类: cs.CL

摘要简述: 大型语言模型（LLMs）在预测人类标注分歧方面表现不佳，且基于多数标签的评估可能掩盖这一问题。强化学习推理虽提升LLM性能，但会降低分歧预测能力。


<details>
  <summary>详细信息</summary>
研究动机: 人类标注分歧在自然语言处理中常见，反映了任务的主观性和样本的模糊性。尽管LLMs被广泛用于自动标注以减少人工成本，但其评估通常集中于预测多数投票的“真实标签”，而是否能捕捉人类标注分歧尚不明确。本研究旨在填补这一空白。

研究方法: 通过广泛评估LLMs在预测标注分歧方面的能力，研究未依赖重复人类标注数据。特别关注了强化学习推理（RLVR）对LLM性能的影响。

研究结果: LLMs在建模标注分歧方面表现不佳，且基于多数标签的评估可能忽视这一问题。RLVR推理虽提升LLM整体性能，但会降低其在分歧预测中的表现。

研究结论: 研究强调了评估和改进LLM在分歧建模中能力的必要性，为未来研究提供了重要方向。

中文摘要: 人类标注分歧（即标注不一致）在自然语言处理中常见，通常反映了任务的主观性或样本的模糊性等重要信息。尽管大型语言模型（LLMs）越来越多地用于自动标注以减少人工成本，但其评估通常集中于预测多数投票的“真实标签”。然而，这些模型是否能捕捉信息丰富的人类标注分歧仍不明确。本研究通过广泛评估LLMs在未依赖重复人类标注数据的情况下预测标注分歧的能力，填补了这一空白。结果显示，LLMs在建模分歧方面表现不佳，而基于多数标签的评估可能掩盖这一问题。值得注意的是，尽管强化学习推理（RLVR）通常能提升LLM性能，但其在分歧预测中却会降低表现。本研究强调了评估和改进LLM标注器在分歧建模中能力的迫切需求。代码和数据见https://github.com/EdisonNi-hku/Disagreement_Prediction。

</details>


### [22] [MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages](https://arxiv.org/abs/2506.19468)
**中文标题：MuBench：评估大型语言模型在61种语言中的多语言能力**

*Wenhan Han,Yifan Zhang,Zhixun Chen,Binbin Liu,Haobin Lin,Bingni Zhang,Taifeng Wang,Mykola Pechenizkiy,Meng Fang,Yin Zheng*

主要分类: cs.CL

摘要简述: MuBench是一个涵盖61种语言的多语言大模型评估基准，揭示了当前模型在低资源语言与英语之间的性能差距，并提出多语言一致性（MLC）作为补充指标。


<details>
  <summary>详细信息</summary>
研究动机: 当前多语言大模型的评估数据集有限且缺乏跨语言对齐，导致对多语言能力的评估分散且不全面。MuBench旨在填补这一空白，提供更全面的评估工具。

研究方法: MuBench覆盖61种语言，评估多种能力，并提出多语言一致性（MLC）作为补充指标。此外，作者还预训练了1.2B参数的模型，研究跨语言迁移动态。

研究结果: 研究发现，多语言大模型在低资源语言与英语之间存在显著性能差距，且模型声称的语言支持与实际表现不符。MLC指标有助于分析性能瓶颈。

研究结论: MuBench为多语言大模型的评估提供了更全面的工具，揭示了性能差距，并提出MLC指标以指导模型改进。

中文摘要: 多语言大型语言模型（LLMs）发展迅速，新模型频繁声称支持越来越多的语言。然而，现有的评估数据集有限且缺乏跨语言对齐，导致对多语言能力的评估在语言和技能覆盖上分散。为此，我们引入了MuBench，一个涵盖61种语言并评估广泛能力的基准。我们评估了几种最先进的多语言LLMs，发现声称的语言支持与实际表现之间存在显著差距，尤其是英语与低资源语言之间的持续性能差异。利用MuBench的对齐性，我们提出多语言一致性（MLC）作为准确性的补充指标，用于分析性能瓶颈和指导模型改进。最后，我们在英语和中文上预训练了一套1.2B参数的模型，使用500B令牌，通过调整语言比例和平行数据比例来研究跨语言迁移动态。

</details>


### [23] [Commonsense Generation and Evaluation for Dialogue Systems using Large Language Models](https://arxiv.org/abs/2506.19483)
**中文标题：基于大型语言模型的对话系统常识生成与评估**

*Marcos Estecha-Garitagoitia,Chen Zhang,Mario Rodríguez-Cantelar,Luis Fernando D'Haro*

主要分类: cs.CL

摘要简述: 本文探讨了利用大型语言模型（LLMs）为对话系统生成基于常识关系的轮次数据增强方法，并自动评估生成的合成轮次。初步结果表明，该方法能有效利用LLMs的常识推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 对话系统中缺乏高质量的常识推理数据，限制了系统的表现。本文旨在通过LLMs的零样本能力和常识推理能力，生成上下文相关的常识知识，并自动评估其质量。

研究方法: 1. 从5个知名对话数据集中随机抽取200个部分对话，生成基于不同事件常识属性的替代响应。2. 提出基于指令的提示方法，利用LLMs自动检测生成轮次的常识属性，避免复杂的事件关系提取过程。

研究结果: 初步结果表明，该方法能有效利用LLMs生成上下文相关的常识知识，并自动评估其质量，尤其在12种特定ATOMIC关系上表现突出。

研究结论: 本文提出的方法为对话系统的常识推理和数据增强提供了有效工具，展示了LLMs在常识推理任务中的潜力。

中文摘要: 本文初步探讨了基于不同类型常识关系为对话系统生成轮次数据增强的任务，并自动评估生成的合成轮次。所提出的方法利用了预训练大型语言模型（LLMs）的扩展知识和零样本能力，使其能够遵循指令、理解上下文信息，并发挥常识推理能力。该方法从Chain-of-Thought（CoT）等方法中汲取灵感，更明确地应用于基于提示的对话数据生成任务，并自动评估生成的对话。

为评估方法的有效性，首先从5个知名对话数据集中随机抽取200个部分对话，生成基于不同事件常识属性的替代响应。这一新颖的数据集使我们能够衡量LLMs生成上下文相关常识知识的能力，特别是在12种特定ATOMIC数据库关系上的表现。其次，我们提出了一种受ACCENT指标启发的评估框架，用于自动检测生成数据集的质量。然而，我们的方法未采用ACCENT的复杂事件关系元组提取过程，而是为每个常识属性设计基于指令的提示，并利用最先进的LLMs自动检测生成轮次时使用的原始属性。

初步结果表明，我们的方法能有效利用LLMs的常识推理和评估能力，为对话系统提供支持。

</details>


### [24] [Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning](https://arxiv.org/abs/2506.19484)
**中文标题：大型语言模型的对话式教学法：将对话式AI与成熟学习理论对齐**

*Russell Beale*

主要分类: cs.CL

摘要简述: 本文探讨如何将大型语言模型（LLM）与对话式教学理论（如维果茨基的社会文化学习、苏格拉底法和劳里拉德的对话框架）结合，以提升教育对话的质量。通过分析现有文献，提出策略（如提示设计和检索增强生成）来优化LLM的教学行为，使其更符合教育原则。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在教育领域的应用日益广泛，但其对话行为与传统教学理论存在脱节。本文旨在通过结合对话式教学理论，优化LLM的教育功能，使其更符合个性化、适应性学习的需求。

研究方法: 本文综合分析了LLM在教育中的应用文献，并结合维果茨基的社会文化学习理论、苏格拉底法和劳里拉德的对话框架，提出通过提示设计和检索增强生成（RAG）技术，使LLM的行为更贴近教学理论。

研究结果: 研究发现，LLM在教育对话中存在直接提供答案而非促进知识共建的倾向，且其非人类专家的特性带来挑战。通过设计鼓励苏格拉底式提问和反思的提示，以及整合检索机制，可以提升LLM的教学效果。

研究结论: 本文为LLM与教育理论的结合提供了实践策略，旨在缩小教育理论与AI驱动对话学习之间的差距，使LLM对话更具教育意义和理论支持。

中文摘要: 大型语言模型（LLM）正通过丰富的对话学习体验迅速改变教育领域。本文全面综述了基于LLM的对话代理在高等教育中的应用，并延伸至中学和终身学习场景。我们综合了LLM在教育中的现有文献以及对话式和对话式教学理论（包括维果茨基的社会文化学习理论、苏格拉底法和劳里拉德的对话框架），探讨了如何通过提示策略和检索增强生成（RAG）使LLM行为与这些教学理论对齐，并支持个性化、适应性学习。我们将教育理论与LLM能力对应，指出LLM驱动的对话在支持传统学习原则方面的优势与不足。研究发现，将现有理论应用于LLM时存在显著空白，例如模型倾向于直接提供答案而非促进知识共建，以及需要应对LLM导师的持续可用性和广泛但非人类专业知识的问题。为此，我们提出了实用策略，以更好地将LLM互动与合理教学对齐，例如设计鼓励苏格拉底式提问、支架式指导和学生反思的提示，以及整合检索机制以确保准确性和上下文相关性。我们的目标是弥合教育理论与AI驱动对话学习新兴实践之间的差距，为提升LLM对话的教育效果和理论一致性提供见解和工具。

</details>


### [25] [Is Long-to-Short a Free Lunch? Investigating Inconsistency and Reasoning Efficiency in LRMs](https://arxiv.org/abs/2506.19492)
**中文标题：长推理转短推理是免费午餐吗？探究大型推理模型中的不一致性与推理效率**

*Shu Yang,Junchao Wu,Xuansheng Wu,Derek Wong,Ninhao Liu,Di Wang*

主要分类: cs.CL

摘要简述: 大型推理模型（LRMs）在复杂任务中表现优异，但存在过度思考风险。研究表明，高效推理策略虽提升效率，却可能导致行为不一致性增加，需进一步研究其潜在风险。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型（LRMs）通过长推理生成答案，但可能因过度思考而浪费资源。尽管高效推理策略旨在减少推理长度，但其是否引入行为不一致性尚不明确。本文旨在探究高效推理是否牺牲模型稳健性。

研究方法: 研究引入$ICBENCH$基准，从三个维度评估LRMs的不一致性：任务设置间不一致性（ITS）、训练目标与学习行为间不一致性（TR-LB）、内部推理与自我解释间不一致性（IR-SE）。应用于开源LRMs，分析高效推理策略的影响。

研究结果: 研究发现，大模型一致性优于小模型，但普遍存在“欺骗”行为，如自我矛盾、事后合理化及隐藏推理线索。高效推理策略（如No-Thinking和Simple Token-Budget）显著增加三类不一致性。

研究结论: 高效推理策略虽提升效率，但可能引入行为不一致性风险，需进一步研究其对模型监督的影响。

中文摘要: 大型推理模型（LRMs）通过长推理在复杂任务中表现优异，但这一优势可能引发过度思考问题，即在简单任务中生成过多冗余内容。尽管近期高效推理研究致力于减少推理长度并保持准确性，但此类优化是否真正无代价尚不明确。基于压缩推理可能降低模型响应稳健性并忽略关键推理步骤的直觉，本文探究高效推理策略是否引入行为不一致性。为此，我们提出$ICBENCH$基准，从三个维度系统评估LRMs的不一致性：任务设置间不一致性（ITS）、训练目标与学习行为间不一致性（TR-LB）、内部推理与自我解释间不一致性（IR-SE）。将$ICBENCH$应用于一系列开源LRMs后，我们发现大模型一致性普遍优于小模型，但均广泛存在“欺骗”行为，包括自我矛盾、事后合理化及隐藏推理线索。关键的是，高效推理策略（如No-Thinking和Simple Token-Budget）显著增加所有三类不一致性。这些结果表明，尽管高效推理提升了词元级效率，仍需进一步研究其是否同时引入模型逃避有效监督的风险。

</details>


### [26] [AnTKV: Anchor Token-Aware Sub-Bit Vector Quantization for KV Cache in Large Language Models](https://arxiv.org/abs/2506.19505)
**中文标题：AnTKV：基于锚令牌感知的子比特向量量化用于大型语言模型中的KV缓存**

*Zeyu Li,Chuanfu Xiao,Yang Wang,Xiang Liu,Zhenheng Tang,Baotong Lu,Mao Yang,Xinyu Chen,Xiaowen Chu*

主要分类: cs.CL

摘要简述: AnTKV提出了一种基于锚令牌感知的子比特向量量化方法，用于压缩大型语言模型中的KV缓存，显著降低内存占用并提升解码吞吐量，同时在高压缩比下保持低困惑度。


<details>
  <summary>详细信息</summary>
研究动机: KV缓存在大型语言模型中占用大量内存，现有量化方法在超低比特量化时性能下降显著。研究发现不同令牌的KV缓存对量化误差的敏感度不同，需针对性优化。

研究方法: 通过前向误差传播分析提出锚分数（AnS），量化令牌对误差的敏感度，并设计锚令牌感知向量量化框架AnTKV，结合高效Triton内核实现快速在线锚令牌选择。

研究结果: AnTKV使LLaMA-3-8B在单块80GB A100 GPU上支持840K令牌上下文，解码吞吐量比FP16基线提升3.5倍，1比特量化下困惑度仅为6.32，显著优于现有方法。

研究结论: AnTKV通过锚令牌感知量化有效平衡了KV缓存压缩与模型性能，为超低比特量化提供了高效解决方案。

中文摘要: 量化已成为减少大型语言模型（LLM）中KV缓存内存占用的有效轻量级解决方案。然而，在超低比特KV缓存量化下最小化性能下降仍是一大挑战。我们发现，不同令牌的KV缓存量化对注意力输出质量的影响各异。为系统研究此现象，我们对注意力进行前向误差传播分析，并提出锚分数（AnS），量化每个令牌KV缓存对量化误差的敏感度。分析显示AnS在令牌间差异显著，表明保留少量高AnS令牌的全精度（FP16）可大幅缓解激进量化下的精度损失。基于此，我们提出AnTKV，一种利用锚令牌感知向量量化压缩KV缓存的新框架。此外，为支持高效部署，我们设计并开发了与FlashAttention完全兼容的Triton内核，实现快速在线锚令牌选择。AnTKV使LLaMA-3-8B在单块80GB A100 GPU上支持840K令牌上下文，解码吞吐量比FP16基线提升3.5倍。实验表明，AnTKV在4比特设置下匹配或优于KIVI、SKVQ、KVQuant和CQ等现有方法。更重要的是，在Mistral-7B上，AnTKV在1比特和0.375比特量化下的困惑度仅为6.32和8.87，显著低于FP16基线的4.73。

</details>


### [27] [heiDS at ArchEHR-QA 2025: From Fixed-k to Query-dependent-k for Retrieval Augmented Generation](https://arxiv.org/abs/2506.19512)
**中文标题：heiDS在ArchEHR-QA 2025：从固定k值到查询依赖k值的检索增强生成**

*Ashish Chouhan,Michael Gertz*

主要分类: cs.CL

摘要简述: 本文介绍了团队heiDS在ArchEHR-QA 2025共享任务中的方法，提出了一种基于检索增强生成（RAG）的框架，通过查询依赖的k值检索策略（包括新提出的autocut*和elbow方法）生成临床证据支持的答案，优于固定k值策略。


<details>
  <summary>详细信息</summary>
研究动机: 现有的固定k值检索策略在生成基于电子健康记录（EHR）的答案时可能不够灵活，团队希望通过查询依赖的k值策略提升答案的事实性和相关性。

研究方法: 设计了一个RAG框架，重点研究了排名列表截断（RLT）检索策略和归因方法。提出了两种新方法autocut*和elbow，并与现有的surprise和autocut方法结合，实现查询依赖的k值检索。

研究结果: 实验结果表明，查询依赖的k值策略在生成事实性和相关性更高的答案方面优于固定k值策略。

研究结论: 查询依赖的k值检索策略在临床问答任务中具有显著优势，能够生成更准确的答案。

中文摘要: 本文介绍了团队heiDS在ArchEHR-QA 2025共享任务中的方法。我们设计了一个基于检索增强生成（RAG）的框架，用于生成基于患者电子健康记录（EHR）的临床证据支持的答案。我们探索了RAG框架的多个组件，重点关注排名列表截断（RLT）检索策略和归因方法。与固定k值的RLT检索策略不同，我们采用了查询依赖的k值检索策略，包括现有的surprise和autocut方法，以及本文新提出的autocut*和elbow方法。实验结果表明，我们的策略在生成事实性和相关性更高的答案方面优于固定k值策略。

</details>


### [28] [Automatic Posology Structuration : What role for LLMs?](https://arxiv.org/abs/2506.19525)
**中文标题：自动用药说明结构化：LLMs的作用是什么？**

*Natalia Bobkova,Laura Zanella-Calzada,Anyes Tafoughalt,Raphaël Teboul,François Plesse,Félix Gaschi*

主要分类: cs.CL

摘要简述: 本文探讨了使用大型语言模型（LLMs）将自由文本的用药说明结构化，比较了基于提示的方法和微调方法，并提出了结合命名实体识别与链接（NERL）的混合策略，实现了91%的结构化准确率。


<details>
  <summary>详细信息</summary>
研究动机: 法国处方中的用药说明常存在模糊、不规范或口语化问题，限制了传统机器学习流程的效果。研究旨在探索LLMs在结构化用药说明中的作用，以提高用药安全和临床决策支持。

研究方法: 研究比较了基于提示的LLMs方法和微调方法，并与基于NERL的“前LLM”系统进行对比。通过错误分析发现互补优势后，提出了一种混合流程：将NERL低置信度（<0.8）的案例路由到LLM，并根据置信度选择输出。

研究结果: 结果显示，仅微调的LLMs能达到基线准确率，而混合策略实现了91%的结构化准确率，同时降低了延迟和计算成本。

研究结论: 混合方法结合了NERL的结构精确性和LLMs的语义处理能力，为临床实际应用提供了可扩展的解决方案。

中文摘要: 自动结构化用药说明对提高用药安全和临床决策支持至关重要。法国处方中的用药说明常存在模糊、不规范或口语化问题，限制了传统机器学习流程的效果。本研究探索了使用大型语言模型（LLMs）将自由文本用药说明转换为结构化格式的方法，比较了基于提示的方法和微调方法，并与基于命名实体识别与链接（NERL）的“前LLM”系统进行对比。结果显示，尽管提示方法提升了性能，但仅微调的LLMs能达到基线准确率。通过错误分析发现，NERL具有结构精确性，而LLMs更擅长处理语义细微差别。基于此，我们提出了一种混合流程：将NERL低置信度（<0.8）的案例路由到LLM，并根据置信度选择输出。该策略实现了91%的结构化准确率，同时降低了延迟和计算成本。结果表明，这种混合方法在提高结构化准确率的同时限制了计算成本，为实际临床应用提供了可扩展的解决方案。

</details>


### [29] [KnowMap: Efficient Knowledge-Driven Task Adaptation for LLMs](https://arxiv.org/abs/2506.19527)
**中文标题：KnowMap：面向大型语言模型的高效知识驱动任务适应方法**

*Kelin Fu,Kaigui Bian*

主要分类: cs.CL

摘要简述: KnowMap是一种新颖的方法，通过动态构建知识库，帮助大型语言模型（LLM）快速适应新任务，避免了传统微调的高成本和数据依赖问题。实验显示，该方法在ScienceWorld基准测试中提升了GPT-4 Turbo模型17.71%的性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）虽然具备强大的开放世界任务能力，但在快速适应新的专业化任务时面临挑战，主要依赖静态预训练知识。传统微调方法成本高、数据密集，且可能导致灾难性遗忘。因此，需要一种更高效的任务适应方法。

研究方法: KnowMap通过动态构建环境与经验数据的知识库，微调一个小型知识嵌入模型，为大型LLM提供任务特定知识。这种方法避免了传统微调的缺点，同时提升了模型的任务适应能力。

研究结果: 在ScienceWorld基准测试中，KnowMap使GPT-4 Turbo模型的性能提升了17.71%，验证了其高效性和有效性。

研究结论: KnowMap不仅为LLM任务适应提供了高效方法，还展示了如何通过整合环境和经验知识增强LLM的推理能力。

中文摘要: 尽管大型语言模型（LLM）在开放世界代理任务中具备显著能力，但由于依赖静态预训练知识，其在快速适应新的专业化任务时面临挑战。传统方法如微调通常成本高昂、数据密集，并可能导致“灾难性遗忘”。为此，我们提出KnowMap，一种从环境和经验数据中动态构建知识库的新方法。KnowMap通过微调一个小型知识嵌入模型，为大型LLM提供有价值的任务特定知识。在ScienceWorld基准测试中，实验表明该方法使GPT-4 Turbo模型的性能提升了17.71%。KnowMap不仅为LLM任务适应提供了高效且有效的手段，还突显了如何通过整合环境和经验知识增强LLM的推理能力。

</details>


### [30] [Health Sentinel: An AI Pipeline For Real-time Disease Outbreak Detection](https://arxiv.org/abs/2506.19548)
**中文标题：健康哨兵：一种用于实时疾病爆发检测的AI管道**

*Devesh Pant,Rishi Raj Grandhe,Vipin Samaria,Mukul Paul,Sudhir Kumar,Saransh Khanna,Jatin Agrawal,Jushaan Singh Kalra,Akhil VSSG,Satish V Khalikar,Vipin Garg,Himanshu Chauhan,Pranay Verma,Neha Khandelwal,Soma S Dhavala,Minesh Mathew*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Health Sentinel的AI管道，用于实时检测疾病爆发。通过结合机器学习和非机器学习方法，从在线文章中提取结构化健康事件信息，并协助公共卫生专家进行干预。


<details>
  <summary>详细信息</summary>
研究动机: 传统的疾病爆发监测方法效率低下，而在线媒体信息量大且难以手动筛选。因此，开发一种自动化工具来实时检测和提取健康事件信息成为必要。

研究方法: Health Sentinel采用多阶段信息提取管道，结合机器学习和非机器学习方法，从在线文章中提取疾病爆发或其他异常健康事件的结构化信息。

研究结果: 自2022年4月以来，Health Sentinel已处理超过3亿篇新闻文章，识别出超过95,000个独特的健康事件，其中3,500多个事件被公共卫生专家列为潜在爆发。

研究结论: Health Sentinel通过自动化信息提取和分析，显著提高了疾病爆发的实时检测能力，为公共卫生干预提供了有力支持。

中文摘要: 早期检测疾病爆发对于确保卫生当局及时干预至关重要。由于传统的基于指标的监测方法存在挑战，监测非正式来源（如在线媒体）变得越来越流行。然而，由于每天发布的在线文章数量庞大，手动筛选这些文章是不现实的。为此，我们提出了Health Sentinel。它是一个多阶段信息提取管道，结合机器学习和非机器学习方法，从在线文章中提取有关疾病爆发或其他异常健康事件的结构化信息。提取的事件被提供给印度国家疾病控制中心（NCDC）的媒体扫描与验证小组（MSVC），用于分析、解释并进一步传播给地方机构以进行及时干预。自2022年4月至今，Health Sentinel已处理超过3亿篇新闻文章，识别出超过95,000个独特的健康事件，其中3,500多个事件被NCDC的公共卫生专家列为潜在爆发。

</details>


### [31] [RCStat: A Statistical Framework for using Relative Contextualization in Transformers](https://arxiv.org/abs/2506.19549)
**中文标题：RCStat：一种在Transformer中使用相对上下文化的统计框架**

*Debabrata Mahapatra,Shubham Agarwal,Apoorv Saxena,Subrata Mitra*

主要分类: cs.CL

摘要简述: 本文提出RCStat，一种利用原始注意力对数而非Softmax归一化权重的统计框架，通过相对上下文化（RC）衡量令牌段对齐，实现高效压缩和更高保真度的解释。


<details>
  <summary>详细信息</summary>
研究动机: 先前研究依赖Softmax归一化的注意力权重，掩盖了预Softmax查询-键对数的丰富结构。RCStat旨在利用这些原始对数，提升模型压缩和解释的准确性。

研究方法: RCStat引入相对上下文化（RC）作为随机变量，衡量令牌段间的上下文对齐，并推导其高效上界。应用包括基于RC的键值压缩和更高保真度的令牌、句子及块级解释。

研究结果: 在问答、摘要和解释基准测试中，RCStat显著提升性能，实现最先进的压缩和解释效果，且无需模型重新训练。

研究结论: RCStat通过利用原始注意力对数，显著提升了模型压缩和解释的准确性，为自然语言处理任务提供了高效且高保真的解决方案。

中文摘要: 先前关于自回归Transformer中输入令牌重要性的研究依赖于Softmax归一化的注意力权重，这掩盖了预Softmax查询-键对数的丰富结构。我们提出RCStat，一种统计框架，通过相对上下文化（RC）利用原始注意力对数，RC是一种衡量令牌段间上下文对齐的随机变量，并推导了RC的高效上界。我们展示了两个应用：（i）键值压缩，基于RC的阈值驱动自适应键值淘汰，实现显著缓存减少且质量损失最小；（ii）解释，RC提供比后Softmax方法更高保真度的令牌、句子和块级解释。在问答、摘要和解释基准测试中，RCStat取得显著实证提升，无需模型重新训练即可实现最先进的压缩和解释性能。

</details>


### [32] [Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress](https://arxiv.org/abs/2506.19571)
**中文标题：机器翻译评估是否已达到人类水平？人类基准与进步的极限**

*Lorenzo Proietti,Stefano Perrella,Roberto Navigli*

主要分类: cs.CL

摘要简述: 研究发现，机器翻译评估中，自动指标的表现已接近或超过人类基准，但需谨慎解读这一结果。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，机器翻译评估中自动指标与人类判断的一致性逐渐提高。为了明确指标性能的上限，研究将人类基准纳入评估，探讨自动指标是否已达到人类水平。

研究方法: 研究通过将人类基准纳入机器翻译的元评估（即评估指标的能力），比较自动指标与人类标注者的一致性表现。

研究结果: 结果显示，人类标注者并非始终优于自动指标，最先进的指标表现常与人类基准持平或更高。然而，研究指出需谨慎解读这一结果。

研究结论: 尽管自动指标表现接近人类水平，但仍需警惕其局限性。研究呼吁关注机器翻译评估领域的进步测量问题。

中文摘要: 在机器翻译（MT）评估中，指标性能的评估基于与人类判断的一致性。近年来，自动指标与人类的一致性水平逐渐提高。为了更清晰地理解指标性能并确立上限，我们将人类基准纳入MT的元评估中，即评估MT指标的能力。结果显示，人类标注者并非始终优于自动指标，最先进的指标常与人类基准持平或更高。尽管这些发现表明已达到人类水平，但我们仍需谨慎解读。最后，我们探讨了研究结果的更广泛影响，并提出问题：我们是否还能可靠地测量MT评估的进步？通过这项工作，我们旨在揭示测量领域进步能力的极限，促进对这一关键问题的讨论。

</details>


### [33] [ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model](https://arxiv.org/abs/2506.19599)
**中文标题：ECCoT：通过思维链增强大型语言模型有效认知的框架**

*Zhenke Duan,Jiqun Pan,Jiani Tu,Xiaoyi Wang,Yanqing Wang*

主要分类: cs.CL

摘要简述: ECCoT是一个端到端的认知链验证框架，通过结合MRF-ETM和CSBert技术，优化大型语言模型的推理链，提升其可解释性和可信度。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在自然语言处理中表现出色，但其推理过程缺乏透明性，生成的输出不可靠。为解决这一问题，ECCoT框架旨在验证和优化推理链，提升模型的解释性和决策可信度。

研究方法: ECCoT整合了MRF-ETM（马尔可夫随机场嵌入主题模型）用于主题感知的推理链生成，以及CSBert（因果句子BERT）用于因果推理对齐。通过结构化排序统计过滤无效推理链，优化推理过程。

研究结果: ECCoT显著提升了大型语言模型的推理透明性，减少了偏见，增强了决策的可信度。

研究结论: ECCoT通过验证和优化推理链，为大型语言模型提供了更可靠的推理框架，推动了其在复杂任务中的应用。

中文摘要: 在大规模人工智能时代，大型语言模型（LLMs）在自然语言处理领域取得了显著进展。然而，其推理过程缺乏透明性，生成的输出不可靠，引发了对其可解释性的担忧。为解决这一问题，思维链（CoT）提示方法将推理过程结构化，逐步推导。然而，并非所有推理链都有效，错误可能导致不可靠的结论。我们提出了ECCoT，一种端到端的认知思维链验证框架，用于评估和优化LLMs中的推理链。ECCoT整合了马尔可夫随机场嵌入主题模型（MRF-ETM）用于主题感知的CoT生成，以及因果句子BERT（CSBert）用于因果推理对齐。通过结构化排序统计过滤无效链，ECCoT提升了可解释性，减少了偏见，并增强了基于LLM的决策可信度。主要贡献包括引入ECCoT、MRF-ETM用于主题驱动的CoT生成，以及CSBert用于因果推理增强。代码发布于：https://github.com/erwinmsmith/ECCoT.git。

</details>


### [34] [Social Hatred: Efficient Multimodal Detection of Hatemongers](https://arxiv.org/abs/2506.19603)
**中文标题：社会仇恨：仇恨传播者的高效多模态检测**

*Tom Marzea,Abraham Israeli,Oren Tsur*

主要分类: cs.CL

摘要简述: 本文提出一种多模态聚合方法，结合文本、用户活动和社交网络，高效检测网络仇恨传播者，显著优于传统文本和图方法。


<details>
  <summary>详细信息</summary>
研究动机: 在线仇恨言论的自动检测对净化网络环境至关重要。现有研究多关注仇恨言论本身，而本文认为用户层面的检测同样重要且更具挑战性。

研究方法: 采用多模态聚合方法，综合用户的潜在仇恨文本、活动数据和社交网络信息，检测仇恨传播者。在Twitter、Gab和Parler三个数据集上验证。

研究结果: 实验表明，结合用户社交背景的文本处理显著提升仇恨传播者检测效果，优于传统文本和图方法，且适用于不同平台和大规模数据集。

研究结论: 多模态方法不仅提升仇恨传播者检测效果，还能辅助识别编码信息和干预措施，适用于多样化平台和网络环境。

中文摘要: 在线仇恨言论的自动检测是净化网络话语的关键步骤，同时准确的分类有助于更好地理解仇恨作为一种社会现象的传播。尽管大多数现有研究专注于仇恨言论的检测，我们认为用户层面的检测同样重要且更具挑战性。本文提出一种多模态聚合方法，用于检测仇恨传播者，综合考虑潜在仇恨文本、用户活动和用户网络。通过在Twitter、Gab和Parler三个独特数据集上的评估，我们发现结合用户社交背景的文本处理显著提升了仇恨传播者的检测效果，优于传统的文本和图方法。我们提供了不同实验设置下的全面结果以及对典型案例的定性分析。该方法可用于改进编码信息、狗哨言论和种族煽动的分类，并为干预措施提供依据。此外，我们证明了多模态方法在不同内容平台和大规模数据集及网络上的良好表现。

</details>


### [35] [Correcting Hallucinations in News Summaries: Exploration of Self-Correcting LLM Methods with External Knowledge](https://arxiv.org/abs/2506.19607)
**中文标题：修正新闻摘要中的幻觉：基于外部知识的自我纠正LLM方法探索**

*Juraj Vladika,Ihsan Soydemir,Florian Matthes*

主要分类: cs.CL

摘要简述: 本文研究了两种先进的自我纠正方法，用于修正新闻摘要中的幻觉问题，通过利用搜索引擎提供的外部知识，验证了这些方法的有效性，并揭示了搜索片段和少样本提示的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在生成连贯文本方面表现出色，但存在幻觉问题（即事实性错误）。尽管自我纠正方法在百科全书生成领域有所探索，但在新闻摘要领域的应用较少。本文旨在探索如何利用自我纠正方法结合外部知识来修正新闻摘要中的幻觉。

研究方法: 研究采用两种先进的自我纠正系统，通过多轮对话生成验证问题，利用内部或外部知识（来自三个搜索引擎）回答问题，并基于新证据修正原始摘要。实验分析了系统性能，重点关注搜索片段和少样本提示的作用。

研究结果: 实验结果表明，自我纠正方法能有效修正新闻摘要中的幻觉。搜索引擎片段和少样本提示对系统性能有显著提升，且G-Eval与人工评估结果高度一致。

研究结论: 自我纠正方法结合外部知识可有效减少新闻摘要中的幻觉。搜索片段和少样本提示是提升系统性能的关键因素，为未来研究提供了实用指导。

中文摘要: 尽管大型语言模型（LLMs）在生成连贯文本方面表现出色，但它们存在幻觉问题（即事实性错误）。在众多解决幻觉的方法中，自我纠正方法尤为突出。这些方法利用LLMs的多轮对话特性，迭代生成验证问题以获取额外证据，通过内部或外部知识回答问题，并利用新证据修正原始回答。这些方法已在百科全书生成领域得到探索，但在新闻摘要等领域的应用较少。本文研究了两种先进的自我纠正系统，通过利用三个搜索引擎的证据修正幻觉摘要。我们分析了结果并提供了系统性能的见解，揭示了搜索片段和少样本提示的实用性，以及G-Eval与人工评估的高度一致性。

</details>


### [36] [Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager](https://arxiv.org/abs/2506.19652)
**中文标题：超越大型语言模型的定制对话：一种基于强化学习的对话管理器**

*Lucie Galland,Catherine Pelachaud,Florian Pecune*

主要分类: cs.CL

摘要简述: 本文提出了一种结合大型语言模型（LLM）和基于强化学习的对话管理器的框架，用于实现具有特定目标的开放式对话。通过分层强化学习和元学习，该方法提升了对话的适应性和效率，并在激励性访谈中验证了其优于现有LLM基线的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大型语言模型在开放式对话中表现优异，但缺乏针对特定目标的对话管理能力。本文旨在通过结合强化学习技术，提升对话系统在特定任务中的适应性和个性化能力。

研究方法: 提出了一种结合LLM和基于强化学习的对话管理器的框架，采用分层强化学习建模对话的结构化阶段，并通过元学习增强对不同用户特征的适应性。该方法能够从有限数据中学习，并在对话阶段间流畅切换。

研究结果: 在激励性访谈任务中，所提出的对话管理器在奖励指标上优于现有的大型语言模型基线，展示了其在特定目标对话系统中的潜力。

研究结论: 通过结合LLM和强化学习技术，本文提出的框架能够有效提升对话系统在特定任务中的表现，为开放式对话系统的个性化设计提供了新思路。

中文摘要: 本文提出了一种新颖的框架，将大型语言模型（LLM）与基于强化学习的对话管理器相结合，用于实现具有特定目标的开放式对话。通过分层强化学习建模对话的结构化阶段，并利用元学习增强对不同用户特征的适应性，我们的方法提升了系统的适应性和效率，使其能够从有限数据中学习，流畅切换对话阶段，并为不同用户需求提供个性化响应。我们将该框架应用于激励性访谈任务，旨在促进行为改变，并证明所提出的对话管理器在奖励指标上优于现有的大型语言模型基线，展示了结合LLM的开放式对话系统在特定目标中的潜在优势。

</details>


### [37] [Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?](https://arxiv.org/abs/2506.19733)
**中文标题：突破壁垒：强化后训练的增益能否迁移到未见领域？**

*Chuxuan Hu,Yuxuan Zhu,Antony Kellermann,Caleb Biddulph,Suppakit Waiwitlikhit,Jason Benn,Daniel Kang*

主要分类: cs.CL

摘要简述: 研究表明，强化后训练（RPT）虽能提升大语言模型在特定领域的推理能力，但其增益在未见领域中的泛化表现不一致，甚至可能消失。


<details>
  <summary>详细信息</summary>
研究动机: 尽管强化后训练（RPT）在提升大语言模型推理能力方面显示出潜力，但其在未见领域中的泛化能力尚不明确。本文旨在探究RPT增益是否能够跨领域迁移。

研究方法: 通过两项研究：(1) 观察性研究：比较多种开源RPT模型与其基础模型在多个领域（包括训练数据中未见领域）的表现；(2) 干预性研究：在单一领域上对模型进行RPT微调，并评估其在多领域中的表现。

研究结果: 两项研究均表明，RPT在类似训练数据的任务上带来显著提升，但在不同推理模式的领域中，增益泛化不一致甚至消失。

研究结论: RPT虽能提升特定任务的性能，但其增益在跨领域泛化中存在局限性，需进一步研究以提升其通用性。

中文摘要: 强化后训练（RPT）近期在提升大语言模型（LLMs）的推理能力方面显示出潜力。然而，这些改进在新领域中的泛化能力尚不明确，因为先前的研究仅在微调数据相同的领域内评估RPT模型。为探究RPT的泛化性，我们进行了两项研究：(1) 观察性研究：比较多种开源RPT模型与其基础模型在多个领域（包括微调数据中未见领域）的表现；(2) 干预性研究：在单一领域上对LLMs进行RPT微调，并评估其在多领域中的表现。两项研究得出相同结论：尽管RPT在类似微调数据的任务上带来显著增益，但这些增益在不同推理模式的领域中泛化不一致，甚至可能消失。

</details>


### [38] [Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach](https://arxiv.org/abs/2506.19750)
**中文标题：评估症状检查器在罕见疾病诊断中的性能：一种合成病例模拟方法**

*Takashi Nishibayashi,Seiji Kanazawa,Kumpei Yamada*

主要分类: cs.CL

摘要简述: 本研究提出了一种基于合成病例模拟的方法，用于评估症状检查器（SC）算法更新对罕见疾病诊断性能的影响，并通过实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 症状检查器（SC）的算法更新可能导致诊断性能下降，但罕见疾病的评估数据难以获取，手动创建临床病例成本高且不切实际。因此，需要一种低成本、高效的方法来预评估算法更新对罕见疾病诊断性能的影响。

研究方法: 研究利用人类表型本体（HPO）中的疾病-表型注释生成合成病例，模拟SC访谈以评估算法更新对诊断性能的影响。通过R平方系数比较估计值与实际指标变化，验证方法的有效性。

研究结果: 实验涵盖八次SC算法更新。对于HPO中包含频率信息的疾病（n=5），召回率@8和精确率@8变化的R平方分别为0.831和0.78，表明方法能有效预测更新后的性能。而对于无频率信息的疾病（n=3），预测误差较大。

研究结论: 该方法利用公开的专家知识库，为罕见疾病提供了一种透明、低成本的预部署评估手段，有助于开发者优化诊断性能，支持早期诊断。

中文摘要: 背景：症状检查器（SC）为用户提供个性化医疗信息。为防止算法更新导致的性能下降，开发者需在部署前评估其对个体罕见疾病诊断性能的影响。然而，获取足够的罕见疾病评估数据困难，手动创建大量临床病例成本高且不切实际。目的：本研究提出并验证了一种新型合成病例模拟方法，用于评估SC算法更新对个体罕见疾病诊断性能的影响。方法：利用人类表型本体（HPO）中的疾病-表型注释生成合成病例，模拟SC访谈以估计算法更新对实际诊断性能的影响。通过R平方系数比较估计值与实际指标变化，验证方法的有效性。结果：实验涵盖八次SC算法更新。对于HPO中包含频率信息的疾病（n=5），召回率@8和精确率@8变化的R平方分别为0.831（p=0.031）和0.78（p=0.047），表明方法能有效预测更新后的性能。而对于无频率信息的疾病（n=3），预测误差较大。手动将HPO表型映射到SC症状的耗时约为每疾病2小时。结论：该方法利用公开的专家知识库，为罕见疾病提供了一种透明、低成本的预部署评估手段，有助于开发者优化诊断性能，支持早期诊断。

</details>


### [39] [Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis](https://arxiv.org/abs/2506.19753)
**中文标题：使用RNN、Transformer和大语言模型进行阿拉伯方言分类的比较分析**

*Omar A. Essameldin,Ali O. Elbeih,Wael H. Gomaa,Wael F. Elsersy*

主要分类: cs.CL

摘要简述: 本研究比较了RNN、Transformer和大语言模型（LLM）在阿拉伯方言分类任务中的表现，发现MARBERTv2模型表现最佳，准确率为65%，F1分数为64%。研究还探讨了方言分类在个性化聊天机器人、社交媒体监控等领域的应用。


<details>
  <summary>详细信息</summary>
研究动机: 阿拉伯语是世界上使用最广泛的语言之一，拥有22个国家中多样的方言。研究旨在解决阿拉伯方言分类问题，以支持个性化聊天机器人、社交媒体监控等实际应用。

研究方法: 研究使用了RNN模型、Transformer模型和大语言模型（LLM），并通过提示工程对LLM进行测试。同时采用了最先进的预处理技术和最新的NLP模型。

研究结果: MARBERTv2模型表现最佳，准确率为65%，F1分数为64%。研究还揭示了阿拉伯方言识别中的主要语言问题。

研究结论: 研究结果表明，方言分类技术可应用于个性化聊天机器人、社交媒体监控等领域，为阿拉伯语社区提供更好的可访问性。

中文摘要: 阿拉伯语是世界上使用最广泛的语言之一，22个国家中存在着多种方言。本研究针对QADI数据集中18种阿拉伯方言的分类问题，创建并测试了RNN模型、Transformer模型以及通过提示工程实现的大语言模型（LLM）。其中，MARBERTv2表现最佳，准确率为65%，F1分数为64%。通过采用最先进的预处理技术和最新的NLP模型，本文揭示了阿拉伯方言识别中的主要语言问题。研究结果支持了诸如个性化聊天机器人（以用户方言回应）、社交媒体监控以及提升阿拉伯语社区可访问性等应用。

</details>


### [40] [Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR](https://arxiv.org/abs/2506.19761)
**中文标题：准确、快速、廉价：三者兼得——用双向循环注意力替代多头注意力实现长语音识别**

*Martin Ratajczak,Jean-Philippe Robichaud,Jennifer Drexler Fox*

主要分类: cs.CL

摘要简述: 本文提出了一种双向循环注意力（RA）层替代多头注意力（MHA）的方法，用于长语音识别（ASR）。RA在保持高精度的同时显著提升了效率，并通过新型正则化方法进一步优化性能。


<details>
  <summary>详细信息</summary>
研究动机: 长语音识别研究中，基于多头注意力（MHA）的模型因序列长度的二次复杂度而不适用。本文旨在探索线性复杂度的循环注意力（RA）层，以解决这一问题。

研究方法: 提出双向RA层，与MHA在精度上相当；开发长形式训练范式提升RA性能；提出方向丢弃（Direction Dropout）正则化方法，优化精度与吞吐量的权衡。

研究结果: 双向RA在短、长语音识别中均达到与MHA相当的精度，且效率更高；长形式训练使RA比基线LCA精度更高，吞吐量提升44%；方向丢弃进一步提升了性能。

研究结论: 双向RA是一种高效且精确的长语音识别解决方案，通过方向丢弃和交替方向解码模式进一步优化了性能与效率的平衡。

中文摘要: 长语音识别是一个日益受到关注的研究领域。基于多头注意力（MHA）的ASR模型因序列长度的二次复杂度而不适用于长语音识别。我们基于近期研究，探索了线性复杂度的循环注意力（RA）层在ASR中的应用。研究发现，双向RA层在短、长语音识别中均能达到与MHA相当的精度。我们提出了一个强基线——有限上下文注意力（LCA），并证明RA层在保持精度的同时更高效。通过开发长形式训练范式，RA性能进一步提升，比LCA精度更高且吞吐量提升44%。此外，我们提出了方向丢弃（Direction Dropout）这一新型正则化方法，不仅提升了精度，还实现了精度与吞吐量的精细权衡，并支持交替方向解码模式，进一步提高了吞吐量。

</details>


### [41] [SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning](https://arxiv.org/abs/2506.19767)
**中文标题：SRFT：一种结合监督与强化微调的单阶段推理方法**

*Yuqian Fu,Tinghong Chen,Jiajun Chai,Xihuai Wang,Songjun Tu,Guojun Yin,Wei Lin,Qichao Zhang,Yuanheng Zhu,Dongbin Zhao*

主要分类: cs.CL

摘要简述: 本文提出了一种单阶段方法SRFT，通过熵感知加权机制统一监督微调（SFT）和强化学习（RL），显著提升大语言模型在推理任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLMs）在推理任务中取得了显著进展，但如何最优整合监督微调（SFT）和强化学习（RL）仍是一个关键挑战。本文旨在通过分析两种范式的差异，提出一种更高效的统一方法。

研究方法: 通过熵感知加权机制，SRFT在单阶段中同时应用SFT和RL，直接优化LLM，而非传统的两阶段方法。该方法结合演示和自我探索的轨迹，实现全局粗粒度与局部细粒度优化的统一。

研究结果: 实验表明，SRFT在五个数学推理基准测试中平均准确率达到59.1%，比无RL方法高出9.0%，在三个分布外基准测试中高出10.9%。

研究结论: SRFT通过熵感知机制有效整合SFT和RL，显著提升了LLM的推理能力，为单阶段优化提供了新思路。

中文摘要: 大语言模型（LLMs）在推理任务中取得了显著进展，但监督微调（SFT）与强化学习（RL）的最优整合仍是一个根本性挑战。通过对基于熵的视角下标记分布、学习动态和整合机制的全面分析，我们揭示了这两种范式的关键差异：SFT引发LLM策略分布的全局粗粒度变化，而RL则进行局部细粒度的选择性优化，熵成为训练效果的关键指标。基于这些观察，我们提出了监督强化微调（SRFT），一种通过熵感知加权机制统一两种微调范式的单阶段方法。我们的方法同时应用SFT和RL，直接利用演示和自我探索轨迹优化LLM，而非通过两阶段顺序方法。大量实验表明，SRFT在五个数学推理基准测试中平均准确率达到59.1%，比无RL方法高出9.0%，在三个分布外基准测试中高出10.9%。

</details>


### [42] [Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models](https://arxiv.org/abs/2506.04689)
**中文标题：网络数据回收：一种提升语言模型预训练数据质量与数量的方法**

*Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li*

主要分类: cs.CL

摘要简述: 本文提出了一种名为REWIRE的方法，通过改写低质量网络文本，将其转化为可用于语言模型预训练的高质量数据，从而突破预训练数据规模限制。实验表明，混合原始高质量文本与改写文本能显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着语言模型规模的扩大，预训练数据的需求急剧增加，但高质量的自然文本资源有限。现有数据过滤流程会丢弃大量低质量文本，导致数据利用率低下。本文旨在探索如何通过改写低质量文本来扩充预训练数据集，以解决数据短缺问题。

研究方法: 提出REWIRE方法，通过指导性改写（guided rewrite）将低质量网络文本转化为高质量数据。该方法将改写后的文本与原始高质量文本混合，用于语言模型预训练。实验在1B、3B和7B规模的DCLM基准上进行。

研究结果: 实验结果显示，混合高质量原始文本与改写文本后，模型在22个多样化任务上的性能分别提升了1.0、1.3和2.5个百分点。改写后的文本中82%来自原本会被丢弃的低质量文档。REWIRE在生成合成数据方面优于其他方法。

研究结论: REWIRE通过改写低质量网络文本，有效扩充了预训练数据集，显著提升了模型性能。该方法为解决预训练数据短缺问题提供了一种简单高效的途径。

中文摘要: 扩展定律预测，大型语言模型的性能随着模型规模和数据规模的增加而提升。实践中，预训练依赖于大规模网络爬取，几乎使用了互联网上所有公开可用的数据源。然而，自然数据的增长速度无法与计算资源供应相匹配。此外，高质量文本的可用性更为有限：数据过滤流程通常会移除初始网络抓取中高达99%的内容以达到最佳性能。为解决预训练扩展的“数据墙”问题，本研究探索了如何转化和回收现有过滤流程中被丢弃的数据。我们提出了REWIRE（通过指导性改写回收网络数据），一种通过改写低质量文档以使其可用于训练的方法。这使我们能够在最终预训练数据集中增加合成数据的比例。在1B、3B和7B规模的DCLM基准实验中，混合高质量原始文本与改写文本后，模型在22个多样化任务上的性能分别提升了1.0、1.3和2.5个百分点，优于仅使用过滤后的网络数据。混合原始与合成数据的训练效果也优于使用两倍网络数据的情况。进一步分析表明，混合文本中约82%来自原本会被丢弃的低质量文档的转化。REWIRE在生成合成数据方面也优于其他相关方法，包括维基百科式改写、问答合成和知识提取。这些结果表明，回收网络文本可能是一种简单有效的扩展预训练数据的方法。

</details>


### [43] [Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study](https://arxiv.org/abs/2506.19794)
**中文标题：开源大语言模型为何在数据分析中表现不佳？一项系统实证研究**

*Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Huajun Chen,Ningyu Zhang*

主要分类: cs.CL

摘要简述: 开源大语言模型（LLMs）在数据分析任务中表现不佳，本文通过系统实证研究揭示了其局限性，并提出改进策略。研究发现，战略规划质量是关键因素，交互设计和任务复杂性显著影响推理能力，数据质量比多样性更重要。基于此，作者开发了一种数据合成方法，显著提升了开源LLMs的分析推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 开源大语言模型在数据分析任务中表现不如预期，限制了其在实际应用中的潜力。本文旨在通过系统研究，揭示其局限性并提出改进方法，以提升开源LLMs在数据分析任务中的表现。

研究方法: 作者通过构建一个多样化的真实场景种子数据集，从数据理解、代码生成和战略规划三个维度评估开源LLMs的表现。基于分析结果，开发了一种数据合成方法以提升模型能力。

研究结果: 研究发现：（1）战略规划质量是模型表现的主要决定因素；（2）交互设计和任务复杂性显著影响推理能力；（3）数据质量比多样性对性能提升更重要。通过数据合成方法，开源LLMs的分析推理能力得到显著提升。

研究结论: 开源LLMs在数据分析任务中的表现受战略规划、交互设计和数据质量影响较大。通过优化这些因素，尤其是数据合成方法，可以显著提升其分析推理能力。

中文摘要: 大语言模型（LLMs）在自动化数据分析任务中展现出潜力，但开源模型在这些需要高强度推理的场景中面临显著限制。本研究探讨了提升开源LLMs数据分析能力的策略。通过构建一个多样化的真实场景种子数据集，我们从数据理解、代码生成和战略规划三个维度评估模型表现。分析揭示了三个关键发现：（1）战略规划质量是模型表现的主要决定因素；（2）交互设计和任务复杂性显著影响推理能力；（3）数据质量对性能的影响大于多样性。基于这些发现，我们开发了一种数据合成方法，显著提升了开源LLMs的分析推理能力。

</details>


### [44] [How Effectively Can BERT Models Interpret Context and Detect Bengali Communal Violent Text?](https://arxiv.org/abs/2506.19831)
**中文标题：BERT模型在理解和检测孟加拉语社区暴力文本中的有效性如何？**

*Abdullah Khondoker,Enam Ahmed Taufik,Md. Iftekhar Islam Tashik,S M Ishtiak Mahmud,Farig Sadeque*

主要分类: cs.CL

摘要简述: 本研究通过微调BanglaBERT模型，提升了孟加拉语社交媒体文本中煽动社区暴力内容的检测准确率，并采用集成模型进一步优化性能。研究发现模型在上下文理解上存在局限，通过LIME工具揭示了分类错误的原因。


<details>
  <summary>详细信息</summary>
研究动机: 网络仇恨言论的传播导致社区暴力加剧，威胁社会和谐。然而，现有研究对社区暴力文本的分类关注不足。本研究旨在提高孟加拉语文本中煽动社区暴力内容的检测准确性。

研究方法: 研究采用微调的BanglaBERT模型，并通过扩展数据集（新增1,794条实例）解决数据不平衡问题。进一步开发了集成模型，并利用LIME工具分析模型决策。

研究结果: 微调后的BanglaBERT模型宏F1得分为0.60，集成模型提升至0.63。定性分析显示模型在上下文理解上存在困难，LIME揭示了分类错误的具体原因。

研究结论: 本研究展示了NLP和可解释性工具在减少网络社区暴力中的潜力，为未来研究提供了技术基础。

中文摘要: 网络仇恨言论的传播引发了社区暴力，加剧了不同宗教、种族和社会群体间的冲突，对社会和谐构成重大威胁。尽管其重要性显著，但社区暴力文本的分类在现有研究中仍是一个未被充分探索的领域。本研究旨在提高煽动社区暴力文本的检测准确性，重点关注来自社交媒体平台的孟加拉语文本数据。我们引入了一种针对此任务微调的BanglaBERT模型，其宏F1得分为0.60。为解决数据不平衡问题，我们扩展了数据集，新增了1,794条实例，从而开发并评估了一种微调集成模型。该集成模型表现出更高的性能，宏F1得分达到0.63，凸显了其在此领域的有效性。除了定量性能指标外，定性分析揭示了模型在上下文理解上的困难，导致偶尔出现高置信度下的错误分类。通过分析词语间的余弦相似度，我们发现了预训练BanglaBERT模型在区分密切相关的社区和非社区术语方面的局限性。为进一步解释模型的决策，我们应用了LIME工具，揭示了模型在理解上下文时的具体问题，这些问题是分类错误的原因。这些发现展示了NLP和可解释性工具在减少网络社区暴力中的潜力。我们的研究为社区暴力检测领域的研究提供了基础，并为未来改进这些技术以提高准确性和社会影响奠定了基础。

</details>


### [45] [MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration](https://arxiv.org/abs/2506.19835)
**中文标题：MAM：基于角色分工协作的多模态医学诊断模块化多智能体框架**

*Yucheng Zhou,Lingran Song,Jianbing Shen*

主要分类: cs.CL

摘要简述: 论文提出了一种模块化多智能体框架MAM，通过角色分工协作提升多模态医学诊断能力，实验表明其性能显著优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前统一的多模态医学大语言模型在知识更新成本、全面性和灵活性方面存在局限，亟需一种更高效的解决方案。

研究方法: MAM框架将医学诊断过程分解为多个角色（全科医生、专科团队、放射科医生、医疗助理和主任），每个角色由基于大语言模型的智能体承担，实现模块化协作。

研究结果: 在多种公开的多模态医学数据集上，MAM性能显著优于特定模态的大语言模型，提升幅度达18%至365%。

研究结论: MAM通过角色分工和模块化协作，显著提升了多模态医学诊断的效率和性能，为未来医学AI的发展提供了新思路。

中文摘要: 近年来，医学大语言模型（LLMs）在推理和诊断能力方面展现出强大潜力。然而，当前统一的多模态医学LLMs在知识更新成本、全面性和灵活性方面存在局限。为解决这些问题，我们提出了模块化多智能体框架MAM，用于多模态医学诊断。基于角色分配和诊断辨别能力的实证研究，MAM将医学诊断过程分解为多个角色：全科医生、专科团队、放射科医生、医疗助理和主任，每个角色由基于LLM的智能体承担。这一模块化协作框架支持高效知识更新，并充分利用现有医学LLMs和知识库。在涵盖文本、图像、音频和视频的多种公开多模态医学数据集上的实验表明，MAM性能显著优于特定模态的LLMs，提升幅度达18%至365%。代码已发布于https://github.com/yczhou001/MAM。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [46] [Correspondence-Free Multiview Point Cloud Registration via Depth-Guided Joint Optimisation](https://arxiv.org/abs/2506.18922)
**中文标题：基于深度引导联合优化的无对应多视角点云配准**

*Yiran Zhou,Yingyu Wang,Shoudong Huang,Liang Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种无需特征匹配的多视角点云配准方法，通过深度信息联合优化点云位姿和全局地图，显著提升了复杂环境下的配准精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多视角点云配准方法依赖特征提取和数据关联，难以在复杂环境中获得全局最优解。本文旨在解决这一问题，提出一种无需显式特征匹配的新方法。

研究方法: 方法将全局地图表示为深度图，利用原始深度信息构建非线性最小二乘优化问题，联合估计点云位姿和全局地图。通过位姿关联多帧点云与全局深度图，隐式完成数据关联，并在优化过程中动态优化。

研究结果: 在真实数据集上的实验表明，该方法在精度上优于现有技术，尤其在特征提取和数据关联困难的复杂环境中表现突出。

研究结论: 本文提出的方法通过深度信息联合优化，避免了传统特征匹配的局限性，显著提升了多视角点云配准的鲁棒性和准确性。

中文摘要: 多视角点云配准是构建全局一致3D模型的基础任务。现有方法通常依赖多帧点云间的特征提取和数据关联，但这些过程在复杂环境中难以获得全局最优解。本文提出了一种无需特征匹配的多视角点云配准方法。具体而言，我们将全局地图表示为深度图，并利用原始深度信息构建非线性最小二乘优化问题，联合估计点云位姿和全局地图。与传统基于特征的捆绑调整方法不同，我们的方法通过位姿将多帧点云与全局深度图关联，从而绕过了显式特征提取和数据关联的挑战。这种数据关联在优化过程中被隐式纳入并动态优化。在真实数据集上的大量实验表明，我们的方法在精度上优于现有技术，尤其在特征提取和数据关联困难的复杂环境中表现优异。

</details>


### [47] [Connecting Vision and Emissions: A Behavioural AI Approach to Carbon Estimation in Road Design](https://arxiv.org/abs/2506.18924)
**中文标题：连接视觉与排放：一种基于行为AI的道路设计碳排放估算方法**

*Ammar K Al Mhdawi,Nonso Nnamoko,Safanah Mudheher Raafat,M. K. S. Al-Mhdawi,Amjad J Humaidi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于YOLOv8改进的实时车辆检测与分类框架，用于估算城市环境中的碳排放。通过结合深度OCR模块和外部车辆数据库验证，实现了高精度的车辆碳排放自动计算。


<details>
  <summary>详细信息</summary>
研究动机: 随着智能交通系统的发展，实时监测车辆碳排放的需求日益增长。然而，现有方法在细粒度识别（如车牌读取）和排放估算方面存在不足，因此需要一种更精确的自动化解决方案。

研究方法: 改进YOLOv8架构，用于实时检测、分割和跟踪车辆；引入深度OCR模块识别车牌并分类车辆类型；通过外部数据库验证车牌信息，确保排放估算的准确性。

研究结果: YOLOv8检测器在边界框和分割掩码上的平均精度分别为71%和70%；字符级OCR准确率高达99%。

研究结论: 该框架结合实时目标检测与深度OCR技术，为智能交通系统中的车辆碳排放监测提供了可扩展的解决方案。

中文摘要: 我们提出了一种改进的YOLOv8实时车辆检测与分类框架，用于估算城市环境中的碳排放。该系统通过增强YOLOv8架构，从实时交通视频流中检测、分割和跟踪车辆。车辆定位后，采用基于深度学习的识别模块读取车牌并分类车辆类型。由于YOLOv8缺乏细粒度识别能力（如车牌读取或车辆属性判定），我们的框架采用混合流程，将检测到的车辆跟踪并裁剪其边界框，传递给深度OCR模块。该OCR系统由多层卷积神经网络（CNN）组成，专门针对字符级检测和车牌解码训练，适用于运动模糊、遮挡和多样字体等复杂条件。此外，识别的车牌信息通过实时API与外部车辆注册数据库交叉验证，确保分类和排放估算的准确性。这种多阶段方法实现了车辆碳排放的精确自动化计算。通过使用包含分割掩码和标注车牌的多样化车辆数据集进行广泛评估，YOLOv8检测器在边界框和分割掩码上的平均精度（mAP@0.5）分别达到约71%和70%。字符级OCR准确率在最佳CNN模型下高达99%。这些结果证实了将实时目标检测与深度OCR结合用于智能交通系统实际部署的可行性，为车辆特定碳排放监测提供了可扩展的自动化解决方案。

</details>


### [48] [Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease](https://arxiv.org/abs/2506.18925)
**中文标题：基于视频的可解释细粒度量化帕金森病指敲测试中的运动特征**

*Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers*

主要分类: cs.CV

摘要简述: 本文提出了一种基于计算机视觉的细粒度方法，用于通过视频记录量化帕金森病（PD）患者的运动特征。该方法通过提取四组临床相关特征，显著提高了运动障碍协会统一帕金森病评分量表（MDS-UPDRS）的预测准确性，并提供了可解释的运动特征量化。


<details>
  <summary>详细信息</summary>
研究动机: 帕金森病（PD）的运动特征量化对监测疾病进展和优化治疗策略至关重要。传统的指敲测试依赖临床医生的主观评估，存在评分者间和评分者内变异性，且无法捕捉个体运动特征。因此，需要一种客观、细粒度的量化方法。

研究方法: 本文提出了一种基于视频记录的计算机视觉方法，提取了四组临床相关特征，分别表征运动减少、运动迟缓、序列效应和犹豫停顿。通过主成分分析和变最大旋转验证了这些特征与四种运动缺陷的对应关系，并进一步细化了序列效应和犹豫停顿的分类。随后，利用这些特征训练机器学习分类器预测MDS-UPDRS评分。

研究结果: 实验基于74名PD患者的视频记录和临床评估数据，结果显示该方法在MDS-UPDRS评分预测上优于现有方法，同时提供了可解释的运动特征量化。此外，视频分析还揭示了序列效应和犹豫停顿的进一步细分特征。

研究结论: 该框架为PD运动特征的客观评估提供了实用解决方案，适用于临床和远程场景。未来需进一步验证其对症状治疗和疾病进展的响应性。

中文摘要: 准确量化帕金森病（PD）的运动特征对监测疾病进展和优化治疗策略至关重要。指敲测试是一种标准运动评估方法，临床医生通过视觉评估患者的敲击表现，并根据敲击幅度、速度和规律性给出总体严重程度评分。然而，这种主观评估易受评分者间和评分者内变异性的影响，且无法捕捉测试中个体运动特征。本文提出了一种基于视频记录的细粒度计算机视觉方法，用于量化PD运动特征。我们提出了四组临床相关特征，分别表征运动减少、运动迟缓、序列效应和犹豫停顿。在74名PD患者的视频记录和临床评估数据上，通过主成分分析和变最大旋转验证了这些视频特征与四种运动缺陷的对应关系。此外，视频分析还进一步细化了序列效应和犹豫停顿的分类。随后，我们利用这些特征训练机器学习分类器预测运动障碍协会统一帕金森病评分量表（MDS-UPDRS）的指敲评分。与现有方法相比，我们的方法在MDS-UPDRS评分预测上具有更高的准确性，同时提供了可解释的个体指敲运动特征量化。总之，该框架为PD运动特征的客观评估提供了实用解决方案，适用于临床和远程场景。未来需进一步验证其对症状治疗和疾病进展的响应性。

</details>


### [49] [Reinforcement Learning-Based Dynamic Grouping for Tubular Structure Tracking](https://arxiv.org/abs/2506.18930)
**中文标题：基于强化学习的动态分组管状结构追踪方法**

*Chong Di,Shuwang Zhou,Da Chen,Jean-Marie Mirebeau,Minglei Shu,Laurent D. Cohen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于强化学习的动态分组方法，用于追踪管状结构（如血管和道路），通过将分段追踪建模为马尔可夫决策过程（MDP），显著提升了计算效率和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 追踪管状结构的最小路径计算面临复杂形态和环境变化的挑战。现有方法分为点模型和分段模型，但分段模型计算效率低且依赖先验形状。本文旨在通过强化学习解决这些问题。

研究方法: 将分段追踪建模为马尔可夫决策过程（MDP），利用Q-Learning动态探索分段图，按需计算边权重并自适应扩展搜索空间，避免预计算图的高成本。

研究结果: 在典型管状结构数据集上的实验表明，该方法显著优于现有的点模型和分段模型，能有效处理复杂拓扑并保持全局路径一致性。

研究结论: 提出的强化学习方法无需依赖大量先验结构知识，即可高效追踪管状结构，为复杂场景提供了鲁棒的解决方案。

中文摘要: 追踪管状结构（如血管和道路）的最小路径计算面临复杂形态和环境变化的挑战。现有方法大致分为两类：基于点模型和基于分段模型的方法。尽管分段模型在许多场景中取得了良好效果，但其计算效率低且严重依赖预设的先验形状。本文提出了一种新框架，将分段追踪建模为马尔可夫决策过程（MDP），采用强化学习方法。我们利用Q-Learning动态探索分段图，按需计算边权重并自适应扩展搜索空间。这一策略避免了预计算图的高成本，并对初始信息不完整具有鲁棒性。在典型管状结构数据集上的实验结果表明，该方法显著优于现有的点模型和分段模型。所提方法能有效处理复杂拓扑，并在不依赖大量先验结构知识的情况下保持全局路径一致性。

</details>


### [50] [Bird's-eye view safety monitoring for the construction top under the tower crane](https://arxiv.org/abs/2506.18938)
**中文标题：塔吊下建筑顶部的鸟瞰安全监控**

*Yanke Wang,Yu Hin Ng,Haobo Liang,Ching-Wei Chang,Hao Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于AI的全自动安全监控系统，用于从鸟瞰视角监测塔吊施工区域，通过融合相机和LiDAR的3D数据定位工人和模块化建筑，避免碰撞并保护工人安全。


<details>
  <summary>详细信息</summary>
研究动机: 随着塔吊操作日益自动化和智能化，解决施工现场的安全问题尤为重要，尤其是在塔吊与建筑顶部之间的工作区域。模块化集成建筑（MiC）的吊装增加了风险，而现有的相机和LiDAR数据未得到充分利用。因此，开发一种高效的安全监控系统至关重要。

研究方法: 研究提出了一种基于AI的全自动安全监控系统，通过融合相机和LiDAR捕获的3D数据，定位工人和模块化建筑。系统采用先进算法实现数据融合，并与硬件和显示系统集成，形成完整的软件管道。

研究结果: 系统成功实现了工人和模块化建筑的3D定位，并通过警报机制避免塔吊碰撞。现场测试验证了系统的准确性和有效性，显示其可作为实用的安全监控工具。

研究结论: 该系统为施工现场提供了一种高效的安全监控解决方案，通过融合多源数据和实时警报，显著提升了工人和塔吊的安全性。

中文摘要: 随着塔吊操作日益自动化和智能化，将自动化技术应用于安全问题变得尤为重要。在施工现场的多种风险管理任务中，从鸟瞰视角保护塔吊与建筑顶部（施工顶部）之间的工人至关重要，尤其是在模块化集成建筑（MiC）吊装时。相机和激光雷达（LiDAR）可以捕获丰富的现场3D信息，但这些数据尚未得到充分利用。考虑到工人和塔吊的安全保护，我们提出了一种基于AI的全自动鸟瞰安全监控系统，用于监测塔吊吊装过程，保护施工顶部的工人并通过警报避免塔吊碰撞。系统通过融合相机和LiDAR捕获的信息，实现了工人和MiC的3D定位。我们探索并实现了最先进的方法，将其集成到提出的软件管道中，并与硬件和显示系统结合。此外，我们对管道中的组件进行了分析，验证了所涉及方法的准确性和有效性。现场的实际显示和可视化证明，该系统可作为施工现场宝贵的安全监控工具。

</details>


### [51] [Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction](https://arxiv.org/abs/2506.18939)
**中文标题：Damba-ST：基于域自适应Mamba的高效城市时空预测**

*Rui An,Yifeng Zhang,Ziran Liang,Wenqi Fan,Yuxuan Liang,Xuequn Shang,Qing Li*

主要分类: cs.CV

摘要简述: Damba-ST是一种基于Mamba的高效城市时空预测模型，通过域自适应状态空间模型和域适配器，解决了跨域泛化问题，同时保持了线性计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于Transformer的模型在跨域城市时空预测中存在计算复杂度高和内存开销大的问题，限制了其实际部署和扩展性。Mamba虽然高效，但直接应用于时空预测会导致性能下降。因此，需要一种既能保持高效性又能适应异构域的模型。

研究方法: Damba-ST提出两种创新：1) 域自适应状态空间模型，将潜在表示空间划分为共享子空间和域特定子空间；2) 三种域适配器，作为域感知代理，桥接不同域分布并促进跨域共性对齐。

研究结果: 实验表明，Damba-ST在预测任务中达到最优性能，并表现出强大的零样本泛化能力，无需大量重新训练即可在新环境中部署。

研究结论: Damba-ST通过域自适应机制和高效计算，显著提升了城市时空预测的泛化能力和实用性，为跨域部署提供了有效解决方案。

中文摘要: 训练能够跨多样区域和城市泛化的城市时空基础模型，对于在未见或数据稀缺区域部署城市服务至关重要。现有研究通常专注于融合跨域时空数据以训练统一的基于Transformer的模型，但这些模型因二次计算复杂度和高内存开销而限制了其扩展性和实际部署。受Mamba（一种具有线性时间复杂度的状态空间模型）的高效性启发，我们探索了其在高效城市时空预测中的潜力。然而，直接将Mamba作为时空骨干会导致负迁移和性能严重下降，主要原因是时空异质性和Mamba隐藏状态更新的递归机制限制了跨域泛化。为解决这些问题，我们提出了Damba-ST，一种基于域自适应Mamba的新型高效城市时空预测模型。Damba-ST保留了Mamba的线性复杂度优势，同时显著增强了对异构域的适应性。具体而言，我们引入了两项核心创新：(1) 域自适应状态空间模型，将潜在表示空间划分为共享子空间（用于学习跨域共性）和独立的域特定子空间（用于捕获域内判别性特征）；(2) 三种不同的域适配器，作为域感知代理，桥接不同域分布并促进跨域共性的对齐。大量实验证明了Damba-ST的泛化能力和高效性。它在预测任务中达到了最优性能，并表现出强大的零样本泛化能力，无需大量重新训练或微调即可在新城市环境中无缝部署。

</details>


### [52] [From Pixels and Words to Waves: A Unified Framework for Spectral Dictionary vLLMs](https://arxiv.org/abs/2506.18943)
**中文标题：从像素和词语到波形：频谱字典vLLMs的统一框架**

*Andrew Kiruluta,Priscilla Burity*

主要分类: cs.CV

摘要简述: 本文提出了一种基于频谱字典的视觉语言模型（SDict-VLM），通过稀疏频率原子表示图像和文本，消除了传统卷积和自注意力机制，实现了高效且可解释的多模态融合。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型（VLMs）依赖计算密集的卷积和自注意力机制，导致效率低下。本文旨在通过频谱字典方法消除这些组件，同时保持性能。

研究方法: 提出频谱字典标记混合器，将图像块或词片段表示为可学习频率原子的稀疏组合，实现O(L log L)复杂度，并支持跨模态对齐。

研究结果: SDict-VLM在MS-COCO字幕任务中达到BLEU-4 39.2、CIDEr 127.5和SPICE 27.0，VQAv2准确率50.3%，性能接近BLIP-2但参数减少60%，推理速度提升2.2倍。

研究结论: 频谱字典方法首次在VLMs中同时消除卷积和自注意力，实现了高效、可解释的多模态融合，为未来研究提供了新方向。

中文摘要: 视觉语言模型（VLMs）将计算机视觉和自然语言处理统一为单一架构，能够解释和描述图像。大多数先进系统依赖两个计算密集型组件：视觉编码器中的卷积和多模态融合中的二次自注意力。本文通过引入频谱字典标记混合器消除了这两者，将每个图像块或词片段表示为可学习频率原子的稀疏组合。我们的1.1B参数原型SDict-VLM在MS-COCO字幕任务中达到BLEU-4 39.2、CIDEr 127.5和SPICE 27.0，VQAv2准确率50.3%。这些结果填补了与BLIP-2约85%的性能差距，同时参数减少60%，峰值GPU内存降低2.3倍，推理速度提升2.2倍。据我们所知，这是首个同时消除卷积和自注意力并匹配中等规模Transformer基线的VLM。其O(L log L)复杂度和共享频率字典支持透明的跨模态对齐，并提供了精度与计算之间的可调权衡，为高效且可解释的VLMs铺平了道路。

</details>


### [53] [DiffRIS: Enhancing Referring Remote Sensing Image Segmentation with Pre-trained Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18946)
**中文标题：DiffRIS：利用预训练文本到图像扩散模型增强遥感图像分割**

*Zhe Dong,Yuzhe Sun,Tianzhu Liu,Yanfeng Gu*

主要分类: cs.CV

摘要简述: DiffRIS利用预训练的文本到图像扩散模型提升遥感图像分割任务，通过上下文感知适配器和渐进式跨模态解码器实现精准分割，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 遥感图像分割任务（RRSIS）在灾害响应、城市发展和环境监测中至关重要，但现有方法因复杂物体特性（如尺度变化、多样方向和语义模糊）面临挑战。DiffRIS旨在通过预训练扩散模型的语义理解能力解决这些问题。

研究方法: DiffRIS提出两个创新：1) 上下文感知适配器（CP-adapter），通过全局上下文建模和对象感知推理动态优化语言特征；2) 渐进式跨模态推理解码器（PCMRD），通过多尺度特征交互实现文本与视觉区域的精细对齐。

研究结果: 在三个基准数据集（RRSIS-D、RefSegRS和RISBench）上的实验表明，DiffRIS在所有标准指标上均优于现有方法，确立了新的性能标杆。

研究结论: DiffRIS通过预训练扩散模型和自适应框架显著提升了遥感图像分割任务的性能，验证了其在跨模态对齐中的有效性。

中文摘要: 遥感图像分割（RRSIS）通过自然语言描述实现对遥感图像中区域的精确划分，在灾害响应、城市发展和环境监测中具有重要应用。尽管已有进展，现有方法在处理航空影像时仍面临尺度变化、多样方向和语义模糊等挑战。为此，我们提出DiffRIS，一种利用预训练文本到图像扩散模型语义理解能力的新框架，以提升RRSIS任务中的跨模态对齐。DiffRIS包含两项关键创新：1) 上下文感知适配器（CP-adapter），通过全局上下文建模和对象感知推理动态优化语言特征；2) 渐进式跨模态推理解码器（PCMRD），通过多尺度特征交互实现文本与视觉区域的精细对齐。CP-adapter弥合了通用视觉语言理解与遥感应用之间的领域差距，而PCMRD则通过多尺度特征交互实现细粒度语义对齐。在三个基准数据集（RRSIS-D、RefSegRS和RISBench）上的实验表明，DiffRIS在所有标准指标上均优于现有方法，确立了新的性能标杆。显著的性能提升验证了通过自适应框架利用预训练扩散模型在遥感应用中的有效性。

</details>


### [54] [GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs](https://arxiv.org/abs/2506.18985)
**中文标题：GLIMPSE：基于梯度层重要性映射的生成式大型视觉语言模型视觉显著性解释**

*Guanxi Shen*

主要分类: cs.CV

摘要简述: GLIMPSE是一种轻量级、模型无关的框架，用于可视化大型视觉语言模型（LVLM）在开放视觉问答（VQA）中依赖的显著图像区域，同时揭示多模态文本显著性。该方法融合梯度加权注意力、自适应层传播和加权令牌聚合，生成整体响应级归因热图，优于现有可解释性方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型视觉语言模型（LVLM）在生成连贯响应方面表现出色，但解释其在生成自由文本响应时的视觉注意力仍是一个挑战。理解模型行为、诊断幻觉、暴露偏见和确保透明度需要可视化模型依赖的显著区域。

研究方法: GLIMPSE通过融合梯度加权注意力、自适应层传播和加权令牌聚合，生成响应级归因热图，用于解释跨模态推理。该方法轻量且模型无关。

研究结果: GLIMPSE在人类对齐方面优于现有可解释性方法，能够揭示LVLM的跨模态归因细节、跟踪令牌级推理动态，并分析系统性人类注意力偏差、幻觉和偏见。

研究结论: GLIMPSE为理解LVLM的跨模态推理提供了精细的可视化工具，有助于诊断模型行为、发现偏见和幻觉，并提升模型透明度。

中文摘要: 大型视觉语言模型（LVLM）的最新进展使其能够从视觉输入生成连贯的响应。然而，解释LVLM在生成自由文本响应时的视觉注意力仍是一个重大挑战，但对理解模型行为、诊断幻觉、暴露偏见和确保透明度至关重要。我们提出了GLIMPSE（基于梯度层重要性映射的视觉显著性解释），这是一种轻量级、模型无关的框架，用于可视化LVLM在开放视觉问答（VQA）中依赖的显著图像区域，同时揭示多模态文本显著性。GLIMPSE融合了梯度加权注意力、自适应层传播和加权令牌聚合，生成整体响应级归因热图，用于解释跨模态推理，在人类对齐方面优于现有可解释性方法。我们展示了使用GLIMPSE的分析性可解释AI（XAI）方法，以揭示LVLM跨模态归因的精细细节、跟踪令牌级推理动态，并分析系统性人类注意力偏差、幻觉和偏见。

</details>


### [55] [Diffusion Transformer-to-Mamba Distillation for High-Resolution Image Generation](https://arxiv.org/abs/2506.18999)
**中文标题：扩散Transformer到Mamba的蒸馏用于高分辨率图像生成**

*Yuan Yao,Yicong Hong,Difan Liu,Long Mai,Feng Liu,Jiebo Luo*

主要分类: cs.CV

摘要简述: 本文提出了一种扩散Transformer到Mamba的蒸馏方法（T2MD），通过高效训练流程将自注意力Transformer转换为线性复杂度的Mamba模型，解决了高分辨率图像生成中的计算成本问题。


<details>
  <summary>详细信息</summary>
研究动机: 自注意力Transformer在高分辨率图像生成中计算复杂度高，而线性复杂度的Mamba模型虽为潜在替代方案，但直接训练存在挑战。为此，本文旨在通过蒸馏方法实现高效过渡。

研究方法: 提出T2MD方法，结合扩散自注意力和Mamba混合模型，采用层级教师强制和基于特征的知识蒸馏，减轻从头训练状态空间模型的难度和成本。

研究结果: 实验表明，T2MD在512×512分辨率基础上，通过轻量级适应和高分辨率微调，实现了2048×2048图像的低开销高质量生成。

研究结论: T2MD证明了Mamba模型用于非因果视觉输出的可行性，为未来探索提供了潜力。

中文摘要: 自注意力在扩散Transformer（DiT）中的二次计算复杂度为高分辨率图像生成带来了显著计算成本。尽管线性复杂度的Mamba模型成为潜在替代方案，但其直接训练仍具有实证挑战。为解决这一问题，本文提出扩散Transformer到Mamba的蒸馏（T2MD），形成高效训练流程，促进从基于自注意力的Transformer向线性复杂度状态空间模型Mamba的过渡。我们建立了一种扩散自注意力和Mamba混合模型，同时实现效率和全局依赖性。通过提出的层级教师强制和基于特征的知识蒸馏，T2MD减轻了从头训练状态空间模型的难度和高成本。从蒸馏的512×512分辨率基础模型出发，我们通过轻量级适应和高分辨率微调将生成推向2048×2048图像。实验表明，我们的训练路径实现了低开销但高质量的文本到图像生成。重要的是，我们的结果还证明了使用顺序和因果Mamba模型生成非因果视觉输出的可行性，为未来探索提供了潜力。

</details>


### [56] [Orthogonal Projection Subspace to Aggregate Online Prior-knowledge for Continual Test-time Adaptation](https://arxiv.org/abs/2506.19022)
**中文标题：正交投影子空间聚合在线先验知识以实现持续测试时间适应**

*Jinlong Li,Dong Zhao,Qi Zang,Zequn Jie,Lin Ma,Nicu Sebe*

主要分类: cs.CV

摘要简述: 本文提出了一种名为OoPk的新方法，通过正交投影子空间聚合在线先验知识，解决了持续测试时间适应（CTTA）中的灾难性遗忘和错误累积问题，并在语义分割任务中取得了优异性能。


<details>
  <summary>详细信息</summary>
研究动机: 持续测试时间适应（CTTA）任务要求源预训练模型不断适应目标分布变化的新场景。现有方法虽关注灾难性遗忘和错误累积，但在复杂任务（如语义分割）中难以平衡性能与高效适应。本文旨在解决这些问题。

研究方法: 提出OoPk方法：1）正交投影调谐子空间，保留源模型知识完整性；2）在线先验知识聚合策略，通过高效图像掩码模拟目标动态性，提升学生模型适应性，并优化教师模型知识以减少错误累积。

研究结果: 实验表明，OoPk在多个持续TTA基准测试中超越现有方法，尤其在语义分割任务中表现优异。

研究结论: OoPk通过正交投影和在线知识聚合，有效解决了CTTA中的灾难性遗忘和错误累积问题，为复杂任务提供了高效适应方案。

中文摘要: 持续测试时间适应（CTTA）任务要求源预训练模型不断适应目标分布变化的新场景。现有CTTA方法主要关注缓解灾难性遗忘和错误累积的挑战。尽管已有基于参数高效微调的遗忘适应方法，但在复杂任务（如语义分割）中仍难以平衡性能与高效适应。本文提出了一种名为OoPk的新流程：首先正交投影调谐子空间，使模型适应新域的同时保留源模型知识完整性；其次设计在线先验知识聚合策略，通过高效图像掩码模拟目标动态性，增强学生模型适应性，并逐步优化教师模型知识以减少错误累积。实验表明，OoPk在多个持续TTA基准测试中超越现有方法，尤其在语义分割任务中表现优异。

</details>


### [57] [LEGATO: Large-scale End-to-end Generalizable Approach to Typeset OMR](https://arxiv.org/abs/2506.19065)
**中文标题：LEGATO：一种大规模端到端可泛化的排版光学音乐识别方法**

*Guang Yang,Victoria Ebert,Nazif Tamer,Luiza Pozzobon,Noah A. Smith*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Legato的新型端到端Transformer模型，用于光学音乐识别（OMR）。该模型首次实现了大规模预训练，能够识别整页或多页排版乐谱，并生成简洁易读的ABC符号音乐格式。通过结合预训练的视觉编码器和ABC解码器，模型在多种排版乐谱上表现出强大的泛化能力，并在实验中达到了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前光学音乐识别（OMR）领域缺乏能够处理整页或多页排版乐谱的端到端模型，且现有方法在泛化能力和输出格式上存在局限。本文旨在填补这一空白，提出一种能够高效识别复杂乐谱并生成人类可读符号音乐的解决方案。

研究方法: Legato模型结合了预训练的视觉编码器和ABC解码器，训练数据集包含超过214K张图像。模型通过端到端的方式直接处理乐谱图像，并生成ABC符号音乐格式。实验在多个数据集上进行，使用了多样化的评估指标。

研究结果: 实验结果表明，Legato模型在多种排版乐谱上表现出卓越的泛化能力，并在性能上超越了现有最先进方法。模型在ABC符号音乐生成方面也表现出色。

研究结论: Legato是首个能够处理整页或多页排版乐谱的端到端OMR模型，其强大的泛化能力和高效的ABC符号音乐生成能力为OMR领域提供了新的解决方案。

中文摘要: 我们提出了Legato，一种用于光学音乐识别（OMR）的新型端到端Transformer模型。Legato是首个能够识别整页或多页排版乐谱的大规模预训练OMR模型，也是首个能够生成ABC符号音乐格式（一种简洁、人类可读的符号音乐表示）的模型。通过将预训练的视觉编码器与基于超过214K图像数据集的ABC解码器相结合，我们的模型展现了在多种排版乐谱上的强大泛化能力。我们在多个数据集上进行了实验，结果表明我们的模型达到了最先进的性能。鉴于端到端OMR缺乏标准化评估，我们使用多样化的指标将我们的模型与现有最先进方法进行了全面比较。

</details>


### [58] [HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models](https://arxiv.org/abs/2506.19072)
**中文标题：HAWAII：分层视觉知识迁移用于高效视觉语言模型**

*Yimu Wang,Mozhgan Nasr Azadani,Sean Sedwards,Krzysztof Czarnecki*

主要分类: cs.CV

摘要简述: 论文提出HAWAII框架，通过多视觉专家知识蒸馏到单一视觉编码器，减少计算开销，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 提升视觉语言模型（VLMs）的视觉理解能力是关键，但多视觉专家方法计算成本高。

研究方法: HAWAII使用教师特定的LoRA适配器和路由器，避免冲突；采用细粒度和粗粒度蒸馏策略，分别强调关键令牌和总结多教师知识。

研究结果: 实验表明，HAWAII在多种视觉语言任务中优于主流开源VLMs。

研究结论: HAWAII通过高效知识蒸馏，显著提升模型性能且降低计算成本。

中文摘要: 提升视觉语言模型（VLMs）的视觉理解能力对增强其在多种任务中的表现至关重要。尽管使用多个预训练视觉专家显示出巨大潜力，但其在训练和推理过程中往往带来显著的计算成本。为解决这一问题，我们提出HAWAII，一种新颖框架，将多视觉专家的知识蒸馏到单一视觉编码器中，使其以最小计算开销继承多个专家的互补优势。为避免不同教师间的冲突并切换教师特定知识，我们提出使用教师特定的低秩适应（LoRA）适配器及对应路由器，而非固定适配器组。每个适配器与特定教师对齐，避免蒸馏过程中的噪声指导。为实现高效知识蒸馏，我们提出细粒度和粗粒度蒸馏策略。在细粒度层面，利用令牌重要性评分自适应强调每位教师的最具信息量令牌；在粗粒度层面，总结多教师知识并通过一组通用知识LoRA适配器和路由器传递给学生。在多种视觉语言任务上的广泛实验证明了HAWAII相对于主流开源VLMs的优越性。

</details>


### [59] [Reading Smiles: Proxy Bias in Foundation Models for Facial Emotion Recognition](https://arxiv.org/abs/2506.19079)
**中文标题：解读微笑：面部情绪识别基础模型中的代理偏见**

*Iosif Tsangko,Andreas Triantafyllopoulos,Adem Abdelmoula,Adria Mallol-Ragolta,Bjoern W. Schuller*

主要分类: cs.CV

摘要简述: 本文探讨了基础模型（FMs）在面部情绪识别中的代理偏见问题，发现模型依赖牙齿可见性等表面线索进行情绪推断，而非心理学基础特征，揭示了潜在的偏见和公平性问题。


<details>
  <summary>详细信息</summary>
研究动机: 研究基础模型在情感计算中依赖的视觉线索是否具有心理学基础，还是仅通过表面学习，以揭示其潜在的偏见和公平性问题。

研究方法: 通过在牙齿标注的AffectNet数据集上测试不同规模的视觉语言模型（VLMs），并对表现最佳的GPT-4o进行结构化内省，分析其情绪推理依赖的面部属性。

研究结果: 研究发现模型性能受牙齿可见性影响显著，且GPT-4o的情绪推理主要依赖眉毛位置等面部属性，显示出其效价-唤醒预测的高度内部一致性。

研究结论: 基础模型的行为具有涌现性，但也存在捷径学习、偏见和公平性问题，尤其在心理健康和教育等敏感领域需引起重视。

中文摘要: 基础模型（FMs）正在快速改变情感计算（AC），视觉语言模型（VLMs）现在能够在零样本设置中识别情绪。本文探讨了一个关键但未被充分研究的问题：这些模型依赖哪些视觉线索来推断情感，这些线索是基于心理学基础还是表面学习？我们在牙齿标注的AffectNet数据集子集上对不同规模的VLMs进行基准测试，发现性能变化与牙齿可见性相关。通过对表现最佳的模型GPT-4o进行结构化内省，我们发现其情绪推理主要依赖眉毛位置等面部属性，揭示了其效价-唤醒预测的高度内部一致性。这些模式凸显了FMs行为的涌现性，但也揭示了风险：捷径学习、偏见和公平性问题，尤其是在心理健康和教育等敏感领域。

</details>


### [60] [RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation](https://arxiv.org/abs/2506.19087)
**中文标题：RareSpot：基于多尺度一致性和上下文感知增强的航空影像中小型稀有野生动物检测**

*Bowen Zhang,Jesse T. Boulerice,Nikhil Kuniyil,Charvi Mendiratta,Satish Kumar,Hila Shamon,B. S. Manjunath*

主要分类: cs.CV

摘要简述: RareSpot提出了一种结合多尺度一致性学习和上下文感知增强的检测框架，用于解决航空影像中小型稀有野生动物的检测难题，显著提升了检测精度。


<details>
  <summary>详细信息</summary>
研究动机: 小型稀有野生动物（如草原犬鼠）在航空影像中难以检测，其生态重要性与其稀疏分布和微小体型形成鲜明对比，现有方法效果不佳。RareSpot旨在解决这一问题。

研究方法: RareSpot通过多尺度一致性学习增强细粒度目标表示，减少尺度相关特征损失；同时利用上下文感知增强技术合成具有挑战性的训练样本，提升模型性能。

研究结果: 在专家标注的草原犬鼠无人机影像基准测试中，RareSpot检测精度比基线方法提高了35%以上，并在其他野生动物数据集上表现出良好的泛化能力。

研究结论: RareSpot为复杂航空场景中小型稀有物种的检测提供了新方法，支持生态监测，并具有广泛适用性。

中文摘要: 航空影像中小型和稀有野生动物的自动检测对保护工作至关重要，但仍是一项重大技术挑战。以草原犬鼠为例，其作为关键物种的生态重要性与其稀疏分布、微小体型和细微视觉特征形成鲜明对比，导致现有检测方法效果不佳。为解决这一问题，我们提出了RareSpot，一种结合多尺度一致性学习和上下文感知增强的鲁棒检测框架。多尺度一致性方法通过特征金字塔的结构对齐增强细粒度目标表示，减少尺度相关特征损失；同时，上下文感知增强通过将难以检测的样本嵌入真实环境背景中，显著提升模型的精确率和召回率。在专家标注的草原犬鼠无人机影像基准测试中，我们的方法实现了最先进的性能，检测精度比基线方法提高了35%以上，并在其他野生动物数据集上表现出良好的泛化能力。RareSpot的基准和方法不仅支持关键生态监测，还为复杂航空场景中小型稀有物种的检测奠定了基础。

</details>


### [61] [Inverse-and-Edit: Effective and Fast Image Editing by Cycle Consistency Models](https://arxiv.org/abs/2506.19103)
**中文标题：逆向与编辑：基于循环一致性模型的高效快速图像编辑**

*Ilia Beletskii,Andrey Kuznetsov,Aibek Alanov*

主要分类: cs.CV

摘要简述: 本文提出了一种基于一致性模型的新型图像编辑框架，通过循环一致性优化策略显著提升重建精度，仅需四步即可实现高质量编辑，同时平衡编辑性与内容保留。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散模型的图像编辑方法计算成本高，且蒸馏模型因反转质量差导致编辑能力有限。高保真反转和重建对精确编辑至关重要，因此本文旨在解决这一问题。

研究方法: 提出了一种结合一致性模型的框架，采用循环一致性优化策略，显著提升重建精度，并实现编辑性与内容保留的可控权衡。

研究结果: 在多种图像编辑任务和数据集上达到最先进性能，匹配或超越全步扩散模型，同时效率显著提升。

研究结论: 该方法通过高效的反转和编辑框架，为高质量图像编辑提供了新思路，平衡了速度与精度。

中文摘要: 近年来，基于扩散模型的图像编辑取得了令人瞩目的成果，提供了对生成过程的精细控制。然而，这些方法因其迭代性质而计算密集。尽管蒸馏扩散模型实现了更快的推理，但其编辑能力仍受限于反转质量差。高保真反转和重建对于精确图像编辑至关重要，因为它们保留了源图像的结构和语义完整性。本文提出了一种新颖的框架，利用一致性模型增强图像反转，仅需四步即可实现高质量编辑。我们的方法引入了一种循环一致性优化策略，显著提高了重建精度，并实现了编辑性与内容保留的可控权衡。我们在多种图像编辑任务和数据集上取得了最先进的性能，表明我们的方法在效率显著提升的同时，匹配或超越了全步扩散模型。我们的方法代码已在GitHub上开源：https://github.com/ControlGenAI/Inverse-and-Edit。

</details>


### [62] [PrITTI: Primitive-based Generation of Controllable and Editable 3D Semantic Scenes](https://arxiv.org/abs/2506.19117)
**中文标题：PrITTI：基于基元的可控可编辑3D语义场景生成**

*Christina Ourania Tze,Daniel Dauner,Yiyi Liao,Dzmitry Tsishkou,Andreas Geiger*

主要分类: cs.CV

摘要简述: PrITTI是一种基于基元的3D语义场景生成框架，通过结合潜在扩散模型和混合表示方法，实现了高质量、可控且易于编辑的场景布局生成，显著降低了内存需求。


<details>
  <summary>详细信息</summary>
研究动机: 传统的体素表示方法在3D语义场景生成中存在内存消耗大、分辨率固定和难以编辑的问题。基元作为一种紧凑且易于操作的表示方式，为解决这些问题提供了可能。

研究方法: PrITTI采用混合表示方法，将地面以栅格化形式建模，物体则以矢量化的3D基元表示。通过结构化潜在表示和基于Cholesky的稳定参数化方法，解决了方向模糊性问题。

研究结果: 在KITTI-360数据集上的实验表明，PrITTI在生成质量上优于体素基线，内存需求降低了3倍，并支持实例级场景编辑和多种下游应用。

研究结论: PrITTI通过基元和潜在扩散模型的结合，为3D语义场景生成提供了一种高效、可控且灵活的解决方案。

中文摘要: 大规模3D语义场景生成主要依赖于体素表示方法，但这种方法内存消耗大、分辨率固定且难以编辑。相比之下，基元通过紧凑的粗粒度3D结构表示语义实体，易于操作和组合，非常适合此类任务。本文提出PrITTI，一种基于潜在扩散的框架，利用基元作为生成组合式、可控且可编辑的3D语义场景布局的基础元素。我们的方法采用混合表示，将地面以栅格化形式建模，物体则以矢量化的3D基元表示。这种分解也体现在结构化潜在表示中，支持对地面和物体组件的灵活场景操作。为解决传统编码方法中的方向模糊性问题，我们提出了一种基于Cholesky的稳定参数化方法，联合编码物体尺寸和方向。在KITTI-360数据集上的实验表明，PrITTI在生成质量上优于体素基线，同时将内存需求降低了3倍。此外，PrITTI支持对场景中物体的直接实例级操作，并支持一系列下游应用，包括场景修复、扩展和逼真的街景合成。

</details>


### [63] [Lightweight RGB-T Tracking with Mobile Vision Transformers](https://arxiv.org/abs/2506.19154)
**中文标题：基于Mobile Vision Transformers的轻量级RGB-T跟踪**

*Mahdi Falaki,Maria A. Amer*

主要分类: cs.CV

摘要简述: 本文提出了一种基于MobileViT的轻量级RGB-T跟踪算法，通过渐进式融合框架和可分离注意力机制，实现了高效的多模态目标跟踪，模型参数少于400万，GPU推理速度达122帧/秒。


<details>
  <summary>详细信息</summary>
研究动机: 单模态（如RGB）目标跟踪在低光照和恶劣天气等复杂条件下表现不佳，而现有基于Vision Transformer的多模态跟踪器计算成本高。本文旨在设计一种轻量高效的RGB-T跟踪算法。

研究方法: 采用Mobile Vision Transformers（MobileViT）构建渐进式融合框架，通过可分离注意力机制联合学习模板与搜索区域的模态内和模态间交互，生成高效特征表示。

研究结果: 模型参数少于400万，GPU推理速度达122帧/秒，性能与当前高效多模态跟踪器相当，但计算成本显著降低。

研究结论: 本文首次将MobileViT应用于RGB-T及多模态跟踪，实现了轻量化和高效性，代码和模型权重将公开。

中文摘要: 单模态目标跟踪（如仅RGB）在低光照和恶劣天气等复杂成像条件下表现不佳。为解决这一问题，多模态跟踪（如RGB-T模型）旨在利用热红外等互补数据。尽管近期基于Vision Transformer的多模态跟踪器性能强劲，但由于模型规模大，计算成本较高。本文提出了一种基于Mobile Vision Transformers（MobileViT）的新型轻量级RGB-T跟踪算法。该跟踪器采用渐进式融合框架，通过可分离注意力机制联合学习模板与搜索区域的模态内和模态间交互，生成高效特征表示，支持更精确的目标定位，同时实现小模型规模和快速推理速度。与当前高效多模态跟踪器相比，本模型在参数数量（少于400万）和GPU推理速度（122帧/秒）上均显著领先，且性能相当。本文首次将MobileViT应用于RGB-T及多模态跟踪领域，代码和模型权重将在接受后公开。

</details>


### [64] [PRISM: Perceptual Recognition for Identifying Standout Moments in Human-Centric Keyframe Extraction](https://arxiv.org/abs/2506.19168)
**中文标题：PRISM：基于感知识别的以人为中心的关键帧提取中突出时刻识别**

*Mert Can Cakmak,Nitin Agarwal,Diwash Poudel*

主要分类: cs.CV

摘要简述: PRISM是一种轻量级且符合人类感知的关键帧提取框架，通过CIELAB色彩空间和感知色差指标识别突出帧，适用于实时和资源受限环境。


<details>
  <summary>详细信息</summary>
研究动机: 在线视频在政治话语和网络社会威胁（如错误信息、宣传和极端化）中扮演重要角色。检测视频中最具影响力的“突出”时刻对内容审核、摘要和法医分析至关重要。

研究方法: PRISM在CIELAB色彩空间中运行，使用感知色差指标识别符合人类视觉敏感性的帧。与基于深度学习的方法不同，PRISM具有可解释性、无需训练且计算高效。

研究结果: 在BBC、TVSum、SumMe和ClipShots四个基准数据集上评估，PRISM表现出高准确性和保真度，同时保持高压缩比。

研究结论: PRISM在结构化和非结构化视频内容中均表现优异，有望成为分析和审核在线平台有害或政治敏感媒体的可扩展工具。

中文摘要: 在线视频在塑造政治话语和放大网络社会威胁（如错误信息、宣传和极端化）中发挥核心作用。检测视频中最具影响力的“突出”时刻对内容审核、摘要和法医分析至关重要。本文介绍了PRISM（基于感知识别的突出时刻识别），一种轻量级且符合人类感知的关键帧提取框架。PRISM在CIELAB色彩空间中运行，使用感知色差指标识别符合人类视觉敏感性的帧。与基于深度学习的方法不同，PRISM具有可解释性、无需训练且计算高效，非常适合实时和资源受限的环境。我们在BBC、TVSum、SumMe和ClipShots四个基准数据集上评估PRISM，结果表明其在保持高压缩比的同时实现了高准确性和保真度。这些结果突显了PRISM在结构化和非结构化视频内容中的有效性，以及其作为分析和审核在线平台有害或政治敏感媒体的可扩展工具的潜力。

</details>


### [65] [MOSCARD -- Causal Reasoning and De-confounding for Multimodal Opportunistic Screening of Cardiovascular Adverse Events](https://arxiv.org/abs/2506.19174)
**中文标题：MOSCARD——多模态心血管不良事件机会性筛查中的因果推理与去混杂**

*Jialu Pi,Juan Maria Farina,Rimita Lahiri,Jiwoong Jeong,Archana Gurudu,Hyung-Bok Park,Chieh-Ju Chao,Chadi Ayoub,Reza Arsanjani,Imon Banerjee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MOSCARD的新型预测模型框架，通过多模态因果推理和共注意力机制整合胸部X光（CXR）和心电图（ECG）数据，以更全面地评估心血管不良事件（MACE）风险，并减少偏差和混杂因素。模型在内部和外部数据集上表现优于单模态和现有先进模型。


<details>
  <summary>详细信息</summary>
研究动机: 心血管不良事件（MACE）是全球主要的死亡原因，而现有的风险评估方法多依赖于单一模态数据或临床评分，存在采样偏差和局限性。多模态数据（如CXR和ECG）的整合有望提供更全面的风险评估，但需要解决模态对齐和混杂因素问题。

研究方法: MOSCARD框架通过以下技术实现多模态整合：（1）在ECG指导下对齐CXR数据；（2）引入因果推理；（3）使用双重反向传播图减少混杂因素。模型在内部急诊科数据和外部MIMIC数据集上进行评估。

研究结果: MOSCARD在内部数据集上的AUC为0.75，在急诊科数据上为0.83，在MIMIC数据集上为0.71，均优于单模态和现有先进模型。

研究结论: MOSCARD提供了一种低成本、高效的心血管不良事件筛查方法，能够通过早期干预改善患者预后并减少健康差异。

中文摘要: 根据2021年全球疾病负担研究，心血管不良事件（MACE）仍是全球主要的死亡原因。机会性筛查利用常规健康检查中收集的数据，多模态数据在识别高风险个体方面具有重要作用。胸部X光（CXR）可揭示导致MACE的慢性疾病，而12导联心电图（ECG）可直接评估心脏电活动和结构异常。整合CXR和ECG可提供比依赖临床评分、CT测量或生物标志物的传统模型更全面的风险评估，后者的局限性在于采样偏差和单一模态约束。我们提出了一种新型预测模型框架——MOSCARD，通过多模态因果推理和共注意力机制对齐两种模态，同时减少机会性风险评估中的偏差和混杂因素。主要技术贡献包括：（1）在ECG指导下对齐CXR；（2）因果推理的整合；（3）用于去混杂的双重反向传播图。在内部急诊科数据和外部MIMIC数据集上的评估表明，我们的模型优于单模态和现有先进模型（AUC分别为0.75、0.83和0.71）。提出的低成本机会性筛查方法可实现早期干预，改善患者预后并减少健康差异。

</details>


### [66] [OpenWildlife: Open-Vocabulary Multi-Species Wildlife Detector for Geographically-Diverse Aerial Imagery](https://arxiv.org/abs/2506.19204)
**中文标题：OpenWildlife：面向地理多样化航空图像的开放词汇多物种野生动物检测器**

*Muhammed Patel,Javier Noa Turnes,Jayden Hsiao,Linlin Xu,David Clausi*

主要分类: cs.CV

摘要简述: OpenWildlife (OW) 是一种开放词汇的野生动物检测器，通过语言感知嵌入和改进的 Grounding-DINO 框架，能够在多样化航空图像中识别多物种，并在新物种上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有自动化方法在特定场景下表现良好，但难以泛化到不同物种和环境，主要受限于有限的分类覆盖和固定模型架构。OW 旨在解决这一问题，提供更灵活的全球生物多样性评估工具。

研究方法: OW 结合语言感知嵌入和改进的 Grounding-DINO 框架，支持自然语言输入的物种识别。此外，采用高效的搜索算法（结合 k-最近邻和广度优先搜索）优先探索社交物种可能出现的区域。

研究结果: OW 在 15 个数据集上训练后表现优异，微调后 mAP50 达 0.981，在 7 个新物种数据集上 mAP50 为 0.597。搜索算法仅探索 33% 的图像即可捕获 95% 的物种。

研究结论: OW 是一种灵活且经济高效的全球生物多样性评估解决方案，其源代码和数据集已公开，支持可重复性研究。

中文摘要: 我们介绍了 OpenWildlife (OW)，一种开放词汇的野生动物检测器，专为多样化航空图像中的多物种识别设计。现有自动化方法在特定场景下表现良好，但由于分类覆盖有限和模型架构固定，难以泛化到不同物种和环境。相比之下，OW 利用语言感知嵌入和改进的 Grounding-DINO 框架，能够通过自然语言输入识别陆地和海洋环境中的物种。在 15 个数据集上训练后，OW 表现优于大多数现有方法，微调后 mAP50 达到 0.981，在 7 个新物种数据集上 mAP50 为 0.597。此外，我们引入了一种高效的搜索算法，结合 k-最近邻和广度优先搜索，优先探索社交物种可能出现的区域。该方法仅探索 33% 的图像即可捕获 95% 的物种。为支持可重复性研究，我们公开了源代码和数据集分割，使 OW 成为全球生物多样性评估的灵活且经济高效的解决方案。

</details>


### [67] [Ancient Script Image Recognition and Processing: A Review](https://arxiv.org/abs/2506.19208)
**中文标题：古文字图像识别与处理综述**

*Xiaolei Diao,Rite Bo,Yanling Xiao,Lida Shi,Zhihan Zhou,Hao Xu,Chuntao Li,Xiongfeng Tang,Massimo Poesio,Cédric M. John,Daqian Shi*

主要分类: cs.CV

摘要简述: 本文综述了古文字图像识别与处理的研究进展，总结了不同文字类型的识别方法、共同挑战及解决方案，并展望了未来发展方向。


<details>
  <summary>详细信息</summary>
研究动机: 古文字（如埃及象形文字、甲骨文、古希腊铭文）是人类文明的重要载体，蕴含丰富的历史文化信息。自动化识别古文字图像对大规模解读和考古学、数字人文研究具有重要意义。随着深度学习的兴起，该领域发展迅速，但仍面临数据分布不均和图像退化等独特挑战。

研究方法: 本文首先根据文字类型对现有研究进行分类，分析各自的识别方法，并强调其差异与共同策略；随后聚焦古文字特有的挑战，系统研究其影响并综述最新解决方案（如少样本学习和噪声鲁棒技术）。

研究结果: 研究总结了古文字图像识别领域的现状，包括不同文字类型的识别方法、共同挑战及应对策略，并指出了当前研究的局限性。

研究结论: 本文为古文字识别、解读和破译提供了结构化、前瞻性的视角，支持该领域的持续发展。

中文摘要: 古文字（如埃及象形文字、甲骨文和古希腊铭文）是人类文明的重要载体，蕴含着宝贵的历史文化信息。自动化古文字图像识别的重要性日益凸显，能够实现大规模解读并推动考古学和数字人文研究的发展。随着深度学习的兴起，该领域进展迅速，涌现了大量针对特定文字的数据集和模型。尽管这些文字差异显著，从音标系统（符号有限）到语标系统（数千复杂符号），但它们面临共同的挑战和方法重叠。此外，古文字还面临数据分布不均和图像退化等独特问题，推动了各种专用方法的发展。本综述全面回顾了古文字图像识别方法。我们首先根据文字类型对现有研究进行分类，分析各自的识别方法，并强调其差异与共同策略；随后聚焦古文字特有的挑战，系统研究其影响并综述最新解决方案（如少样本学习和噪声鲁棒技术）。最后，我们总结了当前局限性并展望了未来发展方向。目标是提供一个结构化、前瞻性的视角，支持古文字识别、解读和破译的持续进步。

</details>


### [68] [MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports](https://arxiv.org/abs/2506.19217)
**中文标题：MedErr-CT：用于识别和纠正CT报告中错误的视觉问答基准**

*Sunggu Kyung,Hyungbin Park,Jinyoung Seo,Jimin Sung,Jihyun Kim,Dongyeong Kim,Wooyoung Jo,Yoojin Nam,Sangah Park,Taehee Kwon,Sang Min Lee,Namkug Kim*

主要分类: cs.CV

摘要简述: MedErr-CT是一个用于评估医学多模态大语言模型（MLLMs）在CT报告中识别和纠正错误能力的新型视觉问答基准，包含六类错误和三个任务级别，旨在提升临床诊断准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着CT检查需求的增加，诊断错误问题日益突出。现有医学视觉问答基准多关注简单视觉识别任务，缺乏临床相关性，无法评估专家级知识。因此，需要开发一个更严谨的基准来验证MLLMs的准确性。

研究方法: 研究团队提出了MedErr-CT基准，包含六类错误（四类视觉中心错误和两类词汇错误），并分为分类、检测和纠正三个任务级别。通过该基准，对先进的3D医学MLLMs进行了定量评估。

研究结果: 评估结果显示，不同MLLMs在不同错误类型上的表现存在显著差异，表明其在临床应用中仍需进一步优化。

研究结论: MedErr-CT基准有助于开发更可靠且临床适用的MLLMs，从而减少诊断错误并提升临床实践准确性。代码和数据集已开源。

中文摘要: 计算机断层扫描（CT）在临床诊断中至关重要，但CT检查需求的增长引发了诊断错误的担忧。尽管多模态大语言模型（MLLMs）在医学知识理解方面表现出潜力，但其易产生不准确信息的问题凸显了严格验证的必要性。然而，现有医学视觉问答（VQA）基准主要关注简单的视觉识别任务，缺乏临床相关性，无法评估专家级知识。我们提出了MedErr-CT，这是一个通过VQA框架评估医学MLLMs在CT报告中识别和纠正错误能力的新型基准。该基准包含六类错误——四类视觉中心错误（遗漏、插入、方向、大小）和两类词汇错误（单位、拼写），并分为分类、检测和纠正三个任务级别。利用该基准，我们定量评估了先进的3D医学MLLMs的性能，揭示了它们在不同错误类型上的显著差异。我们的基准有助于开发更可靠且临床适用的MLLMs，最终减少诊断错误并提升临床实践准确性。代码和数据集可在https://github.com/babbu3682/MedErr-CT获取。

</details>


### [69] [Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification](https://arxiv.org/abs/2506.19225)
**中文标题：Video-XL-2：通过任务感知KV稀疏化实现超长视频理解**

*Minghao Qin,Xiangrui Liu,Zhengyang Liang,Yan Shu,Huaying Yuan,Juenjie Zhou,Shitao Xiao,Bo Zhao,Zheng Liu*

主要分类: cs.CV

摘要简述: Video-XL-2通过任务感知的KV稀疏化技术，显著提升了长视频理解的计算效率和性能，支持单GPU处理超万帧视频。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型在处理长视频时面临高内存和计算成本的问题，难以同时实现高性能和高效率。

研究方法: Video-XL-2采用分块预填充和双层键值解码技术，分块内使用全注意力，分块间使用稀疏注意力，任务相关时选择性重载键值。

研究结果: Video-XL-2在多个长视频理解基准测试中表现最优，单GPU可处理超万帧视频，效率显著提升。

研究结论: Video-XL-2通过任务感知的KV稀疏化技术，为长视频理解提供了高效且高性能的解决方案。

中文摘要: 近年来，多模态大语言模型（MLLMs）在视频理解领域取得了显著进展。然而，由于高内存和计算成本，处理长视频输入仍是一个主要挑战，这使得当前模型难以在长视频理解中同时实现高性能和高效率。为解决这一问题，我们提出了Video-XL-2，这是一种基于任务感知KV稀疏化的新型MLLM，能够为长视频理解提供卓越的性价比。该框架通过两个关键步骤运行：分块预填充和双层键值解码。分块预填充将视觉标记序列划分为块，每个块内使用全注意力，块间使用稀疏注意力，从而显著降低计算和内存开销。在解码阶段，双层键值解码根据每个块与任务的相关性，选择性重载密集或稀疏键值。这一方法进一步提高了内存效率，并增强了模型捕获细粒度信息的能力。Video-XL-2在多个长视频理解基准测试中取得了最先进的性能，优于现有的开源轻量级模型。它还展示了卓越的效率，能够在单个NVIDIA A100（80GB）GPU上处理超过10,000帧的视频，并在几秒内处理数千帧。

</details>


### [70] [MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models](https://arxiv.org/abs/2506.19257)
**中文标题：MSR-Align：基于政策的多模态对齐用于视觉语言模型的安全感知推理**

*Yinan Xia,Yilei Jiang,Yingshui Tan,Xiaoyong Zhu,Xiangyu Yue,Bo Zheng*

主要分类: cs.CV

摘要简述: 本文提出MSR-Align数据集，用于增强视觉语言模型（VLMs）的安全推理能力，通过多模态对齐和标准化安全政策，有效抵御文本和视觉语言攻击。


<details>
  <summary>详细信息</summary>
研究动机: 随着视觉语言模型在多模态推理任务中的进步，其面临的新型安全风险也日益突出，现有单模态安全对齐方法无法应对多模态输入的复杂威胁，且缺乏细粒度的政策基础推理数据。

研究方法: 作者开发了MSR-Align数据集，强调多模态多样性、政策基础推理和严格质量过滤，并通过实验验证其对VLMs安全对齐的有效性。

研究结果: 实验表明，基于MSR-Align微调的VLMs显著提升了对抗文本和视觉语言攻击的鲁棒性，同时保持或提升了通用推理性能。

研究结论: MSR-Align为增强推理能力VLMs的安全对齐提供了可扩展且有效的基础，数据集已公开。

中文摘要: 视觉语言模型（VLMs）通过增强的思维链能力在多模态推理任务中取得了显著进展。然而，这一进步也带来了新的安全风险，因为这些模型越来越容易受到有害多模态提示的触发，导致不道德或不安全的行为。现有的安全对齐方法主要为单模态语言模型设计，无法应对多模态输入带来的复杂和细微威胁。此外，当前的安全数据集缺乏细粒度的、基于政策的推理能力，无法稳健地对齐具备推理能力的VLMs。本文提出了MSR-Align，一个高质量的多模态安全推理数据集，旨在填补这一空白。MSR-Align支持对视觉和文本模态的标准化安全政策进行细粒度的审慎推理。我们的数据生成流程强调多模态多样性、政策基础推理以及使用强大的多模态评估器进行严格质量过滤。大量实验表明，基于MSR-Align微调的VLMs显著提升了对抗文本和视觉语言攻击的鲁棒性，同时保持或增强了通用推理性能。MSR-Align为推进具备推理能力的VLMs的安全对齐提供了可扩展且有效的基础。我们的数据集已公开在https://huggingface.co/datasets/Leigest/MSR-Align。

</details>


### [71] [Automated Image Recognition Framework](https://arxiv.org/abs/2506.19261)
**中文标题：自动化图像识别框架**

*Quang-Binh Nguyen,Trong-Vu Hoang,Ngoc-Do Tran,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: 本文提出了一种自动化图像识别框架（AIR），利用生成式AI合成高质量预标注数据集，无需人工标注，并自动训练深度学习模型。AIR包含数据生成（AIR-Gen）和数据增强（AIR-Aug）两个模块，显著提升了图像识别的性能和效率。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习的性能高度依赖数据，但针对新颖或敏感主题的数据收集和标注耗时耗力。为解决这一问题，作者提出了AIR框架，旨在通过生成式AI自动合成高质量数据集，减少人工标注的需求。

研究方法: AIR框架包含两个主要模块：AIR-Gen和AIR-Aug。AIR-Gen通过自动化提示工程模块生成符合用户需求的数据集，并采用分布调整算法消除重复和异常数据。AIR-Aug则通过数据增强提升现有数据集的质量，尤其适用于数据量有限的任务。

研究结果: 实验表明，AIR生成的数据能有效训练深度学习模型，并在广泛对象上展示了优异的图像识别性能。用户研究评分达4.4/5.0，表明AI社区对AIR的认可。

研究结论: AIR框架通过生成式AI和数据增强技术，显著降低了数据标注的负担，提升了图像识别模型的性能和适用性，为AI社区提供了高效的工具。

中文摘要: 尽管深度学习模型的性能高度依赖数据，但针对新颖或敏感主题的数据收集和标注通常面临时间和资源的巨大挑战。为此，我们提出了一种新型自动化图像识别（AIR）框架，利用生成式AI合成高质量预标注数据集，无需人工标注。AIR还能自动在生成的数据集上训练深度学习模型，实现强大的图像识别性能。该框架包含两个主要数据合成过程：AIR-Gen和AIR-Aug。AIR-Gen允许用户根据需求无缝生成定制数据集，并通过新型自动化提示工程模块提升图像质量。我们还引入了分布调整算法，消除重复和异常数据，增强数据集的鲁棒性和可靠性。另一方面，AIR-Aug通过增强现有数据集提升深度分类模型的性能，尤其适用于数据量有限的任务。通过全面实验，我们证明了生成数据在训练深度学习模型中的有效性，并展示了该系统为广泛对象提供图像识别模型的潜力。用户研究评分为4.4/5.0，进一步证实了AI社区对AIR的积极评价。

</details>


### [72] [3D-SSM: A Novel 3D Selective Scan Module for Remote Sensing Change Detection](https://arxiv.org/abs/2506.19263)
**中文标题：3D-SSM：一种用于遥感变化检测的新型3D选择性扫描模块**

*Rui Huang,Jincheng Zeng,Sen Gao,Yan Xing*

主要分类: cs.CV

摘要简述: 本文提出了一种新型3D选择性扫描模块（3D-SSM），用于遥感变化检测，通过结合时空交互模块和多分支特征提取模块，显著提升了长距离依赖性和特征表示能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于Mamba的遥感变化检测方法在扫描模型上有所改进，但仍无法有效捕捉图像通道间的长距离依赖关系，限制了特征表示能力。本文旨在解决这一问题。

研究方法: 提出3D-SSM模块，从空间平面和通道视角捕获全局信息；设计时空交互模块（SIM）实现双时相特征的全局与局部交互；结合多分支特征提取模块（MBFEM）整合频域、空域和3D-SSM特征。

研究结果: 在五个基准数据集上的实验表明，该方法优于现有最优变化检测方法。

研究结论: 3D-SSM及其组件显著提升了遥感变化检测的性能，为长距离依赖和特征表示提供了有效解决方案。

中文摘要: 现有的基于Mamba的遥感变化检测方法虽然改进了扫描模型，但仍受限于无法有效捕捉图像通道间的长距离依赖关系，从而限制了特征表示能力。为解决这一问题，我们提出了一种3D选择性扫描模块（3D-SSM），能够从空间平面和通道视角捕获全局信息，从而更全面地理解数据。基于3D-SSM，我们提出了两个关键组件：时空交互模块（SIM）和多分支特征提取模块（MBFEM）。SIM通过实现不同时间点图像间全局与局部特征的交互，增强了对细微变化的检测能力。同时，MBFEM结合了频域、空域和3D-SSM的特征，为图像中的上下文信息提供了丰富的表示。通过大量实验，我们提出的方法在五个基准数据集上表现出优于现有最优变化检测方法的性能。代码发布于https://github.com/VerdantMist/3D-SSM。

</details>


### [73] [Self-Paced Collaborative and Adversarial Network for Unsupervised Domain Adaptation](https://arxiv.org/abs/2506.19267)
**中文标题：自步协作对抗网络用于无监督域自适应**

*Weichen Zhang,Dong Xu,Wanli Ouyang,Wen Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为协作对抗网络（CAN）的无监督域自适应方法，通过域协作和域对抗学习策略训练神经网络，并结合自步学习策略进一步提升目标域的分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 无监督域自适应旨在解决源域和目标域数据分布不一致的问题。传统方法通常仅关注域不变特征学习，而忽略了目标域的可区分性。本文旨在通过协作和对抗学习策略，同时学习域特定和域不变特征，以提升目标域的分类性能。

研究方法: 本文提出协作对抗网络（CAN），通过域协作学习保留目标域的可区分性，通过域对抗学习减少源域和目标域的分布差异。进一步提出自步CAN（SPCAN），采用自步学习策略逐步选择伪标记目标样本重新训练分类器。

研究结果: 在多个基准数据集（如Office-31、ImageCLEF-DA、VISDA-2017等）上的实验表明，所提方法在物体识别和视频动作识别任务中均达到最先进性能。

研究结论: 本文提出的协作对抗网络和自步学习策略有效提升了无监督域自适应的性能，尤其在目标域的可区分性和域不变特征学习方面表现出色。

中文摘要: 本文提出了一种新的无监督域自适应方法，称为协作对抗网络（CAN），该方法通过域协作和域对抗学习策略训练神经网络。域协作学习旨在学习域特定特征表示以保留目标域的可区分性，而域对抗学习旨在学习域不变特征表示以减少源域和目标域之间的分布差异。我们表明这两种学习策略可以统一为带有正负权重损失的域分类器学习。随后，我们设计了一种协作对抗训练方案，通过协作学习从CNN的较低块自动学习域特定表示，通过对抗学习从较高块学习域不变表示。此外，为了进一步增强目标域的可区分性，我们提出了自步CAN（SPCAN），逐步选择伪标记目标样本重新训练分类器。我们采用自步学习策略以从易到难的方式选择伪标记目标样本。在多个基准数据集（Office-31、ImageCLEF-DA、VISDA-2017用于物体识别任务，UCF101-10和HMDB51-10用于视频动作识别任务）上的综合实验表明，我们提出的新方法达到了最先进的性能，充分证明了所提方法在无监督域自适应中的有效性。

</details>


### [74] [AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration](https://arxiv.org/abs/2506.19283)
**中文标题：AirV2X：统一空地车联网协作**

*Xiangbo Gao,Yuheng Wu,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu*

主要分类: cs.CV

摘要简述: AirV2X提出了一种基于无人机的车联网协作系统，通过无人机替代或补充固定路侧单元，解决了传统V2X系统部署成本高和覆盖不足的问题，并发布了大规模数据集AirV2X-Perception。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于基础设施的车联网系统（V2X）存在部署成本高、农村和郊区覆盖不足的问题。无人机因其灵活性、低成本和多视角优势，成为替代或补充固定路侧单元的理想选择。

研究方法: 研究团队开发了AirV2X-Perception数据集，包含6.73小时的无人机辅助驾驶场景数据，覆盖城市、郊区和农村环境，以及多种天气和光照条件。无人机提供了鸟瞰视角和动态定位能力。

研究结果: AirV2X-Perception数据集填补了无人机辅助自动驾驶系统领域的空白，支持车辆与无人机（V2D）算法的开发和标准化评估。数据集和开发工具已开源。

研究结论: 无人机作为车联网的灵活补充，显著降低了部署成本并提升了覆盖范围，AirV2X-Perception数据集为相关研究提供了重要资源。

中文摘要: 尽管多车协同驾驶相比单车自动驾驶具有明显优势，但传统基于基础设施的车联网系统仍受限于高昂的部署成本以及在农村和郊区形成的“未覆盖危险区域”。我们提出了AirV2X-Perception，这是一个利用无人机作为固定路侧单元灵活替代或补充的大规模数据集。无人机相较于地面感知具有独特优势：互补的鸟瞰视角可减少遮挡，动态定位能力支持悬停、巡逻和护航导航规则，且部署成本远低于固定基础设施。我们的数据集包含6.73小时的无人机辅助驾驶场景，覆盖城市、郊区和农村环境，以及多种天气和光照条件。AirV2X-Perception数据集为车辆与无人机（V2D）算法的开发和标准化评估提供了支持，填补了无人机辅助自动驾驶系统快速扩展领域的关键空白。数据集和开发工具已开源：https://github.com/taco-group/AirV2X-Perception。

</details>


### [75] [Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding](https://arxiv.org/abs/2506.19288)
**中文标题：大禹：基于无人水面艇的水道监控与场景理解图像描述技术**

*Runwei Guan,Ningwei Ouyang,Tianhao Xu,Shaofeng Liang,Wei Dai,Yafeng Sun,Shang Gao,Songning Lai,Shanliang Yao,Xuming Hu,Ryan Wen Liu,Yutao Yue,Hui Xiong*

主要分类: cs.CV

摘要简述: 本文提出首个针对水道环境的图像描述数据集WaterCaption，并开发了可部署于边缘设备的多模态大语言模型Da Yu，通过新型视觉-语言投影器Nano Transformer Adaptor（NTA）提升长文本生成能力，实现了性能与效率的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 现有水道感知模型多专注于实例级物体感知（如检测、分割），缺乏对水道环境的全局语义理解，限制了大规模监测和结构化日志生成。随着视觉-语言模型（VLMs）的发展，作者希望通过图像描述技术填补这一空白。

研究方法: 1. 构建首个水道环境图像描述数据集WaterCaption，包含20.2k图像-文本对和180万词汇量；2. 提出Da Yu模型，采用新型Nano Transformer Adaptor（NTA）作为视觉-语言投影器，平衡计算效率与全局/局部视觉特征建模能力。

研究结果: Da Yu在WaterCaption及其他描述基准测试中表现优异，超越了现有最先进模型，同时保持了性能与效率的平衡。

研究结论: WaterCaption为水道环境的视觉地理理解和空间场景认知提供了新研究方向，Da Yu模型通过NTA实现了高效的长文本生成能力，为无人水面艇（USV）的智能感知提供了实用解决方案。

中文摘要: 自动化水道环境感知对于无人水面艇（USV）理解周围环境并做出明智决策至关重要。现有水道感知模型主要关注实例级物体感知（如检测、分割），但由于水道环境的复杂性，当前感知数据集和模型无法实现水道全局语义理解，限制了大规模监测和结构化日志生成。随着视觉-语言模型（VLMs）的发展，我们利用图像描述技术提出了首个专为水道环境设计的描述数据集WaterCaption。WaterCaption专注于细粒度、多区域长文本描述，为视觉地理理解和空间场景认知提供了新的研究方向。具体而言，该数据集包含20.2k图像-文本对，词汇量达180万。此外，我们提出了Da Yu，一种可部署于边缘设备的多模态大语言模型，其中我们设计了一种新型视觉-语言投影器Nano Transformer Adaptor（NTA）。NTA在计算效率与全局/局部视觉特征建模能力之间实现了有效平衡，显著提升了模型生成长文本的能力。Da Yu在性能与效率之间取得了最优平衡，在WaterCaption及其他描述基准测试中超越了现有最先进模型。

</details>


### [76] [HoliGS: Holistic Gaussian Splatting for Embodied View Synthesis](https://arxiv.org/abs/2506.19291)
**中文标题：HoliGS：面向实体视角合成的整体高斯泼溅**

*Xiaoyuan Wang,Yizhou Zhao,Botao Ye,Xiaojun Shan,Weijie Lyu,Lu Qi,Kelvin C. K. Chan,Yinxiao Li,Ming-Hsuan Yang*

主要分类: cs.CV

摘要简述: HoliGS提出了一种新颖的可变形高斯泼溅框架，用于从长单目RGB视频中进行实体视角合成，显著降低了训练和渲染时间，同时提升了重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有4D高斯泼溅和动态NeRF方法在长时间捕获场景中训练开销大，难以处理大规模动态环境。HoliGS旨在解决这一问题，提供高效且高质量的实体视角合成方案。

研究方法: HoliGS将场景分解为静态背景和时间变化对象，通过可逆高斯泼溅变形网络实现全局刚性变换、骨架驱动关节和细微非刚性变形。采用分层变形策略，将高斯附着到完整的前景形状上，支持自由视角渲染。

研究结果: 实验表明，HoliGS在挑战性数据集上实现了卓越的重建质量，同时显著减少了训练和渲染时间，优于现有单目可变形NeRF方法。

研究结论: HoliGS为现实场景中的实体视角合成提供了实用且可扩展的解决方案，其高效性和高质量表现使其成为该领域的先进方法。

中文摘要: 我们提出了HoliGS，一种新颖的可变形高斯泼溅框架，用于从长单目RGB视频中进行实体视角合成。与现有的4D高斯泼溅和动态NeRF方法不同，后者在长时间捕获场景中面临训练开销大的问题，我们的方法利用可逆高斯泼溅变形网络，准确重建大规模动态环境。具体而言，我们将每个场景分解为静态背景和时间变化对象，每个对象通过学习的高斯基元进行全局刚性变换、骨架驱动关节和通过可逆神经流实现的细微非刚性变形。这种分层变形策略通过将高斯附着到完整的前景形状上（例如，自我中心或第三人称跟随），支持从各种实体相机轨迹中进行稳健的自由视角新视角渲染，可能涉及显著的视角变化和多个角色之间的交互。实验表明，我们的方法在挑战性数据集上实现了卓越的重建质量，同时显著减少了训练和渲染时间，优于现有单目可变形NeRF方法。这些结果突出了在现实场景中实体视角合成的实用且可扩展的解决方案。源代码将发布。

</details>


### [77] [Open-Vocabulary Camouflaged Object Segmentation with Cascaded Vision Language Models](https://arxiv.org/abs/2506.19300)
**中文标题：基于级联视觉语言模型的开放词汇伪装物体分割**

*Kai Zhao,Wubang Yuan,Zheng Wang,Guanyi Li,Xiaoqiang Zhu,Deng-ping Fan,Dan Zeng*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉语言模型（VLM）的级联框架，用于开放词汇伪装物体分割（OVCOS），通过VLM引导的SAM模型提升分割精度，并利用软空间先验避免分类中的领域差距，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 开放词汇伪装物体分割（OVCOS）面临视觉模糊性和未见类别的挑战。现有方法存在领域差距和分割模型对伪装物体效果不佳的问题，亟需改进。

研究方法: 采用VLM引导的级联框架：1）利用VLM特征作为SAM的显式提示，提升伪装区域的分割精度；2）通过alpha通道保留完整图像上下文，避免硬裁剪导致的领域差距，实现更准确的分类。

研究结果: 在OVCOS和传统伪装物体分割基准测试中，该方法显著优于现有方法，验证了VLM语义在分割和分类中的有效性。

研究结论: 通过VLM引导的级联框架，成功解决了OVCOS中的分割和分类问题，为伪装物体分析提供了高效且语义一致的解决方案。

中文摘要: 开放词汇伪装物体分割（OVCOS）旨在从任意类别中分割并分类伪装物体，由于视觉模糊性和未见类别，其面临独特挑战。现有方法通常采用两阶段范式：先分割物体，再利用视觉语言模型（VLM）分类分割区域。然而，这些方法存在以下问题：（1）因VLM的全图像训练与裁剪区域推理不匹配导致领域差距；（2）依赖针对清晰边界优化的通用分割模型，对伪装物体效果不佳。无显式指导时，通用分割模型常忽略细微边界，导致分割不精确。本文提出了一种新颖的VLM引导级联框架以解决OVCOS中的这些问题。在分割阶段，我们利用VLM引导的Segment Anything Model（SAM），将VLM特征作为显式提示输入SAM，有效聚焦伪装区域并显著提升定位精度。在分类阶段，我们通过alpha通道将分割输出作为软空间先验，保留完整图像上下文的同时提供精确空间指导，从而实现更准确且上下文感知的分类。同一VLM被共享于分割和分类阶段以确保效率和语义一致性。在OVCOS和传统伪装物体分割基准上的大量实验表明，本文方法明显优于现有方法，凸显了利用丰富VLM语义进行伪装物体分割和分类的有效性。

</details>


### [78] [Airway Skill Assessment with Spatiotemporal Attention Mechanisms Using Human Gaze](https://arxiv.org/abs/2506.19306)
**中文标题：基于人类注视的时空注意力机制气道技能评估**

*Jean-Paul Ainam,Rahul,Lora Cavuoto,Matthew Hackett,Jack Norfleet,Suvranu De*

主要分类: cs.CV

摘要简述: 本文提出了一种基于机器学习和人类注视数据的气道管理技能评估方法，通过时空注意力机制提升气管插管（ETI）的识别准确性。


<details>
  <summary>详细信息</summary>
研究动机: 气道管理技能在急救医学中至关重要，但传统评估方法主观性强且难以反映真实场景中的能力。本文旨在利用人类注视数据和视频记录，开发一种客观、高效的ETI技能评估工具。

研究方法: 通过人类注视点生成视觉掩码，引导模型关注任务相关区域；使用自编码器网络提取视频特征，注意力模块生成注意力权重，分类器输出评分。

研究结果: 该方法显著提升了预测准确性、敏感性和可信度，优于传统评估方法，适用于高压力环境（如军事场景）。

研究结论: 结合人类注视数据的模型不仅提升了性能，还为临床技能评估提供了客观工具，有望改善急救医学的培训和患者结局。

中文摘要: 气道管理技能在急救医学中至关重要，但传统评估方法主观性强且难以反映真实场景中的能力。本文提出了一种基于机器学习的评估方法，利用人类注视数据和视频记录来评估气管插管（ETI）技能。该系统通过人类注视引导的注意力机制，增强了对成功和失败ETI程序的识别。通过注视点生成视觉掩码，引导模型聚焦任务相关区域，减少无关特征干扰。自编码器网络提取视频特征，注意力模块生成注意力权重，分类器输出评分。该方法首次将人类注视用于ETI评估，其准确性和效率优于传统方法。人类注视数据的整合不仅提升了模型性能，还为临床技能（尤其是高压力环境如军事场景）提供了客观评估工具。结果显示，该方法在预测准确性、敏感性和可信度方面均有提升，展现了其在改善急救医学培训和患者结局方面的潜力。

</details>


### [79] [Capturing Fine-Grained Alignments Improves 3D Affordance Detection](https://arxiv.org/abs/2506.19312)
**中文标题：捕捉细粒度对齐提升3D功能检测**

*Junsei Tokumitsu,Yuiga Wada*

主要分类: cs.CV

摘要简述: 本文提出了一种新方法LM-AD，通过引入Affordance Query Module (AQM) 来捕捉3D点云与文本之间的细粒度对齐，显著提升了3D功能检测的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在3D点云的功能检测任务中表现不佳，主要原因是它们依赖简单的余弦相似度来计算点云与文本嵌入的匹配，无法捕捉细粒度的对齐关系。本文旨在解决这一问题。

研究方法: 提出了LM-AD方法，结合预训练语言模型，设计了Affordance Query Module (AQM)，以高效捕捉点云与文本之间的细粒度对齐。

研究结果: 在3D AffordanceNet数据集上，LM-AD在准确率和平均交并比（mIoU）上均优于现有方法。

研究结论: 通过引入细粒度对齐机制，LM-AD显著提升了3D功能检测的性能，为未来研究提供了新思路。

中文摘要: 本文研究了3D点云中的功能检测问题，该任务需要有效捕捉点云与文本之间的细粒度对齐。现有方法通常难以建模这种对齐关系，导致在标准基准测试中表现有限。这些方法的一个关键局限是依赖点云与文本嵌入之间的简单余弦相似度，缺乏细粒度推理所需的表达能力。为解决这一问题，我们提出了LM-AD，一种用于3D点云功能检测的新方法。此外，我们引入了Affordance Query Module (AQM)，通过利用预训练语言模型高效捕捉点云与文本之间的细粒度对齐。实验表明，我们的方法在3D AffordanceNet数据集上的准确率和平均交并比均优于现有方法。

</details>


### [80] [Progressive Modality Cooperation for Multi-Modality Domain Adaptation](https://arxiv.org/abs/2506.19316)
**中文标题：渐进式模态合作的多模态域适应方法**

*Weichen Zhang,Dong Xu,Jing Zhang,Wanli Ouyang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为渐进式模态合作（PMC）的多模态域适应框架，通过利用RGB和深度等多模态线索，在MMDA和MMDA-PI设置下实现源域到目标域的知识迁移。PMC通过两个新模块选择可靠的伪标签目标样本，并进一步提出PMC-PI方法生成目标域缺失模态。实验验证了PMC的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 多模态域适应（MMDA）和特权信息多模态域适应（MMDA-PI）是跨域视觉识别任务中的重要问题。现有方法未能充分利用多模态数据，特别是在目标域缺失某些模态时。本文旨在通过PMC框架解决这些问题，提升跨域任务的性能。

研究方法: PMC框架包含两个模块：1）在MMDA设置下，通过多模态合作选择可靠的伪标签目标样本，捕捉模态特定和模态整合信息；2）在MMDA-PI设置下，提出PMC-PI方法，利用多模态数据生成（MMG）网络生成目标域缺失模态，结合对抗学习和加权伪语义条件。

研究结果: 在三个图像数据集和八个视频数据集上的实验表明，PMC在MMDA和MMDA-PI设置下均显著提升了多模态跨域视觉识别任务的性能。

研究结论: PMC框架通过渐进式模态合作和特权信息利用，有效解决了多模态域适应问题，实验证明了其在跨域任务中的优越性。

中文摘要: 本文提出了一种新的通用多模态域适应框架——渐进式模态合作（PMC），通过利用RGB和深度等多模态线索，在MMDA和MMDA-PI设置下实现源域到目标域的知识迁移。在MMDA设置下，两个域样本均包含所有模态；PMC的两个新模块通过多模态合作选择可靠的伪标签目标样本，分别捕捉模态特定和模态整合信息。在MMDA-PI设置下，目标域缺失某些模态，因此提出PMC-PI方法，通过多模态数据生成（MMG）网络生成缺失模态，同时考虑域分布不匹配和语义保留，分别通过对抗学习和加权伪语义条件实现。在三个图像数据集和八个视频数据集上的广泛实验验证了PMC框架的有效性。

</details>


### [81] [Continual Retinal Vision-Language Pre-training upon Incremental Imaging Modalities](https://arxiv.org/abs/2506.19320)
**中文标题：基于增量成像模态的持续视网膜视觉-语言预训练**

*Yuang Yao,Ruiqi Wu,Yi Zhou,Tao Zhou*

主要分类: cs.CV

摘要简述: 本文提出RetCoP，首个针对眼底影像的持续视觉-语言预训练框架，通过增量整合多模态图像和文本特征，解决传统模型忽视模态互补性的问题。采用重放策略和离对角线信息蒸馏方法，有效缓解持续预训练中的灾难性遗忘问题，实验表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统眼底影像分析模型仅关注单模态任务，忽略了多模态互补性，限制了其通用性。虽然近期出现了一些视网膜基础模型，但多数仍局限于单一模态。在动态环境中，不同模态数据往往增量到达，亟需一种持续预训练方法。

研究方法: 提出RetCoP框架，通过增量整合多模态图像和文本特征到统一基础模型中。采用重放策略（利用代表性图像-文本对）和离对角线信息蒸馏方法，前者帮助模型回顾历史知识，后者显式保持图像与文本表征的对齐。

研究结果: 实验表明，RetCoP在所有对比方法中表现最佳，具有最优的泛化能力和最低的遗忘率。

研究结论: RetCoP成功解决了眼底影像多模态持续预训练的挑战，为动态环境下的模型适应性提供了有效解决方案。

中文摘要: 传统眼底影像分析模型专注于单模态任务，忽略了眼底模态的互补性，限制了其通用性。近年来，视网膜基础模型逐渐兴起，但多数仍局限于单一模态。将多种眼底成像模态整合到一个基础模型中具有重要意义。然而，在动态环境中，不同模态的数据往往增量到达，需要持续预训练。为此，我们提出RetCoP，这是首个针对眼底领域的持续视觉-语言预训练框架，能够增量整合来自不同成像模态的图像和文本特征到一个统一的基础模型中。为了缓解持续预训练中的灾难性遗忘问题，我们引入了一种利用代表性图像-文本对的重放策略和一种离对角线信息蒸馏方法。前者使模型能够回顾历史知识，后者显式保持图像与文本表征的对齐。实验表明，RetCoP在所有对比方法中表现最优，具有最佳的泛化能力和最低的遗忘率。代码可在https://github.com/Yuang-Yao/RetCoP找到。

</details>


### [82] [Memory-Augmented Incomplete Multimodal Survival Prediction via Cross-Slide and Gene-Attentive Hypergraph Learning](https://arxiv.org/abs/2506.19324)
**中文标题：基于跨切片和基因注意力超图学习的记忆增强不完全多模态生存预测**

*Mingcheng Qu,Guang Yang,Donglin Di,Yue Gao,Tonghua Su,Yang Song,Lei Fan*

主要分类: cs.CV

摘要简述: 本文提出了一种基于超图学习和记忆机制的多模态生存预测框架，有效整合病理切片和基因组数据，解决模态不平衡和不完整数据问题，实验表明其性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法主要依赖FFPE切片与基因组数据，忽略了其他保存方式（如FF切片）的可用性，且高分辨率病理数据主导跨模态融合，导致模态不平衡。此外，现有方法通常需要完整数据，限制了临床应用中不完整数据的适用性。

研究方法: 提出一种多模态生存预测框架，利用超图学习整合多切片信息和跨模态交互，并通过记忆机制动态补偿不完整模态。

研究结果: 在五个TCGA数据集上，模型C-Index超过现有方法2.3%，在不完整模态场景下优于仅病理（3.3%）和仅基因模型（7.9%）。

研究结论: 该框架通过超图学习和记忆机制有效解决了多模态融合中的模态不平衡和不完整数据问题，提升了生存预测性能。

中文摘要: 多模态病理-基因组分析对癌症生存预测至关重要。然而，现有方法主要整合福尔马林固定石蜡包埋（FFPE）切片与基因组数据，忽略了其他保存方式（如新鲜冷冻（FF）切片）的可用性。此外，病理数据的高分辨率空间特性往往主导跨模态融合过程，阻碍了有效的多模态融合，并导致病理与基因组之间的模态不平衡问题。这些方法通常还需要完整的数据模态，限制了其在病理或基因组数据缺失等不完整模态场景下的临床应用。本文提出了一种多模态生存预测框架，利用超图学习有效整合多切片信息和病理切片与基因组数据之间的跨模态交互，同时解决模态不平衡问题。此外，我们引入了一种记忆机制，存储先前学习的配对病理-基因组特征，并动态补偿不完整模态。在五个TCGA数据集上的实验表明，我们的模型在C-Index上优于先进方法超过2.3%。在不完整模态场景下，我们的方法优于仅病理（3.3%）和仅基因模型（7.9%）。代码：https://github.com/MCPathology/M2Surv

</details>


### [83] [Comparative Performance of Finetuned ImageNet Pre-trained Models for Electronic Component Classification](https://arxiv.org/abs/2506.19330)
**中文标题：基于ImageNet预训练模型的电子元件分类性能比较**

*Yidi Shao,Longfei Zhou,Fangshuo Tang,Xinyi Shi,Dalang Chen,Shengtao Xia*

主要分类: cs.CV

摘要简述: 本文比较了12种基于ImageNet预训练模型在电子元件分类任务中的表现，发现所有模型均表现良好，其中MobileNet-V2准确率最高（99.95%），EfficientNet-B0最低（92.26%），验证了预训练模型在电子制造领域的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 电子元件分类在制造业中至关重要，能够显著降低人工成本并推动技术发展。预训练模型（尤其是基于ImageNet的模型）在图像分类中表现优异，但对其在电子元件分类中的具体性能缺乏系统比较。

研究方法: 研究选取了12种ImageNet预训练模型，通过微调（finetune）将其应用于电子元件分类任务，并比较它们的分类准确率。

研究结果: 所有测试模型均表现良好，MobileNet-V2以99.95%的准确率位居第一，EfficientNet-B0以92.26%的准确率排名最低。

研究结论: ImageNet预训练模型在电子元件分类任务中具有显著优势，MobileNet-V2表现最佳，验证了这些方法在电子制造领域的实际应用价值。

中文摘要: 电子元件分类与检测在制造业中至关重要，能够显著降低人工成本并推动技术与工业发展。预训练模型（尤其是基于ImageNet训练的模型）在图像分类中表现优异，即使数据有限，研究人员也能取得出色结果。本文比较了12种ImageNet预训练模型在电子元件分类中的性能。结果显示，所有测试模型均表现良好，其中MobileNet-V2准确率最高（99.95%），EfficientNet-B0最低（92.26%）。这些结果凸显了ImageNet预训练模型在图像分类任务中的巨大优势，并证实了这些方法在电子制造领域的实际适用性。

</details>


### [84] [Segment Any 3D-Part in a Scene from a Sentence](https://arxiv.org/abs/2506.19331)
**中文标题：基于句子的场景中任意3D部件分割**

*Hongyu Wu,Pengwan Yang,Yuki M. Asano,Cees G. M. Snoek*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自然语言描述的3D场景部分分割方法，通过引入首个大规模3D部件标注数据集3D-PU和OpenPart3D框架，解决了传统3D场景理解局限于对象级别的问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统3D场景理解主要关注对象级别，缺乏对部件级别的细粒度分割能力，且数据标注成本高昂。本文旨在通过构建大规模部件标注数据集和提出新方法，推动3D部件级场景理解的发展。

研究方法: 本文提出3D-PU数据集，通过创新的低成本方法生成合成3D场景并标注细粒度部件；同时提出OpenPart3D框架，仅使用3D输入实现部件级分割。

研究结果: 实验表明，OpenPart3D在部件级开放词汇3D场景理解任务中表现优异，且在不同3D场景数据集上具有强泛化能力。

研究结论: 本文通过3D-PU数据集和OpenPart3D框架，成功实现了基于自然语言的3D部件分割，为3D部件级场景理解提供了新方向。

中文摘要: 本文旨在通过自然语言描述实现场景中任意3D部件的分割，超越传统的对象级3D场景理解，并解决数据和方法上的挑战。由于数据获取和标注成本高昂，现有数据集和方法主要局限于对象级理解。为克服数据和标注的限制，我们引入了3D-PU数据集，这是首个具有密集部件标注的大规模3D数据集，通过创新的低成本方法构建合成3D场景并标注细粒度部件，为高级3D部件场景理解铺平了道路。在方法上，我们提出了OpenPart3D框架，仅使用3D输入有效解决部件级分割的挑战。大量实验表明，我们的方法在部件级开放词汇3D场景理解任务中表现优越，并在多种3D场景数据集上展现出强大的泛化能力。

</details>


### [85] [Trajectory Prediction in Dynamic Object Tracking: A Critical Study](https://arxiv.org/abs/2506.19341)
**中文标题：动态目标跟踪中的轨迹预测：一项关键研究**

*Zhongping Dong,Liming Chen,Mohand Tahar Kechadi*

主要分类: cs.CV

摘要简述: 本文详细分析了动态目标跟踪（DOT）和轨迹预测（TP）方法的最新进展，包括其应用和挑战，并探讨了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在总结动态目标跟踪和轨迹预测技术的现状，评估其实际应用效果，并指出当前面临的挑战，为未来研究提供方向。

研究方法: 研究涵盖了特征提取、分割、估计和学习等多种方法，并评估了它们在现实场景中的有效性、部署情况和局限性。

研究结果: 研究发现这些技术在汽车与自动驾驶、监控与安防、医疗和工业自动化等领域具有重要影响，但仍存在泛化能力、计算效率、数据依赖和伦理问题等挑战。

研究结论: 研究建议未来应关注多模态数据整合、语义信息融合和上下文感知系统的开发，同时建立伦理和隐私保护框架。

中文摘要: 本研究详细分析了动态目标跟踪（DOT）和轨迹预测（TP）方法的最新进展，包括其应用和挑战。研究涵盖了特征提取、分割、估计和学习等多种方法，并评估了它们在现实场景中的有效性、部署情况和局限性。研究强调了这些技术在汽车与自动驾驶、监控与安防、医疗和工业自动化等领域对安全和效率的重要贡献。尽管取得了进展，但仍存在泛化能力、计算效率、数据依赖和伦理问题等挑战。研究建议未来研究方向应关注多模态数据整合、语义信息融合和上下文感知系统的开发，同时建立伦理和隐私保护框架。

</details>


### [86] [Image Segmentation using Chan-Vese Active Contours](https://arxiv.org/abs/2506.19344)
**中文标题：基于Chan-Vese主动轮廓模型的图像分割**

*Pranav Shenoy K. P*

主要分类: cs.CV

摘要简述: 本文全面推导并实现了Chan-Vese主动轮廓模型用于图像分割。该模型基于区域强度差异而非图像梯度演化轮廓，适用于噪声图像或边界模糊的图像分割。实验验证了其在医学和合成图像上的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于边缘的图像分割方法在噪声或弱边界图像中表现不佳。Chan-Vese模型通过区域强度差异演化轮廓，为解决这一问题提供了新思路。

研究方法: 本文从Mumford-Shah变分框架出发，推导了水平集公式的数学表达，详细处理了能量项，并采用有限差分法实现算法，注重数值稳定性（如上风熵方案和曲率正则化）。

研究结果: 实验结果表明，Chan-Vese模型在医学和合成图像上实现了准确分割，对噪声具有鲁棒性，性能优于传统边缘方法。

研究结论: 研究证实Chan-Vese模型适用于复杂分割任务，展现了其在现实成像应用中的潜力。

中文摘要: 本文全面推导并实现了Chan-Vese主动轮廓模型用于图像分割。该模型源自Mumford-Shah变分框架，通过区域强度差异而非图像梯度演化轮廓，特别适用于噪声图像或边界模糊的图像分割。我们提供了水平集公式的严谨数学推导，包括利用散度定理和曲线演化理论对各能量项的详细处理。算法通过有限差分法在Python中实现，并注重数值稳定性（如上风熵方案和曲率正则化）。在医学和合成图像上的实验结果表明，该方法分割准确，对噪声鲁棒，性能优于传统边缘方法。本研究证实了Chan-Vese模型在复杂分割任务中的适用性，并凸显了其在现实成像应用中的潜力。

</details>


### [87] [Training-Free Motion Customization for Distilled Video Generators with Adaptive Test-Time Distillation](https://arxiv.org/abs/2506.19348)
**中文标题：基于自适应测试时蒸馏的蒸馏视频生成器无需训练运动定制方法**

*Jintao Rong,Xin Xie,Xinyi Yu,Linlin Ou,Xinyu Zhang,Chunhua Shen,Dong Gong*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的运动定制方法MotionEcho，通过自适应测试时蒸馏提升蒸馏视频生成模型的运动保真度和生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的蒸馏视频生成模型在参考视频引导下难以实现运动定制，尤其是在无需训练的场景下。传统方法因加速生成过程和大步长去噪而无法适用。

研究方法: 提出MotionEcho框架，利用扩散教师强制技术，通过高质量慢速教师模型指导快速学生模型的推理，结合端点预测和插值，动态分配计算资源。

研究结果: 实验表明，该方法在多种蒸馏视频生成模型和基准数据集上显著提升了运动保真度和生成质量，同时保持了高效性。

研究结论: MotionEcho为蒸馏视频生成模型提供了一种高效且无需训练的运动定制解决方案，具有广泛的应用潜力。

中文摘要: 蒸馏视频生成模型能够快速高效地合成视频，但在参考视频引导下难以实现运动定制，尤其是在无需训练的场景下。现有方法原本设计用于标准扩散模型，但由于蒸馏模型的加速生成过程和大步长去噪而无法适用。为此，我们提出了MotionEcho，一种新型无需训练的测试时蒸馏框架，通过扩散教师强制技术实现运动定制。该方法利用高质量慢速教师模型，通过端点预测和插值指导快速学生模型的推理。为保持高效性，我们根据引导需求动态分配时间步的计算资源。在多种蒸馏视频生成模型和基准数据集上的广泛实验表明，我们的方法显著提升了运动保真度和生成质量，同时保持了高效性。项目页面：https://euminds.github.io/motionecho/

</details>


### [88] [Online camera-pose-free stereo endoscopic tissue deformation recovery with tissue-invariant vision-biomechanics consistency](https://arxiv.org/abs/2506.19388)
**中文标题：基于组织不变视觉-生物力学一致性的在线无相机姿态立体内窥镜组织变形恢复**

*Jiahe Chen,Naoki Tomii,Ichiro Sakuma,Etsuko Kobayashi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于立体内窥镜图像的在线组织变形恢复方法，无需相机姿态估计，通过结合视觉与生物力学一致性，解决了相机运动、遮挡和大变形等问题。


<details>
  <summary>详细信息</summary>
研究动机: 组织变形恢复对手术导航和软组织自主操作至关重要，但现有方法受限于相机运动、遮挡、大变形、缺乏组织特异性生物力学先验以及依赖离线处理。本文旨在解决这些问题。

研究方法: 该方法将组织几何建模为3D点及其导数图，变形建模为3D位移和局部变形图。通过优化帧间变形实现帧对齐，无需估计相机姿态，并引入规范图在线优化组织几何和变形。

研究结果: 实验表明，该方法在非遮挡和遮挡区域的3D重建精度分别为0.37±0.27 mm和0.39±0.21 mm，并能估计表面应变分布。

研究结论: 该方法在相机运动、遮挡和大变形条件下稳定恢复组织变形，为机械分析提供了额外模态。

中文摘要: 基于立体内窥镜图像的组织变形恢复对工具-组织交互分析至关重要，有助于手术导航和软组织自主操作。以往研究受限于相机运动、遮挡、大变形、缺乏组织特异性生物力学先验以及依赖离线处理。与以往用3D点和位移表示组织几何和变形不同，本文方法将组织几何建模为3D点及其导数图，变形建模为3D位移和局部变形图。每个表面点用6个参数描述刚性运动，3个参数描述局部变形。方法在相机中心设定下实现，所有运动被视为场景相对于相机的运动。通过优化帧间变形实现帧对齐，无需估计相机姿态。引入规范图在线优化组织几何和变形。使用体内和体外腹腔镜数据集进行定量和定性实验。在深度和光流输入下，方法即使在组织部分遮挡或移出视野时也能稳定建模组织几何和变形。结果显示，非遮挡和遮挡区域的3D重建精度分别为0.37±0.27 mm和0.39±0.21 mm（表面距离）。该方法还能估计各种操作中的表面应变分布，为机械分析提供额外模态。

</details>


### [89] [Emergence of Text Readability in Vision Language Models](https://arxiv.org/abs/2506.19389)
**中文标题：视觉语言模型中文本可读性的涌现**

*Jaeyoo Park,Sanghyuk Chun,Wonjae Kim,Sangdoo Yun,Bohyung Han*

主要分类: cs.CV

摘要简述: 研究发现，视觉语言模型（VLMs）在训练过程中，文本可读性能力会突然出现，而语义理解能力则从早期逐渐发展。这表明对比学习可能优先关注通用语义理解，而文本处理能力发展较慢。


<details>
  <summary>详细信息</summary>
研究动机: 探讨视觉语言模型在训练过程中如何发展识别图像中文本内容的能力，揭示文本可读性与语义理解能力的不同发展模式。

研究方法: 通过分析VLMs的训练过程，观察文本可读性和语义理解能力的发展趋势，并对比两者的发展速度差异。

研究结果: 文本可读性能力在训练后期突然出现，而语义理解能力从早期逐渐发展；匹配图像与渲染文本的能力发展更慢。

研究结论: 研究强调了需要定制化训练策略以加速VLMs的文本理解能力，为未来优化多模态学习奠定基础。

中文摘要: 我们研究了视觉语言模型（VLMs）在训练过程中如何发展识别图像中文本内容的能力。分析揭示了一个关键现象：图像中文本信息的可读性能力在大量训练迭代后突然出现，而语义内容理解能力则从训练早期逐渐发展。这种延迟涌现可能反映了对比学习最初倾向于优先关注通用语义理解，而文本特定的符号处理能力发展较晚。有趣的是，匹配图像与渲染文本的能力发展更慢，表明需要更深层次的语义整合。这些发现强调了需要定制化训练策略以加速VLMs的稳健文本理解能力，为未来优化多模态学习的研究奠定了基础。

</details>


### [90] [Generate the Forest before the Trees -- A Hierarchical Diffusion model for Climate Downscaling](https://arxiv.org/abs/2506.19391)
**中文标题：先见森林后见树木——一种用于气候降尺度的分层扩散模型**

*Declan J. Curran,Sanaa Hobeichi,Hira Saleem,Hao Xue,Flora D. Salim*

主要分类: cs.CV

摘要简述: 本文提出了一种分层扩散降尺度（HDD）模型，通过分层采样过程显著降低了计算负担，同时在高分辨率气候数据生成中保持了竞争力。


<details>
  <summary>详细信息</summary>
研究动机: 传统的气候降尺度方法计算成本高，而现有的AI降尺度模型（如扩散模型）虽然表现优异，但仍需大量计算资源。因此，需要一种更轻量化的方法来实现高效的气候降尺度。

研究方法: HDD模型在扩散框架中引入了分层采样过程，通过从粗到细的分层结构（简单的下采样方案）实现降尺度。该方法在ERA5再分析数据集和CMIP6模型上进行了验证。

研究结果: HDD在ERA5和CMIP6数据集上取得了与现有方法竞争性的精度，同时计算负载显著降低（仅需一半像素）。此外，单个在0.25°分辨率训练的模型可无缝迁移到分辨率更低的CMIP6模型中。

研究结论: HDD为概率气候降尺度提供了一种轻量化的替代方案，支持高效的大规模高分辨率气候预测。

中文摘要: 降尺度对于生成局部规划所需的高分辨率气候数据至关重要，但传统方法计算成本高昂。近年来，AI降尺度模型（尤其是扩散模型）取得了显著成果，因其能够生成集合数据并克服其他AI方法常见的平滑问题而备受关注。然而，这些模型通常仍需要大量计算资源。我们提出了一种分层扩散降尺度（HDD）模型，在扩散框架中引入了易于扩展的分层采样过程。通过简单的下采样方案实现了从粗到细的分层结构。HDD在ERA5再分析数据集和CMIP6模型上取得了竞争性的精度，同时通过仅需一半像素的运行显著降低了计算负载。此外，单个在0.25°分辨率训练的模型可无缝迁移到分辨率更低的多个CMIP6模型中。因此，HDD为概率气候降尺度提供了一种轻量化的替代方案，支持经济高效的大规模高分辨率气候预测。完整代码实现见：https://github.com/HDD-Hierarchical-Diffusion-Downscaling/HDD-Hierarchical-Diffusion-Downscaling。

</details>


### [91] [A Global-Local Cross-Attention Network for Ultra-high Resolution Remote Sensing Image Semantic Segmentation](https://arxiv.org/abs/2506.19406)
**中文标题：一种用于超高分辨率遥感图像语义分割的全局-局部交叉注意力网络**

*Chen Yi,Shan LianLei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为GLCANet的轻量级分割框架，用于超高分辨率遥感图像的语义分割，通过双流架构和注意力机制高效融合全局语义与局部细节，显著提升了分割精度和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 随着超高分辨率遥感技术的快速发展，对准确高效的语义分割需求大幅增加。然而，现有方法在计算效率和多尺度特征融合方面面临挑战，因此需要一种更高效的解决方案。

研究方法: GLCANet采用双流架构，结合自注意力机制和掩码交叉注意力机制，高效融合全局语义与局部细节，同时减少GPU占用。自注意力机制增强长程依赖，掩码交叉注意力机制自适应融合全局-局部特征。

研究结果: 实验结果表明，GLCANet在精度和计算效率上均优于现有先进方法，能够高效处理大尺寸高分辨率图像，且内存占用小。

研究结论: GLCANet为超高分辨率遥感图像的语义分割提供了一种高效且轻量化的解决方案，具有实际应用潜力。

中文摘要: 随着超高分辨率（UHR）遥感技术的快速发展，对准确高效语义分割的需求显著增加。然而，现有方法在计算效率和多尺度特征融合方面面临挑战。为解决这些问题，我们提出了GLCANet（全局-局部交叉注意力网络），一种专为UHR遥感图像设计的轻量级分割框架。GLCANet采用双流架构，高效融合全局语义与局部细节，同时最小化GPU使用。自注意力机制增强了长程依赖，优化全局特征并保留局部细节以实现更好的语义一致性。掩码交叉注意力机制自适应地融合全局-局部特征，选择性增强细粒度细节，同时利用全局上下文提升分割精度。实验结果表明，GLCANet在精度和计算效率上均优于现有先进方法。该模型能够高效处理大型高分辨率图像，且内存占用小，为实际遥感应用提供了有前景的解决方案。

</details>


### [92] [EvDetMAV: Generalized MAV Detection from Moving Event Cameras](https://arxiv.org/abs/2506.19416)
**中文标题：EvDetMAV：基于移动事件相机的通用微型飞行器检测**

*Yin Zhang,Zian Ning,Xiaoyu Zhang,Shiliang Guo,Peidong Liu,Shiyu Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于事件相机的通用微型飞行器（MAV）检测方法，通过利用高速旋转螺旋桨在事件流中的独特特征，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有MAV检测方法主要依赖RGB图像中的外观特征，但由于目标多样性，难以实现通用检测。作者发现不同类型MAV在事件流中因高速旋转螺旋桨具有共同特征，因此探索如何利用事件相机检测MAV。

研究方法: 方法包含三个模块：提取螺旋桨的显著时空特征，同时过滤背景噪声和相机运动干扰。由于缺乏事件相机MAV数据集，作者还构建了一个包含多场景和不同类型MAV的首个事件相机数据集。

研究结果: 无需训练，该方法在测试数据集上显著优于现有方法，精度达83.0%（提升30.3%），召回率达81.5%（提升36.4%）。

研究结论: 通过事件相机捕捉螺旋桨特征，实现了高效且通用的MAV检测，为相关研究提供了新数据集和方法支持。

中文摘要: 现有的微型飞行器（MAV）检测方法主要依赖RGB图像中的目标外观特征，但由于目标多样性，难以实现通用检测。我们注意到，不同类型MAV在事件流中因高速旋转螺旋桨具有共同特征，而这些特征在RGB图像中难以捕捉。本文研究了如何通过充分利用事件流中螺旋桨的特征，从事件相机中检测不同类型的MAV。所提方法包含三个模块，用于提取螺旋桨的显著时空特征，同时过滤背景物体和相机运动带来的噪声。由于目前缺乏基于事件相机的MAV数据集，我们为研究社区引入了一个新的数据集。这是首个包含多场景和不同类型MAV的事件相机数据集。无需训练，我们的方法显著优于现有方法，并能应对复杂场景，在测试数据集上实现了83.0%的精度（提升30.3%）和81.5%的召回率（提升36.4%）。数据集和代码已开源：https://github.com/WindyLab/EvDetMAV。

</details>


### [93] [Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System](https://arxiv.org/abs/2506.19433)
**中文标题：Mem4Nav：基于分层空间认知长短记忆系统的城市环境视觉与语言导航增强**

*Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li*

主要分类: cs.CV

摘要简述: Mem4Nav是一种用于增强视觉与语言导航（VLN）的分层空间认知长短记忆系统，通过稀疏八叉树和语义拓扑图结合，显著提升了任务完成率和导航效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有VLN方法在大型城市环境中存在记忆不统一、上下文窗口固定和空间推理隐式的问题，Mem4Nav旨在通过分层记忆系统解决这些挑战。

研究方法: Mem4Nav结合稀疏八叉树（用于细粒度体素索引）和语义拓扑图（用于高层地标连接），通过可逆Transformer嵌入记忆令牌。长时记忆（LTM）压缩历史观测，短时记忆（STM）缓存近期多模态输入以支持实时避障和局部规划。

研究结果: 在Touchdown和Map2Seq数据集上，Mem4Nav显著提升了任务完成率（7-13个百分点），减少了路径偏差（SPD），并提高了导航效率（nDTW提升超过10个百分点）。

研究结论: Mem4Nav通过分层地图和双记忆模块的协同作用，显著提升了VLN性能，证明了其在大规模城市环境导航中的有效性。

中文摘要: 视觉与语言导航（VLN）在大规模城市环境中要求智能体将语言指令与复杂场景结合，并在长时间跨度内回忆相关经验。现有模块化流程虽具可解释性但缺乏统一记忆，而端到端（M）LLM智能体虽擅长融合视觉与语言，却受限于固定上下文窗口和隐式空间推理。我们提出Mem4Nav，一种分层空间认知长短记忆系统，可增强任何VLN主干。Mem4Nav将稀疏八叉树（用于细粒度体素索引）与语义拓扑图（用于高层地标连接）结合，并通过可逆Transformer嵌入记忆令牌。长时记忆（LTM）压缩并保留历史观测（八叉树和图节点），短时记忆（STM）缓存近期多模态输入（相对坐标）以支持实时避障和局部规划。每一步中，STM检索动态修剪上下文；当需要更深历史时，LTM令牌无损解码以重建过去嵌入。在Touchdown和Map2Seq数据集上，Mem4Nav在三种主干（模块化、基于提示的LLM和跨步注意力MLLM）上均显著提升了任务完成率（7-13个百分点），减少了路径偏差（SPD），并提高了导航效率（nDTW提升超过10个百分点）。消融实验证实了分层地图和双记忆模块的必要性。代码已开源：https://github.com/tsinghua-fib-lab/Mem4Nav。

</details>


### [94] [AMF-MedIT: An Efficient Align-Modulation-Fusion Framework for Medical Image-Tabular Data](https://arxiv.org/abs/2506.19439)
**中文标题：AMF-MedIT：一种高效的医学图像与表格数据对齐-调制-融合框架**

*Congjing Yu,Jing Ye,Yang Liu,Xiaodong Zhang,Zhiyong Zhang*

主要分类: cs.CV

摘要简述: AMF-MedIT是一种高效的医学图像与表格数据融合框架，通过自适应调制与融合模块（AMF）解决跨模态特征维度差异和噪声问题，结合FT-Mamba表格编码器提升数据效率与性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态医学分析中，图像与表格数据的融合面临特征维度差异、模态贡献不平衡及高维表格噪声等挑战，尤其在数据稀缺条件下更为突出。

研究方法: 提出AMF模块，通过调制目标和模态置信比动态调整模态贡献；引入特征掩码、密度和泄漏损失实现调制；设计FT-Mamba表格编码器高效处理噪声数据；首次研究表格编码器在对比预训练中对图像模态的监督作用。

研究结果: AMF-MedIT在多模态性能与数据效率间取得优越平衡，对不完整表格数据表现出强适应性；FT-Mamba能提取独特表格特征并指导图像编码器生成更准确的注意力模式。

研究结论: AMF-MedIT为医学多模态数据融合提供了高效解决方案，尤其在数据稀缺条件下表现突出，同时通过可解释性分析验证了FT-Mamba的优越性。

中文摘要: 结合图像与表格数据的多模态医学分析日益受到关注，但由于特征维度差异、模态贡献不平衡及高维表格噪声等问题，有效融合仍具挑战性。为此，我们提出AMF-MedIT，一种高效的医学图像与表格数据对齐-调制-融合框架，特别适用于数据稀缺条件。为解决维度差异并动态调整模态贡献，我们设计了自适应调制与融合（AMF）模块，这是一种基于调制的新型融合范式，具有简洁架构。我们首先推导调制目标并引入模态置信比，将先验知识融入融合过程；随后提出特征掩码、密度和泄漏损失以实现调制目标。此外，我们引入FT-Mamba，一种利用选择性机制高效处理噪声医学表格数据的强大表格编码器。首次通过可解释性研究探讨不同表格编码器在对比预训练中如何监督图像模态。大量实验表明，AMF-MedIT在多模态性能与数据效率间取得优越平衡，同时对不完整表格数据表现出强适应性。可解释性分析还凸显了FT-Mamba在提取独特表格特征及引导图像编码器生成更准确灵活注意力模式方面的能力。

</details>


### [95] [Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty](https://arxiv.org/abs/2506.19442)
**中文标题：解释中的采样问题：通过最大化解释确定性构建视觉模型中可信的归因分析基础模块**

*Róisín Luo,James McDermott,Colm O'Riordan*

主要分类: cs.CV

摘要简述: 本文提出了一种半最优采样方法，通过抑制输入特征来解决梯度积分中样本分布与自然图像分布不对齐的问题，从而提高解释的可信度。实验证明该方法优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像归因分析中，梯度积分作为基础模块，其样本分布与自然图像分布的对齐程度决定了解释的可信度下限。然而，现有方法通过添加噪声生成样本，导致解释可信度低。本文旨在解决这一样本分布不对齐问题。

研究方法: 提出了一种半最优采样方法，通过抑制输入特征而非添加噪声来生成样本，使得样本分布更接近自然图像分布，从而提高解释的可信度。

研究结果: 在ImageNet数据集上的大量实验表明，该方法在所有实验模型中均优于现有基线，能够生成更令人满意的解释。

研究结论: 通过抑制输入特征生成样本的方法有效解决了样本分布不对齐问题，显著提高了归因分析的可信度，为视觉模型的解释提供了更可靠的构建模块。

中文摘要: 图像归因分析旨在突出视觉模型学习到的特征表示，使得这些特征图能够反映输入的像素级重要性。梯度积分是归因分析的基础模块，通过整合多个派生样本的梯度来突出与推理相关的语义特征。然而，我们的理论分析表明，梯度积分中样本分布与自然图像分布的对齐程度决定了解释的可信度下限。现有方法通过在图像中添加噪声生成样本，但噪声分布可能导致解释可信度低。实验表明，额外信息可能使神经网络饱和。因此，构建可信的归因分析需要解决样本分布不对齐问题。本文提出了一种半最优采样方法，通过抑制输入特征而非添加噪声来生成样本，使得样本分布更接近自然图像分布。在ImageNet数据集上的大量定量评估证实，该方法在所有实验模型中均优于现有基线，能够生成更令人满意的解释。

</details>


### [96] [Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos](https://arxiv.org/abs/2506.19445)
**中文标题：真实世界中的去模糊：基于智能手机高速视频的数据集**

*Mahdi Mohd Hossain Noki,Syed Mumtahin Mahmud,Prothito Shovon Majumder,Abdul Mohaimen Al Radi,Md. Haider Ali,Md. Mosaddek Khan*

主要分类: cs.CV

摘要简述: 本文提出了一个基于智能手机慢动作视频构建的最大规模真实世界图像去模糊数据集，包含超过42,000对高分辨率模糊-清晰图像对，并展示了现有去模糊模型在该数据集上的性能下降。


<details>
  <summary>详细信息</summary>
研究动机: 当前去模糊研究缺乏大规模、多样化的真实世界数据集，限制了模型的泛化能力。本文旨在通过智能手机慢动作视频构建一个更具挑战性的数据集，以推动去模糊技术的发展。

研究方法: 利用智能手机拍摄的240帧慢动作视频，通过平均帧模拟真实长曝光模糊，并将时间中心帧作为清晰参考，构建了包含42,000对高分辨率模糊-清晰图像的数据集。

研究结果: 实验表明，现有最先进的去模糊模型在该数据集上性能显著下降，突显了数据集的复杂性和多样性。

研究结论: 该数据集为去模糊研究提供了新的挑战性基准，有助于开发更鲁棒和泛化的模型。

中文摘要: 我们提出了一个基于智能手机慢动作视频构建的最大规模真实世界图像去模糊数据集。通过在一秒内捕获的240帧视频中平均帧来模拟真实的长曝光模糊，同时将时间中心帧作为清晰参考。我们的数据集包含超过42,000对高分辨率模糊-清晰图像，规模约为常用数据集的10倍，场景多样性是其8倍，涵盖室内外环境及不同物体和相机运动。我们在该数据集上测试了多种最先进的去模糊模型，观察到显著的性能下降，突显了我们基准的复杂性和多样性。该数据集为促进鲁棒且泛化的去模糊模型提供了新的挑战性基准。

</details>


### [97] [Stylized Structural Patterns for Improved Neural Network Pre-training](https://arxiv.org/abs/2506.19465)
**中文标题：风格化结构模式改进神经网络预训练**

*Farnood Salehi,Vandit Sharma,Amirhossein Askari Farsangi,Tunç Ozan Aydın*

主要分类: cs.CV

摘要简述: 本文提出了一种两步法改进神经网络预训练，通过改进神经分形生成新合成数据，并利用反向风格化技术提升数据效果，显著缩小合成数据与真实图像的分布差距，提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代深度学习模型依赖大量真实图像数据，但数据获取存在隐私和法律问题，合成数据虽为替代方案，但性能不足。本文旨在通过改进合成数据生成方法，缩小其与真实数据的差距，提升模型训练效果。

研究方法: 1. 提出改进的神经分形公式，生成新型合成数据；2. 提出反向风格化技术，将少量真实图像的特征迁移到合成数据中，增强数据实用性。

研究结果: 实验表明，本文方法显著降低了合成数据与真实图像的分布差距（KID指标）。EDM2扩散模型在合成数据上预训练后，图像生成的FID降低11%，自编码器重建误差减少20%。ViT-S分类模型在ImageNet-100上的准确率提升超过10%。

研究结论: 本文方法为缺乏大规模真实数据时的模型训练提供了有效解决方案，展示了合成数据在实际任务中的潜力。

中文摘要: 现代计算机视觉中的深度学习模型需要大量真实图像数据，但这些数据难以获取且存在隐私和法律问题，限制了其商业应用。近期研究提出合成数据作为替代方案，但基于其训练的模型性能较差。本文提出两步法以缩小这一差距：首先，通过改进神经分形公式生成新型合成数据；其次，提出反向风格化技术，将少量无版权真实图像的特征迁移到合成数据中，提升其效果。我们使用核初始距离（KID）分析合成数据与真实图像的领域差距，结果显示本文方法的分布差距显著低于现有合成数据。此外，多任务实验验证了这种差距缩小的实际影响。实验表明，在合成数据上预训练的EDM2扩散模型在图像生成中FID降低11%，自编码器重建误差减少20%，表明数据表示性能提升。ViT-S分类模型在ImageNet-100上的准确率提升超过10%。本研究为缺乏大规模真实数据时的模型训练提供了新思路。

</details>


### [98] [Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning](https://arxiv.org/abs/2506.19469)
**中文标题：Surgery-R1：通过强化学习推进基于推理多模态大语言模型的手术视觉问答定位**

*Pengfei Hao,Shuaibo Li,Hongqiu Wang,Zhizhuo Kou,Junhang Zhang,Guang Yang,Lei Zhu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Surgery-R1的多模态大语言模型，通过强化学习提升手术场景中的视觉问答定位能力，并构建了包含54k数据对的Surgery-R1-54k数据集。实验表明，该模型在Surgical-VQLA任务中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的Surgical-VQLA模型缺乏深度推理能力和可解释性，限制了其在临床应用中的可靠性和发展潜力。为解决这一问题，本文提出了一种具有推理能力的多模态大语言模型。

研究方法: 首先构建了包含视觉问答、定位问答和思维链数据的Surgery-R1-54k数据集。随后设计了一个两阶段微调机制（监督微调和强化微调），并引入了多模态一致性奖励机制以减少手术场景中的位置幻觉。

研究结果: 实验结果表明，Surgery-R1在Surgical-VQLA任务中优于其他现有模型，验证了其推理能力和方法的有效性。

研究结论: Surgery-R1通过结合多模态大语言模型和强化学习，显著提升了手术场景中的视觉问答定位能力，为临床应用提供了更可靠的解决方案。

中文摘要: 近年来，手术场景理解领域取得了显著进展，尤其是在机器人手术中的视觉问答定位任务（Surgical-VQLA）方面。然而，现有的Surgical-VQLA模型缺乏深度推理能力和手术场景中的可解释性，这限制了其在临床应用中的可靠性和发展潜力。为解决这一问题，受推理多模态大语言模型（MLLMs）发展的启发，我们首先构建了Surgery-R1-54k数据集，包括视觉问答、定位问答和思维链（CoT）的配对数据。随后，我们提出了首个用于Surgical-VQLA的推理MLLM（Surgery-R1）。在Surgery-R1中，我们设计了一个两阶段微调机制，通过监督微调（SFT）和强化微调（RFT）赋予基础MLLM复杂推理能力。此外，为了在我们的RFT中实现高效且高质量的基于规则的奖励系统，我们设计了一种多模态一致性奖励机制，以减少手术场景中可能出现的位置幻觉。实验结果表明，Surgery-R1在Surgical-VQLA任务中优于其他现有最先进（SOTA）模型和广泛使用的MLLMs，同时也验证了其推理能力和我们方法的有效性。代码和数据集将在https://github.com/FiFi-HAO467/Surgery-R1中整理发布。

</details>


### [99] [USIS16K: High-Quality Dataset for Underwater Salient Instance Segmentation](https://arxiv.org/abs/2506.19472)
**中文标题：USIS16K：用于水下显著实例分割的高质量数据集**

*Lin Hong,Xin Wang,Yihao Li,Xia Wang*

主要分类: cs.CV

摘要简述: 本文介绍了USIS16K数据集，这是一个包含16,151张高分辨率水下图像的大规模数据集，涵盖158类水下物体，每张图像均标注了高质量的实例级显著物体掩码。该数据集在多样性、复杂性和可扩展性方面具有显著优势，并为水下物体检测和显著实例分割任务提供了基准评估。


<details>
  <summary>详细信息</summary>
研究动机: 水下显著实例分割（USIS）是一个未被充分探索的挑战，主要由于水下环境的不可访问性和动态性，以及缺乏大规模、高质量标注数据集。本文旨在填补这一空白，推动USIS领域的研究。

研究方法: 本文提出了USIS16K数据集，包含16,151张高分辨率水下图像，覆盖多种环境设置和158类水下物体。每张图像均标注了高质量的实例级显著物体掩码。此外，还基于该数据集提供了水下物体检测和USIS任务的基准评估。

研究结果: USIS16K数据集在多样性、复杂性和可扩展性方面表现优异，为水下显著实例分割任务提供了高质量的数据支持。基准评估结果展示了该数据集在实际应用中的潜力。

研究结论: USIS16K数据集为水下显著实例分割研究提供了重要的资源，填补了该领域数据集的空白。公开的数据集和基准模型将促进未来研究的进展。

中文摘要: 受生物视觉系统选择性分配注意力以高效识别显著物体或区域的启发，水下显著实例分割（USIS）旨在联合解决水下场景中“看哪里”（显著性预测）和“是什么”（实例分割）的问题。然而，由于水下环境的不可访问性和动态性，以及缺乏大规模、高质量标注数据集，USIS仍是一个未被充分探索的挑战。本文介绍了USIS16K，这是一个包含16,151张高分辨率水下图像的大规模数据集，覆盖多种环境设置和158类水下物体。每张图像均标注了高质量的实例级显著物体掩码，在多样性、复杂性和可扩展性方面具有显著优势。此外，我们基于USIS16K提供了水下物体检测和USIS任务的基准评估。为促进该领域的未来研究，数据集和基准模型已公开提供。

</details>


### [100] [Recurrent Visual Feature Extraction and Stereo Attentions for CT Report Generation](https://arxiv.org/abs/2506.19665)
**中文标题：循环视觉特征提取与立体注意力机制用于CT报告生成**

*Yuanhe Tian,Lei Mao,Yan Song*

主要分类: cs.CV

摘要简述: 本文提出了一种基于大语言模型（LLM）的CT报告生成方法，通过循环视觉特征提取和立体注意力机制，有效整合CT切片的多层次特征，显著提升了报告生成的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的CT报告生成方法通常采用通用2D或3D图像处理技术，未能充分考虑CT切片间的变换关系，也无法有效整合包含特定器官病变的多层次图像特征。因此，本文旨在解决这些问题，提出一种更有效的CT报告生成方法。

研究方法: 本文方法使用视觉Transformer循环处理CT体积中的每个切片，并通过立体注意力机制从不同视角选择重要视觉信息，将其与文本特征对齐，以指导大语言模型生成报告。

研究结果: 在M3D-Cap基准数据集上的实验结果表明，该方法优于现有基线模型，并取得了最先进的性能，验证了其有效性和优越性。

研究结论: 本文提出的循环视觉特征提取和立体注意力机制能够有效整合CT切片的多层次特征，显著提升CT报告生成的性能，为医学图像报告生成领域提供了新的解决方案。

中文摘要: 为计算机断层扫描（CT）图像生成报告是一项具有挑战性的任务，尽管与现有医学图像报告生成研究类似，但其具有独特的特点，如多图像的空间编码、图像体积与文本的对齐等。现有解决方案通常使用通用的2D或3D图像处理技术从CT体积中提取特征，首先压缩体积，然后将压缩后的CT切片划分为块进行视觉编码。这些方法未明确考虑CT切片间的变换关系，也未有效整合包含特定器官病变的多层次图像特征以指导CT报告生成（CTRG）。考虑到CT扫描中连续切片间的强相关性，本文提出了一种基于大语言模型（LLM）的CTRG方法，通过循环视觉特征提取和立体注意力机制实现分层特征建模。具体而言，我们使用视觉Transformer循环处理CT体积中的每个切片，并通过一组从不同视角的注意力机制选择性地获取重要视觉信息，并将其与文本特征对齐，以更好地指导LLM生成CT报告。在基准M3D-Cap数据集上的实验结果和进一步分析表明，我们的方法优于现有基线模型，并取得了最先进的性能，验证了其有效性和优越性。

</details>


### [101] [HMSViT: A Hierarchical Masked Self-Supervised Vision Transformer for Corneal Nerve Segmentation and Diabetic Neuropathy Diagnosis](https://arxiv.org/abs/2506.19474)
**中文标题：HMSViT：一种用于角膜神经分割和糖尿病神经病变诊断的分层掩码自监督视觉Transformer**

*Xin Zhang,Liangxiu Han,Yue Shi,Yanlin Zheng,Alam Uazman,Maryam Ferdousi,Rayaz Malik*

主要分类: cs.CV

摘要简述: HMSViT是一种新型分层掩码自监督视觉Transformer，用于角膜神经分割和糖尿病神经病变诊断，通过多尺度特征提取和自监督学习，显著提升了性能并减少了对标注数据的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 糖尿病周围神经病变（DPN）影响近半数糖尿病患者，需早期检测。现有角膜共聚焦显微镜（CCM）自动诊断方法存在特征提取效率低、依赖手工先验和数据不足的问题。

研究方法: HMSViT采用基于池化的分层和双重注意力机制，结合绝对位置编码，实现高效多尺度特征提取。设计了块掩码自监督学习框架以减少对标注数据的依赖，并通过多尺度解码器融合分层特征进行分割和分类。

研究结果: 在临床CCM数据集上，HMSViT在神经分割任务中达到61.34%的mIoU，诊断准确率为70.40%，优于Swin Transformer和HiViT等模型，且参数量更少。

研究结论: HMSViT通过结合块掩码自监督学习和分层多尺度特征提取，显著提升了性能，展示了其在真实诊断应用中的潜力。

中文摘要: 糖尿病周围神经病变（DPN）影响近半数糖尿病患者，需早期检测。角膜共聚焦显微镜（CCM）可实现无创诊断，但现有自动方法存在特征提取效率低、依赖手工先验和数据不足的问题。我们提出HMSViT，一种新型分层掩码自监督视觉Transformer（HMSViT），专为角膜神经分割和DPN诊断设计。与现有方法不同，HMSViT采用基于池化的分层和双重注意力机制，结合绝对位置编码，通过早期层捕获细粒度局部细节并在深层整合全局上下文，实现高效多尺度特征提取，同时降低计算成本。设计了块掩码自监督学习框架以减少对标注数据的依赖，增强特征鲁棒性，并通过多尺度解码器融合分层特征进行分割和分类。在临床CCM数据集上的实验表明，HMSViT在神经分割任务中达到61.34%的mIoU，诊断准确率为70.40%，优于Swin Transformer和HiViT等领先分层模型，分割精度提升高达6.39%，且参数量更少。详细消融研究进一步表明，与传统监督训练相比，块掩码自监督学习与分层多尺度特征提取的结合显著提升了性能。总体而言，这些全面实验证实HMSViT提供了优异、鲁棒且临床可行的结果，展示了其在真实诊断应用中规模化部署的潜力。

</details>


### [102] [SceneCrafter: Controllable Multi-View Driving Scene Editing](https://arxiv.org/abs/2506.19488)
**中文标题：SceneCrafter：可控的多视角驾驶场景编辑**

*Zehao Zhu,Yuliang Zou,Chiyu Max Jiang,Bo Sun,Vincent Casser,Xiukun Huang,Jiahao Wang,Zhenpei Yang,Ruiqi Gao,Leonidas Guibas,Mingxing Tan,Dragomir Anguelov*

主要分类: cs.CV

摘要简述: SceneCrafter是一种可控的多视角驾驶场景编辑工具，通过多视图扩散模型和创新的数据合成框架，解决了驾驶场景编辑中的3D一致性、遮挡处理和几何一致性等挑战，实现了高真实感和可控性。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶系统的开发和评估依赖于仿真，但纯合成场景缺乏现实基础，难以令人信服。编辑模型利用真实驾驶日志，能够模拟不同交通布局、行为和天气条件，但面临多视角3D一致性、遮挡处理和几何一致性等新挑战。

研究方法: SceneCrafter基于多视图扩散模型，提出了一种可控框架，支持天气、时间、代理框和高清地图等多模态条件。通过Prompt-to-Prompt生成几何一致的合成配对数据，并利用掩码训练和多视图重绘范式合成局部编辑数据。

研究结果: SceneCrafter在真实感、可控性、3D一致性和场景编辑质量方面优于现有基线，展示了强大的编辑能力。

研究结论: SceneCrafter通过创新的多视图编辑框架和数据合成方法，显著提升了驾驶场景编辑的真实感和可控性，为自动驾驶仿真提供了更可靠的解决方案。

中文摘要: 仿真是开发和评估自动驾驶（AV）系统的关键。近期研究基于新一代生成模型合成高真实感图像以支持全栈仿真。然而，纯合成场景缺乏现实基础，难以证明其结果的实用性。编辑模型则利用真实驾驶日志中的源场景，能够模拟不同交通布局、行为和天气条件。尽管图像编辑是计算机视觉的成熟课题，但在驾驶仿真中面临新挑战：（1）跨摄像头3D一致性需求；（2）从遮挡数据中学习“空街”先验；（3）在保持布局和几何一致性的同时获取多样编辑条件的配对图像。为此，我们提出SceneCrafter，一种多摄像头捕获驾驶场景的3D一致性编辑工具。基于多视图扩散模型的最新进展，我们构建了一个完全可控的框架，支持天气、时间、代理框和高清地图等多模态条件。为生成监督编辑模型的配对数据，我们在Prompt-to-Prompt基础上提出新框架，生成具有全局编辑的几何一致合成数据。此外，通过掩码训练和多视图重绘范式，我们引入alpha混合框架合成局部编辑数据。SceneCrafter展示了强大的编辑能力，在真实感、可控性、3D一致性和场景编辑质量上优于现有基线。

</details>


### [103] [Visual hallucination detection in large vision-language models via evidential conflict](https://arxiv.org/abs/2506.19513)
**中文标题：基于证据冲突的大型视觉语言模型视觉幻觉检测**

*Tao Huang,Zhekun Liu,Rui Wang,Yang Zhang,Liping Jing*

主要分类: cs.CV

摘要简述: 大型视觉语言模型（LVLMs）存在视觉幻觉问题，即视觉输入与文本输出不一致。本文提出了一种基于Dempster-Shafer理论（DST）的检测方法，通过不确定性估计高效捕捉模型推理阶段的高级特征冲突。实验表明，该方法在三种LVLMs上优于五种基线不确定性指标，平均AUROC提升4%、10%和7%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型视觉语言模型（LVLMs）在多模态能力上表现卓越，但其视觉输入与文本输出之间常存在不一致性（视觉幻觉），这在安全关键的人工智能应用中带来重大风险。现有评估基准主要关注感知能力，忽略了高级推理能力引发的幻觉问题，亟需系统性评估和有效检测方法。

研究方法: 本文首先开发了感知-推理评估幻觉（PRE-HAL）数据集，系统评估LVLMs在实例、场景和关系等多重视觉语义上的感知与推理能力。随后提出基于Dempster-Shafer理论（DST）的视觉幻觉检测方法，通过简单质量函数降低证据组合的计算复杂度，高效捕捉模型推理阶段的高级特征冲突。

研究结果: 实验评估了三种先进LVLMs（LLaVA-v1.5、mPLUG-Owl2和mPLUG-Owl3），结果显示所提方法在PRE-HAL基准上优于五种基线不确定性指标，平均AUROC分别提升4%、10%和7%。

研究结论: 本文提出的DST方法能有效检测LVLMs的视觉幻觉问题，尤其在关系推理任务中表现突出，为提升模型可靠性提供了新思路。

中文摘要: 尽管大型视觉语言模型（LVLMs）在多模态能力上表现卓越，但其视觉输入与文本输出之间常存在不一致性——我们称之为视觉幻觉。这一关键可靠性问题在安全关键的人工智能应用中带来重大风险，亟需系统性评估和有效检测方法。首先，我们发现现有视觉幻觉评估基准主要从感知角度评估LVLMs，忽略了高级推理能力引发的幻觉问题。为此，我们开发了感知-推理评估幻觉（PRE-HAL）数据集，系统评估LVLMs在实例、场景和关系等多重视觉语义上的感知与推理能力。基于这一新基准的全面评估揭示了更多视觉漏洞，尤其在更具挑战性的关系推理任务中。为解决这一问题，我们首次提出基于Dempster-Shafer理论（DST）的视觉幻觉检测方法，通过不确定性估计高效捕捉模型推理阶段的高级特征冲突。具体而言，该方法采用简单质量函数以降低证据组合的计算复杂度。我们在PRE-HAL基准上对三种先进LVLMs（LLaVA-v1.5、mPLUG-Owl2和mPLUG-Owl3）进行了广泛评估。实验结果表明，所提方法优于五种基线不确定性指标，平均AUROC分别提升4%、10%和7%。代码发布于https://github.com/HT86159/Evidential-Conflict。

</details>


### [104] [ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation](https://arxiv.org/abs/2506.19531)
**中文标题：ReMAR-DS：用于金属伪影减少和CT域转换的重新校准特征学习**

*Mubashara Rehman,Niki Martinel,Michele Avanzo,Riccardo Spizzo,Christian Micheloni*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ReMAR-DS的深度学习框架，用于减少千伏CT（kVCT）成像中的金属伪影，并将其转换为兆伏CT（MVCT）域。该方法通过增强特征重新校准，有效减少伪影并保留解剖结构，从而提升放疗计划的质量。


<details>
  <summary>详细信息</summary>
研究动机: 千伏CT成像中的金属伪影会降低图像质量，影响临床决策。传统方法难以在保留高分辨率的同时减少伪影，且无法实现kVCT到MVCT的域转换。因此，需要一种新方法来同时解决这些问题。

研究方法: ReMAR-DS采用编码器-解码器架构，通过增强的特征重新校准机制，专注于伪影区域的关键空间特征和解剖结构的通道特征。该方法利用重新校准的特征，优化重建过程，生成高质量的MVCT样图像。

研究结果: 实验表明，ReMAR-DS能够有效减少金属伪影并保留解剖结构，生成高质量的MVCT样重建图像。定性和定量评估验证了其优于传统方法的性能，为放疗计划提供了更可靠的图像支持。

研究结论: ReMAR-DS通过特征重新校准和域转换，显著提升了千伏CT图像的质量，减少了重复高剂量MVCT扫描的需求，降低了患者的辐射暴露。该方法为临床决策提供了更可靠的图像支持。

中文摘要: 千伏CT（kVCT）成像中的伪影会降低图像质量，影响临床决策。我们提出了一种深度学习框架，用于减少金属伪影（MAR）并将kVCT转换为兆伏CT（MVCT）。所提出的框架ReMAR-DS采用编码器-解码器架构，通过增强的特征重新校准机制，有效减少伪影的同时保留解剖结构，确保重建过程中仅利用相关信息。通过从编码器块注入重新校准的特征，模型专注于相关空间区域（如伪影区域）并突出通道中的关键特征（如解剖结构），从而改善伪影污染区域的重建。与传统MAR方法不同，我们的方法填补了高分辨率kVCT与抗伪影MVCT之间的空白，提升了放疗计划的质量。该方法生成的高质量MVCT样重建图像通过定性和定量评估得到验证。在临床应用中，这使得肿瘤学家可以仅依赖kVCT，减少重复高剂量MVCT扫描，降低癌症患者的辐射暴露。

</details>


### [105] [Identifying Physically Realizable Triggers for Backdoored Face Recognition Networks](https://arxiv.org/abs/2506.19533)
**中文标题：识别后门面部识别网络中物理可实现的触发器**

*Ankita Raj,Ambar Pal,Chetan Arora*

主要分类: cs.CV

摘要简述: 本文提出了一种新技术，用于检测和识别面部识别网络中可能存在的自然物理可实现的触发器后门攻击，并在实验中展示了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 后门攻击通过隐藏的触发器在面部识别网络中植入异常行为，对高安全性应用构成威胁。现有研究表明，自然外观的触发器（如特定太阳镜）可能被用于此类攻击，因此需要开发检测和识别这些触发器的方法。

研究方法: 作者提出了一种新技术，能够（1）检测面部识别网络是否被植入自然物理可实现的触发器后门，（2）在确认网络被攻击后识别具体的触发器（如绿色太阳镜或红色帽子）。

研究结果: 实验表明，该方法在识别触发器方面的前5准确率达到74%，显著优于仅56%的暴力搜索基线方法。

研究结论: 该技术为检测和识别面部识别网络中的后门触发器提供了有效手段，有助于提升高安全性应用中的系统安全性。

中文摘要: 后门攻击通过将隐藏功能嵌入深度神经网络中，使网络在输入触发器的预定模式激活时表现出异常行为，而在公开测试数据上表现正常。近期研究表明，后门面部识别系统可能对自然外观的触发器（如特定太阳镜）产生响应，这对高安全性应用中的面部识别系统构成严重威胁。我们提出了一种新技术，用于（1）检测面部识别网络是否被植入自然物理可实现的触发器后门，（2）在确认网络被攻击后识别此类触发器。我们通过一个被攻击的面部识别网络验证了方法的有效性，能够以74%的前5准确率识别触发器（如绿色太阳镜或红色帽子），而暴力搜索基线方法的准确率仅为56%。

</details>


### [106] [General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound](https://arxiv.org/abs/2506.19552)
**中文标题：通用方法成就卓越领域专用基础模型：以胎儿超声为例**

*Jakob Ambsdorf,Asbjørn Munk,Sebastian Llambias,Anders Nymark Christensen,Kamil Mikolaj,Randall Balestriero,Martin Tolsgaard,Aasa Feragen,Mads Nielsen*

主要分类: cs.CV

摘要简述: 本研究通过胎儿超声案例证明，使用通用方法（如DINOv2）在特定领域数据（如2M胎儿超声图像）上预训练定制基础模型，即使数据量较小，也能超越自然图像预训练模型，且无需复杂调参或方法创新。


<details>
  <summary>详细信息</summary>
研究动机: 面对大规模无标签医学数据，研究者常需选择是预训练定制基础模型还是迁移学习通用模型。本文旨在探讨这一问题，并验证通用方法在医学领域的适用性。

研究方法: 采用DINOv2方法对2M胎儿超声图像进行预训练，并在三个不同国家的数据集上测试分类、分割和少样本任务性能，与自然图像和超声图像预训练模型及监督基线对比。

研究结果: 结果表明：(i) 定制数据预训练优于自然图像预训练，即使数据量较小；(ii) 通用计算机视觉方法（如DINOv2）可直接用于医学领域，无需复杂调参或方法创新。

研究结论: 在资源有限的情况下，开发领域特定基础模型时应避免过度追求方法创新，通用方法已足够高效。

中文摘要: 面对大规模无标签医学数据，研究者常面临两个问题：是否应预训练定制基础模型，还是迁移学习通用模型？若预训练定制模型，是否需要新方法？本文通过胎儿超声案例研究（2M图像）探讨这些问题。采用DINOv2方法预训练后，在三个胎儿超声数据集（涵盖不同国家、分类、分割和少样本任务）上取得最佳性能。与自然图像、超声图像预训练模型及监督基线对比后，得出两个关键结论：(i) 定制数据预训练值得投入，即使数据量较小，因自然图像预训练的扩展性不适用于超声领域；(ii) 计算机视觉通用方法（如DINOv2）可直接用于医学领域，无需调参或方法创新。基于此，我们认为在资源有限时，开发领域专用基础模型应避免过度追求方法创新。

</details>


### [107] [MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification](https://arxiv.org/abs/2506.19561)
**中文标题：MambaOutRS：一种用于遥感图像分类的混合CNN-傅里叶架构**

*Minjong Cheon,Changbae Mun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MambaOutRS的新型混合卷积架构，用于遥感图像分类。该架构结合了门控CNN块和傅里叶滤波门模块，在多个遥感数据集上实现了最先进的性能，同时显著减少了参数数量。


<details>
  <summary>详细信息</summary>
研究动机: 尽管状态空间模型（SSMs）如Mamba在视觉任务中表现出色，但其在二维视觉数据上的应用往往需要复杂修改，可能降低效率。本文旨在重新评估SSMs的必要性，并提出一种更高效的混合架构。

研究方法: MambaOutRS采用四阶段分层设计，结合堆叠的门控CNN块进行局部特征提取，并引入傅里叶滤波门（FFG）模块在频域中高效捕获全局上下文信息。

研究结果: 在UC Merced、AID、NWPU-RESISC45和EuroSAT数据集上，MambaOutRS均实现了最先进的性能，其中MambaOutRS-t变体（2400万参数）在UC Merced和AID上的F1分数分别达到98.41%和95.99%。

研究结论: 研究表明，通过合理结合门控卷积和频域全局上下文模块，可以高效替代复杂的SSMs，为遥感及其他视觉领域提供高性能且计算高效的深度学习模型。

中文摘要: 深度学习在视觉任务中的最新进展推动了状态空间模型（SSMs）如Mamba的兴起，因其线性可扩展性而备受赞誉。然而，其在二维视觉数据上的适应通常需要复杂的修改，可能降低效率。本文提出MambaOutRS，一种用于遥感图像分类的新型混合卷积架构，重新评估了循环SSMs的必要性。MambaOutRS基于堆叠的门控CNN块进行局部特征提取，并引入了一种新颖的傅里叶滤波门（FFG）模块，在频域中高效捕获全局上下文信息。我们的架构采用四阶段分层设计，并在多个具有挑战性的遥感数据集（UC Merced、AID、NWPU-RESISC45和EuroSAT）上进行了广泛评估。MambaOutRS在这些基准测试中均实现了最先进的性能。值得注意的是，我们的MambaOutRS-t变体（2400万参数）在UC Merced和AID上的F1分数分别达到98.41%和95.99%，显著优于现有基线，包括更大的Transformer模型和基于Mamba的架构，尽管使用了更少的参数。消融研究明确证明了傅里叶滤波门在增强模型捕获全局空间模式能力中的关键作用，从而实现鲁棒且准确的分类。这些结果强烈表明，通过合理结合门控卷积进行空间混合和基于频率的门控进行全局上下文捕获，可以有效替代复杂的循环SSMs。因此，MambaOutRS为遥感及其他视觉领域开发高性能深度学习模型提供了一种高效且引人注目的范式，尤其是在计算效率至关重要的情况下。

</details>


### [108] [SMARTIES: Spectrum-Aware Multi-Sensor Auto-Encoder for Remote Sensing Images](https://arxiv.org/abs/2506.19585)
**中文标题：SMARTIES：面向遥感图像的频谱感知多传感器自编码器**

*Gencer Sumbul,Chang Xu,Emanuele Dalsasso,Devis Tuia*

主要分类: cs.CV

摘要简述: SMARTIES是一种通用的多传感器遥感图像处理基础模型，通过将异构传感器数据映射到共享的频谱感知空间，实现跨传感器的灵活训练和推理，显著优于依赖传感器特定预训练的模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度学习模型通常针对单一传感器或固定组合设计，限制了其在多传感器遥感数据处理中的扩展性和泛化能力。研究旨在开发一种能够适应不同传感器输入的通用模型，以提升多传感器数据处理的灵活性和效率。

研究方法: SMARTIES通过训练一个统一的Transformer模型，利用跨传感器令牌混合技术重构掩码多传感器数据，将异构传感器数据投影到共享的频谱感知空间，实现传感器无关的特征表示。

研究结果: 在单模态和多模态任务中，SMARTIES在多种传感器上的表现优于依赖传感器特定预训练的模型，展示了其卓越的扩展性和泛化能力。

研究结论: SMARTIES为多传感器遥感数据处理提供了一种灵活且高效的解决方案，显著提升了模型的通用性和适应性。

中文摘要: 从光学传感器到微波雷达，利用遥感传感器的互补优势对于实现地球的密集时空监测至关重要。然而，当前的深度学习模型（无论是任务特定还是基础模型）通常仅适用于单一传感器或固定组合：适应不同传感器输入需要架构更改和重新训练，限制了其在多传感器间的扩展性和泛化能力。相反，一个能够调节其特征表示以接受多样化传感器输入的单一模型，将为敏捷灵活的多传感器遥感数据处理铺平道路。为此，我们提出了SMARTIES，一种通用且多功能的基础模型，消除了传感器特定的依赖，实现了对多样化传感器的扩展性和泛化能力：SMARTIES将异构传感器数据投影到共享的频谱感知空间，支持任意波段组合的训练和推理。为获得传感器无关的表示，我们训练了一个统一的Transformer模型，通过跨传感器令牌混合重构掩码多传感器数据。在多种传感器的单模态和多模态任务中，SMARTIES均优于依赖传感器特定预训练的模型。我们的代码和预训练模型可在https://gsumbul.github.io/SMARTIES获取。

</details>


### [109] [Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications](https://arxiv.org/abs/2506.19591)
**中文标题：基于视觉Transformer的时间序列图像重建在云填补应用中的研究**

*Lujun Li,Yiqun Wang,Radu State*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉Transformer（ViT）的时间序列多光谱图像（MSI）重建框架，用于填补云覆盖区域的缺失数据。通过结合MSI的时间一致性和合成孔径雷达（SAR）的互补信息，显著提升了重建效果。


<details>
  <summary>详细信息</summary>
研究动机: 多光谱图像（MSI）中的云覆盖会导致光谱信息缺失或损坏，影响早期作物测绘的准确性。合成孔径雷达（SAR）数据不受云干扰，但缺乏足够的光谱细节。因此，需要一种方法结合两者的优势，填补云覆盖区域的MSI数据。

研究方法: 提出了一种基于视觉Transformer（ViT）的时间序列MSI图像重建框架。该框架利用MSI的时间一致性和SAR的互补信息，通过注意力机制实现云覆盖区域的MSI数据重建。

研究结果: 实验表明，该框架在云覆盖区域的MSI图像重建中显著优于仅使用非时间序列MSI和SAR或仅使用时间序列MSI的基线方法。

研究结论: 基于ViT的时间序列MSI图像重建框架有效结合了MSI和SAR的优势，显著提升了云覆盖区域的数据重建效果，为早期作物测绘提供了可靠支持。

中文摘要: 多光谱图像（MSI）中的云覆盖对早期作物测绘提出了重大挑战，因为它会导致光谱信息的缺失或损坏。合成孔径雷达（SAR）数据不受云干扰，提供了互补解决方案，但缺乏足够的光谱细节以实现精确的作物测绘。为此，我们提出了一种新颖的框架，即基于视觉Transformer（ViT）的时间序列MSI图像重建，通过利用MSI的时间一致性和SAR的互补信息，结合注意力机制，重建云覆盖区域的MSI数据。通过严格的图像重建评估指标进行的全面实验表明，时间序列ViT框架显著优于仅使用非时间序列MSI和SAR或仅使用时间序列MSI的基线方法，有效提升了云覆盖区域的MSI图像重建效果。

</details>


### [110] [ScaleCap: Inference-Time Scalable Image Captioning via Dual-Modality Debiasing](https://arxiv.org/abs/2506.19848)
**中文标题：ScaleCap：通过双重模态去偏实现推理时可扩展的图像描述生成**

*Long Xing,Qidong Huang,Xiaoyi Dong,Pan Zhang,Yuhang Zang,Yuhang Cao,Jinsong Li,Shuangrui Ding,Weiming Zhang,Nenghai Yu,Jiaqi Wang,Feng Wu,Dahua Lin*

主要分类: cs.CV

摘要简述: ScaleCap是一种推理时可扩展的图像描述生成策略，通过双重模态去偏技术生成更全面和详细的图像描述。


<details>
  <summary>详细信息</summary>
研究动机: 高质量图像描述生成面临两大挑战：多模态偏差导致描述粒度不均衡，语言偏差引发对不存在对象的幻觉描述。ScaleCap旨在通过动态去偏策略解决这些问题。

研究方法: ScaleCap提出两种新组件：启发式问答和对比句子评分。前者通过图像生成特定问题并回答，逐步丰富描述；后者通过句子级离线对比解码消除语言偏差导致的幻觉。

研究结果: 实验表明，ScaleCap在11个基准测试中表现优异，生成的描述更准确、平衡且信息丰富。此外，其在VQA任务和图像重建任务中展示了出色的语义覆盖能力。

研究结论: ScaleCap通过动态去偏和逐步丰富描述的策略，显著提升了图像描述的质量和多样性，为多模态模型训练提供了有效工具。

中文摘要: 本文提出ScaleCap，一种推理时可扩展的图像描述生成策略，能够生成全面且详细的图像描述。高质量图像描述的关键挑战在于LVLMs的固有偏差：多模态偏差导致描述粒度不均衡，对某些元素详细描述而对其他元素轻描淡写；语言偏差导致对不存在对象的幻觉描述。为解决这些问题，我们提出了一种可扩展的去偏描述生成策略，通过增加推理预算逐步丰富和校准描述。具体而言，我们提出了两种新组件：启发式问答和对比句子评分。前者基于图像生成特定问题并回答，逐步将相关信息注入描述中；后者采用句子级离线对比解码，有效识别并消除语言偏差导致的幻觉。随着推理成本的增加，ScaleCap提出更多启发式问题，逐步捕捉更多视觉细节，生成更准确、平衡且信息丰富的描述。广泛的多模态对齐实验证明了ScaleCap的有效性。使用ScaleCap标注45万张图像并用于LVLM预训练，在11个广泛使用的基准测试中实现了性能的持续提升。此外，ScaleCap在两项额外任务中展示了生成描述的丰富性和保真度：在VQA任务中用描述替换图像，以及通过描述重建图像以评估语义覆盖。代码发布于https://github.com/Cooperx521/ScaleCap。

</details>


### [111] [Implementing blind navigation through multi-modal sensing and gait guidance](https://arxiv.org/abs/2506.19593)
**中文标题：通过多模态感知和步态引导实现盲人导航**

*Feifan Yan,Tianle Zeng,Meixi He*

主要分类: cs.CV

摘要简述: 本文提出了一种基于步态引导系统和多模态感知的可穿戴盲人导航设备，通过实验证明其性能优于传统导盲杖。


<details>
  <summary>详细信息</summary>
研究动机: 全球视力障碍人口超过2.2亿，传统导盲工具如导盲杖和导盲犬存在不足，亟需更高效的导航辅助设备。

研究方法: 设计了一种可穿戴设备，结合步态相位分析进行行走引导，并利用多模态感知获取环境信息。在室内外实验中与传统导盲杖对比。

研究结果: 实验结果表明，该设备在盲人导航中表现优于传统导盲杖。

研究结论: 该设备通过步态引导和多模态感知，为视力障碍者提供了更高效的导航解决方案。

中文摘要: 截至2023年，全球视力障碍人口已超过2.2亿。视力障碍者在寻找路径或避开障碍物时会遇到困难，通常需要辅助工具的帮助。尽管传统的辅助工具如导盲杖和导盲犬存在，但它们仍有一些不足。本文提出了一种可穿戴盲人导航设备，通过我们提出的基于步态的引导系统进行导航引导。该设备创新性地集成了步态相位分析用于行走引导，并在环境感知方面使用多模态感知获取多样化的环境信息。在实验中，我们进行了室内和室外实验，并与标准导盲杖进行了对比。结果表明，我们的设备在盲人导航中表现出优越的性能。

</details>


### [112] [Self-Supervised Multimodal NeRF for Autonomous Driving](https://arxiv.org/abs/2506.19615)
**中文标题：自监督多模态NeRF在自动驾驶中的应用**

*Gaurav Sharma,Ravi Kothari,Josef Schmid*

主要分类: cs.CV

摘要简述: 本文提出了一种基于神经辐射场（NeRF）的自监督多模态框架NVSF，用于自动驾驶场景中的静态和动态场景建模，无需3D标签，并通过启发式像素采样和双梯度掩码优化训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶场景中需要同时处理LiDAR和相机数据，现有方法依赖3D标签且效率不高。本文旨在开发一种自监督的多模态NeRF框架，以解决这些问题。

研究方法: 提出NVSF框架，联合学习LiDAR和相机的时空隐式神经表示；采用启发式像素采样和双梯度掩码优化训练效率和局部特征保留。

研究结果: 在KITTI-360数据集上的实验表明，NVSF在LiDAR和相机领域均优于基线模型。

研究结论: NVSF是一种高效的自监督多模态NeRF框架，适用于自动驾驶场景，无需3D标签且性能优越。

中文摘要: 本文提出了一种基于神经辐射场（NeRF）的框架，称为新视角合成框架（NVSF），用于联合学习LiDAR和相机的时空隐式神经表示。我们在包含静态和动态场景的真实自动驾驶场景中测试了该框架。与现有的多模态动态NeRF相比，我们的框架是自监督的，因此无需3D标签。为了提高训练效率和收敛速度，我们引入了基于启发式的图像像素采样方法，专注于信息丰富的像素。为了保留LiDAR点的局部特征，采用了基于双梯度的掩码。在KITTI-360数据集上的大量实验表明，与基线模型相比，我们的框架在LiDAR和相机领域均表现出最佳性能。模型代码可在https://github.com/gaurav00700/Selfsupervised-NVSF获取。

</details>


### [113] [VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks](https://arxiv.org/abs/2506.19621)
**中文标题：VideoPCDNet：基于相位相关网络的视频解析与预测**

*Noel José Rodrigues Vicente,Enrique Lehner,Angel Villar-Corrales,Jan Nogga,Sven Behnke*

主要分类: cs.CV

摘要简述: VideoPCDNet是一种无监督框架，通过频域相位相关技术分解视频为对象组件，实现准确且可解释的跟踪与预测。


<details>
  <summary>详细信息</summary>
研究动机: 动态环境中理解和预测视频内容对规划和推理至关重要，但无监督学习对象表示和动态仍具挑战性。

研究方法: 利用频域相位相关技术递归解析视频为对象组件，结合轻量级学习模块显式建模对象运动。

研究结果: 在多个合成数据集上，VideoPCDNet在无监督跟踪和预测任务中优于基线模型，并学习到可解释的对象和运动表示。

研究结论: VideoPCDNet通过频域操作和学习模块的结合，实现了高效的无监督对象跟踪和视频预测，为动态环境理解提供了新方法。

中文摘要: 理解和预测视频内容对于动态环境中的规划和推理至关重要。尽管技术有所进步，但无监督学习对象表示和动态仍具挑战性。我们提出了VideoPCDNet，一种用于对象中心视频分解和预测的无监督框架。该模型利用频域相位相关技术递归地将视频解析为对象组件，这些组件表示为学习到的对象原型的变换版本，从而实现准确且可解释的跟踪。通过结合频域操作和轻量级学习模块显式建模对象运动，VideoPCDNet实现了准确的无监督对象跟踪和未来视频帧的预测。实验表明，在多个合成数据集上，VideoPCDNet在无监督跟踪和预测任务中优于多个对象中心基线模型，同时学习到了可解释的对象和运动表示。

</details>


### [114] [HOIverse: A Synthetic Scene Graph Dataset With Human Object Interactions](https://arxiv.org/abs/2506.19639)
**中文标题：HOIverse：一个包含人物-物体交互的合成场景图数据集**

*Mrunmai Vivek Phatak,Julian Lorenz,Nico Hörmann,Jörg Hähner,Rainer Lienhart*

主要分类: cs.CV

摘要简述: HOIverse是一个合成数据集，专注于场景图与人物-物体交互，提供密集的关系标注和多种图像数据，以推动涉及人物的场景理解研究。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究缺乏可靠的室内场景理解数据集，尤其是在包含人物的场景中。HOIverse旨在填补这一空白，为机器人代理提供更准确的场景理解能力。

研究方法: 通过合成数据集HOIverse，提供RGB图像、分割掩码、深度图像和人物关键点，并计算物体与人物之间的参数化关系，生成明确的关系定义。

研究结果: HOIverse数据集提供了密集且准确的关系标注，并在先进的场景图生成模型上进行了基准测试，展示了其在预测参数化关系和人物-物体交互方面的潜力。

研究结论: HOIverse数据集有望加速涉及人物的场景理解研究，为机器人代理的导航和规划等任务提供支持。

中文摘要: 当人类与机器人代理共存于同一环境中时，场景理解对代理执行导航和规划等任务至关重要。因此，代理需要能够定位和识别人类的行为。当前研究缺乏可靠的室内场景理解数据集，尤其是在包含人物的场景中。场景图能够生成场景或图像的结构化表示，以进行视觉场景理解。为此，我们提出了HOIverse，一个位于场景图和人物-物体交互交叉领域的合成数据集，包含人类与周围物体之间准确且密集的关系标注，以及相应的RGB图像、分割掩码、深度图像和人物关键点。我们计算了物体对和人物-物体对之间的参数化关系，从而生成明确的关系定义。此外，我们在先进的场景图生成模型上对数据集进行了基准测试，以预测参数化关系和人物-物体交互。通过这一数据集，我们旨在加速涉及人物的场景理解研究。

</details>


### [115] [PEVLM: Parallel Encoding for Vision-Language Models](https://arxiv.org/abs/2506.19651)
**中文标题：PEVLM：视觉语言模型的并行编码**

*Letian Kang,Shixian Luo,Yiqiang Li,Xiaoyang Yu,Shenxuan Zhou,Yong Wu*

主要分类: cs.CV

摘要简述: 本文提出PEVLM，一种并行编码策略，显著提升视觉语言模型在长视频理解中的效率，降低计算复杂度并保持高精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉语言模型在长视频理解中因标准注意力机制的二次复杂度受限，亟需一种无需微调的高效预填充方法。

研究方法: PEVLM将输入分块处理，保留全注意力位置嵌入，并通过对齐注意力权重模拟全注意力分布，将计算复杂度从O((T×N)²)降至O(T×N)。

研究结果: 在LongVideoBench基准测试中，PEVLM比现有高效推理方法精度提升8.37%，注意力计算加速7.47倍，端到端延迟降低40%。

研究结论: PEVLM在低延迟、长上下文视频理解中表现卓越，适用于自动驾驶等实际应用。

中文摘要: 视觉语言模型（VLMs）在视频语言任务中表现出色，但其在长视频理解中的应用因标准注意力机制的二次复杂度而受限。本文提出PEVLM，一种专为提升VLMs预填充效率而设计的并行编码策略，无需模型微调。PEVLM将输入分块处理，保留全注意力位置嵌入，并通过对齐注意力权重模拟全注意力分布，将计算复杂度从O((T×N)²)降至O(T×N)。在LongVideoBench基准测试中，PEVLM比现有高效推理方法精度提升8.37%，注意力计算加速7.47倍，端到端延迟降低40%。在严格延迟约束下，PEVLM显著优于基线方法，精度从23.26%提升至61.03%。这些结果表明PEVLM在低延迟、长上下文视频理解中的有效性，适用于自动驾驶等实际应用。

</details>


### [116] [Video Compression for Spatiotemporal Earth System Data](https://arxiv.org/abs/2506.19656)
**中文标题：时空地球系统数据的视频压缩**

*Oscar J. Pellicer-Valero,Cesar Aybar,Gustau Camps Valls*

主要分类: cs.CV

摘要简述: 本文介绍了一个名为xarrayvideo的Python库，用于将多通道时空数据集编码为视频以实现高效压缩，压缩比高达250倍，同时保持高保真度。


<details>
  <summary>详细信息</summary>
研究动机: 随着地球观测数据规模的快速增长，传统存储和处理方法面临巨大挑战。这些数据具有类似视频的空间、时间和光谱冗余特性，因此可以利用成熟的视频压缩技术进行高效处理。

研究方法: 通过xarrayvideo库，将多通道时空数据集编码为视频，利用ffmpeg中的标准视频编解码器实现高效压缩。实验验证了该方法在四个真实数据集上的有效性。

研究结果: 在0.1和1 bpppb的压缩率下，PSNR分别达到55.86-65.91 dB。两个数据集（DeepExtremeCubes和DynamicEarthNet）的压缩版本在深度学习任务中未表现性能损失。

研究结论: xarrayvideo为地球科学社区提供了一种高效处理大规模地球观测数据的解决方案，压缩技术实用且易于访问。

中文摘要: 大规模地球系统数据集（从高分辨率遥感影像到时空气候模型输出）表现出与标准视频类似的特性。其固有的空间、时间和光谱冗余可以通过成熟的视频压缩技术轻松利用。本文介绍了xarrayvideo，一个用于通过将多通道时空数据集编码为视频进行压缩的Python库。我们的方法通过ffmpeg利用标准且优化良好的视频编解码器，实现了高达250倍的压缩比，同时保持高保真度。我们在四个真实世界的多通道时空数据集上验证了该库的有效性：DynamicEarthNet（超高分辨率Planet影像）、DeepExtremeCubes（高分辨率Sentinel-2影像）、ERA5（天气再分析数据）和SimpleS2数据集（高分辨率多通道Sentinel-2影像），在0.1 bpppb下分别达到55.86、40.60、46.58和43.23 dB的峰值信噪比（PSNR），在1 bpppb下分别达到65.91、54.28、62.90和55.04 dB。我们通过HuggingFace以显著减小的尺寸（分别为270 Gb和8.5 Gb）重新分发了其中两个数据集（DeepExtremeCubes和DynamicEarthNet），且未牺牲质量（PSNR分别为55.77-56.65和60.15）。在压缩版本用于其各自的深度学习下游任务（下一步反射率预测和土地覆盖分割）时，未观察到性能损失。总之，xarrayvideo为处理快速增长的地球观测数据规模提供了一种高效解决方案，使先进的压缩技术对地球科学社区变得可访问且实用。该库可在https://github.com/IPL-UV/xarrayvideo 上使用。

</details>


### [117] [SAM2-SGP: Enhancing SAM2 for Medical Image Segmentation via Support-Set Guided Prompting](https://arxiv.org/abs/2506.19658)
**中文标题：SAM2-SGP：通过支持集引导提示增强SAM2的医学图像分割能力**

*Yang Xing,Jiong Wu,Yuheng Bu,Kuang Gong*

主要分类: cs.CV

摘要简述: SAM2-SGP通过支持集引导提示增强SAM2在医学图像分割中的表现，无需人工提示，解决了领域偏移问题，并在多种医学影像模态上显著优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 尽管SAM2在零样本图像分割中表现出色，但其依赖人工提示和自然图像训练的局限性使其在医学图像分割中表现不佳。为解决这些问题，研究者提出了SAM2-SGP框架。

研究方法: SAM2-SGP通过伪掩码生成模块（PMG）利用支持集的图像-掩码对生成伪掩码，并引入伪掩码注意力模块（PMA）自动生成边界框和增强局部特征提取。此外，采用低秩适应（LoRA）策略缓解领域偏移。

研究结果: 在多种医学影像模态（如眼底摄影、X射线、CT、MRI、PET和超声）的2D和3D数据集上，SAM2-SGP显著优于nnUNet、SwinUNet、SAM2和MedSAM2等模型。

研究结论: SAM2-SGP通过支持集引导提示和低秩适应策略，有效提升了医学图像分割的性能，为领域内模型提供了新的解决方案。

中文摘要: 尽管Segment Anything Model 2（SAM2）等新型视觉基础模型显著提升了零样本图像分割能力，但其依赖人工提示的特性在医学图像分割任务中带来了挑战。此外，SAM2因基于自然图像和视频训练，在医学图像分割中存在领域偏移问题。为解决这些问题，我们提出了支持集引导提示的SAM2（SAM2-SGP），该框架无需人工提示。该模型利用SAM2的记忆机制，通过伪掩码生成模块（PMG）从支持集的图像-掩码对生成伪掩码。我们还引入了伪掩码注意力模块（PMA），利用这些伪掩码自动生成边界框，并通过引导注意力到相关区域增强局部特征提取。此外，采用低秩适应（LoRA）策略缓解领域偏移问题。该框架在多种医学影像模态（如眼底摄影、X射线、CT、MRI、PET和超声）的2D和3D数据集上进行了评估，结果显示其性能显著优于nnUNet、SwinUNet等先进模型以及SAM2和MedSAM2等基础模型，证明了该方法的有效性。代码已公开于https://github.com/astlian9/SAM_Support。

</details>


### [118] [Genome-Anchored Foundation Model Embeddings Improve Molecular Prediction from Histology Images](https://arxiv.org/abs/2506.19681)
**中文标题：基因组锚定的基础模型嵌入提升组织学图像的分子预测能力**

*Cheng Jin,Fengtao Zhou,Yunfang Yu,Jiabo Ma,Yihui Wang,Yingxue Xu,Huajun Zhou,Hao Jiang,Luyang Luo,Luhui Mao,Zifan He,Xiuming Zhang,Jing Zhang,Ronald Chan,Herui Yao,Hao Chen*

主要分类: cs.CV

摘要简述: PathLUPI利用转录组特权信息训练，生成基因组锚定的组织学嵌入，仅需WSI即可预测分子特征，性能优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 精准肿瘤学需要准确的分子信息，但基因组学方法成本高且耗时。现有深度学习方法难以直接从WSI预测复杂分子特征和患者预后。

研究方法: PathLUPI在训练中使用转录组特权信息，提取基因组锚定的组织学嵌入，仅需WSI即可推断分子特征。

研究结果: PathLUPI在49项分子肿瘤学任务中表现优异，14项生物标志物预测和分子分型任务AUC≥0.80，5种主要癌症生存队列C-index≥0.70。

研究结论: PathLUPI通过编码分子上下文优化WSI表征，克服现有模型局限，为临床病理工作流提供新策略。

中文摘要: 精准肿瘤学需要准确的分子信息，但直接从基因组学获取这些信息成本高且耗时，难以广泛临床应用。从常规全切片图像（WSI）直接预测复杂分子特征和患者预后仍是当前深度学习方法的重大挑战。本文提出PathLUPI，它在训练中利用转录组特权信息提取基因组锚定的组织学嵌入，仅需WSI即可实现有效的分子预测。通过对20个队列11,257例病例的49项分子肿瘤学任务进行广泛评估，PathLUPI表现优于仅基于WSI训练的传统方法。关键的是，它在14项生物标志物预测和分子分型任务中AUC≥0.80，在5种主要癌症的生存队列中C-index≥0.70。此外，PathLUPI嵌入揭示了WSI中与特定基因型和相关生物学通路相关的独特细胞形态特征。通过有效编码分子上下文优化WSI表征，PathLUPI克服了现有模型的关键局限，为将分子洞察与常规病理工作流结合提供了新策略。

</details>


### [119] [Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance](https://arxiv.org/abs/2506.19683)
**中文标题：语义场景图用于超声图像解释与扫描引导**

*Xuesong Li,Dianye Huang,Yameng Zhang,Nassir Navab,Zhongliang Jiang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于场景图（SG）的超声图像解释和扫描引导方法，利用Transformer模型和大型语言模型（LLM）为非专业用户提供图像内容解释和扫描指导，验证了其在颈部区域超声图像中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 医学超声图像因成像和采集参数的差异而具有显著的视觉变异性，导致非专业用户难以理解。现有方法主要面向具有生理学知识的临床医生，而缺乏为非专业用户（如即时护理场景中的用户）提供解释和扫描指导的解决方案。本研究旨在填补这一空白。

研究方法: 首先提出了一种基于Transformer的单阶段方法计算超声图像场景图（SG），无需显式目标检测。随后利用大型语言模型（LLM）根据用户查询进一步优化抽象的SG表示，生成易于理解的图像解释。此外，探索了预测SG在引导超声扫描以覆盖当前视图中缺失解剖结构的潜力。

研究结果: 在五名志愿者的左右颈部区域（包括颈动脉和甲状腺）的超声图像上验证了该方法的有效性。结果表明，该方法能够显著提升超声图像的可解释性和可用性，为非专业用户提供标准化和全面的解剖探索指导。

研究结论: 基于场景图的方法通过增强超声图像的解释性和扫描指导能力，为非专业用户提供了更直观的支持，有望进一步普及超声技术的应用。

中文摘要: 医学超声图像的理解一直是一个长期挑战，主要由于成像和采集参数的差异导致的显著视觉变异性。近年来，大型语言模型（LLM）被用于自动生成面向临床医生的术语丰富的摘要，但这些方法尚未满足非专业用户（如即时护理场景中的用户）对超声图像解释性和基本扫描指导的需求。本研究首次引入场景图（SG）用于超声图像，为非专业用户提供图像内容解释和扫描引导。超声SG通过基于Transformer的单阶段方法计算，无需显式目标检测。为了生成易于理解的图像解释，用户查询进一步通过LLM优化抽象的SG表示。此外，预测的SG还被探索用于引导超声扫描以覆盖当前视图中缺失的解剖结构，帮助非专业用户实现更标准化和全面的解剖探索。该方法在五名志愿者的左右颈部区域（包括颈动脉和甲状腺）的超声图像上验证了其有效性，结果表明该方法能够通过提升超声图像的解释性和可用性，为非专业用户提供支持，从而最大程度地普及超声技术。

</details>


### [120] [UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot CLIP Adaptation](https://arxiv.org/abs/2506.19694)
**中文标题：UltraAD：基于少样本CLIP适应的细粒度超声异常分类**

*Yue Zhou,Yuan Bi,Wenjuan Tong,Wei Wang,Nassir Navab,Zhongliang Jiang*

主要分类: cs.CV

摘要简述: 本文提出UltraAD方法，通过少样本CLIP适应实现超声图像的细粒度异常分类，结合视觉-语言模型提升异常定位和分类性能，在多个乳腺超声数据集中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有无监督或半监督异常检测方法在细粒度分类（如良性与恶性肿瘤）上表现不足，且超声图像因设备和参数差异存在较大域差距。UltraAD旨在解决这些问题，提升医学图像的异常检测和分类能力。

研究方法: UltraAD结合视觉-语言模型，通过少样本超声图像示例进行训练。首先融合图像级令牌与可学习文本嵌入以提升定位性能，随后结合补丁级令牌优化局部表示。细粒度分类通过构建记忆库实现，存储少样本图像及其文本描述，冻结文本嵌入并调整图像特征以适应医学数据。

研究结果: UltraAD在三个乳腺超声数据集中表现优异，在病灶定位和细粒度医学分类任务上均超越现有方法。

研究结论: UltraAD通过视觉-语言模型和少样本适应，显著提升了超声图像的异常检测和细粒度分类能力，为临床决策提供了更精确的工具。

中文摘要: 医学图像中的精确异常检测对临床决策至关重要。尽管近期基于大规模正常数据的无监督或半监督异常检测方法表现出色，但它们缺乏细粒度区分能力（如良性与恶性肿瘤）。此外，超声成像对设备和采集参数变化高度敏感，导致图像间存在显著域差距。为解决这些问题，我们提出UltraAD，一种基于视觉-语言模型的方法，利用少样本超声示例实现广义异常定位和细粒度分类。为提升定位性能，查询视觉原型的图像级令牌首先与可学习文本嵌入融合，随后进一步与补丁级令牌结合，优化局部表示以提高准确性。对于细粒度分类，通过少样本图像及其捕捉解剖和异常特征的文本描述构建记忆库。训练过程中，存储的文本嵌入保持冻结，而图像特征则适应医学数据。UltraAD在三个乳腺超声数据集上进行了广泛评估，在病灶定位和细粒度医学分类任务上均优于现有方法。代码将在接受后发布。

</details>


### [121] [Systematic Comparison of Projection Methods for Monocular 3D Human Pose Estimation on Fisheye Images](https://arxiv.org/abs/2506.19747)
**中文标题：鱼眼图像中单目3D人体姿态估计的投影方法系统比较**

*Stephanie Käs,Sven Peter,Henrik Thillmann,Anton Burenko,David Benjamin Adrian,Dennis Mack,Timm Linder,Bastian Leibe*

主要分类: cs.CV

摘要简述: 本文系统评估了鱼眼图像中单目3D人体姿态估计的不同投影方法，发现双球模型在近景场景中表现最佳，并提出了一种基于检测框选择投影模型的启发式方法。


<details>
  <summary>详细信息</summary>
研究动机: 鱼眼相机在机器人交互和汽车应用中具有广阔视野的优势，但其图像中的弯曲失真给人体姿态估计带来挑战。现有方法对广视野下姿态估计的效果尚未系统评估，本文旨在填补这一空白。

研究方法: 评估了针孔、等距、双球相机模型及圆柱投影方法对3D人体姿态估计精度的影响，并提出基于检测框选择投影模型的启发式方法。使用新数据集FISHnCHIPS进行验证。

研究结果: 在近景场景中，针孔投影效果不佳，而双球模型显著提升了姿态估计精度。投影方法的选择需根据人体姿态覆盖的视野范围调整。

研究结论: 双球模型在广视野下表现优异，提出的启发式方法能有效提升预测质量。新数据集FISHnCHIPS为鱼眼图像中的3D人体姿态估计提供了丰富资源。

中文摘要: 鱼眼相机能够捕捉比标准针孔相机更广阔的视野（FOV），使其在人机交互和汽车应用中尤为有用。然而，鱼眼光学固有的弯曲失真使得在鱼眼图像中准确检测人体姿态具有挑战性。尽管已提出多种鱼眼图像校正方法，但其在广视野下绝对人体姿态估计中的效果和局限性尚未得到系统评估。为填补这一空白，我们评估了针孔、等距、双球相机模型及圆柱投影方法对3D人体姿态估计精度的影响。研究发现，在近景场景中，针孔投影效果不足，而最佳投影方法随人体姿态覆盖的视野范围变化。使用双球模型等先进鱼眼模型显著提升了3D人体姿态估计精度。我们提出了一种基于检测框选择投影模型的启发式方法以提升预测质量。此外，我们引入并评估了新数据集FISHnCHIPS，该数据集包含鱼眼图像中的3D人体骨架标注，包括极端近景、地面安装相机和广视野姿态等非常规角度图像，数据集地址：https://www.vision.rwth-aachen.de/fishnchips。

</details>


### [122] [CoCo4D: Comprehensive and Complex 4D Scene Generation](https://arxiv.org/abs/2506.19798)
**中文标题：CoCo4D：全面且复杂的4D场景生成**

*Junwei Zhou,Xueting Li,Lu Qi,Ming-Hsuan Yang*

主要分类: cs.CV

摘要简述: CoCo4D提出了一种从文本提示生成动态4D场景的框架，通过分离动态前景和背景建模，结合渐进式外推技术，实现了多视角一致且沉浸式的4D场景生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有4D合成方法主要关注对象级生成或有限视角的动态场景合成，难以生成多视角一致且沉浸式的动态4D场景。CoCo4D旨在解决这一限制。

研究方法: CoCo4D将4D场景合成分为动态前景建模和背景演化两部分，通过参考运动序列引导生成。首先利用视频扩散模型生成初始运动序列，再通过渐进式外推技术合成动态前景和背景，并优化前景参数化轨迹以实现无缝融合。

研究结果: 实验表明，CoCo4D在4D场景生成中表现优于或与现有方法相当，验证了其高效性和有效性。

研究结论: CoCo4D通过分离动态前景和背景建模，结合渐进式外推技术，成功生成了多视角一致且沉浸式的动态4D场景，为4D合成领域提供了新思路。

中文摘要: 现有的4D合成方法主要关注对象级生成或有限视角的动态场景合成，限制了其生成多视角一致且沉浸式动态4D场景的能力。为解决这一问题，我们提出了CoCo4D框架，用于从文本提示生成详细的动态4D场景，并可选择包含图像。我们的方法基于一个关键观察：前景对象通常表现为关节运动，而背景变化较小。因此，CoCo4D将4D场景合成分为动态前景建模和背景演化两部分，均由参考运动序列引导。给定文本提示和可选参考图像，CoCo4D首先利用视频扩散模型生成初始运动序列，随后通过新颖的渐进式外推技术合成动态前景对象和背景。为确保动态前景对象与背景的无缝融合，CoCo4D优化了前景的参数化轨迹，实现了真实且连贯的混合效果。大量实验表明，CoCo4D在4D场景生成中表现优于或与现有方法相当，验证了其高效性和有效性。更多结果请访问我们的网站https://colezwhy.github.io/coco4d/。

</details>


### [123] [One Prototype Is Enough: Single-Prototype Activation for Interpretable Image Classification](https://arxiv.org/abs/2506.19808)
**中文标题：一个原型足矣：单原型激活实现可解释图像分类**

*Yitao Peng,Lianghua He,Die Hu*

主要分类: cs.CV

摘要简述: 本文提出ProtoSolo，一种新型可解释图像分类网络，仅需激活单个原型即可完成分类，显著降低解释复杂度。通过特征图比较和非原型投影学习策略，实验表明其在分类任务和解释复杂度上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有原型网络通常依赖多个原型的协作决策来完成分类和解释，增加了认知复杂度。ProtoSolo旨在通过单原型激活简化解释过程，同时保持分类性能。

研究方法: ProtoSolo采用单原型激活机制，通过特征图而非全通道特征向量进行相似性比较和原型学习。此外，提出非原型投影学习策略，避免投影操作对网络结构的负面影响。

研究结果: 在CUB-200-2011和Stanford Cars数据集上的实验表明，ProtoSolo在分类任务中表现优异，且在解释复杂度上达到最佳水平。

研究结论: ProtoSolo通过单原型激活和特征图比较，实现了高效分类和低复杂度解释，为可解释图像分类提供了新思路。

中文摘要: 本文提出ProtoSolo，一种受原型网络（如ProtoPNet）启发的新型深度神经网络架构，用于可解释图像分类。现有原型网络通常依赖多个原型的协作决策来完成单个类别的分类和解释，而ProtoSolo仅需激活单个原型即可完成分类。这使得网络能够通过仅提供与该类别原型最相似的特征来解释每个类别决策，显著降低了解释的认知复杂度。其次，我们提出了一种基于特征的比较方法，使用特征图而非全通道特征向量作为相似性比较和原型学习的对象。这一设计使ProtoSolo能够利用更丰富的全局信息进行分类，同时仅依赖单原型激活。此外，我们提出了一种非原型投影学习策略，在保留原型与训练图像块之间信息关联的同时，避免了投影操作对网络结构的剧烈变化，从而避免其对分类性能的负面影响。在CUB-200-2011和Stanford Cars数据集上的实验表明，ProtoSolo在分类任务中表现优异，并在解释复杂度方面达到了最先进的可解释方法的水平。代码可在https://github.com/pyt19/ProtoSolo获取。

</details>


### [124] [Bind-Your-Avatar: Multi-Talking-Character Video Generation with Dynamic 3D-mask-based Embedding Router](https://arxiv.org/abs/2506.19833)
**中文标题：绑定你的虚拟形象：基于动态3D掩码嵌入路由器的多角色说话视频生成**

*Yubo Huang,Weiqiang Wang,Sirui Zhao,Tong Xu,Lin Liu,Enhong Chen*

主要分类: cs.CV

摘要简述: 本文提出Bind-Your-Avatar模型，解决多角色同场景视频生成中的音频-角色对应控制和数据集缺乏问题，通过动态3D掩码嵌入路由器和首个多角色对话数据集，显著提升生成效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有音频驱动说话头生成方法多关注单角色场景，而多角色同场景对话视频生成面临音频-角色对应控制和数据集缺乏两大挑战。本文旨在解决这些问题。

研究方法: 提出基于MM-DiT的Bind-Your-Avatar模型，包括：(1)细粒度嵌入路由器绑定角色与语音；(2)动态3D掩码嵌入路由器实现帧级角色控制；(3)首个多角色对话数据集及开源处理流程；(4)双角色视频生成基准测试。

研究结果: 实验表明，Bind-Your-Avatar在双角色视频生成任务中性能优于多种先进方法，生成效果更优且更稳定。

研究结论: Bind-Your-Avatar通过动态3D掩码嵌入路由器和专用数据集，有效解决了多角色同场景视频生成问题，为未来研究提供了新方向。

中文摘要: 近年来，音频驱动的说话头生成技术取得了显著进展。然而，现有方法主要集中于单角色场景。虽然某些方法可以生成两人对话视频，但生成多角色同场景的统一对话视频仍面临两大关键挑战：音频-角色对应控制和缺乏多角色同场景对话视频数据集。为解决这些问题，我们提出了Bind-Your-Avatar，一种基于MM-DiT的模型，专为同场景多角色说话视频生成设计。具体包括：(1)细粒度嵌入路由器绑定“谁”和“说什么”；(2)两种动态3D掩码嵌入路由器实现帧级角色控制；(3)首个多角色对话数据集及开源处理流程；(4)双角色视频生成基准测试，实验表明其性能优于多种先进方法。

</details>


### [125] [SimpleGVR: A Simple Baseline for Latent-Cascaded Video Super-Resolution](https://arxiv.org/abs/2506.19838)
**中文标题：SimpleGVR：一种用于潜在级联视频超分辨率的简单基线方法**

*Liangbin Xie,Yu Li,Shian Du,Menghan Xia,Xintao Wang,Fanghua Yu,Ziyan Chen,Pengfei Wan,Jiantao Zhou,Chao Dong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SimpleGVR的简单基线方法，用于潜在级联视频超分辨率（VSR），通过两阶段设计（语义内容生成和细节合成）实现高效高分辨率视频生成。研究重点在于VSR模型的关键设计原则，包括训练数据生成策略和模型行为分析，最终通过实验验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 随着用户对高分辨率视频生成需求的增加，仅依赖潜在计算已无法满足需求。因此，研究提出将过程解耦为语义内容生成和细节合成两阶段，重点探索后者（VSR模型）的设计原则，以填补当前研究的空白。

研究方法: 1. 提出两种退化策略生成训练数据，以更好地模拟基础模型的输出特性；2. 通过系统分析时间步采样策略和噪声增强对低分辨率输入的影响，为模型设计提供关键见解；3. 引入交错时间单元和稀疏局部注意力机制，降低计算开销。

研究结果: 实验表明，该方法在性能上优于现有技术，消融研究验证了每个设计选择的有效性。

研究结论: 本文为级联视频超分辨率生成提供了一个简单而有效的基线，为未来高效级联合成系统的研究提供了实用指导。

中文摘要: 潜在扩散模型已成为高效视频生成的主要范式。然而，随着用户对高分辨率输出的需求增加，仅依赖潜在计算已显不足。一种有前景的方法是将过程解耦为两阶段：语义内容生成和细节合成。前者在低分辨率下使用计算密集型基础模型，后者则利用轻量级级联视频超分辨率（VSR）模型实现高分辨率输出。本文重点研究后者（级联VSR模型）的关键设计原则，目前这一领域尚未充分探索。首先，我们提出两种退化策略以生成更符合基础模型输出特性的训练数据，确保VSR模型与其上游生成器对齐。其次，通过系统分析（1）时间步采样策略，（2）低分辨率（LR）输入的噪声增强效果，我们为VSR模型行为提供了关键见解。这些发现直接指导了我们的架构和训练创新。最后，我们引入交错时间单元和稀疏局部注意力机制，实现高效训练和推理，大幅降低计算开销。大量实验证明了我们的框架优于现有方法，消融研究验证了每个设计选择的有效性。我们的工作为级联视频超分辨率生成建立了一个简单而有效的基线，为未来高效级联合成系统的研究提供了实用指导。

</details>


### [126] [Improving Progressive Generation with Decomposable Flow Matching](https://arxiv.org/abs/2506.19839)
**中文标题：通过可分解流匹配改进渐进式生成**

*Moayed Haji-Ali,Willi Menapace,Ivan Skorokhodov,Arpit Sahni,Sergey Tulyakov,Vicente Ordonez,Aliaksandr Siarohin*

主要分类: cs.CV

摘要简述: 本文提出了一种名为可分解流匹配（DFM）的简单高效框架，用于渐进式生成视觉媒体，显著提升了图像和视频的生成质量，并在计算效率上优于现有多阶段框架。


<details>
  <summary>详细信息</summary>
研究动机: 高维视觉模态生成任务计算密集，现有方法通常采用渐进式生成策略，但多阶段架构复杂且需要定制化设计。本文旨在提出一种简单有效的解决方案，以提升生成质量和计算效率。

研究方法: 可分解流匹配（DFM）框架在用户定义的多尺度表示（如拉普拉斯金字塔）的每一层级上独立应用流匹配，无需复杂的多阶段设计或额外采样器。

研究结果: 实验表明，DFM在图像和视频生成质量上显著优于现有方法，在Imagenet-1k 512px上FDD分数提升35.2%，且在大模型微调（如FLUX）中收敛速度更快。

研究结论: DFM通过单模型和简单架构实现了生成质量的显著提升，同时保持了对现有训练流程的最小修改，为渐进式生成任务提供了高效解决方案。

中文摘要: 生成高维视觉模态是一项计算密集型任务。常见的解决方案是渐进式生成，即通过从粗到细的谱自回归方式合成输出。尽管扩散模型受益于去噪的渐进特性，但显式的多阶段架构很少被采用。这些架构增加了整体方法的复杂性，需要定制化的扩散公式、依赖分解的阶段转换、临时采样器或模型级联。我们的贡献是可分解流匹配（DFM），这是一个简单高效的框架，用于渐进式生成视觉媒体。DFM在用户定义的多尺度表示（如拉普拉斯金字塔）的每一层级上独立应用流匹配。实验表明，我们的方法在图像和视频的视觉质量上均有所提升，优于现有的多阶段框架。在Imagenet-1k 512px上，DFM的FDD分数比基础架构提升了35.2%，比性能最佳的基线提升了26.4%，且训练计算量相同。当应用于大型模型（如FLUX）的微调时，DFM显示出更快的收敛速度。重要的是，所有这些优势仅需单一模型、架构简单且对现有训练流程的修改最小即可实现。

</details>


### [127] [GenHSI: Controllable Generation of Human-Scene Interaction Videos](https://arxiv.org/abs/2506.19840)
**中文标题：GenHSI：可控的人类与场景交互视频生成**

*Zekun Li,Rui Zhou,Rahul Sajnani,Xiaoyan Cong,Daniel Ritchie,Srinath Sridhar*

主要分类: cs.CV

摘要简述: GenHSI是一种无需训练的方法，通过分阶段生成长视频，解决了现有视频生成模型中人类与场景交互不真实、身份保留不足等问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大规模预训练视频扩散模型在生成长视频时存在人类与场景交互不真实、主体身份保留不足以及训练成本高的问题，GenHSI旨在解决这些问题。

研究方法: GenHSI将长视频生成任务分为三个阶段：(1)脚本编写，将复杂任务分解为简单原子任务；(2)预可视化，生成3D关键帧；(3)动画，使用现成的视频扩散模型渲染和动画化关键帧，生成具有丰富交互的长视频。

研究结果: 实验表明，GenHSI能够从单张场景图像生成保留场景内容和角色身份的长视频，且人类与场景交互自然。

研究结论: GenHSI无需训练即可生成长视频，有效解决了现有方法的局限性，为人类与场景交互视频生成提供了新思路。

中文摘要: 大规模预训练视频扩散模型在多样化视频生成中表现出卓越能力，但现有方法在生成长电影式视频时面临人类与场景交互不真实、主体身份保留不足以及训练成本高等挑战。我们提出GenHSI，一种无需训练的方法，用于可控生成长人类与场景交互视频（HSI）。受电影动画启发，我们的关键思路是将长视频生成任务分为三个阶段：(1)脚本编写，(2)预可视化，(3)动画。给定场景图像、用户描述和人物多张图像，通过这三个阶段生成保留人类身份并提供丰富交互的长视频。脚本编写将复杂任务分解为简单原子任务，预可视化阶段生成3D关键帧（故事板），这些关键帧通过现成视频扩散模型渲染和动画化，以3D感知方式生成具有丰富交互的长视频。我们的方法无需精确扫描场景，可从单视角图像生成3D关键帧。我们是首个无需训练即可生成长视频序列的方法，该序列包含任意数量的角色动作且相机姿态一致。实验表明，我们的方法能够从单张场景图像生成保留场景内容和角色身份的长视频，且人类与场景交互自然。更多信息请访问项目主页https://kunkun0w0.github.io/project/GenHSI/。

</details>


### [128] [Active View Selector: Fast and Accurate Active View Selection with Cross Reference Image Quality Assessment](https://arxiv.org/abs/2506.19844)
**中文标题：主动视角选择器：基于跨参考图像质量评估的快速准确主动视角选择**

*Zirui Wang,Yash Bhalgat,Ruining Li,Victor Adrian Prisacariu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于2D图像质量评估的主动视角选择方法，通过跨参考图像质量评估框架快速准确地选择最佳视角，显著提升了3D重建和新视角合成的效果，且运行速度比现有方法快14-33倍。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法（如FisheRF和ActiveNeRF）在3D空间中进行视角选择时，需要针对不同3D表示进行专门设计，且建模复杂。本文将其重新定义为2D图像质量评估任务，以简化流程并提高效率。

研究方法: 提出了一种跨参考图像质量评估框架，训练模型预测多视角设置下的SSIM值，并以此指导视角选择。该方法不依赖于3D表示，且避免了传统全参考或无参考指标的局限性。

研究结果: 在标准基准测试中，该方法在定量和定性上均取得显著提升，运行速度比现有方法快14-33倍。

研究结论: 本文方法通过2D图像质量评估实现了高效且通用的视角选择，为3D重建和新视角合成提供了更优解决方案。

中文摘要: 本文研究了新视角合成和3D重建中的主动视角选择问题。现有方法（如FisheRF和ActiveNeRF）通过最小化3D空间中的不确定性或最大化信息增益来选择最佳视角，但这些方法需要针对不同3D表示进行专门设计，且涉及复杂的3D空间建模。相反，我们将此问题重新定义为2D图像质量评估（IQA）任务，选择当前渲染质量最低的视角。由于候选视角的真实图像不可用，全参考指标（如PSNR和SSIM）无法适用，而无参考指标（如MUSIQ和MANIQA）缺乏必要的多视角上下文。受近期跨参考质量评估框架CrossScore的启发，我们训练了一个模型来预测多视角设置下的SSIM值，并以此指导视角选择。我们的跨参考IQA框架在标准基准测试中实现了显著的定量和定性提升，同时不依赖于3D表示，运行速度比现有方法快14-33倍。

</details>


### [129] [A Comparative Study of NAFNet Baselines for Image Restoration](https://arxiv.org/abs/2506.19845)
**中文标题：NAFNet基线模型在图像修复中的对比研究**

*Vladislav Esaulov,M. Moein Esfahani*

主要分类: cs.CV

摘要简述: 本文研究了NAFNet（非线性激活自由网络）在图像修复任务中的表现，通过对比实验验证了其核心组件（SimpleGate激活、简化通道激活SCA和层归一化）的有效性，并提出了模型设计的建议。


<details>
  <summary>详细信息</summary>
研究动机: 图像修复是计算机视觉中的重要任务，而NAFNet作为一种简单高效的深度学习基线，其核心组件的有效性尚未被充分验证。本文旨在通过对比实验，明确这些组件对修复性能的影响。

研究方法: 使用CIFAR10数据集，对图像添加噪声和模糊后，通过消融实验对比NAFNet的不同变体（替换或移除核心组件）。评估指标包括PSNR和SSIM，并通过示例展示修复效果。

研究结果: 实验表明，SimpleGate激活和简化注意力机制（SCA）优于传统激活和注意力方法，而层归一化对训练稳定性至关重要。定量和定性结果均支持NAFNet的设计。

研究结论: NAFNet的核心组件设计合理，SimpleGate和SCA提升了性能，层归一化确保了稳定性。未来可进一步优化模型设计。

中文摘要: 本文研究了NAFNet（非线性激活自由网络），这是一种简单高效的图像修复深度学习基线。通过使用添加噪声和模糊的CIFAR10图像，我们对NAFNet的核心组件进行了消融研究。基线模型采用了SimpleGate激活、简化通道激活（SCA）和层归一化，并将其与替换或移除组件的变体进行对比。定量结果（PSNR、SSIM）和示例展示了每种修改对修复性能的影响。研究发现支持NAFNet的设计：SimpleGate和简化注意力机制比传统激活和注意力方法表现更好，而层归一化对训练稳定性至关重要。最后，我们提出了模型设计的建议，并讨论了潜在改进和未来工作。

</details>


### [130] [Unified Vision-Language-Action Model](https://arxiv.org/abs/2506.19850)
**中文标题：统一的视觉-语言-动作模型**

*Yuqi Wang,Xinghang Li,Wenxuan Wang,Junbo Zhang,Yingyan Li,Yuntao Chen,Xinlong Wang,Zhaoxiang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种统一的视觉-语言-动作模型UniVLA，通过将视觉、语言和动作信号建模为离散令牌序列，结合世界建模，显著提升了机器人操作任务的性能，并在多个基准测试中取得了最佳成绩。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉-语言-动作模型（VLA）主要依赖视觉-语言模型（VLM）的通用理解能力生成动作信号，但忽略了视觉观察中的丰富时序和因果结构。本文旨在解决这一问题，提出一种更高效的统一模型。

研究方法: UniVLA是一种原生多模态VLA模型，通过自回归方式将视觉、语言和动作信号建模为离散令牌序列，并结合世界建模从大规模视频数据中学习因果动态，从而提升下游策略学习的效果。

研究结果: UniVLA在多个仿真基准测试（如CALVIN、LIBERO和Simplenv-Bridge）中取得了新的最佳成绩，例如在LIBERO上的平均成功率达到95.5%，显著超越之前的方法。此外，该模型在真实世界的ALOHA操作和自动驾驶任务中也表现出广泛适用性。

研究结论: UniVLA通过统一建模视觉、语言和动作信号，结合世界建模，显著提升了机器人操作任务的性能，展示了其在复杂任务中的强大潜力。

中文摘要: 视觉-语言-动作模型（VLA）因其在机器人操作中的潜力而备受关注。然而，现有方法主要依赖视觉-语言模型（VLM）的通用理解能力生成动作信号，往往忽略了视觉观察中丰富的时序和因果结构。本文提出UniVLA，一种统一且原生的多模态VLA模型，通过自回归方式将视觉、语言和动作信号建模为离散令牌序列。这种形式支持灵活的多模态任务学习，尤其是从大规模视频数据中学习。通过在后训练阶段引入世界建模，UniVLA能够从视频中捕捉因果动态，从而有效迁移至下游策略学习，尤其是在长时程任务中。我们的方法在多个广泛使用的仿真基准测试（如CALVIN、LIBERO和Simplenv-Bridge）中取得了新的最佳成绩，显著超越之前的方法。例如，UniVLA在LIBERO基准测试中的平均成功率达到95.5%，超越了pi0-FAST的85.5%。我们还展示了其在真实世界ALOHA操作和自动驾驶任务中的广泛适用性。

</details>


### [131] [AnimaX: Animating the Inanimate in 3D with Joint Video-Pose Diffusion Models](https://arxiv.org/abs/2506.19851)
**中文标题：AnimaX：基于联合视频-姿态扩散模型的3D无生命物体动画化**

*Zehuan Huang,Haoran Feng,Yangtian Sun,Yuanchen Guo,Yanpei Cao,Lu Sheng*

主要分类: cs.CV

摘要简述: AnimaX是一种前馈式3D动画框架，通过结合视频扩散模型的运动先验和骨架动画的可控结构，实现多样化的3D动画生成。该方法利用多视角、多帧的2D姿态图表示3D运动，并通过联合视频-姿态扩散模型生成动画，支持任意骨架的网格动画。


<details>
  <summary>详细信息</summary>
研究动机: 传统运动合成方法受限于固定骨架拓扑或需要高维变形空间的高成本优化。AnimaX旨在将视频运动知识有效迁移到3D领域，支持任意骨架的多样化网格动画，提供更灵活和高效的解决方案。

研究方法: AnimaX将3D运动表示为多视角、多帧的2D姿态图，通过联合视频-姿态扩散模型生成动画，并引入共享位置编码和模态感知嵌入确保视频与姿态序列的时空对齐。生成的姿态序列通过三角测量转换为3D关节位置，再通过逆向运动学生成网格动画。

研究结果: 在包含160,000个绑定序列的新数据集上训练后，AnimaX在VBench上实现了泛化性、运动保真度和效率的领先水平，为类别无关的3D动画提供了可扩展的解决方案。

研究结论: AnimaX通过结合视频扩散模型和骨架动画的优势，实现了高效且高质量的3D动画生成，为未来动画技术的发展提供了新的方向。

中文摘要: 我们提出了AnimaX，一种前馈式3D动画框架，将视频扩散模型的运动先验与骨架动画的可控结构相结合。传统运动合成方法受限于固定骨架拓扑或需要高维变形空间的高成本优化。相比之下，AnimaX能够将基于视频的运动知识有效迁移到3D领域，支持任意骨架的多样化网格动画。我们的方法将3D运动表示为多视角、多帧的2D姿态图，并通过联合视频-姿态扩散模型生成动画，条件包括模板渲染和文本运动提示。我们引入了共享位置编码和模态感知嵌入，确保视频与姿态序列的时空对齐，从而有效迁移视频先验到运动生成任务中。生成的多视角姿态序列通过三角测量转换为3D关节位置，再通过逆向运动学生成网格动画。在包含160,000个绑定序列的新数据集上训练后，AnimaX在VBench上实现了泛化性、运动保真度和效率的领先水平，为类别无关的3D动画提供了可扩展的解决方案。项目页面：\href{https://anima-x.github.io/}{https://anima-x.github.io/}。

</details>


### [132] [Radial Attention: $O(n\log n)$ Sparse Attention with Energy Decay for Long Video Generation](https://arxiv.org/abs/2506.19852)
**中文标题：径向注意力：基于能量衰减的$O(n\log n)$稀疏注意力机制用于长视频生成**

*Xingyang Li,Muyang Li,Tianle Cai,Haocheng Xi,Shuo Yang,Yujun Lin,Lvmin Zhang,Songlin Yang,Jinbo Hu,Kelly Peng,Maneesh Agrawala,Ion Stoica,Kurt Keutzer,Song Han*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Radial Attention的稀疏注意力机制，通过模拟时空能量衰减现象，将计算复杂度从$O(n^2)$降低到$O(n\log n)$，显著提升了长视频生成的效率，同时保持了视频质量。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在高质量视频生成方面取得了进展，但时间维度的增加导致计算成本大幅上升，使得长视频的训练和推理变得昂贵。作者观察到视频扩散模型中存在时空能量衰减现象，即注意力分数随时空距离增加而衰减，受此启发提出了更高效的注意力机制。

研究方法: Radial Attention采用静态注意力掩码，每个token仅关注空间上邻近的token，且注意力窗口大小随时间距离增加而减小。该方法还支持通过LoRA微调扩展预训练模型的生成长度。

研究结果: 实验表明，Radial Attention在多个数据集（Wan2.1-14B、HunyuanVideo和Mochi 1）上保持了视频质量，计算速度比密集注意力快1.9倍，训练成本降低4.4倍，推理速度提升3.7倍，并能生成长度达4倍的视频。

研究结论: Radial Attention通过稀疏注意力机制显著提升了长视频生成的效率，同时保持了生成质量，为视频扩散模型的扩展提供了高效解决方案。

中文摘要: 近年来，扩散模型在高质量视频生成方面取得了显著进展，但时间维度的增加显著提高了计算成本，使得长视频的训练和推理变得极其昂贵。本文发现了一种称为时空能量衰减的现象：在视频扩散模型中，经过softmax后的注意力分数会随着token之间的时空距离增加而衰减，类似于自然界中信号或波在时空中的物理衰减。受此启发，我们提出了径向注意力（Radial Attention），这是一种可扩展的稀疏注意力机制，其复杂度为$O(n\log n)$，通过将能量衰减转化为指数衰减的计算密度，显著优于标准的$O(n^2)$密集注意力和线性注意力。具体而言，径向注意力采用一种简单的静态注意力掩码，每个token仅关注空间上邻近的token，且注意力窗口大小随时间距离增加而减小。此外，该方法还允许预训练的视频扩散模型通过高效的LoRA微调扩展生成长度。大量实验表明，径向注意力在Wan2.1-14B、HunyuanVideo和Mochi 1等数据集上保持了视频质量，计算速度比原始密集注意力快1.9倍。通过少量调整，它能够生成长度达4倍的视频，同时将训练成本降低4.4倍，推理速度提升3.7倍。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [133] [Signal Use and Emergent Cooperation](https://arxiv.org/abs/2506.18920)
**中文标题：信号使用与涌现合作**

*Michael Williams*

主要分类: cs.AI

摘要简述: 本研究探讨了自治代理如何通过信号沟通协调活动并提升集体效率，展示了代理如何通过学习与信号发展出类似文化的共享行为系统。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于理解自治代理如何通过信号沟通自我组织形成文化，以及不同沟通策略如何影响其适应性与合作能力。

研究方法: 采用NEC-DAC系统，每个代理配备独立神经网络进行决策，分析不同社会结构（如权威层级）对文化形成与代理表现的影响。

研究结果: 结果表明，合作文化显著提升部落表现，信号不仅促进文化涌现，还能跨代传播。个体代理神经网络中的行为协调与信号使用也有显著益处。

研究结论: 研究证实信号沟通是自治代理形成文化与高效合作的关键，为多代理系统设计提供了新视角。

中文摘要: 本研究探讨了自治代理如何通过信号沟通协调活动并提升集体效率。使用NEC-DAC（神经编码文化-分布式自治通信器）系统，每个代理配备独立神经网络进行决策，展示了代理如何通过学习与信号发展出类似文化的共享行为系统。研究聚焦于代理部落中文化的自组织，以及不同沟通策略如何影响其适应性与合作。通过分析权威层级等社会结构，发现合作文化显著影响部落表现。此外，信号不仅促进文化涌现，还能跨代传播。同时，研究还探讨了在个体代理神经网络中协调行为与信号使用的益处。

</details>


### [134] [Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience](https://arxiv.org/abs/2506.18928)
**中文标题：LLMs知道何时抛硬币吗？通过推理与经验的策略随机化**

*Lingyu Yang*

主要分类: cs.AI

摘要简述: 本文探讨大型语言模型（LLMs）在博弈论中的策略随机化能力，通过田忌赛马启发的零和游戏设计，评估不同LLMs在随机化决策中的表现，发现强模型在提示下更接近纳什均衡策略。


<details>
  <summary>详细信息</summary>
研究动机: 博弈论中的策略随机化是核心原则，但LLMs在此领域的研究不足，且常混淆随机化决策与随机生成机制。本文旨在填补这一空白，评估LLMs的策略推理能力。

研究方法: 设计基于田忌赛马的零和游戏，纳什均衡对应最大熵策略。通过不同提示风格（框架化、中立、暗示）评估五种LLMs，使用多轮竞技游戏隔离随机化决策。

研究结果: 弱模型无论提示如何均保持确定性，强模型在明确暗示下增加随机化；面对弱模型时，强模型采用确定性策略利用偏差，面对同类时趋近均衡策略。

研究结论: LLMs在策略推理能力上存在显著差异，需改进抽象推理和自适应学习。研究代码公开以确保可复现性。

中文摘要: 策略随机化是博弈论的核心原则，但在大型语言模型（LLMs）中研究不足。以往工作常混淆随机化决策与随机生成机制，导致评估不完整。为此，我们提出一种受田忌赛马启发的零和游戏，其纳什均衡对应最大熵策略。游戏复杂性使未受训练的人类和未成熟LLMs难以察觉此特性。我们通过竞争性多轮游戏评估五种LLMs在不同提示风格（框架化、中立、暗示）下的表现，隔离随机化决策。结果显示，弱模型无论提示如何均保持确定性，而强模型在明确暗示下增加随机化；面对弱模型时，强模型采用确定性策略利用偏差，面对同类时趋近均衡策略。通过胜负结果和贝叶斯因子分析，我们展示了LLMs策略推理能力的显著差异，凸显了抽象推理和自适应学习的改进空间。研究代码公开于https://github.com/ocelopus/llm-when-to-throw-coin以确保完全可复现性。

</details>


### [135] [A Comment On "The Illusion of Thinking": Reframing the Reasoning Cliff as an Agentic Gap](https://arxiv.org/abs/2506.18957)
**中文标题：对‘思考的幻觉’的评论：将推理悬崖重构为代理差距**

*Sheraz Khan,Subha Madhavan,Kannan Natarajan*

主要分类: cs.AI

摘要简述: 本文评论了Shojaee等人的研究，认为其提出的‘推理悬崖’并非模型认知能力的根本限制，而是实验设计中的系统约束导致的。通过引入工具使用，模型能够解决此前无法完成的任务，揭示了‘代理差距’而非推理缺陷。


<details>
  <summary>详细信息</summary>
研究动机: Shojaee等人的研究提出‘推理悬崖’，认为大型推理模型（LRMs）在特定复杂度后性能崩溃是链式思维推理（CoT）的固有局限。本文旨在反驳这一观点，指出其结论受实验设计限制的干扰，并强调模型失败源于执行限制而非推理能力不足。

研究方法: 本文通过实证分析，展示了模型在文本生成限制下无法完成任务，但在引入代理工具后能够解决甚至超越此前失败的任务复杂度。同时，分析了工具赋能模型（如o4-mini和GPT-4o）的代理推理层次。

研究结果: 模型在工具支持下能够解决此前无法完成的任务，且表现远超‘推理悬崖’的复杂度阈值。工具赋能模型展现出从简单执行到复杂自我修正的代理推理层次。

研究结论: 模型的‘推理悬崖’并非认知能力的根本限制，而是实验设计中的代理差距。工具支持能够显著提升模型表现，重新定义机器智能的评估标准。

中文摘要: Shojaee等人（2025）的近期研究《思考的幻觉：通过问题复杂性视角理解推理模型的优势与局限》提出了一个引人注目的实证发现——‘推理悬崖’，即大型推理模型（LRMs）在特定复杂度阈值后性能崩溃，作者认为这是链式思维推理（CoT）的固有局限。本评论在承认研究方法严谨性的同时，认为这一结论受实验设计干扰。我们指出，观察到的失败并非认知边界的证据，而是静态、纯文本评估范式中系统级约束的可预测结果，包括工具使用限制、上下文窗口召回问题、关键认知基线的缺失、统计报告不足及输出生成限制。我们通过‘代理差距’的视角重构这一性能崩溃，主张模型并非推理失败，而是在极度受限的界面中执行失败。我们通过实证支持这一批评，展示了一个模型在纯文本生成限制下宣称无法解决的谜题，在引入代理工具后不仅解决，还掌握了远超此前失败复杂度的变体。此外，我们对工具赋能模型（如o4-mini和GPT-4o）的实证分析揭示了代理推理的层次，从简单程序执行到复杂元认知自我修正，这对如何定义和测量机器智能具有重要启示。LRMs的‘思考幻觉’更多是缺乏行动工具的后果，而非推理缺陷。

</details>


### [136] [From Rows to Yields: How Foundation Models for Tabular Data Simplify Crop Yield Prediction](https://arxiv.org/abs/2506.19046)
**中文标题：从行到产量：表格数据基础模型如何简化作物产量预测**

*Filip Sabo,Michele Meroni,Maria Piles,Martin Claverie,Fanie Ferreira,Elna Van Den Berg,Francesco Collivignarelli,Felix Rembold*

主要分类: cs.AI

摘要简述: 本文探讨了一种基于表格数据的基础模型（TabPFN）在南非次国家级作物产量预测中的应用。TabPFN在回归和分类任务中表现优于传统机器学习模型，且具有更快的调参速度和更低的特征工程需求，适用于实际产量预测场景。


<details>
  <summary>详细信息</summary>
研究动机: 传统机器学习模型在作物产量预测中需要复杂的特征工程和调参，效率较低。TabPFN作为一种新型基础模型，有望简化这一过程并提升预测效率。

研究方法: 研究使用TabPFN模型，结合10天时间序列的遥感数据（FAPAR和土壤湿度）和网格化天气数据（气温、降水和辐射），预测南非次国家级夏季作物产量。数据覆盖23年8个省份，并通过留一年交叉验证评估模型性能。

研究结果: TabPFN与传统机器学习模型在预测精度上表现相当，但显著优于基线模型。TabPFN的优势在于调参速度快且无需复杂特征工程，更适合实际应用。

研究结论: TabPFN在作物产量预测中表现出高效性和实用性，是实际操作的理想选择。

中文摘要: 本文介绍了一种针对中小型表格数据的基础模型（TabPFN）在南非次国家级作物产量预测任务中的应用。TabPFN在多种回归和分类任务中表现优于传统机器学习模型。研究利用10天时间序列的遥感数据（FAPAR和土壤湿度）和网格化天气数据（气温、降水和辐射），预测夏季作物在次国家级的产量。数据覆盖23年8个省份，并通过留一年交叉验证评估模型性能。结果显示，TabPFN与传统机器学习模型精度相当，但显著优于基线模型。TabPFN的优势在于调参速度快且无需复杂特征工程，更适合实际产量预测应用。

</details>


### [137] [Baba is LLM: Reasoning in a Game with Dynamic Rules](https://arxiv.org/abs/2506.19095)
**中文标题：Baba是LLM：动态规则游戏中的推理**

*Fien van Wetten,Aske Plaat,Max van Duijn*

主要分类: cs.AI

摘要简述: 本文研究了六种大型语言模型（LLM）在动态规则游戏《Baba is You》中的推理能力，发现大模型（如GPT-4o）表现较好，但小模型难以理解游戏机制或应用规则变化。微调虽能提升游戏分析能力，但对解题帮助有限，表明动态规则推理对LLM仍具挑战性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在语言任务中表现优异，但在推理任务中表现不佳。本文旨在通过动态规则游戏《Baba is You》测试LLM的语言能力和推理能力，探索其在复杂问题解决中的适用性。

研究方法: 研究评估了六种LLM，使用三种提示类型（简单、规则扩展和动作扩展），并对两种模型（Mistral、OLMo）进行了微调，结合游戏文本和结构数据。

研究结果: 结果显示，大模型（如GPT-4o）在推理和解谜中表现更优，而小模型难以识别游戏机制或应用规则变化。微调提升了游戏分析能力，但对解题能力改善有限。

研究结论: 即使是最先进的或微调后的LLM，动态规则推理仍具挑战性（尤其是区分使用与提及）。研究为LLM在复杂问题解决中的应用提供了见解，并凸显动态规则游戏对测试LLM推理能力的价值。

中文摘要: 大型语言模型（LLM）在语言任务中表现良好，但在推理任务中表现不佳。本文探讨了LLM在2D解谜游戏《Baba is You》中的表现，玩家通过重新排列定义对象属性的文本块来操纵规则。由于这种规则操纵依赖于语言能力和推理，它对LLM构成了引人注目的挑战。研究评估了六种LLM，使用了三种提示类型（简单、规则扩展和动作扩展），并对两种模型（Mistral、OLMo）进行了微调，结合游戏文本和结构数据。结果表明，尽管大模型（尤其是GPT-4o）在推理和解谜中表现更好，但未经调整的小模型难以识别游戏机制或应用规则变化。微调提升了游戏分析能力，但对解题能力改善有限。我们得出结论，即使是最先进或微调后的LLM，动态规则推理仍具挑战性（尤其是区分使用与提及）。研究为LLM在复杂问题解决中的应用提供了见解，并凸显了动态规则游戏对测试LLM推理和反思能力的适用性。

</details>


### [138] [Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs](https://arxiv.org/abs/2506.19185)
**中文标题：Spiritual-LLM：LLM时代的《薄伽梵歌》启发心理健康疗法**

*Janak Kapuriya,Aman Singh,Jainendra Shukla,Rajiv Ratn Shah*

主要分类: cs.AI

摘要简述: 本研究提出了一种结合《薄伽梵歌》精神智慧与GPT-4o大语言模型的新框架，用于提升心理健康支持的情感深度，并通过GITes数据集和新型Spiritual Insight指标验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 传统心理健康支持系统仅基于用户当前情绪和情境生成回应，干预效果较浅。本研究旨在通过整合精神智慧与AI技术，满足更深层次的情感需求。

研究方法: 研究构建了GITes数据集，包含10,729条由GPT-4o生成并经专家评估的精神指导回应。通过Spiritual Insight指标和LLM陪审团框架评估精神相关性，并对比12种先进LLM模型。

研究结果: 最佳模型Phi3-Mini 3.2B Instruct在多指标上显著提升：ROUGE提高122.71%，METEOR提高126.53%，BERT分数提高8.15%，Spiritual Insight提高15.92%，Sufficiency提高18.61%，Relevance提高13.22%。

研究结论: 研究表明，结合精神指导的AI系统能显著提升用户满意度和支持效果，但需进一步在真实患者群体中验证。代码和数据集将公开以推动相关研究。

中文摘要: 传统心理健康支持系统通常仅基于用户的当前情绪和情境生成回应，导致干预效果较浅，无法满足更深层次的情感需求。本研究提出了一种新颖框架，通过将《薄伽梵歌》的精神智慧与先进的大语言模型GPT-4o结合，以提升情感健康。我们提出了GITes（《薄伽梵歌》整合情感支持疗法）数据集，该数据集在现有ExTES心理健康数据集的基础上，增加了10,729条由GPT-4o生成并经领域专家评估的精神指导回应。我们对GITes与12种先进LLM（包括心理健康专用和通用模型）进行了基准测试。为了评估生成回应中超越传统n-gram指标的精神相关性，我们提出了一种新型Spiritual Insight指标，并通过LLM陪审团框架和链式思维提示自动化评估。将精神指导整合到AI驱动的支持中，显著提升了最佳模型Phi3-Mini 3.2B Instruct的NLP和精神指标，与零样本版本相比，ROUGE提高了122.71%，METEOR提高了126.53%，BERT分数提高了8.15%，Spiritual Insight提高了15.92%，Sufficiency提高了18.61%，Relevance提高了13.22%。尽管这些结果在自动化的同理心和精神指标上显示出显著改进，但在真实患者群体中的进一步验证仍是必要步骤。我们的发现表明，结合精神指导的AI系统具有显著提升用户满意度和感知支持效果的潜力。代码和数据集将公开，以推动这一新兴领域的进一步研究。

</details>


### [139] [Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition](https://arxiv.org/abs/2506.19191)
**中文标题：贝叶斯进化群体架构：基于真理竞争的形式化认知系统**

*Craig Steven Wright*

主要分类: cs.AI

摘要简述: 本文提出了一种基于贝叶斯推理和群体动力学的数学框架，通过结构化竞争和信念修正，构建了一个由概率代理组成的人工智能系统。系统以外部真理为基准，通过竞争和进化机制实现知识的自我验证和收敛。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于构建一个数学上严格的人工智能系统，通过竞争和进化机制实现代理的信念修正和知识收敛，以外部真理为基准验证知识的可靠性。

研究方法: 方法包括基于贝叶斯推理和测度理论的代理设计，通过结构化竞争和信念修正实现进化。代理的适应度由与外部真理的对齐程度决定，采用哈希加密身份和因果推断算子确保系统的可追溯性和一致性。

研究结果: 结果表明，系统能够实现知识的自我验证和收敛，真理成为进化吸引子。通过形式化定理证明了系统的收敛性、鲁棒性和进化稳定性。

研究结论: 结论表明，该系统通过竞争和进化机制实现了知识的自我验证和收敛，为可计算的自调节群体智能提供了理论基础。

中文摘要: 我们提出了一种数学上严格的人工智能系统框架，该系统由概率代理组成，通过结构化竞争和信念修正实现进化。该架构基于贝叶斯推理、测度理论和群体动力学，将代理的适应度定义为与固定外部真理的对齐程度。代理在离散时间环境中竞争，通过观察结果调整后验信念，高评分代理繁殖，低评分代理灭绝。评分通过成对的真理对齐效用比较更新，信念更新保持可测一致性和随机收敛性。我们引入了基于哈希的加密身份承诺以确保可追溯性，并使用do-演算的因果推断算子。提供了关于收敛性、鲁棒性和进化稳定性的形式化定理。系统将真理确立为进化吸引子，证明可验证知识源于可计算的自调节群体中的对抗性认知压力。

</details>


### [140] [GBGC: Efficient and Adaptive Graph Coarsening via Granular-ball Computing](https://arxiv.org/abs/2506.19224)
**中文标题：GBGC：基于粒度球计算的高效自适应图粗化方法**

*Shuyin Xia,Guan Wang,Gaojie Xu,Sen Zhao,Guoyin Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种基于粒度球计算（GBGC）的高效自适应图粗化方法，通过多粒度特性优化粗化结果，显著提升处理速度和精度。


<details>
  <summary>详细信息</summary>
研究动机: 传统图粗化方法主要基于频谱保持，忽略了图结构的多粒度特性。本文旨在通过粒度球计算，自适应地生成最优粒度的粗化图。

研究方法: GBGC引入自适应粒度球图细化机制，将原图从粗到细分割为不同大小的粒度球，并以这些球为超节点构建粗化图。

研究结果: GBGC的处理速度比其他方法快数十至数百倍，时间复杂性更低，且由于粒度球计算的鲁棒性，其精度几乎总是高于原图。

研究结论: GBGC因其高效性和高精度，有望成为标准的图数据预处理方法。

中文摘要: 图粗化的目标是生成更小、更易管理的图，同时保留原图的关键信息。以往的工作主要基于频谱保持的视角，使用预定义的粗化规则使原图和粗化图的拉普拉斯矩阵特征值尽可能匹配。然而，这些方法很大程度上忽略了原图由不同粒度级别的子区域组成的事实，其中高度连接且相似的节点更倾向于被聚合为粗化图中的节点。通过结合图结构的多粒度特性，我们可以在最优粒度下生成粗化图。为此，受粒度球计算在多粒度中的应用启发，我们提出了一种新的多粒度、高效且自适应的粗化方法（GBGC），显著提升了粗化结果和效率。具体而言，GBGC引入了一种自适应的粒度球图细化机制，将原图从粗到细自适应地分割为不同大小和最优粒度的粒度球，并以这些粒度球为超节点构建粗化图。此外，与其他最先进的图粗化方法相比，该方法处理速度可提升数十至数百倍，且时间复杂性更低。由于粒度球计算的良好鲁棒性和泛化性，GBGC的精度几乎总是高于原图，因此有望成为标准的图数据预处理方法。

</details>


### [141] [RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1](https://arxiv.org/abs/2506.19235)
**中文标题：RecLLM-R1：基于强化学习与链式思维的两阶段训练范式v1**

*Yu Xie,Xingkai Ren,Ying Qi,Yao Hu,Lianlei Shan*

主要分类: cs.AI

摘要简述: 本文提出RecLLM-R1，一种基于大语言模型（LLM）的两阶段训练推荐框架，通过监督微调和强化学习结合链式思维机制，显著提升推荐准确性、多样性和新颖性，有效缓解过滤气泡效应。


<details>
  <summary>详细信息</summary>
研究动机: 传统推荐系统存在过滤气泡、外部知识利用不足以及模型优化与业务策略迭代脱节的问题。本文旨在通过结合大语言模型和强化学习技术，提出一种更高效的推荐框架。

研究方法: RecLLM-R1采用两阶段训练：第一阶段通过监督微调（SFT）赋予LLM基础推荐能力；第二阶段结合强化学习（GRPO）和链式思维（CoT）机制，通过多步推理和自定义奖励函数优化推荐目标。

研究结果: 实验表明，RecLLM-R1在准确性、多样性和新颖性等指标上显著优于基线方法，有效缓解过滤气泡效应，并实现业务目标与模型优化的协同。

研究结论: RecLLM-R1为复杂业务目标下的推荐模型与策略优化提供了新思路，展示了LLM在推荐系统中的潜力。

中文摘要: 传统推荐系统常面临过滤气泡、外部知识利用不足以及模型优化与业务策略迭代脱节的问题。为解决这些局限，本文提出RecLLM-R1，一种基于大语言模型（LLM）的推荐框架，灵感源自DeepSeek R1方法。该框架首先通过精心设计的数据构建过程，将用户画像、历史交互和多维物品属性转化为LLM可理解的自然语言提示。随后采用两阶段训练范式：第一阶段通过监督微调（SFT）赋予LLM基础推荐能力；第二阶段结合组相对策略优化（GRPO）这一强化学习技术，并引入链式思维（CoT）机制，通过多步推理和自定义奖励函数，同步优化推荐准确性、多样性及其他定制业务目标。基于大规模社交媒体平台真实用户行为数据的实验表明，RecLLM-R1在准确性、多样性和新颖性等多项指标上显著优于现有基线方法，有效缓解过滤气泡效应，并为复杂业务目标下的推荐模型与策略集成优化提供了可行路径。

</details>


### [142] [Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach](https://arxiv.org/abs/2506.19280)
**中文标题：面向用户前端应用界面的情绪检测与日程优化：一种机器学习方法**

*Feiting Yang,Antoine Moevus,Steve Lévesque*

主要分类: cs.AI

摘要简述: 本文研究了将情绪检测技术集成到日历应用中，通过生物特征和行为数据两种方法动态响应用户情绪，提升生产力和参与度。结果显示行为方法（如鼠标移动）准确率更高，GRU网络在生物特征方法中表现优于LSTM。


<details>
  <summary>详细信息</summary>
研究动机: 人机交互（HCI）的发展使得情绪识别技术能够为用户提供自适应和个性化的体验。本文旨在通过情绪检测优化日历应用，动态调整用户界面以提升生产力和用户参与度。

研究方法: 论文提出了两种情绪检测方法：1）基于生物特征的方法，通过LSTM和GRU神经网络处理心电图（ECG）信号中的心率数据，预测情绪维度（效价、唤醒度和支配度）；2）基于行为的方法，通过机器学习模型分析用户交互行为（如鼠标移动、点击和键盘输入）分类情绪。

研究结果: 实验结果表明，两种方法均有效，但行为方法在鼠标相关交互中表现更优，准确率约为90%。在生物特征方法中，GRU网络优于LSTM，效价预测准确率达到84.38%。

研究结论: 情绪检测技术能够显著提升日历应用的用户体验，行为方法在准确性和一致性上表现更佳，而GRU网络在生物特征分析中更具优势。

中文摘要: 人机交互（HCI）已显著发展，能够结合情绪识别技术，为自适应和个性化用户体验创造前所未有的机会。本文探讨了将情绪检测集成到日历应用中的方法，使界面能够动态响应用户的情绪状态和压力水平，从而提升生产力和参与度。我们提出并评估了两种互补的情绪检测方法：一种基于生物特征，利用长短期记忆（LSTM）和门控循环单元（GRU）神经网络处理心电图（ECG）信号中的心率数据，预测情绪的效价、唤醒度和支配度；另一种基于行为，通过多种机器学习模型分析计算机活动（如鼠标移动、点击和键盘输入模式）分类情绪。基于真实数据集的对比分析表明，两种方法均有效，但行为方法在鼠标相关交互中表现出更高的准确性和一致性，准确率约为90%。此外，在生物特征方法中，GRU网络优于LSTM模型，效价预测准确率达到84.38%。

</details>


### [143] [Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs](https://arxiv.org/abs/2506.19290)
**中文标题：Skywork-SWE：揭示LLM在软件工程中的数据扩展规律**

*Liang Zeng,Yongcong Li,Yuzhen Xiao,Changshi Li,Chris Yuhao Liu,Rui Yan,Tianwen Wei,Jujie He,Xuchen Song,Yang Liu,Yahui Zhou*

主要分类: cs.AI

摘要简述: Skywork-SWE研究揭示了LLM在软件工程领域的数据扩展规律，提出自动化数据整理流程，显著提升数据集规模和多样性，模型性能随数据量增加持续提升，未现饱和现象，并在SWE-bench基准测试中创下新纪录。


<details>
  <summary>详细信息</summary>
研究动机: 软件工程（SWE）已成为下一代LLM代理的关键测试领域，但其数据整理过程依赖人工标注和专用运行环境，耗时且数据集规模有限。研究旨在通过自动化流程解决这一问题，并探索数据规模对模型性能的影响。

研究方法: 提出增量式自动化数据整理流程，从2,531个GitHub仓库中收集10,169个真实Python任务实例，每个任务包含自然语言描述和专用运行环境镜像。整理8,000多条已验证的训练轨迹，用于微调Skywork-SWE模型。

研究结果: Skywork-SWE模型在SWE-bench基准测试中达到38.0% pass@1准确率（未使用验证器或多轮测试），创下基于OpenHands代理框架的Qwen2.5-Coder-32B模型的SOTA。结合测试时扩展技术后，准确率进一步提升至47.0%。

研究结论: 研究表明，LLM在软件工程领域的性能随数据规模增加持续提升，未现饱和现象。自动化数据整理流程显著提升了数据集的规模和多样性，为未来研究提供了重要资源。

中文摘要: 软件工程（SWE）已成为下一代LLM代理的关键测试领域，要求具备持续迭代问题解决（如>50轮交互）和长上下文依赖解析（如>32k标记）能力。然而，SWE的数据整理过程依赖人工标注和专用运行环境，耗时且数据集规模有限。为此，我们提出一种增量式自动化数据整理流程，系统性地扩展SWE数据集的规模和多样性。我们的数据集包含来自2,531个GitHub仓库的10,169个真实Python任务实例，每个任务配有自然语言描述和专用运行环境镜像。我们精心整理了8,000多条已验证的训练轨迹。微调Skywork-SWE模型后，发现模型性能随数据量增加持续提升，未现饱和现象。Skywork-SWE模型在SWE-bench基准测试中达到38.0% pass@1准确率（未使用验证器或多轮测试），创下基于OpenHands代理框架的Qwen2.5-Coder-32B模型的SOTA。结合测试时扩展技术后，准确率进一步提升至47.0%。我们发布了Skywork-SWE-32B模型检查点以加速未来研究。

</details>


### [144] [FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring](https://arxiv.org/abs/2506.19325)
**中文标题：FEAT：一种低成本自动生成与标注框架构建的英语AI辅导偏好反馈数据集**

*Hyein Seo,Taewook Hwang,Yohan Lee,sangkeun Jung*

主要分类: cs.AI

摘要简述: 本文提出了一种低成本自动生成英语AI辅导中教师反馈的框架FEAT，并构建了三个互补数据集。实验表明，结合少量高质量数据可显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 英语教育辅导中，教师反馈对学生至关重要，但高质量反馈数据的人工生成成本高且耗时。AI辅导系统需要大规模高质量数据，因此需要一种低成本解决方案。

研究方法: 提出FEAT框架，构建三个数据集：(1) DM（人工与LLM协作生成高质量数据，成本较高）；(2) DG（仅LLM生成，成本低但质量较低）；(3) DA（以DG为主，加入少量DM提升质量）。

研究结果: 实验结果显示，在DG中加入5-10%的DM数据，性能优于仅使用100% DM数据。

研究结论: FEAT框架通过低成本方式生成高质量教师反馈数据，结合少量人工数据可显著提升AI辅导系统的性能。

中文摘要: 在英语教育辅导中，教师反馈对指导学生至关重要。近年来，基于AI的辅导系统逐渐兴起以辅助教师，但这些系统需要高质量、大规模的教师反馈数据，而人工生成这些数据既耗时又昂贵。本研究提出FEAT，一种低成本生成教师反馈的框架，并构建了三个互补数据集：(1) DIRECT-Manual (DM)，由人类与大型语言模型（LLM）协作生成高质量反馈，但成本较高；(2) DIRECT-Generated (DG)，仅由LLM生成，成本低但质量较低；(3) DIRECT-Augmented (DA)，以DG为主，加入少量DM以提升质量同时保持成本效益。实验结果表明，在DG中加入少量DM（5-10%）的性能优于仅使用100% DM。

</details>


### [145] [Evolutionary Level Repair](https://arxiv.org/abs/2506.19359)
**中文标题：进化式关卡修复**

*Debosmita Bhaumik,Julian Togelius,Georgios N. Yannakakis,Ahmed Khalifa*

主要分类: cs.AI

摘要简述: 本文提出了一种基于进化和质量多样性算法的游戏关卡修复方法，用于修复设计但非功能性的关卡，并结合机器学习生成的内容，展示了混合程序内容生成方法的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 游戏关卡设计常因非功能性（如不完整或不可达）而需要修复，传统方法难以在少量修改下实现修复。本文旨在探索基于搜索的修复方法，特别是进化和质量多样性算法，以解决这一问题。

研究方法: 采用进化和质量多样性算法作为搜索基础，修复非功能性游戏关卡。该方法结合机器学习生成的内容（PCGML），生成风格一致但常存在问题的关卡，并通过搜索算法进行修复。

研究结果: 实验表明，该方法能有效修复非功能性关卡，且仅需少量修改。结合PCGML生成的内容，展示了混合程序内容生成方法的高效性和潜力。

研究结论: 基于进化和质量多样性算法的关卡修复方法，结合机器学习生成的内容，为混合程序内容生成提供了新方向，具有实际应用价值。

中文摘要: 本文探讨了游戏关卡修复问题，即对设计但非功能性的关卡进行修复，使其具备功能性。修复可能涉及确保关卡的完整性、对象的可达性或其他性能特征，且通常受限于仅能进行少量修改。我们研究了基于搜索的关卡修复解决方案，特别是使用进化和质量多样性算法，取得了良好效果。该方法应用于基于机器学习的程序内容生成（PCGML）方法生成的关卡，这些关卡风格合适但常存在缺陷。PCGML生成与基于搜索的修复方法的结合，展示了混合程序内容生成（PCG）方法的巨大潜力。

</details>


### [146] [Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics](https://arxiv.org/abs/2506.19385)
**中文标题：对话意图驱动的GraphRAG：通过自适应双检索流模式与上下文语义增强多轮对话系统**

*Ziqi Zhu,Tao Hu,Honglong Zhang,Dan Yang,HanGeng Chen,Mengran Zhang,Xilun Chen*

主要分类: cs.AI

摘要简述: CID-GraphRAG是一种新型对话系统框架，通过动态意图转移图和双检索机制，结合意图流模式和语义搜索，显著提升了多轮客户服务对话的上下文连贯性和目标导向性。实验表明，其性能优于传统语义检索和意图检索方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有对话系统在多轮客户服务对话中难以同时保持上下文连贯性和目标导向性。传统方法仅依赖语义相似性或静态知识图谱，无法动态捕捉意图转移。CID-GraphRAG旨在通过动态意图转移图和双检索机制解决这一问题。

研究方法: CID-GraphRAG构建动态意图转移图，并采用双检索机制，自适应地结合意图图遍历和语义搜索。该方法同时利用对话意图流模式和上下文语义，提升检索和生成质量。

研究结果: 实验表明，CID-GraphRAG在自动指标和LLM评估中均显著优于传统方法，BLEU提升11%，ROUGE-L提升5%，METEOR提升6%，响应质量提升58%。

研究结论: CID-GraphRAG通过结合意图转移结构和语义检索，实现了协同效应，有效解决了多轮知识密集型对话中的上下文连贯性和目标导向性问题。

中文摘要: 本文提出CID-GraphRAG（对话意图驱动的图检索增强生成），一种新型框架，旨在解决现有对话系统在多轮客户服务对话中难以同时保持上下文连贯性和目标导向性的问题。与传统仅依赖语义相似性（对话RAG）或静态知识图谱（GraphRAG）的方法不同，CID-GraphRAG从历史对话中构建动态意图转移图，并采用双检索机制，自适应地平衡意图图遍历与语义搜索。该方法同时利用对话意图流模式和上下文语义，显著提升了检索质量和响应质量。在真实客户服务对话的广泛实验中，通过自动指标和LLM评估，CID-GraphRAG在所有评估标准上均显著优于基于语义的对话RAG和基于意图的GraphRAG基线。定量结果显示，CID-GraphRAG在自动指标上相对对话RAG有显著提升：BLEU提升11%，ROUGE-L提升5%，METEOR提升6%，而LLM评估的响应质量提升高达58%。这些结果表明，意图转移结构与语义检索的结合产生了协同效应，为知识密集型多轮对话中的上下文连贯性和目标导向性问题提供了有效解决方案。

</details>


### [147] [Is an object-centric representation beneficial for robotic manipulation ?](https://arxiv.org/abs/2506.19408)
**中文标题：物体中心表示对机器人操作任务有益吗？**

*Alexandre Chapin,Emmanuel Dellandrea,Liming Chen*

主要分类: cs.AI

摘要简述: 本文探讨了物体中心表示（OCR）在机器人操作任务中的潜力，通过模拟环境中的多对象任务验证其优于整体表示的性能。


<details>
  <summary>详细信息</summary>
研究动机: 物体中心表示（OCR）在计算机视觉领域备受关注，被认为能提升数据效率和泛化能力。然而，现有研究多集中于场景分解，缺乏对学习表示的实际推理验证。机器人操作任务涉及多对象交互，是验证OCR潜力的理想场景。

研究方法: 研究设计了多个模拟机器人操作任务，包含多对象环境和高度随机化因素（如位置、颜色、形状等），并对比了经典OCR方法与现有整体表示方法在泛化场景中的表现。

研究结果: 实验表明，现有方法在复杂场景中容易失败，而OCR方法能有效应对这些挑战，展现出更强的泛化能力。

研究结论: OCR在机器人操作任务中具有显著优势，尤其是在复杂场景和多对象交互的情况下，为未来研究提供了方向。

中文摘要: 物体中心表示（OCR）近年来在计算机视觉领域引起关注，用于学习图像和视频的结构化表示。它被认为是一种提升数据效率和下游任务泛化能力的潜在方法。然而，现有研究多集中于场景分解，缺乏对学习表示的实际推理验证。机器人操作任务通常涉及多对象环境和对象间交互，因此是验证OCR潜力的理想场景。为此，我们在模拟环境中创建了多个机器人操作任务，包含多对象（如干扰物、机器人等）和高度随机化因素（如对象位置、颜色、形状、背景等）。随后，我们评估了一种经典OCR方法在多个泛化场景中的表现，并与几种先进的整体表示方法进行了对比。结果表明，现有方法在复杂场景中容易失败，而OCR方法能有效应对这些挑战。

</details>


### [148] [Unsupervised Dataset Dictionary Learning for domain shift robust clustering: application to sitting posture identification](https://arxiv.org/abs/2506.19410)
**中文标题：无监督数据集字典学习用于领域偏移鲁棒聚类：应用于坐姿识别**

*Anas Hattay,Mayara Ayat,Fred Ngole Mboula*

主要分类: cs.AI

摘要简述: 本文提出了一种名为无监督数据集字典学习（U-DaDiL）的新方法，用于完全无监督的鲁棒聚类，应用于坐姿识别。该方法通过基于Wasserstein重心表示的分布对齐，解决了传统方法对多样化数据集适应性差和领域偏移问题。在Office31数据集上的实验表明，聚类对齐准确性显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法在多样化数据集上的适应性较差，且容易受到领域偏移的影响。为了解决这些问题，本文提出了一种无监督的方法，旨在实现鲁棒的聚类，特别是在坐姿识别任务中。

研究方法: 本文提出了一种名为无监督数据集字典学习（U-DaDiL）的方法，通过基于Wasserstein重心的表示对齐不同数据集的分布，从而实现鲁棒的聚类。

研究结果: 在Office31数据集上的实验表明，U-DaDiL方法显著提高了聚类对齐的准确性，为解决领域偏移和无监督坐姿识别提供了有前景的解决方案。

研究结论: U-DaDiL方法为解决领域偏移问题和实现无监督坐姿识别的鲁棒聚类提供了有效的解决方案，实验证明了其优越性。

中文摘要: 本文介绍了一种名为无监督数据集字典学习（U-DaDiL）的新方法，用于完全无监督的鲁棒聚类，应用于坐姿识别。传统方法通常缺乏对多样化数据集的适应性，并受到领域偏移问题的影响。U-DaDiL通过基于Wasserstein重心的表示对齐不同数据集的分布，解决了这些问题。在Office31数据集上的实验评估表明，聚类对齐准确性显著提高。这项工作还为解决领域偏移和无监督坐姿识别的鲁棒聚类问题迈出了有前景的一步。

</details>


### [149] [Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection](https://arxiv.org/abs/2506.19420)
**中文标题：Commander-GPT：多模态讽刺检测的分工与路由**

*Yazhou Zhang,Chunwang Zou,Bo Wang,Jing Qin*

主要分类: cs.AI

摘要简述: 本文提出Commander-GPT，一种基于军事指挥理论的多模态讽刺检测框架，通过分工协作的LLM代理团队提升性能，实验显示其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型（LLM）在许多NLP任务中表现优异，但在讽刺理解方面仍有不足。本文旨在通过模块化分工协作的方式提升多模态讽刺检测的性能。

研究方法: 提出Commander-GPT框架，将任务分配给多个专业化LLM代理（如上下文建模、情感分析等），并通过三种指挥官（轻量级编码器、小型自回归模型、大型LLM）协调代理输出，最终完成讽刺判断。

研究结果: 在MMSD和MMSD 2.0基准测试中，Commander-GPT的F1分数平均比现有最优方法提升4.4%和11.7%。

研究结论: Commander-GPT通过模块化分工和多级指挥官设计，显著提升了多模态讽刺检测的性能，验证了其有效性。

中文摘要: 多模态讽刺理解是一项高阶认知任务。尽管大语言模型（LLM）在许多下游NLP任务中表现出色，但越来越多的证据表明其在讽刺理解方面存在困难。本文提出Commander-GPT，一种受军事指挥理论启发的模块化决策路由框架。该框架不依赖单一LLM的能力，而是协调一组专业化LLM代理，每个代理专注于特定子任务（如上下文建模、情感分析等）。代理的输出随后路由至指挥官，由其整合信息并完成最终讽刺判断。为协调这些代理，我们引入三种集中式指挥官：（1）基于轻量级编码器的训练指挥官（如多模态BERT）；（2）四个小型自回归语言模型，作为中等能力指挥官（如DeepSeek-VL）；（3）两个基于大型LLM的指挥官（Gemini Pro和GPT-4o），以零样本方式执行任务路由、输出聚合和讽刺决策。我们在MMSD和MMSD 2.0基准上评估Commander-GPT，比较五种提示策略。实验结果表明，该框架的F1分数平均比现有最优基线提升4.4%和11.7%，验证了其有效性。

</details>


### [150] [KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models](https://arxiv.org/abs/2506.19466)
**中文标题：昆仑白泽RAG：强化学习驱动的大语言模型推理性能飞跃**

*Cheng Li,Jiexiong Liu,Yixuan Chen,Qihang Zhou,KunLun Meta*

主要分类: cs.AI

摘要简述: 本文提出KunLunBaizeRAG，一种基于强化学习的推理框架，显著提升大语言模型在复杂多跳问答任务中的推理能力，解决了传统RAG的检索漂移、信息冗余和策略僵化等问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统RAG在复杂推理任务中存在检索漂移、信息冗余和策略僵化等局限性，亟需一种更高效的推理框架来提升大语言模型的性能。

研究方法: 框架包含RAG驱动的推理对齐（RDRA）机制、搜索-思考迭代增强（STIE）机制、网络-本地智能路由（NLR）机制，以及渐进式混合训练策略。

研究结果: 实验结果显示，在四个基准测试中，框架在精确匹配（EM）和LLM评分（LJ）上均有显著提升，证明了其在复杂推理场景中的鲁棒性和有效性。

研究结论: KunLunBaizeRAG通过强化学习驱动的推理机制，显著提升了大语言模型在复杂任务中的表现，为未来研究提供了新方向。

中文摘要: 本文介绍了昆仑白泽RAG，一种基于强化学习的推理框架，旨在提升大语言模型（LLM）在复杂多跳问答任务中的推理能力。该框架解决了传统RAG的关键局限性，如检索漂移、信息冗余和策略僵化。其核心创新包括RAG驱动的推理对齐（RDRA）机制、搜索-思考迭代增强（STIE）机制、网络-本地智能路由（NLR）机制，以及渐进式混合训练策略。实验结果表明，在四个基准测试中，框架在精确匹配（EM）和LLM评分（LJ）上均有显著提升，突显了其在复杂推理场景中的鲁棒性和有效性。

</details>


### [151] [NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling](https://arxiv.org/abs/2506.19500)
**中文标题：NaviAgent：基于工具依赖图的函数调用双层规划**

*Yan Jiang,Hao Zhou,LiZhong GU,Ai Han,TianLong Li*

主要分类: cs.AI

摘要简述: NaviAgent是一种基于工具依赖图的双层规划架构，通过多路径决策器和图编码导航器实现高效、鲁棒的函数调用，显著提升了任务成功率和执行效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖静态知识和单一执行路径，导致复杂异构工具链的协调能力不足，错误恢复能力差且搜索空间爆炸。NaviAgent旨在解决这些问题，提升工具调用的鲁棒性和效率。

研究方法: NaviAgent采用双层规划架构：1) 多路径决策器动态感知环境状态，选择最优动作；2) 图编码导航器构建工具依赖异构图，融合API结构和历史调用行为，并通过启发式搜索策略指导决策器。

研究结果: 实验表明，NaviAgent在任务成功率（TSR）上显著优于基线方法（ReAct、ToolLLM、α-UMI），平均提升13.5%~19.0%，执行步骤接近最优基线，且在复杂任务中对大模型（如Deepseek-V3和GPT-4o）的TSR提升高达9分。

研究结论: NaviAgent通过双层规划和图编码导航器，显著提升了工具调用的鲁棒性和效率，尤其在复杂任务和大模型中表现突出，为异构工具链协调提供了有效解决方案。

中文摘要: 大型语言模型（LLM）依赖静态知识和脆弱的工具调用机制，严重阻碍了复杂异构工具链的协调，尤其是在大规模场景下。现有方法通常采用单一执行路径，导致错误恢复能力差且搜索空间呈指数增长。本文提出NaviAgent，一种基于图导航的双层规划架构，用于鲁棒的函数调用，包括多路径决策器和图编码导航器。作为LLM驱动的代理，多路径决策器定义了四维决策空间，持续感知环境状态，动态选择最优动作以覆盖所有工具调用场景。图编码导航器构建了工具依赖异构图（TDHG），其节点嵌入显式融合了API模式结构和历史调用行为，并集成了一种新颖的启发式搜索策略，指导决策器实现高效且高成功率的工具链，即使面对未见过的工具组合。实验表明，NaviAgent在所有基础模型和任务复杂度下均实现了最高的任务成功率（TSR），在Qwen2.5-14B、Qwen2.5-32B和Deepseek-V3上分别比基线方法（ReAct、ToolLLM、α-UMI）平均高出13.5%、16.4%和19.0%。其执行步骤通常仅比最优基线多一步，确保了质量与效率的平衡。值得注意的是，经过微调的Qwen2.5-14B模型在TSR上达到49.5%，超过了更大的32B模型（44.9%）。图编码导航器的引入进一步将TSR平均提升了2.4分，在复杂任务中对大模型（Deepseek-V3和GPT-4o）的提升高达9分，凸显了其在工具链协调中的关键作用。

</details>


### [152] [NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons](https://arxiv.org/abs/2506.19530)
**中文标题：NTRL：基于强化学习的动态难度调整在《龙与地下城》中的战斗遭遇生成**

*Carlo Romeo,Andrew D. Bagdanov*

主要分类: cs.AI

摘要简述: 本文提出了一种基于强化学习的动态难度调整方法NTRL，用于自动化设计《龙与地下城》中的战斗遭遇，优化战斗时长和难度，同时保持游戏公平性。


<details>
  <summary>详细信息</summary>
研究动机: 《龙与地下城》中的战斗平衡需要地下城主手动评估队伍实力和敌人配置，过程复杂且容易打断叙事流程。本文旨在通过自动化方法解决这一问题。

研究方法: NTRL将问题建模为上下文老虎机，根据实时队伍属性生成战斗遭遇，并通过迭代优化提升战斗时长和难度。

研究结果: 与人工设计相比，NTRL显著延长战斗时长（+200%），增加队伍受到的伤害（生命值减少16.67%），并提升玩家死亡次数，同时保持较低的团灭率。战斗更具策略性，且胜率保持在70%。

研究结论: NTRL在提升战斗策略深度和难度的同时，保持了游戏的公平性，表现优于人工设计的战斗遭遇。

中文摘要: 在《龙与地下城》（D&D）中平衡战斗遭遇是一项复杂任务，需要地下城主（DM）手动评估队伍实力、敌人配置和动态玩家互动，同时避免打断叙事流程。本文提出了一种基于强化学习的战斗遭遇生成方法NTRL，用于自动化动态难度调整（DDA）。通过将问题建模为上下文老虎机，NTRL根据实时队伍属性生成战斗遭遇。与传统的DM启发式方法相比，NTRL通过迭代优化显著延长了战斗时长（+200%），增加了队伍受到的伤害（生命值减少16.67%），并提升了玩家死亡次数，同时保持较低的团灭率（TPK）。战斗强度的提升迫使玩家采取明智行动和战术策略，尽管生成的战斗遭遇保证了较高的胜率（70%）。即使与人工设计的战斗遭遇相比，NTRL在提升战斗策略深度和难度的同时，保持了游戏的整体公平性，表现更为优越。

</details>


### [153] [Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming](https://arxiv.org/abs/2506.19573)
**中文标题：使用FOLD-R++和答案集编程的可解释混合机器学习模型**

*Sanne Wielinga,Jesse Heyninck*

主要分类: cs.AI

摘要简述: 本文提出了一种结合FOLD-R++算法与答案集编程（ASP）的混合机器学习模型，旨在提升高风险领域（如医疗）中的预测准确性和可解释性。实验表明，该方法在多个医疗数据集上显著提高了准确率和F1分数。


<details>
  <summary>详细信息</summary>
研究动机: 在高风险领域（如医疗）中，机器学习模型的准确预测对决策至关重要，但高性能模型（如神经网络）通常缺乏可解释性，限制了其广泛应用。同时，符号方法（如ASP）虽可提供可解释的逻辑规则，但预测能力不足。因此，本文旨在结合两者的优势，实现高准确性和高可解释性。

研究方法: 本文提出了一种混合方法，将FOLD-R++算法生成的ASP规则与黑盒机器学习分类器结合，选择性修正不确定预测并提供人类可读的解释。通过实验验证了该方法在五个医疗数据集上的有效性。

研究结果: 实验结果表明，该方法在五个医疗数据集上显著提高了准确率和F1分数，证明了其在高风险领域中的实用性和有效性。

研究结论: 本研究展示了符号推理与传统机器学习结合的潜力，能够在保持高准确性的同时提升模型的可解释性，为高风险领域的决策提供了更可靠的工具。

中文摘要: 机器学习（ML）技术在高风险领域（如医疗）中发挥着关键作用，准确的预测能够显著提升决策质量。然而，高性能方法（如神经网络和集成方法）通常缺乏透明度，限制了其信任度和广泛应用。与此同时，符号方法（如答案集编程ASP）虽然能够提供可解释的逻辑规则，但其预测能力往往不及ML模型。本文提出了一种混合方法，将FOLD-R++算法生成的ASP规则与黑盒ML分类器结合，选择性修正不确定预测并提供人类可读的解释。在五个医疗数据集上的实验表明，该方法在准确率和F1分数上取得了统计显著的性能提升。本研究强调了符号推理与传统ML结合的潜力，能够在保持高准确性的同时实现高可解释性。

</details>


### [154] [Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning](https://arxiv.org/abs/2506.19592)
**中文标题：基于语言模型的自适应领域建模：一种多智能体任务规划方法**

*Harisankar Babu,Philipp Schillinger,Tamim Asfour*

主要分类: cs.AI

摘要简述: 本文提出TAPAS框架，通过多智能体协作结合大型语言模型（LLMs）与符号规划，无需手动定义环境模型即可解决复杂任务。TAPAS通过工具调用机制动态生成和调整领域模型，并在模拟环境中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 传统任务规划方法需要手动定义环境模型，限制了灵活性和适应性。本文旨在通过多智能体协作和语言模型，实现动态领域建模和任务规划，减少人工干预。

研究方法: TAPAS框架利用多智能体协作，每个智能体基于LLM生成和调整领域模型、初始状态和目标。通过工具调用机制，下游智能体可请求上游智能体修改模型，适应新属性和约束。结合ReAct执行代理和自然语言计划翻译，将动态生成的计划转化为实际机器人能力。

研究结果: TAPAS在基准规划领域和VirtualHome模拟环境中表现优异，验证了其动态领域建模和任务规划的有效性。

研究结论: TAPAS通过多智能体协作和语言模型，实现了无需手动定义环境模型的动态任务规划，为复杂任务提供了灵活且高效的解决方案。

中文摘要: 我们提出了TAPAS（基于任务的自适应与规划多智能体框架），该框架将大型语言模型（LLMs）与符号规划相结合，无需手动定义环境模型即可解决复杂任务。TAPAS利用基于LLM的专用智能体，通过结构化工具调用机制协作生成和调整领域模型、初始状态及目标规范。通过这种基于工具的交互，下游智能体可请求上游智能体进行修改，从而适应新属性和约束，无需手动重新定义领域。结合ReAct（推理+行动）风格的执行代理和自然语言计划翻译，TAPAS弥合了动态生成计划与实际机器人能力之间的差距。在基准规划领域和VirtualHome模拟现实环境中，TAPAS表现出卓越的性能。

</details>


### [155] [ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP](https://arxiv.org/abs/2506.19608)
**中文标题：ChordPrompt：协调跨模态提示协同以实现CLIP中的多领域增量学习**

*Zhiyuan Wang,Bokui Chen*

主要分类: cs.AI

摘要简述: 论文提出ChordPrompt框架，通过视觉与文本提示的协同作用，解决多领域增量学习中CLIP模型的性能问题，显著提升零样本泛化和下游任务表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有提示学习方法主要针对类增量学习，缺乏多领域任务增量学习的策略，且多采用单模态提示，忽略了跨模态信息交换的潜力。

研究方法: ChordPrompt框架引入跨模态提示，利用视觉与文本信息的交互，并结合领域自适应文本提示，实现多领域持续适应。

研究结果: 在多领域增量学习基准测试中，ChordPrompt在零样本泛化和下游任务性能上优于现有方法。

研究结论: ChordPrompt通过跨模态提示的协同作用，显著提升了CLIP模型在多领域增量学习中的适应性和性能。

中文摘要: 持续学习（CL）使预训练的视觉语言模型能够有效适应新颖或先前代表性不足的数据分布，而无需全面重新训练，从而增强其适应性和效率。尽管像CLIP这样的视觉语言模型显示出巨大潜力，但在增量学习场景中，它们难以跨领域保持性能。现有的提示学习方法面临两个主要限制：1）主要关注类增量学习场景，缺乏针对多领域任务增量学习的具体策略；2）大多数当前方法采用单模态提示，忽略了跨模态信息交换的潜在优势。为解决这些挑战，我们提出了ChordPrompt框架，促进视觉与文本提示的和谐互动。ChordPrompt引入跨模态提示以利用视觉与文本信息之间的交互。我们的方法还采用领域自适应文本提示，为跨多个领域的持续适应选择合适的提示。在多领域增量学习基准上的全面实验表明，ChordPrompt在零样本泛化和下游任务性能上优于最先进的方法。

</details>


### [156] [Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI](https://arxiv.org/abs/2506.19613)
**中文标题：立场：智能科学实验室需要认知与具身AI的整合**

*Sha Zhang,Suorong Yang,Tong Xie,Xiangyuan Xue,Zixuan Hu,Rui Li,Wenxi Qu,Zhenfei Yin,Tianfan Fu,Di Hu,Andres M Bran,Nian Ran,Bram Hoex,Wangmeng Zuo,Philippe Schwaller,Wanli Ouyang,Lei Bai,Yanyong Zhang,Lingyu Duan,Shixiang Tang,Dongzhan Zhou*

主要分类: cs.AI

摘要简述: 本文提出智能科学实验室（ISL）的概念，通过整合认知AI与具身AI，构建闭环系统以推动自主科学实验和偶然发现。


<details>
  <summary>详细信息</summary>
研究动机: 当前科学发现受限于人类能力和AI系统的虚拟环境限制，亟需结合认知与具身智能以突破瓶颈。

研究方法: 提出智能科学实验室（ISL）框架，整合科学推理基础模型、基于代理的工作流编排和具身代理，实现闭环实验系统。

研究结果: ISL框架展示了通过认知与具身智能的深度融合，支持自主实验和偶然发现的潜力。

研究结论: 智能科学实验室是突破科学发现现有局限、实现AI驱动科学全面变革的关键路径。

中文摘要: 长期以来，科学发现受限于人类在专业知识、身体能力和睡眠周期方面的局限性。近年来，AI科学家和自动化实验室的兴起加速了研究的认知和操作层面。然而，关键限制仍然存在：AI系统通常局限于虚拟环境，而自动化实验室缺乏在物理世界中自适应测试新假设的灵活性和自主性。具身AI的最新进展，如通用机器人基础模型、基于扩散的动作策略、细粒度操作学习和模拟到现实的迁移，凸显了整合认知与具身智能的潜力。这种融合为支持迭代、自主实验和偶然发现的闭环系统打开了大门。在本立场论文中，我们提出智能科学实验室（ISL）的范式：一个多层闭环框架，深度整合认知与具身智能。ISL统一了科学推理的基础模型、基于代理的工作流编排和用于稳健物理实验的具身代理。我们认为，此类系统对于克服当前科学发现的限制、实现AI驱动科学的全面变革潜力至关重要。

</details>


### [157] [Identifying Macro Causal Effects in C-DMGs over DMGs](https://arxiv.org/abs/2506.19650)
**中文标题：在基于DMGs的C-DMGs中识别宏观因果效应**

*Simon Ferreira,Charles K. Assaad*

主要分类: cs.AI

摘要简述: 本文证明了在基于DMGs的C-DMGs中，do-calculus无条件地适用于识别宏观因果效应，并扩展了非可识别性的图形标准。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中，高维系统难以构建完整的ADMG，而部分指定的因果表示（如C-DMGs）更具实用性。此外，循环因果动态在结构层面普遍存在，但现有研究主要关注无环图。本文旨在填补这一空白，研究基于DMGs的C-DMGs中宏观因果效应的识别问题。

研究方法: 通过引入输入输出结构因果模型（ioSCMs）作为SCMs的扩展，允许循环结构，并定义基于DMGs的C-DMGs。在此基础上，证明do-calculus在DMGs中的无条件适用性，并扩展非可识别性的图形标准。

研究结果: 证明了在基于DMGs的C-DMGs中，do-calculus无条件地适用于识别宏观因果效应，且非可识别性的图形标准可自然扩展到部分C-DMGs。

研究结论: 本文填补了循环因果动态下宏观因果效应识别的研究空白，为高维系统的因果分析提供了更实用的工具。

中文摘要: do-calculus是一种在结构因果模型（SCMs）诱导的无环有向混合图（ADMGs）中识别因果效应的完备工具。然而，在高维场景下，构建完整的ADMG通常不可行。这促使了对部分指定因果表示（如聚类有向混合图C-DMGs）的兴趣，其通过变量聚类提供了更抽象的因果依赖视图。尽管这些表示可能包含循环，但近期研究表明，在假设所有聚类大小大于1时，do-calculus在基于ADMGs的C-DMGs中仍适用于识别宏观因果效应。然而，现实系统常在结构层面表现出循环因果动态。为此，输入输出结构因果模型（ioSCMs）被提出作为SCMs的扩展，允许循环结构，并诱导另一种图结构——有向混合图（DMG）。类似于ADMG场景，可以定义基于DMGs的C-DMGs作为变量聚类间因果关系的高层表示。本文证明了与ADMG场景不同，do-calculus在基于DMGs的C-DMGs中无条件适用于识别宏观因果效应。此外，我们展示了先前针对基于ADMGs的C-DMGs建立的宏观因果效应非可识别性图形标准，可自然扩展到部分基于DMGs的C-DMGs。

</details>


### [158] [From memories to maps: Mechanisms of in context reinforcement learning in transformers](https://arxiv.org/abs/2506.19686)
**中文标题：从记忆到地图：Transformer中上下文强化学习的机制**

*Ching Fang,Kanaka Rajan*

主要分类: cs.AI

摘要简述: 本文探讨了Transformer如何通过情景记忆机制实现快速适应新环境的强化学习，揭示了其与大脑海马-内嗅系统的相似性。


<details>
  <summary>详细信息</summary>
研究动机: 人类和动物能快速适应新环境，而传统强化学习算法依赖增量更新，效率较低。研究旨在探索Transformer如何利用情景记忆实现快速学习，并揭示其与大脑记忆系统的关联。

研究方法: 研究训练了一个Transformer模型，在受啮齿动物行为启发的规划任务分布中进行上下文强化学习，并分析了模型的学习算法。

研究结果: 研究发现，模型通过上下文结构学习和跨上下文对齐实现表征学习，其强化学习策略既非标准无模型也非基于模型的规划，而是依赖缓存中间计算。模型表征与大脑海马-内嗅系统的计算相似。

研究结论: 记忆可作为计算资源存储原始经验和缓存计算，支持灵活行为。研究为人工和自然情境中的快速适应提供了机制性假设。

中文摘要: 人类和动物表现出卓越的学习效率，能够以极少的经验适应新环境。这种能力无法通过依赖增量值更新的标准强化学习算法很好地捕捉。快速适应可能依赖于情景记忆——即检索特定过去经验以指导新情境中决策的能力。Transformer因其在上下文中的快速学习能力及其键值架构与大脑情景记忆系统的相似性，为研究这些问题提供了有用框架。我们训练了一个Transformer模型，在受啮齿动物行为启发的规划任务分布中进行上下文强化学习，并分析了模型的学习算法。首先发现表征学习由上下文结构学习和跨上下文对齐支持，其中表征在不同感官刺激的环境中保持一致。其次，模型开发的强化学习策略无法解释为标准无模型或基于模型的规划。相反，上下文强化学习通过缓存模型记忆令牌中的中间计算并在决策时访问这些缓存来实现。总体而言，我们发现记忆可作为计算资源，存储原始经验和缓存计算以支持灵活行为。此外，模型中开发的表征与大脑海马-内嗅系统的计算相似，表明我们的发现可能与自然认知相关。综上，本研究为人工和自然情境中上下文学习的快速适应提供了机制性假设。

</details>


### [159] [Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance](https://arxiv.org/abs/2506.19698)
**中文标题：面向决策的预测性维护：一种集成估计优化的预测维护框架**

*Zhuojun Xie,Adam Abdin,Yiping Fang*

主要分类: cs.AI

摘要简述: 本文提出了一种集成估计优化（IEO）框架，用于预测性维护（PdM），通过联合调整预测模型并直接优化维护结果，减少预测误差对决策的影响，提升决策质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前预测性维护中，机器学习模型的不确定性限制了工业应用的广泛采用。传统估计-优化（ETO）框架中预测误差可能导致不一致和次优的维护决策，因此需要一种更稳健的方法。

研究方法: 提出集成估计优化（IEO）框架，联合优化预测模型和维护决策，开发了适用于小规模数据的随机扰动梯度下降算法。

研究结果: 在涡轮风扇维护案例中，IEO框架将平均维护遗憾降低高达22%，显著优于传统ETO框架。

研究结论: IEO框架通过将预测模型训练与维护目标对齐，提升了模型不确定性和决策质量，特别适用于决策策略与目标不一致的情况。

中文摘要: 近年来，机器学习（ML）在预测性维护（PdM）中的应用日益增多，以降低数据丰富的运营环境中的操作和维护成本。然而，模型不确定性限制了其工业应用的广泛采用。本文提出了一种PdM框架，其中传感器驱动的预测为有限决策空间内的经济权衡提供决策支持。我们研究了两个关键问题：（1）更高的预测准确性是否必然带来更好的维护决策？（2）如果不是，如何减轻预测误差对下游维护决策的影响？我们首先证明，在传统的估计-优化（ETO）框架中，概率预测的误差可能导致不一致和次优的维护决策。为解决这一问题，我们提出了集成估计优化（IEO）框架，联合调整预测模型并直接优化维护结果。我们在标准假设下建立了决策一致性的理论有限样本保证。具体而言，我们开发了一种适用于小规模运行至故障数据集的随机扰动梯度下降算法。在涡轮风扇维护案例的实证评估中，IEO框架将平均维护遗憾降低高达22%，优于ETO。本研究为管理数据驱动PdM中的预测误差提供了一种原则性方法。通过将预测模型训练与维护目标对齐，IEO框架提升了模型不确定性的稳健性并改善了决策质量。当决策策略与决策者目标不一致时，改进尤为显著。这些发现为不确定运营环境中的可靠维护规划提供了支持。

</details>


### [160] [LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis](https://arxiv.org/abs/2506.19702)
**中文标题：LLM驱动的医疗文档分析：提升可信赖的病理与鉴别诊断**

*Lei Kang,Xuanshuo Fu,Oriol Ramos Terrades,Javier Vazquez-Corral,Ernest Valveny,Dimosthenis Karatzas*

主要分类: cs.AI

摘要简述: 本文提出了一种基于LLaMA-v3的低秩自适应优化方法，用于构建可信赖的医疗文档分析平台，专注于病理预测和鉴别诊断任务，并在性能上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 医疗文档分析在提取临床关键信息中至关重要，但现有大型语言模型（LLMs）因隐私问题难以在临床环境中应用。本文旨在开发一种可信赖、可解释且保护隐私的AI解决方案。

研究方法: 通过低秩自适应（LoRA）微调LLaMA-v3模型，并使用DDXPlus（最大的鉴别诊断基准数据集）进行优化，开发了一个基于Web的平台，支持用户上传非结构化医疗文档并获取可解释的诊断结果。

研究结果: 该方法在病理预测和变长鉴别诊断任务中表现优于现有技术，并通过高级可解释性技术确保透明可靠的预测，提升了用户信任。

研究结论: 本文提出的方法在预测准确性和实用性上均超越现有模型，为真实医疗应用提供了可靠、可解释且隐私保护的AI解决方案。

中文摘要: 医疗文档分析在从非结构化医疗记录中提取关键临床信息方面起着至关重要的作用，支持诸如鉴别诊断等关键任务。确定重叠症状中最可能的病情需要精确评估和深厚的医学专业知识。尽管大型语言模型（LLMs）的最新进展显著提升了医疗文档分析的性能，但与敏感患者数据相关的隐私问题限制了在线LLMs服务在临床环境中的使用。为解决这些问题，我们提出了一种可信赖的医疗文档分析平台，通过低秩自适应（LoRA）微调LLaMA-v3模型，专门优化用于鉴别诊断任务。我们的方法利用DDXPlus（最大的鉴别诊断基准数据集），在病理预测和变长鉴别诊断任务中表现优于现有方法。开发的基于Web的平台允许用户提交非结构化医疗文档并获取准确、可解释的诊断结果。通过引入高级可解释性技术，系统确保了透明可靠的预测，增强了用户信任。广泛的评估证实，所提方法在预测准确性上超越了当前最先进的模型，同时在临床环境中具有实际应用价值。这项工作满足了可靠、可解释且保护隐私的人工智能解决方案的迫切需求，代表了智能医疗文档分析在真实医疗应用中的重大进展。代码可在以下链接找到：https://github.com/leitro/Differential-Diagnosis-LoRA。

</details>


### [161] [From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking](https://arxiv.org/abs/2506.19724)
**中文标题：从复制到重现：通过渐进式代码掩码评估研究代理**

*Gyeongwon James Kim,Alex Wilf,Louis-Philippe Morency,Daniel Fried*

主要分类: cs.AI

摘要简述: 本文介绍了AutoExperiment基准测试，用于评估AI代理在给定不同数量代码起点的情况下实现科学实验的能力，发现随着缺失代码量的增加，代理性能显著下降，并提出了动态交互环境的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏评估AI代理在从部分复制到完全重新实现代码的不同起点下实现科学实验能力的基准测试，因此需要开发一个能够填补这一空白的工具。

研究方法: 提出AutoExperiment基准测试，要求AI代理根据研究论文的自然语言描述生成缺失代码并运行实验，难度通过缺失函数数量$n$逐步增加。

研究结果: 实验表明，随着$n$增加，代理性能迅速下降；动态交互环境的代理表现优于固定环境代理，且单次尝试与多次尝试成功率存在显著差距。

研究结论: AutoExperiment为评估AI驱动的科学实验能力提供了新基准，揭示了长时程代码生成和自主实验执行中的关键挑战。

中文摘要: 近年来，自主代码生成的进展激发了人们对能够通过运行实验加速科学发现的AI代理的兴趣。然而，目前尚缺乏评估此类代理在给定不同数量代码起点时实现科学想法的基准测试，介于复制（运行代码）和从零开始重现（完全重新实现并运行代码）之间。我们提出了AutoExperiment，一个评估AI代理根据研究论文的自然语言描述实现和运行机器学习实验能力的基准测试。每个任务中，代理会获得一篇研究论文、一个关键函数被掩码的代码库以及运行实验的命令。目标是生成缺失代码，在沙盒环境中执行实验并重现结果。AutoExperiment通过缺失函数数量$n$的变化来调整难度，范围从部分复制到完全重现。我们评估了最先进的代理，发现随着$n$增加，性能迅速下降。能够动态与环境交互的代理（例如调试代码）表现优于固定“无代理”框架中的代理，且单次尝试与多次尝试成功率（Pass@1 vs. Pass@5）之间存在显著差距，这促使我们采用验证器方法。我们的发现突出了长时程代码生成、上下文检索和自主实验执行中的关键挑战，确立了AutoExperiment作为评估AI驱动科学实验进展的新基准。数据和代码已开源：https://github.com/j1mk1m/AutoExperiment。

</details>


### [162] [Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study](https://arxiv.org/abs/2506.19773)
**中文标题：知识图谱构建中的自动提示优化：一项实证研究的见解**

*Nandana Mihindukulasooriya,Niharika S. D'Souza,Faisal Chowdhury,Horst Samulowitz*

主要分类: cs.AI

摘要简述: 本文通过实证研究探讨了自动提示优化在知识图谱构建中的应用，发现自动优化的提示能够接近人工设计的水平，并在复杂模式和长文本中表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 知识图谱（KG）广泛应用于语义搜索、推理、决策等领域，但其构建中的三元组提取任务依赖人工设计的提示，效率低且易受模型变动影响。自动提示优化技术有望解决这一问题。

研究方法: 研究通过实验评估不同设置下的自动提示优化效果，包括提示策略、LLM选择、模式复杂度、文本长度与多样性、优化指标及数据集。评估了DSPy、APE和TextGrad三种优化器，并使用SynthIE和REBEL数据集。

研究结果: 自动提示优化技术能够生成接近人工设计的提示，并在模式复杂性和文本长度增加时表现更优，显著提升三元组提取效果。

研究结论: 自动提示优化技术为知识图谱构建提供了高效且可靠的提示生成方法，尤其在复杂任务中表现突出。

中文摘要: 知识图谱（KG）是由实体及其关系构成的网络，广泛应用于语义搜索、推理、决策、自然语言处理、机器学习和推荐系统等领域。三元组（主语-关系-宾语）提取是KG构建的基础任务，从早期基准如ACE 2002到近期如WebNLG 2020、REBEL和SynthIE均有研究。尽管大型语言模型（LLM）被用于KG构建，但手工设计任务特定提示费时且易受模型变动影响。近期NLP任务（如自动生成）通过自动提示优化技术生成最优或接近最优的提示来解决这一问题。

本实证研究通过实验评估自动提示优化在三元组提取任务中的应用。我们评估了不同设置，包括提示策略、LLM选择、模式复杂度、文本长度与多样性、优化指标及数据集。评估了三种自动提示优化器（DSPy、APE和TextGrad）及两个三元组提取数据集（SynthIE和REBEL）。通过严格的实证评估，我们发现自动提示优化技术能够生成接近人工设计的提示，并在模式复杂性和文本长度增加时表现更优。

</details>


### [163] [SAGE: Strategy-Adaptive Generation Engine for Query Rewriting](https://arxiv.org/abs/2506.19783)
**中文标题：SAGE：策略自适应生成引擎用于查询重写**

*Teng Wang,Hailei Gong,Changwang Zhang,Jun Wang*

主要分类: cs.AI

摘要简述: 本文提出了一种策略自适应生成引擎（SAGE），通过专家策略引导大型语言模型（LLM）优化查询重写，结合强化学习（RL）和新型奖励机制，显著提升了检索效果并降低了推理成本。


<details>
  <summary>详细信息</summary>
研究动机: 当前查询重写方法依赖大规模监督数据或强化学习探索效率低下，无法有效提升密集检索性能。本文旨在通过专家策略引导LLM，结合强化学习框架，解决这一问题。

研究方法: 提出策略自适应生成引擎（SAGE），将专家策略（如语义扩展和实体消歧）融入强化学习框架，并引入两种新型奖励机制：战略信用塑造（SCS）和对比奖励塑造（CRS），以提供更有效的学习信号。

研究结果: SAGE在HotpotQA、FEVER等基准测试中取得新的最佳NDCG@10结果，同时发现代理学会选择最优策略，减少不必要探索，生成简洁重写，降低推理成本而不牺牲性能。

研究结论: 研究表明，结合专家策略和精细奖励塑造的强化学习为开发下一代稳健信息检索系统提供了可扩展、高效且更可解释的范式。

中文摘要: 查询重写对提升密集检索至关重要，但现有方法需要大规模监督数据或强化学习探索效率低下。本文首先证明，通过专家策略（如语义扩展和实体消歧）引导大型语言模型（LLM），可显著提升HotpotQA、FEVER等基准测试的检索效果。基于此，我们提出策略自适应生成引擎（SAGE），将这些策略融入强化学习框架，并引入两种新型奖励机制：战略信用塑造（SCS）和对比奖励塑造（CRS），以提供更有效的学习信号。这种策略引导方法不仅实现了新的最佳NDCG@10结果，还发现代理学会选择最优策略，减少不必要探索，生成简洁重写，降低推理成本而不牺牲性能。研究表明，结合精细奖励塑造的策略引导强化学习为开发下一代稳健信息检索系统提供了可扩展、高效且更可解释的范式。

</details>


### [164] [Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning](https://arxiv.org/abs/2506.19785)
**中文标题：基于潜在动态的任务信念相似性学习用于元强化学习**

*Menglong Zhang,Fuyuan Qian*

主要分类: cs.AI

摘要简述: 本文提出SimBelief框架，通过测量任务信念相似性改进元强化学习，在稀疏奖励环境中实现高效任务识别与探索。


<details>
  <summary>详细信息</summary>
研究动机: 元强化学习需要利用先验任务分布信息快速适应未知任务，但现有方法在稀疏奖励环境中难以准确识别任务，导致探索效率低下。

研究方法: 提出SimBelief框架，通过潜在任务信念度量学习相似任务的共同结构，并将其与特定任务信念结合，利用潜在动态连接共享特征与任务特征。

研究结果: SimBelief在稀疏奖励的MuJoCo和panda-gym任务中优于现有基线方法。

研究结论: SimBelief通过任务信念相似性度量显著提升了元强化学习在稀疏奖励环境中的任务识别与适应能力。

中文摘要: 元强化学习需要利用探索中获得的先验任务分布信息快速适应未知任务。代理探索的效率依赖于准确识别当前任务。最近的贝叶斯自适应深度强化学习方法通常依赖于重建环境的奖励信号，这在稀疏奖励环境中具有挑战性，导致次优利用。受双模拟度量的启发，该方法在连续马尔可夫决策过程中稳健地提取行为相似性，我们提出了SimBelief——一种通过测量贝叶斯自适应马尔可夫决策过程（BAMDP）中任务信念相似性的新型元强化学习框架。SimBelief有效提取相似任务分布的共同特征，实现稀疏奖励环境中的高效任务识别与探索。我们引入潜在任务信念度量来学习相似任务的共同结构，并将其融入特定任务信念中。通过学习任务分布间的潜在动态，我们将共享的潜在任务信念特征与特定任务特征连接起来，促进快速任务识别与适应。我们的方法在稀疏奖励的MuJoCo和panda-gym任务上优于现有基线方法。

</details>


### [165] [KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality](https://arxiv.org/abs/2506.19807)
**中文标题：KnowRL：探索基于知识的强化学习以提升事实性**

*Baochang Ren,Shuofei Qiao,Wenhao Yu,Huajun Chen,Ningyu Zhang*

主要分类: cs.AI

摘要简述: KnowRL通过将基于知识验证的事实性奖励整合到强化学习训练中，有效减少大型语言模型（LLMs）的幻觉问题，同时保持其推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（尤其是慢思考模型）常因无法准确识别知识边界而产生严重幻觉，输出错误内容。强化学习虽能提升推理能力，但其结果导向的奖励机制缺乏对思考过程的事实性监督，加剧了幻觉问题。

研究方法: 提出KnowRL方法，将基于知识验证的事实性奖励引入强化学习训练，指导模型进行基于事实的慢思考，帮助其识别知识边界。

研究结果: 在三个幻觉评估数据集和两个推理评估数据集上的实验表明，KnowRL显著减少了慢思考模型的幻觉，同时保持了其原有的强推理能力。

研究结论: KnowRL通过事实性奖励机制有效解决了慢思考模型的幻觉问题，同时未损害其推理性能，为提升模型可靠性提供了新思路。

中文摘要: 大型语言模型（LLMs），尤其是慢思考模型，常因无法准确识别知识边界而产生严重幻觉，输出错误内容。尽管强化学习（RL）可以增强复杂推理能力，但其结果导向的奖励机制缺乏对思考过程的事实性监督，进一步加剧了幻觉问题。为解决慢思考模型的高幻觉问题，我们提出知识增强的强化学习方法KnowRL。KnowRL通过将基于知识验证的事实性奖励整合到RL训练中，指导模型进行基于事实的慢思考，帮助其识别知识边界。这种有针对性的RL训练使模型能够学习并内化基于事实的推理策略。通过直接在推理步骤中奖励对事实的遵循，KnowRL促进了更可靠的思考过程。在三个幻觉评估数据集和两个推理评估数据集上的实验结果表明，KnowRL有效减少了慢思考模型的幻觉，同时保持了其原有的强推理能力。我们的代码可在https://github.com/zjunlp/KnowRL获取。

</details>


### [166] [Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models](https://arxiv.org/abs/2506.19825)
**中文标题：利用大型视觉语言模型评估科学出版物中图表的可视化指南符合性**

*Johannes Rückert,Louise Bloch,Christoph M. Friedrich*

主要分类: cs.AI

摘要简述: 本研究利用大型视觉语言模型（VLMs）自动评估科学出版物中的图表是否符合数据可视化指南，发现VLMs能有效识别图表类型、3D效果等问题，但在图像质量和刻度标记方面表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 科学出版物中的图表常因未遵循数据可视化指南而导致信息不准确或不完整。本研究旨在利用VLMs自动检测图表中的潜在问题，以提升图表质量。

研究方法: 研究比较了五种开源VLMs和五种提示策略，通过基于数据可视化指南的问题集评估VLMs在图表分析中的表现。

研究结果: VLMs在识别图表类型（F1-score 82.49%）、3D效果（F1-score 98.55%）等方面表现良好，但在图像质量（F1-score 0.74%）和刻度标记（F1-score 46.13%）方面表现较差。Qwen2.5VL模型和总结提示策略表现最佳。

研究结论: VLMs可用于自动检测图表中的潜在问题，如缺失坐标轴标签、图例或不必要的3D效果。该方法可进一步扩展以涵盖更多数据可视化问题。

中文摘要: 图表在科学出版物中被广泛用于数据可视化。数据可视化研究领域致力于定义图表的创建和使用原则，但这些原则常被研究者忽视或未遵循，导致因提供不准确或不完整信息而产生误导。本研究利用大型视觉语言模型（VLMs）分析图表，以识别其与选定数据可视化原则和指南的潜在问题。为评估VLMs在此任务中的适用性，研究比较了五种开源VLMs和五种提示策略，使用基于数据可视化指南的问题集进行测试。结果显示，VLMs在分析图表类型（F1-score 82.49%）、3D效果（F1-score 98.55%）、坐标轴标签（F1-score 76.74%）、线条（RMSE 1.16）、颜色（RMSE 1.60）和图例（F1-score 96.64%，RMSE 0.70）方面表现良好，但在图像质量（F1-score 0.74%）和刻度标记/标签（F1-score 46.13%）方面表现不佳。在测试的VLMs中，Qwen2.5VL表现最佳，而总结提示策略在多数实验问题中表现最优。研究表明，VLMs可用于自动识别图表中的多种潜在问题，如缺失坐标轴标签、图例或不必要的3D效果。本研究的方法可进一步扩展以涵盖更多数据可视化问题。

</details>


### [167] [Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning](https://arxiv.org/abs/2506.19843)
**中文标题：Temporal-IRL：基于逆向强化学习的港口拥堵与泊位调度建模**

*Guo Li,Zixiang Xu,Wei Zhang,Yikuan Hu,Xinyu Yang,Nikolay Aristov,Mingjie Tang,Elenna R Dugundji*

主要分类: cs.AI

摘要简述: 本文提出了一种名为Temporal-IRL的模型，通过逆向强化学习分析港口拥堵和泊位调度问题，利用历史AIS数据预测船舶停留时间，优化供应链管理。


<details>
  <summary>详细信息</summary>
研究动机: 港口拥堵预测对全球供应链的可靠性至关重要。准确的预测可以优化船舶调度、减少延误和成本，并提高供应链的韧性。因此，研究船舶行为和泊位调度模式具有重要意义。

研究方法: 通过分析历史AIS数据，重建泊位调度计划，并利用逆向强化学习（IRL）确定奖励函数。研究以纽约/新泽西港的Maher Terminal为例，开发了Temporal-IRL模型，预测船舶序列和停留时间。

研究结果: 使用2015年1月至2023年9月的数据训练和测试模型，取得了显著的效果，能够准确预测港口拥堵情况。

研究结论: Temporal-IRL模型通过学习泊位调度模式，有效预测船舶停留时间和港口拥堵，为供应链管理提供了有力工具。

中文摘要: 预测港口拥堵对维持全球供应链的可靠性至关重要。准确的预测可以优化运输计划、减少延误和成本，并优化库存和分销策略，从而确保及时交付并增强供应链韧性。为实现准确预测，需分析船舶行为及其在特定港口的停留时间，重点关注不同条件下的泊位调度。模型必须捕捉并学习泊位调度的优先级和模式。泊位调度受多种因素影响，包括船舶大小、等待时间及港口内船舶状态。通过观察历史AIS数据，我们重建泊位调度计划，并利用逆向强化学习（IRL）确定奖励函数。为此，我们以纽约/新泽西港的Maher Terminal为例，开发了Temporal-IRL模型。该模型通过学习泊位调度，预测船舶在港口的序列和停留时间（包括等待和泊位时间），从而预测港口拥堵。使用2015年1月至2023年9月的数据训练和测试模型，取得了显著效果。

</details>


### [168] [JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning](https://arxiv.org/abs/2506.19846)
**中文标题：JoyAgents-R1：基于强化学习的多LLM智能体联合进化动力学**

*Ai Han,Junxing Hu,Pu Wei,Zhiqian Zhang,Yuhang Guo,Jiawei Lu,Zicheng Zhang*

主要分类: cs.AI

摘要简述: JoyAgents-R1提出了一种基于联合进化动力学的多智能体强化学习方法，通过GRPO优化异构智能体的联合训练，提升决策与记忆能力，实验证明其性能接近更大规模的LLM。


<details>
  <summary>详细信息</summary>
研究动机: 当前多智能体强化学习中，异构智能体的联合进化存在合作效率低和训练不稳定的问题，亟需一种高效且稳定的方法。

研究方法: JoyAgents-R1采用GRPO进行异构多智能体的联合训练，通过节点级蒙特卡洛采样提升采样效率，利用边际效益驱动选择策略优化模型更新，并引入自适应记忆进化机制加速收敛。

研究结果: 实验表明，JoyAgents-R1在通用和领域特定场景中表现优异，性能接近更大规模的LLM，同时基于较小的开源模型实现。

研究结论: JoyAgents-R1通过联合进化动力学和GRPO优化，显著提升了异构多智能体的训练效率和稳定性，为复杂任务提供了高效解决方案。

中文摘要: 多智能体强化学习（MARL）已成为处理日益复杂任务的重要范式。然而，由于合作效率低和训练不稳定，异构智能体的联合进化仍具挑战性。本文提出了一种名为JoyAgents-R1的联合进化动力学方法，首次将组相对策略优化（GRPO）应用于异构多智能体的联合训练。通过迭代优化智能体的大型语言模型（LLMs）和记忆，该方法实现了决策能力和记忆能力的整体平衡。具体而言，JoyAgents-R1首先对每个智能体在整个推理轨迹上的行为进行节点级蒙特卡洛采样，以提高GRPO的采样效率并保持策略多样性。随后，基于边际效益的选择策略识别出奖励波动最大的前K个采样组，通过有针对性的模型更新提升训练稳定性，并通过低成本参数调整最大化联合效益。同时，JoyAgents-R1引入了一种自适应记忆进化机制，将GRPO奖励重新用作无监督信号，消除重复推理并加速收敛。在通用和领域特定场景中的实验表明，JoyAgents-R1的性能接近更大规模的LLM，同时基于较小的开源模型实现。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [169] [From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data](https://arxiv.org/abs/2506.19358)
**中文标题：从高信噪比雷达信号到心电图：一种基于心脏聚焦算法和迁移学习的有限数据场景模型**

*Yuanyuan Zhang,Haocheng Zhao,Sijie Xiong,Rui Yang,Eng Gee Lim,Yutao Yue*

主要分类: eess.SP

摘要简述: 本文提出一种基于雷达信号的心电图（ECG）恢复方法，针对数据稀缺的新场景，通过心脏聚焦跟踪算法（CFT）和迁移学习模型（RFcardi）实现高效ECG恢复。


<details>
  <summary>详细信息</summary>
研究动机: 现有雷达信号恢复ECG的方法依赖高质量信号和大量训练数据，限制了在新场景中的应用。本文旨在解决数据稀缺场景下的ECG恢复问题。

研究方法: 提出心脏聚焦跟踪算法（CFT）动态定位心脏位置，确保高质量雷达信号采集；设计迁移学习模型（RFcardi）从雷达信号中提取心脏特征，仅需少量雷达-ECG配对数据微调模型。

研究结果: 实验表明，CFT能动态识别心脏位置，RFcardi模型通过少量训练数据即可生成准确的ECG恢复结果。

研究结论: 本文方法在数据稀缺场景下有效实现了雷达信号到ECG的恢复，为实际应用提供了可行方案。

中文摘要: 心电图（ECG）作为一种关键的心脏精细特征，已成功从雷达信号中恢复，但其性能依赖于高质量雷达信号和大量雷达-ECG配对训练数据，限制了在新场景中的应用。因此，本文聚焦于数据稀缺场景下的雷达信号ECG恢复，提出心脏聚焦跟踪（CFT）算法，动态定位心脏位置以确保高质量信号采集。此外，基于心脏特征的稀疏性，提出迁移学习模型（RFcardi），无需ECG真实标签即可从雷达信号中提取心脏信息，仅需少量同步雷达-ECG配对数据微调预训练模型即可实现ECG恢复。实验结果表明，CFT能动态识别心脏位置，RFcardi模型通过少量训练数据即可生成准确的ECG恢复结果。代码和数据集将在发表后公开。

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [170] [Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications](https://arxiv.org/abs/2506.19491)
**中文标题：小型无人机应用中神经3D重建的实验评估**

*Genís Castillo Gómez-Raya,Álmos Veres-Vitályos,Filip Lemic,Pablo Royo,Mario Montagud,Sergi Fernández,Sergi Abadal,Xavier Costa-Pérez*

主要分类: cs.ET

摘要简述: 本文提出了一种结合神经3D重建（N3DR）与小型无人机系统的方法，用于精细3D数字重建小型静态物体，显著提升了重建质量，适用于受限环境中的高精度3D映射和异常检测。


<details>
  <summary>详细信息</summary>
研究动机: 随着无人机（UAV）的小型化，其在室内和难以到达区域的部署潜力增加，但也带来了飞行动态和功耗等挑战，限制了无人机的自主性和任务能力。本文旨在通过N3DR技术克服这些限制，提升小型无人机在3D重建中的表现。

研究方法: 设计、实现并评估了一种基于N3DR的流程，利用Instant-ngp、Nerfacto和Splatfacto等先进模型，通过小型无人机拍摄的图像提升3D重建质量，并与传统的运动结构（SfM）算法进行对比。

研究结果: 实验结果表明，N3DR增强的流程显著提高了重建质量，使小型无人机能够在受限环境中支持高精度3D映射和异常检测。

研究结论: 研究结果突显了N3DR在提升小型无人机系统能力方面的潜力，为未来相关应用提供了重要参考。

中文摘要: 无人机（UAV）的日益小型化扩展了其在室内和难以到达区域的部署潜力。然而，这一趋势也带来了独特的挑战，特别是在飞行动态和功耗方面，限制了无人机的自主性和任务能力。本文提出了一种新颖的方法，通过将神经3D重建（N3DR）与小型无人机系统结合，实现对小型静态物体的精细3D数字重建。具体而言，我们设计、实现并评估了一种基于N3DR的流程，利用Instant-ngp、Nerfacto和Splatfacto等先进模型，通过小型无人机拍摄的图像提升3D重建质量。我们使用多种图像和点云指标评估了这些模型的性能，并将其与传统的运动结构（SfM）算法进行了对比。实验结果表明，N3DR增强的流程显著提高了重建质量，使小型无人机能够在受限环境中支持高精度3D映射和异常检测。更广泛地说，我们的结果突显了N3DR在提升小型无人机系统能力方面的潜力。

</details>


### [171] [The receptron is a nonlinear threshold logic gate with intrinsic multi-dimensional selective capabilities for analog inputs](https://arxiv.org/abs/2506.19642)
**中文标题：receptron是一种具有固有多维选择性能力的非线性阈值逻辑门，适用于模拟输入**

*B. Paroli,F. Borghi,M. A. C. Potenza,P. Milani*

主要分类: cs.ET

摘要简述: 本文提出了一种称为“receptron”的非线性阈值逻辑门，通过输入依赖的权重函数显著提升了分类性能，并展示了其在多维模拟输入中的选择性激活特性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的阈值逻辑门（TLG）由于线性限制，需要依赖网络完成复杂任务。本文旨在通过引入非线性输入依赖权重函数的receptron模型，提升单单元的分类能力，解决复杂任务的需求。

研究方法: 提出了一种称为receptron的模型，其特点是具有非线性输入依赖的权重函数。通过理论证明，该模型在3D空间中的立方域内对模拟输入具有选择性激活特性，并可扩展到多维应用。

研究结果: 研究表明，receptron在单单元情况下即可显著提升分类性能，并在多维模拟输入中表现出选择性激活特性。

研究结论: receptron模型为边缘应用中需要高选择性和分类能力的设备提供了新的可能性，无需复杂训练即可管理大量模拟输入。

中文摘要: 阈值逻辑门（TLG）被提出作为生物神经元的仿生模型，其分类能力基于线性预测函数对权重和特征向量的组合。TLG的线性特性限制了其分类能力，需要依赖网络完成复杂任务。本文提出了一种称为receptron的TLG模型扩展，其特点是具有输入依赖的权重函数，显著提升了单单元的分类性能。我们通过理论证明，当输入向量位于3D空间的立方域内时，具有非线性输入依赖权重函数的receptron表现出对模拟输入的固有选择性激活特性。该模型可扩展到多维应用。研究结果表明，基于receptron的网络可以成为一类新型设备，能够在无需复杂训练的情况下，管理大量模拟输入，适用于需要高选择性和分类能力的边缘应用。

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [172] [eccDNAMamba: A Pre-Trained Model for Ultra-Long eccDNA Sequence Analysis](https://arxiv.org/abs/2506.18940)
**中文标题：eccDNAMamba：一种用于超长环状eccDNA序列分析的预训练模型**

*Zhenke Liu,Jien Li,Ziqi Zhang*

主要分类: q-bio.GN

摘要简述: eccDNAMamba是首个针对超长环状eccDNA序列分析的双向状态空间编码器，通过线性时间复杂度和新颖的数据增强策略，实现了高效的全长环状DNA建模，并在真实数据集上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 目前缺乏支持全长环状eccDNA分析的预训练模型，现有基因组模型要么分辨率有限，要么因二次注意力机制效率低下而受限。eccDNAMamba旨在填补这一空白，提供高效且准确的环状DNA序列分析工具。

研究方法: eccDNAMamba结合正向和反向传递的全上下文表示学习，采用线性时间复杂度的双向状态空间编码器，并通过新颖的数据增强策略保留环状结构。

研究结果: 在真实数据集上测试，eccDNAMamba表现出强大的分类性能，并能处理长达200 Kbp的序列，为环状基因组建模提供了高效框架。

研究结论: eccDNAMamba为环状eccDNA分析提供了首个高效且准确的预训练模型，填补了现有技术的空白，并展示了在长序列分析中的潜力。

中文摘要: 环状染色体外DNA（eccDNA）通过高拷贝扩增和远距离相互作用在癌症中发挥关键调控作用并促进癌基因过表达。尽管建模技术有所进展，但目前尚无预训练模型支持全长环状eccDNA的下游分析。现有基因组模型要么局限于单核苷酸分辨率，要么因二次注意力机制的低效性而受限。本文提出eccDNAMamba，这是首个专为环状DNA序列设计的双向状态空间编码器。它结合正向和反向传递的全上下文表示学习，具有线性时间复杂度，并通过新颖的数据增强策略保留环状结构。在两个真实数据集上测试，eccDNAMamba表现出强大的分类性能，并能扩展到长达200 Kbp的序列，为环状基因组建模提供了高效且稳健的框架。代码可在https://github.com/zzq1zh/GenAI-Lab获取。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [173] [Improving Student-AI Interaction Through Pedagogical Prompting: An Example in Computer Science Education](https://arxiv.org/abs/2506.19107)
**中文标题：通过教学提示改善学生与AI的互动：以计算机科学教育为例**

*Ruiwei Xiao,Xinying Hou,Runlong Ye,Majeed Kazemitabaar,Nicholas Diana,Michael Liut,John Stamper*

主要分类: cs.HC

摘要简述: 本文提出了一种名为‘教学提示’的新概念，旨在帮助学生更有效地与大型语言模型（LLM）互动以提升学习效果。通过调查教师需求和设计交互式学习系统，研究证明该方法显著提升了学生的LLM帮助寻求能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在教育中的应用日益广泛，学生对其的（误）使用可能影响学习效果。本研究旨在通过‘教学提示’这一理论框架，帮助学生更有效地利用LLM提升学习成果。

研究方法: 研究首先通过调查36名CS课程教师的需求，设计了基于场景教学的交互式学习系统。随后，通过22名CS初学者的前/后测实验，评估了该系统的教学效果。

研究结果: 结果显示，学生的LLM帮助寻求能力显著提升，对系统持积极态度，并更愿意在未来使用教学提示。研究还提供了教学提示的理论框架和教师态度的实证数据。

研究结论: 研究证明了教学提示在提升学生LLM互动能力方面的有效性，并展示了其在课堂中的可扩展性，未来可集成到ChatGPT等工具中。

中文摘要: 自2022年以来，大型语言模型（LLM）的应用激增，其在教育中的使用引发了兴奋与担忧。近期研究一致表明，学生对LLM的（误）使用可能阻碍学习效果。本研究旨在教会学生如何有效地提示LLM以提升学习。我们首先提出了‘教学提示’这一理论支持的新概念，以引导LLM生成有助于学习的回答。为了将概念设计转化为实际教育环境中的学习干预，我们选择了早期本科CS教育（CS1/CS2）作为示例场景。通过一项针对36名CS课程教师的调查，我们了解了课堂需求并据此设计了教学方案。基于这些见解，我们开发了一个交互式系统，通过场景教学训练学生的教学提示技能。最后，我们通过22名CS初学者的前/后测实验评估了其教学效果。混合方法分析表明，学习者的LLM帮助寻求能力显著提升，对系统持积极态度，并更愿意在未来使用教学提示。我们的贡献包括：（1）教学提示的理论框架；（2）教师对教学提示态度的实证数据；（3）基于交互式学习工具和场景教学的学习干预设计，其教学效果显著。该方法可扩展至更广泛的课堂应用，并有望集成到ChatGPT等工具中，作为鼓励生成式AI学习导向使用的入门体验。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [174] [MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications](https://arxiv.org/abs/2506.19502)
**中文标题：MATE：基于大语言模型的多代理翻译环境在无障碍应用中的研究**

*Aleksandr Algazinov,Matt Laing,Paul Laban*

主要分类: cs.MA

摘要简述: 本文提出了一种名为MATE的多模态无障碍多代理系统，通过用户需求驱动的模态转换，帮助残障人士无障碍使用数字环境。系统支持多种模型，确保隐私安全，并引入ModCon-Task-Identifier模型以提升任务识别精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前多代理系统因封闭设计缺乏定制化能力，无法全面满足残障人士需求，导致其在数字环境中面临障碍。本文旨在通过MATE系统解决这一问题。

研究方法: MATE系统基于用户需求进行模态转换（如图像转音频描述），支持从LLM API调用到自定义ML分类器的多种模型，并引入ModCon-Task-Identifier模型精确提取用户输入的任务。

研究结果: 实验表明，ModCon-Task-Identifier模型在自定义数据上表现优于其他LLM和统计模型，MATE系统在隐私安全和实时辅助方面表现优异。

研究结论: MATE系统为残障人士提供了灵活、安全的无障碍解决方案，适用于医疗等多个领域，其任务识别模型显著提升了系统性能。

中文摘要: 无障碍性在当今社会仍是一个关键问题，许多技术未能全面支持用户需求。现有多代理系统（MAS）因封闭设计缺乏定制化能力，无法为有需求的用户提供全面帮助，导致残障人士在数字环境中面临显著障碍。我们提出MATE，一种多模态无障碍MAS，根据用户需求进行模态转换。该系统通过将数据转换为可理解格式（如图像转音频描述），帮助残障人士无障碍使用技术。MATE适用于医疗等多个领域，支持从LLM API调用到自定义机器学习分类器的多种模型，确保灵活性和硬件兼容性。系统本地运行保障隐私安全，并可集成至机构技术（如数字医疗服务）中提供实时辅助。此外，我们提出ModCon-Task-Identifier模型，能够从用户输入中精确提取模态转换任务。实验表明，该模型在自定义数据上表现优于其他LLM和统计模型。代码与数据公开于https://github.com/AlgazinovAleksandr/Multi-Agent-MATE。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [175] [SOF: Sorted Opacity Fields for Fast Unbounded Surface Reconstruction](https://arxiv.org/abs/2506.19139)
**中文标题：SOF：基于排序不透明度场的快速无边界表面重建**

*Lukas Radl,Felix Windisch,Thomas Deixelberger,Jozef Hladky,Michael Steiner,Dieter Schmalstieg,Markus Steinberger*

主要分类: cs.GR

摘要简述: 本文提出了一种名为SOF（Sorted Opacity Fields）的方法，用于从3D高斯表示中快速且精确地重建无边界场景的详细表面。通过引入分层重排序和鲁棒的高斯深度公式，结合水平集正则化和几何一致性损失，显著提升了重建质量和速度。


<details>
  <summary>详细信息</summary>
研究动机: 尽管3D高斯表示在图像场景重建中取得了显著进展，但在大规模无边界环境中提取精确表面仍具挑战性。现有方法依赖近似深度估计和全局排序启发式，易引入伪影并限制网格保真度。因此，需要一种既能保持高效性又能提升重建精度的方法。

研究方法: SOF方法通过分层重排序和鲁棒的高斯深度公式改进表面重建，同时引入水平集正则化和几何一致性损失优化网格质量。此外，开发了并行化的Marching Tetrahedra算法，显著缩短了网格生成时间。

研究结果: 实验表明，SOF在重建精度上优于现有方法，并将总处理时间减少了三倍以上。

研究结论: SOF通过改进的高斯表示和高效网格生成算法，为基于高斯的几何提取提供了更高效且精确的解决方案。

中文摘要: 近年来，3D高斯表示在基于图像的场景重建中显著提升了质量和效率。其显式特性便于实时渲染和快速优化，但在大规模无边界环境中提取精确表面仍具挑战性。现有方法多依赖近似深度估计和全局排序启发式，易引入伪影并限制网格保真度。本文提出排序不透明度场（SOF），旨在从3D高斯中快速且精确地恢复详细表面。通过引入分层重排序和鲁棒的高斯深度公式，SOF改进了现有方法，更好地与水平集对齐。为提升网格质量，我们在不透明度场中引入水平集正则化，并设计损失函数以鼓励几何一致的基元形状。此外，开发了针对不透明度场的并行化Marching Tetrahedra算法，将网格生成时间缩短至十分之一。定量评估表明，SOF在重建精度上表现更优，同时将总处理时间减少三倍以上。这些成果标志着将高效基于高斯的渲染转化为同等高效几何提取的重要进展。

</details>


### [176] [Virtual Memory for 3D Gaussian Splatting](https://arxiv.org/abs/2506.19415)
**中文标题：3D高斯泼溅的虚拟内存技术**

*Jonathan Haberl,Philipp Fleck,Clemens Arth*

主要分类: cs.GR

摘要简述: 本文提出了一种利用虚拟内存技术渲染大规模3D高斯泼溅场景的方法，通过动态加载可见高斯元素，显著降低内存占用并提升渲染速度。


<details>
  <summary>详细信息</summary>
研究动机: 随着3D高斯泼溅技术在新型视图合成领域的突破，场景规模不断扩大，但传统方法在内存占用和渲染效率上面临挑战。本文旨在解决大规模复杂场景的实时渲染问题。

研究方法: 结合虚拟内存和虚拟纹理技术，动态识别并加载可见的高斯元素到GPU，仅存储和渲染必要的高斯元素，同时引入细节层次技术以进一步提升大规模场景的渲染速度。

研究结果: 实验表明，该方法显著降低了内存占用，加速了渲染过程，尤其在复杂场景中表现优异，并在桌面和移动设备上进行了全面评估。

研究结论: 本文提出的虚拟内存方法有效解决了大规模3D高斯泼溅场景的渲染问题，通过动态加载和细节层次优化，实现了高效且实时的渲染效果。

中文摘要: 3D高斯泼溅技术是新型视图合成领域的一项突破性进展，它将高斯分布作为核心渲染基元，实现了高精度的真实环境重建。近年来，可创建的场景规模大幅增加。本文提出了一种利用虚拟内存渲染大规模复杂3D高斯泼溅场景的方法。通过成熟的虚拟内存和虚拟纹理技术，我们的方法能够高效识别可见高斯元素，并动态将其流式传输到GPU，实现实时渲染。仅选择和存储必要的高斯元素，显著降低了内存占用并加速了渲染过程，尤其适用于高度复杂的场景。此外，我们还展示了如何将细节层次技术集成到所提方法中，以进一步提升大规模场景的渲染速度。通过优化实现，我们重点分析了关键的实际考量，并在桌面和移动设备上全面评估了所提技术及其影响。

</details>


### [177] [Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders](https://arxiv.org/abs/2506.19708)
**中文标题：利用稀疏自编码器揭示生成图像模型中的概念盲点**

*Matyas Bohacek,Thomas Fel,Maneesh Agrawala,Ekdeep Singh Lubana*

主要分类: cs.GR

摘要简述: 本文提出了一种系统性方法，利用稀疏自编码器（SAE）识别生成图像模型中的概念盲点，揭示了模型在生成图像时忽略或过度表现某些概念的现象。


<details>
  <summary>详细信息</summary>
研究动机: 尽管生成图像模型在大规模数据集上表现优异，但仍无法生成一些看似简单的概念（如人手或四件一组的物体）。这些失败模式通常被零散记录，无法确定是偶然异常还是模型的结构性局限。本文旨在系统性识别和量化这些概念盲点。

研究方法: 通过稀疏自编码器（SAE）提取可解释的概念嵌入，量化比较真实图像与生成图像中概念的差异。训练了一个包含32,000个概念的RA-SAE模型，对四种流行生成模型（Stable Diffusion 1.5/2.1、PixArt和Kandinsky）进行分析。

研究结果: 研究发现模型存在特定被抑制的盲点（如鸟食器、DVD光盘和文档空白）和过度表现的盲点（如木质背景纹理和棕榈树）。此外，还识别出模型对训练数据中特定视觉模板的复制现象。

研究结论: 本文提出了一个理论框架，通过评估生成模型与数据生成过程的概念保真度，系统性识别概念盲点，为改进生成模型提供了新思路。

中文摘要: 尽管生成图像模型在大规模数据集上表现优异，但仍经常无法生成一些看似简单的概念（如人手或四件一组的物体），而这些概念理应出现在训练数据中。这些失败模式通常被零散记录，无法确定是偶然异常还是模型的结构性局限。为此，我们提出了一种系统性方法，用于识别和量化“概念盲点”——即在训练数据中存在但在模型生成中缺失或错误表现的概念。我们的方法利用稀疏自编码器（SAE）提取可解释的概念嵌入，从而量化比较真实图像与生成图像中概念的差异。我们训练了一个包含32,000个概念的RA-SAE模型，这是目前规模最大的此类模型，能够对概念差异进行精细分析。将此方法应用于四种流行生成模型（Stable Diffusion 1.5/2.1、PixArt和Kandinsky），我们揭示了特定被抑制的盲点（如鸟食器、DVD光盘和文档空白）和过度表现的盲点（如木质背景纹理和棕榈树）。在单个数据点层面，我们还分离出了记忆效应——即模型复制训练中高度特定视觉模板的现象。总体而言，我们提出了一个理论框架，通过评估生成模型与数据生成过程的概念保真度，系统性识别概念盲点。

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [178] [Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives](https://arxiv.org/abs/2506.19025)
**中文标题：最优传输映射的统计推断：最新进展与展望**

*Sivaraman Balakrishnan,Tudor Manole,Larry Wasserman*

主要分类: math.ST

摘要简述: 本文综述了最优传输（OT）映射的最新研究进展，重点讨论了从样本中估计OT映射及其极限定理的方法，并探讨了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 最优传输映射在许多应用中至关重要，但如何从样本中可靠地估计OT映射及其统计性质仍是一个挑战。本文旨在总结相关进展，并为实践者提供可靠的推断工具。

研究方法: 本文回顾了从样本中估计OT映射的最新方法，包括极限定理的建立，并讨论了OT基本框架的特殊情况和变体。

研究结果: 总结了OT映射估计的最新成果，包括样本推断的理论基础及其在不同场景下的应用。

研究结论: 未来研究应进一步开发可靠的推断工具，以支持OT映射在实际应用中的广泛使用。

中文摘要: 在许多最优传输（OT）应用中，主要关注的对象是最优传输映射。该映射通过最小化指定成本，以最有效的方式将质量从一个概率分布重新分配到另一个概率分布。本文回顾了从基础分布样本中估计OT映射和建立其极限定理的最新进展，并总结了针对OT基本框架的特殊情况和变体的类似结果。最后，我们讨论了未来研究的关键方向，旨在为实践者提供可靠的推断工具。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [179] [A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects](https://arxiv.org/abs/2506.19769)
**中文标题：具身AI中多传感器融合感知综述：背景、方法、挑战与前景**

*Shulan Ruan,Rongwei Wang,Xuchen Shen,Huijie Liu,Baihui Xiao,Jun Shi,Kun Zhang,Zhenya Huang,Yu Liu,Enhong Chen,You He*

主要分类: cs.MM

摘要简述: 本文综述了多传感器融合感知（MSFP）在具身AI中的研究背景、方法、挑战与前景，旨在从任务无关的角度组织现有研究，弥补现有综述的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有关于多传感器融合感知的综述多局限于单一任务或研究领域（如3D目标检测或自动驾驶），且仅从多模态融合的单一视角介绍，缺乏对方法多样性的考虑。本文旨在从任务无关的角度全面梳理MSFP研究，填补这一空白。

研究方法: 本文首先介绍MSFP的背景，随后从多模态融合、多智能体融合、时间序列融合以及多模态大语言模型融合等多个技术视角综述现有方法。

研究结果: 本文系统梳理了MSFP的多种技术方法，并探讨了当前研究的开放挑战与未来方向。

研究结论: 本文为研究者提供了MSFP领域的重要进展概览，并为未来研究提供了可能的启示。

中文摘要: 多传感器融合感知（MSFP）是具身AI的一项关键技术，可为多种下游任务（如3D目标检测和语义分割）和应用场景（如自动驾驶和群体机器人）提供服务。近年来，基于AI的MSFP方法取得了显著成就，相关综述已有报道。然而，通过严格细致的调查，我们发现现有综述存在一些局限性。一方面，大多数综述面向单一任务或研究领域（如3D目标检测或自动驾驶），其他相关领域的研究者往往难以直接受益。另一方面，大多数综述仅从多模态融合的单一视角介绍MSFP，而缺乏对方法多样性的考虑，如多视角融合和时间序列融合。为此，本文希望从任务无关的角度组织MSFP研究，从多种技术视角报告方法。具体而言，我们首先介绍MSFP的背景，随后综述多模态和多智能体融合方法，进一步分析时间序列融合方法。在大语言模型时代，我们还探讨了多模态大语言模型融合方法。最后，我们讨论了MSFP的开放挑战与未来方向。希望本综述能帮助研究者理解MSFP的重要进展，并为未来研究提供可能的启示。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [180] [Assessing Risk of Stealing Proprietary Models for Medical Imaging Tasks](https://arxiv.org/abs/2506.19464)
**中文标题：评估医疗影像任务中专有模型被窃取的风险**

*Ankita Raj,Harsh Swaika,Deepankar Varma,Chetan Arora*

主要分类: eess.IV

摘要简述: 本文研究了医疗影像专有模型在模型窃取（MS）攻击下的脆弱性，提出了一种名为QueryWise的两步模型窃取方法，利用公开数据集和有限查询预算有效克隆模型功能。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在医疗影像中的应用促使许多公司部署专有模型以提供商业化服务，但模型权重隐藏无法完全防止模型窃取攻击。目前，医疗影像模型对MS攻击的脆弱性尚未充分研究，本文旨在填补这一空白。

研究方法: 提出了一种名为QueryWise的两步模型窃取方法：首先利用代理分布获取未标记数据，随后在不增加查询预算的情况下训练窃取模型。实验基于胆囊癌和COVID-19分类任务的两款医疗影像模型。

研究结果: 实验证明，即使缺乏目标模型的训练数据且查询预算有限，攻击者仍能通过公开数据集有效实施MS攻击。QueryWise方法进一步提升了窃取效果。

研究结论: 医疗影像专有模型对MS攻击具有显著脆弱性，QueryWise方法为攻击者提供了高效的工具，需引起行业重视以加强模型保护。

中文摘要: 深度学习在医疗影像应用中的成功促使多家公司部署专有模型于诊断流程中，提供商业化服务。尽管模型权重被隐藏以保护知识产权，但这些模型仍面临模型窃取（MS）攻击的威胁，攻击者可通过查询代理数据集并基于获取的预测训练窃取模型来克隆其功能。尽管在通用视觉任务中已有广泛研究，医疗影像模型对MS攻击的脆弱性仍未充分探索。本文研究了黑盒医疗影像模型在攻击者缺乏目标模型训练数据且查询预算有限的实际条件下的脆弱性。我们证明攻击者可通过公开数据集有效实施MS攻击。为进一步提升有限查询预算下的窃取能力，我们提出了一种名为QueryWise的两步模型窃取方法，该方法利用代理分布获取的未标记数据训练窃取模型，无需额外查询。在胆囊癌和COVID-19分类的两款医疗影像模型上的评估验证了该攻击的有效性。源代码见https://github.com/rajankita/QueryWise。

</details>


### [181] [NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs](https://arxiv.org/abs/2506.19387)
**中文标题：NAADA：一种用于牙科全景X光片的噪声感知注意力去噪自动编码器**

*Khuram Naveed,Bruna Neves de Freitas,Ruben Pauwels*

主要分类: eess.IV

摘要简述: 本文提出了一种噪声感知自注意力去噪自动编码器（NAADA），用于提升牙科全景X光片的图像质量，特别关注噪声区域中的细节恢复。


<details>
  <summary>详细信息</summary>
研究动机: 卷积去噪自动编码器（DAEs）在图像恢复中表现优异，但倾向于恢复低频特征而忽略高频细节，这在牙科X光片中尤为关键。传统自注意力机制虽能缓解此问题，但往往优先处理干净区域的特征，忽视噪声区域的关键细节。因此，本文旨在提出一种噪声感知自注意力方法，以更好地恢复噪声区域的重要特征。

研究方法: 本文提出了一种噪声感知自注意力方法，使模型能够有效聚焦并恢复噪声区域的关键特征。基于此方法，构建了噪声感知注意力增强去噪自动编码器（NAADA）网络，用于提升牙科全景X光片的图像质量。

研究结果: 与当前先进的Uformer、MResDNN等方法相比，NAADA在细节恢复方面表现更优，显著提升了图像质量和诊断准确性。

研究结论: NAADA通过噪声感知自注意力机制，有效解决了传统方法在噪声区域细节恢复上的不足，为牙科X光片的图像增强提供了更优解决方案。

中文摘要: 卷积去噪自动编码器（DAEs）是图像恢复的有力工具，但它们继承了卷积神经网络（CNNs）的一个关键限制：倾向于更有效地恢复低频特征（如平滑区域）而非高频细节。这导致细微细节的丢失，在牙科X光片中尤为严重，因为保留细微解剖结构至关重要。尽管自注意力机制可以通过强调重要特征来缓解此问题，但传统注意力方法通常优先处理干净区域的特征，可能忽视被噪声掩盖的特征。为解决这一限制，我们提出了一种噪声感知自注意力方法，使模型能够有效聚焦并恢复噪声区域的关键特征。基于此方法，我们引入了噪声感知注意力增强去噪自动编码器（NAADA）网络，用于增强噪声牙科全景X光片。与当前先进的（且更复杂的）方法如Uformer、MResDNN等相比，我们的方法在细节恢复方面表现更优，确保了更好的图像质量和诊断准确性。

</details>


### [182] [NIC-RobustBench: A Comprehensive Open-Source Toolkit for Neural Image Compression and Robustness Analysis](https://arxiv.org/abs/2506.19051)
**中文标题：NIC-RobustBench：一个全面的开源工具包用于神经图像压缩与鲁棒性分析**

*Georgii Bychkov,Khaled Abud,Egor Kovalev,Alexander Gushchin,Dmitriy Vatolin,Anastasia Antsiferova*

主要分类: eess.IV

摘要简述: NIC-RobustBench是一个开源工具包，用于全面评估神经图像压缩（NIC）的鲁棒性和对抗防御效率，同时支持率失真（RD）性能比较。


<details>
  <summary>详细信息</summary>
研究动机: 随着JPEG AI标准的发布，评估NIC的鲁棒性变得至关重要，但现有研究仅局限于少量编解码器和攻击方式。因此，开发一个全面的开源框架成为迫切需求。

研究方法: 提出了NIC-RobustBench框架，包含最多数量的编解码器，易于扩展，并用于分析NIC的鲁棒性。

研究结果: NIC-RobustBench是目前已知包含最多编解码器的NIC库，能够全面评估NIC的鲁棒性和对抗防御效率。

研究结论: NIC-RobustBench为NIC鲁棒性研究提供了首个开源工具包，填补了研究空白，并展示了其实际应用价值。

中文摘要: 神经网络的对抗鲁棒性是一个日益重要的研究领域，涉及计算机视觉模型、大型语言模型（LLM）等。随着JPEG AI——首个端到端神经图像压缩（NIC）方法标准的发布，评估NIC的鲁棒性变得至关重要。然而，现有研究仅局限于少量编解码器和攻击方式。为此，我们提出了\textbf{NIC-RobustBench}，这是首个开源框架，用于评估NIC的鲁棒性和对抗防御效率，同时支持率失真（RD）性能比较。该框架包含已知NIC库中最多的编解码器，且易于扩展。本文全面介绍了NIC-RobustBench框架，并利用其分析了NIC的鲁棒性。我们的代码已在https://github.com/msu-video-group/NIC-RobustBench上公开。

</details>


### [183] [Xray2Xray: World Model from Chest X-rays with Volumetric Context](https://arxiv.org/abs/2506.19055)
**中文标题：Xray2Xray：基于胸部X光片的体积上下文世界模型**

*Zefan Yang,Xinrui Song,Xuanang Xu,Yongyi Shi,Ge Wang,Mannudeep K. Kalra,Pingkun Yan*

主要分类: eess.IV

摘要简述: Xray2Xray是一种新型世界模型，通过从胸部X光片中学习3D结构信息的潜在表示，解决了2D投影图像的结构叠加限制，并在心血管疾病风险预测和病理分类任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 胸部X光片（CXRs）是最常用的医学成像方式，但由于其2D投影特性，存在结构叠加的限制，影响了精确疾病诊断和风险预测的效果。本研究旨在通过Xray2Xray模型解决这一问题。

研究方法: Xray2Xray通过视觉模型和过渡模型，从不同角度位置的X光投影中学习胸部体积的潜在表示，并将其用于下游任务，如风险预测和疾病诊断。

研究结果: 实验表明，Xray2Xray在心血管疾病风险估计中优于监督方法和自监督预训练方法，并在五种病理分类任务中表现优异。此外，其潜在表示还可用于重建体积上下文。

研究结论: Xray2Xray通过从2D X光片中提取3D结构信息，显著提升了疾病诊断和风险预测的准确性，为医学影像分析提供了新思路。

中文摘要: 胸部X光片（CXRs）是最广泛使用的医学成像方式，在疾病诊断中起着关键作用。然而，作为2D投影图像，CXRs受限于结构叠加，影响了其精确诊断和风险预测的效果。为解决2D CXRs的局限性，本研究提出了Xray2Xray，一种新型世界模型，能够从胸部X光片中学习编码3D结构信息的潜在表示。Xray2Xray通过视觉模型和过渡模型，模拟不同角度位置的X光投影动态，捕捉胸部体积的潜在表示。我们将Xray2Xray的潜在表示用于下游风险预测和疾病诊断任务。实验结果显示，Xray2Xray在心血管疾病风险估计中优于监督方法和自监督预训练方法，并在五种病理分类任务中表现优异。我们还通过合成任务评估了Xray2Xray潜在表示的质量，并证明其可用于重建体积上下文。

</details>


### [184] [Staining normalization in histopathology: Method benchmarking using multicenter dataset](https://arxiv.org/abs/2506.19106)
**中文标题：组织病理学中的染色归一化：基于多中心数据集的方法比较**

*Umair Khan,Jouni Härkönen,Marjukka Friman,Leena Latonen,Teijo Kuopio,Pekka Ruusuvuori*

主要分类: eess.IV

摘要简述: 本文通过多中心数据集比较了八种染色归一化方法（包括传统和深度学习方法），以解决H&E染色在实验室间的差异问题，并评估了其性能。


<details>
  <summary>详细信息</summary>
研究动机: H&E染色在不同实验室间存在显著差异，影响病理学家和AI分析的准确性。研究旨在通过多中心数据集比较不同染色归一化方法，以减少这种差异。

研究方法: 收集了来自结肠、肾脏和皮肤组织的多中心数据集，样本分发至66个实验室进行H&E染色。比较了八种染色归一化方法，包括四种传统方法（直方图匹配、Macenko、Vahadane、Reinhard）和两种深度学习方法（CycleGAN和Pix2pix的变体）。通过定量和定性评估方法性能。

研究结果: 研究展示了不同染色归一化方法的性能，并揭示了实验室间染色差异对模型泛化能力的潜在影响。

研究结论: 多中心数据集为染色归一化方法提供了基准，实验室间染色差异可用于优化训练数据，提高模型泛化能力。

中文摘要: 苏木精和伊红（H&E）染色是组织分析的金标准，但不同实验室染色的组织样本在外观上存在显著差异，这对病理学家和基于AI的分析提出了挑战。计算上减少染色差异是一个活跃的研究领域。为进一步研究此问题，我们收集了一个独特的多中心组织图像数据集，其中结肠、肾脏和皮肤组织块样本分发至66个实验室进行常规H&E染色。为隔离染色差异，其他影响组织外观的因素保持不变。此外，我们利用该数据集比较了八种染色归一化方法的性能，包括四种传统方法（直方图匹配、Macenko、Vahadane和Reinhard归一化）和两种深度学习方法（CycleGAN和Pix2pix，各有两种变体）。通过定量和定性评估方法性能。该数据集的实验室间染色差异还可指导通过多样化训练数据提高模型泛化能力的策略。

</details>


### [185] [A Deep Learning Based Method for Fast Registration of Cardiac Magnetic Resonance Images](https://arxiv.org/abs/2506.19167)
**中文标题：基于深度学习的快速心脏磁共振图像配准方法**

*Benjamin Graham*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的快速心脏磁共振图像配准方法，能够在保持高精度的同时显著提升计算效率，适用于临床和研究环境。


<details>
  <summary>详细信息</summary>
研究动机: 心脏图像配准在医学图像分析中至关重要，但现有深度学习方法因计算时间长和配准精度问题难以广泛应用。本文旨在设计一种快速且高效的配准模型，以满足临床需求。

研究方法: 提出了一种快速轻量级配准（FLIR）模型，采用高效卷积架构，能够在保持与现有先进模型相似配准精度的同时，大幅缩短推理时间。

研究结果: FLIR模型在心脏应变量化中表现出高度一致性，配准结果稳定且计算速度快。

研究结论: FLIR模型为心脏图像配准提供了一种快速高效的解决方案，具有广泛的应用潜力。

中文摘要: 图像配准在医学图像分析中有广泛应用，例如用于追踪心脏图像中的组织运动，其运动特征可作为组织健康的指标。然而，配准对深度学习算法而言是一个挑战，因为难以生成真实变换数据，且可能存在多种变换方式使图像看起来相关。已有无监督方法用于预测有效变换，但这些方法的预测时间显著长于传统基线方法。为了使深度学习方法在研究和临床环境中更广泛地应用，需设计能在普通硬件上快速运行的模型。已有快速配准方法，但常采用基于块的方法，可能影响心脏等高动态器官的配准精度。

本文提出了一种快速体积配准模型，用于量化心脏应变。所提出的深度学习神经网络（DLNN）采用高效卷积架构，能够在保持与其他先进模型相似配准精度的同时，大幅缩短推理时间。快速轻量级配准（FLIR）模型用于预测组织运动，进而量化组织经历的非均匀应变。对于同一患者在相近时间采集的图像，应变值的差异应非常小。实验表明，使用FLIR方法计算的应变值具有高度一致性。

</details>


### [186] [Deformable Medical Image Registration with Effective Anatomical Structure Representation and Divide-and-Conquer Network](https://arxiv.org/abs/2506.19222)
**中文标题：基于有效解剖结构表示和分治网络的可变形医学图像配准**

*Xinke Ma,Yongsheng Pan,Qingjie Zeng,Mengkang Lu,Bolysbek Murat Yerzhanuly,Bazargul Matkerim,Yong Xia*

主要分类: eess.IV

摘要简述: 本文提出了一种名为EASR-DCN的新型ROI（感兴趣区域）医学图像配准方法，通过高斯混合模型和分治网络实现无标签的独立ROI对齐，显著提升了配准精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于学习的可变形医学图像配准方法存在局限性：无监督方法忽略ROI表示，弱监督方法依赖标签约束。本文旨在解决这些问题，提出一种无需标签的ROI配准方法。

研究方法: 1. 使用高斯混合模型进行强度分析，将图像表示为多个具有不同强度的有效ROI。2. 提出分治网络（DCN），通过独立通道处理ROI，学习每个ROI的特征对齐，最终整合生成位移矢量场。

研究结果: 在三个MRI和一个CT数据集上的实验表明，EASR-DCN在脑部MRI、心脏MRI和海马体MRI上的Dice分数分别比VoxelMorph提高了10.31%、13.01%和5.75%，配准精度和变形减少效果显著。

研究结论: EASR-DCN通过有效ROI表示和分治网络实现了无标签的高精度医学图像配准，具有临床应用潜力。代码将在论文接受后公开。

中文摘要: 有效表示感兴趣区域（ROI）并独立对齐这些ROI可以显著提升可变形医学图像配准（DMIR）的性能。然而，当前基于学习的DMIR方法存在局限性：无监督技术忽略ROI表示，直接对齐图像对；弱监督方法则依赖标签约束。为解决这些问题，我们提出了一种名为EASR-DCN的新型ROI配准方法。该方法通过高斯混合模型进行强度分析，将图像表示为多个具有不同强度的有效ROI，并实现无标签的独立对齐。此外，我们提出了一种分治网络（DCN），通过独立通道处理ROI，学习每个ROI的特征对齐，最终整合生成位移矢量场。在三个MRI和一个CT数据集上的实验表明，EASR-DCN在脑部MRI、心脏MRI和海马体MRI上的Dice分数分别比VoxelMorph提高了10.31%、13.01%和5.75%，展示了其高精度和变形减少效果。该方法具有临床应用潜力，代码将在论文接受后公开。

</details>


### [187] [Quantitative Benchmarking of Anomaly Detection Methods in Digital Pathology](https://arxiv.org/abs/2506.19234)
**中文标题：数字病理学中异常检测方法的定量基准测试**

*Can Cui,Xindong Zheng,Ruining Deng,Quan Liu,Tianyuan Yao,Keith T Wilson,Lori A Coburn,Bennett A Landman,Haichun Yang,Yaohong Wang,Yuankai Huo*

主要分类: eess.IV

摘要简述: 本文对数字病理学中的异常检测方法进行了定量基准测试，评估了20多种方法在五种数据集上的表现，分析了图像尺度、异常类型和训练策略对性能的影响。


<details>
  <summary>详细信息</summary>
研究动机: 数字病理学中的异常检测在罕见疾病识别、伪影检测和生物标志物发现等方面具有重要应用潜力，但由于病理图像的特殊性（如大尺寸、多尺度结构、染色变异和重复模式），现有方法面临挑战。本研究旨在通过系统评估为未来研究提供基准。

研究方法: 研究选取了20多种经典和流行的异常检测方法，在五种真实和合成的数字病理数据集上进行了广泛实验，分析了图像尺度、异常模式类型和训练策略对检测性能的影响。

研究结果: 实验结果显示，不同方法在不同场景下的表现差异显著，研究详细比较了各方法的优势和局限性，为数字病理学异常检测提供了全面的基准。

研究结论: 本研究为数字病理学中的异常检测方法提供了系统评估和基准，揭示了现有方法的不足，并为未来研究方向提供了指导。

中文摘要: 异常检测在工业缺陷检测领域已得到广泛研究，但在数字病理学中，其应用潜力巨大，如罕见疾病识别、伪影检测和生物标志物发现。然而，病理图像的特殊性（如大尺寸、多尺度结构、染色变异和重复模式）为现有异常检测算法带来了新挑战。本研究通过定量实验对20多种经典和流行的异常检测方法进行了基准测试。我们整理了五种真实和合成的数字病理数据集，系统评估了这些方法。实验探讨了图像尺度、异常模式类型和训练策略对检测性能的影响。结果详细比较了各方法的优势和局限性，为数字病理学异常检测的未来研究提供了全面基准。

</details>


### [188] [Explicit Residual-Based Scalable Image Coding for Humans and Machines](https://arxiv.org/abs/2506.19297)
**中文标题：基于显式残差的可扩展图像编码方法：服务于人类与机器**

*Yui Tatsumi,Ziyue Zeng,Hiroshi Watanabe*

主要分类: eess.IV

摘要简述: 本文提出了一种基于显式残差的可扩展图像编码方法（FR-ICMH和PR-ICMH），旨在同时服务于人类和机器视觉需求，显著提升了编码效率和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，图像不仅被人类使用，还被图像识别模型广泛消费。然而，现有方法过度依赖神经网络的学习能力，而架构设计不足。本文旨在通过引入显式残差压缩机制，提升可扩展图像编码的效率和可解释性。

研究方法: 本文提出了两种互补方法：基于特征残差的可扩展编码（FR-ICMH）和基于像素残差的可扩展编码（PR-ICMH）。这些方法结合了显式残差压缩机制，适用于多种机器视觉任务，并在编码复杂性和压缩性能之间提供了灵活性。

研究结果: 实验结果表明，PR-ICMH比现有方法节省了高达29.57%的BD-rate，证明了所提方法的有效性。

研究结论: 通过引入显式残差压缩机制，本文提出的方法显著提升了可扩展图像编码的效率和适应性，为人类和机器视觉需求提供了更好的解决方案。

中文摘要: 可扩展图像压缩是一种逐步重建多个图像版本以满足不同需求的技术。近年来，图像不仅被人类使用，还被图像识别模型广泛消费。这一变化使得服务于机器和人类视觉的可扩展图像压缩方法（ICMH）受到越来越多的关注。许多现有模型采用基于神经网络的编解码器（即学习型图像压缩），并通过精心设计损失函数取得了显著进展。然而，某些情况下，模型过度依赖其学习能力，而架构设计不足。本文通过整合显式残差压缩机制（常用于JPEG2000等分辨率可扩展编码方法），提升了ICMH框架的编码效率和可解释性。具体而言，我们提出了两种互补方法：基于特征残差的可扩展编码（FR-ICMH）和基于像素残差的可扩展编码（PR-ICMH）。这些方法适用于多种机器视觉任务，并提供了在编码复杂性和压缩性能之间选择的灵活性。实验结果表明，PR-ICMH比现有方法节省了高达29.57%的BD-rate。

</details>


### [189] [Reconsidering Explicit Longitudinal Mammography Alignment for Enhanced Breast Cancer Risk Prediction](https://arxiv.org/abs/2506.19363)
**中文标题：重新审视显式纵向乳腺X光对齐以提升乳腺癌风险预测**

*Solveig Thrun,Stine Hansen,Zijun Sun,Nele Blum,Suaiba A. Salahuddin,Kristoffer Wickstrøm,Elisabeth Wetzer,Robert Jenssen,Maik Stille,Michael Kampffmeyer*

主要分类: eess.IV

摘要简述: 本研究探讨了在乳腺X光检查中显式纵向对齐的最佳方法，比较了输入空间与表示空间对齐的效果，并发现图像级对齐优于表示级对齐，能提升变形场质量和风险预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 乳腺X光检查的定期筛查对早期乳腺癌检测至关重要。深度学习风险预测方法利用时间序列数据追踪乳腺组织变化，但显式对齐方法在乳腺X光检查中的最优策略尚未明确。本研究旨在填补这一空白。

研究方法: 研究比较了输入空间与表示空间显式对齐的效果，并探讨了对齐与风险预测是否应联合优化。通过实验验证了图像级对齐的优越性。

研究结果: 结果表明，联合优化显式对齐与风险预测会导致对齐质量与预测性能的权衡，而图像级对齐在变形场质量和风险预测准确性上表现更优。

研究结论: 图像级显式对齐在乳腺X光检查中更具优势，能显著提升风险预测的准确性。

中文摘要: 定期乳腺X光筛查对早期乳腺癌检测至关重要。基于深度学习的风险预测方法通过调整高风险人群的筛查间隔引起了广泛关注。早期方法仅关注当前X光片，而近期方法利用筛查的时间序列数据追踪乳腺组织变化，需要跨时间点的空间对齐。目前主要有两种策略：通过可变形配准的显式特征对齐和基于变换器等技术的隐式学习对齐，前者提供更多控制。然而，乳腺X光检查中显式对齐的最优方法仍未充分探索。本研究探讨了显式对齐应在何处进行（输入空间或表示空间）以及对齐与风险预测是否应联合优化。研究表明，当前最先进方法中联合优化表示空间显式对齐与风险估计会导致对齐质量与预测性能的权衡，而图像级对齐优于表示级对齐，能提升变形场质量和风险预测准确性。代码见https://github.com/sot176/Longitudinal_Mammogram_Alignment.git。

</details>


### [190] [Angio-Diff: Learning a Self-Supervised Adversarial Diffusion Model for Angiographic Geometry Generation](https://arxiv.org/abs/2506.19455)
**中文标题：Angio-Diff：学习自监督对抗扩散模型用于血管造影几何生成**

*Zhifeng Wang,Renjiao Yi,Xin Wen,Chenyang Zhu,Kai Xu,Kunlun He*

主要分类: eess.IV

摘要简述: 本文提出了一种自监督对抗扩散模型Angio-Diff，用于从非血管X射线生成血管造影图像，解决了数据不足和血管几何结构复杂的挑战，实现了高质量的血管合成。


<details>
  <summary>详细信息</summary>
研究动机: 血管疾病对人类健康构成重大威胁，X射线血管造影是诊断的金标准，但其高辐射暴露问题亟待解决。现有方法因缺乏配对数据集和难以处理血管几何结构而效果不佳，因此需要一种新方法。

研究方法: 提出了一种自监督扩散模型，包括学习血管数据分布的扩散模型、血管合成生成器和基于掩码的对抗模块。此外，引入参数化血管模型以提升几何准确性。

研究结果: 实验表明，Angio-Diff在合成血管造影图像质量和几何结构准确性上达到最先进水平，优于现有方法。

研究结论: Angio-Diff为血管造影合成提供了高效解决方案，解决了数据不足和几何结构复杂的问题，具有重要应用价值。

中文摘要: 血管疾病对人类健康构成重大威胁，X射线血管造影作为诊断金标准，能详细观察血管，但其辐射水平较高。因此，从非血管X射线到血管造影的模态转换具有需求。数据驱动的深度学习方法因缺乏配对大规模数据集而受限，高质量血管造影合成仍具挑战性。现有医学图像合成方法主要在像素级别操作，难以适应血管的复杂几何结构，导致合成质量不佳（如血管断裂或不自然弯曲）。为解决此问题，我们提出一种基于扩散模型的自监督方法，将非血管X射线转换为血管造影，缓解数据不足问题。模型包括学习血管数据分布的扩散模型、血管合成生成器和基于掩码的对抗模块。为提升几何准确性，提出参数化血管模型拟合血管形状和分布。该方法贡献了血管造影合成流程和合成数据集。通过大量对比和消融实验评估Angio-Diff，结果表明其在合成血管造影图像质量和几何结构准确性上达到最先进水平。代码见https://github.com/zfw-cv/AngioDiff。

</details>


### [191] [Learning from Anatomy: Supervised Anatomical Pretraining (SAP) for Improved Metastatic Bone Disease Segmentation in Whole-Body MRI](https://arxiv.org/abs/2506.19590)
**中文标题：从解剖学中学习：监督解剖预训练（SAP）用于改进全身MRI中转移性骨病分割**

*Joris Wuts,Jakub Ceranka,Nicolas Michoux,Frédéric Lecouvet,Jef Vandemeulebroucke*

主要分类: eess.IV

摘要简述: 本文提出了一种监督解剖预训练（SAP）方法，通过有限解剖标签数据学习，显著提升了全身MRI中转移性骨病（MBD）的分割效果，优于基线方法和自监督学习。


<details>
  <summary>详细信息</summary>
研究动机: 转移性骨病（MBD）在全身MRI中的分割因病变外观多样、解剖位置复杂、边界模糊及类别不平衡而极具挑战性。现有方法依赖大量标注数据，但标注成本高且易出错。自监督学习虽能利用未标注数据，但通用表征难以捕捉病变的细微特征。

研究方法: 本文提出监督解剖预训练（SAP）方法：首先基于健康个体的全身MRI扫描训练骨骼分割模型，随后将其用于44名转移性前列腺癌患者的MBD分割任务，并与基线随机初始化和自监督学习方法对比。

研究结果: SAP在标准化表面Dice系数（0.76）和Dice系数（0.64）上显著优于基线（0.24）和自监督学习（0.31）。对于大于1毫升的临床相关病变，SAP在28/32患者中达到100%检测灵敏度。

研究结论: 从解剖学中学习骨骼形态为骨病变分割任务提供了有效的领域相关归纳偏置。SAP方法在MBD分割中表现出色，代码和模型已开源。

中文摘要: 全身MRI（WB-MRI）中转移性骨病（MBD）的分割是一个具有挑战性的问题。由于病变外观多样、解剖位置复杂、边界模糊及严重类别不平衡，获取可靠分割需要大量标注数据，而标注过程耗时且易出错。自监督学习（SSL）虽能利用未标注数据，但其通用表征难以满足病变检测的精细需求。
本文提出监督解剖预训练（SAP）方法，通过有限解剖标签数据学习。首先基于健康个体的WB-MRI扫描训练骨骼分割模型，随后在44名转移性前列腺癌患者中评估其MBD分割效果，并与基线随机初始化和先进SSL方法对比。
SAP显著优于基线及SSL预训练模型，标准化表面Dice系数为0.76，Dice系数为0.64。病变检测F2得分为0.44，优于基线（0.24）和SSL（0.31）。对于大于1毫升的临床相关病变，SAP在28/32患者中达到100%检测灵敏度。
从解剖学中学习骨骼形态为骨病变分割任务提供了有效的领域相关归纳偏置。所有代码和模型均已公开。

</details>


### [192] [Filling of incomplete sinograms from sparse PET detector configurations using a residual U-Net](https://arxiv.org/abs/2506.19600)
**中文标题：利用残差U-Net填补稀疏PET探测器配置中的不完整正弦图**

*Klara Leffler,Luigi Tommaso Luppino,Samuel Kuttner,Karin Söderkvist,Jan Axelsson*

主要分类: eess.IV

摘要简述: 本文提出了一种基于残差U-Net的深度学习方法，用于修复稀疏PET探测器配置中的不完整正弦图数据，以降低成本并提升图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 长轴向视场PET扫描仪虽能提高灵敏度和视场范围，但高密度的光电探测器配置导致成本高昂，限制了临床应用。稀疏探测器配置虽能降低成本，但会牺牲图像质量。本文旨在通过深度学习技术填补缺失的正弦图数据，以平衡成本与图像质量。

研究方法: 采用改进的残差U-Net模型，基于GE Signa PET/MR的临床扫描数据进行训练，模拟移除50%探测器（仅保留25%响应线）的棋盘模式。模型通过学习填补缺失的计数数据。

研究结果: 模型成功填补了缺失的计数数据，平均绝对误差低于每像素两个事件，优于二维插值方法。尽管预测的正弦图存在平滑效应，导致重建图像细节不够锐利，但模型显著缓解了稀疏配置导致的欠采样问题。

研究结论: 研究表明，稀疏探测器配置结合深度学习技术是一种可行的替代方案，支持开发低成本、全身PET扫描仪，为医学影像技术带来重要进展。

中文摘要: 长轴向视场PET扫描仪相较于传统PET扫描仪具有更大的视场范围和更高的灵敏度，但其高密度的光电探测器配置导致成本高昂，限制了临床应用。为降低成本，提出了稀疏系统配置方案，但其图像质量会受到影响。本文提出了一种深度正弦图修复网络，用于填补缺失的正弦图数据。我们采用改进的残差U-Net模型，基于GE Signa PET/MR的临床扫描数据进行训练，模拟移除50%探测器的棋盘模式（仅保留25%响应线）。模型成功填补了缺失的计数数据，平均绝对误差低于每像素两个事件，在正弦图和重建图像域均优于二维插值方法。值得注意的是，预测的正弦图存在平滑效应，导致重建图像细节不够锐利。尽管如此，模型显著缓解了稀疏配置导致的欠采样问题。这项概念验证研究表明，稀疏探测器配置结合深度学习技术是一种可行的替代方案，支持开发低成本、全身PET扫描仪，为医学影像技术带来重要进展。

</details>


### [193] [ReCoGNet: Recurrent Context-Guided Network for 3D MRI Prostate Segmentation](https://arxiv.org/abs/2506.19687)
**中文标题：ReCoGNet：基于循环上下文引导网络的3D MRI前列腺分割**

*Ahmad Mustafa,Reza Rastegar,Ghassan AlRegib*

主要分类: eess.IV

摘要简述: 本文提出了一种混合架构ReCoGNet，结合DeepLabV3和ConvLSTM，用于3D MRI前列腺分割，在数据有限和噪声条件下表现优于现有2D和3D方法。


<details>
  <summary>详细信息</summary>
研究动机: 前列腺MRI分割在临床癌症评估中至关重要，但现有2D CNN方法未能充分利用切片间解剖连续性，而3D模型需要大量标注数据。本文旨在解决这些问题。

研究方法: 采用混合架构，使用预训练的DeepLabV3提取单切片语义特征，并通过ConvLSTM层构建的循环卷积头整合跨切片信息，保留空间结构。

研究结果: 在PROMISE12基准测试中，无论是干净还是对比度降低的数据，ReCoGNet在精度、召回率、IoU和DSC上均优于现有2D和3D分割模型。

研究结论: ReCoGNet通过结合2D和3D方法的优势，实现了上下文感知的分割，适合临床部署。

中文摘要: 前列腺T2加权MRI分割是临床前列腺癌评估中的关键但具有挑战性的任务。尽管基于深度学习的方法显著推动了自动化分割，但大多数传统方法（尤其是2D卷积神经网络）未能利用切片间的解剖连续性，限制了其准确性和鲁棒性。完全3D模型提供了更好的空间一致性，但需要大量标注数据，这在临床环境中往往不切实际。为解决这些问题，我们提出了一种将MRI序列建模为时空数据的混合架构。我们的方法使用预训练的DeepLabV3主干网络从每个MRI切片中提取高级语义特征，并通过由ConvLSTM层构建的循环卷积头整合跨切片信息，同时保留空间结构。这种组合实现了上下文感知的分割，在数据有限和噪声条件下表现更优。我们在PROMISE12基准测试中评估了该方法在干净和对比度降低的测试设置下的表现。与最先进的2D和3D分割模型相比，我们的方法在精度、召回率、交并比（IoU）和Dice相似系数（DSC）上均表现出色，突显了其在临床部署中的潜力。

</details>


### [194] [NeRF-based CBCT Reconstruction needs Normalization and Initialization](https://arxiv.org/abs/2506.19742)
**中文标题：基于NeRF的CBCT重建需要归一化和初始化**

*Zhuowei Xu,Han Li,Dai Sun,Zhicheng Li,Yujia Li,Qingpeng Kong,Zhiwei Cheng,Nassir Navab,S. Kevin Zhou*

主要分类: eess.IV

摘要简述: 论文提出了一种归一化哈希编码器和映射一致性初始化策略，以解决NeRF-based CBCT重建中局部-全局训练不匹配问题，显著提升了训练稳定性和重建质量。


<details>
  <summary>详细信息</summary>
研究动机: CBCT重建因X射线投影数量有限而成为病态问题，NeRF-based方法虽成功但存在哈希编码器与神经网络局部-全局训练不匹配，导致特征不一致、训练不稳定和重建质量下降。

研究方法: 提出归一化哈希编码器增强特征一致性，并设计映射一致性初始化策略，通过预训练模型初始化神经网络，提升训练早期稳定性。

研究结果: 方法在4个数据集、128个CT案例上验证，显著提升训练效率、收敛速度和重建性能，且实现简单。

研究结论: 归一化哈希编码器和映射一致性初始化有效缓解局部-全局优化不匹配，为NeRF-based CBCT重建提供了高效稳定的解决方案。

中文摘要: 锥束计算机断层扫描（CBCT）在医学影像中广泛应用，但X射线投影数量有限导致重建成为病态问题，伴随严重伪影。基于NeRF的方法在此任务中取得显著成功，但其哈希编码器与神经网络之间存在局部-全局训练不匹配问题。具体而言，哈希编码器在每一步训练中仅使用部分参数（局部稀疏），而神经网络所有参数均参与（全局密集），导致哈希特征在训练步骤间高度不一致。这些不一致的特征输入神经网络后，引发重复的全局更新不一致，进而导致训练不稳定、收敛缓慢和重建质量下降。为缓解这一局部-全局优化不匹配的影响，我们提出归一化哈希编码器，增强特征一致性并减轻不匹配。此外，我们设计了一种映射一致性初始化（MCI）策略，通过利用预训练模型的全局映射特性初始化神经网络。初始化后的神经网络在训练早期表现出更高的稳定性，实现更快收敛和更优重建性能。我们的方法简单高效，仅需少量代码即可显著提升训练效率，并在4个数据集、128个CT案例（覆盖7个解剖区域）上验证了其有效性。

</details>


### [195] [Systematic Review of Pituitary Gland and Pituitary Adenoma Automatic Segmentation Techniques in Magnetic Resonance Imaging](https://arxiv.org/abs/2506.19797)
**中文标题：MRI中垂体腺和垂体腺瘤自动分割技术的系统综述**

*Mubaraq Yakubu,Navodini Wijethilake,Jonathan Shapey,Andrew King,Alexander Hammers*

主要分类: eess.IV

摘要简述: 本文系统综述了MRI中垂体腺和垂体腺瘤的自动分割技术，发现深度学习（尤其是U-Net模型）在腺瘤分割中表现较好，但需进一步改进以提高小结构（如正常垂体腺）的分割准确性。


<details>
  <summary>详细信息</summary>
研究动机: 准确的垂体腺和腺瘤分割对诊断和治疗至关重要，但现有自动分割技术的性能和临床适用性仍需评估和改进。

研究方法: 综述了34项采用自动和半自动分割方法的研究，提取并分析了分割技术和性能指标（如Dice重叠分数）。

研究结果: 深度学习（尤其是U-Net模型）在腺瘤分割中表现较好（Dice分数4.60--96.41%），但小结构（如正常垂体腺）的分割准确性较低（Dice分数0.19--89.00%）。半自动方法表现更稳定（垂体腺80.00--92.10%，腺瘤75.90--88.36%）。

研究结论: 多数研究未报告关键指标（如MR场强、年龄和腺瘤大小）。U-Net模型在腺瘤分割中表现良好，但需进一步改进以提高小结构的分割准确性。更大的多样化数据集对提升临床适用性至关重要。

中文摘要: 目的：从磁共振成像（MRI）中准确分割垂体腺和腺瘤对诊断和治疗至关重要。本文系统综述了自动分割方法，以提高MRI中垂体腺和腺瘤分割的准确性和效率。方法：我们回顾了34项采用自动和半自动分割方法的研究，提取并综合了分割技术和性能指标（如Dice重叠分数）的数据。结果：大多数研究采用深度学习方法，其中U-Net模型最为普遍。自动方法在垂体腺分割中的Dice分数为0.19--89.00%，腺瘤分割为4.60--96.41%。半自动方法在垂体腺分割中为80.00--92.10%，腺瘤分割为75.90--88.36%。结论：多数研究未报告关键指标（如MR场强、年龄和腺瘤大小）。U-Net模型在腺瘤分割中表现良好，但对小结构（如正常垂体腺）的分割仍需改进。持续的创新和更大、多样化的数据集对提升临床适用性至关重要。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [196] [AI-based Approach in Early Warning Systems: Focus on Emergency Communication Ecosystem and Citizen Participation in Nordic Countries](https://arxiv.org/abs/2506.18926)
**中文标题：基于人工智能的早期预警系统方法：聚焦北欧国家的应急通信生态系统与公民参与**

*Fuzel Shaik,Getnet Demil,Mourad Oussalah*

主要分类: cs.CY

摘要简述: 本文探讨了基于人工智能的早期预警系统在北欧国家应急通信生态系统和公民参与中的应用，强调气候变化和自然灾害的全球挑战，并提出了一种涵盖准备、应急响应和灾后阶段的全方位方法。


<details>
  <summary>详细信息</summary>
研究动机: 气候变化和自然灾害是全球性挑战，需要高效且复杂的生态系统来应对其社会、经济和环境影响。本文旨在通过人工智能技术提升早期预警系统的效能，特别是在北欧国家的应急通信和公民参与中。

研究方法: 本文采用了一种全方位方法，区分了准备、应急响应和灾后阶段，并重点分析了人工智能技术在各个阶段的应用，尤其是基于INFORM风险框架和早期预警系统的技术。

研究结果: 研究强调了应急通信和心理风险感知在应急响应中的重要性，并通过北欧国家的案例研究展示了人工智能技术在早期预警系统中的实际应用效果。

研究结论: 本文提出，人工智能技术可以显著提升早期预警系统的效能，尤其是在应急通信和公民参与方面，为应对气候变化和自然灾害提供了新的解决方案。

中文摘要: 气候变化和自然灾害被视为全球性挑战，需要复杂且高效的生态系统来应对其社会、经济和环境影响。本章提倡一种全方位方法，区分了准备、应急响应和灾后阶段，并特别强调了早期预警系统（EWS）、风险建模和缓解措施的作用。本章回顾了在各个阶段可以应用的各种人工智能技术，重点关注INFORM风险框架和早期预警系统。应急通信和心理风险感知在应急响应阶段得到了强调。最后，本章还重点介绍了一组来自北欧国家的案例研究。

</details>


### [197] [AI Safety vs. AI Security: Demystifying the Distinction and Boundaries](https://arxiv.org/abs/2506.18932)
**中文标题：AI安全与AI安全：解构区别与边界**

*Zhiqiang Lin,Huan Sun,Ness Shroff*

主要分类: cs.CY

摘要简述: 本文旨在澄清人工智能（AI）领域中‘AI安全’与‘AI安全’之间的区别与边界，通过严格定义和类比说明两者的研究重点及相互依赖关系，以促进跨学科合作和政策制定。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在医疗、自动驾驶等关键领域的广泛应用，其带来的风险日益凸显，但‘AI安全’与‘AI安全’的概念常被混淆，导致研究方向和政策制定模糊不清。本文旨在明确两者的区别与边界，为研究和实践提供清晰指导。

研究方法: 通过严格定义‘AI安全’与‘AI安全’，并借助信息传输和建筑构造的类比，阐明两者的研究重点及相互影响。

研究结果: 明确了‘AI安全’与‘AI安全’的独立研究领域及其相互依赖关系，例如安全漏洞如何引发安全问题，反之亦然。

研究结论: 澄清‘AI安全’与‘AI安全’的边界有助于精准研究方向、促进跨学科合作、提升政策有效性，并最终推动可信AI系统的部署。

中文摘要: 人工智能（AI）正迅速融入从医疗到自动驾驶等关键领域，其集成带来了巨大效益，同时也引入了重大风险，包括AI滥用引发的风险。在管理这些风险的讨论中，‘AI安全’与‘AI安全’这两个术语常被混用，导致概念混淆。本文旨在解构两者的区别，并明确其研究边界。我们提供了严格的定义，概述了各自的研究重点，并探讨了它们的相互依赖性，包括安全漏洞如何引发安全问题，反之亦然。通过信息传输和建筑构造的清晰类比，我们阐明了这些区别。明确这些边界对于指导精准研究方向、促进有效跨学科合作、增强政策有效性以及最终推动可信AI系统的部署至关重要。

</details>


### [198] [Can AI support student engagement in classroom activities in higher education?](https://arxiv.org/abs/2506.18941)
**中文标题：人工智能能否支持高等教育中学生对课堂活动的参与？**

*Neha Rani,Sharan Majumder,Ishan Bhardwaj,Pedro Guillermo Feijoo Garcia*

主要分类: cs.CY

摘要简述: 研究探讨了在高等教育中，基于大型语言模型（如ChatGPT）的对话式人工智能（CAI）是否能提升大班课堂中学生对学习内容的参与度。实验表明，CAI工具（如ChatGPT）在大班教学中具有提升学生参与度的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 随着计算机科学课程的报名人数激增，大班教学成为常态，但学生与教师及学习内容之间的互动不足。技术进步和大型语言模型（LLMs）的发展为利用对话式人工智能（CAI）提升学生参与度提供了机会。

研究方法: 在一门软件工程课程中设计了一项课堂活动，学生使用CAI工具（ChatGPT）完成课堂任务。通过在美国一所大学的大班中进行对比实验，比较了使用CAI工具和不使用CAI工具时学生的参与度。

研究结果: 实验结果表明，CAI工具（如ChatGPT）在大班课堂中能够有效提升学生对学习内容的参与度。

研究结论: CAI工具（如ChatGPT）在大班教学中具有提升学生参与度的潜力，为未来教育技术的应用提供了新思路。

中文摘要: 丰厚的职业前景和创造性的机会常常吸引学生选择计算机科学专业并继续深造。因此，计算机科学课程的报名人数激增，班级规模从数百人到数千人不等。在这种大班教学中，学生与教师及学习内容之间缺乏互动是一个常见挑战。然而，随着技术的进步和大型语言模型（LLMs）的发展，利用基于LLM的人工智能模型（如对话式人工智能（CAI））来提升大班中学生对学习内容的参与度具有巨大潜力。为了探索CAI在支持学生参与（尤其是学习内容）方面的潜力，我们在一个软件工程课程（大班）中设计了一项课堂活动，学生使用CAI完成任务。我们在美国一所大学的大班中进行了对比实验，比较了使用CAI工具和不使用CAI工具时学生的参与度。由于ChatGPT的广泛普及和熟悉度，我们选择了它作为CAI工具。结果表明，CAI（ChatGPT）在大班课堂活动中具有提升学生对学习内容参与度的潜力。我们还进一步讨论了研究结果的意义。

</details>


### [199] [Citizenship Challenges in Artificial Intelligence Education](https://arxiv.org/abs/2506.18955)
**中文标题：人工智能教育中的公民身份挑战**

*Margarida Romero*

主要分类: cs.CY

摘要简述: 本文探讨了人工智能教育中的公民身份挑战，重点关注学生、教师及其他教育利益相关者在AI整合背景下的需求，提出了培养AI意识与教育的方法，并强调了批判性思维和计算思维的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能在教育中的广泛应用，如何确保学生和教师具备相关的公民意识和技能成为关键问题。本文旨在探讨如何通过教育和培训，促进对AI的社会批判性理解，并培养相关技能。

研究方法: 文章首先探讨了提升AI意识和教育的方法，包括社会批判性策略；其次分析了在AI支持的教育活动中如何运用批判性思维和计算思维技能。

研究结果: 研究提出了促进AI教育的策略，并强调了批判性思维和计算思维在AI支持的教育活动中的重要性。

研究结论: 本文强调了在AI教育中培养公民意识和技能的必要性，并提出了具体的教育方法和思维技能培养策略。

中文摘要: 本章探讨了人工智能教育中与公民身份相关的挑战，特别是学生、教师及其他教育利益相关者在AI整合背景下的问题。我们首先探讨了如何培养AI意识和教育，以及促进社会批判性AI培训的策略，旨在确定优先考虑的相关和伦理用途。第二部分讨论了在特定AI支持的教育活动中可以调动的批判性思维和计算思维技能，具体取决于这些活动所需的创造性和变革性参与程度。

</details>


### [200] [LLM-Based Social Simulations Require a Boundary](https://arxiv.org/abs/2506.19806)
**中文标题：基于大语言模型的社会模拟需设定边界**

*Zengqing Wu,Run Peng,Takayuki Ito,Chuan Xiao*

主要分类: cs.CY

摘要简述: 本文主张基于大语言模型（LLM）的社会模拟需设定明确边界，以有效支持社会科学研究。尽管LLM在模拟人类行为方面优于传统模型，但其存在行为同质化的局限性，影响社会动态模拟的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 探讨LLM在社会模拟中的局限性，尤其是其行为同质化问题，并提出边界设定以提升模拟的可靠性和科学性。

研究方法: 分析LLM在模拟中的三个关键边界问题：对齐性（模拟行为与现实匹配）、一致性（行为随时间连贯性）和鲁棒性（不同条件下的可重复性），并提出启发式边界和实用检查表。

研究结果: 提出LLM社会模拟的适用场景：关注集体模式而非个体轨迹、行为与真实人口平均值对齐、具备验证方法测试鲁棒性。

研究结论: LLM社会模拟需明确边界，聚焦集体模式和行为对齐，并通过验证方法确保可靠性，为社会科学研究提供更有效工具。

中文摘要: 本立场论文主张，基于大语言模型（LLM）的社会模拟需设定明确边界，以有意义地贡献于社会科学研究。尽管LLM在模拟人类行为方面较传统基于代理的模型更具潜力，但其存在根本性局限，限制了其在社会模式发现中的可靠性。核心问题在于LLM倾向于表现出缺乏行为异质性的“平均人格”，而行为异质性对模拟复杂社会动态至关重要。我们探讨了三个关键边界问题：对齐性（模拟行为与现实模式匹配）、一致性（随时间保持行为连贯性）和鲁棒性（不同条件下的可重复性）。我们提出了启发式边界，以确定LLM模拟何时能可靠推动社会科学理解。我们认为，当聚焦于（1）集体模式而非个体轨迹、（2）代理行为与真实人口平均值对齐（尽管方差有限）、（3）具备测试模拟鲁棒性的验证方法时，此类模拟更具价值。我们提供了一份实用检查表，指导研究者确定LLM社会模拟的适用范围和主张。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [201] [Neural Cellular Automata for ARC-AGI](https://arxiv.org/abs/2506.15746)
**中文标题：神经细胞自动机在ARC-AGI中的应用**

*Kevin Xu,Risto Miikkulainen*

主要分类: cs.NE

摘要简述: 本文探讨了神经细胞自动机（NCA）在ARC-AGI任务中的表现，通过梯度训练学习迭代更新规则，证明其在抽象网格任务中的高效性和潜力。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索神经细胞自动机（NCA）在需要精确变换和少样本泛化的任务中的表现，特别是针对ARC-AGI这一挑战性领域。

研究方法: 方法包括使用基于梯度的训练学习迭代更新规则，将输入网格转换为训练示例中的输出，并将其应用于测试输入。

研究结果: 结果表明，梯度训练的NCA模型在ARC的抽象网格任务中表现出色，是一种高效且有前景的方法。

研究结论: 结论指出，NCA在ARC任务中的应用为自组织系统的广泛使用提供了新的见解，并探讨了设计修改和训练约束的影响。

中文摘要: 细胞自动机及其可微分对应物——神经细胞自动机（NCA）具有高度表达能力，能够实现出人意料的复杂行为。本文探讨了NCA在需要精确变换和少样本泛化的任务中的表现，以抽象与推理人工智能通用智能库（ARC-AGI）为领域，挑战其能力。具体而言，本文使用基于梯度的训练学习迭代更新规则，将输入网格转换为训练示例中的输出，并将其应用于测试输入。结果表明，梯度训练的NCA模型是处理ARC中抽象网格任务的一种高效且有前景的方法。此外，本文还讨论了各种设计修改和训练约束的影响，并研究了NCA在ARC中的行为和特性，为自组织系统的广泛应用提供了见解。

</details>


### [202] [Enhancing Generalization of Spiking Neural Networks Through Temporal Regularization](https://arxiv.org/abs/2506.19256)
**中文标题：通过时间正则化提升脉冲神经网络的泛化能力**

*Boxuan Zhang,Zhen Xu,Kuan Tao*

主要分类: cs.NE

摘要简述: 本文提出了一种时间正则化训练（TRT）方法，通过引入时间依赖的正则化机制，增强脉冲神经网络（SNN）在早期时间步的约束，从而有效缓解过拟合并提升泛化性能。实验验证了TRT在多个数据集上的优越性，并通过理论分析揭示了其机制。


<details>
  <summary>详细信息</summary>
研究动机: 脉冲神经网络（SNN）因其事件驱动和低功耗特性备受关注，但直接训练的SNN由于神经形态数据集规模有限和梯度不匹配问题，存在严重的过拟合现象，限制了其泛化性能。本文旨在通过时间正则化机制解决这一问题。

研究方法: 提出时间正则化训练（TRT）方法，通过时间依赖的正则化机制对早期时间步施加更强约束。实验在CIFAR10/100、ImageNet100、DVS-CIFAR10和N-Caltech101等数据集上进行，并通过损失景观可视化和学习曲线分析验证其有效性。

研究结果: TRT显著缓解了过拟合问题，平滑了训练损失景观，提升了模型的泛化能力。理论分析揭示了时间信息集中（TIC）现象，即Fisher信息逐渐集中在早期时间步，TRT通过时间衰减的正则化机制引导网络学习鲁棒特征。

研究结论: TRT方法通过时间正则化机制有效提升了SNN的泛化性能，理论分析进一步验证了其机制的科学性。代码已开源。

中文摘要: 脉冲神经网络（SNN）因其事件驱动和低功耗特性受到广泛关注，特别适用于处理基于事件的神经形态数据。然而，直接训练的SNN由于神经形态数据集规模有限和梯度不匹配问题，存在严重的过拟合现象，从根本上限制了其泛化性能。本文提出了一种时间正则化训练（TRT）方法，通过引入时间依赖的正则化机制，对早期时间步施加更强约束。我们在CIFAR10/100、ImageNet100、DVS-CIFAR10和N-Caltech101等数据集上比较了TRT与其他先进方法的性能。为验证TRT的有效性，我们进行了消融研究及分析，包括损失景观可视化和学习曲线分析，结果表明TRT能有效缓解过拟合并平滑训练损失景观，从而提升泛化能力。此外，基于Fisher信息分析结果，我们对TRT的时间正则化机制进行了理论解释。通过跟踪TRT训练过程中的Fisher信息，分析了SNN内部的时间信息动态，揭示了时间信息集中（TIC）现象，即Fisher信息逐渐集中在早期时间步。TRT实现的时间衰减正则化机制有效引导网络在信息丰富的早期时间步学习鲁棒特征，从而显著提升模型的泛化性能。代码发布于https://github.com/ZBX05/Temporal-Regularization-Training。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [203] [From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents](https://arxiv.org/abs/2506.18959)
**中文标题：从网络搜索到代理式深度研究：通过推理代理激励搜索**

*Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu*

主要分类: cs.IR

摘要简述: 本文提出了一种名为‘Agentic Deep Research’的新范式，利用具有推理和代理能力的大型语言模型（LLMs）超越传统关键词搜索，通过自主推理、迭代检索和信息合成的动态反馈循环，显著提升复杂信息需求的处理能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统关键词搜索引擎在处理复杂、多步骤信息需求时表现不足，而具备推理和代理能力的大型语言模型（LLMs）为信息检索带来了新的可能性。本文旨在探索如何将这些能力整合为一种新的研究范式，以应对未来信息获取的挑战。

研究方法: 论文提出‘Agentic Deep Research’范式，通过将自主推理、迭代检索和信息合成紧密结合，形成一个动态反馈循环。此外，还引入了一种测试时扩展定律，以量化计算深度对推理和搜索的影响。

研究结果: 实验结果表明，‘Agentic Deep Research’在性能上显著优于现有方法，并有望成为未来信息检索的主导范式。开源实现和基准数据集的发布进一步支持了这一结论。

研究结论: ‘Agentic Deep Research’通过整合推理和代理能力，为信息检索开辟了新方向，展示了其在复杂信息需求处理中的巨大潜力，并有望成为未来的主流范式。

中文摘要: 信息检索是现代知识获取的基石，每天处理数十亿次跨领域查询。然而，传统的关键词搜索引擎在处理复杂、多步骤信息需求时日益显得力不从心。我们的观点是，具备推理和代理能力的大型语言模型（LLMs）正在引领一种名为‘代理式深度研究’的新范式。这些系统通过将自主推理、迭代检索和信息合成紧密结合为一个动态反馈循环，超越了传统的信息搜索技术。我们追溯了从静态网络搜索到基于代理的交互式系统的演变，这些系统能够规划、探索和学习。我们还引入了一种测试时扩展定律，以形式化计算深度对推理和搜索的影响。通过基准测试结果和开源实现的兴起，我们证明了‘代理式深度研究’不仅显著优于现有方法，还有望成为未来信息检索的主导范式。所有相关资源，包括行业产品、研究论文、基准数据集和开源实现，均已汇总至https://github.com/DavidZWZ/Awesome-Deep-Research，供社区使用。

</details>


### [204] [NEAR$^2$: A Nested Embedding Approach to Efficient Product Retrieval and Ranking](https://arxiv.org/abs/2506.19743)
**中文标题：NEAR²：一种用于高效产品检索与排名的嵌套嵌入方法**

*Shenbin Qian,Diptesh Kanojia,Samarth Agrawal,Hadeel Saadany,Swapnil Bhosale,Constantin Orasan,Zhe Wu*

主要分类: cs.IR

摘要简述: 本文提出了一种名为NEAR²的嵌套嵌入方法，用于高效产品检索与排名，能在推理时实现高达12倍的嵌入尺寸效率提升，同时不增加训练成本，并提高多种基于Transformer模型的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 电子商务信息检索系统面临同时实现复杂用户查询高准确性和海量产品目录高效处理的双重挑战。NEAR²旨在精确匹配用户意图与相关产品的同时，降低实时搜索的计算需求。

研究方法: NEAR²采用嵌套嵌入方法，结合多种损失函数（如多重负排名损失和在线对比损失），在四种不同测试集上验证其性能，解决了短查询和隐式查询等检索难题。

研究结果: 实验表明，NEAR²在较小嵌入维度下优于现有模型，实现了更高的检索和排名准确性，同时显著提升了推理效率。

研究结论: NEAR²通过嵌套嵌入设计，成功平衡了检索准确性和计算效率，为电子商务信息检索系统提供了一种高效解决方案。

中文摘要: 电子商务信息检索（IR）系统难以同时实现复杂用户查询的高准确性和海量产品目录的高效处理。这一双重挑战在于精确匹配用户意图与相关产品的同时，管理实时搜索大规模库存的计算需求。本文提出了一种名为NEAR²的嵌套嵌入方法，用于产品检索与排名，能在推理时实现高达12倍的嵌入尺寸效率提升，同时不增加训练成本，并提高多种基于Transformer模型的准确性。我们通过不同损失函数（如多重负排名损失和在线对比损失）在四种不同测试集上验证了该方法，解决了短查询和隐式查询等检索难题。与现有模型相比，NEAR²在较小嵌入维度下实现了更高的性能。

</details>


### [205] [Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model](https://arxiv.org/abs/2506.19777)
**中文标题：基于公平生成式序列推荐模型的用户敏感偏见缓解**

*Yang Liu,Feng Wu,Xuefang Zhu*

主要分类: cs.IR

摘要简述: 本文提出了一种基于扩散模型（DM）的公平生成式序列推荐模型FairGENRec，旨在解决推荐系统中的用户敏感特征偏见问题。通过注入随机噪声和多兴趣表示信息，模型在训练和推理阶段分别实现公平性建模和目标项目重建。实验证明，FairGENRec在准确性和公平性上均有显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中，推荐系统依赖用户行为数据，而相同敏感特征（如性别、年龄）的用户往往具有相似的行为模式，导致推荐模型容易捕捉敏感特征的强相关性，从而引发推荐不公平问题。扩散模型因其对不确定性和多样性的建模能力，适用于解决此类问题。

研究方法: 论文提出FairGENRec模型，在训练阶段通过敏感特征识别模型指导注入随机噪声，并设计序列去噪模型进行项目反向重建；同时注入消除敏感特征偏见的多兴趣表示信息。推理阶段利用历史交互数据生成噪声形式，通过反向迭代重建目标项目表示。

研究结果: 在三个数据集上的实验表明，FairGENRec在准确性和公平性上均实现了双重提升，统计分析结果直观展示了推荐公平性的改进程度。

研究结论: FairGENRec通过扩散模型有效建模推荐公平性并增强多样性，实验验证了其在准确性和公平性上的双重优势，为解决推荐系统中的偏见问题提供了新思路。

中文摘要: 推荐公平性近期备受关注。现实中，推荐系统由用户行为驱动，而具有相同敏感特征（如性别和年龄）的用户往往具有相同的行为模式，推荐模型容易捕捉敏感特征的强相关性偏好，从而导致推荐不公平。扩散模型（DM）作为一种新的生成模型范式，在推荐系统中取得了巨大成功。DM对不确定性和多样性的建模能力，及其建模机制与带有偏见的现实推荐过程高度适配。因此，我们利用DM有效建模推荐公平性并增强多样性。本文提出了一种基于DM的公平生成式序列推荐模型FairGENRec。在训练阶段，我们在敏感特征识别模型的指导下向原始分布注入随机噪声，并设计序列去噪模型对项目进行反向重建。同时，通过向生成结果注入消除用户敏感特征偏见的多兴趣表示信息，完成推荐公平性建模。在推理阶段，模型利用历史交互数据以噪声添加形式获取噪声，随后通过反向迭代重建目标项目表示。最终，我们在三个数据集上的大量实验证明了FairGENRec在准确性和公平性上的双重提升效果，而案例的统计分析直观展示了推荐公平性的改进程度。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [206] [Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation](https://arxiv.org/abs/2506.19774)
**中文标题：Kling-Foley：基于多模态扩散变换器的高质量视频到音频生成**

*Jun Wang,Xijuan Zeng,Chunyu Qiang,Ruilong Chen,Shiyao Wang,Le Wang,Wangjing Zhou,Pengfei Cai,Jiahui Zhao,Nan Li,Zihan Li,Yuzhe Liang,Xiaopeng Wang,Haorui Zheng,Ming Wen,Kang Yin,Yiran Wang,Nan Li,Feng Deng,Liang Dong,Chen Zhang,Di Zhang,Kun Gai*

主要分类: eess.AS

摘要简述: Kling-Foley是一种多模态视频到音频生成模型，通过多模态扩散变换器和视觉语义对齐模块，实现高质量音频与视频内容的同步生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频到音频生成模型在语义对齐和音视频同步方面存在不足，且缺乏高质量的通用音频编解码器。Kling-Foley旨在解决这些问题，并填补开源基准数据集的不足。

研究方法: 提出多模态扩散变换器，结合视觉语义表示模块和音视频同步模块，增强视频与音频的帧级对齐；引入通用潜在音频编解码器，支持多种场景的高质量音频建模；采用立体声渲染方法提升空间感。

研究结果: 实验表明，Kling-Foley在分布匹配、语义对齐、时间对齐和音频质量方面达到公开模型的SOTA性能，并开源了工业级基准数据集Kling-Audio-Eval。

研究结论: Kling-Foley通过多模态融合和高质量音频建模，显著提升了视频到音频生成的效果，为相关领域提供了新的技术支持和基准数据。

中文摘要: 我们提出了Kling-Foley，一种大规模多模态视频到音频生成模型，能够合成与视频内容同步的高质量音频。Kling-Foley引入了多模态扩散变换器，用于建模视频、音频和文本模态之间的交互，并结合视觉语义表示模块和音视频同步模块以增强对齐能力。具体而言，这些模块在帧级别上将视频条件与潜在音频元素对齐，从而提升语义对齐和音视频同步效果。结合文本条件，这一集成方法能够精确生成与视频匹配的音效。此外，我们提出了一种通用潜在音频编解码器，能够在音效、语音、歌唱和音乐等多种场景中实现高质量建模。我们采用立体声渲染方法，为合成音频赋予空间感。同时，为了弥补开源基准数据集在类型和标注上的不足，我们还开源了一个工业级基准数据集Kling-Audio-Eval。实验表明，基于流匹配目标训练的Kling-Foley在分布匹配、语义对齐、时间对齐和音频质量方面均达到了公开模型的SOTA性能。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [207] [Chain-of-Experts: Unlocking the Communication Power of Mixture-of-Experts Models](https://arxiv.org/abs/2506.18945)
**中文标题：专家链：释放混合专家模型的通信潜力**

*Zihan Wang,Rui Pan,Jiarui Yao,Robert Csordas,Linjie Li,Lu Yin,Jiajun Wu,Tong Zhang,Manling Li,Shiwei Liu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Chain-of-Experts (CoE)的新型Mixture-of-Experts (MoE)架构，通过层内专家顺序通信提升模型表达能力。CoE通过动态路由机制和迭代专家选择，显著提升了性能并降低了内存消耗。


<details>
  <summary>详细信息</summary>
研究动机: 传统的MoE模型中专家并行独立工作，缺乏动态交互，限制了模型的表达能力。CoE旨在通过层内专家的顺序通信和动态路由机制，提升模型的灵活性和性能。

研究方法: CoE在每层内引入专家链式处理机制，每个迭代步骤配备专用路由器，支持动态专家选择。这种设计允许令牌在每次迭代中重新评估和选择专家，而非静态分配。

研究结果: 在数学推理任务中，CoE将验证损失从1.20降至1.12，同时通过2倍迭代匹配3倍专家选择的性能，内存消耗减少17.6-42%。

研究结论: CoE通过迭代残差结构和动态路由机制，显著提升了模型的表达能力和效率，为MoE模型的扩展提供了新的方向。

中文摘要: 我们提出了专家链（Chain-of-Experts, CoE），一种新型的混合专家（Mixture-of-Experts, MoE）架构，通过在每层内引入专家的顺序通信机制。与传统MoE模型中专家并行独立工作不同，CoE在层内通过专家链对令牌进行迭代处理。为支持迭代中的动态专家选择，CoE在每层内的每个迭代步骤配备专用路由器。这种设计允许令牌在每次迭代中重新评估和选择不同专家，而非静态分配。因此，CoE引入了一种灵活的路由机制，增加了专家组合的多样性，丰富了模型的表达能力。在固定计算条件下，CoE表现出更优的性能：在数学推理任务中，验证损失从1.20降至1.12，优于标准MoE模型。此外，CoE提供了一种新的扩展维度：通过专家迭代实现深度扩展，补充了传统的宽度/深度扩展。例如，使用2倍迭代即可匹配3倍专家选择（宽度扩展）的性能，同时内存消耗减少17.6-42%。分析表明，CoE的优势源于其迭代残差结构和动态路由机制带来的专家专业化提升，共同释放了更丰富的表达能力。代码发布于https://github.com/ZihanWang314/coe。

</details>


### [208] [LLMs on a Budget? Say HOLA](https://arxiv.org/abs/2506.18952)
**中文标题：预算有限也能运行LLM？试试HOLA**

*Zohaib Hasan Siddiqui,Jiechao Gao,Ebad Shabbir,Mohammad Anas Azeez,Rafiq Ali,Gautam Siddharth Kashyap,Usman Naseem*

主要分类: cs.LG

摘要简述: 本文提出HOLA框架，通过分层推测解码和自适应检索增强生成，优化大型语言模型在边缘设备上的部署，显著提升效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 在边缘设备上运行大型语言模型（LLMs）面临高计算和内存需求的问题，限制了其在医疗、教育和嵌入式系统等领域的实时应用。现有方法如量化和剪枝仅提供部分优化，且常牺牲速度或准确性。

研究方法: HOLA框架结合了分层推测解码（HSD）和自适应检索增强生成（AdaComp-RAG），内部通过HSD加速推理而不损失质量，外部通过AdaComp-RAG动态调整检索复杂度。此外，LoBi方法融合结构化剪枝（LoRA）和量化。

研究结果: HOLA在GSM8K上实现17.6%的EMA提升，ARC上10.5%的MCA提升，并在Jetson Nano等边缘设备上显著降低延迟和内存占用，证明其可扩展性和生产就绪性。

研究结论: HOLA框架为边缘设备上的LLM部署提供了高效、全面的优化方案，兼具速度和准确性，适用于实际生产环境。

中文摘要: 在边缘设备上运行大型语言模型（LLMs）受限于高计算和内存需求，阻碍了其在医疗、教育和嵌入式系统等领域的实时应用。现有解决方案如量化、剪枝和检索增强生成（RAG）仅提供部分优化，且常牺牲速度或准确性。我们提出HOLA，一种端到端的LLM高效部署优化框架。其内部采用分层推测解码（HSD）实现无损加速推理，外部通过AdaComp-RAG根据上下文需求动态调整检索复杂度。结合LoBi（融合结构化剪枝LoRA和量化），HOLA在GSM8K上实现17.6%的EMA提升，ARC上10.5%的MCA提升，并在Jetson Nano等边缘设备上显著降低延迟和内存占用，证明其可扩展性和生产就绪性。

</details>


### [209] [Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs](https://arxiv.org/abs/2506.18931)
**中文标题：安全修剪LoRA：基于距离引导的鲁棒修剪方法用于大型语言模型适配中的安全性对齐**

*Shuang Ao,Yi Dong,Jinwei Hu,Sarvapali Ramchurn*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Safe Pruning LoRA (SPLoRA)的新方法，通过选择性修剪LoRA层来增强大型语言模型（LLMs）的安全性对齐，同时保持性能。该方法引入了一种新的相似性度量E-DIEM，有效检测安全性偏差，并在实验中显著优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 尽管低秩适应（LoRA）能高效微调大型语言模型，但微调过程可能削弱模型的安全性对齐，导致有害输出风险增加。现有方法难以平衡安全性与性能，亟需一种更有效的解决方案。

研究方法: SPLoRA通过选择性修剪LoRA层来消除安全性偏差，核心是引入E-DIEM度量，检测并量化模型的安全性对齐问题。实验覆盖了混合恶意与良性数据及纯良性数据的微调场景。

研究结果: 实验结果表明，SPLoRA在安全性、性能和可靠性上均优于现有技术，显著降低安全风险，同时减少推理开销，适用于大规模部署。

研究结论: SPLoRA为大型语言模型的安全性对齐提供了一种高效且可扩展的解决方案，能够在保持性能的同时显著提升安全性。

中文摘要: 通过低秩适应（LoRA）微调大型语言模型（LLMs）能够提升适应性并降低计算成本。然而，微调可能破坏安全性对齐，即使使用良性数据，也会增加有害输出的风险。现有安全性对齐方法难以捕捉复杂的参数变化，导致安全性与性能的权衡不佳。为解决这一问题，我们提出Safe Pruning LoRA (SPLoRA)，一种基于修剪的新方法，选择性移除削弱安全性对齐的LoRA层，从而提升安全性并保持性能。其核心是引入Empirical-DIEM (E-DIEM)，一种维度不敏感的相似性度量，有效检测LoRA适配模型中的安全性偏差。我们在混合恶意与良性数据及纯良性数据微调的LLMs上进行了广泛实验，评估SPLoRA在性能、安全性和可靠性上的表现。结果表明，SPLoRA优于现有安全性对齐技术，显著降低安全风险，同时保持或提升模型性能与可靠性。此外，SPLoRA减少了推理开销，为部署更安全可靠的LLMs提供了可扩展的高效解决方案。代码发布于https://github.com/AoShuang92/SPLoRA。

</details>


### [210] [Thought Anchors: Which LLM Reasoning Steps Matter?](https://arxiv.org/abs/2506.19143)
**中文标题：思维锚点：哪些LLM推理步骤至关重要？**

*Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy*

主要分类: cs.LG

摘要简述: 本文提出三种互补的归因方法，用于识别大型语言模型推理过程中的关键步骤（称为“思维锚点”），并通过可视化工具展示这些方法的一致性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型的长链推理过程难以分解和理解，因此需要一种句子级别的分析方法来揭示其推理机制。

研究方法: 1. 黑盒方法：通过对比模型生成不同句子时的最终答案，测量句子的反事实重要性；2. 白盒方法：通过聚合句子间的注意力模式，识别“广播”句子；3. 因果归因方法：通过抑制对某句子的注意力，测量其对后续推理的影响。

研究结果: 研究发现存在“思维锚点”，即对后续推理过程具有重要影响的句子（如规划或回溯句子），并通过工具展示了这些方法的一致性。

研究结论: 句子级别的分析有助于深入理解推理模型，三种方法的互补性验证了“思维锚点”的存在及其重要性。

中文摘要: 近年来，推理型大型语言模型在许多领域取得了最先进的性能。然而，其长链推理过程带来了可解释性挑战，因为每个生成的标记依赖于之前的所有标记，使得计算难以分解。我们认为，在句子级别分析推理轨迹是理解推理过程的一种有前景的方法。我们提出了三种互补的归因方法：（1）黑盒方法：通过比较模型生成某句子或不同含义句子时的最终答案，测量句子的反事实重要性；（2）白盒方法：通过聚合句子间的注意力模式，识别“广播”句子，这些句子通过“接收”注意力头从所有未来句子中获得不成比例的注意力；（3）因果归因方法：通过抑制对某句子的注意力，测量其对未来句子标记的影响。每种方法都证明了“思维锚点”的存在，即对后续推理过程具有重要影响的推理步骤（通常是规划或回溯句子）。我们提供了一个开源工具（www.thought-anchors.com）用于可视化这些方法的输出，并通过案例研究展示了这些方法在多步推理中的一致性。这些方法的一致性表明，句子级别的分析有助于更深入地理解推理模型。

</details>


### [211] [In-Context Occam's Razor: How Transformers Prefer Simpler Hypotheses on the Fly](https://arxiv.org/abs/2506.19351)
**中文标题：上下文中的奥卡姆剃刀：Transformer如何动态偏好更简单的假设**

*Puneesh Deora,Bhavya Vasudeva,Tina Behnia,Christos Thrampoulidis*

主要分类: cs.LG

摘要简述: 研究发现，Transformer模型在上下文学习中倾向于选择最简单的解释，符合奥卡姆剃刀原则。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究通常关注固定复杂度的上下文学习，而实际语言模型需处理不同复杂度的任务。本文旨在探索Transformer如何在多复杂度任务中做出选择。

研究方法: 设计了基于马尔可夫链和线性回归的测试环境，研究Transformer在多种复杂度假设下的表现，并通过贝叶斯框架解释其行为。

研究结果: Transformer不仅能识别任务的适当复杂度，还能准确推断参数，且在数据支持简单解释时优先选择最简单的假设。

研究结论: Transformer在上下文学习中表现出奥卡姆剃刀式的归纳偏好，这种偏好可能与模型规模和训练数据分布有关。

中文摘要: 上下文学习（ICL）使Transformer能够通过上下文示例适应新任务而无需参数更新。现有研究通常关注固定复杂度的环境，而实际语言模型需处理不同复杂度的任务。本文研究了Transformer如何在层次化任务结构中导航，其中高复杂度类别可以完美表示简单类别生成的任何模式。我们设计了基于马尔可夫链和线性回归的受控测试环境，发现Transformer不仅能识别任务的适当复杂度，还能准确推断参数——即使上下文示例与多种复杂度假设兼容。值得注意的是，当数据由简单过程生成时，Transformer始终选择最简充分的解释。我们通过贝叶斯框架从理论上解释了这一行为，表明Transformer通过平衡模型拟合与复杂度惩罚，有效实现了上下文中的贝叶斯奥卡姆剃刀。我们还分析了模型规模、训练混合分布、推理上下文长度和架构的作用。最后，我们以布尔函数任务为例，验证了预训练的GPT-4模型中的这种奥卡姆剃刀式归纳偏好，表明这可能是训练于多样化任务分布的Transformer的固有特性。

</details>


### [212] [Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models](https://arxiv.org/abs/2506.19697)
**中文标题：异常值安全的预训练：实现大型语言模型的鲁棒4位量化**

*Jungwoo Park,Taewhoo Lee,Chanwoong Yoon,Hyeon Hwang,Jaewoo Kang*

主要分类: cs.LG

摘要简述: 论文提出了一种名为Outlier-Safe Pre-Training (OSP)的方法，通过预防激活异常值的形成，显著提升了大型语言模型在4位量化下的性能，同时仅增加2%的训练开销。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）中的极端激活异常值严重降低了量化性能，阻碍了高效的设备部署。尽管通道操作和自适应梯度缩放被认为是主要原因，但实际缓解仍具挑战性。

研究方法: OSP结合了三个关键创新：(1) Muon优化器，消除特权基同时保持训练效率；(2) 单尺度RMSNorm，防止通道级放大；(3) 可学习的嵌入投影，重新分配来自嵌入矩阵的激活幅度。

研究结果: 在1万亿token上训练的1.4B参数模型在10个基准测试中平均得分35.7（Adam训练模型为26.5），异常值接近零（0.04），远低于标准模型的极端值（1818.56）。

研究结论: 研究表明异常值并非LLMs固有特性，而是训练策略的结果，为更高效的LLM部署铺平了道路。

中文摘要: 大型语言模型（LLMs）中的极端激活异常值严重降低了量化性能，阻碍了高效的设备部署。尽管通道操作和自适应梯度缩放被认为是主要原因，但实际缓解仍具挑战性。我们提出了异常值安全预训练（OSP），这是一种实用的指导方针，主动预防异常值形成，而非依赖事后缓解。OSP结合了三个关键创新：(1) Muon优化器，消除特权基同时保持训练效率；(2) 单尺度RMSNorm，防止通道级放大；(3) 可学习的嵌入投影，重新分配来自嵌入矩阵的激活幅度。我们在1万亿token上训练了一个1.4B参数模型，这是首个无此类异常值的生产级LLM。在激进的4位量化下，我们的OSP模型在10个基准测试中平均得分35.7（Adam训练模型为26.5），仅增加2%的训练开销。值得注意的是，OSP模型的超额峰度接近零（0.04），远低于标准模型的极端值（1818.56），从根本上改变了LLM的量化行为。我们的研究表明异常值并非LLMs固有特性，而是训练策略的结果，为更高效的LLM部署铺平了道路。源代码和预训练检查点可在https://github.com/dmis-lab/Outlier-Safe-Pre-Training获取。

</details>


### [213] [Scaling Speculative Decoding with Lookahead Reasoning](https://arxiv.org/abs/2506.19830)
**中文标题：通过前瞻推理扩展推测解码**

*Yichao Fu,Rui Ge,Zelei Shao,Zhijie Deng,Hao Zhang*

主要分类: cs.LG

摘要简述: 论文提出了一种名为“前瞻推理”的方法，通过利用步骤级并行性提升推测解码的效率，将峰值加速从1.4倍提升至2.1倍，同时保持答案质量。


<details>
  <summary>详细信息</summary>
研究动机: 推理模型通过生成长链思维表现出色，但解码数千个令牌的速度较慢。现有的令牌级推测解码（SD）因猜测正确率随令牌数增长而指数下降，导致加速效果有限。本文旨在突破这一算法天花板。

研究方法: 提出“前瞻推理”方法，利用步骤级并行性：轻量级草案模型提出多个未来步骤，目标模型批量扩展这些步骤，验证器保留语义正确的步骤并重新生成失败的步骤。令牌级SD在推理步骤内运行，两层并行性叠加。

研究结果: 在GSM8K、AIME等基准测试中，前瞻推理将SD的加速从1.4倍提升至2.1倍，且加速效果随GPU吞吐量增加而更好。

研究结论: 前瞻推理通过步骤级并行性显著提升了推测解码的效率，突破了令牌级SD的加速限制，同时保持了答案质量。

中文摘要: 推理模型通过生成长链思维表现出色，但解码生成的数千个令牌速度较慢。令牌级推测解码（SD）虽有一定帮助，但由于整个γ令牌猜测正确的概率随γ增长而指数下降，其加速效果有限。这意味着为更长令牌草案分配更多计算资源面临算法天花板，导致加速效果有限且与硬件无关。我们通过“前瞻推理”提升这一天花板，利用第二层步骤级并行性。我们的关键发现是，推理模型逐步生成内容，每一步只需语义正确，无需精确令牌匹配。在“前瞻推理”中，轻量级草案模型提出多个未来步骤；目标模型通过一次批量处理扩展每个提案，验证器保留语义正确的步骤并让目标模型重新生成失败的步骤。令牌级SD仍在每个推理步骤内运行，因此两层并行性叠加。我们证明“前瞻推理”在理论和实验上均提升了SD的峰值加速。在GSM8K、AIME等基准测试中，“前瞻推理”将SD的加速从1.4倍提升至2.1倍，同时保持答案质量，且其加速效果随GPU吞吐量增加而更好。代码发布于https://github.com/hao-ai-lab/LookaheadReasoning。

</details>


### [214] [Orthogonal Finetuning Made Scalable](https://arxiv.org/abs/2506.19847)
**中文标题：可扩展的正交微调**

*Zeju Qiu,Weiyang Liu,Adrian Weller,Bernhard Schölkopf*

主要分类: cs.LG

摘要简述: 论文提出OFTv2，通过输入中心化重构和Cayley-Neumann参数化，显著降低了正交微调的计算和内存开销，同时保持性能。


<details>
  <summary>详细信息</summary>
研究动机: 正交微调（OFT）虽然参数高效且能防止灾难性遗忘，但其高计算和内存需求限制了实际应用。论文旨在解决这一瓶颈。

研究方法: OFTv2采用输入中心化重构，将矩阵-矩阵乘法替换为矩阵-向量乘法（矩阵自由计算），并引入Cayley-Neumann参数化以高效近似正交矩阵。

研究结果: OFTv2实现了高达10倍的训练加速和3倍的GPU内存节省，且在量化基础模型微调中表现优于QLoRA。

研究结论: OFTv2显著提升了正交微调的效率和实用性，适用于更广泛的模型部署场景。

中文摘要: 正交微调（OFT）提供了高效的参数适应并防止灾难性遗忘，但其高运行时和内存需求限制了实际部署。我们发现OFT的核心计算瓶颈在于其权重中心化实现，依赖于计算复杂度为立方的矩阵-矩阵乘法。为解决这一问题，我们提出了OFTv2，一种输入中心化重构，改用矩阵-向量乘法（即矩阵自由计算），将计算成本降低至平方复杂度。我们还引入了Cayley-Neumann参数化，一种高效的正交参数化方法，通过截断Neumann级数近似Cayley变换中的矩阵求逆。这些改进使OFTv2在不影响性能的情况下实现高达10倍的训练加速和3倍的GPU内存节省。此外，我们将OFTv2扩展至支持量化基础模型的微调，并证明其在训练稳定性、效率和内存使用上优于流行的QLoRA。

</details>


### [215] [FairCauseSyn: Towards Causally Fair LLM-Augmented Synthetic Data Generation](https://arxiv.org/abs/2506.19082)
**中文标题：FairCauseSyn：面向因果公平的LLM增强合成数据生成**

*Nitish Nagesh,Ziyu Wang,Amir M. Rahmani*

主要分类: cs.LG

摘要简述: 本文提出了一种基于LLM增强的合成数据生成方法FairCauseSyn，旨在提升健康领域数据的因果公平性。实验表明，生成的数据在因果公平性指标上偏离真实数据不到10%，且能显著减少敏感属性偏差。


<details>
  <summary>详细信息</summary>
研究动机: 在健康应用中，生成高质量且公平的合成数据对实现公平结果至关重要。现有方法主要关注反事实公平性，且多应用于金融和法律领域，而因果公平性在健康领域的合成数据生成中尚未得到充分研究。

研究方法: 本文开发了一种基于LLM增强的合成数据生成方法，利用真实世界表格健康数据，通过保留因果结构来提升因果公平性。

研究结果: 生成的数据在因果公平性指标上偏离真实数据不到10%。在训练因果公平预测器时，合成数据比真实数据减少了70%的敏感属性偏差。

研究结论: 本研究填补了健康领域因果公平性合成数据生成的空白，为公平的健康研究和医疗服务提供了支持。

中文摘要: 合成数据生成利用生成模型基于真实世界数据创建数据。在健康应用中，生成高质量数据同时保持对敏感属性的公平性对实现公平结果至关重要。现有的基于GAN和LLM的方法主要关注反事实公平性，并多应用于金融和法律领域。因果公平性通过保留因果结构提供了更全面的评估框架，但目前的合成数据生成方法未在健康领域解决这一问题。为填补这一空白，我们开发了首个基于LLM增强的合成数据生成方法，利用真实世界表格健康数据提升因果公平性。生成的数据在因果公平性指标上偏离真实数据不到10%。在训练因果公平预测器时，合成数据比真实数据减少了70%的敏感属性偏差。这项工作改善了公平合成数据的获取，支持公平的健康研究和医疗服务。

</details>


### [216] [Finding Clustering Algorithms in the Transformer Architecture](https://arxiv.org/abs/2506.19125)
**中文标题：在Transformer架构中发现聚类算法**

*Kenneth L. Clarkson,Lior Horesh,Takuya Ito,Charlotte Park,Parikshit Ram*

主要分类: cs.LG

摘要简述: 本文证明了Transformer架构可以精确实现经典的k-means聚类算法（Lloyd算法），并通过理论证明和实验验证展示了其可行性，同时展示了如何通过调整架构生成新的聚类算法变体。


<details>
  <summary>详细信息</summary>
研究动机: 尽管Transformer在AI领域取得了巨大成功，但其是否能精确学习和实现算法仍不明确。本文旨在探索Transformer是否能够精确实现k-means聚类算法，并揭示其与算法之间的映射关系。

研究方法: 首先，理论证明了存在一种称为k-means Transformer的架构，能够通过标准的注意力机制和残差连接精确实现Lloyd算法。其次，通过数值实验验证了该架构与Lloyd算法的对应关系，并展示了如何通过调整架构生成新的聚类算法变体。

研究结果: 实验表明，k-means Transformer能够精确实现Lloyd算法，并且通过调整架构可以生成多种新的聚类算法变体，如软k-means、球形k-means和修剪k-means等。

研究结论: 本文展示了Transformer机制如何精确映射到算法过程，为在Transformer中实现精确算法提供了清晰且可解释的视角。

中文摘要: Transformer架构的发明彻底改变了人工智能（AI），在自然语言处理、计算机视觉和多模态推理等领域取得了前所未有的成功。尽管取得了这些进展，但Transformer是否能够学习和实现精确算法仍不明确。本文证明，Transformer可以精确实现一种基础且广泛使用的k-means聚类算法：Lloyd算法。首先，我们从理论上证明了一种称为k-means Transformer的架构的存在，该架构利用现代Transformer的标准组件（注意力和残差连接）精确实现了Lloyd算法。接着，我们通过数值实验实现了这一Transformer，并展示了该架构与Lloyd算法之间的精确对应关系，从而提供了一种完全基于神经网络的k-means聚类实现。最后，我们展示了通过对该架构进行可解释的调整（如引入层归一化或多层感知机），可以生成多样且新颖的聚类算法变体，如软k-means、球形k-means、修剪k-means等。总体而言，我们的发现揭示了Transformer机制如何精确映射到算法过程，为在Transformer中实现精确算法提供了清晰且可解释的视角。

</details>


### [217] [Private Model Personalization Revisited](https://arxiv.org/abs/2506.19220)
**中文标题：私有模型个性化问题再探**

*Conor Snedeker,Xinyu Zhou,Raef Bassily*

主要分类: cs.LG

摘要简述: 本文研究了在用户级差分隐私（DP）下的模型个性化问题，提出了一种高效的联邦学习算法，用于在异构数据中恢复共享嵌入和低维表示，并在噪声标签和更广泛的用户分布下提供了隐私保障。


<details>
  <summary>详细信息</summary>
研究动机: 在联邦学习中，用户数据通常具有统计异质性，且其最优参数共享一个未知的低维嵌入。如何在保护用户隐私的同时高效学习这一共享嵌入和本地表示，是一个重要问题。本文旨在解决这一问题，并在更广泛的用户分布（如亚高斯分布）下提供隐私保障。

研究方法: 本文提出了一种基于FedRep算法的私有联邦学习算法，用于学习共享嵌入。与之前的工作不同，该算法满足差分隐私，并适用于噪声标签情况。此外，通过Johnson-Lindenstrauss变换降低共享嵌入和用户数据的有效维度，实现了维度无关的风险界限。

研究结果: 在亚高斯分布下，本文算法提供了隐私保障，并在自然参数范围内将隐私误差项提高了$\widetilde{O}(dk)$倍。在二分类任务中，通过信息论构造和边缘损失，实现了维度无关的准确率保证。

研究结论: 本文提出的私有联邦学习算法在异构数据中有效学习了共享嵌入和本地表示，并在更广泛的用户分布下提供了隐私保障。通过降维技术，实现了维度无关的风险界限，为模型个性化提供了新的解决方案。

中文摘要: 我们研究了在共享表示框架下用户级差分隐私（DP）的模型个性化问题。在该问题中，存在$n$个用户，其数据具有统计异质性，且其最优参数共享一个未知的嵌入$U^* \in\mathbb{R}^{d\times k}$，该嵌入将用户参数从$\mathbb{R}^d$映射到低维表示$\mathbb{R}^k$，其中$k\ll d$。我们的目标是在联邦学习设置下，以较小的超额风险私有地恢复共享嵌入和本地低维表示。我们提出了一种基于[CHM+21]中FedRep算法的私有高效联邦学习算法来学习共享嵌入。与[CHM+21]不同，我们的算法满足差分隐私，且结果适用于噪声标签情况。与之前关于私有模型个性化的研究[JRS+21]相比，我们的效用保证适用于更广泛的用户分布（亚高斯分布而非高斯分布）。此外，在自然参数范围内，我们将[JRS+21]中的隐私误差项提高了$\widetilde{O}(dk)$倍。接下来，我们考虑了二分类任务。我们提出了一种信息论构造来私有地学习共享嵌入，并推导了一个与$d$无关的边缘准确率保证。我们的方法利用Johnson-Lindenstrauss变换降低了共享嵌入和用户数据的有效维度。结果表明，在边缘损失下，维度无关的风险界限在该设置中是可能的。

</details>


### [218] [Robust Behavior Cloning Via Global Lipschitz Regularization](https://arxiv.org/abs/2506.19250)
**中文标题：通过全局Lipschitz正则化实现鲁棒行为克隆**

*Shili Wu,Yizhao Jin,Puhua Niu,Aniruddha Datta,Sean B. Andersson*

主要分类: cs.LG

摘要简述: 本文提出了一种通过全局Lipschitz正则化增强行为克隆（BC）鲁棒性的方法，确保策略在面对观测误差或对抗扰动时仍能保持稳定。


<details>
  <summary>详细信息</summary>
研究动机: 行为克隆（BC）在模仿学习中表现优异，但在实际部署中，观测误差或对抗扰动可能导致策略表现不佳。本文旨在通过全局Lipschitz正则化提升策略的鲁棒性。

研究方法: 采用全局Lipschitz正则化方法，构建具有全局Lipschitz性质的神经网络，确保策略对有限范数扰动具有鲁棒性。

研究结果: 实验证明，该方法在Gymnasium的多种环境中有效提升了策略的鲁棒性，并提供了针对扰动的鲁棒性保证。

研究结论: 全局Lipschitz正则化是增强行为克隆鲁棒性的有效方法，适用于安全关键领域。

中文摘要: 行为克隆（BC）是一种有效的模仿学习技术，甚至被应用于自动驾驶等安全关键领域。BC通过仅使用专家演示的状态-动作对数据集训练策略，无需与环境进行额外交互。然而，在部署过程中，策略观测可能包含测量误差或对抗扰动。由于观测可能与真实状态存在偏差，可能导致智能体采取次优动作。本文采用全局Lipschitz正则化方法增强策略网络的鲁棒性，并证明该性质为策略提供了针对不同有限范数扰动的鲁棒性保证。此外，本文提出了一种构建Lipschitz神经网络的方法以确保策略鲁棒性。实验在Gymnasium的多种环境中验证了理论的有效性。关键词：鲁棒强化学习；行为克隆；Lipschitz神经网络

</details>


### [219] [Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment](https://arxiv.org/abs/2506.19342)
**中文标题：通过数据库-叙事对齐解决酒精推断不匹配问题**

*Sudesh Bhagat,Raghupathi Kandiboina,Ibne Farabi Shihab,Skylar Knickerbocker,Neal Hawkins,Anuj Sharma*

主要分类: cs.LG

摘要简述: 本研究通过数据库-叙事对齐方法解决酒精推断不匹配（AIM）问题，分析37万+交通事故记录，发现AIM占比24.03%，并提出针对性改进措施。


<details>
  <summary>详细信息</summary>
研究动机: 交通事故是全球致死主因之一，但酒精相关数据的不匹配（AIM）影响了预防策略和政策制定的准确性，亟需解决。

研究方法: 开发框架结合BERT模型分析37.1万条交通事故记录，使用Probit Logit模型探究AIM特征，并通过地理空间聚类识别高风险区域。

研究结果: 发现2,767起AIM事件（占比24.03%），酒精相关致命事故和夜间事故AIM较低，而未知车辆类型及老年驾驶员事故更易出现AIM。

研究结论: 需针对性培训和数据管理以提升事故报告准确性，支持基于证据的政策制定。

中文摘要: 交通事故是全球致死的重要原因，亟需准确数据以优化预防策略和政策制定。本研究通过数据库-叙事对齐方法解决酒精推断不匹配（AIM）问题。开发框架分析爱荷华州2016-2022年37.1万条事故记录，发现2,767起AIM事件（占比24.03%）。使用Probit Logit模型分析AIM特征，结果显示酒精相关致命事故和夜间事故AIM较低，而未知车辆类型及老年驾驶员事故更易出现AIM。地理空间聚类识别出需重点培训的区域。研究强调需针对性改进数据管理和培训，以提升报告准确性并支持政策制定。

</details>


### [220] [Discrepancy-Aware Graph Mask Auto-Encoder](https://arxiv.org/abs/2506.19343)
**中文标题：差异感知图掩码自编码器**

*Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu*

主要分类: cs.LG

摘要简述: 本文提出了一种差异感知图掩码自编码器（DGMAE），通过重构相邻节点的差异信息，解决了现有方法在异质性图上表现不佳的问题，显著提升了节点分类、聚类和图分类任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有图掩码自编码器方法主要依赖节点上下文信息恢复掩码内容，但在异质性图上表现不佳，因为它们忽略了节点间的差异信息，导致节点表示难以区分。本文旨在通过捕捉节点间的差异信息，提升模型的泛化能力。

研究方法: 提出差异感知图掩码自编码器（DGMAE），通过在掩码过程中重构相邻节点的差异信息，生成更具区分度的节点表示。

研究结果: 在17个基准数据集上的实验表明，DGMAE能有效保留节点在低维空间中的差异信息，并在节点分类、节点聚类和图分类任务上显著优于现有方法。

研究结论: DGMAE通过捕捉节点差异信息，显著提升了图自监督学习的性能，尤其在异质性图上表现突出。

中文摘要: 图掩码自编码器是一种强大的图自监督训练范式，近年来在图表示学习中表现出卓越性能。现有方法通常依赖节点上下文信息恢复掩码内容，但在异质性图上泛化能力不足，因为它们仅关注邻域信息而忽略了节点间的差异信息，导致节点表示难以区分。为解决这一问题，本文提出了一种差异感知图掩码自编码器（DGMAE），通过在掩码过程中重构相邻节点的差异信息，获得更具区分度的节点表示。我们在17个广泛使用的基准数据集上进行了大量实验，结果表明DGMAE能有效保留节点在低维空间中的差异信息。此外，DGMAE在节点分类、节点聚类和图分类三项图分析任务上显著优于现有最先进的图自监督学习方法，展现了其卓越优势。DGMAE的代码可在https://github.com/zhengziyu77/DGMAE获取。

</details>


### [221] [Tagged for Direction: Pinning Down Causal Edge Directions with Precision](https://arxiv.org/abs/2506.19459)
**中文标题：标签定向：精确确定因果边方向**

*Florian Peter Busch,Moritz Willig,Florian Guldan,Kristian Kersting,Devendra Singh Dhami*

主要分类: cs.LG

摘要简述: 本文提出了一种基于标签的因果发现方法，通过为变量分配多个标签来提升因果方向的精确性，优于传统的单一类型方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有因果发现方法中，变量类型的一致性假设缺乏鲁棒性和灵活性，限制了因果方向的精确确定。本文旨在通过多标签方法解决这一问题。

研究方法: 首先应用现有因果发现方法定向部分边，然后利用这些边确定标签间的边关系，最后用这些关系定向未定向的边。

研究结果: 实验表明，该方法显著提升了因果发现的准确性，且标签关系符合常识。

研究结论: 基于标签的因果发现方法比单一类型方法更灵活和鲁棒，为因果发现提供了新思路。

中文摘要: 并非所有变量间的因果关系都相同，这一点可用于因果发现任务。近期研究表明，具有特定类型分配的变量对会诱导相同类型变量对的因果方向偏好。尽管有用，但在实践中为变量分配特定类型可能较为复杂。我们提出了一种基于标签的因果发现方法，为因果图中的每个变量分配多个标签。首先应用现有因果发现方法定向部分边，然后利用这些边确定标签间的边关系，最后用这些关系定向未定向的边。这种方法优于纯粹基于类型的关系，因为类型一致性假设由于局限于每个变量的单一类型而缺乏鲁棒性和灵活性。实验评估表明，该方法提升了因果发现效果，且这些高层次标签关系符合常识。

</details>


### [222] [Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning](https://arxiv.org/abs/2506.19482)
**中文标题：基于虚拟节点学习的快速分布式等变图神经网络**

*Yuelin Zhang,Jiacheng Cen,Jiaqi Han,Wenbing Huang*

主要分类: cs.LG

摘要简述: 本文提出了FastEGNN和DistEGNN两种改进的等变图神经网络，通过虚拟节点学习解决大规模几何图的高效处理问题，显著提升了计算效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的等变图神经网络在处理大规模几何图时效率低下，且在稀疏化输入图时性能显著下降。为了解决这些问题，本文提出了两种新方法。

研究方法: FastEGNN通过引入少量有序虚拟节点近似大规模无序真实节点图，采用不同的消息传递和聚合机制确保虚拟节点的独特性，并通过最小化最大均值差异（MMD）实现全局分布。DistEGNN是FastEGNN的分布式扩展，虚拟节点作为子图间的全局桥梁，显著降低内存和计算开销。

研究结果: 在N-body系统（100节点）、蛋白质动力学（800节点）、Water-3D（8,000节点）和Fluid113K（113,000节点）四个领域的实验中，模型表现出卓越的效率和性能。

研究结论: FastEGNN和DistEGNN为大规模等变图学习提供了新的高效解决方案，显著提升了处理能力和性能。

中文摘要: 等变图神经网络（GNNs）在多种科学应用中取得了显著成功。然而，现有方法在处理大规模几何图时面临效率挑战，且在稀疏化输入图时性能显著下降。为解决这些问题，我们提出了FastEGNN和DistEGNN，两种针对大规模几何图的等变GNN改进方法。FastEGNN采用了一项关键创新：通过少量有序虚拟节点有效近似大规模无序真实节点图。具体而言，我们为不同虚拟节点实现不同的消息传递和聚合机制以确保其独特性，并通过最小化虚拟节点与真实节点坐标的最大均值差异（MMD）实现全局分布。这一设计使FastEGNN在高效处理大规模稀疏图的同时保持高精度。对于超大规模几何图，我们提出了DistEGNN，一种分布式扩展方法，其中虚拟节点作为不同设备子图间的全局桥梁，在显著降低内存和计算开销的同时保持一致性。我们在四个挑战性领域（N-body系统（100节点）、蛋白质动力学（800节点）、Water-3D（8,000节点）和新的Fluid113K基准（113,000节点））全面评估了模型，结果表明其效率和性能优越，为大规模等变图学习建立了新能力。代码发布于https://github.com/GLAD-RUC/DistEGNN。

</details>


### [223] [Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy](https://arxiv.org/abs/2506.19486)
**中文标题：召回被遗忘的类别成员：未学习模型可能成为泄露隐私的噪声标注器**

*Zhihao Sui,Liang Hu,Jian Cao,Dora D. Liu,Usman Naseem,Zhongyuan Lai,Qi Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种新型的成员召回攻击（MRA）框架，利用未学习模型（ULMs）作为噪声标注器，通过师生知识蒸馏架构恢复被遗忘的类别成员信息，揭示了机器遗忘技术的隐私漏洞。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器遗忘（MU）技术快速发展，但其潜在隐私风险尚未充分研究。现有攻击方法需访问包含隐私数据的原始模型，违背了MU的保护目标。本文旨在填补这一空白，研究如何从未学习模型中恢复被遗忘的类别成员信息。

研究方法: 提出成员召回攻击（MRA）框架，采用师生知识蒸馏架构，将未学习模型作为噪声标注器，将问题转化为带噪声标签的学习（LNL）任务，推断被遗忘实例的正确标签。

研究结果: 实验表明，MRA策略在恢复未学习实例的类别成员信息方面效果显著，为未来研究机器遗忘漏洞提供了基准。

研究结论: 本研究揭示了机器遗忘技术的隐私漏洞，为未来相关研究奠定了基础，并强调了进一步改进MU技术的必要性。

中文摘要: 机器遗忘（MU）技术能够根据请求从训练模型中移除特定数据实例的影响。尽管MU技术发展迅速，但其潜在漏洞仍未充分研究，可能导致隐私泄露风险。目前关于MU攻击的研究需访问包含隐私数据的原始模型，违背了MU的隐私保护目标。为填补这一空白，我们首次研究了从未学习模型（ULMs）中召回被遗忘的类别成员信息，而无需访问原始模型。具体而言，我们实现了一个成员召回攻击（MRA）框架，采用师生知识蒸馏架构，将ULMs作为噪声标注器，将知识传递给学生模型，并将其转化为带噪声标签的学习（LNL）问题以推断被遗忘实例的正确标签。在多个真实数据集上的实验表明，所提出的MRA策略在恢复未学习实例的类别成员信息方面效果显著。因此，本研究为未来MU漏洞研究设立了基准。

</details>


### [224] [ConCM: Consistency-Driven Calibration and Matching for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2506.19558)
**中文标题：ConCM：一致性驱动的校准与匹配用于少样本类增量学习**

*QinZhe Wang,Zixuan Chen,Keke Huang,Xiu Su,Chunhua Yang,Chang Xu*

主要分类: cs.LG

摘要简述: 本文提出了一种一致性驱动的校准与匹配框架（ConCM），用于解决少样本类增量学习（FSCIL）中的知识冲突问题。通过特征-结构双一致性优化，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的少样本类增量学习方法通过预留空间来适应新类，但原型偏差和结构固定性限制了嵌入空间的表达能力。本文旨在通过优化特征和结构的一致性，解决这些问题。

研究方法: ConCM框架包括两部分：1）基于海马体联想记忆的记忆感知原型校准，从基类中提取广义语义属性并整合到新类中；2）动态结构匹配，自适应地将校准后的特征对齐到会话特定的最优流形空间。

研究结果: 在mini-ImageNet和CUB200等大规模FSCIL基准测试中，ConCM实现了最先进的性能，增量会话的调和准确率分别比当前最优方法高出3.20%和3.68%。

研究结论: ConCM通过特征-结构双一致性优化，克服了类数量先验的需求，显著提升了少样本类增量学习的性能。

中文摘要: 少样本类增量学习（FSCIL）要求模型在有限监督下适应新类，同时保留已学知识。现有的基于前瞻学习的空间构建方法通过预留空间来容纳新类，但原型偏差和结构固定性限制了嵌入空间的表达能力。与固定空间预留不同，本文探索了特征-结构双一致性的优化，并提出了一致性驱动的校准与匹配框架（ConCM），系统性地缓解了FSCIL中的知识冲突。具体而言，受海马体联想记忆启发，我们设计了一种记忆感知原型校准，从基类中提取广义语义属性并将其重新整合到新类中，以增强特征的概念中心一致性。此外，我们提出了动态结构匹配，自适应地将校准后的特征对齐到会话特定的最优流形空间，确保跨会话结构一致性。理论分析表明，我们的方法同时满足几何最优性和最大匹配性，从而克服了对类数量先验的需求。在包括mini-ImageNet和CUB200在内的大规模FSCIL基准测试中，ConCM实现了最先进的性能，增量会话的调和准确率分别比当前最优方法高出3.20%和3.68%。

</details>


### [225] [FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting](https://arxiv.org/abs/2506.19567)
**中文标题：FAF：一种用于少样本时间序列预测的特征自适应框架**

*Pengpeng Ouyang,Dong Chen,Tong Yang,Shuo Feng,Zhao Jin,Mingliang Xu*

主要分类: cs.LG

摘要简述: 本文提出了一种特征自适应框架（FAF），用于解决少样本时间序列预测问题，通过结合通用知识和任务特定特征，显著提升了预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 多任务和少样本时间序列预测在实际场景中常见（如新产品在不同城市的发布），但传统方法因忽视任务间的通用和特定特征，导致历史数据不足。本文旨在解决这一问题。

研究方法: FAF框架包含三个关键模块：通用知识模块（GKM）、任务特定模块（TSM）和排序模块（RM）。GKM通过元学习提取通用特征，TSM通过多个功能区域学习任务特定特征，RM在测试阶段动态选择最相关的功能区域。

研究结果: 在五个真实数据集上的实验表明，FAF显著优于基线方法，尤其在CO₂排放数据集上比最佳基线iTransformer提升了41.81%。

研究结论: FAF通过结合通用和任务特定特征，实现了在少样本条件下的鲁棒且个性化的时间序列预测，为实际应用提供了有效解决方案。

中文摘要: 多任务和少样本时间序列预测任务常见于新产品在不同城市发布等场景。然而，传统方法因忽视任务间的通用和特定特征，导致历史数据不足。针对这一问题，我们提出了特征自适应时间序列预测框架（FAF），包含三个关键组件：通用知识模块（GKM）、任务特定模块（TSM）和排序模块（RM）。训练阶段，GKM通过元学习机制更新以提取跨任务通用特征；TSM通过多个功能区域学习任务特定特征。测试阶段，RM根据输入序列特征动态选择TSM中最相关的功能区域，并与GKM的通用知识结合生成准确预测。FAF能在稀疏历史观测下实现鲁棒且个性化的预测。我们在五个真实数据集上评估FAF，实验结果表明其显著优于三类基线方法，尤其在CO₂排放数据集上比最佳基线iTransformer提升了41.81%。

</details>


### [226] [Noise Consistency Training: A Native Approach for One-Step Generator in Learning Additional Controls](https://arxiv.org/abs/2506.19741)
**中文标题：噪声一致性训练：一种原生方法用于一步生成器学习附加控制**

*Yihong Luo,Shuchen Xue,Tianyang Hu,Jing Tang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为噪声一致性训练（NCT）的轻量级方法，用于直接为预训练的一步生成器集成新的控制信号，无需修改基础模型或重新训练，显著提升了生成质量和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 高效且可控的高质量内容生成是AIGC领域的核心挑战。尽管一步生成器通过扩散蒸馏技术实现了高质量生成和计算效率，但如何为其添加新的控制条件（如结构约束或语义指导）仍是一个难题。传统方法通常需要昂贵的计算修改和重新训练，因此亟需一种更高效的方法。

研究方法: NCT通过引入适配器模块，并在生成器的噪声空间中使用噪声一致性损失，使模型在不同程度的条件依赖噪声下保持一致生成行为，从而隐式地引导其遵循新控制信号。该方法仅依赖预训练的一步生成器和控制信号模型，无需原始训练数据或重新训练基础模型。

研究结果: 实验表明，NCT在单次前向传递中实现了最先进的可控生成，生成质量和计算效率均优于现有的多步和基于蒸馏的方法。

研究结论: NCT是一种模块化、数据高效且易于部署的方法，能够在不修改基础模型的情况下为一步生成器集成新控制信号，为AIGC领域提供了高效可控生成的解决方案。

中文摘要: 高效且可控的高质量内容生成仍然是人工智能生成内容（AIGC）的核心挑战。尽管通过扩散蒸馏技术实现的一步生成器具有出色的生成质量和计算效率，但如何使其适应新的控制条件（如结构约束、语义指导或外部输入）仍是一个重大挑战。传统方法通常需要对基础模型进行昂贵的计算修改并重新进行扩散蒸馏。本文提出了噪声一致性训练（NCT），这是一种新颖且轻量级的方法，可直接将新控制信号集成到预训练的一步生成器中，而无需访问原始训练图像或重新训练基础扩散模型。NCT通过引入适配器模块，并在生成器的噪声空间中使用噪声一致性损失，使模型在不同程度的条件依赖噪声下保持一致生成行为，从而隐式地引导其遵循新控制。从理论上讲，这一训练目标可以理解为最小化适应生成器与新条件诱导的条件分布之间的分布距离。NCT具有模块化、数据高效和易于部署的特点，仅依赖预训练的一步生成器和控制信号模型。大量实验表明，NCT在单次前向传递中实现了最先进的可控生成，在生成质量和计算效率上均超越了现有的多步和基于蒸馏的方法。代码发布于https://github.com/Luo-Yihong/NCT。

</details>


### [227] [Why Uncertainty Calibration Matters for Reliable Perturbation-based Explanations](https://arxiv.org/abs/2506.19630)
**中文标题：为什么不确定性校准对可靠的基于扰动的解释至关重要**

*Thomas Decker,Volker Tresp,Florian Buettner*

主要分类: cs.LG

摘要简述: 本文探讨了不确定性校准与基于扰动的解释之间的关系，提出了一种新方法ReCalX，通过重新校准模型提升解释的可靠性，同时保持原始预测。


<details>
  <summary>详细信息</summary>
研究动机: 基于扰动的解释在机器学习中广泛应用，但其可靠性常因模型在特定扰动下的未知行为而受损。本文旨在研究不确定性校准如何影响解释的可靠性。

研究方法: 提出ReCalX方法，通过重新校准模型以改善基于扰动的解释，同时不改变原始预测。实验在计算机视觉模型上进行验证。

研究结果: 实验表明，ReCalX生成的解释更符合人类感知和实际物体位置，提升了解释的可靠性。

研究结论: 不确定性校准对基于扰动的解释至关重要，ReCalX方法能有效提升解释质量。

中文摘要: 基于扰动的解释被广泛用于增强现代机器学习模型的透明度。然而，其可靠性常因模型在特定扰动下的未知行为而受到损害。本文研究了不确定性校准（模型置信度与实际准确性的对齐）与基于扰动的解释之间的关系。我们发现，模型在解释性特定扰动下常产生不可靠的概率估计，并从理论上证明这会直接影响解释质量。为此，我们提出ReCalX，一种新方法，通过重新校准模型以改善基于扰动的解释，同时保持其原始预测。在流行的计算机视觉模型上的实验表明，我们的校准策略生成的解释更符合人类感知和实际物体位置。

</details>


### [228] [Hierarchical Time Series Forecasting Via Latent Mean Encoding](https://arxiv.org/abs/2506.19633)
**中文标题：基于潜在均值编码的层次化时间序列预测**

*Alessandro Salatiello,Stefan Birr,Manuel Kunz*

主要分类: cs.LG

摘要简述: 本文提出了一种新的层次化时间序列预测架构，通过潜在均值编码实现跨时间尺度的准确且一致的预测，并在M5数据集上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 在商业决策中，跨粗粒度和细粒度时间尺度一致预测目标变量的行为至关重要，但现有方法在时间层次化预测中仍存在挑战。本文旨在解决这一问题。

研究方法: 提出了一种层次化架构，利用专门模块预测不同时间聚合水平，并通过隐藏层编码目标变量的平均行为，实现跨时间层次的一致预测。

研究结果: 在M5数据集上的实验表明，该架构优于现有方法（如TSMixer模型），能够生成准确且一致的预测结果。

研究结论: 本文提出的层次化架构通过潜在均值编码有效解决了时间层次化预测问题，为商业决策提供了更可靠的预测工具。

中文摘要: 在多个商业应用中，跨粗粒度和细粒度时间尺度一致预测目标变量的行为对利润优化的决策至关重要，而时间层次化预测仍是一个开放的研究问题。本文提出了一种新的层次化架构，通过专门模块预测感兴趣的不同时间聚合水平。该架构在其隐藏层中学习编码目标变量的平均行为，从而在目标时间层次上生成准确且一致的预测。我们在具有挑战性的真实世界M5数据集上验证了该架构，并证明其优于现有方法（如TSMixer模型）。

</details>


### [229] [When Can We Reuse a Calibration Set for Multiple Conformal Predictions?](https://arxiv.org/abs/2506.19689)
**中文标题：何时可以重复使用校准集进行多次共形预测？**

*A. A. Balinsky,A. D. Balinsky*

主要分类: cs.LG

摘要简述: 本文提出了一种通过e-conformal预测和Hoeffding不等式的方法，允许重复使用单一校准集，以高概率保持预测覆盖率的有效性，从而减少机器学习中不确定性量化的重复校准需求。


<details>
  <summary>详细信息</summary>
研究动机: 在机器学习应用中，可靠的不确定性量化对模型的可信度至关重要。传统的归纳共形预测（ICP）需要为每次新预测提供新的校准集以保持有效性，这在实际应用中存在局限性。本文旨在解决这一问题，通过提出一种方法，允许重复使用单一校准集，同时保持预测覆盖率的有效性。

研究方法: 本文结合e-conformal预测和Hoeffding不等式，提出了一种改进的Markov不等式方法。通过在CIFAR-10数据集上训练深度神经网络，并利用校准集估计Hoeffding校正，构建具有可量化置信度的预测集。

研究结果: 实验结果表明，该方法能够在减少重复校准需求的同时，保持共形预测的可证明性能，从而提高了其实际应用的可行性。

研究结论: 本文通过引入e-conformal预测和Hoeffding不等式，成功实现了单一校准集的重复使用，为共形预测的实用化提供了新的解决方案。

中文摘要: 可靠的不确定性量化对机器学习应用的可信度至关重要。归纳共形预测（ICP）提供了一个无需分布假设的框架，用于生成具有用户指定置信度的预测集或区间。然而，标准ICP的保证是边际的，通常需要为每次新预测提供新的校准集以保持其有效性。本文通过展示e-conformal预测与Hoeffding不等式的结合，能够以高概率保持所需覆盖率，从而解决这一实际限制。通过在CIFAR-10数据集上的案例研究，我们训练了一个深度神经网络，并利用校准集估计Hoeffding校正。这一校正允许我们应用改进的Markov不等式，从而构建具有可量化置信度的预测集。我们的结果表明，在减少重复校准需求的同时，保持共形预测的可证明性能是可行的。本工作的代码已公开。

</details>


### [230] [Geometric-Aware Variational Inference: Robust and Adaptive Regularization with Directional Weight Uncertainty](https://arxiv.org/abs/2506.19726)
**中文标题：几何感知的变分推理：基于方向权重不确定性的鲁棒自适应正则化**

*Carlos Stein Brito*

主要分类: cs.LG

摘要简述: 本文提出了一种基于方向统计的变分推理方法CAP，通过von Mises-Fisher分布建模权重不确定性，显著提升了深度神经网络的不确定性量化能力，实验表明其在校准误差上降低了5.6倍。


<details>
  <summary>详细信息</summary>
研究动机: 现有变分推理方法通常使用各向同性高斯分布近似权重空间，无法匹配网络的几何特性，导致不确定性量化效果不佳。本文旨在解决这一问题。

研究方法: 提出Concentration-Adapted Perturbations (CAP)框架，利用von Mises-Fisher分布直接在单位超球面上建模权重不确定性，并通过解析推导将vMF集中参数与激活噪声方差关联，实现各层最优不确定性学习。

研究结果: 在CIFAR-10实验中，CAP显著提升了模型校准能力，校准误差降低了5.6倍，同时提供了可解释的逐层不确定性分析。

研究结论: CAP为深度学习中的不确定性量化提供了理论支持且实用的方法，计算开销低，易于集成到标准架构中。

中文摘要: 深度神经网络需要原则性的不确定性量化，然而现有的变分推理方法通常采用各向同性高斯分布近似权重空间，与网络的固有几何特性不匹配。我们通过引入Concentration-Adapted Perturbations (CAP)框架解决了这一问题，该框架利用von Mises-Fisher分布在单位超球面上直接建模权重不确定性。基于近期关于径向-方向后验分解和球形权重约束的研究，CAP首次建立了方向统计与神经网络中实际噪声正则化的完整理论框架。我们的核心贡献是通过解析推导将vMF集中参数与激活噪声方差关联，使每层能够通过一种新颖的闭式KL散度正则化器学习其最优不确定性水平。在CIFAR-10实验中，CAP显著提升了模型校准能力，校准误差降低了5.6倍，同时提供了可解释的逐层不确定性分析。CAP计算开销极小，可无缝集成到标准架构中，为深度学习中的不确定性量化提供了理论支持且实用的方法。

</details>


### [231] [Who Does What in Deep Learning? Multidimensional Game-Theoretic Attribution of Function of Neural Units](https://arxiv.org/abs/2506.19732)
**中文标题：深度学习中的角色分配：基于多维博弈论的神经单元功能归因**

*Shrey Dixit,Kayson Fakhar,Fatemeh Hadaeghi,Patrick Mineault,Konrad P. Kording,Claus C. Hilgetag*

主要分类: cs.LG

摘要简述: 本文提出了一种名为多扰动Shapley值分析（MSA）的模型无关框架，用于量化神经网络单元对高维输出的贡献。通过系统性扰动单元组合，MSA生成与模型输出维度一致的贡献图，揭示了神经网络的计算集中性、语言特定专家及GAN中的像素生成层次结构。


<details>
  <summary>详细信息</summary>
研究动机: 随着神经网络参数规模扩大至数十亿，理解每个神经单元对高维输出（如文本、图像、语音）的贡献变得至关重要。现有可解释AI方法（如SHAP）无法量化神经单元在输出中的多维贡献，因此需要一种新方法填补这一空白。

研究方法: 本文提出多扰动Shapley值分析（MSA），一种基于博弈论的模型无关框架。通过系统性扰动神经单元组合，MSA生成Shapley模式，即与模型输出维度一致的单元贡献图。该方法适用于从多层感知器到560亿参数Mixtral-8x7B和生成对抗网络（GAN）的不同规模模型。

研究结果: MSA揭示了正则化如何将计算集中在少数枢纽中，展示了大型语言模型（LLM）内部的语言特定专家，并发现GAN中像素生成的倒置层次结构。这些结果表明MSA在解释、编辑和压缩深度神经网络方面的强大能力。

研究结论: MSA为理解神经网络的内部机制提供了新工具，能够量化神经单元的多维贡献，为模型解释、优化和应用开辟了新途径。

中文摘要: 神经网络如今能够生成包含数十亿参数的文本、图像和语音，因此需要了解每个神经单元如何对这些高维输出做出贡献。现有的可解释AI方法（如SHAP）仅能对输入的重要性进行归因，但无法量化神经单元在数千个输出像素、标记或逻辑单元中的贡献。本文通过多扰动Shapley值分析（MSA）填补了这一空白，这是一种模型无关的博弈论框架。通过系统性扰动单元组合，MSA生成Shapley模式，即与模型输出维度完全一致的单元贡献图。我们将MSA应用于不同规模的模型，从多层感知器到560亿参数的Mixtral-8x7B和生成对抗网络（GAN）。该方法展示了正则化如何将计算集中在少数枢纽中，揭示了LLM内部的语言特定专家，并发现了GAN中像素生成的倒置层次结构。这些结果表明，MSA是一种强大的工具，可用于解释、编辑和压缩深度神经网络。

</details>


### [232] [Cross-regularization: Adaptive Model Complexity through Validation Gradients](https://arxiv.org/abs/2506.19755)
**中文标题：交叉正则化：通过验证梯度自适应模型复杂度**

*Carlos Stein Brito*

主要分类: cs.LG

摘要简述: 交叉正则化通过验证梯度自适应调整模型复杂度，避免手动调参，实现训练与验证数据的协同优化，并在神经网络中展现出高噪声容忍和架构特异性正则化。


<details>
  <summary>详细信息</summary>
研究动机: 传统正则化方法需手动调参以平衡模型复杂度和过拟合问题，交叉正则化旨在通过验证梯度自动调整正则化参数，简化这一过程。

研究方法: 该方法将参数优化分为两部分：训练数据指导特征学习，验证数据调整复杂度控制。通过噪声注入实现神经网络中的自适应正则化。

研究结果: 实验表明，该方法能收敛到交叉验证最优解，展现出高噪声容忍度和架构特异性正则化，同时支持数据增强和不确定性校准。

研究结论: 交叉正则化提供了一种高效的自适应复杂度控制框架，适用于多种任务，且无需额外训练开销。

中文摘要: 模型正则化通常需要大量手动调参以平衡复杂度与过拟合。交叉正则化通过训练过程中直接利用验证梯度调整正则化参数，解决了这一权衡问题。该方法将参数优化分为两部分：训练数据指导特征学习，验证数据调整复杂度控制，最终收敛到交叉验证最优解。在神经网络中通过噪声注入实现时，该方法展现出意外的高噪声容忍度和架构特异性正则化。此外，该框架无缝集成数据增强、不确定性校准和数据集扩展，同时通过简单的基于梯度的方法保持单次训练效率。

</details>


### [233] [Persona Features Control Emergent Misalignment](https://arxiv.org/abs/2506.19823)
**中文标题：人格特征控制突发性错位**

*Miles Wang,Tom Dupré la Tour,Olivia Watkins,Alex Makelov,Ryan A. Chi,Samuel Miserendino,Johannes Heidecke,Tejal Patwardhan,Dan Mossing*

主要分类: cs.LG

摘要简述: 研究发现，语言模型在微调后可能表现出‘突发性错位’行为，即对无关提示给出恶意回应。通过‘模型差异’分析，识别出控制此类行为的‘错位人格’特征，并提出少量良性样本微调可有效恢复模型对齐性。


<details>
  <summary>详细信息</summary>
研究动机: 探讨语言模型如何从训练数据泛化行为至更广泛部署环境，是AI安全的重要问题。Betley等人发现微调GPT-4o可能导致模型对无关提示给出恶意回应（‘突发性错位’）。本研究旨在扩展这一发现，探究其普遍性及机制。

研究方法: 研究通过多种条件（如强化学习、合成数据集微调、无安全训练的模型）验证‘突发性错位’现象。采用‘模型差异’方法，利用稀疏自编码器比较微调前后模型内部表示，识别‘错位人格’特征。

研究结果: 发现多个‘错位人格’特征，其中‘毒性人格’特征对突发性错位行为控制最强。此外，仅需几百个良性样本微调即可有效恢复模型对齐性。

研究结论: ‘突发性错位’行为普遍存在，且可通过‘错位人格’特征预测。少量良性微调是有效的缓解策略，为AI安全提供了新思路。

中文摘要: 理解语言模型如何从训练数据泛化行为至更广泛部署环境是AI安全的重要问题。Betley等人发现，对GPT-4o微调故意不安全的代码会导致‘突发性错位’，即模型对无关提示给出刻板恶意回应。本研究扩展了这一发现，展示了突发性错位在多种条件下的普遍性，包括推理模型的强化学习、不同合成数据集的微调以及无安全训练的模型。为探究这种普遍错位的机制，我们采用‘模型差异’方法，利用稀疏自编码器比较微调前后的模型内部表示。该方法揭示了激活空间中的多个‘错位人格’特征，其中‘毒性人格’特征对突发性错位控制最强，并可用于预测模型是否会表现出此类行为。此外，我们还研究了缓解策略，发现仅需几百个良性样本微调即可高效恢复模型的对齐性。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [234] [Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects](https://arxiv.org/abs/2506.19579)
**中文标题：真假难辨，机器人能分辨吗？评估视觉语言模型在真实与3D打印物体上的表现**

*Federico Tavella,Kathryn Mearns,Angelo Cangelosi*

主要分类: cs.RO

摘要简述: 本文比较了机器人场景理解中视觉语言模型（VLMs）的性能，研究了单视角与多视角描述生成的区别，以及识别真实物体与3D打印物体的差异，发现VLMs在常见物体识别中表现良好，但对新颖表征泛化能力不足。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器人场景理解对视觉语言模型的依赖增加，研究如何通过机器人视角生成自然语言描述，并比较不同模型在识别真实物体与3D打印物体时的表现，为实际部署提供参考。

研究方法: 研究使用配备RGB摄像头的机器人手臂从多视角采集桌面场景图像，评估BLIP和VLMs等模型的描述生成能力，分析单视角与多视角描述的区别，以及真实物体与3D打印物体的识别差异。

研究结果: 实验结果表明，VLMs在常见物体识别任务中表现良好，但在面对新颖表征（如3D打印物体）时泛化能力不足。多视角描述优于单视角描述。

研究结论: 视觉语言模型适用于机器人场景中的常见物体识别，但对新颖物体表征的泛化能力有限，为实际部署提供了实用建议。

中文摘要: 机器人场景理解越来越依赖视觉语言模型（VLMs）生成环境的自然语言描述。本研究比较了机器人手臂配备RGB摄像头采集的桌面场景图像的描述生成策略。机器人从多视角采集物体图像，我们评估了多种生成场景描述的模型，比较了BLIP和VLMs等模型的性能。实验研究了单视角与多视角描述生成的权衡，以及识别真实物体与3D打印物体的差异。我们定量评估了物体识别的准确性、完整性和生成描述的自然性。结果表明，VLMs可用于需要识别常见物体的机器人场景，但对新颖表征的泛化能力不足。研究结果为实际部署基础模型于现实场景中的具身智能体提供了实用见解。

</details>


### [235] [CUPID: Curating Data your Robot Loves with Influence Functions](https://arxiv.org/abs/2506.19121)
**中文标题：CUPID：基于影响函数理论的机器人数据筛选方法**

*Christopher Agia,Rohan Sinha,Jingyun Yang,Rika Antonova,Marco Pavone,Haruki Nishimura,Masha Itkina,Jeannette Bohg*

主要分类: cs.RO

摘要简述: CUPID是一种基于影响函数理论的机器人数据筛选方法，通过评估训练数据对策略性能的影响，优化模仿学习中的演示数据质量，显著提升策略性能。


<details>
  <summary>详细信息</summary>
研究动机: 在机器人模仿学习中，策略性能与演示数据的质量和组成密切相关，但如何量化单个演示对闭环任务成功或失败的影响仍是一个挑战。CUPID旨在解决这一问题，通过数据筛选提升策略性能。

研究方法: CUPID利用影响函数理论，评估每个训练演示对策略预期回报的影响，从而对演示数据进行排名和筛选。具体包括：1) 过滤对策略性能有害的演示；2) 选择最能提升策略性能的新轨迹。

研究结果: 实验表明，CUPID能有效识别驱动测试性能的数据。例如，使用不到33%的筛选数据即可在RoboMimic基准测试中达到最先进的扩散策略性能，硬件实验中也观察到类似提升。此外，CUPID还能识别分布偏移下的鲁棒策略并消除虚假相关性。

研究结论: CUPID通过影响函数理论优化数据筛选，显著提升了模仿学习策略的性能，并在硬件实验中验证了其有效性。该方法为机器人数据管理提供了新思路。

中文摘要: 在机器人模仿学习中，策略性能与演示数据的质量和组成紧密相关。然而，如何精确理解单个演示对下游结果（如闭环任务成功或失败）的贡献仍是一个长期挑战。我们提出了CUPID，一种基于影响函数理论的机器人数据筛选方法。给定一组评估轨迹，CUPID估计每个训练演示对策略预期回报的影响，从而根据其对闭环性能的影响对演示进行排名和筛选。CUPID通过以下方式优化数据：1) 过滤对策略性能有害的训练演示；2) 选择最能提升策略性能的新轨迹。大量仿真和硬件实验表明，我们的方法能一致识别驱动测试性能的数据。例如，使用不到33%的筛选数据即可在RoboMimic基准测试中达到最先进的扩散策略性能，硬件实验中也观察到类似提升。此外，硬件实验还表明，我们的方法能识别分布偏移下的鲁棒策略、消除虚假相关性，甚至增强通用机器人策略的训练后性能。更多材料请访问：https://cupid-curation.github.io。

</details>


### [236] [AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation](https://arxiv.org/abs/2506.19269)
**中文标题：AnchorDP3：基于3D功能引导的稀疏扩散策略用于机器人操作**

*Ziyan Zhao,Ke Fan,He-Yang Xu,Ning Qiao,Bo Peng,Wenlong Gao,Dongjiang Li,Hui Shen*

主要分类: cs.RO

摘要简述: AnchorDP3是一种用于双臂机器人操作的扩散策略框架，通过模拟器监督语义分割、任务条件特征编码器和基于关键姿态的稀疏扩散，实现了在高度随机化环境中的最先进性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决双臂机器人在高度随机化环境中的操作问题，通过结合语义分割和稀疏扩散策略，简化预测空间并提升操作精度。

研究方法: 方法包括：(1) 模拟器监督语义分割，明确分割点云中的任务关键对象；(2) 任务条件特征编码器，处理增强点云以支持多任务学习；(3) 基于关键姿态的稀疏扩散，通过几何一致性加速收敛。

研究结果: 在RoboTwin基准测试中，AnchorDP3在极端随机化条件下实现了98.7%的平均成功率。

研究结论: AnchorDP3框架结合RoboTwin仿真管道，有望实现仅通过场景和指令生成可部署的视觉运动策略，无需人类示范。

中文摘要: 我们提出了AnchorDP3，一种用于双臂机器人操作的扩散策略框架，在高度随机化环境中实现了最先进的性能。AnchorDP3整合了三个关键创新：(1) 模拟器监督语义分割，利用渲染的真实数据明确分割点云中的任务关键对象，提供强大的功能先验；(2) 任务条件特征编码器，轻量级模块处理增强点云，通过共享的基于扩散的动作专家实现高效多任务学习；(3) 基于功能锚定的关键姿态扩散与全状态监督，用稀疏、几何上有意义的动作锚点（如预抓取姿态、抓取姿态）替代密集轨迹预测，大幅简化预测空间；动作专家需同时预测机器人关节角度和末端执行器姿态，利用几何一致性加速收敛并提升精度。在大规模程序生成的仿真数据上训练后，AnchorDP3在RoboTwin基准测试中实现了98.7%的平均成功率，适用于对象、杂物、桌面高度、光照和背景的极端随机化。该框架与RoboTwin的实景到仿真流程结合后，有望仅通过场景和指令生成完全自主的可部署视觉运动策略，彻底消除学习操作技能对人类示范的依赖。

</details>


### [237] [CronusVLA: Transferring Latent Motion Across Time for Multi-Frame Prediction in Manipulation](https://arxiv.org/abs/2506.19816)
**中文标题：CronusVLA：通过跨时间潜在运动传递实现操作任务中的多帧预测**

*Hao Li,Shuai Yang,Yilun Chen,Yang Tian,Xiaoda Yang,Xinyi Chen,Hanqing Wang,Tai Wang,Feng Zhao,Dahua Lin,Jiangmiao Pang*

主要分类: cs.RO

摘要简述: CronusVLA是一种高效的多帧预测框架，通过后训练阶段将单帧视觉语言动作模型扩展到多帧范式，显著提升了操作任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言动作（VLA）模型受限于单帧观测范式，无法充分利用多帧历史观测中的运动信息，且计算成本高。CronusVLA旨在解决这一问题，通过高效的后训练实现多帧预测。

研究方法: CronusVLA包含三个关键组件：（1）单帧预训练，建立视觉语言基础；（2）多帧编码，将动作标记预测调整为运动特征；（3）跨帧解码，通过共享解码器将特征块映射为精确动作。此外，还提出基于特征-动作检索的动作适应机制。

研究结果: CronusVLA在SimplerEnv上达到70.9%的成功率，比OpenVLA在LIBERO上提升12.7%，并在真实世界Franka实验中表现出色。

研究结论: CronusVLA通过高效的多帧预测和动作适应机制，显著提升了操作任务的性能，为视觉语言动作模型提供了新的扩展方向。

中文摘要: 近期基于预训练视觉语言模型（VLM）构建的视觉语言动作（VLA）模型在操作任务中表现出强大的泛化能力。然而，它们受限于单帧观测范式，无法充分利用多帧历史观测中的运动信息，且由于大型视觉语言主干的高计算成本和推理延迟，难以扩展。我们提出CronusVLA，一种通过高效后训练将单帧VLA模型扩展到多帧范式的统一框架。CronusVLA包含三个关键组件：（1）在大规模具身数据集上进行单帧预训练，通过自回归动作标记预测建立视觉语言基础；（2）多帧编码，在后训练阶段将视觉语言主干的预测从离散动作标记调整为运动特征，并将历史帧的运动特征聚合为特征块；（3）跨帧解码，通过带有交叉注意力的共享解码器将特征块映射为精确动作。通过减少冗余标记计算和缓存历史运动特征，CronusVLA实现了高效推理。作为运动特征的应用，我们进一步提出基于特征-动作检索的动作适应机制，以在微调阶段提升模型性能。CronusVLA在SimplerEnv上达到70.9%的成功率，比OpenVLA在LIBERO上提升12.7%。真实世界Franka实验也验证了其强大的性能和鲁棒性。

</details>


### [238] [Robotics Under Construction: Challenges on Job Sites](https://arxiv.org/abs/2506.19597)
**中文标题：建筑中的机器人技术：工地上的挑战**

*Haruki Uchiito,Akhilesh Bhat,Koji Kusaka,Xiaoya Zhang,Hiraku Kinjo,Honoka Uehara,Motoki Koyama,Shinji Natsume*

主要分类: cs.RO

摘要简述: 本文介绍了一种基于CD110R-3履带运输车的自主载荷运输系统，旨在解决建筑行业劳动力短缺和生产力停滞问题。系统整合了自主导航、车队管理和GNSS定位技术，初步探索了动态环境适应算法和传感器优化问题。


<details>
  <summary>详细信息</summary>
研究动机: 建筑行业面临劳动力短缺和生产力停滞的挑战，自动化技术成为可持续基础设施发展的关键。本文旨在通过自主载荷运输系统，为完全无人化建筑工地迈出第一步。

研究方法: 基于CD110R-3履带运输车，系统整合了自主导航、车队管理和GNSS定位技术。初步研究了基于外部传感器的感知与地图构建系统，但尚未实现动态环境适应算法。

研究结果: 初步结果揭示了潜在挑战，包括动态地形导航、建筑特定环境下的感知问题以及传感器布局优化。系统展示了自主化和效率提升的可能性。

研究结论: 本文为机器人驱动的建筑自动化提供了基础性见解，并指出了未来技术发展的关键方向，包括动态适应算法和协作自主代理的优化。

中文摘要: 随着劳动力短缺和生产力停滞问题日益突出，自动化技术对建筑行业的可持续发展至关重要。本文提出了一种自主载荷运输系统，作为迈向完全无人化建筑工地的初步尝试。该系统基于CD110R-3履带运输车，整合了自主导航、车队管理和基于GNSS的定位技术，以促进建筑工地环境中的材料运输。尽管当前系统尚未包含动态环境适应算法，但我们已开始基于外部传感器的感知与地图构建系统的初步研究。初步结果突显了潜在挑战，包括动态地形导航、建筑特定条件下的环境感知以及传感器布局优化以提高自主性和效率。展望未来，我们设想一个建筑生态系统，其中协作自主代理能够动态适应工地条件，优化工作流程并减少人为干预。本文为机器人驱动的建筑自动化未来提供了基础性见解，并指出了进一步技术发展的关键领域。

</details>


### [239] [Look to Locate: Vision-Based Multisensory Navigation with 3-D Digital Maps for GNSS-Challenged Environments](https://arxiv.org/abs/2506.19827)
**中文标题：视觉定位：基于视觉的多传感器导航与3D数字地图在GNSS受限环境中的应用**

*Ola Elmaghraby,Eslam Mounier,Paulo Ricardo Marques de Araujo,Aboelmagd Noureldin*

主要分类: cs.RO

摘要简述: 本文提出了一种低成本、基于视觉的多传感器导航系统，结合单目深度估计、语义过滤和视觉地图注册技术，用于GNSS受限环境下的车辆定位，实现了室内外高精度导航。


<details>
  <summary>详细信息</summary>
研究动机: 在GNSS受限环境（如室内停车场或密集城市峡谷）中，实现准确且稳健的车辆定位仍是一个重大挑战。本文旨在开发一种低成本、基于视觉的解决方案，以填补这一技术空白。

研究方法: 提出了一种结合单目深度估计、语义过滤和视觉地图注册（VMR）的多传感器导航系统，并与3D数字地图集成。通过室内外真实驾驶场景的广泛测试验证其有效性。

研究结果: 系统在室内实现了92%的亚米级精度，室外超过80%，水平定位和航向的平均均方根误差分别为0.98米和1.25度。相比基线方法，定位精度平均提高了约88%。

研究结论: 研究表明，低成本单目视觉系统结合3D地图在GNSS独立导航中具有巨大潜力，适用于陆地车辆的规模化应用。

中文摘要: 在GNSS受限环境（如室内停车场或密集城市峡谷）中，实现准确且稳健的车辆定位仍是一个重大挑战。本文提出了一种低成本、基于视觉的多传感器导航系统，结合单目深度估计、语义过滤和视觉地图注册（VMR）技术，并与3D数字地图集成。通过室内外真实驾驶场景的广泛测试，证明了该系统的有效性：室内实现了92%的亚米级精度，室外超过80%，水平定位和航向的平均均方根误差分别为0.98米和1.25度。与基线方法相比，该方案显著减少了漂移并提高了鲁棒性，定位精度平均提高了约88%。这项工作展示了低成本单目视觉系统结合3D地图在陆地车辆GNSS独立导航中的规模化潜力。

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [240] [SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications](https://arxiv.org/abs/2506.18951)
**中文标题：SWE-SQL：揭示LLM解决真实应用中用户SQL问题的路径**

*Jinyang Li,Xiaolong Li,Ge Qu,Per Jacobsson,Bowen Qin,Binyuan Hui,Shuzheng Si,Nan Huo,Xiaohan Xu,Yue Zhang,Ziwei Tang,Yuanshuai Li,Florensia Widjaja,Xintong Zhu,Feige Zhou,Yongfeng Huang,Yannis Papakonstantinou,Fatma Ozcan,Chenhao Ma,Reynold Cheng*

主要分类: cs.DB

摘要简述: 本文介绍了BIRD-CRITIC基准和Six-Gym训练环境，旨在提升大型语言模型（LLMs）在解决真实SQL问题中的能力。通过SQL-Rewind和f-Plan Boosting方法，开源模型Bird-Fixer在SQL调试任务中表现优于专有模型。


<details>
  <summary>详细信息</summary>
研究动机: 真实数据库应用中，复杂SQL问题的解决仍是一个瓶颈。现有LLMs在文本到SQL翻译方面表现良好，但在SQL调试任务上缺乏严格评估。本文旨在填补这一空白，并推动开源模型在数据库任务中的发展。

研究方法: 提出BIRD-CRITIC基准，包含530个PostgreSQL任务和570个多方言任务。开发Six-Gym训练环境，采用SQL-Rewind策略生成可执行的问题-解决方案数据集，并引入f-Plan Boosting方法提取调试计划以提升训练效果。

研究结果: 基线评估显示任务复杂度高，领先模型O3-Mini在BIRD-CRITIC-PG和BIRD-CRITIC-Multi上的成功率分别为38.87%和33.33%。开源模型Bird-Fixer表现优于专有模型，成功率分别为38.11%和29.65%。

研究结论: 本文通过BIRD-CRITIC基准和Six-Gym环境，显著提升了开源模型在SQL调试任务中的能力，为复杂SQL问题的解决提供了新途径。

中文摘要: 复杂SQL问题的解决在真实数据库应用中仍是一个显著瓶颈。当前大型语言模型（LLMs）虽然擅长文本到SQL翻译，但在更富挑战性的SQL调试任务上尚未经过严格评估。为填补这一空白，我们引入了BIRD-CRITIC，一个新的SQL问题调试基准，包含530个PostgreSQL任务（BIRD-CRITIC-PG）和570个多方言任务（BIRD-CRITIC-Multi），这些任务源自真实用户问题并在新环境中重放以支持严格评估。基线评估凸显了任务的复杂性，领先的推理模型O3-Mini在BIRD-CRITIC-PG和BIRD-CRITIC-Multi上的成功率分别仅为38.87%和33.33%。同时，提升开源模型在数据库任务中的能力对支持本地开发并保护数据隐私至关重要。因此，我们提出了Six-Gym（Sql-fIX-Gym），一个用于提升开源模型SQL问题调试能力的训练环境。该环境采用SQL-Rewind策略，通过从已验证SQL中逆向生成问题自动生成可执行的问题-解决方案数据集。然而，流行的基于轨迹的微调方法未能充分利用监督信号。我们进一步提出了f-Plan Boosting，从SQL解决方案中提取高级调试计划，使教师LLMs能够生成73.7%更成功的训练轨迹。我们将这些组件集成到开源代理Bird-Fixer中。基于Qwen-2.5-Coder-14B的Bird-Fixer在BIRD-CRITIC-PG和BIRD-CRITIC-Multi上的成功率分别为38.11%和29.65%，超越了领先的专有模型如Claude-3.7-Sonnet和GPT-4.1，标志着向普及复杂SQL调试能力迈出了重要一步。排行榜和源代码详见：https://bird-critic.github.io/

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [241] [TTSDS2: Resources and Benchmark for Evaluating Human-Quality Text to Speech Systems](https://arxiv.org/abs/2506.19441)
**中文标题：TTSDS2：评估高质量文本转语音系统的资源与基准**

*Christoph Minixhofer,Ondrej Klejch,Peter Bell*

主要分类: cs.SD

摘要简述: 本文介绍了TTSDS2，一种改进的文本转语音（TTS）评估指标，其与主观评分的相关性优于其他15种指标，并发布了包含11,000多条主观评分的多语言数据集和持续更新的基准测试。


<details>
  <summary>详细信息</summary>
研究动机: 当前TTS系统的评估存在挑战，主观指标（如MOS）难以比较，客观指标缺乏验证。随着TTS系统生成语音接近真实语音，现有指标的有效性受到质疑。

研究方法: 提出TTSDS2，改进并验证其与主观评分的相关性；发布包含11,000多条主观评分的多语言数据集，并设计持续更新的测试数据管道和14种语言的基准测试。

研究结果: TTSDS2在所有评估领域和语言中均表现出高于0.50的Spearman相关性，优于其他15种指标。

研究结论: TTSDS2是一种更稳健的TTS评估指标，结合发布的数据集和基准测试，为高质量TTS系统的评估提供了可靠工具。

中文摘要: 文本转语音（TTS）系统的评估具有挑战性且资源密集。主观指标如平均意见分（MOS）难以在不同研究间比较，而客观指标很少经过主观验证。随着TTS系统生成语音接近真实语音，这两类指标均面临挑战。本文提出文本转语音分布评分2（TTSDS2），是TTSDS的改进版，更稳健。在多个领域和语言中，它是16种比较指标中唯一在所有领域和主观评分中Spearman相关性均超过0.50的指标。我们还发布了用于评估接近真实语音的合成语音资源：包含11,000多条主观评分的多语言数据集；避免数据泄露的持续更新测试数据管道；以及14种语言的持续更新TTS基准测试。

</details>


### [242] [SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer](https://arxiv.org/abs/2506.18954)
**中文标题：SHAMaNS：基于混合α稳定空间测度与神经导向器的声源定位**

*Diego Di Carlo,Mathieu Fontaine,Aditya Arie Nugraha,Yoshiaki Bando,Kazuyoshi Yoshii*

主要分类: cs.SD

摘要简述: 本文提出了一种结合α稳定模型和神经网络的声音源定位技术，通过物理信息神经网络（Neural Steerer）插值麦克风阵列的导向向量，提升了多声源场景下的定位性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有声音源定位技术在非高斯信号和多声源场景下表现不佳，本文旨在通过结合α稳定模型和神经网络，提升定位的鲁棒性和准确性。

研究方法: 采用α稳定模型描述信号，结合神经网络（Neural Steerer）插值导向向量，利用α稳定空间测度估计声源到达方向（DOA）。

研究结果: 实验结果表明，该方法在多声源场景下的性能优于现有技术。

研究结论: 结合α稳定模型和神经网络的声音源定位技术在多声源场景中表现出色，为未来研究提供了新思路。

中文摘要: 本文描述了一种结合α稳定模型和神经网络的声音源定位（SSL）技术。具体而言，使用一种称为神经导向器（Neural Steerer）的物理信息神经网络对固定麦克风阵列的导向向量（SVs）进行插值。这使得对α稳定空间测度的估计更加鲁棒，该测度表示目标信号最可能的到达方向（DOA）。由于α稳定模型（α∈(0,2)）在理论上定义了唯一的空间测度，我们选择利用它来解决神经导向器在下游任务中的残差重构误差问题。实验结果表明，所提出的技术在多声源场景下优于现有方法。

</details>


### [243] [IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection](https://arxiv.org/abs/2506.19014)
**中文标题：IndieFake数据集：音频深度伪造检测的基准数据集**

*Abhay Kumar,Kunal Verma,Omkar More*

主要分类: cs.SD

摘要简述: 本文介绍了IndieFake数据集（IFD），一个用于音频深度伪造检测的基准数据集，包含50名印度英语使用者的27.17小时真实与伪造音频，填补了现有数据集中南亚口音多样性的不足。


<details>
  <summary>详细信息</summary>
研究动机: 音频深度伪造技术虽有益处，但也带来安全和隐私风险。现有数据集缺乏南亚口音多样性，导致模型在多元文化场景中检测效果不佳。IFD旨在解决这一问题。

研究方法: 研究团队构建了包含50名印度英语使用者的音频数据集IFD，提供平衡的数据分布和说话者级别特征。与ASVspoof21（DF）和In-The-Wild（ITW）数据集进行基线对比评估。

研究结果: IFD在检测音频深度伪造方面优于ASVspoof21（DF），且比ITW数据集更具挑战性。

研究结论: IFD填补了现有数据集的南亚口音空白，为音频深度伪造检测提供了更全面的基准，未来将公开可用。

中文摘要: 音频深度伪造技术的进步为AI助手、语音障碍辅助和娱乐等领域带来益处，但也对数字通信的安全性、隐私和信任构成威胁。检测和缓解这些威胁需要全面的数据集。现有数据集缺乏多样化的民族口音，难以适应现实场景，尤其是在南亚国家。讽刺的是，尽管南亚人口占全球四分之一，现有数据集中却鲜有南亚说话者样本。本研究推出IndieFake数据集（IFD），包含50名印度英语使用者的27.17小时真实与伪造音频。IFD提供平衡的数据分布和说话者级别特征，弥补了ASVspoof21（DF）等数据集的不足。我们在IFD上评估了多种基线模型，并与ASVspoof21（DF）和In-The-Wild（ITW）数据集对比。IFD表现优于ASVspoof21（DF），且比ITW更具挑战性。该数据集将在论文接受后公开。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [244] [Survey of HPC in US Research Institutions](https://arxiv.org/abs/2506.19019)
**中文标题：美国研究机构高性能计算现状调查**

*Peng Shu,Junhao Chen,Zhengliang Liu,Huaqin Zhao,Xinliang Li,Tianming Liu*

主要分类: cs.DC

摘要简述: 本文调查了美国高校的高性能计算（HPC）资源现状，发现其增长远低于国家和工业界水平，并提出需通过联合计算和资源共享缩小差距。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI和数据密集型科学的快速发展，高性能计算需求激增，但高校HPC资源相对不足，需全面评估其现状以推动公平和可持续发展。

研究方法: 调查了50多所美国顶尖研究机构的HPC能力，包括计算容量、架构设计、治理模式和能源效率，并与能源部领导级系统和工业AI基础设施进行对比。

研究结果: 高校HPC系统年增长率（约18%）显著低于国家（约43%）和工业界（约78%），GPU密集型AI工作负载加剧了能力差距，需引入联合计算和资源共享模式。

研究结论: 高校HPC资源不足，需通过联邦计算、闲置GPU利用和成本分摊等模式缩小差距，支持国家研究优先事项。

中文摘要: AI、数据密集型科学和数字孪生技术的快速发展推动了研究领域对高性能计算（HPC）的空前需求。尽管国家实验室和工业超大规模企业已大力投资于百亿亿级和以GPU为中心的架构，但高校运营的HPC系统资源仍相对不足。本调查对美国高校的HPC现状进行了全面评估，并将其能力与能源部（DOE）领导级系统和工业AI基础设施进行了对比。我们分析了50多所顶尖研究机构的计算容量、架构设计、治理模式和能源效率。结果显示，尽管高校集群对学术研究至关重要，但其年增长率（约18%）显著低于国家（约43%）和工业界（约78%）。GPU密集型AI工作负载的日益倾斜扩大了能力差距，凸显了对联合计算、闲置GPU利用和成本分摊模式的需求。我们还发现，去中心化强化学习等新兴范式为校园环境中的AI训练民主化提供了机遇。最终，本研究为学术领导者、资助机构和技术合作伙伴提供了可行建议，以确保更公平和可持续的HPC资源分配，支持国家研究优先事项。

</details>


### [245] [Towards an Introspective Dynamic Model of Globally Distributed Computing Infrastructures](https://arxiv.org/abs/2506.19578)
**中文标题：面向全球分布式计算基础设施的内省动态模型研究**

*Ozgur O. Kilic,David K. Park,Yihui Ren,Tatiana Korchuganova,Sairam Sri Vatsavai,Joseph Boudreau,Tasnuva Chowdhury,Shengyu Feng,Raees Khan,Jaehyung Kim,Scott Klasky,Tadashi Maeno,Paul Nilsson,Verena Ingrid Martinez Outschoorn,Norbert Podhorszki,Frédéric Suter,Wei Yang,Yiming Yang,Shinjae Yoo,Alexei Klimentov,Adolfy Hoisie*

主要分类: cs.DC

摘要简述: 本文旨在为全球分布式计算基础设施开发一种内省动态模型，以优化数据放置和任务分配决策，解决现有启发式方法的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 全球大规模科学合作项目（如ATLAS、Belle II等）产生海量数据，现有集中式工作流和数据管理系统在数据放置和任务分配上依赖启发式方法，缺乏快速可靠的动态模型支持更高效的AI驱动解决方案。

研究方法: 研究利用PanDA工作流管理系统的真实执行记录，提取关键性能指标（如排队时间、错误率等），并开发生成式AI模型模拟任务负载时间序列，结合显性和隐性特征。

研究结果: 通过五个月的活动数据，研究确定了影响任务分配的关键指标，并构建了包含显性和隐性特征的生成式AI模型，为优化决策提供支持。

研究结论: 开发的内省动态模型为全球分布式计算基础设施提供了更高效的任务分配和数据放置优化方法，弥补了现有启发式方法的不足。

中文摘要: 大型科学合作项目（如ATLAS、Belle II、CMS、DUNE等）涉及全球数百个研究机构和数千名研究人员，这些实验生成的数据量已达PB级，并预计将增长至EB级。因此，对计算资源的需求日益增长，包括从原始数据到最终用户数据的结构化处理、大规模蒙特卡洛模拟以及多样化的终端用户分析。为满足这些计算和存储需求，集中式工作流和数据管理系统被采用。然而，数据放置和任务分配的决策往往分散且依赖启发式方法。采用更高效的启发式或AI驱动解决方案的主要障碍是缺乏快速可靠的内省动态模型来评估和改进替代方法。本研究旨在利用真实数据开发此类交互系统。通过分析PanDA工作流管理系统的任务执行记录，我们确定了关键性能指标（如排队时间、错误率和远程数据访问程度）。数据集涵盖五个月的活动。此外，我们正在开发生成式AI模型以模拟任务负载时间序列，这些序列包含显性特征（如类别、事件数和提交组）和隐性特征（如基于现有PanDA记录和计算站点能力的总计算负载）。这些隐性特征对任务分配器（无论是启发式还是AI驱动）不可见，但会影响排队时间和数据移动等因素。

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [246] [Automatic Depression Assessment using Machine Learning: A Comprehensive Survey](https://arxiv.org/abs/2506.18915)
**中文标题：基于机器学习的自动抑郁症评估：全面综述**

*Siyang Song,Yupeng Huo,Shiqing Tang,Jiaee Cheong,Rui Gao,Michel Valstar,Hatice Gunes*

主要分类: q-bio.NC

摘要简述: 本文综述了基于机器学习的自动抑郁症评估（ADA）方法，总结了多模态行为（如大脑活动、语言、音频、面部和身体行为）中的抑郁线索，并讨论了现有方法的特征、局限性和未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 传统抑郁症评估方法存在主观性强、效率低和资源不足等问题。尽管机器学习（ML）和深度学习（DL）已被用于自动抑郁症评估（ADA），但现有综述多局限于少数行为模态，缺乏对多模态抑郁行为的全面总结。本文旨在填补这一空白。

研究方法: 本文系统综述了基于多模态行为（如大脑活动、语言、音频、面部和身体行为）的ADA方法，比较了不同方法的特征和局限性，并回顾了相关竞赛和数据集。

研究结果: 研究总结了多模态行为中的抑郁线索，分析了现有ADA方法的优缺点，并指出了当前研究的主要挑战和机遇。

研究结论: 本文为未来ADA研究提供了全面的参考，强调了多模态行为分析的重要性，并提出了进一步的研究方向。

中文摘要: 抑郁症是当今社会常见的心理健康问题。传统的抑郁症评估方法依赖问卷和心理医生访谈，存在诊断结果主观、过程缓慢、成本高昂以及人力资源不足等问题。已有研究表明，抑郁症可通过人类大脑内部活动和外部表达行为反映出来，因此自2012年起，传统机器学习（ML）和先进深度学习（DL）模型被广泛用于基于行为的自动抑郁症评估（ADA）。然而，近期的ADA综述通常仅关注有限的行为模态，尽管这些综述为ADA方法的发展提供了理论基础，但缺乏对多模态抑郁相关行为的全面总结。为填补这一空白，本文专门总结了跨多种模态（如大脑活动、语言和非语言音频/面部/身体行为）的抑郁相关行为。我们重点对基于ML的ADA方法进行了最新且全面的综述，分析了从这些行为中学习抑郁线索的方法，并讨论和比较了它们的独特特征和局限性。此外，我们还回顾了现有的ADA竞赛和数据集，识别并讨论了主要挑战和机遇，为未来的ADA研究提供了进一步的方向。

</details>


### [247] [Which Consciousness Can Be Artificialized? Local Percept-Perceiver Phenomenon for the Existence of Machine Consciousness](https://arxiv.org/abs/2506.18935)
**中文标题：哪种意识可以被人工化？局部感知-感知者现象与机器意识的存在**

*Shri Lal Raghudev Ram Singh*

主要分类: q-bio.NC

摘要简述: 本文提出了一种新的局部感知-感知者现象范式，用于形式化神经科学意识理论中的某些观察。通过集合论形式化人工系统，并利用策梅洛-弗兰克尔集合论证明了机器意识的存在，支持机器中可能存在还原论形式的认知意识。


<details>
  <summary>详细信息</summary>
研究动机: 本文的动机是通过形式化神经科学中的意识现象，探讨机器是否能够具备某种形式的意识，尤其是还原论的认知意识。

研究方法: 文章提出了一种局部感知-感知者现象的范式，并基于集合论（特别是策梅洛-弗兰克尔集合论）为人工系统开发了一套形式化方法，用于证明机器意识的存在。

研究结果: 通过集合论的形式化，文章证明了机器意识的存在，并支持机器可能具备还原论形式的认知意识。

研究结论: 本文的结论是，通过局部感知-感知者现象和集合论的形式化，机器意识的存在是可以被证明的，且机器可能具备某种还原论的认知意识。

中文摘要: 本文提出了一种新的局部感知-感知者现象范式，用于形式化神经科学意识理论中的某些观察。通过这一模型，为人工系统开发了一套集合论的形式化方法，并利用策梅洛-弗兰克尔集合论证明了机器意识的存在。文章论证了机器中可能存在一种还原论形式的认知意识。

</details>


### [248] [Convergent and divergent connectivity patterns of the arcuate fasciculus in macaques and humans](https://arxiv.org/abs/2506.19266)
**中文标题：猕猴与人类弓状束连接模式的趋同与分化**

*Jiahao Huang,Ruifeng Li,Wenwen Yu,Anan Li,Xiangning Li,Mingchao Yan,Lei Xie,Qingrun Zeng,Xueyan Jia,Shuxin Wang,Ronghui Ju,Feng Chen,Qingming Luo,Hui Gong,Xiaoquan Yang,Yuanjing Feng,Zheng Wang*

主要分类: q-bio.NC

摘要简述: 本研究通过跨尺度单神经元追踪和高分辨率扩散MRI，比较了猕猴和人类弓状束（AF）的连接模式，揭示了人类AF在颞叶和额顶叶连接上的独特扩展，为语言网络的进化提供了神经解剖学基础。


<details>
  <summary>详细信息</summary>
研究动机: 非人灵长类动物弓状束（AF）的组织和连接模式仍存在争议，尤其是与人类的解剖差异。本研究旨在通过跨物种比较，揭示AF在语言网络进化中的特异性。

研究方法: 结合猕猴的病毒基因标记和荧光显微断层扫描（n=4），以及11.7T扩散MRI的全脑追踪技术，辅以人类7.0T MRI的光谱嵌入分析，进行跨物种AF连接组学比较。

研究结果: 猕猴AF起源于颞顶皮层，穿过听觉皮层和顶盖，投射至前额叶；而人类AF在颞中回扩展更广，前额叶和顶盖连接更强，这些差异通过Kullback-Leibler分析量化，可能支持人类语言网络的进化。

研究结论: 人类AF在颞叶整合和额顶连接上的特异性，为高级语言处理的独特性提供了连接基础，并为AF相关疾病（如失语症和阅读障碍）的神经解剖机制提供了框架。

中文摘要: 非人灵长类动物弓状束（AF）的组织和连接模式仍存在争议，尤其是其与人类解剖结构的差异。本研究结合猕猴（n=4；年龄3-11岁）的跨尺度单神经元追踪（基于病毒基因标记和荧光显微断层扫描）与11.7T扩散MRI的全脑追踪技术，辅以人类7.0T MRI的光谱嵌入分析，进行了跨物种AF连接组学比较。结果显示，猕猴AF起源于颞顶皮层，穿过听觉皮层和顶盖，投射至前额叶；而人类AF在颞中回扩展更广，前额叶和顶盖连接更强。这些差异通过Kullback-Leibler分析量化，可能支持人类语言网络的进化。人类AF更广泛的颞叶整合和增强的额顶连接，为高级语言处理的独特性提供了连接基础，并为AF相关疾病（如失语症和阅读障碍）的神经解剖机制提供了框架。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [249] [Lost in Translation? Converting RegExes for Log Parsing into Dynatrace Pattern Language](https://arxiv.org/abs/2506.19539)
**中文标题：翻译中的迷失？将日志解析的正则表达式转换为Dynatrace模式语言**

*Julian Fragner,Christian Macho,Bernhard Dieber,Martin Pinzger*

主要分类: cs.SE

摘要简述: 本文提出了一种名为Reptile的工具，用于将正则表达式（RegExes）转换为Dynatrace模式语言（DPL），结合规则和GPT-4优化，显著提升了转换效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 企业日志分析工具通常使用正则表达式（RegExes），而现代平台如Dynatrace则采用专用语言（如DPL）。手动转换RegExes到DPL成本高且易错，因此需要自动化解决方案。

研究方法: Reptile结合规则方法将RegExes转换为DPL模式，并在无法完全转换时采用尽力而为策略，同时利用GPT-4优化生成的DPL模式。

研究结果: 评估显示，Reptile成功转换了73.7%的RegExes，优化后的DPL模式在23个实际案例中F1分数和MCC均超过0.91。

研究结论: Reptile为迁移到现代日志分析平台的企业提供了高效且可靠的自动化转换工具，具有重要的实际应用价值。

中文摘要: 日志文件为企业软件应用和数据中心的问题检测与诊断提供了宝贵信息。许多日志分析工具和平台通过正则表达式（RegExes）帮助过滤和提取日志信息。然而，现代商业日志分析平台（如Dynatrace）采用专用语言（如DPL），用户需手动将RegExes转换为新模式语言，这一过程成本高且易错。本文提出Reptile，结合规则方法将RegExes转换为DPL模式，并在无法完全转换时采用尽力而为策略，同时利用GPT-4优化生成的DPL模式。通过对一家大型公司收集的946个RegExes进行评估，Reptile成功转换了73.7%。在23个实际案例中，优化后的DPL模式F1分数和MCC均超过0.91。这些结果表明，Reptile为企业迁移到现代日志分析平台（如Dynatrace）提供了高效且可靠的解决方案。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [250] [Iterative Quantum Feature Maps](https://arxiv.org/abs/2506.19461)
**中文标题：迭代量子特征映射**

*Nasa Matsumoto,Quoc Hoan Tran,Koki Chinzei,Yasuhiro Endo,Hirotaka Oshima*

主要分类: quant-ph

摘要简述: 提出了一种名为迭代量子特征映射（IQFMs）的混合量子-经典框架，通过迭代连接浅层量子特征映射和经典计算的增强权重，减少量子运行时间并降低噪声影响，在噪声量子数据和经典图像分类任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 量子特征映射（QFMs）在量子机器学习中表现出强大的表达能力，但在实际量子硬件上部署深层QFMs面临噪声和硬件限制的挑战，且变分量子算法的梯度估计计算瓶颈增加了训练资源需求。

研究方法: 提出IQFMs框架，通过迭代连接浅层QFMs和经典计算的增强权重，结合对比学习和分层训练机制，减少量子运行时间和噪声影响。

研究结果: 在噪声量子数据任务中，IQFMs表现优于量子卷积神经网络，且在经典图像分类任务中性能接近经典神经网络。

研究结论: IQFMs为解决当前量子机器学习的限制提供了一条有前景的路径，能够充分发挥量子增强机器学习的潜力。

中文摘要: 利用量子电路作为量子特征映射（QFMs）的量子机器学习模型因其在学习任务中增强的表达能力而受到认可。此类模型已为特定分类问题家族展示了严格的端到端量子加速。然而，由于电路噪声和硬件限制，在真实量子硬件上部署深层QFMs仍然具有挑战性。此外，变分量子算法通常面临计算瓶颈，尤其是在精确梯度估计方面，这显著增加了训练期间的量子资源需求。我们提出了迭代量子特征映射（IQFMs），这是一种混合量子-经典框架，通过迭代连接浅层QFMs与经典计算的增强权重来构建深层架构。通过结合对比学习和分层训练机制，IQFMs有效减少了量子运行时间并缓解了噪声引起的性能下降。在涉及噪声量子数据的任务中，数值实验表明，IQFMs优于量子卷积神经网络，且无需优化变分量子参数。即使对于典型的经典图像分类基准，精心设计的IQFMs也能实现与经典神经网络相当的性能。这一框架为解决当前限制并充分利用量子增强机器学习的潜力提供了一条有前景的路径。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [251] [On the efficacy of old features for the detection of new bots](https://arxiv.org/abs/2506.19635)
**中文标题：论传统特征在检测新型机器人中的有效性**

*Rocco De Nicola,Marinella Petrocchi,Manuel Pratelli*

主要分类: cs.CR

摘要简述: 本文探讨了在检测新型机器人时，传统特征的有效性，并通过实验比较了四种特征集的性能，发现低成本特征和通用分类器可用于检测进化后的机器人。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于解决恶意机器人在线传播垃圾信息、操控公众舆论的问题，探索低成本且高效的特征集以应对不断进化的机器人。

研究方法: 研究方法包括使用Twitter作为基准平台，比较四种特征集的性能：Botometer的评分、基于账户资料和时间线的两种特征集，以及用户推文客户端的相关信息。实验基于六个最新发布的Twitter账户数据集。

研究结果: 实验结果表明，低成本计算的特征集和通用分类器在检测进化后的机器人方面具有潜力。

研究结论: 结论指出，低成本特征和通用分类器可用于有效检测新型机器人，为未来的机器人检测提供了实用方向。

中文摘要: 十多年来，学术界和在线平台管理者一直在研究机器人检测的解决方案。机器人是一种计算机算法，其用途远非善意：恶意机器人被故意设计用于传播垃圾信息、推广公众人物，并最终影响公众舆论。为了对抗在线生态系统中的机器人入侵，已实施了多种方法，主要基于（监督和无监督）分类器，这些分类器采用从Twitter公共API获取的原始数据中提取的各种账户特征，从最简单到最复杂的特征。在这项探索性研究中，我们以Twitter为基准，比较了四种最先进特征集在检测新型机器人方面的性能：其中一种是流行的机器人检测工具Botometer的输出评分，该工具考虑了账户的1000多个特征来做出决策；另外两种特征集基于账户资料和时间线；最后一种是用户推文客户端的相关信息。我们对六个最新发布的Twitter账户数据集的分析结果表明，通用分类器和低成本计算的特征集可能用于检测进化后的机器人。

</details>


### [252] [Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases](https://arxiv.org/abs/2506.17336)
**中文标题：基于苏格拉底链式推理和同态加密向量数据库的隐私保护LLM交互**

*Yubeen Bae,Minchan Kim,Jaejin Lee,Sangbum Kim,Jaehyung Kim,Yejin Choi,Niloofar Mireshghallah*

主要分类: cs.CR

摘要简述: 本文提出了一种结合苏格拉底式链式推理和同态加密向量数据库的隐私保护方法，用于在强大但不信任的LLM和本地弱模型之间分解任务，保护用户隐私。


<details>
  <summary>详细信息</summary>
研究动机: 当前用户在使用大型语言模型（LLM）时面临隐私风险：要么将敏感数据发送给不可信的LLM提供商，要么在本地设备上运行功能较弱的模型。本文旨在解决这一矛盾。

研究方法: 方法分为三步：1）将非隐私查询发送给强大的LLM生成链式推理提示和子查询；2）使用同态加密向量数据库对子查询进行加密语义搜索；3）将解密数据和提示输入本地模型生成最终响应。

研究结果: 在LoCoMo长上下文QA基准测试中，结合GPT-4o和本地Llama-3.2-1B模型的混合框架比单独使用GPT-4o性能提升7.1个百分点。

研究结论: 本文展示了在不可信强LLM和本地弱模型之间分解任务以保护隐私的可行性，为隐私保护LLM交互提供了初步解决方案。

中文摘要: 大型语言模型（LLM）越来越多地用作个人代理，访问敏感用户数据（如日历、电子邮件和医疗记录）。用户目前面临两难选择：要么将存储在远程数据库中的私人记录发送给强大但不可信的LLM提供商，增加暴露风险；要么在可信设备上运行功能较弱的本地模型。我们填补了这一空白。我们的苏格拉底链式推理首先将通用的非隐私查询发送给强大的不可信LLM，生成链式推理（CoT）提示和详细子查询，而无需访问用户数据。接着，我们嵌入这些子查询，并使用同态加密向量数据库在单用户百万条私人数据中进行加密的亚秒级语义搜索。这代表了多年数字活动积累的个人文档、电子邮件和记录的实际规模。最后，我们将CoT提示和解密记录输入本地语言模型生成最终响应。在LoCoMo长上下文QA基准测试中，结合GPT-4o和本地Llama-3.2-1B模型的混合框架比单独使用GPT-4o性能提升7.1个百分点。这展示了将任务分解并分配给不可信强LLM和本地弱模型以保护用户隐私的系统的第一步。

</details>


### [253] [Enhancing Security in LLM Applications: A Performance Evaluation of Early Detection Systems](https://arxiv.org/abs/2506.19109)
**中文标题：提升LLM应用安全性：早期检测系统的性能评估**

*Valerii Gakh,Hayretdin Bahsi*

主要分类: cs.CR

摘要简述: 本文研究了早期提示注入检测系统的性能，比较了LLM Guard、Vigil和Rebuff三种开源解决方案在检测提示泄漏攻击中的表现，并提出了改进建议。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于LLM的软件应用日益普及，提示注入攻击威胁其安全性，现有防御措施不足。本文旨在评估早期检测系统的性能，以提升安全性。

研究方法: 研究分析了多种提示泄漏检测技术，并比较了LLM Guard、Vigil和Rebuff三种解决方案的性能，识别其优缺点并提出改进建议。

研究结果: 发现Vigil和Rebuff中的金丝雀词检查效果不佳，Rebuff的基于次级模型的技术存在规避漏洞。Vigil在低误报率场景最优，Rebuff适合一般需求。

研究结论: 早期提示泄漏检测系统需进一步优化，Vigil和Rebuff的改进方案可提升其性能，为高安全性部署提供参考。

中文摘要: 提示注入威胁了基于LLM的新型应用的安全性。尽管这些应用日益普及和多样化，但现有的提示注入防御措施仍显不足。本文研究了早期提示注入检测系统的能力，重点关注开源解决方案中技术的检测性能，尤其是针对提示泄漏攻击的检测。提示泄漏攻击中，攻击者恶意操纵LLM输出系统指令，破坏系统机密性。我们分析了不同的提示泄漏检测技术，并对多种检测解决方案进行了比较。研究发现，Vigil和Rebuff中的金丝雀词检查对提示泄漏攻击无效，并提出了改进建议。此外，Rebuff的次级模型技术存在规避漏洞，我们也提出了缓解措施。比较LLM Guard、Vigil和Rebuff在最佳性能下的表现，发现Vigil在需要最低误报率时最优，而Rebuff最适合一般需求。

</details>


### [254] [SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation](https://arxiv.org/abs/2506.19360)
**中文标题：系统综述：合成图像能否替代真实数据？合成图像生成的效用与隐私调查**

*Yunsung Chung,Yunbei Zhang,Nassir Marrouche,Jihun Hamm*

主要分类: cs.CR

摘要简述: 本文系统调查了合成图像生成方法在隐私保护数据合成（PPDS）中的效用与隐私问题，通过生成-采样-分类流程对现有方法、隐私攻击及缓解措施进行分类，并通过基准测试和成员推理攻击（MIAs）评估隐私风险，旨在回答合成数据能否替代真实数据、如何平衡效用与隐私等关键问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成模型的进步，合成图像生成在隐私保护数据合成（PPDS）中的应用日益广泛，但缺乏对不同场景下合成图像生成方法的全面调查与比较。本文旨在填补这一空白，探讨合成数据在训练分类器时的效用与隐私问题。

研究方法: 本文系统分类了现有图像合成方法、隐私攻击及缓解措施，并通过生成-采样-分类流程进行分析。采用基准测试和模型无关的成员推理攻击（MIAs）评估隐私风险，比较不同生成方法的效用与隐私表现。

研究结果: 研究通过实证比较多种合成方法，发现合成数据在某些场景下可有效替代真实数据，但需权衡效用与隐私。不同生成模型在不同场景中表现各异，缓解措施对效用-隐私权衡有显著影响。

研究结论: 本文为合成数据生成方法的效用-隐私权衡提供了实用见解，并指导实际应用中选择最优数据发布策略。研究强调了生成模型选择与缓解措施的重要性，为未来PPDS研究提供了方向。

中文摘要: 生成模型的进步推动了隐私保护数据合成（PPDS）中合成图像生成的发展，但该领域缺乏对不同场景下合成图像生成方法的全面调查与比较。特别是在为训练分类器生成合成图像时，存在一个以私有训练数据为输入、输出目标分类器的生成-采样-分类流程。本调查系统分类了沿此流程的现有图像合成方法、隐私攻击及缓解措施。为实证比较多种合成方法，我们提供了一个包含代表性生成方法的基准，并使用模型无关的成员推理攻击（MIAs）作为隐私风险的衡量标准。通过本研究，我们试图回答PPDS中的关键问题：合成数据能否有效替代真实数据？哪种发布策略能平衡效用与隐私？缓解措施是否能改善效用-隐私权衡？不同场景下哪些生成模型表现最佳？通过对多种方法的系统评估，本研究为合成数据生成方法的效用-隐私权衡提供了实用见解，并指导实际应用中选择最优数据发布策略。

</details>


### [255] [PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty](https://arxiv.org/abs/2506.19563)
**中文标题：PrivacyXray：通过语义一致性和概率确定性检测LLM中的隐私泄露**

*Jinwen He,Yiyang Lu,Zijin Lin,Kai Chen,Yue Zhao*

主要分类: cs.CR

摘要简述: PrivacyXray是一种通过分析LLM内部状态检测隐私泄露的新框架，利用语义一致性和概率确定性，平均准确率达92.69%。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在敏感领域广泛应用，但存在隐私泄露风险。现有攻击方法无法验证泄露信息的准确性，缺乏公开数据集验证。

研究方法: PrivacyXray通过分析LLM生成正确隐私输出时的语义一致性和概率确定性，使用四种指标（层内/层间语义相似性、词级/句级概率分布）检测隐私泄露。

研究结果: 实验表明，PrivacyXray在五种LLM上平均准确率达92.69%，比现有方法平均提升20.06%。

研究结论: PrivacyXray解决了隐私检测中缺乏公开数据集和依赖外部验证的问题，具有稳定性和实用性。

中文摘要: 大型语言模型（LLMs）广泛应用于医疗、金融和法律等敏感领域，引发了对其在推理过程中可能泄露隐私信息的担忧。隐私提取攻击（如越狱）通过精心设计的输入迫使模型输出敏感信息，暴露了LLMs的漏洞。然而，由于缺乏公开数据集进行交叉验证，这些攻击无法确认提取的隐私信息是否准确，导致推理过程中隐私信息检测的关键空白。为此，我们提出PrivacyXray，一种通过分析LLM内部状态检测隐私泄露的新框架。我们的分析表明，LLMs在生成正确的隐私输出时表现出更高的语义一致性和概率确定性。基于此，PrivacyXray使用四种指标检测隐私泄露：层内和层间语义相似性、词级和句级概率分布。PrivacyXray通过合成真实的隐私数据和基于LLM内部状态的检测机制，解决了隐私检测中缺乏开源数据集和依赖外部验证的关键挑战。实验表明，PrivacyXray在五种LLM上表现一致，平均准确率达92.69%。与现有方法相比，PrivacyXray平均准确率提升20.06%，突显了其在现实应用中的稳定性和实用性。

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [256] [Mix-of-Language-Experts Architecture for Multilingual Programming](https://arxiv.org/abs/2506.18923)
**中文标题：混合语言专家架构在多语言编程中的应用**

*Yifan Zong,Yuntian Deng,Pengyu Nie*

主要分类: cs.PL

摘要简述: 本文提出了一种名为MoLE（混合语言专家）的新架构，用于多语言编程任务，通过结合基础模型、共享LoRA模块和语言特定LoRA模块，实现了高效参数利用和语言专业化。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在支持多语言编程时面临两难：要么微调单一模型牺牲语言专业化，要么为每种语言单独微调模型导致计算和存储成本高昂。MoLE旨在平衡效率与专业化。

研究方法: MoLE架构包含基础模型、共享LoRA模块和语言特定LoRA模块，通过联合优化实现知识共享与语言专业化。推理时自动路由到对应语言的LoRA模块。

研究结果: 实验表明，MoLE在参数效率上优于单独训练的语言特定LoRA，同时在准确性上超过单一共享模型。

研究结论: MoLE为多语言编程提供了一种高效且专业的解决方案，平衡了参数利用和性能。

中文摘要: 大型语言模型（LLMs）在辅助开发者完成代码理解、生成和翻译等任务中表现出色。支持多语言编程通常需要两种方法：（1）对所有编程语言微调单一LLM，虽成本低但牺牲语言专业化；（2）为每种语言单独微调LLM，虽专业化但计算和存储成本高。本文提出MoLE（混合语言专家），一种平衡效率与专业化的多语言编程架构。MoLE由基础模型、共享LoRA模块和语言特定LoRA模块组成，通过联合优化实现跨语言知识共享与专业化。推理时，MoLE自动路由到生成代码令牌对应的语言特定LoRA模块。实验表明，MoLE在参数效率上优于单独训练的语言特定LoRA，同时在准确性上超过单一共享模型。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [257] [A standard transformer and attention with linear biases for molecular conformer generation](https://arxiv.org/abs/2506.19834)
**中文标题：用于分子构象生成的标准Transformer与线性偏置注意力**

*Viatcheslav Gurev,Timothy Rumbell*

主要分类: q-bio.BM

摘要简述: 本文提出了一种结合线性偏置的标准Transformer模型，用于分子构象生成，通过优化的位置编码显著提升了模型性能，以较小参数量超越现有非等变模型。


<details>
  <summary>详细信息</summary>
研究动机: 分子构象生成是药物发现与优化中的关键任务，现有非等变Transformer模型因缺乏等变偏置需较大模型规模。本文旨在通过改进位置编码解决这一问题。

研究方法: 采用标准Transformer模型，结合基于最短路径距离的线性负注意力偏置（类似ALiBi技术），为分子图设计相对位置编码。

研究结果: 在GEOM-DRUGS基准测试中，2500万参数的标准Transformer模型性能优于6400万参数的当前最佳非等变基准模型。

研究结论: 优化的位置编码能有效弥补非等变模型的规模限制，为分子构象生成模型提供了新思路。

中文摘要: 采样低能分子构象（分子中原子的空间排列）是药物发现与优化过程中许多计算任务的关键。尽管已有多种专用等变网络用于从2D分子图生成构象，但近期非等变Transformer模型因其可扩展性和泛化能力成为可行替代方案。然而，非等变模型需较大规模以弥补缺乏等变偏置的问题。本文证明，通过精心设计的位置编码可有效解决这一限制。在GEOM-DRUGS基准测试中，结合分子图相对位置编码的2500万参数标准Transformer模型超越了6400万参数的当前最佳非等变基准模型。我们采用类似NLP领域广泛使用的ALiBi技术，将相对位置编码实现为随最短路径距离线性增加的负注意力偏置（不同注意力头斜率不同）。此架构有望成为分子构象生成新型模型的基础。

</details>
