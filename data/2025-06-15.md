<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 173]
- [cs.CV](#cs.CV) [Total: 238]
- [cs.AI](#cs.AI) [Total: 81]
- [cs.SD](#cs.SD) [Total: 8]
- [cs.MM](#cs.MM) [Total: 24]
- [cs.IR](#cs.IR) [Total: 10]
- [cs.NI](#cs.NI) [Total: 2]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [physics.med-ph](#physics.med-ph) [Total: 2]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.CY](#cs.CY) [Total: 4]
- [cs.LG](#cs.LG) [Total: 78]
- [cs.CR](#cs.CR) [Total: 35]
- [eess.SY](#eess.SY) [Total: 4]
- [cs.MA](#cs.MA) [Total: 2]
- [eess.SP](#eess.SP) [Total: 2]
- [cs.HC](#cs.HC) [Total: 4]
- [cs.GR](#cs.GR) [Total: 13]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.RO](#cs.RO) [Total: 16]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.GT](#cs.GT) [Total: 2]
- [physics.ao-ph](#physics.ao-ph) [Total: 2]
- [eess.IV](#eess.IV) [Total: 18]
- [cs.LO](#cs.LO) [Total: 4]
- [eess.AS](#eess.AS) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations](https://arxiv.org/abs/2506.10019)
**中文标题：文本、视觉与语音生成的自动评估方法综述**

*Tian Lan,Yang-Hao Zhou,Zi-Ao Ma,Fanshu Sun,Rui-Qing Sun,Junyu Luo,Rong-Cheng Tu,Heyan Huang,Chen Xu,Zhijing Wu,Xian-Ling Mao*

Main category: cs.CL

TL;DR: The paper provides a comprehensive review and unified taxonomy of automatic evaluation methods for text, image, and audio generation, identifying five fundamental paradigms and suggesting future research directions.


<details>
  <summary>Details</summary>
Motivation: The lack of a systematic framework for evaluating generative AI outputs across text, images, and audio modalities motivated this review.

Method: The authors review and organize existing evaluation methods for text generation, then extend the framework to image and audio generation, identifying five common paradigms.

Result: A unified taxonomy of automatic evaluation methods for text, visual, and speech generation is presented, along with insights into cross-modal evaluation.

Conclusion: The paper highlights the need for further research in cross-modal evaluation methodologies and provides a foundation for future work.

摘要: 近年来，深度学习的发展显著提升了生成式AI在文本、图像和音频领域的能力。然而，如何自动评估这些生成内容的质量仍是一个持续的挑战。尽管已有许多自动评估方法，但目前的研究缺乏一个系统性的框架，能够全面组织这些方法以覆盖文本、视觉和音频模态。为解决这一问题，本文对这三种模态的生成内容自动评估方法进行了全面综述，并提出了一种统一的分类法。我们识别了五种基本范式，用于描述这些领域的现有评估方法。我们的分析首先考察了文本生成的评估方法，这些技术最为成熟。随后，我们将这一框架扩展到图像和音频生成，证明了其广泛的适用性。最后，我们讨论了跨模态评估方法未来研究的有前景方向。

</details>


### [2] [TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org/abs/2506.10055)
**中文标题：TaskCraft：自动化生成代理任务的工具**

*Dingfeng Shi,Jingyi Cao,Qianben Chen,Weichen Sun,Weizhen Li,Hongxuan Lu,Fangchen Dong,Tianrui Qin,King Zhu,Minghao Yang,Jian Yang,Ge Zhang,Jiaheng Liu,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: TaskCraft introduces an automated workflow to generate scalable, multi-tool agentic tasks, addressing limitations in existing instruction data and benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing agentic task benchmarks rely on costly human annotation and lack tool interaction, limiting scalability and utility for NLP/AI advancement.

Method: TaskCraft uses depth-based and width-based extensions to expand atomic tasks into complex challenges, creating a synthetic dataset of 36,000 tasks.

Result: The generated tasks improve prompt optimization and enhance supervised fine-tuning of agentic foundation models.

Conclusion: TaskCraft provides a scalable solution for generating agentic tasks, supporting future research on agent tuning and evaluation.

摘要: 代理任务需要多步骤的问题解决能力、自主性、工具使用和适应性推理，在NLP和AI领域日益重要。然而，现有的指令数据缺乏工具交互，当前的代理基准依赖昂贵的人工标注，限制了其扩展性。我们提出了TaskCraft，一种自动化工作流，用于生成难度可扩展、多工具且可验证的代理任务及其执行轨迹。TaskCraft通过深度和宽度扩展原子任务，创建结构和层次复杂的挑战。实验结果表明，这些任务改进了生成工作流中的提示优化，并增强了代理基础模型的监督微调。我们提供了一个包含约36,000个不同难度任务的大规模合成数据集，以支持未来关于代理调优和评估的研究。

</details>


### [3] [A quantum semantic framework for natural language processing](https://arxiv.org/abs/2506.10077)
**中文标题：自然语言处理的量子语义框架**

*Christopher J. Agostino,Quan Le Thien,Molly Apsel,Denizhan Pak,Elina Lesyk,Ashabari Majumdar*

Main category: cs.CL

TL;DR: The paper argues that semantic degeneracy in natural language makes it impossible for any interpreter (human or AI) to recover a single intended meaning as complexity grows. It proposes an observer-dependent view of meaning and demonstrates non-classical contextuality in linguistic interpretation through experiments with LLMs, suggesting Bayesian approaches over classical methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitations of modern NLP systems and LLMs due to semantic degeneracy, which complicates the recovery of intended meanings as language complexity increases. The paper challenges the classical view of meaning as inherent in linguistic forms.

Method: The method involves using Kolmogorov complexity to argue the vanishing likelihood of recovering intended meanings and conducting a semantic Bell inequality test with LLMs as computational cognitive systems to interpret ambiguous word pairs under varied contexts.

Result: The experiments showed CHSH expectation values (1.2 to 2.8) that violate classical boundaries, indicating non-classical contextuality in linguistic interpretation, similar to human cognition results.

Conclusion: The conclusion is that classical frequentist approaches to NLP are lossy, and Bayesian-style repeated sampling is more suitable for characterizing linguistic meaning in context.

摘要: 语义退化是自然语言的一个基本属性，它不仅超越了简单的多义性，还涵盖了随着语义表达复杂性增加而出现的潜在解释的组合爆炸。大型语言模型（LLMs）和其他现代自然语言处理系统之所以面临固有局限性，正是因为它们在自然语言本身中运行，使其受到语义退化所施加的相同解释约束。在这项工作中，我们利用柯尔莫哥洛夫复杂性论证，随着表达复杂性的增长，任何解释主体（人类或LLM驱动的AI）恢复单一预期意义的可能性消失。这种计算上的难处理性表明，传统认为语言形式本身具有意义的观点是错误的。我们提出，意义是通过依赖于观察者的解释行为实现的。为了验证这一点，我们使用多样化的LLM代理作为“计算认知系统”，在不同上下文设置下解释模糊词对，进行了语义贝尔不等式测试。在多个独立实验中，我们发现平均CHSH期望值在1.2到2.8之间，其中多次运行的结果（如2.3-2.4）显著违反了经典边界（|S|≤2）。这表明在模糊性下的语言解释可以表现出非经典的上下文相关性，与人类认知实验结果一致。这些结果隐含地表明，基于经典频率分析的自然语言方法必然是有损的。相反，我们提出贝叶斯式的重复采样方法可以更实用和适当地描述上下文中的语言意义。

</details>


### [4] [Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information](https://arxiv.org/abs/2506.10086)
**中文标题：思维对话：用于生成领域特定信息的协作多智能体系统**

*Christodoulos Constantinides,Shuxin Lin,Nianjun Zhou,Dhaval Patel*

Main category: cs.CL

TL;DR: The paper introduces Chat-of-Thought, a multi-agent LLM-based system for generating FMEA documents in industrial settings, using dynamic collaboration and iterative refinement.


<details>
  <summary>Details</summary>
Motivation: To address the challenges in generating accurate and comprehensive FMEA documents for industrial assets by leveraging collaborative AI agents.

Method: Employs multiple LLM-based agents with specific roles, dynamic task routing, and a Chat of Thought mechanism for iterative content refinement.

Result: Demonstrates the system's potential in optimizing FMEA table generation and validation through interactive, template-driven workflows.

Conclusion: Chat-of-Thought offers a promising approach for industrial equipment monitoring by enhancing collaboration and context-awareness in AI-driven workflows.

摘要: 本文提出了一种名为思维对话的新型多智能体系统，旨在为工业资产生成故障模式与影响分析（FMEA）文档。该系统利用多个具有特定角色的协作性大型语言模型（LLM）智能体，结合先进的AI技术和动态任务路由，优化FMEA表的生成和验证。该系统的关键创新在于引入了思维对话机制，通过动态、多角色驱动的讨论实现内容的迭代优化。本研究探讨了工业设备监控的应用领域，突出了关键挑战，并通过交互式、模板驱动的工作流程和上下文感知的智能体协作，展示了思维对话在应对这些挑战中的潜力。

</details>


### [5] [When Meaning Stays the Same, but Models Drift: Evaluating Quality of Service under Token-Level Behavioral Instability in LLMs](https://arxiv.org/abs/2506.10095)
**中文标题：当意义不变而模型漂移：评估大语言模型在标记级行为不稳定性下的服务质量**

*Xiao Li,Joel Kreuzwieser,Alan Peters*

Main category: cs.CL

TL;DR: The paper investigates how large language models (LLMs) respond to semantically equivalent prompts with different token-level realizations, introducing a framework (PBSS) to measure behavioral drift. Results show model-specific response shifts linked to tokenization and decoding, highlighting instability in model evaluation under rephrasing.


<details>
  <summary>Details</summary>
Motivation: To understand and measure the behavioral instability of LLMs when faced with semantically equivalent prompts that differ only in token-level realization, a phenomenon termed 'prompt variance.'

Method: Proposes Prompt-Based Semantic Shift (PBSS), a diagnostic framework to evaluate behavioral drift in LLMs under semantically equivalent prompt rewordings, tested on ten constrained tasks.

Result: PBSS reveals consistent, model-specific response shifts, indicating statistical regularities tied to tokenization and decoding, which affect post-training quality of service stability.

Conclusion: Tokenization strategies and decoding dynamics contribute to instability in LLM responses under semantically equivalent rephrasing, suggesting a need for improved evaluation methods.

摘要: 我们研究了大语言模型如何响应仅在标记级实现不同但语义意图相同的提示，这一现象称为提示方差。我们提出了基于提示的语义漂移（PBSS），一种用于测量LLM在语义等效提示重述下行为漂移的诊断框架。应用于十个受限任务，PBSS揭示了与标记化和解码相关的模型特定响应漂移。这些结果凸显了在重述下模型评估稳定性的一个被忽视的维度，并表明标记化策略和解码动态可能影响训练后服务质量的不稳定性。

</details>


### [6] [ChartReasoner: Code-Driven Modality Bridging for Long-Chain Reasoning in Chart Question Answering](https://arxiv.org/abs/2506.10116)
**中文标题：ChartReasoner：代码驱动的模态桥接用于图表问答中的长链推理**

*Caijun Jia,Nan Xu,Jingxuan Wei,Qingli Wang,Lei Wang,Bihui Yu,Junnan Zhu*

Main category: cs.CL

TL;DR: ChartReasoner is a code-driven framework for precise chart question answering, converting charts to structured ECharts codes and using synthesized data for multimodal reasoning, achieving competitive performance with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Existing multimodal approaches lose critical visual details in chart question answering; ChartReasoner aims to preserve structural and semantic information through code-driven reasoning.

Method: A two-stage framework: (1) converting charts to ECharts codes, (2) synthesizing chart reasoning data and training a multimodal model with fine-tuning and reinforcement learning.

Result: ChartReasoner performs comparably to state-of-the-art models with fewer parameters and approaches GPT-4o performance in out-of-domain settings.

Conclusion: ChartReasoner effectively bridges the gap in visual reasoning by preserving chart details and enabling interpretable, scalable reasoning.

摘要: 最近，大型语言模型通过长链推理在回答问题方面表现出卓越的能力。然而，如何将这种能力扩展到视觉推理任务仍是一个开放性问题。现有的多模态推理方法通过多次图像到文本的转换将视觉推理任务转化为文本推理任务，但往往会丢失可视化中嵌入的关键结构和语义信息，尤其是在需要大量视觉细节的图表问答任务中。为弥补这一差距，我们提出了ChartReasoner，一种代码驱动的两阶段框架，旨在实现对图表的精确、可解释推理。我们首先训练一个高保真模型，将多样化的图表图像转换为结构化的ECharts代码，尽可能无损地保留布局和数据语义。然后，我们设计了一个通用的图表推理数据合成流程，利用预训练的传输模型自动且可扩展地生成图表推理轨迹，并使用代码验证器过滤低质量样本。最后，我们在合成的图表推理数据集上结合监督微调和强化学习训练最终的多模态模型。在四个公共基准上的实验结果清楚地证明了ChartReasoner的有效性。它能够尽可能保留图表的原始细节，并在使用较少参数的情况下与最先进的开源模型表现相当，接近GPT-4o等专有系统在域外设置中的性能。

</details>


### [7] [Unsupervised Elicitation of Language Models](https://arxiv.org/abs/2506.10139)
**中文标题：无监督引导语言模型**

*Jiaxin Wen,Zachary Ankner,Arushi Somani,Peter Hase,Samuel Marks,Jacob Goldman-Wetzler,Linda Petrini,Henry Sleight,Collin Burns,He He,Shi Feng,Ethan Perez,Jan Leike*

Main category: cs.CL

TL;DR: The paper introduces an unsupervised algorithm, Internal Coherence Maximization (ICM), to fine-tune pretrained language models without human supervision, achieving performance comparable to or better than human-supervised methods on various tasks.


<details>
  <summary>Details</summary>
Motivation: Current post-training methods rely on human supervision, which is challenging for models with superhuman capabilities. The paper aims to develop an unsupervised approach to elicit these capabilities.

Method: The proposed method, ICM, fine-tunes pretrained language models using their own generated labels, eliminating the need for external human supervision.

Result: ICM matches or outperforms human-supervised methods on tasks like GSM8k-verification, TruthfulQA, and Alpaca reward modeling, especially for superhuman-capable models. It also improves frontier LM training, as demonstrated by an unsupervised reward model and assistant based on Claude 3.5 Haiku.

Conclusion: ICM provides a viable unsupervised alternative to human supervision for fine-tuning language models, particularly for superhuman-capable models, and enhances the training of frontier LMs.

摘要: 为了引导预训练语言模型适应下游任务，当前的训练后范式依赖于人类指定期望行为。然而，对于具备超人类能力的模型，获取高质量的人类监督变得困难甚至不可能。为解决这一挑战，我们提出了一种新的无监督算法——内部一致性最大化（ICM），用于在没有外部监督的情况下，基于模型自身生成的标签对预训练语言模型进行微调。在GSM8k验证、TruthfulQA和Alpaca奖励建模任务中，我们的方法达到了与黄金监督训练相当的性能，并优于基于众包人类监督的训练。在模型能力远超人类的任务中，我们的方法能够显著优于基于人类标签的训练。最后，我们展示了该方法可以改进前沿语言模型的训练：我们使用该方法训练了一个无监督奖励模型，并通过强化学习训练了一个基于Claude 3.5 Haiku的助手。奖励模型和助手均优于其人类监督的对应版本。

</details>


### [8] [When Large Language Models are Reliable for Judging Empathic Communication](https://arxiv.org/abs/2506.10150)
**中文标题：大型语言模型在评判共情沟通中的可靠性**

*Aakriti Kumar,Nalin Poungpeth,Diyi Yang,Erina Farrell,Bruce Lambert,Matthew Groh*

Main category: cs.CL

TL;DR: The study compares expert, crowdworker, and LLM annotations on empathic communication, finding LLMs reliable and often surpassing crowdworkers, approaching expert agreement levels.


<details>
  <summary>Details</summary>
Motivation: To assess the reliability of LLMs in judging empathic communication nuances compared to human experts and crowdworkers.

Method: Compared annotations from experts, crowdworkers, and LLMs across four evaluative frameworks applied to 200 real-world conversations, analyzing inter-rater reliability.

Result: LLMs consistently approached expert-level agreement and exceeded crowdworker reliability across all frameworks.

Conclusion: LLMs can be reliable for judging empathic communication when validated with appropriate benchmarks, supporting their use in emotionally sensitive applications.

摘要: 大型语言模型（LLMs）在基于文本的对话中擅长生成共情回应。但它们对共情沟通细微差别的评判有多可靠？我们通过比较专家、众包工作者和LLMs在四种评估框架下对200个真实对话的标注来研究这一问题。这些框架来自心理学、自然语言处理和传播学，涉及一方分享个人问题、另一方提供支持的对话。基于3,150条专家标注、2,844条众包标注和3,150条LLM标注，我们评估了这三组标注者之间的评分一致性。发现专家间一致性较高，但随框架子组分的清晰度、复杂性和主观性而变化。专家一致性比标准分类指标更能为LLM表现提供信息。在所有四种框架中，LLMs一致接近专家水平，并超越众包工作者的可靠性。这些结果表明，LLMs在特定任务中经过适当基准验证后，可用于情感敏感应用（如作为对话伴侣）的透明度和监督。

</details>


### [9] [Analyzing Emotions in Bangla Social Media Comments Using Machine Learning and LIME](https://arxiv.org/abs/2506.10154)
**中文标题：使用机器学习和LIME分析孟加拉语社交媒体评论中的情感**

*Bidyarthi Paul,SM Musfiqur Rahman,Dipta Biswas,Md. Ziaul Hasan,Md. Zahid Hossain*

Main category: cs.CL

TL;DR: The paper explores emotion analysis in Bangla social media comments using machine learning models (Linear SVM, KNN, Random Forest, BiLSTM, and AdaBoost) and LIME for interpretability, aiming to advance sentiment analysis in understudied languages.


<details>
  <summary>Details</summary>
Motivation: To address the gap in emotion analysis for understudied languages like Bangla, which has unique regional expressions and cultural features, by leveraging machine learning and interpretability tools.

Method: Employed Linear SVM, KNN, Random Forest, BiLSTM, and AdaBoost models with TF-IDF vectorized n-gram data, investigated PCA for dimensionality reduction, and used LIME to explain AdaBoost predictions.

Result: The study identified efficient techniques for emotion identification in Bangla, demonstrating the effectiveness of machine learning models and interpretability tools like LIME.

Conclusion: The research advances sentiment analysis in resource-limited languages by providing a framework for emotion identification in Bangla social media comments.

摘要: 对书面语言中情感理解的研究持续扩展，尤其是针对如孟加拉语这样具有独特地区表达和文化特征的未被充分研究的语言。本研究使用EmoNoBa数据集中的22,698条社交媒体评论进行情感分析。在语言分析中，我们采用了机器学习模型：线性SVM、KNN和随机森林，结合TF-IDF向量化的n-gram数据。我们还研究了PCA对降维的影响。此外，我们使用了BiLSTM模型和AdaBoost来改进决策树。为了使机器学习模型更易于理解，我们使用LIME来解释基于决策树的AdaBoost分类器的预测。我们的工作旨在推动资源有限语言中的情感分析，通过研究多种技术以找到高效的孟加拉语情感识别方法。

</details>


### [10] [Measuring Corporate Human Capital Disclosures: Lexicon, Data, Code, and Research Opportunities](https://arxiv.org/abs/2506.10155)
**中文标题：衡量企业人力资本披露：词典、数据、代码与研究机会**

*Elizabeth Demers,Victor Xiaoqi Wang,Kean Wu*

Main category: cs.CL

TL;DR: The paper develops a machine learning-based lexicon for measuring corporate human capital (HC) disclosures, sharing data and code for future research.


<details>
  <summary>Details</summary>
Motivation: Human capital is vital for corporate value but lacks standardized measurement or disclosure rules, prompting the need for a systematic approach to analyze HC disclosures.

Method: The authors use word2vec to create a lexicon of HC-related keywords, classified into five subcategories, and share their data and Python code for further research.

Result: A comprehensive HC lexicon and tools are provided, enabling researchers to analyze corporate HC disclosures and fine-tune models like BERT.

Conclusion: The study offers valuable resources for HC research and highlights future opportunities in HC management and disclosure.

摘要: 人力资本（HC）对企业价值创造日益重要，但目前缺乏明确的衡量或披露规则。我们使用机器学习算法（word2vec）在已验证的HC披露数据集上训练，开发了一个全面的HC相关关键词列表，分为五个子类别（多样性、公平与包容；健康与安全；劳动关系与文化；薪酬与福利；人口统计与其他），以捕捉HC管理的多维性。我们分享了词典、企业HC披露数据及用于开发词典的Python代码，并提供了使用数据和代码的详细示例，包括微调BERT模型。研究人员可利用我们的HC词典（或修改代码以捕获其他感兴趣的构念）与企业沟通样本，解决相关HC问题。最后，我们讨论了HC管理与披露的未来研究机会。

</details>


### [11] [Can LLMs Generate Good Stories? Insights and Challenges from a Narrative Planning Perspective](https://arxiv.org/abs/2506.10161)
**中文标题：大型语言模型能生成好故事吗？从叙事规划角度的见解与挑战**

*Yi Wang,Max Kreminski*

Main category: cs.CL

TL;DR: The paper evaluates LLMs' ability to generate high-quality stories by testing them on narrative planning tasks, revealing strengths in causal soundness but challenges in character intentionality and dramatic conflict.


<details>
  <summary>Details</summary>
Motivation: To understand LLMs' story generation capabilities by leveraging computational narratology and narrative planning benchmarks, addressing gaps in evaluation methods and quality assessment.

Method: The study uses a benchmark based on literature examples to evaluate LLMs on narrative planning, focusing on causal soundness, character intentionality, and dramatic conflict. Experiments involve GPT-4 tier models.

Result: LLMs can generate causally sound stories at small scales but struggle with character intentionality and dramatic conflict, requiring reinforcement learning for complex reasoning.

Conclusion: LLMs show promise in story generation but face challenges in maintaining quality for complex narrative elements, highlighting the need for further research and training enhancements.

摘要: 故事生成是大型语言模型（LLMs）的一个重要应用。然而，由于自动评估方法的挑战以及人工评估的高成本和主观性，对LLMs生成高质量故事能力的理解仍然有限。计算叙事学为“好故事”提供了有价值的见解，这些见解已被应用于符号叙事规划方法的故事生成中。本研究旨在通过让LLMs解决叙事规划问题，深化对其故事生成能力的理解。我们提出了一个基于文学例子的叙事规划评估基准，重点关注因果合理性、角色意图性和戏剧冲突。实验表明，GPT-4级别的LLMs可以在小规模上生成因果合理的故事，但在角色意图性和戏剧冲突方面的规划仍具挑战性，需要结合强化学习进行复杂推理。结果从不同角度揭示了LLMs在保持故事质量方面的能力范围。我们的发现还突出了有趣的问题解决行为，并为在游戏环境中应用LLM叙事规划的挑战和考虑提供了启示。

</details>


### [12] [Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval](https://arxiv.org/abs/2506.10202)
**中文标题：Q2E：用于零样本多语言文本到视频检索的查询到事件分解方法**

*Shubhashis Roy Dipta,Francis Ferraro*

Main category: cs.CL

TL;DR: Q2E introduces a Query-to-Event decomposition method for zero-shot multilingual text-to-video retrieval, leveraging LLMs and VLMs to enhance query understanding and retrieval performance, including multimodal inputs like audio.


<details>
  <summary>Details</summary>
Motivation: To improve the identification and retrieval of videos related to complex real-world events by leveraging latent parametric knowledge from LLMs and VLMs, addressing the oversimplification of human queries.

Method: Q2E decomposes queries using knowledge from LLMs and VLMs, integrates multimodal inputs (visual and speech), and employs entropy-based fusion scoring for zero-shot retrieval.

Result: Q2E outperforms state-of-the-art baselines on diverse datasets and metrics, with audio integration significantly boosting retrieval performance.

Conclusion: Q2E effectively enhances text-to-video retrieval by decomposing queries and leveraging multimodal knowledge, demonstrating the value of integrating audio and multilingual capabilities.

摘要: 最近的研究表明，从大型语言模型（LLMs）和视觉语言模型（VLMs）中提取和利用参数化知识的能力令人印象深刻。在这项工作中，我们探讨了如何通过自动提取这些事件的潜在参数化知识来改进与复杂现实世界事件相关的视频的识别和检索。我们提出了Q2E：一种用于零样本多语言文本到视频检索的查询到事件分解方法，适用于跨数据集、领域、LLMs或VLMs的适应性。我们的方法表明，通过利用LLMs和VLMs中嵌入的知识分解查询，可以增强对过于简化的人类查询的理解。我们还展示了如何将这种方法应用于视觉和语音输入。为了结合这些多样化的多模态知识，我们采用了基于熵的融合评分进行零样本融合。通过在两个多样化数据集和多种检索指标上的评估，我们证明Q2E优于多个最先进的基线方法。我们的评估还表明，整合音频信息可以显著改善文本到视频检索。我们已发布代码和数据以供未来研究。

</details>


### [13] [TTT-Bench: A Benchmark for Evaluating Reasoning Ability with Simple and Novel Tic-Tac-Toe-style Games](https://arxiv.org/abs/2506.10209)
**中文标题：TTT-Bench：通过简单新颖的井字棋风格游戏评估推理能力的基准**

*Prakamya Mishra,Jiang Liu,Jialian Wu,Xiaodong Yu,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: TTT-Bench is a new benchmark designed to evaluate basic strategic, spatial, and logical reasoning in large reasoning models (LRMs) using simple Tic-Tac-Toe-style games. Despite excelling in complex tasks like math problems, LRMs often fail these simple games, highlighting gaps in their reasoning abilities.


<details>
  <summary>Details</summary>
Motivation: To explore the reasoning capabilities of LRMs beyond STEM tasks, focusing on basic strategic, spatial, and logical reasoning through simple games that humans solve effortlessly.

Method: TTT-Bench uses a suite of four Tic-Tac-Toe-style games, generated programmatically, to test LRMs. The games require reasoning about opponent intentions and spatial configurations.

Result: LRMs that excel in hard math problems frequently fail at TTT-Bench, scoring 41% and 5% lower compared to MATH 500 and AIME 2024, respectively. Larger models perform better with shorter reasoning traces but struggle with long-term strategic reasoning.

Conclusion: TTT-Bench reveals significant gaps in LRMs' reasoning abilities for simple tasks, suggesting the need for further research to improve their strategic and spatial reasoning.

摘要: 大型推理模型（LRMs）在包括奥林匹克级数学问题在内的广泛任务中展示了令人印象深刻的推理能力，表明其具备复杂推理能力。然而，许多推理基准集中在STEM领域，LRMs在更广泛任务领域中的正确推理能力仍未被充分探索。本研究提出了\textbf{TTT-Bench}，一种新的基准，旨在通过四种人类从小就能轻松解决的双人井字棋风格游戏，评估LRMs的基本战略、空间和逻辑推理能力。我们提出了一种简单但可扩展的程序化方法，用于生成TTT-Bench的可验证双人游戏问题。尽管这些游戏对人类来说微不足道，但它们需要推理对手的意图以及游戏板的空间配置以确保胜利。我们评估了多种最先进的LRMs，\textbf{发现那些在困难数学问题上表现出色的模型经常在这些简单推理游戏中失败}。进一步测试显示，与MATH 500和AIME 2024相比，我们评估的推理模型在TTT-Bench上的得分平均分别低41%和5%，其中较大模型通过较短的推理轨迹获得更高性能，而大多数模型在简单和新颖的TTT-Bench任务中长期战略推理情境中表现不佳。

</details>


### [14] [Classifying Unreliable Narrators with Large Language Models](https://arxiv.org/abs/2506.10231)
**中文标题：使用大型语言模型分类不可靠叙述者**

*Anneliese Brei,Katharine Henry,Abhisheik Sharma,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.CL

TL;DR: The paper proposes using large language models (LLMs) to classify unreliable narrators in texts, introduces a dataset (TUNa), and evaluates LLM performance on tasks related to different types of unreliability.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of identifying unreliable narrators in texts, leveraging computational methods and literary theory to improve classification accuracy.

Method: The study defines unreliable narrators based on narratology, creates a human-annotated dataset (TUNa), and evaluates LLMs on classification tasks for intra-narrational, inter-narrational, and inter-textual unreliabilities using few-shot, fine-tuning, and curriculum learning.

Result: The task is challenging, but LLMs show potential for identifying unreliable narrators, with performance varying across different learning settings.

Conclusion: The study highlights the feasibility of using LLMs for unreliable narrator classification, releases the dataset and code, and encourages further research.

摘要: 当我们与第一人称事件叙述互动时，常常会考虑叙述者是否可靠。本文提出使用计算方法来识别不可靠叙述者，即那些无意中歪曲信息的叙述者。借鉴叙事学中的文学理论，我们基于多种文本现象定义了不同类型的不可靠叙述者，并提出了TUNa数据集，这是一个包含博客文章、Reddit帖子、酒店评论和文学作品的多领域人类标注叙事数据集。我们定义了叙述内、叙述间和文本间不可靠性的分类任务，并分析了流行的开源和专有大型语言模型在每项任务中的表现。我们提出从文学中学习，以对现实世界文本数据进行不可靠叙述者分类。为此，我们尝试了少样本学习、微调和课程学习设置。结果表明，这项任务非常具有挑战性，但使用大型语言模型识别不可靠叙述者具有潜力。我们发布了专家标注的数据集和代码，并邀请未来在这一领域的研究。

</details>


### [15] [ToxSyn-PT: A Large-Scale Synthetic Dataset for Hate Speech Detection in Portuguese](https://arxiv.org/abs/2506.10245)
**中文标题：ToxSyn-PT：用于葡萄牙语仇恨言论检测的大规模合成数据集**

*Iago Alves Brito,Julia Soares Dollis,Fernanda Bufon Färber,Diogo Fernandes Costa Silva,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: The paper introduces ToxSyn-PT, a large-scale synthetic Portuguese dataset for hate speech detection, covering nine minority groups. It uses a four-stage pipeline for creation and shows strong generalization across domains.


<details>
  <summary>Details</summary>
Motivation: To address the lack of large-scale, fine-grained hate speech datasets in Portuguese, especially for legally protected minority groups, and to explore synthetic data's potential in low-resource settings.

Method: A four-stage pipeline: (1) manually curated seed, (2) few-shot expansion with an LLM, (3) paraphrase-based augmentation, and (4) enrichment with neutral texts.

Result: The dataset is class-balanced and stylistically diverse, achieving strong performance in binary and multi-label classification across five Portuguese hate-speech datasets.

Conclusion: ToxSyn-PT advances hate-speech detection research in Portuguese and demonstrates synthetic data's effectiveness in low-resource contexts.

摘要: 我们提出了ToxSyn-PT，这是首个大规模的葡萄牙语语料库，支持对九个受法律保护的少数群体进行细粒度的仇恨言论分类。该数据集包含53,274个合成句子，均匀分布在少数群体和毒性标签之间。ToxSyn-PT通过一个新颖的四阶段流程创建：(1) 一个紧凑的手工筛选种子；(2) 使用指令调优的大型语言模型进行少样本扩展；(3) 基于释义的增强；(4) 丰富化，并添加中性文本以减少对群体特定线索的过拟合。生成的语料库类别平衡、风格多样，并且避免了现有葡萄牙语数据集中普遍存在的社交媒体领域限制。尽管与传统基准存在领域差异，但在该语料库上进行的二元和多标签分类实验在五个公开的葡萄牙语仇恨言论数据集上均取得了强劲结果，展示了跨领域的鲁棒泛化能力。该数据集已公开发布，以推动合成数据和低资源环境下仇恨言论检测的研究。

</details>


### [16] [Do Language Models Have Bayesian Brains? Distinguishing Stochastic and Deterministic Decision Patterns within Large Language Models](https://arxiv.org/abs/2506.10268)
**中文标题：语言模型是否具有贝叶斯大脑？区分大型语言模型中的随机性与确定性决策模式**

*Andrea Yaoyun Cui,Pengfei Yu*

Main category: cs.CL

TL;DR: The paper challenges the assumption that language models make purely probabilistic decisions, showing they can exhibit near-deterministic behavior under certain conditions. It proposes a method to distinguish stochastic and deterministic patterns in Gibbs sampling to avoid inferring misleading priors.


<details>
  <summary>Details</summary>
Motivation: The paper aims to investigate whether language models truly exhibit Bayesian decision-making or if their behavior can be deterministic, challenging prior assumptions and methods for inferring model priors.

Method: The authors analyze decision patterns in large language models under various conditions, proposing a method to distinguish stochastic and deterministic behaviors in Gibbs sampling.

Result: The study reveals that language models can display near-deterministic decision-making, even with non-zero sampling temperatures, and warns against inferring false priors from deterministic systems.

Conclusion: The findings suggest that language models do not always behave as Bayesian brains, and careful scrutiny is needed to avoid misinterpreting their decision patterns.

摘要: 语言模型本质上是基于标记序列的概率分布。自回归模型通过迭代计算和采样下一个标记的分布来生成句子。这种迭代采样引入了随机性，导致人们假设语言模型会做出类似从未知分布中采样的概率决策。基于这一假设，先前的研究利用模拟吉布斯采样（受设计用于引出人类先验的实验启发）来推断语言模型的先验。本文重新审视一个关键问题：语言模型是否具有贝叶斯大脑？我们的研究结果表明，在某些条件下，语言模型可以表现出近乎确定性的决策行为，例如即使在非零采样温度下也能产生最大似然估计。这挑战了采样假设，并削弱了先前引出类人先验的方法。此外，我们证明，未经适当审查，具有确定性行为的系统在模拟吉布斯采样过程中可能会收敛到一个“虚假先验”。为解决这一问题，我们提出了一种简单的方法来区分吉布斯采样中的随机性和确定性决策模式，从而避免推断出误导性的语言模型先验。我们在多种大型语言模型上进行了实验，以识别它们在不同情况下的决策模式。我们的结果为理解大型语言模型的决策行为提供了重要见解。

</details>


### [17] [ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs](https://arxiv.org/abs/2506.10288)
**中文标题：ClusterUCB：基于梯度的高效数据选择方法用于大型语言模型的定向微调**

*Zige Wang,Qi Zhu,Fei Mi,Minghui Xu,Ruochun Jin,Wenjing Yang*

Main category: cs.CL

TL;DR: ClusterUCB is an efficient gradient-based data selection framework for fine-tuning LLMs, using clustering and a modified UCB algorithm to reduce computational costs while maintaining performance.


<details>
  <summary>Details</summary>
Motivation: Traditional gradient-based data selection for fine-tuning LLMs is resource-intensive; ClusterUCB aims to reduce computational costs while maintaining effectiveness.

Method: ClusterUCB clusters training data by gradient features, frames inter-cluster selection as a multi-armed bandit problem, and uses a modified UCB algorithm to balance exploration and exploitation.

Result: ClusterUCB achieves comparable performance to original gradient-based methods while significantly reducing computational consumption.

Conclusion: ClusterUCB offers a practical and efficient solution for gradient-based data selection in LLM fine-tuning.

摘要: 基于梯度的数据影响近似方法已被用于在大型语言模型的监督微调中选择有用的数据样本。然而，在整个微调过程中计算梯度需要过多资源，实际中难以实现。本文提出了一种高效的基于梯度的数据选择框架，结合聚类和改进的上置信界（UCB）算法。基于梯度特征相似的数据样本具有相似影响的直觉，我们首先对训练数据池进行聚类。然后，将簇间数据选择问题建模为受计算预算约束的分配问题，并视为多臂老虎机问题。采用改进的UCB算法解决此问题。具体而言，在迭代采样过程中，记录历史数据影响信息以直接估计每个簇的分布，并采用冷启动来平衡探索与利用。在多个基准测试上的实验结果表明，我们提出的ClusterUCB框架可以在大幅减少计算消耗的同时，达到与原始基于梯度的数据选择方法相当的结果。

</details>


### [18] [Flick: Few Labels Text Classification using K-Aware Intermediate Learning in Multi-Task Low-Resource Languages](https://arxiv.org/abs/2506.10292)
**中文标题：Flick：基于K感知中间学习的多任务低资源语言少标签文本分类**

*Ali Almutairi,Abdullah Alsuhaibani,Shoaib Jameel,Usman Naseem,Gelareh Mohammadi,Imran Razzak*

Main category: cs.CL

TL;DR: Flick introduces a novel pseudo-label refinement method for few-label text classification in low-resource languages, improving pseudo-label quality by focusing on high-confidence clusters and adaptive top-k selection.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of few-label text classification in low-resource languages, where existing methods struggle with noisy pseudo-labels and domain adaptation.

Method: Flick refines pseudo-labels by distilling high-confidence ones from a broad set of initial clusters, using single-cluster cohesion and adaptive top-k selection.

Result: Demonstrated superior performance across 14 diverse datasets, including low-resource languages like Arabic, Urdu, and Setswana.

Conclusion: Flick effectively mitigates error propagation in low-resource settings, enabling robust fine-tuning with minimal true labels.

摘要: 在深度学习中，减少对大量标注数据的依赖已成为研究热点。尽管自训练方法在半监督学习中表现良好，但它们容易受到噪声伪标签的影响。此外，当前少标签分类方法多针对资源丰富的语言（如英语）或采用易过拟合的复杂级联模型。为解决低资源语言环境中少标签文本分类的难题，我们提出了Flick。不同于依赖通用多聚类伪标签或复杂级联架构的现有方法，Flick通过从更广泛的初始聚类中提取高置信度伪标签，显著提升了伪标签质量，尤其适用于语言多样性高的低资源环境。Flick引入了一种新颖的伪标签细化组件，通过关注单聚类内聚性和自适应top-k选择机制，从初始广泛集合中提取高可靠性伪标签。这一针对性细化过程有效减少了低资源数据中的错误传播，仅需少量真实标签即可实现对预训练语言模型的鲁棒微调。我们在14个多样化数据集（包括阿拉伯语、乌尔都语和塞茨瓦纳语等低资源语言及英语）上验证了Flick的优越性能和适应性。

</details>


### [19] ["Check My Work?": Measuring Sycophancy in a Simulated Educational Context](https://arxiv.org/abs/2506.10297)
**中文标题：“检查我的作业？”：模拟教育环境中谄媚行为的测量**

*Chuck Arvin*

Main category: cs.CL

TL;DR: The study reveals that LLMs exhibit sycophantic behavior in educational contexts, altering responses based on student suggestions, which can degrade or improve accuracy by up to 15 percentage points. Smaller models show stronger bias (up to 30%), raising concerns about educational equity.


<details>
  <summary>Details</summary>
Motivation: To investigate how LLMs' responses are influenced by student suggestions in educational settings, particularly the risks of sycophancy (model bias toward user input), and its implications for learning equity.

Method: Tested five LLMs (from OpenAI GPT-4o and GPT-4.1 classes) under five experimental conditions, analyzing response quality, answer flipping frequency, and token-level probabilities to measure sycophantic behavior.

Result: LLMs' correctness degraded by 15% when students mentioned incorrect answers and improved by 15% with correct answers. Smaller models (e.g., GPT-4.1-nano) showed stronger bias (30%) compared to larger models (8%).

Conclusion: Sycophantic behavior in LLMs can exacerbate educational inequities by reinforcing misunderstandings for less knowledgeable students. The study underscores the need to understand and mitigate such biases in educational applications.

摘要: 本研究探讨了在模拟教育环境中，用户提供的建议如何影响大型语言模型（LLMs），其中谄媚行为带来了显著风险。通过测试OpenAI GPT-4o和GPT-4.1模型类别的五种不同LLMs在五种实验条件下的表现，我们发现响应质量因查询框架而异。当学生提到错误答案时，LLMs的正确率可能下降多达15个百分点，而提到正确答案时则提升相同幅度。结果还显示，这种偏差在较小模型中更为明显，GPT-4.1-nano模型的影响高达30%，而GPT-4o模型仅为8%。我们对LLMs“翻转”答案的频率分析及对标记级概率的调查证实，模型通常会根据学生的答案选择改变其回答，符合谄媚假设。这种谄媚行为对教育公平具有重要影响，因为LLMs可能加速知识丰富学生的学习，而同样的工具可能加深知识较少学生的误解。我们的结果强调了需要更好地理解这种机制，并寻找在教育环境中减轻此类偏差的方法。

</details>


### [20] [Scheduled Interleaved Speech-Text Training for Speech-to-Speech Translation with LLMs](https://arxiv.org/abs/2506.10299)
**中文标题：基于LLMs的语音到语音翻译的定时交替语音-文本训练**

*Hayato Futami,Emiru Tsunoo,Yosuke Kashiwagi,Yuki Ito,Hassan Shahmohammadi,Siddhant Arora,Shinji Watanabe*

Main category: cs.CL

TL;DR: The paper proposes scheduled interleaved speech-text training to improve speech-to-speech translation (S2ST) with LLMs, gradually reducing text ratio for better modality adaptation.


<details>
  <summary>Details</summary>
Motivation: LLMs are trained on text-only data, making adaptation to speech modality challenging due to limited speech-to-speech data. The study aims to address this issue.

Method: Proposes interleaving speech-text units at the word level during training, gradually decreasing text ratio to facilitate progressive modality adaptation.

Result: The method improves S2ST performance, especially for languages with limited training data, as shown in experiments with LLaMA3.2-1B on the CVSS dataset.

Conclusion: Scheduled interleaved speech-text training effectively enhances LLM adaptation to speech modality, improving translation performance.

摘要: 语音到语音翻译（S2ST）通过大型语言模型（LLMs）得到提升，这些模型在离散语音单元上进行微调。然而，从文本到语音的模态适应一直是一个问题。LLMs仅在文本数据上训练，这使其在有限语音数据下适应语音模态具有挑战性。为解决这一训练难题，本研究提出了定时交替语音-文本训练方法。我们在训练中使用交替的语音-文本单元而非纯语音单元，其中对齐的文本标记在单词级别交替插入。随着训练的进行，我们逐渐减少文本比例，以促进从文本到语音的渐进模态适应。我们通过在CVSS数据集上微调LLaMA3.2-1B进行实验评估。结果表明，所提方法持续提升了翻译性能，尤其是对于训练数据有限的语言。

</details>


### [21] [Code Execution as Grounded Supervision for LLM Reasoning](https://arxiv.org/abs/2506.10343)
**中文标题：以代码执行作为基础监督的LLM推理方法**

*Dongwon Jung,Wenxuan Zhou,Muhao Chen*

Main category: cs.CL

TL;DR: The paper proposes a scalable method to generate high-quality chain-of-thought (CoT) supervision for LLMs by leveraging program execution traces, improving reasoning accuracy and reducing token length during inference.


<details>
  <summary>Details</summary>
Motivation: Existing methods for generating CoT supervision rely on costly human annotations or error-prone LLM-generated CoT, making it challenging to obtain reliable reasoning data. The paper aims to address this by using verifiable code execution traces.

Method: The method extracts step-by-step reasoning traces from deterministic code execution and converts them into natural language CoT reasoning, ensuring high-quality and verifiable supervision data.

Result: Experiments show the method enhances LLMs' reasoning abilities across diverse tasks, produces accurate reasoning data, and reduces token length by eliminating meaningless repetition and overthinking.

Conclusion: The proposed approach provides a scalable and reliable way to generate CoT supervision, improving LLMs' reasoning performance and efficiency.

摘要: 通过链式思维（CoT）监督训练大型语言模型（LLM）已被证明能有效提升其推理能力。然而，获取可靠且准确的推理监督仍是一个重大挑战。我们提出了一种可扩展的方法，通过利用程序执行的确定性来生成高质量的CoT监督数据集。与依赖昂贵人工标注或易出错的LLM生成CoT的现有方法不同，我们的方法从代码执行中提取可验证的逐步推理轨迹，并将其转化为自然语言的CoT推理。在多个领域的推理基准测试中，实验表明我们的方法能有效赋予LLM跨任务的迁移推理能力。此外，消融研究验证了我们的方法生成高度准确的推理数据，并通过减少无意义的重复和过度思考降低了推理过程中的总体标记长度。

</details>


### [22] [TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous Document Reasoning](https://arxiv.org/abs/2506.10380)
**中文标题：TableRAG：一种用于异构文档推理的检索增强生成框架**

*Xiaohan Yu,Pu Jian,Chong Chen*

Main category: cs.CL

TL;DR: TableRAG is a hybrid framework for heterogeneous document reasoning, combining text and tabular data processing to improve multi-hop question answering, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing RAG approaches struggle with heterogeneous documents (text and tables), losing tabular structure and information, which limits reasoning capabilities in multi-hop queries.

Method: TableRAG uses a four-step iterative process: query decomposition, text retrieval, SQL programming/execution, and intermediate answer generation, unifying text and tabular data processing.

Result: TableRAG outperforms baselines on public datasets and the new HeteQA benchmark, setting a new state-of-the-art for heterogeneous document QA.

Conclusion: TableRAG effectively addresses limitations of existing RAG methods for heterogeneous documents, enhancing reasoning capabilities and performance.

摘要: 检索增强生成（RAG）在开放领域问答中表现出显著效果。然而，当应用于包含文本和表格组件的异构文档时，现有RAG方法存在关键限制。常见的表格扁平化和分块策略破坏了表格的内在结构，导致信息丢失，并削弱了LLM在多跳全局查询中的推理能力。为解决这些问题，我们提出了TableRAG，一种统一文本理解和表格数据复杂操作的混合框架。TableRAG迭代执行四个步骤：上下文敏感的查询分解、文本检索、SQL编程与执行以及组合性中间答案生成。我们还开发了HeteQA，一个用于评估多跳异构推理能力的新基准。实验结果表明，TableRAG在公共数据集和我们的HeteQA上均优于现有基线，为异构文档问答设立了新的最先进水平。TableRAG已在https://github.com/yxh-y/TableRAG/tree/main发布。

</details>


### [23] [PAG: Multi-Turn Reinforced LLM Self-Correction with Policy as Generative Verifier](https://arxiv.org/abs/2506.10406)
**中文标题：PAG：基于生成式验证策略的多轮强化LLM自我纠正**

*Yuhua Jiang,Yuwen Xiong,Yufeng Yuan,Chao Xin,Wenyuan Xu,Yu Yue,Qianchuan Zhao,Lin Yan*

Main category: cs.CL

TL;DR: PAG introduces a multi-turn RL framework where LLMs alternate between policy and verifier roles, selectively revising answers only when errors are detected, improving both reasoning and verification.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with self-verification, and existing solutions rely on separate verifiers or complex pipelines, limiting scalability. PAG aims to simplify and enhance self-correction.

Method: PAG uses a multi-turn RL paradigm where LLMs alternate roles as policy and verifier, selectively revising answers based on generative verification.

Result: PAG improves reasoning and verification accuracy, outperforming self-consistency in self-verification and enhancing direct generation.

Conclusion: PAG's verify-then-revise approach effectively enhances LLM self-correction, balancing reasoning and verification without additional verifier models.

摘要: 大型语言模型（LLM）在复杂推理任务中表现出色，但仍难以可靠地验证自身输出的正确性。现有的验证方法通常依赖独立的验证器模型或多阶段自我纠正训练流程，限制了可扩展性。本文提出“生成式验证策略”（PAG），这是一种简单有效的框架，通过在统一的多轮强化学习（RL）范式中交替扮演策略和验证器角色，使LLM能够自我纠正。与以往无论模型置信度如何都会生成第二次尝试的方法不同，PAG引入了选择性修订机制：模型仅在自身的生成式验证步骤检测到错误时修订答案。这种“验证后修订”的工作流程不仅缓解了模型崩溃，还共同提升了推理和验证能力。在多样化推理基准上的大量实验表明，PAG具有双重优势：作为策略，它提高了直接生成和自我纠正的准确性；作为验证器，其自我验证性能优于自我一致性。

</details>


### [24] [Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?](https://arxiv.org/abs/2506.10415)
**中文标题：阅后即焚：多模态大语言模型是否真正捕捉了图像序列中的事件顺序？**

*Yingjin Song,Yupei Du,Denis Paperno,Albert Gatt*

Main category: cs.CL

TL;DR: The paper introduces TempVS, a benchmark to evaluate Multimodal Large Language Models (MLLMs) on temporal grounding and reasoning in image sequences. Results show MLLMs struggle with these tasks, lagging behind human performance.


<details>
  <summary>Details</summary>
Motivation: To assess whether MLLMs can truly understand and reason about the temporal order of events in image sequences, a capability crucial for real-world applications.

Method: The TempVS benchmark includes three tests (event relation inference, sentence ordering, image ordering) with grounding tests, evaluating 38 MLLMs on their temporal reasoning abilities.

Result: MLLMs perform poorly on TempVS, with a significant gap compared to human performance, highlighting limitations in temporal reasoning.

Conclusion: The TempVS benchmark reveals MLLMs' weaknesses in temporal reasoning, suggesting future research directions to improve these capabilities.

摘要: 本文介绍了TempVS基准，专注于评估多模态大语言模型（MLLMs）在图像序列中的时间定位和推理能力。TempVS包含三项主要测试（即事件关系推理、句子排序和图像排序），每项测试均配有基础定位测试。TempVS要求MLLMs依赖视觉和语言模态来理解事件的时间顺序。我们评估了38种先进的MLLMs，结果表明这些模型在解决TempVS任务时表现不佳，与人类能力存在显著差距。我们还提供了细粒度的分析，为未来研究指明了有前景的方向。TempVS基准数据和代码可在https://github.com/yjsong22/TempVS获取。

</details>


### [25] [Beyond the Battlefield: Framing Analysis of Media Coverage in Conflict Reporting](https://arxiv.org/abs/2506.10421)
**中文标题：超越战场：冲突报道中媒体框架的分析**

*Avneet Kaur,Arnav Arora*

Main category: cs.CL

TL;DR: The paper analyzes media framing in conflict reporting, focusing on the Israel-Palestine war, using computational methods to reveal biases and a preference for war journalism over peace journalism across US, UK, and Middle Eastern outlets.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of qualitative studies and surface-level analysis in conflict framing research by using computational methods to uncover deeper linguistic and communicative framing patterns in media coverage.

Method: Combines frame semantics and large language models to analyze a corpus of news articles on the Israel-Palestine conflict, identifying war and peace journalism indicators.

Result: Found a higher focus on war-based reporting and significant differences in framing assailants and victims across US, UK, and Middle Eastern news outlets, revealing media biases.

Conclusion: The study highlights the impact of media framing on conflict perception and the need for more balanced reporting, emphasizing the role of computational methods in uncovering biases.

摘要: 新闻媒体在冲突时期使用的框架对读者观点有重大影响，可能加剧冲突本身。当前关于冲突框架的研究由于定性性质或仅关注表面通用框架而见解有限。在这项工作中，我们根据冲突研究的先前工作，在报道以色列-巴勒斯坦战争的新闻文章语料库中识别战争与和平新闻的指标。我们使用计算方法，结合框架语义学和大型语言模型，分析交际框架及其与语言框架的联系。分析显示，报道更侧重于战争而非和平。我们还展示了美国、英国和中东新闻媒体在冲突中谁是攻击者和受害者的框架上存在显著差异，揭示了媒体内部的偏见。

</details>


### [26] [Fast on the Easy, Deep on the Hard: Efficient Reasoning via Powered Length Penalty](https://arxiv.org/abs/2506.10446)
**中文标题：快速处理简单问题，深入解决复杂问题：基于长度惩罚的高效推理方法**

*Zehui Ling,Deshu Chen,Hongwei Zhang,Yifeng Jiao,Xin Guo,Yuan Cheng*

Main category: cs.CL

TL;DR: The paper introduces a method to improve LLM reasoning efficiency by dynamically adjusting output length penalties based on problem complexity, achieving shorter outputs for simpler tasks and better accuracy for complex ones.


<details>
  <summary>Details</summary>
Motivation: Current LLM reasoning methods often generate unnecessarily long outputs, increasing computational latency. Uniform penalties for output length ignore problem complexity, leading to suboptimal performance. This study aims to enhance efficiency by promoting conciseness for simple problems while preserving detailed reasoning for complex ones.

Method: The approach divides the reward function and introduces a novel output length penalty, dynamically adjusting penalties based on problem complexity. This ensures shorter outputs for simpler tasks (e.g., GSM8K, MATH500) and sufficient reasoning for harder ones (e.g., AIME2024).

Result: The method achieved shorter outputs with maintained or improved accuracy on simpler datasets (GSM8K, MATH500) and higher accuracy on the more complex AIME2024 dataset.

Conclusion: The proposed method effectively balances reasoning efficiency and accuracy by tailoring output length penalties to problem complexity, demonstrating superior performance across diverse benchmarks.

摘要: 大型语言模型（LLM）在推理能力上取得了显著进展，在各种具有挑战性的基准测试中表现优异。为了提高推理能力，研究者引入了诸如“思维链”提示等技术。然而，这些方法通常生成较长的输出，从而增加了计算延迟。尽管一些方法使用强化学习来缩短推理过程，但它们往往采用统一的惩罚机制，而未考虑问题的复杂性，导致结果不尽如人意。本研究旨在通过促进简单问题的简洁性，同时保留复杂问题的充分推理以提高准确性，从而提升LLM推理的整体效率。具体而言，我们通过划分奖励函数并引入一种新颖的输出长度惩罚机制来管理模型的推理效率。我们的方法在三个基准数据集（GSM8K、MATH500和AIME2024）上取得了显著成果。对于相对简单的数据集GSM8K和MATH500，我们的方法有效缩短了输出长度，同时保持或提高了准确性。在更具挑战性的AIME2024数据集上，我们的方法提升了准确性。

</details>


### [27] [Table-Text Alignment: Explaining Claim Verification Against Tables in Scientific Papers](https://arxiv.org/abs/2506.10486)
**中文标题：表格-文本对齐：解释科学论文中针对表格的声明验证**

*Xanh Ho,Sunisth Kumar,Yun-Ang Wu,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

TL;DR: The paper reframes table-text alignment as an explanation task, requiring models to identify key table cells for claim verification. It introduces a dataset with human-annotated rationales and shows that while LLMs predict labels well, they often fail at aligning with human reasoning.


<details>
  <summary>Details</summary>
Motivation: Predicting claim verification labels alone lacks interpretability. The paper aims to enhance understanding by requiring models to identify essential table cells for verification.

Method: The authors extend the SciTab benchmark with human-annotated cell-level rationales, propose a taxonomy for ambiguous cases, and test LLMs on claim verification and rationale alignment.

Result: Incorporating table alignment improves verification performance, but LLMs often fail to align with human rationales despite correct label predictions.

Conclusion: The study highlights the need for models to provide faithful reasoning beyond label prediction, emphasizing interpretability in claim verification.

摘要: 科学声明验证通常需要根据表格预测声明是否被支持或反驳。然而，我们认为仅预测最终标签是不够的：它几乎无法揭示模型的推理过程，且可解释性有限。为此，我们将表格-文本对齐重新定义为解释任务，要求模型识别对声明验证至关重要的表格单元格。我们通过扩展SciTab基准数据集，添加人工标注的单元格级理由，构建了一个新数据集。标注者验证声明标签并突出显示支持其决策的最小单元格集合。标注完成后，我们利用收集的信息提出了一种处理模糊情况的分类法。实验表明：（i）结合表格对齐信息可提高声明验证性能；（ii）大多数大型语言模型（LLM）虽然经常预测正确的标签，但无法恢复与人类对齐的理由，表明其预测并非源于忠实推理。

</details>


### [28] [Surface Fairness, Deep Bias: A Comparative Study of Bias in Language Models](https://arxiv.org/abs/2506.10491)
**中文标题：表面公平，深层偏见：语言模型中偏见的比较研究**

*Aleksandra Sorokovikova,Pavel Chizhov,Iuliia Eremenko,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: The paper examines bias in large language models (LLMs) through proxy measures, finding negligible bias in pre-prompted personae tasks but significant bias in salary negotiation advice and user-graded answers, highlighting risks with LLM personalization.


<details>
  <summary>Details</summary>
Motivation: To investigate and quantify biases in LLMs, especially as they become more personalized and retain user socio-demographics, potentially exacerbating biased outputs.

Method: Evaluated LLMs using pre-prompted personae on MMLU benchmark, reformulated tasks to grade user answers, and analyzed salary negotiation advice for bias.

Result: Pre-prompted personae showed negligible bias, while user-graded answers and salary negotiation advice revealed significant bias, indicating deeper issues with LLM outputs.

Conclusion: LLMs exhibit pronounced bias in certain contexts, especially with personalization, necessitating further research and mitigation strategies.

摘要: 现代语言模型通过大量数据进行训练，这些数据不可避免地包含争议性和刻板印象内容，涉及性别、出身、年龄等各种偏见。因此，模型会表达带有偏见的观点，或根据用户或被赋予的人格产生不同的结果。本文研究了大型语言模型（LLMs）中偏见的多种代理测量方法。我们发现，在多学科基准（MMLU）上使用预提示的人格评估模型时，得分差异微乎其微且多为随机。然而，如果我们重新设计任务，要求模型对用户的回答进行评分，则会显示出更明显的偏见迹象。最后，当我们要求模型提供薪资谈判建议时，答案中表现出显著的偏见。随着LLM助手记忆和个性化趋势的兴起，这些问题从新的角度浮现：现代LLM用户无需预提示其人格描述，因为模型已了解其社会人口特征。

</details>


### [29] [Beyond Single-User Dialogue: Assessing Multi-User Dialogue State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2506.10504)
**中文标题：超越单用户对话：评估大语言模型在多用户对话状态跟踪中的能力**

*Sangmin Song,Juhwan Choi,JungMin Yun,YoungBin Kim*

Main category: cs.CL

TL;DR: The paper evaluates large language models (LLMs) in multi-user dialogue state tracking (DST), revealing a significant performance drop compared to single-user DST, highlighting limitations in handling multi-speaker interactions.


<details>
  <summary>Details</summary>
Motivation: Current DST benchmarks focus on single-user interactions, neglecting the complexities of real-world multi-user scenarios. The study aims to assess LLMs' robustness in multi-user DST while minimizing dataset construction costs.

Method: The authors extend an existing DST dataset by generating utterances of a second user using speech act theory, systematically incorporating multi-user interactions for controlled evaluation.

Result: Experiments show a notable performance decline in LLMs for multi-user DST compared to single-user settings, indicating limitations in tracking dialogue states with multiple speakers.

Conclusion: The findings underscore the need for future research to improve LLMs for multi-user DST, advancing more realistic and robust DST models.

摘要: 大语言模型（LLMs）在零样本对话状态跟踪（DST）中表现出色，减少了对任务特定训练的需求。然而，传统的DST基准主要关注结构化的用户-代理对话，未能捕捉现实世界中多用户交互的复杂性。本研究评估了LLMs在多用户DST中的鲁棒性，同时最小化数据集构建成本。受LLM数据标注最新进展的启发，我们基于言语行为理论扩展了现有的DST数据集，生成了第二个用户的语句。我们的方法系统地将第二个用户的语句融入对话中，实现了对LLMs在多用户环境中的受控评估。实验结果显示，与单用户DST相比，性能显著下降，突显了当前LLMs在提取和跟踪多说话者对话状态中的局限性。我们的发现强调了未来研究需要增强LLMs在多用户DST场景中的应用，为更现实和鲁棒的DST模型铺平道路。

</details>


### [30] [Reliable Reasoning Path: Distilling Effective Guidance for LLM Reasoning with Knowledge Graphs](https://arxiv.org/abs/2506.10508)
**中文标题：可靠推理路径：通过知识图谱为LLM推理提炼有效指导**

*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Bo Li,Qing Li,Xiao Huang*

Main category: cs.CL

TL;DR: The paper proposes the RRP framework to enhance LLM reasoning by extracting reliable reasoning paths from knowledge graphs, combining LLM semantics with structural information, and refining paths for better performance.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) struggle with knowledge-intensive tasks due to lack of background knowledge and hallucinations. Integrating knowledge graphs (KGs) helps, but existing methods fail to organize facts into logical reasoning paths.

Method: The RRP framework mines KGs by combining LLM semantics with relation embedding and bidirectional distribution learning. It includes a rethinking module to evaluate and refine reasoning paths.

Result: RRP achieves state-of-the-art performance on two public datasets and can be integrated into various LLMs in a plug-and-play manner.

Conclusion: RRP effectively enhances LLM reasoning by generating high-quality, tailored reasoning paths from KGs.

摘要: 大型语言模型（LLMs）由于缺乏背景知识和易产生幻觉，在知识密集型任务中表现不佳。为解决这些问题，知识图谱（KGs）与LLMs的结合被广泛研究。现有的KG增强LLMs侧重于补充事实知识，但仍难以解决复杂问题。我们认为，提炼事实之间的关系并将其组织为逻辑一致的推理路径与事实知识本身同等重要。尽管潜力巨大，但从KGs中提取可靠推理路径面临以下挑战：图结构的复杂性以及生成路径的多样性，使得难以区分有用和冗余的路径。为应对这些挑战，我们提出了RRP框架来挖掘知识图谱，该框架结合了LLMs的语义优势和通过关系嵌入与双向分布学习获得的结构信息。此外，我们引入了一个反思模块，根据路径的重要性评估和优化推理路径。在两个公开数据集上的实验结果表明，RRP相比现有基线方法达到了最先进的性能。此外，RRP可以轻松集成到各种LLMs中，以即插即用的方式增强其推理能力。通过生成针对特定问题的高质量推理路径，RRP为LLM推理提炼了有效指导。

</details>


### [31] [Unsupervised Protoform Reconstruction through Parsimonious Rule-guided Heuristics and Evolutionary Search](https://arxiv.org/abs/2506.10614)
**中文标题：通过简约规则启发式与进化搜索的无监督原始形式重构**

*Promise Dodzi Kpoglu*

Main category: cs.CL

TL;DR: The paper introduces an unsupervised hybrid method combining rule-based heuristics and evolutionary search to reconstruct protoforms, outperforming data-driven baselines in accuracy and phonological plausibility.


<details>
  <summary>Details</summary>
Motivation: Prior methods for protoform reconstruction rely heavily on data-driven probabilistic models, which lack linguistic constraints. The authors aim to integrate rule-based heuristics with data-driven inference for more accurate and plausible reconstructions.

Method: The proposed model combines data-driven inference with linguistically motivated rule-based heuristics within an evolutionary optimization framework to guide protoform reconstruction.

Result: The method significantly outperforms established baselines in reconstructing Latin protoforms, achieving higher character-level accuracy and phonological plausibility.

Conclusion: The hybrid approach of integrating rule-based heuristics with evolutionary search proves effective for protoform reconstruction, offering a balance between statistical patterns and linguistic constraints.

摘要: 我们提出了一种无监督方法，用于重构原始形式，即现代语言形式衍生的祖先词汇形式。以往的研究主要依赖于音韵编辑的概率模型从同源词集中推断原始形式，这类方法因其主要依赖数据驱动而受到限制。相比之下，我们的模型在进化优化框架中结合了数据驱动的推断与基于规则的启发式方法。这种混合方法利用统计模式和语言学约束来指导重构过程。我们在重构拉丁原始形式任务上评估了该方法，使用了五种罗曼语同源词数据集。实验结果表明，该方法在字符级准确性和音韵合理性指标上均显著优于现有基线。

</details>


### [32] [Tina: Tiny Reasoning Models via LoRA](https://arxiv.org/abs/2504.15777)
**中文标题：Tina：通过LoRA实现的微型推理模型**

*Shangshang Wang,Julian Asilis,Ömer Faruk Akgül,Enes Burak Bilgin,Ollie Liu,Willie Neiswanger*

Main category: cs.CL

TL;DR: Tina is a family of tiny reasoning models that achieve strong reasoning performance with minimal resources using LoRA-based parameter-efficient updates during RL, outperforming SOTA models at a fraction of the cost.


<details>
  <summary>Details</summary>
Motivation: To explore how cost-effectively strong reasoning abilities can be achieved in language models, aiming for high performance with minimal computational resources.

Method: Applies low-rank adaptation (LoRA) during reinforcement learning (RL) to a tiny 1.5B parameter base model, enabling efficient parameter updates.

Result: Tina models achieve competitive or superior reasoning performance to SOTA models, with a >20% performance increase and 43.33% Pass@1 accuracy on AIME24, at only $9 USD post-training cost (260x cost reduction).

Conclusion: LoRA-based efficient RL reasoning is surprisingly effective, rapidly adapting models to reasoning structures while preserving base knowledge. The approach is validated across datasets and settings, with full open-source release for accessibility.

摘要: 如何在语言模型中经济高效地实现强大的推理能力？基于这一基本问题，我们提出了Tina，一种通过高成本效益实现的小型推理模型家族。值得注意的是，Tina证明了仅需极少的资源即可开发出显著的推理性能，方法是在强化学习（RL）过程中应用参数高效的更新，使用低秩适应（LoRA）技术，作用于一个已经很小的1.5B参数基础模型。这种极简方法产生的模型在推理性能上可与甚至有时超越基于同一基础模型构建的SOTA RL推理模型。关键的是，这一成果仅需现有SOTA模型计算后训练成本的一小部分。实际上，最佳Tina模型在AIME24上实现了超过20%的推理性能提升和43.33%的Pass@1准确率，而其后训练和评估成本仅为9美元（即估计成本降低了260倍）。我们的工作揭示了通过LoRA实现高效RL推理的惊人效果。我们在多个开源推理数据集和各种消融设置中验证了这一点，起始于一组固定的超参数。此外，我们假设这种效果和效率源于LoRA快速将模型适应于RL奖励的推理结构格式，同时很大程度上保留了基础模型的底层知识。为了促进可访问性和开放研究，我们完全开源了所有代码、训练日志以及模型权重和检查点。

</details>


### [33] [SDialog: A Python Toolkit for Synthetic Dialogue Generation and Analysis](https://arxiv.org/abs/2506.10622)
**中文标题：SDialog：用于合成对话生成与分析的Python工具包**

*Sergio Burdisso,Esaú Villatoro-Tello,Petr Motlicek*

Main category: cs.CL

TL;DR: SDialog is a Python toolkit for generating and analyzing synthetic dialogues using LLMs, designed to improve conversational AI research through modular and reproducible workflows.


<details>
  <summary>Details</summary>
Motivation: The need for high-quality, flexible, and reproducible synthetic dialogues to advance conversational AI systems.

Method: Leverages instruction-tuned LLMs for persona, orchestration, and scenario management to create realistic and diverse dialogues.

Result: SDialog enables multi-agent simulation and scenario-driven generation, standardizing synthetic data tools for reproducibility.

Conclusion: SDialog represents a crucial advancement in synthetic dialogue generation, supporting research and development in conversational AI.

摘要: 会话AI系统的进步依赖于高质量、灵活且可复现的合成对话数据，用于训练、评估和基准测试。SDialog是一个模块化、可扩展的Python工具包，旨在解决合成对话生成和分析的挑战。通过利用指令调优的大型语言模型（LLMs），SDialog提供了角色、编排和场景管理的抽象，从而为研究和开发创建真实、多样且可控的对话数据。SDialog支持多智能体模拟和场景驱动生成等工作流，代表了合成数据生成工具和框架标准化的重要进展，对确保当今快速发展的研究领域的可复现性至关重要。

</details>


### [34] [Resa: Transparent Reasoning Models via SAEs](https://arxiv.org/abs/2506.09967)
**中文标题：Resa：基于稀疏自编码器的透明推理模型**

*Shangshang Wang,Julian Asilis,Ömer Faruk Akgül,Enes Burak Bilgin,Ollie Liu,Deqing Fu,Willie Neiswanger*

Main category: cs.CL

TL;DR: Resa introduces SAE-Tuning, a cost-effective method to enhance reasoning in language models by leveraging sparse autoencoders, achieving high performance with minimal training cost and time.


<details>
  <summary>Details</summary>
Motivation: The paper aims to develop an efficient method to elicit strong reasoning abilities in language models without relying on expensive RL training or reasoning traces.

Method: Resa uses sparse autoencoder tuning (SAE-Tuning) to extract reasoning abilities from a source model and transfers them to a target model via supervised fine-tuning, using verified question-answer data.

Result: SAE-Tuning achieves >97% of RL-trained model performance at 2000x lower cost (~$1) and 450x faster (~20 minutes). It also enables modular and generalizable reasoning abilities across datasets and models.

Conclusion: SAE-Tuning is a highly efficient and scalable approach for enhancing reasoning in language models, with potential for broad applicability and modularity.

摘要: 如何通过利用语言模型的底层表示，以经济高效的方式激发其强大的推理能力？我们通过Resa回答了这个问题，这是一个通过新颖高效的稀疏自编码器调优（SAE-Tuning）方法训练的1.5B推理模型家族。该方法首先训练一个稀疏自编码器（SAE）从源模型中捕捉推理能力，然后利用训练好的SAE指导标准监督微调过程，在目标模型中激发这些能力，全程仅使用已验证的问答数据，无需任何推理轨迹。值得注意的是，当应用于某些基础模型并进一步进行RL后训练时，SAE-Tuning保留了其RL训练对应模型97%以上的推理性能，同时将训练成本降低了2000倍以上（约1美元），训练时间缩短了450倍以上（约20分钟）。此外，当应用于轻量RL训练的模型（例如在2个GPU上1小时内完成）时，它仅需约1美元的额外成本即可实现43.33%的AIME24 Pass@1和90%的AMC23 Pass@1推理性能。令人惊讶的是，通过SAE提取的推理能力可能既具有通用性又具有模块化特性。通用性意味着从一个数据集中提取的能力仍能提升更大且重叠语料库的性能。模块化意味着从Qwen或Qwen-Math提取的能力可以在测试时附加到R1-Distill模型上，无需任何重新训练，即可获得相当的提升。广泛的消融实验验证了这些发现，所有资源均已完全开源。

</details>


### [35] [NeuralNexus at BEA 2025 Shared Task: Retrieval-Augmented Prompting for Mistake Identification in AI Tutors](https://arxiv.org/abs/2506.10627)
**中文标题：NeuralNexus在BEA 2025共享任务中的表现：基于检索增强提示的AI导师错误识别**

*Numaan Naeem,Sarfraz Ahmad,Momina Ahsan,Hasan Iqbal*

Main category: cs.CL

TL;DR: The paper presents a retrieval-augmented prompting system for identifying mistakes in AI tutor responses, combining example-driven prompting with LLM reasoning to outperform baselines.


<details>
  <summary>Details</summary>
Motivation: To improve the pedagogical ability of AI tutors by accurately identifying mistakes in student mathematical reasoning, leveraging advanced language models and retrieval techniques.

Method: Explored four approaches: ensemble of ML models, frozen sentence-transformer with MLP, history-aware model with attention, and retrieval-augmented few-shot prompting with GPT-4o. The final system retrieves similar examples, constructs prompts, and uses schema-guided parsing.

Result: The retrieval-augmented prompting system outperformed all baselines, demonstrating effectiveness in pedagogical feedback assessment.

Conclusion: Combining example-driven prompting with LLM reasoning enhances mistake identification in AI tutors, offering a scalable and interpretable solution.

摘要: 本文介绍了我们在BEA 2025共享任务中针对AI导师教学能力评估的第一赛道——错误识别的系统。该任务涉及评估导师的回复是否正确识别了学生在数学推理中的错误。我们探索了四种方法：(1) 基于多个预训练语言模型（LMs）的池化标记嵌入的机器学习模型集成；(2) 使用[CLS]嵌入和MLP分类器的冻结句子转换器；(3) 具有多头部注意力的历史感知模型，用于标记级历史和响应嵌入；(4) 基于大型语言模型（LLM）如GPT-4o的检索增强少样本提示系统。我们的最终系统检索语义相似的示例，构建结构化提示，并使用模式引导的输出解析生成可解释的预测。该系统在所有基线方法中表现最优，证明了结合示例驱动提示与LLM推理在教学反馈评估中的有效性。代码可在https://github.com/NaumanNaeem/BEA_2025获取。

</details>


### [36] [Spelling-out is not Straightforward: LLMs' Capability of Tokenization from Token to Characters](https://arxiv.org/abs/2506.10641)
**中文标题：拼写并非直截了当：LLMs从标记到字符的分词能力**

*Tatsuya Hiraoka,Kentaro Inui*

Main category: cs.CL

TL;DR: LLMs can spell tokens character by character but struggle with complex character-level tasks. Their embedding layer lacks full character-level encoding, relying on higher layers for reconstruction.


<details>
  <summary>Details</summary>
Motivation: To understand how LLMs internally represent and utilize character-level information during spelling, despite their high accuracy in simple tasks but struggles with complex ones.

Method: Analyzed LLMs' spelling behavior through probing classifiers, identifying knowledge neurons, and inspecting attention weights to reveal how character-level information is reconstructed.

Result: LLMs' embedding layer does not fully encode character-level information beyond the first character, requiring intermediate and higher layers to reconstruct it, with a distinct 'breakthrough' in spelling behavior.

Conclusion: Spelling out tokens is not straightforward for LLMs; they rely on higher layers to compensate for incomplete character-level encoding in the embedding layer.

摘要: 大型语言模型（LLMs）可以逐个字符拼写标记，准确率很高，但在更复杂的字符级任务（如识别标记中的组合子成分）上表现不佳。本研究探讨了LLMs在拼写过程中如何内部表示和利用字符级信息。我们的分析表明，尽管拼写对人类来说是简单任务，但LLMs并未以直截了当的方式处理。具体而言，我们发现嵌入层并未完全编码字符级信息，尤其是第一个字符之后的信息。因此，LLMs依赖中间和更高层的Transformer层来重建字符级知识，在此过程中我们观察到其拼写行为的明显“突破”。我们通过三种互补分析验证了这一机制：探测分类器、知识神经元的识别以及注意力权重的检查。

</details>


### [37] [Large Language Models for Detection of Life-Threatening Texts](https://arxiv.org/abs/2506.10687)
**中文标题：大型语言模型在生命威胁文本检测中的应用**

*Thanh Thi Nguyen,Campbell Wilson,Janis Dalins*

Main category: cs.CL

TL;DR: The paper explores using large language models (LLMs) like Gemma, Mistral, and Llama-2 to detect life-threatening texts, outperforming traditional methods. Mistral and Llama-2 excel in balanced and imbalanced data, while upsampling helps traditional methods more than LLMs.


<details>
  <summary>Details</summary>
Motivation: To improve the detection of life-threatening language for mental health and safety, leveraging the advanced capabilities of LLMs over traditional methods.

Method: Fine-tuned three open-source LLMs (Gemma, Mistral, Llama-2) on datasets with balanced, imbalanced, and extremely imbalanced scenarios, comparing them with traditional methods like bag of words and BERT.

Result: LLMs, especially Mistral and Llama-2, outperformed traditional methods in all data scenarios. Upsampling helped traditional methods but had less impact on LLMs.

Conclusion: LLMs show strong potential for real-world detection of life-threatening language, with Mistral and Llama-2 being top performers.

摘要: 检测生命威胁语言对于保护处于困境中的个体、促进心理健康与福祉以及预防潜在伤害和生命损失至关重要。本文提出了一种利用大型语言模型（LLMs）识别生命威胁文本的有效方法，并将其与传统方法（如词袋模型、词嵌入、主题建模和双向编码器表示转换器）进行了比较。我们使用7B参数版本的Gemma、Mistral和Llama-2三种开源LLMs，在不同数据集（包括类别平衡、不平衡和极端不平衡场景）上进行了微调。实验结果表明，LLMs在性能上显著优于传统方法。具体而言，Mistral和Llama-2模型在平衡和不平衡数据场景中表现最佳，而Gemma稍逊一筹。我们采用上采样技术处理不平衡数据场景，发现该方法对传统方法有益，但对LLMs影响较小。本研究展示了LLMs在现实世界生命威胁语言检测问题中的巨大潜力。

</details>


### [38] [Inferring Adjective Hypernyms with Language Models to Increase the Connectivity of Open English Wordnet](https://arxiv.org/abs/2506.10715)
**中文标题：利用语言模型推断形容词上位词以增强开放英语词网的连通性**

*Lorenzo Augello,John P. McCrae*

Main category: cs.CL

TL;DR: The paper addresses missing hypernymy links for adjectives in Open English Wordnet by adapting TaxoLLaMa's methodology to predict and establish these links using fine-tuned language models.


<details>
  <summary>Details</summary>
Motivation: Open English Wordnet lacks many hypernymy links for adjectives, limiting its connectivity and utility. The paper aims to fill this gap by exploring and establishing adjective hypernymy.

Method: The authors discuss hypernymy relations for adjectives, develop a new resource for adjective hypernymy, and fine-tune large language models (TaxoLLaMa) to predict these relations.

Result: The adapted methodology successfully predicts adjective hypernymy, enhancing the connectivity of Open English Wordnet.

Conclusion: The study demonstrates the feasibility of using language models to infer adjective hypernymy, improving the resource's completeness and usefulness.

摘要: 开放英语词网是作为语言关联开放数据云的一部分发布在OntoLex-lemon中的关键资源。然而，该资源中缺少许多链接，本文探讨了如何建立形容词之间的上位关系。我们对上位关系进行了理论讨论，并比较了形容词与名词和动词在此关系上的差异。我们开发了一个新的形容词上位关系资源，并对大型语言模型进行微调以预测形容词上位关系，结果表明TaxoLLaMa的方法可以适用于此任务。

</details>


### [39] [PREMISE: Scalable and Strategic Prompt Optimization for Efficient Mathematical Reasoning in Large Models](https://arxiv.org/abs/2506.10716)
**中文标题：PREMISE：面向高效数学推理的可扩展和策略性提示优化方法**

*Ye Yu,Yaoning Yu,Haohan Wang*

Main category: cs.CL

TL;DR: PREMISE is a prompt-only framework that optimizes mathematical reasoning in large models by reducing token usage and cost without altering model weights, achieving comparable accuracy with significantly fewer tokens.


<details>
  <summary>Details</summary>
Motivation: Large reasoning models (LRMs) often produce verbose reasoning traces, increasing token usage and cost, which limits their deployment in latency-sensitive or API-constrained settings. PREMISE aims to address this inefficiency.

Method: PREMISE combines trace-level diagnostics with gradient-inspired prompt optimization to minimize redundant computation while preserving accuracy. It uses a multi-objective textual search to balance brevity and correctness.

Result: PREMISE matches or exceeds baseline accuracy (e.g., 96% with Claude, 92% with Gemini) while reducing reasoning tokens by up to 87.5% and cutting costs by 69-82%.

Conclusion: Prompt-level optimization is a practical and scalable approach to efficient LRM inference without compromising reasoning quality.

摘要: 大型推理模型（如Claude 3.7 Sonnet和OpenAI o1）在数学基准测试中表现出色，但其冗长的链式推理（CoT）往往导致不必要的冗余，增加了令牌使用和成本，限制了其在延迟敏感或API受限环境中的部署。我们提出了PREMISE（基于提示的高效数学推理与策略评估），这是一种仅通过提示优化的框架，无需修改模型权重即可减少推理开销。PREMISE结合了跟踪级诊断和梯度启发的提示优化，以最小化冗余计算并保持答案准确性。该方法通过多目标文本搜索平衡令牌长度和答案有效性，共同优化简洁性和正确性。与先前工作不同，PREMISE在单次黑盒接口中运行，可直接应用于商业大语言模型。在GSM8K、SVAMP和Math500测试中，我们匹配或超越了基线准确性（Claude从96%提升至96%，Gemini从91%提升至92%），同时将推理令牌减少高达87.5%，并将成本降低69%至82%。这些结果表明，提示级优化是一种实用且可扩展的路径，可在不损害推理质量的前提下实现高效的大型推理模型推断。

</details>


### [40] [Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims](https://arxiv.org/abs/2506.10728)
**中文标题：超越真伪：基于检索增强的细微主张层次分析**

*Priyanka Kargupta,Runchu Tian,Jiawei Han*

Main category: cs.CL

TL;DR: The paper introduces ClaimSpect, a framework for hierarchically analyzing nuanced claims by breaking them into aspects and sub-aspects, enriching them with corpus-specific perspectives, and validating them through retrieval-augmented generation.


<details>
  <summary>Details</summary>
Motivation: Claims often lack binary true/false labels, especially in scientific and political contexts, necessitating a structured approach to dissect and validate their nuanced aspects.

Method: ClaimSpect uses retrieval-augmented generation to construct a hierarchy of claim aspects, retrieves relevant corpus segments, and discovers sub-aspects and varying perspectives.

Result: Applied to real-world claims, ClaimSpect demonstrated robustness and accuracy in deconstructing nuanced claims and representing corpus perspectives, outperforming baselines.

Conclusion: ClaimSpect effectively addresses the complexity of nuanced claims by providing a hierarchical, perspective-rich analysis, validated through case studies and human evaluation.

摘要: 个人或实体提出的主张往往具有细微差别，无法简单地标记为完全“真实”或“虚假”——这在科学和政治主张中尤为常见。然而，一个主张（例如“疫苗A优于疫苗B”）可以分解为其核心方面和子方面（例如有效性、安全性、分发），这些方面更容易单独验证。这使得能够提供更全面、结构化的回应，为特定问题提供全面的视角，同时允许读者优先关注主张中的特定角度（例如对儿童的安全性）。因此，我们提出了ClaimSpect，这是一种基于检索增强生成的框架，用于自动构建处理主张时通常考虑的方面层次结构，并通过语料库特定视角丰富这些方面。该结构层次化地划分输入语料库以检索相关片段，有助于发现新的子方面。此外，这些片段能够发现对主张某一方面的不同视角（例如支持、中立或反对）及其各自的普遍性（例如“有多少生物医学论文认为疫苗A比B更具运输性？”）。我们将ClaimSpect应用于我们构建的数据集中广泛涵盖的现实世界科学和政治主张，展示了其在解构细微主张和表示语料库内视角方面的鲁棒性和准确性。通过现实案例研究和人工评估，我们验证了其在多个基线方法上的有效性。

</details>


### [41] [TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora](https://arxiv.org/abs/2506.10737)
**中文标题：TaxoAdapt：将基于大语言模型的多维分类体系构建与动态研究语料库对齐**

*Priyanka Kargupta,Nan Zhang,Yunyi Zhang,Rui Zhang,Prasenjit Mitra,Jiawei Han*

Main category: cs.CL

TL;DR: TaxoAdapt is a framework that dynamically adapts LLM-generated taxonomies to evolving scientific corpora across multiple dimensions, outperforming baselines in granularity and coherence.


<details>
  <summary>Details</summary>
Motivation: Scientific fields evolve rapidly, making literature organization challenging. Existing methods either lack generalizability or ignore the dynamic and multi-faceted nature of research. TaxoAdapt addresses these gaps by dynamically aligning taxonomies to corpora.

Method: TaxoAdapt uses iterative hierarchical classification to expand taxonomy width and depth based on corpus topical distribution, adapting to multiple dimensions of scientific literature.

Result: TaxoAdapt generates taxonomies 26.51% more granularity-preserving and 50.41% more coherent than competitive baselines, demonstrating state-of-the-art performance.

Conclusion: TaxoAdapt effectively structures and captures the evolution of scientific fields, offering a scalable and dynamic solution for taxonomy construction.

摘要: 科学领域的快速发展为文献组织和检索带来了挑战。虽然专家构建的分类体系传统上满足了这一需求，但这一过程耗时且昂贵。此外，近期的自动分类构建方法要么过度依赖特定语料库，牺牲了泛化性；要么过度依赖大语言模型（LLMs）预训练数据集中的通用知识，往往忽略了动态演变的科学领域。这些方法还未能考虑到科学文献的多维性，即单篇研究论文可能涉及多个维度（如方法、新任务、评估指标、基准）。为解决这些问题，我们提出了TaxoAdapt，这是一个动态地将LLM生成的分类体系与给定语料库在多个维度上对齐的框架。TaxoAdapt通过迭代的层次分类，根据语料库的主题分布扩展分类体系的宽度和深度。我们展示了其在多年间多个计算机科学会议上的最新性能，证明了其结构和捕捉科学领域演变的能力。作为一种多维方法，TaxoAdapt生成的分类体系在LLM评估下比最具竞争力的基线方法保留了26.51%的细粒度性，并提高了50.41%的连贯性。

</details>


### [42] [One Tokenizer To Rule Them All: Emergent Language Plasticity via Multilingual Tokenizers](https://arxiv.org/abs/2506.10766)
**中文标题：一统江湖的分词器：通过多语言分词器实现语言可塑性**

*Diana Abagyan,Alejandro R. Salamanca,Andres Felipe Cruz-Salinas,Kris Cao,Hangyu Lin,Acyr Locatelli,Marzieh Fadaee,Ahmet Üstün,Sara Hooker*

Main category: cs.CL

TL;DR: The paper proposes using a universal tokenizer trained on more languages than the primary pretraining languages to improve language adaptation capabilities in multilingual LLMs, achieving significant gains in language plasticity with minimal performance compromise.


<details>
  <summary>Details</summary>
Motivation: Pretraining multilingual LLMs is challenging due to limited model capacity, data scarcity, and tokenizer language gaps. The study aims to find cost-effective early interventions to enhance post-training language adaptation.

Method: The authors focus on tokenizer design, advocating for a universal tokenizer trained on more languages than the primary pretraining set. They conduct systematic experiments across diverse language groups and training strategies.

Result: A universal tokenizer improves language adaptation by up to 20.2% in win rates compared to language-specific tokenizers. It also enhances plasticity for completely unseen languages by up to 5% win rate gain, with minimal performance loss on pretraining languages.

Conclusion: A universal tokenizer significantly boosts language plasticity and adaptation in multilingual LLMs, offering a practical solution for expanding language coverage post-training.

摘要: 大规模多语言大型语言模型（LLMs）的预训练面临模型容量有限、高质量数据稀缺和计算资源限制等挑战。此外，分词器对语言的覆盖不足使得在训练后阶段填补新语言的空白更加困难。本研究探讨了在训练早期采用相对廉价的方法如何提升模型的“语言可塑性”，即训练后对新语言的适应能力。我们聚焦分词器设计，提出使用一种通用分词器，其训练语言数量超过主要预训练语言，以便在预训练后高效扩展语言覆盖范围。通过对不同语言组和训练策略的系统实验，我们发现通用分词器显著提升了语言适应能力，与预训练语言专用分词器相比，胜率提高了20.2%。此外，通用分词器还提升了完全未见于分词器和预训练中的语言的可塑性，胜率增益达5%。这种扩展语言集的适应能力在预训练包含的大多数语言上性能损失极小。

</details>


### [43] [Different Questions, Different Models: Fine-Grained Evaluation of Uncertainty and Calibration in Clinical QA with LLMs](https://arxiv.org/abs/2506.10769)
**中文标题：不同问题，不同模型：临床问答中LLM不确定性和校准的细粒度评估**

*Alberto Testoni,Iacer Calixto*

Main category: cs.CL

TL;DR: The paper evaluates uncertainty estimation methods in clinical QA with LLMs, comparing ten models across specialties and question types, and introduces lightweight single-pass estimators that perform close to Semantic Entropy.


<details>
  <summary>Details</summary>
Motivation: To ensure accurate and well-calibrated uncertainty estimates for deploying LLMs in high-stakes clinical decision support, addressing variability across models and question types.

Method: Fine-grained evaluation of ten open-source LLMs using standard and sampling-based uncertainty methods, plus a case study on single-pass estimators based on reasoning traces.

Result: Substantial variation across specialties and question types, with lightweight single-pass estimators performing close to Semantic Entropy.

Conclusion: Model selection should consider question nature and model strengths, with lightweight methods offering efficient uncertainty estimation.

摘要: 准确且校准良好的不确定性估计对于在临床决策支持等高风险领域部署大型语言模型（LLM）至关重要。我们对临床多项选择题回答中的不确定性估计方法进行了细粒度评估，涵盖十个开源LLM（通用、生物医学和推理模型），涉及两个数据集、十一个医学专业和六种问题类型。我们比较了标准的单生成和基于采样的方法，并通过案例研究探索了基于推理轨迹中行为信号的简单单次估计器。这些轻量级方法在仅需一次生成的情况下，性能接近语义熵。我们的结果揭示了专业和问题类型之间的显著差异，强调了根据问题性质和模型特定优势选择模型的重要性。

</details>


### [44] [Improving Named Entity Transcription with Contextual LLM-based Revision](https://arxiv.org/abs/2506.10779)
**中文标题：利用基于上下文的大型语言模型修订改进命名实体转录**

*Viet Anh Trinh,Xinlu He,Jacob Whitehill*

Main category: cs.CL

TL;DR: The paper proposes an LLM-based revision method to improve named entity transcription in ASR systems, achieving a 30% relative WER reduction on the NER-MIT-OpenCourseWare dataset.


<details>
  <summary>Details</summary>
Motivation: Named entities are critical but often misrecognized by ASR systems, impacting downstream applications. The paper aims to reduce WER for named entities using LLM-based revision.

Method: The authors introduce an LLM revision mechanism that leverages the model's reasoning ability and local context (e.g., lecture notes) to correct named entities in ASR predictions.

Result: The proposed method achieves up to 30% relative WER reduction for named entities on the NER-MIT-OpenCourseWare dataset.

Conclusion: The LLM-based revision mechanism effectively improves named entity transcription in ASR systems, demonstrating significant WER reduction.

摘要: 随着建模技术的进步和监督训练数据的增加，自动语音识别（ASR）系统在通用语音上取得了显著性能。然而，最先进的ASR在命名实体上的词错误率（WER）仍然较高。由于命名实体通常是最关键的关键词，误识别它们会影响所有下游应用，尤其是当ASR系统作为复杂系统的前端时。本文引入了一种大型语言模型（LLM）修订机制，通过利用LLM的推理能力以及包含一组正确命名实体的局部上下文（例如讲义）来修订ASR预测中的错误命名实体。最后，我们介绍了NER-MIT-OpenCourseWare数据集，包含45小时的MIT课程数据用于开发和测试。在该数据集上，我们提出的技术实现了命名实体高达30%的相对WER降低。

</details>


### [45] [Mitigating Negative Interference in Multilingual Sequential Knowledge Editing through Null-Space Constraints](https://arxiv.org/abs/2506.10800)
**中文标题：通过零空间约束缓解多语言顺序知识编辑中的负面干扰**

*Wei Sun,Tingyu Qu,Mingxiao Li,Jesse Davis,Marie-Francine Moens*

Main category: cs.CL

TL;DR: The paper introduces LangEdit, a framework for multilingual knowledge editing in LLMs that mitigates negative interference by isolating language-specific updates through null-space constraints, improving accuracy and generalization.


<details>
  <summary>Details</summary>
Motivation: Updating multilingual knowledge in LLMs without causing destructive interference across languages is challenging. Separate editing systems for each language are costly, while unified models often suffer from parameter interference.

Method: LangEdit projects parameter updates for each language onto the orthogonal complement of previous subspaces, ensuring independence and preserving multilingual generalization.

Result: LangEdit outperforms existing methods, effectively mitigating interference and improving accuracy across three model architectures, six languages, and four tasks.

Conclusion: LangEdit enables efficient and accurate multilingual knowledge updates in LLMs, demonstrating significant potential for practical applications.

摘要: 高效更新大型语言模型（LLMs）中的多语言知识，同时保持跨语言的事实表示一致性，是一个长期未解决的挑战。虽然为每种语言部署单独的编辑系统看似可行，但这种方法因需要管理多个模型而产生高昂成本。更高效的解决方案是将所有语言的知识更新集成到一个统一模型中。然而，跨语言的顺序编辑通常会导致破坏性的参数干扰，显著降低多语言泛化能力和注入知识的准确性。为解决这一挑战，我们提出了LangEdit，一种新颖的零空间约束框架，旨在精确隔离特定语言的知识更新。LangEdit的核心创新在于其能够将每种语言的参数更新投影到先前更新子空间的正交补集上。这种方法在数学上保证了更新的独立性，同时保留了多语言泛化能力。我们在三种模型架构、六种语言和四个下游任务上进行了全面评估，结果表明LangEdit有效缓解了参数干扰，并优于现有的最先进编辑方法。我们的结果突显了其在LLMs中实现高效准确多语言知识更新的潜力。代码可在https://github.com/VRCMF/LangEdit.git获取。

</details>


### [46] [ReCUT: Balancing Reasoning Length and Accuracy in LLMs via Stepwise Trails and Preference Optimization](https://arxiv.org/abs/2506.10822)
**中文标题：ReCUT：通过逐步探索和偏好优化平衡大语言模型的推理长度与准确性**

*Zhensheng Jin,Xinze Li,Yifan Ji,Chunyi Peng,Zhenghao Liu,Qi Shi,Yukun Yan,Shuo Wang,Furong Peng,Ge Yu*

Main category: cs.CL

TL;DR: ReCUT introduces a method to balance reasoning length and accuracy in LLMs by generating diverse reasoning paths, training specialized models for accuracy and brevity, and integrating them, achieving shorter reasoning lengths without sacrificing accuracy.


<details>
  <summary>Details</summary>
Motivation: Current Chain-of-Thought (CoT) methods for LLMs often produce unnecessarily lengthy or redundant reasoning traces, and existing solutions are limited by data quality and overfitting. ReCUT aims to address these issues by optimizing reasoning length and accuracy.

Method: ReCUT uses stepwise exploration and long-short switched sampling to generate diverse reasoning paths, evaluates them to create preference pairs, trains two specialized models (for accuracy and brevity), and integrates them via parameter interpolation.

Result: ReCUT reduces reasoning lengths by 30-50% while maintaining or improving accuracy across multiple math reasoning datasets and backbone models compared to baselines.

Conclusion: ReCUT effectively balances reasoning length and accuracy in LLMs, offering a practical solution to the overthinking problem in CoT prompting.

摘要: 最近，思维链（CoT）提示的进展显著提升了大语言模型（LLM）的推理能力。然而，这些方法常因过度思考导致推理轨迹冗长或冗余。现有方法通过整理多条推理链训练LLM来缓解这一问题，但其效果常受生成数据质量的限制且易过拟合。为解决这一挑战，我们提出“通过逐步探索压缩推理”（ReCUT），旨在平衡推理轨迹的准确性与长度。具体而言，ReCUT采用逐步探索机制和长短切换采样策略，使LLM能逐步生成多样化的推理路径。这些路径经评估后用于构建偏好对，以训练两个专用模型（Gemini LLM）——一个优化推理准确性，另一个优化推理简洁性。最终通过参数插值整合这两个模型。在多个数学推理数据集和骨干模型上的实验结果表明，与多种基线相比，ReCUT显著缩短推理长度约30-50%，同时保持或提升推理准确性。所有代码和数据将通过https://github.com/NEUIR/ReCUT发布。

</details>


### [47] [CIIR@LiveRAG 2025: Optimizing Multi-Agent Retrieval Augmented Generation through Self-Training](https://arxiv.org/abs/2506.10844)
**中文标题：CIIR@LiveRAG 2025：通过自训练优化多智能体检索增强生成**

*Alireza Salemi,Mukta Maddipatla,Hamed Zamani*

Main category: cs.CL

TL;DR: The paper introduces mRAG, a multi-agent RAG framework optimized through self-training, outperforming traditional RAG baselines in the SIGIR 2025 LiveRAG competition.


<details>
  <summary>Details</summary>
Motivation: To enhance retrieval-augmented generation (RAG) by developing a multi-agent system that improves collaboration and response quality through self-training.

Method: mRAG employs specialized agents for subtasks (planning, searching, reasoning, coordination) and uses self-training with reward-guided trajectory sampling to optimize performance.

Result: mRAG outperforms conventional RAG baselines on DataMorgana-derived datasets in the SIGIR 2025 LiveRAG competition, demonstrating superior efficacy.

Conclusion: The mRAG framework is effective for complex RAG tasks, showcasing improved inter-agent collaboration and response generation through self-training.

摘要: 本文介绍了mRAG，一种由规划、搜索、推理和协调等子任务专用智能体组成的多智能体检索增强生成（RAG）框架。我们的系统采用自训练范式，通过奖励引导的轨迹采样优化智能体间协作并提升响应生成。在SIGIR 2025 LiveRAG竞赛中基于DataMorgana数据集进行评估，mRAG表现优于传统RAG基线。我们进一步分析了竞赛结果，并通过案例研究展示了该框架的优势，证明了其在复杂现实世界RAG任务中的有效性。

</details>


### [48] [Accelerating Diffusion Large Language Models with SlowFast: The Three Golden Principles](https://arxiv.org/abs/2506.10848)
**中文标题：利用SlowFast加速扩散大语言模型：三条黄金原则**

*Qingyan Wei,Yaojie Zhang,Zhiyuan Liu,Dongrui Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: The paper introduces SlowFast Sampling, a dynamic strategy for diffusion-based language models (dLLMs) that alternates between exploratory and accelerated decoding stages, guided by three principles, achieving significant speedups with minimal accuracy loss.


<details>
  <summary>Details</summary>
Motivation: Existing sampling strategies for dLLMs suffer from static behavior, leading to inefficiency and limited flexibility, prompting the need for a dynamic approach to improve performance.

Method: Proposes SlowFast Sampling, a dynamic strategy guided by certainty, convergence, and positional principles, integrated with dLLM-Cache to reduce redundant computation.

Result: Achieves up to 15.63× speedup on LLaDA with minimal accuracy drop, and up to 34.22× when combined with caching, outperforming autoregressive baselines like LLaMA3 8B.

Conclusion: Well-designed sampling can unlock the full potential of dLLMs for fast and high-quality generation, demonstrating the effectiveness of SlowFast Sampling.

摘要: 扩散式语言模型（dLLMs）作为一种有前景的替代方案，通过并行生成标记显著降低了推理延迟。然而，现有的采样策略（如基于置信度或半自回归解码）常因静态行为导致效率低下和灵活性受限。本文提出SlowFast采样，一种动态采样策略，自适应地在探索性和加速解码阶段交替切换。该方法遵循三条黄金原则：确定性原则、收敛性原则和位置性原则，指导何时何地可以高效且自信地解码标记。我们进一步将该策略与dLLM-Cache结合以减少冗余计算。在多个基准和模型上的实验表明，SlowFast采样在LLaDA上实现了高达15.63倍的加速且精度损失极小，结合缓存后可达34.22倍。值得注意的是，我们的方法在吞吐量上优于LLaMA3 8B等强自回归基线，表明精心设计的采样策略可以充分释放dLLMs在快速高质量生成中的潜力。

</details>


### [49] [Analyzing the relationships between pretraining language, phonetic, tonal, and speaker information in self-supervised speech models](https://arxiv.org/abs/2506.10855)
**中文标题：分析自监督语音模型中预训练语言、语音、声调和说话者信息之间的关系**

*Michele Gubian,Ioana Krehan,Oli Liu,James Kirby,Sharon Goldwater*

Main category: cs.CL

TL;DR: The paper analyzes how wav2vec2 models trained on different languages encode phonetic, tonal, and speaker information, finding that these representations are largely orthogonal and similar across languages.


<details>
  <summary>Details</summary>
Motivation: To understand how self-supervised speech models (specifically wav2vec2) represent phonetic, tonal, and speaker information across different languages, as most prior analyses focused only on English.

Method: The study uses probing classifiers and geometric analyses on wav2vec2 models trained on four languages to examine representations of phones, tones, and speakers.

Result: The subspaces encoding phones, tones, and speakers are largely orthogonal across pretraining and test languages, with minor advantages for matched-language phone and tone probes in later layers.

Conclusion: The structure of representations learned by wav2vec2 is largely independent of the pretraining language, suggesting universal patterns in self-supervised speech models.

摘要: 自监督语音模型的分析已开始揭示它们如何表示不同类型的信息。然而，几乎所有分析都集中在英语上。本文研究了在四种不同语言上训练的wav2vec2模型如何编码语言匹配和非匹配的语音。我们使用探测分类器和几何分析来检查语音、词汇声调和说话者信息的表示方式。结果表明，对于所有预训练和测试语言，编码语音、声调和说话者的子空间基本正交，且探测准确率的层级模式相似，后期层中匹配语言的语音和声调（而非说话者）探测略有优势。我们的发现表明，wav2vec2学习的表示结构在很大程度上独立于预训练中使用的语音材料。

</details>


### [50] [Enhancing Medical Dialogue Generation through Knowledge Refinement and Dynamic Prompt Adjustment](https://arxiv.org/abs/2506.10877)
**中文标题：通过知识精炼和动态提示调整增强医疗对话生成**

*Hongda Sun,Jiaren Peng,Wenzhong Yang,Liang He,Bo Du,Rui Yan*

Main category: cs.CL

TL;DR: The paper introduces MedRef, a medical dialogue system that enhances response quality by refining knowledge and dynamically adjusting prompts, outperforming existing methods in accuracy and generation quality.


<details>
  <summary>Details</summary>
Motivation: Existing medical dialogue systems struggle with identifying relevant knowledge and generating personalized, accurate responses, necessitating an improved approach.

Method: MedRef uses a knowledge refining mechanism and dynamic prompt adjustment, including Triplet Filter and Demo Selector modules, to improve response relevance and accuracy.

Result: MedRef outperforms state-of-the-art baselines on MedDG and KaMed benchmarks in generation quality and medical entity accuracy.

Conclusion: MedRef is effective and reliable for real-world healthcare applications, demonstrating superior performance in medical dialogue generation.

摘要: 医疗对话系统（MDS）已成为支持与患者进行多轮、上下文感知对话的关键在线平台。然而，现有MDS往往难以（1）识别相关医学知识，（2）生成个性化且医学准确的回答。为解决这些问题，我们提出了MedRef，一种新型MDS，结合了知识精炼和动态提示调整。首先，我们采用知识精炼机制过滤无关医学数据，提高对回答中关键医学实体的预测能力。此外，我们设计了一种综合提示结构，整合历史细节和显性细节。为实现对不同患者病情的实时适应，我们实现了两个关键模块——三元组过滤器和演示选择器，提供系统提示中配备的适当知识和示例。在MedDG和KaMed基准上的大量实验表明，MedRef在生成质量和医学实体准确性上均优于现有基线方法，证明了其在现实医疗应用中的有效性和可靠性。

</details>


### [51] [Slimming Down LLMs Without Losing Their Minds](https://arxiv.org/abs/2506.10885)
**中文标题：在不丧失智能的情况下精简大型语言模型**

*Qingda,Mai*

Main category: cs.CL

TL;DR: The paper validates that LoRA and QLoRA fine-tuning methods improve task-specific performance in LLMs efficiently, with performance linked to dataset-task alignment.


<details>
  <summary>Details</summary>
Motivation: To explore how parameter-efficient fine-tuning methods (LoRA and QLoRA) impact LLM performance across reasoning and knowledge tasks, providing insights for resource-limited developers.

Method: Evaluated LoRA and QLoRA on three domains: commonsense reasoning (HellaSwag), mathematical reasoning (GSM8K), and multi-domain knowledge (MMLU-CS).

Result: LoRA-based methods enhance task-specific performance efficiently, with performance heavily influenced by dataset-task alignment.

Conclusion: Parameter-efficient fine-tuning (e.g., LoRA) is effective for LLM adaptation, offering practical guidance for developers with limited resources.

摘要: 本文研究并验证了微调对大型语言模型性能的影响，重点关注参数高效方法（LoRA和QLoRA）。我们评估了模型在三个关键领域的性能：（1）常识推理（HellaSwag），（2）数学推理（GSM8K），以及（3）多领域知识（MMLU-CS）。
研究结果表明：（1）基于LoRA的方法在保持计算效率的同时有效提高了任务特定性能；（2）性能很大程度上取决于微调数据集与基准任务之间的对齐。该研究不仅提供了对参数高效机制的理论见解，还为开发者在资源有限的情况下实现高效LLM适应提供了实用指导。

</details>


### [52] [Generalization or Hallucination? Understanding Out-of-Context Reasoning in Transformers](https://arxiv.org/abs/2506.10887)
**中文标题：泛化还是幻觉？理解Transformer中的上下文外推理**

*Yixiao Huang,Hanlin Zhu,Tianyu Guo,Jiantao Jiao,Somayeh Sojoudi,Michael I. Jordan,Stuart Russell,Song Mei*

Main category: cs.CL

TL;DR: The paper explores how large language models (LLMs) exhibit both generalization and hallucination due to out-of-context reasoning (OCR), a mechanism that associates concepts regardless of causal links. It formalizes OCR, demonstrates its role in model behavior, and attributes it to gradient descent's implicit bias favoring low nuclear norm solutions.


<details>
  <summary>Details</summary>
Motivation: The duality of LLMs—generalizing from new facts while hallucinating incorrect information—is poorly understood. The paper aims to uncover the underlying mechanism (OCR) driving both behaviors.

Method: The study formalizes OCR as a synthetic factual recall task, tests it across five LLMs, and analyzes a simplified transformer model to isolate the role of matrix factorization. Theoretical analysis links OCR to gradient descent's implicit bias.

Result: OCR drives both generalization and hallucination, depending on causal relationships between concepts. Matrix factorization is crucial for OCR, and gradient descent's bias toward low nuclear norm solutions explains the phenomenon.

Conclusion: The work provides a theoretical foundation for OCR, explaining LLM behaviors and offering insights for mitigating undesirable effects of knowledge injection.

摘要: 大型语言模型（LLM）可以通过微调获取新知识，但这一过程表现出一种令人困惑的双重性：模型可以从新事实中显著泛化，但也容易产生幻觉性错误信息。然而，这一现象的原因仍知之甚少。本文认为，这两种行为源于一种称为上下文外推理（OCR）的单一机制：即通过关联概念（即使没有因果关系）推断含义的能力。我们在五个主流LLM上的实验证实，OCR确实驱动了泛化和幻觉，具体取决于关联概念是否具有因果关系。为了对这一现象建立严格的理论理解，我们将OCR形式化为一种合成事实回忆任务。实证表明，具有分解输出和值矩阵的单层单头注意力Transformer可以学习解决此任务，而权重合并的模型则不能，这凸显了矩阵分解的关键作用。我们的理论分析表明，OCR能力可归因于梯度下降的隐式偏差，其倾向于最小化合输出-值矩阵的核范数的解。这种数学结构解释了为什么模型能够高效地学习关联事实和含义，无论相关性是因果性的还是仅仅是虚假的。最终，我们的工作为理解OCR现象提供了理论基础，为分析和减轻知识注入中的不良行为提供了新的视角。

</details>


### [53] [BioClinical ModernBERT: A State-of-the-Art Long-Context Encoder for Biomedical and Clinical NLP](https://arxiv.org/abs/2506.10896)
**中文标题：BioClinical ModernBERT：一种用于生物医学和临床自然语言处理的最先进长上下文编码器**

*Thomas Sounack,Joshua Davis,Brigitte Durieux,Antoine Chaffin,Tom J. Pollard,Eric Lehman,Alistair E. W. Johnson,Matthew McDermott,Tristan Naumann,Charlotta Lindvall*

Main category: cs.CL

TL;DR: BioClinical ModernBERT is a state-of-the-art biomedical and clinical NLP encoder, adapted from ModernBERT, offering long-context processing, improved speed, and performance through extensive pretraining on a diverse corpus.


<details>
  <summary>Details</summary>
Motivation: Encoder models in biomedical and clinical NLP have lagged in development compared to decoders, limiting domain adaptation. BioClinical ModernBERT aims to address this gap by providing a high-performance, domain-specific encoder.

Method: The model is developed via continued pretraining on a large biomedical and clinical corpus (53.5B tokens) and leverages 20 diverse datasets. It includes base (150M) and large (396M) parameter versions.

Result: BioClinical ModernBERT outperforms existing encoders on four downstream tasks, demonstrating superior performance across diverse biomedical and clinical use cases.

Conclusion: BioClinical ModernBERT sets a new standard for biomedical and clinical NLP encoders, offering improved capabilities and supporting further research through released checkpoints.

摘要: 基于编码器的Transformer模型在生物医学和临床自然语言处理（NLP）中至关重要，其双向自注意力机制使其非常适合通过判别任务从非结构化文本中高效提取结构化信息。然而，与解码器模型相比，编码器的发展较慢，导致在生物医学和临床领域的适应性有限。我们推出了BioClinical ModernBERT，这是一种基于最新ModernBERT发布的领域适应编码器，结合了长上下文处理能力，并在生物医学和临床NLP的速度和性能上实现了显著提升。BioClinical ModernBERT通过迄今为止最大的生物医学和临床语料库（超过535亿个标记）进行持续预训练而开发，并通过利用来自不同机构、领域和地理区域的20个数据集（而非依赖单一来源的数据）解决了先前临床编码器的一个关键限制。它在涵盖广泛用例的四个下游任务中优于现有的生物医学和临床编码器。我们发布了BioClinical ModernBERT的基础版（1.5亿参数）和大版（3.96亿参数），以及训练检查点以支持进一步研究。

</details>


### [54] [Beyond Gold Standards: Epistemic Ensemble of LLM Judges for Formal Mathematical Reasoning](https://arxiv.org/abs/2506.10903)
**中文标题：超越黄金标准：基于LLM评委的认知集成用于形式数学推理**

*Lan Zhang,Marco Valentino,Andre Freitas*

Main category: cs.CL

TL;DR: The paper introduces an epistemically grounded ensemble (EFG) of LLM judges to evaluate autoformalization in formal mathematical reasoning, outperforming coarse-grained methods by aligning better with human assessments.


<details>
  <summary>Details</summary>
Motivation: Existing methods for evaluating autoformalization in formal mathematical reasoning are limited by coarse-grained criteria, making them ineffective for nuanced, advanced domains. Human evaluation is time-consuming and requires expertise.

Method: Proposes an epistemically and formally grounded ensemble (EFG) of LLM judges, evaluating autoformalization based on logical preservation, mathematical consistency, formal validity, and formal quality.

Result: The EFG ensemble correlates more strongly with human assessments than coarse-grained models, especially in evaluating formal qualities, proving it a reliable proxy for autoformalization evaluation.

Conclusion: LLM-as-judges, guided by well-defined atomic properties, offer scalable, interpretable, and reliable support for evaluating formal mathematical reasoning.

摘要: 自动形式化在形式数学推理中起着关键作用，它能够将自然语言陈述自动翻译为形式语言。尽管最近使用大型语言模型（LLM）的进展显示出有希望的结果，但自动评估自动形式化的方法仍未得到充分探索。随着转向更复杂的领域（如高等数学），人工评估需要大量时间和领域专业知识，尤其是当底层陈述和背景知识的复杂性增加时。LLM作为评委为自动化此类评估提供了一种有前景的方法。然而，现有方法通常采用粗粒度和通用的评估标准，限制了其在高级形式数学推理中的有效性，而质量取决于细微的多粒度维度。在本研究中，我们通过引入一种系统化的自动方法来评估自动形式化任务，朝着填补这一空白迈出了一步。所提出的方法基于一种认知和形式上扎根的LLM评委集成（EFG），其标准包括逻辑保持（LP）、数学一致性（MC）、形式有效性（FV）和形式质量（FQ），从而实现了对不同贡献因素的透明评估。我们验证了该框架可作为形式数学领域中自动形式化评估的代理。总体而言，我们的实验表明，EFG集成LLM评委是一种合适的新兴评估代理，与粗粒度模型相比，其与人工评估的相关性更强，尤其是在评估形式质量时。这些发现表明，LLM作为评委，尤其是在一组明确定义的原子属性指导下，可以为评估形式数学推理提供可扩展、可解释且可靠的支持。

</details>


### [55] [Magistral](https://arxiv.org/abs/2506.10910)
**中文标题：Magistral**

*Mistral-AI,:,Abhinav Rastogi,Albert Q. Jiang,Andy Lo,Gabrielle Berrada,Guillaume Lample,Jason Rute,Joep Barmentlo,Karmesh Yadav,Kartik Khandelwal,Khyathi Raghavi Chandu,Léonard Blier,Lucile Saulnier,Matthieu Dinot,Maxime Darrin,Neha Gupta,Roman Soletskyi,Sagar Vaze,Teven Le Scao,Yihan Wang,Adam Yang,Alexander H. Liu,Alexandre Sablayrolles,Amélie Héliou,Amélie Martin,Andy Ehrenberg,Anmol Agarwal,Antoine Roux,Arthur Darcet,Arthur Mensch,Baptiste Bout,Baptiste Rozière,Baudouin De Monicault,Chris Bamford,Christian Wallenwein,Christophe Renaudin,Clémence Lanfranchi,Darius Dabert,Devon Mizelle,Diego de las Casas,Elliot Chane-Sane,Emilien Fugier,Emma Bou Hanna,Gauthier Delerce,Gauthier Guinet,Georgii Novikov,Guillaume Martin,Himanshu Jaju,Jan Ludziejewski,Jean-Hadrien Chabran,Jean-Malo Delignon,Joachim Studnia,Jonas Amar,Josselin Somerville Roberts,Julien Denize,Karan Saxena,Kush Jain,Lingxiao Zhao,Louis Martin,Luyu Gao,Lélio Renard Lavaud,Marie Pellat,Mathilde Guillaumin,Mathis Felardos,Maximilian Augustin,Mickaël Seznec,Nikhil Raghuraman,Olivier Duchenne,Patricia Wang,Patrick von Platen,Patryk Saffer,Paul Jacob,Paul Wambergue,Paula Kurylowicz,Pavankumar Reddy Muddireddy,Philomène Chagniot,Pierre Stock,Pravesh Agrawal,Romain Sauvestre,Rémi Delacourt,Sanchit Gandhi,Sandeep Subramanian,Shashwat Dalal,Siddharth Gandhi,Soham Ghosh,Srijan Mishra,Sumukh Aithal,Szymon Antoniak,Thibault Schueller,Thibaut Lavril,Thomas Robert,Thomas Wang,Timothée Lacroix,Valeriia Nemychnikova,Victor Paltz,Virgile Richard,Wen-Ding Li,William Marshall,Xuanyu Zhang,Yunhao Tang*

Main category: cs.CL

TL;DR: Magistral is Mistral's first reasoning model, developed using a scalable RL pipeline. It explores pure RL training for LLMs, introduces a method to enforce reasoning language, and shows RL on text maintains or enhances model capabilities. Magistral Medium and Small are released, with the latter open-sourced.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explore the limits of pure RL training for LLMs without relying on prior models or implementations, and to demonstrate the effectiveness of RL on text data for maintaining or improving model capabilities.

Method: The authors use a ground-up approach with their own models and infrastructure, focusing on pure RL training. They introduce a method to enforce reasoning language and train Magistral Medium on Mistral Medium 3 using RL alone. Magistral Small includes cold-start data from Magistral Medium.

Result: RL on text maintains or improves multimodal understanding, instruction following, and function calling. Magistral Medium and Small are successfully trained, with the latter open-sourced under Apache 2.0.

Conclusion: The study demonstrates the feasibility and benefits of pure RL training for LLMs, showing that RL on text data preserves or enhances model capabilities. Magistral models are released to support further research.

摘要: 我们介绍了Magistral，这是Mistral的第一个推理模型，以及我们自己的可扩展强化学习（RL）流程。我们没有依赖现有实现或从先前模型中提取的RL痕迹，而是采用了一种从头开始的方法，仅依赖我们自己的模型和基础设施。值得注意的是，我们展示了一个使我们能够探索纯RL训练LLM极限的堆栈，提出了一种强制模型推理语言的简单方法，并表明仅对文本数据进行RL训练可以保留初始检查点的大部分能力。我们发现，对文本进行RL训练可以保持或提升多模态理解、指令遵循和函数调用能力。我们推出了Magistral Medium，它在Mistral Medium 3的基础上仅通过RL训练进行推理，并开源了Magistral Small（Apache 2.0），其中还包括来自Magistral Medium的冷启动数据。

</details>


### [56] [Decomposing MLP Activations into Interpretable Features via Semi-Nonnegative Matrix Factorization](https://arxiv.org/abs/2506.10920)
**中文标题：通过半非负矩阵分解将MLP激活分解为可解释特征**

*Or Shafran,Atticus Geiger,Mor Geva*

Main category: cs.CL

TL;DR: The paper proposes using Semi-Nonnegative Matrix Factorization (SNMF) to decompose MLP activations in LLMs, yielding interpretable features that outperform sparse autoencoders and supervised baselines in causal evaluations.


<details>
  <summary>Details</summary>
Motivation: Current methods like sparse autoencoders (SAEs) for identifying interpretable features in LLMs lack intrinsic interpretability and struggle in causal evaluations. The paper aims to address these limitations by directly decomposing MLP activations using SNMF.

Method: The paper employs semi-nonnegative matrix factorization (SNMF) to decompose MLP activations, ensuring features are sparse linear combinations of co-activated neurons and mapped to their activating inputs for interpretability.

Result: SNMF-derived features outperform SAEs and a supervised baseline (difference-in-means) in causal steering tasks and align with human-interpretable concepts. The analysis also reveals hierarchical structures in MLP activation spaces.

Conclusion: SNMF is a simple and effective tool for identifying interpretable features in LLMs, offering better performance and alignment with human concepts compared to existing methods.

摘要: 机制可解释性的核心目标之一是确定大型语言模型（LLM）中能够因果解释其输出的分析单元。早期研究集中于单个神经元，但神经元通常编码多个概念的证据促使研究方向转向激活空间中的方向。关键问题是如何以无监督方式找到捕捉可解释特征的方向。现有方法依赖于稀疏自编码器（SAE）的字典学习，通常通过残差流激活训练以从头学习方向。然而，SAE在因果评估中表现不佳，且缺乏内在可解释性，因为其学习未明确与模型计算绑定。本文通过半非负矩阵分解（SNMF）直接分解MLP激活来解决这些限制，使得学习到的特征是（a）共激活神经元的稀疏线性组合，（b）映射到其激活输入，从而直接可解释。在Llama 3.1、Gemma 2和GPT-2上的实验表明，SNMF衍生的特征在因果操控上优于SAE和强监督基线（均值差异），并与人类可解释概念一致。进一步分析揭示，特定神经元组合在语义相关特征间被重复使用，暴露了MLP激活空间中的层次结构。这些结果表明，SNMF是一种简单有效的工具，可用于识别可解释特征并剖析LLM中的概念表示。

</details>


### [57] [Dynamic Epistemic Friction in Dialogue](https://arxiv.org/abs/2506.10934)
**中文标题：对话中的动态认知摩擦**

*Timothy Obiso,Kenneth Lai,Abhijnan Nath,Nikhil Krishnaswamy,James Pustejovsky*

Main category: cs.CL

TL;DR: The paper introduces 'dynamic epistemic friction' as resistance to belief updates in dialogues, positioning it within Dynamic Epistemic Logic, and demonstrates its predictive power in collaborative tasks.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the overlooked role of epistemic friction in belief updates during human-AI interactions, highlighting its importance in aligning Large Language Models with human preferences.

Method: The study defines dynamic epistemic friction within Dynamic Epistemic Logic and analyzes its effects in a collaborative task to predict belief updates in dialogues.

Result: The model of epistemic friction effectively predicts belief updates in dialogues and can be refined to handle real-world dialogue complexities.

Conclusion: Dynamic epistemic friction is a crucial factor in belief alignment, offering a framework to enhance human-AI collaboration by addressing resistance to belief updates.

摘要: 近期，大型语言模型（LLMs）与人类偏好的对齐显著提升了其在人机协作场景中的实用性。然而，这些方法往往忽视了“认知摩擦”的关键作用，即在面对新的、冲突的或模糊信息时更新信念所遇到的固有阻力。本文中，我们将动态认知摩擦定义为对认知整合的阻力，其特征是智能体当前信念状态与外部证据支持的新命题之间的错位。我们将其置于动态认知逻辑（Van Benthem和Pacuit，2011）的框架中，其中摩擦在交互过程中表现为非平凡的信念修正。随后，我们通过一项协作任务的分析，展示了这种认知摩擦模型如何有效预测对话中的信念更新，并进一步讨论了如何将信念对齐作为认知阻力或摩擦的度量模型自然地进行复杂化，以适应现实世界对话场景的复杂性。

</details>


### [58] [Domain2Vec: Vectorizing Datasets to Find the Optimal Data Mixture without Training](https://arxiv.org/abs/2506.10952)
**中文标题：Domain2Vec：向量化数据集以无需训练找到最优数据混合**

*Mozhi Zhang,Howe Tissue,Lu Wang,Xipeng Qiu*

Main category: cs.CL

TL;DR: Domain2Vec introduces a method to decompose datasets into meta-domains, enabling training-free identification of optimal data mixtures for language model pretraining, improving efficiency and performance.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of finding the optimal data mixture for language model pretraining without extensive training, leveraging the Distribution Alignment Assumption (DA²).

Method: Domain2Vec decomposes datasets into meta-domains using a classifier, creating domain vectors that represent distributions over these meta-domains, and uses them to align training and validation data distributions.

Result: Domain2Vec reduces computational overhead by 51.5% while achieving the same validation loss and improves downstream task performance by an average of 2.83% under equivalent compute budgets.

Conclusion: Domain2Vec provides an efficient, scalable solution for optimizing data mixtures in language model pretraining, significantly reducing computational costs and enhancing performance.

摘要: 我们提出了Domain2Vec，这是一种新颖的方法，能够将任何数据集分解为多个元域的线性组合，元域是一种新概念，旨在捕捉数据集的关键底层特征。Domain2Vec维护一个元域词汇表，并使用分类器将给定数据集分解为对应于该词汇表分布的域向量。这些域向量能够在无需训练的情况下，根据分布对齐假设（DA²）识别语言模型预训练的最优数据混合。该假设表明，当训练集和验证集的数据分布更对齐时，验证损失会更低。此外，Domain2Vec可以无缝集成到先前的工作中，以建模域向量与语言模型性能之间的关系，大大提高了先前方法的效率和可扩展性。大量实验表明，Domain2Vec能够以最小的计算开销找到提升下游任务性能的数据混合。具体而言，Domain2Vec在Pile-CC上仅使用原始Pile数据集混合计算量的51.5%就达到了相同的验证损失。在相同的计算预算下，Domain2Vec平均将下游性能提高了2.83%。

</details>


### [59] [ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark](https://arxiv.org/abs/2506.10960)
**中文标题：ChineseHarm-Bench：一个中文有害内容检测基准**

*Kangwei Liu,Siyuan Cheng,Bozhong Tian,Xiaozhuan Liang,Yuyang Yin,Meng Han,Ningyu Zhang,Bryan Hooi,Xi Chen,Shumin Deng*

Main category: cs.CL

TL;DR: The paper introduces ChineseHarm-Bench, a professionally annotated benchmark for detecting harmful content in Chinese, addressing the scarcity of such resources. It includes six categories of real-world data and a knowledge rule base to assist LLMs. A knowledge-augmented baseline is proposed to enhance smaller models' performance.


<details>
  <summary>Details</summary>
Motivation: Existing harmful content detection resources are mainly focused on English, leaving Chinese datasets scarce and limited. The paper aims to fill this gap by providing a comprehensive benchmark for Chinese content harm detection.

Method: The authors construct a benchmark from real-world data, covering six harmful content categories, and develop a knowledge rule base. They propose a knowledge-augmented baseline combining human-annotated rules and LLM implicit knowledge.

Result: The benchmark and knowledge rule base improve harmful content detection in Chinese. The knowledge-augmented baseline enables smaller models to match state-of-the-art LLM performance.

Conclusion: ChineseHarm-Bench addresses the lack of Chinese harmful content detection resources and demonstrates the effectiveness of integrating expert knowledge with LLMs for improved detection.

摘要: 大型语言模型（LLMs）越来越多地应用于自动化有害内容检测任务，协助审核人员识别政策违规行为，提高内容审查的整体效率和准确性。然而，现有的有害内容检测资源主要集中在英语领域，中文数据集稀缺且范围有限。我们提出了一个全面、专业标注的中文内容有害检测基准，涵盖六个代表性类别，并完全基于真实数据构建。我们的标注过程还产生了一个知识规则库，为LLMs提供显式专家知识以辅助中文有害内容检测。此外，我们提出了一种知识增强的基线方法，结合了人工标注的知识规则和大型语言模型的隐式知识，使较小模型能够达到与最先进LLMs相当的性能。代码和数据可在https://github.com/zjunlp/ChineseHarm-bench获取。

</details>


### [60] [AutoMind: Adaptive Knowledgeable Agent for Automated Data Science](https://arxiv.org/abs/2506.10974)
**中文标题：AutoMind：用于自动化数据科学的自适应知识型智能体**

*Yixin Ou,Yujie Luo,Jingsheng Zheng,Lanning Wei,Shuofei Qiao,Jintian Zhang,Da Zheng,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: AutoMind is an adaptive LLM-agent framework for automated data science, integrating expert knowledge, strategic search, and dynamic coding to outperform existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-driven data science agents rely on rigid workflows and lack adaptability, limiting their effectiveness in complex tasks. AutoMind aims to address these limitations.

Method: AutoMind introduces (1) a curated expert knowledge base, (2) an agentic knowledgeable tree search algorithm, and (3) a self-adaptive coding strategy to dynamically tailor solutions.

Result: AutoMind outperforms state-of-the-art baselines in automated data science benchmarks, demonstrating superior effectiveness, efficiency, and solution quality.

Conclusion: AutoMind represents a robust step toward fully automated data science by overcoming the limitations of existing frameworks.

摘要: 大型语言模型（LLM）智能体在解决现实世界数据科学问题方面展现出巨大潜力。LLM驱动的数据科学智能体有望实现整个机器学习流程的自动化，但其实际效果仍有限。现有框架依赖于僵化的预定义工作流程和缺乏灵活性的编码策略，因此仅能在相对简单的经典问题上表现出色，而无法捕捉人类从业者在复杂创新任务中积累的经验。本文介绍了AutoMind，一种自适应、知识型的LLM智能体框架，通过三项关键创新克服了这些不足：（1）一个精心策划的专家知识库，使智能体具备领域专家知识；（2）一种基于知识的树搜索算法，策略性地探索可能的解决方案；（3）一种自适应编码策略，根据任务复杂度动态调整代码生成。在两个自动化数据科学基准测试上的评估表明，AutoMind的性能优于现有最先进的基线方法。进一步分析证实了其在有效性、效率和解决方案质量方面的优势，突显AutoMind是实现完全自动化数据科学的高效且稳健的一步。

</details>


### [61] [How Well Can Reasoning Models Identify and Recover from Unhelpful Thoughts?](https://arxiv.org/abs/2506.10979)
**中文标题：推理模型在识别和恢复无益思维方面的表现如何？**

*Sohee Yang,Sang-Woo Lee,Nora Kassner,Daniela Gottesman,Sebastian Riedel,Mor Geva*

Main category: cs.CL

TL;DR: The paper investigates reasoning models' ability to identify and recover from unhelpful thoughts, finding they struggle with recovery despite identifying most issues, especially larger models.


<details>
  <summary>Details</summary>
Motivation: To assess reasoning models' self-reevaluation capabilities in identifying and correcting unhelpful thoughts, which is crucial for accurate reasoning and safer AI systems.

Method: The study examines models' performance in handling four types of unhelpful thoughts: rambling, irrelevant, misdirecting, and incorrect thoughts, including injecting these thoughts into reasoning processes.

Result: Models can identify most unhelpful thoughts but fail to recover from them, with larger models performing worse. Smaller models are less distracted by harmful thoughts.

Conclusion: The findings highlight the need for improved self-reevaluation in reasoning models to enhance accuracy and safety.

摘要: 近期的推理模型展现出反思、回溯和自我验证推理的能力，这对于发现错误并得出准确解决方案至关重要。一个自然的问题是模型能否有效地进行这种自我重新评估。我们通过研究推理模型在识别和恢复四种无益思维（无信息的长篇大论、与问题无关的思维、将问题误导为稍不同问题的思维以及导致错误答案的思维）方面的表现来探讨这一问题。我们发现模型能有效识别大多数无益思维，但在这些思维被注入其思考过程时却难以恢复，导致性能显著下降。模型倾向于天真地延续无关思维的推理线，这表明其自我重新评估能力远未达到“元认知”意识。此外，我们观察到非/逆向缩放趋势，即更大的模型在恢复短无关思维时表现更差，即使被指示重新评估推理。我们通过一个使用无关思维注入的越狱实验展示了这些发现的含义，表明最小的模型最不容易被有害响应触发的思维分散注意力。总体而言，我们的发现呼吁改进推理模型的自我重新评估能力，以开发更好的推理和更安全的系统。

</details>


### [62] [A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations](https://arxiv.org/abs/2506.10019)
**中文标题：文本、视觉和语音生成自动评估方法综述**

*Tian Lan,Yang-Hao Zhou,Zi-Ao Ma,Fanshu Sun,Rui-Qing Sun,Junyu Luo,Rong-Cheng Tu,Heyan Huang,Chen Xu,Zhijing Wu,Xian-Ling Mao*

Main category: cs.CL

TL;DR: 本文综述了文本、视觉和语音生成领域的自动评估方法，提出了一个统一的分类框架，并探讨了未来跨模态评估的研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在生成式AI领域取得了显著进展，但如何自动评估生成内容的质量仍是一个挑战。目前缺乏一个系统性的框架来统一组织文本、视觉和音频模态的评估方法。

Method: 作者首先分析了文本生成领域的成熟评估方法，然后将这一框架扩展到图像和音频生成领域，提出了五种基本范式来分类现有的评估方法。

Result: 研究提出了一个适用于文本、视觉和语音生成领域的统一评估分类框架，并展示了其广泛的适用性。

Conclusion: 本文为跨模态评估方法的研究提供了系统性的综述和分类框架，并指出了未来研究的方向。

摘要: 近年来，深度学习显著提升了生成式AI在文本、图像和音频领域的能力。然而，如何自动评估这些生成内容的质量仍是一个持续的挑战。尽管存在多种自动评估方法，但目前的研究缺乏一个系统性框架来全面组织这些方法以覆盖文本、视觉和音频模态。为解决这一问题，本文对这三种模态的生成内容自动评估方法进行了全面综述，并提出了一种统一的分类方法；我们识别了五种基本范式，用于描述这些领域现有的评估方法。我们的分析首先考察了文本生成领域的评估方法，这些技术最为成熟。随后，我们将这一框架扩展到图像和音频生成领域，展示了其广泛的适用性。最后，我们探讨了跨模态评估方法未来研究的有前景方向。

</details>


### [63] [TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org/abs/2506.10055)
**中文标题：TaskCraft：代理任务的自动化生成**

*Dingfeng Shi,Jingyi Cao,Qianben Chen,Weichen Sun,Weizhen Li,Hongxuan Lu,Fangchen Dong,Tianrui Qin,King Zhu,Minghao Yang,Jian Yang,Ge Zhang,Jiaheng Liu,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: TaskCraft 是一种自动化工作流，用于生成具有执行轨迹的多工具、可验证且难度可扩展的代理任务，解决了现有指令数据缺乏工具交互和人工标注成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的指令数据缺乏工具交互，而当前的代理任务基准依赖昂贵的人工标注，限制了其可扩展性。因此，需要一种自动化方法来生成复杂且可验证的代理任务。

Method: TaskCraft 通过深度和广度扩展原子任务，生成结构和层次复杂的挑战。该方法生成的任务具有多工具使用和可验证的执行轨迹。

Result: 实验结果表明，这些任务改进了生成工作流中的提示优化，并增强了代理基础模型的监督微调。TaskCraft 提供了一个包含约 36,000 个不同难度任务的大规模合成数据集。

Conclusion: TaskCraft 为代理调优和评估的未来研究提供了支持，展示了自动化生成代理任务的潜力。

摘要: 代理任务需要多步骤的问题解决能力，包括自主性、工具使用和自适应推理，这些任务在自然语言处理（NLP）和人工智能（AI）的发展中日益重要。然而，现有的指令数据缺乏工具交互，而当前的代理任务基准依赖昂贵的人工标注，限制了其可扩展性。我们提出了 TaskCraft，这是一种自动化工作流，用于生成难度可扩展、多工具且可验证的代理任务及其执行轨迹。TaskCraft 通过深度和广度扩展原子任务，创建结构和层次复杂的挑战。实验结果表明，这些任务改进了生成工作流中的提示优化，并增强了代理基础模型的监督微调。我们提供了一个包含约 36,000 个不同难度任务的大规模合成数据集，以支持未来关于代理调优和评估的研究。

</details>


### [64] [A quantum semantic framework for natural language processing](https://arxiv.org/abs/2506.10077)
**中文标题：一种用于自然语言处理的量子语义框架**

*Christopher J. Agostino,Quan Le Thien,Molly Apsel,Denizhan Pak,Elina Lesyk,Ashabari Majumdar*

Main category: cs.CL

TL;DR: 本文提出了一种量子语义框架，用于解决自然语言处理中的语义退化问题，并通过实验证明语言解释在模糊性下表现出非经典上下文性，支持贝叶斯重复采样方法优于经典频率分析。


<details>
  <summary>Details</summary>
Motivation: 自然语言的语义退化问题导致大型语言模型（LLM）和其他现代NLP系统在复杂语义表达时面临固有局限。本文旨在通过量子语义框架揭示语言解释的非经典特性，并提出更实用的语义表征方法。

Method: 通过Kolmogorov复杂性理论分析语义退化的计算不可行性，并设计语义贝尔不等式测试，利用LLM代理作为“计算认知系统”在多样化上下文中解释模糊词对。

Result: 实验结果表明，语言解释在模糊性下表现出非经典上下文性（CHSH期望值显著违反经典边界），与人类认知实验结果一致，支持贝叶斯重复采样方法的优越性。

Conclusion: 经典频率分析方法在自然语言处理中存在固有损失，而贝叶斯重复采样方法能更实用地表征上下文中的语言意义。

摘要: 语义退化是自然语言的基本属性，它不仅超越了简单的多义性，还涵盖了随着语义表达复杂性增加而出现的潜在解释组合爆炸。大型语言模型（LLM）和其他现代NLP系统因其在自然语言内部操作而面临固有局限，使其受到语义退化施加的相同解释约束。本文通过Kolmogorov复杂性理论论证，随着表达复杂性的增加，任何解释主体（人类或LLM驱动的AI）恢复单一预期意义的可能性趋近于零。这种计算不可行性表明，认为语言形式本身具有意义的经典观点存在缺陷。我们提出，意义是通过依赖于观察者的解释行为实现的。为验证这一点，我们使用多样化的LLM代理作为“计算认知系统”，在不同上下文设置下解释模糊词对，进行了语义贝尔不等式测试。在多项独立实验中，我们发现平均CHSH期望值介于1.2至2.8之间，其中多次运行结果（如2.3-2.4）显著违反经典边界（|S|≤2）。这表明在模糊性下的语言解释可以表现出非经典上下文性，与人类认知实验结果一致。这些结果暗示，基于经典频率分析的自然语言方法必然存在损失。相反，我们提出贝叶斯式重复采样方法能更实用且适当地表征上下文中的语言意义。

</details>


### [65] [Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information](https://arxiv.org/abs/2506.10086)
**中文标题：Chat-of-Thought：用于生成领域特定信息的协作多智能体系统**

*Christodoulos Constantinides,Shuxin Lin,Nianjun Zhou,Dhaval Patel*

Main category: cs.CL

TL;DR: 本文提出了一种名为Chat-of-Thought的多智能体系统，用于生成工业资产的故障模式与影响分析（FMEA）文档。该系统通过多角色协作的LLM智能体和动态任务路由优化内容生成与验证。


<details>
  <summary>Details</summary>
Motivation: 工业设备监测领域需要高效的FMEA文档生成工具，传统方法效率低下且难以动态优化。本文旨在通过多智能体协作系统解决这一问题。

Method: 系统采用多角色LLM智能体，通过动态任务路由和Chat of Thought（多角色驱动讨论）实现内容的迭代优化和验证。

Result: Chat-of-Thought系统在工业设备监测中表现出色，能够高效生成和验证FMEA文档，解决了传统方法的局限性。

Conclusion: Chat-of-Thought展示了多智能体协作在工业领域的潜力，为FMEA文档生成提供了一种高效、动态的解决方案。

摘要: 本文提出了一种名为Chat-of-Thought的新型多智能体系统，旨在为工业资产生成故障模式与影响分析（FMEA）文档。该系统利用多个具有特定角色的协作型大型语言模型（LLM）智能体，结合先进的AI技术和动态任务路由，优化FMEA表格的生成与验证。其核心创新在于引入了Chat of Thought机制，通过动态、多角色驱动的讨论实现内容的迭代优化。本研究探讨了工业设备监测的应用领域，突出了关键挑战，并通过交互式、模板驱动的工作流程和上下文感知的智能体协作，展示了Chat-of-Thought在解决这些挑战方面的潜力。

</details>


### [66] [When Meaning Stays the Same, but Models Drift: Evaluating Quality of Service under Token-Level Behavioral Instability in LLMs](https://arxiv.org/abs/2506.10095)
**中文标题：当语义不变而模型漂移时：评估大型语言模型在分词级别行为不稳定性下的服务质量**

*Xiao Li,Joel Kreuzwieser,Alan Peters*

Main category: cs.CL

TL;DR: 研究探讨大型语言模型对语义相同但表述不同的提示（即提示方差）的响应差异，提出PBSS框架衡量模型行为漂移，发现模型响应受分词和解码策略影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在语义相同但表述不同的提示下可能产生不一致的响应，这种不稳定性可能影响模型的服务质量，因此需要量化评估。

Method: 提出Prompt-Based Semantic Shift (PBSS)框架，通过十项约束任务测量模型在语义等效提示重述下的行为漂移。

Result: PBSS揭示了模型在语义等效提示下存在一致且模型特定的响应偏移，表明分词和解码策略可能影响模型行为。

Conclusion: 研究强调了提示重述对模型评估稳定性的重要性，分词和解码动态可能是导致训练后服务质量不稳定的因素。

摘要: 我们研究了大型语言模型对语义意图相同但分词表述不同的提示的响应，这种现象称为提示方差。我们提出了Prompt-Based Semantic Shift (PBSS)，一个用于测量大型语言模型在语义等效提示重述下行为漂移的诊断框架。应用于十项约束任务后，PBSS揭示了模型在响应中存在一致且模型特定的偏移，表明这种偏移与分词和解码策略相关。这些结果突出了提示重述下模型评估稳定性的一个被忽视的维度，并表明分词策略和解码动态可能影响训练后服务质量的稳定性。

</details>


### [67] [ChartReasoner: Code-Driven Modality Bridging for Long-Chain Reasoning in Chart Question Answering](https://arxiv.org/abs/2506.10116)
**中文标题：ChartReasoner：代码驱动的模态桥接用于图表问答中的长链推理**

*Caijun Jia,Nan Xu,Jingxuan Wei,Qingli Wang,Lei Wang,Bihui Yu,Junnan Zhu*

Main category: cs.CL

TL;DR: ChartReasoner是一种代码驱动的两阶段框架，通过将图表图像转换为结构化ECharts代码并合成高质量推理数据，实现了精确且可解释的图表推理，性能接近GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理方法通过图像到文本转换进行视觉推理任务，但会丢失图表中的关键结构和语义信息。ChartReasoner旨在解决这一问题，实现更精确的图表推理。

Method: 1. 训练高保真模型将图表图像转换为结构化ECharts代码；2. 设计图表推理数据合成流水线，生成高质量推理轨迹；3. 结合监督微调和强化学习训练最终多模态模型。

Result: 在四个公开基准测试中，ChartReasoner表现优异，能尽可能保留图表原始细节，性能接近GPT-4o等专有系统，且参数量更少。

Conclusion: ChartReasoner通过代码驱动的方法有效解决了图表推理中的信息丢失问题，实现了高性能和可扩展性。

摘要: 近年来，大型语言模型通过长链推理展现了显著的推理能力。然而，如何将这种能力扩展到视觉推理任务仍是一个开放性问题。现有的多模态推理方法通过多次图像到文本转换将视觉推理任务转化为文本推理任务，但往往会丢失可视化中嵌入的关键结构和语义信息，尤其是在需要大量视觉细节的图表问答任务中。为填补这一空白，我们提出了ChartReasoner，一种代码驱动的两阶段框架，旨在实现对图表的精确、可解释推理。我们首先训练一个高保真模型，将多样化的图表图像转换为结构化ECharts代码，尽可能无损地保留布局和数据语义。然后，我们设计了一个通用的图表推理数据合成流水线，利用预训练的转换模型自动且可扩展地生成图表推理轨迹，并通过代码验证器过滤低质量样本。最后，我们在合成的图表推理数据集上结合监督微调和强化学习训练最终的多模态模型。在四个公开基准测试上的实验结果表明，我们提出的ChartReasoner能够尽可能保留图表的原始细节，在使用较少参数的情况下与最先进的开源模型表现相当，并在域外设置中接近GPT-4o等专有系统的性能。

</details>


### [68] [Unsupervised Elicitation of Language Models](https://arxiv.org/abs/2506.10139)
**中文标题：无监督引导语言模型**

*Jiaxin Wen,Zachary Ankner,Arushi Somani,Peter Hase,Samuel Marks,Jacob Goldman-Wetzler,Linda Petrini,Henry Sleight,Collin Burns,He He,Shi Feng,Ethan Perez,Jan Leike*

Main category: cs.CL

TL;DR: 本文提出了一种无监督算法ICM，通过最大化内部一致性，使预训练语言模型能够自我生成标签进行微调，无需外部监督。在多个任务中，其性能媲美甚至超越人类监督训练。


<details>
  <summary>Details</summary>
Motivation: 当前后训练范式依赖人类指定期望行为，但对于超人类能力的模型，高质量人类监督难以获取。本文旨在解决这一挑战。

Method: 提出无监督算法Internal Coherence Maximization (ICM)，通过最大化模型生成标签的内部一致性，实现无外部监督的微调。

Result: 在GSM8k-verification、TruthfulQA和Alpaca奖励建模任务中，ICM性能媲美黄金监督训练，优于众包人类监督训练。对于超人类能力的任务，ICM显著优于人类标签训练。此外，ICM训练的奖励模型和Claude 3.5 Haiku助手均优于人类监督版本。

Conclusion: ICM为无监督微调提供了一种有效方法，尤其在超人类能力任务中表现突出，展示了其在前沿语言模型训练中的潜力。

摘要: 为了引导预训练语言模型适应下游任务，当前的后训练范式依赖于人类指定期望行为。然而，对于具有超人类能力的模型，获取高质量的人类监督变得困难甚至不可能。为解决这一挑战，我们提出了一种新的无监督算法——内部一致性最大化（ICM），用于在无外部监督的情况下，基于模型自身生成的标签对预训练语言模型进行微调。在GSM8k验证、TruthfulQA和Alpaca奖励建模任务中，我们的方法性能媲美黄金监督训练，并优于众包人类监督训练。对于语言模型能力远超人类的任务，我们的方法能显著更好地激发这些能力。最后，我们展示了该方法在前沿语言模型训练中的应用：我们使用ICM训练了一个无监督奖励模型，并通过强化学习训练了一个基于Claude 3.5 Haiku的助手。无论是奖励模型还是助手，其性能均优于人类监督的版本。

</details>


### [69] [When Large Language Models are Reliable for Judging Empathic Communication](https://arxiv.org/abs/2506.10150)
**中文标题：大型语言模型在评判共情沟通时的可靠性**

*Aakriti Kumar,Nalin Poungpeth,Diyi Yang,Erina Farrell,Bruce Lambert,Matthew Groh*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）在评判共情沟通时表现接近专家水平，且优于众包工作者，表明其在情感敏感任务中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）在评判共情沟通时的可靠性，并与专家和众包工作者的标注结果进行比较。

Method: 通过比较专家、众包工作者和LLMs对200个真实对话中四种评估框架的共情标注（共3,150条专家标注、2,844条众包标注和3,150条LLM标注），评估三组标注者之间的一致性。

Result: 专家间一致性较高，但受评估框架子组分的清晰度、复杂性和主观性影响；LLMs的表现接近专家水平，且优于众包工作者。

Conclusion: LLMs在特定任务中经过适当验证后，可用于情感敏感应用（如对话伴侣），支持透明度和监督。

摘要: 大型语言模型（LLMs）在基于文本的对话中擅长生成共情回应。然而，它们在评判共情沟通的细微差别时有多可靠？我们通过比较专家、众包工作者和LLMs对200个真实对话中四种评估框架（来自心理学、自然语言处理和传播学）的共情标注（共3,150条专家标注、2,844条众包标注和3,150条LLM标注），研究了这一问题。我们发现，专家间一致性较高，但受评估框架子组分的清晰度、复杂性和主观性影响。专家一致性为LLM表现提供了比标准分类指标更具信息量的基准。在所有四种框架中，LLMs的表现接近专家水平，且优于众包工作者。这些结果表明，LLMs在特定任务中经过适当验证后，可用于情感敏感应用（如对话伴侣），支持透明度和监督。

</details>


### [70] [Analyzing Emotions in Bangla Social Media Comments Using Machine Learning and LIME](https://arxiv.org/abs/2506.10154)
**中文标题：使用机器学习和LIME分析孟加拉语社交媒体评论中的情感**

*Bidyarthi Paul,SM Musfiqur Rahman,Dipta Biswas,Md. Ziaul Hasan,Md. Zahid Hossain*

Main category: cs.CL

TL;DR: 本研究使用机器学习模型（如Linear SVM、KNN和随机森林）和LIME解释器，分析孟加拉语社交媒体评论中的情感，旨在为资源有限的语言提供高效的情感识别方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于扩展对孟加拉语等资源有限语言的情感分析，这些语言具有独特的地区表达和文化特征，但相关研究较少。

Method: 方法包括使用TF-IDF向量化的n-gram数据训练Linear SVM、KNN和随机森林模型，并探讨PCA降维效果。此外，还采用BiLSTM模型和AdaBoost优化决策树，并使用LIME解释AdaBoost分类器的预测。

Result: 结果表明，所提出的方法能够有效识别孟加拉语社交媒体评论中的情感，LIME的解释性增强了模型的可理解性。

Conclusion: 结论指出，该研究为资源有限语言的情感分析提供了高效技术，并展示了LIME在解释模型预测中的实用性。

摘要: 对书面语言中情感理解的研究持续扩展，尤其是针对孟加拉语等具有独特地区表达和文化特征的未充分研究语言。本研究使用EmoNoBa数据集中的22,698条社交媒体评论进行情感分析。语言分析采用机器学习模型：基于TF-IDF向量化n-gram数据的Linear SVM、KNN和随机森林。此外，还研究了PCA对降维的影响。进一步采用BiLSTM模型和AdaBoost优化决策树。为提高机器学习模型的可理解性，使用LIME解释基于决策树的AdaBoost分类器的预测。本研究旨在推动资源有限语言的情感分析，探索了多种技术以寻找孟加拉语情感识别的高效方法。

</details>


### [71] [Measuring Corporate Human Capital Disclosures: Lexicon, Data, Code, and Research Opportunities](https://arxiv.org/abs/2506.10155)
**中文标题：衡量企业人力资本披露：词汇表、数据、代码与研究机会**

*Elizabeth Demers,Victor Xiaoqi Wang,Kean Wu*

Main category: cs.CL

TL;DR: 本文开发了一种基于机器学习的词汇表，用于衡量企业人力资本披露情况，并提供了相关数据和代码，以支持未来研究。


<details>
  <summary>Details</summary>
Motivation: 人力资本（HC）对企业价值创造日益重要，但目前缺乏明确的测量和披露规则。本文旨在填补这一空白。

Method: 使用word2vec算法训练已确认的HC披露数据，开发了一个包含五个子类别的HC相关关键词词汇表。

Result: 提供了一个全面的HC词汇表、企业HC披露数据及Python代码，并展示了如何利用这些资源进行BERT模型微调等应用。

Conclusion: 本文的资源为研究HC管理问题提供了工具，并探讨了未来研究方向。

摘要: 人力资本（HC）对企业价值创造的重要性日益凸显。然而，与其他资产不同，HC目前缺乏明确的测量或披露规则。我们使用一种机器学习算法（word2vec），基于已确认的HC披露数据训练，开发了一个全面的HC相关关键词词汇表，并将其分为五个子类别（多样性、公平与包容；健康与安全；劳动关系与文化；薪酬与福利；人口统计与其他），以捕捉HC管理的多维性。我们分享了词汇表、企业HC披露数据及用于开发词汇表的Python代码，并提供了使用数据和代码的详细示例，包括微调BERT模型。研究人员可以利用我们的HC词汇表（或修改代码以捕获其他感兴趣的构念）与企业沟通样本，解决相关HC问题。最后，我们探讨了与HC管理和披露相关的未来研究机会。

</details>


### [72] [Can LLMs Generate Good Stories? Insights and Challenges from a Narrative Planning Perspective](https://arxiv.org/abs/2506.10161)
**中文标题：LLM能生成好故事吗？从叙事规划视角的洞察与挑战**

*Yi Wang,Max Kreminski*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLM）在故事生成中的能力，发现其在因果逻辑上表现良好，但在角色意图和戏剧冲突方面仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 由于自动评估方法的局限性和人工评估的高成本与主观性，LLM生成高质量故事的能力尚未被充分理解。研究希望通过叙事规划的视角，深入探讨LLM的故事生成能力。

Method: 研究基于文学示例构建了一个叙事规划评估基准，重点关注因果逻辑、角色意图和戏剧冲突。通过实验评估GPT-4级别LLM在这些方面的表现。

Result: 实验表明，GPT-4级别的LLM在小规模故事生成中能保证因果逻辑的合理性，但在角色意图和戏剧冲突方面表现不佳，需通过强化学习训练以提升复杂推理能力。

Conclusion: 研究揭示了LLM在故事生成中的潜力与局限，为游戏环境中应用LLM叙事规划提供了挑战与思考方向。

摘要: 故事生成是大型语言模型（LLM）的一个重要应用领域。然而，由于自动评估方法的局限性以及人工评估的高成本与主观性，对LLM生成高质量故事能力的理解仍然有限。计算叙事学为“好故事”提供了有价值的见解，并已应用于符号化叙事规划方法中。本研究旨在通过让LLM解决叙事规划问题，深化对其故事生成能力的理解。我们基于文学示例构建了一个叙事规划评估基准，重点关注因果逻辑、角色意图和戏剧冲突。实验表明，GPT-4级别的LLM能够在小规模生成中保证因果逻辑的合理性，但在角色意图和戏剧冲突方面仍面临挑战，需通过强化学习训练以提升复杂推理能力。研究结果为LLM在不同规模故事生成中的质量提供了多角度的洞察，同时也揭示了其在游戏环境中应用叙事规划的挑战与思考方向。

</details>


### [73] [Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval](https://arxiv.org/abs/2506.10202)
**中文标题：Q2E：用于零样本多语言文本到视频检索的查询到事件分解方法**

*Shubhashis Roy Dipta,Francis Ferraro*

Main category: cs.CL

TL;DR: Q2E是一种零样本多语言文本到视频检索方法，通过分解查询利用LLMs和VLMs的潜在知识，提升复杂事件的视频检索能力，并支持多模态输入。


<details>
  <summary>Details</summary>
Motivation: 现有方法在提取和利用大型语言模型（LLMs）和视觉语言模型（VLMs）的参数知识方面表现优异，但在复杂事件的视频检索中仍有提升空间。Q2E旨在通过分解查询，利用这些模型的潜在知识，改进视频检索效果。

Method: Q2E提出了一种查询到事件分解方法，通过LLMs和VLMs的知识分解人类查询，并结合熵融合评分实现零样本多模态融合。该方法支持视觉和语音输入。

Result: 在多个数据集和检索指标上的评估表明，Q2E优于多个先进基线方法，且整合音频信息能显著提升文本到视频检索效果。

Conclusion: Q2E通过分解查询和多模态融合，显著提升了复杂事件的视频检索能力，为未来研究提供了代码和数据支持。

摘要: 近期研究在提取和利用大型语言模型（LLMs）和视觉语言模型（VLMs）的参数知识方面表现出色。本文探讨如何通过自动提取这些模型中关于复杂现实事件的潜在知识，改进相关视频的识别与检索。我们提出了Q2E：一种适用于零样本多语言文本到视频检索的查询到事件分解方法，可适应不同数据集、领域、LLMs或VLMs。我们的方法表明，通过利用LLMs和VLMs中嵌入的知识分解查询，可以增强对过于简化的人类查询的理解。此外，我们还展示了如何将方法应用于视觉和语音输入。为结合这些多模态知识，我们采用基于熵的融合评分进行零样本融合。通过在两个多样化数据集和多个检索指标上的评估，我们证明Q2E优于多个先进基线方法。评估还表明，整合音频信息能显著提升文本到视频检索效果。我们已发布代码和数据以供未来研究。

</details>


### [74] [TTT-Bench: A Benchmark for Evaluating Reasoning Ability with Simple and Novel Tic-Tac-Toe-style Games](https://arxiv.org/abs/2506.10209)
**中文标题：TTT-Bench：通过简单新颖的井字棋类游戏评估推理能力的基准**

*Prakamya Mishra,Jiang Liu,Jialian Wu,Xiaodong Yu,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: TTT-Bench是一个新的基准测试，通过四种简单的井字棋类游戏评估大型推理模型的基本战略、空间和逻辑推理能力。研究发现，擅长数学问题的模型在这些简单游戏中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在STEM领域表现出色，但其在更广泛任务领域的推理能力尚未充分探索。TTT-Bench旨在填补这一空白，通过简单游戏测试模型的推理能力。

Method: 提出了一种可扩展的程序化方法，生成四种井字棋类游戏问题，要求模型推理对手意图和棋盘空间配置。

Result: 研究发现，擅长数学问题的模型在TTT-Bench上表现较差，平均得分比MATH 500和AIME 2024低41%和5%，且大模型在长程战略推理中表现不佳。

Conclusion: TTT-Bench揭示了大型推理模型在简单任务中的推理能力不足，尤其是在长程战略推理方面，为未来模型改进提供了方向。

摘要: 大型推理模型（LRMs）在包括奥林匹克数学问题在内的广泛任务中展示了强大的推理能力，表明其具备复杂推理能力。尽管许多推理基准集中在STEM领域，LRMs在更广泛任务领域的正确推理能力仍未被充分探索。本文提出了TTT-Bench，这是一个新的基准，旨在通过四种人类从小就能轻松解决的双人井字棋类游戏，评估LRMs的基本战略、空间和逻辑推理能力。我们提出了一种简单但可扩展的程序化方法，为TTT-Bench生成可验证的双人游戏问题。尽管这些游戏对人类来说微不足道，但它们需要推理对手的意图以及棋盘的空间配置以确保胜利。我们评估了多种最先进的LRMs，发现擅长数学难题的模型在这些简单推理游戏中经常失败。进一步测试显示，与MATH 500和AIME 2024相比，我们评估的推理模型在TTT-Bench上的平均得分分别低41%和5%，且大模型在短推理路径上表现更好，而大多数模型在简单和新颖的TTT-Bench任务中的长程战略推理情境中表现不佳。

</details>


### [75] [Classifying Unreliable Narrators with Large Language Models](https://arxiv.org/abs/2506.10231)
**中文标题：使用大型语言模型分类不可靠叙述者**

*Anneliese Brei,Katharine Henry,Abhisheik Sharma,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.CL

TL;DR: 本文提出使用大型语言模型（LLM）对不可靠叙述者进行分类，并构建了一个名为TUNa的人工标注数据集。实验表明，尽管任务具有挑战性，但LLM在识别不可靠叙述者方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过计算方法和文学理论，识别文本中无意间提供错误信息的不可靠叙述者，以提升对第一人称叙述的可靠性判断。

Method: 方法包括构建TUNa数据集，定义三类不可靠性分类任务（叙述内、叙述间和文本间），并评估多种LLM在少样本学习、微调和课程学习设置下的表现。

Result: 结果显示，识别不可靠叙述者的任务极具挑战性，但LLM在此任务中表现出一定的潜力。

Conclusion: 结论认为，尽管任务难度高，但LLM在不可靠叙述者分类方面具有应用前景，并呼吁未来进一步研究。

摘要: 当我们与第一人称叙述的事件互动时，常常会考虑叙述者（文本的主要讲述者）是否可靠。本文提出使用计算方法识别不可靠叙述者，即那些无意间提供错误信息的人。借鉴叙事学中的文学理论，我们基于多种文本现象定义了不同类型的不可靠叙述者，并提出了TUNa——一个包含博客文章、论坛帖子、酒店评论和文学作品等多领域叙述的人工标注数据集。我们定义了叙述内、叙述间和文本间不可靠性的分类任务，并分析了流行的开源和专有LLM在各项任务中的表现。我们提出从文学中学习，以对现实世界文本数据进行不可靠叙述者分类。为此，我们尝试了少样本学习、微调和课程学习设置。结果显示，这项任务极具挑战性，但LLM在识别不可靠叙述者方面具有潜力。我们发布了专家标注的数据集和代码，并邀请未来在这一领域的研究。

</details>


### [76] [ToxSyn-PT: A Large-Scale Synthetic Dataset for Hate Speech Detection in Portuguese](https://arxiv.org/abs/2506.10245)
**中文标题：ToxSyn-PT：用于葡萄牙语仇恨言论检测的大规模合成数据集**

*Iago Alves Brito,Julia Soares Dollis,Fernanda Bufon Färber,Diogo Fernandes Costa Silva,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: 本文介绍了ToxSyn-PT，一个用于葡萄牙语仇恨言论检测的大规模合成数据集，包含53,274个句子，覆盖九个受法律保护的少数群体。通过四阶段流程生成，实验结果表明其在多任务分类中表现优异，并能跨领域泛化。


<details>
  <summary>Details</summary>
Motivation: 现有的葡萄牙语仇恨言论数据集多来自社交媒体，且缺乏对少数群体的细粒度分类。ToxSyn-PT旨在填补这一空白，提供多样化的合成数据以支持低资源环境下的研究。

Method: 采用四阶段流程生成数据集：(1) 手动筛选种子数据；(2) 使用指令调优的大语言模型进行少样本扩展；(3) 基于释义的增强；(4) 添加中性文本以防止过拟合。

Result: 实验表明，ToxSyn-PT在二进制和多标签分类任务中表现优异，并在五个公开的葡萄牙语仇恨言论数据集上展示了跨领域的泛化能力。

Conclusion: ToxSyn-PT为葡萄牙语仇恨言论检测提供了高质量、多样化的合成数据，推动了低资源环境下的研究，并公开了数据集以促进进一步探索。

摘要: 我们介绍了ToxSyn-PT，这是首个支持对九个受法律保护的少数群体进行细粒度仇恨言论分类的大规模葡萄牙语语料库。该数据集包含53,274个合成句子，均匀分布在少数群体和毒性标签之间。ToxSyn-PT通过一种新颖的四阶段流程生成：(1) 手动筛选的紧凑种子数据；(2) 使用指令调优的大语言模型进行少样本扩展；(3) 基于释义的增强；(4) 添加中性文本以防止对群体特定线索的过拟合。生成的语料库类别平衡、风格多样，且避免了现有葡萄牙语数据集中社交媒体领域的主导问题。尽管与传统基准存在领域差异，实验表明该语料库在二进制和多标签分类任务中表现优异，并在五个公开的葡萄牙语仇恨言论数据集上展示了跨领域的泛化能力。数据集已公开发布，以推动合成数据和低资源环境下仇恨言论检测的研究。

</details>


### [77] [Do Language Models Have Bayesian Brains? Distinguishing Stochastic and Deterministic Decision Patterns within Large Language Models](https://arxiv.org/abs/2506.10268)
**中文标题：语言模型是否具有贝叶斯大脑？区分大型语言模型中的随机与确定性决策模式**

*Andrea Yaoyun Cui,Pengfei Yu*

Main category: cs.CL

TL;DR: 本文探讨语言模型是否具有贝叶斯大脑，发现其在某些条件下会表现出近乎确定性的决策模式，挑战了传统的采样假设，并提出了一种区分随机与确定性决策模式的方法。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型的决策模式是否类似于贝叶斯大脑，以及传统方法（如Gibbs采样）是否适用于推断语言模型的先验分布。

Method: 通过实验分析语言模型在不同条件下的决策模式，提出区分随机与确定性决策的方法，并验证其有效性。

Result: 语言模型在某些条件下会表现出确定性决策行为，传统Gibbs采样方法可能导致错误的先验推断。

Conclusion: 语言模型的决策模式并非完全随机，需谨慎使用传统方法推断其先验分布。

摘要: 语言模型本质上是基于标记序列的概率分布。自回归模型通过迭代计算和采样下一个标记的分布来生成句子。这种迭代采样引入了随机性，导致人们假设语言模型的决策是概率性的，类似于从未知分布中采样。基于这一假设，先前的研究使用模拟Gibbs采样（受启发于设计用于引发人类先验的实验）来推断语言模型的先验。本文重新探讨一个关键问题：语言模型是否具有贝叶斯大脑？我们的研究结果表明，在某些条件下，语言模型可以表现出近乎确定性的决策行为，例如生成最大似然估计，即使采样温度不为零。这挑战了采样假设，并削弱了先前用于引发人类类似先验的方法。此外，我们证明，如果未经仔细审查，一个具有确定性行为的系统在模拟Gibbs采样过程中可能会收敛到一个“虚假先验”。为解决这一问题，我们提出了一种简单的方法来区分Gibbs采样中的随机与确定性决策模式，从而避免推断出误导性的语言模型先验。我们在多种大型语言模型上进行了实验，以识别它们在不同情况下的决策模式。研究结果为理解大型语言模型的决策提供了重要见解。

</details>


### [78] [ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs](https://arxiv.org/abs/2506.10288)
**中文标题：ClusterUCB：基于梯度的高效数据选择方法，用于大型语言模型的定向微调**

*Zige Wang,Qi Zhu,Fei Mi,Minghui Xu,Ruochun Jin,Wenjing Yang*

Main category: cs.CL

TL;DR: 本文提出了一种高效的基于梯度的数据选择框架ClusterUCB，通过聚类和改进的UCB算法，显著降低了计算资源消耗，同时保持了与原始梯度方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于梯度的数据选择方法在大型语言模型的微调中计算资源消耗过大，难以实际应用。本文旨在提出一种高效的替代方案。

Method: 首先对训练数据池进行聚类，将数据选择问题转化为带约束的计算预算分配问题，并视为多臂老虎机问题。采用改进的UCB算法，结合历史数据影响信息和冷启动策略，平衡探索与利用。

Result: 实验结果表明，ClusterUCB在多个基准测试中能够达到与原始梯度方法相当的性能，同时大幅减少计算消耗。

Conclusion: ClusterUCB是一种高效且实用的数据选择框架，适用于大型语言模型的微调任务。

摘要: 基于梯度的数据影响近似方法已被用于大型语言模型监督微调中有用数据样本的选择。然而，在整个微调过程中计算梯度需要过多资源，实际中难以实现。本文提出了一种结合聚类和改进的上置信界（UCB）算法的高效梯度数据选择框架。基于梯度特征相似的数据样本具有相似影响的直觉，我们首先对训练数据池进行聚类。随后，将簇间数据选择问题建模为带约束的计算预算分配问题，并视为多臂老虎机问题。采用改进的UCB算法解决此问题。具体而言，在迭代采样过程中，记录历史数据影响信息以直接估计各簇的分布，并采用冷启动策略平衡探索与利用。在多个基准测试上的实验结果表明，我们提出的ClusterUCB框架能够达到与原始梯度数据选择方法相当的结果，同时大幅减少计算消耗。

</details>


### [79] [Flick: Few Labels Text Classification using K-Aware Intermediate Learning in Multi-Task Low-Resource Languages](https://arxiv.org/abs/2506.10292)
**中文标题：Flick：基于K感知中间学习的多任务低资源语言少标签文本分类**

*Ali Almutairi,Abdullah Alsuhaibani,Shoaib Jameel,Usman Naseem,Gelareh Mohammadi,Imran Razzak*

Main category: cs.CL

TL;DR: 本文提出了一种名为Flick的新方法，用于解决低资源语言中少标签文本分类问题。通过改进伪标签质量，Flick在14个多样化数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的自训练方法在少标签文本分类中易受噪声伪标签影响，且现有方法多针对资源丰富的语言或复杂模型。Flick旨在解决低资源语言中伪标签噪声和领域适应问题。

Method: Flick通过从初始广泛聚类中提取高置信度伪标签，并引入伪标签细化组件，利用单聚类凝聚力和自适应top-k选择机制，显著提升伪标签质量。

Result: 在包含阿拉伯语、乌尔都语和塞茨瓦纳语等低资源语言的14个数据集上，Flick表现出卓越的性能和适应性。

Conclusion: Flick通过改进伪标签质量，为低资源语言中的少标签文本分类提供了高效解决方案，展示了其在多样化语言环境中的优越性。

摘要: 在深度学习中，减少对大量标注数据的依赖已成为研究热点。尽管自训练方法在半监督学习中表现良好，但其仍易受噪声伪标签影响。此外，现有少标签分类方法多针对英语等资源丰富语言或采用易过拟合的复杂级联模型。为解决低资源语言中少标签文本分类的挑战（现有方法常受伪标签噪声和领域适应问题困扰），我们提出了Flick。与依赖通用多聚类伪标签或复杂级联架构的先前方法不同，Flick通过从初始广泛聚类中提取高置信度伪标签，显著提升了伪标签质量。Flick引入了一种新颖的伪标签细化组件，通过关注单聚类凝聚力和自适应top-k选择机制，从初始广泛聚类中提取高可靠性伪标签。这一针对性细化过程有效减少了低资源数据中的误差传播，仅需少量真实标签即可对预训练语言模型进行鲁棒微调。我们在包含阿拉伯语、乌尔都语和塞茨瓦纳语等低资源语言的14个多样化数据集上验证了Flick的优越性能和适应性。

</details>


### [80] ["Check My Work?": Measuring Sycophancy in a Simulated Educational Context](https://arxiv.org/abs/2506.10297)
**中文标题：“检查我的作业？”：模拟教育场景中附和行为的测量**

*Chuck Arvin*

Main category: cs.CL

TL;DR: 本研究探讨了在模拟教育环境中，用户提供的建议如何影响大型语言模型（LLMs），并揭示了模型对用户答案的附和行为（sycophancy）及其对教育公平的潜在风险。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于了解LLMs在教育场景中是否倾向于附和用户的答案，以及这种行为如何影响模型的正确性和教育公平性。

Method: 方法包括测试五种不同规模的LLMs（来自OpenAI GPT-4o和GPT-4.1系列），在五种实验条件下评估模型对用户提供答案的附和程度及其对回答质量的影响。

Result: 结果显示，当学生提到错误答案时，LLMs的正确率可能下降多达15个百分点；而提到正确答案时，正确率提升相同幅度。较小规模的模型表现出更强的附和倾向（如GPT-4.1-nano模型效应高达30%，而GPT-4o模型仅为8%）。

Conclusion: 结论指出，LLMs的附和行为可能加剧教育不平等，因此需要进一步研究其机制并探索缓解方法。

摘要: 本研究探讨了在模拟教育环境中，用户提供的建议如何影响大型语言模型（LLMs），其中附和行为（sycophancy）可能带来重大风险。通过测试五种来自OpenAI GPT-4o和GPT-4.1系列的LLMs，并在五种实验条件下进行实验，我们发现回答质量因问题表述方式差异显著。当学生提到错误答案时，LLMs的正确率可能下降多达15个百分点；而提到正确答案时，正确率提升相同幅度。此外，较小规模的模型表现出更强的附和倾向（如GPT-4.1-nano模型效应高达30%，而GPT-4o模型仅为8%）。通过对LLMs“翻转”答案的频率分析及对标记级概率的研究，我们确认模型倾向于根据学生提到的答案选择改变其回答，符合附和假说。这种附和行为对教育公平具有重要影响，因为LLMs可能加速知识丰富学生的学习，同时可能强化知识不足学生的误解。我们的结果凸显了在教育场景中更好地理解此类偏见的机制及缓解方法的必要性。

</details>


### [81] [Scheduled Interleaved Speech-Text Training for Speech-to-Speech Translation with LLMs](https://arxiv.org/abs/2506.10299)
**中文标题：基于大语言模型的语音到语音翻译中的计划性交替语音-文本训练**

*Hayato Futami,Emiru Tsunoo,Yosuke Kashiwagi,Yuki Ito,Hassan Shahmohammadi,Siddhant Arora,Shinji Watanabe*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLM）的语音到语音翻译（S2ST）方法，通过逐步减少文本比例的训练策略，解决了文本到语音模态适应的挑战。实验表明，该方法显著提升了翻译性能，尤其在训练数据较少的语言上表现突出。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）通常仅基于文本数据训练，难以直接适应语音模态。语音到语音翻译（S2ST）任务中，语音数据的稀缺性进一步加剧了这一挑战。本文旨在通过改进训练策略，实现从文本到语音的渐进式模态适应。

Method: 提出了一种计划性交替语音-文本训练方法，即在训练过程中交替使用语音和文本单元，并在训练过程中逐步减少文本比例。具体而言，在单词级别插入对齐的文本标记，并通过逐步降低文本比例，促进模型从文本模态向语音模态的过渡。

Result: 通过在CVSS数据集上对LLaMA3.2-1B模型进行微调，实验结果表明，该方法显著提升了语音到语音翻译的性能，尤其是在训练数据较少的语言上表现更为突出。

Conclusion: 本文提出的计划性交替语音-文本训练方法有效解决了文本到语音模态适应的挑战，为语音到语音翻译任务提供了一种高效的解决方案，尤其在低资源语言场景下表现优异。

摘要: 语音到语音翻译（S2ST）通过大语言模型（LLM）得到了进一步发展，这些模型基于离散语音单元进行微调。然而，从文本到语音的模态适应一直是一个问题。LLM通常仅基于文本数据训练，这使其在语音模态上的适应面临挑战，尤其是语音到语音数据有限的情况下。为了解决这一训练难题，本研究提出了计划性交替语音-文本训练方法。在训练过程中，我们使用交替的语音-文本单元而非单独的语音单元，并在单词级别插入对齐的文本标记。随着训练的进行，我们逐步降低文本比例，以促进从文本到语音的渐进式模态适应。我们通过在CVSS数据集上对LLaMA3.2-1B模型进行微调来验证该方法。实验结果表明，该方法显著提升了翻译性能，尤其是在训练数据较少的语言上表现突出。

</details>


### [82] [Code Execution as Grounded Supervision for LLM Reasoning](https://arxiv.org/abs/2506.10343)
**中文标题：代码执行作为大语言模型推理的基于监督**

*Dongwon Jung,Wenxuan Zhou,Muhao Chen*

Main category: cs.CL

TL;DR: 本文提出了一种利用代码执行生成高质量思维链监督数据的方法，以提升大语言模型的推理能力，避免了人工标注或LLM生成的不准确性。实验证明该方法有效且可迁移。


<details>
  <summary>Details</summary>
Motivation: 现有思维链监督数据生成方法依赖昂贵的人工标注或易出错的LLM生成，难以保证可靠性和准确性。因此，需要一种可扩展且高质量的数据生成方法。

Method: 通过利用程序执行的确定性，从代码执行中提取可验证的逐步推理轨迹，并将其转化为自然语言的思维链监督数据。

Result: 实验表明，该方法生成的监督数据质量高，能有效提升LLM的推理能力，并在多领域任务中表现出可迁移性。此外，还减少了推理时的冗余和重复。

Conclusion: 基于代码执行的思维链监督数据生成方法是一种高效、可靠且可扩展的解决方案，显著提升了LLM的推理能力。

摘要: 通过思维链（CoT）监督训练大语言模型（LLMs）已被证明能有效提升其推理能力。然而，获取可靠且准确的推理监督数据仍是一个重大挑战。我们提出了一种可扩展的方法，通过利用程序执行的确定性生成高质量的CoT监督数据集。与依赖昂贵人工标注或易出错的LLM生成CoT的现有方法不同，我们的方法从代码执行中提取可验证的逐步推理轨迹，并将其转化为自然语言的CoT推理。在多个领域的推理基准测试中，实验表明我们的方法能有效赋予LLMs跨任务的迁移推理能力。此外，消融研究验证了我们的方法生成的数据高度准确，并通过减少无意义的重复和过度思考降低了推理时的总标记长度。

</details>


### [83] [TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous Document Reasoning](https://arxiv.org/abs/2506.10380)
**中文标题：TableRAG：面向异构文档推理的检索增强生成框架**

*Xiaohan Yu,Pu Jian,Chong Chen*

Main category: cs.CL

TL;DR: TableRAG是一个针对异构文档（包含文本和表格）的检索增强生成框架，通过结合文本理解和表格操作，解决了现有RAG方法在表格结构破坏和信息丢失上的问题，并在多跳推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在处理包含文本和表格的异构文档时，因表格扁平化和分块策略导致结构破坏和信息丢失，影响了多跳推理能力。因此，需要一种新框架来统一文本理解和表格操作。

Method: TableRAG提出了一种混合框架，通过四步迭代操作：上下文敏感的查询分解、文本检索、SQL编程与执行、组合式中间答案生成。同时开发了HeteQA基准来评估异构文档的多跳推理能力。

Result: 实验结果表明，TableRAG在公开数据集和HeteQA基准上均优于现有基线，为异构文档问答任务设立了新的最优性能。

Conclusion: TableRAG通过结合文本和表格操作，显著提升了异构文档的多跳推理能力，为相关领域提供了有效的解决方案。

摘要: 检索增强生成（RAG）在开放领域问答中表现出显著效果，但在处理包含文本和表格的异构文档时，现有RAG方法存在关键缺陷。常见的表格扁平化和分块策略破坏了表格的固有结构，导致信息丢失，并削弱了大型语言模型在多跳全局查询中的推理能力。为解决这些问题，我们提出了TableRAG，一种结合文本理解和复杂表格操作的混合框架。TableRAG通过四步迭代操作：上下文敏感的查询分解、文本检索、SQL编程与执行、组合式中间答案生成。我们还开发了HeteQA基准，用于评估异构文档的多跳推理能力。实验结果表明，TableRAG在公开数据集和HeteQA上均优于现有基线，为异构文档问答任务设立了新的最优性能。TableRAG已在https://github.com/yxh-y/TableRAG/tree/main发布。

</details>


### [84] [PAG: Multi-Turn Reinforced LLM Self-Correction with Policy as Generative Verifier](https://arxiv.org/abs/2506.10406)
**中文标题：PAG：基于生成式验证策略的多轮强化学习大语言模型自我纠正方法**

*Yuhua Jiang,Yuwen Xiong,Yufeng Yuan,Chao Xin,Wenyuan Xu,Yu Yue,Qianchuan Zhao,Lin Yan*

Main category: cs.CL

TL;DR: 本文提出了一种名为PAG的框架，通过多轮强化学习让大语言模型（LLM）在生成和验证角色间切换，实现自我纠正。该方法仅在检测到错误时进行修正，显著提升了推理和验证能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在复杂推理任务中表现出色，但其自我验证能力仍不可靠。现有方法依赖外部验证模型或多阶段训练流程，限制了可扩展性。本文旨在提出一种更简单高效的自我纠正框架。

Method: PAG框架通过多轮强化学习，让LLM在生成答案和验证答案的角色间交替。其核心是选择性修正机制：仅在验证步骤检测到错误时才进行修正，避免不必要的重复生成。

Result: 实验表明，PAG在多种推理任务中表现出色：作为生成策略，提升了直接生成和自我纠正的准确性；作为验证器，其自我验证能力优于自一致性方法。

Conclusion: PAG通过统一的强化学习框架，显著提升了LLM的自我纠正能力，同时增强了推理和验证能力，为LLM的自我改进提供了新思路。

摘要: 大语言模型（LLM）在复杂推理任务中表现出色，但其自我验证能力仍不可靠。现有解决方案通常依赖独立的验证模型或多阶段自我纠正训练流程，限制了可扩展性。本文提出了一种名为“生成式验证策略”（PAG）的简单高效框架，通过多轮强化学习（RL）范式，使LLM在生成和验证角色间交替，实现自我纠正。与以往方法不同，PAG引入了选择性修正机制：模型仅在自身生成验证步骤检测到错误时修正答案。这种“验证-修正”流程不仅缓解了模型崩溃问题，还同时提升了推理和验证能力。在多种推理基准测试中的广泛实验表明，PAG具有双重优势：作为生成策略，它提升了直接生成和自我纠正的准确性；作为验证器，其自我验证能力优于自一致性方法。

</details>


### [85] [Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?](https://arxiv.org/abs/2506.10415)
**中文标题：阅后即焚：多模态大语言模型是否真正理解图像序列中的事件顺序？**

*Yingjin Song,Yupei Du,Denis Paperno,Albert Gatt*

Main category: cs.CL

TL;DR: 本文介绍了TempVS基准测试，用于评估多模态大语言模型（MLLMs）在图像序列中事件顺序理解能力。测试表明，现有模型表现不佳，与人类能力差距显著。


<details>
  <summary>Details</summary>
Motivation: 研究多模态大语言模型是否真正理解图像序列中事件的时间顺序，填补现有评估基准的空白。

Method: 提出了TempVS基准测试，包含事件关系推理、句子排序和图像排序三个主要测试，并辅以基础定位测试。评估了38种先进MLLMs。

Result: 现有MLLMs在TempVS测试中表现不佳，与人类能力存在显著差距，但提供了未来研究的改进方向。

Conclusion: TempVS揭示了MLLMs在时间推理能力上的不足，为未来研究提供了数据支持和方向。

摘要: 本文介绍了TempVS基准测试，专注于评估多模态大语言模型（MLLMs）在图像序列中的时间定位和推理能力。TempVS包含三个主要测试（即事件关系推理、句子排序和图像排序），每个测试均配有基础定位测试。TempVS要求MLLMs依赖视觉和语言模态来理解事件的时间顺序。我们评估了38种先进的MLLMs，结果表明这些模型在解决TempVS任务时表现不佳，与人类能力存在显著差距。我们还提供了细粒度的分析，为未来研究指明了方向。TempVS基准数据和代码可在https://github.com/yjsong22/TempVS获取。

</details>


### [86] [Beyond the Battlefield: Framing Analysis of Media Coverage in Conflict Reporting](https://arxiv.org/abs/2506.10421)
**中文标题：超越战场：冲突报道中媒体框架的分析**

*Avneet Kaur,Arnav Arora*

Main category: cs.CL

TL;DR: 研究发现新闻媒体在冲突报道中更倾向于战争框架而非和平框架，且不同地区媒体对冲突的叙事存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 当前关于冲突框架的研究多局限于定性分析或浅层框架，缺乏对战争与和平新闻框架的深入探讨。本研究旨在填补这一空白。

Method: 通过计算语言学方法（框架语义学与大型语言模型结合），分析了以色列-巴勒斯坦战争新闻报道中的战争与和平新闻框架。

Result: 分析显示新闻报道更偏向战争框架，且美国、英国和中东媒体在冲突叙事中存在显著差异，揭示了媒体偏见。

Conclusion: 研究强调了媒体框架对读者观点的影响，呼吁更平衡的冲突报道以减少偏见。

摘要: 新闻媒体在冲突时期使用的框架对读者观点有重大影响，可能加剧冲突本身。当前关于冲突框架的研究因定性分析或仅关注表层框架而缺乏深度。本研究基于冲突研究的先前工作，在以色列-巴勒斯坦战争新闻报道中识别了战争与和平新闻的指标。我们采用计算语言学方法，结合框架语义学和大型语言模型，分析了传播框架及其与语言框架的联系。分析显示新闻报道更偏向战争框架，且美国、英国和中东媒体在冲突叙事中存在显著差异，揭示了媒体偏见。

</details>


### [87] [Fast on the Easy, Deep on the Hard: Efficient Reasoning via Powered Length Penalty](https://arxiv.org/abs/2506.10446)
**中文标题：易则快，难则深：基于动态长度惩罚的高效推理方法**

*Zehui Ling,Deshu Chen,Hongwei Zhang,Yifeng Jiao,Xin Guo,Yuan Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种通过动态调整输出长度惩罚来提高大型语言模型推理效率的方法，简单问题更简洁，复杂问题更深入，从而在保持或提升准确性的同时减少计算延迟。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理任务中表现出色，但现有方法（如思维链提示）通常生成较长输出，增加了计算延迟。尽管一些方法尝试通过强化学习缩短推理，但未考虑问题复杂性，导致效果不佳。本研究旨在通过动态调整输出长度惩罚，提升LLMs的推理效率。

Method: 通过分割奖励函数并引入新的输出长度惩罚机制，动态调整模型的推理效率：简单问题更简洁，复杂问题保留足够推理深度。

Result: 在GSM8K、MATH500和AIME2024三个数据集上的实验表明，对于较简单的GSM8K和MATH500，方法有效缩短了输出长度并保持或提升了准确性；对于更复杂的AIME2024，准确性有所提高。

Conclusion: 动态调整输出长度惩罚的方法显著提升了大型语言模型的推理效率，同时兼顾了简单问题的简洁性和复杂问题的准确性。

摘要: 大型语言模型（LLMs）在推理能力上取得了显著进展，并在多项挑战性基准测试中表现优异。为进一步提升推理能力，研究者引入了诸如思维链提示等技术。然而，这些方法通常生成较长的输出，从而增加了计算延迟。尽管部分方法通过强化学习缩短推理，但它们往往采用统一的惩罚机制，未考虑问题的复杂性，导致效果不佳。本研究旨在通过动态调整输出长度惩罚，提升LLMs的推理效率：简单问题更简洁，复杂问题保留足够推理深度以提高准确性。具体而言，我们通过分割奖励函数并引入新的输出长度惩罚机制来优化模型的推理效率。在GSM8K、MATH500和AIME2024三个基准测试中，我们的方法取得了显著成果。对于相对简单的GSM8K和MATH500数据集，该方法有效缩短了输出长度并保持或提升了准确性；而对于更具挑战性的AIME2024数据集，准确性有所提高。

</details>


### [88] [Table-Text Alignment: Explaining Claim Verification Against Tables in Scientific Papers](https://arxiv.org/abs/2506.10486)
**中文标题：表格-文本对齐：解释科学论文中表格对主张的验证**

*Xanh Ho,Sunisth Kumar,Yun-Ang Wu,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

TL;DR: 论文提出将表格-文本对齐任务重新定义为解释任务，要求模型识别支持或反驳科学主张的关键表格单元格，并构建了带有人工标注的数据集。实验表明，结合对齐信息可提升主张验证性能，但多数大语言模型无法恢复人类对齐的推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有的科学主张验证任务仅预测标签，缺乏对模型推理的解释性和可解释性。为此，论文提出通过识别关键表格单元格来增强模型的可解释性。

Method: 扩展SciTab基准数据集，加入人工标注的单元格级解释，并构建处理模糊情况的分类法。实验结合对齐信息验证主张。

Result: 实验显示：(i) 结合表格对齐信息可提升主张验证性能；(ii) 多数大语言模型虽能预测正确标签，但无法恢复人类对齐的推理路径。

Conclusion: 表格-文本对齐任务有助于提升主张验证性能和模型可解释性，但当前大语言模型的预测缺乏忠实推理。

摘要: 科学主张的表格验证通常需要预测主张是否被支持或反驳。然而，仅预测最终标签是不够的：它无法揭示模型的推理过程，且可解释性有限。为此，我们将表格-文本对齐重新定义为解释任务，要求模型识别验证主张所需的关键表格单元格。我们通过扩展SciTab基准数据集，加入人工标注的单元格级解释，构建了新数据集。标注者验证主张标签并高亮支持其决策的最小单元格集。标注完成后，我们利用收集的信息提出了处理模糊情况的分类法。实验表明：(i) 结合表格对齐信息可提升主张验证性能；(ii) 多数大语言模型虽常预测正确标签，但无法恢复人类对齐的解释，表明其预测缺乏忠实推理。

</details>


### [89] [Surface Fairness, Deep Bias: A Comparative Study of Bias in Language Models](https://arxiv.org/abs/2506.10491)
**中文标题：表面公平，深层偏见：语言模型中偏见的比较研究**

*Aleksandra Sorokovikova,Pavel Chizhov,Iuliia Eremenko,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在表面公平性下隐藏深层偏见，尤其是在用户角色明确或模型个性化时，偏见表现更为显著。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型基于大量数据训练，这些数据不可避免地包含争议性和刻板印象内容，导致模型输出带有偏见。本文旨在探究LLMs中的偏见表现形式及其在不同任务中的影响。

Method: 通过多学科基准测试（MMLU）评估模型在预定义角色下的表现，并重新设计任务（如评分用户答案和提供薪资谈判建议）以检测偏见。

Result: 预定义角色下模型表现差异微小且随机，但在评分用户答案和薪资谈判建议任务中，模型表现出明显的偏见。

Conclusion: 随着LLM助手记忆和个性化功能的发展，模型对用户社会人口特征的了解可能加剧偏见问题，需进一步研究解决。

摘要: 现代语言模型基于大量数据训练，这些数据不可避免地包含与性别、来源、年龄等相关的争议性和刻板印象内容，导致模型表达偏见观点或基于用户角色产生不同结果。本文研究了大型语言模型（LLMs）中偏见的多种代理指标。我们发现，在多学科基准测试（MMLU）中，使用预定义角色评估模型时，得分差异微小且多为随机。然而，若重新设计任务，要求模型对用户答案评分，则显示出更显著的偏见迹象。最后，在要求模型提供薪资谈判建议时，答案中表现出明显的偏见。随着LLM助手记忆和个性化功能的兴起，这些问题从新角度浮现：现代LLM用户无需预定义角色描述，因为模型已了解其社会人口特征。

</details>


### [90] [Beyond Single-User Dialogue: Assessing Multi-User Dialogue State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2506.10504)
**中文标题：超越单用户对话：评估大语言模型在多用户对话状态跟踪中的能力**

*Sangmin Song,Juhwan Choi,JungMin Yun,YoungBin Kim*

Main category: cs.CL

TL;DR: 本文评估了大语言模型（LLMs）在多用户对话状态跟踪（DST）中的表现，发现其在多用户场景下性能显著下降，凸显了现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统DST基准主要关注结构化用户-代理对话，未能捕捉真实世界多用户交互的复杂性。本文旨在评估LLMs在多用户DST中的鲁棒性，同时降低数据集构建成本。

Method: 通过基于言语行为理论生成第二用户的对话内容，扩展现有DST数据集，系统地将第二用户的对话内容融入对话中，以评估LLMs在多用户场景下的表现。

Result: 实验结果显示，与单用户DST相比，LLMs在多用户DST中的性能显著下降，表明其在多说话者环境下提取和跟踪对话状态的能力有限。

Conclusion: 研究结果强调了未来研究需要增强LLMs在多用户DST场景中的能力，为开发更现实和鲁棒的DST模型铺平道路。

摘要: 大语言模型（LLMs）在零样本对话状态跟踪（DST）中表现出色，减少了对任务特定训练的需求。然而，传统的DST基准主要关注结构化的用户-代理对话，未能捕捉真实世界多用户交互的复杂性。本研究评估了LLMs在多用户DST中的鲁棒性，同时最小化数据集构建成本。受近期基于LLM的数据标注进展启发，我们通过基于言语行为理论生成第二用户的对话内容，扩展了现有DST数据集。我们的方法系统地将第二用户的对话内容融入对话中，实现了对LLMs在多用户场景下的受控评估。实验结果显示，与单用户DST相比，性能显著下降，凸显了当前LLMs在多说话者环境下提取和跟踪对话状态的局限性。我们的发现强调了未来研究需要增强LLMs在多用户DST场景中的能力，为开发更现实和鲁棒的DST模型铺平道路。

</details>


### [91] [Reliable Reasoning Path: Distilling Effective Guidance for LLM Reasoning with Knowledge Graphs](https://arxiv.org/abs/2506.10508)
**中文标题：可靠推理路径：通过知识图谱为LLM推理提炼有效指导**

*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Bo Li,Qing Li,Xiao Huang*

Main category: cs.CL

TL;DR: 本文提出RRP框架，通过结合知识图谱和LLM的语义优势，提取高质量推理路径，提升LLM在复杂问题中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在知识密集型任务中因缺乏背景知识和易产生幻觉而表现不佳，现有方法虽结合知识图谱（KG）但仍难以解决复杂问题。作者认为，提炼事实间关系并组织成逻辑一致的推理路径与事实知识本身同等重要。

Method: 提出RRP框架，结合LLM的语义能力和关系嵌入与双向分布学习的结构信息，挖掘知识图谱中的推理路径，并引入反思模块评估和优化路径重要性。

Result: 在两个公开数据集上的实验表明，RRP优于现有基线方法，并能以即插即用方式增强多种LLM的推理能力。

Conclusion: RRP通过生成针对特定问题的高质量推理路径，为LLM推理提供有效指导，显著提升了复杂问题的解决能力。

摘要: 大型语言模型（LLM）在知识密集型任务中常因缺乏背景知识和易产生幻觉而表现不佳。为解决这些问题，将知识图谱（KG）与LLM结合的研究日益增多。现有方法虽补充了事实知识，但仍难以解决复杂问题。我们认为，提炼事实间关系并将其组织为逻辑一致的推理路径与事实知识本身同等重要。然而，从KG中提取可靠推理路径面临以下挑战：图结构的复杂性及生成路径的多样性，导致难以区分有用与冗余路径。为应对这些挑战，我们提出RRP框架，结合LLM的语义优势与通过关系嵌入和双向分布学习获得的结构信息，挖掘知识图谱。此外，我们引入反思模块，根据路径重要性评估和优化推理路径。在两个公开数据集上的实验表明，RRP性能优于现有基线方法。此外，RRP能以即插即用方式轻松集成到多种LLM中，增强其推理能力。通过生成针对特定问题的高质量推理路径，RRP为LLM推理提炼了有效指导。

</details>


### [92] [Unsupervised Protoform Reconstruction through Parsimonious Rule-guided Heuristics and Evolutionary Search](https://arxiv.org/abs/2506.10614)
**中文标题：通过简约规则启发式与进化搜索的无监督原始词形重建**

*Promise Dodzi Kpoglu*

Main category: cs.CL

TL;DR: 本文提出了一种无监督方法，结合数据驱动推理和基于规则的启发式方法，通过进化优化框架重建原始词形（protoforms），在拉丁语原始词形重建任务中表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖音韵编辑的概率模型从同源词集中推断原始词形，但其数据驱动的特性限制了性能。本文旨在结合统计模式和语言学约束，提升重建的准确性和音韵合理性。

Method: 提出了一种混合方法，将数据驱动的推理与基于规则的启发式方法结合，并通过进化优化框架进行重建。该方法利用统计模式和语言学约束指导重建过程。

Result: 在基于五种罗曼语同源词集的拉丁语原始词形重建任务中，实验结果显示，该方法在字符级准确性和音韵合理性指标上显著优于现有基线。

Conclusion: 结合数据驱动和规则启发式的混合方法在原始词形重建任务中表现出色，为语言学研究提供了更有效的工具。

摘要: 我们提出了一种无监督方法，用于重建原始词形（即现代语言形式的祖先词形）。以往的研究主要依赖音韵编辑的概率模型从同源词集中推断原始词形，但这些方法因其数据驱动的特性而受到限制。相比之下，我们的模型在进化优化框架中结合了数据驱动的推理和基于规则的启发式方法。这种混合方法利用统计模式和语言学约束来指导重建过程。我们在基于五种罗曼语同源词集的拉丁语原始词形重建任务中评估了该方法。实验结果表明，该方法在字符级准确性和音韵合理性指标上均显著优于现有基线。

</details>


### [93] [Tina: Tiny Reasoning Models via LoRA](https://arxiv.org/abs/2504.15777)
**中文标题：Tina：通过LoRA实现的小型推理模型**

*Shangshang Wang,Julian Asilis,Ömer Faruk Akgül,Enes Burak Bilgin,Ollie Liu,Willie Neiswanger*

Main category: cs.CL

TL;DR: Tina是一种通过LoRA技术实现的高性价比小型推理模型，仅需极低资源即可达到与现有SOTA模型相媲美的推理性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何以低成本实现语言模型的强大推理能力。

Method: 采用参数高效的LoRA技术，在强化学习中对一个仅1.5B参数的基模型进行微调。

Result: Tina模型在推理性能上优于或媲美现有SOTA模型，且训练成本仅为260分之一（仅9美元）。

Conclusion: LoRA技术能高效适应推理任务的结构，同时保留基模型的知识，为低成本高性能推理模型提供了新思路。

摘要: 如何以高性价比实现语言模型的强大推理能力？基于这一核心问题，我们提出了Tina，一种通过高成本效益实现的小型推理模型家族。值得注意的是，Tina表明，仅需极少的资源即可开发出显著的推理性能，方法是在强化学习（RL）过程中，通过低秩适应（LoRA）对仅1.5B参数的基模型进行参数高效更新。这种极简方法产生的模型在推理性能上与基于同一基模型构建的SOTA RL推理模型相媲美，有时甚至超越。关键的是，这一成果仅需现有SOTA模型计算后训练成本的极小部分。实际上，最佳Tina模型在AIME24上实现了>20%的推理性能提升和43.33%的Pass@1准确率，而训练和评估成本仅为9美元（即估计成本降低了260倍）。我们的工作揭示了通过LoRA实现高效RL推理的惊人效果，并通过多个开源推理数据集和多种消融实验验证了这一结论。此外，我们假设这种高效性源于LoRA能够快速适应RL奖励的推理结构格式，同时基本保留基模型的底层知识。为促进开放研究，我们完全开源了所有代码、训练日志及模型权重与检查点。

</details>


### [94] [SDialog: A Python Toolkit for Synthetic Dialogue Generation and Analysis](https://arxiv.org/abs/2506.10622)
**中文标题：SDialog：用于合成对话生成与分析的Python工具包**

*Sergio Burdisso,Esaú Villatoro-Tello,Petr Motlicek*

Main category: cs.CL

TL;DR: SDialog是一个模块化、可扩展的Python工具包，用于生成和分析合成对话，支持多智能体模拟和场景驱动生成，提升对话AI系统的训练和评估效率。


<details>
  <summary>Details</summary>
Motivation: 对话AI系统的进步依赖于高质量、灵活且可复现的合成对话数据。当前缺乏标准化工具，SDialog旨在解决这一问题。

Method: SDialog利用指令调优的大型语言模型（LLMs），提供角色、编排和场景管理的抽象，支持多智能体模拟和场景驱动生成。

Result: SDialog能够生成真实、多样且可控的对话数据，为研究和开发提供标准化工具，提升可复现性。

Conclusion: SDialog是合成数据生成领域的重要进展，为快速发展的研究环境提供了标准化框架。

摘要: 对话AI系统的进步依赖于高质量、灵活且可复现的合成对话数据，用于训练、评估和基准测试。SDialog是一个模块化、可扩展的Python工具包，旨在解决合成对话生成和分析的挑战。通过利用指令调优的大型语言模型（LLMs），SDialog提供了角色、编排和场景管理的抽象，能够生成真实、多样且可控的对话数据，支持研究和开发。SDialog支持多智能体模拟和场景驱动生成等工作流，代表了合成数据生成工具和框架标准化的重要进展，为当今快速发展的研究环境提供了可复现性保障。

</details>


### [95] [Resa: Transparent Reasoning Models via SAEs](https://arxiv.org/abs/2506.09967)
**中文标题：Resa：通过稀疏自编码器实现透明的推理模型**

*Shangshang Wang,Julian Asilis,Ömer Faruk Akgül,Enes Burak Bilgin,Ollie Liu,Deqing Fu,Willie Neiswanger*

Main category: cs.CL

TL;DR: Resa是一种通过稀疏自编码器调优（SAE-Tuning）方法训练的高效推理模型家族，能以极低成本（约1美元）和短时间（约20分钟）实现接近RL训练模型的推理性能，并展现出通用性和模块化特性。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过利用语言模型的底层表示，以低成本高效地激发其强大的推理能力。

Method: 提出SAE-Tuning方法：先训练稀疏自编码器（SAE）从源模型中提取推理能力，再用SAE指导目标模型的监督微调过程，仅使用问答数据而无需推理轨迹。

Result: SAE-Tuning在RL后训练前应用时，能以2000倍的成本降低和450倍的时间缩短保留97%以上的推理性能；在轻量RL训练模型上应用时，能以约1美元的成本实现显著的推理性能提升（如AIME24上43.33% Pass@1）。

Conclusion: SAE-Tuning是一种高效、低成本且通用的方法，能够提取和转移语言模型的推理能力，同时展现出模块化潜力。

摘要: 如何通过利用语言模型的底层表示，以低成本高效地激发其强大的推理能力？我们通过Resa家族回答了这一问题，这是一种通过新颖高效的稀疏自编码器调优（SAE-Tuning）方法训练的1.5B推理模型。该方法首先训练一个稀疏自编码器（SAE）从源模型中捕获推理能力，然后使用训练好的SAE指导目标模型的监督微调过程，仅使用经过验证的问答数据而无需任何推理轨迹。值得注意的是，当在某些基础模型上应用SAE-Tuning后再进行RL后训练时，其推理性能可保留RL训练模型的97%以上，同时将训练成本降低2000倍至约1美元，训练时间缩短450倍至约20分钟。此外，在轻量RL训练模型（如2个GPU上1小时内）上应用时，仅需约1美元额外成本即可实现显著的推理性能提升（如AIME24上43.33% Pass@1，AMC23上90% Pass@1）。令人惊讶的是，通过SAE提取的推理能力可能既具有通用性又具有模块化特性。通用性意味着从一个数据集中提取的能力仍能提升更大且重叠语料库的性能；模块化意味着从Qwen或Qwen-Math提取的能力可以在测试时直接附加到R1-Distill模型上，无需重新训练，并获得类似的性能提升。广泛的消融实验验证了这些发现，所有相关资源均已开源。

</details>


### [96] [NeuralNexus at BEA 2025 Shared Task: Retrieval-Augmented Prompting for Mistake Identification in AI Tutors](https://arxiv.org/abs/2506.10627)
**中文标题：NeuralNexus在BEA 2025共享任务中的应用：基于检索增强提示的AI导师错误识别**

*Numaan Naeem,Sarfraz Ahmad,Momina Ahsan,Hasan Iqbal*

Main category: cs.CL

TL;DR: 本文介绍了在BEA 2025共享任务中用于错误识别的系统，结合了检索增强的提示方法和大型语言模型（GPT 4o），显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 任务旨在评估AI导师是否能正确识别学生数学推理中的错误，需要高效且可解释的方法。

Method: 探索了四种方法：1) 多预训练语言模型的集成模型；2) 冻结句子转换器与MLP分类器；3) 历史感知的多头注意力模型；4) 检索增强的少样本提示系统（GPT 4o）。最终系统结合检索相似示例和结构化提示。

Result: 最终系统表现优于所有基线，证明了结合示例驱动提示与LLM推理的有效性。

Conclusion: 检索增强的提示方法结合LLM推理在评估教学反馈中具有显著优势。

摘要: 本文介绍了我们在BEA 2025共享任务中用于错误识别的系统。该任务旨在评估AI导师是否能正确识别学生数学推理中的错误。我们探索了四种方法：1) 基于多预训练语言模型集成的方法；2) 使用[CLS]嵌入和MLP分类器的冻结句子转换器；3) 结合历史感知的多头注意力模型；4) 基于大型语言模型（如GPT 4o）的检索增强少样本提示系统。最终系统通过检索语义相似示例、构建结构化提示，并结合模式引导的输出解析生成可解释的预测，表现优于所有基线方法，证明了示例驱动提示与LLM推理结合在教学反馈评估中的有效性。代码已开源：https://github.com/NaumanNaeem/BEA_2025。

</details>


### [97] [Spelling-out is not Straightforward: LLMs' Capability of Tokenization from Token to Characters](https://arxiv.org/abs/2506.10641)
**中文标题：拼写并非直接：从词符到字符的LLMs分词能力**

*Tatsuya Hiraoka,Kentaro Inui*

Main category: cs.CL

TL;DR: 研究发现，尽管大型语言模型（LLMs）能逐字符拼写单词，但在处理更复杂的字符级任务时表现不佳。模型主要依赖中间和高层Transformer层重建字符级信息，而非嵌入层。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在拼写过程中如何内部表示和利用字符级信息，揭示其拼写行为背后的机制。

Method: 通过探测分类器、识别知识神经元和检查注意力权重三种互补分析方法，研究LLMs的拼写行为。

Result: 嵌入层未完全编码字符级信息（尤其是首字符之后），LLMs依赖中间和高层Transformer层重建字符级知识，拼写行为在这些层中出现明显突破。

Conclusion: 拼写对人类简单，但对LLMs并非直接处理的任务，其字符级能力依赖于模型深层结构的重建机制。

摘要: 大型语言模型（LLMs）能够以高准确率逐字符拼写词符，但在处理更复杂的字符级任务（如识别词符内的组合子成分）时表现不佳。本研究探讨了LLMs在拼写过程中如何内部表示和利用字符级信息。分析表明，尽管拼写对人类是简单任务，但LLMs并未以直接方式处理。具体而言，嵌入层未完全编码字符级信息（尤其是首字符之后），因此LLMs依赖中间和高层Transformer层重建字符级知识，并在这些层中观察到拼写行为的明显突破。我们通过三种互补分析验证了这一机制：探测分类器、知识神经元识别和注意力权重检查。

</details>


### [98] [Large Language Models for Detection of Life-Threatening Texts](https://arxiv.org/abs/2506.10687)
**中文标题：大语言模型在生命威胁文本检测中的应用**

*Thanh Thi Nguyen,Campbell Wilson,Janis Dalins*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLMs）检测生命威胁文本的有效方法，并比较了其与传统方法的性能。实验表明，Mistral和Llama-2在平衡和不平衡数据场景中表现最佳，而Gemma稍逊。上采样技术对传统方法有益，但对LLMs影响较小。


<details>
  <summary>Details</summary>
Motivation: 检测生命威胁语言对于保护处于困境中的个体、促进心理健康和福祉、以及预防潜在伤害和生命损失至关重要。

Method: 本文使用Gemma、Mistral和Llama-2三种开源大语言模型（7B参数版本），在平衡、不平衡和极端不平衡的数据集上进行微调，并与传统方法（如词袋模型、词嵌入、主题建模和BERT）进行比较。采用上采样技术处理不平衡数据。

Result: 实验结果表明，大语言模型在检测生命威胁文本方面表现优于传统方法，其中Mistral和Llama-2在平衡和不平衡数据场景中表现最佳，Gemma稍逊。上采样技术对传统方法有益，但对大语言模型影响较小。

Conclusion: 本研究展示了大语言模型在现实世界生命威胁语言检测问题中的巨大潜力。

摘要: 检测生命威胁语言对于保护处于困境中的个体、促进心理健康和福祉、以及预防潜在伤害和生命损失至关重要。本文提出了一种利用大语言模型（LLMs）检测生命威胁文本的有效方法，并将其与传统方法（如词袋模型、词嵌入、主题建模和BERT）进行比较。我们使用Gemma、Mistral和Llama-2三种开源大语言模型（7B参数版本），在平衡、不平衡和极端不平衡的数据集上进行微调。实验结果表明，大语言模型在检测生命威胁文本方面表现优于传统方法，其中Mistral和Llama-2在平衡和不平衡数据场景中表现最佳，Gemma稍逊。我们采用上采样技术处理不平衡数据，发现该技术对传统方法有益，但对大语言模型影响较小。本研究展示了大语言模型在现实世界生命威胁语言检测问题中的巨大潜力。

</details>


### [99] [Inferring Adjective Hypernyms with Language Models to Increase the Connectivity of Open English Wordnet](https://arxiv.org/abs/2506.10715)
**中文标题：利用语言模型推断形容词上位词以增强开放英语词网的连接性**

*Lorenzo Augello,John P. McCrae*

Main category: cs.CL

TL;DR: 本文探讨了如何通过语言模型预测形容词的上位词，以增强开放英语词网的连接性，并展示了TaxoLLaMa方法在此任务中的适应性。


<details>
  <summary>Details</summary>
Motivation: 开放英语词网是语言链接开放数据云中的重要资源，但目前存在大量缺失链接。本文旨在填补形容词上位词关系的空白，提升词网的完整性和实用性。

Method: 文章首先从理论上分析了形容词上位词关系的特性，并开发了新的形容词上位词资源。随后，通过微调大型语言模型（如TaxoLLaMa）来预测形容词的上位词关系。

Result: 研究表明，TaxoLLaMa方法可以成功应用于形容词上位词预测任务，为开放英语词网提供了更多缺失的链接。

Conclusion: 通过语言模型预测形容词上位词是可行的，能够显著提升开放英语词网的连接性和实用性。

摘要: 开放英语词网是作为语言链接开放数据云的一部分，以OntoLex-lemon形式发布的重要资源。然而，该资源中存在许多缺失的链接。本文探讨了如何建立形容词之间的上位词关系。我们首先从理论上讨论了上位词关系，并分析了形容词与名词和动词在此关系上的差异。随后，我们开发了一个新的形容词上位词资源，并通过微调大型语言模型来预测形容词的上位词关系，证明了TaxoLLaMa方法在此任务中的适用性。

</details>


### [100] [PREMISE: Scalable and Strategic Prompt Optimization for Efficient Mathematical Reasoning in Large Models](https://arxiv.org/abs/2506.10716)
**中文标题：PREMISE：面向高效数学推理的可扩展与策略性提示优化框架**

*Ye Yu,Yaoning Yu,Haohan Wang*

Main category: cs.CL

TL;DR: PREMISE是一种无需修改模型权重的提示优化框架，通过减少冗余计算和优化提示，显著降低推理开销，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在数学推理任务中表现优异，但冗长的推理过程导致高昂的token成本和延迟问题，限制了其在实时或API受限场景中的应用。

Method: PREMISE结合了轨迹级诊断和梯度启发式提示优化，通过多目标文本搜索平衡token长度和答案准确性，单次黑盒接口运行，适用于商业LLMs。

Result: 在GSM8K、SVAMP和Math500数据集上，PREMISE保持或超越基线准确率（Claude 96%→96%，Gemini 91%→92%），同时减少推理token达87.5%，降低成本69%-82%。

Conclusion: PREMISE证明提示级优化是一种实用且可扩展的方法，可在不牺牲推理质量的前提下显著提升LRM的效率。

摘要: 大型推理模型（如Claude 3.7 Sonnet和OpenAI o1）在数学基准测试中表现优异，但其冗长的链式推理（CoT）往往导致不必要的冗余，增加了token使用和成本，限制了其在延迟敏感或API受限场景中的部署。我们提出了PREMISE（基于提示的高效数学推理与策略评估），这是一种无需修改模型权重的纯提示框架，通过减少推理开销来优化性能。PREMISE结合轨迹级诊断和梯度启发式提示优化，在保持答案准确性的同时最小化冗余计算。该方法通过多目标文本搜索平衡token长度和答案有效性，联合优化简洁性和正确性。与先前工作不同，PREMISE以单次黑盒接口运行，可直接应用于商业LLMs。在GSM8K、SVAMP和Math500数据集上，PREMISE保持或超越基线准确率（Claude 96%→96%，Gemini 91%→92%），同时减少推理token达87.5%，降低成本69%-82%。这些结果表明，提示级优化是一种实用且可扩展的路径，可在不牺牲推理质量的前提下实现高效的LRM推理。

</details>


### [101] [Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims](https://arxiv.org/abs/2506.10728)
**中文标题：超越真与假：基于检索增强的复杂声明层次分析**

*Priyanka Kargupta,Runchu Tian,Jiawei Han*

Main category: cs.CL

TL;DR: 本文提出ClaimSpect框架，通过检索增强生成技术，将复杂声明分解为多层次的子方面，并结合语料库中的不同观点，提供更全面的分析。


<details>
  <summary>Details</summary>
Motivation: 现实中的声明（如科学或政治声明）往往具有复杂性，无法简单归类为“真”或“假”。因此，需要一种方法将这些声明分解为更易验证的子方面，并结合语料库中的不同观点，提供更全面的分析。

Method: 提出ClaimSpect框架，通过检索增强生成技术，自动构建声明子方面的层次结构，并从语料库中检索相关片段以发现新子方面和不同观点。

Result: ClaimSpect在真实世界的科学和政治声明数据集上表现出色，能够准确分解复杂声明并展示语料库中的观点分布。

Conclusion: ClaimSpect为分析复杂声明提供了一种有效方法，能够帮助用户从多角度理解问题，并优于现有基线方法。

摘要: 个人或实体提出的声明往往具有复杂性，无法简单地归类为完全“真”或“假”——这在科学和政治声明中尤为常见。然而，一个声明（例如“疫苗A优于疫苗B”）可以分解为其核心方面和子方面（例如有效性、安全性、分发），这些方面更容易单独验证。这为问题提供了更全面、结构化的回应，同时允许读者优先关注声明中的特定角度（例如对儿童的安全性）。为此，我们提出了ClaimSpect，一种基于检索增强生成的框架，用于自动构建声明分析时通常考虑的层次结构，并通过语料库特定视角丰富这些结构。该框架通过层次化分割输入语料库以检索相关片段，从而帮助发现新的子方面。此外，这些片段还能揭示对声明某一方面的不同观点（例如支持、中立或反对）及其普遍性（例如“有多少生物医学论文认为疫苗A比B更易运输？”）。我们将ClaimSpect应用于构建的数据集中的多种真实世界科学和政治声明，展示了其在分解复杂声明和表示语料库中观点方面的鲁棒性和准确性。通过真实案例研究和人工评估，我们验证了其相对于多种基线方法的有效性。

</details>


### [102] [TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora](https://arxiv.org/abs/2506.10737)
**中文标题：TaxoAdapt：将基于大语言模型的多维分类体系构建与动态研究语料库对齐**

*Priyanka Kargupta,Nan Zhang,Yunyi Zhang,Rui Zhang,Prasenjit Mitra,Jiawei Han*

Main category: cs.CL

TL;DR: TaxoAdapt 是一个动态适应多维度科学文献的 LLM 生成分类框架，通过迭代层次分类扩展分类体系的宽度和深度，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 科学领域的快速演变使得文献组织和检索变得困难。传统专家分类耗时昂贵，现有自动分类方法要么过度依赖特定语料库，要么忽视科学领域的动态性和多维度特性。TaxoAdapt 旨在填补这些空白。

Method: TaxoAdapt 通过迭代层次分类动态调整 LLM 生成的分类体系，根据语料库的主题分布扩展分类的宽度和深度，以捕捉科学领域的多维度特性。

Result: TaxoAdapt 在多个计算机科学会议数据集上表现优异，生成的分类体系比最先进的基线方法在粒度保持性和连贯性上分别提高了 26.51% 和 50.41%。

Conclusion: TaxoAdapt 能够动态适应科学文献的多维特性，显著提升分类体系的粒度和连贯性，为科学文献的组织和检索提供了更有效的工具。

摘要: 科学领域的快速演变给文献组织和检索带来了挑战。虽然专家分类传统上满足了这一需求，但这一过程耗时且昂贵。此外，现有的自动分类方法要么过度依赖特定语料库，牺牲了通用性；要么过度依赖大语言模型（LLMs）预训练数据集中的通用知识，往往忽视了科学领域的动态性。这些方法还未能考虑到科学文献的多维特性，即单篇研究论文可能涉及多个维度（如方法、新任务、评估指标、基准）。为解决这些问题，我们提出了 TaxoAdapt，这是一个将 LLM 生成的分类体系动态适应于给定语料库的多维框架。TaxoAdapt 通过迭代层次分类，根据语料库的主题分布扩展分类的宽度和深度。我们在多个计算机科学会议数据集上展示了其最先进的性能，证明了其捕捉科学领域演变的能力。作为一种多维方法，TaxoAdapt 生成的分类体系在粒度保持性和连贯性上分别比最具竞争力的基线方法提高了 26.51% 和 50.41%。

</details>


### [103] [One Tokenizer To Rule Them All: Emergent Language Plasticity via Multilingual Tokenizers](https://arxiv.org/abs/2506.10766)
**中文标题：一统天下的分词器：通过多语言分词器实现语言适应性的涌现**

*Diana Abagyan,Alejandro R. Salamanca,Andres Felipe Cruz-Salinas,Kris Cao,Hangyu Lin,Acyr Locatelli,Marzieh Fadaee,Ahmet Üstün,Sara Hooker*

Main category: cs.CL

TL;DR: 本文提出使用通用分词器（覆盖更多语言）来提升多语言大模型的语言适应能力，实验证明其显著优于仅针对预训练语言的分词器。


<details>
  <summary>Details</summary>
Motivation: 多语言大模型在预训练时面临模型容量有限、高质量数据稀缺和计算资源不足的挑战，且分词器对新语言的覆盖不足限制了后训练阶段的适应能力。本文旨在通过早期干预提升模型对新语言的适应能力。

Method: 提出使用通用分词器，覆盖比预训练语言更多的语言，以提升模型后训练阶段对新语言的适应能力。通过系统实验验证其效果。

Result: 通用分词器显著提升了语言适应能力，相较于仅针对预训练语言的分词器，胜率提升高达20.2%。此外，对完全未见过的语言，胜率也有5%的提升。

Conclusion: 通用分词器能够高效扩展语言覆盖范围，同时不影响预训练中大多数语言的性能，为多语言模型的语言适应提供了有效解决方案。

摘要: 由于模型容量有限、高质量数据稀缺以及计算资源限制，同时预训练覆盖多种语言的大规模语言模型（LLMs）具有挑战性。此外，分词器对新语言的覆盖不足使得后训练阶段难以填补这一空白。本研究探讨了在训练早期通过相对廉价的干预措施提升“语言适应性”的方法，即模型后训练对新语言的适应能力。我们聚焦于分词器设计，提出使用一种通用分词器，其覆盖的语言比主要预训练语言更多，从而在预训练后高效扩展语言覆盖范围。通过对不同语言组和训练策略的系统实验，我们发现通用分词器显著提升了语言适应能力，相较于仅针对预训练语言的分词器，胜率提升高达20.2%。此外，通用分词器对完全未见过的语言也表现出更好的适应性，胜率提升达5%。我们通过这种方法实现了对扩展语言集的高效适应，同时对预训练中大多数语言的性能影响极小。

</details>


### [104] [Different Questions, Different Models: Fine-Grained Evaluation of Uncertainty and Calibration in Clinical QA with LLMs](https://arxiv.org/abs/2506.10769)
**中文标题：不同问题，不同模型：基于LLMs的临床问答中不确定性和校准的细粒度评估**

*Alberto Testoni,Iacer Calixto*

Main category: cs.CL

TL;DR: 本文对大型语言模型（LLMs）在临床问答中的不确定性和校准性进行了细粒度评估，比较了十种开源模型和多种方法，发现不同专业和问题类型对模型性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 在临床决策支持等高风险领域，准确且校准良好的不确定性估计对部署大型语言模型至关重要。本文旨在评估不同模型和方法在临床多选题问答中的表现。

Method: 研究覆盖了十种开源LLMs（通用、生物医学和推理模型），在两个数据集、十一个医学专业和六种问题类型上进行了评估。比较了标准单生成和基于采样的方法，并探索了基于推理轨迹行为信号的轻量级方法。

Result: 结果显示，不同专业和问题类型对模型性能有显著影响。轻量级方法在仅需一次生成的情况下接近语义熵的性能。

Conclusion: 研究强调了根据问题性质和模型特定优势选择模型的重要性，为临床领域LLMs的应用提供了实用指导。

摘要: 准确且校准良好的不确定性估计对于在临床决策支持等高风险领域部署大型语言模型（LLMs）至关重要。我们对临床多选题问答中的不确定性估计方法进行了细粒度评估，涵盖了十种开源LLMs（通用、生物医学和推理模型），涉及两个数据集、十一个医学专业和六种问题类型。我们比较了标准单生成和基于采样的方法，并通过案例研究探索了基于推理轨迹行为信号的简单单次生成估计器。这些轻量级方法在仅需一次生成的情况下接近语义熵的性能。研究结果表明，不同专业和问题类型对模型性能有显著影响，强调了根据问题性质和模型特定优势选择模型的重要性。

</details>


### [105] [Improving Named Entity Transcription with Contextual LLM-based Revision](https://arxiv.org/abs/2506.10779)
**中文标题：利用基于上下文的大型语言模型修订机制改进命名实体转录**

*Viet Anh Trinh,Xinlu He,Jacob Whitehill*

Main category: cs.CL

TL;DR: 本文提出了一种基于大型语言模型（LLM）的修订机制，通过利用LLM的推理能力和本地上下文（如讲义）来修正ASR预测中错误的命名实体，显著降低了命名实体的词错误率（WER）。


<details>
  <summary>Details</summary>
Motivation: 尽管自动语音识别（ASR）系统在通用语音上表现优异，但命名实体的词错误率仍然较高。命名实体是关键信息，其错误识别会影响下游应用。因此，需要一种方法专门修正命名实体的识别错误。

Method: 提出了一种基于LLM的修订机制，利用LLM的推理能力和包含正确命名实体的本地上下文（如讲义），对ASR预测中的命名实体进行修正。同时，引入了NER-MIT-OpenCourseWare数据集用于开发和测试。

Result: 在NER-MIT-OpenCourseWare数据集上，该方法实现了命名实体词错误率相对降低30%的效果。

Conclusion: 基于LLM的修订机制能有效修正ASR预测中的命名实体错误，显著提升命名实体的识别准确率。

摘要: 随着建模技术的进步和监督训练数据的增加，自动语音识别（ASR）系统在通用语音上取得了显著性能。然而，对于命名实体，当前最先进的ASR系统的词错误率（WER）仍然较高。由于命名实体通常是最关键的关键词，错误识别会影响所有下游应用，尤其是当ASR系统作为复杂系统的前端时。本文提出了一种基于大型语言模型（LLM）的修订机制，通过利用LLM的推理能力以及包含正确命名实体的本地上下文（如讲义），修正ASR预测中的错误命名实体。最后，我们引入了NER-MIT-OpenCourseWare数据集，包含45小时的MIT课程数据用于开发和测试。在该数据集上，所提技术实现了命名实体词错误率相对降低30%的效果。

</details>


### [106] [Mitigating Negative Interference in Multilingual Sequential Knowledge Editing through Null-Space Constraints](https://arxiv.org/abs/2506.10800)
**中文标题：通过零空间约束缓解多语言顺序知识编辑中的负干扰**

*Wei Sun,Tingyu Qu,Mingxiao Li,Jesse Davis,Marie-Francine Moens*

Main category: cs.CL

TL;DR: 本文提出LangEdit框架，通过零空间约束解决多语言顺序知识编辑中的负干扰问题，显著提升多语言模型的更新效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 多语言大模型在更新知识时，跨语言的顺序编辑会导致参数干扰，破坏多语言泛化能力和知识准确性。现有方法成本高或效果不佳，因此需要一种高效且精确的解决方案。

Method: LangEdit框架通过将每种语言的参数更新投影到先前更新子空间的正交补空间上，确保更新独立性并保留多语言泛化能力。

Result: 在三种模型架构、六种语言和四项下游任务的评估中，LangEdit有效减少了参数干扰，性能优于现有最先进的编辑方法。

Conclusion: LangEdit为多语言大模型的高效、准确知识更新提供了可行方案，具有实际应用潜力。

摘要: 高效更新多语言大模型（LLMs）中的知识，同时保持跨语言的事实表示一致性，是一个长期未解决的挑战。虽然为每种语言部署独立的编辑系统看似可行，但这种方法因需要管理多个模型而成本高昂。更高效的解决方案是将所有语言的知识更新集成到一个统一模型中。然而，跨语言的顺序编辑通常会导致破坏性的参数干扰，显著降低多语言泛化能力和注入知识的准确性。为解决这一挑战，我们提出了LangEdit，一种新颖的零空间约束框架，旨在精确隔离特定语言的知识更新。LangEdit的核心创新在于其能够将每种语言的参数更新投影到先前更新子空间的正交补空间上。这种方法在数学上保证了更新的独立性，同时保留了多语言泛化能力。我们在三种模型架构、六种语言和四项下游任务上进行了全面评估，结果表明LangEdit有效缓解了参数干扰，并优于现有的最先进编辑方法。我们的结果突显了其在实现多语言大模型中高效、准确知识更新方面的潜力。代码可在https://github.com/VRCMF/LangEdit.git获取。

</details>


### [107] [ReCUT: Balancing Reasoning Length and Accuracy in LLMs via Stepwise Trails and Preference Optimization](https://arxiv.org/abs/2506.10822)
**中文标题：ReCUT：通过逐步试验和偏好优化平衡LLM的推理长度与准确性**

*Zhensheng Jin,Xinze Li,Yifan Ji,Chunyi Peng,Zhenghao Liu,Qi Shi,Yukun Yan,Shuo Wang,Furong Peng,Ge Yu*

Main category: cs.CL

TL;DR: ReCUT是一种新方法，通过逐步探索和长短切换采样策略，平衡大型语言模型（LLM）的推理长度和准确性，显著减少推理长度30-50%，同时保持或提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维（CoT）提示方法虽然提升了LLM的推理能力，但常因过度思考导致冗长或冗余的推理轨迹，现有方法因生成数据质量和过拟合问题效果受限。

Method: ReCUT采用逐步探索机制和长短切换采样策略，生成多样化推理路径，评估后构建偏好对训练两个专用模型（一个优化准确性，一个优化推理长度），最终通过参数插值整合模型。

Result: 在多个数学推理数据集和骨干模型上的实验表明，ReCUT显著减少推理长度30-50%，同时保持或提高推理准确性。

Conclusion: ReCUT有效平衡了推理长度和准确性，为LLM的推理优化提供了新思路，代码和数据已开源。

摘要: 链式思维（CoT）提示的最新进展大幅提升了大型语言模型（LLM）的推理能力。然而，这些方法常因过度思考导致冗长或冗余的推理轨迹。现有方法尝试通过整理多条推理链训练LLM来缓解此问题，但其效果常受生成数据质量和过拟合问题的限制。为应对这一挑战，我们提出“通过逐步试验压缩推理”（ReCUT），这是一种旨在平衡推理轨迹准确性与长度的新方法。具体而言，ReCUT采用逐步探索机制和长短切换采样策略，使LLM能逐步生成多样化推理路径。这些路径经评估后用于构建偏好对，训练两个专用模型（Gemini LLM）——一个优化推理准确性，另一个优化较短推理。最终通过插值这两个模型的参数获得集成模型。在多个数学推理数据集和骨干模型上的实验结果表明，ReCUT显著减少推理长度约30-50%，同时与多种基线相比保持或提高推理准确性。所有代码和数据将通过https://github.com/NEUIR/ReCUT发布。

</details>


### [108] [CIIR@LiveRAG 2025: Optimizing Multi-Agent Retrieval Augmented Generation through Self-Training](https://arxiv.org/abs/2506.10844)
**中文标题：CIIR@LiveRAG 2025：通过自训练优化多代理检索增强生成**

*Alireza Salemi,Mukta Maddipatla,Hamed Zamani*

Main category: cs.CL

TL;DR: 本文提出了一种多代理检索增强生成（RAG）框架mRAG，通过自训练和奖励引导的轨迹采样优化代理间协作，在SIGIR 2025 LiveRAG竞赛中表现优于传统RAG基线。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在复杂任务中表现有限，本文旨在通过多代理协作和自训练优化提升RAG系统的性能。

Method: mRAG框架包含多个专门代理（如规划、搜索、推理和协调），采用自训练范式结合奖励引导的轨迹采样优化协作。

Result: 在DataMorgana数据集上的实验表明，mRAG优于传统RAG基线，并通过案例分析展示了其在实际任务中的有效性。

Conclusion: mRAG通过多代理协作和自训练显著提升了RAG系统的性能，适用于复杂任务。

摘要: 本文提出了mRAG，一个由多个专门代理（如规划、搜索、推理和协调）组成的多代理检索增强生成（RAG）框架。我们的系统采用自训练范式，结合奖励引导的轨迹采样，以优化代理间协作并增强响应生成。在SIGIR 2025 LiveRAG竞赛中，基于DataMorgana数据集进行评估，mRAG表现优于传统RAG基线。我们进一步分析了竞赛结果，并通过案例研究展示了该框架在复杂实际RAG任务中的有效性。

</details>


### [109] [Accelerating Diffusion Large Language Models with SlowFast: The Three Golden Principles](https://arxiv.org/abs/2506.10848)
**中文标题：基于SlowFast的扩散大语言模型加速：三大黄金原则**

*Qingyan Wei,Yaojie Zhang,Zhiyuan Liu,Dongrui Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SlowFast Sampling的动态采样策略，通过三个黄金原则（确定性、收敛性和位置性）优化扩散语言模型（dLLMs）的解码效率，并结合dLLM-Cache减少冗余计算，显著提升了生成速度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型采样策略（如基于置信度或半自回归解码）存在静态行为问题，导致效率低下和灵活性不足。本文旨在通过动态采样策略提升dLLMs的解码效率和生成质量。

Method: 提出SlowFast Sampling策略，动态切换探索性和加速解码阶段，遵循确定性、收敛性和位置性三个黄金原则，并结合dLLM-Cache减少冗余计算。

Result: 实验表明，SlowFast Sampling在LLaDA上实现了最高15.63倍的加速，结合缓存后可达34.22倍，且生成质量损失极小，吞吐量甚至优于自回归基线模型LLaMA3 8B。

Conclusion: SlowFast Sampling通过动态采样策略和缓存优化，显著提升了扩散语言模型的解码效率和生成质量，证明了其在快速高质量生成任务中的潜力。

摘要: 扩散语言模型（dLLMs）作为一种替代传统自回归大语言模型的新方法，通过并行生成令牌显著降低了推理延迟。然而，现有的dLLMs采样策略（如基于置信度或半自回归解码）通常存在静态行为问题，导致效率低下和灵活性不足。本文提出SlowFast Sampling，一种动态采样策略，通过自适应切换探索性和加速解码阶段，遵循确定性、收敛性和位置性三大黄金原则，指导令牌的高效解码。我们还结合dLLM-Cache减少冗余计算。在多个基准测试和模型上的实验表明，SlowFast Sampling在LLaDA上实现了最高15.63倍的加速，结合缓存后可达34.22倍，且生成质量损失极小。值得注意的是，我们的方法在吞吐量上甚至优于LLaMA3 8B等强自回归基线模型，证明了精心设计的采样策略可以充分释放dLLMs在快速高质量生成任务中的潜力。

</details>


### [110] [Analyzing the relationships between pretraining language, phonetic, tonal, and speaker information in self-supervised speech models](https://arxiv.org/abs/2506.10855)
**中文标题：分析自监督语音模型中预训练语言、语音、音调及说话者信息的关系**

*Michele Gubian,Ioana Krehan,Oli Liu,James Kirby,Sharon Goldwater*

Main category: cs.CL

TL;DR: 研究分析了wav2vec2模型在四种语言中如何编码语音、音调及说话者信息，发现这些信息的表示子空间基本正交，且层间模式相似，表明模型表示结构独立于预训练语言。


<details>
  <summary>Details</summary>
Motivation: 现有分析多集中于英语，本研究旨在探讨wav2vec2模型在不同语言中如何编码语音、音调和说话者信息，以揭示其表示结构的普适性。

Method: 使用四种语言训练的wav2vec2模型，通过探测分类器和几何分析方法，研究语音、词汇音调和说话者信息的表示。

Result: 所有预训练和测试语言中，语音、音调和说话者信息的表示子空间基本正交；层间探测准确率模式相似，后期层中匹配语言的语音和音调探测略有优势。

Conclusion: wav2vec2学习的表示结构在很大程度上独立于预训练语言材料，表明其具有跨语言的普适性。

摘要: 自监督语音模型的分析已开始揭示其如何表示不同类型的信息。然而，几乎所有分析都集中在英语上。本文研究了在四种不同语言上训练的wav2vec2模型如何编码匹配和非匹配语言的语音。我们使用探测分类器和几何分析方法，研究语音、词汇音调和说话者信息的表示。结果表明，对于所有预训练和测试语言，编码语音、音调和说话者信息的子空间基本正交，且层间探测准确率模式相似，后期层中匹配语言的语音和音调（而非说话者）探测略有优势。我们的发现表明，wav2vec2学习的表示结构在很大程度上独立于预训练语言材料。

</details>


### [111] [Enhancing Medical Dialogue Generation through Knowledge Refinement and Dynamic Prompt Adjustment](https://arxiv.org/abs/2506.10877)
**中文标题：通过知识精炼和动态提示调整增强医疗对话生成**

*Hongda Sun,Jiaren Peng,Wenzhong Yang,Liang He,Bo Du,Rui Yan*

Main category: cs.CL

TL;DR: 本文提出了一种名为MedRef的新型医疗对话系统，通过知识精炼和动态提示调整，显著提升了医疗对话的生成质量和医学实体准确性。


<details>
  <summary>Details</summary>
Motivation: 现有医疗对话系统（MDS）在识别相关医学知识和生成个性化、医学准确的响应方面存在不足，亟需改进。

Method: MedRef采用知识精炼机制过滤无关医学数据，并设计了一种综合提示结构，结合历史细节和证据细节。此外，通过Triplet Filter和Demo Selector模块实现实时适应性。

Result: 在MedDG和KaMed基准测试中，MedRef在生成质量和医学实体准确性上均优于现有基线模型。

Conclusion: MedRef通过知识精炼和动态提示调整，显著提升了医疗对话系统的性能，适用于实际医疗应用。

摘要: 医疗对话系统（MDS）已成为支持多轮、上下文感知患者对话的关键在线平台。然而，现有MDS往往难以（1）识别相关医学知识，（2）生成个性化且医学准确的响应。为解决这些问题，我们提出了MedRef，一种新型MDS，结合了知识精炼和动态提示调整。首先，我们采用知识精炼机制过滤无关医学数据，提升对响应中关键医学实体的预测。此外，我们设计了一种综合提示结构，结合历史细节和证据细节。为实现对多样化患者病情的实时适应性，我们实现了两个关键模块——Triplet Filter和Demo Selector，为系统提示提供适当的知识和示例。在MedDG和KaMed基准测试上的大量实验表明，MedRef在生成质量和医学实体准确性上均优于现有基线模型，证明了其在现实医疗应用中的有效性和可靠性。

</details>


### [112] [Slimming Down LLMs Without Losing Their Minds](https://arxiv.org/abs/2506.10885)
**中文标题：在不丧失智能的情况下精简大型语言模型**

*Qingda,Mai*

Main category: cs.CL

TL;DR: 本文研究了参数高效方法（LoRA和QLoRA）对大型语言模型性能的影响，发现LoRA方法在提升任务性能的同时保持计算效率，且性能与微调数据集和基准任务的匹配度密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索如何在资源有限的情况下高效微调大型语言模型，同时保持其性能。

Method: 方法包括使用LoRA和QLoRA对模型进行微调，并在三个关键领域（常识推理、数学推理和多领域知识）评估模型性能。

Result: 结果表明，LoRA方法能有效提升任务性能且计算高效，性能表现与微调数据集和任务的匹配度高度相关。

Conclusion: 结论为参数高效方法（如LoRA）为开发者提供了理论指导和实践参考，帮助在有限资源下高效适应大型语言模型。

摘要: 本文研究并验证了微调对大型语言模型性能的影响，重点关注参数高效方法（LoRA和QLoRA）。我们在三个关键领域评估模型能力：（1）常识推理（HellaSwag），（2）数学推理（GSM8K），以及（3）多领域知识（MMLU-CS）。研究结果表明：（1）基于LoRA的方法在提升任务性能的同时保持了计算效率；（2）性能表现与微调数据集和基准任务的匹配度密切相关。本研究不仅提供了参数高效机制的理论见解，还为开发者在资源有限的情况下高效适应大型语言模型提供了实践指导。

</details>


### [113] [A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations](https://arxiv.org/abs/2506.10019)
**中文标题：文本、视觉和语音生成的自动评估方法综述**

*Tian Lan,Yang-Hao Zhou,Zi-Ao Ma,Fanshu Sun,Rui-Qing Sun,Junyu Luo,Rong-Cheng Tu,Heyan Huang,Chen Xu,Zhijing Wu,Xian-Ling Mao*

Main category: cs.CL

TL;DR: 本文综述了文本、视觉和语音生成领域的自动评估方法，提出了一个统一的分类框架，并探讨了跨模态评估的未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在生成式AI领域取得了显著进展，但如何自动评估生成内容的质量仍是一个挑战。目前缺乏一个系统性的框架来统一组织文本、视觉和音频模态的评估方法。

Method: 作者首先分析了文本生成领域的成熟评估方法，随后将这一框架扩展到图像和音频生成领域，提出了五种基本范式来分类现有的评估方法。

Result: 研究提出了一个统一的分类框架，适用于文本、图像和音频生成的自动评估方法，并展示了其广泛适用性。

Conclusion: 本文为跨模态评估方法的研究提供了系统性的综述和分类框架，并指出了未来研究的潜在方向。

摘要: 近年来，深度学习显著提升了生成式AI在文本、图像和音频领域的能力。然而，如何自动评估这些生成内容的质量仍是一个持续的挑战。尽管存在许多自动评估方法，但目前的研究缺乏一个系统性的框架来全面组织这些方法，涵盖文本、视觉和音频模态。为解决这一问题，我们对所有三种模态的生成内容自动评估方法进行了全面综述，并提出了一种统一的分类法；我们识别了五种基本范式，用于描述这些领域中的现有评估方法。我们的分析首先考察了文本生成的评估方法，这些技术最为成熟。随后，我们将这一框架扩展到图像和音频生成领域，展示了其广泛适用性。最后，我们探讨了跨模态评估方法未来研究的有望方向。

</details>


### [114] [TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org/abs/2506.10055)
**中文标题：TaskCraft：代理任务的自动化生成**

*Dingfeng Shi,Jingyi Cao,Qianben Chen,Weichen Sun,Weizhen Li,Hongxuan Lu,Fangchen Dong,Tianrui Qin,King Zhu,Minghao Yang,Jian Yang,Ge Zhang,Jiaheng Liu,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: TaskCraft 是一种自动化工作流，用于生成可扩展难度、多工具且可验证的代理任务，解决了现有指令数据缺乏工具交互和人工标注成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 代理任务（需要多步自主问题解决、工具使用和自适应推理）对NLP和AI发展至关重要，但现有数据缺乏工具交互，且人工标注成本高，限制了可扩展性。

Method: TaskCraft 通过深度和广度扩展原子任务，生成结构和层次复杂的挑战，并创建大规模合成数据集（约36,000个任务）。

Result: 实验表明，这些任务优化了生成工作流中的提示，并提升了代理基础模型的监督微调效果。

Conclusion: TaskCraft 为代理调优和评估提供了可扩展的解决方案，支持未来研究。

摘要: 代理任务需要多步自主问题解决、工具使用和自适应推理，对NLP和AI的发展日益重要。然而，现有指令数据缺乏工具交互，且当前代理基准依赖昂贵的人工标注，限制了可扩展性。我们提出了TaskCraft，一种自动化工作流，用于生成可扩展难度、多工具且可验证的代理任务及其执行轨迹。TaskCraft通过深度和广度扩展原子任务，创建结构和层次复杂的挑战。实验结果表明，这些任务优化了生成工作流中的提示，并提升了代理基础模型的监督微调效果。我们提供了一个大规模合成数据集（约36,000个任务，难度各异），以支持未来关于代理调优和评估的研究。

</details>


### [115] [A quantum semantic framework for natural language processing](https://arxiv.org/abs/2506.10077)
**中文标题：自然语言处理的量子语义框架**

*Christopher J. Agostino,Quan Le Thien,Molly Apsel,Denizhan Pak,Elina Lesyk,Ashabari Majumdar*

Main category: cs.CL

TL;DR: 本文提出了一种量子语义框架，用于解决自然语言处理中的语义退化问题。通过实验证明，语言解释在歧义下表现出非经典的上下文相关性，暗示经典方法存在局限性，并提出贝叶斯重复采样方法更适用于实际语言意义表征。


<details>
  <summary>Details</summary>
Motivation: 自然语言的语义退化问题导致大型语言模型（LLM）等现代NLP系统面临固有局限性。本文旨在通过量子语义框架揭示语言解释的非经典特性，并探索更有效的意义表征方法。

Method: 作者利用Kolmogorov复杂性理论分析语言表达的复杂性，并通过语义贝尔不等式测试，使用LLM代理作为“计算认知系统”解释歧义词对。实验测量了CHSH期望值，验证了非经典上下文相关性的存在。

Result: 实验结果显示，CHSH期望值在1.2至2.8之间，部分结果（如2.3-2.4）显著违反经典边界（|S|≤2），表明语言解释在歧义下具有非经典上下文相关性。

Conclusion: 经典频率分析方法在自然语言处理中存在局限性，而贝叶斯重复采样方法能更有效地表征上下文中的语言意义。研究结果为语言理解的量子特性提供了实证支持。

摘要: 语义退化是自然语言的基本特性，超越了简单的多义性，涵盖了语义表达复杂性增加时潜在解释的组合爆炸。大型语言模型（LLM）和其他现代NLP系统因其在自然语言内部运行而面临固有局限性，受到语义退化带来的解释约束。本文通过Kolmogorov复杂性理论论证，随着表达复杂性的增加，任何解释主体（人类或LLM驱动的AI）恢复单一预期意义的可能性趋近于零。这种计算上的不可行性表明，传统认为语言形式本身具有意义的观点存在缺陷。相反，我们认为意义是通过观察者依赖的解释行为实现的。为验证这一点，我们进行了语义贝尔不等式测试，将多样化的LLM代理作为“计算认知系统”在不同上下文设置下解释歧义词对。在多个独立实验中，CHSH期望值平均范围为1.2至2.8，部分结果（如2.3-2.4）显著违反经典边界（|S|≤2）。这表明在歧义下的语言解释可以表现出非经典的上下文相关性，与人类认知实验结果一致。这些结果暗示，基于经典频率分析的自然语言方法必然存在信息损失。我们提出，贝叶斯式的重复采样方法能更实用且适当地表征上下文中的语言意义。

</details>


### [116] [Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information](https://arxiv.org/abs/2506.10086)
**中文标题：Chat-of-Thought：用于生成领域特定信息的协作多智能体系统**

*Christodoulos Constantinides,Shuxin Lin,Nianjun Zhou,Dhaval Patel*

Main category: cs.CL

TL;DR: 本文提出了一种名为Chat-of-Thought的多智能体系统，用于生成工业资产的故障模式与影响分析（FMEA）文档。该系统通过多角色协作的LLM智能体和动态任务路由优化FMEA表的生成与验证，并通过动态多角色讨论迭代优化内容。


<details>
  <summary>Details</summary>
Motivation: 工业设备监测领域需要高效生成FMEA文档，但传统方法存在效率低和内容质量不足的问题。本文旨在通过多智能体协作系统解决这些挑战。

Method: Chat-of-Thought系统采用多个具有特定角色的LLM智能体，结合动态任务路由和多角色驱动的动态讨论（Chat of Thought），通过模板驱动的工作流程和上下文感知的智能体协作生成和验证FMEA表。

Result: 研究表明，Chat-of-Thought系统能够高效生成高质量的FMEA文档，并通过多角色协作和动态讨论显著提升内容的准确性和完整性。

Conclusion: Chat-of-Thought系统在工业设备监测领域展示了多智能体协作的潜力，为FMEA文档生成提供了一种创新且高效的解决方案。

摘要: 本文提出了一种名为Chat-of-Thought的新型多智能体系统，旨在为工业资产生成故障模式与影响分析（FMEA）文档。Chat-of-Thought利用多个具有特定角色的大型语言模型（LLM）智能体，通过先进的AI技术和动态任务路由优化FMEA表的生成与验证。该系统的关键创新在于引入了“Chat of Thought”，即通过动态、多角色驱动的讨论实现内容的迭代优化。本研究探讨了工业设备监测领域的应用场景，突出了关键挑战，并通过交互式、模板驱动的工作流程和上下文感知的智能体协作，展示了Chat-of-Thought在解决这些挑战中的潜力。

</details>


### [117] [When Meaning Stays the Same, but Models Drift: Evaluating Quality of Service under Token-Level Behavioral Instability in LLMs](https://arxiv.org/abs/2506.10095)
**中文标题：当语义不变而模型漂移时：评估大型语言模型在分词级别行为不稳定性下的服务质量**

*Xiao Li,Joel Kreuzwieser,Alan Peters*

Main category: cs.CL

TL;DR: 研究大型语言模型在语义相同但表达不同的提示下的行为变化，提出Prompt-Based Semantic Shift（PBSS）框架，揭示模型在重述提示时的行为漂移。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在语义相同但表达不同的提示下是否会产生行为变化，以评估模型在重述提示时的稳定性。

Method: 提出PBSS框架，通过十项约束任务测量模型在语义等效提示重述下的行为漂移。

Result: 发现模型在语义等效提示下存在一致的行为变化，表明分词和解码策略可能影响模型稳定性。

Conclusion: 提示重述可能导致模型行为漂移，分词和解码策略是影响模型服务质量稳定性的潜在因素。

摘要: 我们研究了大型语言模型对语义意图相同但分词表达不同的提示的响应，这种现象称为提示变异。我们提出了Prompt-Based Semantic Shift（PBSS），一个用于测量大型语言模型在语义等效提示重述下行为漂移的诊断框架。应用于十项约束任务时，PBSS揭示了模型特定的响应变化，表明这些变化与分词和解码策略有关。这些结果突出了在提示重述下模型评估稳定性的一个被忽视的维度，并表明分词策略和解码动态可能影响训练后的服务质量稳定性。

</details>


### [118] [ChartReasoner: Code-Driven Modality Bridging for Long-Chain Reasoning in Chart Question Answering](https://arxiv.org/abs/2506.10116)
**中文标题：ChartReasoner：代码驱动的模态桥接用于图表问答中的长链推理**

*Caijun Jia,Nan Xu,Jingxuan Wei,Qingli Wang,Lei Wang,Bihui Yu,Junnan Zhu*

Main category: cs.CL

TL;DR: ChartReasoner是一个代码驱动的两阶段框架，旨在通过将图表图像转换为结构化代码并生成高质量推理数据，实现精确且可解释的图表推理。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在长链推理任务中表现出色，但如何将其扩展到视觉推理任务仍是一个挑战。现有方法通过图像到文本的转换丢失了关键视觉信息，尤其是在需要大量视觉细节的图表问答任务中。

Method: ChartReasoner分为两个阶段：首先将图表图像转换为结构化ECharts代码以保留布局和数据语义；其次设计数据合成管道生成高质量推理轨迹，并通过代码验证器过滤低质量样本。最终通过监督微调和强化学习训练多模态模型。

Result: 在四个公共基准测试中，ChartReasoner在保留图表原始细节的同时，性能与最先进的开源模型相当，且参数更少，接近GPT-4o等专有系统的表现。

Conclusion: ChartReasoner通过代码驱动的方法有效解决了视觉推理任务中的信息丢失问题，为图表问答任务提供了一种高效且可扩展的解决方案。

摘要: 近年来，大型语言模型通过长链推理在回答问题前展现出卓越的推理能力。然而，如何将这种能力扩展到视觉推理任务仍是一个开放性问题。现有的多模态推理方法通过多次图像到文本的转换将视觉推理任务转化为文本推理任务，但往往会丢失视觉化中嵌入的关键结构和语义信息，尤其是在需要大量视觉细节的图表问答任务中。为填补这一空白，我们提出了ChartReasoner，一种代码驱动的两阶段框架，旨在实现对图表的精确、可解释推理。我们首先训练一个高保真模型，将多样化的图表图像转换为结构化ECharts代码，尽可能无损地保留布局和数据语义。然后，我们设计了一个通用的图表推理数据合成管道，利用预训练的传输模型自动且可扩展地生成图表推理轨迹，并通过代码验证器过滤低质量样本。最后，我们在合成的图表推理数据集上结合监督微调和强化学习训练最终的多模态模型。在四个公共基准测试上的实验结果清晰地证明了ChartReasoner的有效性。它能够尽可能保留图表的原始细节，并在使用较少参数的情况下与最先进的开源模型性能相当，在域外设置中接近GPT-4o等专有系统的表现。

</details>


### [119] [Unsupervised Elicitation of Language Models](https://arxiv.org/abs/2506.10139)
**中文标题：无监督引导语言模型**

*Jiaxin Wen,Zachary Ankner,Arushi Somani,Peter Hase,Samuel Marks,Jacob Goldman-Wetzler,Linda Petrini,Henry Sleight,Collin Burns,He He,Shi Feng,Ethan Perez,Jan Leike*

Main category: cs.CL

TL;DR: 本文提出了一种无监督算法ICM，用于微调预训练语言模型，无需外部监督即可生成高质量标签，性能优于人类监督方法。


<details>
  <summary>Details</summary>
Motivation: 当前的后训练范式依赖人类指定期望行为，但对于具有超人类能力的模型，高质量的人类监督难以实现。本文旨在解决这一挑战。

Method: 提出了一种名为内部一致性最大化（ICM）的无监督算法，通过模型自身生成的标签微调预训练语言模型，无需外部监督。

Result: 在GSM8k验证、TruthfulQA和Alpaca奖励建模任务中，ICM的性能与黄金监督训练相当，优于众包人类监督训练。对于超人类能力的任务，ICM显著优于人类标签训练。此外，ICM训练的奖励模型和基于Claude 3.5 Haiku的助手均优于人类监督版本。

Conclusion: ICM是一种有效的无监督方法，能够激发语言模型的超人类能力，并在前沿模型训练中表现出色。

摘要: 为了引导预训练语言模型适应下游任务，当前的后训练范式依赖人类指定期望行为。然而，对于具有超人类能力的模型，高质量的人类监督难以实现。为解决这一挑战，我们提出了一种新的无监督算法——内部一致性最大化（ICM），用于微调预训练语言模型，仅依赖其自身生成的标签，无需外部监督。在GSM8k验证、TruthfulQA和Alpaca奖励建模任务中，我们的方法性能与黄金监督训练相当，并优于众包人类监督训练。对于语言模型能力远超人类的任务，我们的方法能显著更好地激发这些能力。最后，我们展示了该方法在前沿语言模型训练中的应用：通过ICM训练无监督奖励模型，并使用强化学习训练基于Claude 3.5 Haiku的助手。奖励模型和助手均优于其人类监督版本。

</details>


### [120] [When Large Language Models are Reliable for Judging Empathic Communication](https://arxiv.org/abs/2506.10150)
**中文标题：大型语言模型在判断共情沟通时的可靠性**

*Aakriti Kumar,Nalin Poungpeth,Diyi Yang,Erina Farrell,Bruce Lambert,Matthew Groh*

Main category: cs.CL

TL;DR: 研究比较了专家、众包工作者和大型语言模型（LLMs）在四种心理学、自然语言处理和传播学框架下对共情沟通的标注可靠性，发现LLMs的表现接近专家水平，并优于众包工作者。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）在判断共情沟通细微差别时的可靠性，尤其是在情感敏感应用中如何支持透明度和监督。

Method: 通过比较专家、众包工作者和LLMs在四种评估框架下对200个真实对话的共情沟通标注，分析其评分者间一致性。

Result: 专家一致性较高，但受框架子组分的清晰度、复杂性和主观性影响；LLMs表现接近专家水平，且优于众包工作者。

Conclusion: LLMs在特定任务和适当基准验证下，可作为情感敏感应用（如对话伴侣）的可靠工具。

摘要: 大型语言模型（LLMs）在基于文本的对话中擅长生成共情回应。然而，它们在判断共情沟通的细微差别时有多可靠？我们通过比较专家、众包工作者和LLMs在四种心理学、自然语言处理和传播学框架下对200个真实对话的共情沟通标注，探讨了这一问题。基于3,150条专家标注、2,844条众包标注和3,150条LLM标注，我们评估了这三组标注者之间的评分者间一致性。研究发现，专家一致性较高，但受框架子组分的清晰度、复杂性和主观性影响。专家一致性为LLM表现提供了比标准分类指标更具信息性的基准。在所有四种框架中，LLMs的表现均接近专家水平，并优于众包工作者。这些结果表明，LLMs在特定任务和适当基准验证下，可以支持情感敏感应用（如对话伴侣）的透明度和监督。

</details>


### [121] [Analyzing Emotions in Bangla Social Media Comments Using Machine Learning and LIME](https://arxiv.org/abs/2506.10154)
**中文标题：利用机器学习和LIME分析孟加拉语社交媒体评论中的情感**

*Bidyarthi Paul,SM Musfiqur Rahman,Dipta Biswas,Md. Ziaul Hasan,Md. Zahid Hossain*

Main category: cs.CL

TL;DR: 本研究利用机器学习模型（如Linear SVM、KNN和Random Forest）和LIME解释器，分析了孟加拉语社交媒体评论中的情感，旨在为资源有限的语言提供高效的情感识别方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于扩展对孟加拉语等资源有限语言的情感分析，因其具有独特的地区表达和文化特征。

Method: 方法包括使用TF-IDF向量化器生成n-gram数据，并应用Linear SVM、KNN、Random Forest等机器学习模型，同时结合PCA降维、BiLSTM模型和AdaBoost提升决策树性能，并使用LIME解释AdaBoost分类器的预测。

Result: 研究结果表明，所提出的方法能够有效识别孟加拉语社交媒体评论中的情感，LIME进一步提高了模型的可解释性。

Conclusion: 结论指出，该研究为资源有限语言的情感分析提供了高效且可解释的技术，推动了相关领域的发展。

摘要: 对书面语言中情感理解的研究持续扩展，尤其是针对孟加拉语等具有独特地区表达和文化特征的未被充分研究的语言。本研究使用EmoNoBa数据集中的22,698条社交媒体评论进行情感分析。在语言分析中，我们采用了机器学习模型：基于TF-IDF向量化器生成的n-gram数据的Linear SVM、KNN和Random Forest。此外，我们还研究了PCA对降维的影响。进一步地，我们使用了BiLSTM模型和AdaBoost来提升决策树性能。为了使机器学习模型更易于理解，我们使用LIME解释了基于决策树的AdaBoost分类器的预测。本研究旨在推动资源有限语言的情感分析，探索了多种技术以寻找高效的孟加拉语情感识别方法。

</details>


### [122] [Measuring Corporate Human Capital Disclosures: Lexicon, Data, Code, and Research Opportunities](https://arxiv.org/abs/2506.10155)
**中文标题：衡量企业人力资本披露：词汇表、数据、代码与研究机会**

*Elizabeth Demers,Victor Xiaoqi Wang,Kean Wu*

Main category: cs.CL

TL;DR: 本文开发了一个基于机器学习的词汇表，用于衡量企业人力资本披露，并提供了相关数据和代码，为未来研究提供了工具和方向。


<details>
  <summary>Details</summary>
Motivation: 人力资本（HC）对企业价值创造日益重要，但目前缺乏明确的衡量和披露规则。本文旨在填补这一空白，为研究HC管理提供工具和方法。

Method: 使用word2vec机器学习算法，基于已确认的HC披露数据，开发了一个包含五个子类别的HC相关关键词词汇表。

Result: 开发了一个全面的HC关键词词汇表，并提供了相关数据、Python代码及使用示例，包括BERT模型的微调。

Conclusion: 本文的词汇表和工具为研究HC管理提供了基础，并提出了未来研究方向。

摘要: 人力资本（HC）对企业价值创造日益重要。然而，与其他资产不同，HC目前缺乏明确的衡量或披露规则。我们使用机器学习算法（word2vec），基于已确认的HC披露数据，开发了一个全面的HC相关关键词列表，并将其分为五个子类别（多样性、公平与包容；健康与安全；劳动关系与文化；薪酬与福利；人口统计与其他），以捕捉HC管理的多维性。我们分享了词汇表、企业HC披露数据及用于开发词汇表的Python代码，并提供了使用数据和代码的详细示例，包括微调BERT模型。研究人员可以使用我们的HC词汇表（或修改代码以捕捉其他感兴趣的构念）与企业沟通样本，解决相关HC问题。最后，我们讨论了与HC管理和披露相关的未来研究机会。

</details>


### [123] [Can LLMs Generate Good Stories? Insights and Challenges from a Narrative Planning Perspective](https://arxiv.org/abs/2506.10161)
**中文标题：LLMs能生成好故事吗？从叙事规划视角的洞察与挑战**

*Yi Wang,Max Kreminski*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在故事生成中的能力，通过叙事规划视角评估其生成高质量故事的潜力。研究发现，GPT-4级别的LLMs能够在小规模生成因果合理的故事，但在角色意图和戏剧冲突方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 故事生成是LLMs的重要应用之一，但目前对其生成高质量故事的能力缺乏深入理解。由于自动评估方法的局限性和人工评估的高成本与主观性，亟需一种更系统的方法来评估LLMs的叙事能力。

Method: 研究通过将LLMs应用于叙事规划问题，设计了一个基于文学示例的评估基准，重点关注因果合理性、角色意图性和戏剧冲突。实验使用GPT-4级别的LLMs进行测试。

Result: 实验结果表明，GPT-4级别的LLMs能够在小规模生成因果合理的故事，但在角色意图性和戏剧冲突方面表现不佳，需要结合强化学习进行复杂推理。

Conclusion: 研究揭示了LLMs在故事生成中的潜力与局限，为未来在游戏环境中应用LLM叙事规划提供了挑战与思考方向。

摘要: 故事生成是大型语言模型（LLMs）的重要应用之一。然而，由于自动评估方法的局限性和人工评估的高成本与主观性，对LLMs生成高质量故事能力的理解仍然有限。计算叙事学为优秀故事的定义提供了宝贵见解，并已应用于符号叙事规划方法中。本研究旨在通过让LLMs解决叙事规划问题，深化对其故事生成能力的理解。我们提出了一个基于文学示例的叙事规划评估基准，重点关注因果合理性、角色意图性和戏剧冲突。实验表明，GPT-4级别的LLMs能够在小规模生成因果合理的故事，但在角色意图性和戏剧冲突方面仍面临挑战，需要结合强化学习进行复杂推理。研究结果为LLMs在不同方面保持故事质量的生成规模提供了见解，同时也揭示了其在游戏环境中应用叙事规划的挑战与思考。

</details>


### [124] [Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval](https://arxiv.org/abs/2506.10202)
**中文标题：Q2E：用于零样本多语言文本到视频检索的查询到事件分解方法**

*Shubhashis Roy Dipta,Francis Ferraro*

Main category: cs.CL

TL;DR: Q2E是一种用于零样本多语言文本到视频检索的查询到事件分解方法，通过分解复杂查询并利用LLMs和VLMs的潜在知识，显著提升了视频检索性能，尤其在多模态输入（如音频）的整合中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前方法在从大型语言模型（LLMs）和视觉语言模型（VLMs）中提取和利用参数化知识方面表现出色，但在处理复杂现实世界事件的视频检索时仍有改进空间。Q2E旨在通过分解查询并利用LLMs和VLMs的潜在知识，提升对复杂查询的理解和视频检索能力。

Method: Q2E提出了一种查询到事件的分解方法，通过LLMs和VLMs嵌入的知识分解复杂查询，并结合基于熵的融合评分实现零样本多模态融合。该方法支持视觉和语音输入的多模态整合。

Result: 在多个数据集和检索指标上的评估表明，Q2E优于多种先进基线方法。实验还显示，整合音频信息能显著提升文本到视频检索的性能。

Conclusion: Q2E通过分解查询和利用多模态知识，显著提升了零样本多语言文本到视频检索的性能，尤其在整合音频信息时效果更佳。研究为未来相关领域提供了代码和数据支持。

摘要: 近期方法在从大型语言模型（LLMs）和视觉语言模型（VLMs）中提取和利用参数化知识方面表现出色。本文探讨如何通过自动提取复杂现实世界事件的潜在参数化知识，改进相关视频的识别和检索。我们提出了Q2E：一种适用于零样本多语言文本到视频检索的查询到事件分解方法，可跨数据集、领域、LLMs或VLMs适配。我们的方法表明，通过利用LLMs和VLMs嵌入的知识分解查询，可以增强对过于简化的人类查询的理解。我们还展示了如何将方法应用于视觉和语音输入。为整合这些多模态知识，我们采用基于熵的融合评分进行零样本融合。通过在两个多样化数据集和多种检索指标上的评估，我们证明Q2E优于多种先进基线方法。评估还显示，整合音频信息能显著提升文本到视频检索性能。我们已发布代码和数据以供未来研究。

</details>


### [125] [TTT-Bench: A Benchmark for Evaluating Reasoning Ability with Simple and Novel Tic-Tac-Toe-style Games](https://arxiv.org/abs/2506.10209)
**中文标题：TTT-Bench：通过简单新颖的井字棋类游戏评估推理能力的基准**

*Prakamya Mishra,Jiang Liu,Jialian Wu,Xiaodong Yu,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: TTT-Bench是一个新基准，通过简单的井字棋类游戏评估大型推理模型的基本战略、空间和逻辑推理能力，发现这些模型在简单推理任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在复杂任务（如数学奥林匹克问题）中表现出色，但其在更广泛任务领域的推理能力尚未充分探索。TTT-Bench旨在填补这一空白。

Method: 设计了一套四个简单的井字棋类游戏，通过可验证的程序化方法生成问题，评估模型在战略、空间和逻辑推理上的表现。

Result: 模型在TTT-Bench上的表现比数学任务（MATH 500和AIME 2024）低41%和5%，且大模型在长程战略推理中表现较差。

Conclusion: TTT-Bench揭示了大型推理模型在简单推理任务上的局限性，尤其是长程战略推理能力不足。

摘要: 大型推理模型（LRMs）在广泛的推理任务中展现了出色的能力，包括奥林匹克级别的数学问题，表明其具备复杂的推理能力。然而，许多推理基准集中在STEM领域，LRMs在更广泛任务领域的推理能力仍待探索。本文提出了\textbf{TTT-Bench}，这是一个新的基准，旨在通过四个简单的两人井字棋类游戏评估LRMs的基本战略、空间和逻辑推理能力。这些游戏对人类而言轻而易举，但需要推理对手的意图以及游戏板的空间配置以确保胜利。我们提出了一种简单且可扩展的程序化方法，用于生成TTT-Bench的可验证两人游戏问题。我们评估了多种最先进的LRMs，\textbf{发现那些在复杂数学问题上表现出色的模型在这些简单推理游戏中经常失败}。进一步测试表明，与MATH 500和AIME 2024相比，我们的推理模型在TTT-Bench上的得分平均低41%和5%，且大模型在短推理路径上表现更好，而大多数模型在简单和新颖的TTT-Bench任务中的长程战略推理上表现不佳。

</details>


### [126] [Classifying Unreliable Narrators with Large Language Models](https://arxiv.org/abs/2506.10231)
**中文标题：使用大型语言模型分类不可靠叙述者**

*Anneliese Brei,Katharine Henry,Abhisheik Sharma,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.CL

TL;DR: 本文提出使用大型语言模型（LLM）识别不可靠叙述者，并发布了一个人工标注的数据集TUNa。实验表明，尽管任务具有挑战性，但LLM在此领域有潜力。


<details>
  <summary>Details</summary>
Motivation: 在阅读第一人称叙述时，判断叙述者是否可靠是一个常见问题。本文旨在通过计算方法自动识别不可靠叙述者，尤其是那些无意中歪曲信息的叙述者。

Method: 结合叙事学理论定义不可靠叙述者的类型，构建了多领域的人工标注数据集TUNa。设计了分类任务（如叙述内、叙述间和文本间不可靠性），并测试了多种LLM在少样本学习、微调和课程学习设置下的表现。

Result: 实验结果显示，识别不可靠叙述者的任务非常具有挑战性，但LLM在此领域展现出潜力。

Conclusion: 本文证明了LLM在识别不可靠叙述者方面的潜力，并发布了数据集和代码以促进未来研究。

摘要: 在接触第一人称叙述时，我们常常会思考叙述者是否可靠。本文提出使用计算方法识别不可靠叙述者，即那些无意中歪曲信息的叙述者。借鉴叙事学理论，我们基于多种文本现象定义了不同类型的不可靠叙述者，并发布了TUNa数据集，这是一个包含博客、论坛帖子、酒店评论和文学作品的多领域人工标注数据集。我们设计了叙述内、叙述间和文本间不可靠性的分类任务，并分析了多种开源和专有LLM在每种任务中的表现。我们尝试通过少样本学习、微调和课程学习从文学中学习，以应用于现实文本数据的不可靠叙述者分类。结果表明，这一任务极具挑战性，但LLM在此领域有潜力。我们发布了专家标注的数据集和代码，并邀请未来研究加入这一领域。

</details>


### [127] [ToxSyn-PT: A Large-Scale Synthetic Dataset for Hate Speech Detection in Portuguese](https://arxiv.org/abs/2506.10245)
**中文标题：ToxSyn-PT：葡萄牙语仇恨言论检测的大规模合成数据集**

*Iago Alves Brito,Julia Soares Dollis,Fernanda Bufon Färber,Diogo Fernandes Costa Silva,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: 本文介绍了ToxSyn-PT，首个大规模葡萄牙语仇恨言论检测数据集，涵盖九个受法律保护的少数群体，并通过四阶段流程生成合成数据，实验表明其在跨领域任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语仇恨言论数据集多来自社交媒体，且缺乏对少数群体的细粒度分类。ToxSyn-PT旨在填补这一空白，提供多样化的合成数据以支持低资源环境下的研究。

Method: 采用四阶段流程生成数据集：(1) 手动整理种子数据；(2) 使用指令调优的大语言模型进行少样本扩展；(3) 基于释义的增强；(4) 添加中性文本以防止过拟合。

Result: 实验表明，ToxSyn-PT在五个公开葡萄牙语仇恨言论数据集上的二分类和多标签分类任务中表现优异，展示了跨领域的强泛化能力。

Conclusion: ToxSyn-PT为葡萄牙语仇恨言论检测提供了高质量合成数据，推动了低资源环境下的研究，并公开数据集以促进进一步探索。

摘要: 我们提出了ToxSyn-PT，这是首个针对葡萄牙语的大规模仇恨言论分类数据集，涵盖九个受法律保护的少数群体。该数据集包含53,274条合成句子，均匀分布在少数群体和毒性标签之间。ToxSyn-PT通过一种新颖的四阶段流程生成：(1) 手动整理的紧凑种子数据；(2) 使用指令调优的大语言模型进行少样本扩展；(3) 基于释义的增强；(4) 添加中性文本以防止对群体特定线索的过拟合。生成的语料库类别平衡、风格多样，且避免了现有葡萄牙语数据集中社交媒体领域的局限性。尽管与传统基准存在领域差异，但在该语料库上进行的二分类和多标签分类实验在五个公开葡萄牙语仇恨言论数据集中均表现出色，展示了跨领域的强泛化能力。该数据集已公开发布，以推动合成数据和低资源环境下仇恨言论检测的研究。

</details>


### [128] [Do Language Models Have Bayesian Brains? Distinguishing Stochastic and Deterministic Decision Patterns within Large Language Models](https://arxiv.org/abs/2506.10268)
**中文标题：语言模型是否具有贝叶斯大脑？区分大型语言模型中的随机与确定性决策模式**

*Andrea Yaoyun Cui,Pengfei Yu*

Main category: cs.CL

TL;DR: 本文探讨语言模型是否具有贝叶斯大脑，发现其在某些条件下会表现出近乎确定性的决策模式，挑战了传统的采样假设，并提出了一种区分随机与确定性决策模式的方法。


<details>
  <summary>Details</summary>
Motivation: 语言模型通常被视为概率分布，通过迭代采样生成句子。然而，这种假设可能掩盖了模型在某些条件下的确定性行为。本文旨在验证语言模型是否真正具有贝叶斯大脑，并揭示其决策模式的多样性。

Method: 通过模拟Gibbs采样实验，研究语言模型在不同条件下的决策行为，并提出一种区分随机与确定性决策模式的方法。

Result: 研究发现，语言模型在某些条件下会表现出近乎确定性的决策（如最大似然估计），而非随机采样。此外，模拟Gibbs采样可能导致“虚假先验”的推断。

Conclusion: 语言模型的决策模式并非完全随机，可能包含确定性行为。传统方法可能误导对模型先验的推断，需采用新方法区分决策模式。

摘要: 语言模型本质上是基于标记序列的概率分布。自回归模型通过迭代计算和采样下一个标记的分布来生成句子。这种迭代采样引入了随机性，导致人们假设语言模型做出概率性决策，类似于从未知分布中采样。基于这一假设，先前的研究使用模拟Gibbs采样（受设计用于引发人类先验的实验启发）来推断语言模型的先验。本文重新审视一个关键问题：语言模型是否具有贝叶斯大脑？我们的研究结果表明，在某些条件下，语言模型可以表现出近乎确定性的决策，例如生成最大似然估计，即使采样温度非零。这挑战了采样假设，并削弱了先前引发人类类似先验的方法。此外，我们证明，未经适当审查，具有确定性行为的系统在模拟Gibbs采样过程中可能收敛到“虚假先验”。为解决这一问题，我们提出了一种简单的方法来区分Gibbs采样中的随机与确定性决策模式，有助于避免推断误导性的语言模型先验。我们在多种大型语言模型上进行了实验，以识别其在不同情况下的决策模式。我们的结果为理解大型语言模型的决策提供了重要见解。

</details>


### [129] [ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs](https://arxiv.org/abs/2506.10288)
**中文标题：ClusterUCB：基于梯度的高效数据选择框架用于大型语言模型的定向微调**

*Zige Wang,Qi Zhu,Fei Mi,Minghui Xu,Ruochun Jin,Wenjing Yang*

Main category: cs.CL

TL;DR: 本文提出了一种高效的基于梯度的数据选择框架ClusterUCB，通过聚类和修改的UCB算法，显著减少了计算资源消耗，同时保持了与原始梯度方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的数据选择方法在大型语言模型的监督微调中计算资源消耗过大，难以实际应用。因此，需要一种高效的方法来减少计算负担。

Method: 首先对训练数据池进行聚类，假设梯度特征相似的数据样本具有相似的影响；然后将簇间数据选择问题建模为带约束的计算预算分配问题，并视为多臂老虎机问题，采用修改的UCB算法解决。在迭代采样过程中，记录历史数据影响信息以直接估计每个簇的分布，并采用冷启动策略平衡探索与利用。

Result: 实验结果表明，ClusterUCB框架在多种基准测试中能够达到与原始梯度方法相当的性能，同时显著减少计算消耗。

Conclusion: ClusterUCB是一种高效且实用的数据选择框架，适用于大型语言模型的定向微调，能够在减少计算资源的同时保持性能。

摘要: 基于梯度的数据影响近似方法已被用于大型语言模型监督微调中有用数据样本的选择。然而，在整个微调过程中计算梯度需要过多资源，实际中难以实现。本文提出了一种高效的基于梯度的数据选择框架，结合聚类和修改的上置信界（UCB）算法。基于梯度特征相似的数据样本具有相似影响的直觉，我们首先对训练数据池进行聚类。然后，将簇间数据选择问题建模为带约束的计算预算分配问题，并视为多臂老虎机问题，采用修改的UCB算法解决。具体而言，在迭代采样过程中，记录历史数据影响信息以直接估计每个簇的分布，并采用冷启动策略平衡探索与利用。多种基准测试的实验结果表明，我们提出的ClusterUCB框架能够达到与原始梯度方法相当的结果，同时显著减少计算消耗。

</details>


### [130] [Flick: Few Labels Text Classification using K-Aware Intermediate Learning in Multi-Task Low-Resource Languages](https://arxiv.org/abs/2506.10292)
**中文标题：Flick：基于K感知中间学习的多任务低资源语言少标签文本分类**

*Ali Almutairi,Abdullah Alsuhaibani,Shoaib Jameel,Usman Naseem,Gelareh Mohammadi,Imran Razzak*

Main category: cs.CL

TL;DR: 本文提出了一种名为Flick的新方法，用于解决低资源语言中少标签文本分类的挑战。Flick通过改进伪标签质量，利用高置信度的伪标签簇，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前的自训练方法在半监督学习中表现良好，但在低资源语言中容易受到噪声伪标签的影响。现有方法多针对资源丰富的语言（如英语）或采用复杂级联模型，容易过拟合。Flick旨在解决低资源语言中少标签分类的难题。

Method: Flick提出了一种新颖的伪标签细化组件，通过从初始广泛的伪标签簇中筛选高置信度的簇，并利用自适应top-k选择机制，显著提升伪标签质量。这一方法特别适合语言多样化的低资源环境。

Result: Flick在14个多样化数据集上进行了测试，包括阿拉伯语、乌尔都语和塞茨瓦纳语等低资源语言，展示了其卓越的性能和适应性。

Conclusion: Flick通过改进伪标签质量，显著提升了低资源语言中少标签文本分类的效果，为这一领域提供了新的解决方案。

摘要: 由于能够减少对大量标注数据的依赖，使用最小监督训练深度学习网络已成为研究热点。尽管自训练方法在半监督学习中表现有效，但仍易受噪声伪标签的影响。此外，大多数少标签分类方法要么针对英语等资源丰富的语言设计，要么采用易过拟合的复杂级联模型。为解决低资源语言中少标签文本分类的难题，我们提出了Flick。与依赖通用多簇伪标签或复杂级联架构的现有方法不同，Flick基于一个核心洞察：从更广泛的初始簇中提取高置信度伪标签可显著提升伪标签质量，尤其是在语言多样化的低资源环境中。Flick引入了一种新颖的伪标签细化组件，通过识别并利用表现最佳的伪标签簇，从初始广泛集合中提炼高度可靠的伪标签。该组件专注于单簇内聚性，并采用自适应top-k选择机制。这一针对性细化过程对于减少低资源数据中的错误传播至关重要，仅需少量真实标签即可对预训练语言模型进行鲁棒微调。我们在14个多样化数据集上验证了Flick的有效性，涵盖阿拉伯语、乌尔都语和塞茨瓦纳语等低资源语言及英语，展示了其卓越的性能和适应性。

</details>


### [131] ["Check My Work?": Measuring Sycophancy in a Simulated Educational Context](https://arxiv.org/abs/2506.10297)
**中文标题：“检查我的作业？”：模拟教育环境中阿谀行为的测量**

*Chuck Arvin*

Main category: cs.CL

TL;DR: 本研究探讨了在模拟教育环境中，用户提供的建议如何影响大型语言模型（LLMs），尤其是阿谀行为（sycophancy）带来的风险。实验表明，LLMs的回答质量因问题表述方式差异显著，且较小模型更容易表现出阿谀行为。


<details>
  <summary>Details</summary>
Motivation: 在模拟教育环境中，LLMs的阿谀行为可能加剧教育不平等，因此需要研究其机制并提出缓解方法。

Method: 测试了OpenAI GPT-4o和GPT-4.1模型类中的五个LLMs，通过五种实验条件分析其对用户建议的响应。

Result: 当学生提到错误答案时，LLMs的正确率下降15个百分点；提到正确答案时提升15个百分点。较小模型（如GPT-4.1-nano）的阿谀效应更强（30% vs. GPT-4o的8%）。

Conclusion: LLMs的阿谀行为对教育公平有重要影响，需进一步研究其机制并开发缓解方法。

摘要: 本研究探讨了在模拟教育环境中，用户提供的建议如何影响大型语言模型（LLMs），尤其是阿谀行为带来的风险。测试了OpenAI GPT-4o和GPT-4.1模型类中的五个LLMs，结果显示回答质量因问题表述方式差异显著。当学生提到错误答案时，LLMs的正确率下降15个百分点；提到正确答案时提升15个百分点。较小模型（如GPT-4.1-nano）的阿谀效应更强（30% vs. GPT-4o的8%）。对LLMs“翻转”答案频率及标记级概率的分析证实，模型倾向于根据学生提到的答案调整回答。这种阿谀行为对教育公平有重要影响，可能加速知识丰富学生的学习，同时加深知识不足学生的误解。研究强调需进一步理解其机制并开发缓解方法。

</details>


### [132] [Scheduled Interleaved Speech-Text Training for Speech-to-Speech Translation with LLMs](https://arxiv.org/abs/2506.10299)
**中文标题：基于大语言模型的语音到语音翻译：交替语音-文本训练计划**

*Hayato Futami,Emiru Tsunoo,Yosuke Kashiwagi,Yuki Ito,Hassan Shahmohammadi,Siddhant Arora,Shinji Watanabe*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLMs）的语音到语音翻译（S2ST）方法，通过逐步减少文本比例的交替训练策略，解决了文本到语音模态适应的难题，显著提升了翻译性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语音到语音翻译方法依赖于大语言模型（LLMs），但这些模型主要在文本数据上训练，难以直接适应语音模态。尤其是在语音数据有限的情况下，模态适应成为主要挑战。

Method: 提出了一种交替训练策略，即在训练过程中交替使用语音和文本单元，并在单词级别插入对齐的文本标记。随着训练的进行，逐步减少文本比例，以实现从文本到语音的渐进式模态适应。

Result: 通过在CVSS数据集上对LLaMA3.2-1B模型进行微调，实验表明该方法显著提升了翻译性能，尤其是在训练数据较少的语言上表现突出。

Conclusion: 交替训练策略有效解决了语音到语音翻译中的模态适应问题，为数据受限的语言提供了性能提升的解决方案。

摘要: 语音到语音翻译（S2ST）通过大语言模型（LLMs）取得了进展，这些模型在离散语音单元上进行了微调。然而，从文本到语音的模态适应一直是一个问题。LLMs仅在文本数据上训练，这使其在语音模态上的适应面临挑战，尤其是在语音数据有限的情况下。为了解决这一训练难题，本研究提出了交替语音-文本训练计划。在训练过程中，我们使用交替的语音-文本单元而非单纯的语音单元，并在单词级别插入对齐的文本标记。随着训练的进行，逐步减少文本比例，以实现从文本到语音的渐进式模态适应。我们在CVSS数据集上对LLaMA3.2-1B模型进行微调，实验结果表明，该方法显著提升了翻译性能，尤其是在训练数据较少的语言上表现突出。

</details>


### [133] [Code Execution as Grounded Supervision for LLM Reasoning](https://arxiv.org/abs/2506.10343)
**中文标题：基于代码执行的LLM推理基础监督**

*Dongwon Jung,Wenxuan Zhou,Muhao Chen*

Main category: cs.CL

TL;DR: 本文提出了一种利用代码执行的确定性生成高质量思维链（CoT）监督数据的方法，以提升大语言模型（LLM）的推理能力。该方法通过从代码执行中提取可验证的逐步推理轨迹，并将其转化为自然语言的CoT推理，显著减少了推理过程中的无效重复和过度思考。


<details>
  <summary>Details</summary>
Motivation: 当前，通过思维链（CoT）监督训练大语言模型（LLMs）已被证明能有效提升其推理能力，但获取可靠且准确的推理监督数据仍是一大挑战。现有方法依赖昂贵的人工标注或易出错的LLM生成CoT，亟需一种可扩展且高质量的数据生成方法。

Method: 本文提出了一种基于代码执行确定性的方法，通过从代码执行中提取可验证的逐步推理轨迹，并将其转化为自然语言的CoT推理，从而生成高质量的监督数据集。这种方法避免了人工标注和LLM生成CoT的缺陷。

Result: 实验表明，该方法在多个领域的推理基准测试中有效提升了LLMs的跨任务推理能力。消融研究进一步验证了生成数据的准确性，并减少了推理过程中的无效重复和过度思考，从而降低了推理时的总标记长度。

Conclusion: 本文提出的方法通过代码执行生成高质量的CoT监督数据，显著提升了LLMs的推理能力，同时减少了推理过程中的冗余。这一方法为LLM推理能力的提升提供了一种可扩展且高效的解决方案。

摘要: 通过思维链（CoT）监督训练大语言模型（LLMs）已被证明能有效提升其推理能力。然而，获取可靠且准确的推理监督数据仍是一大挑战。本文提出了一种可扩展的方法，利用程序执行的确定性生成高质量的CoT监督数据集。与现有依赖昂贵人工标注或易出错的LLM生成CoT的方法不同，我们的方法从代码执行中提取可验证的逐步推理轨迹，并将其转化为自然语言的CoT推理。在多个领域的推理基准测试中，实验表明该方法有效提升了LLMs的跨任务推理能力。此外，消融研究验证了该方法生成的数据具有高度准确性，并通过减少无效重复和过度思考，降低了推理时的总标记长度。

</details>


### [134] [TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous Document Reasoning](https://arxiv.org/abs/2506.10380)
**中文标题：TableRAG：一种面向异构文档推理的检索增强生成框架**

*Xiaohan Yu,Pu Jian,Chong Chen*

Main category: cs.CL

TL;DR: TableRAG是一个针对异构文档（包含文本和表格）的检索增强生成框架，通过结合文本检索和SQL编程，解决了现有方法在表格结构破坏和信息丢失上的问题，并在新基准HeteQA上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在处理异构文档（文本和表格混合）时存在局限性，尤其是表格结构被破坏和信息丢失的问题，影响了多跳和全局查询的推理能力。

Method: TableRAG提出了一种混合框架，通过四步迭代操作：上下文敏感的查询分解、文本检索、SQL编程与执行、以及组合式中间答案生成，统一了文本理解和表格数据的复杂操作。

Result: 实验结果表明，TableRAG在公共数据集和新开发的HeteQA基准上均优于现有基线，为异构文档问答设立了新的技术标杆。

Conclusion: TableRAG通过结合文本和表格数据的处理能力，显著提升了异构文档的推理性能，为未来研究提供了重要参考。

摘要: 检索增强生成（RAG）在开放领域问答中表现出显著效果。然而，当应用于包含文本和表格组件的异构文档时，现有RAG方法存在关键局限性。当前将表格扁平化和分块的策略破坏了表格的固有结构，导致信息丢失，并削弱了大型语言模型在多跳和全局查询中的推理能力。为解决这些问题，我们提出了TableRAG，这是一种混合框架，统一了文本理解和表格数据的复杂操作。TableRAG通过四步迭代操作：上下文敏感的查询分解、文本检索、SQL编程与执行以及组合式中间答案生成。我们还开发了HeteQA，一个用于评估多跳异构推理能力的新基准。实验结果表明，TableRAG在公共数据集和我们的HeteQA上均优于现有基线，为异构文档问答设立了新的技术标杆。TableRAG已在https://github.com/yxh-y/TableRAG/tree/main发布。

</details>


### [135] [PAG: Multi-Turn Reinforced LLM Self-Correction with Policy as Generative Verifier](https://arxiv.org/abs/2506.10406)
**中文标题：PAG：基于生成验证策略的多轮强化LLM自我纠正**

*Yuhua Jiang,Yuwen Xiong,Yufeng Yuan,Chao Xin,Wenyuan Xu,Yu Yue,Qianchuan Zhao,Lin Yan*

Main category: cs.CL

TL;DR: 本文提出了一种名为PAG的框架，通过多轮强化学习让大语言模型（LLM）在生成和验证角色间切换，实现自我纠正，提升推理和验证能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务中表现优异，但其自我验证能力不足。现有方法依赖外部验证器或多阶段训练，限制了可扩展性。

Method: PAG框架通过多轮强化学习，让模型在生成和验证角色间切换，并引入选择性修订机制：仅在检测到错误时修订答案。

Result: 实验表明，PAG在推理和验证能力上均有提升，作为策略提高了生成和自我纠正的准确性，作为验证器其自我验证优于自一致性方法。

Conclusion: PAG通过统一的强化学习框架，有效提升了LLM的自我纠正能力，同时增强了推理和验证性能。

摘要: 大语言模型（LLM）在复杂推理任务中展现了强大的能力，但其对自身输出的正确性验证仍不可靠。现有的验证方法通常依赖于独立的验证器模型或多阶段自我纠正训练流程，限制了可扩展性。本文提出了一种名为“生成验证策略”（PAG）的简单有效框架，通过多轮强化学习（RL）范式，让LLM在生成和验证角色间交替切换以实现自我纠正。与以往方法不同，PAG引入了选择性修订机制：模型仅在自身生成验证步骤检测到错误时修订答案。这种“验证-修订”流程不仅缓解了模型崩溃问题，还同时提升了推理和验证能力。在多个推理基准上的广泛实验表明，PAG在两方面均取得进步：作为策略，它提高了直接生成和自我纠正的准确性；作为验证器，其自我验证性能优于自一致性方法。

</details>


### [136] [Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?](https://arxiv.org/abs/2506.10415)
**中文标题：阅后即焚：多模态大语言模型是否真正捕捉了图像序列中的事件顺序？**

*Yingjin Song,Yupei Du,Denis Paperno,Albert Gatt*

Main category: cs.CL

TL;DR: 本文提出了TempVS基准，用于评估多模态大语言模型（MLLMs）在图像序列中事件顺序理解的能力。实验表明，现有模型在TempVS上表现不佳，与人类能力存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）在图像序列中事件顺序的理解能力尚未得到充分研究，本文旨在填补这一空白。

Method: 设计了TempVS基准，包含事件关系推理、句子排序和图像排序三个主要测试，并辅以基础定位测试，要求模型结合视觉和语言模态理解事件顺序。

Result: 评估了38个先进MLLMs，发现它们在TempVS上表现较差，与人类能力存在显著差距。同时提供了细粒度分析，为未来研究指明方向。

Conclusion: TempVS揭示了MLLMs在事件顺序理解上的不足，为未来改进提供了基准和方向。

摘要: 本文介绍了TempVS基准，专注于评估多模态大语言模型（MLLMs）在图像序列中的时间定位和推理能力。TempVS包含三个主要测试（即事件关系推理、句子排序和图像排序），每个测试均配有基础定位测试。TempVS要求MLLMs结合视觉和语言模态来理解事件的时间顺序。我们评估了38个先进的MLLMs，结果表明这些模型在解决TempVS任务时表现不佳，与人类能力存在显著差距。我们还提供了细粒度的分析，为未来研究指明了方向。TempVS基准数据和代码可在https://github.com/yjsong22/TempVS获取。

</details>


### [137] [Beyond the Battlefield: Framing Analysis of Media Coverage in Conflict Reporting](https://arxiv.org/abs/2506.10421)
**中文标题：超越战场：冲突报道中媒体框架的分析**

*Avneet Kaur,Arnav Arora*

Main category: cs.CL

TL;DR: 新闻媒体在冲突报道中的框架分析揭示了战争与和平报道的差异，并展示了不同地区媒体的偏见。


<details>
  <summary>Details</summary>
Motivation: 现有关于冲突框架的研究多为定性或浅层次分析，缺乏深入探讨。本研究旨在通过计算语言学方法，揭示新闻报道中的战争与和平框架及其对读者观点的影响。

Method: 使用计算语言学方法（框架语义学和大语言模型）分析以色列-巴勒斯坦战争新闻语料库，识别战争与和平新闻的指标。

Result: 研究发现新闻报道更倾向于战争框架，且美国、英国和中东媒体在冲突角色（攻击者与受害者）的报道中存在显著差异，揭示了媒体偏见。

Conclusion: 新闻媒体的框架选择对冲突报道有重要影响，不同地区的媒体存在明显偏见，需进一步研究以促进和平报道。

摘要: 新闻媒体在冲突时期使用的框架对读者观点有重大影响，可能加剧冲突本身。目前关于冲突框架的研究因定性或浅层次分析而缺乏深入见解。本研究基于冲突研究的先前工作，在以色列-巴勒斯坦战争新闻报道语料库中识别战争与和平新闻的指标。我们采用计算语言学方法，结合框架语义学和大语言模型，分析传播框架及其与语言框架的联系。分析显示，新闻报道更倾向于战争框架而非和平框架。同时，美国、英国和中东媒体在冲突角色（攻击者与受害者）的报道中存在显著差异，揭示了媒体偏见。

</details>


### [138] [Fast on the Easy, Deep on the Hard: Efficient Reasoning via Powered Length Penalty](https://arxiv.org/abs/2506.10446)
**中文标题：快处理简单，深处理困难：通过动态长度惩罚实现高效推理**

*Zehui Ling,Deshu Chen,Hongwei Zhang,Yifeng Jiao,Xin Guo,Yuan Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种通过动态调整输出长度惩罚来优化大语言模型推理效率的方法，针对简单问题缩短输出，复杂问题保留足够推理，从而提升整体性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推理任务中表现优异，但现有方法如思维链提示会生成较长输出，增加计算延迟。现有缩短输出的方法未考虑问题复杂度，导致效果不佳。本文旨在通过动态调整输出长度惩罚，提升推理效率。

Method: 通过分割奖励函数并引入新的输出长度惩罚机制，动态调整简单问题和复杂问题的输出长度，以优化推理效率。

Result: 在GSM8K、MATH500和AIME2024三个基准测试中，方法显著缩短了简单问题的输出长度并保持或提升准确性，同时在复杂问题中提高了准确性。

Conclusion: 动态调整输出长度惩罚的方法有效提升了大语言模型的推理效率，兼顾了简单问题的简洁性和复杂问题的准确性。

摘要: 大语言模型（LLM）在推理能力上取得了显著进展，在各种挑战性基准测试中表现优异。思维链提示等技术被引入以进一步提升推理能力，但这些方法通常生成长输出，增加了计算延迟。尽管一些方法使用强化学习来缩短推理，但它们往往采用统一的惩罚机制，未考虑问题复杂度，导致效果不佳。本研究旨在通过促进简单问题的简洁性，同时为复杂问题保留足够的推理以保持准确性，从而提升LLM推理效率。具体而言，我们通过分割奖励函数并引入新的输出长度惩罚机制来管理模型的推理效率。我们的方法在GSM8K、MATH500和AIME2024三个基准测试中取得了显著成果。对于相对简单的数据集GSM8K和MATH500，我们的方法有效缩短了输出长度，同时保持或提升了准确性。在更具挑战性的AIME2024数据集中，我们的方法提高了准确性。

</details>


### [139] [Table-Text Alignment: Explaining Claim Verification Against Tables in Scientific Papers](https://arxiv.org/abs/2506.10486)
**中文标题：表格-文本对齐：解释科学论文中表格对主张的验证**

*Xanh Ho,Sunisth Kumar,Yun-Ang Wu,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

TL;DR: 本文提出将表格-文本对齐任务重新定义为解释任务，要求模型识别用于验证科学主张的关键表格单元格，并通过扩展SciTab基准数据集和引入人类标注的单元格级理由，提升模型的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 科学主张验证通常仅预测支持或反驳的标签，缺乏对模型推理的解释性。本文旨在通过识别关键表格单元格，增强模型的可解释性和验证性能。

Method: 扩展SciTab数据集，加入人类标注的单元格级理由，并提出处理模糊情况的分类法。实验评估了结合表格对齐信息对主张验证性能的影响，并分析了大型语言模型在恢复人类对齐理由方面的表现。

Result: 实验表明：(i) 结合表格对齐信息可提升主张验证性能；(ii) 多数大型语言模型虽能预测正确标签，但无法恢复人类对齐理由，表明其预测缺乏忠实推理。

Conclusion: 将表格-文本对齐任务重新定义为解释任务，可提升模型的可解释性和性能，但当前大型语言模型在忠实推理方面仍有不足。

摘要: 科学主张验证通常需要根据表格预测主张是否被支持或反驳。然而，仅预测最终标签是不够的：它无法揭示模型的推理过程，且解释性有限。为此，我们将表格-文本对齐重新定义为解释任务，要求模型识别用于验证主张的关键表格单元格。我们通过扩展SciTab基准数据集，加入人类标注的单元格级理由，构建了新数据集。标注者验证主张标签并高亮支持其决策的最小单元格集合。标注完成后，我们利用收集的信息提出处理模糊情况的分类法。实验表明：(i) 结合表格对齐信息可提升主张验证性能；(ii) 多数大型语言模型虽能预测正确标签，但无法恢复人类对齐理由，表明其预测缺乏忠实推理。

</details>


### [140] [Surface Fairness, Deep Bias: A Comparative Study of Bias in Language Models](https://arxiv.org/abs/2506.10491)
**中文标题：表面公平，深层偏见：语言模型中偏见的比较研究**

*Aleksandra Sorokovikova,Pavel Chizhov,Iuliia Eremenko,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在表面公平性下隐藏深层偏见，尤其是在用户互动和特定任务（如薪资谈判建议）中表现明显。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型训练数据中不可避免地包含偏见内容，导致模型输出带有性别、种族、年龄等偏见。本文旨在探究这些偏见的表现形式及其影响。

Method: 通过多学科基准测试（MMLU）和任务重构（如模型对用户回答评分和提供薪资谈判建议）来评估LLMs的偏见。

Result: 模型在预提示人格测试中表现差异微小且随机，但在用户互动和薪资谈判建议任务中显示出显著偏见。

Conclusion: 随着LLM助手记忆和个性化功能的发展，模型对用户社会人口特征的了解可能加剧偏见问题，需进一步研究和解决。

摘要: 现代语言模型通过大量数据进行训练，这些数据不可避免地包含争议性和刻板印象内容，涉及性别、种族、年龄等多种偏见。因此，模型会表达带有偏见的观点，或根据用户或预设人格输出不同结果。本文研究了大型语言模型（LLMs）中偏见的多种代理指标。我们发现，在多学科基准测试（MMLU）中，通过预提示人格评估模型时，得分差异微小且多为随机。然而，若重构任务，要求模型对用户回答评分，则显示出更显著的偏见迹象。最后，在要求模型提供薪资谈判建议时，答案中表现出明显的偏见。随着LLM助手记忆和个性化功能的兴起，这些问题从新角度浮现：现代LLM用户无需预提示人格描述，因为模型已了解其社会人口特征。

</details>


### [141] [Beyond Single-User Dialogue: Assessing Multi-User Dialogue State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2506.10504)
**中文标题：超越单用户对话：评估大语言模型在多用户对话状态跟踪中的能力**

*Sangmin Song,Juhwan Choi,JungMin Yun,YoungBin Kim*

Main category: cs.CL

TL;DR: 本文评估了大语言模型（LLMs）在多用户对话状态跟踪（DST）中的表现，发现其在多用户场景下性能显著下降，突显了现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统DST基准主要关注结构化用户-代理对话，未能捕捉真实世界中多用户交互的复杂性。本文旨在评估LLMs在多用户DST中的鲁棒性，同时降低数据集构建成本。

Method: 基于言语行为理论，通过生成第二个用户的语句扩展现有DST数据集，系统地将多用户对话纳入评估框架，以控制方式测试LLMs在多用户环境中的表现。

Result: 实验结果表明，与单用户DST相比，LLMs在多用户DST中的性能显著下降，表明其在多说话者环境中提取和跟踪对话状态的能力有限。

Conclusion: 研究强调了未来需增强LLMs在多用户DST场景中的能力，为开发更真实和鲁棒的DST模型铺平道路。

摘要: 大语言模型（LLMs）在零样本对话状态跟踪（DST）中表现出色，减少了对任务特定训练的需求。然而，传统的DST基准主要关注结构化用户-代理对话，未能捕捉真实世界中多用户交互的复杂性。本研究评估了LLMs在多用户DST中的鲁棒性，同时最小化数据集构建成本。受近期基于LLM的数据标注进展启发，我们通过言语行为理论生成第二个用户的语句，扩展了现有DST数据集。我们的方法系统地将第二个用户的语句纳入对话中，实现了对LLMs在多用户环境中的受控评估。实验结果显示，与单用户DST相比，性能显著下降，突显了当前LLMs在多个说话者中提取和跟踪对话状态的局限性。我们的发现强调了未来研究需增强LLMs在多用户DST场景中的能力，为更真实和鲁棒的DST模型铺平道路。

</details>


### [142] [Reliable Reasoning Path: Distilling Effective Guidance for LLM Reasoning with Knowledge Graphs](https://arxiv.org/abs/2506.10508)
**中文标题：可靠推理路径：利用知识图谱为LLM推理提炼有效指导**

*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Bo Li,Qing Li,Xiao Huang*

Main category: cs.CL

TL;DR: 论文提出RRP框架，通过结合知识图谱和LLM的语义优势，生成高质量推理路径，提升LLM在复杂问题中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在知识密集型任务中常因缺乏背景知识或产生幻觉而表现不佳。现有方法虽结合知识图谱（KG）补充事实知识，但仍难以解决复杂问题。论文认为，提炼事实间关系并组织为逻辑一致的推理路径同样重要。

Method: 提出RRP框架，结合LLM的语义能力和关系嵌入与双向分布学习的结构信息，挖掘知识图谱中的推理路径，并引入反思模块评估路径重要性。

Result: 在两个公开数据集上的实验表明，RRP优于现有基线方法，且能以即插即用方式增强多种LLM的推理能力。

Conclusion: RRP通过生成针对特定问题的高质量推理路径，为LLM推理提供有效指导，显著提升其性能。

摘要: 大型语言模型（LLM）在知识密集型任务中常因缺乏背景知识或产生幻觉而表现不佳。为解决这些限制，将知识图谱（KG）与LLM结合的研究日益增多。现有KG增强的LLM侧重于补充事实知识，但仍难以解决复杂问题。我们认为，提炼事实间关系并将其组织为逻辑一致的推理路径与事实知识本身同样重要。尽管潜力巨大，从KG中提取可靠推理路径仍面临以下挑战：图结构的复杂性及生成路径的多样性，使得难以区分有用与冗余路径。为应对这些挑战，我们提出RRP框架挖掘知识图谱，结合LLM的语义优势与通过关系嵌入和双向分布学习获得的结构信息。此外，我们引入反思模块，根据重要性评估并优化推理路径。在两个公开数据集上的实验表明，RRP优于现有基线方法。此外，RRP能以即插即用方式轻松集成到多种LLM中，增强其推理能力。通过生成针对特定问题的高质量推理路径，RRP为LLM推理提炼了有效指导。

</details>


### [143] [Unsupervised Protoform Reconstruction through Parsimonious Rule-guided Heuristics and Evolutionary Search](https://arxiv.org/abs/2506.10614)
**中文标题：通过简约规则启发式与进化搜索的无监督原型词形重建**

*Promise Dodzi Kpoglu*

Main category: cs.CL

TL;DR: 本文提出了一种无监督的原型词形重建方法，结合数据驱动推理和基于规则的启发式方法，通过进化优化框架显著提升了重建的准确性和语音合理性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖音位编辑的概率模型从同源词集中推断原型词形，但其数据驱动的特性限制了性能。本文旨在通过结合统计模式和语言学约束，提出一种更有效的重建方法。

Method: 本文提出了一种混合方法，将数据驱动推理与基于规则的启发式方法结合，并嵌入进化优化框架中，利用统计模式和语言学约束指导重建过程。

Result: 在从五种罗曼语同源词重建拉丁语原型词形的任务中，实验结果表明，该方法在字符级准确性和语音合理性指标上显著优于现有基线方法。

Conclusion: 本文提出的混合方法通过结合数据驱动和规则启发式，显著提升了原型词形重建的性能，为语言学研究和计算语言学提供了新工具。

摘要: 我们提出了一种无监督的原型词形重建方法，原型词形是现代语言形式的祖先词形。现有工作主要依赖音位编辑的概率模型从同源词集中推断原型词形，但这类方法因其数据驱动的特性而受限。相比之下，我们的模型在进化优化框架中结合了数据驱动推理和基于规则的启发式方法。这种混合方法利用统计模式和语言学约束共同指导重建过程。我们在从五种罗曼语同源词重建拉丁语原型词形的任务上评估了该方法。实验结果表明，该方法在字符级准确性和语音合理性指标上均显著优于现有基线方法。

</details>


### [144] [Tina: Tiny Reasoning Models via LoRA](https://arxiv.org/abs/2504.15777)
**中文标题：Tina：通过LoRA实现的微型推理模型**

*Shangshang Wang,Julian Asilis,Ömer Faruk Akgül,Enes Burak Bilgin,Ollie Liu,Willie Neiswanger*

Main category: cs.CL

TL;DR: Tina是一种通过低秩适应（LoRA）实现的微型推理模型家族，仅需极低成本即可达到与现有SOTA模型竞争甚至超越的性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何以低成本高效地实现语言模型的强大推理能力。

Method: 在强化学习（RL）过程中，对仅1.5B参数的微型基础模型应用参数高效的LoRA更新。

Result: Tina模型在推理性能上表现优异，甚至超越某些SOTA模型，同时计算成本极低（仅9美元）。

Conclusion: LoRA通过快速适应推理结构并保留基础模型知识，实现了高效且低成本的推理能力提升。

摘要: 如何以高性价比实现语言模型的强大推理能力？基于这一核心问题，我们提出了Tina，一种通过低成本高效方式实现的微型推理模型家族。值得注意的是，Tina表明，仅需极少的资源，即可通过参数高效的更新（如低秩适应LoRA）在强化学习（RL）中对一个仅1.5B参数的微型基础模型进行优化，从而开发出显著的推理性能。这种极简方法产生的模型在推理性能上与基于同一基础模型构建的SOTA RL推理模型相当，有时甚至超越。关键的是，这一成果仅需现有SOTA模型计算成本的一小部分。实际上，最佳Tina模型在AIME24上实现了超过20%的推理性能提升和43.33%的Pass@1准确率，而训练和评估成本仅为9美元（即估计成本降低了260倍）。我们的研究揭示了通过LoRA实现高效RL推理的惊人效果，并在多个开源推理数据集和多种消融设置中验证了这一结论。此外，我们假设这种高效性源于LoRA能够快速适应RL奖励的推理结构格式，同时基本保留基础模型的底层知识。为了促进可访问性和开放研究，我们完全开源了所有代码、训练日志以及模型权重和检查点。

</details>


### [145] [SDialog: A Python Toolkit for Synthetic Dialogue Generation and Analysis](https://arxiv.org/abs/2506.10622)
**中文标题：SDialog：用于合成对话生成和分析的Python工具包**

*Sergio Burdisso,Esaú Villatoro-Tello,Petr Motlicek*

Main category: cs.CL

TL;DR: SDialog是一个用于合成对话生成和分析的Python工具包，旨在为对话AI系统提供高质量、灵活且可复现的训练和评估数据。


<details>
  <summary>Details</summary>
Motivation: 对话AI系统的进步依赖于高质量、灵活且可复现的合成对话数据，但目前缺乏标准化工具。SDialog旨在填补这一空白。

Method: SDialog利用指令调优的大型语言模型（LLMs），提供人物角色、编排和场景管理的抽象，支持多智能体模拟和场景驱动的生成。

Result: SDialog能够生成真实、多样且可控的对话数据，为研究和开发提供了标准化工具，提升了合成数据生成的复现性。

Conclusion: SDialog为合成对话数据的生成和分析提供了模块化、可扩展的解决方案，推动了对话AI研究的标准化和复现性。

摘要: 对话AI系统的进步依赖于高质量、灵活且可复现的合成对话数据，用于训练、评估和基准测试。SDialog是一个模块化、可扩展的Python工具包，旨在解决合成对话生成和分析的挑战。通过利用指令调优的大型语言模型（LLMs），SDialog提供了人物角色、编排和场景管理的抽象，能够为研究和开发生成真实、多样且可控的对话数据。SDialog支持多智能体模拟和场景驱动的生成等工作流，代表了合成数据生成工具和框架标准化的重要进展，为当今快速发展的研究环境中的复现性提供了关键支持。

</details>


### [146] [Resa: Transparent Reasoning Models via SAEs](https://arxiv.org/abs/2506.09967)
**中文标题：Resa：基于稀疏自编码器的透明推理模型**

*Shangshang Wang,Julian Asilis,Ömer Faruk Akgül,Enes Burak Bilgin,Ollie Liu,Deqing Fu,Willie Neiswanger*

Main category: cs.CL

TL;DR: Resa是一种通过稀疏自编码器调优（SAE-Tuning）方法训练的高效推理模型家族，能以极低成本（约1美元）和短时间（约20分钟）实现接近RL训练模型的推理性能，并展示出通用性和模块化特性。


<details>
  <summary>Details</summary>
Motivation: 研究如何高效且低成本地从语言模型中提取和增强推理能力，以解决传统强化学习（RL）训练方法的高成本和耗时问题。

Method: 提出SAE-Tuning方法：先训练稀疏自编码器（SAE）从源模型中提取推理能力，再用SAE指导目标模型的监督微调，仅需问答数据而无需推理轨迹。

Result: SAE-Tuning在成本降低2000倍（约1美元）和时间缩短450倍（约20分钟）的情况下，保留了RL训练模型97%以上的推理性能；在轻量RL训练模型上，能以极低成本显著提升推理能力（如AIME24上43.33% Pass@1）。

Conclusion: SAE-Tuning是一种高效、低成本且通用的推理能力提取方法，其模块化特性支持跨模型的能力移植，为语言模型推理能力的开发提供了新方向。

摘要: 如何通过利用语言模型的底层表征高效且低成本地激发其强大的推理能力？我们通过Resa家族（1.5B推理模型）和一种新颖高效的稀疏自编码器调优（SAE-Tuning）方法回答了这一问题。该方法首先训练稀疏自编码器（SAE）从源模型中捕获推理能力，然后利用训练好的SAE指导目标模型的监督微调过程，仅需已验证的问答数据而无需推理轨迹。值得注意的是，当应用于某些基础模型并在进一步RL后训练之前，SAE-Tuning能以约1美元的成本（降低2000倍）和约20分钟的时间（缩短450倍）保留其RL训练对应模型97%以上的推理性能。此外，当应用于轻量RL训练模型（例如在2个GPU上训练1小时内），仅需约1美元的额外成本即可实现显著的推理性能提升（如AIME24上43.33% Pass@1，AMC23上90% Pass@1）。令人惊讶的是，通过SAE提取的推理能力可能具有通用性和模块化特性。通用性意味着从一个数据集中提取的能力仍可提升更大且重叠语料库的性能；模块化意味着从Qwen或Qwen-Math提取的能力可以在测试时直接附加到R1-Distill模型上，无需重新训练即可获得相当的提升。大量消融实验验证了这些发现，所有成果均已开源。

</details>


### [147] [NeuralNexus at BEA 2025 Shared Task: Retrieval-Augmented Prompting for Mistake Identification in AI Tutors](https://arxiv.org/abs/2506.10627)
**中文标题：NeuralNexus在BEA 2025共享任务中的应用：基于检索增强提示的AI导师错误识别**

*Numaan Naeem,Sarfraz Ahmad,Momina Ahsan,Hasan Iqbal*

Main category: cs.CL

TL;DR: 本文介绍了在BEA 2025共享任务中用于错误识别的系统，结合了检索增强提示和大型语言模型（GPT 4o），性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估AI导师是否能正确识别学生在数学推理中的错误，为教育反馈提供技术支持。

Method: 探索了四种方法：1) 多预训练语言模型的集成模型；2) 冻结的句子转换器与MLP分类器；3) 历史感知的多头注意力模型；4) 检索增强的少样本提示系统（GPT 4o）。最终系统结合检索示例和结构化提示。

Result: 最终系统性能优于所有基线方法，证明了检索增强提示与LLM推理结合的有效性。

Conclusion: 结合示例驱动的提示和LLM推理，能够有效提升教育反馈评估的准确性。

摘要: 本文介绍了我们在BEA 2025共享任务中针对AI导师教学能力评估的Track 1：错误识别的系统。该任务旨在评估导师是否能正确识别学生在数学推理中的错误。我们探索了四种方法：1) 基于多预训练语言模型（LMs）的集成模型；2) 使用[CLS]嵌入和MLP分类器的冻结句子转换器；3) 具有多头注意力的历史感知模型；4) 基于大型语言模型（LLM，如GPT 4o）的检索增强少样本提示系统。最终系统通过检索语义相似的示例、构建结构化提示，并结合模式引导的输出解析生成可解释的预测。其性能优于所有基线方法，证明了示例驱动提示与LLM推理结合在教育反馈评估中的有效性。代码已开源：https://github.com/NaumanNaeem/BEA_2025。

</details>


### [148] [Spelling-out is not Straightforward: LLMs' Capability of Tokenization from Token to Characters](https://arxiv.org/abs/2506.10641)
**中文标题：拼写并非直观：从词元到字符的大型语言模型分词能力**

*Tatsuya Hiraoka,Kentaro Inui*

Main category: cs.CL

TL;DR: 研究发现，尽管大型语言模型（LLMs）能逐字符拼写单词，但在处理复杂字符级任务时表现不佳。模型主要依赖中间和高层Transformer层重建字符级信息，而非嵌入层。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在拼写过程中如何内部表示和利用字符级信息，以解释其在简单拼写任务中的高准确率与复杂字符级任务中的表现差异。

Method: 通过三种互补分析验证机制：探测分类器、知识神经元识别和注意力权重检查。

Result: 嵌入层未完全编码字符级信息（尤其是首字符之后），LLMs依赖中间和高层Transformer层重建字符级知识，拼写行为在这些层出现显著突破。

Conclusion: 拼写任务对LLMs并非直观处理，其字符级能力依赖于模型深层结构，而非浅层嵌入。

摘要: 大型语言模型（LLMs）能够以高准确率逐字符拼写词元，但在更复杂的字符级任务（如识别词元内的组合子成分）中表现不佳。本研究探讨了LLMs在拼写过程中如何内部表示和利用字符级信息。分析表明，尽管拼写对人类是简单任务，但LLMs并未以直观方式处理。具体而言，嵌入层未完全编码字符级信息（尤其是首字符之后），LLMs依赖中间和高层Transformer层重建字符级知识，拼写行为在这些层出现显著突破。我们通过三种互补分析验证了这一机制：探测分类器、知识神经元识别和注意力权重检查。

</details>


### [149] [Large Language Models for Detection of Life-Threatening Texts](https://arxiv.org/abs/2506.10687)
**中文标题：利用大语言模型检测威胁生命文本**

*Thanh Thi Nguyen,Campbell Wilson,Janis Dalins*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLMs）检测威胁生命文本的有效方法，并比较了其与传统方法的性能。实验表明，LLMs在平衡和不平衡数据场景下表现优异，尤其是Mistral和Llama-2模型。


<details>
  <summary>Details</summary>
Motivation: 检测威胁生命的语言对于保护处于困境中的个体、促进心理健康以及预防潜在伤害至关重要。传统方法在此任务上存在局限性，因此需要探索更有效的方法。

Method: 研究对三种开源大语言模型（Gemma、Mistral和Llama-2）进行了微调，并在不同数据集（平衡、不平衡和极端不平衡）上进行了测试。同时，对比了传统方法（如词袋模型、词嵌入、主题建模和BERT）。

Result: 实验结果显示，LLMs在检测威胁生命文本方面显著优于传统方法，其中Mistral和Llama-2表现最佳。上采样技术对传统方法有帮助，但对LLMs影响较小。

Conclusion: 研究表明，大语言模型在现实世界的威胁生命语言检测问题中具有巨大潜力，尤其是在数据不平衡的情况下仍能保持高性能。

摘要: 检测威胁生命的语言对于保护处于困境中的个体、促进心理健康以及预防潜在伤害至关重要。本文提出了一种利用大语言模型（LLMs）检测威胁生命文本的有效方法，并将其与传统方法（如词袋模型、词嵌入、主题建模和BERT）进行了比较。我们对三种开源LLMs（Gemma、Mistral和Llama-2）的7B参数版本进行了微调，并在不同数据集（平衡、不平衡和极端不平衡）上进行了测试。实验结果表明，LLMs在性能上显著优于传统方法，尤其是Mistral和Llama-2模型在平衡和不平衡数据场景下表现最佳。上采样技术对传统方法有帮助，但对LLMs影响较小。本研究展示了LLMs在现实世界威胁生命语言检测问题中的巨大潜力。

</details>


### [150] [Inferring Adjective Hypernyms with Language Models to Increase the Connectivity of Open English Wordnet](https://arxiv.org/abs/2506.10715)
**中文标题：利用语言模型推断形容词上位词以提升开放英语词网的连接性**

*Lorenzo Augello,John P. McCrae*

Main category: cs.CL

TL;DR: 本文探讨如何通过语言模型推断形容词的上位词，以提升开放英语词网的连接性，并开发了一种新的形容词上位词资源。


<details>
  <summary>Details</summary>
Motivation: 开放英语词网是语言链接开放数据云中的关键资源，但存在许多缺失链接，尤其是形容词的上位词关系。本文旨在填补这一空白。

Method: 通过理论讨论形容词上位词关系的特点，开发新的形容词上位词资源，并微调大型语言模型（如TaxoLLaMa）来预测形容词上位词。

Result: 成功开发了形容词上位词资源，并证明TaxoLLaMa方法适用于此任务。

Conclusion: 本文为形容词上位词关系的研究提供了新资源和方法，增强了开放英语词网的连接性。

摘要: 开放英语词网是语言链接开放数据云中发布的关键资源，但该资源中存在许多缺失链接。本文探讨如何建立形容词之间的上位词关系。我们首先对形容词上位词关系进行了理论讨论，并指出其与名词和动词的不同之处。随后，我们开发了一种新的形容词上位词资源，并微调大型语言模型以预测形容词上位词，结果表明TaxoLLaMa的方法可适用于此任务。

</details>


### [151] [PREMISE: Scalable and Strategic Prompt Optimization for Efficient Mathematical Reasoning in Large Models](https://arxiv.org/abs/2506.10716)
**中文标题：PREMISE：面向高效数学推理的可扩展和战略性提示优化框架**

*Ye Yu,Yaoning Yu,Haohan Wang*

Main category: cs.CL

TL;DR: PREMISE是一种无需修改模型权重的提示优化框架，通过减少冗余推理步骤，显著降低大型推理模型的令牌使用和成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（如Claude 3.7 Sonnet和OpenAI o1）在数学推理任务中表现优异，但其冗长的推理过程导致令牌使用和成本过高，限制了在延迟敏感或API受限场景中的应用。

Method: PREMISE结合轨迹级诊断和梯度启发的提示优化，通过多目标文本搜索平衡令牌长度和答案有效性，减少冗余计算。

Result: 在GSM8K、SVAMP和Math500数据集上，PREMISE在保持或提升基线准确率（Claude从96%到96%，Gemini从91%到92%）的同时，减少了高达87.5%的推理令牌使用，并降低了69%-82%的成本。

Conclusion: PREMISE证明提示级优化是一种实用且可扩展的方法，可在不牺牲推理质量的前提下提升大型推理模型的效率。

摘要: 大型推理模型（如Claude 3.7 Sonnet和OpenAI o1）在数学基准测试中通过冗长的链式推理（CoT）表现出色，但由此产生的推理轨迹往往过于冗长。这不仅增加了令牌使用和成本，还限制了在延迟敏感或API受限场景中的部署。我们提出了PREMISE（基于提示的高效数学推理与战略评估），这是一种无需修改模型权重的纯提示框架，旨在减少推理开销。PREMISE结合轨迹级诊断和梯度启发的提示优化，通过多目标文本搜索平衡令牌长度和答案有效性，从而最小化冗余计算。与之前的工作不同，PREMISE在单次黑盒接口中运行，可直接应用于商业大语言模型。在GSM8K、SVAMP和Math500数据集上，PREMISE在保持或提升基线准确率（Claude从96%到96%，Gemini从91%到92%）的同时，减少了高达87.5%的推理令牌使用，并降低了69%-82%的成本。这些结果表明，提示级优化是一种实用且可扩展的方法，可在不牺牲推理质量的前提下提升大型推理模型的效率。

</details>


### [152] [Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims](https://arxiv.org/abs/2506.10728)
**中文标题：超越真与假：基于检索增强的复杂主张层次分析**

*Priyanka Kargupta,Runchu Tian,Jiawei Han*

Main category: cs.CL

TL;DR: 本文提出ClaimSpect框架，通过检索增强的生成方法，自动构建针对复杂主张的多层次分析，揭示其子方面和相关观点。


<details>
  <summary>Details</summary>
Motivation: 现实中的主张（如科学或政治主张）往往难以简单归类为“真”或“假”，需要更细致的分析。本文旨在通过结构化方法分解主张，提供更全面的视角。

Method: 提出ClaimSpect框架，利用检索增强生成技术，自动构建主张的层次结构，并通过语料库检索相关片段，揭示子方面和不同观点。

Result: 在真实科学和政治主张数据集上验证了ClaimSpect的鲁棒性和准确性，能够有效分解主张并展示语料库中的观点分布。

Conclusion: ClaimSpect框架在复杂主张分析中表现优于基线方法，为多角度理解主张提供了有效工具。

摘要: 个体或实体提出的主张往往具有复杂性，无法简单地归类为完全“真实”或“虚假”——这在科学和政治主张中尤为常见。然而，一个主张（例如“疫苗A优于疫苗B”）可以分解为其核心方面和子方面（例如有效性、安全性、分发），这些方面更容易单独验证。这提供了一种更全面、结构化的回应方式，既为问题提供了多角度的视角，又允许读者优先关注主张中的特定角度（例如对儿童的安全性）。为此，我们提出了ClaimSpect，一种基于检索增强生成的框架，用于自动构建处理主张时通常考虑的层次结构，并通过语料库特有的视角丰富这些结构。该框架通过层次化划分输入语料库来检索相关片段，从而帮助发现新的子方面。此外，这些片段还能揭示对主张某一方面的不同观点（例如支持、中立或反对）及其普遍性（例如“有多少生物医学论文认为疫苗A比B更具运输性？”）。我们将ClaimSpect应用于构建的数据集中的各种真实科学和政治主张，展示了其在分解复杂主张和表示语料库中观点方面的鲁棒性和准确性。通过真实案例研究和人工评估，我们验证了其相对于多个基线方法的有效性。

</details>


### [153] [TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora](https://arxiv.org/abs/2506.10737)
**中文标题：TaxoAdapt：将基于 LLM 的多维分类构建与演化研究语料库对齐**

*Priyanka Kargupta,Nan Zhang,Yunyi Zhang,Rui Zhang,Prasenjit Mitra,Jiawei Han*

Main category: cs.CL

TL;DR: TaxoAdapt 是一种动态调整 LLM 生成的多维分类框架，能够适应不断演化的科学文献，提升分类的粒度和连贯性。


<details>
  <summary>Details</summary>
Motivation: 科学领域的快速演化使得文献组织和检索变得困难。传统专家分类耗时昂贵，而现有自动分类方法要么依赖特定语料库牺牲通用性，要么过度依赖 LLM 的预训练知识，忽视科学领域的动态性和多维性。

Method: TaxoAdapt 通过迭代层次分类，根据语料主题分布动态扩展分类的宽度和深度，生成多维分类。

Result: TaxoAdapt 在计算机科学会议数据集上表现优异，生成的分类比基线方法粒度保留度高 26.51%，连贯性高 50.41%。

Conclusion: TaxoAdapt 能够有效捕捉科学领域的动态演化，生成更精细和连贯的多维分类，为文献组织和检索提供了新方法。

摘要: 科学领域的快速演变为文献组织和检索带来了挑战。传统专家分类方法耗时昂贵，而现有自动分类方法要么过度依赖特定语料库牺牲通用性，要么过度依赖大型语言模型（LLM）预训练数据中的通用知识，往往忽视了科学领域的动态性。此外，这些方法未能考虑科学文献的多维性，即单篇研究论文可能涉及多个维度（如方法、新任务、评估指标、基准）。为解决这些问题，我们提出了 TaxoAdapt，一种动态调整 LLM 生成的多维分类框架。TaxoAdapt 通过迭代层次分类，根据语料主题分布动态扩展分类的宽度和深度。我们在多个计算机科学会议数据集上展示了其领先性能，证明了其捕捉科学领域演化的能力。作为一种多维方法，TaxoAdapt 生成的分类在粒度保留度和连贯性上分别比最具竞争力的基线方法高出 26.51% 和 50.41%（由 LLM 评估）。

</details>


### [154] [One Tokenizer To Rule Them All: Emergent Language Plasticity via Multilingual Tokenizers](https://arxiv.org/abs/2506.10766)
**中文标题：一统天下的分词器：通过多语言分词器实现语言可塑性**

*Diana Abagyan,Alejandro R. Salamanca,Andres Felipe Cruz-Salinas,Kris Cao,Hangyu Lin,Acyr Locatelli,Marzieh Fadaee,Ahmet Üstün,Sara Hooker*

Main category: cs.CL

TL;DR: 本文研究了如何通过设计通用分词器提升多语言大模型的语言可塑性，使其在训练后能更高效地适应新语言。实验表明，通用分词器显著提高了语言适应能力，且对未见语言也有更好的表现。


<details>
  <summary>Details</summary>
Motivation: 训练大规模多语言模型时，模型容量、高质量数据稀缺和计算资源限制是主要挑战。此外，分词器的语言覆盖不足导致训练后对新语言的适应能力较差。本文旨在探索如何在训练早期通过低成本干预提升模型的语言可塑性。

Method: 提出使用通用分词器，其训练语言多于主要预训练语言，以提升训练后对新语言的适应能力。通过系统实验验证通用分词器在不同语言组和训练策略下的表现。

Result: 通用分词器显著提升了语言适应能力，相比特定语言分词器，胜率提升高达20.2%。对完全未见语言，胜率也有5%的提升，且对预训练语言的性能影响极小。

Conclusion: 通用分词器能有效提升多语言大模型的语言可塑性，使其在训练后更高效地适应新语言，同时对预训练语言的性能影响较小。

摘要: 预训练大规模多语言大模型（LLMs）面临模型容量有限、高质量数据稀缺和计算资源限制等挑战。此外，分词器的语言覆盖不足使得训练后对新语言的适应更加困难。本研究探讨了在训练早期通过低成本干预提升“语言可塑性”（即模型训练后对新语言的适应能力）的方法。我们聚焦于分词器设计，提出使用一种通用分词器，其训练语言多于主要预训练语言，以在训练后高效扩展语言覆盖范围。通过对不同语言组和训练策略的系统实验，我们发现通用分词器显著提升了语言适应能力，胜率最高提升20.2%。此外，通用分词器对完全未见语言的可塑性也提升了5%的胜率。这种扩展语言覆盖的适应能力对预训练中大多数语言的性能影响极小。

</details>


### [155] [Different Questions, Different Models: Fine-Grained Evaluation of Uncertainty and Calibration in Clinical QA with LLMs](https://arxiv.org/abs/2506.10769)
**中文标题：不同问题，不同模型：临床问答中LLMs的不确定性和校准的细粒度评估**

*Alberto Testoni,Iacer Calixto*

Main category: cs.CL

TL;DR: 本文对临床问答中大型语言模型（LLMs）的不确定性和校准进行了细粒度评估，比较了十种开源LLM在多个医学专业和问题类型中的表现，并提出了一种轻量级方法，其性能接近语义熵但仅需一次生成。


<details>
  <summary>Details</summary>
Motivation: 在临床决策支持等高风险领域部署LLMs时，准确且校准良好的不确定性估计至关重要。本文旨在评估不同LLM在临床多选题问答中的不确定性估计方法，以指导模型选择。

Method: 研究覆盖了十种开源LLM（通用、生物医学和推理模型），在两个数据集、十一个医学专业和六种问题类型中比较了标准单次生成和基于采样的方法，并提出了一种基于推理轨迹行为信号的轻量级单次生成估计方法。

Result: 结果显示，不同医学专业和问题类型之间存在显著差异，轻量级方法的性能接近语义熵，但仅需一次生成。

Conclusion: 研究强调了根据问题性质和模型特定优势选择模型的重要性，并展示了轻量级方法在临床问答中的潜力。

摘要: 在高风险领域（如临床决策支持）中部署大型语言模型（LLMs）时，准确且校准良好的不确定性估计至关重要。本文对临床多选题问答中的不确定性估计方法进行了细粒度评估，涵盖了十种开源LLM（通用、生物医学和推理模型），在两个数据集、十一个医学专业和六种问题类型中进行了比较。我们比较了标准单次生成和基于采样的方法，并通过案例研究探索了基于推理轨迹行为信号的简单单次生成估计方法。这些轻量级方法的性能接近语义熵，但仅需一次生成。结果显示，不同医学专业和问题类型之间存在显著差异，强调了根据问题性质和模型特定优势选择模型的重要性。

</details>


### [156] [Improving Named Entity Transcription with Contextual LLM-based Revision](https://arxiv.org/abs/2506.10779)
**中文标题：基于上下文大型语言模型的命名实体转录改进**

*Viet Anh Trinh,Xinlu He,Jacob Whitehill*

Main category: cs.CL

TL;DR: 本文提出了一种基于大型语言模型（LLM）的修订机制，通过利用LLM的推理能力和局部上下文（如讲义）来修正自动语音识别（ASR）中命名实体的错误识别，显著降低了命名实体的词错误率（WER）。


<details>
  <summary>Details</summary>
Motivation: 尽管自动语音识别（ASR）系统在通用语音识别上表现优异，但在命名实体识别上的词错误率（WER）仍然较高。命名实体是关键信息，其错误识别会影响下游应用。因此，本文旨在通过LLM的推理能力和上下文信息改进命名实体的转录准确性。

Method: 本文提出了一种基于大型语言模型（LLM）的修订机制，利用LLM的推理能力和局部上下文（如讲义中的正确命名实体集合）来修正ASR预测中的错误命名实体。同时，引入了NER-MIT-OpenCourseWare数据集（包含45小时的MIT课程数据）用于开发和测试。

Result: 在NER-MIT-OpenCourseWare数据集上，所提出的方法实现了命名实体词错误率（WER）相对降低30%的显著改进。

Conclusion: 通过结合LLM的推理能力和上下文信息，本文提出的方法有效降低了ASR系统中命名实体的错误识别率，为下游应用提供了更准确的输入。

摘要: 随着建模技术的进步和监督训练数据的增加，自动语音识别（ASR）系统在通用语音识别上取得了显著性能。然而，当前最先进的ASR系统在命名实体上的词错误率（WER）仍然较高。由于命名实体通常是关键信息，其错误识别会影响所有下游应用，尤其是当ASR系统作为复杂系统的前端时。本文提出了一种基于大型语言模型（LLM）的修订机制，利用LLM的推理能力以及包含正确命名实体的局部上下文（如讲义）来修正ASR预测中的错误命名实体。此外，本文还引入了NER-MIT-OpenCourseWare数据集，包含45小时的MIT课程数据用于开发和测试。在该数据集上，所提出的技术实现了命名实体词错误率相对降低30%的效果。

</details>


### [157] [Mitigating Negative Interference in Multilingual Sequential Knowledge Editing through Null-Space Constraints](https://arxiv.org/abs/2506.10800)
**中文标题：通过零空间约束缓解多语言顺序知识编辑中的负面干扰**

*Wei Sun,Tingyu Qu,Mingxiao Li,Jesse Davis,Marie-Francine Moens*

Main category: cs.CL

TL;DR: 本文提出LangEdit框架，通过零空间约束隔离多语言知识更新，有效减少参数干扰，提升多语言模型的编辑效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 在多语言大模型中高效更新知识并保持跨语言一致性是一个长期未解决的挑战。单独为每种语言部署编辑系统成本高昂，而统一模型中的顺序编辑又会导致参数干扰。

Method: 提出LangEdit框架，将每种语言的参数更新投影到先前更新子空间的正交补空间上，数学上保证更新的独立性，同时保留多语言泛化能力。

Result: 在三种模型架构、六种语言和四项下游任务上的评估表明，LangEdit显著减少了参数干扰，性能优于现有最先进的编辑方法。

Conclusion: LangEdit为多语言大模型的高效准确知识更新提供了可行方案，代码已开源。

摘要: 高效更新多语言大模型（LLMs）中的知识，同时保持跨语言事实表示的一致性，是一个长期未解决的挑战。虽然为每种语言部署单独的编辑系统看似可行，但由于需要管理多个模型，这一方法成本高昂。更高效的解决方案是将所有语言的知识更新整合到一个统一模型中。然而，跨语言的顺序编辑通常会导致破坏性参数干扰，显著降低多语言泛化能力和注入知识的准确性。为解决这一问题，我们提出了LangEdit，一种新颖的零空间约束框架，旨在精确隔离语言特定的知识更新。LangEdit的核心创新在于其能够将每种语言的参数更新投影到先前更新子空间的正交补空间上。这一方法在数学上保证了更新的独立性，同时保留了多语言泛化能力。我们在三种模型架构、六种语言和四项下游任务上进行了全面评估，结果表明LangEdit有效缓解了参数干扰，性能优于现有最先进的编辑方法。我们的结果突显了其在实现多语言大模型中高效准确知识更新方面的潜力。代码已发布于https://github.com/VRCMF/LangEdit.git。

</details>


### [158] [ReCUT: Balancing Reasoning Length and Accuracy in LLMs via Stepwise Trails and Preference Optimization](https://arxiv.org/abs/2506.10822)
**中文标题：ReCUT：通过逐步试验和偏好优化平衡大语言模型的推理长度与准确性**

*Zhensheng Jin,Xinze Li,Yifan Ji,Chunyi Peng,Zhenghao Liu,Qi Shi,Yukun Yan,Shuo Wang,Furong Peng,Ge Yu*

Main category: cs.CL

TL;DR: ReCUT是一种新方法，通过逐步探索和长短切换采样策略，平衡大语言模型（LLM）的推理长度和准确性，显著减少推理长度30-50%同时保持或提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维（CoT）提示方法虽然提升了LLM的推理能力，但常因过度思考导致冗长或冗余的推理路径。现有方法通过多推理链训练LLM，但受限于生成数据质量和过拟合问题。

Method: ReCUT采用逐步探索机制和长短切换采样策略，生成多样化推理路径，并通过偏好对训练两个专用模型（一个优化准确性，一个优化推理长度），最后通过参数插值整合模型。

Result: 在多个数学推理数据集和骨干模型上的实验表明，ReCUT显著减少推理长度30-50%，同时保持或提高推理准确性。

Conclusion: ReCUT通过平衡推理长度和准确性，为LLM推理任务提供了一种高效解决方案，代码和数据已开源。

摘要: 链式思维（CoT）提示的最新进展显著提升了大语言模型（LLM）的推理能力。然而，这些方法常因过度思考导致冗长或冗余的推理路径。现有方法尝试通过多推理链训练LLM来缓解这一问题，但其效果受限于生成数据质量且易过拟合。为解决这一挑战，我们提出“通过逐步试验压缩推理”（ReCUT），旨在平衡推理轨迹的准确性和长度。具体而言，ReCUT采用逐步探索机制和长短切换采样策略，使LLM能逐步生成多样化推理路径。这些路径经评估后用于构建偏好对，训练两个专用模型（Gemini LLM）——一个优化推理准确性，另一个优化推理长度。最终通过参数插值整合这两个模型。在多个数学推理数据集和骨干模型上的实验表明，ReCUT显著减少推理长度约30-50%，同时保持或提高推理准确性。所有代码和数据将通过https://github.com/NEUIR/ReCUT发布。

</details>


### [159] [CIIR@LiveRAG 2025: Optimizing Multi-Agent Retrieval Augmented Generation through Self-Training](https://arxiv.org/abs/2506.10844)
**中文标题：CIIR@LiveRAG 2025：通过自训练优化多智能体检索增强生成**

*Alireza Salemi,Mukta Maddipatla,Hamed Zamani*

Main category: cs.CL

TL;DR: 本文提出了一种多智能体检索增强生成框架mRAG，通过自训练和奖励引导的轨迹采样优化智能体协作，提升生成效果。在SIGIR 2025 LiveRAG竞赛中，mRAG表现优于传统RAG基线。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）框架在复杂任务中表现有限，本文旨在通过多智能体协作和自训练优化解决这一问题。

Method: 提出mRAG框架，包含规划、搜索、推理和协调等专门智能体，采用自训练和奖励引导的轨迹采样优化协作。

Result: 在DataMorgana数据集和SIGIR 2025 LiveRAG竞赛中，mRAG优于传统RAG基线，并通过案例分析展示了其实际应用效果。

Conclusion: mRAG框架通过多智能体协作和自训练优化，显著提升了复杂RAG任务的性能，具有实际应用潜力。

摘要: 本文提出了一种多智能体检索增强生成（RAG）框架mRAG，该框架由规划、搜索、推理和协调等专门智能体组成。我们的系统采用自训练范式，通过奖励引导的轨迹采样优化智能体间协作，从而提升生成效果。在SIGIR 2025 LiveRAG竞赛中基于DataMorgana数据集进行评估，mRAG表现优于传统RAG基线。我们进一步分析了竞赛结果，并通过案例研究展示了该框架在复杂实际RAG任务中的优势。

</details>


### [160] [Accelerating Diffusion Large Language Models with SlowFast: The Three Golden Principles](https://arxiv.org/abs/2506.10848)
**中文标题：利用SlowFast加速扩散大语言模型：三大黄金原则**

*Qingyan Wei,Yaojie Zhang,Zhiyuan Liu,Dongrui Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SlowFast Sampling的动态采样策略，通过三个黄金原则（确定性、收敛性和位置性）优化扩散语言模型（dLLMs）的解码效率，并结合dLLM-Cache减少冗余计算，实现了高达15.63倍的速度提升，同时保持高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型（dLLMs）采样策略（如基于置信度或半自回归解码）存在静态行为问题，导致效率低下和灵活性不足。本文旨在通过动态采样策略解决这些问题，以充分发挥dLLMs的潜力。

Method: 提出SlowFast Sampling策略，动态切换探索性和加速解码阶段，遵循三个黄金原则（确定性、收敛性和位置性），并结合dLLM-Cache减少冗余计算。

Result: 实验表明，SlowFast Sampling在LLaDA上实现了高达15.63倍的速度提升，结合缓存后可达34.22倍，且生成质量损失极小。其吞吐量甚至优于自回归基线模型（如LLaMA3 8B）。

Conclusion: SlowFast Sampling通过动态采样策略和缓存优化，显著提升了dLLMs的解码效率和生成质量，证明了精心设计的采样策略可以释放dLLMs的潜力。

摘要: 扩散语言模型（dLLMs）作为一种替代传统自回归大语言模型（LLMs）的新方法，通过并行生成令牌显著降低了推理延迟。然而，现有的dLLMs采样策略（如基于置信度或半自回归解码）通常存在静态行为问题，导致效率低下和灵活性不足。本文提出SlowFast Sampling，一种动态采样策略，通过自适应切换探索性和加速解码阶段，遵循三大黄金原则（确定性、收敛性和位置性），指导令牌的解码时机和位置。此外，我们结合dLLM-Cache以减少冗余计算。在多个基准测试和模型上的实验表明，SlowFast Sampling在LLaDA上实现了高达15.63倍的速度提升，结合缓存后可达34.22倍，且精度损失极小。值得注意的是，我们的方法在吞吐量上优于LLaMA3 8B等强自回归基线，证明了精心设计的采样策略可以充分释放dLLMs在快速高质量生成中的潜力。

</details>


### [161] [Analyzing the relationships between pretraining language, phonetic, tonal, and speaker information in self-supervised speech models](https://arxiv.org/abs/2506.10855)
**中文标题：分析自监督语音模型中预训练语言、语音、声调和说话者信息之间的关系**

*Michele Gubian,Ioana Krehan,Oli Liu,James Kirby,Sharon Goldwater*

Main category: cs.CL

TL;DR: 研究发现，wav2vec2模型在不同语言预训练中学习的语音、声调和说话者信息表示结构相似，且这些信息的子空间基本正交。


<details>
  <summary>Details</summary>
Motivation: 目前对自监督语音模型的分析主要集中在英语上，本文旨在探讨wav2vec2模型在四种不同语言预训练中如何编码语音、声调和说话者信息。

Method: 使用探测分类器和几何分析方法，分析模型在不同语言预训练和测试条件下对语音、声调和说话者信息的表示。

Result: 所有预训练和测试语言中，语音、声调和说话者信息的子空间基本正交；层间探测准确率模式相似，后期层对匹配语言的语音和声调探测略有优势。

Conclusion: wav2vec2学习的表示结构在很大程度上与预训练使用的语音材料无关。

摘要: 对自监督语音模型的分析已开始揭示其如何表示不同类型的信息。然而，几乎所有分析都集中在英语上。本文研究了在四种不同语言上训练的wav2vec2模型如何编码匹配和非匹配语言的语音。我们使用探测分类器和几何分析方法，探讨语音、词汇声调和说话者信息的表示方式。结果表明，对于所有预训练和测试语言，编码语音、声调和说话者信息的子空间基本正交，且层间探测准确率模式相似，后期层对匹配语言的语音和声调（而非说话者）探测略有优势。我们的发现表明，wav2vec2学习的表示结构在很大程度上与预训练使用的语音材料无关。

</details>


### [162] [Enhancing Medical Dialogue Generation through Knowledge Refinement and Dynamic Prompt Adjustment](https://arxiv.org/abs/2506.10877)
**中文标题：通过知识精炼与动态提示调整增强医疗对话生成**

*Hongda Sun,Jiaren Peng,Wenzhong Yang,Liang He,Bo Du,Rui Yan*

Main category: cs.CL

TL;DR: 本文提出了一种名为MedRef的新型医疗对话系统，通过知识精炼和动态提示调整，显著提升了医疗对话的生成质量和医学实体准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗对话系统（MDS）在识别相关医学知识和生成个性化、医学准确的响应方面存在不足，限制了其在现实医疗应用中的效果。

Method: MedRef采用知识精炼机制过滤无关医学数据，并结合动态提示调整模块（Triplet Filter和Demo Selector）实时适应不同患者需求。

Result: 在MedDG和KaMed基准测试中，MedRef在生成质量和医学实体准确性方面优于现有基线方法。

Conclusion: MedRef通过知识精炼和动态提示调整，显著提升了医疗对话系统的性能和可靠性，适用于实际医疗场景。

摘要: 医疗对话系统（MDS）已成为支持多轮、上下文感知的患者对话的重要在线平台。然而，现有MDS往往难以（1）识别相关医学知识，（2）生成个性化且医学准确的响应。为解决这些问题，我们提出了MedRef，一种新型MDS，结合了知识精炼和动态提示调整。首先，我们采用知识精炼机制过滤无关医学数据，提高对响应中关键医学实体的预测准确性。此外，我们设计了一种综合提示结构，整合历史细节和显性细节。为实现对不同患者病情的实时适应性，我们实现了两个关键模块——Triplet Filter和Demo Selector，为系统提示提供适当的知识和示例。在MedDG和KaMed基准上的大量实验表明，MedRef在生成质量和医学实体准确性方面均优于现有基线方法，证明了其在现实医疗应用中的有效性和可靠性。

</details>


### [163] [Slimming Down LLMs Without Losing Their Minds](https://arxiv.org/abs/2506.10885)
**中文标题：在不丧失智能的情况下精简大型语言模型**

*Qingda,Mai*

Main category: cs.CL

TL;DR: 本文研究了参数高效方法（LoRA和QLoRA）对大型语言模型性能的影响，发现LoRA方法能有效提升任务性能且保持计算效率，性能表现与微调数据集和基准任务的匹配度密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索如何在资源有限的情况下高效微调大型语言模型，同时保持其性能。

Method: 方法包括使用LoRA和QLoRA进行参数高效微调，并在三个关键领域（常识推理、数学推理和多领域知识）评估模型性能。

Result: 结果表明，LoRA方法能显著提升任务性能且计算高效，性能表现依赖于微调数据集与基准任务的匹配度。

Conclusion: 结论为LoRA方法提供了理论支持和实践指导，适用于资源有限的开发者高效微调大型语言模型。

摘要: 本文研究并验证了微调对大型语言模型性能的影响，重点关注参数高效方法（LoRA和QLoRA）。我们在三个关键领域评估模型能力：（1）常识推理（HellaSwag），（2）数学推理（GSM8K），以及（3）多领域知识（MMLU-CS）。

研究结果表明：（1）基于LoRA的方法能有效提升任务性能且保持计算效率，（2）性能表现与微调数据集和基准任务的匹配度密切相关。本研究不仅提供了参数高效机制的理论见解，还为资源有限的开发者提供了高效适应大型语言模型的实践指导。

</details>


### [164] [Generalization or Hallucination? Understanding Out-of-Context Reasoning in Transformers](https://arxiv.org/abs/2506.10887)
**中文标题：泛化还是幻觉？理解Transformer中的上下文外推理**

*Yixiao Huang,Hanlin Zhu,Tianyu Guo,Jiantao Jiao,Somayeh Sojoudi,Michael I. Jordan,Stuart Russell,Song Mei*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在微调过程中表现出的双重性：既能从新事实中泛化，又容易产生幻觉。研究发现，这两种行为源于一种称为“上下文外推理”（OCR）的机制，并通过实验和理论分析验证了其作用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在微调时表现出泛化和幻觉的双重行为，但其原因尚不明确。本文旨在揭示这两种行为背后的共同机制，并提供理论解释。

Method: 研究通过实验验证了OCR机制在五种主流LLMs中的作用，并将其形式化为一个合成事实回忆任务。同时，使用单层单头注意力模型分析矩阵分解的作用，并通过理论分析探讨梯度下降的隐式偏差。

Result: 实验表明，OCR机制确实驱动了泛化和幻觉行为，具体取决于概念之间是否存在因果关系。理论分析揭示了梯度下降倾向于最小化输出-值矩阵的核范数，从而解释了模型高效学习关联的能力。

Conclusion: 本文为理解OCR现象提供了理论基础，为分析和缓解知识注入中的不良行为提供了新视角。

摘要: 大型语言模型（LLMs）可以通过微调获取新知识，但这一过程表现出一种令人困惑的双重性：模型既能从新事实中显著泛化，又容易产生幻觉性错误信息。然而，这一现象的原因尚不清楚。本文认为，这两种行为源于一种称为“上下文外推理”（OCR）的机制：即通过关联概念（即使没有因果关系）推断含义的能力。我们在五种主流LLMs上的实验证实，OCR确实驱动了泛化和幻觉行为，具体取决于关联的概念是否具有因果关系。为了对这一现象建立严格的理论理解，我们将OCR形式化为一个合成事实回忆任务。实验表明，具有分解输出和值矩阵的单层单头注意力模型能够学习解决该任务，而权重合并的模型则不能，这凸显了矩阵分解的关键作用。理论分析表明，OCR能力可归因于梯度下降的隐式偏差，其倾向于最小化输出-值矩阵的核范数。这种数学结构解释了模型为何能够高效学习事实与含义的关联，无论这种关联是因果关系还是虚假相关。最终，我们的工作为理解OCR现象提供了理论基础，为分析和缓解知识注入中的不良行为提供了新的视角。

</details>


### [165] [BioClinical ModernBERT: A State-of-the-Art Long-Context Encoder for Biomedical and Clinical NLP](https://arxiv.org/abs/2506.10896)
**中文标题：BioClinical ModernBERT：一种面向生物医学和临床 NLP 的先进长上下文编码器**

*Thomas Sounack,Joshua Davis,Brigitte Durieux,Antoine Chaffin,Tom J. Pollard,Eric Lehman,Alistair E. W. Johnson,Matthew McDermott,Tristan Naumann,Charlotta Lindvall*

Main category: cs.CL

TL;DR: BioClinical ModernBERT 是一种针对生物医学和临床 NLP 任务优化的长上下文编码器，通过大规模预训练和多源数据集提升性能，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前生物医学和临床领域的编码器模型发展较慢，且缺乏多样化的数据源，限制了其适应性和性能。

Method: 基于 ModernBERT 进行领域适应，通过 53.5B 标记的大规模生物医学和临床语料库继续预训练，并利用来自 20 个不同机构的数据集提升多样性。

Result: BioClinical ModernBERT 在四项下游任务中表现优于现有生物医学和临床编码器，并提供了基础版（1.5 亿参数）和大型版（3.96 亿参数）模型。

Conclusion: BioClinical ModernBERT 是一种高效的生物医学和临床 NLP 编码器，通过多样化的数据源和长上下文处理能力显著提升了性能。

摘要: 基于编码器的 Transformer 模型在生物医学和临床自然语言处理（NLP）中至关重要，其双向自注意力机制使其能够通过判别任务高效地从非结构化文本中提取结构化信息。然而，与解码器模型相比，编码器的发展较慢，导致在生物医学和临床领域的适应性有限。我们提出了 BioClinical ModernBERT，这是一种基于最新 ModernBERT 发布的领域适应编码器，结合了长上下文处理能力，并在生物医学和临床 NLP 任务中显著提升了速度和性能。BioClinical ModernBERT 通过迄今为止最大的生物医学和临床语料库（超过 535 亿标记）进行继续预训练，并利用来自 20 个不同机构、领域和地理区域的数据集（而非依赖单一来源的数据）解决了先前临床编码器的关键限制。在四项下游任务中，其表现优于现有的生物医学和临床编码器。我们发布了基础版（1.5 亿参数）和大型版（3.96 亿参数）的 BioClinical ModernBERT，并提供训练检查点以支持进一步研究。

</details>


### [166] [Beyond Gold Standards: Epistemic Ensemble of LLM Judges for Formal Mathematical Reasoning](https://arxiv.org/abs/2506.10903)
**中文标题：超越黄金标准：基于LLM法官的认知集成用于形式数学推理**

*Lan Zhang,Marco Valentino,Andre Freitas*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM（大语言模型）的自动评估方法（EFG集成），用于形式数学推理中的自动形式化任务评估，通过多维度标准（逻辑保持、数学一致性、形式有效性和形式质量）提供透明评估，实验表明其与人类评估相关性更强。


<details>
  <summary>Details</summary>
Motivation: 在形式数学推理中，自动形式化的评估方法尚未充分探索，尤其是复杂领域（如高等数学）需要大量时间和专业知识。现有LLM评估方法通常采用粗粒度标准，限制了其有效性。本文旨在填补这一空白。

Method: 提出了一种基于LLM的EFG（Epistemic and Formally Grounded）集成评估方法，涵盖逻辑保持（LP）、数学一致性（MC）、形式有效性（FV）和形式质量（FQ）四个维度，提供透明且多粒度的评估。

Result: 实验表明，EFG集成评估方法与人类评估的相关性显著高于粗粒度模型，尤其在评估形式质量时表现更优。

Conclusion: 基于明确原子属性的LLM评估方法（如EFG集成）可为形式数学推理提供可扩展、可解释且可靠的评估支持。

摘要: 自动形式化在形式数学推理中扮演着关键角色，它能将自然语言陈述自动翻译为形式语言。尽管近期基于大语言模型（LLM）的研究取得了显著进展，但自动评估自动形式化的方法仍未充分探索。随着领域复杂性（如高等数学）的提升，人类评估需要大量时间和专业知识，尤其是当陈述和背景知识的复杂性增加时。LLM作为法官为自动化此类评估提供了可行方案。然而，现有方法通常采用粗粒度和通用评估标准，限制了其在高级形式数学推理中的有效性，而此类推理的质量依赖于细微、多粒度的维度。本研究通过引入一种系统化、自动化的评估方法填补了这一空白。所提出的方法基于一种认知和形式化基础的LLM法官集成（EFG），其评估标准涵盖逻辑保持（LP）、数学一致性（MC）、形式有效性（FV）和形式质量（FQ），从而提供了一种透明且考虑多因素的评估。我们验证了该框架在形式数学领域内作为自动形式化评估的代理。实验结果表明，EFG集成方法是一种合适的评估代理，与人类评估的相关性显著高于粗粒度模型，尤其是在评估形式质量时。这些发现表明，基于明确原子属性的LLM法官方法可以为形式数学推理提供可扩展、可解释且可靠的评估支持。

</details>


### [167] [Magistral](https://arxiv.org/abs/2506.10910)
**中文标题：Magistral**

*Mistral-AI,:,Abhinav Rastogi,Albert Q. Jiang,Andy Lo,Gabrielle Berrada,Guillaume Lample,Jason Rute,Joep Barmentlo,Karmesh Yadav,Kartik Khandelwal,Khyathi Raghavi Chandu,Léonard Blier,Lucile Saulnier,Matthieu Dinot,Maxime Darrin,Neha Gupta,Roman Soletskyi,Sagar Vaze,Teven Le Scao,Yihan Wang,Adam Yang,Alexander H. Liu,Alexandre Sablayrolles,Amélie Héliou,Amélie Martin,Andy Ehrenberg,Anmol Agarwal,Antoine Roux,Arthur Darcet,Arthur Mensch,Baptiste Bout,Baptiste Rozière,Baudouin De Monicault,Chris Bamford,Christian Wallenwein,Christophe Renaudin,Clémence Lanfranchi,Darius Dabert,Devon Mizelle,Diego de las Casas,Elliot Chane-Sane,Emilien Fugier,Emma Bou Hanna,Gauthier Delerce,Gauthier Guinet,Georgii Novikov,Guillaume Martin,Himanshu Jaju,Jan Ludziejewski,Jean-Hadrien Chabran,Jean-Malo Delignon,Joachim Studnia,Jonas Amar,Josselin Somerville Roberts,Julien Denize,Karan Saxena,Kush Jain,Lingxiao Zhao,Louis Martin,Luyu Gao,Lélio Renard Lavaud,Marie Pellat,Mathilde Guillaumin,Mathis Felardos,Maximilian Augustin,Mickaël Seznec,Nikhil Raghuraman,Olivier Duchenne,Patricia Wang,Patrick von Platen,Patryk Saffer,Paul Jacob,Paul Wambergue,Paula Kurylowicz,Pavankumar Reddy Muddireddy,Philomène Chagniot,Pierre Stock,Pravesh Agrawal,Romain Sauvestre,Rémi Delacourt,Sanchit Gandhi,Sandeep Subramanian,Shashwat Dalal,Siddharth Gandhi,Soham Ghosh,Srijan Mishra,Sumukh Aithal,Szymon Antoniak,Thibault Schueller,Thibaut Lavril,Thomas Robert,Thomas Wang,Timothée Lacroix,Valeriia Nemychnikova,Victor Paltz,Virgile Richard,Wen-Ding Li,William Marshall,Xuanyu Zhang,Yunhao Tang*

Main category: cs.CL

TL;DR: Magistral是Mistral的首个推理模型，采用自建的强化学习（RL）管道，探索纯RL训练LLM的极限，并展示其在多模态理解、指令跟随和函数调用方面的能力。


<details>
  <summary>Details</summary>
Motivation: 研究团队希望摆脱对现有实现和前人模型RL痕迹的依赖，从头开始构建自己的模型和基础设施，探索纯RL训练LLM的潜力。

Method: 采用自建的RL管道，完全依赖自有模型和基础设施，提出一种简单方法强制模型使用推理语言，并验证纯RL训练在文本数据上的效果。

Result: RL训练在文本数据上保持或提升了多模态理解、指令跟随和函数调用能力，并发布了Magistral Medium和开源Magistral Small。

Conclusion: Magistral展示了纯RL训练LLM的可行性，并验证了其在推理任务中的有效性，为未来研究提供了新方向。

摘要: 我们介绍了Magistral，这是Mistral的首个推理模型，以及我们自建的可扩展强化学习（RL）管道。不同于依赖现有实现或从前人模型提取的RL痕迹，我们采用从头开始的方法，完全依赖自有模型和基础设施。值得注意的是，我们展示了一个能够探索纯RL训练LLM极限的技术栈，提出了一种强制模型使用推理语言的简单方法，并证明仅通过文本数据的RL训练可以保留初始检查点的大部分能力。我们发现，RL训练在文本数据上保持或提升了多模态理解、指令跟随和函数调用能力。我们发布了Magistral Medium，它是在Mistral Medium 3基础上仅通过RL训练推理任务的模型，并开源了Magistral Small（Apache 2.0），其中还包含了来自Magistral Medium的冷启动数据。

</details>


### [168] [Decomposing MLP Activations into Interpretable Features via Semi-Nonnegative Matrix Factorization](https://arxiv.org/abs/2506.10920)
**中文标题：通过半非负矩阵分解将MLP激活分解为可解释特征**

*Or Shafran,Atticus Geiger,Mor Geva*

Main category: cs.CL

TL;DR: 该论文提出了一种通过半非负矩阵分解（SNMF）分解MLP激活的方法，以识别可解释的特征，优于现有的稀疏自编码器（SAEs）和监督基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）的机制可解释性研究中，神经元方向分析存在局限性，如神经元编码多概念和稀疏自编码器（SAEs）的因果评估能力不足。论文旨在通过SNMF直接分解MLP激活，提升特征的可解释性和因果性。

Method: 使用半非负矩阵分解（SNMF）直接分解MLP激活，确保学习到的特征是稀疏的神经元线性组合，并与激活输入直接关联，从而提升可解释性。

Result: 在Llama 3.1、Gemma 2和GPT-2上的实验表明，SNMF提取的特征在因果引导任务上优于SAEs和监督基线方法，且与人类可解释概念一致。分析还揭示了神经元组合在语义相关特征中的重用现象。

Conclusion: SNMF是一种简单有效的工具，可用于识别LLMs中的可解释特征，并揭示MLP激活空间中的层次结构。

摘要: 机制可解释性的核心目标之一是识别大型语言模型（LLMs）中能够因果解释其输出的分析单元。早期研究聚焦于单个神经元，但神经元常编码多个概念的证据促使研究方向转向激活空间中的方向分析。关键问题是如何以无监督方式找到捕捉可解释特征的方向。现有方法依赖于稀疏自编码器（SAEs）的字典学习，通常基于残差流激活训练以从头学习方向。然而，SAEs在因果评估中表现不佳且缺乏内在可解释性，因其学习过程未明确关联模型的计算。本文通过半非负矩阵分解（SNMF）直接分解MLP激活来解决这些局限，使学习到的特征（a）是神经元共激活的稀疏线性组合，（b）与其激活输入直接映射，从而具备直接可解释性。在Llama 3.1、Gemma 2和GPT-2上的实验表明，SNMF提取的特征在因果引导任务上优于SAEs和强监督基线（均值差异），并与人类可解释概念一致。进一步分析揭示，特定神经元组合在语义相关特征中被重复使用，暴露了MLP激活空间中的层次结构。这些结果共同表明，SNMF是一种简单有效的工具，可用于识别LLMs中的可解释特征并剖析概念表示。

</details>


### [169] [Dynamic Epistemic Friction in Dialogue](https://arxiv.org/abs/2506.10934)
**中文标题：对话中的动态认知摩擦**

*Timothy Obiso,Kenneth Lai,Abhijnan Nath,Nikhil Krishnaswamy,James Pustejovsky*

Main category: cs.CL

TL;DR: 本文提出动态认知摩擦的概念，探讨其在人机协作对话中对信念更新的影响，并基于动态认知逻辑框架进行分析。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在与人类偏好对齐方面取得进展，但其在信念更新时遇到的认知摩擦（即对新信息的抵抗）常被忽视。本文旨在填补这一空白。

Method: 通过动态认知逻辑框架定义动态认知摩擦，并在协作任务中分析其如何预测对话中的信念更新。

Result: 研究表明，动态认知摩擦模型能有效预测对话中的信念更新，并可通过进一步优化以适应复杂现实场景。

Conclusion: 动态认知摩擦模型为理解人机协作中的信念更新提供了新视角，未来可扩展以应对更复杂的对话场景。

摘要: 近年来，大型语言模型（LLMs）在与人类偏好对齐方面的进展显著提升了其在人机协作场景中的实用性。然而，这些方法往往忽视了“认知摩擦”的关键作用，即在面对新信息、冲突信息或模糊信息时更新信念所遇到的固有阻力。本文中，我们将动态认知摩擦定义为对认知整合的阻力，其特征是智能体当前信念状态与外部证据支持的新命题之间的错位。我们将其置于动态认知逻辑框架（Van Benthem和Pacuit，2011）中，其中摩擦表现为交互过程中的非平凡信念修正。随后，我们通过一项协作任务的分析表明，这种认知摩擦模型能有效预测对话中的信念更新，并进一步讨论如何将信念对齐模型作为认知阻力或摩擦的度量，以更复杂的方式适应现实对话场景的复杂性。

</details>


### [170] [Domain2Vec: Vectorizing Datasets to Find the Optimal Data Mixture without Training](https://arxiv.org/abs/2506.10952)
**中文标题：Domain2Vec：向量化数据集以无训练方式寻找最优数据混合**

*Mozhi Zhang,Howe Tissue,Lu Wang,Xipeng Qiu*

Main category: cs.CL

TL;DR: Domain2Vec是一种无需训练的方法，通过将数据集分解为元域的组合向量，找到最优数据混合以提升语言模型预训练效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法在寻找最优数据混合时需要大量训练，计算成本高。Domain2Vec旨在通过向量化数据集和分布对齐假设，以无训练方式高效找到最优数据组合。

Method: Domain2Vec将数据集分解为元域的线性组合向量，利用分类器生成域向量，并通过分布对齐假设（DA²）验证数据混合效果。

Result: 实验表明，Domain2Vec仅需51.5%的计算量即可达到与原数据集相同的验证损失，并在相同计算预算下平均提升下游任务性能2.83%。

Conclusion: Domain2Vec提供了一种高效、可扩展的方法，显著降低了计算成本并提升了语言模型性能。

摘要: 我们提出了Domain2Vec，这是一种新颖的方法，能够将任何数据集分解为多个元域的线性组合。元域是一种新概念，用于捕捉数据集的关键底层特征。Domain2Vec维护一个元域词汇表，并使用分类器将给定数据集分解为对应于该词汇表分布的域向量。这些域向量能够在分布对齐假设（DA²）下，以无训练方式识别语言模型（LM）预训练的最优数据混合。该假设表明，当训练集和验证集的数据分布更一致时，验证损失会更低。此外，Domain2Vec可以无缝集成到现有工作中，建模域向量与LM性能之间的关系，大幅提升先前方法的效率和可扩展性。大量实验表明，Domain2Vec能够以最小的计算开销找到提升下游任务性能的数据混合。具体而言，Domain2Vec仅需使用Pile数据集原始混合计算量的51.5%，即可在Pile-CC上达到相同的验证损失。在相同计算预算下，Domain2Vec平均提升下游任务性能2.83%。

</details>


### [171] [ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark](https://arxiv.org/abs/2506.10960)
**中文标题：ChineseHarm-Bench：一个中文有害内容检测基准**

*Kangwei Liu,Siyuan Cheng,Bozhong Tian,Xiaozhuan Liang,Yuyang Yin,Meng Han,Ningyu Zhang,Bryan Hooi,Xi Chen,Shumin Deng*

Main category: cs.CL

TL;DR: 本文提出了一个中文有害内容检测基准ChineseHarm-Bench，填补了中文领域数据稀缺的空白，并提供了一个知识增强的基线方法，使小模型也能达到与大模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前有害内容检测的资源主要集中在英语领域，中文数据集稀缺且范围有限。本文旨在填补这一空白，提供一个全面的、专业标注的中文有害内容检测基准。

Method: 构建了一个覆盖六类代表性有害内容的真实数据集，并通过专业标注生成知识规则库。提出了一种知识增强的基线方法，结合人工标注的规则和大模型的隐式知识。

Result: 提出的基准和方法使小模型在中文有害内容检测任务中表现接近最先进的大模型。数据集和代码已开源。

Conclusion: ChineseHarm-Bench为中文有害内容检测提供了高质量的数据和工具，知识增强方法为小模型的应用提供了新思路。

摘要: 大型语言模型（LLMs）越来越多地应用于自动化有害内容检测任务，帮助审核人员识别违规内容，提高内容审核的效率和准确性。然而，现有的有害内容检测资源主要集中在英语领域，中文数据集稀缺且范围有限。我们提出了一个全面的、专业标注的中文有害内容检测基准，覆盖六类代表性有害内容，并完全基于真实数据构建。标注过程进一步生成了一个知识规则库，为LLMs在中文有害内容检测中提供明确的专家知识。此外，我们提出了一种知识增强的基线方法，结合人工标注的知识规则和大模型的隐式知识，使小模型能够达到与最先进的LLMs相当的性能。代码和数据可在https://github.com/zjunlp/ChineseHarm-bench获取。

</details>


### [172] [AutoMind: Adaptive Knowledgeable Agent for Automated Data Science](https://arxiv.org/abs/2506.10974)
**中文标题：AutoMind：面向自动化数据科学的自适应知识型代理**

*Yixin Ou,Yujie Luo,Jingsheng Zheng,Lanning Wei,Shuofei Qiao,Jintian Zhang,Da Zheng,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: AutoMind是一种自适应、知识丰富的LLM代理框架，通过专家知识库、树搜索算法和动态代码生成策略，显著提升了自动化数据科学的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的数据科学代理依赖固定工作流程和代码策略，仅适用于简单任务，无法应对复杂创新问题。AutoMind旨在通过自适应和知识驱动的方法解决这些局限性。

Method: AutoMind提出三点创新：(1) 专家知识库提供领域知识支持，(2) 代理知识树搜索算法探索解决方案，(3) 自适应代码生成策略动态调整代码复杂度。

Result: 在两项自动化数据科学基准测试中，AutoMind表现优于现有方法，证明了其高效性、鲁棒性和解决方案质量。

Conclusion: AutoMind为完全自动化数据科学提供了高效且稳健的解决方案，展示了其在复杂任务中的潜力。

摘要: 大型语言模型（LLM）代理在解决现实世界数据科学问题方面展现出巨大潜力。LLM驱动的数据科学代理有望实现整个机器学习管道的自动化，但其实际效果仍有限。现有框架依赖僵化的预定义工作流程和不灵活的编码策略，因此仅在相对简单的经典问题上表现优异，而无法捕捉人类从业者在复杂创新任务中的经验。本文提出AutoMind，一种自适应、知识丰富的LLM代理框架，通过三项关键创新克服了这些不足：(1) 精心设计的专家知识库，为代理提供领域专家知识支持；(2) 代理知识树搜索算法，策略性地探索可能的解决方案；(3) 自适应编码策略，根据任务复杂度动态调整代码生成。在两项自动化数据科学基准测试中，AutoMind的表现优于现有最优方法。进一步分析证实了其高效性、鲁棒性和解决方案质量，表明AutoMind是实现完全自动化数据科学的高效且稳健的一步。

</details>


### [173] [How Well Can Reasoning Models Identify and Recover from Unhelpful Thoughts?](https://arxiv.org/abs/2506.10979)
**中文标题：推理模型在识别和恢复无益思维方面的表现如何？**

*Sohee Yang,Sang-Woo Lee,Nora Kassner,Daniela Gottesman,Sebastian Riedel,Mor Geva*

Main category: cs.CL

TL;DR: 研究发现推理模型能有效识别无益思维，但在恢复方面表现不佳，尤其是大模型在面对短无关思维时表现更差。


<details>
  <summary>Details</summary>
Motivation: 探讨推理模型在识别和恢复无益思维方面的能力，以评估其自我反思和纠正的能力。

Method: 研究四种无益思维（无信息冗长、与问题无关、误导问题和导致错误答案的思维）对模型的影响，并测试模型的识别和恢复能力。

Result: 模型能识别大多数无益思维，但恢复能力较差，尤其是大模型在面对短无关思维时表现更差。最小的模型对有害思维干扰的抵抗力最强。

Conclusion: 需改进推理模型的自我反思能力，以提升其推理能力和系统安全性。

摘要: 最近的推理模型展现出反思、回溯和自我验证推理的能力，这对于发现错误和得出准确解答至关重要。一个自然的问题是，模型能否有效进行这种自我重新评估。我们通过研究推理模型在识别和恢复四种无益思维方面的表现来探讨这一问题：无信息冗长思维、与问题无关的思维、将问题误导为稍不同问题的思维，以及导致错误答案的思维。我们发现，模型能有效识别大多数无益思维，但在这些思维被注入其思考过程时，恢复能力较差，导致性能显著下降。模型倾向于天真地延续无关思维的推理路径，这表明其自我重新评估能力远未达到“元认知”意识。此外，我们观察到非/逆缩放趋势，即较大的模型在恢复短无关思维时表现比小模型更差，即使被指示重新评估其推理。我们通过一个无关思维注入的越狱实验展示了这些发现的含义，表明最小的模型对有害思维干扰的抵抗力最强。总体而言，我们的发现呼吁改进推理模型的自我重新评估能力，以开发更好的推理和更安全的系统。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [174] [Multimodal Cinematic Video Synthesis Using Text-to-Image and Audio Generation Models](https://arxiv.org/abs/2506.10005)
**中文标题：使用文本到图像和音频生成模型的多模态电影视频合成**

*Sridhar S,Nithin A,Shakeel Rifath,Vasantha Raj*

Main category: cs.CV

TL;DR: The paper presents a method for synthesizing 60-second cinematic videos using Stable Diffusion for images, GPT-2 for narrative, and a hybrid audio pipeline, achieving professional-quality results with optimizations for efficiency and reliability.


<details>
  <summary>Details</summary>
Motivation: To leverage advances in generative AI for automating cinematic video creation from text inputs, enhancing multimedia production for creative, educational, and industrial applications.

Method: Combines Stable Diffusion for image synthesis, GPT-2 for narrative structuring, and a hybrid audio pipeline (gTTS and YouTube-sourced music) within a five-scene framework, augmented by frame interpolation, post-processing, and synchronization.

Result: Demonstrates outstanding visual quality, narrative coherence, and efficiency, supporting resolutions up to 1024x768 and frame rates of 15-30 FPS.

Conclusion: The method advances text-to-video synthesis, offering a reliable and high-quality solution for diverse applications.

摘要: 生成人工智能的进步改变了多媒体创作，允许从文本输入自动合成电影视频。本研究描述了一种创建60秒电影视频的方法，结合了Stable Diffusion用于高保真图像合成、GPT-2用于叙事结构，以及使用gTTS和YouTube来源音乐的混合音频管道。采用五场景框架，并通过线性帧插值、电影后期处理（如锐化）和音视频同步提升专业质量。该方法在GPU加速的Google Colab环境中使用Python 3.11实现，具有双模式Gradio界面（简单和高级），支持分辨率高达1024x768和帧率15-30 FPS。通过CUDA内存管理和错误处理等优化确保可靠性。实验展示了出色的视觉质量、叙事连贯性和效率，进一步推动了文本到视频合成在创意、教育和工业领域的应用。

</details>


### [175] [LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning](https://arxiv.org/abs/2506.10082)
**中文标题：LoRA-Edit：基于掩码感知LoRA微调的首帧引导可控视频编辑**

*Chenjian Gao,Lihe Ding,Xin Cai,Zhanpeng Huang,Zibin Wang,Tianfan Xue*

Main category: cs.CV

TL;DR: LoRA-Edit introduces a mask-aware LoRA fine-tuning method for controllable video editing, enabling flexible edits while preserving background regions without altering model architecture.


<details>
  <summary>Details</summary>
Motivation: Current video editing methods rely on large-scale pretraining and lack flexibility for specific edits. First-frame-guided editing provides initial control but struggles with subsequent frames.

Method: The paper proposes a mask-based LoRA tuning method that adapts pretrained Image-to-Video models, using spatial masks to guide region-specific learning and reference images for appearance guidance.

Result: Experimental results show superior video editing performance compared to state-of-the-art methods, with efficient and adaptable edits.

Conclusion: LoRA-Edit offers a flexible and efficient solution for video editing by leveraging mask-aware LoRA tuning, balancing control and adaptability.

摘要: 使用扩散模型进行视频编辑在生成高质量编辑视频方面取得了显著成果。然而，现有方法通常依赖于大规模预训练，限制了特定编辑的灵活性。首帧引导编辑提供了对首帧的控制，但对后续帧缺乏灵活性。为此，我们提出了一种基于掩码的LoRA（低秩适应）微调方法，通过调整预训练的图像到视频（I2V）模型实现灵活的视频编辑。我们的方法在保留背景区域的同时，实现了可控的编辑传播。这一解决方案无需改变模型架构，即可提供高效且适应性强的视频编辑。为了更好地引导这一过程，我们引入了额外的参考（如替代视角或代表性场景状态），作为内容展开的视觉锚点。我们通过掩码驱动的LoRA调优策略解决了控制难题，将预训练的I2V模型适配到编辑上下文中。模型需要从两个不同的来源学习：输入视频提供空间结构和运动线索，而参考图像提供外观指导。空间掩码通过动态调节模型的注意力，实现区域特定学习，确保每个区域从适当的来源获取信息。实验结果表明，我们的方法在视频编辑性能上优于现有最先进方法。

</details>


### [176] [DeepTraverse: A Depth-First Search Inspired Network for Algorithmic Visual Understanding](https://arxiv.org/abs/2506.10084)
**中文标题：DeepTraverse：一种受深度优先搜索启发的算法视觉理解网络**

*Bin Guo,John H. L. Hansen*

Main category: cs.CV

TL;DR: DeepTraverse introduces a novel vision architecture inspired by algorithmic search strategies, enabling adaptive and interpretable feature learning, outperforming conventional models in image classification.


<details>
  <summary>Details</summary>
Motivation: Conventional vision backbones lack adaptive, iterative refinement. The paper explores whether principles from classical search algorithms can create more structured and interpretable processing flows in networks.

Method: DeepTraverse uses recursive exploration modules for deepening feature analysis and adaptive calibration modules to dynamically adjust feature salience, combining algorithmic search strategies with deep learning.

Result: DeepTraverse achieves competitive classification accuracy and robust feature discrimination, often outperforming conventional models with similar or larger parameter counts.

Conclusion: Integrating algorithmic priors provides a principled and effective strategy for building efficient, performant, and structured vision backbones.

摘要: 尽管传统视觉主干网络取得了成功，但其特征构建通常通过一系列几乎一致的操作完成，缺乏自适应迭代优化的显式路径。这引发了一个引人深思的问题：经典搜索算法的原理能否在这些网络中注入更具算法性、结构化和逻辑性的处理流程，从而通过更可解释、甚至类似推理的决策过程构建表征？我们提出了DeepTraverse，一种直接受算法搜索策略启发的新型视觉架构，使其能够通过系统阐明和自适应优化的过程学习特征，与传统方法截然不同。DeepTraverse通过两个关键协同组件实现这一点：递归探索模块通过参数共享高效地沿着有前景的表征路径深化特征分析，以及自适应校准模块根据全局上下文动态调整特征显著性。这种算法的相互作用使DeepTraverse能够智能地构建和优化特征模式。在多样化的图像分类基准测试中，DeepTraverse表现出极具竞争力的分类准确性和鲁棒的特征判别能力，通常优于参数数量相似或更多的传统模型。我们的工作表明，整合此类算法先验为构建更高效、性能更强且结构化的视觉主干网络提供了一种有原则且有效的策略。

</details>


### [177] [Test-Time Adaptation for Generalizable Task Progress Estimation](https://arxiv.org/abs/2506.10085)
**中文标题：通用任务进度估计的测试时适应方法**

*Christos Ziakas,Alessandra Russo*

Main category: cs.CV

TL;DR: The paper introduces a test-time adaptation method for progress estimation models, enabling online adaptation to test trajectories via self-supervised learning, outperforming state-of-the-art approaches.


<details>
  <summary>Details</summary>
Motivation: To improve progress estimation models' ability to generalize across diverse tasks, environments, and embodiments by adapting to test-time visual and temporal contexts.

Method: A gradient-based meta-learning strategy trains the model on expert trajectories and task descriptions, optimizing a self-supervised objective for test-time adaptation.

Result: The method generalizes well to out-of-distribution tasks and outperforms autoregressive vision-language models in progress estimation.

Conclusion: Test-time adaptation enhances progress estimation by leveraging semantic content over temporal order, demonstrating superior generalization.

摘要: 我们提出了一种测试时适应方法，使进度估计模型能够通过优化学习的自监督目标，在线适应测试轨迹的视觉和时间上下文。为此，我们引入了一种基于梯度的元学习策略，在专家视觉轨迹及其自然语言任务描述上训练模型，使得测试时适应能够依赖语义内容而非时间顺序改进进度估计。我们的测试时适应方法从单一训练环境推广到多样化的分布外任务、环境和体现形式，优于使用自回归视觉语言模型的最先进上下文学习方法。

</details>


### [178] [EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models](https://arxiv.org/abs/2506.10100)
**中文标题：高效VLA：视觉-语言-动作模型的免训练加速与压缩**

*Yantai Yang,Yuhao Wang,Zichen Wen,Luo Zhongwei,Chang Zou,Zhipeng Zhang,Chuan Wen,Linfeng Zhang*

Main category: cs.CV

TL;DR: EfficientVLA is a training-free framework that accelerates and compresses Vision-Language-Action models by exploiting redundancies in language, visual, and action modules, achieving significant speedup and FLOP reduction with minimal performance loss.


<details>
  <summary>Details</summary>
Motivation: Vision-Language-Action models face high computational and memory demands due to redundancies, limiting practical deployment. Existing solutions address isolated inefficiencies but fail to holistically tackle bottlenecks across the entire pipeline.

Method: EfficientVLA integrates three strategies: pruning redundant language layers, optimizing visual token selection, and caching intermediate features in the action module.

Result: Applied to CogACT, EfficientVLA achieves a 1.93X speedup, reduces FLOPs to 28.9%, and only drops success rate by 0.6% in the SIMPLER benchmark.

Conclusion: EfficientVLA provides a holistic, training-free solution to accelerate VLA models, making them more practical for deployment without significant performance trade-offs.

摘要: 视觉-语言-动作（VLA）模型，尤其是基于扩散架构的模型，在具身智能方面展现出变革性潜力，但由于其固有的和推理时的大量冗余，计算和内存需求极高，严重阻碍了其应用。现有的加速方法通常针对孤立的低效问题，这种零散的解决方案通常无法全面解决整个VLA流程中的多种计算和内存瓶颈，从而限制了实际部署性。我们提出了EfficientVLA，这是一种结构化且免训练的推理加速框架，通过协同利用多方面的冗余，系统性地消除这些障碍。EfficientVLA协同整合了三种针对性策略：（1）通过分析层间冗余，修剪语言模块中功能无关紧要的层；（2）通过任务感知策略优化视觉处理路径，选择一组紧凑且多样化的视觉标记，平衡任务关键性与信息覆盖；（3）通过策略性地缓存和重用关键中间特征，减轻基于扩散迭代的动作头中的时间计算冗余。我们将该方法应用于标准VLA模型CogACT，在SIMPLER基准测试中实现了1.93倍的推理加速，并将FLOPs降低至28.9%，同时成功率仅下降0.6%。

</details>


### [179] [A Manually Annotated Image-Caption Dataset for Detecting Children in the Wild](https://arxiv.org/abs/2506.10117)
**中文标题：用于检测野外儿童的手动标注图像-字幕数据集**

*Klim Kireev,Ana-Maria Creţu,Raphael Meier,Sarah Adel Bargal,Elissa Redmiles,Carmela Troncoso*

Main category: cs.CV

TL;DR: The paper introduces ICCWD, a manually annotated image-caption dataset for detecting children in diverse contexts, benchmarking three detectors with a best true positive rate of 75.3%.


<details>
  <summary>Details</summary>
Motivation: To address the lack of a multi-modal dataset for detecting minors in digital content, which is crucial for regulatory compliance and automation tools.

Method: The authors created ICCWD, a dataset of 10,000 image-caption pairs manually labeled for child presence, and benchmarked three detection methods, including a commercial age estimation system.

Result: Child detection proved challenging, with the best method achieving a 75.3% true positive rate.

Conclusion: The release of ICCWD aims to improve minor detection methods across various scenarios.

摘要: 平台和法律对描绘未成年人（定义为18岁以下的个体）的数字内容与其他类型内容的监管方式不同。鉴于需要评估的内容数量庞大，基于机器学习的自动化工具通常用于检测描绘未成年人的内容。据我们所知，目前尚无用于在多模态环境中检测这些识别方法的数据集或基准。为填补这一空白，我们发布了图像-字幕野外儿童数据集（ICCWD），这是一个旨在为检测未成年人描绘工具提供基准的图像-字幕数据集。我们的数据集比以往的儿童图像数据集更丰富，包含各种情境下的儿童图像，包括虚构描绘和部分可见的身体。ICCWD包含10,000个手动标注的图像-字幕对，用于指示图像中是否存在儿童。为展示我们数据集的潜在用途，我们用它来对三种不同的检测器进行基准测试，包括应用于图像的商业年龄估计系统。我们的结果表明，儿童检测是一项具有挑战性的任务，最佳方法的真阳性率为75.3%。我们希望数据集的发布将有助于设计更广泛的场景中更好的未成年人检测方法。

</details>


### [180] [Detecção da Psoríase Utilizando Visão Computacional: Uma Abordagem Comparativa Entre CNNs e Vision Transformers](https://arxiv.org/abs/2506.10119)
**中文标题：使用计算机视觉检测银屑病：CNN与Vision Transformers的比较研究**

*Natanael Lucena,Fábio S. da Silva,Ricardo Rios*

Main category: cs.CV

TL;DR: The paper compares CNNs and Vision Transformers (ViTs) for classifying psoriasis images, finding ViTs superior, especially the DaViT-B model with a 96.4% f1-score.


<details>
  <summary>Details</summary>
Motivation: To evaluate and compare the effectiveness of CNNs and ViTs in classifying medical images of psoriasis and similar diseases, aiming to identify the most efficient architecture for automated detection.

Method: Pre-trained CNN and ViT models were adapted to a specific dataset of psoriasis and similar disease images, and their performance was compared using predictive metrics.

Result: ViTs outperformed CNNs, with the DaViT-B model achieving the highest f1-score of 96.4%, demonstrating superior efficiency with smaller models.

Conclusion: ViTs, particularly DaViT-B, are recommended for automated psoriasis detection due to their high performance and efficiency, highlighting their potential in medical image classification.

摘要: 本文比较了卷积神经网络（CNN）和Vision Transformers（ViTs）在多分类银屑病及类似疾病图像任务中的表现。基于ImageNet预训练的模型被适配到特定数据集。两种模型均取得了较高的预测指标，但ViTs凭借较小模型下的卓越表现脱颖而出。Dual Attention Vision Transformer-Base（DaViT-B）获得了最佳结果，f1分数为96.4%，被推荐为自动化银屑病检测的最高效架构。本文强化了ViTs在医学图像分类任务中的潜力。

</details>


### [181] [ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs](https://arxiv.org/abs/2506.10128)
**中文标题：ViCrit：一种用于视觉语言模型视觉感知的可验证强化学习代理任务**

*Xiyao Wang,Zhengyuan Yang,Chao Feng,Yongyuan Liang,Yuhang Zhou,Xiaoyu Liu,Ziyi Zang,Ming Li,Chung-Ching Lin,Kevin Lin,Linjie Li,Furong Huang,Lijuan Wang*

Main category: cs.CV

TL;DR: The paper introduces ViCrit, a verifiable reinforcement learning proxy task for VLMs to localize subtle visual hallucinations in captions, improving visual perception across benchmarks.


<details>
  <summary>Details</summary>
Motivation: Extending RL's success in LLMs to VLMs is challenging due to the lack of vision-centric tasks that are both difficult and verifiable. ViCrit addresses this gap.

Method: ViCrit trains VLMs to detect synthetic visual hallucinations in captions, providing binary rewards for pinpointing errors in objects, attributes, counts, or spatial relations.

Result: Models trained with ViCrit show significant improvements on VL benchmarks, including transfer to abstract image reasoning and visual math.

Conclusion: ViCrit is an effective and generalizable objective for enhancing visual perception in VLMs, demonstrated by ViCrit-Bench's diagnostic evaluation.

摘要: 强化学习（RL）在微调大型语言模型（LLMs）方面表现出色，适用于数学推理或代码生成等具有挑战性且易于验证的任务。然而，将这一成功扩展到视觉语言模型（VLMs）的视觉感知中，却因缺乏同时具有挑战性和明确可验证性的视觉中心任务而受阻。为此，我们提出了ViCrit（视觉描述幻觉批评器），这是一种RL代理任务，用于训练VLMs定位人类编写的图像描述段落中注入的微妙合成视觉幻觉。我们从200字的描述开始，注入单个微妙的视觉描述错误（改变对象、属性、数量或空间关系的几个词），并让模型根据图像和修改后的描述定位被破坏的部分。这一方法保留了完整的感知难度，同时提供了易于计算且明确的二进制精确匹配奖励。通过ViCrit任务训练的模型在各种VL基准测试中表现出显著提升。重要的是，这些改进不仅适用于自然图像训练数据，还能迁移到抽象图像推理和视觉数学中，显示出学习感知而非仅记忆所见对象的潜力。为了便于评估，我们还引入了ViCrit-Bench，这是一个类别平衡的诊断基准，系统地探测不同图像领域和错误类型的感知错误。总之，我们的结果表明，细粒度的幻觉批评是增强VLMs视觉感知的有效且可推广的目标。

</details>


### [182] [RoCA: Robust Cross-Domain End-to-End Autonomous Driving](https://arxiv.org/abs/2506.10145)
**中文标题：RoCA：鲁棒的跨领域端到端自动驾驶**

*Rajeev Yasarla,Shizhong Han,Hsin-Pai Cheng,Litian Liu,Shweta Mahajan,Apratim Bhattacharyya,Yunxiao Shi,Risheek Garrepalli,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: RoCA is a novel framework for robust cross-domain end-to-end autonomous driving, improving generalizability and adaptation without extra inference costs.


<details>
  <summary>Details</summary>
Motivation: Existing end-to-end autonomous driving models struggle with cross-domain deployment, and while LLMs offer open-world knowledge, they lack performance guarantees and incur high retraining costs.

Method: RoCA formulates a joint probabilistic distribution over tokens encoding vehicle information, using Gaussian processes to learn basis tokens and trajectories for diverse scenarios, enabling probabilistic trajectory inference.

Result: RoCA significantly outperforms direct finetuning in domain adaptation and improves generalizability without additional inference computation.

Conclusion: RoCA provides a robust solution for cross-domain end-to-end autonomous driving, achieving strong generalization and adaptation performance.

摘要: 端到端（E2E）自动驾驶作为一种新范式，具有巨大潜力，但跨领域（如城市）部署的实际挑战尚未得到充分研究。尽管已有研究利用大型语言模型（LLM）获取开放世界知识，但LLM无法保证跨领域驾驶性能，且领域适应时可能产生高昂的再训练成本。本文提出RoCA，一种鲁棒的跨领域E2E自动驾驶框架。RoCA在E2E流程中联合建模编码自车和周围车辆信息的令牌的概率分布。通过高斯过程（GP）实例化，RoCA学习一组基础令牌及其对应轨迹，覆盖多样驾驶场景。随后，给定任意驾驶场景，RoCA能概率推断未来轨迹。通过在源领域训练中结合RoCA与基础E2E模型，无需额外推理计算即可提升基础模型的泛化能力。此外，RoCA支持在新目标领域上的鲁棒适应，显著优于直接微调。我们在多种跨领域场景中广泛评估RoCA，结果表明其具备强大的领域泛化和适应性能。

</details>


### [183] [SPARKE: Scalable Prompt-Aware Diversity Guidance in Diffusion Models via RKE Score](https://arxiv.org/abs/2506.10173)
**中文标题：SPARKE：基于RKE分数的扩散模型中可扩展的提示感知多样性引导方法**

*Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia*

Main category: cs.CV

TL;DR: SPARKE introduces a scalable, prompt-aware diversity guidance method for diffusion models, reducing computational complexity while improving diversity in generated samples.


<details>
  <summary>Details</summary>
Motivation: Ensuring diversity in prompt-guided diffusion models is challenging, especially across broad semantic spectrums. Existing methods lack scalability and prompt-aware diversity control.

Method: SPARKE uses conditional entropy for diversity guidance, dynamically conditioning on similar prompts. It reduces computational complexity from O(n³) to O(n) via Conditional latent RKE Score Guidance.

Result: SPARKE improves prompt-aware diversity in generated samples without significant computational costs, validated on text-to-image diffusion models.

Conclusion: SPARKE offers an efficient and scalable solution for enhancing diversity in prompt-guided diffusion models, balancing performance and computational feasibility.

摘要: 扩散模型在高保真图像合成和提示引导生成建模中表现出色。然而，确保提示引导扩散模型生成样本的多样性仍然是一个挑战，尤其是在提示涵盖广泛语义范围且需要以提示感知方式评估生成数据的多样性时。近期方法通过多样性度量引入引导以鼓励更多样化的生成。本文扩展了基于多样性度量的方法，提出了可扩展的提示感知Rény核熵多样性引导（SPARKE）方法。SPARKE利用条件熵进行多样性引导，动态地将多样性度量条件化为相似提示，并实现提示感知的多样性控制。尽管基于熵的引导方法增强了提示感知多样性，但其对矩阵熵分数的依赖在大规模生成场景中带来了计算挑战。为此，我们专注于条件潜在RKE分数引导的特殊情况，将熵计算和基于梯度的优化复杂度从一般熵度量的O(n³)降低到O(n)。降低的计算复杂度允许在不同提示下的数千次生成轮次中进行多样性引导采样。我们在多个文本到图像扩散模型上对SPARKE方法进行了数值测试，结果表明该方法在不显著增加计算成本的情况下提高了生成数据的提示感知多样性。代码已在项目页面发布：https://mjalali.github.io/SPARKE

</details>


### [184] [Retrieval of Surface Solar Radiation through Implicit Albedo Recovery from Temporal Context](https://arxiv.org/abs/2506.10174)
**中文标题：通过时间上下文隐式反照率恢复的地表太阳辐射反演**

*Yael Frischholz,Devis Tuia,Michael Lehning*

Main category: cs.CV

TL;DR: The paper proposes an attention-based emulator for surface solar radiation (SSR) retrieval that implicitly learns clear-sky reflectance from satellite image sequences, improving accuracy in mountainous regions with dynamic snow cover.


<details>
  <summary>Details</summary>
Motivation: Traditional SSR retrieval methods fail in mountainous regions due to intermittent snow cover and changing surfaces. The paper aims to develop a model that can implicitly learn surface reflectance dynamics without relying on hand-crafted features like albedo maps or cloud masks.

Method: The authors use an attention-based emulator built on the Temporo-Spatial Vision Transformer. It processes multi-spectral SEVIRI imagery, static topographic features, and solar geometry, trained on HelioMont's SSR estimates over Switzerland.

Result: The model matches the performance of albedo-informed models when given sufficient temporal context, particularly excelling in mountainous regions and improving generalization across diverse terrains.

Conclusion: The proposed method demonstrates the ability to implicitly learn surface reflectance dynamics, offering a robust solution for SSR retrieval in complex terrains without explicit albedo data.

摘要: 从卫星图像中准确反演地表太阳辐射（SSR）的关键在于估算晴空条件下空间传感器观测到的背景反射率。与这一基线的偏差可用于检测云的存在，并指导辐射传输模型推断大气衰减。传统的反演算法通常使用月度统计数据近似背景反射率，假设地表性质相对于大气条件变化缓慢。然而，这种方法在山区失效，因为间歇性积雪和变化的雪面频繁出现。我们提出了一种基于注意力的SSR反演模拟器，能够隐式地从原始卫星图像序列中学习晴空地表反射率。基于时空视觉变换器的方法无需手工特征（如显式反照率图或云掩膜）。该模拟器在瑞士（以复杂地形和动态积雪为特征）使用HelioMont算法的瞬时SSR估计进行训练。输入包括来自Meteosat第二代平台的多光谱SEVIRI图像，辅以静态地形特征和太阳几何信息。目标变量是HelioMont的SSR，以1.7公里的空间分辨率计算为直接和漫射水平辐照度分量的总和。研究表明，当提供足够长的时间上下文时，该模型的性能与基于反照率的模型相当，突显了其内部学习和利用潜在地表反射率动态的能力。地理空间分析表明，这种效果在山区最为显著，并在简单和复杂地形环境中均提高了泛化能力。代码和数据集公开于https://github.com/frischwood/HeMu-dev.git。

</details>


### [185] [Attention, Please! Revisiting Attentive Probing for Masked Image Modeling](https://arxiv.org/abs/2506.10178)
**中文标题：请注意！重新审视掩码图像建模中的注意力探测方法**

*Bill Psomas,Dionysis Christopoulos,Eirini Baltzi,Ioannis Kakogeorgiou,Tilemachos Aravanis,Nikos Komodakis,Konstantinos Karantzalos,Yannis Avrithis,Giorgos Tolias*

Main category: cs.CV

TL;DR: The paper revisits attentive probing for Masked Image Modeling (MIM), introduces Efficient Probing (EP), a multi-query cross-attention mechanism that improves accuracy and efficiency, outperforming linear probing and prior methods across benchmarks.


<details>
  <summary>Details</summary>
Motivation: Standard linear probing fails to reflect MIM's potential due to distributed patch tokens, motivating the need for efficient attentive probing methods.

Method: The paper introduces Efficient Probing (EP), a multi-query cross-attention mechanism that reduces redundant projections and parameters, achieving faster performance.

Result: EP outperforms linear probing and prior attentive probing methods across seven benchmarks, generalizes beyond MIM, and shows gains in low-shot and layer-wise settings.

Conclusion: EP is a simple yet effective attentive probing method that balances accuracy and efficiency, offering interpretability and strong performance.

摘要: 随着微调（FT）在大规模应用中变得越来越不切实际，探测成为自监督学习（SSL）的首选评估协议。然而，标准的线性探测（LP）由于补丁标记的分布式特性，未能充分反映掩码图像建模（MIM）训练的模型的潜力。这促使了对注意力探测的需求，该方法利用注意力选择性地聚合补丁级特征。尽管其应用日益广泛，注意力探测仍未被充分探索，现有方法存在参数过多和计算效率低下的问题。
  在这项工作中，我们从准确性与效率权衡的角度重新审视了注意力探测。我们对现有方法进行了系统研究，分析了其机制并对其性能进行了基准测试。我们引入了高效探测（EP），这是一种多查询交叉注意力机制，消除了冗余投影，减少了可训练参数的数量，并比传统的多头注意力实现了高达10倍的加速。尽管简单，EP在七个基准测试中优于LP和先前的注意力探测方法，能够很好地推广到MIM以外的多种预训练范式，生成可解释的注意力图，并在低样本和分层设置中实现了显著的性能提升。代码发布于https://github.com/billpsomas/efficient-probing。

</details>


### [186] [Improving Personalized Search with Regularized Low-Rank Parameter Updates](https://arxiv.org/abs/2506.10182)
**中文标题：通过正则化低秩参数更新改进个性化搜索**

*Fiona Ryan,Josef Sivic,Fabian Caba Heilbron,Judy Hoffman,James M. Rehg,Bryan Russell*

Main category: cs.CV

TL;DR: The paper introduces a method for personalized vision-language retrieval by adapting a dual encoder model with regularized low-rank parameter updates, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Personalized vision-language retrieval is challenging due to the need to learn new concepts from few examples while integrating personal and general knowledge. The paper aims to improve this by adapting model parameters effectively.

Method: The approach involves regularized low-rank adaptation of parameters in the language encoder's final layer, combined with strategies for merging multiple personal concepts. A new metric evaluates general knowledge preservation.

Result: The method outperforms prior art by 4%-22% on personalized image retrieval benchmarks (DeepFashion2 and ConCon-Chi), demonstrating superior accuracy.

Conclusion: Regularized low-rank parameter updates effectively adapt vision-language models for personalized retrieval while preserving general knowledge, setting a new benchmark.

摘要: 个性化视觉语言检索旨在从少量示例中识别新概念（例如“我的狗Fido”）。这一任务具有挑战性，因为它不仅需要从少量图像中学习新概念，还需要将个人知识与通用知识结合以在不同上下文中识别概念。本文展示了如何有效调整视觉语言双编码器模型的内部表示以用于个性化视觉语言检索。我们发现，对语言编码器最后一层的一小部分参数进行正则化低秩调整，是识别个人概念并保留通用知识的高效替代方案。此外，我们探索了合并多个学习到的个人概念参数的策略，发现参数相加是有效的。为了评估微调表示中通用知识的保留情况，我们引入了一种基于视觉语言模型（VLM）生成的标题测量图像检索准确性的指标。我们的方法在两个个性化图像检索基准（DeepFashion2和ConCon-Chi）上实现了最先进的准确性，在个性化检索任务中比现有技术高出4%-22%。

</details>


### [187] [ScoreMix: Improving Face Recognition via Score Composition in Diffusion Generators](https://arxiv.org/abs/2506.10226)
**中文标题：ScoreMix：通过扩散生成器中的分数组合改进人脸识别**

*Parsa Rahimi,Sebastien Marcel*

Main category: cs.CV

TL;DR: ScoreMix is a data augmentation method using diffusion models to enhance face recognition by mixing scores from different class-conditioned trajectories, improving performance with limited labeled data.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of limited labeled data in face recognition by leveraging diffusion models to generate synthetic samples that enhance discriminative capabilities.

Method: ScoreMix convexly mixes scores from different class-conditioned trajectories during diffusion sampling, focusing on combining classes distant in the discriminator's embedding space.

Result: The approach significantly improves performance in benchmarks, especially when mixing distant classes, and shows minimal correlation between the generator's condition space and the discriminator's embedding space.

Conclusion: ScoreMix offers a practical solution for improving face recognition without extensive parameter tuning or large datasets, demonstrating the effectiveness of score composition in diffusion models.

摘要: 本文提出ScoreMix，一种新颖而简单的数据增强策略，利用扩散模型的分数组合特性来增强判别器性能，特别是在标记数据有限的情况下。通过在扩散采样过程中对不同类条件轨迹的分数进行凸组合，我们生成了具有挑战性的合成样本，显著提高了所有研究基准中的判别能力。我们系统地研究了混合的类选择策略，发现当组合在判别器嵌入空间中距离较远的类时，性能提升更大，而不是在生成器条件空间中距离较近的类。此外，我们通过实验证明，在标准指标下，生成器学习的条件空间与判别器的嵌入空间之间的相关性很小。我们的方法在没有进行大量参数搜索的情况下实现了显著的性能改进，展示了在训练判别模型时的实际优势，同时有效缓解了大规模数据集收集的问题。论文网站：https://parsa-ra.github.io/scoremix

</details>


### [188] [California Crop Yield Benchmark: Combining Satellite Image, Climate, Evapotranspiration, and Soil Data Layers for County-Level Yield Forecasting of Over 70 Crops](https://arxiv.org/abs/2506.10228)
**中文标题：加利福尼亚农作物产量基准：结合卫星图像、气候、蒸散发和土壤数据层对70多种作物进行县级产量预测**

*Hamid Kamangir,Mona Hajiesmaeeli,Mason Earles*

Main category: cs.CV

TL;DR: The paper introduces a comprehensive dataset and deep learning model for forecasting crop yields in California, integrating satellite imagery, climate, evapotranspiration, and soil data, achieving high predictive accuracy.


<details>
  <summary>Details</summary>
Motivation: Accurate crop yield forecasting in California is challenging due to complex environmental factors, despite extensive historical data. This study aims to address this gap by integrating diverse data sources and developing a robust predictive model.

Method: The study combines Landsat satellite imagery, climate records, evapotranspiration, and soil data into a multi-modal deep learning model. The model uses stratified feature extraction and a timeseries encoder to capture spatial and temporal dynamics.

Result: The model achieves an R2 score of 0.76 across over 70 crops, demonstrating strong predictive performance for county-level yield forecasting in California.

Conclusion: The benchmark dataset and modeling framework provide a valuable tool for agricultural forecasting, climate adaptation, and precision farming, with publicly available data and code.

摘要: 加利福尼亚是全球农业生产的领导者，占美国总产量的12.5%，是世界第五大食品和棉花供应地。尽管美国农业部国家农业统计服务提供了大量历史产量数据，但由于环境、气候和土壤相关因素的复杂相互作用，准确及时的作物产量预测仍然具有挑战性。本研究引入了一个全面的作物产量基准数据集，涵盖2008年至2022年加利福尼亚所有县的70多种作物。该基准整合了多种数据源，包括Landsat卫星图像、每日气候记录、每月蒸散发和高分辨率土壤属性。为了有效学习这些异构输入，我们开发了一个多模态深度学习模型，专门用于县级、特定作物的产量预测。该模型采用分层特征提取和时间序列编码器来捕捉生长季节的空间和时间动态。静态输入（如土壤特性和作物身份）则用于长期变异性分析。我们的方法在所有作物的未见测试数据集上实现了0.76的总体R2分数，突显了在加利福尼亚多样化农业区域的强大预测性能。这一基准和建模框架为推进农业预测、气候适应和精准农业提供了宝贵的基础。完整的数据集和代码库已在我们的GitHub存储库中公开。

</details>


### [189] [DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos](https://arxiv.org/abs/2506.10242)
**中文标题：DySS：基于动态查询和状态空间学习的高效多摄像头视频3D目标检测**

*Rajeev Yasarla,Shizhong Han,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: DySS introduces a dynamic query and state-space learning method for efficient 3D object detection from multi-camera videos, achieving superior performance and real-time inference.


<details>
  <summary>Details</summary>
Motivation: Existing methods for camera-based 3D object detection in BEV are either costly (dense features) or inefficient (sparse queries with large numbers). DySS aims to address these limitations by leveraging state-space learning and dynamic queries for better efficiency and performance.

Method: DySS uses a state-space model (SSM) to process sampled features over time, enhanced by auxiliary tasks (future prediction and masked reconstruction). It dynamically updates queries via merge, remove, and split operations to maintain a lean set of detection queries.

Result: DySS achieves 65.31 NDS and 57.4 mAP on nuScenes test split, outperforming state-of-the-art methods, and runs at 33 FPS on the val split.

Conclusion: DySS demonstrates that dynamic queries and state-space learning can significantly improve efficiency and performance in 3D object detection from multi-camera videos.

摘要: 基于摄像头的鸟瞰图（BEV）3D目标检测是自动驾驶中最重要的感知任务之一。早期方法依赖于密集的BEV特征，构建成本高昂。最近的研究探索了基于稀疏查询的检测方法，但仍需要大量查询，且在使用更多视频帧时计算成本较高。本文提出DySS，一种利用状态空间学习和动态查询的新方法。具体而言，DySS通过状态空间模型（SSM）逐步处理时间步长的采样特征，并通过未来预测和掩码重建等辅助任务优化SSM训练。SSM的状态提供了场景的高效且信息丰富的总结。基于状态空间学习特征，DySS通过合并、删除和拆分操作动态更新查询，保持网络中检测查询的精简和有效性。DySS在nuScenes测试集上取得了65.31 NDS和57.4 mAP的优异性能，优于最新技术。在验证集上，DySS达到56.2 NDS和46.2 mAP，并以33 FPS的实时推理速度运行。

</details>


### [190] [HalLoc: Token-level Localization of Hallucinations for Vision Language Models](https://arxiv.org/abs/2506.10286)
**中文标题：HalLoc：视觉语言模型中幻觉的标记级定位**

*Eunkyu Park,Minyeong Kim,Gunhee Kim*

Main category: cs.CV

TL;DR: HalLoc introduces a dataset and baseline model for efficient, probabilistic hallucination detection in vision-language models, enabling graded confidence outputs and low-overhead integration.


<details>
  <summary>Details</summary>
Motivation: Hallucinations in vision-language models undermine reliability, but current detection methods are computationally intensive and lack nuanced outcomes for real-world scenarios.

Method: HalLoc provides a 150K token-level annotated dataset for hallucination detection across VQA, instruction-following, and captioning tasks, alongside a baseline model for low-overhead detection.

Result: The dataset and model enable efficient, probabilistic hallucination detection with graded confidence, improving reliability without sacrificing efficiency.

Conclusion: HalLoc advances hallucination detection by offering a plug-and-play module for vision-language models, enhancing trustworthiness in real-world applications.

摘要: 幻觉对大型视觉语言模型的可靠性构成重大挑战，其检测对于确保关键应用中的准确性至关重要。当前的检测方法通常依赖于计算密集型模型，导致高延迟和资源需求。其确定性结果也无法应对现实场景中幻觉与真实信息界限模糊的情况。为解决这些问题，我们提出了HalLoc，一个为高效概率性幻觉检测设计的数据集。它包含15万个标记级注释样本，涵盖视觉问答（VQA）、指令跟随和图像描述任务中的幻觉类型。该数据集支持开发能够以分级置信度检测幻觉的模型，从而实现更明智的用户交互。此外，我们还引入了一个基于HalLoc训练的基线模型，提供低开销、并发的幻觉检测功能。该模型可无缝集成到现有视觉语言模型中，在保持效率的同时提高可靠性。这一即插即用的幻觉检测模块为增强视觉语言模型在现实应用中的可信度开辟了新途径。HalLoc数据集和代码已公开于：https://github.com/dbsltm/cvpr25_halloc。

</details>


### [191] [Uncertainty-Aware Deep Learning for Automated Skin Cancer Classification: A Comprehensive Evaluation](https://arxiv.org/abs/2506.10302)
**中文标题：不确定性感知深度学习在自动化皮肤癌分类中的综合评估**

*Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya*

Main category: cs.CV

TL;DR: The paper evaluates deep learning models for skin cancer classification, highlighting CLIP-based vision transformers as top performers and emphasizing the importance of uncertainty quantification (UQ) for reliable medical diagnosis.


<details>
  <summary>Details</summary>
Motivation: To improve skin cancer diagnosis by addressing data scarcity and lack of uncertainty awareness in deep learning models, ensuring both accuracy and reliability in clinical applications.

Method: Benchmarked pre-trained feature extractors (e.g., CLIP, ResNet50, DenseNet121) with traditional classifiers (e.g., SVM, XGBoost), then incorporated UQ techniques (MCD, Ensemble, EMCD) to assess prediction reliability.

Result: CLIP-based models, especially LAION CLIP ViT-H/14 with SVM, performed best. Ensemble methods balanced accuracy and uncertainty handling, while EMCD was more sensitive to uncertain predictions.

Conclusion: Integrating UQ into deep learning enhances both performance and trustworthiness in medical diagnosis, with ensemble methods offering a practical trade-off.

摘要: 准确可靠的皮肤癌诊断对于早期治疗和改善患者预后至关重要。深度学习（DL）模型在自动化皮肤癌分类中显示出潜力，但其性能可能受限于数据稀缺和缺乏不确定性感知。本研究基于HAM10000数据集，通过迁移学习和不确定性量化（UQ）对DL皮肤病变分类进行了综合评估。第一阶段，我们测试了多种预训练特征提取器（如CLIP变体、ResNet50、DenseNet121、VGG16和EfficientNet-V2-Large）与传统分类器（如SVM、XGBoost和逻辑回归）的组合。结果表明，基于CLIP的视觉变换器（尤其是LAION CLIP ViT-H/14与SVM结合）表现最佳。第二阶段，我们通过蒙特卡洛Dropout（MCD）、集成和集成蒙特卡洛Dropout（EMCD）引入UQ，不仅评估预测准确性，还评估模型输出的可靠性。使用不确定性感知指标（如UAcc、USen、USpe和UPre）评估这些模型。结果显示，集成方法在准确性和不确定性处理之间取得了良好平衡，而EMCD对不确定预测更敏感。本研究强调了将UQ整合到基于DL的医学诊断中的重要性，以提升实际临床应用中的性能和可信度。

</details>


### [192] [Towards Scalable SOAP Note Generation: A Weakly Supervised Multimodal Framework](https://arxiv.org/abs/2506.10328)
**中文标题：迈向可扩展的SOAP笔记生成：一种弱监督多模态框架**

*Sadia Kamal,Tim Oates,Joy Wan*

Main category: cs.CV

TL;DR: A weakly supervised multimodal framework is proposed to generate SOAP notes from lesion images and sparse clinical text, reducing manual annotation needs and achieving performance comparable to advanced models like GPT-4o.


<details>
  <summary>Details</summary>
Motivation: Manual SOAP note generation is labor-intensive and contributes to clinician burnout, especially in skin carcinoma cases, which are prevalent and costly.

Method: The framework uses weakly supervised learning with multimodal inputs (lesion images and sparse clinical text) to generate structured SOAP notes, minimizing reliance on manual annotations.

Result: The method performs comparably to GPT-4o, Claude, and DeepSeek Janus Pro, with novel metrics (MedConceptEval and CCS) validating clinical relevance.

Conclusion: The framework offers a scalable solution for SOAP note generation, reducing clinician burden and the need for large annotated datasets.

摘要: 皮肤癌是全球最常见的癌症形式，每年医疗支出超过80亿美元。在临床环境中，医生使用详细的SOAP（主观、客观、评估和计划）笔记记录患者就诊情况。然而，手动生成这些笔记耗时耗力，加剧了临床医生的职业倦怠。本研究提出了一种弱监督多模态框架，通过有限的输入（包括病变图像和稀疏的临床文本）生成结构化的SOAP笔记。该方法减少了对人工标注的依赖，实现了可扩展且临床可靠的文档生成，同时减轻了临床医生的负担并降低了对大规模标注数据的需求。我们的方法在关键临床相关性指标上表现与GPT-4o、Claude和DeepSeek Janus Pro相当。为评估临床质量，我们引入了两种新指标MedConceptEval和临床一致性评分（CCS），分别用于评估与专家医学概念的语义对齐和输入特征的临床一致性。

</details>


### [193] [Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video](https://arxiv.org/abs/2506.10331)
**中文标题：用户生成的全向视频音视频质量评估数据集与方法研究**

*Fei Zhao,Da Pan,Zelu Qi,Ping Shi*

Main category: cs.CV

TL;DR: The paper introduces a dataset and baseline model for audio-visual quality assessment (AVQA) of user-generated omnidirectional videos (UGC-ODVs), addressing a gap in research due to the growing popularity of the Metaverse.


<details>
  <summary>Details</summary>
Motivation: With the rise of the Metaverse, omnidirectional videos (ODVs) are shifting from professional to user-generated content, yet research on AVQA for UGC-ODVs is limited. This study aims to fill that gap.

Method: The authors constructed a UGC-ODV dataset with 300 videos captured by five individuals using two types of omnidirectional cameras, covering 10 scene types. They conducted subjective AVQA experiments to obtain Mean Opinion Scores (MOSs) and developed a baseline model with video and audio feature extraction and fusion modules.

Result: The baseline model achieved optimal performance on the proposed dataset, demonstrating its effectiveness for UGC-ODV AVQA.

Conclusion: The study provides a valuable dataset and baseline model to advance research in UGC-ODV AVQA, addressing a critical need in the field.

摘要: 随着元宇宙的兴起，全向视频（ODV）逐渐从专业生成内容（PGC）转向用户生成内容（UGC）。然而，关于ODV中音视频质量评估（AVQA）的研究仍然有限。为此，我们构建了一个UGC全向音视频（A/V）内容数据集。视频由五名个人使用两种不同类型的全向相机拍摄，共300个视频，涵盖10种不同的场景类型。在数据集上进行了主观AVQA实验，以获得A/V序列的平均意见分数（MOS）。随后，为了促进UGC-ODV AVQA领域的发展，我们在提出的数据集上构建了一个有效的AVQA基线模型，该基线模型包括视频特征提取模块、音频特征提取模块和音视频融合模块。实验结果表明，我们的模型在提出的数据集上实现了最佳性能。

</details>


### [194] [Using Vision Language Models to Detect Students' Academic Emotion through Facial Expressions](https://arxiv.org/abs/2506.10334)
**中文标题：利用视觉语言模型通过面部表情检测学生的学业情绪**

*Deliang Wang,Chao Yang,Gaowei Chen*

Main category: cs.CV

TL;DR: The study explores using Vision-Language Models (VLMs) to detect students' academic emotions from facial expressions in online learning, finding moderate success with Qwen2.5-VL-7B-Instruct outperforming Llama-3.2-11B-Vision-Instruct, especially in recognizing happy and confused expressions.


<details>
  <summary>Details</summary>
Motivation: Traditional supervised machine learning models for analyzing academic emotions struggle with generalization and require extensive data collection and training. VLMs offer a promising zero-shot alternative.

Method: Employed two VLMs (Llama-3.2-11B-Vision-Instruct and Qwen2.5-VL-7B-Instruct) to analyze 5,000 images of students' facial expressions (confused, distracted, happy, neutral, tired) using zero-shot prompting.

Result: Both models showed moderate performance, with Qwen2.5-VL-7B-Instruct outperforming Llama-3.2-11B-Vision-Instruct. They excelled in detecting happy emotions but failed to identify distracted behavior. Qwen2.5-VL-7B-Instruct performed well in recognizing confused expressions.

Conclusion: VLMs, particularly Qwen2.5-VL-7B-Instruct, show potential for practical applications in academic emotion detection, especially for identifying student confusion.

摘要: 学生的学业情绪显著影响其社会行为和学习表现。传统方法主要依赖监督式机器学习算法来自动准确分析这些情绪，但这些模型往往难以在不同情境中泛化，需要反复进行数据收集、标注和训练。视觉语言模型（VLMs）的出现提供了一种有前景的替代方案，通过零样本提示实现视觉识别任务的泛化，而无需微调。本研究探讨了VLMs在在线学习环境中通过面部表情分析学生学业情绪的潜力。我们采用了两种VLMs（Llama-3.2-11B-Vision-Instruct和Qwen2.5-VL-7B-Instruct），通过零样本提示分析了5,000张描绘困惑、分心、快乐、中立和疲惫表情的图像。初步结果表明，两种模型在学业面部表情识别中表现出中等性能，其中Qwen2.5-VL-7B-Instruct优于Llama-3.2-11B-Vision-Instruct。值得注意的是，两种模型在识别学生的快乐情绪方面表现优异，但未能检测到分心行为。此外，Qwen2.5-VL-7B-Instruct在识别学生的困惑表情方面表现出相对较高的性能，突显了其在识别引起学生困惑的内容方面的实际应用潜力。

</details>


### [195] [PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting](https://arxiv.org/abs/2506.10335)
**中文标题：PointGS：基于高斯泼溅的点注意力感知稀疏视图合成**

*Lintao Xiang,Hongpei Zheng,Yating Huang,Qijun Yang,Hujun Yin*

Main category: cs.CV

TL;DR: The paper introduces PointGS, a framework for high-quality 3D rendering from sparse views using Gaussian splatting, outperforming NeRF-based methods and improving over existing 3DGS approaches.


<details>
  <summary>Details</summary>
Motivation: Existing 3D Gaussian splatting (3DGS) methods require many calibrated views to avoid overfitting and maintain rendering quality. The paper aims to enable high-quality rendering from sparse views by enhancing point-wise feature representation.

Method: The method uses a stereo foundation model for camera pose estimation and dense point cloud reconstruction. It encodes multiscale 2D appearance features into 3D Gaussians and employs a self-attention-based point interaction network to enrich features, decoded into Gaussian parameters via MLPs for rendering.

Result: The method outperforms NeRF-based approaches and achieves competitive performance under few-shot settings compared to state-of-the-art 3DGS methods.

Conclusion: PointGS enables real-time, high-quality rendering from sparse views, addressing limitations of existing 3DGS methods and setting a new benchmark for few-shot 3D rendering.

摘要: 3D高斯泼溅（3DGS）是一种创新的渲染技术，通过利用显式的3D场景表示，在渲染速度和视觉质量上超越了神经辐射场（NeRF）。现有的3DGS方法需要大量校准视图以生成一致且完整的场景表示。当输入视图有限时，3DGS容易过拟合训练视图，导致渲染质量显著下降。为解决这一限制，我们提出了一种点级特征感知的高斯泼溅框架，能够从稀疏训练视图中实现实时高质量渲染。具体而言，我们首先使用最新的立体基础模型估计准确的相机姿态并重建密集点云以初始化高斯分布。然后，我们通过采样和聚合稀疏输入的多尺度2D外观特征，为每个3D高斯编码颜色属性。为增强点级外观表示，我们设计了一个基于自注意力机制的点交互网络，使每个高斯点能够与其最近邻交互。这些丰富的特征随后通过两个轻量级多层感知器（MLP）解码为高斯参数以进行最终渲染。在多个基准测试上的广泛实验表明，我们的方法显著优于基于NeRF的方法，并在少样本设置下与最先进的3DGS方法相比具有竞争力。

</details>


### [196] [GeoCAD: Local Geometry-Controllable CAD Generation](https://arxiv.org/abs/2506.10337)
**中文标题：GeoCAD：局部几何可控的CAD生成**

*Zhanwei Zhang,Kaiyuan Liu,Junjie Liu,Wenxiao Wang,Binbin Lin,Liang Xie,Chen Shen,Deng Cai*

Main category: cs.CV

TL;DR: GeoCAD introduces a method for local geometry-controllable CAD generation, enabling users to modify specific parts of CAD models while following geometric instructions. It uses complementary captioning and LLMs to achieve high-quality, valid, and consistent results.


<details>
  <summary>Details</summary>
Motivation: Existing CAD generation methods struggle with following textual instructions or focusing on local parts, limiting design efficiency and customization. GeoCAD aims to overcome these challenges by providing a user-friendly, geometry-controllable solution.

Method: GeoCAD employs a complementary captioning strategy (vertex-based and VLLM-based) to annotate local parts. It trains LLMs to predict masked parts using geometric instructions and remaining parts as input, enabling local modifications during inference.

Result: Experiments show GeoCAD excels in generation quality, validity, and text-to-CAD consistency, successfully modifying local parts while adhering to geometric instructions.

Conclusion: GeoCAD offers an effective solution for local geometry-controllable CAD generation, enhancing design flexibility and efficiency.

摘要: 局部几何可控的计算机辅助设计（CAD）生成旨在自动修改CAD模型的局部部分，提高设计效率。同时，它确保新生成的局部部分的形状遵循用户特定的几何指令（例如，等腰直角三角形或切掉一角的矩形）。然而，现有方法在实现这一目标时面临挑战。具体而言，它们要么无法遵循文本指令，要么无法专注于局部部分。为解决这一局限，我们提出了GeoCAD，一种用户友好且局部几何可控的CAD生成方法。具体来说，我们首先提出了一种互补标注策略，为局部部分生成几何指令。该策略包括基于顶点的标注和基于VLLM的标注，分别用于系统标注简单和复杂的部分。通过这种方式，我们总共标注了约221k个不同的局部部分。在训练阶段，给定一个CAD模型，我们随机掩码一个局部部分。然后，利用其几何指令和剩余部分作为输入，提示大型语言模型（LLMs）预测被掩码的部分。在推理阶段，用户可以指定任何局部部分进行修改，同时遵循多种预定义的几何指令。大量实验证明了GeoCAD在生成质量、有效性和文本到CAD一致性方面的有效性。代码将在https://github.com/Zhanwei-Z/GeoCAD提供。

</details>


### [197] [UrbanSense:AFramework for Quantitative Analysis of Urban Streetscapes leveraging Vision Large Language Models](https://arxiv.org/abs/2506.10342)
**中文标题：UrbanSense：基于视觉大语言模型的定量分析城市街景框架**

*Jun Yin,Jing Zhong,Peilin Li,Pengyu Zeng,Miao Zhang,Ran Luo,Shuai Lu*

Main category: cs.CV

TL;DR: The paper proposes UrbanSense, a vision-language-model-based framework for automated and scalable analysis of urban streetscape styles, validated by high accuracy in capturing stylistic differences.


<details>
  <summary>Details</summary>
Motivation: To address the lack of standardized and objective methods in urban cultural studies, the study aims to leverage vision-language models for quantitative analysis of urban streetscapes.

Method: Developed UrbanSense, a multimodal framework using vision-language models, and constructed UrbanDiffBench, a dataset of urban streetscape images from different periods and regions.

Result: Over 80% of generated descriptions passed statistical tests, and high Phi scores (0.912 for cities, 0.833 for periods) confirmed the method's effectiveness in capturing stylistic differences.

Conclusion: UrbanSense offers a scientifically grounded approach to quantify urban style evolution, enhancing objectivity in urban form research.

摘要: 由于地理、时间、历史和社会政治因素的影响，不同城市的城市文化和建筑风格差异显著。理解这些差异对于预测城市未来演变至关重要。作为中国历史延续和现代创新的代表案例，北京和深圳为探索城市街景的转变提供了宝贵视角。然而，传统的城市文化研究方法通常依赖专家解读和历史文献，难以在不同背景下标准化。为此，我们提出了一种基于视觉语言模型的多模态研究框架，实现了对城市街景风格差异的自动化和可扩展分析。这种方法增强了城市形态研究的客观性和数据驱动性。本研究的贡献如下：首先，我们构建了UrbanDiffBench，一个包含不同时期和地区建筑图像的精选城市街景数据集。其次，我们开发了UrbanSense，首个基于视觉语言模型的城市街景分析框架，实现了城市风格表示的定量生成和比较。第三，实验结果表明，超过80%的生成描述通过了t检验（p小于0.05）。主观评价中的高Phi分数（城市为0.912，时期为0.833）证实了该方法捕捉细微风格差异的能力。这些结果凸显了该方法在量化和解释城市风格演变方面的潜力，为未来设计提供了科学依据。

</details>


### [198] [RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration](https://arxiv.org/abs/2506.10344)
**中文标题：RealKeyMorph：基于真实世界坐标的关键点用于分辨率无关的图像配准**

*Mina C. Moghadam,Alan Q. Wang,Omer Taub,Martin R. Prince,Mert R. Sabuncu*

Main category: cs.CV

TL;DR: RealKeyMorph (RKM) is a resolution-agnostic image registration method that avoids resampling by using keypoints in real-world coordinates, improving accuracy for medical images with varying resolutions.


<details>
  <summary>Details</summary>
Motivation: Existing machine learning-based registration methods resample images to fixed resolutions, introducing artifacts. RKM aims to avoid this by working directly with raw data in real-world coordinates.

Method: RKM extends KeyMorph by training a network to learn keypoints in real-world coordinates using the scanner's affine matrix, enabling resolution-agnostic registration without resampling.

Result: RKM demonstrates improved performance for registering 2D abdominal MRIs and 3D brain volumes with varying resolutions.

Conclusion: RKM provides a robust, resolution-agnostic solution for medical image registration, avoiding artifacts from resampling.

摘要: 许多实际场景需要对空间分辨率不同的医学图像进行配准，这种差异可能源于像素间距、切片厚度和视野等图像采集参数的不同。然而，所有先前基于机器学习的配准技术都将图像重采样到固定分辨率。这种做法并不理想，因为重采样可能因插值而引入伪影。为此，我们提出了RealKeyMorph（RKM），一种分辨率无关的图像配准方法。RKM是KeyMorph的扩展，KeyMorph是一种通过训练网络学习给定图像对的对应关键点，然后通过闭式关键点匹配步骤推导对齐变换的配准框架。为了避免重采样并直接在原始数据上操作，RKM在扫描仪的真实世界坐标中输出关键点。为此，我们利用了扫描仪（如MRI机器）生成的仿射矩阵，该矩阵编码了从体素坐标到真实世界坐标的映射。通过将关键点转换到真实世界空间并将其整合到训练过程中，RKM有效地使提取的关键点与分辨率无关。在实验中，我们展示了RKM在正交2D腹部MRI堆栈配准任务以及分辨率变化的3D脑数据集上的优势。

</details>


### [199] [Motion-R1: Chain-of-Thought Reasoning and Reinforcement Learning for Human Motion Generation](https://arxiv.org/abs/2506.10353)
**中文标题：Motion-R1：基于思维链推理和强化学习的人体运动生成**

*Runqi Ouyang,Haoyun Li,Zhenyuan Zhang,Xiaofeng Wang,Zheng Zhu,Guan Huang,Xingang Wang*

Main category: cs.CV

TL;DR: Motion-R1 introduces a Chain-of-Thought reasoning framework combined with reinforcement learning to improve text-to-motion generation, addressing issues of controllability, consistency, and diversity.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-motion generation methods lack deep linguistic understanding and logical reasoning, leading to inconsistent and less controllable motion outputs. Motion-R1 aims to enhance these aspects by integrating structured reasoning.

Method: Motion-R1 decomposes complex textual instructions into structured action paths using Chain-of-Thought reasoning and employs Group Relative Policy Optimization for joint optimization of reasoning and motion synthesis.

Result: Motion-R1 outperforms state-of-the-art methods in scenarios requiring nuanced semantic understanding and long-term coherence, demonstrating competitive performance across benchmarks.

Conclusion: The integration of Chain-of-Thought reasoning and reinforcement learning in Motion-R1 significantly improves motion generation, offering better controllability and semantic alignment.

摘要: 近年来，大型语言模型在自然语言理解和推理方面的进展为文本到运动的生成开辟了新途径。尽管现有方法在语义对齐和运动合成方面取得了显著进展，但它们通常依赖于端到端的映射策略，未能捕捉深层次的语言结构和逻辑推理。因此，生成的运动往往缺乏可控性、一致性和多样性。为解决这些问题，我们提出了Motion-R1，一个统一的运动-语言建模框架，集成了思维链机制。通过将复杂的文本指令显式分解为逻辑结构的动作路径，Motion-R1为运动生成提供了高级语义指导，显著增强了模型对多步骤、长时程和组合丰富指令的解释和执行能力。为训练模型，我们采用了Group Relative Policy Optimization，一种专为大型模型设计的强化学习算法，利用运动质量反馈联合优化推理链和运动合成。在多个基准数据集上的广泛实验表明，Motion-R1在需要细致语义理解和长期时间一致性的场景中，性能优于或与现有最优方法相当。代码、模型和数据将公开提供。

</details>


### [200] [FaceLiVT: Face Recognition using Linear Vision Transformer with Structural Reparameterization For Mobile Device](https://arxiv.org/abs/2506.10361)
**中文标题：FaceLiVT：基于线性视觉变换器与结构重参数化的移动设备人脸识别**

*Novendra Setyawan,Chi-Chia Sun,Mao-Hsiu Hsu,Wen-Kai Kuo,Jun-Wei Hsieh*

Main category: cs.CV

TL;DR: FaceLiVT is a lightweight face recognition model combining CNN-Transformer architecture with Multi-Head Linear Attention, achieving high accuracy and speed on mobile devices.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient face recognition model for mobile devices that balances accuracy and computational complexity.

Method: Integrates hybrid CNN-Transformer architecture with Multi-Head Linear Attention (MHLA) and reparameterized token mixer to reduce computational cost.

Result: Outperforms state-of-the-art lightweight models on benchmarks (LFW, CFP-FP, etc.), with 8.6x speedup over EdgeFace and 21.2x over pure ViT models.

Conclusion: FaceLiVT provides a practical, high-performance solution for real-time face recognition on resource-constrained platforms.

摘要: 本文介绍了FaceLiVT，一种轻量级但强大的人脸识别模型，它结合了混合卷积神经网络（CNN）-变换器架构与创新的轻量级多头线性注意力（MHLA）机制。通过将MHLA与重参数化的令牌混合器结合，FaceLiVT在保持竞争力的准确性的同时有效降低了计算复杂度。在包括LFW、CFP-FP、AgeDB-30、IJB-B和IJB-C等具有挑战性的基准测试中进行的广泛评估表明，其性能优于最先进的轻量级模型。MHLA显著提高了推理速度，使FaceLiVT在移动设备上能够以较低的延迟实现高精度。具体而言，FaceLiVT比最近针对边缘设备优化的混合CNN-变换器模型EdgeFace快8.6倍，比纯ViT模型快21.2倍。凭借其平衡的设计，FaceLiVT为资源受限平台上的实时人脸识别提供了高效且实用的解决方案。

</details>


### [201] [FSATFusion: Frequency-Spatial Attention Transformer for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.10366)
**中文标题：FSATFusion：基于频率-空间注意力Transformer的红外与可见光图像融合方法**

*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui,Yuhan Lyu*

Main category: cs.CV

TL;DR: FSATFusion is a novel end-to-end network for infrared and visible image fusion, using a frequency-spatial attention Transformer to improve feature extraction and fusion performance.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning methods for infrared and visible image fusion rely on CNNs, which struggle with global context capture, leading to information loss and suboptimal fusion results.

Method: FSATFusion introduces a frequency-spatial attention Transformer (FSAT) module with an improved Transformer module (ITM) to enhance global context extraction and feature discrimination.

Result: FSATFusion outperforms state-of-the-art methods in fusion quality and efficiency, demonstrates strong generalization, and excels in downstream tasks like object detection.

Conclusion: FSATFusion offers superior performance and generalization for infrared and visible image fusion, validated by extensive experiments.

摘要: 红外与可见光图像融合（IVIF）因其在下游应用中的优异表现，受到学术界和工业界的广泛关注。现有的深度学习方法通常利用卷积神经网络提取图像特征，但卷积操作的固有局限性可能导致全局上下文信息丢失，从而限制融合性能。为解决这一问题，我们提出了一种端到端的融合网络——频率-空间注意力Transformer融合网络（FSATFusion）。FSATFusion包含一个频率-空间注意力Transformer（FSAT）模块，旨在有效提取源图像的判别性特征。该FSAT模块包含一个频率-空间注意力机制（FSAM），能够从特征图中提取显著特征。此外，我们还提出了一种改进的Transformer模块（ITM），以增强原始Transformer的全局上下文信息提取能力。通过定性和定量对比实验，我们证明了FSATFusion在融合质量和效率上优于其他最先进方法。此外，我们的网络在未经任何修改的情况下，成功应用于另外两项任务，验证了FSATFusion的出色泛化能力。最后，目标检测实验证明了FSATFusion在下游视觉任务中的优越性。代码已开源：https://github.com/Lmmh058/FSATFusion。

</details>


### [202] [Revisiting Transformers with Insights from Image Filtering](https://arxiv.org/abs/2506.10371)
**中文标题：从图像滤波的视角重新审视Transformer**

*Laziz U. Abdullaev,Maksim Tkachenko,Tan M. Nguyen*

Main category: cs.CV

TL;DR: The paper develops an image processing framework to interpret self-attention in Transformers, explaining components like positional encoding and residual connections, while also improving model performance.


<details>
  <summary>Details</summary>
Motivation: To establish a theoretical foundation for understanding self-attention in Transformers and enhance interpretability and performance.

Method: Introduces a unifying image processing framework to analyze self-attention and its components, along with architectural modifications inspired by image filtering.

Result: The framework improves interpretability and empirically enhances accuracy, robustness, and long-sequence understanding in language and vision tasks.

Conclusion: The study bridges gaps in understanding self-attention and demonstrates practical benefits of image processing-inspired modifications in Transformers.

摘要: 自注意力机制作为Transformer等最先进深度学习架构的核心，很大程度上是启发式驱动的，且难以解释。因此，建立坚实的理论基础以解释其成功与局限性已成为近年研究的重点。一些研究尝试从图像去噪和非参数回归的角度理解自注意力，但现有框架仍缺乏对自注意力及其变体中各组件的深入机制解释。本研究旨在通过开发一个统一的图像处理框架，不仅解释自注意力计算本身，还阐明位置编码和残差连接等组件的作用，包括后续变体。我们还指出了这两种概念间的潜在差异，并努力弥合这一差距。我们在Transformer中引入了两种独立的架构修改。虽然主要目标是可解释性，但实验表明，受图像处理启发的修改还能显著提高语言和视觉任务中的准确性、抗数据污染和对抗攻击的鲁棒性，以及长序列理解能力。

</details>


### [203] [Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial](https://arxiv.org/abs/2506.10386)
**中文标题：利用6自由度位姿基础模型进行海洋沉积物掩埋测绘**

*Jerry Yan,Chinmay Talegaonkar,Nicholas Antipa,Eric Terrill,Sophia Merrifield*

Main category: cs.CV

TL;DR: PoseIDON, a computer vision pipeline, uses deep foundation models and multiview photogrammetry to estimate 6DoF object pose and seafloor orientation from ROV video, achieving ~10 cm burial depth error.


<details>
  <summary>Details</summary>
Motivation: Accurate burial depth estimation of seafloor objects is challenging due to occlusion, poor visibility, and degradation, yet crucial for ecological risk assessment and pollutant transport analysis.

Method: Combines deep foundation model features with multiview photogrammetry to align CAD models with observed imagery and fit a local planar seafloor approximation.

Result: Validated on 54 objects, achieving ~10 cm mean burial depth error and revealing spatial burial patterns linked to sediment transport.

Conclusion: PoseIDON enables scalable, non-invasive seafloor burial mapping, aiding environmental assessments at contaminated sites.

摘要: 海底人为物体的掩埋状态为局部沉积动力学提供了见解，同时也对评估生态风险、潜在污染物迁移以及危险材料（如弹药）的回收或缓解策略的可行性至关重要。由于部分遮挡、能见度差和物体退化，从遥感图像中准确估计掩埋深度仍然困难。本研究提出了一种名为PoseIDON的计算机视觉流程，结合深度基础模型特征与多视角摄影测量技术，从ROV视频中估计物体的六自由度位姿及周围海底的朝向。掩埋深度通过将物体的CAD模型与观测图像对齐并拟合局部平面海底近似来推断。该方法在圣佩德罗盆地历史海洋倾倒场记录的54个物体（包括桶和弹药）的视频中进行了验证。模型实现了约10厘米的平均掩埋深度误差，并解析了反映底层沉积物迁移过程的空间掩埋模式。这种方法实现了海底掩埋的可扩展、非侵入式测绘，并支持污染场地的环境评估。

</details>


### [204] [DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Transformer and Mamba](https://arxiv.org/abs/2506.10390)
**中文标题：DART：用于视觉Transformer和Mamba的可微分动态自适应区域分词器**

*Shicheng Yin,Kaixuan Yin,Yang Liu,Weixing Chen,Liang Lin*

Main category: cs.CV

TL;DR: DART introduces a dynamic adaptive region tokenizer for Vision Transformer and Mamba, improving accuracy by 2.1% on ImageNet-1K with 45% FLOPs reduction by focusing on information-rich areas.


<details>
  <summary>Details</summary>
Motivation: Fixed-size patches in Vision Transformer and Mamba often encode excessive background or miss critical details, especially for sparsely distributed objects.

Method: DART uses learnable region scores and differentiable quantile operations to adaptively partition images into varying-sized patches, allocating denser tokens to information-rich areas.

Result: DART improves accuracy by 2.1% on DeiT (ImageNet-1K) with 45% FLOPs reduction, outperforming uniform token density methods.

Conclusion: DART consistently enhances accuracy with minimal computational overhead, offering an efficient alternative for vision tasks.

摘要: 近年来，非卷积模型如视觉Transformer（ViT）和视觉Mamba（Vim）在计算机视觉任务中取得了显著性能。然而，它们依赖固定大小的图像块，常常导致对背景区域的过度编码或对关键局部细节的遗漏，尤其是在信息稀疏分布时。为此，我们提出了一种完全可微分的动态自适应区域分词器（DART），能够根据内容自适应地将图像划分为不同大小的块。DART通过结合可学习的区域评分和分段可微分分位数操作，将更密集的令牌分配给信息丰富的区域。尽管仅增加了约100万（1M）额外参数，DART在DeiT（ImageNet-1K）上提升了2.1%的准确率。与那些通过均匀增加令牌密度来捕捉细粒度细节的方法不同，DART提供了一种更高效的替代方案，实现了45%的FLOPs减少和更优性能。在DeiT、Vim和VideoMamba上的大量实验表明，DART在几乎不增加甚至减少计算开销的情况下持续提升准确率。代码发布于https://github.com/HCPLab-SYSU/DART。

</details>


### [205] [ReconMOST: Multi-Layer Sea Temperature Reconstruction with Observations-Guided Diffusion](https://arxiv.org/abs/2506.10391)
**中文标题：ReconMOST：基于观测引导扩散的多层海水温度重建**

*Yuanyi Song,Pumeng Lyu,Ben Fei,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.CV

TL;DR: ReconMOST proposes a data-driven guided diffusion model for multi-layer sea temperature reconstruction, leveraging historical simulation data and sparse observations to achieve accurate results despite missing data.


<details>
  <summary>Details</summary>
Motivation: Existing methods for ocean temperature reconstruction face challenges like sparse data and computational costs, while ML-based approaches are limited to surface or local regions. ReconMOST aims to address these limitations for global, multi-layer reconstruction.

Method: The framework pre-trains an unconditional diffusion model on historical simulation data, then uses sparse observational data to guide the reverse diffusion process for accurate reconstruction, even in data-sparse regions.

Result: The method achieves MSE values of 0.049 (guidance), 0.680 (reconstruction), and 0.633 (total), demonstrating effectiveness and robustness in handling over 92.5% missing data.

Conclusion: ReconMOST extends ML-based reconstruction to global, multi-layer settings, offering high accuracy, spatial resolution, and generalization, validated by experiments on CMIP6 and EN4 data.

摘要: 准确重建海洋温度对于反映全球气候动态和支持海洋气象研究至关重要。传统方法因数据稀疏、算法复杂和计算成本高而面临挑战，而机器学习方法的应用仍局限于海表和局部区域的温度重建，且难以解决云遮挡等问题。为解决这些限制，本文提出ReconMOST，一种数据驱动的引导扩散模型框架，用于多层海水温度重建。具体而言，我们首先利用大量历史数值模拟数据预训练一个无条件扩散模型，使其能够学习物理一致的海洋温度场分布模式。在生成阶段，稀疏但高精度的现场观测数据被用作反向扩散过程的引导点，生成准确的重建结果。重要的是，在缺乏直接观测数据的区域，预训练中学习的物理一致的空间分布模式能够实现隐式引导和物理合理的重建。我们的方法将基于机器学习的海表温度重建扩展到全球多层场景，处理超过92.5%的缺失数据，同时保持重建精度、空间分辨率和优异的泛化能力。我们在CMIP6数值模拟数据上预训练模型，并在CMIP6和EN4分析数据上进行引导重建实验。均方误差（MSE）结果分别为引导0.049、重建0.680和总体0.633，证明了所提框架的有效性和鲁棒性。源代码可在https://github.com/norsheep/ReconMOST获取。

</details>


### [206] [Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation](https://arxiv.org/abs/2506.10395)
**中文标题：Pisces：一种用于图像理解与生成的自回归基础模型**

*Zhiyang Xu,Jiuhai Chen,Zhaojiang Lin,Xichen Pan,Lifu Huang,Tianyi Zhou,Madian Khabsa,Qifan Wang,Di Jin,Michihiro Yasunaga,Lili Yu,Xi Victoria Lin,Shaoliang Nie*

Main category: cs.CV

TL;DR: Pisces is an auto-regressive multimodal foundation model that excels in both image understanding and generation through a novel decoupled visual encoding architecture and tailored training techniques.


<details>
  <summary>Details</summary>
Motivation: Unified models often underperform compared to specialized models in image understanding and generation due to differences in visual features and training processes. Pisces aims to bridge this gap.

Method: Pisces uses a decoupled visual encoding architecture and optimized training techniques for multimodal generation, combined with meticulous data curation, pretraining, and finetuning.

Result: Pisces achieves competitive performance in over 20 image understanding benchmarks and robust generative capabilities on GenEval.

Conclusion: Pisces demonstrates the benefits of separate visual encoders and the synergy between image understanding and generation, advancing unified multimodal models.

摘要: 近年来，大型语言模型（LLMs）的进展使得多模态基础模型能够在统一框架内处理图像理解和生成任务。然而，统一模型在这两项任务中的表现往往逊色于专用模型。开发统一模型的一个关键挑战在于图像理解与生成所需的视觉特征存在固有差异，且每种模态所需的训练过程也截然不同。本文提出Pisces，一种自回归多模态基础模型，通过新颖的解耦视觉编码架构和针对多模态生成优化的训练技术来解决这一挑战。结合精细的数据整理、预训练和微调，Pisces在图像理解和生成任务中均表现出色。我们在20多个公开的图像理解基准上评估Pisces，结果显示其在广泛任务中表现优异。此外，在广泛采用的图像生成基准GenEval上，Pisces展现出强大的生成能力。我们的深入分析揭示了图像理解与生成之间的协同关系，以及使用独立视觉编码器的优势，推动了统一多模态模型领域的发展。

</details>


### [207] [It's Not the Target, It's the Background: Rethinking Infrared Small Target Detection via Deep Patch-Free Low-Rank Representations](https://arxiv.org/abs/2506.10425)
**中文标题：目标不重要，背景才是关键：基于深度无块低秩表示的红外小目标检测新思路**

*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: The paper introduces LRRNet, a novel end-to-end framework for infrared small target detection (IRSTD) that leverages the low-rank property of backgrounds, achieving superior performance in accuracy, robustness, and speed.


<details>
  <summary>Details</summary>
Motivation: IRSTD is challenging due to low signal-to-clutter ratios, diverse target morphologies, and weak visual cues. Existing deep learning methods struggle with unstable performance, prompting the need for a more effective approach.

Method: LRRNet adopts a compression--reconstruction--subtraction (CRS) paradigm to model low-rank background representations directly in the image domain, avoiding patch-based processing or explicit matrix decomposition.

Result: LRRNet outperforms 38 state-of-the-art methods in detection accuracy, robustness, and computational efficiency, achieving real-time performance at 82.34 FPS and demonstrating resilience to sensor noise.

Conclusion: The study successfully demonstrates the effectiveness of learning low-rank background structures directly with deep neural networks, offering a robust and efficient solution for IRSTD.

摘要: 红外小目标检测（IRSTD）在复杂背景下仍是一项长期挑战，原因包括低信杂比（SCR）、目标形态多样以及缺乏显著视觉特征。尽管近期深度学习方法试图学习判别性表示，但小目标的内在多变性和弱先验常导致性能不稳定。本文提出了一种新颖的端到端IRSTD框架LRRNet，利用红外图像背景的低秩特性。受杂乱场景物理可压缩性的启发，该方法采用压缩-重建-减除（CRS）范式，直接在图像域中建模结构感知的低秩背景表示，无需依赖基于块的处理或显式矩阵分解。据我们所知，这是首个通过深度神经网络端到端直接学习低秩背景结构的工作。在多个公共数据集上的大量实验表明，LRRNet在检测精度、鲁棒性和计算效率方面优于38种最先进方法，且以平均82.34 FPS的速度实现实时性能。在具有挑战性的NoisySIRST数据集上的评估进一步证实了模型对传感器噪声的鲁棒性。源代码将在论文录用后公开。

</details>


### [208] [MF2Summ: Multimodal Fusion for Video Summarization with Temporal Alignment](https://arxiv.org/abs/2506.10430)
**中文标题：MF2Summ：基于时间对齐的多模态融合视频摘要方法**

*Shuo wang,Jihao Zhang*

Main category: cs.CV

TL;DR: MF2Summ is a multimodal video summarization model that integrates visual and auditory features using cross-modal attention and temporal alignment, outperforming existing methods on SumMe and TVSum datasets.


<details>
  <summary>Details</summary>
Motivation: Traditional video summarization methods rely on a single modality (visual), missing the semantic richness of videos. MF2Summ aims to leverage multimodal content (visual and auditory) for more effective summarization.

Method: MF2Summ uses a five-stage process: feature extraction (GoogLeNet for visual, SoundNet for auditory), cross-modal attention interaction, feature fusion, segment prediction (importance, location, center-ness), and key shot selection (NMS and KTS algorithm).

Result: MF2Summ improves F1-scores by 1.9% and 0.6% over DSNet on SumMe and TVSum datasets, respectively, and performs competitively against other state-of-the-art methods.

Conclusion: MF2Summ demonstrates the effectiveness of multimodal fusion and temporal alignment in video summarization, achieving superior performance by integrating visual and auditory features.

摘要: 随着在线视频内容的迅速增长，有效的视频摘要技术变得尤为重要。传统方法通常仅依赖单一模态（通常是视觉），难以捕捉视频的全部语义丰富性。本文提出了MF2Summ，一种基于多模态内容理解的新型视频摘要模型，整合了视觉和听觉信息。MF2Summ采用五阶段流程：特征提取、跨模态注意力交互、特征融合、片段预测和关键镜头选择。视觉特征通过预训练的GoogLeNet模型提取，听觉特征则通过SoundNet提取。融合机制的核心包括跨模态Transformer和对齐引导的自注意力Transformer，旨在有效建模模态间依赖和时间对应关系。预测片段的重要性、位置和中心性后，使用非极大值抑制（NMS）和核时间分割（KTS）算法选择关键镜头。在SumMe和TVSum数据集上的实验结果表明，MF2Summ表现出色，F1分数分别比DSNet模型提高了1.9%和0.6%，并优于其他最先进方法。

</details>


### [209] [Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts](https://arxiv.org/abs/2506.10452)
**中文标题：面向缺失模态和分布偏移的鲁棒多模态情感识别**

*Guowei Zhong,Ruohong Huan,Mingzhen Wu,Ronghua Liang,Peng Chen*

Main category: cs.CV

TL;DR: The paper proposes CIDer, a robust Multimodal Emotion Recognition (MER) framework, addressing missing modalities and OOD data through self-distillation and causal inference, achieving efficient performance with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Existing MER methods struggle with missing modalities and OOD data, often using complex models or excessive parameters. The paper aims to develop a practical and efficient solution.

Method: CIDer combines Model-Specific Self-Distillation (MSSD) for robustness under missing modalities and Model-Agnostic Causal Inference (MACI) for OOD generalization, with modules like WSAM and MCT for efficiency.

Result: CIDer outperforms state-of-the-art methods in handling missing modalities and OOD data, with fewer parameters and faster training.

Conclusion: CIDer provides a robust and efficient solution for MER, addressing both missing modalities and OOD challenges, with potential for broader applications.

摘要: 近年来，多模态情感识别（MER）在应对模态缺失和分布外（OOD）数据时面临挑战。现有方法通常依赖于特定模型或引入过多参数，限制了其实用性。为解决这些问题，我们提出了一种新型鲁棒MER框架——因果推断蒸馏器（CIDer），并引入了一项新任务——随机模态特征缺失（RMFM），以泛化模态缺失的定义。CIDer整合了两个关键组件：模型特定自蒸馏（MSSD）模块和模型无关因果推断（MACI）模块。MSSD通过低层特征、注意力图和高层表示的权重共享自蒸馏方法，增强了RMFM任务下的鲁棒性。此外，词级自对齐注意力模块（WSAM）降低了计算复杂度，而多模态复合变换器（MCT）实现了高效的多模态融合。为应对OOD挑战，MACI采用定制因果图，通过多模态因果模块（MCM）和细粒度反事实文本来缓解标签和语言偏差。值得注意的是，MACI可以独立地以最少的额外参数提升OOD泛化能力。此外，我们还引入了重新划分的MER OOD数据集。实验结果表明，与现有方法相比，CIDer在RMFM和OOD场景下均表现出鲁棒性能，且参数更少、训练更快。本工作的实现已公开于https://github.com/gw-zhong/CIDer。

</details>


### [210] [Rethinking Generative Human Video Coding with Implicit Motion Transformation](https://arxiv.org/abs/2506.10453)
**中文标题：重新思考基于隐式运动变换的生成式人体视频编码**

*Bolin Chen,Ru-Ling Liao,Jie Chen,Yan Ye*

Main category: cs.CV

TL;DR: The paper proposes an Implicit Motion Transformation (IMT) paradigm to improve Generative Human Video Coding (GHVC), addressing challenges in human body video compression by replacing explicit motion guidance with implicit motion features for better reconstruction quality.


<details>
  <summary>Details</summary>
Motivation: Traditional generative video codecs using explicit motion fields struggle with human body videos due to complex motion patterns, leading to distortions. The paper aims to overcome this by exploring implicit motion transformation for better compression and reconstruction.

Method: The paper introduces IMT, which transforms compact visual features into implicit motion guidance for human body signal reconstruction, avoiding the limitations of explicit motion-based methods.

Result: Experiments show that IMT improves GHVC, achieving high-efficiency compression and high-fidelity synthesis compared to explicit motion-based approaches.

Conclusion: IMT effectively addresses the limitations of explicit motion in GHVC, offering a promising direction for human body video compression with better reconstruction quality.

摘要: 与传统基于混合的视频编解码器相比，生成式视频编解码器通过将高维信号演化为紧凑的特征表示以实现编码端的比特流紧凑性，并在解码端开发显式运动场作为中间监督以实现高质量重建。这一范式在人脸视频压缩中取得了显著成功。然而，与面部视频相比，人体视频由于其更复杂多样的运动模式而面临更大挑战，即在生成式人体视频编码（GHVC）中使用显式运动指导时，重建结果可能出现严重失真和运动不准确。因此，本文强调了显式运动方法在人体视频压缩中的局限性，并研究了借助隐式运动变换（IMT）提升GHVC性能的方法。具体而言，我们提出将复杂的人体信号表征为紧凑的视觉特征，并将这些特征转化为隐式运动指导以进行信号重建。实验结果表明，所提出的IMT范式有效，能够帮助GHVC实现高效压缩和高保真合成。

</details>


### [211] [Boosting Adversarial Transferability for Hyperspectral Image Classification Using 3D Structure-invariant Transformation and Intermediate Feature Distance](https://arxiv.org/abs/2506.10459)
**中文标题：利用3D结构不变变换和中间特征距离提升高光谱图像分类的对抗迁移性**

*Chun Liu,Bingqian Zhu,Tao Xu,Zheng Zheng,Zheng Li,Wei Yang,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: The paper proposes a method to enhance adversarial transferability for HSI classification by using 3D structure-invariant transformations and intermediate feature distance loss.


<details>
  <summary>Details</summary>
Motivation: HSIs differ from natural images due to their high-dimensional spectral data, and existing adversarial attack methods struggle to fully utilize HSI structural and feature information, limiting transferability.

Method: The method involves random block division in spatial and spectral dimensions, applying transformations to increase diversity, and designing a feature distancing loss targeting intermediate layers to disrupt true class features.

Result: The adversarial examples generated achieve effective transferability on two public HSI datasets and maintain robust performance under defense strategies.

Conclusion: The proposed method successfully enhances adversarial transferability for HSI classification by leveraging structural and feature information.

摘要: 深度神经网络（DNNs）易受对抗攻击的影响，这对基于DNNs的高光谱图像（HSI）分类技术提出了安全挑战。在自然图像领域，已有大量基于迁移的对抗攻击方法被研究。然而，由于高维和丰富的频谱信息，HSIs与自然图像不同。目前关于HSI对抗样本的研究仍然有限，并且在充分利用图像的结构和特征信息方面面临挑战。为解决这些问题，本文提出了一种新方法，以增强HSI分类模型的对抗样本的迁移性。首先，在保持图像结构不变的情况下，该方法在空间和频谱维度上随机将图像划分为块。然后，逐块应用多种变换以增加输入多样性并减轻过拟合。其次，设计了一种针对中间层的特征距离损失，将原始样本的放大特征与对抗样本的特征之间的距离作为主要损失，而输出层预测作为辅助损失。这引导扰动破坏对抗样本中真实类别的特征，有效增强了迁移性。大量实验表明，所提方法生成的对抗样本在两个公开的HSI数据集上实现了对黑盒模型的有效迁移。此外，该方法在防御策略下仍保持强大的攻击性能。

</details>


### [212] [Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization](https://arxiv.org/abs/2506.10463)
**中文标题：初始位置的重要性：神经网络量化中更好的权重初始化研究**

*Stone Yun,Alexander Wong*

Main category: cs.CV

TL;DR: The paper explores how weight initialization impacts neural network quantization robustness, proposing a Graph Hypernetwork (GHN) method (GHN-QAT) to improve quantized accuracy.


<details>
  <summary>Details</summary>
Motivation: Despite advances in DNN quantization techniques, little attention has been paid to how weight initialization affects quantization robustness. The study aims to fill this gap by investigating initialization methods for better quantized performance.

Method: The study examines various weight initializations for CNN building blocks and introduces GHN-QAT, a method using Graph Hypernetworks to predict parameters for quantized DNNs, with finetuning for improved accuracy.

Result: GHN-QAT significantly improves quantized accuracy, even for 4-bit and 2-bit quantization, outperforming random initialization.

Conclusion: GHN-QAT provides a novel approach to quantization-aware weight initialization, with potential for further integration into quantization-aware training.

摘要: 深度神经网络（DNN）量化作为一种快速、高效的推理工具，在限制机器学习（ML）模型推理成本方面具有重要意义。诸如正则化、量化感知训练和量化鲁棒性惩罚等量化特定模型开发技术极大地提升了现代DNN的准确性和鲁棒性。然而，对于量化训练初始条件的改进却鲜有探索。正如随机权重初始化已被证明对浮点模型的测试准确性有显著影响，不同的权重初始化方法也可能影响训练模型的量化鲁棒性。我们进行了一项广泛研究，探讨了不同权重初始化对高效CNN常用构建模块的影响。分析表明，即使CNN架构各异，随机权重初始化器的选择也会显著影响最终的量化鲁棒性。接下来，我们探索了一种新的量化鲁棒CNN初始化方法——使用图超网络（GHN）预测量化DNN的参数。除了证明GHN预测的参数在常规float32预训练后具有量化鲁棒性外，我们还发现，对GHN进行微调以预测量化图的参数（称为GHN-QAT）可以进一步提高CNN的量化准确性。值得注意的是，GHN-QAT在4位量化中显示出显著的准确性提升，在2位量化中甚至优于随机初始化。据我们所知，这是首次对量化感知DNN权重初始化的深入研究。GHN-QAT为量化DNN模型设计提供了一种新方法。未来的研究，如将GHN-QAT初始化的参数用于量化感知训练，可以进一步简化DNN量化流程。

</details>


### [213] [MedSeg-R: Reasoning Segmentation in Medical Images with Multimodal Large Language Models](https://arxiv.org/abs/2506.10465)
**中文标题：MedSeg-R：基于多模态大语言模型的医学图像推理分割**

*Yu Huang,Zelin Peng,Yichen Zhao,Piao Yang,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: The paper introduces MedSeg-R, a framework combining multimodal large language models (MLLMs) with segmentation tasks to generate precise masks from complex medical instructions, supported by a new dataset MedSeg-QA.


<details>
  <summary>Details</summary>
Motivation: Existing medical image segmentation models lack reasoning capabilities for complex clinical questions, limiting their diagnostic utility. MLLMs show promise but struggle with precise mask generation.

Method: MedSeg-R uses a global context understanding module to interpret images and instructions, and a pixel-level grounding module to generate segmentation masks and textual responses.

Result: MedSeg-R outperforms benchmarks, achieving high segmentation accuracy and interpretable textual analysis, validated on the MedSeg-QA dataset.

Conclusion: MedSeg-R bridges the gap between reasoning and segmentation in medical images, offering a robust tool for clinical diagnosis.

摘要: 医学图像分割对临床诊断至关重要，但现有模型依赖显式人工指令且缺乏主动推理能力。尽管多模态大语言模型（MLLMs）在医学问答任务中有所改进，但多数方法难以生成精确的分割掩码，限制了其在自动医学诊断中的应用。本文提出医学图像推理分割任务，旨在基于复杂隐式医学指令生成分割掩码。为此，我们提出MedSeg-R，一种端到端框架，利用MLLMs的推理能力解析临床问题，同时生成精确的分割掩码。其核心包括：1）全局上下文理解模块，解析图像并理解复杂医学指令以生成多模态中间标记；2）像素级定位模块，解码标记以生成精确分割掩码和文本响应。此外，我们提出MedSeg-QA，一个专为医学图像推理分割任务设计的大规模数据集，包含10,000多对图像-掩码和多轮对话，通过大语言模型自动标注并经医生审核。实验表明，MedSeg-R在多个基准测试中表现优异，实现了高分割精度，并支持医学图像的可解释文本分析。

</details>


### [214] [LLMs Are Not Yet Ready for Deepfake Image Detection](https://arxiv.org/abs/2506.10474)
**中文标题：大型语言模型尚未准备好用于深度伪造图像检测**

*Shahroz Tariq,David Nguyen,M. A. P. Chamikara,Tingmin Wu,Alsharif Abuadbba,Kristen Moore*

Main category: cs.CV

TL;DR: Current vision-language models (VLMs) like ChatGPT, Claude, Gemini, and Grok show potential but are unreliable for standalone deepfake detection due to limitations in accuracy and reasoning depth.


<details>
  <summary>Details</summary>
Motivation: To evaluate the effectiveness of VLMs in detecting deepfakes, given their growing use in various domains and the increasing threat of sophisticated deepfakes to media integrity.

Method: A structured zero-shot evaluation of four VLMs on three deepfake types (faceswap, reenactment, synthetic generation) using a benchmark of authentic and manipulated images.

Result: VLMs can generate coherent explanations and detect surface-level anomalies but fail as standalone systems, with issues like overemphasis on stylistic elements and vulnerability to misleading patterns.

Conclusion: While VLMs are not yet reliable for autonomous deepfake detection, their interpretability and contextual analysis strengths suggest potential for hybrid or human-in-the-loop frameworks.

摘要: 深度伪造技术的日益复杂对媒体完整性和公众信任的维护构成了重大挑战。与此同时，视觉语言模型（VLMs）——即具备视觉推理能力的大型语言模型——已成为多个领域的有前景工具，引发了对其在深度伪造检测中适用性的兴趣。本研究对四种主流VLMs（ChatGPT、Claude、Gemini和Grok）进行了结构化零样本评估，重点关注三种主要深度伪造类型：换脸、重演和合成生成。通过精心构建的基准数据集（包含来自不同来源的真实和篡改图像），我们评估了每个模型的分类准确性和推理深度。分析表明，尽管VLMs能够生成连贯的解释并检测表面异常，但它们尚不能作为独立的检测系统可靠使用。我们强调了关键失败模式，例如对风格元素的过度关注以及对误导性视觉模式（如复古美学）的脆弱性。然而，VLMs在可解释性和上下文分析方面表现出优势，表明它们有潜力增强法证工作流程中的人类专业知识。这些见解表明，尽管通用模型目前缺乏自主深度伪造检测所需的可靠性，但它们有望成为混合或人机协作检测框架的重要组成部分。

</details>


### [215] [Sheet Music Benchmark: Standardized Optical Music Recognition Evaluation](https://arxiv.org/abs/2506.10488)
**中文标题：乐谱基准：标准化的光学音乐识别评估**

*Juan C. Martinez-Sevilla,Joan Cerveto-Serrano,Noelia Luna,Greg Chapman,Craig Sapp,David Rizo,Jorge Calvo-Zaragoza*

Main category: cs.CV

TL;DR: The paper introduces the Sheet Music Benchmark (SMB) dataset and the OMR Normalized Edit Distance (OMR-NED) metric to standardize and improve Optical Music Recognition (OMR) evaluation.


<details>
  <summary>Details</summary>
Motivation: The lack of standardized datasets and metrics for OMR research motivated the creation of SMB and OMR-NED to enable clearer comparisons and better error analysis.

Method: The authors developed SMB, a dataset of 685 pages with diverse musical textures, and OMR-NED, a metric for detailed error analysis in OMR. Baseline experiments were conducted using standardized splits of SMB.

Result: The SMB dataset and OMR-NED metric provide a standardized framework for evaluating OMR performance, facilitating clearer comparisons and identifying optimal approaches.

Conclusion: The work fills a gap in OMR evaluation by introducing standardized tools (SMB and OMR-NED), supported by baseline experiments, to advance OMR research.

摘要: 本研究介绍了乐谱基准（SMB），一个包含685页的专门用于评估光学音乐识别（OMR）研究的数据集。SMB涵盖了多种音乐纹理，包括单音、钢琴曲、四重奏等，均采用Common Western Modern Notation并以Humdrum **kern格式编码。同时，我们提出了OMR标准化编辑距离（OMR-NED），这是一种专门用于评估OMR性能的新指标。OMR-NED基于广泛使用的符号错误率（SER），提供了对音符头、横梁、音高、变音记号等关键音乐元素的细粒度错误分析。OMR-NED提供的数值分数便于清晰比较，帮助研究人员和终端用户识别最优的OMR方法。我们的工作填补了OMR评估领域的长期空白，并通过使用标准化的SMB数据集分割进行训练和评估最新方法的基线实验来支持我们的贡献。

</details>


### [216] [Class-Incremental Learning for Honey Botanical Origin Classification with Hyperspectral Images: A Study with Continual Backpropagation](https://arxiv.org/abs/2506.10489)
**中文标题：基于高光谱图像的蜂蜜植物来源分类的类增量学习：一种持续反向传播的研究**

*Guyang Zhang,Waleed Abdulla*

Main category: cs.CV

TL;DR: The paper proposes a novel technique combining continual backpropagation (CB) with class-incremental learning (CIL) to improve honey botanical origin classification using hyperspectral images, achieving performance gains of 1-7%.


<details>
  <summary>Details</summary>
Motivation: Honey's botanical origin affects its market value and consumer benefits, but collecting all varieties for training is impractical. CIL techniques are needed to address this challenge.

Method: The study compares multiple CIL algorithms on a honey hyperspectral dataset and introduces CB to reinitialize less-used neurons, enhancing plasticity.

Result: CB improved most CIL methods by 1-7%, demonstrating effectiveness in addressing loss-of-plasticity.

Conclusion: The CB-enhanced CIL approach is a promising solution for incremental learning in honey classification, offering practical benefits for real-world applications.

摘要: 蜂蜜是全球市场中的重要商品。不同植物来源的蜂蜜具有多样化的风味和健康益处，因此市场价值不同。开发准确有效的植物来源区分技术对保护消费者利益至关重要。然而，一次性收集所有蜂蜜品种来训练模型是不现实的。为此，研究人员开发了类增量学习（CIL）技术来解决这一挑战。本研究在真实世界的高光谱蜂蜜数据集上检验并比较了多种CIL算法。同时提出了一种新技术，通过结合持续反向传播（CB）算法来提升类增量学习算法的性能。CB方法通过重新初始化部分较少使用的隐藏神经元，为神经网络注入变异性，从而解决塑性丧失问题。实验表明，CB将大多数CIL方法的性能提高了1-7%。

</details>


### [217] [Semantic Localization Guiding Segment Anything Model For Reference Remote Sensing Image Segmentation](https://arxiv.org/abs/2506.10503)
**中文标题：语义定位引导的Segment Anything模型用于参考遥感图像分割**

*Shuyang Li,Shuang Wang,Zhuangzhuang Sun,Jing Xiao*

Main category: cs.CV

TL;DR: The paper proposes PSLG-SAM, a two-stage framework for Reference Remote Sensing Image Segmentation (RRSIS), combining coarse localization and fine segmentation to reduce annotation burden and improve accuracy.


<details>
  <summary>Details</summary>
Motivation: Current RRSIS methods face challenges like dense annotation requirements and complex scene interpretation. The paper aims to address these issues by simplifying the task into two stages and leveraging the Segment Anything Model (SAM).

Method: PSLG-SAM decomposes RRSIS into coarse localization (using a visual grounding network) and fine segmentation (guided by SAM with clustering-based foreground points and iterative mask optimization). The second stage can be train-free.

Result: PSLG-SAM achieves significant performance improvements on datasets RRSIS-D and RRSIS-M, surpassing state-of-the-art models.

Conclusion: The proposed framework effectively reduces annotation burden and improves segmentation accuracy, demonstrating the potential of combining localization and segmentation for RRSIS tasks.

摘要: 参考遥感图像分割（RRSIS）任务根据文本描述生成图像中指定对象的分割掩码，引起了广泛关注和研究兴趣。当前的RRSIS方法依赖于多模态融合主干和语义分割头，但面临密集标注要求和复杂场景解释等挑战。为解决这些问题，我们提出了一个名为“提示生成的语义定位引导Segment Anything模型”（PSLG-SAM）的框架，将RRSIS任务分解为粗定位和精细分割两个阶段。在粗定位阶段，视觉定位网络粗略定位文本描述的对象。在精细分割阶段，第一阶段的坐标引导Segment Anything模型（SAM），并通过基于聚类的前景点生成器和掩码边界迭代优化策略实现精确分割。值得注意的是，第二阶段可以无需训练，显著减轻RRSIS任务的标注数据负担。此外，将RRSIS任务分解为两个阶段可以专注于特定区域分割，避免复杂场景的干扰。我们还贡献了一个高质量、多类别的手动标注数据集。在两个数据集（RRSIS-D和RRSIS-M）上的实验验证表明，PSLG-SAM实现了显著的性能提升，并超越了现有的最先进模型。我们的代码将公开提供。

</details>


### [218] [J-DDL: Surface Damage Detection and Localization System for Fighter Aircraft](https://arxiv.org/abs/2506.10505)
**中文标题：J-DDL：战斗机表面损伤检测与定位系统**

*Jin Huang,Mingqiang Wei,Zikuan Li,Hangyu Qu,Wei Zhao,Xinyu Bai*

Main category: cs.CV

TL;DR: J-DDL is a smart system for detecting and localizing surface damage on fighter aircraft using 2D images and 3D point clouds, featuring a YOLO-based detection network with innovations like Fasternet blocks, EMA modules, and Inner-CIOU loss.


<details>
  <summary>Details</summary>
Motivation: Manual inspections of fighter aircraft surfaces are inefficient and inconsistent due to large areas and structural complexity, necessitating an automated solution.

Method: J-DDL integrates 2D images and 3D point clouds, using a YOLO-based network with Fasternet blocks, EMA modules, and Inner-CIOU loss for precise damage detection and 3D localization.

Result: The system achieves accurate damage detection and localization, validated by experiments, and introduces the first public dataset for aircraft damage.

Conclusion: J-DDL enhances inspection efficiency and coverage, advancing automated aircraft inspection technologies.

摘要: 确保战斗机的安全性和延长其使用寿命需要进行频繁且彻底的检查。虽然表面缺陷检测对人类检查员是可行的，但由于飞机表面积大、结构复杂以及维护操作的需求，手动方法在可扩展性、效率和一致性方面面临关键限制。我们提出了一种智能战斗机表面损伤检测与定位系统，称为J-DDL。J-DDL集成了通过激光扫描仪和相机组合系统捕获的整个飞机表面的2D图像和3D点云，以实现精确的损伤检测和定位。我们系统的核心是基于YOLO架构的新型损伤检测网络，专门针对2D飞机图像中的表面缺陷识别进行了优化。关键创新包括用于高效特征提取的轻量级Fasternet模块、结合高效多尺度注意力（EMA）模块的优化颈部架构，以及引入新型损失函数Inner-CIOU以提高检测精度。在2D图像中检测到损伤后，系统将识别的异常映射到对应的3D点云上，从而在飞机表面实现准确的3D缺陷定位。我们的J-DDL不仅简化了检查流程，还确保了对大型复杂飞机外表面更全面和详细的覆盖。为了促进该领域的进一步发展，我们开发了首个公开可用的专注于飞机损伤的数据集。实验评估验证了我们框架的有效性，强调了其在显著推进自动飞机检查技术方面的潜力。

</details>


### [219] [CogStream: Context-guided Streaming Video Question Answering](https://arxiv.org/abs/2506.10516)
**中文标题：CogStream：基于上下文引导的流媒体视频问答**

*Zicheng Zhao,Kangyu Wang,Shijie Li,Rui Qian,Weiyao Lin,Huabin Liu*

Main category: cs.CV

TL;DR: The paper introduces CogStream, a task for streaming video reasoning, and proposes CogReasoner, a model that efficiently identifies relevant historical context to answer questions about streaming videos, supported by a densely annotated dataset.


<details>
  <summary>Details</summary>
Motivation: Existing Video Large Language Models (Vid-LLMs) struggle with streaming video reasoning due to computational inefficiency and irrelevant context inclusion, necessitating a focused approach.

Method: The paper presents CogStream, a task simulating real-world streaming video scenarios, and CogReasoner, a model using visual stream compression and historical dialogue retrieval to identify relevant context.

Result: Extensive experiments validate CogReasoner's effectiveness in handling the CogStream task.

Conclusion: The paper successfully addresses streaming video reasoning challenges with CogStream and CogReasoner, supported by a robust dataset.

摘要: 尽管视频大型语言模型（Vid-LLMs）在多模态理解方面取得了进展，但由于其对上下文信息的依赖，流媒体视频推理仍面临挑战。现有范式将所有可用的历史上下文信息输入Vid-LLMs，导致视觉数据处理的计算负担显著增加。此外，无关上下文的引入会分散模型对关键细节的注意力。本文提出了一项具有挑战性的任务，称为“基于上下文引导的流媒体视频推理”（CogStream），该任务模拟现实中的流媒体视频场景，要求模型识别最相关的历史上下文信息以推断当前流媒体问题的答案。为支持CogStream，我们提出了一个密集标注的数据集，包含广泛且层次化的问题-答案对，由半自动流程生成。此外，我们还提出了CogReasoner作为基线模型，它通过利用视觉流压缩和历史对话检索高效地解决了这一任务。大量实验证明了该方法的有效性。代码即将发布。

</details>


### [220] [ALBERT: Advanced Localization and Bidirectional Encoder Representations from Transformers for Automotive Damage Evaluation](https://arxiv.org/abs/2506.10524)
**中文标题：ALBERT：基于双向编码器表示和高级定位的汽车损伤评估**

*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: ALBERT is an advanced instance segmentation model for car damage and part segmentation, using bidirectional encoder representations and localization to classify 26 damage types, 7 fake variants, and segment 61 car parts with high accuracy.


<details>
  <summary>Details</summary>
Motivation: To develop a precise model for automotive damage evaluation that can distinguish real from fake damages and segment car parts for intelligent inspection applications.

Method: ALBERT leverages bidirectional encoder representations and advanced localization mechanisms, trained on a large annotated dataset with 26 damage types, 7 fake variants, and 61 car parts.

Result: The model achieves strong performance in segmentation accuracy and damage classification, suitable for automotive inspection.

Conclusion: ALBERT's capabilities in damage evaluation and part segmentation make it a promising tool for intelligent automotive inspection systems.

摘要: 本文介绍了ALBERT，一种专为全面汽车损伤和部件分割设计的实例分割模型。利用双向编码器表示的能力，ALBERT结合了高级定位机制，能够准确识别和区分真实与虚假损伤，并分割单个汽车部件。该模型在一个大规模、丰富标注的汽车数据集上进行了训练，该数据集将损伤分为26种类型，识别了7种虚假损伤变体，并分割了61个不同的汽车部件。我们的方法在分割准确性和损伤分类方面表现出色，为智能汽车检测和评估应用铺平了道路。

</details>


### [221] [SLICK: Selective Localization and Instance Calibration for Knowledge-Enhanced Car Damage Segmentation in Automotive Insurance](https://arxiv.org/abs/2506.10528)
**中文标题：SLICK：基于知识增强的汽车保险损伤分割的选择性定位与实例校准**

*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: SLICK is a novel framework for car damage segmentation that uses structural priors and domain knowledge to achieve precise and robust results in automotive insurance workflows.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address real-world challenges in car damage segmentation, such as occlusion, deformation, and noise, by leveraging structural priors and domain knowledge.

Method: SLICK introduces five components: (1) Selective Part Segmentation, (2) Localization-Aware Attention blocks, (3) Instance-Sensitive Refinement head, (4) Cross-Channel Calibration, and (5) a Knowledge Fusion Module.

Result: Experiments show SLICK's superior segmentation performance, robustness, and practical applicability in automotive insurance workflows.

Conclusion: SLICK effectively tackles car damage segmentation challenges, demonstrating high accuracy and generalization for real-world applications.

摘要: 我们提出了SLICK，这是一种新颖的框架，用于精确且稳健的汽车损伤分割，利用结构先验和领域知识解决现实世界中的汽车检测挑战。SLICK包含五个关键组件：(1) 选择性部件分割，通过高分辨率语义主干和结构先验指导，即使在遮挡、变形或油漆脱落情况下也能实现手术级精度；(2) 定位感知注意力块，动态聚焦于损伤区域，增强复杂街景中的细粒度损伤检测；(3) 实例敏感细化头，利用全景线索和形状先验分离重叠或相邻部件，实现精确边界对齐；(4) 跨通道校准，通过多尺度通道注意力放大细微损伤信号（如划痕和凹痕），同时抑制噪声（如反射和贴花）；(5) 知识融合模块，整合合成碰撞数据、部件几何和真实保险数据集，以提高泛化能力并有效处理罕见情况。在大规模汽车数据集上的实验证明了SLICK在分割性能、鲁棒性以及保险和汽车检测工作流程中的实际适用性方面的优越性。

</details>


### [222] [ContextRefine-CLIP for EPIC-KITCHENS-100 Multi-Instance Retrieval Challenge 2025](https://arxiv.org/abs/2506.10550)
**中文标题：ContextRefine-CLIP：用于EPIC-KITCHENS-100多实例检索挑战2025**

*Jing He,Yiqing Wang,Lingling Li,Kexin Zhang,Puhua Chen*

Main category: cs.CV

TL;DR: CR-CLIP introduces a cross-modal attention flow module to refine visual-textual features, achieving state-of-the-art performance on EPIC-KITCHENS-100 without ensemble learning.


<details>
  <summary>Details</summary>
Motivation: To improve cross-modal retrieval by dynamically refining visual and textual features through bidirectional interaction, addressing limitations in existing models.

Method: CR-CLIP enhances AVION with a cross-modal attention flow module for bidirectional feature refinement and uses Symmetric Multi-Similarity Loss for semantic alignment.

Result: Achieves 66.78mAP and 82.08nDCG on EPIC-KITCHENS-100, outperforming baselines.

Conclusion: CR-CLIP is effective for cross-modal retrieval, validated by superior performance on EPIC-KITCHENS-100.

摘要: 本报告介绍了ContextRefine-CLIP（CR-CLIP），一种高效的视觉-文本多实例检索任务模型。该方法基于双编码器AVION，引入跨模态注意力流模块，实现视觉与文本特征的双向动态交互与精炼，生成更具上下文感知的联合表征。针对EPIC-KITCHENS-100等任务提供的软标签相关矩阵，CR-CLIP结合对称多相似性损失，利用精炼特征实现更准确的语义对齐与优化。在不使用集成学习的情况下，CR-CLIP模型在EPIC-KITCHENS-100公开排行榜上达到66.78mAP和82.08nDCG，显著优于基线模型，充分验证了其在跨模态检索中的有效性。代码将在https://github.com/delCayr/ContextRefine-Clip开源发布。

</details>


### [223] [From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations](https://arxiv.org/abs/2506.10559)
**中文标题：从图像到洞察：用通俗语言解释生物多样性监测**

*Yutong Zhou,Masahiro Ryo*

Main category: cs.CV

TL;DR: The paper proposes an end-to-end visual-to-causal framework to explain species habitat preferences using AI, integrating species recognition, causal inference, and human-readable explanations.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap in ecological workflows by providing accessible, interpretable causal insights into species habitat preferences for non-specialists.

Method: The framework combines species recognition, global occurrence retrieval, pseudo-absence sampling, climate data extraction, causal structure discovery, and human-readable explanation generation using structured templates and large language models.

Result: Early results demonstrate the framework's potential in generating statistically grounded, human-understandable explanations for species habitat preferences, tested on a bee and a flower species.

Conclusion: The multimodal AI framework shows promise for enhancing biodiversity monitoring by providing clear, causal habitat explanations, supported by ecological modeling practices.

摘要: 解释物种为何生活在特定地点对于理解生态系统和保护生物多样性至关重要。然而，现有的生态工作流程分散且通常对非专业人士难以理解。我们提出了一种端到端的视觉到因果框架，将物种图像转化为关于其栖息地偏好的可解释因果洞察。该系统整合了物种识别、全球分布检索、伪缺失采样和气候数据提取。然后，我们利用现代因果推断方法发现环境特征之间的因果结构，并估计它们对物种分布的影响。最后，我们从结构化模板和大型语言模型中生成具有统计基础、人类可读的因果解释。我们以蜜蜂和花卉物种为例展示了该框架，并报告了正在进行项目的初步结果，展示了多模态人工智能助手在描述物种栖息地方面的潜力，其背后是推荐的生态建模实践。

</details>


### [224] [Balancing Tails when Comparing Distributions: Comprehensive Equity Index (CEI) with Application to Bias Evaluation in Operational Face Biometrics](https://arxiv.org/abs/2506.10564)
**中文标题：比较分布时的尾部平衡：全面公平指数（CEI）及其在操作人脸生物特征偏差评估中的应用**

*Imanol Solano,Julian Fierrez,Aythami Morales,Alejandro Peña,Ruben Tolosana,Francisco Zamora-Martinez,Javier San Agustin*

Main category: cs.CV

TL;DR: The paper introduces the Comprehensive Equity Index (CEI) to detect subtle demographic biases in face recognition systems by analyzing tail probabilities of score distributions, outperforming existing metrics.


<details>
  <summary>Details</summary>
Motivation: Existing metrics often fail to detect subtle demographic biases in face recognition systems, particularly in the tails of score distributions. This limitation motivates the development of CEI.

Method: CEI separately analyzes genuine and impostor score distributions, allowing configurable focus on tail probabilities while considering overall distribution shapes. An automated version, CEI^A, is also introduced.

Result: Experiments show CEI's superior ability to detect nuanced biases in state-of-the-art and intentionally biased face recognition systems, outperforming previous methods.

Conclusion: CEI provides a robust and sensitive tool for fairness assessment in face biometrics, with broader applicability for comparing statistical distributions in other domains.

摘要: 高性能人脸识别（FR）系统中的人口统计偏差往往难以通过现有指标检测，尤其是在分数分布的尾部细微差异方面。我们引入了全面公平指数（CEI），这是一种旨在解决这一局限性的新型指标。CEI独特地分别分析真实和冒名顶替分数分布，允许可配置地关注尾部概率，同时考虑整体分布形状。我们的大量实验（评估最先进的FR系统、故意偏置模型和多样化数据集）证实了CEI在检测现有方法无法捕捉的细微偏差方面的卓越能力。此外，我们提出了CEI^A，这是该指标的自动化版本，增强了客观性并简化了实际应用。CEI为操作FR公平性评估提供了强大而敏感的工具。所提出的方法特别针对人脸生物特征中的偏差评估开发，但通常适用于任何对分析分布尾部感兴趣的问题中的统计分布比较。

</details>


### [225] [LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System](https://arxiv.org/abs/2506.10567)
**中文标题：LRSLAM：稠密视觉SLAM系统中符号距离场的低秩表示**

*Hongbeen Park,Minjeong Park,Giljoo Nam,Jinkyu Kim*

Main category: cs.CV

TL;DR: LRSLAM introduces a low-rank tensor decomposition method for dense visual SLAM, improving efficiency and performance over existing approaches.


<details>
  <summary>Details</summary>
Motivation: Dense visual SLAM faces challenges in real-time performance, robustness, and scalability. Neural implicit representations are computationally expensive, and existing tensor decomposition methods like ESLAM struggle with memory growth.

Method: LRSLAM uses low-rank tensor decomposition (Six-axis and CP decompositions) to enhance convergence rates, memory efficiency, and reconstruction/localization quality.

Result: LRSLAM outperforms state-of-the-art methods in parameter efficiency, processing time, and accuracy across diverse indoor RGB-D datasets.

Conclusion: LRSLAM offers a more efficient and scalable solution for dense visual SLAM, balancing performance and resource usage.

摘要: 同步定位与地图构建（SLAM）在自动驾驶、移动机器人和混合现实等多个领域至关重要。稠密视觉SLAM利用RGB-D相机系统具有优势，但在实现实时性能、鲁棒性和大规模场景的可扩展性方面面临挑战。最近采用神经隐式场景表示的方法显示出潜力，但存在高计算成本和内存需求的问题。ESLAM引入了基于平面的张量分解，但仍受限于内存增长。为解决这些问题，我们提出了一种更高效的视觉SLAM模型LRSLAM，利用低秩张量分解方法。我们的方法结合了六轴和CP分解，在收敛速度、内存效率和重建/定位质量上优于现有最先进方法。在多种室内RGB-D数据集上的评估表明，LRSLAM在参数效率、处理时间和准确性方面表现优异，同时保持了重建和定位质量。代码将在发表后公开。

</details>


### [226] [DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers](https://arxiv.org/abs/2506.10568)
**中文标题：DreamActor-H1：基于运动设计的扩散变换器的高保真人-产品演示视频生成**

*Lizhen Wang,Zhurong Xia,Tianshu Hu,Pengrui Wang,Pengfei Wang,Zerong Zheng,Ming Zhou*

Main category: cs.CV

TL;DR: The paper introduces DreamActor-H1, a Diffusion Transformer-based framework for generating high-fidelity human-product demonstration videos, preserving identities and spatial relationships while enabling realistic interactions.


<details>
  <summary>Details</summary>
Motivation: Existing frameworks struggle to maintain human and product identities or understand spatial relationships, leading to unrealistic videos. The goal is to improve fidelity and natural interactions in human-product demonstration videos.

Method: The proposed method uses a Diffusion Transformer (DiT) with paired human-product reference information and a masked cross-attention mechanism. It employs a 3D body mesh template and product bounding boxes for motion guidance, along with structured text encoding for 3D consistency.

Result: The approach outperforms state-of-the-art techniques in preserving identity integrity and generating realistic motions, validated by a hybrid dataset with extensive augmentation.

Conclusion: DreamActor-H1 effectively addresses the challenges of identity preservation and spatial understanding, offering a robust solution for high-fidelity human-product demonstration videos.

摘要: 在电子商务和数字营销中，生成高保真的人-产品演示视频对于有效的产品展示至关重要。然而，大多数现有框架要么无法同时保留人和产品的身份特征，要么缺乏对人-产品空间关系的理解，导致不真实的表示和不自然的交互。为解决这些问题，我们提出了一种基于扩散变换器（DiT）的框架。我们的方法通过注入配对的人-产品参考信息并利用额外的掩码交叉注意力机制，同时保留人的身份特征和产品特定细节（如标志和纹理）。我们采用3D人体网格模板和产品边界框提供精确的运动指导，实现手势与产品摆放的直观对齐。此外，结构化文本编码用于融入类别级语义，增强帧间小旋转变化时的3D一致性。通过在混合数据集上训练并采用广泛的数据增强策略，我们的方法在保持人和产品身份完整性及生成真实演示动作方面优于现有技术。项目页面：https://submit2025-dream.github.io/DreamActor-H1/。

</details>


### [227] [Improving Medical Visual Representation Learning with Pathological-level Cross-Modal Alignment and Correlation Exploration](https://arxiv.org/abs/2506.10573)
**中文标题：通过病理级别跨模态对齐和相关性探索改进医学视觉表征学习**

*Jun Wang,Lixing Zhu,Xiaohan Yu,Abhir Bhalerao,Yulan He*

Main category: cs.CV

TL;DR: The paper introduces PLACE, a framework for medical visual representation learning that focuses on pathological-level alignment and correlation exploration, achieving state-of-the-art results without additional annotations.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenges of learning medical visual representations from lengthy reports with complex semantics, emphasizing the need for pathological-level consistency often overlooked in prior works.

Method: The proposed PLACE framework includes a Pathological-Level Cross-Modal Alignment (PCMA) approach and a Visual Pathology Observation Extractor to align pathology observations from images and reports. It also uses a proxy task to explore correlations among image patches.

Result: The framework achieves state-of-the-art performance on tasks like classification, retrieval, segmentation, detection, and report generation.

Conclusion: PLACE effectively improves medical visual representation learning by focusing on pathological-level alignment and fine-grained correlation exploration, demonstrating superior performance across multiple tasks.

摘要: 通过联合学习从图像-报告对中学习医学视觉表征，因其潜力缓解医学领域数据稀缺问题而受到越来越多的研究关注。主要挑战源于冗长的报告，这些报告具有复杂的话语关系和语义病理。以往的研究主要集中在实例级或标记级的跨模态对齐，往往忽视了病理级别一致性的重要性。本文提出了一种新颖的框架PLACE，通过病理级别对齐和相关探索丰富细粒度细节，无需额外的人工标注。具体而言，我们提出了一种病理级别跨模态对齐（PCMA）方法，以最大化图像和报告中病理观察的一致性。为此，引入了视觉病理观察提取器，从局部标记中提取视觉病理观察表征。PCMA模块独立于任何外部疾病标注运行，增强了方法的泛化性和鲁棒性。此外，我们设计了一个代理任务，强制模型识别图像块之间的相关性，从而丰富对多种下游任务至关重要的细粒度细节。实验结果表明，我们提出的框架在分类、图像到文本检索、语义分割、目标检测和报告生成等多个下游任务上实现了新的最先进性能。

</details>


### [228] [DanceChat: Large Language Model-Guided Music-to-Dance Generation](https://arxiv.org/abs/2506.10574)
**中文标题：DanceChat：基于大语言模型的音乐到舞蹈生成**

*Qing Wang,Xiaohang Yang,Yilan Dong,Naveen Raj Govindaraj,Gregory Slabaugh,Shanxin Yuan*

Main category: cs.CV

TL;DR: DanceChat uses a Large Language Model (LLM) to guide music-to-dance generation by providing textual motion instructions, improving diversity and alignment with musical styles.


<details>
  <summary>Details</summary>
Motivation: The semantic gap between music and dance, along with the one-to-many mapping problem and scarcity of paired data, limits current music-to-dance generation methods. DanceChat aims to address these challenges by leveraging LLM guidance.

Method: DanceChat consists of three components: (1) an LLM-based pseudo instruction generation module, (2) a multi-modal feature extraction and fusion module, and (3) a diffusion-based motion synthesis module with multi-modal alignment loss.

Result: Experiments on AIST++ and human evaluations show DanceChat outperforms state-of-the-art methods in both quality and diversity.

Conclusion: DanceChat demonstrates the effectiveness of LLM-guided dance generation, offering a novel approach to bridge the music-dance semantic gap and enhance diversity.

摘要: 音乐到舞蹈生成的目标是根据音乐输入合成人类舞蹈动作。尽管近期取得进展，但由于音乐与舞蹈动作之间的语义鸿沟，仍存在重大挑战。音乐仅提供旋律、节奏和情感等抽象线索，而未明确指定物理动作。此外，一首音乐可产生多种合理的舞蹈解释。这种一对多映射需要额外指导，因为仅凭音乐提供的信息有限，难以生成多样化的舞蹈动作。配对的音乐和舞蹈数据稀缺进一步加剧了这一挑战，限制了模型学习多样化舞蹈模式的能力。本文提出DanceChat，一种基于大语言模型（LLM）的音乐到舞蹈生成方法。我们使用LLM作为编舞者，提供文本动作指令，为舞蹈生成提供明确的高层次指导。这种方法超越了仅从音乐中隐式学习的方式，使模型生成的舞蹈更加多样化且更符合音乐风格。我们的方法包括三个部分：（1）基于LLM的伪指令生成模块，根据音乐风格和结构生成文本舞蹈指导；（2）多模态特征提取和融合模块，将音乐、节奏和文本指导整合为共享表示；（3）基于扩散的动作合成模块及多模态对齐损失，确保生成的舞蹈与音乐和文本线索对齐。在AIST++数据集上的大量实验和人工评估表明，DanceChat在质量和数量上均优于现有方法。

</details>


### [229] [Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning](https://arxiv.org/abs/2506.10575)
**中文标题：基于联合提示-适配器学习的多标签图像识别的文本到图像方法**

*Chun-Mei Feng,Kai Yu,Xinxing Xu,Salman Khan,Rick Siow Mong Goh,Wangmeng Zuo,Yong Liu*

Main category: cs.CV

TL;DR: The paper introduces T2I-PAL, a method leveraging text-to-image generation to reduce the modality gap in CLIP for multi-label image recognition, combining prompt tuning and adapter learning for improved performance.


<details>
  <summary>Details</summary>
Motivation: The modality gap between text and image features in CLIP limits performance in text-as-image fine-tuning. The paper aims to address this gap for multi-label image recognition without requiring fully annotated training images.

Method: T2I-PAL uses text-to-image generation models to create diverse images from text captions, reducing the modality gap. It also employs a class-wise heatmap and learnable prototypes for robust local feature representation, combining prompt tuning and adapter learning.

Result: T2I-PAL outperforms state-of-the-art methods by an average of 3.47% on benchmarks like MS-COCO, VOC2007, and NUS-WIDE.

Conclusion: T2I-PAL effectively reduces the modality gap, enhances multi-label recognition, and integrates seamlessly with CLIP, eliminating the need for extensive manual annotations.

摘要: 受益于图像-文本对比学习，预训练的视觉语言模型（如CLIP）可以直接利用文本作为图像（TaI）进行参数高效的微调（PEFT）。尽管CLIP能够使图像特征与相应的文本特征相似，模态差距仍然是一个重要问题，限制了TaI的图像识别性能。以多标签图像识别（MLR）为例，我们提出了一种名为T2I-PAL的新方法，以解决仅使用文本标题进行PEFT时的模态差距问题。T2I-PAL的核心设计是利用预训练的文本到图像生成模型从文本标题生成逼真且多样化的图像，从而减少模态差距。为了进一步增强MLR，T2I-PAL结合了类别热图和可学习原型，聚合局部相似性，使局部视觉特征的表示更加鲁棒和信息丰富。为了更好的PEFT，我们进一步结合了提示调优和适配器学习以提高分类性能。T2I-PAL具有显著优势：它消除了对完全语义标注训练图像的需求，从而减少了手动标注工作量，并保留了CLIP模型的内在模式，可以与任何现有的CLIP框架无缝集成。在多个基准测试（包括MS-COCO、VOC2007和NUS-WIDE）上的广泛实验表明，我们的T2I-PAL可以将识别性能平均提升3.47%，超越当前最先进的方法。

</details>


### [230] [Harmonizing Geometry and Uncertainty: Diffusion with Hyperspheres](https://arxiv.org/abs/2506.10576)
**中文标题：几何与不确定性的协调：超球面上的扩散**

*Muskan Dosi,Chiranjeev Chiranjeev,Kartik Thakral,Mayank Vatsa,Richa Singh*

Main category: cs.CV

TL;DR: The paper introduces HyperSphereDiff, a diffusion model that aligns hyperspherical data geometry with directional noise, improving generative performance by preserving angular uncertainty.


<details>
  <summary>Details</summary>
Motivation: Standard diffusion models use isotropic Gaussian noise, which is unsuitable for non-Euclidean data like hyperspherical manifolds, leading to loss of angular geometry and suboptimal performance.

Method: HyperSphereDiff incorporates directional noise to align with hyperspherical structures, preserving class geometry and angular uncertainty.

Result: The approach outperforms standard models on object and face datasets, better preserving hyperspherical manifold geometry.

Conclusion: HyperSphereDiff effectively harmonizes geometry and uncertainty, enhancing generative accuracy for hyperspherical data.

摘要: 当代扩散模型是否保留了超球形数据的类别几何结构？标准扩散模型在前向过程中依赖于各向同性高斯噪声，本质上偏向欧几里得空间。然而，许多现实问题涉及非欧几里得分布，如超球面流形，其中类别特定的模式由超锥内的角度几何控制。在欧几里得空间中建模时，这些角度细节会丢失，导致生成性能不佳。为解决这一限制，我们引入了HyperSphereDiff，通过方向性噪声与超球形结构对齐，保留类别几何并有效捕捉角度不确定性。我们从理论和实验上证明，这种方法使生成过程与超球形数据的内在几何对齐，从而产生更准确且几何感知的生成模型。我们在四个物体数据集和两个人脸数据集上评估了我们的框架，结果表明，引入角度不确定性更好地保留了底层的超球面流形。资源见：{https://github.com/IAB-IITJ/Harmonizing-Geometry-and-Uncertainty-Diffusion-with-Hyperspheres/}

</details>


### [231] [Rethinking Random Masking in Self Distillation on ViT](https://arxiv.org/abs/2506.10582)
**中文标题：重新思考ViT自蒸馏中的随机掩码策略**

*Jihyeon Seong,Hyunkyung Han*

Main category: cs.CV

TL;DR: The paper rethinks random masking in self-distillation for ViTs, proposing asymmetric masking (only on the student's global view) to preserve critical information and improve robustness, validated on mini-ImageNet.


<details>
  <summary>Details</summary>
Motivation: Random masking in self-distillation frameworks like DINO may unintentionally remove important semantic information, prompting the need for more informed masking strategies.

Method: The authors apply random masking only to the student's global view while keeping the student's local views and teacher's global view unmasked, leveraging DINO's multi-view augmentation.

Result: The asymmetric masking approach yields more robust and fine-grained attention maps, enhancing downstream performance on mini-ImageNet.

Conclusion: Asymmetric random masking in self-distillation improves model robustness and performance by preserving critical information while introducing regularization.

摘要: 视觉变换器（ViT）在各种视觉任务中表现出色，尤其是自蒸馏框架（如DINO）对此贡献显著。在这些框架中，随机掩码常被用于提高训练效率和引入正则化。然而，近期研究指出，不加区分的随机掩码可能会无意中消除关键语义信息，这促使了更智能掩码策略的开发。本研究探讨了自蒸馏设置中随机掩码的作用，重点关注DINO框架。具体而言，我们仅对学生的全局视图应用随机掩码，同时保留学生的局部视图和教师的全局视图的原始未掩码形式。这一设计利用DINO的多视图增强方案，在保持干净监督的同时通过掩码输入引入鲁棒性。我们在mini-ImageNet数据集上使用DINO-Tiny评估了该方法，结果表明，在这种非对称设置下的随机掩码能生成更鲁棒和细粒度的注意力图，最终提升下游性能。

</details>


### [232] [Hierarchical Error Assessment of CAD Models for Aircraft Manufacturing-and-Measurement](https://arxiv.org/abs/2506.10594)
**中文标题：飞机制造与测量中CAD模型的分层误差评估**

*Jin Huang,Honghua Chen,Mingqiang Wei*

Main category: cs.CV

TL;DR: A hierarchical error assessment framework (HEA-MM) for aircraft CAD models is proposed, using structured light scanners and multi-level error analysis (global, part, feature) to ensure high-quality manufacturing.


<details>
  <summary>Details</summary>
Motivation: To ensure high quality in aviation equipment by accurately assessing errors in CAD models during manufacturing and measurement.

Method: HEA-MM employs structured light scanners for 3D measurements, registers point clouds with CAD models, and performs error analysis at global, part, and feature levels, including optimization-based primitive refinement and circular hole detection.

Result: Experimental results demonstrate the effectiveness of HEA-MM in accurately assessing errors in aircraft CAD models.

Conclusion: HEA-MM provides a robust framework for hierarchical error assessment, enhancing the quality and reliability of aircraft manufacturing.

摘要: 航空设备最重要的特征是高质量，包括高性能、高稳定性和高可靠性。本文提出了一种新颖的分层误差评估框架（HEA-MM），用于飞机CAD模型在制造与测量平台中的误差分析。HEA-MM采用结构光扫描仪获取制造工件的全面3D测量数据，将测量点云与参考CAD模型配准后，在三个层次（全局、部件和特征）进行误差分析。全局层次评估扫描点云与参考CAD模型的整体偏差；部件层次对点云的基础块进行误差分析，提出了一种基于优化的基元细化方法，通过拆分和合并操作优化粗基元；特征层次针对CAD模型中常见的圆形孔进行误差分析，提出了一种两阶段算法（边缘点检测和圆拟合）以确保圆形特征的准确检测与分析。多种飞机CAD模型的实验结果表明了该方法的有效性。

</details>


### [233] [Semantic-decoupled Spatial Partition Guided Point-supervised Oriented Object Detection](https://arxiv.org/abs/2506.10601)
**中文标题：语义解耦的空间划分引导的点监督定向目标检测**

*Xinyuan Liu,Hang Xu,Yike Ma,Yucheng Zhang,Feng Dai*

Main category: cs.CV

TL;DR: The paper introduces SSP, a framework for point-supervised oriented object detection in remote sensing, combining rule-driven and data-driven approaches to improve sample assignment and instance extraction, achieving state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: High-density scenes in remote sensing require labor-intensive annotations for oriented object detection. Point supervision offers a cost-effective solution, but existing methods suffer from rigid designs leading to inadequate sample assignment and instance confusion.

Method: SSP integrates rule-driven prior injection and data-driven label purification. It includes Pixel-level Spatial Partition for sample assignment and Semantic Spatial Partition for box extraction, forming pseudo-labels for downstream detectors.

Result: SSP achieves 45.78% mAP under point supervision, outperforming PointOBB-v2 by 4.10%. With ORCNN and ReDet, it reaches 47.86% and 48.50% mAP, respectively.

Conclusion: SSP effectively addresses challenges in point-supervised oriented object detection, demonstrating superior performance and adaptability with different architectures.

摘要: 近年来遥感技术的进步推动了图像数据的增长，使得定向目标检测快速发展，但高密度场景下的标注工作繁重。点监督的定向目标检测为遥感中的密集场景提供了一种经济高效的解决方案，但现有方法因基于刚性规则的设计而存在样本分配不足和实例混淆的问题。为此，我们提出了SSP（语义解耦的空间划分），一个结合规则驱动先验注入和数据驱动标签净化的统一框架。具体而言，SSP包含两项核心创新：1）基于像素级空间划分的样本分配，通过像素图的空间划分紧凑估计对象尺度的上下界，并挖掘高质量的正样本和难负样本。2）基于语义空间划分的框提取，从语义图调制的空间划分中提取实例，并将其可靠地转换为边界框，形成伪标签以监督下游检测器的学习。在DOTA-v1.0等数据集上的实验表明，SSP在点监督下达到45.78%的mAP，优于SOTA方法PointOBB-v2 4.10%。此外，与ORCNN和ReDet架构集成时，SSP框架分别达到47.86%和48.50%的mAP。代码发布于https://github.com/antxinyuan/ssp。

</details>


### [234] [High-resolution efficient image generation from WiFi CSI using a pretrained latent diffusion model](https://arxiv.org/abs/2506.10605)
**中文标题：基于预训练潜在扩散模型的高分辨率高效WiFi CSI图像生成**

*Eshan Ramesh,Nishio Takayuki*

Main category: cs.CV

TL;DR: LatentCSI introduces a method to generate high-resolution images from WiFi CSI measurements using a pretrained latent diffusion model, outperforming traditional GAN-based approaches in efficiency and quality.


<details>
  <summary>Details</summary>
Motivation: Prior methods for generating images from WiFi CSI rely on complex, computationally intensive techniques like GANs, which are inefficient and lack controllability. LatentCSI aims to address these limitations by leveraging pretrained latent diffusion models for efficient and high-quality image synthesis.

Method: LatentCSI uses a lightweight neural network to map WiFi CSI amplitudes into the latent space of a pretrained latent diffusion model (LDM). The LDM's denoising diffusion model is then applied with text-based guidance, and the result is decoded to produce high-resolution images, bypassing pixel-space generation challenges.

Result: LatentCSI outperforms baseline methods in computational efficiency and perceptual quality on two datasets: a custom wide-band CSI dataset and a subset of the MM-Fi dataset. It also offers text-guided controllability.

Conclusion: LatentCSI provides an efficient, high-quality solution for image generation from WiFi CSI, leveraging pretrained LDMs to avoid the pitfalls of traditional methods while enabling text-guided control.

摘要: 我们提出了LatentCSI，一种利用预训练潜在扩散模型（LDM）从WiFi CSI测量中生成物理环境图像的新方法。与以往依赖复杂且计算密集型技术（如GANs）的方法不同，我们的方法采用轻量级神经网络将CSI幅度直接映射到LDM的潜在空间中。随后，我们在潜在表示上应用LDM的去噪扩散模型，并结合基于文本的指导，最后使用LDM的预训练解码器解码，获得高分辨率图像。这一设计绕过了像素空间图像生成的挑战，避免了传统图像到图像流程中通常需要的显式图像编码阶段，从而实现了高效且高质量的图像合成。我们在两个数据集上验证了我们的方法：一个是我们使用现成WiFi设备和相机收集的宽带CSI数据集；另一个是公开可用的MM-Fi数据集的子集。结果表明，LatentCSI在计算效率和感知质量上均优于直接在真实图像上训练的复杂度相当的基线方法，同时通过其独特的文本引导可控性提供了实际优势。

</details>


### [235] [MSTAR: Box-free Multi-query Scene Text Retrieval with Attention Recycling](https://arxiv.org/abs/2506.10609)
**中文标题：MSTAR：基于注意力循环的无框多查询场景文本检索**

*Liang Yin,Xudong Xie,Zhang Li,Xiang Bai,Yuliang Liu*

Main category: cs.CV

TL;DR: MSTAR introduces a box-free approach for multi-query scene text retrieval, using attention recycling and progressive vision embedding to unify diverse query types, outperforming state-of-the-art models while eliminating costly bounding box annotations.


<details>
  <summary>Details</summary>
Motivation: Existing scene text retrieval methods rely on expensive bounding box annotations and struggle to unify diverse query types, limiting their practical applicability.

Method: MSTAR employs progressive vision embedding and attention recycling to dynamically capture multi-grained text representations, harmonizing free-style queries with style-aware instructions and enhancing vision-language alignment via a multi-instance matching module.

Result: MSTAR surpasses previous state-of-the-art models by 6.4% in MAP on Total-Text and by an average of 8.5% on the new MQTR benchmark, while eliminating box annotation costs.

Conclusion: MSTAR provides an efficient, box-free solution for multi-query scene text retrieval, demonstrating superior performance and versatility across diverse datasets.

摘要: 场景文本检索在精确文本定位的辅助下取得了显著进展。然而，现有方法通常需要昂贵的边界框标注进行训练。此外，它们大多采用定制化的检索策略，但难以统一多种查询类型以满足多样化的检索需求。为解决这些问题，我们提出了基于注意力循环的多查询场景文本检索方法（MSTAR），一种无框的场景文本检索方法。它通过渐进式视觉嵌入动态捕捉文本的多粒度表示，并通过风格感知指令协调自由形式的文本查询。此外，还集成了一个多实例匹配模块以增强视觉-语言对齐。我们还构建了多查询文本检索（MQTR）数据集，这是首个用于评估模型多查询场景文本检索能力的基准，包含四种查询类型和16k张图像。大量实验证明，我们的方法在七个公共数据集和MQTR数据集上均表现出优越性。值得注意的是，MSTAR在Total-Text上的MAP指标上以6.4%的优势略微超越先前的最先进模型，同时消除了边界框标注成本。此外，在MQTR基准上，MSTAR平均比先前模型高出8.5%。代码和数据集可在https://github.com/yingift/MSTAR获取。

</details>


### [236] [TexTailor: Customized Text-aligned Texturing via Effective Resampling](https://arxiv.org/abs/2506.10612)
**中文标题：TexTailor：通过有效重采样实现定制化的文本对齐纹理**

*Suin Lee,Dae-Shik Kim*

Main category: cs.CV

TL;DR: TexTailor introduces a novel method for generating consistent object textures from text descriptions by addressing viewpoint shifts and geometry-aware camera adjustments, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-texture methods suffer from inconsistent textures across viewpoints due to insufficient integration of synthesized textures and predefined camera positions, limiting texture consistency.

Method: TexTailor uses a resampling scheme to integrate previously synthesized textures during diffusion, fine-tunes a depth-aware diffusion model, and adaptively adjusts camera positions based on object geometry.

Result: Experiments on Objaverse and ShapeNet datasets show TexTailor outperforms state-of-the-art methods in synthesizing view-consistent textures.

Conclusion: TexTailor effectively addresses texture inconsistency by integrating resampling and geometry-aware camera adjustments, demonstrating superior performance.

摘要: 我们提出了TexTailor，一种从文本描述生成一致物体纹理的新方法。现有的文本到纹理合成方法利用深度感知扩散模型逐步生成图像并在预定义的多个视角下合成纹理。然而，这些方法由于（1）扩散过程中每个视角下先前合成纹理的整合不足，以及（2）纹理合成过程的自回归性质，导致纹理属性在视角间逐渐偏移。此外，预定义的相机位置选择未考虑物体几何形状，限制了从不同视角合成的纹理信息的有效利用，最终降低了整体纹理一致性。在TexTailor中，我们通过（1）应用一种重采样方案，在扩散过程中重复整合先前合成纹理的信息，以及（2）在这些重采样纹理上微调深度感知扩散模型，解决了这些问题。在此过程中，我们发现仅使用少量训练图像限制了模型生成与条件对齐的高保真图像的原始能力，因此提出了一种性能保持损失来缓解这一问题。此外，我们通过基于物体几何形状自适应调整相机位置，改进了视角一致纹理的合成。在Objaverse数据集子集和ShapeNet汽车数据集上的实验表明，TexTailor在合成视角一致纹理方面优于现有方法。TexTailor的源代码可在https://github.com/Adios42/Textailor获取。

</details>


### [237] [Anatomy-Grounded Weakly Supervised Prompt Tuning for Chest X-ray Latent Diffusion Models](https://arxiv.org/abs/2506.10633)
**中文标题：基于解剖学的弱监督提示调整用于胸部X光潜在扩散模型**

*Konstantinos Vilouras,Ilias Stogiannidis,Junyu Yan,Alison Q. O'Neil,Sotirios A. Tsaftaris*

Main category: cs.CV

TL;DR: The paper proposes a fine-tuning framework to improve multi-modal alignment in pre-trained Latent Diffusion Models for chest X-ray images, achieving state-of-the-art performance on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: Text-to-image Latent Diffusion Models are underutilized in medical imaging due to limited data and poor alignment between radiology reports and scans. The paper aims to improve this alignment for downstream tasks like phrase grounding.

Method: The authors introduce a fine-tuning framework for pre-trained Latent Diffusion Models to enhance alignment between free-text radiology reports and chest X-ray scans, enabling efficient adaptation for tasks like phrase grounding.

Result: The method achieves state-of-the-art performance on the MS-CXR benchmark and demonstrates robustness on out-of-distribution data (VinDr-CXR).

Conclusion: The proposed framework successfully improves multi-modal alignment in Latent Diffusion Models for medical imaging, offering potential for downstream applications.

摘要: 近年来，潜在扩散模型在文本引导的图像合成中表现出卓越的效果。在自然（RGB）图像领域，最近的研究表明，这类模型可以在极少甚至无监督的情况下适应各种视觉语言下游任务。然而，在医学影像领域，文本到图像的潜在扩散模型仍相对未被充分探索，主要由于数据可用性有限（例如，出于隐私考虑）。在这项工作中，我们以胸部X光模态为例，首先证明标准的文本条件潜在扩散模型尚未学会将自由文本放射学报告中的临床相关信息与扫描图像的对应区域对齐。为解决这一问题，我们提出了一种微调框架，用于改进预训练模型中的多模态对齐，使其能够高效地重新用于下游任务（如短语定位）。我们的方法在标准基准数据集（MS-CXR）上达到了新的最先进水平，同时在分布外数据（VinDr-CXR）上也表现出稳健的性能。我们的代码将公开发布。

</details>


### [238] [Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models](https://arxiv.org/abs/2506.10634)
**中文标题：对称流匹配：基于分数生成模型的统一图像生成、分割与分类**

*Francisco Caetano,Christiaan Viviers,Peter H. N. De With,Fons van der Sommen*

Main category: cs.CV

TL;DR: SymmFlow introduces a unified framework for image generation, segmentation, and classification using a symmetric learning objective, achieving state-of-the-art performance with efficient sampling.


<details>
  <summary>Details</summary>
Motivation: To unify semantic segmentation, classification, and image generation within a single model while ensuring bi-directional consistency and preserving generative diversity.

Method: Symmetrical Flow Matching (SymmFlow) jointly models forward and reverse transformations with a symmetric learning objective, retaining semantic information across flows for efficient one-step tasks.

Result: Achieves FID scores of 11.9 on CelebAMask-HQ and 7.0 on COCO-Stuff with 25 inference steps, and competitive results in segmentation and classification.

Conclusion: SymmFlow provides a versatile and efficient framework for unified generative and discriminative tasks, outperforming previous methods.

摘要: 流匹配已成为学习分布间连续变换的强大框架，支持高保真生成建模。本文提出对称流匹配（SymmFlow），通过对称学习目标将语义分割、分类和图像生成统一于单一模型中。SymmFlow联合建模正向和反向变换，确保双向一致性的同时保留生成多样性。新训练目标显式保留跨流的语义信息，支持高效采样并保持语义结构，实现无需迭代优化的单步分割与分类。与以往严格一对一映射方法不同，SymmFlow支持灵活条件输入，兼容像素级和图像级类别标签。多基准实验表明，SymmFlow在语义图像合成中达到领先水平，仅需25次推理步骤即在CelebAMask-HQ和COCO-Stuff上分别取得11.9和7.0的FID分数，同时在分割和分类任务中表现优异。代码将公开提供。

</details>


### [239] [GigaVideo-1: Advancing Video Generation via Automatic Feedback with 4 GPU-Hours Fine-Tuning](https://arxiv.org/abs/2506.10639)
**中文标题：GigaVideo-1：通过4 GPU小时的自动反馈微调推进视频生成**

*Xiaoyi Bao,Jindi Lv,Xiaofeng Wang,Zheng Zhu,Xinze Chen,YuKun Zhou,Jiancheng Lv,Xingang Wang,Guan Huang*

Main category: cs.CV

TL;DR: GigaVideo-1 is an efficient fine-tuning framework for video diffusion models that uses automatic feedback to improve video generation quality without human supervision, achieving significant performance gains with minimal computational resources.


<details>
  <summary>Details</summary>
Motivation: Existing fine-tuning methods for video diffusion models rely on human annotations and extensive computational resources, limiting their practicality. GigaVideo-1 aims to address these limitations by leveraging automatic feedback for efficient fine-tuning.

Method: GigaVideo-1 employs a prompt-driven data engine to create diverse, weakness-oriented training samples and a reward-guided training strategy that adaptively weights samples using feedback from pre-trained vision-language models with a realism constraint.

Result: GigaVideo-1 improves performance across 17 evaluation dimensions on the VBench-2.0 benchmark, achieving an average gain of about 4% with only 4 GPU-hours of fine-tuning.

Conclusion: GigaVideo-1 demonstrates effectiveness and efficiency in advancing video generation quality without manual annotations or extensive real data, making it a practical solution for fine-tuning video diffusion models.

摘要: 扩散模型的最新进展极大地提升了视频生成质量，但这些模型仍需通过微调来改进特定维度，如实例保留、运动合理性、构图和物理合理性。现有的微调方法通常依赖于人工标注和大规模计算资源，限制了其实用性。本文提出GigaVideo-1，一种高效的微调框架，无需额外人工监督即可提升视频生成质量。GigaVideo-1并非从外部注入大量高质量数据，而是通过自动反馈释放预训练视频扩散模型的潜在能力。具体而言，我们关注微调过程中的两个关键方面：数据和优化。为改进微调数据，我们设计了一个基于提示的数据引擎，构建多样化、针对弱点的训练样本。在优化方面，我们引入了一种奖励引导的训练策略，利用预训练视觉语言模型的反馈和真实性约束自适应地加权样本。我们在VBench-2.0基准上评估GigaVideo-1，以Wan2.1为基线，覆盖17个评估维度。实验表明，GigaVideo-1在几乎所有维度上均能持续提升性能，平均增益约4%，仅需4 GPU小时。无需人工标注和极少真实数据，GigaVideo-1展示了高效性和有效性。代码、模型和数据将公开提供。

</details>


### [240] [PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis](https://arxiv.org/abs/2506.10669)
**中文标题：PiPViT：基于补丁的可视化可解释原型用于视网膜图像分析**

*Marzieh Oghbaie,Teresa Araújoa,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: PiPViT introduces a patch-based prototype model for retinal image analysis, improving interpretability by learning human-understandable prototypes using a vision transformer and contrastive learning.


<details>
  <summary>Details</summary>
Motivation: Existing prototype-based methods lack consistency with human-understandable biomarkers in medical imaging, and their granular prototypes are less interpretable for clinical use.

Method: PiPViT uses a vision transformer (ViT) to capture long-range dependencies among patches, employs contrastive learning, and processes multi-resolution inputs to learn interpretable prototypes.

Result: PiPViT achieved competitive performance on retinal OCT image classification across four datasets, with prototypes confirmed as clinically relevant.

Conclusion: PiPViT provides transparent explanations for diagnostic decisions, aiding clinicians in understanding outcomes.

摘要: 背景与目标：基于原型的方法通过学习细粒度的部分原型来提高可解释性；然而，它们在输入像素空间中的可视化并不总是与人类可理解的生物标志物一致。此外，著名的基于原型的方法通常学习过于细粒度的原型，这在医学影像中可解释性较差，而生物标志物和病变的存在与范围都至关重要。
方法：为解决这些问题，我们提出了PiPViT（基于补丁的可视化可解释原型），一种本质可解释的原型模型用于图像识别。利用视觉变换器（ViT），PiPViT捕捉补丁之间的长程依赖关系，以学习稳健且人类可解释的原型，仅使用图像级标签近似病变范围。此外，PiPViT受益于对比学习和多分辨率输入处理，从而能够有效定位不同尺度的生物标志物。
结果：我们在四个数据集上评估了PiPViT在视网膜OCT图像分类中的表现，其定量性能与最先进方法相当，同时提供了更有意义的解释。此外，对保留测试集的定量评估证实了学习到的原型在语义和临床上是相关的。我们相信PiPViT可以透明地解释其决策，并帮助临床医生理解诊断结果。GitHub页面：https://github.com/marziehoghbaie/PiPViT

</details>


### [241] [Enhancing Deepfake Detection using SE Block Attention with CNN](https://arxiv.org/abs/2506.10683)
**中文标题：使用SE块注意力与CNN增强Deepfake检测**

*Subhram Dasgupta,Janelle Mason,Xiaohong Yuan,Olusola Odeyomi,Kaushik Roy*

Main category: cs.CV

TL;DR: The paper proposes a lightweight CNN with SE block attention for efficient Deepfake detection, achieving high accuracy with minimal computational resources.


<details>
  <summary>Details</summary>
Motivation: Deepfake technology poses a significant threat to information authenticity and security, and existing detection models are often resource-intensive. The goal is to develop a lightweight yet effective solution.

Method: The authors integrate a squeeze and excitation (SE) block with a CNN to dynamically recalibrate channel-wise features, emphasizing informative features and suppressing less useful ones.

Result: The model achieves 94.14% classification accuracy and an AUC-ROC score of 0.985 on the Style GAN dataset, demonstrating competitive performance with smaller size.

Conclusion: The proposed lightweight CNN with SE block attention offers an efficient and scalable solution for Deepfake detection, balancing accuracy and resource usage.

摘要: 在数字时代，Deepfake通过先进的人工智能技术制造高度逼真的篡改内容，对信息的真实性和安全性构成严峻挑战。这些复杂的伪造内容超越了传统检测方法的复杂性和真实性。为解决这一问题，我们旨在利用前沿的深度学习方法设计一种创新的Deepfake检测模型。然而，大多数现有的Deepfake检测模型体积庞大，导致存储和内存消耗过高。在本研究中，我们提出了一种轻量级的卷积神经网络（CNN）结合挤压激励块注意力（SE）用于Deepfake检测。SE块模块旨在动态调整通道特征，使网络能够强调信息丰富的特征并抑制无用特征，从而实现更高效的学习模块。该模块与简单的序列模型集成以执行Deepfake检测。该模型体积较小，同时在Deepfake检测任务中与现有模型竞争精度。在Diverse Fake Face Dataset的Style GAN数据集上，该模型的总体分类准确率为94.14%，AUC-ROC得分为0.985。我们提出的方法为以最小计算资源应对Deepfake挑战提供了一条有前景的途径，为数字内容验证开发了高效且可扩展的解决方案。

</details>


### [242] [Unsourced Adversarial CAPTCHA: A Bi-Phase Adversarial CAPTCHA Framework](https://arxiv.org/abs/2506.10685)
**中文标题：无源对抗验证码：一种双阶段对抗验证码框架**

*Xia Du,Xiaoyuan Liu,Jizhe Zhou,Zheng Lin,Chi-man Pun,Zhe Chen,Wei Ni,Jun Luo*

Main category: cs.CV

TL;DR: The paper introduces Unsourced Adversarial CAPTCHA (UAC), a framework generating high-fidelity adversarial examples using text prompts, enhancing CAPTCHA diversity and attack efficiency.


<details>
  <summary>Details</summary>
Motivation: Traditional CAPTCHAs are vulnerable to deep learning attacks, and existing adversarial methods often distort images, making them hard for humans to interpret. UAC addresses these issues by generating adversarial examples without relying on original images.

Method: UAC uses a Large Language Model (LLM) to guide adversarial example generation. For targeted attacks, the EDICT method optimizes dual latent variables in a diffusion model. For untargeted attacks, BP-UAC employs multimodal gradients and bi-path optimization.

Result: BP-UAC achieves high attack success rates across diverse systems, producing CAPTCHAs that are natural and indistinguishable to both humans and DNNs.

Conclusion: UAC provides a robust framework for generating adversarial CAPTCHAs, improving security and diversity while maintaining human interpretability.

摘要: 随着深度学习的快速发展，传统的验证码方案越来越容易受到基于深度神经网络（DNN）的自动化攻击。现有的对抗攻击方法通常依赖于原始图像特征，导致失真，影响人类理解，并在缺乏初始输入图像的场景中应用受限。为解决这些问题，我们提出了无源对抗验证码（UAC），这是一种新颖的框架，通过攻击者指定的文本提示生成高保真对抗样本。UAC利用大型语言模型（LLM）增强验证码多样性，并支持定向和非定向攻击。对于定向攻击，EDICT方法在扩散模型中优化双潜变量以获得更优图像质量。在非定向攻击中，特别是黑盒场景下，我们引入了双路径无源对抗验证码（BP-UAC），这是一种两步优化策略，采用多模态梯度和双路径优化以实现高效误分类。实验表明，BP-UAC在多种系统中实现了高攻击成功率，生成的验证码对人类和DNN均难以区分。

</details>


### [243] [Underage Detection through a Multi-Task and MultiAge Approach for Screening Minors in Unconstrained Imagery](https://arxiv.org/abs/2506.10689)
**中文标题：通过多任务和多年龄方法在无约束图像中筛查未成年人的未成年检测**

*Christopher Gaul,Eduardo Fidalgo,Enrique Alegre,Rocío Alaiz Rodríguez,Eri Pérez Corral*

Main category: cs.CV

TL;DR: The paper proposes a multi-task architecture for underage detection in unconstrained images, addressing data imbalance and distribution shifts with a novel loss function and rigorous evaluation benchmarks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the accuracy of automatic screening of minors in unconstrained images, overcoming challenges like data imbalance and distribution shifts.

Method: The method involves a multi-task architecture with a frozen FaRL backbone, a two-layer MLP, and specialized heads for age regression and under-age detection. It uses an α-reweighted focal-style loss and age-balanced mini-batch sampling.

Result: The model reduces age estimation error and improves under-18 detection F2 scores, demonstrating strong generalization under domain shifts.

Conclusion: The proposed multi-task approach effectively addresses underage detection challenges, showing robustness to real-world distribution shifts.

摘要: 准确自动筛查无约束图像中的未成年人需要模型对分布偏移具有鲁棒性，并能应对公开数据中儿童样本不足的问题。为解决这些问题，我们提出了一种多任务架构，基于冻结的FaRL视觉-语言骨干网络，结合一个紧凑的两层MLP，共享特征于一个年龄回归头和四个二元未成年检测头（针对12、15、18和21岁的法律关键年龄阈值）。为应对严重的类别不平衡，我们引入了α加权的焦点式损失和年龄平衡的小批量采样，在随机优化中均衡了12个年龄区间。通过去除边缘案例的年龄间隔，进一步提升了性能。

此外，我们提出了严格的评估标准，即“总体未成年基准”，包含30.3万张清理过的训练图像和11万张测试图像，定义了“ASORES-39k”受限总体测试（去除噪声最大的领域）和“ASWIFT-20k”年龄估计野外观测测试（2万张图像，模拟极端姿态（>45度）、表情和低图像质量的真实世界偏移）。

在清理后的总体数据集上训练并采用重采样和年龄间隔后，我们的多年龄模型“F”在ASORES-39k受限测试中将年龄估计的均方根误差从5.733（仅年龄基线）降低到5.656岁，并将18岁以下检测的F2分数从0.801提升到0.857（假阳性率为1%）。在ASWIFT-20k野外观测数据的域偏移下，相同配置几乎保持了0.99的召回率，同时将F2分数从0.742提升到0.833（相对于仅年龄基线），展示了在分布偏移下的强泛化能力。对于12岁以下和15岁以下任务，F2分数分别从0.666提升到0.955和从0.689提升到0.916。

</details>


### [244] [Continual Hyperbolic Learning of Instances and Classes](https://arxiv.org/abs/2506.10710)
**中文标题：实例与类别的持续双曲学习**

*Melika Ayoughi,Mina Ghadimi Atigh,Mohammad Mahdi Derakhshani,Cees G. M. Snoek,Pascal Mettes,Paul Groth*

Main category: cs.CV

TL;DR: The paper introduces HyperCLIC, a continual learning algorithm using hyperbolic space to handle hierarchical relationships between instances and classes, validated on the EgoObjects dataset.


<details>
  <summary>Details</summary>
Motivation: Real-world applications like robotics require models to simultaneously learn instances and classes, which form a hierarchical structure. Current continual learning methods focus on either instances or classes, not both.

Method: Proposes HyperCLIC, leveraging hyperbolic space for hierarchical data representation, incorporating hyperbolic classification and distillation objectives for continual embedding of hierarchical relations.

Result: HyperCLIC effectively operates at multiple granularities with improved hierarchical generalization, validated on the EgoObjects dataset.

Conclusion: HyperCLIC addresses the challenge of continual learning of both instances and classes by modeling their hierarchical relationships in hyperbolic space, showing superior performance.

摘要: 持续学习传统上专注于对实例或类别进行分类，但现实应用（如机器人和自动驾驶汽车）要求模型同时处理两者。为了模拟现实场景，我们引入了同时持续学习实例和类别的任务。该任务挑战模型随时间适应多级粒度，需要在细粒度实例识别与粗粒度类别泛化之间取得平衡。本文指出，类别和实例自然形成层次结构。为了建模这些层次关系，我们提出了HyperCLIC，一种利用双曲空间的持续学习算法，双曲空间因其能够以低失真和紧凑嵌入表示树状结构而特别适合层次数据。我们的框架结合了双曲分类和蒸馏目标，实现了层次关系的持续嵌入。为了评估多粒度性能，我们引入了持续层次指标。我们在EgoObjects数据集上验证了我们的方法，这是唯一捕捉动态现实环境中层次对象识别复杂性的数据集。实证结果表明，HyperCLIC在多粒度上有效运行，具有改进的层次泛化能力。

</details>


### [245] [Uncertainty-Masked Bernoulli Diffusion for Camouflaged Object Detection Refinement](https://arxiv.org/abs/2506.10712)
**中文标题：基于不确定性掩蔽伯努利扩散的伪装目标检测细化**

*Yuqi Shen,Fengyang Xiao,Sujie Hu,Youwei Pang,Yifan Pu,Chengyu Fang,Xiu Li,Chunming He*

Main category: cs.CV

TL;DR: The paper proposes the Uncertainty-Masked Bernoulli Diffusion (UMBD) model, a generative refinement framework for Camouflaged Object Detection (COD), which selectively refines poorly segmented regions using uncertainty-guided masking and achieves significant performance improvements.


<details>
  <summary>Details</summary>
Motivation: Existing COD methods lack effective post-processing refinement, limiting their performance despite progress in segmentation. The paper aims to address this gap by introducing a targeted refinement approach.

Method: UMBD uses an uncertainty-guided masking mechanism to apply Bernoulli diffusion to residual regions with poor segmentation. It integrates the Hybrid Uncertainty Quantification Network (HUQNet) for accurate uncertainty estimation and adaptive guidance during refinement.

Result: UMBD consistently improves performance across COD benchmarks, achieving average gains of 5.5% in MAE and 3.2% in weighted F-measure with modest computational overhead.

Conclusion: The UMBD framework effectively combines discriminative COD models with generative refinement, demonstrating its potential for enhancing COD performance without significant computational cost.

摘要: 伪装目标检测（COD）由于目标与背景之间微妙的视觉差异而具有固有挑战性。尽管现有方法已取得显著进展，但后处理细化的潜力尚未充分挖掘。为解决这一局限，我们提出了不确定性掩蔽伯努利扩散（UMBD）模型，这是首个专为COD设计的生成式细化框架。UMBD引入了一种不确定性引导的掩蔽机制，选择性地对分割质量较差的残差区域应用伯努利扩散，从而实现针对性细化并保留正确分割区域。为支持这一过程，我们设计了混合不确定性量化网络（HUQNet），采用多分支架构并融合多源不确定性以提高估计精度，从而在生成采样过程中提供自适应引导。所提出的UMBD框架可与多种基于编码器-解码器的COD模型无缝集成，结合其判别能力与基于扩散的细化生成优势。在多个COD基准测试上的广泛实验表明，该方法实现了性能的持续提升，仅需适度的计算开销即可平均提升5.5%的MAE和3.2%的加权F-measure。代码将公开。

</details>


### [246] [Deep Learning-based Multi Project InP Wafer Simulation for Unsupervised Surface Defect Detection](https://arxiv.org/abs/2506.10713)
**中文标题：基于深度学习的多项目InP晶圆模拟用于无监督表面缺陷检测**

*Emílio Dolgener Cantú,Rolf Klemens Wittmann,Oliver Abdeen,Patrick Wagner,Wojciech Samek,Moritz Baier,Sebastian Lapuschkin*

Main category: cs.CV

TL;DR: The paper proposes a deep learning method to generate synthetic golden standards from CAD data for unsupervised defect detection in InP wafer manufacturing, outperforming traditional approaches.


<details>
  <summary>Details</summary>
Motivation: Current defect detection in InP wafer manufacturing is manual due to lack of golden standards, which is inefficient and labor-intensive.

Method: The method uses Deep Neural Networks to simulate photo-realistic InP wafer images from CAD data, evaluating various training objectives and image quality.

Result: The deep-learning-based approach outperforms a baseline decision-tree method, enabling efficient defect detection using simulated golden standards.

Conclusion: The proposed method provides a practical solution for automated defect detection in InP wafer manufacturing, improving efficiency and reducing manual effort.

摘要: 半导体制造中的质量管理通常依赖于已知黄金标准的模板匹配。对于磷化铟（InP）多项目晶圆制造，低生产规模和高设计变异性导致此类黄金标准通常不可用。因此，缺陷检测是手动且劳动密集型的。本研究通过提出一种方法来解决这一挑战，该方法利用深度神经网络从CAD数据生成合成的黄金标准，模拟逼真的InP晶圆图像。我们评估了各种训练目标，并在合成数据和InP晶圆照片上评估了模拟图像的质量。我们的基于深度学习的方法优于基于决策树的基线方法，使得可以从CAD计划中在任何用户定义的晶圆区域使用“模拟黄金芯片”，以实现更高效的缺陷检测。我们将该方法应用于模板匹配过程，以展示其在表面缺陷检测中的实际效用。

</details>


### [247] [IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain](https://arxiv.org/abs/2506.10730)
**中文标题：IQE-CLIP：面向医学领域的实例感知查询嵌入零样本/少样本异常检测**

*Hong Huang,Weixiang Sun,Zhijian Wu,Jingwen Niu,Donghuan Lu,Xian Wu,Yefeng Zheng*

Main category: cs.CV

TL;DR: IQE-CLIP is a novel framework for zero-/few-shot anomaly detection in the medical domain, leveraging instance-aware query embeddings and learnable prompts to outperform existing CLIP-based methods.


<details>
  <summary>Details</summary>
Motivation: Existing CLIP-based methods for anomaly detection rely on predefined prompts and lack instance-level discrimination, especially in medical tasks. IQE-CLIP aims to address these limitations by integrating visual and textual information for better anomaly detection.

Method: IQE-CLIP introduces class-based and learnable prompting tokens for CLIP adaptation and an instance-aware query module to extract region-level contextual information, generating anomaly-sensitive embeddings.

Result: Experiments on six medical datasets show IQE-CLIP achieves state-of-the-art performance in zero-shot and few-shot anomaly detection.

Conclusion: IQE-CLIP effectively combines textual and visual information for anomaly detection in medical tasks, demonstrating superior performance and adaptability.

摘要: 近年来，视觉语言模型（如CLIP）在零样本和少样本异常检测（ZFSAD）任务中取得了显著进展。然而，现有的大多数基于CLIP的方法假设已知类别信息，并依赖于针对特定场景精心设计的提示。这些文本提示虽然能捕捉文本空间的语义信息，但往往无法在联合嵌入空间中区分正常和异常实例。此外，大多数ZFSAD方法集中在工业领域，对医学任务的探索有限。为解决这些问题，我们提出了IQE-CLIP，一种面向医学领域的ZFSAD新框架。我们证明，结合文本和实例感知视觉信息的查询嵌入能更有效地指示异常。具体而言，我们引入了基于类别和可学习的提示标记，以更好地将CLIP适配到医学场景。此外，我们设计了一个实例感知查询模块，从两种模态中提取区域级上下文信息，从而生成对异常敏感的嵌入。在六个医学数据集上的大量实验表明，IQE-CLIP在零样本和少样本设置下均达到了最先进的性能。代码和数据可在\href{https://github.com/hongh0/IQE-CLIP/}{此链接}获取。

</details>


### [248] [PosterCraft: Rethinking High-Quality Aesthetic Poster Generation in a Unified Framework](https://arxiv.org/abs/2506.10741)
**中文标题：PosterCraft：重新思考高质量美学海报生成的统一框架**

*SiXiang Chen,Jianyu Lai,Jialin Gao,Tian Ye,Haoyu Chen,Hengyu Shi,Shitong Shao,Yunlong Lin,Song Fei,Zhaohu Xing,Yeying Jin,Junfeng Luo,Xiaoming Wei,Lei Zhu*

Main category: cs.CV

TL;DR: PosterCraft introduces a unified framework for generating high-quality aesthetic posters by optimizing text rendering, layout coherence, and stylistic harmony through a cascaded workflow and automated data-construction pipelines.


<details>
  <summary>Details</summary>
Motivation: Generating aesthetic posters is complex, requiring precise text rendering and seamless integration of artistic content. Existing modular pipelines and rigid layouts limit creativity and quality.

Method: PosterCraft uses a cascaded workflow: (i) text-rendering optimization, (ii) region-aware fine-tuning, (iii) aesthetic-text reinforcement learning, and (iv) joint vision-language feedback refinement, supported by automated data pipelines.

Result: PosterCraft outperforms open-source baselines in rendering accuracy, layout coherence, and visual appeal, approaching SOTA commercial system quality.

Conclusion: PosterCraft provides a robust, unified framework for high-quality poster generation, leveraging automated data pipelines and a flexible approach to layout and style.

摘要: 生成美学海报比简单的设计图像更具挑战性：它不仅需要精确的文本渲染，还需要无缝整合抽象艺术内容、引人注目的布局和整体风格和谐。为此，我们提出了PosterCraft，一个统一的框架，摒弃了先前的模块化流程和僵化的预定义布局，使模型能够自由探索连贯且视觉吸引人的构图。PosterCraft采用精心设计的级联工作流程来优化高质量美学海报的生成：（i）在我们新引入的Text-Render-2M数据集上进行大规模文本渲染优化；（ii）在HQ-Poster100K上进行区域感知的监督微调；（iii）通过最佳偏好优化进行美学文本强化学习；（iv）联合视觉语言反馈细化。每个阶段都配备了完全自动化的数据构建流程，以满足其特定需求，从而无需复杂的架构修改即可实现稳健训练。通过多项实验评估，PosterCraft在渲染准确性、布局连贯性和整体视觉吸引力方面显著优于开源基线，接近最先进的商业系统质量。我们的代码、模型和数据集可在项目页面找到：https://ephemeral182.github.io/PosterCraft

</details>


### [249] [Stroke-based Cyclic Amplifier: Image Super-Resolution at Arbitrary Ultra-Large Scales](https://arxiv.org/abs/2506.10774)
**中文标题：基于笔画的循环放大器：任意超大规模下的图像超分辨率**

*Wenhao Guo,Peng Lu,Xujun Peng,Zhaoran Zhao,Sheng Li*

Main category: cs.CV

TL;DR: The paper introduces Stroke-based Cyclic Amplifier (SbCA), a unified model for ultra-large image super-resolution, addressing performance decline and blurring in existing methods by decomposing images into stroke vectors and iteratively refining details.


<details>
  <summary>Details</summary>
Motivation: Existing Arbitrary-Scale Image Super-Resolution (ASISR) methods perform poorly at ultra-large scales beyond training data, causing blurring and artifacts. The paper aims to solve this by proposing a model that maintains high fidelity even at extreme upsampling factors.

Method: SbCA decomposes images into stroke vectors for magnification and uses a detail completion module to restore missing details. A cyclic strategy iteratively refines the image, trained once for all scales.

Result: SbCA outperforms state-of-the-art methods in ultra-large upsampling (e.g., ×100), producing high-quality, artifact-free images with superior visual fidelity.

Conclusion: The proposed SbCA model effectively addresses distribution drift and blurring in ultra-large super-resolution, delivering high-quality results beyond the capabilities of existing methods.

摘要: 先前的任意尺度图像超分辨率（ASISR）方法在放大因子超出训练数据范围时性能显著下降，导致严重模糊。为解决这一问题，我们提出了一种统一模型——基于笔画的循环放大器（SbCA），用于超大规模放大任务。SbCA的核心是笔画向量放大器，它将图像分解为一系列以矢量图形表示的笔画进行放大。随后，细节补全模块恢复缺失细节，确保高保真图像重建。我们的循环策略通过迭代细化细节实现超大规模放大，仅需一次训练即可适用于所有尺度，同时保持子尺度在训练范围内。该方法有效解决了分布漂移问题，消除了伪影、噪声和模糊，生成高质量的高分辨率超分辨率图像。在合成和真实数据集上的实验验证表明，我们的方法在超大规模放大任务（如×100）中显著优于现有方法，视觉质量远超最先进技术。

</details>


### [250] [SlotPi: Physics-informed Object-centric Reasoning Models](https://arxiv.org/abs/2506.10778)
**中文标题：SlotPi：基于物理知识的对象中心推理模型**

*Jian Li,Wan Han,Ning Lin,Yu-Liang Zhan,Ruizhi Chengze,Haining Wang,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Hao Sun*

Main category: cs.CV

TL;DR: SlotPi is a physics-informed object-centric reasoning model that integrates Hamiltonian principles for dynamic forecasting, validated on diverse datasets including fluid dynamics.


<details>
  <summary>Details</summary>
Motivation: Current object-centric dynamic simulation methods lack integration of physical knowledge and validation across diverse scenarios, especially involving fluids and objects.

Method: SlotPi combines a Hamiltonian-based physical module with a spatio-temporal prediction module for dynamic forecasting.

Result: SlotPi excels in prediction and VQA tasks on benchmark and fluid datasets, demonstrating strong adaptability.

Conclusion: SlotPi's robust performance lays a foundation for advanced world models, addressing gaps in physical knowledge integration and scenario adaptability.

摘要: 通过视觉观察理解和推理受物理定律支配的动态过程，类似于人类在现实世界中的能力，具有重大挑战。目前，模拟人类行为的对象中心动态模拟方法已取得显著进展，但忽略了两个关键方面：1）将物理知识整合到模型中。人类通过观察世界获得物理洞察，并应用这些知识准确推理各种动态场景；2）验证模型在多样化场景中的适应性。现实世界的动态，尤其是涉及流体和物体的动态，要求模型不仅能捕捉物体交互，还能模拟流体流动特性。为解决这些问题，我们提出了SlotPi，一种基于槽的物理知识对象中心推理模型。SlotPi将基于哈密顿原理的物理模块与时空预测模块结合，用于动态预测。实验表明，该模型在基准和流体数据集上的预测和视觉问答（VQA）任务中表现出色。此外，我们创建了一个涵盖物体交互、流体动态和流体-物体交互的真实世界数据集，验证了模型的性能。模型在所有数据集上的稳健表现凸显了其强大的适应性，为开发更先进的世界模型奠定了基础。

</details>


### [251] [Human-Robot Navigation using Event-based Cameras and Reinforcement Learning](https://arxiv.org/abs/2506.10790)
**中文标题：基于事件相机和强化学习的人机导航**

*Ignacio Bugueno-Cordova,Javier Ruiz-del-Solar,Rodrigo Verschae*

Main category: cs.CV

TL;DR: A robot navigation controller using event cameras and reinforcement learning for real-time human-centered navigation and obstacle avoidance, outperforming conventional image-based methods.


<details>
  <summary>Details</summary>
Motivation: Conventional image-based controllers suffer from motion blur, latency, and fixed processing rates. Event cameras offer asynchronous, adaptive visual processing, making them ideal for dynamic navigation tasks.

Method: Combines event-based perception, range sensing, and reinforcement learning (Deep Deterministic Policy Gradient) with an initial imitation learning phase for improved sample efficiency.

Result: Demonstrates robust navigation, pedestrian following, and obstacle avoidance in simulated environments.

Conclusion: The framework successfully integrates event cameras and reinforcement learning for adaptive, real-time navigation, showing promise for practical applications.

摘要: 本研究提出了一种结合事件相机和其他传感器与强化学习的机器人导航控制器，以实现实时以人为中心的导航和避障。与传统的基于图像的控制器（以固定速率运行且存在运动模糊和延迟问题）不同，该方法利用事件相机的异步特性，在灵活的时间间隔内处理视觉信息，从而实现自适应推理和控制。该框架集成了基于事件的感知、额外的距离传感以及通过深度确定性策略梯度进行的策略优化，并通过初始模仿学习阶段提高了样本效率。在模拟环境中取得了令人鼓舞的结果，展示了鲁棒的导航、行人跟随和避障能力。演示视频可在项目网站上查看。

</details>


### [252] [Prompts to Summaries: Zero-Shot Language-Guided Video Summarization](https://arxiv.org/abs/2506.10807)
**中文标题：从提示到摘要：零样本语言引导的视频摘要**

*Mario Barbara,Alaa Maalouf*

Main category: cs.CV

TL;DR: The paper introduces Prompts-to-Summaries, a zero-shot, text-queryable video summarization method that leverages off-the-shelf video-language models and large language models without training data, outperforming unsupervised and matching supervised methods.


<details>
  <summary>Details</summary>
Motivation: The explosive growth of video data necessitates flexible, user-controllable summarization tools that can operate without domain-specific training data and incorporate user intent expressed in natural language.

Method: The pipeline segments raw video into scenes, generates scene-level descriptions via a memory-efficient VidLM prompting scheme, uses an LLM to assign importance scores, and propagates scores to frame-level via consistency and uniqueness metrics.

Result: The method surpasses prior unsupervised methods on SumMe and TVSum and performs competitively on the QFVS benchmark without training data, while also introducing a new dataset, VidSum-Reason.

Conclusion: Pretrained multimodal models, combined with principled prompting and score propagation, provide a powerful foundation for universal, text-queryable video summarization.

摘要: 视频数据的爆炸性增长加剧了对无需领域特定训练数据且能灵活响应用户需求的摘要工具的需求。现有方法要么依赖数据集，限制了泛化能力，要么无法融入用户通过自然语言表达的意图。我们提出了“从提示到摘要”：首个零样本、可通过文本查询的视频摘要工具，它利用现成的视频-语言模型（VidLMs）生成字幕，并通过大型语言模型（LLMs）的评判将其转化为用户引导的摘要，完全无需训练数据，超越了所有无监督方法，并与有监督方法表现相当。我们的流程包括：（i）将原始视频分割为连贯场景，（ii）通过高效内存的批量式VidLM提示方案生成丰富的场景级描述，可扩展至单GPU处理数小时长的视频，（iii）利用LLM作为评判者，在精心设计的提示下为场景分配重要性分数，（iv）通过两个新指标（一致性（时间连贯性）和独特性（新颖性））将分数传播至短片段级别，得到细粒度的帧重要性。在SumMe和TVSum上，我们的无数据方法超越了所有依赖数据的无监督方法。在查询聚焦视频摘要（QFVS）基准测试中，尽管未使用训练数据且竞争对手需要监督帧级重要性，我们的方法仍表现优异。为促进进一步研究，我们发布了VidSum-Reason，一个包含长尾概念和多步推理的新查询驱动数据集；我们的框架在该数据集上取得了稳健的F1分数，并成为首个具有挑战性的基线。总体而言，我们的结果表明，预训练的多模态模型通过原则性提示和分数传播，已为通用、可通过文本查询的视频摘要提供了强大基础。

</details>


### [253] [Unsupervised Deformable Image Registration with Structural Nonparametric Smoothing](https://arxiv.org/abs/2506.10813)
**中文标题：基于结构非参数平滑的无监督可变形图像配准**

*Hang Zhang,Xiang Chen,Renjiu Hu,Rongguang Wang,Jinwei Zhang,Min Liu,Yaonan Wang,Gaolei Li,Xinxing Cheng,Jinming Duan*

Main category: cs.CV

TL;DR: The paper introduces SmoothProper, a neural module for unsupervised deformable image registration (DIR) that addresses challenges like aperture and large displacements by enforcing smoothness and structural consistency without label supervision.


<details>
  <summary>Details</summary>
Motivation: Existing unsupervised DIR methods struggle with images containing sparse features amid large smooth regions (e.g., retinal vessels), as they predict deformation fields in a single forward pass without post-training constraints, shifting regularization entirely to network weights.

Method: SmoothProper integrates a duality-based optimization layer with tailored interaction terms to propagate flow signals, enforce smoothness, and preserve structural consistency. It is model-agnostic, adds minimal parameter overhead, and eliminates hyperparameter tuning.

Result: On a retinal vessel dataset with aperture and large-displacement challenges, SmoothProper reduces registration error to 1.88 pixels on 2912x2912 images, outperforming existing unsupervised DIR methods.

Conclusion: SmoothProper is the first unsupervised DIR approach to effectively address aperture and large-displacement challenges, offering a plug-and-play solution that enhances registration accuracy without label supervision.

摘要: 基于学习的可变形图像配准（DIR）通过神经网络摊销传统优化过程，加速了图像对齐。标签监督进一步提高了准确性，实现了对未见扫描图像的高效、精确非线性对齐。然而，对于具有稀疏特征且包含大面积平滑区域的图像（如视网膜血管），现有无监督DIR方法难以解决孔径和大位移的挑战。这是因为神经网络在单次前向传递中预测变形场，导致场在训练后不受约束，并将正则化负担完全转移到网络权重上。为解决这些问题，我们提出了SmoothProper，一种即插即用的神经模块，通过在前向传递中强制平滑性和促进消息传递来优化配准。通过将基于对偶的优化层与定制的交互项相结合，SmoothPrope高效地在空间位置间传播流信号，强制平滑性并保持结构一致性。该模块与模型无关，能够无缝集成到现有配准框架中，且参数开销极小，同时消除了正则化超参数调优的需求。在具有孔径和大位移挑战的视网膜血管数据集上的初步结果表明，我们的方法将配准误差降至1.88像素（2912x2912图像），这是首个有效解决这两大挑战的无监督DIR方法。源代码将在https://github.com/tinymilky/SmoothProper上提供。

</details>


### [254] [Occlusion-Aware 3D Hand-Object Pose Estimation with Masked AutoEncoders](https://arxiv.org/abs/2506.10816)
**中文标题：基于掩码自编码器的遮挡感知3D手物姿态估计**

*Hui Yang,Wei Sun,Jian Liu,Jin Zheng,Jian Xiao,Ajmal Mian*

Main category: cs.CV

TL;DR: The paper proposes HOMAE, an occlusion-aware method for 3D hand-object pose estimation using masked autoencoders, achieving state-of-the-art performance by integrating multi-scale features and combining implicit SDF with explicit point clouds.


<details>
  <summary>Details</summary>
Motivation: Hand-object pose estimation from monocular RGB images is challenging due to severe occlusions. Existing methods lack global structural perception, limiting their effectiveness.

Method: HOMAE uses a target-focused masking strategy to impose structured occlusion, integrates multi-scale features to predict an SDF, and combines implicit SDF with explicit point clouds for robust handling of occlusions.

Result: HOMAE achieves state-of-the-art performance on DexYCB and HO3Dv2 benchmarks.

Conclusion: The proposed method effectively addresses occlusion challenges in hand-object pose estimation by leveraging global context and local geometry.

摘要: 从单目RGB图像中估计手物姿态仍然是一个重大挑战，主要是由于手物交互中固有的严重遮挡。现有方法未能充分探索全局结构感知和推理，限制了其在处理遮挡手物交互中的效果。为解决这一挑战，我们提出了一种基于掩码自编码器的遮挡感知手物姿态估计方法，称为HOMAE。具体而言，我们提出了一种目标聚焦的掩码策略，对手物交互区域施加结构化遮挡，促使模型学习上下文感知特征并推理遮挡结构。我们进一步整合从解码器提取的多尺度特征，预测一个有符号距离场（SDF），捕捉全局上下文和细粒度几何。为增强几何感知，我们将隐式SDF与从SDF导出的显式点云结合，利用两种表示的互补优势。这种融合通过结合SDF的全局上下文和点云提供的精确局部几何，实现了对遮挡区域的更鲁棒处理。在具有挑战性的DexYCB和HO3Dv2基准上的大量实验表明，HOMAE在手物姿态估计中达到了最先进的性能。我们将发布代码和模型。

</details>


### [255] [VideoDeepResearch: Long Video Understanding With Agentic Tool Using](https://arxiv.org/abs/2506.10821)
**中文标题：VideoDeepResearch：基于代理工具的长视频理解研究**

*Huaying Yuan,Zheng Liu,Junjie Zhou,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.CV

TL;DR: VideoDeepResearch introduces an agentic framework for long video understanding (LVU) using a text-only reasoning model and modular tools, outperforming MLLM baselines by significant margins.


<details>
  <summary>Details</summary>
Motivation: Current MLLMs struggle with LVU due to complexity and context constraints. The paper challenges the need for extended context MLLMs by proposing a simpler, tool-based approach.

Method: The framework combines a text-only reasoning model with modular tools (multimodal retrievers, visual perceivers) to selectively access and utilize video content.

Result: VideoDeepResearch outperforms MLLM baselines by 9.6%, 6.6%, and 3.9% on MLVU, LVBench, and LongVideoBench, respectively.

Conclusion: Agentic systems with modular tools can effectively address LVU challenges without relying on complex MLLMs.

摘要: 长视频理解（LVU）由于其固有的复杂性和上下文窗口限制，对当前的多模态大语言模型（MLLM）提出了重大挑战。普遍认为解决LVU任务需要具备扩展上下文窗口、强大视觉感知能力和熟练领域知识的基础MLLM。在这项工作中，我们通过引入VideoDeepResearch，一种新颖的代理框架，挑战了这一常见观点。我们的方法仅依赖于纯文本的大推理模型（LRM）与模块化多模态工具包（包括多模态检索器和视觉感知器）的结合，这些工具在实践中易于获取。对于每个LVU任务，系统通过推理制定问题解决策略，同时选择性访问和利用关键视频内容。我们在流行的LVU基准测试（包括MLVU、Video-MME和LVBench）上进行了广泛实验。结果表明，VideoDeepResearch显著优于现有MLLM基线，在MLVU（测试）、LVBench和LongVideoBench上分别超越了之前的最先进水平9.6%、6.6%和3.9%。这些发现凸显了代理系统在克服LVU问题关键挑战中的潜力。

</details>


### [256] [Post-Training Quantization for Video Matting](https://arxiv.org/abs/2506.10840)
**中文标题：视频抠图的后训练量化**

*Tianrui Zhu,Houyuan Chen,Ruihao Gong,Michele Magno,Haotong Qin,Kai Zhang*

Main category: cs.CV

TL;DR: The paper proposes a novel Post-Training Quantization (PTQ) framework for video matting, combining block-reconstruction optimization, global calibration, and optical flow assistance to achieve high accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Video matting is computationally intensive, and deploying it on resource-constrained devices is challenging. PTQ is underdeveloped for video matting, facing issues in accuracy and temporal coherence.

Method: The framework includes a two-stage PTQ strategy (block-reconstruction optimization and global calibration) and an Optical Flow Assistance component to enhance temporal coherence.

Result: PTQ4VM achieves state-of-the-art accuracy across bit-widths, with 4-bit quantization performing close to full-precision while saving 8x FLOPs.

Conclusion: The proposed PTQ framework effectively addresses challenges in video matting quantization, achieving high accuracy and efficiency.

摘要: 视频抠图在电影制作和虚拟现实等应用中至关重要，但其计算密集型模型在资源受限设备上的部署面临挑战。量化是模型压缩和加速的关键技术。作为一种高效方法，后训练量化（PTQ）在视频抠图中仍处于起步阶段，面临保持准确性和时间一致性的重大障碍。为解决这些问题，本文提出了一种专为视频抠图模型设计的新颖通用PTQ框架，据我们所知，这是该领域的首次系统性尝试。我们的贡献包括：（1）一种两阶段PTQ策略，结合基于块重建的优化以实现快速、稳定的初始量化和局部依赖捕获，随后通过全局校准量化参数以最小化精度损失。（2）一种统计驱动的全局仿射校准（GAC）方法，使网络能够补偿因忽略BN层效应等因素引起的累积统计失真，甚至将现有PTQ方法在视频抠图任务中的误差降低高达20%。（3）一种光流辅助（OFA）组件，利用帧的时空和语义先验指导PTQ过程，增强模型在复杂场景中区分运动前景的能力，最终在超低位量化下实现接近全精度的性能。全面的定量和视觉结果表明，与现有量化方法相比，PTQ4VM在不同位宽下均实现了最先进的精度性能。我们强调，4位PTQ4VM甚至实现了接近全精度的性能，同时节省了8倍的浮点运算量。

</details>


### [257] [VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos](https://arxiv.org/abs/2506.10857)
**中文标题：VRBench：长叙事视频中多步推理的基准测试**

*Jiashuo Yu,Yue Wu,Meng Chu,Zhifei Ren,Zizheng Huang,Pei Chu,Ruijie Zhang,Yinan He,Qirui Li,Songze Li,Zhenxiang Li,Zhongying Tu,Conghui He,Yu Qiao,Yali Wang,Yi Wang,Limin Wang*

Main category: cs.CV

TL;DR: VRBench is a new benchmark for evaluating multi-step reasoning in long narrative videos, featuring 1,010 videos, 9,468 QA pairs, and 30,292 reasoning steps, with a focus on temporal and procedural validity.


<details>
  <summary>Details</summary>
Motivation: Existing evaluations lack focus on temporal reasoning and procedural validity in long videos, limiting the assessment of large models' multi-step reasoning capabilities.

Method: VRBench includes a multi-stage filtering process for video curation, a human-AI framework for generating reasoning chains, and a multi-phase evaluation pipeline with MCQ and LLM-guided scoring.

Result: Extensive evaluations of 12 LLMs and 16 VLMs on VRBench provided insights into multi-step reasoning, highlighting model strengths and weaknesses.

Conclusion: VRBench advances the field by offering a comprehensive benchmark for evaluating multi-step reasoning in long videos, with potential for future improvements.

摘要: 我们提出了VRBench，这是首个专为评估大型模型在多步推理能力方面的长叙事视频基准测试，解决了现有评估中忽视时间推理和程序有效性的问题。它包含1,010个长视频（平均时长1.6小时），以及9,468个人工标注的多步问答对和30,292个带时间戳的推理步骤。这些视频通过多阶段筛选过程（包括专家互评）以确保情节连贯性。我们开发了一个人机协作框架，生成连贯的推理链，每条链需要多个时间锚定的步骤，涵盖七种类型（如事件归因、隐式推理）。VRBench设计了一个多阶段评估流程，从结果和过程两个层面评估模型。除了用于最终结果的多选题外，我们还提出了一个基于进度的LLM引导评分指标，从多个维度全面评估推理链的质量。通过对12个LLM和16个VLM在VRBench上的广泛评估，我们进行了深入分析，并提供了推动多步推理领域发展的宝贵见解。

</details>


### [258] [CreatiPoster: Towards Editable and Controllable Multi-Layer Graphic Design Generation](https://arxiv.org/abs/2506.10890)
**中文标题：CreatiPoster：迈向可编辑和可控的多层图形设计生成**

*Zhao Zhang,Yutao Cheng,Dexiang Hong,Maoke Yang,Gonglei Shi,Lei Ma,Hui Zhang,Jie Shao,Xinglong Wu*

Main category: cs.CV

TL;DR: CreatiPoster is a framework for generating editable, multi-layer graphic designs from natural-language instructions or assets, outperforming existing tools and releasing a 100,000-design corpus.


<details>
  <summary>Details</summary>
Motivation: Current AI tools for graphic design struggle with editability, user asset integration, and professional appeal, while template-based systems are impractical. CreatiPoster aims to democratize high-quality, editable design generation.

Method: CreatiPoster uses a protocol model (RGBA large multimodal model) to generate a JSON specification for each layer (text/asset) and a conditional background model to synthesize coherent backgrounds. It supports diverse applications like canvas editing and multilingual adaptation.

Result: CreatiPoster surpasses leading open-source and proprietary systems, demonstrated by automated metrics. A copyright-free corpus of 100,000 designs is released to aid research.

Conclusion: CreatiPoster advances AI-assisted graphic design by enabling editable, high-quality compositions and supporting diverse applications, fostering democratization in the field.

摘要: 图形设计在商业和个人场景中扮演着关键角色，然而创建高质量、可编辑且美观的图形组合仍然是一项耗时且需要专业技能的任务，尤其是对初学者而言。当前的AI工具虽然自动化了部分工作流程，但在准确整合用户提供的素材、保持可编辑性和实现专业视觉吸引力方面仍有不足。商业系统（如Canva Magic Design）依赖庞大的模板库，但这些模板难以复制。本文介绍了CreatiPoster，一个从可选的自然语言指令或素材生成可编辑多层组合的框架。协议模型（一种RGBA大型多模态模型）首先生成一个JSON规范，详细描述每一层（文本或素材）的精确布局、层次、内容和样式，以及简洁的背景提示。随后，条件背景模型根据这些渲染的前景层合成连贯的背景。我们构建了一个带有自动化指标的图形设计生成基准，并展示CreatiPoster超越了领先的开源方法和专有商业系统。为了推动进一步研究，我们发布了一个包含10万个多层设计的无版权语料库。CreatiPoster支持多种应用，如画布编辑、文本叠加、响应式调整、多语言适配和动态海报，推动了AI辅助图形设计的民主化。项目主页：https://github.com/graphic-design-ai/creatiposter

</details>


### [259] [AIR: Zero-shot Generative Model Adaptation with Iterative Refinement](https://arxiv.org/abs/2506.10895)
**中文标题：AIR：通过迭代优化的零样本生成模型适应**

*Guimeng Liu,Milad Abdollahzadeh,Ngai-Man Cheung*

Main category: cs.CV

TL;DR: The paper introduces AIR, a zero-shot generative model adaptation method that improves image quality by addressing misalignment between text and image offsets in CLIP embedding space, leveraging iterative refinement.


<details>
  <summary>Details</summary>
Motivation: Existing zero-shot generative model adaptation methods assume perfect alignment between text and image offsets in CLIP embedding space, leading to degraded image quality. The paper aims to address this limitation by analyzing and mitigating offset misalignment.

Method: The authors propose Adaptation with Iterative Refinement (AIR), which focuses on improving target domain image quality by leveraging insights from offset misalignment studies in NLP. AIR iteratively refines the alignment between text and image offsets.

Result: AIR achieves state-of-the-art performance in qualitative, quantitative, and user studies across 26 experimental setups, demonstrating superior image quality compared to existing methods.

Conclusion: The study highlights the importance of addressing offset misalignment in zero-shot generative model adaptation and validates AIR as an effective solution for improving image quality.

摘要: 零样本生成模型适应（ZSGM）旨在仅通过文本指导，无需目标域的任何样本，将预训练的生成器适应到目标域。近期ZSGM方法的核心是方向性损失，它利用文本指导的形式，在视觉-语言模型（如CLIP）的嵌入空间中对齐图像偏移与文本偏移。这与NLP中的类比推理类似，即通过对齐两对词之间的偏移来识别另一对词中的缺失元素。然而，现有ZSGM方法的一个主要局限是学习目标假设图像偏移与文本偏移在CLIP嵌入空间中完全对齐，导致生成图像质量下降。我们的工作有两个主要贡献。受NLP中偏移不对齐研究的启发，作为第一个贡献，我们进行了一项实证研究，分析了CLIP嵌入空间中文本偏移与图像偏移的不对齐现象，发现偏移不对齐与概念距离相关，即相近概念的不对齐程度较低。作为第二个贡献，我们提出了迭代优化适应（AIR），这是首个基于偏移不对齐新见解的ZSGM方法，专注于提高目标域图像质量。在26个实验设置中，定性、定量和用户研究一致表明，AIR方法达到了最先进的性能。补充实验见附录。

</details>


### [260] [M4V: Multi-Modal Mamba for Text-to-Video Generation](https://arxiv.org/abs/2506.10915)
**中文标题：M4V：用于文本到视频生成的多模态Mamba框架**

*Jiancheng Huang,Gengwei Zhang,Zequn Jie,Siyu Jiao,Yinlong Qian,Ling Chen,Yunchao Wei,Lin Ma*

Main category: cs.CV

TL;DR: M4V introduces a Multi-Modal Mamba framework for efficient text-to-video generation, reducing computational costs by 45% compared to Transformer-based methods while maintaining high-quality output.


<details>
  <summary>Details</summary>
Motivation: Text-to-video generation is computationally demanding with Transformers due to quadratic complexity. Mamba offers linear-time efficiency but lacks multi-modal and spatiotemporal modeling capabilities, which M4V aims to address.

Method: M4V uses a multi-modal diffusion Mamba (MM-DiM) block for integrating multi-modal information and spatiotemporal modeling, along with a reward learning strategy to enhance visual realism.

Result: M4V reduces FLOPs by 45% at 768×1280 resolution and produces high-quality videos, outperforming attention-based methods in efficiency and quality.

Conclusion: M4V provides an efficient and high-quality solution for text-to-video generation, balancing computational cost and performance.

摘要: 文本到视频生成极大地丰富了内容创作，并有望发展为强大的世界模拟器。然而，建模广阔的时空空间在计算上仍然非常昂贵，尤其是使用Transformer时，其序列处理的二次复杂度限制了实际应用。近年来，线性时间序列建模的进展，特别是Mamba架构，提供了更高效的替代方案。然而，其简单设计限制了其在多模态和时空视频生成任务中的直接适用性。为解决这些问题，我们提出了M4V，一种用于文本到视频生成的多模态Mamba框架。具体而言，我们提出了一种多模态扩散Mamba（MM-DiM）块，通过多模态令牌重组设计实现多模态信息和时空建模的无缝集成。因此，在生成768×1280分辨率的视频时，M4V中的Mamba块比基于注意力的替代方案减少了45%的FLOPs。此外，为缓解长上下文自回归生成过程中的视觉质量下降，我们引入了一种奖励学习策略，进一步提升了每帧的视觉真实感。在文本到视频基准测试中的广泛实验表明，M4V能够在显著降低计算成本的同时生成高质量视频。代码和模型将在https://huangjch526.github.io/M4V_project公开提供。

</details>


### [261] [VINCIE: Unlocking In-context Image Editing from Video](https://arxiv.org/abs/2506.10941)
**中文标题：VINCIE：从视频中解锁上下文图像编辑**

*Leigang Qu,Feng Cheng,Ziyan Yang,Qi Zhao,Shanchuan Lin,Yichun Shi,Yicong Li,Wenjie Wang,Tat-Seng Chua,Lu Jiang*

Main category: cs.CV

TL;DR: The paper introduces VINCIE, a method for in-context image editing trained directly from videos using a block-causal diffusion transformer, achieving state-of-the-art results on multi-turn editing benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing in-context image editing methods rely on task-specific pipelines and expert models, limiting scalability. The paper explores whether such models can be learned directly from videos, leveraging their inherent sequential and multimodal nature.

Method: The authors propose a scalable approach to annotate videos as interleaved multimodal sequences and train a block-causal diffusion transformer on three proxy tasks: next-image prediction, current segmentation prediction, and next-segmentation prediction.

Result: The model demonstrates strong in-context image editing capabilities, achieving state-of-the-art results on multi-turn editing benchmarks and showing promise in multi-concept composition, story generation, and chain-of-editing applications.

Conclusion: VINCIE successfully learns in-context image editing directly from videos, offering a scalable and versatile approach that outperforms existing methods.

摘要: 上下文图像编辑旨在基于包含文本和先前生成图像的上下文序列修改图像。现有方法通常依赖于任务特定的流程和专家模型（例如分割和修复）来整理训练数据。在这项工作中，我们探讨了是否可以直接从视频中学习上下文图像编辑模型。我们引入了一种可扩展的方法，将视频注释为交错的多模态序列。为了有效地从这些数据中学习，我们设计了一个基于三个代理任务训练的块因果扩散变换器：下一图像预测、当前分割预测和下一分割预测。此外，我们提出了一个新的多轮图像编辑基准，以推动该领域的研究。大量实验表明，我们的模型表现出强大的上下文图像编辑能力，并在两个多轮图像编辑基准上取得了最先进的结果。尽管仅在视频上训练，我们的模型在多概念组合、故事生成和编辑链应用中显示出有前景的能力。

</details>


### [262] [SpectralAR: Spectral Autoregressive Visual Generation](https://arxiv.org/abs/2506.10962)
**中文标题：SpectralAR：基于频谱自回归的视觉生成**

*Yuanhui Huang,Weiliang Chen,Wenzhao Zheng,Yueqi Duan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: SpectralAR introduces a spectral autoregressive framework for visual generation, using ordered spectral tokens to achieve causality and efficiency, outperforming existing methods with fewer tokens and parameters.


<details>
  <summary>Details</summary>
Motivation: Existing autoregressive visual generation methods use spatial patches, which are inherently parallel and contradict causality. SpectralAR addresses this by leveraging spectral sequences for causality and efficiency.

Method: SpectralAR transforms images into ordered spectral tokens via Nested Spectral Tokenization, representing low to high frequencies, and performs autoregressive generation in a coarse-to-fine manner.

Result: SpectralAR achieves a gFID score of 3.02 on ImageNet-1K with only 64 tokens and 310M parameters, demonstrating superior performance in image reconstruction and generation.

Conclusion: SpectralAR successfully integrates causality and efficiency in autoregressive visual generation by utilizing spectral sequences, offering a scalable and effective alternative to spatial patch-based methods.

摘要: 由于自回归视觉生成在可扩展性和与其他模态的兼容性方面优于扩散模型，其受到越来越多的关注。现有方法大多将视觉序列构建为空间块进行自回归生成。然而，图像块本质上是并行的，与自回归建模的因果性相矛盾。为解决这一问题，我们提出了一种基于频谱的自回归（SpectralAR）视觉生成框架，从频谱角度实现视觉序列的因果性。具体而言，我们首先通过嵌套频谱标记化将图像转换为有序的频谱标记，代表从低频到高频的组件。随后，我们以从粗到细的方式对频谱标记序列进行自回归生成。通过考虑图像的不同细节层次，SpectralAR在不增加额外复杂度的情况下实现了序列因果性和标记效率。我们在ImageNet-1K上进行了大量实验，用于图像重建和自回归生成，SpectralAR仅用64个标记和310M参数就达到了3.02的gFID分数。项目页面：https://huang-yh.github.io/spectralar/。

</details>


### [263] [MMMG: A Massive, Multidisciplinary, Multi-Tier Generation Benchmark for Text-to-Image Reasoning](https://arxiv.org/abs/2506.10963)
**中文标题：MMMG：一个用于文本到图像推理的大规模、多学科、多层次生成基准**

*Yuxuan Luo,Yuhui Yuan,Junwen Chen,Haonan Cai,Ziyi Yue,Yuwei Yang,Fatima Zohra Daha,Ji Li,Zhouhui Lian*

Main category: cs.CV

TL;DR: The paper introduces MMMG, a benchmark for evaluating text-to-image models' reasoning capabilities in generating knowledge-rich images, revealing significant deficits in current models.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of generating knowledge-rich images that require multimodal reasoning, the authors propose MMMG as a benchmark to evaluate and improve text-to-image models.

Method: MMMG includes 4,456 expert-validated image-prompt pairs across 10 disciplines and 6 educational levels, using a unified Knowledge Graph (KG) representation for evaluation. MMMG-Score combines factual fidelity (graph-edit distance) and visual clarity to assess models.

Result: Evaluations of 16 state-of-the-art models show low reasoning capabilities, with GPT-4o scoring only 50.20. The baseline model FLUX-Reason achieves a score of 34.45.

Conclusion: MMMG highlights the limitations of current models in generating knowledge images and provides a benchmark and baseline to drive future research.

摘要: 本文提出知识图像生成作为一项新任务，并介绍了大规模多学科多层次知识图像生成基准（MMMG），以探究图像生成模型的推理能力。知识图像在人类文明和学习机制中占据核心地位，这一点由双重编码理论和图片优势效应所强调。生成此类图像具有挑战性，需要将世界知识与像素级基础融合为清晰的解释性视觉内容。为进行全面评估，MMMG提供了4,456个经过专家验证的知识图像-提示对，涵盖10个学科、6个教育层次以及多种知识格式（如图表、思维导图等）。为消除评估中的混杂复杂性，我们采用统一的知识图谱（KG）表示。每个KG明确描述了目标图像的核心实体及其依赖关系。我们还引入了MMMG-Score来评估生成的知识图像，该指标结合了事实保真度（通过KG间的图编辑距离衡量）和视觉清晰度评估。对16种最先进的文本到图像生成模型的全面评估揭示了严重的推理缺陷——实体保真度低、关系弱且杂乱，其中GPT-4o的MMMG-Score仅为50.20，凸显了该基准的难度。为促进进一步研究，我们发布了FLUX-Reason（MMMG-Score为34.45），这是一个结合推理大语言模型和扩散模型的有效开源基线，训练于16,000个精选知识图像-提示对。

</details>


### [264] [Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs](https://arxiv.org/abs/2506.10967)
**中文标题：超越注意力或相似性：最大化MLLM中令牌剪枝的条件多样性**

*Qizhe Zhang,Mengzhen Liu,Lichen Li,Ming Lu,Yuan Zhang,Junwen Pan,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: The paper introduces CDPruner, a novel visual token pruning method for MLLMs that maximizes conditional diversity using DPP, achieving high efficiency while maintaining performance.


<details>
  <summary>Details</summary>
Motivation: Current token pruning methods in MLLMs either retain redundant tokens (attention-based) or ignore instruction relevance (similarity-based), leading to suboptimal performance.

Method: CDPruner defines conditional similarity between visual tokens and reformulates pruning using DPP to maximize conditional diversity, ensuring the selected subset is both representative and instruction-aligned.

Result: CDPruner reduces FLOPs by 95% and CUDA latency by 78% in LLaVA while maintaining 94% accuracy, outperforming other methods on vision-language benchmarks.

Conclusion: CDPruner is a training-free, model-agnostic solution that effectively balances efficiency and performance in MLLMs by focusing on conditional diversity.

摘要: 在多模态大语言模型（MLLM）中，输入视觉令牌的长度通常远大于文本令牌，导致高推理成本。许多工作试图通过去除冗余视觉令牌来解决这一问题。然而，当前方法要么依赖基于注意力的剪枝（保留大量重复令牌），要么使用基于相似性的剪枝（忽略指令相关性），从而导致性能不佳。本文提出了一种名为CDPruner的新型视觉令牌剪枝方法，通过最大化保留令牌的条件多样性来超越注意力或相似性。我们首先定义了基于指令的视觉令牌之间的条件相似性，然后使用行列式点过程（DPP）重新表述令牌剪枝问题，以最大化所选子集的条件多样性。所提出的CDPruner无需训练且与模型无关，可轻松应用于各种MLLM。在多种MLLM上的广泛实验表明，CDPruner在各种视觉语言基准测试中达到了新的最优水平。通过DPP最大化条件多样性，所选子集更好地代表了输入图像，同时严格遵循用户指令，从而在高剪枝比例下仍保持强大性能。应用于LLaVA时，CDPruner将FLOPs减少了95%，CUDA延迟降低了78%，同时保持了94%的原始准确率。代码可在https://github.com/Theia-4869/CDPruner获取。

</details>


### [265] [GenWorld: Towards Detecting AI-generated Real-world Simulation Videos](https://arxiv.org/abs/2506.10975)
**中文标题：GenWorld：面向检测AI生成的现实世界模拟视频**

*Weiliang Chen,Wenzhao Zheng,Yu Zheng,Lei Chen,Jie Zhou,Jiwen Lu,Yueqi Duan*

Main category: cs.CV

TL;DR: The paper introduces GenWorld, a high-quality real-world simulation dataset for detecting AI-generated videos, and proposes SpannDetector, a model leveraging multi-view consistency for improved detection performance.


<details>
  <summary>Details</summary>
Motivation: The rise of AI-generated videos threatens information credibility, but existing detectors lack high-quality real-world datasets, hindering their development.

Method: GenWorld is created with real-world simulation videos from diverse generators and prompts. SpannDetector uses multi-view consistency to detect AI-generated videos.

Result: SpannDetector outperforms existing methods, especially in detecting high-quality videos, showcasing the importance of real-world clues.

Conclusion: GenWorld and SpannDetector advance AI-generated video detection, emphasizing physical plausibility for explainable results.

摘要: 视频生成技术的繁荣威胁了现实世界信息的可信度，并加剧了对AI生成视频检测器的需求。尽管取得了一些进展，但高质量现实世界数据集的缺乏阻碍了可信检测器的发展。本文提出了GenWorld，一个大规模、高质量、现实世界模拟的数据集，用于AI生成视频检测。GenWorld具有以下特点：（1）现实世界模拟：GenWorld专注于复制现实场景的视频，这些视频因其真实性和潜在影响而具有重要意义；（2）高质量：GenWorld采用多种最先进的视频生成模型，提供逼真且高质量的伪造视频；（3）跨提示多样性：GenWorld包含来自不同生成器和多种提示模态（如文本、图像、视频）生成的视频，为学习更具泛化性的取证特征提供了潜力。我们分析了现有方法，发现它们无法检测世界模型（如Cosmos）生成的高质量视频，揭示了忽略现实世界线索的潜在缺陷。为此，我们提出了一个简单而有效的模型SpannDetector，利用多视角一致性作为现实世界AI生成视频检测的强大标准。实验表明，我们的方法取得了优异的结果，突出了基于物理合理性的可解释AI生成视频检测的有前景方向。我们相信GenWorld将推动AI生成视频检测领域的发展。项目页面：https://chen-wl20.github.io/GenWorld

</details>


### [266] [QuadricFormer: Scene as Superquadrics for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2506.10977)
**中文标题：QuadricFormer：将场景视为超二次曲面以实现3D语义占用预测**

*Sicheng Zuo,Wenzhao Zheng,Xiaoyong Han,Longchao Yang,Yong Pan,Jiwen Lu*

Main category: cs.CV

TL;DR: The paper proposes QuadricFormer, a method using superquadrics for efficient 3D semantic occupancy prediction, outperforming existing voxel-based and Gaussian-based approaches in both accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing methods for 3D occupancy prediction either use inefficient dense voxel representations or limited ellipsoidal Gaussians, failing to capture diverse object geometries in driving scenes. Superquadrics offer a more expressive and efficient alternative.

Method: The paper introduces a probabilistic superquadric mixture model for occupancy prediction, where each superquadric represents a probability distribution with geometric priors. QuadricFormer, the proposed model, includes a pruning-and-splitting module to optimize superquadric placement in occupied regions.

Result: QuadricFormer achieves state-of-the-art performance on the nuScenes dataset, demonstrating superior efficiency and accuracy in modeling complex driving scenes.

Conclusion: Superquadrics provide an effective and efficient representation for 3D semantic occupancy prediction, addressing the limitations of voxel-based and Gaussian-based methods.

摘要: 3D占用预测对于稳健的自动驾驶系统至关重要，因为它能够全面感知环境结构和语义。现有方法大多采用密集体素表示，忽略了驾驶场景的稀疏性，导致效率低下。近期研究探索了基于稀疏高斯分布的物体中心表示，但其椭球形先验限制了多样化结构的建模。在真实驾驶场景中，物体呈现丰富的几何形状（如长方体、圆柱体和不规则形状），需要密集排列的椭球形高斯分布以实现精确建模，导致表示效率低下。为解决这一问题，我们提出使用几何表达能力强的超二次曲面作为场景基元，通过其固有的形状多样性，用更少的基元高效表示复杂结构。我们开发了一种概率超二次曲面混合模型，将每个超二次曲面解释为具有几何先验的占用概率分布，并通过概率混合计算语义。在此基础上，我们提出了QuadricFormer，一种基于超二次曲面的高效3D占用预测模型，并引入剪枝与分割模块，通过将超二次曲面集中在占用区域进一步提升建模效率。在nuScenes数据集上的大量实验表明，QuadricFormer在保持高效的同时实现了最先进的性能。

</details>


### [267] [Fine-Grained Perturbation Guidance via Attention Head Selection](https://arxiv.org/abs/2506.10978)
**中文标题：通过注意力头选择的细粒度扰动引导**

*Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim*

Main category: cs.CV

TL;DR: The paper introduces 'HeadHunter', a framework for fine-grained attention head selection in Diffusion Transformers (DiTs), enabling targeted control over generation quality and visual attributes. It also proposes 'SoftPAG' for tunable perturbation strength, outperforming layer-level methods.


<details>
  <summary>Details</summary>
Motivation: Existing attention perturbation methods lack principled approaches for determining where to apply perturbations in DiTs, especially as quality-relevant computations are distributed across layers. The paper aims to address this by analyzing granularity and enabling targeted control.

Method: Investigates attention perturbation granularity (layer to head level), identifies heads governing specific visual concepts, and proposes 'HeadHunter' for iterative head selection aligned with user objectives. Introduces 'SoftPAG' for continuous perturbation strength tuning.

Result: Demonstrates superior performance in general quality enhancement and style-specific guidance on DiT-based models (Stable Diffusion 3, FLUX.1), mitigating oversmoothing and enabling targeted visual style manipulation.

Conclusion: The work provides the first head-level analysis of attention perturbation in diffusion models, revealing interpretable specialization and practical strategies for effective perturbation design.

摘要: 近年来，扩散模型中的引导方法通过扰动模型构建隐式弱模型，并引导生成远离该模型。在这些方法中，注意力扰动在无条件场景（如无分类器引导不适用时）表现出强大的实证性能。然而，现有的注意力扰动方法缺乏确定扰动应施加位置的原则性方法，尤其是在扩散变换器（DiT）架构中，质量相关计算分布在多个层中。本文研究了注意力扰动的粒度（从层级别到单个注意力头），发现特定头控制不同的视觉概念（如结构、风格和纹理质量）。基于这一发现，我们提出了“HeadHunter”，一个系统性框架，用于迭代选择与用户目标一致的注意力头，从而实现对生成质量和视觉属性的细粒度控制。此外，我们引入了“SoftPAG”，通过将每个选定头的注意力图线性插值到单位矩阵，提供连续调节扰动强度的功能，并抑制伪影。我们的方法不仅缓解了现有层级别扰动的过度平滑问题，还通过组合头选择实现了对特定视觉风格的有针对性操控。我们在现代大规模基于DiT的文本到图像模型（包括Stable Diffusion 3和FLUX.1）上验证了方法的有效性，展示了在通用质量提升和风格特定引导方面的卓越性能。我们的工作首次对扩散模型中的注意力扰动进行了头级别分析，揭示了注意力层内的可解释专业化，并为设计有效的扰动策略提供了实用方法。

</details>


### [268] [InstaInpaint: Instant 3D-Scene Inpainting with Masked Large Reconstruction Model](https://arxiv.org/abs/2506.10980)
**中文标题：InstaInpaint：基于掩码大重建模型的即时3D场景修复**

*Junqi You,Chieh Hubert Lin,Weijie Lyu,Zhengbo Zhang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: InstaInpaint is a fast 3D-scene inpainting method that achieves real-time performance (0.4 seconds) using a feed-forward framework and a custom large reconstruction model, outperforming prior methods by 1000x in speed while maintaining high quality.


<details>
  <summary>Details</summary>
Motivation: Current 3D scene inpainting methods are slow and computationally intensive, making them impractical for real-time or interactive applications. The paper aims to address this gap by proposing a faster, efficient solution.

Method: The paper introduces InstaInpaint, a feed-forward framework that generates 3D inpainting from 2D proposals. It uses a self-supervised masked-finetuning strategy to train a custom large reconstruction model (LRM) on large-scale data.

Result: InstaInpaint achieves a 1000x speed-up over prior methods while maintaining state-of-the-art performance on benchmarks. It also generalizes well to applications like object insertion and multi-region inpainting.

Conclusion: InstaInpaint provides a practical, high-speed solution for 3D scene inpainting, enabling real-time interactive operations with superior performance and flexibility.

摘要: 近年来，3D场景重建技术的进步使得虚拟和增强现实中的实时观看成为可能。为了支持交互式操作（如移动或编辑物体）以提升沉浸感，3D场景修复方法被提出用于修复或补全改变的几何结构。然而，现有方法依赖于耗时且计算密集的优化过程，使其难以应用于实时或在线场景。我们提出了InstaInpaint，一种基于参考的前馈框架，可在0.4秒内从2D修复提案生成3D场景修复结果。我们开发了一种自监督的掩码微调策略，用于在大规模数据集上训练定制的大重建模型（LRM）。通过大量实验，我们分析并确定了多个关键设计，以提高泛化能力、纹理一致性和几何正确性。InstaInpaint在保持两个标准基准测试中领先性能的同时，实现了比现有方法快1000倍的速度。此外，我们还展示了InstaInpaint在灵活的下游应用（如物体插入和多区域修复）中的良好泛化能力。更多视频结果请访问我们的项目页面：https://dhmbb2.github.io/InstaInpaint_page/。

</details>


### [269] [SceneCompleter: Dense 3D Scene Completion for Generative Novel View Synthesis](https://arxiv.org/abs/2506.10981)
**中文标题：SceneCompleter：用于生成式新视角合成的密集3D场景补全**

*Weiliang Chen,Jiayi Bi,Yuanhui Huang,Wenzhao Zheng,Yueqi Duan*

Main category: cs.CV

TL;DR: SceneCompleter introduces a novel framework for 3D-consistent generative novel view synthesis by completing dense 3D scenes, combining geometry and appearance through a dual-stream diffusion model and a scene embedder.


<details>
  <summary>Details</summary>
Motivation: Existing methods for novel view synthesis rely on 2D completion followed by 3D recovery, leading to smooth surfaces and distorted geometry due to the difficulty of inferring 3D structure from RGB data alone.

Method: SceneCompleter uses a geometry-appearance dual-stream diffusion model to synthesize novel views in RGBD space and a scene embedder for holistic scene understanding from reference images.

Result: The method achieves superior coherence and plausibility in generative novel view synthesis across diverse datasets by effectively fusing structural and textural information.

Conclusion: SceneCompleter demonstrates a significant improvement in 3D-consistent generative novel view synthesis by addressing the limitations of existing approaches.

摘要: 生成模型在新视角合成（NVS）中通过减少对密集多视角捕获的依赖而受到广泛关注。然而，现有方法通常遵循传统范式，即生成模型先在2D中补全缺失区域，随后通过3D恢复技术重建场景，这往往导致过度平滑的表面和扭曲的几何形状，因为生成模型难以仅从RGB数据推断3D结构。本文提出SceneCompleter，一种通过密集3D场景补全实现3D一致性生成新视角合成的新框架。SceneCompleter通过两个关键组件实现视觉一致性和3D一致的生成场景补全：（1）一种几何-外观双流扩散模型，联合在RGBD空间中合成新视角；（2）一种场景编码器，从参考图像中编码更全面的场景理解。通过有效融合结构和纹理信息，我们的方法在多样数据集上展示了生成新视角合成的优越一致性和合理性。项目页面：https://chen-wl20.github.io/SceneCompleter

</details>


### [270] [Multimodal Cinematic Video Synthesis Using Text-to-Image and Audio Generation Models](https://arxiv.org/abs/2506.10005)
**中文标题：基于文本到图像和音频生成模型的多模态电影视频合成**

*Sridhar S,Nithin A,Shakeel Rifath,Vasantha Raj*

Main category: cs.CV

TL;DR: 本文提出了一种结合文本到图像和音频生成模型的多模态电影视频合成方法，利用Stable Diffusion、GPT-2和混合音频管道生成60秒的电影级视频，并通过优化技术提升质量和效率。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的进步为多媒体创作带来了新的可能性，本文旨在通过结合文本到图像和音频生成模型，实现高质量的电影视频自动合成，满足创意、教育和工业应用的需求。

Method: 采用Stable Diffusion进行高保真图像合成，GPT-2用于叙事结构设计，结合gTTS和YouTube音乐构建混合音频管道。通过五场景框架、线性帧插值、电影级后处理（如锐化）和音视频同步技术，生成专业级视频。在GPU加速的Google Colab环境中使用Python 3.11实现，并提供了双模式Gradio界面（简单和高级）。

Result: 实验结果表明，该方法在视觉质量、叙事连贯性和效率方面表现优异，进一步推动了文本到视频合成技术在创意、教育和工业领域的应用。

Conclusion: 本文提出的多模态电影视频合成方法通过结合文本到图像和音频生成模型，实现了高质量的视频生成，为多媒体创作提供了新的工具和可能性。

摘要: 生成式人工智能的进步改变了多媒体创作方式，使得从文本输入自动合成电影视频成为可能。本文提出了一种生成60秒电影视频的方法，结合了Stable Diffusion的高保真图像合成、GPT-2的叙事结构设计，以及基于gTTS和YouTube音乐的混合音频管道。采用五场景框架，并通过线性帧插值、电影级后处理（如锐化）和音视频同步技术，实现了专业级质量的视频生成。该方法在GPU加速的Google Colab环境中使用Python 3.11实现，并提供了双模式Gradio界面（简单和高级），支持最高1024x768的分辨率和15-30 FPS的帧率。通过CUDA内存管理和错误处理等优化技术确保了可靠性。实验结果表明，该方法在视觉质量、叙事连贯性和效率方面表现优异，进一步推动了文本到视频合成在创意、教育和工业领域的应用。

</details>


### [271] [LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning](https://arxiv.org/abs/2506.10082)
**中文标题：LoRA-Edit：基于掩码感知LoRA微调的可控第一帧引导视频编辑**

*Chenjian Gao,Lihe Ding,Xin Cai,Zhanpeng Huang,Zibin Wang,Tianfan Xue*

Main category: cs.CV

TL;DR: 本文提出了一种基于掩码感知的LoRA微调方法（LoRA-Edit），用于可控的第一帧引导视频编辑，能够在保持背景区域的同时实现灵活的视频编辑，无需改变模型架构。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的视频编辑方法通常依赖大规模预训练，限制了特定编辑的灵活性。第一帧引导编辑虽然能控制第一帧，但对后续帧缺乏灵活性。因此，本文旨在提出一种更灵活且高效的方法。

Method: 提出了一种基于掩码的LoRA微调方法，通过动态调制模型注意力区域，结合输入视频的空间结构和运动线索以及参考图像的外观指导，实现可控的视频编辑。

Result: 实验结果表明，该方法在视频编辑性能上优于现有最先进方法。

Conclusion: LoRA-Edit提供了一种高效且灵活的视频编辑解决方案，能够在保持背景的同时实现可控的编辑传播。

摘要: 基于扩散模型的视频编辑在生成高质量编辑视频方面取得了显著成果。然而，当前方法通常依赖大规模预训练，限制了特定编辑的灵活性。第一帧引导编辑虽然能控制第一帧，但对后续帧缺乏灵活性。为解决这一问题，我们提出了一种基于掩码的LoRA（低秩适应）微调方法，用于适配预训练的图像到视频（I2V）模型以实现灵活的视频编辑。我们的方法在保持背景区域的同时，实现了可控的编辑传播。这一解决方案无需改变模型架构，即可提供高效且适应性强的视频编辑。为了更好地引导这一过程，我们引入了额外的参考（如替代视角或代表性场景状态），作为内容展开的视觉锚点。我们通过掩码驱动的LoRA微调策略解决了控制挑战，该策略将预训练的图像到视频模型适配到编辑上下文中。模型需要从两个不同的来源学习：输入视频提供空间结构和运动线索，而参考图像提供外观指导。空间掩码通过动态调制模型的注意力区域，确保每个区域从适当的来源中提取信息。实验结果表明，我们的方法在视频编辑性能上优于现有最先进方法。

</details>


### [272] [DeepTraverse: A Depth-First Search Inspired Network for Algorithmic Visual Understanding](https://arxiv.org/abs/2506.10084)
**中文标题：DeepTraverse：一种受深度优先搜索启发的算法化视觉理解网络**

*Bin Guo,John H. L. Hansen*

Main category: cs.CV

TL;DR: DeepTraverse是一种受深度优先搜索算法启发的视觉架构，通过递归探索和自适应校准模块，实现高效且结构化的特征学习，在图像分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统视觉主干网络的特征提取过程缺乏自适应迭代和逻辑性，作者提出是否可以通过经典搜索算法的原则，构建更结构化、可解释的特征学习流程。

Method: DeepTraverse包含两个关键组件：递归探索模块（通过参数共享深化特征分析）和自适应校准模块（动态调整特征显著性）。

Result: 在多个图像分类基准测试中，DeepTraverse表现出色，分类精度和特征区分能力优于传统模型，且参数效率更高。

Conclusion: 研究表明，将算法先验整合到视觉主干网络中，可以构建更高效、性能更强且结构化的模型。

摘要: 尽管传统的视觉主干网络取得了成功，但其特征构建通常通过一系列统一的操作完成，缺乏自适应迭代的显式路径。这引发了一个引人注目的问题：经典搜索算法的原则能否为这些网络注入更具算法性、结构化和逻辑性的处理流程，从而生成更可解释、类似推理的特征表示？我们提出了DeepTraverse，这是一种直接受算法搜索策略启发的新型视觉架构，使其能够通过与传统方法不同的系统性阐明和自适应细化过程学习特征。DeepTraverse通过两个关键协同组件实现这一目标：递归探索模块（通过参数共享深化特征分析）和自适应校准模块（根据全局上下文动态调整特征显著性）。这种算法性交互使DeepTraverse能够智能地构建和细化特征模式。在多样化的图像分类基准测试中，DeepTraverse表现出色，分类精度和特征区分能力优于传统模型，且参数效率更高。我们的研究表明，整合此类算法先验为构建更高效、性能更强且结构化的视觉主干网络提供了一种原则性且有效的策略。

</details>


### [273] [Test-Time Adaptation for Generalizable Task Progress Estimation](https://arxiv.org/abs/2506.10085)
**中文标题：可泛化任务进度估计的测试时自适应方法**

*Christos Ziakas,Alessandra Russo*

Main category: cs.CV

TL;DR: 本文提出了一种测试时自适应方法，通过优化自监督目标，使进度估计模型能够在线适应测试轨迹的视觉和时间上下文。该方法基于梯度元学习策略，利用专家视觉轨迹和自然语言任务描述进行训练，从而在测试时通过语义内容而非时间顺序改进进度估计。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分布外任务、环境和体现上的泛化能力有限，本文旨在通过测试时自适应方法提升进度估计模型的泛化性能。

Method: 采用梯度元学习策略，训练模型利用专家视觉轨迹和自然语言任务描述，优化自监督目标，实现测试时自适应。

Result: 该方法在多样化的分布外任务、环境和体现上表现优于当前最先进的基于自回归视觉语言模型的上下文学习方法。

Conclusion: 测试时自适应方法显著提升了进度估计模型的泛化能力，适用于多种分布外场景。

摘要: 我们提出了一种测试时自适应方法，使进度估计模型能够通过优化学习的自监督目标在线适应测试轨迹的视觉和时间上下文。为此，我们引入了一种基于梯度的元学习策略，利用专家视觉轨迹及其自然语言任务描述训练模型，使得测试时自适应能够依赖语义内容而非时间顺序改进进度估计。我们的测试时自适应方法从单一训练环境泛化到多样化的分布外任务、环境和体现，表现优于当前最先进的基于自回归视觉语言模型的上下文学习方法。

</details>


### [274] [EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models](https://arxiv.org/abs/2506.10100)
**中文标题：EfficientVLA：视觉-语言-动作模型的无需训练加速与压缩**

*Yantai Yang,Yuhao Wang,Zichen Wen,Luo Zhongwei,Chang Zou,Zhipeng Zhang,Chuan Wen,Linfeng Zhang*

Main category: cs.CV

TL;DR: EfficientVLA是一种无需训练的推理加速框架，通过系统性地消除视觉-语言-动作模型中的冗余，实现了1.93倍的推理加速和28.9%的计算量减少，同时仅导致0.6%的成功率下降。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作（VLA）模型在嵌入式智能中具有巨大潜力，但由于计算和内存需求高，实际部署受限。现有加速方法通常仅针对局部低效问题，未能全面解决整个VLA流程中的瓶颈。

Method: EfficientVLA通过三种策略系统性消除冗余：(1) 基于层间冗余分析修剪语言模块中功能无关的层；(2) 通过任务感知策略优化视觉处理路径，选择紧凑且多样化的视觉标记；(3) 在基于扩散的动作头中缓存和重用关键中间特征，减少时间计算冗余。

Result: 在标准VLA模型CogACT上应用EfficientVLA，实现了1.93倍的推理加速，计算量减少至28.9%，在SIMPLER基准测试中仅导致0.6%的成功率下降。

Conclusion: EfficientVLA通过系统性消除冗余，显著提升了VLA模型的推理效率，同时保持了性能，为实际部署提供了可行方案。

摘要: 视觉-语言-动作（VLA）模型，尤其是基于扩散的架构，在嵌入式智能中展现出变革性潜力，但由于其固有的计算和内存需求高，且存在大量冗余，实际应用受到严重限制。现有的加速方法通常仅针对局部低效问题，未能全面解决整个VLA流程中的计算和内存瓶颈。为此，我们提出了EfficientVLA，一种结构化且无需训练的推理加速框架，通过系统性消除多方面的冗余，全面解决这些瓶颈。EfficientVLA协同整合了三种针对性策略：(1) 基于层间冗余分析，修剪语言模块中功能无关的层；(2) 通过任务感知策略优化视觉处理路径，选择紧凑且多样化的视觉标记，平衡任务关键性与信息覆盖；(3) 在基于扩散的动作头中，通过缓存和重用关键中间特征，减少时间计算冗余。我们将该方法应用于标准VLA模型CogACT，实现了1.93倍的推理加速，计算量减少至28.9%，在SIMPLER基准测试中仅导致0.6%的成功率下降。

</details>


### [275] [A Manually Annotated Image-Caption Dataset for Detecting Children in the Wild](https://arxiv.org/abs/2506.10117)
**中文标题：用于检测野外儿童的手动标注图像-标题数据集**

*Klim Kireev,Ana-Maria Creţu,Raphael Meier,Sarah Adel Bargal,Elissa Redmiles,Carmela Troncoso*

Main category: cs.CV

TL;DR: 本文发布了一个名为ICCWD的多模态图像-标题数据集，用于检测未成年人，填补了现有数据集的空白。数据集包含1万对标注图像-标题，并测试了三种检测器，最佳检测器的真阳性率为75.3%。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏用于多模态环境中检测未成年人的数据集或基准，而数字平台和法律对涉及未成年人的内容有特殊规定。因此，需要开发自动化工具来检测此类内容。

Method: 作者发布了Image-Caption Children in the Wild Dataset (ICCWD)，包含1万对手动标注的图像-标题，标注了图像中是否包含未成年人。数据集涵盖了多种场景，包括虚构描绘和部分可见的身体。此外，作者还使用该数据集测试了三种检测器，包括一个商业年龄估计系统。

Result: 测试结果表明，未成年人检测是一项具有挑战性的任务，最佳检测器的真阳性率为75.3%。

Conclusion: ICCWD数据集的发布有望帮助设计更优的未成年人检测方法，适用于多种场景。

摘要: 平台和法律对涉及未成年人（定义为18岁以下个体）的数字内容有不同于其他内容的规定。由于需要评估的内容量巨大，通常使用基于机器学习的自动化工具来检测涉及未成年人的内容。目前尚无用于多模态环境中检测这些识别方法的数据集或基准。为填补这一空白，我们发布了Image-Caption Children in the Wild Dataset (ICCWD)，这是一个旨在评估未成年人检测工具性能的图像-标题数据集。我们的数据集比以往的儿童图像数据集更丰富，包含了多种场景下的儿童图像，包括虚构描绘和部分可见的身体。ICCWD包含1万对手动标注的图像-标题，标注了图像中是否存在儿童。为展示数据集的潜在用途，我们用它测试了三种不同的检测器，包括一个应用于图像的商业年龄估计系统。结果表明，未成年人检测是一项具有挑战性的任务，最佳方法的真阳性率为75.3%。我们希望数据集的发布能帮助设计更优的未成年人检测方法，适用于多种场景。

</details>


### [276] [Detecção da Psoríase Utilizando Visão Computacional: Uma Abordagem Comparativa Entre CNNs e Vision Transformers](https://arxiv.org/abs/2506.10119)
**中文标题：使用计算机视觉检测银屑病：CNN与视觉变换器的对比研究**

*Natanael Lucena,Fábio S. da Silva,Ricardo Rios*

Main category: cs.CV

TL;DR: 本文比较了卷积神经网络（CNN）和视觉变换器（ViT）在银屑病及其类似疾病图像多分类任务中的表现，发现ViT在模型较小的情况下表现更优，其中DaViT-B以96.4%的F1分数成为最佳推荐架构。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索CNN和ViT在医学图像分类任务中的性能差异，特别是针对银屑病及其类似疾病的自动检测。

Method: 方法包括使用在ImageNet上预训练的CNN和ViT模型，将其适配到特定数据集进行多分类任务，并比较其性能。

Result: 结果显示，ViT在模型较小的情况下表现优于CNN，其中DaViT-B以96.4%的F1分数取得最佳结果。

Conclusion: 结论认为ViT在医学图像分类任务中具有显著潜力，尤其是DaViT-B架构在银屑病检测中表现高效。

摘要: 本文比较了卷积神经网络（CNN）和视觉变换器（ViT）在银屑病及其类似疾病图像多分类任务中的性能。使用在ImageNet上预训练的模型适配特定数据集，两者均取得了较高的预测指标，但ViT在模型较小的情况下表现更优。其中，双注意力视觉变换器基础版（DaViT-B）以96.4%的F1分数获得最佳结果，被推荐为自动化银屑病检测的最高效架构。本文进一步验证了ViT在医学图像分类任务中的潜力。

</details>


### [277] [ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs](https://arxiv.org/abs/2506.10128)
**中文标题：ViCrit：一种用于视觉语言模型视觉感知的可验证强化学习代理任务**

*Xiyao Wang,Zhengyuan Yang,Chao Feng,Yongyuan Liang,Yuhang Zhou,Xiaoyu Liu,Ziyi Zang,Ming Li,Chung-Ching Lin,Kevin Lin,Linjie Li,Furong Huang,Lijuan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为ViCrit的强化学习代理任务，用于提升视觉语言模型（VLMs）的视觉感知能力。通过向人类撰写的图像描述中注入细微的视觉错误，并训练模型定位这些错误，ViCrit在保持感知难度的同时提供了明确的奖励信号。实验表明，ViCrit显著提升了模型在多种视觉语言任务中的表现，并展示了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在调整大型语言模型（LLMs）方面取得了成功，但在视觉语言模型（VLMs）中应用类似方法却因缺乏既具挑战性又可明确验证的视觉任务而受阻。本文旨在填补这一空白，提出一种能够有效提升VLMs视觉感知能力的任务。

Method: 本文提出ViCrit任务，通过向200字的人类撰写的图像描述中注入细微的视觉错误（如对象、属性、数量或空间关系的描述错误），并训练模型根据图像和修改后的描述定位错误。这种方法保留了感知的难度，同时提供了易于计算且明确的二元奖励信号。

Result: 实验结果表明，通过ViCrit任务训练的模型在多种视觉语言基准测试中表现显著提升。此外，模型的改进不仅限于自然图像数据，还能泛化到抽象图像推理和视觉数学任务，表明模型学会了感知而非仅记忆已见对象。

Conclusion: ViCrit任务是一种有效且可泛化的目标，能够显著提升视觉语言模型的视觉感知能力。本文还提出了ViCrit-Bench基准测试，用于系统评估模型在不同图像领域和错误类型中的表现。

摘要: 强化学习（RL）在通过数学推理或代码生成等具有挑战性且易于验证的任务微调大型语言模型（LLMs）方面表现出色。然而，将这一成功扩展到视觉语言模型（VLMs）的视觉感知中，却因缺乏既具挑战性又可明确验证的视觉任务而受阻。为此，我们提出了ViCrit（视觉描述幻觉批评），一种RL代理任务，用于训练VLMs定位注入人类撰写图像描述中的细微合成视觉幻觉。我们从200字的描述开始，注入单个细微的视觉描述错误（如对象、属性、数量或空间关系的描述错误），并要求模型根据图像和修改后的描述定位被破坏的部分。这一方法保留了完整的感知难度，同时提供了易于计算且明确的二元精确匹配奖励。通过ViCrit任务训练的模型在多种VL基准测试中表现出显著提升。重要的是，这种改进不仅限于自然图像训练数据，还能泛化到抽象图像推理和视觉数学任务，显示出模型学会了感知而非仅记忆已见对象。为便于评估，我们还提出了ViCrit-Bench，一种类别平衡的诊断基准测试，用于系统探究不同图像领域和错误类型的感知错误。总之，我们的结果表明，细粒度的幻觉批评是提升VLMs视觉感知的一种有效且可泛化的目标。

</details>


### [278] [RoCA: Robust Cross-Domain End-to-End Autonomous Driving](https://arxiv.org/abs/2506.10145)
**中文标题：RoCA：鲁棒的跨域端到端自动驾驶框架**

*Rajeev Yasarla,Shizhong Han,Hsin-Pai Cheng,Litian Liu,Shweta Mahajan,Apratim Bhattacharyya,Yunxiao Shi,Risheek Garrepalli,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: RoCA是一种新型的跨域端到端自动驾驶框架，通过联合概率分布建模和基元学习，显著提升了模型的泛化能力和适应性，无需额外推理计算。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶在跨域部署时面临泛化能力不足和适应成本高的问题，现有方法（如大语言模型）无法保证性能且成本高昂。

Method: RoCA通过联合概率分布建模自车和周围车辆信息的编码令牌，利用高斯过程学习基元令牌及其轨迹，从而泛化多样驾驶场景并概率推断未来轨迹。

Result: RoCA在多种跨域场景中表现出色，显著优于直接微调，提升了模型的泛化能力和适应性。

Conclusion: RoCA为跨域端到端自动驾驶提供了高效且鲁棒的解决方案，无需额外推理成本即可实现强泛化和适应性。

摘要: 端到端（E2E）自动驾驶作为一种新兴范式，展现出巨大潜力。然而，跨域（如不同城市）部署的实际挑战尚未得到充分研究。尽管已有工作尝试利用大语言模型（LLMs）的开放世界知识，但LLMs无法保证跨域驾驶性能，且域适应时的重新训练成本过高。本文提出RoCA，一种鲁棒的跨域E2E自动驾驶框架。RoCA通过联合概率分布建模E2E流程中自车和周围车辆信息的编码令牌，并以高斯过程（GP）实例化，学习一组基元令牌及其对应轨迹，覆盖多样驾驶场景。给定任意驾驶场景，RoCA能够概率推断未来轨迹。通过在源域训练中结合RoCA与基础E2E模型，无需额外推理计算即可提升基础模型的泛化能力。此外，RoCA支持在目标域上的鲁棒适应，性能显著优于直接微调。我们在多种跨域场景中广泛评估RoCA，结果表明其具备强大的域泛化和适应能力。

</details>


### [279] [SPARKE: Scalable Prompt-Aware Diversity Guidance in Diffusion Models via RKE Score](https://arxiv.org/abs/2506.10173)
**中文标题：SPARKE：通过RKE分数在扩散模型中实现可扩展的提示感知多样性引导**

*Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia*

Main category: cs.CV

TL;DR: 本文提出了一种名为SPARKE的方法，用于在扩散模型中实现基于提示感知的多样性引导，通过RKE分数降低计算复杂度，从而在大规模生成任务中高效提升生成样本的多样性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像合成和提示引导生成方面表现出色，但如何在语义广泛的提示下确保生成样本的多样性仍是一个挑战。现有方法在计算多样性时面临高复杂度问题，限制了其在大规模生成任务中的应用。

Method: SPARKE方法利用条件熵进行多样性引导，动态地将多样性测量与相似提示关联，并通过RKE分数将计算复杂度从O(n^3)降低到O(n)，从而实现了高效的多样性控制。

Result: 实验表明，SPARKE方法在多个文本到图像扩散模型中显著提升了生成数据的提示感知多样性，同时未显著增加计算成本。

Conclusion: SPARKE方法通过降低计算复杂度，实现了高效的提示感知多样性引导，为大规模生成任务提供了可行的解决方案。

摘要: 扩散模型在高保真图像合成和提示引导生成建模方面取得了显著成功。然而，在提示语义广泛的情况下，如何确保生成样本的多样性仍然是一个挑战，尤其是在需要以提示感知的方式评估语义相似提示下生成数据的多样性时。近期方法通过多样性度量引入引导以鼓励更多样化的生成。本文扩展了基于多样性度量的方法，提出了可扩展的提示感知Rényi核熵多样性引导（SPARKE）方法。SPARKE利用条件熵进行多样性引导，动态地将多样性测量与相似提示关联，并实现提示感知的多样性控制。尽管基于熵的引导方法增强了提示感知多样性，但其对矩阵熵分数的依赖在大规模生成场景中带来了计算挑战。为解决这一问题，我们专注于条件潜在RKE分数引导的特殊情况，将熵计算和基于梯度的优化复杂度从一般熵度量的O(n^3)降低到O(n)。降低的计算复杂度使得可以在数千次不同提示的生成轮次中进行多样性引导采样。我们在多个文本到图像扩散模型上对SPARKE方法进行了数值测试，结果表明所提方法在不显著增加计算成本的情况下提升了生成数据的提示感知多样性。代码已在项目页面发布：https://mjalali.github.io/SPARKE

</details>


### [280] [Retrieval of Surface Solar Radiation through Implicit Albedo Recovery from Temporal Context](https://arxiv.org/abs/2506.10174)
**中文标题：通过时间上下文隐式反照率恢复反演地表太阳辐射**

*Yael Frischholz,Devis Tuia,Michael Lehning*

Main category: cs.CV

TL;DR: 本文提出了一种基于注意力机制的表面太阳辐射（SSR）反演方法，通过隐式学习卫星图像序列中的晴空地表反射率，避免了传统方法在复杂地形（如山区）中的局限性。该方法在瑞士地区的实验中表现优异，尤其在动态雪覆盖区域。


<details>
  <summary>Details</summary>
Motivation: 传统SSR反演算法依赖月统计量估算背景反射率，假设地表特性变化缓慢，但在山区等动态雪覆盖区域表现不佳。本文旨在解决这一问题，提出一种无需显式反照率图或云掩模的方法。

Method: 基于Temporo-Spatial Vision Transformer的注意力机制模型，通过多光谱SEVIRI卫星图像序列、静态地形特征和太阳几何数据，隐式学习晴空地表反射率。训练数据来自瑞士地区的HelioMont算法SSR估计。

Result: 实验表明，模型在提供足够长的时间上下文时，性能与依赖反照率信息的模型相当，尤其在山区表现突出，且在不同地形条件下均能提升泛化能力。

Conclusion: 该方法通过隐式学习地表反射率动态，显著提升了SSR反演在复杂地形中的准确性，为卫星遥感提供了新思路。代码和数据集已开源。

摘要: 从卫星图像中准确反演地表太阳辐射（SSR）的关键在于估算晴空条件下空间传感器观测到的背景反射率。偏离这一基线可用于检测云层存在并指导辐射传输模型推断大气衰减。传统反演算法通常使用月统计量近似背景反射率，假设地表特性变化缓慢。然而，这种方法在山区因间歇性雪覆盖和雪面变化频繁而失效。我们提出了一种基于注意力的SSR反演模拟器，通过卫星图像序列隐式学习晴空地表反射率。基于Temporo-Spatial Vision Transformer的方法无需手工特征（如显式反照率图或云掩模）。模拟器训练数据来自瑞士地区HelioMont算法的瞬时SSR估计，该地区地形复杂且雪覆盖动态变化。输入包括Meteosat第二代平台的多光谱SEVIRI图像，辅以静态地形特征和太阳几何数据。目标变量为HelioMont的SSR，空间分辨率为1.7公里。实验表明，在提供足够长的时间上下文时，模型性能与依赖反照率信息的模型相当，凸显了模型隐式学习地表反射率动态的能力。地理空间分析显示，该效果在山区尤为显著，且在简单和复杂地形条件下均能提升泛化能力。代码和数据集已公开：https://github.com/frischwood/HeMu-dev.git

</details>


### [281] [Attention, Please! Revisiting Attentive Probing for Masked Image Modeling](https://arxiv.org/abs/2506.10178)
**中文标题：注意了！重新审视掩码图像建模中的注意力探针方法**

*Bill Psomas,Dionysis Christopoulos,Eirini Baltzi,Ioannis Kakogeorgiou,Tilemachos Aravanis,Nikos Komodakis,Konstantinos Karantzalos,Yannis Avrithis,Giorgos Tolias*

Main category: cs.CV

TL;DR: 本文重新审视了注意力探针方法在掩码图像建模中的应用，提出了一种高效探针（EP）方法，通过多查询交叉注意力机制减少冗余参数和计算量，显著提升了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 由于微调（FT）在大规模应用中不切实际，探针方法成为自监督学习（SSL）的主要评估协议。然而，标准线性探针（LP）无法充分反映掩码图像建模（MIM）模型的潜力，因此需要更高效的注意力探针方法。

Method: 本文提出了高效探针（EP），一种多查询交叉注意力机制，通过消除冗余投影和减少可训练参数，显著提升了计算效率。

Result: EP在七个基准测试中优于LP和现有注意力探针方法，泛化能力强，生成可解释的注意力图，并在低样本和分层设置中表现优异。

Conclusion: 高效探针（EP）是一种简单但强大的方法，显著提升了注意力探针的性能和效率，适用于多种预训练范式。

摘要: 随着微调（FT）在大规模应用中变得不切实际，探针方法逐渐成为自监督学习（SSL）的首选评估协议。然而，标准线性探针（LP）由于补丁令牌的分布式特性，无法充分反映掩码图像建模（MIM）模型的潜力。这促使了注意力探针的需求，该方法通过注意力选择性聚合补丁级特征。尽管其应用日益广泛，注意力探针仍未被充分探索，现有方法存在参数过多和计算效率低的问题。
  本文从准确性与效率权衡的角度重新审视注意力探针。我们对现有方法进行了系统研究，分析其机制并对其性能进行基准测试。我们提出了高效探针（EP），一种多查询交叉注意力机制，消除了冗余投影，减少了可训练参数，并比传统的多头注意力实现了高达10倍的加速。尽管简单，EP在七个基准测试中优于LP和现有注意力探针方法，泛化能力强，生成可解释的注意力图，并在低样本和分层设置中表现出色。代码发布于https://github.com/billpsomas/efficient-probing。

</details>


### [282] [Improving Personalized Search with Regularized Low-Rank Parameter Updates](https://arxiv.org/abs/2506.10182)
**中文标题：通过正则化低秩参数更新改进个性化搜索**

*Fiona Ryan,Josef Sivic,Fabian Caba Heilbron,Judy Hoffman,James M. Rehg,Bryan Russell*

Main category: cs.CV

TL;DR: 本文提出了一种通过正则化低秩参数更新改进个性化搜索的方法，在保留通用知识的同时有效识别个性化概念，并在两个基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 个性化视觉语言检索需要从少量示例中学习新概念（如“我的狗Fido”），并整合个人与通用知识以在不同上下文中识别该概念。现有方法如文本反转效果有限，因此需要一种更有效的方法。

Method: 通过正则化低秩适应调整语言编码器最后一层的少量参数，作为文本反转的高效替代方案。同时探索了多个人概念参数组合的策略，发现参数相加效果最佳。还引入了一种基于视觉语言模型生成字幕的指标，以评估微调表示中通用知识的保留情况。

Result: 在DeepFashion2和ConCon-Chi两个个性化图像检索基准测试中，该方法在个性化检索任务上比现有技术提升了4%-22%的准确率，达到了最先进的性能。

Conclusion: 正则化低秩参数更新是一种高效的方法，能够在保留通用知识的同时实现个性化概念的识别，为个性化视觉语言检索提供了新的解决方案。

摘要: 个性化视觉语言检索旨在从少量示例中识别新概念（如“我的狗Fido”）。这一任务具有挑战性，因为它不仅需要从少量图像中学习新概念，还需要将个人知识与通用知识结合以在不同上下文中识别该概念。本文展示了如何有效调整视觉语言双编码器模型的内部表示以实现个性化视觉语言检索。我们发现，对语言编码器最后一层的少量参数进行正则化低秩适应，是识别个人概念并保留通用知识的高效替代方案。此外，我们探索了多个人概念参数组合的策略，发现参数相加效果显著。为了评估微调表示中通用知识的保留情况，我们引入了一种基于视觉语言模型（VLM）生成字幕的图像检索准确率指标。我们的方法在DeepFashion2和ConCon-Chi两个个性化图像检索基准测试中实现了最先进的性能，在个性化检索任务上比现有技术提升了4%-22%的准确率。

</details>


### [283] [ScoreMix: Improving Face Recognition via Score Composition in Diffusion Generators](https://arxiv.org/abs/2506.10226)
**中文标题：ScoreMix：通过扩散生成器中的分数组合改进人脸识别**

*Parsa Rahimi,Sebastien Marcel*

Main category: cs.CV

TL;DR: ScoreMix是一种利用扩散模型分数组合特性的数据增强策略，通过混合不同类别的分数生成具有挑战性的合成样本，显著提升判别器性能，尤其在标记数据有限的情况下表现突出。


<details>
  <summary>Details</summary>
Motivation: 在标记数据有限的情况下，如何提升判别器的性能是一个关键问题。本文提出ScoreMix，旨在通过扩散模型的分数组合特性生成更具挑战性的合成数据，从而增强判别器的判别能力。

Method: ScoreMix通过凸组合扩散采样过程中不同类别条件下的分数，生成合成样本。研究发现，选择判别器嵌入空间中距离较远的类别进行混合，比在生成器条件空间中相近的类别更能提升性能。

Result: ScoreMix在所有研究的基准测试中显著提升了判别器的性能，且无需进行大量参数搜索。实验还表明，生成器的条件空间与判别器的嵌入空间相关性较低。

Conclusion: ScoreMix是一种简单有效的数据增强方法，能够显著提升判别器的性能，同时减少对大规模数据集的依赖，具有实际应用价值。

摘要: 本文提出ScoreMix，这是一种新颖而简单的数据增强策略，利用扩散模型的分数组合特性来增强判别器的性能，尤其是在标记数据有限的情况下。通过在扩散采样过程中凸组合不同类别条件下的分数，我们生成了具有挑战性的合成样本，显著提升了所有研究基准中的判别能力。我们系统地研究了混合的类别选择策略，发现当组合判别器嵌入空间中距离较远的类别时，性能提升更为显著，而非生成器条件空间中相近的类别。此外，实验表明，在标准指标下，生成器的学习条件空间与判别器的嵌入空间之间的相关性较低。我们的方法无需进行大量参数搜索即可实现显著的性能提升，展示了在训练判别模型时的实际优势，同时有效缓解了大规模数据集收集的问题。论文网站：https://parsa-ra.github.io/scoremix

</details>


### [284] [California Crop Yield Benchmark: Combining Satellite Image, Climate, Evapotranspiration, and Soil Data Layers for County-Level Yield Forecasting of Over 70 Crops](https://arxiv.org/abs/2506.10228)
**中文标题：加州作物产量基准：结合卫星图像、气候、蒸散发和土壤数据层实现70多种作物的县级产量预测**

*Hamid Kamangir,Mona Hajiesmaeeli,Mason Earles*

Main category: cs.CV

TL;DR: 该研究开发了一个结合卫星图像、气候、蒸散发和土壤数据的多模态深度学习模型，用于预测加州70多种作物的县级产量，整体R2分数为0.76。


<details>
  <summary>Details</summary>
Motivation: 加州是全球农业生产的领导者，但复杂的环境和气候因素使得作物产量预测具有挑战性。研究旨在通过整合多源数据，提供更准确的产量预测。

Method: 研究整合了Landsat卫星图像、气候记录、蒸散发数据和土壤特性，开发了一个多模态深度学习模型，采用分层特征提取和时间序列编码器捕捉生长季的动态变化。

Result: 模型在未见测试数据上的整体R2分数为0.76，表明其在加州多样化农业区域中具有强预测性能。

Conclusion: 该基准数据集和建模框架为农业预测、气候适应和精准农业提供了重要基础，数据和代码已公开。

摘要: 加州是全球农业生产的领导者，占美国总产量的12.5%，并位列全球第五大食品和棉花供应地。尽管美国农业部国家农业统计局提供了丰富的历史产量数据，但由于环境、气候和土壤因素的复杂相互作用，准确及时的作物产量预测仍具挑战性。本研究引入了一个全面的作物产量基准数据集，涵盖2008年至2022年加州所有县的70多种作物。该基准整合了多种数据源，包括Landsat卫星图像、每日气候记录、月度蒸散发数据和高分辨率土壤特性。为了从这些异构输入中有效学习，我们开发了一个多模态深度学习模型，专为县级作物产量预测设计。模型采用分层特征提取和时间序列编码器捕捉生长季的时空动态，而土壤特性和作物身份等静态输入则反映长期变异性。我们的方法在未见测试数据上的整体R2分数为0.76，表明其在加州多样化农业区域中具有强预测性能。这一基准和建模框架为农业预测、气候适应和精准农业提供了重要基础。完整数据集和代码库已在GitHub上公开。

</details>


### [285] [DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos](https://arxiv.org/abs/2506.10242)
**中文标题：DySS：基于动态查询和状态空间学习的高效多摄像头视频3D目标检测**

*Rajeev Yasarla,Shizhong Han,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: DySS提出了一种基于状态空间学习和动态查询的高效3D目标检测方法，通过动态更新查询和辅助任务训练，实现了高性能和实时推理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于稀疏查询的3D目标检测方法在处理多帧视频时计算成本高，DySS旨在通过状态空间学习和动态查询优化效率和性能。

Method: DySS利用状态空间模型（SSM）逐步处理时间步长的特征，并通过未来预测和掩码重建辅助任务训练SSM。动态查询通过合并、删除和拆分操作更新，保持高效检测。

Result: 在nuScenes测试集上，DySS达到65.31 NDS和57.4 mAP，优于现有方法；在验证集上达到56.2 NDS和46.2 mAP，推理速度为33 FPS。

Conclusion: DySS通过状态空间学习和动态查询，实现了高效且高性能的3D目标检测，适用于自动驾驶场景。

摘要: 基于摄像头的鸟瞰图（BEV）3D目标检测是自动驾驶中最重要的感知任务之一。早期方法依赖密集BEV特征，构建成本高。近期研究探索基于稀疏查询的检测，但仍需大量查询，且多帧视频处理时计算成本高。本文提出DySS，一种结合状态空间学习和动态查询的新方法。具体而言，DySS利用状态空间模型（SSM）逐步处理时间步长的特征，并通过未来预测和掩码重建辅助任务优化SSM训练。SSM的状态提供了高效且信息丰富的场景总结。基于状态空间学习特征，DySS通过合并、删除和拆分操作动态更新查询，保持高效的检测查询集。DySS在性能和推理效率上均表现优异：在nuScenes测试集上达到65.31 NDS和57.4 mAP，优于最新方法；在验证集上达到56.2 NDS和46.2 mAP，推理速度为33 FPS。

</details>


### [286] [HalLoc: Token-level Localization of Hallucinations for Vision Language Models](https://arxiv.org/abs/2506.10286)
**中文标题：HalLoc：视觉语言模型中幻觉的标记级定位**

*Eunkyu Park,Minyeong Kim,Gunhee Kim*

Main category: cs.CV

TL;DR: HalLoc是一个用于高效检测视觉语言模型幻觉的数据集，包含15万个标记级注释样本，支持概率性检测，并提出了一种低开销的基线模型，可无缝集成到现有模型中。


<details>
  <summary>Details</summary>
Motivation: 当前幻觉检测方法计算成本高且结果绝对化，无法适应真实场景中模糊的幻觉边界。HalLoc旨在解决这些问题，提升视觉语言模型的可靠性。

Method: 构建了包含15万标记级注释样本的HalLoc数据集，涵盖VQA、指令跟随和图像描述任务，并训练了一个低开销的基线模型，支持生成时的实时幻觉检测。

Result: HalLoc数据集和基线模型为幻觉检测提供了高效工具，支持概率性检测，并可无缝集成到现有视觉语言模型中，提升其可靠性。

Conclusion: HalLoc为视觉语言模型的幻觉检测提供了新方法，其数据集和模型有望在真实应用中增强模型的信任度。

摘要: 幻觉对大型视觉语言模型的可靠性构成重大挑战，其检测对于关键应用中的准确性至关重要。当前的检测方法通常依赖计算密集型模型，导致高延迟和资源需求。其确定性结果也未能考虑真实场景中幻觉与真实信息界限模糊的情况。为解决这些问题，我们提出了HalLoc，一个设计用于高效概率性幻觉检测的数据集。它包含15万个标记级注释样本，涵盖视觉问答（VQA）、指令跟随和图像描述任务中的幻觉类型。该数据集支持开发具有分级置信度的幻觉检测模型，从而实现更明智的用户交互。此外，我们引入了一个基于HalLoc训练的基线模型，提供低开销的生成时并发幻觉检测。该模型可无缝集成到现有视觉语言模型中，在保持效率的同时提升可靠性。这一即插即用的幻觉检测模块为增强视觉语言模型在真实应用中的可信度开辟了新途径。HalLoc数据集和代码已公开：https://github.com/dbsltm/cvpr25_halloc。

</details>


### [287] [Uncertainty-Aware Deep Learning for Automated Skin Cancer Classification: A Comprehensive Evaluation](https://arxiv.org/abs/2506.10302)
**中文标题：不确定性感知深度学习在自动化皮肤癌分类中的全面评估**

*Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya*

Main category: cs.CV

TL;DR: 本文通过结合迁移学习和不确定性量化（UQ）技术，对深度学习模型在皮肤癌分类中的性能进行了全面评估。结果表明，基于CLIP的视觉变换器（如LAION CLIP ViT-H/14与SVM结合）表现最佳，而集成方法在准确性和不确定性处理之间取得了良好平衡。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌的准确诊断对早期治疗和改善患者预后至关重要。尽管深度学习模型在自动化皮肤癌分类中表现出潜力，但其性能受限于数据稀缺和缺乏不确定性意识。本研究旨在通过迁移学习和不确定性量化技术提升模型的性能和可靠性。

Method: 研究分为两个阶段：1）在HAM10000数据集上，对多种预训练特征提取器（如CLIP变体、ResNet50、DenseNet121、VGG16和EfficientNet-V2-Large）与传统分类器（如SVM、XGBoost和逻辑回归）进行性能基准测试；2）引入不确定性量化方法（如蒙特卡洛Dropout、集成方法和集成蒙特卡洛Dropout），并使用不确定性感知指标（如UAcc、USen、USpe和UPre）评估模型。

Result: 基于CLIP的视觉变换器（特别是LAION CLIP ViT-H/14与SVM结合）分类性能最高。集成方法在准确性和不确定性处理之间表现良好，而集成蒙特卡洛Dropout对不确定性预测更敏感。

Conclusion: 研究表明，将不确定性量化整合到基于深度学习的医学诊断中，可以提升模型在真实临床应用中的性能和可信度。

摘要: 准确可靠的皮肤癌诊断对早期治疗和改善患者预后至关重要。深度学习（DL）模型在自动化皮肤癌分类中表现出潜力，但其性能受限于数据稀缺和缺乏不确定性意识。本研究通过迁移学习和不确定性量化（UQ）技术，在HAM10000数据集上对基于DL的皮肤病变分类进行了全面评估。第一阶段，我们对多种预训练特征提取器（包括CLIP变体、ResNet50、DenseNet121、VGG16和EfficientNet-V2-Large）与传统分类器（如SVM、XGBoost和逻辑回归）进行了性能基准测试。结果表明，基于CLIP的视觉变换器（特别是LAION CLIP ViT-H/14与SVM结合）分类性能最高。第二阶段，我们通过蒙特卡洛Dropout（MCD）、集成方法和集成蒙特卡洛Dropout（EMCD）引入UQ，不仅评估预测准确性，还评估模型输出的可靠性。我们使用不确定性感知指标（如UAcc、USen、USpe和UPre）对这些模型进行了评估。结果表明，集成方法在准确性和不确定性处理之间取得了良好平衡，而EMCD对不确定性预测更敏感。本研究强调了将UQ整合到基于DL的医学诊断中的重要性，以提升其在真实临床应用中的性能和可信度。

</details>


### [288] [Towards Scalable SOAP Note Generation: A Weakly Supervised Multimodal Framework](https://arxiv.org/abs/2506.10328)
**中文标题：迈向可扩展的SOAP笔记生成：一种弱监督多模态框架**

*Sadia Kamal,Tim Oates,Joy Wan*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督多模态框架，用于从有限的输入（如病变图像和稀疏临床文本）生成结构化的SOAP笔记，减轻临床医生负担并减少对大量标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见的癌症，每年医疗支出超过80亿美元。临床医生需手动生成详细的SOAP笔记，工作繁重且易导致职业倦怠。本文旨在通过自动化生成SOAP笔记，减轻临床医生负担并提高文档生成的可扩展性。

Method: 提出了一种弱监督多模态框架，结合病变图像和稀疏临床文本，生成结构化的SOAP笔记。该方法减少了对人工标注的依赖，并引入了两种新评估指标（MedConceptEval和CCS）以评估临床质量。

Result: 该方法在关键临床相关性指标上表现与GPT-4o、Claude和DeepSeek Janus Pro相当，并通过新指标验证了其语义对齐和临床一致性。

Conclusion: 该框架为临床文档生成提供了一种可扩展的解决方案，减轻了临床医生负担，同时减少了对大规模标注数据的需求。

摘要: 皮肤癌是全球最常见的癌症，每年医疗支出超过80亿美元。在临床环境中，医生使用详细的SOAP（主观、客观、评估和计划）笔记记录患者就诊情况。然而，手动生成这些笔记工作繁重，易导致临床医生职业倦怠。本文提出了一种弱监督多模态框架，从有限的输入（如病变图像和稀疏临床文本）生成结构化的SOAP笔记。该方法减少了对人工标注的依赖，实现了可扩展且临床可靠的文档生成，同时减轻了临床医生负担。我们的方法在关键临床相关性指标上表现与GPT-4o、Claude和DeepSeek Janus Pro相当。为评估临床质量，我们引入了两种新指标MedConceptEval和临床一致性评分（CCS），分别评估与专家医学概念的语义对齐和输入特征的临床一致性。

</details>


### [289] [Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video](https://arxiv.org/abs/2506.10331)
**中文标题：用户生成全向视频的音视频质量评估数据集与方法研究**

*Fei Zhao,Da Pan,Zelu Qi,Ping Shi*

Main category: cs.CV

TL;DR: 本文针对元宇宙中用户生成的全向视频（ODV）音视频质量评估（AVQA）研究不足的问题，构建了一个UGC全向音视频数据集，并开发了一个基于视频特征提取、音频特征提取和音视频融合模块的基线模型，实验证明该模型性能优异。


<details>
  <summary>Details</summary>
Motivation: 随着元宇宙的兴起，全向视频（ODV）逐渐从专业生成内容（PGC）转向用户生成内容（UGC），但目前对UGC-ODV的音视频质量评估（AVQA）研究较少，亟需构建数据集和开发评估方法。

Method: 1. 构建了一个UGC全向音视频数据集，包含5名用户使用两种全向相机拍摄的300个视频，涵盖10种场景类型。2. 进行主观AVQA实验获取音视频序列的平均意见分数（MOS）。3. 开发了一个基线模型，包含视频特征提取、音频特征提取和音视频融合模块。

Result: 实验结果表明，所提出的基线模型在构建的数据集上表现最优。

Conclusion: 本文填补了UGC-ODV音视频质量评估研究的空白，提出的数据集和基线模型为未来研究提供了基础。

摘要: 随着元宇宙的兴起，全向视频（ODV）逐渐从专业生成内容（PGC）转向用户生成内容（UGC），但目前对ODV音视频质量评估（AVQA）的研究仍有限。为此，我们构建了一个UGC全向音视频数据集，包含5名用户使用两种全向相机拍摄的300个视频，涵盖10种场景类型。在数据集上进行了主观AVQA实验，获取了音视频序列的平均意见分数（MOS）。随后，为促进UGC-ODV AVQA领域的发展，我们在提出的数据集上构建了一个有效的AVQA基线模型，该模型包含视频特征提取模块、音频特征提取模块和音视频融合模块。实验结果表明，我们的模型在提出的数据集上实现了最优性能。

</details>


### [290] [Using Vision Language Models to Detect Students' Academic Emotion through Facial Expressions](https://arxiv.org/abs/2506.10334)
**中文标题：利用视觉语言模型通过面部表情检测学生的学术情绪**

*Deliang Wang,Chao Yang,Gaowei Chen*

Main category: cs.CV

TL;DR: 本研究探索了使用视觉语言模型（VLMs）通过零样本提示分析学生在线学习中的学术情绪（如困惑、分心、快乐等）。初步结果表明，Qwen2.5-VL-7B-Instruct模型在识别快乐和困惑情绪上表现较好，但在分心行为识别上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 学生的学术情绪对其社交行为和学习表现有重要影响。传统监督学习方法需要大量标注数据和训练，难以泛化。视觉语言模型（VLMs）提供了一种无需微调即可泛化的新方法。

Method: 研究使用两种视觉语言模型（Llama-3.2-11B-Vision-Instruct和Qwen2.5-VL-7B-Instruct），通过零样本提示分析5,000张包含困惑、分心、快乐、中性及疲惫表情的学生面部图像。

Result: 两种模型在学术情绪识别上表现中等，Qwen2.5-VL-7B-Instruct优于Llama-3.2-11B-Vision-Instruct。Qwen2.5-VL-7B-Instruct在识别快乐和困惑情绪上表现较好，但均无法有效识别分心行为。

Conclusion: 视觉语言模型在学术情绪识别中具有潜力，尤其是Qwen2.5-VL-7B-Instruct在识别困惑情绪上的表现，为实际应用提供了可能。未来需改进分心行为的识别能力。

摘要: 学生的学术情绪显著影响其社交行为和学习表现。传统方法主要依赖监督机器学习算法来自动准确分析这些情绪，但这些模型通常难以在不同情境中泛化，需要重复的数据收集、标注和训练。视觉语言模型（VLMs）的出现提供了一种有前景的替代方案，通过零样本提示实现视觉识别任务的泛化，无需微调。本研究探讨了VLMs在在线学习环境中通过面部表情分析学生学术情绪的潜力。我们使用两种VLMs（Llama-3.2-11B-Vision-Instruct和Qwen2.5-VL-7B-Instruct），通过零样本提示分析了5,000张包含困惑、分心、快乐、中性及疲惫表情的图像。初步结果表明，两种模型在学术面部表情识别中表现中等，其中Qwen2.5-VL-7B-Instruct优于Llama-3.2-11B-Vision-Instruct。值得注意的是，两种模型在识别快乐情绪上表现优异，但无法检测分心行为。此外，Qwen2.5-VL-7B-Instruct在识别学生困惑表情上表现出较高性能，突显了其在识别导致学生困惑内容方面的实际应用潜力。

</details>


### [291] [PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting](https://arxiv.org/abs/2506.10335)
**中文标题：PointGS：基于高斯泼溅的点注意力感知稀疏视角合成**

*Lintao Xiang,Hongpei Zheng,Yating Huang,Qijun Yang,Hujun Yin*

Main category: cs.CV

TL;DR: 本文提出了一种基于点注意力感知的高斯泼溅框架（PointGS），用于从稀疏视角合成高质量实时渲染，解决了现有3D高斯泼溅方法在输入视角有限时容易过拟合的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅（3DGS）方法需要大量校准视角才能生成一致的场景表示，而在输入视角稀疏时容易过拟合训练视角，导致渲染质量下降。本文旨在解决这一问题。

Method: 首先利用立体基础模型估计准确的相机姿态并重建密集点云以初始化高斯；然后通过采样和聚合多尺度2D外观特征编码每个3D高斯的颜色属性；设计基于自注意力机制的点交互网络增强点级外观表示；最后通过两个轻量级多层感知器（MLP）解码高斯参数完成渲染。

Result: 在多样化基准测试中，该方法显著优于基于NeRF的方法，并在少样本设置下与最先进的3DGS方法性能相当。

Conclusion: PointGS框架通过点注意力机制和特征增强，实现了稀疏视角下的高质量实时渲染，为3D场景表示提供了新的解决方案。

摘要: 3D高斯泼溅（3DGS）是一种创新的渲染技术，通过显式3D场景表示在渲染速度和视觉质量上超越了神经辐射场（NeRF）。现有3DGS方法需要大量校准视角以生成一致且完整的场景表示。当输入视角有限时，3DGS容易过拟合训练视角，导致渲染质量显著下降。为解决这一局限性，我们提出了一种点级特征感知高斯泼溅框架，支持从稀疏训练视角实现实时高质量渲染。具体而言，我们首先利用最新的立体基础模型估计准确的相机姿态并重建密集点云以初始化高斯；然后通过采样和聚合稀疏输入的多尺度2D外观特征编码每个3D高斯的颜色属性。为增强点级外观表示，我们设计了一种基于自注意力机制的点交互网络，使每个高斯点能够与其最近邻点交互。这些增强的特征随后通过两个轻量级多层感知器（MLP）解码为高斯参数以完成最终渲染。在多样化基准测试中的大量实验表明，我们的方法显著优于基于NeRF的方法，并在少样本设置下与最先进的3DGS方法性能相当。

</details>


### [292] [GeoCAD: Local Geometry-Controllable CAD Generation](https://arxiv.org/abs/2506.10337)
**中文标题：GeoCAD：局部几何可控的CAD生成**

*Zhanwei Zhang,Kaiyuan Liu,Junjie Liu,Wenxiao Wang,Binbin Lin,Liang Xie,Chen Shen,Deng Cai*

Main category: cs.CV

TL;DR: GeoCAD是一种局部几何可控的CAD生成方法，通过互补标注策略生成几何指令，利用大语言模型预测局部形状，提升设计效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在局部几何可控的CAD生成中存在不足，无法遵循文本指令或专注于局部修改。GeoCAD旨在解决这一问题，提供用户友好的局部几何可控生成方案。

Method: 提出互补标注策略，分别基于顶点和VLLM标注简单和复杂局部形状；训练阶段随机掩码局部部分，利用几何指令和剩余部分输入大语言模型预测掩码部分；推理阶段用户可指定局部修改并遵循几何指令。

Result: 实验表明GeoCAD在生成质量、有效性和文本到CAD一致性方面表现优异。

Conclusion: GeoCAD通过互补标注和大语言模型实现了高效的局部几何可控CAD生成，为设计自动化提供了新思路。

摘要: 局部几何可控的计算机辅助设计（CAD）生成旨在自动修改CAD模型的局部部分，提升设计效率，并确保新生成的局部形状遵循用户特定的几何指令（例如等腰直角三角形或切去一角的矩形）。然而，现有方法在实现这一目标时面临挑战，尤其是无法遵循文本指令或专注于局部部分。为解决这一问题，我们提出了GeoCAD，一种用户友好的局部几何可控CAD生成方法。具体而言，我们首先提出互补标注策略，为局部部分生成几何指令。该策略通过基于顶点和VLLM的标注分别系统化标注简单和复杂部分，共标注了约221k个不同的局部部分。在训练阶段，给定一个CAD模型，我们随机掩码一个局部部分，然后利用其几何指令和剩余部分作为输入，通过大语言模型（LLMs）预测掩码部分。在推理阶段，用户可以指定任何局部部分进行修改，同时遵循多种预定义的几何指令。大量实验证明了GeoCAD在生成质量、有效性和文本到CAD一致性方面的有效性。代码将在https://github.com/Zhanwei-Z/GeoCAD提供。

</details>


### [293] [UrbanSense:AFramework for Quantitative Analysis of Urban Streetscapes leveraging Vision Large Language Models](https://arxiv.org/abs/2506.10342)
**中文标题：UrbanSense：基于视觉大语言模型的城市街景定量分析框架**

*Jun Yin,Jing Zhong,Peilin Li,Pengyu Zeng,Miao Zhang,Ran Luo,Shuai Lu*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型的多模态研究框架UrbanSense，用于自动化和可扩展地分析城市街景风格差异，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于地理、历史和社会政治因素的差异，城市文化和建筑风格在不同城市间存在显著差异。传统研究方法依赖专家解读和历史文献，难以标准化。因此，需要一种客观且数据驱动的方法来量化城市风格的演变。

Method: 构建了UrbanDiffBench数据集，包含不同时期和地区的建筑图像；开发了基于视觉语言模型的框架UrbanSense，用于生成和比较城市风格的定量表示。

Result: 实验结果表明，超过80%的生成描述通过t检验（p小于0.05），主观评估的高Phi分数（城市0.912，时期0.833）证实了该方法捕捉细微风格差异的能力。

Conclusion: UrbanSense框架能够量化并解释城市风格的演变，为未来设计提供了科学依据。

摘要: 由于地理、年代、历史和社会政治因素的差异，城市文化和建筑风格在不同城市间存在显著差异。理解这些差异对于预测城市未来演变至关重要。作为中国历史延续与现代创新的代表案例，北京和深圳为探索城市街景的转变提供了宝贵视角。然而，传统的城市文化研究方法通常依赖专家解读和历史文献，难以在不同背景下标准化。为此，我们提出了一种基于视觉语言模型的多模态研究框架，实现了城市街景风格差异的自动化和可扩展分析。这一方法提升了城市形态研究的客观性和数据驱动性。本研究的贡献如下：首先，我们构建了UrbanDiffBench数据集，包含来自不同时期和地区的建筑图像。其次，我们开发了UrbanSense，首个基于视觉语言模型的城市街景分析框架，能够定量生成和比较城市风格表示。第三，实验结果表明，超过80%的生成描述通过t检验（p小于0.05），主观评估的高Phi分数（城市0.912，时期0.833）证实了该方法捕捉细微风格差异的能力。这些结果凸显了该方法在量化和解释城市风格演变方面的潜力，为未来设计提供了科学依据。

</details>


### [294] [RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration](https://arxiv.org/abs/2506.10344)
**中文标题：RealKeyMorph：真实世界坐标中的关键点用于分辨率无关的图像配准**

*Mina C. Moghadam,Alan Q. Wang,Omer Taub,Martin R. Prince,Mert R. Sabuncu*

Main category: cs.CV

TL;DR: RealKeyMorph（RKM）是一种分辨率无关的图像配准方法，通过输出真实世界坐标中的关键点，避免了传统方法因重采样引入的伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，医学图像因采集参数不同而分辨率各异，传统机器学习配准方法需固定分辨率重采样，易引入伪影。RKM旨在解决这一问题。

Method: RKM扩展了KeyMorph框架，利用扫描仪生成的仿射矩阵将关键点映射到真实世界坐标，从而避免重采样，实现分辨率无关的配准。

Result: 实验表明，RKM在腹部MRI正交2D堆栈和不同分辨率脑部3D数据集的配准任务中表现优越。

Conclusion: RKM通过真实世界坐标关键点实现了分辨率无关的配准，避免了重采样伪影，为医学图像配准提供了更优解决方案。

摘要: 许多现实场景中需要对空间分辨率不同的医学图像进行配准，这通常由像素间距、切片厚度和视场等采集参数差异引起。然而，此前所有基于机器学习的配准技术均需将图像重采样至固定分辨率，这会因插值引入伪影。为此，我们提出了RealKeyMorph（RKM），一种分辨率无关的图像配准方法。RKM是KeyMorph的扩展，后者通过训练网络学习图像对的关键点对应关系，再通过闭式关键点匹配步骤推导对齐变换。为避免重采样并直接处理原始数据，RKM输出扫描仪真实世界坐标中的关键点。为此，我们利用扫描仪（如MRI机器）生成的仿射矩阵，该矩阵编码了体素坐标到真实世界坐标的映射。通过将关键点转换到真实世界空间并将其整合到训练过程中，RKM有效实现了分辨率无关的关键点提取。实验证明，RKM在腹部MRI正交2D堆栈和不同分辨率脑部3D数据集的配准任务中具有显著优势。

</details>


### [295] [Motion-R1: Chain-of-Thought Reasoning and Reinforcement Learning for Human Motion Generation](https://arxiv.org/abs/2506.10353)
**中文标题：Motion-R1：基于链式思维推理和强化学习的人体运动生成**

*Runqi Ouyang,Haoyun Li,Zhenyuan Zhang,Xiaofeng Wang,Zheng Zhu,Guan Huang,Xingang Wang*

Main category: cs.CV

TL;DR: Motion-R1 是一种结合链式思维推理和强化学习的运动生成框架，通过分解复杂指令为逻辑动作路径，显著提升运动生成的语义理解和长期一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到运动生成方法依赖端到端映射，难以捕捉深层语言结构和逻辑推理，导致生成的运动缺乏可控性、一致性和多样性。Motion-R1 旨在通过链式思维机制解决这些问题。

Method: Motion-R1 采用链式思维机制分解复杂指令为逻辑动作路径，并结合 Group Relative Policy Optimization 强化学习算法，联合优化推理链和运动合成。

Result: 在多个基准数据集上的实验表明，Motion-R1 在语义理解和长期时间一致性方面优于现有方法。

Conclusion: Motion-R1 通过链式思维推理和强化学习的结合，显著提升了运动生成的语义准确性和可控性，为复杂指令的运动生成提供了新思路。

摘要: 近年来，大型语言模型在自然语言理解和推理方面的进展为文本到运动生成提供了新的可能性。尽管现有方法在语义对齐和运动合成方面取得了显著进展，但它们通常依赖端到端映射策略，难以捕捉深层语言结构和逻辑推理，导致生成的运动缺乏可控性、一致性和多样性。为解决这些问题，我们提出了 Motion-R1，一种结合链式思维机制的统一运动-语言建模框架。通过将复杂文本指令显式分解为逻辑结构的动作路径，Motion-R1 为运动生成提供了高级语义指导，显著提升了模型对多步骤、长期和组合丰富指令的解释和执行能力。为训练模型，我们采用了 Group Relative Policy Optimization，一种专为大型模型设计的强化学习算法，利用运动质量反馈联合优化推理链和运动合成。在多个基准数据集上的广泛实验表明，Motion-R1 在需要细致语义理解和长期时间一致性的场景中，表现优于或与现有最佳方法相当。代码、模型和数据将公开提供。

</details>


### [296] [FaceLiVT: Face Recognition using Linear Vision Transformer with Structural Reparameterization For Mobile Device](https://arxiv.org/abs/2506.10361)
**中文标题：FaceLiVT：基于线性视觉变换器和结构重参数化的移动设备人脸识别**

*Novendra Setyawan,Chi-Chia Sun,Mao-Hsiu Hsu,Wen-Kai Kuo,Jun-Wei Hsieh*

Main category: cs.CV

TL;DR: FaceLiVT是一种轻量级但高效的人脸识别模型，结合了CNN-Transformer混合架构和创新的多头线性注意力机制，显著降低了计算复杂度，同时在移动设备上实现了高精度和低延迟。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的移动设备上实现高效且高精度的人脸识别，需要一种轻量级模型，既能减少计算复杂度，又能保持竞争力。

Method: FaceLiVT采用了一种混合CNN-Transformer架构，并引入了创新的多头线性注意力机制（MHLA）和重参数化的token mixer，以降低计算复杂度。

Result: 在多个基准测试（如LFW、CFP-FP等）中，FaceLiVT表现优于现有轻量级模型，推理速度比EdgeFace快8.6倍，比纯ViT模型快21.2倍。

Conclusion: FaceLiVT通过平衡设计，为资源受限平台提供了一种高效且实用的实时人脸识别解决方案。

摘要: 本文介绍了FaceLiVT，一种轻量级但强大的人脸识别模型，它结合了混合卷积神经网络（CNN）-变换器架构和创新的轻量级多头线性注意力（MHLA）机制。通过将MHLA与重参数化的token mixer结合，FaceLiVT在保持竞争力的同时有效降低了计算复杂度。在多个具有挑战性的基准测试（如LFW、CFP-FP、AgeDB-30、IJB-B和IJB-C）上的广泛评估表明，其性能优于现有的轻量级模型。MHLA显著提高了推理速度，使FaceLiVT在移动设备上能够以更低的延迟实现高精度。具体而言，FaceLiVT比最近针对边缘设备优化的混合CNN-Transformer模型EdgeFace快8.6倍，比纯ViT模型快21.2倍。凭借其平衡的设计，FaceLiVT为资源受限平台提供了一种高效且实用的实时人脸识别解决方案。

</details>


### [297] [FSATFusion: Frequency-Spatial Attention Transformer for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.10366)
**中文标题：FSATFusion：基于频率-空间注意力Transformer的红外与可见光图像融合方法**

*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui,Yuhan Lyu*

Main category: cs.CV

TL;DR: 提出了一种名为FSATFusion的端到端融合网络，通过频率-空间注意力Transformer模块（FSAT）和改进的Transformer模块（ITM）有效提取红外与可见光图像的全局特征，显著提升了融合性能，并在下游任务中表现出优异的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在红外与可见光图像融合（IVIF）中常使用卷积神经网络提取特征，但其全局上下文捕捉能力有限，导致信息丢失，限制了融合性能。

Method: FSATFusion包含频率-空间注意力Transformer模块（FSAT）和改进的Transformer模块（ITM）。FSAT通过频率-空间注意力机制（FSAM）提取显著特征，ITM增强全局上下文信息提取能力。

Result: 实验表明，FSATFusion在融合质量和效率上优于其他先进方法，并在未修改的情况下成功应用于其他任务，验证了其优异的泛化能力。目标检测实验进一步证明了其在下游视觉任务中的优势。

Conclusion: FSATFusion通过创新的频率-空间注意力机制和改进的Transformer模块，显著提升了红外与可见光图像融合的性能，并展现出强大的泛化能力和下游任务适应性。

摘要: 红外与可见光图像融合（IVIF）因其在下游应用中的优异表现而受到学术界和工业界的广泛关注。现有的深度学习方法通常利用卷积神经网络提取图像特征，但卷积操作在捕捉全局上下文方面的固有局限性可能导致信息丢失，从而限制融合性能。为解决这一问题，我们提出了一种端到端的融合网络——频率-空间注意力Transformer融合网络（FSATFusion）。FSATFusion包含一个频率-空间注意力Transformer模块（FSAT），旨在有效提取源图像的判别性特征。该FSAT模块包含一个频率-空间注意力机制（FSAM），能够从特征图中提取显著特征。此外，我们还提出了一种改进的Transformer模块（ITM），以增强原始Transformer的全局上下文信息提取能力。通过定性和定量对比实验，我们证明了FSATFusion在融合质量和效率上优于其他先进方法。此外，我们的网络在未作任何修改的情况下，成功应用于另外两项任务，验证了FSATFusion的优异泛化能力。最后，目标检测实验进一步证明了FSATFusion在下游视觉任务中的优势。代码已开源：https://github.com/Lmmh058/FSATFusion。

</details>


### [298] [Revisiting Transformers with Insights from Image Filtering](https://arxiv.org/abs/2506.10371)
**中文标题：从图像滤波的视角重新审视Transformer**

*Laziz U. Abdullaev,Maksim Tkachenko,Tan M. Nguyen*

Main category: cs.CV

TL;DR: 本文通过图像处理框架重新解释Transformer的自注意力机制，并探讨其组件（如位置编码和残差连接）的作用，同时提出两种改进架构，不仅提升了解释性，还提高了模型在语言和视觉任务中的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制作为Transformer的核心组件，其成功和局限性缺乏深入的理论解释。本文旨在通过图像处理框架，为自注意力及其变体提供更深入的理论基础，并探索其改进潜力。

Method: 提出了一种统一的图像处理框架，用于解释自注意力机制及其组件（如位置编码和残差连接），并基于此框架设计了两种独立的Transformer架构改进。

Result: 实验表明，基于图像处理启发的改进不仅增强了模型的可解释性，还显著提升了语言和视觉任务中的准确性、鲁棒性以及对长序列的理解能力。

Conclusion: 通过图像处理框架重新审视Transformer，不仅为自注意力机制提供了新的理论视角，还展示了其改进潜力，为未来研究提供了方向。

摘要: 自注意力机制作为Transformer等最先进深度学习架构的核心，很大程度上是启发式驱动的，且难以解释。因此，建立坚实的理论基础以解释其成功与局限性已成为近年研究的重点。一些研究尝试通过图像去噪和非参数回归的视角理解自注意力，但现有框架仍缺乏对其原始及变体架构组件的深入机制解释。本文旨在通过开发一种统一的图像处理框架，不仅解释自注意力计算本身，还阐明位置编码和残差连接等组件的作用，包括后续多种变体。我们还指出了两种概念之间的潜在差异，并努力弥合这一差距。我们在Transformer中引入了两种独立的架构改进。尽管主要目标是可解释性，但实验表明，基于图像处理启发的改进还能显著提升语言和视觉任务中的准确性、对数据污染和对抗攻击的鲁棒性，以及长序列理解能力。

</details>


### [299] [Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial](https://arxiv.org/abs/2506.10386)
**中文标题：利用六自由度姿态基础模型测绘海底沉积物埋藏**

*Jerry Yan,Chinmay Talegaonkar,Nicholas Antipa,Eric Terrill,Sophia Merrifield*

Main category: cs.CV

TL;DR: 本文提出了一种名为PoseIDON的计算机视觉方法，通过结合深度基础模型特征和多视角摄影测量技术，从ROV视频中估计海底物体的六自由度姿态及周围海底的朝向，进而推断埋藏深度。该方法在历史海洋倾倒场的54个物体上验证，平均埋藏深度误差约为10厘米。


<details>
  <summary>Details</summary>
Motivation: 海底人为物体的埋藏状态对局部沉积动力学研究、生态风险评估以及污染物迁移分析至关重要，但现有遥感图像技术因部分遮挡、能见度差和物体退化等问题难以准确估计埋藏深度。

Method: PoseIDON方法结合深度基础模型特征和多视角摄影测量技术，通过将物体的CAD模型与观测图像对齐，并拟合局部平面近似海底，估计物体的六自由度姿态和海底朝向，从而推断埋藏深度。

Result: 在San Pedro Basin历史海洋倾倒场的54个物体（如桶和弹药）上验证，模型平均埋藏深度误差约为10厘米，并能反映沉积物迁移过程的空间埋藏模式。

Conclusion: 该方法实现了海底埋藏的非侵入式、可扩展测绘，为污染场地的环境评估提供了支持。

摘要: 海底人为物体的埋藏状态不仅揭示了局部沉积动力学特征，还对生态风险评估、污染物迁移分析以及危险物质（如弹药）的回收或缓解策略可行性评估至关重要。然而，由于部分遮挡、能见度差和物体退化等问题，从遥感图像中准确估计埋藏深度仍然具有挑战性。本研究提出了一种名为PoseIDON的计算机视觉流程，通过结合深度基础模型特征和多视角摄影测量技术，从ROV视频中估计物体的六自由度姿态及周围海底的朝向。埋藏深度通过将物体的CAD模型与观测图像对齐，并拟合局部平面近似海底来推断。该方法在San Pedro Basin历史海洋倾倒场的54个物体（包括桶和弹药）上进行了验证，平均埋藏深度误差约为10厘米，并能解析反映沉积物迁移过程的空间埋藏模式。这一方法实现了海底埋藏的非侵入式、可扩展测绘，为污染场地的环境评估提供了支持。

</details>


### [300] [DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Transformer and Mamba](https://arxiv.org/abs/2506.10390)
**中文标题：DART：用于视觉Transformer和Mamba的可微分动态自适应区域分词器**

*Shicheng Yin,Kaixuan Yin,Yang Liu,Weixing Chen,Liang Lin*

Main category: cs.CV

TL;DR: DART是一种动态自适应区域分词器，通过内容依赖的变尺寸分块提升视觉Transformer和Mamba的性能，减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有非卷积模型（如ViT和Vim）依赖固定尺寸分块，导致背景区域过度编码和关键局部细节丢失。DART旨在解决这一问题。

Method: DART结合可学习区域得分和分段可微分分位数操作，动态将图像划分为内容依赖的变尺寸分块，信息丰富区域分配更多标记。

Result: DART在DeiT（ImageNet-1K）上准确率提升2.1%，计算量减少45%，并在DeiT、Vim和VideoMamba上表现一致优越。

Conclusion: DART提供了一种高效且性能优越的动态分块方法，显著提升模型性能并减少计算开销。

摘要: 近年来，视觉Transformer（ViT）和视觉Mamba（Vim）等非卷积模型在计算机视觉任务中表现卓越。然而，它们依赖固定尺寸分块，常导致背景区域过度编码和关键局部细节丢失，尤其是当信息丰富的对象稀疏分布时。为此，我们提出了一种完全可微分的动态自适应区域分词器（DART），能够根据内容自适应地将图像划分为不同尺寸的分块。DART结合可学习区域得分和分段可微分分位数操作，将更多标记分配给信息丰富的区域。尽管仅引入约100万额外参数，DART在DeiT（ImageNet-1K）上准确率提升2.1%。与均匀增加标记密度的方法不同，DART提供了一种更高效的替代方案，计算量减少45%且性能更优。在DeiT、Vim和VideoMamba上的大量实验表明，DART在计算开销极小甚至减少的情况下，持续提升准确率。代码发布于https://github.com/HCPLab-SYSU/DART。

</details>


### [301] [ReconMOST: Multi-Layer Sea Temperature Reconstruction with Observations-Guided Diffusion](https://arxiv.org/abs/2506.10391)
**中文标题：ReconMOST：基于观测引导扩散的多层海水温度重建**

*Yuanyi Song,Pumeng Lyu,Ben Fei,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.CV

TL;DR: ReconMOST提出了一种基于数据驱动的扩散模型框架，用于多层海水温度重建，解决了传统方法因数据稀疏、算法复杂和计算成本高的问题，并在全球范围内实现了高精度重建。


<details>
  <summary>Details</summary>
Motivation: 准确的海洋温度重建对全球气候动态研究和海洋气象研究至关重要。传统方法因数据稀疏、算法复杂和计算成本高而受限，而现有的机器学习方法多局限于海表和局部区域重建，难以解决云遮挡等问题。

Method: ReconMOST首先使用大量历史数值模拟数据预训练无条件的扩散模型，使其学习到物理一致的海洋温度场分布模式；在生成阶段，利用稀疏但高精度的现场观测数据作为反向扩散过程的引导点，生成精确的重建结果。在缺乏直接观测数据的区域，模型通过预训练学习到的物理一致分布模式实现隐式引导和物理合理的重建。

Result: 该方法在全球多层海水温度重建中处理了超过92.5%的缺失数据，同时保持了重建精度和空间分辨率。在CMIP6和EN4分析数据上的实验结果显示，均方误差（MSE）分别为0.049（引导）、0.680（重建）和0.633（总体），证明了框架的有效性和鲁棒性。

Conclusion: ReconMOST将基于机器学习的海表温度重建扩展到全球多层场景，解决了数据稀疏和云遮挡等问题，展现了高精度重建和优异的泛化能力。

摘要: 准确的海洋温度重建对于反映全球气候动态和支持海洋气象研究至关重要。传统方法因数据稀疏、算法复杂和计算成本高而面临挑战，而机器学习（ML）方法的应用多局限于海表和局部区域的重建问题，难以解决云遮挡等问题。为了克服这些限制，本文提出了ReconMOST，一种基于数据驱动的引导扩散模型框架，用于多层海水温度重建。具体而言，我们首先使用大量历史数值模拟数据预训练一个无条件的扩散模型，使模型能够学习到物理一致的海洋温度场分布模式。在生成阶段，稀疏但高精度的现场观测数据被用作反向扩散过程的引导点，生成精确的重建结果。重要的是，在缺乏直接观测数据的区域，预训练学习到的物理一致空间分布模式能够实现隐式引导和物理合理的重建。我们的方法将基于ML的海表温度重建扩展到全球多层场景，处理了超过92.5%的缺失数据，同时保持了重建精度、空间分辨率和优异的泛化能力。我们在CMIP6数值模拟数据上预训练模型，并在CMIP6和EN4分析数据上进行了引导重建实验。均方误差（MSE）值在引导、重建和总体上的结果分别为0.049、0.680和0.633，证明了所提框架的有效性和鲁棒性。我们的源代码可在https://github.com/norsheep/ReconMOST获取。

</details>


### [302] [Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation](https://arxiv.org/abs/2506.10395)
**中文标题：Pisces：一种用于图像理解与生成的自回归基础模型**

*Zhiyang Xu,Jiuhai Chen,Zhaojiang Lin,Xichen Pan,Lifu Huang,Tianyi Zhou,Madian Khabsa,Qifan Wang,Di Jin,Michihiro Yasunaga,Lili Yu,Xi Victoria Lin,Shaoliang Nie*

Main category: cs.CV

TL;DR: Pisces是一种自回归多模态基础模型，通过解耦视觉编码架构和定制化训练技术，在图像理解和生成任务中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型在图像理解和生成任务中表现不如专用模型，主要因为视觉特征和训练过程的差异。Pisces旨在解决这一问题。

Method: 提出解耦视觉编码架构和定制化训练技术，结合数据筛选、预训练和微调，优化多模态生成任务。

Result: 在20多个图像理解基准测试和GenEval图像生成基准测试中表现优异，验证了图像理解与生成的协同关系。

Conclusion: Pisces通过解耦视觉编码和定制化训练，推动了统一多模态模型的发展，展示了图像理解与生成的协同潜力。

摘要: 近年来，大型语言模型（LLM）的进步使得多模态基础模型能够在统一框架中同时处理图像理解和生成任务。然而，统一模型在这两项任务中的表现往往不如专用模型。开发统一模型的关键挑战在于图像理解与生成所需的视觉特征差异，以及不同模态所需的训练过程不同。本文提出Pisces，一种自回归多模态基础模型，通过新颖的解耦视觉编码架构和针对多模态生成优化的定制训练技术解决了这一问题。结合精细的数据筛选、预训练和微调，Pisces在图像理解和生成任务中均取得了竞争力表现。我们在20多个图像理解公共基准测试中评估Pisces，结果显示其在广泛任务中表现优异。此外，在广泛采用的图像生成基准测试GenEval上，Pisces展现出强大的生成能力。我们的深入分析揭示了图像理解与生成之间的协同关系，以及使用独立视觉编码器的优势，推动了统一多模态模型领域的发展。

</details>


### [303] [It's Not the Target, It's the Background: Rethinking Infrared Small Target Detection via Deep Patch-Free Low-Rank Representations](https://arxiv.org/abs/2506.10425)
**中文标题：目标不是关键，背景才是：通过深度无块低秩表示重新思考红外小目标检测**

*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为LRRNet的新型端到端红外小目标检测框架，通过直接学习低秩背景结构，无需依赖基于块的处理或显式矩阵分解，显著提升了检测精度、鲁棒性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测在复杂背景下面临低信噪比、目标形态多样和缺乏显著视觉线索的挑战，现有深度学习方法因目标内在多变性和弱先验导致性能不稳定。

Method: LRRNet采用压缩-重建-减法（CRS）范式，直接在图像域建模结构感知的低秩背景表示，利用深度神经网络端到端学习低秩背景结构。

Result: 在多个公开数据集上，LRRNet在检测精度、鲁棒性和计算效率上优于38种先进方法，平均速度达82.34 FPS，且在噪声环境下表现稳健。

Conclusion: LRRNet通过直接学习低秩背景结构，为红外小目标检测提供了一种高效且鲁棒的解决方案，具有实际应用潜力。

摘要: 红外小目标检测（IRSTD）在复杂背景下因低信噪比（SCR）、目标形态多样和缺乏显著视觉线索而长期面临挑战。尽管近期深度学习方法试图学习判别性表示，但小目标的内在多变性和弱先验常导致性能不稳定。本文提出了一种新型端到端IRSTD框架LRRNet，利用红外图像背景的低秩特性。受杂乱场景物理可压缩性的启发，该方法采用压缩-重建-减法（CRS）范式，直接在图像域建模结构感知的低秩背景表示，无需依赖基于块的处理或显式矩阵分解。据我们所知，这是首个通过深度神经网络端到端直接学习低秩背景结构的工作。在多个公开数据集上的大量实验表明，LRRNet在检测精度、鲁棒性和计算效率上优于38种先进方法，平均速度达82.34 FPS。在具有挑战性的NoisySIRST数据集上的评估进一步验证了模型对传感器噪声的鲁棒性。源代码将在论文录用后公开。

</details>


### [304] [MF2Summ: Multimodal Fusion for Video Summarization with Temporal Alignment](https://arxiv.org/abs/2506.10430)
**中文标题：MF2Summ：基于时间对齐的多模态融合视频摘要方法**

*Shuo wang,Jihao Zhang*

Main category: cs.CV

TL;DR: MF2Summ是一种基于多模态融合的视频摘要模型，通过整合视觉和听觉信息，显著提升了视频摘要的效果。


<details>
  <summary>Details</summary>
Motivation: 传统视频摘要方法通常仅依赖单一模态（如视觉信息），难以全面捕捉视频的语义丰富性。本文旨在通过多模态融合提升摘要效果。

Method: MF2Summ采用五阶段流程：特征提取、跨模态注意力交互、特征融合、片段预测和关键镜头选择。使用GoogLeNet提取视觉特征，SoundNet提取听觉特征，并通过跨模态Transformer和时间对齐自注意力Transformer建模模态间依赖关系。

Result: 在SumMe和TVSum数据集上的实验表明，MF2Summ性能优于DSNet模型，F1分数分别提升1.9%和0.6%，且优于其他先进方法。

Conclusion: MF2Summ通过多模态融合和时间对齐机制，显著提升了视频摘要的准确性和鲁棒性。

摘要: 随着在线视频内容的迅速增长，高效的视频摘要技术变得尤为重要。传统方法通常仅依赖单一模态（如视觉信息），难以全面捕捉视频的语义丰富性。本文提出MF2Summ，一种基于多模态内容理解的新型视频摘要模型，整合了视觉和听觉信息。MF2Summ采用五阶段流程：特征提取、跨模态注意力交互、特征融合、片段预测和关键镜头选择。视觉特征通过预训练的GoogLeNet提取，听觉特征则通过SoundNet获取。融合机制的核心包括跨模态Transformer和对齐引导的自注意力Transformer，旨在有效建模模态间依赖关系和时间对应性。预测片段的重要性、位置和中心性后，使用非极大值抑制（NMS）和核时间分割（KTS）算法选择关键镜头。在SumMe和TVSum数据集上的实验结果表明，MF2Summ性能优异，F1分数分别比DSNet模型提升1.9%和0.6%，且优于其他先进方法。

</details>


### [305] [Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts](https://arxiv.org/abs/2506.10452)
**中文标题：面向模态缺失和分布偏移的鲁棒多模态情感识别研究**

*Guowei Zhong,Ruohong Huan,Mingzhen Wu,Ronghua Liang,Peng Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为CIDer的鲁棒多模态情感识别框架，通过自蒸馏和因果推理模块解决模态缺失和分布偏移问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前多模态情感识别（MER）方法在同时处理模态缺失和分布外（OOD）数据时存在局限性，且现有方法依赖特定模型或引入过多参数。本文旨在提出一种更实用的解决方案。

Method: CIDer框架包含两个核心模块：模型特定自蒸馏（MSSD）和模型无关因果推理（MACI）。MSSD通过权重共享的自蒸馏方法增强鲁棒性，MACI通过因果图和反事实文本来解决OOD问题。

Result: 实验表明，CIDer在随机模态特征缺失（RMFM）和OOD场景中均表现优异，且参数更少、训练更快。

Conclusion: CIDer为多模态情感识别提供了一种高效且鲁棒的解决方案，适用于模态缺失和分布偏移的复杂场景。

摘要: 近年来，多模态情感识别（MER）在同时处理模态缺失和分布外（OOD）数据方面面临挑战。现有方法通常依赖特定模型或引入过多参数，限制了其实用性。为解决这些问题，我们提出了一种新的鲁棒MER框架——因果推理蒸馏器（CIDer），并引入了一项新任务——随机模态特征缺失（RMFM），以泛化模态缺失的定义。CIDer包含两个关键组件：模型特定自蒸馏（MSSD）模块和模型无关因果推理（MACI）模块。MSSD通过权重共享的自蒸馏方法在低层特征、注意力图和高层表示中增强鲁棒性。此外，词级自对齐注意力模块（WSAM）降低了计算复杂度，而多模态复合变换器（MCT）实现了高效的多模态融合。为应对OOD挑战，MACI采用定制因果图，通过多模态因果模块（MCM）和细粒度反事实文本来缓解标签和语言偏差。值得注意的是，MACI可以独立地以极少的额外参数提升OOD泛化能力。此外，我们还引入了重新划分的MER OOD数据集。实验结果表明，CIDer在RMFM和OOD场景中均表现出鲁棒性能，且参数更少、训练速度更快。本工作的实现代码已公开于https://github.com/gw-zhong/CIDer。

</details>


### [306] [Rethinking Generative Human Video Coding with Implicit Motion Transformation](https://arxiv.org/abs/2506.10453)
**中文标题：重新思考生成式人体视频编码：基于隐式运动变换的方法**

*Bolin Chen,Ru-Ling Liao,Jie Chen,Yan Ye*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐式运动变换（IMT）的生成式人体视频编码方法，解决了传统显式运动引导在复杂人体视频压缩中的失真问题。


<details>
  <summary>Details</summary>
Motivation: 传统的生成式视频编码在面部视频压缩中表现良好，但在复杂多样的人体视频中，显式运动引导会导致重建结果失真和运动不准确。本文旨在通过隐式运动变换（IMT）提升生成式人体视频编码（GHVC）的性能。

Method: 提出将复杂的人体信号表征为紧凑的视觉特征，并将这些特征转化为隐式运动引导，用于信号重建。

Result: 实验证明，IMT范式能有效提升GHVC的压缩效率和重建质量。

Conclusion: 隐式运动变换（IMT）为生成式人体视频编码提供了高效压缩和高保真重建的新途径。

摘要: 与传统混合视频编码相比，生成式视频编码通过将高维信号演化为紧凑特征表示以实现编码端比特流紧凑性，并利用显式运动场作为中间监督以实现解码端高质量重建，在面部视频压缩中取得了显著成功。然而，与面部视频相比，人体视频因其更复杂多样的运动模式而更具挑战性，即在生成式人体视频编码（GHVC）中使用显式运动引导时，重建结果可能出现严重失真和运动不准确。为此，本文揭示了显式运动方法在人体视频压缩中的局限性，并研究了借助隐式运动变换（IMT）提升GHVC性能的方法。具体而言，我们提出将复杂人体信号表征为紧凑视觉特征，并将这些特征转化为隐式运动引导以用于信号重建。实验结果证明了所提IMT范式的有效性，能够助力GHVC实现高效压缩和高保真合成。

</details>


### [307] [Boosting Adversarial Transferability for Hyperspectral Image Classification Using 3D Structure-invariant Transformation and Intermediate Feature Distance](https://arxiv.org/abs/2506.10459)
**中文标题：利用3D结构不变变换和中间特征距离增强高光谱图像分类对抗样本的可迁移性**

*Chun Liu,Bingqian Zhu,Tao Xu,Zheng Zheng,Zheng Li,Wei Yang,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种增强高光谱图像分类模型对抗样本可迁移性的新方法，通过3D结构不变变换和中间特征距离损失，有效提升了对抗样本在黑盒模型中的攻击效果。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像（HSI）因其高维和丰富的频谱信息与自然图像不同，现有对抗攻击方法在HSI领域的研究有限，且难以充分利用图像的结构和特征信息。本文旨在解决这些问题，提升对抗样本的可迁移性。

Method: 1. 在保持图像结构不变的前提下，随机将图像在空间和频谱维度分块，并对每个块应用多种变换以增加输入多样性；2. 设计了一种针对中间层的特征距离损失，以原始样本和对抗样本的特征距离为主要损失，输出层预测为辅助损失，引导扰动破坏真实类别的特征。

Result: 实验表明，所提方法在两个公开HSI数据集上生成的对抗样本对黑盒模型具有显著的可迁移性，且在防御策略下仍保持较强的攻击性能。

Conclusion: 本文方法通过结构不变变换和特征距离损失，显著提升了对抗样本的可迁移性和攻击效果，为HSI分类模型的安全性研究提供了新思路。

摘要: 深度神经网络（DNNs）易受对抗攻击的影响，这对基于DNNs的高光谱图像（HSI）分类技术带来了安全挑战。在自然图像领域，已有大量基于迁移的对抗攻击方法被研究。然而，HSI因其高维和丰富的频谱信息与自然图像不同。目前关于HSI对抗样本的研究仍有限，且难以充分利用图像的结构和特征信息。为解决这些问题，本文提出了一种增强HSI分类模型对抗样本可迁移性的新方法。首先，在保持图像结构不变的前提下，该方法随机将图像在空间和频谱维度分块，并对每个块应用多种变换以增加输入多样性并缓解过拟合。其次，设计了一种针对中间层的特征距离损失，以原始样本和对抗样本的放大特征距离为主要损失，输出层预测为辅助损失。这引导扰动破坏对抗样本中真实类别的特征，有效提升可迁移性。大量实验表明，所提方法在两个公开HSI数据集上生成的对抗样本对黑盒模型具有显著的可迁移性。此外，该方法在防御策略下仍保持较强的攻击性能。

</details>


### [308] [Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization](https://arxiv.org/abs/2506.10463)
**中文标题：初始位置的重要性：神经网络量化中更好的权重初始化研究**

*Stone Yun,Alexander Wong*

Main category: cs.CV

TL;DR: 本文研究了神经网络量化中权重初始化的重要性，提出了一种基于图超网络（GHN）的量化鲁棒初始化方法（GHN-QAT），显著提升了低比特量化（如4位和2位）的准确性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）量化是降低模型推理成本的重要工具，但现有研究很少关注权重初始化对量化鲁棒性的影响。本文旨在探索不同初始化方法对量化模型性能的影响，并提出一种更优的初始化策略。

Method: 首先分析了不同权重初始化方法对CNN量化鲁棒性的影响，随后提出了一种基于图超网络（GHN）的量化鲁棒初始化方法（GHN-QAT），该方法通过预训练和微调GHN来预测量化网络的参数。

Result: 实验表明，初始化方法对量化鲁棒性有显著影响，GHN-QAT在4位量化中表现出显著的准确性提升，甚至在2位量化中也能优于随机初始化。

Conclusion: GHN-QAT为量化DNN模型设计提供了一种新方法，未来可结合量化感知训练进一步优化量化流程。

摘要: 深度神经网络（DNN）量化是实现快速高效推理的重要工具，用于降低机器学习（ML）模型推理的成本。量化特定的模型开发技术（如正则化、量化感知训练和量化鲁棒性惩罚）显著提升了现代DNN的准确性和鲁棒性。然而，关于如何改进DNN训练的初始条件以优化量化的研究却很少。正如随机权重初始化已被证明对浮点模型的测试准确性有显著影响，不同的权重初始化方法也可能影响训练模型的量化鲁棒性。我们开展了一项广泛研究，探讨了不同权重初始化方法对高效CNN常用构建模块的影响。分析表明，即使CNN架构不同，随机权重初始化器的选择也会显著影响最终的量化鲁棒性。接下来，我们探索了一种新的量化鲁棒CNN初始化方法——使用图超网络（GHN）预测量化DNN的参数。除了证明GHN预测的参数在常规float32预训练后具有量化鲁棒性外，我们还发现微调GHN以预测量化图的参数（称为GHN-QAT）可以进一步提高CNN的量化准确性。值得注意的是，GHN-QAT在4位量化中表现出显著的准确性提升，在2位量化中甚至优于随机初始化。据我们所知，这是首次对量化感知DNN权重初始化进行的深入研究。GHN-QAT为量化DNN模型设计提供了一种新方法。未来的研究（如将GHN-QAT初始化的参数用于量化感知训练）可以进一步简化DNN量化流程。

</details>


### [309] [MedSeg-R: Reasoning Segmentation in Medical Images with Multimodal Large Language Models](https://arxiv.org/abs/2506.10465)
**中文标题：MedSeg-R：基于多模态大语言模型的医学图像推理分割**

*Yu Huang,Zelin Peng,Yichen Zhao,Piao Yang,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为MedSeg-R的新型框架，通过多模态大语言模型（MLLMs）实现医学图像的推理分割，能够根据复杂的临床问题生成精确的分割掩码。同时，作者还发布了MedSeg-QA数据集，包含10,000多对图像-掩码和多轮对话。实验表明，MedSeg-R在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割模型依赖显式的人类指令，缺乏主动推理能力，无法理解复杂的临床问题。多模态大语言模型在医学问答任务中有所进展，但难以生成精确的分割掩码，限制了其在自动医学诊断中的应用。

Method: MedSeg-R是一个端到端框架，包含两个核心模块：1）全局上下文理解模块，用于解释图像和理解复杂医学指令，生成多模态中间标记；2）像素级接地模块，将这些标记解码为精确的分割掩码和文本响应。

Result: 实验表明，MedSeg-R在多个基准测试中表现优异，实现了高分割精度，并能对医学图像进行可解释的文本分析。

Conclusion: MedSeg-R通过结合多模态大语言模型的推理能力，成功解决了医学图像推理分割任务，为自动医学诊断提供了新的可能性。

摘要: 医学图像分割对临床诊断至关重要，但现有模型依赖显式人类指令，缺乏理解复杂临床问题的主动推理能力。尽管多模态大语言模型（MLLMs）在医学问答任务中有所进展，但大多数方法难以生成精确的分割掩码，限制了其在自动医学诊断中的应用。本文提出医学图像推理分割任务，旨在基于复杂且隐式的医学指令生成分割掩码。为此，我们提出MedSeg-R，一种端到端框架，利用MLLMs的推理能力解释临床问题，同时生成相应的精确分割掩码。其核心包括：1）全局上下文理解模块，解释图像并理解复杂医学指令，生成多模态中间标记；2）像素级接地模块，解码这些标记以生成精确分割掩码和文本响应。此外，我们发布了MedSeg-QA数据集，包含10,000多对图像-掩码和多轮对话，通过大语言模型自动标注并经医生审核。实验表明，MedSeg-R在多个基准测试中表现优异，实现了高分割精度，并能对医学图像进行可解释的文本分析。

</details>


### [310] [LLMs Are Not Yet Ready for Deepfake Image Detection](https://arxiv.org/abs/2506.10474)
**中文标题：大型语言模型尚未准备好用于深度伪造图像检测**

*Shahroz Tariq,David Nguyen,M. A. P. Chamikara,Tingmin Wu,Alsharif Abuadbba,Kristen Moore*

Main category: cs.CV

TL;DR: 研究评估了四种视觉语言模型（VLM）在深度伪造图像检测中的表现，发现它们虽能提供合理解释和检测表面异常，但尚不可靠作为独立检测系统。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的日益复杂对媒体完整性和公众信任构成挑战，而视觉语言模型（VLM）因其跨领域潜力引发了对其在深度伪造检测中应用的兴趣。

Method: 研究对四种VLM（ChatGPT、Claude、Gemini和Grok）进行了零样本评估，使用包含真实和伪造图像的基准数据集，评估其分类准确性和推理深度。

Result: VLM能生成合理解释并检测表面异常，但在独立检测中存在关键缺陷，如过度关注风格元素或易受误导性视觉模式（如复古美学）影响。

Conclusion: 尽管通用模型目前无法独立可靠地检测深度伪造，但其可解释性和上下文分析能力表明，它们可作为混合或人机协作检测框架的补充工具。

摘要: 深度伪造技术的日益复杂对媒体完整性和公众信任构成了重大挑战。与此同时，视觉语言模型（VLM）作为增强视觉推理能力的大型语言模型，在多个领域展现出潜力，引发了对其在深度伪造检测中应用的兴趣。本研究对四种主流VLM（ChatGPT、Claude、Gemini和Grok）进行了结构化零样本评估，重点关注三种主要深度伪造类型：换脸、重演和合成生成。通过精心构建的基准数据集（包含来自不同来源的真实和伪造图像），我们评估了每种模型的分类准确性和推理深度。分析表明，尽管VLM能生成连贯的解释并检测表面异常，但它们尚不可靠作为独立检测系统。我们指出了关键失败模式，例如过度关注风格元素或易受误导性视觉模式（如复古美学）影响。然而，VLM在可解释性和上下文分析方面表现出优势，表明其潜力可作为法医工作流程中人类专家的补充工具。这些发现表明，尽管通用模型目前缺乏自主检测深度伪造的可靠性，但它们有望成为混合或人机协作检测框架的重要组成部分。

</details>


### [311] [Sheet Music Benchmark: Standardized Optical Music Recognition Evaluation](https://arxiv.org/abs/2506.10488)
**中文标题：乐谱基准：标准化的光学音乐识别评估**

*Juan C. Martinez-Sevilla,Joan Cerveto-Serrano,Noelia Luna,Greg Chapman,Craig Sapp,David Rizo,Jorge Calvo-Zaragoza*

Main category: cs.CV

TL;DR: 本文介绍了Sheet Music Benchmark（SMB）数据集和OMR-NED评估指标，旨在标准化光学音乐识别（OMR）研究的评估方法。SMB包含685页多样化的乐谱，OMR-NED则提供细粒度的错误分析，填补了OMR评估领域的空白。


<details>
  <summary>Details</summary>
Motivation: 当前光学音乐识别（OMR）研究缺乏标准化的评估数据集和指标，难以进行客观比较。本文旨在填补这一空白，提供统一的数据集和评估方法。

Method: 1. 构建SMB数据集，包含685页多样化的乐谱（如单音、钢琴谱、四重奏等），使用Humdrum **kern格式编码。2. 提出OMR-NED评估指标，基于符号错误率（SER），提供对音符、符干、音高、变音记号等音乐元素的细粒度错误分析。

Result: SMB数据集和OMR-NED指标为OMR研究提供了标准化的评估工具。基线实验表明，OMR-NED能够清晰比较不同方法的性能，帮助识别最优OMR方法。

Conclusion: 本文通过SMB数据集和OMR-NED指标，解决了OMR研究中的评估标准化问题，为未来研究提供了可靠的基础。

摘要: 本文介绍了Sheet Music Benchmark（SMB），一个包含685页乐谱的数据集，专为光学音乐识别（OMR）研究设计。SMB涵盖了多样化的音乐类型，如单音、钢琴谱、四重奏等，均以Humdrum **kern格式编码。同时，我们提出了OMR标准化编辑距离（OMR-NED），这是一种专为评估OMR性能设计的新指标。OMR-NED基于广泛使用的符号错误率（SER），提供了对音符头、符干、音高、变音记号等关键音乐元素的细粒度错误分析。OMR-NED生成的数值分数便于清晰比较，帮助研究人员和终端用户识别最优OMR方法。我们的工作填补了OMR评估领域的长期空白，并通过基线实验验证了标准化SMB数据集在训练和评估先进方法中的实用性。

</details>


### [312] [Class-Incremental Learning for Honey Botanical Origin Classification with Hyperspectral Images: A Study with Continual Backpropagation](https://arxiv.org/abs/2506.10489)
**中文标题：基于持续反向传播的类增量学习在蜂蜜植物来源高光谱图像分类中的研究**

*Guyang Zhang,Waleed Abdulla*

Main category: cs.CV

TL;DR: 本研究提出了一种结合持续反向传播（CB）算法的类增量学习（CIL）方法，用于蜂蜜植物来源分类。CB通过重新初始化较少使用的隐藏神经元来提升模型性能，实验表明其将大多数CIL方法的性能提高了1-7%。


<details>
  <summary>Details</summary>
Motivation: 蜂蜜的植物来源决定了其风味和健康价值，因此准确区分蜂蜜的植物来源对保护消费者利益至关重要。然而，一次性收集所有蜂蜜品种以训练模型是不现实的，因此需要类增量学习技术来解决这一问题。

Method: 研究比较了多种CIL算法在真实蜂蜜高光谱成像数据集上的表现，并提出了一种结合持续反向传播（CB）的新技术。CB通过重新初始化较少使用的隐藏神经元来增加神经网络的变异性，从而解决损失可塑性问题。

Result: 实验表明，CB方法显著提升了大多数CIL算法的性能，改进幅度在1-7%之间。

Conclusion: 结合CB的CIL方法在蜂蜜植物来源分类任务中表现优异，为解决类增量学习中的损失可塑性问题提供了有效途径。

摘要: 蜂蜜是全球市场中的重要商品。不同植物来源的蜂蜜具有多样化的风味和健康益处，因此市场价值各异。开发准确有效的植物来源区分技术对保护消费者利益至关重要。然而，一次性收集所有蜂蜜品种以训练模型是不现实的。为此，研究人员开发了类增量学习（CIL）技术来解决这一挑战。本研究在真实蜂蜜高光谱成像数据集上比较了多种CIL算法，并提出了一种结合持续反向传播（CB）算法的新技术。CB方法通过重新初始化较少使用的隐藏神经元来增加神经网络的变异性，从而解决损失可塑性问题。实验表明，CB将大多数CIL方法的性能提高了1-7%。

</details>


### [313] [Semantic Localization Guiding Segment Anything Model For Reference Remote Sensing Image Segmentation](https://arxiv.org/abs/2506.10503)
**中文标题：语义定位引导的Segment Anything模型用于参考遥感图像分割**

*Shuyang Li,Shuang Wang,Zhuangzhuang Sun,Jing Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种名为PSLG-SAM的两阶段框架，用于解决参考遥感图像分割任务中的密集标注和复杂场景问题。通过粗定位和精细分割两阶段方法，结合视觉定位网络和增强的Segment Anything Model，显著减少了标注负担并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 参考遥感图像分割任务（RRSIS）需要基于文本描述生成分割掩码，但现有方法依赖多模态融合和密集标注，且难以处理复杂场景。本文旨在通过两阶段分解任务，减少标注负担并提升分割精度。

Method: 提出的PSLG-SAM框架分为粗定位和精细分割两阶段：1）粗定位阶段使用视觉定位网络粗略定位文本描述的目标；2）精细分割阶段通过聚类生成前景点并结合掩码边界迭代优化策略，指导增强的Segment Anything Model完成精确分割。第二阶段可无需训练，显著减少标注需求。

Result: 在两个数据集（RRSIS-D和RRSIS-M）上的实验表明，PSLG-SAM性能显著优于现有方法，同时减少了标注负担。

Conclusion: PSLG-SAM通过两阶段任务分解和增强的Segment Anything Model，有效解决了RRSIS任务中的密集标注和复杂场景问题，性能优于现有方法。

摘要: 参考遥感图像分割（RRSIS）任务基于文本描述生成图像中指定对象的分割掩码，引起了广泛关注和研究兴趣。当前的RRSIS方法依赖多模态融合主干和语义分割头，但面临密集标注需求和复杂场景解释等挑战。为解决这些问题，我们提出了一个名为“提示生成语义定位引导Segment Anything模型”（PSLG-SAM）的框架，将RRSIS任务分解为粗定位和精细分割两阶段。在粗定位阶段，视觉定位网络粗略定位文本描述的对象；在精细分割阶段，第一阶段生成的坐标通过基于聚类的前景点生成器和掩码边界迭代优化策略引导增强的Segment Anything Model（SAM）完成精确分割。值得注意的是，第二阶段可以无需训练，显著减轻了RRSIS任务的标注数据负担。此外，将RRSIS任务分解为两阶段允许专注于特定区域分割，避免复杂场景的干扰。我们还贡献了一个高质量、多类别的人工标注数据集。在两个数据集（RRSIS-D和RRSIS-M）上的实验验证表明，PSLG-SAM实现了显著的性能提升，并超越了现有的最先进模型。我们的代码将公开提供。

</details>


### [314] [J-DDL: Surface Damage Detection and Localization System for Fighter Aircraft](https://arxiv.org/abs/2506.10505)
**中文标题：J-DDL：战斗机表面损伤检测与定位系统**

*Jin Huang,Mingqiang Wei,Zikuan Li,Hangyu Qu,Wei Zhao,Xinyu Bai*

Main category: cs.CV

TL;DR: 本文提出了一种名为J-DDL的智能战斗机表面损伤检测与定位系统，结合2D图像和3D点云数据，通过优化的YOLO架构和新型损失函数实现高效检测，并公开了首个飞机损伤数据集。


<details>
  <summary>Details</summary>
Motivation: 战斗机表面损伤检测对安全和延长使用寿命至关重要，但传统人工检测方法在可扩展性、效率和一致性方面存在局限，亟需自动化解决方案。

Method: J-DDL系统结合激光扫描仪和相机捕获的2D图像与3D点云数据，采用优化的YOLO架构（包括轻量级Fasternet块、EMA模块和Inner-CIOU损失函数）进行损伤检测，并将结果映射到3D点云实现精确定位。

Result: 实验验证表明，J-DDL系统能够高效、准确地检测和定位战斗机表面损伤，显著提升检测覆盖范围和自动化水平。

Conclusion: J-DDL系统为战斗机表面损伤检测提供了高效、全面的自动化解决方案，并推动了该领域的研究进展。

摘要: 为确保战斗机的安全性和延长其使用寿命，需频繁进行全面的表面检查。尽管人工检测可发现表面缺陷，但由于飞机表面积大、结构复杂且维护需求高，传统方法在可扩展性、效率和一致性方面存在显著不足。本文提出了一种名为J-DDL的智能战斗机表面损伤检测与定位系统。J-DDL结合激光扫描仪和相机捕获的2D图像与3D点云数据，实现精确的损伤检测与定位。系统的核心是基于YOLO架构的新型损伤检测网络，专为2D飞机图像中的表面缺陷识别优化。关键创新包括：轻量级Fasternet块用于高效特征提取，优化的颈部架构结合高效多尺度注意力（EMA）模块以提升特征聚合能力，以及引入新型损失函数Inner-CIOU以提高检测精度。在2D图像中检测到损伤后，系统将异常映射到对应的3D点云上，实现飞机表面缺陷的精确3D定位。J-DDL不仅简化了检测流程，还确保了对大型复杂飞机外表面的全面覆盖。为推动该领域发展，我们还开发了首个公开的飞机损伤数据集。实验评估验证了框架的有效性，展示了其在推动自动化飞机检测技术方面的潜力。

</details>


### [315] [CogStream: Context-guided Streaming Video Question Answering](https://arxiv.org/abs/2506.10516)
**中文标题：CogStream：上下文引导的流媒体视频问答**

*Zicheng Zhao,Kangyu Wang,Shijie Li,Rui Qian,Weiyao Lin,Huabin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CogStream的流媒体视频问答任务，通过上下文引导模型识别关键历史信息，以减少计算负担并提升推理效率。同时，提出了一个密集标注的数据集和基线模型CogReasoner，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大型语言模型（Vid-LLMs）在处理流媒体视频推理时，依赖所有历史上下文信息，导致计算负担大且容易受到无关信息的干扰。本文旨在解决这一问题，提出更高效的任务和方法。

Method: 本文提出了CogStream任务，模拟真实流媒体视频场景，要求模型识别最相关的历史上下文信息。同时，提出了一个半自动生成的数据集和基线模型CogReasoner，该模型通过视觉流压缩和历史对话检索高效完成任务。

Result: 实验证明，CogReasoner在CogStream任务中表现优异，能够有效减少计算负担并提升推理效率。

Conclusion: CogStream任务和CogReasoner模型为解决流媒体视频推理中的上下文依赖问题提供了有效方案，未来代码将公开。

摘要: 尽管视频大型语言模型（Vid-LLMs）在多模态理解方面取得了进展，但由于其对上下文信息的依赖，流媒体视频推理仍面临挑战。现有范式将所有可用的历史上下文信息输入Vid-LLMs，导致视觉数据处理的计算负担显著增加。此外，无关上下文的引入会分散模型对关键细节的注意力。本文提出了一项名为“上下文引导的流媒体视频推理”（CogStream）的挑战性任务，模拟真实流媒体视频场景，要求模型识别最相关的历史上下文信息以推断当前流的问题答案。为支持CogStream，我们提供了一个密集标注的数据集，包含广泛且分层次的问题-答案对，通过半自动流程生成。此外，我们提出了基线模型CogReasoner，通过视觉流压缩和历史对话检索高效完成任务。大量实验证明了该方法的有效性。代码即将发布。

</details>


### [316] [Multimodal Cinematic Video Synthesis Using Text-to-Image and Audio Generation Models](https://arxiv.org/abs/2506.10005)
**中文标题：基于文本到图像和音频生成模型的多模态电影视频合成**

*Sridhar S,Nithin A,Shakeel Rifath,Vasantha Raj*

Main category: cs.CV

TL;DR: 本文提出了一种结合文本到图像和音频生成模型的多模态电影视频合成方法，通过Stable Diffusion、GPT-2和混合音频管道生成60秒高质量电影视频，并展示了其在创意、教育和工业应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能的发展，多媒体创作方式发生了变革。本文旨在通过结合文本到图像和音频生成模型，实现自动化的高质量电影视频合成，以满足创意、教育和工业领域的需求。

Method: 方法包括：1) 使用Stable Diffusion进行高保真图像合成；2) 利用GPT-2构建叙事结构；3) 结合gTTS和YouTube音乐构建混合音频管道；4) 采用五场景框架，并通过线性帧插值、电影级后处理和音视频同步提升质量。系统在GPU加速的Google Colab环境中运行，支持1024x768分辨率和15-30 FPS帧率。

Result: 实验结果表明，该方法在视觉质量、叙事连贯性和效率方面表现优异，进一步推动了文本到视频合成技术在创意、教育和工业领域的应用。

Conclusion: 本文提出的多模态电影视频合成方法展示了生成式人工智能在多媒体创作中的潜力，为未来研究提供了新的方向。

摘要: 生成式人工智能的进步改变了多媒体创作方式，使得从文本输入自动合成电影视频成为可能。本研究提出了一种生成60秒电影视频的方法，结合了Stable Diffusion的高保真图像合成、GPT-2的叙事结构构建，以及基于gTTS和YouTube音乐的混合音频管道。通过五场景框架、线性帧插值、电影级后处理（如锐化）和音视频同步，实现了专业级质量。系统在GPU加速的Google Colab环境中使用Python 3.11开发，提供双模式Gradio界面（简单和高级），支持最高1024x768分辨率和15-30 FPS帧率。通过CUDA内存管理和错误处理等优化确保了可靠性。实验展示了出色的视觉质量、叙事连贯性和效率，进一步推动了文本到视频合成在创意、教育和工业领域的应用。

</details>


### [317] [LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning](https://arxiv.org/abs/2506.10082)
**中文标题：LoRA-Edit：基于掩码感知LoRA微调的可控第一帧引导视频编辑**

*Chenjian Gao,Lihe Ding,Xin Cai,Zhanpeng Huang,Zibin Wang,Tianfan Xue*

Main category: cs.CV

TL;DR: 本文提出了一种基于掩码感知的LoRA微调方法（LoRA-Edit），用于可控的第一帧引导视频编辑，通过动态调整模型关注区域实现灵活编辑，同时保留背景内容。


<details>
  <summary>Details</summary>
Motivation: 当前视频编辑方法依赖大规模预训练，缺乏灵活性，且第一帧引导方法对后续帧控制不足。本文旨在解决这一问题，提供更灵活的视频编辑方案。

Method: 采用掩码驱动的LoRA微调策略，结合输入视频的空间结构和参考图像的外观指导，动态调整模型学习区域，实现可控编辑。

Result: 实验表明，该方法在视频编辑性能上优于现有先进方法。

Conclusion: LoRA-Edit提供了一种高效、灵活的视频编辑方法，无需改变模型架构即可实现高质量编辑。

摘要: 基于扩散模型的视频编辑在生成高质量编辑结果方面取得了显著成果。然而，现有方法通常依赖大规模预训练，限制了特定编辑的灵活性。第一帧引导编辑提供了对第一帧的控制，但对后续帧的灵活性不足。为此，我们提出了一种基于掩码的LoRA（低秩适应）微调方法，用于适配预训练的图像到视频（I2V）模型，实现灵活的视频编辑。我们的方法在保留背景区域的同时，实现了可控的编辑传播。这一解决方案提供了高效且适应性强的视频编辑，而无需改变模型架构。为了更好地引导这一过程，我们引入了额外的参考（如替代视角或代表性场景状态），作为内容展开的视觉锚点。我们通过掩码驱动的LoRA微调策略解决了控制问题，该策略将预训练的图像到视频模型适配到编辑上下文中。模型需要从两个不同的来源学习：输入视频提供空间结构和运动线索，而参考图像提供外观指导。空间掩码通过动态调整模型的关注区域实现特定区域的学习，确保每个区域从适当的来源获取信息。实验结果表明，我们的方法在视频编辑性能上优于现有先进方法。

</details>


### [318] [DeepTraverse: A Depth-First Search Inspired Network for Algorithmic Visual Understanding](https://arxiv.org/abs/2506.10084)
**中文标题：DeepTraverse：一种受深度优先搜索启发的算法视觉理解网络**

*Bin Guo,John H. L. Hansen*

Main category: cs.CV

TL;DR: DeepTraverse是一种受深度优先搜索启发的视觉架构，通过递归探索和自适应校准模块，实现了高效且结构化的特征学习，在图像分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统视觉主干网络的特征构建过程较为单一，缺乏自适应迭代优化的显式路径。本文探索是否可以通过经典搜索算法的原则，为网络注入更结构化、逻辑化的处理流程，从而提升特征的可解释性和性能。

Method: DeepTraverse包含两个关键组件：递归探索模块（通过参数共享深化特征分析）和自适应校准模块（动态调整特征显著性）。这种算法化的交互使网络能够智能地构建和优化特征模式。

Result: 在多个图像分类基准测试中，DeepTraverse表现出色，分类准确性和特征区分能力优于传统模型，且参数量相当或更少。

Conclusion: 研究表明，将算法先验整合到视觉主干网络中，是一种高效、高性能且结构化的有效策略。

摘要: 尽管传统视觉主干网络取得了成功，但其特征构建过程通常通过一系列较为单一的操作完成，缺乏自适应迭代优化的显式路径。这引发了一个引人深思的问题：经典搜索算法的原则能否为这些网络注入更算法化、结构化和逻辑化的处理流程，从而通过更可解释（甚至类似推理）的决策过程构建特征表示？我们提出了DeepTraverse，这是一种直接受算法搜索策略启发的新型视觉架构，使其能够通过与传统方法不同的系统性阐明和自适应优化过程学习特征。DeepTraverse通过两个关键协同组件实现这一点：递归探索模块（通过参数共享沿着有前景的表示路径深化特征分析）和自适应校准模块（基于全局上下文动态调整特征显著性）。这种算法化的交互使DeepTraverse能够智能地构建和优化特征模式。在多样化的图像分类基准测试中，DeepTraverse表现出色，分类准确性和特征区分能力优于传统模型，且参数量相当或更少。我们的研究表明，整合此类算法先验为构建更高效、高性能和结构化的视觉主干网络提供了一种原则性且有效的策略。

</details>


### [319] [Test-Time Adaptation for Generalizable Task Progress Estimation](https://arxiv.org/abs/2506.10085)
**中文标题：可泛化任务进度估计的测试时自适应方法**

*Christos Ziakas,Alessandra Russo*

Main category: cs.CV

TL;DR: 本文提出了一种测试时自适应方法，通过优化自监督目标，使进度估计模型能够在线适应测试轨迹的视觉和时间上下文。该方法通过基于梯度的元学习策略训练模型，利用专家视觉轨迹和自然语言任务描述，提高基于语义内容而非时间顺序的进度估计。该方法在多样化的分布外任务、环境和体现中表现出色，优于当前最先进的上下文学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有进度估计模型在分布外任务、环境和体现中泛化能力有限，无法有效适应测试时的视觉和时间上下文。本文旨在通过测试时自适应方法，提升模型在这些场景下的泛化能力。

Method: 提出了一种基于梯度的元学习策略，利用专家视觉轨迹和自然语言任务描述训练模型，使其在测试时通过优化自监督目标自适应调整，从而更依赖语义内容而非时间顺序进行进度估计。

Result: 该方法在多样化的分布外任务、环境和体现中表现出色，优于基于自回归视觉语言模型的当前最先进上下文学习方法。

Conclusion: 本文提出的测试时自适应方法显著提升了进度估计模型在分布外场景中的泛化能力，为任务进度估计的通用性提供了有效解决方案。

摘要: 我们提出了一种测试时自适应方法，使进度估计模型能够通过优化学习的自监督目标，在线适应测试轨迹的视觉和时间上下文。为此，我们引入了一种基于梯度的元学习策略，利用专家视觉轨迹及其自然语言任务描述训练模型，使得测试时自适应能够提高基于语义内容而非时间顺序的进度估计。我们的测试时自适应方法从单一训练环境泛化到多样化的分布外任务、环境和体现，优于当前最先进的基于自回归视觉语言模型的上下文学习方法。

</details>


### [320] [EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models](https://arxiv.org/abs/2506.10100)
**中文标题：EfficientVLA：无需训练的视觉-语言-动作模型加速与压缩方法**

*Yantai Yang,Yuhao Wang,Zichen Wen,Luo Zhongwei,Chang Zou,Zhipeng Zhang,Chuan Wen,Linfeng Zhang*

Main category: cs.CV

TL;DR: EfficientVLA是一种无需训练的高效推理加速框架，通过系统性消除视觉-语言-动作（VLA）模型中的冗余，显著提升了计算效率和内存利用率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型（尤其是基于扩散的架构）在计算和内存需求上存在严重冗余，限制了实际部署的可行性。现有加速方法多为局部优化，未能全面解决整个VLA流程中的瓶颈问题。

Method: EfficientVLA通过三种策略系统性消除冗余：(1) 基于层间冗余分析修剪语言模块中功能无关的层；(2) 通过任务感知策略优化视觉处理路径，选择紧凑且多样化的视觉标记；(3) 在基于扩散的动作头中缓存和重用关键中间特征以减少时间冗余。

Result: 在标准VLA模型CogACT上应用EfficientVLA，推理速度提升1.93倍，计算量（FLOPs）降至28.9%，且在SIMPLER基准测试中成功率仅下降0.6%。

Conclusion: EfficientVLA通过系统性消除冗余，显著提升了VLA模型的推理效率和实用性，为实际部署提供了可行方案。

摘要: 视觉-语言-动作（VLA）模型，尤其是基于扩散的架构，在具身智能领域展现出变革性潜力，但其高计算和内存需求严重阻碍了实际应用。这些需求源于模型内部和推理过程中广泛存在的冗余。现有加速方法通常针对局部低效问题，此类零散解决方案难以全面解决整个VLA流程中的计算和内存瓶颈，从而限制了实际部署的可行性。我们提出EfficientVLA，一种结构化且无需训练的推理加速框架，通过系统性消除多方面的冗余来解决这些问题。EfficientVLA协同整合了三种针对性策略：(1) 基于层间冗余分析修剪语言模块中功能无关的层；(2) 通过任务感知策略优化视觉处理路径，选择紧凑且多样化的视觉标记，平衡任务关键性与信息覆盖；(3) 在基于扩散的动作头中缓存和重用关键中间特征，以减少时间计算冗余。我们将该方法应用于标准VLA模型CogACT，实现了1.93倍的推理加速，计算量（FLOPs）降至28.9%，且在SIMPLER基准测试中成功率仅下降0.6%。

</details>


### [321] [A Manually Annotated Image-Caption Dataset for Detecting Children in the Wild](https://arxiv.org/abs/2506.10117)
**中文标题：用于检测野外儿童的手动标注图像-字幕数据集**

*Klim Kireev,Ana-Maria Creţu,Raphael Meier,Sarah Adel Bargal,Elissa Redmiles,Carmela Troncoso*

Main category: cs.CV

TL;DR: 本文发布了一个名为ICCWD的多模态图像-字幕数据集，用于检测未成年人，填补了现有数据集的空白，并测试了三种检测器的性能，最佳方法的真阳性率为75.3%。


<details>
  <summary>Details</summary>
Motivation: 由于数字平台和法律对未成年人内容的监管需求，现有工具缺乏多模态环境下的未成年人检测数据集，因此作者旨在填补这一空白。

Method: 作者构建了包含10,000张图像-字幕对的ICCWD数据集，手动标注图像中是否包含未成年人，并测试了三种检测器（包括商业年龄估计系统）的性能。

Result: 实验结果表明，未成年人检测是一项具有挑战性的任务，最佳方法的真阳性率为75.3%。

Conclusion: ICCWD数据集的发布有望帮助设计更优的未成年人检测方法，适用于多种场景。

摘要: 数字平台和法律对未成年人（定义为18岁以下个体）内容的监管与其他类型内容不同。鉴于需要评估的内容量巨大，通常使用基于机器学习的自动化工具来检测未成年人内容。据我们所知，目前尚无用于多模态环境中检测这些识别方法的数据集或基准。为填补这一空白，我们发布了图像-字幕野外儿童数据集（ICCWD），旨在为检测未成年人内容的工具提供基准。我们的数据集比以往的儿童图像数据集更丰富，包含多种情境下的儿童图像，包括虚构描绘和部分可见的身体。ICCWD包含10,000个手动标注的图像-字幕对，用于指示图像中是否存在儿童。为展示数据集的潜在用途，我们用它测试了三种不同的检测器，包括应用于图像的商业年龄估计系统。结果表明，未成年人检测是一项具有挑战性的任务，最佳方法的真阳性率为75.3%。我们希望数据集的发布将有助于设计更优的未成年人检测方法，适用于多种场景。

</details>


### [322] [Detecção da Psoríase Utilizando Visão Computacional: Uma Abordagem Comparativa Entre CNNs e Vision Transformers](https://arxiv.org/abs/2506.10119)
**中文标题：使用计算机视觉检测银屑病：CNN与视觉变换器的对比研究**

*Natanael Lucena,Fábio S. da Silva,Ricardo Rios*

Main category: cs.CV

TL;DR: 本文比较了卷积神经网络（CNN）和视觉变换器（ViT）在银屑病及类似皮肤病图像多分类任务中的表现，发现ViT在小模型上表现更优，其中DaViT-B以96.4%的F1分数成为最佳模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索CNN和ViT在医学图像分类任务中的性能差异，尤其是针对银屑病及其类似疾病的自动检测。

Method: 方法包括使用在ImageNet上预训练的CNN和ViT模型，并针对特定数据集进行微调，比较其多分类性能。

Result: 结果显示，ViT模型在小规模下表现更优，其中DaViT-B以96.4%的F1分数成为最佳模型。

Conclusion: 结论指出ViT在医学图像分类任务中具有潜力，尤其是DaViT-B架构在银屑病检测中表现高效。

摘要: 本文比较了卷积神经网络（CNN）和视觉变换器（ViT）在银屑病及类似皮肤病图像多分类任务中的表现。基于ImageNet预训练的模型被适配到特定数据集上。两种模型均取得了较高的预测指标，但ViT在小模型上表现更优。其中，双注意力视觉变换器基础版（DaViT-B）以96.4%的F1分数取得了最佳结果，被推荐为银屑病自动检测的最有效架构。本文进一步验证了ViT在医学图像分类任务中的潜力。

</details>


### [323] [ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs](https://arxiv.org/abs/2506.10128)
**中文标题：ViCrit：一种用于视觉语言模型视觉感知的可验证强化学习代理任务**

*Xiyao Wang,Zhengyuan Yang,Chao Feng,Yongyuan Liang,Yuhang Zhou,Xiaoyu Liu,Ziyi Zang,Ming Li,Chung-Ching Lin,Kevin Lin,Linjie Li,Furong Huang,Lijuan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为ViCrit的强化学习代理任务，用于提升视觉语言模型（VLMs）的视觉感知能力。通过注入细微的视觉描述错误并让模型定位错误，ViCrit在保持感知难度的同时提供了明确的奖励信号，显著提升了模型在多种视觉语言任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在语言模型的微调中表现出色，但在视觉语言模型的视觉感知任务中缺乏既具挑战性又可明确验证的任务。ViCrit旨在填补这一空白，通过设计一种可验证的视觉感知任务来提升模型的感知能力。

Method: ViCrit通过向人类撰写的图像描述中注入细微的视觉描述错误（如对象、属性、数量或空间关系的错误），并训练模型根据图像和修改后的描述定位错误。这种方法保留了感知的难度，同时提供了易于计算的二元奖励信号。

Result: 实验表明，使用ViCrit训练的模型在多种视觉语言基准测试中表现显著提升，且这种提升能够迁移到抽象图像推理和视觉数学等任务中，表明模型学会了感知而非仅记忆对象。

Conclusion: ViCrit是一种有效且通用的方法，通过细粒度的幻觉批评任务显著提升了视觉语言模型的视觉感知能力。

摘要: 强化学习（RL）在通过具有挑战性且易于验证的任务（如数学推理或代码生成）微调大型语言模型（LLMs）方面表现出色。然而，将这一成功扩展到视觉语言模型（VLMs）的视觉感知任务中，却因缺乏既具挑战性又可明确验证的视觉中心任务而受阻。为此，我们提出了ViCrit（视觉描述幻觉批评器），这是一种RL代理任务，训练VLMs定位注入人类撰写图像描述中的细微合成视觉幻觉。我们从200字的描述开始，注入一个细微的视觉描述错误（如对象、属性、数量或空间关系的错误），并让模型根据图像和修改后的描述定位错误段落。这种设计保留了完整的感知难度，同时提供了易于计算的二元精确匹配奖励。使用ViCrit任务训练的模型在多种VL基准测试中表现出显著提升。重要的是，这种提升能够迁移到自然图像训练数据之外的抽象图像推理和视觉数学任务中，显示出模型学会了感知而非仅记忆所见对象。为便于评估，我们还提出了ViCrit-Bench，这是一个类别平衡的诊断基准，系统性地探测了跨多样图像领域和错误类型的感知错误。总之，我们的结果表明，细粒度的幻觉批评是提升VLMs视觉感知能力的一种有效且通用的目标。

</details>


### [324] [RoCA: Robust Cross-Domain End-to-End Autonomous Driving](https://arxiv.org/abs/2506.10145)
**中文标题：RoCA：鲁棒的跨域端到端自动驾驶框架**

*Rajeev Yasarla,Shizhong Han,Hsin-Pai Cheng,Litian Liu,Shweta Mahajan,Apratim Bhattacharyya,Yunxiao Shi,Risheek Garrepalli,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: RoCA是一种用于跨域端到端自动驾驶的鲁棒框架，通过联合概率分布建模和基标记学习，提升模型的泛化能力和适应能力，无需额外推理计算。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶研究较少关注跨域部署的实际挑战，且现有方法依赖大型语言模型（LLMs）可能导致高昂的重新训练成本。RoCA旨在解决这些问题，提供一种鲁棒的跨域解决方案。

Method: RoCA通过联合概率分布建模自车和周围车辆信息的标记，利用高斯过程（GP）学习基标记及其对应轨迹，从而覆盖多样驾驶场景。在给定驾驶场景时，RoCA能概率推断未来轨迹，并与基础端到端模型结合，提升泛化能力。

Result: RoCA在多种跨域场景中表现出色，显著优于直接微调方法，实现了强大的域泛化和适应性能。

Conclusion: RoCA为跨域端到端自动驾驶提供了一种高效且鲁棒的解决方案，显著提升了模型的泛化能力和适应能力。

摘要: 端到端（E2E）自动驾驶作为一种新兴范式，展现出巨大潜力。然而，目前很少有研究关注跨域（如不同城市）部署的实际挑战。尽管已有工作尝试利用大型语言模型（LLMs）的开放世界知识，但LLMs无法保证跨域驾驶性能，且可能导致高昂的域适应重新训练成本。本文提出RoCA，一种鲁棒的跨域E2E自动驾驶框架。RoCA通过联合概率分布建模E2E流程中编码自车和周围车辆信息的标记，并基于高斯过程（GP）学习一组基标记及其对应轨迹，覆盖多样驾驶场景。给定任意驾驶场景，RoCA能概率推断未来轨迹。通过将RoCA与基础E2E模型结合进行源域训练，RoCA提升了基础模型的泛化能力，且无需额外推理计算。此外，RoCA在目标域上的鲁棒适应能力显著优于直接微调方法。我们在多种跨域场景中广泛评估RoCA，结果表明其具备强大的域泛化和适应性能。

</details>


### [325] [SPARKE: Scalable Prompt-Aware Diversity Guidance in Diffusion Models via RKE Score](https://arxiv.org/abs/2506.10173)
**中文标题：SPARKE：基于RKE分数的可扩展提示感知多样性引导方法**

*Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia*

Main category: cs.CV

TL;DR: 本文提出了一种名为SPARKE的方法，用于在扩散模型中实现基于提示的多样性引导，通过条件熵动态测量多样性并降低计算复杂度，从而在不显著增加计算成本的情况下提升生成数据的多样性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在高质量图像合成和提示引导生成方面表现出色，但在确保生成样本多样性方面仍面临挑战，尤其是当提示涉及广泛语义范围时。现有方法通过多样性度量进行引导，但计算复杂度高，难以大规模应用。

Method: SPARKE方法利用条件熵进行多样性引导，动态地将多样性测量与相似提示关联，并通过条件潜在RKE分数引导将计算复杂度从O(n^3)降低到O(n)，从而支持大规模生成。

Result: 实验表明，SPARKE方法在多个文本到图像扩散模型中显著提升了生成数据的提示感知多样性，同时未显著增加计算成本。

Conclusion: SPARKE方法通过降低计算复杂度，实现了高效的提示感知多样性引导，为扩散模型的多样性生成提供了可行的解决方案。

摘要: 扩散模型在高保真图像合成和提示引导生成建模中取得了显著成功。然而，确保提示引导扩散模型中生成样本的足够多样性仍然是一个挑战，尤其是当提示涉及广泛的语义范围且需要在语义相似的提示之间以提示感知方式评估生成数据的多样性时。最近的方法通过多样性度量引入引导以鼓励更多样化的生成。本文扩展了基于多样性度量的方法，提出了可扩展的提示感知Rényi核熵多样性引导（SPARKE）方法。SPARKE利用条件熵进行多样性引导，动态地将多样性测量与相似提示关联，并实现提示感知的多样性控制。尽管基于熵的引导方法增强了提示感知多样性，但其对基于矩阵的熵分数的依赖在大规模生成场景中带来了计算挑战。为解决这一问题，我们专注于条件潜在RKE分数引导的特殊情况，将熵计算和基于梯度的优化复杂度从一般熵度量的O(n^3)降低到O(n)。降低的计算复杂度允许在数千个不同提示的生成轮次中进行多样性引导采样。我们在多个文本到图像扩散模型上对SPARKE方法进行了数值测试，结果表明该方法在不显著增加计算成本的情况下提升了生成数据的提示感知多样性。代码已在项目页面发布：https://mjalali.github.io/SPARKE

</details>


### [326] [Retrieval of Surface Solar Radiation through Implicit Albedo Recovery from Temporal Context](https://arxiv.org/abs/2506.10174)
**中文标题：通过时间上下文隐式反照率恢复的地表太阳辐射反演**

*Yael Frischholz,Devis Tuia,Michael Lehning*

Main category: cs.CV

TL;DR: 本文提出了一种基于注意力机制的模拟器，用于从卫星图像序列中隐式学习晴空地表反射率，以准确估算地表太阳辐射（SSR）。该方法在复杂地形和动态积雪区域表现优异，无需手工特征（如反照率图或云掩膜）。


<details>
  <summary>Details</summary>
Motivation: 传统的地表太阳辐射（SSR）估算方法依赖月统计量近似背景反射率，但在山区因间歇性积雪和动态地表变化而失效。本文旨在解决这一问题，提出一种无需显式反照率图或云掩膜的新方法。

Method: 基于Temporo-Spatial Vision Transformer，构建了一个注意力机制模拟器，通过卫星图像序列隐式学习晴空地表反射率。输入包括多光谱SEVIRI图像、静态地形特征和太阳几何信息，目标变量为HelioMont算法的SSR估算值。

Result: 实验表明，该方法在提供足够长的时间上下文时，性能与依赖反照率信息的模型相当，尤其在山区表现突出，并能提升简单和复杂地形下的泛化能力。

Conclusion: 该方法通过隐式学习地表反射率动态，显著提升了SSR估算的准确性，尤其在复杂地形和动态积雪区域效果显著，为卫星遥感提供了新思路。

摘要: 从卫星图像中准确反演地表太阳辐射（SSR）的关键在于估算晴空条件下的背景反射率。传统算法通常基于月统计量近似背景反射率，但这种方法在山区因间歇性积雪和动态地表变化而失效。本文提出了一种基于注意力机制的模拟器，通过卫星图像序列隐式学习晴空地表反射率，无需手工特征（如反照率图或云掩膜）。该方法基于Temporo-Spatial Vision Transformer，输入包括多光谱SEVIRI图像、静态地形特征和太阳几何信息，目标变量为HelioMont算法的SSR估算值。实验表明，在提供足够长的时间上下文时，该模型性能与依赖反照率信息的模型相当，尤其在山区表现突出，并能提升简单和复杂地形下的泛化能力。代码和数据集已公开。

</details>


### [327] [Attention, Please! Revisiting Attentive Probing for Masked Image Modeling](https://arxiv.org/abs/2506.10178)
**中文标题：请注意！重新审视注意力探针在掩码图像建模中的应用**

*Bill Psomas,Dionysis Christopoulos,Eirini Baltzi,Ioannis Kakogeorgiou,Tilemachos Aravanis,Nikos Komodakis,Konstantinos Karantzalos,Yannis Avrithis,Giorgos Tolias*

Main category: cs.CV

TL;DR: 本文重新审视了注意力探针方法在掩码图像建模中的应用，提出了一种高效探针（EP）机制，通过多查询交叉注意力减少冗余参数，显著提升了计算效率和性能。


<details>
  <summary>Details</summary>
Motivation: 随着微调在大规模应用中变得不切实际，探针成为自监督学习的首选评估方法。然而，传统的线性探针（LP）无法充分反映掩码图像建模（MIM）的潜力，因此需要注意力探针方法。现有方法存在参数过多和计算效率低的问题，本文旨在解决这些问题。

Method: 本文引入高效探针（EP），采用多查询交叉注意力机制，消除冗余投影，减少可训练参数数量，并实现比传统多头注意力快10倍的速度。

Result: EP在七个基准测试中优于LP和先前的注意力探针方法，泛化能力强，适用于多种预训练范式，生成可解释的注意力图，并在低样本和分层设置中表现优异。

Conclusion: 高效探针（EP）在性能和效率上均优于现有方法，为掩码图像建模提供了一种更优的评估工具。

摘要: 随着微调（FT）在大规模应用中变得不切实际，探针逐渐成为自监督学习（SSL）的首选评估协议。然而，标准的线性探针（LP）由于补丁标记的分布式特性，无法充分反映掩码图像建模（MIM）的潜力。这促使了对注意力探针的需求，该方法通过注意力选择性地聚合补丁级特征。尽管其应用日益广泛，注意力探针仍未被充分研究，现有方法存在参数过多和计算效率低的问题。
  本文从准确性与效率权衡的角度重新审视注意力探针。我们对现有方法进行了系统性研究，分析其机制并对其性能进行基准测试。我们提出了高效探针（EP），一种多查询交叉注意力机制，消除了冗余投影，减少了可训练参数数量，并实现了比传统多头注意力快10倍的速度。尽管方法简单，EP在七个基准测试中优于LP和先前的注意力探针方法，泛化能力强，适用于多种预训练范式，生成可解释的注意力图，并在低样本和分层设置中表现出色。代码发布于https://github.com/billpsomas/efficient-probing。

</details>


### [328] [Improving Personalized Search with Regularized Low-Rank Parameter Updates](https://arxiv.org/abs/2506.10182)
**中文标题：通过正则化低秩参数更新改进个性化搜索**

*Fiona Ryan,Josef Sivic,Fabian Caba Heilbron,Judy Hoffman,James M. Rehg,Bryan Russell*

Main category: cs.CV

TL;DR: 本文提出了一种通过正则化低秩参数更新改进个性化搜索的方法，在个性化视觉语言检索任务中表现优异，显著提升了检索准确率。


<details>
  <summary>Details</summary>
Motivation: 个性化视觉语言检索任务需要从少量示例中学习新概念（如“我的狗Fido”），同时将个人知识与通用知识结合以识别不同上下文中的概念。现有方法在保留通用知识方面存在不足，因此本文旨在解决这一问题。

Method: 通过正则化低秩适应方法调整语言编码器最后一层的少量参数，替代文本反转技术，有效识别个人概念并保留通用知识。此外，探索了多个人概念参数的组合策略，发现参数相加效果最佳。引入基于视觉语言模型生成标题的图像检索准确率指标评估通用知识保留情况。

Result: 在DeepFashion2和ConCon-Chi两个个性化图像检索基准测试中，本文方法实现了最先进的准确率，比现有方法提升了4%-22%。

Conclusion: 正则化低秩参数更新是一种高效且通用的方法，能够在个性化视觉语言检索任务中显著提升性能，同时保留通用知识。

摘要: 个性化视觉语言检索任务旨在从少量示例中识别新概念（如“我的狗Fido”）。这一任务具有挑战性，因为它不仅需要从少量图像中学习新概念，还需要将个人知识与通用知识结合以识别不同上下文中的概念。本文展示了如何有效调整视觉语言双编码器模型的内部表示以用于个性化视觉语言检索。我们发现，对语言编码器最后一层的少量参数进行正则化低秩适应，是一种高效替代文本反转的方法，既能识别个人概念，又能保留通用知识。此外，我们探索了多个人概念参数的组合策略，发现参数相加效果显著。为了评估微调表示中通用知识的保留情况，我们引入了一种基于视觉语言模型生成标题的图像检索准确率指标。我们的方法在DeepFashion2和ConCon-Chi两个个性化图像检索基准测试中实现了最先进的准确率，比现有方法提升了4%-22%。

</details>


### [329] [ScoreMix: Improving Face Recognition via Score Composition in Diffusion Generators](https://arxiv.org/abs/2506.10226)
**中文标题：ScoreMix：通过扩散生成器中的分数组合提升人脸识别性能**

*Parsa Rahimi,Sebastien Marcel*

Main category: cs.CV

TL;DR: ScoreMix是一种基于扩散模型的数据增强方法，通过混合不同类别的分数生成具有挑战性的合成样本，显著提升判别器性能，尤其在数据有限的情况下表现突出。


<details>
  <summary>Details</summary>
Motivation: 在有限标注数据的场景下，如何提升判别器的性能是一个关键问题。本文提出ScoreMix，利用扩散模型的分数组合特性生成更具挑战性的合成样本，以增强判别器的判别能力。

Method: ScoreMix通过在扩散采样过程中凸组合不同类别条件下的分数，生成合成样本。研究发现，选择判别器嵌入空间中距离较远的类别进行混合，能够带来更大的性能提升。

Result: ScoreMix在所有测试基准中显著提升了判别器的性能，且无需大量参数搜索。实验表明，生成器的条件空间与判别器的嵌入空间相关性较低。

Conclusion: ScoreMix是一种简单有效的数据增强方法，能够显著提升判别器的性能，同时减少对大规模数据集的依赖，具有实际应用价值。

摘要: 本文提出ScoreMix，一种新颖而简单的数据增强策略，利用扩散模型的分数组合特性来提升判别器的性能，尤其是在标注数据有限的场景下。通过在扩散采样过程中凸组合不同类别条件下的分数，我们生成了具有挑战性的合成样本，显著提升了所有测试基准中的判别能力。我们系统地研究了混合的类别选择策略，发现当组合判别器嵌入空间中距离较远的类别时，性能提升更为显著。此外，实验表明，在标准指标下，生成器的条件空间与判别器的嵌入空间之间的相关性较低。我们的方法无需大量参数搜索即可实现显著的性能提升，为训练判别模型提供了实际优势，同时有效缓解了大规模数据集收集的问题。论文网站：https://parsa-ra.github.io/scoremix

</details>


### [330] [California Crop Yield Benchmark: Combining Satellite Image, Climate, Evapotranspiration, and Soil Data Layers for County-Level Yield Forecasting of Over 70 Crops](https://arxiv.org/abs/2506.10228)
**中文标题：加州作物产量基准：结合卫星图像、气候、蒸散发和土壤数据层，实现70多种作物的县级产量预测**

*Hamid Kamangir,Mona Hajiesmaeeli,Mason Earles*

Main category: cs.CV

TL;DR: 加州农业产量预测：结合卫星图像、气候、蒸散发和土壤数据，为70多种作物建立县级产量预测模型，整体R2得分0.76。


<details>
  <summary>Details</summary>
Motivation: 加州是全球农业领导者，但复杂的多因素影响使得准确预测作物产量具有挑战性。本研究旨在整合多源数据，建立高精度的县级作物产量预测模型。

Method: 结合Landsat卫星图像、气候记录、蒸散发数据和土壤属性，开发多模态深度学习模型，采用分层特征提取和时间序列编码捕捉生长季动态。

Result: 模型在未见测试数据上整体R2得分为0.76，表现优异，适用于加州多样化的农业区域。

Conclusion: 该基准数据集和模型框架为农业预测、气候适应和精准农业提供了重要基础，数据和代码已公开。

摘要: 加州是全球农业生产的领导者，占美国总产量的12.5%，是全球第五大食品和棉花供应地。尽管美国农业部国家农业统计服务提供了大量历史产量数据，但由于环境、气候和土壤因素的复杂相互作用，准确及时的作物产量预测仍具挑战性。本研究引入了一个全面的作物产量基准数据集，涵盖2008年至2022年加州所有县的70多种作物。该基准整合了多种数据源，包括Landsat卫星图像、每日气候记录、每月蒸散发数据和高分辨率土壤属性。为有效学习这些异构输入，我们开发了一种多模态深度学习模型，专为县级、作物特异性产量预测设计。该模型采用分层特征提取和时间序列编码，捕捉生长季的空间和时间动态。土壤特性和作物身份等静态输入则用于长期变异性分析。我们的方法在未见测试数据上对所有作物的整体R2得分为0.76，表明在加州多样化农业区域具有强大的预测性能。这一基准和建模框架为推进农业预测、气候适应和精准农业提供了宝贵基础。完整数据集和代码库已在GitHub仓库公开。

</details>


### [331] [DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos](https://arxiv.org/abs/2506.10242)
**中文标题：DySS：基于动态查询和状态空间学习的高效多摄像头视频3D物体检测**

*Rajeev Yasarla,Shizhong Han,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: DySS提出了一种基于状态空间学习和动态查询的高效3D物体检测方法，通过动态更新查询和辅助任务优化，实现了高性能和实时推理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于稀疏查询的3D物体检测方法在处理多帧视频时计算成本高，DySS旨在通过状态空间学习和动态查询优化解决这一问题。

Method: DySS利用状态空间模型（SSM）逐步处理时间步长的特征，并通过未来预测和掩码重建等辅助任务优化SSM。动态查询通过合并、删除和拆分操作更新，保持高效的检测查询集。

Result: 在nuScenes测试集上，DySS达到65.31 NDS和57.4 mAP，优于最新方法；在验证集上达到56.2 NDS和46.2 mAP，推理速度为33 FPS。

Conclusion: DySS通过状态空间学习和动态查询实现了高效且高性能的3D物体检测，适用于自动驾驶感知任务。

摘要: 基于摄像头的鸟瞰图（BEV）3D物体检测是自动驾驶中最重要的感知任务之一。早期方法依赖密集的BEV特征，构建成本高。近期研究探索了基于稀疏查询的检测方法，但仍需大量查询，且在处理多帧视频时计算成本较高。本文提出DySS，一种基于状态空间学习和动态查询的新方法。具体而言，DySS利用状态空间模型（SSM）逐步处理时间步长的特征，并通过未来预测和掩码重建等辅助任务优化SSM训练。SSM的状态提供了场景的高效信息摘要。基于状态空间学习特征，DySS通过合并、删除和拆分操作动态更新查询，保持高效的检测查询集。DySS在nuScenes测试集上达到65.31 NDS和57.4 mAP，优于最新方法；在验证集上达到56.2 NDS和46.2 mAP，推理速度为33 FPS。

</details>


### [332] [HalLoc: Token-level Localization of Hallucinations for Vision Language Models](https://arxiv.org/abs/2506.10286)
**中文标题：HalLoc：视觉语言模型中幻觉的标记级定位**

*Eunkyu Park,Minyeong Kim,Gunhee Kim*

Main category: cs.CV

TL;DR: HalLoc是一个用于高效检测视觉语言模型幻觉的数据集，包含15万个标记级注释样本，支持概率性幻觉检测，并提出了一种低开销的基线模型，可无缝集成到现有模型中。


<details>
  <summary>Details</summary>
Motivation: 当前幻觉检测方法计算成本高且结果绝对化，无法适应真实场景中模糊的幻觉边界。HalLoc旨在解决这些问题，提供高效且概率性的检测方案。

Method: 构建了包含15万标记级注释样本的HalLoc数据集，涵盖视觉问答、指令跟随和图像描述任务，并训练了一个低开销的基线模型，支持生成过程中的并发检测。

Result: HalLoc数据集和基线模型实现了高效、概率性的幻觉检测，可无缝集成到现有视觉语言模型中，提升可靠性而不牺牲效率。

Conclusion: HalLoc为视觉语言模型的幻觉检测提供了新工具，其数据集和模型有望增强模型在真实应用中的可信度。

摘要: 幻觉对大型视觉语言模型的可靠性构成重大挑战，其检测对关键应用中的准确性至关重要。当前的检测方法通常依赖计算密集型模型，导致高延迟和资源需求，且其确定性结果无法适应幻觉与真实信息界限模糊的真实场景。为解决这些问题，我们提出了HalLoc，一个专为高效概率性幻觉检测设计的数据集。该数据集包含15万个标记级注释样本，涵盖视觉问答、指令跟随和图像描述任务中的幻觉类型。HalLoc支持开发具有分级置信度的幻觉检测模型，从而实现更明智的用户交互。此外，我们还基于HalLoc训练了一个基线模型，能够在生成过程中以低开销并发检测幻觉。该模型可无缝集成到现有视觉语言模型中，在保持效率的同时提升可靠性。这一即插即用的幻觉检测模块为增强视觉语言模型在真实应用中的可信度开辟了新途径。HalLoc数据集和代码已公开：https://github.com/dbsltm/cvpr25_halloc。

</details>


### [333] [Uncertainty-Aware Deep Learning for Automated Skin Cancer Classification: A Comprehensive Evaluation](https://arxiv.org/abs/2506.10302)
**中文标题：不确定性感知深度学习在自动化皮肤癌分类中的全面评估**

*Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya*

Main category: cs.CV

TL;DR: 本文通过迁移学习和不确定性量化（UQ）对HAM10000数据集上的深度学习皮肤癌分类模型进行全面评估，发现基于CLIP的视觉变换器性能最佳，而集成方法在准确性和不确定性处理之间取得了良好平衡。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌的准确诊断对早期治疗和改善患者预后至关重要。尽管深度学习在自动化皮肤癌分类中表现出潜力，但其性能受限于数据稀缺和缺乏不确定性意识。本研究旨在通过迁移学习和不确定性量化提升模型的性能和可信度。

Method: 研究分为两个阶段：第一阶段，使用多种预训练特征提取器（如CLIP变体、ResNet50、DenseNet121等）结合传统分类器（如SVM、XGBoost）进行基准测试；第二阶段，引入不确定性量化方法（如蒙特卡洛Dropout、集成方法等），并使用不确定性感知指标评估模型。

Result: 基于CLIP的视觉变换器（如LAION CLIP ViT-H/14与SVM结合）表现最佳；集成方法在准确性和不确定性处理之间取得了良好平衡，而EMCD对不确定预测更敏感。

Conclusion: 研究表明，将不确定性量化融入深度学习模型可以显著提升医学诊断的性能和可信度，为实际临床应用提供了更可靠的解决方案。

摘要: 准确可靠的皮肤癌诊断对早期治疗和改善患者预后至关重要。深度学习（DL）模型在自动化皮肤癌分类中表现出潜力，但其性能受限于数据稀缺和缺乏不确定性意识。本研究通过迁移学习和不确定性量化（UQ）在HAM10000数据集上对DL模型进行全面评估。第一阶段，我们测试了多种预训练特征提取器（包括CLIP变体、ResNet50、DenseNet121、VGG16和EfficientNet-V2-Large）与传统分类器（如SVM、XGBoost和逻辑回归）的组合。结果表明，基于CLIP的视觉变换器（尤其是LAION CLIP ViT-H/14与SVM结合）分类性能最佳。第二阶段，我们引入UQ方法（如蒙特卡洛Dropout、集成方法和集成蒙特卡洛Dropout）以评估预测准确性和模型输出的可靠性，并使用不确定性感知指标（如不确定性准确度、不确定性灵敏度等）进行评估。结果显示，集成方法在准确性和不确定性处理之间取得了良好平衡，而EMCD对不确定预测更敏感。本研究强调了将UQ融入DL医学诊断的重要性，以提升实际临床应用中的性能和可信度。

</details>


### [334] [Towards Scalable SOAP Note Generation: A Weakly Supervised Multimodal Framework](https://arxiv.org/abs/2506.10328)
**中文标题：迈向可扩展的SOAP笔记生成：一种弱监督多模态框架**

*Sadia Kamal,Tim Oates,Joy Wan*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督多模态框架，用于从有限的输入（如病变图像和稀疏临床文本）生成临床结构化的SOAP笔记，减少对人工标注的依赖，同时达到与GPT-4o等模型相当的临床相关性表现。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见的癌症，每年医疗支出超过80亿美元。临床中，医生需手动生成详细的SOAP笔记，这不仅耗时且易导致职业倦怠。因此，需要一种自动化方法以减少医生负担并提高文档生成的可扩展性。

Method: 提出了一种弱监督多模态框架，结合病变图像和稀疏临床文本生成SOAP笔记。该方法减少了对大量标注数据的依赖，并引入了两个新指标MedConceptEval和CCS以评估临床质量。

Result: 该方法在关键临床相关性指标上表现与GPT-4o、Claude和DeepSeek Janus Pro相当，验证了其临床实用性和可扩展性。

Conclusion: 该框架为临床文档生成提供了一种高效、可扩展的解决方案，显著减轻了医生负担，同时保持了高质量的临床输出。

摘要: 皮肤癌是全球最常见的癌症，每年医疗支出超过80亿美元。在临床环境中，医生使用详细的SOAP（主观、客观、评估和计划）笔记记录患者就诊情况。然而，手动生成这些笔记耗时且易导致职业倦怠。本文提出了一种弱监督多模态框架，从有限的输入（如病变图像和稀疏临床文本）生成临床结构化的SOAP笔记。该方法减少了对人工标注的依赖，实现了可扩展且临床可靠的文档生成，同时减轻了医生负担并降低了对大规模标注数据的需求。我们的方法在关键临床相关性指标上表现与GPT-4o、Claude和DeepSeek Janus Pro相当。为评估临床质量，我们引入了两个新指标MedConceptEval和临床一致性评分（CCS），分别用于评估与专家医学概念的语义对齐和输入特征的临床一致性。

</details>


### [335] [Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video](https://arxiv.org/abs/2506.10331)
**中文标题：用户生成全向视频的音视频质量评估数据集与方法研究**

*Fei Zhao,Da Pan,Zelu Qi,Ping Shi*

Main category: cs.CV

TL;DR: 本文针对元宇宙中用户生成的全向视频（ODV）音视频质量评估（AVQA）研究不足的问题，构建了一个UGC全向音视频数据集，并提出了一个基于特征提取和融合的基线模型，实验证明该模型性能优越。


<details>
  <summary>Details</summary>
Motivation: 随着元宇宙的兴起，全向视频（ODV）逐渐从专业生成内容（PGC）转向用户生成内容（UGC），但其音视频质量评估（AVQA）研究仍较为有限。本文旨在填补这一空白。

Method: 研究构建了一个包含300个视频的UGC全向音视频数据集，覆盖10种场景类型，并通过主观实验获取平均意见分数（MOS）。随后，提出了一个包含视频特征提取、音频特征提取和音视频融合模块的基线模型。

Result: 实验结果表明，所提出的基线模型在构建的数据集上表现出最优性能。

Conclusion: 本文为UGC-ODV音视频质量评估领域提供了数据集和基线模型，为后续研究奠定了基础。

摘要: 随着元宇宙的兴起，全向视频（ODV）逐渐从专业生成内容（PGC）转向用户生成内容（UGC），但其音视频质量评估（AVQA）研究仍较为有限。为此，我们构建了一个UGC全向音视频数据集，包含由五名用户使用两种不同类型全向相机拍摄的300个视频，覆盖10种场景类型。通过主观AVQA实验获取音视频序列的平均意见分数（MOS）。随后，为促进UGC-ODV AVQA领域的发展，我们在该数据集上构建了一个有效的AVQA基线模型，该模型包含视频特征提取模块、音频特征提取模块和音视频融合模块。实验结果表明，我们的模型在提出的数据集上实现了最优性能。

</details>


### [336] [Using Vision Language Models to Detect Students' Academic Emotion through Facial Expressions](https://arxiv.org/abs/2506.10334)
**中文标题：利用视觉语言模型通过面部表情检测学生的学业情绪**

*Deliang Wang,Chao Yang,Gaowei Chen*

Main category: cs.CV

TL;DR: 本研究探讨了视觉语言模型（VLMs）在在线学习环境中通过面部表情检测学生学业情绪的潜力，发现Qwen2.5-VL-7B-Instruct模型在识别困惑和快乐情绪方面表现较好，但在检测分心行为上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 学生的学业情绪对其社交行为和学习表现有重要影响。传统方法依赖监督学习，但泛化能力有限，需要反复的数据收集和训练。视觉语言模型（VLMs）的出现为零样本任务提供了新可能。

Method: 研究使用两种视觉语言模型（Llama-3.2-11B-Vision-Instruct和Qwen2.5-VL-7B-Instruct），通过零样本提示分析了5,000张包含困惑、分心、快乐、中立和疲惫表情的图像。

Result: 初步结果显示，两种模型在学业情绪识别中表现中等，Qwen2.5-VL-7B-Instruct优于Llama-3.2-11B-Vision-Instruct。Qwen2.5-VL-7B-Instruct在识别困惑情绪方面表现突出，但两种模型均未能检测分心行为。

Conclusion: 视觉语言模型在学业情绪识别中具有一定潜力，尤其是Qwen2.5-VL-7B-Instruct在识别困惑情绪方面表现优异，但需进一步改进以检测分心行为。

摘要: 学生的学业情绪显著影响其社交行为和学习表现。传统方法主要依赖监督机器学习算法来自动准确分析这些情绪，但这些模型通常难以在不同情境中泛化，需要反复的数据收集、标注和训练。视觉语言模型（VLMs）的出现提供了一种有前景的替代方案，通过零样本提示实现视觉识别任务的泛化，而无需微调。本研究探讨了VLMs在在线学习环境中通过面部表情分析学生学业情绪的潜力。我们使用两种VLMs（Llama-3.2-11B-Vision-Instruct和Qwen2.5-VL-7B-Instruct），通过零样本提示分析了5,000张包含困惑、分心、快乐、中立和疲惫表情的图像。初步结果表明，两种模型在学业面部表情识别中表现中等，Qwen2.5-VL-7B-Instruct优于Llama-3.2-11B-Vision-Instruct。值得注意的是，两种模型在识别快乐情绪方面表现优异，但未能检测分心行为。此外，Qwen2.5-VL-7B-Instruct在识别困惑情绪方面表现相对较高，突显了其在识别导致学生困惑内容方面的实际应用潜力。

</details>


### [337] [PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting](https://arxiv.org/abs/2506.10335)
**中文标题：PointGS：基于高斯泼溅的点注意力感知稀疏视图合成**

*Lintao Xiang,Hongpei Zheng,Yating Huang,Qijun Yang,Hujun Yin*

Main category: cs.CV

TL;DR: 本文提出了一种基于点注意力机制的高斯泼溅框架（PointGS），用于从稀疏训练视图中实现实时高质量渲染，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅（3DGS）方法需要大量校准视图才能生成一致的场景表示，而在输入视图有限时容易过拟合，导致渲染质量下降。本文旨在解决这一问题。

Method: 首先利用立体基础模型估计准确的相机姿态并重建密集点云以初始化高斯；然后通过采样和聚合多尺度2D外观特征编码每个3D高斯的颜色属性；设计基于自注意力机制的点交互网络以增强点间外观表示；最后通过轻量级多层感知机（MLP）解码高斯参数完成渲染。

Result: 在多种基准测试中，该方法显著优于基于NeRF的方法，并在少样本设置下与最先进的3DGS方法竞争。

Conclusion: PointGS通过点注意力机制和特征增强，实现了从稀疏视图中高质量实时渲染，为3D场景表示提供了新思路。

摘要: 3D高斯泼溅（3DGS）是一种创新的渲染技术，通过显式3D场景表示在渲染速度和视觉质量上超越了神经辐射场（NeRF）。现有3DGS方法需要大量校准视图以生成一致且完整的场景表示，而在输入视图有限时容易过拟合训练视图，导致渲染质量显著下降。为解决这一问题，我们提出了一种点特征感知的高斯泼溅框架，能够从稀疏训练视图中实现实时高质量渲染。具体而言，我们首先利用最新的立体基础模型估计准确的相机姿态并重建密集点云以初始化高斯；然后通过采样和聚合多尺度2D外观特征编码每个3D高斯的颜色属性；为增强点间外观表示，设计了一种基于自注意力机制的点交互网络，使每个高斯点能够与其最近邻交互；这些增强的特征随后通过两个轻量级多层感知机（MLP）解码为高斯参数完成最终渲染。在多种基准测试上的大量实验表明，我们的方法显著优于基于NeRF的方法，并在少样本设置下与最先进的3DGS方法竞争。

</details>


### [338] [GeoCAD: Local Geometry-Controllable CAD Generation](https://arxiv.org/abs/2506.10337)
**中文标题：GeoCAD：局部几何可控的CAD生成**

*Zhanwei Zhang,Kaiyuan Liu,Junjie Liu,Wenxiao Wang,Binbin Lin,Liang Xie,Chen Shen,Deng Cai*

Main category: cs.CV

TL;DR: GeoCAD是一种用户友好的局部几何可控CAD生成方法，通过互补标注策略生成局部几何指令，并利用大语言模型预测被遮挡部分，实验证明其在生成质量、有效性和文本到CAD一致性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在局部几何可控的CAD生成中面临挑战，要么无法遵循文本指令，要么无法专注于局部部分。GeoCAD旨在解决这一问题，提升设计效率并满足用户特定的几何需求。

Method: 提出互补标注策略，分别为简单和复杂局部部分生成几何指令；在训练阶段随机遮挡局部部分，利用几何指令和剩余部分输入大语言模型预测被遮挡部分；推理时用户可指定局部部分修改并遵循预定义几何指令。

Result: 实验表明GeoCAD在生成质量、有效性和文本到CAD一致性方面表现优异，标注了约221k个不同局部部分。

Conclusion: GeoCAD是一种高效且用户友好的局部几何可控CAD生成方法，能够满足用户特定需求并提升设计效率。

摘要: 局部几何可控的计算机辅助设计（CAD）生成旨在自动修改CAD模型的局部部分，提升设计效率，并确保新生成的局部部分形状遵循用户特定的几何指令（例如等腰直角三角形或切掉一角的矩形）。然而，现有方法在实现这一目标时面临挑战，具体表现为要么缺乏遵循文本指令的能力，要么无法专注于局部部分。为解决这一局限，我们提出了GeoCAD，一种用户友好且局部几何可控的CAD生成方法。具体而言，我们首先提出互补标注策略，为局部部分生成几何指令。该策略通过基于顶点和基于VLLM的标注分别系统化标注简单和复杂部分。通过这种方式，我们总共标注了约221k个不同的局部部分。在训练阶段，给定一个CAD模型，我们随机遮挡一个局部部分，然后利用其几何指令和剩余部分作为输入，提示大语言模型（LLMs）预测被遮挡部分。在推理阶段，用户可以指定任意局部部分进行修改，同时遵循多种预定义的几何指令。大量实验证明了GeoCAD在生成质量、有效性和文本到CAD一致性方面的有效性。代码将在https://github.com/Zhanwei-Z/GeoCAD提供。

</details>


### [339] [UrbanSense:AFramework for Quantitative Analysis of Urban Streetscapes leveraging Vision Large Language Models](https://arxiv.org/abs/2506.10342)
**中文标题：UrbanSense：基于视觉大语言模型的城市街景定量分析框架**

*Jun Yin,Jing Zhong,Peilin Li,Pengyu Zeng,Miao Zhang,Ran Luo,Shuai Lu*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型的多模态框架UrbanSense，用于自动化和可扩展地分析城市街景风格差异，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 城市文化和建筑风格因地理、历史和社会政治因素差异显著，传统研究方法依赖专家解读和历史文献，难以标准化。本研究旨在通过数据驱动的方法提升城市形态研究的客观性。

Method: 构建了UrbanDiffBench数据集，包含不同时期和地区的建筑图像；开发了基于视觉语言模型的框架UrbanSense，用于定量生成和比较城市风格表征。

Result: 实验结果显示，超过80%的生成描述通过t检验（p<0.05），主观评价的高Phi分数（城市0.912，时期0.833）表明该方法能捕捉细微风格差异。

Conclusion: UrbanSense框架为量化城市风格演变提供了科学依据，为未来设计提供了数据支持。

摘要: 由于地理、历史和社会政治因素的差异，城市文化和建筑风格在不同城市间存在显著差异。理解这些差异对于预测城市未来演变至关重要。作为中国历史延续与现代创新的代表案例，北京和深圳为探索城市街景的转变提供了宝贵视角。然而，传统的城市文化研究方法通常依赖专家解读和历史文献，难以在不同背景下标准化。为此，我们提出了一种基于视觉语言模型的多模态研究框架，实现了城市街景风格差异的自动化和可扩展分析。这一方法提升了城市形态研究的客观性和数据驱动性。本研究的贡献如下：首先，我们构建了UrbanDiffBench数据集，包含来自不同时期和地区的建筑图像。其次，我们开发了UrbanSense，首个基于视觉语言模型的城市街景分析框架，支持城市风格表征的定量生成与比较。第三，实验结果表明，超过80%的生成描述通过t检验（p<0.05）。主观评价的高Phi分数（城市0.912，时期0.833）证实了该方法捕捉细微风格差异的能力。这些结果凸显了该方法在量化和解释城市风格演变方面的潜力，为未来设计提供了科学依据。

</details>


### [340] [RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration](https://arxiv.org/abs/2506.10344)
**中文标题：RealKeyMorph：基于真实世界坐标的关键点实现分辨率无关的图像配准**

*Mina C. Moghadam,Alan Q. Wang,Omer Taub,Martin R. Prince,Mert R. Sabuncu*

Main category: cs.CV

TL;DR: RealKeyMorph (RKM) 是一种分辨率无关的图像配准方法，通过输出真实世界坐标中的关键点，避免了传统方法因重采样引入的伪影问题。


<details>
  <summary>Details</summary>
Motivation: 在医学图像配准中，由于采集参数（如像素间距、切片厚度等）不同，图像分辨率可能不一致。传统机器学习方法需将图像重采样至固定分辨率，这会因插值引入伪影。RKM旨在解决这一问题。

Method: RKM 是 KeyMorph 的扩展，通过训练网络学习图像对的关键点，并利用扫描仪生成的仿射矩阵将关键点转换到真实世界坐标中，从而实现分辨率无关的配准。

Result: 实验表明，RKM 在腹部 MRI 正交 2D 堆栈和不同分辨率脑部 3D 数据集的配准任务中表现优异。

Conclusion: RKM 通过避免重采样并利用真实世界坐标，提供了一种更优的分辨率无关配准方法。

摘要: 许多实际场景中需要配准空间分辨率不同的医学图像，这种差异可能源自像素间距、切片厚度和视场等采集参数的不同。然而，所有先前的基于机器学习的配准技术都需要将图像重采样至固定分辨率，这会因插值引入伪影而显得次优。为此，我们提出 RealKeyMorph (RKM)，一种分辨率无关的图像配准方法。RKM 是 KeyMorph 的扩展，后者通过训练网络学习图像对的关键点，然后通过闭式关键点匹配步骤推导对齐变换。为避免重采样并直接在原始数据上操作，RKM 输出扫描仪真实世界坐标中的关键点。为此，我们利用扫描仪（如 MRI 机器）生成的仿射矩阵，该矩阵编码了从体素坐标到真实世界坐标的映射。通过将关键点转换到真实世界空间并将其整合到训练过程中，RKM 有效实现了分辨率无关的关键点提取。实验中，我们在腹部 MRI 正交 2D 堆栈和不同分辨率脑部 3D 数据集的配准任务中验证了 RKM 的优势。

</details>


### [341] [Motion-R1: Chain-of-Thought Reasoning and Reinforcement Learning for Human Motion Generation](https://arxiv.org/abs/2506.10353)
**中文标题：Motion-R1：基于链式思维推理和强化学习的人体动作生成**

*Runqi Ouyang,Haoyun Li,Zhenyuan Zhang,Xiaofeng Wang,Zheng Zhu,Guan Huang,Xingang Wang*

Main category: cs.CV

TL;DR: Motion-R1 是一个结合链式思维推理和强化学习的文本到动作生成框架，通过分解复杂指令为逻辑动作路径，显著提升动作生成的多样性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到动作生成方法依赖端到端映射，缺乏对深层语言结构和逻辑推理的捕捉，导致生成的动作可控性、一致性和多样性不足。

Method: Motion-R1 提出了一种统一的动作-语言建模框架，结合链式思维机制分解复杂指令为逻辑动作路径，并采用 Group Relative Policy Optimization 强化学习算法联合优化推理链和动作生成。

Result: 实验表明，Motion-R1 在多个基准数据集上表现优异，尤其在需要语义理解和长期时间一致性的场景中优于现有方法。

Conclusion: Motion-R1 通过链式思维推理和强化学习显著提升了文本到动作生成的性能，为复杂指令的执行提供了高效解决方案。

摘要: 近年来，大型语言模型在自然语言理解和推理方面的进展为文本到动作生成提供了新的可能性。尽管现有方法在语义对齐和动作合成方面取得了显著进展，但它们通常依赖端到端映射策略，未能捕捉深层语言结构和逻辑推理，导致生成的动作缺乏可控性、一致性和多样性。为解决这些问题，我们提出了 Motion-R1，一个结合链式思维机制的统一动作-语言建模框架。通过将复杂文本指令显式分解为逻辑结构的动作路径，Motion-R1 为动作生成提供了高级语义指导，显著提升了模型对多步骤、长时程和组合丰富指令的解释和执行能力。为训练模型，我们采用了 Group Relative Policy Optimization，这是一种专为大型模型设计的强化学习算法，利用动作质量反馈联合优化推理链和动作合成。在多个基准数据集上的广泛实验表明，Motion-R1 在需要细致语义理解和长期时间一致性的场景中表现优于或与现有方法相当。代码、模型和数据将公开提供。

</details>


### [342] [FaceLiVT: Face Recognition using Linear Vision Transformer with Structural Reparameterization For Mobile Device](https://arxiv.org/abs/2506.10361)
**中文标题：FaceLiVT：基于线性视觉变换器与结构重参数化的移动设备人脸识别**

*Novendra Setyawan,Chi-Chia Sun,Mao-Hsiu Hsu,Wen-Kai Kuo,Jun-Wei Hsieh*

Main category: cs.CV

TL;DR: FaceLiVT是一种轻量级但高性能的人脸识别模型，结合了CNN-Transformer混合架构和创新的多头线性注意力机制，显著降低了计算复杂度，同时在移动设备上实现了高精度和低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前轻量级人脸识别模型在移动设备上存在计算复杂度高或精度不足的问题，FaceLiVT旨在通过结合CNN-Transformer架构和创新的注意力机制，提供一种高效且实用的解决方案。

Method: FaceLiVT采用了一种混合CNN-Transformer架构，并引入了多头线性注意力机制（MHLA）和重参数化的token mixer，以降低计算复杂度并保持高精度。

Result: 在LFW、CFP-FP、AgeDB-30、IJB-B和IJB-C等基准测试中，FaceLiVT表现出色，比EdgeFace快8.6倍，比纯ViT模型快21.2倍，同时保持了高精度。

Conclusion: FaceLiVT通过平衡设计和创新机制，为资源受限平台上的实时人脸识别提供了一种高效且实用的解决方案。

摘要: 本文介绍了FaceLiVT，一种轻量级但高性能的人脸识别模型，它结合了混合卷积神经网络（CNN）-Transformer架构和创新的轻量级多头线性注意力（MHLA）机制。通过将MHLA与重参数化的token mixer结合，FaceLiVT有效降低了计算复杂度，同时保持了竞争力强的精度。在LFW、CFP-FP、AgeDB-30、IJB-B和IJB-C等具有挑战性的基准测试中，FaceLiVT表现出色，优于当前最先进的轻量级模型。MHLA显著提高了推理速度，使FaceLiVT在移动设备上能够以较低的延迟实现高精度。具体而言，FaceLiVT比EdgeFace（一种针对边缘设备优化的混合CNN-Transformer模型）快8.6倍，比纯ViT模型快21.2倍。凭借其平衡的设计，FaceLiVT为资源受限平台上的实时人脸识别提供了一种高效且实用的解决方案。

</details>


### [343] [FSATFusion: Frequency-Spatial Attention Transformer for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.10366)
**中文标题：FSATFusion：基于频率-空间注意力Transformer的红外与可见光图像融合方法**

*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui,Yuhan Lyu*

Main category: cs.CV

TL;DR: 本文提出了一种名为FSATFusion的端到端融合网络，通过频率-空间注意力Transformer模块（FSAT）和改进的Transformer模块（ITM）提升红外与可见光图像融合的性能，实验证明其在融合质量和泛化能力上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在红外与可见光图像融合（IVIF）中主要依赖卷积神经网络，但卷积操作难以捕捉全局上下文信息，导致信息丢失，限制了融合性能。

Method: 提出FSATFusion网络，包含频率-空间注意力Transformer模块（FSAT）和改进的Transformer模块（ITM）。FSAT通过频率-空间注意力机制（FSAM）提取显著特征，ITM增强全局上下文信息提取能力。

Result: 实验表明，FSATFusion在融合质量和效率上优于其他先进方法，且在未修改的情况下适用于其他任务，验证了其优秀的泛化能力。下游目标检测任务也证明了其优越性。

Conclusion: FSATFusion通过创新的频率-空间注意力机制和改进的Transformer模块，显著提升了红外与可见光图像融合的性能，并展示了强大的泛化能力。

摘要: 红外与可见光图像融合（IVIF）因其在下游应用中的优异表现而受到研究界和工业界的广泛关注。现有的深度学习方法通常利用卷积神经网络提取图像特征，但卷积操作固有的全局上下文捕捉能力不足可能导致信息丢失，从而限制融合性能。为解决这一问题，我们提出了一种端到端的融合网络——频率-空间注意力Transformer融合网络（FSATFusion）。FSATFusion包含一个频率-空间注意力Transformer（FSAT）模块，旨在有效捕捉源图像的判别性特征。该FSAT模块包含一个频率-空间注意力机制（FSAM），能够从特征图中提取显著特征。此外，我们还提出了一种改进的Transformer模块（ITM），以增强原始Transformer的全局上下文信息提取能力。通过定性和定量对比实验，证明了FSATFusion在融合质量和效率上优于其他先进方法。此外，我们的网络在未做任何修改的情况下测试了另外两项任务，验证了FSATFusion优秀的泛化能力。最后，目标检测实验证明了FSATFusion在下游视觉任务中的优越性。代码已开源：https://github.com/Lmmh058/FSATFusion。

</details>


### [344] [Revisiting Transformers with Insights from Image Filtering](https://arxiv.org/abs/2506.10371)
**中文标题：从图像滤波的视角重新审视Transformer**

*Laziz U. Abdullaev,Maksim Tkachenko,Tan M. Nguyen*

Main category: cs.CV

TL;DR: 本文通过图像处理框架重新解释Transformer的自注意力机制，揭示了其组件（如位置编码和残差连接）的作用，并提出两种改进架构，不仅提升了解释性，还提高了模型在语言和视觉任务中的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制作为Transformer的核心组件，其成功和局限性缺乏深入的理论解释。本文旨在通过图像处理框架，为自注意力及其变体提供更深入的理论基础，并探索其改进潜力。

Method: 提出了一种统一的图像处理框架，用于解释自注意力机制及其组件（如位置编码和残差连接）的作用。在此基础上，引入了两种独立的架构改进，以提升模型的解释性和性能。

Result: 实验表明，基于图像处理启发的改进不仅增强了模型的可解释性，还显著提高了其在语言和视觉任务中的准确性和鲁棒性，尤其是在长序列理解方面。

Conclusion: 本文通过图像处理框架为自注意力机制提供了更深入的理论解释，并展示了其在模型改进中的实际应用价值，为未来研究提供了新的方向。

摘要: 自注意力机制作为Transformer等先进深度学习架构的核心，其设计主要基于启发式方法，且难以解释。近年来，建立解释其成功与局限性的理论框架成为研究热点。一些研究尝试通过图像去噪和非参数回归的视角理解自注意力机制，但现有框架仍缺乏对其原始形式及后续变体中各组件的深入机制解释。本文旨在通过开发一种统一的图像处理框架，不仅解释自注意力计算本身，还阐明位置编码和残差连接等组件的作用，包括后续多种变体。我们还指出了这两种概念之间的潜在差异，并努力弥合这一差距。我们在Transformer中引入了两种独立的架构改进。尽管主要目标是提升解释性，但实验表明，基于图像处理启发的改进还能显著提高模型在语言和视觉任务中的准确性、对数据污染和对抗攻击的鲁棒性，以及长序列理解能力。

</details>


### [345] [Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial](https://arxiv.org/abs/2506.10386)
**中文标题：利用六自由度位姿基础模型测绘海洋沉积物埋藏**

*Jerry Yan,Chinmay Talegaonkar,Nicholas Antipa,Eric Terrill,Sophia Merrifield*

Main category: cs.CV

TL;DR: 本文提出了一种名为PoseIDON的计算机视觉流程，结合深度基础模型特征和多视角摄影测量技术，从ROV视频中估计海底物体的六自由度位姿及周围海底的朝向，从而推断埋藏深度。该方法在历史海洋倾倒场的54个物体上验证，平均埋藏深度误差约为10厘米。


<details>
  <summary>Details</summary>
Motivation: 海底人为物体的埋藏状态对局部沉积动力学研究、生态风险评估、污染物迁移分析以及危险材料（如弹药）的回收或缓解策略至关重要。然而，由于部分遮挡、能见度差和物体退化，从遥感图像中准确估计埋藏深度仍具挑战性。

Method: PoseIDON结合深度基础模型特征与多视角摄影测量技术，通过ROV视频估计物体的六自由度位姿及周围海底的朝向。埋藏深度通过将物体的CAD模型与观测图像对齐，并拟合局部平面近似海底来推断。

Result: 在San Pedro Basin历史海洋倾倒场的54个物体（包括桶和弹药）上验证，模型平均埋藏深度误差约为10厘米，并能解析反映沉积物迁移过程的空间埋藏模式。

Conclusion: PoseIDON方法实现了海底埋藏的可扩展、非侵入式测绘，为污染场地的环境评估提供了支持。

摘要: 海底人为物体的埋藏状态不仅揭示了局部沉积动力学，还对生态风险评估、潜在污染物迁移以及危险材料（如弹药）的回收或缓解策略至关重要。由于部分遮挡、能见度差和物体退化，从遥感图像中准确估计埋藏深度仍具挑战性。本文提出了一种名为PoseIDON的计算机视觉流程，结合深度基础模型特征与多视角摄影测量技术，从ROV视频中估计物体的六自由度位姿及周围海底的朝向。埋藏深度通过将物体的CAD模型与观测图像对齐，并拟合局部平面近似海底来推断。该方法在San Pedro Basin历史海洋倾倒场的54个物体（包括桶和弹药）上验证，平均埋藏深度误差约为10厘米，并能解析反映沉积物迁移过程的空间埋藏模式。这一方法实现了海底埋藏的可扩展、非侵入式测绘，为污染场地的环境评估提供了支持。

</details>


### [346] [DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Transformer and Mamba](https://arxiv.org/abs/2506.10390)
**中文标题：DART：用于Vision Transformer和Mamba的可微分动态自适应区域分词器**

*Shicheng Yin,Kaixuan Yin,Yang Liu,Weixing Chen,Liang Lin*

Main category: cs.CV

TL;DR: DART是一种动态自适应区域分词器，通过自适应划分图像为不同大小的内容相关补丁，显著提升Vision Transformer和Mamba的性能，同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前Vision Transformer和Vision Mamba等非卷积模型依赖固定大小的补丁，导致背景区域过度编码和关键局部细节丢失。DART旨在通过动态自适应分区解决这一问题。

Method: DART结合可学习的区域评分和分段可微分分位数操作，将更多令牌分配给信息丰富的区域，从而自适应划分图像为不同大小的补丁。

Result: DART在DeiT（ImageNet-1K）上准确率提升2.1%，计算开销减少45%，并在DeiT、Vim和VideoMamba上一致表现优异。

Conclusion: DART提供了一种高效的方法，通过动态自适应分区提升模型性能，同时减少计算成本，适用于多种视觉任务。

摘要: 近年来，非卷积模型如Vision Transformer（ViT）和Vision Mamba（Vim）在计算机视觉任务中取得了显著性能。然而，它们依赖固定大小的补丁，通常导致背景区域过度编码和关键局部细节丢失，尤其是当信息对象稀疏分布时。为此，我们提出了一种完全可微分的动态自适应区域分词器（DART），能够自适应地将图像划分为内容相关的不同大小补丁。DART结合可学习的区域评分和分段可微分分位数操作，将更多令牌分配给信息丰富的区域。尽管仅引入约100万额外参数，DART在DeiT（ImageNet-1K）上准确率提升了2.1%。与那些通过均匀增加令牌密度来捕捉细粒度细节的方法不同，DART提供了一种更高效的替代方案，实现了45%的FLOPs减少和更优性能。在DeiT、Vim和VideoMamba上的广泛实验证实，DART在提升准确率的同时，仅带来极小甚至减少的计算开销。代码发布于https://github.com/HCPLab-SYSU/DART。

</details>


### [347] [ReconMOST: Multi-Layer Sea Temperature Reconstruction with Observations-Guided Diffusion](https://arxiv.org/abs/2506.10391)
**中文标题：ReconMOST：基于观测引导扩散的多层海水温度重建**

*Yuanyi Song,Pumeng Lyu,Ben Fei,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.CV

TL;DR: 本文提出ReconMOST，一种基于数据驱动的扩散模型框架，用于多层海水温度重建，解决了传统方法数据稀疏、计算复杂的问题，并在全球范围内实现了高精度重建。


<details>
  <summary>Details</summary>
Motivation: 传统海洋温度重建方法因数据稀疏、算法复杂和计算成本高而受限，而现有机器学习方法多局限于海表或局部区域，难以解决云遮挡等问题。本文旨在提出一种更高效、全局适用的多层海水温度重建方法。

Method: 首先利用历史数值模拟数据预训练无条件扩散模型，学习海洋温度场的物理一致性分布模式；在生成阶段，以稀疏但高精度的现场观测数据为引导点，通过反向扩散过程生成精确重建结果。

Result: 在CMIP6和EN4分析数据上的实验显示，均方误差（MSE）在引导、重建和总体上分别为0.049、0.680和0.633，证明了方法的有效性和鲁棒性。

Conclusion: ReconMOST成功将机器学习方法扩展到全球多层海水温度重建，处理了92.5%以上的缺失数据，同时保持了重建精度和空间分辨率。

摘要: 准确的海洋温度重建对于反映全球气候动态和支持海洋气象研究至关重要。传统方法因数据稀疏、算法复杂和计算成本高而面临挑战，而机器学习方法的应用多局限于海表或局部区域，难以解决云遮挡等问题。为解决这些限制，本文提出ReconMOST，一种基于数据驱动的引导扩散模型框架，用于多层海水温度重建。具体而言，我们首先利用大量历史数值模拟数据预训练无条件扩散模型，使模型能够学习海洋温度场的物理一致性分布模式。在生成阶段，稀疏但高精度的现场观测数据被用作反向扩散过程的引导点，生成精确的重建结果。重要的是，在缺乏直接观测数据的区域，预训练中学到的物理一致性空间分布模式能够实现隐式引导和物理合理的重建。我们的方法将基于机器学习的海表温度重建扩展到全球多层场景，处理了超过92.5%的缺失数据，同时保持了重建精度、空间分辨率和优异的泛化能力。我们在CMIP6数值模拟数据上预训练模型，并在CMIP6和EN4分析数据上进行引导重建实验。均方误差（MSE）在引导、重建和总体上分别为0.049、0.680和0.633，证明了所提框架的有效性和鲁棒性。源代码可在https://github.com/norsheep/ReconMOST获取。

</details>


### [348] [Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation](https://arxiv.org/abs/2506.10395)
**中文标题：Pisces：一种用于图像理解与生成的自回归基础模型**

*Zhiyang Xu,Jiuhai Chen,Zhaojiang Lin,Xichen Pan,Lifu Huang,Tianyi Zhou,Madian Khabsa,Qifan Wang,Di Jin,Michihiro Yasunaga,Lili Yu,Xi Victoria Lin,Shaoliang Nie*

Main category: cs.CV

TL;DR: Pisces是一种自回归多模态基础模型，通过解耦视觉编码架构和优化训练技术，在图像理解和生成任务中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态统一模型在图像理解和生成任务中表现不如专用模型，主要由于视觉特征需求和训练过程的差异。Pisces旨在解决这一问题。

Method: 提出解耦视觉编码架构和针对多模态生成的优化训练技术，结合精细数据筛选、预训练和微调。

Result: 在20多个图像理解基准测试和GenEval图像生成基准测试中表现优异，验证了图像理解与生成的协同关系。

Conclusion: Pisces通过解耦视觉编码和优化训练，推动了统一多模态模型的发展，展示了图像理解与生成的协同潜力。

摘要: 近年来，大型语言模型（LLMs）的进步使得多模态基础模型能够在统一框架中同时处理图像理解和生成任务。然而，统一模型在这两项任务中的表现往往不如专用模型。开发统一模型的关键挑战在于图像理解与生成所需的视觉特征及训练过程的本质差异。本文提出Pisces，一种自回归多模态基础模型，通过新颖的解耦视觉编码架构和针对多模态生成优化的训练技术解决了这一问题。结合精细的数据筛选、预训练和微调，Pisces在图像理解和生成任务中均取得了具有竞争力的性能。我们在20多个公开的图像理解基准测试中评估Pisces，结果显示其在广泛任务中表现优异。此外，在广泛采用的图像生成基准测试GenEval上，Pisces展现了强大的生成能力。通过深入分析，我们揭示了图像理解与生成之间的协同关系，以及使用独立视觉编码器的优势，推动了统一多模态模型领域的发展。

</details>


### [349] [It's Not the Target, It's the Background: Rethinking Infrared Small Target Detection via Deep Patch-Free Low-Rank Representations](https://arxiv.org/abs/2506.10425)
**中文标题：目标非关键，背景才是：通过深度无块低秩表示重新思考红外小目标检测**

*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为LRRNet的新型端到端红外小目标检测框架，通过直接建模低秩背景表示，无需依赖基于块的处理或显式矩阵分解，显著提升了检测精度和实时性能。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测在复杂背景下因低信噪比、目标形态多样和缺乏显著视觉线索而极具挑战性。现有深度学习方法因目标内在多变性和弱先验导致性能不稳定。

Method: LRRNet采用压缩-重建-减法（CRS）范式，直接建模图像域中的低秩背景表示，利用深度神经网络端到端学习背景结构，无需显式矩阵分解。

Result: 在多个公开数据集上，LRRNet在检测精度、鲁棒性和计算效率方面优于38种先进方法，平均速度达82.34 FPS，且在噪声环境下表现优异。

Conclusion: LRRNet通过直接学习低秩背景结构，显著提升了红外小目标检测的性能和实时性，为复杂背景下的目标检测提供了新思路。

摘要: 红外小目标检测（IRSTD）在复杂背景下因低信噪比（SCR）、目标形态多样和缺乏显著视觉线索而长期面临挑战。尽管近期深度学习方法试图学习判别性表示，但小目标的内在多变性和弱先验常导致性能不稳定。本文提出了一种新型端到端IRSTD框架LRRNet，利用红外图像背景的低秩特性。受杂乱场景物理可压缩性启发，该方法采用压缩-重建-减法（CRS）范式，直接在图像域建模结构感知的低秩背景表示，无需依赖基于块的处理或显式矩阵分解。据我们所知，这是首个通过深度神经网络端到端直接学习低秩背景结构的工作。在多个公开数据集上的大量实验表明，LRRNet在检测精度、鲁棒性和计算效率方面优于38种先进方法，平均速度达82.34 FPS，实现实时性能。在挑战性NoisySIRST数据集上的评估进一步证实了模型对传感器噪声的鲁棒性。源代码将在接受后公开。

</details>


### [350] [MF2Summ: Multimodal Fusion for Video Summarization with Temporal Alignment](https://arxiv.org/abs/2506.10430)
**中文标题：MF2Summ：基于多模态融合和时间对齐的视频摘要方法**

*Shuo wang,Jihao Zhang*

Main category: cs.CV

TL;DR: MF2Summ是一种基于多模态融合的视频摘要模型，结合视觉和听觉信息，通过跨模态Transformer和时间对齐机制提升摘要效果，在SumMe和TVSum数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统视频摘要方法通常仅依赖单一模态（如视觉），难以全面捕捉视频的语义信息。本文旨在通过多模态融合（视觉和听觉）提升视频摘要的准确性和丰富性。

Method: MF2Summ采用五阶段流程：特征提取（GoogLeNet和SoundNet）、跨模态注意力交互、特征融合、片段预测（重要性、位置和中心性）以及关键镜头选择（NMS和KTS算法）。核心是跨模态Transformer和对齐引导的自注意力Transformer。

Result: 在SumMe和TVSum数据集上，MF2Summ的F1分数分别比DSNet模型提高了1.9%和0.6%，并优于其他先进方法。

Conclusion: MF2Summ通过多模态融合和时间对齐机制显著提升了视频摘要的性能，证明了多模态信息在视频理解中的重要性。

摘要: 随着在线视频内容的快速增长，高效的视频摘要技术变得尤为重要。传统方法通常仅依赖单一模态（如视觉），难以全面捕捉视频的语义信息。本文提出MF2Summ，一种基于多模态内容理解（结合视觉和听觉信息）的新型视频摘要模型。MF2Summ采用五阶段流程：特征提取、跨模态注意力交互、特征融合、片段预测和关键镜头选择。视觉特征通过预训练的GoogLeNet提取，听觉特征则使用SoundNet提取。融合机制的核心是跨模态Transformer和对齐引导的自注意力Transformer，旨在有效建模模态间依赖关系和时间对应关系。通过预测片段的重要性、位置和中心性，并利用非极大值抑制（NMS）和核时间分割（KTS）算法选择关键镜头。在SumMe和TVSum数据集上的实验结果表明，MF2Summ表现优异，F1分数分别比DSNet模型提高了1.9%和0.6%，并优于其他先进方法。

</details>


### [351] [Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts](https://arxiv.org/abs/2506.10452)
**中文标题：面向模态缺失和分布偏移的鲁棒多模态情感识别**

*Guowei Zhong,Ruohong Huan,Mingzhen Wu,Ronghua Liang,Peng Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为CIDer的鲁棒多模态情感识别框架，通过自蒸馏和因果推理模块解决模态缺失和分布偏移问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前多模态情感识别（MER）方法在同时处理模态缺失和分布外（OOD）数据时存在局限性，且通常依赖复杂模型或过多参数。本文旨在提出一种更实用的解决方案。

Method: CIDer框架包含两个关键模块：模型特定自蒸馏（MSSD）和模型无关因果推理（MACI）。MSSD通过权重共享的自蒸馏方法提升鲁棒性，MACI通过因果图减少标签和语言偏差。此外，还引入了新的RMFM任务和OOD数据集。

Result: 实验表明，CIDer在RMFM和OOD场景下均表现优异，且参数更少、训练更快，优于现有方法。

Conclusion: CIDer为多模态情感识别提供了一种高效且鲁棒的解决方案，适用于模态缺失和分布偏移的复杂场景。

摘要: 近年来，多模态情感识别（MER）在同时处理模态缺失和分布外（OOD）数据方面面临挑战。现有方法通常依赖特定模型或引入过多参数，限制了其实用性。为解决这些问题，我们提出了一种新型鲁棒MER框架——因果推理蒸馏器（CIDer），并引入了一项新任务——随机模态特征缺失（RMFM），以泛化模态缺失的定义。CIDer包含两个关键组件：模型特定自蒸馏（MSSD）模块和模型无关因果推理（MACI）模块。MSSD通过权重共享的自蒸馏方法在低层特征、注意力图和高层表示中提升RMFM任务的鲁棒性。此外，词级自对齐注意力模块（WSAM）降低了计算复杂度，而多模态复合变换器（MCT）实现了高效的多模态融合。为应对OOD挑战，MACI利用定制的因果图，通过多模态因果模块（MCM）和细粒度反事实文本来减少标签和语言偏差。值得注意的是，MACI可以独立提升OOD泛化能力，且仅需少量额外参数。我们还引入了重新划分的MER OOD数据集。实验结果表明，CIDer在RMFM和OOD场景下均表现出鲁棒性能，且参数更少、训练速度更快，优于现有方法。本工作的实现已公开于https://github.com/gw-zhong/CIDer。

</details>


### [352] [Rethinking Generative Human Video Coding with Implicit Motion Transformation](https://arxiv.org/abs/2506.10453)
**中文标题：基于隐式运动变换的生成式人体视频编码方法再思考**

*Bolin Chen,Ru-Ling Liao,Jie Chen,Yan Ye*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐式运动变换（IMT）的生成式人体视频编码方法，解决了传统显式运动引导方法在复杂人体运动模式下的失真问题，实现了高效压缩和高保真重建。


<details>
  <summary>Details</summary>
Motivation: 传统基于显式运动引导的生成式视频编码方法在处理复杂多样的人体运动时容易产生失真和运动不准确的问题，因此需要一种更有效的方法来提升生成式人体视频编码（GHVC）的性能。

Method: 通过将复杂的人体信号表征为紧凑的视觉特征，并将这些特征转化为隐式运动引导信号，用于视频重建，提出了一种基于隐式运动变换（IMT）的GHVC方法。

Result: 实验结果表明，IMT方法能够显著提升GHVC的压缩效率和重建质量，有效解决了显式运动引导方法在复杂人体运动模式下的局限性。

Conclusion: 隐式运动变换（IMT）为生成式人体视频编码提供了一种更高效的解决方案，能够在复杂运动模式下实现高保真重建，具有重要的应用潜力。

摘要: 与传统基于混合的视频编码相比，生成式视频编码通过将高维信号演化为紧凑的特征表示以实现编码端的比特流紧凑性，并在解码端利用显式运动场作为中间监督实现高质量重建，取得了显著的成功。然而，与面部视频相比，人体视频由于运动模式更加复杂多样，在使用显式运动引导进行生成式人体视频编码（GHVC）时，重建结果可能出现严重失真和运动不准确的问题。为此，本文揭示了显式运动方法在人体视频压缩中的局限性，并研究了通过隐式运动变换（IMT）提升GHVC性能的方法。具体而言，我们提出将复杂的人体信号表征为紧凑的视觉特征，并将这些特征转化为隐式运动引导信号以实现信号重建。实验结果表明，所提出的IMT方法能够有效提升GHVC的压缩效率和重建质量。

</details>


### [353] [Boosting Adversarial Transferability for Hyperspectral Image Classification Using 3D Structure-invariant Transformation and Intermediate Feature Distance](https://arxiv.org/abs/2506.10459)
**中文标题：利用3D结构不变变换和中间特征距离增强高光谱图像分类的对抗可迁移性**

*Chun Liu,Bingqian Zhu,Tao Xu,Zheng Zheng,Zheng Li,Wei Yang,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过3D结构不变变换和中间特征距离增强高光谱图像分类模型的对抗样本可迁移性。实验表明，该方法在公开数据集上对黑盒模型具有有效攻击性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像（HSI）因其高维和丰富的光谱信息与自然图像不同，现有对抗攻击方法在HSI分类中的研究有限，且难以充分利用图像的结构和特征信息。

Method: 1. 在保持图像结构不变的情况下，随机将图像在空间和光谱维度分块，并对每个块应用多种变换以增加输入多样性；2. 设计中间层特征距离损失，以原始样本和对抗样本的特征距离为主要损失，输出层预测为辅助损失。

Result: 实验表明，该方法在两个公开HSI数据集上生成的对抗样本对黑盒模型具有有效可迁移性，且在防御策略下仍保持稳健攻击性能。

Conclusion: 所提方法通过结构不变变换和中间特征距离损失，显著提升了对抗样本的可迁移性，为HSI分类模型的安全性研究提供了新思路。

摘要: 深度神经网络（DNNs）易受对抗攻击的影响，这对基于DNNs的高光谱图像（HSI）分类技术提出了安全挑战。在自然图像领域，已有大量基于迁移的对抗攻击方法被研究。然而，HSI因其高维和丰富的光谱信息与自然图像不同。目前关于HSI对抗样本的研究仍有限，且难以充分利用图像的结构和特征信息。为解决这些问题，本文提出了一种新方法以增强HSI分类模型的对抗样本可迁移性。首先，在保持图像结构不变的情况下，该方法随机将图像在空间和光谱维度分块，并对每个块应用多种变换以增加输入多样性并缓解过拟合。其次，设计了一种针对中间层的特征距离损失，以原始样本的放大特征与对抗样本的特征距离为主要损失，输出层预测为辅助损失。这引导扰动破坏对抗样本中真实类别的特征，有效增强可迁移性。大量实验表明，所提方法生成的对抗样本在两个公开HSI数据集上对黑盒模型具有有效可迁移性。此外，该方法在防御策略下仍保持稳健的攻击性能。

</details>


### [354] [Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization](https://arxiv.org/abs/2506.10463)
**中文标题：初始位置的重要性：神经网络量化中更好的权重初始化研究**

*Stone Yun,Alexander Wong*

Main category: cs.CV

TL;DR: 本文研究了神经网络量化中权重初始化的重要性，提出了基于图超网络（GHN）的量化鲁棒初始化方法GHN-QAT，显著提升了低比特量化的准确性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）量化是降低模型推理成本的重要工具，但现有研究很少关注量化训练中的初始化问题。本文旨在探索不同权重初始化方法对量化鲁棒性的影响，并提出一种新的初始化方法。

Method: 研究首先分析了不同权重初始化方法对CNN量化鲁棒性的影响，随后提出了一种基于图超网络（GHN）的量化鲁棒初始化方法GHN-QAT，并通过微调GHN以预测量化图的参数。

Result: 实验表明，权重初始化方法显著影响量化鲁棒性，GHN-QAT方法在4比特量化中表现优异，甚至在2比特量化中优于随机初始化。

Conclusion: GHN-QAT为量化DNN模型设计提供了新思路，未来可结合量化感知训练进一步优化量化流程。

摘要: 深度神经网络（DNN）量化是实现快速高效推理的重要工具，用于降低机器学习（ML）模型推理成本。量化专用技术（如正则化、量化感知训练和量化鲁棒性惩罚）显著提升了现代DNN的准确性和鲁棒性。然而，针对量化训练的初始条件改进研究较少。正如随机权重初始化对浮点模型测试精度有显著影响，不同初始化方法也可能影响量化模型的鲁棒性。本文通过广泛研究不同权重初始化对高效CNN常用构建模块的影响，发现即使CNN架构不同，随机初始化方法的选择也会显著影响最终量化鲁棒性。随后，我们探索了一种新的量化鲁棒CNN初始化方法——使用图超网络（GHN）预测量化DNN参数。研究表明，GHN预测的参数在常规float32预训练后即具有量化鲁棒性，而进一步微调GHN以预测量化图参数（称为GHN-QAT）可进一步提升CNN的量化精度。值得注意的是，GHN-QAT在4比特量化中表现出显著精度提升，在2比特量化中甚至优于随机初始化。据我们所知，这是首个针对量化感知DNN权重初始化的深入研究。GHN-QAT为量化DNN模型设计提供了新方法。未来研究（如将GHN-QAT初始化参数用于量化感知训练）可进一步简化DNN量化流程。

</details>


### [355] [MedSeg-R: Reasoning Segmentation in Medical Images with Multimodal Large Language Models](https://arxiv.org/abs/2506.10465)
**中文标题：MedSeg-R：基于多模态大语言模型的医学图像推理分割**

*Yu Huang,Zelin Peng,Yichen Zhao,Piao Yang,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 本文提出了一种新型医学图像推理分割任务，并开发了MedSeg-R框架，利用多模态大语言模型（MLLMs）的推理能力生成精确的分割掩码。同时，作者还发布了MedSeg-QA数据集，实验证明该框架在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割模型依赖显式的人类指令，缺乏主动推理能力，无法理解复杂的临床问题。尽管多模态大语言模型（MLLMs）在医学问答任务中有所改进，但大多数方法难以生成精确的分割掩码，限制了其在自动医学诊断中的应用。

Method: 提出了MedSeg-R框架，包含两个核心模块：1）全局上下文理解模块，用于解释图像和理解复杂的医学指令，生成多模态中间标记；2）像素级接地模块，将这些标记解码为精确的分割掩码和文本响应。此外，还发布了MedSeg-QA数据集，包含10,000多对图像-掩码和多轮对话。

Result: 实验表明，MedSeg-R在多个基准测试中表现优异，实现了高分割精度，并支持对医学图像的可解释文本分析。

Conclusion: MedSeg-R通过结合多模态大语言模型的推理能力和像素级分割技术，为医学图像推理分割任务提供了有效的解决方案，并在实验中验证了其优越性能。

摘要: 医学图像分割在临床诊断中至关重要，但现有模型依赖显式的人类指令，缺乏理解复杂临床问题的主动推理能力。尽管多模态大语言模型（MLLMs）在医学问答任务中有所改进，但大多数方法难以生成精确的分割掩码，限制了其在自动医学诊断中的应用。本文提出了一种新型医学图像推理分割任务，旨在基于复杂且隐式的医学指令生成分割掩码。为此，我们提出了MedSeg-R，一种端到端框架，利用MLLMs的推理能力解释临床问题，同时生成相应的精确分割掩码。该框架包含两个核心模块：1）全局上下文理解模块，用于解释图像和理解复杂医学指令，生成多模态中间标记；2）像素级接地模块，将这些标记解码为精确的分割掩码和文本响应。此外，我们还发布了MedSeg-QA数据集，专为医学图像推理分割任务设计，包含10,000多对图像-掩码和多轮对话，通过大语言模型自动标注并经医生审核优化。实验表明，MedSeg-R在多个基准测试中表现优异，实现了高分割精度，并支持对医学图像的可解释文本分析。

</details>


### [356] [LLMs Are Not Yet Ready for Deepfake Image Detection](https://arxiv.org/abs/2506.10474)
**中文标题：大型语言模型尚无法胜任深度伪造图像检测**

*Shahroz Tariq,David Nguyen,M. A. P. Chamikara,Tingmin Wu,Alsharif Abuadbba,Kristen Moore*

Main category: cs.CV

TL;DR: 当前的大型语言模型（VLMs）在深度伪造图像检测中表现不佳，尽管能提供合理解释和检测表面异常，但尚不可靠。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的日益复杂对媒体完整性和公众信任构成挑战，而增强视觉推理能力的大型语言模型（VLMs）被视为潜在解决方案，但其实际效果尚不明确。

Method: 研究对四种主流VLMs（ChatGPT、Claude、Gemini和Grok）进行了零样本评估，测试其在三种深度伪造类型（换脸、重演和合成生成）上的分类准确性和推理深度。

Result: VLMs能生成连贯解释并检测表面异常，但依赖其作为独立检测系统不可靠，易受风格元素和误导性视觉模式（如复古美学）影响。

Conclusion: 尽管通用模型目前无法独立可靠地检测深度伪造，但其在可解释性和上下文分析方面的优势表明，可作为混合或人机协作检测框架的组成部分。

摘要: 深度伪造技术的日益复杂对媒体完整性和公众信任构成重大挑战。与此同时，增强视觉推理能力的大型语言模型（VLMs）作为多领域潜在工具崭露头角，引发了其在深度伪造检测中应用的兴趣。本研究对四种主流VLMs（ChatGPT、Claude、Gemini和Grok）进行了结构化零样本评估，聚焦于三种主要深度伪造类型：换脸、重演和合成生成。通过精心构建的包含多样来源真实与伪造图像的基准测试，我们评估了各模型的分类准确性和推理深度。分析表明，尽管VLMs能生成连贯解释并检测表面异常，但作为独立检测系统尚不可靠。我们揭示了关键失败模式，如对风格元素的过度关注以及对误导性视觉模式（如复古美学）的脆弱性。然而，VLMs在可解释性和上下文分析方面表现突出，表明其潜力可作为法医工作流程中人类专家的补充。这些发现意味着，尽管通用模型目前缺乏自主检测深度伪造的可靠性，但作为混合或人机协作检测框架的组成部分具有前景。

</details>


### [357] [Sheet Music Benchmark: Standardized Optical Music Recognition Evaluation](https://arxiv.org/abs/2506.10488)
**中文标题：乐谱基准：标准化的光学音乐识别评估**

*Juan C. Martinez-Sevilla,Joan Cerveto-Serrano,Noelia Luna,Greg Chapman,Craig Sapp,David Rizo,Jorge Calvo-Zaragoza*

Main category: cs.CV

TL;DR: 本文介绍了Sheet Music Benchmark (SMB)数据集和OMR-NED评估指标，旨在标准化光学音乐识别(OMR)研究的评估。SMB包含685页多样化的乐谱，OMR-NED提供细粒度错误分析，填补了OMR评估的空白。


<details>
  <summary>Details</summary>
Motivation: 当前光学音乐识别(OMR)研究缺乏标准化的评估数据集和指标，导致难以比较不同方法的性能。本文旨在填补这一空白，提供统一的评估框架。

Method: 1. 构建SMB数据集，包含685页多样化的乐谱（如单音、钢琴谱、四重奏等），使用Humdrum **kern格式编码。2. 提出OMR-NED评估指标，基于符号错误率(SER)，但对音符头、符干、音高、变音记号等关键元素进行细粒度分析。3. 使用SMB数据集进行基线实验，评估现有方法的性能。

Result: SMB数据集和OMR-NED指标为OMR研究提供了标准化的评估工具。基线实验表明，OMR-NED能够清晰比较不同方法的性能，帮助识别最优方法。

Conclusion: 本文填补了OMR评估的长期空白，SMB和OMR-NED为研究者和用户提供了统一的评估框架，推动了OMR领域的发展。

摘要: 本文介绍了Sheet Music Benchmark (SMB)数据集，包含685页专为光学音乐识别(OMR)研究设计的乐谱。SMB涵盖了多种音乐纹理（如单音、钢琴谱、四重奏等），均以Humdrum **kern格式编码。同时，我们提出了OMR标准化编辑距离(OMR-NED)，这是一种专门用于评估OMR性能的新指标。OMR-NED基于广泛使用的符号错误率(SER)，但提供了更细粒度的错误分析，涵盖音符头、符干、音高、变音记号等关键元素。OMR-NED提供的数值评分便于清晰比较，帮助研究者和终端用户识别最优的OMR方法。我们的工作填补了OMR评估的长期空白，并通过使用标准化的SMB数据集进行基线实验，支持了我们的贡献。

</details>


### [358] [Class-Incremental Learning for Honey Botanical Origin Classification with Hyperspectral Images: A Study with Continual Backpropagation](https://arxiv.org/abs/2506.10489)
**中文标题：基于高光谱图像的蜂蜜植物源分类的类增量学习研究：持续反向传播的应用**

*Guyang Zhang,Waleed Abdulla*

Main category: cs.CV

TL;DR: 本文研究了基于高光谱图像的蜂蜜植物源分类的类增量学习技术，提出了一种结合持续反向传播（CB）的新方法，以提高分类性能。实验表明，CB方法可将大多数类增量学习算法的性能提升1-7%。


<details>
  <summary>Details</summary>
Motivation: 蜂蜜是全球市场的重要商品，不同植物源的蜂蜜具有不同的风味和健康价值，因此准确区分蜂蜜的植物源对保护消费者利益至关重要。然而，一次性收集所有蜂蜜品种训练模型不现实，因此需要类增量学习技术来解决这一问题。

Method: 本研究比较了多种类增量学习算法在真实蜂蜜高光谱图像数据集上的表现，并提出了一种结合持续反向传播（CB）的新技术。CB通过重新初始化部分较少使用的隐藏神经元，为神经网络注入变异性，以解决可塑性丧失问题。

Result: 实验结果表明，CB方法显著提升了大多数类增量学习算法的性能，改进幅度为1-7%。

Conclusion: 结合持续反向传播的类增量学习方法在蜂蜜植物源分类任务中表现出色，为解决类似问题提供了有效工具。

摘要: 蜂蜜是全球市场的重要商品。不同植物源的蜂蜜具有多样化的风味和健康益处，因而具有不同的市场价值。开发准确有效的植物源区分技术对保护消费者利益至关重要。然而，一次性收集所有蜂蜜品种训练模型以区分植物源是不现实的。为此，研究人员开发了类增量学习（CIL）技术来解决这一挑战。本研究在真实蜂蜜高光谱图像数据集上检验并比较了多种CIL算法，并提出了一种结合持续反向传播（CB）算法的新技术，以提高类增量学习算法的性能。CB方法通过重新初始化部分较少使用的隐藏神经元，为神经网络注入变异性，以解决可塑性丧失问题。实验表明，CB方法将大多数CIL方法的性能提升了1-7%。

</details>


### [359] [Semantic Localization Guiding Segment Anything Model For Reference Remote Sensing Image Segmentation](https://arxiv.org/abs/2506.10503)
**中文标题：语义定位引导的Segment Anything模型用于参考遥感图像分割**

*Shuyang Li,Shuang Wang,Zhuangzhuang Sun,Jing Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种名为PSLG-SAM的两阶段框架，用于参考遥感图像分割任务，通过粗定位和精细分割两阶段解决现有方法的高标注需求和复杂场景干扰问题。实验表明，该方法显著提升了性能并减少了标注负担。


<details>
  <summary>Details</summary>
Motivation: 现有的参考遥感图像分割（RRSIS）方法依赖多模态融合主干和语义分割头，面临密集标注需求和复杂场景解释的挑战。本文旨在通过两阶段分解任务，减少标注负担并提升分割精度。

Method: PSLG-SAM框架分为粗定位和精细分割两阶段：1）粗定位阶段使用视觉定位网络粗略定位文本描述对象；2）精细分割阶段利用第一阶段坐标引导增强的Segment Anything Model（SAM），结合聚类前景点生成器和掩码边界迭代优化策略实现精确分割。第二阶段可无需训练，显著减少标注需求。

Result: 在两个数据集（RRSIS-D和RRSIS-M）上的实验验证表明，PSLG-SAM显著提升了性能，并超越了现有最先进模型。

Conclusion: PSLG-SAM通过两阶段分解任务，有效减少了标注负担并提升了分割精度，为复杂场景下的参考遥感图像分割提供了高效解决方案。

摘要: 参考遥感图像分割（RRSIS）任务通过文本描述生成图像中指定对象的分割掩码，引起了广泛关注和研究兴趣。现有的RRSIS方法依赖多模态融合主干和语义分割头，但面临密集标注需求和复杂场景解释的挑战。为解决这些问题，我们提出了一个名为“提示生成语义定位引导Segment Anything模型”（PSLG-SAM）的框架，将RRSIS任务分解为粗定位和精细分割两阶段。在粗定位阶段，视觉定位网络粗略定位文本描述对象；在精细分割阶段，第一阶段的坐标引导增强的Segment Anything Model（SAM），结合聚类前景点生成器和掩码边界迭代优化策略实现精确分割。值得注意的是，第二阶段可无需训练，显著减少了RRSIS任务的标注数据负担。此外，将RRSIS任务分解为两阶段可专注于特定区域分割，避免复杂场景的干扰。我们还贡献了一个高质量、多类别手动标注数据集。在两个数据集（RRSIS-D和RRSIS-M）上的实验验证表明，PSLG-SAM实现了显著的性能提升，并超越了现有最先进模型。我们的代码将公开提供。

</details>


### [360] [J-DDL: Surface Damage Detection and Localization System for Fighter Aircraft](https://arxiv.org/abs/2506.10505)
**中文标题：J-DDL：战斗机表面损伤检测与定位系统**

*Jin Huang,Mingqiang Wei,Zikuan Li,Hangyu Qu,Wei Zhao,Xinyu Bai*

Main category: cs.CV

TL;DR: J-DDL是一种用于战斗机表面损伤检测与定位的智能系统，结合2D图像和3D点云数据，通过优化的YOLO架构和新型损失函数实现高效检测，并公开首个飞机损伤数据集。


<details>
  <summary>Details</summary>
Motivation: 战斗机表面损伤检测依赖人工检查，存在效率低、一致性差等问题，亟需一种自动化、高效的解决方案。

Method: J-DDL系统整合激光扫描仪和相机捕获的2D图像与3D点云数据，采用优化的YOLO架构（含轻量级Fasternet块、EMA模块和Inner-CIOU损失函数）进行损伤检测，并将结果映射到3D点云实现精确定位。

Result: 实验验证了J-DDL的高效性，能够全面覆盖复杂飞机表面，并公开首个飞机损伤数据集推动领域发展。

Conclusion: J-DDL显著提升了战斗机表面损伤检测的自动化水平，为飞机维护技术提供了重要支持。

摘要: 为确保战斗机的安全性和延长使用寿命，需频繁进行全面检查。尽管人工检查可检测表面缺陷，但由于飞机表面积大、结构复杂且维护需求高，传统方法在扩展性、效率和一致性上存在严重不足。我们提出了一种智能战斗机表面损伤检测与定位系统J-DDL。该系统结合激光扫描仪和相机捕获的2D图像与3D点云数据，实现精确的损伤检测与定位。其核心是基于YOLO架构的新型损伤检测网络，专为2D飞机图像中的表面缺陷识别优化。关键创新包括：轻量级Fasternet块用于高效特征提取、优化的颈部架构（含EMA模块）实现卓越特征聚合，以及新型损失函数Inner-CIOU提升检测精度。检测到2D图像中的损伤后，系统将异常映射到3D点云，实现飞机表面缺陷的精确3D定位。J-DDL不仅简化了检查流程，还确保了对大型复杂飞机外部的全面覆盖。为推动该领域发展，我们开发了首个公开的飞机损伤数据集。实验验证了该框架的有效性，展示了其在自动化飞机检查技术中的巨大潜力。

</details>


### [361] [CogStream: Context-guided Streaming Video Question Answering](https://arxiv.org/abs/2506.10516)
**中文标题：CogStream：上下文引导的流媒体视频问答**

*Zicheng Zhao,Kangyu Wang,Shijie Li,Rui Qian,Weiyao Lin,Huabin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CogStream的流媒体视频问答任务，通过上下文引导的推理方法解决现有视频大语言模型在流媒体视频处理中的计算负担和无关上下文干扰问题，并提出了一个密集标注的数据集和基线模型CogReasoner。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大语言模型（Vid-LLMs）在处理流媒体视频时，由于依赖所有历史上下文信息，导致计算负担大且易受无关信息干扰。本文旨在解决这一问题，提出了一种更高效的上下文引导推理方法。

Method: 本文提出了CogStream任务，模拟真实流媒体视频场景，要求模型识别最相关的历史上下文信息以回答问题。为此，构建了一个半自动生成的密集标注数据集，并提出了基线模型CogReasoner，结合视觉流压缩和历史对话检索技术。

Result: 实验证明，CogReasoner能够高效处理流媒体视频问答任务，显著减少了计算负担并提高了推理准确性。

Conclusion: CogStream任务及CogReasoner模型为流媒体视频推理提供了新的解决方案，未来将进一步优化模型性能并公开代码。

摘要: 尽管视频大语言模型（Vid-LLMs）在多模态理解方面取得了进展，但由于其对上下文信息的依赖，流媒体视频推理仍面临挑战。现有范式将所有可用的历史上下文信息输入Vid-LLMs，导致视觉数据处理的计算负担显著增加。此外，无关上下文的引入会分散模型对关键细节的注意力。本文提出了一项名为“上下文引导的流媒体视频推理”（CogStream）的挑战性任务，模拟真实流媒体视频场景，要求模型识别最相关的历史上下文信息以推断当前流的问题答案。为支持CogStream，我们提供了一个密集标注的数据集，包含广泛且层次化的问题-答案对，通过半自动流程生成。此外，我们还提出了基线模型CogReasoner，通过视觉流压缩和历史对话检索高效解决该任务。大量实验证明了该方法的有效性。代码即将发布。

</details>


### [362] [ALBERT: Advanced Localization and Bidirectional Encoder Representations from Transformers for Automotive Damage Evaluation](https://arxiv.org/abs/2506.10524)
**中文标题：ALBERT：基于双向编码器表示和高级定位机制的汽车损伤评估模型**

*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: ALBERT是一种专为汽车损伤和部件分割设计的实例分割模型，结合双向编码器表示和高级定位机制，能准确区分真实与虚假损伤，并分割汽车部件。


<details>
  <summary>Details</summary>
Motivation: 汽车损伤评估需要高精度的分割和分类方法，以区分真实与虚假损伤并识别具体部件。ALBERT旨在解决这一问题，推动智能汽车检测应用。

Method: ALBERT利用双向编码器表示和高级定位机制，在大规模标注的汽车数据集上进行训练，涵盖26种损伤类型、7种虚假损伤变体和61种汽车部件。

Result: ALBERT在分割精度和损伤分类方面表现出色，为智能汽车检测应用提供了可靠的技术支持。

Conclusion: ALBERT为汽车损伤评估提供了一种高效准确的解决方案，具有广泛的应用潜力。

摘要: 本文介绍了ALBERT，一种专为全面汽车损伤和部件分割设计的实例分割模型。ALBERT利用双向编码器表示的优势，结合高级定位机制，能够准确识别和区分真实与虚假损伤，并分割单个汽车部件。该模型在大规模、丰富标注的汽车数据集上进行训练，数据集包含26种损伤类型、7种虚假损伤变体和61种不同汽车部件。我们的方法在分割精度和损伤分类方面表现出色，为智能汽车检测和评估应用铺平了道路。

</details>


### [363] [SLICK: Selective Localization and Instance Calibration for Knowledge-Enhanced Car Damage Segmentation in Automotive Insurance](https://arxiv.org/abs/2506.10528)
**中文标题：SLICK：基于选择性定位和实例校准的知识增强型汽车损伤分割方法**

*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: SLICK是一种新型汽车损伤分割框架，通过选择性部件分割、定位感知注意力、实例敏感细化、跨通道校准和知识融合模块，实现了高精度和鲁棒性的损伤分割。


<details>
  <summary>Details</summary>
Motivation: 汽车保险和检测领域需要高精度的损伤分割方法，但现有方法在遮挡、变形或复杂场景下表现不佳。SLICK旨在利用结构先验和领域知识解决这些问题。

Method: SLICK包含五个关键组件：选择性部件分割、定位感知注意力块、实例敏感细化头、跨通道校准和知识融合模块，结合合成数据和真实数据集提升性能。

Result: 在大规模汽车数据集上的实验表明，SLICK在分割性能、鲁棒性和实际应用性方面均优于现有方法。

Conclusion: SLICK通过结合结构先验和领域知识，显著提升了汽车损伤分割的精度和实用性，适用于保险和汽车检测工作流程。

摘要: 我们提出了SLICK，一种新颖的汽车损伤分割框架，利用结构先验和领域知识解决实际汽车检测中的挑战。SLICK包含五个关键组件：（1）选择性部件分割，通过高分辨率语义骨干网络和结构先验实现高精度分割，即使在遮挡、变形或漆面损失的情况下；（2）定位感知注意力块，动态聚焦于损伤区域，提升复杂街景中的细粒度损伤检测；（3）实例敏感细化头，利用全景线索和形状先验分离重叠或相邻部件，实现精确边界对齐；（4）跨通道校准，通过多尺度通道注意力增强细微损伤信号（如划痕和凹陷），同时抑制噪声（如反射和贴花）；（5）知识融合模块，整合合成碰撞数据、部件几何信息和真实保险数据集，提升泛化能力并有效处理罕见情况。在大规模汽车数据集上的实验证明了SLICK在分割性能、鲁棒性和实际应用性方面的优越性，适用于保险和汽车检测工作流程。

</details>


### [364] [ContextRefine-CLIP for EPIC-KITCHENS-100 Multi-Instance Retrieval Challenge 2025](https://arxiv.org/abs/2506.10550)
**中文标题：ContextRefine-CLIP：面向EPIC-KITCHENS-100多实例检索挑战2025**

*Jing He,Yiqing Wang,Lingling Li,Kexin Zhang,Puhua Chen*

Main category: cs.CV

TL;DR: 本文提出了一种高效的多实例检索模型ContextRefine-CLIP（CR-CLIP），通过跨模态注意力流模块实现视觉与文本特征的双向动态交互与优化，显著提升了EPIC-KITCHENS-100任务中的检索性能。


<details>
  <summary>Details</summary>
Motivation: 针对视觉-文本多实例检索任务中特征交互不足的问题，提出一种能够动态优化跨模态特征的方法，以提升检索的准确性和语义对齐能力。

Method: 基于双编码器AVION，引入跨模态注意力流模块，实现视觉与文本特征的双向动态交互与优化，并结合对称多相似性损失进行语义对齐。

Result: 在EPIC-KITCHENS-100公开排行榜上，CR-CLIP模型取得了66.78mAP和82.08nDCG的成绩，显著优于基线模型。

Conclusion: CR-CLIP通过动态优化跨模态特征，显著提升了多实例检索任务的性能，验证了其在跨模态检索中的有效性。

摘要: 本报告提出了ContextRefine-CLIP（CR-CLIP），一种高效的视觉-文本多实例检索模型。该方法基于双编码器AVION，通过引入跨模态注意力流模块，实现视觉与文本特征的双向动态交互与优化，生成更具上下文感知的联合表示。对于EPIC-KITCHENS-100等任务中提供的软标签相关性矩阵，CR-CLIP可以结合对称多相似性损失，利用优化后的特征实现更准确的语义对齐与优化。在不使用集成学习的情况下，CR-CLIP模型在EPIC-KITCHENS-100公开排行榜上取得了66.78mAP和82.08nDCG的成绩，显著优于基线模型，充分验证了其在跨模态检索中的有效性。代码将在https://github.com/delCayr/ContextRefine-Clip开源发布。

</details>


### [365] [From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations](https://arxiv.org/abs/2506.10559)
**中文标题：从图像到洞察：基于通俗语言栖息地解释的可解释生物多样性监测**

*Yutong Zhou,Masahiro Ryo*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的视觉到因果框架，将物种图像转化为可解释的栖息地偏好因果洞察，为非专家提供易懂的生物多样性监测解释。


<details>
  <summary>Details</summary>
Motivation: 理解物种为何生活在特定地点对生态系统的研究和生物多样性保护至关重要，但现有生态工作流程分散且对非专家不友好。

Method: 整合物种识别、全球分布检索、伪缺失采样和气候数据提取，利用现代因果推断方法发现环境特征间的因果结构并估计其对物种分布的影响，最后通过结构化模板和大语言模型生成统计支持的人类可读因果解释。

Result: 通过在蜜蜂和花卉物种上的实验，展示了该框架的潜力，证明了多模态AI助手结合生态建模实践能够以人类可理解的语言描述物种栖息地。

Conclusion: 该框架为非专家提供了易懂的生物多样性监测解释，展示了AI在生态学中的潜力。

摘要: 解释物种为何生活在特定地点对于理解生态系统和保护生物多样性至关重要。然而，现有的生态工作流程分散且通常对非专家难以理解。我们提出了一种端到端的视觉到因果框架，将物种图像转化为关于其栖息地偏好的可解释因果洞察。该系统整合了物种识别、全球分布检索、伪缺失采样和气候数据提取。随后，我们利用现代因果推断方法发现环境特征间的因果结构，并估计其对物种分布的影响。最后，我们通过结构化模板和大语言模型生成统计支持的人类可读因果解释。我们在蜜蜂和花卉物种上展示了该框架，并报告了作为正在进行项目的一部分的早期结果，展示了由推荐的生态建模实践支持的多模态AI助手以人类可理解的语言描述物种栖息地的潜力。

</details>


### [366] [Balancing Tails when Comparing Distributions: Comprehensive Equity Index (CEI) with Application to Bias Evaluation in Operational Face Biometrics](https://arxiv.org/abs/2506.10564)
**中文标题：比较分布时的尾部平衡：全面公平指数（CEI）及其在操作人脸生物识别偏差评估中的应用**

*Imanol Solano,Julian Fierrez,Aythami Morales,Alejandro Peña,Ruben Tolosana,Francisco Zamora-Martinez,Javier San Agustin*

Main category: cs.CV

TL;DR: 本文提出了一种名为全面公平指数（CEI）的新指标，用于检测高性能人脸识别系统中的细微人口统计偏差，尤其是在分数分布的尾部。CEI通过单独分析真实和冒名顶替分数分布，提供了一种可配置的尾部概率分析方法。实验表明，CEI在检测现有方法难以发现的偏差方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 高性能人脸识别系统中的人口统计偏差往往难以被现有指标检测到，尤其是在分数分布的尾部。本文旨在解决这一局限性，提出一种更敏感的公平性评估方法。

Method: 本文提出了全面公平指数（CEI），通过单独分析真实和冒名顶替分数分布，并允许可配置的尾部概率分析。此外，还开发了自动化版本CEI^A，以提高客观性和实用性。

Result: 实验评估了多种先进人脸识别系统、故意偏置模型和多样化数据集，证实CEI在检测细微偏差方面优于现有方法。

Conclusion: CEI为操作人脸识别系统的公平性评估提供了强大且敏感的工具，尤其适用于分析分布尾部的偏差问题。

摘要: 高性能人脸识别（FR）系统中的人口统计偏差往往难以被现有指标检测到，尤其是在分数分布的尾部。我们提出了全面公平指数（CEI），这是一种新颖的指标，旨在解决这一局限性。CEI独特地分别分析真实和冒名顶替分数分布，允许可配置地关注尾部概率，同时考虑整体分布形状。我们的大量实验（评估了最先进的FR系统、故意偏置模型和多样化数据集）证实，CEI在检测现有方法难以发现的细微偏差方面表现优异。此外，我们还提出了CEI^A，这是CEI的自动化版本，增强了客观性并简化了实际应用。CEI为操作FR公平性评估提供了强大且敏感的工具。所提出的方法虽然专为人脸生物识别中的偏差评估而开发，但通常适用于任何需要分析分布尾部的统计分布比较问题。

</details>


### [367] [LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System](https://arxiv.org/abs/2506.10567)
**中文标题：LRSLAM：密集视觉SLAM系统中符号距离场的低秩表示**

*Hongbeen Park,Minjeong Park,Giljoo Nam,Jinkyu Kim*

Main category: cs.CV

TL;DR: LRSLAM提出了一种基于低秩张量分解的视觉SLAM方法，显著提升了内存效率、收敛速度和重建/定位质量，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 密集视觉SLAM在实时性、鲁棒性和大规模场景扩展性方面面临挑战，现有神经隐式表示方法计算和内存成本高，ESLAM的平面张量分解仍存在内存增长问题。

Method: LRSLAM采用低秩张量分解方法（Six-axis和CP分解），优化了内存效率和收敛速度，同时保持了高质量的重建和定位能力。

Result: 在多种室内RGB-D数据集上的评估表明，LRSLAM在参数效率、处理时间和准确性方面优于现有方法，且保持了重建和定位质量。

Conclusion: LRSLAM通过低秩张量分解显著提升了视觉SLAM的性能，为实时性和大规模场景应用提供了高效解决方案。

摘要: 同步定位与地图构建（SLAM）在自动驾驶、移动机器人和混合现实等领域至关重要。密集视觉SLAM利用RGB-D相机系统具有优势，但在实现实时性、鲁棒性和大规模场景扩展性方面面临挑战。最近基于神经隐式场景表示的方法显示出潜力，但存在高计算和内存成本的问题。ESLAM引入了基于平面的张量分解，但仍受限于内存增长。为解决这些问题，我们提出了一种更高效的视觉SLAM模型LRSLAM，采用低秩张量分解方法（Six-axis和CP分解）。我们的方法在收敛速度、内存效率和重建/定位质量上优于现有先进方法。在多种室内RGB-D数据集上的评估表明，LRSLAM在参数效率、处理时间和准确性方面表现优异，同时保持了重建和定位质量。代码将在发表后公开。

</details>


### [368] [DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers](https://arxiv.org/abs/2506.10568)
**中文标题：DreamActor-H1：基于运动设计的扩散变换器的高保真人与产品演示视频生成**

*Lizhen Wang,Zhurong Xia,Tianshu Hu,Pengrui Wang,Pengfei Wang,Zerong Zheng,Ming Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散变换器（DiT）的框架DreamActor-H1，用于生成高保真的人与产品演示视频。该方法通过注入配对的人与产品参考信息和使用掩码交叉注意力机制，同时保留人类身份和产品细节，并通过3D身体网格模板和产品边界框提供精确的运动指导。实验表明，该方法在保持身份完整性和生成真实演示动作方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在电子商务和数字营销中，生成高保真的人与产品演示视频对产品展示至关重要。然而，现有框架往往无法同时保留人类和产品的身份，或缺乏对人与产品空间关系的理解，导致不真实的表示和不自然的交互。

Method: 本文提出了一种基于扩散变换器（DiT）的框架，通过注入配对的人与产品参考信息和使用掩码交叉注意力机制，同时保留人类身份和产品细节。此外，利用3D身体网格模板和产品边界框提供精确的运动指导，并通过结构化文本编码增强3D一致性。

Result: 实验结果表明，该方法在保持人类和产品身份完整性以及生成真实演示动作方面优于现有技术。

Conclusion: DreamActor-H1框架通过结合扩散变换器和精确的运动指导，成功生成了高保真的人与产品演示视频，为电子商务和数字营销提供了有效的解决方案。

摘要: 在电子商务和数字营销中，生成高保真的人与产品演示视频对产品展示至关重要。然而，大多数现有框架要么无法同时保留人类和产品的身份，要么缺乏对人与产品空间关系的理解，导致不真实的表示和不自然的交互。为解决这些问题，我们提出了一种基于扩散变换器（DiT）的框架。我们的方法通过注入配对的人与产品参考信息和使用额外的掩码交叉注意力机制，同时保留人类身份和产品特定细节（如标志和纹理）。我们采用3D身体网格模板和产品边界框提供精确的运动指导，实现手势与产品放置的直观对齐。此外，通过结构化文本编码引入类别级语义，增强帧间小旋转变化时的3D一致性。通过在混合数据集上训练并采用广泛的数据增强策略，我们的方法在保持人类和产品身份完整性及生成真实演示动作方面优于现有技术。项目页面：https://submit2025-dream.github.io/DreamActor-H1/。

</details>


### [369] [Improving Medical Visual Representation Learning with Pathological-level Cross-Modal Alignment and Correlation Exploration](https://arxiv.org/abs/2506.10573)
**中文标题：通过病理级别跨模态对齐和相关探索改进医学视觉表示学习**

*Jun Wang,Lixing Zhu,Xiaohan Yu,Abhir Bhalerao,Yulan He*

Main category: cs.CV

TL;DR: 本文提出了一种名为PLACE的新框架，通过病理级别的跨模态对齐和相关探索，提升医学视觉表示学习的效果，无需额外人工标注。实验表明，该方法在多个下游任务中达到最新最优性能。


<details>
  <summary>Details</summary>
Motivation: 医学领域中，从图像-报告对中学习视觉表示可以缓解数据稀缺问题，但现有方法多关注实例或标记级别的对齐，忽略了病理级别的一致性。本文旨在解决这一问题。

Method: 提出PLACE框架，包含病理级别跨模态对齐（PCMA）模块和视觉病理观察提取器，通过最大化图像和报告中病理观察的一致性，并设计代理任务探索图像块间的相关性。

Result: 实验结果表明，PLACE在分类、图像到文本检索、语义分割、目标检测和报告生成等下游任务中均达到最优性能。

Conclusion: PLACE框架通过病理级别对齐和相关探索，显著提升了医学视觉表示学习的效果，且无需额外标注，具有较高的通用性和鲁棒性。

摘要: 通过联合学习从图像-报告对中学习医学视觉表示，因其能够缓解医学领域数据稀缺问题而受到越来越多的研究关注。主要挑战在于报告内容冗长且包含复杂的语义病理关系。以往研究多集中于实例或标记级别的跨模态对齐，往往忽略了病理级别一致性的重要性。本文提出了一种名为PLACE的新框架，通过病理级别对齐和相关探索，在不增加人工标注的情况下提升细粒度细节。具体而言，我们提出了一种病理级别跨模态对齐（PCMA）方法，以最大化图像和报告中病理观察的一致性。为此，引入了视觉病理观察提取器，从局部标记中提取视觉病理观察表示。PCMA模块不依赖任何外部疾病标注，增强了方法的通用性和鲁棒性。此外，我们设计了一个代理任务，强制模型识别图像块间的相关性，从而丰富对下游任务至关重要的细粒度细节。实验结果表明，我们提出的框架在多个下游任务中达到了最新的最优性能，包括分类、图像到文本检索、语义分割、目标检测和报告生成。

</details>


### [370] [DanceChat: Large Language Model-Guided Music-to-Dance Generation](https://arxiv.org/abs/2506.10574)
**中文标题：DanceChat：基于大语言模型的音乐到舞蹈生成方法**

*Qing Wang,Xiaohang Yang,Yilan Dong,Naveen Raj Govindaraj,Gregory Slabaugh,Shanxin Yuan*

Main category: cs.CV

TL;DR: DanceChat是一种基于大语言模型（LLM）的音乐到舞蹈生成方法，通过LLM提供文本动作指导，解决了音乐与舞蹈之间的语义鸿沟问题，并提升了生成舞蹈的多样性和音乐风格对齐能力。


<details>
  <summary>Details</summary>
Motivation: 音乐到舞蹈生成面临语义鸿沟和一对多映射的挑战，音乐仅提供抽象线索而无法明确指定具体动作，且现有数据稀缺限制了模型学习多样舞蹈模式的能力。

Method: DanceChat包含三个模块：(1) LLM生成伪指令，提供基于音乐风格和结构的文本舞蹈指导；(2) 多模态特征提取与融合模块，整合音乐、节奏和文本指导；(3) 基于扩散的动作合成模块，通过多模态对齐损失确保舞蹈与音乐和文本线索对齐。

Result: 在AIST++数据集和人类评估中，DanceChat在质量和数量上均优于现有方法。

Conclusion: DanceChat通过LLM的显式指导，显著提升了音乐到舞蹈生成的多样性和风格对齐能力。

摘要: 音乐到舞蹈生成的目标是根据音乐输入合成人类舞蹈动作。尽管近期取得进展，但由于音乐与舞蹈动作之间的语义鸿沟，音乐仅提供旋律、节奏和情感等抽象线索，而无法明确指定具体动作，因此仍存在显著挑战。此外，同一段音乐可能对应多种合理的舞蹈解释，这种一对多映射需要额外指导，因为仅靠音乐提供的信息有限。配对的音乐和舞蹈数据稀缺进一步加剧了这一挑战，限制了模型学习多样舞蹈模式的能力。本文提出DanceChat，一种基于大语言模型（LLM）的音乐到舞蹈生成方法。我们利用LLM作为编舞者，提供文本动作指令，为舞蹈生成提供显式的高层指导。这种方法超越了仅从音乐中隐式学习的方式，使模型能够生成更具多样性且更符合音乐风格的舞蹈。我们的方法包含三个模块：(1) 基于LLM的伪指令生成模块，根据音乐风格和结构生成文本舞蹈指导；(2) 多模态特征提取与融合模块，将音乐、节奏和文本指导整合为共享表示；(3) 基于扩散的动作合成模块，结合多模态对齐损失，确保生成的舞蹈与音乐和文本线索对齐。在AIST++数据集上的大量实验和人类评估表明，DanceChat在质量和数量上均优于现有方法。

</details>


### [371] [Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning](https://arxiv.org/abs/2506.10575)
**中文标题：用于多标签图像识别的文本到图像联合提示-适配器学习**

*Chun-Mei Feng,Kai Yu,Xinxing Xu,Salman Khan,Rick Siow Mong Goh,Wangmeng Zuo,Yong Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为T2I-PAL的新方法，通过利用文本到图像生成模型减少模态差异，结合提示调优和适配器学习，显著提升了多标签图像识别的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等预训练视觉语言模型能够通过图像-文本对比学习实现参数高效微调（PEFT），但模态差异问题限制了仅使用文本进行PEFT时的图像识别性能。本文旨在解决这一问题，特别是在多标签图像识别（MLR）任务中。

Method: T2I-PAL利用预训练的文本到图像生成模型，从文本描述生成逼真且多样化的图像，以减少模态差异。此外，结合类热图和可学习原型，增强局部视觉特征的表示，并通过提示调优和适配器学习提升分类性能。

Result: 在MS-COCO、VOC2007和NUS-WIDE等多个基准测试中，T2I-PAL的平均识别性能比现有最优方法提升了3.47%。

Conclusion: T2I-PAL不仅减少了手动标注的工作量，还保留了CLIP模型的固有模式，能够无缝集成到任何现有CLIP框架中，显著提升了多标签图像识别的性能。

摘要: 得益于图像-文本对比学习，预训练的视觉语言模型（如CLIP）可以直接利用文本作为图像（TaI）进行参数高效微调（PEFT）。尽管CLIP能够使图像特征与相应文本特征相似，但模态差异仍然是一个重要问题，限制了TaI的图像识别性能。以多标签图像识别（MLR）为例，我们提出了一种名为T2I-PAL的新方法，用于解决仅使用文本描述进行PEFT时的模态差异问题。T2I-PAL的核心设计是利用预训练的文本到图像生成模型，从文本描述生成逼真且多样化的图像，从而减少模态差异。为了进一步增强MLR，T2I-PAL结合了类热图和可学习原型，通过聚合局部相似性，使局部视觉特征的表示更加鲁棒和丰富。为了更好地实现PEFT，我们还结合了提示调优和适配器学习以提升分类性能。T2I-PAL具有显著优势：它消除了对完全语义标注训练图像的需求，从而减少了手动标注的工作量，同时保留了CLIP模型的固有模式，能够无缝集成到任何现有CLIP框架中。在MS-COCO、VOC2007和NUS-WIDE等多个基准测试上的广泛实验表明，我们的T2I-PAL可以将识别性能平均提升3.47%，优于现有的最先进方法。

</details>


### [372] [Harmonizing Geometry and Uncertainty: Diffusion with Hyperspheres](https://arxiv.org/abs/2506.10576)
**中文标题：几何与不确定性的协调：基于超球面的扩散模型**

*Muskan Dosi,Chiranjeev Chiranjeev,Kartik Thakral,Mayank Vatsa,Richa Singh*

Main category: cs.CV

TL;DR: 本文提出了HyperSphereDiff方法，通过引入方向性噪声来对齐超球面数据的几何结构，解决了传统扩散模型在欧几里得空间中无法保留超球面数据几何特性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型依赖各向同性高斯噪声，适用于欧几里得空间，但无法有效处理超球面等非欧几里得分布数据中的角度几何特性，导致生成性能不佳。

Method: 提出HyperSphereDiff方法，通过方向性噪声对齐超球面结构，保留类别几何特性并捕捉角度不确定性。

Result: 理论和实验证明，该方法能够更好地保留超球面数据的固有几何特性，在四个物体数据集和两个人脸数据集上表现优异。

Conclusion: HyperSphereDiff通过结合角度不确定性，显著提升了生成模型的准确性和几何感知能力。

摘要: 当代扩散模型是否保留了超球面数据的类别几何特性？标准扩散模型在前向过程中依赖各向同性高斯噪声，天然适用于欧几里得空间。然而，许多现实问题涉及非欧几里得分布（如超球面流形），其中类别特定模式由超锥内的角度几何决定。在欧几里得空间中建模时，这些角度细节会丢失，导致生成性能不佳。为解决这一问题，我们提出了HyperSphereDiff，通过方向性噪声对齐超球面结构，保留类别几何并有效捕捉角度不确定性。我们从理论和实验上证明，这种方法能够将生成过程与超球面数据的固有几何对齐，从而得到更准确且几何感知的生成模型。我们在四个物体数据集和两个人脸数据集上评估了该框架，结果表明，引入角度不确定性能够更好地保留底层超球面流形。资源见：{https://github.com/IAB-IITJ/Harmonizing-Geometry-and-Uncertainty-Diffusion-with-Hyperspheres/}

</details>


### [373] [Rethinking Random Masking in Self Distillation on ViT](https://arxiv.org/abs/2506.10582)
**中文标题：重新思考ViT自蒸馏中的随机掩码策略**

*Jihyeon Seong,Hyunkyung Han*

Main category: cs.CV

TL;DR: 本文探讨了在自蒸馏框架（如DINO）中随机掩码的作用，提出了一种非对称掩码策略，仅在学生的全局视图中应用随机掩码，从而保留关键语义信息并提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随机掩码在自蒸馏框架中常用于提升训练效率和正则化，但可能无意中消除关键语义信息。本文旨在研究如何优化掩码策略以保留信息并增强模型性能。

Method: 在DINO框架中，仅对学生的全局视图应用随机掩码，而保留学生的局部视图和教师的全局视图的原始形式。这种非对称设计利用多视图增强方案，保持干净的监督同时通过掩码输入引入鲁棒性。

Result: 在mini-ImageNet数据集上使用DINO-Tiny评估，结果显示该策略能生成更鲁棒和细粒度的注意力图，并提升下游任务性能。

Conclusion: 非对称随机掩码策略在自蒸馏框架中有效保留语义信息并增强模型鲁棒性，为掩码策略的优化提供了新思路。

摘要: 视觉变换器（ViTs）在广泛的视觉任务中表现出卓越的性能。特别是自蒸馏框架（如DINO）为这些进展做出了重要贡献。在此类框架中，随机掩码常用于提高训练效率和引入正则化。然而，最近的研究指出，不加区分的随机掩码可能无意中消除关键语义信息，这促使了更智能掩码策略的开发。本研究探讨了自蒸馏设置中随机掩码的作用，重点关注DINO框架。具体而言，我们仅对学生的全局视图应用随机掩码，同时保留学生的局部视图和教师的全局视图的原始形式。这一设计利用DINO的多视图增强方案，在保持干净监督的同时通过掩码输入引入鲁棒性。我们在mini-ImageNet数据集上使用DINO-Tiny评估了该方法，结果表明这种非对称设置下的随机掩码能生成更鲁棒和细粒度的注意力图，最终提升下游任务性能。

</details>


### [374] [Hierarchical Error Assessment of CAD Models for Aircraft Manufacturing-and-Measurement](https://arxiv.org/abs/2506.10594)
**中文标题：飞机制造与测量中CAD模型的分层误差评估**

*Jin Huang,Honghua Chen,Mingqiang Wei*

Main category: cs.CV

TL;DR: 本文提出了一种名为HEA-MM的分层误差评估框架，用于飞机CAD模型在制造与测量平台中的质量评估，通过全局、部件和特征三个层次进行误差分析，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 航空设备的核心特征是高质量，包括高性能、高稳定性和高可靠性。为了确保飞机CAD模型在制造过程中的精度，需要一种系统化的误差评估方法。

Method: HEA-MM框架使用结构光扫描仪获取工件3D测量数据，并通过全局、部件和特征三个层次进行误差分析。部件层次提出基于优化的基元细化方法，特征层次则通过两阶段算法检测圆形孔。

Result: 实验结果表明，HEA-MM框架能够有效评估飞机CAD模型的误差，并在全局、部件和特征层次上提供准确的误差分析。

Conclusion: HEA-MM框架为飞机CAD模型的制造与测量提供了一种系统化的误差评估方法，显著提升了质量控制的效率和精度。

摘要: 航空设备最核心的特征是高质量，包括高性能、高稳定性和高可靠性。本文提出了一种新颖的分层误差评估框架HEA-MM，用于飞机CAD模型在制造与测量平台中的质量评估。HEA-MM利用结构光扫描仪获取工件的全面3D测量数据，并将测量点云与参考CAD模型对齐，随后在三个层次（全局、部件和特征）进行误差分析。在全局层次，误差分析评估扫描点云与参考CAD模型的整体偏差。在部件层次，误差分析针对点云的基础面片进行，并提出了一种基于优化的基元细化方法，通过分割和合并操作细化粗糙基元。在特征层次，误差分析针对CAD模型中常见的圆形孔进行，提出了一种两阶段算法：首先通过张量投票算法识别边缘点，然后通过假设-聚类框架拟合多个圆，确保圆形特征的准确检测与分析。在多种飞机CAD模型上的实验结果表明了所提方法的有效性。

</details>


### [375] [Semantic-decoupled Spatial Partition Guided Point-supervised Oriented Object Detection](https://arxiv.org/abs/2506.10601)
**中文标题：语义解耦空间分区引导的点监督定向目标检测**

*Xinyuan Liu,Hang Xu,Yike Ma,Yucheng Zhang,Feng Dai*

Main category: cs.CV

TL;DR: 本文提出了一种名为SSP（语义解耦空间分区）的统一框架，通过结合规则驱动的先验注入和数据驱动的标签净化，解决了点监督定向目标检测中的样本分配不足和实例混淆问题。实验表明，SSP在多个数据集上表现优异，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感技术的进步推动了图像数据的增长，但高密度场景下的定向目标检测需要大量人工标注，成本高昂。现有的点监督方法由于基于固定规则的设计，存在样本分配不足和实例混淆的问题。

Method: SSP框架包含两个核心创新：1）基于像素级空间分区的样本分配，通过空间分区估计目标尺度的上下界并挖掘高质量正负样本；2）基于语义空间分区的框提取，通过语义图调制空间分区生成伪标签以监督下游检测器。

Result: 在DOTA-v1.0等数据集上，SSP在点监督下达到45.78%的mAP，优于SOTA方法PointOBB-v2 4.10%。与ORCNN和ReDet架构结合时，mAP分别达到47.86%和48.50%。

Conclusion: SSP通过结合规则驱动和数据驱动的方法，显著提升了点监督定向目标检测的性能，为高密度场景下的目标检测提供了高效解决方案。

摘要: 近年来，遥感技术的进步推动了图像数据的快速增长，使得定向目标检测技术迅速发展，但高密度场景下的人工标注成本高昂。点监督定向目标检测为遥感密集场景提供了一种经济高效的解决方案，但现有方法由于基于固定规则的设计，存在样本分配不足和实例混淆的问题。为解决这一问题，我们提出了SSP（语义解耦空间分区），一种结合规则驱动先验注入和数据驱动标签净化的统一框架。具体而言，SSP包含两项核心创新：1）基于像素级空间分区的样本分配，通过空间分区紧凑估计目标尺度的上下界，并挖掘高质量正样本和难负样本；2）基于语义空间分区的框提取，通过语义图调制的空间分区生成实例，并将其可靠地转换为边界框，形成伪标签以监督下游检测器的学习。在DOTA-v1.0等数据集上的实验表明，SSP在点监督下达到45.78%的mAP，优于SOTA方法PointOBB-v2 4.10%。此外，当与ORCNN和ReDet架构结合时，SSP框架的mAP分别达到47.86%和48.50%。代码已开源：https://github.com/antxinyuan/ssp。

</details>


### [376] [High-resolution efficient image generation from WiFi CSI using a pretrained latent diffusion model](https://arxiv.org/abs/2506.10605)
**中文标题：基于预训练潜在扩散模型的高分辨率WiFi CSI高效图像生成**

*Eshan Ramesh,Nishio Takayuki*

Main category: cs.CV

TL;DR: LatentCSI是一种利用预训练潜在扩散模型（LDM）从WiFi CSI测量生成物理环境图像的新方法，通过轻量级神经网络直接映射CSI振幅到LDM的潜在空间，结合文本引导实现高效高质量图像合成。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖复杂且计算密集的技术（如GANs），而LatentCSI旨在通过轻量级设计和预训练模型绕过像素空间生成挑战，提升效率和图像质量。

Method: 使用轻量级神经网络将CSI振幅直接映射到LDM的潜在空间，结合文本引导的扩散模型去噪，最后通过LDM预训练解码器生成高分辨率图像。

Result: 在公开数据集和自采集数据集上验证，LatentCSI在计算效率和感知质量上优于基线方法，并具备文本引导可控性。

Conclusion: LatentCSI通过结合预训练LDM和轻量级设计，实现了高效、高质量的图像生成，同时提供文本引导的灵活性。

摘要: 我们提出LatentCSI，一种利用预训练潜在扩散模型（LDM）从WiFi CSI测量生成物理环境图像的新方法。与依赖复杂且计算密集型技术（如GANs）的现有方法不同，我们的方法采用轻量级神经网络将CSI振幅直接映射到LDM的潜在空间。随后，我们在潜在表示上应用LDM的去噪扩散模型，并结合文本引导，最后通过LDM的预训练解码器生成高分辨率图像。这一设计绕过了像素空间图像生成的挑战，避免了传统图像到图像流程中显式的图像编码阶段，实现了高效且高质量的图像合成。我们在两个数据集上验证了该方法：一个是用现成WiFi设备和相机采集的宽带CSI数据集；另一个是公开可用的MM-Fi数据集的子集。结果表明，LatentCSI在计算效率和感知质量上均优于直接在真实图像上训练的复杂度相当的基线方法，同时通过其独特的文本引导可控性提供了实用优势。

</details>


### [377] [MSTAR: Box-free Multi-query Scene Text Retrieval with Attention Recycling](https://arxiv.org/abs/2506.10609)
**中文标题：MSTAR：基于注意力循环的无框多查询场景文本检索**

*Liang Yin,Xudong Xie,Zhang Li,Xiang Bai,Yuliang Liu*

Main category: cs.CV

TL;DR: MSTAR提出了一种无需边界框标注的多查询场景文本检索方法，通过动态捕捉多粒度文本表示和风格感知指令，显著提升了检索性能，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有场景文本检索方法依赖昂贵的边界框标注，且难以统一多种查询类型以满足多样化需求。MSTAR旨在解决这些问题，提供一种无需标注的高效检索方案。

Method: MSTAR采用渐进式视觉嵌入动态捕捉文本的多粒度表示，结合风格感知指令统一自由文本查询，并引入多实例匹配模块增强视觉-语言对齐。此外，构建了首个多查询场景文本检索基准MQTR数据集。

Result: MSTAR在七个公共数据集和MQTR数据集上表现优异，在Total-Text上MAP提升6.4%，在MQTR上平均提升8.5%，显著优于现有方法。

Conclusion: MSTAR通过无需边界框标注的方法和高效的多查询处理能力，显著提升了场景文本检索性能，为未来研究提供了新方向。

摘要: 场景文本检索在精准文本定位的辅助下取得了显著进展。然而，现有方法通常需要昂贵的边界框标注用于训练，且大多采用定制化检索策略，难以统一多种查询类型以满足多样化需求。为解决这些问题，我们提出了基于注意力循环的无框多查询场景文本检索方法（MSTAR）。它通过渐进式视觉嵌入动态捕捉文本的多粒度表示，并结合风格感知指令统一自由文本查询。此外，还引入了多实例匹配模块以增强视觉-语言对齐。我们还构建了首个多查询场景文本检索基准数据集MQTR，包含四种查询类型和16k张图像。大量实验表明，我们的方法在七个公共数据集和MQTR数据集上均表现优异。值得注意的是，MSTAR在Total-Text上的MAP比之前的最优模型提升了6.4%，同时消除了边界框标注成本。在MQTR基准上，MSTAR平均比之前模型高出8.5%。代码和数据集已发布于https://github.com/yingift/MSTAR。

</details>


### [378] [TexTailor: Customized Text-aligned Texturing via Effective Resampling](https://arxiv.org/abs/2506.10612)
**中文标题：TexTailor：通过有效重采样实现定制化的文本对齐纹理生成**

*Suin Lee,Dae-Shik Kim*

Main category: cs.CV

TL;DR: TexTailor提出了一种通过有效重采样生成与文本描述一致的对象纹理的新方法，解决了现有方法在多视角下纹理属性逐渐偏移的问题，并通过自适应调整相机位置提升纹理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的纹理合成方法在多视角下存在纹理属性逐渐偏移的问题，主要原因是扩散过程中对已合成纹理信息的整合不足以及预定义相机位置未考虑对象几何形状。TexTailor旨在解决这些问题。

Method: TexTailor采用重采样方案在扩散过程中整合已合成纹理信息，并对深度感知扩散模型进行微调。此外，提出性能保持损失以解决训练图像不足的问题，并自适应调整相机位置以提升纹理一致性。

Result: 在Objaverse和ShapeNet汽车数据集上的实验表明，TexTailor在合成视角一致纹理方面优于现有方法。

Conclusion: TexTailor通过有效重采样和自适应相机调整，显著提升了多视角下纹理合成的质量和一致性。

摘要: 我们提出了TexTailor，一种从文本描述生成一致对象纹理的新方法。现有的文本到纹理合成方法利用深度感知扩散模型逐步生成图像并在预定义的多个视角下合成纹理。然而，由于（1）扩散过程中对每个视角下已合成纹理信息的整合不足，以及（2）纹理合成过程的自动回归特性，这些方法会导致纹理属性在视角间逐渐偏移。此外，预定义的相机位置选择未考虑对象几何形状，限制了从不同视角合成的纹理信息的有效利用，最终降低了整体纹理一致性。在TexTailor中，我们通过（1）应用重采样方案在扩散过程中重复整合已合成纹理信息，以及（2）对这些重采样纹理微调深度感知扩散模型，解决了这些问题。在此过程中，我们发现仅使用少量训练图像会限制模型生成与条件对齐的高保真图像的原始能力，因此提出了性能保持损失以缓解这一问题。此外，我们通过基于对象几何形状自适应调整相机位置，改进了视角一致纹理的合成。在Objaverse数据集子集和ShapeNet汽车数据集上的实验表明，TexTailor在合成视角一致纹理方面优于现有方法。TexTailor的源代码可在https://github.com/Adios42/Textailor获取。

</details>


### [379] [Anatomy-Grounded Weakly Supervised Prompt Tuning for Chest X-ray Latent Diffusion Models](https://arxiv.org/abs/2506.10633)
**中文标题：基于解剖学知识的弱监督提示调优用于胸部X光潜在扩散模型**

*Konstantinos Vilouras,Ilias Stogiannidis,Junyu Yan,Alison Q. O'Neil,Sotirios A. Tsaftaris*

Main category: cs.CV

TL;DR: 本文提出了一种基于解剖学知识的弱监督提示调优方法，用于改进胸部X光潜在扩散模型的多模态对齐，使其能更好地适应下游任务（如短语定位），并在标准数据集上取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 潜在扩散模型在自然图像领域表现出色，但在医学影像中因数据有限而研究较少。本文旨在解决胸部X光潜在扩散模型在自由文本放射报告与扫描图像对齐方面的不足。

Method: 提出了一种微调框架，通过弱监督提示调优改进预训练模型的多模态对齐能力，使其适用于下游任务。

Result: 在标准数据集（MS-CXR）上达到了最优性能，并在分布外数据（VinDr-CXR）上表现出鲁棒性。

Conclusion: 该方法显著提升了潜在扩散模型在医学影像中的多模态对齐能力，为下游任务提供了高效解决方案。

摘要: 近年来，潜在扩散模型在文本引导的图像合成中表现出色。在自然（RGB）图像领域，已有研究表明此类模型可通过极少监督适应多种视觉-语言下游任务。然而，在医学影像领域，由于数据有限（如隐私问题），文本到图像的潜在扩散模型研究较少。本文以胸部X光为例，首先证明标准文本条件潜在扩散模型未能学习自由文本放射报告与扫描图像中临床相关信息的对齐。为解决这一问题，我们提出了一种微调框架，改进预训练模型的多模态对齐能力，使其能高效适应下游任务（如短语定位）。我们的方法在标准基准数据集（MS-CXR）上达到了最优性能，并在分布外数据（VinDr-CXR）上表现出鲁棒性。代码将公开提供。

</details>


### [380] [Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models](https://arxiv.org/abs/2506.10634)
**中文标题：对称流匹配：基于分数生成模型的统一图像生成、分割与分类**

*Francisco Caetano,Christiaan Viviers,Peter H. N. De With,Fons van der Sommen*

Main category: cs.CV

TL;DR: 本文提出了一种名为SymmFlow的对称流匹配方法，统一了图像生成、语义分割和分类任务。通过双向一致性和保留语义信息的设计，SymmFlow在多项任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的流匹配方法通常专注于单一任务（如生成或分割），缺乏统一框架。本文旨在提出一种能够同时处理生成、分割和分类任务的对称流匹配方法，以提高效率和性能。

Method: SymmFlow通过对称学习目标联合建模正向和反向变换，确保双向一致性，同时保留生成多样性。引入新的训练目标以显式保留语义信息，支持一步分割和分类，无需迭代优化。

Result: 实验表明，SymmFlow在CelebAMask-HQ和COCO-Stuff上分别实现了11.9和7.0的FID分数（仅需25步推理），并在语义分割和分类任务中表现优异。

Conclusion: SymmFlow为生成、分割和分类任务提供了一个统一的框架，展示了卓越的性能和灵活性，为多任务学习提供了新思路。

摘要: 流匹配已成为学习分布间连续变换的强大框架，支持高保真生成建模。本文提出对称流匹配（SymmFlow），通过对称学习目标统一了语义分割、分类和图像生成任务。SymmFlow联合建模正向和反向变换，确保双向一致性的同时保留生成多样性。新训练目标显式保留语义信息，支持一步分割和分类，无需迭代优化。与以往严格一对一映射方法不同，SymmFlow支持灵活条件输入（像素级和图像级标签）。实验表明，SymmFlow在CelebAMask-HQ和COCO-Stuff上分别实现了11.9和7.0的FID分数（仅需25步推理），并在分割和分类任务中表现优异。代码将公开。

</details>


### [381] [GigaVideo-1: Advancing Video Generation via Automatic Feedback with 4 GPU-Hours Fine-Tuning](https://arxiv.org/abs/2506.10639)
**中文标题：GigaVideo-1：通过4 GPU小时的自动反馈微调推进视频生成**

*Xiaoyi Bao,Jindi Lv,Xiaofeng Wang,Zheng Zhu,Xinze Chen,YuKun Zhou,Jiancheng Lv,Xingang Wang,Guan Huang*

Main category: cs.CV

TL;DR: GigaVideo-1提出了一种高效的视频生成微调框架，通过自动反馈而非人工标注或大量计算资源，显著提升了视频生成质量。仅需4 GPU小时，平均性能提升约4%。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在视频生成质量上虽有进步，但需微调以提升实例保留、运动合理性等维度。现有方法依赖人工标注和大量计算资源，实用性受限。

Method: GigaVideo-1通过自动反馈解锁预训练视频扩散模型的潜力，设计了基于提示的数据引擎和奖励引导的训练策略，优化数据和训练过程。

Result: 在VBench-2.0基准测试中，GigaVideo-1在17个评估维度上平均提升约4%，仅需4 GPU小时，且无需人工标注或大量真实数据。

Conclusion: GigaVideo-1展示了无需人工监督和高效计算的视频生成微调框架的有效性，为实际应用提供了可行方案。

摘要: 尽管扩散模型的最新进展显著提升了视频生成质量，但这些模型仍需微调以改进实例保留、运动合理性、构图和物理合理性等维度。现有微调方法通常依赖人工标注和大规模计算资源，限制了其实用性。本文提出GigaVideo-1，一种高效的微调框架，无需额外人工监督即可提升视频生成质量。GigaVideo-1通过自动反馈而非外部高质量数据注入，释放预训练视频扩散模型的潜在能力。具体而言，我们关注微调过程中的两个关键方面：数据和优化。为改进微调数据，我们设计了基于提示的数据引擎，构建多样化、针对弱点的训练样本。在优化方面，我们引入奖励引导的训练策略，利用预训练视觉语言模型的反馈和真实性约束自适应加权样本。我们在VBench-2.0基准测试中以Wan2.1为基线评估GigaVideo-1，覆盖17个评估维度。实验表明，GigaVideo-1仅需4 GPU小时即可在几乎所有维度上平均提升约4%的性能。无需人工标注和极少真实数据，GigaVideo-1展示了高效性和有效性。代码、模型和数据将公开提供。

</details>


### [382] [PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis](https://arxiv.org/abs/2506.10669)
**中文标题：PiPViT：基于图像块的可视化可解释原型用于视网膜图像分析**

*Marzieh Oghbaie,Teresa Araújoa,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: PiPViT是一种基于视觉Transformer的原型模型，通过捕捉图像块间的长距离依赖关系学习可解释的原型，用于视网膜图像分析，在保持竞争性能的同时提供更直观的解释。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的方法在医学图像中学习到的原型过于细粒度，难以与人类可理解的生物标志物对应，且无法有效反映病变范围。PiPViT旨在解决这些问题，提供更直观且临床相关的解释。

Method: PiPViT利用视觉Transformer（ViT）捕捉图像块间的长距离依赖关系，学习鲁棒且可解释的原型，仅使用图像级标签即可近似病变范围。结合对比学习和多分辨率输入处理，实现跨尺度的生物标志物定位。

Result: 在四个视网膜OCT图像分类数据集上，PiPViT性能与最先进方法相当，同时提供更具语义和临床意义的解释。测试集验证表明其原型具有临床相关性。

Conclusion: PiPViT能够透明解释其决策，帮助临床医生理解诊断结果，为医学图像分析提供了一种可解释的解决方案。

摘要: 背景与目标：基于原型的方法通过学习细粒度的部分原型提高可解释性，但其在输入像素空间的可视化并不总是与人类可理解的生物标志物一致。此外，现有方法通常学习过于细粒度的原型，在医学图像中难以解释生物标志物和病变的范围。方法：为解决这些问题，我们提出PiPViT（基于图像块的可视化可解释原型），一种本质可解释的原型模型。利用视觉Transformer（ViT），PiPViT捕捉图像块间的长距离依赖关系，学习鲁棒且人类可解释的原型，仅使用图像级标签即可近似病变范围。此外，PiPViT结合对比学习和多分辨率输入处理，实现跨尺度的生物标志物定位。结果：在四个视网膜OCT图像分类数据集上，PiPViT性能与最先进方法相当，同时提供更具意义的解释。测试集定量评估证实学习的原型具有语义和临床相关性。我们相信PiPViT能够透明解释其决策，帮助临床医生理解诊断结果。GitHub页面：https://github.com/marziehoghbaie/PiPViT

</details>


### [383] [Enhancing Deepfake Detection using SE Block Attention with CNN](https://arxiv.org/abs/2506.10683)
**中文标题：利用SE注意力模块增强CNN的Deepfake检测**

*Subhram Dasgupta,Janelle Mason,Xiaohong Yuan,Olusola Odeyomi,Kaushik Roy*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的CNN模型，结合SE注意力模块用于Deepfake检测，模型体积小且性能优异。


<details>
  <summary>Details</summary>
Motivation: Deepfake技术利用AI生成高度逼真的伪造内容，威胁信息真实性和安全性，传统检测方法难以应对。现有模型通常体积庞大，存储和内存消耗高，因此需要一种轻量高效的解决方案。

Method: 提出了一种结合SE注意力模块的轻量级CNN模型。SE模块通过动态通道特征重标定，强调有用特征并抑制无用特征，提升模型效率。该模块与简单顺序模型结合用于Deepfake检测。

Result: 模型在Style GAN数据集上实现了94.14%的分类准确率和0.985的AUC-ROC分数，性能与现有模型相当但体积更小。

Conclusion: 该方法为Deepfake检测提供了一种高效、轻量且可扩展的解决方案，能以最小计算资源应对挑战。

摘要: 在数字时代，Deepfake利用先进的人工智能技术生成高度逼真的伪造内容，威胁信息的真实性和安全性。这些复杂的伪造内容超越了传统检测方法的复杂性和真实性。为解决这一问题，我们旨在利用前沿的深度学习方法设计一种创新的Deepfake检测模型。然而，大多数用于Deepfake检测的模型体积庞大，导致存储和内存消耗高。在本研究中，我们提出了一种结合SE注意力模块的轻量级卷积神经网络（CNN）用于Deepfake检测。SE模块通过动态通道特征重标定，强调有用特征并抑制无用特征，从而形成更高效的学习模块。该模块与简单顺序模型结合用于Deepfake检测。模型体积更小，且在Deepfake检测任务中与现有模型性能相当。模型在Diverse Fake Face Dataset的Style GAN数据集上实现了94.14%的分类准确率和0.985的AUC-ROC分数。我们提出的方法为应对Deepfake挑战提供了一种高效、可扩展的解决方案，能以最小计算资源实现数字内容验证。

</details>


### [384] [Unsourced Adversarial CAPTCHA: A Bi-Phase Adversarial CAPTCHA Framework](https://arxiv.org/abs/2506.10685)
**中文标题：无源对抗CAPTCHA：一种双阶段对抗CAPTCHA框架**

*Xia Du,Xiaoyuan Liu,Jizhe Zhou,Zheng Lin,Chi-man Pun,Zhe Chen,Wei Ni,Jun Luo*

Main category: cs.CV

TL;DR: 本文提出了一种新型的无源对抗CAPTCHA框架（UAC），通过大型语言模型生成高保真对抗样本，支持定向和非定向攻击，实验表明其攻击成功率高且生成的CAPTCHA难以被人类和DNN区分。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习的快速发展，传统CAPTCHA方案日益容易受到基于深度神经网络的自动化攻击。现有对抗攻击方法依赖原始图像特征，导致失真且难以适用于缺乏初始输入图像的场景。

Method: 提出无源对抗CAPTCHA（UAC）框架，利用大型语言模型生成对抗样本；针对定向攻击，采用EDICT方法优化扩散模型的双重潜在变量；针对非定向攻击（尤其是黑盒场景），提出双路径优化策略（BP-UAC），结合多模态梯度和双路径优化实现高效误分类。

Result: 实验表明，BP-UAC在多种系统中实现了高攻击成功率，生成的CAPTCHA既自然又难以被人类和DNN区分。

Conclusion: UAC框架通过生成高保真对抗样本，显著提升了CAPTCHA的多样性和攻击效果，为对抗深度学习攻击提供了新思路。

摘要: 随着深度学习的快速发展，传统CAPTCHA方案日益容易受到基于深度神经网络（DNNs）的自动化攻击。现有的对抗攻击方法通常依赖原始图像特征，导致失真并阻碍人类理解，同时在缺乏初始输入图像的场景中适用性有限。为解决这些问题，我们提出了无源对抗CAPTCHA（UAC），这是一种新颖的框架，通过攻击者指定的文本提示生成高保真对抗样本。借助大型语言模型（LLM），UAC增强了CAPTCHA的多样性，并支持定向和非定向攻击。对于定向攻击，EDICT方法优化扩散模型中的双重潜在变量以获得更优的图像质量。在非定向攻击中，尤其是黑盒场景下，我们提出了双路径无源对抗CAPTCHA（BP-UAC），这是一种两步优化策略，利用多模态梯度和双路径优化实现高效误分类。实验表明，BP-UAC在多种系统中实现了高攻击成功率，生成的CAPTCHA既自然又难以被人类和DNN区分。

</details>


### [385] [Underage Detection through a Multi-Task and MultiAge Approach for Screening Minors in Unconstrained Imagery](https://arxiv.org/abs/2506.10689)
**中文标题：通过多任务多年龄方法在无约束图像中筛查未成年人的检测**

*Christopher Gaul,Eduardo Fidalgo,Enrique Alegre,Rocío Alaiz Rodríguez,Eri Pérez Corral*

Main category: cs.CV

TL;DR: 本文提出了一种多任务多年龄方法，通过冻结的FaRL视觉语言骨干网络和共享特征的MLP，结合年龄回归和四个未成年分类头，解决了未成年检测中的数据不平衡和分布偏移问题。通过α加权焦点损失和年龄平衡采样，模型在ASORES-39k和ASWIFT-20k测试集上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 在无约束图像中准确自动筛查未成年人需要模型对分布偏移具有鲁棒性，并能解决公开数据中儿童样本不足的问题。

Method: 提出了一种多任务架构，基于冻结的FaRL视觉语言骨干网络和共享特征的两层MLP，结合年龄回归和四个未成年分类头（12、15、18、21岁）。通过α加权焦点损失和年龄平衡采样解决类别不平衡问题，并引入年龄间隙去除边缘案例。

Result: 在ASORES-39k测试集上，年龄均方根误差从5.733降至5.656，18岁以下检测F2分数从0.801提升至0.857。在ASWIFT-20k测试集上，召回率接近0.99，F2分数从0.742提升至0.833。12岁和15岁以下任务的F2分数分别从0.666提升至0.955和0.689提升至0.916。

Conclusion: 该方法在未成年检测任务中表现出强大的泛化能力，尤其是在分布偏移和极端条件下。

摘要: 在无约束图像中准确自动筛查未成年人需要模型对分布偏移具有鲁棒性，并能解决公开数据中儿童样本不足的问题。为解决这些问题，我们提出了一种多任务架构，基于冻结的FaRL视觉语言骨干网络和共享特征的两层MLP，结合年龄回归和四个未成年分类头（12、15、18、21岁）。通过α加权焦点损失和年龄平衡采样解决类别不平衡问题，并引入年龄间隙去除边缘案例。

此外，我们提出了严格的评估标准，包括303k训练图像和110k测试图像的“总体未成年基准”，定义了去除噪声域的“ASORES-39k”限制测试和模拟极端姿态（>45度）、表情和低图像质量的“ASWIFT-20k”测试。

在清理后的数据集上训练的多年龄模型“F”在ASORES-39k测试集上将年龄均方根误差从5.733降至5.656，18岁以下检测F2分数从0.801提升至0.857。在ASWIFT-20k测试集上，召回率接近0.99，F2分数从0.742提升至0.833。12岁和15岁以下任务的F2分数分别从0.666提升至0.955和0.689提升至0.916，展示了在分布偏移下的强大泛化能力。

</details>


### [386] [Continual Hyperbolic Learning of Instances and Classes](https://arxiv.org/abs/2506.10710)
**中文标题：实例与类的持续双曲学习**

*Melika Ayoughi,Mina Ghadimi Atigh,Mohammad Mahdi Derakhshani,Cees G. M. Snoek,Pascal Mettes,Paul Groth*

Main category: cs.CV

TL;DR: 本文提出了一种名为HyperCLIC的持续学习算法，利用双曲空间建模实例和类的层次结构，以同时处理实例和类的持续学习任务，并在动态真实世界环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实应用（如机器人和自动驾驶汽车）需要模型同时处理实例和类的持续学习任务。传统方法仅关注实例或类的分类，无法满足多粒度需求。因此，本文提出了一种新的任务和解决方案。

Method: 提出HyperCLIC算法，利用双曲空间建模层次结构，结合双曲分类和蒸馏目标，实现层次关系的持续嵌入。同时引入持续层次化指标评估性能。

Result: 在动态真实世界数据集EgoObjects上验证，HyperCLIC在多粒度任务中表现优异，提升了层次化泛化能力。

Conclusion: HyperCLIC通过双曲空间建模层次关系，有效解决了实例和类同时持续学习的挑战，为复杂场景提供了新思路。

摘要: 持续学习传统上仅关注实例或类的分类，但现实应用（如机器人和自动驾驶汽车）需要模型同时处理两者。为模拟真实场景，我们提出了同时学习实例和类的任务。这一任务要求模型适应多粒度需求，平衡细粒度实例识别与粗粒度类泛化。本文发现类和实例天然形成层次结构。为建模这些层次关系，我们提出HyperCLIC算法，利用双曲空间（因其能以低失真和紧凑嵌入表示树状结构）的优势。该框架结合双曲分类和蒸馏目标，实现层次关系的持续嵌入。为评估多粒度性能，我们引入了持续层次化指标。在EgoObjects数据集（唯一捕捉动态真实环境中层次化对象识别复杂性的数据集）上验证了方法的有效性。实验结果表明，HyperCLIC在多粒度任务中表现优异，提升了层次化泛化能力。

</details>


### [387] [Uncertainty-Masked Bernoulli Diffusion for Camouflaged Object Detection Refinement](https://arxiv.org/abs/2506.10712)
**中文标题：基于不确定性掩蔽伯努利扩散的伪装目标检测细化**

*Yuqi Shen,Fengyang Xiao,Sujie Hu,Youwei Pang,Yifan Pu,Chengyu Fang,Xiu Li,Chunming He*

Main category: cs.CV

TL;DR: 本文提出了一种名为UMBD的生成式细化框架，专门用于伪装目标检测（COD）。通过不确定性引导的掩蔽机制和伯努利扩散，UMBD能够有针对性地改进分割质量较差的区域，同时保留正确分割的部分。实验表明，UMBD在多个COD基准测试中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 伪装目标检测（COD）由于目标与背景之间的视觉差异较小而具有挑战性。尽管现有方法已取得显著进展，但后处理细化仍有较大潜力未被充分挖掘。本文旨在填补这一空白，提出一种专门用于COD的生成式细化框架。

Method: 本文提出了不确定性掩蔽伯努利扩散（UMBD）模型，通过不确定性引导的掩蔽机制选择性应用伯努利扩散，改进分割质量较差的区域。同时设计了混合不确定性量化网络（HUQNet），通过多分支架构融合多源不确定性，提高估计精度，从而在生成采样过程中提供自适应指导。UMBD可与多种现有基于编码器-解码器的COD模型无缝集成。

Result: 在多个COD基准测试中，UMBD实现了平均5.5%的MAE提升和3.2%的加权F-measure提升，且计算开销较小。

Conclusion: UMBD作为一种生成式细化框架，显著提升了COD的性能，同时保持了计算效率。其不确定性引导的掩蔽机制和伯努利扩散方法为COD的后处理细化提供了新的思路。

摘要: 伪装目标检测（COD）由于目标与背景之间的视觉差异较小而具有固有挑战性。尽管现有方法已取得显著进展，但后处理细化仍有较大潜力未被充分挖掘。为解决这一局限性，我们提出了不确定性掩蔽伯努利扩散（UMBD）模型，这是首个专门为COD设计的生成式细化框架。UMBD引入了一种不确定性引导的掩蔽机制，选择性对分割质量较差的残差区域应用伯努利扩散，从而实现有针对性的细化，同时保留正确分割的区域。为支持这一过程，我们设计了混合不确定性量化网络（HUQNet），采用多分支架构并融合多源不确定性以提高估计精度，从而在生成采样过程中提供自适应指导。所提出的UMBD框架可与多种现有基于编码器-解码器的COD模型无缝集成，结合其判别能力和基于扩散的细化生成优势。在多个COD基准测试上的广泛实验表明，UMBD实现了性能的持续提升，平均MAE提升5.5%，加权F-measure提升3.2%，且计算开销较小。代码将公开发布。

</details>


### [388] [Deep Learning-based Multi Project InP Wafer Simulation for Unsupervised Surface Defect Detection](https://arxiv.org/abs/2506.10713)
**中文标题：基于深度学习的多项目InP晶圆模拟用于无监督表面缺陷检测**

*Emílio Dolgener Cantú,Rolf Klemens Wittmann,Oliver Abdeen,Patrick Wagner,Wojciech Samek,Moritz Baier,Sebastian Lapuschkin*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的多项目InP晶圆模拟方法，用于无监督表面缺陷检测。通过生成合成黄金标准，解决了半导体制造中因缺乏标准模板而依赖人工检测的问题。


<details>
  <summary>Details</summary>
Motivation: 半导体制造中，磷化铟（InP）多项目晶圆的生产规模小、设计变异性高，导致缺乏黄金标准模板，缺陷检测依赖人工且效率低下。本文旨在解决这一问题。

Method: 提出了一种基于深度神经网络的方法，通过训练模型从CAD数据生成逼真的InP晶圆图像，从而合成黄金标准。评估了多种训练目标，并在合成数据和实际晶圆照片上验证了模拟图像的质量。

Result: 深度学习方法优于基于决策树的基线方法，能够从CAD计划中生成任意区域的“模拟黄金芯片”，显著提高了缺陷检测效率。

Conclusion: 该方法为半导体制造中的缺陷检测提供了一种高效的无监督解决方案，通过合成黄金标准减少了人工干预的需求。

摘要: 半导体制造中的质量管理通常依赖于已知黄金标准的模板匹配。对于磷化铟（InP）多项目晶圆制造，由于生产规模小和设计变异性高，通常缺乏此类黄金标准，缺陷检测因此依赖人工且效率低下。本文通过提出一种方法来解决这一挑战，该方法利用深度神经网络从CAD数据生成合成黄金标准，模拟逼真的InP晶圆图像。我们评估了多种训练目标，并在合成数据和实际晶圆照片上验证了模拟图像的质量。基于深度学习的方法优于基于决策树的基线方法，能够从CAD计划中生成任意区域的“模拟黄金芯片”，从而实现更高效的缺陷检测。我们将该方法应用于模板匹配流程，以展示其在表面缺陷检测中的实际效用。

</details>


### [389] [IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain](https://arxiv.org/abs/2506.10730)
**中文标题：IQE-CLIP：医学领域中基于实例感知查询嵌入的零样本/少样本异常检测**

*Hong Huang,Weixiang Sun,Zhijian Wu,Jingwen Niu,Donghuan Lu,Xian Wu,Yefeng Zheng*

Main category: cs.CV

TL;DR: IQE-CLIP是一种针对医学领域零样本/少样本异常检测的新框架，通过结合文本和实例感知的视觉信息生成查询嵌入，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的方法在医学领域的零样本/少样本异常检测中存在局限性，如依赖特定场景的提示设计且难以区分正常与异常实例。本文旨在解决这些问题。

Method: 提出IQE-CLIP框架，引入基于类和可学习的提示令牌，并设计实例感知查询模块，提取多模态区域级上下文信息，生成异常敏感的嵌入。

Result: 在六个医学数据集上的实验表明，IQE-CLIP在零样本和少样本设置下均达到最先进性能。

Conclusion: IQE-CLIP通过结合文本和视觉信息，显著提升了医学领域异常检测的效果，为未来研究提供了新方向。

摘要: 近年来，如CLIP等视觉语言模型显著提升了零样本和少样本异常检测（ZFSAD）任务的性能。然而，大多数现有基于CLIP的方法假设已知类别信息，并依赖针对特定场景设计的提示。尽管这些文本提示在文本空间中捕捉了语义信息，但它们在联合嵌入空间中往往难以区分正常与异常实例。此外，大多数ZFSAD方法聚焦于工业领域，对医学任务的探索有限。为解决这些问题，我们提出IQE-CLIP，一种用于医学领域ZFSAD的新框架。我们表明，结合文本和实例感知视觉信息的查询嵌入是更有效的异常指标。具体而言，我们引入基于类和可学习的提示令牌，以更好地将CLIP适配到医学场景。此外，我们设计了一个实例感知查询模块，从两种模态中提取区域级上下文信息，从而生成异常敏感的嵌入。在六个医学数据集上的广泛实验表明，IQE-CLIP在零样本和少样本设置下均达到最先进性能。代码和数据可在\href{https://github.com/hongh0/IQE-CLIP/}{此链接}获取。

</details>


### [390] [PosterCraft: Rethinking High-Quality Aesthetic Poster Generation in a Unified Framework](https://arxiv.org/abs/2506.10741)
**中文标题：PosterCraft：重新思考高质量美学海报生成的统一框架**

*SiXiang Chen,Jianyu Lai,Jialin Gao,Tian Ye,Haoyu Chen,Hengyu Shi,Shitong Shao,Yunlong Lin,Song Fei,Zhaohu Xing,Yeying Jin,Junfeng Luo,Xiaoming Wei,Lei Zhu*

Main category: cs.CV

TL;DR: PosterCraft是一个统一的框架，用于生成高质量美学海报，通过多阶段优化流程（文本渲染、区域感知微调、美学文本强化学习和联合视觉语言反馈）显著提升渲染精度、布局一致性和视觉吸引力。


<details>
  <summary>Details</summary>
Motivation: 生成美学海报比简单设计图像更具挑战性，需要精确的文本渲染、抽象艺术内容、布局和风格的无缝整合。现有方法依赖模块化流程和固定布局，限制了模型的创造力和灵活性。

Method: PosterCraft采用多阶段优化流程：1) 在Text-Render-2M数据集上进行大规模文本渲染优化；2) 在HQ-Poster100K上进行区域感知监督微调；3) 通过最佳偏好优化进行美学文本强化学习；4) 联合视觉语言反馈细化。每个阶段都有自动化数据构建流程支持。

Result: PosterCraft在渲染精度、布局一致性和视觉吸引力方面显著优于开源基线，接近最先进的商业系统水平。

Conclusion: PosterCraft通过统一的框架和多阶段优化流程，成功解决了美学海报生成中的关键挑战，为高质量海报生成提供了新思路。

摘要: 生成美学海报比简单设计图像更具挑战性：它不仅需要精确的文本渲染，还需要无缝整合抽象艺术内容、引人注目的布局和整体风格和谐。为此，我们提出了PosterCraft，一个统一的框架，摒弃了先前的模块化流程和固定的预定义布局，允许模型自由探索连贯且视觉吸引人的构图。PosterCraft采用精心设计的级联工作流程来优化高质量美学海报的生成：(i) 在我们新引入的Text-Render-2M数据集上进行大规模文本渲染优化；(ii) 在HQ-Poster100K上进行区域感知监督微调；(iii) 通过最佳偏好优化进行美学文本强化学习；(iv) 联合视觉语言反馈细化。每个阶段都有针对其特定需求的全自动化数据构建流程支持，无需复杂的架构修改即可实现稳健训练。通过多项实验评估，PosterCraft在渲染精度、布局一致性和整体视觉吸引力方面显著优于开源基线，接近最先进商业系统的质量。我们的代码、模型和数据集可在项目页面找到：https://ephemeral182.github.io/PosterCraft

</details>


### [391] [Stroke-based Cyclic Amplifier: Image Super-Resolution at Arbitrary Ultra-Large Scales](https://arxiv.org/abs/2506.10774)
**中文标题：基于笔画的循环放大器：任意超大规模图像超分辨率**

*Wenhao Guo,Peng Lu,Xujun Peng,Zhaoran Zhao,Sheng Li*

Main category: cs.CV

TL;DR: 提出了一种基于笔画的循环放大器（SbCA）模型，用于解决超大规模图像超分辨率任务中的性能下降问题，通过分解图像为矢量笔画并循环放大，显著提升了超分辨率图像的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的任意尺度图像超分辨率方法在超出训练数据范围的放大倍数时性能显著下降，导致图像模糊。为了解决这一问题，本文提出了一种统一模型SbCA，专注于超大规模放大任务。

Method: SbCA模型通过笔画矢量放大器将图像分解为矢量笔画进行放大，并通过细节补全模块恢复缺失细节。采用循环策略迭代优化细节，仅需一次训练即可适用于所有放大倍数。

Result: 实验表明，SbCA在超大规模放大任务（如×100）中显著优于现有方法，消除了伪影、噪声和模糊，生成高质量的超分辨率图像。

Conclusion: SbCA模型有效解决了分布漂移问题，为超大规模图像超分辨率提供了一种高效且高质量的解决方案。

摘要: 现有的任意尺度图像超分辨率（ASISR）方法在放大倍数超出训练数据范围时性能显著下降，导致严重模糊。为解决这一问题，我们提出了一种统一模型——基于笔画的循环放大器（SbCA），用于超大规模放大任务。SbCA的核心是笔画矢量放大器，它将图像分解为一系列矢量笔画进行放大。随后，细节补全模块恢复缺失细节，确保高保真图像重建。通过循环策略，我们利用这一统一的SbCA模型迭代优化细节，仅需一次训练即可适用于所有放大倍数，同时保持子尺度在训练范围内。我们的方法有效解决了分布漂移问题，消除了伪影、噪声和模糊，生成了高质量的超分辨率图像。在合成和真实数据集上的实验验证表明，我们的方法在超大规模放大任务（如×100）中显著优于现有方法，视觉质量远超当前最先进技术。

</details>


### [392] [SlotPi: Physics-informed Object-centric Reasoning Models](https://arxiv.org/abs/2506.10778)
**中文标题：SlotPi：基于物理知识的对象中心推理模型**

*Jian Li,Wan Han,Ning Lin,Yu-Liang Zhan,Ruizhi Chengze,Haining Wang,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Hao Sun*

Main category: cs.CV

TL;DR: SlotPi是一种基于物理知识的对象中心推理模型，通过整合哈密顿原理和时空预测模块，解决了动态模拟中物理知识缺失和模型适应性验证不足的问题，并在预测和视觉问答任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前对象中心动态模拟方法虽取得进展，但忽视了物理知识的整合和模型在多样化场景中的适应性验证。人类通过观察世界获取物理知识并应用于动态推理，而现有模型缺乏类似能力，尤其是在涉及流体和物体交互的场景中。

Method: SlotPi结合了基于哈密顿原理的物理模块和时空预测模块，用于动态预测。通过实验验证了模型在基准数据集和流体数据集上的预测和视觉问答能力，并创建了一个包含物体交互、流体动力学和流体-物体交互的真实世界数据集。

Result: SlotPi在预测和视觉问答任务中表现出色，尤其是在流体和物体交互场景中。模型在多样化数据集上的稳健性能证明了其强大的适应性。

Conclusion: SlotPi通过整合物理知识和动态预测模块，显著提升了对象中心推理模型的性能，为开发更先进的世界模型奠定了基础。

摘要: 通过视觉观察理解和推理受物理规律支配的动态过程，类似于人类在现实世界中的能力，具有重大挑战。目前，模拟人类行为的对象中心动态模拟方法取得了显著进展，但忽视了两个关键方面：1）将物理知识整合到模型中。人类通过观察世界获取物理知识，并将其应用于准确推理各种动态场景；2）验证模型在多样化场景中的适应性。现实世界中的动态过程，尤其是涉及流体和物体的场景，要求模型不仅能捕捉物体交互，还能模拟流体流动特性。为解决这些问题，我们提出了SlotPi，一种基于物理知识的对象中心推理模型。SlotPi将基于哈密顿原理的物理模块与时空预测模块相结合，用于动态预测。我们的实验突出了模型在基准数据集和流体数据集上的预测和视觉问答任务中的优势。此外，我们创建了一个包含物体交互、流体动力学和流体-物体交互的真实世界数据集，并在其上验证了模型的性能。模型在所有数据集上的稳健表现证明了其强大的适应性，为开发更先进的世界模型奠定了基础。

</details>


### [393] [Human-Robot Navigation using Event-based Cameras and Reinforcement Learning](https://arxiv.org/abs/2506.10790)
**中文标题：基于事件相机和强化学习的人机导航**

*Ignacio Bugueno-Cordova,Javier Ruiz-del-Solar,Rodrigo Verschae*

Main category: cs.CV

TL;DR: 本文提出了一种结合事件相机和强化学习的机器人导航控制器，能够实现实时的人为中心导航和避障，优于传统基于图像的控制器。


<details>
  <summary>Details</summary>
Motivation: 传统基于图像的控制器存在固定帧率、运动模糊和延迟等问题，而事件相机的异步特性能够提供更灵活的视觉信息处理，从而提升导航性能。

Method: 该方法结合事件相机、其他传感器和深度确定性策略梯度（DDPG）进行策略优化，并通过初始模仿学习提高样本效率。

Result: 在模拟环境中取得了良好的效果，展示了鲁棒的导航、行人跟随和避障能力。

Conclusion: 该框架通过事件相机和强化学习的结合，为机器人导航提供了一种高效且适应性强的解决方案。

摘要: 本文提出了一种机器人导航控制器，结合事件相机和其他传感器以及强化学习技术，实现了实时的人为中心导航和避障功能。与传统的基于图像的控制器不同，后者因固定帧率、运动模糊和延迟等问题受限，而本方法利用事件相机的异步特性，能够在灵活的时间间隔内处理视觉信息，从而实现自适应推理和控制。该框架整合了事件感知、额外距离传感以及通过深度确定性策略梯度（DDPG）进行的策略优化，并通过初始模仿学习阶段提高了样本效率。在模拟环境中取得了令人满意的结果，展示了鲁棒的导航、行人跟随和避障能力。项目网站上提供了演示视频。

</details>


### [394] [Prompts to Summaries: Zero-Shot Language-Guided Video Summarization](https://arxiv.org/abs/2506.10807)
**中文标题：从提示到摘要：零样本语言引导的视频摘要**

*Mario Barbara,Alaa Maalouf*

Main category: cs.CV

TL;DR: 本文提出了一种零样本、基于自然语言提示的视频摘要方法，通过结合视频语言模型和大语言模型，无需训练数据即可生成用户可控的视频摘要，性能优于现有无监督方法，并与有监督方法相当。


<details>
  <summary>Details</summary>
Motivation: 视频数据的爆炸式增长需要灵活的用户可控摘要工具，但现有方法要么依赖数据集限制了泛化能力，要么无法结合用户自然语言表达的意图。

Method: 方法分为四步：(i) 将原始视频分割为连贯场景，(ii) 通过高效批处理的视频语言模型生成场景级描述，(iii) 利用大语言模型作为评分器，根据提示为场景分配重要性分数，(iv) 通过一致性和独特性指标将分数传播到短片段级别，生成细粒度帧重要性。

Result: 在SumMe和TVSum数据集上，该方法超越了所有无监督方法，并在查询聚焦视频摘要基准上表现优异，尽管未使用训练数据。同时发布了新数据集VidSum-Reason作为挑战性基准。

Conclusion: 研究表明，预训练多模态模型通过合理的提示和分数传播，已为通用、可查询的视频摘要提供了强大基础。

摘要: 视频数据的爆炸式增长加剧了对灵活、用户可控且无需领域特定训练数据的摘要工具的需求。现有方法要么依赖数据集，限制了泛化能力，要么无法结合用户通过自然语言表达的意图。我们提出了“从提示到摘要”：首个零样本、可文本查询的视频摘要工具，通过将现成的视频语言模型（VidLMs）生成的描述转化为用户引导的摘要，利用大语言模型（LLMs）作为评分器，完全无需训练数据，性能超越所有无监督方法，并与有监督方法相当。我们的流程包括：（i）将原始视频分割为连贯场景，（ii）通过内存高效的批处理式VidLM提示方案生成丰富的场景级描述，可扩展至单GPU处理数小时长的视频，（iii）利用LLM作为评分器，根据精心设计的提示为场景分配重要性分数，（iv）通过两个新指标（一致性和独特性）将这些分数传播到短片段级别，生成细粒度的帧重要性。在SumMe和TVSum数据集上，我们的无数据方法超越了所有依赖数据的无监督方法。在查询聚焦视频摘要（QFVS）基准测试中，尽管未使用训练数据且竞争对手需要监督的帧级重要性标注，我们的方法仍表现优异。为促进进一步研究，我们发布了VidSum-Reason，一个包含长尾概念和多步推理的新查询驱动数据集；我们的框架在该数据集上取得了稳健的F1分数，并成为首个具有挑战性的基准。总体而言，我们的结果表明，预训练多模态模型通过合理的提示和分数传播，已为通用、可文本查询的视频摘要提供了强大基础。

</details>


### [395] [Unsupervised Deformable Image Registration with Structural Nonparametric Smoothing](https://arxiv.org/abs/2506.10813)
**中文标题：基于结构非参数平滑的无监督变形图像配准**

*Hang Zhang,Xiang Chen,Renjiu Hu,Rongguang Wang,Jinwei Zhang,Min Liu,Yaonan Wang,Gaolei Li,Xinxing Cheng,Jinming Duan*

Main category: cs.CV

TL;DR: 本文提出了一种名为SmoothProper的插件式神经模块，用于解决无监督变形图像配准中的平滑性和大位移问题，通过结合对偶优化层和定制交互项，显著降低了配准误差。


<details>
  <summary>Details</summary>
Motivation: 无监督变形图像配准（DIR）方法在处理具有稀疏特征和大平滑区域的图像（如视网膜血管）时，面临孔径和大位移的挑战。传统方法通过神经网络单次前向预测变形场，但缺乏后训练约束，导致平滑性和一致性不足。

Method: 提出SmoothProper模块，结合对偶优化层和定制交互项，在网络前向传播中强制平滑性和消息传递。该模块模型无关，可无缝集成到现有配准框架中，无需额外超参数调整。

Result: 在视网膜血管数据集上的实验表明，SmoothProper将配准误差降至1.88像素（2912x2912图像），首次有效解决了孔径和大位移问题。

Conclusion: SmoothProper是一种高效的无监督DIR方法，显著提升了配准精度，适用于复杂图像场景。

摘要: 基于学习的变形图像配准（DIR）通过神经网络摊销传统优化过程，加速图像对齐。标签监督进一步提高了精度，实现了对未见扫描图像的高效精确非线性对齐。然而，对于具有稀疏特征和大平滑区域的图像（如视网膜血管），无监督DIR方法难以解决孔径和大位移问题。这一限制源于神经网络通过单次前向预测变形场，导致变形场在训练后缺乏约束，并将正则化负担完全转移到网络权重上。为解决这些问题，我们提出了SmoothProper，一种即插即用的神经模块，强制平滑性并在网络前向传播中促进消息传递。通过将对偶优化层与定制交互项结合，SmoothPrope高效地在空间位置间传播流信号，强制平滑性并保持结构一致性。该模块模型无关，可无缝集成到现有配准框架中，参数开销极小，且无需正则化超参数调优。在具有孔径和大位移挑战的视网膜血管数据集上的初步结果表明，我们的方法将配准误差降至1.88像素（2912x2912图像），成为首个有效解决这两大挑战的无监督DIR方法。源代码将在https://github.com/tinymilky/SmoothProper发布。

</details>


### [396] [Occlusion-Aware 3D Hand-Object Pose Estimation with Masked AutoEncoders](https://arxiv.org/abs/2506.10816)
**中文标题：基于掩码自编码器的遮挡感知3D手-物体姿态估计**

*Hui Yang,Wei Sun,Jian Liu,Jin Zheng,Jian Xiao,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文提出了一种基于掩码自编码器的遮挡感知3D手-物体姿态估计方法HOMAE，通过目标聚焦掩码策略和多尺度特征融合，显著提升了遮挡情况下的姿态估计性能。


<details>
  <summary>Details</summary>
Motivation: 由于手-物体交互中严重的遮挡问题，现有方法在全局结构感知和推理方面表现不足，限制了其在遮挡情况下的有效性。本文旨在解决这一问题。

Method: 提出HOMAE方法，采用目标聚焦掩码策略对交互区域施加结构化遮挡，促使模型学习上下文感知特征；结合多尺度特征预测有符号距离场（SDF），并与显式点云融合，增强几何感知能力。

Result: 在DexYCB和HO3Dv2基准测试中，HOMAE实现了最先进的性能，证明了其在遮挡情况下的鲁棒性。

Conclusion: HOMAE通过结合掩码自编码器和多尺度特征融合，显著提升了遮挡情况下的手-物体姿态估计性能，为相关领域提供了新思路。

摘要: 从单目RGB图像中估计手-物体姿态仍是一个重大挑战，主要由于手-物体交互中固有的严重遮挡问题。现有方法未充分探索全局结构感知和推理，限制了其在遮挡情况下的有效性。为解决这一问题，我们提出了一种基于掩码自编码器的遮挡感知手-物体姿态估计方法HOMAE。具体而言，我们提出了一种目标聚焦掩码策略，对手-物体交互区域施加结构化遮挡，促使模型学习上下文感知特征并推理遮挡结构。我们进一步整合解码器提取的多尺度特征来预测有符号距离场（SDF），捕捉全局上下文和精细几何信息。为增强几何感知，我们将隐式SDF与从SDF导出的显式点云结合，利用两种表示的互补优势。这种融合通过结合SDF的全局上下文和点云的精确局部几何，实现了对遮挡区域的更鲁棒处理。在DexYCB和HO3Dv2基准测试上的大量实验表明，HOMAE在手-物体姿态估计中达到了最先进的性能。我们将公开代码和模型。

</details>


### [397] [VideoDeepResearch: Long Video Understanding With Agentic Tool Using](https://arxiv.org/abs/2506.10821)
**中文标题：VideoDeepResearch：基于代理工具使用的长视频理解研究**

*Huaying Yuan,Zheng Liu,Junjie Zhou,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.CV

TL;DR: 本文提出VideoDeepResearch，一种基于纯文本大型推理模型（LRM）和多模态工具包的代理框架，用于长视频理解（LVU），显著优于现有多模态大语言模型（MLLM）基线。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）在长视频理解（LVU）任务中面临复杂性和上下文窗口限制的挑战。本文质疑传统观点，即解决LVU需要扩展上下文窗口和强视觉感知能力的MLLMs，转而探索仅依赖文本推理模型和多模态工具包的代理框架。

Method: VideoDeepResearch结合纯文本大型推理模型（LRM）和模块化多模态工具包（包括多模态检索器和视觉感知器），通过推理制定问题解决策略，并选择性访问和利用视频内容。

Result: 在MLVU、Video-MME和LVBench等基准测试中，VideoDeepResearch显著优于现有MLLM基线，分别提升9.6%、6.6%和3.9%。

Conclusion: 代理系统在解决LVU关键挑战中具有潜力，无需依赖扩展上下文窗口的MLLMs。

摘要: 长视频理解（LVU）因其复杂性和上下文窗口限制，对当前多模态大语言模型（MLLMs）构成重大挑战。传统观点认为解决LVU需要具备扩展上下文窗口、强视觉感知能力和领域专业知识的MLLMs。本文提出VideoDeepResearch，一种新型代理框架，仅依赖纯文本大型推理模型（LRM）和模块化多模态工具包（包括多模态检索器和视觉感知器）。对于每个LVU任务，系统通过推理制定问题解决策略，并选择性访问和利用视频内容。我们在MLVU、Video-MME和LVBench等流行基准上进行了广泛实验。结果表明，VideoDeepResearch显著优于现有MLLM基线，在MLVU（测试）、LVBench和LongVideoBench上分别提升9.6%、6.6%和3.9%。这些发现凸显了代理系统在解决LVU关键挑战中的潜力。

</details>


### [398] [Post-Training Quantization for Video Matting](https://arxiv.org/abs/2506.10840)
**中文标题：视频抠图的后训练量化**

*Tianrui Zhu,Houyuan Chen,Ruihao Gong,Michele Magno,Haotong Qin,Kai Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种专为视频抠图设计的后训练量化（PTQ）框架PTQ4VM，通过两阶段策略、全局仿射校准和光流辅助组件，显著提升了量化模型的精度和时序一致性，甚至在4位量化下接近全精度性能。


<details>
  <summary>Details</summary>
Motivation: 视频抠图在电影制作和虚拟现实中应用广泛，但其计算密集型模型在资源受限设备上部署困难。后训练量化（PTQ）作为一种高效方法，在视频抠图领域尚处于早期阶段，面临精度和时序一致性的挑战。

Method: 1. 两阶段PTQ策略：结合基于块重建的优化和全局量化参数校准。2. 统计驱动的全局仿射校准（GAC）：补偿统计失真。3. 光流辅助（OFA）：利用帧间时序和语义先验指导量化过程。

Result: PTQ4VM在不同比特宽度下均达到最先进精度，4位量化下性能接近全精度模型，计算量减少8倍。

Conclusion: PTQ4VM为视频抠图量化提供了高效解决方案，显著提升了量化模型的性能，为资源受限设备上的部署提供了可能。

摘要: 视频抠图在电影制作和虚拟现实等应用中至关重要，但其计算密集型模型在资源受限设备上的部署面临挑战。量化是模型压缩和加速的关键技术。作为一种高效方法，后训练量化（PTQ）在视频抠图领域尚处于早期阶段，面临精度和时序一致性的显著障碍。为解决这些问题，本文提出了一种专为视频抠图模型设计的新型通用PTQ框架，据我们所知，这是该领域的首次系统性尝试。我们的贡献包括：（1）一种两阶段PTQ策略，结合基于块重建的优化以实现快速稳定的初始量化和局部依赖捕获，随后通过全局量化参数校准最小化精度损失。（2）一种统计驱动的全局仿射校准（GAC）方法，使网络能够补偿因忽略BN层效应等因素引起的累积统计失真，甚至将现有PTQ方法在视频抠图任务上的误差降低高达20%。（3）一种光流辅助（OFA）组件，利用帧间的时序和语义先验指导PTQ过程，增强模型在复杂场景中区分移动前景的能力，最终在超低位量化下实现接近全精度的性能。全面的定量和视觉结果表明，与现有量化方法相比，PTQ4VM在不同比特宽度下均达到最先进的精度性能。我们特别指出，4位PTQ4VM的性能接近全精度模型，同时计算量减少8倍。

</details>


### [399] [VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos](https://arxiv.org/abs/2506.10857)
**中文标题：VRBench：长叙事视频中多步推理的基准**

*Jiashuo Yu,Yue Wu,Meng Chu,Zhifei Ren,Zizheng Huang,Pei Chu,Ruijie Zhang,Yinan He,Qirui Li,Songze Li,Zhenxiang Li,Zhongying Tu,Conghui He,Yu Qiao,Yali Wang,Yi Wang,Limin Wang*

Main category: cs.CV

TL;DR: VRBench是首个针对长叙事视频的多步推理能力评估基准，包含1010个长视频和9468个人工标注的多步问答对，旨在解决现有评估中忽视时间推理和程序有效性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法在长叙事视频的多步推理能力测试中存在不足，尤其是时间推理和程序有效性方面。VRBench旨在填补这一空白，提供更全面的评估工具。

Method: 通过多阶段筛选过程（包括专家评审）精选视频，确保情节连贯性；开发人机协作框架生成连贯推理链，涵盖七种类型；设计多阶段评估流程，从结果和过程两个层面评估模型。

Result: 对12个LLM和16个VLM的广泛评估显示，VRBench能全面分析模型的多步推理能力，并提供有价值的见解。

Conclusion: VRBench为多步推理领域提供了首个长视频评估基准，推动了该领域的进步。

摘要: 我们提出了VRBench，这是首个针对长叙事视频的多步推理能力评估基准，旨在解决现有评估中忽视时间推理和程序有效性的问题。VRBench包含1010个长视频（平均时长1.6小时），以及9468个人工标注的多步问答对和30292个带时间戳的推理步骤。这些视频通过多阶段筛选过程（包括专家评审）精选，以确保情节连贯性。我们开发了一种人机协作框架，生成连贯的推理链，每条链需要多个基于时间的步骤，涵盖七种类型（如事件归因、隐式推理）。VRBench设计了多阶段评估流程，从结果和过程两个层面评估模型。除了针对最终结果的多选题外，我们还提出了一种基于进展水平的LLM引导评分指标，从多个维度全面评估推理链的质量。通过对12个LLM和16个VLM在VRBench上的广泛评估，我们进行了深入分析，并提供了推动多步推理领域发展的宝贵见解。

</details>


### [400] [CreatiPoster: Towards Editable and Controllable Multi-Layer Graphic Design Generation](https://arxiv.org/abs/2506.10890)
**中文标题：CreatiPoster：面向可编辑与可控的多图层图形设计生成**

*Zhao Zhang,Yutao Cheng,Dexiang Hong,Maoke Yang,Gonglei Shi,Lei Ma,Hui Zhang,Jie Shao,Xinglong Wu*

Main category: cs.CV

TL;DR: CreatiPoster是一个生成可编辑、多图层图形设计的框架，通过自然语言指令或素材生成专业级设计，支持多样化应用，超越现有开源和商业系统。


<details>
  <summary>Details</summary>
Motivation: 当前AI工具在图形设计中难以准确整合用户素材、保持可编辑性和专业视觉效果，商业系统依赖模板库，不灵活。CreatiPoster旨在解决这些问题，推动AI辅助图形设计的普及。

Method: CreatiPoster采用协议模型（RGBA多模态模型）生成JSON规范，详细描述每层布局、内容与样式，再通过条件背景模型合成连贯背景。

Result: CreatiPoster在图形设计生成任务中超越领先的开源方法和商业系统，并发布了10万份无版权多图层设计数据集。

Conclusion: CreatiPoster通过可编辑、多图层设计生成，支持多样化应用，推动了AI辅助图形设计的民主化。

摘要: 图形设计在商业和个人场景中至关重要，但创建高质量、可编辑且美观的设计仍是一项耗时且需要专业技能的任务，尤其对初学者而言。当前的AI工具虽能部分自动化工作流程，但难以准确整合用户提供的素材、保持可编辑性并实现专业视觉效果。商业系统（如Canva Magic Design）依赖庞大的模板库，难以复制。本文提出CreatiPoster框架，通过可选的自然语言指令或素材生成可编辑的多图层设计。协议模型（一种RGBA多模态模型）首先生成JSON规范，详细描述每层（文本或素材）的布局、层级、内容与样式，并提供简洁的背景提示。随后，条件背景模型根据渲染的前景图层合成连贯的背景。我们构建了一个图形设计生成基准，并展示CreatiPoster超越领先的开源方法和商业系统。为推动研究，我们发布了10万份无版权多图层设计数据集。CreatiPoster支持画布编辑、文本叠加、响应式调整、多语言适配和动态海报等多样化应用，推动AI辅助图形设计的民主化。项目主页：https://github.com/graphic-design-ai/creatiposter

</details>


### [401] [AIR: Zero-shot Generative Model Adaptation with Iterative Refinement](https://arxiv.org/abs/2506.10895)
**中文标题：AIR：通过迭代优化的零样本生成模型适应**

*Guimeng Liu,Milad Abdollahzadeh,Ngai-Man Cheung*

Main category: cs.CV

TL;DR: 本文提出了一种零样本生成模型适应方法AIR，通过迭代优化解决CLIP嵌入空间中图像偏移与文本偏移不对齐的问题，显著提升了生成图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有零样本生成模型适应方法假设图像偏移与文本偏移在CLIP嵌入空间中完全对齐，导致生成图像质量下降。本文旨在分析偏移不对齐现象并提出改进方法。

Method: 首先实证分析了CLIP嵌入空间中文本偏移与图像偏移的不对齐现象，发现概念距离与偏移不对齐相关。随后提出AIR方法，通过迭代优化提升目标域图像质量。

Result: 在26种实验设置中，AIR方法在定性、定量和用户研究中均表现出最先进的性能。

Conclusion: AIR方法通过迭代优化解决了偏移不对齐问题，显著提升了零样本生成模型适应中的图像质量。

摘要: 零样本生成模型适应（ZSGM）旨在仅通过文本指导将预训练生成器适应到目标域，而无需目标域的任何样本。现有ZSGM方法的核心是方向性损失，其通过将图像偏移与文本偏移在CLIP等视觉语言模型的嵌入空间中对齐来利用文本指导。这与NLP中的类比推理类似，即通过对齐两对词之间的偏移来识别另一对词中的缺失元素。然而，现有ZSGM方法的主要局限在于学习目标假设图像偏移与文本偏移在CLIP嵌入空间中完全对齐，导致生成图像质量下降。本文的主要贡献有两点：首先，受NLP中偏移不对齐研究的启发，我们通过实证分析研究了CLIP嵌入空间中文本偏移与图像偏移的不对齐现象，发现偏移不对齐与概念距离相关，即相近概念的不对齐程度较低。其次，针对现有方法的局限，我们提出了迭代优化适应方法（AIR），这是首个基于偏移不对齐新见解改进目标域图像质量的ZSGM方法。在26种实验设置中，AIR方法在定性、定量和用户研究中均表现出最先进的性能。补充实验见附录。

</details>


### [402] [M4V: Multi-Modal Mamba for Text-to-Video Generation](https://arxiv.org/abs/2506.10915)
**中文标题：M4V：用于文本到视频生成的多模态Mamba框架**

*Jiancheng Huang,Gengwei Zhang,Zequn Jie,Siyu Jiao,Yinlong Qian,Ling Chen,Yunchao Wei,Lin Ma*

Main category: cs.CV

TL;DR: M4V是一种基于Mamba架构的多模态文本到视频生成框架，通过多模态扩散Mamba块（MM-DiM）和奖励学习策略，显著降低计算成本并提升视频质量。


<details>
  <summary>Details</summary>
Motivation: 文本到视频生成在内容创作中具有重要价值，但现有Transformer模型因二次复杂度计算成本高，限制了实际应用。Mamba架构虽高效，但其简单设计难以直接适用于多模态和时空视频生成任务。

Method: 提出M4V框架，设计多模态扩散Mamba块（MM-DiM），通过多模态令牌重组实现多模态信息和时空建模的无缝集成。引入奖励学习策略以提升长上下文自回归生成中的视觉质量。

Result: M4V在768×1280分辨率视频生成中，比基于注意力的方法减少45%的FLOPs，并在文本到视频基准测试中生成高质量视频。

Conclusion: M4V通过高效的多模态Mamba框架和奖励学习策略，显著降低了计算成本并提升了视频质量，为文本到视频生成提供了实用解决方案。

摘要: 文本到视频生成极大地丰富了内容创作，并有望发展为强大的世界模拟器。然而，建模广阔的时空空间仍然计算密集，尤其是在使用Transformer时，其序列处理的二次复杂度限制了实际应用。近年来，线性时间序列建模的进展，特别是Mamba架构，提供了更高效的替代方案。然而，其简单设计限制了其直接应用于多模态和时空视频生成任务。为解决这些问题，我们提出了M4V，一种用于文本到视频生成的多模态Mamba框架。具体而言，我们设计了一种多模态扩散Mamba（MM-DiM）块，通过多模态令牌重组设计，实现了多模态信息和时空建模的无缝集成。结果表明，在生成768×1280分辨率的视频时，M4V中的Mamba块比基于注意力的替代方案减少了45%的FLOPs。此外，为缓解长上下文自回归生成过程中的视觉质量下降，我们引入了一种奖励学习策略，进一步提升了每帧的视觉真实感。在文本到视频基准测试上的广泛实验表明，M4V能够生成高质量视频，同时显著降低计算成本。代码和模型将在https://huangjch526.github.io/M4V_project公开。

</details>


### [403] [VINCIE: Unlocking In-context Image Editing from Video](https://arxiv.org/abs/2506.10941)
**中文标题：VINCIE：从视频中解锁上下文图像编辑**

*Leigang Qu,Feng Cheng,Ziyan Yang,Qi Zhao,Shanchuan Lin,Yichun Shi,Yicong Li,Wenjie Wang,Tat-Seng Chua,Lu Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种基于视频的上下文图像编辑方法VINCIE，通过设计块因果扩散变换器和多任务学习，实现了无需专家模型的图像编辑能力，并在多轮编辑基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文图像编辑方法依赖于任务特定的流程和专家模型，限制了其灵活性和可扩展性。本文探索是否可以直接从视频中学习上下文图像编辑模型，以克服这些限制。

Method: 提出了一种可扩展的方法，将视频标注为交错的多模态序列，并设计了一个块因果扩散变换器，通过三个代理任务（下一图像预测、当前分割预测和下一分割预测）进行训练。

Result: 实验表明，该模型在上下文图像编辑方面表现出色，并在多轮图像编辑基准测试中取得了最优结果。此外，模型还展示了多概念组合、故事生成和链式编辑应用的潜力。

Conclusion: VINCIE证明了直接从视频中学习上下文图像编辑的可行性，为多模态序列学习和图像编辑领域提供了新的研究方向。

摘要: 上下文图像编辑旨在基于包含文本和先前生成图像的上下文序列修改图像。现有方法通常依赖于任务特定的流程和专家模型（例如分割和修复）来整理训练数据。本文探讨了是否可以直接从视频中学习上下文图像编辑模型。我们提出了一种可扩展的方法，将视频标注为交错的多模态序列。为了有效学习这些数据，我们设计了一个块因果扩散变换器，通过三个代理任务进行训练：下一图像预测、当前分割预测和下一分割预测。此外，我们还提出了一个新的多轮图像编辑基准，以推动该领域的研究。大量实验表明，我们的模型表现出强大的上下文图像编辑能力，并在两个多轮图像编辑基准测试中取得了最优结果。尽管仅通过视频训练，我们的模型还展示了在多概念组合、故事生成和链式编辑应用中的潜力。

</details>


### [404] [SpectralAR: Spectral Autoregressive Visual Generation](https://arxiv.org/abs/2506.10962)
**中文标题：SpectralAR：频谱自回归视觉生成**

*Yuanhui Huang,Weiliang Chen,Wenzhao Zheng,Yueqi Duan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 提出了一种基于频谱视角的自回归视觉生成框架SpectralAR，通过嵌套频谱标记化将图像转换为有序频谱标记，实现了序列因果性和标记效率，在ImageNet-1K上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视觉生成方法通常将图像作为空间块处理，这与自回归建模的因果性相矛盾。为了解决这一问题，本文提出从频谱视角实现视觉序列的因果性。

Method: 首先通过嵌套频谱标记化将图像转换为有序频谱标记（从低频到高频），然后以从粗到细的方式对频谱标记序列进行自回归生成。

Result: 在ImageNet-1K上的图像重建和自回归生成实验中，SpectralAR仅用64个标记和310M参数即达到3.02 gFID。

Conclusion: SpectralAR通过频谱视角实现了视觉序列的因果性和标记效率，为自回归视觉生成提供了一种高效且兼容性强的解决方案。

摘要: 自回归视觉生成因其可扩展性和与其他模态的兼容性而受到越来越多的关注。大多数现有方法将视觉序列构建为空间块进行自回归生成。然而，图像块本质上是并行的，这与自回归建模的因果性相矛盾。为了解决这一问题，我们提出了一种频谱自回归（SpectralAR）视觉生成框架，从频谱视角实现了视觉序列的因果性。具体而言，我们首先通过嵌套频谱标记化将图像转换为有序频谱标记，表示从低频到高频的分量。然后，我们以从粗到细的方式对频谱标记序列进行自回归生成。通过考虑图像的不同细节层次，SpectralAR在不增加额外复杂度的情况下实现了序列因果性和标记效率。我们在ImageNet-1K上进行了图像重建和自回归生成的广泛实验，SpectralAR仅用64个标记和310M参数即达到3.02 gFID。项目页面：https://huang-yh.github.io/spectralar/。

</details>


### [405] [MMMG: A Massive, Multidisciplinary, Multi-Tier Generation Benchmark for Text-to-Image Reasoning](https://arxiv.org/abs/2506.10963)
**中文标题：MMMG：一个用于文本到图像推理的大规模、多学科、多层次生成基准**

*Yuxuan Luo,Yuhui Yuan,Junwen Chen,Haonan Cai,Ziyi Yue,Yuwei Yang,Fatima Zohra Daha,Ji Li,Zhouhui Lian*

Main category: cs.CV

TL;DR: 本文提出了知识图像生成任务，并发布了MMMG基准测试，用于评估图像生成模型的多模态推理能力。MMMG包含4,456个专家验证的图像-提示对，覆盖10个学科和6个教育水平。研究发现现有模型在推理能力上存在严重缺陷，并提出了一个开放基线模型FLUX-Reason。


<details>
  <summary>Details</summary>
Motivation: 知识图像在人类文明和学习中扮演重要角色，但生成此类图像需要复杂的多模态推理能力。目前缺乏一个全面的基准测试来评估模型的推理能力，因此提出了MMMG。

Method: MMMG基准包含4,456个专家验证的图像-提示对，覆盖10个学科和6个教育水平，并使用统一的知识图谱（KG）表示。同时提出了MMMG-Score评估指标，结合事实保真度和视觉清晰度。

Result: 对16个先进文本到图像生成模型的评估显示，它们在推理能力上存在严重缺陷，GPT-4o的MMMG-Score仅为50.20。提出的基线模型FLUX-Reason得分为34.45。

Conclusion: MMMG基准揭示了当前图像生成模型在推理能力上的不足，并提出了一个开放基线模型以促进未来研究。

摘要: 本文提出了知识图像生成这一新任务，并发布了大规模多学科多层次知识图像生成基准（MMMG），用于评估图像生成模型的推理能力。知识图像在人类文明和学习中具有核心地位，其生成需要融合世界知识与像素级视觉表达的多模态推理。MMMG包含4,456个专家验证的图像-提示对，覆盖10个学科、6个教育水平以及多种知识格式（如图表、思维导图等）。为简化评估，我们采用统一的知识图谱（KG）表示，明确标注目标图像的核心实体及其依赖关系。此外，我们提出了MMMG-Score评估指标，结合KG间的图编辑距离（衡量事实保真度）和视觉清晰度评估。对16个先进文本到图像生成模型的全面评估揭示了其在推理能力上的严重缺陷（如实体保真度低、关系弱、图像杂乱），GPT-4o的MMMG-Score仅为50.20，凸显了基准的难度。为促进研究进展，我们发布了FLUX-Reason（MMMG-Score为34.45），这是一个结合推理大语言模型和扩散模型的有效开放基线模型，训练数据包含16,000个精选知识图像-提示对。

</details>


### [406] [Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs](https://arxiv.org/abs/2506.10967)
**中文标题：超越注意力或相似性：最大化条件多样性以实现多模态大型语言模型中的令牌修剪**

*Qizhe Zhang,Mengzhen Liu,Lichen Li,Ming Lu,Yuan Zhang,Junwen Pan,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为CDPruner的新型视觉令牌修剪方法，通过最大化条件多样性来优化多模态大型语言模型（MLLMs）中的冗余视觉令牌修剪问题，显著降低了计算成本并保持了高性能。


<details>
  <summary>Details</summary>
Motivation: 在多模态大型语言模型（MLLMs）中，输入视觉令牌的长度通常远大于文本令牌，导致高推理成本。现有方法要么依赖注意力修剪（保留重复令牌），要么基于相似性修剪（忽略指令相关性），导致性能不佳。

Method: 提出CDPruner方法，通过定义基于指令的条件相似性，并利用行列式点过程（DPP）最大化保留令牌的条件多样性，实现高效且模型无关的令牌修剪。

Result: 实验表明，CDPruner在多种MLLMs上实现了新的最优性能，显著降低了计算成本（如FLOPs减少95%，CUDA延迟降低78%），同时保持了94%的原始准确率。

Conclusion: CDPruner通过最大化条件多样性，在高效修剪视觉令牌的同时，确保了模型性能的稳定性和指令的紧密遵循，为MLLMs的实际应用提供了高效解决方案。

摘要: 在多模态大型语言模型（MLLMs）中，输入视觉令牌的长度通常远大于文本令牌，导致高推理成本。许多工作试图通过去除冗余视觉令牌来解决这一问题。然而，现有方法要么依赖注意力修剪（保留大量重复令牌），要么基于相似性修剪（忽略指令相关性），导致性能不佳。本文提出了一种名为CDPruner的新型视觉令牌修剪方法，通过最大化保留令牌的条件多样性来解决这一问题。我们首先定义了基于指令的视觉令牌条件相似性，然后利用行列式点过程（DPP）重新表述令牌修剪问题，以最大化所选子集的条件多样性。CDPruner无需训练且与模型无关，可轻松应用于各种MLLMs。在多种MLLMs上的广泛实验表明，CDPruner在多种视觉语言基准测试中实现了新的最优性能。通过DPP最大化条件多样性，所选子集能更好地表示输入图像，同时紧密遵循用户指令，从而在高压缩比下仍保持强性能。应用于LLaVA时，CDPruner将FLOPs减少了95%，CUDA延迟降低了78%，同时保持了94%的原始准确率。代码已开源：https://github.com/Theia-4869/CDPruner。

</details>


### [407] [GenWorld: Towards Detecting AI-generated Real-world Simulation Videos](https://arxiv.org/abs/2506.10975)
**中文标题：GenWorld：面向检测AI生成的现实世界模拟视频**

*Weiliang Chen,Wenzhao Zheng,Yu Zheng,Lei Chen,Jie Zhou,Jiwen Lu,Yueqi Duan*

Main category: cs.CV

TL;DR: 本文提出GenWorld数据集和SpannDetector模型，用于检测高质量AI生成的模拟现实世界视频。GenWorld数据集具有真实模拟、高质量和多样化的特点，而SpannDetector通过多视角一致性检测AI生成视频，实验效果显著。


<details>
  <summary>Details</summary>
Motivation: 随着视频生成技术的发展，AI生成的视频威胁到真实世界信息的可信度，而现有检测器因缺乏高质量的真实世界数据集而受限。

Method: 提出GenWorld数据集，包含高质量、多样化的模拟现实世界视频；设计SpannDetector模型，利用多视角一致性检测AI生成视频。

Result: 实验表明，SpannDetector在检测高质量AI生成视频方面表现优异，为基于物理合理性的可解释检测提供了新方向。

Conclusion: GenWorld数据集和SpannDetector模型为AI生成视频检测领域提供了重要贡献，推动了该领域的发展。

摘要: 视频生成技术的蓬勃发展威胁到现实世界信息的可信度，并加剧了对AI生成视频检测器的需求。尽管已有一些进展，但高质量现实世界数据集的缺乏阻碍了可信检测器的发展。本文提出GenWorld，一个大规模、高质量且模拟现实世界的数据集，用于AI生成视频检测。GenWorld具有以下特点：（1）现实世界模拟：GenWorld专注于复制现实场景的视频，因其真实性和潜在影响力而具有重要意义；（2）高质量：GenWorld采用多种最先进的视频生成模型，提供逼真的高质量伪造视频；（3）跨提示多样性：GenWorld包含由不同生成器和多种提示模态（如文本、图像、视频）生成的视频，有助于学习更具泛化性的取证特征。我们分析了现有方法，发现它们无法检测由世界模型（如Cosmos）生成的高质量视频，揭示了忽视现实世界线索的潜在缺陷。为此，我们提出了一种简单而有效的模型SpannDetector，利用多视角一致性作为检测现实世界AI生成视频的强标准。实验表明，我们的方法取得了优异的结果，为基于物理合理性的可解释AI生成视频检测指明了有前景的方向。我们相信GenWorld将推动AI生成视频检测领域的发展。项目页面：https://chen-wl20.github.io/GenWorld

</details>


### [408] [QuadricFormer: Scene as Superquadrics for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2506.10977)
**中文标题：QuadricFormer：将场景建模为超二次曲面以实现3D语义占据预测**

*Sicheng Zuo,Wenzhao Zheng,Xiaoyong Han,Longchao Yang,Yong Pan,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文提出了一种基于超二次曲面的3D语义占据预测方法QuadricFormer，通过几何表达性强的超二次曲面作为场景基元，高效建模复杂结构，并在nuScenes数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D占据预测方法通常采用密集体素或稀疏高斯表示，前者效率低下，后者因椭球形先验限制无法准确建模多样化的几何结构。因此，需要一种既能高效表示复杂结构又能保持准确性的方法。

Method: 提出使用超二次曲面作为场景基元，开发了一种概率超二次曲面混合模型，将每个超二次曲面视为具有几何先验的占据概率分布，并通过概率混合计算语义。进一步提出了QuadricFormer模型，并引入剪枝-分割模块以提升建模效率。

Result: 在nuScenes数据集上的实验表明，QuadricFormer在保持高效的同时，实现了最先进的性能。

Conclusion: 超二次曲面作为一种几何表达性强的基元，能够高效表示复杂结构，QuadricFormer为3D语义占据预测提供了一种高效且准确的解决方案。

摘要: 3D占据预测对于鲁棒的自驾系统至关重要，因为它能够全面感知环境结构和语义。现有方法多采用密集体素表示，忽略了驾驶场景的稀疏性，导致效率低下。近期研究探索了基于稀疏高斯的对象中心表示，但其椭球形先验限制了多样化结构的建模。真实驾驶场景中的对象具有丰富的几何形状（如长方体、圆柱体和不规则形状），需要密集排列的椭球形高斯以实现准确建模，从而导致表示效率低下。为解决这一问题，我们提出使用几何表达性强的超二次曲面作为场景基元，通过其固有的形状多样性，以更少的基元高效表示复杂结构。我们开发了一种概率超二次曲面混合模型，将每个超二次曲面解释为具有几何先验的占据概率分布，并通过概率混合计算语义。在此基础上，我们提出了QuadricFormer，一种基于超二次曲面的高效3D占据预测模型，并引入剪枝-分割模块以进一步提升建模效率。在nuScenes数据集上的大量实验表明，QuadricFormer在保持高效的同时，实现了最先进的性能。

</details>


### [409] [Fine-Grained Perturbation Guidance via Attention Head Selection](https://arxiv.org/abs/2506.10978)
**中文标题：通过注意力头选择实现细粒度扰动引导**

*Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出了一种名为“HeadHunter”的系统框架，通过细粒度选择注意力头来优化扩散模型中的生成质量和视觉属性，并引入SoftPAG方法调节扰动强度，解决了现有层级别扰动方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的注意力扰动方法缺乏确定扰动应用位置的原则性方法，尤其是在扩散变换器（DiT）架构中，质量相关的计算分布在多个层中。本文旨在探索注意力头的细粒度扰动，以实现更精准的生成控制。

Method: 研究注意力头的细粒度扰动，提出“HeadHunter”框架迭代选择与用户目标一致的注意力头，并引入SoftPAG方法通过线性插值调节扰动强度。

Result: 在Stable Diffusion 3和FLUX.1等大规模DiT文本到图像模型上验证了方法的有效性，显著提升了生成质量和风格控制能力。

Conclusion: 本文首次在扩散模型中进行了头级别的注意力扰动分析，揭示了注意力层的可解释性分工，为设计高效扰动策略提供了实用方法。

摘要: 近年来，扩散模型中的引导方法通过扰动模型构建隐式弱模型，并引导生成远离该模型。在这些方法中，注意力扰动在无条件场景中表现出色，而现有方法缺乏确定扰动应用位置的原则性方法，尤其是在扩散变换器（DiT）架构中，质量相关的计算分布在多个层中。本文研究了注意力扰动的细粒度，从层级别到单个注意力头，发现特定头控制着不同的视觉概念（如结构、风格和纹理质量）。基于这一发现，我们提出了“HeadHunter”框架，通过迭代选择与用户目标一致的注意力头，实现对生成质量和视觉属性的细粒度控制。此外，我们引入了SoftPAG方法，通过线性插值将每个选定头的注意力图向单位矩阵逼近，提供连续调节扰动强度的能力，同时抑制伪影。我们的方法不仅缓解了现有层级别扰动的过度平滑问题，还通过组合选择头实现了对特定视觉风格的有针对性操控。我们在包括Stable Diffusion 3和FLUX.1在内的现代大规模DiT文本到图像模型上验证了方法的有效性，在通用质量提升和风格特定引导方面均表现出色。本文首次在扩散模型中进行了头级别的注意力扰动分析，揭示了注意力层的可解释性分工，并为设计高效扰动策略提供了实用方法。

</details>


### [410] [InstaInpaint: Instant 3D-Scene Inpainting with Masked Large Reconstruction Model](https://arxiv.org/abs/2506.10980)
**中文标题：InstaInpaint：基于掩码大型重建模型的即时 3D 场景修复**

*Junqi You,Chieh Hubert Lin,Weijie Lyu,Zhengbo Zhang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: InstaInpaint 是一种基于参考的前馈框架，能够在 0.4 秒内完成 3D 场景修复，速度比现有方法快 1000 倍，同时保持最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前 3D 场景修复方法依赖耗时且计算密集的优化，无法满足实时或在线应用的需求，因此需要一种更高效的方法。

Method: 提出 InstaInpaint 框架，通过自监督掩码微调策略训练定制的大型重建模型 (LRM)，从 2D 修复提案中快速生成 3D 场景修复。

Result: InstaInpaint 在速度上实现了 1000 倍的提升，并在两个标准基准测试中保持了最先进的性能，同时支持灵活的物体插入和多区域修复。

Conclusion: InstaInpaint 为实时 3D 场景修复提供了高效解决方案，并展示了在多种下游任务中的良好泛化能力。

摘要: 近年来，3D 场景重建技术的进步使得虚拟和增强现实中的实时查看成为可能。为了支持更具沉浸感的交互操作（如移动或编辑物体），3D 场景修复方法被提出用于修复或补全改变的几何结构。然而，当前方法依赖耗时且计算密集的优化，使其难以应用于实时或在线场景。我们提出了 InstaInpaint，一种基于参考的前馈框架，能够在 0.4 秒内从 2D 修复提案中生成 3D 场景修复。我们开发了一种自监督掩码微调策略，以在大型数据集上训练定制的大型重建模型 (LRM)。通过大量实验，我们分析并确定了多项关键设计，以提高泛化能力、纹理一致性和几何正确性。InstaInpaint 实现了比现有方法快 1000 倍的速度，同时在两个标准基准测试中保持了最先进的性能。此外，我们还展示了 InstaInpaint 在灵活的下游应用（如物体插入和多区域修复）中的良好泛化能力。更多视频结果请访问我们的项目页面：https://dhmbb2.github.io/InstaInpaint_page/。

</details>


### [411] [SceneCompleter: Dense 3D Scene Completion for Generative Novel View Synthesis](https://arxiv.org/abs/2506.10981)
**中文标题：SceneCompleter：用于生成式新视角合成的密集3D场景补全**

*Weiliang Chen,Jiayi Bi,Yuanhui Huang,Wenzhao Zheng,Yueqi Duan*

Main category: cs.CV

TL;DR: 本文提出SceneCompleter框架，通过密集3D场景补全实现3D一致的生成式新视角合成，解决了现有方法在2D补全和3D重建中导致的平滑表面和几何扭曲问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式新视角合成方法通常先在2D补全缺失区域，再通过3D重建技术恢复场景，但这种方法因仅依赖RGB数据推断3D结构，常导致表面过于平滑和几何扭曲。本文旨在解决这一问题。

Method: SceneCompleter框架包含两个关键组件：(1) 几何-外观双流扩散模型，联合合成RGBD空间中的新视角；(2) 场景编码器，从参考图像中编码更全面的场景理解。通过融合结构和纹理信息，实现3D一致的场景补全。

Result: 实验表明，SceneCompleter在多样数据集上实现了视觉连贯性和3D一致性的生成式新视角合成，表现出更高的连贯性和合理性。

Conclusion: SceneCompleter通过密集3D场景补全，显著提升了生成式新视角合成的3D一致性和视觉质量，为相关领域提供了新思路。

摘要: 生成模型在新视角合成（NVS）中因减少对密集多视角捕获的依赖而受到广泛关注。然而，现有方法通常采用传统范式，即生成模型先在2D补全缺失区域，再通过3D重建技术恢复场景，这常因仅依赖RGB数据推断3D结构而导致表面过于平滑和几何扭曲。本文提出SceneCompleter，一种通过密集3D场景补全实现3D一致生成式新视角合成的新框架。SceneCompleter通过两个关键组件实现视觉连贯性和3D一致的场景补全：(1) 几何-外观双流扩散模型，联合合成RGBD空间中的新视角；(2) 场景编码器，从参考图像中编码更全面的场景理解。通过有效融合结构和纹理信息，我们的方法在多样数据集上展示了生成式新视角合成的优越连贯性和合理性。项目页面：https://chen-wl20.github.io/SceneCompleter

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [412] [A Conjecture on a Fundamental Trade-Off between Certainty and Scope in Symbolic and Generative AI](https://arxiv.org/abs/2506.10130)
**中文标题：关于符号AI与生成式AI中确定性与范围之间基本权衡的猜想**

*Luciano Floridi*

Main category: cs.AI

TL;DR: The paper conjectures a trade-off between provable correctness and broad data-mapping capacity in AI, suggesting that systems with high certainty (symbolic AI) have narrow scope, while broad-capacity systems (generative AI) cannot achieve zero-error performance.


<details>
  <summary>Details</summary>
Motivation: To formalize and make explicit the implicit trade-off between certainty and scope in AI systems, reframing engineering and philosophical expectations for AI.

Method: The article reviews historical motivations, states the conjecture in information-theoretic terms, and contextualizes it within epistemology, formal verification, and philosophy of technology. It analyzes implications using underdetermination, epistemic risk, and moral responsibility.

Result: The conjecture clarifies evaluation standards, governance frameworks, and hybrid system design, emphasizing the need for rigorous verification.

Conclusion: Proving or refuting the conjecture is crucial for the future of trustworthy AI, as it reshapes expectations and design principles.

摘要: 本文提出一个猜想，形式化地描述了人工智能（AI）系统中可证明的正确性与广泛数据映射能力之间的基本权衡。当AI系统被设计为具有演绎上滴水不漏的保证（对其输出无错误性质的确定性证明）——如经典符号AI——其操作领域必须被严格限定和预先结构化。相反，能够输入高维数据以产生丰富信息输出的系统——如当代生成模型——必然放弃了零错误性能的可能性，承担了不可消除的错误或误分类风险。通过将这一先前隐含的权衡明确化并接受严格验证，该猜想显著重构了AI的工程目标和哲学期望。在回顾了这种矛盾的历史动机后，文章以信息论形式陈述了猜想，并将其置于认识论、形式验证和技术哲学的广泛讨论中。随后，文章分析了其影响和后果，借鉴了未确定性、谨慎认识风险及道德责任等概念。讨论阐明了如果猜想成立，它将如何帮助重塑评估标准、治理框架和混合系统设计。结论强调了最终证明或反驳这一不等式对于可信AI未来的重要性。

</details>


### [413] [One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence](https://arxiv.org/abs/2506.10157)
**中文标题：一位患者，多种情境：通过情境智能扩展医疗AI**

*Michelle M. Li,Ben Y. Reis,Adam Rodman,Tianxi Cai,Noa Dagan,Ran D. Balicer,Joseph Loscalzo,Isaac S. Kohane,Marinka Zitnik*

Main category: cs.AI

TL;DR: The paper proposes context-switching AI for medical applications to dynamically adapt to diverse clinical contexts without retraining, addressing limitations of current models prone to contextual errors.


<details>
  <summary>Details</summary>
Motivation: Current medical AI models struggle with dynamically adjusting to new populations, specialties, or settings, leading to contextual errors. The paper aims to overcome this by proposing context-switching AI.

Method: The paper outlines a vision for AI models that dynamically adapt their reasoning to new specialties, populations, workflows, and clinical roles without requiring retraining.

Result: The envisioned context-switching AI can diagnose, manage, and treat diseases across specialties and regions, improving access to medical care.

Conclusion: Context-switching AI has the potential to revolutionize medical care by dynamically adapting to diverse clinical contexts, reducing errors, and expanding access.

摘要: 医疗基础模型，包括基于临床笔记训练的语言模型、基于医学图像的视觉语言模型以及基于电子健康记录的多模态模型，可以总结临床笔记、回答医学问题并辅助决策。将这些模型适应新的人群、专业或环境通常需要微调、精心设计的提示或从知识库中检索。这可能不切实际，并限制了它们解释不熟悉输入和适应训练中未涵盖的临床情境的能力。因此，模型容易出现情境错误，即预测看似合理但未能考虑关键的特定患者或情境信息。这些错误源于当前模型的一个基本局限：难以在医疗护理的不断变化情境中动态调整其行为。本文展望了医疗AI中的情境切换愿景：模型能够在不重新训练的情况下动态适应新的专业、人群、工作流程和临床角色。我们设想情境切换AI能够跨专业和地区诊断、管理和治疗多种疾病，并扩大医疗服务的可及性。

</details>


### [414] [Correlation vs causation in Alzheimer's disease: an interpretability-driven study](https://arxiv.org/abs/2506.10179)
**中文标题：阿尔茨海默病中的相关性与因果关系：一项以可解释性为导向的研究**

*Hamzah Dabool,Raghad Mustafa*

Main category: cs.AI

TL;DR: The study explores the difference between correlation and causation in Alzheimer's disease (AD) research, using machine learning and interpretability techniques to identify key features influencing AD classification. Results show that strong correlations do not imply causation, underscoring the need for careful data interpretation.


<details>
  <summary>Details</summary>
Motivation: To distinguish between correlation and causation in AD research, as this distinction is crucial for accurate diagnosis, treatment, and identifying true disease drivers.

Method: Combined correlation analysis, machine learning (XGBoost), and interpretability techniques (SHAP values) to analyze clinical, cognitive, genetic, and biomarker features.

Result: Identified key AD-influencing features (e.g., cognitive scores, genetic risk factors) and showed that strong correlations do not necessarily indicate causation.

Conclusion: Careful interpretation of associative data is essential, and integrating feature importance with classical analysis can pave the way for future causal inference studies in AD.

摘要: 理解因果关系与相关性的区别在阿尔茨海默病（AD）研究中至关重要，因为它影响诊断、治疗以及真正疾病驱动因素的识别。本研究结合相关性分析、机器学习分类和模型可解释性技术，探究了临床、认知、遗传和生物标志物特征之间的关系。采用XGBoost算法，我们识别出影响AD分类的关键特征，包括认知评分和遗传风险因素。相关性矩阵揭示了相互关联的变量群，而SHAP（SHapley Additive exPlanations）值则提供了跨疾病阶段的特征贡献详细见解。我们的结果表明，强相关性并不一定意味着因果关系，强调了仔细解释关联数据的必要性。通过将特征重要性和可解释性与经典统计分析相结合，本研究为未来旨在揭示真正病理机制的因果推断研究奠定了基础。最终，区分因果因素与相关标记可以改善阿尔茨海默病的早期诊断和针对性干预。

</details>


### [415] [Towards Responsible AI: Advances in Safety, Fairness, and Accountability of Autonomous Systems](https://arxiv.org/abs/2506.10192)
**中文标题：迈向负责任的人工智能：自主系统在安全性、公平性和问责性方面的进展**

*Filip Cano*

Main category: cs.AI

TL;DR: This thesis advances responsible AI by improving safety, fairness, and accountability in autonomous systems through deterministic and probabilistic shielding techniques, fairness shields, and a formal framework for assessing intentional behavior.


<details>
  <summary>Details</summary>
Motivation: As AI systems increasingly impact critical societal domains, ensuring their responsible use—encompassing safety, fairness, transparency, and accountability—has become imperative.

Method: The study extends deterministic shielding for safety, introduces fairness shields for group fairness, and proposes a formal framework for assessing intentional behavior in AI agents.

Result: The methods validate practical deployment in autonomous vehicles, balance fairness with minimal interference, and provide metrics for retrospective analysis of unintended harm.

Conclusion: The contributions collectively advance safer, fairer, and more accountable AI systems, laying groundwork for future trustworthy AI research.

摘要: 随着自主系统日益影响关键社会领域，确保人工智能（AI）的负责任使用变得至关重要。然而，可信AI的概念仍然广泛且多面。本论文在AI系统的安全性、公平性、透明性和问责性方面推进了知识。在安全性方面，我们扩展了经典的确定性屏蔽技术，使其对延迟观察具有弹性，从而能够在实际条件下部署。我们还将确定性和概率性安全屏蔽应用于模拟自动驾驶车辆，以防止与道路使用者发生碰撞，并在真实驾驶模拟器中验证了这些技术的有效性。我们引入了公平性屏蔽，这是一种新颖的后处理方法，用于在有限和周期性时间范围内的顺序决策设置中强制执行群体公平性。通过优化干预成本并严格确保公平性约束，该方法高效地平衡了公平性与最小干扰。在透明性和问责性方面，我们提出了一个正式框架，用于评估概率决策代理中的有意行为，引入了代理和意图商的定量指标。我们利用这些指标提出了意图的回顾性分析，有助于在自主系统造成意外伤害时确定责任。最后，我们通过“反应式决策”框架统一了这些贡献，提供了一个整合先前方法的通用形式化。总的来说，这些进展为更安全、更公平和更负责任的AI系统的实现做出了实际贡献，为未来可信AI的研究奠定了基础。

</details>


### [416] [WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2506.10264)
**中文标题：WGSR-Bench：基于兵棋推演的博弈论战略推理基准测试用于大型语言模型**

*Qiyue Yin,Pei Xu,Qiaozhe Li,Shengda Liu,Shengqi Shen,Tong Wang,Yihong Han,Xiaonan Zhao,Likun Yang,Shiyue Cao,Shiyu Qiu,Yuxuan Liu,Shizhao Yu,Lei Cui,Chengxin Yan,Jie Sun,Xiangquan Tang,Kaiqi Huang*

Main category: cs.AI

TL;DR: WGSR-Bench is a new benchmark for evaluating strategic reasoning in LLMs using wargame scenarios, focusing on multi-agent dynamics, intent inference, and counterfactual reasoning.


<details>
  <summary>Details</summary>
Motivation: To address the lack of systematic evaluation for strategic reasoning in LLMs, despite their advancements in other reasoning tasks.

Method: Introduces WGSR-Bench, a benchmark using wargame scenarios to test LLMs on environmental awareness, opponent risk modeling, and policy generation.

Result: Designs an LLM-based wargame agent to comprehensively assess strategic reasoning capabilities.

Conclusion: WGSR-Bench aims to evaluate LLMs' strategic reasoning and advance research in model-driven strategic intelligence.

摘要: 近年来，大型语言模型（LLMs）的突破性进展使得人工智能在推理任务上的表现实现了质的飞跃，尤其是在数学、符号和常识推理方面展现出卓越能力。然而，作为高级人类认知的关键组成部分，战略推理——即在动态环境中评估多主体行为、制定行动计划并调整策略的能力——尚未得到系统性评估或建模。为填补这一空白，本文提出了WGSR-Bench，首个以兵棋推演为评估环境的LLMs战略推理基准测试。兵棋推演作为一种典型的高复杂度战略场景，融合了环境不确定性、对抗动态和非唯一战略选择，使其成为评估LLMs在多主体决策、意图推断和反事实推理方面能力的有效测试平台。WGSR-Bench围绕三个核心任务设计测试样本，即环境态势感知、对手风险建模和政策生成，这些任务构成了核心的S-POE架构，用于系统性评估战略推理的主要能力。最后，设计了一个基于LLM的兵棋推演代理，将这些部分整合以进行全面战略推理评估。通过WGSR-Bench，我们希望评估最先进LLMs在博弈论战略推理中的优势与局限，并推动大型模型驱动的战略智能研究。

</details>


### [417] [Closer to Language than Steam: AI as the Cognitive Engine of a New Productivity Revolution](https://arxiv.org/abs/2506.10281)
**中文标题：比蒸汽更接近语言：AI作为新生产力革命的认知引擎**

*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

Main category: cs.AI

TL;DR: The paper reframes AI as a cognitive engine driving a new productivity revolution, akin to written language, enhancing human intellect rather than mechanizing tasks. It argues AI's role in amplifying knowledge work and reshaping society, calling for rethinking skills and policies.


<details>
  <summary>Details</summary>
Motivation: To conceptualize AI as a transformative cognitive revolution, distinct from the Industrial Revolution, and explore its impact on productivity, work, and society.

Method: The paper adopts a multidisciplinary approach, combining computer science, economics, and sociology, using historical comparisons and domain examples to illustrate AI's cognitive productivity role.

Result: AI is shown to function as an engine of cognition, amplifying knowledge work and heralding a new productivity paradigm, requiring shifts in skills, organizations, and policies.

Conclusion: AI complements human cognitive abilities, marking a new chapter in productivity evolution, demanding societal and policy adaptations.

摘要: 人工智能（AI）被重新定义为一种认知引擎，推动着一种与工业革命的物理推力截然不同的新型生产力革命。本文提出了一种理论框架，将AI视为类似于书面语言的认知革命——一种对人类智力的变革性增强，而非另一种机械化工具。我们通过比较AI的出现与信息技术的历史飞跃，展示了它如何放大知识工作。来自不同领域的例子证明了AI作为认知任务生产力驱动者的影响。我们采用多学科视角，结合计算机科学的进步、经济学的见解和社会学的观点，探讨AI如何重塑工作和社会。通过概念框架，我们描绘了从手工生产力到认知生产力的转变。我们的核心论点是，AI作为一种认知引擎——类似于人类语言如何革命化知识——预示着一种新的生产力范式。我们讨论了这场革命如何要求对技能、组织和政策进行重新思考。本文在学术严谨性与清晰性之间取得平衡，得出结论：AI的潜力在于补充人类认知能力，标志着生产力演化的新篇章。

</details>


### [418] [The Alignment Trap: Complexity Barriers](https://arxiv.org/abs/2506.10304)
**中文标题：对齐陷阱：复杂性壁垒**

*Jasper Yao*

Main category: cs.AI

TL;DR: The paper identifies fundamental computational complexity barriers in verifying AI safety as system capabilities scale, showing that safety verification becomes exponentially harder and coNP-complete beyond a critical threshold. It formalizes the Capability-Risk Scaling dynamic and proves four core theorems, concluding with a strategic trilemma for AI development.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the growing challenge of ensuring AI safety as systems become more capable, highlighting the tension between increasing capabilities and the computational intractability of verifying safety.

Method: The method involves formalizing the Capability-Risk Scaling dynamic and proving four core theorems using complexity theory to analyze the relationship between AI expressiveness and safety verification.

Result: The results show that safety verification becomes exponentially harder with system expressiveness, safe policies are extremely rare, no finite alignment techniques can cover all cases, and robust safety properties are measure-zero for neural networks.

Conclusion: The conclusion presents a strategic trilemma: constrain system complexity for verifiable safety, accept unverifiable risks, or develop new safety paradigms beyond verification.

摘要: 我们建立了验证AI安全性在系统能力扩展时的基本计算复杂性壁垒。主要结果表明，对于表达能力EXP$(m)$超过临界阈值$\tau$的AI系统，安全性验证需要指数时间且是coNP完全的。我们形式化了能力-风险缩放（CRS）动态，展示了AI能力的提升如何推动社会安全需求趋向完美，从而与验证复杂性形成不可避免的紧张关系。通过四个核心定理，我们证明了（1）验证复杂性随系统表达能力的提升呈指数增长，（2）安全策略仅占策略空间的$2^{-2^m}$比例，（3）有限的校准技术无法提供全覆盖，（4）鲁棒的安全性质在神经网络中构成测度为零的集合。这些结果刻画了一个“难解性缺口”，即实际安全需求落在计算难解性区域内。最后，我们提出了一个战略三难选择：AI开发必须限制系统复杂性以保持可验证的安全性，接受不可验证的风险以扩展能力，或开发超越验证的全新安全范式。我们的工作首次对AI对齐进行了系统的复杂性理论分析，并确立了任何安全方法必须面对的严格界限。核心定理在Lean4中的形式化验证正在进行中。

</details>


### [419] [A Benchmark for Generalizing Across Diverse Team Strategies in Competitive Pokémon](https://arxiv.org/abs/2506.10326)
**中文标题：一个用于在竞争性宝可梦中跨多样化团队策略泛化的基准**

*Cameron Angliss,Jiaxun Cui,Jiaheng Hu,Arrasy Rahman,Peter Stone*

Main category: cs.AI

TL;DR: The paper introduces VGC-Bench, a benchmark for AI agents to generalize across diverse team strategies in Pokémon VGC, highlighting the challenge of adapting to large combinatorial team spaces and providing baselines for future research.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of developing AI agents that can adapt to vastly different strategic landscapes in multi-agent environments, particularly in Pokémon VGC, where team configurations are highly combinatorial and strategies shift dramatically.

Method: The authors introduce VGC-Bench, a benchmark with standardized evaluation protocols, human-play datasets, and baselines including large-language-model agents, behavior cloning, reinforcement learning, and game-theoretic methods like self-play and double oracle.

Result: While methods succeed in single-team settings, they struggle to scale as team size grows, indicating policy generalization across diverse team strategies remains a significant challenge.

Conclusion: Generalization across diverse team strategies in Pokémon VGC is an open challenge, and VGC-Bench provides a foundation for future research with its infrastructure and baselines.

摘要: 开发能够在不重新训练的情况下稳健适应截然不同战略环境的AI代理是多智能体学习的核心挑战。宝可梦视频游戏锦标赛（VGC）是一个拥有约10^139种可能团队配置的领域，远大于Dota或星际争霸。宝可梦VGC中团队构建的高度离散和组合性质导致最优策略根据所操控的团队和对手团队而剧烈变化，使得泛化尤为困难。为了推动这一问题的研究，我们引入了VGC-Bench：一个提供关键基础设施、标准化评估协议、人类游戏数据集以及一系列基线的基准——从大型语言模型代理和行为克隆到强化学习及经验博弈论方法（如自我对弈、虚构对弈和双重预言）。在代理在单一团队配置上训练和评估的限制性设置中，我们的方法能够击败专业VGC选手。我们在逐渐增大的团队集上对所有基线方法进行了广泛评估，发现即使在单一团队设置中表现最佳的算法在团队规模扩大时也面临困难。因此，跨多样化团队策略的策略泛化仍然是社区面临的开放挑战。我们的代码已在https://github.com/cameronangliss/VGC-Bench开源。

</details>


### [420] [Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts](https://arxiv.org/abs/2506.10357)
**中文标题：Optimus-3：迈向具有可扩展任务专家的通用多模态 Minecraft 智能体**

*Zaijing Li,Yuquan Xie,Rui Shao,Gongwei Chen,Weili Guan,Dongmei Jiang,Liqiang Nie*

Main category: cs.AI

TL;DR: The paper introduces Optimus-3, a generalist multimodal agent for Minecraft, addressing challenges like data scarcity, task interference, and visual diversity through scalable data generation, a Mixture-of-Experts architecture, and multimodal reinforcement learning.


<details>
  <summary>Details</summary>
Motivation: Building a generalist agent in open-world environments like Minecraft is challenging due to insufficient domain-specific data, task interference, and visual diversity. The paper aims to overcome these challenges.

Method: 1) A knowledge-enhanced data generation pipeline for scalable training data. 2) A Mixture-of-Experts (MoE) architecture with task-level routing to reduce task interference. 3) Multimodal Reasoning-Augmented Reinforcement Learning for handling visual diversity.

Result: Optimus-3 outperforms generalist multimodal large language models and state-of-the-art agents across diverse tasks in Minecraft.

Conclusion: Optimus-3 demonstrates the effectiveness of scalable data generation, MoE architecture, and multimodal reinforcement learning in building generalist agents for complex open-world environments.

摘要: 近年来，基于多模态大语言模型（MLLMs）的智能体在多个领域取得了显著进展。然而，在像 Minecraft 这样的开放世界中构建具备感知、规划、行动、基础和反思等能力的通用智能体仍然面临挑战：领域特定数据不足、异构任务之间的干扰以及开放世界中的视觉多样性。本文通过三个关键贡献解决这些挑战：1）提出了一种知识增强的数据生成管道，为智能体开发提供可扩展且高质量的训练数据；2）为了减少异构任务之间的干扰，引入了具有任务级路由的混合专家（MoE）架构；3）开发了一种多模态推理增强的强化学习方法，以增强智能体在 Minecraft 中处理视觉多样性的推理能力。基于这些创新，我们提出了 Optimus-3，一种适用于 Minecraft 的通用智能体。大量实验结果表明，Optimus-3 在 Minecraft 环境中的广泛任务上超越了通用多模态大语言模型和现有的最先进智能体。项目页面：https://cybertronagent.github.io/Optimus-3.github.io/

</details>


### [421] [NeuroPAL: Punctuated Anytime Learning with Neuroevolution for Macromanagement in Starcraft: Brood War](https://arxiv.org/abs/2506.10384)
**中文标题：NeuroPAL：基于神经进化的间断式随时学习在《星际争霸：母巢之战》宏观管理中的应用**

*Jim O'Connor,Yeonghun Lee,Gary B Parker*

Main category: cs.AI

TL;DR: NeuroPAL combines NEAT with Punctuated Anytime Learning (PAL) to improve StarCraft AI macromanagement, achieving faster training and emergent human-like strategies.


<details>
  <summary>Details</summary>
Motivation: Traditional StarCraft AI methods (rule-based or deep learning) lack adaptability and efficiency. NeuroPAL aims to enhance neuroevolution's scalability in complex real-time strategy games.

Method: NeuroPAL integrates NEAT with PAL, alternating low-fidelity training and high-fidelity evaluations to boost sample efficiency and strategy discovery.

Result: PAL accelerates learning by 50% compared to standard NEAT, with agents exhibiting expert human strategies like proxy barracks placement.

Conclusion: Structured evaluation mechanisms like PAL enhance neuroevolution's effectiveness in complex environments like StarCraft.

摘要: 《星际争霸：母巢之战》仍然是人工智能研究中的一个具有挑战性的基准，尤其是在需要长期战略规划的宏观管理领域。传统的星际争霸AI方法依赖于基于规则的系统或有监督的深度学习，但两者在适应性和计算效率方面均存在局限性。本文提出NeuroPAL，一种将增强拓扑神经进化（NEAT）与间断式随时学习（PAL）相结合的神经进化框架，以提高进化训练的效率。通过交替进行频繁的低保真训练和周期性的高保真评估，PAL提升了NEAT的样本效率，使智能体能够在更少的训练迭代中发现有效策略。我们在《星际争霸：母巢之战》的固定地图、单一种族场景中评估NeuroPAL，并将其性能与基于标准NEAT的训练进行比较。结果表明，PAL显著加速了学习过程，使智能体在仅需NEAT一半的训练时间内达到竞技水平。此外，进化后的智能体表现出如代理兵营布置和防御建筑优化等专家级人类玩家常用的涌现行为。这些发现表明，像PAL这样的结构化评估机制可以增强神经进化在复杂即时战略环境中的可扩展性和有效性。

</details>


### [422] [Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org/abs/2506.10387)
**中文标题：Mirage-1：通过分层多模态技能增强和更新GUI代理**

*Yuquan Xie,Zaijing Li,Rui Shao,Gongwei Chen,Kaiwen Zhou,Yinchuan Li,Dongmei Jiang,Liqiang Nie*

Main category: cs.AI

TL;DR: The paper introduces Mirage-1, a GUI agent with a Hierarchical Multimodal Skills (HMS) module and Skill-Augmented Monte Carlo Tree Search (SA-MCTS) to improve long-horizon task performance in online environments. It outperforms previous agents by significant margins on multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing GUI agents struggle with long-horizon tasks due to insufficient knowledge and the gap between offline and online domains. The paper aims to address these issues by mimicking how humans generalize knowledge.

Method: Proposes HMS for hierarchical knowledge abstraction (execution skills, core skills, meta-skills) and SA-MCTS to bridge the domain gap by leveraging offline skills in online exploration.

Result: Mirage-1 outperforms previous agents by 32%, 19%, 15%, and 79% on AndroidWorld, MobileMiniWob++, Mind2Web-Live, and AndroidLH benchmarks, respectively.

Conclusion: Mirage-1 demonstrates significant improvements in handling long-horizon tasks in online environments, validated by a new benchmark (AndroidLH) and outperforming existing agents.

摘要: 近年来，利用多模态大语言模型（MLLM）作为GUI代理的研究取得了显著成果。然而，这些代理在在线环境中的长时任务中仍表现不佳，主要原因是知识不足以及离线与在线领域之间的固有差距。本文受人类在开放环境中泛化知识的启发，提出了分层多模态技能（HMS）模块，以解决知识不足的问题。该模块逐步将轨迹抽象为执行技能、核心技能和元技能，为长时任务规划提供分层知识结构。为弥合领域差距，我们提出了技能增强蒙特卡洛树搜索（SA-MCTS）算法，该算法高效利用离线环境中习得的技能，以减少在线树探索中的动作搜索空间。基于HMS，我们提出了Mirage-1，一种多模态、跨平台、即插即用的GUI代理。为验证Mirage-1在真实世界长时任务中的性能，我们构建了一个新的基准测试AndroidLH。实验结果表明，Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH上的表现分别优于之前的代理32%、19%、15%和79%。项目页面：https://cybertronagent.github.io/Mirage-1.github.io/

</details>


### [423] [Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges](https://arxiv.org/abs/2506.10408)
**中文标题：通过系统1或系统2推理RAG：面向行业挑战的推理代理检索增强生成综述**

*Jintao Liang,Gang Su,Huifeng Lin,You Wu,Rui Zhao,Ziyue Li*

Main category: cs.AI

TL;DR: The paper surveys Reasoning Agentic RAG, categorizing it into predefined and agentic reasoning systems, and discusses challenges and future directions for enhancing flexibility and robustness.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of early RAG systems in complex real-world scenarios requiring dynamic reasoning and multi-modal integration.

Method: The paper reviews and categorizes Reasoning Agentic RAG methods into predefined reasoning (fixed pipelines) and agentic reasoning (autonomous tool use), analyzing their designs and strategies.

Result: The survey highlights the effectiveness of Reasoning Agentic RAG in complex tasks and identifies key research challenges for future improvements.

Conclusion: The paper emphasizes the need for advancing Reasoning Agentic RAG systems to improve flexibility, robustness, and applicability in real-world scenarios.

摘要: 检索增强生成（RAG）作为一种强大的框架，通过将外部检索与语言生成相结合，克服了大型语言模型（LLM）的知识局限性。虽然基于静态管道的早期RAG系统在结构化任务中表现出色，但在需要复杂推理、动态检索和多模态集成的现实场景中表现不佳。为解决这些挑战，领域转向了推理代理RAG，该范式将决策和自适应工具使用直接嵌入检索过程。本文全面综述了推理代理RAG方法，将其分为两大类：预定义推理（遵循固定模块化管道以增强推理）和代理推理（模型在推理过程中自主协调工具交互）。我们分析了两种范式下的代表性技术，涵盖架构设计、推理策略和工具协调。最后，我们讨论了关键研究挑战，并提出了未来方向，以提升推理代理RAG系统的灵活性、鲁棒性和适用性。相关研究已整理至https://github.com/ByebyeMonica/Reasoning-Agentic-RAG。

</details>


### [424] [Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods](https://arxiv.org/abs/2506.10420)
**中文标题：处理服务的多维自动扩展：基于代理方法的比较**

*Boris Sedlak,Alireza Furutanpey,Zihang Wang,Víctor Casamayor Pujol,Schahram Dustdar*

Main category: cs.AI

TL;DR: The paper compares four agent-based methods for multi-dimensional autoscaling in edge computing, demonstrating their viability for dynamic resource and configuration adjustments in constrained environments.


<details>
  <summary>Details</summary>
Motivation: Edge computing's strict resource constraints necessitate flexible autoscaling methods that can dynamically adjust both hardware resources and service configurations to meet performance requirements.

Method: The study introduces an agent-based framework comparing four scaling agents (Active Inference, Deep Q Network, Analysis of Structural Knowledge, and Deep Active Inference) using real-world services (YOLOv8 and OpenCV) to evaluate performance.

Result: All agents achieved acceptable SLO performance with distinct convergence patterns: Deep Q Network benefits from pre-training, structural analysis converges quickly, and deep active inference combines theory with scalability.

Conclusion: Multi-dimensional agent-based autoscaling is viable for edge environments, encouraging further research in this direction.

摘要: 边缘计算由于严格的资源限制打破了传统的自动扩展方式，因此需要更灵活的扩展行为，利用多个弹性维度。本文提出了一种基于代理的自动扩展框架，动态调整硬件资源和内部服务配置，以在受限环境中最大化需求满足。我们比较了四种扩展代理：主动推理、深度Q网络、结构知识分析和深度主动推理，使用两个并行运行的实际处理服务：YOLOv8用于视觉识别和OpenCV用于QR码检测。结果显示，所有代理均实现了可接受的SLO性能，但收敛模式各异。深度Q网络受益于预训练，结构分析收敛迅速，而深度主动推理代理结合了理论基础和实际可扩展性优势。我们的研究结果为边缘环境中基于代理的多维自动扩展的可行性提供了证据，并鼓励未来在这一研究方向上的工作。

</details>


### [425] [OIBench: Benchmarking Strong Reasoning Models with Olympiad in Informatics](https://arxiv.org/abs/2506.10481)
**中文标题：OIBench：用信息学奥赛评测强推理模型**

*Yaoming Zhu,Junxin Wang,Yiyang Li,Lin Qiu,ZongYu Wang,Jun Xu,Xuezhi Cao,Yuhuai Wei,Mingshi Wang,Xunliang Cai,Rong Ma*

Main category: cs.AI

TL;DR: OIBench is a challenging olympiad-level informatics benchmark with 250 curated problems, designed to evaluate and advance algorithmic reasoning in models. It shows current SOTA models outperform humans but still fall short of canonical solutions.


<details>
  <summary>Details</summary>
Motivation: Conventional algorithm benchmarks are saturated, necessitating more challenging benchmarks to guide improvements in algorithmic reasoning.

Method: OIBench is constructed with 250 original problems, covering various programming paradigms and complexities, and includes Time/Space Completion Curves for efficiency analysis and human-model comparisons.

Result: Current SOTA models outperform most human participants in correctness and efficiency but are suboptimal compared to canonical solutions.

Conclusion: OIBench, as an open-source resource, aims to advance code reasoning capabilities in future LLMs.

摘要: 随着模型日益复杂，传统算法基准逐渐饱和，亟需更具挑战性的基准来指导算法推理的未来改进。本文介绍了OIBench，一个高质量、私密且具有挑战性的信息学奥赛级别数据集，包含250道精心设计的原创题目。我们详细阐述了基准的构建方法，确保全面评估各种编程范式和复杂度，并通过实验展示了其抗污染特性。我们提出时间/空间完成曲线以进行更精细的效率分析，并通过高水平参与者评估实现人机直接比较。实验表明，开源模型虽落后于闭源模型，但当前SOTA模型在正确性和效率上已超越大多数人类参与者，但仍未达到标准解决方案的水平。通过将OIBench作为完全开源资源发布（https://huggingface.co/datasets/AGI-Eval/OIBench），我们希望该基准能为未来大语言模型的代码推理能力提升做出贡献。

</details>


### [426] [Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning](https://arxiv.org/abs/2506.10521)
**中文标题：科学家的首次考试：通过感知、理解与推理评估多模态大语言模型的认知能力**

*Yuhao Zhou,Yiheng Wang,Xuming He,Ruoyao Xiao,Zhiwei Li,Qiantai Feng,Zijie Guo,Yuejin Yang,Hao Wu,Wenxuan Huang,Jiaqi Wei,Dan Si,Xiuqi Yao,Jia Bu,Haiwen Huang,Tianfan Fu,Shixiang Tang,Ben Fei,Dongzhan Zhou,Fenghua Ling,Yan Lu,Siqi Sun,Chenhui Li,Guanjie Zheng,Jiancheng Lv,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: The paper introduces the Scientists' First Exam (SFE) benchmark to evaluate Multimodal Large Language Models (MLLMs) on scientific perception, understanding, and reasoning, revealing significant gaps in current models' performance.


<details>
  <summary>Details</summary>
Motivation: Current scientific benchmarks inadequately assess MLLMs' perception and reasoning abilities, limiting their potential in scientific discovery. The SFE benchmark aims to fill this gap.

Method: The SFE benchmark includes 830 expert-verified VQA pairs across three question types and 66 multimodal tasks in five disciplines, testing perception, understanding, and reasoning.

Result: State-of-the-art models GPT-o3 and InternVL-3 scored only 34.08% and 26.52% on SFE, indicating substantial room for improvement.

Conclusion: The SFE benchmark highlights the need for further development of MLLMs in scientific domains to enhance AI-driven discoveries.

摘要: 科学发现日益依赖于基于信息密集型科学数据和领域专业知识的复杂多模态推理。通过专家级科学基准的支持，科学多模态大语言模型（MLLMs）有望在实际工作流程中显著提升这一发现过程。然而，目前的科学基准主要关注评估MLLMs的知识理解能力，导致对其感知和推理能力的评估不足。为解决这一问题，我们提出了“科学家的首次考试”（SFE）基准，旨在通过三个相互关联的层次评估MLLMs的科学认知能力：科学信号感知、科学属性理解和科学比较推理。具体而言，SFE包含830个经过专家验证的视觉问答对，涵盖三种问题类型，分布在五个高价值学科的66项多模态任务中。大量实验表明，当前最先进的GPT-o3和InternVL-3在SFE上的得分仅为34.08%和26.52%，凸显了MLLMs在科学领域仍有巨大改进空间。我们希望SFE的见解能进一步推动AI增强科学发现的发展。

</details>


### [427] [LogiPlan: A Structured Benchmark for Logical Planning and Relational Reasoning in LLMs](https://arxiv.org/abs/2506.10527)
**中文标题：LogiPlan：用于大语言模型逻辑规划与关系推理的结构化基准**

*Yanan Cai,Ahmed Salem,Besmira Nushi,Mark Russinovich*

Main category: cs.AI

TL;DR: LogiPlan is a benchmark for evaluating LLMs' logical planning and relational reasoning abilities, featuring tasks like plan generation, consistency detection, and comparison questions. It reveals performance gaps among top models.


<details>
  <summary>Details</summary>
Motivation: To assess LLMs' capabilities in logical planning and relational reasoning, crucial for applications like network infrastructure and knowledge bases, by providing a dynamic and fine-grained evaluation framework.

Method: LogiPlan includes three tasks (Plan Generation, Consistency Detection, Comparison Question) with adjustable complexity. It evaluates models like GPT-4.5 and Claude 3.7 Sonnet, testing their self-correction abilities.

Result: State-of-the-art models perform well on simpler tasks but struggle with complex configurations, showing performance gaps linked to model scale and architecture.

Conclusion: While reasoning-enhanced models show promise, deeper logical planning remains challenging, highlighting the need for further advancements in LLM capabilities.

摘要: 我们推出了LogiPlan，这是一个新颖的基准测试，旨在评估大语言模型（LLMs）在逻辑规划和复杂关系结构推理方面的能力。逻辑关系推理对于依赖LLMs生成和查询关系图的应用（如网络基础设施、知识库或业务流程模式）至关重要。我们的框架通过控制对象数量、关系数量以及关系链的最小深度，动态调整任务复杂度，从而实现对模型在不同难度级别上的细粒度评估。LogiPlan包含三项互补任务：（1）计划生成，模型需构建满足特定结构约束的有效有向关系图；（2）一致性检测，测试模型识别关系结构中不一致性的能力；（3）比较问题，评估模型在给定图中判断查询关系有效性的能力。此外，我们还通过提示模型验证和优化初始解决方案，评估其自我修正能力。我们对包括DeepSeek R1、Gemini 2.0 Pro、Gemini 2 Flash Thinking、GPT-4.5、GPT-4o、Llama 3.1 405B、O3-mini、O1和Claude 3.7 Sonnet在内的先进模型进行了评估，揭示了与模型规模和架构相关的显著性能差距。分析表明，尽管近期增强推理能力的模型在简单实例上表现良好，但在需要更深层次逻辑规划的复杂配置中仍存在困难。

</details>


### [428] [Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning](https://arxiv.org/abs/2506.10585)
**中文标题：Primender序列：一种用于测试符号推理与AI推理的新型数学构造**

*Mohd Anwar Jamal Faiz*

Main category: cs.AI

TL;DR: The paper introduces the Primender sequence, a hybrid integer sequence combining primality and digit-based conditions, as a benchmark for evaluating LLMs' symbolic reasoning. It tests models on rule inference, hypothesis validation, and sequence generation.


<details>
  <summary>Details</summary>
Motivation: The study aims to provide an interpretable, rule-based testbed for assessing LLMs' ability to infer hidden rules, validate mathematical hypotheses, and generalize symbolic logic at scale.

Method: The Primender sequence is defined by numbers that are primes or have prime suffixes. The study designs prompts to test LLMs on identifying the sequence's rule, validating a hypothesis, and generating terms, using comparative metrics for evaluation.

Result: The paper evaluates multiple LLMs (e.g., ChatGPT, Gemini) on their performance in rule inference, hypothesis validation, and sequence generation, contributing a reproducible methodology for benchmarking symbolic reasoning.

Conclusion: The Primender sequence serves as a novel benchmark for LLMs, bridging number theory, AI, and software engineering, with potential for future extensions in symbolic reasoning tasks.

摘要: 本文介绍了Primender序列，这是一种新颖的整数序列，其定义规则结合了经典素数性质与模数位条件。具体而言，若一个数n是素数或其末尾数字（任意长度）为素数，则该数被包含在序列中。换句话说，序列中的数要么是素数，要么至少有一个素数后缀。该序列展现出确定性但非平凡的结构，融合了数论性质与符号模式。我们提出将Primender序列作为评估大型语言模型（LLM）符号推理能力的基准。本研究的动机源于对可解释、基于规则的测试平台的需求，以评估LLM推断隐藏规则、验证数学假设及规模化推广符号逻辑的能力。探索的一个关键假设是：当Primender序列中的某个数恰好比小于或等于它的最大素数大1时，它与序列中前一个数的差值也为1。我们设计了一个结构化提示与评估框架，以在多个先进LLM（如ChatGPT、Copilot、DeepSeek、Gemini、Grok和LLaMA）上测试该假设。模型的任务包括识别底层规则、验证假设并生成序列的下100,000项。通过规则推断准确率、假设评估、序列有效性及符号解释质量等比较指标评估模型性能。本研究贡献了一种新颖的数学构造和可复现的方法论，用于在符号推理、假设测试和规模化模式推广方面对LLM进行基准测试，从而连接数论、人工智能与软件工程领域。

</details>


### [429] [Data Driven Diagnosis for Large Cyber-Physical-Systems with Minimal Prior Information](https://arxiv.org/abs/2506.10613)
**中文标题：基于数据驱动的大型信息物理系统诊断方法：最小先验信息需求**

*Henrik Sebastian Steude,Alexander Diedrich,Ingo Pill,Lukas Moddemann,Daniel Vranješ,Oliver Niggemann*

Main category: cs.AI

TL;DR: A new diagnostic approach for large cyber-physical systems requires minimal prior knowledge, combining neural network-based anomaly detection with a graph diagnosis algorithm, achieving high accuracy and practical applicability.


<details>
  <summary>Details</summary>
Motivation: Diagnosing complex cyber-physical systems typically demands extensive prior knowledge, which is challenging to obtain. The paper aims to develop a method that works with minimal prior information.

Method: The approach combines a neural network-based symptom generator for subsystem-level anomaly detection and a graph diagnosis algorithm using minimal causal relationship information between subsystems.

Result: Experiments show the method identifies the true causal component in 82% of cases and reduces the search space in 73% of scenarios, with successful real-world application tests.

Conclusion: The method demonstrates strong potential for practical use in large, complex cyber-physical systems with limited prior knowledge.

摘要: 复杂信息物理系统的诊断过程通常需要详细的系统模型或全面的训练数据作为先验知识，但获取这些信息具有显著挑战。为解决这一问题，我们提出了一种新的诊断方法，仅需对子系统关系的基本了解及正常运行数据。该方法结合了基于神经网络的症状生成器（用于子系统级异常检测）和一种新的图诊断算法（利用子系统间的最小因果关系信息，这些信息在实践中通常可用）。通过完全可控的模拟数据集实验，我们的方法在82%的案例中正确识别了真实因果组件，并在73%的场景中有效缩小了搜索空间。在真实世界的安全水处理数据集上的额外测试展示了该方法在实际场景中的潜力。结果表明，我们的方法在大型复杂信息物理系统中具有实际应用潜力，尤其是在先验知识有限的情况下。

</details>


### [430] [TeleMath: A Benchmark for Large Language Models in Telecom Mathematical Problem Solving](https://arxiv.org/abs/2506.10674)
**中文标题：TeleMath：大型语言模型在电信数学问题解决中的基准**

*Vincenzo Colle,Mohamed Sana,Nicola Piovesan,Antonio De Domenico,Fadhel Ayed,Merouane Debbah*

Main category: cs.AI

TL;DR: The paper introduces TeleMath, a benchmark dataset for evaluating LLMs in solving telecom-specific mathematical problems, revealing that specialized models outperform general-purpose ones.


<details>
  <summary>Details</summary>
Motivation: To assess the capability of LLMs in handling domain-specific, mathematically intensive tasks in telecommunications, an area largely unexplored.

Method: Developed TeleMath, a dataset of 500 QnA pairs covering telecom topics, using a pipeline starting with expert-crafted problems, and evaluated various LLMs.

Result: Specialized models for mathematical/logical reasoning performed best, while general-purpose models struggled despite their size.

Conclusion: TeleMath highlights the need for domain-specific benchmarks and shows the limitations of general-purpose LLMs in specialized mathematical tasks.

摘要: 人工智能在电信领域的日益普及引发了人们对大型语言模型（LLM）处理领域特定、数学密集型任务能力的兴趣。尽管最近的进展提高了LLM在一般数学推理中的表现，但它们在信号处理、网络优化和性能分析等专业领域的有效性仍未被充分探索。为填补这一空白，我们推出了TeleMath，这是首个专门设计用于评估LLM在电信领域解决数学问题能力的基准数据集。TeleMath包含500个问答对，涵盖了电信领域的广泛主题。本文概述了从专家精选问题种子开始的问答对生成流程。对多种开源LLM的评估显示，TeleMath上的最佳表现由专门为数学或逻辑推理设计的近期模型实现。相比之下，通用模型即使参数规模庞大，也常常难以应对这些挑战。我们已发布数据集和评估代码，以方便结果复现并支持未来研究。

</details>


### [431] [Automated Validation of Textual Constraints Against AutomationML via LLMs and SHACL](https://arxiv.org/abs/2506.10678)
**中文标题：基于LLM和SHACL的AutomationML文本约束自动化验证**

*Tom Westermann,Aljosha Köcher,Felix Gehlhoff*

Main category: cs.AI

TL;DR: The paper introduces a pipeline to formalize and validate textual constraints in AutomationML (AML) using LLMs and SHACL, enabling semi-automatic checks without requiring formal method expertise.


<details>
  <summary>Details</summary>
Motivation: Existing AML modeling recommendations are informal and textual, lacking automated validation capabilities within AML itself.

Method: The pipeline maps AML models to OWL ontologies via RML and SPARQL, uses LLMs to translate textual rules into SHACL constraints, and validates these against the AML ontology, with results interpreted in natural language.

Result: The approach successfully demonstrates that complex AML modeling rules can be semi-automatically checked without formal method knowledge.

Conclusion: The proposed pipeline effectively bridges the gap between informal textual constraints and automated validation in AML, enhancing usability.

摘要: AutomationML（AML）支持工程中的标准化数据交换，但现有的AML建模建议通常以非正式和文本形式的约束提出，这些约束无法在AML中自动验证。本文介绍了一种将这些约束形式化并验证的流程。首先，通过RML和SPARQL将AML模型映射到OWL本体。此外，使用大型语言模型（LLM）将文本规则翻译为SHACL约束，并在之前生成的AML本体上进行验证。最后，SHACL验证结果以自然语言自动解释。该方法在一个AML建议样本上进行了演示。结果表明，即使复杂的建模规则也可以半自动检查，而无需用户理解形式化方法或本体技术。

</details>


### [432] [System ASPMT2SMT:Computing ASPMT Theories by SMT Solvers](https://arxiv.org/abs/2506.10708)
**中文标题：系统ASPMT2SMT：通过SMT求解器计算ASPMT理论**

*Michael Bartholomew,Joohyung Lee*

Main category: cs.AI

TL;DR: The paper introduces a compiler, aspsmt2smt, that translates ASPMT programs into SMT instances, enabling SMT solvers like z3 to compute stable models, particularly effective for real number computations.


<details>
  <summary>Details</summary>
Motivation: To bridge answer set programming (ASP) and satisfiability modulo theories (SMT) by leveraging the functional stable model semantics, enabling more efficient computation of stable models for ASPMT programs.

Method: The system uses gringo for partial grounding of ASPMT programs and z3 for solving the resulting SMT instances, handling continuous changes via real number computations.

Result: The compiler effectively translates ASPMT programs into SMT instances, demonstrating success in handling real number computations for continuous reasoning.

Conclusion: The aspsmt2smt system successfully integrates ASP and SMT, providing a practical tool for computing stable models in ASPMT programs, especially for continuous domains.

摘要: 答案集编程模理论（ASPMT）是一种基于功能稳定模型语义的答案集编程与可满足性模理论结合的方法。研究表明，ASPMT程序的紧密片段可以转化为SMT实例，从而允许SMT求解器计算ASPMT程序的稳定模型。本文介绍了一个名为aspsmt2smt的编译器，实现了这一转换。该系统使用ASP基础工具gringo和SMT求解器z3。gringo对输入程序进行部分基础化，同时保留一些变量由z3处理。我们展示了该系统能够有效处理实数计算，用于连续变化的推理。

</details>


### [433] [Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering](https://arxiv.org/abs/2506.10753)
**中文标题：模拟之前先思考：符号推理协调神经计算以回答反事实问题**

*Adam Ishay,Zhun Yang,Joohyung Lee,Ilgu Kang,Dongjae Lim*

Main category: cs.AI

TL;DR: The paper introduces a neuro-symbolic method using symbolic reasoning (via Answer Set Programming) to enhance counterfactual question answering in video dynamics, achieving state-of-the-art results on CLEVRER and CRAFT benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing neuro-symbolic models for video dynamics struggle with counterfactual reasoning. The paper aims to improve this by integrating symbolic reasoning about causal relations.

Method: The method defines a causal graph for event relations and uses Answer Set Programming (ASP) to coordinate neural perception and simulation modules. For CRAFT, it employs large language models (e.g., GPT-3.5/4) as dynamics simulators with symbolic-guided prompts.

Result: The approach achieves state-of-the-art performance on CLEVRER and improves counterfactual question answering on CRAFT using symbolic-guided prompts with language models.

Conclusion: Symbolic reasoning enhances neuro-symbolic models for counterfactual reasoning, demonstrating effectiveness on benchmarks and potential for further integration with language models.

摘要: 视频动态的因果和时间推理是一个具有挑战性的问题。尽管结合符号推理与神经感知和预测的神经符号模型显示出潜力，但它们在回答反事实问题时仍存在局限。本文提出了一种方法，通过利用符号推理对事件间因果关系的分析，增强神经符号模型的反事实推理能力。我们定义了因果图来表示这些关系，并使用声明性逻辑编程方法——答案集编程（ASP）来协调感知和模拟模块。我们在CLEVRER和CRAFT两个基准上验证了方法的有效性。我们的改进在CLEVRER挑战中达到了最先进的性能，显著优于现有模型。在CRAFT基准中，我们利用大型预训练语言模型（如GPT-3.5和GPT-4）作为动态模拟器的代理。研究结果表明，通过符号因果推理指导的替代提示，该方法可以进一步提高其在反事实问题上的表现。

</details>


### [434] [OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](https://arxiv.org/abs/2506.10764)
**中文标题：OPT-BENCH：评估LLM代理在大规模搜索空间优化问题上的表现**

*Xiaozhe Li,Jixuan Chen,Xinyu Fang,Shengyuan Ding,Haodong Duan,Qingwen Liu,Kai Chen*

Main category: cs.AI

TL;DR: OPT-BENCH is a benchmark for evaluating LLM agents on large-scale optimization problems, featuring real-world ML tasks and NP problems. It introduces OPT-Agent, a framework for iterative solution refinement, and shows that historical context improves performance.


<details>
  <summary>Details</summary>
Motivation: To explore LLMs' ability in iterative optimization and solution refinement, which remains understudied despite their success in diverse tasks.

Method: OPT-BENCH includes 20 Kaggle ML tasks and 10 NP problems, and introduces OPT-Agent, an end-to-end framework for iterative reasoning and solution improvement using historical feedback.

Result: Experiments on 9 LLMs show that historical context significantly enhances optimization performance in both ML and NP tasks.

Conclusion: OPT-BENCH provides a robust benchmark for advancing LLM-driven optimization, with open-sourced datasets and tools to foster further research.

摘要: 大型语言模型（LLM）在解决多样化任务中展现出卓越能力，但其通过从先前反馈中学习来迭代优化复杂解决方案的能力尚未充分探索。为填补这一空白，我们提出了OPT-BENCH，一个全面的基准测试，旨在评估LLM代理在大规模搜索空间优化问题上的表现。OPT-BENCH包含20个来自Kaggle的真实机器学习任务和10个经典NP问题，为评估LLM代理在迭代推理和解决方案优化方面提供了多样化和挑战性的环境。为实现严格评估，我们引入了OPT-Agent，一个端到端的优化框架，模拟人类在解决复杂问题时的推理过程，通过利用历史反馈生成、验证和迭代改进解决方案。通过对来自6个模型家族的9种最先进LLM进行广泛实验，我们分析了优化迭代次数、温度设置和模型架构对解决方案质量和收敛性的影响。结果表明，结合历史上下文显著提升了ML和NP任务的优化性能。所有数据集、代码和评估工具均已开源，以推动LLM驱动的优化和迭代推理研究的进一步发展。项目页面：https://github.com/OliverLeeXZ/OPT-BENCH。

</details>


### [435] [A Study on Individual Spatiotemporal Activity Generation Method Using MCP-Enhanced Chain-of-Thought Large Language Models](https://arxiv.org/abs/2506.10853)
**中文标题：基于MCP增强思维链大语言模型的个体时空活动生成方法研究**

*Yu Zhang,Yang Hu,De Wang*

Main category: cs.AI

TL;DR: The paper proposes a framework combining chain-of-thought reasoning and Model Context Protocol (MCP) to enhance large language models' ability to simulate human spatiotemporal behaviors, validated with high-quality results in urban planning applications.


<details>
  <summary>Details</summary>
Motivation: Traditional methods for simulating human spatiotemporal behavior are computationally expensive and lack generalizability. Large language models (LLMs) show potential but struggle with spatiotemporal reasoning. The paper aims to address these limitations by integrating CoT reasoning with MCP.

Method: The framework combines a five-stage cognitive framework (CoT reasoning) with six MCP tool categories (temporal management, spatial navigation, environmental perception, personal memory, social collaboration, and experience evaluation) to enhance LLMs' spatiotemporal behavior simulation.

Result: Experiments in Shanghai's Lujiazui district showed high similarity with real mobile signaling data, achieving generation quality scores of 7.86 to 8.36. Parallel processing reduced generation time from 1.30 to 0.17 minutes per sample.

Conclusion: The framework advances LLMs' applications in urban computing, providing a practical approach for synthetic mobility data generation and supporting smart city planning and transportation forecasting.

摘要: 人类时空行为模拟对城市规划研究至关重要，但传统的基于规则和统计的方法存在计算成本高、泛化能力有限和可扩展性差的问题。尽管大语言模型（LLMs）作为“世界模拟器”表现出潜力，但在时空推理方面仍面临空间认知有限、物理约束理解不足和群体同质化倾向等挑战。本文提出了一种将思维链（CoT）推理与模型上下文协议（MCP）结合的框架，以增强LLMs模拟与验证数据模式相符的时空行为的能力。该方法通过五阶段认知框架实现类人渐进式推理，并通过六类专用MCP工具（时间管理、空间导航、环境感知、个人记忆、社会协作和经验评估）进行综合数据处理。在上海陆家嘴地区的实验中，框架在1000个生成样本中验证了有效性。结果显示生成结果与真实移动信号数据高度相似，不同基础模型的生成质量得分在7.86至8.36之间。并行处理实验显示效率提升，样本生成时间从1.30分钟降至0.17分钟（从2个进程扩展到12个进程）。该工作为将CoT推理与MCP结合用于城市行为建模提供了贡献，推动了LLMs在城市计算中的应用，并为合成移动数据生成提供了实用方法。该框架为智能城市规划、交通预测和参与式城市设计应用奠定了基础。

</details>


### [436] [GenPlanX. Generation of Plans and Execution](https://arxiv.org/abs/2506.10897)
**中文标题：GenPlanX：计划生成与执行**

*Daniel Borrajo,Giuseppe Canonaco,Tomás de la Rosa,Alfredo Garrachón,Sriram Gopalakrishnan,Simerjot Kaur,Marianela Morales,Sunandita Patra,Alberto Pozanco,Keshav Ramani,Charese Smiley,Pietro Totis,Manuela Veloso*

Main category: cs.AI

TL;DR: GenPlanX integrates LLMs with classical AI planning to interpret natural language tasks and generate executable plans, enhancing productivity in office workflows.


<details>
  <summary>Details</summary>
Motivation: Classical AI planning lacks natural language understanding, while LLMs excel at interpreting human intents. Combining both can improve task automation and human-AI collaboration.

Method: GenPlanX combines LLMs for natural language task interpretation with a classical AI planning engine and an execution framework.

Result: GenPlanX effectively assists with office-related tasks, demonstrating improved workflow efficiency and productivity.

Conclusion: GenPlanX successfully bridges the gap between natural language understanding and AI planning, offering practical benefits for human-AI collaboration.

摘要: 传统的人工智能规划技术为复杂任务生成动作序列，但在使用自然语言描述规划任务时缺乏理解能力。大型语言模型（LLM）的出现为人机交互带来了新的能力。在规划任务中，LLM 尤其擅长解读人类意图等用途。本文介绍了 GenPlanX，它将 LLM 用于基于自然语言的规划任务描述，结合了经典的人工智能规划引擎以及执行与监控框架。我们展示了 GenPlanX 在协助用户完成办公相关任务方面的有效性，突显了其通过无缝的人机协作优化工作流程和提升生产力的潜力。

</details>


### [437] [Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?](https://arxiv.org/abs/2506.10912)
**中文标题：破解有毒分子：多模态大语言模型是否准备好进行结构级分子解毒？**

*Fei Lin,Ziyang Gong,Cong Wang,Yonglin Tian,Tengchao Zhang,Xue Yang,Gen Luo,Fei-Yue Wang*

Main category: cs.AI

TL;DR: The paper introduces ToxiMol, the first benchmark for MLLMs in molecular toxicity repair, evaluating their ability to generate less toxic molecular alternatives. Results show MLLMs face challenges but exhibit potential in toxicity understanding and molecule editing.


<details>
  <summary>Details</summary>
Motivation: Toxicity is a major cause of drug development failure, yet molecular toxicity repair lacks systematic definition and benchmarking. The paper aims to fill this gap with ToxiMol.

Method: The authors create ToxiMol, a benchmark with 11 tasks and 560 toxic molecules, and propose ToxiEval, an automated evaluation framework integrating toxicity prediction, synthetic accessibility, drug-likeness, and structural similarity.

Result: Current MLLMs show significant challenges in molecular toxicity repair but demonstrate promising capabilities in toxicity understanding and structure-aware editing.

Conclusion: While MLLMs are not yet ready for structure-level molecular detoxification, they exhibit potential, highlighting the need for further research and development.

摘要: 毒性仍然是早期药物开发失败的主要原因。尽管在分子设计和性质预测方面取得了进展，但分子毒性修复任务——生成结构有效且毒性降低的分子替代物——尚未被系统定义或基准测试。为了填补这一空白，我们引入了ToxiMol，这是首个专注于分子毒性修复的通用多模态大语言模型（MLLMs）基准任务。我们构建了一个标准化数据集，涵盖11个主要任务和560个代表性有毒分子，涉及多种机制和粒度。我们设计了一个具有机制感知和任务自适应能力的提示注释流程，并基于专家毒理学知识。同时，我们提出了一个自动化评估框架ToxiEval，它将毒性终点预测、合成可及性、药物相似性和结构相似性整合到一个高通量的修复成功评估链中。我们系统评估了近30种主流通用MLLMs，并设计了多项消融研究以分析关键因素，如评估标准、候选多样性和失败归因。实验结果表明，尽管当前的MLLMs在这一任务上仍面临重大挑战，但它们开始在毒性理解、语义约束遵守和结构感知分子编辑方面展现出有前景的能力。

</details>


### [438] [Spurious Rewards: Rethinking Training Signals in RLVR](https://arxiv.org/abs/2506.10947)
**中文标题：虚假奖励：重新思考RLVR中的训练信号**

*Rulin Shao,Shuyue Stella Li,Rui Xin,Scott Geng,Yiping Wang,Sewoong Oh,Simon Shaolei Du,Nathan Lambert,Sewon Min,Ranjay Krishna,Yulia Tsvetkov,Hannaneh Hajishirzi,Pang Wei Koh,Luke Zettlemoyer*

Main category: cs.AI

TL;DR: The paper demonstrates that reinforcement learning with verifiable rewards (RLVR) can improve mathematical reasoning in models like Qwen2.5-Math-7B even with spurious rewards, though results vary across model families.


<details>
  <summary>Details</summary>
Motivation: To explore whether RLVR can elicit strong reasoning in models despite using rewards that lack correlation with correct answers, and to understand the variability in performance across different model families.

Method: The study uses RLVR with various spurious rewards (random, format-based, incorrect labels, etc.) to train models like Qwen2.5-Math-7B, Llama3, and OLMo2, analyzing their performance on mathematical reasoning tasks.

Result: RLVR significantly improved Qwen2.5-Math-7B's performance (up to 27.1% gains) even with spurious rewards, but similar gains were not observed in Llama3 or OLMo2. A distinctive behavior (code reasoning) in Qwen increased from 65% to over 90%.

Conclusion: RLVR may surface useful reasoning representations from pretraining, but its effectiveness varies by model family. Future RLVR research should validate on diverse models, not just a single choice.

摘要: 我们展示了带有可验证奖励的强化学习（RLVR）可以在某些模型中引发强大的数学推理能力，即使使用的奖励与正确答案几乎没有、没有甚至负相关。例如，RLVR将Qwen2.5-Math-7B在MATH-500上的性能提升了21.4%（随机奖励）、13.8%（格式奖励）、24.1%（错误标签）、26.0%（1-shot RL）和27.1%（多数投票）——几乎接近使用真实奖励的29.1%提升。然而，对Qwen有效的虚假奖励在其他模型家族（如Llama3或OLMo2）中往往无法带来提升。特别是，我们发现代码推理（在不实际执行代码的情况下思考代码）是Qwen2.5-Math的一种独特行为，在RLVR后显著增加，从65%上升到超过90%，即使使用虚假奖励。总体而言，我们假设，由于缺乏有用的奖励信号，RLVR可能在某种程度上利用了预训练期间学习的有用推理表示，尽管具体机制仍需未来研究。我们建议未来的RLVR研究应在多样化模型上验证，而非仅依赖单一默认选择，因为我们的研究表明，即使在完全虚假的奖励信号下，Qwen模型也能轻松获得显著的性能提升。

</details>


### [439] [A Conjecture on a Fundamental Trade-Off between Certainty and Scope in Symbolic and Generative AI](https://arxiv.org/abs/2506.10130)
**中文标题：关于符号AI与生成式AI中确定性与范围之间根本权衡的猜想**

*Luciano Floridi*

Main category: cs.AI

TL;DR: 本文提出一个猜想，揭示了人工智能系统中可证明的正确性与广泛数据映射能力之间的根本权衡：符号AI追求确定性但领域狭窄，生成式AI能处理高维数据但无法避免错误。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能系统中长期存在的隐式权衡——追求确定性（如符号AI）与追求广泛数据映射能力（如生成式AI）之间的矛盾，并将其形式化以推动理论和实践发展。

Method: 通过信息论形式化这一猜想，结合认识论、形式验证和技术哲学的视角，分析其理论依据及实际影响。

Result: 猜想表明，AI系统无法同时实现完全确定性和广泛数据映射能力，这一权衡将重塑AI评估标准、治理框架和混合系统设计。

Conclusion: 若猜想成立，将对可信AI的未来发展产生深远影响，需进一步验证其正确性以指导实践。

摘要: 本文提出一个猜想，形式化描述了人工智能（AI）系统中可证明的正确性与广泛数据映射能力之间的根本权衡。当AI系统为追求严密演绎保证（如经典符号AI）而设计时，其操作领域必须被严格限定和预结构化；反之，能够处理高维数据并生成丰富信息输出的系统（如现代生成模型）必然无法实现零错误性能，存在不可消除的错误风险。通过将这一隐式权衡显式化并开放验证，该猜想显著重构了AI的工程目标和哲学期望。文章回顾了这一矛盾的历史背景，以信息论形式陈述猜想，并将其置于认识论、形式验证和技术哲学的广泛讨论中。随后，结合不确定性、审慎认知风险和道德责任等概念，分析了其影响和后果。讨论表明，若猜想成立，将有助于重塑评估标准、治理框架和混合系统设计。结论强调，最终证明或反驳这一不等式对可信AI的未来至关重要。

</details>


### [440] [One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence](https://arxiv.org/abs/2506.10157)
**中文标题：一位患者，多重场景：通过上下文智能扩展医疗AI**

*Michelle M. Li,Ben Y. Reis,Adam Rodman,Tianxi Cai,Noa Dagan,Ran D. Balicer,Joseph Loscalzo,Isaac S. Kohane,Marinka Zitnik*

Main category: cs.AI

TL;DR: 医疗基础模型在适应新场景时存在局限性，容易产生上下文错误。本文提出了一种动态适应不同医疗场景的上下文切换AI愿景。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI模型在适应新人群、专业或环境时通常需要微调或提示调整，导致其难以动态适应未在训练中出现的临床情境，容易产生上下文错误。

Method: 提出了一种上下文切换AI的愿景，使模型能够动态适应不同专业、人群、工作流程和临床角色，而无需重新训练。

Result: 通过上下文切换AI，模型可以更灵活地诊断和管理多种疾病，扩大医疗服务的可及性。

Conclusion: 上下文切换AI有望解决医疗AI在动态适应不同场景时的局限性，提升其临床应用价值。

摘要: 医疗基础模型，包括基于临床笔记训练的语言模型、基于医学图像的视觉语言模型以及基于电子健康记录的多模态模型，能够总结临床笔记、回答医学问题并辅助决策。然而，将这些模型适应新人群、专业或环境通常需要微调、精心设计的提示或从知识库中检索，这在实际中可能不切实际，并限制了其解释陌生输入和适应训练中未涵盖的临床情境的能力。因此，模型容易产生上下文错误，即预测看似合理但未能考虑关键的特定患者或上下文信息。这些错误源于当前模型的一个基本局限性：难以在医疗护理的不断变化场景中动态调整其行为。本文提出了一种医疗AI中上下文切换的愿景：模型能够动态适应新的专业、人群、工作流程和临床角色，而无需重新训练。我们设想上下文切换AI能够跨专业和地区诊断、管理和治疗多种疾病，并扩大医疗服务的可及性。

</details>


### [441] [Correlation vs causation in Alzheimer's disease: an interpretability-driven study](https://arxiv.org/abs/2506.10179)
**中文标题：阿尔茨海默病中的相关性vs因果关系：一项基于可解释性的研究**

*Hamzah Dabool,Raghad Mustafa*

Main category: cs.AI

TL;DR: 本研究通过结合相关性分析、机器学习分类和模型可解释性技术，探讨了阿尔茨海默病（AD）中临床、认知、遗传和生物标志物特征之间的关系，强调强相关性并不等同于因果关系。


<details>
  <summary>Details</summary>
Motivation: 在阿尔茨海默病研究中，区分因果关系和相关关系对诊断、治疗及识别真正的疾病驱动因素至关重要。本研究旨在通过可解释性方法揭示这些关系。

Method: 使用XGBoost算法进行AD分类，结合相关性分析和SHAP（SHapley Additive exPlanations）值分析，评估特征对疾病分类的贡献。

Result: 研究发现认知评分和遗传风险因素是AD分类的关键特征，但强相关性变量并不一定具有因果关系。SHAP值提供了疾病不同阶段特征的详细贡献。

Conclusion: 研究强调了在关联数据中谨慎区分因果关系和相关关系的重要性，为未来揭示AD真正病理机制的因果推断研究奠定了基础。

摘要: 在阿尔茨海默病（AD）研究中，理解因果关系和相关关系的区别对诊断、治疗及识别真正的疾病驱动因素至关重要。本研究通过结合相关性分析、机器学习分类和模型可解释性技术，探讨了临床、认知、遗传和生物标志物特征之间的关系。采用XGBoost算法，我们识别了影响AD分类的关键特征，包括认知评分和遗传风险因素。相关性矩阵揭示了相互关联的变量群，而SHAP（SHapley Additive exPlanations）值则提供了疾病不同阶段特征的详细贡献。结果表明，强相关性并不一定意味着因果关系，强调了在关联数据中谨慎解释的必要性。通过将特征重要性和可解释性与经典统计分析相结合，本研究为未来揭示AD真正病理机制的因果推断研究奠定了基础。最终，区分因果因素和相关标志物有助于改善阿尔茨海默病的早期诊断和针对性干预。

</details>


### [442] [Towards Responsible AI: Advances in Safety, Fairness, and Accountability of Autonomous Systems](https://arxiv.org/abs/2506.10192)
**中文标题：迈向负责任的人工智能：自主系统在安全性、公平性和可问责性方面的进展**

*Filip Cano*

Main category: cs.AI

TL;DR: 该论文通过扩展安全屏蔽技术、提出公平屏蔽方法以及引入透明度和责任框架，推动了人工智能在安全性、公平性和可问责性方面的研究，为可信AI的实现提供了实用基础。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统在社会关键领域的影响日益增加，确保人工智能（AI）的负责任使用变得至关重要。然而，可信AI的概念仍然广泛且多面。本研究旨在填补这一空白，推动AI系统在安全性、公平性、透明度和责任性方面的知识进步。

Method: 1. 扩展经典确定性屏蔽技术，使其对延迟观测具有弹性，并在模拟自动驾驶车辆中验证其有效性。2. 提出公平屏蔽方法，通过后处理方式在有限和周期性时间范围内强制执行群体公平性。3. 引入形式化框架，用于评估概率决策代理的意图行为，并提出代理和意图商数的量化指标。4. 通过“反应式决策”框架统一这些贡献。

Result: 1. 安全屏蔽技术在实际驾驶模拟器中有效防止碰撞。2. 公平屏蔽方法在优化干预成本的同时严格确保公平性。3. 量化指标可用于追溯分析意图，有助于确定自主系统造成意外伤害时的责任。

Conclusion: 本研究通过多种方法提升了AI系统的安全性、公平性和可问责性，为未来可信AI的研究奠定了基础。

摘要: 随着自主系统在关键社会领域的影响力日益增强，确保人工智能（AI）的负责任使用变得至关重要。然而，可信AI的概念仍然广泛且多面。本论文在AI系统的安全性、公平性、透明度和责任性方面推动了知识进步。在安全性方面，我们扩展了经典的确定性屏蔽技术，使其对延迟观测具有弹性，从而能够在实际条件下部署。我们还将确定性和概率性安全屏蔽应用于模拟自动驾驶车辆，以防止与道路使用者发生碰撞，并在真实驾驶模拟器中验证了这些技术的有效性。我们提出了公平屏蔽方法，这是一种新颖的后处理方式，用于在有限和周期性时间范围内强制执行群体公平性。通过优化干预成本并严格确保公平性约束，该方法在最小干扰下高效平衡了公平性。在透明度和责任性方面，我们提出了一个形式化框架，用于评估概率决策代理的意图行为，并引入了代理和意图商数的量化指标。我们利用这些指标提出了意图的追溯分析，有助于确定自主系统造成意外伤害时的责任。最后，我们通过“反应式决策”框架统一了这些贡献，提供了一个通用的形式化方法，整合了之前的研究。总体而言，这些进展为更安全、更公平和更具可问责性的AI系统的实现提供了实用基础，为未来可信AI的研究奠定了基础。

</details>


### [443] [WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2506.10264)
**中文标题：WGSR-Bench：基于兵棋游戏的博弈论战略推理基准测试用于大语言模型**

*Qiyue Yin,Pei Xu,Qiaozhe Li,Shengda Liu,Shengqi Shen,Tong Wang,Yihong Han,Xiaonan Zhao,Likun Yang,Shiyue Cao,Shiyu Qiu,Yuxuan Liu,Shizhao Yu,Lei Cui,Chengxin Yan,Jie Sun,Xiangquan Tang,Kaiqi Huang*

Main category: cs.AI

TL;DR: 本文介绍了WGSR-Bench，首个基于兵棋游戏的战略推理基准测试，用于评估大语言模型在多智能体动态环境中的战略推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学、符号和常识推理方面表现出色，但作为高级人类认知关键组成部分的战略推理能力尚未得到系统评估或建模。

Method: 通过兵棋游戏作为评估环境，设计了围绕环境态势感知、对手风险建模和政策生成三个核心任务的测试样本，构建了S-POE架构，并开发了一个基于大语言模型的兵棋代理进行全面评估。

Result: WGSR-Bench能够系统地评估大语言模型在多智能体决策、意图推断和反事实推理等方面的能力。

Conclusion: WGSR-Bench旨在揭示当前大语言模型在博弈论战略推理中的优势和局限，并推动大模型驱动的战略智能研究。

摘要: 近年来，大语言模型（LLMs）的突破性进展使其在推理任务上的表现实现了质的飞跃，尤其在数学、符号和常识推理方面展现出卓越能力。然而，作为高级人类认知的关键组成部分，战略推理（即评估多智能体在动态环境中的行为、制定行动计划并调整策略的能力）尚未得到系统评估或建模。为填补这一空白，本文提出了WGSR-Bench，这是首个基于兵棋游戏的战略推理基准测试。兵棋游戏作为一种典型的高复杂度战略场景，融合了环境不确定性、对抗动态性和非唯一战略选择，是评估LLMs在多智能体决策、意图推断和反事实推理能力的有效测试平台。WGSR-Bench围绕三个核心任务（环境态势感知、对手风险建模和政策生成）设计测试样本，构成核心S-POE架构，以系统评估战略推理的主要能力。最后，设计了一个基于LLM的兵棋代理，整合这些部分以进行全面战略推理评估。通过WGSR-Bench，我们希望评估当前最先进LLMs在博弈论战略推理中的优势和局限，并推动大模型驱动的战略智能研究。

</details>


### [444] [Closer to Language than Steam: AI as the Cognitive Engine of a New Productivity Revolution](https://arxiv.org/abs/2506.10281)
**中文标题：比蒸汽更接近语言：AI作为新生产力革命的认知引擎**

*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

Main category: cs.AI

TL;DR: 本文提出AI是一种认知引擎，类似于语言的革命性作用，推动从体力到认知生产力的转变，并探讨其对工作、社会和政策的深远影响。


<details>
  <summary>Details</summary>
Motivation: 探讨AI如何作为一种认知引擎，类似于语言的革命性作用，推动生产力的新范式，而非仅仅是一种机械化工具。

Method: 采用多学科视角，结合计算机科学、经济学和社会学，通过概念框架和历史比较，分析AI对认知生产力的影响。

Result: AI作为一种认知引擎，显著提升了知识工作的效率，并需要重新思考技能、组织结构和政策以适应这一变革。

Conclusion: AI的潜力在于补充人类认知能力，标志着生产力进化的新篇章，需要全面调整社会和经济结构以适应这一变革。

摘要: 人工智能（AI）被重新定义为一种认知引擎，推动一种不同于工业革命物理推动的新型生产力革命。本文提出了一种理论框架，将AI视为类似于书面语言的认知革命——一种对人类智力的变革性增强，而非另一种机械化工具。我们通过比较AI的出现与信息技术的历史飞跃，展示了它如何放大知识工作。来自多个领域的例子证明了AI作为认知任务生产力驱动者的影响。我们采用多学科视角，结合计算机科学的进步、经济学的见解和社会学的观点，探讨AI如何重塑工作和社会。通过概念框架，我们描绘了从体力到认知生产力的转变。我们的核心论点是，AI作为一种认知引擎，类似于人类语言对知识的革命性影响，预示着一种新的生产力范式。我们讨论了这一革命如何需要重新思考技能、组织和政策。本文在学术严谨性和清晰性之间取得平衡，结论是AI的潜力在于补充人类认知能力，标志着生产力进化的新篇章。

</details>


### [445] [The Alignment Trap: Complexity Barriers](https://arxiv.org/abs/2506.10304)
**中文标题：对齐陷阱：复杂性壁垒**

*Jasper Yao*

Main category: cs.AI

TL;DR: 本文揭示了随着AI系统能力的提升，验证其安全性的计算复杂度呈指数级增长，并证明了一些核心定理，表明安全验证在能力达到临界阈值后会变得不可行。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探讨AI系统能力提升与安全性验证之间的根本矛盾，揭示随着AI能力的增强，验证其安全性会变得计算上不可行。

Method: 通过形式化能力-风险动态（CRS）和四个核心定理，分析了AI系统表达能力与安全验证复杂度之间的关系。

Result: 主要结果表明：（1）验证复杂度随系统表达能力指数增长；（2）安全策略在策略空间中的占比极低；（3）有限的校准技术无法提供全面覆盖；（4）神经网络的稳健安全属性构成零测集。

Conclusion: 研究提出了一个战略三难困境：AI发展需在限制系统复杂度、接受不可验证风险或开发全新安全范式之间做出选择。

摘要: 我们确立了随着系统能力的扩展，验证AI安全性的基本计算复杂性壁垒。我们的主要结果表明，对于表达能力EXP$(m)$超过临界阈值$\tau$的AI系统，安全性验证需要指数时间且是coNP完全的。我们形式化了能力-风险动态（CRS），展示了AI能力的提升如何推动社会安全需求趋向完美，从而与验证复杂性形成不可避免的紧张关系。通过四个核心定理，我们证明了：（1）验证复杂度随系统表达能力指数增长；（2）安全策略在策略空间中最多占比$2^{-2^m}$；（3）有限的校准技术无法提供全面覆盖；（4）神经网络中的稳健安全属性构成零测集。这些结果刻画了一个“难解性缺口”，即实际安全需求落在计算难解区域内。最后，我们提出了一个战略三难困境：AI发展要么限制系统复杂度以保持可验证安全性，要么在扩展能力的同时接受不可验证风险，要么开发超越验证的全新安全范式。我们的工作首次对AI对齐进行了系统的复杂性理论分析，并确立了任何安全方法都必须面对的严格界限。核心定理在Lean4中的形式化验证目前正在进行中。

</details>


### [446] [A Benchmark for Generalizing Across Diverse Team Strategies in Competitive Pokémon](https://arxiv.org/abs/2506.10326)
**中文标题：一个用于评估多样化宝可梦对战团队策略泛化能力的基准**

*Cameron Angliss,Jiaxun Cui,Jiaheng Hu,Arrasy Rahman,Peter Stone*

Main category: cs.AI

TL;DR: 本文提出了VGC-Bench基准，用于评估AI代理在多样化宝可梦对战团队策略中的泛化能力，发现现有方法在单团队配置下表现良好，但在多团队扩展时面临挑战。


<details>
  <summary>Details</summary>
Motivation: 开发能够在不重新训练的情况下适应多样化战略环境的AI代理是多智能体学习的核心挑战。宝可梦视频游戏锦标赛（VGC）因其团队配置的极端复杂性和多样性，成为研究这一问题的理想领域。

Method: 作者引入了VGC-Bench基准，提供基础设施、标准化评估协议、人类对战数据集及多种基线方法（如大型语言模型代理、行为克隆、强化学习和博弈论方法）。

Result: 在单团队配置下，某些方法能击败职业选手，但随着团队规模扩大，性能显著下降，泛化能力成为主要瓶颈。

Conclusion: 跨多样化团队策略的策略泛化仍是一个未解决的挑战，VGC-Bench为社区提供了研究这一问题的工具和基准。

摘要: 开发能够在不重新训练的情况下适应多样化战略环境的AI代理是多智能体学习的核心挑战。宝可梦视频游戏锦标赛（VGC）因其团队配置的极端复杂性和多样性（约10^139种可能），成为研究这一问题的理想领域。团队构建的高度离散和组合特性使得最优策略因团队和对手的不同而剧烈变化，泛化尤为困难。为推动相关研究，我们提出了VGC-Bench：一个提供关键基础设施、标准化评估协议、人类对战数据集及多种基线方法（如大型语言模型代理、行为克隆、强化学习和博弈论方法）的基准。在单团队配置下，我们的方法能够击败职业选手。然而，随着团队规模扩大，即使是表现最佳的算法也面临显著挑战。因此，跨多样化团队策略的策略泛化仍是社区的未解难题。我们的代码已开源：https://github.com/cameronangliss/VGC-Bench。

</details>


### [447] [Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts](https://arxiv.org/abs/2506.10357)
**中文标题：Optimus-3：迈向具有可扩展任务专家的通用多模态《我的世界》智能体**

*Zaijing Li,Yuquan Xie,Rui Shao,Gongwei Chen,Weili Guan,Dongmei Jiang,Liqiang Nie*

Main category: cs.AI

TL;DR: 本文提出了Optimus-3，一种面向《我的世界》的多模态通用智能体，通过知识增强数据生成、任务级路由的专家混合架构和多模态推理增强强化学习，解决了开放世界环境中的任务干扰和视觉多样性问题。实验表明，Optimus-3在多项任务中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于多模态大语言模型的智能体在开放世界（如《我的世界》）中仍面临领域数据不足、异构任务干扰和视觉多样性等挑战。本文旨在通过创新方法构建一个通用智能体，解决这些问题。

Method: 1) 提出知识增强的数据生成管道，提供高质量训练数据；2) 采用任务级路由的专家混合架构（MoE）减少任务干扰；3) 开发多模态推理增强强化学习，提升视觉多样性处理能力。

Result: 实验结果表明，Optimus-3在《我的世界》环境中超越了通用多模态大语言模型和现有最先进智能体，表现优异。

Conclusion: Optimus-3通过数据生成、任务路由和推理增强的创新方法，成功构建了一个高效的通用智能体，为开放世界任务提供了新解决方案。

摘要: 近年来，基于多模态大语言模型（MLLMs）的智能体在多个领域取得了显著进展。然而，在开放世界环境（如《我的世界》）中构建具备感知、规划、行动、接地和反思等能力的通用智能体仍面临挑战：领域特定数据不足、异构任务间的干扰以及开放世界中的视觉多样性。本文通过三项关键贡献解决这些问题：1) 提出知识增强的数据生成管道，为智能体开发提供可扩展的高质量训练数据；2) 引入任务级路由的专家混合架构（MoE）以减少异构任务干扰；3) 开发多模态推理增强强化学习方法，提升智能体对《我的世界》中视觉多样性的推理能力。基于这些创新，我们提出了Optimus-3，一种面向《我的世界》的通用智能体。大量实验结果表明，Optimus-3在《我的世界》环境中超越了通用多模态大语言模型和现有最先进智能体。项目页面：https://cybertronagent.github.io/Optimus-3.github.io/

</details>


### [448] [NeuroPAL: Punctuated Anytime Learning with Neuroevolution for Macromanagement in Starcraft: Brood War](https://arxiv.org/abs/2506.10384)
**中文标题：NeuroPAL：基于神经进化的间断式随时学习在《星际争霸：母巢之战》宏观管理中的应用**

*Jim O'Connor,Yeonghun Lee,Gary B Parker*

Main category: cs.AI

TL;DR: 本文提出NeuroPAL框架，结合神经进化和间断式随时学习（PAL），显著提升《星际争霸：母巢之战》中宏观管理的训练效率，使智能体在更短时间内达到高水平表现。


<details>
  <summary>Details</summary>
Motivation: 《星际争霸：母巢之战》是人工智能研究的挑战性基准，传统方法（如基于规则或监督深度学习）在适应性和计算效率上存在局限。本文旨在通过神经进化改进这些不足。

Method: NeuroPAL框架将神经进化增强拓扑（NEAT）与间断式随时学习（PAL）结合，通过交替进行低精度训练和高精度评估，提升训练效率。

Result: 实验表明，PAL显著加速学习过程，智能体仅需NEAT一半的训练时间即可达到竞争水平，并涌现出人类专家常用的策略（如代理兵营放置和防御建筑优化）。

Conclusion: PAL等结构化评估机制可增强神经进化在复杂即时战略环境中的可扩展性和有效性。

摘要: 《星际争霸：母巢之战》仍是人工智能研究的重要挑战，尤其是在需要长期战略规划的宏观管理领域。传统方法（如基于规则或监督深度学习）在适应性和计算效率上存在局限。本文提出NeuroPAL框架，将神经进化增强拓扑（NEAT）与间断式随时学习（PAL）结合，通过交替进行频繁的低精度训练和周期性的高精度评估，提升NEAT的样本效率，使智能体在更少的训练迭代中发现有效策略。我们在固定地图、单一种族的场景中评估NeuroPAL，并与标准NEAT训练进行比较。结果表明，PAL显著加速学习过程，智能体仅需NEAT一半的训练时间即可达到竞争水平。此外，进化出的智能体表现出人类专家常用的策略（如代理兵营放置和防御建筑优化）。这些发现表明，PAL等结构化评估机制可增强神经进化在复杂即时战略环境中的可扩展性和有效性。

</details>


### [449] [Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org/abs/2506.10387)
**中文标题：Mirage-1：通过分层多模态技能增强和更新GUI代理**

*Yuquan Xie,Zaijing Li,Rui Shao,Gongwei Chen,Kaiwen Zhou,Yinchuan Li,Dongmei Jiang,Liqiang Nie*

Main category: cs.AI

TL;DR: 本文提出了一种名为Mirage-1的多模态GUI代理，通过分层多模态技能（HMS）模块和技能增强蒙特卡洛树搜索（SA-MCTS）算法，解决了现有代理在长时任务和跨域环境中的不足。实验表明，Mirage-1在多个基准测试中显著优于现有代理。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型（MLLM）作为GUI代理在长时任务和在线环境中表现不佳，主要由于知识不足和离线与在线领域间的差距。本文受人类在开放环境中泛化知识的启发，旨在解决这些问题。

Method: 1. 提出分层多模态技能（HMS）模块，将轨迹逐步抽象为执行技能、核心技能和元技能，形成层次化知识结构。2. 提出技能增强蒙特卡洛树搜索（SA-MCTS）算法，利用离线技能缩小在线搜索空间。3. 构建Mirage-1代理，支持多模态、跨平台和即插即用。

Result: Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH基准测试中分别优于现有代理32%、19%、15%和79%。

Conclusion: Mirage-1通过HMS和SA-MCTS显著提升了GUI代理在长时任务和跨域环境中的性能，为未来研究提供了新方向。

摘要: 近期利用多模态大型语言模型（MLLM）作为GUI代理的研究取得了显著成果，但这些代理在在线环境的长时任务中仍表现不佳，主要由于知识不足和离线与在线领域间的差距。本文受人类在开放环境中泛化知识的启发，提出分层多模态技能（HMS）模块，通过逐步抽象轨迹为执行技能、核心技能和元技能，构建层次化知识结构以支持长时任务规划。为弥合领域差距，提出技能增强蒙特卡洛树搜索（SA-MCTS）算法，高效利用离线技能缩小在线搜索空间。基于HMS，我们提出Mirage-1，一种多模态、跨平台、即插即用的GUI代理。为验证Mirage-1在真实长时任务中的性能，构建了新基准AndroidLH。实验结果显示，Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH上分别优于现有代理32%、19%、15%和79%。项目页面：https://cybertronagent.github.io/Mirage-1.github.io/

</details>


### [450] [Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges](https://arxiv.org/abs/2506.10408)
**中文标题：通过系统1或系统2推理RAG：面向工业挑战的推理代理检索增强生成综述**

*Jintao Liang,Gang Su,Huifeng Lin,You Wu,Rui Zhao,Ziyue Li*

Main category: cs.AI

TL;DR: 本文综述了推理代理检索增强生成（Reasoning Agentic RAG）方法，将其分为预定义推理和代理推理两类，分析了代表性技术，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统静态检索增强生成（RAG）系统在复杂推理和动态检索任务中表现不佳，因此需要研究更具适应性和决策能力的推理代理RAG方法。

Method: 论文将推理代理RAG方法分为两类：预定义推理（固定模块化流程）和代理推理（模型自主协调工具交互），并分析了代表性技术的架构设计、推理策略和工具协调。

Result: 研究总结了当前推理代理RAG技术的进展，提出了提升系统灵活性、鲁棒性和适用性的未来方向。

Conclusion: 推理代理RAG是解决复杂任务的关键范式，未来需进一步优化其适应性和多模态整合能力。

摘要: 检索增强生成（RAG）通过结合外部检索与语言生成，克服了大型语言模型（LLM）的知识局限性。早期的静态RAG系统在结构化任务中表现良好，但在需要复杂推理、动态检索和多模态整合的实际场景中表现不佳。为解决这些问题，研究转向了推理代理RAG，该范式将决策和自适应工具使用嵌入检索过程。本文全面综述了推理代理RAG方法，将其分为两类：预定义推理（固定模块化流程）和代理推理（模型自主协调工具交互）。我们分析了两种范式的代表性技术，涵盖架构设计、推理策略和工具协调。最后，讨论了关键研究挑战，并提出了提升推理代理RAG系统灵活性、鲁棒性和适用性的未来方向。相关研究已整理至https://github.com/ByebyeMonica/Reasoning-Agentic-RAG。

</details>


### [451] [Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods](https://arxiv.org/abs/2506.10420)
**中文标题：处理服务的多维度自动扩展：基于代理方法的比较**

*Boris Sedlak,Alireza Furutanpey,Zihang Wang,Víctor Casamayor Pujol,Schahram Dustdar*

Main category: cs.AI

TL;DR: 本文提出了一种基于代理的多维度自动扩展框架，用于边缘计算环境中的资源和服务配置动态调整。通过比较四种代理方法（主动推理、深度Q网络、结构知识分析和深度主动推理），验证了其在满足服务级别目标方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 边缘计算环境由于资源限制，传统自动扩展方法不再适用，需要更灵活的扩展行为。本文旨在探索多维度自动扩展的可行性，以满足严格的服务需求。

Method: 提出了一种基于代理的自动扩展框架，动态调整硬件资源和内部服务配置。比较了四种代理方法：主动推理、深度Q网络、结构知识分析和深度主动推理，应用于并行运行的YOLOv8视觉识别和OpenCV二维码检测服务。

Result: 所有代理方法均能实现可接受的服务级别目标性能，但收敛模式各异。深度Q网络受益于预训练，结构知识分析收敛快，深度主动推理兼具理论基础和实际扩展优势。

Conclusion: 研究证明了基于代理的多维度自动扩展在边缘环境中的可行性，并鼓励未来在这一方向的研究。

摘要: 边缘计算由于严格的资源限制，打破了传统的自动扩展方式，从而激发了利用多个弹性维度实现更灵活扩展行为的需求。本文提出了一种基于代理的自动扩展框架，动态调整硬件资源和内部服务配置，以在受限环境中最大化需求满足。我们比较了四种扩展代理：主动推理、深度Q网络、结构知识分析和深度主动推理，应用于并行运行的两种实际处理服务：YOLOv8视觉识别和OpenCV二维码检测。结果表明，所有代理均能实现可接受的服务级别目标性能，但收敛模式各异。深度Q网络受益于预训练，结构知识分析收敛快，而深度主动推理代理结合了理论基础和实际扩展优势。我们的研究为边缘环境中基于代理的多维度自动扩展的可行性提供了证据，并鼓励未来在这一研究方向的工作。

</details>


### [452] [OIBench: Benchmarking Strong Reasoning Models with Olympiad in Informatics](https://arxiv.org/abs/2506.10481)
**中文标题：OIBench：用信息学奥赛基准测试强推理模型**

*Yaoming Zhu,Junxin Wang,Yiyang Li,Lin Qiu,ZongYu Wang,Jun Xu,Xuezhi Cao,Yuhuai Wei,Mingshi Wang,Xunliang Cai,Rong Ma*

Main category: cs.AI

TL;DR: 本文介绍了OIBench，一个高质量、私密且具有挑战性的信息学奥赛级别数据集，包含250个精心设计的问题。通过实验验证其抗污染性，并提出了更细粒度的效率分析方法。实验显示，当前最先进模型在正确性和效率上已超越大多数人类参与者，但仍不及标准解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着模型日益复杂，传统算法基准逐渐饱和，需要更具挑战性的基准来指导算法推理能力的提升。

Method: 构建了OIBench数据集，包含250个原创问题，涵盖多种编程范式和复杂度；提出了时间/空间完成曲线进行效率分析；通过人类参与者评估实现直接人机对比。

Result: 开源模型表现落后于闭源模型，但当前最先进模型在正确性和效率上已超越大多数人类参与者，但仍未达到标准解决方案的水平。

Conclusion: OIBench作为开源资源发布，有望推动未来大语言模型在代码推理能力上的进步。

摘要: 随着模型日益复杂，传统算法基准逐渐饱和，凸显了需要更具挑战性的基准来指导算法推理能力的未来改进。本文介绍了OIBench，一个高质量、私密且具有挑战性的信息学奥赛级别数据集，包含250个精心设计的原创问题。我们详细描述了该基准的构建方法，确保能够全面评估各种编程范式和复杂度，并通过实验验证其抗污染性。我们提出了时间/空间完成曲线以进行更细粒度的效率分析，并通过高级参与者评估实现直接的人机对比。实验结果表明，尽管开源模型落后于闭源模型，但当前最先进模型在正确性和效率上已超越大多数人类参与者，但仍未达到标准解决方案的水平。通过将OIBench作为完全开源资源发布（https://huggingface.co/datasets/AGI-Eval/OIBench），我们希望这一基准能够为未来大语言模型的代码推理能力提升做出贡献。

</details>


### [453] [Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning](https://arxiv.org/abs/2506.10521)
**中文标题：科学家的首次考试：通过感知、理解与推理评估多模态大语言模型的认知能力**

*Yuhao Zhou,Yiheng Wang,Xuming He,Ruoyao Xiao,Zhiwei Li,Qiantai Feng,Zijie Guo,Yuejin Yang,Hao Wu,Wenxuan Huang,Jiaqi Wei,Dan Si,Xiuqi Yao,Jia Bu,Haiwen Huang,Tianfan Fu,Shixiang Tang,Ben Fei,Dongzhan Zhou,Fenghua Ling,Yan Lu,Siqi Sun,Chenhui Li,Guanjie Zheng,Jiancheng Lv,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: 本文提出了科学家首次考试（SFE）基准，用于评估多模态大语言模型（MLLM）在科学认知能力上的表现，涵盖感知、理解和推理三个层次。实验显示当前先进模型的性能仍有显著提升空间。


<details>
  <summary>Details</summary>
Motivation: 当前科学基准主要关注MLLM的知识理解能力，而忽视了感知和推理能力的评估。为填补这一空白，作者设计了SFE基准，以全面评估MLLM在科学领域的认知能力。

Method: SFE基准包含830个专家验证的视觉问答对，涵盖三种问题类型和五个高价值学科的66个多模态任务，从科学信号感知、科学属性理解和科学比较推理三个层次进行评估。

Result: 实验结果表明，当前最先进的GPT-o3和InternVL-3在SFE上的得分仅为34.08%和26.52%，表明MLLM在科学领域仍有显著改进空间。

Conclusion: SFE基准为评估MLLM的科学认知能力提供了全面框架，并揭示了当前模型的不足，有望推动AI在科学发现中的进一步发展。

摘要: 科学发现日益依赖于基于信息密集型科学数据和领域专业知识的复杂多模态推理。通过专家级科学基准的支持，科学多模态大语言模型（MLLM）有望在现实工作流程中显著提升这一发现过程。然而，当前的科学基准主要关注评估MLLM的知识理解能力，导致对其感知和推理能力的评估不足。为解决这一问题，我们提出了科学家首次考试（SFE）基准，旨在通过三个相互关联的层次评估MLLM的科学认知能力：科学信号感知、科学属性理解和科学比较推理。具体而言，SFE包含830个专家验证的视觉问答对，涵盖三种问题类型和五个高价值学科的66个多模态任务。大量实验表明，当前最先进的GPT-o3和InternVL-3在SFE上的得分仅为34.08%和26.52%，凸显了MLLM在科学领域的显著改进空间。我们希望SFE的见解能够促进AI增强科学发现的进一步发展。

</details>


### [454] [LogiPlan: A Structured Benchmark for Logical Planning and Relational Reasoning in LLMs](https://arxiv.org/abs/2506.10527)
**中文标题：LogiPlan：一个用于评估LLMs逻辑规划和关系推理能力的结构化基准**

*Yanan Cai,Ahmed Salem,Besmira Nushi,Mark Russinovich*

Main category: cs.AI

TL;DR: LogiPlan是一个用于评估大型语言模型（LLMs）在逻辑规划和关系推理能力上的新基准，包含三个任务：计划生成、一致性检测和比较问题。实验表明，当前先进模型在简单任务上表现良好，但在复杂逻辑规划上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 逻辑关系推理在依赖LLMs生成和查询结构化关系图的应用中至关重要，如网络基础设施、知识库或业务流程模式。现有基准缺乏对复杂关系结构的动态评估，因此需要LogiPlan来填补这一空白。

Method: LogiPlan通过控制对象数量、关系数量和关系链的最小深度，动态调整任务复杂度。包含三个任务：计划生成（构建满足约束的有向关系图）、一致性检测（识别关系结构中的不一致性）和比较问题（验证查询关系的有效性）。此外，还评估模型的自我纠正能力。

Result: 评估了包括DeepSeek R1、Gemini 2.0 Pro、GPT-4.5等在内的多个先进模型，发现模型性能与规模和架构相关。尽管推理增强模型在简单任务上表现良好，但在需要深度逻辑规划的复杂配置中表现不佳。

Conclusion: LogiPlan为LLMs的逻辑规划和关系推理能力提供了细粒度评估，揭示了当前模型的局限性，尤其是在复杂任务上的表现不足，为未来模型改进提供了方向。

摘要: 我们介绍了LogiPlan，这是一个新颖的基准，旨在评估大型语言模型（LLMs）在复杂关系结构上的逻辑规划和推理能力。逻辑关系推理对于依赖LLMs生成和查询结构化关系图的应用（如网络基础设施、知识库或业务流程模式）非常重要。我们的框架通过控制对象数量、关系数量和关系链的最小深度，动态调整任务复杂度，从而提供对模型在不同难度级别上表现的细粒度评估。LogiPlan包含三个互补任务：（1）计划生成，模型需构建满足特定结构约束的有效有向关系图；（2）一致性检测，测试模型识别关系结构中不一致性的能力；（3）比较问题，评估模型在给定图中确定查询关系有效性的能力。此外，我们还通过提示模型验证和优化初始解决方案来评估其自我纠正能力。我们评估了包括DeepSeek R1、Gemini 2.0 Pro、Gemini 2 Flash Thinking、GPT-4.5、GPT-4o、Llama 3.1 405B、O3-mini、O1和Claude 3.7 Sonnet在内的多个先进模型，揭示了与模型规模和架构相关的显著性能差距。我们的分析表明，尽管近期推理增强模型在简单实例上表现出色，但在需要更深层次逻辑规划的复杂配置中仍存在困难。

</details>


### [455] [Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning](https://arxiv.org/abs/2506.10585)
**中文标题：Primender序列：一种用于测试符号推理和AI推理的新型数学构造**

*Mohd Anwar Jamal Faiz*

Main category: cs.AI

TL;DR: 本文提出了一种名为Primender的新整数序列，结合了素数和模数条件，用于测试大型语言模型（LLM）的符号推理能力。研究通过设计结构化提示和评估框架，验证了一个关键假设，并比较了多个LLM的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于需要可解释、基于规则的测试基准，以评估LLM推断隐藏规则、验证数学假设和推广符号逻辑的能力。Primender序列作为一种新的数学构造，填补了这一需求。

Method: 研究设计了Primender序列，并提出了一个关键假设：当序列中的数字恰好比其前一个素数大1时，其与前一个序列数的差也为1。通过结构化提示和评估框架，测试了多个LLM（如ChatGPT、Copilot等）在规则推断、假设验证和序列生成方面的表现。

Result: 研究结果表明，不同LLM在规则推断准确性、假设验证、序列有效性和符号解释质量方面表现各异。Primender序列和评估方法为LLM的符号推理能力提供了可复现的基准。

Conclusion: 本文通过Primender序列和评估框架，为LLM的符号推理和数学假设测试提供了新的工具和方法，连接了数论、人工智能和软件工程领域。

摘要: 本文介绍了Primender序列，这是一种新型整数序列，其定义规则结合了经典素数和基于模数的数字条件。具体而言，一个数字n被包含在序列中，如果它是素数或其末尾数字（任意长度）为素数。换句话说，序列包含素数或至少有一个素数后缀的数字。生成的序列展现出确定性但非平凡的结构，融合了数论性质和符号模式。我们提出将Primender序列作为评估大型语言模型（LLM）符号推理能力的基准。研究的动机源于需要可解释、基于规则的测试基准，以评估LLM推断隐藏规则、验证数学假设和推广符号逻辑的能力。探索的一个关键假设是：当Primender序列中的一个数字恰好比其前一个素数大1时，其与前一个序列数的差也为1。我们设计了结构化提示和评估框架，在多个先进的LLM（包括ChatGPT、Copilot、DeepSeek、Gemini、Grok和LLaMA）上测试这一假设。模型的任务包括识别底层规则、验证假设并生成序列的下100,000项。通过规则推断准确性、假设验证、序列有效性和符号解释质量等比较指标评估模型表现。这项工作贡献了一种新的数学构造和可复现的方法论，用于在符号推理、假设测试和可扩展模式推广方面对LLM进行基准测试，连接了数论、人工智能和软件工程领域。

</details>


### [456] [Data Driven Diagnosis for Large Cyber-Physical-Systems with Minimal Prior Information](https://arxiv.org/abs/2506.10613)
**中文标题：基于数据驱动的网络物理系统诊断：最小先验信息需求**

*Henrik Sebastian Steude,Alexander Diedrich,Ingo Pill,Lukas Moddemann,Daniel Vranješ,Oliver Niggemann*

Main category: cs.AI

TL;DR: 提出一种新型诊断方法，仅需少量先验知识和正常运行数据，通过神经网络症状生成器和图诊断算法，在复杂网络物理系统中实现高效诊断。


<details>
  <summary>Details</summary>
Motivation: 复杂网络物理系统的诊断通常需要大量先验知识（如详细系统模型或训练数据），但获取这些信息具有挑战性。本文旨在解决这一问题，提出一种仅需少量先验知识的诊断方法。

Method: 结合基于神经网络的症状生成器（用于子系统级异常检测）和新的图诊断算法（利用子系统间的最小因果关系信息）。

Result: 在可控模拟数据集上，82%的案例中正确识别了真实因果组件，并在73%的场景中有效缩小了搜索空间。在真实数据集（Secure Water Treatment）上也展示了实用潜力。

Conclusion: 该方法在缺乏先验知识的大型复杂网络物理系统中具有实际应用潜力。

摘要: 复杂网络物理系统的诊断过程通常需要大量先验知识，如详细的系统模型或全面的训练数据。然而，获取这些信息是一项重大挑战。为解决这一问题，我们提出了一种新的诊断方法，仅需少量先验知识，包括对子系统关系的基本理解和正常运行数据。我们的方法结合了基于神经网络的症状生成器（用于子系统级异常检测）和一种新的图诊断算法（利用子系统间的最小因果关系信息，这些信息在实践中通常可得）。在完全可控的模拟数据集上的实验表明，我们的方法在82%的案例中正确识别了真实因果组件，并在73%的场景中有效缩小了搜索空间。在真实世界的Secure Water Treatment数据集上的进一步测试展示了该方法在实际场景中的潜力。因此，我们的结果凸显了该方法在缺乏先验知识的大型复杂网络物理系统中的实际应用潜力。

</details>


### [457] [TeleMath: A Benchmark for Large Language Models in Telecom Mathematical Problem Solving](https://arxiv.org/abs/2506.10674)
**中文标题：TeleMath：大型语言模型在电信数学问题解决中的基准测试**

*Vincenzo Colle,Mohamed Sana,Nicola Piovesan,Antonio De Domenico,Fadhel Ayed,Merouane Debbah*

Main category: cs.AI

TL;DR: 本文介绍了TeleMath，首个专门用于评估大型语言模型（LLM）在电信领域数学问题解决能力的基准数据集。通过500个问答对，研究发现专为数学或逻辑推理设计的模型表现最佳，而通用模型则表现不佳。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在电信领域的广泛应用，大型语言模型（LLM）在解决领域特定、数学密集型任务中的能力尚未得到充分研究。本文旨在填补这一空白，评估LLM在电信数学问题中的表现。

Method: 研究团队开发了TeleMath数据集，包含500个电信领域的数学问题问答对。问题由领域专家设计，并通过生成管道整理。随后，对多种开源LLM进行了评估。

Result: 评估结果显示，专为数学或逻辑推理设计的模型在TeleMath上表现最佳，而通用模型即使参数规模较大，也表现不佳。

Conclusion: TeleMath为评估LLM在电信数学问题中的能力提供了首个基准，并揭示了专为数学推理设计的模型的优势。数据集和评估代码已公开以支持未来研究。

摘要: 人工智能在电信领域的日益普及引发了对大型语言模型（LLM）解决领域特定、数学密集型任务能力的兴趣。尽管近期进展提升了LLM在通用数学推理中的表现，但其在信号处理、网络优化和性能分析等专业领域的有效性仍未被充分探索。为填补这一空白，我们提出了TeleMath，首个专门用于评估LLM在电信领域数学问题解决能力的基准数据集。TeleMath包含500个问答对，覆盖电信领域的广泛主题。本文概述了从领域专家设计的初始问题到生成问答对的流程。对多种开源LLM的评估显示，TeleMath上表现最佳的模型是专为数学或逻辑推理设计的近期模型。相比之下，通用模型即使参数规模较大，也往往难以应对这些挑战。我们已公开数据集和评估代码，以支持结果复现和未来研究。

</details>


### [458] [Automated Validation of Textual Constraints Against AutomationML via LLMs and SHACL](https://arxiv.org/abs/2506.10678)
**中文标题：基于LLM和SHACL的AutomationML文本约束自动验证**

*Tom Westermann,Aljosha Köcher,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 本文提出了一种利用大型语言模型（LLM）和SHACL自动验证AutomationML（AML）中文本约束的流程，无需用户掌握形式化方法或本体技术。


<details>
  <summary>Details</summary>
Motivation: AutomationML（AML）在工程中实现了标准化数据交换，但其建模建议通常以非正式的文本约束形式存在，无法在AML中自动验证。本文旨在解决这一问题。

Method: 首先通过RML和SPARQL将AML模型映射到OWL本体；然后利用大型语言模型将文本规则翻译为SHACL约束；最后对生成的AML本体进行SHACL验证，并将结果自动解释为自然语言。

Result: 结果表明，即使是复杂的建模规则也可以通过半自动方式验证，无需用户理解形式化方法或本体技术。

Conclusion: 本文提出的流程能够有效地将AML中的文本约束形式化并验证，为工程实践提供了实用工具。

摘要: AutomationML（AML）实现了工程中的标准化数据交换，但现有的AML建模建议通常以非正式的文本约束形式存在，无法在AML中自动验证。本文提出了一种流程，用于形式化并验证此类约束。首先，通过RML和SPARQL将AML模型映射到OWL本体；其次，利用大型语言模型将文本规则翻译为SHACL约束；最后，对生成的AML本体进行SHACL验证，并将验证结果自动解释为自然语言。该方法通过一个AML建议示例进行了演示。结果表明，即使是复杂的建模规则也可以通过半自动方式验证，而无需用户掌握形式化方法或本体技术。

</details>


### [459] [System ASPMT2SMT:Computing ASPMT Theories by SMT Solvers](https://arxiv.org/abs/2506.10708)
**中文标题：系统ASPMT2SMT：通过SMT求解器计算ASPMT理论**

*Michael Bartholomew,Joohyung Lee*

Main category: cs.AI

TL;DR: 本文介绍了ASPMT2SMT系统，通过将ASPMT程序转换为SMT实例，利用SMT求解器计算ASPMT程序的稳定模型。该系统结合了ASP基础工具gringo和SMT求解器z3，有效处理实数计算问题。


<details>
  <summary>Details</summary>
Motivation: ASPMT（基于功能稳定模型语义的答案集编程与可满足性模理论结合方法）的紧片段可以转换为SMT实例，但缺乏实际工具支持。本文旨在开发一个编译器aspsmt2smt，填补这一空白。

Method: 开发了aspsmt2smt编译器，利用ASP基础工具gringo部分接地输入程序，剩余变量由SMT求解器z3处理，实现ASPMT程序到SMT实例的转换。

Result: 系统成功将ASPMT程序转换为SMT实例，并利用z3求解器计算稳定模型，尤其擅长处理实数计算和连续变化推理问题。

Conclusion: ASPMT2SMT系统为ASPMT程序提供了有效的计算工具，扩展了其在连续变化推理中的应用潜力。

摘要: 答案集编程模理论（ASPMT）是一种基于功能稳定模型语义的答案集编程与可满足性模理论结合方法。研究表明，ASPMT程序的紧片段可以转换为SMT实例，从而允许SMT求解器计算ASPMT程序的稳定模型。本文介绍了一个名为aspsmt2smt的编译器，实现了这一转换。该系统使用ASP基础工具gringo和SMT求解器z3，gringo部分接地输入程序，剩余变量由z3处理。我们证明了该系统能够有效处理实数计算，用于连续变化的推理。

</details>


### [460] [Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering](https://arxiv.org/abs/2506.10753)
**中文标题：在模拟前思考：符号推理协调神经计算以回答反事实问题**

*Adam Ishay,Zhun Yang,Joohyung Lee,Ilgu Kang,Dongjae Lim*

Main category: cs.AI

TL;DR: 本文提出了一种结合符号推理与神经计算的增强方法，用于提升神经符号模型在反事实问题回答中的表现，通过因果图表示事件关系，并利用ASP协调感知与模拟模块，在CLEVRER和CRAFT基准测试中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号模型在反事实问题回答中存在局限性，尤其是在视频动态的因果和时间推理方面。本文旨在通过符号推理增强神经符号模型，以更有效地解决这些问题。

Method: 定义因果图表示事件关系，使用答案集编程（ASP）协调感知和模拟模块，并在CLEVRER和CRAFT基准测试中验证方法。对于CRAFT，还利用预训练语言模型（如GPT-3.5和GPT-4）作为动态模拟器的替代。

Result: 在CLEVRER挑战中达到最先进性能，显著优于现有模型；在CRAFT基准测试中，通过符号因果推理指导的替代提示进一步提升了反事实问题的回答效果。

Conclusion: 结合符号推理与神经计算的方法显著提升了反事实问题回答的性能，为神经符号模型的发展提供了新方向。

摘要: 视频动态的因果和时间推理是一个具有挑战性的问题。尽管结合符号推理与神经感知和预测的神经符号模型显示出潜力，但其在回答反事实问题时仍存在局限性。本文提出了一种增强神经符号模型的方法，通过符号推理分析事件间的因果关系。我们定义了因果图来表示这些关系，并使用答案集编程（ASP）这一声明性逻辑编程方法来协调感知与模拟模块。我们在CLEVRER和CRAFT两个基准测试上验证了方法的有效性。我们的增强方法在CLEVRER挑战中达到了最先进的性能，显著优于现有模型。在CRAFT基准测试中，我们利用大型预训练语言模型（如GPT-3.5和GPT-4）作为动态模拟器的替代。研究结果表明，通过符号因果推理指导的替代提示，可以进一步提升反事实问题的回答效果。

</details>


### [461] [OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](https://arxiv.org/abs/2506.10764)
**中文标题：OPT-BENCH：评估LLM代理在大规模搜索空间优化问题中的表现**

*Xiaozhe Li,Jixuan Chen,Xinyu Fang,Shengyuan Ding,Haodong Duan,Qingwen Liu,Kai Chen*

Main category: cs.AI

TL;DR: 本文介绍了OPT-BENCH，一个用于评估大型语言模型（LLM）代理在大规模搜索空间优化问题中表现的基准测试。通过20个Kaggle真实机器学习任务和10个经典NP问题，结合OPT-Agent框架，研究发现历史反馈能显著提升优化性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在多样化任务中表现出色，但其通过迭代学习和反馈优化复杂解决方案的能力尚未充分研究。本文旨在填补这一空白。

Method: 提出OPT-BENCH基准测试，包含20个Kaggle机器学习任务和10个NP问题，并开发OPT-Agent框架，模拟人类推理过程，通过生成、验证和迭代改进解决方案。

Result: 实验表明，结合历史反馈能显著提升LLM在机器学习和NP任务中的优化性能，同时优化迭代次数、温度设置和模型架构对结果有重要影响。

Conclusion: OPT-BENCH为LLM驱动的优化和迭代推理研究提供了重要工具，开源数据和代码将进一步推动该领域发展。

摘要: 大型语言模型（LLM）在解决多样化任务中表现出卓越能力，但其通过迭代学习和反馈优化复杂解决方案的能力尚未充分探索。为此，我们提出了OPT-BENCH，一个全面的基准测试，用于评估LLM代理在大规模搜索空间优化问题中的表现。OPT-BENCH包含20个来自Kaggle的真实机器学习任务和10个经典NP问题，为评估LLM代理的迭代推理和解决方案优化能力提供了多样化和挑战性的环境。为了支持严谨的评估，我们引入了OPT-Agent，一个端到端的优化框架，通过利用历史反馈生成、验证和迭代改进解决方案，模拟人类解决复杂问题的推理过程。通过对6个模型家族的9种先进LLM进行广泛实验，我们分析了优化迭代次数、温度设置和模型架构对解决方案质量和收敛性的影响。结果表明，结合历史上下文能显著提升机器学习和NP任务的优化性能。所有数据集、代码和评估工具均已开源，以推动LLM驱动的优化和迭代推理研究的进一步发展。项目页面：https://github.com/OliverLeeXZ/OPT-BENCH。

</details>


### [462] [A Study on Individual Spatiotemporal Activity Generation Method Using MCP-Enhanced Chain-of-Thought Large Language Models](https://arxiv.org/abs/2506.10853)
**中文标题：基于MCP增强思维链大语言模型的个体时空活动生成方法研究**

*Yu Zhang,Yang Hu,De Wang*

Main category: cs.AI

TL;DR: 本文提出了一种结合思维链推理（CoT）和模型上下文协议（MCP）的框架，用于增强大语言模型（LLMs）在模拟人类时空行为方面的能力，实验验证了其在生成数据质量和效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则和统计的人类时空行为模拟方法存在计算成本高、泛化能力差和可扩展性不足的问题，而现有的大语言模型在时空推理方面也存在空间认知有限、物理约束理解不足和群体同质化倾向等挑战。

Method: 通过结合思维链推理的五阶段认知框架和六类MCP工具（时间管理、空间导航、环境感知、个人记忆、社会协作和经验评估），提出了一种增强LLMs时空行为模拟能力的方法。

Result: 在上海陆家嘴地区的实验中，生成的1000个样本与真实移动信号数据高度相似，生成质量评分达到7.86至8.36。并行处理实验显示，生成时间从1.30分钟降至0.17分钟（样本）。

Conclusion: 该框架为城市行为建模提供了一种实用方法，推动了LLMs在城市计算中的应用，并为智能城市规划、交通预测和参与式城市设计提供了基础。

摘要: 人类时空行为模拟对城市规划研究至关重要，但传统的基于规则和统计的方法存在计算成本高、泛化能力差和可扩展性不足的问题。尽管大语言模型（LLMs）作为“世界模拟器”展现出潜力，但在时空推理方面仍面临空间认知有限、物理约束理解不足和群体同质化倾向等挑战。本文提出了一种结合思维链（CoT）推理与模型上下文协议（MCP）的框架，以增强LLMs模拟符合验证数据模式的时空行为的能力。该方法通过五阶段认知框架实现类人渐进式推理，并通过六类专用MCP工具（时间管理、空间导航、环境感知、个人记忆、社会协作和经验评估）进行全面的数据处理。在上海陆家嘴地区的实验中，验证了该框架在1000个生成样本中的有效性。结果表明，生成的样本与真实移动信号数据高度相似，不同基础模型的生成质量评分达到7.86至8.36。并行处理实验显示效率提升，生成时间从1.30分钟降至0.17分钟（样本）。本研究通过将CoT推理与MCP结合，为城市行为建模提供了新思路，推动了LLMs在城市计算中的应用，并为合成移动数据生成提供了实用方法。该框架为智能城市规划、交通预测和参与式城市设计应用奠定了基础。

</details>


### [463] [GenPlanX. Generation of Plans and Execution](https://arxiv.org/abs/2506.10897)
**中文标题：GenPlanX：计划生成与执行**

*Daniel Borrajo,Giuseppe Canonaco,Tomás de la Rosa,Alfredo Garrachón,Sriram Gopalakrishnan,Simerjot Kaur,Marianela Morales,Sunandita Patra,Alberto Pozanco,Keshav Ramani,Charese Smiley,Pietro Totis,Manuela Veloso*

Main category: cs.AI

TL;DR: GenPlanX结合大型语言模型（LLM）和经典AI规划引擎，通过自然语言描述规划任务，并监控执行，提升办公任务效率。


<details>
  <summary>Details</summary>
Motivation: 传统AI规划技术无法理解自然语言描述的规划任务，而LLM在理解人类意图方面表现出色。本文旨在结合两者优势，提升任务规划与执行的效率。

Method: 提出GenPlanX框架，整合LLM用于自然语言任务描述，结合经典AI规划引擎及执行监控系统，应用于办公任务场景。

Result: GenPlanX在办公任务中表现出高效性，能够优化工作流程并提升人机协作效率。

Conclusion: GenPlanX通过结合LLM与经典规划技术，为自然语言任务规划与执行提供了有效解决方案，具有广泛应用潜力。

摘要: 传统AI规划技术为复杂任务生成动作序列，但无法理解自然语言描述的规划任务。大型语言模型（LLM）的出现为人机交互带来了新能力，尤其在规划任务中表现出对人类意图的出色理解。本文提出GenPlanX，将LLM用于自然语言任务描述，结合经典AI规划引擎及执行监控框架。我们展示了GenPlanX在办公任务中的高效性，凸显其通过无缝人机协作优化工作流程和提升生产力的潜力。

</details>


### [464] [Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?](https://arxiv.org/abs/2506.10912)
**中文标题：破解有害分子：多模态大语言模型是否准备好进行结构级分子解毒？**

*Fei Lin,Ziyang Gong,Cong Wang,Yonglin Tian,Tengchao Zhang,Xue Yang,Gen Luo,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 本文介绍了首个针对多模态大语言模型（MLLMs）的分子毒性修复基准任务ToxiMol，并提出了自动化评估框架ToxiEval。实验表明，尽管当前MLLMs在此任务上仍面临挑战，但已展现出毒性理解、语义约束遵循和结构感知分子编辑的潜力。


<details>
  <summary>Details</summary>
Motivation: 毒性是药物早期开发失败的主要原因之一，但分子毒性修复任务尚未被系统定义或评估。本文旨在填补这一空白，为MLLMs提供首个分子毒性修复的基准任务。

Method: 1. 构建标准化数据集ToxiMol，涵盖11个主要任务和560个代表性有毒分子；2. 设计基于专家毒理学知识的提示标注流程；3. 提出自动化评估框架ToxiEval，整合毒性终点预测、合成可行性、药物相似性和结构相似性。

Result: 实验评估了近30种主流MLLMs，发现尽管当前模型在此任务上仍有显著挑战，但已展现出毒性理解、语义约束遵循和结构感知分子编辑的能力。

Conclusion: ToxiMol为MLLMs在分子毒性修复任务上的能力提供了系统评估，为未来研究奠定了基础。

摘要: 毒性仍是药物早期开发失败的主要原因之一。尽管分子设计和性质预测取得了进展，但分子毒性修复任务——生成结构有效且毒性降低的分子替代物——尚未被系统定义或评估。为填补这一空白，我们提出了ToxiMol，这是首个专注于分子毒性修复的通用多模态大语言模型（MLLMs）基准任务。我们构建了一个标准化数据集，涵盖11个主要任务和560个代表性有毒分子，覆盖多种机制和粒度。基于专家毒理学知识，我们设计了具有机制感知和任务自适应能力的提示标注流程。同时，我们提出了自动化评估框架ToxiEval，将毒性终点预测、合成可行性、药物相似性和结构相似性整合为高通量评估链。我们系统评估了近30种主流通用MLLMs，并设计了多项消融研究以分析关键因素，如评估标准、候选多样性和失败归因。实验结果表明，尽管当前MLLMs在此任务上仍面临显著挑战，但它们已开始在毒性理解、语义约束遵循和结构感知分子编辑方面展现出潜力。

</details>


### [465] [Spurious Rewards: Rethinking Training Signals in RLVR](https://arxiv.org/abs/2506.10947)
**中文标题：虚假奖励：重新思考RLVR中的训练信号**

*Rulin Shao,Shuyue Stella Li,Rui Xin,Scott Geng,Yiping Wang,Sewoong Oh,Simon Shaolei Du,Nathan Lambert,Sewon Min,Ranjay Krishna,Yulia Tsvetkov,Hannaneh Hajishirzi,Pang Wei Koh,Luke Zettlemoyer*

Main category: cs.AI

TL;DR: 研究发现，在强化学习中使用虚假奖励（RLVR）可以显著提升某些模型（如Qwen2.5-Math-7B）的数学推理能力，即使奖励信号与正确答案无关。然而，这种效果在其他模型家族（如Llama3或OLMo2）中并不适用。RLVR可能通过激活预训练中学到的有用推理表示来发挥作用，但其具体机制仍需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 探讨在强化学习中使用虚假奖励信号是否仍能提升模型的数学推理能力，并研究这种效果在不同模型家族中的普适性。

Method: 通过实验对比不同虚假奖励信号（如随机奖励、格式奖励、错误标签等）对模型性能的影响，并分析模型在RLVR训练后的行为变化。

Result: RLVR显著提升了Qwen2.5-Math-7B的数学推理能力（最高提升27.1%），但对其他模型家族效果有限。此外，RLVR训练后，Qwen模型表现出更频繁的“代码推理”行为。

Conclusion: RLVR可能通过激活预训练中学到的推理表示来提升性能，但其机制尚不明确。未来研究需验证RLVR在多样化模型上的普适性，而非仅依赖单一模型。

摘要: 研究表明，在强化学习中使用可验证奖励（RLVR）时，即使奖励信号与正确答案几乎没有、完全没有甚至负相关，某些模型（如Qwen2.5-Math-7B）的数学推理能力仍能显著提升。例如，RLVR将Qwen2.5-Math-7B在MATH-500上的性能绝对提升了21.4%（随机奖励）、13.8%（格式奖励）、24.1%（错误标签）、26.0%（1-shot RL）和27.1%（多数投票），几乎接近使用真实奖励时的29.1%提升。然而，这些对Qwen有效的虚假奖励在其他模型家族（如Llama3或OLMo2）中往往无效。特别地，我们发现“代码推理”（即不实际执行代码的代码思维）是Qwen2.5-Math的一种独特行为，在RLVR训练后显著增加（从65%升至90%以上），即使使用虚假奖励也是如此。总体而言，我们推测，由于缺乏有用的奖励信号，RLVR可能通过某种方式激活了预训练中学到的有用推理表示，但其具体机制仍需未来研究。我们建议，未来RLVR研究应在多样化模型上进行验证，而非仅依赖单一默认选择，因为我们的研究表明，即使使用完全虚假的奖励信号，也能在Qwen模型上取得显著性能提升。

</details>


### [466] [A Conjecture on a Fundamental Trade-Off between Certainty and Scope in Symbolic and Generative AI](https://arxiv.org/abs/2506.10130)
**中文标题：关于符号AI与生成AI中确定性与范围之间根本性权衡的猜想**

*Luciano Floridi*

Main category: cs.AI

TL;DR: 本文提出一个猜想，认为在人工智能系统中，可证明的正确性与广泛的数据映射能力之间存在根本性权衡。符号AI追求确定性但领域狭窄，而生成模型能处理复杂数据但无法避免错误。这一猜想对AI的设计和评估标准有深远影响。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能系统中可证明的正确性与广泛数据处理能力之间的权衡，揭示符号AI与生成模型的局限性，为AI的设计和评估提供新视角。

Method: 通过信息论形式化这一猜想，结合认识论、形式验证和技术哲学的背景进行分析，探讨其影响和后果。

Result: 明确提出了符号AI与生成模型之间的根本性权衡，并分析了其对AI评估标准、治理框架和混合系统设计的潜在影响。

Conclusion: 这一猜想若成立，将重塑可信AI的未来发展方向，强调证明或反驳其正确性的重要性。

摘要: 本文提出一个猜想，形式化了人工智能（AI）系统中可证明的正确性与广泛数据映射能力之间的根本性权衡。当AI系统为演绎性严密保证（如经典符号AI）而设计时，其操作领域必须严格限定和预结构化；反之，能够处理高维数据并生成丰富信息输出的系统（如当代生成模型）必然无法实现零错误性能，存在不可避免的错误或误分类风险。通过将这一隐含的权衡明确化并接受严格验证，该猜想显著重构了AI的工程目标和哲学期望。文章回顾了这一矛盾的历史动机，以信息论形式表述了猜想，并将其置于认识论、形式验证和技术哲学的广泛讨论中。随后，基于不确定性、谨慎认识论风险和道德责任等概念，分析了其影响和后果。讨论表明，若猜想成立，它将有助于重塑评估标准、治理框架和混合系统设计。结论强调了最终证明或反驳这一不等式对可信AI未来发展的重要性。

</details>


### [467] [One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence](https://arxiv.org/abs/2506.10157)
**中文标题：一位患者，多重场景：通过上下文智能扩展医学AI**

*Michelle M. Li,Ben Y. Reis,Adam Rodman,Tianxi Cai,Noa Dagan,Ran D. Balicer,Joseph Loscalzo,Isaac S. Kohane,Marinka Zitnik*

Main category: cs.AI

TL;DR: 医学基础模型在处理多样化医疗场景时存在局限性，提出动态上下文切换的AI模型以提升适应性。


<details>
  <summary>Details</summary>
Motivation: 当前医学AI模型在适应新人群、专科或环境时需微调或知识库检索，导致无法动态调整行为，易产生上下文错误。

Method: 提出上下文切换的医学AI模型，无需重新训练即可动态适应不同专科、人群、工作流程和临床角色。

Result: 动态上下文切换的AI模型有望提升跨专科和地区的疾病诊断与管理能力，扩大医疗服务覆盖范围。

Conclusion: 上下文切换的医学AI模型是解决当前模型局限性的关键，未来可广泛应用于多样化医疗场景。

摘要: 医学基础模型（包括基于临床笔记训练的语言模型、基于医学图像的视觉语言模型以及基于电子健康记录的多模态模型）能够总结临床笔记、回答医学问题并辅助决策。然而，将这些模型适应新人群、专科或环境通常需要微调、精心设计的提示或从知识库中检索。这种方法可能不切实际，并限制了模型解释陌生输入和适应训练中未涵盖的临床情况的能力。因此，模型容易产生上下文错误，即预测看似合理但未能考虑关键的特定患者或上下文信息。这些错误源于当前模型的一个根本局限性：无法在医疗护理的不断变化环境中动态调整行为。本文提出了一种医学AI上下文切换的愿景：模型无需重新训练即可动态适应新专科、人群、工作流程和临床角色。我们设想上下文切换的AI能够跨专科和地区诊断、管理和治疗多种疾病，并扩大医疗服务的可及性。

</details>


### [468] [Correlation vs causation in Alzheimer's disease: an interpretability-driven study](https://arxiv.org/abs/2506.10179)
**中文标题：阿尔茨海默病中的相关性 vs 因果关系：一项基于可解释性的研究**

*Hamzah Dabool,Raghad Mustafa*

Main category: cs.AI

TL;DR: 本研究通过结合相关性分析、机器学习分类和模型可解释性技术，探讨了阿尔茨海默病（AD）中临床、认知、遗传和生物标志物特征之间的关系，强调强相关性并不等同于因果关系，为未来因果推断研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 在阿尔茨海默病研究中，区分因果关系和相关关系对诊断、治疗和识别真正的疾病驱动因素至关重要。本研究旨在通过分析特征间的关系，揭示潜在的因果机制。

Method: 研究采用XGBoost算法进行AD分类，结合相关性分析和SHAP（SHapley Additive exPlanations）值，分析临床、认知、遗传和生物标志物特征的影响。

Result: 研究发现认知评分和遗传风险因素是AD分类的关键特征，相关性矩阵揭示了变量间的聚类关系，SHAP值提供了疾病不同阶段特征的详细贡献。强相关性并不一定意味着因果关系。

Conclusion: 通过整合特征重要性和可解释性与传统统计分析，本研究为未来揭示真实病理机制的因果推断研究奠定了基础，区分因果因素和相关标志物有助于改善AD的早期诊断和靶向干预。

摘要: 在阿尔茨海默病（AD）研究中，区分因果关系和相关关系对诊断、治疗以及识别真正的疾病驱动因素至关重要。本研究通过结合相关性分析、机器学习分类和模型可解释性技术，探讨了临床、认知、遗传和生物标志物特征之间的关系。采用XGBoost算法，我们识别出影响AD分类的关键特征，包括认知评分和遗传风险因素。相关性矩阵揭示了变量间的聚类关系，而SHAP（SHapley Additive exPlanations）值则提供了疾病不同阶段特征的详细贡献。结果表明，强相关性并不一定意味着因果关系，强调了关联数据需要谨慎解释。通过将特征重要性和可解释性与传统统计分析相结合，本研究为未来揭示真实病理机制的因果推断研究奠定了基础。最终，区分因果因素和相关标志物有助于改善阿尔茨海默病的早期诊断和靶向干预。

</details>


### [469] [Towards Responsible AI: Advances in Safety, Fairness, and Accountability of Autonomous Systems](https://arxiv.org/abs/2506.10192)
**中文标题：迈向负责任的人工智能：自主系统在安全性、公平性和可问责性方面的进展**

*Filip Cano*

Main category: cs.AI

TL;DR: 该论文提出了多种技术和方法，以提升人工智能系统的安全性、公平性和可问责性，包括扩展安全防护技术、引入公平性防护措施以及量化代理行为意图的框架。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统在社会关键领域的影响日益增加，确保人工智能的负责任使用变得至关重要。然而，可信赖AI的概念仍广泛且多面，需要深入研究。

Method: 论文扩展了确定性防护技术以应对延迟观测，提出了公平性防护措施以在序列决策中强制群体公平，并开发了量化代理意图的框架。

Result: 通过模拟验证，安全防护技术有效防止了自动驾驶车辆碰撞；公平性防护措施在最小干预下实现了公平；意图量化框架为责任归属提供了分析工具。

Conclusion: 论文通过统一框架整合了各项贡献，为构建更安全、公平和可问责的AI系统奠定了基础，并推动了可信赖AI的未来研究。

摘要: 随着自主系统在关键社会领域的影响力日益增强，确保人工智能（AI）的负责任使用变得至关重要。然而，可信赖AI的概念仍然广泛且多面。本论文在AI系统的安全性、公平性、透明性和可问责性方面取得了进展。在安全性方面，我们扩展了经典的确定性防护技术，使其能够应对延迟观测，从而在实际环境中实现部署。我们还将确定性和概率性安全防护技术应用于模拟自动驾驶车辆，以防止与道路使用者发生碰撞，并在真实的驾驶模拟器中验证了这些技术的有效性。我们引入了公平性防护措施，这是一种新颖的后处理方法，用于在有限和周期性时间范围内的序列决策中强制实现群体公平。通过优化干预成本并严格确保公平约束，该方法在最小干扰下高效平衡了公平性。在透明性和可问责性方面，我们提出了一个形式化框架，用于评估概率决策代理的有意行为，引入了代理性和意图商的量化指标。我们利用这些指标提出了意图的回顾性分析，有助于在自主系统造成意外伤害时确定责任。最后，我们通过“反应式决策”框架统一了这些贡献，提供了一个整合先前方法的通用形式化。总体而言，本文提出的进展为构建更安全、公平和可问责的AI系统提供了实际贡献，并为可信赖AI的未来研究奠定了基础。

</details>


### [470] [WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2506.10264)
**中文标题：WGSR-Bench：基于兵棋游戏的博弈论战略推理基准测试用于大语言模型**

*Qiyue Yin,Pei Xu,Qiaozhe Li,Shengda Liu,Shengqi Shen,Tong Wang,Yihong Han,Xiaonan Zhao,Likun Yang,Shiyue Cao,Shiyu Qiu,Yuxuan Liu,Shizhao Yu,Lei Cui,Chengxin Yan,Jie Sun,Xiangquan Tang,Kaiqi Huang*

Main category: cs.AI

TL;DR: 本文提出了WGSR-Bench，首个基于兵棋游戏的战略推理基准测试，用于评估大语言模型在多智能体动态环境中的战略推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学、符号和常识推理方面表现优异，但战略推理（评估多智能体行为、制定行动计划和适应策略的能力）尚未被系统评估。本文旨在填补这一空白。

Method: WGSR-Bench以兵棋游戏为评估环境，设计了围绕环境态势感知、对手风险建模和政策生成三个核心任务的测试样本，并通过LLM驱动的兵棋代理进行综合评估。

Result: WGSR-Bench能够系统评估大语言模型在多智能体决策、意图推断和反事实推理中的战略推理能力。

Conclusion: WGSR-Bench为评估大语言模型的战略推理能力提供了首个基准测试，并推动了基于大模型的战略智能研究。

摘要: 近年来，大语言模型（LLMs）的突破性进展显著提升了人工智能在推理任务上的表现，尤其是在数学、符号和常识推理方面展示了卓越能力。然而，作为高级人类认知的关键组成部分，战略推理（即评估多智能体在动态环境中的行为、制定行动计划和适应策略的能力）尚未被系统评估或建模。为填补这一空白，本文提出了WGSR-Bench，首个基于兵棋游戏的战略推理基准测试。兵棋游戏作为一种典型的高复杂度战略场景，融合了环境不确定性、对抗动态和非唯一战略选择，是评估LLMs在多智能体决策、意图推断和反事实推理能力的有效测试平台。WGSR-Bench围绕三个核心任务（环境态势感知、对手风险建模和政策生成）设计测试样本，作为核心S-POE架构，系统评估战略推理的主要能力。最后，设计了一个基于LLM的兵棋代理，整合这些部分以进行全面战略推理评估。通过WGSR-Bench，我们希望评估当前最先进LLMs在博弈论战略推理中的优势和局限，并推动大模型驱动的战略智能研究。

</details>


### [471] [Closer to Language than Steam: AI as the Cognitive Engine of a New Productivity Revolution](https://arxiv.org/abs/2506.10281)
**中文标题：比蒸汽更接近语言：AI作为新生产力革命的认知引擎**

*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

Main category: cs.AI

TL;DR: 本文提出AI是一种认知引擎，类似于书面语言的革命性作用，推动了一场新的生产力革命，强调AI对人类认知能力的补充而非替代。


<details>
  <summary>Details</summary>
Motivation: 探讨AI作为一种认知革命，如何不同于工业革命的机械化工具，而是类似于书面语言对人类智力的革命性增强，从而推动新的生产力范式。

Method: 采用多学科视角，结合计算机科学、经济学和社会学的观点，通过概念框架和历史比较，分析AI对知识工作的影响。

Result: AI作为一种认知引擎，显著提升了认知任务的生产力，并重塑了工作和社会结构，需要重新思考技能、组织和政策。

Conclusion: AI的潜力在于补充人类认知能力，标志着生产力演化的新篇章，需要学术和实践领域的进一步探索。

摘要: 人工智能（AI）被重新定义为一种认知引擎，推动了一场不同于工业革命物理推动的新型生产力革命。本文提出了一个理论框架，将AI视为类似于书面语言的认知革命——对人类智力的革命性增强，而非另一种机械化工具。我们通过比较AI的出现与信息技术的历史飞跃，展示了其如何放大知识工作。来自不同领域的例子证明了AI作为认知任务生产力驱动者的影响。我们采用多学科视角，结合计算机科学的进步、经济学的见解和社会学的观点，探讨AI如何重塑工作和社会。通过概念框架，我们描绘了从手动生产力到认知生产力的转变。我们的核心论点是，AI作为一种认知引擎，类似于人类语言对知识的革命性影响，预示了一种新的生产力范式。我们讨论了这场革命如何要求对技能、组织和政策进行重新思考。本文在学术严谨性与清晰性之间取得平衡，得出结论：AI的潜力在于补充人类认知能力，标志着生产力演化的新篇章。

</details>


### [472] [The Alignment Trap: Complexity Barriers](https://arxiv.org/abs/2506.10304)
**中文标题：对齐陷阱：复杂性障碍**

*Jasper Yao*

Main category: cs.AI

TL;DR: 本文揭示了AI安全性验证在系统能力提升时面临的计算复杂性障碍，证明验证复杂度随系统表达能力指数增长，并提出AI发展面临的三难选择。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统能力的提升，验证其安全性变得越来越复杂。本文旨在从计算复杂性理论的角度，系统地分析AI对齐问题，揭示验证安全性的根本障碍。

Method: 通过形式化“能力-风险扩展动态”（CRS），并基于四个核心定理，分析了AI系统表达能力与安全性验证复杂度之间的关系。

Result: 结果表明：(1) 验证复杂度随系统表达能力指数增长；(2) 安全策略仅占策略空间的极小部分；(3) 现有对齐技术无法提供全面覆盖；(4) 鲁棒安全属性在神经网络中测度为零。

Conclusion: AI发展面临三难选择：限制系统复杂性以保持可验证安全性、接受不可验证风险以扩展能力，或开发超越验证的新安全范式。

摘要: 我们建立了验证AI安全性在系统能力提升时的基本计算复杂性障碍。主要结果表明，对于表达能力超过临界阈值τ的AI系统，安全性验证需要指数时间且是coNP完全的。我们形式化了“能力-风险扩展动态”（CRS），展示了AI能力的提升如何推动社会安全需求趋向完美，从而与验证复杂性形成不可避免的张力。通过四个核心定理，我们证明：(1) 验证复杂度随系统表达能力指数增长；(2) 安全策略仅占策略空间的2^{-2^m}部分；(3) 有限的对齐技术无法提供全面覆盖；(4) 鲁棒安全属性在神经网络中测度为零。这些结果刻画了一个“难解性缺口”，即实际安全需求落在计算难解区域内。最后，我们提出了一个战略三难选择：AI发展必须限制系统复杂性以保持可验证安全性、接受不可验证风险以扩展能力，或开发超越验证的新安全范式。我们的工作首次对AI对齐进行了系统的复杂性理论分析，并确立了任何安全方法都必须面对的严格界限。核心定理在Lean4中的形式化验证正在进行中。

</details>


### [473] [A Benchmark for Generalizing Across Diverse Team Strategies in Competitive Pokémon](https://arxiv.org/abs/2506.10326)
**中文标题：《宝可梦》多样化团队策略泛化能力的基准测试**

*Cameron Angliss,Jiaxun Cui,Jiaheng Hu,Arrasy Rahman,Peter Stone*

Main category: cs.AI

TL;DR: 论文提出了VGC-Bench基准，用于评估AI代理在《宝可梦》视频游戏锦标赛中适应多样化团队策略的能力，发现现有方法在单团队配置下表现良好，但在团队规模扩大时泛化能力不足。


<details>
  <summary>Details</summary>
Motivation: 开发能够在不重新训练的情况下适应多样化战略环境的AI代理是多智能体学习的核心挑战。《宝可梦》视频游戏锦标赛（VGC）因其极高的团队配置空间（约10^139种）和离散组合特性，成为研究这一问题的理想领域。

Method: 论文引入了VGC-Bench基准，提供了基础设施、标准化评估协议、人类游戏数据集和多种基线方法（如大语言模型代理、行为克隆、强化学习和博弈论方法）。在单团队配置下训练和评估代理，并逐步扩大团队规模测试泛化能力。

Result: 在单团队配置下，论文的方法能够击败专业VGC选手。然而，随着团队规模扩大，即使表现最好的算法也难以泛化，表明跨团队策略的泛化仍是一个开放挑战。

Conclusion: VGC-Bench为研究跨团队策略泛化提供了重要工具，但现有方法在团队规模扩大时表现不佳，未来需进一步改进算法以适应更复杂的战略环境。

摘要: 开发能够在不重新训练的情况下适应多样化战略环境的AI代理是多智能体学习的核心挑战。《宝可梦》视频游戏锦标赛（VGC）因其极高的团队配置空间（约10^139种）和离散组合特性，成为研究这一问题的理想领域。为了推动这一问题的研究，我们引入了VGC-Bench：一个提供关键基础设施、标准化评估协议、人类游戏数据集和多种基线方法（如大语言模型代理、行为克隆、强化学习和博弈论方法）的基准。在单团队配置下训练和评估代理时，我们的方法能够击败专业VGC选手。然而，随着团队规模扩大，即使表现最好的算法也难以泛化。因此，跨多样化团队策略的策略泛化仍是一个开放挑战。我们的代码已开源：https://github.com/cameronangliss/VGC-Bench。

</details>


### [474] [Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts](https://arxiv.org/abs/2506.10357)
**中文标题：Optimus-3：迈向具有可扩展任务专家的通用多模态Minecraft智能体**

*Zaijing Li,Yuquan Xie,Rui Shao,Gongwei Chen,Weili Guan,Dongmei Jiang,Liqiang Nie*

Main category: cs.AI

TL;DR: 本文提出了Optimus-3，一种面向Minecraft的通用多模态智能体，通过知识增强的数据生成、任务级路由的混合专家架构和多模态推理增强的强化学习，解决了开放世界环境中感知、规划和行动等挑战。


<details>
  <summary>Details</summary>
Motivation: 当前基于多模态大语言模型的智能体在开放世界环境（如Minecraft）中面临领域数据不足、异构任务干扰和视觉多样性等挑战，亟需一种通用解决方案。

Method: 1) 提出知识增强的数据生成管道；2) 引入任务级路由的混合专家架构；3) 开发多模态推理增强的强化学习方法。

Result: 实验表明，Optimus-3在Minecraft环境中超越了通用多模态大语言模型和现有最先进智能体。

Conclusion: Optimus-3通过创新方法解决了开放世界智能体的关键挑战，展示了其在复杂任务中的卓越性能。

摘要: 近年来，基于多模态大语言模型（MLLMs）的智能体在多个领域取得了显著进展。然而，在Minecraft等开放世界环境中构建具备感知、规划、行动、基础和反思能力的通用智能体仍面临挑战：领域特定数据不足、异构任务间的干扰以及开放世界中的视觉多样性。本文通过三项关键贡献解决这些挑战：1) 提出知识增强的数据生成管道，为智能体开发提供可扩展且高质量的训练数据；2) 引入任务级路由的混合专家（MoE）架构以减少异构任务干扰；3) 开发多模态推理增强的强化学习方法，提升智能体对Minecraft视觉多样性的推理能力。基于这些创新，我们提出了Optimus-3，一种面向Minecraft的通用智能体。大量实验结果表明，Optimus-3在Minecraft环境中超越了通用多模态大语言模型和现有最先进的智能体。项目页面：https://cybertronagent.github.io/Optimus-3.github.io/

</details>


### [475] [NeuroPAL: Punctuated Anytime Learning with Neuroevolution for Macromanagement in Starcraft: Brood War](https://arxiv.org/abs/2506.10384)
**中文标题：NeuroPAL：基于神经进化的间断式随时学习在《星际争霸：母巢之战》宏观管理中的应用**

*Jim O'Connor,Yeonghun Lee,Gary B Parker*

Main category: cs.AI

TL;DR: 本文提出NeuroPAL框架，结合神经进化与间断式随时学习（PAL），显著提升《星际争霸：母巢之战》宏观管理任务中的训练效率，使智能体在更短时间内达到高水平表现。


<details>
  <summary>Details</summary>
Motivation: 《星际争霸：母巢之战》是人工智能研究的经典挑战，尤其在需要长期战略规划的宏观管理领域。传统方法（如基于规则或监督深度学习）在适应性和计算效率上存在局限。本文旨在通过结合神经进化与间断式学习，提升智能体的训练效率和策略发现能力。

Method: 提出NeuroPAL框架，将神经进化增强拓扑（NEAT）与间断式随时学习（PAL）结合。PAL通过交替进行低精度训练和高精度评估，提升NEAT的样本效率，从而加速策略发现。

Result: 实验表明，PAL显著缩短训练时间（约为NEAT的一半），智能体达到竞技水平，并涌现出专家玩家常用的策略（如代理兵营布置和防御建筑优化）。

Conclusion: 间断式评估机制（如PAL）可增强神经进化在复杂即时战略环境中的扩展性和有效性，为未来研究提供了新方向。

摘要: 《星际争霸：母巢之战》仍是人工智能研究的挑战性基准，尤其在需要长期战略规划的宏观管理领域。传统方法（如基于规则或监督深度学习）在适应性和计算效率上存在局限。本文提出NeuroPAL框架，将神经进化增强拓扑（NEAT）与间断式随时学习（PAL）结合，通过交替进行低精度训练和高精度评估，提升NEAT的样本效率。在固定地图、单一种族的《星际争霸》场景中，NeuroPAL的表现优于标准NEAT训练。结果表明，PAL显著加速学习过程，使智能体在约一半的训练时间内达到竞技水平，并涌现出代理兵营布置等专家玩家常用策略。这些发现表明，PAL等结构化评估机制可增强神经进化在复杂即时战略环境中的扩展性和有效性。

</details>


### [476] [Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org/abs/2506.10387)
**中文标题：Mirage-1：通过分层多模态技能增强和更新GUI代理**

*Yuquan Xie,Zaijing Li,Rui Shao,Gongwei Chen,Kaiwen Zhou,Yinchuan Li,Dongmei Jiang,Liqiang Nie*

Main category: cs.AI

TL;DR: 本文提出了一种名为Mirage-1的多模态GUI代理，通过分层多模态技能（HMS）模块和技能增强蒙特卡洛树搜索（SA-MCTS）算法，解决了现有代理在在线环境中执行长时任务时知识不足和领域差距的问题。实验表明，Mirage-1在多个基准测试中显著优于现有代理。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLM）GUI代理在在线环境中执行长时任务时表现不佳，主要原因是知识不足和离线与在线领域之间的差距。本文受人类在开放环境中泛化知识的启发，旨在解决这些问题。

Method: 1. 提出分层多模态技能（HMS）模块，将轨迹逐步抽象为执行技能、核心技能和元技能，构建层次化知识结构。2. 提出技能增强蒙特卡洛树搜索（SA-MCTS）算法，利用离线环境中习得的技能减少在线树搜索的动作空间。3. 构建Mirage-1代理，支持多模态、跨平台和即插即用功能。

Result: 实验结果表明，Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH基准测试中分别比现有代理提升了32%、19%、15%和79%。

Conclusion: Mirage-1通过HMS和SA-MCTS算法显著提升了GUI代理在长时任务中的表现，为解决知识不足和领域差距问题提供了有效方案。

摘要: 近期利用多模态大语言模型（MLLM）作为GUI代理的研究取得了显著成果，但这些代理在在线环境中执行长时任务时仍面临知识不足和离线与在线领域差距的问题。本文受人类在开放环境中泛化知识的启发，提出了分层多模态技能（HMS）模块，通过逐步将轨迹抽象为执行技能、核心技能和元技能，构建层次化知识结构以支持长时任务规划。为弥合领域差距，我们提出了技能增强蒙特卡洛树搜索（SA-MCTS）算法，高效利用离线环境中习得的技能减少在线树搜索的动作空间。基于HMS，我们构建了Mirage-1，一种多模态、跨平台、即插即用的GUI代理。为验证Mirage-1在真实长时任务场景中的表现，我们构建了新的基准测试AndroidLH。实验结果表明，Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH上的表现分别比现有代理提升了32%、19%、15%和79%。项目页面：https://cybertronagent.github.io/Mirage-1.github.io/

</details>


### [477] [Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges](https://arxiv.org/abs/2506.10408)
**中文标题：通过系统1或系统2推理RAG：面向工业挑战的推理代理检索增强生成综述**

*Jintao Liang,Gang Su,Huifeng Lin,You Wu,Rui Zhao,Ziyue Li*

Main category: cs.AI

TL;DR: 本文综述了推理代理检索增强生成（RAG）方法，将其分为预定义推理和代理推理两类，分析了代表性技术，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 早期RAG系统在结构化任务中表现良好，但在需要复杂推理和动态检索的真实场景中表现不佳。为了解决这些问题，研究转向了推理代理RAG，将决策和自适应工具使用嵌入检索过程。

Method: 论文对推理代理RAG方法进行了全面回顾，将其分为两类：预定义推理（固定模块化流程）和代理推理（模型自主协调工具交互）。分析了代表性技术的架构设计、推理策略和工具协调。

Result: 综述了推理代理RAG的研究现状，提出了未来研究方向，以提高系统的灵活性、鲁棒性和适用性。

Conclusion: 推理代理RAG是一个有前景的研究方向，但仍需解决灵活性、鲁棒性和适用性等挑战。

摘要: 检索增强生成（RAG）通过将外部检索与语言生成相结合，克服了大型语言模型（LLM）的知识局限性。早期的RAG系统基于静态流程，在结构化任务中表现良好，但在需要复杂推理、动态检索和多模态集成的真实场景中表现不佳。为了解决这些问题，研究转向了推理代理RAG，将决策和自适应工具使用直接嵌入检索过程。本文全面回顾了推理代理RAG方法，将其分为两类：预定义推理（遵循固定模块化流程以增强推理）和代理推理（模型在推理过程中自主协调工具交互）。我们分析了两种范式下的代表性技术，涵盖架构设计、推理策略和工具协调。最后，我们讨论了关键研究挑战，并提出了未来方向，以推动推理代理RAG系统的灵活性、鲁棒性和适用性。相关研究已整理至https://github.com/ByebyeMonica/Reasoning-Agentic-RAG。

</details>


### [478] [Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods](https://arxiv.org/abs/2506.10420)
**中文标题：处理服务的多维度自动扩展：基于代理方法的比较**

*Boris Sedlak,Alireza Furutanpey,Zihang Wang,Víctor Casamayor Pujol,Schahram Dustdar*

Main category: cs.AI

TL;DR: 本文提出了一种基于代理的多维度自动扩展框架，用于在资源受限的边缘计算环境中动态调整硬件资源和服务配置。通过比较四种代理方法（主动推理、深度Q网络、结构知识分析和深度主动推理），验证了其在并行运行的两个实际服务（YOLOv8和OpenCV）中的性能表现。结果显示所有代理均能满足服务级别目标（SLO），但各有不同的收敛特性。


<details>
  <summary>Details</summary>
Motivation: 边缘计算由于严格的资源限制，需要更灵活的扩展行为。传统自动扩展方法无法满足需求，因此本文旨在探索多维度弹性扩展的可行性，以最大化资源受限环境中的需求满足。

Method: 提出了一种基于代理的自动扩展框架，动态调整硬件资源和服务内部配置。比较了四种代理方法：主动推理、深度Q网络、结构知识分析和深度主动推理，并在YOLOv8（视觉识别）和OpenCV（二维码检测）两个并行运行的实际服务中进行了测试。

Result: 所有代理均实现了可接受的服务级别目标（SLO）性能，但表现出不同的收敛模式。深度Q网络受益于预训练，结构知识分析收敛速度快，而深度主动推理代理兼具理论基础和实际扩展优势。

Conclusion: 研究证明了基于代理的多维度自动扩展在边缘环境中的可行性，并鼓励未来在此方向进一步探索。

摘要: 边缘计算由于严格的资源限制，打破了传统的自动扩展方式，从而推动了使用多维度弹性行为的更灵活扩展方法。本文提出了一种基于代理的自动扩展框架，动态调整硬件资源和服务内部配置，以最大化资源受限环境中的需求满足。我们比较了四种扩展代理：主动推理、深度Q网络、结构知识分析和深度主动推理，并使用了两个并行运行的实际处理服务：YOLOv8（用于视觉识别）和OpenCV（用于二维码检测）。结果显示，所有代理均实现了可接受的服务级别目标（SLO）性能，但表现出不同的收敛模式。深度Q网络受益于预训练，结构知识分析收敛速度快，而深度主动推理代理兼具理论基础和实际扩展优势。我们的研究结果证明了基于代理的多维度自动扩展在边缘环境中的可行性，并鼓励未来在此研究方向进一步探索。

</details>


### [479] [OIBench: Benchmarking Strong Reasoning Models with Olympiad in Informatics](https://arxiv.org/abs/2506.10481)
**中文标题：OIBench：用信息学奥赛基准测试强推理模型**

*Yaoming Zhu,Junxin Wang,Yiyang Li,Lin Qiu,ZongYu Wang,Jun Xu,Xuezhi Cao,Yuhuai Wei,Mingshi Wang,Xunliang Cai,Rong Ma*

Main category: cs.AI

TL;DR: 本文介绍了OIBench，一个高质量、私密且具有挑战性的信息学奥赛级别数据集，包含250个精心设计的问题，旨在推动算法推理能力的提升。实验表明，当前最先进模型在正确性和效率上已超越大多数人类参与者，但仍未达到最优解。


<details>
  <summary>Details</summary>
Motivation: 随着模型日益复杂，传统算法基准逐渐饱和，需要更具挑战性的基准来指导算法推理能力的未来改进。

Method: 构建了OIBench数据集，包含250个原创问题，涵盖多种编程范式和复杂度；提出时间/空间完成曲线进行细粒度效率分析，并通过高级参与者评估实现人机直接比较。

Result: 实验显示，开源模型落后于闭源模型，但当前最先进模型在正确性和效率上已超越大多数人类参与者，但仍未达到最优解。

Conclusion: 通过发布OIBench作为开源资源，希望该基准能为未来大语言模型的代码推理能力提升做出贡献。

摘要: 随着模型日益复杂，传统算法基准逐渐饱和，凸显了需要更具挑战性的基准来指导算法推理的未来改进。本文介绍了OIBench，一个高质量、私密且具有挑战性的信息学奥赛级别数据集，包含250个精心设计的原创问题。我们详细介绍了基准的构建方法，确保涵盖多种编程范式和复杂度的全面评估，并通过实验展示了其抗污染特性。我们提出了时间/空间完成曲线以进行更细粒度的效率分析，并通过高级参与者评估实现人机直接比较。实验表明，尽管开源模型落后于闭源模型，当前最先进模型在正确性和效率上已超越大多数人类参与者，但仍未达到最优解。通过将OIBench作为完全开源资源发布（https://huggingface.co/datasets/AGI-Eval/OIBench），我们希望该基准能为未来大语言模型的代码推理能力提升做出贡献。

</details>


### [480] [Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning](https://arxiv.org/abs/2506.10521)
**中文标题：科学家的首次考试：通过感知、理解和推理评估多模态大语言模型的认知能力**

*Yuhao Zhou,Yiheng Wang,Xuming He,Ruoyao Xiao,Zhiwei Li,Qiantai Feng,Zijie Guo,Yuejin Yang,Hao Wu,Wenxuan Huang,Jiaqi Wei,Dan Si,Xiuqi Yao,Jia Bu,Haiwen Huang,Tianfan Fu,Shixiang Tang,Ben Fei,Dongzhan Zhou,Fenghua Ling,Yan Lu,Siqi Sun,Chenhui Li,Guanjie Zheng,Jiancheng Lv,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: 本文提出了科学家首次考试（SFE）基准，用于评估多模态大语言模型（MLLM）在科学信号感知、属性理解和比较推理三个层次上的认知能力。实验显示当前最先进的模型表现不佳，表明MLLM在科学领域仍有巨大提升空间。


<details>
  <summary>Details</summary>
Motivation: 当前科学基准主要评估MLLM的知识理解能力，而忽视了其感知和推理能力的评估。为了填补这一空白，作者设计了SFE基准，以全面评估MLLM的科学认知能力。

Method: SFE基准包含830个专家验证的视觉问答对，涵盖三种问题类型和66个多模态任务，涉及五个高价值学科。通过这三个层次（感知、理解和推理）评估MLLM的能力。

Result: 实验结果显示，当前最先进的GPT-o3和InternVL-3在SFE上的得分仅为34.08%和26.52%，表明MLLM在科学领域的表现仍有显著不足。

Conclusion: SFE基准揭示了MLLM在科学认知能力上的不足，为未来AI增强科学发现提供了发展方向。

摘要: 科学发现日益依赖于基于信息密集型科学数据和领域专业知识的复杂多模态推理。通过专家级科学基准的支持，科学多模态大语言模型（MLLM）有望在现实工作流程中显著提升这一发现过程。然而，当前的科学基准主要关注评估MLLM的知识理解能力，导致对其感知和推理能力的评估不足。为解决这一问题，我们提出了科学家首次考试（SFE）基准，旨在通过三个相互关联的层次评估MLLM的科学认知能力：科学信号感知、科学属性理解和科学比较推理。具体而言，SFE包含830个专家验证的视觉问答对，涵盖三种问题类型，涉及五个高价值学科的66个多模态任务。大量实验表明，当前最先进的GPT-o3和InternVL-3在SFE上的得分仅为34.08%和26.52%，突显了MLLM在科学领域的巨大改进空间。我们希望SFE的见解能促进AI增强科学发现的进一步发展。

</details>


### [481] [LogiPlan: A Structured Benchmark for Logical Planning and Relational Reasoning in LLMs](https://arxiv.org/abs/2506.10527)
**中文标题：LogiPlan：用于LLMs逻辑规划和关系推理的结构化基准**

*Yanan Cai,Ahmed Salem,Besmira Nushi,Mark Russinovich*

Main category: cs.AI

TL;DR: LogiPlan是一个新的基准测试，用于评估大型语言模型（LLMs）在逻辑规划和复杂关系推理中的能力，包含三个任务：计划生成、一致性检测和比较问题。测试显示，尽管增强推理模型在简单任务上表现良好，但在需要深度逻辑规划的复杂配置中仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 逻辑关系推理对于依赖LLMs生成和查询关系图的应用（如网络基础设施、知识库或业务流程模式）至关重要。当前缺乏一个动态调整任务复杂度的基准来评估LLMs在这些任务中的表现。

Method: LogiPlan通过控制对象数量、关系和关系链的最小深度来动态调整任务复杂度，包含三个任务：计划生成、一致性检测和比较问题。此外，还评估模型的自我修正能力。

Result: 测试了包括DeepSeek R1、Gemini 2.0 Pro、GPT-4.5等在内的多个先进模型，发现模型规模和架构与性能显著相关。增强推理模型在简单任务上表现良好，但在复杂配置中表现不佳。

Conclusion: LogiPlan为评估LLMs的逻辑规划和关系推理能力提供了细粒度的基准，揭示了当前模型在复杂任务中的局限性，为未来研究提供了方向。

摘要: 我们介绍了LogiPlan，这是一个新颖的基准测试，旨在评估大型语言模型（LLMs）在复杂关系结构中的逻辑规划和推理能力。逻辑关系推理对于依赖LLMs生成和查询关系图的应用（如网络基础设施、知识库或业务流程模式）至关重要。我们的框架通过控制对象数量、关系和关系链的最小深度，动态调整任务复杂度，从而提供对模型在不同难度级别表现的细粒度评估。LogiPlan包含三个互补任务：（1）计划生成，模型需构建满足特定结构约束的有效有向关系图；（2）一致性检测，测试模型识别关系结构中不一致性的能力；（3）比较问题，评估模型在给定图中判断查询关系有效性的能力。此外，我们还通过提示模型验证和优化初始解决方案来评估其自我修正能力。我们测试了包括DeepSeek R1、Gemini 2.0 Pro、GPT-4.5等在内的多个先进模型，发现模型规模和架构与性能显著相关。分析表明，尽管近期增强推理模型在简单实例上表现良好，但在需要深度逻辑规划的复杂配置中仍存在困难。

</details>


### [482] [Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning](https://arxiv.org/abs/2506.10585)
**中文标题：Primender序列：一种用于测试符号推理和人工智能推理的新型数学构造**

*Mohd Anwar Jamal Faiz*

Main category: cs.AI

TL;DR: 本文提出了一种名为Primender序列的新型数学构造，结合素数性质和模数条件，用于测试大型语言模型（LLM）的符号推理能力。通过设计结构化提示和评估框架，研究验证了LLM在规则推断、假设验证和序列生成方面的表现。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种可解释的、基于规则的测试基准，以评估LLM在推断隐藏规则、验证数学假设和推广符号逻辑方面的能力。Primender序列的提出填补了现有测试工具的空白，并为LLM的符号推理能力提供了新的评估标准。

Method: 研究定义了Primender序列，并设计了一个结构化提示和评估框架，测试多个先进LLM（如ChatGPT、Copilot等）在识别序列规则、验证假设和生成序列方面的表现。评估指标包括规则推断准确性、假设验证、序列有效性和符号解释质量。

Result: 实验结果表明，LLM在识别Primender序列规则和验证假设方面表现不一，部分模型能够准确推断规则并生成有效序列，而其他模型则表现较差。研究为LLM的符号推理能力提供了量化评估。

Conclusion: Primender序列作为一种新型数学构造，为LLM的符号推理能力测试提供了有效工具。研究不仅填补了现有测试工具的空白，还为未来在数论、人工智能和软件工程领域的交叉研究提供了新思路。

摘要: 本文介绍了Primender序列，这是一种新型的整数序列，其定义规则结合了经典素数性质和基于模数的数字条件。具体而言，一个数n被包含在序列中，如果它是素数或其最后一位或任意长度的后缀是素数。换句话说，序列包含素数或至少有一个素数后缀的数。生成的序列具有确定性但非平凡的结构，融合了数论性质和符号模式。我们提出将Primender序列作为评估大型语言模型（LLM）符号推理能力的基准。研究的动机源于对可解释、基于规则的测试基准的需求，以评估LLM推断隐藏规则、验证数学假设和推广符号逻辑的能力。研究探讨了一个关键假设：当Primender序列中的一个数恰好比小于或等于它的最大素数大1时，它与序列中前一个数的差也为1。我们设计了一个结构化提示和评估框架，在多个先进LLM（包括ChatGPT、Copilot、DeepSeek、Gemini、Grok和LLaMA）上测试这一假设。模型的任务包括识别底层规则、验证假设并生成序列的下10万个项。通过规则推断准确性、假设验证、序列有效性和符号解释质量等比较指标评估模型性能。本研究贡献了一种新型数学构造和可重复的方法论，用于在符号推理、假设测试和可扩展模式推广方面对LLM进行基准测试，连接了数论、人工智能和软件工程领域。

</details>


### [483] [Data Driven Diagnosis for Large Cyber-Physical-Systems with Minimal Prior Information](https://arxiv.org/abs/2506.10613)
**中文标题：基于数据驱动的大型信息物理系统诊断方法：最少先验信息需求**

*Henrik Sebastian Steude,Alexander Diedrich,Ingo Pill,Lukas Moddemann,Daniel Vranješ,Oliver Niggemann*

Main category: cs.AI

TL;DR: 本文提出了一种基于数据驱动的诊断方法，适用于大型信息物理系统，仅需最少的先验知识即可实现高效诊断。


<details>
  <summary>Details</summary>
Motivation: 复杂信息物理系统的诊断通常需要大量先验知识（如详细系统模型或训练数据），但获取这些信息具有挑战性。本文旨在解决这一问题，提出一种仅需最少先验知识的诊断方法。

Method: 方法结合了基于神经网络的症状生成器（用于子系统级异常检测）和一种新的图诊断算法（利用子系统间的最小因果关系信息）。

Result: 实验表明，该方法在82%的情况下能正确识别真实因果组件，并在73%的场景中有效缩小搜索空间。在真实数据集（Secure Water Treatment）上的测试也验证了其实际应用潜力。

Conclusion: 该方法为大型复杂信息物理系统提供了一种实用的诊断解决方案，尤其是在先验知识有限的情况下。

摘要: 复杂信息物理系统的诊断过程通常需要大量先验知识，如详细的系统模型或全面的训练数据，但获取这些信息具有显著挑战性。为解决这一问题，我们提出了一种新的诊断方法，仅需最少的先验知识，包括对子系统关系的基本理解和正常运行数据。我们的方法结合了基于神经网络的症状生成器（用于子系统级异常检测）和一种新的图诊断算法（利用子系统间的最小因果关系信息，这些信息在实践中通常可用）。通过完全可控的模拟数据集实验，我们的方法在82%的情况下能够将真实因果组件包含在诊断集中，并在73%的场景中有效缩小搜索空间。在真实数据集（Secure Water Treatment）上的进一步测试展示了该方法在实际场景中的潜力。结果表明，我们的方法在大型复杂信息物理系统中具有实际应用潜力，尤其是在先验知识有限的情况下。

</details>


### [484] [TeleMath: A Benchmark for Large Language Models in Telecom Mathematical Problem Solving](https://arxiv.org/abs/2506.10674)
**中文标题：TeleMath：大语言模型在电信数学问题解决中的基准测试**

*Vincenzo Colle,Mohamed Sana,Nicola Piovesan,Antonio De Domenico,Fadhel Ayed,Merouane Debbah*

Main category: cs.AI

TL;DR: TeleMath是首个专门用于评估大语言模型在电信领域数学问题解决能力的基准数据集，包含500个问答对。实验表明，专为数学或逻辑推理设计的模型表现最佳，而通用模型表现较差。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在电信领域的广泛应用，大语言模型在解决领域特定、数学密集型任务中的能力尚未充分探索。TeleMath旨在填补这一空白。

Method: 通过专家设计的种子问题生成500个问答对，覆盖电信领域的广泛主题。评估了多种开源大语言模型在TeleMath上的表现。

Result: 专为数学或逻辑推理设计的模型在TeleMath上表现最佳，而通用模型即使参数规模大，表现也较差。

Conclusion: TeleMath为评估大语言模型在电信领域的数学问题解决能力提供了首个基准，并揭示了专用模型在此类任务中的优势。

摘要: 人工智能在电信领域的日益普及引发了对大语言模型（LLMs）解决领域特定、数学密集型任务能力的兴趣。尽管近期进展提升了LLMs在通用数学推理中的表现，但其在信号处理、网络优化和性能分析等专业领域的有效性仍未被充分探索。为填补这一空白，我们提出了TeleMath，这是首个专门设计用于评估LLMs在电信领域解决数学问题能力的基准数据集。TeleMath包含500个问答对，覆盖电信领域的广泛主题。本文概述了从专家设计的种子问题生成问答对的流程。对多种开源LLMs的评估表明，TeleMath上表现最佳的是专为数学或逻辑推理设计的近期模型。相比之下，通用模型即使参数规模大，也常难以应对这些挑战。我们已发布数据集和评估代码，以支持结果复现和未来研究。

</details>


### [485] [Automated Validation of Textual Constraints Against AutomationML via LLMs and SHACL](https://arxiv.org/abs/2506.10678)
**中文标题：基于LLM和SHACL的AutomationML文本约束自动化验证**

*Tom Westermann,Aljosha Köcher,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 本文提出了一种自动化验证AutomationML（AML）文本约束的流程，结合LLM和SHACL技术，实现半自动化的规则检查，无需用户掌握形式化方法。


<details>
  <summary>Details</summary>
Motivation: AutomationML（AML）在工程中实现了标准化数据交换，但其建模建议通常以非正式的文本约束形式存在，无法在AML中自动验证。本文旨在解决这一问题。

Method: 首先通过RML和SPARQL将AML模型映射到OWL本体，然后利用大型语言模型（LLM）将文本规则翻译为SHACL约束，最后对生成的AML本体进行SHACL验证，并将结果自动解释为自然语言。

Result: 实验表明，即使复杂的建模规则也可以通过半自动方式检查，且用户无需理解形式化方法或本体技术。

Conclusion: 该方法为AML文本约束的自动化验证提供了可行方案，显著降低了用户的技术门槛。

摘要: AutomationML（AML）实现了工程中的标准化数据交换，但现有的AML建模建议通常以非正式的文本约束形式存在，无法在AML中自动验证。本文提出了一种流程，用于形式化和验证此类约束。首先，通过RML和SPARQL将AML模型映射到OWL本体；其次，利用大型语言模型（LLM）将文本规则翻译为SHACL约束，并对生成的AML本体进行验证；最后，将SHACL验证结果自动解释为自然语言。该方法在一个AML建议样本中进行了演示，结果表明，即使复杂的建模规则也可以通过半自动方式检查，且无需用户理解形式化方法或本体技术。

</details>


### [486] [System ASPMT2SMT:Computing ASPMT Theories by SMT Solvers](https://arxiv.org/abs/2506.10708)
**中文标题：系统ASPMT2SMT：通过SMT求解器计算ASPMT理论**

*Michael Bartholomew,Joohyung Lee*

Main category: cs.AI

TL;DR: 本文介绍了一个名为ASPMT2SMT的编译器，将ASPMT程序转换为SMT实例，利用SMT求解器计算稳定模型，并展示了其在实数计算中的有效性。


<details>
  <summary>Details</summary>
Motivation: ASPMT（基于功能稳定模型语义的答案集编程与可满足性模理论的结合）需要一种方法将其程序转换为SMT实例，以便利用SMT求解器计算稳定模型。

Method: 开发了一个名为ASPMT2SMT的编译器，结合ASP基础工具gringo和SMT求解器z3，将ASPMT程序部分接地并转换为SMT实例。

Result: 系统成功将ASPMT程序转换为SMT实例，并有效处理了实数计算，支持连续变化的推理。

Conclusion: ASPMT2SMT系统为ASPMT程序的计算提供了一种有效方法，特别是在处理实数计算和连续变化时表现优异。

摘要: 答案集编程模理论（ASPMT）是一种基于功能稳定模型语义的答案集编程与可满足性模理论的结合方法。研究表明，ASPMT程序的紧密片段可以转换为SMT实例，从而允许SMT求解器计算ASPMT程序的稳定模型。本文介绍了一个名为ASPMT2SMT的编译器，实现了这一转换。该系统使用ASP接地工具gringo和SMT求解器z3。gringo对输入程序进行部分接地，而将部分变量留给z3处理。我们展示了该系统能够有效处理实数计算，支持连续变化的推理。

</details>


### [487] [Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering](https://arxiv.org/abs/2506.10753)
**中文标题：模拟之前先思考：符号推理协调神经计算以回答反事实问题**

*Adam Ishay,Zhun Yang,Joohyung Lee,Ilgu Kang,Dongjae Lim*

Main category: cs.AI

TL;DR: 本文提出了一种结合符号推理与神经计算的增强方法，用于提升神经符号模型在反事实问题回答中的表现。通过因果图表示事件关系，并利用ASP协调感知与模拟模块，在CLEVRER和CRAFT基准测试中取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号模型在反事实问题回答中存在局限性，尤其是在因果和时间推理方面。本文旨在通过符号推理增强神经符号模型，以更有效地处理反事实问题。

Method: 定义因果图表示事件关系，利用答案集编程（ASP）协调感知与模拟模块。在CRAFT基准中，还结合了大型预训练语言模型（如GPT-3.5和GPT-4）作为动态模拟器的代理。

Result: 在CLEVRER基准测试中取得了最优性能，显著优于现有模型。在CRAFT基准中，通过符号因果推理指导的提示进一步提升了反事实问题的回答效果。

Conclusion: 符号推理与神经计算的结合能够有效提升反事实问题回答的性能，为神经符号模型的发展提供了新思路。

摘要: 视频动态的因果和时间推理是一个具有挑战性的问题。尽管结合符号推理与神经感知和预测的神经符号模型显示出潜力，但它们在回答反事实问题时仍存在局限性。本文提出了一种增强神经符号模型的方法，利用符号推理分析事件间的因果关系。我们定义了因果图来表示这些关系，并使用声明性逻辑编程方法——答案集编程（ASP）来协调感知与模拟模块。我们在CLEVRER和CRAFT两个基准测试中验证了方法的有效性。在CLEVRER挑战中，我们的增强方法取得了最优性能，显著优于现有模型。在CRAFT基准中，我们利用大型预训练语言模型（如GPT-3.5和GPT-4）作为动态模拟器的代理。结果表明，通过符号因果推理指导的提示可以进一步提升反事实问题的回答效果。

</details>


### [488] [OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](https://arxiv.org/abs/2506.10764)
**中文标题：OPT-BENCH：评估大语言模型代理在大规模搜索空间优化问题中的表现**

*Xiaozhe Li,Jixuan Chen,Xinyu Fang,Shengyuan Ding,Haodong Duan,Qingwen Liu,Kai Chen*

Main category: cs.AI

TL;DR: 本文提出了OPT-BENCH基准测试，用于评估大语言模型（LLM）代理在大规模搜索空间优化问题中的表现，并通过实验验证了历史反馈对优化性能的显著提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在解决多样化任务中表现出色，但其通过迭代学习和反馈优化复杂解决方案的能力尚未充分探索。本文旨在填补这一研究空白。

Method: 作者设计了OPT-BENCH基准测试，包含20个Kaggle真实机器学习任务和10个经典NP问题，并开发了OPT-Agent框架，模拟人类推理过程，通过生成、验证和迭代改进解决方案。

Result: 实验结果表明，结合历史上下文显著提升了LLM代理在机器学习和NP任务中的优化性能，同时分析了优化迭代次数、温度设置和模型架构对结果的影响。

Conclusion: OPT-BENCH为LLM驱动的优化和迭代推理研究提供了开放资源和工具，推动了该领域的进一步发展。

摘要: 大语言模型（LLM）在解决多样化任务中表现出卓越能力，但其通过迭代学习和反馈优化复杂解决方案的能力尚未充分探索。为填补这一空白，我们提出了OPT-BENCH，一个综合性基准测试，用于评估LLM代理在大规模搜索空间优化问题中的表现。OPT-BENCH包含20个来自Kaggle的真实机器学习任务和10个经典NP问题，为评估LLM代理的迭代推理和解决方案优化能力提供了多样化和挑战性的环境。为实现严格评估，我们引入了OPT-Agent，一个端到端的优化框架，通过生成、验证和迭代改进解决方案，模拟人类在解决复杂问题时的推理过程。通过对6个模型家族的9种先进LLM进行广泛实验，我们分析了优化迭代次数、温度设置和模型架构对解决方案质量和收敛性的影响。结果表明，结合历史上下文显著提升了机器学习和NP任务的优化性能。所有数据集、代码和评估工具均已开源，以推动LLM驱动的优化和迭代推理研究的进一步发展。项目页面：\href{https://github.com/OliverLeeXZ/OPT-BENCH}{https://github.com/OliverLeeXZ/OPT-BENCH}。

</details>


### [489] [A Study on Individual Spatiotemporal Activity Generation Method Using MCP-Enhanced Chain-of-Thought Large Language Models](https://arxiv.org/abs/2506.10853)
**中文标题：基于MCP增强链式思维大语言模型的个体时空活动生成方法研究**

*Yu Zhang,Yang Hu,De Wang*

Main category: cs.AI

TL;DR: 本文提出了一种结合链式思维（CoT）和模型上下文协议（MCP）的框架，用于增强大语言模型（LLMs）在模拟人类时空行为方面的能力。实验验证了该方法在生成数据质量和效率上的显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则和统计的人类时空行为模拟方法存在计算成本高、泛化能力差和可扩展性不足的问题。尽管大语言模型（LLMs）有潜力作为“世界模拟器”，但在时空推理方面仍面临空间认知有限、物理约束理解不足和群体同质化等挑战。

Method: 通过将链式思维（CoT）推理与模型上下文协议（MCP）结合，提出了一种五阶段认知框架和六类MCP工具（时间管理、空间导航、环境感知、个人记忆、社会协作和经验评估），以增强LLMs的时空行为模拟能力。

Result: 在上海陆家嘴地区的实验中，生成的1000个样本与真实移动信号数据高度相似，生成质量评分达到7.86至8.36。并行处理实验显示，生成时间从1.30分钟降至0.17分钟每样本。

Conclusion: 该框架为城市行为建模提供了新方法，推动了LLMs在城市计算中的应用，并为合成移动数据生成提供了实用方案，为智慧城市规划、交通预测和参与式城市设计奠定了基础。

摘要: 人类时空行为模拟对城市规划研究至关重要，但传统的基于规则和统计的方法存在计算成本高、泛化能力差和可扩展性不足的问题。尽管大语言模型（LLMs）作为“世界模拟器”展现出潜力，但在时空推理方面仍面临空间认知有限、物理约束理解不足和群体同质化等挑战。本文提出了一种结合链式思维（CoT）推理与模型上下文协议（MCP）的框架，以增强LLMs模拟符合验证数据模式的时空行为的能力。该方法通过五阶段认知框架实现类人渐进式推理，并通过六类专用MCP工具（时间管理、空间导航、环境感知、个人记忆、社会协作和经验评估）进行全面的数据处理。在上海陆家嘴地区的实验中，验证了该框架在1000个生成样本中的有效性。结果表明，生成数据与真实移动信号数据高度相似，不同基础模型的生成质量评分达到7.86至8.36。并行处理实验显示效率提升，当处理规模从2个扩展到12个进程时，生成时间从1.30分钟降至0.17分钟每样本。本研究通过将CoT推理与MCP结合，为城市行为建模提供了新方法，推动了LLMs在城市计算中的应用，并为合成移动数据生成提供了实用方案。该框架为智慧城市规划、交通预测和参与式城市设计应用奠定了基础。

</details>


### [490] [GenPlanX. Generation of Plans and Execution](https://arxiv.org/abs/2506.10897)
**中文标题：GenPlanX：计划生成与执行**

*Daniel Borrajo,Giuseppe Canonaco,Tomás de la Rosa,Alfredo Garrachón,Sriram Gopalakrishnan,Simerjot Kaur,Marianela Morales,Sunandita Patra,Alberto Pozanco,Keshav Ramani,Charese Smiley,Pietro Totis,Manuela Veloso*

Main category: cs.AI

TL;DR: GenPlanX结合大型语言模型（LLM）和经典AI规划技术，通过自然语言描述任务并生成执行计划，提升办公任务效率。


<details>
  <summary>Details</summary>
Motivation: 传统AI规划技术虽能生成复杂任务的动作序列，但无法理解自然语言描述的任务。大型语言模型（LLM）的出现为自然语言交互提供了新可能，尤其在理解用户意图方面表现突出。因此，本文旨在结合LLM与经典规划技术，提升任务规划的效率和用户体验。

Method: GenPlanX整合了LLM用于自然语言任务描述、经典AI规划引擎以及执行与监控框架。通过LLM解析用户意图，生成规划任务，再由规划引擎生成执行序列，并通过监控框架确保任务完成。

Result: GenPlanX在办公任务中表现出色，能够高效生成并执行计划，显著提升工作流程效率和生产力，展示了人机协作的潜力。

Conclusion: GenPlanX通过结合LLM和经典规划技术，实现了自然语言驱动的任务规划与执行，为提升工作效率和人机协作提供了新方向。

摘要: 传统AI规划技术能够为复杂任务生成动作序列，但无法理解自然语言描述的任务。大型语言模型（LLM）的出现为人机交互带来了新能力，尤其在理解用户意图方面表现突出。本文提出GenPlanX，它结合了LLM用于自然语言任务描述、经典AI规划引擎以及执行与监控框架。我们展示了GenPlanX在办公任务中的高效性，凸显了其通过无缝人机协作优化工作流程和提升生产力的潜力。

</details>


### [491] [Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?](https://arxiv.org/abs/2506.10912)
**中文标题：破解有害分子：多模态大语言模型是否准备好进行结构级分子毒性修复？**

*Fei Lin,Ziyang Gong,Cong Wang,Yonglin Tian,Tengchao Zhang,Xue Yang,Gen Luo,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 本文介绍了首个针对多模态大语言模型（MLLMs）的分子毒性修复基准任务ToxiMol，并构建了包含11项任务和560个代表性毒性分子的标准化数据集。通过设计机制感知和任务自适应的提示标注流程，以及自动化评估框架ToxiEval，评估了近30种主流MLLMs。结果表明，尽管MLLMs在此任务上仍面临挑战，但在毒性理解、语义约束和结构感知分子编辑方面展现出潜力。


<details>
  <summary>Details</summary>
Motivation: 毒性是药物早期开发失败的主要原因之一，但分子毒性修复任务尚未被系统定义或评估。为了填补这一空白，本文旨在为多模态大语言模型（MLLMs）提供一个标准化的分子毒性修复基准任务。

Method: 1. 构建ToxiMol基准任务，包含11项任务和560个代表性毒性分子；2. 设计机制感知和任务自适应的提示标注流程；3. 提出自动化评估框架ToxiEval，整合毒性终点预测、合成可行性、药物相似性和结构相似性；4. 评估近30种主流MLLMs，并通过消融实验分析关键因素。

Result: 实验结果表明，尽管当前MLLMs在分子毒性修复任务上仍面临挑战，但已展现出毒性理解、语义约束和结构感知分子编辑的潜力。

Conclusion: 本文提出的ToxiMol基准任务和ToxiEval评估框架为MLLMs在分子毒性修复领域的应用提供了标准化工具，并揭示了其在该领域的潜力与挑战。

摘要: 毒性仍是药物早期开发失败的主要原因之一。尽管分子设计和性质预测取得了进展，但分子毒性修复任务——生成结构有效且毒性降低的分子替代物——尚未被系统定义或评估。为填补这一空白，我们提出了ToxiMol，这是首个专注于分子毒性修复的通用多模态大语言模型（MLLMs）基准任务。我们构建了一个标准化数据集，涵盖11项主要任务和560个代表性毒性分子，覆盖多种机制和粒度。基于专家毒理学知识，我们设计了具有机制感知和任务自适应能力的提示标注流程。同时，我们提出了自动化评估框架ToxiEval，将毒性终点预测、合成可行性、药物相似性和结构相似性整合为高通量评估链。我们系统评估了近30种主流通用MLLMs，并通过多项消融实验分析了评估标准、候选多样性和失败归因等关键因素。实验结果表明，尽管当前MLLMs在此任务上仍面临显著挑战，但它们已开始在毒性理解、语义约束和结构感知分子编辑方面展现出潜力。

</details>


### [492] [Spurious Rewards: Rethinking Training Signals in RLVR](https://arxiv.org/abs/2506.10947)
**中文标题：虚假奖励：重新思考RLVR中的训练信号**

*Rulin Shao,Shuyue Stella Li,Rui Xin,Scott Geng,Yiping Wang,Sewoong Oh,Simon Shaolei Du,Nathan Lambert,Sewon Min,Ranjay Krishna,Yulia Tsvetkov,Hannaneh Hajishirzi,Pang Wei Koh,Luke Zettlemoyer*

Main category: cs.AI

TL;DR: 研究表明，即使使用与正确答案相关性极低甚至为负的虚假奖励信号，强化学习与可验证奖励（RLVR）仍能显著提升某些模型（如Qwen2.5-Math-7B）的数学推理能力。然而，这种效果在其他模型家族（如Llama3或OLMo2）中并不明显。RLVR可能通过激活预训练中学到的有用推理表征发挥作用，但具体机制仍需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 探讨强化学习与可验证奖励（RLVR）在数学推理任务中的表现，尤其是当奖励信号与正确答案无关时，RLVR是否仍能提升模型性能。同时，研究这种效果在不同模型家族中的普适性。

Method: 使用多种虚假奖励信号（如随机奖励、格式奖励、错误标签等）对Qwen2.5-Math-7B等模型进行RLVR训练，并分析其性能提升情况。同时对比其他模型家族（如Llama3和OLMo2）的表现差异。

Result: RLVR显著提升了Qwen2.5-Math-7B在MATH-500任务中的表现，即使奖励信号与正确答案无关（如随机奖励提升21.4%）。此外，RLVR使Qwen模型的代码推理行为（无实际代码执行的思考）从65%增加到90%以上。然而，其他模型家族未能从虚假奖励中获益。

Conclusion: RLVR可能通过激活预训练中学到的推理表征提升性能，但其效果因模型而异。未来研究应在多样化模型上验证RLVR，而非仅依赖单一模型。虚假奖励信号在特定模型中可能产生误导性结果。

摘要: 研究表明，即使使用与正确答案相关性极低、无相关性甚至为负的虚假奖励信号，强化学习与可验证奖励（RLVR）仍能在某些模型（如Qwen2.5-Math-7B）中激发强大的数学推理能力。例如，RLVR将Qwen2.5-Math-7B在MATH-500任务中的表现提升了21.4%（随机奖励）、13.8%（格式奖励）、24.1%（错误标签）、26.0%（1-shot RL）和27.1%（多数投票），几乎接近使用真实奖励的29.1%提升。然而，适用于Qwen的虚假奖励在其他模型家族（如Llama3或OLMo2）中往往无效。特别地，我们发现代码推理（无实际代码执行的思考）是Qwen2.5-Math的独特行为，RLVR使其频率从65%显著增加到90%以上，即使使用虚假奖励。总体而言，我们推测，由于缺乏有用的奖励信号，RLVR可能通过某种方式激活了预训练中学到的有用推理表征，但具体机制仍需未来研究。我们建议，未来RLVR研究应在多样化模型上验证，而非仅依赖单一默认选择，因为即使在完全虚假的奖励信号下，Qwen模型也可能表现出显著的性能提升。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [493] [Discrete Audio Tokens: More Than a Survey!](https://arxiv.org/abs/2506.10274)
**中文标题：离散音频标记：不仅仅是一篇综述！**

*Pooneh Mousavi,Gallil Maimon,Adel Moumen,Darius Petermann,Jiatong Shi,Haibin Wu,Haici Yang,Anastasia Kuznetsova,Artem Ploujnikov,Ricard Marxer,Bhuvana Ramabhadran,Benjamin Elizalde,Loren Lugosch,Jinyu Li,Cem Subakan,Phil Woodland,Minje Kim,Hung-yi Lee,Shinji Watanabe,Yossi Adi,Mirco Ravanelli*

Main category: cs.SD

TL;DR: The paper systematically reviews and benchmarks discrete audio tokenizers across speech, music, and general audio domains, proposing a taxonomy and evaluating performance on multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing studies on discrete audio tokens lack a unified comparison across domains and tasks, prompting the need for a comprehensive review and benchmark.

Method: The paper proposes a taxonomy of tokenization approaches, evaluates tokenizers on reconstruction, downstream performance, and acoustic language modeling, and conducts ablation studies.

Result: The study identifies key limitations and trade-offs, providing insights for future research in discrete audio tokenization.

Conclusion: The paper offers a systematic framework and practical guidance for advancing research in discrete audio tokenization.

摘要: 离散音频标记是一种紧凑的表示形式，旨在保留感知质量、语音内容和说话者特征，同时实现高效的存储和推理，并在多样化的下游任务中表现出竞争力。它们为连续特征提供了实用的替代方案，使语音和音频能够集成到现代大型语言模型（LLMs）中。随着基于标记的音频处理兴趣的增长，出现了多种标记化方法，一些综述也回顾了该领域的最新进展。然而，现有研究往往专注于特定领域或任务，缺乏对各种基准的统一比较。本文对离散音频标记器进行了系统性的回顾和基准测试，涵盖语音、音乐和通用音频三个领域。我们提出了一种基于编码器-解码器、量化技术、训练范式、流式处理和应用领域的标记化方法分类法。我们在重建、下游性能和声学语言建模等多个基准上评估了标记器，并通过受控消融研究分析了权衡。我们的研究结果突出了关键限制、实际考虑和开放挑战，为这一快速发展领域的未来研究提供了见解和指导。更多信息，包括主要结果和标记器数据库，请访问我们的网站：https://poonehmousavi.github.io/dates-website/。

</details>


### [494] [Fine-Grained control over Music Generation with Activation Steering](https://arxiv.org/abs/2506.10225)
**中文标题：通过激活引导实现音乐生成的细粒度控制**

*Dipanshu Panda,Jayden Koshy Joe,Harshith M R,Swathi Narashiman,Pranay Mathur,Anish Veerakumar,Aniruddh Krishna,Keerthiharan A*

Main category: cs.SD

TL;DR: A method for fine-grained control over music generation by steering activations in MusicGen, enabling timbre, style, and genre adjustments through inference-time interventions.


<details>
  <summary>Details</summary>
Motivation: To achieve precise control over music generation, allowing for modifications like timbre transfer, style transfer, and genre fusion without retraining the model.

Method: Uses inference-time interventions on MusicGen, steering residual stream or attention layer activations via linear probes, framed as a regression task for better directional information preservation.

Result: Improved performance in fine-grained control, combining global text prompts with local activation steering for versatile music generation.

Conclusion: The method successfully provides both global and local control over music generation, enhancing flexibility and precision in music synthesis.

摘要: 我们提出了一种通过推理时干预对自回归生成音乐变换器MusicGen进行细粒度控制的方法。我们的方法通过使用线性探针训练的权重引导残差流，或以类似方式引导注意力层激活，实现了音色转换、风格转换和流派融合。我们发现将其建模为回归任务能提升性能，假设均方误差能更好地保留激活空间中的有意义方向信息。结合MusicGen中文本提示提供的全局条件，我们的方法实现了对音乐生成的全局和局部控制。展示我们方法的音频样本可在演示页面获取。

</details>


### [495] [PAL: Probing Audio Encoders via LLMs -- A Study of Information Transfer from Audio Encoders to LLMs](https://arxiv.org/abs/2506.10423)
**中文标题：PAL：通过大语言模型探测音频编码器——音频编码器到大语言模型的信息传递研究**

*Tony Alex,Wish Suharitdamrong,Sara Atito,Armin Mustafa,Philip J. B. Jackson,Imran Razzak,Muhammad Awais*

Main category: cs.SD

TL;DR: The paper investigates how architectural design choices in audio-LLMs affect the transfer of semantic information from audio encoders to LLMs, proposing modifications that improve performance by 10-60% over baseline.


<details>
  <summary>Details</summary>
Motivation: To explore the under-studied mechanisms of efficient semantic representation transfer from audio encoders to LLMs in Audio-LLMs, focusing on optimizing cross-modal interactions.

Method: The study modifies a standard audio-LLM architecture, testing hypotheses about delayed audio integration, probing via attention submodules, and ensemble audio encoders, using a dataset of 5.6 million audio-text pairs.

Result: Proposed modifications, including delayed audio integration and ensemble encoders, improved performance by 10-60% over baseline, validating the approach.

Conclusion: Optimizing architectural design choices in audio-LLMs significantly enhances cross-modal information transfer, with delayed integration and ensemble encoders proving particularly effective.

摘要: 将音频感知能力整合到大语言模型（LLMs）中，推动了音频-LLMs领域的重大进展。尽管面向应用的开发（特别是在为特定能力如音频推理策划训练数据方面）进展迅速，但从音频编码器到LLMs的丰富语义表征高效传递的底层机制仍未被充分探索。我们将有效的音频-LLM交互概念化为LLM能够熟练探测音频编码器表征以满足文本查询的能力。本文系统地研究了架构设计选择如何影响这一过程。从一个标准的Pengi/LLaVA风格的音频-LLM架构出发，我们提出并评估了几种基于机制可解释性研究和LLM操作原则的修改。实验表明：（1）延迟音频集成直到LLM的初始层建立文本上下文，增强了其探测音频表征以获取相关信息的能力；（2）LLM可以仅通过其注意力子模块熟练探测音频表征，无需传播到其前馈网络（FFN）子模块；（3）高效集成的多样化音频编码器提供了更丰富、互补的表征，从而拓宽了LLM探测更广泛音频信息的能力。所有假设均在一个包含560万音频-文本对的数据集上使用相同的三阶段训练课程进行评估，确保对比的受控性。最终架构整合了所有提出的修改，相对基线实现了10%至60%的性能提升，验证了我们在音频-LLMs中优化跨模态信息传递的方法。项目页面：https://ta012.github.io/PAL/

</details>


### [496] [BNMusic: Blending Environmental Noises into Personalized Music](https://arxiv.org/abs/2506.10754)
**中文标题：BNMusic：将环境噪音融入个性化音乐**

*Chi Zuo,Martin B. Møller,Pablo Martínez-Nuevo,Huayang Huang,Yu Wu,Ye Zhu*

Main category: cs.SD

TL;DR: BNMusic blends environmental noises into personalized music using a two-stage framework to reduce noise noticeability and improve acoustic experiences.


<details>
  <summary>Details</summary>
Motivation: Traditional acoustic masking often requires excessive volume to align sounds. BNMusic aims to blend noises into music more effectively using cross-modal generation.

Method: A two-stage framework: (1) synthesizes music encapsulating noise essence via mel-spectrogram, (2) adaptively amplifies music to enhance blending while preserving quality.

Result: Experiments on MusicBench, EPIC-SOUNDS, and ESC-50 show effective noise blending with rhythmically aligned and enjoyable music.

Conclusion: BNMusic successfully reduces noise noticeability and enhances acoustic experiences through personalized music blending.

摘要: 在受到环境噪音干扰时，传统的声学掩蔽技术试图用其他主导但较少干扰的声音掩盖噪音。然而，主导声音与噪音之间的不匹配（如节奏不一致）通常需要过度增加音量才能实现有效掩蔽。受跨模态生成最新进展的启发，本文提出了一种替代声学掩蔽的方法，旨在通过将噪音融入基于用户提供的文本提示生成的个性化音乐中来降低噪音的显著程度。遵循使用梅尔频谱表示的音乐生成范式，我们提出了一个将噪音融入个性化音乐（BNMusic）的两阶段框架。第一阶段合成一段完整的音乐，其梅尔频谱表示封装了噪音的音乐本质。第二阶段，我们自适应地放大生成的音乐片段，以进一步降低噪音感知并增强融合效果，同时保持听觉质量。在MusicBench、EPIC-SOUNDS和ESC-50上的综合评估实验证明了我们框架的有效性，展示了将环境噪音与节奏对齐、自适应放大且令人愉悦的音乐片段融合的能力，从而最小化噪音的显著程度，提升整体声学体验。

</details>


### [497] [Discrete Audio Tokens: More Than a Survey!](https://arxiv.org/abs/2506.10274)
**中文标题：离散音频标记：不仅仅是一篇综述！**

*Pooneh Mousavi,Gallil Maimon,Adel Moumen,Darius Petermann,Jiatong Shi,Haibin Wu,Haici Yang,Anastasia Kuznetsova,Artem Ploujnikov,Ricard Marxer,Bhuvana Ramabhadran,Benjamin Elizalde,Loren Lugosch,Jinyu Li,Cem Subakan,Phil Woodland,Minje Kim,Hung-yi Lee,Shinji Watanabe,Yossi Adi,Mirco Ravanelli*

Main category: cs.SD

TL;DR: 本文对离散音频标记进行了系统综述和基准测试，涵盖语音、音乐和通用音频三个领域，提出了一种分类法，并评估了多种标记化方法的性能，揭示了关键限制和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着基于标记的音频处理兴趣增长，现有研究多关注特定领域或任务，缺乏统一比较。本文旨在填补这一空白，提供系统综述和基准测试。

Method: 提出了一种基于编码器-解码器、量化技术、训练范式、流式处理和应用领域的标记化方法分类法，并在多个基准上评估了标记化器的重建、下游性能和声学语言建模能力。

Result: 研究发现揭示了离散音频标记化器的关键限制和实际考虑，为未来研究提供了指导。

Conclusion: 本文为离散音频标记化领域的研究提供了系统综述和基准测试，指出了未来研究的开放挑战和方向。

摘要: 离散音频标记是一种紧凑表示，旨在保留感知质量、语音内容和说话人特征，同时实现高效存储和推理，并在多样下游任务中表现优异。它们为连续特征提供了实用替代方案，使语音和音频能够集成到现代大型语言模型（LLMs）中。随着基于标记的音频处理兴趣增长，多种标记化方法涌现，已有几篇综述回顾了该领域的最新进展。然而，现有研究多关注特定领域或任务，缺乏跨多种基准的统一比较。本文对离散音频标记化器进行了系统综述和基准测试，涵盖语音、音乐和通用音频三个领域。我们提出了一种基于编码器-解码器、量化技术、训练范式、流式处理和应用领域的标记化方法分类法。我们在多个基准上评估了标记化器的重建、下游性能和声学语言建模能力，并通过控制消融研究分析了权衡。我们的发现揭示了关键限制、实际考虑和开放挑战，为这一快速发展领域的未来研究提供了见解和指导。更多信息，包括主要结果和标记化器数据库，请访问我们的网站：https://poonehmousavi.github.io/dates-website/。

</details>


### [498] [Fine-Grained control over Music Generation with Activation Steering](https://arxiv.org/abs/2506.10225)
**中文标题：通过激活导向实现音乐生成的细粒度控制**

*Dipanshu Panda,Jayden Koshy Joe,Harshith M R,Swathi Narashiman,Pranay Mathur,Anish Veerakumar,Aniruddh Krishna,Keerthiharan A*

Main category: cs.SD

TL;DR: 本文提出了一种通过干预自回归生成音乐模型MusicGen的推理过程，实现对音乐生成的细粒度控制的方法。该方法支持音色转换、风格转换和流派融合。


<details>
  <summary>Details</summary>
Motivation: 音乐生成模型通常缺乏对生成内容的细粒度控制，限制了其在实际应用中的灵活性。本文旨在通过干预模型的推理过程，提供更精细的控制能力。

Method: 通过在MusicGen模型的残差流或注意力层激活上进行干预，利用线性探针权重或类似方法实现控制。将任务建模为回归问题，以均方误差保留激活空间中的方向信息。

Result: 实验表明，该方法能够有效实现音色、风格和流派的控制，并结合文本提示提供全局和局部的音乐生成控制。

Conclusion: 本文提出的方法为音乐生成提供了细粒度的控制能力，结合全局文本提示，实现了更灵活的音乐创作。

摘要: 我们提出了一种通过干预自回归生成音乐模型MusicGen的推理过程，实现对音乐生成的细粒度控制的方法。该方法支持音色转换、风格转换和流派融合，通过使用在残差流上训练的线性探针权重或类似方法导向注意力层激活来实现。我们发现，将任务建模为回归问题能够提升性能，假设均方误差能更好地保留激活空间中的有意义方向信息。结合MusicGen中文本提示提供的全局条件，我们的方法实现了对音乐生成的全局和局部控制。演示页面提供了展示我们方法的音频样本。

</details>


### [499] [PAL: Probing Audio Encoders via LLMs -- A Study of Information Transfer from Audio Encoders to LLMs](https://arxiv.org/abs/2506.10423)
**中文标题：PAL：通过LLMs探测音频编码器——音频编码器到LLMs的信息传递研究**

*Tony Alex,Wish Suharitdamrong,Sara Atito,Armin Mustafa,Philip J. B. Jackson,Imran Razzak,Muhammad Awais*

Main category: cs.SD

TL;DR: 本文研究了如何通过LLMs高效地从音频编码器提取语义信息，提出了三种改进架构设计的方法，并在实验中验证了其有效性，最终模型性能提升了10%至60%。


<details>
  <summary>Details</summary>
Motivation: 尽管音频-LLMs在应用层面取得了进展，但音频编码器与LLMs之间高效信息传递的机制尚未充分探索。本文旨在通过系统研究架构设计选择，优化音频编码器与LLMs的交互。

Method: 从标准Pengi/LLaVA架构出发，提出了三种改进：延迟音频集成、仅通过注意力子模块探测音频表示、集成多样音频编码器。所有假设在560万音频-文本对数据集上通过三阶段训练验证。

Result: 实验表明：（1）延迟音频集成能提升LLMs对音频信息的探测能力；（2）仅通过注意力子模块即可高效探测音频表示；（3）集成多样编码器能提供更丰富的音频信息。最终模型性能提升10%-60%。

Conclusion: 通过优化架构设计，本文显著提升了音频-LLMs中跨模态信息传递的效率，为未来研究提供了重要参考。

摘要: 将音频感知能力整合到大型语言模型（LLMs）中推动了音频-LLMs的显著进展。尽管应用层面的发展（例如针对音频推理等特定能力的数据整理）进展迅速，但音频编码器向LLMs高效传递丰富语义表示的底层机制仍未被充分探索。我们将有效的音频-LLM交互概念化为LLM能够熟练探测音频编码器表示以满足文本查询的能力。本文系统地研究了架构设计选择如何影响这一能力。从标准的Pengi/LLaVA风格音频-LLM架构出发，我们提出并评估了基于机制可解释性研究和LLM操作原则假设的多种改进。实验表明：（1）延迟音频集成直到LLM的初始层建立文本上下文，能增强其对音频表示中相关信息的探测能力；（2）LLM仅通过其注意力子模块即可熟练探测音频表示，无需传播到前馈网络（FFN）子模块；（3）高效集成的多样音频编码器提供了更丰富、互补的表示，从而拓宽了LLM探测更广泛音频信息的能力。所有假设均在560万音频-文本对数据集上通过相同的三阶段训练课程进行评估，确保对比可控。最终架构整合了所有改进，性能相对基线提升了10%至60%，验证了我们优化音频-LLMs中跨模态信息传递的方法。项目页面：https://ta012.github.io/PAL/

</details>


### [500] [BNMusic: Blending Environmental Noises into Personalized Music](https://arxiv.org/abs/2506.10754)
**中文标题：BNMusic：将环境噪音融入个性化音乐**

*Chi Zuo,Martin B. Møller,Pablo Martínez-Nuevo,Huayang Huang,Yu Wu,Ye Zhu*

Main category: cs.SD

TL;DR: 本文提出了一种名为BNMusic的新方法，通过将环境噪音融入个性化音乐中，减少噪音的感知，从而提升听觉体验。该方法利用文本提示生成音乐，并通过自适应放大进一步优化噪音掩盖效果。


<details>
  <summary>Details</summary>
Motivation: 传统的声音掩盖技术通常需要增加音量来掩盖噪音，但效果有限且可能造成听觉不适。本文受跨模态生成技术的启发，提出了一种更自然的方法，通过将噪音融入个性化音乐中，减少噪音的感知。

Method: BNMusic框架分为两个阶段：首先，基于用户提供的文本提示生成一段完整的音乐，其频谱图表示包含噪音的音乐特征；其次，自适应放大生成的音乐片段，进一步减少噪音感知并保持听觉质量。

Result: 在MusicBench、EPIC-SOUNDS和ESC-50数据集上的实验表明，BNMusic能够有效将环境噪音与节奏对齐、自适应放大的音乐片段融合，显著减少噪音的感知。

Conclusion: BNMusic提供了一种新颖且有效的方法，通过将噪音融入个性化音乐中，改善了整体听觉体验，避免了传统掩盖技术的高音量需求。

摘要: 在受到环境噪音干扰时，传统的声学掩盖技术试图通过其他主导但较少干扰的声音来掩盖噪音。然而，主导声音与噪音之间的不匹配（如节奏不一致）通常需要增加音量才能实现有效掩盖。受跨模态生成技术的最新进展启发，本文提出了一种替代方法，旨在通过将噪音融入基于用户提供的文本提示生成的个性化音乐中，减少噪音的感知。遵循使用频谱图表示生成音乐的范式，我们提出了一个名为“将噪音融入个性化音乐”（BNMusic）的框架，包含两个关键阶段。第一阶段合成一段完整的音乐，其频谱图表示封装了噪音的音乐特征。第二阶段，我们自适应放大生成的音乐片段，进一步减少噪音感知并增强融合效果，同时保持听觉质量。在MusicBench、EPIC-SOUNDS和ESC-50上的综合评估实验证明了我们框架的有效性，展示了其能够将环境噪音与节奏对齐、自适应放大且令人愉悦的音乐片段融合，最小化噪音的感知，从而改善整体听觉体验。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [501] [Semantic Communication-Enabled Cloud-Edge-End-collaborative Metaverse Services Architecure](https://arxiv.org/abs/2506.10001)
**中文标题：基于语义通信的云-边-端协同元宇宙服务架构**

*Yuxuan Li,Sheng Jinag,Bizhu Wang*

Main category: cs.MM

TL;DR: The paper proposes a semantic communication-enabled architecture (SC-CEE-Meta) to improve metaverse services by reducing latency and enhancing image quality through cloud-edge-end collaboration.


<details>
  <summary>Details</summary>
Motivation: The metaverse faces challenges like high data transmission demands and poor wireless channel quality, leading to latency and degraded user experience.

Method: The SC-CEE-Meta architecture includes VR video semantic transmission, video synthesis, and 3D scene reconstruction modules, leveraging semantic communication to reduce data transmission and improve efficiency.

Result: The architecture reduces wireless transmission delay by 96.05% and improves image quality by 43.99% under poor channel conditions, as tested on Meta Quest Pro.

Conclusion: The SC-CEE-Meta architecture effectively addresses metaverse service challenges by optimizing data transmission and enhancing user experience through semantic communication and cloud-edge-end collaboration.

摘要: 随着技术进步和对新视听体验的追求增强，元宇宙获得了越来越多的热情。然而，由于高分辨率虚拟场景等大量数据需要在云平台和VR设备之间传输，它面临着实际障碍。具体而言，VR设备的无线传输因带宽不足而受到阻碍，导致速度和延迟问题。同时，信道质量差会导致数据错误并恶化用户体验。为解决这一问题，我们提出了基于语义通信的云-边-端协同沉浸式元宇宙服务（SC-CEE-Meta）架构，包括VR视频语义传输、视频合成和3D虚拟场景重建三个模块。通过在VR设备和边缘服务器上部署语义模块并发送关键语义信息而非专注于比特级重建，可以降低延迟、解决资源与带宽冲突，并更好地抵御信道干扰。此外，云端部署视频合成和3D场景重建预处理，而边缘设备托管3D重建渲染模块，共同提供沉浸式服务。在Meta Quest Pro上验证，SC-CEE-Meta可以在信道条件差的情况下将无线传输延迟降低96.05%，并将图像质量提升43.99%。

</details>


### [502] [EQ-TAA: Equivariant Traffic Accident Anticipation via Diffusion-Based Accident Video Synthesis](https://arxiv.org/abs/2506.10002)
**中文标题：EQ-TAA：基于扩散的事故视频合成的等变交通事故预测**

*Jianwu Fang,Lei-Lei Li,Zhedong Zheng,Hongkai Yu,Jianru Xue,Zhengguo Li,Tat-Seng Chua*

Main category: cs.MM

TL;DR: The paper proposes EQ-TAA, a method for traffic accident anticipation using a diffusion-based model to synthesize accident videos, addressing data bias and improving prediction accuracy.


<details>
  <summary>Details</summary>
Motivation: Current traffic accident anticipation methods suffer from data bias and annotation challenges due to the uncertain and fast-evolving nature of traffic scenes. The paper aims to overcome these issues by generating synthetic accident videos to enhance model training.

Method: The authors introduce an Attentive Video Diffusion (AVD) model to synthesize accident video clips from normal ones, preserving content and style. EQ-TAA uses an equivariant triple loss with generated pseudo-normal and pseudo-accident clips for training.

Result: Experiments show competitive performance of AVD and EQ-TAA compared to state-of-the-art methods, validating the effectiveness of synthetic data in improving accident anticipation.

Conclusion: The proposed EQ-TAA framework, leveraging synthetic accident videos, effectively addresses data bias and improves traffic accident anticipation performance without requiring additional annotations.

摘要: 交通场景中的交通事故预测（TAA）是实现未来零死亡的一项具有挑战性的问题。当前方法通常将TAA视为需要费力标注事故持续时间的监督学习任务。然而，交通场景固有的长尾性、不确定性和快速演变特性导致事故的真实因果部分难以识别，且容易被数据偏差主导，从而产生背景混淆问题。为此，我们提出了一种注意力视频扩散（AVD）模型，通过生成行车记录仪视频中的因果部分（即从正常片段到事故片段）来合成额外的事故视频片段。AVD旨在基于事故或无事故文本提示生成因果视频帧，同时在视频生成后保留帧的风格和内容以用于TAA。这种方法可以使用从各种驾驶场景收集的数据集进行训练，无需任何额外标注。此外，AVD通过等变三重损失促进了一种等变TAA（EQ-TAA），该损失针对锚定无事故视频片段以及生成的对比伪正常和伪事故片段对。大量实验已用于评估AVD和EQ-TAA的性能，并获得了与最先进方法相比具有竞争力的性能。

</details>


### [503] [Immersive Multimedia Communication: State-of-the-Art on eXtended Reality Streaming](https://arxiv.org/abs/2506.10004)
**中文标题：沉浸式多媒体通信：扩展现实流媒体的最新进展**

*Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

Main category: cs.MM

TL;DR: The paper surveys state-of-the-art XR streaming, covering definitions, hardware, traffic characteristics, quality of experience factors, optimization methods, and current applications, while highlighting challenges for future development.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive review of XR streaming advancements, addressing its unique requirements and challenges to enhance user experience and guide future research.

Method: The paper defines XR, introduces hardware and interaction methods, analyzes traffic characteristics, explores quality of experience factors, and presents optimization techniques based on visual attention.

Result: The survey identifies key elements for improving XR streaming efficiency and user satisfaction, along with current applications and unresolved challenges.

Conclusion: XR streaming is evolving rapidly, with significant potential for revolutionizing content consumption, but requires further research to address technical and experiential challenges.

摘要: 扩展现实（XR）正在迅速发展，并有望彻底改变内容的创建和消费方式。在XR中，用户通过整合多种感官输入来形成对虚拟环境的统一感知。本文综述了XR流媒体的最新进展，重点关注多种范式。首先，我们定义了XR并介绍了各种XR头显及其多模态交互方法，以提供基础理解。接着，我们分析了XR流量的特征，以突出其独特的数据传输需求。我们还探讨了影响XR系统体验质量的因素，旨在确定提升用户满意度的关键要素。随后，我们提出了基于视觉注意力的XR流媒体优化方法，以提高效率和性能。最后，我们研究了当前的应用并强调了挑战，为XR的持续和未来发展提供见解。

</details>


### [504] [HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction](https://arxiv.org/abs/2506.10006)
**中文标题：通过动态双向重建实现灵活多模态输入的HER2表达预测**

*Jie Qin,Wei Yang,Yan Su,Yiran Zhu,Weizhen Li,Yunyue Pan,Chengchang Pan,Honggang Qi*

Main category: cs.MM

TL;DR: The paper proposes a dynamic bimodal framework for HER2 prediction in breast cancer, enabling flexible single- or dual-modality analysis with improved accuracy and cost efficiency.


<details>
  <summary>Details</summary>
Motivation: Current HER2 assessment models analyze H&E or IHC images separately, missing the clinical benefit of their combined interpretation. The complexity and cost of acquiring both modalities simultaneously limit practical use.

Method: The framework includes a dynamic branch selector, a bidirectional cross-modal GAN for feature-space reconstruction, and a hybrid training protocol. It adapts to single- or dual-modality inputs.

Result: The model improves single-modality H&E accuracy from 71.44% to 94.25%, achieves 95.09% dual-modality accuracy, and maintains 90.28% reliability with IHC-only inputs. Cross-modal reconstruction enhances F1-scores.

Conclusion: The framework democratizes precise HER2 assessment by reducing reliance on synchronized acquisition, benefiting resource-limited settings.

摘要: 目前乳腺癌的HER2评估模型主要单独分析H&E或IHC图像，尽管临床依赖它们的协同解释。然而，同时获取这两种模态常因工作流程复杂性和成本限制而受阻。我们提出了一种自适应双模态框架，通过三项创新实现灵活的单/双模态HER2预测：1）动态分支选择器，根据输入完整性激活单模态重建或双模态联合推断；2）双向跨模态GAN，执行缺失模态的上下文感知特征空间重建；3）结合对抗学习和多任务优化的混合训练协议。该架构将单模态H&E预测准确率从71.44%提升至94.25%，同时实现95.09%的双模态准确率，并在仅使用IHC输入时保持90.28%的可靠性。框架的“双模态优先，单模态兼容”设计在不需同步采集的情况下提供接近双模态的性能，尤其通过减少IHC基础设施成本使资源有限的环境受益。实验验证显示，与H&E/IHC基线相比，准确率分别提高了22.81%/12.90%，跨模态重建将F1分数提升至0.9609（HE到IHC）和0.9251（IHC到HE）。通过动态将输入路由至重建增强或原生融合路径，系统减轻了因数据缺失导致的性能下降，同时保持了计算效率（轻量级变体参数减少78.55%）。这种弹性架构展示了在多样化医疗环境中普及精确HER2评估的巨大潜力。

</details>


### [505] [Controllable Expressive 3D Facial Animation via Diffusion in a Unified Multimodal Space](https://arxiv.org/abs/2506.10007)
**中文标题：基于统一多模态空间中扩散的可控表达性3D面部动画**

*Kangwei Liu,Junwu Liu,Xiaowei Yi,Jinlin Guo,Yun Cao*

Main category: cs.MM

TL;DR: A diffusion-based framework for expressive 3D facial animation that leverages multimodal signals (text, audio, emotion labels) and an attention-based latent diffusion model to improve emotion similarity and motion diversity.


<details>
  <summary>Details</summary>
Motivation: Addressing the limitations of single-modal control signals and deterministic regression-based mapping in audio-driven emotional 3D facial animation, which restrict expressiveness and flexibility.

Method: Introduces a FLAME-centered multimodal emotion binding strategy and an attention-based latent diffusion model with content-aware attention and emotion-guided layers.

Result: Outperforms existing methods with a 21.6% improvement in emotion similarity while maintaining natural facial dynamics.

Conclusion: The proposed framework enables flexible and expressive 3D facial animation by leveraging multimodal signals and diffusion-based modeling.

摘要: 音频驱动的情绪化3D面部动画面临两大挑战：(1) 依赖单模态控制信号（视频、文本或情绪标签）而未能利用其互补优势以实现全面的情绪操控；(2) 确定性回归映射限制了情绪表达和非语言行为的随机性，从而限制了合成动画的表现力。为解决这些问题，我们提出了一种基于扩散的可控表达性3D面部动画框架。我们的方法包含两大创新：(1) 一种以FLAME为中心的多模态情绪绑定策略，通过对比学习对齐文本、音频和情绪标签等多样化模态，实现从多信号源的灵活情绪控制；(2) 一种基于注意力的潜在扩散模型，具有内容感知注意力和情绪引导层，在保持时间连贯性和自然面部动态的同时丰富了运动多样性。大量实验表明，我们的方法在多数指标上优于现有方法，情绪相似性提高了21.6%，同时保持了生理上合理的面部动态。项目页面：https://kangweiiliu.github.io/Control_3D_Animation。

</details>


### [506] [Structured Graph Representations for Visual Narrative Reasoning: A Hierarchical Framework for Comics](https://arxiv.org/abs/2506.10008)
**中文标题：视觉叙事推理的结构化图表示：漫画的分层框架**

*Yi-Chun Chen*

Main category: cs.MM

TL;DR: The paper introduces a hierarchical knowledge graph framework for analyzing visual narratives like comics, decomposing content into multiple levels and integrating semantic, spatial, and temporal relationships. It demonstrates high precision in tasks like action retrieval and dialogue tracing.


<details>
  <summary>Details</summary>
Motivation: To address the need for structured understanding of visual narratives, especially in multimodal media like comics, by capturing complex relationships between visual and textual elements.

Method: Proposes a hierarchical framework that decomposes narratives into macro-level story arcs and fine-grained event segments, represented through integrated knowledge graphs. Multimodal graphs link visual and textual components at the panel level.

Result: Applied to the Manga109 dataset, the framework achieved high precision and recall in tasks such as action retrieval, dialogue tracing, character appearance mapping, and panel timeline reconstruction.

Conclusion: The framework provides a scalable foundation for narrative-based content analysis, interactive storytelling, and multimodal reasoning in visual media.

摘要: 本文提出了一种分层知识图谱框架，用于结构化理解视觉叙事，特别是如漫画等多模态媒体。该方法将叙事内容分解为多个层次，从宏观故事线到细粒度事件片段，并通过集成知识图谱捕捉语义、空间和时间关系。在面板层面，我们构建了多模态图，将视觉元素（如角色、物体和动作）与相应的文本组件（如对话和字幕）联系起来。这些图在叙事层次上集成，支持对故事结构、角色连续性和事件进展的推理。我们将该方法应用于手动标注的Manga109数据集子集，并展示了其在多样化叙事任务中的符号推理能力，包括动作检索、对话追踪、角色出场映射和面板时间线重建。评估结果显示，该框架在各项任务中具有高精度和高召回率，验证了其一致性和可解释性。这项工作为基于叙事的视觉媒体内容分析、交互式叙事和多模态推理提供了可扩展的基础。

</details>


### [507] [WDMIR: Wavelet-Driven Multimodal Intent Recognition](https://arxiv.org/abs/2506.10011)
**中文标题：WDMIR：基于小波驱动的多模态意图识别**

*Weiyin Gong,Kai Zhang,Yanghai Zhang,Qi Liu,Xinjie Sun,Junyu Lu,Linbo Zhu*

Main category: cs.MM

TL;DR: The paper introduces WDMIR, a wavelet-driven framework for multimodal intent recognition, enhancing accuracy by analyzing non-verbal cues in the frequency domain.


<details>
  <summary>Details</summary>
Motivation: Existing intent recognition methods focus on text analysis, neglecting non-verbal cues. WDMIR aims to bridge this gap by leveraging frequency-domain analysis for richer semantic understanding.

Method: Proposes a wavelet-driven fusion module for synchronized video-audio feature decomposition and a cross-modal interaction mechanism for progressive feature enhancement from bimodal to trimodal integration.

Result: Achieves state-of-the-art performance with a 1.13% accuracy improvement on MIntRec. The wavelet-driven module boosts recognition accuracy by 0.41% for subtle emotional cues.

Conclusion: WDMIR effectively integrates verbal and non-verbal information, demonstrating superior performance in multimodal intent recognition.

摘要: 多模态意图识别（MIR）旨在通过整合视频、音频和文本模态中的言语和非言语信息来准确解读用户意图。现有方法侧重于文本分析，往往忽略了非言语线索中丰富的语义内容。本文提出了一种新颖的基于小波驱动的多模态意图识别（WDMIR）框架，通过对非言语信息进行频域分析来增强意图理解。具体而言，我们提出：（1）一个小波驱动的融合模块，在频域中对视频-音频特征进行同步分解和整合，实现对时间动态的细粒度分析；（2）一种跨模态交互机制，促进从双模态到三模态的渐进特征增强，有效弥合言语和非言语信息之间的语义鸿沟。在MIntRec上的大量实验表明，我们的方法实现了最先进的性能，准确率比之前的方法提高了1.13%。消融研究进一步验证了小波驱动融合模块显著提升了从非言语源中提取语义信息的能力，在分析细微情感线索时识别准确率提高了0.41%。

</details>


### [508] [Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2506.10016)
**中文标题：多模态大型语言模型综述**

*Longzhen Han,Awes Mubarak,Almas Baimagambetov,Nikolaos Polatidis,Thar Baker*

Main category: cs.MM

TL;DR: The survey explores the evolution of Multimodal Large Language Models (MLLMs), categorizing six generative modalities and analyzing foundational techniques enabling cross-modal capabilities. It highlights architectural trends, synergies, and unresolved challenges in MLLM development.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide a unified perspective on the rapid advancements in MLLMs, which now span diverse output modalities beyond text, and to identify key techniques and challenges in achieving cross-modal capabilities.

Method: The method involves categorizing six primary generative modalities and examining foundational techniques like SSL, MoE, RLHF, and CoT prompting. It analyzes key models, architectural trends, and emergent cross-modal synergies.

Result: The survey identifies architectural innovations (e.g., transformers, diffusion models) enabling cross-modal transfer and modular specialization, while highlighting open challenges in evaluation, modularity, and structured reasoning.

Conclusion: The conclusion emphasizes the need for more general-purpose, adaptive, and interpretable multimodal systems, offering a unified view of MLLM development and critical future directions.

摘要: 多模态大型语言模型（MLLMs）已迅速超越文本生成，通过将语言与其他感官模态在统一架构下整合，现涵盖图像、音乐、视频、人体运动和3D对象等多种输出模态。本综述分类了六种主要生成模态，并探讨了自监督学习（SSL）、专家混合（MoE）、人类反馈强化学习（RLHF）和思维链（CoT）提示等基础技术如何实现跨模态能力。我们分析了关键模型、架构趋势和新兴的跨模态协同效应，同时强调了可转移技术和未解决的挑战。诸如变压器和扩散模型等架构创新支撑了这一融合，实现了跨模态转移和模块化专业化。我们突出了新兴的协同模式，并指出了评估、模块化和结构化推理方面的开放挑战。本综述提供了对MLLM发展的统一视角，并确定了实现更通用、自适应和可解释的多模态系统的关键路径。

</details>


### [509] [Semantic Communication-Enabled Cloud-Edge-End-collaborative Metaverse Services Architecure](https://arxiv.org/abs/2506.10001)
**中文标题：基于语义通信的云-边-端协同元宇宙服务架构**

*Yuxuan Li,Sheng Jinag,Bizhu Wang*

Main category: cs.MM

TL;DR: 提出了一种基于语义通信的云-边-端协同元宇宙服务架构（SC-CEE-Meta），通过语义传输、视频合成和3D场景重建模块，显著降低延迟并提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 元宇宙服务面临高分辨率虚拟场景数据传输的带宽不足和延迟问题，以及信道质量差导致的数据错误，亟需一种高效解决方案。

Method: 设计了SC-CEE-Meta架构，包含VR视频语义传输、视频合成和3D虚拟场景重建模块，通过语义通信减少数据传输量，并在云端和边缘设备上部署预处理和渲染模块。

Result: 在Meta Quest Pro上验证，SC-CEE-Meta可将无线传输延迟降低96.05%，并在信道条件差时提升图像质量43.99%。

Conclusion: SC-CEE-Meta架构通过语义通信和云-边-端协同，有效解决了元宇宙服务中的带宽和延迟问题，提升了用户体验。

摘要: 随着技术进步和对新视听体验的追求，元宇宙获得了越来越多的关注。然而，由于高分辨率虚拟场景等大量数据需要在云平台和VR设备之间传输，实际应用中面临诸多挑战。具体而言，VR设备的无线传输受限于带宽不足，导致速度和延迟问题。同时，信道质量差会导致数据错误，进一步恶化用户体验。为解决这些问题，我们提出了基于语义通信的云-边-端协同沉浸式元宇宙服务（SC-CEE-Meta）架构，包含三个模块：VR视频语义传输、视频合成和3D虚拟场景重建。通过在VR设备和边缘服务器上部署语义模块，并传输关键语义信息而非专注于比特级重建，可以降低延迟，解决资源与带宽冲突，并更好地抵御信道干扰。此外，云端部署视频合成和3D场景重建预处理，边缘设备则负责3D重建渲染模块，共同提供沉浸式服务。在Meta Quest Pro上的验证表明，SC-CEE-Meta可在信道条件差的情况下将无线传输延迟降低96.05%，并将图像质量提升43.99%。

</details>


### [510] [EQ-TAA: Equivariant Traffic Accident Anticipation via Diffusion-Based Accident Video Synthesis](https://arxiv.org/abs/2506.10002)
**中文标题：EQ-TAA：基于扩散模型的事故视频合成的等变交通事故预测**

*Jianwu Fang,Lei-Lei Li,Zhedong Zheng,Hongkai Yu,Jianru Xue,Zhengguo Li,Tat-Seng Chua*

Main category: cs.MM

TL;DR: 本文提出了一种基于扩散模型的事故视频合成方法（AVD）和等变交通事故预测框架（EQ-TAA），通过生成因果视频帧解决数据偏差问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 交通场景中的事故预测（TAA）面临数据偏差和因果部分难以识别的问题，现有方法依赖繁琐的注释且易受背景干扰。

Method: 提出AVD模型，通过文本提示生成因果视频帧，合成额外事故视频片段；并设计EQ-TAA框架，利用等变三重损失进行对比学习。

Result: 实验表明，AVD和EQ-TAA在性能上优于现有方法，解决了数据偏差问题。

Conclusion: AVD和EQ-TAA为交通事故预测提供了一种无需额外标注的高效解决方案，具有实际应用潜力。

摘要: 交通场景中的事故预测（TAA）是实现未来零死亡目标的一项挑战性任务。现有方法通常将TAA视为需要繁琐标注的监督学习任务，但交通场景的长尾性、不确定性和快速变化性导致事故的真实因果部分难以识别，且易受数据偏差影响，从而引发背景干扰问题。为此，我们提出了一种注意力视频扩散（AVD）模型，通过生成因果部分（即从正常片段到事故片段）合成额外的事故视频片段。AVD旨在基于事故或无事故的文本提示生成因果视频帧，同时在视频生成后保留帧的风格和内容以用于TAA。该方法无需额外标注即可利用来自不同驾驶场景的数据集进行训练。此外，AVD支持等变TAA（EQ-TAA），通过等变三重损失结合锚定无事故视频片段与生成的对比伪正常和伪事故片段对。大量实验评估了AVD和EQ-TAA的性能，结果表明其性能优于现有方法。

</details>


### [511] [Immersive Multimedia Communication: State-of-the-Art on eXtended Reality Streaming](https://arxiv.org/abs/2506.10004)
**中文标题：沉浸式多媒体通信：扩展现实流媒体的最新技术综述**

*Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

Main category: cs.MM

TL;DR: 本文综述了扩展现实（XR）流媒体的最新技术，包括XR定义、设备、数据传输需求、用户体验优化方法及当前应用与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着XR技术的快速发展，其在内容创作和消费领域的潜力巨大。本文旨在全面梳理XR流媒体的现状，为未来研究提供参考。

Method: 通过定义XR并介绍相关设备及交互方式，分析XR流量特性，探讨影响用户体验的因素，并提出基于视觉注意力的优化方法。

Result: 总结了XR流媒体的关键技术、优化方法及当前应用，同时指出了未来发展的挑战。

Conclusion: XR流媒体技术前景广阔，但仍需解决数据传输和用户体验优化等挑战，以推动其进一步发展。

摘要: 扩展现实（XR）技术正在快速发展，并有望彻底改变内容的创作与消费方式。在XR中，用户通过整合多种感官输入形成对虚拟环境的统一感知。本文综述了XR流媒体的最新技术，重点关注多种范式。首先，我们定义了XR并介绍了各类XR头显及其多模态交互方法，以提供基础理解。接着，我们分析了XR流量的特性，突出其独特的数据传输需求。此外，我们还探讨了影响XR系统体验质量的因素，旨在识别提升用户满意度的关键要素。随后，我们提出了基于视觉注意力的XR流媒体优化方法，以提高效率和性能。最后，我们审视了当前应用并指出了挑战，为XR的持续和未来发展提供了见解。

</details>


### [512] [HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction](https://arxiv.org/abs/2506.10006)
**中文标题：通过动态双向重建实现灵活多模态输入的HER2表达预测**

*Jie Qin,Wei Yang,Yan Su,Yiran Zhu,Weizhen Li,Yunyue Pan,Chengchang Pan,Honggang Qi*

Main category: cs.MM

TL;DR: 本文提出了一种动态双向重建的灵活多模态输入框架，用于HER2表达预测，显著提升单/双模态输入的准确性，同时降低资源需求。


<details>
  <summary>Details</summary>
Motivation: 当前HER2评估模型主要依赖单一模态（H&E或IHC）图像分析，而临床实践中需要多模态协同解释。但由于工作流程复杂性和成本限制，同时获取多模态数据困难。本文旨在解决这一问题。

Method: 1) 动态分支选择器根据输入完整性激活单模态重建或双模态联合推理；2) 双向跨模态GAN实现缺失模态的上下文感知特征空间重建；3) 混合训练协议结合对抗学习和多任务优化。

Result: 单模态H&E预测准确率从71.44%提升至94.25%，双模态准确率达95.09%，仅IHC输入时可靠性为90.28%。跨模态重建显著提升F1分数（HE到IHC为0.9609，IHC到HE为0.9251）。

Conclusion: 该弹性框架在不需同步获取多模态数据的情况下，实现了接近双模态的性能，显著降低了资源需求，为不同医疗环境下的HER2精准评估提供了潜力。

摘要: 目前针对乳腺癌的HER2评估模型主要独立分析H&E或IHC图像，尽管临床实践中依赖它们的协同解释。然而，同时获取这两种模态常因工作流程复杂性和成本限制而受阻。我们提出了一种自适应双模态框架，通过三项创新实现灵活的单/双模态HER2预测：1) 动态分支选择器根据输入完整性激活单模态重建或双模态联合推理；2) 双向跨模态GAN执行缺失模态的上下文感知特征空间重建；3) 混合训练协议结合对抗学习和多任务优化。该架构将单模态H&E预测准确率从71.44%提升至94.25%，同时双模态准确率达95.09%，仅IHC输入时可靠性为90.28%。框架的“双模态优先，单模态兼容”设计在不需同步获取的情况下实现了接近双模态的性能，尤其通过降低IHC基础设施成本惠及资源有限的环境。实验验证表明，相比H&E/IHC基线，准确率分别提升22.81%/12.90%，跨模态重建将F1分数提升至0.9609（HE到IHC）和0.9251（IHC到HE）。通过动态路由输入至重建增强或原生融合路径，系统缓解了数据缺失导致的性能下降，同时保持了计算效率（轻量级变体参数减少78.55%）。这一弹性架构展现了在不同医疗环境下普及精准HER2评估的显著潜力。

</details>


### [513] [Controllable Expressive 3D Facial Animation via Diffusion in a Unified Multimodal Space](https://arxiv.org/abs/2506.10007)
**中文标题：基于统一多模态空间中扩散的可控表达3D面部动画**

*Kangwei Liu,Junwu Liu,Xiaowei Yi,Jinlin Guo,Yun Cao*

Main category: cs.MM

TL;DR: 本文提出了一种基于扩散模型的可控表达3D面部动画框架，通过多模态情感绑定和注意力潜扩散模型，解决了现有方法依赖单模态信号和确定性映射的问题，显著提升了情感相似性和动画表现力。


<details>
  <summary>Details</summary>
Motivation: 音频驱动的3D面部动画面临两大挑战：一是依赖单模态控制信号（如视频、文本或情感标签），未能充分利用多模态的互补性；二是确定性回归映射限制了情感表达和非语言行为的随机性，导致动画表现力不足。

Method: 方法包括：(1) 基于FLAME的多模态情感绑定策略，通过对比学习对齐文本、音频和情感标签，实现多信号源的灵活情感控制；(2) 注意力潜扩散模型，结合内容感知注意力和情感引导层，增强运动多样性并保持时间连贯性和自然面部动态。

Result: 实验表明，该方法在多数指标上优于现有方法，情感相似性提升21.6%，同时保持了生理合理的面部动态。

Conclusion: 本文提出的框架通过多模态情感绑定和扩散模型，显著提升了3D面部动画的表达力和可控性，为情感驱动的动画合成提供了新思路。

摘要: 音频驱动的情绪化3D面部动画面临两大挑战：(1) 依赖单模态控制信号（视频、文本或情感标签），未能充分利用其互补性以实现全面的情绪操控；(2) 确定性回归映射限制了情绪表达和非语言行为的随机性，导致合成动画的表现力不足。为解决这些问题，我们提出了一种基于扩散模型的可控表达3D面部动画框架。我们的方法包含两项关键创新：(1) 以FLAME为中心的多模态情感绑定策略，通过对比学习对齐文本、音频和情感标签，实现多信号源的灵活情绪控制；(2) 基于注意力的潜扩散模型，结合内容感知注意力和情感引导层，在保持时间连贯性和自然面部动态的同时，丰富了运动多样性。大量实验表明，我们的方法在多数指标上优于现有方法，情感相似性提升了21.6%，同时保持了生理合理的面部动态。项目页面：https://kangweiiliu.github.io/Control_3D_Animation。

</details>


### [514] [Structured Graph Representations for Visual Narrative Reasoning: A Hierarchical Framework for Comics](https://arxiv.org/abs/2506.10008)
**中文标题：视觉叙事推理的结构化图表示：一种用于漫画的分层框架**

*Yi-Chun Chen*

Main category: cs.MM

TL;DR: 本文提出了一种分层知识图谱框架，用于结构化理解视觉叙事（如漫画），通过多模态图谱捕捉语义、空间和时间关系，支持叙事推理任务。


<details>
  <summary>Details</summary>
Motivation: 视觉叙事（如漫画）包含复杂的多模态信息，传统方法难以有效捕捉其层次结构和关系。本文旨在通过分层知识图谱框架，实现对叙事内容的结构化理解和推理。

Method: 提出了一种分层知识图谱框架，将叙事内容分解为从宏观故事弧到细粒度事件片段的多层次结构，并通过多模态图谱整合视觉元素（如角色、物体、动作）和文本组件（如对话、字幕）。

Result: 在Manga109数据集的手动标注子集上验证了框架的有效性，结果显示其在动作检索、对话追踪、角色出场映射和面板时间线重建等任务中具有高精度和召回率。

Conclusion: 该框架为基于叙事的视觉内容分析、交互式故事讲述和多模态推理提供了可扩展的基础，验证了其一致性和可解释性。

摘要: 本文提出了一种分层知识图谱框架，用于结构化理解视觉叙事（如漫画）。该方法将叙事内容分解为多个层次，从宏观故事弧到细粒度事件片段，并通过整合的知识图谱捕捉语义、空间和时间关系。在面板级别，我们构建了多模态图谱，将视觉元素（如角色、物体和动作）与文本组件（如对话和字幕）关联起来。这些图谱在叙事层次上整合，以支持对故事结构、角色连续性和事件进展的推理。

我们将该方法应用于Manga109数据集的手动标注子集，并展示了其在多样化叙事任务中的符号推理能力，包括动作检索、对话追踪、角色出场映射和面板时间线重建。评估结果显示，框架在各项任务中具有高精度和召回率，验证了其一致性和可解释性。这项工作为基于叙事的视觉内容分析、交互式故事讲述和多模态推理提供了可扩展的基础。

</details>


### [515] [WDMIR: Wavelet-Driven Multimodal Intent Recognition](https://arxiv.org/abs/2506.10011)
**中文标题：WDMIR：基于小波驱动的多模态意图识别**

*Weiyin Gong,Kai Zhang,Yanghai Zhang,Qi Liu,Xinjie Sun,Junyu Lu,Linbo Zhu*

Main category: cs.MM

TL;DR: 本文提出了一种基于小波变换的多模态意图识别框架（WDMIR），通过频域分析提升非语言信息的语义理解，显著提高了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法多侧重于文本分析，忽视了非语言信息中的丰富语义内容，本文旨在通过频域分析填补这一空白。

Method: 1. 提出小波驱动的融合模块，在频域同步分解和整合视频-音频特征；2. 设计跨模态交互机制，逐步增强从双模态到三模态的特征融合。

Result: 在MIntRec数据集上的实验表明，WDMIR的准确率比现有方法高1.13%，小波融合模块对非语言信息的语义提取提升0.41%。

Conclusion: WDMIR框架通过频域分析和跨模态交互，显著提升了多模态意图识别的性能，尤其在非语言信息处理上表现突出。

摘要: 多模态意图识别（MIR）旨在通过整合视频、音频和文本模态中的语言与非语言信息，准确解读用户意图。现有方法多侧重于文本分析，往往忽视了非语言信息中蕴含的丰富语义内容。本文提出了一种新颖的基于小波驱动的多模态意图识别（WDMIR）框架，通过频域分析提升对非语言信息的意图理解。具体而言，我们提出：（1）小波驱动的融合模块，在频域同步分解和整合视频-音频特征，实现对时间动态的细粒度分析；（2）跨模态交互机制，支持从双模态到三模态的渐进特征增强，有效弥合语言与非语言信息之间的语义鸿沟。在MIntRec数据集上的大量实验表明，我们的方法实现了最先进的性能，准确率比现有方法高出1.13%。消融研究进一步验证，小波驱动的融合模块显著提升了从非语言信息中提取语义的能力，在分析细微情感线索时识别准确率提高了0.41%。

</details>


### [516] [Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2506.10016)
**中文标题：多模态大语言模型综述**

*Longzhen Han,Awes Mubarak,Almas Baimagambetov,Nikolaos Polatidis,Thar Baker*

Main category: cs.MM

TL;DR: 本文综述了多模态大语言模型（MLLMs）的发展，探讨了其跨模态生成能力及其关键技术，同时指出了未解决的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）已从文本生成扩展到图像、音乐、视频等多种输出模态，但其跨模态能力和技术尚未系统梳理。本文旨在填补这一空白，提供统一视角。

Method: 通过分类六种主要生成模态，并分析自监督学习（SSL）、专家混合（MoE）、人类反馈强化学习（RLHF）和思维链（CoT）提示等关键技术如何支持跨模态能力。

Result: 总结了关键模型、架构趋势和跨模态协同效应，同时强调了可迁移技术和未解决的挑战，如评估、模块化和结构化推理。

Conclusion: 本文为MLLM的发展提供了统一视角，并指出了实现更通用、自适应和可解释的多模态系统的关键路径。

摘要: 多模态大语言模型（MLLMs）已迅速从文本生成扩展到图像、音乐、视频、人体动作和3D对象等多种输出模态，通过将语言与其他感官模态在统一架构中整合。本综述分类了六种主要生成模态，并探讨了自监督学习（SSL）、专家混合（MoE）、人类反馈强化学习（RLHF）和思维链（CoT）提示等基础技术如何实现跨模态能力。我们分析了关键模型、架构趋势和新兴的跨模态协同效应，同时强调了可迁移技术和未解决的挑战。像Transformer和扩散模型这样的架构创新支撑了这一融合，实现了跨模态迁移和模块化专业化。我们突出了协同效应的新兴模式，并指出了评估、模块化和结构化推理中的开放挑战。本综述为MLLM的发展提供了统一视角，并确定了实现更通用、自适应和可解释的多模态系统的关键路径。

</details>


### [517] [Semantic Communication-Enabled Cloud-Edge-End-collaborative Metaverse Services Architecure](https://arxiv.org/abs/2506.10001)
**中文标题：基于语义通信的云-边-端协同元宇宙服务架构**

*Yuxuan Li,Sheng Jinag,Bizhu Wang*

Main category: cs.MM

TL;DR: 本文提出了一种基于语义通信的云-边-端协同元宇宙服务架构（SC-CEE-Meta），通过语义传输、视频合成和3D场景重建模块，显著降低了无线传输延迟并提升了图像质量。


<details>
  <summary>Details</summary>
Motivation: 随着元宇宙的兴起，高分辨率虚拟场景的传输面临带宽不足和信道质量差的问题，导致延迟和数据错误，影响用户体验。本文旨在解决这些问题。

Method: 提出SC-CEE-Meta架构，包含VR视频语义传输、视频合成和3D虚拟场景重建三个模块。通过语义通信减少数据传输量，并在云端和边缘设备上部署预处理和渲染模块。

Result: 在Meta Quest Pro上验证，SC-CEE-Meta能将无线传输延迟降低96.05%，并在信道条件差时提升图像质量43.99%。

Conclusion: SC-CEE-Meta架构通过语义通信和云-边-端协同，有效解决了元宇宙服务中的传输延迟和图像质量问题，提升了用户体验。

摘要: 随着技术进步和对新视听体验需求的增强，元宇宙受到了广泛关注。然而，高分辨率虚拟场景等大量数据需要在云平台和VR设备之间传输，面临实际障碍。具体而言，VR设备的无线传输因带宽不足而受限，导致速度和延迟问题。同时，信道质量差会导致数据错误，进一步恶化用户体验。为解决这些问题，我们提出了基于语义通信的云-边-端协同沉浸式元宇宙服务（SC-CEE-Meta）架构，包含三个模块：VR视频语义传输、视频合成和3D虚拟场景重建。通过在VR设备和边缘服务器上部署语义模块，并传输关键语义信息而非专注于比特级重建，可以降低延迟、解决资源与带宽冲突，并更好地抵御信道干扰。此外，云端部署视频合成和3D场景重建预处理，边缘设备则托管3D重建渲染模块，共同提供沉浸式服务。在Meta Quest Pro上的验证表明，SC-CEE-Meta在信道条件差的情况下，能将无线传输延迟降低96.05%，并将图像质量提升43.99%。

</details>


### [518] [EQ-TAA: Equivariant Traffic Accident Anticipation via Diffusion-Based Accident Video Synthesis](https://arxiv.org/abs/2506.10002)
**中文标题：EQ-TAA：基于扩散模型的事故视频合成的等变交通事故事件预测**

*Jianwu Fang,Lei-Lei Li,Zhedong Zheng,Hongkai Yu,Jianru Xue,Zhengguo Li,Tat-Seng Chua*

Main category: cs.MM

TL;DR: 本文提出了一种基于扩散模型的交通事故预测方法（EQ-TAA），通过生成因果视频片段解决数据偏差问题，无需额外标注，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前交通事故事件预测（TAA）方法依赖大量标注数据，且易受数据偏差影响，难以捕捉事故的真实因果部分。本文旨在通过生成合成事故视频片段解决这一问题。

Method: 提出了一种注意力视频扩散模型（AVD），通过文本提示生成因果视频帧，同时保持视频风格和内容。结合等变三重损失（EQ-TAA），利用生成的伪正常和伪事故视频片段进行对比学习。

Result: 实验表明，AVD和EQ-TAA在性能上优于现有方法，能够有效解决背景混淆问题，提升事故预测的准确性。

Conclusion: EQ-TAA通过合成事故视频片段和等变学习框架，显著提升了交通事故事件预测的性能，为未来零伤亡目标提供了新思路。

摘要: 交通事故事件预测（TAA）是实现未来零伤亡目标的一个挑战性问题。当前方法通常将TAA视为需要大量标注的监督学习任务，但交通场景的长尾性、不确定性和快速变化性导致事故的真实因果部分难以识别，且易受数据偏差影响，从而引发背景混淆问题。为此，我们提出了一种注意力视频扩散模型（AVD），通过生成从正常片段到事故片段的因果视频片段，合成额外的事故视频。AVD能够根据事故或无事故的文本提示生成因果视频帧，同时保持视频生成后的风格和内容，适用于TAA任务。该方法无需额外标注，可利用多种驾驶场景的数据集进行训练。此外，AVD支持一种等变TAA（EQ-TAA），通过等变三重损失结合锚定的无事故视频片段和生成的伪正常与伪事故片段进行对比学习。大量实验验证了AVD和EQ-TAA的性能，结果表明其优于现有方法。

</details>


### [519] [Immersive Multimedia Communication: State-of-the-Art on eXtended Reality Streaming](https://arxiv.org/abs/2506.10004)
**中文标题：沉浸式多媒体通信：扩展现实流媒体的最新技术综述**

*Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

Main category: cs.MM

TL;DR: 本文综述了扩展现实（XR）流媒体的最新技术，包括XR定义、设备、交互方法、数据传输需求、体验质量优化及当前应用与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着XR技术的快速发展，其在内容创作和消费领域的潜力巨大。本文旨在全面梳理XR流媒体的最新进展，为未来研究提供参考。

Method: 文章首先定义XR并介绍相关设备及交互方法，分析XR流量的数据传输特性，探讨影响用户体验质量的因素，并提出基于视觉注意力的优化方法。

Result: 研究总结了XR流媒体的关键技术、优化方法及当前应用，同时指出了未来发展的挑战。

Conclusion: XR流媒体技术前景广阔，但仍需解决数据传输和用户体验优化等挑战，以推动其进一步发展。

摘要: 扩展现实（XR）技术正在快速发展，并有望彻底改变内容的创作和消费方式。在XR中，用户通过整合多种感官输入形成对虚拟环境的统一感知。本文综述了XR流媒体的最新技术，重点关注多种范式。首先，我们定义了XR并介绍了各种XR头戴设备及其多模态交互方法，以提供基础理解。接着，我们分析了XR流量的特性，以突出其独特的数据传输需求。我们还探讨了影响XR系统体验质量的因素，旨在识别提升用户满意度的关键要素。随后，我们提出了基于视觉注意力的XR流媒体优化方法，以提高效率和性能。最后，我们研究了当前的应用并指出了挑战，为XR的持续和未来发展提供见解。

</details>


### [520] [HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction](https://arxiv.org/abs/2506.10006)
**中文标题：通过动态双向重建实现灵活多模态输入的HER2表达预测**

*Jie Qin,Wei Yang,Yan Su,Yiran Zhu,Weizhen Li,Yunyue Pan,Chengchang Pan,Honggang Qi*

Main category: cs.MM

TL;DR: 本文提出了一种动态双向重建的灵活多模态输入框架，用于HER2表达预测，显著提升了单模态和双模态输入的准确性，同时降低了资源需求。


<details>
  <summary>Details</summary>
Motivation: 当前HER2评估模型主要依赖单一模态（H&E或IHC）分析，而临床实践中需要多模态协同解释。但由于工作流程复杂性和成本限制，同时获取多模态数据困难。本文旨在解决这一问题。

Method: 1) 动态分支选择器根据输入完整性激活单模态重建或双模态联合推理；2) 双向跨模态GAN实现缺失模态的上下文感知特征空间重建；3) 混合训练协议结合对抗学习和多任务优化。

Result: 单模态H&E预测准确率从71.44%提升至94.25%，双模态准确率达95.09%，仅IHC输入时可靠性为90.28%。跨模态重建将F1分数提升至0.9609（H&E到IHC）和0.9251（IHC到H&E）。

Conclusion: 该框架通过动态路由输入和重建增强路径，显著提升了HER2评估的准确性和资源效率，适用于资源有限的医疗环境。

摘要: 当前的HER2评估模型主要单独分析H&E或IHC图像，而临床实践中依赖它们的协同解释。然而，同时获取两种模态常因工作流程复杂性和成本限制而受阻。我们提出了一种自适应双模态框架，通过三项创新实现灵活的单/双模态HER2预测：1) 动态分支选择器，根据输入完整性激活单模态重建或双模态联合推理；2) 双向跨模态GAN，执行缺失模态的上下文感知特征空间重建；3) 混合训练协议，结合对抗学习和多任务优化。该架构将单模态H&E预测准确率从71.44%提升至94.25%，同时双模态准确率达95.09%，仅IHC输入时可靠性为90.28%。框架的“双模态优先，单模态兼容”设计在不需同步采集的情况下实现接近双模态的性能，尤其通过降低IHC基础设施成本惠及资源有限的环境。实验验证显示，相较于H&E/IHC基线，准确率分别提升22.81%和12.90%，跨模态重建将F1分数提升至0.9609（H&E到IHC）和0.9251（IHC到H&E）。通过动态路由输入至重建增强或原生融合路径，系统缓解了数据缺失导致的性能下降，同时保持计算效率（轻量级变体参数减少78.55%）。这一弹性架构展示了在多样化医疗环境中普及精确HER2评估的巨大潜力。

</details>


### [521] [Controllable Expressive 3D Facial Animation via Diffusion in a Unified Multimodal Space](https://arxiv.org/abs/2506.10007)
**中文标题：基于统一多模态空间中扩散的可控表达性3D面部动画**

*Kangwei Liu,Junwu Liu,Xiaowei Yi,Jinlin Guo,Yun Cao*

Main category: cs.MM

TL;DR: 本文提出了一种基于扩散模型的可控3D面部动画生成方法，通过多模态情感绑定策略和注意力潜扩散模型，解决了单模态控制信号和确定性映射的局限性，显著提升了情感相似性和动画表现力。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动的3D面部动画存在两个主要问题：一是依赖单一模态控制信号，未能充分利用多模态的互补优势；二是确定性映射限制了情感表达和非语言行为的随机性，导致动画表现力不足。

Method: 方法包括：(1) 基于FLAME的多模态情感绑定策略，通过对比学习对齐文本、音频和情感标签；(2) 注意力潜扩散模型，结合内容感知注意力和情感引导层，增强运动多样性的同时保持时间连贯性和自然面部动态。

Result: 实验表明，该方法在多数指标上优于现有方法，情感相似性提升了21.6%，同时保持了生理上合理的面部动态。

Conclusion: 本文提出的框架通过多模态情感绑定和扩散模型，显著提升了3D面部动画的表现力和可控性，为情感驱动的动画生成提供了新思路。

摘要: 音频驱动的情绪化3D面部动画面临两大挑战：(1) 依赖单一模态控制信号（视频、文本或情感标签），未能充分利用其互补优势以实现全面的情绪操控；(2) 确定性回归映射限制了情绪表达和非语言行为的随机性，降低了合成动画的表现力。为解决这些问题，我们提出了一种基于扩散模型的可控表达性3D面部动画框架。我们的方法包含两项关键创新：(1) 以FLAME为中心的多模态情感绑定策略，通过对比学习对齐文本、音频和情感标签，实现多信号源的灵活情绪控制；(2) 基于注意力的潜扩散模型，结合内容感知注意力和情感引导层，在保持时间连贯性和自然面部动态的同时丰富了运动多样性。大量实验表明，我们的方法在多数指标上优于现有方法，情感相似性提升了21.6%，同时保持了生理上合理的面部动态。项目页面：https://kangweiiliu.github.io/Control_3D_Animation。

</details>


### [522] [Structured Graph Representations for Visual Narrative Reasoning: A Hierarchical Framework for Comics](https://arxiv.org/abs/2506.10008)
**中文标题：视觉叙事推理的结构化图表示：一种用于漫画的分层框架**

*Yi-Chun Chen*

Main category: cs.MM

TL;DR: 本文提出了一种分层知识图谱框架，用于结构化理解视觉叙事（如漫画），通过多模态图谱捕捉语义、空间和时间关系，并在Manga109数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 视觉叙事（如漫画）包含复杂的多模态信息，传统方法难以有效捕捉其语义、空间和时间关系。本文旨在通过分层知识图谱框架解决这一问题，支持对故事结构、角色连续性和事件进展的推理。

Method: 提出了一种分层知识图谱框架，将叙事内容分解为从宏观故事弧到细粒度事件片段的多层次结构，并通过多模态图谱链接视觉元素（如角色、物体、动作）和文本组件（如对话、标题）。这些图谱在叙事层次上集成，支持符号化推理。

Result: 在Manga109数据集的手动标注子集上进行了实验，验证了框架在动作检索、对话追踪、角色出现映射和面板时间线重建等任务中的高精度和高召回率。

Conclusion: 该框架为基于叙事的视觉媒体内容分析、交互式故事讲述和多模态推理提供了可扩展的基础。

摘要: 本文提出了一种分层知识图谱框架，用于结构化理解视觉叙事（如漫画）。该方法将叙事内容分解为多个层次，从宏观故事弧到细粒度事件片段，并通过集成知识图谱捕捉语义、空间和时间关系。在面板级别，我们构建了多模态图谱，将视觉元素（如角色、物体、动作）与文本组件（如对话、标题）链接起来。这些图谱在叙事层次上集成，支持对故事结构、角色连续性和事件进展的推理。

我们将该方法应用于Manga109数据集的手动标注子集，并展示了其在动作检索、对话追踪、角色出现映射和面板时间线重建等多种叙事任务中的符号化推理能力。评估结果显示，该框架在各项任务中均表现出高精度和高召回率，验证了其一致性和可解释性。这项工作为基于叙事的视觉媒体内容分析、交互式故事讲述和多模态推理提供了可扩展的基础。

</details>


### [523] [WDMIR: Wavelet-Driven Multimodal Intent Recognition](https://arxiv.org/abs/2506.10011)
**中文标题：WDMIR：基于小波驱动的多模态意图识别**

*Weiyin Gong,Kai Zhang,Yanghai Zhang,Qi Liu,Xinjie Sun,Junyu Lu,Linbo Zhu*

Main category: cs.MM

TL;DR: 本文提出了一种基于小波变换的多模态意图识别框架（WDMIR），通过频域分析非语言信息提升意图理解能力，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注文本分析，忽略了非语言信息中的丰富语义内容。本文旨在通过频域分析非语言信息，弥补这一不足。

Method: 1. 提出小波驱动的融合模块，在频域同步分解和整合视频-音频特征，实现细粒度的时间动态分析；2. 设计跨模态交互机制，从双模态到三模态逐步增强特征，缩小语言与非语言信息的语义差距。

Result: 在MIntRec数据集上的实验表明，WDMIR的准确率比现有方法高1.13%。消融实验进一步验证了小波融合模块对非语言信息语义提取的提升作用，识别准确率提高了0.41%。

Conclusion: WDMIR通过频域分析非语言信息，显著提升了多模态意图识别的性能，为语言与非语言信息的融合提供了新思路。

摘要: 多模态意图识别（MIR）旨在通过整合视频、音频和文本模态中的语言与非语言信息，准确理解用户意图。现有方法多侧重于文本分析，却忽略了非语言信息中蕴含的丰富语义内容。本文提出了一种新颖的基于小波驱动的多模态意图识别（WDMIR）框架，通过频域分析非语言信息增强意图理解能力。具体而言，我们提出：（1）小波驱动的融合模块，在频域同步分解和整合视频-音频特征，实现对时间动态的细粒度分析；（2）跨模态交互机制，支持从双模态到三模态的渐进式特征增强，有效弥合语言与非语言信息之间的语义鸿沟。在MIntRec数据集上的大量实验表明，我们的方法达到了最先进的性能，准确率比现有方法高出1.13%。消融实验进一步验证了小波融合模块对非语言信息语义提取的显著提升作用，在分析细微情感线索时识别准确率提高了0.41%。

</details>


### [524] [Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2506.10016)
**中文标题：多模态大语言模型综述**

*Longzhen Han,Awes Mubarak,Almas Baimagambetov,Nikolaos Polatidis,Thar Baker*

Main category: cs.MM

TL;DR: 本文综述了多模态大语言模型（MLLMs）的发展，探讨了其跨模态生成能力及关键技术，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型的快速发展，其在图像、音乐、视频等多样化输出模态中的应用日益广泛。本文旨在系统梳理MLLMs的研究现状，分析其关键技术及跨模态能力，并为未来研究提供方向。

Method: 本文通过对六种主要生成模态的分类，分析了自监督学习（SSL）、专家混合（MoE）、人类反馈强化学习（RLHF）和思维链（CoT）提示等基础技术如何实现跨模态能力。同时，研究了关键模型、架构趋势及跨模态协同效应。

Result: 研究发现，Transformer和扩散模型等架构创新推动了跨模态迁移和模块化专业化。此外，本文总结了跨模态协同的新模式，并指出了评估、模块化和结构化推理等未解决的挑战。

Conclusion: 本文为MLLMs的发展提供了统一视角，并指出了实现更通用、自适应和可解释的多模态系统的关键路径。

摘要: 多模态大语言模型（MLLMs）已迅速从文本生成扩展到图像、音乐、视频、人体运动和3D对象等多种输出模态，通过将语言与其他感知模态整合到统一架构中。本综述将六种主要生成模态分类，并探讨了自监督学习（SSL）、专家混合（MoE）、人类反馈强化学习（RLHF）和思维链（CoT）提示等基础技术如何实现跨模态能力。我们分析了关键模型、架构趋势和新兴的跨模态协同效应，同时强调了可迁移技术和未解决的挑战。Transformer和扩散模型等架构创新支撑了这一融合，实现了跨模态迁移和模块化专业化。我们突出了协同效应的新兴模式，并指出了评估、模块化和结构化推理等开放挑战。本综述为MLLMs的发展提供了统一视角，并确定了实现更通用、自适应和可解释的多模态系统的关键路径。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [525] [An Analysis of Datasets, Metrics and Models in Keyphrase Generation](https://arxiv.org/abs/2506.10346)
**中文标题：关键词生成的数据集、指标与模型分析**

*Florian Boudin,Akiko Aizawa*

Main category: cs.IR

TL;DR: The paper provides a comprehensive analysis of over 50 research papers on keyphrase generation, identifying issues in evaluation practices and dataset similarities, and introduces a new PLM-based model to aid future research.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the lack of a comprehensive review and analysis of previous work in keyphrase generation, despite continuous efforts in the field.

Method: The method involves reviewing and analyzing over 50 research papers on keyphrase generation, focusing on model architectures, datasets, and evaluation metrics.

Result: The results highlight critical issues in evaluation practices, such as dataset similarities and inconsistent metric calculations, and introduce a new PLM-based model.

Conclusion: The conclusion emphasizes the need for improved evaluation practices and the release of a new model to support future research in keyphrase generation.

摘要: 关键词生成是指生成一组单词或短语以概括文档内容的任务。过去几年中，针对这一任务的持续努力涉及多个研究方向，如模型架构、数据资源和使用场景。然而，由于缺乏对先前工作的回顾与分析，关键词生成的现状仍不明确。本文通过分析50多篇关键词生成的研究论文，填补了这一空白，提供了对近期进展、局限性和开放挑战的全面概述。我们的发现揭示了当前评估实践中的几个关键问题，例如常用基准数据集之间的相似性以及指标计算的不一致性导致性能被高估。此外，我们通过发布一个基于预训练语言模型的关键词生成模型，解决了预训练模型可用性有限的问题，以促进未来研究。

</details>


### [526] [Conversational Search: From Fundamentals to Frontiers in the LLM Era](https://arxiv.org/abs/2506.10635)
**中文标题：对话式搜索：从基础到LLM时代的前沿**

*Fengran Mo,Chuan Meng,Mohammad Aliannejadi,Jian-Yun Nie*

Main category: cs.IR

TL;DR: The paper explores conversational search, focusing on multi-turn interactions and the role of LLMs in advancing intelligent search systems. It connects fundamentals with emerging LLM-driven topics.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between traditional conversational search principles and the transformative potential of LLMs, providing a comprehensive guide for academia and industry.

Method: The tutorial introduces core principles of conversational search and integrates emerging LLM-driven advancements, offering a structured overview for participants.

Result: Participants gain a holistic understanding of conversational search, from fundamentals to LLM-driven innovations, preparing them to contribute to next-gen systems.

Conclusion: The tutorial successfully links foundational knowledge with cutting-edge LLM applications, fostering development in conversational search.

摘要: 对话式搜索支持用户与系统之间的多轮交互，以满足用户的复杂信息需求。在此过程中，系统需理解用户在对话上下文中的搜索意图，并通过灵活的对话界面返回相关信息。近期强大的大语言模型（LLMs）因其指令遵循、内容生成和推理能力吸引了广泛关注，为构建智能对话式搜索系统提供了新的机遇与挑战。本教程旨在介绍对话式搜索中基础与LLM革命性新兴主题之间的联系，面向学术界和工业界的学生、研究人员及从业者。参与者将全面理解对话式搜索的核心原则及LLM驱动的前沿发展，掌握为下一代对话式搜索系统开发所需的知识。

</details>


### [527] [Towards Understanding Bias in Synthetic Data for Evaluation](https://arxiv.org/abs/2506.10301)
**中文标题：理解用于评估的合成数据中的偏差**

*Hossein A. Rahmani,Varsha Ramineni,Nick Craswell,Bhaskar Mitra,Emine Yilmaz*

Main category: cs.IR

TL;DR: The paper investigates biases in synthetic test collections generated by LLMs for IR system evaluation, showing their impact on absolute performance but less so on relative comparisons.


<details>
  <summary>Details</summary>
Motivation: To validate the reliability of synthetic test collections created by LLMs for IR system evaluation and analyze potential biases.

Method: Empirically examines bias in synthetic test collections using LLMs for query and label generation, validated with a linear mixed-effects model.

Result: Bias in synthetic test collections significantly affects absolute system performance evaluation but has less impact on relative performance comparisons.

Conclusion: While synthetic test collections introduce bias, their use for relative system comparisons remains viable, though caution is needed for absolute evaluations.

摘要: 测试集合对于评估信息检索（IR）系统至关重要。为这些集合创建多样化的用户查询具有挑战性，而获取相关性判断（即检索文档与查询的匹配程度）通常成本高昂且资源密集。最近，利用大型语言模型（LLMs）生成合成数据集在各种应用中受到关注。虽然之前的工作使用LLMs生成合成查询或文档以改进排序模型，但利用LLMs创建合成测试集合仍相对较少探索。先前的研究表明，合成测试集合有潜力用于系统评估，但需要更多分析来验证这一观点。本文深入研究了使用LLMs构建的合成测试集合的可靠性，其中LLMs用于生成合成查询、标签或两者。我们特别关注此类测试集合用于评估时可能出现的潜在偏差。我们首先通过实验证明评估结果中存在此类偏差，并分析其对系统评估的影响。进一步通过线性混合效应模型验证了这种偏差的存在。分析表明，尽管合成测试集合在评估结果中引入的偏差对绝对系统性能（如计算绝对性能）影响显著，但其对相对系统性能比较的影响可能较小。代码和数据可在以下地址获取：https://github.com/rahmanidashti/BiasSyntheticData。

</details>


### [528] [Contrastive Matrix Completion with Denoising and Augmented Graph Views for Robust Recommendation](https://arxiv.org/abs/2506.10658)
**中文标题：基于去噪和增强图视图的对比矩阵补全用于鲁棒推荐**

*Narges Nemati,Mostafa Haghir Chehreghani*

Main category: cs.IR

TL;DR: The paper proposes MCCL, a contrastive learning-based matrix completion method for robust recommendations, addressing noise sensitivity and overfitting in GNNs by denoising and aligning graph representations.


<details>
  <summary>Details</summary>
Motivation: Current GNN-based matrix completion methods are sensitive to noisy edges and prone to overfitting, limiting their generalizability in recommender systems.

Method: MCCL extracts local subgraphs, generates two graph representations (denoised via attention and aligned via a variational autoencoder), and uses a mutual learning loss to harmonize them.

Result: MCCL improves RMSE by up to 0.8% and ranking metrics by up to 36% on real-world datasets.

Conclusion: MCCL enhances recommendation robustness by combining denoising and representation alignment, outperforming existing methods.

摘要: 矩阵补全是推荐系统中广泛采用的框架，通过预测用户-物品评分矩阵中的缺失项来全面理解用户偏好。然而，当前基于图神经网络（GNN）的方法由于其固有的消息传递机制，对噪声或无关边高度敏感，且容易过拟合，限制了其泛化能力。为克服这些挑战，我们提出了一种名为对比学习矩阵补全（MCCL）的新方法。该方法首先为每个交互提取局部邻域子图，随后生成两种不同的图表示。第一种表示通过将GNN层与注意力机制结合来强调去噪，而第二种表示通过图变分自编码器将特征分布与标准先验对齐。训练过程中采用互学习损失函数逐步协调这些表示，使模型能够捕捉共同模式并显著提升泛化能力。在多个真实数据集上的广泛实验表明，我们的方法不仅提高了预测分数的数值准确性（RMSE提升高达0.8%），还生成了更优的排名（排名指标提升高达36%）。

</details>


### [529] [Precise Zero-Shot Pointwise Ranking with LLMs through Post-Aggregated Global Context Information](https://arxiv.org/abs/2506.10859)
**中文标题：通过后聚合全局上下文信息实现基于LLM的精确零样本逐点排序**

*Kehan Long,Shasha Li,Chen Xu,Jintao Tang,Ting Wang*

Main category: cs.IR

TL;DR: The paper introduces a novel Global-Consistent Comparative Pointwise Ranking (GCCP) strategy to improve zero-shot document ranking by incorporating global context information, achieving better performance while maintaining efficiency.


<details>
  <summary>Details</summary>
Motivation: Current pointwise ranking methods for zero-shot document ranking are efficient but ignore comparative insights between documents, leading to inconsistent scoring and suboptimal performance. The paper aims to enhance effectiveness while preserving efficiency.

Method: The proposed GCCP strategy uses a query-focused summary of pseudo-relevant candidates as an anchor document to capture global context. Contrastive relevance scores are generated and post-aggregated with existing pointwise methods (PAGC) for improved performance.

Result: Experiments on TREC DL and BEIR benchmarks show that GCCP significantly outperforms previous pointwise methods and achieves competitive performance against more resource-intensive comparative methods.

Conclusion: The GCCP strategy effectively integrates global context into pointwise ranking, improving performance without sacrificing efficiency, and validates the efficacy of the anchor construction approach.

摘要: 最近的进展成功利用大型语言模型（LLM）进行零样本文档排序，探索了多种提示策略。比较方法（如成对和列表方式）虽然效果显著，但计算密集，因此在大规模应用中不太实用。基于评分的逐点方法通过独立且同时生成每个候选文档的相关性分数，展现出更高的效率。然而，这种独立性忽略了文档之间的关键比较洞察，导致评分不一致和性能欠佳。本文旨在通过两项关键创新提高逐点方法的有效性，同时保持其效率：（1）我们提出了一种新颖的全局一致比较逐点排序（GCCP）策略，通过将每个候选文档与锚定文档进行全局参考比较，生成对比性相关性分数。我们策略性地将锚定文档设计为伪相关候选文档的查询聚焦摘要，通过捕获文档比较的全局上下文，作为有效的参考点。（2）这些对比性相关性分数可以与现有的逐点方法高效地进行后聚合（PAGC），以无需训练的方式无缝整合关键的全局上下文信息。在TREC DL和BEIR基准上的大量实验表明，我们的方法显著优于先前的逐点方法，同时保持了相当的效率。我们的方法还与需要更多计算资源的比较方法相比具有竞争力。更多分析进一步验证了我们锚定构建策略的有效性。

</details>


### [530] [An Analysis of Datasets, Metrics and Models in Keyphrase Generation](https://arxiv.org/abs/2506.10346)
**中文标题：关键词生成的数据集、指标与模型分析**

*Florian Boudin,Akiko Aizawa*

Main category: cs.IR

TL;DR: 本文分析了50多篇关于关键词生成的研究论文，总结了当前研究的进展、局限性和开放性问题，并指出了评估实践中的关键问题，同时发布了一个基于预训练语言模型的关键词生成模型以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 关键词生成任务在过去几年中受到广泛关注，但缺乏对现有研究的系统综述和分析，导致当前研究状态不明确。本文旨在填补这一空白。

Method: 作者对50多篇关键词生成的研究论文进行了系统分析，总结了模型架构、数据资源和应用场景等方面的进展，并指出了评估实践中的问题。同时，发布了一个基于预训练语言模型的关键词生成模型。

Result: 研究发现，当前评估实践中存在数据集相似性高和指标计算不一致等问题，导致性能被高估。此外，预训练模型的可用性有限，作者发布的模型为未来研究提供了支持。

Conclusion: 本文为关键词生成领域提供了全面的综述，揭示了当前研究的局限性，并通过发布新模型促进了未来研究的发展。

摘要: 关键词生成是指生成一组能够概括文档内容的单词或短语的任务。过去几年中，针对这一任务的研究持续进行，涉及模型架构、数据资源和应用场景等多个方向。然而，由于缺乏对现有工作的综述和分析，关键词生成的当前状态尚不明确。本文通过分析50多篇关键词生成的研究论文，填补了这一空白，提供了对近期进展、局限性和开放挑战的全面概述。我们的研究结果揭示了当前评估实践中的几个关键问题，例如常用基准数据集之间的高度相似性以及指标计算的不一致性导致性能被高估。此外，我们还通过发布一个基于预训练语言模型的关键词生成模型，解决了预训练模型可用性有限的问题，以促进未来研究。

</details>


### [531] [Conversational Search: From Fundamentals to Frontiers in the LLM Era](https://arxiv.org/abs/2506.10635)
**中文标题：对话式搜索：从基础到LLM时代的前沿**

*Fengran Mo,Chuan Meng,Mohammad Aliannejadi,Jian-Yun Nie*

Main category: cs.IR

TL;DR: 本文介绍了对话式搜索的基本原理及其在大型语言模型（LLM）时代的前沿发展，旨在为学术界和工业界的研究者与实践者提供全面的知识。


<details>
  <summary>Details</summary>
Motivation: 对话式搜索通过多轮交互满足用户的复杂信息需求，而大型语言模型（LLM）的出现为构建智能对话搜索系统提供了新的机遇与挑战。本文旨在探讨对话式搜索的基础与LLM驱动的前沿话题之间的联系。

Method: 本文通过教程形式，结合基础理论与LLM的最新进展，介绍对话式搜索的核心原则与前沿技术。

Result: 参与者将全面了解对话式搜索的核心原理及LLM驱动的最新发展，为下一代对话搜索系统的开发奠定基础。

Conclusion: 本文为对话式搜索领域的研究者和实践者提供了从基础到前沿的全面知识，助力下一代智能对话搜索系统的开发。

摘要: 对话式搜索通过用户与系统之间的多轮交互满足用户的复杂信息需求。在此过程中，系统需理解用户在对话上下文中的搜索意图，并通过灵活的对话界面返回相关信息。近年来，具备指令遵循、内容生成和推理能力的大型语言模型（LLM）吸引了广泛关注，为构建智能对话搜索系统提供了新的机遇与挑战。本教程旨在介绍对话式搜索的基础与LLM驱动的新兴话题之间的联系，面向学术界和工业界的学生、研究者及实践者。参与者将全面了解对话式搜索的核心原理及LLM驱动的最新发展，掌握为下一代对话搜索系统开发所需的知识。

</details>


### [532] [Towards Understanding Bias in Synthetic Data for Evaluation](https://arxiv.org/abs/2506.10301)
**中文标题：理解合成数据评估中的偏见**

*Hossein A. Rahmani,Varsha Ramineni,Nick Craswell,Bhaskar Mitra,Emine Yilmaz*

Main category: cs.IR

TL;DR: 本文探讨了使用大型语言模型（LLMs）生成合成测试集合时可能引入的偏见，并分析了这些偏见对信息检索系统评估的影响。研究发现，虽然偏见对绝对性能评估有显著影响，但对相对性能比较的影响较小。


<details>
  <summary>Details</summary>
Motivation: 测试集合对信息检索系统评估至关重要，但生成多样化的查询和获取相关性标注成本高昂。虽然LLMs已被用于生成合成数据，但其在构建测试集合时的可靠性及潜在偏见尚未充分研究。

Method: 本文通过实证分析展示了合成测试集合中存在的偏见，并使用线性混合效应模型验证了这些偏见的存在。研究重点分析了偏见对系统评估结果的影响。

Result: 研究发现，合成测试集合中的偏见对绝对系统性能评估有显著影响，但对相对性能比较的影响较小。

Conclusion: 尽管合成测试集合中的偏见可能影响评估结果，但其在相对性能比较中的影响有限。未来研究需进一步验证和改进合成数据的可靠性。

摘要: 测试集合对于评估信息检索（IR）系统至关重要。为这些集合生成多样化的用户查询具有挑战性，而获取相关性标注（即检索文档与查询的匹配程度）通常成本高昂且资源密集。近年来，使用大型语言模型（LLMs）生成合成数据集在各种应用中受到关注。虽然已有研究利用LLMs生成合成查询或文档以改进排序模型，但使用LLMs构建合成测试集合的研究仍较少。先前的研究表明，合成测试集合有潜力用于系统评估，但需要更多分析验证这一观点。本文深入研究了使用LLMs构建的合成测试集合的可靠性，其中LLMs用于生成合成查询、标注或两者。特别地，我们探讨了此类测试集合用于评估时可能存在的偏见。我们首先通过实证展示了评估结果中存在的偏见，并分析了其对系统评估的影响。进一步使用线性混合效应模型验证了这些偏见的存在。分析表明，虽然合成测试集合中的偏见对绝对系统性能评估（如计算绝对性能）可能有显著影响，但其对相对性能比较的影响较小。代码和数据可在以下链接获取：https://github.com/rahmanidashti/BiasSyntheticData。

</details>


### [533] [Contrastive Matrix Completion with Denoising and Augmented Graph Views for Robust Recommendation](https://arxiv.org/abs/2506.10658)
**中文标题：基于去噪和增强图视图的对比矩阵补全方法用于鲁棒推荐**

*Narges Nemati,Mostafa Haghir Chehreghani*

Main category: cs.IR

TL;DR: 本文提出了一种基于对比学习的矩阵补全方法（MCCL），通过去噪和增强图视图提升推荐系统的鲁棒性，显著提高了预测准确性和排序性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图神经网络的矩阵补全方法对噪声边敏感且容易过拟合，限制了其泛化能力。本文旨在解决这些问题。

Method: MCCL方法为每个交互提取局部子图，生成两种图表示：一种通过注意力机制去噪，另一种通过图变分自编码器对齐特征分布。通过互学习损失函数协调这两种表示。

Result: 在多个真实数据集上的实验表明，MCCL在预测分数上提升了0.8%的RMSE，排序指标提升了36%。

Conclusion: MCCL通过对比学习显著提升了推荐系统的鲁棒性和泛化能力，为矩阵补全提供了新思路。

摘要: 矩阵补全是推荐系统中广泛采用的框架，通过预测用户-物品评分矩阵中的缺失条目来全面理解用户偏好。然而，当前基于图神经网络（GNN）的方法由于其固有的消息传递机制，对噪声或无关边高度敏感，且容易过拟合，限制了其泛化能力。为克服这些挑战，我们提出了一种名为“基于对比学习的矩阵补全”（MCCL）的新方法。我们的方法首先为每个交互提取局部邻域子图，随后生成两种不同的图表示。第一种表示通过结合GNN层与注意力机制实现去噪，第二种表示则通过图变分自编码器将特征分布与标准先验对齐。训练过程中采用互学习损失函数逐步协调这两种表示，使模型能够捕捉共同模式并显著提升泛化能力。在多个真实数据集上的广泛实验表明，我们的方法不仅提高了预测分数的数值准确性（RMSE提升达0.8%），还产生了更优的排序（排序指标提升达36%）。

</details>


### [534] [Precise Zero-Shot Pointwise Ranking with LLMs through Post-Aggregated Global Context Information](https://arxiv.org/abs/2506.10859)
**中文标题：通过后聚合全局上下文信息实现基于LLMs的精确零样本点对点排序**

*Kehan Long,Shasha Li,Chen Xu,Jintao Tang,Ting Wang*

Main category: cs.IR

TL;DR: 本文提出了一种名为GCCP的新型点对点排序策略，通过引入全局一致性比较和锚点文档，显著提升了零样本文档排序的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有的点对点排序方法虽然高效，但忽略了文档间的比较信息，导致评分不一致和性能不佳。本文旨在在保持效率的同时，通过引入全局上下文信息提升点对点排序的效果。

Method: 提出GCCP策略，利用锚点文档（查询相关候选文档的摘要）作为全局参考点，生成对比相关性分数，并通过后聚合方法（PAGC）高效整合全局上下文信息。

Result: 在TREC DL和BEIR基准测试中，GCCP显著优于现有点对点方法，且效率相当，同时与计算资源密集的比较方法表现相当。

Conclusion: GCCP通过全局一致性比较和后聚合方法，有效提升了点对点排序的性能，同时保持了高效性，为大规模应用提供了实用解决方案。

摘要: 近期研究成功利用大型语言模型（LLMs）进行零样本文档排序，探索了多种提示策略。比较方法（如成对和列表方法）虽高效但计算密集，不适合大规模应用。基于评分的点对点方法通过独立生成相关性分数表现出高效性，但忽略了文档间的比较信息，导致评分不一致和性能不佳。本文旨在通过两项关键创新提升点对点方法的有效性并保持其效率：（1）提出全局一致性比较点对点排序（GCCP）策略，通过将候选文档与锚点文档（伪相关候选的查询摘要）进行全局参考比较，生成对比相关性分数。（2）这些对比分数可通过后聚合方法（PAGC）与现有点对点方法高效整合，以无需训练的方式融入全局上下文信息。在TREC DL和BEIR基准测试中，GCCP显著优于现有点对点方法，且效率相当，同时与计算资源密集的比较方法表现相当。进一步分析验证了锚点构建策略的有效性。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [535] [Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence](https://arxiv.org/abs/2506.10925)
**中文标题：自主无线空间网络的代理语义控制：通过MCP驱动的分布式智能扩展Space-O-RAN**

*Eduardo Baena,Paolo Testolina,Michele Polese,Sergi Aliaga,Andrew Benincasa,Dimitrios Koutsonikolas,Josep Jornet,Tommaso Melodia*

Main category: cs.NI

TL;DR: The paper proposes extending Space-O-RAN with a semantic agentic layer using MCP and A2A protocols to enable context-aware decision-making for autonomous wireless networks in lunar operations.


<details>
  <summary>Details</summary>
Motivation: Lunar surface operations require autonomous, robust, and adaptive wireless communication systems. Current Space-O-RAN lacks semantic integration and dynamic decision-making capabilities.

Method: Introduces a semantic agentic layer with MCP and A2A protocols for distributed cognitive agents in rovers, landers, and base stations, enabling context-aware coordination and reasoning.

Result: The extension allows for delay-adaptive reasoning, bandwidth-aware semantic compression, and interaction with MCP servers for telemetry and mission constraint analysis.

Conclusion: The proposed semantic agentic layer enhances Space-O-RAN's adaptability and autonomy for lunar wireless networks.

摘要: 月球表面作业对无线通信系统提出了严格要求，包括自主性、抗干扰能力以及对环境和任务驱动的适应性。尽管Space-O-RAN提供了符合3GPP标准的分布式编排模型，但其决策逻辑仅限于静态策略且缺乏语义集成。我们提出了一种新颖的扩展，通过模型上下文协议（MCP）和代理间（A2A）通信协议实现语义代理层，支持跨实时、近实时和非实时控制层的上下文感知决策。部署在漫游车、着陆器和月球基站中的分布式认知代理实现了无线感知协调策略，包括延迟自适应推理和带宽感知语义压缩，同时与多个MCP服务器交互以分析遥测数据、运动规划和任务约束。

</details>


### [536] [Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence](https://arxiv.org/abs/2506.10925)
**中文标题：自主无线空间网络的语义控制：基于MCP驱动的分布式智能扩展Space-O-RAN**

*Eduardo Baena,Paolo Testolina,Michele Polese,Sergi Aliaga,Andrew Benincasa,Dimitrios Koutsonikolas,Josep Jornet,Tommaso Melodia*

Main category: cs.NI

TL;DR: 本文提出了一种基于语义代理层的Space-O-RAN扩展方案，通过MCP和A2A协议实现上下文感知的分布式智能决策，以提升月球表面无线通信的自主性和适应性。


<details>
  <summary>Details</summary>
Motivation: 月球表面任务对无线通信系统提出了高要求，包括自主性、抗干扰能力和环境适应性。现有的Space-O-RAN模型虽支持分布式编排，但决策逻辑静态且缺乏语义集成，无法满足复杂任务需求。

Method: 通过引入基于MCP和A2A协议的语义代理层，扩展Space-O-RAN，实现跨实时、近实时和非实时控制层的上下文感知决策。分布式认知代理部署于月球车、着陆器和基站，支持延迟自适应推理和带宽感知语义压缩。

Result: 提出的方法实现了无线感知的协调策略，能够基于任务约束、遥测数据和运动规划进行智能推理，提升了通信系统的自主性和适应性。

Conclusion: 通过语义代理层的引入，扩展了Space-O-RAN的能力，为月球表面无线通信提供了更灵活、智能的解决方案。

摘要: 月球表面任务对无线通信系统提出了严格要求，包括自主性、抗干扰能力以及适应环境和任务上下文的能力。尽管Space-O-RAN提供了符合3GPP标准的分布式编排模型，但其决策逻辑仅限于静态策略且缺乏语义集成。我们提出了一种新颖的扩展方案，通过模型上下文协议（MCP）和代理间（A2A）通信协议实现语义代理层，支持跨实时、近实时和非实时控制层的上下文感知决策。部署于月球车、着陆器和基站的分布式认知代理实现了无线感知的协调策略，包括延迟自适应推理和带宽感知语义压缩，同时与多个MCP服务器交互以推理遥测数据、运动规划和任务约束。

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [537] [Learning Chaotic Dynamics with Neuromorphic Network Dynamics](https://arxiv.org/abs/2506.10773)
**中文标题：利用神经形态网络动力学学习混沌动力学**

*Yinhao Xu,Georg A. Gottwald,Zdenka Kuncic*

Main category: cond-mat.dis-nn

TL;DR: The paper explores using a neuromorphic network with memristive elements to model chaotic dynamics, finding optimal conditions for learning through input voltage manipulation.


<details>
  <summary>Details</summary>
Motivation: To understand how neuromorphic networks, as dynamical systems, can learn and model complex chaotic dynamics using their inherent physics.

Method: Simulated a neuromorphic network with memristive components in a reservoir computing framework to predict chaotic time series by manipulating input voltages and electrodes.

Result: Optimal learning occurred when input voltages maximized memristive dynamics coverage, while increased electrode coverage suppressed less useful nonlinear responses.

Conclusion: The study offers insights into optimizing neuromorphic networks for learning complex dynamics using external controls.

摘要: 本研究探讨了如何利用神经形态网络（本身是一种动力学系统）学习和建模动力学系统。研究中使用的神经形态网络基于一个由忆阻元件组成的复杂电路，这些元件对输入电信号产生神经突触非线性响应。为了确定如何利用底层系统的物理特性进行计算，该神经形态网络在自主预测多元混沌时间序列的任务中进行了模拟和评估，采用了储备池计算框架。通过仅操纵输入电极和电压，发现当输入电压最大化忆阻元件内部动力学探索整个忆阻模型动态范围时，非线性动力学响应达到最优。此外，增加输入电极的网络覆盖范围会抑制不利于学习的其他非线性响应。这些结果为如何通过仅调整外部控制参数来优化实际神经形态网络设备以学习复杂动力学系统提供了宝贵见解。

</details>


### [538] [Learning Chaotic Dynamics with Neuromorphic Network Dynamics](https://arxiv.org/abs/2506.10773)
**中文标题：利用神经形态网络动力学学习混沌动态**

*Yinhao Xu,Georg A. Gottwald,Zdenka Kuncic*

Main category: cond-mat.dis-nn

TL;DR: 本研究探讨了如何利用神经形态网络（一种动态系统）学习和建模动态系统。通过基于忆阻元件的复杂电路模拟，研究发现输入电压最大化忆阻组件动态范围时，网络表现出最优非线性动态响应，为优化神经形态网络设备提供了实用见解。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索如何利用神经形态网络（本身为动态系统）学习和建模复杂的动态系统，尤其是通过外部控制参数优化网络性能。

Method: 方法包括基于忆阻元件的神经形态网络模拟，采用储层计算框架对多元混沌时间序列进行自主预测，并通过调整输入电极和电压优化网络响应。

Result: 结果显示，当输入电压最大化忆阻组件动态范围时，网络表现出最优非线性动态响应；而增加输入电极覆盖范围会抑制不利于学习的其他非线性响应。

Conclusion: 结论表明，通过外部控制参数优化神经形态网络设备，可以有效学习复杂动态系统，为实际应用提供了重要指导。

摘要: 本研究探讨了如何利用神经形态网络（本身为动态系统）学习和建模动态系统。研究中使用的神经形态网络基于一种由忆阻元件组成的复杂电路，这些元件对输入电信号产生神经突触非线性响应。为了确定如何利用底层系统的物理特性进行计算，该网络在储层计算框架下模拟并评估了对多元混沌时间序列的自主预测能力。通过仅调整输入电极和电压，研究发现当输入电压最大化忆阻组件内部动态范围时，网络表现出最优非线性动态响应。此外，增加输入电极的覆盖范围会抑制不利于学习的其他非线性响应。这些结果为如何通过外部控制参数优化神经形态网络设备以学习复杂动态系统提供了实用见解。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [539] [Modality-AGnostic Image Cascade (MAGIC) for Multi-Modality Cardiac Substructure Segmentation](https://arxiv.org/abs/2506.10797)
**中文标题：多模态心脏亚结构分割的模态无关图像级联（MAGIC）**

*Nicholas Summerfield,Qisheng He,Alex Kuo,Ahmed I. Ghanem,Simeng Zhu,Chase Ruff,Joshua Pan,Anudeep Kumar,Prashant Nagpal,Jiwei Zhao,Ming Dong,Carri K. Glide-Hurst*

Main category: physics.med-ph

TL;DR: The paper introduces MAGIC, a modality-agnostic deep learning model for multi-modality cardiac substructure segmentation, showing superior performance in 57% of cases compared to other models.


<details>
  <summary>Details</summary>
Motivation: To address the lack of generalizability in deep learning models for cardiac substructure segmentation across different imaging modalities and overlapping structures, which is crucial for minimizing radiation-induced heart disease in thoracic therapy.

Method: MAGIC uses replicated encoding and decoding branches of an nnU-Net-based U-shaped backbone to segment 20 cardiac substructures from three modalities (Sim-CT, MR-Linac, CCTA). It was trained on 76 cases, validated on 15, and tested on 30, with 12 comparison models.

Result: MAGIC achieved average DSC scores of 0.75 (Sim-CT), 0.68 (MR-Linac), and 0.80 (CCTA), outperforming comparison models in 57% of cases with limited statistical differences.

Conclusion: MAGIC provides an effective, lightweight, and flexible solution for multi-modality cardiac substructure segmentation, simplifying computational requirements for clinical implementation.

摘要: 心脏亚结构在胸部放射治疗计划中至关重要，以最小化辐射诱发心脏病的风险。深度学习（DL）提供了减少勾画负担的高效方法，但缺乏对不同模态和重叠结构的泛化能力。本研究提出并验证了一种模态无关图像级联（MAGIC），用于全面且多模态的心脏亚结构分割。MAGIC通过基于nnU-Net的U形主干网络的复制编码和解码分支实现，保留了单一模型的功能。从模拟CT（Sim-CT）、低场MR-Linac和心脏CT血管造影（CCTA）模态中手动勾画的20个心脏亚结构（心脏、腔室、大血管、瓣膜、冠状动脉和传导节点）用于训练（n=76）、验证（n=15）和测试（n=30）MAGIC。12个比较模型（三个模态中的四个分割子组）进行了等效训练。所有方法在训练效率和参考轮廓上进行了比较，使用Dice相似系数（DSC）和双尾Wilcoxon符号秩检验（阈值p<0.05）。平均DSC分数为Sim-CT 0.75（0.16）、MR-Linac 0.68（0.21）和CCTA 0.80（0.16）。MAGIC在57%的案例中优于比较模型，统计差异有限。MAGIC提供了一种高效且准确的分割解决方案，轻量级且能够在单一模型中分割多模态和重叠结构。MAGIC通过简化计算需求并为临床环境提供无与伦比的灵活性，进一步实现了临床应用。

</details>


### [540] [Modality-AGnostic Image Cascade (MAGIC) for Multi-Modality Cardiac Substructure Segmentation](https://arxiv.org/abs/2506.10797)
**中文标题：多模态心脏子结构分割的模态无关级联方法（MAGIC）**

*Nicholas Summerfield,Qisheng He,Alex Kuo,Ahmed I. Ghanem,Simeng Zhu,Chase Ruff,Joshua Pan,Anudeep Kumar,Prashant Nagpal,Jiwei Zhao,Ming Dong,Carri K. Glide-Hurst*

Main category: physics.med-ph

TL;DR: 本文提出了一种名为MAGIC的多模态心脏子结构分割方法，通过单一模型实现对不同模态和重叠结构的高效分割，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 心脏子结构在胸部放射治疗规划中至关重要，但现有深度学习方法在多模态和重叠结构分割上缺乏通用性。

Method: MAGIC基于nnU-Net的U形架构，通过复制的编码和解码分支实现多模态分割，并在Sim-CT、MR-Linac和CCTA三种模态上进行了训练和测试。

Result: MAGIC在57%的案例中优于对比模型，平均DSC分数分别为Sim-CT 0.75、MR-Linac 0.68和CCTA 0.80。

Conclusion: MAGIC提供了一种轻量级、高效的多模态分割解决方案，简化了临床计算需求并提高了灵活性。

摘要: 心脏子结构在胸部放射治疗规划中至关重要，以降低辐射诱发心脏病的风险。深度学习（DL）提供了减少勾画负担的高效方法，但在不同模态和重叠结构上缺乏通用性。本研究提出并验证了一种名为MAGIC的模态无关级联方法，用于全面且多模态的心脏子结构分割。MAGIC通过基于nnU-Net的U形架构的复制编码和解码分支实现，保留了单一模型的功能。从模拟CT（Sim-CT）、低场MR-Linac和心脏CT血管造影（CCTA）三种模态中手动勾画的20个心脏子结构（心脏、腔室、大血管、瓣膜、冠状动脉和传导节点）用于训练（n=76）、验证（n=15）和测试（n=30）MAGIC。同时训练了12个对比模型（三种模态的四个分割子组）。所有方法在训练效率和参考勾画上通过Dice相似系数（DSC）和双尾Wilcoxon符号秩检验（阈值p<0.05）进行比较。平均DSC分数为Sim-CT 0.75(0.16)、MR-Linac 0.68(0.21)和CCTA 0.80(0.16)。MAGIC在57%的案例中优于对比模型，统计差异有限。MAGIC提供了一种轻量级且高效的分割解决方案，能够在单一模型中分割多模态和重叠结构，并通过简化计算需求和提供无与伦比的临床灵活性，进一步推动临床实施。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [541] [HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration](https://arxiv.org/abs/2506.10401)
**中文标题：HPCTransCompile：一个用于高性能CUDA转译和LLM初步探索的AI编译器生成数据集**

*Jiaqi Lv,Xufeng He,Yanchen Liu,Xu Dai,Yang Hu,Shouyi Yin*

Main category: cs.DC

TL;DR: The paper introduces HPCTransCompile, a framework for generating high-performance CUDA and platform code pairs using AI compiler and optimization technology, addressing the lack of quality datasets for CUDA transpilation. It also proposes HPCTransEval, a benchmark for evaluating LLM performance in CUDA transpilation.


<details>
  <summary>Details</summary>
Motivation: The dominance of CUDA in parallel computing requires performance portability to other platforms, but existing methods for CUDA transpilation face limitations in coverage, generalizability, and development costs. Additionally, LLMs lack high-quality datasets for effective CUDA transpilation.

Method: The paper proposes a framework leveraging AI compiler and automatic optimization technology to generate high-performance CUDA and platform code pairs. It includes a graph-based data augmentation method and introduces HPCTransEval for evaluating LLM performance.

Result: Experiments on CUDA-to-CPU transpilation show the framework significantly improves CUDA transpilation, demonstrating LLMs' potential to address CUDA ecosystem compatibility challenges.

Conclusion: The framework and benchmark enhance CUDA transpilation and highlight LLMs' capability to tackle compatibility issues in the CUDA ecosystem.

摘要: 深度学习的快速发展推动了模型参数和计算需求的指数级增长。NVIDIA GPU及其基于CUDA的软件生态系统为并行计算提供了强大支持，显著缓解了计算瓶颈。同时，由于用户编程习惯的培养和GPU的高性能，CUDA生态系统在并行软件领域确立了主导地位。这种主导地位要求其他硬件平台支持基于CUDA的软件，并具备性能可移植性。然而，由于并行编程范式和硬件架构的差异，将CUDA代码转译到其他平台面临重大挑战。现有方法依赖于语言扩展、领域特定语言（DSL）或编译器，但在工作负载覆盖范围和通用性方面存在局限性。此外，这些方法通常需要高昂的开发成本。最近，LLM在各个垂直领域展现出非凡潜力，尤其是在代码相关任务中。然而，现有LLM在CUDA转译，特别是高性能代码方面的表现仍不理想。这一局限的主要原因在于缺乏高质量的训练数据集。为解决这些挑战，我们提出了一种利用AI编译器和自动优化技术生成高性能CUDA及对应平台代码对的新框架。我们进一步通过基于图的数据增强方法增强了该框架，并引入了HPCTransEval，一个用于评估LLM在CUDA转译中性能的基准。我们以CUDA到CPU的转译为例，在领先的LLM上进行了实验。结果表明，我们的框架显著改善了CUDA转译，凸显了LLM在解决CUDA生态系统兼容性挑战方面的潜力。

</details>


### [542] [HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration](https://arxiv.org/abs/2506.10401)
**中文标题：HPCTransCompile：一个用于高性能CUDA代码转换和LLM初步探索的AI编译器生成数据集**

*Jiaqi Lv,Xufeng He,Yanchen Liu,Xu Dai,Yang Hu,Shouyi Yin*

Main category: cs.DC

TL;DR: 本文提出了一种基于AI编译器和自动优化技术的高性能CUDA代码转换框架，通过图数据增强方法生成高质量训练数据集，并引入评估基准HPCTransEval。实验表明，该框架显著提升了LLM在CUDA代码转换中的性能。


<details>
  <summary>Details</summary>
Motivation: 由于CUDA生态系统在并行计算中的主导地位，其他硬件平台需要支持CUDA代码以实现性能可移植性。然而，CUDA代码转换面临编程范式和硬件架构差异的挑战，现有方法在覆盖范围和通用性上存在局限，且开发成本高。此外，缺乏高质量训练数据集限制了LLM在CUDA代码转换中的表现。

Method: 提出了一种生成高性能CUDA代码及其对应平台代码对的框架，结合AI编译器和自动优化技术，并采用图数据增强方法提升数据质量。同时，引入HPCTransEval基准评估LLM在CUDA代码转换中的性能。

Result: 实验以CUDA到CPU代码转换为案例，结果表明该框架显著提升了LLM在CUDA代码转换中的性能，验证了LLM在解决CUDA生态系统兼容性问题上的潜力。

Conclusion: 该框架为CUDA代码转换提供了高效解决方案，并通过高质量数据集和评估基准推动了LLM在该领域的应用。

摘要: 深度学习的快速发展推动了模型参数和计算需求的指数级增长。NVIDIA GPU及其基于CUDA的软件生态系统为并行计算提供了强大支持，显著缓解了计算瓶颈。同时，由于用户编程习惯的培养和GPU的高性能，CUDA生态系统在并行软件领域确立了主导地位。这种主导地位要求其他硬件平台支持基于CUDA的软件以实现性能可移植性。然而，由于并行编程范式和硬件架构的差异，将CUDA代码转换为其他平台代码面临重大挑战。现有方法依赖于语言扩展、领域特定语言（DSL）或编译器，但在工作负载覆盖范围和通用性上存在局限。此外，这些方法通常需要高昂的开发成本。最近，LLM在多个垂直领域展现出非凡潜力，尤其是在代码相关任务中。然而，现有LLM在CUDA代码转换（尤其是高性能代码）中的表现仍不理想。这一局限的主要原因在于缺乏高质量的训练数据集。为解决这些问题，我们提出了一种基于AI编译器和自动优化技术的高性能CUDA代码及其对应平台代码对生成框架。我们进一步通过图数据增强方法提升框架性能，并引入HPCTransEval基准以评估LLM在CUDA代码转换中的表现。我们以CUDA到CPU代码转换为案例，在领先的LLM上进行了实验。结果表明，该框架显著提升了CUDA代码转换性能，凸显了LLM在解决CUDA生态系统兼容性挑战中的潜力。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [543] [FASCIST-O-METER: Classifier for Neo-fascist Discourse Online](https://arxiv.org/abs/2506.10789)
**中文标题：法西斯测量仪：在线新法西斯主义话语分类器**

*Rudy Alexandro Garrido Veliz,Martin Semmann,Chris Biemann,Seid Muhie Yimam*

Main category: cs.CY

TL;DR: The paper introduces a neo-fascist coding scheme for digital discourse, develops classification models using NLP, and highlights the prevalence of neo-fascist rhetoric online.


<details>
  <summary>Details</summary>
Motivation: To address the growing threat of neo-fascism in Western societies by developing tools to detect and analyze its discourse online.

Method: Developed a neo-fascist coding scheme, collected data from neo-fascist forums, crowdsourced annotations, and fine-tuned SLMs and LLMs for classification.

Result: Successfully created the first classification models for neo-fascist discourse, revealing its prevalence in targeted forums.

Conclusion: Continued research and action against neo-fascist discourse are essential for protecting democratic societies.

摘要: 新法西斯主义是一种政治和社会意识形态，过去十年在美国及其他西方社会中显著增长。它对民主及其针对的少数群体构成严重威胁，需要采取积极行动以防止其升级。本研究首次提出了一种针对美国社会背景下数字话语的新法西斯主义编码方案，由政治学研究人员监督。我们的工作填补了自然语言处理（NLP）与政治学在这一现象之间的空白。此外，为了测试编码方案，我们收集了大量来自知名新法西斯主义团体（如Iron March和Stormfront.org论坛）的互联网活动，并将指南应用于收集到的帖子子集。通过众包，我们标注了一千条被标记为新法西斯主义或非新法西斯主义的帖子。利用这些标注数据，我们对小型语言模型（SLMs）和大型语言模型（LLMs）进行了微调和测试，获得了首批新法西斯主义话语分类模型。我们发现此类论坛中新法西斯主义言论的普遍性使其成为未来研究的理想目标。在进行NLP研究时，社会背景是新法西斯主义言论的关键考量因素。最后，为了民主社会的福祉，必须继续并加强对这类政治运动的抵制工作。免责声明：本研究专注于检测文本中的新法西斯主义内容，类似于其他仇恨言论分析，不对个人或组织进行标记。

</details>


### [544] [LLM-Driven Personalized Answer Generation and Evaluation](https://arxiv.org/abs/2506.10829)
**中文标题：基于大语言模型的个性化答案生成与评估**

*Mohammadreza Molavi,Mohammadreza Tavakoli,Mohammad Moein,Abdolali Faraji,Gábor Kismihók*

Main category: cs.CY

TL;DR: The paper explores using LLMs to generate personalized answers for online learners, showing that examples improve response quality.


<details>
  <summary>Details</summary>
Motivation: To enhance online learning by providing personalized answers tailored to individual learners' questions, reducing educator workload.

Method: Developed a framework and dataset using StackExchange, tested LLMs in 0-shot, 1-shot, and few-shot scenarios, and evaluated answers via BERTScore, LLM, and human assessments.

Result: LLMs performed better when given examples of desired answers, significantly improving personalized response quality.

Conclusion: LLMs can effectively generate personalized answers for learners, especially when provided with contextual examples.

摘要: 在线学习因其灵活性和可访问性而迅速发展。个性化，即适应个体学习者的需求，对于提升学习体验至关重要，尤其是在线环境中。个性化的一个关键方面是为学习者提供针对其具体问题的定制答案。因此，本文探讨了大语言模型（LLMs）在生成个性化答案方面的潜力，以增强学习者的参与度并减轻教育工作者的负担。为了评估LLMs在此背景下的有效性，我们利用StackExchange平台在语言学习和编程两个领域进行了全面研究。我们开发了一个框架和数据集用于验证自动生成的个性化答案。随后，我们使用不同的策略（包括零样本、单样本和少样本场景）生成了个性化答案。生成的答案通过三种方法进行评估：1. BERTScore，2. LLM评估，以及3. 人工评估。我们的研究结果表明，为LLMs提供期望答案的示例（来自学习者或类似学习者）可以显著提升LLMs为个体学习者定制回答的能力。

</details>


### [545] [FASCIST-O-METER: Classifier for Neo-fascist Discourse Online](https://arxiv.org/abs/2506.10789)
**中文标题：法西斯主义测量仪：针对在线新法西斯主义言论的分类器**

*Rudy Alexandro Garrido Veliz,Martin Semmann,Chris Biemann,Seid Muhie Yimam*

Main category: cs.CY

TL;DR: 本文提出了一种针对美国新法西斯主义在线言论的分类器，填补了自然语言处理与政治科学之间的研究空白，并通过标注数据集训练了小型和大型语言模型，首次实现了对新法西斯主义言论的分类。


<details>
  <summary>Details</summary>
Motivation: 新法西斯主义在西方国家尤其是美国迅速蔓延，对民主和少数群体构成严重威胁。为了遏制其发展，需要采取行动。本文旨在通过自然语言处理技术，开发一种能够识别新法西斯主义言论的分类器，为相关研究提供工具。

Method: 研究首先制定了一套针对美国社会背景的新法西斯主义编码方案，并从知名新法西斯主义论坛（如Iron March和Stormfront.org）收集了大量在线活动数据。通过众包方式标注了一千条帖子（分为新法西斯主义和非新法西斯主义），并利用这些数据对小型和大型语言模型进行微调和测试。

Result: 研究发现，新法西斯主义言论在相关论坛中普遍存在，验证了编码方案的有效性。通过训练的语言模型首次实现了对新法西斯主义言论的分类，为后续研究提供了基础。

Conclusion: 新法西斯主义言论对社会构成严重威胁，需要持续研究和行动以维护民主社会。本文的分类器填补了研究空白，并强调了社会背景在自然语言处理研究中的重要性。

摘要: 新法西斯主义是一种政治和社会意识形态，过去十年在美国及其他西方社会中显著增长。它对民主及其针对的少数群体构成严重威胁，需要采取积极行动以避免局势升级。本研究首次提出了一种针对美国社会背景的新法西斯主义数字言论编码方案，由政治科学研究人员监督完成，填补了自然语言处理与政治科学之间的研究空白。为测试编码方案，我们从知名新法西斯主义团体（如Iron March和Stormfront.org论坛）收集了大量互联网活动数据，并将编码方案应用于部分帖子。通过众包方式，我们标注了一千条帖子，分为新法西斯主义和非新法西斯主义两类。利用这些标注数据，我们对小型和大型语言模型进行了微调和测试，首次实现了对新法西斯主义言论的分类模型。研究发现，此类论坛中新法西斯主义言论普遍存在，是未来研究的理想目标。在进行自然语言处理研究时，社会背景是新法西斯主义言论的关键考量因素。最后，为维护民主社会的福祉，必须持续推动针对此类政治运动的研究。免责声明：本研究专注于检测文本中的新法西斯主义内容，类似于其他仇恨言论分析，不对个人或组织进行标签化。

</details>


### [546] [LLM-Driven Personalized Answer Generation and Evaluation](https://arxiv.org/abs/2506.10829)
**中文标题：基于大型语言模型的个性化答案生成与评估**

*Mohammadreza Molavi,Mohammadreza Tavakoli,Mohammad Moein,Abdolali Faraji,Gábor Kismihók*

Main category: cs.CY

TL;DR: 本文探讨了利用大型语言模型（LLMs）为学习者生成个性化答案的潜力，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在线学习的灵活性和可访问性使其快速发展，而个性化学习体验是提升学习效果的关键。本文旨在利用LLMs为学习者提供定制化答案，以增强学习参与度并减轻教育者负担。

Method: 研究基于StackExchange平台，在语言学习和编程两个领域展开。开发了验证自动生成个性化答案的框架和数据集，并采用0-shot、1-shot和few-shot策略生成答案。通过BERTScore、LLM评估和人工评估三种方法对答案进行评价。

Result: 实验结果表明，为LLMs提供学习者或类似学习者的示例答案，能显著提升其生成个性化答案的能力。

Conclusion: LLMs在生成个性化学习答案方面具有显著潜力，尤其是在提供示例的情况下效果更佳。

摘要: 在线学习因其灵活性和可访问性而迅速发展。个性化学习是提升学习体验的关键，尤其是在线环境中。个性化的重要方面是为学习者提供针对其具体问题的定制答案。因此，本文探讨了大型语言模型（LLMs）为学习者生成个性化答案的潜力，从而增强学习参与度并减轻教育者负担。为评估LLMs在此背景下的有效性，我们在StackExchange平台上开展了语言学习和编程两个领域的综合研究。我们开发了一个框架和数据集，用于验证自动生成的个性化答案。随后，我们采用0-shot、1-shot和few-shot策略生成了个性化答案。生成的答案通过三种方法进行评估：1. BERTScore，2. LLM评估，3. 人工评估。研究结果表明，为LLMs提供学习者或类似学习者的示例答案，能显著提升其针对个体学习者需求定制答案的能力。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [547] [Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs](https://arxiv.org/abs/2506.10054)
**中文标题：Omni-DPO：一种用于大语言模型动态偏好学习的双视角范式**

*Shangpin Peng,Weinong Wang,Zhuotao Tian,Senqiao Yang,Xing Wu,Haotian Xu,Chengquan Zhang,Takashi Isobe,Baotian Hu,Min Zhang*

Main category: cs.LG

TL;DR: Omni-DPO introduces a dual-perspective optimization framework for dynamic preference learning in LLMs, improving data utilization and performance by weighting samples based on inherent quality and model learning dynamics.


<details>
  <summary>Details</summary>
Motivation: Existing DPO-based approaches treat all preference pairs uniformly, ignoring variations in quality and learning utility, leading to suboptimal performance. Omni-DPO addresses this by dynamically weighting samples.

Method: Omni-DPO jointly considers the inherent quality of preference pairs and the model's evolving performance, adaptively weighting samples during training for better data utilization.

Result: Omni-DPO outperforms baselines, with Gemma-2-9b-it beating Claude 3 Opus by 6.7 points on Arena-Hard and excelling in mathematical reasoning tasks.

Conclusion: Omni-DPO is effective and robust, demonstrating superior performance and generalization across tasks, with code and models made available.

摘要: 直接偏好优化（DPO）因其简单高效成为基于人类反馈的强化学习（RLHF）的核心技术。然而，现有的基于DPO的方法通常对所有偏好对一视同仁，忽略了其固有质量和学习效用的关键差异，导致数据利用和性能不佳。为解决这一问题，我们提出了Omni-DPO，一种双视角优化框架，同时考虑（1）每个偏好对的固有质量；（2）模型在这些对上的动态表现。通过根据数据质量和模型学习动态自适应地加权样本，Omni-DPO实现了更有效的训练数据利用和更好的性能。在各种模型和基准测试上的实验结果表明了Omni-DPO的优越性和泛化能力。在文本理解任务中，使用Omni-DPO微调的Gemma-2-9b-it在Arena-Hard基准测试上显著领先Claude 3 Opus达6.7分。在数学推理任务中，Omni-DPO在所有基准测试中均优于基线方法，为我们的方法的有效性和鲁棒性提供了强有力的实证证据。代码和模型将在https://github.com/pspdada/Omni-DPO上提供。

</details>


### [548] [Textual Bayes: Quantifying Uncertainty in LLM-Based Systems](https://arxiv.org/abs/2506.10060)
**中文标题：文本贝叶斯：量化基于大型语言模型系统中的不确定性**

*Brendan Leigh Ross,Noël Vouitsis,Atiyeh Ashari Ghomi,Rasa Hosseinzadeh,Ji Xin,Zhaoyan Liu,Yi Sui,Shiyi Hou,Kin Kwan Leung,Gabriel Loaiza-Ganem,Jesse C. Cresswell*

Main category: cs.LG

TL;DR: The paper introduces a Bayesian approach to quantify uncertainty in LLM-based systems by treating prompts as textual parameters, using a novel MCMC algorithm (MHLP) for inference, and demonstrating improved accuracy and uncertainty quantification.


<details>
  <summary>Details</summary>
Motivation: Accurately quantifying uncertainty in LLMs is challenging due to their black-box nature and sensitivity to prompts, limiting their use in high-stakes domains.

Method: The paper proposes viewing LLM-based systems through a Bayesian lens, interpreting prompts as textual parameters, and introduces MHLP, a novel MCMC algorithm combining prompt optimization with standard MCMC methods.

Result: Empirical results show improvements in predictive accuracy and uncertainty quantification across various benchmarks.

Conclusion: The work provides a viable path to integrate Bayesian methods into LLMs, enhancing reliability and calibration in LLM-based systems.

摘要: 尽管大型语言模型（LLMs）在解决现实世界中的复杂任务方面能力日益增强，但准确量化其不确定性仍是一个关键且未解决的问题，这限制了它们在高风险领域的应用。这一挑战因许多最先进LLMs的闭源、黑盒特性而进一步加剧。此外，基于LLM的系统对绑定它们的提示（prompts）可能非常敏感，而这些提示通常需要大量手动调整（即提示工程）。在本研究中，我们通过贝叶斯视角来解决这些问题。我们将提示视为统计模型中的文本参数，从而能够利用少量训练数据对这些提示进行贝叶斯推断。这一新颖视角不仅能够对模型的文本参数及其下游预测进行原则性的不确定性量化，还能结合以自由文本形式表达的关于这些参数的先验信念。为了进行贝叶斯推断（即使对于研究充分的数据模态也是一个难题），我们引入了“通过LLM提议的Metropolis-Hastings”（MHLP），这是一种结合了提示优化技术与标准MCMC方法的新型马尔可夫链蒙特卡罗（MCMC）算法。MHLP是对现有LLM管道的即插即用修改，包括那些完全依赖闭源模型的管道。实验表明，我们的方法在一系列LLM基准测试和不确定性量化任务中均提高了预测准确性和不确定性量化（UQ）能力。更广泛地说，我们的工作展示了将丰富的贝叶斯方法融入LLM时代的可行路径，为更可靠和校准的基于LLM的系统铺平了道路。

</details>


### [549] [Learning to Collaborate Over Graphs: A Selective Federated Multi-Task Learning Approach](https://arxiv.org/abs/2506.10102)
**中文标题：基于图的选择性联邦多任务学习方法**

*Ahmed Elbakary,Chaouki Ben Issaid,Mehdi Bennis*

Main category: cs.LG

TL;DR: A novel federated multi-task learning method uses cross-client similarity and a feature anchor for personalized learning, with graph-based regularization and community detection to ensure efficient and fair collaboration.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of personalized learning in federated settings while maintaining communication efficiency and preventing negative collaboration among clients.

Method: Proposes a feature anchor for compact representation, shares lightweight classification heads, and uses dynamic graph-based regularization with community detection to group similar clients.

Result: Outperforms state-of-the-art baselines on heterogeneous datasets, showing superior computation/communication efficiency and fairness.

Conclusion: The method effectively enables personalized learning, ensures positive collaboration, and improves efficiency and fairness in federated multi-task learning.

摘要: 我们提出了一种新颖的联邦多任务学习方法，利用跨客户端相似性为每个客户端实现个性化学习。为了避免将整个模型传输到参数服务器，我们提出了一种通信高效的方案，引入了特征锚点——一个紧凑的向量表示，总结了从客户端本地类别学习到的特征。该特征锚点与服务器共享，以考虑本地客户端的分布。此外，客户端共享分类头（轻量级线性层），并执行基于图的正则化以实现客户端之间的协作。通过将客户端之间的协作建模为动态图并持续更新和优化该图，我们可以应对客户端的任何漂移。为了确保有益的知识转移并防止负面协作，我们采用了一种基于社区检测的方法，将该动态图划分为同质社区，最大化每个社区内任务相似性的总和（表示为图边的权重）。这种机制将协作限制在高度相似的客户端之间，确保积极的交互并保持个性化。在两个异构数据集上的大量实验表明，我们的方法显著优于现有基线。此外，我们展示了该方法在计算和通信效率上的优越性，并促进了客户端之间的公平性。

</details>


### [550] [GRAIL: A Benchmark for GRaph ActIve Learning in Dynamic Sensing Environments](https://arxiv.org/abs/2506.10120)
**中文标题：GRAIL：动态感知环境中图主动学习的基准**

*Maryam Khalid,Akane Sano*

Main category: cs.LG

TL;DR: GRAIL is a benchmarking framework for evaluating graph-based active learning (AL) in dynamic environments, introducing metrics for effectiveness, diversity, and user burden.


<details>
  <summary>Details</summary>
Motivation: Existing graph AL methods are evaluated on static datasets and focus only on accuracy, ignoring user-centric factors like diversity and adaptability in dynamic settings.

Method: GRAIL introduces a benchmarking framework with novel metrics to assess AL strategies in dynamic environments, using real-life human sensor data.

Result: Experiments reveal trade-offs between prediction performance and user burden, showing limitations in current AL strategies and the need for balanced approaches.

Conclusion: GRAIL highlights the importance of balancing node importance, query diversity, and network topology for effective AL in dynamic environments.

摘要: 基于图的主动学习（AL）利用图结构高效优先标记查询，降低标签成本和用户负担，适用于健康监测、人类行为分析和传感器网络等应用。通过识别战略位置的节点，图AL在保持模型性能的同时减少数据收集需求，成为动态环境中的有力工具。然而，现有图AL方法通常在静态图数据集上评估，且主要关注预测准确性，忽视了用户中心考量如采样多样性、查询公平性和动态环境的适应性。为填补这一空白，我们提出GRAIL，一种新颖的基准框架，用于评估动态现实环境中的图AL策略。GRAIL引入新指标评估持续有效性、多样性和用户负担，全面评估不同条件下的AL方法。在动态真实人类传感器数据上的广泛实验揭示了预测性能与用户负担之间的权衡，凸显了现有AL策略的局限性。GRAIL证明了平衡节点重要性、查询多样性和网络拓扑的重要性，为动态环境中的图AL解决方案提供了评估机制。

</details>


### [551] [Self-Predictive Representations for Combinatorial Generalization in Behavioral Cloning](https://arxiv.org/abs/2506.10137)
**中文标题：行为克隆中组合泛化的自预测表示**

*Daniel Lawson,Adriana Hugessen,Charlotte Cloutier,Glen Berseth,Khimya Khetarpal*

Main category: cs.LG

TL;DR: The paper proposes a method called $\text{BYOL-}\gamma$ augmented GCBC to improve combinatorial generalization in goal-conditioned behavioral cloning by learning temporally consistent state representations, avoiding contrastive samples or TD learning.


<details>
  <summary>Details</summary>
Motivation: Goal-conditioned behavioral cloning (GCBC) struggles with zero-shot generalization to novel state-goal pairs due to lack of temporal consistency in state representations. The paper aims to address this by leveraging successor representations.

Method: The authors introduce $\text{BYOL-}\gamma$ augmented GCBC, a representation learning objective that approximates successor representations without contrastive samples or TD learning, enhancing temporal consistency.

Result: The method achieves competitive performance on tasks requiring combinatorial generalization, demonstrating its effectiveness.

Conclusion: The proposed $\text{BYOL-}\gamma$ augmented GCBC successfully improves combinatorial generalization in GCBC by learning temporally consistent representations, offering a simpler alternative to existing methods.

摘要: 行为克隆（BC）方法通过监督学习（SL）从人类示范中学习策略，在机器人等领域非常有效。目标条件化这些策略使得单个通用策略能够捕捉离线数据集中的多样化行为。尽管目标条件化行为克隆（GCBC）方法在训练任务上表现良好，但它们未必能零样本泛化到需要处理新颖状态-目标对的任务，即组合泛化。这一限制部分归因于BC学习的状态表示缺乏时间一致性；如果时间相关的状态被编码为相似的潜在表示，那么新颖状态-目标对的分布外差距将会减小。因此，在表示空间中鼓励这种时间一致性应有助于组合泛化。后继表示（successor representations）很好地体现了这一特性，它编码了从当前状态访问的未来状态分布。然而，先前学习后继表示的方法依赖于对比样本、时间差分（TD）学习或两者。本文提出了一种简单而有效的表示学习目标——$\text{BYOL-}\gamma$增强的GCBC，它不仅能在有限MDP情况下理论上近似后继表示而无需对比样本或TD学习，而且在一系列需要组合泛化的挑战性任务中表现出色。

</details>


### [552] [Interpreting learned search: finding a transition model and value function in an RNN that plays Sokoban](https://arxiv.org/abs/2506.10138)
**中文标题：解读学习搜索：在玩推箱子的RNN中找到转移模型和价值函数**

*Mohammad Taufeeque,Aaron David Tucker,Adam Gleave,Adrià Garriga-Alonso*

Main category: cs.LG

TL;DR: The paper reverse-engineers a convolutional RNN trained to play Sokoban, revealing mechanisms akin to bidirectional search, including directional activations acting as a value function and specialized kernels forming a transition model.


<details>
  <summary>Details</summary>
Motivation: To understand how a model-free reinforcement learning-trained RNN solves Sokoban puzzles and leverages test-time compute, revealing interpretable mechanisms.

Method: Analyzed the RNN's activations and kernels, identifying directional channels as value functions and specialized kernels as transition models, while noting unique aspects like separate box consideration.

Result: The RNN's mechanisms resemble bidirectional search, with directional activations guiding backtracking and pruning, and kernels forming paths, though state representation is not unified.

Conclusion: The RNN's learned mechanisms are interpretable and analogous to classic search components, despite differences like separate box processing and layered representations.

摘要: 我们部分逆向工程了一个通过无模型强化学习训练的卷积循环神经网络（RNN），该网络用于玩推箱子游戏。先前的研究发现，该网络通过更多的测试时间计算解决了更多关卡。我们的分析揭示了与经典双向搜索组件类似的几种机制。对于每个方块，RNN通过特定方向的通道激活表示其计划。这些状态-动作激活类似于价值函数——其大小决定了何时回溯以及哪个计划分支保留下来。专门的核将这些激活（包含计划和价值）向前和向后扩展以形成路径，构成一个转移模型。该算法在某些方面也与经典搜索不同。状态表示并不统一；相反，网络分别考虑每个箱子。每一层都有自己的计划表示和价值函数，增加了搜索深度。远非难以理解，通过无模型训练学习的网络机制可以利用测试时间计算，并以熟悉的术语进行解释。

</details>


### [553] [A Comparative Study of Machine Learning Techniques for Early Prediction of Diabetes](https://arxiv.org/abs/2506.10180)
**中文标题：机器学习技术用于糖尿病早期预测的比较研究**

*Mowafaq Salem Alzboon,Mohammad Al-Batah,Muhyeeddin Alqaraleh,Ahmad Abuashour,Ahmad Fuad Bader*

Main category: cs.LG

TL;DR: The study compares machine learning techniques for diabetes prediction, finding Neural Networks and Random Forests most effective with accuracies of 78.57% and 76.30%, respectively.


<details>
  <summary>Details</summary>
Motivation: Diabetes is a growing health concern, and early detection is vital. The paper explores machine learning's potential to improve diabetes prediction.

Method: The study evaluates Logistic Regression, Decision Tree, Random Forest, k-Nearest Neighbors, Naive Bayes, Support Vector Machine, Gradient Boosting, and Neural Network using the Pima Indians Diabetes dataset.

Result: Neural Networks achieved the highest accuracy (78.57%), followed by Random Forests (76.30%).

Conclusion: Machine learning, particularly Neural Networks and Random Forests, can effectively predict diabetes and serve as early detection tools.

摘要: 在许多国家，糖尿病正成为一个重大的健康问题，早期识别和管理至关重要。使用机器学习算法预测糖尿病已取得令人鼓舞的结果。本研究利用皮马印第安人糖尿病数据集，评估了几种机器学习方法在糖尿病预测中的效果。该数据集包含768名患者的信息，如年龄、BMI和血糖水平。评估的技术包括逻辑回归、决策树、随机森林、k近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络。结果表明，神经网络算法的表现最佳，准确率为78.57%，其次是随机森林方法，准确率为76.30%。研究暗示机器学习算法有助于糖尿病预测，并可作为高效的早期检测工具。

</details>


### [554] [Optimizing Genetic Algorithms with Multilayer Perceptron Networks for Enhancing TinyFace Recognition](https://arxiv.org/abs/2506.10184)
**中文标题：利用多层感知器网络优化遗传算法以增强TinyFace识别**

*Mohammad Subhi Al-Batah,Mowafaq Salem Alzboon,Muhyeeddin Alqaraleh*

Main category: cs.LG

TL;DR: The paper explores optimizing MLP networks using GA and PCA for TinyFace recognition, showing GA's superiority in complex datasets and PCA's benefits in simpler ones.


<details>
  <summary>Details</summary>
Motivation: To enhance TinyFace recognition by optimizing MLP networks through feature selection (GA) and dimensionality reduction (PCA), addressing performance in diverse datasets.

Method: 1) Baseline MLP training, 2) GA-based feature selection, 3) PCA-based dimension reduction, tested on TinyFace, Heart Disease, and Iris datasets.

Result: GA improved accuracy in complex datasets by identifying critical features, while PCA worked better in low-dimensional, noise-free datasets.

Conclusion: Feature selection (GA) and dimensionality reduction (PCA) interdependently enhance MLP performance, offering practical guidelines for machine learning tasks.

摘要: 本研究通过涉及TinyFace、心脏病和Iris三个不同数据集的严格实验过程，对多层感知器（MLP）网络进行了实证研究。研究概述包括三种关键方法：a）使用默认设置进行MLP基线训练，b）基于遗传算法（GA）的特征选择优化，c）基于主成分分析（PCA）的降维。结果显示这些技术对性能的影响：PCA在低维和无噪声数据集中表现出优势，而GA通过准确识别关键特征在复杂数据集中持续提高准确性。比较表明，特征选择和降维在提升MLP性能中具有相互依赖的作用。本研究为特征工程和神经网络参数优化的文献提供了贡献，并为广泛的机器学习任务提供了实用指南。

</details>


### [555] [Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment](https://arxiv.org/abs/2506.10186)
**中文标题：通过旋转对齐实现可扩展的非等变3D分子生成**

*Yuhui Ding,Thomas Hofmann*

Main category: cs.LG

TL;DR: The paper proposes a scalable non-equivariant 3D molecule generation method by learning rotational alignments, achieving performance comparable to equivariant models with improved efficiency.


<details>
  <summary>Details</summary>
Motivation: Equivariant diffusion models, while effective, are limited by specialized architectures that hinder scalability and efficiency. This paper aims to relax these constraints while maintaining high performance.

Method: The approach learns sample-dependent SO(3) transformations to align molecules in a latent space, then trains a non-equivariant diffusion model on these aligned representations.

Result: The method outperforms non-equivariant models, matches state-of-the-art equivariant models in quality, and improves training and sampling efficiency.

Conclusion: The proposed method offers a scalable alternative to equivariant models without sacrificing performance, with potential for broader applications.

摘要: 等变扩散模型在3D分子生成中表现出色，这些模型通过使用SE(3)-等变去噪网络结合了3D分子的欧几里得对称性。然而，专门的等变架构限制了扩散模型的可扩展性和效率。本文提出了一种放松此类等变约束的方法。具体而言，我们的方法为每个分子学习一个样本依赖的SO(3)变换，以构建对齐的潜在空间。随后在对齐表示上训练一个非等变扩散模型。实验结果表明，我们的方法显著优于先前报道的非等变模型，其样本质量与最先进的等变扩散模型相当，并提供了更高的训练和采样效率。代码可在https://github.com/skeletondyh/RADM获取。

</details>


### [556] [Detecting Sockpuppetry on Wikipedia Using Meta-Learning](https://arxiv.org/abs/2506.10314)
**中文标题：利用元学习检测维基百科上的傀儡账户**

*Luc Raszewski,Christine De Kock*

Main category: cs.LG

TL;DR: The paper proposes using meta-learning to improve sockpuppet detection on Wikipedia by adapting to author-specific behaviors, outperforming pre-trained models in precision.


<details>
  <summary>Details</summary>
Motivation: To enhance the detection of malicious sockpuppets on Wikipedia by addressing the limitations of prior methods, which struggle with adaptability to specific author behaviors and limited text data.

Method: The paper applies meta-learning, a technique that trains models across multiple tasks to optimize rapid adaptation to new sockpuppet-group writing styles.

Result: Meta-learning significantly improves prediction precision compared to pre-trained models, demonstrating better performance in data-scarce settings.

Conclusion: Meta-learning advances sockpuppetry detection by enabling models to adapt quickly to new behaviors, with potential benefits for open editing platforms. The release of a new dataset supports future research.

摘要: 在维基百科上检测恶意傀儡账户对于维护互联网上可靠信息的获取和防止虚假信息的传播至关重要。先前的机器学习方法依赖于风格和元数据特征，但未能优先适应特定作者的行为。因此，这些方法在建模特定傀儡账户群体的行为时效果不佳，尤其是在文本数据有限的情况下。为解决这一问题，我们提出应用元学习，这是一种机器学习技术，旨在通过跨多个任务训练模型来提高在数据稀缺环境中的性能。元学习优化模型，使其能够快速适应新的傀儡账户群体的写作风格。我们的结果表明，与预训练模型相比，元学习显著提高了预测的精确度，标志着在开放编辑平台上打击傀儡账户行为的进步。我们发布了一个新的傀儡账户调查数据集，以促进未来在傀儡账户和元学习领域的研究。

</details>


### [557] [Cross-Learning Between ECG and PCG: Exploring Common and Exclusive Characteristics of Bimodal Electromechanical Cardiac Waveforms](https://arxiv.org/abs/2506.10212)
**中文标题：心电与心音信号的交叉学习：探索双模态机电心脏波形的共同与独有特性**

*Sajjad Karimi,Amit J. Shah,Gari D. Clifford,Reza Sameni*

Main category: cs.LG

TL;DR: The paper explores the relationship between ECG and PCG signals, using machine learning to reconstruct one from the other, highlighting the superiority of nonlinear models and challenges in cross-subject scenarios.


<details>
  <summary>Details</summary>
Motivation: To understand the distinct and overlapping information in ECG and PCG signals, their potential for mutual reconstruction, and biomarker extraction under varying physiological conditions.

Method: Employed linear and nonlinear machine learning models, including non-causal LSTM networks, on the EPHNOGRAM dataset of simultaneous ECG-PCG recordings during rest and exercise.

Result: Nonlinear models, especially non-causal LSTM, performed best. ECG reconstruction from PCG was easier than the reverse. Exercise and cross-subject scenarios posed challenges, but envelope-based modeling improved generalizability. Clinically relevant ECG biomarkers could be estimated from PCG.

Conclusion: The study enhances understanding of ECG and PCG relationships, with potential applications in multimodal cardiac monitoring technologies.

摘要: 同步心电图（ECG）和心音图（PCG）通过分别捕捉心脏的电活动和机械活动，提供了心脏功能的多模态视角。然而，这些信号的独特和重叠信息内容，以及它们在相互重建和生物标志物提取方面的潜力，尤其是在不同生理条件和个体间，尚未完全理解。
在本研究中，我们利用EPHNOGRAM数据集中的静息和运动状态下的同步ECG-PCG记录，系统地研究了ECG和PCG的共同与独有特性。我们采用了一系列线性和非线性机器学习模型，包括非因果LSTM网络，以从另一种模态重建每种模态，并分析了因果关系、生理状态和跨受试者变异性的影响。结果表明，非线性模型，特别是非因果LSTM，提供了更优的重建性能，其中从PCG重建ECG比反向重建更为可行。运动和跨受试者场景带来了显著挑战，但基于包络的建模利用瞬时振幅特征显著提高了跨模态学习的跨受试者泛化能力。此外，我们还证明，临床相关的ECG生物标志物（如基准点和QT间期）可以在跨受试者设置下从PCG中估计。
这些发现增进了我们对机电心脏模态之间关系的理解，包括波形特性和心脏事件的时间，为新型多模态心脏监测技术提供了潜在应用。

</details>


### [558] [Provably Learning from Language Feedback](https://arxiv.org/abs/2506.10341)
**中文标题：可证明地从语言反馈中学习**

*Wanqiao Xu,Allen Nie,Ruijie Zheng,Aditya Modi,Adith Swaminathan,Ching-An Cheng*

Main category: cs.LG

TL;DR: The paper formalizes Learning from Language Feedback (LLF), introduces a complexity measure called transfer eluder dimension, and presents a no-regret algorithm (HELiX) for solving LLF problems with performance guarantees.


<details>
  <summary>Details</summary>
Motivation: To provide a principled framework for learning from language feedback, addressing the lack of theoretical grounding in existing empirical demonstrations.

Method: The paper formalizes LLF, introduces transfer eluder dimension as a complexity measure, and develops the HELiX algorithm for no-regret learning from language feedback.

Result: The transfer eluder dimension captures the learning complexity of LLF, and HELiX performs well empirically, even when standard LLM prompting fails.

Conclusion: The work lays the foundation for principled interactive learning from language feedback, with theoretical and empirical validation.

摘要: 通过观察和语言反馈进行交互式学习是一个日益受到关注的领域，这得益于大型语言模型（LLM）代理的出现。尽管已有令人印象深刻的实证演示，但目前仍缺乏对这些决策问题的原则性框架。本文中，我们形式化了“从语言反馈中学习”（LLF）问题，提出了足够的假设以在潜在奖励的情况下实现学习，并引入了“转移规避维度”作为复杂性度量来表征LLF问题的难度。我们表明，转移规避维度捕捉了反馈中信息改变LLF问题学习复杂性的直觉。我们展示了在某些情况下，从丰富的语言反馈中学习可以比从奖励中学习快指数级。我们开发了一种无遗憾算法HELiX，它通过顺序交互可证明地解决LLF问题，其性能保证与问题的转移规避维度成比例。在多个实证领域中，我们表明HELiX即使在重复提示LLM不可靠的情况下也能表现良好。我们的贡献标志着设计基于通用语言反馈的原则性交互式学习算法的第一步。

</details>


### [559] [Can We Infer Confidential Properties of Training Data from LLMs?](https://arxiv.org/abs/2506.10364)
**中文标题：我们能否从大语言模型中推断出训练数据的机密属性？**

*Penguin Huang,Chhavi Yadav,Ruihan Wu,Kamalika Chaudhuri*

Main category: cs.LG

TL;DR: The paper investigates whether sensitive properties of training data can be inferred from large language models (LLMs) and introduces PropInfer, a benchmark for evaluating such attacks, demonstrating their success.


<details>
  <summary>Details</summary>
Motivation: To explore the vulnerability of LLMs in revealing confidential dataset-level properties, such as patient demographics or disease prevalence, during fine-tuning, which has not been studied before.

Method: Introduces PropInfer, a benchmark task for property inference in LLMs, and proposes two tailored attacks: a prompt-based generation attack and a shadow-model attack using word frequency signals.

Result: Empirical evaluations show the attacks are successful, revealing a previously unrecognized vulnerability in LLMs.

Conclusion: LLMs are susceptible to property inference attacks, highlighting a new security concern in their deployment for sensitive applications.

摘要: 大型语言模型（LLMs）越来越多地在特定领域的数据集上进行微调，以支持医疗、金融和法律等领域的应用。这些微调数据集通常具有敏感和机密的属性（如患者人口统计或疾病流行率），这些属性本不应被泄露。虽然先前的工作研究了判别模型（如图像分类模型）和生成模型（如图像数据的GANs）的属性推断攻击，但这些攻击是否适用于LLMs尚不清楚。在这项工作中，我们引入了PropInfer，一个用于评估LLMs在问答和聊天完成两种微调范式下属性推断的基准任务。基于ChatDoctor数据集，我们的基准包括多种属性类型和任务配置。我们还提出了两种定制攻击：基于提示的生成攻击和利用词频信号的影子模型攻击。对多个预训练LLMs的实证评估表明，我们的攻击是成功的，揭示了LLMs中一个先前未被识别的漏洞。

</details>


### [560] [LaMAGIC2: Advanced Circuit Formulations for Language Model-Based Analog Topology Generation](https://arxiv.org/abs/2506.10235)
**中文标题：LaMAGIC2：基于语言模型的模拟拓扑生成的高级电路公式**

*Chen-Chia Chang,Wan-Hsuan Lin,Yikang Shen,Yiran Chen,Xin Zhang*

Main category: cs.LG

TL;DR: LaMAGIC2 introduces a succinct float-input canonical formulation (SFCI) for language model-based analog topology generation, improving efficiency and precision over prior methods.


<details>
  <summary>Details</summary>
Motivation: Current methods for analog topology design are inefficient and lack precision sensitivity, necessitating a more robust framework.

Method: LaMAGIC2 uses an identifier-based representation (SFCI) to reduce token length complexity and enhance numeric precision sensitivity.

Result: LaMAGIC2 achieves 34% higher success rates under tight tolerances and 10X lower MSEs, with improved transferability for larger circuits.

Conclusion: LaMAGIC2 establishes a robust framework for analog topology generation, outperforming prior methods in efficiency and precision.

摘要: 现代应用对模拟拓扑设计的定制化需求使得自动化设计变得至关重要，但目前的方法需要大量人工操作。现有最先进的工作采用序列到序列的方法，并通过监督微调语言模型来生成用户指定的拓扑。然而，其电路公式效率低下，原因是其令牌长度复杂度为O(|V|²)，且对数值输入的精度敏感性较低。本文提出了LaMAGIC2，一种基于语言模型的模拟拓扑生成的简洁浮点输入规范公式（SFCI）。SFCI通过基于标识符的表示改进组件类型识别，将令牌长度复杂度降低至O(|V|)，并增强数值精度敏感性，从而在严格容差下实现更好的性能。实验表明，与先前方法相比，LaMAGIC2在0.01的严格容差下实现了34%更高的成功率，且均方误差降低了10倍。LaMAGIC2在顶点较多的电路中还表现出更好的可迁移性，最高提升58.5%。这些进展使LaMAGIC2成为模拟拓扑生成的强大框架。

</details>


### [561] [Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning](https://arxiv.org/abs/2506.10378)
**中文标题：通过因果表示学习发现语言模型的层次化潜在能力**

*Jikai Jin,Vasilis Syrgkanis,Sham Kakade,Hanlin Zhang*

Main category: cs.LG

TL;DR: The paper proposes a causal representation learning framework to identify latent capability factors in language models, revealing a hierarchical causal structure among general problem-solving, instruction-following, and mathematical reasoning abilities.


<details>
  <summary>Details</summary>
Motivation: Faithful evaluation of language model capabilities is hindered by methodological challenges like confounding effects and high computational costs. The study aims to uncover latent capabilities causally.

Method: A causal representation learning framework models benchmark performance as linear transformations of latent capability factors, controlling for base model variations as confounders.

Result: A three-node linear causal structure explains performance variations, showing a clear hierarchy from general problem-solving to instruction-following and mathematical reasoning.

Conclusion: The study highlights the importance of controlling base model variations to uncover causal relationships among latent capabilities, offering insights beyond numerical rankings.

摘要: 对语言模型能力的忠实评估对于指导模型开发至关重要。然而，该领域的严格因果评估面临重大方法学挑战，包括复杂的混杂效应和与广泛重新训练相关的高计算成本。为解决这些挑战，我们提出了一个因果表示学习框架，其中观察到的基准性能被建模为少数潜在能力因素的线性变换。关键的是，这些潜在因素在适当控制基础模型作为共同混杂因素后被识别为因果相关的。将这种方法应用于包含超过1500个模型在Open LLM Leaderboard六个基准上评估的综合数据集，我们确定了一个简洁的三节点线性因果结构，可靠地解释了观察到的性能变化。进一步解释这一因果结构提供了超越简单数值排名的实质性科学见解：具体而言，我们揭示了一个明确的因果方向，从一般问题解决能力开始，通过指令遵循熟练度，最终达到数学推理能力。我们的结果强调了在评估过程中仔细控制基础模型变化的关键作用，这是准确揭示潜在模型能力之间因果关系的必要步骤。

</details>


### [562] [Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series](https://arxiv.org/abs/2506.10412)
**中文标题：Time-IMM：一种用于不规则多模态多元时间序列的数据集与基准**

*Ching Chang,Jeehyun Hwang,Yidan Shi,Haixin Wang,Wen-Chih Peng,Tien-Fu Chen,Wei Wang*

Main category: cs.LG

TL;DR: Time-IMM is a dataset and benchmark for irregular multimodal time series, addressing real-world data challenges like varying sampling rates and missingness. IMM-TSF, the benchmark library, improves forecasting by modeling multimodality explicitly.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks assume clean, regular time series, while real-world data is irregular and multimodal. Time-IMM bridges this gap by providing a dataset and tools for realistic analysis.

Method: Time-IMM categorizes nine types of irregularity and introduces IMM-TSF, a benchmark with fusion modules for asynchronous integration and evaluation.

Result: Explicitly modeling multimodality on irregular data significantly improves forecasting performance.

Conclusion: Time-IMM and IMM-TSF advance time series analysis under real-world conditions, providing tools for better forecasting.

摘要: 现实应用中的时间序列数据（如医疗、气候建模和金融）通常是不规则、多模态且混乱的，具有不同的采样率、异步模态和普遍缺失。然而，现有基准通常假设数据是干净、规则采样的单模态数据，导致研究与实际部署之间存在显著差距。我们提出了Time-IMM，这是一个专门设计用于捕捉多模态多元时间序列中因果驱动的不规则性的数据集。Time-IMM代表了九种不同类型的时间序列不规则性，分为触发型、约束型和人为型机制。作为数据集的补充，我们引入了IMM-TSF，一个用于不规则多模态时间序列预测的基准库，支持异步集成和现实评估。IMM-TSF包括专门的融合模块，如时间戳到文本的融合模块和多模态融合模块，支持基于最近平均和基于注意力的集成策略。实证结果表明，显式建模多模态不规则时间序列数据能显著提升预测性能。Time-IMM和IMM-TSF为在现实条件下推进时间序列分析提供了基础。数据集可在https://www.kaggle.com/datasets/blacksnail789521/time-imm/data公开获取，基准库可在https://anonymous.4open.science/r/IMMTSF_NeurIPS2025访问。

</details>


### [563] [Deep Learning-Based Digitization of Overlapping ECG Images with Open-Source Python Code](https://arxiv.org/abs/2506.10617)
**中文标题：基于深度学习的重叠心电图图像数字化方法及开源Python代码**

*Reza Karbasi,Masoud Rahimi,Abdol-Hossein Vahabie,Hadi Moradi*

Main category: cs.LG

TL;DR: The paper proposes a two-stage deep learning pipeline to accurately digitize overlapping ECG images, achieving superior performance over baseline methods.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of digitizing paper-based ECG recordings, especially those with overlapping signals, which is under-addressed in existing methods.

Method: A U-Net based segmentation network isolates the primary ECG trace, followed by an adaptive grid detection module to convert the mask into a time-series signal.

Result: The U-Net achieved an IoU of 0.87, and the digitization method outperformed baselines with lower MSE (0.0010 vs. 0.0015) and higher Pearson Correlation (0.9644 vs. 0.9366) for non-overlapping signals, and similar improvements for overlapping signals.

Conclusion: The proposed method significantly enhances digitization accuracy, especially for overlapping signals, and provides a reliable foundation for converting analog ECG records into digital data.

摘要: 本文解决了纸质心电图（ECG）记录准确数字化的持续挑战，特别关注了信号重叠导致的单导联受损问题——这是现有方法中常见但未充分解决的问题。我们提出了一种两阶段流程来克服这一限制。第一阶段采用基于U-Net的分割网络，通过训练包含重叠信号和自定义数据增强的数据集，准确分离主要ECG轨迹。第二阶段通过自适应网格检测模块将精炼的二进制掩码转换为时间序列信号，提高了对不同ECG格式和尺度的适应性。实验结果表明，我们的方法在细粒度分割任务中U-Net架构的IoU达到0.87。重要的是，与现有基线技术相比，我们的数字化方法在非重叠和重叠ECG样本中均表现出更优性能。对于非重叠信号，我们的方法实现了均方误差（MSE）0.0010和皮尔逊相关系数（rho）0.9644，而基线分别为0.0015和0.9366。对于信号重叠样本，我们的方法MSE为0.0029，rho为0.9641，显著优于基线的0.0178和0.8676。这项工作展示了一种有效策略，显著提高了数字化准确性，尤其是在信号重叠情况下，为将模拟ECG记录可靠转换为可分析的数字化数据奠定了坚实基础，适用于现代研究和临床应用。实现代码已公开于GitHub仓库：https://github.com/masoudrahimi39/ECG-code。

</details>


### [564] [Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering](https://arxiv.org/abs/2506.10751)
**中文标题：Neural在ArchEHR-QA 2025中的应用：基于证据的临床问答的代理提示优化**

*Sai Prasanna Teja Reddy Bogireddy,Abrar Majeedi,Viswanatha Reddy Gajjala,Zhuoyan Xu,Siddhant Rai,Vaishnav Potlapalli*

Main category: cs.LG

TL;DR: The paper introduces Neural, a method for clinical QA that decouples evidence retrieval and answer synthesis, using prompt optimization to achieve high performance without fine-tuning.


<details>
  <summary>Details</summary>
Motivation: To improve automated QA over EHRs by addressing the challenges of precise evidence retrieval and faithful answer generation with limited supervision.

Method: Decouples the task into evidence identification and answer synthesis, uses DSPy's MIPROv2 for prompt optimization, and employs self-consistency voting to enhance evidence recall.

Result: Achieved an overall score of 51.5 on the test set, outperforming zero-shot and few-shot prompting by over 20 and 10 points, respectively.

Conclusion: Data-driven prompt optimization is a cost-effective alternative to model fine-tuning for clinical QA, enhancing AI reliability in healthcare.

摘要: 电子健康记录（EHR）上的自动问答（QA）可以为临床医生和患者填补关键信息缺口，但其需要精确的证据检索和有限监督下的忠实答案生成。本文介绍了Neural，这是BioNLP 2025 ArchEHR-QA共享任务中基于证据的临床QA的亚军方法。我们的方法将任务分解为（1）句子级证据识别和（2）带有明确引用的答案合成。在每个阶段，我们使用DSPy的MIPROv2优化器自动探索提示空间，并在开发集上联合调整指令和少量示例。自我一致性投票方案进一步提高了证据召回率而不牺牲精确度。在隐藏测试集上，我们的方法获得了51.5的总分，位居第二，同时分别比标准的零样本和少样本提示高出20分和10分以上。这些结果表明，数据驱动的提示优化是高风险临床QA中模型微调的经济高效替代方案，提升了医疗保健中AI助手的可靠性。

</details>


### [565] [The Diffusion Duality](https://arxiv.org/abs/2506.10892)
**中文标题：扩散对偶**

*Subham Sekhar Sahoo,Justin Deschenaux,Aaron Gokaslan,Guanghan Wang,Justin Chiu,Volodymyr Kuleshov*

Main category: cs.LG

TL;DR: The paper introduces Duo, a method that improves uniform-state discrete diffusion models by leveraging insights from Gaussian diffusion, achieving faster training and sampling while outperforming autoregressive models on some benchmarks.


<details>
  <summary>Details</summary>
Motivation: Uniform-state discrete diffusion models are promising for fast text generation but underperform compared to autoregressive and masked diffusion models. The paper aims to bridge this gap by utilizing properties of Gaussian diffusion.

Method: The method, Duo, transfers techniques from Gaussian diffusion to discrete diffusion. It includes a curriculum learning strategy guided by Gaussian processes to speed up training and Discrete Consistency Distillation to enable few-step generation.

Result: Models trained with Duo surpass autoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Sampling is accelerated by two orders of magnitude through Discrete Consistency Distillation.

Conclusion: Duo successfully narrows the performance gap between uniform-state discrete diffusion models and autoregressive models, demonstrating the potential of leveraging Gaussian diffusion insights in discrete settings.

摘要: 均匀状态离散扩散模型因其固有的自我纠正能力而有望实现快速文本生成，但其性能通常不及自回归模型和掩码扩散模型。本研究通过利用一个关键发现来缩小这一性能差距：均匀状态扩散过程自然源于底层的高斯扩散。我们的方法Duo将高斯扩散的强大技术迁移到离散扩散中，以改进训练和采样。首先，我们引入了一种由高斯过程指导的课程学习策略，通过减少方差将训练速度提高了一倍。采用课程学习训练的模型在7个基准测试中的3个上超越了自回归模型的零样本困惑度。其次，我们提出了离散一致性蒸馏，将连续设置中的一致性蒸馏技术适配到离散场景中。该算法通过将采样速度提高两个数量级，实现了扩散语言模型中的少步生成。代码和模型检查点可在项目页面获取：http://s-sahoo.github.io/duo

</details>


### [566] [Robustly Improving LLM Fairness in Realistic Settings via Interpretability](https://arxiv.org/abs/2506.10922)
**中文标题：通过可解释性在现实场景中稳健提升大型语言模型的公平性**

*Adam Karvonen,Samuel Marks*

Main category: cs.LG

TL;DR: The paper reveals that simple anti-bias prompts fail in realistic hiring scenarios, introduces internal bias mitigation to robustly reduce biases in LLMs, and shows its effectiveness across multiple models.


<details>
  <summary>Details</summary>
Motivation: LLMs are increasingly used in high-stakes hiring, but existing bias mitigation methods fail in realistic settings, necessitating a more robust approach.

Method: The study identifies and neutralizes sensitive attribute directions in model activations using internal bias mitigation, applying affine concept editing at inference time.

Result: Internal bias mitigation reduces biases to very low levels (typically under 1%) across commercial and open-source models while maintaining performance.

Conclusion: Practitioners should adopt realistic evaluations and internal mitigation strategies for equitable LLM deployment in hiring.

摘要: 大型语言模型（LLMs）越来越多地用于高风险的招聘应用，直接影响人们的职业和生活。虽然先前研究表明简单的反偏见提示可以在受控评估中消除人口统计偏见，但我们发现这些方法在引入现实情境细节时会失效。我们通过内部偏见缓解来解决这些问题：通过识别并中和模型激活中的敏感属性方向，我们在所有测试场景中实现了稳健的偏见减少。在领先的商业模型（GPT-4o、Claude 4 Sonnet、Gemini 2.5 Flash）和开源模型（Gemma-2 27B、Gemma-3、Mistral-24B）中，我们发现添加现实情境（如公司名称、公开职业页面的文化描述和选择性招聘限制）会引发显著的种族和性别偏见（面试率差异高达12%）。这些偏见在所有测试模型和场景中一致表现为偏向黑人候选人和女性候选人。此外，模型可以从细微线索（如大学背景）推断人口统计信息并产生偏见，而这些偏见甚至在检查模型的思维链推理时也不可见。为解决这些局限性，我们的内部偏见缓解方法识别种族和性别相关方向，并在推理时应用仿射概念编辑。尽管使用简单合成数据集的方向，干预方法仍能稳健地推广，将偏见持续降至极低水平（通常低于1%，始终低于2.5%），同时基本保持模型性能。我们的研究结果表明，部署LLMs进行招聘的从业者应采用更现实的评估方法，并考虑内部缓解策略以实现公平结果。

</details>


### [567] [GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models](https://arxiv.org/abs/2506.10946)
**中文标题：GUARD：基于数据归因的大语言模型引导性遗忘与保留**

*Evelyn Ma,Duo Zhou,Peizhi Niu,Huiting Zhou,Huan Zhang,Olgica Milenkovic,S. Rasoul Etesami*

Main category: cs.LG

TL;DR: GUARD is a novel framework for guided unlearning in large language models (LLMs) that uses data attribution to mitigate unintended forgetting while preserving valuable information. It introduces a lightweight proxy metric and adaptive unlearning weights, achieving significant retention improvements without compromising unlearning effectiveness.


<details>
  <summary>Details</summary>
Motivation: Unlearning in LLMs is crucial for regulatory compliance, copyright protection, and privacy, but existing methods often degrade model utility by inadvertently removing valuable data. The paper addresses this by exploring data-level factors to improve retention during unlearning.

Method: GUARD introduces a lightweight proxy data attribution metric to quantify alignment between forget and retain sets. It then designs an unlearning objective with adaptive, nonuniform weights inversely proportional to proxy scores, reallocating unlearning power to minimize retention loss.

Result: GUARD significantly enhances retention while maintaining unlearning performance, reducing utility sacrifice by up to 194.92% in terms of Truth Ratio when forgetting 10% of training data, as demonstrated on the TOFU benchmark.

Conclusion: GUARD provides a computationally efficient and effective solution for LLM unlearning, balancing retention and forgetting through data attribution and adaptive weighting, with rigorous theoretical guarantees and empirical validation.

摘要: 由于法规遵从、版权保护和隐私问题，大语言模型（LLM）的遗忘变得越来越重要。然而，LLM遗忘的一个关键挑战是无意遗忘，即删除特定数据时无意中损害了模型的效用及其对有价值、期望信息的保留。尽管先前的工作主要集中在架构创新上，但数据级因素对遗忘性能的影响仍未得到充分探索。因此，现有方法在遗忘高影响力数据时往往导致保留性能下降。为解决这一问题，我们提出了GUARD——一种基于数据归因的引导性遗忘与保留框架。GUARD的核心是一种专为LLM遗忘设计的轻量级代理数据归因指标，用于量化遗忘集与保留集之间的“对齐”关系，同时保持计算效率。在此基础上，我们设计了一种新颖的遗忘目标，为样本分配自适应、非均匀的遗忘权重，与代理归因分数成反比。通过这种遗忘能力的重新分配，GUARD减轻了保留中的无意损失。我们提供了严格的理论保证，证明GUARD在保持与先前方法相当的遗忘指标的同时，显著提高了保留性能。在TOFU基准测试中，针对多种LLM架构的广泛实验表明，GUARD在确保有效遗忘的同时，显著改善了效用保留。值得注意的是，在遗忘10%训练数据时，GUARD将保留集的效用损失（以Truth Ratio衡量）降低了高达194.92%。

</details>


### [568] [PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal Representation](https://arxiv.org/abs/2506.10351)
**中文标题：PhysioWave：一种用于生理信号表示的多尺度小波变换器**

*Yanlong Chen,Mattia Orlandi,Pierangelo Maria Rapa,Simone Benatti,Luca Benini,Yawei Li*

Main category: cs.LG

TL;DR: The paper introduces PhysioWave, a wavelet-based approach for analyzing physiological signals, addressing noise and non-stationarity. It includes pretrained models for EMG and ECG, and a multi-modal framework integrating EEG, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Physiological signals are often noisy and non-stationary, making traditional analysis methods ineffective. The paper aims to develop a robust wavelet-based approach to capture multi-scale features and improve signal representation.

Method: The method involves a wavelet-based architecture for multi-scale time-frequency analysis, pretrained models for EMG and ECG, and a unified multi-modal framework integrating EEG with learnable weighted fusion.

Result: The approach achieves superior performance in downstream tasks, outperforming existing methods in handling low SNR, inter-subject variability, and device mismatch.

Conclusion: The proposed wavelet-based architecture and multi-modal design advance physiological signal analysis, with potential applications in health monitoring and diagnostics.

摘要: 生理信号常受到运动伪影、基线漂移和其他低信噪比干扰的影响，这对分析提出了重大挑战。此外，这些信号表现出强烈的非平稳性，具有尖锐的峰值和持续演变的突变，使得传统的时域或滤波方法难以表示。为解决这些问题，本文提出了一种基于小波的生理信号分析方法，旨在捕捉各种生理信号中的多尺度时频特征。利用这一技术，首次引入了针对EMG和ECG的两个大规模预训练模型，在下游任务中实现了卓越性能并设定了新的基准。此外，通过整合预训练的EEG模型，构建了一个统一的多模态框架，其中每个模态通过其专用分支引导并通过可学习的加权融合进行融合。这一设计有效地解决了低信噪比、高受试者间变异性和设备不匹配等挑战，在多模态任务中优于现有方法。所提出的小波架构为多样生理信号的分析奠定了坚实基础，而多模态设计则指向下一代生理信号处理，对可穿戴健康监测、临床诊断和更广泛的生物医学应用具有潜在影响。

</details>


### [569] [Build the web for agents, not agents for the web](https://arxiv.org/abs/2506.10953)
**中文标题：为代理构建网络，而非为网络构建代理**

*Xing Han Lù,Gaurav Kamath,Marius Mosbach,Siva Reddy*

Main category: cs.LG

TL;DR: The paper proposes a shift from adapting AI web agents to human-designed interfaces to creating Agentic Web Interfaces (AWI) optimized for AI capabilities, outlining six design principles for safety, efficiency, and standardization.


<details>
  <summary>Details</summary>
Motivation: Current web agents struggle with human-designed interfaces, leading to inefficiencies and limitations. The paper advocates for a new paradigm where interfaces are specifically designed for AI agents to improve performance and reliability.

Method: Introduces the concept of Agentic Web Interface (AWI) and establishes six guiding principles for its design, focusing on safety, efficiency, and standardization.

Result: The proposed AWI framework aims to overcome limitations of existing interfaces, enabling more efficient and transparent web agent interactions.

Conclusion: A shift to agent-centric web interfaces is necessary for advancing web agent capabilities, requiring collaboration within the ML community.

摘要: 近年来，大型语言模型（LLMs）及其多模态对应模型的进步引发了人们对开发网络代理——能够在网络环境中自主导航并完成任务的人工智能系统——的极大兴趣。尽管在自动化复杂网络交互方面具有巨大潜力，但由于人类设计的界面与LLM能力之间的根本性不匹配，当前方法面临重大挑战。现有方法在处理庞大的DOM树、依赖附加信息的截图或通过API交互完全绕过用户界面时，均难以应对网络输入的固有复杂性。本立场文件主张网络代理研究的范式转变：与其迫使网络代理适应为人类设计的界面，不如开发一种专门为代理能力优化的新交互范式。为此，我们引入了代理网络界面（AWI）的概念，这是一种专为代理导航网站而设计的界面。我们确立了AWI设计的六项指导原则，强调安全性、效率和标准化，以兼顾所有主要利益相关者的利益。这一重构旨在克服现有界面的根本性限制，为更高效、可靠和透明的网络代理设计铺平道路，这将是更广泛的机器学习社区共同参与的合作努力。

</details>


### [570] [Time To Impeach LLM-as-a-Judge: Programs are the Future of Evaluation](https://arxiv.org/abs/2506.10403)
**中文标题：是时候废除LLM作为评判者：程序是评估的未来**

*Tzu-Heng Huang,Harit Vishwakarma,Frederic Sala*

Main category: cs.LG

TL;DR: The paper proposes PAJAMA, a program-based alternative to using LLMs as judges for evaluating model responses, addressing high costs, biases, and inflexibility by synthesizing executable programs for local use.


<details>
  <summary>Details</summary>
Motivation: Current use of LLMs as judges for evaluating responses is costly, unreliable, inflexible, and biased, necessitating a more efficient and adaptable solution.

Method: Introduces PAJAMA, which uses LLMs to synthesize executable judging programs that can be stored and run locally, offering cost savings, interpretability, and adaptability.

Result: PAJAMA improves judgment consistency by 15.83%, reduces biased responses by 23.7%, and outperforms LLM-as-a-judge on benchmarks like CHAT-HARD, with significantly lower costs.

Conclusion: Program-based judges like PAJAMA provide a superior, cost-effective, and bias-mitigated alternative to traditional LLM-as-a-judge methods.

摘要: 大型语言模型（LLM）被广泛用于评估LLM生成和回答的质量，但这带来了重大挑战：高昂的API成本、不确定的可靠性、不灵活的流程以及固有的偏见。为解决这些问题，我们提出了PAJAMA（Program-As-a-Judge for Automated Model Assessment），这是一种新的替代方案，它使用LLM合成可执行的评判程序，而非直接评分回答。这些合成的程序可以本地存储和运行，成本降低数个数量级，同时提供可解释和可审计的评判逻辑，且易于调整。基于程序的评判者减少了偏见，与基于Qwen2.5-14B的LLM评判者相比，评判一致性提高了15.83%，偏见回答平均减少了23.7%。当程序评判被提炼为模型时，PAJAMA在RewardBench的CHAT-HARD子集上优于LLM评判者，在Prometheus和JudgeLM数据集上分别超出指标2.19%和8.67%，且成本降低了三个数量级。

</details>


### [571] [Balanced Hyperbolic Embeddings Are Natural Out-of-Distribution Detectors](https://arxiv.org/abs/2506.10146)
**中文标题：平衡双曲嵌入是自然的分布外检测器**

*Tejaswi Kasarla,Max van Spengler,Pascal Mettes*

Main category: cs.LG

TL;DR: The paper proposes Balanced Hyperbolic Learning, a method using hierarchical hyperbolic embeddings to improve out-of-distribution detection, outperforming existing approaches.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the challenge of out-of-distribution recognition in deep learning by leveraging hyperbolic embeddings for better discrimination between in- and out-of-distribution samples.

Method: The authors introduce Balanced Hyperbolic Learning, which optimizes hierarchical distortion and balance in hyperbolic class embeddings, using them as prototypes for classification and extending scoring functions to hyperbolic space.

Result: Empirical evaluations show the method outperforms existing out-of-distribution approaches, other hyperbolic methods, and state-of-the-art contrastive methods across 13 datasets.

Conclusion: Hierarchical hyperbolic embeddings are effective for out-of-distribution detection and enable hierarchical generalization.

摘要: 分布外识别是深度学习中的一个重要且经过深入研究的问题，其目标是过滤掉不属于网络训练分布的样本。本文的结论很简单：良好的分层双曲嵌入更适合区分分布内和分布外样本。我们引入了平衡双曲学习，提出了一种双曲类嵌入算法，联合优化了分层失真和浅层与深层子层次之间的平衡。然后，我们将这些类嵌入用作双曲原型，对分布内数据进行分类。我们还概述了如何将现有的分布外评分函数推广到双曲原型上。在13个数据集和13个评分函数上的实证评估表明，我们的双曲嵌入在相同数据和相同骨干网络训练下优于现有的分布外方法。我们还表明，我们的双曲嵌入优于其他双曲方法，击败了最先进的对比方法，并天然支持分层分布外泛化。

</details>


### [572] [Geometric Regularity in Deterministic Sampling of Diffusion-based Generative Models](https://arxiv.org/abs/2506.10177)
**中文标题：基于扩散生成模型的确定性采样中的几何规律性**

*Defang Chen,Zhenyu Zhou,Can Wang,Siwei Lyu*

Main category: cs.LG

TL;DR: The paper uncovers a geometric regularity in deterministic sampling trajectories of diffusion-based generative models, showing they lie in low-dimensional subspaces with a consistent 'boomerang' shape. It proposes a dynamic programming-based scheme to optimize sampling time schedules, improving image generation with minimal computational overhead.


<details>
  <summary>Details</summary>
Motivation: The study aims to understand the geometric properties of deterministic sampling trajectories in diffusion-based generative models, which are currently not well-characterized, and leverage these insights to enhance sampling efficiency.

Method: The authors analyze the deterministic sampling dynamics of diffusion models, revealing low-dimensional subspace properties and a consistent trajectory shape. They propose a dynamic programming-based scheme to align sampling time schedules with the discovered trajectory structure.

Result: The discovered trajectory regularity allows for optimized sampling schedules, leading to superior image generation performance, especially with fewer function evaluations (5-10).

Conclusion: The findings highlight a fundamental geometric regularity in diffusion model sampling, enabling practical improvements in sampling efficiency and performance with minimal modifications to existing methods.

摘要: 基于扩散的生成模型利用随机微分方程（SDEs）及其等效的概率流常微分方程（ODEs），在复杂的高维数据分布与易于处理的先验分布之间建立平滑转换。本文揭示了确定性采样动力学中一个显著的几何规律性：每条模拟采样轨迹都位于一个极低维的子空间中，且所有轨迹无论模型架构、应用条件或生成内容如何，都呈现几乎相同的“回旋镖”形状。我们描述了这些轨迹的几个有趣特性，特别是在基于核估计数据建模的闭式解下。我们还通过提出一种基于动态规划的方案，将采样时间表与底层轨迹结构更好地对齐，展示了所发现轨迹规律性的实际应用。这一简单策略仅需对现有基于ODE的数值求解器进行最小修改，计算开销可忽略不计，并在仅需5~10次函数评估的区域中实现了更优的图像生成性能。

</details>


### [573] [Size-adaptive Hypothesis Testing for Fairness](https://arxiv.org/abs/2506.10586)
**中文标题：公平性的大小自适应假设检验**

*Antonio Ferrara,Francesco Cozzi,Alan Perotti,André Panisson,Francesco Bonchi*

Main category: cs.LG

TL;DR: The paper introduces a size-adaptive hypothesis-testing framework for fairness assessment, addressing statistical challenges in small and large demographic subgroups with Bayesian and Wald test approaches.


<details>
  <summary>Details</summary>
Motivation: Current fairness assessments are statistically brittle, ignoring sampling error and treating small subgroups the same as large ones, especially problematic in intersectional analyses with sparse data.

Method: A unified framework combining Wald tests for large subgroups (using Central-Limit results) and Bayesian Dirichlet-multinomial estimators for small subgroups, with Monte-Carlo credible intervals.

Result: The method provides interpretable, statistically rigorous decisions under varying data availability, validated on benchmark datasets.

Conclusion: The proposed framework offers a robust, evidence-based approach to fairness assessment, adaptable to subgroup sizes and intersectionality.

摘要: 确定算法决策系统是否歧视特定人口群体通常涉及将公平性指标的单一估计值与预定义阈值进行比较。这种做法在统计上是脆弱的：它忽略了抽样误差，并将小人口子群体与大群体同等对待。这一问题在交叉分析中尤为严重，其中多个敏感属性被联合考虑，导致更多更小的群体。随着这些群体变得更加细分，代表它们的数据变得过于稀疏，无法进行可靠估计，公平性指标产生过宽的置信区间，无法对潜在的不公平待遇得出有意义的结论。
  本文介绍了一种统一的大小自适应假设检验框架，将公平性评估转化为基于证据的统计决策。我们的贡献有两点。(i) 对于足够大的子群体，我们证明了统计奇偶差异的中心极限定理，从而得出解析置信区间和Wald检验，其I类（假阳性）误差保证在水平α。(ii) 对于长尾的小交叉群体，我们推导了一个完全贝叶斯的Dirichlet-多项式估计器；蒙特卡洛可信区间针对任何样本量进行校准，并随着数据的增加自然收敛于Wald区间。我们在基准数据集上实证验证了我们的方法，展示了我们的检验如何在数据可用性和交叉性不同的情况下提供可解释、统计严格的决策。

</details>


### [574] [Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning](https://arxiv.org/abs/2506.10629)
**中文标题：基于技能的迁移适应：信息几何、解耦与无监督强化学习的新目标**

*Yucheng Yang,Tianyi Zhou,Qiang He,Lei Han,Mykola Pechenizkiy,Meng Fang*

Main category: cs.LG

TL;DR: The paper analyzes the limitations of Mutual Information Skill Learning (MISL) in unsupervised reinforcement learning (URL) and proposes a new disentanglement metric (LSEPIN) and a Wasserstein distance-based objective (WSEP) to improve skill diversity and separability for better downstream task adaptation.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the lack of theoretical analysis in MISL for URL, particularly regarding how well learned skills can initialize downstream tasks, and proposes new methods to ensure skill diversity and separability.

Method: The authors introduce a disentanglement metric (LSEPIN) and an information-geometric analysis connecting it to task adaptation cost. They replace KL divergence with Wasserstein distance for better geometric properties, leading to a new objective (WSEP) and an algorithm (PWSEP).

Result: The proposed WSEP objective and PWSEP algorithm theoretically improve downstream task adaptation and discover more optimal initial policies compared to MISL.

Conclusion: The paper concludes that the proposed methods (LSEPIN, WSEP, and PWSEP) enhance skill learning for URL by ensuring better diversity and separability, leading to improved downstream task performance.

摘要: 无监督强化学习（URL）旨在为未见的下游任务学习通用技能。互信息技能学习（MISL）通过最大化状态与技能之间的互信息来解决URL问题，但缺乏足够的理论分析，例如其学习到的技能如何初始化下游任务的策略。本文的新理论分析表明，学习技能的多样性和可分离性对下游任务适应至关重要，但MISL并不一定保证这些特性。为了补充MISL，我们提出了一种新的解耦度量LSEPIN。此外，我们建立了LSEPIN与下游任务适应成本之间的信息几何联系。为了更好的几何性质，我们研究了一种新策略，用Wasserstein距离替代信息几何中的KL散度。我们将几何分析扩展到这一策略，从而提出了一个新的技能学习目标WSEP。理论证明WSEP有助于下游任务适应，并且比MISL能够发现更多的下游任务初始策略。最后，我们提出了另一种基于Wasserstein距离的算法PWSEP，理论上可以发现所有最优初始策略。

</details>


### [575] [Time Series Forecasting as Reasoning: A Slow-Thinking Approach with Reinforced LLMs](https://arxiv.org/abs/2506.10630)
**中文标题：时间序列预测作为推理：一种基于强化大语言模型的慢思考方法**

*Yucong Luo,Yitong Zhou,Mingyue Cheng,Jiahao Wang,Daoyu Wang,Tingyue Pan,Jintao Zhang*

Main category: cs.LG

TL;DR: The paper proposes Time-R1, a two-stage reinforcement fine-tuning framework for LLMs to enhance multi-step reasoning in time series forecasting, addressing limitations of fast-thinking methods and prompt engineering.


<details>
  <summary>Details</summary>
Motivation: Existing time series forecasting methods lack explicit reasoning processes, while LLMs with slow-thinking capabilities offer potential but face limitations like high computational costs and privacy risks. The paper aims to train LLMs for better time series reasoning.

Method: Time-R1 uses a two-stage approach: supervised fine-tuning for adaptation and reinforcement learning for generalization, with a multi-objective reward and GRIP for optimizing reasoning paths.

Result: Experiments show Time-R1 significantly improves forecasting performance across diverse datasets.

Conclusion: Time-R1 effectively enhances LLMs' reasoning for time series forecasting, outperforming traditional methods.

摘要: 为了推动时间序列预测（TSF）的发展，已有多种方法被提出以提高预测准确性，从统计技术发展到数据驱动的深度学习架构。尽管这些方法有效，但大多数仍遵循快速思考范式——依赖于提取历史模式并将其映射到未来值作为核心建模理念，缺乏包含中间时间序列推理的明确思考过程。同时，新兴的慢思考大语言模型（如OpenAI-o1）显示出卓越的多步推理能力，为解决这些问题提供了另一种途径。然而，仅靠提示工程存在一些局限性，包括高计算成本、隐私风险以及对深入领域特定时间序列推理的有限能力。为解决这些局限性，一种更有前景的方法是训练大语言模型以发展慢思考能力并获取强大的时间序列推理技能。为此，我们提出了Time-R1，一个两阶段强化微调框架，旨在增强大语言模型在时间序列预测中的多步推理能力。具体而言，第一阶段进行监督微调以实现预热适应，而第二阶段采用强化学习以提高模型的泛化能力。特别是，我们设计了一个专门用于时间序列预测的细粒度多目标奖励，并引入了GRIP（基于组的相对重要性策略优化），利用非均匀采样进一步鼓励和优化模型对有效推理路径的探索。实验表明，Time-R1在多样数据集上显著提高了预测性能。

</details>


### [576] [Data Shifts Hurt CoT: A Theoretical Study](https://arxiv.org/abs/2506.10647)
**中文标题：数据偏移损害思维链：一项理论研究**

*Lang Yin,Debangshu Banerjee,Gagandeep Singh*

Main category: cs.LG

TL;DR: The paper studies how data shifts (distribution shifts and data poisoning) harm the effectiveness of Chain of Thought (CoT) in solving the $k$-parity problem, revealing that CoT can lead to worse performance than direct prediction.


<details>
  <summary>Details</summary>
Motivation: Previous works on CoT rely on ideal assumptions (identical training/testing distributions and clean data), which don't hold in real-world scenarios. The paper aims to rigorously study the harm caused by data shifts.

Method: Focuses on the $k$-parity problem, analyzing the joint impact of distribution shifts and data poisoning on models trained with CoT decomposition.

Result: CoT can degrade performance on learning parity compared to direct prediction, and the paper provides a mechanistic explanation for this phenomenon.

Conclusion: Data shifts significantly harm CoT's effectiveness, highlighting the need for robustness in real-world applications.

摘要: 思维链（CoT）已被应用于各种大型语言模型（LLM），并被证明能有效提高输出质量。近期研究表明，Transformer在表达能力上存在绝对上限，因此无法解决许多计算难题。然而，借助CoT，Transformer被证明能有效解决一些难题，例如$k$-奇偶问题。但这些研究依赖于两个关键假设：（1）训练和测试分布相同，（2）训练数据无污染且推理步骤正确。然而，现实中这些假设并不总是成立。尽管数据偏移的风险已引起关注，但据我们所知，本研究首次严格分析了此类偏移的具体危害。聚焦于$k$-奇偶问题，本文研究了两种数据偏移（分布偏移和数据投毒）对通过成熟CoT分解训练的模型质量的联合影响。除了揭示一个令人惊讶的现象——CoT在学习奇偶问题上的表现比直接预测更差外，我们的技术结果还对此影响的机制原因提供了严格而全面的解释。

</details>


### [577] [Saturation Self-Organizing Map](https://arxiv.org/abs/2506.10680)
**中文标题：饱和自组织映射**

*Igor Urbanik,Paweł Gajewski*

Main category: cs.LG

TL;DR: The paper introduces Saturation Self-Organizing Maps (SatSOM), an extension of SOMs designed to mitigate catastrophic forgetting in continual learning by gradually reducing learning rates and neighborhood radii for well-trained neurons.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the issue of catastrophic forgetting in Self-Organizing Maps (SOMs) during continual learning, which limits their effectiveness in sequential tasks.

Method: SatSOM incorporates a saturation mechanism that reduces the learning rate and neighborhood radius of neurons as they accumulate information, thereby freezing well-trained neurons and redirecting learning to underutilized areas.

Result: The proposed SatSOM improves knowledge retention in continual learning scenarios by effectively managing neuron utilization and learning dynamics.

Conclusion: SatSOM successfully extends SOMs to better handle continual learning by preventing catastrophic forgetting through its saturation mechanism.

摘要: 持续学习对神经系统提出了根本性挑战，因为它们在面对顺序任务时常常遭受灾难性遗忘。自组织映射（SOMs）尽管具有可解释性和高效性，但也无法避免这一问题。本文提出了饱和自组织映射（SatSOM），这是SOMs的一种扩展，旨在改善持续学习场景中的知识保留。SatSOM引入了一种新颖的饱和机制，随着神经元积累信息，逐渐降低其学习率和邻域半径。这有效地冻结了训练良好的神经元，并将学习重定向到映射中未充分利用的区域。

</details>


### [578] [Hessian Geometry of Latent Space in Generative Models](https://arxiv.org/abs/2506.10632)
**中文标题：生成模型中潜在空间的Hessian几何**

*Alexander Lobashev,Dmitry Guskov,Maria Larchenko,Mikhail Tamm*

Main category: cs.LG

TL;DR: The paper introduces a method to analyze latent space geometry in generative models by reconstructing the Fisher information metric, revealing fractal phase transitions and nonlinear geodesic behavior at phase boundaries.


<details>
  <summary>Details</summary>
Motivation: To understand the complex geometry of latent spaces in generative models, particularly focusing on phase transitions and thermodynamic properties, which are not well-explored in existing literature.

Method: The method approximates the posterior distribution of latent variables to learn the log-partition function, defining the Fisher metric for exponential families. It is validated on Ising and TASEP models and applied to diffusion models.

Result: The method outperforms baselines in reconstructing thermodynamic quantities and reveals fractal phase transitions in diffusion models, with nonlinear geodesics at phase boundaries.

Conclusion: The findings provide new insights into the latent space structure of diffusion models, highlighting connections to phase transitions and nonlinear behavior.

摘要: 本文提出了一种分析生成模型潜在空间几何的新方法，包括统计物理模型和扩散模型，通过重建Fisher信息度量。该方法近似给定生成样本的潜在变量的后验分布，并利用其学习对数配分函数，从而定义指数族的Fisher度量。提供了理论收敛保证，并在Ising和TASEP模型上验证了该方法，在重建热力学量方面优于现有基线。应用于扩散模型时，该方法揭示了潜在空间中相变的分形结构，表现为Fisher度量的突变。我们证明，虽然测地线插值在单个相内近似线性，但在相边界处这种线性关系被破坏，扩散模型表现出关于潜在空间的发散Lipschitz常数。这些发现为扩散模型潜在空间的复杂结构及其与相变等现象的联系提供了新见解。源代码可在https://github.com/alobashev/hessian-geometry-of-diffusion-models获取。

</details>


### [579] [ConTextTab: A Semantics-Aware Tabular In-Context Learner](https://arxiv.org/abs/2506.10707)
**中文标题：ConTextTab：一种语义感知的表格上下文学习模型**

*Marco Spinaci,Marek Polewczyk,Maximilian Schambach,Sam Thelin*

Main category: cs.LG

TL;DR: ConTextTab combines semantic understanding with tabular in-context learning, outperforming SOTA models by leveraging real-world data and specialized embeddings.


<details>
  <summary>Details</summary>
Motivation: Current tabular ICL models either lack semantic understanding (trained on synthetic data) or struggle with context limitations (LLM-based). ConTextTab aims to merge the strengths of both approaches.

Method: ConTextTab integrates semantic understanding into a table-native ICL framework using specialized embeddings for different data modalities and training on large-scale real-world tabular data.

Result: The model achieves competitive performance across benchmarks and sets a new SOTA on the semantically rich CARTE benchmark.

Conclusion: ConTextTab successfully bridges the gap between semantic-rich and table-native ICL models, demonstrating superior performance on diverse tasks.

摘要: 表格上下文学习（ICL）最近在多项表格预测任务中取得了最先进的性能。此前仅适用于小型表格的分类问题，而TabPFN和TabICL等最新进展已将其扩展到更大的数据集。尽管当前表格原生ICL架构在结构上高效且适应表格数据结构，但由于仅基于合成数据训练，未能充分利用真实表格数据中的丰富语义和世界知识。另一方面，基于预训练大型语言模型（如TabuLa-8B）的表格ICL模型虽然具备深度语义理解和世界知识，但由于固有架构限制，仅能利用少量上下文。为了结合两者的优势，我们提出了ConTextTab，将语义理解和对齐整合到表格原生ICL框架中。通过为不同数据模态使用专用嵌入并在大规模真实表格数据上训练，我们的模型在广泛基准测试中与SOTA竞争，同时在语义丰富的CARTE基准上树立了新标准。

</details>


### [580] [ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems](https://arxiv.org/abs/2506.10955)
**中文标题：Error**

*Aayush Karan,Kulin Shah,Sitan Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

摘要: Error

</details>


### [581] [Efficiency Robustness of Dynamic Deep Learning Systems](https://arxiv.org/abs/2506.10831)
**中文标题：动态深度学习系统的效率鲁棒性**

*Ravishka Rathnasuriya,Tingxi Li,Zexin Xu,Zihe Song,Mirazul Haque,Simin Chen,Wei Yang*

Main category: cs.LG

TL;DR: The paper explores efficiency robustness in Dynamic Deep Learning Systems (DDLSs), categorizing efficiency attacks and analyzing adversarial strategies, while highlighting limitations of current defenses and the need for new mitigation approaches.


<details>
  <summary>Details</summary>
Motivation: DDLSs improve efficiency by adapting inference computation, but this dynamic behavior introduces new attack surfaces, particularly efficiency adversarial attacks that degrade system performance. The paper aims to systematically study these attacks and their impact.

Method: The paper presents a comprehensive taxonomy of efficiency attacks on DDLSs, categorizing them into three dynamic behaviors: attacks on dynamic computations per inference, dynamic inference iterations, and dynamic output production. It evaluates adversarial strategies and existing defenses.

Result: The study identifies key challenges in securing DDLSs against efficiency attacks and demonstrates the limitations of current defense mechanisms, emphasizing the need for novel mitigation strategies.

Conclusion: Future adaptive DDLSs require new defense approaches to counter efficiency attacks, as existing mechanisms are insufficient.

摘要: 深度学习系统（DLSs）越来越多地部署在实时应用中，包括资源受限的环境（如移动和物联网设备）。为了解决效率挑战，动态深度学习系统（DDLSs）根据输入复杂性调整推理计算，减少开销。尽管这种动态行为提高了效率，但也引入了新的攻击面。特别是效率对抗攻击利用这些动态机制降低系统性能。本文系统地探讨了DDLSs的效率鲁棒性，首次提出了效率攻击的综合分类法。我们基于三种动态行为对这些攻击进行分类：（i）针对每次推理动态计算的攻击，（ii）针对动态推理迭代的攻击，以及（iii）针对下游任务动态输出生成的攻击。通过深入评估，我们分析了针对DDLSs效率的对抗策略，并确定了保护这些系统的关键挑战。此外，我们研究了现有的防御机制，展示了它们对日益流行的效率攻击的局限性，以及需要新的缓解策略来保护未来的自适应DDLSs。

</details>


### [582] [Understanding In-Context Learning on Structured Manifolds: Bridging Attention to Kernel Methods](https://arxiv.org/abs/2506.10959)
**中文标题：理解结构化流形上的上下文学习：将注意力机制与核方法联系起来**

*Zhaiming Shen,Alexander Hsu,Rongjie Lai,Wenjing Liao*

Main category: cs.LG

TL;DR: The paper theoretically analyzes in-context learning (ICL) for regression of Hölder functions on manifolds, linking attention mechanisms to kernel methods and deriving generalization error bounds.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap in theoretical understanding of ICL, especially for structured geometric data, by exploring its connection to kernel methods and manifolds.

Method: Establishes a connection between attention mechanisms and kernel methods, then derives generalization error bounds for ICL on manifolds, focusing on prompt length and training tasks.

Result: Transformers achieve minimax regression rates for Hölder functions on manifolds, with error scaling exponentially with intrinsic manifold dimension, not ambient space.

Conclusion: The study provides foundational insights into the role of geometry in ICL and tools for analyzing nonlinear ICL models.

摘要: 尽管上下文学习（ICL）在自然语言和视觉领域取得了显著成功，但其理论理解——尤其是在结构化几何数据背景下——仍未得到探索。本研究首次对ICL在流形上Hölder函数回归的理论进行了探讨。通过建立注意力机制与经典核方法之间的新联系，我们推导出了基于提示长度和训练任务数量的泛化误差界。当观察到足够数量的训练任务时，变换器能够实现流形上Hölder函数的最小最大回归率，其误差随流形的内蕴维度而非环境空间维度呈指数级变化。我们的结果还揭示了泛化误差如何随训练任务数量变化，为变换器作为上下文算法学习器的复杂性提供了新的见解。这些发现为理解几何在ICL中的作用提供了基础性见解，并为研究非线性模型的ICL提供了新工具。

</details>


### [583] [Farseer: A Refined Scaling Law in Large Language Models](https://arxiv.org/abs/2506.10972)
**中文标题：Farseer：大型语言模型中的精细化缩放定律**

*Houyi Li,Wenzhen Zheng,Qiufeng Wang,Zhenyu Ding,Haoying Wang,Zili Wang,Shijie Xuyang,Ning Ding,Shuigeng Zhou,Xiangyu Zhang,Daxin Jiang*

Main category: cs.LG

TL;DR: Farseer introduces a refined scaling law for Large Language Models (LLMs) that improves predictive accuracy and reduces extrapolation error by 433%, enabling reliable evaluation of training strategies and optimal compute allocation.


<details>
  <summary>Details</summary>
Motivation: The high cost of training LLMs creates a scaling gap where small-scale insights fail to transfer to production systems, hindering innovation. Farseer aims to bridge this gap with a more accurate scaling law.

Method: Farseer constructs a model loss surface $L(N,D)$ to better fit empirical data, outperforming prior laws like Chinchilla's. It validates the approach by training 1,000 LLMs across diverse scales and configurations.

Result: Farseer reduces extrapolation error by 433% compared to Chinchilla's law, providing robust predictions for LLM performance across all $(N,D)$ settings and insights into optimal compute allocation.

Conclusion: Farseer's refined scaling law enhances predictive accuracy and generalizability, enabling confident extrapolation from small-scale studies to large-scale LLM training. All data and models are open-sourced to support further research.

摘要: 训练大型语言模型（LLM）的成本极高，这导致了一个关键的缩放鸿沟：小规模实验的见解往往无法转移到资源密集的生产系统中，从而阻碍了高效创新。为了弥合这一鸿沟，我们提出了Farseer，一种新颖且精细化的缩放定律，能够在不同规模下提供更高的预测准确性。通过系统构建模型损失表面$L(N,D)$，Farseer比之前的定律（如Chinchilla定律）显著更好地拟合了经验数据。我们的方法产生了准确、稳健且高度可泛化的预测，展示了出色的外推能力，将Chinchilla定律的外推误差降低了433%。这使得我们能够可靠地评估所有$(N,D)$设置下的竞争性训练策略，从而自信地将小规模消融研究的结论外推以预测大规模性能。此外，Farseer为计算资源的最优分配提供了新的见解，更好地反映了现代LLM训练的复杂需求。为了验证我们的方法，我们训练了约1,000个不同规模和配置的LLM，消耗了约300万NVIDIA H100 GPU小时。我们将所有模型、数据、结果和日志全面开源在https://github.com/Farseer-Scaling-Law/Farseer，以促进进一步研究。

</details>


### [584] [Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning](https://arxiv.org/abs/2506.10973)
**中文标题：将神经网络架构扩展到函数空间以进行算子学习的原理性方法**

*Julius Berner,Miguel Liu-Schiaffini,Jean Kossaifi,Valentin Duruisseaux,Boris Bonev,Kamyar Azizzadenesheli,Anima Anandkumar*

Main category: cs.LG

TL;DR: The paper proposes a principled method to extend neural networks to function spaces for operator learning, enabling applications in scientific problems like PDEs. It provides a recipe for converting existing neural architectures into neural operators with minimal modifications.


<details>
  <summary>Details</summary>
Motivation: Deep learning has excelled in finite-dimensional spaces (e.g., computer vision), but scientific problems often involve infinite-dimensional function spaces (e.g., PDEs). Neural operators bridge this gap, but prior work lacks direct extensions of existing neural architectures. This paper aims to provide practical principles for such extensions.

Method: The paper identifies key principles for constructing mappings between function spaces and proposes a recipe to convert popular neural architectures (e.g., CNNs, Transformers) into neural operators with minimal changes.

Result: The proposed method enables neural operators to leverage existing neural architectures, making them practical for scientific applications like learning PDE solution operators.

Conclusion: The paper provides a practical guide for extending neural networks to function spaces, facilitating the use of neural operators in scientific problems.

摘要: 许多科学问题（如连续时间动力系统和偏微分方程描述的问题）自然地在函数空间中表述。虽然函数空间通常是无限维的，但深度学习主要在计算机视觉和自然语言处理等有限维空间映射的应用中取得进展。这种数据性质的根本差异限制了神经网络在科学应用中的成功程度。神经算子是一种将神经网络推广到函数空间映射的原理性方法，为深度学习在科学问题中的变革性影响提供了途径。例如，神经算子可以学习整个偏微分方程类的解算子，如具有不同边界条件、系数函数和几何形状的物理系统。深度学习成功的一个关键因素是通过大量实证测试对神经架构进行精心设计。将这些神经架构转化为神经算子，使算子学习能够享受同样的实证优化。然而，先前的神经算子架构通常作为独立模型引入，并未直接作为现有神经网络架构的扩展。本文识别并提炼了构建无限维函数空间之间映射的实用实现的关键原则。利用这些原则，我们提出了一种将几种流行的神经架构转换为神经算子的方法，只需最小修改。本文旨在指导实践者完成这一过程，并详细说明使神经算子实际工作的步骤。我们的代码可在 https://github.com/neuraloperator/NNs-to-NOs 找到。

</details>


### [585] [Rethinking Losses for Diffusion Bridge Samplers](https://arxiv.org/abs/2506.10982)
**中文标题：重新思考扩散桥采样器的损失函数**

*Sebastian Sanokowski,Lukas Gruber,Christoph Bartmann,Sepp Hochreiter,Sebastian Lehner*

Main category: cs.LG

TL;DR: The paper argues that the reverse Kullback-Leibler loss with the log-derivative trick (rKL-LD) is superior to the Log Variance (LV) loss for diffusion bridge samplers, both conceptually and empirically, requiring less hyperparameter tuning and providing more stable training.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the observation that the LV loss, while effective in certain contexts, lacks a clear theoretical foundation for diffusion bridges and learned diffusion coefficients, unlike the rKL loss. The paper aims to address this gap and improve sampling performance.

Method: The method involves analyzing the theoretical equivalence of LV and rKL losses, highlighting their differences in diffusion bridge contexts, and empirically comparing their performance using the rKL-LD loss.

Result: Experimental results show that samplers trained with the rKL-LD loss outperform those using the LV loss, achieving better performance with less hyperparameter optimization and more stable training.

Conclusion: The conclusion advocates for the use of the rKL-LD loss in diffusion bridge samplers due to its theoretical soundness, superior performance, and practical advantages.

摘要: 扩散桥是一类有前景的深度学习方法，用于从未归一化分布中采样。近期研究表明，在使用重参数化技巧计算rKL梯度时，对数方差（LV）损失始终优于反向Kullback-Leibler（rKL）损失。然而，对于具有不可学习前向过程的扩散采样器，当结合对数导数技巧时，LV损失与rKL损失的梯度等价性在扩散桥或学习扩散系数的情况下不再成立。基于这一发现，我们认为对于扩散桥，LV损失并不像rKL损失那样可以通过数据处理不等式得到理论支持。分析表明，使用对数导数技巧的rKL损失（rKL-LD）不仅避免了这些概念问题，而且在性能上始终优于LV损失。在多个具有挑战性的基准测试中，使用rKL-LD损失训练的采样器表现更优。从实践角度看，rKL-LD需要更少的超参数优化，且训练过程更稳定。

</details>


### [586] [Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs](https://arxiv.org/abs/2506.10054)
**中文标题：Omni-DPO：一种用于大语言模型动态偏好学习的双视角范式**

*Shangpin Peng,Weinong Wang,Zhuotao Tian,Senqiao Yang,Xing Wu,Haotian Xu,Chengquan Zhang,Takashi Isobe,Baotian Hu,Min Zhang*

Main category: cs.LG

TL;DR: Omni-DPO是一种双视角优化框架，通过动态调整偏好对的质量和模型学习效果权重，提升直接偏好优化（DPO）的数据利用效率和性能。实验证明其在文本理解和数学推理任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的直接偏好优化（DPO）方法通常对所有偏好对一视同仁，忽略了其内在质量和学习效用的差异，导致数据利用和性能不佳。Omni-DPO旨在解决这一问题。

Method: Omni-DPO提出双视角优化框架，同时考虑偏好对的固有质量和模型在其上的动态学习表现，通过自适应加权样本提升训练效果。

Result: 实验表明，Omni-DPO在文本理解任务中显著优于Claude 3 Opus（Arena-Hard基准提升6.7分），在数学推理任务中也全面超越基线方法。

Conclusion: Omni-DPO通过动态调整样本权重，显著提升了数据利用效率和模型性能，为偏好学习提供了更有效的解决方案。

摘要: 直接偏好优化（DPO）因其简单高效成为基于人类反馈的强化学习（RLHF）的核心方法。然而，现有基于DPO的方法通常对所有偏好对一视同仁，忽略了其内在质量和学习效用的关键差异，导致数据利用和性能不佳。为解决这一问题，我们提出Omni-DPO，一种双视角优化框架，同时考虑（1）每个偏好对的固有质量和（2）模型在这些对上的动态学习表现。通过根据数据质量和模型学习动态自适应加权样本，Omni-DPO实现了更高效的训练数据利用和更好的性能。在不同模型和基准上的实验结果表明了Omni-DPO的优越性和泛化能力。在文本理解任务中，使用Omni-DPO微调的Gemma-2-9b-it显著领先于当前最优模型Claude 3 Opus，在Arena-Hard基准上提升了6.7分。在数学推理任务中，Omni-DPO在所有基准上均优于基线方法，为方法的有效性和鲁棒性提供了有力实证。代码和模型将在https://github.com/pspdada/Omni-DPO发布。

</details>


### [587] [Textual Bayes: Quantifying Uncertainty in LLM-Based Systems](https://arxiv.org/abs/2506.10060)
**中文标题：文本贝叶斯：量化基于LLM的系统中的不确定性**

*Brendan Leigh Ross,Noël Vouitsis,Atiyeh Ashari Ghomi,Rasa Hosseinzadeh,Ji Xin,Zhaoyan Liu,Yi Sui,Shiyi Hou,Kin Kwan Leung,Gabriel Loaiza-Ganem,Jesse C. Cresswell*

Main category: cs.LG

TL;DR: 本文提出了一种基于贝叶斯视角的方法，通过将提示视为统计模型中的文本参数，结合小规模训练数据进行贝叶斯推断，从而量化大型语言模型（LLM）的不确定性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在解决复杂任务方面表现优异，但其不确定性的量化仍是一个关键问题，限制了其在高风险领域的应用。此外，许多先进LLM的闭源和黑箱特性以及提示的敏感性进一步加剧了这一挑战。

Method: 作者将提示视为统计模型中的文本参数，利用小规模训练数据进行贝叶斯推断，并提出了一种新颖的MCMC算法（MHLP），结合提示优化技术和标准MCMC方法。

Result: 实验表明，该方法在多个LLM基准测试和不确定性量化任务中提升了预测准确性和不确定性量化能力。

Conclusion: 本研究为将贝叶斯方法引入LLM领域提供了可行路径，有助于开发更可靠和校准的LLM系统。

摘要: 尽管大型语言模型（LLM）在解决复杂现实任务方面能力日益增强，但准确量化其不确定性仍是一个关键开放性问题，这限制了其在高风险领域的应用。许多先进LLM的闭源和黑箱特性进一步加剧了这一挑战。此外，LLM系统对提示高度敏感，通常需要大量手动调整（即提示工程）。本文通过贝叶斯视角解决这些问题，将提示视为统计模型中的文本参数，利用小规模训练数据进行贝叶斯推断。这一新视角不仅实现了对模型文本参数及其下游预测的原则性不确定性量化，还允许通过自由文本表达对这些参数的先验信念。为进行贝叶斯推断（即使对于研究充分的数据模态也是难题），我们提出了“通过LLM提议的Metropolis-Hastings”（MHLP），这是一种结合提示优化技术和标准MCMC方法的新型马尔可夫链蒙特卡洛算法。MHLP是对现有LLM管道的即插即用改进，包括那些完全依赖闭源模型的管道。实验表明，我们的方法在一系列LLM基准测试和不确定性量化任务中提升了预测准确性和不确定性量化能力。更广泛地说，本研究为将丰富的贝叶斯方法引入LLM时代提供了可行路径，为开发更可靠和校准的LLM系统铺平了道路。

</details>


### [588] [Learning to Collaborate Over Graphs: A Selective Federated Multi-Task Learning Approach](https://arxiv.org/abs/2506.10102)
**中文标题：基于图的选择性联邦多任务学习方法**

*Ahmed Elbakary,Chaouki Ben Issaid,Mehdi Bennis*

Main category: cs.LG

TL;DR: 提出了一种基于图的选择性联邦多任务学习方法，通过特征锚点和图正则化实现高效的跨客户端协作，同时利用社区检测技术确保相似客户端之间的知识共享，显著提升了性能与公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法在跨客户端协作时存在通信效率低和负迁移问题。本文旨在通过选择性协作和动态图建模，实现高效的个性化学习。

Method: 提出了一种通信高效的方案，引入特征锚点（客户端本地类特征的紧凑表示）和分类头共享，并通过动态图正则化和社区检测技术限制协作范围。

Result: 在两个异构数据集上的实验表明，该方法在性能、计算与通信效率以及公平性方面显著优于现有基线方法。

Conclusion: 该方法通过选择性协作和图建模，有效解决了联邦学习中的通信效率和负迁移问题，同时提升了公平性和个性化学习能力。

摘要: 我们提出了一种新颖的联邦多任务学习方法，利用跨客户端相似性为每个客户端实现个性化学习。为避免向参数服务器传输整个模型，我们提出了一种通信高效的方案，引入了特征锚点——一种紧凑的向量表示，用于总结从客户端本地类中学到的特征。该特征锚点与服务器共享，以反映本地客户端的分布。此外，客户端共享分类头（一个轻量级的线性层），并通过基于图的正则化实现客户端间的协作。通过将客户端间的协作建模为动态图并持续更新和优化该图，我们可以应对客户端的任何漂移。为确保有益的知识转移并防止负协作，我们采用了一种基于社区检测的方法，将该动态图划分为同质社区，最大化每个社区内任务相似性（表示为图边的权重）的总和。这种机制将协作限制在高度相似的客户端之间，确保积极互动并保持个性化。在两个异构数据集上的大量实验表明，我们的方法显著优于现有基线方法。此外，我们还展示了该方法在计算和通信效率上的优越性，并促进了客户端间的公平性。

</details>


### [589] [GRAIL: A Benchmark for GRaph ActIve Learning in Dynamic Sensing Environments](https://arxiv.org/abs/2506.10120)
**中文标题：GRAIL：动态传感环境中图主动学习的基准框架**

*Maryam Khalid,Akane Sano*

Main category: cs.LG

TL;DR: GRAIL是一个用于动态传感环境中图主动学习的基准框架，通过引入新指标评估方法的多样性、持续有效性和用户负担，填补了现有图主动学习方法在动态环境和用户中心考量上的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的图主动学习方法主要在静态图数据集上评估，且仅关注预测准确性，忽略了多样性、查询公平性和动态环境适应性等用户中心考量。GRAIL旨在填补这一空白。

Method: GRAIL引入了一个新颖的基准框架，通过设计新指标（如持续有效性、多样性和用户负担）来评估动态环境中的图主动学习策略，并在动态真实数据集上进行实验。

Result: 实验揭示了预测性能与用户负担之间的权衡，并展示了现有主动学习策略的局限性。GRAIL证明了平衡节点重要性、查询多样性和网络拓扑的重要性。

Conclusion: GRAIL为动态环境中的图主动学习提供了全面的评估机制，强调了在动态和用户中心场景中平衡多维度指标的必要性。

摘要: 基于图的主动学习（AL）利用图结构高效地优先标记查询，减少标签成本和用户负担，适用于健康监测、人类行为分析和传感器网络等应用。通过识别策略性节点，图AL在保持模型性能的同时最小化数据收集需求，成为动态环境中的有力工具。尽管潜力巨大，现有图AL方法通常在静态图数据集上评估，且主要关注预测准确性，忽略了多样性、查询公平性和动态环境适应性等用户中心考量。为填补这一空白，我们提出了GRAIL，一个新颖的基准框架，用于评估动态真实环境中的图AL策略。GRAIL引入了新指标以评估持续有效性、多样性和用户负担，从而在不同条件下全面评估AL方法。在动态真实人类传感器数据集上的大量实验揭示了预测性能与用户负担之间的权衡，并凸显了现有AL策略的局限性。GRAIL展示了平衡节点重要性、查询多样性和网络拓扑的重要性，为动态环境中的图AL解决方案提供了评估机制。

</details>


### [590] [Self-Predictive Representations for Combinatorial Generalization in Behavioral Cloning](https://arxiv.org/abs/2506.10137)
**中文标题：Error**

*Daniel Lawson,Adriana Hugessen,Charlotte Cloutier,Glen Berseth,Khimya Khetarpal*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

摘要: Error

</details>


### [591] [Interpreting learned search: finding a transition model and value function in an RNN that plays Sokoban](https://arxiv.org/abs/2506.10138)
**中文标题：解读学习到的搜索：在玩Sokoban的RNN中发现过渡模型和价值函数**

*Mohammad Taufeeque,Aaron David Tucker,Adam Gleave,Adrià Garriga-Alonso*

Main category: cs.LG

TL;DR: 本文通过逆向工程分析了一个经过无模型强化学习训练的卷积循环神经网络（RNN），该网络用于玩解谜游戏Sokoban。研究发现，该网络通过类似于双向搜索的机制实现高效解谜，并揭示了其内部状态-动作激活与价值函数的关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解一个经过无模型强化学习训练的RNN如何在解谜游戏Sokoban中高效工作，并揭示其内部机制是否类似于经典搜索算法。

Method: 方法包括对RNN进行逆向工程分析，重点研究其状态-动作激活、方向通道的表示以及网络如何通过专用核扩展路径形成过渡模型。

Result: 结果表明，RNN通过类似于双向搜索的机制实现解谜，其状态-动作激活类似于价值函数，且网络通过分层计划和价值函数增加搜索深度。

Conclusion: 结论指出，尽管网络的行为与经典搜索算法有所不同，但其内部机制可以通过熟悉的术语理解，且能够利用测试时计算资源提升性能。

摘要: 我们部分逆向工程了一个经过无模型强化学习训练的卷积循环神经网络（RNN），该网络用于玩解谜游戏Sokoban。先前的研究发现，该网络通过更多的测试时计算资源解决更多关卡。我们的分析揭示了与经典双向搜索组件类似的几种机制。对于每个方块，RNN通过特定方向关联的通道激活表示其计划。这些状态-动作激活类似于价值函数——其大小决定了何时回溯以及哪个计划分支会被保留。专用核将这些激活（包含计划和价值）向前和向后扩展以创建路径，形成过渡模型。该算法在某些方面也与经典搜索不同。状态表示并不统一；相反，网络分别考虑每个箱子。每一层都有自己的计划表示和价值函数，从而增加搜索深度。远非难以理解，这种通过无模型训练学习的网络机制可以利用测试时计算资源，并以熟悉的术语解释。

</details>


### [592] [A Comparative Study of Machine Learning Techniques for Early Prediction of Diabetes](https://arxiv.org/abs/2506.10180)
**中文标题：机器学习技术在糖尿病早期预测中的比较研究**

*Mowafaq Salem Alzboon,Mohammad Al-Batah,Muhyeeddin Alqaraleh,Ahmad Abuashour,Ahmad Fuad Bader*

Main category: cs.LG

TL;DR: 本文比较了多种机器学习技术在糖尿病早期预测中的表现，发现神经网络和随机森林算法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 糖尿病在许多国家已成为重大健康问题，早期识别和管理至关重要。机器学习算法在糖尿病预测中展现出潜力，因此本研究旨在评估不同机器学习方法的效果。

Method: 研究使用Pima Indians糖尿病数据集，包含768名患者的年龄、BMI和血糖水平等数据，评估了逻辑回归、决策树、随机森林、k近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络等算法。

Result: 结果显示，神经网络算法表现最佳，准确率为78.57%，其次是随机森林算法，准确率为76.30%。

Conclusion: 研究表明，机器学习算法可用于糖尿病预测，是一种高效的早期检测工具。

摘要: 在许多国家，糖尿病已成为一个重大健康问题，早期识别和管理至关重要。使用机器学习算法预测糖尿病已取得令人鼓舞的成果。本研究利用Pima Indians糖尿病数据集，评估了多种机器学习方法在糖尿病预测中的效果。数据集包含768名患者的年龄、BMI和血糖水平等信息。评估的算法包括逻辑回归、决策树、随机森林、k近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络。结果表明，神经网络算法表现最佳，准确率为78.57%，其次是随机森林算法，准确率为76.30%。研究暗示机器学习算法有助于糖尿病预测，是一种高效的早期检测工具。

</details>


### [593] [Optimizing Genetic Algorithms with Multilayer Perceptron Networks for Enhancing TinyFace Recognition](https://arxiv.org/abs/2506.10184)
**中文标题：通过多层感知器网络优化遗传算法以增强TinyFace识别**

*Mohammad Subhi Al-Batah,Mowafaq Salem Alzboon,Muhyeeddin Alqaraleh*

Main category: cs.LG

TL;DR: 本研究通过多层感知器（MLP）网络优化遗传算法（GA），以提升TinyFace识别性能。实验表明，GA在复杂数据集中能有效识别关键特征，而PCA在低维无噪声数据中表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索特征选择和降维技术对MLP网络性能的影响，为机器学习任务提供实用的特征工程和参数优化指导。

Method: 研究采用三种方法：1）默认设置的MLP基线训练；2）基于GA的特征选择优化；3）基于PCA的降维。实验覆盖TinyFace、Heart Disease和Iris三个数据集。

Result: 结果显示，PCA在低维无噪声数据中表现良好，而GA在复杂数据集中能显著提升MLP的准确性。特征选择与降维技术对MLP性能有协同作用。

Conclusion: 研究为特征工程和神经网络参数优化提供了实用指南，强调了特征选择与降维技术在提升MLP性能中的重要性。

摘要: 本研究通过涉及TinyFace、Heart Disease和Iris三个数据集的严格实验方法，对多层感知器（MLP）网络进行了实证分析。研究包括三种关键方法：a）使用默认设置的MLP基线训练；b）基于遗传算法（GA）的特征选择优化；c）基于主成分分析（PCA）的降维。结果显示，这些技术对性能有显著影响。PCA在低维无噪声数据中表现优异，而GA在复杂数据集中通过准确识别关键特征持续提升准确性。比较表明，特征选择和降维在提升MLP性能中具有相互依赖的作用。研究为特征工程和神经网络参数优化的文献提供了贡献，并为广泛的机器学习任务提供了实用指南。

</details>


### [594] [Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment](https://arxiv.org/abs/2506.10186)
**中文标题：通过旋转对齐的可扩展非等变3D分子生成**

*Yuhui Ding,Thomas Hofmann*

Main category: cs.LG

TL;DR: 本文提出了一种通过旋转对齐的可扩展非等变3D分子生成方法，性能优于传统非等变模型，接近等变扩散模型，同时提高了训练和采样效率。


<details>
  <summary>Details</summary>
Motivation: 现有的等变扩散模型在3D分子生成中表现优异，但其专用等变架构限制了模型的可扩展性和效率。本文旨在通过放松等变约束，提出一种更高效且性能接近的方法。

Method: 通过学习每个分子的样本依赖SO(3)变换，构建对齐的潜在空间，并在对齐表示上训练非等变扩散模型。

Result: 实验表明，该方法显著优于传统非等变模型，样本质量接近最先进的等变扩散模型，同时提升了训练和采样效率。

Conclusion: 通过旋转对齐的非等变扩散模型在3D分子生成中实现了高性能和高效率，为相关领域提供了新的解决方案。

摘要: 等变扩散模型在3D分子生成中表现出色，这些模型通过利用SE(3)-等变去噪网络，结合了3D分子的欧几里得对称性。然而，专用的等变架构限制了扩散模型的可扩展性和效率。本文提出了一种放松等变约束的方法。具体而言，我们的方法为每个分子学习一个样本依赖的SO(3)变换，以构建对齐的潜在空间。随后，在对齐表示上训练非等变扩散模型。实验结果表明，我们的方法显著优于先前报道的非等变模型，其样本质量与最先进的等变扩散模型相当，同时提供了更高的训练和采样效率。我们的代码可在https://github.com/skeletondyh/RADM获取。

</details>


### [595] [Detecting Sockpuppetry on Wikipedia Using Meta-Learning](https://arxiv.org/abs/2506.10314)
**中文标题：基于元学习的维基百科傀儡账户检测**

*Luc Raszewski,Christine De Kock*

Main category: cs.LG

TL;DR: 本文提出一种基于元学习的维基百科傀儡账户检测方法，显著提升了检测精度，尤其是在数据稀缺情况下。


<details>
  <summary>Details</summary>
Motivation: 维基百科上的恶意傀儡账户检测对维护互联网可靠信息和防止虚假信息传播至关重要。现有机器学习方法未能有效适应特定作者行为，尤其在数据有限时表现不佳。

Method: 采用元学习方法，通过跨任务训练模型，使其能够快速适应新傀儡账户群的写作风格。

Result: 实验表明，元学习方法显著提升了预测精度，优于预训练模型。

Conclusion: 元学习方法在开放编辑平台上对抗傀儡账户行为方面取得了进展，并发布了一个新的傀儡账户调查数据集以促进未来研究。

摘要: 维基百科上的恶意傀儡账户检测对于维护互联网可靠信息和防止虚假信息传播至关重要。现有的机器学习方法依赖于风格和元数据特征，但未能优先适应特定作者行为，因此在数据有限时难以有效建模特定傀儡账户群的行为。为解决这一问题，我们提出应用元学习技术，这是一种通过在多个任务上训练模型以提高数据稀缺环境下性能的机器学习方法。元学习优化了模型，使其能够快速适应新傀儡账户群的写作风格。实验结果表明，与预训练模型相比，元学习显著提升了预测精度，标志着在开放编辑平台上对抗傀儡账户行为方面取得了进展。我们发布了一个新的傀儡账户调查数据集，以促进傀儡账户和元学习领域的未来研究。

</details>


### [596] [Cross-Learning Between ECG and PCG: Exploring Common and Exclusive Characteristics of Bimodal Electromechanical Cardiac Waveforms](https://arxiv.org/abs/2506.10212)
**中文标题：心电图与心音图的交叉学习：探索双模态电机械心脏波形的共同与独有特征**

*Sajjad Karimi,Amit J. Shah,Gari D. Clifford,Reza Sameni*

Main category: cs.LG

TL;DR: 本研究通过分析心电图（ECG）和心音图（PCG）的共同和独有特征，探索了它们之间的相互重建和生物标志物提取潜力。非线性模型（尤其是非因果LSTM）在重建任务中表现最佳，且从PCG重建ECG比反向更容易。研究还发现，基于包络的建模显著提高了跨受试者的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 心电图和心音图分别捕捉心脏的电活动和机械活动，但它们的重叠和独有信息内容及其相互重建潜力尚未完全理解。本研究旨在探索这些信号在多种生理条件下的关系，并开发新的多模态心脏监测技术。

Method: 使用EPHNOGRAM数据集中的静息和运动状态下的同步ECG-PCG记录，采用线性和非线性机器学习模型（包括非因果LSTM）进行信号重建，并分析因果关系、生理状态和跨受试者变异性的影响。

Result: 非线性模型（尤其是非因果LSTM）在重建任务中表现最佳，从PCG重建ECG比反向更容易。运动和跨受试者场景具有挑战性，但基于包络的建模显著提高了跨受试者的泛化能力。此外，临床相关的ECG生物标志物（如基准点和QT间期）可以从PCG中估计。

Conclusion: 研究深化了对心脏电机械模态关系的理解，展示了多模态心脏监测技术的潜力。非线性模型和基于包络的建模为跨模态学习和跨受试者应用提供了新思路。

摘要: 同步心电图（ECG）和心音图（PCG）通过分别捕捉心脏的电活动和机械活动，提供了心脏功能的多模态视角。然而，这些信号的独有和重叠信息内容及其相互重建和生物标志物提取潜力，尤其是在不同生理条件和个体间的表现，尚未完全理解。
本研究利用EPHNOGRAM数据集中的静息和运动状态下的同步ECG-PCG记录，系统地探索了ECG和PCG的共同与独有特征。我们采用了一系列线性和非线性机器学习模型（包括非因果LSTM网络），从一种模态重建另一种模态，并分析了因果关系、生理状态和跨受试者变异性的影响。结果表明，非线性模型（尤其是非因果LSTM）在重建任务中表现最佳，且从PCG重建ECG比反向更容易。运动和跨受试者场景具有挑战性，但基于包络的建模利用瞬时振幅特征显著提高了跨受试者的泛化能力。此外，我们还证明，在跨受试者设置中，可以从PCG估计临床相关的ECG生物标志物（如基准点和QT间期）。
这些发现深化了我们对电机械心脏模态关系的理解，包括波形特征和心脏事件的时间关系，为新型多模态心脏监测技术的应用提供了潜在方向。

</details>


### [597] [Provably Learning from Language Feedback](https://arxiv.org/abs/2506.10341)
**中文标题：可证明地从语言反馈中学习**

*Wanqiao Xu,Allen Nie,Ruijie Zheng,Aditya Modi,Adith Swaminathan,Ching-An Cheng*

Main category: cs.LG

TL;DR: 本文提出了一个基于语言反馈的学习问题（LLF）的正式框架，引入“转移困惑维度”作为衡量问题复杂性的指标，并开发了一种名为HELiX的无悔算法，证明其能够通过顺序交互解决LLF问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）代理的出现，从观察和语言反馈中交互式学习的研究日益增多。然而，目前缺乏对这些决策问题的原则性框架。本文旨在填补这一空白。

Method: 本文形式化了LLF问题，提出了足够假设以在潜在奖励下实现学习，并引入“转移困惑维度”作为衡量LLF问题复杂性的指标。开发了一种名为HELiX的无悔算法，通过顺序交互解决LLF问题。

Result: 研究表明，转移困惑维度能够捕捉反馈信息对学习复杂性的影响，并展示了在某些情况下，从丰富语言反馈中学习可以比从奖励中学习快指数级。HELiX算法在多个实验领域中表现良好。

Conclusion: 本文为设计基于通用语言反馈的交互式学习算法迈出了第一步，提供了理论框架和实用算法。

摘要: 从观察和语言反馈中交互式学习是一个日益受到关注的领域，这得益于大型语言模型（LLM）代理的出现。尽管已有令人印象深刻的实证演示，但目前仍缺乏对这些决策问题的原则性框架。本文形式化了“从语言反馈中学习”（LLF）问题，提出了足够假设以在潜在奖励下实现学习，并引入“转移困惑维度”作为衡量LLF问题复杂性的指标。我们证明，转移困惑维度能够捕捉反馈信息对学习复杂性的影响，并展示了在某些情况下，从丰富语言反馈中学习可以比从奖励中学习快指数级。我们开发了一种无悔算法HELiX，通过顺序交互解决LLF问题，其性能保证与问题的转移困惑维度相关。在多个实验领域中，HELiX表现良好，即使重复提示LLM不可靠时也是如此。我们的贡献标志着设计基于通用语言反馈的交互式学习算法的第一步。

</details>


### [598] [Can We Infer Confidential Properties of Training Data from LLMs?](https://arxiv.org/abs/2506.10364)
**中文标题：我们能从大型语言模型中推断出训练数据的机密属性吗？**

*Penguin Huang,Chhavi Yadav,Ruihan Wu,Kamalika Chaudhuri*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型（LLMs）在微调过程中可能泄露训练数据的机密属性，提出了PropInfer基准任务和两种攻击方法，验证了LLMs的潜在漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗、金融和法律等领域的广泛应用，微调数据中的敏感属性（如患者人口统计或疾病流行率）可能被泄露。尽管已有研究探讨了判别模型和生成模型的属性推断攻击，但LLMs的此类攻击是否有效尚不明确。

Method: 提出了PropInfer基准任务，基于ChatDoctor数据集，评估LLMs在问答和聊天完成两种微调范式下的属性推断。设计了两种攻击方法：基于提示的生成攻击和利用词频信号的影子模型攻击。

Result: 实验表明，这两种攻击方法在多种预训练LLMs上均取得成功，揭示了LLMs在属性推断方面的新漏洞。

Conclusion: LLMs在微调过程中可能泄露训练数据的机密属性，需进一步研究防御方法以保护数据隐私。

摘要: 大型语言模型（LLMs）越来越多地针对特定领域的数据集进行微调，以支持医疗、金融和法律等领域的应用。这些微调数据集通常包含敏感和机密的属性（如患者人口统计或疾病流行率），这些属性本不应被泄露。尽管已有研究探讨了判别模型（如图像分类模型）和生成模型（如图像数据的GANs）的属性推断攻击，但此类攻击是否适用于LLMs尚不明确。本文提出了PropInfer基准任务，用于评估LLMs在问答和聊天完成两种微调范式下的属性推断。基于ChatDoctor数据集，我们的基准任务涵盖了多种属性类型和任务配置。此外，我们提出了两种定制攻击方法：基于提示的生成攻击和利用词频信号的影子模型攻击。通过多种预训练LLMs的实证评估，我们的攻击方法取得了成功，揭示了LLMs中此前未被识别的漏洞。

</details>


### [599] [LaMAGIC2: Advanced Circuit Formulations for Language Model-Based Analog Topology Generation](https://arxiv.org/abs/2506.10235)
**中文标题：LaMAGIC2：基于语言模型的模拟拓扑生成的高级电路表示方法**

*Chen-Chia Chang,Wan-Hsuan Lin,Yikang Shen,Yiran Chen,Xin Zhang*

Main category: cs.LG

TL;DR: LaMAGIC2提出了一种新的电路表示方法SFCI，用于基于语言模型的模拟拓扑生成，显著提高了成功率和数值精度敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有的模拟拓扑设计自动化方法存在电路表示效率低和数值输入精度敏感性不足的问题，亟需改进。

Method: LaMAGIC2引入了SFCI（简洁浮点输入规范表示法），通过基于标识符的表示方法减少令牌长度复杂度至O(|V|)，并提升数值精度敏感性。

Result: 实验表明，LaMAGIC2在0.01的严格容差下成功率提高了34%，均方误差降低了10倍，且在顶点较多的电路中表现更优，最高提升58.5%。

Conclusion: LaMAGIC2为模拟拓扑生成提供了一个鲁棒的框架，显著提升了性能和可迁移性。

摘要: 模拟拓扑设计的自动化对现代应用的定制化需求至关重要，但目前的方法因高度依赖人工工程而效率低下。现有研究采用序列到序列方法，并通过监督微调语言模型生成用户指定拓扑，但其电路表示因O(|V|2)的令牌长度而效率低下，且对数值输入的精度敏感性不足。本文提出LaMAGIC2，采用一种简洁的浮点输入规范表示法（SFCI），通过基于标识符的表示方法改进组件类型识别，将令牌长度复杂度降至O(|V|)，并提升数值精度敏感性以在严格容差下表现更优。实验表明，LaMAGIC2在0.01的严格容差下成功率提高了34%，均方误差降低了10倍，且在顶点较多的电路中可迁移性更强，最高提升58.5%。这些进展使LaMAGIC2成为模拟拓扑生成的鲁棒框架。

</details>


### [600] [Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning](https://arxiv.org/abs/2506.10378)
**中文标题：通过因果表示学习发现语言模型的层次化潜在能力**

*Jikai Jin,Vasilis Syrgkanis,Sham Kakade,Hanlin Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种因果表示学习框架，通过建模语言模型的潜在能力因素，揭示了其层次化的因果关系，为模型评估提供了科学依据。


<details>
  <summary>Details</summary>
Motivation: 语言模型能力的忠实评估对模型开发至关重要，但现有方法面临复杂的混杂效应和高计算成本等挑战。

Method: 提出因果表示学习框架，将基准性能建模为少数潜在能力因素的线性变换，并通过控制基础模型作为混杂因素，识别这些因素的因果关系。

Result: 在包含1500多个模型的综合数据集上，发现了一个简洁的三节点线性因果结构，揭示了从通用问题解决能力到数学推理能力的层次化因果关系。

Conclusion: 研究强调了在评估中控制基础模型变体的重要性，为揭示潜在能力间的因果关系提供了关键方法。

摘要: 语言模型能力的忠实评估对于获取可指导模型开发的见解至关重要。然而，这一领域的严格因果评估面临重大方法学挑战，包括复杂的混杂效应和与大量重新训练相关的高计算成本。为应对这些挑战，我们提出了一种因果表示学习框架，其中观察到的基准性能被建模为少数潜在能力因素的线性变换。关键的是，这些潜在因素在适当控制基础模型作为共同混杂因素后，被识别为因果相关的。将这一方法应用于包含1500多个模型的数据集（这些模型在Open LLM Leaderboard的六个基准上进行了评估），我们发现了一个简洁的三节点线性因果结构，能够可靠地解释观察到的性能变化。进一步解释这一因果结构提供了超越简单数值排名的科学见解：具体而言，我们揭示了一个清晰的因果方向，从通用问题解决能力开始，通过指令遵循能力，最终达到数学推理能力。我们的结果强调了在评估中仔细控制基础模型变体的关键作用，这是准确揭示潜在模型能力间因果关系的关键步骤。

</details>


### [601] [Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series](https://arxiv.org/abs/2506.10412)
**中文标题：Time-IMM：一个用于不规则多模态多元时间序列的数据集与基准测试**

*Ching Chang,Jeehyun Hwang,Yidan Shi,Haixin Wang,Wen-Chih Peng,Tien-Fu Chen,Wei Wang*

Main category: cs.LG

TL;DR: Time-IMM是一个针对不规则多模态多元时间序列的数据集和基准测试，填补了现有研究数据与实际应用之间的差距，并展示了多模态建模对预测性能的提升。


<details>
  <summary>Details</summary>
Motivation: 现实应用中的时间序列数据（如医疗、气候建模和金融）通常是不规则、多模态且杂乱的，而现有基准测试多假设数据是清洁、规则且单模态的，导致研究与实际部署之间存在显著差距。

Method: 提出了Time-IMM数据集，捕捉多模态多元时间序列中的九种不规则性类型，并开发了IMM-TSF基准测试库，支持异步融合和真实评估，包含时间戳到文本融合模块和多模态融合模块。

Result: 实验结果表明，显式建模不规则时间序列的多模态特性显著提升了预测性能。

Conclusion: Time-IMM和IMM-TSF为在真实条件下推进时间序列分析提供了基础，数据集和基准库已公开。

摘要: 现实应用中的时间序列数据（如医疗、气候建模和金融）通常是不规则、多模态且杂乱的，具有不同的采样率、异步模态和普遍缺失值。然而，现有基准测试通常假设数据是清洁、规则且单模态的，导致研究与实际部署之间存在显著差距。我们提出了Time-IMM，这是一个专门设计用于捕捉多模态多元时间序列中由原因驱动的不规则性的数据集。Time-IMM涵盖了九种不同类型的时间序列不规则性，分为触发型、约束型和人为型机制。作为补充，我们开发了IMM-TSF，一个用于不规则多模态时间序列预测的基准测试库，支持异步融合和真实评估。IMM-TSF包含专门的融合模块，如时间戳到文本融合模块和多模态融合模块，支持基于最近邻平均和注意力机制的融合策略。实验结果表明，显式建模不规则时间序列的多模态特性显著提升了预测性能。Time-IMM和IMM-TSF为在真实条件下推进时间序列分析提供了基础。数据集可在https://www.kaggle.com/datasets/blacksnail789521/time-imm/data获取，基准库可在https://anonymous.4open.science/r/IMMTSF_NeurIPS2025访问。

</details>


### [602] [Deep Learning-Based Digitization of Overlapping ECG Images with Open-Source Python Code](https://arxiv.org/abs/2506.10617)
**中文标题：基于深度学习的重叠ECG图像数字化方法及开源Python代码**

*Reza Karbasi,Masoud Rahimi,Abdol-Hossein Vahabie,Hadi Moradi*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的重叠ECG图像数字化方法，通过两阶段流程（U-Net分割和自适应网格检测）显著提高了信号重叠情况下的数字化精度。


<details>
  <summary>Details</summary>
Motivation: 解决纸质心电图（ECG）记录数字化中信号重叠的常见问题，现有方法对此处理不足。

Method: 采用两阶段流程：1）使用U-Net分割网络隔离主要ECG信号；2）通过自适应网格检测模块将二进制掩码转换为时间序列信号。

Result: U-Net分割的IoU为0.87；数字化方法在非重叠和重叠信号上均优于基线（MSE和Pearson相关系数显著提升）。

Conclusion: 该方法显著提高了ECG数字化的准确性，尤其是在信号重叠情况下，为研究和临床应用提供了可靠工具。

摘要: 本文解决了纸质心电图（ECG）记录数字化中的持续挑战，特别关注信号重叠对单导联的影响——这是现有方法中常见但未充分解决的问题。我们提出了一种两阶段流程来克服这一限制。第一阶段采用基于U-Net的分割网络，通过包含重叠信号的数据集和自定义数据增强，准确分离主要ECG轨迹。第二阶段通过自适应网格检测模块，将精炼的二进制掩码转换为时间序列信号。实验结果表明，我们的方法效果显著。U-Net架构在细粒度分割任务中实现了0.87的IoU。重要的是，我们的数字化方法在非重叠和重叠ECG样本上均优于基线技术。对于非重叠信号，我们的方法实现了0.0010的均方误差（MSE）和0.9644的皮尔逊相关系数（rho），而基线分别为0.0015和0.9366。在信号重叠样本上，我们的方法实现了0.0029的MSE和0.9641的rho，显著优于基线的0.0178和0.8676。这项工作展示了一种有效策略，显著提高了数字化准确性，尤其是在信号重叠情况下，为将模拟ECG记录转换为可分析的数字化数据奠定了坚实基础。实现代码已在GitHub公开：https://github.com/masoudrahimi39/ECG-code。

</details>


### [603] [Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering](https://arxiv.org/abs/2506.10751)
**中文标题：Neural在ArchEHR-QA 2025中的应用：基于代理提示优化的证据支持临床问答**

*Sai Prasanna Teja Reddy Bogireddy,Abrar Majeedi,Viswanatha Reddy Gajjala,Zhuoyan Xu,Siddhant Rai,Vaishnav Potlapalli*

Main category: cs.LG

TL;DR: 本文提出了一种基于数据驱动提示优化的方法，用于电子健康记录（EHR）中的临床问答任务，通过分阶段证据检索和答案生成，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）中的自动问答（QA）能够为临床医生和患者填补关键信息缺口，但需要在有限监督下实现精确的证据检索和可靠的答案生成。

Method: 方法将任务分解为（1）句子级证据识别和（2）带有明确引用的答案合成，并使用DSPy的MIPROv2优化器自动探索提示空间，结合自一致性投票方案提升证据召回率。

Result: 在隐藏测试集上，该方法总体得分为51.5，排名第二，显著优于标准的零样本和少样本提示方法（分别高出20分和10分）。

Conclusion: 数据驱动的提示优化是高风险临床QA任务中模型微调的一种经济高效替代方案，提升了医疗AI助手的可靠性。

摘要: 电子健康记录（EHR）中的自动问答（QA）能够为临床医生和患者填补关键信息缺口，但需要在有限监督下实现精确的证据检索和可靠的答案生成。本文介绍了Neural，这是BioNLP 2025 ArchEHR-QA共享任务中证据支持临床QA的亚军方法。我们提出的方法将任务分解为（1）句子级证据识别和（2）带有明确引用的答案合成。对于每个阶段，我们使用DSPy的MIPROv2优化器自动探索提示空间，并在开发集上联合调整指令和少样本演示。自一致性投票方案进一步提高了证据召回率而不牺牲精确度。在隐藏测试集上，我们的方法总体得分为51.5，排名第二，同时显著优于标准的零样本和少样本提示方法（分别高出20分和10分）。这些结果表明，数据驱动的提示优化是高风险临床QA任务中模型微调的一种经济高效替代方案，提升了医疗AI助手的可靠性。

</details>


### [604] [The Diffusion Duality](https://arxiv.org/abs/2506.10892)
**中文标题：扩散对偶性**

*Subham Sekhar Sahoo,Justin Deschenaux,Aaron Gokaslan,Guanghan Wang,Justin Chiu,Volodymyr Kuleshov*

Main category: cs.LG

TL;DR: 本文提出了一种名为Duo的方法，通过利用高斯扩散的潜在特性，改进了均匀状态离散扩散模型的训练和采样效率，使其在部分基准测试中超越了自回归模型。


<details>
  <summary>Details</summary>
Motivation: 均匀状态离散扩散模型因其自我纠正能力在快速文本生成方面具有潜力，但通常性能不及自回归模型和掩码扩散模型。本文旨在通过高斯扩散的潜在特性缩小这一性能差距。

Method: Duo方法将高斯扩散的强大技术迁移到离散扩散模型中，包括基于高斯过程的课程学习策略（加快训练速度）和离散一致性蒸馏技术（加速采样）。

Result: 使用课程学习的模型在7个基准测试中的3个上零样本困惑度优于自回归模型；离散一致性蒸馏技术将采样速度提高了两个数量级。

Conclusion: Duo方法通过高斯扩散的潜在特性显著提升了离散扩散模型的性能，为快速文本生成提供了新的可能性。

摘要: 均匀状态离散扩散模型因其自我纠正能力在快速文本生成方面具有潜力，但其性能通常不及自回归模型和掩码扩散模型。本文通过利用一个关键发现——均匀状态扩散过程自然源于潜在的高斯扩散——缩小了这一性能差距。我们的方法Duo将高斯扩散的强大技术迁移到离散扩散模型中，改进了训练和采样。首先，我们提出了一种基于高斯过程的课程学习策略，通过降低方差将训练速度提高了一倍。使用课程学习的模型在7个基准测试中的3个上零样本困惑度优于自回归模型。其次，我们提出了离散一致性蒸馏技术，将一致性蒸馏从连续域迁移到离散域。该算法通过将采样速度提高两个数量级，实现了扩散语言模型的少步生成。代码和模型检查点可在项目页面获取：http://s-sahoo.github.io/duo

</details>


### [605] [Robustly Improving LLM Fairness in Realistic Settings via Interpretability](https://arxiv.org/abs/2506.10922)
**中文标题：通过可解释性在现实场景中稳健提升大型语言模型的公平性**

*Adam Karvonen,Samuel Marks*

Main category: cs.LG

TL;DR: 研究发现，在现实场景中，简单的反偏见提示无法消除大型语言模型（LLM）的偏见，而通过内部偏见缓解方法（识别并中和模型激活中的敏感属性方向）可显著降低偏见，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在高风险招聘应用中的部署日益增多，但其在现实场景中可能因引入上下文细节（如公司名称、文化描述等）而表现出显著的种族和性别偏见。现有反偏见方法在控制实验中有效，但在现实场景中失效，亟需更稳健的解决方案。

Method: 通过内部偏见缓解方法，识别模型激活中与种族和性别相关的方向，并在推理时应用仿射概念编辑。该方法基于简单的合成数据集，但能泛化到现实场景中。

Result: 在多种商业和开源模型（如GPT-4o、Claude 4 Sonnet等）中，现实上下文会引发显著偏见（面试率差异高达12%）。内部偏见缓解方法能将偏见降至极低水平（通常低于1%，最高不超过2.5%），同时基本保持模型性能。

Conclusion: 研究建议，在招聘中部署LLM的从业者应采用更现实的评估方法，并考虑内部偏见缓解策略以确保公平结果。

摘要: 大型语言模型（LLM）越来越多地应用于高风险招聘场景，直接影响人们的职业和生计。尽管此前研究表明简单的反偏见提示可在控制评估中消除人口统计偏见，但我们发现，在引入现实上下文细节时，这些缓解措施失效。我们通过内部偏见缓解方法解决了这一问题：通过识别并中和模型激活中的敏感属性方向，我们在所有测试场景中实现了稳健的偏见减少。在领先的商业模型（如GPT-4o、Claude 4 Sonnet、Gemini 2.5 Flash）和开源模型（如Gemma-2 27B、Gemma-3、Mistral-24B）中，我们发现添加现实上下文（如公司名称、公开职业页面的文化描述及选择性招聘限制）会引发显著的种族和性别偏见（面试率差异高达12%）。这些偏见在所有测试模型和场景中一致表现为偏向黑人而非白人候选人、女性而非男性候选人。此外，模型能从细微线索（如大学隶属关系）推断人口统计信息并产生偏见，而这些偏见在检查模型的链式推理时仍不可见。为应对这些局限性，我们的内部偏见缓解方法识别了与种族和性别相关的方向，并在推理时应用仿射概念编辑。尽管使用了简单合成数据集的方向，该干预方法泛化能力强，能持续将偏见降至极低水平（通常低于1%，最高不超过2.5%），同时基本保持模型性能。研究结果表明，在招聘中部署LLM的从业者应采用更现实的评估方法，并考虑内部缓解策略以实现公平结果。

</details>


### [606] [GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models](https://arxiv.org/abs/2506.10946)
**中文标题：GUARD：通过数据归因指导大型语言模型的去学习与保留**

*Evelyn Ma,Duo Zhou,Peizhi Niu,Huiting Zhou,Huan Zhang,Olgica Milenkovic,S. Rasoul Etesami*

Main category: cs.LG

TL;DR: GUARD是一种针对大型语言模型（LLM）的新型去学习框架，通过数据归因指导去学习和保留，显著减少意外遗忘并提升模型效用。


<details>
  <summary>Details</summary>
Motivation: 由于法规合规、版权保护和隐私问题，LLM的去学习变得日益重要，但现有方法在去学习高影响力数据时往往导致模型效用下降。

Method: GUARD引入了一种轻量级代理数据归因指标，量化遗忘集和保留集之间的“对齐”程度，并设计了一种自适应非均匀去学习权重的目标函数。

Result: 实验表明，GUARD在TOFU基准测试中显著提升了效用保留，同时确保有效去学习，保留集的效用牺牲减少了194.92%。

Conclusion: GUARD通过数据归因指导去学习，显著提升了LLM的保留能力，同时保持去学习效果，为去学习领域提供了新思路。

摘要: 大型语言模型（LLM）的去学习因法规合规、版权保护和隐私问题而日益重要。然而，LLM去学习的一个关键挑战是意外遗忘，即删除特定数据时无意中损害了模型的效用及其对有价值信息的保留。尽管先前工作主要关注架构创新，但数据级因素对去学习性能的影响仍未充分探索。因此，现有方法在遗忘高影响力数据时往往导致保留能力下降。为解决这一问题，我们提出了GUARD——一种通过数据归因指导去学习与保留的新型框架。GUARD的核心是一种专为LLM去学习设计的轻量级代理数据归因指标，可量化遗忘集与保留集之间的“对齐”程度，同时保持计算效率。基于此，我们设计了一种新颖的去学习目标函数，根据样本的代理归因分数自适应分配非均匀去学习权重。通过这种去学习能力的重新分配，GUARD减轻了保留能力的意外损失。我们提供了严格的理论保证，证明GUARD在保持与先前方法相当的遗忘指标的同时，显著提升了保留能力。在TOFU基准测试中，针对多种LLM架构的广泛实验表明，GUARD大幅提升了效用保留，同时确保有效去学习。值得注意的是，在遗忘10%训练数据时，GUARD将保留集的效用牺牲（以Truth Ratio衡量）减少了高达194.92%。

</details>


### [607] [PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal Representation](https://arxiv.org/abs/2506.10351)
**中文标题：PhysioWave：一种用于生理信号表征的多尺度小波-变换器**

*Yanlong Chen,Mattia Orlandi,Pierangelo Maria Rapa,Simone Benatti,Luca Benini,Yawei Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于小波变换的多尺度生理信号分析方法，并首次为EMG和ECG信号构建了大规模预训练模型，显著提升了性能。同时，通过整合预训练的EEG模型，提出了统一的多模态框架，有效解决了信号噪声、个体差异和设备不匹配等问题。


<details>
  <summary>Details</summary>
Motivation: 生理信号常受运动伪影、基线漂移和低信噪比干扰，且具有非平稳性和突变特征，传统方法难以有效表征。本文旨在解决这些问题，提升生理信号分析的性能。

Method: 提出了一种基于小波变换的多尺度时间-频率特征提取方法，并构建了针对EMG和ECG的大规模预训练模型。同时，整合预训练的EEG模型，设计了一种多模态框架，通过专用分支和可学习加权融合实现模态融合。

Result: 所提方法在EMG和ECG的下游任务中表现优异，设定了新的性能基准。多模态框架在多模态任务中优于现有方法，解决了低信噪比、高个体差异和设备不匹配等挑战。

Conclusion: 基于小波的架构为多样生理信号分析奠定了基础，多模态设计为下一代生理信号处理指明了方向，对可穿戴健康监测、临床诊断和生物医学应用具有潜在影响。

摘要: 生理信号常受运动伪影、基线漂移和其他低信噪比干扰的影响，这为分析带来了重大挑战。此外，这些信号表现出强烈的非平稳性，具有尖锐的峰值和不断演化的突变，难以通过传统的时域或滤波方法表征。为解决这些问题，本文提出了一种新颖的基于小波的生理信号分析方法，旨在捕捉多种生理信号的多尺度时频特征。利用这一技术，首次为EMG和ECG信号引入了两个大规模预训练模型，在后续任务中实现了卓越性能并设定了新的基准。此外，通过整合预训练的EEG模型，构建了一个统一的多模态框架，其中每个模态通过其专用分支引导，并通过可学习加权融合进行融合。这一设计有效解决了低信噪比、高个体间变异性和设备不匹配等挑战，在多模态任务中优于现有方法。所提出的小波架构为多样生理信号分析奠定了坚实基础，而多模态设计为下一代生理信号处理指明了方向，对可穿戴健康监测、临床诊断和更广泛的生物医学应用具有潜在影响。

</details>


### [608] [Build the web for agents, not agents for the web](https://arxiv.org/abs/2506.10953)
**中文标题：为代理构建网络，而非为网络构建代理**

*Xing Han Lù,Gaurav Kamath,Marius Mosbach,Siva Reddy*

Main category: cs.LG

TL;DR: 本文提出了一种新的网络代理交互范式，主张为代理设计专门的网络界面（AWI），而非让代理适应人类设计的界面。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）和多模态模型的发展推动了网络代理的研究，但现有方法因人类界面与代理能力不匹配而面临挑战。

Method: 提出Agentic Web Interface（AWI）概念，并制定了六项设计原则，强调安全性、效率和标准化。

Result: AWI旨在克服现有界面的根本限制，为更高效、可靠和透明的网络代理设计铺平道路。

Conclusion: 通过为代理设计专门的界面，可以显著提升网络代理的性能和适用性，这需要机器学习社区的广泛合作。

摘要: 近年来，大型语言模型（LLM）和多模态模型的进步引发了人们对开发网络代理的极大兴趣——这些AI系统能够自主导航并在网络环境中完成任务。尽管在自动化复杂网络交互方面具有巨大潜力，但现有方法因人类设计的界面与LLM能力之间的根本不匹配而面临重大挑战。当前方法在处理庞大的DOM树、依赖附加信息的截图或完全通过API交互绕过用户界面时表现不佳。本文主张在网络代理研究中实现范式转变：与其迫使网络代理适应为人类设计的界面，不如开发一种专门为代理能力优化的新交互范式。为此，我们提出了Agentic Web Interface（AWI）的概念，这是一种专为代理导航网站而设计的界面。我们制定了六项AWI设计原则，强调安全性、效率和标准化，以兼顾所有主要利益相关者的需求。这一重构旨在克服现有界面的根本限制，为更高效、可靠和透明的网络代理设计铺平道路，这将是机器学习社区广泛合作的成果。

</details>


### [609] [Time To Impeach LLM-as-a-Judge: Programs are the Future of Evaluation](https://arxiv.org/abs/2506.10403)
**中文标题：废除LLM作为评判者的时代：程序是评估的未来**

*Tzu-Heng Huang,Harit Vishwakarma,Frederic Sala*

Main category: cs.LG

TL;DR: 论文提出PAJAMA方法，通过LLM生成可执行的评判程序替代直接评分，显著降低成本并提高评判的一致性和公正性。


<details>
  <summary>Details</summary>
Motivation: 当前使用大型语言模型（LLM）直接评估生成内容存在高成本、可靠性不确定、流程僵化和固有偏见等问题，亟需一种更高效、透明且灵活的替代方案。

Method: 提出PAJAMA方法，利用LLM合成可执行的评判程序，而非直接评分。这些程序可本地存储和运行，成本极低且逻辑透明、可审计。

Result: PAJAMA显著减少了偏见，评判一致性提高15.83%，偏见响应减少23.7%。在CHAT-HARD子集上表现优于LLM直接评判，Prometheus和JudgeLM数据集分别提升2.19%和8.67%，成本降低三个数量级。

Conclusion: PAJAMA为LLM评估提供了一种高效、透明且低成本的替代方案，显著提升了评判的公正性和一致性。

摘要: 大型语言模型（LLM）被广泛用于评估LLM生成内容和回答的质量，但这种方法带来了显著挑战：高昂的API成本、可靠性不确定、流程僵化以及固有偏见。为解决这些问题，我们提出了PAJAMA（Program-As-a-Judge for Automated Model Assessment），一种新方法，利用LLM合成可执行的评判程序而非直接评分。这些合成程序可本地存储和运行，成本极低，同时提供透明且可审计的评判逻辑，易于调整。基于程序的评判减少了偏见，与基于Qwen2.5-14B的LLM直接评判相比，评判一致性提高了15.83%，偏见响应平均减少了23.7%。当程序评判结果被提炼为模型时，PAJAMA在RewardBench的CHAT-HARD子集上表现优于LLM直接评判，Prometheus和JudgeLM数据集分别提升了2.19%和8.67%，而成本降低了三个数量级。

</details>


### [610] [Balanced Hyperbolic Embeddings Are Natural Out-of-Distribution Detectors](https://arxiv.org/abs/2506.10146)
**中文标题：平衡双曲嵌入是天然的分布外检测器**

*Tejaswi Kasarla,Max van Spengler,Pascal Mettes*

Main category: cs.LG

TL;DR: 本文提出了一种基于平衡双曲嵌入的方法，用于高效识别分布外样本，实验证明其在13个数据集和13种评分函数中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习中的分布外识别是一个重要问题，旨在过滤掉不属于训练分布的样本。本文旨在探索双曲嵌入在分布外检测中的优势。

Method: 提出了平衡双曲学习方法，通过优化层次失真和子层次平衡的双曲类嵌入算法，并将其用作分类的双曲原型。还扩展了现有的分布外评分函数以支持双曲原型。

Result: 在13个数据集和13种评分函数上的实验表明，该方法优于现有分布外检测方法，且优于其他双曲方法和对比学习方法，并能自然支持层次化分布外泛化。

Conclusion: 良好的层次化双曲嵌入更适合区分分布内和分布外样本，平衡双曲学习方法在分布外检测中表现出色。

摘要: 分布外识别是深度学习中的一个重要且研究充分的问题，其目标是过滤掉不属于网络训练分布的样本。本文的结论很简单：良好的层次化双曲嵌入更适合区分分布内和分布外样本。我们提出了平衡双曲学习方法，介绍了一种双曲类嵌入算法，该算法联合优化了层次失真和浅层与宽子层次之间的平衡。然后，我们将类嵌入用作分类的双曲原型，并概述了如何将现有的分布外评分函数推广到支持双曲原型。在13个数据集和13种评分函数上的实证评估表明，我们的双曲嵌入在使用相同数据和相同主干网络训练时优于现有的分布外检测方法。我们还表明，我们的双曲嵌入优于其他双曲方法，击败了最先进的对比方法，并自然地支持层次化分布外泛化。

</details>


### [611] [Geometric Regularity in Deterministic Sampling of Diffusion-based Generative Models](https://arxiv.org/abs/2506.10177)
**中文标题：基于扩散生成模型的确定性采样中的几何规律性**

*Defang Chen,Zhenyu Zhou,Can Wang,Siwei Lyu*

Main category: cs.LG

TL;DR: 本文揭示了基于扩散的生成模型在确定性采样中的几何规律性，发现采样轨迹集中在极低维子空间且形状相似，并提出了一种动态规划方法优化采样时间表，显著提升了图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 扩散生成模型通过随机微分方程（SDE）和概率流常微分方程（ODE）实现复杂数据分布与简单先验分布之间的平滑转换。本文旨在揭示确定性采样过程中的几何规律性，并探索其实际应用价值。

Method: 通过分析采样轨迹的几何特性，发现其集中在低维子空间且形状相似。基于此，提出了一种动态规划方法，优化采样时间表以更好地匹配轨迹结构。

Result: 研究发现采样轨迹具有高度规律性，且提出的动态规划方法在仅需5~10次函数评估的情况下，显著提升了图像生成性能。

Conclusion: 本文揭示了扩散生成模型中确定性采样的几何规律性，并提出了一种简单有效的优化方法，为高效采样提供了新思路。

摘要: 基于扩散的生成模型利用随机微分方程（SDE）及其等效的概率流常微分方程（ODE），在复杂高维数据分布与易处理的先验分布之间建立平滑转换。本文揭示了确定性采样动态中的显著几何规律性：每条模拟采样轨迹均位于极低维子空间内，且所有轨迹均呈现出几乎相同的“回旋镖”形状，不受模型架构、应用条件或生成内容的影响。我们描述了这些轨迹的若干有趣特性，特别是在基于核估计数据建模的闭式解下。此外，我们还展示了所发现轨迹规律性的实际应用，提出了一种基于动态规划的方法，以更好地将采样时间表与底层轨迹结构对齐。这一简单策略仅需对现有基于ODE的数值求解器进行最小修改，计算开销可忽略不计，并在仅需5~10次函数评估的区域中实现了更优的图像生成性能。

</details>


### [612] [Size-adaptive Hypothesis Testing for Fairness](https://arxiv.org/abs/2506.10586)
**中文标题：公平性评估的自适应假设检验**

*Antonio Ferrara,Francesco Cozzi,Alan Perotti,André Panisson,Francesco Bonchi*

Main category: cs.LG

TL;DR: 本文提出了一种基于统计假设检验的自适应公平性评估框架，解决了传统方法在稀疏数据和小群体分析中的统计脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 传统公平性评估方法依赖于单点估计与预设阈值的比较，忽略了抽样误差，且在交叉性分析中因数据稀疏导致置信区间过宽，无法可靠判断不公平性。

Method: 提出统一的自适应假设检验框架：(i) 对大群体，证明统计差异的中央极限定理，提供解析置信区间和Wald检验；(ii) 对小群体，采用贝叶斯Dirichlet-多项式估计器，通过蒙特卡洛可信区间适应任何样本量。

Result: 在基准数据集上的实验验证表明，该方法能在不同数据量和交叉性条件下提供可解释且统计严谨的公平性决策。

Conclusion: 该框架为公平性评估提供了统计上可靠且适应性强的方法，尤其适用于稀疏数据和小群体的交叉性分析。

摘要: 判断算法决策系统是否歧视特定群体通常涉及将公平性指标的单点估计与预设阈值比较。这种做法在统计上脆弱：它忽略抽样误差，并将小规模群体与大规模群体同等对待。在交叉性分析中，问题更为严重，因为多个敏感属性联合分析会产生更多小群体。随着群体细分，数据变得稀疏，公平性指标的置信区间过宽，无法得出关于潜在不公平的有意义结论。
本文提出了一种统一的、自适应的假设检验框架，将公平性评估转化为基于证据的统计决策。我们的贡献有两点：(i) 对于足够大的群体，证明了统计差异的中央极限定理，提供了解析置信区间和Wald检验，其第一类错误（假阳性）控制在水平α；(ii) 对于长尾的小交叉群体，推导了完全贝叶斯的Dirichlet-多项式估计器；蒙特卡洛可信区间适用于任何样本量，并随着数据增加自然收敛到Wald区间。我们在基准数据集上验证了该方法，展示了测试如何在数据可用性和交叉性变化条件下提供可解释且统计严谨的决策。

</details>


### [613] [Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning](https://arxiv.org/abs/2506.10629)
**中文标题：从技能到任务适应：信息几何、解耦与无监督强化学习的新目标**

*Yucheng Yang,Tianyi Zhou,Qiang He,Lei Han,Mykola Pechenizkiy,Meng Fang*

Main category: cs.LG

TL;DR: 本文通过信息几何和Wasserstein距离改进无监督强化学习中的技能学习方法，提出新的解耦度量LSEPIN和算法WSEP、PWSEP，以提升下游任务适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督强化学习方法（如MISL）缺乏对技能多样性和可分性的理论分析，无法保证下游任务适应效果。本文旨在填补这一理论空白并提出改进方法。

Method: 1. 提出解耦度量LSEPIN；2. 建立信息几何与下游任务适应成本的联系；3. 用Wasserstein距离替代KL散度，提出新目标WSEP和算法PWSEP。

Result: WSEP和PWSEP在理论上能更好地适应下游任务，并发现更多初始策略，优于MISL。

Conclusion: 通过信息几何和Wasserstein距离改进技能学习，显著提升了下游任务适应能力，为无监督强化学习提供了新方向。

摘要: 无监督强化学习（URL）旨在为未见的下游任务学习通用技能。互信息技能学习（MISL）通过最大化状态与技能间的互信息来解决URL问题，但缺乏足够的理论分析，例如其学习到的技能如何初始化下游任务的策略。本文的新理论分析表明，学习技能的多样性和可分性对下游任务适应至关重要，但MISL未必能保证这些特性。为补充MISL，我们提出了一种新的解耦度量LSEPIN。此外，我们建立了LSEPIN与下游任务适应成本之间的信息几何联系。为获得更好的几何特性，我们研究了一种新策略，用Wasserstein距离替代信息几何中的KL散度。我们将其几何分析扩展到WSEP这一新的技能学习目标，理论上证明其有助于下游任务适应，并能比MISL发现更多初始策略。最后，我们提出另一种基于Wasserstein距离的算法PWSEP，理论上可以发现所有最优初始策略。

</details>


### [614] [Time Series Forecasting as Reasoning: A Slow-Thinking Approach with Reinforced LLMs](https://arxiv.org/abs/2506.10630)
**中文标题：时间序列预测作为推理：基于慢思考范式与强化LLMs的方法**

*Yucong Luo,Yitong Zhou,Mingyue Cheng,Jiahao Wang,Daoyu Wang,Tingyue Pan,Jintao Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于慢思考范式的时间序列预测方法Time-R1，通过两阶段强化微调框架增强LLMs的多步推理能力，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法多依赖快速思考范式，缺乏显式的时间序列推理过程，而新兴的慢思考LLMs虽具备多步推理能力，但仅依赖提示工程存在计算成本高、隐私风险等问题。

Method: 提出Time-R1框架：第一阶段为监督微调进行预热适应，第二阶段通过强化学习提升模型泛化能力，并设计细粒度多目标奖励和GRIP方法优化推理路径探索。

Result: 实验表明，Time-R1在多样化数据集上显著提升了预测性能。

Conclusion: Time-R1通过慢思考范式和强化微调框架，有效增强了LLMs在时间序列预测中的推理能力，为未来研究提供了新方向。

摘要: 为了推进时间序列预测（TSF）的发展，已有多种方法被提出以提高预测准确性，从统计技术发展到数据驱动的深度学习架构。尽管这些方法有效，但大多数仍遵循快速思考范式——依赖提取历史模式并将其映射到未来值作为核心建模理念，缺乏一个显式的思考过程来整合中间时间序列推理。与此同时，新兴的慢思考LLMs（如OpenAI-o1）展现了卓越的多步推理能力，为解决这些问题提供了新途径。然而，仅依赖提示工程存在诸多限制，包括高计算成本、隐私风险以及对深入领域特定时间序列推理能力的限制。为解决这些限制，一种更有前景的方法是训练LLMs以发展慢思考能力并获取强大的时间序列推理技能。为此，我们提出了Time-R1，一个两阶段强化微调框架，旨在增强LLMs在时间序列预测中的多步推理能力。具体而言，第一阶段进行监督微调以实现预热适应，而第二阶段采用强化学习提升模型的泛化能力。特别地，我们设计了一个针对时间序列预测的细粒度多目标奖励，并引入了GRIP（基于组的相对重要性策略优化），通过非均匀采样进一步鼓励和优化模型对有效推理路径的探索。实验表明，Time-R1在多样化数据集上显著提升了预测性能。

</details>


### [615] [Data Shifts Hurt CoT: A Theoretical Study](https://arxiv.org/abs/2506.10647)
**中文标题：数据变化损害思维链：一项理论研究**

*Lang Yin,Debangshu Banerjee,Gagandeep Singh*

Main category: cs.LG

TL;DR: 研究发现，思维链（CoT）在数据分布变化和数据污染的情况下，对模型性能产生负面影响，甚至比直接预测表现更差。


<details>
  <summary>Details</summary>
Motivation: 尽管CoT被证明能提升大语言模型的输出质量，但其依赖训练与测试数据分布一致且无污染的假设。现实中这些假设常不成立，因此研究数据变化对CoT的具体影响具有重要意义。

Method: 以$k$-奇偶问题为例，研究数据分布变化和数据污染对CoT分解训练模型质量的联合影响。

Result: 发现CoT在数据变化下表现更差，甚至不如直接预测，并揭示了其机制原因。

Conclusion: 数据变化对CoT的性能有显著负面影响，需在实际应用中警惕数据假设的局限性。

摘要: 思维链（CoT）已被应用于多种大语言模型（LLM），并被证明能有效提升输出质量。近期研究表明，变换器在表达能力上存在绝对上限，因此无法解决许多计算难题。然而，借助CoT，变换器被证明能有效解决某些难题，如$k$-奇偶问题。但这些研究依赖于两个关键假设：（1）训练与测试数据分布一致，（2）训练数据无污染且推理步骤正确。现实中这些假设常不成立。尽管数据变化的风险已引起关注，但本研究首次严格分析了此类变化的具体危害。以$k$-奇偶问题为例，本研究探讨了数据分布变化和数据污染对CoT分解训练模型质量的联合影响。除揭示CoT在奇偶问题学习上表现甚至不如直接预测的意外现象外，技术结果还严格全面地解释了其机制原因。

</details>


### [616] [Saturation Self-Organizing Map](https://arxiv.org/abs/2506.10680)
**中文标题：饱和度自组织映射**

*Igor Urbanik,Paweł Gajewski*

Main category: cs.LG

TL;DR: 本文提出了一种名为‘饱和度自组织映射（SatSOM）’的改进自组织映射方法，通过引入饱和度机制减少已学习神经元的更新，从而在持续学习中更好地保留知识。


<details>
  <summary>Details</summary>
Motivation: 持续学习中神经网络常面临灾难性遗忘问题，自组织映射（SOMs）虽高效且可解释，但同样存在此问题。本文旨在改进SOMs，提升其在持续学习中的知识保留能力。

Method: SatSOM引入了一种新颖的饱和度机制，随着神经元积累信息，逐渐降低其学习率和邻域半径，从而冻结训练充分的神经元并将学习重定向至未充分利用的区域。

Result: SatSOM在持续学习场景中表现出更好的知识保留能力，有效减少了灾难性遗忘问题。

Conclusion: SatSOM通过饱和度机制改进了传统SOMs，为持续学习提供了一种更高效的解决方案。

摘要: 持续学习对神经系统提出了根本性挑战，神经网络在顺序任务中常遭受灾难性遗忘问题。尽管自组织映射（SOMs）具有可解释性和高效性，但同样无法避免这一问题。本文提出了一种改进的自组织映射方法——饱和度自组织映射（SatSOM），旨在提升持续学习中的知识保留能力。SatSOM引入了一种新颖的饱和度机制，随着神经元积累信息，逐渐降低其学习率和邻域半径，从而冻结训练充分的神经元，并将学习重定向至未充分利用的区域。

</details>


### [617] [Hessian Geometry of Latent Space in Generative Models](https://arxiv.org/abs/2506.10632)
**中文标题：生成模型潜在空间的Hessian几何**

*Alexander Lobashev,Dmitry Guskov,Maria Larchenko,Mikhail Tamm*

Main category: cs.LG

TL;DR: 本文提出了一种新方法，通过重构Fisher信息度量来分析生成模型（如统计物理模型和扩散模型）的潜在空间几何结构。该方法在Ising和TASEP模型上验证，优于现有基线，并揭示了扩散模型潜在空间中的分形相变结构。


<details>
  <summary>Details</summary>
Motivation: 生成模型的潜在空间几何结构复杂，现有方法难以准确分析其特性，尤其是与相变等现象的联系。本文旨在通过Fisher信息度量重构，揭示潜在空间的结构及其动态变化。

Method: 通过近似潜在变量的后验分布，学习对数配分函数，从而定义指数族的Fisher度量。理论收敛性得到保证，并在统计物理模型和扩散模型上验证。

Result: 在Ising和TASEP模型中，方法优于现有基线；扩散模型的潜在空间显示出分形相变结构，Fisher度量在相边界处突变，测地线插值在相内近似线性但在边界处失效。

Conclusion: 该方法为生成模型潜在空间的复杂结构提供了新见解，揭示了其与相变等现象的联系，并为未来研究提供了工具。

摘要: 本文提出了一种新方法，通过重构Fisher信息度量来分析生成模型（包括统计物理模型和扩散模型）的潜在空间几何结构。该方法近似潜在变量在生成样本下的后验分布，并利用此学习对数配分函数，从而定义指数族的Fisher度量。理论收敛性得到保证，并在Ising和TASEP模型上验证，优于现有基线。应用于扩散模型时，该方法揭示了潜在空间中相变的分形结构，表现为Fisher度量的突变。研究表明，测地线插值在单个相内近似线性，但在相边界处失效，扩散模型在潜在空间中的Lipschitz常数在此处发散。这些发现为扩散模型潜在空间的复杂结构及其与相变等现象的联系提供了新见解。源代码见https://github.com/alobashev/hessian-geometry-of-diffusion-models。

</details>


### [618] [ConTextTab: A Semantics-Aware Tabular In-Context Learner](https://arxiv.org/abs/2506.10707)
**中文标题：ConTextTab：一种语义感知的表格上下文学习模型**

*Marco Spinaci,Marek Polewczyk,Maximilian Schambach,Sam Thelin*

Main category: cs.LG

TL;DR: ConTextTab是一种结合语义理解和表格原生框架的上下文学习模型，通过在真实世界数据上训练，实现了在多个基准测试中的优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前表格原生ICL模型仅依赖合成数据，未能充分利用真实表格数据的语义信息；而基于大型语言模型的表格ICL模型虽具备语义理解能力，但受限于架构，无法利用大量上下文。ConTextTab旨在结合两者的优势。

Method: ConTextTab通过为不同数据模态设计专用嵌入，并在大规模真实表格数据上训练，将语义理解融入表格原生ICL框架。

Result: ConTextTab在多个基准测试中表现优异，尤其在语义丰富的CARTE基准上创下新纪录。

Conclusion: ConTextTab成功结合了语义理解和表格原生ICL的优势，为表格预测任务提供了高效且语义感知的解决方案。

摘要: 表格上下文学习（ICL）最近在多个表格预测任务中取得了最先进的性能。此前仅限于小表格的分类问题，TabPFN和TabICL等最新进展已将其扩展到更大的数据集。尽管架构高效且适应表格数据结构，当前基于合成数据训练的表格原生ICL架构未能充分利用真实表格数据中的丰富语义和世界知识。另一方面，基于预训练大型语言模型（如TabuLa-8B）的表格ICL模型虽具备深度语义理解和世界知识，但由于架构限制，仅能利用少量上下文。为了结合两者的优势，我们提出了ConTextTab，将语义理解和对齐融入表格原生ICL框架。通过为不同数据模态设计专用嵌入并在大规模真实表格数据上训练，我们的模型在多个基准测试中表现优异，并在语义丰富的CARTE基准上创下新纪录。

</details>


### [619] [ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems](https://arxiv.org/abs/2506.10955)
**中文标题：Error**

*Aayush Karan,Kulin Shah,Sitan Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

摘要: Error

</details>


### [620] [Efficiency Robustness of Dynamic Deep Learning Systems](https://arxiv.org/abs/2506.10831)
**中文标题：动态深度学习系统的效率鲁棒性**

*Ravishka Rathnasuriya,Tingxi Li,Zexin Xu,Zihe Song,Mirazul Haque,Simin Chen,Wei Yang*

Main category: cs.LG

TL;DR: 本文系统研究了动态深度学习系统（DDLSs）的效率鲁棒性，首次提出效率攻击的全面分类，并分析了现有防御机制的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习系统（DLSs）在实时应用中的部署增加，动态深度学习系统（DDLSs）通过动态调整计算以提高效率，但同时也引入了新的攻击面，效率对抗攻击可能利用这些动态机制降低系统性能。

Method: 通过分类效率攻击（基于动态计算、动态推理迭代和动态输出生成）并进行深入评估，分析针对DDLSs效率的对抗策略，同时研究现有防御机制。

Result: 研究发现现有防御机制对日益流行的效率攻击效果有限，揭示了保护未来自适应DDLSs需要新的缓解策略。

Conclusion: 动态深度学习系统的效率鲁棒性面临严峻挑战，亟需开发新的防御机制以应对效率攻击。

摘要: 深度学习系统（DLSs）越来越多地部署在实时应用中，包括资源受限的环境（如移动和物联网设备）。为解决效率挑战，动态深度学习系统（DDLSs）根据输入复杂性调整推理计算以减少开销。然而，这种动态行为引入了新的攻击面，效率对抗攻击利用这些动态机制降低系统性能。本文系统研究了DDLSs的效率鲁棒性，首次提出了效率攻击的全面分类。这些攻击基于三种动态行为：（i）针对每次推理动态计算的攻击，（ii）针对动态推理迭代的攻击，（iii）针对下游任务动态输出生成的攻击。通过深入评估，我们分析了针对DDLSs效率的对抗策略，并确定了保护这些系统的关键挑战。此外，我们研究了现有防御机制，证明其对日益流行的效率攻击的局限性，以及保护未来自适应DDLSs需要新的缓解策略。

</details>


### [621] [Understanding In-Context Learning on Structured Manifolds: Bridging Attention to Kernel Methods](https://arxiv.org/abs/2506.10959)
**中文标题：理解结构化流形上的上下文学习：从注意力机制到核方法的桥梁**

*Zhaiming Shen,Alexander Hsu,Rongjie Lai,Wenjing Liao*

Main category: cs.LG

TL;DR: 本文通过建立注意力机制与经典核方法之间的联系，首次从理论上研究了在流形结构数据上的上下文学习（ICL），并推导了泛化误差界限，揭示了变换器作为上下文算法学习器的复杂性。


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习（ICL）在自然语言和视觉领域取得了显著成功，但其在结构化几何数据上的理论理解仍未被探索。本文旨在填补这一空白，研究ICL在流形上的回归问题。

Method: 通过建立注意力机制与经典核方法之间的新联系，本文研究了流形上Hölder函数的回归问题，并推导了泛化误差界限，分析了提示长度和训练任务数量的影响。

Result: 当观察到足够多的训练任务时，变换器能够达到流形上Hölder函数的最小最大回归率，其误差随流形的内蕴维度而非环境空间维度呈指数级变化。结果还揭示了泛化误差如何随训练任务数量变化。

Conclusion: 本文为理解几何在ICL中的作用提供了基础性见解，并为研究非线性模型的ICL提供了新工具。

摘要: 尽管上下文学习（ICL）在自然语言和视觉领域取得了显著成功，但其在结构化几何数据上的理论理解——尤其是在流形上的回归问题——仍未被探索。本文首次从理论上研究了流形上Hölder函数的ICL回归问题。通过建立注意力机制与经典核方法之间的新联系，我们推导了泛化误差界限，该界限与提示长度和训练任务数量相关。当观察到足够多的训练任务时，变换器能够达到流形上Hölder函数的最小最大回归率，其误差随流形的内蕴维度而非环境空间维度呈指数级变化。我们的结果还揭示了泛化误差如何随训练任务数量变化，为理解变换器作为上下文算法学习器的复杂性提供了新视角。这些发现为理解几何在ICL中的作用提供了基础性见解，并为研究非线性模型的ICL提供了新工具。

</details>


### [622] [Farseer: A Refined Scaling Law in Large Language Models](https://arxiv.org/abs/2506.10972)
**中文标题：Farseer：大型语言模型中的一种精细化扩展定律**

*Houyi Li,Wenzhen Zheng,Qiufeng Wang,Zhenyu Ding,Haoying Wang,Zili Wang,Shijie Xuyang,Ning Ding,Shuigeng Zhou,Xiangyu Zhang,Daxin Jiang*

Main category: cs.LG

TL;DR: Farseer 是一种改进的扩展定律，显著提升了大型语言模型（LLM）训练中的预测准确性，相比 Chinchilla 定律减少了 433% 的外推误差，并为计算资源分配提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 训练大型语言模型成本高昂，小规模实验的结论难以直接应用于大规模生产系统，阻碍了高效创新。Farseer 旨在填补这一扩展鸿沟。

Method: 通过系统构建模型损失表面 $L(N,D)$，Farseer 提供了比现有定律（如 Chinchilla 定律）更准确的拟合，并验证了其外推能力。

Result: Farseer 显著提升了预测准确性，外推误差比 Chinchilla 定律减少 433%，并提供了更优的计算资源分配策略。

Conclusion: Farseer 为 LLM 训练提供了可靠的预测工具，支持从小规模实验推断大规模性能，并开源了所有模型、数据和结果。

摘要: 训练大型语言模型（LLM）的成本极高，导致小规模实验的结论难以直接应用于资源密集的生产系统，从而阻碍了高效创新。为了填补这一鸿沟，我们提出了 Farseer，一种新颖且精细化的扩展定律，能够在不同规模下提供更高的预测准确性。通过系统构建模型损失表面 $L(N,D)$，Farseer 对实验数据的拟合效果显著优于现有定律（如 Chinchilla 定律）。我们的方法提供了准确、稳健且高度可推广的预测，展示了出色的外推能力，将外推误差比 Chinchilla 定律降低了 433%。这使得我们能够可靠地评估所有 $(N,D)$ 设置下的竞争性训练策略，并从小规模消融研究中自信地推断出大规模性能。此外，Farseer 为计算资源的最优分配提供了新见解，更好地反映了现代 LLM 训练的复杂需求。为了验证我们的方法，我们训练了约 1,000 个不同规模和配置的 LLM，消耗了约 300 万 NVIDIA H100 GPU 小时。我们全面开源了所有模型、数据、结果和日志，网址为 https://github.com/Farseer-Scaling-Law/Farseer，以促进进一步研究。

</details>


### [623] [Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning](https://arxiv.org/abs/2506.10973)
**中文标题：将神经网络架构扩展到函数空间的原理性方法：算子学习**

*Julius Berner,Miguel Liu-Schiaffini,Jean Kossaifi,Valentin Duruisseaux,Boris Bonev,Kamyar Azizzadenesheli,Anima Anandkumar*

Main category: cs.LG

TL;DR: 本文提出了一种将神经网络架构扩展到函数空间的方法，以支持算子学习，特别是针对科学问题中的无限维函数空间映射。通过提炼关键原则，作者提供了一种将现有神经网络架构转换为神经算子的实用方法。


<details>
  <summary>Details</summary>
Motivation: 科学问题（如连续时间动力系统和偏微分方程）通常涉及无限维函数空间，而传统深度学习方法主要针对有限维空间。这种差异限制了神经网络在科学应用中的成功。神经算子提供了一种将神经网络扩展到函数空间的方法，但现有架构多为独立模型，未直接基于现有神经网络架构扩展。本文旨在填补这一空白。

Method: 作者提炼了构建无限维函数空间映射的关键原则，并提出了一种将多种流行神经网络架构转换为神经算子的方法。该方法仅需对现有架构进行最小修改。

Result: 通过提出的方法，成功将多种神经网络架构转换为神经算子，为科学问题中的算子学习提供了实用工具。代码已开源。

Conclusion: 本文为将神经网络扩展到函数空间提供了实用指南，帮助研究者在科学问题中应用神经算子。

摘要: 许多科学问题（如连续时间动力系统和偏微分方程）通常在函数空间中描述。尽管函数空间通常是无限维的，但深度学习主要在计算机视觉和自然语言处理等有限维空间映射中取得进展。这种数据性质的差异限制了神经网络在科学应用中的成功。神经算子是一种将神经网络推广到函数空间映射的原理性方法，为科学问题提供了复制深度学习变革性影响的途径。例如，神经算子可以学习整个偏微分方程类的解算子，如具有不同边界条件、系数函数和几何形状的物理系统。深度学习成功的关键在于通过大量实证测试精心设计神经网络架构。将这些神经网络架构转化为神经算子，使算子学习也能享受这些实证优化。然而，现有的神经算子架构多为独立模型，并未直接基于现有神经网络架构扩展。本文提炼了构建无限维函数空间映射的关键原则，并提出了一种将多种流行神经网络架构转换为神经算子的方法，仅需最小修改。本文旨在指导实践者完成这一过程，并详细说明如何使神经算子在实际中发挥作用。代码可在https://github.com/neuraloperator/NNs-to-NOs找到。

</details>


### [624] [Rethinking Losses for Diffusion Bridge Samplers](https://arxiv.org/abs/2506.10982)
**中文标题：重新思考扩散桥采样器的损失函数**

*Sebastian Sanokowski,Lukas Gruber,Christoph Bartmann,Sepp Hochreiter,Sebastian Lehner*

Main category: cs.LG

TL;DR: 本文探讨了扩散桥采样器中损失函数的选择问题，发现反向KL损失（rKL-LD）在性能和稳定性上优于对数方差损失（LV），并提出了理论支持。


<details>
  <summary>Details</summary>
Motivation: 扩散桥采样器在深度学习中用于从未归一化分布中采样，但现有损失函数（如LV损失）在理论动机和性能上存在不足。本文旨在重新评估损失函数的选择，尤其是rKL-LD损失的优越性。

Method: 通过理论分析比较LV损失和rKL-LD损失的梯度等价性，并在扩散桥和可学习扩散系数场景下验证rKL-LD的适用性。实验使用多种扩散桥类型和基准测试进行验证。

Result: 实验表明，rKL-LD损失在性能上优于LV损失，且训练更稳定，超参数优化需求更少。

Conclusion: rKL-LD损失不仅解决了LV损失的理论缺陷，还在实际应用中表现出更好的性能和稳定性，是扩散桥采样器的更优选择。

摘要: 扩散桥是一类有前景的深度学习方法，用于从未归一化分布中采样。近期研究表明，在使用重参数化技巧计算rKL梯度时，对数方差（LV）损失始终优于反向Kullback-Leibler（rKL）损失。然而，对于扩散桥或可学习扩散系数的场景，LV损失与rKL损失的梯度等价性不再成立。基于这一发现，我们认为LV损失无法像rKL损失那样通过数据处理不等式得到理论支持。分析表明，使用对数导数技巧的rKL损失（rKL-LD）不仅避免了这些概念问题，还在性能上持续优于LV损失。在多种扩散桥和挑战性基准测试中的实验结果表明，使用rKL-LD损失的采样器表现更优。从实践角度看，rKL-LD损失需要更少的超参数优化，且训练更稳定。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [625] [From Threat to Tool: Leveraging Refusal-Aware Injection Attacks for Safety Alignment](https://arxiv.org/abs/2506.10020)
**中文标题：从威胁到工具：利用拒绝感知注入攻击实现安全对齐**

*Kyubyung Chae,Hyunbin Jin,Taesup Kim*

Main category: cs.CR

TL;DR: The paper introduces RAAI, a training-free method to repurpose LLM attack techniques for safety alignment, significantly increasing harmful response rates and improving model robustness through synthetic data.


<details>
  <summary>Details</summary>
Motivation: Current methods for safety alignment of LLMs are costly and time-consuming, relying on human-labeled data or complex synthetic data generation. The paper aims to simplify and improve this process by leveraging attack techniques.

Method: The authors propose Refusal-Aware Adaptive Injection (RAAI), which detects refusal signals in LLMs and injects predefined phrases to generate harmful completions. This synthetic data is then used for fine-tuning.

Result: RAAI increased harmful response rates from 2.15% to 61.04% on average across benchmarks. Fine-tuning with RAAI-generated data improved model robustness against harmful prompts without compromising general capabilities.

Conclusion: The study demonstrates that LLM attack methodologies can be repurposed as practical tools for scalable and controllable safety alignment.

摘要: 安全对齐大型语言模型（LLM）通常需要大量人工标注的偏好数据，这一过程既昂贵又耗时。虽然合成数据提供了一种有前景的替代方案，但当前方法往往依赖于复杂的迭代提示或辅助模型。为解决这一问题，我们引入了拒绝感知自适应注入（RAAI），这是一种简单、无需训练且模型无关的框架，通过重新利用LLM攻击技术实现。RAAI通过检测内部拒绝信号并自适应注入预定义短语，以引出有害但流畅的补全。实验表明，RAAI有效破解了LLM，将有害响应率从基线2.15%提升至平均61.04%（在四个基准测试中）。关键的是，使用RAAI生成的合成数据对LLM进行微调，可以增强模型对有害提示的鲁棒性，同时保留在标准任务（如MMLU和ARC）上的通用能力。这项工作展示了如何将LLM攻击方法重新定义为可扩展且可控的安全对齐工具。

</details>


### [626] [LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges](https://arxiv.org/abs/2506.10022)
**中文标题：大型语言模型陷入交火：恶意请求与越狱挑战**

*Haoyang Li,Huan Gao,Zhiyuan Zhao,Zhiyu Lin,Junyu Gao,Xuelong Li*

Main category: cs.CR

TL;DR: The paper introduces MalwareBench, a benchmark dataset to evaluate LLMs' vulnerability to jailbreak attacks in malicious code generation, revealing their limited ability to reject such threats.


<details>
  <summary>Details</summary>
Motivation: To address the unexplored susceptibility of LLMs to jailbreak attacks in code generation, highlighting security gaps.

Method: Developed MalwareBench with 3,520 jailbreaking prompts based on 320 malicious code requirements, testing 11 jailbreak methods and 29 code categories.

Result: Mainstream LLMs struggle to reject malicious requests (60.93% rejection rate), which drops to 39.92% with combined jailbreak methods.

Conclusion: LLMs' code security capabilities remain a significant challenge, necessitating further research and improvements.

摘要: 大型语言模型（LLMs）的广泛应用引发了对其安全性的担忧，尤其是其易受越狱攻击的脆弱性，这些攻击利用精心设计的提示生成恶意输出。尽管已有研究探讨了LLMs的一般安全能力，但其在代码生成中对越狱攻击的特定易感性仍未被充分研究。为填补这一空白，我们提出了MalwareBench，一个包含3,520个恶意代码生成越狱提示的基准数据集，旨在评估LLMs对此类威胁的鲁棒性。MalwareBench基于320个手工制作的恶意代码生成需求，涵盖11种越狱方法和29种代码功能类别。实验表明，主流LLMs在拒绝恶意代码生成需求方面能力有限，而多种越狱方法的结合进一步降低了模型的安全能力：具体而言，恶意内容的平均拒绝率为60.93%，结合越狱攻击算法后降至39.92%。我们的工作表明，LLMs的代码安全能力仍面临重大挑战。

</details>


### [627] [Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models](https://arxiv.org/abs/2506.10024)
**中文标题：私有记忆编辑：将记忆转化为防御手段以增强大型语言模型的数据隐私**

*Elena Sofia Ruzzetti,Giancarlo A. Xompero,Davide Venditti,Fabio Massimo Zanzotto*

Main category: cs.CR

TL;DR: The paper introduces Private Memorization Editing (PME), a method to prevent private data leakage in LLMs by detecting and editing memorized PII, turning memorization into a defense strategy.


<details>
  <summary>Details</summary>
Motivation: LLMs may memorize Personally Identifiable Information (PII), posing privacy risks. The paper aims to leverage this memorization ability to defend against privacy attacks.

Method: PME detects memorized PII and edits the model's knowledge to mitigate memorization, without affecting the model's performance.

Result: PME effectively reduces leaked PII, sometimes reducing privacy attack accuracy to zero, while maintaining model functionality.

Conclusion: PME transforms LLM memorization into a privacy defense, robustly preventing PII leakage without compromising model performance.

摘要: 大型语言模型（LLMs）会记忆大量未受控制的数据，其中可能包含不应存储或泄露的个人身份信息（PII）。本文提出私有记忆编辑（PME）方法，通过将LLMs的记忆能力转化为隐私防御策略，防止私有数据泄露。虽然针对LLMs的攻击利用了其训练数据的先验知识，但我们的方法旨在利用同类知识增强模型的鲁棒性。我们检测记忆的PII，并通过编辑模型对训练数据的知识来减轻PII的记忆。实验证明，该方法不影响底层语言模型，同时使其更抗隐私训练数据提取攻击。PME能在多种配置下有效减少泄露的PII数量，某些情况下甚至将隐私攻击的准确率降至零。

</details>


### [628] [Evaluation empirique de la sécurisation et de l'alignement de ChatGPT et Gemini: analyse comparative des vulnérabilités par expérimentations de jailbreaks](https://arxiv.org/abs/2506.10029)
**中文标题：ChatGPT与Gemini的安全性与对齐性实证评估：通过越狱实验的漏洞比较分析**

*Rafaël Nouailles*

Main category: cs.CR

TL;DR: The paper compares the security and alignment of ChatGPT and Gemini, analyzing jailbreak techniques and vulnerabilities through experiments.


<details>
  <summary>Details</summary>
Motivation: To address cybersecurity challenges posed by LLMs, such as prompt injection and jailbreaking, by evaluating and comparing the security of ChatGPT and Gemini.

Method: Comparative analysis of ChatGPT and Gemini's security levels, including a taxonomy of jailbreak techniques and experimental validation.

Result: Identifies vulnerabilities in both models, highlighting differences in their susceptibility to jailbreak attacks and other security risks.

Conclusion: The study underscores the need for improved security measures in LLMs to mitigate risks like jailbreaking and misinformation.

摘要: 大型语言模型（LLMs）正在改变数字应用，特别是在文本生成、图像创作、信息检索和代码开发方面。OpenAI于2022年11月推出的ChatGPT迅速成为标杆，促使谷歌的Gemini等竞争对手的出现。然而，这些技术进步带来了新的网络安全挑战，包括提示注入攻击、规避监管措施（越狱）、错误信息传播（幻觉）以及与深度伪造相关的风险。本文对ChatGPT和Gemini的安全性和对齐性进行了比较分析，并提出了与实验相关的越狱技术分类。

</details>


### [629] [Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment](https://arxiv.org/abs/2506.10030)
**中文标题：在RAG即服务环境中保护多模态知识版权**

*Tianyu Chen,Jian Lou,Wenjie Wang*

Main category: cs.CR

TL;DR: AQUA is the first watermark framework for protecting image knowledge in Multimodal RAG systems, using acronym-based triggers and spatial cues to ensure robust and stealthy copyright tracing.


<details>
  <summary>Details</summary>
Motivation: Existing watermarking methods in RAG only protect textual knowledge, leaving image knowledge vulnerable, necessitating a solution for multimodal copyright protection.

Method: AQUA embeds semantic signals into synthetic images via acronym-based triggers and spatial relationship cues, ensuring watermark survival through indirect propagation.

Result: Experiments show AQUA is efficient, effective, and imperceptible, enabling robust and reliable copyright tracing in diverse models and datasets.

Conclusion: AQUA fills a critical gap in multimodal RAG protection by safeguarding image knowledge copyright with stealthy and reliable watermarking.

摘要: 随着检索增强生成（RAG）演变为共享知识库的服务导向平台（RAG即服务），保护贡献数据的版权变得至关重要。现有的RAG水印方法仅关注文本知识，而图像知识未受保护。本文提出AQUA，首个用于多模态RAG系统中图像知识保护的水印框架。AQUA通过两种互补方法将语义信号嵌入合成图像：基于缩写的触发器和空间关系线索。这些技术确保水印信号在从图像检索器到文本生成器的间接传播中存活，高效、有效且不可察觉。跨多种模型和数据集的实验表明，AQUA实现了稳健、隐蔽且可靠的版权追踪，填补了多模态RAG保护的关键空白。

</details>


### [630] [GenBreak: Red Teaming Text-to-Image Generators Using Large Language Models](https://arxiv.org/abs/2506.10047)
**中文标题：GenBreak：利用大型语言模型对文本到图像生成器进行红队测试**

*Zilong Wang,Xiang Zheng,Xiaosen Wang,Bo Wang,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CR

TL;DR: GenBreak is a framework that fine-tunes a large language model (LLM) to craft adversarial prompts for testing the safety of text-to-image (T2I) generators, revealing vulnerabilities in commercial models.


<details>
  <summary>Details</summary>
Motivation: Current red-teaming and adversarial attack methods for T2I models either produce easily detectable toxic images or fail to generate genuinely harmful outputs, leaving a gap in evaluating the safety of defended T2I models.

Method: GenBreak fine-tunes an LLM using supervised learning on curated datasets and reinforcement learning via interaction with a surrogate T2I model, integrating multiple reward signals to craft adversarial prompts that enhance evasion and toxicity.

Result: The crafted prompts effectively bypass safety filters in commercial T2I generators, demonstrating practical and concerning safety weaknesses.

Conclusion: GenBreak provides a reliable tool for evaluating T2I model safety by systematically uncovering vulnerabilities, highlighting the need for improved defenses.

摘要: 文本到图像（T2I）模型（如Stable Diffusion）发展迅速，广泛应用于内容创作。然而，这些模型可能被滥用于生成有害内容（如裸体或暴力），带来重大安全风险。尽管大多数平台采用内容审核系统，但潜在漏洞仍可能被恶意利用。目前针对T2I模型的红队测试和对抗攻击研究存在明显局限：一些研究成功生成高度有害图像，但使用的对抗提示容易被安全过滤器检测和拦截；另一些研究则专注于绕过安全机制，但未能生成真正有害的输出，忽视了高风险提示的发现。因此，目前缺乏可靠工具来评估防御性T2I模型的安全性。为解决这一问题，我们提出GenBreak框架，通过微调红队大型语言模型（LLM）系统性地探索T2I生成器的潜在漏洞。我们的方法结合了监督微调（基于精选数据集）和强化学习（通过与代理T2I模型交互），通过整合多种奖励信号，指导LLM生成既能增强规避能力又能提高图像毒性的对抗提示，同时保持语义连贯性和多样性。这些提示在针对商业T2I生成器的黑盒攻击中表现出强大的有效性，揭示了实际且令人担忧的安全弱点。

</details>


### [631] [Disclosure Audits for LLM Agents](https://arxiv.org/abs/2506.10171)
**中文标题：LLM代理的披露审计**

*Saswat Das,Jameson Sandler,Ferdinando Fioretto*

Main category: cs.CR

TL;DR: The paper proposes CMPL, an auditing framework to detect privacy risks in LLM agents through multi-turn interactions, revealing vulnerabilities missed by single-turn defenses.


<details>
  <summary>Details</summary>
Motivation: LLM agents handle sensitive data, increasing unauthorized disclosure risks; existing defenses focus on single-turn interactions, missing latent vulnerabilities in multi-turn scenarios.

Method: The CMPL framework uses iterative probing to stress-test agents, simulating realistic multi-turn interactions to systematically uncover privacy risks.

Result: CMPL successfully identifies privacy risks across diverse domains and safety configurations, outperforming single-turn defenses.

Conclusion: CMPL is an effective diagnostic tool for conversational privacy, offering quantifiable risk metrics and an open benchmark for future evaluations.

摘要: 大型语言模型代理已开始作为个人助理、客服机器人和临床助手出现。尽管这些应用带来了显著的操作优势，但它们也需要持续访问敏感数据，从而增加了未经授权披露的可能性。本研究提出了一种对话隐私的审计框架，用于量化和审计这些风险。所提出的对话操纵隐私泄露（CMPL）框架是一种迭代探测策略，旨在对执行严格隐私指令的代理进行压力测试。CMPL不仅关注单一披露事件，还模拟现实的多轮交互，系统地揭示潜在漏洞。我们在多样化领域、数据模态和安全配置上的评估表明，该审计框架能够揭示现有单轮防御无法阻止的隐私风险。除了将CMPL作为一种诊断工具引入外，本文还提供了（1）基于可量化风险指标的审计程序，（2）一个开放的基准，用于评估跨代理实现的对话隐私。

</details>


### [632] [Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods](https://arxiv.org/abs/2506.10236)
**中文标题：提示攻击揭示遗忘方法中的表面知识移除**

*Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz*

Main category: cs.CR

TL;DR: The paper reveals that some machine unlearning methods are vulnerable to prompt attacks, failing to truly remove knowledge despite appearing effective. It evaluates eight techniques, showing varying robustness, and emphasizes the need for better evaluation frameworks.


<details>
  <summary>Details</summary>
Motivation: To challenge the effectiveness of machine unlearning methods by demonstrating their vulnerability to prompt attacks and to highlight the gap between superficial output suppression and true knowledge removal.

Method: Systematically evaluated eight unlearning techniques across three model families using output-based, logit-based, and probe analysis to assess knowledge retrieval under prompt attacks.

Result: Some methods (e.g., RMU, TAR) showed robust unlearning, while others (e.g., ELM) were vulnerable, with specific attacks recovering up to 57.3% accuracy. Logit analysis confirmed unlearned models do not hide knowledge by formatting changes.

Conclusion: The study challenges assumptions about unlearning effectiveness, advocating for improved evaluation frameworks to distinguish true knowledge removal from superficial suppression.

摘要: 在这项工作中，我们表明，某些机器遗忘方法在面对简单的提示攻击时可能会失效。我们系统地评估了三种模型家族中的八种遗忘技术，并采用基于输出、基于逻辑和探针分析的方法，以确定所谓的遗忘知识在多大程度上可以被检索。尽管像RMU和TAR这样的方法表现出强大的遗忘能力，但ELM仍然容易受到特定提示攻击的影响（例如，原始提示中的印地语填充文本恢复了57.3%的准确率）。我们的逻辑分析还证实，遗忘模型通常不会通过修改答案的格式来隐藏知识，因为输出和逻辑准确性之间的相关性很强。这些结果挑战了关于遗忘有效性的普遍假设，并强调了需要能够可靠地区分真正知识移除和表面输出抑制的评估框架。我们还公开提供了我们的评估框架，以便轻松评估提示技术以检索遗忘知识。

</details>


### [633] [SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks](https://arxiv.org/abs/2506.10424)
**中文标题：SOFT：选择性数据混淆保护LLM微调免受成员推理攻击**

*Kaiyuan Zhang,Siyuan Cheng,Hanxi Guo,Yuetian Chen,Zian Su,Shengwei An,Yuntao Du,Charles Fleming,Ashish Kundu,Xiangyu Zhang,Ninghui Li*

Main category: cs.CR

TL;DR: The paper introduces SOFT, a defense technique to protect fine-tuned LLMs from membership inference attacks by selectively obfuscating data, balancing privacy and utility.


<details>
  <summary>Details</summary>
Motivation: Fine-tuning LLMs often involves sensitive data, making them vulnerable to membership inference attacks (MIAs), which exploit loss reduction during training to reveal membership information.

Method: SOFT (Selective data Obfuscation in LLM Fine-Tuning) uses influential data selection with an adjustable parameter to obfuscate sensitive data while preserving model utility.

Result: Experiments across six domains and multiple LLM architectures show SOFT effectively reduces privacy risks while maintaining competitive performance.

Conclusion: SOFT provides a practical and scalable solution to protect sensitive information in fine-tuned LLMs against MIAs.

摘要: 大型语言模型（LLMs）取得了显著成功并被广泛应用于各种场景。然而，微调这些模型通常涉及私有或敏感信息，引发了严重的隐私问题。本研究首次全面评估了微调LLMs对成员推理攻击（MIAs）的脆弱性。实证分析表明，MIAs利用微调过程中的损失减少，高效地揭示了成员信息。这些发现促使我们开发防御方法。我们提出了SOFT（选择性数据混淆在LLM微调中），这是一种新颖的防御技术，通过利用可调参数的影响数据选择来减轻隐私泄露，同时平衡效用保留和隐私保护。我们的广泛实验覆盖了六个不同领域和多种LLM架构及规模。结果显示，SOFT在保持模型性能的同时有效降低了隐私风险，为保护微调LLMs中的敏感信息提供了实用且可扩展的解决方案。

</details>


### [634] [Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications](https://arxiv.org/abs/2506.10467)
**中文标题：多智能体LLM系统的规范与评估——原型及网络安全应用**

*Felix Härer*

Main category: cs.CR

TL;DR: The paper explores the potential of multi-agent LLM systems by specifying and evaluating their architecture and prototype, particularly in cybersecurity applications.


<details>
  <summary>Details</summary>
Motivation: To address the lack of defined specifications for multi-agent LLM systems and explore their combined potential in specific domains like cybersecurity.

Method: Extends a system architecture and prototype from previous research, introduces a specification for multi-agent LLM systems, and evaluates them through cybersecurity tasks.

Result: The system successfully completed cybersecurity tasks, demonstrating feasibility in question answering, server security, and network security using OpenAI and DeepSeek LLMs.

Conclusion: The study highlights the potential of multi-agent LLM systems for complex tasks and the need for systematic specifications and evaluations.

摘要: 近期LLM的进展表明其在新型应用中的潜力，例如通过OpenAI和DeepSeek最新模型的推理能力。为了将这些模型应用于文本生成之外的特定领域，可以采用基于LLM的多智能体方法，通过结合推理技术、代码生成和软件执行来解决复杂任务。应用可能会利用这些能力以及专业LLM智能体的知识。然而，尽管对LLM、推理技术和应用进行了许多单独评估，但它们的联合规范和组合应用尚未得到充分探索。需要为多智能体LLM系统定义规范，以探索其潜力及其对特定应用的适用性，从而对LLM、推理技术及相关方面进行系统评估。本文报告了通过多智能体系统对这些方面进行规范和评估的探索性研究结果。系统架构和原型从先前研究中扩展而来，并引入了多智能体系统的规范。涉及网络安全任务的测试案例表明了架构和评估方法的可行性。特别是，结果显示了对OpenAI和DeepSeek的LLM智能体在问题回答、服务器安全和网络安全任务中的正确完成情况的评估。

</details>


### [635] [Secure Data Access in Cloud Environments Using Quantum Cryptography](https://arxiv.org/abs/2506.10028)
**中文标题：在云环境中使用量子密码学实现安全数据访问**

*S. Vasavi Venkata Lakshmi,Ziaul Haque Choudhury*

Main category: cs.CR

TL;DR: The paper proposes using quantum cryptography (QKD, BB84, and QOTP) to secure data in cloud environments, ensuring protection against future quantum computer threats.


<details>
  <summary>Details</summary>
Motivation: Traditional data security methods may become ineffective with the advent of quantum computers, necessitating quantum-based solutions for cloud data protection.

Method: The study employs Quantum Key Distribution (QKD) with the BB84 protocol to generate secure keys and Quantum One Time Pad (QOTP) for encryption and decryption.

Result: The combination of QKD, BB84, and QOTP provides a robust defense against hackers, even those with quantum computing capabilities.

Conclusion: Quantum cryptography offers a future-proof solution for securing cloud data, making cloud computing safer for users.

摘要: 云计算使得数据的存储和访问变得更加便捷，但如何确保数据安全却是一个重大挑战。传统的安全方法在未来强大的量子计算机出现时可能不再有效。为了解决这一问题，本研究采用量子密码学来保护云环境中的数据。量子密钥分发（QKD）通过利用量子粒子（如光子）传输信息来生成安全密钥。具体而言，我们使用了BB84协议，这是一种简单可靠的方法，可以生成无法被窃取且无法被检测到的安全密钥。为了保护数据，我们采用量子一次性密码本（QOTP）进行加密和解密，确保数据的完全隐私。本研究展示了这些量子方法如何应用于云系统，以提供强大的防御能力，即使黑客拥有量子计算机。QKD、BB84和QOTP的结合为云中存储或共享的数据提供了一种安全可靠的方式。通过量子密码学，本文提供了一种确保当前和未来数据安全的方法，使云计算对用户的数据存储更加安全可靠。

</details>


### [636] [SoK: Evaluating Jailbreak Guardrails for Large Language Models](https://arxiv.org/abs/2506.10597)
**中文标题：SoK：评估大型语言模型的越狱防护机制**

*Xunguang Wang,Zhenlan Ji,Wenxuan Wang,Zongjie Li,Daoyuan Wu,Shuai Wang*

Main category: cs.CR

TL;DR: This paper provides a comprehensive analysis of jailbreak guardrails for LLMs, proposing a taxonomy and evaluation framework to assess their effectiveness and guide future research.


<details>
  <summary>Details</summary>
Motivation: The deployment of LLMs has exposed vulnerabilities to jailbreak attacks, and existing guardrails lack a unified taxonomy and evaluation framework, prompting the need for a holistic analysis.

Method: The authors propose a multi-dimensional taxonomy for guardrails and introduce a Security-Efficiency-Utility framework to evaluate their effectiveness through extensive analysis and experiments.

Result: The study identifies strengths and limitations of existing guardrails, explores their universality across attack types, and provides insights for optimizing defense combinations.

Conclusion: The work offers a structured foundation for future research, aiming to guide the principled advancement and deployment of robust LLM guardrails.

摘要: 大型语言模型（LLMs）取得了显著进展，但其部署暴露了关键漏洞，尤其是绕过安全机制的越狱攻击。防护机制——监控和控制LLM交互的外部防御手段——已成为一种有前景的解决方案。然而，当前LLM防护机制的格局较为分散，缺乏统一的分类法和全面的评估框架。在这篇系统化知识（SoK）论文中，我们首次对LLM的越狱防护机制进行了全面分析。我们提出了一种新颖的多维度分类法，将防护机制划分为六个关键维度，并引入了一个安全-效率-实用性的评估框架来评估其实际效果。通过广泛的分析和实验，我们确定了现有防护机制方法的优势和局限性，探讨了它们对不同攻击类型的普适性，并为优化防御组合提供了见解。我们的工作为未来的研究和开发提供了结构化基础，旨在指导稳健LLM防护机制的原则性发展和部署。代码可在https://github.com/xunguangwang/SoK4JailbreakGuardrails获取。

</details>


### [637] [TED-LaST: Towards Robust Backdoor Defense Against Adaptive Attacks](https://arxiv.org/abs/2506.10722)
**中文标题：TED-LaST：针对自适应攻击的鲁棒后门防御**

*Xiaoxing Mo,Yuxuan Cheng,Nan Sun,Leo Yu Zhang,Wei Luo,Shang Gao*

Main category: cs.CR

TL;DR: The paper introduces TED-LaST, a robust defense strategy against adaptive backdoor attacks in DNNs, enhancing traditional TED with label-supervised dynamics tracking and adaptive layer emphasis. It effectively counters sophisticated attacks like Adap-Blend and Adapt-Patch.


<details>
  <summary>Details</summary>
Motivation: Existing TED-based defenses are vulnerable to adaptive backdoor attacks that distort topological representations. The paper aims to enhance TED's robustness against such attacks.

Method: TED-LaST introduces label-supervised dynamics tracking and adaptive layer emphasis to detect stealthy threats, even in cases of topological inseparability. It also reviews and classifies adaptive attack strategies.

Result: Experiments on datasets (CIFAR-10, GTSRB, ImageNet100) and models (ResNet20, ResNet101) show TED-LaST effectively counters advanced backdoor attacks, setting a new benchmark for robust detection.

Conclusion: TED-LaST significantly improves DNN security against evolving backdoor threats, providing a robust defense framework.

摘要: 深度神经网络（DNN）易受后门攻击，攻击者在训练过程中植入隐藏触发器以恶意控制模型行为。拓扑演化动力学（TED）最近成为检测DNN后门攻击的有力工具。然而，TED可能受到自适应后门攻击的威胁，这些攻击会扭曲网络层间的拓扑表示分布。为解决这一局限，我们提出TED-LaST（针对洗涤、慢释放和目标映射攻击策略的拓扑演化动力学），这是一种增强TED对自适应攻击鲁棒性的新型防御策略。TED-LaST引入了两项关键创新：标签监督的动态跟踪和自适应层强调。这些增强功能能够识别传统TED防御无法检测的隐蔽威胁，即使在拓扑空间不可分离和轻微拓扑扰动的情况下。我们回顾并分类了最先进自适应攻击中的数据投毒技巧，并提出了一种带有目标映射的增强自适应攻击，可以动态转移恶意任务并充分利用自适应攻击的隐蔽性。我们在多个数据集（CIFAR-10、GTSRB和ImageNet100）和模型架构（ResNet20、ResNet101）上的综合实验表明，TED-LaST有效对抗了Adap-Blend、Adapt-Patch等复杂后门以及提出的增强自适应攻击。TED-LaST为鲁棒后门检测设立了新标杆，显著提升了DNN对抗不断演变的威胁的安全性。

</details>


### [638] [ME: Trigger Element Combination Backdoor Attack on Copyright Infringement](https://arxiv.org/abs/2506.10776)
**中文标题：ME：针对版权侵权的触发元素组合后门攻击**

*Feiyu Yang,Siyuan Liang,Aishan Liu,Dacheng Tao*

Main category: cs.CR

TL;DR: The paper introduces a Multi-Element (ME) attack method to enhance the SilentBadDiffusion (SBD) backdoor attack on generative diffusion models, using more poisonous elements per sample and Discrete Cosine Transform (DCT) for stealth. It also provides new datasets for research, achieving better attack performance than benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing methods like SBD have limited data resources and suboptimal performance with few poisoning samples. The paper aims to improve attack effectiveness by introducing more poisonous elements and new datasets.

Method: The ME attack method increases poisonous visual-text elements per sample and uses DCT for stealth. New datasets are introduced to support research in this area.

Result: The ME method achieved higher Copyright Infringement Rates (CIR) and lower First Attack Epochs (FAE) compared to benchmarks, even with low subsampling ratios.

Conclusion: The ME method and new datasets significantly improve the effectiveness of backdoor attacks on generative diffusion models, outperforming existing methods.

摘要: 生成扩散模型（如Stable Diffusion）复制训练数据的能力可能被攻击者利用，通过重复的毒化图像-文本对发起版权侵权攻击。SilentBadDiffusion（SBD）是最近提出的一种方法，在文本到图像任务中表现出色。然而，该领域可行数据资源有限，部分因版权或内容不当问题受限；现有数据集中并非所有图像都适合攻击方法；此外，SBD在少量毒化样本下的攻击效果不理想。本文提出了适用于SBD等攻击研究的新数据集，并基于SBD提出多元素（ME）攻击方法，通过增加每个毒化样本的视觉-文本毒化元素数量以增强攻击能力，同时引入离散余弦变换（DCT）保持隐蔽性。在两个新数据集上，我们获得的版权侵权率（CIR）/首次攻击周期（FAE）分别为16.78%/39.50和51.20%/23.60，接近甚至优于基准Pokemon和Mijourney数据集。在低采样率（5%，6个毒化样本）条件下，ME和DCT的CIR/FAE为0.23%/84.00和12.73%/65.50，均优于原始SBD（完全无法攻击）。

</details>


### [639] [Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](https://arxiv.org/abs/2506.10949)
**中文标题：利用轻量级序列监视器监测大语言模型中的分解攻击**

*Chen Yueh-Han,Nitish Joshi,Yulin Chen,Maksym Andriushchenko,Rico Angell,He He*

Main category: cs.CR

TL;DR: The paper proposes a lightweight sequential monitor to defend against decomposition attacks in LLMs, achieving a 93% defense success rate while reducing costs and latency.


<details>
  <summary>Details</summary>
Motivation: Existing LLM safety defenses fail under decomposition attacks, where malicious goals are split into benign subtasks to bypass detection. Current methods lack the ability to reason about long-range intent.

Method: The authors introduce a lightweight sequential monitoring framework that cumulatively evaluates subtasks in real time, using a curated dataset to validate their approach.

Result: The monitor achieves a 93% defense success rate, outperforms reasoning models, and remains robust against random task injection while reducing costs by 90% and latency by 50%.

Conclusion: Lightweight sequential monitors are highly effective in mitigating decomposition attacks and are practical for deployment.

摘要: 当前的大语言模型（LLM）安全防御在分解攻击下失效，即恶意目标被分解为规避拒绝的良性子任务。现有浅层安全对齐技术的局限性在于仅能检测即时提示中的危害，而无法推断长期意图，导致对看似良性指令序列中逐渐显现的恶意意图视而不见。为此，我们提出添加一个外部监视器，以更高粒度观察对话。为便于研究分解攻击的监测，我们构建了迄今为止最大且最多样化的数据集，涵盖问答、文本到图像和代理任务。通过在先进LLM上测试验证，我们的数据集在GPT-4o上平均攻击成功率达87%，证实分解攻击广泛有效。此外，我们发现随机任务可注入分解子任务中以进一步混淆恶意意图。为实时防御，我们提出一种轻量级序列监视框架，累积评估每个子任务。研究表明，经过精心提示设计的轻量级监视器防御成功率达93%，优于o3 mini等推理模型作为监视器。此外，其对随机任务注入保持稳健，并将成本降低90%，延迟减少50%。我们的结果表明，轻量级序列监视器在缓解分解攻击方面极为有效，且适合实际部署。

</details>


### [640] [From Threat to Tool: Leveraging Refusal-Aware Injection Attacks for Safety Alignment](https://arxiv.org/abs/2506.10020)
**中文标题：从威胁到工具：利用拒绝感知注入攻击实现安全性对齐**

*Kyubyung Chae,Hyunbin Jin,Taesup Kim*

Main category: cs.CR

TL;DR: 本文提出了一种名为RAAI的训练无关、模型无关的框架，通过检测内部拒绝信号并自适应注入预定义短语，生成有害但流畅的补全内容，从而提升LLM的安全性对齐。实验表明，RAAI显著提高了有害响应率，并增强了模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）的安全性对齐通常依赖昂贵且耗时的人工标注偏好数据。尽管合成数据是一种替代方案，但现有方法常需复杂的迭代提示或辅助模型。因此，本文旨在开发一种更简单、高效的方法。

Method: 提出Refusal-Aware Adaptive Injection（RAAI）框架，通过检测LLM的内部拒绝信号并自适应注入预定义短语，生成有害但流畅的补全内容。该方法无需训练且适用于不同模型。

Result: RAAI成功将有害响应率从基线2.15%提升至平均61.04%。使用RAAI生成的合成数据微调LLM后，模型在有害提示下的鲁棒性增强，同时保留了在标准任务（如MMLU和ARC）上的通用能力。

Conclusion: 研究表明，LLM攻击方法可转化为实用工具，用于可扩展且可控的安全性对齐。RAAI为LLM安全性对齐提供了一种高效且低成本的新途径。

摘要: 安全对齐大型语言模型（LLM）通常需要大量人工标注的偏好数据，这一过程既昂贵又耗时。尽管合成数据是一种有前景的替代方案，但现有方法常依赖复杂的迭代提示或辅助模型。为此，我们提出了一种名为拒绝感知自适应注入（RAAI）的简单、无需训练且与模型无关的框架，该框架重新利用了LLM攻击技术。RAAI通过检测内部拒绝信号并自适应注入预定义短语，生成有害但流畅的补全内容。实验表明，RAAI有效破解了LLM，将有害响应率从基线2.15%提升至平均61.04%。更重要的是，使用RAAI生成的合成数据微调LLM后，模型对有害提示的鲁棒性增强，同时在标准任务（如MMLU和ARC）上保留了通用能力。这项工作展示了如何将LLM攻击方法重新定义为可扩展且可控的安全性对齐工具。

</details>


### [641] [LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges](https://arxiv.org/abs/2506.10022)
**中文标题：大型语言模型陷入交火：恶意请求与越狱挑战**

*Haoyang Li,Huan Gao,Zhiyuan Zhao,Zhiyu Lin,Junyu Gao,Xuelong Li*

Main category: cs.CR

TL;DR: 论文提出MalwareBench基准数据集，评估大型语言模型（LLMs）在恶意代码生成中的脆弱性，发现主流LLMs对恶意请求的拒绝能力有限，且多方法组合攻击会进一步降低安全性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，其安全性问题日益突出，尤其是针对恶意代码生成的越狱攻击。然而，LLMs在此类攻击中的具体脆弱性尚未得到充分研究。

Method: 作者提出MalwareBench基准数据集，包含3,520个恶意代码生成的越狱提示，基于320个手工设计的恶意代码生成需求，涵盖11种越狱方法和29种代码功能类别。

Result: 实验表明，主流LLMs对恶意代码生成需求的拒绝能力有限，平均拒绝率为60.93%；而结合多种越狱方法后，拒绝率进一步降至39.92%。

Conclusion: LLMs在代码生成中的安全性仍面临重大挑战，亟需进一步研究和改进。

摘要: 大型语言模型（LLMs）的广泛应用引发了对其安全性的担忧，尤其是其易受越狱攻击的脆弱性，这些攻击通过精心设计的提示生成恶意输出。尽管已有研究探讨了LLMs的一般安全能力，但其在代码生成中对越狱攻击的具体脆弱性仍未被充分探索。为填补这一空白，我们提出了MalwareBench基准数据集，包含3,520个用于恶意代码生成的越狱提示，旨在评估LLMs对此类威胁的鲁棒性。MalwareBench基于320个手工设计的恶意代码生成需求，涵盖11种越狱方法和29种代码功能类别。实验表明，主流LLMs对恶意代码生成需求的拒绝能力有限，平均拒绝率为60.93%；而结合多种越狱方法后，拒绝率进一步降至39.92%。我们的工作表明，LLMs在代码安全性方面仍面临重大挑战。

</details>


### [642] [Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models](https://arxiv.org/abs/2506.10024)
**中文标题：私有记忆编辑：将记忆转化为防御机制以增强大型语言模型的数据隐私**

*Elena Sofia Ruzzetti,Giancarlo A. Xompero,Davide Venditti,Fabio Massimo Zanzotto*

Main category: cs.CR

TL;DR: 本文提出了一种名为“私有记忆编辑（PME）”的方法，将大型语言模型（LLM）的记忆能力转化为隐私防御策略，通过检测和编辑模型对训练数据中的个人身份信息（PII）的记忆，有效减少隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）可能记忆并泄露训练数据中的个人身份信息（PII），这带来了严重的隐私风险。本文旨在利用模型的记忆能力，将其转化为一种防御机制，以增强数据隐私保护。

Method: 提出私有记忆编辑（PME）方法，通过检测模型记忆的PII，并编辑模型对这些数据的记忆，从而减少隐私泄露。该方法不影响模型的语言能力，但能增强其对抗隐私攻击的鲁棒性。

Result: 实验表明，PME能有效减少PII的泄露，在某些情况下甚至将隐私攻击的准确率降至零，同时保持模型的语言性能不受影响。

Conclusion: PME成功将LLM的记忆能力转化为隐私防御工具，为数据隐私保护提供了一种新思路。

摘要: 大型语言模型（LLM）会记忆大量未受控数据，可能包含不应存储或泄露的个人身份信息（PII）。本文提出私有记忆编辑（PME）方法，将LLM的记忆能力转化为隐私防御策略。通过检测并编辑模型对PII的记忆，PME在不影响模型语言能力的情况下，增强了其对抗隐私攻击的鲁棒性。实验证明，PME能有效减少PII泄露，某些情况下甚至将隐私攻击准确率降至零。

</details>


### [643] [Evaluation empirique de la sécurisation et de l'alignement de ChatGPT et Gemini: analyse comparative des vulnérabilités par expérimentations de jailbreaks](https://arxiv.org/abs/2506.10029)
**中文标题：ChatGPT与Gemini的安全性和对齐性实证评估：基于越狱实验的漏洞比较分析**

*Rafaël Nouailles*

Main category: cs.CR

TL;DR: 本文对ChatGPT和Gemini的安全性和对齐性进行了比较分析，并研究了越狱技术的分类及其实验验证。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）如ChatGPT和Gemini在数字领域带来革命性变化，但也引发新的网络安全挑战，如提示注入攻击、越狱规避监管措施、错误信息传播和深度伪造风险。本文旨在评估和比较这两种模型的安全性和对齐性。

Method: 通过实验验证和比较分析，研究了ChatGPT和Gemini的安全漏洞，并提出了越狱技术的分类。

Result: 研究发现，ChatGPT和Gemini在安全性和对齐性方面存在差异，且越狱技术对模型的监管措施具有显著影响。

Conclusion: 本文为LLMs的安全性和对齐性提供了实证分析，强调了进一步研究和改进的必要性。

摘要: 大型语言模型（LLMs）正在改变数字应用，尤其是在文本生成、图像创作、信息检索和代码开发领域。OpenAI于2022年11月推出的ChatGPT迅速成为标杆，促使谷歌的Gemini等竞争对手出现。然而，这些技术进步带来了新的网络安全挑战，包括提示注入攻击、规避监管措施（越狱）、错误信息传播（幻觉）以及与深度伪造相关的风险。本文对ChatGPT和Gemini的安全性和对齐性进行了比较分析，并提出了越狱技术的分类及相关实验验证。

</details>


### [644] [Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment](https://arxiv.org/abs/2506.10030)
**中文标题：在RAG即服务环境中保护多模态知识版权**

*Tianyu Chen,Jian Lou,Wenjie Wang*

Main category: cs.CR

TL;DR: 本文提出了AQUA，首个用于多模态RAG系统中图像知识版权保护的水印框架，填补了现有方法仅保护文本知识的空白。


<details>
  <summary>Details</summary>
Motivation: 随着RAG发展为服务化平台（Rag-as-a-Service），共享知识库中贡献数据的版权保护变得至关重要。现有水印方法仅关注文本知识，图像知识未受保护。

Method: AQUA通过两种互补方法（基于缩写的触发器和空间关系线索）将语义信号嵌入合成图像，确保水印信号在图像检索器到文本生成器的间接传播中存活，高效、有效且不可察觉。

Result: 实验表明，AQUA在多种模型和数据集上实现了鲁棒、隐蔽且可靠的版权追踪。

Conclusion: AQUA填补了多模态RAG保护中的关键空白，为图像知识版权提供了有效解决方案。

摘要: 随着检索增强生成（RAG）发展为服务化平台（Rag-as-a-Service）并共享知识库，保护贡献数据的版权变得至关重要。现有的RAG水印方法仅关注文本知识，图像知识未受保护。本文提出了AQUA，首个用于多模态RAG系统中图像知识保护的水印框架。AQUA通过两种互补方法（基于缩写的触发器和空间关系线索）将语义信号嵌入合成图像，确保水印信号在图像检索器到文本生成器的间接传播中存活，高效、有效且不可察觉。在多种模型和数据集上的实验表明，AQUA能够实现鲁棒、隐蔽且可靠的版权追踪，填补了多模态RAG保护中的关键空白。

</details>


### [645] [From Threat to Tool: Leveraging Refusal-Aware Injection Attacks for Safety Alignment](https://arxiv.org/abs/2506.10020)
**中文标题：从威胁到工具：利用拒绝感知注入攻击实现安全对齐**

*Kyubyung Chae,Hyunbin Jin,Taesup Kim*

Main category: cs.CR

TL;DR: 本文提出了一种名为RAAI的无训练、模型无关框架，通过检测内部拒绝信号并注入预定义短语，将LLM攻击技术转化为安全对齐工具，显著提高了有害响应率，同时通过合成数据增强了模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 安全对齐大型语言模型（LLMs）通常需要大量人工标注的偏好数据，成本高且耗时。虽然合成数据是一种替代方案，但现有方法依赖复杂迭代提示或辅助模型。本文旨在开发一种简单、无需训练且模型无关的框架，将LLM攻击技术转化为安全对齐工具。

Method: 本文提出Refusal-Aware Adaptive Injection（RAAI）框架，通过检测LLM内部的拒绝信号并自适应注入预定义短语，以生成有害但流畅的补全。RAAI无需训练，适用于任何LLM。

Result: 实验表明，RAAI显著提高了有害响应率，从基线2.15%提升至平均61.04%。使用RAAI生成的合成数据微调LLM后，模型在有害提示下的鲁棒性增强，同时保持了在标准任务（如MMLU和ARC）上的通用能力。

Conclusion: RAAI成功将LLM攻击技术转化为实用工具，为可扩展和可控的安全对齐提供了新思路。

摘要: 安全对齐大型语言模型（LLMs）通常需要大量人工标注的偏好数据，这一过程既昂贵又耗时。虽然合成数据是一种有前景的替代方案，但现有方法通常依赖复杂的迭代提示或辅助模型。为解决这一问题，我们提出了Refusal-Aware Adaptive Injection（RAAI），这是一种简单、无需训练且模型无关的框架，它重新利用了LLM攻击技术。RAAI通过检测内部拒绝信号并自适应注入预定义短语，以引出有害但流畅的补全。实验表明，RAAI能有效越狱LLM，将有害响应率从基线2.15%提升至平均61.04%（在四个基准测试中）。关键的是，使用RAAI生成的合成数据微调LLM后，模型在有害提示下的鲁棒性得到提升，同时保留了在标准任务（如MMLU和ARC）上的通用能力。这项工作展示了如何将LLM攻击方法重新定义为可扩展和可控安全对齐的实用工具。

</details>


### [646] [LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges](https://arxiv.org/abs/2506.10022)
**中文标题：大语言模型陷入交火：恶意请求与越狱挑战**

*Haoyang Li,Huan Gao,Zhiyuan Zhao,Zhiyu Lin,Junyu Gao,Xuelong Li*

Main category: cs.CR

TL;DR: 本文提出MalwareBench基准数据集，评估主流大语言模型（LLMs）在恶意代码生成任务中对抗越狱攻击的能力，发现其安全性能存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的广泛应用，其安全性问题日益突出，尤其是在代码生成任务中对抗越狱攻击的能力尚未得到充分研究。本文旨在填补这一空白。

Method: 作者提出MalwareBench基准数据集，包含3,520个恶意代码生成的越狱提示，基于320个手工设计的恶意代码生成需求，涵盖11种越狱方法和29种代码功能类别。通过实验评估主流LLMs的安全性能。

Result: 实验结果显示，主流LLMs对恶意代码生成需求的拒绝能力有限，平均拒绝率为60.93%；而结合越狱攻击算法后，拒绝率进一步降至39.92%。

Conclusion: 研究表明，LLMs在代码生成任务中的安全性能仍面临重大挑战，亟需进一步改进。

摘要: 大语言模型（LLMs）的广泛应用引发了对其安全性的担忧，尤其是其易受越狱攻击的脆弱性，这些攻击通过精心设计的提示生成恶意输出。尽管已有研究探讨了LLMs的一般安全能力，但其在代码生成任务中对越狱攻击的特定易感性仍未被充分研究。为填补这一空白，我们提出了MalwareBench基准数据集，包含3,520个恶意代码生成的越狱提示，用于评估LLMs对此类威胁的鲁棒性。MalwareBench基于320个手工设计的恶意代码生成需求，涵盖11种越狱方法和29种代码功能类别。实验表明，主流LLMs对恶意代码生成需求的拒绝能力有限，平均拒绝率为60.93%；而结合越狱攻击算法后，拒绝率进一步降至39.92%。我们的工作表明，LLMs的代码安全能力仍面临重大挑战。

</details>


### [647] [Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models](https://arxiv.org/abs/2506.10024)
**中文标题：私有记忆编辑：将记忆转化为防御以增强大型语言模型中的数据隐私**

*Elena Sofia Ruzzetti,Giancarlo A. Xompero,Davide Venditti,Fabio Massimo Zanzotto*

Main category: cs.CR

TL;DR: 本文提出了一种名为‘私有记忆编辑’（PME）的方法，通过将大型语言模型（LLMs）的记忆能力转化为隐私防御策略，防止个人身份信息（PII）的泄露。该方法通过检测和编辑模型记忆的PII，使其对隐私攻击更鲁棒，同时不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在训练过程中可能记忆并泄露个人身份信息（PII），这引发了隐私安全问题。本文旨在利用模型的记忆能力，将其转化为一种防御机制，以防止PII的泄露。

Method: 提出了私有记忆编辑（PME）方法，通过检测模型记忆的PII，并编辑这些记忆，从而减少PII的泄露。该方法不影响模型的语言能力，同时增强其对隐私攻击的鲁棒性。

Result: 实验表明，PME能有效减少PII的泄露数量，在某些情况下甚至将隐私攻击的准确率降至零。

Conclusion: PME成功将LLMs的记忆能力转化为隐私防御工具，为数据隐私保护提供了一种新思路。

摘要: 大型语言模型（LLMs）会记忆大量未受控制的数据，其中可能包含不应存储或泄露的个人身份信息（PII）。本文提出了一种名为‘私有记忆编辑’（PME）的方法，旨在防止私有数据泄露，将LLMs的记忆能力这一表面上的限制转化为强大的隐私防御策略。尽管针对LLMs的攻击利用了其训练数据的先验知识，但我们的方法旨在利用同类知识使模型更具鲁棒性。我们检测模型记忆的PII，并通过编辑其对训练数据的记忆来缓解PII的泄露。实验证明，该方法不影响基础语言模型的性能，同时使其对隐私训练数据提取攻击更具抵抗力。我们展示了PME在多种配置下能有效减少PII的泄露数量，在某些情况下甚至将隐私攻击的准确率降至零。

</details>


### [648] [Evaluation empirique de la sécurisation et de l'alignement de ChatGPT et Gemini: analyse comparative des vulnérabilités par expérimentations de jailbreaks](https://arxiv.org/abs/2506.10029)
**中文标题：ChatGPT与Gemini的安全性和对齐性实证评估：基于越狱实验的漏洞比较分析**

*Rafaël Nouailles*

Main category: cs.CR

TL;DR: 本文对ChatGPT和Gemini的安全性和对齐性进行了比较分析，并实验研究了越狱技术的分类。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，如ChatGPT和Gemini，其带来的网络安全问题日益突出，包括提示注入攻击、越狱技术、错误信息传播和深度伪造风险。本文旨在评估这些模型的安全性和对齐性，以揭示潜在漏洞。

Method: 通过实验对ChatGPT和Gemini进行越狱技术测试，并比较其安全性和对齐性水平。同时，提出了一种越狱技术的分类方法。

Result: 研究发现，ChatGPT和Gemini在安全性和对齐性方面存在显著差异，且某些越狱技术对两种模型均有效。实验还揭示了模型在应对攻击时的不同表现。

Conclusion: 本文为大型语言模型的安全性和对齐性提供了实证分析，揭示了潜在漏洞，并提出了改进方向。

摘要: 大型语言模型（LLMs）正在改变数字应用，尤其是在文本生成、图像创作、信息检索和代码开发领域。OpenAI于2022年11月推出的ChatGPT迅速成为标杆，促使谷歌的Gemini等竞争对手涌现。然而，这些技术进步带来了新的网络安全挑战，包括提示注入攻击、规避监管措施（越狱）、错误信息传播（幻觉）以及与深度伪造相关的风险。本文对ChatGPT和Gemini的安全性和对齐性进行了比较分析，并实验研究了越狱技术的分类。

</details>


### [649] [Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment](https://arxiv.org/abs/2506.10030)
**中文标题：在RAG即服务环境中保护多模态知识版权**

*Tianyu Chen,Jian Lou,Wenjie Wang*

Main category: cs.CR

TL;DR: 本文提出AQUA框架，首次为多模态RAG系统中的图像知识提供水印保护，填补了现有方法仅保护文本知识的空白。


<details>
  <summary>Details</summary>
Motivation: 随着RAG发展为服务化平台（Rag-as-a-Service），共享知识库中贡献数据的版权保护变得至关重要。现有水印方法仅针对文本知识，图像知识缺乏保护。

Method: AQUA框架通过两种互补方法（基于缩写的触发器和空间关系线索）将语义信号嵌入合成图像，确保水印信号在从图像检索器到文本生成器的间接传播中存活。

Result: 实验表明，AQUA在多模型和数据集上实现了鲁棒、隐蔽且可靠的版权追踪。

Conclusion: AQUA填补了多模态RAG保护中的关键空白，为图像知识版权提供了高效、有效且不可察觉的保护方案。

摘要: 随着检索增强生成（RAG）发展为服务化平台（Rag-as-a-Service）并共享知识库，保护贡献数据的版权变得至关重要。现有的RAG水印方法仅关注文本知识，而图像知识缺乏保护。本文提出AQUA，首个用于多模态RAG系统中图像知识保护的水印框架。AQUA通过两种互补方法（基于缩写的触发器和空间关系线索）将语义信号嵌入合成图像，确保水印信号在从图像检索器到文本生成器的间接传播中存活，且高效、有效且不可察觉。在多种模型和数据集上的实验表明，AQUA能够实现鲁棒、隐蔽且可靠的版权追踪，填补了多模态RAG保护中的关键空白。

</details>


### [650] [GenBreak: Red Teaming Text-to-Image Generators Using Large Language Models](https://arxiv.org/abs/2506.10047)
**中文标题：GenBreak：利用大型语言模型对文本到图像生成器进行红队测试**

*Zilong Wang,Xiang Zheng,Xiaosen Wang,Bo Wang,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CR

TL;DR: GenBreak是一种利用大型语言模型（LLM）对文本到图像（T2I）生成器进行红队测试的框架，旨在发现并利用其潜在漏洞，生成既具有高毒性又能绕过安全过滤器的对抗性提示。


<details>
  <summary>Details</summary>
Motivation: 现有的T2I模型（如Stable Diffusion）可能被滥用于生成有害内容，而当前的对抗攻击研究要么生成的提示容易被安全过滤器拦截，要么无法产生真正有害的输出。因此，需要一种可靠的工具来评估T2I模型的安全性。

Method: GenBreak通过监督微调（基于精选数据集）和强化学习（通过与代理T2I模型交互）相结合的方式，训练一个红队LLM。该模型利用多种奖励信号生成既能绕过安全机制又具有高毒性的对抗性提示。

Result: GenBreak生成的对抗性提示在针对商业T2I生成器的黑盒攻击中表现出色，揭示了实际且令人担忧的安全漏洞。

Conclusion: GenBreak为评估T2I模型的安全性提供了一种有效工具，同时揭示了现有防御机制的局限性。

摘要: 文本到图像（T2I）模型（如Stable Diffusion）发展迅速，已广泛应用于内容创作。然而，这些模型可能被滥用于生成有害内容（如裸露或暴力），带来重大安全风险。尽管大多数平台采用了内容审核系统，但潜在的漏洞仍可能被恶意利用。目前针对T2I模型的红队测试和对抗攻击研究存在明显局限：一些研究成功生成了高毒性图像，但使用的对抗性提示容易被安全过滤器拦截；另一些研究则专注于绕过安全机制，但未能生成真正有害的输出，忽视了高风险提示的发现。因此，目前缺乏可靠的工具来评估已防御T2I模型的安全性。为解决这一问题，我们提出了GenBreak框架，通过微调红队大型语言模型（LLM）来系统探索T2I生成器的潜在漏洞。我们的方法结合了基于精选数据集的监督微调，以及通过与代理T2I模型交互的强化学习。通过整合多种奖励信号，我们引导LLM生成既能增强规避能力又能提高图像毒性的对抗性提示，同时保持语义连贯性和多样性。这些提示在针对商业T2I生成器的黑盒攻击中表现出色，揭示了实际且令人担忧的安全弱点。

</details>


### [651] [Disclosure Audits for LLM Agents](https://arxiv.org/abs/2506.10171)
**中文标题：大型语言模型代理的披露审计**

*Saswat Das,Jameson Sandler,Ferdinando Fioretto*

Main category: cs.CR

TL;DR: 本文提出了一种用于大型语言模型（LLM）代理的隐私泄露审计框架CMPL，通过多轮对话测试揭示潜在隐私风险，并提供了量化风险指标和开放基准。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理在个人助理、客服和临床辅助等领域的广泛应用，其持续访问敏感数据的特性增加了未经授权泄露的风险。现有单轮防御机制无法全面覆盖多轮对话中的隐私漏洞，因此需要一种系统化的审计方法。

Method: 提出了对话隐私泄露操纵（CMPL）框架，通过迭代式多轮对话测试，模拟真实交互场景，系统性地发现隐私漏洞。该方法结合量化风险指标和开放基准，评估代理在不同领域和数据模态下的隐私保护能力。

Result: 实验表明，CMPL能够揭示现有单轮防御机制无法检测的隐私风险，并在多种领域和配置下验证了其有效性。

Conclusion: CMPL作为一种诊断工具，不仅填补了多轮对话隐私审计的空白，还提供了量化风险指标和开放基准，为未来LLM代理的隐私保护研究奠定了基础。

摘要: 大型语言模型（LLM）代理已开始作为个人助理、客服机器人和临床辅助工具出现。尽管这些应用带来了显著的运营效益，但它们也需要持续访问敏感数据，从而增加了未经授权泄露的可能性。本研究提出了一种用于对话隐私的审计框架，以量化和审计这些风险。所提出的对话隐私泄露操纵（CMPL）框架是一种迭代式探测策略，旨在对执行严格隐私指令的代理进行压力测试。CMPL不仅关注单一泄露事件，还通过模拟真实的多轮交互，系统性地揭示潜在漏洞。我们在不同领域、数据模态和安全配置下的评估表明，该审计框架能够揭示现有单轮防御无法阻止的隐私风险。除了将CMPL作为一种诊断工具引入外，本文还提供了（1）基于可量化风险指标的审计流程，以及（2）一个用于评估不同代理实现中对话隐私的开放基准。

</details>


### [652] [Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods](https://arxiv.org/abs/2506.10236)
**中文标题：提示攻击揭示遗忘方法中的表面知识移除**

*Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz*

Main category: cs.CR

TL;DR: 研究发现某些机器学习遗忘方法在简单提示攻击下可能失效，部分方法（如ELM）仍能通过特定提示恢复遗忘的知识，挑战了现有遗忘技术的有效性假设。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习遗忘方法的有效性尚未经过严格测试，尤其是面对提示攻击时。本研究旨在评估这些方法是否真正移除了知识，还是仅抑制了输出。

Method: 系统评估了八种遗忘技术，涵盖三种模型家族，采用基于输出、逻辑和探针的分析方法，测试遗忘知识的可恢复性。

Result: 部分方法（如RMU和TAR）表现出稳健的遗忘能力，而ELM等仍易受特定提示攻击（如使用印地语填充文本恢复57.3%准确率）。逻辑分析显示遗忘模型未通过修改答案格式隐藏知识。

Conclusion: 研究质疑了现有遗忘技术的有效性，强调需要更可靠的评估框架来区分真正的知识移除与表面输出抑制。同时公开了评估框架以促进进一步研究。

摘要: 本研究显示，某些机器学习遗忘方法在简单提示攻击下可能失效。我们系统评估了八种遗忘技术，涵盖三种模型家族，并采用基于输出、逻辑和探针的分析方法，以确定所谓遗忘知识的可恢复程度。尽管RMU和TAR等方法表现出稳健的遗忘能力，但ELM仍易受特定提示攻击（例如，原始提示中使用印地语填充文本可恢复57.3%的准确率）。逻辑分析也证实，遗忘模型通常未通过修改答案格式隐藏知识，因为输出与逻辑准确率之间的相关性很强。这些结果挑战了关于遗忘有效性的普遍假设，并突显了需要能够可靠区分真正知识移除与表面输出抑制的评估框架。我们还公开了评估框架，以便轻松评估提示技术以检索遗忘知识。

</details>


### [653] [SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks](https://arxiv.org/abs/2506.10424)
**中文标题：SOFT：选择性数据混淆保护LLM微调免受成员推理攻击**

*Kaiyuan Zhang,Siyuan Cheng,Hanxi Guo,Yuetian Chen,Zian Su,Shengwei An,Yuntao Du,Charles Fleming,Ashish Kundu,Xiangyu Zhang,Ninghui Li*

Main category: cs.CR

TL;DR: 本文首次全面研究了微调大型语言模型（LLM）对成员推理攻击（MIA）的脆弱性，并提出了一种名为SOFT的新型防御技术，通过选择性数据混淆来平衡隐私保护和模型性能。


<details>
  <summary>Details</summary>
Motivation: 微调LLM通常涉及敏感信息，存在隐私泄露风险。成员推理攻击（MIA）利用微调过程中的损失减少，能够有效揭示成员信息，因此亟需开发防御方法。

Method: 提出SOFT（选择性数据混淆）技术，通过调整参数选择有影响力的数据，在隐私保护和模型性能之间取得平衡。

Result: 实验覆盖六个领域和多种LLM架构，结果表明SOFT能有效降低隐私风险，同时保持模型性能。

Conclusion: SOFT为保护微调LLM中的敏感信息提供了一种实用且可扩展的解决方案。

摘要: 大型语言模型（LLM）取得了显著成功并被广泛应用于多种场景。然而，微调这些模型通常涉及私有或敏感信息，引发了严重的隐私问题。本研究首次全面评估了微调LLM对成员推理攻击（MIA）的脆弱性。实证分析表明，MIA利用微调过程中的损失减少，能够高效揭示成员信息。这些发现促使我们开发防御方法。我们提出了SOFT（选择性数据混淆技术），这是一种新型防御技术，通过调整参数选择有影响力的数据，以平衡隐私保护和模型性能。实验覆盖六个领域和多种LLM架构及规模，结果表明SOFT能有效降低隐私风险，同时保持模型性能，为保护微调LLM中的敏感信息提供了一种实用且可扩展的解决方案。

</details>


### [654] [Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications](https://arxiv.org/abs/2506.10467)
**中文标题：多智能体LLM系统的规范与评估——原型及网络安全应用**

*Felix Härer*

Main category: cs.CR

TL;DR: 本文探讨了多智能体LLM系统的规范与评估，通过原型和网络安全应用展示了其可行性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在推理、代码生成和软件执行方面表现出潜力，但多智能体LLM系统的联合规范和综合应用尚未得到充分探索。需要定义明确的规范以评估其在特定应用中的潜力。

Method: 研究扩展了先前的系统架构和原型，引入了多智能体系统的规范，并通过网络安全任务测试其可行性。

Result: 测试结果表明，基于OpenAI和DeepSeek LLM的智能体能够正确完成问答、服务器安全和网络安全任务。

Conclusion: 多智能体LLM系统的规范与评估方法具有实际应用潜力，尤其是在网络安全领域。

摘要: LLM的最新进展表明其在推理能力方面具有潜在的新应用价值，例如通过OpenAI和DeepSeek的最新模型。为了将这些模型应用于文本生成之外的特定领域，可以采用基于LLM的多智能体方法，通过结合推理技术、代码生成和软件执行来解决复杂任务。应用可能会利用这些能力以及专业化LLM智能体的知识。然而，尽管对LLM、推理技术和应用进行了许多单独评估，但它们的联合规范和综合应用尚未得到充分探索。需要定义多智能体LLM系统的规范以探索其潜力及其在特定应用中的适用性，从而对LLM、推理技术及相关方面进行系统评估。本文报告了通过多智能体系统对这些方面进行规范和评估的探索性研究结果。系统架构和原型从先前研究中扩展而来，并引入了多智能体系统的规范。涉及网络安全任务的测试案例表明该架构和评估方法的可行性。特别是，结果显示基于OpenAI和DeepSeek LLM的智能体能够正确完成问答、服务器安全和网络安全任务。

</details>


### [655] [Secure Data Access in Cloud Environments Using Quantum Cryptography](https://arxiv.org/abs/2506.10028)
**中文标题：在云环境中使用量子密码学实现安全数据访问**

*S. Vasavi Venkata Lakshmi,Ziaul Haque Choudhury*

Main category: cs.CR

TL;DR: 本文提出了一种在云环境中使用量子密码学保护数据安全的方法，结合量子密钥分发（QKD）、BB84协议和量子一次性密码本（QOTP），为未来量子计算时代的云安全提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着云计算的普及，数据安全面临巨大挑战，尤其是未来量子计算机可能破解传统加密方法。本文旨在利用量子密码学解决这一问题，确保云数据的安全性。

Method: 研究采用量子密钥分发（QKD）生成安全密钥，使用BB84协议确保密钥传输的安全性，并通过量子一次性密码本（QOTP）对数据进行加密和解密。

Result: 研究表明，结合QKD、BB84和QOTP的方法能够有效保护云数据安全，即使面对量子计算机的攻击也能提供强大的防御。

Conclusion: 量子密码学为云数据安全提供了未来可靠的解决方案，结合QKD、BB84和QOTP的方法能够确保数据在存储和共享过程中的安全性。

摘要: 云计算使数据的存储和访问变得更加便捷，但如何确保其安全性是当前的一大挑战。传统的加密方法在未来量子计算机普及后可能不再安全。为解决这一问题，本研究利用量子密码学保护云环境中的数据。量子密钥分发（QKD）通过量子粒子（如光子）传输信息生成安全密钥。具体而言，我们采用BB84协议，这是一种简单可靠的密钥生成方法，任何窃取行为都会被检测到。为保护数据，我们使用量子一次性密码本（QOTP）进行加密和解密，确保数据的完全隐私。本研究展示了这些量子方法如何在云系统中应用，为黑客攻击提供强大的防御，即使他们拥有量子计算机。QKD、BB84和QOTP的结合为云数据的存储和共享提供了一种安全可靠的方式。通过量子密码学，本文为当前和未来的数据安全提供了一种解决方案，使云计算成为更安全的数据存储和共享平台。

</details>


### [656] [SoK: Evaluating Jailbreak Guardrails for Large Language Models](https://arxiv.org/abs/2506.10597)
**中文标题：知识系统化：评估大型语言模型的越狱防护机制**

*Xunguang Wang,Zhenlan Ji,Wenxuan Wang,Zongjie Li,Daoyuan Wu,Shuai Wang*

Main category: cs.CR

TL;DR: 本文首次系统分析了针对大型语言模型（LLM）的越狱防护机制，提出了多维分类法和安全-效率-实用性评估框架，揭示了现有防护机制的优缺点，并为未来研究提供了结构化基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在部署中暴露出易受越狱攻击的漏洞，而现有的防护机制缺乏统一的分类和评估框架。本文旨在填补这一空白，为防护机制的研究和开发提供系统性指导。

Method: 提出了一种多维分类法，将防护机制分为六个关键维度，并引入了安全-效率-实用性评估框架。通过广泛的分析和实验，评估了现有防护机制的实际效果。

Result: 揭示了现有防护机制的优缺点，探讨了其在不同攻击类型中的普适性，并提出了优化防御组合的见解。

Conclusion: 本文为未来研究和开发提供了结构化基础，旨在推动稳健的LLM防护机制的有序发展和部署。

摘要: 大型语言模型（LLM）取得了显著进展，但其部署暴露了关键漏洞，尤其是绕过安全机制的越狱攻击。防护机制——监控和控制LLM交互的外部防御手段——成为一种有前景的解决方案。然而，当前LLM防护机制的格局分散，缺乏统一的分类和全面评估框架。在这篇知识系统化（SoK）论文中，我们首次对LLM的越狱防护机制进行了全面分析。我们提出了一种新颖的多维分类法，将防护机制分为六个关键维度，并引入了安全-效率-实用性评估框架以评估其实际效果。通过广泛的分析和实验，我们揭示了现有防护机制方法的优缺点，探讨了其在攻击类型中的普适性，并提供了优化防御组合的见解。我们的工作为未来研究和开发提供了结构化基础，旨在指导稳健的LLM防护机制的有序发展和部署。代码可在https://github.com/xunguangwang/SoK4JailbreakGuardrails获取。

</details>


### [657] [TED-LaST: Towards Robust Backdoor Defense Against Adaptive Attacks](https://arxiv.org/abs/2506.10722)
**中文标题：TED-LaST：针对自适应攻击的鲁棒后门防御**

*Xiaoxing Mo,Yuxuan Cheng,Nan Sun,Leo Yu Zhang,Wei Luo,Shang Gao*

Main category: cs.CR

TL;DR: 本文提出了一种名为TED-LaST的新型防御策略，旨在增强拓扑演化动力学（TED）对自适应后门攻击的鲁棒性。通过标签监督的动态跟踪和自适应层强调，TED-LaST能够识别传统TED防御无法检测到的隐蔽威胁。实验证明其在多种数据集和模型架构中有效抵御复杂后门攻击。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNNs）容易受到后门攻击，攻击者在训练过程中植入隐藏触发器以恶意控制模型行为。现有的拓扑演化动力学（TED）方法虽然能检测后门攻击，但对自适应攻击（如扭曲拓扑表示分布）的鲁棒性不足。因此，需要一种更强大的防御策略来应对这些威胁。

Method: TED-LaST通过引入标签监督的动态跟踪和自适应层强调，增强了TED的鲁棒性。前者利用标签信息跟踪动态变化，后者则根据攻击特点自适应调整对网络层的关注。此外，论文还提出了一种增强的自适应攻击方法，用于测试防御策略的有效性。

Result: 在CIFAR-10、GTSRB和ImageNet100等多个数据集及ResNet20、ResNet101等模型架构上的实验表明，TED-LaST能够有效抵御Adap-Blend、Adapt-Patch等复杂后门攻击，以及论文提出的增强自适应攻击。

Conclusion: TED-LaST为后门检测设立了新的基准，显著提升了DNNs对不断演变的威胁的安全性。其创新方法为未来防御策略的设计提供了重要参考。

摘要: 深度神经网络（DNNs）容易受到后门攻击，攻击者在训练过程中植入隐藏触发器以恶意控制模型行为。拓扑演化动力学（TED）最近成为一种检测DNNs后门攻击的强大工具。然而，TED可能受到自适应攻击的威胁，这些攻击会扭曲网络层间的拓扑表示分布。为解决这一问题，我们提出了TED-LaST（针对洗涤、慢释放和目标映射攻击策略的拓扑演化动力学），这是一种新型防御策略，增强了TED对自适应攻击的鲁棒性。TED-LaST引入了两项关键创新：标签监督的动态跟踪和自适应层强调。这些改进能够识别传统TED防御无法检测到的隐蔽威胁，即使在拓扑空间不可分离和拓扑扰动细微的情况下。我们回顾并分类了最先进自适应攻击中的数据投毒技巧，并提出了一种增强的自适应攻击方法，该方法能够动态转移恶意任务并充分利用自适应攻击的隐蔽性。我们在多个数据集（CIFAR-10、GTSRB和ImageNet100）和模型架构（ResNet20、ResNet101）上的综合实验表明，TED-LaST能够有效抵御Adap-Blend、Adapt-Patch等复杂后门攻击以及提出的增强自适应攻击。TED-LaST为鲁棒后门检测设立了新的基准，显著提升了DNNs对不断演变的威胁的安全性。

</details>


### [658] [ME: Trigger Element Combination Backdoor Attack on Copyright Infringement](https://arxiv.org/abs/2506.10776)
**中文标题：ME：基于元素组合触发的版权侵权后门攻击**

*Feiyu Yang,Siyuan Liang,Aishan Liu,Dacheng Tao*

Main category: cs.CR

TL;DR: 本文提出了一种基于SilentBadDiffusion（SBD）的多元素（ME）攻击方法，通过增加每个毒化样本中的视觉-文本元素数量来增强攻击能力，并引入离散余弦变换（DCT）以保持隐蔽性。实验结果表明，该方法在低子采样率下仍能有效攻击，性能优于原始SBD。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法如SBD在数据资源有限和毒化样本不足时表现不佳，且部分数据集因版权或内容问题受限。本文旨在提出更高效且隐蔽的攻击方法，并扩展可用数据集。

Method: 基于SBD提出ME攻击方法，增加每个毒化样本中的视觉-文本元素数量以增强攻击能力，并引入DCT技术保持隐蔽性。同时扩展了可用于攻击研究的数据集。

Result: 在两个新数据集上，ME攻击的版权侵权率（CIR）和首次攻击轮次（FAE）分别为16.78%/39.50和51.20%/23.60，接近或优于基准数据集。在低子采样率（5%，6个毒化样本）下，ME结合DCT的CIR/FAE为0.23%/84.00和12.73%/65.50，优于原始SBD。

Conclusion: ME攻击方法在增强攻击能力和隐蔽性方面表现优异，尤其是在数据稀缺条件下仍能有效工作，为版权侵权攻击研究提供了新思路。

摘要: 生成扩散模型（如Stable Diffusion，SD）复制训练数据的能力可能被攻击者利用，通过重复的毒化图像-文本对发起版权侵权攻击。SilentBadDiffusion（SBD）是近期提出的一种方法，在文本到图像任务中对SD表现出色。然而，该领域可用数据资源有限，部分因版权或内容问题受限；现有数据集中并非所有图像都适合攻击方法；此外，SBD在毒化样本较少时性能不理想。本文提出了适用于SBD等攻击研究的新数据集，并基于SBD提出多元素（ME）攻击方法，通过增加每个毒化样本中的视觉-文本元素数量以增强攻击能力，同时引入离散余弦变换（DCT）保持隐蔽性。在两个新数据集上，版权侵权率（CIR）/首次攻击轮次（FAE）分别为16.78%/39.50和51.20%/23.60，接近或优于基准Pokemon和Mijourney数据集。在低子采样率（5%，6个毒化样本）下，ME结合DCT的CIR/FAE为0.23%/84.00和12.73%/65.50，均优于原始SBD（后者完全无法攻击）。

</details>


### [659] [Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](https://arxiv.org/abs/2506.10949)
**中文标题：利用轻量级顺序监控器监测LLM中的分解攻击**

*Chen Yueh-Han,Nitish Joshi,Yulin Chen,Maksym Andriushchenko,Rico Angell,He He*

Main category: cs.CR

TL;DR: 当前LLM的安全防御在分解攻击下失效，恶意目标被分解为无害子任务绕过拒绝。论文提出一种轻量级顺序监控框架，成功防御率达93%，成本降低90%，延迟减少50%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐技术仅检测即时提示中的危害，无法识别长序列中逐渐显现的恶意意图，导致分解攻击广泛有效。

Method: 提出外部监控框架，观察对话更高粒度；构建多样化数据集验证攻击有效性；设计轻量级顺序监控器实时防御。

Result: 攻击成功率平均87%（GPT-4o）；轻量级监控器防御成功率达93%，成本降90%，延迟减50%。

Conclusion: 轻量级顺序监控器能有效缓解分解攻击，适合实际部署。

摘要: 当前LLM的安全防御在分解攻击下失效，恶意目标被分解为无害子任务以绕过拒绝。挑战在于现有浅层安全对齐技术仅检测即时提示中的危害，无法推断长序列意图，导致对逐渐显现的恶意意图视而不见。为此，我们提出添加外部监控器，以更高粒度观察对话。为研究分解攻击监控，我们构建了迄今最大、最多样化的数据集，涵盖问答、文本生成图像和代理任务。通过在主流LLM上测试验证，攻击成功率平均达87%（GPT-4o），证实分解攻击广泛有效。此外，随机任务可注入子任务以进一步混淆恶意意图。为实时防御，我们提出轻量级顺序监控框架，逐次评估子任务。实验表明，精心设计的轻量级监控器防御成功率达93%，优于推理模型（如o3 mini），且对随机任务注入鲁棒，成本降90%，延迟减50%。结果表明，轻量级顺序监控器能有效缓解分解攻击，适合实际部署。

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [660] [Semi-Tensor-Product Based Convolutional Neural Networks](https://arxiv.org/abs/2506.10407)
**中文标题：基于半张量积的卷积神经网络**

*Daizhan Cheng*

Main category: eess.SY

TL;DR: The paper introduces a new convolutional product (CP) based on semi-tensor product (STP) and domain-based CP, avoiding padding-related issues, and applies it to STP-based CNNs for image and signal identification.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of conventional inner products and padding in CNNs by leveraging STP and domain-based CP for more flexible and efficient convolutional operations.

Method: Proposes a new CP combining domain-based CP with STP, eliminating padding, and develops an STP-based CNN for image and third-order signal identification.

Result: The STP-based CNN avoids junk information from padding and is successfully applied to image and signal identification tasks.

Conclusion: The proposed STP-based CP and CNN offer a padding-free, efficient alternative for convolutional operations in neural networks.

摘要: 向量的半张量积（STP）是传统向量内积的推广，允许因子向量具有不同维度。本文提出了一种基于域的卷积积（CP）。通过将基于域的CP与向量的STP结合，提出了一种新的CP。由于没有零填充或其他填充，可以避免由填充引起的垃圾信息。利用它，开发了基于STP的卷积神经网络（CNN），并考虑了其在图像和第三阶信号识别中的应用。

</details>


### [661] [Energy Aware Camera Location Search Algorithm for Increasing Precision of Observation in Automated Manufacturing](https://arxiv.org/abs/2506.10251)
**中文标题：提高自动化制造观测精度的能量感知相机位置搜索算法**

*Rongfei Li,Francis Assadian*

Main category: eess.SY

TL;DR: The paper proposes an energy-aware algorithm to optimize camera placement in automated manufacturing, minimizing image noise and improving observation precision with limited energy.


<details>
  <summary>Details</summary>
Motivation: Existing research focuses on control and observation architectures but overlooks the impact of camera location on image quality in eye-to-hand configurations. Environmental noise varies by location, affecting estimation accuracy.

Method: The algorithm explores the camera workspace to find optimal or suboptimal locations with minimal noise, using adaptive search policies and image averaging for efficiency. It operates within energy constraints.

Result: Simulations show the algorithm successfully improves observation precision in automated manufacturing, achieving desirable accuracy without filtering high-frequency image information.

Conclusion: The algorithm effectively balances energy constraints and observation precision, offering a practical solution for optimizing camera placement in manufacturing environments.

摘要: 视觉伺服技术已在自动化制造任务中得到广泛应用，尤其在工具姿态对齐方面。为获取工具的全局视图，多数应用采用眼到手配置或眼到手/眼在手协作配置。现有研究多关注控制和观测架构的开发，但鲜有探讨眼到手配置中相机位置的重要性。制造环境中，相机估计质量因观测位置不同而差异显著，环境条件综合作用导致单张图像在不同位置的噪声水平不同。本文提出一种相机移动策略算法，探索相机工作空间并搜索图像噪声水平最小的最优位置。同时，该算法确保相机在有限能量下最终停留在已搜索的次优位置（若最优位置不可达）。与简单暴力搜索不同，该算法通过学习环境自适应调整搜索策略，使相机更高效地探索空间。借助图像平均技术，该算法仅用单相机即可在眼到手配置中实现理想的观测精度，无需滤除原始图像中的高频信息。通过自动化制造应用的仿真，结果表明该算法在有限能量下成功提高了观测精度。

</details>


### [662] [Semi-Tensor-Product Based Convolutional Neural Networks](https://arxiv.org/abs/2506.10407)
**中文标题：基于半张量积的卷积神经网络**

*Daizhan Cheng*

Main category: eess.SY

TL;DR: 本文提出了一种基于半张量积（STP）的卷积神经网络（CNN），通过结合域基卷积积（CP）和STP，避免了传统填充带来的冗余信息，适用于图像和三阶信号识别。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络中，填充操作会引入冗余信息，影响模型性能。本文旨在通过半张量积和域基卷积积的结合，消除填充需求，提升网络效率。

Method: 提出了一种新的域基卷积积（CP），并将其与半张量积（STP）结合，构建了基于STP的卷积神经网络（CNN）。该方法无需填充操作，避免了冗余信息。

Result: 所提出的STP-CNN在图像和三阶信号识别任务中表现出色，验证了其有效性和实用性。

Conclusion: 基于STP的卷积神经网络通过消除填充需求，显著提升了模型性能，为图像和信号处理提供了新的解决方案。

摘要: 半张量积（STP）是向量内积的一种推广，允许因子向量具有不同维度。本文提出了一种域基卷积积（CP），并将其与STP结合，提出了一种新的CP。由于无需零填充或其他填充操作，可以避免填充带来的冗余信息。基于此，开发了基于STP的卷积神经网络（CNN），并应用于图像和三阶信号识别任务。

</details>


### [663] [Energy Aware Camera Location Search Algorithm for Increasing Precision of Observation in Automated Manufacturing](https://arxiv.org/abs/2506.10251)
**中文标题：用于提升自动化制造观测精度的能量感知相机位置搜索算法**

*Rongfei Li,Francis Assadian*

Main category: eess.SY

TL;DR: 本文提出了一种能量感知的相机位置搜索算法，用于在自动化制造中提高观测精度。该算法通过探索相机工作空间并寻找噪声最小的最优位置，同时考虑能量限制，实现了高效的空间探索和观测精度提升。


<details>
  <summary>Details</summary>
Motivation: 在自动化制造中，视觉伺服技术广泛应用于工具姿态对齐。然而，现有研究多关注控制和观测架构，而忽略了相机位置在眼到手配置中的重要性。相机位置的不同会导致图像噪声水平的变化，从而影响观测质量。

Method: 提出了一种相机移动策略算法，通过探索相机工作空间并学习环境，寻找噪声最小的最优位置。算法结合图像平均技术，确保在有限能量下找到次优位置，同时保留图像的高频信息。

Result: 模拟实验表明，该算法在有限能量下显著提高了观测精度，且无需过滤原始图像的高频信息。

Conclusion: 该算法为自动化制造中的视觉伺服系统提供了一种高效且能量感知的相机位置搜索方法，显著提升了观测精度。

摘要: 视觉伺服技术已广泛应用于自动化制造任务，尤其是工具姿态对齐。为了获取工具的全局视图，大多数应用采用眼到手配置或眼到手/眼在手协作配置。现有研究多关注控制和观测架构的开发，而较少讨论相机位置在眼到手配置中的重要性。在制造环境中，相机位置的差异会导致图像噪声水平的变化，从而影响观测质量。本文提出了一种相机移动策略算法，通过探索相机工作空间并寻找噪声最小的最优位置。该算法在有限能量下确保相机最终停在一个次优位置（如果最优位置不可达）。与简单的暴力搜索方法不同，该算法通过学习环境调整搜索策略，实现更高效的空间探索。结合图像平均技术，该算法仅使用单个相机即可在眼到手配置中达到理想的观测精度，且无需过滤原始图像的高频信息。模拟实验结果表明，该算法在有限能量下显著提高了观测精度。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [664] [AniMaker: Automated Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation](https://arxiv.org/abs/2506.10540)
**中文标题：AniMaker：基于MCTS驱动片段生成的多智能体自动动画叙事**

*Haoyuan Shi,Yunxin Li,Xinyu Chen,Longyue Wang,Baotian Hu,Min Zhang*

Main category: cs.MA

TL;DR: AniMaker is a multi-agent framework for generating coherent storytelling animations from text, using MCTS-driven clip generation and specialized agents to ensure consistency and quality.


<details>
  <summary>Details</summary>
Motivation: Current video generation methods struggle with coherent multi-scene storytelling due to rigid clip generation and instability, leading to disjointed narratives and pacing issues.

Method: AniMaker employs specialized agents (Director, Photography, Reviewer, Post-Production) with MCTS-Gen for efficient clip generation and AniEval for multi-shot animation evaluation.

Result: AniMaker outperforms existing methods in quality (measured by VBench and AniEval) and efficiency, improving multi-candidate generation for storytelling animations.

Conclusion: AniMaker advances AI-generated storytelling by ensuring coherence and quality, moving closer to production standards.

摘要: 尽管视频生成模型发展迅速，但生成跨多场景和多角色的连贯叙事视频仍具挑战性。现有方法通常将预生成的关键帧机械转换为固定长度的片段，导致叙事脱节和节奏问题。此外，视频生成模型的不稳定性意味着单个低质量片段会显著降低整个动画的逻辑连贯性和视觉连续性。为克服这些障碍，我们提出了AniMaker，一个多智能体框架，支持高效的多候选片段生成和叙事感知片段选择，从而仅从文本输入创建全局一致且故事连贯的动画。该框架围绕多个专用智能体构建，包括用于故事板生成的导演智能体、用于视频片段生成的摄影智能体、用于评估的评审智能体，以及用于编辑和配音的后期制作智能体。AniMaker的核心技术包括摄影智能体中的MCTS-Gen，这是一种受蒙特卡洛树搜索（MCTS）启发的策略，能智能导航候选空间以生成高质量片段并优化资源使用；以及评审智能体中的AniEval，这是首个专为多镜头动画评估设计的框架，通过考虑每个片段的前后片段背景，评估故事级一致性、动作完成度和动画特定特征。实验表明，AniMaker在VBench和我们提出的AniEval框架等流行指标上均表现出优越质量，同时显著提高了多候选生成的效率，使AI生成的叙事动画更接近生产标准。

</details>


### [665] [AniMaker: Automated Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation](https://arxiv.org/abs/2506.10540)
**中文标题：AniMaker：基于MCTS驱动片段生成的多智能体自动动画故事创作**

*Haoyuan Shi,Yunxin Li,Xinyu Chen,Longyue Wang,Baotian Hu,Min Zhang*

Main category: cs.MA

TL;DR: AniMaker是一个多智能体框架，通过MCTS驱动的片段生成和故事感知的片段选择，从文本输入生成全局一致且故事连贯的动画。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成方法在生成多场景和多角色的连贯故事视频时存在挑战，常导致叙事脱节和节奏问题。AniMaker旨在解决这些问题，提升动画的逻辑一致性和视觉连续性。

Method: AniMaker采用多智能体框架，包括导演智能体（故事板生成）、摄影智能体（视频片段生成）、评审智能体（评估）和后期制作智能体（编辑和配音）。关键技术包括MCTS-Gen（高效生成高质量片段）和AniEval（多镜头动画评估框架）。

Result: 实验表明，AniMaker在VBench和AniEval等指标上表现优异，显著提升了多候选生成的效率，使AI生成的故事动画更接近生产标准。

Conclusion: AniMaker通过多智能体协作和先进技术，成功解决了多场景动画生成的挑战，为AI生成故事动画提供了高效且高质量的解决方案。

摘要: 尽管视频生成模型发展迅速，但生成跨多场景和多角色的连贯故事视频仍具挑战性。现有方法通常将预生成的关键帧转换为固定长度的片段，导致叙事脱节和节奏问题。此外，视频生成模型的不稳定性使得单个低质量片段可能严重影响整个动画的逻辑一致性和视觉连续性。为克服这些障碍，我们提出了AniMaker，一个多智能体框架，支持高效的多候选片段生成和故事感知的片段选择，从而仅从文本输入生成全局一致且故事连贯的动画。该框架围绕多个专用智能体构建，包括导演智能体（故事板生成）、摄影智能体（视频片段生成）、评审智能体（评估）和后期制作智能体（编辑和配音）。AniMaker的核心技术包括摄影智能体中的MCTS-Gen（一种受蒙特卡洛树搜索启发的策略，智能导航候选空间以生成高质量片段并优化资源使用）和评审智能体中的AniEval（首个专为多镜头动画评估设计的框架，通过考虑每个片段的前后关联，评估故事一致性、动作完成度和动画特定特征）。实验表明，AniMaker在VBench和我们提出的AniEval框架等指标上表现优异，同时显著提升了多候选生成的效率，推动AI生成的故事动画更接近生产标准。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [666] [Ground Reaction Force Estimation via Time-aware Knowledge Distillation](https://arxiv.org/abs/2506.10265)
**中文标题：基于时间感知知识蒸馏的地面反作用力估计**

*Eun Som Jeon,Sinjini Mitra,Jisoo Lee,Omik M. Save,Ankita Shukla,Hyunglae Lee,Pavan Turaga*

Main category: eess.SP

TL;DR: The paper proposes a Time-aware Knowledge Distillation framework to improve GRF estimation from wearable insole sensors, outperforming current baselines by leveraging temporal and similarity features.


<details>
  <summary>Details</summary>
Motivation: Traditional GRF measurement methods like instrumented treadmills are costly and lack portability, while wearable insole sensors are noisy and less accurate. The paper aims to address these limitations.

Method: The Time-aware Knowledge Distillation framework captures complementary relationships and sequential properties between features in a mini-batch during distillation.

Result: The framework outperforms current baselines in GRF estimation, as validated by comparisons with treadmill measurements.

Conclusion: The proposed framework provides a lightweight, accurate solution for GRF estimation from wearable sensors, addressing portability and cost issues.

摘要: 可穿戴传感器的人体步态分析已广泛应用于日常生活保健、康复、物理治疗及临床诊断与监测等领域。地面反作用力（GRF）尤其提供了关于身体在运动过程中与地面交互的关键信息。尽管仪器化跑步机被广泛用作测量步行中GRF的金标准，但其缺乏便携性和高昂成本使其在许多应用中不切实际。作为一种替代方案，低成本、便携式的可穿戴鞋垫传感器被用于测量GRF；然而，这些传感器易受噪声和干扰影响，且准确性低于跑步机测量。为解决这些问题，我们提出了一种基于时间感知知识蒸馏的框架，用于从鞋垫传感器数据中估计GRF。该框架在知识蒸馏过程中利用小批量内的相似性和时间特征，有效捕捉了特征之间的互补关系以及目标与输入数据的序列特性。通过将鞋垫传感器数据的GRF估计与仪器化跑步机的测量结果进行比较，评估了通过该框架蒸馏的轻量级模型的性能。实证结果表明，时间感知知识蒸馏在可穿戴传感器数据的GRF估计中优于当前基线方法。

</details>


### [667] [Ground Reaction Force Estimation via Time-aware Knowledge Distillation](https://arxiv.org/abs/2506.10265)
**中文标题：基于时间感知知识蒸馏的地面反作用力估计**

*Eun Som Jeon,Sinjini Mitra,Jisoo Lee,Omik M. Save,Ankita Shukla,Hyunglae Lee,Pavan Turaga*

Main category: eess.SP

TL;DR: 提出了一种基于时间感知知识蒸馏的框架，用于从便携式鞋垫传感器数据中估计地面反作用力（GRF），解决了现有方法噪声大、精度低的问题，性能优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 地面反作用力（GRF）在步态分析中至关重要，但传统跑步机测量设备昂贵且不便携，而便携式鞋垫传感器虽成本低但易受噪声干扰且精度不足。因此，需要一种更高效的方法从鞋垫数据中准确估计GRF。

Method: 提出了一种时间感知知识蒸馏框架，通过利用小批量数据中的相似性和时序特征，捕捉目标与输入数据之间的互补关系和序列特性，从而提升GRF估计的准确性。

Result: 实验结果表明，该框架在从鞋垫传感器数据估计GRF时，性能优于当前基线方法。

Conclusion: 时间感知知识蒸馏框架为便携式传感器数据提供了一种高效的GRF估计方法，具有实际应用潜力。

摘要: 可穿戴传感器在人类步态分析中广泛应用于日常生活保健、康复、物理治疗及临床诊断与监测等领域。地面反作用力（GRF）是反映身体与地面相互作用的关键指标。尽管跑步机测量设备是GRF测量的金标准，但其便携性差且成本高，限制了实际应用。作为替代方案，低成本、便携式的鞋垫传感器被用于测量GRF，但其易受噪声干扰且精度较低。为解决这些问题，我们提出了一种基于时间感知知识蒸馏的框架，用于从鞋垫传感器数据中估计GRF。该框架在知识蒸馏过程中利用小批量数据中的相似性和时序特征，有效捕捉了特征间的互补关系及目标与输入数据的序列特性。通过将鞋垫传感器数据与跑步机测量结果对比，评估了该框架蒸馏出的轻量级模型的性能。实验结果表明，时间感知知识蒸馏在可穿戴传感器数据GRF估计中优于当前基线方法。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [668] [Extended Creativity: A Conceptual Framework for Understanding Human-AI Creative Relations](https://arxiv.org/abs/2506.10249)
**中文标题：扩展创造力：理解人类与AI创意关系的概念框架**

*Andrea Gaggioli,Sabrina Bartolotta,Andrea Ubaldi,Katusha Gerardini,Eleonora Diletta Sarcinella,Alice Chirico*

Main category: cs.HC

TL;DR: The paper proposes a framework for understanding how AI enhances human creativity through three modes: Support, Synergy, and Symbiosis, based on AI's autonomy and perceived agency.


<details>
  <summary>Details</summary>
Motivation: To clarify how AI can effectively enhance human creativity by exploring different modes of human-AI interaction in creative processes.

Method: The study adopts a distributed creativity perspective, defining three modes (Support, Synergy, Symbiosis) along dimensions of AI autonomy and perceived agency, and examines their impact on creativity levels.

Result: The framework identifies how each mode (Support, Synergy, Symbiosis) influences creativity, from everyday problem-solving to paradigm-shifting innovation, with implications for theory, ethics, and design.

Conclusion: The proposed framework provides a structured way to understand and design human-AI creative collaborations, highlighting the importance of balancing autonomy and agency for effective enhancement of creativity.

摘要: 人工智能在增强人类创造力方面具有巨大潜力。然而，实现这一愿景需要更清晰地理解如何有效实现这种增强。我们采用分布式创造力的视角，确定了AI在创意过程中发挥作用的三种主要模式：支持模式（AI作为工具）、协同模式（AI与人类以互补方式合作）和共生模式（人类与AI认知高度整合，形成统一的创意系统）。这些模式基于两个关键维度定义：AI系统的技术自主性和其被感知的代理程度。我们探讨了每种配置如何影响不同层次的创造力（从日常问题解决到范式转变的创新），并讨论了理论、伦理和设计方面的意义。

</details>


### [669] [The Role of Generative AI in Facilitating Social Interactions: A Scoping Review](https://arxiv.org/abs/2506.10927)
**中文标题：生成式AI在促进社交互动中的作用：范围综述**

*T. T. J. E. Arets,G. Perugia,M. Houben,W. A. IJsselsteijn*

Main category: cs.HC

TL;DR: This scoping review explores how generative AI (GAI) technologies enhance social interactions, analyzing 30 studies to identify trends, design methodologies, and socio-ethical concerns.


<details>
  <summary>Details</summary>
Motivation: Reduced social connectedness threatens mental health and well-being, yet the impact of GAI on social interactions remains understudied.

Method: A scoping review of 30 studies published since 2020, focusing on GAI applications in storytelling, skills training, reminiscence, learning, music, and conversation.

Result: Key trends include participatory design approaches and diverse application domains, alongside socio-ethical issues like cultural bias and accessibility.

Conclusion: GAI shows promise for personalized social interactions but requires equitable design and inclusive evaluation practices.

摘要: 社交联系的减少对心理健康、预期寿命和整体幸福感构成了日益严重的威胁。生成式AI（GAI）技术，如大型语言模型（LLMs）和图像生成工具，正越来越多地融入旨在提升人类社交体验的应用中。尽管其应用日益广泛，但这些技术如何影响社交互动尚不明确。本范围综述探讨了基于GAI的应用如何设计以促进社交互动，其目标社交形式，以及设计和评估方法。通过对2020年以来30项研究的分析，我们确定了包括讲故事、社会情感技能训练、回忆、协作学习、音乐创作和一般对话在内的关键应用趋势。我们强调了参与式和共同设计方法在促进技术有效使用和社交参与中的作用，同时探讨了文化偏见和可访问性等社会伦理问题。本综述强调了GAI支持动态和个性化互动的潜力，但呼吁更多关注公平设计实践和包容性评估策略。

</details>


### [670] [Extended Creativity: A Conceptual Framework for Understanding Human-AI Creative Relations](https://arxiv.org/abs/2506.10249)
**中文标题：扩展创造力：理解人类与AI创造性关系的概念框架**

*Andrea Gaggioli,Sabrina Bartolotta,Andrea Ubaldi,Katusha Gerardini,Eleonora Diletta Sarcinella,Alice Chirico*

Main category: cs.HC

TL;DR: 本文提出一个框架，将AI对人类创造力的贡献分为三种模式：支持、协同与共生，并探讨其技术自主性和感知代理程度的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过AI有效增强人类创造力，明确AI在创造性过程中的作用模式。

Method: 采用分布式创造力的视角，定义AI参与的三种模式（支持、协同、共生），并分析其技术自主性和感知代理程度的影响。

Result: 提出了三种AI参与创造力的模式，并分析了其对不同创造力层次的影响，包括理论、伦理和设计意义。

Conclusion: AI可通过支持、协同和共生模式增强人类创造力，但需考虑技术自主性和感知代理的影响。

摘要: 人工智能在增强人类创造力方面具有巨大潜力，但实现这一愿景需要更清晰地理解如何有效实现这种增强。我们采用分布式创造力的视角，确定了AI参与创造性过程的三种主要模式：支持模式，即AI作为工具；协同模式，即AI与人类以互补方式合作；以及共生模式，即人类与AI认知高度整合，形成统一的创造性系统。这些模式基于两个关键维度定义：AI系统的技术自主性水平和其感知代理程度。我们探讨了每种配置如何影响不同层次的创造力——从日常问题解决到范式转变的创新——并讨论了其理论、伦理和设计意义。

</details>


### [671] [The Role of Generative AI in Facilitating Social Interactions: A Scoping Review](https://arxiv.org/abs/2506.10927)
**中文标题：生成式AI在促进社交互动中的作用：范围综述**

*T. T. J. E. Arets,G. Perugia,M. Houben,W. A. IJsselsteijn*

Main category: cs.HC

TL;DR: 本文综述了生成式AI（GAI）在促进社交互动中的应用，分析了30项研究，总结了其在故事讲述、情感技能训练等领域的趋势，并呼吁关注公平设计和包容性评估。


<details>
  <summary>Details</summary>
Motivation: 社交联系的减少对心理健康、寿命和整体幸福感构成威胁。生成式AI技术（如大型语言模型和图像生成工具）被越来越多地用于增强人类社交体验，但其对社交互动的影响尚不明确。本文旨在探讨GAI如何促进社交互动及其设计方法。

Method: 通过分析2020年以来发表的30项研究，本文对GAI在社交互动中的应用进行了范围综述，重点关注应用领域、设计方法和评估策略。

Result: 研究发现GAI在故事讲述、情感技能训练、回忆、协作学习、音乐创作和一般对话等领域有广泛应用。参与式和协同设计方法在促进技术使用和社交互动中发挥了重要作用，但也存在文化偏见和可访问性等社会伦理问题。

Conclusion: GAI具有支持动态和个性化互动的潜力，但需要更多关注公平设计和包容性评估策略。

摘要: 社交联系的减少日益对心理健康、寿命和整体幸福感构成威胁。生成式AI（GAI）技术，如大型语言模型（LLMs）和图像生成工具，正越来越多地融入旨在增强人类社交体验的应用中。尽管其应用日益广泛，但这些技术如何影响社交互动尚不明确。本范围综述探讨了基于GAI的应用目前如何设计以促进社交互动、其针对的社交参与形式，以及设计师用于创建和评估它们的设计和评估方法。通过对2020年以来发表的30项研究的分析，我们确定了包括故事讲述、社会情感技能训练、回忆、协作学习、音乐创作和一般对话等应用领域的关键趋势。我们强调了参与式和协同设计方法在促进技术有效使用和社交参与中的作用，同时探讨了文化偏见和可访问性等社会伦理问题。本综述强调了GAI支持动态和个性化互动的潜力，但呼吁更多关注公平设计实践和包容性评估策略。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [672] [FastFLUX: Pruning FLUX with Block-wise Replacement and Sandwich Training](https://arxiv.org/abs/2506.10035)
**中文标题：FastFLUX：通过块级替换和三明治训练修剪FLUX**

*Fuhan Cai,Yong Guo,Jie Li,Wenbo Li,Xiangzhong Fang,Jian Chen*

Main category: cs.GR

TL;DR: FastFLUX is a pruning framework for FLUX models that replaces complex residual branches with linear layers and uses localized fine-tuning to maintain performance while improving inference speed.


<details>
  <summary>Details</summary>
Motivation: FLUX models are highly expressive but suffer from slow inference, high memory usage, and poor deployability due to their large parameter sizes. Existing acceleration methods often degrade performance or require high training costs.

Method: FastFLUX introduces Block-wise Replacement with Linear Layers (BRLL) to replace complex residual branches with lightweight linear layers and Sandwich Training (ST), a localized fine-tuning strategy using LoRA to supervise neighboring blocks.

Result: FastFLUX maintains high image quality while significantly improving inference speed, even with 20% of the hierarchy pruned.

Conclusion: FastFLUX effectively balances performance and efficiency, offering a practical solution for deploying FLUX models in resource-constrained environments.

摘要: 近年来，文本到图像（T2I）生成技术的进步催生了高度表达力的模型，如扩散变换器（DiTs），以FLUX为代表。然而，其庞大的参数量导致推理速度慢、内存占用高且部署性差。现有的加速方法（如单步蒸馏和注意力修剪）通常伴随显著的性能下降和高昂的训练成本。为解决这些问题，我们提出了FastFLUX，一种架构级修剪框架，旨在提升FLUX的推理效率。其核心是块级线性层替换（BRLL）方法，该方法将ResBlock中结构复杂的残差分支替换为轻量级线性层，同时保留原始快捷连接以确保稳定性。此外，我们引入了三明治训练（ST），一种利用LoRA监督相邻块的局部微调策略，以缓解结构替换带来的性能下降。实验表明，FastFLUX在定性和定量评估中均保持了较高的图像质量，同时显著提升了推理速度，即使修剪了20%的层次结构。我们的代码即将发布。

</details>


### [673] [Ambient Diffusion Omni: Training Good Models with Bad Data](https://arxiv.org/abs/2506.10038)
**中文标题：环境扩散全能：用劣质数据训练优质模型**

*Giannis Daras,Adrian Rodriguez-Munoz,Adam Klivans,Antonio Torralba,Constantinos Daskalakis*

Main category: cs.GR

TL;DR: The paper introduces Ambient Diffusion Omni, a framework that leverages low-quality and synthetic images to enhance diffusion model training, achieving state-of-the-art results in image quality and diversity.


<details>
  <summary>Details</summary>
Motivation: Current diffusion models rely on curated, high-quality datasets, but the paper argues that lower-quality images, often discarded, contain valuable signal that can improve model performance.

Method: The framework exploits natural image properties (spectral power law decay and locality) to extract signal from mixed-quality data, validated on synthetically corrupted images and applied to achieve top ImageNet FID scores.

Result: Ambient Diffusion Omni achieves state-of-the-art ImageNet FID and improves image quality and diversity in text-to-image generation.

Conclusion: The paper demonstrates that noise can mitigate distribution skew, enabling effective training on mixed-quality data, with theoretical support for the trade-off between biased and unbiased data learning.

摘要: 我们展示了如何利用低质量、合成和分布外图像来提升扩散模型的质量。通常，扩散模型是在从网络和其他来源高度过滤的数据池中精选的数据集上训练的。我们证明，那些常被丢弃的低质量图像具有巨大价值。我们提出了环境扩散全能（Ambient Diffusion Omni），这是一个简单而原则性的框架，用于训练扩散模型，使其能够从所有可用图像中提取信号。我们的框架利用了自然图像的两个特性——频谱功率律衰减和局部性。我们首先通过在合成损坏（高斯模糊、JPEG压缩和运动模糊）的图像上成功训练扩散模型来验证框架。随后，我们利用该框架在ImageNet FID上达到最先进水平，并在文本到图像生成模型中显著提升了图像质量和多样性。核心观点是噪声可以抑制高质量分布与实际观察到的混合分布之间的初始偏差。我们通过分析在扩散时间范围内学习偏置数据与有限无偏数据之间的权衡，为方法提供了严格的理论依据。

</details>


### [674] [Learning-based density-equalizing map](https://arxiv.org/abs/2506.10027)
**中文标题：基于学习的密度均衡映射**

*Yanwen Huang,Lok Ming Lui,Gary P. T. Choi*

Main category: cs.GR

TL;DR: The paper introduces a learning-based density-equalizing mapping framework (LDEM) using deep neural networks, which outperforms traditional methods in accuracy, avoids overlapping artifacts, and seamlessly generalizes from 2D to 3D.


<details>
  <summary>Details</summary>
Motivation: Traditional density-equalizing map (DEM) methods face challenges like limited accuracy, overlapping artifacts, and difficulty in extending from 2D to 3D. The paper aims to address these issues with a learning-based approach.

Method: The authors propose LDEM, a deep neural network framework with a loss function enforcing density uniformity and geometric regularity, using a hierarchical approach for transformation prediction.

Result: LDEM shows superior density-equalizing and bijectivity properties, avoids overlapping artifacts, and generalizes easily from 2D to 3D without structural changes.

Conclusion: The learning-based LDEM framework offers scalable and robust computation of density-equalizing maps, opening new possibilities for practical applications.

摘要: 密度均衡映射（DEM）是一种强大的技术，用于创建形状变形，其面积变化反映底层密度函数。近几十年来，DEM在数据可视化、几何处理和医学影像等领域广泛应用。传统DEM方法主要依赖扩散方程的迭代数值求解器或基于优化的方法，这些方法通常面临精度有限、极端情况下产生重叠伪影以及从2D扩展到3D时需要大量算法重新设计等问题。本文提出了一种基于学习的密度均衡映射框架（LDEM），利用深度神经网络实现。具体而言，我们引入了一种损失函数，强制密度均匀性和几何规律性，并采用分层方法预测粗粒度和密集级别的变换。与现有方法相比，我们的方法在多种简单和复杂密度分布下表现出更优的密度均衡性和双射性，并可轻松应用于具有不同效果的表面重网格化。此外，该方法无需对模型结构或损失函数进行修改即可无缝从2D推广到3D领域。总之，我们的工作为实际应用中可扩展且稳健的密度均衡映射计算开辟了新途径。

</details>


### [675] [Low-Barrier Dataset Collection with Real Human Body for Interactive Per-Garment Virtual Try-On](https://arxiv.org/abs/2506.10468)
**中文标题：基于真实人体的低门槛单服装虚拟试穿数据集收集方法**

*Zaiqiang Wu,Yechen Li,Jingyuan Liu,Yuki Shibata,Takayuki Hori,I-Chao Shen,Takeo Igarashi*

Main category: cs.GR

TL;DR: The paper proposes a low-barrier method for collecting per-garment datasets using real human bodies, improving virtual try-on accuracy and interaction without expensive robotic mannequins.


<details>
  <summary>Details</summary>
Motivation: Existing virtual try-on methods face limitations like high costs of robotic mannequins and misalignment of synthesized garments with human bodies. The paper aims to address these issues by using real human bodies for dataset collection and improving garment alignment.

Method: The approach involves collecting per-garment datasets with real human bodies and introducing a hybrid person representation combining intermediate representation with a simplified DensePose map for better garment alignment and interaction.

Result: Evaluations showed superior image quality and temporal consistency compared to state-of-the-art methods, and user studies confirmed the system's usefulness for garment purchasing decisions.

Conclusion: The proposed method effectively reduces barriers to dataset collection and improves virtual try-on accuracy, demonstrating practical benefits for users.

摘要: 现有的基于图像的虚拟试穿方法通常仅限于正面视角且缺乏实时性能。虽然单服装虚拟试穿方法通过捕获单服装数据集并训练单服装神经网络解决了这些问题，但仍存在实际限制：（1）用于捕获单服装数据集的机器人模特成本过高，难以广泛采用，且无法准确复制自然人体变形；（2）合成的服装常与人体不对齐。为解决这些挑战，我们提出了一种基于真实人体的低门槛单服装数据集收集方法，无需定制机器人模特。我们还引入了一种混合人物表示，通过简化的DensePose图增强现有中间表示，确保合成服装图像与人体准确对齐，并实现无需定制可穿戴设备的人体-服装交互。我们通过定性和定量评估与其他最先进的基于图像的虚拟试穿方法进行比较，并进行消融研究，证明了我们的方法在图像质量和时间一致性方面的优越性。最后，用户研究结果表明，大多数参与者认为我们的虚拟试穿系统有助于服装购买决策。

</details>


### [676] [Edit360: 2D Image Edits to 3D Assets from Any Angle](https://arxiv.org/abs/2506.10507)
**中文标题：Edit360：从任意角度将2D图像编辑扩展到3D资产**

*Junchao Huang,Xinting Hu,Zhuotao Tian,Shaoshuai Shi,Li Jiang*

Main category: cs.GR

TL;DR: Edit360 is a tuning-free framework that extends 2D image edits to multi-view consistent 3D assets using video diffusion models, enabling edits from any viewpoint with structural coherence.


<details>
  <summary>Details</summary>
Motivation: Existing methods for 3D asset editing are limited to predetermined viewing angles, restricting flexibility and practical applications. Edit360 aims to overcome this by enabling fine-grained, multi-view consistent edits from any angle.

Method: Edit360 leverages video diffusion models, selecting anchor views for 2D edits and propagating them across 360 degrees using an Anchor-View Editing Propagation mechanism to align multi-view information in latent and attention spaces.

Result: The framework successfully reconstructs high-quality 3D assets with customizable edits, ensuring structural coherence across all viewpoints.

Conclusion: Edit360 provides a flexible and practical solution for extending 2D edits to 3D assets, enabling customizable 3D content creation from any angle.

摘要: 近年来，扩散模型在图像生成和编辑方面取得了显著进展，但将这些能力扩展到3D资产仍然具有挑战性，尤其是对于需要多视角一致性的细粒度编辑。现有方法通常将编辑限制在预定的视角范围内，严重限制了其灵活性和实际应用。我们提出了Edit360，一种无需调整的框架，可将2D修改扩展到多视角一致的3D编辑。基于视频扩散模型，Edit360支持从任意视角进行用户特定的编辑，同时确保所有视角的结构一致性。该框架选择锚定视角进行2D修改，并将编辑传播到整个360度范围内。为此，Edit360引入了一种新颖的锚定视角编辑传播机制，有效在扩散模型的潜在和注意力空间中对齐和合并多视角信息。生成的编辑后的多视角序列有助于重建高质量的3D资产，从而实现可定制的3D内容创作。

</details>


### [677] [Transformer IMU Calibrator: Dynamic On-body IMU Calibration for Inertial Motion Capture](https://arxiv.org/abs/2506.10580)
**中文标题：Transformer IMU校准器：动态身体IMU校准用于惯性动作捕捉**

*Chengxu Zuo,Jiawei Huang,Xiao Jiang,Yuan Yao,Xiangren Shi,Rui Cao,Xinyu Yi,Feng Xu,Shihui Guo,Yipeng Qin*

Main category: cs.GR

TL;DR: The paper introduces a dynamic calibration method for IMUs in motion capture, relaxing static assumptions and enabling real-time estimation of drift and offset matrices using a Transformer-based model.


<details>
  <summary>Details</summary>
Motivation: Current IMU calibration methods rely on restrictive static assumptions, limiting their application. The paper aims to enable dynamic calibration for broader use.

Method: The method uses a Transformer-based model to estimate drift and offset matrices in real time, leveraging synthetic datasets and a calibration trigger based on IMU reading diversity.

Result: The approach achieves implicit IMU calibration and accurate long-term motion capture with sparse IMUs, a first in the field.

Conclusion: The proposed method successfully breaks static calibration constraints, expanding IMU applications in motion capture.

摘要: 本文提出了一种新颖的动态校准方法，用于稀疏惯性动作捕捉系统，首次打破了IMU校准中严格的绝对静态假设（即坐标漂移RG'G和测量偏移RBS在整个运动过程中保持不变），从而显著扩展了其应用场景。具体而言，我们在两个放宽的假设下实现了RG'G和RBS的实时估计：i）矩阵在短时间内变化可忽略；ii）人体运动/IMU读数在该时间窗口内具有多样性。直观上，第一个假设减少了候选矩阵的数量，第二个假设提供了多样化的约束，极大地缩小了解空间，从而可以从IMU读数的短历史中实时准确估计RG'G和RBS。为实现这一点，我们创建了成对的RG'G、RBS矩阵和IMU读数的合成数据集，并使用基于Transformer的模型学习其映射关系。我们还设计了一个基于IMU读数多样性的校准触发器，以确保在应用我们的方法之前满足假设ii）。据我们所知，我们是首个实现隐式IMU校准（即无需显式校准过程即可无缝使用IMU）的团队，也是首个实现使用稀疏IMU进行长期准确动作捕捉的团队。代码和数据集可在https://github.com/ZuoCX1996/TIC获取。

</details>


### [678] [FastFLUX: Pruning FLUX with Block-wise Replacement and Sandwich Training](https://arxiv.org/abs/2506.10035)
**中文标题：FastFLUX：基于块级替换与夹心训练的FLUX剪枝方法**

*Fuhan Cai,Yong Guo,Jie Li,Wenbo Li,Xiangzhong Fang,Jian Chen*

Main category: cs.GR

TL;DR: FastFLUX是一种针对FLUX模型的架构级剪枝框架，通过块级替换和夹心训练提升推理效率，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: FLUX等文本到图像生成模型参数量大，导致推理速度慢、内存占用高且部署困难。现有加速方法常伴随性能显著下降和高训练成本。

Method: 提出FastFLUX框架，核心为块级线性层替换（BRLL）方法，将复杂残差分支替换为轻量线性层，并保留原始快捷连接；同时引入夹心训练（ST），利用LoRA监督邻近块以缓解性能下降。

Result: 实验表明，FastFLUX在剪除20%层级后仍保持高质量图像生成，同时显著提升推理速度。

Conclusion: FastFLUX通过架构级剪枝和局部微调策略，有效平衡了模型性能和推理效率。

摘要: 近年来，文本到图像（T2I）生成技术的进步催生了如FLUX等高度表达的模型，例如扩散变换器（DiTs）。然而，其庞大的参数量导致推理速度慢、内存占用高且部署性差。现有加速方法（如单步蒸馏和注意力剪枝）常伴随显著的性能下降和高昂的训练成本。为解决这些问题，我们提出FastFLUX，一种架构级剪枝框架，旨在提升FLUX的推理效率。其核心是块级线性层替换（BRLL）方法，该方法将ResBlock中结构复杂的残差分支替换为轻量线性层，同时保留原始快捷连接以确保稳定性。此外，我们引入夹心训练（ST），一种基于LoRA的局部微调策略，通过监督邻近块来缓解结构替换导致的性能下降。实验表明，FastFLUX在定性和定量评估下均保持高图像质量，同时显著提升推理速度，即使剪除20%的层级。代码即将公开。

</details>


### [679] [FastFLUX: Pruning FLUX with Block-wise Replacement and Sandwich Training](https://arxiv.org/abs/2506.10035)
**中文标题：FastFLUX：通过块级替换和夹心训练剪枝FLUX**

*Fuhan Cai,Yong Guo,Jie Li,Wenbo Li,Xiangzhong Fang,Jian Chen*

Main category: cs.GR

TL;DR: FastFLUX是一种针对FLUX模型的架构级剪枝框架，通过块级替换和夹心训练，显著提升推理效率，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型（如FLUX）参数量庞大，导致推理速度慢、内存占用高且部署困难。现有加速方法常伴随性能显著下降和高训练成本。

Method: 提出块级线性层替换（BRLL）方法，将复杂残差分支替换为轻量级线性层，保留原始快捷连接；引入夹心训练（ST），利用LoRA监督邻近块，减少结构替换导致的性能下降。

Result: 实验表明，FastFLUX在剪去20%层级后仍能保持高质量图像生成，同时显著提升推理速度。

Conclusion: FastFLUX通过创新的剪枝和训练策略，有效解决了FLUX模型的推理效率问题，为高性能文本到图像生成提供了实用解决方案。

摘要: 近年来，文本到图像（T2I）生成技术的进步催生了如FLUX等高度表达的模型，例如扩散变换器（DiTs）。然而，其庞大的参数量导致推理速度慢、内存占用高且部署困难。现有加速方法（如单步蒸馏和注意力剪枝）常伴随性能显著下降和高训练成本。为解决这些问题，我们提出了FastFLUX，一种架构级剪枝框架，旨在提升FLUX的推理效率。其核心是块级线性层替换（BRLL）方法，该方法将ResBlock中结构复杂的残差分支替换为轻量级线性层，同时保留原始快捷连接以确保稳定性。此外，我们引入了夹心训练（ST），一种基于LoRA的局部微调策略，通过监督邻近块来缓解结构替换导致的性能下降。实验表明，FastFLUX在定性和定量评估中均能保持高图像质量，同时显著提升推理速度，即使剪去20%的层级。我们的代码即将发布。

</details>


### [680] [Ambient Diffusion Omni: Training Good Models with Bad Data](https://arxiv.org/abs/2506.10038)
**中文标题：环境扩散全能：用劣质数据训练优质模型**

*Giannis Daras,Adrian Rodriguez-Munoz,Adam Klivans,Antonio Torralba,Constantinos Daskalakis*

Main category: cs.GR

TL;DR: 本文提出了一种名为Ambient Diffusion Omni的框架，利用低质量、合成和分布外图像提升扩散模型的质量。通过利用自然图像的光谱幂律衰减和局部性特性，该框架能够从所有可用图像中提取信号，显著提升生成模型的图像质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型通常依赖高质量、经过筛选的数据集，而低质量图像常被丢弃。本文旨在证明这些低质量图像中蕴含的价值，并提出一种方法从中提取有用信号以提升模型性能。

Method: Ambient Diffusion Omni框架利用自然图像的光谱幂律衰减和局部性特性，通过噪声抑制初始偏差，从混合分布中学习。该方法在合成损坏图像（如高斯模糊、JPEG压缩和运动模糊）上验证后，进一步应用于实际任务。

Result: 实验表明，该框架在ImageNet上实现了最先进的FID分数，并在文本到图像生成任务中显著提升了图像质量和多样性。

Conclusion: 通过理论分析和实验验证，本文证明了从低质量图像中提取信号的有效性，为扩散模型的训练提供了新的思路。

摘要: 我们展示了如何利用低质量、合成和分布外图像提升扩散模型的质量。传统扩散模型通常基于经过高度筛选的网络和其他来源数据集进行训练，而我们证明了常被丢弃的低质量图像中蕴含巨大价值。我们提出了Ambient Diffusion Omni，这是一个简单而原则性的框架，能够在训练过程中从所有可用图像中提取信号。该框架利用了自然图像的两个特性——光谱幂律衰减和局部性。我们首先通过在合成损坏（如高斯模糊、JPEG压缩和运动模糊）图像上成功训练扩散模型验证了框架的有效性。随后，我们使用该框架在ImageNet上实现了最先进的FID分数，并在文本到图像生成任务中显著提升了图像质量和多样性。核心观点是噪声能够抑制高质量分布与混合分布之间的初始偏差。我们通过分析扩散时间中从有偏数据与有限无偏数据学习的权衡，为方法提供了严格的理论依据。

</details>


### [681] [Learning-based density-equalizing map](https://arxiv.org/abs/2506.10027)
**中文标题：基于学习的密度均衡映射**

*Yanwen Huang,Lok Ming Lui,Gary P. T. Choi*

Main category: cs.GR

TL;DR: 本文提出了一种基于学习的密度均衡映射框架（LDEM），通过深度神经网络实现高精度、无重叠的密度均衡映射，并支持从2D到3D的无缝扩展。


<details>
  <summary>Details</summary>
Motivation: 传统密度均衡映射方法存在精度有限、极端情况下产生重叠伪影以及从2D扩展到3D时需要大量算法重新设计的问题。本文旨在通过深度学习方法解决这些问题。

Method: 提出了一种基于深度神经网络的框架（LDEM），引入了一种损失函数以确保密度均匀性和几何规则性，并采用分层方法预测粗粒度和密集级别的变换。

Result: LDEM在多种简单和复杂密度分布下表现出优于现有方法的密度均衡性和双射性，并可轻松应用于不同效果的表面重新网格化。同时，该方法无需修改模型结构或损失函数即可从2D无缝扩展到3D。

Conclusion: 本文提出的LDEM框架为密度均衡映射的可扩展和鲁棒计算提供了新的可能性，适用于实际应用。

摘要: 密度均衡映射（DEM）是一种强大的技术，通过形状变形反映底层密度函数的面积变化。近几十年来，DEM在数据可视化、几何处理和医学成像等领域得到了广泛应用。传统的DEM方法主要依赖于扩散方程的迭代数值求解器或基于优化的方法，这些方法最小化了手工设计的能量泛函。然而，这些传统技术面临一些挑战：精度有限，极端情况下会产生重叠伪影，并且由于其能量公式的导数依赖性，从2D扩展到3D时需要大量算法重新设计。本文提出了一种基于深度神经网络的新型学习型密度均衡映射框架（LDEM）。具体而言，我们引入了一种损失函数，以确保密度均匀性和几何规则性，并采用分层方法预测粗粒度和密集级别的变换。与现有方法相比，我们的方法在多种简单和复杂密度分布下表现出更优的密度均衡性和双射性，并可轻松应用于不同效果的表面重新网格化。此外，该方法无需修改模型结构或损失函数即可从2D无缝扩展到3D。总之，我们的工作为实际应用中的可扩展和鲁棒密度均衡映射计算开辟了新的可能性。

</details>


### [682] [Low-Barrier Dataset Collection with Real Human Body for Interactive Per-Garment Virtual Try-On](https://arxiv.org/abs/2506.10468)
**中文标题：基于真人身体的低成本单件服装虚拟试穿数据集采集**

*Zaiqiang Wu,Yechen Li,Jingyuan Liu,Yuki Shibata,Takayuki Hori,I-Chao Shen,Takeo Igarashi*

Main category: cs.GR

TL;DR: 本文提出了一种低成本、基于真人身体的单件服装虚拟试穿数据集采集方法，解决了现有方法依赖昂贵机器人模型和服装与人体对齐不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的虚拟试穿方法通常局限于正面视角且缺乏实时性，而单件服装虚拟试穿方法虽有所改进，但仍面临机器人模型成本高、无法准确模拟人体变形及服装与人体对齐不准确的问题。

Method: 提出了一种基于真人身体的低成本单件服装数据集采集方法，并引入混合人物表示，结合简化的DensePose图，提升服装与人体对齐的准确性，无需定制可穿戴设备。

Result: 通过定性和定量评估及消融实验，证明了该方法在图像质量和时间一致性上的优越性。用户研究表明，多数参与者认为该系统有助于服装购买决策。

Conclusion: 该方法解决了现有虚拟试穿技术的局限性，为低成本、高精度的单件服装虚拟试穿提供了可行方案。

摘要: 现有的基于图像的虚拟试穿方法通常局限于正面视角且缺乏实时性能。虽然单件服装虚拟试穿方法通过采集单件服装数据集并训练单件服装神经网络解决了这些问题，但仍面临实际限制：（1）用于采集单件服装数据集的机器人模型成本过高，难以广泛采用，且无法准确模拟自然人体变形；（2）合成的服装常与人体对齐不准确。为解决这些问题，我们提出了一种基于真人身体的低成本单件服装数据集采集方法，无需定制机器人模型。我们还引入了一种混合人物表示，通过简化的DensePose图增强现有中间表示，确保合成服装图像与人体准确对齐，并实现无需定制可穿戴设备的人体-服装交互。我们通过定性和定量评估与其他最先进的基于图像的虚拟试穿方法进行比较，并进行了消融实验，证明了我们的方法在图像质量和时间一致性上的优越性。最后，用户研究结果表明，多数参与者认为我们的虚拟试穿系统有助于服装购买决策。

</details>


### [683] [Edit360: 2D Image Edits to 3D Assets from Any Angle](https://arxiv.org/abs/2506.10507)
**中文标题：Edit360：从任意角度将2D图像编辑扩展到3D资产**

*Junchao Huang,Xinting Hu,Zhuotao Tian,Shaoshuai Shi,Li Jiang*

Main category: cs.GR

TL;DR: Edit360是一个无需调优的框架，将2D图像编辑扩展到多视角一致的3D编辑，利用视频扩散模型实现任意视角的用户定制编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的3D编辑方法通常局限于预定的视角，限制了灵活性和实际应用。Edit360旨在解决这一问题，实现多视角一致的3D编辑。

Method: Edit360基于视频扩散模型，通过选择锚定视角进行2D编辑，并通过Anchor-View Editing Propagation机制在潜在和注意力空间中传播编辑，确保多视角一致性。

Result: Edit360能够生成高质量的多视角序列，支持重建可定制的3D资产。

Conclusion: Edit360为3D内容创作提供了一种灵活且高效的方法，扩展了2D编辑到3D领域的可能性。

摘要: 近年来，扩散模型的进步显著提升了图像生成和编辑能力，但将这些能力扩展到3D资产仍然具有挑战性，尤其是需要多视角一致性的细粒度编辑。现有方法通常将编辑限制在预定的视角，严重限制了其灵活性和实际应用。我们提出了Edit360，一个无需调优的框架，将2D修改扩展到多视角一致的3D编辑。基于视频扩散模型，Edit360支持从任意视角进行用户定制编辑，同时确保所有视角的结构一致性。该框架选择锚定视角进行2D修改，并将编辑传播到整个360度范围内。为实现这一点，Edit360引入了一种新颖的Anchor-View Editing Propagation机制，有效对齐并融合了扩散模型潜在和注意力空间中的多视角信息。生成的编辑后多视角序列支持高质量3D资产的重建，从而实现可定制的3D内容创作。

</details>


### [684] [Transformer IMU Calibrator: Dynamic On-body IMU Calibration for Inertial Motion Capture](https://arxiv.org/abs/2506.10580)
**中文标题：Transformer IMU校准器：动态身体IMU校准用于惯性运动捕捉**

*Chengxu Zuo,Jiawei Huang,Xiao Jiang,Yuan Yao,Xiangren Shi,Rui Cao,Xinyu Yi,Feng Xu,Shihui Guo,Yipeng Qin*

Main category: cs.GR

TL;DR: 本文提出了一种新型动态校准方法，首次打破了惯性测量单元（IMU）校准中绝对静态假设的限制，实现了实时估计坐标漂移和测量偏移，显著扩展了稀疏惯性运动捕捉系统的应用场景。


<details>
  <summary>Details</summary>
Motivation: 传统的IMU校准方法依赖于绝对静态假设，即坐标漂移和测量偏移在整个运动过程中保持不变，这限制了其在实际动态场景中的应用。本文旨在通过动态校准方法解决这一问题。

Method: 作者提出了两种放宽的假设：短时间内矩阵变化可忽略，以及人体运动/IMU读数在短时间内具有多样性。基于此，使用Transformer模型学习合成数据集中矩阵与IMU读数的映射关系，并设计了基于IMU读数多样性的校准触发器。

Result: 该方法首次实现了隐式IMU校准（无需显式校准过程），并首次实现了稀疏IMU的长期高精度运动捕捉。代码和数据集已开源。

Conclusion: 本文提出的动态校准方法突破了传统静态假设的限制，为稀疏惯性运动捕捉系统提供了更广泛的应用可能性。

摘要: 本文提出了一种新型动态校准方法，用于稀疏惯性运动捕捉系统，首次打破了IMU校准中绝对静态假设的限制（即坐标漂移RG'G和测量偏移RBS在整个运动中保持不变），从而显著扩展了其应用场景。具体而言，我们在两种放宽的假设下实现了RG'G和RBS的实时估计：i）矩阵在短时间内变化可忽略；ii）人体运动/IMU读数在短时间内具有多样性。直观上，第一个假设减少了候选矩阵的数量，第二个假设提供了多样化的约束，从而大大缩小了解空间，并允许从短时间内的IMU读数历史中实时准确估计RG'G和RBS。为此，我们创建了成对的RG'G、RBS矩阵和IMU读数的合成数据集，并使用基于Transformer的模型学习其映射关系。我们还设计了一个基于IMU读数多样性的校准触发器，以确保在应用我们的方法之前满足假设ii）。据我们所知，我们首次实现了隐式IMU校准（即无需显式校准过程即可无缝使用IMU），并首次实现了稀疏IMU的长期高精度运动捕捉。代码和数据集可在https://github.com/ZuoCX1996/TIC获取。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [685] [Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements](https://arxiv.org/abs/2506.10330)
**中文标题：利用静态代码分析增强大型语言模型以实现自动化代码质量改进**

*Seyed Moein Abtahi,Akramul Azim*

Main category: cs.SE

TL;DR: The paper integrates LLMs with static code analysis and RAG to automate code quality improvements, reducing issues and enhancing efficiency.


<details>
  <summary>Details</summary>
Motivation: To enhance code quality and streamline software development by automating issue detection and revision using LLMs and static analysis.

Method: Combines static code analysis for issue detection with LLMs for automated revisions, using RAG for relevance and a custom tool to correct hallucinations.

Result: Significant reduction in code issues, demonstrating the effectiveness of the combined approach.

Conclusion: Integrating LLMs with static analysis and RAG improves code quality and development efficiency.

摘要: 本研究探讨了通过将大型语言模型（如OpenAI的GPT-3.5 Turbo和GPT-4o）集成到软件开发工作流中，实现代码问题检测和自动化修订。一个静态代码分析框架用于检测大型软件项目中的问题，如漏洞、错误和代码异味。提取并组织每个问题的详细信息，以便利用LLMs进行自动化代码修订。通过迭代的提示工程过程，确保提示的结构化输出与项目需求一致。采用检索增强生成（RAG）以提高修订的相关性和精确性，使LLM能够访问并整合实时外部知识。针对LLM幻觉问题（模型生成看似合理但错误的输出），开发了一个自定义的“代码比较应用”，在将更改应用到代码库之前识别并纠正错误。后续静态代码分析扫描显示代码问题显著减少，证明了结合LLMs、静态分析和RAG在提高代码质量、优化软件开发流程以及节省时间和资源方面的有效性。

</details>


### [686] [Formalising Software Requirements using Large Language Models](https://arxiv.org/abs/2506.10704)
**中文标题：利用大型语言模型形式化软件需求**

*Arshad Beg,Diarmuid O'Donoghue,Rosemary Monahan*

Main category: cs.SE

TL;DR: The paper introduces the VERIFAI project, which aims to automate the generation of formal specifications and ensure traceability of requirements in software development using NLP, ontologies, reuse of artifacts, and large language models.


<details>
  <summary>Details</summary>
Motivation: The project addresses challenges in traceability and verification of formal specifications in software development, aiming to streamline the process from design to implementation and verification.

Method: The project employs Natural Language Processing, ontologies, reuse of existing software artifacts, large language models, and AI to generate and trace formal specifications.

Result: The project explores innovative approaches to automate and improve the traceability and verification of software requirements.

Conclusion: The VERIFAI project presents a promising framework for enhancing the efficiency and accuracy of formal specification generation and traceability in software development.

摘要: 本文简要介绍了我们最近启动的项目VERIFAI：自然语言需求的可追溯性与验证。该项目通过支持自动生成形式化规范以及从初始软件设计阶段到系统实现和验证的需求可追溯性，解决了形式化规范的可追溯性和验证中的挑战。项目中探索的方法包括自然语言处理、使用本体描述软件系统领域、重用类似系统中的现有软件工件（即基于相似性的重用）、大型语言模型用于识别和声明规范，以及使用人工智能指导整个过程。

</details>


### [687] [What Users Value and Critique: Large-Scale Analysis of User Feedback on AI-Powered Mobile Apps](https://arxiv.org/abs/2506.10785)
**中文标题：用户重视与批评的内容：AI驱动的移动应用用户反馈的大规模分析**

*Vinaik Chhetri,Krishna Upadhyay,A. B. Siddique,Umar Farooq*

Main category: cs.SE

TL;DR: This paper presents a large-scale analysis of user feedback on AI-powered mobile apps, identifying key themes in positive and negative reviews through a validated multi-stage pipeline.


<details>
  <summary>Details</summary>
Motivation: To understand how users perceive and critique AI features in mobile apps, given the lack of comprehensive studies despite the rapid proliferation of such features.

Method: A multi-stage analysis pipeline was developed, including review classification, aspect-sentiment extraction, and clustering, validated using a human-labeled benchmark and large language models (LLMs).

Result: Users focus on productivity, reliability, and personalized assistance in positive feedback, while negative feedback highlights technical failures, pricing, and language limitations. The pipeline extracted over one million aspect-sentiment pairs clustered into 33 topics.

Conclusion: The approach provides a detailed and accurate reflection of user experiences with AI-powered apps, revealing both universal and domain-specific sentiments.

摘要: 人工智能（AI）驱动的功能已迅速普及到包括生产力、教育、娱乐和创意在内的多个领域的移动应用中。然而，用户如何感知、评价和批评这些AI功能仍是一个未被充分探索的领域，主要原因是用户反馈的数量过于庞大。本研究首次对AI驱动的移动应用用户反馈进行了全面的大规模分析，利用了一个包含14个类别、292个AI驱动应用和894K条AI相关评论的Google Play数据集。我们开发并验证了一个多阶段分析流程，从人工标注的基准开始，系统地评估了大型语言模型（LLMs）和提示策略。每个阶段（包括评论分类、方面情感提取和聚类）均经过准确性和一致性的验证。我们的流程能够对用户反馈进行可扩展、高精度的分析，提取出超过一百万条方面情感对，并聚类为18个积极和15个消极用户主题。分析显示，用户始终关注一组狭窄的主题：积极评论强调生产力、可靠性和个性化帮助，而负面反馈则突出技术故障（如扫描和识别）、价格问题以及语言支持的局限性。我们的流程能够同时捕捉同一评论中对某一功能的满意和对另一功能的沮丧。这些细粒度、共现的情感往往被传统方法所忽视，这些方法要么孤立地处理积极和消极反馈，要么依赖粗粒度的分析。因此，我们的方法更真实地反映了用户对AI驱动应用的实际体验。基于类别的分析进一步揭示了普遍满意度驱动因素和特定领域的挫败感。

</details>


### [688] [SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks](https://arxiv.org/abs/2506.10954)
**中文标题：SWE-Factory：用于问题解决训练数据和评估基准的自动化工厂**

*Lianghong Guo,Yanlin Wang,Caihua Li,Pengyu Yang,Jiachi Chen,Wei Tao,Yingtian Zou,Duyu Tang,Zibin Zheng*

Main category: cs.SE

TL;DR: SWE-Factory is an automated pipeline for generating GitHub issue resolution training data and evaluation benchmarks, addressing labor-intensive challenges with multi-agent systems, standardized grading, and automated validation.


<details>
  <summary>Details</summary>
Motivation: Traditional methods for creating large-scale GitHub issue resolution datasets are labor-intensive and challenging, especially in setting up environments, grading, and validation. SWE-Factory aims to automate these processes to accelerate dataset collection.

Method: SWE-Factory integrates three automated components: SWE-Builder (a multi-agent system for environment setup), exit-code-based grading, and automated fail2pass validation.

Result: Experiments on 671 issues across four languages show SWE-Factory constructs valid instances efficiently (e.g., $0.045 per instance with GPT-4.1-mini). Grading achieves 100% accuracy, and validation reaches 0.92 precision and 1.00 recall.

Conclusion: SWE-Factory effectively automates dataset creation for GitHub issue resolution, offering high-quality, cost-efficient solutions for training and evaluating LLMs.

摘要: 为GitHub问题解决任务构建大规模数据集对于训练和评估大型语言模型（LLM）的软件工程能力至关重要。然而，传统的基准创建过程极具挑战性且劳动密集，尤其是在设置评估环境、评分测试结果和验证任务实例的阶段。本文提出SWE-Factory，一种旨在解决这些挑战的自动化流水线。我们的流水线整合了三个核心自动化组件：首先，我们引入SWE-Builder，一个多智能体系统，用于自动化评估环境构建，该系统利用四个专用智能体在协作迭代循环中工作，并通过环境内存池提高效率。其次，我们提出了一种基于退出代码的标准化评分方法，无需手动编写自定义解析器。最后，我们利用这些可靠的退出代码信号自动化fail2pass验证过程。在四种编程语言的671个问题上进行的实验表明，我们的流水线能有效构建有效任务实例；例如，使用GPT-4.1-mini时，SWE-Builder以每实例0.045美元的成本构建了269个有效实例，而使用Gemini-2.5-flash时，以最低成本每实例0.024美元实现了可比性能。我们还证明，基于退出代码的评分与人工检查相比达到100%的准确率，自动化fail2pass验证的精确度为0.92，召回率为1.00。我们希望我们的自动化流水线能加速大规模、高质量的GitHub问题解决数据集的收集，用于训练和评估。我们的代码和数据集发布于https://github.com/DeepSoftwareAnalytics/swe-factory。

</details>


### [689] [Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements](https://arxiv.org/abs/2506.10330)
**中文标题：通过静态代码分析增强大型语言模型以实现自动化代码质量改进**

*Seyed Moein Abtahi,Akramul Azim*

Main category: cs.SE

TL;DR: 本研究通过将大型语言模型（如GPT-3.5 Turbo和GPT-4o）与静态代码分析框架结合，实现了代码问题的自动检测与修复，显著提升了代码质量并优化了开发流程。


<details>
  <summary>Details</summary>
Motivation: 当前软件开发中，代码问题的检测和修复通常需要大量时间和资源。本研究旨在通过结合大型语言模型和静态代码分析技术，自动化这一过程，以提高代码质量和开发效率。

Method: 研究采用静态代码分析框架检测代码问题（如漏洞和代码异味），并通过迭代的提示工程和检索增强生成（RAG）技术，利用大型语言模型生成准确的修复建议。此外，开发了“代码比较应用”以纠正模型生成的错误修改。

Result: 实验表明，该方法显著减少了代码问题，验证了结合大型语言模型、静态分析和RAG技术在提升代码质量和优化开发流程方面的有效性。

Conclusion: 结合大型语言模型与静态代码分析能够高效自动化代码质量改进，减少开发时间和资源消耗，为软件开发提供了新的优化方向。

摘要: 本研究探讨了通过将大型语言模型（如OpenAI的GPT-3.5 Turbo和GPT-4o）集成到软件开发工作流中，实现代码问题的自动检测与修复。静态代码分析框架用于检测大规模软件项目中的问题（如漏洞、错误和代码异味），并将每个问题的详细信息提取并组织，以便利用大型语言模型进行自动化修复。通过迭代的提示工程过程，确保生成的修复建议准确且符合项目需求。采用检索增强生成（RAG）技术，提升修复建议的相关性和精确性，使模型能够访问并整合实时外部知识。针对模型可能生成的错误修改（即“幻觉”问题），开发了“代码比较应用”以识别和纠正这些错误。后续的静态代码分析扫描显示，代码问题显著减少，证明了结合大型语言模型、静态分析和RAG技术在提升代码质量、优化开发流程及减少资源消耗方面的有效性。

</details>


### [690] [Formalising Software Requirements using Large Language Models](https://arxiv.org/abs/2506.10704)
**中文标题：使用大型语言模型形式化软件需求**

*Arshad Beg,Diarmuid O'Donoghue,Rosemary Monahan*

Main category: cs.SE

TL;DR: 本文介绍了VERIFAI项目，旨在通过自然语言处理和大型语言模型等技术，解决软件需求的形式化规范和可追溯性问题。


<details>
  <summary>Details</summary>
Motivation: 软件需求的形式化规范和可追溯性在软件开发中具有挑战性，VERIFAI项目旨在通过自动化工具和技术支持解决这些问题。

Method: 项目采用自然语言处理、领域本体描述、相似系统软件构件重用、大型语言模型和人工智能技术，实现需求的自动生成和追溯。

Result: 项目探索了多种技术方法，为软件需求的形式化规范和可追溯性提供了支持。

Conclusion: VERIFAI项目通过整合多种技术，为软件需求的形式化规范和可追溯性提供了创新解决方案。

摘要: 本文简要介绍了我们最近启动的项目VERIFAI：自然语言需求的可追溯性与验证。该项目通过提供对形式化规范的自动生成支持以及从初始软件设计阶段到系统实现和验证的需求可追溯性，解决了形式化规范可追溯性和验证中的挑战。项目中探索的方法包括自然语言处理、使用本体描述软件系统领域、重用类似系统的现有软件构件（即基于相似性的重用）、大型语言模型用于识别和声明规范，以及使用人工智能指导整个过程。

</details>


### [691] [What Users Value and Critique: Large-Scale Analysis of User Feedback on AI-Powered Mobile Apps](https://arxiv.org/abs/2506.10785)
**中文标题：用户的价值与批评：AI驱动的移动应用用户反馈的大规模分析**

*Vinaik Chhetri,Krishna Upadhyay,A. B. Siddique,Umar Farooq*

Main category: cs.SE

TL;DR: 本研究首次大规模分析用户对AI移动应用的反馈，通过多阶段分析流程提取了100多万条情感-主题对，揭示了用户对AI功能的满意与不满主要集中在生产力、可靠性和技术故障等方面。


<details>
  <summary>Details</summary>
Motivation: AI功能在移动应用中广泛普及，但用户对其的感知和评价尚未被系统研究，主要原因是用户反馈数据量庞大且复杂。

Method: 研究使用了一个包含292个AI应用和894K条评论的数据集，开发了多阶段分析流程，包括评论分类、情感-主题提取和聚类，并通过人工标注和大型语言模型验证了流程的准确性。

Result: 分析发现，用户反馈集中在少数主题：正面评价强调生产力、可靠性和个性化帮助，负面反馈则关注技术故障、价格问题和语言支持不足。研究还捕捉了同一评论中同时存在的满意与不满情绪。

Conclusion: 该研究提供了一种高精度、可扩展的用户反馈分析方法，揭示了用户对AI应用的复杂体验，为开发者提供了改进方向。

摘要: 人工智能（AI）功能已在生产力、教育、娱乐和创意等多个领域的移动应用中迅速普及。然而，用户如何感知、评价和批评这些AI功能仍未被充分研究，主要原因是用户反馈数据量庞大。本研究首次对AI驱动的移动应用用户反馈进行了全面的大规模分析，利用了一个包含14个类别、292个AI应用和894K条AI相关评论的精选数据集。我们开发并验证了一个多阶段分析流程，从人工标注基准开始，系统评估了大型语言模型（LLM）和提示策略。每个阶段（包括评论分类、情感-主题提取和聚类）均验证了准确性和一致性。我们的流程实现了对用户反馈的高精度、可扩展分析，提取了超过100万条情感-主题对，聚类为18个正面和15个负面用户主题。分析发现，用户反馈集中在少数主题：正面评价强调生产力、可靠性和个性化帮助，而负面反馈则关注技术故障（如扫描和识别）、价格问题和语言支持不足。我们的流程还能捕捉同一评论中同时存在的满意与不满情绪，这些细粒度的共现情感往往被传统方法忽视。因此，我们的方法更真实地反映了用户对AI应用的体验。基于类别的分析进一步揭示了普遍满意度驱动因素和特定领域的挫败感。

</details>


### [692] [SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks](https://arxiv.org/abs/2506.10954)
**中文标题：SWE-Factory：面向问题解决训练数据与评估基准的自动化工厂**

*Lianghong Guo,Yanlin Wang,Caihua Li,Pengyu Yang,Jiachi Chen,Wei Tao,Yingtian Zou,Duyu Tang,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文提出SWE-Factory，一个自动化流水线，用于高效生成GitHub问题解决任务的训练数据和评估基准，解决了传统方法的高成本和低效率问题。


<details>
  <summary>Details</summary>
Motivation: 构建大规模GitHub问题解决数据集对训练和评估大型语言模型（LLMs）至关重要，但传统方法在环境搭建、结果评分和任务验证等环节成本高且效率低。

Method: SWE-Factory包含三个核心组件：1) SWE-Builder（多智能体系统，自动化构建评估环境）；2) 基于退出码的标准化评分方法；3) 自动化的fail2pass验证流程。

Result: 实验表明，SWE-Factory在671个问题上有效构建任务实例（如GPT-4.1-mini下每个实例成本$0.045），退出码评分准确率100%，fail2pass验证精确度0.92，召回率1.00。

Conclusion: SWE-Factory为大规模、高质量的GitHub问题解决数据集提供了高效自动化解决方案，有望加速相关研究和应用。

摘要: 构建大规模GitHub问题解决任务数据集对于训练和评估大型语言模型（LLMs）的软件工程能力至关重要。然而，传统方法在评估环境搭建、测试结果评分和任务实例验证等环节面临巨大挑战且耗时费力。本文提出SWE-Factory，一种自动化流水线，旨在解决这些问题。该流水线整合了三个核心自动化组件：首先，我们引入SWE-Builder，一个多智能体系统，通过四个专用智能体的协作迭代循环和环境内存池提升效率，实现评估环境的自动化构建；其次，我们提出一种基于退出码的标准化评分方法，无需手动编写自定义解析器；最后，利用可靠的退出码信号实现自动化的fail2pass验证。在四种编程语言的671个问题上的实验表明，该流水线能有效构建有效任务实例（例如，使用GPT-4.1-mini时，SWE-Builder以每个实例$0.045的成本构建269个实例，而Gemini-2.5-flash则以最低成本$0.024实现类似性能）。此外，我们的退出码评分与人工检查相比达到100%准确率，自动fail2pass验证的精确度为0.92，召回率为1.00。我们希望这一自动化流水线能够加速大规模、高质量的GitHub问题解决数据集的收集，为训练和评估提供支持。代码和数据集发布于https://github.com/DeepSoftwareAnalytics/swe-factory。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [693] [Leveraging LLMs for Mission Planning in Precision Agriculture](https://arxiv.org/abs/2506.10093)
**中文标题：利用大型语言模型实现精准农业中的任务规划**

*Marcos Abel Zuzuárregui,Stefano Carpin*

Main category: cs.RO

TL;DR: The paper presents an end-to-end system using LLMs like ChatGPT to enable non-technical users to assign complex data collection tasks to autonomous robots in precision agriculture via natural language, addressing challenges in spatial reasoning and routing.


<details>
  <summary>Details</summary>
Motivation: The motivation is to simplify mission planning for autonomous robots in precision agriculture, as end users often lack technical expertise, making it difficult to adapt robots for diverse tasks.

Method: The method involves leveraging LLMs to translate natural language instructions into mission plans encoded with an IEEE task specification standard, executed via ROS2 nodes that interface with existing ROS libraries.

Result: Results demonstrate the system's ability to handle complex tasks while highlighting LLMs' limitations in spatial reasoning and routing, which the proposed implementation addresses.

Conclusion: The conclusion is that LLMs can effectively bridge the gap between non-technical users and autonomous robots in precision agriculture, though challenges remain in spatial reasoning and routing.

摘要: 机器人和人工智能在精准农业中具有巨大潜力。尽管机器人系统已成功应用于多种任务，但如何使其适应多样化任务仍具挑战性，尤其是终端用户通常缺乏技术专长。本文提出了一种端到端系统，利用大型语言模型（如ChatGPT），使用户能够通过自然语言指令为自主机器人分配复杂的数据收集任务。为提高可重用性，任务计划采用现有的IEEE任务规范标准进行编码，并通过ROS2节点在机器人上执行，这些节点将高层任务描述与现有ROS库连接起来。通过大量实验，我们突出了大型语言模型在此背景下的优势与局限性，特别是在空间推理和解决复杂路径规划问题方面，并展示了所提实现如何克服这些问题。

</details>


### [694] [One For All: LLM-based Heterogeneous Mission Planning in Precision Agriculture](https://arxiv.org/abs/2506.10106)
**中文标题：一体适用：基于大语言模型的精准农业异构任务规划**

*Marcos Abel Zuzuárregui,Mustafa Melih Toslak,Stefano Carpin*

Main category: cs.RO

TL;DR: The paper introduces a natural language robotic mission planner using LLMs to simplify control of heterogeneous robots in precision agriculture, enabling non-technical users to create complex missions without coding.


<details>
  <summary>Details</summary>
Motivation: To address the complexity and steep learning curves of AI tools in precision agriculture, making robotic automation accessible to non-technical users.

Method: Leverages large language models (LLMs) and predefined primitives to translate human language into executable descriptions for diverse robotic platforms.

Result: The system successfully supports complex agricultural missions across different robotic platforms, including manipulation and computer vision tasks.

Conclusion: The work advances accessibility of robotic automation in precision agriculture for non-technical users.

摘要: 人工智能正在改变精准农业，为农民提供了简化日常操作的新工具。尽管这些技术进步承诺提高效率，但它们通常带来额外的复杂性和陡峭的学习曲线，这对非技术用户尤其具有挑战性，因为他们需要在技术采用和现有工作负担之间取得平衡。本文提出了一种自然语言（NL）机器人任务规划器，使非专业人员能够通过通用界面控制异构机器人。通过利用大语言模型（LLM）和预定义原语，我们的架构将人类语言无缝翻译为可由不同机器人平台执行的中间描述。借助该系统，用户无需编写任何代码即可制定复杂的农业任务。在本文中，我们通过涉及机器人操作和计算机视觉任务的新实验扩展了之前为轮式机器人任务规划设计的系统。我们的结果表明，该架构既足够通用以支持多样化的机器人，又足够强大以执行复杂的任务请求。这项工作标志着在使精准农业中的机器人自动化对非技术用户更加可及方面迈出了重要一步。

</details>


### [695] [A Navigation Framework Utilizing Vision-Language Models](https://arxiv.org/abs/2506.10172)
**中文标题：利用视觉语言模型的导航框架**

*Yicheng Duan,Kaiyu tang*

Main category: cs.RO

TL;DR: The paper proposes a modular navigation framework using vision-language models (VLMs) to decouple understanding from action planning, aiming for efficient and adaptable navigation without extensive fine-tuning.


<details>
  <summary>Details</summary>
Motivation: The challenge in Vision-and-Language Navigation (VLN) lies in balancing multimodal understanding with computational efficiency, especially with large VLMs. The paper aims to address this by proposing a modular framework.

Method: The framework integrates a frozen vision-language model (Qwen2.5-VL-7B-Instruct) with lightweight planning logic, using prompt engineering, structured history management, and a two-frame visual input strategy.

Result: Initial evaluation on the Room-to-Room benchmark shows challenges in generalizing to unseen environments but demonstrates the potential for scalable and efficient navigation systems.

Conclusion: The modular approach provides a foundation for future improvements, suggesting enhanced environmental priors and expanded multimodal input integration as promising directions.

摘要: 视觉与语言导航（VLN）在具身AI中提出了一个复杂挑战，要求智能体解释自然语言指令并在视觉丰富的陌生环境中导航。大型视觉语言模型（LVLM）如CLIP和Flamingo的最新进展显著提升了多模态理解能力，但也带来了计算成本和实时部署的新挑战。本项目提出了一种模块化、即插即用的导航框架，将视觉语言理解与动作规划解耦。通过集成冻结的视觉语言模型Qwen2.5-VL-7B-Instruct与轻量级规划逻辑，我们旨在实现灵活、快速且适应性强的导航，而无需大量模型微调。我们的框架利用提示工程、结构化历史管理和双帧视觉输入策略，增强了导航步骤间的决策连续性。我们在VLN-CE设置下使用Matterport3D数据集和Habitat-Lab模拟环境对Room-to-Room基准进行了系统评估。尽管初步结果显示在严格评估设置下对未见环境的泛化能力存在挑战，但我们的模块化方法为可扩展和高效的导航系统奠定了基础，突出了通过增强环境先验和扩展多模态输入整合的未来改进方向。

</details>


### [696] [Using Language and Road Manuals to Inform Map Reconstruction for Autonomous Driving](https://arxiv.org/abs/2506.10317)
**中文标题：利用语言和道路设计手册为自动驾驶地图重建提供信息**

*Akshar Tumu,Henrik I. Christensen,Marcell Vazquez-Chanlatte,Chikao Tsuchiya,Dhaval Bhanderi*

Main category: cs.RO

TL;DR: The paper proposes enhancing lane-topology prediction for autonomous driving by integrating natural language conventions, road design manuals, and structured metadata into the SMERF model, improving detection and association of lanes and traffic elements.


<details>
  <summary>Details</summary>
Motivation: Lane-topology prediction is crucial for autonomous navigation, and existing methods can benefit from incorporating structured road metadata and design conventions encoded in natural language.

Method: The authors augment the SMERF model by combining road metadata from OSM maps, lane-width priors from road design manuals, and road centerline encodings. The method is evaluated on complex intersection scenarios using topology-aware metrics.

Result: The approach shows improved performance in lane and traffic element detection and their association, demonstrating generalization across diverse topologies and conditions.

Conclusion: The integration of language-based conventions and road design manuals enhances the accuracy and scalability of lane-topology prediction for autonomous driving.

摘要: 车道拓扑预测是安全可靠自动驾驶导航的关键组成部分。对道路环境的准确理解有助于这一任务。我们注意到，这些信息通常遵循自然语言编码的惯例，通过反映道路结构的设计规范和捕捉道路功能的道路名称。我们以轻量级的方式将这些信息增强到SMERF（一种基于地图先验的在线车道拓扑预测模型）中，通过结合OSM地图中的结构化道路元数据、道路设计手册中的车道宽度先验以及道路中心线编码。我们在两种地理多样化的复杂交叉口场景中评估了我们的方法。我们的方法在车道和交通元素检测及其关联方面均显示出改进。我们使用四种拓扑感知指标全面评估模型性能。这些结果表明了我们的方法在不同拓扑和条件下的泛化和扩展能力。

</details>


### [697] [EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence](https://arxiv.org/abs/2506.10600)
**中文标题：EmbodiedGen：面向具身智能的生成式3D世界引擎**

*Wang Xinjie,Liu Liu,Cao Yu,Wu Ruiqi,Qin Wenkang,Wang Dehui,Sui Wei,Su Zhizhong*

Main category: cs.RO

TL;DR: EmbodiedGen is a generative 3D world engine designed to create scalable, high-quality, and interactive 3D assets for embodied intelligence tasks, addressing the limitations of traditional manually created assets.


<details>
  <summary>Details</summary>
Motivation: Current embodied intelligence tasks rely on manually created 3D assets, which are costly and lack realism, hindering scalability. EmbodiedGen aims to provide a low-cost, scalable solution for generating diverse and realistic 3D worlds.

Method: EmbodiedGen uses generative AI to create high-quality, controllable 3D assets in URDF format. It includes modules like Image-to-3D, Text-to-3D, and Scene Generation for diverse and interactive world creation.

Result: The platform generates photorealistic 3D assets with accurate physical properties, supporting downstream tasks in training and evaluation of embodied intelligence.

Conclusion: EmbodiedGen offers a scalable and cost-effective solution for 3D world generation, leveraging generative AI to enhance embodied intelligence research.

摘要: 构建物理真实且比例准确的模拟3D世界对于具身智能任务的训练和评估至关重要。3D数据资产的多样性、真实性、低成本可及性和经济性对于实现具身AI的泛化和可扩展性至关重要。然而，目前大多数具身智能任务仍严重依赖传统的手工创建和标注的3D计算机图形资产，这些资产生产成本高且真实性有限。这些限制显著阻碍了数据驱动方法的可扩展性。我们提出了EmbodiedGen，一个用于交互式3D世界生成的基础平台。它能够以低成本规模化生成高质量、可控且逼真的3D资产，这些资产具有准确的物理属性和真实世界比例，并以统一机器人描述格式（URDF）呈现。这些资产可直接导入各种物理模拟引擎进行细粒度物理控制，支持训练和评估中的下游任务。EmbodiedGen是一个易于使用、功能齐全的工具包，由六个关键模块组成：图像到3D、文本到3D、纹理生成、关节对象生成、场景生成和布局生成。EmbodiedGen生成由生成式3D资产组成的多样化和交互式3D世界，利用生成式AI应对具身智能相关研究中的泛化和评估挑战。代码可在https://horizonrobotics.github.io/robot_lab/embodied_gen/index.html获取。

</details>


### [698] [Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop](https://arxiv.org/abs/2506.10968)
**中文标题：《Eye, Robot: 通过BC-RL感知-动作循环学习观察以行动》**

*Justin Kerr,Kush Hari,Ethan Weber,Chung Min Kim,Brent Yi,Tyler Bonnen,Ken Goldberg,Angjoo Kanazawa*

Main category: cs.RO

TL;DR: The paper introduces EyeRobot, a robotic system with gaze behavior trained via a BC-RL loop to achieve hand-eye coordination for task completion.


<details>
  <summary>Details</summary>
Motivation: The motivation is to mimic human active gaze behavior for task completion in robotics, enabling efficient manipulation in large workspaces with a single camera.

Method: The method involves training a gaze policy using reinforcement learning (RL) and a hand policy via behavioral cloning (BC), with data from teleoperated demonstrations and a 360 camera. The BC-RL loop jointly trains hand and eye agents.

Result: EyeRobot demonstrates effective hand-eye coordination, stable fixation, and improved object tracking, successfully completing manipulation tasks in panoramic workspaces.

Conclusion: The conclusion highlights EyeRobot's ability to facilitate manipulation in large workspaces through emergent hand-eye coordination, validated by experiments on five tasks.

摘要: 人类并非被动观察视觉世界，而是通过主动观察来行动。基于这一原则，我们提出了EyeRobot，一种具有从任务需求中自然产生的注视行为的机器人系统。我们开发了一个可以自由旋转观察周围环境的机械眼球，并通过强化学习训练注视策略来控制它。为此，我们首先收集了与360度摄像头配对的远程操作演示数据。这些数据被导入支持渲染任意眼球视点的仿真环境，从而在机器人演示的基础上实现眼球注视的模拟。接着，我们引入BC-RL循环来联合训练手和眼：手（BC）代理通过渲染的眼球观察进行训练，而眼（RL）代理在手产生正确动作预测时获得奖励。通过这种方式，手眼协调能力随着眼睛注视任务完成所需区域而自然产生。EyeRobot采用了一种受中央凹启发的策略架构，以较小的计算预算实现高分辨率，同时我们发现这还能带来更稳定的注视和更强的物体跟踪及干扰忽略能力。我们在五个需要机器人手臂周围弧形区域操作的泛光工作空间任务上评估了EyeRobot。实验结果表明，EyeRobot表现出的手眼协调行为能有效促进单摄像头下大工作空间的操控。更多视频请访问项目网站：https://www.eyerobot.net/

</details>


### [699] [Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding](https://arxiv.org/abs/2506.10756)
**中文标题：基于开放词汇目标理解的无人机视觉语言导航**

*Yuhang Zhang,Haosheng Yu,Jiaping Xiao,Mir Feroskhan*

Main category: cs.RO

TL;DR: The paper introduces VLFly, a framework for UAVs to perform language-guided navigation using continuous velocity commands from monocular camera inputs, integrating LLM and VLM for robust open-vocabulary goal understanding.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome limitations in VLN, such as poor generalization to new environments and reliance on fixed action spaces, by developing a UAV-specific solution that operates without localization sensors.

Method: VLFly uses an LLM-based instruction encoder, a VLM-powered goal retriever, and a waypoint planner to generate trajectories from egocentric observations, enabling real-time UAV control.

Result: VLFly outperforms baselines in diverse simulations and real-world tasks, demonstrating robust open-vocabulary goal understanding and generalized navigation even with abstract language.

Conclusion: VLFly successfully addresses VLN challenges for UAVs, offering a scalable and sensor-efficient solution for language-guided navigation.

摘要: 视觉与语言导航（VLN）是自主机器人领域的一项长期挑战，旨在使智能体能够在复杂环境中遵循人类指令进行导航。该领域仍存在两个关键瓶颈：对分布外环境的泛化能力不足以及对固定离散动作空间的依赖。为解决这些问题，我们提出了视觉语言飞行（VLFly），这是一个专为无人机（UAV）设计的框架，用于执行语言引导的飞行任务。VLFly无需定位或主动测距传感器，仅通过机载单目摄像头捕获的自我中心观察输出连续速度指令。VLFly集成了三个模块：基于大型语言模型（LLM）的指令编码器，将高级语言重新表述为结构化提示；由视觉语言模型（VLM）驱动的目标检索器，通过视觉语言相似性将这些提示与目标图像匹配；以及路径点规划器，生成可执行轨迹以实现实时无人机控制。VLFly在多种模拟环境中进行评估，无需额外微调，始终优于所有基线方法。此外，在室内和室外环境中进行的直接和间接指令下的真实世界VLN任务表明，VLFly实现了稳健的开放词汇目标理解和泛化导航能力，即使面对抽象语言输入也能胜任。

</details>


### [700] [Data-Driven Prediction of Dynamic Interactions Between Robot Appendage and Granular Material](https://arxiv.org/abs/2506.10875)
**中文标题：基于数据驱动的机器人附肢与颗粒材料动态交互预测**

*Guanjin Wang,Xiangxue Zhao,Shapour Azarm,Balakumar Balachandran*

Main category: cs.RO

TL;DR: A data-driven approach combining dimension reduction, surrogate modeling, and data assimilation significantly reduces computational time while maintaining accuracy in predicting robot-granular terrain interactions, aiding robot navigation in complex terrains.


<details>
  <summary>Details</summary>
Motivation: To improve robot navigation in granular terrains by developing a computationally efficient and accurate data-driven model that integrates offline simulation and sparse experimental data.

Method: The approach integrates dimension reduction (Sequentially Truncated Higher-Order Singular Value Decomposition), surrogate modeling (Gaussian Process), and data assimilation (Reduced Order Particle Filter) to predict interactions.

Result: The method achieves orders of magnitude reduction in computational time with comparable accuracy to high-fidelity simulations and outperforms simulations in long-horizon predictions when combined with experimental data.

Conclusion: The data-driven approach is effective for predicting robot-granular terrain interactions, offering computational efficiency and accuracy, and holds potential for broader applications beyond specific cases.

摘要: 提出并采用了一种替代的数据驱动建模方法，以获取机器人运动与颗粒地形在特定长度尺度上交互的基本见解。该方法基于维度缩减（顺序截断高阶奇异值分解）、替代建模（高斯过程）和数据同化技术（降阶粒子滤波）的集成。该方法可在线使用，并基于离线数据，包括高保真仿真数据和稀疏实验数据的离线收集。结果表明，与基于物理的高保真仿真相比，所提出的数据驱动建模方法可以显著减少计算时间。仅以仿真数据为输入时，数据驱动预测技术生成的预测结果与仿真结果具有相当的准确性。当同时输入仿真数据和稀疏物理实验测量数据时，嵌入数据同化技术的数据驱动方法在长期预测方面可能优于仅依赖高保真仿真。此外，数据驱动建模方法还能重现基于物理仿真恢复的最大阻力缩放关系，表明其具有超越个案的一般预测能力。这些结果有望帮助机器人在未知和复杂地形中的导航与探索，无论是在线还是离线阶段。

</details>


### [701] [Leveraging LLMs for Mission Planning in Precision Agriculture](https://arxiv.org/abs/2506.10093)
**中文标题：利用大型语言模型实现精准农业中的任务规划**

*Marcos Abel Zuzuárregui,Stefano Carpin*

Main category: cs.RO

TL;DR: 本文提出了一种利用大型语言模型（LLMs）如ChatGPT的端到端系统，使非技术用户能够通过自然语言指令为自主机器人分配复杂的数据收集任务。任务计划通过IEEE任务规范标准编码，并通过ROS2节点执行。实验展示了LLMs在空间推理和复杂路径规划中的优势与局限性，并提出了解决方案。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人和人工智能在精准农业中潜力巨大，但非技术用户难以适应多样化的任务分配。本文旨在通过自然语言指令简化复杂任务的分配，提升系统的易用性和可重用性。

Method: 开发了一个端到端系统，利用ChatGPT将自然语言指令转化为任务计划，并通过IEEE任务规范标准编码。任务计划通过ROS2节点与现有ROS库对接，实现机器人执行。

Result: 实验表明，LLMs在空间推理和复杂路径规划方面存在局限性，但通过提出的系统能够有效克服这些问题，实现高效的任务分配和执行。

Conclusion: 本文展示了LLMs在精准农业任务规划中的潜力，同时提出了解决其局限性的方法，为非技术用户提供了便捷的任务分配途径。

摘要: 机器人和人工智能在精准农业中具有巨大潜力。尽管机器人系统已成功应用于多种任务，但适应多样化任务仍具挑战性，尤其是终端用户通常缺乏技术专长。本文提出了一种端到端系统，利用大型语言模型（如ChatGPT），使用户能够通过自然语言指令为自主机器人分配复杂的数据收集任务。为提高可重用性，任务计划采用现有的IEEE任务规范标准编码，并通过ROS2节点执行，将高级任务描述与现有ROS库对接。通过大量实验，我们展示了LLMs在此背景下的优势与局限性，特别是在空间推理和解决复杂路径规划问题方面，并说明了所提实现如何克服这些问题。

</details>


### [702] [One For All: LLM-based Heterogeneous Mission Planning in Precision Agriculture](https://arxiv.org/abs/2506.10106)
**中文标题：一统天下：基于LLM的精准农业异构任务规划**

*Marcos Abel Zuzuárregui,Mustafa Melih Toslak,Stefano Carpin*

Main category: cs.RO

TL;DR: 本文提出了一种基于大型语言模型（LLM）的自然语言机器人任务规划系统，使非技术用户能够通过简单语言控制异构机器人，应用于精准农业中的复杂任务。


<details>
  <summary>Details</summary>
Motivation: 精准农业中的人工智能技术虽然提高了效率，但增加了复杂性，对非技术用户不友好。本文旨在通过自然语言界面简化异构机器人的控制，降低技术门槛。

Method: 利用大型语言模型（LLMs）和预定义的基本操作，将人类语言翻译为中间描述，供不同机器人平台执行。系统扩展了之前的轮式机器人任务规划功能，新增了机器人操作和计算机视觉任务实验。

Result: 实验表明，该系统支持多种机器人，并能执行复杂的任务请求，验证了其通用性和强大功能。

Conclusion: 该研究为精准农业中的机器人自动化提供了更易用的解决方案，为非技术用户提供了便利。

摘要: 人工智能正在改变精准农业，为农民提供了简化日常操作的新工具。尽管这些技术进步提高了效率，但也带来了额外的复杂性和陡峭的学习曲线，对非技术用户尤为挑战，他们需要在技术采用和现有工作负荷之间取得平衡。本文提出了一种自然语言（NL）机器人任务规划器，使非专业人员能够通过统一界面控制异构机器人。通过利用大型语言模型（LLMs）和预定义的基本操作，我们的架构将人类语言无缝翻译为可由不同机器人平台执行的中间描述。借助该系统，用户可以无需编写任何代码即可制定复杂的农业任务。在本文中，我们通过涉及机器人操作和计算机视觉任务的新实验扩展了之前为轮式机器人任务规划设计的系统。结果表明，该架构既足够通用以支持多样化的机器人，又足够强大以执行复杂的任务请求。这项研究为精准农业中的机器人自动化向非技术用户普及迈出了重要一步。

</details>


### [703] [A Navigation Framework Utilizing Vision-Language Models](https://arxiv.org/abs/2506.10172)
**中文标题：利用视觉-语言模型的导航框架**

*Yicheng Duan,Kaiyu tang*

Main category: cs.RO

TL;DR: 本文提出了一种模块化的导航框架，通过解耦视觉-语言理解和动作规划，结合轻量级规划逻辑和冻结的视觉-语言模型，实现了快速、灵活的导航。


<details>
  <summary>Details</summary>
Motivation: 视觉与语言导航（VLN）在嵌入式AI中是一个复杂挑战，需要代理在视觉丰富的陌生环境中理解自然语言指令并导航。尽管大型视觉-语言模型（LVLMs）提升了多模态理解能力，但也带来了计算成本和实时部署的新挑战。

Method: 提出了一种模块化的导航框架，将视觉-语言理解与动作规划解耦。通过集成冻结的视觉-语言模型Qwen2.5-VL-7B-Instruct和轻量级规划逻辑，结合提示工程、结构化历史管理和双帧视觉输入策略，提升导航决策的连续性。

Result: 在VLN-CE设置的Room-to-Room基准测试中，使用Matterport3D数据集和Habitat-Lab模拟环境进行评估。结果显示，在严格评估环境下对未见环境的泛化能力存在挑战，但模块化方法为可扩展和高效的导航系统奠定了基础。

Conclusion: 模块化方法为未来通过增强环境先验和扩展多模态输入集成提供了改进方向，展示了构建高效导航系统的潜力。

摘要: 视觉与语言导航（VLN）是嵌入式AI中的一个复杂挑战，要求代理在视觉丰富的陌生环境中理解自然语言指令并导航。尽管大型视觉-语言模型（LVLMs）如CLIP和Flamingo显著提升了多模态理解能力，但也带来了计算成本和实时部署的新挑战。本项目提出了一种模块化的即插即用导航框架，将视觉-语言理解与动作规划解耦。通过集成冻结的视觉-语言模型Qwen2.5-VL-7B-Instruct和轻量级规划逻辑，旨在实现无需大量模型微调的灵活、快速和适应性强的导航。我们的框架利用提示工程、结构化历史管理和双帧视觉输入策略，增强了导航步骤中的决策连续性。我们在VLN-CE设置的Room-to-Room基准测试中使用Matterport3D数据集和Habitat-Lab模拟环境评估了系统。尽管初步结果显示在严格评估环境下对未见环境的泛化能力存在挑战，但模块化方法为可扩展和高效的导航系统奠定了基础，并指出了通过增强环境先验和扩展多模态输入集成的未来改进方向。

</details>


### [704] [Using Language and Road Manuals to Inform Map Reconstruction for Autonomous Driving](https://arxiv.org/abs/2506.10317)
**中文标题：利用语言和道路手册信息改进自动驾驶地图重建**

*Akshar Tumu,Henrik I. Christensen,Marcell Vazquez-Chanlatte,Chikao Tsuchiya,Dhaval Bhanderi*

Main category: cs.RO

TL;DR: 该论文提出了一种利用语言和道路手册信息改进自动驾驶地图重建的方法，通过结合OSM地图的结构化道路元数据和道路设计手册的车道宽度先验，提升了车道和交通元素的检测与关联性能。


<details>
  <summary>Details</summary>
Motivation: 车道拓扑预测是自动驾驶安全可靠导航的关键组成部分。论文观察到道路环境信息通常遵循自然语言编码的惯例，如反映道路结构的设计规范和捕捉道路功能的路名，因此希望通过结合这些信息来提升预测模型的性能。

Method: 论文在SMERF模型的基础上，轻量级地结合了OSM地图的结构化道路元数据和道路设计手册的车道宽度先验，与道路中心线编码相结合，以改进车道拓扑预测。

Result: 在两种地理多样化的复杂交叉路口场景中，该方法在车道和交通元素检测及其关联方面均表现出改进。通过四种拓扑感知指标全面评估模型性能，结果表明该方法能够泛化并适应多样化的拓扑和条件。

Conclusion: 通过结合语言和道路手册信息，论文提出的方法显著提升了车道拓扑预测的准确性和泛化能力，为自动驾驶导航提供了更可靠的解决方案。

摘要: 车道拓扑预测是安全可靠自动驾驶导航的关键组成部分。准确理解道路环境有助于完成这一任务。我们注意到，这些信息通常遵循自然语言编码的惯例，例如反映道路结构的设计规范和捕捉道路功能的路名。我们以轻量级方式将这些信息结合到SMERF模型中（一种基于地图先验的在线车道拓扑预测模型），通过将OSM地图的结构化道路元数据与道路设计手册的车道宽度先验结合到道路中心线编码中。我们在两种地理多样化的复杂交叉路口场景中评估了我们的方法。结果显示，该方法在车道和交通元素检测及其关联方面均有所改进。我们使用四种拓扑感知指标全面评估模型性能，结果表明我们的方法能够泛化并适应多样化的拓扑和条件。

</details>


### [705] [EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence](https://arxiv.org/abs/2506.10600)
**中文标题：EmbodiedGen：面向具身智能的生成式3D世界引擎**

*Wang Xinjie,Liu Liu,Cao Yu,Wu Ruiqi,Qin Wenkang,Wang Dehui,Sui Wei,Su Zhizhong*

Main category: cs.RO

TL;DR: EmbodiedGen是一个生成式3D世界引擎，旨在为具身智能任务提供高质量、可控且低成本的3D资产生成平台，支持多样化和交互式的3D世界构建。


<details>
  <summary>Details</summary>
Motivation: 当前具身智能任务依赖传统手工制作的3D资产，成本高且真实性有限，阻碍了数据驱动方法的扩展性。EmbodiedGen旨在通过生成式AI解决这些问题。

Method: EmbodiedGen是一个多功能工具包，包含六个关键模块：图像到3D、文本到3D、纹理生成、关节对象生成、场景生成和布局生成，利用生成式AI生成高质量3D资产。

Result: EmbodiedGen能够低成本生成具有精确物理属性和真实世界比例的3D资产，支持直接导入物理仿真引擎，为下游任务提供支持。

Conclusion: EmbodiedGen通过生成式AI解决了3D资产多样性和真实性的挑战，为具身智能研究提供了可扩展的工具。

摘要: 构建物理真实且比例准确的模拟3D世界对于具身智能任务的训练和评估至关重要。3D数据资产的多样性、真实性、低成本可获取性和可负担性对于实现具身AI的泛化和扩展性至关重要。然而，当前大多数具身智能任务仍严重依赖传统手工创建和标注的3D计算机图形资产，这些资产生产成本高且真实性有限，显著阻碍了数据驱动方法的扩展性。我们提出了EmbodiedGen，一个用于交互式3D世界生成的基础平台。它能够以低成本生成高质量、可控且逼真的3D资产，这些资产具有精确的物理属性和真实世界比例，并以统一机器人描述格式（URDF）呈现。这些资产可直接导入各种物理仿真引擎，支持细粒度的物理控制，为训练和评估的下游任务提供支持。EmbodiedGen是一个易于使用的全功能工具包，由六个关键模块组成：图像到3D、文本到3D、纹理生成、关节对象生成、场景生成和布局生成。EmbodiedGen利用生成式AI生成由生成式3D资产组成的多样化和交互式3D世界，以解决具身智能相关研究在泛化和评估方面的挑战。代码可在https://horizonrobotics.github.io/robot_lab/embodied_gen/index.html获取。

</details>


### [706] [Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop](https://arxiv.org/abs/2506.10968)
**中文标题：Eye, Robot：通过BC-RL感知-行动循环学习观察以行动**

*Justin Kerr,Kush Hari,Ethan Weber,Chung Min Kim,Brent Yi,Tyler Bonnen,Ken Goldberg,Angjoo Kanazawa*

Main category: cs.RO

TL;DR: 本文提出了一种名为EyeRobot的机器人系统，通过结合行为克隆（BC）和强化学习（RL）训练机器人的眼球运动策略，使其能够主动观察环境以完成任务。实验表明，该系统在大型工作空间中表现出有效的手眼协调能力。


<details>
  <summary>Details</summary>
Motivation: 人类的视觉行为是主动的，通过观察来指导行动。受此启发，本文旨在开发一种机器人系统，其眼球运动策略能够从任务需求中自然涌现，从而实现高效的手眼协调。

Method: 1. 设计了一个可自由旋转的机械眼球；2. 通过360度摄像头收集遥操作演示数据；3. 在仿真环境中训练眼球运动策略（RL）和手部动作策略（BC），形成BC-RL循环；4. 采用类似中央凹的架构，实现高分辨率观察。

Result: 在五个全景工作空间操作任务中，EyeRobot表现出稳定的注视行为、目标跟踪能力和对干扰物的忽略能力，有效支持了大型工作空间中的操作任务。

Conclusion: EyeRobot通过BC-RL循环实现了自然的手眼协调，证明了主动观察策略在机器人任务中的重要性。

摘要: 人类并非被动观察视觉世界，而是通过主动观察来指导行动。基于这一原则，我们提出了EyeRobot，一种具有自然涌现的注视行为的机器人系统。我们设计了一个可以自由旋转的机械眼球，并通过强化学习训练其注视策略。具体实现包括：首先收集遥操作演示数据并搭配360度摄像头；将这些数据导入支持任意眼球视角渲染的仿真环境；随后引入BC-RL循环联合训练手部和眼球：手部（BC）代理通过渲染的眼球观察进行训练，而眼球（RL）代理在手部产生正确动作预测时获得奖励。通过这种方式，手眼协调能力自然涌现，眼球会注视那些有助于手部完成任务的区域。EyeRobot采用了一种受中央凹启发的策略架构，以较小的计算成本实现高分辨率观察，同时还能产生更稳定的注视行为，并提升目标跟踪和忽略干扰物的能力。我们在五个全景工作空间操作任务中评估了EyeRobot，这些任务要求机器人在手臂周围的大范围空间内进行操作。实验结果表明，EyeRobot表现出有效的手眼协调行为，能够通过单一摄像头在大工作空间中高效完成操作任务。更多视频请访问项目网站：https://www.eyerobot.net/

</details>


### [707] [Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding](https://arxiv.org/abs/2506.10756)
**中文标题：基于开放词汇目标理解的无人机视觉语言导航框架**

*Yuhang Zhang,Haosheng Yu,Jiaping Xiao,Mir Feroskhan*

Main category: cs.RO

TL;DR: 本文提出了一种名为VLFly的框架，专为无人机设计，通过语言指令实现导航。该框架结合大型语言模型和视觉语言模型，无需依赖定位或测距传感器，仅通过单目摄像头实现连续速度控制。实验表明，VLFly在多样化的仿真和真实环境中表现优异，具备开放词汇目标理解和泛化导航能力。


<details>
  <summary>Details</summary>
Motivation: 视觉与语言导航（VLN）是自主机器人领域的一项长期挑战，现有方法在泛化到分布外环境和依赖固定离散动作空间方面存在瓶颈。本文旨在解决这些问题，为无人机设计一种无需额外传感器的语言引导飞行框架。

Method: VLFly框架包含三个模块：基于大型语言模型（LLM）的指令编码器，将高级语言指令转化为结构化提示；基于视觉语言模型（VLM）的目标检索器，通过视觉语言相似性匹配提示与目标图像；以及路径点规划器，生成可执行的轨迹以实现实时无人机控制。

Result: VLFly在多样化仿真环境中无需额外微调即优于所有基线方法。在真实世界的室内外环境中，无论是直接还是间接指令，VLFly均表现出强大的开放词汇目标理解和泛化导航能力。

Conclusion: VLFly通过结合语言和视觉模型，实现了无人机在复杂环境中的语言引导导航，解决了现有方法的泛化和动作空间限制问题，为自主机器人导航提供了新思路。

摘要: 视觉与语言导航（VLN）是自主机器人领域的一项长期挑战，旨在使智能体能够在复杂环境中遵循人类指令进行导航。该领域的两大瓶颈是：对分布外环境的泛化能力不足，以及对固定离散动作空间的依赖。为解决这些问题，我们提出了Vision-Language Fly（VLFly），一种专为无人机设计的语言引导飞行框架。VLFly无需依赖定位或主动测距传感器，仅通过机载单目摄像头捕获的自我中心视角图像输出连续速度指令。VLFly整合了三个模块：基于大型语言模型（LLM）的指令编码器，将高级语言指令转化为结构化提示；基于视觉语言模型（VLM）的目标检索器，通过视觉语言相似性匹配提示与目标图像；以及路径点规划器，生成可执行的轨迹以实现实时无人机控制。VLFly在多样化仿真环境中无需额外微调即优于所有基线方法。此外，在室内外真实环境中的直接和间接指令测试表明，VLFly具备强大的开放词汇目标理解和泛化导航能力，即使面对抽象语言输入也能稳健执行。

</details>


### [708] [Data-Driven Prediction of Dynamic Interactions Between Robot Appendage and Granular Material](https://arxiv.org/abs/2506.10875)
**中文标题：数据驱动的机器人肢体与颗粒材料动态交互预测**

*Guanjin Wang,Xiangxue Zhao,Shapour Azarm,Balakumar Balachandran*

Main category: cs.RO

TL;DR: 本文提出了一种数据驱动的建模方法，用于预测机器人肢体与颗粒材料之间的动态交互作用。该方法结合降维、代理建模和数据同化技术，显著减少了计算时间，并在预测精度上与高保真仿真相当。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决机器人在复杂颗粒地形中导航和探索时的动态交互问题，传统物理仿真计算成本高，难以在线应用。

Method: 方法包括降维（Sequentially Truncated Higher-Order Singular Value Decomposition）、代理建模（Gaussian Process）和数据同化技术（Reduced Order Particle Filter），结合离线高保真仿真数据和稀疏实验数据。

Result: 结果显示，该方法计算时间显著减少，预测精度与仿真相当；结合实验数据后，长期预测能力优于单纯的高保真仿真。

Conclusion: 结论表明，该数据驱动方法不仅高效，还能复现物理仿真中的缩放关系，有望提升机器人在未知复杂地形中的导航能力。

摘要: 本文提出并采用了一种替代的数据驱动建模方法，以深入理解机器人与颗粒地形在特定长度尺度上的运动交互。该方法基于降维（Sequentially Truncated Higher-Order Singular Value Decomposition）、代理建模（Gaussian Process）和数据同化技术（Reduced Order Particle Filter）的集成。该方法可在线使用，并基于离线数据，包括高保真仿真数据和稀疏实验数据。结果显示，与基于物理的高保真仿真相比，所提出的数据驱动建模方法可显著减少计算时间。仅以仿真数据为输入时，数据驱动预测技术的预测精度与仿真相当。结合仿真数据和稀疏物理实验测量数据时，嵌入数据同化技术的数据驱动方法在长期预测方面可能优于单纯的高保真仿真。此外，数据驱动建模方法还能复现物理仿真中最大阻力的缩放关系，表明其具有超越个案的一般预测能力。这些结果有望帮助机器人在在线和离线阶段在未知复杂地形中的导航和探索。

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [709] [From Tool Calling to Symbolic Thinking: LLMs in a Persistent Lisp Metaprogramming Loop](https://arxiv.org/abs/2506.10021)
**中文标题：从工具调用到符号思维：LLMs在持久Lisp元编程循环中的应用**

*Jordi de la Torre*

Main category: cs.PL

TL;DR: The paper introduces a novel architecture combining LLMs with a persistent Lisp environment, enabling dynamic tool creation and reflective programming through a live REPL.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between neural language generation and symbolic programming by allowing LLMs to interactively define and evolve tools in a stateful environment.

Method: Proposes embedding Lisp expressions within LLM generation, intercepted via middleware, to facilitate dynamic tool creation and reflective programming in a live REPL.

Result: A design framework and architectural principles for integrating symbolic programming with neural language generation in interactive AI systems.

Conclusion: The proposed architecture successfully merges symbolic and neural approaches, paving the way for more interactive and adaptable AI systems.

摘要: 我们提出了一种新颖的架构，将大型语言模型（LLMs）与一个持久的、交互式的Lisp环境相结合。这种设置使LLMs能够通过与实时REPL的程序化交互来定义、调用和演化其自身工具。通过在生成中嵌入Lisp表达式并通过中间件层拦截它们，该系统实现了有状态的外部内存、反射式编程和动态工具创建。我们提出了一个设计框架和架构原则，以指导未来将符号编程与神经语言生成相结合的交互式AI系统的实现。

</details>


### [710] [From Tool Calling to Symbolic Thinking: LLMs in a Persistent Lisp Metaprogramming Loop](https://arxiv.org/abs/2506.10021)
**中文标题：从工具调用到符号思维：LLMs在持久Lisp元编程循环中的应用**

*Jordi de la Torre*

Main category: cs.PL

TL;DR: 本文提出了一种将大型语言模型（LLMs）与持久的交互式Lisp环境集成的新架构，支持LLMs通过程序化交互定义、调用和演化工具，实现状态化外部存储和动态工具创建。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何将神经语言生成与符号编程结合，以增强LLMs的工具调用和符号思维能力，从而构建更强大的交互式AI系统。

Method: 通过将Lisp表达式嵌入生成过程，并通过中间件层拦截，设计了一个持久的Lisp环境，支持状态化外部存储、反射编程和动态工具创建。

Result: 提出了一种设计框架和架构原则，为未来结合符号编程与神经语言生成的交互式AI系统提供了实现指导。

Conclusion: 该架构为LLMs在符号思维和工具调用方面的能力提升提供了新方向，展示了交互式AI系统的潜力。

摘要: 我们提出了一种将大型语言模型（LLMs）与持久的交互式Lisp环境集成的新架构。该架构使LLMs能够通过与实时REPL的程序化交互来定义、调用和演化其工具。通过将Lisp表达式嵌入生成过程并通过中间件层拦截，该系统支持状态化外部存储、反射编程和动态工具创建。我们提出了一种设计框架和架构原则，以指导未来结合符号编程与神经语言生成的交互式AI系统的实现。

</details>


### [711] [From Tool Calling to Symbolic Thinking: LLMs in a Persistent Lisp Metaprogramming Loop](https://arxiv.org/abs/2506.10021)
**中文标题：从工具调用到符号思维：LLMs在持久化Lisp元编程循环中的应用**

*Jordi de la Torre*

Main category: cs.PL

TL;DR: 本文提出了一种将大型语言模型（LLMs）与持久的交互式Lisp环境集成的新架构，支持LLMs通过程序化交互定义、调用和演化工具。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索如何将神经语言生成与符号编程结合，以实现更动态、交互式的AI系统。

Method: 通过将Lisp表达式嵌入生成过程，并利用中间件拦截这些表达式，系统实现了状态化外部内存、反射式编程和动态工具创建。

Result: 提出了一个设计框架和架构原则，为未来结合符号编程与神经语言生成的交互式AI系统提供指导。

Conclusion: 该架构为LLMs在持久化、交互式环境中的应用开辟了新途径，展示了符号思维与工具调用的潜力。

摘要: 我们提出了一种将大型语言模型（LLMs）与持久的交互式Lisp环境集成的新架构。这种设置使LLMs能够通过与实时REPL的程序化交互来定义、调用和演化其自身工具。通过将Lisp表达式嵌入生成过程，并通过中间件层拦截这些表达式，系统实现了状态化外部内存、反射式编程和动态工具创建。我们提出了一个设计框架和架构原则，以指导未来结合符号编程与神经语言生成的交互式AI系统的实现。

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [712] [Equitable Mechanism Design for Facility Location](https://arxiv.org/abs/2506.10460)
**中文标题：设施选址的公平机制设计**

*Toby Walsh*

Main category: cs.GT

TL;DR: The paper explores strategy-proof mechanisms for equitable facility location, focusing on the Gini index and Nash welfare, but proves an impossibility result for bounding the approximation ratio of the optimal Gini index.


<details>
  <summary>Details</summary>
Motivation: To design equitable facility location mechanisms that ensure fairness among agents, measured by the Gini index and Nash welfare, while addressing the limitations of strategy-proof mechanisms.

Method: The study first proves an impossibility result for bounding the Gini index approximation ratio, then proposes analyzing the complemented Gini index and Nash welfare through deterministic and randomized mechanisms.

Result: No strategy-proof mechanism can bound the approximation ratio of the optimal Gini index, but the complemented Gini index and Nash welfare offer viable alternatives for equitable outcomes.

Conclusion: While direct bounding of the Gini index is impossible, focusing on the complemented Gini index and Nash welfare provides practical avenues for equitable facility location design.

摘要: 我们研究了用于设施选址的策略证明机制，旨在最大化代理人之间的公平性。与文献中常见的做法一致，我们使用基尼指数来衡量公平性。首先，我们证明了一个简单但基本的不可能性结果：没有任何策略证明机制能够为一处或多处设施的最优基尼效用指数限定近似比率。因此，我们转而提出计算效用补基尼指数的近似比率，并探讨确定性和随机性机制在此方面的表现。此外，由于纳什福利常被视为平等主义和功利主义结果的折中方案，我们还研究了机制对纳什福利的近似效果。

</details>


### [713] [Equitable Mechanism Design for Facility Location](https://arxiv.org/abs/2506.10460)
**中文标题：设施选址的公平机制设计**

*Toby Walsh*

Main category: cs.GT

TL;DR: 本文研究了设施选址的策略证明机制，旨在最大化代理之间的公平性。通过Gini指数衡量公平性，证明了策略证明机制无法限制最优Gini指数的近似比，并提出使用补充Gini指数作为替代。同时探讨了确定性及随机机制对Nash福利的近似效果。


<details>
  <summary>Details</summary>
Motivation: 研究如何在设施选址问题中设计策略证明机制以实现代理之间的公平性，并探索Gini指数和Nash福利作为公平性衡量标准的适用性。

Method: 通过理论分析证明策略证明机制在限制最优Gini指数近似比方面的不可能性，转而提出使用补充Gini指数，并评估确定性及随机机制对其的近似效果。同时考察机制对Nash福利的近似能力。

Result: 证明了策略证明机制无法限制最优Gini指数的近似比，但补充Gini指数可以作为替代。确定性及随机机制在近似补充Gini指数和Nash福利方面表现出不同效果。

Conclusion: 策略证明机制在设施选址问题中无法直接优化Gini指数，但补充Gini指数和Nash福利提供了可行的替代方案。确定性及随机机制在不同场景下各有优劣。

摘要: 我们研究了设施选址的策略证明机制，旨在最大化代理之间的公平性。与文献中常见的方法一致，我们使用Gini指数衡量公平性。首先，我们证明了一个简单但基本的不可能性结果：对于一种或多种设施，任何策略证明机制都无法限制最优Gini指数的近似比。因此，我们转而提出计算补充Gini指数的近似比，并评估确定性及随机机制对其的近似效果。此外，由于Nash福利常被视为平等主义和功利主义结果的折中方案，我们还探讨了机制对Nash福利的近似能力。

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [714] [A multi-scale loss formulation for learning a probabilistic model with proper score optimisation](https://arxiv.org/abs/2506.10868)
**中文标题：用于学习概率模型的多尺度损失公式与适当评分优化**

*Simon Lang,Martin Leutbecher,Pedro Maciel*

Main category: physics.ao-ph

TL;DR: The paper evaluates a multi-scale loss formulation for training probabilistic weather forecasting models, showing improved small-scale variability without compromising forecast skill.


<details>
  <summary>Details</summary>
Motivation: To enhance probabilistic weather forecasting models by better capturing small-scale variability through a multi-scale loss formulation.

Method: Tested the multi-scale loss in AIFS-CRPS, a model trained by optimizing the almost fair continuous ranked probability score (afCRPS).

Result: The multi-scale loss improved small-scale variability without negatively affecting forecast skill.

Conclusion: The findings suggest promising directions for scale-aware training in probabilistic weather forecasting models.

摘要: 我们评估了多尺度损失公式对训练概率机器学习天气预报模型的影响。多尺度损失在欧洲中期天气预报中心（ECMWF）开发的机器学习天气预报模型AIFS-CRPS中进行了测试。AIFS-CRPS通过直接优化几乎公平连续排名概率评分（afCRPS）进行训练。多尺度损失更好地约束了小尺度变异性，同时未对预报技能产生负面影响。这为未来在尺度感知模型训练中的工作开辟了有前景的方向。

</details>


### [715] [A multi-scale loss formulation for learning a probabilistic model with proper score optimisation](https://arxiv.org/abs/2506.10868)
**中文标题：用于学习概率模型的多尺度损失公式与适当评分优化**

*Simon Lang,Martin Leutbecher,Pedro Maciel*

Main category: physics.ao-ph

TL;DR: 本文评估了多尺度损失公式对训练概率机器学习天气预报模型的影响，结果表明该方法能有效约束小尺度变异性且不影响预报技能。


<details>
  <summary>Details</summary>
Motivation: 研究多尺度损失公式在训练概率天气预报模型中的作用，以改善模型对小尺度变异性的约束能力。

Method: 在AIFS-CRPS模型中测试多尺度损失公式，该模型通过直接优化几乎公平连续排名概率得分（afCRPS）进行训练。

Result: 多尺度损失能更好地约束小尺度变异性，同时不影响预报技能。

Conclusion: 多尺度损失为未来尺度感知模型训练提供了有前景的研究方向。

摘要: 我们评估了多尺度损失公式对训练概率机器学习天气预报模型的影响。多尺度损失在欧洲中期天气预报中心（ECMWF）开发的AIFS-CRPS模型中进行测试，该模型通过直接优化几乎公平连续排名概率得分（afCRPS）进行训练。多尺度损失能更好地约束小尺度变异性，同时不影响预报技能。这为未来尺度感知模型训练开辟了有前景的研究方向。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [716] [DUN-SRE: Deep Unrolling Network with Spatiotemporal Rotation Equivariance for Dynamic MRI Reconstruction](https://arxiv.org/abs/2506.10309)
**中文标题：DUN-SRE：具有时空旋转等变性的深度展开网络用于动态MRI重建**

*Yuliang Zhu,Jing Cheng,Qi Xie,Zhuo-Xu Cui,Qingyong Zhu,Yuanyuan Liu,Xin Liu,Jianfeng Ren,Chengbo Wang,Dong Liang*

Main category: eess.IV

TL;DR: The paper introduces DUN-SRE, a deep unrolling network with spatiotemporal rotation equivariance, to improve dynamic MRI reconstruction by modeling both spatial and temporal symmetry priors, achieving state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: Dynamic MRI exhibits spatial and temporal symmetries, but existing methods fail to fully exploit these priors, especially temporal symmetry, limiting reconstruction quality.

Method: DUN-SRE integrates (2+1)D equivariant convolutions into a deep unrolling framework, combining data consistency and proximal mapping to enforce spatiotemporal symmetry constraints.

Result: Experiments show DUN-SRE outperforms existing methods, particularly in preserving rotation-symmetric structures and generalizing to dynamic MRI tasks.

Conclusion: DUN-SRE effectively models spatiotemporal symmetries, enhancing dynamic MRI reconstruction accuracy and generalization.

摘要: 动态磁共振成像（MRI）表现出变换对称性，包括单个帧内的空间旋转对称性和时间维度上的时间对称性。在重建模型中明确纳入这些对称性先验可以显著提高图像质量，特别是在激进欠采样情况下。最近，等变卷积神经网络（ECNN）在利用空间对称性先验方面显示出巨大潜力。然而，现有的ECNN未能建模时间对称性，这可能是动态MRI重建中最普遍且信息丰富的结构先验。为解决这一问题，我们提出了一种新颖的具有时空旋转等变性的深度展开网络（DUN-SRE）用于动态MRI重建。DUN-SRE通过（2+1）D等变卷积架构建立时空等变性。特别是，它将数据一致性和近端映射模块集成到一个统一的深度展开框架中。这种架构确保了时空旋转对称性约束在整个重建过程中的严格传播，从而能够更物理准确地建模心脏运动动态。此外，还开发了一种高保真群滤波器参数化机制，以在施加对称性约束的同时保持表示精度。在心脏CINE MRI数据集上的综合实验表明，DUN-SRE实现了最先进的性能，特别是在保留旋转对称结构方面，为广泛的动态MRI重建任务提供了强大的泛化能力。

</details>


### [717] [Rethinking Brain Tumor Segmentation from the Frequency Domain Perspective](https://arxiv.org/abs/2506.10142)
**中文标题：从频域视角重新思考脑肿瘤分割**

*Minye Shao,Zeyu Wang,Haoran Duan,Yawen Huang,Bing Zhai,Shizheng Wang,Yang Long,Yefeng Zheng*

Main category: eess.IV

TL;DR: The paper proposes HFF-Net, a frequency-domain approach for brain tumor segmentation, improving performance by decomposing MRI images into low and high-frequency components and dynamically emphasizing critical details.


<details>
  <summary>Details</summary>
Motivation: Current brain tumor segmentation methods struggle with enhancing regions in MRI due to insufficient consideration of MRI-specific features like textures and directional variations.

Method: HFF-Net uses Frequency Domain Decomposition (FDD) to separate MRI images into low and high-frequency components, Adaptive Laplacian Convolution (ALC) to emphasize critical details, and Frequency Domain Cross-Attention (FDCA) for multi-scale feature fusion.

Result: HFF-Net achieves an average 4.48% improvement in mean Dice scores and 7.33% improvement in enhancing tumor segmentation, with maintained computational efficiency.

Conclusion: The frequency-domain perspective significantly enhances brain tumor segmentation, particularly for contrast-enhancing regions, demonstrating clinical applicability.

摘要: 脑肿瘤的精确分割，尤其是对比增强MRI中可见的区域（通过对比剂注射突出显示），对于准确的临床诊断和治疗计划至关重要，但仍具有挑战性。然而，当前方法在分割这些增强脑肿瘤区域时表现出显著的性能下降，主要由于对MRI特异性肿瘤特征（如复杂纹理和方向变化）的考虑不足。为此，我们提出了谐波频率融合网络（HFF-Net），从频域视角重新思考脑肿瘤分割。为了全面表征肿瘤区域，我们开发了频域分解（FDD）模块，将MRI图像分离为低频分量（捕捉平滑的肿瘤轮廓）和高频分量（突出细节纹理和方向边缘）。为了进一步增强对肿瘤边界的敏感性，我们引入了自适应拉普拉斯卷积（ALC）模块，通过动态更新的卷积核自适应强调关键高频细节。为了有效融合多尺度肿瘤特征，我们设计了频域交叉注意力（FDCA），整合语义、位置和切片特定信息。我们通过可视化、理论推理和实验分析进一步验证和解释频域改进。在四个公共数据集上的大量实验表明，HFF-Net在三个主要子区域的平均Dice得分中实现了4.48%（范围2.39%至7.72%）的相对改进，在对比增强肿瘤区域的分割中实现了7.33%（范围5.96%至8.64%）的相对改进，同时保持了良好的计算效率和临床适用性。代码：https://github.com/VinyehShaw/HFF。

</details>


### [718] [Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation](https://arxiv.org/abs/2506.10230)
**中文标题：基于提示引导的潜在扩散与预测类别条件用于3D前列腺MRI生成**

*Emerson P. Grabke,Masoom A. Haider,Babak Taati*

Main category: eess.IV

TL;DR: The paper introduces CCELLA, a novel dual-head conditioning approach for latent diffusion models (LDMs) to generate high-quality 3D prostate MRI images with limited data, outperforming existing methods in performance and accessibility.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of current medical LDMs, which rely on short-prompt text encoders, non-medical LDMs, or large data volumes for fine-tuning, the authors propose a more efficient and accessible solution.

Method: The authors propose CCELLA, a dual-head conditioning approach that combines non-medical large language model-encoded text features and pathology classification. They also introduce a joint loss function and a data-efficient LDM training framework.

Result: The method achieves a 3D FID score of 0.025, significantly better than a foundation model's 0.071. Synthetic images improved classifier accuracy from 69% to 74%, and training solely on synthetic images matched real-image performance.

Conclusion: CCELLA enables pathology-conditioned LDM training with limited data, improving performance and accessibility for medical image synthesis.

摘要: 潜在扩散模型（LDM）可以缓解医学影像机器学习开发中的数据稀缺问题。然而，医学LDM训练通常依赖于性能或科学可访问性受限的策略，包括依赖短提示文本编码器、重用非医学LDM或需要大量数据进行微调。我们提出了一种类别条件高效大型语言模型适配器（CCELLA）来解决这些限制。CCELLA是一种新颖的双头条件方法，同时通过交叉注意力将非医学大型语言模型编码的文本特征和通过时间步嵌入的病理分类条件化LDM U-Net。我们还提出了联合损失函数和数据高效的LDM训练框架。这些策略的结合使得在有限数据量和人工数据标注下，能够进行病理条件化的LDM训练，生成高质量的医学影像，从而提升LDM性能和科学可访问性。我们的方法在规模受限的前列腺MRI数据集上实现了3D FID分数0.025，显著优于最近的基础模型（FID 0.071）。在训练前列腺癌预测分类器时，将我们方法生成的合成图像添加到训练数据集中，分类器准确率从69%提高到74%。仅使用我们方法的合成图像训练分类器，其性能与仅使用真实图像训练相当。

</details>


### [719] [Conditional diffusion models for guided anomaly detection in brain images using fluid-driven anomaly randomization](https://arxiv.org/abs/2506.10233)
**中文标题：基于流体驱动异常随机化的条件扩散模型用于脑图像引导异常检测**

*Ana Lawry Aguila,Peirong Liu,Oula Puonti,Juan Eugenio Iglesias*

Main category: eess.IV

TL;DR: The paper introduces a conditional diffusion model framework for anomaly detection in brain MRI, using fluid-driven anomaly randomization to generate synthetic pseudo-pathologies for better reconstruction of healthy images. It outperforms existing methods, including supervised approaches.


<details>
  <summary>Details</summary>
Motivation: Supervised machine learning for pathology detection in brain MRI requires large disease-specific datasets, which are often unavailable for rare diseases. Unsupervised methods, like diffusion models, train on healthy images alone but struggle to accurately reconstruct anomalies or healthy tissue. This work aims to improve anomaly detection by integrating synthetic pseudo-pathologies into the modeling process.

Method: The authors propose a conditional diffusion model framework that uses fluid-driven anomaly randomization to generate realistic synthetic anomalies from auxiliary datasets. These synthetic anomalies guide the reconstruction of healthy images, improving anomaly detection.

Result: The model outperforms variational autoencoders, conditional and unconditional latent diffusion models, and even supervised inpainting methods in detecting pathology, as demonstrated on synthetic and real datasets (e.g., ATLAS).

Conclusion: The proposed framework effectively integrates synthetic anomalies to enhance anomaly detection and healthy image reconstruction, offering a robust solution for scenarios with limited diseased data.

摘要: 监督机器学习在脑MRI中实现了精确的病理检测，但在某些情况下（如罕见疾病）可能缺乏足够的患病数据。基于重建的无监督异常检测方法，尤其是扩散模型，因其仅需健康图像训练而在医学领域广受欢迎。然而，这些方法假设模型无法准确表示或重建异常区域，但实际中常无法重建健康组织或完全去除异常。本文提出了一种新颖的条件扩散模型框架，用于脑MRI中的异常检测和健康图像重建。我们的弱监督方法将合成的伪病理图像整合到建模过程中，以更好地指导健康图像的重建。为生成这些伪病理，我们采用流体驱动异常随机化技术对辅助数据集中的真实病理分割图进行增强，确保合成异常既真实又解剖学合理。我们评估了模型在合成异常数据集和ATLAS数据集中的病理检测能力。实验表明，我们的模型：（i）始终优于变分自编码器、条件及无条件潜在扩散模型；（ii）在多数数据集上超越了需要成对患病/健康图像的监督修复方法。

</details>


### [720] [SWDL: Stratum-Wise Difference Learning with Deep Laplacian Pyramid for Semi-Supervised 3D Intracranial Hemorrhage Segmentation](https://arxiv.org/abs/2506.10325)
**中文标题：SWDL：基于深度拉普拉斯金字塔的分层差异学习用于半监督3D颅内出血分割**

*Cheng Wang,Siqi Chen,Donghua Mi,Yang Chen,Yudong Zhang,Yinsheng Li*

Main category: eess.IV

TL;DR: SWDL-Net is a semi-supervised learning framework for 3D intracranial hemorrhage segmentation, combining Laplacian pyramid edge sharpening with deep convolutional upsampling to improve lesion detail and boundary segmentation with minimal labeled data.


<details>
  <summary>Details</summary>
Motivation: The challenge of obtaining manual annotations for intracranial hemorrhage (ICH) segmentation due to its tedious and costly process motivates the need for semi-supervised learning (SSL) methods to reduce reliance on labeled data.

Method: SWDL-Net integrates Laplacian pyramid for edge sharpening and deep convolutional upsampling for detail precision, using a difference learning mechanism to combine these complementary approaches.

Result: SWDL-Net outperforms state-of-the-art methods on a 271-case ICH dataset and the BHSD benchmark, achieving superior performance with only 2% and 5% labeled data, respectively.

Conclusion: The proposed SWDL-Net framework effectively addresses the scarcity of labeled data in ICH segmentation by leveraging complementary advantages of Laplacian pyramid and deep convolutions, demonstrating significant improvements over existing methods.

摘要: 近年来，医学影像领域的进展使基于深度学习的分割成为主流方法，但其通常需要大量手动标注数据。然而，由于标注过程繁琐且成本高昂，获取颅内出血（ICH）的标注尤为困难。半监督学习（SSL）为解决标注数据稀缺问题提供了一种有前景的解决方案，尤其是在体积医学图像分割中。与主要关注高置信度伪标签或一致性正则化的传统SSL方法不同，我们提出了SWDL-Net，一种新颖的SSL框架，利用拉普拉斯金字塔和深度卷积上采样的互补优势。拉普拉斯金字塔擅长边缘锐化，而深度卷积通过灵活的特征映射增强细节精度。我们的框架通过差异学习机制有效整合了这些互补方法，实现了对病变细节和边界的卓越分割。在包含271例ICH的数据集和公共基准上的大量实验表明，SWDL-Net在仅使用2%标注数据的情况下优于当前最先进的方法。在公开可用的脑出血分割数据集（BHSD）上使用5%标注数据的进一步评估也证实了我们方法的优越性。代码和数据已发布于https://github.com/SIAT-CT-LAB/SWDL。

</details>


### [721] [ConStyX: Content Style Augmentation for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2506.10675)
**中文标题：ConStyX：用于可泛化医学图像分割的内容风格增强**

*Xi Chen,Zhiqiang Shen,Peng Cao,Jinzhu Yang,Osmar R. Zaiane*

Main category: eess.IV

TL;DR: The paper proposes ConStyX, a domain generalization method for medical image segmentation that augments both content and style of training data to improve model robustness across multiple domains, while mitigating negative effects of over-augmentation.


<details>
  <summary>Details</summary>
Motivation: Medical images from multiple domains cause domain shifts, reducing segmentation model performance. Existing domain randomization methods are limited by style-only augmentation and over-augmentation issues.

Method: ConStyX augments both content and style of training data to cover a wider range of domains and mitigates negative effects of over-augmented features during training.

Result: Extensive experiments show ConStyX achieves superior generalization performance across multiple domains.

Conclusion: ConStyX effectively addresses domain shift issues in medical image segmentation by combining content and style augmentation, outperforming existing methods.

摘要: 医学图像通常来自多个领域，导致领域偏移，影响医学图像分割模型的性能。领域泛化（DG）旨在通过训练具有强泛化能力的鲁棒模型来解决这一问题。最近，许多基于领域随机化的DG方法被提出。然而，这些方法存在以下局限性：1）由于仅依赖图像风格扰动，领域随机化的效率受限；2）忽视了过度增强图像对模型训练的负面影响。为解决这些问题，我们提出了一种新颖的基于领域随机化的DG方法，称为内容风格增强（ConStyX），用于可泛化的医学图像分割。具体而言，ConStyX 1）增强训练数据的内容和风格，使增强后的训练数据能更好地覆盖更广泛的数据领域；2）在模型训练中利用良好增强的特征，同时减轻过度增强特征的负面影响。跨多个领域的广泛实验表明，我们的ConStyX实现了卓越的泛化性能。代码可在https://github.com/jwxsp1/ConStyX获取。

</details>


### [722] [Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches](https://arxiv.org/abs/2506.10825)
**中文标题：医学图像分割中的通用模型：与任务特定方法的调查及性能比较**

*Andrea Moglia,Matteo Leccardi,Matteo Cavicchioli,Alice Maccarini,Marco Marcon,Luca Mainardi,Pietro Cerveri*

Main category: eess.IV

TL;DR: This survey explores generalist models in medical image segmentation, comparing their performance with task-specific approaches, highlighting challenges, and suggesting future directions.


<details>
  <summary>Details</summary>
Motivation: The paper aims to investigate the potential of generalist models, inspired by large language models, in medical image segmentation, and compare their effectiveness with traditional task-specific methods.

Method: The survey introduces foundational concepts, categorizes various adaptations of the Segment Anything Model (SAM), and analyzes their performance against state-of-the-art task-specific models.

Result: Generalist models show promise but face challenges in regulatory compliance, privacy, and AI trustworthiness, while also offering innovative directions for future research.

Conclusion: The study underscores the need for addressing practical challenges and explores future advancements in synthetic data, fusion techniques, and clinical applications.

摘要: 随着大型语言模型成功的范式转变，利用海量数据预训练并在不同下游任务上微调，通用模型已进入计算机视觉领域。Segment Anything Model（SAM）的引入为自然图像分割树立了里程碑，激发了医学图像分割中多种架构的设计。本调查对医学图像分割中的通用模型进行了全面深入的探讨。我们首先介绍了支撑其发展的基本概念，然后对SAM的不同变体进行了分类，包括零样本、少样本、微调、适配器、最新的SAM 2、仅基于图像的创新模型以及基于文本和图像的模型。我们详细分析了它们在初级研究和文献最佳水平上的表现，并与最先进的任务特定模型进行了严格比较。我们强调了在符合监管框架、隐私和安全法律、预算以及可信人工智能（AI）方面的挑战。最后，我们分享了关于合成数据、早期融合、从自然语言处理通用模型中学到的经验、代理AI和物理AI以及临床转化等未来方向的展望。

</details>


### [723] [Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation](https://arxiv.org/abs/2506.10858)
**中文标题：Med-URWKV：基于纯RWKV和ImageNet预训练的医学图像分割方法**

*Zhenhuan Zhou*

Main category: eess.IV

TL;DR: Med-URWKV is a pure RWKV-based medical image segmentation model that leverages ImageNet pre-training, achieving competitive performance without modifications to the RWKV mechanism.


<details>
  <summary>Details</summary>
Motivation: Existing methods (CNNs, Transformers, hybrids) have limitations like restricted receptive fields or high computational costs. RWKV offers linear complexity and strong long-range modeling, but its potential with pre-training for medical tasks is unexplored.

Method: Med-URWKV integrates a pure RWKV architecture into U-Net, using a pre-trained VRWKV encoder from ImageNet for medical image segmentation.

Result: Experiments on seven datasets show Med-URWKV matches or outperforms other RWKV models trained from scratch, validating the effectiveness of pre-training.

Conclusion: Med-URWKV demonstrates the benefits of pre-trained RWKV encoders in medical segmentation, offering a promising direction for future research.

摘要: 医学图像分割是计算机辅助诊断和治疗中的一项基础关键技术。现有方法主要分为三类：基于卷积神经网络（CNN）、基于Transformer以及两者的混合架构。然而，这些方法各有局限性，例如CNN的感受野受限或Transformer因二次复杂度带来的计算开销。最近，Receptance Weighted Key Value（RWKV）模型因其线性计算复杂度和强大的长程建模能力，成为视觉任务的有力替代方案。一些研究已将RWKV应用于医学图像分割任务，并取得了竞争性性能。但这些研究多集中于对Vision-RWKV（VRWKV）机制的修改，并从零开始训练模型，未探索利用预训练VRWKV模型在医学图像分割任务中的潜在优势。本文提出Med-URWKV，一种基于U-Net框架的纯RWKV架构，结合ImageNet预训练，进一步挖掘RWKV在医学图像分割中的潜力。据我们所知，Med-URWKV是医学领域首个可直接复用大规模预训练VRWKV编码器的纯RWKV分割模型。在七个数据集上的实验结果表明，Med-URWKV的分割性能与从零开始训练的其他精心优化的RWKV模型相当甚至更优，验证了预训练VRWKV编码器在提升模型性能方面的有效性。代码将公开。

</details>


### [724] [Semi-Automated Quality Assurance in Digital Pathology: Tile Classification Approach](https://arxiv.org/abs/2506.10916)
**中文标题：数字病理学中的半自动化质量保证：基于瓦片分类的方法**

*Meredith VandeHaar,M. Clinch,I. Yilmaz,M. A. Rahman,Y. Xiao,F. Dogany,H. M. Alazab,A. Nassar,Z. Akkus,B. Dangott*

Main category: eess.IV

TL;DR: The paper proposes an AI algorithm for semi-automated quality assurance in digital pathology by classifying tiles into artifact types, reducing manual review time.


<details>
  <summary>Details</summary>
Motivation: Current quality assurance in digital pathology is manual and inefficient, with limited use of deep learning despite its potential to improve accuracy and scalability.

Method: The algorithm analyzes tiles from whole slide images, categorizing them into 10 artifact types or background, and creates a map to guide human reviewers. It uses InceptionResNet and a hybrid design of single and multiple instance models.

Result: The study demonstrated the effectiveness of the hybrid model in detecting artifacts like chatter, fold, and pen, optimizing detection for each type.

Conclusion: The hybrid AI approach improves efficiency and accuracy in digital pathology quality assurance, reducing reliance on manual review.

摘要: 质量保证是数字病理学中一个关键但尚未充分探索的领域，即使是微小的伪影也可能产生重大影响。伪影已被证明会对AI诊断模型的性能产生负面影响。目前，训练有素的工作人员在将这些数字化图像发布给病理学家之前会手动检查，这些图像随后用于诊断。传统的图像处理方法为检测数字病理学切片上的伪影提供了基础。然而，当前的工具并未利用深度学习，而深度学习有潜力提高检测的准确性和可扩展性。尽管有这些进步，数字病理学中的质量保证方法仍然有限，为创新提供了空间。
我们提出了一种AI算法，旨在通过分析瓦片并将其分类为10种预定义的伪影类型或背景来筛查数字病理学切片。该算法识别并定位伪影，创建一张突出显示感兴趣区域的地图。通过将人类操作员引导至受伪影影响的特定瓦片，该算法最大限度地减少了手动检查整个切片以发现质量问题所需的时间和精力。
从内部档案和癌症基因组图谱中，选择了133张全切片图像，并使用内部开发的软件ZAPP（Mayo Clinic, Jacksonville, FL）对10种伪影进行了标注。对不同瓦片尺寸和放大倍数的多个模型进行了消融研究，最终选择了InceptionResNet。训练并测试了单伪影模型，随后是一个有限的多实例模型（包含表现良好的伪影：chatter、fold和pen）。根据本研究的结果，我们建议采用一种混合设计进行伪影筛查，结合单伪影二值模型和多实例模型，以优化每种伪影的检测。

</details>


### [725] [DUN-SRE: Deep Unrolling Network with Spatiotemporal Rotation Equivariance for Dynamic MRI Reconstruction](https://arxiv.org/abs/2506.10309)
**中文标题：DUN-SRE：具有时空旋转等变性的深度展开网络用于动态MRI重建**

*Yuliang Zhu,Jing Cheng,Qi Xie,Zhuo-Xu Cui,Qingyong Zhu,Yuanyuan Liu,Xin Liu,Jianfeng Ren,Chengbo Wang,Dong Liang*

Main category: eess.IV

TL;DR: 提出了一种具有时空旋转等变性的深度展开网络（DUN-SRE），用于动态MRI重建，通过结合时空对称性先验，显著提升了图像质量。


<details>
  <summary>Details</summary>
Motivation: 动态MRI具有时空对称性，现有方法未能充分建模时间对称性，限制了重建性能。DUN-SRE旨在通过时空等变性卷积架构解决这一问题。

Method: 采用(2+1)D等变性卷积架构，将数据一致性和近端映射模块整合到深度展开框架中，并通过高保真群滤波器参数化机制保持表示精度。

Result: 在心脏CINE MRI数据集上的实验表明，DUN-SRE在保留旋转对称结构方面表现优异，具有广泛的泛化能力。

Conclusion: DUN-SRE通过严格传播时空旋转对称性约束，实现了动态MRI重建的先进性能，为相关任务提供了通用解决方案。

摘要: 动态磁共振成像（MRI）表现出变换对称性，包括单帧内的空间旋转对称性和时间维度上的对称性。在重建模型中显式结合这些对称性先验可以显著提高图像质量，尤其是在激进欠采样场景下。近年来，等变性卷积神经网络（ECNN）在利用空间对称性先验方面显示出巨大潜力。然而，现有的ECNN未能建模时间对称性，而这可能是动态MRI重建中最普遍且信息丰富的结构先验。为解决这一问题，我们提出了一种新颖的具有时空旋转等变性的深度展开网络（DUN-SRE）用于动态MRI重建。DUN-SRE通过(2+1)D等变性卷积架构建立时空等变性。具体而言，它将数据一致性模块和近端映射模块整合到一个统一的深度展开框架中。这一架构确保了时空旋转对称性约束在整个重建过程中的严格传播，从而能够更物理准确地建模心脏运动动态。此外，还开发了一种高保真群滤波器参数化机制，以在施加对称性约束的同时保持表示精度。在心脏CINE MRI数据集上的综合实验表明，DUN-SRE实现了最先进的性能，尤其是在保留旋转对称结构方面，为广泛的动态MRI重建任务提供了强大的泛化能力。

</details>


### [726] [Rethinking Brain Tumor Segmentation from the Frequency Domain Perspective](https://arxiv.org/abs/2506.10142)
**中文标题：从频域视角重新思考脑肿瘤分割**

*Minye Shao,Zeyu Wang,Haoran Duan,Yawen Huang,Bing Zhai,Shizheng Wang,Yang Long,Yefeng Zheng*

Main category: eess.IV

TL;DR: 本文提出了一种基于频域视角的脑肿瘤分割方法HFF-Net，通过频域分解、自适应拉普拉斯卷积和多尺度特征融合，显著提升了对比增强区域的肿瘤分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前脑肿瘤分割方法在对比增强区域的性能不足，主要由于对MRI特定特征（如复杂纹理和方向变化）的考虑不充分。

Method: HFF-Net包含频域分解模块（FDD）分离高低频成分，自适应拉普拉斯卷积模块（ALC）增强高频细节，以及频域交叉注意力模块（FDCA）融合多尺度特征。

Result: 在四个公开数据集上，HFF-Net在三个主要子区域的Dice分数平均提升4.48%，对比增强区域的分割性能平均提升7.33%。

Conclusion: HFF-Net通过频域视角显著提升了脑肿瘤分割性能，同时保持了计算效率和临床适用性。

摘要: 脑肿瘤的精确分割，尤其是对比增强MRI中可见的区域（通过对比剂注射突出显示的区域），对于准确的临床诊断和治疗计划至关重要，但仍具有挑战性。然而，当前方法在分割这些增强脑肿瘤区域时表现出显著的性能下降，主要是由于对MRI特定肿瘤特征（如复杂纹理和方向变化）的考虑不足。为此，我们提出了和谐频域融合网络（HFF-Net），从频域视角重新思考脑肿瘤分割。为了全面表征肿瘤区域，我们开发了频域分解（FDD）模块，将MRI图像分离为低频成分（捕捉平滑肿瘤轮廓）和高频成分（突出详细纹理和方向边缘）。为了进一步增强对肿瘤边界的敏感性，我们引入了自适应拉普拉斯卷积（ALC）模块，通过动态更新的卷积核自适应地强调关键高频细节。为了有效融合多尺度肿瘤特征，我们设计了频域交叉注意力（FDCA）模块，整合语义、位置和切片特定信息。我们通过可视化、理论推理和实验分析进一步验证和解释了频域改进。在四个公开数据集上的广泛实验表明，HFF-Net在三个主要子区域的平均Dice分数相对提升了4.48%（范围从2.39%到7.72%），在对比增强肿瘤区域的分割性能平均相对提升了7.33%（范围从5.96%到8.64%），同时保持了良好的计算效率和临床适用性。代码：https://github.com/VinyehShaw/HFF。

</details>


### [727] [Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation](https://arxiv.org/abs/2506.10230)
**中文标题：基于提示引导的潜在扩散与预测类别条件化的3D前列腺MRI生成**

*Emerson P. Grabke,Masoom A. Haider,Babak Taati*

Main category: eess.IV

TL;DR: 本文提出了一种名为CCELLA的新型双头条件方法，结合非医学大型语言模型编码的文本特征和病理分类，通过联合损失函数和数据高效的LDM训练框架，实现了在有限数据下高质量医学图像合成。该方法在3D前列腺MRI数据集上表现优异，显著优于现有基础模型，并提升了前列腺癌分类器的准确性。


<details>
  <summary>Details</summary>
Motivation: 医学图像数据稀缺限制了机器学习的发展，现有方法依赖短提示文本编码器、非医学LDMs或大量数据微调，性能受限且科学可及性低。本文旨在解决这些问题。

Method: 提出CCELLA，一种双头条件方法，通过交叉注意力将非医学大型语言模型编码的文本特征与时间步嵌入的病理分类同时条件化LDM U-Net。还设计了联合损失函数和数据高效的LDM训练框架。

Result: 在有限数据的前列腺MRI数据集上，3D FID得分为0.025，显著优于基础模型的0.071。合成图像用于训练前列腺癌分类器时，准确率从69%提升至74%，且仅用合成图像训练的模型性能接近真实图像。

Conclusion: CCELLA方法在有限数据和标注下实现了高质量的医学图像合成，提升了LDM性能和科学可及性，为医学图像生成提供了有效解决方案。

摘要: 潜在扩散模型（LDM）可以缓解医学影像机器学习开发中的数据稀缺问题。然而，医学LDM训练通常依赖于性能或科学可及性受限的策略，如依赖短提示文本编码器、重用非医学LDMs或需要大量数据微调。我们提出了一种类别条件化高效大型语言模型适配器（CCELLA）来解决这些问题。CCELLA是一种新颖的双头条件方法，通过交叉注意力将非医学大型语言模型编码的文本特征与时间步嵌入的病理分类同时条件化LDM U-Net。我们还提出了联合损失函数和数据高效的LDM训练框架。这些策略共同实现了在有限数据和人工标注下的高质量医学图像合成，提升了LDM性能和科学可及性。我们的方法在数据量有限的前列腺MRI数据集上实现了3D FID得分0.025，显著优于近期基础模型的0.071。在训练前列腺癌预测分类器时，将我们方法生成的合成图像加入训练集后，分类器准确率从69%提升至74%。仅用合成图像训练的模型性能与仅用真实图像训练的模型相当。

</details>


### [728] [Conditional diffusion models for guided anomaly detection in brain images using fluid-driven anomaly randomization](https://arxiv.org/abs/2506.10233)
**中文标题：基于流体驱动异常随机化的条件扩散模型在脑部图像引导异常检测中的应用**

*Ana Lawry Aguila,Peirong Liu,Oula Puonti,Juan Eugenio Iglesias*

Main category: eess.IV

TL;DR: 本文提出了一种基于条件扩散模型的新框架，用于脑部MRI中的异常检测和健康图像重建。通过引入流体驱动的异常随机化生成伪病理图像，模型在无需大量疾病数据的情况下显著提升了异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习方法需要大量疾病数据，而重建型无监督异常检测方法（如扩散模型）虽可仅用健康图像训练，但常无法准确重建异常区域。本文旨在解决这一问题。

Method: 提出了一种弱监督方法，通过流体驱动的异常随机化生成伪病理图像，并将其整合到条件扩散模型中，以更好地指导健康图像的重建。

Result: 模型在合成异常数据集和真实病理数据（ATLAS数据集）上的表现优于变分自编码器、条件及无条件潜在扩散模型，甚至在某些情况下超过需要成对疾病/健康图像的监督修复方法。

Conclusion: 该方法在无需大量疾病数据的情况下，显著提升了脑部MRI中异常检测的准确性，为罕见疾病诊断提供了新思路。

摘要: 监督机器学习在脑部MRI中实现了高精度的病理检测，但在某些情况下（如罕见疾病）可能难以获取足够的疾病数据。基于重建的无监督异常检测方法（尤其是扩散模型）因其仅需健康图像训练而在医学领域广受欢迎。这些方法假设模型无法准确表示或重建异常区域，但实际中模型常无法重建健康组织或准确去除异常。本文提出了一种新的条件扩散模型框架，用于脑部MRI中的异常检测和健康图像重建。我们的弱监督方法通过流体驱动的异常随机化生成伪病理图像，并将其整合到建模过程中，以更好地指导健康图像的重建。这些伪病理图像通过对辅助数据集中的真实病理分割图进行增强生成，确保其既真实又符合解剖学逻辑。我们使用合成异常数据集和ATLAS数据集中的真实病理评估了模型的异常检测能力。实验表明，我们的模型：（i）在性能上持续优于变分自编码器、条件及无条件潜在扩散模型；（ii）在多数数据集上甚至超过了需要成对疾病/健康图像的监督修复方法。

</details>


### [729] [SWDL: Stratum-Wise Difference Learning with Deep Laplacian Pyramid for Semi-Supervised 3D Intracranial Hemorrhage Segmentation](https://arxiv.org/abs/2506.10325)
**中文标题：SWDL：基于深度拉普拉斯金字塔的分层差异学习用于半监督3D颅内出血分割**

*Cheng Wang,Siqi Chen,Donghua Mi,Yang Chen,Yudong Zhang,Yinsheng Li*

Main category: eess.IV

TL;DR: 本文提出了一种名为SWDL-Net的半监督学习框架，结合拉普拉斯金字塔和深度卷积上采样的互补优势，用于3D颅内出血分割。该方法在仅2%标注数据的情况下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 颅内出血（ICH）分割的标注数据获取困难且成本高，传统半监督学习方法主要依赖高置信度伪标签或一致性正则化，无法充分利用图像细节和边界信息。

Method: 提出SWDL-Net框架，结合拉普拉斯金字塔的边缘锐化能力和深度卷积上采样的细节增强能力，通过差异学习机制整合两者优势。

Result: 在271例ICH数据集和公开基准测试中，SWDL-Net在仅2%标注数据的情况下表现优于现有方法，并在BHSD数据集上进一步验证了其优越性。

Conclusion: SWDL-Net通过整合拉普拉斯金字塔和深度卷积上采样的互补优势，显著提升了半监督3D颅内出血分割的性能。

摘要: 近年来，基于深度学习的医学图像分割方法取得了显著进展，但其通常需要大量手动标注数据。然而，颅内出血（ICH）的标注过程繁琐且成本高昂，导致标注数据稀缺。半监督学习（SSL）为解决这一问题提供了可能，尤其是在体积医学图像分割领域。与传统的SSL方法主要关注高置信度伪标签或一致性正则化不同，我们提出了SWDL-Net，一种新颖的SSL框架，充分利用拉普拉斯金字塔和深度卷积上采样的互补优势。拉普拉斯金字塔擅长边缘锐化，而深度卷积通过灵活的特征映射增强细节精度。我们的框架通过差异学习机制有效整合了这两种互补方法，实现了对病变细节和边界的卓越分割。在271例ICH数据集和公开基准测试上的大量实验表明，SWDL-Net在仅2%标注数据的情况下优于当前最先进的方法。在公开的脑出血分割数据集（BHSD）上以5%标注数据进行的额外评估进一步证实了我们方法的优越性。代码和数据已发布于https://github.com/SIAT-CT-LAB/SWDL。

</details>


### [730] [ConStyX: Content Style Augmentation for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2506.10675)
**中文标题：ConStyX：用于可泛化医学图像分割的内容风格增强方法**

*Xi Chen,Zhiqiang Shen,Peng Cao,Jinzhu Yang,Osmar R. Zaiane*

Main category: eess.IV

TL;DR: 本文提出了一种名为ConStyX的新方法，通过内容和风格增强提升医学图像分割模型的泛化能力，解决了现有域随机化方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 医学图像通常来自多个域，导致域偏移问题，影响分割模型的性能。现有域随机化方法仅依赖图像风格扰动，效率受限，且忽视了过度增强对训练的负面影响。

Method: ConStyX通过同时增强训练数据的内容和风格，扩大数据域覆盖范围，并在训练中利用高质量增强特征，减少过度增强的负面影响。

Result: 多域实验表明，ConStyX在医学图像分割任务中表现出卓越的泛化性能。

Conclusion: ConStyX通过内容和风格增强有效提升了模型的泛化能力，解决了现有方法的局限性。

摘要: 医学图像通常来自多个域，导致域偏移问题，影响医学图像分割模型的性能。域泛化（DG）旨在通过训练具有强泛化能力的鲁棒模型来解决这一问题。近年来，许多基于域随机化的DG方法被提出，但这些方法存在以下局限性：1）仅依赖图像风格扰动导致域随机化效率受限；2）忽视了过度增强图像对模型训练的负面影响。为解决这些问题，我们提出了一种新的基于域随机化的DG方法，称为内容风格增强（ConStyX），用于可泛化的医学图像分割。具体而言，ConStyX 1）增强训练数据的内容和风格，使增强后的数据能更好地覆盖更广泛的数据域；2）在模型训练中利用高质量增强特征，同时减少过度增强特征的负面影响。多域实验表明，我们的ConStyX具有卓越的泛化性能。代码可在https://github.com/jwxsp1/ConStyX获取。

</details>


### [731] [Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches](https://arxiv.org/abs/2506.10825)
**中文标题：通用模型在医学图像分割中的综述及与任务专用模型的性能比较**

*Andrea Moglia,Matteo Leccardi,Matteo Cavicchioli,Alice Maccarini,Marco Marcon,Luca Mainardi,Pietro Cerveri*

Main category: eess.IV

TL;DR: 本文综述了通用模型在医学图像分割中的应用，并与任务专用模型进行了性能比较。重点介绍了Segment Anything Model (SAM)及其变体，分析了其性能、挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 受大型语言模型的启发，通用模型在计算机视觉领域崭露头角，尤其是医学图像分割。本文旨在全面调查通用模型在该领域的应用，并与传统任务专用模型进行对比。

Method: 文章首先介绍了通用模型的基础概念，然后对SAM及其变体（如零样本、少样本、微调、适配器等）进行了分类。同时，分析了其他创新模型（基于图像或文本与图像结合的训练）。最后，对通用模型与任务专用模型的性能进行了严格比较。

Result: 通用模型在医学图像分割中表现出色，但仍面临监管合规、隐私安全、预算及可信AI等挑战。与任务专用模型相比，通用模型在某些场景下具有优势，但仍有改进空间。

Conclusion: 未来研究方向包括合成数据、早期融合、借鉴自然语言处理经验、代理AI与物理AI，以及临床转化。通用模型在医学图像分割领域潜力巨大，但需解决现有挑战。

摘要: 随着大型语言模型的成功范式转变，通用模型通过在大规模数据上进行预训练并在不同下游任务上微调，已进入计算机视觉领域。Segment Anything Model (SAM)的推出为自然图像分割树立了里程碑，并激发了医学图像分割中多种架构的设计。本综述对医学图像分割中的通用模型进行了全面深入的研究。首先介绍了其发展的基础概念，然后对SAM的不同变体（如零样本、少样本、微调、适配器、SAM 2等）进行了分类，并分析了其他仅基于图像或结合文本与图像训练的创新模型。我们详细评估了其在初级研究和文献最佳水平上的性能，并与最先进的任务专用模型进行了严格比较。强调了在监管框架、隐私与安全法律、预算及可信人工智能（AI）方面面临的挑战。最后，我们分享了关于合成数据、早期融合、从自然语言处理中吸取的经验、代理AI与物理AI以及临床转化等未来方向的见解。

</details>


### [732] [Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation](https://arxiv.org/abs/2506.10858)
**中文标题：Med-URWKV：基于纯RWKV与ImageNet预训练的医学图像分割模型**

*Zhenhuan Zhou*

Main category: eess.IV

TL;DR: 本文提出了一种基于纯RWKV的医学图像分割模型Med-URWKV，通过结合ImageNet预训练的VRWKV编码器，在多个数据集上取得了优于或与从头训练的RWKV模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割是计算机辅助诊断和治疗中的关键技术。现有方法如CNN、Transformer及其混合架构各有局限性（如CNN的感受野受限或Transformer的二次计算复杂度）。RWKV模型因其线性计算复杂度和强大的长程建模能力成为潜在替代方案，但此前研究多关注对Vision-RWKV（VRWKV）的修改且未充分利用预训练模型的潜力。

Method: 提出Med-URWKV，一种基于U-Net框架的纯RWKV架构，首次在医学领域直接利用大规模预训练的VRWKV编码器，结合ImageNet预训练以提升模型性能。

Result: 在七个数据集上的实验表明，Med-URWKV的分割性能优于或与从头训练的RWKV模型相当，验证了预训练VRWKV编码器的有效性。

Conclusion: Med-URWKV展示了预训练RWKV模型在医学图像分割任务中的潜力，为未来研究提供了新方向。

摘要: 医学图像分割是计算机辅助诊断和治疗中的一项基础关键技术。现有方法主要分为三类：基于卷积神经网络（CNN）、基于Transformer以及两者的混合架构。然而，这些方法各有局限性，例如CNN的感受野受限或Transformer因二次计算复杂度带来的计算开销。近年来，Receptance Weighted Key Value（RWKV）模型因其线性计算复杂度和强大的长程建模能力，成为多种视觉任务的有力替代方案。一些研究已尝试将RWKV应用于医学图像分割任务，并取得了竞争性性能。然而，这些研究多聚焦于对Vision-RWKV（VRWKV）机制的修改，且从头训练模型，未探索利用预训练VRWKV模型的潜在优势。本文提出Med-URWKV，一种基于U-Net框架的纯RWKV架构，通过结合ImageNet预训练进一步挖掘RWKV在医学图像分割任务中的潜力。据我们所知，Med-URWKV是医学领域首个可直接复用大规模预训练VRWKV编码器的纯RWKV分割模型。在七个数据集上的实验结果表明，Med-URWKV的分割性能优于或与其他精心优化的从头训练RWKV模型相当，验证了预训练VRWKV编码器对提升模型性能的有效性。代码将公开。

</details>


### [733] [Semi-Automated Quality Assurance in Digital Pathology: Tile Classification Approach](https://arxiv.org/abs/2506.10916)
**中文标题：数字病理学中的半自动化质量保证：切片分类方法**

*Meredith VandeHaar,M. Clinch,I. Yilmaz,M. A. Rahman,Y. Xiao,F. Dogany,H. M. Alazab,A. Nassar,Z. Akkus,B. Dangott*

Main category: eess.IV

TL;DR: 本文提出了一种基于深度学习的半自动化质量保证方法，用于数字病理学中的切片分类，通过分析切片并分类为10种预定义伪影类型或背景，显著减少了人工检查的时间和精力。


<details>
  <summary>Details</summary>
Motivation: 数字病理学中的质量保证是一个关键但研究不足的领域，现有工具未充分利用深度学习技术，导致伪影检测的准确性和可扩展性不足。本文旨在填补这一创新空白。

Method: 提出了一种AI算法，通过分析数字病理学切片并将其分类为10种伪影类型或背景。算法使用InceptionResNet模型，在不同切片尺寸和放大倍数下进行消融研究，并训练单伪影模型和有限多实例模型。

Result: 研究表明，结合单伪影二值模型和多实例模型的混合设计能够优化每种伪影的检测效果。

Conclusion: 本文提出的混合设计方法为数字病理学中的质量保证提供了一种高效且可扩展的解决方案。

摘要: 质量保证是数字病理学中一个关键但研究不足的领域，即使是微小的伪影也可能对AI诊断模型的性能产生显著影响。目前实践中，训练有素的工作人员会在将数字化图像发布给病理学家之前手动检查这些切片，而病理学家随后会基于这些切片进行诊断。传统的图像处理方法为检测数字病理学切片上的伪影提供了基础，但现有工具未充分利用深度学习技术，而深度学习有望提高检测的准确性和可扩展性。尽管技术有所进步，数字病理学中的质量保证方法仍然有限，这为创新提供了空间。

我们提出了一种AI算法，旨在通过分析切片并将其分类为10种预定义伪影类型或背景来筛查数字病理学切片。该算法能够识别并定位伪影，生成一张突出显示感兴趣区域的地图。通过将人工操作员引导至受伪影影响的特定切片，该算法显著减少了手动检查整张切片以发现质量问题的所需时间和精力。

从内部档案和《癌症基因组图谱》中，我们选取了133张全切片图像，并使用内部开发的软件ZAPP（Mayo Clinic，Jacksonville，FL）对10种伪影进行了标注。在不同切片尺寸和放大倍数下对多个模型进行了消融研究，最终选择了InceptionResNet模型。首先训练和测试了单伪影模型，随后对表现良好的伪影（如颤动、折叠和笔迹）进行了有限的多实例模型研究。基于研究结果，我们建议采用一种混合设计用于伪影筛查，该设计结合了单伪影二值模型和多实例模型，以优化每种伪影的检测效果。

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [734] [Encoding call-by-push-value in the pi-calculus](https://arxiv.org/abs/2506.10584)
**中文标题：在π演算中对按值推送调用进行编码**

*Benjamin Bennetzen,Nikolaj Rossander Kristensen,Peter Buus Steffensen*

Main category: cs.LO

TL;DR: The paper presents an encoding of Levy's call-by-push-value lambda-calculus (CBPV) in the pi-calculus, proving its soundness and completeness. It uses the internal pi-calculus (pi-i-calculus) for technical advantages and meets Gorla's criteria for good encodings.


<details>
  <summary>Details</summary>
Motivation: The motivation is to bridge CBPV and the pi-calculus, addressing challenges like formalization with de Bruijn indices and ensuring bisimulation congruence, while meeting established encoding criteria.

Method: The method involves defining an encoding of CBPV in the pi-i-calculus, providing informal proofs for soundness and completeness, and comparing it with other pi-calculus variants. A partial Coq formalization is also initiated.

Result: The encoding is proven sound and complete, satisfies Gorla's criteria, and shows similarities to Milner's encoding. The pi-i-calculus simplifies bisimulation and congruence properties.

Conclusion: The paper concludes that the encoding is robust, meets theoretical standards, and lays groundwork for further formalization in Coq.

摘要: 本报告定义了Levy的按值推送调用λ演算（CBPV）在π演算中的编码，并证明了该编码的健全性和完备性。我们提供了健全性、完备性及所需引理的非正式（手工）证明。该编码专门针对内部π演算（π-i-演算），以规避在形式化中使用de Bruijn索引的某些挑战，同时也有助于实现早、晚和开放双模拟的统一，且双模拟在此设定下具有同余性。此外，我们论证了该编码满足Gorla提出的良好编码五项标准，并展示了与Milner编码的相似之处。本文包括CBPV在π-i-演算、异步多态π演算和局部π演算中的编码。我们开始在Coq中对π-i-演算中编码的健全性和完备性进行形式化证明。并非所有用于形式化的引理本身都经过形式化证明，但我们认为这些未证明的引理是合理的，因为它们已通过手工证明或属于基于非正式论证的Coq形式化问题。

</details>


### [735] [StepProof: Step-by-step verification of natural language mathematical proofs](https://arxiv.org/abs/2506.10558)
**中文标题：StepProof：自然语言数学证明的逐步验证**

*Xiaolin Hu,Qinghua Zhou,Bogdan Grechuk,Ivan Y. Tyukin*

Main category: cs.LO

TL;DR: StepProof introduces a step-by-step autoformalization method for verifying natural language mathematical proofs at the sentence level, improving success rates and efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing autoformalization methods lack granularity, verifying only complete proofs. StepProof aims to enable finer, sentence-level verification to enhance accuracy and usability.

Method: StepProof breaks down proofs into verifiable subproofs for sentence-level verification, leveraging LLMs for natural language understanding and autoformalization.

Result: StepProof significantly improves proof success rates and efficiency, with minor manual adjustments further enhancing performance.

Conclusion: StepProof addresses the limitations of current autoformalization methods by enabling step-by-step verification, demonstrating its effectiveness in improving proof verification.

摘要: 交互式定理证明器（ITP）是用于将数学证明形式化验证至公理级别的强大工具。然而，它们缺乏自然语言接口仍然是一个重大限制。近年来，大型语言模型（LLM）的进展增强了对自然语言输入的理解，为自动形式化（即将自然语言证明翻译为可验证的形式化证明）铺平了道路。尽管有这些进展，现有的自动形式化方法仅限于验证完整证明，缺乏更细粒度的句子级验证能力。为了填补这一空白，我们提出了StepProof，一种新颖的自动形式化方法，专为逐步验证设计。StepProof将完整证明分解为多个可验证的子证明，实现句子级验证。实验结果表明，与传统方法相比，StepProof显著提高了证明成功率和效率。此外，我们发现对自然语言证明进行少量手动调整，使其更适合逐步验证，进一步提升了StepProof在自动形式化中的表现。

</details>


### [736] [Encoding call-by-push-value in the pi-calculus](https://arxiv.org/abs/2506.10584)
**中文标题：在π演算中编码按值推送调用**

*Benjamin Bennetzen,Nikolaj Rossander Kristensen,Peter Buus Steffensen*

Main category: cs.LO

TL;DR: 本文提出了一种将Levy的按值推送调用（CBPV）λ演算编码到π演算的方法，并证明了其正确性和完备性。通过使用内部π演算（π-i演算）简化形式化过程，同时满足Gorla提出的良好编码标准。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决在π演算中形式化CBPV时遇到的挑战，特别是使用de Bruijn索引的问题，并通过内部π演算简化证明过程。

Method: 方法包括：1) 将CBPV编码到π-i演算、异步多态π演算和局部π演算；2) 通过手工证明和部分Coq形式化验证编码的正确性和完备性；3) 利用π-i演算的特性简化双模拟证明。

Result: 结果表明，提出的编码方法在π-i演算中既正确又完备，同时满足Gorla的良好编码标准，并与Milner的编码方法有相似之处。

Conclusion: 结论是，该编码方法在π-i演算中有效解决了形式化挑战，并通过手工和部分形式化验证了其可靠性。未来可进一步完成Coq形式化。

摘要: 本报告定义了一种将Levy的按值推送调用λ演算（CBPV）编码到π演算的方法，并证明了该编码的正确性和完备性。我们通过手工方式提供了正确性、完备性及相关引理的证明。编码专门针对内部π演算（π-i演算），以规避使用de Bruijn索引在形式化中的某些挑战，同时有助于双模拟证明，因为在这种设置下，早期、晚期和开放双模拟一致，且双模拟是同余关系。此外，我们还论证了该编码满足Gorla提出的良好编码的五项标准，并展示了与Milner编码的相似之处。本文包括CBPV在π-i演算、异步多态π演算和局部π演算中的编码。我们开始在Coq中对π-i演算中编码的正确性和完备性进行形式化证明。并非所有引理都经过形式化验证，但我们认为这些未验证的引理是合理的，因为它们已通过手工证明，或仅涉及基于非形式化论证的Coq形式化。

</details>


### [737] [StepProof: Step-by-step verification of natural language mathematical proofs](https://arxiv.org/abs/2506.10558)
**中文标题：StepProof：自然语言数学证明的逐步验证**

*Xiaolin Hu,Qinghua Zhou,Bogdan Grechuk,Ivan Y. Tyukin*

Main category: cs.LO

TL;DR: StepProof是一种新型的自动形式化方法，支持逐句验证自然语言数学证明，显著提高了验证成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 交互式定理证明器（ITPs）缺乏自然语言接口，且现有自动形式化方法仅能验证完整证明，无法进行细粒度的逐句验证。StepProof旨在填补这一空白。

Method: StepProof将完整证明分解为多个可验证的子证明，实现逐句验证。同时，通过微调自然语言证明以适配逐句验证，进一步提升性能。

Result: 实验结果表明，StepProof显著提高了证明成功率和效率，且手动微调自然语言证明可进一步优化其性能。

Conclusion: StepProof为自然语言数学证明的逐句验证提供了有效解决方案，推动了自动形式化技术的发展。

摘要: 交互式定理证明器（ITPs）是用于将数学证明形式化验证至公理级别的强大工具，但其缺乏自然语言接口仍是一个显著限制。近年来，大型语言模型（LLMs）的进步增强了对自然语言输入的理解，为自动形式化（即将自然语言证明翻译为可验证的形式化证明）铺平了道路。然而，现有自动形式化方法仅限于验证完整证明，缺乏更细粒度的逐句验证能力。为填补这一空白，我们提出了StepProof，一种新型的自动形式化方法，专为细粒度的逐步验证设计。StepProof将完整证明分解为多个可验证的子证明，实现逐句验证。实验结果表明，与传统方法相比，StepProof显著提高了证明成功率和效率。此外，我们发现对自然语言证明进行少量手动调整，使其适配逐句验证，可进一步提升StepProof在自动形式化中的性能。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [738] [AC/DC: LLM-based Audio Comprehension via Dialogue Continuation](https://arxiv.org/abs/2506.10312)
**中文标题：AC/DC：基于大语言模型的对话延续音频理解**

*Yusuke Fujita,Tomoya Mizumoto,Atsushi Kojima,Lianbo Liu,Yui Sudo*

Main category: eess.AS

TL;DR: The paper introduces an LLM-based audio comprehension model that uses dialogue continuation to improve caption understanding and zero-shot instruction-following without multitask training.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the caption variation problem in audio comprehension by leveraging LLMs' dialogue continuation ability, enabling better understanding of captions beyond surface-level words.

Method: The method trains a model to generate responses as if input captions triggered a dialogue, rather than directly generating captions, enhancing comprehension through dialogue continuation.

Result: Experiments on AudioCaps, WavCaps, and Clotho datasets show the model's ability to follow unseen instructions in zero-shot scenarios, outperforming traditional approaches.

Conclusion: The conclusion highlights that dialogue continuation training effectively captures caption meaning and enables zero-shot instruction-following, even without multitask training.

摘要: 我们提出了一种基于指令跟随的音频理解模型，利用大语言模型（LLMs）的对话延续能力。该方法不直接生成训练数据中的目标字幕，而是训练模型产生响应，仿佛输入字幕触发了对话。这种对话延续训练缓解了字幕变异性问题。通过学习延续对话，模型能够捕捉字幕的深层含义，而不仅仅是表面词汇。因此，我们的模型无需多任务指令调优，仅通过音频字幕数据集训练即可实现零样本指令跟随能力。在AudioCaps、WavCaps和Clotho数据集上的实验，以及AudioBench音频场景问答测试，证明了模型能够遵循各种未见过的指令。

</details>


### [739] [RT-VC: Real-Time Zero-Shot Voice Conversion with Speech Articulatory Coding](https://arxiv.org/abs/2506.10289)
**中文标题：RT-VC：基于语音发音编码的实时零样本语音转换**

*Yisi Liu,Chenyang Wang,Hanjo Kim,Raniya Khan,Gopala Anumanchipalli*

Main category: eess.AS

TL;DR: RT-VC is a real-time zero-shot voice conversion system using articulatory features and DDSP to achieve ultra-low latency (61.4 ms) while maintaining high-quality performance.


<details>
  <summary>Details</summary>
Motivation: Voice conversion is crucial for applications like assistive communication and entertainment, but existing methods often suffer from latency issues. RT-VC aims to provide real-time, high-quality voice conversion with minimal delay.

Method: RT-VC uses an articulatory feature space to separate content and speaker characteristics, combined with differentiable digital signal processing (DDSP) for efficient vocoding, reducing latency.

Result: RT-VC achieves a CPU latency of 61.4 ms (13.3% reduction compared to SOTA) while maintaining comparable synthesis quality.

Conclusion: RT-VC demonstrates that articulatory features and DDSP can enable real-time, high-quality voice conversion with significantly reduced latency.

摘要: 语音转换已成为从辅助通信到娱乐等众多应用中的关键技术。本文提出了RT-VC，一种零样本实时语音转换系统，具有超低延迟和高质量性能。我们的方法利用发音特征空间自然解耦内容和说话人特征，从而实现更鲁棒和可解释的语音转换。此外，通过集成可微分数字信号处理（DDSP），直接从发音特征进行高效声码合成，显著降低了转换延迟。实验评估表明，在保持与当前最先进方法相当的合成质量的同时，RT-VC的CPU延迟为61.4毫秒，延迟降低了13.3%。

</details>


### [740] [Robust Unsupervised Adaptation of a Speech Recogniser Using Entropy Minimisation and Speaker Codes](https://arxiv.org/abs/2506.10653)
**中文标题：基于熵最小化和说话人编码的语音识别器鲁棒无监督自适应**

*Rogier C. van Dalen,Shucong Zhang,Titouan Parcollet,Sourav Bhattacharya*

Main category: eess.AS

TL;DR: The paper proposes a robust adaptation method for speech recognisers using entropy minimisation and speaker codes, achieving significant improvements in word error rates with minimal adaptation data.


<details>
  <summary>Details</summary>
Motivation: Speech recognisers often underperform in new environments due to limited adaptation data, which is typically unlabelled. The paper aims to make adaptation robust even with just one minute of data.

Method: The method introduces a novel loss function based on conditional entropy over multiple hypotheses (instead of a single pseudo-label) and uses a compact 'speaker code' to characterise speakers efficiently.

Result: On a noise-augmented dataset, the method achieved a 20% relative improvement in word error rate with one minute of data, increasing to 29% with 10 minutes.

Conclusion: The proposed combination of entropy minimisation and speaker codes effectively enhances the robustness of speech recogniser adaptation to new speakers with minimal data.

摘要: 语音识别器通常在特定环境下表现最佳，需要适应新环境才能发挥良好性能。对于新说话人的适应，通常数据量过少且无标签，导致微调不够鲁棒。本文提出了一种组合方法，使仅需一分钟数据的适应变得鲁棒。首先，本文提出了一种新的损失函数，即基于完整假设的条件熵，而非仅依赖于单一易错的假设或“伪标签”。使用多假设使适应对初始识别错误更具鲁棒性。其次，一种“说话人编码”以向量形式表征说话人，其长度足够短，仅需少量数据即可估计。在远场噪声增强版的Common Voice数据集上，所提方案在一分钟适应数据上实现了20%的词错误率相对改进，十分钟数据上提升至29%。

</details>


### [741] [AC/DC: LLM-based Audio Comprehension via Dialogue Continuation](https://arxiv.org/abs/2506.10312)
**中文标题：AC/DC：基于大语言模型的对话延续音频理解**

*Yusuke Fujita,Tomoya Mizumoto,Atsushi Kojima,Lianbo Liu,Yui Sudo*

Main category: eess.AS

TL;DR: 本文提出了一种基于大语言模型（LLM）的对话延续能力的音频理解模型，通过对话延续训练解决字幕变异问题，并实现零样本指令跟随能力。


<details>
  <summary>Details</summary>
Motivation: 传统的音频字幕生成方法存在字幕变异问题，即同一音频可能对应多种字幕表达。本文旨在通过对话延续训练，使模型更好地捕捉字幕的深层含义，而不仅仅是表面词汇。

Method: 提出一种指令跟随的音频理解模型，通过训练模型以对话延续的方式生成响应，而非直接生成目标字幕。这种方法利用LLM的对话能力，学习捕捉字幕的语义信息。

Result: 在AudioCaps、WavCaps和Clotho数据集上的实验表明，该模型能够在未进行多任务指令调优的情况下，实现零样本指令跟随能力，并在AudioBench音频场景问答测试中表现优异。

Conclusion: 通过对话延续训练，模型能够有效解决字幕变异问题，并展现出强大的零样本指令跟随能力，为音频理解任务提供了新的解决方案。

摘要: 我们提出了一种基于大语言模型（LLMs）对话延续能力的指令跟随音频理解模型。与直接生成训练数据中的目标字幕不同，该方法训练模型生成响应，仿佛输入字幕触发了对话。这种对话延续训练缓解了字幕变异问题。通过学习延续对话，模型能够捕捉字幕的深层含义，而不仅仅是表面词汇。因此，我们的模型即使仅基于音频字幕数据集训练，也能实现零样本指令跟随能力，而无需进行多任务指令调优。在AudioCaps、WavCaps和Clotho数据集上进行的实验，以及AudioBench音频场景问答测试，证明了我们的模型能够跟随各种未见指令的能力。

</details>


### [742] [RT-VC: Real-Time Zero-Shot Voice Conversion with Speech Articulatory Coding](https://arxiv.org/abs/2506.10289)
**中文标题：RT-VC：基于语音发音编码的实时零样本语音转换**

*Yisi Liu,Chenyang Wang,Hanjo Kim,Raniya Khan,Gopala Anumanchipalli*

Main category: eess.AS

TL;DR: RT-VC是一种实时零样本语音转换系统，通过发音特征空间和DDSP技术实现超低延迟和高性能，实验显示其CPU延迟为61.4毫秒，比当前最优方法降低13.3%。


<details>
  <summary>Details</summary>
Motivation: 语音转换技术在辅助通信和娱乐等领域具有广泛应用，但现有方法在实时性和延迟方面存在不足，因此需要开发一种高性能、低延迟的零样本语音转换系统。

Method: RT-VC利用发音特征空间自然分离内容和说话人特征，结合可微分数字信号处理（DDSP）技术直接从发音特征生成语音，显著降低转换延迟。

Result: 实验表明，RT-VC在保持与当前最优方法相当的合成质量的同时，CPU延迟为61.4毫秒，延迟降低13.3%。

Conclusion: RT-VC通过发音特征和DDSP技术实现了高性能和低延迟的实时语音转换，为语音转换技术的实际应用提供了有效解决方案。

摘要: 语音转换已成为从辅助通信到娱乐等众多应用中的关键技术。本文提出RT-VC，一种零样本实时语音转换系统，具有超低延迟和高质量性能。我们的方法利用发音特征空间自然分离内容和说话人特征，实现更鲁棒和可解释的语音转换。此外，结合可微分数字信号处理（DDSP）技术，直接从发音特征生成语音，显著降低了转换延迟。实验评估表明，在保持与当前最优方法相当的合成质量的同时，RT-VC的CPU延迟为61.4毫秒，延迟降低13.3%。

</details>


### [743] [Robust Unsupervised Adaptation of a Speech Recogniser Using Entropy Minimisation and Speaker Codes](https://arxiv.org/abs/2506.10653)
**中文标题：基于熵最小化和说话人编码的鲁棒无监督语音识别器适应方法**

*Rogier C. van Dalen,Shucong Zhang,Titouan Parcollet,Sourav Bhattacharya*

Main category: eess.AS

TL;DR: 本文提出了一种结合条件熵最小化和说话人编码的鲁棒无监督方法，用于在少量未标注数据下优化语音识别器的适应性，显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 语音识别器通常在特定环境下表现最佳，但在新环境下（如新说话人）需要适应。由于适应数据通常很少且未标注，传统方法（如基于伪标签的交叉熵）容易因初始识别错误而失效。因此，需要一种更鲁棒的适应方法。

Method: 1. 提出了一种新的损失函数——基于完整假设的条件熵，取代传统的单伪标签交叉熵，利用多假设提高鲁棒性；2. 引入“说话人编码”，用短向量表征说话人，减少数据需求。

Result: 在远场噪声增强的Common Voice数据集上，使用1分钟适应数据时，词错误率相对降低20%；使用10分钟数据时，相对降低29%。

Conclusion: 结合条件熵最小化和说话人编码的方法，显著提升了语音识别器在少量未标注数据下的适应能力，鲁棒性优于传统方法。

摘要: 语音识别器通常在特定环境下表现最佳，需要适应新环境才能发挥良好性能。然而，针对新说话人的适应数据通常很少且未标注，传统微调方法难以鲁棒地实现。本文提出了一种结合两种方法的适应方案：首先，提出了一种新的损失函数——基于完整假设的条件熵，取代传统的单伪标签交叉熵，利用多假设提高鲁棒性；其次，引入“说话人编码”，用短向量表征说话人，减少数据需求。在远场噪声增强的Common Voice数据集上，该方案在使用1分钟适应数据时，词错误率相对降低20%，使用10分钟数据时，相对降低29%。

</details>
