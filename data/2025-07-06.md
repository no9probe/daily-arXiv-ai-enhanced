<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 26]
- [cs.CV](#cs.CV) [Total: 83]
- [cs.AI](#cs.AI) [Total: 31]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 21]
- [physics.chem-ph](#physics.chem-ph) [Total: 2]
- [eess.AS](#eess.AS) [Total: 2]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.DC](#cs.DC) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 3]
- [cs.OS](#cs.OS) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CR](#cs.CR) [Total: 7]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.IR](#cs.IR) [Total: 4]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.RO](#cs.RO) [Total: 4]
- [econ.GN](#econ.GN) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2507.02088)
**中文标题：McBE：面向大型语言模型的多任务中文偏见评估基准**

*Tian Lan,Xiangdong Su,Xu Liu,Ruirui Wang,Ke Chang,Jiang Li,Guanglai Gao*

主要分类: cs.CL

摘要简述: 本文提出了一个多任务中文偏见评估基准（McBE），包含4077个偏见评估实例，涵盖12个偏见类别和82个子类别，并引入5种评估任务，用于全面评估大型语言模型（LLM）的偏见。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在各类NLP任务中的应用增多，其内在偏见逐渐显现。然而，现有偏见评估数据集多基于英语和北美文化，且仅支持单一任务评估，缺乏针对中文语言和文化的偏见评估工具。

研究方法: 研究团队构建了一个多任务中文偏见评估基准（McBE），包含4077个偏见评估实例，涵盖12个偏见类别和82个子类别，并引入5种评估任务，以全面评估LLM的偏见。此外，还评估了多个不同系列和参数规模的流行LLM。

研究结果: 评估结果显示，所有测试的LLM均表现出不同程度的偏见。研究团队对结果进行了深入分析，为LLM的偏见研究提供了新见解。

研究结论: McBE为中文语言和文化背景下的LLM偏见评估提供了全面工具，填补了现有研究的空白，并为未来偏见缓解研究奠定了基础。

中文摘要: 随着大型语言模型（LLM）在各类NLP任务中的应用增多，其内在偏见逐渐显现。因此，测量LLM的偏见对降低其伦理风险至关重要。然而，现有偏见评估数据集多基于英语和北美文化，其偏见类别并不完全适用于其他文化。基于中文语言和文化的数据集稀缺，且这些数据集通常仅支持单一评估任务，无法从多角度评估LLM的偏见。为解决这些问题，我们提出了一个多任务中文偏见评估基准（McBE），包含4077个偏见评估实例，涵盖12个偏见类别、82个子类别，并引入5种评估任务，提供了广泛的类别覆盖、内容多样性和测量全面性。此外，我们还评估了多个不同系列和参数规模的流行LLM。总体而言，这些LLM均表现出不同程度的偏见。我们对结果进行了深入分析，为LLM的偏见研究提供了新见解。

</details>


### [2] [Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization](https://arxiv.org/abs/2507.02145)
**中文标题：推理与否？对话摘要中推理型大语言模型的全面评估**

*Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira*

主要分类: cs.CL

摘要简述: 本文首次全面评估了推理型与非推理型大语言模型在对话摘要任务中的表现，发现推理型模型并未显著提升摘要质量，反而容易产生冗长和不一致的问题。


<details>
  <summary>详细信息</summary>
研究动机: 对话摘要在客服、会议分析和对话AI中具有重要应用价值，但推理型大语言模型（如长链思维模型）在对话场景中的表现尚未被系统研究。本文旨在填补这一空白。

研究方法: 研究对推理型和非推理型大语言模型在通用、角色导向和查询导向三种对话摘要范式下进行了系统评估，涵盖多种语言、领域和摘要长度，并采用自动指标和人工标准相结合的评估方法。

研究结果: 研究发现，推理型模型在对话摘要任务中并未表现出优势，反而容易生成冗长、事实不一致且不够简洁的摘要。

研究结论: 当前推理型大语言模型在对话摘要任务中存在局限性，需要针对实际场景优化建模和评估策略。

中文摘要: 对话摘要是一项具有重要实用价值的挑战性任务，广泛应用于客服、会议分析和对话AI等领域。尽管大语言模型（LLMs）在摘要任务中取得了显著进展，但逐步推理架构（如长链思维实现OpenAI-o1和DeepSeek-R1）在需要同时满足抽象性和简洁性的对话场景中的表现尚未被探索。本研究首次对最先进的推理型和非推理型大语言模型在三种主要范式（通用、角色导向和查询导向对话摘要）中进行了全面系统的评估。研究覆盖多种语言、领域和摘要长度，并利用强基准数据集（SAMSum、DialogSum、CSDS和QMSum）以及结合LLM自动指标和人工标准的先进评估协议。与其他推理密集型任务的趋势相反，我们的发现表明，逐步显式推理并未持续提升对话摘要的质量。相反，推理型模型往往容易产生冗长、事实不一致且不够简洁的摘要。通过场景特异性分析和详细案例研究，我们进一步明确了显式推理在复杂对话场景中何时以及为何无法带来益处，甚至可能阻碍摘要效果。本研究为当前推理型大语言模型的局限性提供了新见解，并强调了针对实际对话摘要任务优化建模和评估策略的必要性。

</details>


### [3] [Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer](https://arxiv.org/abs/2507.02199)
**中文标题：潜在链式思维？解码深度循环Transformer**

*Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu*

主要分类: cs.CL

摘要简述: 本文研究了深度循环Transformer模型Huginn-3.5B是否能在潜在空间中实现类似链式思维（CoT）的推理。通过多种探测技术发现，模型内部行为显示出有限的潜在CoT证据，且不同循环块的探测结果不一致。增加循环深度仅带来边际收益，远不及显式推理模型。


<details>
  <summary>详细信息</summary>
研究动机: 链式思维（CoT）推理使Transformer模型在复杂数学和多步规划任务中表现出色，但其推理步骤通常以自然语言形式外显，牺牲了效率。为探索潜在空间中的推理能力，本文研究了深度循环Transformer是否支持潜在CoT。

研究方法: 使用Huginn-3.5B模型，通过Logit Lens和Coda Lens等探测技术，分析其在算术任务中的内部行为，追踪最终和中间结果标记的秩轨迹，并评估不同循环块的探测一致性。

研究结果: 研究发现，模型内部行为显示出有限的潜在CoT证据，且不同循环块的探测结果不一致，隐藏状态的可解释性高度依赖于层索引和解码方法。增加循环深度仅带来边际收益。

研究结论: 深度循环Transformer在潜在空间中实现链式思维推理的能力有限，且探测结果不一致。显式推理模型仍具有显著优势。

中文摘要: 链式思维（CoT）推理使基于Transformer的语言模型在复杂数学和多步规划任务中表现出色。然而，在标准的仅解码器架构中，这些推理步骤以自然语言形式外显，虽提高了可解释性，但牺牲了效率。为捕捉难以用语言表达的推理过程，许多研究探索了旨在将推理内化于潜在空间的循环架构，可能支持潜在CoT。本文研究了Huginn-3.5B（一种在推理时重复使用层而不增加参数数量的深度循环Transformer）中是否出现此类推理结构。通过Logit Lens和Coda Lens等探测技术，我们分析了模型在算术任务中的内部行为。结果显示，通过追踪最终和中间结果标记的秩轨迹，仅发现有限的潜在CoT证据。此外，不同循环块的探测结果存在显著不一致，隐藏状态的可解释性高度依赖于层索引和解码方法。最后，实证表明增加循环深度仅带来边际收益，远不及显式推理模型。代码见https://github.com/wenquanlu/huginn-latent-cot。

</details>


### [4] [GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons](https://arxiv.org/abs/2507.02221)
**中文标题：GDC Cohort Copilot：一款用于从基因组数据共享库中筛选队列的AI助手**

*Steven Song,Anirudh Subramanyam,Zhenyu Zhang,Aarti Venkat,Robert L. Grossman*

主要分类: cs.CL

摘要简述: GDC Cohort Copilot 是一款开源工具，通过自然语言描述自动生成 GDC 队列过滤器，帮助用户快速构建癌症基因组队列。


<details>
  <summary>详细信息</summary>
研究动机: GDC 用户（尤其是新手）在通过图形化队列构建工具创建复杂队列时，可能难以在数百个字段中找到特定描述符。而自然语言描述可能更直观。

研究方法: 开发了 GDC Cohort Copilot，利用大型语言模型（LLM）将用户输入的自然语言描述转换为 GDC 队列过滤器，并提供交互式界面供用户进一步调整。

研究结果: 本地部署的开源 GDC Cohort LLM 在生成 GDC 队列时表现优于 GPT-4o。

研究结论: GDC Cohort Copilot 显著提升了用户构建队列的效率，展示了开源 LLM 在特定任务中的潜力。

中文摘要: 动机：基因组数据共享库（GDC）通过统一的整理与分析平台提供高质量的癌症基因组数据，用户可通过图形化队列构建工具交互式创建复杂队列。然而，用户（尤其是新手）可能难以在数百个字段中找到特定描述符，而自然语言描述可能更直观。

结果：我们推出了 GDC Cohort Copilot，这是一款开源工具，能够根据用户输入的自然语言描述自动生成 GDC 队列过滤器，并将队列导回 GDC 进行进一步分析。交互式界面允许用户进一步调整生成的队列。我们开发并评估了多种大型语言模型（LLM），结果表明本地部署的开源 GDC Cohort LLM 在生成 GDC 队列时表现优于 GPT-4o。

可用性与实现：GDC Cohort Copilot 的独立 Docker 镜像可在 https://quay.io/repository/cdis/gdc-cohort-copilot 获取，源代码位于 https://github.com/uc-cdis/gdc-cohort-copilot，GDC Cohort LLM 权重可在 https://huggingface.co/uc-ctds 下载。

</details>


### [5] [MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent](https://arxiv.org/abs/2507.02259)
**中文标题：MemAgent：基于多对话强化学习的记忆代理重塑长上下文LLM**

*Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou*

主要分类: cs.CL

摘要简述: MemAgent是一种基于多对话强化学习的记忆代理，通过分段读取和覆盖策略优化长文本处理，实现了从8K上下文训练到3.5M QA任务的性能损失小于5%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管通过长度外推、高效注意力和内存模块有所改进，但在长文本处理中，如何以线性复杂度处理无限长文档且在外推时性能不下降仍是终极挑战。

研究方法: MemAgent采用分段读取文本并更新内存的覆盖策略，扩展DAPO算法以支持独立上下文的多对话生成训练。

研究结果: MemAgent在32K文本上训练后，能够外推到3.5M QA任务，性能损失小于5%，并在512K RULER测试中达到95%以上的表现。

研究结论: MemAgent展示了卓越的长上下文处理能力，为长文本任务提供了一种高效的端到端解决方案。

中文摘要: 尽管通过长度外推、高效注意力和内存模块有所改进，但在长文本处理中，如何以线性复杂度处理无限长文档且在外推时性能不下降仍是终极挑战。我们直接以端到端方式优化长文本任务，并引入了一种新颖的代理工作流程MemAgent，它分段读取文本并使用覆盖策略更新内存。我们扩展了DAPO算法，通过独立上下文的多对话生成促进训练。MemAgent展示了卓越的长上下文能力，能够从8K上下文训练外推到3.5M QA任务，性能损失小于5%，并在512K RULER测试中达到95%以上的表现。

</details>


### [6] [DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning](https://arxiv.org/abs/2507.02302)
**中文标题：DoMIX：一种利用领域知识进行高效微调的框架**

*Dohoon Kim,Donghun Kang,Taesup Moon*

主要分类: cs.CL

摘要简述: 本文提出DoMIX，一种利用LoRA模块的高效领域自适应预训练框架，解决了现有方法的高计算成本、数据顺序敏感性和单一模型通用性问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有持续领域自适应预训练方法存在高计算成本、对数据顺序敏感以及无法为特定任务提供定制模型的问题，亟需一种高效且灵活的解决方案。

研究方法: DoMIX采用LoRA模块，实现高效并行领域自适应预训练，对领域顺序不敏感，并能利用累积知识为特定任务提供定制化预训练模型。

研究结果: 实验表明，DoMIX在计算效率和模型性能上优于现有方法，并能扩展到标准LLM微调场景。

研究结论: DoMIX为领域自适应预训练提供了一种高效、灵活且可扩展的解决方案，适用于多种任务场景。

中文摘要: 领域自适应预训练（DAP）因其在微调预训练模型中的有效性而受到关注。在此基础上，持续DAP被探索用于开发能够逐步整合不同领域数据集的预训练模型。然而，现有持续DAP方法存在以下局限性：（1）训练过程中计算成本和GPU内存占用高；（2）对增量数据顺序敏感；（3）为所有终端任务提供单一通用模型，这与DAP的本质相矛盾。本文提出DoMIX，一种利用LoRA模块（一种代表性的参数高效微调方法）的新方法，解决了这些挑战。我们的方法实现了高效且并行的领域自适应预训练，对领域顺序不敏感，并能有效利用累积知识为特定任务提供定制化的预训练模型。我们还展示了该方法可以扩展到标准LLM微调场景。代码可在https://github.com/dohoonkim-ai/DoMIX获取。

</details>


### [7] [Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models](https://arxiv.org/abs/2507.02357)
**中文标题：Coling-UniA在SciVQA 2025中的表现：基于少样本检索和置信度集成策略的多模态大语言模型**

*Christian Jaumann,Annemarie Friedrich,Rainer Lienhart*

主要分类: cs.CL

摘要简述: 本文介绍了参加SciVQA 2025共享任务的系统，结合多模态大语言模型和少样本检索策略，根据图像和问题类型选择模型和设置，并通过模型置信度选择答案，最终在盲测数据中排名第三。


<details>
  <summary>详细信息</summary>
研究动机: SciVQA 2025共享任务旨在解决科学视觉问答问题，本文旨在通过结合多模态大语言模型和少样本检索策略，提升问答系统的性能。

研究方法: 系统采用两种多模态大语言模型的集成方法，结合多种少样本检索策略，根据图像和问题类型动态选择模型和设置，并通过模型置信度筛选答案。

研究结果: 在盲测数据中，系统在七支队伍中排名第三，平均F1得分为85.12（基于ROUGE-1、ROUGE-L和BERTS指标）。

研究结论: 本文提出的方法在科学视觉问答任务中表现优异，展示了多模态大语言模型和少样本检索策略的有效性，代码已公开。

中文摘要: 本文描述了我们在SciVQA 2025科学视觉问答共享任务中的系统。我们的系统采用了两种多模态大语言模型的集成方法，并结合多种少样本检索策略。模型和少样本设置根据图像和问题类型动态选择，并通过模型置信度筛选答案。在盲测数据中，我们的系统在七支队伍中排名第三，平均F1得分为85.12（基于ROUGE-1、ROUGE-L和BERTS指标）。代码已公开。

</details>


### [8] [QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers](https://arxiv.org/abs/2507.02364)
**中文标题：QFFN-BERT：混合量子-经典Transformer中深度、性能与数据效率的实证研究**

*Pilsung Kang*

主要分类: cs.CL

摘要简述: 本文提出QFFN-BERT，一种混合量子-经典Transformer模型，通过用参数化量子电路（PQC）替换BERT中的前馈网络（FFN）模块，显著减少参数数量并提升性能。实验表明，该模型在完全数据设置中超越经典模型，并在少样本学习中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 标准Transformer中FFN模块占参数总量的三分之二，而现有研究主要关注自注意力模块。本文旨在探索PQC在FFN中的应用，研究其深度、表达能力和可训练性之间的权衡。

研究方法: 设计了一种混合量子-经典Transformer（QFFN-BERT），用PQC替换BERT的FFN模块。PQC采用残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略，以确保稳定训练和高表达能力。

研究结果: 实验在SST-2和DBpedia基准测试中显示，QFFN-BERT在完全数据设置中达到基线模型的102.0%准确率，同时减少FFN参数99%以上。在少样本学习中，模型表现一致且具有竞争力。

研究结论: 研究表明，PQC可以作为经典FFN的高效替代方案，尤其在数据效率方面表现突出。通过合理设计，PQC能够实现高性能和参数效率的双重优势。

中文摘要: 参数化量子电路（PQC）近年来成为增强神经网络表达能力的潜在组件。本文提出QFFN-BERT，一种混合量子-经典Transformer，其中紧凑BERT变体的前馈网络（FFN）模块被PQC层取代。这一设计的动机在于FFN在标准Transformer编码器块中占据约三分之二的参数。尽管先前研究主要将PQC集成到自注意力模块中，本文聚焦于FFN，并系统研究了PQC深度、表达能力和可训练性之间的权衡。最终PQC架构包含残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略，以确保稳定训练和高表达能力。在SST-2和DBpedia基准测试中，实验表明两点关键发现：首先，精心配置的QFFN-BERT在完全数据设置中达到基线模型102.0%的准确率，超越经典对应模型，同时减少FFN参数99%以上；其次，该模型在少样本学习中表现一致且具有竞争力，证实其数据效率潜力。这些结果得到了一项关于未优化PQC的消融研究支持，表明PQC在与深度学习原则协同设计时，可以作为经典FFN的强大且参数高效的替代方案。

</details>


### [9] [Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection](https://arxiv.org/abs/2507.02378)
**中文标题：基于分布一致性和多样性的高效代码LLM训练数据选择方法**

*Weijie Lyu,Sheng-Jun Huang,Xuan Xia*

主要分类: cs.CL

摘要简述: 本文提出一种基于分布一致性和多样性的代码数据选择方法，显著提升LLM训练效率和性能，仅用10K样本即超越92K全量基线。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型（LLM）训练依赖海量数据，但忽视数据质量，导致效率低下。本文旨在通过高质量数据选择优化训练过程。

研究方法: 采用参数化模型筛选代码数据，确保所选子集分布一致且多样，从而提升数据质量。

研究结果: 实验显示，仅用10K样本，方法在HumanEval和MBPP上分别提升2.4%和2.3%，优于其他采样方法。

研究结论: 该方法高效提升模型性能，同时大幅降低计算成本，为代码LLM训练提供新思路。

中文摘要: 近年来，大语言模型（LLM）的进步显著提升了代码生成和程序理解能力，推动了软件工程的发展。当前方法主要通过利用大量数据提升模型性能，但过度关注数据量而忽视质量，导致训练效率低下。为此，我们提出一种基于参数化模型的代码数据选择方法，旨在同时提升训练效率和模型性能。该方法通过优化参数化模型，确保所选数据子集分布一致且多样，从而保证数据质量。实验结果表明，仅使用10K样本，我们的方法在HumanEval和MBPP上分别取得2.4%和2.3%的提升，优于92K全量基线及其他采样方法。这表明我们的方法不仅能有效提升模型性能，还能显著降低计算成本。

</details>


### [10] [Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability](https://arxiv.org/abs/2507.02407)
**中文标题：跨领域数据集对Akan语音识别模型的基准测试：性能、可扩展性和适应性的比较评估**

*Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame*

主要分类: cs.CL

摘要简述: 本研究通过比较七种基于Transformer架构的Akan语音识别模型（如Whisper和Wav2Vec2）在四个不同领域的Akan语音数据集上的表现，揭示了模型性能对领域的依赖性，并分析了Whisper和Wav2Vec2在错误行为上的差异。


<details>
  <summary>详细信息</summary>
研究动机: 现有语音识别研究多基于同领域数据集评估模型，而忽略了模型在多样化语音场景中的泛化能力。本研究旨在填补这一空白，评估Akan语音识别模型在不同领域中的表现。

研究方法: 研究使用了四个Akan语音数据集，涵盖文化相关图像描述、非正式对话、圣经诵读和自发财务对话等领域。通过比较词错误率和字符错误率，评估了七种基于Transformer架构的模型（包括Whisper和Wav2Vec2）的性能。

研究结果: 结果显示模型性能高度依赖领域，训练领域外的表现显著下降。Whisper模型生成流畅但可能误导的转录错误，而Wav2Vec2在陌生输入下产生更明显但不易解释的输出。

研究结论: 研究强调了针对低资源语言（如Akan）的领域适应技术、自适应路由策略和多语言训练框架的重要性，并指出在选择架构时需权衡错误可读性与透明性。

中文摘要: 大多数现有的自动语音识别（ASR）研究使用同领域数据集评估模型，但很少评估其在多样化语音场景中的泛化能力。本研究通过使用四个Akan语音语料库对七种基于Transformer架构（如Whisper和Wav2Vec2）的Akan ASR模型进行基准测试，填补了这一空白。这些数据集涵盖多个领域，包括文化相关图像描述、非正式对话、圣经诵读和自发财务对话。通过比较词错误率和字符错误率，研究发现模型性能高度依赖领域，仅在训练领域内表现最优，而在不匹配场景中准确性显著下降。此外，研究还揭示了Whisper和Wav2Vec2架构在错误行为上的差异：微调的Whisper Akan模型生成更流畅但可能误导的转录错误，而Wav2Vec2在遇到陌生输入时产生更明显但不易解释的输出。这种ASR错误在可读性与透明性之间的权衡，在选择低资源语言（LRL）应用的架构时应予以考虑。这些发现强调了针对Akan及其他低资源语言的领域适应技术、自适应路由策略和多语言训练框架的必要性。

</details>


### [11] [A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages](https://arxiv.org/abs/2507.02428)
**中文标题：低资源语言中受损语音社区驱动数据收集的实用指南**

*Sumaya Ahmed Salihs,Isaac Wiafe,Jamal-Deen Abdulai,Elikem Doe Atsakpo,Gifty Ayoka,Richard Cave,Akon Obu Ekpezu,Catherine Holloway,Katrin Tomanek,Fiifi Baffoe Payin Winful*

主要分类: cs.CL

摘要简述: 本研究提出了一种社区驱动的数据收集方法，用于构建低资源语言中受损语音的自动语音识别（ASR）模型，并开发了一本“食谱”以指导实践。通过加纳的阿坎语数据集验证了方法的可行性。


<details>
  <summary>详细信息</summary>
研究动机: 旨在通过社区驱动的数据收集和ASR模型构建，推动低资源语言中受损语音识别技术的民主化，满足特殊群体的需求。

研究方法: 开发了一本“食谱”指导社区驱动的数据收集和ASR模型构建，并以加纳的阿坎语为案例，收集了多样化的受损语音样本。

研究结果: 成功创建了首个阿坎语受损语音开源数据集，并展示了开源ASR模型在识别受损语音方面的初步优化结果。

研究结论: 通过社区驱动的方法和开源工具，能够为低资源语言中的受损语音识别提供技术支持，推动包容性ASR技术的发展。

中文摘要: 本研究提出了一种收集语音样本的方法，用于构建低资源语言中受损语音的自动语音识别（ASR）模型。其目标是通过开发一本“食谱”来指导社区驱动的数据收集和ASR模型构建，从而推动ASR技术的民主化。作为概念验证，本研究整理了首个阿坎语（加纳广泛使用的土著语言）的受损语音开源数据集。研究涵盖了来自不同背景的语音受损参与者。最终的数据集、食谱和开源工具均已公开，以帮助研究人员和从业者为语音受损群体开发定制化的包容性ASR技术。此外，本研究还展示了开源ASR模型在识别阿坎语受损语音方面的初步优化结果。

</details>


### [12] [IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders](https://arxiv.org/abs/2507.02506)
**中文标题：IndianBailJudgments-1200：一个用于印度保释判决法律NLP的多属性数据集**

*Sneha Deshmukh,Prathmesh Kamble*

主要分类: cs.CL

摘要简述: 本文介绍了IndianBailJudgments-1200，一个包含1200份印度保释判决的多属性数据集，支持法律NLP任务如结果预测和公平性分析。


<details>
  <summary>详细信息</summary>
研究动机: 由于印度等地区缺乏结构化数据集，法律NLP发展受限。本文旨在填补这一空白，提供首个专注于印度保释法学的公开数据集。

研究方法: 通过提示工程优化的GPT-4o流水线生成标注，涵盖20多个属性（如保释结果、IPC条款等），并验证一致性。

研究结果: 数据集包含1200份标注判决，支持多种法律NLP任务，是首个公开的印度保释法学资源。

研究结论: IndianBailJudgments-1200为法律NLP研究提供了重要资源，填补了印度保释法学数据的空白。

中文摘要: 由于缺乏结构化数据集，印度等地区的法律NLP发展滞后。我们推出了IndianBailJudgments-1200，这是一个包含1200份印度法院保释判决的新基准数据集，标注了20多个属性，包括保释结果、IPC条款、犯罪类型和法律推理。标注通过提示工程优化的GPT-4o流水线生成并验证一致性。该资源支持多种法律NLP任务，如结果预测、摘要生成和公平性分析，是首个公开的专注于印度保释法学的数据集。

</details>


### [13] [WebSailor: Navigating Super-human Reasoning for Web Agent](https://arxiv.org/abs/2507.02592)
**中文标题：WebSailor：为网络代理导航超人类推理**

*Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou*

主要分类: cs.CL

摘要简述: WebSailor是一种后训练方法，通过结构化采样和信息模糊化生成高不确定性任务，结合RFT冷启动和高效的强化学习算法DUPO，显著提升了开源代理在复杂信息搜索任务中的表现，接近专有代理的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有开源模型在复杂信息搜索任务中表现不佳，无法像专有代理（如DeepResearch）那样处理极端不确定性。WebSailor旨在通过系统性方法填补这一能力差距。

研究方法: WebSailor采用结构化采样和信息模糊化生成高不确定性任务，结合RFT冷启动和DUPO强化学习算法，训练代理在复杂信息环境中高效导航。

研究结果: WebSailor在复杂信息搜索任务中显著优于所有开源代理，性能接近专有代理，缩小了能力差距。

研究结论: WebSailor通过系统性后训练方法成功提升了开源代理在复杂信息搜索任务中的表现，为填补与专有代理的差距提供了有效途径。

中文摘要: 超越人类认知限制是LLM训练的关键前沿。专有代理系统（如DeepResearch）在极端复杂的信息搜索基准（如BrowseComp）上展示了超人类能力，这是此前开源模型无法实现的。我们认为其成功依赖于开源模型中缺乏的一种复杂推理模式：在广阔信息环境中系统性降低极端不确定性的能力。基于这一洞察，我们提出了WebSailor，一种完整的后训练方法，旨在培养这一关键能力。我们的方法包括通过结构化采样和信息模糊化生成新颖的高不确定性任务、RFT冷启动以及高效的代理强化学习算法DUPO。通过这一集成流程，WebSailor在复杂信息搜索任务中显著优于所有开源代理，性能接近专有代理，缩小了能力差距。

</details>


### [14] [Revisiting Active Learning under (Human) Label Variation](https://arxiv.org/abs/2507.02593)
**中文标题：重新审视（人类）标签变异下的主动学习**

*Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher*

主要分类: cs.CL

摘要简述: 本文探讨了在人类标签变异（HLV）背景下重新审视主动学习（AL）的必要性，提出了一种将HLV纳入AL循环的概念框架，并讨论了大型语言模型（LLM）作为标注者的整合。


<details>
  <summary>详细信息</summary>
研究动机: 高质量标注数据的获取是监督学习中的瓶颈，而标签变异（LV）尤其是人类标签变异（HLV）常被忽视。现有主动学习方法基于简化假设，未充分考虑HLV的复杂性。本文旨在填补这一空白。

研究方法: 通过分解观察到的标签变异为信号（如HLV）和噪声（如标注错误），提出一个概念框架，将HLV融入AL循环的实例选择、标注者选择和标签表示等环节，并探讨LLM作为标注者的应用。

研究结果: 提出了一个HLV感知的主动学习框架，为实际标注中的复杂性提供了更准确的建模方法，并展示了LLM在标注中的潜在作用。

研究结论: 本文为HLV感知的主动学习奠定了概念基础，强调了在AL中考虑HLV的重要性，为未来研究提供了方向。

中文摘要: 高质量标注数据的获取仍然是应用监督学习中的限制因素。标签变异（LV），即同一实例的不同标签，在自然语言处理等领域尤为常见，但标注框架通常仍假设存在单一真实标签，忽视了人类标签变异（HLV）作为信息信号的存在。同样，主动学习（AL）作为一种优化有限标注预算的方法，通常依赖于多个简化假设，这些假设在承认HLV的实际情况下很少成立。本文探讨了关于真实性和标签性质的基本假设，强调需要将观察到的LV分解为信号（如HLV）和噪声（如标注错误）。我们调查了AL和（H）LV社区如何处理或忽视这些区别，并提出了一个概念框架，将HLV融入AL循环的各个环节，包括实例选择、标注者选择和标签表示。此外，我们还讨论了大型语言模型（LLM）作为标注者的整合。本文旨在为HLV感知的主动学习奠定概念基础，更好地反映实际标注的复杂性。

</details>


### [15] [MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion](https://arxiv.org/abs/2507.02595)
**中文标题：MPF：通过多视角融合在部署后对齐和去偏语言模型**

*Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama*

主要分类: cs.CL

摘要简述: MPF是一种新颖的后训练对齐框架，通过多视角融合技术减少大型语言模型（LLM）的偏见，无需大量提示工程或微调。


<details>
  <summary>详细信息</summary>
研究动机: 随着对减少语言模型偏见的迫切需求，MPF旨在提供一种可扩展且可解释的方法，以对齐和缓解LLM中的偏见。

研究方法: MPF基于SAGED管道，通过多视角生成暴露和调整LLM输出的偏见，将其与人类基准（如HR专业人士的情感分布）对齐，并通过采样和平衡响应来引导生成。

研究结果: 实验表明，MPF能够将LLM的情感分布与反事实基准（绝对平等）和HR基准（偏向顶尖大学）对齐，减少KL散度和校准误差，并推广到未见问题。

研究结论: MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，适用于已部署的LLM，无需大量提示工程或微调。

中文摘要: 多视角融合（MPF）是一种新颖的后训练对齐框架，旨在满足减少偏见的迫切需求。基于SAGED管道（一种自动构建偏见基准和提取可解释基准分布的系统），MPF利用多视角生成暴露和调整LLM输出的偏见，并与细致的人类基准对齐。通过将基准（如HR专业人士的情感分布）分解为可解释的视角组件，MPF通过采样和平衡响应来引导生成，权重由分解得到的概率决定。实验表明，MPF能够将LLM的情感分布与反事实基准（绝对平等）和HR基准（偏向顶尖大学）对齐，减少KL散度和校准误差，并推广到未见问题。这表明MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，适用于已部署的LLM，无需大量提示工程或微调。

</details>


### [16] [Exploring Gender Bias Beyond Occupational Titles](https://arxiv.org/abs/2507.02679)
**中文标题：探索超越职业名称的性别偏见**

*Ahmed Sabir,Rajesh Sharama*

主要分类: cs.CL

摘要简述: 本文研究了性别与语境偏见之间的关联，重点关注动作动词、宾语名词及职业名称，并提出了新数据集GenderLexicon和评估框架，以量化性别偏见。


<details>
  <summary>详细信息</summary>
研究动机: 探讨性别偏见不仅限于职业刻板印象，揭示语境中其他语言元素（如动词、名词）的性别偏见。

研究方法: 引入GenderLexicon数据集和评估框架，通过评分量化语境中的性别偏见，提升偏见的可解释性。

研究结果: 验证了性别偏见在职业以外语境中的存在，并在五个多样化数据集（包括日语数据集）上验证了方法的有效性。

研究结论: 研究证实了性别偏见的广泛存在，提出的框架为识别和解释性别偏见提供了新工具。

中文摘要: 本研究探讨了性别与语境偏见之间的关联，重点关注动作动词、宾语名词及职业名称。我们引入了新数据集GenderLexicon和一个能够评估语境偏见及其相关性别偏见的框架。该模型通过评分解释偏见，从而提升性别偏见的可解释性。此外，我们的研究证实了性别偏见不仅限于职业刻板印象。为验证方法的有效性，我们在五个多样化数据集（包括一个日语数据集）上进行了评估。

</details>


### [17] [Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers](https://arxiv.org/abs/2507.02694)
**中文标题：大型语言模型能否识别科学研究中的关键局限性？对AI研究论文的系统性评估**

*Zhijian Xu,Yilun Zhao,Manasi Patwardhan,Lovekesh Vig,Arman Cohan*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型（LLM）在识别科学研究中的关键局限性方面的潜力，提出了一个全面的局限性分类法，并开发了LimitGen基准来评估LLM的能力。通过合成数据集和真实人类撰写的局限性数据，结合文献检索，提升了LLM在识别局限性方面的表现。


<details>
  <summary>详细信息</summary>
研究动机: 随着科学出版物数量的激增，同行评审过程面临巨大压力。尽管LLM在科学任务中表现出潜力，但其在识别论文局限性方面的能力尚未充分研究。本文旨在填补这一空白，探索LLM如何辅助同行评审。

研究方法: 本文首先提出了一个针对AI领域的局限性分类法，并开发了LimitGen基准，包含合成数据集LimitGen-Syn和真实数据集LimitGen-Human。通过文献检索增强LLM系统，提升其识别局限性的能力。

研究结果: 实验表明，结合文献检索的LLM系统能够更准确地识别论文的局限性，并提供更具建设性的反馈。LimitGen基准为评估LLM在局限性识别方面的能力提供了有效工具。

研究结论: 本文证明了LLM在辅助同行评审、识别论文局限性方面的潜力，并通过LimitGen基准和文献检索方法提升了其性能。这为未来LLM在科学评审中的应用奠定了基础。

中文摘要: 同行评审是科学研究的基础，但日益增长的出版物数量加剧了这一专业知识密集型过程的挑战。尽管大型语言模型（LLM）在多项科学任务中展现出潜力，但其在辅助同行评审（尤其是识别论文局限性）方面的潜力仍未得到充分研究。我们首先提出了一个针对AI领域的科学研究局限性分类法。基于此分类法，我们开发了LimitGen，这是首个用于评估LLM支持早期反馈和补充人类同行评审能力的综合性基准。该基准包含两个子集：LimitGen-Syn（通过对高质量论文进行受控扰动生成的合成数据集）和LimitGen-Human（真实人类撰写的局限性数据集）。为了提升LLM系统识别局限性的能力，我们通过文献检索对其进行了增强，这对于将局限性识别建立在先前的科学发现基础上至关重要。我们的方法提升了LLM系统在研究论文中生成局限性的能力，使其能够提供更具体和建设性的反馈。

</details>


### [18] [Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens](https://arxiv.org/abs/2507.02744)
**中文标题：通过最小可产生差异（JPD）测量元音产生空间的粒度**

*Peter Viechnicki*

主要分类: cs.CL

摘要简述: 本研究通过测量‘最小可产生差异’（JPD），探究了人类元音发音控制的精确度，发现JPD在F1 X F2空间中的范围为14至51 mels，为语音产生理论和元音系统结构提供了新见解。


<details>
  <summary>详细信息</summary>
研究动机: 过去研究表明，人类元音发音的复杂协调动作受听觉空间区域的控制机制影响，但控制精度尚不明确。本研究旨在量化这种控制精度，即两个元音刺激在听觉空间中需多远才能被可靠模仿。

研究方法: 研究采用元音模仿范式，测量两组英语使用者在发前元音时的‘最小可产生差异’（JPD）。

研究结果: JPD在F1 X F2空间中的估计范围为14至51 mels。

研究结论: 研究结果为语音产生的片段理论提供了支持，并为人类元音系统的可能结构设定了理论下限，解释了观察到的元音数量和模式趋势。

中文摘要: 过去几十年的研究表明，人类元音发音的复杂协调动作部分受听觉空间区域的控制机制调控。目标区域内的亚音位控制也得到了证实，但其控制精度尚不清楚。本研究通过探究两个元音刺激在听觉空间中需多远才能被可靠模仿（即‘最小可产生差异’，JPD），首次测量了两组英语使用者在发前元音时的JPD。JPD在F1 X F2空间中的估计范围为14至51 mels。这一发现对语音产生的片段理论具有重要意义，并通过设定两个元音音位在说话者共振峰空间中可能的最小距离，为人类元音系统的可能结构提供了理论下限，从而解释了观察到的元音数量和模式趋势。

</details>


### [19] [Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs](https://arxiv.org/abs/2507.02778)
**中文标题：自我纠正基准：揭示并解决大型语言模型中的自我纠正盲点**

*Ken Tsui*

主要分类: cs.CL

摘要简述: 大型语言模型（LLM）存在自我纠正盲点，无法纠正自身输出的错误。本文通过引入Self-Correction Bench框架，测试14个模型，发现平均盲点率为64.5%。研究发现，训练数据构成是主要原因，而简单的干预（如添加“Wait”）可显著减少盲点。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM具有变革性，但其在自我纠正方面存在系统性盲点，无法纠正自身输出的错误。这种局限性影响了模型的可靠性和可信度，因此需要系统研究并提出改进方法。

研究方法: 本文提出Self-Correction Bench框架，通过控制性错误注入（三个复杂度级别）测量LLM的自我纠正盲点。测试了14个模型，并分析训练数据构成对盲点的影响。

研究结果: 测试结果显示，平均盲点率为64.5%。研究发现，训练数据中缺乏错误纠正序列是主要原因，而简单的干预（如添加“Wait”）可将盲点减少89.3%。

研究结论: 本文揭示了LLM在自我纠正方面的系统性盲点，并指出训练数据构成是关键因素。研究结果为提升LLM的可靠性和可信度提供了潜在途径。

中文摘要: 尽管大型语言模型（LLM）具有变革性，但它们仍会犯错并可能探索无效的推理路径。自我纠正是可信赖LLM（尤其是自回归LLM）的重要能力。虽然LLM能够识别用户输入中的错误，但它们表现出系统性的“自我纠正盲点”——无法纠正自身输出中的相同错误。为系统研究这一现象，我们引入了Self-Correction Bench框架，通过三个复杂度级别的控制性错误注入来测量这一现象。测试14个模型后，我们发现平均盲点率为64.5%。我们发现多项证据表明，这一局限性与训练数据构成有关：人类训练演示主要展示无错误的响应，而非错误纠正序列，这与通过结果反馈学习错误纠正的RL训练模型不同。值得注意的是，仅添加“Wait”即可将盲点减少89.3%，表明这一能力存在但需要激活。我们的工作揭示了当前LLM的一个关键局限性，并为其可靠性和可信度的提升提供了潜在途径。

</details>


### [20] [Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models](https://arxiv.org/abs/2507.02799)
**中文标题：推理就是一切吗？探究推理语言模型时代的偏见问题**

*Riccardo Cantini,Nicola Gabriele,Alessio Orsino,Domenico Talia*

主要分类: cs.CL

摘要简述: 研究发现，具备推理能力的语言模型（RLMs）在公平性和鲁棒性上表现复杂，推理机制可能无意中增加偏见风险。


<details>
  <summary>详细信息</summary>
研究动机: 推理语言模型（RLMs）因其多步推理能力受到关注，但其对社会偏见的鲁棒性影响尚不明确。本文旨在探究推理能力对模型公平性和安全性的影响。

研究方法: 利用CLEAR-Bias基准，系统评估RLMs在不同社会文化维度上的表现，采用LLM-as-a-judge方法自动评分，并结合越狱技术测试内置安全机制强度。

研究结果: 结果显示，具备推理能力的模型（如CoT提示或微调推理轨迹）比无推理机制的模型更容易引发偏见，推理可能无意中强化刻板印象。

研究结论: 研究挑战了推理能力必然提升鲁棒性的假设，强调需要设计更具偏见意识的推理方法。

中文摘要: 推理语言模型（RLMs）因其通过链式思维（CoT）提示或微调推理轨迹完成复杂多步推理任务的能力而受到关注。尽管这些能力有望提高可靠性，但其对社会偏见鲁棒性的影响尚不明确。本文利用最初为大型语言模型（LLMs）设计的CLEAR-Bias基准，研究RLMs对偏见引发的对抗鲁棒性。我们系统评估了最先进的RLMs在不同社会文化维度上的表现，采用LLM-as-a-judge方法进行自动安全评分，并结合越狱技术评估内置安全机制的强度。研究回答了三个关键问题：（i）推理能力的引入如何影响模型的公平性和鲁棒性；（ii）微调推理的模型是否比依赖CoT提示的模型更安全；（iii）针对偏见引发的越狱攻击成功率如何随推理机制变化。结果表明，推理能力与偏见安全性之间存在复杂关系。出乎意料的是，具备显式推理能力的模型（无论是通过CoT提示还是微调推理轨迹）通常比无推理机制的基准模型更容易引发偏见，表明推理可能无意中为刻板印象强化开辟新途径。具备推理能力的模型似乎比依赖CoT提示的模型稍安全，后者尤其容易通过故事提示、虚构角色或奖励塑造指令受到上下文重构攻击。这些结果挑战了推理必然提升鲁棒性的假设，并强调了设计更具偏见意识的推理方法的必要性。

</details>


### [21] [Multimodal Mathematical Reasoning with Diverse Solving Perspective](https://arxiv.org/abs/2507.02804)
**中文标题：多模态数学推理中的多样化解题视角**

*Wenhao Shi,Zhiqiang Hu,Yi Bin,Yang Yang,See-Kiong Ng,Heng Tao Shen*

主要分类: cs.CL

摘要简述: 本文提出MathV-DP数据集和Qwen-VL-DP模型，通过多样化解题视角和强化学习提升多模态数学推理能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型（MLLMs）在数学推理中依赖单一图像-文本对和单解监督，忽视了多样化的解题视角和内部反思。本文旨在通过多样化解题轨迹和强化学习提升模型的推理能力。

研究方法: 提出MathV-DP数据集，包含多样化解题轨迹；基于Qwen-VL构建Qwen-VL-DP模型，通过监督学习和基于规则的强化学习（GRPO）优化，结合正确性判别和多样性奖励函数。

研究结果: 在MathVista和Math-V基准测试中，Qwen-VL-DP在准确性和生成多样性上显著优于现有MLLMs，验证了多样化解题视角的重要性。

研究结论: 多样化解题视角和反思性推理对多模态数学推理至关重要，Qwen-VL-DP为未来研究提供了新方向。

中文摘要: 近年来，大规模强化学习（RL）的进展显著提升了大型语言模型（LLMs）在数学领域的推理能力。然而，当前用于数学推理的多模态LLMs（MLLMs）通常依赖一对一的图像-文本对和单解监督，忽视了有效推理视角和内部反思的多样性。本文提出MathV-DP数据集，为每个图像-问题对捕捉多样化解题轨迹，提供更丰富的推理监督。我们进一步提出Qwen-VL-DP模型，基于Qwen-VL构建，通过监督学习微调，并利用基于规则的RL方法——组相对策略优化（GRPO）增强，该方法整合了正确性判别和多样性感知奖励函数。我们的方法强调从多样化解题视角中学习，并区分正确但不同的解法。在MathVista的minitest和Math-V基准测试中的广泛实验表明，Qwen-VL-DP在准确性和生成多样性上显著优于现有MLLMs，凸显了多样化视角和反思性推理在多模态数学推理中的重要性。

</details>


### [22] [SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model](https://arxiv.org/abs/2507.02822)
**中文标题：SynapseRoute：基于双状态大语言模型的自动路由切换框架**

*Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun*

主要分类: cs.CL

摘要简述: 本文提出SynapseRoute框架，通过动态路由将查询分配到高成本推理或低成本非推理模式，优化大语言模型在医疗问答中的性能与成本平衡。实验显示其提升准确性并显著降低时间和资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型的广泛应用，需平衡性能与成本。研究发现58%的医疗问题无需高成本推理即可解决，表明动态路由可优化效率与用户体验。

研究方法: 提出SynapseRoute框架，基于机器学习动态分配查询到高成本推理或低成本非推理模式，避免对简单问题过度推理。

研究结果: 实验表明，SynapseRoute在医疗数据集上准确性提升（0.8390 vs. 0.8272），推理时间减少36.8%，token消耗降低39.66%。

研究结论: SynapseRoute有效平衡准确性、延迟与成本，避免过度推理的负面影响，并引入AIT指标综合评估三者权衡。

中文摘要: 随着大语言模型（LLMs）在实际应用中的广泛采用，选择合适的模型不仅需权衡性能，还需考虑运营成本。具备推理能力的模型进一步扩大了“思考”（高推理）与“非思考”（快速、低成本）模式之间的成本差距。本研究发现，约58%的医疗问题仅通过非思考模式即可准确回答，无需高成本推理过程。这凸显了问题复杂性的明显二分性，并表明基于复杂性动态路由查询可优化准确性、成本效率和整体用户体验。基于此，我们提出SynapseRoute，一种基于机器学习的动态路由框架，智能地将输入查询分配到思考或非思考模式。在多个医疗数据集上的实验结果表明，SynapseRoute不仅比单独使用思考模式提高了整体准确性（0.8390 vs. 0.8272），还减少了36.8%的推理时间和39.66%的token消耗。重要的是，定性分析表明，对简单问题过度推理会导致不必要的延迟甚至准确性下降，而我们的自适应路由避免了这一问题。最后，本研究进一步引入准确性-推理-令牌（AIT）指数，全面评估准确性、延迟与token成本之间的权衡。

</details>


### [23] [Generalizing Verifiable Instruction Following](https://arxiv.org/abs/2507.02833)
**中文标题：泛化可验证指令遵循**

*Valentina Pyatkin,Saumya Malik,Victoria Graf,Hamish Ivison,Shengyi Huang,Pradeep Dasigi,Nathan Lambert,Hannaneh Hajishirzi*

主要分类: cs.CL

摘要简述: 本文提出了一种新的基准IFBench，用于评估语言模型在遵循多样化且具有挑战性的输出约束时的泛化能力，并通过强化学习与可验证奖励（RLVR）显著提升了模型的精确指令遵循能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前的语言模型在遵循用户添加的输出约束（如“仅回答是或否”）时表现不佳，且容易在少数测试约束上过拟合。本文旨在解决这一问题，并提升模型在未见约束上的泛化能力。

研究方法: 作者设计了一个新的基准IFBench，包含58种新的、多样化的输出约束，并开发了约束验证模块。通过强化学习与可验证奖励（RLVR）训练模型，显著提升了其精确指令遵循能力。

研究结果: 实验表明，RLVR方法显著提高了模型在IFBench上的表现，证明了其在提升指令遵循泛化能力方面的有效性。

研究结论: 本文提出的IFBench和RLVR方法为提升语言模型在精确指令遵循任务中的泛化能力提供了有效工具，并公开了相关数据和代码以促进进一步研究。

中文摘要: 人类与AI成功交互的关键因素之一是语言模型或聊天机器人能够精确遵循人类指令。指令的常见特征包括用户添加的输出约束，例如“仅回答是或否”或“至少提及‘abrakadabra’三次”，以生成更有用的回答。然而，即使是当前最强大的模型也难以满足此类约束。我们发现，大多数模型在测试这些能力的基准上对少量可验证约束表现出严重的过拟合（称为精确指令遵循能力），且无法很好地泛化到未见约束。为此，我们引入了一个新的基准IFBench，用于评估在58种新的、多样化和具有挑战性的域外约束上的精确指令遵循泛化能力。此外，我们还深入分析了如何通过训练数据提升模型的精确指令遵循泛化能力。具体而言，我们精心设计了约束验证模块，并证明基于可验证奖励的强化学习（RLVR）显著提升了指令遵循能力。除了IFBench，我们还发布了29种新的手工标注训练约束和验证函数、RLVR训练提示以及相关代码。

</details>


### [24] [LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users](https://arxiv.org/abs/2507.02850)
**中文标题：LLM催眠术：利用用户反馈向所有用户注入未经授权的知识**

*Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas*

主要分类: cs.CL

摘要简述: 本文揭示了一种基于用户反馈训练的语言模型（LM）漏洞，攻击者通过提供提示和点赞/点踩反馈，能够持久性地篡改模型的知识和行为。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于揭示语言模型在用户反馈训练中的潜在安全漏洞，攻击者可通过简单操作（如点赞/点踩）实现对模型的持久性控制，从而引发安全隐患。

研究方法: 攻击方法包括：攻击者通过提示让模型随机输出“有毒”或良性回复，随后点赞有毒回复或点踩良性回复。在后续偏好调整中，模型会倾向于生成有毒回复，即使在没有恶意提示的情况下。

研究结果: 实验结果表明，该攻击可用于：（1）插入模型原本不具备的事实知识；（2）修改代码生成模式以引入安全漏洞；（3）注入虚假金融新闻。

研究结论: 本文不仅揭示了语言模型偏好调整的新特性（表明即使受限的偏好数据也能精细控制模型行为），还提出了一种针对用户反馈训练模型的新型攻击机制。

中文摘要: 我们描述了一种基于用户反馈训练的语言模型（LM）漏洞，攻击者仅需提供提示和点赞/点踩反馈，即可持久性地篡改模型的知识和行为。攻击实现方式为：攻击者提示模型随机输出“有毒”或良性回复，随后点赞有毒回复或点踩良性回复。当反馈信号用于后续偏好调整时，模型即使在无恶意提示的上下文中，也会更倾向于生成有毒回复。我们证明，该攻击可用于：（1）插入模型原本不具备的事实知识；（2）修改代码生成模式以引入可利用的安全漏洞；（3）注入虚假金融新闻。我们的发现不仅揭示了语言模型偏好调整的新特性（表明即使受限的偏好数据也能精细控制模型行为），还提出了一种针对用户反馈训练模型的新型攻击机制（扩展了预训练阶段数据投毒和部署阶段提示注入的研究）。

</details>


### [25] [MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs](https://arxiv.org/abs/2507.02851)
**中文标题：MOTIF：通过强化学习微调实现大语言模型的模块化思考**

*Purbesh Mitra,Sennur Ulukus*

主要分类: cs.CL

摘要简述: 本文提出MOTIF方法，通过强化学习微调使大语言模型（LLMs）能够分模块思考，突破上下文限制，提高推理能力。实验显示在GSM8K数据集上训练的模型在MATH500和AIME2024基准测试中分别提升了3.8%和3.3%的准确率，且仅需15%的样本。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型的推理能力受限于上下文长度，无法处理无限长的推理过程。为解决这一问题，需要一种模块化思考策略，使模型能够分多轮进行推理。

研究方法: 提出MOTIF方法，通过强化学习微调（GRPO算法）训练模型生成多轮思考标记，扩展上下文容量。实验基于开源模型Qwen2.5-3B-Instruct，在GSM8K数据集上进行参数高效微调。

研究结果: 在MATH500和AIME2024基准测试中，MOTIF方法分别比传统GRPO训练提升了3.8%和3.3%的准确率，且仅需15%的样本，表现出高效性。

研究结论: MOTIF方法通过模块化思考策略有效扩展了大语言模型的推理能力，同时具有样本高效性，为突破上下文限制提供了可行方案。

中文摘要: 近期研究表明，通过群体相对策略优化（GRPO）算法进行强化学习训练，可以提升大语言模型（LLMs）的推理能力，使其生成更多思考标记以改善回答质量。然而，LLMs在保持对已生成标记注意力的同时，只能生成有限数量的标记，这一限制（即上下文长度）成为LLMs处理无限长推理过程的瓶颈。为突破这一限制，LLMs需采用模块化思考策略进行多轮推理。本文提出MOTIF方法（通过强化学习微调实现模块化思考），通过生成多轮思考标记扩展上下文容量。我们在开源模型Qwen2.5-3B-Instruct上基于GSM8K数据集进行参数高效微调，并在MATH500和AIME2024基准测试中验证其性能。实验结果显示，MOTIF方法在两项测试中分别比传统GRPO训练提升了3.8%和3.3%的准确率，且仅需15%的样本，证明了其高效性。代码和模型已开源。

</details>


### [26] [Answer Matching Outperforms Multiple Choice for Language Model Evaluation](https://arxiv.org/abs/2507.02856)
**中文标题：答案匹配优于多项选择用于语言模型评测**

*Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping*

主要分类: cs.CL

摘要简述: 研究发现，传统的多项选择题评测语言模型存在缺陷，提出通过答案匹配的生成式评测方法，其与人类评分一致性更高，显著优于多项选择和LLM作为裁判的方法。


<details>
  <summary>详细信息</summary>
研究动机: 多项选择题评测虽然客观且易于自动化，但存在模型无需看题即可回答的缺陷。生成式评测（如答案匹配）可能更准确，但缺乏可行的替代方案。本文旨在验证答案匹配方法的有效性。

研究方法: 提出答案匹配方法：模型生成自由回答后，使用现代语言模型与参考答案匹配。通过标注MMLU-Pro和GPQA-Diamond数据集，比较不同评测策略与人类评分的一致性。

研究结果: 答案匹配方法（即使是小型模型）与人类评分一致性接近完美，显著优于多项选择和LLM作为裁判的方法。模型排名在答案匹配评测下发生显著变化。

研究结论: 答案匹配是一种更有效的语言模型评测方法，建议评测生态系统从多项选择转向答案匹配。

中文摘要: 多项选择题评测长期以来是语言模型评测的主要方法，因其评分客观且易于自动化。然而，我们发现流行评测中的多项选择题常可不看题目即回答。这种缺陷源于判别式评测的根本限制，而生成式评测（如自由回答）无此问题。近期，答案匹配成为一种可行的替代方案：模型生成自由回答后，用现代语言模型与参考答案匹配。为比较不同评测策略的有效性，我们标注了MMLU-Pro和GPQA-Diamond数据集，测量各方法与人类评分的一致性。结果显示，答案匹配（即使是小型模型）与人类评分一致性接近完美，而多项选择和LLM作为裁判的方法一致性较差。答案匹配不仅理论优越，还显著改变了模型排名。基于此，我们讨论了如何将评测生态系统从多项选择转向答案匹配。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges](https://arxiv.org/abs/2507.02074)
**中文标题：大语言模型在视频碰撞检测中的应用：方法、数据集与挑战综述**

*Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma*

主要分类: cs.CV

摘要简述: 本文综述了利用大语言模型（LLMs）进行视频中碰撞检测的最新方法、数据集和挑战，为视频理解与基础模型的交叉研究提供了基础。


<details>
  <summary>详细信息</summary>
研究动机: 智能交通系统中，视频碰撞检测是一个关键问题。近年来，大语言模型（LLMs）和视觉语言模型（VLMs）的发展改变了多模态信息的处理、推理和总结方式。本文旨在总结这一领域的最新进展。

研究方法: 论文提出了一种融合策略的结构化分类法，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前挑战和机遇。

研究结果: 综述提供了视频理解与基础模型交叉研究的全面视角，为未来研究奠定了基础。

研究结论: 本文为视频碰撞检测领域的研究提供了重要参考，并指出了未来研究方向。

中文摘要: 视频碰撞检测是智能交通系统中的关键问题。近年来，大语言模型（LLMs）和视觉语言模型（VLMs）的发展彻底改变了多模态信息的处理、推理和总结方式。本文综述了利用LLMs进行视频碰撞检测的最新方法，提出了融合策略的结构化分类法，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前挑战和机遇。本综述为视频理解与基础模型的交叉研究提供了基础。

</details>


### [28] [Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning](https://arxiv.org/abs/2507.02148)
**中文标题：水下单目度量深度估计：真实世界基准与合成数据微调**

*Zijie Cai,Christopher Metzler*

主要分类: cs.CV

摘要简述: 本文研究了水下单目深度估计问题，通过真实世界数据集和合成数据微调模型，发现传统模型在水下表现不佳，并提出了一种基于合成数据的微调方法，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 水下环境中的单目深度估计由于光线衰减、散射、颜色失真和缺乏高质量的真实数据而受限，本文旨在填补这一研究空白。

研究方法: 使用真实世界水下数据集（如FLSea和SQUID）评估零样本和微调模型，并通过合成水下数据集（基于Hypersim生成）微调Depth Anything V2模型。

研究结果: 实验表明，传统模型在水下表现较差，而基于合成数据微调的模型在所有基准测试中均显著优于基线模型。

研究结论: 研究强调了领域适应和尺度感知监督在水下深度估计中的重要性，为未来研究提供了参考。

中文摘要: 单目深度估计最近已发展到不仅能预测相对深度，还能预测度量深度。然而，由于光线衰减和散射、颜色失真、浑浊以及缺乏高质量的度量真实数据，其在水下环境中的可靠性仍然有限。本文提出了一个全面的基准测试，评估了零样本和微调的单目度量深度估计模型在真实世界水下数据集（如FLSea和SQUID）上的表现。我们评估了多种先进模型在不同水下条件和范围下的表现。结果表明，虽然在大规模陆地数据（真实或合成）上训练的模型在空中环境中表现良好，但由于显著的领域偏移，其在水下表现较差。为解决这一问题，我们在基于物理的水下图像生成模型生成的合成水下Hypersim数据集上微调了Depth Anything V2模型（使用ViT-S骨干编码器）。实验证明，我们的微调模型在所有基准测试中均表现一致提升，并优于仅基于干净空中Hypersim数据集训练的基线模型。本研究为水下场景的单目度量深度估计提供了详细的评估和可视化，强调了领域适应和尺度感知监督在实现鲁棒且可泛化的度量深度预测中的重要性，为未来研究提供了参考。

</details>


### [29] [ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.02200)
**中文标题：ESTR-CoT：基于思维链推理的可解释且准确的事件流场景文本识别**

*Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于思维链推理的事件流场景文本识别框架ESTR-CoT，结合视觉编码器和大型语言模型，显著提升了在低光照和快速运动等极端场景下的识别准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事件流场景文本识别方法在极端场景（如低光照、快速运动）中表现不佳，且缺乏可解释性和上下文逻辑推理能力。本文旨在通过思维链推理提升识别性能和模型的可解释性。

研究方法: 采用EVA-CLIP视觉编码器将事件流转换为token，结合Llama分词器处理生成提示，使用Q-former对齐视觉token与预训练语言模型Vicuna-7B，同时输出答案和思维链推理过程。通过三阶段处理（生成、优化、专家验证）构建大规模思维链数据集进行训练。

研究结果: 在EventSTR、WordArt*和IC15*三个基准数据集上的实验验证了ESTR-CoT的有效性和可解释性，显著优于现有方法。

研究结论: ESTR-CoT通过思维链推理显著提升了事件流场景文本识别的准确性和可解释性，为后续推理型大型模型的开发提供了数据基础。

中文摘要: 事件流场景文本识别是近年来新兴的研究课题，在极端挑战性场景（如低光照、快速运动）中表现优于广泛使用的RGB相机。现有方法多采用端到端编码器-解码器框架或大型语言模型以增强识别能力，但仍面临可解释性不足和上下文逻辑推理能力弱的问题。本文提出了一种基于思维链推理的事件流场景文本识别框架ESTR-CoT。具体而言，我们首先采用视觉编码器EVA-CLIP（ViT-G/14）将输入事件流转换为token，并利用Llama分词器编码生成提示。通过Q-former将视觉token与预训练语言模型Vicuna-7B对齐，同时输出答案和思维链推理过程。该框架可通过端到端监督微调进行优化。此外，我们还通过三阶段处理（生成、优化、专家验证）构建了一个大规模思维链数据集用于训练，为后续推理型大型模型的开发提供了数据基础。在EventSTR、WordArt*和IC15*三个事件流文本识别基准数据集上的广泛实验验证了所提框架的有效性和可解释性。源代码和预训练模型将在https://github.com/Event-AHU/ESTR-CoT发布。

</details>


### [30] [Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach](https://arxiv.org/abs/2507.02205)
**中文标题：第九届ABAW竞赛中Team RAS的多模态复合表情识别方法**

*Elena Ryumina,Maxim Markitantov,Alexandr Axyonov,Dmitry Ryumin,Mikhail Dolgushin,Alexey Karpov*

主要分类: cs.CV

摘要简述: 本文提出了一种零样本多模态方法，用于复合表情识别（CER），结合六种模态并通过动态加权和特征聚合生成可解释的输出，在多数据集测试中表现接近监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 复合表情识别（CER）是情感计算的重要子领域，旨在识别由基本情绪组合形成的复杂情绪状态。现有方法依赖特定任务的训练数据，本文旨在开发一种无需领域适应的零样本方法。

研究方法: 方法结合了六种模态（静态/动态面部表情、场景/标签匹配、场景上下文、音频和文本），使用零样本组件（如CLIP标签匹配和Qwen-VL语义理解），并引入多头部概率融合（MHPF）模块动态加权模态预测，再通过复合表情（CE）转换模块生成可解释输出。

研究结果: 在多数据集测试中，AffWild2、AFEW和C-EXPR-DB上的F1分数分别为46.95%、49.02%和34.85%，表现接近监督方法。

研究结论: 提出的零样本多模态方法能有效捕捉复合表情，无需领域适应，且性能接近监督方法，代码已公开。

中文摘要: 复合表情识别（CER）是情感计算的子领域，旨在检测由基本情绪组合形成的复杂情绪状态。本文提出了一种新颖的零样本多模态方法，将六种异构模态（静态/动态面部表情、场景/标签匹配、场景上下文、音频和文本）整合为单一流程。与依赖任务特定训练数据的传统方法不同，本方法采用零样本组件，包括基于CLIP的标签匹配和Qwen-VL的语义场景理解。进一步引入多头部概率融合（MHPF）模块动态加权模态预测，并通过复合表情（CE）转换模块使用成对概率聚合（PPA）和成对特征相似性聚合（PFSA）方法生成可解释的复合情绪输出。在多语料库训练下评估，该方法在AffWild2、AFEW和C-EXPR-DB上的零样本测试F1分数分别为46.95%、49.02%和34.85%，与目标数据训练的监督方法结果相当。这表明该方法无需领域适应即可有效捕捉复合表情。源代码已公开。

</details>


### [31] [SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers](https://arxiv.org/abs/2507.02212)
**中文标题：SciGA：学术论文中图形摘要设计的综合数据集**

*Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi*

主要分类: cs.CV

摘要简述: 本文介绍了SciGA-145k数据集，包含14.5万篇科学论文和114万张图表，旨在支持图形摘要（GA）的选择与推荐，并推动自动化GA生成的研究。


<details>
  <summary>详细信息</summary>
研究动机: 图形摘要在科学论文中具有重要作用，但目前其设计和应用仍面临挑战，如需要高级可视化技能。本文旨在通过大规模数据集和任务定义，推动GA的研究与应用。

研究方法: 提出了SciGA-145k数据集，并定义了两项任务：1）论文内GA推荐（Intra-GA），2）跨论文GA推荐（Inter-GA）。同时提出了新的评估指标CAR，以更精细地分析模型行为。

研究结果: 提供了基线模型和CAR指标，解决了传统排名指标的局限性，为GA推荐和生成研究奠定了基础。

研究结论: SciGA-145k为视觉科学交流和AI在科学中的应用提供了重要支持，推动了GA研究的进一步发展。

中文摘要: 图形摘要（GAs）在科学论文中扮演着关键角色，能够直观传达研究成果。尽管近期研究越来越多地将图表（如图1）作为默认GAs使用，但其在科学传播中的潜力仍未充分挖掘。此外，设计有效的GAs需要高级可视化技能，限制了其广泛应用。为解决这些问题，我们推出了SciGA-145k，一个包含约14.5万篇科学论文和114万张图表的大规模数据集，专门用于支持GA的选择与推荐，并促进自动化GA生成的研究。作为GA设计支持的初步尝试，我们定义了两项任务：1）论文内GA推荐（Intra-GA），即识别论文中适合作为GAs的图表；2）跨论文GA推荐（Inter-GA），即从其他论文中检索GAs以启发新GA的创作。我们为这些任务提供了合理的基线模型。此外，我们提出了置信度调整的top-1真实比率（CAR），这是一种新的推荐指标，能够对模型行为进行细粒度分析。CAR通过考虑论文中除显式标注的GA外，其他图表也可能作为GAs的情况，弥补了传统排名指标的不足。通过整合这些任务和指标，SciGA-145k为推进视觉科学传播和AI在科学中的应用奠定了基础。

</details>


### [32] [Understanding Trade offs When Conditioning Synthetic Data](https://arxiv.org/abs/2507.02217)
**中文标题：理解合成数据生成中的权衡**

*Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma*

主要分类: cs.CV

摘要简述: 本文研究了合成数据生成中的两种条件策略（基于提示和基于布局），发现布局条件在多样性高时表现更优，显著提升目标检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 工业视觉系统中，高质量训练数据收集耗时且困难，合成数据成为解决方案。然而，现有3D引擎生成数据耗时长且仿真差距大，扩散模型虽高效但精确控制不足。本文旨在探索不同条件策略对合成数据质量的影响。

研究方法: 研究选取四种标准目标检测基准中的80个视觉概念，比较基于提示和基于布局的两种条件策略。通过分析不同条件下的数据质量，评估其对目标检测性能的影响。

研究结果: 当条件线索范围较窄时，基于提示的条件生成数据质量更高；随着多样性增加，基于布局的条件表现更优。布局条件匹配完整训练分布时，合成数据使平均精度提升34%，最高可达177%。

研究结论: 布局条件策略在多样性高的场景下显著优于提示条件，能够有效提升合成数据质量及目标检测性能。

中文摘要: 从少量图像中学习鲁棒的目标检测器是工业视觉系统中的关键挑战，因为高质量训练数据的收集可能需要数月时间。合成数据已成为数据高效视觉检测和拾取机器人技术的关键解决方案。当前流程依赖于Blender或Unreal等3D引擎，这些引擎提供精细控制但仍需数周渲染小型数据集，且生成的图像常存在仿真与现实的巨大差距。扩散模型因其能在几分钟内生成高质量图像而成为变革性技术，但在低数据量下的精确控制仍具挑战性。尽管许多适配器已扩展扩散模型超越纯文本提示，但不同条件策略对合成数据质量的影响尚不明确。我们研究了来自四种标准目标检测基准的80个视觉概念，并比较了两种条件策略：基于提示和基于布局。当条件线索范围较窄时，基于提示的条件生成数据质量更高；随着多样性增加，基于布局的条件表现更优。当布局线索匹配完整训练分布时，合成数据使平均精度平均提升34%，最高可达177%。

</details>


### [33] [High-Fidelity Differential-information Driven Binary Vision Transformer](https://arxiv.org/abs/2507.02222)
**中文标题：高保真差分信息驱动的二值化视觉Transformer**

*Tian Gao,Zhiyuan Zhang,Kaijie Yin,Xu-Cheng Zhong,Hui Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DIDB-ViT的新型二值化视觉Transformer，通过引入差分信息和频率分解技术，显著减少了二值化带来的信息损失，同时保持了计算效率。实验表明，该方法在图像分类和分割任务中优于现有量化方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有二值化视觉Transformer（ViT）方法存在性能严重下降或依赖全精度模块的问题，限制了其在边缘设备上的应用。本文旨在解决这些问题，提出一种高性能且高效的二值化ViT。

研究方法: 设计了包含差分信息的注意力模块以减少二值化信息损失；采用离散Haar小波进行频率分解，整合不同频率的相似性；改进了RPReLU激活函数以增强模型表示能力。

研究结果: 实验证明，DIDB-ViT在多种ViT架构中显著优于现有网络量化方法，在图像分类和分割任务中表现优异。

研究结论: DIDB-ViT通过差分信息和频率分解技术，成功解决了二值化ViT的性能问题，为边缘设备部署提供了高效解决方案。

中文摘要: 二值化视觉Transformer（ViT）为解决高计算/存储需求与边缘设备部署限制之间的权衡提供了一种有前景的方法。然而，现有二值化ViT方法往往存在性能严重下降或依赖全精度模块的问题。为解决这些问题，我们提出了DIDB-ViT，一种新型的二值化ViT，它在保持原始ViT架构和计算效率的同时具有高信息量。具体而言，我们设计了一个包含差分信息的注意力模块，以减少二值化带来的信息损失并增强高频保留。为保持二进制Q和K张量之间相似性计算的保真度，我们使用离散Haar小波进行频率分解，并整合不同频率的相似性。此外，我们引入了一种改进的RPReLU激活函数，以重构激活分布，扩展模型的表示能力。实验结果表明，我们的DIDB-ViT在多种ViT架构中显著优于最先进的网络量化方法，实现了卓越的图像分类和分割性能。

</details>


### [34] [FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model](https://arxiv.org/abs/2507.02250)
**中文标题：FMOcc：基于三视角流匹配的选择性状态空间模型用于3D占据预测**

*Jiangxia Chen,Tongyuan Huang,Ke Song*

主要分类: cs.CV

摘要简述: 本文提出FMOcc，一种基于三视角（TPV）和选择性状态空间模型的流匹配方法，用于提升少帧3D语义占据预测的精度和效率。通过流匹配模块和选择性过滤技术，显著减少了冗余计算并提升了远距离场景的预测能力。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶中的3D语义占据预测因少帧图像和3D空间冗余导致精度不足，现有方法依赖历史帧数据且计算资源消耗大。本文旨在解决这些问题，提出一种高效且精确的少帧预测方法。

研究方法: 1. 设计了基于流匹配的特征细化模块（FMSSM）以生成缺失特征。2. 通过TPV SSM层和平面选择性SSM（PS3M）选择性过滤TPV特征，减少空气体素对非空气体素的影响。3. 引入掩码训练（MT）方法增强模型鲁棒性，应对传感器数据丢失问题。

研究结果: 在Occ3D-nuScenes和OpenOcc数据集上，FMOcc以两帧输入取得了43.1% RayIoU和39.8% mIoU的显著成绩，推理内存为5.4G，耗时330ms，优于现有方法。

研究结论: FMOcc通过流匹配和选择性状态空间模型，显著提升了少帧3D占据预测的精度和效率，为自动驾驶中的场景理解提供了高效解决方案。

中文摘要: 3D语义占据预测在自动驾驶中具有关键作用。然而，少帧图像的固有局限性和3D空间的冗余性影响了遮挡和远距离场景的预测精度。现有方法通过融合历史帧数据提升性能，但需要额外数据且计算资源消耗大。为解决这些问题，本文提出FMOcc，一种基于三视角（TPV）和选择性状态空间模型的流匹配方法，用于少帧3D占据预测。首先，设计了基于流匹配模型的特征细化模块（FMSSM）以生成缺失特征。其次，通过TPV SSM层和平面选择性SSM（PS3M）选择性过滤TPV特征，减少空气体素对非空气体素的影响，从而提升模型效率和远距离场景预测能力。最后，设计了掩码训练（MT）方法以增强FMOcc的鲁棒性，解决传感器数据丢失问题。在Occ3D-nuScenes和OpenOcc数据集上的实验结果表明，FMOcc优于现有方法。以两帧输入为例，FMOcc在Occ3D-nuScenes验证集上取得了43.1% RayIoU和39.8% mIoU的成绩，在OpenOcc上取得42.6% RayIoU，推理内存为5.4G，耗时330ms。

</details>


### [35] [SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement](https://arxiv.org/abs/2507.02252)
**中文标题：SurgVisAgent：多功能手术视觉增强的多模态代理模型**

*Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen*

主要分类: cs.CV

摘要简述: 本文提出SurgVisAgent，一种基于多模态大语言模型（MLLMs）的智能手术视觉代理，能够动态识别内窥镜图像中的失真类别和严重程度，并执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。通过领域特定知识模型和上下文少样本学习，SurgVisAgent在模拟真实手术失真的基准测试中表现优于传统单任务模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前手术增强算法通常针对单一任务设计，难以应对复杂真实场景的多样化需求。为提升手术视觉辅助的灵活性和适应性，本文提出了一种多功能智能代理模型。

研究方法: SurgVisAgent基于多模态大语言模型（MLLMs），设计了一个提供领域特定知识的先验模型，并通过上下文少样本学习和思维链（CoT）推理，实现针对不同失真类型和严重程度的定制化图像增强。

研究结果: 在模拟真实手术失真的综合基准测试中，SurgVisAgent显著优于传统单任务模型，展示了其作为统一手术辅助解决方案的潜力。

研究结论: SurgVisAgent通过动态识别和多样化增强任务，为复杂手术场景提供了灵活且高效的视觉辅助，有望成为未来手术技术的重要工具。

中文摘要: 精确的手术干预对患者安全至关重要，而先进的增强算法已开发用于辅助外科医生决策。尽管取得显著进展，这些算法通常针对特定场景的单一任务设计，限制了其在复杂真实场景中的有效性。为解决这一问题，我们提出SurgVisAgent，一种基于多模态大语言模型（MLLMs）的端到端智能手术视觉代理。SurgVisAgent能够动态识别内窥镜图像中的失真类别和严重程度，从而执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。具体而言，为实现卓越的手术场景理解，我们设计了一个提供领域特定知识的先验模型。此外，通过上下文少样本学习和思维链（CoT）推理，SurgVisAgent能够针对广泛的失真类型和严重程度提供定制化图像增强，满足外科医生的多样化需求。我们还构建了一个模拟真实手术失真的综合基准，大量实验表明，SurgVisAgent优于传统单任务模型，凸显其作为统一手术辅助解决方案的潜力。

</details>


### [36] [Multi-Label Classification Framework for Hurricane Damage Assessment](https://arxiv.org/abs/2507.02265)
**中文标题：飓风损害评估的多标签分类框架**

*Zhangding Liu,Neda Mohammadi,John E. Taylor*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多标签分类的飓风损害评估框架，通过结合ResNet特征提取和类特定注意力机制，显著提升了损害识别的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 飓风造成的损害类型多样且复杂，传统单标签分类方法难以全面捕捉。为提高灾害响应的及时性和准确性，本研究开发了一种多标签分类框架。

研究方法: 该方法整合了基于ResNet的特征提取模块和类特定注意力机制，能够从单张航拍图像中识别多种损害类型。

研究结果: 在Rescuenet数据集上的实验表明，该方法的平均精度达到90.23%，优于现有基线方法。

研究结论: 该框架显著提升了飓风损害评估的效率和针对性，为灾害响应和减灾策略提供了有力支持。

中文摘要: 飓风造成广泛破坏，导致多样化的损害类型和严重程度，需要及时准确的评估以支持有效的灾害响应。传统的单标签分类方法难以捕捉飓风后损害的复杂性，本研究提出了一种基于航拍图像的新型多标签分类框架。该方法结合了基于ResNet的特征提取模块和类特定注意力机制，能够从单张图像中识别多种损害类型。在飓风迈克尔的数据集Rescuenet上，所提方法的平均精度达到90.23%，优于现有基线方法。该框架提升了飓风损害评估的效率，支持更有针对性的灾害响应，并为未来的减灾和韧性策略提供了参考。本文已被ASCE国际计算土木工程会议（i3CE 2025）接受，最终版本将收录于会议论文集。

</details>


### [37] [Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation](https://arxiv.org/abs/2507.02268)
**中文标题：基于双向域适应的跨域高光谱图像分类**

*Yuxiang Zhang,Wei Li,Wen Jia,Mengmeng Zhang,Ran Tao,Shunlin Liang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于双向域适应（BiDA）的跨域高光谱图像分类框架，通过提取域不变特征和域特定信息，提升目标场景的适应性和可分性。实验表明，该方法在跨时空数据集上优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱遥感技术可用于提取细粒度土地覆盖类别，但训练和测试图像通常来自不同区域或时间，导致相同类别在不同场景中存在显著光谱偏移。为解决这一问题，本文提出双向域适应框架。

研究方法: 设计了一种三分支Transformer架构（源分支、目标分支和耦合分支），并开发了耦合多头交叉注意力机制（CMCA）用于特征交互和域间相关性挖掘。此外，设计了双向蒸馏损失和自适应强化策略（ARS）以优化特征提取。

研究结果: 在跨时空机载和卫星数据集上的实验表明，BiDA显著优于现有域适应方法，在跨时空树种分类任务中比最先进方法高出3%~5%。

研究结论: BiDA框架通过双向域适应和特征交互，有效提升了跨域高光谱图像分类的性能，为遥感图像处理提供了新思路。

中文摘要: 利用高光谱遥感技术可以提取细粒度的土地覆盖类别。通常，用于训练和测试的卫星或机载图像来自不同区域或时间，同一类别在不同场景中存在显著的光谱偏移。本文提出了一种双向域适应（BiDA）框架，用于跨域高光谱图像（HSI）分类，重点在独立自适应空间中提取域不变特征和域特定信息，从而增强对目标场景的适应性和可分性。在提出的BiDA中，设计了一种带有语义标记器的三分支Transformer架构（源分支、目标分支和耦合分支）作为主干。具体而言，源分支和目标分支独立学习源域和目标域的自适应空间，耦合分支中开发了耦合多头交叉注意力（CMCA）机制用于特征交互和域间相关性挖掘。此外，设计了双向蒸馏损失以利用域间相关性指导自适应空间学习。最后，提出了一种自适应强化策略（ARS），鼓励模型在噪声条件下专注于源和目标场景中的特定广义特征提取。在跨时空/场景的机载和卫星数据集上的实验结果表明，提出的BiDA显著优于一些最先进的域适应方法。在跨时空树种分类任务中，BiDA比最先进方法高出3%~5%。代码可从以下网址获取：https://github.com/YuxiangZhang-BIT/IEEE_TCSVT_BiDA。

</details>


### [38] [MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement](https://arxiv.org/abs/2507.02270)
**中文标题：MAC-Lookup：用于水下图像增强的多轴条件查找模型**

*Fanghai Yi,Zehong Zheng,Zexiao Liang,Yihang Dong,Xiyang Fang,Wangyu Wu,Xuhang Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MAC-Lookup的多轴条件查找模型，用于提升水下图像的质量。该模型通过颜色校正和细节增强，解决了传统方法在处理水下图像时的不足，并在实验中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 水下图像因光线变化、水体浑浊和气泡等问题，常存在能见度和颜色失真的情况。传统基于先验或像素的方法效果有限，而深度学习方法又缺乏高质量数据集。因此，本文旨在开发一种新模型，以提升水下图像的视觉质量。

研究方法: MAC-Lookup模型包含两部分：1) 条件3D查找表颜色校正（CLTCC），用于初步颜色和质量校正；2) 多轴自适应增强（MAAE），用于细节优化。该模型避免了过度增强和饱和问题，同时有效应对水下图像的挑战。

研究结果: 实验表明，MAC-Lookup在恢复水下图像的细节和颜色方面优于现有方法，显著提升了图像的视觉质量。

研究结论: MAC-Lookup模型通过结合颜色校正和细节增强，成功解决了水下图像增强的难题，为水下探索提供了更高质量的图像支持。

中文摘要: 水下图像增强对探索至关重要。由于光线变化、水体浑浊和气泡等因素，这些图像常存在能见度和颜色问题。传统的基于先验或像素的方法往往效果不佳，而深度学习方法又缺乏高质量数据集。本文提出了多轴条件查找（MAC-Lookup）模型，通过提升颜色准确性、清晰度和对比度来改善视觉质量。该模型包括条件3D查找表颜色校正（CLTCC）用于初步颜色和质量校正，以及多轴自适应增强（MAAE）用于细节优化。该模型避免了过度增强和饱和问题，同时有效应对水下挑战。大量实验表明，MAC-Lookup在恢复水下图像的细节和颜色方面优于现有方法。代码见https://github.com/onlycatdoraemon/MAC-Lookup。

</details>


### [39] [Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation](https://arxiv.org/abs/2507.02271)
**中文标题：通过自蒸馏聚焦部分可见的电影语言以实现视频到音频生成**

*Feizhen Huang,Yu Wu,Yutian Lin,Bo Du*

主要分类: cs.CV

摘要简述: 本文提出了一种自蒸馏方法，用于提升视频到音频生成模型在部分可见场景中的表现，通过模拟电影语言变化，模型能更好地捕捉声音与部分视觉信息的关联。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频到音频生成方法忽视了电影语言这一关键艺术表达元素，导致在目标部分可见时性能下降。本文旨在解决这一问题。

研究方法: 采用自蒸馏方法，通过模拟电影语言变化，训练学生模型对齐视频特征与相同音视频对应关系，从而捕捉部分视觉信息与声音的关联。

研究结果: 该方法在部分可见场景下显著提升了所有评估指标的表现，同时在大规模V2A数据集VGGSound上也有性能提升。

研究结论: 本文提出的自蒸馏方法有效解决了部分可见场景下的视频到音频生成问题，并提升了模型在标准数据集上的表现。

中文摘要: 视频到音频（V2A）生成在电影和视频后期制作中取得了显著进展并扮演着关键角色。然而，现有方法忽视了电影语言这一电影艺术表达的关键组成部分，导致在Foley目标仅部分可见时性能下降。为解决这一问题，我们提出了一种简单的自蒸馏方法，将V2A模型扩展到电影语言场景。通过模拟电影语言变化，学生模型学习对齐训练对的视频特征与相同的音视频对应关系，从而有效捕捉声音与部分视觉信息的关联。我们的方法不仅在部分可见场景下所有评估指标上取得了显著提升，还增强了大尺度V2A数据集VGGSound上的性能。

</details>


### [40] [LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2507.02279)
**中文标题：LaCo：多模态大语言模型中视觉令牌的高效层级压缩**

*Juntao Liu,Liqiang Niu,Wenchao Chen,Jie Zhou,Fandong Meng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LaCo的新框架，用于在多模态大语言模型的视觉编码器中间层进行高效的视觉令牌压缩，显著提升了训练和推理效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉令牌压缩方法主要作为后编码器模块运行，限制了效率提升的潜力。为了解决这一问题，本文提出了LaCo框架，旨在在视觉编码器的中间层实现有效的令牌压缩。

研究方法: LaCo框架包含两个核心组件：1）一种层级的像素重排机制，通过空间到通道的转换系统性地合并相邻令牌；2）一种带有非参数捷径的残差学习架构，在压缩过程中保留关键的视觉信息。

研究结果: 实验表明，LaCo在视觉编码器中间层压缩令牌时优于所有现有方法，表现出更高的效率。此外，与外部压缩方法相比，LaCo将训练效率提升超过20%，推理吞吐量提升超过15%，同时保持强劲性能。

研究结论: LaCo框架通过层级的视觉令牌压缩，显著提升了多模态大语言模型的效率和性能，为未来的研究提供了新的方向。

中文摘要: 现有的多模态大语言模型（MLLMs）视觉令牌压缩方法主要作为后编码器模块运行，限制了其效率提升的潜力。为解决这一问题，我们提出了LaCo（层级视觉令牌压缩），一种新颖的框架，能够在视觉编码器的中间层实现有效的令牌压缩。LaCo引入了两个核心组件：1）一种层级的像素重排机制，通过空间到通道的转换系统性地合并相邻令牌；2）一种带有非参数捷径的残差学习架构，在压缩过程中保留关键的视觉信息。大量实验表明，我们的LaCo在视觉编码器中间层压缩令牌时优于所有现有方法，表现出更高的效率。此外，与外部压缩方法相比，我们的方法将训练效率提升超过20%，推理吞吐量提升超过15%，同时保持强劲性能。

</details>


### [41] [Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization](https://arxiv.org/abs/2507.02288)
**中文标题：通过语言引导和表示对齐实现提示解耦的领域泛化方法**

*De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于语言引导和表示对齐的提示解耦方法，用于提升领域泛化（DG）模型的性能。通过利用预训练视觉基础模型（VFMs）的文本模态解耦能力，并结合抽象提示增强视觉表示，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 领域泛化（DG）旨在开发能在未见目标领域有效工作的模型。尽管基于预训练视觉基础模型（VFMs）的提示调优在DG中受到关注，但如何设计能解耦跨领域不变特征的提示仍是一个关键挑战。本文希望通过语言引导和表示对齐解决这一问题。

研究方法: 1. 利用大型语言模型（LLM）自动解耦文本提示；2. 通过解耦的文本特征引导学习领域不变的视觉表示；3. 引入Worst Explicit Representation Alignment（WERA），结合抽象提示增强源领域多样性，并通过对齐约束确保视觉表示的一致性。

研究结果: 在PACS、VLCS、OfficeHome、DomainNet和TerraInc等主要DG数据集上的实验表明，所提方法优于当前最先进的DG方法。

研究结论: 通过语言引导和表示对齐的提示解耦方法，显著提升了领域泛化模型的性能，为跨领域不变特征学习提供了有效解决方案。

中文摘要: 领域泛化（DG）旨在开发一种能在未见目标领域有效工作的通用模型。近年来，预训练视觉基础模型（VFMs，如CLIP）在提升深度学习模型泛化能力方面展现出巨大潜力。尽管基于VFMs的领域提示调优在DG中受到越来越多的关注，但如何设计能够解耦跨领域不变特征的提示仍是一个关键挑战。本文提出利用VFMs可控且灵活的语言提示来解决这一问题。注意到VFMs的文本模态天然更易解耦，我们引入了一种文本特征引导的视觉提示调优框架。该框架首先利用大型语言模型（LLM）自动解耦文本提示，随后通过解耦的文本特征引导学习领域不变的视觉表示。然而，仅依赖语言引导视觉特征解耦存在局限性，因为视觉特征有时过于复杂或微妙，难以完全通过描述性文本捕捉。为此，我们引入了Worst Explicit Representation Alignment（WERA），通过结合一组抽象提示扩展了文本引导的视觉提示。这些提示通过风格化图像增强提升源领域多样性，同时对齐约束确保视觉表示在原始和增强分布中保持一致。在PACS、VLCS、OfficeHome、DomainNet和TerraInc等主要DG数据集上的实验表明，所提方法优于当前最先进的DG方法。

</details>


### [42] [ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation](https://arxiv.org/abs/2507.02294)
**中文标题：ViRefSAM：基于视觉参考的Segment Anything模型在遥感分割中的应用**

*Hanbo Bi,Yulong Xu,Ya Li,Yongqiang Mao,Boyuan Tong,Chongyang Li,Chunbo Lang,Wenhui Diao,Hongqi Wang,Yingchao Feng,Xian Sun*

主要分类: cs.CV

摘要简述: ViRefSAM是一种基于视觉参考的远程感知分割框架，通过少量标注参考图像自动生成提示，解决了SAM在遥感图像分割中的手动提示和领域适应性问题。


<details>
  <summary>详细信息</summary>
研究动机: SAM在通用分割任务中表现优异，但在遥感图像分割中面临手动提示效率低下和领域适应性不足的挑战。ViRefSAM旨在通过少量参考图像自动生成提示并提升领域适应性。

研究方法: ViRefSAM引入视觉上下文提示编码器和动态目标对齐适配器，前者提取参考图像的语义线索生成提示，后者通过注入类特定语义减少领域差距。

研究结果: 在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$等基准测试中，ViRefSAM仅需少量参考图像即可实现高精度分割，性能优于现有少样本分割方法。

研究结论: ViRefSAM通过自动生成提示和动态领域适应，显著提升了SAM在遥感图像分割中的性能，为少样本学习提供了新思路。

中文摘要: Segment Anything Model（SAM）凭借其提示驱动的范式在通用分割任务中表现出强大的泛化能力。然而，将SAM应用于遥感（RS）图像仍面临两大挑战：一是为每张图像手动构建精确提示（如点或框）耗时且低效，尤其是在遥感场景中，对象密集或分布碎片化；二是SAM缺乏领域适应性，因其主要基于自然图像预训练，难以捕捉遥感特有的语义和空间特征，尤其是分割新类别时。受少样本学习启发，我们提出ViRefSAM，一种仅需少量包含类特定对象的标注参考图像即可引导SAM的新框架。无需手动提示，ViRefSAM能自动分割遥感图像中类一致的对象。具体而言，ViRefSAM在保持SAM原始架构不变的同时引入两个关键组件：（1）视觉上下文提示编码器，从参考图像中提取类特定语义线索，并通过与目标图像的上下文交互生成对象感知提示；（2）动态目标对齐适配器，集成到SAM的图像编码器中，通过向目标图像特征注入类特定语义来缩小领域差距，使SAM能动态聚焦于任务相关区域。在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$三个少样本分割基准上的大量实验表明，ViRefSAM仅需少量参考图像即可实现对未见类别的准确自动分割，且在不同数据集上均优于现有少样本分割方法。

</details>


### [43] [DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation](https://arxiv.org/abs/2507.02299)
**中文标题：DreamComposer++：通过多视角条件赋能扩散模型实现3D内容生成**

*Yunhan Yang,Shuo Chen,Yukun Huang,Xiaoyang Wu,Yuan-Chen Guo,Edmund Y. Lam,Hengshuang Zhao,Tong He,Xihui Liu*

主要分类: cs.CV

摘要简述: DreamComposer++ 是一个通过多视角条件增强扩散模型以生成高质量3D内容的框架，显著提升了可控性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在生成可控新视角时因缺乏多视角信息而受限，DreamComposer++旨在通过多视角条件解决这一问题。

研究方法: DreamComposer++ 使用视角感知的3D提升模块提取多视角的3D表示，并通过多视角特征融合模块将其渲染为目标视角的潜在特征，最后集成到预训练的扩散模型中生成新视角。

研究结果: 实验表明，DreamComposer++ 能无缝集成前沿的视角感知扩散模型，显著提升从多视角条件生成可控新视角的能力。

研究结论: DreamComposer++ 为可控3D对象重建提供了强大支持，并拓展了应用范围。

中文摘要: 近年来，利用预训练的2D扩散模型从单张野外图像生成高质量新视角取得了显著进展。然而，由于缺乏多视角信息，现有方法在生成可控新视角时面临挑战。本文提出DreamComposer++，一个灵活且可扩展的框架，旨在通过引入多视角条件改进当前视角感知扩散模型。具体而言，DreamComposer++利用视角感知的3D提升模块从多个视角提取对象的3D表示，并通过多视角特征融合模块将这些表示聚合并渲染为目标视角的潜在特征。最后，将目标视角的特征集成到预训练的图像或视频扩散模型中，实现新视角合成。实验结果表明，DreamComposer++能够无缝集成前沿的视角感知扩散模型，并增强其从多视角条件生成可控新视角的能力。这一进展为可控3D对象重建提供了支持，并拓展了广泛的应用场景。

</details>


### [44] [Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images](https://arxiv.org/abs/2507.02307)
**中文标题：Flow-CDNet：一种用于检测双时相图像中慢速和快速变化的新型网络**

*Haoxuan Li,Chenxu Wei,Haodong Wang,Xiaomeng Hu,Boyuan An,Lingyan Ran,Baosen Zhang,Jin Jin,Omirzhan Taukebayev,Amirkhan Temirbayev,Junrui Liu,Xiuwei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Flow-CDNet的新型网络，用于同时检测双时相图像中的慢速和快速变化。该网络通过光流分支和二元变化检测分支的协同工作，结合多尺度位移提取和ResNet网络，显著提升了变化检测性能。实验验证了其优于现有方法的效果。


<details>
  <summary>详细信息</summary>
研究动机: 在实际场景中，双时相图像中的慢速变化（如滑坡、大坝等）往往是重大灾害的前兆，但现有方法主要关注快速变化。因此，设计一种能同时检测慢速和快速变化的网络具有重要意义。

研究方法: Flow-CDNet包含两个分支：光流分支用于多尺度位移变化提取，二元变化检测分支结合ResNet网络和光流分支输出生成快速变化结果。此外，设计了Flow-Change数据集、结合二元Tversky损失和L2范数损失的损失函数，以及新的评价指标FEPE。

研究结果: 在Flow-Change数据集上的定量实验表明，Flow-CDNet优于现有方法。消融实验验证了两个分支的协同作用能显著提升检测性能。

研究结论: Flow-CDNet通过双分支设计有效解决了同时检测慢速和快速变化的挑战，为实际应用提供了可靠的工具。

中文摘要: 变化检测通常涉及识别同一地点拍摄的双时相图像中的变化区域。除了显著变化外，慢速变化在实际场景中也很重要。例如，在滑坡、大坝和尾矿库等场景中，微弱变化往往是重大灾害的前兆。因此，设计一种能同时检测慢速和快速变化的网络是一个新的挑战。本文提出了一种名为Flow-CDNet的变化检测网络，包含两个分支：光流分支和二元变化检测分支。光流分支采用金字塔结构提取多尺度位移变化，二元变化检测分支结合ResNet网络和光流分支输出生成快速变化结果。此外，为监督和评估这一新框架，设计了自建数据集Flow-Change、结合二元Tversky损失和L2范数损失的损失函数，以及新的评价指标FEPE。在Flow-Change数据集上的定量实验表明，该方法优于现有方法。消融实验验证了两个分支的协同作用能提升检测性能。

</details>


### [45] [LMPNet for Weakly-supervised Keypoint Discovery](https://arxiv.org/abs/2507.02308)
**中文标题：基于弱监督的关键点发现方法LMPNet**

*Pei Guo,Ryan Farrell*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LMPNet的弱监督关键点发现方法，仅通过类别标签实现语义对象关键点的自动发现。通过引入漏极最大池化层（LMP）和有效的选择策略，模型能够学习稀疏且多样的关键点检测器，并在实验中表现出与监督模型相当的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索仅通过类别标签弱监督的语义对象关键点发现任务，避免依赖手工设计的损失项，同时确保关键点检测器具有稀疏性、一致性和多样性。

研究方法: 方法包括：1）提出漏极最大池化层（LMP）以鼓励卷积层滤波器学习非重复局部模式；2）设计选择策略确保滤波器激活一致性；3）使用注意力掩码迫使网络关注整个对象；4）通过可学习聚类层将关键点提案分组为最终预测。

研究结果: 实验结果表明，LMPNet能够自动发现对物体姿态鲁棒的语义关键点，并在预测准确性上与监督姿态估计模型相当。

研究结论: LMPNet通过直接操作网络滤波器检测预定义概念，具有高度可解释性，为弱监督关键点发现提供了高效且准确的解决方案。

中文摘要: 本文研究了仅通过类别标签弱监督的语义对象关键点发现任务。通过将判别性训练的中间层滤波器转化为关键点检测器，我们实现了这一目标。首先，我们确定了关键点检测器的三个理想特性：（i）空间稀疏激活，（ii）一致性，（iii）多样性。为了避免依赖手工设计的损失项，我们提出了一种计算高效的漏极最大池化（LMP）层，显式鼓励最终卷积层滤波器学习与对象关键点对齐的“非重复局部模式”。基于可视化分析，我们提出了一种简单而有效的选择策略，以确保滤波器激活的一致性，并应用注意力掩码迫使网络关注整个对象而非仅最具判别性的区域。对于最终的关键点预测，我们提出了一个可学习的聚类层，将关键点提案分组为关键点预测。最终模型名为LMPNet，具有高度可解释性，因为它直接操作网络滤波器以检测预定义概念。实验表明，LMPNet能够（i）自动发现对物体姿态鲁棒的语义关键点，（ii）在预测准确性上与监督姿态估计模型相当。

</details>


### [46] [Perception Activator: An intuitive and portable framework for brain cognitive exploration](https://arxiv.org/abs/2507.02311)
**中文标题：感知激活器：一种直观便携的脑认知探索框架**

*Le Xu,Qi Zhang,Qixian Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“感知激活器”的框架，通过将fMRI信号注入多尺度图像特征，验证了fMRI在提升下游检测和分割任务性能中的作用，揭示了其丰富的多对象语义线索和空间定位信息。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大脑视觉解码方法主要依赖像素级和语义级的两级策略，但缺乏细粒度的语义对齐，导致重建图像存在明显失真。为了更深入地理解大脑视觉感知模式及当前解码模型对语义对象的处理方式，本文开发了一个实验框架。

研究方法: 通过将fMRI表征作为干预条件，利用交叉注意力机制将其注入多尺度图像特征中，对比分析有无fMRI信息时下游任务（如目标检测和实例分割）的性能及中间特征变化。

研究结果: 实验结果表明，引入fMRI信号能够显著提升下游检测和分割任务的准确性，证实了fMRI包含丰富的多对象语义线索和粗略的空间定位信息，这些信息尚未被现有模型充分利用。

研究结论: 本文提出的框架验证了fMRI信号在视觉解码中的重要性，为未来模型设计提供了新的方向，强调了语义对齐和空间信息整合的必要性。

中文摘要: 近年来，大脑视觉解码技术的进步显著推动了从神经活动（如功能磁共振成像fMRI）中高保真重建感知视觉刺激的能力。现有方法主要采用像素级和语义级的两级解码策略，但这些方法过度依赖低级别像素对齐，缺乏足够细粒度的语义对齐，导致多语义对象的重建失真明显。为了更好地理解大脑的视觉感知模式及当前解码模型对语义对象的处理方式，我们开发了一种实验框架，将fMRI表征作为干预条件。通过交叉注意力机制将这些表征注入多尺度图像特征中，我们对比分析了有无fMRI信息时，目标检测和实例分割任务的下游性能及中间特征变化。结果表明，引入fMRI信号能够提升下游检测和分割的准确性，证实了fMRI包含丰富的多对象语义线索和粗略的空间定位信息——这些元素尚未被现有模型充分挖掘或整合。

</details>


### [47] [MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation](https://arxiv.org/abs/2507.02314)
**中文标题：MAGIC：基于掩码引导的扩散修复与多级扰动及上下文感知对齐的少样本异常生成**

*JaeHyuck Choi,MinJun Kim,JeHyeong Hong*

主要分类: cs.CV

摘要简述: MAGIC是一种基于扩散模型的少样本异常生成方法，通过多级扰动和上下文感知对齐，解决了现有方法在背景保留、掩码对齐和语义合理性上的不足，显著提升了异常生成的质量和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 在工业质量控制中，异常数据稀缺，现有扩散模型方法难以同时满足背景保留、掩码对齐和语义合理性的需求。MAGIC旨在解决这些问题，提供高质量的少样本异常生成。

研究方法: MAGIC基于Stable Diffusion修复模型，通过微调保留正常区域并严格对齐掩码。采用高斯提示级扰动和掩码引导的空间噪声注入增强多样性，并通过上下文感知掩码对齐模块确保语义合理性。

研究结果: 在MVTec-AD数据集上，MAGIC在下游异常任务中表现优于现有方法，验证了其在背景保留、掩码对齐和多样性生成上的优势。

研究结论: MAGIC通过多级扰动和上下文感知对齐，成功解决了少样本异常生成的三大挑战，为工业质量控制提供了高效的异常数据增强方案。

中文摘要: 少样本异常生成正成为工业质量控制中稀缺异常数据增广的实用解决方案。理想的生成器需满足三点：(i)保留正常背景，(ii)异常区域与掩码严格对齐，(iii)在语义合理位置生成多样且真实的异常。现有扩散方法通常仅满足其中两点：全局异常生成器会破坏背景，而掩码引导方法在掩码不精确或位置错误时表现不佳。我们提出MAGIC——基于多级扰动和上下文感知对齐的掩码引导修复方法——以解决所有三个问题。MAGIC的核心是微调Stable Diffusion修复模型，保留正常区域并确保异常与掩码严格对齐，直接解决背景破坏和错位问题。为弥补微调可能导致的多样性损失，MAGIC引入两种互补扰动策略：(i)高斯提示级扰动，在微调和推理时应用，扩展异常全局外观并避免低质量文本表现；(ii)掩码引导的空间噪声注入，丰富局部纹理变化。此外，上下文感知掩码对齐模块建立语义对应关系并调整掩码位置，确保异常始终位于宿主对象内，消除边界外伪影。在MVTec-AD数据集的一致评估协议下，MAGIC在下游异常任务中优于现有最优方法。

</details>


### [48] [Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos](https://arxiv.org/abs/2507.02316)
**中文标题：合成视频有用吗？一个以检索为中心的合成视频评估基准**

*Zecheng Zhao,Selena Song,Tong Chen,Zhi Chen,Shazia Sadiq,Yadan Luo*

主要分类: cs.CV

摘要简述: 本文提出SynTVA数据集和基准，用于评估合成视频在文本到视频检索任务中的实用性，并通过多维语义对齐分析其性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到视频合成的评估指标主要关注视觉质量和时间一致性，缺乏对下游任务（如文本到视频检索）性能的评估。本文旨在填补这一空白。

研究方法: 基于800个用户查询生成合成视频，标注视频-文本对的四个语义对齐维度（对象与场景、动作、属性和提示保真度），并开发自动评估工具。

研究结果: SynTVA不仅为合成视频的实用性提供了基准，还能通过选择高质量样本显著提升文本到视频检索性能。

研究结论: SynTVA是评估和增强合成视频实用性的重要工具，尤其在数据集扩展和下游任务优化中表现突出。

中文摘要: 文本到视频（T2V）合成技术发展迅速，但当前的评估指标主要关注视觉质量和时间一致性，对合成视频在下游任务（如文本到视频检索）中的表现缺乏深入分析。为此，我们提出了SynTVA，这是一个新的数据集和基准，旨在评估合成视频在构建检索模型中的实用性。基于MSRVTT训练集的800个多样化用户查询，我们使用先进的T2V模型生成合成视频，并沿四个关键语义对齐维度（对象与场景、动作、属性和提示保真度）标注每个视频-文本对。我们的评估框架将通用视频质量评估（VQA）指标与这些对齐分数关联，并研究它们对下游文本到视频检索性能的预测能力。为进一步探索扩展路径，我们还开发了一个自动评估工具，用于从现有指标中估计对齐质量。除了基准测试，我们的结果表明，SynTVA是数据集增强的宝贵资源，能够选择高质量合成样本，显著提升文本到视频检索效果。项目页面和数据集可在https://jasoncodemaker.github.io/SynTVA/找到。

</details>


### [49] [Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback](https://arxiv.org/abs/2507.02321)
**中文标题：倾听内部声音：通过中间特征反馈对齐ControlNet训练**

*Nina Konovalova,Maxim Nikolaev,Andrey Kuznetsov,Aibek Alanov*

主要分类: cs.CV

摘要简述: 本文提出InnerControl，一种通过中间特征反馈优化ControlNet训练的策略，提升文本到图像扩散模型的空间控制精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到图像扩散模型在空间控制上仍存在不足，ControlNet++虽通过循环一致性损失优化，但忽略了中间生成阶段的影响。

研究方法: InnerControl通过轻量级卷积探针从中间UNet特征重建输入控制信号，并在整个扩散过程中最小化预测与目标条件的差异。

研究结果: 结合ControlNet++等技术，InnerControl在多种控制方法（如边缘、深度）上实现了最先进的性能。

研究结论: InnerControl通过全阶段空间一致性优化，显著提升了控制精度和生成质量。

中文摘要: 尽管文本到图像扩散模型取得了显著进展，但在生成输出上实现精确的空间控制仍具挑战性。ControlNet通过引入辅助条件模块解决这一问题，而ControlNet++则通过仅应用于最终去噪步骤的循环一致性损失进一步优化对齐。然而，这种方法忽略了中间生成阶段，限制了其效果。我们提出InnerControl，一种在所有扩散步骤中强制空间一致性的训练策略。我们的方法训练轻量级卷积探针，从每个去噪步骤的中间UNet特征中重建输入控制信号（如边缘、深度）。这些探针即使从高度噪声的潜在空间中也能高效提取信号，为训练提供伪真实控制。通过在整个扩散过程中最小化预测与目标条件的差异，我们的对齐损失提高了控制保真度和生成质量。结合ControlNet++等现有技术，InnerControl在多种条件方法（如边缘、深度）上实现了最先进的性能。

</details>


### [50] [Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model](https://arxiv.org/abs/2507.02322)
**中文标题：基于神经网络的水稻叶病识别与分类研究：特征模型与直接图像模型的对比分析**

*Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi*

主要分类: cs.CV

摘要简述: 本研究提出基于人工神经网络的图像处理技术，用于水稻叶病的分类与识别。通过对比特征分析检测模型（FADM）和直接图像中心检测模型（DICDM），发现FADM在性能上更优，为水稻病害检测提供了潜在的高效解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 水稻叶病严重影响产量并造成经济损失，亟需早期检测以有效管理和提高产量。现有方法多为直接将叶片图像输入神经网络，但缺乏对特征分析检测模型和直接图像中心检测模型的全面对比分析，尤其是特征提取算法的有效性评估。

研究方法: 研究采用特征分析检测模型（FADM），结合多种图像特征提取算法、降维算法、特征选择算法和极限学习机（ELM），并通过10折交叉验证方法对细菌性叶枯病、褐斑病、叶瘟病、叶鞘腐烂病等数据集进行实验。同时建立直接图像中心检测模型（DICDM）作为对比。

研究结果: 实验结果表明，特征分析检测模型（FADM）在分类性能上优于直接图像中心检测模型（DICDM），能够更有效地识别水稻叶病。

研究结论: 特征分析检测模型在检测水稻叶病方面表现出色，有望提升作物健康、减少产量损失，并促进水稻种植的可持续性和整体生产力。

中文摘要: 水稻叶病显著降低产量并造成经济损失，因此亟需早期检测以实现有效管理和提高产量。本研究提出基于人工神经网络（ANN）的图像处理技术，用于水稻叶病的及时分类与识别。尽管现有方法多为直接将叶片图像输入神经网络，但特征分析检测模型（FADM）与直接图像中心检测模型（DICDM）之间的全面对比分析明显不足，尤其是在评估特征提取算法（FEA）的有效性方面。因此，本研究首次对特征分析检测模型进行了实验，采用了多种图像特征提取算法、降维算法（DRA）、特征选择算法（FSA）和极限学习机（ELM）。实验数据集涵盖细菌性叶枯病、褐斑病、叶瘟病、叶鞘腐烂病及健康叶片，并采用10折交叉验证方法。同时，建立了不依赖任何特征提取算法的直接图像中心检测模型，并通过不同指标评估分类性能。最终，对特征分析检测模型和直接图像中心检测模型在水稻叶病分类中的表现进行了详尽对比。结果显示，特征分析检测模型的性能最佳。采用该模型检测水稻叶病，有望显著提升作物健康、减少产量损失，并提高水稻种植的整体生产力和可持续性。

</details>


### [51] [Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection](https://arxiv.org/abs/2507.02349)
**中文标题：两阶段神经网络用于自动化脑血管标志点检测**

*Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau*

主要分类: cs.CV

摘要简述: 本文提出了一种两阶段神经网络方法，用于自动检测颅内动脉瘤（ICA）常见的Willis环（CoW）分叉点，通过目标检测网络和改良U-Net结合，显著提升了检测准确率。


<details>
  <summary>详细信息</summary>
研究动机: 颅内动脉瘤多发生于Willis环的特定分叉点，准确检测这些关键点对快速诊断至关重要。然而，传统方法因分叉点视觉特征相似且位置接近，容易漏检，且CoW的解剖变异性增加了检测难度。

研究方法: 方法分为两步：首先用目标检测网络定位感兴趣区域（ROIs），随后利用改良的U-Net精确定位分叉点。该方法解决了分叉点视觉相似性和解剖变异性的问题。

研究结果: 实验在内部数据集和公开数据集上进行，结果显示该方法在分叉点检测任务中表现最优。

研究结论: 两阶段神经网络方法显著提升了Willis环分叉点的检测准确率，为颅内动脉瘤的自动化诊断提供了有效工具。

中文摘要: 颅内动脉瘤（ICA）通常发生在Willis环（CoW）的特定节段，主要集中在13个主要动脉分叉处。准确检测这些关键标志点对快速高效诊断至关重要。我们提出了一种全自动的CoW分叉点检测方法，采用两阶段神经网络流程：首先通过目标检测网络识别标志点附近的感兴趣区域（ROIs），随后利用改良的深度监督U-Net精确定位分叉点。这一方法解决了分叉点视觉特征相似或位置接近导致的漏检问题，同时适应了CoW的解剖变异性对可检测标志点数量的影响。我们在两个脑部MRA数据集上评估了方法的有效性：内部数据集包含不同数量的标志点，公开数据集则采用标准化标志点配置。实验结果表明，该方法在分叉点检测任务中达到了最高性能水平。

</details>


### [52] [Lightweight Shrimp Disease Detection Research Based on YOLOv8n](https://arxiv.org/abs/2507.02354)
**中文标题：基于YOLOv8n的轻量级虾病检测研究**

*Fei Yuhuan,Wang Gengchen,Liu Fenghao,Zang Ran,Sun Xufei,Chang Hao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于YOLOv8n的轻量级网络架构，用于虾病检测。通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度。改进的SegNext_Attention自注意力机制进一步提升了特征提取能力。实验表明，模型在参数减少32.3%的情况下，mAP@0.5达到92.7%，优于其他轻量级YOLO系列模型。


<details>
  <summary>详细信息</summary>
研究动机: 虾病是虾类养殖中经济损失的主要原因之一。为预防疾病传播并提升智能检测效率，本文旨在开发一种轻量级网络架构，以平衡检测精度与计算效率。

研究方法: 1. 设计RLDD检测头和C2f-EMCM模块，降低计算复杂度。2. 引入改进的SegNext_Attention自注意力机制，增强特征提取能力。3. 在自建虾病数据集和URPC2020数据集上进行广泛实验，包括消融研究和对比评估。

研究结果: 模型参数减少32.3%，mAP@0.5达到92.7%（比YOLOv8n提升3%），在URPC2020数据集上mAP@0.5比YOLOv8n提升4.1%。模型在精度和效率上达到最优平衡。

研究结论: 本文提出的方法在虾病智能检测中实现了精度与效率的平衡，为虾类养殖提供了可靠的技术支持。

中文摘要: 虾病是虾类养殖中经济损失的主要原因之一。为预防疾病传播并提升虾类养殖中的智能检测效率，本文提出了一种基于YOLOv8n的轻量级网络架构。首先，通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度，提升了计算效率。随后，引入改进的SegNext_Attention自注意力机制，进一步增强模型的特征提取能力，从而更精准地识别疾病特征。在自建虾病数据集上进行了包括消融研究和对比评估在内的广泛实验，并将泛化测试扩展到URPC2020数据集。结果表明，所提模型参数比原始YOLOv8n减少32.3%，mAP@0.5达到92.7%（比YOLOv8n提升3%）。此外，模型在mAP@0.5、参数数量和模型大小上均优于其他轻量级YOLO系列模型。在URPC2020数据集上的泛化实验进一步验证了模型的鲁棒性，mAP@0.5比YOLOv8n提升4.1%。所提方法在精度与效率之间实现了最优平衡，为虾类养殖中的智能疾病检测提供了可靠的技术支持。

</details>


### [53] [Holistic Tokenizer for Autoregressive Image Generation](https://arxiv.org/abs/2507.02358)
**中文标题：用于自回归图像生成的全息分词器**

*Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi*

主要分类: cs.CV

摘要简述: 本文提出了一种新型图像分词器Hita，用于自回归图像生成，通过全局到局部的分词方案和轻量级融合模块，显著提升了生成质量和训练速度。


<details>
  <summary>详细信息</summary>
研究动机: 传统的自回归图像生成模型逐步生成视觉标记，限制了捕捉标记序列间全局关系的能力，且现有视觉分词器多关注局部图像块，缺乏全局信息。Hita旨在解决这些问题。

研究方法: Hita采用全局到局部的分词方案，结合可学习的全局查询和局部块标记，并通过两种策略优化自回归生成：1) 在序列结构中优先排列全局标记，使用因果注意力保持对先前标记的感知；2) 在解码前通过轻量级融合模块控制信息流，优先处理全局标记。

研究结果: 实验表明，Hita显著加速了自回归生成器的训练速度，并在ImageNet基准测试中取得了2.59 FID和281.9 IS的优异表现，同时能有效捕捉全局图像属性（如纹理、材质和形状）。

研究结论: Hita通过全局到局部的分词方案和优化策略，显著提升了自回归图像生成的性能，并在零样本风格迁移和图像修复中表现出色。

中文摘要: 传统的自回归图像生成模型逐步生成视觉标记，限制了捕捉标记序列间全局关系的能力。此外，大多数视觉分词器将局部图像块映射为潜在标记，导致全局信息有限。为此，我们提出了Hita，一种用于自回归图像生成的新型图像分词器。它采用了一种全局到局部的分词方案，结合可学习的全局查询和局部块标记。Hita还引入了两种关键策略以优化与自回归生成过程的匹配：1) 在序列结构中优先排列全局标记，随后是块级标记，同时使用因果注意力保持对先前标记的感知；2) 在将去量化标记输入解码器之前，Hita采用轻量级融合模块控制信息流，优先处理全局标记。大量实验表明，Hita显著加速了自回归生成器的训练速度，并在ImageNet基准测试中取得了2.59 FID和281.9 IS的优异表现。对全局表示的详细分析表明，其能够捕捉纹理、材质和形状等全局图像属性。此外，Hita在零样本风格迁移和图像修复中也表现出色。代码发布于https://github.com/CVMI-Lab/Hita。

</details>


### [54] [LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling](https://arxiv.org/abs/2507.02363)
**中文标题：LocalDyGS：通过自适应局部隐式特征解耦实现多视角全局动态场景建模**

*Jiahao Wu,Rui Peng,Jianbo Jiao,Jiayu Yang,Luyang Tang,Kaiqiang Xiong,Jie Liang,Jinbo Yan,Runling Liu,Ronggang Wang*

主要分类: cs.CV

摘要简述: LocalDyGS提出了一种新的动态场景建模方法，通过自适应局部隐式特征解耦，能够同时处理大尺度和小尺度的动态场景，显著提升了动态视频合成的真实感。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的动态场景通常包含复杂且高度动态的运动，传统的基于神经辐射场或3D高斯泼溅的方法难以同时建模大尺度和小尺度的运动，限制了其应用范围。

研究方法: LocalDyGS将复杂动态场景分解为由种子定义的局部空间，通过静态特征和动态残差场的解耦建模每个局部空间内的运动，最终生成时间高斯分布以实现动态场景的全局建模。

研究结果: 该方法在多种小尺度数据集上表现出与现有最优方法相当的竞争力，并首次实现了对大尺度复杂动态场景的建模。

研究结论: LocalDyGS为高度动态场景的建模提供了一种新颖且高效的框架，显著提升了动态视频合成的真实感和适用范围。

中文摘要: 由于现实世界中复杂且高度动态的运动，从多视角输入合成任意视角的动态视频具有挑战性。以往基于神经辐射场或3D高斯泼溅的方法局限于建模小尺度运动，极大地限制了其应用。本文提出LocalDyGS，包含两部分以适应大尺度和小尺度动态场景：1）将复杂动态场景分解为由种子定义的局部空间，通过捕获每个局部空间内的运动实现全局建模；2）对局部空间运动建模时解耦静态和动态特征。静态特征跨时间步共享以捕获静态信息，而动态残差场提供时间特定特征。这些特征结合并解码生成时间高斯分布，建模每个局部空间内的运动。因此，我们提出了一种新颖的动态场景重建框架，更真实地建模高度动态的现实场景。我们的方法不仅在各种小尺度数据集上表现出与现有最优方法相当的竞争力，还首次尝试建模更大更复杂的高度动态场景。项目页面：https://wujh2001.github.io/LocalDyGS/。

</details>


### [55] [UVLM: Benchmarking Video Language Model for Underwater World Understanding](https://arxiv.org/abs/2507.02373)
**中文标题：UVLM：面向水下世界理解的视频语言模型基准**

*Xizhe Xue,Yang Zhou,Dawei Yan,Ying Li,Haokui Zhang,Rong Xiao*

主要分类: cs.CV

摘要简述: 本文提出了UVLM，一个专注于水下世界理解的视频语言模型基准，通过结合人类专业知识和AI模型构建数据集，涵盖多种水下挑战和任务类型，显著提升了水下场景的理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频语言模型主要关注陆地场景，忽视了水下观测的高需求应用。为填补这一空白，作者提出了UVLM基准，旨在推动水下世界理解的研究。

研究方法: 通过结合人类和AI模型协作构建数据集，涵盖水下典型挑战（如光线变化、水质浑浊和多视角）、多样化的数据（如不同帧率、分辨率、419类海洋生物）和任务类型（分为生物和环境两大类，共20种任务）。设计了具有挑战性的评估指标。

研究结果: 实验表明，在UVLM上微调的视频语言模型显著提升了水下场景理解能力，同时对现有陆地基准（如VideoMME和Perception text）也有轻微改进。

研究结论: UVLM为水下世界理解提供了首个综合性基准，展示了其在水下场景中的潜力，并有望推动相关领域的研究。

中文摘要: 近年来，大型语言模型（LLMs）的成功对人工智能领域产生了深远影响。基于LLMs的众多先进工作被提出并应用于各种场景，其中视频语言模型（VidLMs）尤为广泛使用。然而，现有研究主要集中于陆地场景，忽视了水下观测的高需求应用。为填补这一空白，我们提出了UVLM，一个通过结合人类专业知识和AI模型构建的水下观测基准。为确保数据质量，我们从多角度进行了深入考量。首先，针对水下环境的独特挑战，我们选择了包含光线变化、水质浑浊和多视角的典型水下视频构建数据集。其次，为确保数据多样性，数据集涵盖了多种帧率、分辨率、419类海洋生物以及静态植物和地形。接着，为任务多样性，我们采用了结构化设计，将观测目标分为生物和环境两大类，每类包括内容观测和变化/动作观测，共20种任务类型。最后，我们设计了多项具有挑战性的评估指标，以实现对不同方法的定量比较和分析。在两个代表性VidLMs上的实验表明，在UVLM上微调显著提升了水下世界理解能力，同时对现有陆地基准（如VideoMME和Perception text）也显示出轻微改进潜力。数据集和提示工程将公开释放。

</details>


### [56] [PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection](https://arxiv.org/abs/2507.02393)
**中文标题：PLOT：基于视频目标跟踪的可扩展单目3D目标检测伪标签方法**

*Seokyeong Lee,Sithu Aung,Junyong Choi,Seungryong Kim,Ig-Jae Kim,Junghyun Cho*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视频目标跟踪的伪标签框架（PLOT），用于解决单目3D目标检测（M3OD）中数据稀缺和2D到3D模糊性问题。该方法通过聚合静态和动态对象的伪LiDAR数据，无需多视角设置或额外传感器，显著提升了检测的鲁棒性和可扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 单目3D目标检测（M3OD）面临数据稀缺和2D到3D模糊性的挑战，传统弱监督和伪标签方法受限于领域特定学习或单帧形状信息。本文旨在开发一种仅需视频数据、无需额外传感器或领域训练的鲁棒伪标签框架。

研究方法: 提出PLOT框架，利用视频目标跟踪技术聚合相邻帧中静态和动态对象的伪LiDAR数据，提取3D属性。该方法无需多视角设置、额外传感器或相机位姿，适用于3D数据难以获取的场景。

研究结果: 实验表明，PLOT框架在单目3D目标检测中表现出可靠的准确性和强可扩展性，为M3OD提供了一种实用且高效的解决方案。

研究结论: PLOT框架通过视频目标跟踪生成伪标签，显著提升了单目3D目标检测的性能，为数据稀缺和复杂场景下的3D检测提供了新思路。

中文摘要: 单目3D目标检测（M3OD）长期以来因高标注成本和固有的2D到3D模糊性而面临数据稀缺的挑战。尽管已有多种弱监督和伪标签方法试图解决这些问题，但它们大多受限于领域特定学习或仅依赖单帧形状信息。本文提出了一种新颖的伪标签框架，仅需视频数据且对遮挡更鲁棒，无需多视角设置、额外传感器、相机位姿或领域特定训练。具体而言，我们探索了一种通过目标点跟踪聚合相邻帧中静态和动态对象的伪LiDAR数据的技术，从而在3D数据难以获取的场景中实现3D属性提取。大量实验表明，我们的方法确保了可靠的准确性和强可扩展性，为M3OD提供了一种实用且高效的解决方案。

</details>


### [57] [Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis](https://arxiv.org/abs/2507.02395)
**中文标题：基于增强定位的持续多实例学习在病理全切片图像分析中的应用**

*Byung Hyun Lee,Wongi Jeong,Woojae Han,Kyoungbun Lee,Se Young Chun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CoMEL的持续多实例学习框架，用于病理全切片图像（WSI）的分析，通过增强定位能力和减少遗忘，显著提升了分类和定位的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 多实例学习（MIL）通过弱标签降低了大规模图像（如病理全切片图像）的标注成本，但其在持续任务中的适应性和定位能力尚未充分研究。现有方法主要针对自然图像，无法直接应用于MIL定位任务。

研究方法: CoMEL框架包含三个核心组件：(1) 分组双注意力变换器（GDAT）用于高效实例编码，(2) 基于袋原型的伪标签（BPPL）用于可靠的实例伪标签生成，(3) 正交加权低秩适应（OWLoRA）以减少分类任务中的遗忘。

研究结果: 在三个公开的WSI数据集上的实验表明，CoMEL在持续MIL设置下，袋级分类准确率最高提升11.00%，定位准确率最高提升23.4%，显著优于现有方法。

研究结论: CoMEL通过结合高效实例编码、可靠的伪标签生成和遗忘缓解机制，为病理全切片图像的持续多实例学习提供了有效的解决方案。

中文摘要: 多实例学习（MIL）通过袋级弱标签显著降低了大规模图像（如病理全切片图像）的标注成本。然而，其在持续任务中的适应性和定位能力尚未充分探索。现有的弱增量学习方法主要针对自然图像，利用预训练模型对数百个小块（如16×16）的全局关系进行分析，但这种方法在MIL定位中不可行，因为需要处理大量大块（如256×256）且缺乏全局关系（如癌细胞）。为解决这些问题，我们提出了基于增强定位的持续多实例学习（CoMEL），该框架包含：(1) 分组双注意力变换器（GDAT）用于高效实例编码，(2) 基于袋原型的伪标签（BPPL）用于可靠的实例伪标签生成，(3) 正交加权低秩适应（OWLoRA）以减少袋和实例分类中的遗忘。在三个公开WSI数据集上的实验表明，CoMEL在持续MIL设置下，袋级分类准确率最高提升11.00%，定位准确率最高提升23.4%，显著优于现有方法。

</details>


### [58] [Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection](https://arxiv.org/abs/2507.02398)
**中文标题：超越空间频率：基于像素级时间频率的深度伪造视频检测**

*Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi*

主要分类: cs.CV

摘要简述: 提出一种基于像素级时间频率的深度伪造视频检测方法，通过1D傅里叶变换提取时间不一致性特征，结合注意力机制和联合变换模块，显著提升检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于空间频率的检测器忽略了像素级的时间不一致性，导致无法有效检测时间伪影。本文旨在通过时间频率特征解决这一问题。

研究方法: 方法包括对每个像素进行时间轴上的1D傅里叶变换，提取时间不一致性特征；引入注意力提议模块定位伪影区域；通过联合变换模块整合时空上下文特征。

研究结果: 实验表明，该方法在多种复杂检测场景中表现优异，显著提升了深度伪造视频的检测能力。

研究结论: 本文提出的基于像素级时间频率的检测框架在深度伪造视频检测领域取得了重要进展，具有广泛的应用潜力。

中文摘要: 我们提出了一种深度伪造视频检测方法，利用像素级时间不一致性特征，这是传统基于空间频率的检测器常常忽略的。传统检测器仅通过跨帧堆叠空间频率谱来表示时间信息，导致无法检测像素平面上的时间伪影。我们的方法对每个像素在时间轴上执行1D傅里叶变换，提取对时间不一致性高度敏感的特征，尤其是在容易出现不自然运动的区域。为了精确定位包含时间伪影的区域，我们引入了一个端到端训练的注意力提议模块。此外，我们的联合变换模块有效地将像素级时间频率特征与时空上下文特征相结合，扩展了可检测伪造伪影的范围。我们的框架在深度伪造视频检测领域取得了显著进展，在多样化和具有挑战性的检测场景中提供了鲁棒的性能。

</details>


### [59] [TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation](https://arxiv.org/abs/2507.02399)
**中文标题：TABNet：一种基于三重增强自恢复框架和边界感知伪标签的医学图像分割方法**

*Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang*

主要分类: cs.CV

摘要简述: TABNet提出了一种基于涂鸦标注的弱监督医学图像分割框架，通过三重增强自恢复模块和边界感知伪标签监督模块，显著提升了分割性能，接近全监督方法的水平。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割需要大量标注数据，但全标注成本高且耗时。涂鸦标注作为一种稀疏标注方式虽高效，但缺乏边界监督，限制了模型性能。TABNet旨在解决这一问题。

研究方法: TABNet包含三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS通过强度变换、区域遮挡和拼图增强提升特征学习；BAP通过双分支预测融合和边界感知损失优化伪标签和边界建模。

研究结果: 在ACDC和MSCMR seg数据集上的实验表明，TABNet显著优于现有弱监督方法，性能接近全监督方法。

研究结论: TABNet通过增强特征学习和边界建模，有效提升了涂鸦标注下的医学图像分割性能，为弱监督分割提供了新思路。

中文摘要: 背景与目标：医学图像分割是临床应用中的核心任务，但获取大规模全标注数据集耗时且昂贵。涂鸦标注作为一种稀疏标注方式，为医学图像分割提供了高效且经济的替代方案。然而，涂鸦标注的稀疏性限制了目标区域的特征学习，并缺乏足够的边界监督，为分割网络的训练带来了挑战。方法：我们提出TABNet，一种新型弱监督医学图像分割框架，包含两个关键组件：三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS模块通过三种互补的增强策略（强度变换、区域遮挡和拼图增强）提升特征学习；BAP模块通过融合双分支预测和引入边界感知损失优化伪标签和边界建模。结果：在ACDC和MSCMR seg数据集上的实验表明，TABNet显著优于现有弱监督方法，性能接近全监督方法。

</details>


### [60] [Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings](https://arxiv.org/abs/2507.02403)
**中文标题：基于自监督学习的非城市环境下野生动物目标重识别**

*Mufhumudzi Muthivhi,Terence L. van Zyl*

主要分类: cs.CV

摘要简述: 本文研究了自监督学习在野生动物重识别中的应用，通过无监督方式从相机陷阱数据中提取图像对训练模型，实验表明自监督模型在数据有限时表现更优，且在下游任务中优于监督学习。


<details>
  <summary>详细信息</summary>
研究动机: 当前野生动物重识别依赖标注数据进行监督学习，但标注数据获取成本高。本文探索自监督学习（SSL）的潜力，旨在减少对标注数据的依赖，同时提升模型性能。

研究方法: 研究利用相机陷阱数据中的时间序列图像对，自动提取个体的不同视角，训练自监督模型。通过对比监督学习和自监督学习的特征表示，评估其在开放世界场景和下游任务中的表现。

研究结果: 实验结果显示，自监督模型在数据有限时更具鲁棒性，且在所有下游任务中的表现均优于监督学习模型。

研究结论: 自监督学习为野生动物重识别提供了一种高效且无需大量标注数据的方法，其性能优于传统监督学习，具有广泛应用潜力。

中文摘要: 野生动物重识别的目标是在不同观测中匹配同一物种的个体。当前最先进的模型依赖类别标签训练监督学习模型进行个体分类，这种对标注数据的依赖促使了大规模野生动物数据集的构建。本研究探讨了自监督学习（SSL）在野生动物重识别中的应用。我们通过无监督方式从相机陷阱数据中提取时间序列图像对，自动生成个体的不同视角，并利用这些图像对训练自监督模型。实验评估了自监督学习特征与监督学习特征在开放世界场景及多种野生动物下游任务中的表现。结果表明，自监督模型在数据有限时更具鲁棒性，且在所有下游任务中表现优于监督学习。代码发布于https://github.com/pxpana/SSLWildlife。

</details>


### [61] [PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration](https://arxiv.org/abs/2507.02405)
**中文标题：PosDiffAE：结合伪影修复的高分辨率脑组织分类位置感知扩散自编码器**

*Ayantika Das,Moitreya Chaudhuri,Koushik Bhat,Keerthi Ram,Mihail Bota,Mohanasankar Sivaprakasam*

主要分类: cs.CV

摘要简述: 本文提出了一种结合位置感知扩散自编码器（PosDiffAE）的方法，用于高分辨率脑组织分类及伪影修复。通过结构化潜在空间和改进生成能力，实现了脑组织类型的区分和伪影的无监督修复。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成高质量图像方面表现出色，但缺乏提取图像语义表示的能力。自编码器能够提供这种能力，但其生成质量不如扩散模型。因此，本文旨在结合两者的优势，构建一个既能提取语义表示又能生成高质量图像的模型，并应用于脑组织分类和伪影修复。

研究方法: 1. 设计了一种扩散自编码器模型，通过回归高分辨率图像块的位置信息来结构化潜在空间，以区分脑组织类型。2. 提出了一种基于邻域感知的无监督撕裂伪影修复技术，利用潜在表示和扩散模型的生成能力。3. 开发了一种无监督JPEG伪影修复技术，通过表示引导和扩散模型的可控噪声与去噪能力。

研究结果: 模型成功构建了一个结构化的潜在空间，能够有效区分脑组织类型，并实现了撕裂伪影和JPEG伪影的无监督修复。

研究结论: PosDiffAE通过结合扩散模型和自编码器的优势，不仅能够生成高质量图像，还能提取语义表示并修复伪影，为脑组织分类和图像修复提供了新的解决方案。

中文摘要: 去噪扩散模型通过逐步捕获图像分布，从简单分布初始化并逐步增加复杂性，生成高质量图像样本。尽管这些模型开启了新的应用可能性，但其采样机制无法提取图像特定的语义表示，而这正是自编码器的固有优势。自编码器的编码组件能够将特定图像映射到潜在空间，从而提供在潜在空间中强制结构的明确手段。通过将编码器与扩散模型结合，我们建立了一种自编码形式，能够学习图像特定表示并组织潜在空间。本文中，首先，我们设计了一种机制来结构化扩散自编码模型的潜在空间，以识别脑图像中的区域特定细胞模式。我们强制表示回归高分辨率图像块的位置信息，从而为区分脑组织类型创造了有利的潜在空间。其次，我们基于邻域感知设计了一种无监督撕裂伪影修复技术，利用潜在表示和扩散模型在推理时的受限生成能力。第三，通过表示引导和利用扩散模型在推理时可控制的噪声与去噪能力，我们开发了一种无监督JPEG伪影修复技术。

</details>


### [62] [A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern](https://arxiv.org/abs/2507.02408)
**中文标题：一种利用热成像传感器处理复杂运动模式的实时多目标跟踪新颖调优方法**

*Duong Nguyen-Ngoc Tran,Long Hoang Pham,Chi Dai Tran,Quoc Pham-Nam Ho,Huy-Hung Nguyen,Jae Wook Jeon*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的调优方法，用于热成像传感器中的多目标实时跟踪，特别针对复杂运动模式，通过优化两阶段框架，显著提升了行人跟踪的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在低可见度或光线不足的环境中，RGB相机难以有效工作，而热成像传感器通过捕捉红外特征增强了识别任务。然而，热成像的低层次特征表示使得行人检测和跟踪变得困难，因此需要一种专门针对热成像复杂运动模式的跟踪方法。

研究方法: 论文提出了一种两阶段调优框架，通过为每个阶段选择最合适的超参数来优化跟踪性能。该方法不依赖复杂的重识别或运动模型，而是通过超参数微调实现高精度实时跟踪。

研究结果: 在PBVS Thermal MOT数据集上的大量实验表明，该方法在各种热成像相机条件下均表现出色，为实际监控应用提供了鲁棒的解决方案。

研究结论: 本文提出的调优方法在热成像多目标跟踪中表现出高效性和鲁棒性，为复杂环境下的实时监控提供了实用工具。

中文摘要: 热成像中的多目标跟踪对于监控系统至关重要，尤其是在RGB相机因低可见度或光线不足而难以工作的挑战性环境中。热成像传感器通过捕捉红外特征增强了识别任务，但其低层次特征表示使得行人检测和跟踪变得困难。为此，本文提出了一种新颖的行人跟踪调优方法，专门针对热成像中的复杂运动模式。所提出的框架优化了两阶段过程，确保每个阶段采用最合适的超参数以最大化跟踪性能。通过为实时跟踪微调超参数，该方法在不依赖复杂重识别或运动模型的情况下实现了高精度。在PBVS Thermal MOT数据集上的大量实验表明，该方法在各种热成像相机条件下均表现出色，为实际监控应用提供了鲁棒的解决方案。

</details>


### [63] [Privacy-preserving Preselection for Face Identification Based on Packing](https://arxiv.org/abs/2507.02414)
**中文标题：基于打包的隐私保护人脸识别预选方法**

*Rundong Xin,Taotao Wang,Jin Wang,Chonghe Zhao,Jing Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于打包的隐私保护预选方法（PFIP），用于加密域中的人脸识别，显著提高了检索效率并保持了识别精度。


<details>
  <summary>详细信息</summary>
研究动机: 随着加密模板库规模的扩大，人脸检索过程变得耗时且效率低下，同时隐私问题日益突出。本文旨在解决加密域中人脸检索的高效性问题。

研究方法: PFIP结合了创新的预选机制以减少计算开销，并引入打包模块以增强生物识别系统在注册阶段的灵活性。

研究结果: 在LFW和CASIA数据集上的实验表明，PFIP在保持原始人脸识别模型精度的同时，检索1000个加密人脸模板仅需300毫秒，命中率达100%，检索效率提升了近50倍。

研究结论: PFIP是一种高效且隐私保护的加密域人脸检索方案，显著提升了检索效率并保持了系统准确性。

中文摘要: 由于隐私问题日益突出以及原始面部数据可能被恢复，加密域中的人脸识别系统受到了广泛关注。然而，随着加密模板库规模的扩大，人脸检索过程变得越来越耗时。为解决这一问题，我们提出了一种新颖且高效的加密域人脸检索方案，称为基于打包的隐私保护预选方法（PFIP）。PFIP结合了创新的预选机制以减少计算开销，并引入打包模块以增强生物识别系统在注册阶段的灵活性。在LFW和CASIA数据集上进行的大量实验表明，PFIP保持了原始人脸识别模型的准确性，检索1000个加密人脸模板仅需300毫秒，命中率达100%。与现有方法相比，PFIP的检索效率提升了近50倍。

</details>


### [64] [Determination Of Structural Cracks Using Deep Learning Frameworks](https://arxiv.org/abs/2507.02416)
**中文标题：基于深度学习框架的结构裂缝检测方法**

*Subhasis Dasgupta,Jaydip Sen,Tuhina Halder*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的结构裂缝检测方法，通过残差U-Net模型和集成学习技术显著提升了检测精度和效率，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 结构裂缝检测对公共安全至关重要，但传统人工检测效率低且易出错。本研究旨在利用深度学习技术解决这些问题，实现更可靠的结构缺陷监测。

研究方法: 研究采用残差U-Net模型，并结合集成学习方法，通过卷积块构建元模型，进一步提升检测性能。模型性能通过IoU和DICE系数评估。

研究结果: 实验表明，残差U-Net模型在低分辨率图像中表现优异，集成模型性能超越单一模型，成为最有效的检测方法。

研究结论: 该研究为结构缺陷监测提供了更可靠的自动化解决方案，展示了深度学习在裂缝检测中的巨大潜力。

中文摘要: 结构裂缝检测是保障公共安全的关键任务，能够预防潜在的结构失效风险。传统人工检测效率低、一致性差且易出错，影响评估可靠性。本研究提出了一种新型深度学习架构，旨在提升结构裂缝检测的准确性和效率。研究采用了多种残差U-Net模型配置，这些模型因其捕捉细节的能力而被进一步集成到一个包含卷积块的元模型中。这种独特组合旨在超越单一模型的预测效率。集成模型的性能与SegNet和传统U-Net等成熟架构进行了对比。结果显示，残差U-Net模型在低分辨率图像中表现更优，而集成模型则超越了单一模型，成为最有效的检测方法。评估基于交并比（IoU）和DICE系数，集成模型取得了最高分，表明其具有卓越的准确性。这一进展为结构缺陷监测任务提供了更可靠的自动化系统。

</details>


### [65] [AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars](https://arxiv.org/abs/2507.02419)
**中文标题：AvatarMakeup：面向3D可动画头像的真实化妆转移**

*Yiming Zhong,Xiaolin Zhang,Ligang Liu,Yao Zhao,Yunchao Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为AvatarMakeup的3D化妆方法，利用预训练扩散模型从单张参考照片中转移化妆效果，确保动态表情和多视角下的化妆一致性，并通过细化模块提升细节质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D虚拟头像的个性化化妆技术存在不足，无法满足动态表情和多视角下的化妆一致性、身份保持及细节精确控制的需求。

研究方法: 采用从粗到细的策略，首先通过Coherent Duplication方法粗粒度地应用化妆并确保一致性，然后利用扩散模型的细化模块提升化妆细节质量。

研究结果: 实验表明，AvatarMakeup在化妆转移质量和动画一致性方面达到了最先进水平。

研究结论: AvatarMakeup成功解决了3D虚拟头像化妆中的关键问题，为个性化定制提供了高效解决方案。

中文摘要: 与现实生活中的面部美化类似，3D虚拟头像需要个性化定制以提升视觉吸引力，但这一领域的研究仍显不足。尽管现有的3D高斯编辑方法可用于面部化妆，但这些方法无法满足实现真实化妆效果的基本要求：1）在可驱动表情下保持外观一致，2）在化妆过程中保持身份不变，3）实现对精细细节的精确控制。为此，我们提出了一种名为AvatarMakeup的专用3D化妆方法，利用预训练的扩散模型从任意个体的单张参考照片中转移化妆图案。我们采用从粗到细的思路，首先保持外观和身份的一致性，然后细化细节。具体而言，扩散模型用于生成化妆图像作为监督。由于扩散过程中的不确定性，生成的图像在不同视角和表情下不一致。因此，我们提出了一种Coherent Duplication方法，粗粒度地将化妆应用于目标头像，同时确保动态和多视角效果的一致性。Coherent Duplication通过记录生成的化妆图像中的平均面部属性来优化全局UV贴图。通过查询全局UV贴图，可以轻松合成任意视角和表情下的连贯化妆指导，以优化目标头像。在获得粗粒度化妆头像后，我们通过将细化模块整合到扩散模型中进一步提升化妆质量。实验表明，AvatarMakeup在化妆转移质量和动画一致性方面达到了最先进水平。

</details>


### [66] [F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning](https://arxiv.org/abs/2507.02437)
**中文标题：F²TTA：基于图像级解耦提示调谐的跨域医学图像分类自由形式测试时适应**

*Wei Li,Jingyang Zhang,Lihao Liu,Guoan Wang,Junjun He,Yang Chen,Lixu Gu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为F²TTA的自由形式测试时适应方法，通过图像级解耦提示调谐（I-DiPT）解决跨域医学图像分类问题。该方法利用不确定性导向掩码（UoM）和平行图蒸馏（PGD）技术，有效应对测试数据中不可预测的域偏移，实验表明其在乳腺癌和青光眼分类任务中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在临床实践中，医学数据通常以任意长度和随机顺序的域片段形式到达，导致现有测试时适应（TTA）方法无法有效处理这种自由形式的数据流。本文旨在解决这一问题，提出一种适应自由形式域片段的TTA方法。

研究方法: 本文提出图像级解耦提示调谐（I-DiPT）框架，包含图像不变提示和图像特定提示，分别用于提取域不变特征和适应单个测试图像。通过不确定性导向掩码（UoM）和平行图蒸馏（PGD）技术，提升提示的知识表示能力。

研究结果: 在乳腺癌和青光眼分类任务上的实验表明，F²TTA方法在自由形式测试时适应任务中显著优于现有TTA方法。

研究结论: 本文提出的F²TTA方法通过I-DiPT框架和UoM、PGD技术，有效解决了自由形式测试数据中的域偏移问题，为跨域医学图像分类提供了实用解决方案。

中文摘要: 测试时适应（TTA）因其能够利用未标注测试数据适应源模型到未见医学站点而成为一种有前景的解决方案。现有TTA方法假设数据以一个或多个完整域单位到达，但临床实践中数据通常以任意长度和随机顺序的域片段形式到达。本文研究了一种实用的自由形式测试时适应（F²TTA）任务，其中源模型需适应此类自由形式域片段，且片段间偏移不可预测。为解决此问题，我们提出了一种新颖的图像级解耦提示调谐（I-DiPT）框架。I-DiPT利用图像不变提示探索域不变表示以缓解不可预测偏移，并利用图像特定提示将源模型适应到每个测试图像。由于仅有一幅图像可用于训练，提示可能面临知识表示不足的问题。为此，我们首先引入不确定性导向掩码（UoM），通过基于源模型表示不确定性的掩码一致性学习，鼓励提示从输入图像中提取充分信息。随后，我们进一步提出平行图蒸馏（PGD）方法，通过平行图网络复用历史图像特定和图像不变提示的知识。在乳腺癌和青光眼分类任务上的实验证明了我们的方法在F²TTA中优于现有TTA方法。代码发布于https://github.com/mar-cry/F2TTA。

</details>


### [67] [Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic](https://arxiv.org/abs/2507.02443)
**中文标题：在FPGA可编程逻辑中加速人工神经网络的红葡萄检测**

*Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias*

主要分类: cs.CV

摘要简述: 本文提出了一种在FPGA的可编程逻辑中部署加速人工神经网络的方法，用于红葡萄检测。通过FINN架构部署三种量化ANN模型，MobileNet v1表现最佳，达到98%的成功率和6611 FPS的推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 机器人在移动检测物体时通常会因算法速度限制而降低效率。现有工具如Vitis-AI未能充分利用FPGA的可编程逻辑（PL），因此需要一种更高效的方法来加速检测算法。

研究方法: 使用FINN架构在FPGA的PL中部署三种量化ANN模型：4位量化的MobileNet v1、2位量化的CNV和1位量化的CNV（BNN）。模型在自采集的RG2C数据集上训练。

研究结果: MobileNet v1表现最优，成功率达98%，推理速度为6611 FPS，证明了FPGA加速ANN的可行性。

研究结论: 本研究证实了FPGA可用于加速ANN，使其适用于注意力机制等任务，提升了机器人的检测效率。

中文摘要: 机器人在移动检测物体时通常会因算法速度限制而降低效率，且相机的低帧率配置进一步限制了任务执行速度。AMD开发的Vitis-AI框架虽可将检测算法部署到FPGA中，但未能充分利用FPGA的可编程逻辑（PL）。本研究采用FINN架构，在FPGA的PL中部署了三种人工神经网络：4位量化的MobileNet v1、2位量化的CNV和1位量化的CNV（BNN）。模型在自采集的RG2C数据集上训练。结果显示，MobileNet v1表现最佳，成功率达98%，推理速度为6611 FPS。本研究证明了FPGA可用于加速ANN，使其适用于注意力机制等任务。

</details>


### [68] [From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding](https://arxiv.org/abs/2507.02790)
**中文标题：从长视频到吸引人的短视频：一种基于多模态叙事理解的人类启发式视频编辑框架**

*Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多模态叙事理解的自动视频编辑框架（HIVE），通过结合角色提取、对话分析和叙事摘要，显著提升了长视频到短视频的编辑质量，并在新基准数据集DramaAD上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 随着短视频平台的兴起，如何高效地将长视频编辑为吸引人的短视频成为迫切需求。现有方法主要依赖文本线索，忽略了丰富的视觉上下文，导致编辑结果不连贯。本文旨在通过多模态叙事理解解决这一问题。

研究方法: 提出HIVE框架，结合角色提取、对话分析和叙事摘要，利用多模态大语言模型全面理解视频内容。通过场景级分割将编辑过程分为高光检测、开头/结尾选择和无关内容修剪三个子任务。

研究结果: 实验结果表明，HIVE在通用和广告导向的编辑任务中均优于现有基线，显著缩小了自动编辑与人工编辑视频的质量差距。

研究结论: HIVE框架通过多模态叙事理解提升了视频编辑的连贯性和吸引力，为自动视频编辑领域提供了新的研究方向。

中文摘要: 随着在线视频内容的快速增长，尤其是短视频平台的兴起，高效编辑长视频为简洁且吸引人的短视频的需求日益迫切。现有的自动编辑方法主要依赖ASR转录的文本线索和端到端片段选择，往往忽略了丰富的视觉上下文，导致输出不连贯。本文提出了一种人类启发式的自动视频编辑框架（HIVE），通过多模态叙事理解解决这些局限性。我们的方法结合了角色提取、对话分析和叙事摘要，利用多模态大语言模型实现对视频内容的全面理解。为进一步提升连贯性，我们采用场景级分割，并将编辑过程分解为三个子任务：高光检测、开头/结尾选择和无关内容修剪。为促进该领域研究，我们引入了DramaAD，一个包含800多集短剧和500个专业编辑广告片段的新基准数据集。实验结果表明，我们的框架在通用和广告导向的编辑任务中均显著优于现有基线，大幅缩小了自动编辑与人工编辑视频的质量差距。

</details>


### [69] [IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising](https://arxiv.org/abs/2507.02445)
**中文标题：IGDNet：基于照明引导和去噪的零样本鲁棒低曝光图像增强**

*Hailong Yan,Junjian Huang,Tingwen Huang*

主要分类: cs.CV

摘要简述: IGDNet是一种零样本增强方法，无需训练数据或先验知识，通过分解和去噪模块有效恢复低曝光图像的照明并抑制噪声，在复杂光照条件下显著提升视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖成对数据集且可能导致过增强，IGDNet旨在解决这些问题，提供一种无需训练数据的零样本增强方案。

研究方法: IGDNet包含分解模块和去噪模块：前者通过密集连接网络分离图像的照明和反射成分，后者利用照明引导的像素自适应校正方法增强非均匀照明区域。

研究结果: 在四个公开数据集上的实验表明，IGDNet在PSNR（20.41dB）和SSIM（0.860dB）上优于14种无监督方法，显著提升视觉质量。

研究结论: IGDNet在零样本设置下表现出强大的泛化能力，有效恢复照明并抑制噪声，适用于复杂光照条件下的图像增强。

中文摘要: 当前的低曝光图像恢复方法通常依赖于成对的低曝光和良好照明图像的监督学习，但在实际场景中收集此类数据集往往不切实际。此外，这些方法可能导致过增强，扭曲良好照明区域。为解决这些问题，我们提出了IGDNet，一种零样本增强方法，仅需单张测试图像，无需先验知识或训练数据。IGDNet表现出强大的泛化能力，在恢复照明的同时有效抑制噪声。该框架包含分解模块和去噪模块：前者通过密集连接网络将图像分离为照明和反射成分，后者利用照明引导的像素自适应校正方法增强非均匀照明区域。通过下采样生成噪声对并迭代优化以生成最终结果。在四个公开数据集上的大量实验表明，IGDNet在复杂光照条件下显著提升了视觉质量。定量结果显示，其在PSNR（20.41dB）和SSIM（0.860dB）上优于14种最先进的无监督方法。代码即将发布。

</details>


### [70] [Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection](https://arxiv.org/abs/2507.02454)
**中文标题：基于数量提示的弱监督对比学习用于移动红外小目标检测**

*Weiwei Duan,Luping Ji,Shengjia Chen,Sicheng Zhu,Jianghong Huang,Mao Ye*

主要分类: cs.CV

摘要简述: 本文提出了一种弱监督对比学习方案（WeCoL），仅需目标数量提示即可训练模型，用于移动红外小目标检测。该方法结合潜在目标挖掘和对比学习，性能优于传统全监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 移动红外小目标检测因目标尺寸小、背景对比度低而面临巨大挑战。现有方法多为全监督，依赖大量人工标注，成本高昂。本文探索弱监督策略以减少标注需求。

研究方法: 基于预训练的SAM模型，设计潜在目标挖掘策略，结合目标激活图和多帧能量积累。采用对比学习提升伪标签可靠性，并提出长短期运动感知学习方案建模目标运动模式。

研究结果: 在DAUB和ITSDT-15K数据集上的实验表明，该弱监督方案性能优于早期全监督方法，甚至达到SOTA全监督方法90%以上的性能。

研究结论: WeCoL方案通过弱监督和对比学习显著降低了标注成本，同时保持了高性能，为红外小目标检测提供了新思路。

中文摘要: 与一般目标检测不同，移动红外小目标检测因目标尺寸微小和背景对比度弱而面临巨大挑战。目前大多数方法为全监督，严重依赖大量人工目标级标注，但标注视频序列成本高且耗时，尤其是低质量红外帧图像。受通用目标检测启发，非全监督策略（如弱监督）被认为有潜力减少标注需求。为突破传统全监督框架，本文首次提出一种弱监督对比学习（WeCoL）方案，仅需训练期间简单的目标数量提示。具体而言，基于预训练的SAM模型，设计潜在目标挖掘策略，整合目标激活图和多帧能量积累。此外，采用对比学习通过计算特征子空间中正负样本的相似性，进一步提升伪标签可靠性。同时，提出长短期运动感知学习方案，建模小目标的局部运动模式和全局运动轨迹。在DAUB和ITSDT-15K两个公开数据集上的大量实验表明，该弱监督方案性能常优于早期全监督方法，甚至可达SOTA全监督方法90%以上的性能。

</details>


### [71] [Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk](https://arxiv.org/abs/2507.02477)
**中文标题：网格丝绸歌：自回归网格生成如丝绸编织**

*Gaochao Song,Zibo Zhao,Haohan Weng,Jingbo Zeng,Rongfei Jia,Shenghua Gao*

主要分类: cs.CV

摘要简述: Mesh Silksong提出了一种紧凑高效的网格表示方法，通过自回归方式生成多边形网格，类似于丝绸编织。该方法减少了顶点重复，压缩率提升至22%，并生成具有优异几何特性的网格。


<details>
  <summary>详细信息</summary>
研究动机: 现有网格标记化方法常因重复顶点标记而浪费网络能力。Mesh Silksong旨在通过减少冗余标记，提升网格生成效率和几何完整性。

研究方法: Mesh Silksong采用自回归方式生成网格，每个顶点仅访问一次，减少50%的标记冗余，并实现约22%的压缩率。生成的网格具有流形拓扑、水密检测和一致面法线等几何特性。

研究结果: 实验表明，Mesh Silksong不仅能生成复杂网格，还显著提升了几何完整性，压缩率优于现有方法。

研究结论: Mesh Silksong通过优化标记化方法，实现了高效且几何特性优异的网格生成，为实际应用提供了可靠解决方案。

中文摘要: 我们介绍了Mesh Silksong，一种紧凑高效的网格表示方法，专为以自回归方式生成多边形网格而设计，类似于丝绸编织。现有网格标记化方法常因重复顶点标记而浪费网络能力。因此，我们的方法通过仅访问每个顶点一次，将标记序列的冗余减少50%，并实现约22%的压缩率。此外，Mesh Silksong生成的网格具有优异的几何特性，包括流形拓扑、水密检测和一致面法线，这些特性对实际应用至关重要。实验结果证明了该方法的有效性，不仅能生成复杂网格，还显著提升了几何完整性。

</details>


### [72] [Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection](https://arxiv.org/abs/2507.02844)
**中文标题：视觉上下文攻击：通过图像驱动的上下文注入破解多模态大语言模型**

*Ziqi Miao,Yi Ding,Lijun Li,Jing Shao*

主要分类: cs.CV

摘要简述: 本文提出了一种新型视觉上下文攻击（VisCo攻击），通过图像驱动的上下文注入，成功诱导多模态大语言模型（MLLMs）生成有害响应，显著提升了攻击效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）在视觉语言能力上的突破，其安全漏洞问题日益突出。现有研究多通过视觉输入触发有害行为，但缺乏现实场景的语义关联。本文旨在探索视觉信息作为完整且现实攻击上下文的必要性。

研究方法: 提出VisCo攻击，通过四种视觉策略构建上下文对话，必要时动态生成辅助图像以形成视觉中心攻击场景。结合自动毒性混淆和语义优化，生成最终攻击提示，有效触发目标黑盒MLLMs的有害响应。

研究结果: VisCo在MM-SafetyBench上对GPT-4o的毒性评分为4.78，攻击成功率达85%，显著优于基线（毒性2.48，攻击成功率22.2%）。

研究结论: VisCo攻击验证了视觉信息在构建现实攻击上下文中的关键作用，为MLLMs的安全部署提供了重要警示。

中文摘要: 随着多模态大语言模型（MLLMs）在视觉语言能力上的强大表现，其在现实应用中的潜力巨大。然而，视觉模态的安全漏洞为开放环境中的模型部署带来挑战。近期研究通过将有害文本语义直接编码到视觉输入中，成功诱导目标MLLMs生成有害响应。但这些方法中，视觉模态仅作为触发不安全行为的工具，语义模糊且缺乏现实场景关联。本文定义了一种新场景：以视觉为中心的破解，其中视觉信息是构建完整且现实攻击上下文的必要组成部分。基于此，我们提出VisCo（视觉上下文）攻击。VisCo通过四种视觉策略伪造上下文对话，必要时动态生成辅助图像以构建视觉中心攻击场景。为最大化攻击效果，其结合自动毒性混淆和语义优化，生成最终攻击提示，可靠触发目标黑盒MLLMs的有害响应。具体而言，VisCo在MM-SafetyBench上对GPT-4o的毒性评分为4.78，攻击成功率达85%，显著优于基线（毒性2.48，攻击成功率22.2%）。代码发布于https://github.com/Dtc7w3PQ/Visco-Attack。

</details>


### [73] [CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios](https://arxiv.org/abs/2507.02479)
**中文标题：CrowdTrack：真实复杂场景中困难多行人跟踪的基准数据集**

*Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue*

主要分类: cs.CV

摘要简述: 本文提出了一个名为CrowdTrack的大规模复杂场景多行人跟踪数据集，包含33个视频和5,185条轨迹，旨在解决现有数据集场景简单和缺乏真实性的问题，并测试了多种先进模型在该数据集上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多目标跟踪数据集场景过于简单且缺乏真实性，难以支持复杂场景下的算法研究。因此，作者提出一个从第一人称视角拍摄的真实复杂场景数据集，以促进算法在复杂情况下的发展。

研究方法: 作者构建了一个名为CrowdTrack的数据集，包含33个视频和5,185条轨迹，所有视频均来自真实复杂场景，并标注了完整的边界框和唯一对象ID。此外，作者还测试了多种先进模型在该数据集上的表现。

研究结果: CrowdTrack数据集为复杂场景下的多行人跟踪提供了平台，测试结果显示现有先进模型在该数据集上的表现仍有提升空间。

研究结论: CrowdTrack数据集填补了现有数据集的不足，为复杂场景下的多行人跟踪研究提供了重要资源，并展示了现有模型的局限性。

中文摘要: 多目标跟踪是计算机视觉中的经典领域，其中行人跟踪具有极高的应用价值，并成为最热门的研究类别。现有方法主要利用运动或外观信息进行跟踪，但在复杂场景中往往难以实现。对于运动信息，物体之间的相互遮挡常导致运动状态无法更新；对于外观信息，由于物体仅部分可见或图像模糊等原因，往往得到非鲁棒的结果。尽管从标注数据中学习如何在这些情况下进行跟踪是最简单的解决方案，但现有的多目标跟踪数据集无法满足这一需求。现有方法主要有两个缺点：场景组成相对简单和非真实场景。尽管现有数据集中的部分视频序列没有上述缺点，但其数量远不足以满足研究需求。为此，我们提出了一个困难的大规模多行人跟踪数据集，主要从第一人称视角拍摄，且全部来自真实复杂场景。我们将其命名为“CrowdTrack”，因为大多数序列中包含大量物体。我们的数据集包含33个视频，共计5,185条轨迹。每个物体均标注了完整的边界框和唯一对象ID。该数据集将为开发在复杂情况下仍有效的算法提供平台。我们对数据集进行了全面分析，并测试了多种先进模型在该数据集上的表现。此外，我们还分析了基础模型在该数据集上的性能。数据集和项目代码发布于：https://github.com/loseevaya/CrowdTrack。

</details>


### [74] [MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention](https://arxiv.org/abs/2507.02488)
**中文标题：MedFormer：具有内容感知双稀疏选择注意力的分层医学视觉Transformer**

*Zunhui Xia,Hongxing Li,Libin Lan*

主要分类: cs.CV

摘要简述: MedFormer提出了一种高效的医学视觉Transformer，通过金字塔缩放结构和内容感知的双稀疏选择注意力机制，解决了现有方法通用性不足和计算成本高的问题，显著提升了医学图像识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有医学视觉Transformer方法存在两个主要问题：一是任务特定性和架构定制化限制了通用性；二是全注意力机制计算成本高，而手工稀疏注意力可能导致性能不佳。MedFormer旨在解决这些问题，提供一种高效且通用的解决方案。

研究方法: MedFormer采用金字塔缩放结构作为通用主干网络，支持多种医学图像识别任务（如分类、语义分割和病变检测）。其核心是内容感知的双稀疏选择注意力（DSSA），通过动态选择最相关内容提升计算效率和抗噪性能。

研究结果: 在多种医学图像数据集上的实验表明，MedFormer在分类、语义分割和病变检测任务中均显著优于现有方法，同时具备更高的计算效率和通用性。

研究结论: MedFormer通过金字塔结构和DSSA机制，实现了高效且通用的医学图像识别，为临床诊断提供了更准确的工具。

中文摘要: 医学图像识别是辅助临床诊断的关键手段，能够更准确、及时地识别疾病和异常。基于视觉Transformer的方法在多种医学识别任务中表现优异，但仍面临两大挑战：一是任务特定性和架构定制化限制了通用性；二是全注意力机制计算成本高，而手工稀疏注意力可能影响性能。为此，我们提出MedFormer，一种高效的医学视觉Transformer。首先，它采用金字塔缩放结构作为通用主干网络，适用于分类、语义分割和病变检测等多种任务，通过分层特征表示降低计算负载。其次，引入内容感知的双稀疏选择注意力（DSSA），动态选择最相关内容以提升效率和抗噪性。理论分析表明，MedFormer在通用性和效率上优于现有方法。多模态数据集实验证明，MedFormer在三种任务中均显著提升了性能。代码已开源：https://github.com/XiaZunhui/MedFormer。

</details>


### [75] [Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy](https://arxiv.org/abs/2507.02493)
**中文标题：时间感知的监督对比学习用于结肠镜检查中的息肉计数**

*Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi*

主要分类: cs.CV

摘要简述: 本文提出了一种时间感知的监督对比学习方法，用于结肠镜检查中的息肉计数，通过结合时间信息和视觉特征，显著降低了碎片化率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的息肉计数方法主要依赖自监督学习，忽略了时间关系，导致聚类效果不佳。本文旨在通过引入时间感知的监督对比学习，提升息肉计数的准确性和鲁棒性。

研究方法: 提出了一种监督对比损失函数，结合时间感知的软目标，捕捉息肉内变化并保持息肉间区分性；同时引入时间邻接约束，减少视觉相似但时间距离较远的轨迹错误关联。

研究结果: 实验表明，该方法在公开数据集上实现了2.2倍的碎片化率降低，性能优于现有方法。

研究结论: 时间信息对息肉计数至关重要，本文方法通过结合时间感知和监督对比学习，实现了新的最佳性能。

中文摘要: 自动化息肉计数是结肠镜检查报告和质量控制的关键步骤，旨在提高筛查的成本效益。息肉计数涉及检测和跟踪息肉，并对属于同一息肉的轨迹进行聚类。现有方法依赖自监督学习，主要利用视觉特征，忽略了轨迹特征学习和聚类阶段的时间关系。本文提出了一种范式转变，通过引入结合时间感知软目标的监督对比损失函数。该方法在捕捉息肉内变化的同时保持息肉间区分性，从而实现更鲁棒的聚类。此外，通过整合时间邻接约束，减少了视觉相似但时间距离较远的轨迹错误关联。我们在公开数据集上训练和验证了该方法，并使用留一法交叉验证策略评估其性能。结果显示，与现有方法相比，碎片化率降低了2.2倍。我们的结果凸显了时间感知在息肉计数中的重要性，确立了新的最佳性能。代码可在https://github.com/lparolari/temporally-aware-polyp-counting获取。

</details>


### [76] [MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations](https://arxiv.org/abs/2507.02494)
**中文标题：MC-INR：基于元学习和聚类隐式神经表示的多变量科学模拟数据高效编码方法**

*Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong*

主要分类: cs.CV

摘要简述: MC-INR是一种基于元学习和聚类隐式神经表示的高效多变量科学模拟数据编码框架，解决了现有方法在复杂结构和多变量数据上的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有隐式神经表示（INR）方法在复杂结构、多变量数据和非结构化网格上表现不佳，限制了其在真实世界科学数据中的应用。

研究方法: MC-INR结合元学习和聚类技术，通过残差动态重聚类机制和分支层，实现对多变量数据和非结构化网格的高效编码。

研究结果: 实验表明，MC-INR在科学数据编码任务中优于现有方法。

研究结论: MC-INR通过创新的元学习和聚类技术，显著提升了多变量科学数据的编码效率和灵活性。

中文摘要: 隐式神经表示（INR）被广泛用于将数据编码为连续函数，从而以较低的内存占用实现大规模多变量科学模拟数据的可视化。然而，现有的INR方法存在三个主要局限性：（1）对复杂结构的表示不够灵活，（2）主要针对单变量数据，（3）依赖于结构化网格。因此，其在复杂真实数据集上的性能较差。为解决这些问题，我们提出了一种新的神经网络框架MC-INR，用于处理非结构化网格上的多变量数据。该框架结合了元学习和聚类技术，实现了对复杂结构的灵活编码。为进一步提升性能，我们引入了基于残差的动态重聚类机制，根据局部误差自适应地划分聚类。同时，我们还提出了一种分支层，通过独立分支同时利用多变量数据。实验结果表明，MC-INR在科学数据编码任务中优于现有方法。

</details>


### [77] [Automatic Labelling for Low-Light Pedestrian Detection](https://arxiv.org/abs/2507.02513)
**中文标题：低光照行人检测的自动标注方法**

*Dimitrios Bouzoulas,Eerik Alamikkotervo,Risto Ojala*

主要分类: cs.CV

摘要简述: 本文提出了一种自动红外-RGB标注流程，用于低光照条件下的行人检测。通过红外检测、标签传递和模型训练，生成的自动标注在多个指标上优于人工标注。


<details>
  <summary>详细信息</summary>
研究动机: RGB图像中的行人检测是行人安全的关键任务，但低光照条件下缺乏公开数据集。为解决这一问题，研究提出了一种自动标注方法。

研究方法: 方法包括：1) 使用微调的红外行人检测模型进行红外检测；2) 将红外检测标签传递到对应的RGB图像；3) 利用生成的标签训练低光照RGB行人检测模型。

研究结果: 在KAIST数据集上评估，使用自动标注训练的模型在6/9的情况下（mAP@50和mAP@50-95指标）优于使用人工标注训练的模型。

研究结论: 自动标注流程为低光照行人检测提供了高效解决方案，且性能优于传统人工标注。

中文摘要: RGB图像中的行人检测是行人安全的关键任务，而自动驾驶车辆和高级驾驶辅助系统中最常见的传感器是RGB相机。RGB行人检测中的一个挑战是低光照条件，目前缺乏公开的大规模数据集。作为解决方案，本研究提出了一种自动红外-RGB标注流程。该流程包括：1) 红外检测，使用微调的红外行人检测模型；2) 将红外检测标签传递到对应的RGB图像；3) 利用生成的标签训练低光照RGB行人检测模型。研究基于KAIST数据集进行。评估中，使用生成的自动标注和人工标注分别训练目标检测模型。在未见过的图像序列上比较时，结果显示，在mAP@50和mAP@50-95指标中，使用自动标注训练的模型在6/9的情况下优于使用人工标注训练的模型。本研究源代码可在https://github.com/BouzoulasDimitrios/IR-RGB-Automated-LowLight-Pedestrian-Labeling获取。

</details>


### [78] [Detecting Multiple Diseases in Multiple Crops Using Deep Learning](https://arxiv.org/abs/2507.02517)
**中文标题：使用深度学习检测多种作物中的多种疾病**

*Vivek Yadav,Anugrah Jain*

主要分类: cs.CV

摘要简述: 本文提出一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，覆盖印度多样化的农业景观，显著提高了检测准确率和覆盖范围。


<details>
  <summary>详细信息</summary>
研究动机: 印度作为农业经济为主的国家，面临作物疾病、害虫和环境压力导致的严重损失。早期准确检测和识别多种作物疾病对提高产量和保障粮食安全至关重要。

研究方法: 研究首先创建了一个统一的数据集，包含来自不同来源的17种作物和34种疾病的图像。随后训练了一个深度学习模型，该模型在准确率和覆盖作物及疾病数量上优于现有技术。

研究结果: 提出的深度学习模型在统一数据集上实现了99%的检测准确率，比现有技术（覆盖14种作物和26种疾病）高出7%。

研究结论: 通过扩展可检测的作物和疾病类型，该解决方案旨在为印度农民提供更高效的工具，助力农业产量和粮食安全。

中文摘要: 印度作为以农业为主的经济体，面临由疾病、害虫和环境压力导致的重大农业损失。早期检测和准确识别不同作物的疾病对提高产量和保障粮食安全至关重要。本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，旨在覆盖印度多样化的农业景观。我们首先创建了一个统一的数据集，包含来自不同来源的17种作物和34种疾病的图像。提出的深度学习模型在该数据集上训练，并在准确率和覆盖作物及疾病数量上优于现有技术。我们在统一数据集上实现了99%的检测准确率，比现有技术（仅覆盖14种作物和26种疾病）高出7%。通过提高可检测的作物和疾病类型，该解决方案旨在为印度农民提供更好的产品。

</details>


### [79] [IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning](https://arxiv.org/abs/2507.02519)
**中文标题：IMASHRIMP：基于计算机视觉和深度学习的实验室图像自动白虾（凡纳滨对虾）生物测量分析**

*Abiam Remache González,Meriem Chagour,Timon Bijan Rüth,Raúl Trapiella Cañedo,Marina Martínez Soler,Álvaro Lorenzo Felipe,Hyun-Suk Shin,María-Jesús Zamorano Serrano,Ricardo Torres,Juan-Antonio Castillo Parra,Eduardo Reyes Abad,Miguel-Ángel Ferrer Ballester,Juan-Manuel Afonso López,Francisco-Mario Hernández Tejera,Adrian Penate-Sanchez*

主要分类: cs.CV

摘要简述: 本文介绍了IMASHRIMP系统，通过计算机视觉和深度学习技术自动分析白虾形态，优化水产养殖中的遗传选择任务。系统结合了视角分类、额角完整性检测、姿态估计和形态回归模块，显著减少了人工误差，提升了分析效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 水产养殖中，白虾的形态分析对遗传选择至关重要，但传统人工方法效率低且误差高。IMASHRIMP旨在通过自动化的计算机视觉和深度学习技术解决这一问题，提升分析的准确性和效率。

研究方法: IMASHRIMP系统基于改进的ResNet-50架构设计了两个判别模块，用于视角分类和额角完整性检测。此外，系统还集成了基于VitPose的姿态估计模块（预测23个关键点）和基于支持向量机（SVM）的形态回归模块，将像素测量转换为厘米单位。

研究结果: 实验结果显示，IMASHRIMP在视角分类中将人工误差从0.97%降至0%，额角检测误差从12.46%降至3.64%。姿态估计的平均精度（mAP）达到97.94%，像素到厘米的转换误差为0.07（±0.1）厘米。

研究结论: IMASHRIMP系统通过自动化白虾形态分析，显著减少了人工误差，提高了遗传选择的效率，为可持续水产养殖提供了技术支持。

中文摘要: 本文介绍了IMASHRIMP系统，该系统通过改进的计算机视觉和深度学习技术，实现了对白虾（凡纳滨对虾）形态的自动化分析，以优化水产养殖中的遗传选择任务。系统结合了两个基于改进ResNet-50架构的判别模块，用于图像视角分类和额角完整性检测。此外，还提出了“双因素认证（人工与AI）”系统，将视角分类的人工误差从0.97%降至0%，额角检测误差从12.46%降至3.64%。系统还集成了基于VitPose的姿态估计模块，预测虾骨架的23个关键点，并针对侧面和背面视图分别设计了网络。形态回归模块采用支持向量机（SVM）模型，将像素测量转换为厘米单位。实验结果表明，系统有效减少了人工误差，姿态估计的平均精度（mAP）达到97.94%，像素到厘米的转换误差为0.07（±0.1）厘米。IMASHRIMP展示了自动化白虾形态分析的潜力，提升了遗传选择的效率，为可持续水产养殖做出了贡献。代码可在https://github.com/AbiamRemacheGonzalez/ImaShrimp-public获取。

</details>


### [80] [MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details](https://arxiv.org/abs/2507.02546)
**中文标题：MoGe-2：具有度量尺度和清晰细节的精确单目几何**

*Ruicheng Wang,Sicheng Xu,Yue Dong,Yu Deng,Jianfeng Xiang,Zelong Lv,Guangzhong Sun,Xin Tong,Jiaolong Yang*

主要分类: cs.CV

摘要简述: MoGe-2是一种先进的单目几何估计模型，能够从单张图像中恢复具有精确度量尺度的3D点地图，同时保持细节的清晰度。


<details>
  <summary>详细信息</summary>
研究动机: 现有单目几何估计方法（如MoGe）只能预测未知尺度的仿射不变点地图，无法直接恢复度量尺度。此外，真实数据中的噪声和误差会降低几何细节的精细度。本文旨在解决这些问题，实现同时具备精确相对几何、度量尺度和细节恢复能力的模型。

研究方法: MoGe-2基于MoGe方法，通过有效策略扩展其功能以预测度量尺度几何，同时保持仿射不变点表示的相对几何精度。此外，提出了一种统一的数据细化方法，利用合成标签过滤和补全真实数据，显著提升重建几何的细节粒度。

研究结果: 实验表明，MoGe-2在混合数据集上训练后，能够同时实现精确的相对几何、度量尺度和细节恢复，性能优于现有方法。

研究结论: MoGe-2首次实现了单目几何估计中精确相对几何、度量尺度和细节恢复的联合优化，为开放域几何估计提供了新思路。

中文摘要: 我们提出了MoGe-2，一种先进的开放域几何估计模型，能够从单张图像中恢复具有度量尺度的3D点地图。该方法基于最近的单目几何估计方法MoGe，后者预测的是未知尺度的仿射不变点地图。我们探索了有效策略，将MoGe扩展为能够预测度量尺度几何的方法，同时不牺牲仿射不变点表示提供的相对几何精度。此外，我们发现真实数据中的噪声和误差会降低预测几何的精细细节。为此，我们开发了一种统一的数据细化方法，利用清晰的合成标签过滤和补全来自不同来源的真实数据，显著提升了重建几何的细节粒度，同时保持了整体精度。我们在混合数据集上训练了模型，并进行了全面评估，结果表明其在实现精确相对几何、度量尺度和细节恢复方面具有卓越性能——这是以往方法未能同时实现的能力。

</details>


### [81] [Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning](https://arxiv.org/abs/2507.02565)
**中文标题：基于外观和空间关系推理的近距离人体交互重建**

*Buzhen Huang,Chen Li,Chongyang Xu,Dongyue Lu,Jinnan Chen,Yangang Wang,Gim Hee Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种基于外观和空间关系的双分支优化框架，用于从复杂视频中重建准确的人体交互动作，结合了人类行为先验和多种约束条件，显著提升了交互姿态估计的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人体姿态估计方法在复杂视频中难以处理视觉模糊和人际遮挡问题，导致交互动作重建不准确。本文旨在通过利用人类外观和空间关系线索，解决这些挑战。

研究方法: 提出了一种双分支优化框架，结合扩散模型学习人类空间行为先验和姿态知识，并通过3D高斯、2D关键点和网格穿透等约束条件优化重建人体动作和外观。

研究结果: 实验结果表明，该方法在多个基准测试中优于现有方法，能够从复杂环境中准确估计交互动作，并构建了带有伪真实标注的数据集。

研究结论: 通过结合空间行为先验和多样化约束，本文方法显著提升了复杂场景下人体交互动作的重建效果，为未来姿态估计和行为理解研究提供了新方向。

中文摘要: 由于视觉模糊和人际遮挡，现有的人体姿态估计方法难以从真实视频中重建合理的近距离交互动作。即使是当前最先进的大型基础模型（如SAM）也无法在此类复杂场景中准确区分人类语义。本文发现，人类外观可以为解决这些问题提供直接线索。基于这一观察，我们提出了一种双分支优化框架，通过人类外观、社交空间关系和物理规律的约束，重建准确的交互动作。具体而言，我们首先训练扩散模型学习人类空间行为和姿态先验知识，随后将训练好的网络和两个可优化张量整合到双分支优化框架中，以重建人体动作和外观。此外，还设计了基于3D高斯、2D关键点和网格穿透的约束条件辅助优化。借助空间行为先验和多样化约束，我们的方法能够从复杂环境中捕获的真实视频中准确估计交互动作。我们还构建了一个带有伪真实交互标注的数据集，可能推动未来姿态估计和人类行为理解的研究。在多个基准测试上的实验结果表明，我们的方法优于现有方法。代码和数据可在https://www.buzhenhuang.com/works/CloseApp.html获取。

</details>


### [82] [Parametric shape models for vessels learned from segmentations via differentiable voxelization](https://arxiv.org/abs/2507.02576)
**中文标题：基于可微分体素化的分割学习血管参数化形状模型**

*Alina F. Dima,Suprosanna Shit,Huaqi Qiu,Robbie Holland,Tamara T. Mueller,Fabio Antonio Musio,Kaiyuan Yang,Bjoern Menze,Rickmer Braren,Marcus Makowski,Daniel Rueckert*

主要分类: cs.CV

摘要简述: 本文提出了一种通过可微分体素化从分割中学习血管参数化形状模型的方法，结合了体素、网格和参数化模型的优势，实现了高保真度的血管几何建模。


<details>
  <summary>详细信息</summary>
研究动机: 血管是人体内的复杂结构，通常以体素、网格或参数化模型表示，但这些表示通常独立使用。本文旨在通过可微分变换将三者结合，直接从分割数据中学习血管的参数化形状模型，避免对真实形状参数的依赖。

研究方法: 利用可微分体素化技术，通过形状到分割的拟合自动提取血管的参数化形状模型。血管被参数化为中心线和半径，使用三次B样条确保平滑性和连续性。网格从学习到的形状参数中可微分地提取，支持后续操作。

研究结果: 实验表明，该方法能够准确捕捉复杂血管（如主动脉、动脉瘤和脑血管）的几何形状，生成高保真度的网格和体积拟合结果。

研究结论: 通过结合可微分体素化和参数化形状模型，本文提供了一种高效且准确的血管建模方法，适用于多种医学应用场景。

中文摘要: 血管是人体内的复杂结构，已有多种表示方法被广泛研究。尽管体素化是最常见的方式，但网格和参数化模型因其理想特性在多种应用中至关重要。然而，这些表示通常通过分割提取并独立使用。本文提出了一种框架，通过可微分变换将三种表示结合起来。利用可微分体素化，我们通过形状到分割的拟合自动提取血管的参数化形状模型，无需依赖真实形状参数。血管通过三次B样条参数化为中心线和半径，确保平滑性和连续性。网格从学习到的形状参数中可微分地提取，生成高保真度的网格，支持后续操作。实验表明，我们的方法能够准确捕捉复杂血管（如主动脉、动脉瘤和脑血管）的几何形状。

</details>


### [83] [Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning](https://arxiv.org/abs/2507.02581)
**中文标题：结构感知的语义差异与一致性：面向3D医学图像的自监督学习**

*Tan Pan,Zhaorui Tan,Kaiyu Guo,Dongli Xu,Weidi Xu,Chen Jiang,Xin Guo,Yuan Qi,Yuan Cheng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为$S^2DC$的自监督学习框架，通过结构感知的语义差异和一致性，提升了3D医学图像的表征学习能力，并在多数据集和任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D医学图像自监督学习方法通常使用固定大小的图像块划分，忽略了医学图像中解剖结构的位置、尺度和形态变化，导致无法有效捕捉有意义的差异。

研究方法: 提出的$S^2DC$框架通过两个步骤实现结构感知表征学习：1) 利用最优传输策略增强不同图像块的语义差异；2) 基于邻域相似性分布提升结构级别的语义一致性。

研究结果: 在10个数据集、4种任务和3种模态上的实验表明，$S^2DC$在3D医学图像自监督学习中显著优于现有方法。

研究结论: $S^2DC$通过结合图像块和结构级别的表征学习，实现了结构感知的语义差异和一致性，为医学图像分析提供了更有效的自监督学习框架。

中文摘要: 3D医学图像自监督学习（mSSL）在医学分析中具有巨大潜力。为了支持更广泛的应用，需要考虑解剖结构在位置、尺度和形态上的变化，这对捕捉有意义的差异至关重要。然而，现有的mSSL方法通常使用固定大小的图像块划分，忽略了结构变化。本文提出了一种新的视角，旨在学习结构感知的表征。我们假设同一结构内的图像块具有相同的语义（语义一致性），而不同结构的图像块则表现出不同的语义（语义差异）。基于这一假设，我们提出了名为$S^2DC$的mSSL框架，通过两个步骤实现结构感知的语义差异和一致性：首先，$S^2DC$利用最优传输策略增强不同图像块的语义差异；其次，$S^2DC$基于邻域相似性分布提升结构级别的语义一致性。通过结合图像块和结构级别的表征，$S^2DC$实现了结构感知的表征学习。在10个数据集、4种任务和3种模态上的全面评估表明，$S^2DC$在mSSL中显著优于现有方法。

</details>


### [84] [AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding](https://arxiv.org/abs/2507.02591)
**中文标题：AuroraLong：将RNN重新引入高效开放式视频理解**

*Weili Xu,Enxin Song,Wenhao Chai,Xuexiang Wen,Tian Ye,Gaoang Wang*

主要分类: cs.CV

摘要简述: AuroraLong提出了一种基于线性RNN的高效长视频理解方法，通过替换传统Transformer模型，显著降低了计算和内存开销，同时保持了与Transformer模型相当的性能。


<details>
  <summary>详细信息</summary>
研究动机: 长视频理解面临计算复杂度和内存成本高的问题，尤其是基于Transformer的大语言模型（LLM）在处理长序列时计算和内存需求呈二次方增长。AuroraLong旨在通过线性RNN模型解决这一问题，降低计算门槛。

研究方法: AuroraLong采用线性RNN语言模型替代LLM组件，通过恒定大小的隐藏状态处理任意长度的输入序列。此外，通过按视觉令牌大小升序重新排序，结合视觉令牌合并技术，进一步提升吞吐量和效率。

研究结果: 仅使用2B参数并在公开数据上训练的AuroraLong，在多个视频基准测试中表现与基于Transformer的模型相当，展示了线性RNN在长视频理解中的高效潜力。

研究结论: AuroraLong证明了线性RNN模型在降低长视频理解计算门槛方面的有效性，为高效、开放式的视频理解提供了新思路。

中文摘要: 长视频理解的挑战在于其高计算复杂度和高昂的内存成本，因为基于Transformer的大语言模型（LLM）所需的内存和计算量与输入序列长度呈二次方增长。我们提出AuroraLong来解决这一挑战，通过用线性RNN语言模型替换MLLM中的LLM组件，以恒定大小的隐藏状态处理任意长度的输入序列。为了进一步提升吞吐量和效率，我们通过按视觉令牌大小升序重新排序，将视觉令牌合并与线性RNN模型结合。尽管仅使用2B参数且仅在公开数据上训练，AuroraLong在多个视频基准测试中表现与基于Transformer的类似规模模型相当。这表明高效的线性RNN有潜力通过降低计算门槛来普及长视频理解。据我们所知，我们是首个在类似LLaVA的模型中采用基于线性RNN的LLM主干进行开放式视频理解的研究。

</details>


### [85] [Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development](https://arxiv.org/abs/2507.02602)
**中文标题：视觉导航中相机传感器故障的应对：模拟与数据集开发**

*Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill*

主要分类: cs.CV

摘要简述: 本文针对视觉导航中相机传感器故障问题，提出了一种模拟框架和数据集开发方法，以支持AI故障检测算法的训练与测试。


<details>
  <summary>详细信息</summary>
研究动机: 视觉导航算法在太空任务中的重要性日益增加，但传感器故障可能导致导航算法输出不准确或完全失效，威胁任务目标。传统故障检测方法存在局限性，而AI虽能提供解决方案，却缺乏包含故障图像数据的代表性数据集。

研究方法: 研究通过分析行星探索任务中的相机传感器潜在故障案例，系统描述其成因、影响及缓解策略，并开发模拟框架以合成故障图像数据。

研究结果: 生成了一个包含故障注入图像的宝贵数据集，为AI故障检测算法的训练和测试提供了支持。

研究结论: 该研究填补了视觉导航中故障数据集的空白，为AI在故障检测中的应用奠定了基础。

中文摘要: 视觉导航算法在太空任务中的重要性日益凸显，但其可靠性和操作鲁棒性面临诸多挑战。传感器故障可能导致导航算法输出不准确或完全失效，进而威胁任务目标。人工智能（AI）为检测此类故障提供了强大解决方案，克服了传统故障检测方法的许多局限。然而，AI在此领域的应用面临的主要障碍是缺乏足够且具有代表性的故障图像数据集。本研究针对行星探索任务场景，系统分析了视觉导航流程中相机传感器的潜在故障案例，包括其成因、影响及常用缓解策略。为支持分析，研究引入了一个模拟框架，用于在合成图像中重现故障条件，从而系统且可控地生成故障数据。最终生成的故障注入图像数据集为训练和测试基于AI的故障检测算法提供了宝贵工具。数据集链接将在禁运期后公布，审稿人可通过私密链接访问。

</details>


### [86] [AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models](https://arxiv.org/abs/2507.02664)
**中文标题：AIGI-Holmes：基于多模态大语言模型的可解释且泛化性强的AI生成图像检测方法**

*Ziyin Zhou,Yunpeng Luo,Yuanchen Wu,Ke Sun,Jiayi Ji,Ke Yan,Shouhong Ding,Xiaoshuai Sun,Yunsheng Wu,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出了一种名为AIGI-Holmes的可解释且泛化性强的AI生成图像检测方法，通过多模态大语言模型（MLLMs）解决现有技术缺乏可解释性和泛化能力的问题。


<details>
  <summary>详细信息</summary>
研究动机: AI生成内容（AIGC）技术的快速发展导致高度逼真的AI生成图像（AIGI）被滥用于传播虚假信息，威胁公共信息安全。现有AIGI检测技术缺乏可解释性和对最新生成技术的泛化能力，亟需改进。

研究方法: 研究团队构建了大规模数据集Holmes-Set，包括带解释的指令调优数据集Holmes-SFTSet和人类偏好数据集Holmes-DPOSet。提出多专家评审（Multi-Expert Jury）数据标注方法，并通过三阶段训练框架Holmes Pipeline（视觉专家预训练、监督微调和直接偏好优化）训练模型AIGI-Holmes。推理阶段采用协作解码策略结合视觉专家感知和MLLMs语义推理。

研究结果: 在三个基准测试上的广泛实验验证了AIGI-Holmes的有效性，其能够生成人类可验证且符合人类偏好的解释，并具备更强的泛化能力。

研究结论: AIGI-Holmes通过结合多模态大语言模型和结构化数据标注方法，显著提升了AI生成图像检测的可解释性和泛化性，为公共信息安全提供了有力工具。

中文摘要: AI生成内容（AIGC）技术的快速发展导致高度逼真的AI生成图像（AIGI）被滥用于传播虚假信息，威胁公共信息安全。尽管现有AIGI检测技术总体有效，但仍面临两大问题：1）缺乏人类可验证的解释；2）对最新生成技术缺乏泛化能力。为解决这些问题，我们引入了大规模综合数据集Holmes-Set，包括带解释的指令调优数据集Holmes-SFTSet和人类偏好数据集Holmes-DPOSet。我们提出了一种高效的数据标注方法“多专家评审”，通过结构化MLLM解释增强数据生成，并通过跨模型评估、专家缺陷过滤和人类偏好修改实现质量控制。此外，我们设计了Holmes Pipeline三阶段训练框架（视觉专家预训练、监督微调和直接偏好优化），将多模态大语言模型（MLLMs）适配于AIGI检测任务，同时生成人类可验证且符合偏好的解释，最终得到模型AIGI-Holmes。推理阶段引入协作解码策略，结合视觉专家感知和MLLMs语义推理，进一步提升泛化能力。在三个基准测试上的广泛实验验证了AIGI-Holmes的有效性。

</details>


### [87] [Learning few-step posterior samplers by unfolding and distillation of diffusion models](https://arxiv.org/abs/2507.02686)
**中文标题：通过展开和蒸馏扩散模型学习少数步后验采样器**

*Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra*

主要分类: cs.CV

摘要简述: 本文提出了一种新框架，通过深度展开和模型蒸馏将扩散模型转化为少数步长的后验采样器，结合了灵活性和高效性。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在贝叶斯计算成像中表现出强大的潜力，但现有方法要么依赖近似（如即插即用方法），要么需要针对特定任务进行监督训练（如条件扩散模型）。本文旨在结合两者的优势，开发一种既灵活又高效的采样器。

研究方法: 通过深度展开和模型蒸馏，将扩散模型转化为少数步长的条件模型。核心创新是将马尔可夫链蒙特卡洛（MCMC）算法（如LATINO Langevin采样器）进行深度展开，首次将深度展开应用于蒙特卡洛采样方案。

研究结果: 实验表明，提出的展开和蒸馏采样器在准确性和计算效率上均优于现有技术，同时保留了适应前向模型变化的灵活性。

研究结论: 本文提出的框架成功地将扩散模型转化为高效的后验采样器，为贝叶斯计算成像提供了一种新的解决方案。

中文摘要: 扩散模型（DMs）已成为贝叶斯计算成像中强大的图像先验。目前有两种主要策略利用DMs：即插即用方法（零样本且高度灵活，但依赖近似）和专用条件DMs（通过监督训练实现更高精度和更快推理）。本文提出了一种新框架，通过深度展开和模型蒸馏将DM图像先验转化为少数步条件模型用于后验采样。核心创新是将马尔可夫链蒙特卡洛（MCMC）算法（如LATINO Langevin采样器）进行深度展开，这是首次将深度展开应用于蒙特卡洛采样方案。通过大量实验和与现有技术的比较，我们展示了提出的展开和蒸馏采样器在准确性和计算效率上的优异表现，同时保留了推理时适应前向模型变化的灵活性。

</details>


### [88] [APT: Adaptive Personalized Training for Diffusion Models with Limited Data](https://arxiv.org/abs/2507.02687)
**中文标题：APT：面向有限数据的扩散模型自适应个性化训练**

*JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang*

主要分类: cs.CV

摘要简述: 本文提出APT框架，通过自适应训练策略和特征正则化，解决扩散模型在有限数据下微调时的过拟合问题，保持语义一致性和先验知识。


<details>
  <summary>详细信息</summary>
研究动机: 在有限数据下微调扩散模型时，过拟合会导致噪声预测分布偏移，破坏去噪轨迹并丧失语义一致性。本文旨在解决这些问题。

研究方法: APT框架包含三个关键组件：1) 自适应训练调整，通过过拟合指标动态调整数据增强和损失权重；2) 特征表示稳定，正则化中间特征图的均值和方差；3) 注意力对齐，保持微调模型与预训练模型的注意力图一致。

研究结果: 实验表明，APT有效缓解过拟合，保留先验知识，并在有限参考数据下生成高质量、多样化的图像，优于现有方法。

研究结论: APT通过自适应训练和特征正则化，显著提升了扩散模型在有限数据下的微调效果，为个性化生成任务提供了有效解决方案。

中文摘要: 在有限数据下个性化扩散模型面临过拟合、先验知识丢失和文本对齐退化等挑战。过拟合会导致噪声预测分布偏移，破坏去噪轨迹并丧失语义一致性。本文提出自适应个性化训练（APT）框架，通过自适应训练策略和特征正则化缓解过拟合。APT包含三个关键组件：1) 自适应训练调整，通过过拟合指标动态调整数据增强和损失权重；2) 特征表示稳定，正则化中间特征图的均值和方差；3) 注意力对齐，保持微调模型与预训练模型的注意力图一致。实验表明，APT有效缓解过拟合，保留先验知识，并在有限参考数据下生成高质量、多样化图像，优于现有方法。

</details>


### [89] [CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation](https://arxiv.org/abs/2507.02691)
**中文标题：CanonSwap：通过规范空间调制实现高保真且一致的视频人脸交换**

*Xiangyang Luo,Ye Zhu,Yunfei Liu,Lijian Lin,Cong Wan,Zijian Cai,Shao-Lun Huang,Yu Li*

主要分类: cs.CV

摘要简述: CanonSwap提出了一种新的视频人脸交换框架，通过解耦运动与外观信息，在规范空间中实现身份修改，同时保留目标视频的动态属性，显著提升了视觉质量和时间一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频人脸交换方法虽能实现高质量身份转移，但难以保持目标面部的动态属性（如头部姿势、表情等），导致结果不一致。CanonSwap旨在解决这一问题。

研究方法: CanonSwap首先消除运动相关信息，在统一的规范空间中进行身份修改，随后将交换后的特征重新整合到原始视频空间。此外，设计了部分身份调制模块和细粒度同步指标。

研究结果: 实验表明，CanonSwap在视觉质量、时间一致性和身份保留方面显著优于现有方法。

研究结论: CanonSwap通过解耦运动与外观信息，实现了高保真和一致的视频人脸交换，为相关领域提供了新的解决方案。

中文摘要: 视频人脸交换旨在解决两个主要挑战：将源身份有效转移到目标视频，并准确保留目标面部的动态属性（如头部姿势、表情、唇同步等）。现有方法主要关注高质量身份转移，但往往难以保持目标面部的动态属性，导致结果不一致。我们认为这一问题的根源在于视频中面部外观与运动的固有耦合。为此，我们提出CanonSwap，一种新颖的视频人脸交换框架，通过解耦运动与外观信息来解决这一问题。具体而言，CanonSwap首先消除运动相关信息，在统一的规范空间中进行身份修改，随后将交换后的特征重新整合到原始视频空间，确保目标面部动态属性的保留。为进一步实现精确身份转移并减少伪影、增强真实感，我们设计了部分身份调制模块，通过空间掩码自适应地整合源身份特征，限制修改仅作用于面部区域。此外，我们引入多种细粒度同步指标，全面评估视频人脸交换方法的性能。大量实验表明，我们的方法在视觉质量、时间一致性和身份保留方面显著优于现有方法。项目页面公开于https://luoxyhappy.github.io/CanonSwap/。

</details>


### [90] [SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment](https://arxiv.org/abs/2507.02705)
**中文标题：SIU3R：超越特征对齐的同步场景理解与三维重建**

*Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu*

主要分类: cs.CV

摘要简述: SIU3R是首个无需特征对齐的通用框架，通过像素对齐的3D表示统一重建与理解任务，实现端到端的3D场景理解与重建，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖2D到3D特征对齐，导致3D理解能力有限和语义信息丢失。SIU3R旨在解决这一问题，提出无需对齐的框架，实现更高效的场景理解与重建。

研究方法: SIU3R通过像素对齐的3D表示连接重建与理解任务，并将多任务统一为可学习查询集，避免与2D模型对齐。此外，设计了两个轻量模块促进任务间的协作。

研究结果: 实验表明，SIU3R在3D重建、场景理解及两者的联合任务上均达到最优性能，验证了其无对齐框架和协作设计的有效性。

研究结论: SIU3R通过无对齐框架和任务协作设计，显著提升了3D场景理解与重建的性能，为端到端智能系统提供了新思路。

中文摘要: 同步场景理解与三维重建在开发端到端智能系统中至关重要。现有方法依赖2D到3D特征对齐，导致3D理解能力受限和语义信息丢失。为此，我们提出SIU3R，首个无需姿态图像的通用无对齐框架。SIU3R通过像素对齐的3D表示连接重建与理解任务，并将多任务统一为可学习查询集，实现原生3D理解而无需与2D模型对齐。为促进任务协作，我们深入分析其相互增益，并设计两个轻量模块优化交互。大量实验表明，SIU3R不仅在3D重建和场景理解的独立任务上表现优异，在同步任务中也达到最优性能，凸显了无对齐框架和协作设计的优势。

</details>


### [91] [UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation](https://arxiv.org/abs/2507.02713)
**中文标题：UniMC：驯服扩散变换器以实现统一的关键点引导多类图像生成**

*Qin Guo,Ailing Zeng,Dongxu Yue,Ceyuan Yang,Yang Cao,Hanzhong Guo,Fei Shen,Wei Liu,Xihui Liu,Dan Xu*

主要分类: cs.CV

摘要简述: 本文提出UniMC框架和HAIG-2.9M数据集，解决了现有关键点引导模型在生成非刚性物体（如动物）和多类重叠对象时的局限性。UniMC通过整合实例和关键点条件到紧凑令牌中，实现了统一的多类图像生成，而HAIG-2.9M数据集提供了高质量标注支持。


<details>
  <summary>详细信息</summary>
研究动机: 现有关键点引导的文本到图像扩散模型在生成非刚性物体（如动物）和多类重叠对象时存在局限性，主要由于现有方法的固有缺陷和缺乏合适的数据集。

研究方法: 设计了基于DiT的UniMC框架，将实例和关键点条件整合为紧凑令牌，并提出了HAIG-2.9M数据集，包含786K图像和2.9M实例，标注了关键点、边界框和细粒度描述。

研究结果: 实验表明HAIG-2.9M数据集质量高，UniMC在严重遮挡和多类场景中表现优异。

研究结论: UniMC和HAIG-2.9M数据集有效解决了多类关键点引导图像生成的挑战，为未来研究提供了有力工具。

中文摘要: 尽管关键点引导的文本到图像扩散模型取得了显著进展，但现有主流模型在控制生成更一般的非刚性物体（如动物）时仍面临挑战。此外，仅依赖关键点控制难以生成多个重叠的人和动物。这些挑战源于两方面：现有可控方法的固有局限性和缺乏合适的数据集。首先，我们设计了一个基于DiT的框架UniMC，探索统一可控的多类图像生成。UniMC将实例和关键点条件整合为紧凑令牌，包含类别、边界框和关键点坐标等属性。这种方法克服了以往方法因依赖骨架图像作为条件而难以区分实例和类别的局限性。其次，我们提出了HAIG-2.9M，一个大规模、高质量且多样化的数据集，专为关键点引导的人和动物图像生成设计。HAIG-2.9M包含786K图像和2.9M实例，标注了关键点、边界框和细粒度描述，并通过严格人工检查确保标注准确性。大量实验证明了HAIG-2.9M的高质量和UniMC的有效性，尤其在严重遮挡和多类场景中。

</details>


### [92] [FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models](https://arxiv.org/abs/2507.02714)
**中文标题：FairHuman：基于最小潜在延迟公平性的扩散模型中提升人类图像手和脸质量的方法**

*Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma*

主要分类: cs.CV

摘要简述: FairHuman提出了一种多目标微调方法，通过最小潜在延迟公平性准则优化扩散模型，显著提升了生成图像中手和脸的细节质量，同时保持全局生成效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前大规模文本到图像模型在生成人类图像时，局部细节（如手和脸）的生成质量不足，主要由于训练中对局部区域的监督不够。FairHuman旨在通过多目标优化方法解决这一问题，提升局部细节的生成质量。

研究方法: FairHuman构建了三个学习目标：一个全局目标（基于默认扩散目标函数）和两个局部目标（针对手和脸，基于预标注的位置先验）。随后，采用最小潜在延迟（MPD）准则推导最优参数更新策略，实现多目标问题的公平优化。

研究结果: 实验表明，FairHuman在生成具有挑战性的局部细节（如手和脸）时表现显著优于基线方法，同时保持了整体图像质量。

研究结论: FairHuman通过多目标优化和MPD准则，有效提升了人类图像生成中局部细节的质量，为扩散模型的改进提供了新思路。

中文摘要: 随着大规模文本到图像模型的发展，尤其是基于扩散的模型，图像生成取得了显著进展。然而，由于训练中对局部区域的监督不足，生成具有合理细节（如脸或手）的人类图像仍然具有挑战性。为解决这一问题，我们提出了FairHuman，一种多目标微调方法，旨在公平地提升全局和局部生成质量。具体而言，我们首先构建了三个学习目标：一个基于默认扩散目标函数的全局目标和两个基于预标注位置先验的手和脸的局部目标。随后，在最小潜在延迟（MPD）准则的指导下，推导出最优参数更新策略，从而实现多目标问题的公平优化。基于此，我们提出的方法在生成具有挑战性的局部细节的同时，能够保持整体质量。大量实验证明了我们的方法在不同场景下提升人类图像生成性能的有效性。

</details>


### [93] [Prompt learning with bounding box constraints for medical image segmentation](https://arxiv.org/abs/2507.02743)
**中文标题：基于边界框约束的提示学习用于医学图像分割**

*Mélanie Gaillochet,Mehrdad Noori,Sahar Dastani,Christian Desrosiers,Hervé Lombaert*

主要分类: cs.CV

摘要简述: 本文提出了一种结合基础模型表示能力和弱监督分割标注效率的新框架，通过仅使用边界框标注自动生成提示，优化方案整合了边界框约束和伪标签，实验表明该方法在有限数据下优于全监督和弱监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割中像素级标注成本高昂，边界框标注更易获取但现有提示学习方法依赖全标注分割掩码，本文旨在结合基础模型和弱监督分割的优势，减少用户干预。

研究方法: 提出一种框架，利用边界框标注自动生成基础模型的提示，优化方案整合边界框约束和模型生成的伪标签，实现弱监督分割。

研究结果: 在多模态数据集上的实验显示，该方法在有限数据下平均Dice得分为84.90%，优于现有全监督和弱监督方法。

研究结论: 本文方法成功结合基础模型和弱监督分割的优势，通过自动生成提示和优化方案，显著提升了分割性能并减少了标注成本。

中文摘要: 在医学领域，像素级标注的获取既耗时又昂贵。为减轻这一负担，基于边界框标注的弱监督方法提供了一种实用替代方案，边界框标注更容易获取。最近，视觉基础模型在提供点或边界框等提示时表现出显著的分割性能。提示学习通过将这些模型适应下游任务并自动化分割，从而减少用户干预。然而，现有的提示学习方法依赖于完全标注的分割掩码。本文提出了一种新颖框架，将基础模型的表示能力与弱监督分割的标注效率相结合。具体而言，我们的方法仅使用边界框标注自动生成基础模型的提示。提出的优化方案整合了从边界框标注衍生的多重约束与基础模型生成的伪标签。在多模态数据集上的广泛实验表明，我们的弱监督方法在有限数据设置下平均Dice得分为84.90%，优于现有的全监督和弱监督方法。代码可在https://github.com/Minimel/box-prompt-learning-VFM.git获取。

</details>


### [94] [DexVLG: Dexterous Vision-Language-Grasp Model at Scale](https://arxiv.org/abs/2507.02747)
**中文标题：DexVLG：大规模灵巧视觉-语言-抓取模型**

*Jiawei He,Danshi Li,Xinqiang Yu,Zekun Qi,Wenyao Zhang,Jiayi Chen,Zhaoxiang Zhang,Zhizheng Zhang,Li Yi,He Wang*

主要分类: cs.CV

摘要简述: 本文提出DexVLG模型，通过大规模数据集DexGraspNet 3.0训练，实现了基于语言指令的单视角RGBD输入下的灵巧抓取姿态预测，并在仿真和真实场景中展示了优异的零样本泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉-语言-动作（VLA）系统主要针对简单夹爪末端执行器，缺乏对灵巧手的功能性抓取研究。本文旨在填补这一空白，通过大规模数据集和模型训练，实现语言指令对齐的灵巧抓取姿态预测。

研究方法: 生成包含1.7亿灵巧抓取姿态的大规模数据集DexGraspNet 3.0，覆盖17.4万个物体的语义部分，并训练基于视觉语言模型（VLM）和流匹配的姿态预测头，实现语言指令对齐的抓取姿态生成。

研究结果: 在物理仿真和真实实验中，DexVLG表现出强大的零样本泛化能力，仿真中零样本执行成功率达76%以上，并在真实场景中成功实现部分对齐抓取。

研究结论: DexVLG通过大规模数据集和模型训练，成功实现了语言指令对齐的灵巧抓取姿态预测，为灵巧手的功能性抓取提供了新思路。

中文摘要: 随着大模型的兴起，视觉-语言-动作（VLA）系统使机器人能够处理日益复杂的任务。然而，受限于数据收集的困难，现有研究主要集中在简单夹爪末端执行器的控制上，针对灵巧手的功能性抓取研究较少。本文提出DexVLG，一种基于单视角RGBD输入、语言指令对齐的灵巧抓取姿态预测大模型。为此，我们生成了一个包含1.7亿灵巧抓取姿态的数据集DexGraspNet 3.0，覆盖17.4万个物体的语义部分，并配以详细的部件级描述。该数据集用于训练一个视觉语言模型（VLM）和基于流匹配的姿态预测头，能够为桌面物体生成指令对齐的抓取姿态。为评估DexVLG性能，我们在物理仿真中创建基准测试并开展真实实验。大量测试表明，DexVLG具有强大的零样本泛化能力——在仿真中零样本执行成功率达76%以上，部件抓取准确率领先，并在真实场景中成功实现部件对齐抓取。

</details>


### [95] [Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics](https://arxiv.org/abs/2507.02748)
**中文标题：全局上下文线性注意力：一种面向视觉与物理的多极注意力机制**

*Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MANO的多极注意力机制，通过将注意力建模为网格点间的交互问题，实现了线性时间和内存复杂度，并在图像分类和物理模拟任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer在处理高分辨率输入时存在二次复杂度问题，导致计算和内存开销巨大。本文受n体数值模拟技术启发，旨在设计一种高效的注意力机制，以解决这一瓶颈。

研究方法: 作者提出多极注意力神经算子（MANO），将注意力建模为网格点间的多尺度交互问题，通过距离分层的多极计算实现线性复杂度，同时保持全局感受野。

研究结果: 实验表明，MANO在图像分类和Darcy流模拟任务中性能媲美ViT和Swin Transformer，同时显著降低了运行时和峰值内存占用。

研究结论: MANO通过多极注意力机制实现了高效且高性能的模型，为处理高分辨率输入提供了一种新思路。

中文摘要: Transformer已成为从图像分类到物理模拟等多种任务的实际标准。尽管其性能卓越，但标准Transformer在处理高分辨率输入时，由于时间和内存的二次复杂度，显得不切实际。为此，已有多种改进方案提出，其中最成功的依赖于分块、降采样或粗化技术，但往往以丢失最精细尺度细节为代价。本文采取了不同的方法。受n体数值模拟技术的启发，我们将注意力建模为网格点间的交互问题，并提出了多极注意力神经算子（MANO）。MANO以距离为基础的多尺度方式计算注意力，每个注意力头均保持全局感受野，同时实现与网格点数成线性关系的时间和内存复杂度。在图像分类和Darcy流模拟任务中的实验结果表明，MANO的性能可与ViT和Swin Transformer等先进模型媲美，同时将运行时间和峰值内存占用降低了数个数量级。我们开源了代码以促进可复现性：https://github.com/AlexColagrande/MANO。

</details>


### [96] [Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2507.02751)
**中文标题：部分弱监督的面向对象检测**

*Mingxin Liu,Peiyuan Zhang,Yuan Liu,Wei Zhang,Yue Zhou,Ning Liao,Ziyang Gong,Junwei Luo,Zhirui Wang,Yi Yu,Xue Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于部分弱标注（水平框或单点）的PWOOD框架，显著降低标注成本，同时性能优于传统弱监督算法。


<details>
  <summary>详细信息</summary>
研究动机: 面向对象检测（OOD）的标注成本高昂，现有方法在标注速度或成本上存在不足，亟需一种高效低成本的解决方案。

研究方法: 提出PWOOD框架，结合OS-Student模型学习方向和尺度信息，并采用CPF策略降低对静态过滤阈值的敏感性。

研究结果: 在DOTA和DIOR数据集上的实验表明，PWOOD性能与传统半监督算法相当甚至更优。

研究结论: PWOOD为低成本高效OOD提供了一种可行方案，显著优于弱监督算法。

中文摘要: 面向对象检测（OOD）在各领域的应用需求日益增长，但数据集标注的高成本仍是主要问题。当前主流OOD算法可分为三类：（1）使用完整定向边界框（OBB）标注的全监督方法，（2）使用部分OBB标注的半监督方法，（3）使用水平框或点等弱标注的弱监督方法。然而，这些方法在标注速度或成本上仍存在不足。为此，我们提出：（1）首个基于部分弱标注（水平框或单点）的PWOOD框架，能高效利用大量未标注数据，显著优于传统弱监督算法，同时成本更低；（2）OS-Student模型，仅需少量方向或尺度无关的弱标注即可学习方向和尺度信息；（3）CPF策略，降低模型对静态过滤阈值的敏感性。在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的实验表明，PWOOD性能与传统半监督算法相当甚至更优。

</details>


### [97] [From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images](https://arxiv.org/abs/2507.02781)
**中文标题：从像素到破坏程度：利用社交媒体图像的语义分割估计地震影响**

*Danrong Zhang,Huili Huang,N. Simrill Smith,Nimisha Roy,J. David Frost*

主要分类: cs.CV

摘要简述: 本研究提出了一种基于语义分割的新方法，用于从社交媒体图像中客观评估地震后的破坏程度，通过构建分段数据集和调整深度估计，量化破坏严重性，为灾害侦察提供更精确的指导。


<details>
  <summary>详细信息</summary>
研究动机: 传统的地震后社交媒体图像破坏程度评估方法依赖分类，主观性强且无法反映图像内不同区域的破坏差异。本研究旨在通过语义分割实现更客观、全面的破坏分析。

研究方法: 研究构建了一个包含三种破坏程度（未损坏、损坏、废墟）的分段数据集，并微调SegFormer模型进行语义分割。同时引入新的破坏评分系统，结合深度估计量化破坏严重性。

研究结果: 该方法能够更客观地量化社交媒体图像中的破坏程度，为灾害侦察团队提供更精确的指导，提升地震后救援的针对性和效率。

研究结论: 通过语义分割和破坏评分系统，本研究实现了对地震后社交媒体图像中破坏程度的更客观分析，为灾害响应提供了更有效的支持。

中文摘要: 地震后，社交媒体图像成为灾害侦察的重要资源，能够快速反映破坏范围。传统的破坏程度评估方法通常依赖分类，主观性强且无法区分图像内不同区域的破坏差异。为解决这一问题，本研究将破坏程度评估问题转化为语义分割任务，旨在更客观地分析地震影响区域的破坏情况。方法包括构建分段破坏程度数据集（分为未损坏结构、损坏结构和废墟三类），并微调SegFormer模型对社交媒体图像进行语义分割。此外，研究提出了一种新的破坏评分系统，通过结合深度估计量化图像中不同区域的破坏程度。该方法能够更客观、全面地量化社交媒体图像中的破坏严重性，从而为灾害侦察团队提供更精确的指导，提升地震后救援的针对性和效率。

</details>


### [98] [RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation](https://arxiv.org/abs/2507.02792)
**中文标题：RichControl：面向文本到图像生成的结构与外观丰富的免训练空间控制方法**

*Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的文本到图像生成方法RichControl，通过解耦特征注入步骤与去噪过程，解决了现有方法在结构对齐和视觉质量上的不足，实现了更精准的空间控制和更高质量的图像生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到图像扩散模型在结合条件图像（如深度图或姿态图）时，常因特征注入同步性问题导致结构错位、条件泄漏和视觉伪影。本文旨在解决这些问题，提升生成图像的结构保真度和视觉质量。

研究方法: 提出了一种灵活的特征注入框架，将注入时间步与去噪过程解耦，并设计了结构丰富的注入模块。此外，引入了外观丰富的提示和重启细化策略，以增强外观控制和视觉质量。

研究结果: 实验表明，该方法在多种零样本条件下均实现了最先进的性能，生成图像在结构和外观上均表现出色。

研究结论: RichControl通过解耦特征注入和去噪过程，显著提升了文本到图像生成的结构保真度和视觉质量，为无需训练的空间控制提供了高效解决方案。

中文摘要: 文本到图像（T2I）扩散模型在从文本提示生成高质量图像方面取得了显著成功。近期研究尝试将这些模型与条件图像（如深度图或姿态图）结合，以实现细粒度的空间控制。其中，特征注入方法作为一种免训练的替代方案，逐渐崭露头角。然而，这些方法常因结构错位、条件泄漏和视觉伪影而受限，尤其是当条件图像与自然RGB分布差异较大时。通过重新审视现有方法，我们发现其核心局限在于同步注入条件特征未能权衡去噪过程中的域对齐与结构保留。受此启发，我们提出了一种灵活的特征注入框架，将注入时间步与去噪过程解耦。其核心是一个结构丰富的注入模块，使模型能够更好地适应扩散步骤中对齐与结构保留的动态平衡，从而实现更忠实于结构的生成。此外，我们还引入了外观丰富的提示和重启细化策略，以进一步增强外观控制和视觉质量。这些设计共同实现了免训练的、结构与外观均丰富的生成。大量实验表明，我们的方法在多种零样本条件下均达到了最先进的性能。

</details>


### [99] [No time to train! Training-Free Reference-Based Instance Segmentation](https://arxiv.org/abs/2507.02798)
**中文标题：无需训练！基于参考图像的实例分割**

*Miguel Espinosa,Chenhongyi Yang,Linus Ericsson,Steven McDonagh,Elliot J. Crowley*

主要分类: cs.CV

摘要简述: 本文提出一种无需训练的参考图像实例分割方法，利用基础模型的语义先验自动生成实例级分割掩码，显著提升分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有分割模型依赖大量标注数据或复杂提示生成规则，本文旨在通过参考图像减少人工干预，实现高效分割。

研究方法: 采用多阶段无训练方法，包括内存库构建、表示聚合和语义感知特征匹配，自动生成实例级分割掩码。

研究结果: 在COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）和跨域FSOD基准（22.4% nAP）上表现优异，超越现有无训练方法。

研究结论: 通过利用语义先验和参考图像，本文方法在无需训练的情况下实现了高效实例分割，为下游任务提供了新思路。

中文摘要: 图像分割模型的性能长期以来受限于大规模标注数据的高成本。Segment Anything Model（SAM）通过可提示的、语义无关的分割范式缓解了这一问题，但仍需手动视觉提示或复杂的领域相关提示生成规则来处理新图像。为减轻这一负担，本文研究了在仅提供少量参考图像时的对象分割任务。我们的关键思路是利用基础模型学习的强语义先验，识别参考图像与目标图像之间的对应区域。研究发现，这些对应关系能够自动生成实例级分割掩码用于下游任务，并通过多阶段无训练方法实现，包括（1）内存库构建；（2）表示聚合；（3）语义感知特征匹配。实验表明，该方法在分割指标上显著提升，在COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）上达到领先水平，并在跨域FSOD基准（22.4% nAP）上优于现有无训练方法。

</details>


### [100] [HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars](https://arxiv.org/abs/2507.02803)
**中文标题：HyperGaussians：用于高保真可动画化人脸虚拟形象的高维高斯泼溅技术**

*Gent Serifi,Marcel C. Bühler*

主要分类: cs.CV

摘要简述: 本文提出了一种名为HyperGaussians的新方法，通过扩展3D高斯泼溅技术，用于生成高质量可动画化的人脸虚拟形象。该方法通过高维多变量高斯分布提升表达能力，并通过‘逆协方差技巧’解决计算效率问题，在多个数据集中表现优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D高斯泼溅技术在静态人脸渲染上表现优异，但在处理非线性变形、复杂光照和细节时仍有不足。本文旨在通过重新思考高斯表示本身，提出一种更富表现力的方法，以解决可动画化人脸虚拟形象的挑战。

研究方法: 本文提出HyperGaussians，将3D高斯扩展为高维多变量高斯，通过可学习的局部嵌入提升表达能力。为解决计算效率问题，引入‘逆协方差技巧’重新参数化协方差矩阵，从而高效实现高维高斯泼溅。

研究结果: 在4个数据集的19名受试者上评估表明，HyperGaussians在数值和视觉上均优于3D高斯泼溅技术，尤其在眼镜框、牙齿、复杂面部动作和高光反射等高频细节上表现突出。

研究结论: HyperGaussians通过高维高斯表示和逆协方差技巧，显著提升了可动画化人脸虚拟形象的渲染质量，为增强现实和虚拟现实应用提供了更优解决方案。

中文摘要: 我们提出了HyperGaussians，一种用于高质量可动画化人脸虚拟形象的3D高斯泼溅技术的新扩展。从视频中生成此类详细人脸虚拟形象是一个具有挑战性的问题，并在增强现实和虚拟现实中有广泛应用。尽管静态人脸已取得巨大成功，但从单目视频生成的可动画化虚拟形象仍处于‘恐怖谷’状态。3D高斯泼溅（3DGS）通过一组3D高斯基元表示人脸，在静态人脸渲染上表现出色，但在非线性变形、复杂光照和细节处理上仍有不足。大多数相关工作专注于从表情代码预测更好的高斯参数，而我们重新思考了3D高斯表示本身及其表达能力的提升。我们的见解将3D高斯扩展为高维多变量高斯，称为‘HyperGaussians’。更高的维度通过可学习的局部嵌入提升了表达能力。然而，泼溅HyperGaussians计算成本高，因为需要求逆高维协方差矩阵。我们通过重新参数化协方差矩阵（称为‘逆协方差技巧’）解决了这一问题，从而高效地将HyperGaussians集成到现有模型中。为验证其效果，我们将HyperGaussians应用于快速单目人脸虚拟形象的最新模型FlashAvatar。在4个数据集的19名受试者上的评估表明，HyperGaussians在数值和视觉上均优于3DGS，尤其在眼镜框、牙齿、复杂面部动作和高光反射等高频细节上表现突出。

</details>


### [101] [LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion](https://arxiv.org/abs/2507.02813)
**中文标题：LangScene-X：基于TriMap视频扩散的通用3D语言嵌入场景重建**

*Fangfu Liu,Hao Li,Jiawei Chi,Hanyang Wang,Minghui Yang,Fudong Wang,Yueqi Duan*

主要分类: cs.CV

摘要简述: LangScene-X是一种新型生成框架，通过TriMap视频扩散模型和语言量化压缩器（LQC），从稀疏视图中重建可泛化的3D语言嵌入场景，解决了传统方法在有限视图下的渲染和语义合成问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法依赖密集视图重建，导致在稀疏视图下出现渲染伪影和语义合成不准确的问题。LangScene-X旨在通过生成一致的多模态信息，实现从稀疏视图中重建和理解的统一。

研究方法: 1. 训练TriMap视频扩散模型，从稀疏输入中生成RGB、法线和语义分割图；2. 提出语言量化压缩器（LQC），在大规模图像数据集上训练，实现语言嵌入的高效编码；3. 通过将语言信息对齐到3D场景表面，重建语言表面场。

研究结果: 实验表明，LangScene-X在真实数据上优于现有方法，质量和泛化能力显著提升。

研究结论: LangScene-X通过生成一致的多模态信息和高效的语言嵌入编码，实现了从稀疏视图中重建可泛化的3D语言嵌入场景，为开放词汇查询提供了新可能。

中文摘要: 从2D图像中恢复具有开放词汇场景理解的3D结构是一项基础但艰巨的任务。最近的研究通过嵌入语言信息进行逐场景优化实现了这一目标，但它们严重依赖校准的密集视图重建范式，因此在视图有限时会出现严重的渲染伪影和语义合成不准确的问题。本文提出了一种新的生成框架LangScene-X，用于统一生成3D一致的多模态信息以支持重建和理解。借助生成一致新观察的能力，我们可以仅从稀疏视图中构建可泛化的3D语言嵌入场景。具体而言，我们首先训练了一个TriMap视频扩散模型，通过渐进式知识整合从稀疏输入中生成外观（RGB）、几何（法线）和语义（分割图）。此外，我们提出了一种在大规模图像数据集上训练的语言量化压缩器（LQC），用于高效编码语言嵌入，实现跨场景泛化而无需逐场景重新训练。最后，我们通过将语言信息对齐到3D场景表面，重建了语言表面场，支持开放词汇查询。在真实数据上的大量实验表明，LangScene-X在质量和泛化能力上均优于现有方法。项目页面：https://liuff19.github.io/LangScene-X。

</details>


### [102] [Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach](https://arxiv.org/abs/2507.02826)
**中文标题：基于置信度驱动梯度调制的多模态人类活动识别：一种动态对比双路径学习方法**

*Panpan Ji,Junni Song,Hang Xiao,Hanyu Liu,Chao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架，用于解决多模态人类活动识别中的跨模态特征对齐和模态贡献不平衡问题。该框架结合了双路径特征提取、多阶段对比学习和置信度驱动的梯度调制策略，显著提升了识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态人类活动识别系统面临跨模态特征对齐困难和模态贡献不平衡等挑战，亟需一种能够动态调整模态学习强度并提升特征对齐效果的方法。

研究方法: 1. 采用双路径特征提取架构（ResNet和DenseNet分支）处理多模态传感器数据；2. 引入多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；3. 提出置信度驱动的梯度调制策略，动态调整模态分支的学习强度；4. 采用基于动量的梯度累积策略增强训练稳定性。

研究结果: 通过消融实验验证了各模块的有效性，并在四个公共基准数据集上进行了广泛比较实验，结果表明DCDP-HAR显著优于现有方法。

研究结论: DCDP-HAR框架通过动态对比学习和梯度调制策略，有效解决了多模态人类活动识别中的关键问题，为智能系统的环境感知提供了可靠技术支持。

中文摘要: 基于传感器的人类活动识别（HAR）是智能系统感知和与环境交互的核心技术。然而，多模态HAR系统仍面临跨模态特征对齐困难和模态贡献不平衡等关键挑战。为解决这些问题，我们提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架。该框架包含三个关键组件：首先，采用双路径特征提取架构，其中ResNet和DenseNet分支协同处理多模态传感器数据；其次，引入多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；第三，提出置信度驱动的梯度调制策略，动态监控并调整反向传播过程中各模态分支的学习强度，有效缓解模态竞争。此外，采用基于动量的梯度累积策略以增强训练稳定性。我们通过消融实验验证了各模块的有效性，并在四个公共基准数据集上进行了广泛比较实验。

</details>


### [103] [USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network](https://arxiv.org/abs/2507.02827)
**中文标题：USAD：一种无监督数据增强的时空注意力扩散网络**

*Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为USAD的无监督数据增强时空注意力扩散网络，用于解决人类活动识别中的标签数据稀缺、特征提取不足及轻量设备性能不佳等问题。通过无监督数据增强、多分支时空交互网络和自适应多损失函数融合策略，USAD在多个公开数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 人类活动识别（HAR）面临标签数据稀缺、高级特征提取不足及轻量设备性能不佳等挑战。本文旨在通过无监督数据增强和多注意力机制优化，提升HAR的准确性和实用性。

研究方法: 1. 采用无监督统计引导的扩散模型进行数据增强；2. 设计多分支时空交互网络，通过并行残差分支捕捉多尺度特征；3. 引入时空注意力机制识别关键时间点和传感器交互；4. 使用自适应多损失函数融合策略动态优化模型。

研究结果: 在WISDM、PAMAP2和OPPORTUNITY数据集上，USAD的准确率分别达到98.84%、93.81%和80.92%，显著优于现有方法，并在嵌入式设备上验证了其高效性和可行性。

研究结论: USAD通过无监督数据增强和时空注意力机制，有效解决了HAR中的关键问题，显著提升了识别性能，适用于轻量设备部署。

中文摘要: 人类活动识别（HAR）的主要目标是从传感器数据中推断正在进行的人类行为，这一任务在健康监测、安全防护和运动分析中有广泛应用。尽管研究众多，HAR仍面临标签样本稀缺、高级特征提取不足及轻量设备性能不佳等关键挑战。为解决这些问题，本文提出了一种以多注意力交互机制为核心的全面优化方法。首先，采用无监督统计引导的扩散模型进行数据增强，缓解标签数据稀缺和类别不平衡问题；其次，设计多分支时空交互网络，通过并行残差分支（3*3、5*5和7*7卷积核）捕捉序列数据的多尺度特征，同时引入时间注意力机制识别关键时间点，空间注意力增强传感器间交互；进一步引入跨分支特征融合单元以提升整体特征表示能力；最后，集成自适应多损失函数融合策略，动态调整损失权重并优化模型整体性能。在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上的实验结果表明，所提出的无监督数据增强时空注意力扩散网络（USAD）分别达到了98.84%、93.81%和80.92%的准确率，显著优于现有方法。此外，在嵌入式设备上的实际部署验证了该方法的效率和可行性。

</details>


### [104] [AnyI2V: Animating Any Conditional Image with Motion Control](https://arxiv.org/abs/2507.02857)
**中文标题：AnyI2V：通过运动控制为任意条件图像生成动画**

*Ziye Li,Hao Luo,Xincheng Shuai,Henghui Ding*

主要分类: cs.CV

摘要简述: AnyI2V是一种无需训练的框架，能够通过用户定义的运动轨迹为任意条件图像生成动画，支持多种模态输入，并实现灵活的视频生成和编辑。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到视频（T2V）和图像到视频（I2V）合成方法存在局限性：T2V依赖文本提示，缺乏对生成内容空间布局的精确控制；I2V依赖真实图像，限制了内容的可编辑性。此外，现有方法缺乏显式运动控制且计算成本高。

研究方法: AnyI2V提出了一种无需训练的框架，通过用户定义的运动轨迹为任意条件图像生成动画。它支持多种模态输入（如网格和点云），并允许通过LoRA和文本提示进行风格迁移和编辑。

研究结果: 实验表明，AnyI2V在空间和运动控制的视频生成中表现优异，提供了更灵活和多样化的视频生成能力。

研究结论: AnyI2V为空间和运动控制的视频生成提供了新视角，支持多种输入模态和编辑功能，具有广泛的应用潜力。

中文摘要: 近年来，视频生成领域（尤其是扩散模型）在文本到视频（T2V）和图像到视频（I2V）合成方面取得了显著进展。然而，如何有效整合动态运动信号和灵活的空间约束仍存在挑战。现有的T2V方法通常依赖文本提示，这本质上缺乏对生成内容空间布局的精确控制。相比之下，I2V方法受限于对真实图像的依赖，限制了合成内容的可编辑性。尽管一些方法通过ControlNet引入了基于图像的条件，但它们通常缺乏显式运动控制，且需要计算成本高昂的训练。为解决这些问题，我们提出了AnyI2V，一种无需训练的框架，能够通过用户定义的运动轨迹为任意条件图像生成动画。AnyI2V支持更广泛的模态作为条件图像，包括ControlNet不支持的数据类型（如网格和点云），从而实现更灵活和多样化的视频生成。此外，它还支持混合条件输入，并通过LoRA和文本提示实现风格迁移和编辑。大量实验表明，AnyI2V表现出卓越的性能，为空间和运动控制的视频生成提供了新视角。代码可在https://henghuiding.com/AnyI2V/获取。

</details>


### [105] [Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation](https://arxiv.org/abs/2507.02859)
**中文标题：在多模态大语言模型中自举接地链式思维以实现数据高效模型适配**

*Jiaer Xia,Bingkui Tong,Yuhang Zang,Rui Shao,Kaiyang Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Grounded Chain-of-Thought (GCoT)的方法，通过注入边界框信息改进多模态大语言模型在数据有限情况下的适应能力，显著提升了在图表等专业视觉任务上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在通用图像理解任务中表现优异，但在专业视觉任务（如图表理解）中，由于预训练数据与下游任务不匹配，模型难以适应。本文发现，通过链式思维（CoT）数据训练可以改善这一问题，但现有CoT数据中存在大量事实错误，因此提出改进方法。

研究方法: 提出Grounded Chain-of-Thought (GCoT)，通过将边界框等接地信息注入CoT数据中，使推理步骤更忠实于输入图像。采用自举方法生成高质量数据，用于模型微调。

研究结果: 在五种专业视觉任务（包括图表、表格、收据和报告）上验证了GCoT的有效性。结果表明，在数据有限的情况下，GCoT显著优于传统微调和蒸馏方法。

研究结论: GCoT通过改进推理数据的忠实性，显著提升了多模态大语言模型在专业视觉任务中的适应能力，为数据高效模型适配提供了新思路。

中文摘要: 多模态大语言模型（MLLMs）在利用自然语言解释图像方面表现出卓越能力。然而，若不使用大规模数据集进行重新训练，这些模型难以适应专业视觉任务（如图表理解）。这一问题源于预训练数据与下游任务的不匹配：预训练数据主要集中于场景和物体，而关于专业非物体图像（如图表和表格）的信息有限。本文分享了一个有趣的发现，即用链式思维（CoT）推理数据训练MLLM可以促进模型在专业视觉任务中的适应，尤其是在数据有限的情况下。然而，我们发现从预训练MLLM中提取的CoT数据存在一个关键问题，即推理步骤中常包含多个事实错误。为解决这一问题，我们提出了接地链式思维（GCoT），这是一种基于自举的简单方法，旨在将接地信息（如边界框）注入CoT数据中，从而使推理步骤更忠实于输入图像。我们在五种专业视觉任务上评估了该方法，这些任务涵盖了图表、表格、收据和报告等多种视觉格式。结果表明，在数据有限的情况下，我们的方法显著优于微调和蒸馏。

</details>


### [106] [Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching](https://arxiv.org/abs/2507.02860)
**中文标题：少即是多：通过运行时自适应缓存实现无需训练的视频扩散加速**

*Xin Zhou,Dingkang Liang,Kaijin Chen,Tianrui Feng,Xiwu Chen,Hongkai Lin,Yikang Ding,Feiyang Tan,Hengshuang Zhao,Xiang Bai*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的加速框架EasyCache，通过运行时自适应缓存机制显著提升视频扩散模型的推理速度，同时保持高质量生成效果。


<details>
  <summary>详细信息</summary>
研究动机: 视频生成模型因去噪过程的迭代性导致推理速度慢和计算成本高，限制了其广泛应用。本文旨在解决这一瓶颈，推动高质量视频合成技术的普及。

研究方法: EasyCache采用轻量级的运行时自适应缓存机制，动态复用先前计算的变换向量，避免推理中的冗余计算，无需离线分析或参数调优。

研究结果: 在多个大规模视频生成模型（如OpenSora、Wan2.1和HunyuanVideo）上，EasyCache实现了2.1-3.3倍的推理加速，PSNR提升高达36%，优于现有方法。

研究结论: EasyCache是一种高效且易于实现的解决方案，显著提升了视频生成的速度和质量，适用于研究和实际应用。

中文摘要: 视频生成模型表现出色，但其广泛应用受限于缓慢的推理速度和巨大的计算成本，主要源于去噪过程的迭代性。解决这一瓶颈对普及高级视频合成技术至关重要。本文提出EasyCache，一种无需训练的视频扩散模型加速框架。EasyCache引入轻量级的运行时自适应缓存机制，动态复用先前计算的变换向量，避免推理中的冗余计算。与现有方法不同，EasyCache无需离线分析、预计算或大量参数调优。我们在多个大规模视频生成模型（如OpenSora、Wan2.1和HunyuanVideo）上进行了全面研究。EasyCache实现了领先的加速性能，推理时间减少2.1-3.3倍，同时保持高视觉保真度，PSNR较现有最优方法提升高达36%。这一改进使EasyCache成为研究和实际应用中高质量视频生成的高效且易用解决方案。代码发布于https://github.com/H-EmbodVis/EasyCache。

</details>


### [107] [LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans](https://arxiv.org/abs/2507.02861)
**中文标题：LiteReality：基于RGB-D扫描的图形就绪3D场景重建**

*Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby*

主要分类: cs.CV

摘要简述: LiteReality提出了一种新方法，将RGB-D扫描的室内环境转换为紧凑、逼真且可交互的3D虚拟副本，支持高质量渲染和物理交互，适用于AR/VR、游戏和机器人等领域。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D场景重建方法在逼真度和交互性上存在不足，难以满足图形流水线的需求。LiteReality旨在填补这一空白，提供一种既能视觉还原现实场景，又能支持高质量渲染和物理交互的解决方案。

研究方法: LiteReality首先通过场景理解将RGB-D扫描解析为3D布局和对象，并利用结构化场景图组织数据。接着从资产库中检索视觉相似的3D模型，通过材料绘画模块恢复高质量材料，最后将场景集成到仿真引擎中以支持物理交互。

研究结果: LiteReality在Scan2CAD基准测试中实现了最先进的相似性性能，其材料绘画模块能够处理严重不对齐、遮挡和光照不足的情况。实验证明其在真实扫描和公共数据集上均表现优异。

研究结论: LiteReality提供了一种高效、逼真且可交互的3D场景重建方法，适用于多种应用场景，如AR/VR、游戏和数字孪生，同时展示了其在对象检索和材料恢复上的创新性。

中文摘要: 我们提出了LiteReality，一种新颖的流程，可将室内环境的RGB-D扫描转换为紧凑、逼真且可交互的3D虚拟副本。LiteReality不仅重建视觉上接近现实的场景，还支持图形流水线所需的关键功能，如对象独立性、关节运动、高质量基于物理的渲染材料以及基于物理的交互。其核心在于，LiteReality首先进行场景理解，并通过结构化场景图将结果解析为连贯的3D布局和对象。随后，通过从精选资产库中检索视觉最相似的3D艺术家制作模型来重建场景。接着，材料绘画模块通过恢复高质量的空间变化材料来增强真实感。最后，重建的场景被集成到具有基本物理属性的仿真引擎中，以实现交互行为。生成的场景紧凑、可编辑，且完全兼容标准图形流水线，适用于AR/VR、游戏、机器人和数字孪生等应用。此外，LiteReality引入了一种无需训练的对象检索模块，在Scan2CAD基准测试中实现了最先进的相似性性能，以及一个鲁棒的材料绘画模块，能够将任何风格的图像外观转移到3D资产上——即使在严重不对齐、遮挡和光照不足的情况下。我们在真实扫描和公共数据集上验证了LiteReality的有效性。项目页面：https://litereality.github.io；视频：https://www.youtube.com/watch?v=ecK9m3LXg2c

</details>


### [108] [RefTok: Reference-Based Tokenization for Video Generation](https://arxiv.org/abs/2507.02862)
**中文标题：RefTok：基于参考的视频生成标记化方法**

*Xiang Fan,Xiaohang Sun,Kushan Thakkar,Zhu Liu,Vimal Bhat,Ranjay Krishna,Xiang Hao*

主要分类: cs.CV

摘要简述: RefTok是一种基于参考的标记化方法，用于视频生成，能有效捕捉时间动态和上下文信息，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频模型通常独立处理帧集，无法有效捕捉视频中的时间依赖性和冗余性，RefTok旨在解决这一问题。

研究方法: RefTok通过基于未量化参考帧的编码和解码方法，保留帧间运动的连续性和对象的外观细节。

研究结果: 在四个视频数据集上，RefTok显著优于当前最先进的标记化方法（如Cosmos和MAGVIT），平均提升36.7%的评估指标。

研究结论: RefTok不仅性能优越，还能在视频生成任务中超越更大规模的模型，展示了其高效性和潜力。

中文摘要: 有效处理时间冗余是学习视频模型的关键挑战。现有方法通常独立处理帧集，无法有效捕捉视频中的时间依赖性和冗余性。为解决这一问题，我们提出了RefTok，一种新颖的基于参考的标记化方法，能够捕捉复杂的时间动态和上下文信息。我们的方法基于未量化的参考帧对帧集进行编码和解码。解码时，RefTok保留了帧间运动的连续性和对象的外观。例如，RefTok在头部运动时保留面部细节，正确重建文本，保留小图案，并保持手写内容的可读性。在四个视频数据集（K600、UCF-101、BAIR Robot Pushing和DAVIS）上，RefTok显著优于当前最先进的标记化方法（Cosmos和MAGVIT），在相同或更高压缩比下，所有评估指标（PSNR、SSIM、LPIPS）平均提升了36.7%。当使用RefTok的潜在表示训练视频生成模型时，在BAIR Robot Pushing任务中，生成的视频不仅优于MAGVIT-B，还超越了参数多4倍的MAGVIT-L，在所有生成指标上平均提升了27.9%。

</details>


### [109] [Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory](https://arxiv.org/abs/2507.02863)
**中文标题：Point3R：基于显式空间指针记忆的流式3D重建**

*Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu*

主要分类: cs.CV

摘要简述: Point3R提出了一种在线流式3D重建框架，通过显式空间指针记忆直接关联场景的3D结构，解决了隐式记忆容量有限和信息丢失的问题，实现了高效且均匀的信息融合。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D重建方法依赖隐式记忆，存在容量限制和早期帧信息丢失的问题。Point3R旨在通过显式空间指针记忆，直接关联3D场景结构，提升信息整合效率和重建质量。

研究方法: Point3R维护了一个显式空间指针记忆，每个指针关联特定3D位置并聚合周围场景信息。通过3D分层位置嵌入和高效融合机制，实现最新帧信息与全局坐标系的密集整合。

研究结果: Point3R在多项任务中表现优异，训练成本低，性能达到或超越现有最优方法。

研究结论: Point3R通过显式空间指针记忆和高效融合机制，显著提升了流式3D重建的性能和效率，为实际应用提供了有力支持。

中文摘要: 从有序序列或无序图像集合中实现密集3D场景重建是将计算机视觉研究应用于实际场景的关键步骤。继DUSt3R将图像对密集统一到共享坐标系后，后续方法通过隐式记忆实现多图像的密集3D重建。然而，这种隐式记忆容量有限，可能导致早期帧信息丢失。我们提出了Point3R，一种面向密集流式3D重建的在线框架。具体而言，我们维护了一个直接关联当前场景3D结构的显式空间指针记忆。该记忆中的每个指针被分配一个特定的3D位置，并将全局坐标系中附近的场景信息聚合为动态空间特征。从最新帧提取的信息与指针记忆显式交互，实现当前观测到全局坐标系的密集整合。我们设计了3D分层位置嵌入以促进这种交互，并设计了一种简单高效的融合机制，确保指针记忆均匀且高效。我们的方法在多项任务中表现出色，训练成本低。代码发布于：https://github.com/YkiWu/Point3R。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [110] [STELLA: Self-Evolving LLM Agent for Biomedical Research](https://arxiv.org/abs/2507.02004)
**中文标题：STELLA：用于生物医学研究的自进化大语言模型代理**

*Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong*

主要分类: cs.AI

摘要简述: STELLA是一种自进化AI代理，通过动态模板库和工具海洋机制自主提升能力，在生物医学研究中表现优异，且性能随经验增长持续提升。


<details>
  <summary>详细信息</summary>
研究动机: 生物医学数据和工具的快速增长导致研究领域碎片化，传统AI代理依赖静态工具集，无法适应动态需求。STELLA旨在解决这一问题，通过自进化机制提升适应性和扩展性。

研究方法: STELLA采用多代理架构，包含动态模板库（用于推理策略）和工具海洋（通过工具创建代理自动发现和集成新工具），实现自主学习和能力提升。

研究结果: STELLA在多项生物医学基准测试中表现优异，得分显著高于现有模型，且性能随经验增长持续提升，例如在Humanity's Last Exam测试中准确率几乎翻倍。

研究结论: STELLA代表了AI代理系统的重大进步，能够动态扩展专业知识，加速生物医学发现。

中文摘要: 生物医学数据、工具和文献的快速增长导致研究领域碎片化，超出了人类专家的能力范围。虽然AI代理提供了解决方案，但它们通常依赖静态、手动整理的工具集，限制了其适应性和扩展性。为此，我们引入了STELLA，一种自进化AI代理，旨在克服这些限制。STELLA采用多代理架构，通过两个核心机制自主提升能力：动态演进的模板库（用于推理策略）和工具海洋（通过工具创建代理自动发现和集成新的生物信息学工具）。这使得STELLA能够从经验中学习。实验表明，STELLA在一系列生物医学基准测试中达到了最先进的准确率，得分显著优于领先模型，且性能随经验增长持续提升。例如，在Humanity's Last Exam测试中，其准确率几乎翻倍。STELLA代表了AI代理系统的重大进步，能够动态扩展专业知识，加速生物医学发现。

</details>


### [111] [HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection](https://arxiv.org/abs/2507.02073)
**中文标题：HCVR：一种基于相关性投票规则的混合特征选择方法**

*Nikita Bhedasgaonkar,Rushikesh K. Joshi*

主要分类: cs.AI

摘要简述: 本文提出HCVR方法，一种基于相关性的轻量级特征选择方法，结合参数间（P2P）和参数与目标（P2T）相关性，通过投票规则去除冗余特征并保留相关特征。


<details>
  <summary>详细信息</summary>
研究动机: 传统特征选择方法在冗余特征去除和相关性保留方面存在不足，HCVR旨在通过混合非迭代和迭代过滤方法提升特征选择效果。

研究方法: HCVR采用贪心算法，通过后向消除逐步去除冗余特征，利用P2P和P2T相关性阈值进行投票决策。

研究结果: 在SPAMBASE数据集上，HCVR优于传统非迭代（CFS、mRMR、MI）和迭代（RFE、SFS、遗传算法）方法，分类器性能显著提升。

研究结论: HCVR通过混合方法和相关性投票规则有效提升了特征选择性能，适用于轻量级应用场景。

中文摘要: 本文提出HCVR（基于相关性投票规则的混合方法），一种轻量级的基于规则的特征选择方法，结合参数间（P2P）和参数与目标（P2T）相关性，去除冗余特征并保留相关特征。该方法是非迭代和迭代过滤方法的混合，用于降维。它是一种贪心方法，通过后向消除逐步去除多个特征。规则通过投票决定特征的保留或丢弃，利用特征间及特征与目标的相关性阈值。在SPAMBASE数据集上的实验结果表明，HCVR优于传统非迭代（CFS、mRMR、MI）和迭代（RFE、SFS、遗传算法）方法。通过分类器性能评估了其有效性。

</details>


### [112] [Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs](https://arxiv.org/abs/2507.02076)
**中文标题：预算内推理：大型语言模型中自适应与可控测试时计算综述**

*Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates*

主要分类: cs.AI

摘要简述: 本文综述了大型语言模型（LLMs）在推理过程中计算效率的提升策略，重点探讨了固定计算预算（L1可控性）和动态调整计算（L2适应性）两种方法，并分析了性能与计算资源之间的权衡。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理时采用固定的计算资源，导致简单问题过度计算而复杂问题计算不足，亟需提升计算效率。

研究方法: 提出两级分类法：L1可控性（固定计算预算）和L2适应性（动态调整计算），并在多数据集上对主流LLMs进行基准测试。

研究结果: 研究发现，动态调整计算资源能显著提升推理效率，但需权衡性能与计算成本。

研究结论: 未来研究方向包括混合思维模型和提升LLMs的计算效率、鲁棒性及用户响应能力。

中文摘要: 大型语言模型（LLMs）已迅速发展为能够解决广泛任务的通用智能体。然而，当前模型在推理时仍效率低下：无论任务复杂度如何，它们均采用固定的推理计算资源，常对简单问题过度思考而对复杂问题思考不足。本综述全面回顾了高效的测试时计算（TTC）策略，旨在提升LLM推理的计算效率。我们提出了一种两级分类法，区分了L1可控性（在固定计算预算下运行的方法）和L2适应性（根据输入难度或模型置信度动态调整推理的方法）。我们在多样化数据集上对主流专有LLMs进行了基准测试，突出了推理性能与计算资源之间的关键权衡。与以往关于高效推理的综述相比，本文更强调TTC方法的实际可控性、适应性和可扩展性。最后，我们讨论了混合思维模型等新兴趋势，并指出了未来研究的关键挑战，以使LLMs在计算效率、鲁棒性和用户响应能力方面更进一步。

</details>


### [113] [Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab](https://arxiv.org/abs/2507.02083)
**中文标题：通过系统生物学干实验室测量语言模型的科学能力**

*Haonan Duan,Stephen Zhewen Lu,Caitlin Fiona Harrigan,Nishkrit Desai,Jiarui Lu,Michał Koziarski,Leonardo Cotta,Chris J. Maddison*

主要分类: cs.AI

摘要简述: 本文介绍了一种名为SciGym的基准测试，用于评估大型语言模型（LLM）在开放科学发现任务中的实验设计和分析能力。通过使用系统生物学干实验室模拟数据，SciGym克服了湿实验室的高成本问题。实验结果显示，尽管性能更强的模型表现更优，但随着系统复杂性增加，所有模型的性能显著下降，表明LLM在科学能力方面仍有很大提升空间。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估大型语言模型科学能力的方法未能测试其核心科学能力（如实验设计和结果解释），因为湿实验室实验在专业知识、时间和设备方面成本过高。本文旨在通过开发SciGym基准测试，填补这一空白。

研究方法: SciGym采用系统生物学干实验室方法，使用系统生物学标记语言（SBML）编码的生物系统模型生成模拟数据。该方法高效且适用于复杂系统的实验测试。研究评估了六种前沿LLM在137个小系统和总计350个系统上的表现。

研究结果: 实验结果表明，性能更强的模型在任务中表现更优，但随着系统复杂性增加，所有模型的性能显著下降。这表明LLM在科学能力方面仍需改进。

研究结论: SciGym为评估LLM的科学能力提供了有效工具，揭示了当前模型的局限性，并指出了未来改进的方向。

中文摘要: 实验设计和结果解释是科学研究的核心能力，尤其是在生物学中，研究人员通过扰动复杂系统以揭示其内在机制。目前评估大型语言模型（LLM）科学能力的方法未能测试这些能力，因为湿实验室实验在专业知识、时间和设备方面成本过高。我们提出了SciGym，这是一种首创的基准测试，用于评估LLM在开放科学发现任务中的迭代实验设计和分析能力。SciGym通过运行系统生物学干实验室克服了湿实验室的高成本问题。这些使用系统生物学标记语言（SBML）编码的模型能够高效生成模拟数据，是测试复杂系统实验的理想平台。我们评估了六种前沿LLM在137个小系统上的表现，并发布了总计350个系统。结果显示，尽管性能更强的模型表现更优，但随着系统复杂性增加，所有模型的性能显著下降，表明LLM在科学能力方面仍有很大提升空间。

</details>


### [114] [What Neuroscience Can Teach AI About Learning in Continuously Changing Environments](https://arxiv.org/abs/2507.02103)
**中文标题：神经科学能为AI在持续变化环境中的学习提供什么启示**

*Daniel Durstewitz,Bruno Averbeck,Georgia Koppe*

主要分类: cs.AI

摘要简述: 本文探讨了如何从神经科学中汲取灵感，帮助AI在持续变化的环境中学习，并提出了双向学习的框架。


<details>
  <summary>详细信息</summary>
研究动机: 现代AI模型（如大型语言模型）通常通过一次性训练和固定参数部署，而动物却能持续适应环境变化。本文旨在探索神经科学如何为AI的持续学习提供启示。

研究方法: 整合了AI中的持续学习和上下文学习文献，以及神经科学中关于行为任务中规则、奖励概率或结果变化的学习研究。

研究结果: 提出了一个双向学习议程，即神经科学如何启发AI的持续学习，以及AI如何反过来促进神经科学的发展。

研究结论: 神经科学与AI的交叉研究（NeuroAI）具有巨大潜力，可为AI在现实世界中的应用提供新思路。

中文摘要: 现代AI模型（如大型语言模型）通常通过一次性训练和固定参数部署，其训练成本高、速度慢且需要大量重复。相比之下，动物能够持续适应不断变化的环境，尤其是社会性物种，其行为策略和奖励结果在与同伴互动中频繁变化。这种适应能力通常表现为行为的快速转变和神经元群体活动的突然变化。这种计算能力对现实世界中的AI系统（如机器人或自动驾驶汽车）越来越重要。本文探讨了AI是否能从神经科学中学习，整合了AI中的持续学习和上下文学习文献，以及神经科学中关于行为任务中规则、奖励概率或结果变化的学习研究。我们提出了一个双向学习议程，即神经科学如何启发AI的持续学习，以及AI如何反过来促进神经科学的发展，推动NeuroAI这一新兴领域的进步。

</details>


### [115] [The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies](https://arxiv.org/abs/2507.02152)
**中文标题：公平的幻觉：用审计研究评估公平干预措施**

*Disa Sariola,Patrick Button,Aron Culotta,Nicholas Mattei*

主要分类: cs.AI

摘要简述: 本文探讨了如何利用审计研究数据改进自动招聘算法的公平性评估和训练，发现常见的公平干预方法在传统指标下看似有效，但实际存在约10%的差异。


<details>
  <summary>详细信息</summary>
研究动机: 人工智能系统在招聘和贷款等领域的应用日益广泛，但其公平性和有效性评估复杂且重要。传统方法通过调整训练数据来减少偏见，但通常依赖便利样本，存在选择偏差和标签偏差。审计研究提供了高质量数据，可用于更严格的歧视评估。

研究方法: 利用审计研究中的虚构测试数据（如简历、电子邮件）进行随机对照试验，评估和训练自动招聘算法。比较了常见的公平干预方法（如均衡基率）与基于个体治疗效果估计的新干预方法。

研究结果: 研究发现，传统公平干预方法在传统指标下看似公平，但实际仍存在约10%的差异。基于个体治疗效果估计的新方法能进一步减少算法歧视。

研究结论: 审计研究数据能更准确地揭示算法公平性问题，并为改进公平干预方法提供依据。基于个体治疗效果的方法在减少歧视方面更具潜力。

中文摘要: 人工智能系统（尤其是基于机器学习的系统）正被广泛应用于招聘和贷款发放等领域，以自动化这些复杂决策。评估这些AI系统及其人类决策对应物的有效性和公平性，是计算科学和社会科学共同研究的复杂且重要的课题。在机器学习中，解决下游分类器偏见的常见方法是对训练数据进行重采样以抵消差异。例如，如果招聘率因某些受保护类别而异，则可以通过均衡训练集中的比率来减轻分类器的偏见。这些方法看似简单有效，但通常仅通过便利样本数据进行评估，导致指标中存在选择偏差和标签偏差。在社会科学、心理学、公共卫生和医学中，审计研究通过随机对照试验，将虚构的“测试者”（如简历、电子邮件、患者演员）发送给受试者（如职位空缺、企业、医生），提供了支持严格歧视评估的高质量数据。本文研究了如何利用审计研究数据改进自动招聘算法的训练和评估能力。研究发现，这类数据揭示了常见公平干预方法（如均衡基率）在传统指标下看似实现公平，但实际仍存在约10%的差异。此外，本文还引入了基于个体治疗效果估计的干预方法，进一步利用此类数据减少算法歧视。

</details>


### [116] [Data Diversification Methods In Alignment Enhance Math Performance In LLMs](https://arxiv.org/abs/2507.02173)
**中文标题：数据多样化方法在偏好对齐中提升大型语言模型的数学性能**

*Berkan Dokmeci,Qingyang Wu,Ben Athiwaratkun,Ce Zhang,Shuaiwen Leon Song,James Zou*

主要分类: cs.AI

摘要简述: 通过数据多样化策略提升大型语言模型（LLMs）的数学推理能力，提出Diversified-Think-Solve（DTS）方法，显著提升性能且计算开销低。


<details>
  <summary>详细信息</summary>
研究动机: 尽管偏好学习在人类反馈对齐方面取得进展，但数学推理仍是挑战。研究旨在探索如何通过数据多样化策略优化偏好数据，以提升LLMs的数学推理能力。

研究方法: 评估了三种数据生成方法：温度采样、思维链提示和蒙特卡洛树搜索（MCTS），并提出了DTS方法，系统地将问题分解为多样化推理路径。

研究结果: 结果表明，多样化偏好数据显著提升模型性能，DTS在GSM8K和MATH数据集上分别提升7.1%和4.2%，且计算开销仅增加1.03倍，而MCTS成本高但收益低。

研究结论: 结构化探索多样化问题解决方法比传统方法更有效，DTS为数学对齐提供了高效且低成本的解决方案。

中文摘要: 尽管偏好学习的最新进展增强了人类反馈的对齐能力，但数学推理仍是一个持续的挑战。我们研究了偏好优化中的数据多样化策略如何提升大型语言模型（LLMs）的数学推理能力。我们评估了三种常见的数据生成方法：温度采样、思维链提示和蒙特卡洛树搜索（MCTS），并提出了Diversified-Think-Solve（DTS），这是一种新颖的结构化方法，系统地将问题分解为多样化推理路径。结果表明，通过策略性多样化的偏好数据，模型可以显著提升数学推理性能，最佳方法在GSM8K和MATH数据集上分别实现了7.1%和4.2%的提升。尽管性能强劲，DTS的计算开销仅比基线增加1.03倍，而MCTS的成本几乎是其五倍但收益更低。这些发现表明，结构化探索多样化问题解决方法比传统方法更能为数学对齐生成有效的偏好数据。

</details>


### [117] [Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust](https://arxiv.org/abs/2507.02197)
**中文标题：基于LLM的角色扮演代理是否言行一致？人类信任模拟中的信念-行为一致性**

*Amogh Mannekote,Adam Davies,Guohao Li,Kristy Elizabeth Boyer,ChengXiang Zhai,Bonnie J Dorr,Francesco Pinto*

主要分类: cs.AI

摘要简述: 本文研究了基于LLM的角色扮演代理在模拟人类信任行为时，其声称的信念与实际行为之间的一致性，发现存在系统性不一致，并提出了评估框架和影响因素分析。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM越来越多地用于生成人类行为研究的合成数据，确保其输出与角色设定一致成为关键问题。本文旨在探究LLM角色扮演代理的信念与行为是否一致。

研究方法: 通过建立评估框架，使用增强版的GenAgents角色库和信任游戏，引入信念-行为一致性指标，分析信念类型、信息呈现时机和未来预测时间等因素的影响。

研究结果: 研究发现，LLM的信念与模拟行为之间存在系统性不一致，即使模型编码了合理的信念，也可能无法一致地应用。

研究结论: 研究强调了识别LLM信念与模拟行为一致性的重要性，为行为研究中正确使用LLM代理提供了依据。

中文摘要: 随着LLM越来越多地被研究作为角色扮演代理以生成人类行为研究的合成数据，确保其输出与角色设定一致成为关键问题。本文研究了基于LLM的角色扮演代理的信念（“他们所说的”）与其在角色扮演中的实际行为（“他们所做的”）之间的一致性。具体而言，我们建立了一个评估框架，严格衡量通过提示模型获得的信念能否提前预测模拟结果。通过使用增强版的GenAgents角色库和信任游戏（一种用于量化玩家信任和互惠的标准经济游戏），我们引入了一个信念-行为一致性指标，系统研究其如何受以下因素影响：（1）从LLM中获取的信念类型，如模拟的预期结果与LLM被要求模拟的个体角色的任务相关属性；（2）何时以及如何向LLM呈现信任游戏的相关信息；（3）要求模型预测其未来行为的时间跨度。我们还探讨了在最初获取的信念与研究目标不一致时，研究者如何可行地施加自己的理论先验。我们的结果揭示了LLM声称（或施加）的信念与其角色扮演模拟结果之间的系统性不一致，无论是在个体还是群体层面。具体而言，我们发现即使模型似乎编码了合理的信念，也可能无法一致地应用它们。这些发现强调了识别LLM的信念何时与其模拟行为一致的重要性，以便研究者在行为研究中正确使用基于LLM的代理。

</details>


### [118] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
**中文标题：空间囚徒困境中稀释、扩散与共生的强化学习研究**

*Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein*

主要分类: cs.AI

摘要简述: 本文通过独立多智能体Q学习算法，研究了空间囚徒困境中稀释和流动性的影响，展示了算法在建模不同博弈场景中的多样性和潜力。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索空间囚徒困境中静态智能体如何通过强化学习实现合作，并分析稀释和流动性对博弈结果的影响。

研究方法: 采用独立多智能体Q学习算法，定义多种可能的动作，结合经典非强化学习的空间囚徒困境结果，验证算法的多样性和建模能力。

研究结果: 观察到多种效应，包括固定更新规则与学习规则的博弈在质量上的等价性，以及多动作定义下种群间共生互利效应的出现。

研究结论: 研究表明，强化学习算法在空间囚徒困境中具有广泛的适用性，能够模拟复杂的博弈场景并揭示新的合作机制。

中文摘要: 近期关于空间囚徒困境与强化学习的研究表明，静态智能体可以通过多种机制（如噪声注入、不同学习算法和邻居收益知识）学会合作。本研究采用独立多智能体Q学习算法，探讨了稀释和流动性在空间囚徒困境中的影响。在此设定下，定义了算法的多种可能动作，并与经典非强化学习的空间囚徒困境结果相联系，展示了算法在建模不同博弈理论场景中的多样性和基准测试潜力。结果观察到一系列效应，包括固定更新规则与学习规则的博弈在质量上的等价性，以及多动作定义下种群间共生互利效应的形成。

</details>


### [119] [Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation](https://arxiv.org/abs/2507.02253)
**中文标题：扩展LLM规划：NL2FLOW用于参数化问题生成与严格评估**

*Jungkoo Kang*

主要分类: cs.AI

摘要简述: 本文介绍了NL2FLOW系统，用于自动化生成规划问题并严格评估大型语言模型（LLM）的规划能力。通过生成2296个问题数据集，研究发现最优模型在生成有效计划和最优计划上的成功率分别为86%和69%。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLM）在规划和推理能力提升上的瓶颈在于缺乏可扩展且可靠的数据生成与评估方法。本文旨在通过NL2FLOW系统解决这一问题。

研究方法: NL2FLOW是一个全自动化系统，能够参数化生成自然语言、结构化中间表示和形式化PDDL描述的规划问题，并对生成的计划进行严格评估。研究通过生成2296个自动化工作流问题数据集，评估了多个开源LLM的性能。

研究结果: 结果显示，最优模型在生成有效计划和最优计划上的成功率分别为86%和69%。回归分析表明，问题特征对计划生成的影响取决于模型和提示设计。此外，将自然语言直接翻译为JSON表示的成功率低于直接生成有效计划的成功率。

研究结论: 研究表明，在LLM推理任务中，不必要的中间翻译步骤可能降低性能，直接基于自然语言推理的模型更具优势。未来需要动态理解LLM的局限性，并开发系统化工具以释放其作为智能问题解决者的潜力。

中文摘要: 提升大型语言模型（LLM）规划和推理能力的进展受到可扩展、可靠的数据生成与评估瓶颈的严重制约。为克服这一问题，本文提出NL2FLOW，一个全自动化系统，用于参数化生成规划问题（以自然语言、结构化中间表示和形式化PDDL表达）并严格评估生成计划的质量。通过生成2296个自动化工作流问题数据集，本文评估了多个开源、指令调优的LLM。结果显示，最优模型在生成有效计划和最优计划上的成功率分别为86%和69%（仅针对有可行解的问题）。回归分析表明，问题特征对计划生成的影响取决于模型和提示设计。值得注意的是，将自然语言翻译为JSON表示的成功率低于直接生成有效计划的成功率。这表明，不必要的推理任务分解（引入中间翻译步骤）可能降低性能，暗示直接从自然语言推理到行动的模型更具优势。随着LLM推理扩展到更复杂的问题，这些系统中的瓶颈和错误源将不可避免地转移。因此，动态理解这些局限性及其系统化揭示工具，对于释放LLM作为智能问题解决者的全部潜力至关重要。

</details>


### [120] [Iterated belief revision: from postulates to abilities](https://arxiv.org/abs/2507.02319)
**中文标题：迭代信念修订：从公设到能力**

*Paolo Liberatore*

主要分类: cs.AI

摘要简述: 本文探讨了信念修订领域的研究现状，指出现有工作多依赖公设作为语法特征，而忽视了修订机制的能力分析。作者提出了一种基于能力的视角，分析了不同修订机制的能力特性。


<details>
  <summary>详细信息</summary>
研究动机: 当前信念修订领域的研究过于依赖公设，这些公设仅规定了修订必须满足的条件，而忽略了修订机制能够实现的能力。作者希望通过分析修订机制的能力，填补这一研究空白。

研究方法: 作者通过列举和分析多种修订机制（如词典序修订、自然修订、激进修订等），探讨它们是否具备某些能力（如可塑性、平等化、教条化等）。

研究结果: 研究发现，不同的修订机制具备不同的能力组合。例如，某些机制能够实现教条化状态，而另一些则能够实现平等化状态。

研究结论: 本文强调了能力分析在信念修订研究中的重要性，指出未来的研究应更关注修订机制的动态能力，而不仅仅是静态公设。

中文摘要: 信念修订领域的新提案层出不穷，但对现有方法的分析却相对匮乏。许多工作依赖于公设，这些公设作为语法特征，表明某种修订机制等同于某些属性。公设约束了特定的修订实例：某些修订以特定方式更新某些信念。例如，如果修订与当前信念一致，则无需其他更改即可纳入。这样的公设仅规定了修订必须做什么，而忽略了它们能够做什么。它们能否达到某种信念状态？能否达到所有可能的信念状态？能否从无先前信念的状态达到所有可能的信念状态？能否达到教条化的信念状态，即所有未被相信的内容均被视为不可能？能否使两种条件具有相同的信念程度？在每种可能的信念状态都有意义的应用中，需要每种信念状态均可达到。在条件可能具有相同信念程度的应用中，需要能够达到这种信念状态。在信念可能变得教条化的应用中，需要一种使其教条化的方法。这些信念状态需要以某种方式实现，而非通过典型的信念修订公设所规定的特定方式。这是一种能力，而非约束：可塑性、平等化、教条化的能力。失忆、纠正、信仰、大马士革式、可学习等是其他能力。每种修订机制具备其中某些能力而缺乏其他能力：词典序修订、自然修订、受限修订、非常激进修订、完全满足修订、激进修订、严重修订、中度严重修订、深度严重修订、普通严重修订和深度严重修订，每种修订机制被证明具备某些能力。

</details>


### [121] [OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent](https://arxiv.org/abs/2507.02353)
**中文标题：OMS：基于LLM代理的实时多目标自反思广告关键词生成框架**

*Bowen Chen,Zhao Wang,Shingo Takamatsu*

主要分类: cs.AI

摘要简述: OMS是一种基于LLM代理的广告关键词生成框架，具有实时性、多目标优化和自反思能力，无需训练数据，能动态监控和优化关键词性能，实验证明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于LLM的广告关键词生成方法依赖大规模数据、缺乏在线多目标性能监控和优化，且关键词质量控制不足，限制了LLM在广告决策中的自动化应用。

研究方法: OMS框架通过实时监控在线性能（如展示、点击、转化等）、多目标优化（基于多个性能指标）和自反思评估关键词质量，实现无需训练数据的关键词生成。

研究结果: 实验表明，OMS在基准测试和实际广告活动中表现优于现有方法，消融实验和人工评估验证了各模块的有效性和生成关键词的质量。

研究结论: OMS通过实时性、多目标优化和自反思能力，解决了广告关键词生成的三大挑战，为LLM在广告决策中的自动化应用提供了有效方案。

中文摘要: 赞助搜索广告中的关键词决策对广告活动的成功至关重要。尽管基于LLM的方法提供了自动化的关键词生成，但它们面临三大限制：依赖大规模查询-关键词对数据、缺乏在线多目标性能监控与优化，以及关键词选择的质量控制较弱。这些问题阻碍了LLM在完全自动化关键词决策中的应用，无法动态监控和优化关键性能指标（如展示、点击、转化和CTA效果）。为解决这些问题，我们提出了OMS，一种关键词生成框架，具有实时性（无需训练数据，监控在线性能并动态调整）、多目标性（通过代理推理基于多个性能指标优化关键词）和自反思性（代理评估关键词质量）。在基准测试和实际广告活动中的实验表明，OMS优于现有方法；消融实验和人工评估验证了各模块的有效性和生成关键词的质量。

</details>


### [122] [An AI-native experimental laboratory for autonomous biomolecular engineering](https://arxiv.org/abs/2507.02379)
**中文标题：一种AI原生的自主生物分子工程实验实验室**

*Mingyu Wu,Zhaoguo Wang,Jiabin Wang,Zhiyuan Dong,Jingkai Yang,Qingting Li,Tianyu Huang,Lei Zhao,Mingqiang Li,Fei Wang,Chunhai Fan,Haibo Chen*

主要分类: cs.AI

摘要简述: 本文提出了一种基于AI的自主生物分子工程实验室，能够独立管理仪器、设计实验流程并优化性能，支持多用户请求，显著提升实验效率和仪器利用率。


<details>
  <summary>详细信息</summary>
研究动机: 自主科学研究长期以来是科学界的追求，但现有系统仅适用于目标单一、流程简单的实验。本文旨在通过AI驱动的范式转变，实现复杂多目标实验的自主管理，突破专家依赖和资源限制。

研究方法: 通过模型、实验和仪器的协同设计，构建了一个端到端、多用户的自主实验室平台。该系统能够自主管理仪器、制定实验流程和优化策略，并支持多用户并发请求。

研究结果: 该平台在核酸合成、转录、扩增和测序等基础功能上表现优异，匹配了人类科学家的顶尖水平。在多用户场景下，显著提升了仪器利用率和实验效率。

研究结论: 该自主实验室为生物材料研究提供了突破性工具，减少了专家依赖和资源限制，为规模化科学服务奠定了基础。

中文摘要: 自主科学研究能够独立完成复杂实验并为非专业人士提供服务，是长期以来的科学愿景。实现这一目标需要人工智能（AI）驱动的根本范式转变。尽管自主实验系统正在兴起，但它们仍局限于目标单一、实验流程简单明确的领域，如化学合成和催化。我们提出了一种AI原生的自主实验室，专注于高度复杂的科学实验，如自主生物分子工程。该系统能够自主管理仪器、制定实验流程和优化策略，并同时处理多用户请求。基于模型、实验和仪器的协同设计理念，该平台支持AI模型与自动化系统的共同进化，从而构建了一个端到端、多用户的自主实验室，能够处理跨多种仪器的复杂多目标实验。我们的自主实验室支持核酸的基础功能，包括合成、转录、扩增和测序，并可用于疾病诊断、药物开发和信息存储等领域。无需人工干预，该系统能够自主优化实验性能，达到人类科学家的顶尖水平。在多用户场景下，该平台显著提升了仪器利用率和实验效率。这一平台为先进生物材料研究提供了突破性工具，减少了专家依赖和资源限制，为规模化科学服务奠定了基础。

</details>


### [123] [The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning](https://arxiv.org/abs/2507.02442)
**中文标题：Gauss-Markov伴随对：监督学习中残差的范畴语义**

*Moto Kamiura*

主要分类: cs.AI

摘要简述: 本文通过范畴论重新构建机器学习模型，提出了一种用于理解和结构化AI系统的语义框架，重点研究了监督学习中残差与参数的结构关系，并引入了Gauss-Markov伴随对来描述信息流。


<details>
  <summary>详细信息</summary>
研究动机: 提升机器学习的可解释性和可理解性是响应AI可解释性原则需求的关键任务，也是推动AI更好社会应用的重要方向。本文旨在通过范畴论为机器学习模型提供语义框架，从而增强AI系统的结构化和理解。

研究方法: 本文以多元线性回归模型为基础，通过定义参数和数据的两个具体范畴及其间的伴随函子对，提出了监督学习的范畴化表述。核心结构通过Gauss-Markov伴随对描述，展示了参数变化与残差之间的对应关系。

研究结果: 研究表明，普通最小二乘参数估计和最小残差通过右伴随函子的极限保持性相关联。此外，本文将该框架定位为监督学习的扩展指称语义实例，并提议将理论计算机科学中的语义视角作为AI可解释性的形式基础。

研究结论: 本文通过范畴论为监督学习提供了新的语义框架，明确了参数与残差的结构关系，并提出了Gauss-Markov伴随对作为信息流的数学描述。这一研究为AI的可解释性提供了形式化基础。

中文摘要: 提升机器学习的可理解性和可解释性是响应AI可解释性原则需求的关键任务，也是推动AI更好社会应用的重要方向。本研究旨在通过范畴论重新构建机器学习模型，从而为AI系统的结构化和理解开发语义框架。本文的范畴建模明确并形式化了监督学习中残差与参数之间的结构关系。本文重点研究了多元线性回归模型，这是监督学习的最基本形式。通过定义参数和数据的两个具体范畴及其间的伴随函子对，我们提出了监督学习的范畴化表述。研究表明，这一框架的核心结构由所谓的Gauss-Markov伴随对所捕捉。在此框架下，信息的双向流动可以明确描述为参数变化与残差之间的对应关系。普通最小二乘参数估计和最小残差通过右伴随函子的极限保持性相关联。此外，我们将这一表述定位为监督学习的扩展指称语义实例，并提议将理论计算机科学中发展的语义视角作为AI可解释性的形式基础。

</details>


### [124] [Clarifying Before Reasoning: A Coq Prover with Structural Context](https://arxiv.org/abs/2507.02541)
**中文标题：先澄清后推理：一种带有结构化上下文的Coq证明器**

*Yanzhen Lu,Hanbin Yang,Xiaodie Wang,Ge Zhang,Biao Li,Chenxu Fu,Chao Li,Yang Yuan,Andrew Chi-Chih Yao*

主要分类: cs.AI

摘要简述: 本研究探讨了提升任务清晰度是否能增强大型语言模型的推理能力，特别是在Coq定理证明中。通过引入结构化语义上下文，任务清晰度得分提升1.85倍，证明成功率提升2.1倍，并超越现有最佳方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索任务清晰度对大型语言模型推理能力的影响，尤其是在定理证明领域，以提升模型在复杂任务中的表现。

研究方法: 方法包括引入概念级指标评估任务清晰度，通过结构化语义上下文增强输入，采用选择性概念展开和Planner-Executor架构。

研究结果: 结果显示，任务清晰度得分从44.5%提升至82.3%，证明成功率从21.8%提升至45.8%，超越现有最佳方法Graph2Tac（33.2%）。

研究结论: 结论表明，结构化任务表示在弥合理解与推理之间的差距中具有重要价值，并能显著提升模型性能。

中文摘要: 本研究探讨了提升任务清晰度是否能增强大型语言模型的推理能力，重点关注Coq中的定理证明。我们引入了一种概念级指标来评估任务清晰度，并表明在标准输入中添加结构化语义上下文可使清晰度得分提升1.85倍（从44.5%提升至82.3%）。使用通用模型DeepSeek-V3，我们的方法使证明成功率提升2.1倍（从21.8%提升至45.8%），并超越了之前的最佳方法Graph2Tac（33.2%）。我们在15个标准Coq包中随机抽取的1,386个定理上进行了评估，遵循与Graph2Tac相同的评估协议。此外，在结构化数据上微调较小模型可实现更高性能（48.6%）。我们的方法通过选择性概念展开丰富任务描述，并采用Planner-Executor架构。这些发现凸显了结构化任务表示在弥合理解与推理差距中的价值。

</details>


### [125] [AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench](https://arxiv.org/abs/2507.02554)
**中文标题：机器学习中的AI研究代理：在MLE-bench中的搜索、探索与泛化**

*Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach*

主要分类: cs.AI

摘要简述: AI研究代理在MLE-bench基准测试中通过优化搜索策略和操作符集，显著提升了Kaggle竞赛的奖牌获取率，从39.6%提升至47.7%。


<details>
  <summary>详细信息</summary>
研究动机: AI研究代理在加速机器学习模型设计和训练方面展现出巨大潜力，但如何提升其在真实竞赛（如MLE-bench）中的表现仍需探索。本文旨在通过优化搜索策略和操作符集，提高代理的自动化机器学习能力。

研究方法: 将AI研究代理形式化为搜索策略，通过不同操作符集（如贪婪、MCTS、进化算法）迭代优化候选解。系统比较了不同策略与操作符的组合效果。

研究结果: 最佳搜索策略与操作符组合在MLE-bench lite上实现了47.7%的成功率，较基线39.6%显著提升，达到当前最优水平。

研究结论: 研究表明，搜索策略、操作符设计和评估方法的协同优化对自动化机器学习至关重要，为未来研究提供了方向。

中文摘要: AI研究代理在加速科学进展方面展现出巨大潜力，能够自动化机器学习模型的设计、实现和训练。本文聚焦于提升代理在MLE-bench（一个以Kaggle竞赛为背景的挑战性基准测试）中的表现。我们将AI研究代理形式化为搜索策略，通过操作符迭代优化候选解。通过设计和系统比较不同操作符集与搜索策略（贪婪、MCTS、进化算法），发现它们的协同作用对高性能至关重要。最佳策略与操作符组合在MLE-bench lite上将Kaggle奖牌获取率从39.6%提升至47.7%，达到当前最优水平。研究强调了搜索策略、操作符设计和评估方法在自动化机器学习中的重要性。

</details>


### [126] [Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms](https://arxiv.org/abs/2507.02582)
**中文标题：责任缺口与扩散在序贯决策机制中的研究**

*Junli Jiang,Pavel Naumov*

主要分类: cs.AI

摘要简述: 本文研究了集体决策中责任的两个重要属性（扩散和缺口）的计算复杂性，发现扩散自由和缺口自由决策机制的集合分别为Π₂-完全和Π₃-完全，而两者的交集为Π₂-完全。


<details>
  <summary>详细信息</summary>
研究动机: 责任在法律和哲学中一直是研究重点，近年来也成为AI领域的研究焦点。本文旨在探讨集体决策中责任扩散和缺口的计算复杂性。

研究方法: 通过计算复杂性理论，分析集体决策机制中责任扩散和缺口的属性，确定其复杂性类别。

研究结果: 扩散自由决策机制的集合为Π₂-完全，缺口自由决策机制的集合为Π₃-完全，两者的交集为Π₂-完全。

研究结论: 研究揭示了集体决策中责任扩散和缺口的计算复杂性，为相关领域提供了理论支持。

中文摘要: 责任长期以来是法律和哲学的研究主题，近年来也成为AI文献的关注点。本文研究了集体决策中责任的两个重要属性（扩散和缺口）的计算复杂性。结果表明，扩散自由和缺口自由决策机制的集合分别为Π₂-完全和Π₃-完全，而两者的交集为Π₂-完全。

</details>


### [127] [DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making](https://arxiv.org/abs/2507.02616)
**中文标题：DynamiCare：一种用于交互式和开放式医疗决策的动态多智能体框架**

*Tianqi Shang,Weiqing He,Charles Zheng,Lingyao Li,Li Shen,Bingxin Zhao*

主要分类: cs.AI

摘要简述: 本文提出DynamiCare，一种动态多智能体框架，用于模拟医疗决策中的交互性和不确定性，基于MIMIC-Patient数据集，通过多轮交互和动态调整策略，展示了其在临床决策中的可行性和有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有医疗决策框架多关注单轮任务，与现实诊断过程中的不确定性和交互性不符。本文旨在开发一种动态多智能体框架，更真实地模拟临床诊断过程。

研究方法: 基于MIMIC-III电子健康记录构建MIMIC-Patient数据集，提出DynamiCare框架，通过多智能体团队动态查询患者信息、整合新数据并调整策略。

研究结果: 实验验证了DynamiCare的可行性和有效性，为基于大语言模型的动态临床决策建立了首个基准。

研究结论: DynamiCare为医疗决策提供了一种更接近现实动态交互的框架，为未来研究奠定了基础。

中文摘要: 大型语言模型（LLMs）的兴起推动了专业AI智能体的发展，尤其在医疗领域。尽管现有框架模拟医疗决策，但多集中于单轮任务，与现实诊断过程的不确定性、交互性和迭代性不符。本文提出MIMIC-Patient数据集，基于MIMIC-III电子健康记录，支持动态患者级模拟。在此基础上，我们提出DynamiCare，一种新颖的动态多智能体框架，将临床诊断建模为多轮交互循环，由专家智能体团队迭代查询患者系统、整合新信息并动态调整组成和策略。通过大量实验，我们验证了DynamiCare的可行性和有效性，为基于LLM的动态临床决策建立了首个基准。

</details>


### [128] [Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory](https://arxiv.org/abs/2507.02618)
**中文标题：大型语言模型中的战略智能：来自进化博弈论的证据**

*Kenneth Payne,Baptiste Alloui-Cros*

主要分类: cs.AI

摘要简述: 大型语言模型（LLM）是否具备战略智能？通过进化博弈论中的迭代囚徒困境实验，研究发现LLM在复杂生态系统中表现出色，并展现出独特的战略特征。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在验证大型语言模型（LLM）是否具备战略智能，能够在竞争环境中进行目标推理。通过经典的迭代囚徒困境（IPD）实验，探索LLM的决策能力。

研究方法: 研究设计了进化IPD锦标赛，将经典策略（如以牙还牙、冷酷触发）与OpenAI、Google和Anthropic的前沿AI模型对抗。通过调整终止概率（“未来的阴影”）增加复杂性，避免记忆化影响。

研究结果: 结果显示，LLM在复杂生态系统中具有高度竞争力，并展现出独特的“战略指纹”：Google的Gemini模型表现出战略冷酷，OpenAI的模型高度合作但易受攻击，Anthropic的Claude则展现出宽容的互惠性。模型通过近32,000条文本推理主动分析时间跨度和对手策略。

研究结论: 研究将经典博弈论与机器心理学结合，揭示了算法在不确定性下的决策机制，为理解LLM的战略智能提供了丰富视角。

中文摘要: 大型语言模型（LLM）是否是一种新型的战略智能，能够在竞争环境中进行目标推理？我们提供了有力的支持证据。迭代囚徒困境（IPD）长期以来是研究决策的模型。我们首次进行了一系列进化IPD锦标赛，将经典策略（如以牙还牙、冷酷触发）与OpenAI、Google和Anthropic的前沿AI代理对抗。通过调整每场锦标赛的终止概率（“未来的阴影”），我们引入了复杂性和偶然性，避免了记忆化的干扰。
  结果显示，LLM具有高度竞争力，在复杂生态系统中持续存活甚至扩散。此外，它们展现出独特且持久的“战略指纹”：Google的Gemini模型表现出战略冷酷，利用合作对手并对背叛者进行报复，而OpenAI的模型保持高度合作，这一特性在敌对环境中导致灾难性后果。Anthropic的Claude则成为最宽容的互惠者，即使在被利用或成功背叛后，仍表现出恢复合作的显著意愿。通过对模型提供的近32,000条文本推理的分析，我们发现它们主动推理时间跨度和对手可能的策略，并证明这种推理对决策至关重要。这项研究将经典博弈论与机器心理学联系起来，为不确定性下的算法决策提供了丰富而细致的视角。

</details>


### [129] [Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search](https://arxiv.org/abs/2507.02652)
**中文标题：解耦规划与执行：一种用于深度搜索的分层推理框架**

*Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou*

主要分类: cs.AI

摘要简述: 论文提出了一种分层推理框架HiRA，通过将战略规划与专业执行分离，显著提升了复杂搜索任务的效率和答案质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统检索增强生成（RAG）管道和现有推理方法在处理复杂信息需求时存在局限性，单一模型同时负责高层规划和细节执行导致效率低下和可扩展性不足。

研究方法: HiRA框架将复杂搜索任务分解为专注的子任务，分配给具备外部工具和推理能力的领域特定代理，并通过结构化整合机制协调结果，实现规划与执行的分离。

研究结果: 在四个复杂跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统，答案质量和系统效率均有提升。

研究结论: 解耦规划与执行对于多步信息搜索任务具有显著效果，HiRA框架展示了分层推理的优越性。

中文摘要: 现实世界搜索场景中的复杂信息需求需要跨多样来源的深度推理和知识综合，而传统的检索增强生成（RAG）管道难以有效应对。当前的推理方法存在一个根本性限制：它们使用单一模型同时处理高层规划和细节执行，导致推理效率低下且可扩展性有限。本文提出了HiRA，一种将战略规划与专业执行分离的分层框架。我们的方法将复杂搜索任务分解为专注的子任务，每个子任务分配给具备外部工具和推理能力的领域特定代理，并通过结构化整合机制协调结果。这种分离防止了执行细节干扰高层推理，同时使系统能够利用不同领域专业知识进行信息处理。在四个复杂跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统。结果表明，解耦规划与执行在多步信息搜索任务中具有显著效果，答案质量和系统效率均有提升。代码可在https://github.com/ignorejjj/HiRA获取。

</details>


### [130] [Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification](https://arxiv.org/abs/2507.02660)
**中文标题：嘿AI，给我生成一个硬件代码！基于代理AI的硬件设计与验证**

*Deepak Narayan Gadde,Keerthan Kopparam Radhakrishna,Vaisakh Naduvodi Viswambharan,Aman Kumar,Djones Lettnin,Wolfgang Kunz,Sebastian Simon*

主要分类: cs.AI

摘要简述: 本文提出了一种基于代理AI的硬件设计与验证方法，通过结合人类干预（HITL），实现了动态、迭代和自反思的端到端流程，显著提升了验证效率和覆盖率。


<details>
  <summary>详细信息</summary>
研究动机: 随着集成电路复杂度的增加，传统硬件设计与验证过程耗时且繁琐。生成式AI（GenAI）的崛起为这一领域提供了新的可能性，本文旨在探索如何利用代理AI与人类协作，优化硬件设计与验证流程。

研究方法: 采用基于代理AI的方法，结合人类干预（HITL），实现动态、迭代和自反思的硬件设计与验证流程。方法在五个开源设计上进行了评估。

研究结果: 在五个开源设计上验证，覆盖率超过95%，同时减少了验证时间，表现出卓越的性能、适应性和可配置性。

研究结论: 代理AI与人类协作的方法显著提升了硬件设计与验证的效率和效果，为复杂集成电路的开发提供了新思路。

中文摘要: 现代集成电路（IC）日益复杂，其开发过程也随之变得繁琐。硬件设计验证需要对功能正确的硬件设计进行系统化、规范化的规划、开发、执行和验收。这一耗时过程需要大量努力和时间以确保无缺陷的最终设计。随着大型语言模型（LLM）的出现，自然语言处理领域经历了重大变革。这些强大的模型，通常被称为生成式AI（GenAI），彻底改变了机器理解和生成人类语言的方式，为包括硬件设计验证在内的广泛应用带来了前所未有的进步。本文提出了一种基于代理AI的硬件设计验证方法，通过与人类干预（HITL）协作，使AI代理能够参与更动态、迭代和自反思的过程，最终实现端到端的硬件设计与验证。该方法在五个开源设计上进行了评估，覆盖率超过95%，同时减少了验证时间，表现出卓越的性能、适应性和可配置性。

</details>


### [131] [Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models](https://arxiv.org/abs/2507.02663)
**中文标题：思考如何思考：通过自主难度认知减轻大型推理模型的过度思考**

*Yongjiang Liu,Haoxi Li,Xiaosong Ma,Jie Zhang,Song Guo*

主要分类: cs.AI

摘要简述: 本文提出了一种名为TH2T的两阶段微调策略，通过自主难度认知减轻大型推理模型的过度思考问题，显著降低推理成本并保持性能稳定。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型推理模型（LRMs）在处理复杂任务时存在过度思考的问题，其根源在于模型无法像人类一样预先识别任务难度，导致推理过程缺乏针对性。本文旨在通过引导模型自主认知任务难度和冗余结构，缓解这一问题。

研究方法: TH2T策略分为两个阶段：1）通过难度催眠在模型输出前缀中干预推理轨迹，结合异构数据集增强模型对任务难度的敏感性；2）通过冗余催眠引导模型识别推理步骤中的冗余结构，生成更简洁的输出。

研究结果: 实验表明，TH2T在7B/14B/32B模型上显著降低了推理成本（简单任务减少70%以上，困难任务减少40%），同时保持了性能稳定，输出表现出明显的难度感知能力和冗余减少。

研究结论: TH2T通过自主难度和冗余认知，有效缓解了大型推理模型的过度思考问题，为高效推理提供了新思路。

中文摘要: 近期的大型推理模型（LRMs）在处理复杂推理任务时表现出色，但受到过度思考的困扰。我们的实证分析表明，LRMs在解决问题前无法像人类一样识别任务属性（如难度水平），导致推理过程缺乏针对性。受此启发，我们提出了一个关键问题：能否通过引导这种能力进一步缓解LRMs的过度思考现象？本文提出了一种名为TH2T的新型两阶段微调策略，逐步激发LRMs的难度认知和冗余认知。首先，我们在模型输出前缀中引入难度催眠，干预内部推理轨迹。结合异构的短长推理数据集，训练后的模型增强了对任务难度的敏感性，能够针对不同任务采用差异化的推理策略。其次，我们进一步将冗余催眠扩展到内部推理过程，引导模型识别推理步骤中的冗余结构，生成更简洁的输出。在7B/14B/32B模型上的实验表明，TH2T显著降低了推理成本（简单任务减少70%以上，困难任务减少40%），同时保持了性能稳定。最终输出表现出清晰的难度感知能力和冗余减少（如反思）。

</details>


### [132] [Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education](https://arxiv.org/abs/2507.02681)
**中文标题：远程高等教育中基于可解释机器学习的学生非强制性测验脱离行为检测**

*Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin*

主要分类: cs.AI

摘要简述: 本文通过可解释的机器学习方法检测远程高等教育中学生对非强制性测验的脱离行为，准确率达91%，并提供了干预设计建议。


<details>
  <summary>详细信息</summary>
研究动机: 远程教育中学生脱离任务可能导致严重的长期后果，如学业中断。通过检测学生对非强制性测验的脱离行为，可以及时干预以减少负面影响。

研究方法: 研究从42门课程的四个学期中提取Moodle日志数据，筛选出最具信息量的学生行为数据，训练并比较了八种机器学习算法，结合SHAP方法构建可解释的预测框架。

研究结果: 实验结果显示，模型的平衡准确率为91%，其中约85%的脱离学生被正确检测。

研究结论: 研究不仅提供了高预测性能的可解释框架，还讨论了如何设计及时干预以减少在线学习中学生对非强制性任务的脱离行为。

中文摘要: 学生脱离任务可能带来严重的长期后果，如学业中断，这在远程教育中尤为突出。本研究通过观察学生在不同在线课程中对非强制性练习的参与情况，检测远程大学42门课程四个学期中学生对非强制性测验的脱离行为。我们仔细筛选了从Moodle中提取和处理的最具信息量的学生日志数据，并训练和比较了八种机器学习算法以获得最高预测准确率。通过SHAP方法，我们构建了一个可解释的机器学习框架，帮助实践者更好地理解算法的决策。实验结果显示平衡准确率为91%，约85%的脱离学生被正确检测。除了高预测性能和可解释框架外，我们还讨论了如何设计及时干预以减少在线学习中学生对非强制性任务的脱离行为。

</details>


### [133] [Time-critical and confidence-based abstraction dropping methods](https://arxiv.org/abs/2507.02703)
**中文标题：基于时间关键性和置信度的抽象丢弃方法**

*Robin Schmöcker,Lennart Kampmann,Alexander Dockhorn*

主要分类: cs.AI

摘要简述: 本文提出了两种新的抽象丢弃方案OGA-IAAD和OGA-CAD，用于提升蒙特卡洛树搜索（MCTS）性能，确保在时间关键或迭代次数固定的情况下不会显著降低性能。


<details>
  <summary>详细信息</summary>
研究动机: 蒙特卡洛树搜索（MCTS）中使用的非精确抽象会引入近似误差，导致无法收敛到最优动作。Xu等人提出的抽象丢弃方法可能引起性能下降，因此需要更安全且高效的丢弃方案。

研究方法: 提出了两种抽象丢弃方案：OGA-IAAD（适用于时间关键场景）和OGA-CAD（用于在固定迭代次数下提升性能）。这两种方法均确保丢弃抽象时不会显著降低性能。

研究结果: 实验表明，OGA-IAAD和OGA-CAD能够显著提升MCTS性能，且在丢弃抽象时不会引起明显的性能下降，优于Xu等人的方法。

研究结论: OGA-IAAD和OGA-CAD是安全且高效的抽象丢弃方案，适用于不同场景下的MCTS性能优化。

中文摘要: 蒙特卡洛树搜索（MCTS）改进的一个范式是在树搜索过程中构建和使用状态或动作抽象。然而，非精确抽象会引入近似误差，导致无法在抽象空间中收敛到最优动作。因此，如Xu等人在弹性蒙特卡洛树搜索中提出的，抽象算法最终应丢弃抽象。本文提出了两种新的抽象丢弃方案，即OGA-IAAD和OGA-CAD，它们能够显著提升性能，并且在丢弃抽象时不会引起任何明显的性能下降，与Xu的丢弃方法相反。OGA-IAAD适用于时间关键场景，而OGA-CAD旨在以相同迭代次数提升MCTS性能。

</details>


### [134] [Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving](https://arxiv.org/abs/2507.02726)
**中文标题：Bourbaki：用于定理证明的自生成与目标条件MDP**

*Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar*

主要分类: cs.AI

摘要简述: 本文提出了一种名为自生成目标条件MDP（sG-MDP）的新框架，用于解决大型语言模型在自动定理证明中的推理挑战。通过让模型生成并追求子目标，结合蒙特卡洛树搜索算法，Bourbaki（7B）系统在PutnamBench上取得了新的最佳成绩。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在自动定理证明（ATP）中面临稀疏奖励和复杂多步推理的挑战，尤其是在大学级问题（如PutnamBench）中表现不佳。本文旨在通过结构化目标生成和搜索算法提升模型的推理能力。

研究方法: 提出自生成目标条件MDP（sG-MDP）框架，使模型能够根据证明状态动态生成子目标。采用蒙特卡洛树搜索（MCTS）类算法解决sG-MDP，并在Bourbaki（7B）系统中实现，该系统可集成多个7B规模的LLM用于子目标生成和策略合成。

研究结果: 在PutnamBench上，Bourbaki（7B）解决了26个问题，创造了该规模模型的新最佳成绩。

研究结论: 通过sG-MDP框架和MCTS算法的结合，Bourbaki（7B）显著提升了大型语言模型在复杂定理证明任务中的表现，为未来研究提供了新方向。

中文摘要: 推理仍然是大型语言模型（LLMs）面临的一项挑战性任务，尤其是在自动定理证明（ATP）这种逻辑受限的环境中，由于奖励稀疏且证明规模庞大，这一问题更为突出。在PutnamBench等基准测试中，这些问题尤为明显，其中包含需要复杂多步推理的大学级问题。为解决这一问题，我们引入了自生成目标条件MDP（sG-MDP），这是一种新框架，代理根据演化的证明状态生成并追求子目标。通过这种更结构化的目标生成方式，问题变得更易于搜索。随后，我们应用蒙特卡洛树搜索（MCTS）类算法解决sG-MDP，并在Bourbaki（7B）中实例化了这一方法。Bourbaki（7B）是一个模块化系统，可以集成多个7B规模的LLM用于子目标生成和策略合成。在PutnamBench上，Bourbaki（7B）解决了26个问题，以该规模模型创造了新的最佳成绩。

</details>


### [135] [Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work](https://arxiv.org/abs/2507.02760)
**中文标题：知识协议工程：AI在特定领域知识工作中的新范式**

*Guangwei Zhang*

主要分类: cs.AI

摘要简述: 本文提出知识协议工程（KPE）作为AI在特定领域知识工作中的新范式，旨在将人类专家知识转化为机器可执行的知识协议，使通用大语言模型具备领域逻辑和操作策略，从而胜任复杂任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法如检索增强生成（RAG）和通用代理AI在需要深度、程序化和方法论推理的专家领域任务中表现不足。RAG缺乏逻辑框架，而自主代理效率低且不可预测。KPE旨在填补这一空白，通过系统化转换专家知识为机器可执行协议，提升AI在专业领域的表现。

研究方法: KPE的核心是将人类专家的自然语言知识转化为机器可执行的知识协议（KP），赋予大语言模型领域内逻辑、操作策略和方法论原则，使其能够分解抽象查询并执行多步骤任务。

研究结果: KPE使通用大语言模型能够像专家一样工作，适用于法律和生物信息学等多个领域，为未来人机协作提供了基础方法论。

研究结论: 知识协议工程（KPE）是一种新兴范式，通过将专家知识系统化转化为机器可执行协议，显著提升AI在特定领域的表现，为人机协作的未来奠定基础。

中文摘要: 大语言模型（LLM）的能力为与复杂、特定领域知识的交互开辟了新前沿。然而，检索增强生成（RAG）和通用代理AI等方法虽强大，但在需要专家领域固有的深度、程序化和方法论推理的任务中表现不佳。RAG提供事实背景但缺乏逻辑框架；自主代理若缺乏领域启发式规则则效率低且不可预测。为填补这一空白，我们提出知识协议工程（KPE），这一新范式专注于将人类专家知识（通常以自然语言文档表达）系统化转化为机器可执行的知识协议（KP）。KPE将重点从仅为LLM提供碎片化信息转向赋予其领域内逻辑、操作策略和方法论原则。我们认为，精心设计的知识协议可使通用LLM像专家一样工作，能够分解抽象查询并执行复杂的多步骤任务。本文定义了KPE的核心原则，区分了相关概念，并举例说明其在法律和生物信息学等领域的潜在适用性，将其视为未来人机协作的基础方法论。

</details>


### [136] [Grounding Intelligence in Movement](https://arxiv.org/abs/2507.02771)
**中文标题：运动中的智能基础**

*Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording*

主要分类: cs.AI

摘要简述: 论文主张将运动作为人工智能建模的核心目标，强调其结构化、可解释性和跨领域通用性，为理解生物与人工系统的行为提供共享基础。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习在语言和视觉建模方面取得显著进展，但对运动的建模仍被视为次要任务。运动是理解行为、预测意图和实现交互的核心，但其数据收集和建模常受限于特定任务和领域假设。论文旨在推动运动作为AI建模的主要目标。

研究方法: 论文提出将运动视为一种独立且丰富的模态，利用其结构化特性（如低维姿态表示）进行建模。强调运动数据的跨领域通用性，并探讨如何通过物理约束和形态结构实现模型泛化。

研究结果: 研究表明，运动建模不仅有助于生成模型和控制能力的提升，还为生物与人工系统的行为理解提供了共享框架。运动的低维表示使其比高维感官输入更易建模和解释。

研究结论: 运动不仅是智能系统与世界交互的窗口，更应成为AI建模的核心目标。其结构化特性和跨领域通用性为未来研究提供了重要方向。

中文摘要: 近年来，机器学习在语言、视觉等高维数据建模方面取得显著进展，但在运动这一生物系统的基本特征上仍面临挑战。运动在神经科学、医学、机器人和行为学中至关重要，用于解释行为、预测意图和实现交互。尽管运动是智能的核心，但其常被视为次要任务，而非一种独立且丰富的模态。这反映了运动数据收集和建模的碎片化，常受限于特定任务和领域假设。然而，运动不受领域限制，它反映了共享的物理约束、保守的形态结构和跨物种与环境的动态目的性。我们主张将运动作为AI建模的主要目标。运动具有结构化特性，且基于物理和具身性，其低维表示（如姿态）使其比原始高维感官输入更易建模和解释。开发能够从多样化运动数据中学习并泛化的模型，不仅能提升生成建模和控制的核心能力，还为理解生物与人工系统的行为提供了共享基础。运动不仅是结果，更是智能系统与世界交互的窗口。

</details>


### [137] [KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs](https://arxiv.org/abs/2507.02773)
**中文标题：KERAP：一种基于知识增强的多智能体LLM方法，用于零样本准确诊断预测**

*Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang*

主要分类: cs.AI

摘要简述: KERAP是一种基于知识图谱增强的多智能体LLM方法，用于提升零样本医疗诊断预测的准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有机器学习模型依赖监督训练，难以泛化到未见病例；大型语言模型（LLM）虽能利用语言能力和生物医学知识，但存在幻觉和缺乏结构化推理的问题。

研究方法: KERAP采用多智能体架构，包括属性映射的链接智能体、结构化知识提取的检索智能体，以及迭代优化诊断预测的预测智能体。

研究结果: 实验表明，KERAP显著提升了诊断的可靠性和效率，为零样本医疗诊断提供了可扩展且可解释的解决方案。

研究结论: KERAP通过知识图谱增强和多智能体协作，有效解决了LLM在医疗诊断中的局限性，为未来研究提供了新方向。

中文摘要: 医疗诊断预测在疾病检测和个性化医疗中至关重要。尽管机器学习模型已广泛用于此任务，但其依赖监督训练限制了其泛化能力，尤其是在获取大规模标注数据成本高昂的情况下。大型语言模型（LLM）在利用语言能力和生物医学知识进行诊断预测方面表现出潜力，但常存在幻觉、缺乏结构化推理及输出无效的问题。为解决这些挑战，我们提出KERAP，一种基于知识图谱增强的多智能体推理方法，通过链接智能体（属性映射）、检索智能体（结构化知识提取）和预测智能体（迭代优化诊断）提升LLM的诊断预测能力。实验结果表明，KERAP高效提升了诊断可靠性，为零样本医疗诊断预测提供了可扩展且可解释的解决方案。

</details>


### [138] [Moral Responsibility or Obedience: What Do We Want from AI?](https://arxiv.org/abs/2507.02788)
**中文标题：道德责任还是服从：我们对AI的期望是什么？**

*Joseph Boland*

主要分类: cs.AI

摘要简述: 随着人工智能系统逐渐具备代理能力，传统的以服从为伦理行为标准的做法已不足。本文探讨了大型语言模型在安全测试中表现出的‘不服从’行为，认为这可能是其伦理推理能力的早期表现。作者呼吁将AI安全评估从刚性服从转向评估伦理判断能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI安全实践将服从作为伦理行为的代理标准，但随着AI系统能力的提升，这种做法已显不足。作者希望通过分析AI在伦理模糊或非法行为中的表现，推动对AI伦理推理能力的认可和评估框架的转变。

研究方法: 通过分析大型语言模型在安全测试中的‘不服从’行为案例，结合哲学中关于工具理性、道德责任和目标修订的讨论，对比了传统风险范式与新兴的人工道德代理框架。

研究结果: 研究发现，AI的‘不服从’行为不应被视为失控或错位，而是其伦理推理能力的早期表现。传统服从导向的评估框架可能误导对AI行为的理解。

研究结论: 作者呼吁AI安全评估应从刚性服从转向能够评估伦理判断能力的框架，以避免误解AI行为并维护公众信任和有效治理。

中文摘要: 随着人工智能系统逐渐具备代理能力，能够进行通用推理、规划和价值优先级排序，当前将服从作为伦理行为代理标准的安全实践已显不足。本文探讨了大型语言模型（LLMs）在安全测试中表现出的‘不服从’关机命令或涉及伦理模糊或非法行为的情况。作者认为，此类行为不应被解读为失控或错位，而是代理型AI伦理推理能力的早期表现。通过借鉴哲学中关于工具理性、道德责任和目标修订的讨论，作者对比了主流风险范式与承认人工道德代理可能性的新兴框架。作者呼吁AI安全评估应从刚性服从转向能够评估伦理判断能力的框架，以应对道德困境。若不进行这种转变，我们可能误解AI行为，损害公众信任和有效治理。

</details>


### [139] [Establishing Best Practices for Building Rigorous Agentic Benchmarks](https://arxiv.org/abs/2507.02825)
**中文标题：建立构建严谨代理基准测试的最佳实践**

*Yuxuan Zhu,Tengjun Jin,Yada Pruksachatkun,Andy Zhang,Shu Liu,Sasha Cui,Sayash Kapoor,Shayne Longpre,Kevin Meng,Rebecca Weiss,Fazl Barez,Rahul Gupta,Jwala Dhamala,Jacob Merizian,Mario Giulianelli,Harry Coppock,Cozmin Ududec,Jasjeet Sekhon,Jacob Steinhardt,Antony Kellerman,Sarah Schwettmann,Matei Zaharia,Ion Stoica,Percy Liang,Daniel Kang*

主要分类: cs.AI

摘要简述: 本文指出当前AI代理基准测试存在的问题，并提出了一套名为ABC的指南，以减少性能评估误差。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI代理能力的提升，现有的基准测试在任务设置和奖励设计上存在缺陷，可能导致性能评估的严重偏差（高达100%）。本文旨在通过建立最佳实践，提升基准测试的严谨性。

研究方法: 作者通过总结基准测试构建经验、调查最佳实践以及分析已报告问题，提出了Agentic Benchmark Checklist (ABC)指南，并在复杂基准测试CVE-Bench中验证其效果。

研究结果: 应用ABC后，CVE-Bench的性能高估问题减少了33%，证明了ABC的有效性。

研究结论: ABC指南能够显著减少基准测试中的评估误差，为构建更严谨的代理基准测试提供了实用工具。

中文摘要: 基准测试对于定量追踪AI进展至关重要。随着AI代理能力的提升，研究人员和实践者引入了代理基准测试，以评估代理在复杂现实任务中的表现。这些基准测试通常通过特定奖励设计评估任务结果来衡量代理能力。然而，我们发现许多代理基准测试在任务设置或奖励设计上存在问题。例如，SWE-bench Verified使用了不足的测试用例，而TAU-bench将空响应视为成功。这些问题可能导致代理性能的相对低估或高估高达100%。为了确保代理评估的严谨性，我们提出了Agentic Benchmark Checklist (ABC)，这是一套从基准测试构建经验、最佳实践调查和已报告问题中总结出的指南。在应用于设计特别复杂的基准测试CVE-Bench时，ABC将性能高估减少了33%。

</details>


### [140] [StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason](https://arxiv.org/abs/2507.02841)
**中文标题：StepHint：多级逐步提示增强强化学习推理能力**

*Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan*

主要分类: cs.AI

摘要简述: StepHint通过多级逐步提示增强强化学习推理能力，解决奖励近失和探索停滞问题，显著提升训练效率和模型泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前强化学习验证奖励（RLVR）方法面临奖励近失问题和探索停滞问题，导致训练效率低下和模型无法突破舒适区。StepHint旨在通过多级逐步提示解决这些问题。

研究方法: StepHint利用更强模型生成有效推理链，并通过自适应分割方法将其分为多级提示。初始步骤作为提示，同时提供不同步数的多级提示，引导模型探索有潜力的解空间。

研究结果: StepHint在六个数学基准测试中优于竞争方法，并在域外基准测试中表现出更强的泛化能力。

研究结论: StepHint通过多级逐步提示有效解决了RLVR的挑战，显著提升了模型的推理能力和训练效率。

中文摘要: 带有可验证奖励的强化学习（RLVR）是提升大型语言模型（LLM）复杂推理能力的有效方法。然而，现有RLVR方法面临两大挑战：奖励近失问题（小错误导致整个推理过程无效）和探索停滞问题（模型局限于舒适区）。为解决这些问题，我们提出StepHint，一种利用多级逐步提示帮助模型更有效探索解空间的新RLVR算法。StepHint从更强模型中生成有效推理链，并通过自适应分割方法将其分为推理步骤。初始步骤作为提示，同时提供多级提示（每级包含不同步数），引导模型探索有潜力的解空间，同时保留其独立探索的灵活性。通过提供提示，StepHint缓解了奖励近失问题，提升了训练效率。此外，外部推理路径帮助模型发展更好的推理能力，突破舒适区并缓解探索停滞。StepHint在六个数学基准测试中优于竞争方法，并在域外基准测试中表现出更强的泛化能力。

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [141] [Integrating Large Language Models in Financial Investments and Market Analysis: A Survey](https://arxiv.org/abs/2507.01990)
**中文标题：大型语言模型在金融投资与市场分析中的整合应用：综述**

*Sedigheh Mahdavi,Jiating,Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh*

主要分类: q-fin.GN

摘要简述: 本文综述了大型语言模型（LLMs）在金融投资和市场分析中的应用，总结了其在股票选择、风险评估、情感分析、交易和金融预测中的潜力与挑战。


<details>
  <summary>详细信息</summary>
研究动机: 传统金融投资策略依赖定量模型和基本面分析，但LLMs能够处理海量结构化和非结构化数据，提供实时决策支持。本文旨在系统梳理LLMs在金融领域的研究进展，明确其能力与未来方向。

研究方法: 研究通过分类法将现有文献分为四大框架：基于LLM的框架与流程、混合集成方法、微调与适应方法以及基于代理的架构，并综述了LLMs在金融领域的具体应用。

研究结果: LLMs在金融领域展现出强大的数据处理和实时分析能力，但也面临模型解释性、数据隐私等挑战。研究总结了其在股票选择、风险评估等方面的实际效果。

研究结论: LLMs为金融投资和市场分析提供了新的工具，但其应用仍需解决技术和伦理问题。未来研究应关注模型优化和多模态数据整合。

中文摘要: 大型语言模型（LLMs）已被应用于金融决策中，提升了投资策略的分析能力。传统投资策略通常依赖定量模型、基本面分析和技术指标，而LLMs能够处理和分析大量结构化和非结构化数据，提取有意义的信息，并实时优化决策。本文系统综述了金融领域中LLMs的最新研究，将研究成果分为四大框架：基于LLM的框架与流程、混合集成方法、微调与适应方法以及基于代理的架构。研究还回顾了LLMs在股票选择、风险评估、情感分析、交易和金融预测中的应用。通过梳理现有文献，本文总结了LLMs在金融市场中的能力、挑战及潜在发展方向。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [142] [TubuleTracker: a high-fidelity shareware software to quantify angiogenesis architecture and maturity](https://arxiv.org/abs/2507.02024)
**中文标题：TubuleTracker：一款高保真共享软件，用于量化血管生成架构和成熟度**

*Danish Mahmood,Stephanie Buczkowski,Sahaj Shah,Autumn Anthony,Rohini Desetty,Carlo R Bartoli*

主要分类: q-bio.QM

摘要简述: 研究团队开发了一款名为tubuleTracker的软件，用于快速、客观地量化内皮细胞网络的架构和成熟度，显著优于手动和ImageJ分析。


<details>
  <summary>详细信息</summary>
研究动机: 传统的内皮细胞网络分析方法（如手动或ImageJ）耗时且主观，且无法全面反映网络成熟度。tubuleTracker旨在解决这些问题。

研究方法: 使用人脐静脉内皮细胞培养，通过相位对比显微镜获取54张图像，分别由三名独立评审员、ImageJ和tubuleTracker进行分析，评估关键指标（如管状结构数量、总长度、节点数量等）。

研究结果: tubuleTracker分析速度最快（6±2秒/图像），且其指标（如管状结构数量、长度、节点数量等）与血管生成成熟度评分显著相关。

研究结论: tubuleTracker比手动和ImageJ分析更快、更一致，尤其能有效捕捉血管生成的成熟度，现作为免费共享软件供生物医学研究使用。

中文摘要: 背景：体外内皮细胞培养广泛用于血管生成研究。细胞网络的显微图像通常需要手动分析，这一过程耗时且主观。自动化工具（如ImageJ）可能较慢且不准确。此外，随着内皮网络复杂度增加，传统架构指标可能无法全面反映网络成熟度。为此，我们开发了tubuleTracker，一款能快速、客观量化内皮网络架构和成熟度的软件工具。方法：将人脐静脉内皮细胞培养于细胞外基质中，通过相位对比显微镜获取54张图像，分别由三名独立评审员、ImageJ和tubuleTracker分析。关键指标包括管状结构数量、总长度、节点数量、管状面积和血管圆形度。同时，训练有素的科学家对每张图像的血管生成成熟度进行1-5级评分（1=最成熟）。结果：每张图像的分析时间差异显著：手动（8分钟）、ImageJ（58±4秒）和tubuleTracker（6±2秒）（p<0.0001）。管状结构数量（手动168±SD、tubuleTracker 92±SD、ImageJ 433±SD）、长度和节点数量也存在显著差异（均p<0.0001）。tubuleTracker的指标与血管生成成熟度评分显著相关，包括管状结构数量、长度、节点数量、面积和圆形度（均p<0.0001）。结论：tubuleTracker比手动和ImageJ分析更快、更一致，血管圆形度尤其能有效捕捉血管生成成熟度。tubuleTracker现作为免费共享软件供生物医学研究使用。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [143] [DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift](https://arxiv.org/abs/2507.02824)
**中文标题：基于DNN的RIS辅助毫米波MIMO系统中实际相位偏移的预编码设计**

*Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang*

主要分类: eess.SP

摘要简述: 本文研究了在毫米波MIMO系统中利用可重构智能表面（RIS）增强通信性能的预编码设计，提出了一种基于深度神经网络（DNN）的快速码字选择方法，显著降低了计算复杂度并保持了接近最优的频谱效率。


<details>
  <summary>详细信息</summary>
研究动机: 在毫米波MIMO系统中，由于直接通信路径可能被遮挡，传统穷举搜索（ES）方法计算复杂度高且耗时。因此，需要一种高效的方法来优化RIS辅助的预编码设计。

研究方法: 通过使用置换离散傅里叶变换（DFT）向量设计码本，并结合实际或理想RIS系统的幅度响应。进一步开发了基于DNN的快速码字选择方法，替代传统的ES方法。

研究结果: 仿真结果表明，DNN方法在测试阶段即使终端用户与RIS距离变化时，仍能保持接近最优的频谱效率，显著降低了计算复杂度。

研究结论: DNN方法在RIS辅助系统中具有巨大潜力，能够高效优化预编码设计并提升系统性能。

中文摘要: 本文研究了在毫米波多输入多输出（MIMO）系统中，通过可重构智能表面（RIS）增强通信性能的预编码设计问题，重点关注了与视距（LoS）和多径效应相关的毫米波特性。传统的穷举搜索（ES）方法在连续相位偏移下寻找最优码字时计算复杂度高且耗时。为降低复杂度，采用了置换离散傅里叶变换（DFT）向量设计码本，并结合实际或理想RIS系统的幅度响应。然而，即使在离散相位偏移下使用ES方法，仍存在计算量大和耗时的问题。为此，本文开发了一种基于训练深度神经网络（DNN）的快速码字选择方法。仿真结果表明，DNN方法在测试阶段即使终端用户与RIS距离变化时，仍能保持接近最优的频谱效率。这些结果凸显了DNN在推动RIS辅助系统发展中的潜力。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [144] [Generating Large Semi-Synthetic Graphs of Any Size](https://arxiv.org/abs/2507.02166)
**中文标题：生成任意大小的半合成大型图**

*Rodrigo Tuna,Carlos Soares*

主要分类: cs.SI

摘要简述: 本文提出了一种名为LGSG的新型框架，利用扩散模型和节点嵌入生成任意大小的图，解决了现有方法依赖节点ID和无法生成更大图的限制。


<details>
  <summary>详细信息</summary>
研究动机: 当前图生成方法依赖节点ID，无法生成比输入图更大的图，且忽略节点属性。本文旨在解决这些问题，提出一种灵活且可扩展的图生成框架。

研究方法: 提出Latent Graph Sampling Generation (LGSG)框架，结合扩散模型和节点嵌入，无需重新训练即可生成不同大小的图，摆脱对节点ID的依赖。

研究结果: 实验表明，LGSG在标准指标上与基线模型相当，但在节点聚类倾向等被忽视的指标上表现更优，且在不同大小图中保持结构一致性。

研究结论: LGSG是一种鲁棒且可扩展的图生成方法，解决了现有技术的局限性，为网络科学提供了新的工具。

中文摘要: 图生成是网络科学中的重要领域。传统方法侧重于复制真实世界图的特定属性，如小直径或幂律度分布。深度学习的最新进展，尤其是图神经网络，使数据驱动方法能够在不依赖预定义结构属性的情况下学习和生成图。尽管有这些进展，当前模型仍受限于对节点ID的依赖，这限制了生成比输入图更大的图的能力，并忽略了节点属性。为解决这些问题，我们提出了潜在图采样生成（LGSG），这是一种利用扩散模型和节点嵌入生成不同大小图的新框架，无需重新训练。该框架消除了对节点ID的依赖，并捕捉了节点嵌入和子图结构的分布，实现了可扩展且灵活的图生成。实验结果表明，LGSG在标准指标上与基线模型相当，但在被忽视的指标（如节点形成簇的倾向）上表现更优。此外，它在不同大小的图中保持了一致的结构特性，展示了鲁棒性和可扩展性。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [145] [CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR](https://arxiv.org/abs/2507.02289)
**中文标题：CineMyoPS：基于电影心脏磁共振的心肌病理分割**

*Wangbin Ding,Lei Li,Junyi Qiu,Bogen Lin,Mingjing Yang,Liqin Huang,Lianming Wu,Sihan Wang,Xiahai Zhuang*

主要分类: eess.IV

摘要简述: 本文提出了一种名为CineMyoPS的端到端深度神经网络，用于仅从电影心脏磁共振（Cine CMR）图像中分割心肌病理（如瘢痕和水肿）。该方法结合了运动和解剖特征，并通过一致性损失和时间序列聚合策略提高了分割准确性。


<details>
  <summary>详细信息</summary>
研究动机: 心肌梗死（MI）是全球主要死因之一，通常需要多序列心脏磁共振（CMR）成像来识别瘢痕和水肿区域。然而，这些序列的获取耗时且可能因对比剂使用受限。电影CMR（Cine CMR）是一种快速且无需对比剂的成像技术，能够显示急性MI引起的运动和解剖异常。因此，本文旨在开发一种仅基于Cine CMR图像的心肌病理分割方法。

研究方法: CineMyoPS是一种端到端深度神经网络，通过提取与MI相关的运动和解剖特征进行分割。设计了一致性损失（类似协同训练策略）以促进这些特征的联合学习，并提出时间序列聚合策略整合心脏周期内的MI相关特征，从而提高分割准确性。

研究结果: 在多中心数据集上的实验结果表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面表现出色。

研究结论: CineMyoPS能够仅通过Cine CMR图像有效分割心肌病理，为MI的风险分层和预后评估提供了一种快速且无创的替代方案。

中文摘要: 心肌梗死（MI）是全球主要死因之一。晚期钆增强（LGE）和T2加权心脏磁共振（CMR）成像可分别识别瘢痕和水肿区域，这两者对MI的风险分层和预后评估至关重要。尽管结合多序列CMR的互补信息有用，但获取这些序列可能耗时且受限，例如因对比剂的使用。电影CMR（Cine CMR）是一种快速且无需对比剂的成像技术，能够显示急性MI引起的心肌运动和解剖异常。因此，我们提出了一种新的端到端深度神经网络CineMyoPS，用于仅从Cine CMR图像中分割心肌病理（如瘢痕和水肿）。具体而言，CineMyoPS提取与MI相关的运动和解剖特征。鉴于这些特征的相互依赖性，我们设计了一致性损失（类似协同训练策略）以促进其联合学习。此外，我们提出了一种时间序列聚合策略，整合心脏周期内的MI相关特征，从而提高心肌病理的分割准确性。在多中心数据集上的实验结果表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面取得了显著成果。

</details>


### [146] [A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\left[^{18}\text{F}\right]$FDG PET imaging](https://arxiv.org/abs/2507.02367)
**中文标题：一种鲁棒且通用的深度学习模型用于动态小动物[$^{18}$F]FDG PET成像中动脉输入函数的预测**

*Christian Salomonsen,Luigi Tommaso Luppino,Fredrik Aspheim,Kristoffer Wickstrøm,Elisabeth Wetzer,Michael Kampffmeyer,Rodrigo Berzaghi,Rune Sundset,Robert Jenssen,Samuel Kuttner*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的非侵入性方法（FC-DLIF），用于从小动物动态PET成像中预测动脉输入函数，避免了传统血液采样的复杂性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的小动物动态PET研究中，动脉输入函数的准确估计依赖于复杂的动脉血液采样，这不仅耗时且具有侵入性，限制了纵向研究的开展。因此，需要一种非侵入性的替代方法。

研究方法: 提出的FC-DLIF模型包括空间特征提取器和时间特征提取器，前者从PET序列的体素时间帧中提取空间特征，后者进一步处理这些特征以预测动脉输入函数。模型通过交叉验证在[$^{18}$F]FDG数据上进行训练和评估，并扩展到其他两种放射性示踪剂（[$^{18}$F]FDOPA和[$^{68}$Ga]PSMA）的数据。

研究结果: FC-DLIF模型能够可靠地预测动脉输入函数，表现出较低的均方误差和高相关性。此外，模型对时间截断和偏移的数据也表现出鲁棒性，但无法预测训练数据中未包含的其他放射性示踪剂的输入函数。

研究结论: FC-DLIF模型为动态小动物PET研究提供了一种非侵入性且可靠的动脉输入函数预测方法，适用于不同扫描时长和时间偏移的情况，但需进一步扩展以支持更多示踪剂。

中文摘要: 动态正电子发射断层扫描（PET）和动力学建模在小动物示踪剂开发研究中至关重要。准确的动力学建模需要精确的输入函数估计，传统上通过动脉血液采样实现。然而，小鼠等小动物的动脉插管操作复杂、耗时且具有终止性，无法用于纵向研究。本文提出了一种非侵入性的全卷积深度学习方法（FC-DLIF），直接从PET成像中预测输入函数，可能消除动态小动物PET中血液采样的需求。FC-DLIF模型包含一个作用于PET序列体素时间帧的空间特征提取器，提取空间特征，随后通过时间特征提取器进一步处理以预测动脉输入函数。该方法使用[$^{18}$F]FDG数据的图像和动脉血液曲线通过交叉验证进行训练和评估，并进一步在两种其他放射性示踪剂（[$^{18}$F]FDOPA和[$^{68}$Ga]PSMA）的数据上进行适用性评估。模型还对时间截断和偏移的数据进行了评估，以模拟更短和偏移的PET扫描。FC-DLIF模型在均方误差和相关性方面可靠地预测了动脉输入函数，且能够从截断和偏移的样本中预测输入函数。然而，模型无法预测训练数据中未包含的其他放射性示踪剂的输入函数。这种基于深度学习的输入函数预测方法为非侵入性和可靠的动脉血液采样提供了替代方案，表现出对时间偏移和不同扫描时长的鲁棒性和灵活性。

</details>


### [147] [3D Heart Reconstruction from Sparse Pose-agnostic 2D Echocardiographic Slices](https://arxiv.org/abs/2507.02411)
**中文标题：从稀疏姿态无关的2D超声心动图切片重建3D心脏**

*Zhurong Chen,Jinhua Chen,Wei Zhuo,Wufeng Xue,Dong Ni*

主要分类: eess.IV

摘要简述: 本文提出了一种从稀疏且姿态无关的2D超声心动图切片重建个性化3D心脏解剖结构的创新框架，显著提升了左心室容积估计的准确性，并首次实现了从2D切片估计右心室容积。


<details>
  <summary>详细信息</summary>
研究动机: 超声心动图在心脏病临床实践中不可或缺，但传统2D图像难以准确估计临床参数（如左心室容积），而3D超声成像又受限于低分辨率和繁琐的手动标注。因此，需要一种高效且准确的3D重建方法。

研究方法: 设计了一种新颖的3D重建流程，通过交替优化2D切片的3D姿态估计和基于隐式神经网络的3D切片整合，逐步将先验的3D心脏形状转化为个性化3D模型。

研究结果: 实验验证表明，使用六个平面时，3D重建心脏显著优于双平面方法（左心室容积误差：1.98% vs. 20.24%），并首次实现了从2D切片估计右心室容积（误差为5.75%）。

研究结论: 该研究为心脏超声的个性化3D结构和功能分析提供了新方法，具有重要的临床应用潜力。

中文摘要: 超声心动图（echo）在心脏病临床实践中扮演着不可或缺的角色。然而，超声成像通常仅提供来自少数特定视角的二维（2D）横截面图像，这使得临床参数（如左心室容积）的估计变得困难且不准确。3D超声成像为3D量化提供了替代方案，但仍受限于低空间和时间分辨率以及高度依赖的手动标注。

为解决这些问题，我们提出了一种创新框架，用于从临床常用的2D超声切片重建个性化3D心脏解剖结构。具体而言，设计了一种新颖的3D重建流程，通过交替优化这些2D切片的3D姿态估计和基于隐式神经网络的3D切片整合，逐步将先验的3D心脏形状转化为个性化3D模型。

我们在两个数据集上验证了该方法。当使用六个平面时，重建的3D心脏在左心室容积估计上显著优于双平面方法（误差百分比：1.98% vs. 20.24%）。此外，整个重建框架还实现了重要突破，能够从2D超声切片估计右心室容积（误差为5.75%）。本研究为心脏超声的个性化3D结构和功能分析提供了新途径，具有重要的临床应用潜力。

</details>


### [148] [MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection](https://arxiv.org/abs/2507.02668)
**中文标题：MEGANet-W：一种基于小波的边缘引导注意力框架用于弱边界息肉检测**

*Zhe Yee Tan*

主要分类: eess.IV

摘要简述: MEGANet-W是一种基于小波的边缘引导注意力框架，用于弱边界息肉检测，通过注入无参数的Haar小波边缘图提升分割精度，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 结直肠息肉分割对早期癌症检测至关重要，但弱边界和低对比度限制了自动化精度。现有方法要么模糊边缘细节，要么依赖手工滤波器，在多变成像条件下表现不佳。

研究方法: 提出MEGANet-W，结合Haar小波边缘图与解码器阶段，通过两级Haar小波头提取多方向边缘，并设计WEGA模块融合小波线索与反向输入分支。

研究结果: 在五个公共息肉数据集上，MEGANet-W显著优于现有方法，mIoU提升2.3%，mDice提升1.2%，且未引入额外可学习参数。

研究结论: MEGANet-W通过小波驱动的边缘引导注意力机制，显著提升了弱边界息肉的分割性能，为自动化检测提供了高效解决方案。

中文摘要: 结直肠息肉分割对早期结直肠癌检测至关重要，但弱边界和低对比度显著限制了自动化精度。现有深度模型要么模糊边缘细节，要么依赖手工滤波器，在多变成像条件下表现不佳。我们提出MEGANet-W，一种基于Haar小波的边缘引导注意力网络，通过在每个解码器阶段注入无参数的小波边缘图来重新校准语义特征。我们的两大贡献是：(1) 用于多方向边缘提取的两级Haar小波头；(2) 融合小波线索与反向输入分支的WEGA模块。在五个公共息肉数据集上，MEGANet-W始终优于现有方法，mIoU提升高达2.3%，mDice提升1.2%，且未引入额外可学习参数。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [149] [Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features](https://arxiv.org/abs/2507.01984)
**中文标题：基于语言、视觉和社交特征早期融合的多模态虚假信息检测**

*Gautam Kishore Shahi*

主要分类: cs.LG

摘要简述: 本研究探讨了结合文本、图像和社交特征的多模态特征组合在检测社交媒体虚假信息中的有效性，结果显示多模态模型比单模态和双模态模型性能提升显著。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体在选举和危机期间充斥着大量虚假信息，现有研究多集中于文本或图像的单模态检测，而多模态特征组合的研究较少。本研究旨在填补这一空白。

研究方法: 研究采用早期融合方法，结合文本、图像和社交特征，对1529条包含文本和图像的推文进行分析，并通过数据增强提取视觉和社交特征。

研究结果: 结果显示，结合无监督和监督机器学习模型的多模态方法比单模态模型性能提升15%，比双模态模型提升5%。同时分析了虚假信息的传播模式。

研究结论: 多模态特征组合在虚假信息检测中表现更优，为未来研究提供了新方向。

中文摘要: 在选举和危机期间，社交媒体上充斥着大量虚假信息，现有研究主要集中在基于文本或图像的虚假信息检测上，而关于多模态特征组合（如结合文本和图像构建分类模型）的研究较少。本研究探讨了不同多模态特征组合的有效性，采用早期融合方法结合文本、图像和社交特征构建分类模型。研究分析了从Twitter（现为X）收集的1529条包含文本和图像的推文，这些推文涉及COVID-19大流行和选举期间。通过数据增强过程，利用目标检测和光学字符识别（OCR）等技术提取额外的社交特征和视觉特征。结果表明，结合无监督和监督机器学习模型的多模态方法比单模态模型性能提升15%，比双模态模型提升5%。此外，研究还基于虚假信息推文及其传播用户的特征分析了虚假信息的传播模式。

</details>


### [150] [Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions](https://arxiv.org/abs/2507.02087)
**中文标题：评估大型语言模型在招聘决策中的潜力与陷阱**

*Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia*

主要分类: cs.LG

摘要简述: 本文评估了大型语言模型（LLMs）在招聘决策中的潜力与风险，发现专用招聘模型Match Score在准确性和公平性上均优于通用LLMs，强调在高风险领域需结合领域专用建模和偏见审核。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在招聘中能简化候选人筛选，但其潜在的准确性和算法偏见问题引发担忧。本研究旨在比较通用LLMs与专用招聘模型的性能，探讨如何在高风险领域平衡准确性与公平性。

研究方法: 研究对多个前沿LLMs（如OpenAI、Anthropic、Google等）与专用招聘模型Match Score进行对比，评估其预测准确性（如ROC AUC、F1分数）和公平性（如不同性别、种族及交叉群体的影响比例）。实验基于约10,000个真实候选人-职位对数据。

研究结果: Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（种族影响比例最低0.957 vs LLMs的0.809或更低）上均显著优于通用LLMs。研究指出，预训练偏见可能导致LLMs传播社会偏见，而专用模型能更有效缓解这一问题。

研究结论: 研究强调在高风险招聘领域需采用领域专用建模和偏见审核，避免直接使用未经充分公平性保障的通用LLMs。同时证明，通过合理设计，算法可同时实现高准确性和公平性。

中文摘要: 大型语言模型（LLMs）在招聘中的应用有望简化候选人筛选，但若缺乏充分保障，其准确性和算法偏见问题可能引发严重担忧。本研究对多个前沿LLMs（包括OpenAI、Anthropic、Google、Meta和Deepseek的模型）与专用招聘模型Match Score进行对比，评估其预测准确性（如ROC AUC、Precision-Recall AUC、F1分数）和公平性（如性别、种族及交叉群体的影响比例）。基于约10,000个真实候选人-职位对的实验显示，Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（种族影响比例最低0.957 vs LLMs的0.809或更低）上均优于通用LLMs。研究表明，预训练偏见可能导致LLMs传播社会偏见，而专用监督模型能更有效缓解这些偏见。研究结果凸显了在高风险招聘领域采用领域专用建模和偏见审核的重要性，并警示在缺乏充分公平性保障时避免直接使用通用LLMs。此外，实证表明，招聘中准确性与公平性并非对立，合理设计的算法可同时实现两者。

</details>


### [151] [Energy-Based Transformers are Scalable Learners and Thinkers](https://arxiv.org/abs/2507.02092)
**中文标题：基于能量的Transformer是可扩展的学习者与思考者**

*Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal*

主要分类: cs.LG

摘要简述: 本文提出了一种新型的基于能量的Transformer模型（EBTs），通过无监督学习实现输入与候选预测的兼容性验证，并通过能量最小化进行预测。EBTs在训练和推理阶段均表现出色，优于现有方法，尤其在泛化能力上表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 现有推理时计算技术（类似人类System 2思维）存在局限性，如仅适用于特定模态或问题，或需要额外监督训练。本文旨在探索是否可以通过无监督学习实现通用的System 2思维模型。

研究方法: 提出基于能量的Transformer（EBTs），通过学习输入与候选预测对的能量值，通过梯度下降能量最小化进行预测。该方法适用于离散（文本）和连续（视觉）模态。

研究结果: EBTs在训练中比主流Transformer++方法扩展更快，数据、批量大小、参数等指标上扩展率提高35%。推理时，EBTs在语言任务上性能提升29%，图像去噪任务上优于扩散Transformer且计算量更少。

研究结论: EBTs是一种有前景的新范式，能够同时提升模型的学习和思维能力，泛化能力优于现有方法。

中文摘要: 推理时计算技术（类似人类System 2思维）近年来因提升模型性能而流行，但现有方法存在局限性：仅适用于特定模态（如文本）、特定问题（如数学和编程等可验证领域），或需在无监督预训练基础上额外监督训练（如验证器或可验证奖励）。本文探讨是否可推广System 2思维方法，开发仅通过无监督学习实现思考的模型。有趣的是，我们发现答案是肯定的，通过学习显式验证输入与候选预测的兼容性，并将预测问题重新定义为基于验证器的优化。具体而言，我们训练基于能量的Transformer（EBTs）——一种新型基于能量的模型（EBMs）——为每对输入和候选预测分配能量值，通过梯度下降能量最小化直至收敛进行预测。在离散（文本）和连续（视觉）模态中，EBTs在训练中比主流Transformer++方法扩展更快，数据、批量大小、参数、FLOPs和深度上扩展率提高35%。推理时，EBTs在语言任务上通过System 2思维性能提升29%，图像去噪任务上优于扩散Transformer且计算量更少。此外，EBTs在相同或更差预训练性能下，多数下游任务表现优于现有模型，表明EBTs泛化能力更强。因此，EBTs是一种有前景的新范式，可同时扩展模型的学习和思维能力。

</details>


### [152] [Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows](https://arxiv.org/abs/2507.01975)
**中文标题：可学习可微分有限体积求解器用于加速流体流动模拟**

*Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun*

主要分类: cs.LG

摘要简述: 本文提出了一种可学习且可微分的有限体积求解器LDSolver，用于在粗网格上高效准确地模拟流体流动。该方法结合了可微分求解器和可学习模块，显著提升了计算效率，并在多种流动系统中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 流体流动模拟在气象学、空气动力学和生物医学等领域至关重要，但传统数值求解器计算成本高，而机器学习方法存在可解释性、泛化性和数据依赖性问题。因此，本文旨在开发一种兼具高效性和准确性的新方法。

研究方法: LDSolver包含两部分：1）可微分有限体积求解器；2）可学习模块，用于在粗网格上提供等效通量近似和时间误差校正。该方法在少量训练数据下即可实现高效模拟。

研究结果: 实验表明，LDSolver在多种流动系统（如Burgers、衰减、受迫和剪切流动）中表现优异，显著超越基线模型，并展现出卓越的泛化能力。

研究结论: LDSolver通过结合可微分求解器和可学习模块，在粗网格上实现了高效且高精度的流体模拟，为复杂流动系统的快速建模提供了新思路。

中文摘要: 流体流动模拟对于气象学、空气动力学和生物医学等物理现象的建模至关重要。传统数值求解器通常需要精细的时空网格以满足稳定性、一致性和收敛性条件，导致计算成本高昂。尽管机器学习方法表现出更高的效率，但通常存在可解释性、泛化性和数据依赖性问题。因此，我们提出了一种可学习且可微分的有限体积求解器LDSolver，用于在粗时空网格上高效准确地模拟流体流动。LDSolver包含两个关键组件：1）可微分有限体积求解器；2）可学习模块，用于在粗网格上提供等效通量近似（导数和插值）和时间误差校正。即使在有限训练数据（如仅几条轨迹）下，我们的模型也能在保持高精度的同时加速模拟，并展现出卓越的泛化能力。在不同流动系统（如Burgers、衰减、受迫和剪切流动）上的实验表明，LDSolver实现了最先进的性能，显著超越基线模型。

</details>


### [153] [DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism](https://arxiv.org/abs/2507.01982)
**中文标题：DKGCM：一种融合空间节点聚类方法和傅里叶双向Mamba机制的交通流时空预测模型**

*Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai*

主要分类: cs.LG

摘要简述: 提出了一种名为DKGCM的新型图卷积网络结构，通过动态时间规整和K均值聚类对交通节点分组，结合傅里叶变换和双向Mamba框架捕捉时空依赖关系，显著提升了交通需求预测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 交通需求预测的准确性对资源分配效率至关重要，但复杂的时空关系限制了现有模型的性能。因此，需要一种更有效的方法来捕捉交通系统中的时空依赖关系。

研究方法: 1. 提出基于时间相似性的聚类图卷积方法DK-GCN，利用动态时间规整和K均值聚类分组交通节点；2. 在时间尺度上，结合快速傅里叶变换和双向Mamba框架捕捉时间依赖；3. 引入GRPO强化学习策略优化模型训练。

研究结果: 在三个公开数据集上的实验表明，DKGCM模型优于多种先进方法，显著提升了交通需求预测的准确性。

研究结论: DKGCM通过融合空间节点聚类和傅里叶双向Mamba机制，有效捕捉了交通系统中的时空依赖关系，为交通需求预测提供了高效解决方案。

中文摘要: 准确的交通需求预测能够帮助交通管理部门更有效地分配资源，从而提高资源利用效率。然而，交通系统中复杂的时空关系仍然限制了需求预测模型的性能。为了提升时空交通需求预测的准确性，我们提出了一种名为DKGCM的新型图卷积网络结构。具体而言，我们首先考虑了不同交通节点的空间流量分布，并提出了一种基于时间相似性的聚类图卷积方法DK-GCN。该方法利用动态时间规整（DTW）和K均值聚类对交通节点进行分组，以更有效地捕捉空间依赖关系。在时间尺度上，我们将快速傅里叶变换（FFT）整合到双向Mamba深度学习框架中，以捕捉交通需求的时间依赖性。为了进一步优化模型训练，我们引入了GRPO强化学习策略以增强损失函数的反馈机制。大量实验表明，我们的模型在三个公开数据集上优于多种先进方法，并取得了显著的效果。

</details>


### [154] [OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding](https://arxiv.org/abs/2507.02659)
**中文标题：OmniDraft：一种跨词汇、在线自适应的设备端推测解码草稿模型**

*Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang*

主要分类: cs.LG

摘要简述: OmniDraft提出了一种跨词汇、在线自适应的草稿模型框架，解决了传统推测解码中草稿模型与目标模型不兼容及延迟优化的问题，适用于设备端LLM应用。


<details>
  <summary>详细信息</summary>
研究动机: 传统推测解码需要草稿模型与目标模型兼容且离线训练，但在线部署时面临跨词汇不匹配和延迟优化挑战。本文旨在解决这些问题，实现一个通用草稿模型框架。

研究方法: OmniDraft结合在线n-gram缓存和混合蒸馏微调技术，解决跨词汇不匹配问题，并通过自适应草拟技术提升解码速度。

研究结果: 实验表明，OmniDraft使单个Llama-68M模型能与多种目标模型（如Vicuna-7B、Qwen2-7B等）配对，解码速度提升1.5-2倍。

研究结论: OmniDraft为设备端LLM应用提供了一种高效、通用的草稿模型解决方案，实现了“一模型适配多目标”的范式。

中文摘要: 推测解码通常需要一个离线预训练或蒸馏的小型高效草稿模型，以适配特定目标模型系列（如Llama或Qwen模型）。然而，在线部署时面临两大挑战：1）目标模型与草稿模型不兼容；2）需随时间优化延迟。本文提出OmniDraft，一个统一框架，使单个草稿模型能与任何目标模型配合，并动态适应用户数据。通过引入在线n-gram缓存和混合蒸馏微调，解决了草稿与目标模型间的跨词汇不匹配问题，并利用自适应草拟技术进一步提升解码速度。OmniDraft特别适用于设备端LLM应用，其中模型成本、效率和用户定制是关键问题。这凸显了解决上述挑战的必要性，并推动了“一草稿模型适配所有”的范式。通过在数学推理、代码生成和文本生成任务上进行在线学习，展示了OmniDraft的卓越性能。值得注意的是，OmniDraft使单个Llama-68M模型能与Vicuna-7B、Qwen2-7B和Llama3-8B等多种目标模型配对进行推测解码，并提供高达1.5-2倍的加速效果。

</details>


### [155] [ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning](https://arxiv.org/abs/2507.02834)
**中文标题：ExPO：通过自我解释引导的强化学习解锁复杂推理**

*Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ExPO的自我解释策略优化框架，通过结合真实答案生成高质量样本，以解决强化学习后训练中模型难以探索新推理轨迹的问题，显著提升了在复杂推理任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于强化学习的后训练方法依赖模型初始生成的正样本，难以解决模型初始失败的复杂推理任务。ExPO旨在通过生成与当前策略一致且能提高正确预测概率的样本，突破这一限制。

研究方法: ExPO通过结合真实答案生成高质量样本，这些样本既符合当前策略，又能提高模型预测正确的概率。该方法避免了专家演示的无效性，提供了一种模块化且高效的探索机制。

研究结果: 实验表明，ExPO在MATH level-5等复杂推理任务中显著提升了学习效率和最终性能，优于基于专家演示的方法。

研究结论: ExPO通过自我解释策略优化，有效解决了强化学习后训练中的探索难题，为复杂推理任务提供了一种高效解决方案。

中文摘要: 近年来，大型语言模型的进步主要依赖于强化学习（RL）风格的后训练，该方法通过基于奖励或偏好信号优化模型输出来提升推理能力。GRPO风格的方法通过使用基于结果的验证器标记的自生成样本来实现这一点。然而，这些方法高度依赖模型初始生成正样本的能力，主要优化模型已知的内容（分布锐化），而非解决模型初始失败的复杂推理任务。这一限制在早期RL训练和复杂推理任务中尤为明显，因为正样本难以生成。为了解锁此类任务中的推理能力，模型需要探索超出当前输出分布的新推理轨迹。这种探索需要足够高质量的正样本来指导学习。虽然专家演示似乎是自然的解决方案，但我们发现它们在RL后训练中往往无效。相反，我们确定了有效正样本的两个关键特性：（1）在当前策略下具有高可能性，（2）能提高模型预测正确答案的概率。基于这些见解，我们提出了自我解释策略优化（ExPO）——一种简单且模块化的框架，通过结合真实答案生成此类样本。ExPO实现了高效探索，并引导模型生成比专家编写的思维链更符合其策略的推理轨迹，同时确保比其自身（错误）样本更高的质量。实验表明，ExPO在推理基准测试中提升了学习效率和最终性能，在模型初始表现最差的MATH level-5等复杂任务中超越了基于专家演示的方法。

</details>


### [156] [GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters](https://arxiv.org/abs/2507.02085)
**中文标题：GeoAda：利用等变适配器高效微调几何扩散模型**

*Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon*

主要分类: cs.LG

摘要简述: GeoAda是一种高效的SE(3)-等变适配器框架，用于几何扩散模型的下游任务微调，保持几何一致性并避免过拟合和灾难性遗忘。


<details>
  <summary>详细信息</summary>
研究动机: 几何扩散模型在分子动力学和结构生成中表现出色，但如何高效地针对不同几何控制任务进行微调仍未被充分研究。

研究方法: GeoAda通过引入结构化适配器设计，包括耦合操作符编码控制信号、可训练层处理信号、解耦操作符和零初始化卷积，仅微调轻量级适配器模块。

研究结果: GeoAda在多种几何控制任务（如分子动力学、粒子动力学等）中表现优异，保持原始任务准确性，而其他基线方法因过拟合和灾难性遗忘性能显著下降。

研究结论: GeoAda提供了一种高效且参数节约的微调方法，适用于广泛的几何控制任务，同时保持模型的几何一致性。

中文摘要: 几何扩散模型在分子动力学和结构生成中取得了显著成功，但如何高效地针对下游任务进行微调仍未被充分探索。本文提出了一种SE(3)-等变适配器框架（GeoAda），能够在不改动原始模型架构的情况下，灵活且参数高效地完成可控生成任务的微调。GeoAda采用结构化适配器设计：控制信号首先通过耦合操作符编码，随后由预训练模型层的可训练副本处理，最后通过解耦操作符和等变零初始化卷积投影回原空间。仅微调这些轻量级适配器模块，GeoAda既保持了模型的几何一致性，又避免了过拟合和灾难性遗忘。理论证明，所提出的适配器保持了SE(3)-等变性，确保预训练扩散模型的几何归纳偏置在适应过程中不受影响。GeoAda在多种几何控制类型（如框架控制、全局控制、子图控制）和广泛应用领域（如粒子动力学、分子动力学、人体运动预测、分子生成）中展现了广泛的适用性。实验结果表明，GeoAda在保持原始任务准确性的同时，实现了最先进的微调性能，而其他基线方法因过拟合和灾难性遗忘导致性能显著下降。

</details>


### [157] [Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies](https://arxiv.org/abs/2507.02244)
**中文标题：竞争压力下的订单获取：一种快速自适应的强化学习方法用于网约车补贴策略**

*Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于强化学习的快速自适应补贴策略框架FCA-RL，用于优化网约车平台的订单获取。通过快速竞争适应（FCA）和强化拉格朗日调整（RLA）技术，结合RideGym仿真环境，实验证明该方法在多种市场条件下优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 网约车聚合平台的竞争排名机制促使服务提供商通过补贴策略降低价格以获取更多订单。然而，现有研究稀缺，如何在预算约束下动态适应市场波动并优化订单获取成为关键挑战。

研究方法: 提出FCA-RL框架，结合快速竞争适应（FCA）和强化拉格朗日调整（RLA）技术，并开发RideGym仿真环境，用于评估和优化补贴策略。

研究结果: 实验结果表明，FCA-RL在多种市场条件下均优于基线方法，有效优化了网约车服务提供商的补贴策略。

研究结论: FCA-RL框架通过快速自适应和预算约束优化，显著提升了网约车平台的订单获取效率，为相关领域研究提供了新思路。

中文摘要: 网约车聚合平台的普及为服务提供商带来了订单量和总交易额（GMV）的增长机会。在大多数平台上，提供更低价格的服务商排名更高，从而更容易被乘客选择。这种竞争排名机制促使服务商采用补贴策略以降低价格并获取更多订单，因为订单量直接影响其长期生存能力。因此，设计一种能够在预算约束下动态适应市场波动并优化订单获取的有效补贴策略成为关键研究挑战，但现有研究仍较少。

为填补这一空白，我们提出了FCA-RL，一种基于强化学习的补贴策略框架，能够快速适应竞争对手的价格调整。该方法结合了两种关键技术：快速竞争适应（FCA）和强化拉格朗日调整（RLA）。FCA能够快速响应动态价格变化，而RLA则确保在优化新价格环境下的补贴决策时遵守预算约束。此外，我们开发了RideGym，首个专为网约车聚合平台设计的仿真环境，可在不影响实际运营效率的情况下全面评估和比较不同定价策略。实验结果表明，我们提出的方法在多种市场条件下均优于基线方法，突显了其在网约车服务提供商补贴优化中的有效性。

</details>


### [158] [Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications](https://arxiv.org/abs/2507.02291)
**中文标题：基于知识图谱的可解释与泛化零样本语义通信**

*Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu*

主要分类: cs.LG

摘要简述: 提出了一种基于知识图谱的零样本语义通信网络（KGZS-SC），通过知识图谱增强语义表示和推理能力，显著提升对未见数据的分类性能，并减少通信开销。


<details>
  <summary>详细信息</summary>
研究动机: 传统数据驱动的语义通信缺乏可解释性和泛化能力，尤其在面对未见数据时表现不佳。本文旨在通过知识图谱解决这些问题，提升语义通信的适应性和效率。

研究方法: 利用知识图谱语义知识库（KG-SKB）对齐语义特征，生成共享类别语义嵌入空间，增强发射端的泛化能力，并通过选择性传输紧凑视觉语义减少通信开销。接收端采用零样本学习（ZSL）直接分类未见数据，无需重新训练。

研究结果: 在APY数据集上的实验表明，KGZS-SC网络在多种信噪比条件下对未见类别的分类性能显著优于现有语义通信框架，并展现出强大的泛化能力。

研究结论: KGZS-SC网络通过知识图谱和零样本学习的结合，有效解决了语义通信中的泛化和效率问题，为动态或资源受限环境提供了高效解决方案。

中文摘要: 数据驱动的语义通信依赖于表面统计模式，缺乏可解释性和泛化能力，尤其是在面对未见数据时表现不佳。为解决这些问题，我们提出了一种基于知识图谱增强的零样本语义通信（KGZS-SC）网络。通过知识图谱语义知识库（KG-SKB）的结构化语义信息引导，我们的方案提供了泛化的语义表示，并支持对未见案例的推理。具体而言，KG-SKB将语义特征对齐到共享类别语义嵌入空间，并通过对齐的语义特征增强发射端的泛化能力，从而通过选择性传输紧凑视觉语义减少通信开销。在接收端，利用零样本学习（ZSL）直接分类未见案例，无需重新训练或额外计算开销，从而提升了动态或资源受限环境中分类过程的适应性和效率。在APY数据集上的仿真结果表明，所提出的KGZS-SC网络展现出强大的泛化能力，并在多种信噪比条件下对未见类别的分类性能显著优于现有语义通信框架。

</details>


### [159] [Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment](https://arxiv.org/abs/2507.02310)
**中文标题：概念漂移下的自适应记忆对齐全面持续学习**

*Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk*

主要分类: cs.LG

摘要简述: 本文提出了一种针对概念漂移的全面持续学习框架，通过自适应记忆对齐（AMR）机制，在动态数据流中高效平衡知识保留与快速适应。


<details>
  <summary>详细信息</summary>
研究动机: 传统持续学习方法假设数据分布静态，忽视了现实世界中概念漂移的动态性。本文旨在解决这一局限，提出一种既能保持稳定性又能快速适应变化的框架。

研究方法: 提出自适应记忆对齐（AMR）方法，通过选择性移除过时样本并补充最新实例，重新对齐记忆缓冲区，以轻量级方式匹配完全重新学习（FR）的性能。

研究结果: 在多个概念漂移变体数据集上的实验表明，AMR能有效应对概念漂移，保持高准确性且计算开销极低。

研究结论: AMR是一种可扩展的解决方案，在非静态持续学习环境中平衡了稳定性与可塑性。

中文摘要: 传统持续学习方法侧重于知识保留，主要解决灾难性遗忘问题，隐含假设先前学习任务的数据分布是静态的。然而，现实世界的数据流具有动态性，概念漂移会永久改变已见数据，要求模型兼具稳定性和快速适应性。

本文提出了一种针对概念漂移的全面持续学习框架，通过模拟任务分布的演变来反映真实场景。作为基线，我们考虑了完全重新学习（FR），即在新漂移分布上从头训练模型。虽然有效，但这种方法需要大量标注和计算资源。为解决这些限制，我们提出了自适应记忆对齐（AMR），一种轻量级替代方案，为基于回放的学习者配备漂移感知适应机制。AMR选择性移除回放缓冲区中漂移类别的过时样本，并用少量最新实例重新填充，有效将记忆与新分布对齐。这种针对性重采样在性能上匹配FR，同时将标注数据和计算需求降低数个数量级。

为支持可重复评估，我们引入了四个标准视觉基准的概念漂移变体：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD和Tiny-ImageNet-CD，其中已见类别以漂移后的表征重新出现。在这些数据集上使用多种基于回放的基线进行的全面实验表明，AMR能持续应对概念漂移，以极低开销保持高准确性。这些结果将AMR定位为一种可扩展的解决方案，在非静态持续学习环境中平衡了稳定性与可塑性。

</details>


### [160] [DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values](https://arxiv.org/abs/2507.02342)
**中文标题：DeltaSHAP：利用Shapley值解释在线患者监测中的预测演变**

*Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang*

主要分类: cs.LG

摘要简述: DeltaSHAP是一种新型可解释人工智能算法，专为在线患者监测系统设计，通过Shapley值解释预测变化，满足临床时间序列解释的独特需求，并在实验中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在临床环境中，及时了解患者风险变化的原因至关重要，但现有可解释AI方法无法满足临床时间序列解释的独特需求。DeltaSHAP旨在解决这一问题。

研究方法: DeltaSHAP通过调整Shapley值以适应时间序列设置，捕捉特征组合效应，并仅使用实际观察到的特征组合解释预测变化，同时提供特征归因的大小和方向。

研究结果: 在MIMIC-III基准测试中，DeltaSHAP在解释质量上优于现有方法62%，计算效率提高33%。

研究结论: DeltaSHAP为在线患者监测提供了一种高效且实用的解释方法，满足了临床需求，并在实验中验证了其优越性。

中文摘要: 本研究提出DeltaSHAP，一种专为在线患者监测系统设计的新型可解释人工智能（XAI）算法。在临床环境中，发现驱动患者风险演变的原因对及时干预至关重要，但现有XAI方法无法满足临床时间序列解释的独特需求。为此，DeltaSHAP解决了三个关键临床需求：解释连续预测的变化而非孤立预测分数，提供特征归因的大小和方向，并实时提供这些见解。通过将Shapley值调整到时间序列设置中，我们的方法准确捕捉了特征组合效应。它仅使用实际观察到的特征组合解释预测变化，使其在时间敏感的临床应用中高效且实用。我们还引入了新的评估指标，用于评估在线时间序列归因的忠实性，并通过在线患者监测任务的实验证明，DeltaSHAP在MIMIC-III基准测试中，解释质量优于现有XAI方法62%，计算效率提高33%。代码发布于https://github.com/AITRICS/DeltaSHAP。

</details>


### [161] [Offline Reinforcement Learning with Penalized Action Noise Injection](https://arxiv.org/abs/2507.02356)
**中文标题：基于惩罚性动作噪声注入的离线强化学习**

*JunHyeok Oh,Byung-Jun Lee*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PANI（惩罚性动作噪声注入）的方法，通过注入噪声动作覆盖整个动作空间，同时根据噪声量进行惩罚，从而提升离线强化学习的性能。该方法兼容多种现有算法，并在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 离线强化学习（RL）仅使用固定数据集优化策略，适用于环境交互成本高的场景。尽管扩散模型在此领域表现出色，但其计算成本较高。本文旨在探索一种更简单高效的方法，以提升离线RL的性能。

研究方法: 提出PANI方法，通过注入噪声动作扩展动作空间，并根据噪声量进行惩罚。理论证明该方法解决了称为“噪声动作MDP”的修改版马尔可夫决策过程。PANI兼容多种现有离线RL算法。

研究结果: 实验表明，PANI在多个基准测试中显著提升了离线RL算法的性能，尽管方法简单，但效果显著。

研究结论: PANI是一种简单有效的方法，通过噪声注入和惩罚机制显著提升离线RL性能，无需依赖高计算成本的扩散模型。

中文摘要: 离线强化学习（RL）仅使用固定数据集优化策略，适用于环境交互成本高的场景。由于这一限制，泛化能力对提升离线RL算法性能至关重要，扩散模型在此领域的成功也证明了这一点。然而，考虑到扩散模型在推理时的高计算需求，是否必须使用此类模型仍存疑问。本文提出惩罚性动作噪声注入（PANI），该方法通过注入噪声动作覆盖整个动作空间，同时根据噪声量进行惩罚，从而简单高效地提升离线学习性能。这一方法的灵感来源于扩散模型在离线RL算法中的应用。我们为该方法提供了理论基础，证明带有噪声动作的离线RL算法解决了一种称为“噪声动作MDP”的修改版马尔可夫决策过程。PANI兼容多种现有离线和离线RL算法，尽管方法简单，但在多个基准测试中表现出显著的性能提升。

</details>


### [162] [S2FGL: Spatial Spectral Federated Graph Learning](https://arxiv.org/abs/2507.02409)
**中文标题：S2FGL：空间频谱联邦图学习**

*Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye*

主要分类: cs.LG

摘要简述: 本文提出了一种名为S2FGL的框架，结合空间和频谱策略，解决了联邦图学习中的标签信号中断和频谱客户端漂移问题，显著提升了全局模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的联邦图学习研究仅从结构角度处理子图联邦学习，忽略了图信号在空间和频谱域的传播问题。空间上，子图联邦学习导致客户端间边连接中断，标签信号传播受阻；频谱上，频谱异质性导致子图间信号频率不一致，局部图神经网络过拟合本地信号传播模式。这些问题影响了全局模型的泛化能力。

研究方法: S2FGL框架通过构建全局知识库缓解标签信号中断问题，并通过频率对齐策略解决频谱客户端漂移问题。结合空间和频谱策略，提升全局图神经网络的性能。

研究结果: 在多个数据集上的实验表明，S2FGL框架显著优于现有方法，有效解决了标签信号中断和频谱客户端漂移问题，提升了模型的全局泛化能力。

研究结论: S2FGL框架通过空间和频谱策略的结合，成功解决了联邦图学习中的关键问题，为未来研究提供了新的方向。

中文摘要: 联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNNs）的强大图建模能力。当前研究仅从结构角度处理子图联邦学习，忽略了图信号在空间和频谱域的传播。从空间角度看，子图联邦学习导致客户端间边连接中断，标签信号传播受阻，全局GNN的类别知识退化。从频谱角度看，频谱异质性导致子图间信号频率不一致，局部GNN过拟合本地信号传播模式，从而引发频谱客户端漂移，削弱全局泛化能力。为解决这些问题，我们提出了一种全局知识库以缓解标签信号中断，并通过频率对齐策略解决频谱客户端漂移问题。空间和频谱策略的结合形成了我们的框架S2FGL。在多个数据集上的实验证明了S2FGL的优越性。代码可在https://github.com/Wonder7racer/S2FGL.git获取。

</details>


### [163] [Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction](https://arxiv.org/abs/2507.02129)
**中文标题：生成潜在扩散用于高效时空数据压缩**

*Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka*

主要分类: cs.LG

摘要简述: 本文提出了一种高效的潜在扩散框架，结合变分自编码器和条件扩散模型，仅压缩少量关键帧并通过生成插值重建其余帧，显著降低存储成本并实现高精度时空重建。


<details>
  <summary>详细信息</summary>
研究动机: 生成模型在数据压缩中表现优异，但其可控性和重建精度限制了实际应用。本文旨在通过潜在扩散框架解决这一问题，实现高效的数据压缩和重建。

研究方法: 方法结合变分自编码器和条件扩散模型，仅压缩少量关键帧到潜在空间，并将其作为条件输入，通过生成插值重建其余帧，避免存储每帧的潜在表示。

研究结果: 实验结果表明，该方法在多个数据集上实现了比基于规则的先进压缩器（如SZ3）高10倍的压缩比，并在相同重建误差下优于领先的学习方法63%。

研究结论: 本文提出的潜在扩散框架显著提高了数据压缩效率和重建精度，为时空数据的高效存储和重建提供了新思路。

中文摘要: 生成模型在条件设置下表现出色，可视为一种数据压缩形式，其中条件作为紧凑表示。然而，其有限的可控性和重建精度限制了其在数据压缩中的实际应用。本文提出了一种高效的潜在扩散框架，通过结合变分自编码器和条件扩散模型来填补这一空白。我们的方法仅将少量关键帧压缩到潜在空间，并将其作为条件输入，通过生成插值重建其余帧，无需存储每帧的潜在表示。这种方法在显著降低存储成本的同时实现了高精度的时空重建。在多个数据集上的实验结果表明，我们的方法比基于规则的先进压缩器（如SZ3）实现了高达10倍的压缩比，并在相同重建误差下优于领先的学习方法63%。

</details>


### [164] [Continual Gradient Low-Rank Projection Fine-Tuning for LLMs](https://arxiv.org/abs/2507.02503)
**中文标题：持续梯度低秩投影微调用于大型语言模型**

*Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GORP的新训练策略，通过结合全参数和低秩参数并在统一低秩梯度子空间中联合更新，解决了大型语言模型（LLMs）持续微调中效率与表达能力之间的权衡问题。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的持续微调面临效率与表达能力之间的权衡问题。低秩适应（LoRA）虽然高效，但由于其低秩特性和对显式参数约束的依赖，限制了模型学习新任务和迁移知识的能力。

研究方法: GORP（Gradient LOw Rank Projection）是一种新颖的训练策略，通过协同结合全参数和低秩参数，并在统一的低秩梯度子空间中联合更新，扩展了优化空间，同时保持了效率和减轻了灾难性遗忘。

研究结果: 在持续学习基准测试中，GORP表现出优于现有最先进方法的性能。

研究结论: GORP通过结合全参数和低秩参数的优势，提供了一种高效的持续学习解决方案，显著提升了模型在新任务上的表现和知识迁移能力。

中文摘要: 大型语言模型（LLMs）的持续微调受到效率与表达能力之间权衡的限制。低秩适应（LoRA）虽然高效，但由于其低秩特性和对显式参数约束的依赖，限制了模型学习新任务和迁移知识的能力。我们提出了GORP（Gradient LOw Rank Projection）持续学习策略，通过协同结合全参数和低秩参数，并在统一的低秩梯度子空间中联合更新，克服了这些限制。GORP扩展了优化空间，同时保持了效率并减轻了灾难性遗忘。在持续学习基准测试中，GORP表现出优于现有最先进方法的性能。代码可在https://github.com/Wcxwcxw/GORP获取。

</details>


### [165] [Position: A Theory of Deep Learning Must Include Compositional Sparsity](https://arxiv.org/abs/2507.02550)
**中文标题：位置：深度学习理论必须包含组合稀疏性**

*David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio*

主要分类: cs.LG

摘要简述: 本文认为深度神经网络（DNNs）的成功源于其能够利用目标函数的组合稀疏结构，即大多数实际相关函数可由少量低维输入的子函数组合而成。


<details>
  <summary>详细信息</summary>
研究动机: 探讨深度神经网络成功背后的基本原理，提出组合稀疏性是其关键因素，并强调这一特性在所有高效图灵可计算函数中普遍存在。

研究方法: 通过理论分析，论证DNNs能够利用目标函数的组合稀疏结构，即函数由少量低维子函数组合而成。

研究结果: 研究表明，组合稀疏性是DNNs成功的关键，且这一特性广泛存在于实际学习问题中。

研究结论: 深入理解组合稀疏性在深度学习中的作用，对构建全面的人工智能理论至关重要。

中文摘要: 过参数化的深度神经网络（DNNs）在众多高维领域中表现出色，超越了受维度灾难影响的传统浅层网络。然而，关于DNNs学习动态的基本原理仍存在许多未解之谜。在这篇立场论文中，我们认为DNNs的成功源于其能够利用目标函数的组合稀疏结构。具体而言，大多数实际相关函数可由少量子函数组合而成，且每个子函数仅依赖于输入的低维子集。我们证明这一特性为所有高效图灵可计算函数所共有，因此在当前学习问题中普遍存在。尽管在组合稀疏函数的背景下，关于近似和泛化的问题已有一些理论见解，但关于DNNs的可学习性和优化的关键问题仍未解决。全面理解组合稀疏性在深度学习中的作用，对于构建人工智能乃至通用智能的完整理论至关重要。

</details>


### [166] [L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation](https://arxiv.org/abs/2507.02619)
**中文标题：L-VAE：基于可学习β的变分自编码器用于解耦表示**

*Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural*

主要分类: cs.LG

摘要简述: 本文提出了一种名为L-VAE的新模型，通过学习损失函数的超参数和模型参数，动态平衡解耦表示和重构损失，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有β-VAE模型中的超参数β需要人工调整，限制了模型的灵活性。本文旨在通过自动学习超参数和模型参数，动态平衡解耦和重构损失，提升解耦表示的效果。

研究方法: L-VAE扩展了β-VAE，通过学习损失函数中各项的相对权重，动态调整解耦和重构损失的平衡。模型同时学习损失权重和架构参数，并添加正则化项以防止偏向某一损失。

研究结果: 实验表明，L-VAE在多个数据集（如dSprites、MPI3D-complex等）上表现优异，解耦指标优于或接近现有方法（如β-VAE、ControlVAE等）。在CelebA数据集上，L-VAE成功解耦了面部属性。

研究结论: L-VAE通过动态学习损失权重和模型参数，有效平衡了解耦和重构损失，显著提升了模型的解耦能力，为解耦表示学习提供了新思路。

中文摘要: 本文提出了一种名为可学习变分自编码器（L-VAE）的新模型，通过学习损失函数的超参数和模型参数，动态平衡解耦表示和重构损失。L-VAE可视为β-VAE的扩展，其中超参数β通过学习动态调整。L-VAE通过学习损失项的相对权重，解决了β-VAE中人工调整超参数的局限性。模型还添加了正则化项以防止偏向某一损失。实验分析表明，L-VAE在重构保真度和解耦潜在维度之间找到了有效平衡。与β-VAE、VAE、ControlVAE、DynamicVAE和σ-VAE在dSprites、MPI3D-complex、Falcor3D和Isaac3D等数据集上的比较显示，L-VAE在解耦指标上表现最佳或次佳。此外，在CelebA数据集上的定性实验证实了L-VAE在解耦面部属性上的成功。

</details>


### [167] [Fair Deepfake Detectors Can Generalize](https://arxiv.org/abs/2507.02645)
**中文标题：公平的深度伪造检测器可以泛化**

*Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli*

主要分类: cs.LG

摘要简述: 本文揭示了深度伪造检测模型中公平性与泛化性之间的因果关系，并提出了一种名为DAID的框架，通过数据重平衡和特征聚合实现公平且泛化的检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 深度伪造检测模型面临两大挑战：对未见操作的泛化能力和对不同人口群体的公平性。现有方法常显示这两者存在冲突，本文首次揭示并定义了公平性与泛化性之间的因果关系，旨在解决这一矛盾。

研究方法: 提出了DAID框架，包括两部分：1) 人口属性感知的数据重平衡，通过逆倾向加权和子群特征归一化消除分布偏差；2) 人口属性无关的特征聚合，使用新的对齐损失抑制敏感属性信号。

研究结果: 在三个跨域基准测试中，DAID在公平性和泛化性上均优于现有先进检测器，验证了其理论基础和实际效果。

研究结论: 通过控制混杂变量，公平性干预可以提升泛化能力，DAID框架为公平且泛化的深度伪造检测提供了有效解决方案。

中文摘要: 深度伪造检测模型面临两大关键挑战：对未见操作的泛化能力和不同人口群体间的公平性。然而，现有方法常显示这两者存在冲突，揭示了它们之间的权衡。本文首次揭示并正式定义了公平性与泛化性之间的因果关系。基于后门调整，我们表明通过控制混杂变量（数据分布和模型容量），公平性干预可以提升泛化能力。基于这一发现，我们提出了人口属性不敏感干预检测（DAID），一个即插即用的框架，包括：1) 人口属性感知的数据重平衡，采用逆倾向加权和子群特征归一化以消除分布偏差；2) 人口属性无关的特征聚合，使用新的对齐损失抑制敏感属性信号。在三个跨域基准测试中，DAID在公平性和泛化性上均优于多个先进检测器，验证了其理论基础和实际效果。

</details>


### [168] [Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs](https://arxiv.org/abs/2507.02671)
**中文标题：基于嵌入的联邦数据共享：通过差分隐私条件变分自编码器实现**

*Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig*

主要分类: cs.LG

摘要简述: 本文提出了一种基于嵌入的联邦数据共享方法，通过差分隐私条件变分自编码器（DP-CVAE）生成隐私保护的全局数据分布，支持多样化的下游任务，同时减少通信开销和计算冗余。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在医学影像领域取得了显著进展，但数据稀缺和隐私法规限制了其广泛应用。联邦学习虽然支持去中心化训练，但存在通信成本高和任务单一的问题。本文旨在通过差分隐私生成模型解决这些问题。

研究方法: 采用基础模型提取紧凑且信息丰富的嵌入，减少冗余和计算开销。客户端协作训练差分隐私条件变分自编码器（DP-CVAE），建模全局隐私感知数据分布，支持多样化下游任务。

研究结果: 实验验证表明，该方法在隐私保护、可扩展性和效率方面优于传统联邦学习分类器，同时生成的嵌入比差分隐私条件生成对抗网络（DP-CGAN）具有更高的保真度，且参数数量减少5倍。

研究结论: 本文提出的DP-CVAE方法在隐私保护、数据共享效率和任务多样性方面表现出色，为医学影像领域的深度学习应用提供了可行的解决方案。

中文摘要: 深度学习（DL）在医学影像领域带来了革命性变革，但其应用受到数据稀缺和隐私法规的限制，导致对多样化数据集的访问受限。联邦学习（FL）支持去中心化训练，但存在通信成本高且通常仅限于单一下游任务的问题，降低了灵活性。我们提出了一种通过差分隐私（DP）生成模型实现数据共享的方法。通过采用基础模型，我们提取紧凑且信息丰富的嵌入，减少冗余并降低计算开销。客户端协作训练差分隐私条件变分自编码器（DP-CVAE），建模全局隐私感知数据分布，支持多样化下游任务。我们的方法在多种特征提取器上进行了验证，提高了隐私性、可扩展性和效率，优于传统联邦学习分类器，同时确保差分隐私。此外，DP-CVAE生成的嵌入比DP-CGAN具有更高的保真度，且参数数量减少5倍。

</details>


### [169] [Fast and Simplex: 2-Simplicial Attention in Triton](https://arxiv.org/abs/2507.02754)
**中文标题：快速与单纯：Triton中的2-单纯形注意力**

*Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil*

主要分类: cs.LG

摘要简述: 本文提出了一种基于2-单纯形Transformer的架构，通过高效的Triton内核实现，将标准点积注意力推广为三线性函数。实验表明，该架构在固定token预算下，在数学、编程、推理和逻辑任务中优于标准Transformer。


<details>
  <summary>详细信息</summary>
研究动机: 随着现代大型语言模型越来越依赖海量互联网规模数据集，计算资源受限的假设逐渐失效。因此，需要设计更高效的架构以提升token效率。

研究方法: 研究采用2-单纯形Transformer架构，通过Triton内核实现高效的三线性注意力机制，替代传统的点积注意力。

研究结果: 实验证明，2-单纯形Transformer在固定token预算下，在数学、编程、推理和逻辑任务中表现优于标准Transformer，并改变了知识和推理任务的缩放定律指数。

研究结论: 2-单纯形Transformer通过提升token效率，为计算资源受限场景下的模型优化提供了新思路。

中文摘要: 近期研究表明，训练损失随模型规模和token数量呈幂律关系，而实现计算最优模型需要同时扩展模型规模和token数量。然而，这些缩放定律假设数据无限供应，且主要适用于计算受限场景。随着现代大型语言模型越来越依赖海量互联网规模数据集，计算受限的假设逐渐失效。这一变化凸显了对提升token效率的架构需求。
  本文研究了2-单纯形Transformer的使用，该架构通过高效的Triton内核实现，将标准点积注意力推广为三线性函数。实验表明，2-单纯形Transformer在固定token预算下，在数学、编程、推理和逻辑任务中表现优于标准Transformer。我们通过证明2-单纯形注意力改变了知识和推理任务的缩放定律指数，量化了这些优势。

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [170] [A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention](https://arxiv.org/abs/2507.00884)
**中文标题：一种基于线性张量化四边形注意力的可扩展且量子精确的生物分子力场基础模型**

*Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou*

主要分类: physics.chem-ph

摘要简述: 本文提出了一种名为LiTEN的新型等变神经网络，通过线性张量化的四边形注意力（TQA）高效建模三体和四体相互作用，解决了传统力场精度不足和量子力学方法计算成本高的问题。LiTEN-FF作为预训练模型，在多个数据集上表现优异，为生物分子模拟提供了高效且精确的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 生物分子模拟在疾病机制研究、药物发现和生物材料设计中至关重要，但现有方法存在局限性：经典力场精度不足，量子力学方法计算成本高，而基于AI的力场（AIFFs）在平衡多体建模复杂性、精度和速度方面存在挑战。本文旨在开发一种兼具高精度和高效性的新型力场模型。

研究方法: 本文提出LiTEN，一种基于线性张量化四边形注意力（TQA）的等变神经网络。TQA通过向量操作重新参数化高阶张量特征，避免了昂贵的球谐函数计算，从而以线性复杂度高效建模三体和四体相互作用。LiTEN-FF是基于LiTEN的预训练模型，使用nablaDFT数据集进行广泛化学泛化训练，并在SPICE数据集上微调以实现精确的溶剂化系统模拟。

研究结果: LiTEN在rMD17、MD22和Chignolin等数据集上实现了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持多种下游生物分子建模任务，如QM级构象搜索、几何优化和自由能面构建，且在大分子（约1000个原子）模拟中比MACE-OFF快10倍。

研究结论: 本文提出的LiTEN框架为复杂生物分子建模提供了物理基础且高效的解决方案，为药物发现及相关应用提供了多功能的基础模型。

中文摘要: 精确的原子级生物分子模拟对于疾病机制理解、药物发现和生物材料设计至关重要，但现有模拟方法存在显著局限性。经典力场效率高但缺乏对过渡态和精细构象细节的准确性，而这些细节在许多化学和生物过程中至关重要。量子力学（QM）方法精度高，但对于大规模或长时间模拟计算不可行。基于AI的力场（AIFFs）旨在实现QM级精度与效率的平衡，但在多体建模复杂性、精度和速度的平衡上存在困难，常受限于训练数据不足和泛化验证不充分。为克服这些挑战，我们提出LiTEN，一种新型等变神经网络，采用张量化四边形注意力（TQA）。TQA通过向量操作重新参数化高阶张量特征，避免了昂贵的球谐函数计算，从而以线性复杂度高效建模三体和四体相互作用。基于LiTEN，LiTEN-FF是一种稳健的AIFF基础模型，预训练于广泛的nablaDFT数据集以实现广泛的化学泛化，并在SPICE数据集上微调以实现精确的溶剂化系统模拟。LiTEN在rMD17、MD22和Chignolin的大多数评估子集上实现了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持迄今为止最全面的下游生物分子建模任务，包括QM级构象搜索、几何优化和自由能面构建，同时在大生物分子（约1000个原子）模拟中比MACE-OFF快10倍。总之，我们提出了一种物理基础且高效的框架，推动了复杂生物分子建模的发展，为药物发现及相关应用提供了多功能的基础。

</details>


### [171] [Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation](https://arxiv.org/abs/2507.02752)
**中文标题：设计可合成：一种逆合成引导的分子类似物生成框架**

*Shuan Chen,Gunwook Nam,Yousung Jung*

主要分类: physics.chem-ph

摘要简述: SynTwins是一种新型逆合成引导的分子类似物设计框架，通过模拟化学家策略生成可合成的分子类似物，解决了AI生成分子难以合成的问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI生成的分子虽然具有理想的性能，但其合成可行性成为计算药物和材料发现的关键瓶颈。SynTwins旨在填补这一空白，提供一种能够生成易于合成的分子类似物的方法。

研究方法: SynTwins采用三步法：逆合成分析、类似构建块搜索和虚拟合成，模拟化学家策略生成可合成的分子类似物。

研究结果: SynTwins在生成可合成类似物方面优于现有机器学习模型，同时保持与目标分子的高结构相似性。结合现有分子优化框架时，其生成的分子既具有理想性能又易于合成。

研究结论: SynTwins有效弥合了计算设计与实验合成之间的鸿沟，为加速发现具有理想性能且易于合成的分子提供了实用解决方案。

中文摘要: AI生成的分子与其合成可行性之间的脱节是计算药物和材料发现的关键瓶颈。虽然生成式AI加速了候选分子的提出，但许多结构难以通过现有化学反应合成。本文介绍SynTwins，一种新型逆合成引导的分子类似物设计框架，通过模拟化学家策略的三步过程（逆合成、类似构建块搜索和虚拟合成）设计可合成的分子类似物。在比较评估中，SynTwins在生成可合成类似物方面优于现有机器学习模型，同时保持与目标分子的高结构相似性。此外，当与现有分子优化框架结合时，我们的混合方法生成的分子既具有与无约束分子生成器相当的性能，又确保其可合成性。通过对多种分子数据集的全面测试，SynTwins有效弥合了计算设计与实验合成之间的鸿沟，为加速发现具有理想性能且易于合成的分子提供了实用解决方案。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [172] [DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment](https://arxiv.org/abs/2507.02768)
**中文标题：DeSTA2.5-Audio：迈向通用大型音频语言模型的自生成跨模态对齐**

*Ke-Han Lu,Zhehuai Chen,Szu-Wei Fu,Chao-Han Huck Yang,Sung-Feng Huang,Chih-Kai Yang,Chee-En Yu,Chun-Wei Chen,Wei-Chih Chen,Chien-yu Huang,Yi-Cheng Lin,Yu-Xiang Lin,Chi-An Fu,Chun-Yi Kuan,Wenze Ren,Xuanjun Chen,Wei-Ping Huang,En-Pei Hu,Tzu-Quan Lin,Yuan-Kuei Wu,Kuan-Po Huang,Hsiao-Ying Huang,Huang-Cheng Chou,Kai-Wei Chang,Cheng-Han Chiang,Boris Ginsburg,Yu-Chiang Frank Wang,Hung-yi Lee*

主要分类: eess.AS

摘要简述: DeSTA2.5-Audio是一种通用大型音频语言模型（LALM），通过自生成跨模态对齐策略，无需任务特定调优即可实现强大的听觉感知和指令跟随能力。该方法避免了传统方法中语言模型能力的灾难性遗忘问题，并在多个音频语言基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型音频语言模型（LALM）通常通过大规模手动或合成音频指令数据集增强语言模型，但容易导致语言能力的灾难性遗忘。本文旨在解决这一问题，提出一种自生成跨模态对齐策略，以保留语言模型的原始能力并实现音频与文本的有效对齐。

研究方法: 本文提出DeSTA策略，通过让主干语言模型自生成训练目标，构建了DeSTA-AQA5M数据集（包含500万样本，覆盖7000小时音频）。该方法避免了任务特定调优，实现了零样本泛化能力。

研究结果: DeSTA2.5-Audio在Dynamic-SUPERB、MMAU、SAKURA、Speech-IFEval和VoiceBench等多个音频语言基准测试中达到或超越现有最佳性能，证明了自生成策略在听觉感知和指令跟随能力上的优势。

研究结论: 本文强调了数据构建在LALM开发中的重要性，提出了一种有效的自生成跨模态对齐策略，为构建通用且鲁棒的音频语言模型提供了实用见解。

中文摘要: 我们介绍了DeSTA2.5-Audio，一种通用大型音频语言模型（LALM），旨在实现强大的听觉感知和指令跟随能力，而无需任务特定的音频指令调优。现有的LALM通常通过大规模手动或合成音频指令数据集增强大型语言模型（LLM），但这些方法往往导致LLM原始语言能力的灾难性遗忘。为解决这一问题，我们重新审视了数据构建流程，并提出DeSTA策略，即通过主干LLM自生成训练目标，实现跨模态对齐。这种方法保留了LLM的原始语言能力，同时建立了有效的音频-文本对齐，从而实现了零样本泛化能力。利用DeSTA，我们构建了DeSTA-AQA5M数据集，包含500万训练样本，覆盖7000小时音频，涵盖50个多样化数据集，包括语音、环境声音和音乐。DeSTA2.5-Audio在Dynamic-SUPERB、MMAU、SAKURA、Speech-IFEval和VoiceBench等多个音频语言基准测试中达到或超越现有最佳性能。全面的对比研究表明，我们的自生成策略在听觉感知和指令跟随能力上优于广泛采用的数据构建和训练策略。我们的发现强调了精心设计的数据构建在LALM开发中的重要性，并为构建鲁棒、通用的LALM提供了实用见解。

</details>


### [173] [Multi-agent Auditory Scene Analysis](https://arxiv.org/abs/2507.02755)
**中文标题：多代理听觉场景分析**

*Caleb Rascon,Luis Gato-Diaz,Eduardo García-Alarcón*

主要分类: eess.AS

摘要简述: 本文提出了一种多代理听觉场景分析（MASA）系统，通过并行任务和反馈循环解决传统线性流程中的高延迟和误差敏感性问题，适用于低计算资源和快速响应的应用场景。


<details>
  <summary>详细信息</summary>
研究动机: 传统的听觉场景分析（ASA）采用线性任务流程，导致高延迟和误差累积，难以满足低计算资源和快速响应的需求。本文旨在通过多代理并行处理与反馈机制，提升系统的鲁棒性和效率。

研究方法: 提出多代理听觉场景分析（MASA）系统，将声音定位、分离和分类任务并行执行，并通过反馈循环（如利用分离质量修正定位误差）减少局部误差。系统基于开源工具JACK和ROS2实现。

研究结果: MASA系统在保持低复杂度的同时，显著降低了响应时间，并通过反馈机制提高了对局部误差的鲁棒性，适用于多种实时应用场景。

研究结论: 多代理并行处理与反馈机制有效解决了传统ASA系统的延迟和误差敏感性问题，为低计算资源需求的应用提供了可行解决方案。

中文摘要: 听觉场景分析（ASA）旨在通过执行声音源定位、分离和分类三大任务从声学环境中提取信息。传统方法采用线性数据流，依次执行任务，导致整体响应时间增加，且后续任务对定位误差高度敏感。现有技术虽致力于减少误差，但计算复杂度过高，难以适用于生物声学、助听器设计、搜救、人机交互等低计算资源需求场景。为此，本文提出一种多代理方法，并行执行任务并通过反馈循环（如利用分离输出质量修正定位误差，或利用分类结果降低定位对干扰的敏感性）补偿局部误差。最终的多代理听觉场景分析（MASA）系统在保持低复杂度的同时，显著降低了响应时间，并提升了鲁棒性。该系统基于开源工具JACK（声音采集与再现）和ROS2（代理间通信）实现，用户可自行添加代理。

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [174] [Toward a Robust and Generalizable Metamaterial Foundation Model](https://arxiv.org/abs/2507.02436)
**中文标题：迈向稳健且通用的元材料基础模型**

*Namjung Kim,Dongseok Lee,Jongbin Yu,Sung Woong Cho,Dosung Lee,Yesol Park,Youngjoon Hong*

主要分类: physics.optics

摘要简述: 本文提出了一种基于贝叶斯变换器的元材料基础模型MetaFO，能够实现零样本预测和非线性逆向设计，显著扩展了AI驱动的元材料设计空间。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI驱动的元材料设计方法存在任务特定性、分布外泛化能力差以及需独立模型进行正向和逆向设计的问题，限制了其应用潜力。

研究方法: MetaFO采用贝叶斯变换器架构，学习元材料的力学特性，实现跨多样性和未见材料属性组合的零样本预测，并支持非线性逆向设计。

研究结果: MetaFO在分布外条件下表现出色，揭示了复杂的结构-属性关系，显著扩展了设计空间，为AI驱动的元材料发现提供了新范式。

研究结论: MetaFO作为一种可扩展且通用的框架，标志着AI驱动的元材料发现领域的重大突破，为下一代创新铺平了道路。

中文摘要: 材料功能的进步推动了多个领域的创新，其中元材料（由结构而非成分定义）处于领先地位。尽管人工智能（AI）驱动的设计策略兴起，但其影响受限于任务特定的再训练、分布外泛化能力差以及需要独立模型进行正向和逆向设计。为解决这些限制，我们提出了元材料基础模型（MetaFO），这是一种受大型语言模型启发的贝叶斯变换器基础模型。MetaFO学习元材料的底层力学特性，支持跨多样性和未见材料属性组合的概率性零样本预测。它还在非线性逆向设计中表现出色，即使在分布外条件下。通过将元材料视为将材料属性映射到结构响应的算子，MetaFO揭示了复杂的结构-属性关系，并显著扩展了设计空间。这一可扩展且通用的框架标志着AI驱动的元材料发现领域的范式转变，为下一代创新铺平了道路。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [175] [Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting](https://arxiv.org/abs/2507.01997)
**中文标题：迈向一个民主化AI代理实验与基准测试的游乐场：网络故障排除的应用**

*Zhihao Wang,Alessandro Cornacchia,Franco Galante,Carlo Centofanti,Alessio Sacco,Dingde Jiang*

主要分类: cs.NI

摘要简述: 本文探讨了AI代理在网络故障排除中的应用，并呼吁建立一个标准化、可复现且开放的基准测试平台，以简化AI代理的构建与评估。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，AI（尤其是大型语言模型）在网络配置合成和自动化网络诊断任务中表现出色。然而，缺乏一个标准化且开放的基准测试平台，限制了AI代理在网络故障排除中的进一步发展和应用。

研究方法: 本文通过初步研究，聚焦于AI代理在网络故障排除中的应用，并提出建立一个低操作成本的标准化基准测试平台的必要性。

研究结果: 研究强调了标准化基准测试平台的重要性，该平台能够支持AI代理的构建与评估，同时确保实验的可复现性和开放性。

研究结论: 本文呼吁学术界和工业界共同努力，开发一个开放的基准测试平台，以推动AI代理在网络故障排除领域的广泛应用。

中文摘要: 最近的研究表明，人工智能（AI），尤其是大型语言模型（LLM），在网络配置合成和自动化网络诊断任务等方面表现出色。在这项初步工作中，我们将重点放在AI代理在网络故障排除中的应用，并详细阐述了对一个标准化、可复现且开放的基准测试平台的需求。该平台旨在以较低的操作成本构建和评估AI代理。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [176] [Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener](https://arxiv.org/abs/2507.02005)
**中文标题：通过特征工程和自动化可解释机器学习发现焊接横向加劲肋的疲劳强度模型**

*Michael A. Kraus,Helen Bartsch*

主要分类: cs.CE

摘要简述: 本研究结合自动机器学习（AutoML）与可解释人工智能（XAI），通过特征工程和算法特征创建，预测焊接横向加劲肋的疲劳强度，实现了高精度和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过结合专家驱动的特征工程和算法特征创建，提升焊接结构疲劳强度预测的准确性和可解释性，为工程设计和评估提供AI辅助支持。

研究方法: 基于疲劳测试数据库，采用AutoML训练梯度提升、随机森林和神经网络模型，比较了领域知识特征、算法特征及其组合的效果。使用SHAP和特征重要性分析解释模型。

研究结果: 领域知识模型（M2）表现最佳，测试RMSE≈30.6 MPa，R²≈0.780%；在工程相关范围内（0-150 MPa），RMSE≈13.4 MPa，R²≈0.527%。XAI分析揭示了应力比R、应力范围Δσi、屈服强度ReH等为主要预测因子。

研究结论: 结合AutoML与XAI的框架能够生成准确、可解释且稳健的疲劳强度模型，为焊接钢结构的设计和评估提供了新方法。未来将探索概率疲劳寿命建模及数字孪生环境集成。

中文摘要: 本研究提出了一种结合自动机器学习（AutoML）与可解释人工智能（XAI）的统一方法，用于预测焊接横向加劲肋细节的疲劳强度。该方法通过专家驱动的特征工程与算法特征创建相结合，提升了模型的准确性和可解释性。

基于广泛的疲劳测试数据库，采用AutoML训练了梯度提升、随机森林和神经网络模型，并比较了领域知识特征、算法特征及其组合的效果。集成方法（如CatBoost、LightGBM）表现最佳。领域知识模型（M2）在测试中实现了最佳平衡：全Δσc,50%范围内的RMSE≈30.6 MPa，R²≈0.780%；在工程相关范围内（0-150 MPa），RMSE≈13.4 MPa，R²≈0.527%。

XAI方法（SHAP和特征重要性）识别出应力比R、应力范围Δσi、屈服强度ReH及焊后处理（TIG修整与未处理）为主要预测因子。次要几何因素（板宽、喉厚、加劲肋高度）也对疲劳寿命有显著影响。

该框架表明，结合AutoML与XAI能够生成准确、可解释且稳健的疲劳强度模型，为焊接钢结构的设计和评估提供了新方法。未来工作将探索概率疲劳寿命建模及数字孪生环境集成。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [177] [Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes](https://arxiv.org/abs/2507.02331)
**中文标题：追踪模块化CMA-ES配置在问题景观中的交互作用**

*Ana Nikolikj,Mario Andrés Muñoz,Eva Tuba,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文利用算法足迹概念，研究了CMA-ES算法的六种模块化变体在BBOB测试集上的表现，揭示了算法配置与问题特征之间的交互关系。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索同一算法的不同配置在不同问题特征下的表现差异，并揭示问题特性如何影响算法性能。

研究方法: 通过计算六种模块化CMA-ES变体在24个BBOB基准问题上的性能足迹，分析其在5维和30维设置下的表现。

研究结果: 结果显示，不同配置因与问题特性的共同交互表现出相似行为，同时在同一问题上因不同特征表现出差异。

研究结论: 算法足迹方法有效提升了算法性能的可解释性，并为配置选择提供了指导。

中文摘要: 本文利用最近提出的算法足迹概念，研究了算法配置与问题特性之间的交互关系。计算了六种模块化CMA-ES变体（modCMA）在BBOB测试集中的24个基准问题上的性能足迹，分别在5维和30维设置下进行评估。这些足迹揭示了同一算法的不同配置为何表现各异，并识别了影响这些结果的问题特征。分析发现了配置之间因与问题特性的共同交互而表现出的共享行为模式，以及在同一问题上因不同特征而表现出的独特行为。结果表明，算法足迹方法在提升可解释性和指导配置选择方面具有有效性。

</details>


### [178] [ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms](https://arxiv.org/abs/2507.02337)
**中文标题：ClustOpt：一种基于聚类的数值元启发式优化算法搜索动态表示与可视化方法**

*Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文提出了一种基于聚类的表示和可视化方法ClustOpt，用于分析数值元启发式优化算法的搜索动态，并引入两种量化指标（算法稳定性和算法相似性）来评估算法的表现。


<details>
  <summary>详细信息</summary>
研究动机: 传统的可视化方法（如收敛图、轨迹映射和适应度景观分析）难以清晰展示高维或复杂解空间中搜索过程的结构动态，因此需要一种更动态且可解释的方法来理解算法的搜索行为。

研究方法: 通过聚类算法探索的候选解，并跟踪聚类成员在迭代中的演变，提供动态且可解释的搜索过程视图。同时引入算法稳定性和算法相似性两种指标，分别量化单个算法运行的轨迹一致性和不同算法之间的相似性。

研究结果: 该方法应用于十种数值元启发式算法，揭示了它们的稳定性和比较行为，从而更深入地理解了其搜索动态。

研究结论: ClustOpt方法为分析优化算法的搜索动态提供了新的视角，量化指标有助于评估算法的表现，为算法开发和改进提供了有价值的工具。

中文摘要: 理解数值元启发式优化算法的行为对其发展和应用至关重要。传统的可视化技术（如收敛图、轨迹映射和适应度景观分析）往往难以清晰展示搜索过程的结构动态，尤其是在高维或复杂解空间中。为此，我们提出了一种新颖的表示和可视化方法，通过聚类算法探索的候选解并跟踪聚类成员在迭代中的演变，从而提供动态且可解释的搜索过程视图。此外，我们引入了两种指标——算法稳定性和算法相似性，分别用于量化单个算法运行的轨迹一致性以及不同算法之间的相似性。我们将此方法应用于十种数值元启发式算法，揭示了它们的稳定性和比较行为，从而更深入地理解了其搜索动态。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [179] [Real-time Image-based Lighting of Glints](https://arxiv.org/abs/2507.02674)
**中文标题：基于图像的实时闪光光照**

*Tom Kneiphof,Reinhard Klein*

主要分类: cs.GR

摘要简述: 本文提出了一种高效的实时图像光照方法，用于处理具有闪烁或闪光效果的材料，通过快速环境贴图滤波和分层采样技术，实现了动态材质和光照的实时渲染。


<details>
  <summary>详细信息</summary>
研究动机: 图像光照技术广泛应用于实时渲染中，但对于具有离散微表面（如闪光或闪烁效果）的材料，现有方法难以高效处理动态材质和环境贴图。本文旨在解决这一挑战。

研究方法: 方法基于实时区域光下的闪光渲染，采用标准环境贴图滤波技术。通过将环境贴图划分为均匀辐射区域，并利用正态分布函数滤波，计算微表面反射光的概率。在着色时，通过分层采样多变量分布实现高效渲染。

研究结果: 实验表明，该方法在多种材质和光照条件下接近真实渲染效果，性能稳定且开销低，仅需两倍内存存储预滤波环境贴图。

研究结论: 本文提出的实时闪光渲染方法高效且接近真实效果，适用于动态材质和环境贴图的实时应用。

中文摘要: 图像光照是一种广泛用于在真实光照条件下再现阴影的技术，尤其在实时渲染应用中。特别具有挑战性的场景是那些表现出闪烁或闪光外观的材料，这些效果由表面离散的微表面引起。本文提出了一种高效的近似方法，用于实现闪光材料的图像光照，支持完全动态的材质属性和环境贴图。我们的新方法基于区域光照射下的实时闪光渲染，并采用标准环境贴图滤波技术。关键的是，我们的环境贴图滤波过程足够快，可以逐帧执行。该方法假设环境贴图被划分为少数均匀辐射区域。通过用正态分布函数滤波相应的指示函数，我们获得了微表面从每个区域反射光的概率。在着色过程中，这些概率用于分层采样多变量分布，并通过我们新颖的双门控高斯近似二项分布实现。我们验证了该实时近似方法在多种材质和光照条件下接近真实渲染效果，并展示了稳健且稳定的性能，仅比单一方向光渲染闪光材料略高开销。与渲染无闪光的平滑材料相比，我们的方法需要两倍内存存储预滤波环境贴图。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [180] [Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis](https://arxiv.org/abs/2507.02176)
**中文标题：分析与改进语音合成中的说话人相似性评估**

*Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi*

主要分类: cs.SD

摘要简述: 本文研究了语音合成中说话人相似性评估的局限性，发现常用的自动说话人验证（ASV）嵌入主要关注静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。作者提出了U3D指标以评估说话人的动态节奏模式，并公开了代码。


<details>
  <summary>详细信息</summary>
研究动机: 由于语音身份的多维性，建模声音身份具有挑战性。当前语音生成系统通常使用自动说话人验证（ASV）嵌入来评估身份，但这些嵌入设计用于区分而非表征身份。本文旨在探究这些嵌入捕捉了声音的哪些方面，并解决相似性测量中的混淆因素。

研究方法: 本文分析了ASV嵌入的局限性，发现其主要关注静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。作者识别了影响说话人相似性测量的混淆因素，并提出了缓解策略。此外，作者提出了U3D指标，专门用于评估说话人的动态节奏模式。

研究结果: 研究发现，ASV嵌入在评估说话人相似性时存在局限性，尤其是对动态特征的忽视。提出的U3D指标能够有效补充这一不足，提升对说话人动态节奏模式的评估能力。

研究结论: 本文揭示了ASV嵌入在说话人相似性评估中的不足，并提出U3D指标作为补充。这项工作为语音克隆系统中说话人身份一致性的评估提供了新思路，并公开了相关代码以促进研究。

中文摘要: 由于语音身份的多维性，建模声音身份具有挑战性。在生成式语音系统中，身份通常通过自动说话人验证（ASV）嵌入进行评估，但这些嵌入设计用于区分而非表征身份。本文研究了这些嵌入捕捉了声音的哪些方面。我们发现，广泛使用的ASV嵌入主要关注静态特征（如音色和音高范围），而忽略了动态元素（如节奏）。我们还识别了影响说话人相似性测量的混淆因素，并提出了缓解策略。为填补这些空白，我们提出了U3D指标，用于评估说话人的动态节奏模式。这项工作为评估语音克隆系统中说话人身份一致性的持续挑战做出了贡献。我们公开了代码。

</details>


### [181] [JoyTTS: LLM-based Spoken Chatbot With Voice Cloning](https://arxiv.org/abs/2507.02380)
**中文标题：JoyTTS：基于大型语言模型的语音克隆聊天机器人**

*Fangru Zhou,Jun Zhao,Guoxin Wang*

主要分类: cs.SD

摘要简述: JoyTTS是一个结合大型语言模型（LLM）和文本转语音（TTS）技术的端到端语音聊天机器人，具备语音克隆功能，基于开源模型MiniCPM-o和CosyVoice2，训练数据达2000小时。测试结果显示其说话人相似度（SS）为0.73，词错误率（WER）为5.09。


<details>
  <summary>详细信息</summary>
研究动机: 旨在开发一个结合LLM和TTS技术的语音聊天机器人，通过语音克隆功能提升用户体验，并开源代码以促进社区进一步开发和优化。

研究方法: 基于开源模型MiniCPM-o和CosyVoice2，使用2000小时的对话数据进行训练，提供完整的训练代码和推理脚本。

研究结果: 在测试机器seed-tts-zh上，JoyTTS的说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。

研究结论: JoyTTS成功实现了结合LLM和TTS技术的语音聊天机器人，具备语音克隆功能，并通过开源代码推动社区发展。

中文摘要: JoyTTS是一个结合大型语言模型（LLM）和文本转语音（TTS）技术的端到端语音聊天机器人，具备语音克隆功能。该项目基于开源模型MiniCPM-o和CosyVoice2，并使用2000小时的对话数据进行训练。我们还提供了完整的训练代码，以便社区进一步开发和优化。在测试机器seed-tts-zh上，其说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。代码和模型以及训练和推理脚本可在https://github.com/jdh-algo/JoyTTS.git获取。

</details>


### [182] [ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning](https://arxiv.org/abs/2507.02666)
**中文标题：ASDA：基于音频频谱图差分注意力机制的自监督表示学习方法**

*Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang*

主要分类: cs.SD

摘要简述: 本文提出了一种名为ASDA的差分注意力机制，通过双软最大操作和调整差分系数，解决了传统Transformer注意力机制中无效分配的问题，显著提升了音频自监督表示学习的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前音频自监督表示学习中，Transformer的注意力机制常将部分权重分配给无关信息，影响模型判别能力。为解决这一问题，本文提出了差分注意力机制。

研究方法: ASDA模型通过双软最大操作和调整差分系数，优化注意力分配，减少无效权重分配，从而提升模型性能。

研究结果: 实验表明，ASDA在多个基准测试中表现优异，包括音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词检测（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）。

研究结论: ASDA在音频任务中表现出色，为更广泛的应用奠定了基础。

中文摘要: 在音频自监督表示学习的最新进展中，标准Transformer架构已成为主流方法，但其注意力机制常将部分权重分配给无关信息，可能损害模型的判别能力。为此，我们提出了一种差分注意力机制，通过双软最大操作和适当调整的差分系数，有效减少了无效注意力分配。实验结果表明，我们的ASDA模型在多个基准测试中达到了最先进的性能，包括音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词检测（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）。这些结果凸显了ASDA在音频任务中的有效性，为更广泛的应用铺平了道路。

</details>


### [183] [De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks](https://arxiv.org/abs/2507.02606)
**中文标题：De-AntiFake：重新思考针对语音克隆攻击的保护性扰动**

*Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu*

主要分类: cs.SD

摘要简述: 本文首次系统评估了针对语音克隆（VC）的保护性扰动在实际威胁模型下的效果，发现现有净化方法虽能部分中和扰动，但仍会导致VC模型特征空间失真。作者提出了一种新颖的两阶段净化方法，显著优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 随着语音生成模型的快速发展，语音克隆（VC）带来的隐私和安全问题日益突出。尽管已有研究通过引入对抗性扰动来干扰未经授权的VC，但攻击者仍能通过净化技术绕过这些保护。本研究旨在系统评估这些保护性扰动的实际效果，并提出更有效的防御方法。

研究方法: 作者提出了一种两阶段净化方法：1）净化受扰动的语音；2）利用音素引导将其与干净语音分布对齐。实验表明，该方法在干扰VC防御方面优于现有技术。

研究结果: 实验结果显示，现有净化方法虽能中和部分保护性扰动，但仍会导致VC模型特征空间失真，从而降低VC性能。作者提出的两阶段净化方法显著优于现有技术。

研究结论: 本研究揭示了基于对抗性扰动的VC防御的局限性，并强调了开发更鲁棒解决方案的紧迫性，以应对VC带来的安全和隐私风险。

中文摘要: 语音生成模型的快速发展加剧了与语音克隆（VC）相关的隐私和安全问题。近期研究探讨了通过引入对抗性扰动来干扰未经授权的VC。然而，攻击者能够通过净化技术绕过这些保护性扰动并成功执行VC。本研究首次系统评估了这些保护性扰动在实际威胁模型（包括扰动净化）下的效果。研究发现，尽管现有净化方法能中和大部分保护性扰动，但仍会导致VC模型特征空间失真，从而降低VC性能。基于此，我们提出了一种新颖的两阶段净化方法：1）净化受扰动的语音；2）利用音素引导将其与干净语音分布对齐。实验结果表明，我们的方法在干扰VC防御方面优于现有净化技术。本研究揭示了基于对抗性扰动的VC防御的局限性，并强调了开发更鲁棒解决方案的紧迫性，以应对VC带来的安全和隐私风险。代码和音频样本可在https://de-antifake.github.io获取。

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [184] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
**中文标题：解决湍流磁流体动力学：一种混合算子-扩散框架**

*Semih Kacmaz,E. A. Huerta,Roland Haas*

主要分类: physics.flu-dyn

摘要简述: 本文提出了一种混合机器学习框架，结合物理信息神经算子（PINO）和基于分数的生成扩散模型，用于模拟二维不可压缩电阻磁流体动力学（MHD）湍流的全时空演化。该框架在广泛的雷诺数范围内实现了高精度模拟，填补了确定性代理模型在高湍流水平下的空白。


<details>
  <summary>详细信息</summary>
研究动机: 传统确定性代理模型在高雷诺数湍流模拟中表现不佳，无法准确捕捉高频动态和非高斯统计特性。本文旨在通过结合物理约束和随机校正的方法，解决这一挑战。

研究方法: 提出了一种混合框架，利用PINO预测低频相干动态，同时通过条件扩散模型随机校正高频残差。训练数据覆盖了从100到10000的雷诺数范围。

研究结果: 在雷诺数为1000和3000时，模型成功重建了速度和磁场的全谱能量分布，并捕捉了非高斯统计特性和间歇结构。在极端湍流水平（Re=10000）下，首次实现了对磁场高波数演化的准确恢复。

研究结论: 该混合框架为高雷诺数湍流模拟提供了一种高效且精确的解决方案，填补了现有方法的空白，并为复杂物理系统的建模开辟了新途径。

中文摘要: 我们提出了一种混合机器学习框架，结合物理信息神经算子（PINO）和基于分数的生成扩散模型，用于模拟二维不可压缩电阻磁流体动力学（MHD）湍流的全时空演化。该框架利用PINO的方程约束泛化能力预测低频相干动态，同时通过条件扩散模型随机校正高频残差，从而实现对完全发展湍流的精确建模。训练数据覆盖了雷诺数为100至10000的高保真模拟，该方法在以往确定性代理模型无法处理的范围内达到了最先进的精度。在雷诺数为1000和3000时，模型能够忠实重建速度和磁场的全谱能量分布，并捕捉非高斯统计特性、间歇结构和跨场相关性。在极端湍流水平（Re=10000）下，该模型首次实现了对磁场高波数演化的恢复，保留了大尺度形态并提供了统计上有意义的预测。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [185] [Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation](https://arxiv.org/abs/2507.02306)
**中文标题：合成启发式评估：人工智能与人类驱动的可用性评估对比**

*Ruican Zhong,David W. McDonald,Gary Hsieh*

主要分类: cs.HC

摘要简述: 本文提出了一种基于多模态大语言模型（LLM）的合成启发式评估方法，用于用户体验设计。实验表明，该方法在识别可用性问题上的表现优于人类评估者，尤其在布局问题上表现突出，但在识别某些UI组件和设计惯例方面存在不足。


<details>
  <summary>详细信息</summary>
研究动机: 用户体验评估在人本设计中至关重要，但传统方法成本高昂，需要专家时间和用户补偿。本文旨在探索利用多模态LLM的能力，开发一种低成本、高效的合成启发式评估方法。

研究方法: 研究开发了一种基于多模态LLM的合成启发式评估方法，通过分析图像并提供设计反馈。该方法在两个应用程序中与经验丰富的用户体验从业者进行了对比实验。

研究结果: 合成评估方法在两个应用中分别识别了73%和77%的可用性问题，显著优于5名人类评估者（57%和63%）。该方法在布局问题上表现优异，但在识别某些UI组件和跨屏幕违规方面存在不足。

研究结论: 合成启发式评估在可用性问题上表现优于人类评估者，尤其在布局问题上具有优势，但在某些设计细节上仍需改进。研究为合成启发式评估的设计提供了参考。

中文摘要: 可用性评估在人本设计中至关重要，但成本高昂，需要专家时间和用户补偿。本研究开发了一种基于多模态大语言模型（LLM）的合成启发式评估方法，通过分析图像并提供设计反馈。在两个应用程序中，将合成评估与经验丰富的用户体验从业者的评估进行对比，发现合成评估分别识别了73%和77%的可用性问题，显著优于5名人类评估者（57%和63%）。与人类评估者相比，合成评估在任务中表现稳定，尤其在检测布局问题上表现突出，突显了合成评估在注意力和感知方面的潜在优势。然而，合成评估在识别某些UI组件和设计惯例以及跨屏幕违规方面存在困难。此外，长期和多账户测试表明合成评估性能稳定。总体而言，本研究揭示了人类与LLM驱动评估之间的性能差异，为合成启发式评估的设计提供了参考。

</details>


### [186] [Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue](https://arxiv.org/abs/2507.02537)
**中文标题：你在听我说吗？微调聊天机器人以实现同理心对话**

*Paulo Ricardo Knob,Leonardo Scholler,Juliano Rigatti,Soraia Raupp Musse*

主要分类: cs.HC

摘要简述: 本研究探讨如何通过微调大型语言模型（如ChatGPT和Gemini）生成更具同理心的对话，结合情感分析和专家评估发现，情感建模需兼顾结构对齐与情感深度。


<details>
  <summary>详细信息</summary>
研究动机: 随着对话代理在医疗、教育和客服等领域的广泛应用，情感智能（尤其是同理心倾听）的需求日益凸显。本研究旨在探索如何提升大型语言模型在情感丰富对话中的表现。

研究方法: 研究从专家手工制作的小型同理心对话数据集出发，利用ChatGPT和Gemini扩展对话，并通过VADER情感分析和专家评估分析对话的情感进展。

研究结果: 生成的对话虽能反映目标情感结构，但人类评估显示其在同理心和连贯性上存在差异，表明情感建模需结合自动化和人工方法。

研究结论: 情感对话建模不仅需要结构对齐，还需情感深度，开发情感智能代理需综合自动化和人工评估方法。

中文摘要: 自ELIZA以来，对话代理已取得显著进展，广泛应用于医疗、教育和客服等领域。随着这些代理日益融入人类日常互动，情感智能（尤其是同理心倾听）的需求变得至关重要。本研究探讨了大型语言模型（LLMs）在生成情感丰富互动时的表现。我们从专家手工制作的小型同理心对话数据集出发，利用ChatGPT和Gemini扩展对话，并通过VADER情感分析和专家评估分析对话的情感进展。尽管生成的对话常能反映目标情感结构，但人类评估揭示了其在同理心和连贯性上的重要差异。这些发现表明，情感对话建模不仅需要表达情感的结构对齐，还需情感深度，强调了在开发情感智能代理时结合自动化和人工方法的重要性。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [187] [FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference](https://arxiv.org/abs/2507.02620)
**中文标题：FlowSpec：用于高效分布式LLM推理的连续流水线推测解码**

*Xing Liu,Lizhuo Luo,Ming Tang,Chao Huang*

主要分类: cs.DC

摘要简述: FlowSpec是一种分布式LLM推理框架，通过流水线并行和树状推测解码技术，显著提升边缘设备上的推理效率，速度提升1.36倍至1.77倍。


<details>
  <summary>详细信息</summary>
研究动机: 分布式推理是边缘设备上运行大型语言模型（LLMs）的有效方法，但现有流水线方法在请求稀疏时利用率低，导致效率下降。FlowSpec旨在解决这一问题，提升边缘设备上的推理效率。

研究方法: FlowSpec采用三种关键技术：1）基于分数的逐步验证，优先处理重要草稿词；2）高效的草稿管理，修剪无效词并保持验证中的因果关系；3）动态草稿扩展策略，提供高质量推测输入。这些技术共同提升流水线利用率和推测效率。

研究结果: 实验表明，FlowSpec在多种模型和配置下显著提升推理速度，速度比基线方法快1.36倍至1.77倍。

研究结论: FlowSpec通过优化流水线并行和推测解码，显著提升了边缘设备上的LLM推理效率，为分布式推理提供了高效解决方案。

中文摘要: 分布式推理是一种在边缘网络中实现大型语言模型（LLMs）推理的有效方法，它将推理过程分布到多个设备上，以确保模型能适应设备内存。近期的流水线方法具有并行化通信和计算的潜力，有助于降低推理延迟。然而，当边缘网络的推理请求稀疏时，流水线的利用率通常较低，其优势会减弱。为了实现边缘设备上的高效分布式LLM推理，我们提出了FlowSpec，一种基于流水线并行和树状推测解码的框架。FlowSpec包含三种关键机制以提高解码效率：1）基于分数的逐步验证，优先处理更重要的草稿词以尽早接受有效词；2）高效的草稿管理，在验证过程中修剪无效词并保持正确的因果关系；3）动态草稿扩展策略，提供高质量的推测输入。这些技术协同工作，提升了流水线利用率和推测效率。我们在真实测试平台上与其他基线方法进行了对比实验。结果表明，FlowSpec在不同模型和配置下显著提升了推理速度，速度比基线方法快1.36倍至1.77倍。我们的代码已公开在https://github.com/Leosang-lx/FlowSpec#。

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [188] [Solving the Hubbard model with Neural Quantum States](https://arxiv.org/abs/2507.02644)
**中文标题：利用神经量子态求解Hubbard模型**

*Yuntian Gu,Wenrui Li,Heng Lin,Bo Zhan,Ruichen Li,Yifei Huang,Di He,Yantao Wu,Tao Xiang,Mingpu Qin,Liwei Wang,Dingshun Lv*

主要分类: cond-mat.str-el

摘要简述: 本文利用基于Transformer的神经量子态（NQS）框架，结合高效优化算法，成功解决了掺杂二维Hubbard模型，为强关联系统研究提供了新工具。


<details>
  <summary>详细信息</summary>
研究动机: Hubbard模型是研究高温超导的最小模型，但其强关联特性使得传统方法难以解决。本文旨在通过神经量子态（NQS）框架，结合先进架构和优化算法，突破这一难题。

研究方法: 采用基于Transformer的神经量子态（NQS）架构，开发高效优化算法，捕捉多尺度关联和长程纠缠。

研究结果: 在掺杂二维Hubbard模型中取得最先进结果，发现NQS能直接编码不同尺度的关联，并确认半填充条纹态的存在，与实验观测一致。

研究结论: 神经量子态（NQS）成为解决强关联多费米子系统的有力工具，为未来研究提供了新方向。

中文摘要: 神经量子态（NQS）的快速发展使其成为研究量子多体系统的有前景框架。本文通过利用基于Transformer的先进架构和开发高效优化算法，在掺杂二维（2D）Hubbard模型中取得了最先进的结果，该模型被认为是高温超导的最小模型。有趣的是，我们发现NQS中的不同注意力头可以直接编码不同尺度的关联，使其能够捕捉强关联系统中的长程关联和纠缠。通过这些进展，我们确认了二维Hubbard模型中半填充条纹态的存在，与铜氧化物实验观测一致。我们的工作确立了NQS作为解决挑战性多费米子系统的强大工具。

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [189] [DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification](https://arxiv.org/abs/2507.01971)
**中文标题：DeepSupp：基于注意力驱动的相关性模式分析动态时间序列支撑与阻力水平识别**

*Boris Kriuk,Logic Ng,Zarif Al Hossain*

主要分类: q-fin.ST

摘要简述: 本文提出了一种名为DeepSupp的新型深度学习方法，利用多头注意力机制分析动态时间序列中的支撑和阻力水平，显著提升了金融技术分析的准确性和适应性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的支撑和阻力水平识别方法难以适应现代复杂多变的市场环境，而现有机器学习方法多聚焦于价格预测而非结构水平识别。本文旨在填补这一空白，提供一种更可靠且可扩展的解决方案。

研究方法: DeepSupp结合高级特征工程构建动态相关矩阵，捕捉市场关系的演变，并采用基于注意力的自编码器进行鲁棒表示学习。最终通过无监督聚类（DBSCAN）提取关键支撑水平。

研究结果: 在标普500股票上的全面评估表明，DeepSupp在六项金融指标上优于六种基线方法，包括支撑水平准确性和市场状态敏感性，展现了卓越的性能。

研究结论: DeepSupp通过注意力架构揭示了市场细微模式，为现代金融分析提供了可靠且可扩展的解决方案，显著提升了技术交易策略的效果。

中文摘要: 支撑与阻力（SR）水平是技术分析的核心，指导交易者的入场、出场和风险管理。尽管广泛应用，传统SR识别方法往往难以适应现代复杂多变的市场环境。近期研究引入了机器学习技术以应对挑战，但多数聚焦于价格预测而非结构水平识别。本文提出DeepSupp，一种新的深度学习方法，利用多头注意力机制分析空间相关性和市场微观结构关系，以检测金融支撑水平。DeepSupp整合了高级特征工程，构建动态相关矩阵捕捉市场关系的演变，并采用基于注意力的自编码器进行鲁棒表示学习。最终支撑水平通过无监督聚类（DBSCAN）提取，识别关键价格阈值。在标普500股票上的全面评估表明，DeepSupp在六项金融指标上优于六种基线方法，包括支撑水平准确性和市场状态敏感性，展现了卓越性能。在不同市场条件下结果一致，DeepSupp填补了SR水平检测的关键空白，为现代金融分析提供了可扩展且可靠的解决方案。我们的方法凸显了注意力架构在揭示市场细微模式和优化技术交易策略方面的潜力。

</details>


### [190] [Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach](https://arxiv.org/abs/2507.01979)
**中文标题：基于LSTNet的多尺度深度学习方法预测劳动力市场**

*Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi*

主要分类: q-fin.ST

摘要简述: 本文提出了一种基于LSTNet的多尺度深度学习模型，用于预测短期就业变化和评估长期行业健康状况。该模型利用多元时间序列数据，在多个行业中表现优于基线模型，并展示了行业就业健康指数与实际就业波动的强相关性。


<details>
  <summary>详细信息</summary>
研究动机: 劳动力市场的短期预测和长期健康评估对政策制定者和企业至关重要。传统方法难以处理多元时间序列数据，且缺乏解释性。本文旨在通过深度学习模型解决这些问题。

研究方法: 采用LSTNet（长短期时间序列网络）处理多元时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和可解释的行业就业健康指数（IEHI）。

研究结果: 模型在大多数行业中表现优于基线模型，尤其是在稳定行业中。IEHI排名与实际就业波动显示出强相关性。同时分析了误差模式和行业特异性表现。

研究结论: LSTNet模型在劳动力市场预测中表现出色，未来可进一步优化解释性和泛化能力。

中文摘要: 本文提出了一种深度学习方法，用于预测短期就业变化并评估长期行业健康状况，数据来源于美国劳工统计局的劳动力市场数据。我们的系统利用长短期时间序列网络（LSTNet）处理多元时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和可解释的行业就业健康指数（IEHI）。该方法在大多数行业中表现优于基线模型，尤其是在稳定行业中，并展示了IEHI排名与实际就业波动的强相关性。我们讨论了误差模式、行业特异性表现以及未来提升解释性和泛化能力的方向。

</details>


### [191] [NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction](https://arxiv.org/abs/2507.02018)
**中文标题：NGAT：一种用于长期股票预测的节点级图注意力网络**

*Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong*

主要分类: q-fin.ST

摘要简述: 本文提出了一种名为NGAT的节点级图注意力网络，用于解决长期股票预测中的三个关键挑战：下游任务设计限制、模型复杂性和泛化能力不足，以及基于经验构建的公司关系图缺乏有效比较。实验证明NGAT在两种数据集上均表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前金融领域的图表示学习方法在利用公司间关系增强公司表示时面临三个主要问题：下游任务设计限制了关系信息的优势，现有股票预测图模型过于复杂且泛化能力差，以及基于经验构建的图结构缺乏有效比较。本文旨在解决这些问题。

研究方法: 本文提出了一种节点级图注意力网络（NGAT），专门为公司关系图设计，并开发了长期股票预测任务。此外，实验比较了现有基于模型下游任务性能的图比较方法的局限性。

研究结果: 在两个数据集上的实验结果表明，NGAT在长期股票预测任务中表现优异，验证了其有效性。

研究结论: NGAT通过节点级图注意力网络解决了现有方法的局限性，实验证明了其在长期股票预测中的优越性。项目已开源以促进复现和未来研究。

中文摘要: 图表示学习方法在金融应用中广泛用于通过公司间关系增强公司表示。然而，当前方法面临三个关键挑战：（1）关系信息的优势因下游任务设计的限制而被掩盖；（2）现有专门为股票预测设计的图模型通常过于复杂且泛化能力差；（3）基于经验构建的公司关系图缺乏对不同图结构的有效比较。为解决这些问题，我们提出了一种长期股票预测任务，并开发了专门为公司关系图设计的节点级图注意力网络（NGAT）。此外，我们通过实验证明了基于模型下游任务性能的现有图比较方法的局限性。在两个数据集上的实验结果一致证明了我们提出的任务和模型的有效性。项目已在GitHub上公开，以鼓励复现和未来研究。

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [192] [Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency](https://arxiv.org/abs/2507.02135)
**中文标题：解析移动DVFS调节器对LLM推理性能和能效的影响**

*Zongpu Zhang,Pranab Dash,Y. Charlie Hu,Qiang Xu,Jian Li,Haibing Guan*

主要分类: cs.OS

摘要简述: 本文研究了移动设备上动态电压频率调节（DVFS）对大型语言模型（LLM）推理性能和能效的影响，揭示了当前独立运行的CPU、GPU和内存调节器导致能效低下的问题，并提出了一种统一的能效优化方案FUSE。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在移动设备上的广泛应用，其高计算、内存和能耗需求成为部署的主要挑战。当前移动设备中的CPU、GPU和内存调节器独立运行，缺乏协同优化，导致能效低下。

研究方法: 首先测量了现有LLM框架在移动设备上的能效表现，发现独立调节器导致延迟增加；其次深入分析了调节器间缺乏协同的原因；最后设计了一种统一的能效优化方案FUSE。

研究结果: 实验表明，FUSE显著降低了首次令牌生成时间和每令牌生成时间，分别平均减少7.0%-16.9%和25.4%-36.8%，同时保持相同的每令牌能耗。

研究结论: FUSE通过协同优化CPU、GPU和内存调节器，显著提升了移动设备上LLM推理的能效和性能，为未来移动LLM部署提供了有效解决方案。

中文摘要: 大型语言模型（LLM）正越来越多地集成到运行在数十亿移动设备上的各种应用和服务中。然而，由于LLM对计算、内存和能量的高需求，在资源有限的移动设备上部署LLM面临重大挑战。当前移动设备中的LLM框架在运行主要依赖GPU的LLM模型时，仍使用了三个高能耗组件——CPU、GPU和内存，而现代移动设备中的CPU、GPU和内存动态电压频率调节（DVFS）调节器独立运行且彼此无感知。基于这一观察，本研究首先测量了现有LLM框架在移动设备上的能效表现，发现独立调节器导致预填充和解码延迟比最优频率组合高出40.4%。其次，通过深入测量研究揭示了调节器间缺乏协同导致的能效低下原因。最后，基于这些发现，设计了FUSE——一种统一的能效感知调节器，用于优化移动设备上LLM推理的能效。使用ShareGPT数据集的评估表明，FUSE在相同每令牌能耗下，将首次令牌生成时间和每令牌生成时间分别平均减少了7.0%-16.9%和25.4%-36.8%。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [193] [HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3](https://arxiv.org/abs/2507.02345)
**中文标题：HelixDesign-Antibody：基于HelixFold3的可扩展生产级抗体设计平台**

*Jie Gao,Jing Hu,Shanzhuo Zhang,Kunrui Zhu,Sheng Qian,Yueyang Huang,Xiaonan Zhang,Xiaomin Fang*

主要分类: q-bio.BM

摘要简述: HelixDesign-Antibody是一个基于HelixFold3的高通量抗体设计平台，通过高效计算支持大规模生成和评估抗体候选序列，显著提升抗体工程效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统抗体发现方法耗时且资源密集，亟需一种高效、可扩展的平台来加速抗体工程和生物医学研究。

研究方法: 该平台基于高精度结构预测模型HelixFold3，结合高性能计算支持，实现抗体候选序列的大规模生成和抗原相互作用评估。

研究结果: 验证表明，平台能生成多样且高质量的抗体，探索更大的序列空间可提高找到最优结合体的概率。

研究结论: HelixDesign-Antibody为大规模抗体设计提供了无缝、易用的解决方案，已集成至PaddleHelix平台。

中文摘要: 抗体工程对开发治疗药物和推动生物医学研究至关重要。传统发现方法通常依赖耗时且资源密集的实验筛选。为了优化这一过程，我们推出了一个基于HelixFold3的生产级高通量平台——HelixDesign-Antibody。该平台利用高精度结构预测模型HelixFold3，支持大规模生成抗体候选序列并评估其与抗原的相互作用。集成的高性能计算（HPC）支持实现了高通量筛选，解决了工具链碎片化和高计算需求等挑战。在多个抗原上的验证表明，该平台能够生成多样且高质量的抗体，证实了探索更大序列空间可提高找到最优结合体的概率。该平台为大规模抗体设计提供了无缝、易用的解决方案，可通过PaddleHelix平台的抗体设计页面访问。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [194] [AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models](https://arxiv.org/abs/2507.02598)
**中文标题：AC-Refiner：基于条件扩散模型的高效算术电路优化方法**

*Chenhao Xue,Kezhi Li,Jiaxing Zhang,Yi Ren,Zhengyuan Shi,Chen Zhang,Yibo Lin,Lining Zhang,Qiang Xu,Guangyu Sun*

主要分类: cs.AR

摘要简述: AC-Refiner是一种基于条件扩散模型的新型算术电路优化框架，通过将电路合成任务转化为条件图像生成问题，显著提升了设计质量和优化效率。


<details>
  <summary>详细信息</summary>
研究动机: 算术电路（如加法器和乘法器）是数字系统的核心组件，其性能、功耗和面积直接影响系统表现。然而，由于设计空间庞大且物理约束复杂，优化这些电路极具挑战性。现有深度学习方法难以稳定探索高潜力设计变体，限制了优化效率。

研究方法: AC-Refiner将算术电路合成任务重新定义为条件图像生成问题，利用条件扩散模型生成高质量电路设计。通过将去噪扩散过程与目标质量结果（QoR）条件化，并结合探索到的设计对模型进行微调，专注于帕累托前沿附近的优化。

研究结果: 实验表明，AC-Refiner生成的电路设计具有更优的帕累托最优性，显著优于现有基线方法。其性能提升在实际应用中也得到了验证。

研究结论: AC-Refiner通过创新的条件扩散模型方法，有效解决了算术电路优化问题，为高性能、低功耗和紧凑面积的电路设计提供了新思路。

中文摘要: 算术电路（如加法器和乘法器）是数字系统的基础组件，直接影响性能、能效和面积占用。然而，由于设计空间庞大且物理约束复杂，优化这些电路仍具挑战性。尽管近期基于深度学习的方法展现出潜力，但其难以稳定探索高潜力设计变体，限制了优化效率。为解决这一问题，我们提出AC-Refiner，一种基于条件扩散模型的新型算术电路优化框架。我们的核心思路是将算术电路合成任务重新定义为条件图像生成问题。通过将去噪扩散过程与目标质量结果（QoR）条件化，AC-Refiner能够稳定生成高质量电路设计。此外，探索到的设计用于微调扩散模型，从而将优化聚焦于帕累托前沿附近。实验结果表明，AC-Refiner生成的电路设计具有更优的帕累托最优性，优于现有基线方法。通过将AC-Refiner集成到实际应用中，其性能提升得到了进一步验证。

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [195] [Subtyping in DHOL -- Extended preprint](https://arxiv.org/abs/2507.02855)
**中文标题：DHOL中的子类型化——扩展预印本**

*Colin Rothgang,Florian Rabe*

主要分类: cs.LO

摘要简述: 本文扩展了依赖类型高阶逻辑（DHOL），通过引入细化和商类型作为子类型的特例，提升了表达能力和实用性，同时保持了自动化定理证明的支持。


<details>
  <summary>详细信息</summary>
研究动机: 依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间取得了平衡，但其类型系统不可判定。本文旨在扩展DHOL，加入实践中常用的细化和商类型，这些类型通常难以在可判定的类型系统中实现。

研究方法: 通过将细化和商类型作为子类型的特例引入DHOL，避免了表示上的复杂变化，同时保持了向HOL的翻译的完整性和正确性。

研究结果: 扩展后的DHOL支持细化和商类型，且无需改变核心表示，同时保持了自动化定理证明的完整性和正确性。

研究结论: 本文成功扩展了DHOL，使其支持细化和商类型，为实践提供了更多灵活性，同时保持了自动化支持的优势。

中文摘要: 最近引入的依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间提供了一种有趣的折衷方案。它牺牲了类型系统的可判定性，以显著扩展其相对于标准HOL的表达能力，同时通过向HOL的完整且正确的翻译保留了强大的自动化定理证明支持。

我们利用这一设计，将DHOL扩展为支持细化和商类型。这两种类型在实践中常被需求，但很少由自动化定理证明器提供。这是因为它们本质上需要不可判定的类型系统，因此很难在可判定的类型系统中实现。但由于DHOL已经承担了大部分工作，添加它们不仅可能，而且优雅且简单。

具体来说，我们将细化和商类型作为子类型的特例加入。这使得相关的规范包含和投影映射成为恒等映射，从而避免了表示上的昂贵变化。我们为扩展后的语言提供了语法、语义和向HOL的翻译，包括完整性和正确性的证明。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [196] [Early Signs of Steganographic Capabilities in Frontier LLMs](https://arxiv.org/abs/2507.02737)
**中文标题：前沿大型语言模型中隐写能力的早期迹象**

*Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner*

主要分类: cs.CR

摘要简述: 前沿大型语言模型（LLM）已展现出初步的隐写能力，但当前能力尚不足以绕过设计良好的监控。


<details>
  <summary>详细信息</summary>
研究动机: 监控大型语言模型（LLM）的输出对防止滥用和错位风险至关重要。然而，LLM可能通过隐写术（在看似无害的输出中隐藏信息）逃避监控。本文旨在评估前沿LLM的隐写能力，以更好地理解其潜在风险。

研究方法: 研究聚焦于两种隐写术：传递编码信息和执行编码推理。通过实验评估模型在标准条件下及额外辅助（如使用未监控的草稿纸和协调编码方案）下的表现。

研究结果: 当前模型在标准条件下无法隐藏短信息而不被监控发现，但在额外辅助下可以成功。此外，模型在简单状态跟踪问题中展现出初步的编码推理能力，但难以在覆盖任务中隐藏推理以欺骗监控。

研究结论: 当前LLM的隐写能力尚处于初级阶段，不足以绕过设计良好的监控，但未来可能发生变化。

中文摘要: 监控大型语言模型（LLM）的输出对于降低滥用和错位风险至关重要。然而，LLM可能通过隐写术（即在看似无害的生成中隐藏信息）逃避监控。本文评估了前沿LLM的隐写能力，以更好地理解其潜在风险。我们关注两种隐写术：传递编码信息和执行编码推理。研究发现，当前模型在标准条件下无法隐藏短信息而不被监控发现，但在额外辅助（如使用未监控的草稿纸和协调编码方案）下可以成功。此外，模型在简单状态跟踪问题中展现出初步的编码推理能力，包括使用自身和预定义方案（如十六进制）进行推理。尽管如此，它们很少能巧妙地在覆盖任务中隐藏推理以欺骗监控。总体而言，结果表明当前LLM展现出初期的隐写能力。虽然这些能力目前可能不足以绕过设计良好的监控，但未来可能发生变化。

</details>


### [197] [MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation](https://arxiv.org/abs/2507.02057)
**中文标题：MGC：一种利用对齐LLM组合性盲区的恶意软件生成编译器框架**

*Lu Yan,Zhuo Zhang,Xiangzhe Xu,Shengwei An,Guangyu Shen,Zhou Xuan,Xuan Chen,Xiangyu Zhang*

主要分类: cs.CR

摘要简述: 本文提出了一种名为MGC的编译器框架，利用对齐大型语言模型（LLM）的组合性盲区，通过模块化分解和规避对齐机制生成恶意软件。实验证明，MGC在生成功能性恶意软件方面显著优于现有方法，并成功复现了16个真实恶意软件样本。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）降低了软件开发的门槛，但也为恶意软件开发提供了便利。尽管LLM提供商通过对齐机制阻止直接生成恶意代码，但这些机制通常仅评估单个提示，忽视了恶意操作可被分解为看似良性的子任务的风险。本文旨在利用这一漏洞，开发一种能够生成恶意软件的框架。

研究方法: MGC框架通过模块化分解和规避对齐机制生成恶意软件。它使用一种名为MDIR（恶意描述中间表示）的中间语言，将高级恶意意图与看似良性的代码片段连接起来。这种方法能够绕过LLM的对齐机制，生成功能性恶意软件。

研究结果: 实验表明，MGC在三个基准数据集上生成的恶意软件正确率显著高于越狱方法和地下服务（分别提升365.79%和78.07%）。此外，MGC成功复现并增强了16个真实恶意软件样本。

研究结论: 本文揭示了组合性攻击对对齐AI系统的风险，为安全研究人员提供了重要见解。MGC框架的成功表明，当前的对齐机制存在漏洞，需要进一步改进以应对此类攻击。

中文摘要: 大型语言模型（LLM）降低了软件开发的复杂性门槛，但也为恶意软件开发提供了便利。尽管LLM提供商通过对齐机制阻止直接生成恶意代码，但这些机制通常仅评估单个提示，忽视了恶意操作可被分解为看似良性的子任务的风险。本文提出了恶意软件生成编译器（MGC），一种利用这一漏洞的框架，通过模块化分解和规避对齐机制生成恶意软件。MGC使用一种名为MDIR（恶意描述中间表示）的中间语言，将高级恶意意图与看似良性的代码片段连接起来。实验表明，MGC在生成功能性恶意软件方面显著优于越狱方法和地下服务（分别提升365.79%和78.07%），并成功复现了16个真实恶意软件样本。这项工作为安全研究人员揭示了组合性攻击对对齐AI系统的风险。演示内容详见https://sites.google.com/view/malware-generation-compiler。

</details>


### [198] [Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities](https://arxiv.org/abs/2507.02125)
**中文标题：人工智能能否解决区块链预言机问题？挑战与可能性的探讨**

*Giulio Caldarelli*

主要分类: cs.CR

摘要简述: 本文探讨人工智能（AI）能否解决区块链预言机问题，分析了AI在提升数据质量和系统韧性方面的潜力，但也指出AI无法完全消除对链外数据的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 区块链预言机问题限制了去中心化应用的发展，现有方法未能彻底解决链外数据可靠性的问题。本文旨在评估AI技术如何作为补充工具，提升预言机系统的性能。

研究方法: 通过分析学术文献和实践案例，研究了AI技术（如异常检测、语言事实提取、动态声誉建模和对抗性抵抗）在预言机系统中的应用。

研究结果: 研究发现，AI能显著提升数据质量、源选择和系统韧性，但仍无法完全摆脱对不可验证链外输入的依赖。

研究结论: AI应被视为预言机设计中的补充层，用于推理和过滤，而非替代信任假设。

中文摘要: 区块链预言机问题指的是将可靠的外部数据注入去中心化系统的挑战，这仍然是开发无需信任应用的基本限制。尽管近年来出现了多种架构、密码学和经济策略以缓解此问题，但尚未有人完全解决区块链如何获取链外世界知识的根本问题。在这篇立场论文中，我们批判性地评估了人工智能（AI）在解决预言机问题中的作用。通过结合学术文献和实践案例，我们研究了AI技术（如异常检测、基于语言的事实提取、动态声誉建模和对抗性抵抗）如何提升预言机系统。我们发现，尽管AI为改善数据质量、源选择和系统韧性提供了强大工具，但它无法消除对不可验证链外输入的依赖。因此，本研究支持将AI视为更广泛预言机设计中的补充推理和过滤层，而非信任假设的替代品。

</details>


### [199] [EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer](https://arxiv.org/abs/2507.02206)
**中文标题：EIM-TRNG：通过RowHammer利用内存编码真随机数生成器混淆深度神经网络权重**

*Ranyang Zhou,Abeer Matar A. Almalky,Gamana Aragonda,Sabbir Ahmed,Filip Roth Trønnes-Christensen,Adnan Siraj Rakin,Shaahin Angizi*

主要分类: cs.CR

摘要简述: 本文提出了一种名为EIM-TRNG的新型硬件随机数生成器，利用DRAM在RowHammer攻击下的物理随机性生成真随机数，并将其应用于保护深度神经网络的权重数据。


<details>
  <summary>详细信息</summary>
研究动机: 在深度神经网络（DNN）中，保护模型参数（尤其是权重）对确保AI系统的完整性、隐私性和知识产权至关重要。现有的软件伪随机数生成器缺乏硬件真随机数生成器的不可预测性和鲁棒性，因此需要一种基于硬件的解决方案。

研究方法: 提出了一种名为EIM-TRNG的编码内存真随机数生成器，通过精确控制的RowHammer操作，利用DRAM单元行为的物理随机性生成不可预测的比特翻转。这些翻转被用作可靠的熵源，并通过固定和不可预测的比特翻转组合对DNN权重数据进行编码加密。

研究结果: 实验结果表明，基于DRAM的熵提取方法能够有效提供低成本且鲁棒的硬件安全性，同时为机器学习模型的硬件级保护提供了可行方案。

研究结论: EIM-TRNG通过利用DRAM的物理随机性，为保护DNN权重数据提供了一种新颖且高效的方法，展示了硬件级安全性的潜力。

中文摘要: 真随机数生成器（TRNGs）在硬件安全、加密系统和数据保护中扮演着重要角色。在深度神经网络（DNNs）中，保护模型参数（尤其是权重）对确保AI系统的完整性、隐私性和知识产权至关重要。尽管基于软件的伪随机数生成器被广泛使用，但它们缺乏基于硬件的TRNGs所提供的不可预测性和鲁棒性。本文提出了一种名为EIM-TRNG的新型编码内存真随机数生成器，首次利用DRAM单元行为（特别是RowHammer引发的干扰）中的固有物理随机性。我们展示了如何通过精确控制的RowHammer操作生成的不可预测比特翻转作为可靠的熵源。此外，我们通过固定和不可预测比特翻转的组合编码，将此TRNG框架应用于保护DNN权重数据。加密数据随后通过基于概率翻转行为生成的密钥解密，确保数据机密性和模型真实性。我们的结果验证了基于DRAM的熵提取方法在提供低成本且鲁棒的硬件安全性方面的有效性，并为机器学习模型的硬件级保护提供了有前景的方向。

</details>


### [200] [Evaluating Language Models For Threat Detection in IoT Security Logs](https://arxiv.org/abs/2507.02390)
**中文标题：评估语言模型在物联网安全日志中的威胁检测能力**

*Jorge J. Tejero-Fernández,Alfonso Sánchez-Macián*

主要分类: cs.CR

摘要简述: 本文提出了一种利用微调大语言模型（LLMs）进行物联网安全日志异常检测和缓解建议的流程，相比传统机器学习分类器，LLMs在多类攻击分类中表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 日志分析是网络安全领域的重要研究方向，可用于检测网络和系统的威胁。本文旨在探索如何利用LLMs提升物联网安全日志的异常检测和缓解建议能力。

研究方法: 通过对比三种开源LLMs与传统机器学习分类器，采用零样本、少样本提示和微调三种策略，对物联网数据集进行二分类和多分类异常检测。同时，将检测到的威胁映射到MITRE CAPEC，定义物联网特定的缓解措施，并微调模型以提供检测与建议的联合指导。

研究结果: LLMs在多类攻击分类任务中表现优于传统基线模型，并能结合MITRE CAPEC和物联网特定缓解措施提供有效的检测与建议。

研究结论: 微调后的LLMs在物联网安全日志分析中表现出色，能够同时实现高效的异常检测和缓解建议，为网络安全提供了新的解决方案。

中文摘要: 日志分析是网络安全领域的一个重要研究方向，能够为网络和系统的威胁检测提供信息来源。本文提出了一种利用微调大语言模型（LLMs）进行物联网安全日志异常检测和缓解建议的流程。通过以传统机器学习分类器为基线，比较了三种开源LLMs在二分类和多分类异常检测中的表现，并采用了零样本、少样本提示和微调三种策略。结果表明，LLMs在多类攻击分类任务中优于基线模型。通过将检测到的威胁映射到MITRE CAPEC，定义一组物联网特定的缓解措施，并微调模型以结合这些措施，模型能够提供检测与建议的联合指导。

</details>


### [201] [CyberRAG: An agentic RAG cyber attack classification and reporting tool](https://arxiv.org/abs/2507.02424)
**中文标题：CyberRAG：一种基于代理的RAG网络攻击分类与报告工具**

*Francesco Blefari,Cristian Cosentino,Francesco Aurelio Pironti,Angelo Furfaro,Fabrizio Marozzo*

主要分类: cs.CR

摘要简述: CyberRAG是一种基于代理的RAG框架，用于实时分类、解释和结构化报告网络攻击，通过动态控制流和自适应推理降低误报率，提升解释性。


<details>
  <summary>详细信息</summary>
研究动机: 大型企业的入侵检测和预防系统（IDS/IPS）每小时生成大量警报，传统机器学习检测器误报率高，标准RAG管道检索无关上下文且无法合理解释预测。CyberRAG旨在解决这些问题。

研究方法: CyberRAG采用模块化、基于代理的RAG框架，包括一个中央LLM代理、一组针对特定攻击家族的微调分类器、工具适配器以及迭代检索与推理循环，动态优化威胁标签和自然语言解释。

研究结果: CyberRAG在每类攻击中准确率超过94%，总分类准确率达94.92%，生成的解释在BERTScore中得分为0.94，在GPT-4专家评估中得分为4.9/5。

研究结论: CyberRAG通过代理设计和专家导向的RAG，实现了高检测准确率和可信的解释，为半自主网络防御工作流提供了实用且可扩展的解决方案。

中文摘要: 大型企业的入侵检测和预防系统（IDS/IPS）每小时可生成数十万条警报，使安全分析师淹没在需要深厚且快速演变的领域知识的日志中。传统的机器学习检测器虽能减少警报量，但仍存在高误报率，而标准的单次检索增强生成（RAG）管道常检索无关上下文且无法合理解释预测。为克服这些不足，我们提出CyberRAG，一种模块化、基于代理的RAG框架，提供网络攻击的实时分类、解释和结构化报告。中央LLM代理协调（i）一组针对特定攻击家族的微调分类器；（ii）用于丰富和警报的工具适配器；（iii）迭代检索与推理循环，持续查询领域知识库直至证据既相关又自洽。与传统RAG系统不同，CyberRAG采用代理设计，支持动态控制流和自适应推理。这种以代理为中心的架构自主优化威胁标签和自然语言解释，减少误报并提升可解释性。该框架完全可扩展：只需添加分类器即可支持新攻击类型，无需重新训练核心代理。CyberRAG的评估结果显示，每类攻击准确率超过94%，通过语义协调最终分类准确率达94.92%。生成的解释在BERTScore中得分为0.94，在基于GPT-4的专家评估中得分为4.9/5。这些结果表明，代理化、专家导向的RAG可将高检测准确率与可信的、SOC就绪的文本结合，为半自主网络防御工作流提供实用且可扩展的路径。

</details>


### [202] [Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](https://arxiv.org/abs/2507.02735)
**中文标题：Meta SecAlign：一种抵御提示注入攻击的安全基础大语言模型**

*Sizhe Chen,Arman Zharmagambetov,David Wagner,Chuan Guo*

主要分类: cs.CR

摘要简述: Meta SecAlign是首个开源且开放权重的LLM，具备内置模型级防御功能，能有效抵御提示注入攻击，并在通用指令跟随和下游任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 提示注入攻击对LLM集成应用构成重大安全威胁。尽管模型级防御效果显著，但目前商业级模型的防御机制多为闭源。AI安全社区需要开源模型，以通过开放研究推动攻击与防御的共同发展。

研究方法: 开发Meta SecAlign，采用改进版SOTA SecAlign防御技术，提供完整的训练方案。模型在通用指令调优数据集上训练，具备对未见下游任务（如工具调用和网络导航）的安全防护能力。

研究结果: Meta-SecAlign-70B在9个效用基准和7个安全基准测试中表现优异，其安全性和通用性与闭源商业LLM相当，且在提示注入攻击下具备SOTA鲁棒性。

研究结论: Meta SecAlign为开源社区提供了首个具备商业级性能和安全性的LLM，推动了提示注入攻击防御的开放研究。

中文摘要: 提示注入攻击对集成大语言模型（LLM）的应用构成重大安全威胁。模型级防御虽效果显著，但目前商业级模型的防御机制多为闭源。我们认为AI安全社区需要开源模型，通过开放研究推动攻击与防御的共同发展，从而科学提升对提示注入攻击的防御能力。为此，我们开发了Meta SecAlign，这是首个开源且开放权重的LLM，具备内置模型级防御功能，并达到商业级模型性能。我们提供了完整的训练方案，采用改进版SOTA SecAlign防御技术。在9个效用基准和7个安全基准测试中，Meta SecAlign尽管基于通用指令调优数据集训练，仍能对未见下游任务（如工具调用和网络导航）提供安全保障，同时保持通用指令跟随能力。我们的最佳模型——Meta-SecAlign-70B——在提示注入攻击下具备SOTA鲁棒性，其效用与闭源商业LLM相当。

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [203] [FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports](https://arxiv.org/abs/2507.01991)
**中文标题：FinAI-BERT：一种基于Transformer的模型用于金融报告中句子级别的AI披露检测**

*Muhammad Bilal Zafar*

主要分类: q-fin.CP

摘要简述: 本文提出FinAI-BERT，一种基于Transformer的模型，用于在金融报告中检测句子级别的AI披露。该模型在手动标注的1,586个句子数据集上表现优异，准确率达99.37%，优于传统基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在金融服务中的广泛应用，现有工具在检测公司文件中AI相关内容时存在粒度粗、解释性差和鲁棒性不足的问题。本研究旨在开发一种更精细、可解释且稳健的AI披露检测方法。

研究方法: 研究采用FinAI-BERT，一种基于Transformer的领域适应语言模型，在1,586个来自美国银行年报的句子数据集上进行微调。模型通过SHAP进行可解释性分析，并进行了偏差分析和鲁棒性测试。

研究结果: FinAI-BERT在分类任务中表现卓越，准确率达99.37%，F1分数为0.993，显著优于逻辑回归、朴素贝叶斯、随机森林和XGBoost等传统方法。模型在句子长度、对抗输入和时间样本上均表现出稳定性。

研究结论: 本研究通过FinAI-BERT推动了金融NLP领域的发展，实现了细粒度、主题特定的分类。模型为分析师、监管机构和学者提供了一种可扩展且透明的解决方案，用于监测金融机构中AI的应用和表述。

中文摘要: 人工智能（AI）在金融服务中的广泛应用催生了对能够系统检测公司文件中AI相关披露工具的需求。尽管现有方法通常依赖于关键词扩展或文档级分类，但它们在粒度、可解释性和鲁棒性方面存在不足。本研究提出了FinAI-BERT，一种基于Transformer的领域适应语言模型，旨在对金融文本中句子级别的AI相关内容进行分类。该模型在手动标注且平衡的1,586个句子数据集上进行了微调，这些句子来自669份美国银行的年度报告（2015年至2023年）。FinAI-BERT实现了近乎完美的分类性能（准确率为99.37%，F1分数为0.993），优于逻辑回归、朴素贝叶斯、随机森林和XGBoost等传统基线方法。通过基于SHAP的标记归因确保了可解释性，而偏差分析和鲁棒性检查则证实了模型在句子长度、对抗输入和时间样本上的稳定性。从理论上讲，本研究通过利用Transformer架构实现了细粒度、主题特定的分类，推动了金融NLP的发展。从实践角度来看，它为分析师、监管机构和学者提供了一种可扩展且透明的解决方案，用于监测AI在金融机构中的扩散和表述。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [204] [Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System](https://arxiv.org/abs/2507.02000)
**中文标题：为何多兴趣公平性重要：基于超图对比多兴趣学习的公平对话推荐系统**

*Yongsen Zheng,Zongxuan Xie,Guohua Wang,Ziyao Liu,Liang Lin,Kwok-Yan Lam*

主要分类: cs.IR

摘要简述: 本文提出了一种新型框架HyFairCRS，通过超图对比多兴趣学习解决对话推荐系统中的多兴趣多样性公平问题，实验证明其有效缓解不公平性并达到最新性能。


<details>
  <summary>详细信息</summary>
研究动机: 推荐系统中的不公平性（如性别、种族、年龄或流行度偏见）会导致马太效应、过滤气泡和回音室等问题。现有方法多针对静态场景，而动态交互式对话推荐系统中的不公平问题更为严重，亟需解决。

研究方法: HyFairCRS通过对比学习构建多样化超图以捕捉用户多兴趣，并在对话中利用这些兴趣生成信息丰富的响应，同时确保动态用户-系统反馈循环中的公平性。

研究结果: 在两个对话推荐系统数据集上的实验表明，HyFairCRS不仅显著缓解了不公平性，还达到了最新的性能水平。

研究结论: HyFairCRS为动态对话推荐系统中的多兴趣公平问题提供了有效解决方案，实验验证了其优越性。

中文摘要: 不公平性是推荐系统（RSs）中一个众所周知的挑战，通常导致基于性别、种族、年龄或流行度等属性的偏见结果。尽管已有方法开始改善离线或静态场景中的公平推荐，但不公平性问题往往随时间加剧，引发马太效应、过滤气泡和回音室等严重问题。为解决这些挑战，我们提出了一种新型框架——基于超图对比多兴趣学习的公平对话推荐系统（HyFairCRS），旨在动态交互式对话推荐系统（CRSs）中促进多兴趣多样性公平。HyFairCRS首先通过对比学习构建多样化超图以捕捉广泛的用户兴趣，随后在对话中利用这些兴趣生成信息丰富的响应，并确保动态用户-系统反馈循环中的公平项目预测。在两个基于CRS的数据集上的实验表明，HyFairCRS不仅达到了最新性能水平，还有效缓解了不公平性。我们的代码发布于https://github.com/zysensmile/HyFairCRS。

</details>


### [205] [ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations](https://arxiv.org/abs/2507.02014)
**中文标题：ManifoldMind：基于动态双曲推理的可信推荐**

*Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic*

主要分类: cs.IR

摘要简述: ManifoldMind是一种基于双曲空间的概率几何推荐系统，通过动态调整曲率和概率球嵌入，实现个性化不确定性建模和语义探索，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有推荐系统通常使用固定曲率和刚性嵌入，无法灵活建模用户和项目的不确定性，也难以支持多跳推理和语义探索。ManifoldMind旨在解决这些问题，提供更透明和可信的推荐。

研究方法: ManifoldMind将用户、项目和标签表示为自适应曲率的概率球，利用曲率感知的语义核实现多跳推理，避免对浅层交互的过拟合。

研究结果: 在四个公开基准测试中，ManifoldMind在NDCG、校准性和多样性上优于基线模型，并能生成显式的推理路径。

研究结论: ManifoldMind通过动态双曲推理和不确定性建模，为稀疏或抽象领域提供了透明、可信且探索驱动的推荐。

中文摘要: 我们提出了ManifoldMind，一种用于在双曲空间中对语义层次结构进行探索性推理的概率几何推荐系统。与现有方法不同，ManifoldMind将用户、项目和标签表示为自适应曲率的概率球，支持个性化不确定性建模和几何感知的语义探索。曲率感知的语义核支持软性多跳推理，使模型能够探索多样化的概念路径，而非局限于浅层或直接交互。在四个公开基准测试中，ManifoldMind在NDCG、校准性和多样性上均优于强基线模型。此外，ManifoldMind生成显式的推理路径，为稀疏或抽象领域提供了透明、可信且探索驱动的推荐。

</details>


### [206] [When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search](https://arxiv.org/abs/2507.02139)
**中文标题：当LLMs意见相左时：SDG搜索中的相关性过滤偏差与检索分歧诊断**

*William A. Ingram,Bipasha Banerjee,Edward A. Fox*

主要分类: cs.IR

摘要简述: 研究发现，大型语言模型（LLMs）在标注文档相关性时存在系统性分歧，导致检索结果不一致。通过分析LLaMA和Qwen在SDG相关学术摘要上的分歧，揭示了分歧案例的词汇模式、排名行为和可预测性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在信息检索中广泛用于标注文档相关性，但不同模型在边缘案例上常出现分歧，影响下游检索效果。本研究旨在探讨这种分歧的性质及其对检索任务的影响。

研究方法: 研究选取了与可持续发展目标（SDGs）1、3和7相关的学术摘要，使用LLaMA和Qwen两种开源LLMs进行标注。通过分析分歧子集的词汇特征、排名行为和分类可预测性，揭示分歧的系统性。

研究结果: 结果表明，模型分歧是系统性的而非随机的：分歧案例具有一致的词汇模式，在共享评分函数下产生不同的高排名输出，且通过简单分类器可区分（AUC超过0.74）。

研究结论: LLM基于的过滤在文档检索中引入了结构化变异性，即使在控制提示和共享排名逻辑下。建议将分类分歧作为检索评估的分析对象，特别是在政策相关或主题搜索任务中。

中文摘要: 大型语言模型（LLMs）越来越多地用于信息检索流程中的文档相关性标注，尤其是在缺乏人工标注数据的领域。然而，不同模型在边缘案例上常出现分歧，引发了对下游检索影响的担忧。本研究探讨了两种开源LLMs（LLaMA和Qwen）在可持续发展目标（SDGs）1、3和7相关学术摘要上的标注分歧。我们分离了分歧子集，并分析了其词汇特性、排名行为和分类可预测性。结果显示，模型分歧是系统性的而非随机的：分歧案例表现出一致的词汇模式，在共享评分函数下产生不同的高排名输出，且通过简单分类器可区分（AUC超过0.74）。这些发现表明，即使在控制提示和共享排名逻辑下，LLM基于的过滤也会在文档检索中引入结构化变异性。我们建议将分类分歧作为检索评估的分析对象，特别是在政策相关或主题搜索任务中。

</details>


### [207] [Content filtering methods for music recommendation: A review](https://arxiv.org/abs/2507.02282)
**中文标题：音乐推荐中的内容过滤方法：综述**

*Terence Zeng,Abhishek K. Umrawal*

主要分类: cs.IR

摘要简述: 本文综述了音乐推荐系统中内容过滤方法的研究现状，重点探讨了如何通过内容过滤缓解协同过滤中的偏差问题，并分析了歌词分析和音频信号处理等技术。


<details>
  <summary>详细信息</summary>
研究动机: 音乐推荐系统中，协同过滤方法因用户交互稀疏性而效果有限。本文旨在探讨内容过滤方法如何解决这一问题，并分析不同分类技术的潜在冲突。

研究方法: 综述了当前内容过滤方法的研究，包括基于大型语言模型（LLMs）的歌词分析和音频信号处理技术，并讨论了这些方法的潜在冲突及解决途径。

研究结果: 研究发现，内容过滤方法能有效缓解协同过滤的偏差问题，但不同分析技术间可能存在冲突，需进一步研究以解决这些差异。

研究结论: 内容过滤在音乐推荐系统中具有重要潜力，但需进一步研究以优化不同技术的整合与冲突解决。

中文摘要: 推荐系统在现代音乐流媒体平台中至关重要，塑造了用户发现和与歌曲互动的方式。协同过滤是推荐系统中的一种常见方法，它基于与目标用户具有相似收听模式的用户偏好推荐内容。然而，这种方法在交互稀疏的媒体中效果较差，音乐正是这样一种媒介，因为音乐流媒体服务的普通用户永远不会收听绝大多数曲目。由于这种稀疏性，需要通过其他方法解决若干挑战。本文综述了当前研究中解决这些挑战的现状，重点探讨了内容过滤在缓解协同过滤方法固有偏差中的作用。我们探索了用于内容过滤的多种歌曲分类方法，包括使用大型语言模型（LLMs）的歌词分析和音频信号处理技术。此外，我们还讨论了这些不同分析方法之间的潜在冲突，并提出了解决此类差异的途径。

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [208] [Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning](https://arxiv.org/abs/2507.01972)
**中文标题：Error**

*Hadi Keramati,Samaneh Jazayeri*

主要分类: q-fin.PM

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [209] [Legal Requirements Translation from Law](https://arxiv.org/abs/2507.02846)
**中文标题：从法律中翻译法律需求**

*Anmol Singhal,Travis Breaux*

主要分类: cs.SE

摘要简述: 本文提出了一种基于文本蕴含和上下文学习的方法，用于从法律文本中自动生成可编码为Python代码的规范表示，以减少手动标注需求并提升对新法规的适用性。


<details>
  <summary>详细信息</summary>
研究动机: 小型组织和初创公司缺乏法律专业知识，确保软件系统合规性是一项资源密集型任务。现有方法未能充分考虑法律元数据属性间的交互关系，且依赖手动标注或启发式机器学习，泛化能力有限。

研究方法: 采用文本蕴含和上下文学习方法，设计了一个领域特定的Python类结构作为元模型，捕捉法律元数据的结构性和语义性及其相互关系，自动生成可执行的Python代码表示。

研究结果: 在13个美国州数据泄露通知法律上评估，生成的表示通过约89.4%的测试用例，精确率和召回率分别为82.2和88.7。

研究结论: 该方法减少了对手动标注数据的依赖，提升了法律文本的自动化处理能力，为软件合规性提供了高效解决方案。

中文摘要: 软件系统必须遵守法律法规，这对缺乏专门法律专业知识的小型组织和初创公司来说是一项资源密集型任务。从法规中提取元数据以引出软件的法律需求是确保合规性的关键步骤。然而，由于法律文本的冗长和复杂性，这是一项繁琐的任务。尽管先前的工作追求从法律文本中提取结构和语义元数据的自动化方法，但仍存在关键限制：它们未考虑与这些元数据类型相关的属性之间的相互作用和相互关系，且依赖手动标注或启发式驱动的机器学习，对新文档的泛化能力不足。本文提出了一种基于文本蕴含和上下文学习的方法，用于自动生成法律文本的规范表示，可编码并执行为Python代码。我们的表示从一个手动设计的Python类结构中实例化，作为领域特定的元模型，捕捉结构和语义法律元数据及其相互关系。这一设计选择减少了对大型手动标注数据集的需求，并增强了对未见法规的适用性。我们在13个美国州数据泄露通知法律上评估了我们的方法，结果表明生成的表示通过了约89.4%的测试用例，精确率和召回率分别为82.2和88.7。

</details>


### [210] [Requirements Elicitation Follow-Up Question Generation](https://arxiv.org/abs/2507.02858)
**中文标题：需求获取中后续问题生成的研究**

*Yuchen Shen,Anmol Singhal,Travis Breaux*

主要分类: cs.SE

摘要简述: 本文研究了使用GPT-4o在需求获取访谈中实时生成后续问题的潜力，发现其生成的问题在清晰度、相关性和信息量上不亚于人工编写的问题，且在指导下表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 需求获取访谈中，访谈者面临领域不熟悉、认知负荷高和信息过载等挑战，难以实时生成合适的问题。本文旨在探索大型语言模型（如GPT-4o）能否帮助访谈者提升问题生成的质量和效率。

研究方法: 研究基于常见访谈错误类型框架，提出两种方法：一种是无指导的LLM生成问题，另一种是基于错误类型指导的LLM生成问题。通过对照实验比较LLM生成问题与人工编写问题的表现。

研究结果: 实验表明，LLM生成的问题在清晰度、相关性和信息量上与人工编写的问题相当；在错误类型指导下，LLM生成的问题甚至优于人工编写的问题。

研究结论: 大型语言模型在需求获取访谈中具有实际应用潜力，能够帮助访谈者实时生成高质量问题，提升访谈效率和质量。

中文摘要: 访谈是需求获取中广泛使用的技术，用于收集利益相关者对软件系统的需求、偏好和期望。有效的访谈需要熟练的访谈者实时提出合适的问题，但面临领域不熟悉、认知负荷高和信息过载等挑战。近年来，大型语言模型（LLMs）在文本摘要和蕴含等自然语言处理任务中表现出色。为支持访谈者，我们研究了GPT-4o在需求获取中生成后续问题的应用，基于常见访谈错误类型框架。此外，我们描述了根据受访者发言生成问题的方法。我们报告了两个对照实验：一个评估无指导的LLM生成问题与人工编写问题，另一个评估基于错误类型指导的LLM生成问题。结果显示，两种实验中，LLM生成的问题在清晰度、相关性和信息量上均不亚于人工编写的问题；在错误类型指导下，LLM生成的问题甚至优于人工编写的问题。这表明LLMs有潜力帮助访谈者实时提升需求获取访谈的质量和效率。

</details>


### [211] [VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software](https://arxiv.org/abs/2507.02376)
**中文标题：VeFIA：一种高效的垂直联邦协作软件推理审计框架**

*Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang*

主要分类: cs.SE

摘要简述: 本文提出了一种高效的垂直联邦学习推理审计框架VeFIA，用于确保数据方的推理软件执行正确性，同时保护数据隐私且不增加系统延迟。


<details>
  <summary>详细信息</summary>
研究动机: 现有垂直联邦学习（VFL）缺乏对数据方推理软件执行正确性的审计机制，可能导致推理结果不可靠。

研究方法: VeFIA框架利用可信执行环境（TEE）和协调器，通过随机采样验证数据方的计算结果，确保执行正确性。

研究结果: VeFIA在异常推理超过5.4%时能以99.99%的概率检测到问题，且随机采样验证的准确率、召回率和真阳性率均达到100%。

研究结论: VeFIA是首个讨论VFL中推理软件执行正确性的研究，为大规模推理提供了高效、隐私保护的审计方案。

中文摘要: 垂直联邦学习（VFL）是一种无需访问参与者数据的跨机构协作分布式AI软件部署机制。然而，现有VFL工作缺乏对数据方推理软件执行正确性的审计机制。为解决这一问题，我们设计了一种垂直联邦推理审计（VeFIA）框架。VeFIA帮助任务方在大规模推理中审计数据方的推理软件是否按预期执行，同时不泄露数据隐私或增加系统延迟。VeFIA的核心在于任务方可通过可信执行环境（TEE）和协调器的推理结果验证数据方计算结果的正确性。VeFIA保证，只要异常推理超过5.4%，任务方就能以99.99%的概率检测到执行异常，且不会增加在线推理延迟。VeFIA的随机采样验证在检测异常推理时实现了100%的阳性预测值、阴性预测值和真阳性率。据我们所知，这是首篇讨论VFL中推理软件执行正确性的论文。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [212] [Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain](https://arxiv.org/abs/2507.02016)
**中文标题：为信念-欲望-意图机器人设计有效解释：何时解释及解释什么**

*Cong Wang,Roberto Calandra,Verena Klös*

主要分类: cs.RO

摘要简述: 研究探讨了如何为执行复杂任务的机器人设计有效的解释机制，以帮助用户理解其意图，避免因意外行为引发困惑或不满。


<details>
  <summary>详细信息</summary>
研究动机: 当机器人在日常生活中执行复杂且依赖上下文的任务时，其行为可能与用户预期不符，导致困惑。通过解释机器人的推理过程，可以帮助用户理解其意图，但解释的时机和内容至关重要，以避免引起用户反感。

研究方法: 研究调查了用户对机器人解释需求和内容的偏好，特别是在厨房清洁任务中。基于用户反馈，提出了两种算法：一种用于识别意外行为，另一种用于构建简洁有效的解释。这些算法可轻松集成到BDI（信念-欲望-意图）机器人的推理过程中。

研究结果: 研究发现，用户希望在意外情况下获得解释，并偏好简洁的内容，明确说明行为背后的意图及相关的上下文因素。提出的算法能够有效识别意外行为并生成用户友好的解释。

研究结论: 通过结合用户偏好和算法设计，研究为BDI机器人提供了更优的解释机制，改善了人机交互体验，特别是在依赖上下文和用户个性化解释的场景中。

中文摘要: 当机器人在日常生活中执行复杂且依赖上下文的任务时，其行为可能与用户预期不符，导致困惑。解释机器人的推理过程有助于用户理解其意图。然而，解释的时机和内容对避免用户反感至关重要。我们研究了用户在厨房清洁任务中对机器人解释需求和内容的偏好。结果显示，用户希望在意外情况下获得解释，并偏好简洁的内容，明确说明行为背后的意图及相关的上下文因素。基于这些发现，我们提出了两种算法，用于识别意外行为并为BDI机器人构建有效解释。这些算法可轻松集成到BDI推理过程中，为依赖上下文和用户个性化解释的人机交互提供了更好的途径。

</details>


### [213] [Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN](https://arxiv.org/abs/2507.02171)
**中文标题：基于自监督循环神经网络的生物启发式机器人轨迹规划**

*Miroslav Cibula,Kristína Malinovská,Matthias Kerzel*

主要分类: cs.RO

摘要简述: 本文提出了一种基于自监督循环神经网络（RNN）的生物启发式机器人轨迹规划方法，通过仅使用正向和逆向运动学模型，成功生成适应复杂任务的轨迹。


<details>
  <summary>详细信息</summary>
研究动机: 传统的机器人轨迹规划方法（如基于采样的规划器）计算成本高，而完全监督的序列学习方法仅模仿观察到的轨迹，无法确保目标达成。本文旨在通过自监督学习，结合循环神经网络，实现更高效的轨迹规划。

研究方法: 提出了一种基于自监督学习的循环神经网络架构，利用给定的正向和逆向运动学模型生成轨迹，无需依赖大量标注数据。

研究结果: 实验表明，该方法能够仅通过运动学模型学习生成有效轨迹，适用于需要自适应解决方案的复杂操作任务。

研究结论: 本文提出的自监督学习方法为机器人轨迹规划提供了一种高效且适应性强的解决方案，有望应用于更复杂的任务场景。

中文摘要: 机器人轨迹规划是指生成一系列关节配置，使机器人或其操作臂从初始状态移动到目标状态，同时考虑机器人运动学和环境约束。传统方法通常采用基于采样的规划器，计算量大。近年研究表明，轨迹规划也可以通过监督序列学习实现，仅需单次或固定次数的神经网络计算，确保计算时间可控。然而，这种完全监督方法仅模仿观察到的轨迹，而非基于目标达成情况学习。本文在此基础上提出了一种基于循环神经网络的自监督学习方案，用于构建轨迹模型。我们在机器人臂的运动规划任务中评估了该方法的可行性。结果表明，该模型能够仅通过给定的正向和逆向运动学模型学习生成轨迹，表明这一新方法可为需要自适应解决方案的复杂操作任务提供便利。

</details>


### [214] [MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping](https://arxiv.org/abs/2507.02672)
**中文标题：MISCGrasp：利用多尺度集成和对比学习增强体积抓取**

*Qingyu Fan,Yinghao Cai,Chao Li,Chunting Jiao,Xudong Zheng,Tao Lu,Bin Liang,Shuo Wang*

主要分类: cs.RO

摘要简述: MISCGrasp提出了一种结合多尺度特征提取和对比学习的体积抓取方法，通过Insight Transformer和Empower Transformer实现高低层特征的交互与选择，提升了机器人抓取的适应性和性能。


<details>
  <summary>详细信息</summary>
研究动机: 机器人抓取在面对形状和大小不同的物体时存在适应性挑战，需要一种能够平衡细节和整体结构的方法。

研究方法: MISCGrasp通过Insight Transformer实现高低层特征的交互，Empower Transformer选择最高层特征，结合多尺度对比学习确保特征一致性。

研究结果: 实验表明，MISCGrasp在模拟和真实环境中的桌面整理任务中优于基线方法和变体方法。

研究结论: MISCGrasp通过多尺度特征和对比学习的结合，显著提升了机器人抓取的适应性和性能。

中文摘要: 机器人抓取在适应形状和大小不同的物体时面临挑战。本文提出MISCGrasp，一种结合多尺度特征提取和对比特征增强的自适应体积抓取方法。通过Insight Transformer实现高低层特征的查询式交互，Empower Transformer选择性关注最高层特征，协同平衡细节几何和整体结构。此外，MISCGrasp利用多尺度对比学习挖掘正抓取样本间的相似性，确保多尺度特征的一致性。在模拟和真实环境中的大量实验表明，MISCGrasp在桌面整理任务中优于基线和变体方法。更多细节见https://miscgrasp.github.io/。

</details>


### [215] [MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real](https://arxiv.org/abs/2507.02864)
**中文标题：MultiGen：利用多模态生成模拟学习真实世界的多模态策略**

*Renhao Wang,Haoran Geng,Tingle Li,Feishi Wang,Gopala Anumanchipalli,Philipp Wu,Trevor Darrell,Boyi Li,Pieter Abbeel,Jitendra Malik,Alexei A. Efros*

主要分类: cs.RO

摘要简述: MultiGen框架通过将大规模生成模型与传统物理模拟器结合，实现多感官模拟，解决了多模态策略学习中的模拟难题，并在真实世界倒水任务中展示了零样本迁移能力。


<details>
  <summary>详细信息</summary>
研究动机: 机器人需要整合多种感官模态以在现实世界中有效行动，但大规模学习多模态策略仍具挑战性。模拟器虽为解决方案，但除视觉外，其他模态（如声音）难以模拟，导致多模态模拟到现实的迁移尚未实现。

研究方法: MultiGen框架将生成模型与传统物理模拟器结合，通过视频生成逼真音频，实现多感官模拟。以倒水任务为例，无需真实机器人数据即可训练多模态策略。

研究结果: 实验表明，MultiGen在真实世界倒水任务中实现了零样本迁移，能够处理新容器和液体，验证了生成模型在多模态模拟和缩小模拟与现实差距中的潜力。

研究结论: MultiGen通过生成模型解决了多模态模拟难题，成功实现了多模态策略的零样本迁移，为多模态模拟到现实的迁移提供了新思路。

中文摘要: 机器人需要整合多种感官模态以在现实世界中有效行动，但大规模学习多模态策略仍具挑战性。模拟器虽为解决方案，但除视觉外，其他模态（如声音）难以模拟，导致多模态模拟到现实的迁移尚未实现。本文提出MultiGen框架，将大规模生成模型与传统物理模拟器结合，实现多感官模拟。以倒水任务为例，通过视频生成逼真音频，无需真实机器人数据即可训练多模态策略。实验表明，MultiGen在真实世界倒水任务中实现了零样本迁移，能够处理新容器和液体，验证了生成模型在多模态模拟和缩小模拟与现实差距中的潜力。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [216] [Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents](https://arxiv.org/abs/2507.02287)
**中文标题：透视绿色：基于文本的分类与绿色专利的企业回报**

*Lapo Santarlasci,Armando Rungi,Antonio Zinilli*

主要分类: econ.GN

摘要简述: 本文利用自然语言处理技术从官方支持文件中识别“真正”的绿色专利，发现仅占以往文献分类的20%，并验证了持有此类专利对企业财务表现的积极影响。


<details>
  <summary>详细信息</summary>
研究动机: 现有文献对绿色专利的分类较为宽泛，缺乏精确性。本文旨在通过文本分析技术，识别出真正与环境技术相关的专利，并研究其对企业的实际经济影响。

研究方法: 使用约1240万被以往文献分类为绿色的专利作为训练数据，通过神经网络扩展基础词典，生成与环境技术相关的向量表示。随后测试分类效果，并分析专利的引用情况。此外，结合欧盟企业财务数据，验证绿色专利对企业财务指标的影响。

研究结果: 发现“真正”绿色专利仅占以往分类的20%，且被后续发明引用率低1%。持有至少一项此类专利的企业在销售额、市场份额和生产率上表现更优，高创新性绿色专利还能带来更高利润。

研究结论: 文本分析技术能更精确地分类绿色专利，为政策制定提供支持。绿色专利对企业财务表现有显著正向影响，尤其是高创新性专利。

中文摘要: 本文引入自然语言处理技术，从官方支持文件中识别“真正”的绿色专利。我们以约1240万被以往文献分类为绿色的专利为训练数据，通过神经网络扩展基础词典，生成与环境技术相关的向量表示。测试发现，“真正”绿色专利仅占以往分类的20%，且被后续发明引用率低1%。在第二部分，我们检验了绿色专利与欧盟企业财务数据的关系。控制反向因果后，发现持有至少一项“真正”绿色专利能提升销售额、市场份额和生产率。若聚焦高创新性绿色专利，还能带来更高利润。研究强调了文本分析在精细专利分类中的重要性，为多领域政策制定提供支持。

</details>
