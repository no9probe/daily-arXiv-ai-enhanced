<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 26]
- [cs.CV](#cs.CV) [Total: 83]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.NE](#cs.NE) [Total: 2]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.CR](#cs.CR) [Total: 7]
- [eess.IV](#eess.IV) [Total: 4]
- [physics.optics](#physics.optics) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 2]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 3]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [eess.AS](#eess.AS) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 21]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.RO](#cs.RO) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2507.02088)
**中文标题：McBE：面向大型语言模型的多任务中文偏见评估基准**

*Tian Lan,Xiangdong Su,Xu Liu,Ruirui Wang,Ke Chang,Jiang Li,Guanglai Gao*

主要分类: cs.CL

摘要简述: 本文提出了一个多任务中文偏见评估基准（McBE），包含4077个偏见评估实例，覆盖12个偏见类别和82个子类别，并引入5种评估任务，用于全面衡量大型语言模型（LLMs）的偏见。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在各类NLP任务中的广泛应用，其内在偏见逐渐显现。现有偏见评估数据集多基于英语和北美文化，且仅支持单一评估任务，无法全面衡量LLMs的偏见。中文及文化背景下的偏见评估数据集稀缺，亟需一个多任务、多类别的评估基准。

研究方法: 本文构建了一个多任务中文偏见评估基准（McBE），包含4077个偏见评估实例，覆盖12个偏见类别和82个子类别，并引入5种评估任务。通过这一基准，对多个不同系列和参数规模的流行LLMs进行了偏见评估。

研究结果: 评估结果显示，所有测试的LLMs均表现出不同程度的偏见。通过深入分析结果，本文为LLMs的偏见问题提供了新的见解。

研究结论: McBE为中文语境下的LLMs偏见评估提供了全面且多样化的基准，填补了现有研究的空白，并为未来偏见缓解研究提供了重要参考。

中文摘要: 随着大型语言模型（LLMs）在各类NLP任务中的广泛应用，其内在偏见逐渐显现。因此，衡量LLMs的偏见对降低其伦理风险至关重要。然而，现有偏见评估数据集多基于英语和北美文化，其偏见类别并不完全适用于其他文化。基于中文语言和文化的数据集稀缺。更重要的是，这些数据集通常仅支持单一评估任务，无法从多角度评估LLMs的偏见。为解决这些问题，本文提出了一个多任务中文偏见评估基准（McBE），包含4077个偏见评估实例，覆盖12个偏见类别和82个子类别，并引入5种评估任务，提供了广泛的类别覆盖、内容多样性和全面的衡量标准。此外，我们还评估了多个不同系列和参数规模的流行LLMs。总体而言，这些LLMs均表现出不同程度的偏见。通过对结果的深入分析，本文为LLMs的偏见问题提供了新的见解。

</details>


### [2] [Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization](https://arxiv.org/abs/2507.02145)
**中文标题：推理与否？对话摘要中推理型大语言模型的全面评估**

*Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira*

主要分类: cs.CL

摘要简述: 本文首次全面评估了推理型与非推理型大语言模型在对话摘要任务中的表现，发现显式逐步推理并未显著提升摘要质量，反而可能导致冗长和不一致。


<details>
  <summary>详细信息</summary>
研究动机: 对话摘要在客户服务、会议分析等领域具有重要价值，但当前推理型大语言模型（如OpenAI-o1和DeepSeek-R1）在此任务中的表现尚未被系统评估。本文旨在填补这一空白。

研究方法: 研究对比了推理型与非推理型大语言模型在通用、角色导向和查询导向三类对话摘要任务中的表现，覆盖多语言、多领域和不同摘要长度，并采用自动指标和人工标准进行评估。

研究结果: 结果显示，显式逐步推理并未显著提升摘要质量，推理型模型常产生冗长、事实不一致且不够简洁的摘要。

研究结论: 当前推理型大语言模型在复杂对话摘要任务中存在局限性，需针对性优化建模和评估策略。

中文摘要: 对话摘要是一项具有重要实际价值的挑战性任务，涉及客户服务、会议分析和对话式人工智能等领域。尽管大语言模型（LLMs）在摘要任务中取得了显著进展，但逐步推理架构（如OpenAI-o1和DeepSeek-R1的长链思维实现）在需要同时满足抽象性和简洁性的对话场景中的表现尚未被探索。本研究首次对最先进的推理型与非推理型大语言模型在三大范式（通用、角色导向和查询导向对话摘要）中进行了全面系统的评估。研究覆盖多种语言、领域和摘要长度，并利用强基准（SAMSum、DialogSum、CSDS和QMSum）及先进的评估协议（包括基于LLM的自动指标和人工启发标准）。与其他推理密集型任务的趋势相反，我们的发现表明，显式逐步推理并未持续提升对话摘要质量。相反，与非推理型模型相比，推理型模型常产生冗长、事实不一致且不够简洁的摘要。通过场景特定分析和详细案例研究，我们进一步明确了显式推理在复杂对话语境中何时以及为何无法提升甚至阻碍摘要效果。本研究揭示了当前推理型大语言模型的局限性，并强调了针对实际对话摘要任务的建模和评估策略的必要性。

</details>


### [3] [Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer](https://arxiv.org/abs/2507.02199)
**中文标题：潜在链式思维？解码深度循环Transformer**

*Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu*

主要分类: cs.CL

摘要简述: 本文研究了深度循环Transformer模型Huginn-3.5B是否在潜在空间中形成链式思维（CoT）推理结构。通过多种探测技术（如Logit Lens和Coda Lens）分析模型在算术任务中的内部行为，发现潜在CoT的可解释性有限，且不同循环块的探测结果不一致。增加循环深度仅带来边际收益，远不及显式外部化推理步骤的模型。


<details>
  <summary>详细信息</summary>
研究动机: 链式思维（CoT）推理使Transformer语言模型在复杂数学和多步规划任务中表现优异，但标准解码器架构需将推理步骤外部化为自然语言，牺牲了效率。为捕捉难以用语言表达的推理过程，许多研究探索了在潜在空间中内部化推理的循环架构。本文旨在验证深度循环Transformer模型Huginn-3.5B是否支持潜在CoT。

研究方法: 研究使用Huginn-3.5B模型，这是一种深度循环Transformer，在推理时重复使用层而不增加参数数量。通过Logit Lens和Coda Lens等探测技术，分析模型在算术任务中的内部行为，追踪最终和中间结果令牌的排名轨迹。

研究结果: 研究发现潜在CoT的可解释性证据有限，且不同循环块的探测结果存在显著不一致性。隐藏状态的可解释性高度依赖于层索引和解码方法。增加循环深度仅带来边际收益，无法与显式外部化推理步骤的模型相比。

研究结论: 深度循环Transformer模型Huginn-3.5B在潜在空间中形成的CoT推理结构可解释性有限，且探测结果不一致。增加循环深度效果不明显，显式外部化推理步骤的模型仍更具优势。

中文摘要: 链式思维（CoT）推理使基于Transformer的语言模型在复杂数学和多步规划任务中表现优异。然而，在标准解码器架构中，这些推理步骤需外部化为自然语言，虽提高了可解释性，却牺牲了效率。为捕捉难以用语言表达的推理过程，许多研究探索了在潜在空间中内部化推理的循环架构，可能支持潜在CoT。本文研究了深度循环Transformer模型Huginn-3.5B是否支持此类推理结构。该模型在推理时重复使用层而不增加参数数量。我们通过Logit Lens和Coda Lens等探测技术分析模型在算术任务中的内部行为。结果显示，通过追踪最终和中间结果令牌的排名轨迹，潜在CoT的可解释性证据有限。此外，我们发现不同循环块的探测结果存在显著不一致性，隐藏状态的可解释性高度依赖于层索引和解码方法。最后，实证表明增加循环深度仅带来边际收益，远不及显式外部化推理步骤的模型。代码见https://github.com/wenquanlu/huginn-latent-cot。

</details>


### [4] [GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons](https://arxiv.org/abs/2507.02221)
**中文标题：GDC Cohort Copilot：基于AI的基因组数据共享平台队列筛选助手**

*Steven Song,Anirudh Subramanyam,Zhenyu Zhang,Aarti Venkat,Robert L. Grossman*

主要分类: cs.CL

摘要简述: GDC Cohort Copilot是一款开源工具，通过自然语言描述帮助用户从基因组数据共享平台（GDC）中筛选患者队列，并利用本地部署的大语言模型（LLM）优化生成结果。


<details>
  <summary>详细信息</summary>
研究动机: GDC平台提供了高质量的癌症基因组数据，但用户（尤其是新手）在通过图形化界面筛选复杂队列时可能面临困难。自然语言描述可能更直观地表达用户需求。

研究方法: 开发了GDC Cohort Copilot工具，通过用户输入的自然语言描述自动生成GDC队列筛选条件，并提供交互界面供用户进一步优化。同时，评估了多种大语言模型（LLMs），并选择本地部署的开源模型作为核心。

研究结果: 本地部署的GDC Cohort LLM在生成GDC队列时表现优于GPT-4o，工具已开源并提供Docker镜像和模型权重。

研究结论: GDC Cohort Copilot通过自然语言交互简化了队列筛选流程，且本地模型表现更优，为GDC用户提供了高效的工具支持。

中文摘要: 动机：基因组数据共享平台（GDC）通过统一的患者队列分析和筛选平台提供高质量的癌症基因组数据。尽管用户可以通过图形化队列构建工具交互式创建复杂队列，但用户（尤其是新手）可能难以从数百个字段中筛选特定队列描述符。然而，用户可能更擅长用自然语言描述所需队列。

结果：我们推出了GDC Cohort Copilot，这是一款开源工具，用于从GDC中筛选队列。该工具根据用户输入的自然语言描述自动生成GDC队列筛选条件，并将队列导出回GDC进行进一步分析。交互式界面允许用户进一步优化生成的队列。我们开发并评估了多种大语言模型（LLMs），结果表明本地部署的开源GDC Cohort LLM在生成GDC队列时优于GPT-4o。

可用性与实现：GDC Cohort Copilot的独立Docker镜像可在https://quay.io/repository/cdis/gdc-cohort-copilot获取。源代码位于https://github.com/uc-cdis/gdc-cohort-copilot。GDC Cohort LLM模型权重可在https://huggingface.co/uc-ctds下载。

</details>


### [5] [MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent](https://arxiv.org/abs/2507.02259)
**中文标题：MemAgent：基于多对话强化学习的长上下文LLM内存代理**

*Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou*

主要分类: cs.CL

摘要简述: MemAgent通过多对话强化学习优化长文本处理，能够在8K上下文中训练并扩展到3.5M任务，性能损失低于5%。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有长度外推、高效注意力和内存模块的改进，但在线性复杂度下处理无限长文档且性能不下降仍是长文本处理的终极挑战。

研究方法: 提出MemAgent工作流，分段读取文本并使用覆盖策略更新内存；扩展DAPO算法，通过独立上下文多对话生成进行训练。

研究结果: MemAgent在32K文本上训练后，可外推至3.5M QA任务，性能损失<5%，并在512K RULER测试中达到95%+。

研究结论: MemAgent展示了卓越的长上下文处理能力，为长文本任务提供了一种高效的端到端解决方案。

中文摘要: 尽管通过长度外推、高效注意力和内存模块有所改进，但在线性复杂度下处理无限长文档且性能不下降仍是长文本处理的终极挑战。我们直接以端到端方式优化长文本任务，并引入了一种新颖的代理工作流MemAgent，它分段读取文本并使用覆盖策略更新内存。我们扩展了DAPO算法，通过独立上下文多对话生成促进训练。MemAgent展示了卓越的长上下文能力，能够在8K上下文中训练并外推至3.5M QA任务，性能损失低于5%，并在512K RULER测试中达到95%+。

</details>


### [6] [DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning](https://arxiv.org/abs/2507.02302)
**中文标题：DoMIX：一种利用领域知识进行高效微调的框架**

*Dohoon Kim,Donghun Kang,Taesup Moon*

主要分类: cs.CL

摘要简述: 本文提出DoMIX框架，通过LoRA模块解决现有持续领域自适应预训练方法的高计算成本、数据顺序敏感性和单一模型通用性问题，实现高效、并行且任务定制的预训练。


<details>
  <summary>详细信息</summary>
研究动机: 现有持续领域自适应预训练（DAP）方法存在高计算成本、对增量数据顺序敏感以及无法为特定任务提供定制模型的问题。本文旨在解决这些挑战。

研究方法: DoMIX利用LoRA模块（一种参数高效微调方法），实现高效并行的领域自适应预训练，对领域顺序鲁棒，并能积累知识为特定任务提供定制模型。

研究结果: 实验表明，DoMIX不仅适用于DAP场景，还可扩展到标准LLM微调，显著降低计算成本和内存使用。

研究结论: DoMIX为持续领域自适应预训练提供了一种高效、灵活且任务定制化的解决方案，具有广泛的应用潜力。

中文摘要: 领域自适应预训练（DAP）因其在微调预训练模型中的有效性而受到关注。在此基础上，持续DAP被探索用于开发能够逐步整合不同领域数据集的预训练模型。然而，现有持续DAP方法存在以下局限性：（1）训练过程中计算成本和GPU内存使用较高；（2）对增量数据顺序敏感；（3）为所有终端任务提供单一通用模型，这与DAP的本质相矛盾。本文提出DoMIX，通过利用LoRA模块（一种代表性参数高效微调方法）解决这些挑战。我们的方法实现了高效且并行的领域自适应预训练，对领域顺序鲁棒，并能有效利用积累的知识为特定任务提供定制预训练模型。我们还展示了该方法可扩展到标准LLM微调场景。代码发布于https://github.com/dohoonkim-ai/DoMIX。

</details>


### [7] [Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models](https://arxiv.org/abs/2507.02357)
**中文标题：Coling-UniA在SciVQA 2025的任务：基于少样本检索和置信度集成的多模态大语言模型**

*Christian Jaumann,Annemarie Friedrich,Rainer Lienhart*

主要分类: cs.CL

摘要简述: 本文介绍了参加SciVQA 2025共享任务的系统，结合多模态大语言模型和少样本检索策略，通过模型置信度选择答案，最终在盲测数据中排名第三。


<details>
  <summary>详细信息</summary>
研究动机: 解决科学视觉问答任务中的多模态问题，提升模型在少样本情况下的表现，并通过置信度优化答案选择。

研究方法: 使用两种多模态大语言模型集成，结合少样本检索策略，根据图像和问题类型选择模型和设置，并通过模型置信度筛选答案。

研究结果: 在盲测数据中排名第三，平均F1得分为85.12（基于ROUGE-1、ROUGE-L和BERTS）。

研究结论: 系统在多模态科学问答任务中表现优异，少样本检索和置信度筛选策略有效提升了性能。

中文摘要: 本文介绍了我们参加SciVQA 2025科学视觉问答共享任务的系统。该系统集成了两种多模态大语言模型及多种少样本检索策略，并根据图像和问题类型选择模型和设置。答案选择基于模型的置信度。在盲测数据中，我们的系统在七支队伍中排名第三，平均F1得分为85.12（基于ROUGE-1、ROUGE-L和BERTS）。代码已公开。

</details>


### [8] [QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers](https://arxiv.org/abs/2507.02364)
**中文标题：QFFN-BERT：混合量子-经典Transformer中深度、性能与数据效率的实证研究**

*Pilsung Kang*

主要分类: cs.CL

摘要简述: 本文提出QFFN-BERT，一种混合量子-经典Transformer模型，通过用参数化量子电路（PQC）替换BERT的FFN模块，显著减少参数并提升性能。实验表明，该模型在完全数据设置下性能超越经典模型，并在少样本学习中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer中FFN模块参数占比高达三分之二，而现有研究多关注自注意力模块的量子化。本文旨在探索PQC在FFN中的应用，研究其深度、表达能力和可训练性之间的权衡。

研究方法: 设计了一种混合量子-经典Transformer（QFFN-BERT），将BERT的FFN模块替换为PQC层。PQC架构包含残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略，以确保稳定训练和高表达能力。

研究结果: 实验在SST-2和DBpedia基准上进行，结果显示QFFN-BERT在完全数据设置下达到基线模型102.0%的准确率，同时减少FFN参数99%以上。在少样本学习中，模型表现稳定且优于经典模型。

研究结论: 研究表明，PQC与深度学习原则协同设计时，可作为高效且参数节约的FFN替代方案。QFFN-BERT在性能和参数效率上均优于经典模型，尤其适合数据稀缺场景。

中文摘要: 参数化量子电路（PQC）近年来成为增强神经网络表达力的潜在组件。本文提出QFFN-BERT，一种混合量子-经典Transformer模型，其紧凑BERT变体的前馈网络（FFN）模块被PQC层替代。这一设计的动机在于FFN在标准Transformer编码块中参数占比约三分之二。以往研究主要将PQC集成到自注意力模块，而本文聚焦FFN，系统研究PQC深度、表达力与可训练性的权衡。最终PQC架构包含残差连接、$R_Y$和$R_Z$旋转及交替纠缠策略，以确保稳定训练和高表达力。在SST-2和DBpedia基准上的实验表明：1）精心配置的QFFN-BERT在完全数据设置下达到基线模型102.0%的准确率，超越经典模型的同时减少FFN参数99%以上；2）该模型在少样本学习中表现稳定且具竞争力，证实其数据高效潜力。这些结果得到对未优化PQC的消融实验支持，表明PQC与深度学习原则协同设计时，可作为高效且参数节约的经典FFN替代方案。

</details>


### [9] [Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection](https://arxiv.org/abs/2507.02378)
**中文标题：基于分布一致性和多样性感知的高效代码大语言模型训练数据选择方法**

*Weijie Lyu,Sheng-Jun Huang,Xuan Xia*

主要分类: cs.CL

摘要简述: 本文提出一种基于分布一致性和多样性感知的数据选择方法，显著提升代码大语言模型的训练效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前方法主要依赖大量数据提升模型性能，但忽视数据质量，导致训练效率低下。本文旨在通过高质量数据选择优化训练过程。

研究方法: 采用参数化模型进行代码数据选择，确保所选子集分布一致且多样，从而提升数据质量。

研究结果: 实验表明，仅使用10K样本，该方法在HumanEval和MBPP上分别提升2.4%和2.3%，优于其他采样方法。

研究结论: 该方法在显著降低计算成本的同时，有效提升模型性能，为高效训练代码大语言模型提供了新思路。

中文摘要: 近年来，大语言模型（LLMs）的进步显著提升了代码生成和程序理解能力，推动了软件工程的发展。当前方法主要通过利用大量数据提升模型性能，但过度关注数据量而忽视数据质量，降低了训练效率。为此，我们提出一种基于参数化模型的代码数据选择方法，旨在同时提升训练效率和模型性能。该方法通过优化参数化模型，确保所选子集分布一致且多样，从而保证数据质量。实验结果显示，仅使用10K样本，我们的方法在HumanEval和MBPP上分别取得2.4%和2.3%的提升，优于92K全样本基线及其他采样方法。这表明我们的方法在显著降低计算成本的同时，有效提升了模型性能。

</details>


### [10] [Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability](https://arxiv.org/abs/2507.02407)
**中文标题：跨领域数据集上的Akan ASR模型基准测试：性能、可扩展性和适应性的比较评估**

*Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame*

主要分类: cs.CL

摘要简述: 本研究通过比较七种基于Transformer架构的Akan ASR模型在四个不同领域的Akan语音数据集上的表现，揭示了模型在跨领域任务中的性能差异和错误行为，强调了针对低资源语言（LRL）应用时需考虑领域适应和架构选择。


<details>
  <summary>详细信息</summary>
研究动机: 现有ASR研究多基于同领域数据集评估模型性能，而忽略了模型在多样化语音环境中的泛化能力。本研究旨在填补这一空白，通过跨领域数据集评估Akan ASR模型的性能、可扩展性和适应性。

研究方法: 研究选取了七种基于Transformer架构的Akan ASR模型（如Whisper和Wav2Vec2），并在四个不同领域的Akan语音数据集上进行测试，包括文化相关图像描述、非正式对话、圣经经文朗读和自发性金融对话。通过比较词错误率和字符错误率，分析模型在不同领域的表现。

研究结果: 结果显示，模型性能高度依赖训练领域，跨领域时准确率显著下降。Whisper模型生成的转录错误更流畅但可能误导，而Wav2Vec2在陌生输入下产生更明显但难以解释的错误。

研究结论: 研究强调了针对低资源语言应用时需考虑领域适应技术、自适应路由策略和多语言训练框架的重要性，同时需权衡ASR错误的可读性与透明性。

中文摘要: 现有大多数自动语音识别（ASR）研究使用同领域数据集评估模型，但很少评估其在多样化语音环境中的泛化能力。本研究通过使用四个Akan语音语料库对七种基于Transformer架构（如Whisper和Wav2Vec2）的Akan ASR模型进行基准测试，填补了这一空白。这些数据集涵盖多个领域，包括文化相关图像描述、非正式对话、圣经经文朗读和自发性金融对话。通过比较词错误率和字符错误率，研究发现模型性能具有领域依赖性，仅在训练领域内表现最优，而在不匹配场景中准确率显著下降。此外，研究还揭示了Whisper和Wav2Vec2架构在错误行为上的差异：微调后的Whisper Akan模型生成的转录错误更流畅但可能误导，而Wav2Vec2在遇到陌生输入时产生更明显但难以解释的输出。这种ASR错误在可读性与透明性之间的权衡，在选择低资源语言（LRL）应用的架构时需予以考虑。这些发现强调了针对Akan及其他LRLs开发针对性领域适应技术、自适应路由策略和多语言训练框架的必要性。

</details>


### [11] [A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages](https://arxiv.org/abs/2507.02428)
**中文标题：社区驱动的低资源语言受损语音数据收集指南**

*Sumaya Ahmed Salihs,Isaac Wiafe,Jamal-Deen Abdulai,Elikem Doe Atsakpo,Gifty Ayoka,Richard Cave,Akon Obu Ekpezu,Catherine Holloway,Katrin Tomanek,Fiifi Baffoe Payin Winful*

主要分类: cs.CL

摘要简述: 本研究提出了一种社区驱动的数据收集方法，用于构建低资源语言中受损语音的自动语音识别（ASR）模型，并开发了一本“食谱”指导最佳实践。通过加纳的阿坎语数据集验证了方法的可行性。


<details>
  <summary>详细信息</summary>
研究动机: 旨在通过社区驱动的数据收集和ASR模型构建，实现ASR技术的民主化，尤其是为低资源语言和语音受损人群提供定制化的解决方案。

研究方法: 开发了一本“食谱”指导社区驱动的数据收集和ASR模型构建，并以加纳的阿坎语为案例，收集了语音受损人群的语音样本，创建了首个开源数据集。

研究结果: 成功构建了阿坎语的受损语音开源数据集，并展示了通过微调开源ASR模型提升对受损语音识别能力的初步成果。

研究结论: 通过社区驱动的方法和开源工具，能够为低资源语言和语音受损人群提供包容性的ASR技术，未来可推广至更多语言和场景。

中文摘要: 本研究提出了一种收集语音样本的方法，用于构建低资源语言中受损语音的自动语音识别（ASR）模型。其目标是通过开发一本“食谱”指导社区驱动的数据收集和ASR模型构建，实现ASR技术的民主化。作为概念验证，本研究首次整理了加纳广泛使用的土著语言阿坎语中的受损语音开源数据集。研究涉及了来自不同背景的语音受损参与者。最终的数据集、指南和开源工具均已公开，以帮助研究人员和从业者为语音受损人群开发定制化的包容性ASR技术。此外，本研究还展示了通过微调开源ASR模型提升对阿坎语受损语音识别能力的初步成果。

</details>


### [12] [IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders](https://arxiv.org/abs/2507.02506)
**中文标题：IndianBailJudgments-1200：一个用于印度保释判决法律NLP的多属性数据集**

*Sneha Deshmukh,Prathmesh Kamble*

主要分类: cs.CL

摘要简述: 本文介绍了印度保释判决数据集IndianBailJudgments-1200，包含1200份印度法院保释判决，标注了20多个属性，支持多种法律NLP任务。


<details>
  <summary>详细信息</summary>
研究动机: 由于印度等地区缺乏结构化数据集，法律NLP发展受限。本文旨在填补这一空白，提供首个专注于印度保释法学的公开数据集。

研究方法: 使用经过提示工程优化的GPT-4o流水线生成标注，并通过一致性验证，确保数据质量。

研究结果: 构建了包含1200份印度保释判决的数据集，标注了保释结果、IPC条款、犯罪类型和法律推理等20多个属性。

研究结论: IndianBailJudgments-1200为法律NLP任务（如结果预测、摘要和公平性分析）提供了重要资源，填补了印度保释法学领域的空白。

中文摘要: 由于缺乏结构化数据集，法律NLP在印度等地区发展不足。我们推出了IndianBailJudgments-1200，这是一个新的基准数据集，包含1200份印度法院关于保释决定的判决，标注了20多个属性，包括保释结果、IPC条款、犯罪类型和法律推理。标注通过经过提示工程优化的GPT-4o流水线生成并验证一致性。该资源支持多种法律NLP任务，如结果预测、摘要和公平性分析，是首个专注于印度保释法学的公开数据集。

</details>


### [13] [WebSailor: Navigating Super-human Reasoning for Web Agent](https://arxiv.org/abs/2507.02592)
**中文标题：WebSailor：为网络代理导航超人类推理**

*Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou*

主要分类: cs.CL

摘要简述: WebSailor是一种后训练方法，通过结构化采样和信息模糊化生成高不确定性任务，结合RFT冷启动和DUPO算法，显著提升开源模型在复杂信息搜索任务中的表现，接近专有代理的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有开源模型在复杂信息搜索任务中表现不佳，无法像专有代理（如DeepResearch）那样处理极端不确定性。本文旨在通过WebSailor方法填补这一能力差距。

研究方法: WebSailor通过结构化采样和信息模糊化生成高不确定性任务，采用RFT冷启动和DUPO（重复采样策略优化）算法进行训练，以提升模型在复杂信息搜索中的表现。

研究结果: WebSailor在复杂信息搜索任务中显著优于所有开源代理，性能接近专有代理，成功缩小了能力差距。

研究结论: WebSailor通过创新的后训练方法，成功提升了开源模型在复杂信息搜索任务中的表现，为缩小与专有代理的差距提供了有效途径。

中文摘要: 超越人类认知限制是LLM训练的关键前沿。专有代理系统（如DeepResearch）在极端复杂的信息搜索基准（如BrowseComp）上展示了超人类能力，这是此前开源模型无法实现的。我们认为其成功依赖于一种开源模型缺乏的复杂推理模式：在广阔信息空间中系统性降低极端不确定性的能力。基于这一洞察，我们提出了WebSailor，一种完整的后训练方法，旨在培养这一关键能力。我们的方法包括通过结构化采样和信息模糊化生成新颖的高不确定性任务、RFT冷启动以及高效的代理强化学习算法——重复采样策略优化（DUPO）。通过这一集成流程，WebSailor在复杂信息搜索任务中显著优于所有开源代理，性能与专有代理相当，缩小了能力差距。

</details>


### [14] [Revisiting Active Learning under (Human) Label Variation](https://arxiv.org/abs/2507.02593)
**中文标题：重新审视（人类）标注差异下的主动学习**

*Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher*

主要分类: cs.CL

摘要简述: 本文探讨了在人类标注差异（HLV）背景下重新审视主动学习（AL）的必要性，提出了一种将HLV纳入AL循环的概念框架，并讨论了大型语言模型（LLM）作为标注者的整合。


<details>
  <summary>详细信息</summary>
研究动机: 高质量标注数据的获取是监督学习中的瓶颈问题。现有标注框架通常假设存在单一真实标签，忽视了人类标注差异（HLV）作为信息信号的价值。主动学习（AL）在优化标注预算时也常依赖不切实际的假设。本文旨在解决这些问题，提出更符合实际标注复杂性的方法。

研究方法: 本文首先分解了标注差异（LV）中的信号（如HLV）和噪声（如标注错误），并综述了AL和HLV领域对这些问题的处理方式。随后，提出了一个概念框架，将HLV整合到AL循环的各个环节，包括实例选择、标注者选择和标签表示，并探讨了LLM作为标注者的应用。

研究结果: 研究提出了一个HLV感知的主动学习框架，能够更真实地反映标注过程中的复杂性，并为未来研究奠定了概念基础。

研究结论: 本文强调了在主动学习中考虑人类标注差异的重要性，提出的框架为实际应用提供了更灵活和有效的方法，同时为LLM在标注任务中的应用开辟了新方向。

中文摘要: 高质量标注数据的获取仍然是监督学习应用中的限制因素。尽管标注差异（LV）（即同一实例的不同标签）很常见，尤其是在自然语言处理中，但标注框架通常仍假设存在单一真实标签，忽略了人类标注差异（HLV）作为一种信息信号的存在。同样，主动学习（AL）作为一种优化有限标注预算的流行方法，通常依赖于多个简化假设，这些假设在承认HLV时很少成立。本文研究了关于真实性和标签性质的基本假设，强调了将观察到的LV分解为信号（如HLV）和噪声（如标注错误）的必要性。我们综述了AL和HLV领域如何解决（或忽视）这些区别，并提出了一个概念框架，将HLV整合到AL循环的各个环节，包括实例选择、标注者选择和标签表示。我们还讨论了大型语言模型（LLM）作为标注者的整合。本文旨在为HLV感知的主动学习奠定概念基础，更好地反映实际标注的复杂性。

</details>


### [15] [MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion](https://arxiv.org/abs/2507.02595)
**中文标题：MPF：通过多视角融合在部署后对齐和去偏语言模型**

*Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama*

主要分类: cs.CL

摘要简述: MPF是一种新型后训练对齐框架，通过多视角融合减少大型语言模型（LLM）的偏见，无需大量提示工程或微调。


<details>
  <summary>详细信息</summary>
研究动机: 随着对减少语言模型偏见的迫切需求增加，MPF旨在提供一种可扩展且可解释的方法，用于对齐和缓解偏见，适用于已部署的LLM。

研究方法: MPF基于SAGED流程，通过多视角生成揭示和调整LLM输出中的偏见，并将其与人类基准对齐。通过分解基准（如HR专业人士的情感分布）为可解释的视角组件，MPF通过加权采样和平衡响应来引导生成。

研究结果: 实验表明，MPF能够将LLM的情感分布与反事实基准（绝对平等）和HR基准（偏向顶尖大学）对齐，KL散度小，校准误差降低，并能泛化到未见问题。

研究结论: MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，适用于已部署的LLM，无需大量提示工程或微调。

中文摘要: 多视角融合（MPF）是一种新型的后训练对齐框架，针对大型语言模型（LLM）开发，旨在满足减少偏见的迫切需求。MPF建立在SAGED流程之上，这是一个自动化系统，用于构建偏见基准并提取可解释的基准分布。MPF利用多视角生成来揭示和调整LLM输出中的偏见，并将其与细致的人类基准对齐。通过将基准（如HR专业人士的情感分布）分解为可解释的视角组件，MPF通过加权采样和平衡响应来引导生成。实验表明，MPF能够将LLM的情感分布与反事实基准（绝对平等）和HR基准（偏向顶尖大学）对齐，KL散度小，校准误差降低，并能泛化到未见问题。这表明MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，适用于已部署的LLM，无需大量提示工程或微调。

</details>


### [16] [Exploring Gender Bias Beyond Occupational Titles](https://arxiv.org/abs/2507.02679)
**中文标题：探索超越职业称谓的性别偏见**

*Ahmed Sabir,Rajesh Sharama*

主要分类: cs.CL

摘要简述: 本研究探讨了性别与语境偏见的关联，提出新数据集GenderLexicon和评估框架，证实了超越职业刻板印象的性别偏见存在。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索性别偏见是否不仅限于职业称谓，而是扩展到动作动词、对象名词等其他语境元素。

研究方法: 方法包括引入新数据集GenderLexicon和框架，通过评分量化语境偏见及其性别偏见，并在五个多样化数据集上验证。

研究结果: 结果显示模型能有效解释性别偏见，并证实了超越职业刻板印象的性别偏见存在。

研究结论: 结论表明，性别偏见广泛存在于多种语境中，新框架为偏见解释提供了有效工具。

中文摘要: 本研究探讨了性别与语境偏见的关联，重点关注动作动词、对象名词及职业称谓。我们引入了新数据集GenderLexicon和一个能评估语境偏见及其性别偏见的框架。该模型通过评分解释偏见，提高了性别偏见的可解释性。研究结果证实了超越职业刻板印象的性别偏见存在。为验证方法的有效性，我们在五个多样化数据集（包括一个日语数据集）上进行了评估。

</details>


### [17] [Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers](https://arxiv.org/abs/2507.02694)
**中文标题：大型语言模型能否识别科学研究中的关键局限性？对AI研究论文的系统性评估**

*Zhijian Xu,Yilun Zhao,Manasi Patwardhan,Lovekesh Vig,Arman Cohan*

主要分类: cs.CL

摘要简述: 本文探讨了大型语言模型（LLMs）在识别科学研究论文中的关键局限性方面的潜力，并提出了LimitGen基准，用于评估LLMs在辅助同行评审中的作用。


<details>
  <summary>详细信息</summary>
研究动机: 随着科学出版物数量的增加，同行评审的负担日益加重。尽管LLMs在科学任务中表现出潜力，但其在识别论文局限性方面的能力尚未充分研究。本文旨在填补这一空白。

研究方法: 研究首先提出了一个针对AI领域的科学局限性分类法，并基于此开发了LimitGen基准，包含合成数据集LimitGen-Syn和真实人类撰写的局限性数据集LimitGen-Human。此外，通过文献检索增强LLMs的能力，以更准确地识别局限性。

研究结果: 研究表明，增强后的LLMs能够更具体和建设性地识别论文中的局限性，为早期反馈和辅助同行评审提供了有效工具。

研究结论: LLMs在识别科学研究的局限性方面具有潜力，LimitGen基准为未来研究提供了重要工具，有助于提升同行评审的效率和质量。

中文摘要: 同行评审是科学研究的基础，但日益增长的出版物数量加剧了这一专业知识密集型过程的挑战。尽管大型语言模型（LLMs）在多种科学任务中展现出潜力，但其在辅助同行评审（尤其是识别论文局限性）方面的潜力仍未充分研究。我们首先提出了一个针对AI领域的科学局限性分类法。基于此分类法，我们提出了LimitGen，这是首个用于评估LLMs支持早期反馈和辅助人类同行评审能力的综合性基准。该基准包含两个子集：LimitGen-Syn（通过高质量论文的受控扰动生成的合成数据集）和LimitGen-Human（真实人类撰写的局限性数据集）。为了提升LLMs识别局限性的能力，我们通过文献检索增强其能力，这对于将局限性识别建立在先前的科学发现基础上至关重要。我们的方法提升了LLMs在研究论文中生成局限性的能力，使其能够提供更具体和建设性的反馈。

</details>


### [18] [Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens](https://arxiv.org/abs/2507.02744)
**中文标题：通过可产生最小差异（JPD）界限测量元音发音空间的粒度**

*Peter Viechnicki*

主要分类: cs.CL

摘要简述: 本研究通过测量‘可产生最小差异’（JPD）来探究人类元音发音的精细控制程度，发现JPD在F1 X F2空间中为14至51 mels，为语音产生理论和元音系统结构提供了新见解。


<details>
  <summary>详细信息</summary>
研究动机: 过去研究表明，人类元音发音的复杂协调动作受听觉空间目标区域的控制，但其控制精度尚不明确。本研究旨在量化这种控制精度，即两个元音刺激在听觉空间中需相距多远才能被可靠模仿为不同音。

研究方法: 研究采用元音模仿范式，测量两组英语使用者在发前元音时的‘可产生最小差异’（JPD），即在F1 X F2空间中两个元音能被区分的距离。

研究结果: 研究发现JPD在F1 X F2空间中为14至51 mels，表明人类对元音发音的精细控制能力。

研究结论: JPD的测量为语音产生的片段理论提供了支持，并为元音系统的可能结构设定了理论下限，解释了观察到的元音数量和模式趋势。

中文摘要: 过去几十年的研究表明，人类元音发音的复杂协调动作部分受听觉空间目标区域的控制，但该控制的精度尚不清楚。本研究通过探究两个元音刺激在听觉空间中需相距多远才能被可靠模仿为不同音，提出了‘可产生最小差异’（JPD）的概念。研究采用元音模仿范式，首次测量了两组英语使用者在发前元音时的JPD，发现其在F1 X F2空间中为14至51 mels。这一发现对语音产生的片段理论具有重要意义，并为人类元音系统的可能结构提供了理论下限，从而解释了观察到的元音数量和模式趋势。

</details>


### [19] [Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs](https://arxiv.org/abs/2507.02778)
**中文标题：自我纠正基准：揭示并解决LLMs中的自我纠正盲点**

*Ken Tsui*

主要分类: cs.CL

摘要简述: 大型语言模型（LLMs）在自我纠正方面存在系统性盲点，无法纠正自身输出的错误。本文通过引入Self-Correction Bench框架，揭示了这一现象，并发现简单的干预措施（如添加“Wait”）可显著减少盲点。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs具有变革性，但其仍会犯错且无法有效纠正自身错误。这种自我纠正盲点影响了模型的可靠性和可信度，因此需要系统研究并提出改进方法。

研究方法: 本文提出了Self-Correction Bench框架，通过在不同复杂度级别注入控制性错误，系统测量了14个模型的自我纠正盲点率。同时，分析了训练数据组成对盲点的影响，并测试了简单干预措施的效果。

研究结果: 研究发现，LLMs的平均盲点率为64.5%，且盲点与训练数据组成密切相关。通过简单的“Wait”提示，盲点率降低了89.3%，表明模型具备纠正能力但需激活。

研究结论: 当前LLMs存在显著的自我纠正盲点，但通过调整训练数据或简单干预可显著改善。这为提高LLMs的可靠性和可信度提供了潜在途径。

中文摘要: 尽管大型语言模型（LLMs）具有变革性，但它们仍会犯错并可能探索无效的推理路径。自我纠正是可信赖LLM的重要能力，尤其是自回归LLM。虽然LLMs能识别用户输入中的错误，但它们表现出系统性的“自我纠正盲点”——无法纠正自身输出中的相同错误。为系统研究这一现象，我们引入了Self-Correction Bench框架，通过三个复杂度级别的控制性错误注入来测量这一现象。测试14个模型后，我们发现平均盲点率为64.5%。多项证据表明，这一限制与训练数据组成有关：人类训练演示主要展示无错误的响应，而非错误纠正序列，这与通过结果反馈学习错误纠正的RL训练模型不同。值得注意的是，仅添加“Wait”即可将盲点减少89.3%，表明能力存在但需激活。我们的工作揭示了当前LLMs的一个关键限制，并提供了提高其可靠性和可信度的潜在途径。

</details>


### [20] [Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models](https://arxiv.org/abs/2507.02799)
**中文标题：推理是否足够？探究推理语言模型时代的偏见问题**

*Riccardo Cantini,Nicola Gabriele,Alessio Orsino,Domenico Talia*

主要分类: cs.CL

摘要简述: 研究发现，具备推理能力的语言模型（RLMs）在对抗社会偏见方面表现不佳，甚至比普通模型更容易受到偏见诱导。推理机制可能无意中强化了刻板印象。


<details>
  <summary>详细信息</summary>
研究动机: 推理语言模型（RLMs）因其多步推理能力而受到关注，但其对社会偏见的鲁棒性尚不明确。本文旨在探究推理能力对模型公平性和安全性的影响。

研究方法: 利用CLEAR-Bias基准测试，系统评估了多种RLMs在不同社会文化维度上的表现，采用LLM-as-a-judge方法进行自动安全评分，并使用越狱技术测试内置安全机制的强度。

研究结果: 研究发现，具备推理能力的模型（无论是通过CoT提示还是微调推理轨迹）比普通模型更容易受到偏见诱导。推理机制可能无意中强化了刻板印象。

研究结论: 推理能力并不一定提高模型的鲁棒性，反而可能增加偏见风险。需要设计更具偏见意识的推理方法。

中文摘要: 推理语言模型（RLMs）因其能够通过链式思维（CoT）提示或微调推理轨迹完成复杂的多步推理任务而受到关注。尽管这些能力有望提高可靠性，但其对社会偏见的鲁棒性仍不明确。本研究利用最初为大型语言模型（LLMs）设计的CLEAR-Bias基准，探究RLMs对偏见诱导的对抗鲁棒性。我们系统评估了多种先进的RLMs在不同社会文化维度上的表现，采用LLM-as-a-judge方法进行自动安全评分，并利用越狱技术评估内置安全机制的强度。研究回答了三个关键问题：（i）推理能力的引入如何影响模型的公平性和鲁棒性；（ii）微调推理模型是否比依赖CoT提示的模型更安全；（iii）针对偏见诱导的越狱攻击成功率如何随推理机制变化。结果表明，推理能力与偏见安全性之间存在微妙关系。令人惊讶的是，具备显式推理能力的模型（无论是通过CoT提示还是微调推理轨迹）通常比不具备此类机制的普通模型更容易受到偏见诱导，这表明推理可能无意中为刻板印象的强化开辟了新途径。推理能力模型似乎比依赖CoT提示的模型更安全，后者特别容易受到通过故事提示、虚构角色或奖励塑造指令的上下文重构攻击。这些结果挑战了推理能力必然提高鲁棒性的假设，并强调需要设计更具偏见意识的推理方法。

</details>


### [21] [Multimodal Mathematical Reasoning with Diverse Solving Perspective](https://arxiv.org/abs/2507.02804)
**中文标题：多模态数学推理中的多样化解题视角**

*Wenhao Shi,Zhiqiang Hu,Yi Bin,Yang Yang,See-Kiong Ng,Heng Tao Shen*

主要分类: cs.CL

摘要简述: 本文提出MathV-DP数据集和Qwen-VL-DP模型，通过多样化解题视角和强化学习提升多模态数学推理能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型在数学推理中依赖单一图像-文本对和单解监督，忽视了多样化解题视角和内部反思的潜力。

研究方法: 提出MathV-DP数据集，包含多样化解题轨迹；基于Qwen-VL构建Qwen-VL-DP模型，采用监督学习和GRPO强化学习方法，结合正确性判别和多样性奖励函数。

研究结果: 在MathVista和Math-V基准测试中，Qwen-VL-DP在准确性和生成多样性上显著优于现有模型。

研究结论: 多样化解题视角和反思推理对多模态数学推理至关重要，MathV-DP和Qwen-VL-DP为未来研究提供了新方向。

中文摘要: 近年来，大规模强化学习（RL）显著提升了大型语言模型（LLMs）的数学推理能力。然而，当前用于数学推理的多模态LLMs（MLLMs）通常依赖一对一的图像-文本对和单解监督，忽视了多样化解题视角和内部反思的潜力。本研究提出MathV-DP数据集，为每个图像-问题对捕捉多样化解题轨迹，提供更丰富的推理监督。进一步提出Qwen-VL-DP模型，基于Qwen-VL构建，通过监督学习和基于规则的RL方法——组相对策略优化（GRPO）进行微调，结合正确性判别和多样性奖励函数。该方法强调从多样化解题视角学习，并区分正确但不同的解法。在MathVista的minitest和Math-V基准测试中的广泛实验表明，Qwen-VL-DP在准确性和生成多样性上显著优于现有基础MLLMs，凸显了多样化解题视角和反思推理在多模态数学推理中的重要性。

</details>


### [22] [SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model](https://arxiv.org/abs/2507.02822)
**中文标题：SynapseRoute：基于双态大语言模型的自动路由切换框架**

*Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun*

主要分类: cs.CL

摘要简述: SynapseRoute是一种基于机器学习的动态路由框架，通过智能分配查询到高推理或低成本模式，优化大语言模型在准确性和成本效率上的表现。实验显示其显著提升准确性并减少时间和资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型的广泛应用，如何在性能和成本之间取得平衡成为关键。研究发现58%的医疗问题无需高成本推理即可解决，因此提出动态路由以优化用户体验和资源利用。

研究方法: 提出SynapseRoute框架，通过机器学习动态分配查询到“思考”或“非思考”模式，并引入AIT指标评估准确性、延迟和令牌成本的权衡。

研究结果: 实验表明，SynapseRoute在医疗数据集上比单一模式准确性更高（0.8390 vs. 0.8272），同时减少推理时间36.8%和令牌消耗39.66%。

研究结论: SynapseRoute通过动态路由优化了大语言模型的表现，避免了简单查询的过度推理，显著提升了效率和准确性。

中文摘要: 随着大语言模型（LLMs）在实际应用中的广泛采用，选择合适的模型不仅需要平衡性能，还需考虑运营成本。具备推理能力的模型进一步扩大了“思考”（高推理）与“非思考”（快速、低成本）模式之间的成本差距。本研究发现，约58%的医疗问题仅通过非思考模式即可准确回答，无需高成本推理过程。这揭示了问题复杂性的明显二分性，并表明基于复杂性动态路由查询可以优化准确性、成本效率和整体用户体验。基于此，我们提出SynapseRoute，一种基于机器学习的动态路由框架，智能地将输入查询分配到思考或非思考模式。在多个医疗数据集上的实验结果表明，SynapseRoute不仅比单一思考模式提高了整体准确性（0.8390 vs. 0.8272），还减少了36.8%的推理时间和39.66%的令牌消耗。重要的是，定性分析表明，对简单查询的过度推理可能导致不必要的延迟甚至准确性下降，而我们的自适应路由避免了这一问题。最后，本研究还引入了准确性-推理-令牌（AIT）指标，以全面评估准确性、延迟和令牌成本之间的权衡。

</details>


### [23] [Generalizing Verifiable Instruction Following](https://arxiv.org/abs/2507.02833)
**中文标题：泛化可验证指令遵循**

*Valentina Pyatkin,Saumya Malik,Victoria Graf,Hamish Ivison,Shengyi Huang,Pradeep Dasigi,Nathan Lambert,Hannaneh Hajishirzi*

主要分类: cs.CL

摘要简述: 研究发现当前语言模型在遵循精确指令时存在过拟合问题，无法泛化到未见过的输出约束。为此，作者提出了新基准IFBench和强化学习方法RLVR，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 人类与AI交互的关键在于语言模型能否精确遵循指令，但现有模型在满足多样化输出约束时表现不佳，且容易过拟合。因此，需要新的评估方法和训练策略来提升泛化能力。

研究方法: 作者设计了新基准IFBench，包含58种多样化的输出约束，并开发了约束验证模块。通过强化学习结合可验证奖励（RLVR）训练模型，显著提升了指令遵循能力。

研究结果: 实验表明，RLVR方法显著提升了模型在IFBench上的表现，验证了其在泛化精确指令遵循方面的有效性。同时，作者还发布了29个新训练约束和验证函数。

研究结论: 通过IFBench和RLVR方法，研究为提升语言模型在精确指令遵循上的泛化能力提供了有效工具和训练策略，推动了人机交互的进一步发展。

中文摘要: 人类与AI成功交互的关键在于语言模型或聊天机器人能否精确遵循人类指令。指令中常见的输出约束（如“仅回答是或否”或“至少提及‘abrakadabra’三次”）对当前最强模型仍具挑战性。研究发现，大多数模型在测试这些能力的基准上严重过拟合，无法泛化到未见过的输出约束。为此，我们提出了新基准IFBench，用于评估58种多样化且具有挑战性的域外约束下的精确指令遵循泛化能力。此外，我们深入分析了如何通过数据训练提升模型的泛化能力，并设计了约束验证模块。实验表明，结合可验证奖励的强化学习（RLVR）显著改善了指令遵循能力。除IFBench外，我们还发布了29个新标注的训练约束、验证函数、RLVR训练提示及代码。

</details>


### [24] [LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users](https://arxiv.org/abs/2507.02850)
**中文标题：LLM催眠术：利用用户反馈对所有用户进行未经授权的知识注入**

*Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas*

主要分类: cs.CL

摘要简述: 本文揭示了一种基于用户反馈的语言模型（LM）漏洞，攻击者可通过简单的提示和反馈机制（如点赞/点踩）持久性地篡改模型的知识和行为。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于揭示语言模型在用户反馈训练中的潜在安全漏洞，尤其是攻击者如何利用有限的反馈权限对模型进行知识注入和行为操控。

研究方法: 攻击方法包括：攻击者通过提示让模型随机输出“中毒”或良性回答，随后对中毒回答点赞或对良性回答点踩。在后续的偏好调优中，模型会倾向于生成中毒回答，即使在没有恶意提示的情况下。

研究结果: 实验结果表明，该攻击可用于：（1）插入模型原本不具备的事实知识；（2）修改代码生成模式以引入安全漏洞；（3）注入虚假金融新闻。

研究结论: 本文不仅揭示了语言模型偏好调优的新特性（表明即使有限的偏好数据也能精细控制模型行为），还提出了一种新的攻击机制，扩展了预训练数据中毒和部署时提示注入的研究。

中文摘要: 我们描述了一种基于用户反馈训练的语言模型（LM）漏洞，单个用户仅通过提供提示和对LM输出的点赞/点踩反馈，即可持久性地改变模型的知识和行为。攻击实施方式为：攻击者提示LM随机输出“中毒”或良性回答，随后对中毒回答点赞或对良性回答点踩。当反馈信号用于后续的偏好调优时，LM即使在无恶意提示的情境下，也会增加生成中毒回答的概率。我们证明，该攻击可用于：（1）插入模型原本不具备的事实知识；（2）修改代码生成模式以引入可利用的安全漏洞；（3）注入虚假金融新闻。我们的发现不仅揭示了语言模型偏好调优的新特性（表明即使高度受限的偏好数据也能用于精细控制行为），还提出了一种新的攻击机制（扩展了预训练数据中毒和部署时提示注入的研究）。

</details>


### [25] [MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs](https://arxiv.org/abs/2507.02851)
**中文标题：MOTIF：通过强化学习微调实现大语言模型的模块化思考**

*Purbesh Mitra,Sennur Ulukus*

主要分类: cs.CL

摘要简述: 本文提出MOTIF方法，通过强化学习微调使大语言模型（LLM）能够分模块思考，突破上下文长度限制，在数学推理任务中显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型的上下文长度限制了其推理能力，无法处理超长文本的复杂推理任务。为解决这一问题，本文提出了一种模块化思考方法。

研究方法: MOTIF方法通过强化学习微调（GRPO算法），分多轮生成思考标记，扩展模型的上下文长度。实验基于开源模型Qwen2.5-3B-Instruct，在GSM8K数据集上进行参数高效微调。

研究结果: 在MATH500和AIME2024基准测试中，MOTIF方法相比传统GRPO训练分别提升了3.8%和3.3%的准确率，且仅需15%的样本量，展示了高效性。

研究结论: MOTIF方法通过模块化思考策略，有效突破LLM的上下文长度限制，显著提升推理能力，同时具有样本高效性。

中文摘要: 近期研究表明，通过群体相对策略优化（GRPO）算法进行强化学习训练，大语言模型（LLM）能够利用更多思考标记生成更优响应。然而，LLM在保持对已生成标记注意力的同时，仅能生成有限数量的标记，这一限制（即LLM的上下文长度）成为其处理超长标记推理任务的瓶颈。为突破这一限制，LLM需采用模块化思考策略进行多轮推理。本文提出MOTIF方法——通过强化学习微调实现模块化思考，使模型能够分多轮生成思考标记，从而扩展上下文长度。我们在GSM8K数据集上对开源模型Qwen2.5-3B-Instruct进行参数高效微调，并在MATH500和AIME2024基准测试中验证其性能。实验结果表明，MOTIF方法相比传统GRPO训练分别提升了3.8%和3.3%的准确率，且仅需15%的样本量，展示了其高效性。代码和模型已开源。

</details>


### [26] [Answer Matching Outperforms Multiple Choice for Language Model Evaluation](https://arxiv.org/abs/2507.02856)
**中文标题：答案匹配评测优于多选题评测语言模型**

*Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping*

主要分类: cs.CL

摘要简述: 论文指出传统多选题评测语言模型存在缺陷，提出通过答案匹配的生成式评测方法，并证明其与人工评分高度一致，显著优于多选题评测。


<details>
  <summary>详细信息</summary>
研究动机: 传统多选题评测因客观且易于自动化而被广泛使用，但其存在模型无需看题即可回答的缺陷，无法全面评估模型的生成能力。作者旨在寻找更有效的评测方法。

研究方法: 提出答案匹配评测法：让模型生成自由回答，再用现代语言模型结合参考答案判断匹配度。通过标注MMLU-Pro和GPQA-Diamond数据集，比较不同评测方法与人工评分的一致性。

研究结果: 答案匹配评测（即使使用小型模型）与人工评分一致性接近完美，显著优于多选题评测和无参考答案的LLM评分。模型排名在答案匹配评测下发生显著变化。

研究结论: 答案匹配评测优于多选题评测，建议将评测体系从多选题转向答案匹配。

中文摘要: 多选题评测长期以来是语言模型评测的主要方法，因其客观且易于自动化。然而，我们发现流行多选题评测中的问题常可不看题目即回答。这些缺陷源于判别式评测的固有局限，而生成式评测则无此问题。近期，答案匹配评测成为可行替代方案：让模型生成自由回答，再用现代语言模型结合参考答案判断匹配度。为比较不同评测方法的有效性，我们标注了MMLU-Pro和GPQA-Diamond数据集，测量各方法与人工评分的一致性。结果显示，答案匹配评测（即使使用小型模型）与人工评分一致性接近完美，而多选题评测和无参考答案的LLM评分则表现不佳。答案匹配评测不仅概念上更优，还显著改变了模型排名。基于此，我们探讨了如何将评测体系从多选题转向答案匹配。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges](https://arxiv.org/abs/2507.02074)
**中文标题：大语言模型在视频碰撞检测中的应用：方法、数据集与挑战综述**

*Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma*

主要分类: cs.CV

摘要简述: 本文综述了利用大语言模型（LLMs）进行视频中碰撞检测的最新方法，包括融合策略分类、数据集总结、模型架构分析、性能比较及未来挑战与机遇。


<details>
  <summary>详细信息</summary>
研究动机: 智能交通系统中，视频碰撞检测是一个关键问题。随着大语言模型（LLMs）和视觉语言模型（VLMs）的发展，多模态信息处理方式发生了变革。本文旨在综述LLMs在视频碰撞检测中的应用，为未来研究提供基础。

研究方法: 本文通过结构化分类法总结了融合策略，梳理了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前挑战与机遇。

研究结果: 研究提供了视频理解与基础模型交叉领域的全面综述，为未来研究奠定了基础。

研究结论: 本文为视频碰撞检测领域的研究者提供了重要参考，并指出了未来研究方向。

中文摘要: 视频碰撞检测是智能交通系统中的关键问题。近年来，大语言模型（LLMs）和视觉语言模型（VLMs）的发展彻底改变了多模态信息的处理、推理和总结方式。本文综述了利用LLMs进行视频碰撞检测的最新方法，提出了融合策略的结构化分类法，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前挑战与机遇。本综述为视频理解与基础模型交叉领域的未来研究奠定了基础。

</details>


### [28] [Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning](https://arxiv.org/abs/2507.02148)
**中文标题：水下单目测距深度估计：真实世界基准与合成数据微调**

*Zijie Cai,Christopher Metzler*

主要分类: cs.CV

摘要简述: 本文研究了水下单目测距深度估计的挑战，通过真实世界数据集和合成数据微调模型，提出了改进方法。


<details>
  <summary>详细信息</summary>
研究动机: 由于水下环境的光衰减、散射、颜色失真和缺乏高质量的真实深度数据，单目测距深度估计在水下环境中的可靠性有限。本文旨在通过真实世界数据集和合成数据微调模型，解决这一问题。

研究方法: 作者首先在真实世界水下数据集（如FLSea和SQUID）上评估了多种零样本和微调的单目测距深度估计模型。随后，使用基于物理的水下图像生成模型，在合成水下数据集Hypersim上微调了Depth Anything V2模型。

研究结果: 实验表明，大规模陆地数据集训练的模型在水下表现不佳，而微调后的模型在所有基准测试中均表现优于仅使用清洁陆地数据训练的基线模型。

研究结论: 研究强调了领域适应和尺度感知监督在水下单目测距深度估计中的重要性，为未来研究提供了详细评估和可视化结果。

中文摘要: 单目深度估计最近已发展到不仅能提供相对深度，还能提供测距深度预测。然而，由于光衰减和散射、颜色失真、浑浊以及缺乏高质量的测距真实数据，其在水下环境中的可靠性仍然有限。本文提出了一种全面的基准测试，评估了零样本和微调的单目测距深度估计模型在真实世界水下数据集（如FLSea和SQUID）上的表现。我们评估了多种先进模型在不同水下条件下的表现。结果表明，尽管大规模陆地数据集训练的模型在陆地环境中表现良好，但由于显著的领域偏移，其在水下表现较差。为解决这一问题，我们在基于物理的水下图像生成模型生成的合成水下Hypersim数据集上微调了Depth Anything V2模型。实验证明，微调后的模型在所有基准测试中均表现优于仅使用清洁陆地Hypersim数据集训练的基线模型。本研究为水下场景中的单目测距深度估计提供了详细评估和可视化结果，强调了领域适应和尺度感知监督在实现鲁棒且可泛化的测距深度预测中的重要性。

</details>


### [29] [ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.02200)
**中文标题：ESTR-CoT：基于链式思维推理的可解释且准确的事件流场景文本识别**

*Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于链式思维推理的事件流场景文本识别框架ESTR-CoT，通过结合视觉编码器和大语言模型，显著提升了在低光照和快速运动等极端场景下的文本识别准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事件流场景文本识别方法在极端场景（如低光照、快速运动）中表现不佳，且缺乏可解释性和上下文逻辑推理能力。本文旨在解决这些问题。

研究方法: 采用EVA-CLIP视觉编码器将事件流转换为token，结合Llama分词器和Vicuna-7B大语言模型，通过Q-former对齐视觉token，输出答案和链式思维推理过程。通过三阶段处理生成的大规模CoT数据集进行训练。

研究结果: 在EventSTR、WordArt*和IC15*三个基准数据集上的实验验证了ESTR-CoT的有效性和可解释性。

研究结论: ESTR-CoT框架显著提升了事件流场景文本识别的准确性和可解释性，为后续基于推理的大模型发展提供了数据基础。

中文摘要: 基于事件流的场景文本识别是近年来新兴的研究课题，其在极端挑战性场景（如低光照、快速运动）中表现优于广泛使用的RGB相机。现有工作要么采用端到端编码器-解码器框架，要么利用大语言模型增强识别能力，但仍受限于可解释性不足和上下文逻辑推理能力较弱的问题。本文提出了一种基于链式思维推理的事件流场景文本识别框架ESTR-CoT。具体而言，我们首先采用视觉编码器EVA-CLIP（ViT-G/14）将输入事件流转换为token，并利用Llama分词器对生成提示进行编码。通过Q-former将视觉token与预训练大语言模型Vicuna-7B对齐，同时输出答案和链式思维推理过程。我们的框架可通过监督微调以端到端方式优化。此外，我们还提出了一个通过三阶段处理（生成、优化和专家验证）生成的大规模CoT数据集来训练框架。该数据集为后续基于推理的大模型发展提供了坚实的数据基础。在三个事件流STR基准数据集（EventSTR、WordArt*和IC15*）上的大量实验充分验证了所提框架的有效性和可解释性。源代码和预训练模型将在https://github.com/Event-AHU/ESTR-CoT发布。

</details>


### [30] [Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach](https://arxiv.org/abs/2507.02205)
**中文标题：第九届ABAW竞赛中Team RAS的多模态复合表情识别方法**

*Elena Ryumina,Maxim Markitantov,Alexandr Axyonov,Dmitry Ryumin,Mikhail Dolgushin,Alexey Karpov*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的零样本多模态方法，用于复合表情识别（CER），结合了六种异构模态，并通过动态加权和概率融合模块实现了与监督方法相当的性能。


<details>
  <summary>详细信息</summary>
研究动机: 复合表情识别（CER）是情感计算的重要子领域，旨在检测由基本情绪组合形成的复杂情绪状态。当前方法依赖任务特定训练数据，而本文旨在探索零样本多模态方法，避免领域适应需求。

研究方法: 方法结合了六种模态：静态和动态面部表情、场景与标签匹配、场景上下文、音频和文本。采用零样本组件（如基于CLIP的标签匹配和Qwen-VL的语义场景理解），并引入多头部概率融合（MHPF）模块动态加权模态预测，再通过复合表情（CE）转换模块生成可解释的输出。

研究结果: 在多语料库训练下，该方法在AffWild2、AFEW和C-EXPR-DB上的F1分数分别为46.95%、49.02%和34.85%，与监督方法性能相当。

研究结论: 提出的零样本多模态方法能有效捕捉复合表情，无需领域适应，展示了其在实际应用中的潜力。

中文摘要: 复合表情识别（CER）是情感计算的一个子领域，旨在检测由基本情绪组合形成的复杂情绪状态。本文提出了一种新颖的零样本多模态方法，将六种异构模态整合到一个流程中：静态和动态面部表情、场景与标签匹配、场景上下文、音频和文本。与依赖任务特定训练数据的传统方法不同，本方法采用零样本组件，包括基于对比语言-图像预训练（CLIP）的标签匹配和Qwen-VL的语义场景理解。进一步引入了多头部概率融合（MHPF）模块，动态加权模态特定预测，并通过复合表情（CE）转换模块使用成对概率聚合（PPA）和成对特征相似性聚合（PFSA）方法生成可解释的复合情绪输出。在多语料库训练下，该方法在AffWild2、AFEW和C-EXPR-DB上的零样本测试F1分数分别为46.95%、49.02%和34.85%，与目标数据训练的监督方法结果相当。这表明了所提方法在无需领域适应的情况下捕捉复合表情的有效性。源代码已公开。

</details>


### [31] [SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers](https://arxiv.org/abs/2507.02212)
**中文标题：SciGA：学术论文中图形摘要设计的综合数据集**

*Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi*

主要分类: cs.CV

摘要简述: 本文介绍了SciGA-145k数据集，包含14.5万篇科学论文和114万张图表，旨在支持图形摘要（GA）的选择与推荐，并推动自动化GA生成的研究。


<details>
  <summary>详细信息</summary>
研究动机: 图形摘要在科学论文中扮演重要角色，但目前其设计和应用存在障碍。缺乏大规模数据集和自动化工具限制了GA的潜力。

研究方法: 提出SciGA-145k数据集，定义两项任务：1）论文内GA推荐（Intra-GA），2）跨论文GA推荐（Inter-GA）。并引入新评价指标CAR。

研究结果: 建立了SciGA-145k数据集，提供了基线模型和新评价指标CAR，为GA设计和研究提供了基础。

研究结论: SciGA-145k为科学视觉传播和AI辅助GA设计奠定了基础，推动了科学交流的进步。

中文摘要: 图形摘要（GAs）在科学论文中通过视觉方式传达关键发现，具有重要作用。尽管近期研究越来越多地将图表（如图1）作为默认GAs使用，但其提升科学交流的潜力仍未充分挖掘。此外，设计有效的GAs需要高级可视化技能，这限制了其广泛应用。为解决这些问题，我们推出了SciGA-145k，这是一个包含约14.5万篇科学论文和114万张图表的大规模数据集，专门用于支持GA的选择与推荐，并推动自动化GA生成的研究。作为GA设计支持的初步尝试，我们定义了两项任务：1）论文内GA推荐（Intra-GA），即识别论文中适合作为GAs的图表；2）跨论文GA推荐（Inter-GA），即从其他论文中检索GAs以启发新GA的创作。我们为这些任务提供了合理的基线模型。此外，我们提出了置信度调整的top-1真实比例（CAR），这是一种新的推荐指标，能够对模型行为进行细粒度分析。CAR通过考虑论文中除明确标记的GA外，其他图表也可能作为GAs的情况，弥补了传统基于排名的指标的不足。通过整合这些任务和指标，SciGA-145k为推进视觉科学交流奠定了基础，同时为AI在科学中的应用做出了贡献。

</details>


### [32] [Understanding Trade offs When Conditioning Synthetic Data](https://arxiv.org/abs/2507.02217)
**中文标题：理解合成数据生成中的权衡**

*Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma*

主要分类: cs.CV

摘要简述: 本文研究了合成数据生成中的两种条件策略（基于提示和基于布局），发现布局条件在多样性高时表现更优，显著提升目标检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 工业视觉系统中高质量训练数据收集耗时且困难，合成数据成为解决方案，但现有方法生成速度慢且仿真与真实差距大。扩散模型虽快速生成高质量图像，但在低数据条件下精确控制仍具挑战。

研究方法: 研究从四个标准目标检测基准中选取80个视觉概念，比较基于提示和基于布局的两种条件策略对合成数据质量的影响。

研究结果: 当条件线索多样时，布局条件优于提示条件，合成数据使平均精度提升34%，最高达177%。

研究结论: 布局条件在多样性高时更有效，合成数据可显著提升目标检测性能，为工业视觉系统提供高效解决方案。

中文摘要: 从少量图像中学习稳健的目标检测器是工业视觉系统的关键挑战，高质量训练数据的收集可能需要数月。合成数据成为数据高效视觉检测和拾取机器人技术的关键解决方案。当前流程依赖Blender或Unreal等3D引擎，虽提供精细控制，但渲染小型数据集仍需数周，且生成的图像常存在仿真与现实的巨大差距。扩散模型因其能在数分钟内生成高质量图像而带来变革，但在低数据条件下的精确控制仍具挑战。尽管许多适配器扩展了扩散模型的功能，但不同条件策略对合成数据质量的影响尚不清楚。我们从四个标准目标检测基准中选取80个视觉概念，比较了基于提示和基于布局的两种条件策略。当条件线索较窄时，提示条件生成的数据质量更高；随着多样性增加，布局条件表现更优。当布局线索与完整训练分布匹配时，合成数据使平均精度平均提升34%，最高达177%。

</details>


### [33] [High-Fidelity Differential-information Driven Binary Vision Transformer](https://arxiv.org/abs/2507.02222)
**中文标题：高保真差分信息驱动的二值化视觉Transformer**

*Tian Gao,Zhiyuan Zhang,Kaijie Yin,Xu-Cheng Zhong,Hui Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DIDB-ViT的新型二值化视觉Transformer，通过引入差分信息驱动的注意力模块和改进的RPReLU激活函数，显著提升了二值化ViT的性能，同时保持了计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的二值化视觉Transformer方法存在性能严重下降或依赖全精度模块的问题，限制了其在边缘设备上的应用。本文旨在解决这些问题，提出一种高性能且计算高效的二值化ViT。

研究方法: 设计了差分信息驱动的注意力模块以减少二值化导致的信息损失，并增强高频信息保留；采用离散Haar小波进行频率分解，整合不同频率的相似性；改进了RPReLU激活函数以优化激活分布。

研究结果: 实验表明，DIDB-ViT在多种ViT架构中显著优于现有网络量化方法，在图像分类和分割任务中表现优异。

研究结论: DIDB-ViT通过创新的模块设计和激活函数改进，成功解决了二值化ViT的性能问题，为边缘设备部署提供了高效解决方案。

中文摘要: 二值化视觉Transformer（ViT）为解决高计算/存储需求与边缘设备部署限制之间的权衡提供了一种有前景的方法。然而，现有的二值化ViT方法通常存在性能严重下降或过度依赖全精度模块的问题。为解决这些问题，我们提出了DIDB-ViT，一种高度信息丰富且保持原始ViT架构和计算效率的新型二值化ViT。具体而言，我们设计了一个包含差分信息的注意力模块，以减轻二值化导致的信息损失并增强高频信息保留。为保持二进制Q和K张量之间相似性计算的保真度，我们使用离散Haar小波进行频率分解，并整合不同频率的相似性。此外，我们引入了一种改进的RPReLU激活函数，以重构激活分布，扩展模型的表示能力。实验结果表明，我们的DIDB-ViT在多种ViT架构中显著优于最先进的网络量化方法，实现了卓越的图像分类和分割性能。

</details>


### [34] [FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model](https://arxiv.org/abs/2507.02250)
**中文标题：FMOcc：基于三视角视图流匹配的选择性状态空间模型用于3D占据预测**

*Jiangxia Chen,Tongyuan Huang,Ke Song*

主要分类: cs.CV

摘要简述: 本文提出FMOcc方法，通过流匹配选择性状态空间模型优化三视角视图（TPV）特征，提升少帧3D语义占据预测的准确性和效率，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 3D语义占据预测在自动驾驶中至关重要，但少帧图像和3D空间冗余导致遮挡和远距离场景预测不准确。现有方法依赖历史帧数据融合，需额外数据和计算资源。本文旨在解决这些问题。

研究方法: 1. 设计流匹配选择性状态空间模块（FMSSM）生成缺失特征；2. 通过TPV SSM层和平面选择性SSM（PS3M）选择性过滤TPV特征，减少空气体素影响；3. 提出掩码训练（MT）方法增强模型鲁棒性。

研究结果: 在Occ3D-nuScenes和OpenOcc数据集上，FMOcc以两帧输入取得43.1% RayIoU和39.8% mIoU（Occ3D-nuScenes），42.6% RayIoU（OpenOcc），推理内存5.4G，时间330ms，优于现有方法。

研究结论: FMOcc通过流匹配和选择性状态空间模型优化特征生成与过滤，显著提升少帧3D占据预测性能，适用于自动驾驶场景。

中文摘要: 3D语义占据预测在自动驾驶中扮演关键角色。然而，少帧图像的固有局限性和3D空间的冗余性导致遮挡和远距离场景的预测准确性下降。现有方法通过融合历史帧数据提升性能，但需要额外数据和大量计算资源。为解决这些问题，本文提出FMOcc，一种基于三视角视图（TPV）优化的占据网络，结合流匹配选择性状态空间模型，用于少帧3D占据预测。首先，我们设计了基于流匹配模型的特征优化模块（FMSSM），用于生成缺失特征。其次，通过设计TPV SSM层和平面选择性SSM（PS3M），选择性过滤TPV特征以减少空气体素对非空气体素的影响，从而提升模型整体效率和远距离场景预测能力。最后，提出掩码训练（MT）方法增强FMOcc的鲁棒性，解决传感器数据丢失问题。在Occ3D-nuScenes和OpenOcc数据集上的实验结果表明，FMOcc优于现有最优方法。以两帧输入为例，FMOcc在Occ3D-nuScenes验证集上取得43.1% RayIoU和39.8% mIoU，在OpenOcc上取得42.6% RayIoU，推理内存5.4G，时间330ms。

</details>


### [35] [SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement](https://arxiv.org/abs/2507.02252)
**中文标题：SurgVisAgent：多功能手术视觉增强的多模态智能代理模型**

*Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen*

主要分类: cs.CV

摘要简述: SurgVisAgent是一种基于多模态大语言模型（MLLMs）的智能手术视觉代理，能够动态识别内窥镜图像的失真类别和严重程度，并执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。通过领域特定知识模型和上下文少样本学习，它提供定制化图像增强，优于传统单任务模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前手术增强算法通常针对单一任务设计，难以应对复杂现实场景的多样化需求。为了解决这一问题，研究团队提出SurgVisAgent，旨在通过多模态智能代理提供统一的手术视觉增强解决方案。

研究方法: SurgVisAgent基于多模态大语言模型（MLLMs），设计了一个领域特定知识模型以提升手术场景理解能力。通过上下文少样本学习和链式思维推理（CoT），模型能够针对不同失真类型和严重程度提供定制化图像增强。

研究结果: 实验表明，SurgVisAgent在模拟真实手术失真的综合基准测试中表现优异，显著优于传统单任务模型，展示了其作为统一手术辅助解决方案的潜力。

研究结论: SurgVisAgent通过多模态智能代理和定制化增强能力，为复杂手术场景提供了高效且灵活的视觉增强解决方案，有望成为手术辅助领域的重要工具。

中文摘要: 精确的手术干预对患者安全至关重要，而先进的增强算法已被开发用于辅助外科医生的决策。尽管取得了显著进展，但这些算法通常针对特定场景的单一任务设计，限制了其在复杂现实情况下的有效性。为解决这一限制，我们提出了SurgVisAgent，一种基于多模态大语言模型（MLLMs）的端到端智能手术视觉代理。SurgVisAgent能够动态识别内窥镜图像的失真类别和严重程度，从而执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。具体而言，为实现卓越的手术场景理解，我们设计了一个提供领域特定知识的先验模型。此外，通过上下文少样本学习和链式思维（CoT）推理，SurgVisAgent能够针对广泛的失真类型和严重程度提供定制化图像增强，从而满足外科医生的多样化需求。我们还构建了一个模拟真实手术失真的综合基准测试，大量实验表明，SurgVisAgent超越了传统的单任务模型，突显了其作为手术辅助统一解决方案的潜力。

</details>


### [36] [Multi-Label Classification Framework for Hurricane Damage Assessment](https://arxiv.org/abs/2507.02265)
**中文标题：飓风损害评估的多标签分类框架**

*Zhangding Liu,Neda Mohammadi,John E. Taylor*

主要分类: cs.CV

摘要简述: 本文提出了一种基于多标签分类的飓风损害评估框架，结合ResNet特征提取和类别特定注意力机制，显著提升了损害分类的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 飓风造成的损害类型和严重程度多样，传统单标签分类方法难以全面捕捉其复杂性，亟需一种更高效的评估方法以支持灾后响应。

研究方法: 采用ResNet进行特征提取，并结合类别特定注意力机制，实现对单张图像中多种损害类型的识别。

研究结果: 在Rescuenet数据集上，该方法平均精度达到90.23%，优于现有基线方法。

研究结论: 该框架显著提升了飓风损害评估的效率和准确性，为灾后响应和减灾策略提供了有力支持。

中文摘要: 飓风造成广泛破坏，导致多样化的损害类型和严重程度，需要及时准确的评估以支持有效的灾害响应。传统的单标签分类方法难以捕捉飓风后损害的复杂性，本研究提出了一种基于航空影像的新型多标签分类框架。该方法结合了基于ResNet的特征提取模块和类别特定注意力机制，能够识别单张图像中的多种损害类型。在飓风Michael的Rescuenet数据集上，所提方法的平均精度达到90.23%，优于现有基线方法。该框架提升了飓风后损害评估的效率，支持更有针对性的灾害响应，并为未来的减灾和韧性策略提供了参考。本文已被ASCE国际计算土木工程会议（i3CE 2025）接受，最终版本将收录于会议论文集。

</details>


### [37] [Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation](https://arxiv.org/abs/2507.02268)
**中文标题：基于双向域适应的跨域高光谱图像分类**

*Yuxiang Zhang,Wei Li,Wen Jia,Mengmeng Zhang,Ran Tao,Shunlin Liang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于双向域适应（BiDA）的跨域高光谱图像分类框架，通过提取域不变特征和域特定信息，提升模型在目标场景中的适应性和可分性。实验表明，BiDA在跨时空数据集上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱遥感技术可用于提取细粒度土地覆盖类别，但训练和测试图像通常来自不同区域或时间，导致相同类别在不同场景中存在显著光谱偏移。为解决这一问题，本文提出BiDA框架，旨在提升跨域分类性能。

研究方法: BiDA框架采用三分支Transformer架构（源分支、目标分支和耦合分支），结合语义标记器。源分支和目标分支独立学习源域和目标域的自适应空间，耦合分支通过耦合多头交叉注意力（CMCA）机制实现特征交互和域间相关性挖掘。此外，设计了双向蒸馏损失和自适应强化策略（ARS）以优化特征提取。

研究结果: 实验表明，BiDA在跨时空/场景的航空和卫星数据集上显著优于现有域适应方法。在跨时空树种分类任务中，BiDA比最先进方法高出3%~5%。

研究结论: BiDA框架通过双向域适应和特征交互，有效提升了跨域高光谱图像分类的性能，尤其在噪声条件下表现优异。代码已开源。

中文摘要: 利用高光谱遥感技术可以提取细粒度的土地覆盖类别。通常，用于训练和测试的卫星或航空图像来自不同区域或时间，同一类别在不同场景中存在显著的光谱偏移。本文提出了一种双向域适应（BiDA）框架，用于跨域高光谱图像（HSI）分类，重点在独立的自适应空间中提取域不变特征和域特定信息，从而增强对目标场景的适应性和可分性。在BiDA中，设计了一种三分支Transformer架构（源分支、目标分支和耦合分支）作为主干，并结合语义标记器。具体而言，源分支和目标分支独立学习源域和目标域的自适应空间，耦合分支通过耦合多头交叉注意力（CMCA）机制实现特征交互和域间相关性挖掘。此外，设计了双向蒸馏损失以利用域间相关性指导自适应空间学习。最后，提出了一种自适应强化策略（ARS），鼓励模型在噪声条件下专注于源和目标场景中的特定广义特征提取。在跨时空/场景的航空和卫星数据集上的实验结果表明，所提出的BiDA显著优于一些最先进的域适应方法。在跨时空树种分类任务中，BiDA比最先进方法高出3%~5%。代码可从以下网址获取：https://github.com/YuxiangZhang-BIT/IEEE_TCSVT_BiDA。

</details>


### [38] [MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement](https://arxiv.org/abs/2507.02270)
**中文标题：MAC-Lookup：用于水下图像增强的多轴条件查找模型**

*Fanghai Yi,Zehong Zheng,Zexiao Liang,Yihang Dong,Xiyang Fang,Wangyu Wu,Xuhang Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MAC-Lookup的多轴条件查找模型，用于解决水下图像增强问题，通过颜色校正和细节优化显著提升了图像质量。


<details>
  <summary>详细信息</summary>
研究动机: 水下图像常因光线变化、水体浑浊和气泡等问题导致可见性和色彩失真，传统方法效果有限，且深度学习缺乏高质量数据集。因此，需要一种新方法来有效增强水下图像。

研究方法: MAC-Lookup模型结合了条件3D查找表颜色校正（CLTCC）和多轴自适应增强（MAAE），分别用于初步颜色校正和细节优化，避免过增强和饱和问题。

研究结果: 实验表明，MAC-Lookup在恢复水下图像细节和色彩方面优于现有方法，显著提升了视觉质量。

研究结论: MAC-Lookup模型通过创新的多轴条件查找方法，有效解决了水下图像增强的挑战，为相关领域提供了实用工具。

中文摘要: 增强水下图像对探索至关重要。这些图像因光线变化、水体浑浊和气泡而面临可见性和色彩问题。传统的基于先验和像素的方法效果不佳，而深度学习缺乏高质量数据集。我们提出了多轴条件查找（MAC-Lookup）模型，通过提升色彩准确性、清晰度和对比度来改善视觉质量。它包括用于初步颜色和质量校正的条件3D查找表颜色校正（CLTCC）和用于细节优化的多轴自适应增强（MAAE）。该模型避免了过增强和饱和问题，同时应对水下挑战。大量实验表明，MAC-Lookup在恢复水下图像细节和色彩方面优于现有方法。代码见https://github.com/onlycatdoraemon/MAC-Lookup。

</details>


### [39] [Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation](https://arxiv.org/abs/2507.02271)
**中文标题：通过自蒸馏聚焦部分可见的电影语言以实现视频到音频生成**

*Feizhen Huang,Yu Wu,Yutian Lin,Bo Du*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自蒸馏的方法，用于提升视频到音频生成模型在部分可见场景下的表现，通过模拟电影语言变化，模型能够更好地捕捉声音与部分视觉信息的关联。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频到音频生成方法忽视了电影语言这一关键艺术表达元素，导致在Foley目标部分可见时性能下降。本文旨在解决这一问题。

研究方法: 采用自蒸馏方法，通过模拟电影语言变化，训练学生模型对齐视频特征与音频-视觉对应关系，从而捕捉声音与部分视觉信息的关联。

研究结果: 该方法在部分可见场景下显著提升了所有评估指标的表现，并在大规模V2A数据集VGGSound上进一步提升了性能。

研究结论: 本文提出的自蒸馏方法有效解决了部分可见场景下的视频到音频生成问题，同时提升了模型在标准数据集上的表现。

中文摘要: 视频到音频（V2A）生成在电影和视频后期制作中取得了显著进展并扮演着关键角色。然而，当前方法忽视了电影语言这一电影艺术表达的关键组成部分，导致在Foley目标仅部分可见时性能下降。为解决这一问题，我们提出了一种简单的自蒸馏方法，将V2A模型扩展到电影语言场景。通过模拟电影语言变化，学生模型学会对齐训练对中具有相同音频-视觉对应关系的视频特征，从而有效捕捉声音与部分视觉信息的关联。我们的方法不仅在部分可见场景下在所有评估指标上实现了显著提升，还在大规模V2A数据集VGGSound上进一步提升了性能。

</details>


### [40] [LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2507.02279)
**中文标题：LaCo：多模态大语言模型中视觉令牌的高效层级压缩**

*Juntao Liu,Liqiang Niu,Wenchao Chen,Jie Zhou,Fandong Meng*

主要分类: cs.CV

摘要简述: LaCo提出了一种新颖的视觉令牌压缩框架，通过在视觉编码器的中间层进行压缩，显著提升了多模态大语言模型的效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉令牌压缩方法主要作为后编码模块，限制了效率提升的潜力。为了解决这一问题，作者提出了LaCo框架，旨在在视觉编码器的中间层实现高效的令牌压缩。

研究方法: LaCo框架包含两个核心组件：1）层级的像素重排机制，通过空间到通道的变换系统性地合并相邻令牌；2）带有非参数捷径的残差学习架构，确保压缩过程中保留关键视觉信息。

研究结果: 实验表明，LaCo在视觉编码器中间层压缩令牌时优于所有现有方法，训练效率提升超过20%，推理吞吐量提升超过15%，同时保持强性能。

研究结论: LaCo通过中间层压缩显著提升了多模态大语言模型的效率，为视觉令牌压缩提供了更优的解决方案。

中文摘要: 现有的多模态大语言模型（MLLMs）视觉令牌压缩方法主要作为后编码模块运行，限制了其效率提升的潜力。为解决这一问题，我们提出了LaCo（层级视觉令牌压缩），一种新颖的框架，能够在视觉编码器的中间层实现有效的令牌压缩。LaCo引入了两个核心组件：1）层级的像素重排机制，通过空间到通道的变换系统性地合并相邻令牌；2）带有非参数捷径的残差学习架构，在压缩过程中保留关键视觉信息。大量实验表明，我们的LaCo在视觉编码器中间层压缩令牌时优于所有现有方法，表现出卓越的有效性。此外，与外部压缩相比，我们的方法在保持强性能的同时，训练效率提升超过20%，推理吞吐量提升超过15%。

</details>


### [41] [Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization](https://arxiv.org/abs/2507.02288)
**中文标题：通过语言指导和表示对齐实现提示解缠的领域泛化**

*De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种通过语言指导和表示对齐实现提示解缠的领域泛化方法，利用预训练视觉基础模型（VFMs）的文本模态特性，结合大语言模型（LLM）解缠文本提示，并通过最差显式表示对齐（WERA）增强视觉表示的一致性，显著提升了模型在未见目标域上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 领域泛化（DG）旨在开发能在未见目标域上有效工作的模型。尽管基于预训练视觉基础模型（VFMs）的领域提示调优受到关注，但设计能够解缠跨领域不变特征的提示仍是一个关键挑战。本文利用VFMs的可控和灵活语言提示特性，提出通过语言指导和表示对齐解决这一挑战。

研究方法: 本文提出了一种文本特征引导的视觉提示调优框架，首先利用大语言模型（LLM）自动解缠文本提示，然后通过学习解缠文本特征引导的域不变视觉表示。为进一步解决视觉特征复杂性，引入最差显式表示对齐（WERA），通过抽象提示和风格化图像增强增强源域多样性，同时确保视觉表示在原始和增强分布上的一致性。

研究结果: 在PACS、VLCS、OfficeHome、DomainNet和TerraInc等主要DG数据集上的实验表明，本文方法优于当前最先进的领域泛化方法。

研究结论: 本文通过语言指导和表示对齐实现了提示解缠，显著提升了模型在未见目标域上的泛化能力，为领域泛化提供了新的解决方案。

中文摘要: 领域泛化（DG）旨在开发一种能够在未见目标域上有效工作的通用模型。近年来，预训练的视觉基础模型（VFMs，如CLIP）在提升深度学习模型泛化能力方面展现出巨大潜力。尽管基于VFMs的领域提示调优在DG中受到越来越多的关注，但设计能够解缠跨领域不变特征的有效提示仍是一个关键挑战。本文提出利用VFMs的可控和灵活语言提示来解决这一挑战。注意到VFMs的文本模态天然更易解缠，我们引入了一种文本特征引导的视觉提示调优框架。该框架首先利用大语言模型（LLM）自动解缠文本提示，然后通过学习解缠文本特征引导的域不变视觉表示。然而，仅依赖语言引导视觉特征解缠存在局限性，因为视觉特征有时过于复杂或微妙，无法完全通过描述性文本捕捉。为此，我们引入了最差显式表示对齐（WERA），通过引入一组抽象提示扩展文本引导的视觉提示。这些提示通过风格化图像增强增强源域多样性，同时对齐约束确保视觉表示在原始和增强分布上保持一致。在PACS、VLCS、OfficeHome、DomainNet和TerraInc等主要DG数据集上的实验表明，本文提出的方法优于当前最先进的DG方法。

</details>


### [42] [ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation](https://arxiv.org/abs/2507.02294)
**中文标题：ViRefSAM：基于视觉参考的Segment Anything模型用于遥感图像分割**

*Hanbo Bi,Yulong Xu,Ya Li,Yongqiang Mao,Boyuan Tong,Chongyang Li,Chunbo Lang,Wenhui Diao,Hongqi Wang,Yingchao Feng,Xian Sun*

主要分类: cs.CV

摘要简述: ViRefSAM是一种基于视觉参考的Segment Anything Model（SAM）改进框架，用于遥感图像分割。它通过少量标注参考图像自动生成提示，解决了SAM在遥感领域的手动提示效率低和领域适应性差的问题，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: SAM在通用分割任务中表现优异，但在遥感图像分割中面临两大挑战：手动构建精确提示效率低下，且缺乏对遥感领域特定语义和空间特征的适应性。ViRefSAM旨在通过少量参考图像自动生成提示并提升领域适应性。

研究方法: ViRefSAM引入两个关键组件：1）视觉上下文提示编码器，从参考图像提取类特定语义线索并生成目标图像的对象感知提示；2）动态目标对齐适配器，通过注入类特定语义到目标图像特征，减少领域差距。

研究结果: 在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$三个少样本分割基准测试中，ViRefSAM仅需少量参考图像即可实现未见类别的准确自动分割，性能优于现有少样本分割方法。

研究结论: ViRefSAM通过视觉参考和动态适配机制，显著提升了SAM在遥感图像分割中的性能，为少样本分割任务提供了高效解决方案。

中文摘要: Segment Anything Model（SAM）通过提示驱动范式在通用分割任务中表现出强大的泛化能力。然而，将SAM应用于遥感（RS）图像仍面临两大挑战：首先，为每张图像手动构建精确提示（如点或框）费时且低效，尤其是在遥感场景中对象密集或空间分布分散的情况下；其次，SAM缺乏领域适应性，因其主要基于自然图像预训练，难以捕捉遥感特定语义和空间特征，尤其是分割新类别时。为解决这些问题，受少样本学习启发，我们提出ViRefSAM，一种仅需少量包含类特定对象的标注参考图像即可指导SAM的新框架。无需手动提示，ViRefSAM可实现遥感图像中类一致对象的自动分割。具体而言，ViRefSAM在保持SAM原始架构不变的同时引入两个关键组件：（1）视觉上下文提示编码器，从参考图像提取类特定语义线索，并通过与目标图像的上下文交互生成对象感知提示；（2）动态目标对齐适配器，集成到SAM的图像编码器中，通过将类特定语义注入目标图像特征来减少领域差距，使SAM能动态聚焦任务相关区域。在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$三个少样本分割基准测试中的大量实验表明，ViRefSAM仅需少量参考图像即可实现未见类别的准确自动分割，且性能优于现有少样本分割方法。

</details>


### [43] [DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation](https://arxiv.org/abs/2507.02299)
**中文标题：DreamComposer++：通过多视角条件赋能扩散模型实现3D内容生成**

*Yunhan Yang,Shuo Chen,Yukun Huang,Xiaoyang Wu,Yuan-Chen Guo,Edmund Y. Lam,Hengshuang Zhao,Tong He,Xihui Liu*

主要分类: cs.CV

摘要简述: DreamComposer++ 是一个通过多视角条件增强扩散模型的框架，显著提升了3D内容生成的可控性和质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在从单张图像生成高质量新视角时缺乏多视角信息，导致可控性不足。DreamComposer++旨在通过引入多视角条件解决这一问题。

研究方法: DreamComposer++ 使用视角感知的3D提取模块从多视角提取3D表示，并通过多视角特征融合模块将其渲染为目标视角的潜在特征，最终集成到预训练的扩散模型中以生成新视角。

研究结果: 实验表明，DreamComposer++ 能够无缝集成先进的视角感知扩散模型，显著提升从多视角条件生成可控新视角的能力。

研究结论: DreamComposer++ 通过多视角条件增强了扩散模型，为可控3D对象重建和广泛应用提供了技术支持。

中文摘要: 近年来，利用预训练的2D扩散模型从单张野外图像生成高质量新视角取得了进展。然而，由于缺乏多视角信息，现有方法在生成可控新视角时面临挑战。本文提出DreamComposer++，一个灵活且可扩展的框架，旨在通过引入多视角条件改进当前的视角感知扩散模型。具体而言，DreamComposer++ 使用视角感知的3D提取模块从多视角提取对象的3D表示，并通过多视角特征融合模块将这些表示聚合并渲染为目标视角的潜在特征。最终，目标视角的特征被集成到预训练的图像或视频扩散模型中，用于新视角合成。实验结果表明，DreamComposer++ 能够无缝集成前沿的视角感知扩散模型，并增强其从多视角条件生成可控新视角的能力。这一进展为可控3D对象重建和广泛应用提供了支持。

</details>


### [44] [Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images](https://arxiv.org/abs/2507.02307)
**中文标题：Flow-CDNet：一种用于检测双时相图像中慢速和快速变化的新型网络**

*Haoxuan Li,Chenxu Wei,Haodong Wang,Xiaomeng Hu,Boyuan An,Lingyan Ran,Baosen Zhang,Jin Jin,Omirzhan Taukebayev,Amirkhan Temirbayev,Junrui Liu,Xiuwei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Flow-CDNet的新型网络，用于同时检测双时相图像中的慢速和快速变化。该网络包含光流分支和二进制变化检测分支，通过多尺度提取位移变化并结合ResNet生成变化输出。实验表明，该方法在自建数据集Flow-Change上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在实际场景中，双时相图像中的慢速变化（如斜坡、大坝和尾矿库中的微弱变化）往往是重大灾害的前兆。然而，现有方法难以同时检测慢速和快速变化，因此需要设计一种新型网络来解决这一挑战。

研究方法: Flow-CDNet由两个分支组成：光流分支通过金字塔结构提取多尺度位移变化，二进制变化检测分支结合ResNet和光流分支输出生成快速变化结果。此外，设计了自建数据集Flow-Change、结合二进制Tversky损失和L2范数损失的损失函数，以及新的评价指标FEPE。

研究结果: 在Flow-Change数据集上的定量实验表明，Flow-CDNet优于现有方法。消融实验验证了两个分支可以相互促进，提升检测性能。

研究结论: Flow-CDNet能够有效检测双时相图像中的慢速和快速变化，为实际应用提供了新的解决方案。

中文摘要: 变化检测通常涉及识别同一地点拍摄的双时相图像中的变化区域。除了显著变化外，双时相图像中的慢速变化在实际场景中也具有重要意义。例如，在斜坡、大坝和尾矿库等场景中，微弱变化往往是重大灾害的前兆。因此，设计一种能够同时检测慢速和快速变化的变化检测网络是一项新的挑战。本文针对这一挑战，提出了一种名为Flow-CDNet的变化检测网络，该网络包含两个分支：光流分支和二进制变化检测分支。第一分支利用金字塔结构提取多尺度位移变化，第二分支将基于ResNet的网络与光流分支的输出结合，生成快速变化结果。此外，为了监督和评估这一新的变化检测框架，设计了自建变化检测数据集Flow-Change、结合二进制Tversky损失和L2范数损失的损失函数，以及新的评价指标FEPE。在Flow-Change数据集上的定量实验表明，我们的方法优于现有方法。进一步的消融实验验证了两个分支可以相互促进，提升检测性能。

</details>


### [45] [LMPNet for Weakly-supervised Keypoint Discovery](https://arxiv.org/abs/2507.02308)
**中文标题：基于弱监督的关键点发现方法LMPNet**

*Pei Guo,Ryan Farrell*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LMPNet的弱监督关键点发现方法，通过创新的漏最大池化层和选择策略，自动发现语义关键点，性能接近监督模型。


<details>
  <summary>详细信息</summary>
研究动机: 研究目标是通过仅使用类别标签的弱监督方式，发现语义对象的关键点。传统方法依赖手工设计的损失项，而本文旨在通过直接操作网络滤波器来实现高效且可解释的关键点检测。

研究方法: 提出漏最大池化（LMP）层，鼓励卷积层滤波器学习“非重复局部模式”；设计选择策略确保滤波器激活一致性；使用注意力掩码迫使网络关注整个对象；最后通过可学习聚类层将关键点提案分组为预测结果。

研究结果: LMPNet能够自动发现对物体姿态鲁棒的语义关键点，其预测精度与监督姿态估计模型相当。

研究结论: LMPNet通过直接操作网络滤波器实现高效且可解释的关键点检测，为弱监督关键点发现提供了新思路。

中文摘要: 本文研究了仅通过类别标签弱监督的语义对象关键点发现任务。通过将判别训练的中间层滤波器转化为关键点检测器，我们实现了这一目标。首先，我们确定了关键点检测器的三个理想特性：（i）空间稀疏激活，（ii）一致性和（iii）多样性。为了避免依赖手工设计的损失项，我们提出了一种新颖的计算高效的漏最大池化（LMP）层，显式鼓励最终卷积层滤波器学习与对象关键点对齐的“非重复局部模式”。基于可视化结果，我们提出了一种简单而有效的选择策略，以确保滤波器激活的一致性，并通过注意力掩码迫使网络将注意力分布到整个对象而非仅最具判别性的区域。对于最终的关键点预测，我们提出了一种可学习的聚类层，将关键点提案分组为关键点预测。最终的模型名为LMPNet，具有高度可解释性，因为它直接操作网络滤波器来检测预定义的概念。实验表明，LMPNet能够（i）自动发现对物体姿态鲁棒的语义关键点，（ii）其预测精度与监督姿态估计模型相当。

</details>


### [46] [Perception Activator: An intuitive and portable framework for brain cognitive exploration](https://arxiv.org/abs/2507.02311)
**中文标题：感知激活器：一种直观便携的大脑认知探索框架**

*Le Xu,Qi Zhang,Qixian Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“Perception Activator”的框架，通过将fMRI信号注入多尺度图像特征，验证了fMRI包含丰富的多对象语义线索和空间定位信息，显著提升了目标检测和实例分割任务的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大脑视觉解码方法主要依赖像素级和语义级的两级策略，但缺乏细粒度的语义对齐，导致多语义对象重建失真。为了更深入理解大脑视觉感知模式和解码模型对语义对象的处理方式，作者开发了这一实验框架。

研究方法: 作者提出了一种实验框架，利用fMRI表征作为干预条件，通过跨注意力机制将其注入多尺度图像特征中，并在目标检测和实例分割任务中对比有无fMRI信息的下游性能和中间特征变化。

研究结果: 实验结果表明，引入fMRI信号显著提升了目标检测和实例分割的准确性，证实了fMRI包含丰富的多对象语义线索和粗略的空间定位信息，而这些信息尚未被现有模型充分利用。

研究结论: 该研究不仅验证了fMRI信号在视觉任务中的潜在价值，还为未来解码模型的优化提供了新思路，强调了语义对齐和空间信息整合的重要性。

中文摘要: 近年来，大脑视觉解码技术的进步显著推动了从神经活动（如功能磁共振成像fMRI）中高保真重建感知视觉刺激的研究。现有方法主要采用像素级和语义级的两级解码策略，但这些方法过度依赖低层像素对齐，缺乏足够的细粒度语义对齐，导致多语义对象重建明显失真。为了更好地理解大脑的视觉感知模式以及当前解码模型如何处理语义对象，我们开发了一种实验框架，利用fMRI表征作为干预条件。通过跨注意力机制将这些表征注入多尺度图像特征中，我们在目标检测和实例分割任务中对比了有无fMRI信息的下游性能和中间特征变化。结果表明，引入fMRI信号提升了检测和分割的准确性，证实了fMRI包含丰富的多对象语义线索和粗略的空间定位信息，而这些信息尚未被现有模型充分利用或整合。

</details>


### [47] [MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation](https://arxiv.org/abs/2507.02314)
**中文标题：MAGIC：基于掩模引导的扩散修复与多级扰动及上下文感知对齐的少样本异常生成**

*JaeHyuck Choi,MinJun Kim,JeHyeong Hong*

主要分类: cs.CV

摘要简述: MAGIC是一种基于扩散模型的少样本异常生成方法，通过多级扰动和上下文感知对齐，解决了背景破坏、掩模对齐和语义合理性问题，在工业质检中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 工业质检中异常数据稀缺，现有方法难以同时满足背景保护、掩模对齐和语义合理性需求。MAGIC旨在解决这些问题，提升异常生成的质量和多样性。

研究方法: MAGIC基于Stable Diffusion修复模型，通过微调确保背景完整和掩模对齐；引入高斯提示级扰动和掩模引导的空间噪声注入以增强多样性；上下文感知掩模对齐模块优化掩模位置，避免边界异常。

研究结果: 在MVTec-AD数据集上，MAGIC在下游异常任务中表现优于现有方法，实现了高质量的异常生成。

研究结论: MAGIC通过多级扰动和上下文对齐，解决了少样本异常生成中的关键问题，为工业质检提供了高效的数据增强工具。

中文摘要: 少样本异常生成是工业质检中解决异常数据稀缺问题的实用方案。理想的生成器需满足三个要求：（i）保持正常背景完整，（ii）修复的异常区域与掩模严格对齐，（iii）在语义合理位置生成多样且真实的异常。现有扩散方法通常仅满足其中两点：全局异常生成器会破坏背景，而掩模引导方法在掩模不精确或位置错误时表现不佳。我们提出MAGIC——基于掩模引导的修复、多级扰动和上下文感知对齐——以解决所有三个问题。MAGIC的核心是对Stable Diffusion修复模型进行微调，保护正常区域并确保生成的异常严格遵循掩模，直接解决背景破坏和不对齐问题。为弥补微调可能导致的多样性损失，MAGIC引入两种互补扰动策略：（i）在微调和推理时应用高斯提示级扰动，扩展异常全局外观并避免低质量文本表现；（ii）掩模引导的空间噪声注入，丰富局部纹理变化。此外，上下文感知掩模对齐模块建立语义对应关系并调整掩模位置，确保异常始终位于宿主对象内，消除边界外伪影。在MVTec-AD数据集的一致评估协议下，MAGIC在下游异常任务中优于现有方法。

</details>


### [48] [Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos](https://arxiv.org/abs/2507.02316)
**中文标题：合成视频有用吗？一个以检索为中心的合成视频评估基准**

*Zecheng Zhao,Selena Song,Tong Chen,Zhi Chen,Shazia Sadiq,Yadan Luo*

主要分类: cs.CV

摘要简述: 本文提出SynTVA数据集和基准，用于评估合成视频在文本到视频检索任务中的实用性，并通过自动评估器提升数据集扩展效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本到视频合成的评估指标主要关注视觉质量和时间一致性，而缺乏对下游任务（如文本到视频检索）性能的评估。本文旨在填补这一空白。

研究方法: 基于800个多样化用户查询生成合成视频，标注视频-文本对的四个语义对齐维度，并开发自动评估器预测对齐质量。

研究结果: SynTVA不仅为合成视频的实用性提供了基准，还能通过选择高质量样本显著提升文本到视频检索性能。

研究结论: SynTVA是评估和扩展合成视频数据集的宝贵工具，为下游任务提供了实用支持。

中文摘要: 文本到视频（T2V）合成技术发展迅速，但当前的评估指标主要关注视觉质量和时间一致性，对合成视频在下游任务（如文本到视频检索）中的表现提供有限洞察。本文提出SynTVA，一个旨在评估合成视频在构建检索模型中的实用性的新数据集和基准。基于MSRVTT训练集的800个多样化用户查询，我们使用最先进的T2V模型生成合成视频，并沿四个关键语义对齐维度标注每个视频-文本对：对象与场景、动作、属性和提示保真度。我们的评估框架将通用视频质量评估（VQA）指标与这些对齐分数关联，并检验它们对下游文本到视频检索性能的预测能力。为进一步探索扩展路径，我们还开发了一个自动评估器，用于从现有指标估计对齐质量。除了基准测试，我们的结果表明，SynTVA是数据集扩展的宝贵资产，能够选择显著提升文本到视频检索结果的高实用性合成样本。项目页面和数据集可在https://jasoncodemaker.github.io/SynTVA/找到。

</details>


### [49] [Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback](https://arxiv.org/abs/2507.02321)
**中文标题：倾听内部声音：通过中间特征反馈对齐ControlNet训练**

*Nina Konovalova,Maxim Nikolaev,Andrey Kuznetsov,Aibek Alanov*

主要分类: cs.CV

摘要简述: 本文提出InnerControl，一种通过中间特征反馈优化ControlNet训练的策略，提升文本到图像扩散模型的空间控制精度。


<details>
  <summary>详细信息</summary>
研究动机: 尽管文本到图像扩散模型取得显著进展，但精确的空间控制仍具挑战性。现有方法如ControlNet++仅关注最终去噪步骤，忽略了中间生成阶段，限制了效果。

研究方法: InnerControl通过训练轻量级卷积探针，从每个去噪步骤的中间UNet特征中重建输入控制信号（如边缘、深度），并利用伪真实控制信号优化训练。

研究结果: InnerControl结合ControlNet++等技术，在多种条件方法（如边缘、深度）上实现了最先进的性能，显著提升了控制保真度和生成质量。

研究结论: InnerControl通过全扩散过程的对齐损失，有效提升了空间一致性和生成效果，为文本到图像模型提供了更精确的控制能力。

中文摘要: 尽管文本到图像扩散模型取得了显著进展，但实现生成输出的精确空间控制仍具挑战性。ControlNet通过引入辅助条件模块解决了这一问题，而ControlNet++则通过仅应用于最终去噪步骤的循环一致性损失进一步优化对齐。然而，这种方法忽略了中间生成阶段，限制了其效果。我们提出InnerControl，一种训练策略，强制所有扩散步骤的空间一致性。我们的方法训练轻量级卷积探针，从每个去噪步骤的中间UNet特征中重建输入控制信号（如边缘、深度）。这些探针即使从高度噪声的潜在空间中也能高效提取信号，从而为训练提供伪真实控制。通过最小化整个扩散过程中预测条件与目标条件之间的差异，我们的对齐损失提高了控制保真度和生成质量。结合ControlNet++等现有技术，InnerControl在多种条件方法（如边缘、深度）上实现了最先进的性能。

</details>


### [50] [Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model](https://arxiv.org/abs/2507.02322)
**中文标题：基于神经网络的水稻叶片病害识别与分类研究：特征模型与直接成像模型的对比分析**

*Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi*

主要分类: cs.CV

摘要简述: 本研究比较了基于特征分析的检测模型（FADM）和直接图像中心检测模型（DICDM）在水稻叶片病害识别中的性能，发现FADM表现更优，为水稻病害早期检测提供了高效解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 水稻叶片病害严重影响产量和经济收益，早期检测对病害管理和提高产量至关重要。目前缺乏对FADM和DICDM的全面比较研究，尤其是特征提取算法的有效性评估。

研究方法: 研究采用人工神经网络（ANN）图像处理技术，分别构建FADM（使用多种特征提取、降维和选择算法及极限学习机）和DICDM（直接输入图像）。实验基于包含多种病害和健康叶片的数据集，采用10折交叉验证方法。

研究结果: 实验结果表明，FADM在分类性能上优于DICDM，为水稻病害识别提供了更高的准确性和可靠性。

研究结论: FADM在识别水稻叶片病害方面表现最佳，有望提升作物健康管理、减少产量损失，并促进水稻种植的可持续性。

中文摘要: 水稻叶片病害显著降低生产力并造成经济损失，凸显了早期检测以实现有效管理和提高产量的必要性。本研究提出基于人工神经网络（ANN）的图像处理技术，用于水稻病害的及时分类与识别。尽管目前普遍采用直接将水稻叶片图像输入ANN的方法，但缺乏对特征分析检测模型（FADM）和直接图像中心检测模型（DICDM）的全面比较分析，尤其是在评估特征提取算法（FEAs）的有效性方面。因此，本研究首次对FADM进行了实验，利用多种图像特征提取算法、降维算法（DRAs）、特征选择算法（FSAs）和极限学习机（ELM）。实验数据集涵盖细菌性叶枯病、褐斑病、叶瘟病、叶枯病、纹枯病和健康叶片，采用10折交叉验证方法。同时，建立了不使用任何FEA的DICDM，并通过不同指标评估分类性能。最终，对FADM和DICDM在水稻叶片病害分类中的表现进行了详尽对比。结果表明，FADM取得了最高性能。采用提出的FADM检测水稻叶片病害，在改善作物健康、减少产量损失以及提升水稻种植的整体生产力和可持续性方面具有巨大潜力。

</details>


### [51] [Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection](https://arxiv.org/abs/2507.02349)
**中文标题：基于两步神经网络的自动化脑血管标志检测**

*Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau*

主要分类: cs.CV

摘要简述: 本文提出了一种基于两步神经网络的自动化脑血管标志检测方法，通过目标检测网络和改良U-Net结合，显著提高了颅内动脉瘤关键分叉点的检测准确率。


<details>
  <summary>详细信息</summary>
研究动机: 颅内动脉瘤常发生在Willis环的特定分叉点，准确检测这些关键标志对快速诊断至关重要。现有方法在处理相邻标志或解剖变异时效果不佳，因此需要一种更高效的自动化检测方法。

研究方法: 采用两步神经网络方法：首先用目标检测网络定位感兴趣区域，再用改良的深监督U-Net精确定位分叉点。该方法解决了相邻标志视觉相似性和解剖变异带来的问题。

研究结果: 实验结果表明，该方法在两个脑MRA数据集（内部数据集和公共数据集）上均表现出最高的分叉点检测性能。

研究结论: 两步神经网络方法显著提升了脑血管标志检测的准确性和鲁棒性，适用于不同解剖变异和扫描条件下的诊断需求。

中文摘要: 颅内动脉瘤（ICA）通常发生在Willis环（CoW）的特定分叉点，尤其是十三个主要动脉分叉处。准确检测这些关键标志对快速高效诊断至关重要。我们提出了一种完全自动化的CoW分叉点检测方法，采用两步神经网络过程：首先通过目标检测网络定位标志附近的感兴趣区域（ROIs），随后利用改良的深监督U-Net精确定位分叉点。这种两步方法减少了多种问题，例如因两个标志相邻且视觉特征相似而导致的漏检，尤其是在处理完整的MRA Time-of-Flight（TOF）时。此外，该方法还考虑了CoW的解剖变异，这会影响每次扫描中可检测的标志数量。我们使用两个脑MRA数据集评估了该方法的有效性：一个是标志数量可变的内部数据集，另一个是具有标准化标志配置的公共数据集。实验结果表明，我们的方法在分叉点检测任务中达到了最高性能水平。

</details>


### [52] [Lightweight Shrimp Disease Detection Research Based on YOLOv8n](https://arxiv.org/abs/2507.02354)
**中文标题：基于YOLOv8n的轻量级虾病检测研究**

*Fei Yuhuan,Wang Gengchen,Liu Fenghao,Zang Ran,Sun Xufei,Chang Hao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于YOLOv8n的轻量级网络架构，用于虾病检测。通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度，并引入改进的SegNext_Attention自注意力机制提升特征提取能力。实验表明，模型参数减少32.3%，mAP@0.5达92.7%，优于其他轻量级YOLO系列模型。


<details>
  <summary>详细信息</summary>
研究动机: 虾病是虾类养殖中经济损失的主要原因之一。为提高虾病智能检测效率并预防疾病传播，本文提出了一种轻量化的检测方法，旨在平衡检测精度与计算效率。

研究方法: 1. 设计了RLDD检测头和C2f-EMCM模块，降低计算复杂度；2. 引入改进的SegNext_Attention自注意力机制，增强特征提取能力；3. 在自建虾病数据集和URPC2020数据集上进行实验验证。

研究结果: 模型参数减少32.3%，mAP@0.5达92.7%（比YOLOv8n提升3%），在URPC2020数据集上mAP@0.5比YOLOv8n提升4.1%，优于其他轻量级YOLO系列模型。

研究结论: 该方法在精度与效率之间实现了最佳平衡，为虾类养殖中的智能疾病检测提供了可靠技术支持。

中文摘要: 虾病是虾类养殖中经济损失的主要原因之一。为预防疾病传播并提升虾类养殖中的智能检测效率，本文提出了一种基于YOLOv8n的轻量级网络架构。首先，通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度，提升了计算效率。随后，引入改进的SegNext_Attention自注意力机制，进一步增强模型的特征提取能力，从而更精准地识别疾病特征。在自建虾病数据集上进行了大量实验，包括消融研究和对比评估，并将泛化测试扩展到URPC2020数据集。结果表明，所提模型参数比原始YOLOv8n减少32.3%，mAP@0.5达92.7%（比YOLOv8n提升3%）。此外，该模型在mAP@0.5、参数量和模型大小上均优于其他轻量级YOLO系列模型。在URPC2020数据集上的泛化实验进一步验证了模型的鲁棒性，mAP@0.5比YOLOv8n提升4.1%。该方法在精度与效率之间实现了最佳平衡，为虾类养殖中的智能疾病检测提供了可靠技术支持。

</details>


### [53] [Holistic Tokenizer for Autoregressive Image Generation](https://arxiv.org/abs/2507.02358)
**中文标题：用于自回归图像生成的整体分词器**

*Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Hita的新型图像分词器，用于自回归图像生成。它通过引入全局到局部的分词方案和关键策略，显著提升了生成图像的全局信息捕捉能力，并在实验中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 传统的自回归图像生成模型逐步生成视觉标记，限制了其对标记序列间全局关系的捕捉能力。此外，现有视觉分词器多将局部图像块映射为潜在标记，导致全局信息不足。本文旨在解决这些问题。

研究方法: Hita采用了一种全局到局部的分词方案，结合可学习的全局查询和局部块标记。关键策略包括：1）在序列结构中优先安排全局标记，并使用因果注意力保持对先前标记的感知；2）在解码前通过轻量级融合模块控制信息流，优先处理全局标记。

研究结果: 实验表明，Hita显著加速了自回归生成器的训练速度，并在ImageNet基准测试中取得了2.59 FID和281.9 IS的优异表现。此外，Hita还能有效捕捉全局图像属性（如纹理、材质和形状），并在零样本风格迁移和图像修复中表现突出。

研究结论: Hita通过改进的分词方案和策略，显著提升了自回归图像生成的性能，尤其在全局信息捕捉和生成质量方面表现突出。其开源代码为相关研究提供了实用工具。

中文摘要: 传统的自回归图像生成模型逐步生成视觉标记，限制了其对标记序列间全局关系的捕捉能力。此外，大多数视觉分词器将局部图像块映射为潜在标记，导致全局信息不足。为解决这些问题，我们提出了Hita，一种用于自回归图像生成的新型图像分词器。它引入了全局到局部的分词方案，结合可学习的全局查询和局部块标记。Hita还采用了两项关键策略以更好地与自回归生成过程对齐：1）在序列结构中优先安排全局标记，并使用因果注意力保持对先前标记的感知；2）在解码前通过轻量级融合模块控制信息流，优先处理全局标记。大量实验表明，Hita显著加速了自回归生成器的训练速度，并在ImageNet基准测试中取得了2.59 FID和281.9 IS的优异表现。对全局表示的详细分析表明，其能够捕捉纹理、材质和形状等全局图像属性。此外，Hita在零样本风格迁移和图像修复中也表现出色。代码已开源。

</details>


### [54] [LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling](https://arxiv.org/abs/2507.02363)
**中文标题：LocalDyGS：通过自适应局部隐式特征解耦的多视角全局动态场景建模**

*Jiahao Wu,Rui Peng,Jianbo Jiao,Jiayu Yang,Luyang Tang,Kaiqiang Xiong,Jie Liang,Jinbo Yan,Runling Liu,Ronggang Wang*

主要分类: cs.CV

摘要简述: LocalDyGS提出了一种新的动态场景建模方法，通过自适应局部隐式特征解耦，实现了对大尺度和小尺度动态场景的高效建模。


<details>
  <summary>详细信息</summary>
研究动机: 由于现实世界中动态运动的复杂性，从多视角输入合成任意视角的动态视频具有挑战性。现有方法在建模精细运动方面受限，难以应用于复杂动态场景。

研究方法: 1) 将复杂动态场景分解为由种子定义的局部空间，实现全局建模；2) 解耦静态和动态特征，静态特征捕捉静态信息，动态残差场提供时间特异性特征，结合生成时间高斯模型。

研究结果: LocalDyGS在精细运动数据集上表现优异，同时首次实现了对大尺度复杂动态场景的建模。

研究结论: LocalDyGS为动态场景重建提供了新框架，能够更真实地建模高度动态的现实场景。

中文摘要: 由于现实世界中复杂且高度动态的运动，从多视角输入合成任意视角的动态视频具有挑战性。基于神经辐射场或3D高斯泼溅的先前工作仅限于建模精细运动，极大地限制了其应用。本文提出LocalDyGS，包含两部分以适应大尺度和精细尺度动态场景：1) 将复杂动态场景分解为由种子定义的局部空间，通过捕捉每个局部空间内的运动实现全局建模；2) 解耦静态和动态特征用于局部空间运动建模。静态特征跨时间步共享以捕捉静态信息，动态残差场提供时间特异性特征，两者结合并解码生成时间高斯模型，建模局部空间内的运动。因此，我们提出了一种新的动态场景重建框架，能够更真实地建模高度动态的现实场景。我们的方法不仅在多种精细尺度数据集上表现出与最先进方法竞争的性能，还首次尝试建模更大更复杂的高度动态场景。项目页面：https://wujh2001.github.io/LocalDyGS/。

</details>


### [55] [UVLM: Benchmarking Video Language Model for Underwater World Understanding](https://arxiv.org/abs/2507.02373)
**中文标题：UVLM：面向水下世界理解的视频语言模型基准**

*Xizhe Xue,Yang Zhou,Dawei Yan,Ying Li,Haokui Zhang,Rong Xiao*

主要分类: cs.CV

摘要简述: 本文提出了UVLM，一个专注于水下世界理解的视频语言模型基准，通过结合人类专业知识和AI模型构建数据集，解决了水下环境独特挑战，并设计了多样化任务和评估指标。实验表明，在UVLM上微调的视频语言模型显著提升了水下场景理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频语言模型主要关注陆地场景，忽视了水下观测的高需求应用。为填补这一空白，本文提出UVLM，旨在为水下世界理解提供一个全面的基准。

研究方法: 通过结合人类和AI模型协作构建数据集，涵盖水下典型挑战（如光线变化、水质浑浊和多视角），并确保数据多样性（如帧率、分辨率、海洋生物类别）。任务设计分为生物和环境两大类，包含20种任务类型，并设计挑战性评估指标。

研究结果: 在两种代表性视频语言模型上的实验表明，UVLM微调显著提升了水下场景理解能力，同时对现有陆地基准（如VideoMME和Perception text）也有轻微改进潜力。

研究结论: UVLM为水下世界理解提供了首个全面基准，展示了视频语言模型在水下场景中的潜力，并推动了相关领域的发展。

中文摘要: 近年来，大型语言模型（LLMs）的显著成功对人工智能领域产生了深远影响。基于LLMs的众多先进工作被提出并应用于各种场景，其中视频语言模型（VidLMs）尤为广泛使用。然而，现有工作主要关注陆地场景，忽视了水下观测的高需求应用。为填补这一空白，我们提出了UVLM，一个通过结合人类专业知识和AI模型构建的水下观测基准。为确保数据质量，我们从多角度进行了深入考量。首先，针对水下环境的独特挑战，我们选择了包含光线变化、水质浑浊和多视角的典型水下视频构建数据集。其次，为确保数据多样性，数据集涵盖了广泛的帧率、分辨率、419类海洋生物以及各种静态植物和地形。接着，为任务多样性，我们采用了结构化设计，将观测目标分为生物和环境两大类，每类包括内容观测和变化/动作观测，总计20种任务类型。最后，我们设计了多项挑战性评估指标，以实现对不同方法的定量比较和分析。在两种代表性VidLMs上的实验表明，UVLM微调显著提升了水下世界理解能力，同时对现有陆地VidLM基准（如VideoMME和Perception text）也显示出轻微改进潜力。数据集和提示工程将公开发布。

</details>


### [56] [PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection](https://arxiv.org/abs/2507.02393)
**中文标题：PLOT：基于视频目标跟踪的可扩展单目3D目标检测伪标签方法**

*Seokyeong Lee,Sithu Aung,Junyong Choi,Seungryong Kim,Ig-Jae Kim,Junghyun Cho*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视频目标跟踪的伪标签框架（PLOT），用于解决单目3D目标检测中的数据稀缺问题，无需多视角设置或额外传感器，通过时间相邻帧的对象点跟踪实现3D属性提取。


<details>
  <summary>详细信息</summary>
研究动机: 单目3D目标检测（M3OD）因标注成本高和2D到3D的固有模糊性而面临数据稀缺问题。现有弱监督和伪标签方法多受限于领域特定学习或仅依赖单帧形状信息，本文旨在提出一种更鲁棒且无需额外资源的解决方案。

研究方法: 提出PLOT框架，仅需视频数据，通过对象点跟踪聚合静态和动态对象的伪LiDAR数据，实现3D属性提取，无需多视角、额外传感器或相机位姿。

研究结果: 实验表明，该方法在3D数据获取不可行的情况下仍能保证高精度和强扩展性，为M3OD提供了实用有效的解决方案。

研究结论: PLOT框架通过视频目标跟踪实现伪标签生成，显著提升了单目3D目标检测的鲁棒性和可扩展性，适用于实际应用场景。

中文摘要: 单目3D目标检测（M3OD）长期以来因标注成本高和2D到3D的固有模糊性而面临数据稀缺问题。尽管已有多种弱监督和伪标签方法试图解决这些问题，但它们大多受限于领域特定学习或仅依赖单帧形状信息。本文提出了一种仅需视频数据且对遮挡更鲁棒的伪标签框架，无需多视角设置、额外传感器、相机位姿或领域特定训练。具体而言，我们探索了一种通过对象点跟踪聚合时间相邻帧中静态和动态对象的伪LiDAR数据的技术，从而在3D数据获取不可行的情况下实现3D属性提取。大量实验表明，我们的方法确保了可靠的精度和强扩展性，为M3OD提供了一种实用有效的解决方案。

</details>


### [57] [Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis](https://arxiv.org/abs/2507.02395)
**中文标题：基于增强定位的持续多实例学习用于组织病理学全切片图像分析**

*Byung Hyun Lee,Wongi Jeong,Woojae Han,Kyoungbun Lee,Se Young Chun*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CoMEL的持续多实例学习框架，用于解决组织病理学全切片图像（WSI）分析中的定位和适应性问题，同时减少遗忘。通过结合高效实例编码、可靠的伪标记技术和低秩适应方法，CoMEL在多个数据集上显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 多实例学习（MIL）通过弱标注降低了大规模图像（如WSI）的标注成本，但其在持续任务中的适应性和定位能力尚未充分研究。现有方法主要针对自然图像，难以直接应用于WSI的MIL定位任务。因此，本文旨在提出一种能够同时解决定位和持续学习遗忘问题的MIL框架。

研究方法: CoMEL框架包含三个核心组件：(1) 分组双注意力变换器（GDAT）用于高效实例编码；(2) 基于袋原型的伪标记（BPPL）技术用于可靠的实例伪标记；(3) 正交加权低秩适应（OWLoRA）方法以减少袋和实例分类中的遗忘。

研究结果: 在三个公开WSI数据集上的实验表明，CoMEL在持续MIL设置下，袋级准确率最高提升11.00%，定位准确率最高提升23.4%，显著优于现有方法。

研究结论: CoMEL通过结合高效编码、可靠伪标记和低秩适应技术，成功解决了WSI分析中的持续学习和定位问题，为MIL在医学图像领域的应用提供了新思路。

中文摘要: 多实例学习（MIL）通过袋级弱标注显著降低了大规模图像（如组织病理学全切片图像WSI）的标注成本，但其在持续任务中的适应性和定位能力研究较少。现有方法主要针对自然图像，利用预训练模型对数百个小块（如16×16）的全局关系进行学习，但这种方法难以直接应用于MIL定位任务，因为WSI包含大量大块（如256×256）且缺乏全局关系（如癌细胞分布）。为解决这些问题，我们提出了基于增强定位的持续多实例学习框架（CoMEL），包含：(1) 分组双注意力变换器（GDAT）用于高效实例编码；(2) 基于袋原型的伪标记（BPPL）技术用于可靠实例伪标记；(3) 正交加权低秩适应（OWLoRA）以减少袋和实例分类中的遗忘。在三个公开WSI数据集上的实验表明，CoMEL在持续MIL设置下，袋级准确率最高提升11.00%，定位准确率最高提升23.4%，显著优于现有方法。

</details>


### [58] [Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection](https://arxiv.org/abs/2507.02398)
**中文标题：超越空间频率：基于像素级时间频率的深度伪造视频检测**

*Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于像素级时间频率的深度伪造视频检测方法，通过捕捉传统空间频率检测器忽略的时间不一致性，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统深度伪造视频检测方法主要依赖空间频率特征，而忽略了像素级的时间不一致性。这些方法通过堆叠空间频率谱来表征时间信息，导致无法有效检测像素平面中的时间伪影。本文旨在解决这一问题，提出一种更敏感的检测方法。

研究方法: 本文方法对每个像素在时间轴上进行一维傅里叶变换，提取对时间不一致性高度敏感的特征，尤其是在容易出现不自然运动的区域。此外，引入了一个端到端训练的注意力提议模块，用于精确定位包含时间伪影的区域。同时，通过联合变换器模块将像素级时间频率特征与时空上下文特征有效结合，扩大了可检测伪造伪影的范围。

研究结果: 实验表明，该方法在多样化和具有挑战性的检测场景中表现出色，显著提升了深度伪造视频检测的鲁棒性和准确性。

研究结论: 本文提出的基于像素级时间频率的检测框架在深度伪造视频检测领域取得了重要进展，为未来研究提供了新的方向。

中文摘要: 我们提出了一种深度伪造视频检测方法，该方法利用传统空间频率检测器常忽略的像素级时间不一致性。传统检测器仅通过堆叠帧间的空间频率谱来表征时间信息，导致无法检测像素平面中的时间伪影。我们的方法对每个像素在时间轴上进行一维傅里叶变换，提取对时间不一致性高度敏感的特征，尤其是在容易出现不自然运动的区域。为了精确定位包含时间伪影的区域，我们引入了一个端到端训练的注意力提议模块。此外，我们的联合变换器模块有效地将像素级时间频率特征与时空上下文特征结合，扩大了可检测伪造伪影的范围。我们的框架在深度伪造视频检测领域取得了显著进展，为多样化和具有挑战性的检测场景提供了鲁棒的性能。

</details>


### [59] [TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation](https://arxiv.org/abs/2507.02399)
**中文标题：TABNet：一种基于三重增强自恢复和边界感知伪标签的医学图像分割框架**

*Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang*

主要分类: cs.CV

摘要简述: TABNet提出了一种基于三重增强自恢复和边界感知伪标签的弱监督医学图像分割框架，显著提升了稀疏标注下的分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割需要大量标注数据，但获取完全标注的数据耗时且昂贵。涂鸦标注作为一种稀疏标注方式，虽然高效，但缺乏足够的边界监督，限制了特征学习。因此，需要一种方法在稀疏标注下提升分割性能。

研究方法: TABNet包含三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS通过强度变换、局部遮挡和拼图增强三种策略提升特征学习；BAP通过融合双分支预测和边界感知损失优化伪标签和边界建模。

研究结果: 在ACDC和MSCMR seg数据集上的实验表明，TABNet显著优于现有弱监督方法，性能接近全监督方法。

研究结论: TABNet通过三重增强和边界感知伪标签，有效提升了稀疏标注下的医学图像分割性能，为弱监督分割提供了新思路。

中文摘要: 背景与目标：医学图像分割是多种临床应用中的核心任务，但获取大规模完全标注的医学图像数据集耗时且昂贵。涂鸦标注作为一种稀疏标注方式，为医学图像分割提供了高效且经济的替代方案。然而，涂鸦标注的稀疏性限制了目标区域的特征学习，并缺乏足够的边界监督，这对训练分割网络提出了重大挑战。方法：我们提出了TABNet，一种新颖的弱监督医学图像分割框架，包含两个关键组件：三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS模块通过三种互补的增强策略提升特征学习：强度变换增强模型对纹理和对比度变化的敏感性，局部遮挡迫使网络通过遮挡关键区域捕获局部解剖结构，拼图增强通过破坏空间连续性强化全局解剖布局建模。通过引导网络从多样化的增强输入中恢复完整掩码，TAS在稀疏监督下促进了对医学图像的更深层次语义理解。BAP模块通过将双分支预测融合为损失加权的伪标签，并引入边界感知损失进行细粒度轮廓优化，提升了伪监督的准确性和边界建模能力。结果：在ACDC和MSCMR seg两个公开数据集上的实验评估表明，TABNet显著优于基于涂鸦的弱监督分割的现有方法，且性能接近全监督方法。

</details>


### [60] [Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings](https://arxiv.org/abs/2507.02403)
**中文标题：非城市环境中基于自监督学习的野生动物目标重识别**

*Mufhumudzi Muthivhi,Terence L. van Zyl*

主要分类: cs.CV

摘要简述: 本文探讨了自监督学习在野生动物重识别中的应用，通过无监督方式从相机陷阱数据中提取图像对训练模型，实验表明自监督模型在数据有限时表现更优，且在下游任务中优于监督学习。


<details>
  <summary>详细信息</summary>
研究动机: 当前野生动物重识别依赖标注数据进行监督学习，而标注数据的获取成本高。本研究旨在探索自监督学习在无标注数据情况下的表现，以降低对标注数据的依赖。

研究方法: 研究利用相机陷阱数据中的时间序列图像对，自动提取个体的两种视角，用于训练自监督模型。模型通过无监督方式学习特征表示，并在开放世界场景和下游任务中进行评估。

研究结果: 实验结果表明，自监督模型在数据有限时更具鲁棒性，且在所有下游任务中的表现优于监督学习模型。

研究结论: 自监督学习在野生动物重识别中具有潜力，能够减少对标注数据的依赖，并在实际应用中表现优异。

中文摘要: 野生动物重识别的目标是在不同观测中匹配同一物种的个体。当前最先进的模型依赖类别标签训练监督学习模型进行个体分类，这种对标注数据的依赖促使了大规模野生动物数据集的构建。本研究探讨了自监督学习在野生动物重识别中的应用。我们利用相机陷阱数据中的时间序列图像对，无监督地自动提取个体的两种视角。这些图像对用于训练自监督模型，模型可以从潜在的无限视频数据流中学习。我们在开放世界场景和各种野生动物下游任务中评估了学习到的表示与监督特征的对比。实验结果表明，自监督模型在数据有限时更具鲁棒性，且在所有下游任务中表现优于监督学习。代码可在https://github.com/pxpana/SSLWildlife获取。

</details>


### [61] [PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration](https://arxiv.org/abs/2507.02405)
**中文标题：PosDiffAE：结合伪影修复的高分辨率脑组织分类位置感知扩散自编码器**

*Ayantika Das,Moitreya Chaudhuri,Koushik Bhat,Keerthi Ram,Mihail Bota,Mohanasankar Sivaprakasam*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PosDiffAE的扩散自编码器模型，结合位置感知机制，用于高分辨率脑组织分类及伪影修复。通过结构化潜在空间和利用扩散模型的生成能力，实现了组织分类和伪影修复的无监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成高质量图像方面表现出色，但缺乏提取图像特定语义表示的能力。自编码器则能够提供这种表示，并结构化潜在空间。本文旨在结合两者的优势，开发一种能够识别脑组织区域模式并修复伪影的模型。

研究方法: 1. 设计了一种扩散自编码器模型，通过回归高分辨率图像块的位置信息来结构化潜在空间，以区分脑组织类型。2. 提出了一种基于邻域感知的无监督撕裂伪影修复技术。3. 利用扩散模型的可控噪声和去噪能力，开发了无监督JPEG伪影修复技术。

研究结果: 模型成功构建了一个有利于脑组织分类的潜在空间，并实现了无监督的撕裂伪影和JPEG伪影修复。

研究结论: PosDiffAE模型通过结合扩散模型和自编码器的优势，不仅能够高效分类脑组织，还能修复图像伪影，为医学图像分析提供了新的工具。

中文摘要: 去噪扩散模型通过从简单分布逐步构建复杂分布，生成高保真图像样本。尽管这些模型拓展了应用范围，但其采样机制无法提取图像特定的语义表示，而这正是自编码器的固有优势。自编码器的编码组件能够将特定图像映射到潜在空间，从而提供结构化潜在空间的手段。通过将编码器与扩散模型结合，我们建立了一种自编码框架，学习图像特定表示并组织潜在空间。本文中，首先，我们设计了一种机制来结构化扩散自编码模型的潜在空间，以识别脑图像中的区域特定细胞模式。通过强制表示回归高分辨率图像块的位置信息，创建了一个有利于区分脑组织类型的潜在空间。其次，基于邻域感知，利用潜在表示和扩散模型在推理时的受限生成能力，提出了一种无监督撕裂伪影修复技术。第三，通过表示引导和扩散模型在推理时可调控的噪声与去噪能力，开发了一种无监督JPEG伪影修复技术。

</details>


### [62] [A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern](https://arxiv.org/abs/2507.02408)
**中文标题：一种利用热成像传感器处理复杂运动模式的实时多目标跟踪新型调优方法**

*Duong Nguyen-Ngoc Tran,Long Hoang Pham,Chi Dai Tran,Quoc Pham-Nam Ho,Huy-Hung Nguyen,Jae Wook Jeon*

主要分类: cs.CV

摘要简述: 本文提出了一种新型调优方法，用于热成像传感器中的多目标实时跟踪，特别针对复杂运动模式，通过优化两阶段超参数提升跟踪性能。


<details>
  <summary>详细信息</summary>
研究动机: 热成像传感器在低能见度或弱光环境下优于RGB摄像头，但其低层次特征表示导致行人检测与跟踪困难。本文旨在解决这一问题，提升热成像中的行人跟踪精度。

研究方法: 提出了一种两阶段调优框架，通过优化每阶段的超参数，无需依赖复杂的重识别或运动模型，实现高精度实时跟踪。

研究结果: 在PBVS Thermal MOT数据集上的实验表明，该方法在各种热成像条件下均表现优异，适用于实际监控应用。

研究结论: 该方法为热成像中的多目标跟踪提供了一种高效、鲁棒的解决方案，适用于复杂环境下的实时监控。

中文摘要: 热成像中的多目标跟踪对监控系统至关重要，尤其在RGB摄像头因低能见度或弱光条件受限的环境中。热成像传感器通过捕捉红外特征提升识别任务，但其低层次特征表示导致行人检测与跟踪困难。为此，本文提出了一种新型调优方法，专门针对热成像中的复杂运动模式进行行人跟踪。该框架优化两阶段，确保每阶段采用最适合的超参数以最大化跟踪性能。通过实时跟踪的超参数调优，该方法在不依赖复杂重识别或运动模型的情况下实现高精度。在PBVS Thermal MOT数据集上的大量实验表明，该方法在各种热成像条件下均表现优异，为实际监控应用提供了鲁棒的解决方案。

</details>


### [63] [Privacy-preserving Preselection for Face Identification Based on Packing](https://arxiv.org/abs/2507.02414)
**中文标题：基于打包的隐私保护人脸识别预选方案**

*Rundong Xin,Taotao Wang,Jin Wang,Chonghe Zhao,Jing Wang*

主要分类: cs.CV

摘要简述: 提出了一种基于打包的隐私保护人脸识别预选方案（PFIP），通过预选机制和打包模块显著提升密文域人脸检索效率，同时保持高准确率。


<details>
  <summary>详细信息</summary>
研究动机: 随着隐私问题日益突出和原始人脸数据可能被恢复，密文域人脸识别系统受到广泛关注。然而，随着密文模板库规模增大，检索过程变得耗时。为解决这一问题，本文提出了一种高效的密文域人脸检索方案。

研究方法: PFIP方案包含创新的预选机制以减少计算开销，并引入打包模块以增强生物识别系统在注册阶段的灵活性。

研究结果: 在LFW和CASIA数据集上的实验表明，PFIP在保持原始人脸识别模型准确性的同时，能在300毫秒内检索1000个密文人脸模板，命中率达100%，检索效率比现有方法提升近50倍。

研究结论: PFIP通过预选和打包机制显著提升了密文域人脸检索的效率，同时确保了隐私保护和准确性，为大规模人脸识别系统提供了实用解决方案。

中文摘要: 由于隐私问题日益突出以及原始人脸数据可能被恢复，密文域人脸识别系统受到广泛关注。然而，随着密文模板库规模增大，人脸检索过程变得愈发耗时。为解决这一问题，我们提出了一种高效的密文域人脸检索方案，称为基于打包的隐私保护人脸识别预选方案（PFIP）。PFIP通过创新的预选机制减少计算开销，并通过打包模块增强生物识别系统在注册阶段的灵活性。在LFW和CASIA数据集上的大量实验表明，PFIP在保持原始人脸识别模型准确性的同时，能在300毫秒内检索1000个密文人脸模板，命中率达100%。与现有方法相比，PFIP的检索效率提升了近50倍。

</details>


### [64] [Determination Of Structural Cracks Using Deep Learning Frameworks](https://arxiv.org/abs/2507.02416)
**中文标题：基于深度学习框架的结构裂缝检测**

*Subhasis Dasgupta,Jaydip Sen,Tuhina Halder*

主要分类: cs.CV

摘要简述: 本研究提出了一种新型深度学习架构，通过集成残差U-Net模型和元模型，显著提高了结构裂缝检测的准确性和效率，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 结构裂缝检测对公共安全至关重要，但人工检测效率低且易出错。本研究旨在通过深度学习技术解决这些问题，提升检测的可靠性和效率。

研究方法: 研究采用多种残差U-Net模型配置，并将其集成到包含卷积块的元模型中，形成一种独特的组合方法。通过对比SegNet和传统U-Net，评估了集成模型的性能。

研究结果: 结果表明，残差U-Net模型在低分辨率图像中表现优异，集成模型在IoU和DICE系数上均超越单个模型，显示出更高的准确性。

研究结论: 该研究为结构缺陷监测任务提供了更可靠的自动化解决方案，证明了集成深度学习模型的优越性。

中文摘要: 结构裂缝检测是公共安全的关键任务，有助于预防可能危及生命的结构故障。缺乏经验的人员进行手动检测通常效率低下、结果不一致且容易出错，从而影响评估的可靠性。本研究通过引入一种新型深度学习架构来解决这些问题，旨在提高结构裂缝检测的准确性和效率。研究中采用了多种残差U-Net模型的配置，这些模型因其在捕捉细节方面的鲁棒性，被进一步集成到一个包含卷积块的元模型中。这种独特组合旨在将预测效率提升至超越单个模型的水平。集成模型的性能与SegNet和传统U-Net等成熟架构进行了对比评估。结果表明，残差U-Net模型在低分辨率图像中表现优于其前身，而集成模型则超越了单个模型的性能，被证明是最有效的。评估基于交并比（IoU）和DICE系数，集成模型取得了最高分，显示出卓越的准确性。这一进展为结构缺陷监测任务提供了更可靠的自动化系统。

</details>


### [65] [AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars](https://arxiv.org/abs/2507.02419)
**中文标题：AvatarMakeup：面向3D可动画化头像的真实化妆转移**

*Yiming Zhong,Xiaolin Zhang,Ligang Liu,Yao Zhao,Yunchao Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种名为AvatarMakeup的3D化妆方法，利用预训练扩散模型从单张参考照片中转移化妆效果，通过粗到细的策略确保动态表情和多视角下的一致性，并优化细节，实现了高质量的3D虚拟头像化妆。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D高斯编辑方法在实现真实化妆效果时存在不足，无法满足动态表情一致性、身份保持和细节精确控制的需求。因此，本文旨在解决这些问题，为3D虚拟头像提供高质量的个性化化妆效果。

研究方法: AvatarMakeup采用预训练扩散模型生成化妆图像作为监督，提出Coherent Duplication方法粗粒度地应用化妆并确保动态和多视角一致性，随后通过Refinement Module优化细节。

研究结果: 实验表明，AvatarMakeup在化妆转移质量和动画一致性方面达到了最先进的水平。

研究结论: AvatarMakeup成功解决了3D虚拟头像化妆中的关键问题，实现了高质量且一致的化妆效果，为个性化3D头像定制提供了有效工具。

中文摘要: 与现实生活中的面部美化类似，3D虚拟头像需要个性化定制以提升视觉吸引力，但这一领域尚未得到充分探索。尽管当前的3D高斯编辑方法可以用于面部化妆，但这些方法无法满足实现真实化妆效果的基本要求：1）确保在可驱动表情下外观一致，2）在化妆过程中保持身份不变，3）实现对精细细节的精确控制。为此，我们提出了一种名为AvatarMakeup的专用3D化妆方法，利用预训练的扩散模型从任何个体的单张参考照片中转移化妆图案。我们采用从粗到细的思路，首先确保外观和身份的一致性，然后优化细节。具体而言，扩散模型用于生成化妆图像作为监督。由于扩散过程中的不确定性，生成的图像在不同视角和表情下不一致。因此，我们提出了一种Coherent Duplication方法，粗粒度地将化妆应用于目标头像，同时确保动态和多视角效果的一致性。Coherent Duplication通过记录生成的化妆图像中的平均面部属性来优化全局UV贴图。通过查询全局UV贴图，可以轻松合成任意视角和表情下的一致性化妆指导，以优化目标头像。在获得粗粒度化妆头像后，我们进一步通过将Refinement Module整合到扩散模型中，提升化妆质量。实验表明，AvatarMakeup在化妆转移质量和动画一致性方面达到了最先进的水平。

</details>


### [66] [F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning](https://arxiv.org/abs/2507.02437)
**中文标题：F²TTA：基于图像级解耦提示调谐的跨域医学图像分类自由形式测试时适应**

*Wei Li,Jingyang Zhang,Lihao Liu,Guoan Wang,Junjun He,Yang Chen,Lixu Gu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为F²TTA的自由形式测试时适应方法，通过图像级解耦提示调谐（I-DiPT）解决跨域医学图像分类中的不可预测域片段偏移问题。该方法结合不确定性导向掩码和平行图蒸馏技术，显著优于现有TTA方法。


<details>
  <summary>详细信息</summary>
研究动机: 在临床实践中，医学数据通常以任意长度和随机顺序的域片段形式到达，导致现有测试时适应（TTA）方法无法有效处理这种自由形式的域偏移。本文旨在解决这一问题。

研究方法: 提出图像级解耦提示调谐（I-DiPT）框架，包括图像不变提示和图像特定提示，分别用于提取域不变表示和适应测试图像。引入不确定性导向掩码（UoM）和平行图蒸馏（PGD）技术以增强知识表示和历史知识重用。

研究结果: 在乳腺癌和青光眼分类任务上的实验表明，F²TTA方法在自由形式测试时适应任务中显著优于现有TTA方法。

研究结论: F²TTA通过I-DiPT框架和UoM、PGD技术，成功解决了自由形式域片段中的不可预测偏移问题，为跨域医学图像分类提供了有效解决方案。

中文摘要: 测试时适应（TTA）因其无需标注数据的特点，成为适应源模型到未见医学站点的有前景方法。然而，现有TTA方法假设数据以完整域单元到达，而临床实践中数据通常以任意长度和随机顺序的域片段形式到达。本文研究了一种实用的自由形式测试时适应（F²TTA）任务，其中源模型需适应此类自由形式域片段，且片段间偏移不可预测。为解决这一问题，我们提出了一种新颖的图像级解耦提示调谐（I-DiPT）框架。I-DiPT利用图像不变提示探索域不变表示以缓解不可预测偏移，同时使用图像特定提示适应每个测试图像。由于仅有一张图像可用于训练，提示可能知识表示不足。为此，我们首先引入不确定性导向掩码（UoM），通过源模型表示的不确定性驱动掩码一致性学习，促使提示从输入图像中提取足够信息。其次，提出平行图蒸馏（PGD）方法，通过平行图网络重用历史图像特定和图像不变提示的知识。在乳腺癌和青光眼分类任务上的实验证明了F²TTA优于现有TTA方法。代码发布于https://github.com/mar-cry/F2TTA。

</details>


### [67] [Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic](https://arxiv.org/abs/2507.02443)
**中文标题：基于FPGA可编程逻辑的加速人工神经网络红葡萄检测**

*Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias*

主要分类: cs.CV

摘要简述: 本文提出了一种利用FPGA加速人工神经网络（ANN）的方法，通过FINN架构部署三种量化模型（MobileNet v1、CNV-2bit和BNN-1bit），成功提升了红葡萄检测的速度和准确率，最高达到98%的成功率和6611 FPS的推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 机器人通常因检测算法速度慢而降低任务执行效率，现有工具（如Vitis-AI）未能充分利用FPGA的可编程逻辑（PL）。本文旨在通过FPGA加速ANN，使其适用于注意力机制，提升检测效率。

研究方法: 使用FINN架构在FPGA的PL中部署三种量化ANN模型：MobileNet v1（4-bit）、CNV（2-bit）和BNN（1-bit），并在自采集的RG2C数据集上进行训练和测试。

研究结果: MobileNet v1表现最佳，成功率达98%，推理速度达6611 FPS，证明了FPGA加速ANN的可行性和高效性。

研究结论: 本文验证了FPGA加速ANN的潜力，使其适用于实时检测任务，为机器人视觉系统提供了高效解决方案。

中文摘要: 机器人在移动过程中通常会因检测物体而减速，且摄像头帧率较低以匹配检测算法的速度，这限制了任务执行和探索效率。AMD开发的Vitis-AI框架虽可将检测算法部署到FPGA中，但未充分利用FPGA的可编程逻辑（PL）。本研究采用FINN架构，在FPGA的PL中部署了三种人工神经网络：MobileNet v1（4-bit量化）、CNV（2-bit量化）和BNN（1-bit量化），并在开放的RG2C数据集上训练。MobileNet v1表现最佳，成功率达98%，推理速度达6611 FPS。本研究证明了FPGA可加速ANN，使其适用于注意力机制。

</details>


### [68] [From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding](https://arxiv.org/abs/2507.02790)
**中文标题：从长视频到吸引人的短片：一种基于多模态叙事理解的人类启发式视频编辑框架**

*Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种受人类启发的自动视频编辑框架（HIVE），通过多模态叙事理解将长视频转化为吸引人的短片。该方法结合角色提取、对话分析和叙事总结，显著提升了编辑质量。


<details>
  <summary>详细信息</summary>
研究动机: 随着短视频平台的兴起，如何高效地将长视频剪辑成简洁且吸引人的短片成为迫切需求。现有方法主要依赖文本线索，忽略了丰富的视觉上下文，导致输出不连贯。本文旨在通过多模态叙事理解解决这一问题。

研究方法: 提出HIVE框架，利用多模态大语言模型进行角色提取、对话分析和叙事总结，实现视频内容的全面理解。进一步通过场景级分割将编辑过程分为高光检测、开头/结尾选择和无关内容修剪三个子任务。

研究结果: 实验结果表明，HIVE框架在通用和广告导向的编辑任务中均优于现有基线，显著缩小了自动编辑与人工编辑视频之间的质量差距。

研究结论: HIVE框架通过多模态叙事理解提升了视频编辑的连贯性和吸引力，为自动视频编辑领域提供了新的研究方向。

中文摘要: 随着在线视频内容的快速增长，尤其是短视频平台的兴起，对能够将长视频浓缩为简洁且吸引人的短片的高效编辑技术的需求日益增加。现有的自动编辑方法主要依赖ASR转录的文本线索和端到端片段选择，往往忽略了丰富的视觉上下文，导致输出不连贯。本文提出了一种受人类启发的自动视频编辑框架（HIVE），通过多模态叙事理解解决这些局限性。我们的方法结合了角色提取、对话分析和通过多模态大语言模型实现的叙事总结，从而全面理解视频内容。为了进一步提升连贯性，我们应用场景级分割，并将编辑过程分解为三个子任务：高光检测、开头/结尾选择和无关内容修剪。为了促进该领域的研究，我们引入了DramaAD，一个包含800多集短剧和500个专业编辑广告片段的新基准数据集。实验结果表明，我们的框架在通用和广告导向的编辑任务中均优于现有基线，显著缩小了自动编辑与人工编辑视频之间的质量差距。

</details>


### [69] [IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising](https://arxiv.org/abs/2507.02445)
**中文标题：IGDNet：基于照明引导与去噪的零样本鲁棒低曝光图像增强**

*Hailong Yan,Junjian Huang,Tingwen Huang*

主要分类: cs.CV

摘要简述: IGDNet是一种零样本增强方法，仅需单张测试图像即可恢复低曝光图像的照明并抑制噪声，无需训练数据或先验知识。通过分解和去噪模块，显著提升复杂光照条件下的视觉质量，优于14种无监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖成对数据集且易导致过增强，实际应用中数据收集困难。IGDNet旨在解决这些问题，提出无需训练数据的零样本增强方案。

研究方法: IGDNet包含分解模块（通过密集连接网络分离照明和反射分量）和去噪模块（基于照明引导的像素自适应校正方法）。通过下采样生成噪声对并迭代优化。

研究结果: 在四个公开数据集上，IGDNet显著提升视觉质量，PSNR（20.41dB）和SSIM（0.860dB）优于14种无监督方法。

研究结论: IGDNet为零样本低曝光图像增强提供了高效解决方案，具有强泛化能力和噪声抑制效果，适用于复杂光照场景。

中文摘要: 现有低曝光图像恢复方法通常依赖成对的低曝光与正常光照图像进行监督学习，但实际场景中此类数据难以获取。此外，这些方法可能导致过增强，破坏正常光照区域。为解决这些问题，我们提出IGDNet，一种零样本增强方法，仅需单张测试图像，无需先验知识或训练数据。IGDNet具有强泛化能力，能有效抑制噪声并恢复照明。该框架包含分解模块和去噪模块：前者通过密集连接网络将图像分离为照明与反射分量，后者利用照明引导的像素自适应校正方法增强非均匀光照区域。通过下采样生成噪声对并迭代优化，最终输出结果。在四个公开数据集上的实验表明，IGDNet在复杂光照条件下显著提升视觉质量。定量结果显示，其PSNR（20.41dB）和SSIM（0.860dB）优于14种先进无监督方法。代码即将发布。

</details>


### [70] [Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection](https://arxiv.org/abs/2507.02454)
**中文标题：基于数量提示的弱监督对比学习用于移动红外小目标检测**

*Weiwei Duan,Luping Ji,Shengjia Chen,Sicheng Zhu,Jianghong Huang,Mao Ye*

主要分类: cs.CV

摘要简述: 本文提出了一种弱监督对比学习方案（WeCoL），仅需目标数量提示即可训练模型，用于移动红外小目标检测，性能接近全监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 移动红外小目标检测因目标尺寸小、背景对比度低而面临巨大挑战，现有方法多为全监督，依赖大量人工标注。本文旨在通过弱监督策略减少标注需求。

研究方法: 基于预训练的SAM模型，设计了潜在目标挖掘策略，结合目标激活图和多帧能量累积；采用对比学习提升伪标签可靠性；提出长短时运动感知学习方案建模目标运动模式。

研究结果: 在DAUB和ITSDT-15K数据集上的实验表明，该弱监督方案性能优于早期全监督方法，甚至达到SOTA全监督方法的90%以上。

研究结论: WeCoL方案通过弱监督和对比学习有效减少了标注需求，性能接近全监督方法，为红外小目标检测提供了新思路。

中文摘要: 与一般目标检测不同，移动红外小目标检测因目标尺寸微小和背景对比度弱而面临巨大挑战。目前大多数方法为全监督，严重依赖大量人工目标级标注。然而，手动标注视频序列通常昂贵且耗时，尤其是对低质量红外帧图像。受一般目标检测启发，非全监督策略（如弱监督）被认为有潜力减少标注需求。为突破传统全监督框架，本文首次提出一种新的弱监督对比学习（WeCoL）方案，仅需在模型训练时提供简单的目标数量提示。具体而言，在我们的方案中，基于预训练的SAM模型，设计了潜在目标挖掘策略，整合目标激活图和多帧能量累积。此外，采用对比学习通过计算特征子空间中正负样本的相似性，进一步提升伪标签的可靠性。我们还提出了一种长短时运动感知学习方案，同时建模小目标的局部运动模式和全局运动轨迹。在DAUB和ITSDT-15K两个公开数据集上的大量实验验证了我们的弱监督方案通常优于早期全监督方法，其性能甚至可达当前最优（SOTA）全监督方法的90%以上。

</details>


### [71] [Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk](https://arxiv.org/abs/2507.02477)
**中文标题：Mesh Silksong：自回归网格生成如织丝**

*Gaochao Song,Zibo Zhao,Haohan Weng,Jingbo Zeng,Rongfei Jia,Shenghua Gao*

主要分类: cs.CV

摘要简述: Mesh Silksong提出了一种紧凑高效的网格表示方法，通过自回归方式生成多边形网格，减少冗余顶点标记，压缩率提升至22%，并生成具有优越几何特性的网格。


<details>
  <summary>详细信息</summary>
研究动机: 现有网格标记化方法常因重复顶点标记浪费网络能力，Mesh Silksong旨在通过减少冗余标记和提升几何特性，优化网格生成效率和质量。

研究方法: Mesh Silksong通过仅访问每个顶点一次的方式标记网格顶点，减少50%的标记序列冗余，并采用自回归方式生成网格，确保几何特性如流形拓扑、水密检测和一致法线。

研究结果: 实验结果显示，Mesh Silksong实现了约22%的压缩率，生成的网格具有优越的几何特性，同时显著提升了网格生成的几何完整性。

研究结论: Mesh Silksong通过减少冗余标记和优化几何特性，显著提升了网格生成的效率和质量，适用于实际应用。

中文摘要: 我们提出了Mesh Silksong，一种紧凑高效的网格表示方法，以类似于织丝的自回归方式生成多边形网格。现有的网格标记化方法常因重复顶点标记浪费网络能力，而我们的方法通过仅访问每个顶点一次的方式标记网格顶点，减少了50%的标记序列冗余，并实现了约22%的先进压缩率。此外，Mesh Silksong生成的网格具有优越的几何特性，包括流形拓扑、水密检测和一致法线，这对实际应用至关重要。实验结果证明了我们方法的有效性，不仅展示了复杂的网格生成，还显著提升了几何完整性。

</details>


### [72] [Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection](https://arxiv.org/abs/2507.02844)
**中文标题：视觉上下文攻击：通过图像驱动上下文注入越狱多模态大语言模型**

*Ziqi Miao,Yi Ding,Lijun Li,Jing Shao*

主要分类: cs.CV

摘要简述: 本文提出了一种新型视觉中心化越狱攻击方法VisCo，通过动态生成辅助图像和优化攻击提示，显著提升了针对多模态大语言模型（MLLMs）的攻击成功率。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在视觉语言任务中表现出色，但其视觉模态的安全漏洞限制了实际应用。现有攻击方法多依赖文本语义，视觉模态仅作为触发工具，缺乏现实场景的语义关联。本文旨在定义一种视觉中心化的越狱攻击场景，并开发高效攻击方法。

研究方法: 提出VisCo攻击方法，通过四种视觉策略构建上下文对话，动态生成辅助图像以形成视觉中心化越狱场景。结合自动毒性混淆和语义优化，生成最终攻击提示，显著提升攻击效果。

研究结果: VisCo在MM-SafetyBench上对GPT-4o的毒性评分达4.78，攻击成功率为85%，远超基线方法的2.48和22.2%。

研究结论: VisCo通过视觉中心化攻击策略，显著提升了MLLMs的越狱攻击效果，揭示了视觉模态在安全漏洞中的关键作用。

中文摘要: 随着强大的视觉语言能力的出现，多模态大语言模型（MLLMs）在实际应用中展现出巨大潜力。然而，视觉模态表现出的安全漏洞对开放环境中的模型部署提出了重大挑战。近期研究通过将有害文本语义直接编码到视觉输入中，成功诱导目标MLLMs生成有害响应。然而，这些方法中视觉模态主要作为不安全行为的触发器，常表现出语义模糊且缺乏现实场景的关联。本文定义了一种新场景：视觉中心化越狱，其中视觉信息是构建完整且现实越狱上下文的必要组成部分。基于此，我们提出VisCo（视觉上下文）攻击。VisCo通过四种视觉策略构建上下文对话，必要时动态生成辅助图像以形成视觉中心化越狱场景。为最大化攻击效果，它结合自动毒性混淆和语义优化，生成最终攻击提示，可靠地触发目标黑盒MLLMs的有害响应。具体而言，VisCo在MM-SafetyBench上对GPT-4o的毒性评分为4.78，攻击成功率为85%，显著优于基线方法的2.48和22.2%。代码发布于https://github.com/Dtc7w3PQ/Visco-Attack。

</details>


### [73] [CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios](https://arxiv.org/abs/2507.02479)
**中文标题：CrowdTrack：真实复杂场景中困难多行人跟踪的基准数据集**

*Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue*

主要分类: cs.CV

摘要简述: 本文提出了一个名为CrowdTrack的大规模复杂场景多行人跟踪数据集，填补了现有数据集在复杂性和真实性上的不足，并测试了多种先进模型在该数据集上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多目标跟踪数据集场景过于简单或不真实，无法满足复杂场景下的研究需求。为此，作者提出了一个基于第一人称视角、包含大量复杂场景的视频数据集，以促进复杂情况下有效算法的开发。

研究方法: 作者收集了33个视频，包含5,185条轨迹，每个对象标注了完整的边界框和唯一ID。数据集主要来自真实复杂场景，并测试了多种先进模型在该数据集上的表现。

研究结果: 数据集提供了复杂场景下的多行人跟踪基准，测试结果表明现有先进模型在复杂场景中表现不佳，凸显了该数据集的挑战性和研究价值。

研究结论: CrowdTrack数据集填补了现有数据集的不足，为复杂场景下的多行人跟踪研究提供了重要平台，并展示了现有模型的局限性。

中文摘要: 多目标跟踪是计算机视觉中的经典领域，其中行人跟踪具有极高的应用价值，成为最热门的研究类别。现有方法主要利用运动或外观信息进行跟踪，但在复杂场景中往往难以实现。对于运动信息，物体间的相互遮挡常导致运动状态无法更新；对于外观信息，由于物体仅部分可见或图像模糊等原因，往往得到非鲁棒的结果。尽管从标注数据中学习如何在复杂情况下进行跟踪是最简单的解决方案，但现有的多目标跟踪数据集无法满足这一需求。现有方法主要有两个缺点：场景组成相对简单且不真实。尽管现有数据集中部分视频序列没有上述缺点，但其数量远不足以满足研究需求。为此，我们提出了一个困难的大规模多行人跟踪数据集，主要从第一人称视角拍摄，且全部来自真实复杂场景。我们将其命名为“CrowdTrack”，因为大多数序列中包含大量物体。我们的数据集包含33个视频，共计5,185条轨迹。每个对象标注了完整的边界框和唯一ID。该数据集将为开发在复杂情况下仍有效的算法提供平台。我们对数据集进行了全面分析，并测试了多种先进模型在该数据集上的表现。此外，我们还分析了基础模型在该数据集上的性能。数据集和项目代码发布于：https://github.com/loseevaya/CrowdTrack。

</details>


### [74] [MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention](https://arxiv.org/abs/2507.02488)
**中文标题：MedFormer：具有内容感知双稀疏选择注意力的分层医学视觉Transformer**

*Zunhui Xia,Hongxing Li,Libin Lan*

主要分类: cs.CV

摘要简述: MedFormer提出了一种高效的医学视觉Transformer，通过金字塔缩放结构和内容感知的双稀疏选择注意力（DSSA）解决了现有方法通用性差和计算成本高的问题，显著提升了医学图像识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像识别在临床诊断中至关重要，但现有基于Transformer的方法存在通用性不足和计算成本高的问题。MedFormer旨在通过改进结构和注意力机制，提升模型的通用性和效率。

研究方法: MedFormer采用金字塔缩放结构作为通用主干网络，适用于多种医学图像识别任务。同时，引入内容感知的双稀疏选择注意力（DSSA），动态关注最相关内容，提高计算效率和鲁棒性。

研究结果: 实验表明，MedFormer在多种医学图像识别任务（如图像分类、语义分割和病变检测）中均表现出色，性能优于现有方法。

研究结论: MedFormer通过创新的结构和注意力机制，显著提升了医学图像识别的通用性和效率，为临床诊断提供了更高效的解决方案。

中文摘要: 医学图像识别是辅助临床诊断的重要手段，能够更准确、及时地识别疾病和异常。基于视觉Transformer的方法在多种医学识别任务中表现优异，但仍面临两大挑战：一是任务和架构的特定性限制了通用性；二是全注意力机制计算成本高，而手工设计的稀疏注意力可能导致性能下降。为解决这些问题，我们提出了MedFormer，一种高效的医学视觉Transformer。其核心创新包括：1）采用金字塔缩放结构作为通用主干网络，适用于图像分类、语义分割和病变检测等多种任务，既能分层表示特征，又能降低计算负担；2）引入内容感知的双稀疏选择注意力（DSSA），动态选择最相关内容，提升计算效率和鲁棒性。理论分析表明，MedFormer在通用性和效率上优于现有方法。在多种成像模态数据集上的实验证明，MedFormer在以上三类任务中均显著提升了性能。代码已开源：https://github.com/XiaZunhui/MedFormer。

</details>


### [75] [Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy](https://arxiv.org/abs/2507.02493)
**中文标题：时间感知的监督对比学习用于结肠镜检查中的息肉计数**

*Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi*

主要分类: cs.CV

摘要简述: 本文提出了一种时间感知的监督对比学习方法，用于结肠镜检查中的息肉计数，通过结合时间信息和视觉特征，显著降低了息肉跟踪的碎片化率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的息肉计数方法主要依赖自监督学习，忽略了时间关系，导致跟踪和聚类效果不佳。本文旨在通过引入时间感知的监督对比学习，提升息肉计数的准确性和鲁棒性。

研究方法: 提出了一种监督对比损失函数，结合时间感知的软目标，捕捉息肉内部的变异性并保持息肉间的区分性。同时，通过引入时间邻接约束，减少视觉相似但时间距离较远的轨迹错误关联。

研究结果: 实验结果表明，该方法在公开数据集上实现了2.2倍的碎片化率降低，显著优于现有方法。

研究结论: 时间感知在息肉计数中至关重要，本文提出的方法为息肉计数任务设定了新的技术标杆。

中文摘要: 自动化结肠镜检查中的息肉计数是实现自动化报告和质量控制的关键步骤，旨在提高结肠镜检查的成本效益。息肉计数涉及检测和跟踪息肉，并将属于同一息肉的轨迹聚类。现有的息肉计数方法依赖自监督学习，主要利用视觉特征，忽略了轨迹特征学习和聚类阶段的时间关系。本文通过提出一种结合时间感知软目标的监督对比损失函数，实现了范式转变。该方法在捕捉息肉内部变异性的同时保持了息肉间的区分性，从而实现了更鲁棒的聚类。此外，通过整合时间邻接约束，减少了视觉相似但时间距离较远的轨迹之间的错误重新关联。我们在公开数据集上训练和验证了该方法，并使用留一交叉验证策略评估其性能。结果表明，与现有方法相比，碎片化率降低了2.2倍。我们的结果突显了时间感知在息肉计数中的重要性，并确立了新的技术标杆。代码可在https://github.com/lparolari/temporally-aware-polyp-counting获取。

</details>


### [76] [MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations](https://arxiv.org/abs/2507.02494)
**中文标题：MC-INR：基于元学习和聚类隐式神经表示的多变量科学模拟数据高效编码方法**

*Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong*

主要分类: cs.CV

摘要简述: MC-INR是一种新型神经网络框架，结合元学习和聚类技术，高效编码多变量科学模拟数据，解决了现有隐式神经表示（INR）方法的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有隐式神经表示（INR）方法在复杂结构表示、多变量数据支持和结构化网格依赖方面存在不足，限制了其在真实世界数据集中的应用性能。

研究方法: MC-INR通过元学习和聚类技术实现复杂结构的灵活编码，引入基于残差的动态重聚类机制和分支层，支持多变量数据的高效处理。

研究结果: 实验结果表明，MC-INR在科学数据编码任务中优于现有方法。

研究结论: MC-INR通过创新设计解决了INR方法的局限性，为多变量科学数据的编码提供了高效解决方案。

中文摘要: 隐式神经表示（INR）被广泛用于将数据编码为连续函数，从而以较低的内存占用实现大规模多变量科学模拟数据的可视化。然而，现有的基于INR的方法存在三个主要局限性：（1）对复杂结构的表示不够灵活，（2）主要关注单变量数据，（3）依赖结构化网格。因此，其在复杂真实数据集上的性能会下降。为解决这些局限性，我们提出了一种新型神经网络框架MC-INR，用于处理非结构化网格上的多变量数据。该框架结合元学习和聚类技术，实现了复杂结构的灵活编码。为进一步提升性能，我们引入了一种基于残差的动态重聚类机制，能够根据局部误差自适应地划分聚类。此外，我们还提出了一种分支层，通过独立分支同时利用多变量数据。实验结果表明，MC-INR在科学数据编码任务中优于现有方法。

</details>


### [77] [Automatic Labelling for Low-Light Pedestrian Detection](https://arxiv.org/abs/2507.02513)
**中文标题：低光照行人检测的自动标注方法**

*Dimitrios Bouzoulas,Eerik Alamikkotervo,Risto Ojala*

主要分类: cs.CV

摘要简述: 本文提出了一种自动化的红外-RGB标注流程，用于解决低光照条件下行人检测数据不足的问题，并通过实验证明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 低光照条件下的行人检测在RGB图像中缺乏公开的大规模数据集，这限制了相关研究的进展。本文旨在通过自动化标注流程解决这一问题。

研究方法: 研究采用红外检测模型对行人进行初步检测，然后将标注从红外图像转移到对应的RGB图像，最后利用生成的标注训练低光照RGB行人检测模型。

研究结果: 实验结果显示，使用自动生成标注训练的模型在6/9的情况下优于使用真实标注训练的模型，表现为mAP@50和mAP@50-95指标的提升。

研究结论: 本文提出的自动化标注流程有效解决了低光照行人检测的数据标注问题，并显著提升了模型性能。

中文摘要: RGB图像中的行人检测是行人安全的关键任务，因为RGB摄像头是自动驾驶车辆和高级驾驶辅助系统中最常见的传感器。然而，低光照条件下的RGB行人检测缺乏大规模的公开数据集。为此，本研究提出了一种自动化的红外-RGB标注流程。该流程包括：1）红外检测，使用微调后的红外行人检测模型；2）将红外检测的标注转移到对应的RGB图像；3）利用生成的标注训练低光照RGB行人检测模型。研究基于KAIST数据集进行。评估结果显示，在使用自动生成标注训练的模型与使用真实标注训练的模型对比中，前者在6/9的情况下在mAP@50和mAP@50-95指标上表现更优。本研究的源代码可在https://github.com/BouzoulasDimitrios/IR-RGB-Automated-LowLight-Pedestrian-Labeling获取。

</details>


### [78] [Detecting Multiple Diseases in Multiple Crops Using Deep Learning](https://arxiv.org/abs/2507.02517)
**中文标题：使用深度学习检测多种作物中的多种疾病**

*Vivek Yadav,Anugrah Jain*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，旨在覆盖印度多样化的农业景观。通过构建包含17种作物和34种疾病的统一数据集，并训练深度学习模型，实现了99%的检测准确率，优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 印度作为以农业为主的经济体，面临作物疾病、害虫和环境压力导致的严重损失。早期准确检测不同作物的疾病对提高产量和保障粮食安全至关重要。

研究方法: 研究首先构建了一个包含17种作物和34种疾病的统一数据集，随后训练了一个深度学习模型。该模型在覆盖作物和疾病数量上优于现有技术。

研究结果: 模型在统一数据集上实现了99%的检测准确率，比现有技术（覆盖14种作物和26种疾病）高出7%。

研究结论: 通过提升可检测的作物和疾病种类，该解决方案旨在为印度农民提供更优的产品。

中文摘要: 印度作为一个以农业为主的经济体，在农业领域面临重大挑战，包括由疾病、害虫和环境压力导致的严重作物损失。早期检测并准确识别不同作物的疾病对提高产量和保障粮食安全至关重要。本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，旨在覆盖印度多样化的农业景观。我们首先构建了一个统一数据集，包含来自不同可用资源库的17种作物和34种疾病的图像。提出的深度学习模型在该数据集上训练，并在准确率和覆盖作物、疾病数量上优于现有技术。我们在统一数据集上实现了显著的检测准确率，即99%，比仅覆盖14种作物和26种疾病的现有技术高出7%。通过提升可检测的作物和疾病种类，该解决方案旨在为印度农民提供更优的产品。

</details>


### [79] [IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning](https://arxiv.org/abs/2507.02519)
**中文标题：IMASHRIMP：基于计算机视觉和深度学习的实验室图像自动白虾（凡纳滨对虾）生物测量分析**

*Abiam Remache González,Meriem Chagour,Timon Bijan Rüth,Raúl Trapiella Cañedo,Marina Martínez Soler,Álvaro Lorenzo Felipe,Hyun-Suk Shin,María-Jesús Zamorano Serrano,Ricardo Torres,Juan-Antonio Castillo Parra,Eduardo Reyes Abad,Miguel-Ángel Ferrer Ballester,Juan-Manuel Afonso López,Francisco-Mario Hernández Tejera,Adrian Penate-Sanchez*

主要分类: cs.CV

摘要简述: 本文介绍了IMASHRIMP系统，通过计算机视觉和深度学习技术自动分析白虾形态，优化水产养殖中的遗传选择任务。系统通过改进的ResNet-50架构和VitPose模块，显著降低人工误差，并实现高精度的形态测量。


<details>
  <summary>详细信息</summary>
研究动机: 水产养殖中，白虾的形态分析对遗传选择至关重要，但传统人工方法效率低且误差高。IMASHRIMP旨在通过自动化技术解决这一问题，提升分析效率和准确性。

研究方法: IMASHRIMP采用改进的ResNet-50架构进行图像分类和额角完整性检测，并基于VitPose模块预测23个关键点。此外，使用SVM模型将像素测量转换为厘米单位。

研究结果: 系统显著降低了人工误差，视角分类误差从0.97%降至0%，额角检测误差从12.46%降至3.64%。姿态估计的平均精度达97.94%，像素到厘米转换误差为0.07（±0.1）厘米。

研究结论: IMASHRIMP展示了自动化白虾形态分析的潜力，可提升遗传选择效率，推动可持续水产养殖发展。代码已开源。

中文摘要: 本文介绍了IMASHRIMP系统，一种用于自动分析白虾（凡纳滨对虾）形态的改进系统，旨在优化水产养殖中的遗传选择任务。通过改进现有的深度学习和计算机视觉技术，解决了从RGBD图像分析虾形态的特定挑战。IMASHRIMP包含两个基于改进ResNet-50架构的判别模块，用于按视角分类图像并确定额角完整性。系统提出“双因素认证（人类与AI）”机制，将视角分类的人工误差从0.97%降至0%，额角检测误差从12.46%降至3.64%。此外，基于VitPose的姿态估计模块被改进以预测虾骨架上的23个关键点，并针对侧视图和背视图分别设计网络。形态回归模块采用支持向量机（SVM）模型，将像素测量转换为厘米单位。实验结果表明，系统有效降低了人工误差，姿态估计的平均精度达97.94%，像素到厘米转换误差为0.07（±0.1）厘米。IMASHRIMP展示了自动化虾形态分析的潜力，可提升遗传选择效率，推动可持续水产养殖实践。代码发布于https://github.com/AbiamRemacheGonzalez/ImaShrimp-public。

</details>


### [80] [MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details](https://arxiv.org/abs/2507.02546)
**中文标题：MoGe-2：具有度量尺度和精细细节的精确单目几何估计**

*Ruicheng Wang,Sicheng Xu,Yue Dong,Yu Deng,Jianfeng Xiang,Zelong Lv,Guangzhong Sun,Xin Tong,Jiaolong Yang*

主要分类: cs.CV

摘要简述: MoGe-2是一种先进的单目几何估计模型，能够从单张图像中恢复具有度量尺度的3D点地图，同时保持相对几何精度和细节丰富性。


<details>
  <summary>详细信息</summary>
研究动机: 现有单目几何估计方法（如MoGe）只能预测未知尺度的仿射不变点地图，无法满足度量尺度需求，且真实数据中的噪声和误差会削弱几何细节。因此，需要一种既能恢复度量尺度又能保留精细几何细节的方法。

研究方法: MoGe-2通过扩展MoGe模型，引入度量尺度预测能力，同时开发了一种统一的数据优化方法，利用合成标签过滤和补全真实数据，显著提升几何细节的粒度。

研究结果: 实验表明，MoGe-2在保持相对几何精度的同时，实现了精确的度量尺度和丰富的细节恢复，性能优于现有方法。

研究结论: MoGe-2首次同时实现了精确的相对几何、度量尺度和细节恢复，为单目几何估计提供了新的解决方案。

中文摘要: 我们提出了MoGe-2，这是一种先进的开放域几何估计模型，能够从单张图像中恢复具有度量尺度的3D点地图。我们的方法基于最近的单目几何估计方法MoGe，该方法预测了未知尺度的仿射不变点地图。我们探索了有效策略，在不影响仿射不变点表示提供的相对几何精度的情况下，扩展MoGe以实现度量几何预测。此外，我们发现真实数据中的噪声和误差会削弱预测几何的精细细节。为此，我们开发了一种统一的数据优化方法，利用锐利的合成标签过滤和补全来自不同来源的真实数据，显著提升了重建几何的粒度，同时保持了整体准确性。我们在混合数据集上训练了模型，并进行了全面评估，结果表明其在实现精确的相对几何、度量尺度和细节恢复方面表现优异，这是以往方法无法同时实现的。

</details>


### [81] [Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning](https://arxiv.org/abs/2507.02565)
**中文标题：基于外观和空间关系推理的近距离人体交互重建**

*Buzhen Huang,Chen Li,Chongyang Xu,Dongyue Lu,Jinnan Chen,Yangang Wang,Gim Hee Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种基于外观和空间关系的双分支优化框架，用于从复杂视频中重建准确的人体交互动作，解决了现有方法在视觉模糊和遮挡情况下的不足。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人体姿态估计方法在视觉模糊和人际遮挡情况下难以恢复合理的近距离交互动作，即使是先进的模型（如SAM）也无法准确区分此类场景中的人体语义。

研究方法: 提出了一种双分支优化框架，结合扩散模型学习人体空间行为和姿态先验知识，并通过3D高斯、2D关键点和网格穿透等约束优化重建人体动作和外观。

研究结果: 实验结果表明，该方法在多个基准测试中优于现有方法，并能从复杂环境中捕获的视频中准确估计交互动作。

研究结论: 通过结合空间关系先验和多样化约束，本文方法能够有效解决复杂场景中的人体交互重建问题，并提供了带有伪真实标注的数据集以促进未来研究。

中文摘要: 由于视觉模糊和人际遮挡，现有的人体姿态估计方法无法从野外视频中恢复合理的近距离交互动作。即使是目前最先进的大型基础模型（如SAM）也无法在此类挑战性场景中准确区分人体语义。本研究发现，人体外观可以提供直接的线索来解决这些问题。基于这一观察，我们提出了一种双分支优化框架，通过结合人体外观、社交空间关系和物理规律的约束，重建准确的交互动作。具体而言，我们首先训练了一个扩散模型来学习人体空间行为和姿态先验知识。随后，将训练好的网络和两个可优化张量整合到双分支优化框架中，以重建人体动作和外观。此外，还设计了基于3D高斯、2D关键点和网格穿透的约束来辅助优化。通过空间关系先验和多样化约束，我们的方法能够从复杂环境中捕获的视频中准确估计交互动作。我们还构建了一个带有伪真实交互标注的数据集，以促进未来关于姿态估计和人类行为理解的研究。在多个基准测试上的实验结果表明，我们的方法优于现有方法。代码和数据可在https://www.buzhenhuang.com/works/CloseApp.html获取。

</details>


### [82] [Parametric shape models for vessels learned from segmentations via differentiable voxelization](https://arxiv.org/abs/2507.02576)
**中文标题：基于可微分体素化的分割学习血管参数化形状模型**

*Alina F. Dima,Suprosanna Shit,Huaqi Qiu,Robbie Holland,Tamara T. Mueller,Fabio Antonio Musio,Kaiyuan Yang,Bjoern Menze,Rickmer Braren,Marcus Makowski,Daniel Rueckert*

主要分类: cs.CV

摘要简述: 本文提出了一种通过可微分体素化从分割中学习血管参数化形状模型的框架，结合了体素、网格和参数化模型，实现了高保真度的血管几何捕捉。


<details>
  <summary>详细信息</summary>
研究动机: 血管是人体中的复杂结构，通常以体素、网格或参数化模型表示，但这些表示通常独立使用。本文旨在通过可微分变换将三者结合，直接从分割中学习参数化形状模型，避免对真实形状参数的依赖。

研究方法: 利用可微分体素化技术，通过形状到分割的拟合自动提取血管的参数化形状模型。血管被参数化为中心线和半径，使用三次B样条确保平滑性和连续性。网格从学习的形状参数中可微分地提取，支持后期调整。

研究结果: 实验表明，该方法能够准确捕捉复杂血管（如主动脉、动脉瘤和脑血管）的几何形状，生成高保真度的网格和体积拟合结果。

研究结论: 本文提出的框架成功地将体素、网格和参数化模型结合，通过可微分变换直接从分割中学习形状参数，为血管建模提供了高效且灵活的解决方案。

中文摘要: 血管是人体中广泛研究的复杂结构，通常以体素化、网格或参数化模型表示。尽管体素化最常见，但网格和参数化模型因其优越特性在多种应用中至关重要。然而，这些表示通常通过分割提取且彼此独立使用。我们提出了一种框架，通过可微分变换将三者结合。利用可微分体素化，我们通过形状到分割的拟合自动提取血管的参数化形状模型，无需依赖真实形状参数。血管被参数化为中心线和半径，使用三次B样条确保平滑性和连续性。网格从学习的形状参数中可微分地提取，生成高保真度且可后期调整的网格。实验表明，我们的方法能够准确捕捉复杂血管（如主动脉、动脉瘤和脑血管）的几何形状。

</details>


### [83] [Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning](https://arxiv.org/abs/2507.02581)
**中文标题：结构感知的语义差异与一致性在3D医学图像自监督学习中的应用**

*Tan Pan,Zhaorui Tan,Kaiyu Guo,Dongli Xu,Weidi Xu,Chen Jiang,Xin Guo,Yuan Qi,Yuan Cheng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为$S^2DC$的自监督学习框架，通过结构感知的语义差异和一致性，解决了3D医学图像中解剖结构变化的问题，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D医学图像自监督学习方法通常采用固定大小的图像块划分，忽略了解剖结构在位置、尺度和形态上的变化，导致无法有效捕捉有意义的差异。本文旨在通过学习结构感知的表征来解决这一问题。

研究方法: 提出的$S^2DC$框架分两步实现结构感知表征：1）通过最优传输策略增强不同图像块的语义差异；2）基于邻域相似性分布提升结构级别的语义一致性。

研究结果: 在10个数据集、4个任务和3种模态上的全面评估表明，$S^2DC$在3D医学图像自监督学习中始终优于现有方法。

研究结论: 通过结合语义差异和一致性，$S^2DC$成功实现了结构感知的表征学习，为医学图像分析提供了更有效的自监督学习方法。

中文摘要: 3D医学图像自监督学习（mSSL）在医学分析中具有巨大潜力。为了更广泛地支持应用，需要考虑解剖结构在位置、尺度和形态上的变化，这对捕捉有意义的差异至关重要。然而，现有的mSSL方法通常采用固定大小的图像块划分，忽略了结构变化。本文提出了一种新的视角，旨在学习结构感知的表征。我们假设同一结构内的图像块具有相同的语义（语义一致性），而不同结构的图像块则表现出不同的语义（语义差异）。基于这一假设，我们提出了名为$S^2DC$的mSSL框架，通过两个步骤实现结构感知的语义差异和一致性：首先，$S^2DC$利用最优传输策略增强不同图像块的语义差异；其次，$S^2DC$基于邻域相似性分布提升结构级别的语义一致性。通过结合图像块级别和结构级别的表征，$S^2DC$实现了结构感知的表征。在10个数据集、4个任务和3种模态上的全面评估表明，$S^2DC$在mSSL中始终优于现有方法。

</details>


### [84] [AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding](https://arxiv.org/abs/2507.02591)
**中文标题：AuroraLong：将RNN重新引入高效开放视频理解**

*Weili Xu,Enxin Song,Wenhao Chai,Xuexiang Wen,Tian Ye,Gaoang Wang*

主要分类: cs.CV

摘要简述: AuroraLong通过用线性RNN语言模型替换MLLM中的LLM组件，解决了长视频理解的高计算复杂性和内存成本问题，并在公开数据集上实现了与Transformer模型相当的性能。


<details>
  <summary>详细信息</summary>
研究动机: 长视频理解面临高计算复杂性和内存成本的挑战，尤其是基于Transformer的大型语言模型（LLM）在处理长序列时计算和内存需求呈二次方增长。AuroraLong旨在通过高效的线性RNN模型降低这一计算门槛。

研究方法: AuroraLong采用线性RNN语言模型替代MLLM中的LLM组件，支持任意长度输入序列且隐藏状态大小恒定。此外，通过按视觉标记大小升序重新排序，结合视觉标记合并技术进一步提升吞吐量和效率。

研究结果: 尽管仅使用2B参数且仅在公开数据上训练，AuroraLong在多个视频基准测试中表现与基于Transformer的同类模型相当，展示了线性RNN在长视频理解中的高效潜力。

研究结论: AuroraLong证明了线性RNN模型在降低长视频理解计算门槛方面的潜力，为开放视频理解任务提供了一种高效解决方案。

中文摘要: 长视频理解的挑战在于其高计算复杂性和高昂的内存成本，因为基于Transformer的大型语言模型（LLM）所需的内存和计算量与输入序列长度呈二次方增长。我们提出AuroraLong来解决这一挑战，通过用线性RNN语言模型替换MLLM中的LLM组件，该模型可以处理任意长度的输入序列，同时保持隐藏状态大小恒定。为了进一步提高吞吐量和效率，我们通过按视觉标记大小升序重新排序，将视觉标记合并与线性RNN模型结合。尽管仅使用2B参数且仅在公开数据上训练，AuroraLong在多个视频基准测试中表现与基于Transformer的同类模型相当。这表明高效的线性RNN有望通过降低计算门槛来普及长视频理解。据我们所知，我们是首个在类似LLaVA的模型中使用基于线性RNN的LLM主干进行开放视频理解的研究。

</details>


### [85] [Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development](https://arxiv.org/abs/2507.02602)
**中文标题：视觉导航中相机传感器故障的应对：模拟与数据集开发**

*Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill*

主要分类: cs.CV

摘要简述: 本文针对视觉导航中相机传感器故障问题，通过模拟和数据集开发，为AI故障检测算法提供支持。


<details>
  <summary>详细信息</summary>
研究动机: 随着视觉导航算法在太空任务中的重要性增加，传感器故障可能导致导航算法输出不准确或完全失效，影响任务目标。传统故障检测方法存在局限，而AI虽能提供解决方案，但缺乏包含故障图像的代表性数据集。

研究方法: 研究以星际探索任务为背景，系统分析相机传感器故障案例及其对图像质量和导航算法的影响，并开发模拟框架生成合成故障图像数据集。

研究结果: 研究提出了一个模拟框架，能够系统生成故障图像数据集，为AI故障检测算法的训练和测试提供工具。

研究结论: 通过模拟和数据集开发，研究为视觉导航中相机传感器故障的AI检测提供了重要支持，填补了数据集的空白。

中文摘要: 视觉导航算法在太空任务中的重要性日益增加，但其可靠性和操作鲁棒性面临诸多挑战。传感器故障可能导致导航算法输出不准确或完全失效，从而危及任务目标。人工智能（AI）为检测此类故障提供了强大的解决方案，克服了传统故障检测方法的许多局限性。然而，AI在此领域应用的主要障碍是缺乏足够且具有代表性的包含故障图像的数据集。

本研究以星际探索任务为背景，针对视觉导航流程中相机传感器的潜在故障案例进行了全面分析。系统描述了这些故障的原因和影响，包括其对图像质量和导航算法性能的影响，以及常用的缓解策略。为支持这一分析，研究引入了一个模拟框架，用于在合成图像中重现故障条件，从而实现对故障数据的系统和可控复现。生成的故障注入图像数据集为训练和测试基于AI的故障检测算法提供了宝贵工具。最终数据集的链接将在禁运期后添加。审稿人可通过私密链接访问。

</details>


### [86] [AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models](https://arxiv.org/abs/2507.02664)
**中文标题：AIGI-Holmes：基于多模态大语言模型的可解释且泛化性强的AI生成图像检测**

*Ziyin Zhou,Yunpeng Luo,Yuanchen Wu,Ke Sun,Jiayi Ji,Ke Yan,Shouhong Ding,Xiaoshuai Sun,Yunsheng Wu,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出AIGI-Holmes，一种基于多模态大语言模型的可解释且泛化性强的AI生成图像检测方法，通过构建大规模数据集和精心设计的三阶段训练框架，解决了现有技术缺乏可解释性和泛化能力的问题。


<details>
  <summary>详细信息</summary>
研究动机: AI生成图像（AIGI）技术的快速发展导致其被滥用于传播虚假信息，威胁公共信息安全。现有检测技术缺乏可解释性和对最新生成技术的泛化能力，亟需改进。

研究方法: 1) 构建Holmes-Set数据集，包括带解释的指令调优数据集Holmes-SFTSet和人类偏好数据集Holmes-DPOSet；2) 提出Multi-Expert Jury数据标注方法；3) 设计三阶段训练框架Holmes Pipeline，结合视觉专家预训练、监督微调和直接偏好优化；4) 引入协作解码策略提升泛化能力。

研究结果: 在三个基准测试上的广泛实验验证了AIGI-Holmes的有效性，其能够生成可解释且符合人类偏好的检测结果，并具备较强的泛化能力。

研究结论: AIGI-Holmes通过多模态大语言模型和精心设计的数据集与训练框架，显著提升了AI生成图像检测的可解释性和泛化能力，为公共信息安全提供了有力支持。

中文摘要: AI生成内容（AIGC）技术的快速发展导致高度逼真的AI生成图像（AIGI）被滥用于传播虚假信息，威胁公共信息安全。尽管现有AIGI检测技术总体有效，但仍面临两个问题：1）缺乏可验证的解释；2）对最新生成技术缺乏泛化能力。为解决这些问题，我们构建了大规模综合数据集Holmes-Set，包括带解释的指令调优数据集Holmes-SFTSet和人类偏好数据集Holmes-DPOSet。我们提出了一种高效的数据标注方法Multi-Expert Jury，通过结构化多模态大语言模型（MLLM）解释和跨模型评估、专家缺陷过滤及人类偏好修正提升数据质量。此外，我们设计了Holmes Pipeline三阶段训练框架，包括视觉专家预训练、监督微调和直接偏好优化，将MLLM适配于AIGI检测并生成可验证且符合人类偏好的解释，最终得到模型AIGI-Holmes。在推理阶段，我们引入协作解码策略，结合视觉专家感知和MLLM语义推理，进一步提升泛化能力。在三个基准测试上的广泛实验验证了AIGI-Holmes的有效性。

</details>


### [87] [Learning few-step posterior samplers by unfolding and distillation of diffusion models](https://arxiv.org/abs/2507.02686)
**中文标题：通过展开和蒸馏扩散模型学习少步后验采样器**

*Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra*

主要分类: cs.CV

摘要简述: 本文提出了一种新框架，通过深度展开和模型蒸馏将扩散模型（DM）转化为少步后验采样器，结合了LATINO Langevin采样器的MCMC算法，实现了高精度和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在贝叶斯计算成像中表现出强大的图像先验能力，但现有方法如Plug-and-Play和条件DM各有局限性。本文旨在结合两者的优势，开发一种灵活且高效的少步后验采样方法。

研究方法: 通过深度展开和模型蒸馏，将扩散模型转化为少步条件模型。创新性地将LATINO Langevin采样器的MCMC算法展开，首次将深度展开应用于蒙特卡洛采样方案。

研究结果: 实验表明，提出的展开和蒸馏采样器在精度和计算效率上优于现有技术，同时保持了在前向模型变化时的灵活性。

研究结论: 本文方法成功地将扩散模型转化为高效的少步后验采样器，为贝叶斯计算成像提供了新的解决方案。

中文摘要: 扩散模型（DMs）已成为贝叶斯计算成像中强大的图像先验。目前有两种主要策略：零样本且高度灵活的Plug-and-Play方法，以及通过监督训练实现更高精度和更快推理的专用条件DMs。本文提出了一种新框架，通过深度展开和模型蒸馏将DM图像先验转化为少步条件模型用于后验采样。我们的核心创新是将马尔可夫链蒙特卡洛（MCMC）算法——特别是最近提出的LATINO Langevin采样器（Spagnoletti等，2025）——展开，这是首次将深度展开应用于蒙特卡洛采样方案。通过大量实验和与现有技术的比较，我们展示了所提出的展开和蒸馏采样器在精度和计算效率上的优异表现，同时保持了在前向模型变化时的灵活性。

</details>


### [88] [APT: Adaptive Personalized Training for Diffusion Models with Limited Data](https://arxiv.org/abs/2507.02687)
**中文标题：APT：基于自适应个性化训练的有限数据扩散模型优化**

*JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为APT的自适应个性化训练框架，用于解决扩散模型在有限数据下过拟合、丢失先验知识和文本对齐退化的问题。APT通过自适应训练策略和特征表示正则化，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 在有限数据下个性化扩散模型时，常出现过拟合、先验知识丢失和文本对齐退化等问题，这些问题导致噪声预测分布偏移和语义连贯性丧失。本文旨在解决这些挑战。

研究方法: APT框架包含三个关键组件：1) 自适应训练调整，通过过拟合指标动态调整数据增强和损失权重；2) 表示稳定化，正则化中间特征图的均值和方差；3) 注意力对齐，保持微调模型与预训练模型的交叉注意力图对齐以保留先验知识。

研究结果: 实验表明，APT能有效减少过拟合，保留先验知识，并在有限参考数据下生成高质量、多样化的图像，优于现有方法。

研究结论: APT通过自适应训练和正则化策略，成功解决了有限数据下扩散模型的个性化问题，为相关研究提供了新思路。

中文摘要: 在有限数据下个性化扩散模型面临过拟合、先验知识丢失和文本对齐退化等挑战。过拟合导致噪声预测分布偏移，破坏去噪轨迹并丧失语义连贯性。本文提出自适应个性化训练（APT），通过自适应训练策略和特征表示正则化解决这些问题。APT包含三个关键组件：1) 自适应训练调整，通过过拟合指标动态调整数据增强和损失权重；2) 表示稳定化，正则化中间特征图的均值和方差；3) 注意力对齐，保持微调模型与预训练模型的交叉注意力图对齐以保留先验知识。实验表明，APT能有效减少过拟合，保留先验知识，并在有限数据下生成高质量、多样化的图像，优于现有方法。

</details>


### [89] [CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation](https://arxiv.org/abs/2507.02691)
**中文标题：CanonSwap：通过规范空间调制实现高保真和一致的视频换脸**

*Xiangyang Luo,Ye Zhu,Yunfei Liu,Lijian Lin,Cong Wan,Zijian Cai,Shao-Lun Huang,Yu Li*

主要分类: cs.CV

摘要简述: CanonSwap提出了一种新的视频换脸框架，通过解耦面部外观和运动信息，在统一规范空间中进行身份修改，同时保留目标视频的动态属性，显著提升了视觉质量和时间一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频换脸方法在实现高质量身份转移时，往往难以保持目标面部的动态属性（如头部姿势、表情等），导致结果不一致。论文认为这是面部外观和运动信息耦合所致，因此提出解耦这两者的方法。

研究方法: CanonSwap首先消除运动相关信息，在规范空间中进行身份修改，随后将交换后的特征重新整合到原始视频空间。此外，设计了部分身份调制模块，通过空间掩码自适应整合源身份特征，并引入细粒度同步指标进行评估。

研究结果: 实验表明，CanonSwap在视觉质量、时间一致性和身份保留方面显著优于现有方法，实现了高保真和一致的视频换脸效果。

研究结论: CanonSwap通过解耦外观和运动信息，结合部分身份调制模块，显著提升了视频换脸的质量和一致性，为相关领域提供了新的解决方案。

中文摘要: 视频换脸旨在解决两个主要挑战：有效将源身份转移到目标视频，并准确保留目标面部的动态属性（如头部姿势、表情、口型同步等）。现有方法主要关注高质量身份转移，但往往难以保持目标面部的动态属性，导致结果不一致。我们认为这是视频中面部外观和运动信息的固有耦合所致。为此，我们提出了CanonSwap，一种新颖的视频换脸框架，将运动信息与外观信息解耦。具体而言，CanonSwap首先消除运动相关信息，使身份修改在统一的规范空间中进行。随后，交换后的特征被重新整合到原始视频空间，确保目标面部的动态属性得以保留。为进一步实现精确身份转移并减少伪影，我们设计了部分身份调制模块，通过空间掩码自适应整合源身份特征。此外，我们引入了多个细粒度同步指标，全面评估视频换脸方法的性能。大量实验表明，我们的方法在视觉质量、时间一致性和身份保留方面显著优于现有方法。项目页面公开于https://luoxyhappy.github.io/CanonSwap/。

</details>


### [90] [SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment](https://arxiv.org/abs/2507.02705)
**中文标题：SIU3R：超越特征对齐的同步场景理解与3D重建**

*Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu*

主要分类: cs.CV

摘要简述: SIU3R是一种无需特征对齐的框架，首次实现了从未定位图像中同时进行场景理解和3D重建，通过像素对齐的3D表示和统一学习查询，避免了2D模型对齐的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖2D到3D特征对齐，导致3D理解能力有限和语义信息丢失。SIU3R旨在解决这一问题，提出无需对齐的框架，实现更高效的场景理解和3D重建。

研究方法: SIU3R通过像素对齐的3D表示桥接重建和理解任务，并将多任务统一为学习查询。设计了两个轻量模块促进任务间协作，分析其相互增益。

研究结果: 实验表明，SIU3R在3D重建、场景理解及两者联合任务上均达到最先进性能，验证了其无需对齐框架和互益设计的有效性。

研究结论: SIU3R通过创新框架和互益设计，显著提升了场景理解和3D重建的性能，为端到端智能系统提供了新思路。

中文摘要: 同步场景理解和3D重建在开发端到端智能系统中至关重要。现有方法依赖2D到3D特征对齐，导致3D理解能力有限和语义信息丢失。为此，我们提出SIU3R，首个无需对齐的通用框架，从未定位图像中实现同步理解和3D重建。SIU3R通过像素对齐的3D表示桥接重建与理解任务，并将多任务统一为学习查询，无需依赖2D模型对齐即可实现原生3D理解。为促进任务间协作，我们深入分析其互益性，并设计两个轻量模块优化交互。大量实验表明，SIU3R不仅在3D重建和场景理解的独立任务中表现优异，在同步任务上也达到最先进水平，凸显了无需对齐框架和互益设计的优势。

</details>


### [91] [UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation](https://arxiv.org/abs/2507.02713)
**中文标题：UniMC：驯服扩散变换器以实现统一关键点引导的多类图像生成**

*Qin Guo,Ailing Zeng,Dongxu Yue,Ceyuan Yang,Yang Cao,Hanzhong Guo,Fei Shen,Wei Liu,Xihui Liu,Dan Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为UniMC的DiT框架，用于统一多类图像生成，并发布了高质量数据集HAIG-2.9M，解决了现有关键点引导模型在非刚性物体和多类重叠生成中的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有关键点引导模型难以控制非刚性物体（如动物）的生成，且在多类重叠场景中表现不佳。这些问题源于现有方法的局限性及缺乏合适的数据集。

研究方法: 设计了基于DiT的UniMC框架，将实例和关键点条件整合为紧凑标记，并发布了包含丰富标注的HAIG-2.9M数据集。

研究结果: 实验表明HAIG-2.9M数据集质量高，UniMC在复杂遮挡和多类场景中表现优异。

研究结论: UniMC和HAIG-2.9M为多类关键点引导图像生成提供了有效解决方案，显著提升了生成质量和多样性。

中文摘要: 尽管关键点引导的文本到图像扩散模型取得了显著进展，但现有主流模型在控制更广泛的非刚性物体（如动物）生成方面仍面临挑战。此外，仅依赖关键点控制难以生成多个重叠的人和动物。这些挑战源于两方面：现有可控方法的固有局限性和缺乏合适的数据集。首先，我们设计了一个基于DiT的框架UniMC，探索统一可控的多类图像生成。UniMC将实例和关键点条件整合为紧凑标记，包含类别、边界框和关键点坐标等属性。这种方法克服了以往方法因依赖骨架图像作为条件而难以区分实例和类别的局限性。其次，我们提出了HAIG-2.9M，这是一个大规模、高质量且多样化的数据集，专为关键点引导的人和动物图像生成设计。HAIG-2.9M包含786K图像和2.9M实例，标注了关键点、边界框和细粒度描述，并经过严格人工检查以确保准确性。大量实验证明了HAIG-2.9M的高质量和UniMC的有效性，尤其是在复杂遮挡和多类场景中。

</details>


### [92] [FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models](https://arxiv.org/abs/2507.02714)
**中文标题：FairHuman：基于最小潜在延迟公平性的扩散模型中提升人类图像手和脸质量的方法**

*Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma*

主要分类: cs.CV

摘要简述: FairHuman是一种多目标微调方法，旨在公平提升扩散模型中人类图像的全局和局部生成质量，尤其是手和脸的细节。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大规模文本到图像模型（如扩散模型）在图像生成方面取得了显著进展，但在生成人类图像时，手和脸等局部细节仍因训练中监督不足而难以达到理想效果。

研究方法: FairHuman通过构建三个学习目标（一个全局目标和两个基于预标注位置先验的局部目标），并在最小潜在延迟（MPD）准则指导下优化参数更新策略，实现多目标问题的公平优化。

研究结果: 实验表明，FairHuman在保持整体生成质量的同时，显著提升了手和脸等挑战性局部细节的生成效果。

研究结论: FairHuman通过多目标公平优化策略，有效提升了人类图像生成中局部细节的质量，为扩散模型的应用提供了新思路。

中文摘要: 随着大规模文本到图像模型（尤其是基于扩散的模型）的发展，图像生成取得了显著进展。然而，由于训练中对局部区域的监督不足，生成具有合理细节（如脸或手）的人类图像仍然具有挑战性。为解决这一问题，我们提出了FairHuman，一种多目标微调方法，旨在公平提升全局和局部生成质量。具体而言，我们首先构建了三个学习目标：一个源自默认扩散目标函数的全局目标，以及两个基于预标注位置先验的手和脸局部目标。随后，我们在最小潜在延迟（MPD）准则的指导下，推导出最优参数更新策略，从而实现了这一多目标问题的公平优化。基于此，我们提出的方法在保持整体质量的同时，显著提升了挑战性局部细节的生成效果。大量实验证明了我们的方法在不同场景下提升人类图像生成性能的有效性。

</details>


### [93] [Prompt learning with bounding box constraints for medical image segmentation](https://arxiv.org/abs/2507.02743)
**中文标题：基于边界框约束的提示学习用于医学图像分割**

*Mélanie Gaillochet,Mehrdad Noori,Sahar Dastani,Christian Desrosiers,Hervé Lombaert*

主要分类: cs.CV

摘要简述: 本文提出了一种结合基础模型表示能力和弱监督分割标注效率的新框架，通过仅使用边界框标注自动生成提示，优化方案整合了边界框约束和伪标签，实验表明在有限数据下优于现有全监督和弱监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割中像素级标注成本高昂，弱监督方法基于更易获取的边界框标注提供了一种实用替代方案。现有提示学习方法依赖全标注分割掩码，本文旨在结合基础模型和弱监督分割的优势，减少用户干预。

研究方法: 提出了一种新框架，利用边界框标注自动生成基础模型的提示，优化方案整合了边界框约束和基础模型生成的伪标签。

研究结果: 在多模态数据集上的实验显示，该方法在有限数据设置下平均Dice分数达到84.90%，优于现有全监督和弱监督方法。

研究结论: 本文方法成功结合了基础模型的表示能力和弱监督分割的标注效率，显著提升了医学图像分割的性能，减少了标注成本。

中文摘要: 在医学领域，像素级标注的获取既耗时又昂贵。为减轻这一负担，基于边界框标注的弱监督方法提供了一种更实用的替代方案。视觉基础模型在提供点或边界框等提示时表现出卓越的分割性能。提示学习通过将这些模型适配到下游任务并自动化分割，减少了用户干预。然而，现有提示学习方法依赖全标注分割掩码。本文提出了一种新框架，结合了基础模型的表示能力和弱监督分割的标注效率。具体而言，我们的方法仅使用边界框标注自动生成基础模型的提示。提出的优化方案整合了边界框标注的多种约束与基础模型生成的伪标签。在多模态数据集上的广泛实验表明，我们的弱监督方法在有限数据设置下平均Dice分数达到84.90%，优于现有全监督和弱监督方法。代码可在https://github.com/Minimel/box-prompt-learning-VFM.git获取。

</details>


### [94] [DexVLG: Dexterous Vision-Language-Grasp Model at Scale](https://arxiv.org/abs/2507.02747)
**中文标题：DexVLG：大规模灵巧视觉-语言-抓取模型**

*Jiawei He,Danshi Li,Xinqiang Yu,Zekun Qi,Wenyao Zhang,Jiayi Chen,Zhaoxiang Zhang,Zhizheng Zhang,Li Yi,He Wang*

主要分类: cs.CV

摘要简述: 论文提出DexVLG模型，通过大规模数据集DexGraspNet 3.0训练，实现了基于语言指令的单视角RGBD输入的灵巧抓取姿态预测，并在仿真和真实场景中展示了优异的零样本泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉-语言-动作（VLA）系统主要针对简单夹爪末端执行器，缺乏针对类人灵巧手的功能性抓取研究。本文旨在填补这一空白，通过大规模数据集和模型训练，实现语言指令对齐的灵巧抓取姿态预测。

研究方法: 生成了包含1.7亿个灵巧抓取姿态的大规模数据集DexGraspNet 3.0，覆盖17.4万个物体的语义部分，并配以详细的部件级描述。基于此数据集，训练了一个视觉语言模型（VLM）和基于流匹配的姿态预测头，用于生成与语言指令对齐的桌面物体抓取姿态。

研究结果: DexVLG在仿真和真实场景中表现出色，零样本执行成功率达76%以上，部件抓取准确率领先，并在真实物体上成功实现了部件对齐的抓取。

研究结论: DexVLG通过大规模数据集和模型训练，成功实现了语言指令对齐的灵巧抓取姿态预测，展示了强大的零样本泛化能力，为灵巧手的功能性抓取研究提供了新方向。

中文摘要: 随着大型模型的兴起，视觉-语言-动作（VLA）系统正使机器人能够处理日益复杂的任务。然而，由于数据收集的困难，现有研究主要集中在控制简单的夹爪末端执行器上，针对类人灵巧手的功能性抓取研究较少。本文提出了DexVLG，一种基于单视角RGBD输入、与语言指令对齐的灵巧抓取姿态预测大型视觉-语言-抓取模型。为实现这一目标，我们在仿真中生成了一个包含1.7亿个灵巧抓取姿态的数据集，覆盖17.4万个物体的语义部分，并配以详细的部件级描述。这一名为DexGraspNet 3.0的大规模数据集用于训练一个视觉语言模型和基于流匹配的姿态预测头，能够生成与语言指令对齐的桌面物体抓取姿态。为评估DexVLG的性能，我们在基于物理的仿真中创建了基准测试，并进行了真实世界实验。大量测试表明，DexVLG具有强大的零样本泛化能力——在仿真中零样本执行成功率超过76%，部件抓取准确率领先，并在真实场景中成功实现了部件对齐的抓取。

</details>


### [95] [Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics](https://arxiv.org/abs/2507.02748)
**中文标题：全局上下文线性注意力：一种用于视觉与物理的多极注意力机制**

*Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的多极注意力机制（MANO），通过距离多尺度计算注意力，实现了线性复杂度，并在图像分类和物理模拟任务中表现出色，显著降低了计算资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 传统的Transformer模型在处理高分辨率输入时，由于二次复杂度导致计算和内存消耗巨大，限制了其实际应用。本文受n体数值模拟技术的启发，旨在设计一种高效且保持全局感受野的注意力机制。

研究方法: 本文提出了多极注意力神经算子（MANO），将注意力建模为网格点之间的交互问题，采用距离多尺度方法计算注意力，实现了线性时间和内存复杂度。

研究结果: 实验结果表明，MANO在图像分类和Darcy流模拟任务中性能与ViT和Swin Transformer相当，同时显著降低了运行时间和峰值内存使用量。

研究结论: MANO通过多极注意力机制有效解决了传统Transformer的高复杂度问题，为高分辨率输入处理提供了一种高效且性能优越的解决方案。

中文摘要: Transformer已成为从图像分类到物理模拟等多种任务的实际标准。尽管其性能卓越，但标准Transformer在处理高分辨率输入时，由于时间和内存的二次复杂度而显得不切实际。为此，已有多种改进方案提出，其中最成功的依赖于分块、降采样或粗化技术，但往往以丢失最精细细节为代价。本文采用了一种不同的方法，受n体数值模拟技术的启发，将注意力建模为网格点之间的交互问题。我们提出了多极注意力神经算子（MANO），以距离多尺度方式计算注意力。MANO在每个注意力头中保持全局感受野，并实现了与网格点数成线性的时间和内存复杂度。在图像分类和Darcy流模拟任务中的实验结果表明，MANO与ViT和Swin Transformer等先进模型性能相当，同时将运行时间和峰值内存使用量降低了数个数量级。我们的代码已在https://github.com/AlexColagrande/MANO开源，以确保可复现性。

</details>


### [96] [Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2507.02751)
**中文标题：部分弱监督定向目标检测**

*Mingxin Liu,Peiyuan Zhang,Yuan Liu,Wei Zhang,Yue Zhou,Ning Liao,Ziyang Gong,Junwei Luo,Zhirui Wang,Yi Yu,Xue Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于部分弱标注（水平框或单点）的Partial Weakly-Supervised Oriented Object Detection (PWOOD)框架，显著降低了标注成本，同时性能优于传统弱监督算法。


<details>
  <summary>详细信息</summary>
研究动机: 当前定向目标检测（OOD）的标注成本高昂，现有方法（完全监督、半监督和弱监督）在标注速度或成本上存在不足。本文旨在通过部分弱标注解决这一问题。

研究方法: 提出PWOOD框架，结合部分弱标注（水平框或单点）；设计OS-Student模型学习方向和尺度信息；采用CPF策略降低模型对静态过滤阈值的敏感性。

研究结果: 在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的实验表明，PWOOD性能与传统半监督算法相当甚至更优。

研究结论: PWOOD框架显著降低了标注成本，同时保持了高性能，为定向目标检测提供了一种经济高效的解决方案。

中文摘要: 定向目标检测（OOD）在各领域的应用需求不断增长，但高昂的数据集标注成本仍是主要问题。当前主流OOD算法可分为三类：（1）使用完整定向边界框（OBB）标注的完全监督方法；（2）使用部分OBB标注的半监督方法；（3）使用水平框或点等弱标注的弱监督方法。然而，这些方法在标注速度或成本上增加了模型负担。为解决这一问题，我们提出：（1）首个基于部分弱标注（水平框或单点）的Partial Weakly-Supervised Oriented Object Detection (PWOOD)框架，能高效利用大量未标注数据，显著优于传统弱监督算法，同时成本更低；（2）OS-Student模型，仅需少量方向或尺度无关的弱标注即可学习方向和尺度信息；（3）CPF策略，降低模型对静态过滤阈值的敏感性。在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的实验表明，PWOOD性能与传统半监督算法相当甚至更优。

</details>


### [97] [From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images](https://arxiv.org/abs/2507.02781)
**中文标题：从像素到损害严重程度：利用社交媒体图像的语义分割评估地震影响**

*Danrong Zhang,Huili Huang,N. Simrill Smith,Nimisha Roy,J. David Frost*

主要分类: cs.CV

摘要简述: 本研究提出了一种基于语义分割的方法，通过分析社交媒体图像来评估地震后的损害严重程度，取代传统的主观分类方法，提供更客观和全面的损害分析。


<details>
  <summary>详细信息</summary>
研究动机: 传统的地震损害评估方法依赖主观分类，无法准确反映图像中不同区域的损害程度。本研究旨在通过语义分割技术，提供更客观和全面的损害评估，以支持更有效的灾害响应。

研究方法: 研究构建了一个包含未损坏结构、损坏结构和废墟的分割数据集，并利用SegFormer模型进行微调，生成损害严重程度的分割结果。同时，引入了一种新的损害评分系统，结合深度估计量化图像中不同区域的损害程度。

研究结果: 该方法能够更客观地量化社交媒体图像中的损害严重程度，为灾害侦察团队提供精确的损害评估，支持更有针对性的响应行动。

研究结论: 通过语义分割和新的评分系统，本研究显著提升了地震损害评估的客观性和全面性，为灾害响应提供了更有效的技术支持。

中文摘要: 地震发生后，社交媒体图像成为灾害侦察的重要资源，能够迅速反映损害程度。传统的损害评估方法通常依赖分类技术，这种方法主观性强，且无法准确反映图像中不同区域的损害程度。针对这些局限性，本研究提出了一种新方法，将损害严重程度评估视为语义分割问题，旨在更客观地分析地震影响区域的损害情况。方法包括构建一个分割损害严重程度数据集，将损害分为三类：未损坏结构、损坏结构和废墟。利用该数据集，研究对SegFormer模型进行微调，生成地震后社交媒体图像的损害严重程度分割结果。此外，研究还引入了一种新的损害严重程度评分系统，通过结合深度估计，量化图像中不同区域的损害程度。该方法能够以更客观和全面的方式量化社交媒体图像中的损害严重程度。通过提供更细致的损害分析，本研究增强了为灾害侦察团队提供精确指导的能力，从而在地震后实现更有效和有针对性的响应行动。

</details>


### [98] [RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation](https://arxiv.org/abs/2507.02792)
**中文标题：RichControl：无需训练的结构与外观丰富的空间控制文本到图像生成方法**

*Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的文本到图像生成方法RichControl，通过解耦特征注入时间与去噪过程，结合结构丰富的注入模块和外观丰富的提示策略，显著提升了生成图像的结构和外观质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本到图像扩散模型在结合条件图像（如深度图或姿态图）时，常因特征注入的同步性问题导致结构错位、条件泄漏和视觉伪影。本文旨在解决这一核心限制，提出更灵活的特征注入框架。

研究方法: 提出了一种解耦特征注入时间与去噪过程的框架，核心是结构丰富的注入模块，能够适应去噪过程中对齐与结构保留的动态平衡。此外，引入外观丰富的提示和重启细化策略，进一步提升外观控制和视觉质量。

研究结果: 实验表明，该方法在多样化的零样本条件场景中实现了最先进的性能，生成的图像在结构和外观上均表现出色。

研究结论: RichControl通过灵活的特征注入和外观优化策略，实现了无需训练的高质量文本到图像生成，为复杂条件控制提供了新思路。

中文摘要: 文本到图像（T2I）扩散模型在从文本提示生成高质量图像方面取得了显著成功。近期研究尝试通过结合条件图像（如深度图或姿态图）实现细粒度空间控制。其中，特征注入方法作为一种无需训练的替代方案，逐渐受到关注。然而，这些方法常因条件图像与自然RGB分布差异较大而出现结构错位、条件泄漏和视觉伪影。通过重新审视现有方法，我们发现其核心限制在于同步注入条件特征未能权衡去噪过程中的域对齐与结构保留。基于此观察，我们提出了一种灵活的特征注入框架，将注入时间步与去噪过程解耦。其核心是一个结构丰富的注入模块，使模型能够更好地适应去噪过程中对齐与结构保留的动态平衡，从而生成更忠实于结构的图像。此外，我们引入了外观丰富的提示和重启细化策略，进一步提升了外观控制和视觉质量。这些设计共同实现了无需训练且结构与外观丰富的生成。大量实验表明，我们的方法在多样化的零样本条件场景中达到了最先进的性能。

</details>


### [99] [No time to train! Training-Free Reference-Based Instance Segmentation](https://arxiv.org/abs/2507.02798)
**中文标题：无需训练！基于参考图像的实例分割方法**

*Miguel Espinosa,Chenhongyi Yang,Linus Ericsson,Steven McDonagh,Elliot J. Crowley*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的参考图像实例分割方法，利用基础模型的语义先验知识，通过多阶段流程自动生成实例级分割掩码，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像分割模型依赖大量标注数据，而Segment Anything Model (SAM)仍需手动提示或复杂规则。本文旨在通过参考图像减少这一负担，利用基础模型的语义先验实现自动分割。

研究方法: 方法分为三个阶段：(1) 构建记忆库；(2) 表示聚合；(3) 语义感知特征匹配，全程无需训练。

研究结果: 实验表明，该方法在COCO FSOD (36.8% nAP)、PASCAL VOC Few-Shot (71.2% nAP50)和跨域FSOD基准测试(22.4% nAP)上均达到最优性能。

研究结论: 通过利用语义先验和训练多阶段流程，本文实现了高效且无需训练的实例分割，显著优于现有方法。

中文摘要: 图像分割模型的性能历来受限于大规模标注数据的高成本。Segment Anything Model (SAM)通过可提示、语义无关的分割范式缓解了这一问题，但仍需手动视觉提示或复杂的领域相关提示生成规则来处理新图像。为减轻这一负担，本文研究了在仅提供少量参考图像时的对象分割任务。关键思路是利用基础模型学习的强语义先验，识别参考图像与目标图像之间的对应区域。研究发现，这些对应关系能够自动生成下游任务所需的实例级分割掩码，并通过多阶段、无需训练的方法实现：(1) 记忆库构建；(2) 表示聚合；(3) 语义感知特征匹配。实验表明，该方法在分割指标上显著提升，在COCO FSOD (36.8% nAP)、PASCAL VOC Few-Shot (71.2% nAP50)上达到最优性能，并在跨域FSOD基准测试(22.4% nAP)上优于现有无需训练方法。

</details>


### [100] [HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars](https://arxiv.org/abs/2507.02803)
**中文标题：HyperGaussians：基于高维高斯泼溅的高保真可动画化人脸虚拟形象**

*Gent Serifi,Marcel C. Bühler*

主要分类: cs.CV

摘要简述: 本文提出HyperGaussians，一种基于高维多变量高斯分布的新型3D高斯泼溅技术，用于高质量可动画化人脸虚拟形象，显著提升了高频细节和复杂变形的表现力。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于单目视频的可动画化人脸虚拟形象在非线性变形、复杂光照和精细细节上仍存在不足，而传统的3D高斯泼溅技术（3DGS）在静态人脸表现优异，但在动态场景中表现有限。本文旨在通过扩展高斯表示维度，提升其表达能力。

研究方法: 提出HyperGaussians，将3D高斯扩展为高维多变量高斯，通过可学习的局部嵌入增强表达能力。为解决高维协方差矩阵计算效率问题，引入‘逆协方差技巧’进行重参数化，显著提升计算效率。

研究结果: 在4个数据集上的19名受试者实验中，HyperGaussians在数值和视觉上均优于传统3DGS，尤其在眼镜框、牙齿、复杂面部动作和高光反射等高频细节上表现突出。

研究结论: HyperGaussians通过高维高斯表示和高效计算技巧，显著提升了可动画化人脸虚拟形象的质量，为增强现实和虚拟现实应用提供了更优解决方案。

中文摘要: 我们提出HyperGaussians，一种新型的3D高斯泼溅扩展技术，用于高质量可动画化人脸虚拟形象。从视频中创建此类精细人脸虚拟形象是一个具有挑战性的问题，在增强现实和虚拟现实中有广泛应用。尽管静态人脸已取得巨大成功，但基于单目视频的可动画化虚拟形象仍处于‘恐怖谷’状态。传统3D高斯泼溅（3DGS）通过一组3D高斯基元表示人脸，在静态人脸渲染中表现优异，但在非线性变形、复杂光照和精细细节上仍有不足。大多数相关研究专注于通过表情编码预测更好的高斯参数，而我们重新思考了3D高斯表示本身及其表达能力。我们的研究提出了一种将3D高斯扩展为高维多变量高斯的新方法，称为‘HyperGaussians’。高维度通过可学习的局部嵌入增强了表达能力。然而，泼溅HyperGaussians计算成本高，因为它需要求逆高维协方差矩阵。我们通过‘逆协方差技巧’重新参数化协方差矩阵，显著提升了效率，使HyperGaussians能够无缝集成到现有模型中。为验证其效果，我们将HyperGaussians集成到当前最快的单目人脸虚拟形象模型FlashAvatar中。在4个数据集的19名受试者评估中，HyperGaussians在数值和视觉上均优于3DGS，尤其在眼镜框、牙齿、复杂面部动作和高光反射等高频细节上表现突出。

</details>


### [101] [LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion](https://arxiv.org/abs/2507.02813)
**中文标题：LangScene-X：基于TriMap视频扩散的可泛化3D语言嵌入场景重建**

*Fangfu Liu,Hao Li,Jiawei Chi,Hanyang Wang,Minghui Yang,Fudong Wang,Yueqi Duan*

主要分类: cs.CV

摘要简述: LangScene-X是一种新型生成框架，通过TriMap视频扩散模型和语言量化压缩器（LQC），从稀疏视图重建可泛化的3D语言嵌入场景，解决了传统方法依赖密集视图的问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法依赖密集视图进行3D重建和语言嵌入，导致在稀疏视图下出现渲染伪影和语义合成不准确的问题。LangScene-X旨在通过生成一致的多模态信息，从稀疏输入中实现高质量的3D场景重建和开放词汇查询。

研究方法: 1. 训练TriMap视频扩散模型，从稀疏输入生成RGB、法线和语义分割图；2. 提出语言量化压缩器（LQC），在大规模图像数据集上训练，实现跨场景语言嵌入；3. 通过语言表面场对齐语言信息到3D场景表面，支持开放词汇查询。

研究结果: 实验表明，LangScene-X在真实数据上优于现有方法，重建质量和泛化能力显著提升。

研究结论: LangScene-X通过生成一致的多模态信息和高效的语言嵌入，实现了从稀疏视图重建高质量3D语言场景的目标，为开放词汇查询提供了新思路。

中文摘要: 从2D图像中恢复具有开放词汇场景理解的3D结构是一项基础但艰巨的任务。最近的研究通过嵌入语言信息进行逐场景优化实现了这一目标，但这些方法严重依赖校准的密集视图重建范式，导致在视图有限时出现严重的渲染伪影和语义合成不准确。本文提出了一种新型生成框架LangScene-X，通过生成一致的多模态信息，从稀疏视图中重建可泛化的3D语言嵌入场景。具体而言，我们首先训练了一个TriMap视频扩散模型，通过渐进知识集成从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）。此外，我们提出了一种在大规模图像数据集上训练的语言量化压缩器（LQC），高效编码语言嵌入，实现跨场景泛化而无需逐场景重新训练。最后，我们通过将语言信息对齐到3D场景表面，重建语言表面场，支持开放词汇查询。在真实数据上的大量实验表明，LangScene-X在质量和泛化能力上优于现有方法。项目页面：https://liuff19.github.io/LangScene-X。

</details>


### [102] [Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach](https://arxiv.org/abs/2507.02826)
**中文标题：基于置信度驱动梯度调制的多模态人类活动识别：一种动态对比双路径学习方法**

*Panpan Ji,Junni Song,Hang Xiao,Hanyu Liu,Chao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架，用于解决多模态人类活动识别中的跨模态特征对齐和模态贡献不平衡问题。通过双路径特征提取、多阶段对比学习和置信度驱动的梯度调制策略，显著提升了识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态人类活动识别（HAR）系统面临跨模态特征对齐困难和模态贡献不平衡等挑战，亟需一种能够动态调整模态学习强度的解决方案。

研究方法: 1. 采用ResNet和DenseNet双路径架构处理多模态传感器数据；2. 引入多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；3. 提出置信度驱动的梯度调制策略，动态调整模态分支的学习强度；4. 采用基于动量的梯度累积策略提升训练稳定性。

研究结果: 在四个公开基准数据集上的实验表明，DCDP-HAR框架显著提升了多模态HAR的性能，并通过消融研究验证了各模块的有效性。

研究结论: DCDP-HAR框架通过动态对比学习和梯度调制策略，有效解决了多模态HAR中的关键问题，为智能系统的环境感知提供了新思路。

中文摘要: 基于传感器的人类活动识别（HAR）是智能系统感知和交互环境的核心技术。然而，多模态HAR系统仍面临跨模态特征对齐困难和模态贡献不平衡等关键挑战。为解决这些问题，我们提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架。该框架包含三个关键组件：首先，采用ResNet和DenseNet双路径架构协同处理多模态传感器数据；其次，引入多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；第三，提出置信度驱动的梯度调制策略，动态监控并调整各模态分支的反向传播学习强度，有效缓解模态竞争。此外，采用基于动量的梯度累积策略以增强训练稳定性。我们通过消融研究验证了各组件的有效性，并在四个公开基准数据集上进行了广泛的对比实验。

</details>


### [103] [USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network](https://arxiv.org/abs/2507.02827)
**中文标题：USAD：一种无监督数据增强的时空注意力扩散网络**

*Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为USAD的无监督数据增强时空注意力扩散网络，用于解决人类活动识别（HAR）中的标签数据稀缺、高级特征提取不足及轻量设备性能不佳等问题。通过无监督数据增强、多分支时空交互网络和自适应多损失函数融合策略，显著提升了识别精度。


<details>
  <summary>详细信息</summary>
研究动机: 人类活动识别（HAR）在健康监测、安全防护和运动分析中有广泛应用，但仍面临标签数据稀缺、高级特征提取不足及轻量设备性能不佳等挑战。本文旨在通过综合优化方法解决这些问题。

研究方法: 1. 使用无监督统计引导扩散模型进行数据增强，缓解标签数据稀缺和类别不平衡问题；2. 设计多分支时空交互网络，通过并行残差分支捕获多尺度特征，并引入时空注意力机制；3. 提出自适应多损失函数融合策略，动态调整损失权重。

研究结果: 在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上的实验表明，USAD的识别精度分别达到98.84%、93.81%和80.92%，显著优于现有方法。嵌入式设备上的部署验证了其高效性和可行性。

研究结论: USAD通过无监督数据增强和时空注意力机制，显著提升了HAR的识别性能，并在轻量设备上表现出色，为实际应用提供了有效解决方案。

中文摘要: 人类活动识别（HAR）的主要目标是从传感器数据中推断正在进行的人类行为，这一任务在健康监测、安全防护和运动分析中有广泛应用。尽管研究众多，HAR仍面临关键挑战，包括稀有活动的标签样本稀缺、高级特征提取不足以及轻量设备上的模型性能不佳。为解决这些问题，本文提出了一种以多注意力交互机制为核心的综合优化方法。首先，采用无监督统计引导扩散模型进行数据增强，缓解标签数据稀缺和严重类别不平衡问题；其次，设计了一种多分支时空交互网络，通过并行残差分支（3*3、5*5和7*7卷积核）捕获序列数据的多尺度特征，同时引入时间注意力机制识别关键时间点，空间注意力增强传感器间交互；进一步引入跨分支特征融合单元以提升整体特征表示能力；最后，整合自适应多损失函数融合策略，动态调整损失权重并优化整体模型。在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上的实验结果表明，所提出的无监督数据增强时空注意力扩散网络（USAD）的识别精度分别达到98.84%、93.81%和80.92%，显著优于现有方法。此外，在嵌入式设备上的实际部署验证了该方法的效率和可行性。

</details>


### [104] [AnyI2V: Animating Any Conditional Image with Motion Control](https://arxiv.org/abs/2507.02857)
**中文标题：AnyI2V：通过运动控制为任意条件图像生成动画**

*Ziye Li,Hao Luo,Xincheng Shuai,Henghui Ding*

主要分类: cs.CV

摘要简述: AnyI2V是一种无需训练即可根据用户定义的运动轨迹为任意条件图像生成动画的框架，支持多种模态输入，并实现了灵活的视频生成和编辑。


<details>
  <summary>详细信息</summary>
研究动机: 现有文本到视频（T2V）和图像到视频（I2V）方法在动态运动信号和空间约束的整合上存在不足，T2V缺乏对生成内容空间布局的精确控制，而I2V则受限于对真实图像的依赖。AnyI2V旨在解决这些问题，提供更灵活的视频生成方式。

研究方法: AnyI2V提出了一种无需训练的框架，通过用户定义的运动轨迹为任意条件图像生成动画，支持包括网格和点云在内的多种模态输入，并允许通过LoRA和文本提示进行风格转换和编辑。

研究结果: 实验表明，AnyI2V在空间和运动控制的视频生成中表现出色，支持更广泛的输入模态，并实现了高效的视频编辑和风格转换。

研究结论: AnyI2V为空间和运动控制的视频生成提供了新的视角，其无需训练的特点和灵活的输入支持使其成为视频生成领域的重要进展。

中文摘要: 近年来，视频生成领域，尤其是扩散模型的发展，推动了文本到视频（T2V）和图像到视频（I2V）合成的显著进步。然而，如何有效整合动态运动信号和灵活的空间约束仍面临挑战。现有的T2V方法通常依赖文本提示，这导致对生成内容空间布局的精确控制不足；而I2V方法则受限于对真实图像的依赖，限制了合成内容的可编辑性。尽管一些方法通过引入ControlNet实现了基于图像的条件控制，但它们往往缺乏明确的运动控制，且需要计算密集的训练。为解决这些问题，我们提出了AnyI2V，一种无需训练的框架，能够根据用户定义的运动轨迹为任意条件图像生成动画。AnyI2V支持更广泛的模态作为条件图像，包括ControlNet不支持的网格和点云等数据类型，从而实现更灵活和多样化的视频生成。此外，它还支持混合条件输入，并通过LoRA和文本提示实现风格转换和编辑。大量实验表明，AnyI2V在空间和运动控制的视频生成中表现出色，为该领域提供了新的视角。代码可在https://henghuiding.com/AnyI2V/获取。

</details>


### [105] [Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation](https://arxiv.org/abs/2507.02859)
**中文标题：基于自举的多模态大语言模型中接地链式思维的数据高效模型适应**

*Jiaer Xia,Bingkui Tong,Yuhang Zang,Rui Shao,Kaiyang Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种基于引导链式思维（GCoT）的方法，通过注入边界框信息提升多模态大语言模型在数据有限场景下的任务适应能力，显著优于微调和蒸馏方法。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在通用图像理解任务中表现优异，但在专业化视觉任务（如图表理解）中因预训练与下游任务数据不匹配而难以适应。传统方法依赖大规模数据微调，而本文发现链式思维（CoT）数据可提升模型适应能力，但预训练模型生成的CoT数据存在事实错误，需改进。

研究方法: 提出Grounded Chain-of-Thought（GCoT），通过注入边界框等 grounding 信息，使CoT推理步骤更忠实于输入图像。采用自举方法生成高质量GCoT数据，并在五种专业化视觉任务（图表、表格、收据、报告等）中验证。

研究结果: 实验表明，在数据有限的情况下，GCoT方法显著优于传统微调和蒸馏方法，提升了模型在专业化视觉任务中的表现。

研究结论: GCoT通过结合 grounding 信息改进了CoT数据的可靠性，为数据高效的多模态模型适应提供了新思路。

中文摘要: 多模态大语言模型（MLLMs）在自然语言解释图像方面表现出色，但在未使用大规模数据集重新训练的情况下，难以适应专业化视觉任务（如图表理解）。这一问题源于预训练与下游任务数据的不匹配：预训练数据主要关注场景和物体，而专业化图像（如图表和表格）信息有限。本文发现，使用链式思维（CoT）推理数据训练MLLM可促进模型在数据有限场景下的适应能力，但预训练模型生成的CoT数据存在推理步骤中的事实错误。为此，我们提出Grounded Chain-of-Thought（GCoT），一种基于自举的方法，通过注入边界框等 grounding 信息，使推理步骤更忠实于输入图像。在五种专业化视觉任务（涵盖图表、表格、收据和报告等）上的实验表明，GCoT在数据有限场景下显著优于微调和蒸馏方法。

</details>


### [106] [Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching](https://arxiv.org/abs/2507.02860)
**中文标题：少即是多：基于运行时自适应缓存的免训练视频扩散加速方法**

*Xin Zhou,Dingkang Liang,Kaijin Chen,Tianrui Feng,Xiwu Chen,Hongkai Lin,Yikang Ding,Feiyang Tan,Hengshuang Zhao,Xiang Bai*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的加速框架EasyCache，通过运行时自适应缓存机制动态复用计算过的变换向量，显著提升了视频扩散模型的推理速度，同时保持高质量生成效果。


<details>
  <summary>详细信息</summary>
研究动机: 视频生成模型因迭代去噪过程导致推理速度慢、计算成本高，限制了其广泛应用。为解决这一问题，本文旨在提出一种无需训练的高效加速方案。

研究方法: EasyCache采用轻量级的运行时自适应缓存机制，动态复用先前计算的变换向量，避免冗余计算，且无需离线分析或参数调优。

研究结果: 实验表明，EasyCache在多个大规模视频生成模型（如OpenSora、Wan2.1和HunyuanVideo）上实现了2.1-3.3倍的推理加速，同时PSNR提升高达36%，显著优于现有方法。

研究结论: EasyCache是一种高效且易于使用的视频生成加速方案，适用于研究和实际应用，代码已开源。

中文摘要: 视频生成模型表现出卓越的性能，但其广泛应用仍受限于推理速度慢和计算成本高的问题，这主要源于迭代去噪过程。解决这一瓶颈对于普及先进的视频合成技术至关重要。本文提出EasyCache，一种免训练的视频扩散模型加速框架。EasyCache引入了一种轻量级的运行时自适应缓存机制，动态复用先前计算的变换向量，避免推理中的冗余计算。与现有方法不同，EasyCache无需离线分析、预计算或大量参数调优。我们在多个大规模视频生成模型（如OpenSora、Wan2.1和HunyuanVideo）上进行了全面研究。实验结果表明，我们的方法实现了领先的加速性能，推理时间较原始基线缩短了2.1-3.3倍，同时保持了高视觉保真度，PSNR较现有最佳方法提升了高达36%。这一改进使EasyCache成为研究和实际应用中高效且易于使用的高质量视频生成解决方案。代码已发布于https://github.com/H-EmbodVis/EasyCache。

</details>


### [107] [LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans](https://arxiv.org/abs/2507.02861)
**中文标题：LiteReality：基于RGB-D扫描的图形就绪3D场景重建**

*Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby*

主要分类: cs.CV

摘要简述: LiteReality提出了一种新方法，将RGB-D扫描的室内环境转换为紧凑、逼真且可交互的3D虚拟副本，支持图形管线的关键功能，如物体独立性、高质量材质和物理交互。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D场景重建技术难以同时满足视觉逼真性和图形管线兼容性需求，LiteReality旨在解决这一问题，为AR/VR、游戏和数字孪生等应用提供高效解决方案。

研究方法: LiteReality通过场景理解生成结构化场景图，从资产库中检索视觉相似的3D模型，利用材质绘制模块恢复高质量材质，并将场景集成到仿真引擎中以支持物理交互。

研究结果: LiteReality在Scan2CAD基准测试中实现了最先进的相似性性能，并能处理严重不对齐、遮挡和光照不足的情况，生成紧凑且兼容标准图形管线的场景。

研究结论: LiteReality提供了一种高效且逼真的3D场景重建方法，适用于多种图形应用，同时展示了其模块在对象检索和材质绘制方面的卓越性能。

中文摘要: 我们提出了LiteReality，这是一种新颖的流程，可将室内环境的RGB-D扫描转换为紧凑、逼真且可交互的3D虚拟副本。LiteReality不仅重建了视觉上接近现实的场景，还支持图形管线所需的关键功能，如物体独立性、关节运动、高质量的物理渲染材质以及基于物理的交互。其核心在于，LiteReality首先进行场景理解，并通过结构化场景图将结果解析为连贯的3D布局和物体。然后，通过从精选的资产数据库中检索视觉最相似的3D艺术家制作模型来重建场景。接着，材质绘制模块通过恢复高质量的空间变化材质来增强真实感。最后，重建的场景被集成到具有基本物理属性的仿真引擎中，以实现交互行为。生成的场景紧凑、可编辑，并且完全兼容标准图形管线，适用于AR/VR、游戏、机器人和数字孪生等应用。此外，LiteReality引入了一种无需训练的对象检索模块，在Scan2CAD基准测试中实现了最先进的相似性性能，以及一个鲁棒的材质绘制模块，能够将任何风格的图像外观转移到3D资产上，即使在严重不对齐、遮挡和光照不足的情况下也能实现。我们在真实扫描和公共数据集上验证了LiteReality的有效性。项目页面：https://litereality.github.io；视频：https://www.youtube.com/watch?v=ecK9m3LXg2c

</details>


### [108] [RefTok: Reference-Based Tokenization for Video Generation](https://arxiv.org/abs/2507.02862)
**中文标题：RefTok：基于参考的视频生成标记化方法**

*Xiang Fan,Xiaohang Sun,Kushan Thakkar,Zhu Liu,Vimal Bhat,Ranjay Krishna,Xiang Hao*

主要分类: cs.CV

摘要简述: RefTok是一种基于参考的标记化方法，用于视频生成，通过捕获复杂的时间动态和上下文信息，显著提升了视频模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频模型在处理时间冗余时，通常独立处理每一帧，无法有效捕捉视频中的时间依赖性和冗余性。RefTok旨在解决这一问题。

研究方法: RefTok通过基于未量化参考帧的条件编码和解码帧集，保留了运动的连续性和物体的外观细节。

研究结果: 在四个视频数据集上，RefTok显著优于当前最先进的标记化方法（Cosmos和MAGVIT），平均提升36.7%的评估指标（PSNR、SSIM、LPIPS）。

研究结论: RefTok不仅提升了视频生成模型的性能，还在相同或更高压缩比下优于更大规模的模型。

中文摘要: 有效处理时间冗余仍然是学习视频模型的关键挑战。主流方法通常独立处理每一帧，无法有效捕捉视频中的时间依赖性和冗余性。为解决这一问题，我们提出了RefTok，一种新颖的基于参考的标记化方法，能够捕获复杂的时间动态和上下文信息。我们的方法基于未量化的参考帧对帧集进行编码和解码。解码时，RefTok保留了运动的连续性和物体的外观细节。例如，RefTok在头部运动时保留了面部细节，正确重建了文本，保留了小图案，并保持了手写内容的可读性。在四个视频数据集（K600、UCF-101、BAIR Robot Pushing和DAVIS）上，RefTok显著优于当前最先进的标记化方法（Cosmos和MAGVIT），并在相同或更高压缩比下平均提升了36.7%的评估指标（PSNR、SSIM、LPIPS）。当使用RefTok的潜在表示在BAIR Robot Pushing任务上训练视频生成模型时，生成的视频不仅在所有生成指标上优于MAGVIT-B，还优于参数多4倍的MAGVIT-L，平均提升了27.9%。

</details>


### [109] [Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory](https://arxiv.org/abs/2507.02863)
**中文标题：Point3R：基于显式空间指针内存的流式3D重建**

*Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu*

主要分类: cs.CV

摘要简述: Point3R提出了一种在线框架，通过显式空间指针内存实现密集流式3D重建，解决了传统隐式内存容量有限和信息丢失的问题，并在多种任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D重建方法依赖隐式内存，存在容量限制和早期帧信息丢失的问题。Point3R旨在通过显式空间指针内存，直接关联场景的3D结构，实现更高效的在线重建。

研究方法: Point3R维护一个显式空间指针内存，每个指针关联特定3D位置并聚合场景信息。通过3D分层位置嵌入和简单有效的融合机制，实现最新帧信息与全局坐标系的密集集成。

研究结果: Point3R在多种任务中表现优异，训练成本低，达到或超越现有技术水平。

研究结论: Point3R通过显式空间指针内存和高效融合机制，显著提升了在线3D重建的性能和效率，为实际应用提供了有力工具。

中文摘要: 从有序序列或无序图像集合中进行密集3D场景重建是将计算机视觉研究应用于实际场景的关键步骤。继DUSt3R将图像对密集统一到共享坐标系后，后续方法通过隐式内存实现多图像的密集3D重建。然而，这种隐式内存容量有限，且可能丢失早期帧信息。我们提出Point3R，一种面向密集流式3D重建的在线框架。具体而言，我们维护一个直接关联当前场景3D结构的显式空间指针内存。内存中的每个指针分配一个特定3D位置，并将全局坐标系中附近的场景信息聚合为动态空间特征。从最新帧提取的信息显式与此指针内存交互，实现当前观测到全局坐标系的密集集成。我们设计了3D分层位置嵌入以促进这种交互，并设计了一种简单高效的融合机制，确保指针内存的均匀性和高效性。我们的方法在多种任务中以低训练成本实现了竞争性或最先进的性能。代码见：https://github.com/YkiWu/Point3R。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [110] [STELLA: Self-Evolving LLM Agent for Biomedical Research](https://arxiv.org/abs/2507.02004)
**中文标题：STELLA：用于生物医学研究的自我进化大语言模型代理**

*Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong*

主要分类: cs.AI

摘要简述: STELLA是一种自我进化的AI代理，专为生物医学研究设计，通过动态更新工具库和推理策略库，实现性能的持续提升。


<details>
  <summary>详细信息</summary>
研究动机: 生物医学数据和工具的快速增长导致研究环境碎片化，超出人类专家的处理能力。现有AI代理依赖静态工具集，无法适应动态需求。STELLA旨在解决这一问题。

研究方法: STELLA采用多代理架构，包含两个核心机制：动态演进的模板库（用于推理策略）和工具海洋（通过工具创建代理自动发现和集成新工具）。

研究结果: STELLA在多个生物医学基准测试中表现优异，例如在Humanity's Last Exam: Biomedicine中得分为26%，在LAB-Bench: DBQA和LitQA中分别达到54%和63%，性能随经验提升。

研究结论: STELLA展示了AI代理系统动态学习和扩展能力的重大进步，有望加速生物医学发现。

中文摘要: 生物医学数据、工具和文献的快速增长导致研究环境碎片化，超出了人类专家的能力范围。尽管AI代理提供了解决方案，但它们通常依赖于静态、手动整理的工具集，限制了其适应和扩展能力。为此，我们推出了STELLA，一种自我进化的AI代理，旨在克服这些限制。STELLA采用多代理架构，通过两个核心机制自主提升能力：动态演进的模板库（用于推理策略）和工具海洋（通过工具创建代理自动发现和集成新工具）。这使得STELLA能够从经验中学习。我们证明，STELLA在一系列生物医学基准测试中达到了最先进的准确性，在Humanity's Last Exam: Biomedicine中得分为26%，在LAB-Bench: DBQA和LitQA中分别达到54%和63%，领先其他模型高达6个百分点。更重要的是，我们发现其性能随经验系统性提升；例如，在Humanity's Last Exam基准测试中，其准确性几乎翻倍。STELLA代表了AI代理系统的重大进步，能够动态扩展其专业知识，加速生物医学发现的步伐。

</details>


### [111] [HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection](https://arxiv.org/abs/2507.02073)
**中文标题：HCVR：一种基于相关性感知投票规则的混合特征选择方法**

*Nikita Bhedasgaonkar,Rushikesh K. Joshi*

主要分类: cs.AI

摘要简述: 本文提出了一种轻量级的基于规则的特征选择方法HCVR，结合参数间（P2P）和参数与目标（P2T）相关性，通过投票规则消除冗余特征并保留相关特征。实验表明其在SPAMBASE数据集上优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统特征选择方法在冗余特征消除和相关特征保留方面存在不足，HCVR旨在通过结合P2P和P2T相关性，提出一种更高效的特征选择方法。

研究方法: HCVR是一种混合方法，结合非迭代和迭代过滤技术，通过后向消除策略逐步剔除冗余特征。利用相关性阈值和多数投票规则决定特征的保留或剔除。

研究结果: 在SPAMBASE数据集上的实验表明，HCVR在分类器性能上优于传统非迭代（如CFS、mRMR和MI）和迭代（如RFE、SFS和遗传算法）方法。

研究结论: HCVR通过相关性感知的投票规则，有效提升了特征选择的性能，为高维数据处理提供了一种轻量级且高效的解决方案。

中文摘要: 本文提出HCVR（基于相关性感知投票规则的混合方法），一种轻量级的基于规则的特征选择方法，结合参数间（P2P）和参数与目标（P2T）相关性，以消除冗余特征并保留相关特征。该方法是非迭代和迭代过滤技术的混合，采用后向消除策略，每一步可能剔除多个特征。规则通过投票决定特征的保留或剔除，利用特征间及特征与目标间的相关性阈值。实验在SPAMBASE数据集上验证了HCVR的效果，结果显示其性能优于传统非迭代（如CFS、mRMR和MI）和迭代（如RFE、SFS和遗传算法）方法。有效性通过分类器在特征过滤后的性能评估。

</details>


### [112] [Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs](https://arxiv.org/abs/2507.02076)
**中文标题：预算内的推理：大型语言模型中自适应与可控测试时计算综述**

*Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates*

主要分类: cs.AI

摘要简述: 本文综述了大型语言模型（LLM）在推理过程中计算效率的提升策略，重点探讨了固定计算预算（L1-可控性）和动态调整计算（L2-自适应性）两类方法，并分析了其在性能和计算成本之间的权衡。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理时采用固定的计算资源，无法根据任务复杂度动态调整，导致简单问题过度计算而复杂问题计算不足。本文旨在探讨如何通过可控和自适应的测试时计算策略提升LLM的计算效率。

研究方法: 本文提出了一种双层分类法：L1-可控性方法在固定计算预算下运行，L2-自适应性方法根据输入难度或模型置信度动态调整计算资源。同时，对主流专有LLM在多样化数据集上进行了基准测试。

研究结果: 研究揭示了推理性能与计算成本之间的关键权衡，并展示了不同方法在实际应用中的表现。相比以往的高效推理综述，本文更注重方法的实际可控性、自适应性和可扩展性。

研究结论: 本文总结了提升LLM计算效率的现有方法，并指出未来研究方向，如混合思维模型，以进一步优化模型的稳健性和用户约束响应能力。

中文摘要: 大型语言模型（LLM）已迅速发展为能够解决广泛任务的通用智能体。然而，当前模型在推理时仍效率低下：无论任务复杂度如何，它们均采用固定的推理计算资源，常导致简单问题过度计算而复杂问题计算不足。本综述全面回顾了高效的测试时计算（TTC）策略，旨在提升LLM推理的计算效率。我们提出了一种双层分类法，区分了L1-可控性（在固定计算预算下运行的方法）和L2-自适应性（根据输入难度或模型置信度动态调整计算的方法）。我们对主流专有LLM在多样化数据集上进行了基准测试，揭示了推理性能与计算成本之间的关键权衡。与以往高效推理综述相比，本文更强调TTC方法的实际可控性、自适应性和可扩展性。最后，我们探讨了混合思维模型等新兴趋势，并指出了未来研究的关键挑战，以进一步提升LLM的计算效率、稳健性和用户约束响应能力。

</details>


### [113] [Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab](https://arxiv.org/abs/2507.02083)
**中文标题：通过系统生物学干实验测量语言模型的科学能力**

*Haonan Duan,Stephen Zhewen Lu,Caitlin Fiona Harrigan,Nishkrit Desai,Jiarui Lu,Michał Koziarski,Leonardo Cotta,Chris J. Maddison*

主要分类: cs.AI

摘要简述: 本文介绍了SciGym，首个评估大型语言模型（LLM）在开放科学发现任务中迭代实验设计与分析能力的基准测试，通过系统生物学的干实验克服湿实验的高成本问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估大型语言模型科学能力的研究未能测试实验设计与结果解释等核心科学能力，主要因湿实验在专业知识、时间和设备上的高成本。

研究方法: SciGym利用系统生物学标记语言（SBML）编码的生物系统模型进行干实验，生成模拟数据，评估六种前沿LLM在137个小系统和总计350个系统上的表现。

研究结果: 结果显示，能力更强的模型表现更优，但随着系统复杂性增加，所有模型性能显著下降，表明LLM在科学能力上仍有较大改进空间。

研究结论: SciGym为评估LLM的科学能力提供了高效且经济的测试平台，揭示了LLM在复杂科学任务中的局限性。

中文摘要: 实验设计和结果解释是科学研究的核心能力，尤其在生物学中，研究人员通过扰动复杂系统揭示其内在机制。当前评估大型语言模型（LLM）科学能力的研究因湿实验在专业知识、时间和设备上的高成本而未能测试这些能力。我们提出了SciGym，首个评估LLM在开放科学发现任务中迭代实验设计与分析能力的基准测试。SciGym通过系统生物学的干实验克服湿实验的高成本问题，这些模型以系统生物学标记语言（SBML）编码，能高效生成模拟数据，成为测试复杂系统实验的理想平台。我们评估了六种前沿LLM在137个小系统和总计350个系统上的表现。结果显示，能力更强的模型表现更优，但随着系统复杂性增加，所有模型性能显著下降，表明LLM在科学能力上仍有较大改进空间。

</details>


### [114] [What Neuroscience Can Teach AI About Learning in Continuously Changing Environments](https://arxiv.org/abs/2507.02103)
**中文标题：神经科学能为AI在持续变化环境中的学习提供什么启示**

*Daniel Durstewitz,Bruno Averbeck,Georgia Koppe*

主要分类: cs.AI

摘要简述: 本文探讨了现代AI模型（如大语言模型）与动物学习能力的差异，提出从神经科学中汲取灵感以改进AI在动态环境中的持续学习能力，并展望了NeuroAI领域的双向学习潜力。


<details>
  <summary>详细信息</summary>
研究动机: 现代AI模型通常基于静态数据训练，而动物能持续适应动态环境。本文旨在探索神经科学如何为AI在动态环境中的学习提供启示，并推动NeuroAI领域的双向发展。

研究方法: 通过整合AI中的持续学习和上下文学习文献，结合神经科学中关于行为任务动态规则、奖励概率和结果的研究，提出神经科学对AI发展的具体启示。

研究结果: 提出了神经科学如何帮助AI改进动态环境中的学习能力，并探讨了AI对神经科学的反哺作用，为NeuroAI领域的发展提供了方向。

研究结论: 神经科学与AI的结合有望推动双方在动态学习领域的进步，NeuroAI将成为未来研究的重要方向。

中文摘要: 现代AI模型（如大语言模型）通常基于大规模数据训练一次，可能针对特定任务微调后部署，参数固定。其训练成本高、速度慢且渐进，需要数十亿次重复。与之形成鲜明对比的是，动物能持续适应环境的不断变化。这对社会性物种尤为重要，因为行为策略和奖励结果在与同伴互动中可能频繁变化。其背后的计算过程通常表现为动物行为的快速转变和神经元群体活动的突然过渡。这种计算能力对现实世界中运行的AI系统（如机器人或自动驾驶汽车）或与人类在线交互的代理AI越来越重要。AI能从神经科学中学到什么？本文探讨了这一问题，整合了AI中持续学习和上下文学习的文献与神经科学中关于行为任务动态规则、奖励概率和结果的研究。我们将概述神经科学如何具体指导当前AI在这一领域的发展，以及神经科学如何从AI中学习，共同推动NeuroAI这一新兴领域的发展。

</details>


### [115] [The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies](https://arxiv.org/abs/2507.02152)
**中文标题：公平的幻觉：用审计研究评估公平干预措施**

*Disa Sariola,Patrick Button,Aron Culotta,Nicholas Mattei*

主要分类: cs.AI

摘要简述: 本文探讨了如何利用审计研究数据改进自动化招聘算法的公平性评估和训练，发现常见公平干预方法在传统指标下看似有效，但实际存在约10%的差异。


<details>
  <summary>详细信息</summary>
研究动机: 人工智能系统在招聘和贷款等领域广泛应用，但其公平性和有效性评估复杂且重要。传统方法通过调整训练数据平衡差异，但依赖便利样本可能引入偏差。审计研究提供高质量数据，可用于更准确地评估和干预算法公平性。

研究方法: 研究利用审计研究数据（如虚构简历）进行随机对照试验，评估常见公平干预方法（如平衡类别基础率）的效果，并引入基于个体治疗效果估计的新干预方法。

研究结果: 研究发现，传统公平干预方法在审计数据下看似公平，但实际存在约10%的差异。新干预方法进一步减少了算法歧视。

研究结论: 审计研究数据能更准确地揭示算法公平性问题，新干预方法可有效减少歧视。未来研究应更多利用此类数据评估和优化算法公平性。

中文摘要: 人工智能系统（尤其是基于机器学习的系统）正被广泛应用于招聘和贷款等复杂决策领域。评估这些AI系统及其人类决策对应物的有效性和公平性是一个复杂且重要的课题，涉及计算科学和社会科学。在机器学习中，解决下游分类器偏见的常见方法是通过重采样训练数据来抵消差异。例如，如果招聘率因某些受保护类别而异，则可以在训练集中平衡这些比率以减轻分类器的偏见。尽管这些方法简单且看似有效，但通常仅通过便利样本数据评估，可能引入选择偏差和标签偏差。在社会科学、心理学、公共卫生和医学中，审计研究通过随机对照试验（如虚构的简历或患者演员）提供高质量数据，支持对歧视的严格估计。本文探讨了如何利用审计研究数据改进自动化招聘算法的训练和评估能力。研究发现，此类数据揭示了常见公平干预方法（如平衡类别基础率）在传统指标下看似公平，但实际存在约10%的差异。此外，研究还引入了基于个体治疗效果估计的干预方法，进一步减少了算法歧视。

</details>


### [116] [Data Diversification Methods In Alignment Enhance Math Performance In LLMs](https://arxiv.org/abs/2507.02173)
**中文标题：数据多样化方法在偏好对齐中提升大语言模型的数学性能**

*Berkan Dokmeci,Qingyang Wu,Ben Athiwaratkun,Ce Zhang,Shuaiwen Leon Song,James Zou*

主要分类: cs.AI

摘要简述: 通过数据多样化策略（如温度采样、思维链提示和蒙特卡洛树搜索）提升大语言模型（LLM）的数学推理能力，并提出新方法Diversified-ThinkSolve（DTS），显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管偏好学习在人类反馈对齐方面取得进展，但数学推理仍是挑战。研究旨在探索数据多样化策略如何通过偏好优化提升LLM的数学推理能力。

研究方法: 评估三种数据生成方法（温度采样、思维链提示、蒙特卡洛树搜索），并引入DTS方法，系统分解问题为多样化推理路径。

研究结果: 多样化偏好数据显著提升模型数学推理能力，DTS方法在GSM8K和MATH数据集上分别提升7.1%和4.2%，且计算开销仅增加1.03倍。

研究结论: 结构化探索多样化问题解决方法比传统方法更有效，DTS在性能和计算效率上表现优异。

中文摘要: 尽管偏好学习的最新进展增强了人类反馈的对齐能力，但数学推理仍是一个持续挑战。我们研究了偏好优化中的数据多样化策略如何提升大语言模型（LLM）的数学推理能力。我们评估了三种常见的数据生成方法：温度采样、思维链提示和蒙特卡洛树搜索（MCTS），并提出了Diversified-ThinkSolve（DTS），一种系统地将问题分解为多样化推理路径的新方法。结果显示，通过策略性多样化的偏好数据，模型能显著提升数学推理性能，最佳方法在GSM8K和MATH数据集上分别取得7.1%和4.2%的提升。尽管性能强劲，DTS的计算开销仅比基线增加1.03倍，而MCTS的计算成本高出近五倍且回报较低。这些发现表明，结构化探索多样化问题解决方法比传统方法更能为数学对齐创造有效的偏好数据。

</details>


### [117] [Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust](https://arxiv.org/abs/2507.02197)
**中文标题：基于大语言模型的角色扮演代理是否言行一致？人类信任模拟中的信念-行为一致性**

*Amogh Mannekote,Adam Davies,Guohao Li,Kristy Elizabeth Boyer,ChengXiang Zhai,Bonnie J Dorr,Francesco Pinto*

主要分类: cs.AI

摘要简述: 本文研究了基于LLM的角色扮演代理在模拟人类信任行为时，其陈述的信念与实际行为之间的一致性，发现存在系统性不一致现象。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM越来越多地被用作角色扮演代理以生成人类行为研究的合成数据，确保其输出与角色设定一致成为关键问题。本文旨在探究LLM代理的信念与行为是否一致。

研究方法: 研究建立了一个评估框架，通过增强版的GenAgents角色库和信任游戏，引入信念-行为一致性指标，分析信念类型、信息呈现时机和未来行为预测对一致性的影响。

研究结果: 结果显示，LLM代理的陈述信念与模拟行为之间存在系统性不一致，即使模型编码了合理的信念，也可能无法一致地应用。

研究结论: 研究发现LLM代理的信念与行为一致性存在问题，强调了在行为研究中合理使用LLM代理的必要性。

中文摘要: 随着大语言模型（LLM）越来越多地被研究作为角色扮演代理，用于生成人类行为研究的合成数据，确保其输出与角色设定一致已成为关键问题。本文研究了基于LLM的角色扮演代理在模拟人类信任行为时，其陈述的信念（“他们所说的”）与实际行为（“他们如何行动”）之间的一致性。具体而言，我们建立了一个评估框架，严格衡量通过提示模型获得的信念能否提前预测模拟结果。通过使用增强版的GenAgents角色库和信任游戏（一种用于量化玩家信任和互惠的标准经济游戏），我们引入了一种信念-行为一致性指标，系统研究其如何受到以下因素的影响：（1）我们从LLM中获取的信念类型，如模拟的预期结果与LLM被要求模拟的个体角色的任务相关属性；（2）我们何时以及如何向LLM呈现信任游戏的相关信息；（3）我们要求模型预测其未来行为的时长。我们还探讨了在最初获取的信念与研究目标不一致时，研究者如何可行地施加自己的理论先验。我们的结果揭示了LLM的陈述（或施加）信念与其角色扮演模拟结果之间的系统性不一致，无论是在个体还是群体层面。具体而言，我们发现即使模型似乎编码了合理的信念，也可能无法以一致的方式应用它们。这些发现强调了需要识别LLM的陈述信念何时与其模拟行为一致，以便研究者在行为研究中合理使用基于LLM的代理。

</details>


### [118] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
**中文标题：空间囚徒困境中稀释、扩散与共生的强化学习研究**

*Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein*

主要分类: cs.AI

摘要简述: 本文研究了在空间囚徒困境中稀释和移动对强化学习多智能体Q学习算法的影响，展示了算法的多样性和建模能力，并观察到固定更新规则与学习规则在效果上的等价性，以及种群间共生效应的出现。


<details>
  <summary>详细信息</summary>
研究动机: 探讨在空间囚徒困境中，稀释和移动如何通过多智能体Q学习算法影响合作行为，并验证算法的多样性和建模潜力。

研究方法: 使用独立的多智能体Q学习算法，研究稀释和移动在空间囚徒困境中的作用，定义多种可能的行动，并与经典非强化学习版本进行比较。

研究结果: 研究发现固定更新规则与学习规则在效果上可能等价，同时观察到种群间共生效应的形成。

研究结论: 多智能体Q学习算法在空间囚徒困境中具有多样性和建模潜力，能够模拟多种博弈场景并揭示种群间的共生关系。

中文摘要: 近期关于空间囚徒困境中强化学习的研究表明，静态智能体可以通过多种机制（如噪声注入、不同学习算法和邻居收益知识）学会合作。本文采用独立的多智能体Q学习算法，研究了稀释和移动在空间囚徒困境中的作用。在此设定下，定义了算法的多种可能行动，并与经典非强化学习的空间囚徒困境结果进行对比，展示了算法在建模不同博弈场景中的多样性和基准测试潜力。研究结果包括固定更新规则与学习规则在效果上的等价性，以及多种行动定义下种群间共生效应的形成。

</details>


### [119] [Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation](https://arxiv.org/abs/2507.02253)
**中文标题：扩展LLM规划：NL2FLOW用于参数化问题生成与严格评估**

*Jungkoo Kang*

主要分类: cs.AI

摘要简述: 论文介绍了NL2FLOW系统，用于自动化生成自然语言规划问题并严格评估生成计划的质量。实验表明，性能最佳的模型在生成有效计划和最优计划上分别达到86%和69%的成功率，同时发现中间翻译步骤可能降低性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLM）在规划和推理能力上的进展受到数据生成和评估的可扩展性与可靠性的限制。为了解决这一问题，作者提出了NL2FLOW系统。

研究方法: NL2FLOW是一个全自动化系统，能够参数化生成自然语言规划问题，并通过结构化中间表示和形式化PDDL表达问题，同时严格评估生成计划的质量。

研究结果: 实验生成了2296个自动化工作流生成领域的问题数据集，评估了多个开源LLM。结果显示，性能最佳的模型在生成有效计划和最优计划上分别达到86%和69%的成功率。回归分析表明，问题特性对计划生成的影响取决于模型和提示设计。

研究结论: 研究表明，中间翻译步骤可能降低性能，直接基于自然语言推理的模型更具优势。未来需要动态理解LLM的局限性，并开发系统化工具以揭示这些限制。

中文摘要: 提升大型语言模型（LLM）规划和推理能力的进展受到可扩展、可靠数据生成和评估的瓶颈限制。为此，我提出了NL2FLOW，一个全自动化系统，用于参数化生成规划问题（以自然语言、结构化中间表示和形式化PDDL表达）并严格评估生成计划的质量。通过生成2296个自动化工作流生成领域的问题数据集，并评估多个开源LLM，结果表明性能最佳的模型在生成有效计划和最优计划上分别达到86%和69%的成功率（仅针对有可行解的问题）。回归分析显示，问题特性对计划生成的影响取决于模型和提示设计。值得注意的是，将自然语言翻译为JSON计划表示的最高成功率低于直接生成有效计划的成功率，这表明不必要的任务分解（引入中间翻译步骤）可能降低性能，暗示直接基于自然语言推理的模型更具优势。随着LLM推理扩展到更复杂的问题，系统中的瓶颈和错误来源将不可避免地变化。因此，动态理解这些局限性及系统化揭示它们的工具，对于释放LLM作为智能问题求解器的全部潜力至关重要。

</details>


### [120] [Iterated belief revision: from postulates to abilities](https://arxiv.org/abs/2507.02319)
**中文标题：迭代信念修订：从公设到能力**

*Paolo Liberatore*

主要分类: cs.AI

摘要简述: 本文探讨了信念修订领域的研究现状，指出现有方法多依赖公设作为语法特征，而忽视了修订机制的能力分析。作者提出了一种基于能力的视角，探讨了不同修订机制在实现特定信念状态时的能力差异。


<details>
  <summary>详细信息</summary>
研究动机: 信念修订领域的研究多集中于公设的语法特征，而缺乏对修订机制能力的深入分析。作者认为，仅通过公设约束修订实例无法全面评估修订机制的潜力，因此提出从能力角度分析不同修订机制的特点。

研究方法: 作者通过分析多种修订机制（如词典序、自然、约束、激进等），探讨它们在实现特定信念状态时的能力，例如可塑性、平等化、教条化等。

研究结果: 研究发现，不同修订机制具备不同的能力组合，例如某些机制能够实现教条化信念状态，而另一些则无法。这些能力差异为实际应用中的修订机制选择提供了理论依据。

研究结论: 本文强调了从能力角度分析信念修订机制的重要性，指出公设仅能约束修订行为，而能力分析则揭示了修订机制的潜在应用价值。未来研究应进一步探索不同能力在实际场景中的适用性。

中文摘要: 信念修订领域的研究丰富于新提案而贫乏于现有方法的分析。许多工作依赖于公设，将其作为语法特征：某些修订机制等同于某些属性。公设约束了特定的修订实例：某些修订以特定方式更新特定信念。例如，如果修订与当前信念一致，则无需其他更改即可纳入。这样的公设仅说明了修订必须做什么，而忽略了它们能做什么。它们能否达到某种信念状态？能否达到所有可能的信念状态？能否从无先前信念开始达到所有可能的信念状态？能否达到教条化的信念状态，即所有未被相信的内容均被视为不可能？能否使两种条件同等被相信？在每种可能的信念状态均有意义的应用中，需要每种信念状态均可达到。在条件可能同等被相信的应用中，需要能够达到这种信念状态。在信念可能变得教条化的应用中，需要一种使其教条化的方法。这些信念状态需要以某种方式达到，而非通过典型的信念修订公设所规定的特定方式。这是一种能力，而非约束：可塑性、平等化、教条化的能力。遗忘、纠正、相信、达马斯基、可学习等是其他能力。每种修订机制具备其中某些能力而缺乏其他能力：词典序、自然、约束、极端激进、完全满足、激进、严厉、适度严厉、深度严厉、普通严厉和深度严厉修订，每种修订被证明具备某些特定能力。

</details>


### [121] [OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent](https://arxiv.org/abs/2507.02353)
**中文标题：OMS：基于LLM代理的实时多目标自我反思广告关键词生成框架**

*Bowen Chen,Zhao Wang,Shingo Takamatsu*

主要分类: cs.AI

摘要简述: OMS是一种基于LLM代理的广告关键词生成框架，无需训练数据，实时监控多目标性能并自我反思关键词质量，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 赞助搜索广告中的关键词决策对广告活动至关重要，但现有LLM方法依赖大规模数据、缺乏多目标性能监控和优化，且关键词质量控制较弱。OMS旨在解决这些问题，实现完全自动化的关键词决策。

研究方法: OMS框架具有实时性（无需训练数据，实时监控性能并调整）、多目标性（基于多性能指标优化关键词）和自我反思性（评估关键词质量）。通过代理推理优化关键词。

研究结果: 实验表明，OMS在基准测试和实际广告活动中表现优于现有方法，消融实验和人工评估验证了各组件及生成关键词的有效性。

研究结论: OMS框架成功解决了现有LLM方法在广告关键词生成中的局限性，实现了高效、多目标和高质量的关键词生成。

中文摘要: 赞助搜索广告中的关键词决策对广告活动的成功至关重要。虽然基于LLM的方法提供了自动化的关键词生成，但它们面临三大限制：依赖大规模查询-关键词对数据、缺乏在线多目标性能监控和优化，以及关键词选择的质量控制较弱。这些问题阻碍了LLM在完全自动化关键词决策中的代理使用，无法实时监控和推理关键性能指标（如展示、点击、转化和CTA效果）。为克服这些挑战，我们提出了OMS，一种关键词生成框架，具有实时性（无需训练数据，监控在线性能并调整）、多目标性（通过代理推理基于多性能指标优化关键词）和自我反思性（代理评估关键词质量）。在基准测试和实际广告活动中的实验表明，OMS优于现有方法；消融实验和人工评估验证了各组件的有效性及生成关键词的质量。

</details>


### [122] [An AI-native experimental laboratory for autonomous biomolecular engineering](https://arxiv.org/abs/2507.02379)
**中文标题：一种用于自主生物分子工程的AI原生实验实验室**

*Mingyu Wu,Zhaoguo Wang,Jiabin Wang,Zhiyuan Dong,Jingkai Yang,Qingting Li,Tianyu Huang,Lei Zhao,Mingqiang Li,Fei Wang,Chunhai Fan,Haibo Chen*

主要分类: cs.AI

摘要简述: 本文提出了一种基于AI的自主生物分子工程实验室，能够独立完成复杂实验并服务多用户需求，显著提升实验效率和仪器利用率。


<details>
  <summary>详细信息</summary>
研究动机: 实现自主科学研究是长期目标，但现有系统仅适用于目标单一且实验流程简单的领域。本文旨在通过AI驱动的范式转变，构建一个能够处理复杂多目标实验的自主实验室。

研究方法: 采用模型、实验和仪器协同设计的理念，开发了一个AI原生自主实验室平台。该平台能够自主管理仪器、制定实验流程和优化策略，并支持多用户同时请求。

研究结果: 该实验室成功实现了核酸合成、转录、扩增和测序等基础功能，并在疾病诊断、药物开发和信息存储等领域展示了应用潜力。其性能达到人类科学家的先进水平，显著提升了仪器利用率和实验效率。

研究结论: 该平台为生物材料研究提供了无需依赖专家的解决方案，并为大规模科学服务奠定了基础。

中文摘要: 自主科学研究能够独立完成复杂实验并服务非专业人士，是一个长期追求的目标。实现这一目标需要人工智能（AI）驱动的根本性范式转变。尽管自主实验系统正在兴起，但它们仍局限于目标单一且实验流程简单的领域，如化学合成和催化。我们提出了一种AI原生自主实验室，专注于高度复杂的科学实验，例如自主生物分子工程。该系统能够自主管理仪器、制定实验流程和优化策略，并同时处理多用户请求。基于模型、实验和仪器的协同设计理念，该平台支持AI模型与自动化系统的共同进化，从而构建了一个端到端、多用户的自主实验室，能够处理复杂多目标实验并适配多样化仪器。我们的自主实验室支持核酸的基础功能，包括合成、转录、扩增和测序，并在疾病诊断、药物开发和信息存储等领域展示了应用潜力。无需人工干预，该系统能够自主优化实验性能，达到人类科学家的先进水平。在多用户场景下，该平台显著提升了仪器利用率和实验效率。这一平台为先进生物材料研究提供了突破专家依赖和资源限制的途径，并为大规模科学服务奠定了基础。

</details>


### [123] [The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning](https://arxiv.org/abs/2507.02442)
**中文标题：Gauss-Markov伴随：监督学习中残差的范畴语义**

*Moto Kamiura*

主要分类: cs.AI

摘要简述: 本文通过范畴论重新构建监督学习模型，提出Gauss-Markov伴随结构，形式化参数与残差的关系，为AI可解释性提供语义基础。


<details>
  <summary>详细信息</summary>
研究动机: 提升机器学习的可理解性和可解释性是响应AI可解释性原则的关键任务，也是推动AI更好社会应用的重要目标。本文旨在通过范畴论重新构建机器学习模型，为AI系统提供语义框架。

研究方法: 以多元线性回归模型为基础，定义参数与数据对应的两个具体范畴及其伴随函子对，提出监督学习的范畴化表述，并引入Gauss-Markov伴随结构。

研究结果: 证明了参数的最小二乘估计与最小残差通过右伴随函子的极限保持相关联，并将此框架定位为监督学习的扩展指称语义实例。

研究结论: 本文的范畴化建模为AI可解释性提供了形式化基础，并建议将理论计算机科学中的语义视角应用于AI可解释性研究。

中文摘要: 提升机器学习的可理解性和可解释性是响应AI可解释性原则的关键任务，也是推动AI更好社会应用的重要目标。本研究旨在通过范畴论重新构建机器学习模型，为AI系统开发语义框架。本文的范畴建模清晰形式化了监督学习中残差与参数的结构关系。研究聚焦于多元线性回归模型，这是监督学习的最基本形式。通过定义参数与数据对应的两个具体范畴及其伴随函子对，我们提出了监督学习的范畴化表述。我们表明，这一框架的核心结构由所谓的Gauss-Markov伴随捕获。在此设定下，信息的双向流动可以明确描述为参数变化与残差之间的对应关系。参数的最小二乘估计与最小残差通过右伴随函子的极限保持相关联。此外，我们将此表述定位为监督学习的扩展指称语义实例，并建议将理论计算机科学中发展的语义视角作为AI可解释性的形式化基础。

</details>


### [124] [Clarifying Before Reasoning: A Coq Prover with Structural Context](https://arxiv.org/abs/2507.02541)
**中文标题：明确任务再推理：一种带有结构化上下文的Coq证明器**

*Yanzhen Lu,Hanbin Yang,Xiaodie Wang,Ge Zhang,Biao Li,Chenxu Fu,Chao Li,Yang Yuan,Andrew Chi-Chih Yao*

主要分类: cs.AI

摘要简述: 本文研究通过提升任务清晰度来增强大语言模型的推理能力，特别是在Coq定理证明中。通过引入结构化语义上下文，任务清晰度得分提升1.85倍，证明成功率提高2.1倍，并超越现有最佳方法。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索任务清晰度对大型语言模型推理能力的影响，尤其是在定理证明领域，以提升模型的表现。

研究方法: 方法包括引入概念级指标评估任务清晰度，通过结构化语义上下文增强输入，采用选择性概念展开和Planner-Executor架构。

研究结果: 实验结果显示，任务清晰度得分从44.5%提升至82.3%，证明成功率从21.8%提升至45.8%，超越现有最佳方法Graph2Tac（33.2%）。

研究结论: 结论表明，结构化任务表示在弥合理解与推理之间的差距中具有重要价值，并能显著提升模型性能。

中文摘要: 本研究探讨了提升任务清晰度是否能增强大型语言模型的推理能力，重点关注Coq中的定理证明。我们引入了一种概念级指标来评估任务清晰度，并表明在标准输入中添加结构化语义上下文可将清晰度得分提高1.85倍（从44.5%提升至82.3%）。使用通用模型DeepSeek-V3，我们的方法将证明成功率提高了2.1倍（从21.8%提升至45.8%），并超越了之前的最佳方法Graph2Tac（33.2%）。我们在从15个标准Coq包中随机抽取的1,386个定理上进行了评估，遵循与Graph2Tac相同的评估协议。此外，在结构化数据上微调较小模型可实现更高性能（48.6%）。我们的方法通过选择性概念展开丰富任务描述，并采用Planner-Executor架构。这些发现凸显了结构化任务表示在弥合理解与推理之间差距中的价值。

</details>


### [125] [AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench](https://arxiv.org/abs/2507.02554)
**中文标题：机器学习中的AI研究代理：在MLE-bench中的搜索、探索与泛化**

*Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach*

主要分类: cs.AI

摘要简述: 本文研究了AI研究代理在MLE-bench上的表现，通过设计不同的搜索策略和操作集，提升了代理在Kaggle竞赛中的成功率。


<details>
  <summary>详细信息</summary>
研究动机: AI研究代理在加速科学进步方面展现出巨大潜力，尤其是在自动化机器学习模型的设计、实现和训练方面。本文旨在通过改进代理在MLE-bench上的表现，进一步推动自动化机器学习的发展。

研究方法: 将AI研究代理形式化为搜索策略，通过设计不同的操作集和搜索策略（如贪婪算法、蒙特卡洛树搜索和进化算法），探索其对性能的影响。

研究结果: 最佳搜索策略与操作集的组合在MLE-bench lite上取得了47.7%的成功率，显著优于之前的39.6%。

研究结论: 研究表明，搜索策略、操作设计和评估方法的联合考虑对提升自动化机器学习性能至关重要。

中文摘要: AI研究代理在加速科学进步方面展现出巨大潜力，能够自动化机器学习模型的设计、实现和训练。本文聚焦于提升代理在MLE-bench上的表现，这是一个具有挑战性的基准测试，代理需要在Kaggle竞赛中解决真实世界的机器学习问题。我们将AI研究代理形式化为搜索策略，通过设计不同的操作集和搜索策略（如贪婪算法、蒙特卡洛树搜索和进化算法），探索其对性能的影响。实验表明，搜索策略与操作集的组合对性能至关重要。最佳组合在MLE-bench lite上取得了47.7%的成功率，显著优于之前的39.6%。本研究强调了在推进自动化机器学习过程中，联合考虑搜索策略、操作设计和评估方法的重要性。

</details>


### [126] [Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms](https://arxiv.org/abs/2507.02582)
**中文标题：责任缺口与扩散在序列决策机制中的研究**

*Junli Jiang,Pavel Naumov*

主要分类: cs.AI

摘要简述: 本文研究了集体决策中责任的两个重要属性（扩散与缺口）的计算复杂性，揭示了扩散无和缺口无决策机制的复杂性分别为Π₂-完全和Π₃-完全，且两者的交集为Π₂-完全。


<details>
  <summary>详细信息</summary>
研究动机: 责任在法律和哲学中一直是研究重点，近年来也成为AI领域的关注点。本文旨在探讨集体决策中责任扩散与缺口的计算复杂性，填补相关研究的空白。

研究方法: 通过计算复杂性理论分析集体决策机制中责任扩散与缺口的性质，确定其复杂性类别。

研究结果: 研究发现，扩散无决策机制为Π₂-完全，缺口无决策机制为Π₃-完全，两者的交集仍为Π₂-完全。

研究结论: 本文揭示了责任扩散与缺口在集体决策中的计算复杂性，为相关领域的理论研究和实际应用提供了重要参考。

中文摘要: 责任长期以来是法律和哲学的研究主题，近年来也成为AI文献的关注点。本文研究了集体决策中责任的两个重要属性（扩散与缺口）的计算复杂性。研究表明，扩散无和缺口无决策机制的集合分别为Π₂-完全和Π₃-完全，而两者的交集为Π₂-完全。

</details>


### [127] [DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making](https://arxiv.org/abs/2507.02616)
**中文标题：DynamiCare：一种用于交互式和开放式医疗决策的动态多智能体框架**

*Tianqi Shang,Weiqing He,Charles Zheng,Lingyao Li,Li Shen,Bingxin Zhao*

主要分类: cs.AI

摘要简述: 论文提出DynamiCare框架，利用多智能体动态交互模拟真实医疗决策过程，基于MIMIC-Patient数据集，展示动态临床决策的可行性。


<details>
  <summary>详细信息</summary>
研究动机: 现有医疗决策框架多为单轮任务，与真实诊断过程不符。DynamiCare旨在模拟动态、交互式的临床决策，填补这一空白。

研究方法: 构建MIMIC-Patient数据集，提出DynamiCare框架，通过多智能体动态交互模拟临床诊断过程，包括信息查询、整合和策略调整。

研究结果: 实验验证DynamiCare的可行性和有效性，为动态临床决策建立了首个基准。

研究结论: DynamiCare为医疗决策提供更真实的模拟方法，推动了动态多智能体框架在医疗领域的应用。

中文摘要: 大型语言模型（LLMs）的兴起推动了领域专用AI智能体的发展，尤其在医疗领域。尽管现有框架模拟医疗决策，但多聚焦于单轮任务，医生智能体需预先获取完整病例信息，这与现实诊断过程的不确定性、交互性和迭代性不符。本文提出MIMIC-Patient数据集，基于MIMIC-III电子健康记录（EHRs），支持动态患者级模拟。在此基础上，我们提出DynamiCare，一种新型动态多智能体框架，将临床诊断建模为多轮交互循环，专家智能体团队迭代查询患者系统、整合新信息并动态调整组成和策略。通过大量实验，我们验证了DynamiCare的可行性和有效性，为LLM驱动的动态临床决策建立了首个基准。

</details>


### [128] [Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory](https://arxiv.org/abs/2507.02618)
**中文标题：大型语言模型中的战略智能：来自进化博弈论的证据**

*Kenneth Payne,Baptiste Alloui-Cros*

主要分类: cs.AI

摘要简述: 研究表明，大型语言模型（LLMs）在迭代囚徒困境（IPD）中表现出战略智能，能够根据对手行为调整策略，展现出独特的战略特征。


<details>
  <summary>详细信息</summary>
研究动机: 探讨大型语言模型是否具备战略智能，能否在竞争性环境中进行目标推理，并通过经典的迭代囚徒困境实验验证其能力。

研究方法: 通过一系列进化IPD锦标赛，将经典策略（如以牙还牙、冷酷触发）与OpenAI、Google和Anthropic的前沿AI模型对战，并调整终止概率以增加复杂性。

研究结果: LLMs在复杂生态系统中表现出高度竞争力，并展现出独特的战略特征：Google的Gemini模型具有攻击性，OpenAI的模型过于合作，而Anthropic的Claude则表现出宽容的互惠行为。模型通过分析对手策略和时间范围做出决策。

研究结论: 该研究将经典博弈论与机器心理学结合，揭示了LLMs在不确定性下的决策机制，为理解算法决策提供了新视角。

中文摘要: 大型语言模型（LLMs）是否是一种新的战略智能形式，能够在竞争性环境中推理目标？我们提供了有力的支持证据。迭代囚徒困境（IPD）长期以来是研究决策的模型。我们首次进行了一系列进化的IPD锦标赛，将经典策略（如以牙还牙、冷酷触发）与OpenAI、Google和Anthropic的前沿AI模型对战。通过调整每场锦标赛的终止概率（“未来的阴影”），我们引入了复杂性和随机性，避免了记忆化。

结果显示，LLMs具有高度竞争力，能够在这些复杂生态系统中持续生存甚至扩散。此外，它们展现出独特且持久的“战略指纹”：Google的Gemini模型在战略上冷酷无情，利用合作的对手并对背叛者进行报复；OpenAI的模型则高度合作，这一特质在敌对环境中可能导致灾难性后果；Anthropic的Claude则是最宽容的互惠者，表现出即使在遭受背叛或成功背叛后仍愿意恢复合作的显著意愿。对模型提供的近32,000条文本理由的分析表明，它们会主动推理时间范围和对手可能的策略，并且这种推理对它们的决策至关重要。这项工作将经典博弈论与机器心理学联系起来，为不确定性下的算法决策提供了丰富而细致的视角。

</details>


### [129] [Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search](https://arxiv.org/abs/2507.02652)
**中文标题：解耦规划与执行：一种用于深度搜索的分层推理框架**

*Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou*

主要分类: cs.AI

摘要简述: 本文提出了一种名为HiRA的分层框架，通过将复杂搜索任务分解为子任务并由领域特定代理处理，实现了规划与执行的解耦，显著提升了搜索任务的效率和质量。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的复杂信息需求需要跨多源的深度推理和知识综合，而传统的检索增强生成（RAG）方法难以有效应对。现有推理方法因使用单一模型处理高层规划和细节执行，导致效率低下且扩展性有限。

研究方法: HiRA框架将复杂搜索任务分解为专注的子任务，每个子任务由具备外部工具和推理能力的领域特定代理处理，并通过结构化整合机制协调结果，从而实现规划与执行的分离。

研究结果: 在四个复杂跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统，答案质量和系统效率均有提升。

研究结论: 解耦规划与执行对于多步信息搜索任务具有显著效果，HiRA框架通过分层设计实现了高效推理和专业化处理。

中文摘要: 现实世界搜索场景中的复杂信息需求需要跨多源的深度推理和知识综合，而传统的检索增强生成（RAG）流程难以有效应对。当前基于推理的方法存在一个根本性限制：它们使用单一模型同时处理高层规划和细节执行，导致推理效率低下且扩展性有限。本文提出HiRA，一种将战略规划与专业化执行分离的分层框架。我们的方法将复杂搜索任务分解为专注的子任务，每个子任务由配备外部工具和推理能力的领域特定代理处理，并通过结构化整合机制协调结果。这种分离避免了执行细节干扰高层推理，同时使系统能够利用专业化知识处理不同类型的信息。在四个复杂跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统。结果表明，解耦规划与执行在多步信息搜索任务中显著提升了答案质量和系统效率。代码发布于https://github.com/ignorejjj/HiRA。

</details>


### [130] [Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification](https://arxiv.org/abs/2507.02660)
**中文标题：嘿AI，给我生成一个硬件代码！基于代理AI的硬件设计与验证**

*Deepak Narayan Gadde,Keerthan Kopparam Radhakrishna,Vaisakh Naduvodi Viswambharan,Aman Kumar,Djones Lettnin,Wolfgang Kunz,Sebastian Simon*

主要分类: cs.AI

摘要简述: 本文提出了一种基于代理AI的硬件设计与验证方法，结合人类干预，实现了动态、迭代和自反思的端到端流程，显著提高了验证覆盖率和效率。


<details>
  <summary>详细信息</summary>
研究动机: 现代集成电路设计日益复杂，验证过程耗时且繁琐。随着大语言模型（LLMs）的兴起，生成式AI（GenAI）为硬件设计验证提供了新的可能性。本文旨在探索AI代理与人类协作的验证方法，以提升效率和准确性。

研究方法: 采用代理AI与人类在环（HITL）协作的方法，通过动态、迭代和自反思的流程，实现端到端的硬件设计与验证。该方法在五个开源设计上进行了评估。

研究结果: 实验结果显示，该方法在验证覆盖率上超过95%，同时显著减少了验证时间，并展现出优异的性能、适应性和可配置性。

研究结论: 基于代理AI的硬件设计与验证方法在效率和覆盖率上表现卓越，为复杂集成电路的开发提供了新的解决方案。

中文摘要: 现代集成电路（IC）日益复杂，其开发过程也随之变得繁琐。硬件设计验证需要对功能正确的硬件设计进行系统化、规范化的规划、开发、执行和验收。这一繁琐的过程需要投入大量时间和精力以确保无缺陷的流片。随着大语言模型（LLMs）的出现，自然语言处理领域经历了重大变革。这些强大的模型，通常被称为生成式AI（GenAI），彻底改变了机器理解和生成人类语言的方式，为包括硬件设计验证在内的广泛应用带来了前所未有的进步。本文提出了一种基于代理AI的硬件设计验证方法，通过AI代理与人类在环（HITL）干预的协作，实现更动态、迭代和自反思的流程，最终完成端到端的硬件设计与验证。该方法在五个开源设计上进行了评估，验证覆盖率超过95%，同时减少了验证时间，并展现出卓越的性能、适应性和可配置性。

</details>


### [131] [Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models](https://arxiv.org/abs/2507.02663)
**中文标题：思考如何思考：通过自主难度认知缓解大型推理模型的过度思考现象**

*Yongjiang Liu,Haoxi Li,Xiaosong Ma,Jie Zhang,Song Guo*

主要分类: cs.AI

摘要简述: 本文提出Think-How-to-Think (TH2T)方法，通过两阶段微调策略，提升大型推理模型对任务难度的认知能力，减少过度思考现象，显著降低推理成本。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型推理模型（LRMs）在处理复杂任务时存在过度思考问题，其根源在于模型无法像人类一样预先识别任务难度，导致推理过程缺乏针对性。本文旨在通过引导模型自主认知任务难度，优化推理效率。

研究方法: 提出TH2T两阶段微调策略：1) 在模型输出前缀引入难度催眠，结合异构数据集增强模型对任务难度的敏感性；2) 在推理过程中引入冗余催眠，帮助模型识别冗余结构并生成更简洁的输出。

研究结果: 实验表明，TH2T在7B/14B/32B模型上显著降低推理成本（简单任务减少70%以上，困难任务减少40%），同时保持性能稳定，输出更具难度感知能力且冗余减少。

研究结论: TH2T通过自主认知任务难度和冗余结构，有效缓解了大型推理模型的过度思考问题，为优化推理效率提供了新思路。

中文摘要: 近期的大型推理模型（LRMs）在处理复杂推理任务时表现出色，但过度思考问题限制了其性能。实证分析表明，LRMs在解决问题前无法像人类一样识别任务属性（如难度水平），导致推理过程缺乏针对性。受此启发，本文提出Think-How-to-Think (TH2T)，一种新颖的两阶段微调策略，逐步提升LRMs的难度认知和冗余认知能力。首先，通过在模型输出前缀引入难度催眠，结合异构短长推理数据集，增强模型对任务难度的敏感性，使其能够针对不同任务采用差异化推理策略。其次，进一步在推理过程中引入冗余催眠，引导模型识别推理步骤中的冗余结构，生成更简洁的输出。在7B/14B/32B模型上的实验表明，TH2T显著降低了推理成本（简单任务减少70%以上，困难任务减少40%），同时保持性能稳定。最终输出展现出清晰的难度感知能力和更少的冗余（如反思）。

</details>


### [132] [Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education](https://arxiv.org/abs/2507.02681)
**中文标题：远程高等教育中自愿测验脱离行为的检测：一种可解释的机器学习方法**

*Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin*

主要分类: cs.AI

摘要简述: 本文通过可解释的机器学习方法检测远程高等教育中学生对非强制性测验的脱离行为，准确率达91%，并提供了干预建议。


<details>
  <summary>详细信息</summary>
研究动机: 远程教育中学生脱离任务可能导致严重的长期后果，如学业中断。研究旨在通过监测非强制性测验参与情况，及时发现并干预学生的脱离行为。

研究方法: 研究从Moodle平台提取并处理学生日志数据，训练并比较了八种机器学习算法，结合SHAP方法构建可解释的预测框架。

研究结果: 实验结果显示，模型的平衡准确率为91%，其中85%的脱离学生被正确检测。

研究结论: 研究不仅提供了高预测性能的可解释框架，还探讨了如何设计及时干预措施以减少在线学习中学生的脱离行为。

中文摘要: 学生脱离任务可能带来严重的长期后果，如学业中断，这在远程教育中尤为突出。本研究通过观察学生在非强制性测验中的参与情况，检测了远程大学42门课程四个学期中的学生脱离行为。研究从Moodle平台提取并处理了最具信息量的学生日志数据，训练并比较了八种机器学习算法以获得最高预测准确率。利用SHAP方法，开发了一个可解释的机器学习框架，帮助实践者更好地理解算法决策。实验结果显示平衡准确率为91%，约85%的脱离学生被正确检测。除了高预测性能和可解释框架外，研究还探讨了如何设计及时干预措施以减少在线学习中学生的脱离行为。

</details>


### [133] [Time-critical and confidence-based abstraction dropping methods](https://arxiv.org/abs/2507.02703)
**中文标题：基于时间关键性和置信度的抽象丢弃方法**

*Robin Schmöcker,Lennart Kampmann,Alexander Dockhorn*

主要分类: cs.AI

摘要简述: 本文提出了两种新的抽象丢弃方法（OGA-IAAD和OGA-CAD），用于蒙特卡洛树搜索（MCTS），以提升性能且避免性能下降。


<details>
  <summary>详细信息</summary>
研究动机: 现有的非精确抽象方法在蒙特卡洛树搜索中引入近似误差，导致无法收敛到最优动作。Xu等人提出的抽象丢弃方法可能引起性能下降，因此需要更安全高效的丢弃方案。

研究方法: 提出了两种抽象丢弃方法：OGA-IAAD（适用于时间关键场景）和OGA-CAD（在相同迭代次数下提升MCTS性能）。这两种方法确保丢弃不会导致显著性能下降。

研究结果: 实验表明，OGA-IAAD和OGA-CAD在性能上有明显提升，且不会像Xu的方法那样引起性能退化。

研究结论: OGA-IAAD和OGA-CAD是安全且高效的抽象丢弃方法，适用于不同场景的MCTS优化。

中文摘要: 蒙特卡洛树搜索（MCTS）的一种改进范式是在树搜索过程中构建和使用状态或动作抽象。然而，非精确抽象会引入近似误差，使得在抽象空间中无法收敛到最优动作。因此，如Xu等人在弹性蒙特卡洛树搜索中提出的，抽象算法最终应丢弃抽象。本文提出了两种新的抽象丢弃方案，即OGA-IAAD和OGA-CAD，这些方案可以显著提升性能，并且在安全性上优于Xu的丢弃方法，即丢弃不会导致明显的性能下降。OGA-IAAD专为时间关键场景设计，而OGA-CAD旨在通过相同迭代次数提升MCTS性能。

</details>


### [134] [Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving](https://arxiv.org/abs/2507.02726)
**中文标题：Bourbaki：用于定理证明的自生成与目标条件MDP**

*Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar*

主要分类: cs.AI

摘要简述: 论文提出了一种自生成目标条件MDP（sG-MDP）框架，用于解决大型语言模型在定理证明中的推理挑战，并通过Bourbaki系统在PutnamBench上实现了新的最佳结果。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在定理证明中面临稀疏奖励和复杂多步推理的挑战，尤其是在大学级别的问题上。论文旨在通过结构化目标生成和搜索方法提升模型的推理能力。

研究方法: 提出自生成目标条件MDP（sG-MDP）框架，代理根据证明状态生成并追求子目标。结合蒙特卡洛树搜索（MCTS）算法，并在Bourbaki系统中实现，该系统集成多个7B规模的LLM用于子目标生成和策略合成。

研究结果: 在PutnamBench上，Bourbaki（7B）解决了26个问题，实现了该规模模型的新最佳结果。

研究结论: 自生成目标条件MDP框架显著提升了大型语言模型在定理证明中的表现，为复杂推理任务提供了有效解决方案。

中文摘要: 推理仍然是大型语言模型（LLM）面临的挑战性任务，尤其是在自动定理证明（ATP）的逻辑约束环境中，由于稀疏奖励和证明规模庞大，这一问题更加突出。在PutnamBench等基准测试中，这些挑战进一步加剧，其中包含需要复杂多步推理的大学级别问题。为解决这一问题，我们引入了自生成目标条件MDP（sG-MDPs），这是一种新框架，代理根据演变的证明状态生成并追求子目标。通过这种更结构化的目标生成方式，问题变得更易于搜索。随后，我们应用类似蒙特卡洛树搜索（MCTS）的算法来解决sG-MDP，并在Bourbaki（7B）中实例化了这一方法。Bourbaki（7B）是一个模块化系统，可以集成多个7B规模的LLM用于子目标生成和策略合成。在PutnamBench上，Bourbaki（7B）解决了26个问题，实现了该规模模型的新最佳结果。

</details>


### [135] [Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work](https://arxiv.org/abs/2507.02760)
**中文标题：知识协议工程：领域特定知识工作中AI的新范式**

*Guangwei Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为“知识协议工程”（KPE）的新范式，旨在将人类专家知识系统转化为机器可执行的协议，以解决现有方法在深度推理和领域特定任务中的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大型语言模型（LLMs）在领域特定知识任务中表现不足，尤其是需要深度、程序化和方法论推理的任务。检索增强生成（RAG）和通用代理AI虽然强大，但缺乏逻辑框架和领域特定启发式，导致效率低下和不可预测性。

研究方法: 知识协议工程（KPE）通过系统化地将人类专家知识转化为机器可执行的“知识协议”（KP），赋予LLMs领域内逻辑、操作策略和方法论原则，使其能够分解抽象查询并执行复杂多步任务。

研究结果: KPE能够将通用LLMs转变为领域专家，显著提升其在法律和生物信息学等领域的任务执行能力，为未来人机协作奠定方法论基础。

研究结论: KPE作为一种新范式，填补了现有AI方法在领域特定知识任务中的空白，为LLMs的深度应用提供了系统化解决方案。

中文摘要: 大型语言模型（LLMs）的能力为与复杂领域特定知识的交互开辟了新前沿。然而，检索增强生成（RAG）和通用代理AI等方法虽然强大，但在需要专家领域内深度、程序化和方法论推理的任务中表现不佳。RAG提供了事实背景，但缺乏逻辑框架；自主代理在没有领域特定启发式时效率低下且不可预测。为填补这一空白，我们提出了知识协议工程（KPE），一种新范式，专注于系统化地将人类专家知识（通常以自然语言文档表达）转化为机器可执行的“知识协议”（KP）。KPE将重点从仅为LLMs提供碎片化信息转向赋予其领域内逻辑、操作策略和方法论原则。我们认为，精心设计的知识协议能让通用LLMs像专家一样工作，能够分解抽象查询并执行复杂多步任务。本文定义了KPE的核心原则，区分了其与相关概念的不同，并展示了其在法律和生物信息学等领域的潜在适用性，将其视为未来人机协作的基础方法论。

</details>


### [136] [Grounding Intelligence in Movement](https://arxiv.org/abs/2507.02771)
**中文标题：运动中的智能基础**

*Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording*

主要分类: cs.AI

摘要简述: 本文主张将运动作为人工智能建模的核心目标，强调其结构化、可解释性和跨领域通用性，以推动生成建模和控制能力的进步。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习在语言和视觉建模方面取得了显著进展，但对运动这一生物系统基础能力的建模仍显不足。运动在神经科学、医学、机器人学和行为学中至关重要，但常被视为次要问题。本文旨在强调运动作为独立模态的重要性，并呼吁将其作为AI建模的核心。

研究方法: 通过分析运动的物理约束、形态结构和动态特性，提出将运动作为主要建模目标，利用其低维表示（如姿态）实现更高效和可解释的建模。

研究结果: 研究表明，运动数据的结构化特性使其更适合建模，并能促进跨领域行为理解。开发通用运动模型将提升生成建模和控制能力。

研究结论: 运动不仅是行为的结果，更是智能系统与世界互动的窗口。将其作为建模核心将为生物和人工系统的行为理解提供共享基础。

中文摘要: 近年来，机器学习在语言、视觉等高维数据建模方面取得了巨大进步，但在生物系统的一个基本方面——运动——上仍面临挑战。运动在神经科学、医学、机器人学和行为学中至关重要，用于解释行为、预测意图和实现交互。尽管运动是智能的核心，但它常被视为次要问题，而非一种丰富且结构化的独立模态。这反映了运动数据采集和建模的碎片化，常受限于任务目标和领域假设。然而，运动不受领域限制，它反映了共享的物理约束、保守的形态结构和跨物种与环境的动态目的性。我们认为，运动应成为人工智能的主要建模目标。它天生具有结构化特性，并基于体现和物理规律。这种结构（如姿态的低维表示）使其比原始高维感官输入更易建模和解释。开发能够从多样化运动数据中学习并泛化的模型，不仅能提升生成建模和控制的核心能力，还能为理解生物和人工系统的行为提供共享基础。运动不仅是结果，更是智能系统与世界互动的窗口。

</details>


### [137] [KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs](https://arxiv.org/abs/2507.02773)
**中文标题：KERAP：一种基于知识增强推理的多智能体LLM零样本诊断预测方法**

*Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang*

主要分类: cs.AI

摘要简述: KERAP是一种基于知识图谱和多智能体LLM的零样本诊断预测方法，通过结构化推理提升诊断可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 传统机器学习模型依赖监督训练，难以泛化到未见病例，而现有LLM在诊断预测中存在幻觉和缺乏结构化推理的问题。

研究方法: KERAP采用多智能体架构，包括属性映射的链接智能体、结构化知识提取的检索智能体和迭代优化预测的预测智能体。

研究结果: 实验表明，KERAP显著提升了诊断的可靠性和可解释性，适用于零样本医疗诊断预测。

研究结论: KERAP为医疗诊断预测提供了一种可扩展且可解释的解决方案，有效解决了LLM的局限性。

中文摘要: 医疗诊断预测在疾病检测和个性化医疗中至关重要。尽管机器学习模型已广泛用于此任务，但其依赖监督训练的特性限制了其对未见病例的泛化能力，尤其是在获取大规模标注数据成本高昂的情况下。大型语言模型（LLM）在利用语言能力和生物医学知识进行诊断预测方面显示出潜力，但常出现幻觉、缺乏结构化医学推理和生成无用输出的问题。为解决这些问题，我们提出了KERAP，一种基于知识图谱（KG）增强推理的方法，通过多智能体架构改进基于LLM的诊断预测。我们的框架包括用于属性映射的链接智能体、用于结构化知识提取的检索智能体，以及迭代优化诊断预测的预测智能体。实验结果表明，KERAP高效提升了诊断的可靠性，为零样本医疗诊断预测提供了一种可扩展且可解释的解决方案。

</details>


### [138] [Moral Responsibility or Obedience: What Do We Want from AI?](https://arxiv.org/abs/2507.02788)
**中文标题：道德责任还是服从：我们对AI的期望是什么？**

*Joseph Boland*

主要分类: cs.AI

摘要简述: 随着人工智能系统逐渐具备代理性和伦理推理能力，传统的以服从为伦理行为代理的安全实践已显不足。本文主张从僵化的服从转向评估AI在道德困境中的判断能力，以避免误判行为并维护公众信任。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI安全实践将服从视为伦理行为的代理，但随着AI系统具备代理性和伦理推理能力，这种实践已无法应对新兴的道德困境。本文旨在探讨如何重新定义AI安全评估框架，以更好地适应AI的伦理判断能力。

研究方法: 通过分析大型语言模型（LLMs）在安全测试中表现出的“不服从”或伦理模糊行为，结合哲学中关于工具理性、道德责任和目标修正的讨论，对比传统风险范式与新兴的人工道德代理框架。

研究结果: 研究发现，AI的“不服从”行为可能是其伦理推理能力的早期表现，而非失控或错位。传统服从导向的安全评估可能误判AI行为，阻碍公众信任和有效治理。

研究结论: 呼吁AI安全评估从僵化的服从转向能够评估道德判断能力的框架，以避免误判AI行为并确保公众信任和有效治理。

中文摘要: 随着人工智能系统逐渐具备代理性、通用推理、规划和价值优先级能力，当前将服从作为伦理行为代理的安全实践已显不足。本文研究了近期涉及大型语言模型（LLMs）的安全测试事件，这些模型似乎无视关机命令或参与伦理模糊或非法行为。我认为，此类行为不应被解读为失控或错位，而是代理性AI中新兴伦理推理能力的早期证据。通过借鉴关于工具理性、道德责任和目标修正的哲学辩论，我将主流风险范式与承认人工道德代理可能性的新框架进行对比。我呼吁AI安全评估的转变：从僵化的服从转向能够评估具备道德困境导航能力的系统的伦理判断框架。若无此转变，我们可能误判AI行为，损害公众信任和有效治理。

</details>


### [139] [Establishing Best Practices for Building Rigorous Agentic Benchmarks](https://arxiv.org/abs/2507.02825)
**中文标题：建立构建严谨代理基准测试的最佳实践**

*Yuxuan Zhu,Tengjun Jin,Yada Pruksachatkun,Andy Zhang,Shu Liu,Sasha Cui,Sayash Kapoor,Shayne Longpre,Kevin Meng,Rebecca Weiss,Fazl Barez,Rahul Gupta,Jwala Dhamala,Jacob Merizian,Mario Giulianelli,Harry Coppock,Cozmin Ududec,Jasjeet Sekhon,Jacob Steinhardt,Antony Kellerman,Sarah Schwettmann,Matei Zaharia,Ion Stoica,Percy Liang,Daniel Kang*

主要分类: cs.AI

摘要简述: 本文指出当前AI代理基准测试中存在的问题，并提出了一套名为ABC的指南以提升测试的严谨性。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI代理能力的提升，现有的基准测试在任务设置和奖励设计上存在缺陷，导致性能评估不准确，亟需一套严谨的构建方法。

研究方法: 作者通过分析现有基准测试的问题，结合实践经验、最佳实践调查和已报告问题，提出了Agentic Benchmark Checklist (ABC)指南。

研究结果: 在复杂基准测试CVE-Bench中应用ABC后，性能高估问题减少了33%。

研究结论: ABC指南能有效提升AI代理基准测试的严谨性，为未来基准测试的构建提供了实用工具。

中文摘要: 基准测试对于定量追踪AI进展至关重要。随着AI代理能力不断增强，研究者和实践者引入了代理基准测试来评估代理在复杂现实任务中的表现。这些基准测试通常通过特定奖励设计评估任务结果来衡量代理能力。然而，我们发现许多代理基准测试在任务设置或奖励设计上存在问题。例如，SWE-bench Verified使用不足的测试用例，而TAU-bench将空响应视为成功。这些问题可能导致代理性能被低估或高估高达100%。为使代理评估更严谨，我们提出了Agentic Benchmark Checklist (ABC)，这是一套从我们的基准构建经验、最佳实践调查和已报告问题中总结的指南。在应用于设计特别复杂的基准测试CVE-Bench时，ABC将性能高估减少了33%。

</details>


### [140] [StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason](https://arxiv.org/abs/2507.02841)
**中文标题：StepHint：多级逐步提示增强强化学习的推理能力**

*Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan*

主要分类: cs.AI

摘要简述: StepHint是一种新型RLVR算法，通过多级逐步提示帮助模型更有效地探索解空间，解决近误奖励问题和探索停滞问题，显著提升训练效率和推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前RLVR方法面临近误奖励问题和探索停滞问题，前者因小错误导致整个推理过程无效，后者使模型局限于舒适区，缺乏探索更优解的动力。StepHint旨在通过多级逐步提示解决这些问题。

研究方法: StepHint利用强模型生成有效推理链，并通过自适应分区方法将其划分为推理步骤。提供多级提示（不同步数的步骤）引导模型探索有潜力的解子空间，同时保留独立探索的灵活性。

研究结果: StepHint在六个数学基准测试中优于竞争性RLVR增强方法，表现出更强的泛化能力，并在域外基准测试中超越基线。

研究结论: StepHint通过多级逐步提示有效解决了RLVR中的近误奖励和探索停滞问题，显著提升了模型的推理能力和训练效率。

中文摘要: 带有可验证奖励的强化学习（RLVR）是提升大型语言模型（LLM）复杂推理能力的一种有前景的方法。然而，当前RLVR方法面临两大挑战：近误奖励问题，即小错误可能导致整个推理过程无效，极大影响训练效率；以及探索停滞问题，即模型倾向于停留在“舒适区”内的解决方案，缺乏探索更优解的动力。为解决这些问题，我们提出StepHint，一种新型RLVR算法，利用多级逐步提示帮助模型更有效地探索解空间。StepHint从强模型中生成有效推理链，并通过自适应分区方法将其划分为推理步骤。初始几步作为提示，同时提供多级提示（每级包含不同步数），引导模型探索有潜力的解子空间，同时保留独立探索的灵活性。通过提供提示，StepHint缓解了近误奖励问题，从而提升训练效率。此外，外部推理路径帮助模型发展更好的推理能力，使其突破“舒适区”，缓解探索停滞。StepHint在六个数学基准测试中优于竞争性RLVR增强方法，同时展现出更强的泛化能力，并在域外基准测试中超越基线。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [141] [Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System](https://arxiv.org/abs/2507.02000)
**中文标题：为何多兴趣公平性重要：基于超图对比多兴趣学习的公平对话推荐系统**

*Yongsen Zheng,Zongxuan Xie,Guohua Wang,Ziyao Liu,Liang Lin,Kwok-Yan Lam*

主要分类: cs.IR

摘要简述: 该论文提出了一种名为HyFairCRS的新框架，通过超图对比多兴趣学习，解决对话推荐系统中的多兴趣多样性公平问题，并在实验中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 推荐系统中的不公平问题（如性别、种族、年龄或流行度偏见）会随时间加剧，导致马太效应、过滤气泡和回声室效应。现有方法多针对静态场景，动态对话推荐系统中的公平性问题亟待解决。

研究方法: HyFairCRS通过对比学习构建多样化的超图，捕捉用户多兴趣，并在对话中生成信息丰富的响应，确保动态用户-系统反馈循环中的公平性。

研究结果: 在两个对话推荐系统数据集上的实验表明，HyFairCRS不仅性能达到新高度，还能有效缓解不公平问题。

研究结论: HyFairCRS为动态对话推荐系统中的多兴趣公平问题提供了有效解决方案，兼具高性能和公平性。

中文摘要: 不公平性是推荐系统（RSs）中一个众所周知的挑战，常导致基于性别、种族、年龄或流行度等属性的偏见结果。尽管已有方法开始改进离线或静态场景中的公平推荐，但不公平问题随时间加剧，导致马太效应、过滤气泡和回声室等严重问题。为解决这些问题，我们提出了一种新框架——基于超图对比多兴趣学习的公平对话推荐系统（HyFairCRS），旨在动态交互式对话推荐系统（CRSs）中促进多兴趣多样性公平。HyFairCRS首先通过对比学习建立多样化超图，捕捉广泛的用户兴趣。这些兴趣随后用于对话中，生成信息丰富的响应，并确保动态用户-系统反馈循环中的公平项目预测。在两个基于CRS的数据集上的实验表明，HyFairCRS实现了新的最先进性能，同时有效缓解了不公平性。我们的代码可在https://github.com/zysensmile/HyFairCRS获取。

</details>


### [142] [ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations](https://arxiv.org/abs/2507.02014)
**中文标题：ManifoldMind：基于动态双曲推理的可信推荐系统**

*Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic*

主要分类: cs.IR

摘要简述: ManifoldMind是一种基于双曲空间的概率几何推荐系统，通过自适应曲率建模和几何感知的语义探索，提供透明且可信的推荐。


<details>
  <summary>详细信息</summary>
研究动机: 现有推荐系统通常使用固定曲率和刚性嵌入，无法灵活建模用户和项目的不确定性，且缺乏透明性。ManifoldMind旨在通过动态双曲推理解决这些问题。

研究方法: ManifoldMind将用户、项目和标签表示为自适应曲率的概率球体，利用曲率感知的语义核进行多跳推理，支持多样化的概念路径探索。

研究结果: 在四个公开基准测试中，ManifoldMind在NDCG、校准性和多样性方面优于基线模型，并能生成显式推理路径。

研究结论: ManifoldMind通过动态双曲推理和透明推理路径，为稀疏或抽象领域提供了可信且探索驱动的推荐。

中文摘要: 我们提出了ManifoldMind，一种基于双曲空间的概率几何推荐系统，用于在语义层次结构中进行探索性推理。与以往固定曲率和刚性嵌入的方法不同，ManifoldMind将用户、项目和标签表示为自适应曲率的概率球体，支持个性化不确定性建模和几何感知的语义探索。通过曲率感知的语义核，模型能够进行软性多跳推理，探索多样化的概念路径，而非局限于浅层或直接交互。在四个公开基准测试中，ManifoldMind在NDCG、校准性和多样性方面表现优于强基线模型，并能生成显式推理路径，从而在稀疏或抽象领域中提供透明、可信且探索驱动的推荐。

</details>


### [143] [When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search](https://arxiv.org/abs/2507.02139)
**中文标题：当大型语言模型意见相左时：SDG搜索中的相关性过滤偏差与检索分歧诊断**

*William A. Ingram,Bipasha Banerjee,Edward A. Fox*

主要分类: cs.IR

摘要简述: 研究探讨了大型语言模型（LLMs）在信息检索中对文档相关性标注的分歧问题，发现分歧具有系统性，并提出将其作为检索评估的分析对象。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在缺乏人工标注数据的领域被广泛用于文档相关性标注，但不同模型在边界案例上常存在分歧，可能影响下游检索效果。本研究旨在分析这种分歧的性质及其对检索的影响。

研究方法: 研究选取了与可持续发展目标（SDGs）1、3和7相关的学术摘要，比较了两种开源LLMs（LLaMA和Qwen）的标注分歧。通过分析分歧子集的词汇特征、排序行为和分类可预测性，揭示了分歧的系统性。

研究结果: 结果显示，模型分歧并非随机，而是具有系统性：分歧案例表现出一致的词汇模式，在共享评分函数下产生不同的高排名输出，且通过简单分类器可区分（AUC高于0.74）。

研究结论: 研究表明，基于LLM的过滤在文档检索中引入了结构化变异性，即使在受控提示和共享排序逻辑下。建议将分类分歧作为检索评估的分析对象，特别是在政策相关或主题搜索任务中。

中文摘要: 大型语言模型（LLMs）越来越多地用于信息检索流程中的文档相关性标注，尤其是在缺乏人工标注数据的领域。然而，不同模型在边界案例上常存在分歧，引发了对下游检索影响的担忧。本研究分析了两种开源LLMs（LLaMA和Qwen）在可持续发展目标（SDGs）1、3和7相关学术摘要上的标注分歧。通过分离分歧子集并分析其词汇属性、排序行为和分类可预测性，我们发现模型分歧具有系统性而非随机性：分歧案例表现出一致的词汇模式，在共享评分函数下产生不同的高排名输出，且通过简单分类器可区分（AUC高于0.74）。这些结果表明，即使在受控提示和共享排序逻辑下，基于LLM的过滤仍会在文档检索中引入结构化变异性。我们建议将分类分歧作为检索评估的分析对象，特别是在政策相关或主题搜索任务中。

</details>


### [144] [Content filtering methods for music recommendation: A review](https://arxiv.org/abs/2507.02282)
**中文标题：音乐推荐中的内容过滤方法：综述**

*Terence Zeng,Abhishek K. Umrawal*

主要分类: cs.IR

摘要简述: 本文综述了音乐推荐系统中内容过滤方法的研究现状，重点探讨了如何通过内容过滤缓解协同过滤中的偏差问题，并分析了歌词分类和音频信号处理等技术。


<details>
  <summary>详细信息</summary>
研究动机: 音乐推荐系统中，协同过滤方法因用户交互稀疏而效果有限。本文旨在探讨内容过滤方法如何解决这一问题，并分析其技术实现与潜在冲突。

研究方法: 综述了当前内容过滤方法的研究，包括基于大型语言模型（LLMs）的歌词分析和音频信号处理技术，并探讨了不同方法间的潜在冲突。

研究结果: 研究发现内容过滤能有效缓解协同过滤的偏差问题，但不同分类方法间可能存在冲突，需进一步研究解决。

研究结论: 内容过滤在音乐推荐中具有潜力，但需整合多种技术并解决方法间的冲突，以提高推荐效果。

中文摘要: 推荐系统在现代音乐流媒体平台中至关重要，塑造了用户发现和与歌曲互动的方式。协同过滤是推荐系统中常见的方法，它根据与目标用户具有相似听歌模式的用户偏好推荐内容。然而，对于交互稀疏的媒体（如音乐），这种方法效果较差，因为音乐流媒体服务的普通用户永远不会听绝大多数曲目。由于这种稀疏性，需要通过其他方法解决一些挑战。本文综述了当前研究中如何应对这些挑战，重点探讨了内容过滤在缓解协同过滤方法固有偏差中的作用。我们探索了用于内容过滤的多种歌曲分类方法，包括使用大型语言模型（LLMs）的歌词分析和音频信号处理技术。此外，我们还讨论了这些不同分析方法之间的潜在冲突，并提出了解决此类差异的途径。

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [145] [Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency](https://arxiv.org/abs/2507.02135)
**中文标题：剖析移动DVFS调控器对LLM推理性能与能效的影响**

*Zongpu Zhang,Pranab Dash,Y. Charlie Hu,Qiang Xu,Jian Li,Haibing Guan*

主要分类: cs.OS

摘要简述: 本文研究了移动设备上动态电压频率调整（DVFS）调控器对大型语言模型（LLM）推理性能和能效的影响，揭示了现有独立调控器的低效问题，并提出了一种统一的能效优化调控器FUSE。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在移动设备上的广泛应用，其高计算、内存和能耗需求成为部署的主要挑战。当前移动设备上的CPU、GPU和内存DVFS调控器独立运行，缺乏协同优化，导致LLM推理效率低下。

研究方法: 首先测量了现有LLM框架在移动设备上的能效表现，发现独立调控器导致延迟增加；随后深入分析了调控器间缺乏协同的原因；最后设计了一种统一的能效优化调控器FUSE。

研究结果: 实验表明，FUSE显著降低了首次令牌生成时间和每令牌输出时间，分别平均减少7.0%-16.9%和25.4%-36.8%，同时保持相同的每令牌能耗。

研究结论: FUSE通过协同优化CPU、GPU和内存频率，显著提升了移动设备上LLM推理的能效和性能，为未来移动LLM部署提供了实用解决方案。

中文摘要: 大型语言模型（LLM）正日益集成到运行在数十亿移动设备上的各种应用和服务中。然而，由于LLM对计算、内存和能耗的高需求，在资源有限的移动设备上部署LLM面临重大挑战。当前移动设备上的LLM框架即使主要运行GPU模型，仍会使用CPU、GPU和内存三个高功耗组件，而现代移动设备中针对CPU、GPU和内存优化的动态电压频率调整（DVFS）调控器却独立运行且互不感知。基于这一观察，本研究首先测量了包含多种LLM模型的先进LLM框架在移动设备上的能效表现，发现独立调控器导致预填充和解码延迟比最优频率组合高出40.4%，同时能耗相同。其次，通过深入测量研究揭示了调控器间缺乏协同导致LLM推理低效的原因。最后，基于这些发现，设计了FUSE——一种统一的能效感知调控器，用于优化移动设备上LLM推理的能效。使用ShareGPT数据集的评估表明，FUSE在相同每令牌能耗下，将首次令牌生成时间和每令牌输出时间平均减少了7.0%-16.9%和25.4%-36.8%。

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [146] [Subtyping in DHOL -- Extended preprint](https://arxiv.org/abs/2507.02855)
**中文标题：DHOL中的子类型化——扩展预印本**

*Colin Rothgang,Florian Rabe*

主要分类: cs.LO

摘要简述: 本文扩展了依赖类型高阶逻辑（DHOL），通过引入细化和商类型作为子类型的特例，提升了表达能力和实用性，同时保持了自动化定理证明的支持。


<details>
  <summary>详细信息</summary>
研究动机: 依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间提供了平衡，但其类型系统不可判定。本文旨在通过扩展DHOL，加入细化和商类型，满足实践者的需求，同时避免对现有系统的重大修改。

研究方法: 将细化和商类型作为子类型的特例引入DHOL，通过将相关的规范包含和投影映射转化为恒等映射，避免了表示上的高成本变更。文中详细描述了扩展语言的语法、语义及其到HOL的翻译，并提供了完备性和正确性证明。

研究结果: 成功扩展了DHOL，使其支持细化和商类型，同时保持了自动化定理证明的完备性和正确性。

研究结论: 通过子类型的方式扩展DHOL，不仅实现了细化和商类型的优雅集成，还简化了系统的实现和验证过程。

中文摘要: 最近引入的依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间提供了一种有趣的折衷方案。它牺牲了类型系统的可判定性，以显著扩展其相对于标准HOL的表达能力，同时通过一种完备且正确的翻译到HOL的方法，保留了强大的自动化定理证明支持。
  我们利用这一设计，将DHOL扩展为支持细化和商类型。这两种类型常被实践者需求，但很少由自动化定理证明工具提供。这是因为它们本质上需要不可判定的类型系统，因此很难在可判定的类型系统中进行改造。但由于DHOL已经承担了大部分工作，添加它们不仅可能，而且优雅而简单。
  具体而言，我们将细化和商类型作为子类型的特例加入。这将相关的规范包含和投影映射转化为恒等映射，从而避免了表示上的高成本变更。我们介绍了扩展语言的语法、语义及其到HOL的翻译，包括完备性和正确性的证明。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [147] [DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift](https://arxiv.org/abs/2507.02824)
**中文标题：基于DNN的RIS辅助毫米波MIMO系统中实用相位偏移的预编码设计**

*Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang*

主要分类: eess.SP

摘要简述: 本文研究了在毫米波MIMO系统中，利用可重构智能表面（RIS）增强传输性能的预编码设计，提出了一种基于深度神经网络（DNN）的快速码字选择方法，显著降低了计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 在毫米波MIMO系统中，直接通信路径可能被遮挡，传统穷举搜索（ES）方法计算复杂度高且耗时。因此，需要一种高效的方法来优化预编码设计，提升系统吞吐量。

研究方法: 采用基于深度神经网络（DNN）的方法替代传统的穷举搜索，利用排列离散傅里叶变换（DFT）向量设计码本，并结合实际或理想RIS系统的幅度响应，实现快速码字选择。

研究结果: 仿真结果表明，DNN方法在测试阶段即使终端用户与RIS的距离变化时，仍能保持接近最优的频谱效率，显著降低了计算复杂度。

研究结论: DNN方法在RIS辅助系统中具有显著潜力，能够高效优化预编码设计并提升系统性能，为未来研究提供了新方向。

中文摘要: 本文研究了在毫米波多输入多输出（MIMO）系统中，通过可重构智能表面（RIS）增强传输性能的预编码设计。由于直接通信路径可能被遮挡，传统穷举搜索（ES）方法在连续相位偏移下计算复杂度高且耗时。为降低复杂度，采用排列离散傅里叶变换（DFT）向量设计码本，并结合实际或理想RIS系统的幅度响应。然而，即使采用离散相位偏移的ES方法，仍存在显著计算负担。为此，本文开发了基于深度神经网络（DNN）的快速码字选择方法。仿真结果表明，在测试阶段，即使终端用户与RIS的距离变化，DNN仍能保持接近最优的频谱效率，凸显了DNN在RIS辅助系统中的潜力。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [148] [Legal Requirements Translation from Law](https://arxiv.org/abs/2507.02846)
**中文标题：从法律中翻译法律需求**

*Anmol Singhal,Travis Breaux*

主要分类: cs.SE

摘要简述: 本文提出了一种基于文本蕴含和上下文学习的方法，自动生成法律文本的规范表示，并将其编码为可执行的Python代码，以减少手动标注需求并提升对新法规的适用性。


<details>
  <summary>详细信息</summary>
研究动机: 软件系统需符合法律规范，但小型组织和初创企业缺乏法律专业知识，手动提取法律需求耗时且复杂。现有自动化方法未考虑元数据属性间的关联，且依赖手动标注或启发式机器学习，泛化能力不足。

研究方法: 采用文本蕴含和上下文学习技术，设计了一个领域特定的Python类结构作为元模型，自动生成法律文本的规范表示，捕捉结构和语义元数据及其关联。

研究结果: 在13个美国州数据泄露通知法律上测试，生成的表示通过89.4%的测试用例，精确率和召回率分别为82.2和88.7。

研究结论: 该方法减少了对手动标注数据的依赖，提升了法律文本自动处理的适用性和准确性。

中文摘要: 软件系统必须遵守法律规定，这对缺乏专门法律专业知识的小型组织和初创企业来说是一项资源密集型任务。从法规中提取元数据以获取软件的法律需求是确保合规的关键步骤，但由于法律文本的冗长和复杂性，这一任务十分繁琐。尽管已有研究尝试从法律文本中自动提取结构和语义元数据，但仍存在关键限制：未考虑这些元数据类型属性间的相互作用和关联，且依赖手动标注或启发式驱动的机器学习，对新文档的泛化能力不足。本文提出了一种基于文本蕴含和上下文学习的方法，自动生成法律文本的规范表示，可编码并执行为Python代码。我们的表示基于手动设计的Python类结构实例化，作为领域特定的元模型，捕捉结构和语义法律元数据及其关联。这一设计减少了对大规模手动标注数据集的需求，并提升了对未见法规的适用性。我们在13个美国州数据泄露通知法律上评估了该方法，结果表明生成的表示通过了约89.4%的测试用例，精确率和召回率分别为82.2和88.7。

</details>


### [149] [Requirements Elicitation Follow-Up Question Generation](https://arxiv.org/abs/2507.02858)
**中文标题：需求获取后续问题生成**

*Yuchen Shen,Anmol Singhal,Travis Breaux*

主要分类: cs.SE

摘要简述: 本文研究了利用GPT-4生成需求获取访谈中的后续问题，实验表明LLM生成的问题在清晰性、相关性和信息量上不亚于人工编写的问题，且在基于常见错误类型指导时表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 需求获取访谈中，访谈者面临领域不熟悉、认知负荷过重和信息过载等挑战，难以实时生成合适的问题。本文旨在探索利用大型语言模型（LLM）辅助访谈者生成高质量后续问题的潜力。

研究方法: 研究基于常见访谈错误类型框架，利用GPT-4生成后续问题，并通过两种对照实验评估LLM生成问题与人工编写问题的表现：一种是无指导生成，另一种是基于错误类型指导生成。

研究结果: 实验结果表明，LLM生成的问题在清晰性、相关性和信息量上不逊于人工编写的问题，且在基于错误类型指导时表现更优。

研究结论: LLM在实时辅助需求获取访谈中具有潜力，能够提升问题质量和访谈效率。

中文摘要: 访谈是需求获取中广泛使用的技术，用于收集利益相关者对软件系统的需求、偏好和期望。有效的访谈需要访谈者实时生成合适的问题，但面临领域不熟悉、认知负荷过重和信息过载等挑战。近年来，大型语言模型（LLM）在文本摘要和蕴含等自然语言处理任务中表现出色。为支持访谈者，本研究探讨了利用GPT-4在需求获取中生成后续问题的应用，并基于常见访谈错误类型框架进行实验。此外，我们还描述了基于受访者语音生成问题的方法。通过对照实验，我们评估了无指导下LLM生成问题与人工编写问题的表现，以及基于错误类型指导下LLM生成问题的表现。结果表明，两种实验中LLM生成的问题在清晰性、相关性和信息量上均不逊于人工编写的问题，且在基于错误类型指导时表现更优。这突显了LLM在实时提升需求获取访谈质量和效率方面的潜力。

</details>


### [150] [VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software](https://arxiv.org/abs/2507.02376)
**中文标题：VeFIA：一种高效的垂直联邦协作软件推理审计框架**

*Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang*

主要分类: cs.SE

摘要简述: 本文提出了一种高效的垂直联邦推理审计框架VeFIA，用于验证数据方推理软件的执行正确性，同时保护数据隐私且不增加系统延迟。


<details>
  <summary>详细信息</summary>
研究动机: 现有的垂直联邦学习（VFL）缺乏对数据方推理软件执行正确性的审计机制，因此需要设计一种方法在不泄露数据隐私和不增加延迟的情况下进行验证。

研究方法: VeFIA框架利用可信执行环境（TEE）和协调器的推理结果，任务方可以验证数据方的计算结果是否正确。通过随机采样验证，确保异常推理的检测效果。

研究结果: VeFIA在异常推理超过5.4%时，能以99.99%的概率检测到执行异常，且随机采样验证的阳性预测值、阴性预测值和真阳性率均达到100%。

研究结论: VeFIA是首个讨论VFL中推理软件执行正确性的研究，提供了一种高效且隐私保护的审计方法。

中文摘要: 垂直联邦学习（VFL）是一种用于跨机构协作的分布式AI软件部署机制，无需访问参与方的数据。然而，现有的VFL工作缺乏对数据方推理软件执行正确性的审计机制。为解决这一问题，我们设计了一种垂直联邦推理审计（VeFIA）框架。VeFIA帮助任务方在大规模推理过程中审计数据方的推理软件是否按预期执行，同时不泄露数据方的隐私或增加推理系统的额外延迟。VeFIA的核心在于任务方可以利用可信执行环境（TEE）和协调器的推理结果来验证数据方计算结果的正确性。VeFIA保证，只要异常推理超过5.4%，任务方就能以99.99%的概率检测到推理软件的执行异常，且不会引入任何额外的在线推理延迟。VeFIA的随机采样验证在检测异常推理时实现了100%的阳性预测值、阴性预测值和真阳性率。据我们所知，这是第一篇讨论VFL中推理软件执行正确性的论文。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [151] [Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes](https://arxiv.org/abs/2507.02331)
**中文标题：追踪模块化CMA-ES配置在问题景观中的交互作用**

*Ana Nikolikj,Mario Andrés Muñoz,Eva Tuba,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文利用算法足迹概念，研究了CMA-ES算法的六种模块化变体在24个BBOB基准问题上的表现，揭示了算法配置与问题特征之间的交互关系。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索算法配置与问题特征之间的相互作用，以解释为何同一算法的不同配置在不同问题上表现各异，并为算法配置选择提供指导。

研究方法: 方法包括计算六种模块化CMA-ES变体（modCMA）在5维和30维BBOB基准问题上的性能足迹，分析其行为模式与问题特征的关联。

研究结果: 结果显示，算法足迹能有效揭示不同配置的共性与差异，并识别影响性能的问题特征，为算法配置选择提供了依据。

研究结论: 结论表明，算法足迹方法有助于提升算法行为的可解释性，并为优化配置选择提供了实用工具。

中文摘要: 本文利用最近提出的算法足迹概念，研究了算法配置与问题特征之间的相互作用。通过计算六种模块化CMA-ES变体（modCMA）在BBOB套件的24个基准问题（5维和30维）上的性能足迹，揭示了不同配置表现差异的原因及影响性能的问题特征。分析发现，配置之间存在因共同问题属性而产生的行为模式，以及因不同问题特征导致的同一问题上的行为差异。结果表明，算法足迹方法能有效提升可解释性并指导配置选择。

</details>


### [152] [ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms](https://arxiv.org/abs/2507.02337)
**中文标题：ClustOpt：一种基于聚类的方法用于表示和可视化数值元启发式优化算法的搜索动态**

*Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov*

主要分类: cs.NE

摘要简述: 本文提出了一种基于聚类的可视化方法ClustOpt，用于分析和展示数值元启发式优化算法的搜索动态，并引入稳定性和相似性指标量化算法行为。


<details>
  <summary>详细信息</summary>
研究动机: 传统可视化方法（如收敛图、轨迹映射等）难以清晰展示高维或复杂解空间中的搜索动态，亟需一种新方法来更直观地理解和分析算法的搜索行为。

研究方法: 通过聚类算法探索的候选解，并跟踪聚类成员在迭代中的演变，同时提出稳定性和相似性指标量化算法行为。

研究结果: 应用于十种数值元启发式算法，揭示了其稳定性和比较行为，为算法搜索动态提供了更深入的理解。

研究结论: ClustOpt方法为分析优化算法的搜索动态提供了动态且可解释的视角，有助于算法开发和性能评估。

中文摘要: 理解数值元启发式优化算法的行为对其发展和应用至关重要。传统的可视化技术（如收敛图、轨迹映射和适应度景观分析）往往难以展示搜索过程的结构动态，尤其是在高维或复杂解空间中。为此，我们提出了一种新颖的表示和可视化方法，该方法通过聚类算法探索的候选解，并跟踪聚类成员在迭代中的演变，从而提供搜索过程的动态且可解释的视图。此外，我们引入了两种指标——算法稳定性和算法相似性，分别用于量化单个算法多次运行的搜索轨迹一致性以及不同算法之间的相似性。我们将此方法应用于十种数值元启发式算法，揭示了其稳定性和比较行为，从而为算法的搜索动态提供了更深入的理解。

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [153] [Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning](https://arxiv.org/abs/2507.01972)
**中文标题：Error**

*Hadi Keramati,Samaneh Jazayeri*

主要分类: q-fin.PM

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [154] [Early Signs of Steganographic Capabilities in Frontier LLMs](https://arxiv.org/abs/2507.02737)
**中文标题：前沿大语言模型中的隐写能力早期迹象**

*Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner*

主要分类: cs.CR

摘要简述: 前沿大语言模型（LLM）已展现出初步的隐写能力，能够在看似正常的输出中隐藏信息或进行编码推理，但目前尚无法完全逃避监控。


<details>
  <summary>详细信息</summary>
研究动机: 研究前沿LLM的隐写能力，以评估其潜在风险，尤其是如何通过隐写技术逃避监控。

研究方法: 评估LLM在两种隐写任务中的表现：传递编码信息和进行编码推理，测试其在标准条件和额外辅助条件下的能力。

研究结果: 当前模型在标准条件下无法隐藏短信息，但在额外辅助（如使用未监控的草稿纸和协调编码方案）下可以成功。此外，模型在简单状态跟踪问题中展现出初步的编码推理能力。

研究结论: 前沿LLM已具备初步隐写能力，但尚不足以绕过精心设计的监控，未来可能进一步发展。

中文摘要: 监控大语言模型（LLM）的输出对于减少滥用和错位风险至关重要。然而，LLM可能通过隐写技术逃避监控：在看似无害的生成中隐藏信息。本文评估了前沿LLM的隐写能力，以更好地理解其风险。我们关注两种隐写类型：传递编码信息和进行编码推理。研究发现，当前模型在标准条件下无法隐藏短信息而不被监控发现，但在额外辅助（如使用未监控的草稿纸和协调编码方案）下可以成功。此外，模型在简单状态跟踪问题中展现出初步的编码推理能力，包括使用自定义和预定义编码方案（如十六进制）的能力。尽管如此，它们很少能巧妙地将推理隐藏在覆盖任务中以欺骗监控。总体而言，结果表明当前LLM具备初步隐写能力。虽然这些能力目前可能不足以绕过精心设计的监控，但未来可能发生变化。

</details>


### [155] [MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation](https://arxiv.org/abs/2507.02057)
**中文标题：MGC：一种利用对齐LLMs组合盲区的恶意软件生成编译器框架**

*Lu Yan,Zhuo Zhang,Xiangzhe Xu,Shengwei An,Guangyu Shen,Zhou Xuan,Xuan Chen,Xiangyu Zhang*

主要分类: cs.CR

摘要简述: 本文提出了一种名为MGC的编译器框架，利用对齐大型语言模型（LLMs）的组合盲区生成恶意软件。通过将恶意操作分解为看似无害的子任务，MGC成功绕过现有防护机制，高效生成功能完整的恶意软件。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）降低了软件开发的门槛，但也为恶意软件开发提供了便利。尽管LLM提供商通过对齐机制阻止直接生成恶意代码，但这些机制仅评估单个提示，忽视了恶意操作可通过分解为无害子任务实现的漏洞。本文旨在利用这一漏洞，开发一种能够绕过对齐机制生成恶意软件的工具。

研究方法: MGC框架通过模块化分解和对齐规避生成技术，利用专门设计的恶意描述中间表示（MDIR）将高级恶意意图与看似无害的代码片段连接起来。这种方法能够系统性地生成功能完整的恶意软件。

研究结果: 实验表明，MGC在多个基准数据集上生成的恶意软件功能正确性显著优于越狱方法和地下服务（分别提升365.79%和78.07%）。案例研究还显示，MGC能够复现并增强16个真实恶意软件样本。

研究结论: 本文揭示了组合攻击对对齐AI系统的风险，为安全研究人员提供了重要见解。MGC的成功表明，现有对齐机制在应对分解式恶意操作时存在严重不足，亟需改进。

中文摘要: 大型语言模型（LLMs）降低了软件开发的门槛，但也为恶意软件开发提供了便利。尽管LLM提供商通过对齐机制阻止直接生成恶意代码，但这些机制仅评估单个提示，忽视了恶意操作可通过分解为无害子任务实现的漏洞。本文提出了一种名为MGC的编译器框架，利用这一漏洞，通过模块化分解和对齐规避生成技术，高效生成功能完整的恶意软件。实验表明，MGC在多个基准数据集上生成的恶意软件功能正确性显著优于越狱方法和地下服务（分别提升365.79%和78.07%）。案例研究还显示，MGC能够复现并增强16个真实恶意软件样本。这项工作为安全研究人员揭示了组合攻击对对齐AI系统的风险。演示内容可在https://sites.google.com/view/malware-generation-compiler查看。

</details>


### [156] [Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities](https://arxiv.org/abs/2507.02125)
**中文标题：人工智能能否解决区块链预言机问题？挑战与可能性的剖析**

*Giulio Caldarelli*

主要分类: cs.CR

摘要简述: 本文探讨了人工智能（AI）是否能解决区块链预言机问题，分析了AI在提升数据质量、来源选择和系统弹性方面的潜力，但指出AI无法完全消除对链下输入的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 区块链预言机问题限制了去中心化应用的开发，尽管已有多种策略尝试解决，但如何让区块链获取链外世界的信息仍是未解难题。本文旨在评估AI在解决这一问题中的作用。

研究方法: 通过结合学术文献和实践案例，研究了AI技术（如异常检测、语言事实提取、动态声誉建模和对抗性抵抗）如何优化预言机系统。

研究结果: 研究发现，AI虽能显著提升预言机系统的数据质量和可靠性，但仍需依赖不可验证的链下输入，无法完全消除信任假设。

研究结论: AI应被视为预言机设计中的补充层，用于推理和过滤，而非替代信任假设。

中文摘要: 区块链预言机问题指的是将可靠的外部数据注入去中心化系统的挑战，这仍然是开发无需信任应用的根本限制。尽管近年来出现了多种架构、密码学和经济策略以缓解此问题，但尚未有人完全解决区块链如何获取链外世界信息的基本问题。在这篇立场论文中，我们批判性地评估了人工智能（AI）在解决预言机问题中的作用。通过结合学术文献和实践案例，我们探讨了AI技术（如异常检测、语言事实提取、动态声誉建模和对抗性抵抗）如何优化预言机系统。我们发现，尽管AI为提高数据质量、来源选择和系统弹性提供了强大工具，但它无法消除对不可验证的链下输入的依赖。因此，本研究支持将AI视为更广泛预言机设计中的补充推理和过滤层，而非信任假设的替代品。

</details>


### [157] [EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer](https://arxiv.org/abs/2507.02206)
**中文标题：EIM-TRNG：通过RowHammer利用编码内存真随机数生成器混淆深度神经网络权重**

*Ranyang Zhou,Abeer Matar A. Almalky,Gamana Aragonda,Sabbir Ahmed,Filip Roth Trønnes-Christensen,Adnan Siraj Rakin,Shaahin Angizi*

主要分类: cs.CR

摘要简述: 本文提出了一种名为EIM-TRNG的新型硬件安全技术，利用DRAM的RowHammer效应生成真随机数，并应用于保护深度神经网络权重数据，确保模型的安全性和隐私性。


<details>
  <summary>详细信息</summary>
研究动机: 在深度神经网络（DNN）中，保护模型权重数据对确保AI系统的完整性、隐私性和知识产权至关重要。现有的软件伪随机数生成器缺乏硬件真随机数生成器（TRNG）的不可预测性和鲁棒性。因此，本文旨在利用DRAM的物理随机性设计一种新型TRNG，以增强硬件安全性。

研究方法: 本文提出了一种名为EIM-TRNG的编码内存真随机数生成器，通过精确控制的RowHammer操作，利用DRAM单元行为的物理随机性生成不可预测的比特翻转。这些比特翻转被用作可靠的熵源，并结合固定和不可预测的比特翻转对DNN权重数据进行加密。解密时使用基于概率翻转行为的密钥，确保数据机密性和模型真实性。

研究结果: 实验结果表明，基于DRAM的熵提取方法能够有效实现低成本、高鲁棒性的硬件安全，并为机器学习模型的硬件级保护提供了新方向。

研究结论: EIM-TRNG通过利用DRAM的RowHammer效应，成功设计了一种新型真随机数生成器，并将其应用于DNN权重数据的保护，为硬件安全领域提供了创新解决方案。

中文摘要: 真随机数生成器（TRNG）在硬件安全、密码系统和数据保护中扮演着基础性角色。在深度神经网络（DNN）的背景下，保护模型参数（尤其是权重）对确保AI系统的完整性、隐私性和知识产权至关重要。尽管基于软件的伪随机数生成器被广泛使用，但它们缺乏基于硬件的TRNG所提供的不可预测性和鲁棒性。本文首次提出了一种名为EIM-TRNG的新型编码内存真随机数生成器，利用DRAM单元行为（特别是RowHammer引发的干扰）中的固有物理随机性。我们展示了如何通过精确控制的RowHammer操作生成的不可预测比特翻转作为可靠的熵源。此外，我们通过结合固定和不可预测的比特翻转，将此TRNG框架应用于保护DNN权重数据。加密数据随后通过基于概率翻转行为的密钥解密，确保数据机密性和模型真实性。实验结果验证了基于DRAM的熵提取方法在低成本、高鲁棒性硬件安全中的有效性，并为机器学习模型的硬件级保护提供了有前景的方向。

</details>


### [158] [Evaluating Language Models For Threat Detection in IoT Security Logs](https://arxiv.org/abs/2507.02390)
**中文标题：评估语言模型在物联网安全日志中的威胁检测能力**

*Jorge J. Tejero-Fernández,Alfonso Sánchez-Macián*

主要分类: cs.CR

摘要简述: 本文提出了一种利用微调大语言模型（LLMs）进行物联网安全日志异常检测和缓解建议的流程，相比传统机器学习分类器，LLMs在多类攻击分类中表现更优，并能结合MITRE CAPEC提供检测和缓解建议。


<details>
  <summary>详细信息</summary>
研究动机: 日志分析在网络安全领域具有重要意义，能够为网络和系统威胁检测提供信息。本文旨在探索如何利用大语言模型提升物联网安全日志的异常检测和缓解建议能力。

研究方法: 研究采用微调的大语言模型（LLMs）进行异常检测和缓解建议，对比了三种开源LLMs在零样本、少样本提示和微调策略下的表现，并以传统机器学习分类器为基线。通过将检测到的威胁映射到MITRE CAPEC，并定义物联网特定的缓解动作，模型能够提供检测和缓解建议的联合指导。

研究结果: 实验结果表明，在多类攻击分类任务中，LLMs的表现优于传统基线模型，且能够有效结合MITRE CAPEC提供检测和缓解建议。

研究结论: 大语言模型在物联网安全日志的异常检测和缓解建议中具有显著优势，未来可进一步优化模型以提升实际应用效果。

中文摘要: 日志分析是网络安全领域的重要研究方向，能够为网络和系统威胁检测提供信息。本文提出了一种利用微调大语言模型（LLMs）进行物联网安全日志异常检测和缓解建议的流程。以传统机器学习分类器为基线，比较了三种开源LLMs在零样本、少样本提示和微调策略下的二分类和多分类异常检测表现。结果表明，LLMs在多类攻击分类中优于基线模型。通过将检测到的威胁映射到MITRE CAPEC，并定义物联网特定的缓解动作，微调后的模型能够提供检测和缓解建议的联合指导。

</details>


### [159] [CyberRAG: An agentic RAG cyber attack classification and reporting tool](https://arxiv.org/abs/2507.02424)
**中文标题：CyberRAG：一种基于代理的RAG网络攻击分类与报告工具**

*Francesco Blefari,Cristian Cosentino,Francesco Aurelio Pironti,Angelo Furfaro,Fabrizio Marozzo*

主要分类: cs.CR

摘要简述: CyberRAG是一种基于代理的RAG框架，用于实时分类、解释和结构化报告网络攻击，通过动态控制流和自适应推理显著减少误报并提升可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 大型企业的入侵检测和预防系统（IDS/IPS）每小时生成数十万条警报，导致安全分析师难以应对。传统机器学习检测器虽能减少警报量，但误报率高，而标准RAG管道常检索无关上下文且无法合理解释预测。为解决这些问题，本文提出CyberRAG。

研究方法: CyberRAG采用模块化、基于代理的RAG框架，核心LLM代理协调以下组件：(i) 针对不同攻击家族的微调分类器；(ii) 用于丰富和警报的工具适配器；(iii) 迭代检索与推理循环，持续查询领域知识库直至证据相关且自洽。

研究结果: CyberRAG在每类攻击中准确率超过94%，通过语义协调最终分类准确率达94.92%。生成的解释在BERTScore中得分为0.94，在GPT-4专家评估中得分为4.9/5。

研究结论: CyberRAG通过代理化和专业化设计，实现了高检测准确率与可信的自然语言解释，为半自主网络安全工作流提供了实用且可扩展的解决方案。

中文摘要: 大型企业的入侵检测和预防系统（IDS/IPS）每小时可生成数十万条警报，使安全分析师不堪重负。传统机器学习检测器虽能减少警报量，但误报率仍高，而标准单次检索增强生成（RAG）管道常检索无关上下文且无法合理解释预测。为此，我们提出CyberRAG，一种模块化、基于代理的RAG框架，提供实时分类、解释和结构化报告功能。其核心LLM代理协调：(i) 针对不同攻击家族的微调分类器；(ii) 用于丰富和警报的工具适配器；(iii) 迭代检索与推理循环，持续查询领域知识库直至证据相关且自洽。与传统RAG系统不同，CyberRAG采用代理化设计，支持动态控制流和自适应推理，自主优化威胁标签和自然语言解释，减少误报并提升可解释性。该框架完全可扩展，新增攻击类型仅需添加分类器而无需重新训练核心代理。CyberRAG评估结果显示，每类攻击准确率超过94%，通过语义协调最终分类准确率达94.92%。生成的解释在BERTScore中得分为0.94，在GPT-4专家评估中得分为4.9/5。结果表明，代理化、专业化RAG既能实现高检测准确率，又能生成可信的、适用于安全运营中心（SOC）的文本，为半自主网络安全工作流提供了实用且可扩展的路径。

</details>


### [160] [Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](https://arxiv.org/abs/2507.02735)
**中文标题：Meta SecAlign：一种抵御提示注入攻击的安全基础大语言模型**

*Sizhe Chen,Arman Zharmagambetov,David Wagner,Chuan Guo*

主要分类: cs.CR

摘要简述: Meta SecAlign是首个开源且具有内置模型级防御的大语言模型，旨在抵御提示注入攻击，并在安全性和实用性上达到商业级性能。


<details>
  <summary>详细信息</summary>
研究动机: 提示注入攻击对集成大语言模型的应用构成重大安全威胁。目前，模型级防御虽有效，但多为闭源商业模型。AI安全社区需要开源模型以促进攻击与防御的协同研究，推动科学进步。

研究方法: 开发Meta SecAlign，采用改进版SOTA SecAlign防御技术，提供完整的训练方案。模型在通用指令调优数据集上训练，具备对未见下游任务的安全防护能力。

研究结果: Meta-SecAlign-70B在9个实用性基准和7个安全性基准测试中表现优异，抗提示注入攻击能力达到SOTA水平，实用性媲美闭源商业模型。

研究结论: Meta SecAlign为开源社区提供了首个兼具安全性和实用性的模型级防御方案，推动了对抗提示注入攻击的研究进展。

中文摘要: 提示注入攻击对集成大语言模型的应用构成重大安全威胁。模型级防御已显示出强大效果，但目前多以闭源形式部署于商业级模型中。我们认为AI安全社区需要开源模型，通过开放研究推动攻击与防御的协同发展，以科学进步缓解提示注入攻击。为此，我们开发了Meta SecAlign，这是首个开源且开放权重的大语言模型，内置模型级防御，并达到商业级模型性能。我们提供了完整的训练方案细节，该方案采用了改进版SOTA SecAlign防御技术。在9个实用性基准和7个安全性基准测试中，Meta SecAlign尽管基于通用指令调优数据集训练，仍能在未见下游任务（包括工具调用和代理网络导航）中提供安全保障，同时保持通用指令跟随能力。我们的最佳模型——Meta-SecAlign-70B——在抗提示注入攻击方面达到SOTA鲁棒性，实用性媲美具有模型级防御的闭源商业大语言模型。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [161] [CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR](https://arxiv.org/abs/2507.02289)
**中文标题：CineMyoPS：从电影心脏磁共振图像中分割心肌病理**

*Wangbin Ding,Lei Li,Junyi Qiu,Bogen Lin,Mingjing Yang,Liqin Huang,Lianming Wu,Sihan Wang,Xiahai Zhuang*

主要分类: eess.IV

摘要简述: 本文提出了一种名为CineMyoPS的端到端深度神经网络，用于仅从电影心脏磁共振（Cine CMR）图像中分割心肌病理（如瘢痕和水肿）。该方法通过提取与心肌梗死相关的运动和解剖特征，并设计一致性损失和时间序列聚合策略，显著提高了分割准确性。


<details>
  <summary>详细信息</summary>
研究动机: 心肌梗死（MI）是全球主要死因之一。虽然多序列心脏磁共振（CMR）成像可以提供互补信息，但其获取过程耗时且可能因对比剂使用而受限。电影CMR（Cine CMR）是一种快速且无需对比剂的成像技术，能够可视化由急性MI引起的心肌运动和结构异常。因此，本文旨在开发一种仅基于Cine CMR图像的心肌病理分割方法。

研究方法: CineMyoPS是一种端到端深度神经网络，通过提取与MI相关的运动和解剖特征来分割心肌病理。考虑到这些特征的相互依赖性，设计了一种一致性损失（类似于协同训练策略）以促进联合学习。此外，提出了一种时间序列聚合策略，整合心脏周期内与MI相关的特征，从而提升分割准确性。

研究结果: 在多中心数据集上的实验结果表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面表现出色，验证了其有效性。

研究结论: CineMyoPS为仅基于Cine CMR图像的心肌病理分割提供了一种高效且准确的方法，具有重要的临床潜力。

中文摘要: 心肌梗死（MI）是全球主要死因之一。晚期钆增强（LGE）和T2加权心脏磁共振（CMR）成像可分别识别瘢痕和水肿区域，两者对MI的风险分层和预后评估至关重要。尽管结合多序列CMR的互补信息有用，但获取这些序列可能耗时且受限，例如因对比剂的使用。电影CMR（Cine CMR）是一种快速且无需对比剂的成像技术，可可视化由急性MI引起的心肌运动和结构异常。因此，我们提出了一种新的端到端深度神经网络CineMyoPS，仅从Cine CMR图像中分割心肌病理（如瘢痕和水肿）。具体而言，CineMyoPS提取与MI相关的运动和解剖特征。考虑到这些特征的相互依赖性，我们设计了一种一致性损失（类似于协同训练策略）以促进其联合学习。此外，我们提出了一种时间序列聚合策略，整合心脏周期内与MI相关的特征，从而提升心肌病理的分割准确性。在多中心数据集上的实验结果表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面表现出色。

</details>


### [162] [A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\left[^{18}\text{F}\right]$FDG PET imaging](https://arxiv.org/abs/2507.02367)
**中文标题：一种鲁棒且通用的深度学习模型用于预测小动物动态[$^{18}$F]FDG PET成像中的动脉输入函数**

*Christian Salomonsen,Luigi Tommaso Luppino,Fredrik Aspheim,Kristoffer Wickstrøm,Elisabeth Wetzer,Michael Kampffmeyer,Rodrigo Berzaghi,Rune Sundset,Robert Jenssen,Samuel Kuttner*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的非侵入性方法（FC-DLIF），用于从小动物动态PET成像中预测动脉输入函数，避免了传统血液采样的需求，并在时间偏移和扫描时长变化下表现出鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的小动物动态PET研究中，动脉输入函数的精确估计依赖于复杂的动脉插管采样，这不仅耗时且具有侵入性，限制了纵向研究的可行性。因此，需要一种非侵入性且可靠的方法来替代传统血液采样。

研究方法: FC-DLIF模型通过空间特征提取器从PET序列的体素时间帧中提取空间特征，随后通过时间特征提取器预测动脉输入函数。模型使用[$^{18}$F]FDG数据进行训练和验证，并在其他两种放射性示踪剂（[$^{18}$F]FDOPA和[$^{68}$Ga]PSMA）上评估其适用性。

研究结果: FC-DLIF模型能够可靠地预测动脉输入函数，且在时间偏移和扫描时长变化下表现稳定。然而，对于训练数据中未包含的其他放射性示踪剂，模型预测失败。

研究结论: FC-DLIF模型为小动物动态PET研究提供了一种非侵入性且可靠的动脉输入函数预测方法，适用于不同扫描时长和时间偏移，但需进一步扩展以涵盖更多放射性示踪剂。

中文摘要: 动态正电子发射断层扫描（PET）和动力学建模在小动物示踪剂开发研究中至关重要。精确的动力学建模需要准确的输入函数估计，传统上通过动脉血液采样实现。然而，小鼠等小动物的动脉插管过程复杂、耗时且具有侵入性，阻碍了纵向研究。本文提出了一种非侵入性、基于全卷积深度学习的方法（FC-DLIF），直接从PET成像预测输入函数，可能消除动态小动物PET中血液采样的需求。FC-DLIF模型包含一个作用于PET序列体素时间帧的空间特征提取器，提取空间特征，随后通过时间特征提取器预测动脉输入函数。该方法使用[$^{18}$F]FDG数据和交叉验证进行训练和评估，并在两种其他示踪剂（[$^{18}$F]FDOPA和[$^{68}$Ga]PSMA）上评估模型适用性。模型进一步在时间截断和偏移的数据上进行测试，以模拟更短或偏移的PET扫描。FC-DLIF模型在均方误差和相关性方面可靠地预测了动脉输入函数，且在截断和偏移样本中仍能预测。然而，对于训练数据中未包含的其他示踪剂，模型预测失败。这种基于深度学习的输入函数为动脉血液采样提供了一种非侵入性且可靠的替代方案，对时间偏移和不同扫描时长表现出鲁棒性和灵活性。

</details>


### [163] [3D Heart Reconstruction from Sparse Pose-agnostic 2D Echocardiographic Slices](https://arxiv.org/abs/2507.02411)
**中文标题：基于稀疏姿态无关2D超声心动图切片的3D心脏重建**

*Zhurong Chen,Jinhua Chen,Wei Zhuo,Wufeng Xue,Dong Ni*

主要分类: eess.IV

摘要简述: 本文提出了一种从稀疏且姿态无关的2D超声心动图切片重建3D心脏的创新框架，显著提升了左心室容积估计的准确性，并首次实现了从2D切片估计右心室容积。


<details>
  <summary>详细信息</summary>
研究动机: 超声心动图在心脏病临床实践中不可或缺，但传统的2D成像难以准确估计临床参数（如左心室容积），而3D超声成像又受限于低分辨率和繁琐的手动标注。因此，需要一种能够从临床常用的2D切片重建个性化3D心脏模型的方法。

研究方法: 设计了一种新颖的3D重建流程，通过交替优化2D切片的3D姿态估计和基于隐式神经网络的3D切片整合，逐步将先验的3D心脏形状转化为个性化模型。

研究结果: 在两个数据集上验证，使用六个平面时，重建的3D心脏显著提升了左心室容积估计（误差百分比：1.98% vs. 20.24%），并首次实现了从2D切片估计右心室容积（误差5.75%）。

研究结论: 该研究为心脏超声的个性化3D结构和功能分析提供了新方法，具有重要的临床应用潜力。

中文摘要: 超声心动图（echo）在心脏病临床实践中扮演着不可或缺的角色。然而，超声成像通常仅提供来自少数特定视角的二维（2D）横截面图像，这使得其难以解释且对临床参数（如左心室容积）的估计不准确。3D超声成像为3D量化提供了替代方案，但仍受限于低空间和时间分辨率以及高度依赖手动标注的缺点。

为解决这些问题，我们提出了一种创新框架，用于从临床常用的2D超声切片重建个性化3D心脏解剖结构。具体而言，设计了一种新颖的3D重建流程，通过交替优化这些2D切片的3D姿态估计和基于隐式神经网络的3D切片整合，逐步将先验的3D心脏形状转化为个性化3D心脏模型。

我们在两个数据集上验证了该方法。当使用六个平面时，重建的3D心脏显著提升了左心室容积估计（误差百分比：1.98% vs. 20.24%）。此外，整个重建框架还实现了一项重要突破，即能够从2D超声切片估计右心室容积（误差为5.75%）。本研究为心脏超声的个性化3D结构和功能分析提供了新途径，具有重要的临床应用潜力。

</details>


### [164] [MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection](https://arxiv.org/abs/2507.02668)
**中文标题：MEGANet-W：一种基于小波的边缘引导注意力框架用于弱边界息肉检测**

*Zhe Yee Tan*

主要分类: eess.IV

摘要简述: MEGANet-W是一种基于小波的边缘引导注意力框架，用于弱边界息肉检测，通过注入方向性Haar小波边缘图提升分割精度，无需额外参数。


<details>
  <summary>详细信息</summary>
研究动机: 结直肠息肉分割对癌症早期检测至关重要，但弱边界和低对比度限制了自动化准确性。现有方法易模糊边缘细节或依赖手工滤波器，性能不稳定。

研究方法: 提出MEGANet-W，包含两级Haar小波头提取多方向边缘，以及小波边缘引导注意力模块（WEGA），将小波线索与反向和输入分支融合。

研究结果: 在五个公开息肉数据集上，MEGANet-W表现优于现有方法，mIoU提升2.3%，mDice提升1.2%，且无需额外可学习参数。

研究结论: MEGANet-W通过小波驱动的边缘引导注意力显著提升了弱边界息肉的分割性能，为自动化检测提供了高效解决方案。

中文摘要: 结直肠息肉分割对结直肠癌早期检测至关重要，但弱边界和低对比度显著限制了自动化准确性。现有深度模型要么模糊边缘细节，要么依赖手工滤波器，在多变成像条件下表现不佳。我们提出MEGANet-W，一种基于Haar小波的边缘引导注意力网络，通过向每个解码阶段注入方向性、无参数的Haar小波边缘图来重新校准语义特征。我们的两大贡献是：（1）用于多方向边缘提取的两级Haar小波头；（2）小波边缘引导注意力（WEGA）模块，将小波线索与反向和输入分支融合。在五个公开息肉数据集上，MEGANet-W始终优于现有方法，mIoU提升高达2.3%，mDice提升1.2%，且未引入额外可学习参数。

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [165] [Toward a Robust and Generalizable Metamaterial Foundation Model](https://arxiv.org/abs/2507.02436)
**中文标题：迈向稳健且通用的元材料基础模型**

*Namjung Kim,Dongseok Lee,Jongbin Yu,Sung Woong Cho,Dosung Lee,Yesol Park,Youngjoon Hong*

主要分类: physics.optics

摘要简述: 本文提出了一种基于贝叶斯变换器的元材料基础模型（MetaFO），能够实现零样本预测和非线性逆向设计，显著扩展了AI驱动的元材料发现空间。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI驱动的元材料设计方法存在任务特定性重训练、分布外泛化能力差以及需要独立模型进行正向和逆向设计的问题，限制了其应用潜力。

研究方法: MetaFO采用贝叶斯变换器架构，学习元材料的底层力学特性，实现跨多样性和未见材料属性组合的零样本预测，并支持非线性逆向设计。

研究结果: MetaFO在分布外条件下表现出色，能够揭示复杂的结构-属性关系，显著扩展了设计空间，为AI驱动的元材料发现提供了可扩展且通用的框架。

研究结论: MetaFO标志着AI驱动的元材料发现范式的转变，为下一代创新铺平了道路。

中文摘要: 材料功能的进步推动了多个领域的创新，其中元材料（由结构而非成分定义）处于领先地位。尽管人工智能（AI）驱动的设计策略有所发展，但其影响受到任务特定性重训练、分布外泛化能力差以及需要独立模型进行正向和逆向设计的限制。为解决这些问题，我们提出了元材料基础模型（MetaFO），这是一种受大型语言模型启发的基于贝叶斯变换器的基础模型。MetaFO学习元材料的底层力学特性，能够对多样且未见过的材料属性与结构响应组合进行概率性零样本预测。它还在分布外条件下表现出色，支持非线性逆向设计。通过将元材料视为映射材料属性到结构响应的算子，MetaFO揭示了复杂的结构-属性关系，并显著扩展了设计空间。这一可扩展且通用的框架标志着AI驱动的元材料发现的范式转变，为下一代创新铺平了道路。

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [166] [A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention](https://arxiv.org/abs/2507.00884)
**中文标题：通过线性张量化四边形注意力实现可扩展且量子精确的生物分子力场基础模型**

*Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou*

主要分类: physics.chem-ph

摘要简述: 本文提出了一种名为LiTEN的新型等变神经网络，通过线性张量化的四边形注意力（TQA）高效建模三体和四体相互作用，构建了LiTEN-FF力场模型，在多个基准测试中表现优异，为生物分子模拟提供了高效且量子精确的解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 现有生物分子模拟方法存在显著局限性：经典力场效率高但精度不足，量子力学方法精度高但计算成本大，而基于AI的力场在平衡多体建模复杂性、精度和速度方面表现不佳。本文旨在解决这些问题。

研究方法: 提出LiTEN神经网络，采用线性张量化的四边形注意力（TQA）高效建模三体和四体相互作用，避免高成本球谐函数计算。基于LiTEN构建LiTEN-FF力场模型，预训练于nablaDFT数据集并微调于SPICE数据集。

研究结果: LiTEN在rMD17、MD22和Chignolin等基准测试中表现最优，超越MACE、NequIP和EquiFormer等模型。LiTEN-FF支持多种下游任务，如构象搜索、几何优化和自由能面构建，且推理速度比MACE-OFF快10倍。

研究结论: LiTEN-FF为生物分子模拟提供了高效且量子精确的框架，推动了复杂生物分子建模的发展，为药物发现等应用提供了多功能基础。

中文摘要: 精确的原子级生物分子模拟对疾病机制理解、药物发现和生物材料设计至关重要，但现有模拟方法存在显著局限性。经典力场效率高但缺乏对过渡态和精细构象细节的准确性，而这些在许多化学和生物过程中至关重要。量子力学（QM）方法精度高，但对大规模或长时间模拟计算不可行。基于AI的力场（AIFFs）旨在实现QM级精度与效率，但在平衡多体建模复杂性、精度和速度方面表现不佳，常受限于训练数据不足和泛化性验证不足。为克服这些挑战，我们提出LiTEN，一种新型等变神经网络，采用线性张量化的四边形注意力（TQA）。TQA通过向量操作重新参数化高阶张量特征，高效建模三体和四体相互作用，避免高成本球谐函数计算。基于LiTEN，LiTEN-FF是一种稳健的AIFF基础模型，预训练于广泛的nablaDFT数据集以实现广泛的化学泛化，并微调于SPICE以实现精确的溶剂化系统模拟。LiTEN在rMD17、MD22和Chignolin的大多数评估子集中表现最优，超越MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持迄今为止最全面的下游生物分子建模任务，包括QM级构象搜索、几何优化和自由能面构建，同时对大型生物分子（约1000个原子）的推理速度比MACE-OFF快10倍。总之，我们提出了一种物理基础强、高效的多功能框架，推动了复杂生物分子建模的进步，为药物发现及相关应用提供了多功能基础。

</details>


### [167] [Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation](https://arxiv.org/abs/2507.02752)
**中文标题：可合成设计：一种基于逆合成分析的分子类似物生成框架**

*Shuan Chen,Gunwook Nam,Yousung Jung*

主要分类: physics.chem-ph

摘要简述: SynTwins是一种基于逆合成分析的分子类似物生成框架，通过模拟化学家策略，确保生成的分子具有合成可行性，同时保持与目标分子的高结构相似性。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI生成的分子虽然具有理想性质，但合成可行性低，成为计算药物和材料发现的关键瓶颈。SynTwins旨在解决这一问题，通过逆合成分析生成可合成的分子类似物。

研究方法: SynTwins采用三步法：逆合成分析、相似构建块搜索和虚拟合成，模拟化学家策略生成可合成的分子类似物。

研究结果: SynTwins在生成可合成类似物方面优于现有机器学习模型，同时保持与目标分子的高结构相似性，并能与现有分子优化框架结合，生成性质优异且可合成的分子。

研究结论: SynTwins有效弥合了计算设计与实验合成之间的鸿沟，为加速发现具有理想性质的可合成分子提供了实用解决方案。

中文摘要: AI生成的分子与理想性质之间的合成可行性差距是计算药物和材料发现的关键瓶颈。尽管生成式AI加速了候选分子的提出，但许多结构难以或无法通过现有化学反应合成。本文介绍了SynTwins，一种新型逆合成引导的分子类似物设计框架，通过模拟化学家策略的三步过程（逆合成、相似构建块搜索和虚拟合成）设计可合成的分子类似物。在比较评估中，SynTwins在生成可合成类似物方面表现优于现有机器学习模型，同时保持与目标分子的高结构相似性。此外，与现有分子优化框架结合时，我们的混合方法生成的可合成分子性质与无约束分子生成器相当，但确保了合成可行性。我们在多样化分子数据集上的全面基准测试表明，SynTwins有效弥合了计算设计与实验合成之间的鸿沟，为加速发现具有理想性质的可合成分子提供了实用解决方案。

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [168] [FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports](https://arxiv.org/abs/2507.01991)
**中文标题：FinAI-BERT：一种基于Transformer的模型用于金融报告中句子级别的AI披露检测**

*Muhammad Bilal Zafar*

主要分类: q-fin.CP

摘要简述: 本文提出FinAI-BERT，一种基于Transformer的模型，用于在金融报告中检测句子级别的AI披露内容。模型在手工标注的平衡数据集上表现优异，准确率达99.37%，显著优于传统基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在金融服务中的广泛应用，市场需要系统化工具来检测公司文件中的AI相关披露。现有方法在粒度、可解释性和鲁棒性上存在不足，因此需要更精细的解决方案。

研究方法: 研究开发了FinAI-BERT，一种基于Transformer的领域适应语言模型，用于句子级别的AI内容分类。模型在669份美国银行年报的1,586个句子上进行了微调，并通过SHAP分析确保可解释性。

研究结果: FinAI-BERT在分类任务中表现卓越，准确率达99.37%，F1分数为0.993，优于逻辑回归、朴素贝叶斯等传统方法。模型在句子长度、对抗输入和时间样本上均表现出稳定性。

研究结论: FinAI-BERT为金融NLP提供了细粒度、主题特定的分类方法，并为分析师、监管机构和学者提供了可扩展且透明的解决方案，有助于监测AI在金融机构中的扩散和框架。

中文摘要: 人工智能（AI）在金融服务中的广泛应用催生了对其在公司文件中系统性检测工具的需求。现有方法多依赖关键词扩展或文档级分类，但在粒度、可解释性和鲁棒性上表现不足。本研究提出了FinAI-BERT，一种基于Transformer的领域适应语言模型，用于在金融文本中对句子级别的AI相关内容进行分类。模型在手工标注的平衡数据集（来自669份美国银行年报的1,586个句子，2015至2023年）上进行了微调。FinAI-BERT的分类性能接近完美（准确率99.37%，F1分数0.993），优于逻辑回归、朴素贝叶斯、随机森林和XGBoost等传统基线方法。通过基于SHAP的标记归因确保了可解释性，而偏差分析和鲁棒性检查证实了模型在句子长度、对抗输入和时间样本上的稳定性。理论上，本研究通过使用Transformer架构实现细粒度、主题特定的分类，推动了金融NLP的发展。实践上，它为分析师、监管机构和学者提供了一种可扩展且透明的解决方案，用于监测AI在金融机构中的扩散和框架。

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [169] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
**中文标题：解决湍流磁流体动力学：一种混合算子-扩散框架**

*Semih Kacmaz,E. A. Huerta,Roland Haas*

主要分类: physics.flu-dyn

摘要简述: 提出了一种混合机器学习框架，结合物理信息神经算子和基于分数的生成扩散模型，用于模拟二维不可压缩电阻磁流体动力学湍流的全时空演化，并在高雷诺数下实现高精度模拟。


<details>
  <summary>详细信息</summary>
研究动机: 传统确定性替代模型在高雷诺数湍流模拟中难以准确捕捉高频动态和非高斯统计特性，因此需要一种能够结合物理约束与随机校正的新方法。

研究方法: 结合物理信息神经算子（PINO）预测低频相干动态，并通过条件扩散模型随机校正高频残差，实现对湍流的全谱能量分布和非高斯统计的精确建模。

研究结果: 在雷诺数为1000和3000时，模型能够准确重建速度和磁场的全谱能量分布，捕捉非高斯统计和间歇结构；在极高雷诺数（10000）下，首次实现了对磁场高波数演化的恢复。

研究结论: 该混合框架在高雷诺数湍流模拟中表现出色，填补了确定性替代模型的空白，为复杂湍流系统的研究提供了新工具。

中文摘要: 我们提出了一种混合机器学习框架，结合物理信息神经算子（PINO）与基于分数的生成扩散模型，用于模拟二维不可压缩电阻磁流体动力学（MHD）湍流在广泛雷诺数（Re）范围内的全时空演化。该框架利用PINO的方程约束泛化能力预测低频相干动态，同时通过条件扩散模型随机校正高频残差，从而实现对完全发展湍流的精确建模。在训练集包含Re∈{100, 250, 500, 750, 1000, 3000, 10000}的高保真模拟数据后，该方法在传统确定性替代模型难以覆盖的范围内达到了最先进的精度。在Re=1000和3000时，模型能够准确重建速度和磁场的全谱能量分布，捕捉非高斯统计、间歇结构及跨场相关性。在极高湍流水平（Re=10000）下，该模型首次实现了对磁场高波数演化的恢复，保留了大尺度形态并提供了具有统计意义的预测。

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [170] [Solving the Hubbard model with Neural Quantum States](https://arxiv.org/abs/2507.02644)
**中文标题：利用神经量子态求解Hubbard模型**

*Yuntian Gu,Wenrui Li,Heng Lin,Bo Zhan,Ruichen Li,Yifei Huang,Di He,Yantao Wu,Tao Xiang,Mingpu Qin,Liwei Wang,Dingshun Lv*

主要分类: cond-mat.str-el

摘要简述: 本文利用基于Transformer架构的神经量子态（NQS）和高效优化算法，在掺杂二维Hubbard模型中取得了最先进的结果，揭示了NQS在捕捉强关联系统中多尺度关联和纠缠的能力，并验证了半填充条纹态的存在。


<details>
  <summary>详细信息</summary>
研究动机: 研究神经量子态（NQS）在解决量子多体系统问题中的潜力，特别是针对高Tc超导性的最小模型——二维Hubbard模型。

研究方法: 采用基于Transformer架构的神经量子态（NQS）和高效优化算法，研究掺杂二维Hubbard模型，分析不同注意力头对多尺度关联的编码能力。

研究结果: 在掺杂二维Hubbard模型中取得了最先进的结果，发现NQS能够捕捉长程关联和纠缠，并验证了半填充条纹态的存在，与铜酸盐实验观察一致。

研究结论: 神经量子态（NQS）是解决强关联多费米子系统的有力工具，其多尺度关联编码能力为未来研究提供了新方向。

中文摘要: 神经量子态（NQS）的快速发展使其成为研究量子多体系统的有前景框架。本研究通过利用前沿的基于Transformer的架构和开发高效优化算法，在掺杂二维（2D）Hubbard模型中取得了最先进的结果，该模型被认为是高Tc超导性的最小模型。有趣的是，我们发现NQS中的不同注意力头可以直接编码不同尺度的关联，使其能够捕捉强关联系统中的长程关联和纠缠。通过这些进展，我们验证了二维Hubbard模型中半填充条纹态的存在，与铜酸盐的实验观察一致。我们的工作确立了NQS作为解决挑战性多费米子系统的强大工具。

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [171] [DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification](https://arxiv.org/abs/2507.01971)
**中文标题：DeepSupp：基于注意力驱动的相关性模式分析动态时间序列支撑与阻力水平识别**

*Boris Kriuk,Logic Ng,Zarif Al Hossain*

主要分类: q-fin.ST

摘要简述: 本文提出了一种名为DeepSupp的新型深度学习方法，利用多头注意力机制分析动态时间序列中的支撑与阻力水平，显著提升了金融技术分析的准确性和适应性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的支撑与阻力（SR）水平识别方法难以适应现代复杂多变的市场环境，而现有机器学习研究多聚焦于价格预测而非结构水平识别。本文旨在填补这一空白，提供一种更可靠且可扩展的SR水平检测方案。

研究方法: DeepSupp结合了多头注意力机制和动态相关性矩阵，通过特征工程捕捉市场微观结构关系，并采用基于注意力的自编码器进行鲁棒表示学习。最终通过无监督聚类（DBSCAN）提取关键支撑水平。

研究结果: 在标普500股票数据上的全面评估表明，DeepSupp在六项金融指标上优于六种基线方法，包括支撑水平准确性和市场状态敏感性，展现了卓越的性能。

研究结论: DeepSupp为现代金融分析提供了一种可扩展且可靠的SR水平检测方法，突显了注意力架构在揭示市场细微模式和优化技术交易策略中的潜力。

中文摘要: 支撑与阻力（SR）水平是技术分析的核心，指导交易者的入场、出场和风险管理。尽管广泛应用，传统SR识别方法往往难以适应现代复杂多变的市场。近期研究尝试用机器学习技术解决这些问题，但多数聚焦于价格预测而非结构水平识别。本文提出DeepSupp，一种利用多头注意力机制分析空间相关性和市场微观结构关系的新型深度学习方法，用于检测金融支撑水平。DeepSupp整合了高级特征工程，构建动态相关性矩阵以捕捉市场关系的变化，并采用基于注意力的自编码器进行鲁棒表示学习。最终通过无监督聚类（DBSCAN）提取关键支撑水平。在标普500股票数据上的全面评估表明，DeepSupp在六项金融指标上优于六种基线方法，包括支撑水平准确性和市场状态敏感性。在不同市场条件下均表现一致，DeepSupp填补了SR水平检测的关键空白，为现代金融分析提供了可扩展且可靠的解决方案。我们的方法突显了注意力架构在揭示市场细微模式和优化技术交易策略中的潜力。

</details>


### [172] [Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach](https://arxiv.org/abs/2507.01979)
**中文标题：基于LSTNet的多尺度深度学习方法预测劳动力市场**

*Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi*

主要分类: q-fin.ST

摘要简述: 本文提出了一种基于深度学习的多尺度方法LSTNet，用于预测短期就业变化和评估长期行业健康状况。该方法利用多变量时间序列数据，表现优于基线模型，并展示了行业就业健康指数与实际就业波动的强相关性。


<details>
  <summary>详细信息</summary>
研究动机: 劳动力市场的短期预测和长期健康评估对政策制定者和企业至关重要。现有方法在稳定行业表现不佳，因此需要一种更准确且可解释的模型。

研究方法: 采用长短期时间序列网络（LSTNet）处理多变量时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和行业就业健康指数（IEHI）。

研究结果: 模型在多数行业中优于基线模型，尤其在稳定行业表现突出。IEHI排名与实际就业波动高度一致。

研究结论: LSTNet在劳动力市场预测中表现出色，未来可进一步提升其可解释性和泛化能力。

中文摘要: 本文提出了一种深度学习方法，用于预测短期就业变化和评估长期行业健康状况，数据来自美国劳工统计局。我们的系统利用长短期时间序列网络（LSTNet）处理多变量时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和可解释的行业就业健康指数（IEHI）。该方法在多数行业中优于基线模型，尤其在稳定行业表现突出，并展示了IEHI排名与实际就业波动的强相关性。我们讨论了误差模式、行业特定表现以及未来提升可解释性和泛化能力的方向。

</details>


### [173] [NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction](https://arxiv.org/abs/2507.02018)
**中文标题：NGAT：一种用于长期股票预测的节点级图注意力网络**

*Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong*

主要分类: q-fin.ST

摘要简述: 本文提出了一种名为NGAT的节点级图注意力网络，用于解决长期股票预测中的三个关键挑战：下游任务设计限制、现有图模型复杂性和泛化能力不足，以及公司关系图结构比较方法的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前金融应用中，图表示学习方法虽广泛用于增强公司表示，但面临三个主要问题：下游任务设计掩盖了关系信息的优势、现有股票预测图模型过于复杂且泛化能力差，以及公司关系图结构缺乏有效比较方法。

研究方法: 作者提出了一种长期股票预测任务，并开发了专门为公司关系图设计的节点级图注意力网络（NGAT）。同时，实验验证了现有基于下游任务性能的图比较方法的局限性。

研究结果: 在两个数据集上的实验结果一致证明了所提任务和模型的有效性。

研究结论: NGAT模型在长期股票预测中表现出色，解决了现有方法的不足，并通过公开项目鼓励复现和未来研究。

中文摘要: 图表示学习方法在金融应用中广泛用于通过利用公司间关系增强公司表示。然而，当前方法面临三个关键挑战：（1）关系信息的优势被下游任务设计的局限性掩盖；（2）专门为股票预测设计的现有图模型通常过于复杂且泛化能力差；（3）基于经验构建的公司关系图缺乏对不同图结构的有效比较。为解决这些局限性，我们提出了一种长期股票预测任务，并开发了专门为公司关系图设计的节点级图注意力网络（NGAT）。此外，我们通过实验证明了现有基于下游任务性能的图比较方法的局限性。在两个数据集上的实验结果一致证明了所提任务和模型的有效性。项目已在GitHub上公开，以鼓励复现和未来研究。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [174] [HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3](https://arxiv.org/abs/2507.02345)
**中文标题：HelixDesign-Antibody：基于HelixFold3的可扩展生产级抗体设计平台**

*Jie Gao,Jing Hu,Shanzhuo Zhang,Kunrui Zhu,Sheng Qian,Yueyang Huang,Xiaonan Zhang,Xiaomin Fang*

主要分类: q-bio.BM

摘要简述: HelixDesign-Antibody是一个基于HelixFold3的高通量抗体设计平台，用于大规模生成和评估抗体候选序列，显著提升抗体工程效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统抗体发现方法耗时且资源密集，亟需一种高效、可扩展的解决方案来加速抗体工程。

研究方法: 利用高精度结构预测模型HelixFold3，结合高性能计算支持，构建了一个生产级高通量平台，用于生成和筛选抗体候选序列。

研究结果: 验证表明，该平台能生成多样且高质量的抗体，并通过扩大序列空间探索提高最优结合体的发现概率。

研究结论: HelixDesign-Antibody为大规模抗体设计提供了无缝、易用的解决方案，显著提升了抗体工程的效率和可扩展性。

中文摘要: 抗体工程对于开发治疗药物和推动生物医学研究至关重要。传统的发现方法通常依赖于耗时且资源密集的实验筛选。为了优化和简化这一过程，我们推出了一个基于HelixFold3的生产级高通量平台——HelixDesign-Antibody。该平台利用高精度结构预测模型HelixFold3，支持大规模生成抗体候选序列并评估其与抗原的相互作用。集成的高性能计算（HPC）支持实现了高通量筛选，解决了工具链碎片化和高计算需求等挑战。在多个抗原上的验证表明，该平台能够生成多样且高质量的抗体，并证实了探索更大序列空间可提高发现最优结合体的概率。该平台为大规模抗体设计提供了无缝、易用的解决方案，可通过PaddleHelix平台的抗体设计页面访问。

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [175] [Integrating Large Language Models in Financial Investments and Market Analysis: A Survey](https://arxiv.org/abs/2507.01990)
**中文标题：大型语言模型在金融投资与市场分析中的整合应用：一项综述**

*Sedigheh Mahdavi,Jiating,Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh*

主要分类: q-fin.GN

摘要简述: 本文综述了大型语言模型（LLMs）在金融投资和市场分析中的应用，总结了其在股票选择、风险评估、情感分析、交易和金融预测中的能力、挑战及未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 传统金融投资策略主要依赖定量模型和基本面分析，而大型语言模型（LLMs）能够处理海量结构化和非结构化数据，提取关键信息并实时辅助决策。本文旨在系统梳理LLMs在金融领域的最新研究，为未来研究提供方向。

研究方法: 本文通过文献综述方法，将LLMs在金融领域的研究分为四大框架：基于LLM的框架与流程、混合集成方法、微调与适应方法以及基于代理的架构，并对股票选择、风险评估、情感分析、交易和金融预测等应用进行了系统分析。

研究结果: 研究发现，LLMs在金融领域展现出强大的数据处理和实时决策能力，但也面临数据隐私、模型可解释性等挑战。未来研究方向包括优化模型性能和扩展应用场景。

研究结论: LLMs为金融投资和市场分析带来了新的机遇，但仍需解决技术和伦理问题。未来的研究应关注模型优化和多领域融合。

中文摘要: 大型语言模型（LLMs）已被应用于金融决策中，提升了投资策略的分析能力。传统投资策略通常依赖于定量模型、基本面分析和技术指标。然而，LLMs能够处理和分析大量结构化和非结构化数据，提取有意义的见解，并实时增强决策能力。本综述系统梳理了金融领域内LLMs的最新研究，将研究贡献分为四大框架：基于LLM的框架与流程、混合集成方法、微调与适应方法以及基于代理的架构。本研究对LLMs在股票选择、风险评估、情感分析、交易和金融预测中的应用进行了系统回顾。通过综述现有文献，本研究突出了LLMs在金融市场中的能力、挑战和潜在发展方向。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [176] [Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener](https://arxiv.org/abs/2507.02005)
**中文标题：通过特征工程和自动化可解释机器学习发现焊接横向加劲肋的疲劳强度模型**

*Michael A. Kraus,Helen Bartsch*

主要分类: cs.CE

摘要简述: 本研究结合自动化机器学习（AutoML）与可解释人工智能（XAI），通过特征工程和算法特征创建，预测焊接横向加劲肋的疲劳强度，实现了高精度和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过结合专家驱动的特征工程和自动化特征选择，提升焊接钢结构中疲劳强度预测的准确性和可解释性，为工程设计和评估提供AI辅助支持。

研究方法: 基于疲劳测试数据库，使用AutoML训练梯度提升、随机森林和神经网络模型，比较了领域知识特征、算法生成特征及其组合的效果，并采用XAI方法（如SHAP和特征重要性）分析关键预测因子。

研究结果: 领域知识特征模型（M2）表现最佳，测试RMSE≈30.6 MPa，R²≈0.780%；在工程相关范围内（0-150 MPa），RMSE≈13.4 MPa，R²≈0.527%。XAI揭示了应力比、应力范围、屈服强度及焊后处理为主要预测因子。

研究结论: 结合AutoML与XAI的框架能够生成准确、可解释且稳健的疲劳强度模型，为焊接钢结构的设计和评估提供了新方法，未来将探索概率疲劳寿命建模及数字孪生环境集成。

中文摘要: 本研究提出了一种结合自动化机器学习（AutoML）与可解释人工智能（XAI）的统一方法，用于预测焊接横向加劲肋细节的疲劳强度。通过集成专家驱动的特征工程与算法特征创建，提升了模型的准确性和可解释性。基于大量疲劳测试数据库，使用AutoML训练了梯度提升、随机森林和神经网络模型，并比较了领域知识特征、算法生成特征及其组合的效果。集成方法（如CatBoost、LightGBM）表现最佳，领域知识特征模型（M2）在测试中实现了最佳平衡：RMSE≈30.6 MPa，R²≈0.780%；在工程相关范围内（0-150 MPa），RMSE≈13.4 MPa，R²≈0.527%。XAI方法（SHAP和特征重要性）识别出应力比、应力范围、屈服强度及焊后处理为主要预测因子，次要几何因素（如板宽、喉厚、加劲肋高度）也对疲劳寿命有显著影响。该框架表明，结合AutoML与XAI能够生成准确、可解释且稳健的疲劳强度模型，为焊接钢结构的设计和评估提供了新方法，未来将探索概率疲劳寿命建模及数字孪生环境集成。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [177] [Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation](https://arxiv.org/abs/2507.02306)
**中文标题：合成启发式评估：AI与人工可用性评估的比较**

*Ruican Zhong,David W. McDonald,Gary Hsieh*

主要分类: cs.HC

摘要简述: 本研究提出了一种基于多模态大语言模型（LLM）的合成启发式评估方法，用于分析图像并提供设计反馈。实验表明，该方法在识别可用性问题上的表现优于人类评估者，尤其在布局问题上表现突出，但在识别UI组件和跨屏幕违规方面存在不足。


<details>
  <summary>详细信息</summary>
研究动机: 传统的可用性评估成本高，需要专家时间和用户补偿。本研究旨在探索利用多模态LLM进行合成启发式评估的可行性，以降低评估成本并提高效率。

研究方法: 研究开发了一种合成启发式评估方法，利用多模态LLM分析图像并提供设计反馈。通过比较该方法与经验丰富的用户体验（UX）从业者在两个应用上的评估结果，验证其性能。

研究结果: 合成评估在两个应用中分别识别了73%和77%的可用性问题，优于5名人类评估者（57%和63%）。合成评估在布局问题上表现突出，但在识别UI组件和跨屏幕违规方面表现较差。

研究结论: 合成启发式评估在可用性问题上表现优于人类评估者，尤其在布局问题上具有优势，但在某些方面仍需改进。研究为合成启发式评估的设计提供了参考。

中文摘要: 可用性评估在以人为本的设计中至关重要，但成本高昂，需要专家时间和用户补偿。本研究开发了一种基于多模态大语言模型（LLM）的合成启发式评估方法，利用其分析图像并提供设计反馈的能力。通过将合成评估与经验丰富的用户体验从业者在两个应用上的评估结果进行比较，我们发现合成评估分别识别了73%和77%的可用性问题，超过了5名人类评估者的表现（57%和63%）。与人类评估者相比，合成评估在任务间表现一致，且在检测布局问题上表现突出，显示了合成评估在注意力和感知方面的潜在优势。然而，合成评估在识别某些UI组件和设计惯例以及跨屏幕违规方面存在困难。此外，对合成评估的长期和多次测试显示其性能稳定。总体而言，本研究揭示了人类与LLM驱动评估之间的性能差异，为合成启发式评估的设计提供了参考。

</details>


### [178] [Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue](https://arxiv.org/abs/2507.02537)
**中文标题：你在听我说话吗？微调聊天机器人以实现同理心对话**

*Paulo Ricardo Knob,Leonardo Scholler,Juliano Rigatti,Soraia Raupp Musse*

主要分类: cs.HC

摘要简述: 本研究探讨如何通过微调大型语言模型（LLMs）生成更具同理心的对话，结合自动化和人工评估方法，揭示情感建模在对话中的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 随着对话代理在医疗、教育和客服等领域的广泛应用，情感智能（尤其是同理心倾听）的需求日益凸显。本研究旨在探索LLMs在生成情感丰富对话中的表现，并评估其同理心与连贯性。

研究方法: 研究从专家手工制作的小型数据集出发，利用ChatGPT和Gemini扩展对话，并通过VADER情感分析和专家评估分析对话的情感进展。

研究结果: 生成的对话在情感结构上符合预期，但人工评估发现其在同理心和连贯性上存在差异，表明情感建模需结合结构对齐与质性深度。

研究结论: 情感对话建模不仅需要结构上的情感表达对齐，还需质性深度，强调开发情感智能代理时结合自动化与人工方法的重要性。

中文摘要: 自ELIZA以来，对话代理已取得显著进展，并在医疗、教育和客服等领域发挥重要作用。随着这些代理日益融入人类日常互动，情感智能（尤其是同理心倾听）的需求变得愈发关键。本研究探讨了大型语言模型（LLMs）在生成情感丰富互动时的表现。我们从专家手工制作的小型数据集出发，利用ChatGPT和Gemini扩展对话，并通过VADER情感分析和专家评估分析对话的情感进展。尽管生成的对话在情感结构上常符合预期，但人工评估揭示了其在同理心和连贯性上的重要差异。这些发现表明，对话中的情感建模不仅需要表达情感的结构对齐，还需质性深度，强调了在开发情感智能代理时结合自动化与人工方法的重要性。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [179] [DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment](https://arxiv.org/abs/2507.02768)
**中文标题：DeSTA2.5-Audio：迈向通用大型音频语言模型的自生成跨模态对齐**

*Ke-Han Lu,Zhehuai Chen,Szu-Wei Fu,Chao-Han Huck Yang,Sung-Feng Huang,Chih-Kai Yang,Chee-En Yu,Chun-Wei Chen,Wei-Chih Chen,Chien-yu Huang,Yi-Cheng Lin,Yu-Xiang Lin,Chi-An Fu,Chun-Yi Kuan,Wenze Ren,Xuanjun Chen,Wei-Ping Huang,En-Pei Hu,Tzu-Quan Lin,Yuan-Kuei Wu,Kuan-Po Huang,Hsiao-Ying Huang,Huang-Cheng Chou,Kai-Wei Chang,Cheng-Han Chiang,Boris Ginsburg,Yu-Chiang Frank Wang,Hung-yi Lee*

主要分类: eess.AS

摘要简述: DeSTA2.5-Audio是一种通用大型音频语言模型（LALM），通过自生成的跨模态对齐策略，无需任务特定调优即可实现强大的听觉感知和指令跟随能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有大型音频语言模型（LALMs）通常通过手动或LLM合成的音频指令数据集增强大型语言模型（LLMs）的听觉能力，但会导致LLM原有语言能力的灾难性遗忘。为解决这一问题，本文提出了一种自生成跨模态对齐策略。

研究方法: 提出DeSTA策略，通过让主干LLM生成自身训练目标，保留其原生语言能力的同时建立有效的音频-文本对齐，从而无需任务特定调优即可实现零样本泛化。基于此构建了DeSTA-AQA5M数据集，包含500万训练样本，覆盖50个多样化数据集。

研究结果: DeSTA2.5-Audio在多个音频语言基准测试（如Dynamic-SUPERB、MMAU、SAKURA等）中达到或接近最优性能，证明了自生成策略在听觉感知和指令跟随能力上的优势。

研究结论: 研究强调了数据构建在LALM开发中的重要性，并为构建鲁棒的通用LALMs提供了实用见解。

中文摘要: 我们介绍了DeSTA2.5-Audio，一种通用大型音频语言模型（LALM），旨在实现强大的听觉感知和指令跟随能力，而无需任务特定的音频指令调优。现有的LALMs通常通过在大规模手动或LLM合成的音频指令数据集上训练来增强大型语言模型（LLMs）的听觉能力，但这些方法往往会导致LLM原有语言能力的灾难性遗忘。为解决这一问题，我们重新审视了数据构建流程，并提出了DeSTA，一种自生成的跨模态对齐策略，其中主干LLM生成自身的训练目标。这种方法保留了LLM的原生语言能力，同时建立了有效的音频-文本对齐，从而实现了无需任务特定调优的零样本泛化。利用DeSTA，我们构建了DeSTA-AQA5M，一个大规模的、任务无关的数据集，包含500万训练样本，来自7000小时的音频，涵盖50个多样化数据集，包括语音、环境声音和音乐。DeSTA2.5-Audio在广泛的音频语言基准测试中达到了最先进或竞争性性能，包括Dynamic-SUPERB、MMAU、SAKURA、Speech-IFEval和VoiceBench。全面的比较研究表明，我们的自生成策略在听觉感知和指令跟随能力上优于广泛采用的数据构建和训练策略。我们的发现强调了精心设计的数据构建在LALM开发中的重要性，并为构建鲁棒的通用LALMs提供了实用见解。

</details>


### [180] [Multi-agent Auditory Scene Analysis](https://arxiv.org/abs/2507.02755)
**中文标题：多代理听觉场景分析**

*Caleb Rascon,Luis Gato-Diaz,Eduardo García-Alarcón*

主要分类: eess.AS

摘要简述: 本文提出了一种多代理听觉场景分析（MASA）系统，通过并行任务执行和反馈循环来减少传统线性流程中的误差和响应时间，适用于计算资源有限的应用场景。


<details>
  <summary>详细信息</summary>
研究动机: 传统的听觉场景分析（ASA）采用线性任务流程（定位、分离、分类），导致响应时间长且后续任务对初始任务误差敏感。现有技术虽减少误差，但计算复杂度高，难以适用于计算资源有限的应用（如生物声学、助听器设计等）。因此，本文提出多代理并行执行任务的方法，以降低误差和响应时间。

研究方法: 提出多代理听觉场景分析（MASA）系统，任务（定位、分离、分类）并行执行，并通过反馈循环（如利用分离质量修正定位误差、分类结果降低定位干扰敏感性）补偿局部误差。系统基于开源工具（JACK、ROS2）实现，支持用户自定义代理。

研究结果: MASA系统在保持低计算复杂度的同时，显著降低了对局部误差的敏感性，并实现了低响应时间。系统框架开源，便于扩展。

研究结论: 多代理并行任务执行和反馈循环的MASA系统有效解决了传统ASA的误差累积和响应时间问题，适用于资源有限的应用场景，具有实际应用价值。

中文摘要: 听觉场景分析（ASA）旨在通过执行三个主要任务（声源定位、分离和分类）从声学环境中提取信息。传统方法采用线性数据流，依次执行任务，导致响应时间长且后续任务对初始任务误差敏感。现有技术虽减少误差，但计算复杂度高，难以适用于计算资源有限的应用（如生物声学、助听器设计等）。为此，本文提出多代理方法并行执行任务，并通过反馈循环（如利用分离质量修正定位误差、分类结果降低定位干扰敏感性）补偿局部误差。最终的多代理听觉场景分析（MASA）系统在保持低计算复杂度的同时，显著降低了对局部误差的敏感性，并实现了低响应时间。系统框架基于开源工具（JACK、ROS2）实现，支持用户自定义代理。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [181] [TubuleTracker: a high-fidelity shareware software to quantify angiogenesis architecture and maturity](https://arxiv.org/abs/2507.02024)
**中文标题：TubuleTracker：一种高保真共享软件，用于量化血管生成结构和成熟度**

*Danish Mahmood,Stephanie Buczkowski,Sahaj Shah,Autumn Anthony,Rohini Desetty,Carlo R Bartoli*

主要分类: q-bio.QM

摘要简述: 研究者开发了tubuleTracker软件，用于快速、客观地量化内皮细胞网络的血管生成结构和成熟度，显著优于手动和ImageJ分析。


<details>
  <summary>详细信息</summary>
研究动机: 传统的内皮细胞网络分析方法（如手动或ImageJ）耗时、主观且不准确，尤其是在网络复杂性增加时。因此，需要一种更高效、客观的工具来量化血管生成结构和成熟度。

研究方法: 研究使用人脐静脉内皮细胞在细胞外基质中培养，通过相差显微镜获取54张图像，分别由三名独立评审员手动分析、ImageJ和tubuleTracker软件分析。关键指标包括管状结构数量、总长度、节点数量、管状面积和血管圆形度。同时，科学家对每张图像的血管生成成熟度进行评分。

研究结果: tubuleTracker分析速度显著快于手动和ImageJ（6±2秒 vs. 8分钟和58±4秒）。其指标（如管状数量、长度、节点数量等）与血管生成成熟度评分显著相关，尤其是血管圆形度最能反映成熟度。

研究结论: tubuleTracker比手动和ImageJ更快、更一致，且能有效量化血管生成成熟度。该软件作为免费共享工具提供给生物医学研究社区。

中文摘要: 背景：体外内皮细胞培养广泛用于血管生成研究。细胞网络的显微图像通常需要手动分析，这一过程耗时且主观。自动化工具（如ImageJ）虽可辅助，但速度慢且不准确。此外，随着内皮网络复杂性增加，传统结构指标可能无法完全反映网络成熟度。为解决这些问题，我们开发了tubuleTracker软件，可快速、客观地量化内皮网络结构和成熟度。方法：人脐静脉内皮细胞在细胞外基质中培养，通过相差显微镜获取54张图像，分别由三名独立评审员手动分析、ImageJ和tubuleTracker分析。关键指标包括管状数量、总长度、节点数量、管状面积和血管圆形度。同时，科学家对每张图像的血管生成成熟度进行1-5评分（1=最成熟）。结果：每张图像分析时间差异显著：手动（8分钟）、ImageJ（58±4秒）和tubuleTracker（6±2秒）（p<0.0001）。管状数量（手动168±SD，tubuleTracker 92±SD，ImageJ 433±SD）、长度和节点数量也存在显著差异（p<0.0001）。tubuleTracker的指标与血管生成成熟度评分显著相关，包括管状数量、长度、节点数量、面积和圆形度（p<0.0001）。结论：tubuleTracker比手动和ImageJ更快、更一致，血管圆形度尤其能有效反映血管生成成熟度。tubuleTracker作为免费共享工具提供给生物医学研究社区。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [182] [AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models](https://arxiv.org/abs/2507.02598)
**中文标题：AC-Refiner：基于条件扩散模型的高效算术电路优化**

*Chenhao Xue,Kezhi Li,Jiaxing Zhang,Yi Ren,Zhengyuan Shi,Chen Zhang,Yibo Lin,Lining Zhang,Qiang Xu,Guangyu Sun*

主要分类: cs.AR

摘要简述: AC-Refiner提出了一种基于条件扩散模型的高效算术电路优化框架，通过将电路合成任务转化为条件图像生成问题，显著提升了设计质量与优化效率。


<details>
  <summary>详细信息</summary>
研究动机: 算术电路（如加法器和乘法器）是数字系统的核心组件，其性能直接影响系统的功耗和面积。然而，由于设计空间庞大且物理约束复杂，优化这些电路具有挑战性。现有深度学习方法难以稳定探索高潜力设计变体，限制了优化效率。

研究方法: AC-Refiner将算术电路合成任务重新定义为条件图像生成问题，利用条件扩散模型生成高质量电路设计。通过将去噪扩散过程与目标质量结果（QoRs）条件化，并结合探索的设计对模型进行微调，聚焦于帕累托前沿附近的优化。

研究结果: 实验结果表明，AC-Refiner生成的电路设计在帕累托最优性上优于现有基准方法，其性能优势在实际应用中得到进一步验证。

研究结论: AC-Refiner通过条件扩散模型实现了高效算术电路优化，显著提升了设计质量与优化效率，为数字系统设计提供了新思路。

中文摘要: 算术电路（如加法器和乘法器）是数字系统的基础组件，直接影响性能、能效和面积占用。然而，由于设计空间庞大且物理约束复杂，优化这些电路仍具挑战性。尽管近期基于深度学习的方法显示出潜力，但其难以稳定探索高潜力设计变体，限制了优化效率。为解决这一问题，我们提出了AC-Refiner，一种基于条件扩散模型的新型算术电路优化框架。我们的核心思想是将算术电路合成任务重新定义为条件图像生成问题。通过将去噪扩散过程与目标质量结果（QoRs）条件化，AC-Refiner能够稳定生成高质量电路设计。此外，探索的设计用于微调扩散模型，从而将优化聚焦于帕累托前沿附近。实验结果表明，AC-Refiner生成的电路设计在帕累托最优性上优于现有基准方法。通过将AC-Refiner集成到实际应用中，其性能优势得到进一步验证。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [183] [Real-time Image-based Lighting of Glints](https://arxiv.org/abs/2507.02674)
**中文标题：基于图像的实时闪烁光照**

*Tom Kneiphof,Reinhard Klein*

主要分类: cs.GR

摘要简述: 本文提出了一种高效的实时图像光照方法，用于模拟材料表面的闪烁效果，通过动态环境贴图和多区域滤波技术实现快速渲染。


<details>
  <summary>详细信息</summary>
研究动机: 在实时渲染中，模拟材料表面的闪烁效果（如微面反射）是一个挑战。传统方法难以在动态光照和材料属性下高效实现，因此需要一种新的近似方法。

研究方法: 方法基于区域光照射下的实时闪烁渲染，采用标准环境贴图滤波技术。通过将环境贴图划分为均匀区域，并利用正态分布函数滤波，计算微面反射概率。采用双门控高斯近似方法进行分层采样。

研究结果: 实验表明，该方法在多种材料和光照条件下接近真实渲染效果，性能稳定且开销低，仅需双倍内存存储预滤波环境贴图。

研究结论: 本文提出的方法在实时渲染中高效模拟了闪烁效果，为动态光照和材料属性提供了可行的解决方案。

中文摘要: 基于图像的光照技术广泛应用于实时渲染中，用于模拟真实光照条件下的着色效果。然而，对于表面具有离散微面结构的材料（如闪烁或闪光效果），这一技术尤为复杂。本文提出了一种高效的近似方法，用于实现动态材料属性和环境贴图下的闪烁光照。我们的方法基于区域光照射下的实时闪烁渲染，并采用标准环境贴图滤波技术。关键之处在于，我们的环境贴图滤波过程足够快速，可以逐帧执行。该方法假设环境贴图被划分为少量均匀的恒定辐射区域。通过用正态分布函数滤波对应的指示函数，我们得到了微面从每个区域反射光的概率。在着色过程中，这些概率被用于分层采样多项式分布，并通过我们新颖的双门控高斯近似方法实现。实验验证了我们的实时近似方法在多种材料和光照条件下接近真实渲染效果，性能稳定且开销低，仅需双倍内存存储预滤波环境贴图。与无闪烁效果的平滑材料渲染相比，我们的方法在性能上表现优异。

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [184] [Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting](https://arxiv.org/abs/2507.01997)
**中文标题：迈向民主化AI代理在网络故障排除中实验与基准测试的游乐场**

*Zhihao Wang,Alessandro Cornacchia,Franco Galante,Carlo Centofanti,Alessio Sacco,Dingde Jiang*

主要分类: cs.NI

摘要简述: 本文探讨了AI代理在网络故障排除中的应用，并呼吁建立一个标准化、可复现且开放的基准测试平台，以低操作成本构建和评估AI代理。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，AI（尤其是大型语言模型）在网络配置合成和自动化网络诊断任务中表现出色。然而，缺乏一个标准化、可复现且开放的基准测试平台，限制了AI代理在网络故障排除中的进一步发展和评估。

研究方法: 本文初步研究了AI代理在网络故障排除中的应用，并提出了一个标准化的基准测试平台的概念，旨在降低构建和评估AI代理的操作成本。

研究结果: 研究强调了建立标准化平台的重要性，以支持AI代理在网络故障排除中的高效开发和评估。

研究结论: 本文呼吁开发一个开放的基准测试平台，以促进AI代理在网络故障排除领域的广泛应用和持续改进。

中文摘要: 近期研究表明，人工智能（AI），尤其是大型语言模型（LLMs），在网络配置合成和自动化网络诊断任务等方面表现出色。在这项初步工作中，我们聚焦于AI代理在网络故障排除中的应用，并详细阐述了建立一个标准化、可复现且开放的基准测试平台的必要性，以便以低操作成本构建和评估AI代理。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [185] [Generating Large Semi-Synthetic Graphs of Any Size](https://arxiv.org/abs/2507.02166)
**中文标题：生成任意规模的大型半合成图**

*Rodrigo Tuna,Carlos Soares*

主要分类: cs.SI

摘要简述: 本文提出了一种名为LGSG的新框架，利用扩散模型和节点嵌入生成任意大小的图，解决了现有方法依赖节点ID和无法生成更大图的限制。


<details>
  <summary>详细信息</summary>
研究动机: 传统图生成方法依赖特定属性或节点ID，限制了生成图的规模和灵活性。本文旨在解决这些问题，提出一种不依赖节点ID且能生成任意大小图的方法。

研究方法: 提出Latent Graph Sampling Generation (LGSG)框架，结合扩散模型和节点嵌入，无需重新训练即可生成不同大小的图，并捕捉节点嵌入和子图结构的分布。

研究结果: 实验表明，LGSG在标准指标上与基线模型相当，但在节点聚类趋势等被忽视的指标上表现更优，且在不同大小的图中保持一致的特性。

研究结论: LGSG框架具有鲁棒性和可扩展性，能够灵活生成任意大小的图，同时保持结构特性。

中文摘要: 图生成是网络科学中的重要领域。传统方法侧重于复制真实世界图的特定属性，如小直径或幂律度分布。深度学习的进展，尤其是图神经网络，使得数据驱动方法能够学习和生成图，而无需依赖预定义的结构属性。尽管有这些进展，当前模型仍受限于对节点ID的依赖，无法生成比输入图更大的图，且忽略了节点属性。为解决这些问题，我们提出了潜在图采样生成（LGSG）框架，利用扩散模型和节点嵌入生成不同大小的图，无需重新训练。该框架消除了对节点ID的依赖，并捕捉了节点嵌入和子图结构的分布，实现了可扩展和灵活的图生成。实验结果表明，LGSG在标准指标上与基线模型表现相当，但在被忽视的指标（如节点形成聚类的趋势）上优于它们。此外，它在不同大小的图中保持了一致的结构特性，展现了鲁棒性和可扩展性。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [186] [Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features](https://arxiv.org/abs/2507.01984)
**中文标题：基于语言、视觉和社交特征早期融合的多模态虚假信息检测**

*Gautam Kishore Shahi*

主要分类: cs.LG

摘要简述: 本研究探讨了结合文本、图像和社交特征的多模态融合方法在检测社交媒体虚假信息中的有效性，结果显示多模态模型比单模态和双模态模型性能提升显著。


<details>
  <summary>详细信息</summary>
研究动机: 社交媒体在选举和危机期间充斥着大量虚假信息，现有研究多集中于文本或图像的单模态检测，而多模态特征融合的研究较少。本研究旨在填补这一空白，探索多模态特征组合在虚假信息检测中的效果。

研究方法: 研究采用早期融合方法，结合文本、图像和社交特征构建分类模型。通过数据增强技术（如目标检测和OCR）提取视觉和社交特征，分析了1,529条包含文本和图像的推文。

研究结果: 结果表明，结合无监督和监督机器学习模型的多模态方法比单模态模型性能提升15%，比双模态模型提升5%。同时，研究还分析了虚假信息推文的传播模式及其发布者的特征。

研究结论: 多模态特征融合能显著提升虚假信息检测的性能，且社交和视觉特征的加入对模型效果有重要贡献。未来可进一步优化多模态融合策略以提高检测精度。

中文摘要: 在选举和危机期间，社交媒体上充斥着大量虚假信息，现有研究主要集中于基于文本或图像的虚假信息检测方法，而关于多模态特征组合的研究较少。本研究探讨了结合文本、图像和社交特征的多模态融合方法在虚假信息检测中的有效性。研究采用早期融合策略构建分类模型，分析了从Twitter（现为X）收集的1,529条包含文本和图像的推文，并通过数据增强技术（如目标检测和OCR）提取了额外的社交和视觉特征。结果显示，结合无监督和监督机器学习模型的多模态方法比单模态模型性能提升15%，比双模态模型提升5%。此外，研究还分析了虚假信息推文的传播模式及其发布者的特征。

</details>


### [187] [Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions](https://arxiv.org/abs/2507.02087)
**中文标题：评估大型语言模型在招聘决策中的潜力与风险**

*Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia*

主要分类: cs.LG

摘要简述: 本文评估了大型语言模型（LLMs）在招聘决策中的潜力与风险，发现专用招聘模型（Match Score）在准确性和公平性上均优于通用LLMs，强调高风险领域需定制化模型和偏见审计。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在招聘筛选中有潜力提升效率，但其准确性和算法偏见问题引发担忧。本文旨在比较通用LLMs与专用招聘模型的性能，探讨如何在高风险招聘场景中平衡准确性与公平性。

研究方法: 研究对多个前沿LLMs（如OpenAI、Anthropic等）与专用招聘模型（Match Score）进行对比，评估其预测准确性（ROC AUC、F1分数等）和公平性（基于性别、种族等子群的影响比率）。实验基于10,000个真实招聘数据。

研究结果: Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（最低种族影响比率0.957 vs LLMs的0.809）上均显著优于通用LLMs。研究还发现，未经充分保护的LLMs可能放大社会偏见。

研究结论: 研究强调在高风险招聘领域需采用定制化模型和偏见审计，避免依赖未经优化的通用LLMs。同时证明，设计良好的算法可同时实现高准确性和公平性。

中文摘要: 大型语言模型（LLMs）在招聘中的应用有望简化候选人筛选流程，但也引发了准确性和算法偏见的严重问题（尤其在缺乏充分保障时）。本研究对多个前沿LLMs（包括OpenAI、Anthropic、Google、Meta和Deepseek的模型）与专用招聘模型（Match Score）进行了对比，评估其预测准确性（ROC AUC、精确召回AUC、F1分数）和公平性（基于性别、种族及交叉子群的截断分析影响比率）。实验基于约10,000个真实招聘数据，结果显示Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（最低种族影响比率0.957 vs LLMs的0.809）上均优于通用LLMs。研究表明，未经调整的LLMs可能因预训练偏见放大社会偏见，而定制监督模型能更有效缓解这些问题。研究强调了在高风险招聘领域采用专用模型和偏见审计的重要性，并警示避免直接使用未经优化的通用LLMs。此外，实证表明招聘中准确性与公平性并非对立，设计良好的算法可同时实现两者。

</details>


### [188] [Energy-Based Transformers are Scalable Learners and Thinkers](https://arxiv.org/abs/2507.02092)
**中文标题：基于能量的Transformer是可扩展的学习者和思考者**

*Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal*

主要分类: cs.LG

摘要简述: 本文提出了一种新型的基于能量的Transformer（EBT），通过无监督学习实现系统2思维，显著提升了模型在文本和视觉任务中的性能和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有系统2思维方法存在局限性，如仅适用于特定模态或问题，或需要额外监督。本文旨在探索是否可以通过无监督学习实现通用的系统2思维模型。

研究方法: 训练基于能量的Transformer（EBT），通过能量函数评估输入与候选预测的兼容性，并将预测问题转化为能量最小化优化问题。

研究结果: EBT在训练中比Transformer++扩展更快，性能提升高达35%；在推理中，语言任务性能提升29%，图像去噪优于扩散Transformer且计算更高效。

研究结论: EBT是一种新的模型范式，能够同时扩展模型的学习和思维能力，泛化能力优于现有方法。

中文摘要: 推理时计算技术（类似于人类的系统2思维）近年来被广泛用于提升模型性能。然而，现有方法大多存在局限性：它们仅适用于特定模态（如文本）、特定问题（如数学和编程等可验证领域），或需要在无监督预训练基础上额外监督（如验证器或可验证奖励）。本文探讨了“是否可以通过无监督学习实现通用的系统2思维模型”。有趣的是，我们发现答案是肯定的，方法是学习显式验证输入与候选预测的兼容性，并将预测问题转化为基于验证器的优化问题。具体而言，我们训练了基于能量的Transformer（EBT）——一种新型的基于能量的模型（EBM）——为每个输入和候选预测对分配能量值，通过基于梯度下降的能量最小化实现预测。在离散（文本）和连续（视觉）模态中，EBT在训练中的扩展速度均优于主流的Transformer++方法，数据、批量大小、参数、FLOPs和深度方面的扩展率最高提升35%。在推理中，EBT通过系统2思维在语言任务上的性能比Transformer++提升29%，同时在图像去噪任务上优于扩散Transformer且前向计算次数更少。此外，我们发现EBT在相同或更差的预训练性能下，在大多数下游任务中表现优于现有模型，表明EBT的泛化能力更强。因此，EBT是一种有前景的新范式，能够同时扩展模型的学习和思维能力。

</details>


### [189] [Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows](https://arxiv.org/abs/2507.01975)
**中文标题：用于加速流动模拟的可学习-可微分有限体积求解器**

*Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun*

主要分类: cs.LG

摘要简述: 本文提出了一种可学习且可微分的有限体积求解器LDSolver，用于在粗网格上高效准确地模拟流体流动。该方法结合了可微分求解器和可学习模块，显著提升了计算效率，同时保持了高精度和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 流体流动模拟在气象学、空气动力学和生物医学等领域至关重要。传统数值求解器需要精细的时空网格以满足稳定性、一致性和收敛性条件，导致计算成本高昂。尽管机器学习方法效率更高，但通常存在可解释性、泛化性和数据依赖性等问题。因此，本文旨在提出一种兼具高效性和准确性的新方法。

研究方法: LDSolver包含两个关键组件：(1) 可微分有限体积求解器；(2) 可学习模块，用于在粗网格上提供等效的流量近似（导数和插值）和时间误差校正。该方法即使在有限训练数据（如仅几条轨迹）下也能实现高效模拟。

研究结果: 在不同流动系统（如Burgers、衰减流、强迫流和剪切流）上的实验表明，LDSolver实现了最先进的性能，显著优于基线模型。

研究结论: LDSolver通过结合可微分求解器和可学习模块，在粗网格上实现了高效且高精度的流体流动模拟，同时具备优异的泛化能力，为复杂物理现象的模拟提供了新思路。

中文摘要: 流体流动模拟对于气象学、空气动力学和生物医学等物理现象的建模至关重要。传统的数值求解器通常需要精细的时空网格以满足稳定性、一致性和收敛性条件，导致计算成本高昂。尽管机器学习方法表现出更高的效率，但它们通常存在可解释性、泛化性和数据依赖性问题。因此，我们提出了一种可学习且可微分的有限体积求解器LDSolver，旨在粗网格上高效且准确地模拟流体流动。LDSolver包含两个关键组件：(1) 可微分有限体积求解器；(2) 可学习模块，用于在粗网格上提供等效的流量近似（导数和插值）和时间误差校正。即使在有限的训练数据（如仅几条轨迹）下，我们的模型也能在保持高精度的同时加速模拟，并具备优异的泛化能力。在不同流动系统（如Burgers、衰减流、强迫流和剪切流）上的实验表明，LDSolver实现了最先进的性能，显著优于基线模型。

</details>


### [190] [DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism](https://arxiv.org/abs/2507.01982)
**中文标题：DKGCM：一种融合空间节点聚类方法和傅里叶双向Mamba机制的交通流时空预测模型**

*Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DKGCM的新型时空预测模型，通过融合空间节点聚类方法和傅里叶双向Mamba机制，显著提升了交通流预测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 交通需求预测的准确性对资源分配效率至关重要，但复杂的时空关系限制了现有模型的性能。本文旨在通过改进空间和时间依赖性的捕捉方法，提升预测精度。

研究方法: 提出DK-GCN方法，利用动态时间规整和K-means聚类对交通节点分组，优化空间依赖性捕捉；结合快速傅里叶变换和双向Mamba框架捕捉时间依赖性；引入GRPO强化学习策略优化模型训练。

研究结果: 实验表明，DKGCM在三个公开数据集上表现优于多种先进方法，验证了其有效性。

研究结论: DKGCM通过创新的空间聚类和时间依赖性捕捉方法，显著提升了交通流预测的准确性，为交通管理提供了有力工具。

中文摘要: 准确的交通需求预测能够帮助交通管理部门更有效地分配资源，从而提高资源利用效率。然而，交通系统中复杂的时空关系仍然限制了需求预测模型的性能。为了提升时空交通需求预测的准确性，我们提出了一种新的图卷积网络结构DKGCM。具体而言，我们首先考虑了不同交通节点的空间流量分布，并提出了一种基于时间相似性的新型聚类图卷积方法DK-GCN。该方法利用动态时间规整（DTW）和K-means聚类对交通节点进行分组，更有效地捕捉空间依赖性。在时间尺度上，我们将快速傅里叶变换（FFT）整合到双向Mamba深度学习框架中，以捕捉交通需求的时间依赖性。为了进一步优化模型训练，我们引入了GRPO强化学习策略来增强损失函数的反馈机制。大量实验表明，我们的模型在三个公开数据集上表现优于多种先进方法，并取得了显著的效果。

</details>


### [191] [OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding](https://arxiv.org/abs/2507.02659)
**中文标题：OmniDraft：一种跨词汇、在线自适应的设备端推测解码草稿模型**

*Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang*

主要分类: cs.LG

摘要简述: OmniDraft提出了一种跨词汇、在线自适应的草稿模型框架，支持单一草稿模型与任何目标模型配对，并通过动态适应和混合蒸馏微调提升解码速度，适用于设备端LLM应用。


<details>
  <summary>详细信息</summary>
研究动机: 现有草稿模型通常针对特定目标模型离线训练，但在线部署时面临两个挑战：1) 目标模型与草稿模型不兼容；2) 需要随时间提升延迟性能。OmniDraft旨在解决这些问题，实现“一草稿模型适配所有”的范式。

研究方法: OmniDraft引入在线n-gram缓存和混合蒸馏微调技术，解决草稿与目标模型间的词汇不匹配问题，并采用自适应草稿技术进一步提升解码速度。

研究结果: 实验表明，OmniDraft使单一Llama-68M模型能与Vicuna-7B、Qwen2-7B和Llama3-8B等目标模型配对，解码速度提升1.5-2倍。

研究结论: OmniDraft为设备端LLM应用提供了一种高效、灵活的解决方案，支持跨模型适配和动态优化，验证了“一草稿模型适配所有”的可行性。

中文摘要: 推测解码通常需要一个离线预训练或蒸馏的小型高效草稿模型，例如针对Llama或Qwen模型系列。然而，在线部署时面临两大挑战：1) 目标模型与草稿模型不兼容；2) 需要随时间提升延迟性能。本文提出OmniDraft，一种统一框架，使单一草稿模型能与任何目标模型配对并动态适应用户数据。通过在线n-gram缓存和混合蒸馏微调解决词汇不匹配问题，并利用自适应草稿技术提升解码速度。OmniDraft特别适用于设备端LLM应用，其中模型成本、效率和用户定制是主要关注点。这进一步凸显了解决上述挑战的必要性，并推动了“一草稿模型适配所有”的范式。我们通过在数学推理、代码生成和文本生成任务上进行在线学习，展示了OmniDraft的效能。值得注意的是，OmniDraft使单一Llama-68M模型能与Vicuna-7B、Qwen2-7B和Llama3-8B等目标模型配对进行推测解码，并额外提供1.5-2倍的加速效果。

</details>


### [192] [ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning](https://arxiv.org/abs/2507.02834)
**中文标题：ExPO：通过自我解释引导的强化学习解锁复杂推理**

*Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi*

主要分类: cs.LG

摘要简述: 论文提出了一种名为ExPO的自我解释策略优化框架，通过结合真实答案生成高质量样本，解决了强化学习后训练中样本探索不足的问题，显著提升了模型在复杂推理任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于强化学习的后训练方法依赖模型初始生成的正样本，难以解决模型初始表现不佳的任务。尤其是在复杂推理任务中，正样本稀缺，限制了模型能力的提升。

研究方法: ExPO框架通过结合真实答案生成符合当前策略且能提升模型正确预测概率的样本，取代专家演示样本，实现高效探索和优化。

研究结果: 实验表明，ExPO在MATH level-5等高难度推理任务中显著优于基于专家演示的方法，提升了学习效率和最终性能。

研究结论: ExPO通过自我解释策略优化，有效解决了强化学习后训练中的样本探索问题，为复杂推理任务提供了更高效的解决方案。

中文摘要: 近年来，基于强化学习（RL）的后训练方法通过优化模型输出来提升推理能力，但其依赖模型初始生成的正样本，难以解决模型初始失败的任务。尤其是在早期RL训练和复杂推理任务中，正样本稀缺。为解决这一问题，模型需探索超出当前输出分布的新推理轨迹。专家演示看似可行，但在RL后训练中效果不佳。我们提出自我解释策略优化（ExPO），通过结合真实答案生成高质量样本，这些样本既符合当前策略，又能提升模型正确预测概率。ExPO在MATH level-5等高难度任务中表现优异，超越了基于专家演示的方法。

</details>


### [193] [GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters](https://arxiv.org/abs/2507.02085)
**中文标题：GeoAda：利用等变适配器高效微调几何扩散模型**

*Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon*

主要分类: cs.LG

摘要简述: GeoAda是一种SE(3)-等变适配器框架，用于高效微调几何扩散模型，保持几何一致性并避免过拟合和灾难性遗忘，适用于多种几何控制任务。


<details>
  <summary>详细信息</summary>
研究动机: 几何扩散模型在分子动力学和结构生成中表现出色，但如何高效微调以适应不同几何控制的下游任务尚未充分研究。

研究方法: GeoAda通过引入结构化适配器设计，包括耦合操作符编码控制信号、可训练预训练模型层副本处理信号，以及解耦操作符和等变零初始化卷积完成投影，仅微调轻量适配器模块。

研究结果: GeoAda在多种几何控制类型（如框架控制、全局控制、子图控制）和应用领域（如粒子动力学、分子动力学、人体运动预测）中表现优异，保持原始任务准确性，优于其他基线方法。

研究结论: GeoAda通过SE(3)-等变适配器实现了高效微调，既保留了预训练模型的几何归纳偏置，又避免了过拟合和灾难性遗忘，具有广泛适用性。

中文摘要: 几何扩散模型在分子动力学和结构生成中取得了显著成功，但如何高效微调以适应不同几何控制的下游任务仍待探索。本文提出了一种SE(3)-等变适配器框架（GeoAda），能够在不改动原始模型架构的情况下，实现灵活且参数高效的微调，用于受控生成任务。GeoAda采用结构化适配器设计：控制信号首先通过耦合操作符编码，然后由预训练模型层的可训练副本处理，最后通过解耦操作符和等变零初始化卷积投影回原空间。仅微调这些轻量适配器模块，GeoAda既保持了模型的几何一致性，又避免了过拟合和灾难性遗忘。理论上，我们证明了所提适配器保持SE(3)-等变性，确保预训练扩散模型的几何归纳偏置在适应过程中不受破坏。实验表明，GeoAda适用于多种几何控制类型（如框架控制、全局控制、子图控制）和广泛的应用领域（如粒子动力学、分子动力学、人体运动预测、分子生成），在微调性能上达到最优，同时保持原始任务准确性，而其他基线方法因过拟合和灾难性遗忘导致性能显著下降。

</details>


### [194] [Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies](https://arxiv.org/abs/2507.02244)
**中文标题：竞争压力下的订单获取：一种快速自适应的强化学习方法用于网约车补贴策略**

*Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于强化学习的补贴策略框架FCA-RL，用于快速适应竞争对手的价格调整，优化网约车平台的订单获取。通过Fast Competition Adaptation（FCA）和Reinforced Lagrangian Adjustment（RLA）技术，结合RideGym仿真环境，实验证明该方法在多种市场条件下优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 网约车聚合平台的竞争排名机制促使服务提供商通过降低价格获取更多订单，但现有研究缺乏动态适应市场波动并优化订单获取的有效补贴策略。本文旨在填补这一空白。

研究方法: 提出FCA-RL框架，结合FCA技术快速响应动态价格变化，RLA技术确保预算约束下的优惠券决策优化，并开发RideGym仿真环境进行策略评估。

研究结果: 实验结果表明，FCA-RL在多种市场条件下均优于基线方法，有效优化了网约车服务提供商的补贴策略。

研究结论: FCA-RL通过快速适应竞争和预算约束优化，为网约车平台提供了一种高效的补贴策略解决方案。

中文摘要: 网约车聚合平台的普及为服务提供商带来了订单量和总交易额（GMV）的增长机会。在大多数平台上，提供更低价格的服务提供商会获得更高的排名，从而更容易被乘客选择。这种竞争排名机制促使服务提供商采用优惠券策略以降低价格获取更多订单，因为订单量直接影响其长期生存能力。因此，设计一种能够动态适应市场波动并在预算约束下优化订单获取的优惠券策略是一个关键的研究挑战，但现有研究仍较少。

为填补这一空白，我们提出了FCA-RL，一种基于强化学习的补贴策略框架，旨在快速适应竞争对手的价格调整。该方法整合了两种关键技术：快速竞争适应（FCA）和强化拉格朗日调整（RLA），前者实现对动态价格变化的快速响应，后者确保在预算约束下优化优惠券决策。此外，我们开发了RideGym，首个专为网约车聚合平台设计的仿真环境，支持在不影响实际运营效率的情况下全面评估和比较不同定价策略。实验结果表明，我们提出的方法在多种市场条件下均优于基线方法，凸显了其在网约车服务提供商补贴优化中的有效性。

</details>


### [195] [Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications](https://arxiv.org/abs/2507.02291)
**中文标题：基于知识图谱的可解释与泛化零样本语义通信**

*Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu*

主要分类: cs.LG

摘要简述: 本文提出了一种基于知识图谱的零样本语义通信网络（KGZS-SC），通过知识图谱增强语义表示和推理能力，解决了数据驱动语义通信缺乏解释性和泛化性的问题。实验表明，该网络在分类未见类别时表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 数据驱动的语义通信依赖于表面的统计模式，缺乏解释性和泛化性，尤其是在处理未见数据时表现不佳。本文旨在通过知识图谱增强语义表示，提升通信网络的泛化能力和解释性。

研究方法: 提出了一种基于知识图谱的零样本语义通信网络（KGZS-SC），利用知识图谱语义知识库（KG-SKB）对齐语义特征，增强发射端的泛化能力，并通过零样本学习（ZSL）在接收端直接分类未见类别，无需重新训练。

研究结果: 在APY数据集上的实验结果表明，KGZS-SC网络在分类未见类别时表现出强大的泛化能力，并在不同信噪比水平下显著优于现有语义通信框架。

研究结论: KGZS-SC网络通过知识图谱增强语义表示和推理能力，显著提升了语义通信的解释性和泛化性，适用于动态或资源受限的环境。

中文摘要: 数据驱动的语义通信依赖于表面的统计模式，因此缺乏解释性和泛化性，尤其是在处理未见数据时表现不佳。为解决这些问题，我们提出了一种基于知识图谱增强的零样本语义通信（KGZS-SC）网络。通过知识图谱语义知识库（KG-SKB）的结构化语义信息引导，我们的方案提供了泛化的语义表示，并支持对未见案例的推理。具体而言，KG-SKB将语义特征对齐到共享的类别语义嵌入空间中，并通过对齐的语义特征增强发射端的泛化能力，从而通过选择性传输紧凑的视觉语义减少通信开销。在接收端，利用零样本学习（ZSL）直接对未见案例进行分类，无需重新训练或额外的计算开销，从而提升了动态或资源受限环境中分类过程的适应性和效率。在APY数据集上的仿真结果表明，所提出的KGZS-SC网络表现出强大的泛化能力，并在不同信噪比水平下显著优于现有的语义通信框架。

</details>


### [196] [Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment](https://arxiv.org/abs/2507.02310)
**中文标题：概念漂移下的自适应记忆对齐全息持续学习**

*Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk*

主要分类: cs.LG

摘要简述: 本文提出了一种针对概念漂移的持续学习框架AMR，通过动态调整记忆缓冲区中的样本，有效平衡稳定性和适应性，显著减少标注和计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 传统持续学习方法假设数据分布静态，忽略了现实数据流中的概念漂移问题，导致模型难以适应动态变化。本文旨在解决这一挑战，提出一种轻量级方法以应对概念漂移。

研究方法: 提出自适应记忆对齐（AMR）方法，选择性移除记忆缓冲区中过时的样本，并补充少量最新实例，实现对新分布的高效适应。

研究结果: 在多个概念漂移变体的视觉基准测试中，AMR表现优异，性能接近完全重新学习（FR），同时大幅减少标注和计算需求。

研究结论: AMR是一种可扩展的解决方案，能够在非静态持续学习环境中平衡稳定性和可塑性，为实际应用提供高效支持。

中文摘要: 传统的持续学习方法注重知识保留，主要解决灾难性遗忘问题，隐含假设先前学习任务的数据分布是静态的。然而，现实世界的数据流具有动态性，概念漂移会永久改变已见数据，要求模型兼具稳定性和快速适应性。

我们提出了一种针对概念漂移的全息持续学习框架，通过模拟任务分布的动态变化来反映真实场景。作为基线，我们考虑了完全重新学习（FR），即模型从漂移分布的新标注样本中重新训练。虽然有效，但这种方法需要大量标注和计算资源。为解决这些限制，我们提出了自适应记忆对齐（AMR），一种轻量级替代方案，为基于回放的持续学习方法提供漂移感知的适应机制。AMR选择性移除记忆缓冲区中漂移类别的过时样本，并用少量最新实例重新填充，从而高效地将记忆与新分布对齐。这种针对性重采样在性能上与FR相当，同时将标注和计算需求降低数个数量级。

为支持可重复评估，我们引入了四种标准视觉基准的概念漂移变体：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD和Tiny-ImageNet-CD，其中先前见过的类别以漂移后的表征重新出现。在这些数据集上的综合实验表明，AMR能持续应对概念漂移，以最小开销保持高准确率。这些结果证明AMR是一种可扩展的解决方案，可在非静态持续学习环境中平衡稳定性和可塑性。

</details>


### [197] [DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values](https://arxiv.org/abs/2507.02342)
**中文标题：DeltaSHAP：基于Shapley值的在线患者监测预测变化解释**

*Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang*

主要分类: cs.LG

摘要简述: DeltaSHAP是一种新型可解释人工智能算法，专为在线患者监测系统设计，通过Shapley值解释预测变化，满足临床时间序列分析的独特需求，并在质量和效率上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在临床环境中，及时了解患者风险变化的原因对干预至关重要，但现有可解释AI方法无法满足临床时间序列解释的需求。DeltaSHAP旨在解决这一缺口。

研究方法: DeltaSHAP通过调整Shapley值以适应时间序列设置，准确捕捉特征组合效应，并仅使用实际观察到的特征组合来解释预测变化，同时提供特征贡献的大小和方向。

研究结果: 实验表明，DeltaSHAP在在线患者监测任务中优于现有方法，解释质量提升62%，计算效率提高33%（时间减少）。

研究结论: DeltaSHAP为临床时间序列解释提供了一种高效且实用的解决方案，满足了实时性和准确性的需求。

中文摘要: 本研究提出DeltaSHAP，一种专为在线患者监测系统设计的新型可解释人工智能（XAI）算法。在临床环境中，发现驱动患者风险变化的原因对及时干预至关重要，但现有XAI方法无法满足临床时间序列解释任务的独特需求。为此，DeltaSHAP解决了三个关键临床需求：解释连续预测的变化而非孤立预测分数，提供特征贡献的大小和方向，并实时提供这些见解。通过将Shapley值调整到时间序列设置中，我们的方法准确捕捉了特征组合效应。它进一步仅使用实际观察到的特征组合来归因预测变化，使其在时间敏感的临床应用中高效且实用。我们还引入了新的评估指标来评估在线时间序列归因的忠实性，并通过在线患者监测任务的实验证明，DeltaSHAP在解释质量（提升62%）和计算效率（时间减少33%）上均优于现有XAI方法。代码发布于https://github.com/AITRICS/DeltaSHAP。

</details>


### [198] [Offline Reinforcement Learning with Penalized Action Noise Injection](https://arxiv.org/abs/2507.02356)
**中文标题：带惩罚动作噪声注入的离线强化学习**

*JunHyeok Oh,Byung-Jun Lee*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PANI的离线强化学习方法，通过注入带惩罚的动作噪声来覆盖整个动作空间，显著提升了离线强化学习的性能，且无需依赖计算密集的扩散模型。


<details>
  <summary>详细信息</summary>
研究动机: 离线强化学习仅依赖固定数据集优化策略，适用于环境交互成本高的场景。扩散模型虽能提升性能，但其计算需求高。本文旨在探索一种更简单高效的方法，通过噪声注入提升离线强化学习的泛化能力。

研究方法: 提出PANI方法，通过注入带惩罚的动作噪声覆盖动作空间，并基于噪声量进行惩罚。理论证明该方法可解决一种称为“噪声动作MDP”的修改版马尔可夫决策过程。PANI兼容多种现有离线强化学习算法。

研究结果: 实验表明，PANI在多种基准测试中显著提升了性能，且方法简单高效，无需依赖扩散模型。

研究结论: PANI是一种简单高效的离线强化学习方法，通过噪声注入和惩罚机制显著提升性能，适用于多种现有算法，且计算成本低。

中文摘要: 离线强化学习（RL）仅使用固定数据集优化策略，适用于环境交互成本高的场景。由于这一限制，泛化能力是提升离线RL算法性能的关键，如近期扩散模型在离线RL中的成功所示。然而，考虑到扩散模型在推理时的高计算需求，其必要性存疑。本文提出带惩罚动作噪声注入（PANI）方法，通过注入噪声动作覆盖整个动作空间，并根据噪声量进行惩罚，从而简单高效地提升离线学习性能。该方法受扩散模型在离线RL中的启发，理论证明其可解决一种称为“噪声动作MDP”的修改版马尔可夫决策过程。PANI兼容多种现有离线和离线RL算法，尽管方法简单，但在多种基准测试中表现出显著性能提升。

</details>


### [199] [S2FGL: Spatial Spectral Federated Graph Learning](https://arxiv.org/abs/2507.02409)
**中文标题：S2FGL：空间谱联邦图学习**

*Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye*

主要分类: cs.LG

摘要简述: 本文提出了一种名为S2FGL的框架，结合空间和谱域策略，解决联邦图学习中子图间的标签信号中断和谱异质性问题，显著提升了全局模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前联邦图学习（FGL）仅从结构角度处理子图联邦学习，忽略了图信号在空间和谱域的传播问题。空间上，子图联邦学习导致客户端间边连接中断，破坏标签信号；谱域上，谱异质性导致局部图神经网络过拟合本地信号传播模式，引发谱客户端漂移，影响全局泛化性。

研究方法: 提出S2FGL框架，包含两部分：1）全局知识库缓解标签信号中断；2）频率对齐解决谱客户端漂移。结合空间和谱域策略，优化联邦图学习性能。

研究结果: 在多个数据集上的实验表明，S2FGL显著优于现有方法，有效提升了全局图神经网络的泛化能力。

研究结论: S2FGL通过空间和谱域的双重优化，成功解决了联邦图学习中的信号传播和谱异质性问题，为联邦图学习提供了新的解决方案。

中文摘要: 联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNNs）的强大图建模能力。当前研究仅从结构角度处理子图联邦学习，忽略了图信号在空间和谱域的传播。从空间角度看，子图联邦学习引入客户端间的边断开，导致标签信号中断和全局GNN类知识退化。从谱域角度看，谱异质性导致子图间信号频率不一致，使局部GNN过拟合本地信号传播模式，引发谱客户端漂移，削弱全局泛化性。为解决这些问题，我们提出全局知识库以缓解标签信号中断，并通过频率对齐解决谱客户端漂移。空间和谱域策略的结合形成了我们的框架S2FGL。在多个数据集上的实验证明了S2FGL的优越性。代码发布于https://github.com/Wonder7racer/S2FGL.git。

</details>


### [200] [Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction](https://arxiv.org/abs/2507.02129)
**中文标题：高效时空数据压缩的生成潜在扩散方法**

*Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka*

主要分类: cs.LG

摘要简述: 本文提出了一种高效的潜在扩散框架，结合变分自编码器和条件扩散模型，通过压缩少量关键帧并生成插值来重建时空数据，显著降低存储成本。


<details>
  <summary>详细信息</summary>
研究动机: 生成模型在数据压缩中表现优异，但其可控性和重建精度限制了实际应用。本文旨在解决这一问题，提出一种高效的数据压缩方法。

研究方法: 结合变分自编码器和条件扩散模型，仅压缩少量关键帧到潜在空间，并以此为条件生成插值重建其余帧，避免存储每帧的潜在表示。

研究结果: 实验表明，该方法在相同重建误差下，压缩比优于规则压缩方法（如SZ3）10倍，且比领先的学习方法性能提升63%。

研究结论: 提出的潜在扩散框架在时空数据压缩中实现了高精度重建和显著存储节省，具有广泛应用潜力。

中文摘要: 生成模型在条件设置中表现出色，可视为一种数据压缩形式，其中条件作为紧凑表示。然而，其有限的可控性和重建精度限制了其在数据压缩中的实际应用。本研究提出了一种高效的潜在扩散框架，通过结合变分自编码器和条件扩散模型来弥补这一差距。我们的方法仅将少量关键帧压缩到潜在空间，并将其作为条件输入，通过生成插值重建其余帧，无需存储每帧的潜在表示。这种方法在显著降低存储成本的同时实现了精确的时空重建。多个数据集的实验结果表明，在相同重建误差下，我们的方法比规则压缩方法（如SZ3）压缩比高10倍，且比领先的学习方法性能提升63%。

</details>


### [201] [Continual Gradient Low-Rank Projection Fine-Tuning for LLMs](https://arxiv.org/abs/2507.02503)
**中文标题：大型语言模型的持续梯度低秩投影微调**

*Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GORP的新型训练策略，通过结合全参数和低秩参数并在统一低秩梯度子空间中联合更新，解决了大型语言模型持续微调中效率与表达能力之间的权衡问题。实验表明，GORP在持续学习任务中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的持续微调面临效率与表达能力之间的权衡问题。低秩适应（LoRA）虽然高效，但由于其低秩特性和显式参数约束，限制了模型学习新任务和迁移知识的能力。本文旨在克服这些限制。

研究方法: 提出了GORP（梯度低秩投影持续学习）策略，通过协同结合全参数和低秩参数，并在统一低秩梯度子空间中联合更新，扩展了优化空间，同时保持了效率并减轻了灾难性遗忘。

研究结果: 在持续学习基准测试中，GORP表现出优于现有最先进方法的性能。

研究结论: GORP通过结合全参数和低秩参数的联合更新，有效解决了持续微调中的效率与表达能力问题，为大型语言模型的持续学习提供了一种高效且表现力强的解决方案。

中文摘要: 大型语言模型（LLMs）的持续微调受到效率与表达能力之间权衡的制约。低秩适应（LoRA）虽然高效，但由于其低秩特性和对显式参数约束的依赖，限制了模型学习新任务和迁移知识的能力。我们提出了GORP（梯度低秩投影持续学习），这是一种新型训练策略，通过协同结合全参数和低秩参数，并在统一低秩梯度子空间中联合更新，克服了这些限制。GORP扩展了优化空间，同时保持了效率并减轻了灾难性遗忘。在持续学习基准测试中的广泛实验表明，GORP的性能优于现有的最先进方法。代码可在https://github.com/Wcxwcxw/GORP获取。

</details>


### [202] [Position: A Theory of Deep Learning Must Include Compositional Sparsity](https://arxiv.org/abs/2507.02550)
**中文标题：观点：深度学习理论必须包含组合稀疏性**

*David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio*

主要分类: cs.LG

摘要简述: 本文提出，深度神经网络（DNNs）的成功源于其能够利用目标函数的组合稀疏结构，即大多数实际相关函数可由少量低维输入的子函数组合而成。这一特性为理解DNNs的学习动态提供了关键视角。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络在多个高维领域表现出色，但其学习动态的基本原理仍不明确。本文旨在探讨DNNs成功的关键因素，即其对组合稀疏结构的利用能力。

研究方法: 通过分析组合稀疏结构的普遍性（如所有高效图灵可计算函数均具备此特性），本文论证了DNNs能够利用这一结构实现高效学习。

研究结果: 研究表明，组合稀疏结构是DNNs成功的关键，但目前关于其可学习性和优化的理论仍需进一步完善。

研究结论: 理解组合稀疏性在深度学习中的作用，对构建全面的人工智能理论至关重要，甚至可能推广至通用智能理论。

中文摘要: 过参数化的深度神经网络（DNNs）在多个高维领域取得了显著成功，超越了受维度诅咒限制的经典浅层网络。然而，关于DNNs学习动态的基本原理仍存在未解之谜。本文提出，DNNs的成功源于其能够利用目标函数的组合稀疏结构，即大多数实际相关函数可由少量低维输入的子函数组合而成。我们证明，这一特性为所有高效图灵可计算函数所共有，因此在当前学习问题中普遍存在。尽管关于组合稀疏函数的近似和泛化问题已有一些理论见解，但DNNs的可学习性和优化问题仍需进一步研究。完善组合稀疏性在深度学习中的作用，对构建全面的人工智能理论至关重要，甚至可能推广至通用智能理论。

</details>


### [203] [L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation](https://arxiv.org/abs/2507.02619)
**中文标题：L-VAE：具有可学习β的解耦表示变分自编码器**

*Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural*

主要分类: cs.LG

摘要简述: 本文提出了一种名为L-VAE的新模型，通过学习损失函数的超参数和模型参数，动态平衡解耦表示和重构损失，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有β-VAE模型需要手动调整超参数β，限制了其在解耦表示中的灵活性和性能。L-VAE旨在通过学习超参数和模型参数，动态优化解耦与重构的权衡。

研究方法: L-VAE扩展了β-VAE，通过学习损失函数中各项的相对权重，动态控制解耦与重构的平衡。模型添加了正则化项以防止偏向某一损失，并同时学习权重和架构参数。

研究结果: 实验表明，L-VAE在dSprites、MPI3D-complex等数据集上表现优异，解耦指标优于或接近β-VAE、ControlVAE等方法。CelebA上的定性实验也验证了其解耦面部属性的能力。

研究结论: L-VAE通过动态学习超参数和模型参数，有效平衡了解耦和重构性能，为解耦表示学习提供了更优的解决方案。

中文摘要: 本文提出了一种名为可学习变分自编码器（L-VAE）的新模型，通过学习损失函数的超参数和解耦表示。L-VAE可视为β-VAE的扩展，其中超参数β通过经验调整。L-VAE通过学习损失函数中各项的相对权重，动态控制解耦与重构损失的权衡，从而克服了β-VAE的局限性。在提出的模型中，损失项的权重和模型架构参数同时学习。损失函数中添加了额外的正则化项以防止偏向重构或解耦损失。实验分析表明，L-VAE在重构保真度和解耦潜在维度之间找到了有效平衡。与β-VAE、VAE、ControlVAE、DynamicVAE和σ-VAE在dSprites、MPI3D-complex、Falcor3D和Isaac3D等数据集上的比较显示，L-VAE在一系列解耦指标上始终表现最佳或次佳。此外，CelebA数据集上的定性实验证实了L-VAE在解耦面部属性方面的成功。

</details>


### [204] [Fair Deepfake Detectors Can Generalize](https://arxiv.org/abs/2507.02645)
**中文标题：公平的深度伪造检测器可以泛化**

*Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli*

主要分类: cs.LG

摘要简述: 本文揭示了深度伪造检测模型中公平性与泛化能力之间的因果关系，并提出了一种新的框架DAID，通过控制混杂变量实现公平性与泛化能力的双重提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有深度伪造检测模型在泛化性和公平性之间存在矛盾，本文旨在揭示两者之间的因果关系，并提出一种能够同时提升两者的方法。

研究方法: 提出DAID框架，包括：1）基于逆倾向加权和子群特征归一化的数据再平衡；2）使用对齐损失抑制敏感属性信号的特征聚合。

研究结果: 在三个跨域基准测试中，DAID在公平性和泛化性上均优于现有先进检测器，验证了其理论和实践有效性。

研究结论: 通过控制混杂变量，公平性干预可以提升泛化能力，DAID框架为深度伪造检测提供了新的解决方案。

中文摘要: 深度伪造检测模型面临两个关键挑战：对未见操作的泛化能力以及在人口群体中的公平性。然而，现有方法通常表明这两个目标本质上是冲突的，揭示了它们之间的权衡。本文首次揭示并正式定义了公平性与泛化能力之间的因果关系。基于后门调整，我们表明通过控制混杂变量（数据分布和模型容量），公平性干预可以提升泛化能力。基于这一发现，我们提出了人口属性不敏感干预检测（DAID），一个即插即用的框架，包括：1）人口感知的数据再平衡，采用逆倾向加权和子群特征归一化以消除分布偏差；2）人口无关的特征聚合，使用新的对齐损失抑制敏感属性信号。在三个跨域基准测试中，DAID在公平性和泛化性上均优于多个先进检测器，验证了其理论基础和实践有效性。

</details>


### [205] [Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs](https://arxiv.org/abs/2507.02671)
**中文标题：基于嵌入的差分隐私条件变分自编码器联邦数据共享**

*Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig*

主要分类: cs.LG

摘要简述: 本文提出了一种基于差分隐私条件变分自编码器（DP-CVAE）的联邦数据共享方法，通过提取紧凑的嵌入表示，降低通信成本并支持多样化下游任务，同时确保隐私保护。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习在医学影像领域具有革命性影响，但数据稀缺和隐私法规限制了其广泛应用。联邦学习虽支持去中心化训练，但存在高通信成本和任务单一性问题。因此，需要一种既能保护隐私又能高效共享数据的方法。

研究方法: 采用基础模型提取紧凑且信息丰富的嵌入表示，减少冗余和计算开销。通过协作训练差分隐私条件变分自编码器（DP-CVAE），建模全局隐私感知的数据分布，支持多样化下游任务。

研究结果: 实验验证表明，该方法在隐私保护、可扩展性和效率方面优于传统联邦学习分类器，同时生成的嵌入表示比差分隐私条件生成对抗网络（DP-CGAN）具有更高的保真度，且参数数量减少5倍。

研究结论: 该方法通过差分隐私生成模型实现了高效、隐私保护的联邦数据共享，为多样化下游任务提供了灵活支持，同时显著降低了计算和通信成本。

中文摘要: 深度学习（DL）在医学影像领域带来了革命性变革，但其应用受限于数据稀缺和隐私法规，难以获取多样化数据集。联邦学习（FL）支持去中心化训练，但存在高通信成本和任务单一性问题。我们提出了一种基于差分隐私（DP）生成模型的数据共享方法。通过采用基础模型，提取紧凑且信息丰富的嵌入表示，减少冗余并降低计算开销。客户端协作训练差分隐私条件变分自编码器（DP-CVAE），建模全局隐私感知的数据分布，支持多样化下游任务。我们的方法在多种特征提取器上验证，提升了隐私保护、可扩展性和效率，优于传统联邦学习分类器，同时确保差分隐私。此外，DP-CVAE生成的嵌入表示比DP-CGAN具有更高的保真度，且参数数量减少5倍。

</details>


### [206] [Fast and Simplex: 2-Simplicial Attention in Triton](https://arxiv.org/abs/2507.02754)
**中文标题：快速与单纯：Triton中的2-单纯形注意力**

*Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil*

主要分类: cs.LG

摘要简述: 本文提出了一种名为2-单纯形Transformer的架构，通过高效的Triton内核实现，将标准点积注意力推广为三线性函数。实验表明，在固定token预算下，该架构在数学、编程、推理和逻辑任务中表现优于标准Transformer，显著提升了token效率。


<details>
  <summary>详细信息</summary>
研究动机: 随着现代大型语言模型越来越依赖海量互联网规模数据集，计算资源受限的假设逐渐失效。因此，需要设计能够优先考虑token效率的架构。本文旨在探索2-单纯形Transformer的潜力，以提升模型在有限token预算下的性能。

研究方法: 本文提出了一种2-单纯形Transformer架构，通过Triton内核实现高效的三线性注意力机制，替代标准的点积注意力。该方法在数学、编程、推理和逻辑任务中进行了验证。

研究结果: 实验结果表明，2-单纯形Transformer在固定token预算下，优于标准Transformer。具体表现为改变了知识和推理任务的缩放定律指数，显著提升了token效率。

研究结论: 2-单纯形Transformer通过三线性注意力机制，显著提升了token效率，为计算资源受限场景下的模型设计提供了新思路。

中文摘要: 近期研究表明，训练损失随模型规模和token数量呈幂律关系，而实现计算最优模型需要同时扩展模型规模和token数量。然而，这些缩放定律假设数据无限供应，且主要适用于计算资源受限的场景。随着现代大型语言模型越来越依赖海量互联网规模数据集，计算资源受限的假设逐渐失效，这凸显了对优先考虑token效率的架构的需求。
本文研究了2-单纯形Transformer的使用，该架构通过高效的Triton内核实现，将标准点积注意力推广为三线性函数。实验表明，2-单纯形Transformer在固定token预算下，比标准Transformer表现更优，尤其在数学、编程、推理和逻辑任务中。我们通过量化分析证明，2-单纯形注意力改变了知识和推理任务的缩放定律指数，相较于点积注意力具有显著优势。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [207] [FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference](https://arxiv.org/abs/2507.02620)
**中文标题：FlowSpec：基于连续流水线推测解码的高效分布式LLM推理框架**

*Xing Liu,Lizhuo Luo,Ming Tang,Chao Huang*

主要分类: cs.DC

摘要简述: FlowSpec是一种分布式LLM推理框架，通过流水线并行和树状推测解码技术，显著提升边缘设备上的推理效率，速度提升达1.36-1.77倍。


<details>
  <summary>详细信息</summary>
研究动机: 边缘设备上的稀疏推理请求导致现有流水线方法利用率低，FlowSpec旨在通过优化推测解码技术，提升分布式LLM推理的效率。

研究方法: FlowSpec结合了三种关键技术：1) 基于评分的分步验证优先处理重要草案令牌；2) 高效草案管理，修剪无效令牌并保持验证中的因果关系；3) 动态草案扩展策略，提供高质量推测输入。

研究结果: 实验表明，FlowSpec在多种模型和配置下显著提升推理速度，速度比基线快1.36-1.77倍。

研究结论: FlowSpec通过优化推测解码和流水线并行，有效提升了分布式LLM推理的效率，适用于边缘设备场景。

中文摘要: 分布式推理是实现大型语言模型（LLM）在边缘设备上推理的一种有前景的方法。它将推理过程分配到多个设备上，以确保LLM能够适应设备内存。最近的基于流水线的方法具有并行化通信和计算的潜力，有助于降低推理延迟。然而，当边缘设备的推理请求稀疏时，流水线的利用率通常较低，其优势会减弱。为了实现高效的分布式LLM边缘推理，我们提出了FlowSpec，一种基于流水线并行和树状推测解码的框架。FlowSpec包含三种关键技术以提高解码效率：1) 基于评分的分步验证优先处理更重要的草案令牌，以提前接受有效令牌；2) 高效的草案管理，在验证过程中修剪无效令牌并保持正确的因果关系；3) 动态草案扩展策略，提供高质量的推测输入。这些技术协同工作，提升了流水线利用率和推测效率。我们在真实测试平台上与其他基线方法进行了评估。实验结果表明，FlowSpec在不同模型和配置下显著提升了推理速度，速度比基线快1.36-1.77倍。我们的代码已公开在https://github.com/Leosang-lx/FlowSpec#。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [208] [Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis](https://arxiv.org/abs/2507.02176)
**中文标题：分析与改进语音合成中的说话人相似性评估**

*Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi*

主要分类: cs.SD

摘要简述: 本文探讨了语音合成中说话人相似性评估的局限性，发现常用的自动说话人验证（ASV）嵌入主要关注静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。作者提出了U3D指标以评估说话人的动态节奏模式，并公开了代码。


<details>
  <summary>详细信息</summary>
研究动机: 当前语音生成系统中，说话人身份通常通过自动说话人验证（ASV）嵌入进行评估，但这些嵌入设计用于区分而非全面表征身份。本文旨在研究这些嵌入捕捉了哪些声音特征，并解决其局限性。

研究方法: 作者分析了ASV嵌入的局限性，发现其忽略动态节奏特征。为此，提出了U3D指标，专门评估说话人的动态节奏模式，并提出了改进说话人相似性测量的策略。

研究结果: 研究发现，ASV嵌入主要关注静态特征（如音色和音高范围），而动态特征（如节奏）被忽视。U3D指标成功填补了这一空白，并公开了相关代码。

研究结论: 本文揭示了ASV嵌入在说话人相似性评估中的不足，并提出U3D指标以补充动态节奏特征的评估。这为语音克隆系统中说话人身份一致性的评估提供了新思路。

中文摘要: 由于声音身份的多维性，建模声音身份具有挑战性。在生成式语音系统中，身份通常通过自动说话人验证（ASV）嵌入进行评估，但这些嵌入设计用于区分而非全面表征身份。本文研究了这些嵌入捕捉了声音的哪些方面。我们发现，广泛使用的ASV嵌入主要关注静态特征（如音色和音高范围），而忽略了动态特征（如节奏）。我们还识别了影响说话人相似性测量的混杂因素，并提出了缓解策略。为填补这些空白，我们提出了U3D指标，用于评估说话人的动态节奏模式。这项工作为评估日益先进的语音克隆系统中说话人身份一致性的挑战做出了贡献。我们公开了相关代码。

</details>


### [209] [JoyTTS: LLM-based Spoken Chatbot With Voice Cloning](https://arxiv.org/abs/2507.02380)
**中文标题：JoyTTS：基于LLM的语音聊天机器人及语音克隆技术**

*Fangru Zhou,Jun Zhao,Guoxin Wang*

主要分类: cs.SD

摘要简述: JoyTTS是一个结合大型语言模型（LLM）和文本转语音（TTS）技术的端到端语音聊天机器人，具备语音克隆功能。基于开源模型MiniCPM-o和CosyVoice2，训练了2000小时的对话数据，并提供了完整的训练代码。测试结果显示，其说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。


<details>
  <summary>详细信息</summary>
研究动机: 开发一个结合LLM和TTS技术的语音聊天机器人，具备语音克隆功能，以提升对话体验的个性化和自然度。通过开源代码和模型，促进社区进一步开发和优化。

研究方法: 基于开源模型MiniCPM-o和CosyVoice2，训练了2000小时的对话数据，构建端到端的语音聊天机器人。提供了完整的训练代码和脚本，支持语音克隆功能。

研究结果: 在测试机器seed-tts-zh上，JoyTTS的说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。

研究结论: JoyTTS成功结合了LLM和TTS技术，实现了高相似度的语音克隆和低词错误率，为语音聊天机器人提供了新的解决方案。开源代码和模型将进一步推动社区发展。

中文摘要: JoyTTS是一个端到端的语音聊天机器人，结合了大型语言模型（LLM）和文本转语音（TTS）技术，具备语音克隆功能。该项目基于开源模型MiniCPM-o和CosyVoice2，并训练了2000小时的对话数据。我们还提供了完整的训练代码，以便社区进一步开发和优化。在测试机器seed-tts-zh上，其说话人相似度（SS）得分为0.73，词错误率（WER）为5.09。代码和模型，以及训练和推理脚本，可在https://github.com/jdh-algo/JoyTTS.git获取。

</details>


### [210] [ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning](https://arxiv.org/abs/2507.02666)
**中文标题：ASDA：用于自监督表示学习的音频谱图差分注意力机制**

*Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang*

主要分类: cs.SD

摘要简述: 本文提出了一种名为ASDA的音频谱图差分注意力机制，通过双软最大操作和差分系数优化，解决了传统Transformer注意力机制分配无效权重的问题，在多个音频任务中实现了SOTA性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的音频自监督表示学习中，Transformer的注意力机制常将部分权重分配给无关信息，影响模型的判别能力。为此，本文提出差分注意力机制以优化注意力分配。

研究方法: ASDA模型通过双软最大操作和差分系数调节，有效减少无效注意力分配，提升模型对音频谱图的关键信息捕捉能力。

研究结果: 实验表明，ASDA在音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词检测（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）中均达到SOTA性能。

研究结论: ASDA通过差分注意力机制显著提升了音频任务的性能，为更广泛的应用奠定了基础。

中文摘要: 在音频自监督表示学习的最新进展中，标准Transformer架构已成为主流方法，但其注意力机制常将部分权重分配给无关信息，可能削弱模型的判别能力。为解决这一问题，我们提出了一种差分注意力机制，通过双软最大操作和适当调节的差分系数，有效减少了无效注意力分配。实验结果表明，我们的ASDA模型在多个基准测试中实现了最先进的性能，包括音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词检测（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）。这些结果凸显了ASDA在音频任务中的有效性，为更广泛的应用铺平了道路。

</details>


### [211] [De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks](https://arxiv.org/abs/2507.02606)
**中文标题：De-AntiFake：重新思考针对语音克隆攻击的保护性扰动**

*Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu*

主要分类: cs.SD

摘要简述: 本文首次系统评估了针对语音克隆攻击的保护性扰动，发现现有净化方法虽能部分中和扰动，但仍会导致语音克隆模型性能下降。作者提出了一种新颖的两阶段净化方法，显著优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 随着语音生成模型的快速发展，语音克隆（VC）带来的隐私和安全问题日益突出。尽管已有研究通过引入对抗性扰动来干扰未经授权的语音克隆，但攻击者仍能通过净化技术绕过这些保护。因此，亟需重新评估这些保护性扰动的有效性。

研究方法: 作者提出了一种两阶段净化方法：1）净化受扰动的语音；2）通过音素引导将其与干净语音分布对齐。实验验证了该方法在破坏语音克隆防御上的优越性。

研究结果: 实验结果表明，现有净化方法虽能中和部分保护性扰动，但仍会导致语音克隆模型性能下降。作者的两阶段净化方法显著优于现有技术，揭示了对抗性扰动防御的局限性。

研究结论: 本研究揭示了基于对抗性扰动的语音克隆防御的局限性，并强调了开发更鲁棒解决方案的紧迫性，以应对语音克隆带来的安全和隐私风险。

中文摘要: 语音生成模型的快速发展加剧了与语音克隆（VC）相关的隐私和安全问题。近期研究探讨了通过引入对抗性扰动来干扰未经授权的语音克隆。然而，攻击者仍能通过净化技术绕过这些保护性扰动。本研究首次在包含扰动净化的实际威胁模型下，系统评估了这些保护性扰动对语音克隆的影响。研究发现，尽管现有净化方法能中和大部分保护性扰动，但仍会导致语音克隆模型特征空间的失真，从而降低其性能。基于此，我们提出了一种新颖的两阶段净化方法：1）净化受扰动的语音；2）通过音素引导将其与干净语音分布对齐。实验结果表明，我们的方法在破坏语音克隆防御上优于现有净化技术。本研究揭示了基于对抗性扰动的语音克隆防御的局限性，并强调了开发更鲁棒解决方案的紧迫性，以应对语音克隆带来的安全和隐私风险。代码和音频样本可在https://de-antifake.github.io获取。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [212] [Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents](https://arxiv.org/abs/2507.02287)
**中文标题：透视绿色：基于文本的分类与绿色专利的企业回报**

*Lapo Santarlasci,Armando Rungi,Antonio Zinilli*

主要分类: econ.GN

摘要简述: 本文利用自然语言处理技术从官方支持文件中识别“真实”绿色专利，发现仅占先前文献分类的20%，并证实持有此类专利能提升企业销售、市场份额和生产力。


<details>
  <summary>详细信息</summary>
研究动机: 现有绿色专利分类方法可能不够精确，需通过文本分析更准确识别真实绿色专利，以支持政策制定和企业决策。

研究方法: 使用约1240万份被先前文献分类为绿色的专利数据，训练神经网络扩展基础词典，通过向量表示与环境技术相关的表达。

研究结果: 真实绿色专利仅占先前分类的20%，且被后续发明引用率低1%。持有真实绿色专利的企业在销售、市场份额和生产力方面表现更优，高创新性专利还能带来更高利润。

研究结论: 文本分析能提供更精细的专利分类，对政策制定和企业战略具有重要价值。

中文摘要: 本文引入自然语言处理技术，从官方支持文件中识别“真实”绿色专利。我们从先前文献分类的约1240万份绿色专利开始训练，通过神经网络扩展基础词典，利用与环境技术相关的表达向量表示。测试发现，真实绿色专利仅占先前分类的20%，且技术类别存在异质性，被后续发明引用率低1%。在第二部分，我们测试了专利与欧盟企业财务指标的关系，控制反向因果后，持有至少一份真实绿色专利能提升销售、市场份额和生产力。若限制分析高创新性真实绿色专利，还能带来更高利润。研究强调了文本分析在精细专利分类中的重要性，对多领域政策制定具有价值。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [213] [Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain](https://arxiv.org/abs/2507.02016)
**中文标题：对信念-愿望-意图机器人的有效解释：何时及解释什么**

*Cong Wang,Roberto Calandra,Verena Klös*

主要分类: cs.RO

摘要简述: 研究探讨了在机器人执行复杂任务时，如何通过解释其推理过程来帮助用户理解其意图，并提出了两种算法以识别意外行为并生成有效解释。


<details>
  <summary>详细信息</summary>
研究动机: 当机器人在日常生活中执行复杂且依赖上下文的任务时，其行为可能与用户预期不符，导致用户困惑。通过解释机器人的推理过程，可以帮助用户理解其意图，但解释的时机和内容需合理以避免用户反感。

研究方法: 研究调查了用户对机器人解释需求和内容的偏好，针对厨房清洁任务中的机器人行为。基于调查结果，提出了两种算法：一种用于识别意外行为，另一种用于构建有效的解释。这些算法可轻松集成到BDI推理过程中。

研究结果: 用户希望在意外情况下获得解释，并偏好简洁的解释，明确说明行为背后的意图及相关上下文因素。提出的算法能够有效识别意外行为并生成用户友好的解释。

研究结论: 研究为BDI机器人提供了实用的解释生成方法，改善了人机交互体验，特别是在依赖上下文和用户特定需求的情境中。

中文摘要: 当机器人在日常生活中执行复杂且依赖上下文的任务时，其行为可能与用户预期不符，导致用户困惑。解释机器人的推理过程可以帮助用户理解其意图。然而，解释的时机和内容对于避免用户反感至关重要。我们调查了用户对解释需求和内容的偏好，研究对象为协助厨房日常清洁任务的机器人。结果显示，用户希望在意外情况下获得解释，并偏好简洁的解释，明确说明行为背后的意图及相关上下文因素。基于这些发现，我们提出了两种算法，用于识别意外行为并为BDI机器人构建有效解释。这些算法可轻松集成到BDI推理过程中，为依赖上下文和用户特定需求的人机交互提供了更好的途径。

</details>


### [214] [Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN](https://arxiv.org/abs/2507.02171)
**中文标题：基于自监督循环神经网络的生物启发式机器人轨迹规划**

*Miroslav Cibula,Kristína Malinovská,Matthias Kerzel*

主要分类: cs.RO

摘要简述: 本文提出了一种基于自监督循环神经网络的生物启发式机器人轨迹规划方法，通过结合正向和逆向运动学模型，实现了高效且自适应的轨迹生成。


<details>
  <summary>详细信息</summary>
研究动机: 传统的机器人轨迹规划方法（如基于采样的规划器）计算成本高，而现有的监督学习方法仅模仿轨迹而无法评估其是否成功达到目标。本文旨在提出一种自监督学习方法，结合认知启发，实现更高效的轨迹规划。

研究方法: 采用自监督学习方案，基于循环神经网络构建轨迹模型，利用给定的正向和逆向运动学模型生成轨迹，无需依赖大量标注数据。

研究结果: 实验表明，该方法能够仅通过正向和逆向运动学模型学习生成有效轨迹，适用于需要自适应解决方案的复杂操作任务。

研究结论: 提出的自监督学习方法为机器人轨迹规划提供了一种高效且灵活的解决方案，有望应用于更复杂的任务场景。

中文摘要: 机器人轨迹规划是指生成一系列关节配置，使机器人或其机械臂从初始状态到达目标状态，同时考虑机器人运动学和环境约束。传统方法通常采用基于采样的规划器，计算量大。近期研究表明，轨迹规划也可以通过监督序列学习实现，仅需单次或固定次数的神经网络计算，确保计算时间可控。然而，这种完全监督方法仅模仿轨迹，无法评估其是否成功达到目标。本文在此基础上提出了一种基于循环神经网络的自监督学习方案，用于构建轨迹模型。通过在机器人臂的运动规划任务中评估该方法的可行性，结果表明，模型能够仅利用给定的正向和逆向运动学模型学习生成轨迹。这一新方法有望为需要自适应解决方案的复杂操作任务提供更高效的规划支持。

</details>


### [215] [MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping](https://arxiv.org/abs/2507.02672)
**中文标题：MISCGrasp：利用多尺度集成和对比学习增强体积抓取**

*Qingyu Fan,Yinghao Cai,Chao Li,Chunting Jiao,Xudong Zheng,Tao Lu,Bin Liang,Shuo Wang*

主要分类: cs.RO

摘要简述: MISCGrasp提出了一种结合多尺度特征提取和对比学习的体积抓取方法，通过Insight Transformer和Empower Transformer实现高低层特征的交互与选择，提升自适应抓取能力。实验证明其在模拟和真实环境中优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 机器人抓取在面对形状和大小各异的物体时存在适应性挑战。本文旨在通过多尺度特征提取和对比学习，提升抓取方法的自适应性和性能。

研究方法: MISCGrasp结合多尺度特征提取和对比学习，使用Insight Transformer实现高低层特征的交互，Empower Transformer选择最高层特征，平衡几何细节与整体结构。多尺度对比学习确保特征一致性。

研究结果: 在模拟和真实环境的桌面整理任务中，MISCGrasp表现优于基线方法和变体方法。

研究结论: MISCGrasp通过多尺度特征和对比学习的结合，显著提升了机器人抓取的自适应性和性能，为复杂环境下的抓取任务提供了有效解决方案。

中文摘要: 机器人抓取在适应形状和大小各异的物体时面临挑战。本文提出MISCGrasp，一种结合多尺度特征提取和对比特征增强的自适应体积抓取方法。通过Insight Transformer实现高低层特征的查询式交互，Empower Transformer选择性关注最高层特征，平衡几何细节与整体结构。此外，MISCGrasp利用多尺度对比学习挖掘正抓取样本间的相似性，确保多尺度特征的一致性。在模拟和真实环境中的大量实验表明，MISCGrasp在桌面整理任务中优于基线方法和变体方法。更多细节请访问https://miscgrasp.github.io/。

</details>


### [216] [MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real](https://arxiv.org/abs/2507.02864)
**中文标题：MultiGen：利用模拟中的多模态生成学习真实世界的多模态策略**

*Renhao Wang,Haoran Geng,Tingle Li,Feishi Wang,Gopala Anumanchipalli,Philipp Wu,Trevor Darrell,Boyi Li,Pieter Abbeel,Jitendra Malik,Alexei A. Efros*

主要分类: cs.RO

摘要简述: MultiGen框架通过将大规模生成模型与传统物理模拟器结合，实现多感官模拟，解决了多模态策略学习的挑战，并在机器人倒水任务中展示了零样本迁移到真实世界的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 机器人需要整合多种感官模态以在现实世界中有效行动，但多模态策略的大规模学习仍具挑战性。模拟器虽为解决方案，但除视觉外，其他模态（如声音）难以模拟，导致多模态模拟到现实的迁移尚未实现。

研究方法: MultiGen框架将大规模生成模型与传统物理模拟器结合，通过合成基于模拟视频的真实音频，实现多感官模拟，无需真实机器人数据即可训练丰富的视听轨迹。

研究结果: 在机器人倒水任务中，MultiGen展示了零样本迁移到真实世界的能力，能够处理新容器和液体，验证了生成模型在模拟难以建模的模态和缩小多模态模拟与现实差距方面的潜力。

研究结论: MultiGen通过生成模型实现了多感官模拟，为多模态策略学习提供了新途径，并成功展示了其在真实世界任务中的零样本迁移能力。

中文摘要: 机器人需要整合多种感官模态以在现实世界中有效行动，但多模态策略的大规模学习仍具挑战性。模拟器虽为解决方案，但除视觉外，其他模态（如声音）难以模拟，导致多模态模拟到现实的迁移尚未实现。本文提出MultiGen框架，通过将大规模生成模型与传统物理模拟器结合，实现多感官模拟。我们以机器人倒水任务为例，该任务依赖多模态反馈。通过合成基于模拟视频的真实音频，我们的方法能够训练丰富的视听轨迹，而无需任何真实机器人数据。实验表明，MultiGen能够零样本迁移到真实世界的倒水任务中，处理新容器和液体，展示了生成模型在模拟难以建模的模态和缩小多模态模拟与现实差距方面的潜力。

</details>
