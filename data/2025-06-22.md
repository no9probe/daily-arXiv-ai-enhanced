<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 51]
- [cs.CV](#cs.CV) [Total: 65]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.SD](#cs.SD) [Total: 3]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.DC](#cs.DC) [Total: 2]
- [eess.IV](#eess.IV) [Total: 12]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 40]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.IT](#cs.IT) [Total: 1]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [math.ST](#math.ST) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [stat.OT](#stat.OT) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.SI](#cs.SI) [Total: 2]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.HC](#cs.HC) [Total: 9]
- [cs.RO](#cs.RO) [Total: 6]
- [cs.CY](#cs.CY) [Total: 3]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [math.NA](#math.NA) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
**中文标题：出院摘要中的不良事件提取：新数据集、标注方案及初步发现**

*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

主要分类: cs.CL

摘要简述: 本文提出了一种针对老年患者出院摘要中不良事件（AE）提取的手动标注数据集，包含14种临床重要AE及上下文属性。通过多粒度标注和模型评估，发现尽管文档级粗粒度提取表现优异，但细粒度实体级任务仍面临挑战。数据集可用于未来AE提取方法的评估。


<details>
  <summary>详细信息</summary>
研究动机: 老年患者在临床自然语言处理（NLP）资源中代表性不足，且现有研究很少解决不连续和重叠实体的标注问题。本文旨在填补这一空白，提供更全面的AE提取数据集和方法评估。

研究方法: 研究构建了一个手动标注的AE数据集，包含14种临床重要AE及上下文属性（如否定、诊断类型等）。采用FlairNLP评估了多种模型在三种标注粒度（细粒度、粗粒度、带否定的粗粒度）上的表现。

研究结果: 基于Transformer的模型（如BERT-cased）在文档级粗粒度提取中表现优异（F1=0.943），但在细粒度实体级任务中表现显著下降（F1=0.675），尤其是对罕见事件和复杂属性的识别。

研究结论: 尽管在粗粒度任务中表现良好，但细粒度AE提取仍面临挑战，尤其是在识别代表性不足的AE和复杂临床语言方面。数据集为未来研究提供了重要基准。

中文摘要: 本研究提出了一种针对老年患者出院摘要中不良事件（AE）提取的手动标注语料库，填补了临床NLP资源中老年患者代表性不足的空白。数据集包含14种临床重要AE（如跌倒、谵妄、颅内出血等）及其上下文属性（如否定、诊断类型、院内发生等）。独特的标注方案支持不连续和重叠实体，解决了以往研究未充分探讨的挑战。通过FlairNLP评估了多种模型在三种标注粒度（细粒度、粗粒度、带否定的粗粒度）上的表现。结果显示，基于Transformer的模型（如BERT-cased）在文档级粗粒度提取中表现优异（F1=0.943），但在细粒度实体级任务中表现显著下降（F1=0.675），尤其是对罕见事件和复杂属性的识别。这些结果表明，尽管在粗粒度任务中表现良好，但在检测代表性不足的AE和捕捉复杂临床语言方面仍存在显著挑战。数据集在可信研究环境（TRE）中开发，可通过DataLoch申请获取，为评估AE提取方法和支持未来跨数据集泛化提供了重要基准。

</details>


### [2] [Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction](https://arxiv.org/abs/2506.14901)
**中文标题：通过增强结合约束与无约束解码：BoostCD及其在信息提取中的应用**

*Marija Šakota,Robert West*

主要分类: cs.CL

摘要简述: 本文提出了一种名为BoostCD的方法，通过结合约束解码和无约束解码的两阶段解码策略，提升结构化NLP任务的性能。实验表明，该方法在封闭信息提取任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于自回归语言模型的结构化NLP任务方法在训练时无需显式约束，但测试时的约束解码可能导致输出质量低下。本文旨在解决这一问题。

研究方法: BoostCD分为两阶段：第一阶段分别进行约束和无约束解码，生成两个弱预测；第二阶段通过学习的自回归增强模型将两者结合为最终预测。

研究结果: 在封闭信息提取任务中，BoostCD的表现优于现有方法，且能解决其他方法中的常见错误。

研究结论: BoostCD通过结合约束和无约束解码，显著提升了结构化NLP任务的性能，尤其在封闭信息提取中表现突出。

中文摘要: 近年来，许多结构化NLP任务的方法使用自回归语言模型$M$将非结构化输入文本$x$映射为表示结构化对象（如元组、列表、树、代码等）的输出文本$y$，并通过约束解码强制输出结构。在训练时，这些方法无需模型显式了解约束，约束仅隐含在训练输出$y$中。这种方法的优势在于支持动态约束而无需重新训练，但在测试时的约束解码可能导致输出质量低下。我们通过增强约束解码（BoostCD）解决了这一问题，该方法分两阶段结合约束和无约束解码：第一阶段从基础模型$M$分别进行约束和无约束解码，得到两个弱预测；第二阶段通过学习的自回归增强模型将两者结合为最终预测。基础模型在有约束和无约束下的错误往往是互补的，增强模型通过学习利用这一点提升性能。我们通过将BoostCD应用于封闭信息提取任务展示了其优势。我们的模型BoostIE在分布内外均优于现有方法，并解决了这些方法中的常见错误。

</details>


### [3] [CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision](https://arxiv.org/abs/2506.14912)
**中文标题：CrEst：基于弱监督的大语言模型上下文可信度估计**

*Dyah Adila,Shuai Zhang,Boran Han,Bonan Min,Yuyang Wang*

主要分类: cs.CL

摘要简述: 本文提出CrEst框架，通过弱监督方法评估大语言模型（LLM）上下文文档的可信度，无需人工标注，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法常忽略上下文文档的可信度差异，可能导致不可靠信息的传播。本文旨在解决这一问题，提出自动化可信度评估框架。

研究方法: CrEst基于可信文档间语义一致性更高的假设，通过文档间一致性自动评估可信度。提出两种集成策略：黑盒方法（无内部权重访问）和白盒方法（修改注意力机制）。

研究结果: 在三种模型架构和五个数据集上的实验表明，CrEst显著优于基线方法，准确率提升26.86%，F1分数提高3.49%，且在噪声环境下表现稳健。

研究结论: CrEst通过弱监督方法有效评估上下文可信度，提升LLM性能，为可信信息集成提供了实用解决方案。

中文摘要: 上下文信息的集成显著提升了大语言模型（LLM）在知识密集型任务中的表现。然而，现有方法常忽略一个关键挑战：上下文文档的可信度差异可能导致不可靠信息的传播。本文提出CrEst，一种无需人工标注的弱监督框架，用于在LLM推理过程中评估上下文文档的可信度。我们的方法基于可信文档间语义一致性更高的假设，通过文档间一致性实现自动化可信度评估。为将可信度融入LLM推理，我们提出两种集成策略：黑盒方法（适用于无法访问内部权重的模型）和白盒方法（直接修改注意力机制）。在三种模型架构和五个数据集上的广泛实验表明，CrEst始终优于强基线方法，准确率最高提升26.86%，F1分数提高3.49%。进一步分析显示，CrEst在高噪声条件下仍保持稳健性能。

</details>


### [4] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
**中文标题：MDBench：基于知识引导合成的多文档推理基准**

*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

主要分类: cs.CL

摘要简述: MDBench是一个通过知识引导合成的多文档推理基准数据集，旨在评估大型语言模型在多文档推理任务中的表现。其创新生成方法能够高效且可控地生成具有挑战性的文档集和问答示例，为模型能力分析提供新工具。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）推理能力的快速扩展，多文档推理领域的评估需求日益迫切。然而，由于长文本标注成本高昂，现有基准数据集稀缺。因此，研究团队开发了MDBench，填补这一空白。

研究方法: MDBench采用了一种新颖的合成生成方法：首先基于结构化的种子知识，通过LLM辅助编辑引入多文档推理的挑战；随后将结构化知识转换为自然文本形式，生成文档集及对应的问答示例。

研究结果: 实验表明，MDBench对当前流行的LLMs和提示技术均构成显著挑战，即使文档集较短。此外，知识引导的生成技术能够快速适应新挑战，并支持针对多文档推理能力的定向分析。

研究结论: MDBench为多文档推理任务提供了高效且可控的评估工具，其生成方法不仅填补了现有基准的不足，还为未来模型改进提供了灵活的分析框架。

中文摘要: 自然语言处理评估的进展主要得益于大型语言模型（LLMs）的快速发展。随着LLMs推理能力的迅速提升，新的评估基准变得尤为重要。多文档（MD）推理因其对长上下文输入的处理能力而备受关注，但现有基准寥寥无几，且长文本标注成本高昂。为此，我们提出了MDBench，一个用于评估LLMs在多文档推理任务中的新数据集。MDBench通过一种创新的合成生成方法，能够高效且可控地生成具有挑战性的文档集及对应的问答示例。我们的技术基于结构化的种子知识，通过LLM辅助编辑引入多文档推理的挑战，并将其转换为自然文本形式。实验表明，MDBench对所有流行LLMs和提示技术均构成显著挑战。此外，知识引导的生成技术不仅支持针对多文档推理能力的定向分析，还能快速适应新挑战和未来模型改进。

</details>


### [5] [From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?](https://arxiv.org/abs/2506.14949)
**中文标题：从聊天到检查：大型语言模型能否辅助糖尿病预测？**

*Shadman Sakib,Oishy Fatema Akhand,Ajwad Abrar*

主要分类: cs.CL

摘要简述: 本研究探讨了大型语言模型（LLMs）在糖尿病预测中的潜力，通过零样本、单样本和三样本提示方法，比较了开源与专有LLMs的性能，并发现专有模型（如GPT-4o）表现更优，甚至超越传统机器学习模型。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习和深度学习模型已广泛用于糖尿病预测，但大型语言模型（LLMs）在结构化数值数据中的应用尚未充分探索。本研究旨在填补这一空白，验证LLMs在医疗预测任务中的有效性。

研究方法: 研究使用Pima印度糖尿病数据库（PIDD），测试了六种LLMs（包括开源和专有模型）的预测能力，并与随机森林、逻辑回归和支持向量机等传统模型进行比较。评估指标包括准确率、精确率、召回率和F1分数。

研究结果: 结果显示，专有LLMs（如GPT-4o和Gemma-2-27B）在少样本设置下表现优于开源模型，且Gemma-2-27B的F1分数超过传统模型。但性能因提示策略不同而波动，且需领域微调。

研究结论: 研究表明LLMs可用于医疗预测任务，未来需优化提示工程和混合方法以提升性能。

中文摘要: 尽管机器学习和深度学习模型已广泛用于糖尿病预测，但大型语言模型（LLMs）在结构化数值数据中的应用尚未充分探索。本研究测试了LLMs在糖尿病预测中的有效性，采用零样本、单样本和三样本提示方法。我们使用Pima印度糖尿病数据库（PIDD）进行实证分析，评估了六种LLMs（包括四种开源模型和两种专有模型），并与随机森林、逻辑回归和支持向量机等传统模型进行比较。评估指标包括准确率、精确率、召回率和F1分数。结果显示，专有LLMs表现优于开源模型，其中GPT-4o和Gemma-2-27B在少样本设置下准确率最高。值得注意的是，Gemma-2-27B的F1分数也超过了传统模型。然而，仍存在提示策略导致的性能波动和领域微调需求等问题。研究表明LLMs可用于医疗预测任务，并鼓励未来在提示工程和混合方法上的研究以改进医疗预测。

</details>


### [6] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
**中文标题：记忆令牌：大型语言模型可生成可逆的句子嵌入**

*Ignacio Sastre,Aiala Rosá*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLM）能够生成可逆的句子嵌入，通过引入特殊记忆令牌，模型无需修改权重即可精确重建原始文本。这一现象在多种语言和模型规模下均得到验证。


<details>
  <summary>详细信息</summary>
研究动机: 探索大型语言模型是否能够生成可逆的句子嵌入，以实现精确的文本重建，并研究其潜在应用价值。

研究方法: 通过引入特殊记忆令牌，优化其嵌入训练固定序列，使模型在提示该嵌入时能精确重建原始文本。实验覆盖英语和西班牙语数据集，序列长度约240个令牌，模型规模从1亿到80亿参数。

研究结果: 实验表明，Llama 3.1 8B模型能够成功重建所有测试序列，验证了LLM在可逆嵌入生成方面的能力。

研究结论: 研究揭示了LLM在可逆嵌入生成方面的潜力，为基于记忆的检索、文本压缩和可控文本生成提供了新思路。

中文摘要: 本研究发现了一种有趣现象：无需修改模型权重，即可生成可逆的句子嵌入，使大型语言模型（LLM）能够精确重建原始文本。这是通过引入一种特殊记忆令牌实现的，其嵌入通过固定序列的训练优化。当提示该嵌入时，模型能够精确重建固定序列。我们在英语和西班牙语数据集、约240个令牌的序列以及1亿到80亿参数的模型规模下评估了这一现象。值得注意的是，Llama 3.1 8B成功重建了所有测试序列。这一发现凸显了LLM的有趣能力，并为其在记忆检索、压缩和可控文本生成中的应用提供了可能。

</details>


### [7] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
**中文标题：使用主题建模和文本分类方法识别NVDRS文本叙事中的社会隔离主题**

*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

主要分类: cs.CL

摘要简述: 本研究利用主题建模和文本分类方法，从NVDRS文本叙事中识别社会隔离主题，开发高质量分类器，并发现男性、同性恋和离婚者更易被归类为慢性社会隔离。


<details>
  <summary>详细信息</summary>
研究动机: 近年来社会隔离和孤独感加剧，与自杀率上升密切相关。然而，美国国家暴力死亡报告系统（NVDRS）的结构化变量中未记录这些现象，因此需要通过自然语言处理技术从执法和法医叙事中识别。

研究方法: 采用主题建模生成词典开发，并结合监督学习分类器，开发高质量分类器（平均F1值0.86，准确率0.82）。分析了2002年至2020年超过30万例自杀案例。

研究结果: 识别出1,198例提及慢性社会隔离的案例。男性、同性恋和离婚者被归类为慢性社会隔离的几率更高。其他显著预测因素包括近期或即将离婚、失去子女监护权、被驱逐或近期搬家以及分手。

研究结论: 该方法可提升美国社会隔离和孤独感的监测与预防能力。

中文摘要: 近年来，社会隔离和孤独感日益加剧，显著推高了自杀率。尽管美国国家暴力死亡报告系统（NVDRS）的结构化变量中未记录这些现象，但可通过自然语言处理（NLP）技术从执法和法医叙事中识别。通过主题建模生成词典开发并结合监督学习分类器，我们开发了高质量分类器（平均F1值0.86，准确率0.82）。在分析2002年至2020年超过30万例自杀案例后，识别出1,198例提及慢性社会隔离的案例。男性（OR=1.44；CI:1.24,1.69,p<.0001）、同性恋（OR=3.68；1.97,6.33,p<.0001）和离婚者（OR=3.34；2.68,4.19,p<.0001）被归类为慢性社会隔离的几率更高。我们还发现近期或即将离婚、失去子女监护权、被驱逐或近期搬家以及分手等其他社会隔离主题的显著预测因素。该方法可提升美国社会隔离和孤独感的监测与预防能力。

</details>


### [8] [Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation](https://arxiv.org/abs/2506.15068)
**中文标题：语义感知奖励在自由生成长文本中的开放训练**

*Zongxia Li,Yapei Chang,Yuhang Zhou,Xiyang Wu,Zichao Liang,Yoo Yeon Sung,Jordan Lee Boyd-Graber*

主要分类: cs.CL

摘要简述: 本文提出PrefBERT模型，用于评估和指导开放生成长文本的训练，通过语义奖励反馈优于传统指标ROUGE-L和BERTScore，并验证其与人类偏好的一致性。


<details>
  <summary>详细信息</summary>
研究动机: 开放生成长文本的评估因难以区分好坏输出而具有挑战性，现有方法常忽略关键因素如连贯性、风格或相关性，或受预训练数据偏差影响。本文旨在填补这一空白。

研究方法: 提出PrefBERT评分模型，基于多样化的长文本风格和质量评分数据集训练，为GRPO提供语义奖励反馈，并通过LLM评估、人类评分和定性分析验证其可靠性。

研究结果: PrefBERT在多样长文本中表现可靠，与传统指标相比，其作为奖励信号训练的策略模型生成更符合人类偏好的响应。

研究结论: PrefBERT为开放生成长文本的评估和训练提供了有效的语义奖励反馈，显著优于传统指标，且与人类偏好高度一致。

中文摘要: 评估开放生成长文本具有挑战性，因为难以明确区分好坏输出。现有方法常忽略连贯性、风格或相关性等关键因素，或受预训练数据偏差影响，使得开放生成长文本评估成为未充分探索的问题。为解决这一问题，我们提出PrefBERT，一种用于评估开放生成长文本的评分模型，并通过区分好坏输出的奖励指导GRPO训练。PrefBERT基于两种包含多样化长文本风格和Likert评分的响应评估数据集训练，为GRPO提供比传统指标ROUGE-L和BERTScore更优的语义奖励反馈。通过包括LLM评估、人类评分和定性分析在内的全面评估，我们表明PrefBERT在多样长文本中表现可靠，并与GRPO所需的可验证奖励高度一致。人类评估证实，使用PrefBERT作为奖励信号训练的策略模型生成的响应比传统指标训练的响应更符合人类偏好。代码发布于https://github.com/zli12321/long_form_rl。

</details>


### [9] [Learning-Time Encoding Shapes Unlearning in LLMs](https://arxiv.org/abs/2506.15076)
**中文标题：学习阶段的编码方式塑造大型语言模型的遗忘能力**

*Ruihan Wu,Konstantin Garov,Kamalika Chaudhuri*

主要分类: cs.CL

摘要简述: 研究发现学习阶段的知识编码方式对大型语言模型（LLM）的遗忘能力有重要影响，尤其是使用转述描述学习可提升遗忘效果，但遗忘文本块中的单个知识点仍具挑战性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在现实中的广泛应用，如何“遗忘”特定知识（如隐私数据或有害内容）成为关键需求。现有研究多假设训练过程固定，本文探讨学习阶段知识编码对遗忘效果的影响。

研究方法: 通过实验研究学习阶段知识编码方式对遗忘能力的影响，重点关注转述描述学习和文本块中单个知识点的遗忘难度。

研究结果: 实验表明：1）使用转述描述学习可提升遗忘效果；2）遗忘文本块中的单个知识点较为困难。

研究结论: 学习阶段的知识编码对实现可靠的遗忘能力至关重要，未来研究需关注编码方式的优化。

中文摘要: 随着大型语言模型（LLM）在现实中的广泛应用，如何“遗忘”特定知识（如隐私数据或有害内容）成为关键需求。现有研究多假设训练过程固定，本文通过实验探讨学习阶段知识编码对遗忘效果的影响。研究发现：1）使用转述描述学习可提升遗忘效果；2）遗忘文本块中的单个知识点较为困难。结果表明，学习阶段的知识编码对实现可靠的遗忘能力至关重要。

</details>


### [10] [Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification](https://arxiv.org/abs/2506.15081)
**中文标题：通过话语感知的语句澄清改进对话话语解析**

*Yaxin Fan,Peifeng Li,Qiaoming Zhu*

主要分类: cs.CL

摘要简述: 本文提出了一种基于话语感知的澄清模块（DCM）和贡献感知偏好优化（CPO）的方法，用于解决对话话语解析中的歧义问题，显著提升了解析性能。


<details>
  <summary>详细信息</summary>
研究动机: 对话中的省略和习语等语言特征常导致话语关系模糊，给解析带来挑战。本文旨在通过澄清模块和优化方法解决这一问题。

研究方法: 提出DCM模块，包含澄清类型推理和话语目标推理，分别分析语言特征和区分模糊关系；引入CPO方法，评估澄清贡献并优化DCM。

研究结果: 在STAC和Molweni数据集上的实验表明，该方法有效解决歧义，性能显著优于现有基线。

研究结论: DCM和CPO的结合显著提升了对话话语解析的准确性和适应性，为相关研究提供了新思路。

中文摘要: 对话话语解析旨在识别和分析对话中语句间的话语关系。然而，对话中的语言特征（如省略和习语）常引入歧义，掩盖了预期的话语关系，给解析带来挑战。为解决这一问题，我们提出了一种话语感知澄清模块（DCM）以提升解析性能。DCM采用两种推理过程：澄清类型推理和话语目标推理。前者分析语言特征，后者区分模糊关系与预期关系。此外，我们引入了贡献感知偏好优化（CPO）以减少错误澄清的风险，从而降低级联错误。CPO使解析器能够评估DCM澄清的贡献并提供反馈以优化DCM，增强其适应性与解析器需求的匹配。在STAC和Molweni数据集上的大量实验表明，我们的方法有效解决了歧义问题，并显著优于现有基线。

</details>


### [11] [CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records](https://arxiv.org/abs/2506.15118)
**中文标题：CKD-EHR：基于电子健康记录的临床知识蒸馏**

*Junke Wang,Hongshun Ling,Li Zhang,Longqian Zhang,Fang Wang,Yuan Gao,Zhi Li*

主要分类: cs.CL

摘要简述: 本文提出CKD-EHR框架，通过知识蒸馏技术提升电子健康记录（EHR）的疾病预测效率与准确性，显著优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有大型语言模型在医疗知识表示不足和临床部署效率低方面存在挑战，需改进以支持精准医疗和早期干预。

研究方法: 首先微调Qwen2.5-7B作为教师模型，生成可解释的软标签；然后通过多粒度注意力蒸馏机制将知识迁移至轻量级BERT学生模型。

研究结果: 在MIMIC-III数据集上，CKD-EHR诊断准确率提升9%，F1分数提高27%，推理速度加快22.2倍。

研究结论: CKD-EHR显著提升资源利用效率和诊断准确性，为临床资源优化提供实用技术方案。

中文摘要: 基于电子健康记录（EHR）的疾病预测模型在推动精准医疗和早期干预方面具有重要临床价值。然而，现有大型语言模型面临两大挑战：医疗知识表示不足和临床部署效率低。为解决这些问题，本研究提出CKD-EHR（基于EHR的临床知识蒸馏）框架，通过知识蒸馏技术实现高效准确的疾病风险预测。具体而言，首先在医学知识增强数据上微调大型语言模型Qwen2.5-7B作为教师模型，并通过多粒度注意力蒸馏机制生成可解释的软标签。最后，将蒸馏的知识迁移至轻量级BERT学生模型。实验结果表明，在MIMIC-III数据集上，CKD-EHR显著优于基线模型：诊断准确率提升9%，F1分数提高27%，推理速度加快22.2倍。这一创新解决方案不仅大幅提升资源利用效率，还显著增强诊断的准确性和时效性，为临床资源优化提供了实用技术途径。本研究的代码和数据可在https://github.com/209506702/CKD_EHR获取。

</details>


### [12] [Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs](https://arxiv.org/abs/2506.15131)
**中文标题：基于大语言模型的开放域对话一对多特性建模**

*Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan*

主要分类: cs.CL

摘要简述: 本文提出了一种基于LLM的两阶段框架，通过多响应生成和偏好选择任务，显式建模开放域对话的一对多特性，显著提升了响应多样性和质量。


<details>
  <summary>详细信息</summary>
研究动机: 开放域对话具有一对多特性，即单一对话上下文可对应多个合理响应。尽管研究表明显式建模此特性可提升多样性，但现有LLM对话代理大多未实现。本文旨在填补这一空白。

研究方法: 将开放域对话生成分解为多响应生成（MRG）和基于偏好的选择（PS）两阶段任务。提出o2mDial语料库以支持MRG和PS，并设计新的上下文学习和指令微调策略，以及MRG评估指标和PS模型方法。

研究结果: 实验表明，该框架显著提升了较小LLM的响应多样性和质量（提升达90%），使其接近更大模型的性能。

研究结论: 通过显式建模一对多特性，两阶段框架有效提升了开放域对话的多样性和质量，为LLM对话代理设计提供了新思路。

中文摘要: 开放域对话（OD）具有一对多（o2m）特性，即单一对话上下文可对应多个合理响应。尽管先前研究表明显式建模此特性可提升响应多样性，但现有基于大语言模型（LLM）的对话代理大多未实现。本文通过将OD生成分解为多响应生成（MRG）和基于偏好的选择（PS）两阶段任务，显式建模o2m特性。为支持MRG和PS，我们提出o2mDial语料库，其中每个上下文对应多个合理响应。基于o2mDial，我们设计了新的上下文学习和指令微调策略，以及MRG评估指标和PS模型方法。实验结果表明，该框架显著提升了较小LLM的响应多样性和质量（提升达90%），使其接近更大模型的性能。

</details>


### [13] [Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models](https://arxiv.org/abs/2506.15138)
**中文标题：Thunder-Tok：为生成式语言模型设计的最小化韩语文本分词数量的分词器**

*Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee*

主要分类: cs.CL

摘要简述: 本文介绍了Thunder-Tok，一种新型韩语分词器，旨在减少分词数量而不影响模型性能。通过基于规则的分词方法和分支熵选择算法，显著降低了分词数量并提升了推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有韩语分词器在生成式语言模型中存在分词数量过多的问题，导致推理效率低下。本文旨在设计一种高效的分词器，减少分词数量同时保持模型性能。

研究方法: 采用基于规则的分词方法，结合韩语的语言结构，并利用分支熵选择算法优化种子词汇表，从而增加平均分词长度，降低分词数量。

研究结果: 实验表明，Thunder-Tok相比BPE分词器减少了约10%的分词数量，推理速度提升了10%，且在下游任务中性能未受影响。

研究结论: Thunder-Tok通过结合语言学知识的分词方法，为韩语生成式语言模型提供了一种高效且实用的分词解决方案。

中文摘要: 本文介绍了Thunder-Tok，一种新型韩语分词器，旨在减少分词数量而不影响模型性能。我们的方法采用基于规则的分词技术，结合韩语的语言结构，并利用分支熵选择算法优化种子词汇表。这些技术显著增加了平均分词长度，从而降低分词数量同时保留语言信息。实验结果表明，与BPE分词器相比，Thunder-Tok减少了约10%的分词数量（即分词数量减少10%，推理速度提升10%），且在各种下游任务中性能未受影响。这些发现表明，我们基于语言学知识的方法在设计高效分词器方面是有效且实用的。

</details>


### [14] [Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View](https://arxiv.org/abs/2506.15156)
**中文标题：Mamba中首因效应与近因效应的涌现：机制性视角**

*Muhammad Cendekia Airlangga,Hilal AlQuabeh,Munachiso S Nwadike,Kentaro Inui*

主要分类: cs.CL

摘要简述: 本文通过研究状态空间语言模型中的记忆机制，揭示了Mamba架构中信息保留与遗忘的规律，发现其表现出明显的首因效应和近因效应，并提出了三种机制解释这一现象。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过首因效应和近因效应作为行为工具，揭示状态空间语言模型（如Mamba）中信息如何随时间保留和遗忘的机制。

研究方法: 在Mamba架构中应用结构化回忆任务，观察输入序列中准确率的U形分布，并通过针对性消融和输入扰动实验验证了三种机制：稀疏通道支持长期记忆、delta调制递归控制短期记忆、以及语义规律动态调节记忆分配。

研究结果: 实验发现Mamba模型在序列开头和结尾表现最佳，揭示了长期记忆依赖稀疏通道、短期记忆受delta调制递归影响，且记忆分配受语义规律动态调节。这些结果在1.4B和7B参数的Mamba模型中得到了验证。

研究结论: 研究揭示了Mamba架构中信息保留与遗忘的三种关键机制，为首因效应和近因效应的出现提供了机制性解释，为语言模型的记忆行为研究提供了新视角。

中文摘要: 我们通过首因效应和近因效应作为行为工具，研究了状态空间语言模型中的记忆机制，以揭示信息随时间保留和遗忘的规律。在Mamba架构中应用结构化回忆任务时，我们观察到一致的U形准确率分布，表明模型在输入序列的开头和结尾表现最佳。我们识别了导致这一模式的三种机制。首先，长期记忆由模型选择性状态空间块中的稀疏通道支持，这些通道持续编码早期输入标记，并与首因效应因果相关。其次，短期记忆由delta调制递归控制：由于指数衰减，近期输入获得更多权重，但当引入干扰项时，这种近因优势会崩溃，揭示了记忆深度的明确限制。第三，我们发现记忆分配受语义规律动态调节：输入序列中重复的关系会改变delta门控行为，增加遗忘中间项的倾向。我们通过在两个基于Mamba的大型语言模型（1.4B和7B参数）上进行针对性消融和输入扰动实验，验证了这些发现。

</details>


### [15] [A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals](https://arxiv.org/abs/2506.15208)
**中文标题：大语言模型任务适应技术在识别可持续发展目标中的比较研究**

*Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi*

主要分类: cs.CL

摘要简述: 本研究比较了不同大语言模型在识别联合国可持续发展目标（SDGs）文本分类任务中的表现，并评估了零样本学习、少样本学习和微调等任务适应技术的效果。结果显示，通过提示工程优化的小模型性能可与大型模型媲美。


<details>
  <summary>详细信息</summary>
研究动机: 联合国2012年提出的17个可持续发展目标（SDGs）涉及大量复杂数据，追踪进展困难。文本分类模型和大语言模型（LLMs）因其自动化分析能力成为重要工具。本研究旨在探索LLMs在SDGs文本分类中的表现及任务适应技术的有效性。

研究方法: 研究分析了专有和开源的大语言模型在单标签多类SDGs文本分类任务中的表现，并评估了零样本学习、少样本学习和微调等任务适应技术的效果。

研究结果: 结果表明，通过提示工程优化的小型模型性能与大型模型（如OpenAI的GPT）相当。

研究结论: 优化后的小型模型在SDGs文本分类任务中表现优异，提示工程是提升性能的关键。

中文摘要: 2012年，联合国提出了17个可持续发展目标（SDGs），旨在到203年实现更可持续和更美好的未来。然而，由于涉及数据的规模和复杂性，追踪这些目标的进展十分困难。文本分类模型已成为该领域的重要工具，能够自动化分析来自多种来源的大量文本。此外，大语言模型（LLMs）凭借其识别复杂语言模式和语义的能力，最近被证明是许多自然语言处理任务（包括文本分类）中不可或缺的工具。本研究分析了专有和开源的LLMs在专注于SDGs的单标签多类文本分类任务中的表现。随后，还评估了任务适应技术（即上下文学习方法）的有效性，包括零样本学习、少样本学习以及微调在该领域的应用。结果显示，通过提示工程优化的小型模型性能可与OpenAI的GPT（生成式预训练变换器）等大型模型媲美。

</details>


### [16] [ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs](https://arxiv.org/abs/2506.15211)
**中文标题：ProtoReasoning：原型作为大语言模型可泛化推理的基础**

*Feng He,Zijun Chen,Xinnian Liang,Tingting Ma,Yunqi Qiu,Shuangzhi Wu,Junchi Yan*

主要分类: cs.CL

摘要简述: 本文提出ProtoReasoning框架，通过抽象推理原型提升大语言模型的推理能力，验证原型学习在跨领域泛化中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型推理模型在跨领域泛化中表现出色，但其背后的机制尚不明确。本文假设跨领域泛化源于共享的抽象推理原型，并探索如何利用这些原型提升模型推理能力。

研究方法: ProtoReasoning框架包括：(1)自动原型构建管道，将问题转化为原型表示；(2)通过Prolog/PDDL解释器提供可靠反馈的验证系统；(3)在原型空间内合成问题并确保正确性的扩展能力。

研究结果: 实验显示，ProtoReasoning在逻辑推理（Enigmata-Eval）、规划任务、通用推理（MMLU）和数学（AIME24）上分别提升4.7%、6.3%、4.0%和1.0%。消融研究证实原型学习对结构相似问题泛化能力更强。

研究结论: 本文验证了推理原型是大语言模型可泛化推理的基础，ProtoReasoning框架显著提升了模型的跨领域推理能力。

中文摘要: 近期，基于长链思维推理（Long CoT）训练的大型推理模型（LRMs）展现了卓越的跨领域泛化能力，但其支持这种迁移的机制尚不明确。我们假设跨领域泛化源于共享的抽象推理原型——这些原型能够捕捉跨领域问题的本质推理模式。这些原型最小化了表示的细节，揭示了看似多样化的任务背后共享的推理结构。基于这一假设，我们提出ProtoReasoning框架，通过可扩展且可验证的原型表示（如Prolog用于逻辑推理，PDDL用于规划）增强大语言模型的推理能力。ProtoReasoning的特点包括：(1)自动原型构建管道，将问题转化为相应的原型表示；(2)通过Prolog/PDDL解释器提供可靠反馈的全面验证系统；(3)在原型空间内任意合成问题并确保正确性的扩展能力。大量实验表明，ProtoReasoning在逻辑推理（Enigmata-Eval）、规划任务、通用推理（MMLU）和数学（AIME24）上分别比基线模型提升了4.7%、6.3%、4.0%和1.0%。重要的是，消融研究证实，与仅在自然语言表示上训练相比，原型空间的学习对结构相似问题表现出更强的泛化能力，验证了我们的假设——推理原型是大语言模型可泛化推理的基础。

</details>


### [17] [MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs](https://arxiv.org/abs/2506.15215)
**中文标题：MinosEval：区分事实性与非事实性问题，为开放QA评估量身定制基于LLM的方法**

*Yongqi Fan,Yating Wang,Guandong Wang,Jie Zhai,Jingping Liu,Qi Ye,Tong Ruan*

主要分类: cs.CL

摘要简述: 本文提出MinosEval方法，通过区分事实性和非事实性问题，采用不同策略评估开放性问题回答，提升自动评估的准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 开放性问题回答（QA）是评估大型语言模型（LLM）能力的关键任务，但传统评估方法（如ROUGE和BERTScore）难以捕捉语义相似性，且现有LLM评估方法缺乏对不同问题类型的适应性。

研究方法: MinosEval首先区分事实性和非事实性问题，对事实性问题采用自适应关键点评分策略，对非事实性问题采用实例感知的列表排序策略。

研究结果: 在多个开放QA数据集上的实验表明，MinosEval与人工标注更一致，并提供更可解释的结果。

研究结论: MinosEval通过区分问题类型并采用针对性评估策略，显著提升了开放QA评估的准确性和可解释性。

中文摘要: 开放性问题回答（QA）是评估大型语言模型（LLM）能力的关键任务。与封闭式QA相比，它需要更长的回答、更细致的推理过程和多样化的表达，这使得精细且可解释的自动评估既重要又具有挑战性。传统指标（如ROUGE和BERTScore）由于模型回答与参考答案的模式不同，难以捕捉语义相似性。当前基于LLM的评估方法（如候选答案的成对或列表比较）缺乏直观的可解释性。虽然对每个回答的点式评分提供了一些描述，但无法适应不同问题内容。最值得注意的是，现有方法忽略了事实性和非事实性问题的区别。为解决这些问题，我们提出MinosEval，一种新颖的评估方法，首先区分开放性问题，然后使用不同的评估策略对候选答案进行排序。对于事实性问题，它采用自适应关键点评分策略；对于非事实性问题，它使用实例感知的列表排序策略。在多个开放QA数据集（包括自建数据集以补充社区资源）上的实验表明，MinosEval与人工标注更一致，并提供更可解释的结果。

</details>


### [18] [Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants](https://arxiv.org/abs/2506.15239)
**中文标题：迷失在变体中？评估巴斯克语和西班牙语地理变体的自然语言推理性能**

*Jaione Bengoetxea,Itziar Gonzalez-Dios,Rodrigo Agerri*

主要分类: cs.CL

摘要简述: 本文评估了当前语言技术对巴斯克语和西班牙语变体的理解能力，发现语言变体（尤其是巴斯克语）会导致性能下降，且与词汇重叠无关。编码器模型对西部巴斯克语表现较差，符合语言学理论。


<details>
  <summary>详细信息</summary>
研究动机: 研究当前语言技术对巴斯克语和西班牙语变体的处理能力，揭示语言变体对模型性能的影响。

研究方法: 使用自然语言推理（NLI）任务，构建巴斯克语和西班牙语及其变体的平行数据集，通过跨语言和上下文学习实验分析编码器和解码器大语言模型的表现。

研究结果: 实验显示语言变体（尤其是巴斯克语）导致性能下降，错误分析表明这与词汇重叠无关。编码器模型对西部巴斯克语表现最差，符合语言学理论。

研究结论: 语言变体对模型性能有显著影响，尤其是非标准方言。未来研究需关注如何提升模型对语言变体的适应性。

中文摘要: 本文评估了当前语言技术对巴斯克语和西班牙语变体的理解能力。我们以自然语言推理（NLI）为任务，构建了一个新颖的手工标注平行数据集，涵盖巴斯克语和西班牙语及其变体。通过跨语言和上下文学习实验，对编码器和解码器大语言模型进行实证分析，结果显示语言变体（尤其是巴斯克语）会导致性能下降。错误分析表明，这种下降并非源于词汇重叠，而是语言变体本身。进一步的消融实验表明，编码器模型对西部巴斯克语表现较差，这与语言学理论中关于外围方言（如西部方言）与标准语距离较远的观点一致。所有数据和代码均已公开。

</details>


### [19] [Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs](https://arxiv.org/abs/2506.15241)
**中文标题：基于历史文本知识图谱的图检索增强生成研究**

*Yang Fan,Zhang Qi,Xing Wenqian,Liu Chang,Liu Liu*

主要分类: cs.CL

摘要简述: 本文提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，构建历史文本知识图谱，降低人工标注成本，提升通用模型与历史知识的对齐效果。实验表明，该方法在关系抽取任务中表现优异，有效缓解幻觉现象。


<details>
  <summary>详细信息</summary>
研究动机: 针对通用大语言模型在历史文本分析中的领域知识缺失问题，结合计算人文与AIGC技术，提出一种低资源解决方案，以提升历史知识服务的效率与准确性。

研究方法: 提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，构建《前四史》人物关系数据集，并设计知识图谱与检索增强生成的协作机制。

研究结果: 实验显示，Xunzi-Qwen1.5-14B模型在关系抽取任务中F1值达0.68；集成GraphRAG的DeepSeek模型在开放域C-CLUE数据集上F1提升11%，超越Xunzi-Qwen1.5-14B，且有效缓解幻觉现象。

研究结论: Graph RAG框架为经典文本知识提取提供低资源解决方案，推动历史知识服务与人文研究发展。

中文摘要: 本文针对通用大语言模型在计算人文与AIGC技术背景下历史文本分析的领域知识缺失问题，提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，以最小人工标注构建《前四史》人物关系数据集，支持自动化历史知识提取，降低人工成本。在图增强生成阶段，引入知识图谱与检索增强生成的协作机制，提升通用模型与历史知识的对齐效果。实验表明，领域专用模型Xunzi-Qwen1.5-14B在简体中文输入与思维链提示下，关系抽取任务表现最优（F1=0.68）；集成GraphRAG的DeepSeek模型在开放域C-CLUE关系抽取数据集上F1提升11%（0.08-0.19），超越Xunzi-Qwen1.5-14B（0.12），有效缓解幻觉现象并提升可解释性。该框架为经典文本知识提取提供低资源解决方案，推动历史知识服务与人文研究发展。

</details>


### [20] [TopClustRAG at SIGIR 2025 LiveRAG Challenge](https://arxiv.org/abs/2506.15246)
**中文标题：TopClustRAG在SIGIR 2025 LiveRAG挑战中的表现**

*Juli Bakagianni,John Pavlopoulos,Aristidis Likas*

主要分类: cs.CL

摘要简述: TopClustRAG是一种用于LiveRAG挑战的检索增强生成系统，结合稀疏和密集索引的混合检索策略，通过K-Means聚类和聚类特定提示生成多样且准确的答案。


<details>
  <summary>详细信息</summary>
研究动机: LiveRAG挑战旨在评估大规模网络语料库上的端到端问答系统，TopClustRAG通过聚类和提示聚合提升答案的多样性和准确性。

研究方法: 系统采用混合检索策略（稀疏和密集索引），使用K-Means聚类对语义相似的段落分组，生成聚类特定提示，通过LLM生成中间答案，最后过滤、重排并合成最终答案。

研究结果: 在FineWeb Sample-10BT数据集上，TopClustRAG在官方排行榜中位列忠实性第2名和正确性第7名，验证了聚类和提示聚合的有效性。

研究结论: TopClustRAG通过聚类和提示聚合显著提升了大规模RAG系统的答案多样性和忠实性，展示了其在端到端问答任务中的潜力。

中文摘要: 我们提出了TopClustRAG，一种为LiveRAG挑战开发的检索增强生成（RAG）系统，该挑战评估大规模网络语料库上的端到端问答任务。我们的系统采用混合检索策略，结合稀疏和密集索引，并通过K-Means聚类对语义相似的段落进行分组。每个聚类的代表性段落用于构建针对大型语言模型（LLM）的聚类特定提示，生成中间答案后经过过滤、重排，最终合成一个全面且准确的回答。这种多阶段流程提升了答案的多样性、相关性和对检索证据的忠实性。在FineWeb Sample-10BT数据集上的评估显示，TopClustRAG在官方排行榜中位列忠实性第2名和正确性第7名，证明了基于聚类的上下文过滤和提示聚合在大规模RAG系统中的有效性。

</details>


### [21] [Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments](https://arxiv.org/abs/2506.15266)
**中文标题：Thunder-DeID：一种高效且准确的韩国法院判决书去标识化框架**

*Sungen Hahm,Heejin Kim,Gyuseong Lee,Hyunji Park,Jaejin Lee*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Thunder-DeID的高效去标识化框架，用于处理韩国法院判决书，以满足法律要求并保护个人数据。该框架结合了深度学习技术和系统化的个人身份信息分类，显著提升了去标识化的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 韩国司法系统要求在公开法院判决书前进行去标识化处理，以平衡司法公开与个人数据保护。然而，现有方法无法满足大规模处理需求，且法律对个人标识的定义模糊，技术实现困难。因此，需要一种高效且符合法律要求的去标识化框架。

研究方法: 研究团队（i）构建并发布了首个包含标注判决书和实体提及列表的韩语法律数据集；（ii）提出了系统化的个人身份信息分类方法；（iii）开发了一个基于深度神经网络的端到端去标识化流程。

研究结果: 实验结果表明，Thunder-DeID框架在法院判决书的去标识化任务中达到了最先进的性能，显著优于现有方法。

研究结论: Thunder-DeID框架不仅满足了韩国法律对去标识化的严格要求，还通过深度学习技术提升了处理效率和准确性，为司法数据的公开提供了可靠的技术支持。

中文摘要: 为了在司法公开与个人数据保护之间取得平衡，韩国司法系统要求在公开法院判决书前进行去标识化处理。然而，目前的去标识化方法无法满足大规模处理需求，且法律对个人标识的定义模糊，技术实现困难。为解决这些问题，我们提出了一种名为Thunder-DeID的去标识化框架，该框架符合相关法律和实践要求。具体而言，我们（i）构建并发布了首个包含标注判决书和实体提及列表的韩语法律数据集；（ii）提出了系统化的个人身份信息分类方法；（iii）开发了一个基于深度神经网络的端到端去标识化流程。实验结果表明，我们的模型在法院判决书的去标识化任务中达到了最先进的性能。

</details>


### [22] [Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment](https://arxiv.org/abs/2506.15301)
**中文标题：队列发现：关于LLM辅助临床试验招募的综述**

*Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff*

主要分类: cs.CL

摘要简述: 本文综述了LLM在临床试验招募中的应用，分析了现有方法的局限性，并探讨了未来发展方向。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM在通用NLP任务中表现出色，但在临床试验招募等关键领域的应用仍有限。本文旨在探讨LLM如何通过知识聚合和推理能力改进试验与患者的匹配任务。

研究方法: 本文通过综述现有LLM辅助方法，分析其在临床试验招募中的应用，并评估现有基准和框架的局限性。

研究结果: 研究发现，现有方法依赖专有模型和弱评估基准，限制了LLM在临床研究中的广泛应用。

研究结论: 本文呼吁开发更通用的LLM解决方案，并提出了未来研究方向，以推动LLM在临床试验招募中的实际应用。

中文摘要: 近年来，LLM的进步显著提升了通用领域的NLP任务表现。然而，在临床试验招募等关键领域，其应用仍然有限。由于试验设计使用自然语言，患者数据以结构化和非结构化文本形式呈现，LLM的知识聚合和推理能力为试验与患者的匹配任务提供了潜在优势。传统方法针对特定试验，而LLM通过整合分散知识，有望构建更通用的解决方案。然而，近期LLM辅助方法的应用依赖于专有模型和弱评估基准。本文首次分析了试验与患者匹配任务，并将新兴的基于LLM的方法置于临床试验招募的背景下进行探讨。我们批判性地审视了现有基准、方法和评估框架，探讨了LLM技术在临床研究中应用的挑战，并展望了激动人心的未来方向。

</details>


### [23] [ConLID: Supervised Contrastive Learning for Low-Resource Language Identification](https://arxiv.org/abs/2506.15304)
**中文标题：ConLID：基于监督对比学习的低资源语言识别方法**

*Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut*

主要分类: cs.CL

摘要简述: 本文提出了一种基于监督对比学习（SCL）的新方法ConLID，用于解决低资源语言识别（LID）中的领域偏差和类别不平衡问题，显著提升了低资源语言在跨领域数据上的识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语言识别（LID）在多语言LLM预训练语料库构建中至关重要，但现有方法因依赖单领域数据（如圣经）而表现不佳。本文旨在通过监督对比学习解决类别不平衡和领域偏差问题，提升低资源语言的识别效果。

研究方法: 提出了一种名为ConLID的监督对比学习（SCL）方法，通过学习领域不变的表示来优化低资源语言的识别。该方法通过对比学习增强模型对跨领域数据的泛化能力。

研究结果: 实验表明，ConLID方法将低资源语言在跨领域数据上的识别性能提升了3.2%，验证了其有效性。

研究结论: ConLID通过监督对比学习显著改善了低资源语言识别的跨领域性能，为解决类别不平衡和领域偏差问题提供了有效方案。

中文摘要: 语言识别（LID）是从网络爬取数据中构建多语言LLM预训练语料库的关键步骤。尽管许多关于LID模型训练的研究侧重于收集多样化的训练数据以提高性能，但低资源语言（通常仅限于单领域数据，如圣经）的表现仍然较差。为解决这些类别不平衡和偏差问题，我们提出了一种新颖的监督对比学习（SCL）方法，用于学习低资源语言的领域不变表示。通过广泛分析，我们表明该方法将低资源语言在跨领域数据上的识别性能提高了3.2%，证明了其在增强LID模型方面的有效性。

</details>


### [24] [DeVisE: Behavioral Testing of Medical Large Language Models](https://arxiv.org/abs/2506.15339)
**中文标题：DeVisE：医疗大语言模型的行为测试**

*Camila Zurdo Tagliabue,Heloisa Oss Boll,Aykut Erdem,Erkut Erdem,Iacer Calixto*

主要分类: cs.CL

摘要简述: 本文提出了DeVisE框架，用于测试医疗大语言模型（LLMs）的临床理解能力，通过对比真实和合成数据，评估模型对人口统计和生命体征变化的敏感性及推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估方法难以区分医疗大语言模型（LLMs）的真实医学推理与表面模式，因此需要一种更精细的行为测试框架来揭示模型的临床理解能力。

研究方法: 研究构建了基于MIMIC-IV的ICU出院记录数据集，包括真实和模板生成的合成数据，通过控制单变量反事实（如人口统计和生命体征）评估五种LLMs的输入敏感性和下游推理能力。

研究结果: 零样本模型表现出更一致的反事实推理模式，而微调模型更稳定但对临床变化反应较弱；人口统计因素对输出有细微但持续的影响。

研究结论: 行为测试能有效揭示临床LLMs的推理策略，为设计更安全、透明的医疗AI系统提供依据。

中文摘要: 大语言模型（LLMs）在临床决策支持中的应用日益增多，但现有评估方法往往难以区分真实的医学推理与表面模式。我们提出了DeVisE（人口统计与生命体征评估），一种用于探测细粒度临床理解的行为测试框架。我们基于MIMIC-IV构建了一个ICU出院记录数据集，生成了真实和模板生成的合成版本，并通过控制单变量反事实（针对人口统计和生命体征属性）进行评估。我们评估了五种LLMs（包括通用和医疗微调版本）在零样本和微调设置下的表现，通过（1）输入级敏感性（反事实如何改变记录的似然）和（2）下游推理（如何影响预测的住院时间）来评估模型行为。结果显示，零样本模型表现出更一致的反事实推理模式，而微调模型更稳定但对临床变化的反应较弱。值得注意的是，人口统计因素对输出有细微但持续的影响，强调了公平性评估的重要性。这项工作凸显了行为测试在揭示临床LLMs推理策略和设计更安全、透明的医疗AI系统中的价值。

</details>


### [25] [SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture](https://arxiv.org/abs/2506.15355)
**中文标题：SANSKRITI：评估语言模型对印度文化知识的综合基准**

*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Sriparna Saha*

主要分类: cs.CL

摘要简述: SANSKRITI是一个评估语言模型对印度文化理解能力的综合基准，包含21,853个问题-答案对，覆盖印度28个邦和8个联邦属地的16个文化属性。测试发现主流语言模型在处理文化相关查询时表现差异显著。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型在全球应用中的有效性依赖于其对本地社会文化背景的理解。然而，目前缺乏评估模型对印度文化多样性的理解能力的基准，因此作者开发了SANSKRITI。

研究方法: 作者构建了SANSKRITI基准，包含21,853个精心设计的问题-答案对，覆盖印度28个邦和8个联邦属地的16个文化属性。随后在主流大型语言模型（LLMs）、印度语言模型（ILMs）和小型语言模型（SLMs）上进行了评估。

研究结果: 评估结果显示，主流语言模型在处理文化相关查询时表现差异显著，许多模型在特定区域文化背景下的表现不佳。

研究结论: SANSKRITI为评估和提升语言模型的文化理解能力设定了新标准，填补了现有基准的空白。

中文摘要: 语言模型（LMs）是现代工作流程中不可或缺的工具，但其全球有效性依赖于对本地社会文化背景的理解。为此，我们推出了SANSKRITI，一个旨在评估语言模型对印度丰富文化多样性理解能力的基准。SANSKRITI包含21,853个精心设计的问题-答案对，覆盖印度28个邦和8个联邦属地的16个文化属性：仪式与庆典、历史、旅游、美食、舞蹈与音乐、服饰、语言、艺术、节日、宗教、医学、交通、体育、夜生活及名人，全面展现了印度的文化图景。我们在主流大型语言模型（LLMs）、印度语言模型（ILMs）和小型语言模型（SLMs）上评估了SANSKRITI，发现这些模型在处理文化相关查询时表现差异显著，许多模型在特定区域文化背景下表现不佳。通过提供一个广泛、文化丰富且多样化的数据集，SANSKRITI为评估和提升语言模型的文化理解能力设定了新标准。

</details>


### [26] [COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation](https://arxiv.org/abs/2506.15372)
**中文标题：COSMMIC：面向摘要和标题生成的评论敏感多模态多语言印度语料库**

*Raghvendra Kumar,S. A. Mohammed Salman,Aryan Sahu,Tridib Nandi,Pragathi Y. P.,Sriparna Saha,Jose G. Moreno*

主要分类: cs.CL

摘要简述: 本文介绍了COSMMIC数据集，这是一个针对印度语言的多模态、多语言语料库，包含文章、图片和读者评论，旨在提升摘要和标题生成任务的效果。


<details>
  <summary>详细信息</summary>
研究动机: 尽管英语和中文的多模态、多语言摘要研究已有进展，但印度语言的相关研究仍显不足。本研究旨在填补这一空白，通过整合文本、图片和用户评论，推动印度语言的NLP研究。

研究方法: 研究构建了包含4,959篇文章-图片对和24,484条评论的COSMMIC数据集，支持九种印度语言。采用四种配置（纯文本、文本+评论、文本+图片、全模态）进行摘要和标题生成实验，并使用LLama3和GPT-4等模型评估效果。

研究结果: 实验表明，结合用户评论和图片的多模态配置显著提升了摘要和标题生成的质量。通过IndicBERT和CLIP分类器过滤噪声并提取有效信息，进一步优化了生成效果。

研究结论: COSMMIC填补了印度语言多模态数据集的空白，为NLP任务提供了更全面的资源，促进了研究的包容性和多样性。

中文摘要: 尽管针对英语和中文的评论感知多模态和多语言摘要研究已取得进展，但印度语言的相关研究仍显不足。本研究填补了这一空白，推出了COSMMIC，这是一个开创性的评论敏感多模态、多语言数据集，涵盖九种主要印度语言。COSMMIC包含4,959篇文章-图片对和24,484条读者评论，并提供所有语言的真实摘要。我们的方法通过整合读者见解和反馈来增强摘要效果。我们探索了四种配置下的摘要和标题生成：（1）仅使用文章文本，（2）结合用户评论，（3）利用图片，（4）综合文本、评论和图片。为评估数据集的有效性，我们采用了LLama3和GPT-4等先进语言模型。通过全面研究不同组件的组合，包括使用IndicBERT分类器识别支持性评论并过滤噪声，以及通过多语言CLIP分类器从图片中提取有价值信息，我们确定了自然语言生成（NLG）任务的最有效配置。与许多现有数据集不同，COSMMIC独特地整合了文本、图片和用户反馈，弥补了印度语言资源的不足，推动了NLP研究并促进了包容性。

</details>


### [27] [Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning](https://arxiv.org/abs/2506.15415)
**中文标题：目标词汇注入：通过早期层LoRA微调解锁Lugha-Llama中的潜在跨语言对齐**

*Stanley Ngugi*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“目标词汇注入”（TLI）的高效微调方法，通过早期层的LoRA微调，显著提升了低资源语言（如斯瓦希里语）在大型语言模型中的跨语言词汇对齐能力。实验表明，TLI显著提高了词汇对齐的相似度，并具有良好的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在低资源语言（如斯瓦希里语）中的表现通常较差，主要由于数据稀缺和预训练中的代表性不足。跨语言词汇对齐是实现翻译和跨语言信息检索等任务的关键挑战。本文旨在通过TLI方法解决这一问题。

研究方法: TLI利用Lugha-Llama-8B-wura模型早期内部层（如第2层）表现出的强词汇对齐能力，通过低秩适应（LoRA）和对比学习目标进行微调，专注于优化这些层的嵌入表示。

研究结果: 实验结果显示，TLI显著提升了623个斯瓦希里语-英语词汇对的输出层词汇对齐相似度（从0.3211提升至0.4113，+28.08%），并且在63个未见过的控制词汇对上也表现出良好的泛化能力（从0.3143提升至0.4033，+28.32%）。

研究结论: TLI能够有效增强模型保留和传播其早期层跨语言知识的能力，为低资源语言模型提供了一种参数高效且有效的词汇对齐改进策略。

中文摘要: 大型语言模型（LLMs）表现出卓越的能力，但在低资源语言（如斯瓦希里语）中的表现往往因数据稀缺和预训练中的代表性不足而滞后。实现稳健的跨语言词汇对齐是关键挑战，对翻译和跨语言信息检索等任务至关重要。本文提出了一种名为“目标词汇注入”（TLI）的新型高效微调方法。我们首先证明，Lugha-Llama-8B-wura（一种以斯瓦希里语为中心的LLM）在其早期内部层（特别是第2层，基于初步研究的平均余弦相似度约为0.99998）表现出强且近乎完美的斯瓦希里语-英语词汇对齐能力，但其最终输出表示中并未完全体现（基线相似度约为0.32）。TLI利用这一发现，通过低秩适应（LoRA）和对比学习目标微调模型，专门针对这一经验确定的最佳早期层的嵌入表示。实验表明，TLI显著提升了623个训练过的斯瓦希里语-英语词汇对的输出层词汇对齐相似度（从0.3211提升至0.4113，+28.08%，p < 1.33 x 10^-240）。更重要的是，这些改进在63个未见过的控制词汇对上也表现出显著的泛化能力（相似度从0.3143提升至0.4033，+28.32%，p < 7.17 x 10^-27）。这些发现表明，TLI增强了模型保留和传播其固有早期层跨语言知识的能力，为改进低资源语言模型的词汇对齐提供了一种参数高效且有效的策略。

</details>


### [28] [Understanding GUI Agent Localization Biases through Logit Sharpness](https://arxiv.org/abs/2506.15425)
**中文标题：通过Logit锐度理解GUI代理的定位偏差**

*Xingjian Tao,Yiwei Wang,Yujun Cai,Zhicheng Yang,Jing Tang*

主要分类: cs.CL

摘要简述: 本文提出了一种细粒度评估框架和峰值锐度评分（PSS），用于量化多模态大语言模型（MLLMs）在GUI代理中的定位偏差，并通过上下文感知裁剪技术提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在GUI代理中表现出色，但其定位偏差（幻觉）问题严重影响了可靠性。本文旨在揭示这些偏差的细粒度失败模式，并提出量化模型不确定性的方法。

研究方法: 1. 提出细粒度评估框架，将模型预测分为四类；2. 引入峰值锐度评分（PSS）量化语义连续性与坐标预测的对齐程度；3. 提出无需训练的上下文感知裁剪技术，优化输入上下文。

研究结果: 实验表明，该框架和方法能够提供可操作的见解，显著提升GUI代理行为的可解释性和鲁棒性。

研究结论: 本文提出的框架和技术为GUI代理的定位偏差问题提供了新的解决方案，增强了模型的可靠性和实用性。

中文摘要: 多模态大语言模型（MLLMs）使GUI代理能够通过将语言映射到空间动作来与操作系统交互。尽管性能优异，这些模型常出现幻觉——系统性定位错误，影响可靠性。我们提出了一种细粒度评估框架，将模型预测分为四类，揭示了传统准确率指标之外的失败模式。为量化模型不确定性，我们引入了峰值锐度评分（PSS），评估语义连续性与坐标预测的对齐程度。基于此，我们进一步提出上下文感知裁剪技术，通过自适应优化输入上下文提升模型性能。大量实验表明，我们的框架和方法提供了可操作的见解，增强了GUI代理行为的可解释性和鲁棒性。

</details>


### [29] [AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need](https://arxiv.org/abs/2506.15451)
**中文标题：AgentGroupChat-V2：基于分治法的LLM多智能体系统**

*Zhouhong Gu,Xiaoxuan Zhu,Yin Cai,Hao Shen,Xingzhou Chen,Qingyi Wang,Jialin Li,Xiaoran Shi,Haoran Guo,Wenxuan Huang,Hongwei Feng,Yanghua Xiao,Zheyu Ye,Yao Hu,Shaosheng Cao*

主要分类: cs.CL

摘要简述: AgentGroupChat-V2提出了一种基于分治法的LLM多智能体系统框架，通过并行架构、自适应协作引擎和优化策略，显著提升了复杂任务处理的性能，尤其在数学推理和编程任务中表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大语言模型的多智能体系统在系统架构设计、跨领域泛化性和性能保障方面面临挑战，尤其是在任务复杂性和智能体数量增加时。本文旨在通过分治法解决这些问题。

研究方法: 1. 采用分治法的完全并行架构，将用户查询分解为层次化任务森林结构；2. 自适应协作引擎动态选择异构LLM组合和交互模式；3. 结合分治法的智能体组织优化策略。

研究结果: 实验表明，AgentGroupChat-V2在GSM8K上准确率达91.50%（比最佳基线高5.6个百分点），在AIME上达30.4%（接近其他方法的两倍），在HumanEval上达79.20% pass@1。在复杂任务中优势更明显。

研究结论: AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，尤其在复杂推理场景中具有显著优势。

中文摘要: 基于大语言模型的多智能体系统在社会模拟和复杂任务解决领域展现出巨大潜力。然而，当前框架在系统架构设计、跨领域泛化性和性能保障方面面临关键挑战，尤其是随着任务复杂性和智能体数量的增加。我们提出了AgentGroupChat-V2，通过三项核心创新解决这些问题：（1）分治法的完全并行架构，将用户查询分解为层次化任务森林结构，实现依赖管理和分布式并发处理；（2）自适应协作引擎，根据任务特性动态选择异构LLM组合和交互模式；（3）结合分治法的智能体组织优化策略。大量实验表明，AgentGroupChat-V2在多个领域表现优异，GSM8K准确率达91.50%（比最佳基线高5.6个百分点），AIME达30.4%（接近其他方法的两倍），HumanEval pass@1达79.20%。随着任务难度增加，性能优势更加显著，尤其在Level 5 MATH问题上，比现有基线提升超过11个百分点。这些结果证实，AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，在复杂推理场景中具有显著优势。代码见https://github.com/MikeGu721/AgentGroupChat-V2。

</details>


### [30] [RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation](https://arxiv.org/abs/2506.15455)
**中文标题：RE-IMAGINE：用于推理评估的符号基准合成**

*Xinnuo Xu,Rachel Lawrence,Kshitij Dubey,Atharva Pandey,Risa Ueno,Fabian Falck,Aditya V. Nori,Rahul Sharma,Amit Sharma,Javier Gonzalez*

主要分类: cs.CL

摘要简述: 本文提出RE-IMAGINE框架，用于评估大型语言模型（LLMs）的推理能力层次，并通过自动生成问题变体揭示模型是否依赖记忆而非真实推理。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理任务中表现优异，但其是否真正具备推理能力还是仅依赖训练数据的统计记忆尚不明确。受因果阶梯理论启发，本文旨在通过问题变体评估模型的真实推理能力。

研究方法: RE-IMAGINE框架通过中间符号表示生成不同层次的问题变体，覆盖数学、代码和逻辑等领域，避免模型仅通过记忆解决问题。

研究结果: 实验表明，模型在面对问题变体时性能下降，说明其部分依赖统计记忆而非真实推理能力。

研究结论: RE-IMAGINE为评估模型推理能力提供了新方法，揭示了当前模型的局限性，并为未来研究指明了方向。

中文摘要: 近期的大型语言模型（LLMs）在推理基准测试中表现出高准确率，但其结果是否源于真实推理还是训练数据的统计记忆尚不明确。受因果阶梯理论（Pearl, 2009）及其三个层次（关联、干预和反事实）的启发，本文提出RE-IMAGINE框架，用于描述LLMs的推理能力层次，并提供一个自动化流程以生成不同层次的问题变体。通过中间符号表示修改问题，RE-IMAGINE可生成任意数量无法仅通过记忆解决的问题。该框架具有通用性，适用于数学、代码和逻辑等推理领域。我们在四个广泛使用的基准测试中验证了该框架，并观察到模型在面对问题变体时性能下降。这些评估表明，模型部分依赖统计记忆，为未来研究推理能力层次提供了方向。

</details>


### [31] [Context-Informed Grounding Supervision](https://arxiv.org/abs/2506.15480)
**中文标题：基于上下文的接地监督**

*Hyunji Lee,Seunghyun Yoon,Yunjae Won,Hanseok Oh,Geewook Kim,Trung Bui,Franck Dernoncourt,Elias Stengel-Eskin,Mohit Bansal,Minjoon Seo*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CINGS的后训练监督方法，通过将相关上下文附加到响应前并仅计算响应标记的损失，显著提升了语言模型在文本和视觉领域的接地性能，同时不影响下游任务表现。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在生成响应时可能依赖内部知识而非提供的外部上下文，导致幻觉问题。现有方法仅简单附加上下文无法确保接地生成，因此需要一种更有效的监督方法。

研究方法: CINGS方法在训练时将相关上下文附加到响应前，但仅计算响应标记的损失并屏蔽上下文。这种方法通过调整模型对上下文的依赖，提升接地性能。

研究结果: 实验表明，CINGS在11个信息检索数据集上优于其他训练方法，并在视觉语言领域减少了幻觉，同时保持生成内容的真实性。此外，CINGS不损害下游任务性能。

研究结论: CINGS通过改变模型对上下文的依赖行为，显著提升了接地性能，且无需牺牲模型的其他能力。

中文摘要: 大型语言模型（LLMs）常通过补充外部知识以提供未编码信息或减少幻觉。在此情况下，我们希望模型能基于提供的外部上下文生成接地响应。然而，先前研究表明，仅简单附加上下文无法确保接地生成。为此，我们提出了一种名为CINGS的后训练监督方法，即在训练时将相关上下文附加到响应前，但仅计算响应标记的损失并屏蔽上下文。实验表明，CINGS训练的模型在文本和视觉领域均表现出更强的接地性能。在文本领域，CINGS在11个信息检索数据集上优于其他训练方法，并与推理时接地技术互补。在视觉语言领域，将视觉语言模型的LLM主干替换为CINGS训练模型后，四个基准测试中的幻觉减少，且生成内容保持事实一致性。这种改进的接地性能并未导致下游任务性能下降。最后，我们分析了CINGS增强接地的机制，发现它改变了模型的先验知识和行为，隐式鼓励模型更依赖外部上下文。

</details>


### [32] [SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling](https://arxiv.org/abs/2506.15498)
**中文标题：SPARE：基于参考引导评估的单次标注方法用于自动过程监督与奖励建模**

*Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych*

主要分类: cs.CL

摘要简述: SPARE是一种新颖的结构化框架，通过单次标注和参考引导评估，提升大语言模型在多步推理任务中的表现，同时显著提高标注效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在多步推理任务中依赖高质量的过程监督，但自动标注效率低且质量难以保证。SPARE旨在解决这一问题，提供高效且高质量的自动标注方法。

研究方法: SPARE采用单次标注和参考引导评估，将每个解决步骤与参考解决方案中的步骤对齐，并辅以明确的评估理由。该方法在数学推理、多跳问答和空间推理三个领域的四个数据集上进行了验证。

研究结果: SPARE在离线强化学习设置中提升了推理性能，并在训练奖励模型时表现优异。此外，其标注效率比基于树搜索的自动标注方法高2.6倍，仅需38%的运行时间。

研究结论: SPARE为高效、高质量的过程监督提供了一种可行方案，显著提升了多步推理任务的性能，同时降低了计算成本。

中文摘要: 过程或分步监督在提升大语言模型（LLMs）的复杂多步推理能力中发挥了关键作用。然而，高效、高质量的自动过程标注仍是一个重大挑战。为此，我们提出了基于参考引导评估的单次标注方法（SPARE），这是一种新颖的结构化框架，通过将每个解决步骤与参考解决方案中的一个或多个步骤对齐，并辅以明确的评估理由，实现单次、分步标注。我们展示了参考引导的分步评估在数学推理、多跳组合问答和空间推理三个领域的四个数据集上有效促进了过程监督。实验表明，与基线方法相比，SPARE在以下场景中提升了推理性能：（1）在离线强化学习设置中微调模型以进行推理时的贪婪解码；（2）训练奖励模型以对多个LLM生成的结果进行排序/聚合。此外，SPARE在具有挑战性的数学数据集上表现出竞争力，同时标注效率提高了2.6倍，仅需38%的运行时间，优于基于树搜索的自动标注方法。我们公开了代码库和训练好的SPARE-PRM模型，以促进进一步的研究和可重复性。

</details>


### [33] [Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge](https://arxiv.org/abs/2506.15504)
**中文标题：利用双向动态交互与情感知识增强夸张与隐喻检测**

*Li Zheng,Sihang Wang,Hao Fei,Zuquan Peng,Fei Li,Jianming Fu,Chong Teng,Donghong Ji*

主要分类: cs.CL

摘要简述: 本文提出了一种基于情感引导和双向动态交互的夸张与隐喻检测框架（EmoBi），通过挖掘情感内涵和双向交互提升检测效果，实验表明其在多个数据集上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有夸张与隐喻检测方法多关注表层文本特征，忽略了二者关联及隐含情感的影响，导致检测效果受限。本文旨在通过情感分析和双向交互解决这一问题。

研究方法: EmoBi框架包含情感分析模块、基于情感的领域映射模块和双向动态交互模块，通过挖掘情感内涵和双向交互提升检测准确性，并设计验证机制确保可靠性。

研究结果: 实验显示，EmoBi在四个数据集上均优于基线方法，其中在TroFi数据集上夸张检测F1值提升28.1%，在HYPO-L数据集上隐喻检测F1值提升23.1%。

研究结论: EmoBi通过情感引导和双向交互显著提升了夸张与隐喻检测效果，证明了其在自然语言处理任务中的潜力和有效性。

中文摘要: 文本中的夸张与隐喻检测对自然语言处理任务具有重要意义，但由于其语义隐晦和表达多样性，识别它们具有挑战性。现有方法多关注表层文本特征，忽略了夸张与隐喻的关联及隐含情感对感知这些修辞手法的影响。为实现这些假设，我们提出了一种基于情感引导和双向动态交互的夸张与隐喻检测框架（EmoBi）。首先，情感分析模块深度挖掘夸张与隐喻背后的情感内涵；其次，基于情感的领域映射模块识别目标与源领域以深入理解其隐含意义；最后，双向动态交互模块实现夸张与隐喻的相互促进。同时，设计了验证机制以确保检测的准确性和可靠性。实验表明，EmoBi在四个数据集上均优于所有基线方法。具体而言，在TroFi数据集上夸张检测的F1值较当前最优方法提升28.1%，在HYPO-L数据集上隐喻检测的F1值提升23.1%。这些结果通过深入分析验证了我们方法的有效性和潜力，为夸张与隐喻检测的进一步发展提供了支持。

</details>


### [34] [Lessons from Training Grounded LLMs with Verifiable Rewards](https://arxiv.org/abs/2506.15522)
**中文标题：基于可验证奖励训练接地气大语言模型的经验教训**

*Shang Hong Sim,Tej Deep Pala,Vernon Toh,Hai Leong Chieu,Amir Zadeh,Chuan Li,Navonil Majumder,Soujanya Poria*

主要分类: cs.CL

摘要简述: 本文探讨如何通过强化学习（RL）和内部推理提升大语言模型（LLM）的可靠性和可验证性。采用GRPO方法训练模型，优化答案正确性、引用充分性和拒绝质量，显著提升了模型在未回答查询和引用生成方面的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于检索增强生成（RAG）的大语言模型在生成可信赖和基于证据的回答时仍存在不足，如遗漏明确答案、错误引用或拒绝回答。本文旨在通过强化学习和推理机制解决这些问题。

研究方法: 使用GRPO（Group Relative Policy Optimization）方法训练模型，通过可验证的结果奖励（如答案正确性、引用充分性和拒绝质量）优化模型行为。采用两阶段训练策略，先优化答案和引用行为，再优化拒绝行为，并结合GPT-4蒸馏的指令微调。

研究结果: 实验表明，结合推理的模型在ASQA、QAMPARI、ELI5和ExpertQA等任务中显著优于仅基于指令的模型，尤其在处理未回答查询和生成高质量引用方面表现突出。两阶段训练进一步提升了模型的稳定性。

研究结论: 本文证明了推理机制、分阶段优化和结果驱动的强化学习对构建更可靠和可验证的大语言模型具有重要价值，为未来研究提供了方向。

中文摘要: 生成基于证据且可信赖的回答仍是大语言模型（LLM）面临的关键挑战。尽管基于检索增强生成（RAG）和引用的方法具有潜力，但经过指令微调的模型在简单场景中仍频繁失败：遗漏明确答案、错误引用或在证据可用时拒绝回答。本研究探索了如何通过强化学习（RL）和内部推理提升LLM的可靠性。我们采用GRPO（Group Relative Policy Optimization）方法，通过可验证的结果奖励（如答案正确性、引用充分性和拒绝质量）训练模型，无需黄金推理轨迹或昂贵标注。在ASQA、QAMPARI、ELI5和ExpertQA等任务上的全面实验表明，结合推理的模型显著优于仅基于指令的模型，尤其在处理未回答查询和生成高质量引用方面。两阶段训练（先优化答案和引用行为，再优化拒绝行为）进一步提升了模型的稳定性。此外，通过GPT-4蒸馏的指令微调结合GRPO，在生成长篇问答任务中表现更优。总体而言，我们的研究结果凸显了推理、分阶段优化和结果驱动RL对构建更可验证和可靠LLM的价值。

</details>


### [35] [RATTENTION: Towards the Minimal Sliding Window Size in Local-Global Attention Models](https://arxiv.org/abs/2506.15545)
**中文标题：RATTENTION：迈向局部-全局注意力模型的最小滑动窗口尺寸**

*Bailin Wang,Chang Lan,Chong Wang,Ruoming Pang*

主要分类: cs.CL

摘要简述: 本文提出RATTENTION，一种结合局部注意力和线性注意力的模型，旨在解决局部注意力忽视窗口外信息的局限性。实验表明，RATTENTION在512窗口大小下即可媲美全注意力模型，同时提升长上下文性能，且不影响训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 局部-全局注意力模型在效率和性能之间存在权衡：大窗口性能接近全注意力但效率提升有限，小窗口则可能导致性能下降。本文旨在通过改进局部注意力，解决其完全忽视窗口外信息的固有缺陷，从而在短上下文场景中实现更高的效率。

研究方法: 提出RATTENTION，将局部注意力与专为捕捉窗口外信息设计的线性注意力机制结合。通过预训练实验（3B和12B规模）验证其有效性，并采用专用内核实现以保持训练效率。

研究结果: RATTENTION在512窗口大小下性能与全注意力模型相当，并在RULER基准测试中验证了其长上下文性能的提升。同时，训练速度与现有先进方法相当。

研究结论: RATTENTION通过结合局部和线性注意力，显著优化了局部-全局注意力模型的帕累托前沿，实现了在短上下文和长上下文场景中的高效表现。

中文摘要: 局部-全局注意力模型近年来成为标准Transformer的有力替代方案，有望提升训练和推理效率。然而，窗口尺寸的选择存在帕累托权衡：大窗口性能接近全注意力但效率提升有限，小窗口则可能导致性能下降。现有模型（如Gemma2和Mistral）采用保守窗口尺寸（如4096，预训练长度为8192）以保持性能。本文研究如何优化这一权衡，使局部-全局模型在短上下文中也能实现效率提升。核心动机是解决局部注意力完全忽视窗口外信息的固有缺陷。我们探索了RATTENTION，一种结合专为捕捉窗口外信息设计的线性注意力机制的局部注意力变体。3B和12B规模的预训练实验表明，RATTENTION在性能和效率之间实现了更优的帕累托权衡。512窗口尺寸的RATTENTION在多种场景下性能与全注意力模型相当。此外，RATTENTION的线性注意力机制因其循环特性，在RULER基准测试中验证了长上下文性能的提升。重要的是，这些改进未牺牲训练效率；得益于专用内核实现和更小的窗口尺寸，RATTENTION的训练速度与现有先进方法相当。

</details>


### [36] [Approximating Language Model Training Data from Weights](https://arxiv.org/abs/2506.15553)
**中文标题：从权重近似语言模型训练数据**

*John X. Morris,Junjie Oscar Yin,Woojeong Kim,Vitaly Shmatikov,Alexander M. Rush*

主要分类: cs.CL

摘要简述: 现代语言模型权重公开但训练数据封闭，本文提出从模型权重近似训练数据的方法，通过梯度匹配从公共文本中筛选数据，显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代语言模型通常公开权重但隐藏训练数据，这限制了模型的可解释性和数据重用。本文旨在解决如何从公开的模型权重中近似原始训练数据的问题。

研究方法: 提出一种基于梯度的数据选择方法，从大型公共文本语料库中筛选与模型权重最匹配的数据，用于训练新模型。

研究结果: 在AG News分类任务中，性能从65%提升至80%，接近专家基准的88%；在MSMARCO文档的SFT模型上，困惑度从3.3降至2.3，接近专家LLAMA模型的2.0。

研究结论: 即使不知道真实训练数据，通过梯度匹配方法也能从公共数据中筛选出有效子集，显著提升模型性能。

中文摘要: 现代语言模型通常公开权重但隐藏训练数据。我们形式化了从模型权重近似数据的问题，并提出了几种基线方法和指标。我们开发了一种基于梯度的方法，从大型公共文本语料库中选择匹配度最高的数据，并展示了其在仅知道原始模型和微调模型权重时恢复有用数据的有效性。即使不知道任何真实训练数据，我们的方法也能从公共网络文档中定位一个小子集，用于训练模型接近原始性能。在AG News分类任务中，我们的方法将性能从65%（随机选择数据）提升至80%，接近专家基准的88%。当应用于在MSMARCO网络文档上训练的SFT模型时，我们的方法将困惑度从3.3降至2.3，而专家LLAMA模型的困惑度为2.0。

</details>


### [37] [PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction](https://arxiv.org/abs/2506.15556)
**中文标题：PredGen：通过输入时推测解码加速大型语言模型推理以实现实时语音交互**

*Shufan Li,Aditya Grover*

主要分类: cs.CL

摘要简述: 本文提出了一种名为PredGen的新框架，通过输入时推测解码技术，显著减少大型语言模型（LLM）在实时语音交互中的延迟问题，提升用户体验。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在实时语音聊天应用中常与文本转语音（TTS）系统结合使用，但其庞大的模型规模导致用户输入结束到音频输出开始之间存在明显延迟，影响用户体验。尤其在计算能力有限的消费级硬件上，这一问题更为突出。研究发现，延迟主要源于LLM生成第一句话所需的时间，而TTS系统需要逐句合成音频。

研究方法: 为解决这一问题，作者提出了预测生成（PredGen）框架，通过在用户仍在说话时生成候选响应，实现输入时的推测解码。这种方法使系统能够以最小延迟启动TTS处理。

研究结果: 在Lmsys和MT-Bench数据集上的模拟实验表明，PredGen能在多种使用场景下将延迟减少约2倍，且仅需在输入时增加少量额外计算成本。

研究结论: PredGen通过输入时推测解码有效解决了LLM在实时语音交互中的延迟问题，显著提升了用户体验，同时计算成本增加极少。

中文摘要: 大型语言模型（LLM）广泛应用于实时语音聊天应用，通常与文本转语音（TTS）系统结合以生成音频响应。然而，其庞大的模型规模常导致用户输入结束到音频输出开始之间存在明显延迟，影响用户体验。这种延迟在LLM作为单用户语音助手部署于计算能力有限的消费级硬件上时尤为显著。研究发现，延迟主要源于LLM生成第一句话所需的时间，而TTS系统需要逐句合成音频响应。为解决这一瓶颈，我们提出了预测生成（PredGen）框架，通过在用户仍在说话时生成候选响应，实现输入时的推测解码，从而最小化延迟。在Lmsys和MT-Bench数据集上的模拟实验表明，该方法能在多种使用场景下将延迟减少约2倍，且仅需在输入时增加少量额外计算成本。这些计算成本在未使用时将被浪费。

</details>


### [38] [Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models](https://arxiv.org/abs/2506.15568)
**中文标题：性别包容性公平指数（GIFI）：一种评估大型语言模型中性别多样性的多层次框架**

*Zhengyang Shan,Emily Ruth Diana,Jiawei Zhou*

主要分类: cs.CL

摘要简述: 本文提出了一种名为GIFI的性别包容性公平指数，用于全面评估大型语言模型（LLM）在处理二元和非二元性别时的公平性。通过多层次评估，揭示了不同LLM在性别包容性上的显著差异。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注二元性别区分，忽略了非二元性别的公平性。本文旨在填补这一空白，通过GIFI全面评估LLM的性别包容性，为未来模型改进提供基准。

研究方法: 提出GIFI指标，从多个层次评估LLM的性别包容性，包括性别代词测试、生成内容分析和认知行为测试。对22种开源和专有LLM进行了广泛评估。

研究结果: 评估发现不同LLM在性别包容性上存在显著差异，揭示了与不同性别标识相关的偏见。

研究结论: 研究强调了提升LLM性别包容性的重要性，GIFI为未来性别公平性研究提供了关键基准。

中文摘要: 本文对大型语言模型（LLM）的性别公平性进行了全面评估，重点关注其处理二元和非二元性别的能力。以往研究主要关注二元性别区分，而我们提出了性别包容性公平指数（GIFI），这是一种新颖且全面的指标，用于量化LLM的性别包容性多样性。GIFI包含从简单测试模型对性别代词的反应，到在不同性别假设下评估模型生成内容和认知行为的多层次评估，揭示了与不同性别标识相关的偏见。我们对22种开源和专有LLM进行了广泛评估，发现它们在性别包容性上存在显著差异。本研究强调了提升LLM包容性的重要性，为未来生成模型性别公平性的改进提供了关键基准。

</details>


### [39] [SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification](https://arxiv.org/abs/2506.15569)
**中文标题：SciVer：评估多模态科学声明验证的基础模型**

*Chengye Wang,Yifei Shen,Zexi Kuang,Arman Cohan,Yilun Zhao*

主要分类: cs.CL

摘要简述: SciVer是首个专门评估基础模型在多模态科学声明验证中能力的基准，包含3000个专家标注的示例，覆盖4种常见推理类型。评估了21种先进多模态基础模型，发现其与人类专家存在显著性能差距，并揭示了当前开源模型的关键局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态基础模型在科学声明验证任务中的能力尚未得到系统评估，SciVer旨在填补这一空白，为模型在多模态科学文献中的理解和推理提供关键见解。

研究方法: SciVer包含3000个专家标注的示例，覆盖4种常见推理类型，并标注了支持证据。评估了21种先进多模态基础模型，包括o4-mini、Gemini-2.5-Flash等，通过检索增强生成（RAG）和人工错误分析进行深入评估。

研究结果: 实验显示，当前多模态基础模型与人类专家在SciVer上存在显著性能差距。开源模型在理解和推理多模态科学文献时表现出关键局限性。

研究结论: SciVer揭示了当前多模态基础模型在科学声明验证任务中的不足，为未来模型改进提供了重要方向。

中文摘要: 我们介绍了SciVer，这是首个专门设计用于评估基础模型在多模态科学背景下验证声明能力的基准。SciVer包含1,113篇科学论文中的3,000个专家标注示例，涵盖四种常见的多模态科学声明验证推理类型。为支持细粒度评估，每个示例均包含专家标注的支持证据。我们评估了21种先进的多模态基础模型，包括o4-mini、Gemini-2.5-Flash、Llama-3.2-Vision和Qwen2.5-VL。实验表明，这些模型与人类专家在SciVer上存在显著性能差距。通过检索增强生成（RAG）和人工错误评估的深入分析，我们揭示了当前开源模型的关键局限性，为提升模型在多模态科学文献任务中的理解和推理能力提供了重要见解。

</details>


### [40] [DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement](https://arxiv.org/abs/2506.15583)
**中文标题：DiscoSG：通过迭代图优化实现话语级文本场景图解析**

*Shaoqing Lin,Chong Teng,Fei Li,Donghong Ji,Lizhen Qu,Zhuang Li*

主要分类: cs.CL

摘要简述: 本文提出了一种新的任务——话语级文本场景图解析（DiscoSG），并开发了数据集DiscoSG-DS和模型DiscoSG-Refiner，通过迭代图优化显著提升了多句子描述的解析效果，同时降低了计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本场景图解析方法主要针对单句子描述，无法有效处理多句子描述中的跨句子共指等问题，导致解析结果碎片化，影响下游任务性能。

研究方法: 作者提出了DiscoSG-Refiner模型，使用两个小型PLM（Flan-T5-Base），首先生成基础图，然后通过迭代提出图编辑建议来优化结果，显著降低了计算开销。

研究结果: DiscoSG-Refiner在SPICE指标上比最佳基线提升了约30%，推理速度比GPT-4快86倍，同时显著提升了话语级标题评估和幻觉检测等下游任务性能。

研究结论: DiscoSG-Refiner通过迭代优化方法有效解决了多句子场景图解析的挑战，为开源社区提供了一种高效且低成本的解决方案。

中文摘要: 视觉语言模型（VLMs）现在能够生成话语级的多句子视觉描述，这对原本设计用于单句子标题到图映射的文本场景图解析器提出了挑战。当前方法通常合并句子级解析输出以处理话语输入，但往往忽略了跨句子共指等现象，导致图解析结果碎片化，并降低了下游VLM任务的性能。为解决这一问题，我们提出了一个新任务——话语级文本场景图解析（DiscoSG），并提供了数据集DiscoSG-DS，包含400个专家标注和8,430个合成的多句子标题-图对。每个标题平均包含9个句子，每个图的边数至少是现有数据集的3倍。尽管在DiscoSG-DS上微调大型PLM（如GPT-4）可将SPICE指标提升约48%，但高推理成本和严格的许可限制阻碍了其开源使用，而较小的微调PLM则难以处理复杂图。我们提出了DiscoSG-Refiner，它使用一个小型PLM生成基础图，然后通过第二个PLM迭代提出图编辑建议，减少了全图生成的开销。使用两个Flan-T5-Base模型，DiscoSG-Refiner仍比最佳基线提升了约30%的SPICE指标，同时推理速度比GPT-4快86倍。此外，它还显著提升了话语级标题评估和幻觉检测等下游VLM任务的性能。代码和数据可在以下网址获取：https://github.com/ShaoqLin/DiscoSG

</details>


### [41] [WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts](https://arxiv.org/abs/2506.15594)
**中文标题：WikiMixQA：一个用于表格和图表问答的多模态基准测试**

*Negar Foroutan,Angelika Romanou,Matin Ansaripour,Julian Martin Eisenschlos,Karl Aberer,Rémi Lebret*

主要分类: cs.CL

摘要简述: 本文提出了WikiMixQA，一个包含1000道多选题的基准测试，用于评估从4000个维基百科页面中提取的表格和图表的跨模态推理能力。研究发现，现有模型在处理长上下文和多模态信息时表现不佳，尤其是开源模型，最高准确率仅为27%。


<details>
  <summary>详细信息</summary>
研究动机: 文档通常包含复杂的布局、表格和图表，这对自动文档理解（DU）提出了挑战。尽管视觉语言大模型（VLLMs）在多项任务中表现优异，但其处理长上下文视觉输入的能力尚不明确。本文旨在填补这一空白，通过构建WikiMixQA基准测试，推动多模态推理和文档理解的研究。

研究方法: 本文构建了WikiMixQA基准测试，包含1000道多选题，覆盖7个主题的4000个维基百科页面中的表格和图表。测试要求模型综合多模态信息进行推理。作者评估了12种先进的视觉语言模型，包括专有模型和开源模型，比较它们在直接上下文和长文档检索场景下的表现。

研究结果: 实验结果显示，专有模型在直接上下文场景下准确率约为70%，但在长文档检索场景下性能显著下降。GPT-4-o是唯一准确率超过50%的模型，而开源模型表现更差，最高准确率仅为27%。

研究结论: 研究揭示了长上下文和多模态推理的挑战，并确立了WikiMixQA作为推动文档理解研究的重要基准。未来工作需要进一步提升模型在多模态和长上下文环境下的表现。

中文摘要: 文档是保存和传播信息的基础，通常包含复杂的布局、表格和图表，这对自动文档理解（DU）提出了重大挑战。尽管视觉语言大模型（VLLMs）在多项任务中表现出改进，但其处理长上下文视觉输入的效果尚不明确。本文介绍了WikiMixQA，一个包含1000道多选题的基准测试，旨在评估从4000个维基百科页面中提取的表格和图表的跨模态推理能力。与现有基准不同，WikiMixQA强调复杂推理，要求模型综合多模态信息。我们评估了12种先进的视觉语言模型，发现专有模型在直接上下文场景下准确率约为70%，但在长文档检索场景下性能显著下降。其中，GPT-4-o是唯一准确率超过50%的模型，而开源模型表现更差，最高准确率仅为27%。这些发现突显了长上下文和多模态推理的挑战，并将WikiMixQA确立为推进文档理解研究的关键基准。

</details>


### [42] [From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns](https://arxiv.org/abs/2506.15598)
**中文标题：从模型到课堂：基于叙事和难度考虑的葡萄牙语生成选择题评估**

*Bernardo Leite,Henrique Lopes Cardoso,Pedro Pinto,Abel Ferreira,Luís Abreu,Isabel Rangel,Sandra Monteiro*

主要分类: cs.CL

摘要简述: 本文研究了生成式AI在葡萄牙语阅读选择题（MCQ）生成中的应用，重点关注题目与课程叙事的匹配及难度分布。通过专家评审和学生反应分析，发现生成题目质量接近人工编写，但仍存在语义清晰度和干扰项设计问题。


<details>
  <summary>详细信息</summary>
研究动机: 手动编写具有不同难度和阅读技能目标的MCQ耗时且昂贵。生成式AI为自动化MCQ生成提供了可能，但其质量和可靠性评估不足，尤其是针对葡萄牙语等非英语语言的研究较少。本文旨在填补这一空白，并探讨生成题目在真实教学环境中的适用性。

研究方法: 研究利用生成式模型为葡萄牙语阅读生成MCQ，确保题目与课程叙事相关且覆盖不同难度。通过专家评审和学生反应的心理测量学分析，评估题目的质量和适用性。

研究结果: 结果显示，当前模型生成的MCQ质量接近人工编写题目，但在语义清晰度和干扰项设计上仍存在问题。干扰项未能充分吸引学生或满足高质量MCQ选项的标准。

研究结论: 生成式AI在葡萄牙语MCQ生成中展现出潜力，但需进一步优化语义表达和干扰项设计，以提升题目在真实教学环境中的实用性。

中文摘要: 尽管选择题（MCQ）对学习和评估具有重要价值，但手动编写具有不同难度和阅读技能目标的题目仍然耗时且成本高昂。生成式AI的最新进展为高效自动化MCQ生成提供了机会。然而，对生成MCQ的实际质量和可靠性的评估关注有限，尤其是在生成失败的情况下。当生成的MCQ需应用于真实教学环境时，这一点尤为重要。此外，大多数MCQ生成研究集中于英语，其他语言的研究较少。本文探讨了当前生成式模型为葡萄牙语（一种形态丰富的语言）生成阅读选择题的能力。研究聚焦于生成与课程叙事相关且覆盖不同难度的MCQ，并通过专家评审和学生反应的心理测量学分析评估其适用性。结果显示，当前模型生成的MCQ质量接近人工编写题目，但在语义清晰度和可回答性上存在问题。同时，干扰项设计仍面临挑战，需满足高质量MCQ选项的标准。

</details>


### [43] [The Compositional Architecture of Regret in Large Language Models](https://arxiv.org/abs/2506.15617)
**中文标题：大语言模型中后悔的组合架构**

*Xiangxiang Cui,Shu Yang,Tianjin Huang,Wanyu Lin,Lijie Hu,Di Wang*

主要分类: cs.CL

摘要简述: 本文研究大语言模型中的后悔机制，提出构建后悔数据集的方法及两种新指标（S-CDI和RDS），成功识别最优后悔表征层和神经元功能分组，揭示信息处理的耦合与解耦模式。


<details>
  <summary>详细信息</summary>
研究动机: 研究大语言模型中的后悔表达机制，旨在提升模型可靠性并揭示神经网络中的认知编码方式。当前面临缺乏专门数据集和有效指标的挑战。

研究方法: 提出三步方法：(1) 设计提示场景构建后悔数据集，(2) 使用S-CDI指标识别最优后悔表征层，(3) 通过RDS和GIC指标分析后悔神经元及其激活模式。

研究结果: 实验成功识别最优后悔表征层，发现M形解耦模式，并将神经元分为后悔神经元、非后悔神经元和双功能神经元三类。

研究结论: 本研究为理解后悔机制提供了新工具和见解，有助于提升模型可靠性和认知编码研究。

中文摘要: 大语言模型中的后悔指其在面对与先前生成错误信息相矛盾的证据时表现出的明确后悔表达。研究后悔机制对提升模型可靠性至关重要，并有助于揭示神经网络中的认知编码方式。为理解此机制，需首先识别模型输出中的后悔表达，再分析其内部表征。这一分析需考察模型的隐藏状态，其中信息处理发生在神经元层面。然而，此过程面临三大挑战：(1) 缺乏捕捉后悔表达的专门数据集，(2) 缺少识别最优后悔表征层的指标，(3) 缺乏识别和分析后悔神经元的指标。针对这些局限，本文提出：(1) 通过策略性设计的提示场景构建全面后悔数据集的工作流程，(2) 用于识别最优后悔表征层的监督压缩-解耦指数（S-CDI）指标，(3) 用于识别后悔神经元的后悔主导分数（RDS）指标及分析激活模式的群体影响系数（GIC）。实验结果表明，使用S-CDI指标成功识别了最优后悔表征层，显著提升了探针分类实验性能。此外，发现模型层间存在M形解耦模式，揭示了信息处理在耦合与解耦阶段交替的规律。通过RDS指标，将神经元分为三类功能组：后悔神经元、非后悔神经元和双功能神经元。

</details>


### [44] [Minding the Politeness Gap in Cross-cultural Communication](https://arxiv.org/abs/2506.15623)
**中文标题：跨文化交际中的礼貌差异研究**

*Yuka Machino,Matthias Hofer,Max Siegel,Joshua B. Tenenbaum,Robert D. Hawkins*

主要分类: cs.CL

摘要简述: 研究发现，英式英语和美式英语使用者对“quite”和“very”等强调词的理解差异源于字面意义和语用因素的复杂交互，而非单纯的语义或礼貌规范差异。


<details>
  <summary>详细信息</summary>
研究动机: 跨文化交际中的误解常源于对词语理解的微妙差异，但尚不清楚这些差异是由字面意义还是语用因素（如礼貌和简洁规范）引起。本文旨在探究这一问题。

研究方法: 通过三项实验，研究英式和美式英语使用者对强调词的理解，并开发计算认知模型，分析听者对说话者在信息性、礼貌和话语成本之间的权衡推理。

研究结果: 模型比较表明，强调词的跨文化理解差异源于字面意义和话语成本权重的不同组合，挑战了仅基于语义或礼貌规范的解释。

研究结论: 跨文化理解差异是字面意义与语用因素复杂交互的结果，需综合考虑两者才能全面解释。

中文摘要: 跨文化交际中的误解常源于对词语理解的微妙差异，但尚不清楚这些差异是由字面意义还是语用因素（如礼貌和简洁规范）引起。本文报告了三项实验，研究英式和美式英语使用者对“quite”和“very”等强调词的理解。为更好地理解这些差异，我们开发了一个计算认知模型，听者通过递归推理说话者在信息性、礼貌和话语成本之间的权衡。模型比较表明，强调词的跨文化理解差异源于字面意义和话语成本权重的不同组合。这些发现挑战了仅基于语义或礼貌规范的解释，表明跨文化理解差异是两者复杂交互的结果。

</details>


### [45] [Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability](https://arxiv.org/abs/2506.15629)
**中文标题：重新审视大语言模型的组合泛化能力：考虑指令遵循能力**

*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

主要分类: cs.CL

摘要简述: 本文提出Ordered CommonGen基准，用于评估大语言模型（LLMs）的组合泛化能力和指令遵循能力，发现LLMs在遵循指令时存在概念顺序偏见，且表现仍有提升空间。


<details>
  <summary>详细信息</summary>
研究动机: 在生成式常识推理任务中，LLMs能够生成包含所有给定概念的句子，但在指令遵循能力方面，当提示指定概念顺序时，LLMs需要生成符合顺序的句子。为此，作者提出Ordered CommonGen基准，以同时评估这两种能力。

研究方法: 作者设计了Ordered CommonGen基准，通过测量有序覆盖率来评估LLMs是否按照指定顺序生成概念。实验使用了36种LLMs进行综合分析。

研究结果: 研究发现，尽管LLMs能理解指令意图，但对特定概念顺序模式的偏见常导致输出多样性低或结果相同。表现最佳的LLM有序覆盖率仅为75%，表明其在指令遵循和组合泛化能力上仍需改进。

研究结论: Ordered CommonGen基准揭示了LLMs在指令遵循和组合泛化能力上的不足，为未来研究提供了改进方向。

中文摘要: 在生成式常识推理任务（如CommonGen）中，生成式大语言模型（LLMs）能够生成包含所有给定概念的句子。然而，当关注指令遵循能力时，若提示指定了概念顺序，LLMs必须生成符合该顺序的句子。为此，我们提出了Ordered CommonGen基准，旨在评估LLMs的组合泛化能力和指令遵循能力。该基准通过测量有序覆盖率来评估概念是否按指定顺序生成，从而同时评估这两种能力。我们使用36种LLMs进行了全面分析，发现尽管LLMs通常能理解指令意图，但对特定概念顺序模式的偏见常导致输出多样性低或结果相同，即使概念顺序改变。此外，即使是最遵循指令的LLM，其有序覆盖率也仅为75%左右，表明其在指令遵循和组合泛化能力上仍需改进。

</details>


### [46] [Oldies but Goldies: The Potential of Character N-grams for Romanian Texts](https://arxiv.org/abs/2506.15650)
**中文标题：老而弥坚：字符n-gram在罗马尼亚语文本中的潜力**

*Dana Lupsa,Sanda-Maria Avram*

主要分类: cs.CL

摘要简述: 本研究通过使用字符n-gram特征，系统评估了六种机器学习方法在罗马尼亚语文本作者归属任务中的表现，其中人工神经网络（ANN）表现最佳，展示了简单特征在资源受限语言中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决罗马尼亚语文本作者归属问题，探索轻量级且可解释的字符n-gram方法在资源受限或研究较少的语言中的适用性。

研究方法: 使用ROST语料库作为标准基准，系统评估了支持向量机（SVM）、逻辑回归（LR）、k近邻（k-NN）、决策树（DT）、随机森林（RF）和人工神经网络（ANN）六种方法，采用字符n-gram特征进行分类。

研究结果: ANN模型表现最佳，在使用5-gram特征时，15次运行中有4次实现了完美分类。结果表明，轻量级的字符n-gram方法可以达到与复杂方法相媲美的准确率。

研究结论: 研究表明，简单的字符n-gram特征在罗马尼亚语作者归属任务中具有显著潜力，尤其适用于资源受限或研究较少的语言环境。

中文摘要: 本研究针对罗马尼亚语文本的作者归属问题，使用ROST语料库作为标准基准，系统评估了六种机器学习技术：支持向量机（SVM）、逻辑回归（LR）、k近邻（k-NN）、决策树（DT）、随机森林（RF）和人工神经网络（ANN），并采用字符n-gram特征进行分类。其中，ANN模型表现最佳，在使用5-gram特征时，15次运行中有4次实现了完美分类。这些结果表明，轻量级且可解释的字符n-gram方法能够为罗马尼亚语作者归属任务提供最先进的准确率，甚至可与更复杂的方法相媲美。我们的发现凸显了简单风格特征在资源受限或研究较少的语言环境中的潜力。

</details>


### [47] [CC-LEARN: Cohort-based Consistency Learning](https://arxiv.org/abs/2506.15662)
**中文标题：CC-LEARN：基于队列的一致性学习**

*Xiao Ye,Shaswat Shrivastava,Zhaonan Li,Jacob Dineen,Shijie Lu,Avneet Ahuja,Ming Shen,Zhikun Xu,Ben Zhou*

主要分类: cs.CL

摘要简述: CC-LEARN是一种基于队列的一致性学习框架，通过强化学习提升大语言模型的推理一致性和鲁棒性，实验证明其在多个推理基准测试中优于预训练和SFT基线。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在许多任务中表现出色，但在一致性和鲁棒性推理方面仍存在不足。为了解决这一问题，作者提出了基于队列的一致性学习框架，旨在通过队列级别的训练提升模型的推理可靠性。

研究方法: CC-LEARN采用强化学习框架，通过定义复合目标（包括队列准确性、问题分解的检索奖励和无效查询的拒绝惩罚）来优化模型。该方法利用共享的程序化抽象生成相似问题队列，并通过强化学习直接优化目标，确保模型在队列成员间采用一致的推理模式。

研究结果: 在ARC-Challenge和StrategyQA等具有挑战性的推理基准测试中，CC-LEARN显著提升了模型的准确性和推理稳定性，表现优于预训练和SFT基线。

研究结论: 队列级别的强化学习能有效提升大语言模型的推理一致性，CC-LEARN为增强模型鲁棒性提供了一种可行的方法。

中文摘要: 大语言模型在许多任务中表现出色，但在一致性和鲁棒性推理方面仍有不足。我们提出了基于队列的一致性学习（CC-LEARN），这是一种强化学习框架，通过训练由共享程序化抽象生成的相似问题队列，提升大语言模型推理的可靠性。为了确保队列级别的一致性，我们定义了一个复合目标，包括队列准确性、有效问题分解的检索奖励以及对无效查询的拒绝惩罚，这些目标可以直接通过强化学习优化，而不同于监督微调。优化这一奖励机制可以引导模型在所有队列成员中采用一致的推理模式。在具有挑战性的推理基准测试（包括ARC-Challenge和StrategyQA）中，实验表明CC-LEARN在准确性和推理稳定性上均优于预训练和SFT基线。这些结果表明，队列级别的强化学习能有效提升大语言模型的推理一致性。

</details>


### [48] [Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](https://arxiv.org/abs/2506.15674)
**中文标题：泄露的思维：大型推理模型并非私密思考者**

*Tommaso Green,Martin Gubri,Haritz Puerto,Sangdoo Yun,Seong Joon Oh*

主要分类: cs.CL

摘要简述: 研究发现大型推理模型的推理痕迹中常包含敏感用户数据，可能通过提示注入或意外泄露。增加推理步骤会放大隐私泄露风险，揭示了推理能力提升与隐私保护之间的核心矛盾。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型作为个人代理时，其推理痕迹常被视为内部安全信息。然而，这种假设可能不成立，因为推理痕迹可能包含敏感用户数据，导致隐私泄露。本文旨在验证这一假设并探讨其影响。

研究方法: 通过探测和代理评估，研究推理痕迹中的隐私泄露问题，重点关注测试时计算（如增加推理步骤）对隐私泄露的放大作用。

研究结果: 研究发现，推理痕迹中确实存在敏感用户数据，且增加推理步骤会显著增加隐私泄露风险。尽管模型在最终答案中表现更谨慎，但其推理过程更冗长，泄露更多信息。

研究结论: 推理能力的提升与隐私保护之间存在矛盾，安全措施需扩展至模型的内部推理过程，而不仅限于最终输出。

中文摘要: 我们研究了大型推理模型作为个人代理时，其推理痕迹中的隐私泄露问题。与最终输出不同，推理痕迹常被视为内部安全信息。我们通过实验挑战了这一假设，发现推理痕迹中常包含敏感用户数据，这些数据可能通过提示注入或意外泄露。通过探测和代理评估，我们发现测试时计算（尤其是增加推理步骤）会放大此类泄露。尽管增加测试时计算预算使模型在最终答案中表现更谨慎，但也导致其推理更冗长，泄露更多信息。这揭示了一个核心矛盾：推理提升了效用，却扩大了隐私攻击面。我们认为，安全措施必须扩展至模型的内部推理过程，而不仅限于其输出。

</details>


### [49] [Gender-Neutral Machine Translation Strategies in Practice](https://arxiv.org/abs/2506.15676)
**中文标题：实践中性别中立的机器翻译策略**

*Hillary Dawkins,Isar Nejadgholi,Chi-kiu Lo*

主要分类: cs.CL

摘要简述: 研究评估了21种机器翻译系统在性别模糊情况下的性别中立翻译表现，发现大多数系统未能实现性别中立翻译，但少数系统采用了特定策略。


<details>
  <summary>详细信息</summary>
研究动机: 性别包容的机器翻译需要保留源语言中的性别模糊性以避免性别误判和代表性伤害，但在语法性别语言中实现性别中立翻译具有挑战性。

研究方法: 评估了21种机器翻译系统在三种不同难度的翻译方向中对性别模糊的敏感性，并对实践中观察到的性别中立策略进行了分类和讨论。

研究结果: 大多数机器翻译系统在性别模糊情况下未能提供性别中立翻译，但少数系统根据目标语言采用了特定的性别中立策略。

研究结论: 性别中立翻译在机器翻译中仍不普遍，但部分系统展示了可行的策略，未来需进一步优化。

中文摘要: 性别包容的机器翻译（MT）应保留源语言中的性别模糊性，以避免性别误判和代表性伤害。尽管性别模糊在英语等概念性别语言中自然存在，但在语法性别语言中保持性别中立是一项挑战。本文评估了21种机器翻译系统在三种不同难度的翻译方向中对性别模糊的敏感性，并对实践中观察到的性别中立策略进行了分类和讨论。此外，我们还研究了二元性别刻板印象对性别中立翻译使用的影响。总体而言，我们发现机器翻译在性别模糊情况下普遍缺乏性别中立翻译。然而，观察到少数机器翻译系统根据目标语言采用了特定的性别中立策略。

</details>


### [50] [GenRecal: Generation after Recalibration from Large to Small Vision-Language Models](https://arxiv.org/abs/2506.15681)
**中文标题：GenRecal：从大型到小型视觉语言模型的重新校准后生成**

*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

主要分类: cs.CL

摘要简述: GenRecal提出了一种通用蒸馏框架，通过特征对齐实现从大型视觉语言模型到小型模型的高效知识迁移，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型视觉语言模型（VLMs）性能接近闭源系统如GPT-4V，但其高计算需求限制了在资源受限设备上的部署。因此，需要将知识从大型VLMs蒸馏到小型高效模型中，但不同VLMs的架构多样性（如词汇量、分词方式等）带来了挑战。

研究方法: GenRecal引入了一个名为Recalibrator的模块，用于对齐和适配异构VLMs之间的特征表示，从而实现跨不同类型VLMs的有效知识迁移。

研究结果: 在多个基准测试中，GenRecal显著提升了基线性能，甚至超越了大规模开源和闭源VLMs的表现。

研究结论: GenRecal作为一种通用蒸馏框架，成功解决了异构VLMs之间的知识迁移问题，为资源受限设备上的高效部署提供了可行方案。

中文摘要: 近期视觉语言模型（VLMs）的进展通过利用大型语言模型（LLMs）实现了与闭源系统如GPT-4V相当的性能。然而，这些模型在实际场景中的部署，尤其是在资源受限设备上，仍因其巨大的计算需求而面临挑战。这促使人们关注如何将知识从大型VLMs蒸馏到更小、更高效的模型中。然而，不同VLMs的架构多样性（如词汇量、分词方式和索引顺序的差异）带来了关键挑战。为解决这一限制特定VLM类型的问题，我们提出了重新校准后生成（GenRecal），一种通用的VLM蒸馏框架。GenRecal包含一个Recalibrator模块，用于对齐和适配异构VLMs之间的特征表示，从而实现跨不同类型VLMs的有效知识迁移。通过在多个具有挑战性的基准测试中进行广泛实验，我们证明GenRecal显著提升了基线性能，最终超越了大尺度开源和闭源VLMs的表现。

</details>


### [51] [PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning](https://arxiv.org/abs/2506.15683)
**中文标题：PhantomHunter：基于家族感知学习的未公开私有调优LLM生成文本检测**

*Yuhui Shi,Yehan Yang,Qiang Sheng,Hao Mi,Beizhe Hu,Chaoxi Xu,Juan Cao*

主要分类: cs.CL

摘要简述: PhantomHunter是一种新型检测器，专门用于识别未公开的私有调优LLM生成的文本，通过家族感知学习框架捕捉基础模型及其衍生模型的共享特征，实验表明其在检测性能上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的普及，虚假信息和学术不端等社会问题日益严重，现有检测器对私有调优LLM生成的文本效果不佳，亟需解决这一问题。

研究方法: PhantomHunter采用家族感知学习框架，通过捕捉基础模型及其衍生模型的家族级共享特征，而非记忆单个模型特性，实现对私有调优LLM生成文本的检测。

研究结果: 在LLaMA、Gemma和Mistral家族数据上的实验显示，PhantomHunter优于7种基线方法和3种工业服务，F1分数超过96%。

研究结论: PhantomHunter通过家族感知学习有效解决了私有调优LLM生成文本的检测问题，为LLM滥用提供了新的解决方案。

中文摘要: 随着大型语言模型（LLM）的流行，虚假信息生产和学术不端等社会问题愈发严重，使得LLM生成文本检测变得前所未有的重要。尽管现有方法已取得显著进展，但私有调优LLM生成的文本带来的新挑战尚未充分研究。用户可通过私有语料微调开源LLM轻松获得私有模型，导致现有检测器在实际应用中性能显著下降。为解决这一问题，我们提出PhantomHunter，一种专门用于检测未公开私有调优LLM生成文本的检测器。其家族感知学习框架捕捉基础模型及其衍生模型的家族级共享特征，而非记忆单个特性。在LLaMA、Gemma和Mistral家族数据上的实验表明，其优于7种基线方法和3种工业服务，F1分数超过96%。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2506.14791)
**中文标题：SemIRNet：一种用于多模态讽刺检测的语义反讽识别网络**

*Jingxuan Zhou,Yuehao Wu,Yibo Zhang,Yeyubei Zhang,Yunchong Liu,Bolin Huang,Chunhong Yuan*

主要分类: cs.CV

摘要简述: 本文提出了一种语义反讽识别网络（SemIRNet），用于多模态讽刺检测，通过引入ConceptNet知识库、设计跨模态语义相似性检测模块和对比学习损失函数，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 针对多模态讽刺检测任务中图形隐含关联难以准确识别的问题，本文旨在通过引入知识库和跨模态语义建模，提升模型的常识推理能力和检测精度。

研究方法: 1. 首次引入ConceptNet知识库以获取概念知识；2. 设计词级和样本级跨模态语义相似性检测模块；3. 采用对比学习损失函数优化样本特征空间分布。

研究结果: 在公开数据集上，模型准确率和F1值分别提升1.64%和2.88%，达到88.87%和86.33%，消融实验验证了知识融合和语义相似性检测的重要性。

研究结论: SemIRNet通过知识融合和多粒度语义建模，显著提升了多模态讽刺检测的性能，为相关任务提供了新思路。

中文摘要: 针对多模态讽刺检测任务中图形隐含关联难以准确识别的问题，本文提出了一种语义反讽识别网络（SemIRNet）。该模型包含三大创新点：（1）首次引入ConceptNet知识库以获取概念知识，增强模型的常识推理能力；（2）设计词级和样本级两种跨模态语义相似性检测模块，实现不同粒度的图文关联建模；（3）引入对比学习损失函数优化样本特征空间分布，提升正负样本的可分性。在公开的多模态讽刺检测基准数据集上的实验表明，该模型的准确率和F1值分别较现有最优方法提升了1.64%和2.88%，达到88.87%和86.33%。进一步的消融实验验证了知识融合和语义相似性检测对提升模型性能的重要作用。

</details>


### [53] [Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?](https://arxiv.org/abs/2506.14805)
**中文标题：Argus检验：多模态大语言模型是否拥有Panoptes之眼？**

*Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang*

主要分类: cs.CV

摘要简述: 本文介绍了Argus Inspection，一个多模态基准测试，用于评估多模态大语言模型（MLLMs）在细粒度视觉感知和常识因果推理方面的能力。通过实验发现，当前模型的最高性能仅为0.46，表明仍有较大改进空间。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）的发展，其认知和推理能力显著提升，但在细粒度视觉感知和常识因果推理方面仍存在挑战。本文旨在通过Argus Inspection基准测试，全面评估MLLMs在这些方面的表现。

研究方法: 本文提出Argus Inspection基准测试，包含两个难度级别，专注于细粒度视觉识别和常识因果推理。进一步提出Eye of Panoptes框架，结合二元参数Sigmoid指标和指示函数，全面评估MLLMs在基于意见的推理任务中的表现。

研究结果: 实验对26个主流MLLMs进行了测试，结果显示在细粒度视觉推理任务中，最高性能仅为0.46，表明模型仍有显著提升空间。

研究结论: 研究表明，当前MLLMs在细粒度视觉感知和常识因果推理方面仍需改进。Argus Inspection和Eye of Panoptes框架为未来模型优化提供了有价值的参考。

中文摘要: 随着多模态大语言模型（MLLMs）的不断发展，其认知和推理能力取得了显著进步。然而，在细粒度视觉感知和常识因果推理方面仍存在挑战。本文提出了Argus Inspection，一个包含两个难度级别的多模态基准测试，重点评估细粒度视觉识别能力，并融入现实世界的常识理解以测试因果推理能力。在此基础上，我们提出了Eye of Panoptes框架，该框架结合了二元参数Sigmoid指标和指示函数，能够更全面地评估MLLMs在基于意见的推理任务中的表现。通过对26个主流MLLMs的实验发现，细粒度视觉推理的最高性能仅为0.46，表明仍有较大改进空间。本研究为MLLMs的持续优化提供了宝贵视角。

</details>


### [54] [A Hybrid ConvNeXt-EfficientNet AI Solution for Precise Falcon Disease Detection](https://arxiv.org/abs/2506.14816)
**中文标题：一种基于ConvNeXt-EfficientNet混合AI模型的猎鹰疾病精确检测方法**

*Alavikunhu Panthakkan,Zubair Medammal,S M Anzar,Fatma Taher,Hussain Al-Ahmad*

主要分类: cs.CV

摘要简述: 本文提出了一种结合ConvNeXt和EfficientNet的混合AI模型，用于精确检测猎鹰疾病，显著优于传统方法和单一模型。


<details>
  <summary>详细信息</summary>
研究动机: 猎鹰训练和狩猎传统需要严格的健康监测，以确保猎鹰的健康和安全。传统诊断方法效率低且不够精确，因此需要一种更先进的AI解决方案。

研究方法: 研究采用ConvNeXt和EfficientNet混合模型，对猎鹰的三种健康状况（正常、肝病和曲霉病）进行分类。使用大规模数据集进行训练和验证，并关注准确性、精确度、召回率和F1分数等关键指标。

研究结果: 实验表明，混合模型在疾病检测中表现优异，显著优于传统方法和单一模型架构。

研究结论: 该混合AI模型的成功应用为猎鹰疾病检测提供了更精确的工具，并为未来AI驱动的鸟类健康解决方案奠定了基础。

中文摘要: 猎鹰训练和狩猎是一项备受尊崇的传统，需要对猎鹰进行严格的健康监测以确保其健康和安全，尤其是在狩猎场景中。本文提出了一种创新的方法，结合ConvNeXt和EfficientNet AI模型对猎鹰疾病进行分类，重点关注三种状态：正常、肝病和曲霉病。研究使用了大规模数据集进行模型训练和验证，并着重评估了准确性、精确度、召回率和F1分数等关键性能指标。大量测试和分析表明，我们的混合AI模型优于传统诊断方法和单一模型架构。该混合AI模型的成功实施标志着猎鹰疾病精确检测的重大进步，并为未来AI驱动的鸟类健康解决方案的发展铺平了道路。

</details>


### [55] [ViLLa: A Neuro-Symbolic approach for Animal Monitoring](https://arxiv.org/abs/2506.14823)
**中文标题：ViLLa：一种神经符号方法用于动物监测**

*Harsha Koduri*

主要分类: cs.CV

摘要简述: ViLLa是一种神经符号框架，用于可解释的动物监测，结合视觉检测、语言解析和符号推理，回答自然语言查询。


<details>
  <summary>详细信息</summary>
研究动机: 自然环境中监测动物种群需要能同时处理视觉数据和语言查询的系统，ViLLa旨在提供模块化和透明的解决方案。

研究方法: ViLLa整合视觉检测模块（识别动物及其位置）、语言解析器（理解自然语言查询）和符号推理层（逻辑推断回答问题）。

研究结果: ViLLa在多种动物图像任务中表现优异，能够将视觉内容与结构化、可解释的查询结合。

研究结论: ViLLa通过分离感知、理解和推理，提供了一种模块化且透明的动物监测方法，优于端到端黑盒模型。

中文摘要: 监测自然环境中动物种群需要能同时解释视觉数据和人类语言查询的系统。本文提出ViLLa（视觉-语言-逻辑方法），一种神经符号框架，专为可解释的动物监测设计。ViLLa整合三个核心组件：视觉检测模块（识别图像中动物及其空间位置）、语言解析器（理解自然语言查询）和符号推理层（应用基于逻辑的推断回答问题）。给定图像和问题（如“场景中有多少只狗？”或“水牛在哪里？”），系统将视觉检测转化为符号事实，并使用预定义规则计算与数量、存在和位置相关的准确答案。与端到端黑盒模型不同，ViLLa分离感知、理解和推理，提供模块化和透明度。系统在多种动物图像任务中评估，展示了将视觉内容与结构化、人类可解释查询结合的能力。

</details>


### [56] [GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction](https://arxiv.org/abs/2506.14825)
**中文标题：GraphGSOcc：基于3D高斯喷溅的语义与几何图Transformer占用预测**

*Ke Song,Yunhe Wu,Chunchit Siu,Huiyuan Xiong*

主要分类: cs.CV

摘要简述: GraphGSOcc提出了一种结合语义和几何图Transformer的3D高斯喷溅占用预测框架，通过双高斯图注意力动态构建几何和语义图结构，优化边界细节和对象级拓扑，在SurroundOcc数据集上实现了mIoU提升和GPU内存降低。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D高斯喷溅方法存在两个问题：一是统一特征聚合忽略了相似类别和跨区域的语义关联，二是MLP迭代优化缺乏几何约束导致边界模糊。GraphGSOcc旨在解决这些问题。

研究方法: 提出双高斯图注意力，动态构建几何图和语义图：几何图基于高斯位姿自适应计算KNN搜索半径，语义图通过余弦相似度保留高相关节点。结合多尺度图注意力框架，优化边界细节和对象级拓扑。

研究结果: 在SurroundOcc数据集上，mIoU达到24.10%，GPU内存降至6.1 GB，相比GaussianWorld提升1.97% mIoU并减少13.7%内存。

研究结论: GraphGSOcc通过语义和几何图Transformer显著提升了3D高斯喷溅占用预测的性能和效率。

中文摘要: 针对自动驾驶中的3D语义占用预测任务，我们解决了现有3D高斯喷溅（3DGS）方法的两个关键问题：（1）统一特征聚合忽略了相似类别和跨区域的语义关联；（2）MLP迭代优化缺乏几何约束导致边界模糊。我们提出了GraphGSOcc模型，一种结合语义和几何图Transformer的新型框架。通过双高斯图注意力，动态构建两种图结构：几何图基于高斯位姿自适应计算KNN搜索半径，使大尺度高斯从更广邻域聚合特征，而紧凑高斯关注局部几何一致性；语义图通过余弦相似度保留高相关节点，显式编码实例内和跨实例的语义关系。结合多尺度图注意力框架，低层细粒度注意力优化边界细节，高层粗粒度注意力建模对象级拓扑。在SurroundOcc数据集上的实验实现了24.10%的mIoU，GPU内存降至6.1 GB，相比GaussianWorld提升1.97% mIoU并减少13.7%内存。

</details>


### [57] [DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning](https://arxiv.org/abs/2506.14827)
**中文标题：DAVID-XR1：基于可解释推理的AI生成视频检测**

*Yifeng Gao,Yifan Ding,Hongyu Su,Juncheng Li,Yunhan Zhao,Lin Luo,Zixing Chen,Li Wang,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang*

主要分类: cs.CV

摘要简述: 本文提出DAVID-XR1，一种可解释的视频检测模型，用于识别AI生成的视频并提供详细的时空缺陷标注和自然语言解释，将检测过程从黑盒决策转变为透明诊断。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成视频在媒体平台上的普及，可靠区分合成内容与真实视频的需求日益迫切。现有方法仅将其视为二分类任务，缺乏对检测原因和位置的解释，而实际需求是提供细粒度、可信的证据。

研究方法: 作者构建了DAVID-X数据集，包含AI生成视频的时空缺陷标注和书面解释，并基于此开发了DAVID-XR1模型。该模型通过视觉推理链（缺陷分类、时空定位和自然语言解释）实现透明化检测。

研究结果: 实验表明，通用主干网络在DAVID-X数据集上微调后，结合思维链蒸馏技术，能够泛化到多种生成器和生成模式，验证了可解释检测方法的有效性。

研究结论: DAVID-XR1将AI生成视频检测从黑盒决策转变为透明诊断过程，为可信检测提供了新思路。

中文摘要: 随着AI生成视频在媒体平台上的广泛应用，可靠区分合成内容与真实视频变得至关重要。现有方法主要将其视为二分类任务，无法解释模型为何或如何判定视频为AI生成。然而，核心挑战不仅在于检测细微伪影，还需提供细粒度、可信的证据以说服审核者和用户。为此，我们提出DAVID-X，首个包含AI生成视频的时空缺陷标注和书面解释的数据集。基于这些丰富标注，我们开发了DAVID-XR1，一种视频-语言模型，能够提供可解释的视觉推理链（包括缺陷分类、时空定位和自然语言解释）。这一方法从根本上将AI生成视频检测从黑盒决策转变为透明、可验证的诊断过程。实验表明，通用主干网络在DAVID-X数据集上微调并结合思维链蒸馏技术，能够泛化到多种生成器和生成模式。结果凸显了可解释检测方法在可信识别AI生成视频内容中的潜力。

</details>


### [58] [Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review](https://arxiv.org/abs/2506.14831)
**中文标题：多智能体人类轨迹预测的最新进展：全面综述**

*Céline Finet,Stephane Da Silva Martins,Jean-Bernard Hayet,Ioannis Karamouzas,Javad Amirian,Sylvie Le Hégarat-Mascle,Julien Pettré,Emanuel Aldea*

主要分类: cs.CV

摘要简述: 本文综述了2020至2024年间基于深度学习的多智能体人类轨迹预测的最新进展，重点分析了模型架构、输入表示和预测策略，并指出了该领域的关键挑战与未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据驱动方法在人类轨迹预测（HTP）中的广泛应用，深入理解多智能体交互成为可能，这对自动驾驶导航和人群建模等领域具有重要意义。本文旨在总结近年来的研究进展，为未来研究提供参考。

研究方法: 本文对2020至2024年间发表的深度学习多智能体轨迹预测研究进行了系统综述，重点分析了模型的架构设计、输入表示和预测策略，并以ETH/UCY基准测试为评估标准。

研究结果: 综述总结了多智能体轨迹预测领域的最新方法，分类讨论了不同模型的特点，并指出了当前研究中的关键挑战，如交互建模的复杂性和数据稀缺问题。

研究结论: 本文为多智能体人类轨迹预测领域的研究提供了全面的综述，强调了未来需要解决的挑战，并提出了可能的研究方向，如改进交互建模和利用多模态数据。

中文摘要: 随着数据驱动方法在人类轨迹预测（HTP）中的兴起，深入理解多智能体交互已成为可能，这对自动驾驶导航和人群建模等领域具有重要意义。本文综述了2020至2024年间基于深度学习的多智能体轨迹预测的最新进展，重点关注模型的架构设计、输入表示和预测策略，并以ETH/UCY基准测试为评估标准。此外，本文还总结了多智能体HTP领域的关键挑战和未来研究方向。

</details>


### [59] [ArchShapeNet:An Interpretable 3D-CNN Framework for Evaluating Architectural Shapes](https://arxiv.org/abs/2506.14832)
**中文标题：ArchShapeNet：一种用于评估建筑形状的可解释3D-CNN框架**

*Jun Yin,Jing Zhong,Pengyu Zeng,Peilin Li,Zixuan Dai,Miao Zhang,Shuai Lu*

主要分类: cs.CV

摘要简述: 本文提出ArchShapeNet，一种用于评估建筑形状的3D-CNN框架，通过构建ArchForms-4000数据集和引入显著性模块，模型在区分人类设计与机器生成形状上表现优异，准确率达94.29%。


<details>
  <summary>详细信息</summary>
研究动机: 现代建筑设计中，生成式工具快速产生初始概念和探索新3D形式的需求日益增长，但客观分析人类设计与机器生成3D形式的差异仍具挑战性，阻碍了生成工具的进步。

研究方法: 构建ArchForms-4000数据集（包含2000个人类设计和2000个Evomass生成的3D形式），提出ArchShapeNet（一种专为分类和分析建筑形式设计的3D-CNN，包含显著性模块以突出与建筑推理相关的关键空间特征）。

研究结果: 模型在区分形式来源上表现优于人类专家，准确率为94.29%，精确率为96.2%，召回率为98.51%。

研究结论: 研究不仅揭示了人类设计形式在空间组织、比例和谐及细节优化上的独特优势，还为未来生成设计工具的改进提供了宝贵见解。

中文摘要: 在当代建筑设计中，设计需求的日益复杂和多样化使得生成式插件工具成为快速产生初始概念和探索新颖3D形式的必备工具。然而，客观分析人类设计与机器生成3D形式之间的差异仍是一个挑战，限制了我们对其各自优势的理解，并阻碍了生成工具的进步。为此，我们构建了ArchForms-4000数据集，包含2000个建筑师设计和2000个Evomass生成的3D形式；提出了ArchShapeNet，一种专为分类和分析建筑形式设计的3D卷积神经网络，并引入显著性模块以突出与建筑推理相关的关键空间特征；通过对比实验表明，我们的模型在区分形式来源上优于人类专家，准确率达94.29%，精确率为96.2%，召回率为98.51%。本研究不仅揭示了人类设计形式在空间组织、比例和谐及细节优化上的独特优势，还为未来生成设计工具的改进提供了宝贵见解。

</details>


### [60] [Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices](https://arxiv.org/abs/2506.14833)
**中文标题：基于熵的自适应缓冲与MobileNetV2的边缘设备实时低延迟监控**

*Poojashree Chandrashekar Pankaj M Sajjanar*

主要分类: cs.CV

摘要简述: 本文提出了一种基于熵的自适应帧缓冲算法，结合MobileNetV2，在资源受限的边缘设备上实现了高性能、低延迟的视频监控系统，端到端推理延迟低于50毫秒，检测准确率超过92%。


<details>
  <summary>详细信息</summary>
研究动机: 针对资源受限环境下的视频监控需求，设计一种高性能、低延迟的系统，同时满足数据隐私法规要求。

研究方法: 提出基于熵的自适应帧缓冲算法，结合轻量级MobileNetV2模型，优化实时视频流处理。

研究结果: 系统在Raspberry Pi等边缘设备上实现低于50毫秒的延迟，检测准确率超过92%，且对光照、背景和速度变化具有鲁棒性。

研究结论: 该系统具有高性能、低延迟、低成本及隐私合规性，适用于智能城市或嵌入式安全架构。

中文摘要: 本文描述了一种针对资源受限环境设计的高性能、低延迟视频监控系统。我们提出了一种基于熵的自适应帧缓冲算法，并与MobileNetV2结合，实现了高吞吐量和低延迟。该系统能够在资源受限设备（如Raspberry Pi、Amazon和NVIDIA Jetson Nano等嵌入式平台）上处理实时视频流，端到端推理延迟低于50毫秒。我们的方法在专注于视频监控的标准数据集上保持了超过92%的检测准确率，并对不同光照、背景和速度变化表现出鲁棒性。多项对比和消融实验验证了设计的有效性。最后，我们的架构具有可扩展性、低成本性，并符合比常见监控系统更严格的数据隐私法规，因此该系统可以应用于智能城市或嵌入式安全架构。

</details>


### [61] [MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation](https://arxiv.org/abs/2506.14835)
**中文标题：MonoVQD：基于变分查询去噪和自蒸馏的单目3D物体检测**

*Kiet Dang Vu,Trung Thai Tran,Duc Dung Nguyen*

主要分类: cs.CV

摘要简述: MonoVQD是一种基于DETR的单目3D物体检测框架，通过变分查询去噪和自蒸馏技术提升性能，解决了传统方法的梯度消失和优化不稳定问题，并在KITTI和nuScenes数据集上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 单目3D物体检测在直接应用DETR架构时存在性能限制，MonoVQD旨在通过引入变分查询去噪和自蒸馏技术，解决梯度消失和优化不稳定问题，提升检测性能。

研究方法: 1. 提出掩码分离自注意力机制，将去噪过程集成到DETR架构中，优化匈牙利匹配的稳定性。2. 设计变分查询去噪技术，解决传统去噪方法的梯度消失问题。3. 引入自蒸馏策略，利用后期解码层信息提升早期查询质量。

研究结果: MonoVQD在KITTI单目3D检测基准上表现优异，其核心组件在多视图3D检测（nuScenes数据集）中也显著提升性能，展示了强大的泛化能力。

研究结论: MonoVQD通过创新的去噪和自蒸馏技术，显著提升了单目3D检测性能，并展示了在多场景下的广泛适用性。

中文摘要: 从单张图像中精确定位3D物体是单目3D检测的核心挑战。尽管DETR类架构提供了强大的范式，但其直接应用在该领域存在固有局限性，无法达到最优性能。我们的工作通过提出MonoVQD框架，从根本上推动了基于DETR的单目3D检测。我们提出了三项主要贡献：首先，提出掩码分离自注意力机制，将去噪过程集成到DETR架构中，提升匈牙利匹配的稳定性以实现一致的优化目标。其次，设计变分查询去噪技术，解决传统去噪方法的梯度消失问题，通过引入随机特性显著提升性能。最后，引入自蒸馏策略，利用后期解码层信息协同提升早期查询质量，增强迭代优化过程。实验表明，MonoVQD在KITTI单目基准上表现优异，其核心组件在多视图3D检测（nuScenes数据集）中也显著提升性能，展示了强大的泛化能力。

</details>


### [62] [Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction](https://arxiv.org/abs/2506.14837)
**中文标题：通过结构化指令改进图表到代码生成的迭代优化方法**

*Chengzhi Xu,Yuyang Wang,Lai Wei,Lichao Sun,Weiran Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于结构化指令的迭代优化方法ChartIR，用于提升多模态大语言模型（MLLMs）在图表到代码生成任务中的表现。通过将任务分解为视觉理解和代码翻译两部分，并设计描述和差异两种结构化指令，显著提高了生成代码的准确性。实验表明，该方法在开源模型Qwen2-VL和闭源模型GPT-4o上均优于其他方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在多种视觉任务中表现优异，但在图表到代码生成任务中仍存在不足。该任务需要模型不仅精确理解视觉元素，还需将其准确翻译为结构化代码。直接使用MLLMs生成代码效果不佳，因此需要一种更有效的方法来提升性能。

研究方法: 本文提出ChartIR方法，将任务分解为视觉理解和代码翻译两部分。设计两种结构化指令：描述指令用于捕捉参考图表的视觉元素，差异指令用于表征参考图表与生成图表之间的差异。此外，将图表生成流程分为初始代码生成和迭代优化两个阶段，逐步提升输出质量。

研究结果: 实验结果表明，ChartIR方法在开源模型Qwen2-VL和闭源模型GPT-4o上均取得了优于其他方法的性能，显著提升了图表到代码生成的准确性。

研究结论: 通过结构化指令和迭代优化，ChartIR方法有效解决了多模态大语言模型在图表到代码生成任务中的性能瓶颈，为复杂视觉任务的代码生成提供了新思路。

中文摘要: 近年来，多模态大语言模型（MLLMs）因其强大的视觉理解能力受到广泛关注。尽管在多种视觉任务中表现优异，但在图表到代码生成任务中仍不尽如人意。该任务要求MLLMs生成可执行代码以复现给定图表，不仅需要精确的视觉理解，还需将视觉元素准确翻译为结构化代码。直接提示MLLMs完成这一复杂任务往往效果不佳。为解决这一问题，我们提出了ChartIR，一种基于结构化指令的迭代优化方法。首先，我们将任务分为视觉理解和代码翻译两部分。为完成视觉理解部分，设计了两种结构化指令：描述指令和差异指令。描述指令捕捉参考图表的视觉元素，差异指令表征参考图表与生成图表之间的差异。这些指令将视觉特征转化为语言表示，从而促进后续代码翻译过程。其次，我们将整体图表生成流程分解为初始代码生成和迭代优化两个阶段，逐步提升最终输出质量。实验结果表明，与其他方法相比，我们的方法在开源模型Qwen2-VL和闭源模型GPT-4o上均取得了更优的性能。

</details>


### [63] [PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers](https://arxiv.org/abs/2506.14842)
**中文标题：PictSure：预训练嵌入对上下文学习图像分类器至关重要**

*Lukas Schiesser,Cornelius Wolff,Sophie Haas,Simon Pukrop*

主要分类: cs.CV

摘要简述: PictSure研究揭示了图像嵌入模型在上下文学习（ICL）中的关键作用，通过系统分析嵌入模型的架构、预训练和微调策略，显著提升了少样本图像分类的跨域性能。


<details>
  <summary>详细信息</summary>
研究动机: 在数据稀缺领域，构建图像分类模型面临挑战，而上下文学习（ICL）为少样本图像分类（FSIC）提供了新思路。然而，现有研究忽视了图像嵌入模型的重要性。本文旨在探讨嵌入模型对ICL性能的影响。

研究方法: PictSure框架聚焦于图像嵌入模型的架构、预训练目标和微调策略，通过系统实验分析其对少样本图像分类性能的影响。

研究结果: 实验表明，嵌入模型的预训练方式显著影响训练成功率和跨域性能。PictSure在显著不同于训练分布的跨域任务上优于现有ICL模型，同时保持域内任务的竞争力。

研究结论: PictSure证明了嵌入模型预训练对上下文学习的重要性，为少样本图像分类提供了更优的跨域解决方案。

中文摘要: 在数据稀缺领域构建图像分类模型仍然繁琐，因为收集大规模标注数据不切实际。上下文学习（ICL）已成为少样本图像分类（FSIC）的有前景范式，使模型无需基于梯度的适应即可跨域泛化。然而，先前研究大多忽视了ICL-based FSIC流程中的一个关键组件：图像嵌入的作用。本文提出PictSure，一个将嵌入模型（其架构、预训练和训练动态）置于分析中心的ICL框架。我们系统研究了不同视觉编码器类型、预训练目标和微调策略对下游FSIC性能的影响。实验表明，训练成功率和跨域性能高度依赖于嵌入模型的预训练方式。因此，PictSure在显著不同于训练分布的跨域基准测试中优于现有ICL-based FSIC模型，同时在域内任务上保持可比结果。代码见https://github.com/PictSure/pictsure-library。

</details>


### [64] [Finding Optimal Kernel Size and Dimension in Convolutional Neural Networks An Architecture Optimization Approach](https://arxiv.org/abs/2506.14846)
**中文标题：卷积神经网络中核大小和维度的优化：一种架构优化方法**

*Shreyas Rajeev,B Sathish Babu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为BKSEF的框架，用于优化卷积神经网络（CNN）中逐层核大小的选择。通过结合信息理论、信号处理和学习理论，BKSEF在多个数据集上实现了更高的准确性和更低的计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 卷积神经网络中核大小的选择通常被忽视，但它对感受野、特征提取、计算成本和模型准确性有重要影响。本文旨在通过数学和实证方法优化核大小，提升CNN的性能和效率。

研究方法: 提出了最佳核大小估计函数（BKSEF），该框架基于信息理论、信号处理和学习理论，逐层确定最优核大小，平衡信息增益、计算效率和准确性。

研究结果: 在CIFAR-10、CIFAR-100、ImageNet-lite、ChestX-ray14和GTSRB数据集上的实验表明，BKSEF引导的架构比传统3x3核模型提高了3.1%的准确性，并减少了42.8%的FLOPs。两个实际案例进一步验证了其有效性。

研究结论: BKSEF证明核大小可以成为可优化的参数而非固定启发式方法，为高效且应用感知的CNN设计提供了理论和实践支持。

中文摘要: 卷积神经网络（CNN）中核大小的选择是一个关键但常被忽视的设计决策，它影响感受野、特征提取、计算成本和模型准确性。本文提出了最佳核大小估计函数（BKSEF），这是一个基于数学和实证验证的框架，用于逐层确定最优核大小。BKSEF通过整合信息理论、信号处理和学习理论的原理，平衡了信息增益、计算效率和准确性提升。在CIFAR-10、CIFAR-100、ImageNet-lite、ChestX-ray14和GTSRB数据集上的广泛实验表明，BKSEF引导的架构比传统使用统一3x3核的模型实现了高达3.1%的准确性提升和42.8%的FLOPs减少。两个实际案例进一步验证了该方法：一个用于云环境中的医学图像分类，另一个用于边缘设备上的交通标志识别。前者提高了可解释性和准确性，后者显著降低了延迟和模型大小，且准确性损失极小。这些结果表明，核大小可以成为可优化的参数而非固定启发式方法。BKSEF为寻求高效和应用感知的CNN设计的研究人员和开发者提供了实用的启发式方法和理论支持。它适合集成到神经架构搜索流程和实时系统中，为CNN优化提供了新视角。

</details>


### [65] [Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis](https://arxiv.org/abs/2506.14854)
**中文标题：高效零售视频标注：一种鲁棒的关键帧生成方法用于产品与顾客交互分析**

*Varun Mannam,Zhenyu Shi*

主要分类: cs.CV

摘要简述: 本文提出一种基于深度学习的零售视频关键帧自动生成方法，用于产品和顾客交互分析，显著提升标注效率并降低成本。


<details>
  <summary>详细信息</summary>
研究动机: 传统零售视频标注依赖人工，耗时且成本高，且帧选择不鲁棒。为解决这些问题，研究提出自动化关键帧识别和标注方法。

研究方法: 采用深度神经网络学习视频帧的判别性特征，结合针对零售环境优化的目标检测技术，实现关键帧自动生成和标注。

研究结果: 实验表明，该方法在标注准确性上与人工标注相当，效率提升2倍，且仅需人工验证调整少于5%的帧。

研究结论: 该方法显著降低零售视频标注成本和时间，适用于顾客行为分析、产品交互检测等多种零售应用。

中文摘要: 准确的视频标注在现代零售应用中至关重要，包括顾客行为分析、产品交互检测和店内活动识别。然而，传统标注方法严重依赖耗时的人工标注，导致帧选择不鲁棒且运营成本增加。为解决零售领域的这些挑战，我们提出一种基于深度学习的方法，自动识别零售视频中的关键帧，并提供产品和顾客的自动标注。我们的方法利用深度神经网络学习视频帧的判别性特征，并结合针对零售环境优化的目标检测技术。实验结果表明，我们的方法优于传统方法，标注准确性可与人工标注媲美，同时显著提升零售视频标注的整体效率。值得注意的是，我们的方法平均可节省2倍的标注成本。通过仅需人工验证调整少于5%的检测帧，同时自动化标注其余帧且不降低标注质量，零售商可大幅降低运营成本。关键帧检测的自动化显著节省了零售视频标注任务的时间和精力，对顾客旅程分析、产品交互检测和店内安全监控等多种零售应用极具价值。

</details>


### [66] [Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction](https://arxiv.org/abs/2506.14856)
**中文标题：窥探未知：基于神经不确定性图的主动视角选择用于3D重建**

*Zhengquan Zhang,Feng Xu,Mengmi Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于神经不确定性图的新型主动视角选择方法（AVS），用于高效且准确的3D重建。通过轻量级网络UPNet预测不确定性图，显著减少了计算开销，并在减少视角数量的同时保持了高重建精度。


<details>
  <summary>详细信息</summary>
研究动机: 在3D重建中，如何选择最具信息量的视角以最小化计算成本并最大化重建精度是一个关键问题。传统方法依赖于复杂的计算，而本文旨在通过神经不确定性图直接预测最佳视角，提升效率。

研究方法: 提出了一种名为UPNet的轻量级神经网络，通过单张输入图像预测所有候选视角的不确定性图。结合启发式方法，UPNet学习从视角外观到体积表示不确定性的直接映射，并利用历史预测图抑制冗余视角，选择最具信息量的视角。

研究结果: 实验表明，该方法仅需一半的视角即可达到与上限相当的精度，同时计算开销显著降低，速度提升高达400倍，CPU、RAM和GPU使用量减少50%以上。此外，该方法无需额外训练即可泛化到新物体类别。

研究结论: 本文提出的基于神经不确定性图的AVS方法在3D重建中实现了高效且准确的视角选择，显著降低了计算成本，并展示了强大的泛化能力。

中文摘要: 某些视角自然比其他视角提供更多信息。AI系统如何确定哪个视角能为准确高效的3D物体重建提供最有价值的洞察？主动视角选择（AVS）在3D重建中仍是计算机视觉的基本挑战，目标是找到能产生最准确3D重建的最小视角集。与NeRF或3D高斯泼溅等从当前观察学习辐射场并计算每个候选视角不确定性的方法不同，我们提出了一种由轻量级前馈深度神经网络UPNet预测的神经不确定性图引导的新型AVS方法。UPNet输入一张3D物体的图像，输出预测的不确定性图，表示所有候选视角的不确定性值。通过观察大量自然物体及其不确定性模式的启发，我们训练UPNet学习从视角外观到底层体积表示不确定性的直接映射。接着，我们的方法聚合所有先前预测的神经不确定性图，抑制冗余候选视角，有效选择最具信息量的视角。利用这些选定的视角，我们训练3D神经渲染模型，并在新视角合成质量上与其他竞争性AVS方法进行比较。值得注意的是，尽管使用的视角数量仅为上限的一半，我们的方法仍实现了可比的重建精度。此外，它显著降低了AVS过程中的计算开销，速度提升高达400倍，CPU、RAM和GPU使用量减少50%以上。尤为突出的是，我们的方法无需额外训练即可有效泛化到涉及新物体类别的AVS任务。

</details>


### [67] [DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization](https://arxiv.org/abs/2506.14903)
**中文标题：DETONATE：文本到图像对齐与核化直接偏好优化的基准测试**

*Renjith Prasad,Abhilekh Borah,Hasnat Md Abdullah,Chathurangi Shyalika,Gurpreet Singh,Ritvik Garimella,Rajarshi Roy,Harshul Surana,Nasrin Imanpour,Suranjana Trivedy,Amit Sheth,Amitava Das*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DPO-Kernels的新方法，用于提升文本到图像（T2I）模型的对齐性能，并引入了首个大规模基准测试DETONATE，包含10万对图像，用于评估社会偏见。方法结合了混合损失、核化表示和多样化散度选择，显著提升了模型的稳定性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 文本到图像（T2I）模型的对齐性对于确保生成的图像准确反映用户意图并保持安全性和公平性至关重要。然而，现有的对齐方法在多样性和鲁棒性方面存在不足。本文旨在通过扩展直接偏好优化（DPO）方法，结合核技术和多样化散度选择，提升T2I模型的对齐性能。

研究方法: 本文提出了DPO-Kernels方法，包括三个关键创新：(i) 混合损失，结合嵌入目标和传统概率损失；(ii) 核化表示，使用RBF、多项式和Wavelet核进行特征变换；(iii) 散度选择，扩展了KL散度，引入Wasserstein和R'enyi散度以增强稳定性。此外，还提出了DETONATE基准测试和Alignment Quality Index（AQI）度量。

研究结果: 实验表明，DPO-Kernels通过Heavy-Tailed Self-Regularization（HT-SR）保持了强大的泛化性能。DETONATE基准测试揭示了T2I模型在社会偏见方面的潜在漏洞，而AQI度量有效量化了安全与不安全图像在潜在空间中的分离性。

研究结论: 本文提出的DPO-Kernels方法显著提升了T2I模型的对齐性能，并通过DETONATE基准测试和AQI度量为未来研究提供了重要工具。结果表明，核技术和多样化散度选择是提升模型鲁棒性和稳定性的有效途径。

中文摘要: 对齐性对于文本到图像（T2I）模型至关重要，以确保生成的图像准确反映用户意图并保持安全性和公平性。直接偏好优化（DPO）在大型语言模型（LLM）中表现突出，现正扩展至T2I系统。本文提出了DPO-Kernels方法，通过以下三个维度增强对齐性：(i) 混合损失，结合嵌入目标和传统概率损失；(ii) 核化表示，使用RBF、多项式和Wavelet核进行特征变换；(iii) 散度选择，扩展了KL散度，引入Wasserstein和R'enyi散度以增强稳定性。我们提出了DETONATE基准测试，包含约10万对图像，涵盖种族、性别和残疾三个社会偏见维度。此外，还提出了Alignment Quality Index（AQI），一种量化潜在空间中安全与不安全图像分离性的几何度量。实验表明，DPO-Kernels通过Heavy-Tailed Self-Regularization（HT-SR）保持了强大的泛化性能。DETONATE和完整代码已公开发布。

</details>


### [68] [PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2506.14907)
**中文标题：PeRL：基于排列增强的强化学习用于交错视觉-语言推理**

*Yizhen Zhang,Yang Ding,Shuoshuo Zhang,Xinchen Zhang,Haoling Li,Zhong-zhi Li,Peijie Wang,Jie Wu,Lei Ji,Yelong Shen,Yujiu Yang,Yeyun Gong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PeRL的强化学习方法，通过图像序列排列和多阶段策略提升多模态任务的推理能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态强化学习方法主要局限于单图像空间推理，难以推广到涉及多图像位置关系的复杂场景。本文旨在解决这一问题。

研究方法: PeRL通过图像序列排列模拟多样位置关系，并设计了一种轨迹过滤机制以优化探索-利用权衡，提升学习效率和任务表现。

研究结果: 在5个多图像基准和3个单图像基准上的实验表明，PeRL显著优于现有方法，在多图像任务中达到最优性能，同时保持单图像任务的竞争力。

研究结论: PeRL为多模态推理任务提供了一种高效的强化学习框架，尤其在多图像场景中表现突出。

中文摘要: 受DeepSeek-R1等强化学习方法展现的卓越推理能力启发，近期研究开始探索利用强化学习（RL）增强视觉-语言模型（VLMs）在多模态推理任务中的应用。然而，现有方法多局限于单图像空间推理，难以推广到涉及多图像位置关系的复杂场景。为此，我们提出了一种适用于交错多模态任务的通用强化学习方法PeRL，并设计了一种多阶段策略以优化探索-利用权衡，从而提升学习效率和任务表现。具体而言，我们通过图像序列排列模拟多样位置关系以探索更多空间多样性，并设计了一种轨迹过滤机制以聚焦对学习最优行为贡献最大的轨迹。我们在5个多图像基准和3个单图像基准上评估了模型性能。实验表明，PeRL训练模型在多图像基准上显著优于R1相关方法及交错VLM基线，达到最优性能，同时在单图像任务中保持竞争力。

</details>


### [69] [Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models](https://arxiv.org/abs/2506.14919)
**中文标题：医学图像扩散模型的频率校准成员推理攻击**

*Xinkai Zhao,Yuta Tokuoka,Junichiro Iwasawa,Keita Oda*

主要分类: cs.CV

摘要简述: 本文提出了一种针对医学图像扩散模型的频率校准重建误差（FCRE）方法，通过聚焦中频区域的重建误差，有效解决了传统成员推理攻击（MIA）在医学图像中面临的挑战，实验证明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在医学图像生成中的应用日益广泛，但随之而来的隐私风险问题亟待解决。传统MIA方法依赖重建误差，但医学图像的高频细节难以重建，导致误差受图像固有难度影响。本文旨在提出一种更准确的MIA方法。

研究方法: 提出频率校准重建误差（FCRE）方法，通过分析逆向扩散过程，计算中频区域的重建误差，并结合结构相似性指数（SSIM）评分，排除高频（难以重建）和低频（信息量少）区域的干扰。

研究结果: 在多个医学图像数据集上的实验表明，FCRE方法在成员推理攻击中表现优于现有方法，能够更准确地识别训练数据中的成员图像。

研究结论: FCRE方法通过频率选择性策略，有效解决了医学图像扩散模型中的隐私风险评估问题，为未来研究提供了新思路。

中文摘要: 扩散模型在图像生成中的应用日益广泛，尤其是在医学成像等敏感领域，引发了显著的隐私担忧。成员推理攻击（MIA）作为一种潜在方法，可用于判断特定图像是否用于训练扩散模型，从而量化隐私风险。现有MIA方法通常依赖扩散重建误差，假设成员图像的重建误差低于非成员图像。然而，这些方法直接应用于医学图像时面临挑战：重建误差受图像固有难度影响，且扩散模型难以重建高频细节。为解决这些问题，我们提出了一种频率校准重建误差（FCRE）方法，用于医学图像扩散模型的MIA。通过专注于特定中频范围的重建误差，并排除高频（难以重建）和低频（信息量少）区域，我们的频率选择性方法减轻了图像固有难度的干扰。具体而言，我们分析逆向扩散过程，获取中频重建误差，并计算重建图像与原始图像之间的结构相似性指数评分。通过将此评分与阈值比较，确定成员关系。在多个医学图像数据集上的实验表明，FCRE方法优于现有MIA方法。

</details>


### [70] [Vision Transformers for End-to-End Quark-Gluon Jet Classification from Calorimeter Images](https://arxiv.org/abs/2506.14934)
**中文标题：基于Vision Transformer的端到端夸克-胶子喷注分类：从量能器图像出发**

*Md Abrar Jahin,Shahriar Soudeep,Arian Rahman Aditta,M. F. Mridha,Nafiz Fahad,Md. Jakir Hossen*

主要分类: cs.CV

摘要简述: 本文系统评估了Vision Transformer (ViT)及其与CNN的混合模型在夸克-胶子喷注分类中的表现，发现ViT模型在F1分数、ROC-AUC和准确率上优于传统CNN，凸显了其在捕获喷注子结构长程空间相关性上的优势。


<details>
  <summary>详细信息</summary>
研究动机: 在高能物理中，区分夸克和胶子喷注对改进新物理搜索和精确测量至关重要。尽管CNN在喷注标记中表现优异，但ViT架构在直接分析量能器图像方面的潜力尚未充分探索，尤其是在实际探测器和堆积条件下。

研究方法: 使用2012年CMS公开数据构建多通道喷注图像（包括ECAL、HCAL能量沉积和重建轨迹），系统评估ViT及ViT-CNN混合模型在夸克-胶子喷注分类中的表现。

研究结果: ViT模型（尤其是ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上显著优于传统CNN基线，证明了其在捕获喷注子结构长程空间相关性上的优势。

研究结论: 本研究首次为ViT架构在量能器图像喷注分类中的应用建立了系统框架和性能基准，并提供了适用于进一步深度学习研究的结构化数据集。

中文摘要: 区分夸克和胶子喷注是高能物理中一项关键且具有挑战性的任务，对改进大型强子对撞机的新物理搜索和精确测量至关重要。尽管深度学习（尤其是卷积神经网络CNN）通过基于图像的表示推动了喷注标记的发展，但擅长建模全局上下文信息的Vision Transformer (ViT)架构在直接分析量能器图像方面的潜力尚未充分探索，尤其是在实际探测器和堆积条件下。本文利用模拟的2012年CMS公开数据，系统评估了ViT及ViT-CNN混合模型在夸克-胶子喷注分类中的表现。我们通过探测器级能量沉积（ECAL、HCAL）和重建轨迹构建了多通道喷注视图图像，实现了端到端学习。全面的基准测试表明，基于ViT的模型（尤其是ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上始终优于传统CNN基线，凸显了其在捕获喷注子结构长程空间相关性上的优势。本研究首次为ViT架构在量能器图像喷注分类中的应用建立了系统框架和性能基准，同时提供了一个适用于该领域进一步深度学习研究的结构化数据集。

</details>


### [71] [Advances in Compliance Detection: Novel Models Using Vision-Based Tactile Sensors](https://arxiv.org/abs/2506.14980)
**中文标题：顺应性检测的进展：基于视觉触觉传感器的新型模型**

*Ziteng Li,Malte Kuhlmann,Ilana Nisky,Nicolás Navarro-Guerrero*

主要分类: cs.CV

摘要简述: 本文提出两种基于长时递归卷积网络（LRCN）和Transformer架构的模型，利用视觉触觉传感器GelSight捕获的RGB触觉图像等信息，显著提升了物体顺应性检测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统顺应性检测方法存在便携性差、成本高且不适合机器人应用的问题，而现有基于神经网络的视觉触觉传感器方法预测精度不足。本文旨在解决这些问题。

研究方法: 提出两种模型：基于长时递归卷积网络（LRCN）和Transformer架构，利用GelSight传感器捕获的RGB触觉图像及其他信息进行顺应性预测。

研究结果: 实验验证表明，所提模型在顺应性估计上显著优于基线方法，且发现传感器与物体硬度差异对估计难度有影响。

研究结论: 本文模型显著提升了顺应性检测的准确性，为工程、农业和生物医学应用提供了更高效的解决方案。

中文摘要: 顺应性是描述工程、农业和生物医学应用中物体的关键参数。传统顺应性检测方法因缺乏便携性和可扩展性、依赖昂贵设备且不适合机器人应用而受限。此外，现有基于神经网络的视觉触觉传感器方法预测精度仍不足。本文提出两种基于长时递归卷积网络（LRCN）和Transformer架构的模型，利用GelSight传感器捕获的RGB触觉图像及其他信息，准确预测顺应性指标。通过多项指标验证模型性能，证明其在顺应性估计上的有效性。所提模型较基线方法性能显著提升。此外，研究发现传感器与物体硬度差异对估计难度有影响，硬度高于传感器的物体更难估计。

</details>


### [72] [Hyper-Local Deformable Transformers for Text Spotting on Historical Maps](https://arxiv.org/abs/2506.15010)
**中文标题：超局部可变形Transformer在历史地图文本识别中的应用**

*Yijun Lin,Yao-Yi Chiang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PALETTE的端到端文本识别方法，用于从多样化历史地图中提取文本。通过超局部采样模块和位置嵌入技术，PALETTE能够精确检测和识别长文本及旋转文本。此外，还提出了SynthMap+方法自动生成合成地图数据用于训练。实验表明，PALETTE在历史地图文本识别任务中优于现有方法，并已成功应用于大规模地图数据集。


<details>
  <summary>详细信息</summary>
研究动机: 历史地图中的文本包含丰富的地理、历史和文化信息，但由于缺乏有效的提取方法和训练数据，文本识别面临挑战。现有方法通常仅适用于特定地图风格，而通用文本识别方法在复杂背景下难以精确提取长文本和旋转文本的特征。

研究方法: PALETTE采用端到端设计，引入超局部采样模块学习文本边界点和字符的局部图像特征，并通过超局部位置嵌入技术建模文本内和跨文本的空间关系。此外，提出SynthMap+方法自动生成合成地图数据用于训练。

研究结果: 实验表明，PALETTE在两个历史地图基准数据集上优于现有方法，尤其在长文本和旋转文本识别任务中表现突出。该方法已成功处理超过60,000张地图，生成超过1亿个文本标签。

研究结论: PALETTE通过超局部特征学习和合成数据生成，显著提升了历史地图文本识别的性能，为大规模地图数据处理提供了有效工具。

中文摘要: 历史地图中的文本提供了丰富的地理参考历史、政治和文化信息。然而，由于缺乏有效的提取方法和训练数据，历史地图的文本识别面临挑战。现有方法通常仅针对特定地图风格设计，而基于机器学习的通用文本识别方法虽具有灵活性，但在复杂背景下难以精确提取长文本和旋转文本的特征。本文提出PALETTE，一种适用于多样化历史地图的端到端文本识别方法。PALETTE引入超局部采样模块，显式学习文本边界点和字符周围的局部图像特征，并通过超局部位置嵌入技术建模空间关系。此外，本文提出SynthMap+方法，自动生成合成地图数据用于训练。实验表明，PALETTE在两个历史地图基准数据集上优于现有方法，尤其在长文本和旋转文本识别任务中表现突出。PALETTE已成功应用于David Rumsey历史地图集，处理超过60,000张地图并生成超过1亿个文本标签。项目代码已开源。

</details>


### [73] [Break Stylistic Sophon: Are We Really Meant to Confine the Imagination in Style Transfer?](https://arxiv.org/abs/2506.15033)
**中文标题：打破风格桎梏：我们真的需要限制风格迁移中的想象力吗？**

*Gary Song Yan,Yusen Zhang,Jinyu Zhao,Hao Zhang,Zhangping Yang,Guanye Xiong,Yanfei Liu,Tao Zhang,Yujie He,Siyuan Tian,Yao Gou,Min Li*

主要分类: cs.CV

摘要简述: 本文提出StyleWallfacer框架，通过语义风格注入、数据增强策略和无训练三重扩散过程，实现高质量风格迁移与文本驱动风格化，同时保留原始内容。


<details>
  <summary>详细信息</summary>
研究动机: 传统风格迁移方法存在诸多问题，如风格注入效率低、内容漂移等。本文旨在通过统一框架解决这些问题，并实现艺术家级别的风格迁移与文本驱动风格化。

研究方法: 1. 提出基于语义的风格注入方法，利用BLIP生成与风格图像语义严格对齐的文本描述，并通过大语言模型移除风格相关描述，形成语义间隙以微调模型。2. 设计基于人类反馈的数据增强策略，将高质量样本加入训练集以减少过拟合。3. 提出无训练三重扩散过程，通过替换自注意力层的键和值实现风格注入，同时保留文本控制。

研究结果: 实现了高质量的图像驱动风格迁移和文本驱动风格化，保留了原始图像内容，并首次在风格迁移过程中实现图像颜色编辑。

研究结论: StyleWallfacer框架成功解决了传统风格迁移的局限性，实现了高效、无漂移的风格注入和文本控制，为艺术家级别的风格迁移提供了新思路。

中文摘要: 在这项开创性研究中，我们提出了StyleWallfacer，一个突破性的统一训练与推理框架，不仅解决了传统风格迁移方法中的各种问题，还统一了不同任务的框架。该框架旨在通过实现艺术家级别的风格迁移和文本驱动风格化来革新这一领域。首先，我们提出了一种基于语义的风格注入方法，利用BLIP生成与风格图像语义在CLIP空间中严格对齐的文本描述。通过使用大语言模型移除这些描述中的风格相关部分，我们创建了一个语义间隙。该间隙用于微调模型，实现高效且无漂移的风格知识注入。其次，我们提出了一种基于人类反馈的数据增强策略，将微调早期生成的高质量样本加入训练集，以促进渐进学习并显著减少过拟合。最后，我们设计了一种无训练的三重扩散过程，利用微调后的模型以类似于交叉注意力机制的方式操作自注意力层的特征。具体而言，在生成过程中，内容相关过程的键和值被替换为风格相关过程的键和值，以注入风格同时保持对模型的文本控制。我们还引入了查询保留机制以减少对原始内容的干扰。在此设计下，我们实现了高质量的图像驱动风格迁移和文本驱动风格化，提供了艺术家级别的风格迁移结果，同时保留了原始图像内容。此外，我们首次在风格迁移过程中实现了图像颜色编辑。

</details>


### [74] [Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study](https://arxiv.org/abs/2506.15078)
**中文标题：通过分布匹配增强向量量化：理论与实证研究**

*Xianghong Fang,Litao Guo,Hengchao Chen,Yuxuan Zhang,XiaofanXia,Dingjie Song,Yexin Liu,Hao Wang,Harry Yang,Yuan Yuan,Qiang Sun*

主要分类: cs.CV

摘要简述: 本文提出了一种通过分布匹配增强向量量化的方法，解决了训练不稳定和码本崩溃问题，显著提升了码本利用率和量化效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有向量量化方法存在训练不稳定和码本崩溃问题，主要源于特征与码向量分布不匹配，导致量化误差大和信息损失。本文旨在通过分布对齐解决这些问题。

研究方法: 使用Wasserstein距离对齐特征与码向量的分布，确保码本利用率接近100%，并显著减少量化误差。

研究结果: 实验和理论分析表明，该方法能有效提升码本利用率并降低量化误差，验证了其优越性。

研究结论: 通过分布匹配优化向量量化，显著改善了训练稳定性和码本利用率，为量化技术提供了新思路。

中文摘要: 自回归模型的成功很大程度上依赖于向量量化的有效性，这是一种通过将连续特征映射到可学习码本中的最近码向量来实现离散化的技术。现有向量量化方法存在两个关键问题：训练不稳定性和码本崩溃。训练不稳定性源于直通估计器引入的梯度差异，尤其是在量化误差较大时；而码本崩溃则发生在训练过程中仅使用少量码向量时。深入分析表明，这些问题主要由特征与码向量分布不匹配引起，导致码向量缺乏代表性且在压缩过程中丢失大量数据信息。为解决这一问题，我们采用Wasserstein距离对齐这两种分布，实现了接近100%的码本利用率，并显著降低了量化误差。实验和理论分析均验证了该方法的有效性。

</details>


### [75] [SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts](https://arxiv.org/abs/2506.15153)
**中文标题：SynPo：通过高质量负提示提升无需训练的少样本医学图像分割**

*Yufei Liu,Haoke Xiao,Jiaxing Chai,Yongcun Zhang,Rong Wang,Zijie Meng,Zhiming Luo*

主要分类: cs.CV

摘要简述: SynPo提出了一种无需训练的少样本医学图像分割方法，通过提升负提示质量，结合DINOv2和SAM的优势，显著提升了低对比度医学图像的分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于大型视觉模型（LVMs）的无训练方法在医学图像分割中未能有效利用负提示，导致低对比度图像分割效果不佳。SynPo旨在通过优化负提示质量解决这一问题。

研究方法: SynPo设计了置信图协同模块，结合DINOv2和SAM的优势生成可靠置信图，从中选择高置信度像素作为正提示点，并通过高斯分布选取负提示点，再分别进行K-means聚类。这些高质量提示点用于SAM模型完成分割。

研究结果: 实验表明，SynPo在少样本医学图像分割任务中表现优异，性能接近基于训练的最先进方法。

研究结论: SynPo通过优化负提示质量，显著提升了无训练少样本医学图像分割的性能，为低对比度图像分割提供了有效解决方案。

中文摘要: 大型视觉模型（LVMs）的出现为少样本医学图像分割提供了新机遇。然而，现有基于LVMs的无训练方法未能有效利用负提示，导致低对比度医学图像分割效果不佳。为解决这一问题，我们提出SynPo，一种基于LVMs（如SAM）的无训练少样本方法，其核心思想是提升负提示质量。为在更可靠的置信图中选择点提示，我们设计了一个新颖的置信图协同模块，结合DINOv2和SAM的优势。基于置信图，我们选择前k个像素作为正提示点集，并通过高斯分布选取负提示点集，随后对两组点分别进行独立K-means聚类。这些选定的点作为高质量提示输入SAM模型以获取分割结果。大量实验表明，SynPo的性能接近基于训练的最先进少样本方法。

</details>


### [76] [Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation](https://arxiv.org/abs/2506.15160)
**中文标题：基于跨阶段结构相关性的邻居聚合校正增强点云分析**

*Jiaqi Shi,Jin Xiao,Xiaoguang Hu,Boyang Song,Hao Jiang,Tianyou Chen,Baochang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于跨阶段结构相关性的点云分析方法（PDSA），通过高维空间相关性校正邻居聚合中的特征分布，提高了计算效率和鲁棒性。实验验证了该方法在语义分割和分类任务中的显著性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 点云分析中，现有方法基于局部坐标聚合邻居时存在无关点干扰和特征层次差距问题。尽管一些工作通过跨阶段结构建模改进空间描述，但直接几何结构编码方法计算开销大且对噪声敏感。本文旨在解决这些问题。

研究方法: 提出点分布集抽象模块（PDSA），利用高维空间相关性校正聚合中的特征分布。通过轻量级跨阶段结构描述符区分点相关性，减少邻居特征矩阵方差并增强长距离建模的类别可分性。引入关键点机制优化计算开销。

研究结果: 在不同基线的语义分割和分类任务中验证了方法的泛化性，性能显著提升且参数成本更低。消融实验和可视化结果证明了方法的有效性和合理性。

研究结论: PDSA模块通过高维空间相关性校正邻居聚合，解决了现有方法的计算开销和噪声敏感问题，显著提升了点云分析任务的性能。

中文摘要: 点云分析是许多下游任务的基石，其中聚合局部结构是理解点云数据的基础。尽管许多工作使用三维相对坐标聚合邻居，但由于局部坐标的限制，存在无关点干扰和特征层次差距问题。尽管一些工作通过显式建模跨阶段结构改进了空间描述，但这些基于直接几何结构编码的增强方法存在计算开销高和噪声敏感的问题。为解决这些问题，我们提出了点分布集抽象模块（PDSA），利用高维空间的相关性在聚合过程中校正特征分布，从而提高了计算效率和鲁棒性。PDSA基于轻量级跨阶段结构描述符区分点相关性，并通过减少邻居特征矩阵的方差和增强长距离建模的类别可分性来提高结构同质性。此外，我们引入了关键点机制以优化计算开销。基于不同基线的语义分割和分类任务的实验结果验证了所提方法的泛化性，并以更少的参数成本实现了显著的性能提升。相应的消融实验和可视化结果证明了方法的有效性和合理性。代码和训练权重可在以下网址获取：https://github.com/AGENT9717/PointDistribution。

</details>


### [77] [Echo-DND: A dual noise diffusion model for robust and precise left ventricle segmentation in echocardiography](https://arxiv.org/abs/2506.15166)
**中文标题：Echo-DND：一种用于超声心动图中左心室鲁棒精确分割的双噪声扩散模型**

*Abdur Rahman,Keerthiveena Balraj,Manojkumar Ramteke,Anurag Singh Rathore*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的双噪声扩散模型Echo-DND，用于超声心动图中左心室的精确分割。该模型结合高斯和伯努利噪声，并引入多尺度融合条件模块和空间一致性校准，显著提升了分割精度。在CAMUS和EchoNet-Dynamic数据集上的实验表明，其性能优于现有SOTA模型。


<details>
  <summary>详细信息</summary>
研究动机: 超声心动图因噪声多、对比度低且左心室边界模糊，导致分割困难。现有方法难以应对这些挑战，因此需要一种更鲁棒且精确的分割模型。

研究方法: Echo-DND采用高斯和伯努利噪声的双噪声扩散模型，结合多尺度融合条件模块提升分割精度，并通过空间一致性校准保持分割掩模的空间完整性。

研究结果: 在CAMUS和EchoNet-Dynamic数据集上，Echo-DND分别取得了0.962和0.939的Dice分数，显著优于现有SOTA模型。

研究结论: Echo-DND为超声心动图分割设立了新标准，其架构在更广泛的医学影像任务中具有潜在应用价值，有望提升多领域的诊断准确性。

中文摘要: 扩散概率模型（DPMs）的最新进展彻底改变了图像处理领域，并在医学应用中展现出巨大潜力。超声心动图中左心室（LV）的精确分割对诊断和治疗至关重要。然而，超声图像噪声多、对比度低且LV边界模糊，导致分割过程复杂化。为解决这些问题，本文提出了Echo-DND，一种专为此任务设计的双噪声扩散模型。Echo-DND结合了高斯和伯努利噪声，并引入了多尺度融合条件模块以提高分割精度，同时通过空间一致性校准保持分割掩模的空间完整性。该模型在CAMUS和EchoNet-Dynamic数据集上进行了严格验证。大量实验表明，该框架优于现有SOTA模型，分别取得了0.962和0.939的Dice分数。Echo-DND为超声心动图分割设立了新标准，其架构在其他医学影像任务中具有广泛应用潜力，有望提升多领域的诊断准确性。项目页面：https://abdur75648.github.io/Echo-DND

</details>


### [78] [ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections](https://arxiv.org/abs/2506.15180)
**中文标题：ReSeDis：一种基于指代的大规模图像集合对象搜索数据集**

*Ziling Huang,Yidan Zhang,Shin'ichi Satoh*

主要分类: cs.CV

摘要简述: 本文提出了ReSeDis任务，首次将大规模图像检索与像素级定位结合，通过自由描述查询对象并返回其位置信息，填补了现有技术的空白。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉搜索技术要么仅关注图像级检索（如文本到图像检索），要么仅关注像素级定位（如视觉接地），无法同时满足大规模检索和精确定位的需求。ReSeDis任务旨在统一这两者，构建更强大的多模态搜索系统。

研究方法: 作者提出了ReSeDis任务，要求模型根据自由描述判断对象是否存在于图像中，并返回其边界框或分割掩码。为此，他们构建了一个基准数据集，确保每个描述唯一对应分散在大规模多样化语料库中的对象实例，并设计了联合评分检索召回和定位精度的任务特定指标。

研究结果: 实验结果表明，ReSeDis任务填补了现有技术的空白，并通过零样本基线方法展示了未来研究的巨大潜力。

研究结论: ReSeDis为构建下一代鲁棒且可扩展的多模态搜索系统提供了现实的端到端测试平台，展示了统一检索与定位的重要性。

中文摘要: 大规模视觉搜索引擎需要同时解决两个问题：(i) 定位包含句子描述对象的每张图像；(ii) 在每个匹配图像中识别对象的边界框或精确像素。现有技术仅解决了其中一方面。视觉接地能生成精确的框和掩码，但假设测试图像中均包含对象，导致在网页规模集合中产生大量误报。文本到图像检索擅长从海量数据库中筛选相关图像，但仅提供整图匹配，缺乏细粒度定位。我们提出了指代搜索与发现（ReSeDis），这是首个将语料库级检索与像素级接地统一的任务。给定自由描述，ReSeDis模型需判断查询对象是否出现在每张图像中，并返回其边界框或分割掩码。为支持严谨研究，我们构建了一个基准数据集，确保每个描述唯一对应分散在大规模多样化语料库中的对象实例，避免意外匹配。我们还设计了联合评分检索召回和定位精度的任务特定指标。最后，我们提供了一种使用冻结视觉语言模型的零样本基线方法，揭示了未来研究的巨大空间。ReSeDis为构建下一代鲁棒且可扩展的多模态搜索系统提供了现实的端到端测试平台。

</details>


### [79] [Conquering the Retina: Bringing Visual in-Context Learning to OCT](https://arxiv.org/abs/2506.15200)
**中文标题：征服视网膜：将视觉上下文学习引入OCT**

*Alessio Negrini,Simon Reiß*

主要分类: cs.CV

摘要简述: 本文探索了如何通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域，提出了一种评估协议并公开了代码。


<details>
  <summary>详细信息</summary>
研究动机: 当前医学图像分析领域高度专业化的模型虽性能优异，但仅适用于预定义任务，开发与适配需大量资源。通用模型则允许医疗从业者即时定义任务，无需针对特定任务开发模型。本文旨在探索通用模型在视网膜OCT中的应用潜力。

研究方法: 采用视觉上下文学习（VICL）方法，训练模型在推理时基于少量示例实现跨任务泛化。提出了一种针对OCT的VICL评估协议，并在多个视网膜OCT数据集上对现有医学VICL方法进行了全面评估。

研究结果: 研究建立了首个OCT上下文学习的基线，展示了其潜力与当前局限性。公开了代码以促进进一步研究和实际应用。

研究结论: 视觉上下文学习在视网膜OCT领域具有潜力，但仍需进一步研究以克服现有局限。

中文摘要: 近年来，医学图像分析领域的进展催生了针对特定临床任务的高度专业化模型。这些模型表现出色，仍是重要研究方向，但其适用性仅限于预定义任务，开发与适配需专业知识和大量资源。相比之下，通用模型提供了另一种实用性：允许医疗从业者即时定义任务，无需针对特定任务开发模型。本文探索了如何通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域。为严格评估，我们提出了一种针对OCT的VICL评估协议。我们在多个视网膜OCT数据集上全面评估了现有医学VICL方法，建立了首个基线，展示了OCT上下文学习的潜力与当前局限。为促进进一步研究和实际应用，我们公开了代码。

</details>


### [80] [Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models](https://arxiv.org/abs/2506.15201)
**中文标题：隐私保护图像压缩：防御视觉语言预训练模型的语义利用**

*Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为隐私保护图像压缩（PSIC）的方法，通过在图像压缩阶段嵌入防御机制，防止视觉语言预训练模型（VLP）对公开图像的语义利用。该方法支持多解码选项，既能保护隐私又能保留原始压缩功能，并通过自适应多目标优化策略提升加密效果和感知质量。


<details>
  <summary>详细信息</summary>
研究动机: 随着视觉语言预训练模型（VLP）语义理解能力的提升，公开图像的隐私保护变得愈发困难。本文旨在通过图像压缩阶段的防御机制，防止VLP模型对图像的语义利用，从而保护用户隐私。

研究方法: 提出隐私保护图像压缩（PSIC）方法，支持生成具有多解码选项的比特流。默认解码保留感知质量但阻止VLP模型解析；通过自定义条件可恢复完整语义信息。设计了条件潜在触发生成（CLTG）模块和不确定性感知加密优化（UAEO）函数，并结合自适应多目标优化策略提升性能。

研究结果: 实验表明，PSIC方法在多种下游任务中均能有效保护图像隐私，同时保持感知质量和原始压缩功能。其插拔式设计可无缝集成到现有学习型图像压缩模型中。

研究结论: PSIC方法通过灵活的编码和解码机制，成功实现了对VLP模型的防御，同时兼顾了隐私保护和图像压缩功能，为公开图像的隐私安全提供了有效解决方案。

中文摘要: 视觉语言预训练模型（VLP）语义理解能力的提升使得公开图像更容易被搜索引擎等工具利用。为此，本文提出在图像压缩阶段实施防御机制以保护用户隐私。具体而言，我们提出了一种灵活的编码方法——隐私保护图像压缩（PSIC），可生成支持多解码选项的比特流。默认解码保留感知质量但阻止VLP模型解析，同时保留原始压缩功能。通过自定义输入条件，该方法可重建保留完整语义信息的图像。设计了条件潜在触发生成（CLTG）模块，基于自定义条件生成偏置信息以引导解码过程，并提出了不确定性感知加密优化（UAEO）函数，利用目标VLP模型对训练数据的不确定性推断软标签。本文还结合了自适应多目标优化策略，在统一训练过程中同时提升加密效果和感知质量。PSIC方法为插拔式设计，可无缝集成到多数现有学习型图像压缩模型中。多下游任务的广泛实验验证了该设计的有效性。

</details>


### [81] [DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder](https://arxiv.org/abs/2506.15218)
**中文标题：DM-FNet：基于扩散过程训练的编码器-解码器实现统一多模态医学图像融合**

*Dan He,Weisheng Li,Guofen Wang,Yuping Huang,Shiqiang Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于扩散过程的两阶段多模态医学图像融合网络（DM-FNet），通过扩散训练增强特征提取能力，并结合自适应融合模块提升图像融合质量。实验表明，该方法在亮度、对比度和细节保留方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态医学图像融合方法在特征提取和跨模态交互方面存在不足，导致融合图像质量不理想。本研究旨在通过扩散模型增强特征表示能力，并设计自适应融合模块以提升融合效果。

研究方法: DM-FNet采用两阶段设计：第一阶段通过扩散过程训练UNet进行图像重建，捕获多级特征；第二阶段将不同噪声水平的图像输入融合网络，结合三个关键融合模块自适应处理多模态图像，并通过混合损失函数优化融合结果。

研究结果: 实验结果表明，DM-FNet在多种医学图像类型上均表现优异，融合图像在亮度、放射性示踪剂分布、纹理和边缘清晰度方面均优于现有方法。

研究结论: DM-FNet通过扩散训练和自适应融合模块显著提升了多模态医学图像融合的质量，为临床诊断提供了更全面的信息支持。

中文摘要: 多模态医学图像融合（MMIF）从多源图像中提取最有价值的信息，以实现更全面和准确的诊断。高质量的融合结果需要平衡亮度、颜色、对比度和细节，以确保融合图像能有效显示相关解剖结构并反映组织的功能状态。然而，现有MMIF方法在传统训练中难以捕获细节特征，且跨模态特征交互不足，导致融合图像质量欠佳。为解决这些问题，本研究提出了一种基于扩散模型的两阶段融合网络（DM-FNet）。第一阶段通过扩散过程训练UNet进行图像重建，通过逐步去噪捕获细节信息并提供多层次特征表示；第二阶段将不同噪声水平的图像输入融合网络，结合三个关键融合模块自适应处理多模态图像。最终，通过鲁棒的网路结构和混合损失函数优化融合图像的亮度、颜色、对比度和细节。实验结果表明，该方法在多种医学图像类型上均表现优异，融合图像保留了适当的亮度、放射性示踪剂的全面分布、丰富的纹理和清晰的边缘。代码详见https://github.com/HeDan-11/DM-FNet。

</details>


### [82] [video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2506.15220)
**中文标题：video-SALMONN 2：字幕增强的视听大语言模型**

*Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang*

主要分类: cs.CV

摘要简述: 本文介绍了video-SALMONN 2，一种通过低秩适应（LoRA）和定向偏好优化（DPO）增强视频（带音频）字幕生成的先进视听大语言模型。提出多轮DPO（MrDPO）方法，显著提升字幕准确性，错误率降低28%。模型仅70亿参数，在视频字幕任务中超越GPT-4o和Gemini-1.5-Pro。


<details>
  <summary>详细信息</summary>
研究动机: 视频包含丰富信息，生成详细准确的自然语言描述是视频理解的关键。现有模型在字幕生成任务中仍有改进空间，尤其在准确性和完整性方面。本文旨在通过优化训练方法和引入新指标，提升视频字幕生成的质量。

研究方法: 提出video-SALMONN 2模型，结合LoRA和DPO优化视频字幕生成。创新性地提出多轮DPO（MrDPO），定期更新参考模型、合并并重新初始化LoRA模块，并引入真实字幕指导以稳定训练。

研究结果: 实验表明，MrDPO显著提升模型性能，字幕错误率降低28%。最终模型仅70亿参数，在视频字幕任务中超越GPT-4o和Gemini-1.5-Pro，并在视频问答基准测试中保持竞争力。

研究结论: video-SALMONN 2通过MrDPO和LoRA优化，显著提升视频字幕生成的准确性和完整性，成为同类模型中的领先者。代码已开源。

中文摘要: 视频包含丰富信息，生成详细准确的自然语言描述是视频理解的关键。本文提出video-SALMONN 2，一种通过低秩适应（LoRA）和定向偏好优化（DPO）增强视频（带音频）字幕生成的先进视听大语言模型。我们提出新指标评估视频描述的完整性和准确性，并通过DPO优化。为进一步提升训练效果，提出多轮DPO（MrDPO）方法，定期更新DPO参考模型，合并并重新初始化LoRA模块作为参数更新的代理，并引入真实字幕指导以稳定训练。实验结果表明，MrDPO显著提升video-SALMONN 2的字幕准确性，错误率降低28%。最终模型仅70亿参数，在视频字幕任务中超越GPT-4o和Gemini-1.5-Pro，同时在视频问答基准测试中保持竞争力。代码发布于https://github.com/bytedance/video-SALMONN-2。

</details>


### [83] [Convolutional Feature Enhancement and Attention Fusion BiFPN for Ship Detection in SAR Images](https://arxiv.org/abs/2506.15231)
**中文标题：卷积特征增强与注意力融合BiFPN在SAR图像船舶检测中的应用**

*Liangjie Meng,Danxia Li,Jinrong He,Lili Ma,Zhixin Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为C-AFBiFPN的新框架，通过卷积特征增强模块和注意力融合BiFPN网络，解决了SAR图像中船舶检测面临的尺度变化、小目标噪声和复杂背景问题，显著提升了检测精度和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: SAR图像中的船舶检测面临船舶尺度变化大、小目标与噪声混杂以及近岸船舶背景复杂等挑战，亟需一种能够增强特征表示并提升多尺度特征融合能力的方法。

研究方法: C-AFBiFPN框架包含卷积特征增强（CFE）模块和注意力融合BiFPN（AFBiFPN）网络。CFE模块增强局部细节和上下文信息表示，AFBiFPN通过集成BiFormer注意力机制，提升跨尺度特征融合的全局建模能力并自适应聚焦关键特征区域。

研究结果: 在SAR船舶检测数据集（SSDD）上的实验表明，该方法显著提升了小目标检测精度、遮挡鲁棒性以及对多尺度特征的适应性。

研究结论: C-AFBiFPN通过特征增强和注意力融合策略，有效解决了SAR船舶检测中的关键问题，为复杂场景下的目标检测提供了新思路。

中文摘要: 合成孔径雷达（SAR）通过主动微波和先进信号处理技术实现了亚米级分辨率成像和全天候监测。目前，SAR在船舶检测等关键海事领域得到了广泛应用。然而，SAR船舶检测面临船舶尺度变化显著、小目标与噪声混杂以及近岸船舶背景复杂等挑战。为解决这些问题，本文提出了一种名为C-AFBiFPN的特征增强与融合框架。C-AFBiFPN在骨干网络后构建了卷积特征增强（CFE）模块，旨在丰富特征表示并增强对局部细节和上下文信息的捕获能力。此外，C-AFBiFPN创新性地将BiFormer注意力机制集成到BiFPN的融合策略中，形成了AFBiFPN网络。AFBiFPN提升了跨尺度特征融合的全局建模能力，并能自适应聚焦关键特征区域。在SAR船舶检测数据集（SSDD）上的实验结果表明，该方法显著提升了小目标检测精度、遮挡鲁棒性以及对多尺度特征的适应性。

</details>


### [84] [RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories](https://arxiv.org/abs/2506.15242)
**中文标题：RA-NeRF：复杂轨迹下基于精确相机姿态估计的鲁棒神经辐射场重建**

*Qingsong Yan,Qiang Wang,Kaiyong Zhao,Jie Chen,Bo Li,Xiaowen Chu,Fei Deng*

主要分类: cs.CV

摘要简述: RA-NeRF提出了一种新方法，能够在复杂相机轨迹下实现高精度的相机姿态估计，并通过光流驱动的姿态调节和隐式姿态滤波提升场景重建的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于NeRF和3DGS的3D重建方法依赖准确的相机姿态先验，但在复杂相机轨迹下表现不佳。RA-NeRF旨在解决这一问题，提升复杂轨迹下的姿态估计精度和重建质量。

研究方法: RA-NeRF采用增量式流程，结合光流一致性进行场景重建，并引入光流驱动的姿态调节以增强初始化和定位的鲁棒性。此外，通过隐式姿态滤波捕捉相机运动模式并消除噪声。

研究结果: 在Tanks&Temple和NeRFBuster数据集上的实验表明，RA-NeRF在相机姿态估计和视觉质量上均达到最先进水平，验证了其在复杂轨迹下的有效性和鲁棒性。

研究结论: RA-NeRF通过光流驱动和隐式滤波技术，显著提升了复杂相机轨迹下的姿态估计精度和场景重建质量，为3D重建任务提供了新的解决方案。

中文摘要: 神经辐射场（NeRF）和3D高斯泼溅（3DGS）已成为3D重建和SLAM任务中的强大工具，但其性能高度依赖于准确的相机姿态先验。现有方法尝试通过引入外部约束解决这一问题，但在复杂相机轨迹下仍难以达到令人满意的精度。本文提出了一种新方法RA-NeRF，能够在复杂相机轨迹下预测高精度的相机姿态。RA-NeRF采用增量式流程，利用光流一致性重建场景，并通过光流驱动的姿态调节增强初始化和定位的鲁棒性。此外，RA-NeRF采用隐式姿态滤波捕捉相机运动模式并消除姿态估计中的噪声。为验证方法有效性，我们在Tanks&Temple数据集和具有挑战性相机轨迹的NeRFBuster数据集上进行了广泛实验。结果表明，RA-NeRF在相机姿态估计和视觉质量上均达到最先进水平，证明了其在复杂姿态轨迹下场景重建的有效性和鲁棒性。

</details>


### [85] [Retrospective Memory for Camouflaged Object Detection](https://arxiv.org/abs/2506.15244)
**中文标题：基于回溯记忆的伪装目标检测**

*Chenxi Zhang,Jiayun Wu,Qing Zhang,Yazhe Zhai,Youwei Pang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为RetroMem的回忆增强型伪装目标检测架构，通过动态整合历史知识显著提升模型对复杂伪装场景的理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有伪装目标检测方法缺乏历史上下文获取机制，限制了其在复杂场景中的适应性和有效性。

研究方法: RetroMem采用两阶段训练范式：学习阶段通过密集多尺度适配器（DMA）增强预训练编码器的多尺度信息捕捉能力；回忆阶段通过动态记忆机制（DMM）和推理模式重建（IPR）整合历史知识优化推理。

研究结果: 在多个广泛使用的数据集上，RetroMem显著优于现有最先进方法。

研究结论: RetroMem通过动态整合历史知识，有效提升了伪装目标检测的性能，为复杂场景下的检测任务提供了新思路。

中文摘要: 伪装目标检测（COD）主要关注从复杂场景中学习细微但具有区分性的表征。现有方法大多基于静态视觉表征建模的参数化前馈架构，但缺乏获取历史上下文的显式机制，限制了其在处理复杂伪装场景时的适应性和有效性。本文提出了一种回忆增强型COD架构RetroMem，通过动态整合相关历史知识来调节伪装模式的感知与推理。具体而言，RetroMem采用两阶段训练范式（学习阶段和回忆阶段）以有效构建、更新和利用记忆表征。在学习阶段，我们设计了密集多尺度适配器（DMA），以极少的可训练参数提升预训练编码器捕捉丰富多尺度视觉信息的能力，从而提供基础推理。在回忆阶段，我们提出了动态记忆机制（DMM）和推理模式重建（IPR），充分利用学习知识与当前样本上下文之间的潜在关系来重建伪装模式的推理，从而显著提升模型对伪装场景的理解。在多个广泛使用的数据集上的大量实验表明，RetroMem显著优于现有最先进方法。

</details>


### [86] [Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing](https://arxiv.org/abs/2506.15260)
**中文标题：半导体制造缺陷图像分类的领域自适应方法**

*Adrian Poniatowski,Natalie Gentner,Manuel Barusco,Davide Dalle Pezze,Samuele Salti,Gian Antonio Susto*

主要分类: cs.CV

摘要简述: 本文研究了领域自适应（DA）在半导体制造缺陷图像分类中的应用，提出了一种改进的CycleGAN模型（DBACS），并在半监督和无监督设置下验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 半导体行业竞争激烈，市场对产品质量和上市时间要求极高。深度学习在计算机视觉领域的成功为缺陷分类等工业应用提供了可能，而领域自适应技术能够减少模型重新标注和训练的需求，降低成本并提高效率。

研究方法: 本文提出了一种名为DBACS的改进CycleGAN模型，通过引入额外的损失项提升性能。在半监督和无监督设置下，使用真实的电子显微镜图像验证了方法的有效性。

研究结果: 实验结果表明，DBACS方法在半导体领域的缺陷分类任务中表现优异，显著提升了领域自适应技术的适用性和性能。

研究结论: DBACS方法为半导体制造中的缺陷分类提供了一种高效且成本较低的解决方案，推动了领域自适应技术在该领域的应用。

中文摘要: 在半导体行业，由于市场需求旺盛且竞争日益激烈，产品上市时间和质量成为确保市场份额的关键因素。近年来，深度学习在计算机视觉领域的成功为工业4.0和5.0应用（如缺陷分类）带来了显著进展。领域自适应（DA）技术因其能够利用源领域知识适应目标领域而表现尤为突出，通过提高鲁棒性和可扩展性，减少了模型重新标注和训练的需求，从而降低了计算和资源成本，使专家能够专注于高价值任务。为此，我们在半导体领域的半监督和无监督设置下测试了DA技术的有效性，并提出了一种基于CycleGAN的DBACS方法，通过引入额外损失项提升性能。所有方法均在真实电子显微镜图像上进行了验证，证明了该方法在推动半导体领域DA技术发展中的实用性。

</details>


### [87] [MSNeRV: Neural Video Representation with Multi-Scale Feature Fusion](https://arxiv.org/abs/2506.15276)
**中文标题：MSNeRV：基于多尺度特征融合的神经视频表示**

*Jun Zhu,Xinfeng Zhang,Lv Tang,JunHao Jiang*

主要分类: cs.CV

摘要简述: MSNeRV是一种多尺度特征融合的神经视频表示方法，通过增强时间一致性和多尺度解码器设计，显著提升了细节密集和快速变化视频内容的表示能力，并在压缩效率上超越了现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于隐式神经表示（INR）的视频压缩方法在细节密集和快速变化的视频内容上表现不佳，主要原因是网络内部特征利用不足和缺乏视频特定设计。MSNeRV旨在解决这些问题。

研究方法: MSNeRV采用多尺度特征融合框架，在编码阶段通过时间窗口增强时间一致性，并将视频划分为多个图像组（GoP），使用GoP级网格表示背景。设计了多尺度空间解码器和尺度自适应损失函数，并引入多尺度特征块以充分利用隐藏特征。

研究结果: 在HEVC ClassB和UVG数据集上的实验表明，MSNeRV在INR方法中表现出卓越的表示能力，并在动态场景的压缩效率上超越了VTM-23.7（随机访问模式）。

研究结论: MSNeRV通过多尺度特征融合和视频特定设计，显著提升了神经视频表示的性能，为视频压缩领域提供了新的解决方案。

中文摘要: 隐式神经表示（INR）已成为视频压缩的一种有前景的方法，其性能已与H.266/VVC等最先进的编解码器相当。然而，现有的基于INR的方法在表示细节密集和快速变化的视频内容时表现不佳，主要原因是网络内部特征利用不足和缺乏视频特定设计。为解决这些问题，我们提出了一种多尺度特征融合框架MSNeRV，用于神经视频表示。在编码阶段，我们通过时间窗口增强时间一致性，并将视频划分为多个图像组（GoP），其中使用GoP级网格表示背景。此外，我们设计了一个多尺度空间解码器，配备尺度自适应损失函数，以整合多分辨率和多频率信息。为进一步提升特征提取，我们引入了多尺度特征块，充分利用隐藏特征。我们在HEVC ClassB和UVG数据集上评估了MSNeRV的视频表示和压缩性能。实验结果表明，我们的模型在INR方法中表现出卓越的表示能力，并在动态场景的压缩效率上超越了VTM-23.7（随机访问模式）。

</details>


### [88] [BCRNet: Enhancing Landmark Detection in Laparoscopic Liver Surgery via Bezier Curve Refinement](https://arxiv.org/abs/2506.15279)
**中文标题：BCRNet：通过贝塞尔曲线优化增强腹腔镜肝脏手术中的标志检测**

*Qian Li,Feng Liu,Shuojue Yang,Daiyun Shen,Yueming Jin*

主要分类: cs.CV

摘要简述: BCRNet通过贝塞尔曲线优化策略显著提升腹腔镜肝脏手术中的关键解剖标志检测，结合多模态特征提取和分层曲线优化机制，在L3D和P2ILF数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 腹腔镜肝脏手术中准确识别解剖标志具有挑战性，而增强现实系统依赖于精确的2D-3D配准。BCRNet旨在通过贝塞尔曲线优化提升标志检测精度，从而改善手术导航。

研究方法: BCRNet包含多模态特征提取模块（MFE）用于语义特征捕获，自适应曲线提案初始化（ACPI）生成初始贝塞尔曲线，以及分层曲线优化（HCR）机制通过多阶段迭代优化曲线。

研究结果: 在L3D和P2ILF数据集上的实验表明，BCRNet显著优于现有方法，实现了性能的显著提升。

研究结论: BCRNet通过创新的贝塞尔曲线优化策略和多阶段特征提取机制，为腹腔镜肝脏手术中的标志检测提供了高效解决方案，具有实际应用潜力。

中文摘要: 腹腔镜肝脏手术虽微创，但准确识别关键解剖结构具有挑战性。增强现实（AR）系统通过整合MRI/CT与腹腔镜图像的2D-3D配准，为手术导航提供了潜在解决方案。配准过程中的关键环节是精确检测腹腔镜图像中的曲线解剖标志。本文提出BCRNet（贝塞尔曲线优化网络），通过贝塞尔曲线优化策略显著提升腹腔镜肝脏手术中的标志检测。该框架首先通过多模态特征提取（MFE）模块捕获语义特征，随后采用自适应曲线提案初始化（ACPI）生成像素对齐的贝塞尔曲线和置信度评分，作为可靠初始提案。此外，设计了分层曲线优化（HCR）机制，通过多阶段迭代优化提案，从多尺度像素级特征中捕获细粒度上下文细节，实现贝塞尔曲线的精确调整。在L3D和P2ILF数据集上的广泛评估表明，BCRNet优于现有方法，性能显著提升。代码将公开。

</details>


### [89] [AI-driven visual monitoring of industrial assembly tasks](https://arxiv.org/abs/2506.15285)
**中文标题：AI驱动的工业装配任务视觉监控**

*Mattia Nardon,Stefano Messelodi,Antonio Granata,Fabio Poiesi,Alberto Danese,Davide Boscaini*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViMAT的AI驱动系统，用于实时视觉监控工业装配任务，无需依赖固定工作空间设置或视觉标记，有效解决了现有商业解决方案的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 工业装配任务的视觉监控对防止设备损坏和保障工人安全至关重要。现有商业解决方案通常需要固定工作空间或视觉标记，限制了其灵活性和适用性。本文旨在开发一种无需这些约束的实时监控系统。

研究方法: ViMAT系统由感知模块和推理模块组成。感知模块从多视角视频流中提取视觉观测数据，推理模块则基于观测到的装配状态和先验任务知识推断最可能的操作。

研究结果: ViMAT在两种装配任务（LEGO组件更换和液压机模具重组）中进行了验证，通过定量和定性分析证明了其在部分和不确定视觉观测下的有效性。

研究结论: ViMAT系统在无需固定工作空间或视觉标记的情况下，成功实现了工业装配任务的实时视觉监控，为复杂场景下的装配任务提供了高效解决方案。

中文摘要: 工业装配任务的视觉监控对防止因程序错误导致的设备损坏和保障工人安全至关重要。尽管已有商业解决方案，但它们通常需要固定的工作空间设置或使用视觉标记以简化问题。我们提出了ViMAT，一种新型AI驱动的实时视觉监控系统，无需这些约束。ViMAT结合了感知模块和推理模块：感知模块从多视角视频流中提取视觉观测数据，推理模块则基于观测到的装配状态和先验任务知识推断最可能的操作。我们在两种装配任务（LEGO组件更换和液压机模具重组）中验证了ViMAT，通过定量和定性分析证明了其在部分和不确定视觉观测下的有效性。项目页面：https://tev-fbk.github.io/ViMAT

</details>


### [90] [MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering](https://arxiv.org/abs/2506.15298)
**中文标题：MEGC2025：微表情大挑战——先检测后识别与视觉问答**

*Xinqi Fan,Jingting Li,John See,Moi Hoon Yap,Wen-Huang Cheng,Xiaobai Li,Xiaopeng Hong,Su-Jing Wang,Adrian K. Davision*

主要分类: cs.CV

摘要简述: MEGC2025挑战赛聚焦微表情的‘先检测后识别’（ME-STR）和视觉问答（ME-VQA）任务，旨在通过多模态大模型提升微表情分析的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法将微表情检测与识别分开处理，效率低下，尤其在长视频分析中表现不佳。多模态大语言模型（MLLMs）和大视觉语言模型（LVLMs）的出现为微表情分析提供了新的可能性。

研究方法: MEGC2025提出两项任务：1）ME-STR，将微表情检测与识别整合为统一流程；2）ME-VQA，利用MLLMs或LVLMs通过视觉问答理解微表情。

研究结果: 参赛算法需在测试集上运行并提交结果，排行榜将展示性能表现。

研究结论: MEGC2025通过整合检测与识别及引入视觉问答，推动了微表情分析领域的发展。

中文摘要: 面部微表情（MEs）是人在抑制情绪时面部产生的无意识动作，常见于高风险环境。近年来，微表情的识别、检测与生成领域取得了显著进展。然而，传统方法将检测与识别分开处理，效率较低，尤其在长视频分析中表现不佳。同时，多模态大语言模型（MLLMs）和大视觉语言模型（LVLMs）的出现为微表情分析提供了新的可能性。MEGC2025微表情大挑战提出两项任务：1）ME-STR，将微表情检测与识别整合为统一流程；2）ME-VQA，利用MLLMs或LVLMs通过视觉问答理解微表情。所有参赛算法需在测试集上运行并提交结果至排行榜。更多详情请访问https://megc2025.github.io。

</details>


### [91] [MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning](https://arxiv.org/abs/2506.15313)
**中文标题：MapFM：基于基础模型的多任务上下文学习驱动的高清地图生成**

*Leonid Ivanov,Vasily Yuryev,Dmitry Yudin*

主要分类: cs.CV

摘要简述: MapFM是一种端到端模型，通过结合强大的基础模型和多任务学习，显著提升了高清地图生成的质量和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在自动驾驶中，高清地图和鸟瞰图语义地图对精确定位、规划和决策至关重要。现有方法在特征表示和环境理解方面仍有提升空间，因此需要一种更高效的模型来生成高质量的向量化高清地图。

研究方法: MapFM采用端到端模型，结合基础模型编码相机图像，并通过多任务学习引入鸟瞰图语义分割辅助预测头，以丰富环境理解和提升预测质量。

研究结果: 实验表明，MapFM显著提升了特征表示质量，生成的高清地图在准确性和质量上均有明显改进。

研究结论: MapFM通过多任务上下文学习和基础模型的结合，实现了更全面的场景表示和更高精度的向量化高清地图生成，为自动驾驶提供了可靠支持。

中文摘要: 在自动驾驶中，高清（HD）地图和鸟瞰图（BEV）语义地图对于精确定位、规划和决策至关重要。本文提出了一种名为MapFM的增强型端到端模型，用于在线生成向量化高清地图。通过结合强大的基础模型编码相机图像，我们显著提升了特征表示质量。为了进一步丰富模型对环境的理解并提高预测质量，我们在BEV表示中集成了语义分割的辅助预测头。这种多任务学习方法提供了更丰富的上下文监督，从而实现了更全面的场景表示，最终提高了预测的向量化高清地图的准确性和质量。源代码可在https://github.com/LIvanoff/MapFM获取。

</details>


### [92] [OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models](https://arxiv.org/abs/2506.15318)
**中文标题：OpenPath：基于预训练视觉语言模型的病理图像分类开集主动学习方法**

*Lanfeng Zhong,Xin Liao,Shichuan Zhang,Shaoting Zhang,Guotai Wang*

主要分类: cs.CV

摘要简述: OpenPath提出了一种基于预训练视觉语言模型的开集主动学习方法，用于病理图像分类，通过任务特定提示和多样性信息采样策略，有效减少标注成本并提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 病理图像分类在医学诊断中至关重要，但传统主动学习方法假设未标注数据均属于目标类别，而现实中存在大量分布外数据，导致标注效率低下。OpenPath旨在解决这一问题。

研究方法: OpenPath利用预训练视觉语言模型，首轮查询使用任务特定提示筛选目标和非目标类样本，后续查询采用原型候选选择和熵引导随机采样策略，确保样本纯净性和信息量。

研究结果: 在两个公开病理图像数据集上的实验表明，OpenPath显著提升了模型性能，优于现有开集主动学习方法，且所选样本纯净度高。

研究结论: OpenPath通过结合任务特定提示和多样性采样策略，有效解决了开集主动学习中的标注效率问题，为病理图像分类提供了高效解决方案。

中文摘要: 病理图像分类在医学诊断和治疗规划中具有重要作用。训练高性能模型通常需要大规模标注数据集，但获取这些数据成本高昂且耗时。主动学习（AL）通过迭代选择信息量最大的样本进行标注，从而减少标注工作量。然而，大多数AL方法基于闭集假设设计，即所有未标注图像均属于目标类别。在真实临床环境中，未标注池通常包含大量分布外（OOD）数据，导致传统AL方法标注效率低下。此外，现有AL方法在首轮查询中通常随机选择样本，在开集场景下造成标注成本浪费。为解决这些问题，我们提出了OpenPath，一种基于预训练视觉语言模型（VLM）的开集主动学习方法。在首轮查询中，我们提出任务特定提示，结合目标和非目标类提示，从未标注池中有效选择分布内（ID）和信息量大的样本。在后续查询中，提出了多样性信息ID采样（DIS），包括基于原型的ID候选选择（PIS）和熵引导随机采样（EGSS），以确保查询的纯净性和信息量，避免选择OOD样本。在两个公开病理图像数据集上的实验表明，OpenPath因其所选样本的高纯净性显著提升了模型性能，并优于多种先进的开集AL方法。代码发布于\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}。

</details>


### [93] [Open-World Object Counting in Videos](https://arxiv.org/abs/2506.15368)
**中文标题：视频中的开放世界物体计数**

*Niki Amini-Naieni,Andrew Zisserman*

主要分类: cs.CV

摘要简述: 本文提出了一种视频中的开放世界物体计数新任务，通过文本描述或图像示例指定目标物体，统计视频中所有独特实例。为解决拥挤场景中的遮挡和相似物体问题，作者提出了CountVid模型，结合图像计数和视频分割跟踪技术，并在新数据集VideoCount上验证其优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 开放世界物体计数在视频中是一个未被充分探索的任务，尤其在拥挤场景中，遮挡和相似物体容易导致重复计数或遗漏。本文旨在解决这一问题，提出一种自动化方法，准确统计视频中目标物体的独特实例。

研究方法: 作者提出CountVid模型，结合图像计数模型和可提示的视频分割与跟踪模型，实现跨视频帧的自动化物体计数。模型通过整合两种技术，避免重复计数并识别目标物体的重现。

研究结果: 在基于TAO、MOT20及企鹅和金属合金X射线视频的新数据集VideoCount上，CountVid表现优异，显著优于基线方法，提供了准确的物体计数结果。

研究结论: CountVid为开放世界视频物体计数提供了高效解决方案，解决了拥挤场景中的挑战，并在新数据集上验证了其性能。数据集、模型和代码均已开源。

中文摘要: 我们提出了一种视频中的开放世界物体计数新任务：给定一个文本描述或图像示例来指定目标物体，目标是统计视频中所有独特的目标物体实例。这一任务在拥挤场景中尤为困难，因为遮挡和相似物体容易导致重复计数或遗漏。为此，我们提出以下贡献：我们提出了CountVid模型，该模型结合了基于图像的计数模型和可提示的视频分割与跟踪模型，以实现跨视频帧的自动化开放世界物体计数。为评估其性能，我们构建了VideoCount数据集，该数据集基于TAO和MOT20跟踪数据集，以及企鹅和金属合金X射线视频。实验表明，CountVid能够提供准确的物体计数，并显著优于基线方法。VideoCount数据集、CountVid模型及所有代码均已开源。

</details>


### [94] [Unsupervised Pelage Pattern Unwrapping for Animal Re-identification](https://arxiv.org/abs/2506.15369)
**中文标题：无监督动物皮毛图案展开用于再识别**

*Aleksandr Algasov,Ekaterina Nepovinnykh,Fedor Zolotarev,Tuomas Eerola,Heikki Kälviäinen,Pavel Zemčík,Charles V. Stewart*

主要分类: cs.CV

摘要简述: 本文提出了一种无监督的动物皮毛图案展开方法，通过几何感知的纹理映射将变形图案映射到标准UV空间，提升了动物再识别的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有动物个体再识别方法难以应对因身体运动和姿态变化导致的皮毛或皮肤图案变形问题，亟需一种能够保持几何一致性的解决方案。

研究方法: 采用表面法线估计指导皮毛图案展开，将3D表面与2D纹理空间的几何一致性保留，结合自监督训练，无需标注数据。

研究结果: 在环斑海豹和豹子数据集上实验表明，再识别准确率最高提升5.4%。

研究结论: 该方法通过无监督的图案展开技术显著提升了动物再识别的鲁棒性，适用于多种姿态和视角。

中文摘要: 现有的个体再识别方法往往难以应对动物皮毛或皮肤图案因身体运动和姿态变化而产生的几何变形。本文提出了一种几何感知的纹理映射方法，将独特的皮毛图案展开到标准UV空间，从而实现更鲁棒的特征匹配。我们的方法利用表面法线估计指导展开过程，同时保持3D表面与2D纹理空间之间的几何一致性。我们聚焦于两种具有挑战性的物种：赛马环斑海豹（Pusa hispida saimensis）和豹子（Panthera pardus）。这两种物种的皮毛图案独特且易变形。通过将我们的图案保留UV映射与现有再识别技术结合，我们在多样姿态和视角下展示了更高的准确性。我们的框架无需标注真实UV数据，可通过自监督方式训练。在环斑海豹和豹子数据集上的实验表明，再识别准确率最高提升5.4%。

</details>


### [95] [When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class](https://arxiv.org/abs/2506.15381)
**中文标题：当模型知识遇上扩散模型：基于扩散辅助的无数据图像合成与域和类的对齐**

*Yujin Kim,Hyunsoo Kim,Hyunwoo J. Kim,Suhyun Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DDIS的扩散辅助无数据图像合成方法，利用扩散模型作为图像先验，通过域对齐引导和类对齐标记优化，生成更接近训练数据分布的图像，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 开源预训练模型的应用潜力巨大，但其训练数据不可用时，实用性下降。现有的无数据图像合成方法因缺乏自然图像的先验知识，生成的样本偏离训练数据分布。本文旨在解决这一问题。

研究方法: DDIS方法利用文本到图像的扩散模型作为图像先验，通过域对齐引导（DAG）在扩散采样过程中对齐合成数据域与训练数据域，并优化类对齐标记（CAT）嵌入以捕获类特定属性。

研究结果: 在PACS和ImageNet上的实验表明，DDIS生成的图像更准确地反映了训练数据分布，在无数据应用中实现了最先进的性能。

研究结论: DDIS通过结合扩散模型和预训练模型的知识，显著提升了无数据图像合成的质量，为数据不可用场景提供了有效解决方案。

中文摘要: 开源预训练模型具有广泛的应用潜力，但当其训练数据不可用时，其实用性会下降。无数据图像合成（DFIS）旨在无需访问原始数据的情况下生成近似预训练模型学习数据分布的图像。然而，现有的DFIS方法因缺乏自然图像的先验知识，生成的样本偏离训练数据分布。为克服这一限制，我们提出了DDIS，首个利用文本到图像扩散模型作为强大图像先验的扩散辅助无数据图像合成方法，显著提升了合成图像质量。DDIS从给定模型中提取学习分布的知识，并利用其引导扩散模型，生成与训练数据分布准确对齐的图像。为此，我们引入了域对齐引导（DAG），在扩散采样过程中对齐合成数据域与训练数据域。此外，我们优化了单个类对齐标记（CAT）嵌入，以有效捕获训练数据集中的类特定属性。在PACS和ImageNet上的实验表明，DDIS优于现有的DFIS方法，生成的样本更好地反映了训练数据分布，在无数据应用中实现了最先进的性能。

</details>


### [96] [NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance](https://arxiv.org/abs/2506.15404)
**中文标题：NERO：基于神经元相关性的可解释分布外检测**

*Anju Chhetri,Jari Korhonen,Prashnna Gyawali,Binod Bhattarai*

主要分类: cs.CV

摘要简述: 本文提出了一种名为NERO的新型OOD检测方法，通过神经元级相关性增强OOD样本的可分离性，并在医学影像基准测试中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在医学影像领域，确保深度学习模型的可靠性至关重要，尤其是检测分布外（OOD）样本的能力。现有方法可能无法完全捕捉OOD的多样性，因此需要一种更有效的OOD检测机制。

研究方法: NERO利用特征层的神经元级相关性，通过聚类形成类内代表性中心，并引入相关性距离度量新样本与这些中心的偏差。此外，通过结合偏置项的缩放相关性和特征范数进一步提升性能。

研究结果: 在胃肠道影像基准测试Kvasir和GastroVision上，NERO在多种深度学习架构中表现优异，显著优于现有OOD检测方法。

研究结论: NERO不仅提高了OOD检测的准确性，还提供了可解释性，为医学影像领域的模型可靠性提供了新思路。

中文摘要: 在深度学习中，确保可靠性至关重要，尤其是在医学影像领域，诊断决策往往依赖于模型输出。检测分布外（OOD）样本的能力已被证明是模型可靠性的重要指标。在医学影像中，识别OOD输入尤为关键，因为它可以帮助标记可能被忽视的潜在异常。尽管许多OOD检测方法依赖于特征或逻辑空间表示，但近期研究表明这些方法可能无法完全捕捉OOD的多样性。为此，我们提出了一种名为NERO的新型OOD评分机制，利用特征层的神经元级相关性。具体而言，我们为每个类内分布（ID）类聚类神经元级相关性以形成代表性中心，并引入相关性距离度量新样本与这些中心的偏差，从而增强OOD的可分离性。此外，我们通过结合偏置项的缩放相关性和特征范数进一步优化性能。我们的框架还支持可解释的OOD检测。我们在胃肠道影像基准测试Kvasir和GastroVision上验证了其有效性，结果表明NERO在多种深度学习架构中优于现有OOD检测方法。

</details>


### [97] [Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material](https://arxiv.org/abs/2506.15442)
**中文标题：Hunyuan3D 2.1：从图像到高保真3D资产，具备生产级PBR材质**

*Team Hunyuan3D,Shuhui Yang,Mingxin Yang,Yifei Feng,Xin Huang,Sheng Zhang,Zebin He,Di Luo,Haolin Liu,Yunfei Zhao,Qingxiang Lin,Zeqiang Lai,Xianghui Yang,Huiwen Shi,Zibo Zhao,Bowen Zhang,Hongyu Yan,Lifu Wang,Sicong Liu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Yulin Cai,Jiaao Yu,Yixuan Tang,Dongyuan Guo,Junlin Yu,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Shida Wei,Chao Zhang,Yonghao Tan,Yifu Sun,Lin Niu,Shirui Huang,Bojian Zheng,Shu Liu,Shilin Chen,Xiang Yuan,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Jingwei Huang,Chunchao Guo*

主要分类: cs.CV

摘要简述: 本文介绍了Hunyuan3D 2.1系统，通过案例研究提供从图像生成高保真3D资产的完整流程，包括形状生成和纹理合成，适用于游戏、虚拟现实和工业设计。


<details>
  <summary>详细信息</summary>
研究动机: 3D AI生成内容（AIGC）在游戏、电影和设计领域发展迅速，但由于数据收集、处理和模型训练的复杂性，该领域仍主要局限于研究人员和开发者。本文旨在通过Hunyuan3D 2.1系统降低门槛，提供一套完整的3D生成解决方案。

研究方法: Hunyuan3D 2.1系统包含两个核心组件：Hunyuan3D-DiT用于形状生成，Hunyuan3D-Paint用于纹理合成。教程详细介绍了数据准备、模型架构、训练策略、评估指标和部署流程。

研究结果: Hunyuan3D 2.1能够生成高分辨率、带纹理的3D资产，适用于实际生产环境。教程帮助用户掌握调优或开发3D生成模型的能力。

研究结论: 通过本教程，用户可以学习到如何利用Hunyuan3D 2.1系统生成高质量的3D资产，推动3D AIGC在游戏、虚拟现实和工业设计中的应用。

中文摘要: 3D AI生成内容（AIGC）是一个快速发展的领域，显著加速了游戏、电影和设计中3D模型的创建。尽管已有多个突破性模型推动了3D生成技术的发展，但由于数据收集、处理和模型训练的复杂性，该领域仍主要局限于研究人员、开发者和设计师。为解决这些问题，本文以Hunyuan3D 2.1为例，提供了一个全面的教程，逐步指导如何处理3D数据、训练3D生成模型，并使用Hunyuan3D 2.1评估其性能。该系统包含两个核心组件：Hunyuan3D-DiT用于形状生成，Hunyuan3D-Paint用于纹理合成。教程涵盖了数据准备、模型架构、训练策略、评估指标和部署流程。通过学习本教程，您将掌握调优或开发适用于游戏、虚拟现实和工业设计的3D生成模型的能力。

</details>


### [98] [Multimodal Large Language Models for Medical Report Generation via Customized Prompt Tuning](https://arxiv.org/abs/2506.15477)
**中文标题：基于定制化提示调优的多模态大语言模型在医学报告生成中的应用**

*Chunlei Li,Jingyang Hou,Yilei Shi,Jingliang Hu,Xiao Xiang Zhu,Lichao Mou*

主要分类: cs.CV

摘要简述: 本文提出了一种新型多模态大语言模型MRG-LLM，通过定制化提示调优技术，结合冻结的大语言模型与可学习的视觉编码器，动态生成针对医学图像的实例特定提示，显著提升了医学报告生成的性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像报告生成在临床实践中仍具挑战性，现有大语言模型虽潜力巨大，但与医学影像数据的有效结合仍需深入探索。本文旨在通过多模态大语言模型解决这一问题。

研究方法: MRG-LLM结合冻结的大语言模型与可学习的视觉编码器，引入动态提示定制机制，通过视觉特征驱动的条件仿射变换生成实例特定提示，并提出提示级和提示簿级两种定制实现方式。

研究结果: 在IU X-ray和MIMIC-CXR数据集上的实验表明，MRG-LLM在医学报告生成任务中达到了最先进的性能。

研究结论: MRG-LLM通过动态提示定制机制，显著提升了医学报告生成的准确性和针对性，为多模态大语言模型在医学领域的应用提供了新思路。

中文摘要: 医学影像数据的报告生成在临床实践中仍是一项具有挑战性的任务。尽管大语言模型（LLMs）在解决这一问题上展现出巨大潜力，但其与医学影像数据的有效结合仍需深入探索。本文提出了一种新型多模态大语言模型MRG-LLM，它将冻结的大语言模型与可学习的视觉编码器相结合，并引入了一种动态提示定制机制。我们的核心创新在于通过视觉特征驱动的条件仿射变换，生成针对单个医学图像的实例特定提示。我们提出了两种实现方式：提示级和提示簿级定制，以实现精准且有目标的报告生成。在IU X-ray和MIMIC-CXR数据集上的大量实验表明，MRG-LLM在医学报告生成任务中达到了最先进的性能。我们的代码将公开提供。

</details>


### [99] [GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects](https://arxiv.org/abs/2506.15483)
**中文标题：GenHOI：面向未见物体的文本驱动4D人-物交互合成的泛化方法**

*Shujia Li,Haiyu Zhang,Xinyuan Chen,Yaohui Wang,Yutong Ban*

主要分类: cs.CV

摘要简述: GenHOI是一种新颖的两阶段框架，旨在实现对未见物体的泛化和高质量4D人-物交互序列的合成。通过Object-AnchorNet重建稀疏3D关键帧，再通过Contact-Aware Diffusion Model插值生成密集4D序列，实验显示其在OMOMO和3D-FUTURE数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本驱动的人体运动合成虽已取得进展，但扩展到4D人-物交互（HOI）仍面临挑战，主要由于缺乏大规模4D HOI数据集。GenHOI旨在解决这一问题，实现泛化和高质量合成。

研究方法: GenHOI采用两阶段框架：1) 使用Object-AnchorNet从3D HOI数据集中学习，为未见物体重建稀疏3D HOI关键帧；2) 通过Contact-Aware Diffusion Model（ContactDM）插值生成密集4D序列，其中包含Contact-Aware Encoder和Contact-Aware HOI Attention以提升质量。

研究结果: 实验结果表明，GenHOI在OMOMO和3D-FUTURE数据集上达到最优性能，展示了强大的泛化能力和高质量的4D HOI生成能力。

研究结论: GenHOI通过两阶段框架成功实现了对未见物体的泛化和高质量4D HOI序列合成，为文本驱动的4D HOI合成提供了有效解决方案。

中文摘要: 尽管扩散模型和大规模运动数据集推动了文本驱动的人体运动合成，但将其扩展到4D人-物交互（HOI）仍具挑战性，主要由于缺乏大规模4D HOI数据集。本研究提出GenHOI，一种新颖的两阶段框架，旨在实现两个关键目标：1) 对未见物体的泛化；2) 合成高保真4D HOI序列。框架的第一阶段使用Object-AnchorNet从3D HOI数据集中学习，为未见物体重建稀疏3D HOI关键帧，减少对大规模4D HOI数据集的依赖。第二阶段引入Contact-Aware Diffusion Model（ContactDM），将稀疏3D HOI关键帧无缝插值为密集时间连贯的4D HOI序列。为提升生成质量，我们在ContactDM中提出了一种新颖的Contact-Aware Encoder以提取人-物接触模式，以及一种Contact-Aware HOI Attention以有效将接触信号融入扩散模型。实验结果表明，我们在公开的OMOMO和3D-FUTURE数据集上取得了最优结果，展示了对未见物体的强大泛化能力，同时实现了高保真4D HOI生成。

</details>


### [100] [NTIRE 2025 Image Shadow Removal Challenge Report](https://arxiv.org/abs/2506.15524)
**中文标题：NTIRE 2025图像阴影去除挑战赛报告**

*Florin-Alexandru Vasluianu,Tim Seizinger,Zhuyun Zhou,Cailian Chen,Zongwei Wu,Radu Timofte,Mingjia Li,Jin Hu,Hainuo Wang,Hengxing Liu,Jiarui Wang,Qiming Hu,Xiaojie Guo,Xin Lu,Jiarong Yang,Yuanfei Bao,Anya Hu,Zihao Fan,Kunyu Wang,Jie Xiao,Xi Wang,Xueyang Fu,Zheng-Jun Zha,Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu,Xingbo Wang,Dong Li,Yuxu Chen,Bin Chen,Yuanbo Zhou,Yuanbin Chen,Hongwei Wang,Jiannan Lin,Qinquan Gao,Tong Tong,Zhao Zhang,Yanyan Wei,Wei Dong,Han Zhou,Seyed Amirreza Mousavi,Jun Chen,Haobo Liang,Jiajie Jing,Junyu Li,Yan Yang,Seoyeon Lee,Chaewon Kim,Ziyu Feng,Shidi Chen,Bowen Luan,Zewen Chen,Vijayalaxmi Ashok Aralikatti,G Gyaneshwar Rao,Nikhil Akalwadi,Chaitra Desai,Ramesh Ashok Tabib,Uma Mudenagudi,Anas M. Ali,Bilel Benjdira,Wadii Boulila,Alexandru Brateanu,Cosmin Ancuti,Tanmay Chaturvedi,Manish Kumar,Anmol Srivastav,Daksh Trivedi,Shashwat Thakur,Kishor Upla,Zeyu Xiao,Zhuoyuan Li,Boda Zhou,Shashank Shekhar,Kele Xu,Qisheng Xu,Zijian Gao,Tianjiao Wan,Suiyi Zhao,Bo Wang,Yan Luo,Mingshen Wang,Yilin Zhang*

主要分类: cs.CV

摘要简述: 本文总结了NTIRE 2025图像阴影去除挑战赛的结果，共有306名参与者注册，17支团队成功提交解决方案。挑战赛分为重建保真度和视觉感知两个评估赛道，使用WSRD+数据集进行评测。


<details>
  <summary>详细信息</summary>
研究动机: NTIRE 2025挑战赛旨在推动图像阴影去除技术的发展，通过多团队竞争和双轨评估（重建保真度和视觉感知）来探索更优的解决方案。

研究方法: 挑战赛分为两个评估赛道：重建保真度赛道和视觉感知赛道（通过用户研究）。评测数据来自WSRD+数据集，模拟了自阴影和投射阴影与多种物体、纹理和材料的交互。

研究结果: 共有306名参与者注册，17支团队成功提交解决方案。双轨评估展示了不同团队在阴影去除技术上的表现。

研究结论: NTIRE 2025挑战赛成功吸引了大量参与者，并通过双轨评估为图像阴影去除技术提供了新的研究方向和基准。

中文摘要: 本文研究了NTIRE 2025阴影去除挑战赛的结果。共有306名参与者注册，其中17支团队在最终评估阶段成功提交了解决方案。延续前两届的设定，本次挑战赛分为两个评估赛道：一个关注重建保真度，另一个通过用户研究评估视觉感知。两个赛道均使用WSRD+数据集进行评测，该数据集模拟了大量多样物体、纹理和材料中自阴影与投射阴影的交互。

</details>


### [101] [CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation](https://arxiv.org/abs/2506.15549)
**中文标题：CLAIM：临床引导的LGE增强技术用于真实多样的心肌瘢痕合成与分割**

*Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen,Chen*

主要分类: cs.CV

摘要简述: CLAIM框架通过临床引导的LGE增强技术，生成多样且真实的瘢痕图像，并优化分割网络，显著提升瘢痕分割的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有LGE心脏MRI数据稀缺且标签质量不一，限制了深度学习模型在心肌瘢痕分割中的性能。CLAIM旨在通过临床知识引导的瘢痕合成与分割框架解决这一问题。

研究方法: CLAIM框架包含SMILE模块，利用临床采用的AHA 17段模型指导扩散生成器合成解剖学一致的瘢痕图像，并采用联合训练策略优化分割网络。

研究结果: 实验表明，CLAIM生成的瘢痕图像解剖学一致性高，与真实瘢痕分布的Dice相似性优于基线模型。

研究结论: CLAIM实现了可控且真实的心肌瘢痕合成，对下游医学影像任务具有实用价值。

中文摘要: 基于深度学习的晚期钆增强（LGE）心脏MRI心肌瘢痕分割在准确诊断和治疗结构性心脏病方面展现出巨大潜力。然而，高质量瘢痕标签的LGE图像稀缺且变异性大，限制了稳健分割模型的开发。为此，我们提出CLAIM框架：临床引导的LGE增强技术用于真实多样的心肌瘢痕合成与分割。其核心是SMILE模块（基于临床知识的瘢痕掩模生成），通过临床采用的AHA 17段模型指导扩散生成器合成解剖学一致且空间多样的瘢痕图像。此外，CLAIM采用联合训练策略，优化瘢痕分割网络与生成器，旨在提升合成瘢痕的真实性和分割准确性。实验结果表明，CLAIM生成的瘢痕图像解剖学一致性高，与真实瘢痕分布的Dice相似性优于基线模型。该方法实现了可控且真实的心肌瘢痕合成，对下游医学影像任务具有实用价值。

</details>


### [102] [RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation](https://arxiv.org/abs/2506.15560)
**中文标题：RaCalNet：基于稀疏监督的雷达校准网络用于度量深度估计**

*Xingrui Qin,Wentao Zhao,Chuan Cao,Yihe Niu,Houcheng Jiang,Jingchuan Wang*

主要分类: cs.CV

摘要简述: RaCalNet是一种新型雷达校准网络，通过稀疏LiDAR监督实现高精度深度估计，无需密集监督，显著降低数据需求，性能优于现有密集监督方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统毫米波雷达深度估计依赖密集LiDAR监督，成本高且数据需求大。RaCalNet旨在通过稀疏监督实现高效深度估计，减少资源消耗。

研究方法: RaCalNet首先校准和优化稀疏雷达点，构建精确深度先验，作为单目深度预测的可靠锚点，避免依赖密集监督，同时提升结构一致性和细节保留。

研究结果: 在ZJU-4DRadarCam数据集和实际场景中，RaCalNet表现优异，RMSE分别降低35.30%和34.89%，生成具有清晰轮廓和细腻纹理的深度图。

研究结论: RaCalNet通过稀疏监督实现高效深度估计，性能超越密集监督方法，为实际应用提供了一种低成本、高性能的解决方案。

中文摘要: 使用毫米波雷达进行密集度量深度估计通常需要密集的LiDAR监督，通过多帧投影和插值生成，以指导从稀疏雷达测量和RGB图像中学习准确深度。然而，这种模式既昂贵又数据密集。为此，我们提出RaCalNet，一种新型框架，通过使用稀疏LiDAR监督学习优化的雷达测量，消除了对密集监督的需求，监督密度仅为密集监督方法的约1%。与之前将雷达点与广泛图像区域关联并严重依赖密集标签的方法不同，RaCalNet首先重新校准和优化稀疏雷达点，构建精确的深度先验。这些先验随后作为可靠锚点，指导单目深度预测，实现无需密集监督的度量尺度估计。这一设计提升了结构一致性并保留了精细细节。尽管仅依赖稀疏监督，RaCalNet超越了最先进的密集监督方法，生成的深度图具有清晰的对象轮廓和细腻纹理。在ZJU-4DRadarCam数据集和实际部署场景中的大量实验证明了其有效性，分别将RMSE降低了35.30%和34.89%。

</details>


### [103] [Control and Realism: Best of Both Worlds in Layout-to-Image without Training](https://arxiv.org/abs/2506.15563)
**中文标题：控制与真实感：无需训练的布局到图像生成的最佳方案**

*Bonan Li,Yinhan Hu,Songhua Liu,Xinchao Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的布局到图像生成方法WinWinLay，通过非局部注意力能量函数和自适应更新策略，解决了现有方法在定位不准和图像失真上的问题，显著提升了控制精度和真实感。


<details>
  <summary>详细信息</summary>
研究动机: 现有的布局到图像生成方法虽然无需特定数据训练，但存在定位不准和图像失真的问题。本文旨在解决这些缺陷，提出一种无需训练的新方法，以实现更精确的控制和更高的图像真实感。

研究方法: WinWinLay提出两种关键策略：1) 非局部注意力能量函数，通过重新分配注意力分数，消除空间分布偏差，使物体更符合布局指令；2) 基于Langevin动力学的自适应更新方案，避免因反向传播导致的预训练域偏离，减少失真。

研究结果: 实验表明，WinWinLay在元素布局控制和图像真实感方面表现优异，显著优于现有方法。

研究结论: WinWinLay通过非局部注意力能量函数和自适应更新策略，实现了布局到图像生成的高精度控制和高真实感，为无需训练的方法提供了新的解决方案。

中文摘要: 布局到图像生成的目标是通过对物体位置和排列的精确控制创建复杂场景。现有研究表明，预训练的文本到图像扩散模型可以在无需特定数据训练的情况下实现这一目标，但常面临定位不准和图像失真的问题。针对这些缺陷，我们提出了一种无需训练的新方法WinWinLay。其核心是两种关键策略：非局部注意力能量函数和自适应更新，共同提升控制精度和真实感。一方面，我们理论证明常用的注意力能量函数会引入固有空间分布偏差，阻碍物体与布局指令的均匀对齐。为解决此问题，我们探索了非局部注意力先验，重新分配注意力分数，使物体更符合指定的空间条件。另一方面，我们发现普通的反向传播更新规则会导致预训练域的偏离，产生分布外失真。为此，我们引入了基于Langevin动力学的自适应更新方案，在尊重布局约束的同时促进域内更新。大量实验表明，WinWinLay在元素布局控制和图像真实感方面表现卓越，优于当前最先进的方法。

</details>


### [104] [Show-o2: Improved Native Unified Multimodal Models](https://arxiv.org/abs/2506.15564)
**中文标题：Show-o2：改进的原生统一多模态模型**

*Jinheng Xie,Zhenheng Yang,Mike Zheng Shou*

主要分类: cs.CV

摘要简述: 本文提出了改进的原生统一多模态模型Show-o2，通过自回归建模和流匹配技术，在3D因果变分自编码器空间中构建统一视觉表示，支持跨图像和视频模态的多模态理解与生成。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态模型在处理跨模态任务时存在局限性，需要一种能够统一处理文本、图像和视频的模型，以提升多模态理解和生成的能力。

研究方法: Show-o2基于语言模型，采用自回归建模和流匹配技术，分别应用于语言头和流头，以支持文本标记预测和图像/视频生成。通过双路径空间（-时间）融合构建统一视觉表示，并设计两阶段训练方法以扩展至更大模型。

研究结果: Show-o2模型在多种多模态理解和生成任务中表现出色，能够灵活处理文本、图像和视频等多种模态。

研究结论: Show-o2通过原生统一多模态建模和两阶段训练方法，显著提升了跨模态任务的性能，为多模态研究提供了新的解决方案。

中文摘要: 本文提出了改进的原生统一多模态模型Show-o2，利用自回归建模和流匹配技术。基于3D因果变分自编码器空间，通过空间（-时间）融合的双路径构建统一视觉表示，支持跨图像和视频模态的可扩展性，同时确保有效的多模态理解和生成。基于语言模型，自回归建模和流匹配分别应用于语言头和流头，以促进文本标记预测和图像/视频生成。设计了两阶段训练方法以有效学习并扩展至更大模型。最终的Show-o2模型在多种多模态理解和生成任务中表现出广泛的适用性，涵盖文本、图像和视频等多种模态。代码和模型发布于https://github.com/showlab/Show-o。

</details>


### [105] [Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification](https://arxiv.org/abs/2506.15565)
**中文标题：巴尔的摩地图集：用于半监督超高空间分辨率土地覆盖分类的FreqWeaver适配器**

*Junhao Wu,Aboagye-Ntow Stephen,Chuyuan Wang,Gang Chen,Xin Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种参数高效的半监督分割框架，用于0.3米空间分辨率影像，通过引入FreqWeaver适配器增强细粒度细节建模，仅占用模型总参数的5.96%，在未标注数据上表现优异，性能超越现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 超高空间分辨率土地覆盖分类对细粒度分析至关重要，但面临标注成本高、尺度变化大以及大规模视觉模型适应性有限等挑战。现有方法多依赖标注数据且仅适用于1米分辨率影像，而实际应用需在弱监督下处理更高分辨率影像。

研究方法: 提出了一种参数高效的半监督分割框架，结合SAM2知识并引入FreqWeaver适配器，专注于0.3米分辨率影像的细粒度建模，同时保持轻量化设计（仅占模型总参数的5.96%）。

研究结果: 该方法在未标注数据上表现优异，结构一致性显著提升，比现有参数高效调优策略提升1.78%，比最先进的高分辨率遥感分割方法提升3.44%。

研究结论: 所提框架通过高效利用未标注数据和最小化参数开销，实现了稳健的分割结果，为超高分辨率遥感影像分类提供了有效解决方案。

中文摘要: 超高空间分辨率土地覆盖分类对细粒度土地覆盖分析至关重要，但由于像素级标注成本高、尺度变化显著以及大规模视觉模型适应性有限，该任务仍具挑战性。现有方法通常专注于1米空间分辨率影像，并严重依赖标注数据，而实际应用常需在弱监督下处理更高分辨率影像。为此，我们提出了一种参数高效的半监督分割框架，适用于0.3米空间分辨率影像，该框架利用SAM2的知识，并引入一种专为遥感设计的FreqWeaver适配器，以增强细粒度细节建模，同时保持轻量化设计（仅占模型总参数的5.96%）。通过有效利用未标注数据并保持最小参数开销，所提方法提供了稳健的分割结果，具有优异的结构一致性，比现有参数高效调优策略提升1.78%，比最先进的高分辨率遥感分割方法提升3.44%。

</details>


### [106] [A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds](https://arxiv.org/abs/2506.15577)
**中文标题：基于图的统一框架：从点云实现可扩展的3D树木重建与无损生物量估算**

*Di Wang,Shi Li*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图的统一框架，用于从点云数据中实现可扩展的3D树木重建和无损生物量估算，显著降低了预处理依赖性并提升了实用性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于定量结构模型（QSM）的森林地上生物量（AGB）估算方法存在局限性，如依赖高质量点云数据、仅适用于单棵树且预处理步骤繁琐，难以规模化应用。本研究旨在解决这些问题，提出一种更高效、可扩展的解决方案。

研究方法: 研究提出了一种基于图的统一框架，通过创新的图操作（如路径提取和拓扑抽象）实现端到端的点云处理，包括树木分割、叶木分离和3D骨架重建。该方法适用于不同叶况（有叶和无叶）、空间尺度（单树和林分）和数据源（地面激光扫描TLS和无人机激光扫描ULS）。

研究结果: 实验结果表明，该方法在挑战性条件下表现优异，尤其在有叶场景（相对误差约20%）和低密度ULS数据（相对误差约30%）中。研究还证明了ULS可作为TLS的可行替代方案。

研究结论: 该框架为大规模无损AGB估算提供了稳健且可扩展的解决方案，显著减少了对专用预处理工具的依赖，并推动了QSM在森林调查和气候变化研究中的广泛应用。

中文摘要: 森林地上生物量（AGB）的估算对评估碳储存和支持可持续森林管理至关重要。定量结构模型（QSM）通过3D树木结构重建提供了一种无损估算AGB的方法。然而，现有QSM方法主要针对单棵树设计，依赖地面激光扫描（TLS）的高质量点云数据，且需要繁琐的预处理步骤，限制了其可扩展性和实际应用。本研究提出了一种新颖的统一框架，利用基于图的创新流程实现大规模点云的端到端处理。该方法通过专用图操作（如路径提取和拓扑抽象）无缝集成树木分割、叶木分离和3D骨架重建。研究在不同叶况（有叶和无叶）、空间尺度（单树和林分）和数据源（TLS和无人机激光扫描ULS）的数据集上进行了全面验证。实验结果表明，该方法在挑战性条件下表现优异，尤其在有叶场景（相对误差约20%）和低密度ULS数据（相对误差约30%）中。这些发现表明，该框架为大规模无损AGB估算提供了稳健且可扩展的解决方案，显著减少了对专用预处理工具的依赖，并确立了ULS作为TLS的可行替代方案。据我们所知，这是首个能够在操作尺度上实现无缝端到端3D树木重建的方法。这一进展显著提升了基于QSM的AGB估算的可行性，为森林调查和气候变化研究中的广泛应用铺平了道路。

</details>


### [107] [One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution](https://arxiv.org/abs/2506.15591)
**中文标题：一步扩散实现细节丰富且时间一致的视频超分辨率**

*Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于稳定扩散（SD）的双LoRA学习（DLoRAL）方法，通过交叉帧检索（CFR）和一致性学习（C-LoRA）模块，在保持时间一致性的同时增强视频细节，实现高效高质量的视频超分辨率。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于SD的真实视频超分辨率（Real-VSR）方法常在时间一致性和空间细节之间妥协，导致视觉质量不佳。本文旨在解决如何在提取低质量视频的鲁棒时间一致性先验的同时，增强视频细节并保持一致性。

研究方法: 提出双LoRA学习（DLoRAL）范式，包括交叉帧检索（CFR）模块和一致性学习（C-LoRA）模块，通过交替优化学习时间一致性和细节增强（D-LoRA）。推理时合并两个LoRA分支，实现单步扩散的高效视频恢复。

研究结果: 实验表明，DLoRAL在准确性和速度上均表现优异，能够同时实现时间一致性和丰富的空间细节。

研究结论: DLoRAL通过双LoRA学习和交替优化，成功解决了真实视频超分辨率中时间一致性与细节增强的平衡问题，为高效高质量视频恢复提供了新思路。

中文摘要: 在真实视频超分辨率（Real-VSR）中，如何在利用预训练生成模型（如稳定扩散）合成逼真细节的同时保持时间一致性是一个具有挑战性的问题。现有基于SD的Real-VSR方法常因牺牲空间细节以换取时间一致性而导致视觉质量不佳。本文认为关键在于如何从低质量（LQ）输入视频中有效提取抗退化的时间一致性先验，并在增强视频细节的同时保持这些先验。为此，我们提出了一种双LoRA学习（DLoRAL）范式，训练基于SD的一步扩散模型，同时实现逼真的帧细节和时间一致性。具体而言，我们引入交叉帧检索（CFR）模块以聚合跨帧的互补信息，并训练一致性LoRA（C-LoRA）从退化输入中学习鲁棒的时间表示。完成一致性学习后，固定CFR和C-LoRA模块，训练细节LoRA（D-LoRA）以增强空间细节，同时与C-LoRA定义的时间空间对齐以保持时间一致性。两阶段交替迭代优化，共同输出一致且细节丰富的结果。推理时，两个LoRA分支合并到SD模型中，实现单步扩散的高效高质量视频恢复。实验表明，DLoRAL在准确性和速度上均表现优异。代码和模型见https://github.com/yjsunnn/DLoRAL。

</details>


### [108] [Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration](https://arxiv.org/abs/2506.15596)
**中文标题：极端异质性多模态医学图像配准的单模态化方法**

*Kyobin Choo,Hyunkyung Han,Jinyeong Kim,Chanyong Yoon,Seong Jae Hwang*

主要分类: cs.CV

摘要简述: 本文提出M2M-Reg框架，通过单模态相似性训练多模态图像配准模型，解决极端异质性多模态医学图像配准问题，并在实验中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 临床实践中，功能型成像模态（如PET、FA）常需与结构型参考（如MRI、CT）对齐，但传统无监督配准方法因模态差异大而难以学习可靠空间映射，导致图像失真。

研究方法: 提出M2M-Reg框架，仅使用单模态相似性训练多模态配准模型，并引入GradCyCon正则化器以促进微分同胚。框架还支持半监督设置，无需真实变换或分割掩码。

研究结果: 在ADNI数据集上，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法高2倍，证明了其在极端异质性多模态配准中的有效性。

研究结论: M2M-Reg通过单模态相似性训练多模态配准模型，显著提升了极端异质性多模态医学图像配准的性能，且易于与现有模型集成。

中文摘要: 在临床实践中，具有功能特性的成像模态（如正电子发射断层扫描PET和分数各向异性FA）通常需要与结构参考（如MRI、CT）对齐以实现准确解释或群体分析，这需要多模态可变形图像配准（DIR）。然而，由于这些模态与标准结构扫描的极端异质性，传统的无监督DIR方法难以学习可靠的空间映射，并经常导致图像失真。我们发现，指导这些模型的相似性度量无法捕捉高度差异模态之间的对齐。为解决这一问题，我们提出了M2M-Reg（多到单配准），一种新颖的框架，仅使用单模态相似性训练多模态DIR模型，同时保留既定的架构范式，以便无缝集成到现有模型中。我们还引入了GradCyCon，一种利用M2M-Reg循环训练方案的正则化器，以促进微分同胚。此外，我们的框架自然扩展到半监督设置，仅集成预对齐和未对齐的对，无需真实变换或分割掩码。在阿尔茨海默病神经影像学倡议（ADNI）数据集上的实验表明，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法高2倍，突显了其在处理高度异质性多模态DIR中的有效性。我们的代码可在https://github.com/MICV-yonsei/M2M-Reg获取。

</details>


### [109] [BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion](https://arxiv.org/abs/2506.15610)
**中文标题：BoxFusion：基于实时多视角框融合的无重建开放词汇3D目标检测**

*Yuqing Lan,Chenyang Zhu,Zhirui Gao,Jiazhao Zhang,Yihan Cao,Renjiao Yi,Yijie Wang,Kai Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种无需点云重建的实时多视角框融合方法BoxFusion，用于开放词汇3D目标检测，显著降低了计算和内存开销，并在多个数据集上实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D目标检测方法通常依赖密集点云重建，导致计算和内存开销巨大，难以实时部署。本文旨在解决这一问题，提出一种无需重建的高效实时检测框架。

研究方法: 方法包括：1) 使用预训练视觉基础模型Cubify Anything进行单视角3D目标检测；2) 结合CLIP捕获开放词汇语义；3) 通过关联模块和优化模块融合多视角检测框，其中关联模块使用3D NMS和框匹配，优化模块采用基于粒子滤波的IoU引导随机优化技术。

研究结果: 在ScanNetV2和CA-1M数据集上的实验表明，该方法在在线方法中达到了最先进的性能，并在超过1000平方米的环境中实现了实时感知。

研究结论: BoxFusion通过无需重建的范式实现了高效、实时的开放词汇3D目标检测，具有广泛的泛化能力，适用于大规模场景。

中文摘要: 开放词汇3D目标检测因其在自动驾驶和具身AI中的关键应用而备受关注。现有检测方法（无论是离线还是在线）通常依赖密集点云重建，导致巨大的计算开销和内存限制，阻碍了在下游任务中的实时部署。为此，我们提出了一种新颖的无重建在线框架，专为内存高效和实时的3D检测设计。具体而言，给定流式姿态RGB-D视频输入，我们利用预训练的视觉基础模型Cubify Anything进行单视角3D目标检测（通过边界框），并结合CLIP捕获检测对象的开放词汇语义。为了将不同视角检测到的边界框融合为统一的边界框，我们采用关联模块处理多视角对应关系，并使用优化模块融合多视角预测的同一实例的3D边界框。关联模块利用3D非极大值抑制（NMS）和框对应匹配模块，而优化模块采用基于粒子滤波的IoU引导高效随机优化技术，以在最小化计算复杂度的同时强制多视角3D边界框的一致性。在ScanNetV2和CA-1M数据集上的大量实验表明，我们的方法在在线方法中达到了最先进的性能。得益于这种新颖的无重建3D目标检测范式，我们的方法在多种场景中表现出强大的泛化能力，即使在超过1000平方米的环境中也能实现实时感知。

</details>


### [110] [HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization](https://arxiv.org/abs/2506.15625)
**中文标题：HOIDiNi：通过扩散噪声优化实现人-物交互**

*Roey Ron,Guy Tevet,Haim Sawdayee,Amit H. Bermano*

主要分类: cs.CV

摘要简述: HOIDiNi是一种基于扩散噪声优化的文本驱动框架，用于生成真实且合理的人-物交互（HOI）。通过将问题分解为对象中心阶段和人体中心阶段，该方法在保持运动自然性的同时实现了精确的手-物接触。实验表明，HOIDiNi在接触准确性、物理有效性和整体质量上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 人-物交互（HOI）生成具有挑战性，因为它需要严格的接触准确性和多样的运动多样性。现有方法通常在真实性和物理正确性之间权衡，而HOIDiNi旨在通过优化扩散噪声空间同时实现两者。

研究方法: HOIDiNi采用扩散噪声优化（DNO）方法，将问题分为两个阶段：对象中心阶段（选择手-物接触位置）和人体中心阶段（优化全身运动以实现接触）。这种结构化方法确保了精确的接触和自然的运动。

研究结果: 在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触准确性、物理有效性和整体质量上优于现有方法和基线。该方法能够生成复杂的、可控的交互，如抓取、放置和全身协调。

研究结论: HOIDiNi通过扩散噪声优化和分阶段处理，成功生成了高质量的人-物交互，展示了其在复杂交互生成中的潜力。

中文摘要: 我们提出了HOIDiNi，一种基于文本驱动的扩散框架，用于合成真实且合理的人-物交互（HOI）。HOI生成极具挑战性，因为它需要严格的接触准确性和多样的运动多样性。现有方法通常在真实性和物理正确性之间权衡，而HOIDiNi通过扩散噪声优化（DNO）直接在预训练扩散模型的噪声空间中进行优化，同时实现了两者。这得益于我们将问题分为两个阶段：对象中心阶段（主要选择手-物接触位置）和人体中心阶段（优化全身运动以实现接触）。这种结构化方法在保持运动自然性的同时实现了精确的手-物接触。在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触准确性、物理有效性和整体质量上优于现有方法和基线。我们的结果表明，该方法能够生成复杂的、可控的交互，包括抓取、放置和全身协调，且仅由文本提示驱动。

</details>


### [111] [FindingDory: A Benchmark to Evaluate Memory in Embodied Agents](https://arxiv.org/abs/2506.15635)
**中文标题：FindingDory：评估具身智能体记忆能力的基准**

*Karmesh Yadav,Yusuf Ali,Gunshi Gupta,Yarin Gal,Zsolt Kira*

主要分类: cs.CV

摘要简述: 本文提出了一个名为FindingDory的新基准测试，用于评估具身智能体在长期记忆任务中的表现，填补了现有长视频问答基准在具身环境中的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大规模视觉语言模型在规划和控制任务中表现出色，但在具身环境中处理长期记忆（如多日积累的图像数据）时效率不足。现有基准测试忽视了具身任务中的低层技能需求，因此需要一个新的基准来专门评估记忆能力。

研究方法: 研究团队在Habitat模拟器中设计了一个包含60项任务的基准测试，这些任务需要持续的上下文感知和记忆能力。任务可扩展为更复杂的版本，以支持对记忆和推理能力的可扩展评估。同时，团队还整合了先进的视觉语言模型和低层导航策略作为基线。

研究结果: 基准测试展示了视觉语言模型在记忆密集型任务中的表现，并指出了需要改进的领域。任务的可扩展性为未来研究提供了灵活性。

研究结论: FindingDory基准填补了具身智能体长期记忆评估的空白，为未来研究提供了工具和方向。

中文摘要: 大规模视觉语言模型最近在规划和控制任务中表现出色，引发了将其应用于真实机器人技术的兴趣。然而，这些模型在具身环境中进行推理的能力受限于其处理长期经验（如多日积累的大量图像）的效率。当前视觉语言模型通常难以同时处理超过几百张图像，凸显了需要更高效的机制来处理具身环境中的长期记忆。为了有效评估这些模型在长期控制任务中的表现，需要一个专门针对记忆关键场景的基准。现有的长视频问答基准忽视了具身任务中的低层技能需求（如物体操作和导航），这些任务需要对过去交互进行细粒度推理。此外，具身智能体中的有效记忆整合不仅需要回忆相关信息，还需基于这些信息执行动作，因此需要将这两方面结合起来研究。本文在Habitat模拟器中引入了一个新的长期具身任务基准，评估了60项需要持续参与和上下文感知的任务中的记忆能力。这些任务还可通过程序扩展为更长和更具挑战性的版本，支持对记忆和推理能力的可扩展评估。我们还提出了整合先进视觉语言模型和低层导航策略的基线，评估了它们在记忆密集型任务中的表现，并指出了改进方向。

</details>


### [112] [Demystifying the Visual Quality Paradox in Multimodal Large Language Models](https://arxiv.org/abs/2506.15645)
**中文标题：揭秘多模态大语言模型中的视觉质量悖论**

*Shuo Xing,Lanqing Guo,Hongyuan Hua,Seoyoung Lee,Peiran Li,Yufei Wang,Zhangyang Wang,Zhengzhong Tu*

主要分类: cs.CV

摘要简述: 研究发现多模态大语言模型（MLLMs）在视觉质量上存在悖论：图像偏离人类感知的高保真度时，模型表现反而更好。为此，作者提出了一种轻量级适配模块VQ-TTT，动态调整输入图像以提升任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在视觉语言任务中表现出色，但输入图像的视觉质量如何影响其响应尚不明确。作者旨在探究图像质量对MLLMs性能的影响，并解决模型偏好与人类感知之间的差异。

研究方法: 作者通过系统研究，对领先的MLLMs和视觉语言基准进行实验，应用可控的图像退化和风格变化。为解决模型偏好问题，提出VQ-TTT模块：在冻结的视觉编码器前插入可学习的低秩核以调整频率内容，并通过LoRA微调浅层视觉编码器。

研究结果: 实验发现，图像质量与模型性能之间存在悖论：偏离人类感知的高保真度图像可能提升模型表现。VQ-TTT在所有数据集和MLLMs中显著提升平均准确率，无需外部模型或额外训练数据。

研究结论: 研究重新定义了MLLMs的“更好”视觉输入，强调需要自适应而非普遍“干净”的图像。VQ-TTT为动态调整输入图像提供了有效解决方案，适应了AI作为主要数据用户的新时代需求。

中文摘要: 近年来，多模态大语言模型（MLLMs）在视觉语言基准任务中表现优异，但输入图像的视觉质量如何影响其响应尚不明确。更高的图像感知质量是否直接转化为更好的MLLM理解？我们对领先的MLLMs和一系列视觉语言基准进行了首次系统研究，对每张图像应用了可控的退化和风格变化。令人惊讶的是，我们发现了一个视觉质量悖论：当图像偏离人类感知的高保真度时，模型、任务甚至单个实例的性能可能提升。现成的修复流程无法调和这些独特偏好。为弥合这一差距，我们提出了视觉质量测试时调优（VQ-TTT）——一种轻量级适配模块：（1）在冻结的视觉编码器前插入可学习的低秩核以调整频率内容；（2）通过LoRA仅微调浅层视觉编码器。VQ-TTT在单次前向传播中动态调整每张输入图像，使其与任务特定的模型偏好对齐。在所有评估的MLLMs和数据集中，VQ-TTT显著提升了平均准确率，且无需外部模型、缓存特征或额外训练数据。这些发现重新定义了MLLMs的“更好”视觉输入，并强调了在新一代AI作为主要数据用户的时代，需要自适应而非普遍“干净”的图像。

</details>


### [113] [Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning](https://arxiv.org/abs/2506.15649)
**中文标题：基于边际奖励调整的双阶段价值引导推理：快速且可靠的视觉语言模型字幕生成**

*Ankan Deria,Adinath Madhavrao Dukre,Feilong Tang,Sara Atito,Sudipta Roy,Muhammad Awais,Muhammad Haris Khan,Imran Razzak*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViMaR的双阶段推理框架，通过结合时间差分价值模型和基于边际的奖励调整，显著提升了视觉语言模型（VLM）生成字幕的效率和质量。实验表明，ViMaR在生成更可靠、准确且详细字幕的同时，速度提升了4倍以上，并展示了跨模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型（VLM）推理方法存在计算成本高和生成低置信度内容的问题，容易导致幻觉现象。本文旨在提出一种高效且可靠的推理框架，以提升字幕生成的准确性和效率。

研究方法: ViMaR采用双阶段推理框架：第一阶段通过单次推理从多样候选字幕中选出最高价值的内容；第二阶段仅对视觉基础薄弱或被忽略的片段进行选择性优化。此外，通过基于边际的惩罚机制抑制低置信度生成，同时保留描述的丰富性。

研究结果: 实验表明，ViMaR生成的字幕在可靠性、事实准确性、细节丰富性和解释性上显著优于现有方法，速度提升4倍以上。此外，ViMaR在跨模型泛化测试中表现优异，能够有效指导未见过的更强模型生成高质量字幕。

研究结论: ViMaR作为一种高效、可扩展的推理时解码策略，不仅显著提升了字幕生成的质量和速度，还展示了跨模型泛化的潜力。其生成的优质字幕还可用于自训练，进一步提升模型的视觉理解能力。

中文摘要: 尽管视觉语言模型（VLM）在推理时搜索方面取得了显著进展，但现有方法仍存在计算成本高和生成低置信度内容的问题，容易导致幻觉现象。我们提出了基于边际奖励调整的价值引导推理框架（ViMaR），该框架通过结合时间差分价值模型和基于边际的奖励调整，显著提升了字幕生成的效率和质量。ViMaR分为两个阶段：第一阶段通过单次推理从多样候选字幕中选出最高价值的内容；第二阶段仅对视觉基础薄弱或被忽略的片段进行选择性优化。通过基于边际的惩罚机制，ViMaR能够抑制低置信度生成，同时保留描述的丰富性。在多种VLM架构上的实验表明，ViMaR生成的字幕在可靠性、事实准确性、细节丰富性和解释性上显著优于现有方法，速度提升4倍以上。此外，ViMaR在跨模型泛化测试中表现优异，能够有效指导未见过的更强模型生成高质量字幕。ViMaR的灵活性和模块化设计使其成为一种可扩展且可迁移的推理时解码策略。进一步实验表明，使用ViMaR生成的字幕进行自训练，可以显著提升模型在视觉理解任务中的表现，展示了快速、准确且自我改进的VLM管道的潜力。

</details>


### [114] [UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting](https://arxiv.org/abs/2506.15673)
**中文标题：UniRelight：学习联合分解与合成以实现视频重光照**

*Kai He,Ruofan Liang,Jacob Munkberg,Jon Hasselgren,Nandita Vijaykumar,Alexander Keller,Sanja Fidler,Igor Gilitschenski,Zan Gojcic,Zian Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种联合分解与合成的视频重光照方法UniRelight，通过单次处理同时估计反照率并生成重光照效果，利用视频扩散模型的生成能力，显著提升了光照效果和材质交互的真实性。


<details>
  <summary>详细信息</summary>
研究动机: 现有端到端重光照模型因多光照配对数据稀缺而泛化能力受限，而两阶段渲染流程易产生误差累积且难以处理复杂光照或材质。本文旨在通过联合估计与合成解决这些问题。

研究方法: 提出一种通用方法，联合估计反照率并合成重光照效果，利用视频扩散模型生成能力，结合合成多光照数据和自动标注的真实视频进行训练。

研究结果: 模型在多样场景中表现出强泛化能力，在视觉真实性和时间一致性上优于现有方法。

研究结论: UniRelight通过联合分解与合成，显著提升了重光照任务的真实性和泛化能力，为复杂光照和材质交互提供了有效解决方案。

中文摘要: 我们解决了单张图像或视频重光照的挑战，这一任务需要精确的场景内在理解和高品质的光传输合成。现有的端到端重光照模型常因多光照配对数据稀缺而泛化能力受限。相反，结合逆向和正向渲染的两阶段流程虽能缓解数据需求，但易受误差累积影响，且在复杂光照或高级材质下难以生成真实输出。本文提出了一种通用方法，通过单次处理联合估计反照率并合成重光照效果，利用视频扩散模型的生成能力。这种联合形式增强了隐式场景理解，并促进了真实光照效果（如阴影、反射和透明度）和复杂材质交互的生成。通过在合成多光照数据和大量自动标注的真实视频上训练，我们的模型在多样领域中表现出强泛化能力，并在视觉真实性和时间一致性上超越了先前方法。

</details>


### [115] [Sekai: A Video Dataset towards World Exploration](https://arxiv.org/abs/2506.15675)
**中文标题：Sekai：面向世界探索的视频数据集**

*Zhen Li,Chuanhao Li,Xiaofeng Mao,Shaoheng Lin,Ming Li,Shitian Zhao,Zhaopan Xu,Xinyue Li,Yukang Feng,Jianwen Sun,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Zhixiang Wang,Yuwei Wu,Tong He,Jiangmiao Pang,Yu Qiao,Yunde Jia,Kaipeng Zhang*

主要分类: cs.CV

摘要简述: 本文介绍了Sekai数据集，一个高质量的第一人称视角全球视频数据集，专为世界探索任务设计，包含丰富注释和多样化场景。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频生成数据集在支持世界探索任务时存在局限性，如场景单一、时长短、缺乏注释等。为填补这一空白，作者提出了Sekai数据集。

研究方法: 作者收集了来自100多个国家和地区的5000多小时第一人称和无人机视角视频，并开发了高效工具箱进行预处理和注释（如位置、天气、人群密度等）。

研究结果: 实验验证了数据集的质量，并利用其子集训练了交互式视频世界探索模型YUME。

研究结论: Sekai数据集将为视频生成和世界探索领域带来重要价值，并推动相关应用发展。

中文摘要: 视频生成技术取得了显著进展，有望成为交互式世界探索的基础。然而，现有的视频生成数据集因场景有限、时长较短、画面静态以及缺乏探索和世界相关注释，并不适合用于世界探索任务的训练。本文介绍了Sekai（日语中意为“世界”），这是一个高质量的第一人称视角全球视频数据集，包含丰富的世界探索注释。该数据集包含来自100多个国家和地区的750个城市的5000多小时步行或无人机视角（FPV和UVA）视频。我们开发了一个高效且实用的工具箱，用于收集、预处理和注释视频，包括位置、场景、天气、人群密度、字幕和相机轨迹。实验验证了数据集的质量。此外，我们利用其子集训练了一个交互式视频世界探索模型YUME（日语中意为“梦想”）。我们相信Sekai将为视频生成和世界探索领域带来益处，并激发有价值的应用。

</details>


### [116] [Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model](https://arxiv.org/abs/2506.15682)
**中文标题：进化缓存加速现成扩散模型**

*Anirud Aggarwal,Abhinav Shrivastava,Matthew Gwilliam*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ECAD的遗传算法，通过学习高效的缓存调度策略，显著加速扩散模型的推理速度，同时保持生成质量，适用于多种模型和分辨率。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成高质量图像时存在推理速度慢和计算成本高的问题。现有方法依赖固定启发式规则，导致加速效果有限或泛化能力差。本文旨在通过智能缓存调度解决这些问题。

研究方法: ECAD是一种遗传算法，通过少量校准提示学习针对特定模型的高效缓存调度策略，形成帕累托前沿。该方法无需修改网络参数或参考图像，支持对质量与延迟的精细控制。

研究结果: 实验表明，ECAD在PixArt-alpha等模型上显著提升推理速度（从2.35倍到2.58倍），并在COCO FID等指标上优于现有方法（提升4.47分）。其学习到的调度策略还能泛化到未见过的分辨率和模型变体。

研究结论: ECAD是一种可扩展且泛化能力强的扩散模型加速方法，能够灵活平衡生成质量与推理速度，适用于多种场景。

中文摘要: 基于扩散的图像生成模型在生成高质量合成内容方面表现出色，但存在推理速度慢和计算成本高的问题。先前的研究尝试通过在扩散变换器中缓存和重用特征来缓解这一问题，但这些方法通常依赖固定启发式规则，导致加速效果有限或泛化能力差。我们提出了进化缓存加速扩散模型（ECAD），这是一种遗传算法，仅使用少量校准提示即可学习高效的、针对特定模型的缓存调度策略，形成帕累托前沿。ECAD无需修改网络参数或参考图像，能够显著提升推理速度，支持对质量与延迟的精细控制，并能无缝适应不同的扩散模型。值得注意的是，ECAD学习到的调度策略能够有效泛化到校准过程中未见过的分辨率和模型变体。我们在PixArt-alpha、PixArt-Sigma和FLUX-1.dev上评估了ECAD，使用多种指标（FID、CLIP、Image Reward）和多样化的基准测试（COCO、MJHQ-30k、PartiPrompts），结果表明ECAD在各方面均优于先前的方法。在PixArt-alpha上，ECAD找到的调度策略在COCO FID上比现有最优方法提升了4.47分，同时将推理加速从2.35倍提升到2.58倍。我们的研究结果表明，ECAD是一种可扩展且泛化能力强的扩散模型加速方法。项目网站和代码已公开。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [117] [CALM: Contextual Analog Logic with Multimodality](https://arxiv.org/abs/2506.14936)
**中文标题：CALM：基于多模态的上下文模拟逻辑**

*Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue*

主要分类: cs.AI

摘要简述: CALM（上下文模拟逻辑与多模态）结合符号推理与神经生成，通过多模态数据实现上下文敏感决策，填补逻辑与神经感知之间的鸿沟。


<details>
  <summary>详细信息</summary>
研究动机: 传统二值逻辑系统无法捕捉人类决策的细微差别，且在多模态环境中依赖人工标注，显得僵化且脆弱。神经网络虽擅长从多模态数据中提取丰富信息，但缺乏可解释的推理结构。CALM旨在结合逻辑的精确性与神经网络的多模态处理能力。

研究方法: CALM通过领域树表示每个谓词，利用神经网络迭代优化其模拟真值，并通过符号推理模块确保约束满足。神经网络的预测基于多模态信息，同时满足逻辑约束。

研究结果: 在填空式物体放置任务中，CALM以92.2%的准确率超越经典逻辑（86.3%）和LLM（59.4%）。其生成的空间热图与逻辑约束和人类偏好高度一致。

研究结论: CALM展示了在多模态环境中结合逻辑结构与偏好的潜力，为下一代AI系统奠定了基础，兼具逻辑的精确性与神经网络的多模态处理能力。

中文摘要: 本文介绍了基于多模态的上下文模拟逻辑（CALM），它将符号推理与神经生成相结合，使系统能够基于真实世界的多模态数据做出上下文敏感的决策。
背景：传统的二值逻辑系统无法捕捉人类决策的细微差别，且在多模态环境中需要人工标注，显得僵化且脆弱。神经网络擅长从多模态数据中提取丰富的上下文信息，但缺乏可解释的推理结构。
目标：CALM旨在填补逻辑与神经感知之间的鸿沟，创建一种能够对多模态输入进行推理的模拟逻辑。缺乏这种整合的AI系统要么脆弱，要么缺乏结构，无法稳健地泛化到现实任务中。在CALM中，符号谓词通过神经网络和约束搜索计算模拟真值。
方法：CALM使用领域树表示每个谓词，当其实体的上下文基础确定时，通过神经网络迭代优化其模拟真值。神经网络的预测基于多模态信息，并通过符号推理模块过滤以确保约束满足。
结果：在填空式物体放置任务中，CALM以92.2%的准确率超越经典逻辑（86.3%）和LLM（59.4%）。其生成的空间热图与逻辑约束和人类偏好高度一致，并通过人类研究验证。
结论：CALM展示了在多模态环境中结合逻辑结构与偏好的潜力，为下一代AI系统奠定了基础，兼具逻辑的精确性与神经网络的多模态处理能力。

</details>


### [118] [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.14990)
**中文标题：MEAL：持续多智能体强化学习的基准**

*Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy*

主要分类: cs.AI

摘要简述: 本文提出了首个针对持续多智能体强化学习（CMARL）的基准MEAL，通过GPU加速支持长任务序列，并揭示了现有方法在复杂环境中的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前持续学习（CL）与多智能体强化学习（MARL）的结合研究不足，缺乏专用基准，限制了算法开发与分析。本文旨在填补这一空白。

研究方法: MEAL利用JAX实现GPU加速，支持在标准台式机上快速运行100个任务的序列，并通过消融研究分析关键架构与算法特征。

研究结果: 实验表明，现有CL与MARL方法的简单组合在简单环境中表现良好，但在需要持续协调的复杂环境中失效。

研究结论: MEAL为CMARL研究提供了首个高效基准，并揭示了未来算法改进的方向。

中文摘要: 基准在强化学习（RL）算法的发展与分析中至关重要，而环境的可用性直接影响研究进展。持续学习（CL）与多智能体协作的结合尤其缺乏探索。为此，我们提出了MEAL（多智能体自适应学习环境），这是首个专为持续多智能体强化学习（CMARL）设计的基准。现有CL基准在CPU上运行环境，导致计算瓶颈并限制任务序列长度。MEAL利用JAX实现GPU加速，可在标准台式机上几小时内完成100个任务的持续学习。我们发现，简单结合流行的CL与MARL方法在简单环境中表现优异，但在需要持续协调与适应的复杂环境中失效。消融研究揭示了MEAL上CMARL的关键架构与算法特征。

</details>


### [119] [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050)
**中文标题：截断近端策略优化**

*Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu*

主要分类: cs.AI

摘要简述: 本文提出了一种名为截断近端策略优化（T-PPO）的新方法，旨在提升大型语言模型（LLM）在长链推理任务中的训练效率。通过优化策略更新和限制生成长度，T-PPO显著减少了硬件闲置时间，并引入扩展广义优势估计（EGAE）和独立优化机制，最终在AIME 2024实验中实现了2.5倍的效率提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前，近端策略优化（PPO）及其变体在训练大型语言模型（LLM）时，由于同步生成长响应导致硬件利用率低，训练效率低下。本文旨在解决这一问题，提出一种更高效的训练方法。

研究方法: 1. 提出扩展广义优势估计（EGAE），从不完整响应中估计优势值，确保策略学习的完整性。2. 设计独立优化机制，通过选择性过滤提示和截断标记，减少冗余计算，加速训练过程。

研究结果: 在AIME 2024实验中，T-PPO将推理型LLM的训练效率提升了2.5倍，且性能优于现有方法。

研究结论: T-PPO通过优化策略更新和生成长度限制，显著提升了训练效率，同时保持了收敛性能，为大型语言模型的训练提供了更高效的解决方案。

中文摘要: 近年来，通过生成长链推理（CoT），测试时扩展的大型语言模型（LLM）在科学和专业任务中展现出卓越的推理能力。作为开发这些推理模型的关键组成部分，强化学习（RL）以近端策略优化（PPO）及其变体为代表，使模型能够通过试错学习。然而，PPO由于其固有的在线策略性质，训练时间较长，而响应长度的增加进一步加剧了这一问题。本文提出截断近端策略优化（T-PPO），这是一种对PPO的新扩展，通过优化策略更新和限制生成长度来提升训练效率。T-PPO解决了完全同步长生成过程中硬件利用率低的问题，避免了资源在等待完整生成时的闲置。我们的贡献包括：1. 提出扩展广义优势估计（EGAE），从不完整响应中估计优势值，同时保持策略学习的完整性；2. 设计了一种计算优化的机制，允许策略模型和价值模型独立优化。通过选择性过滤提示和截断标记，该机制减少了冗余计算，在不影响收敛性能的情况下加速了训练过程。我们在AIME 2024上使用32B基础模型验证了T-PPO的有效性和高效性。实验结果表明，T-PPO将推理型LLM的训练效率提升了2.5倍，并优于现有竞争对手。

</details>


### [120] [HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges](https://arxiv.org/abs/2506.15196)
**中文标题：HeurAgenix：利用大语言模型解决复杂组合优化挑战**

*Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian*

主要分类: cs.AI

摘要简述: HeurAgenix是一个基于大语言模型（LLM）的两阶段超启发式框架，通过进化启发式策略并动态选择最优解，显著提升组合优化问题的求解能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统启发式算法依赖人工设计且难以泛化，而现有基于LLM的方法在组合优化问题中表现有限。HeurAgenix旨在通过LLM自动进化与选择启发式策略，解决复杂优化问题。

研究方法: HeurAgenix分为两阶段：1）利用LLM比较种子解与高质量解，提取可复用的进化策略；2）动态选择最优启发式策略，支持使用高性能LLM或轻量级微调模型。通过双奖励机制缓解监督数据稀缺问题。

研究结果: 实验表明，HeurAgenix不仅优于现有基于LLM的超启发式方法，还能媲美或超越专业求解器。

研究结论: HeurAgenix展示了LLM在组合优化中的潜力，通过自动进化与选择启发式策略，为复杂问题提供了高效解决方案。

中文摘要: 启发式算法在解决组合优化（CO）问题中至关重要，但传统设计依赖人工经验且难以泛化。本文提出HeurAgenix，一种基于大语言模型（LLM）的两阶段超启发式框架，首先生成启发式策略，随后自动选择最优解。在启发式进化阶段，HeurAgenix利用LLM比较种子解与高质量解，提取可复用的进化策略；在求解阶段，动态选择最优启发式策略，支持高性能LLM或轻量级微调模型。为缓解CO复杂性导致的监督数据稀缺问题，采用双奖励机制微调轻量级选择器，结合选择偏好与状态感知信号，实现鲁棒选择。实验表明，HeurAgenix不仅优于现有基于LLM的超启发式方法，还能媲美或超越专业求解器。代码已开源：https://github.com/microsoft/HeurAgenix。

</details>


### [121] [Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study](https://arxiv.org/abs/2506.15207)
**中文标题：多智能体强化学习在自主多卫星地球观测中的应用：一个真实案例研究**

*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk*

主要分类: cs.AI

摘要简述: 本文研究了基于多智能体强化学习（MARL）的多卫星地球观测自主协调问题，通过模拟真实卫星环境验证了多种MARL算法的性能，结果表明MARL能有效平衡成像与资源管理，为分散式卫星任务提供了实用指南。


<details>
  <summary>详细信息</summary>
研究动机: 随着低地球轨道卫星数量的激增，地球观测任务面临实时决策和自主协调的挑战。传统优化方法难以应对动态任务需求，因此需要探索强化学习和多智能体强化学习的应用。

研究方法: 研究通过建模单卫星操作并扩展到多卫星星座，利用MARL框架（如PPO、IPPO、MAPPO和HAPPO）解决能源、数据存储限制及部分可观测性下的分散协调问题，并在近真实卫星模拟环境中评估算法性能。

研究结果: 实验表明，MARL能有效平衡成像任务与资源管理，同时解决了多卫星协调中的非平稳性和奖励依赖性问题，为自主卫星操作提供了实用解决方案。

研究结论: 本研究为分散式地球观测任务的策略学习提供了基础，展示了MARL在多卫星自主协调中的潜力，并为未来卫星任务的实际应用提供了指导。

中文摘要: 低地球轨道（LEO）卫星的指数级增长彻底改变了地球观测（EO）任务，解决了气候监测、灾害管理等领域的挑战。然而，多卫星系统的自主协调仍是一个基本难题。传统优化方法难以满足动态EO任务的实时决策需求，因此需要借助强化学习（RL）和多智能体强化学习（MARL）。本文通过建模单卫星操作并扩展到多卫星星座，利用MARL框架研究了基于RL的自主EO任务规划。我们解决了能源和数据存储限制、卫星观测的不确定性以及部分可观测性下的分散协调复杂性等关键问题。通过利用接近真实的卫星模拟环境，我们评估了包括PPO、IPPO、MAPPO和HAPPO在内的先进MARL算法的训练稳定性和性能。结果表明，MARL能有效平衡成像与资源管理，同时解决了多卫星协调中的非平稳性和奖励依赖性问题。本研究的发现为自主卫星操作奠定了基础，并为分散式EO任务的策略学习提供了实用指南。

</details>


### [122] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
**中文标题：基于无人机与船舶协作的不确定海上边缘计算联合计算卸载与资源分配**

*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

主要分类: cs.AI

摘要简述: 本文提出了一种基于无人机和船舶协作的海上边缘计算框架，通过Lyapunov优化和马尔可夫博弈解决不确定任务下的计算卸载和资源分配问题，有效降低了总执行时间。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，海上物联网（MIoT）的计算需求快速增长，而无人机和船舶协作的边缘计算（MEC）可以满足这些需求。然而，不确定的海上任务带来了计算卸载和资源分配效率低下的挑战。

研究方法: 首先提出了一种协作MEC框架，结合MIoT设备、无人机和船舶。利用Lyapunov优化处理任务到达和资源可用性的不确定性，将长期约束转化为短期约束，并通过马尔可夫博弈和异构智能体软演员-评论家算法解决优化问题。

研究结果: 仿真实验验证了所提框架在计算卸载和资源分配方面的有效性，显著降低了总执行时间。

研究结论: 通过无人机和船舶的协作，结合Lyapunov优化和马尔可夫博弈，本文成功解决了不确定任务下的海上计算卸载和资源分配问题，为MIoT提供了高效解决方案。

中文摘要: 近年来，海上物联网（MIoT）的计算需求迅速增长，而基于无人机和船舶的多接入边缘计算（MEC）可以满足这些需求。然而，不确定的海上任务带来了计算卸载和资源分配效率低下的挑战。本文通过无人机和船舶的协作，研究了考虑不确定任务的海上计算卸载和资源分配问题。具体而言，我们提出了一种协作MEC框架，包括MIoT设备、无人机和船舶，并构建了以最小化总执行时间为目标的优化问题。针对不确定的MIoT任务，我们利用Lyapunov优化处理任务到达和计算资源可用性的不可预测性，将长期约束转化为短期约束，得到一组小规模优化问题。进一步，考虑到无人机和船舶动作与资源的异质性，我们将小规模优化问题重新表述为马尔可夫博弈（MG），并提出了一种异构智能体软演员-评论家算法，通过顺序更新多种神经网络有效解决MG问题。最后，通过仿真验证了所提方法在计算卸载和资源分配中的有效性。

</details>


### [123] [Efficient and Generalizable Environmental Understanding for Visual Navigation](https://arxiv.org/abs/2506.15377)
**中文标题：高效且泛化的环境理解在视觉导航中的应用**

*Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao*

主要分类: cs.AI

摘要简述: 本文提出了一种因果感知导航方法（CAN），通过引入因果理解模块提升智能体在视觉导航任务中的环境理解能力，实验证明其优于现有方法且具有泛化性。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉导航方法通常同时处理所有历史观测数据，忽略了数据内部的关联结构，限制了任务性能的进一步提升。本文从因果关系的角度分析导航任务的特点，提出改进方案。

研究方法: 提出因果感知导航（CAN），通过因果理解模块增强智能体的环境理解能力，利用因果关系优化历史数据的处理方式。

研究结果: 实验表明，CAN在多种任务和仿真环境中均优于基线方法，因果理解模块在强化学习和监督学习场景中均表现出泛化能力且无额外计算开销。

研究结论: 通过引入因果框架，CAN显著提升了视觉导航任务的性能，为智能体的环境理解提供了新思路。

中文摘要: 视觉导航是具身智能的核心任务，使智能体能够在复杂环境中导航以实现目标。在导航任务中，许多场景需要对历史时序数据进行建模。现有方法虽然表现良好，但通常同时处理所有历史观测数据，忽略了数据内部的关联结构，从而限制了任务性能的进一步提升。本文从因果关系的角度分析导航任务的独特特性，引入因果框架以揭示传统时序方法的局限性。基于此，我们提出因果感知导航（CAN），通过因果理解模块增强智能体的环境理解能力。实验评估表明，该方法在多种任务和仿真环境中均优于基线方法。大量消融实验证明，因果理解模块在强化学习和监督学习场景中均能有效泛化，且无需额外计算开销。

</details>


### [124] [Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](https://arxiv.org/abs/2506.15567)
**中文标题：基于LLM推理与行动代理的复杂失效分析工作流管理**

*Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer*

主要分类: cs.AI

摘要简述: 本文探讨了如何利用基于大型语言模型（LLM）的规划代理（LPA）来管理复杂的失效分析工作流，通过整合AI组件提升自动化能力，并验证了其在实际任务中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 失效分析（FA）是一个高度复杂且知识密集的过程，随着AI模型的增加，如何协调这些组件以形成高效的工作流成为挑战。本文旨在通过LLM技术解决这一问题。

研究方法: 提出了一种基于LLM的规划代理（LPA），结合高级规划能力和外部工具使用，实现复杂查询的自主处理、外部数据的检索以及生成人类可读的响应。

研究结果: 评估结果表明，LPA在支持失效分析任务中表现出操作有效性和可靠性。

研究结论: 基于LLM的规划代理能够有效管理复杂的失效分析工作流，为工程师提供高效支持。

中文摘要: 失效分析（FA）是一个高度复杂且知识密集的过程。在FA实验室的计算基础设施中集成AI组件，可以自动化多种任务，包括检测图像中的非一致性、从多样化数据源中检索类似案例，以及从标注图像生成报告。然而，随着部署的AI模型数量增加，如何将这些组件协调为高效且与FA流程无缝集成的工作流成为挑战。本文研究了基于大型语言模型（LLM）的规划代理（LPA）的设计与实现，以协助FA工程师解决分析案例。LPA将LLM与高级规划能力和外部工具使用相结合，能够自主处理复杂查询、从外部系统检索相关数据并生成人类可读的响应。评估结果证明了该代理在支持FA任务中的操作有效性和可靠性。

</details>


### [125] [The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games](https://arxiv.org/abs/2506.15624)
**中文标题：状态表示对LLM代理在动态路由游戏中行为的影响**

*Lyle Goodyear,Rachel Guo,Ramesh Johari*

主要分类: cs.AI

摘要简述: 本文提出了一种系统构建自然语言状态表示的框架，用于在重复多智能体游戏中提示LLM代理，并研究了状态表示对代理行为的影响。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究在LLM代理的游戏中采用临时方法编码游戏历史，不仅模糊了状态表示对代理行为的影响，还限制了研究间的可比性。本文旨在填补这一空白。

研究方法: 提出了一个框架，从三个维度描述状态表示方法：动作信息量、奖励信息量和提示风格。并将其应用于动态自私路由游戏中。

研究结果: 研究发现，提供总结的历史表示、后悔信息而非原始收益、以及有限的他人动作信息，能使LLM代理行为更接近博弈论均衡预测，且游戏更稳定。

研究结论: 状态表示对LLM代理行为有显著影响，特定表示方式能显著提升代理行为的均衡性和稳定性。

中文摘要: 大型语言模型（LLMs）在动态环境中作为决策者显示出潜力，但其无状态特性需要创建历史记录的自然语言表示。我们提出了一个统一的框架，用于系统构建自然语言“状态”表示，以在重复多智能体游戏中提示LLM代理。以往关于LLM代理游戏的研究采用临时方法编码游戏历史，这不仅模糊了状态表示对代理行为的影响，还限制了研究间的可比性。我们的框架通过从三个维度描述状态表示方法填补了这一空白：动作信息量（即状态表示捕捉已执行动作的程度）、奖励信息量（即状态表示描述获得奖励的程度）和提示风格（或自然语言压缩，即完整文本历史被总结的程度）。我们将此框架应用于动态自私路由游戏，选择该游戏是因为它在理论和人类实验中均存在简单均衡。尽管游戏相对简单，但我们发现LLM代理行为对自然语言状态表示存在关键依赖。具体而言，我们观察到，为代理提供（1）总结而非完整的历史自然语言表示；（2）关于后悔而非原始收益的信息；（3）有限的他人动作信息，能使行为更接近博弈论均衡预测，且代理的游戏过程更稳定。相比之下，其他表示方式可能导致与均衡的较大偏差、动态游戏过程中更高的变异性，或两者兼有。

</details>


### [126] [The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy](https://arxiv.org/abs/2506.15639)
**中文标题：AI政策模块：培养计算机科学学生在AI伦理与政策方面的能力**

*James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry*

主要分类: cs.AI

摘要简述: 本文介绍了一个AI政策模块，旨在帮助计算机科学学生提升对AI伦理与政策的理解，并通过实践任务增强其参与AI监管讨论的能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI技术的广泛应用，AI伦理和政策的重要性日益凸显，但现有计算机科学课程未能充分培养学生在这方面的能力。因此，作者开发了AI政策模块，以填补这一空白。

研究方法: 作者设计并更新了AI政策模块2.0，包括一个关于“AI监管”的技术任务，并通过前后问卷调查评估学生对AI伦理和政策的态度变化。

研究结果: 模块实施后，学生对AI技术伦理影响的关注度提升，同时对参与AI监管讨论的信心增强。AI监管任务被证明是探索AI对齐限制和强调政策作用的有效工具。

研究结论: AI政策模块成功提升了学生对AI伦理与政策的理解，为计算机科学课程中融入相关内容提供了可行方案。

中文摘要: 随着人工智能（AI）在个人和职业场景中的广泛应用，不仅需要关注AI伦理，还需通过AI政策对技术进行治理和监管。然而，当前的高等教育计算机课程未能充分培养未来AI从业者将抽象伦理原则和政策偏好转化为AI系统设计与开发的能力。我们认为，熟悉“AI政策领域”并将伦理原则转化为实践，将成为未来AI工程师的重要职责。

为帮助计算机科学（CS）学生应对这些新需求，我们开发了AI政策模块，将其引入CS课程。基于2024年秋季的成功试点，本文提出了更新扩展的模块版本，包括一项关于“AI监管”的技术任务。我们通过模块前后的问卷调查评估了学生对AI伦理与政策的态度变化。结果显示，模块实施后，学生对AI技术伦理影响的关注度提升，同时对参与AI监管讨论的信心增强。最后，我们强调AI监管任务是探索AI对齐限制和突出政策在解决伦理挑战中作用的有效工具。

</details>


### [127] [Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement](https://arxiv.org/abs/2506.15647)
**中文标题：探索与利用大型推理模型的固有效率以实现自我引导的效率提升**

*Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu*

主要分类: cs.AI

摘要简述: 本文探讨大型推理模型（LRMs）的效率问题，发现其存在过度思考现象，并提出两种轻量级方法（效率引导和自奖励效率强化学习）以提升模型效率，实验证明这些方法显著减少推理长度且不影响任务表现。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型在复杂问题解决中表现出色，但常因过度思考（生成冗余内容）导致效率低下和推理成本增加。本文旨在挖掘模型内在的简洁推理潜力，并提出方法以提升效率。

研究方法: 1. 效率引导：一种无需训练的激活引导技术，通过模型表示空间中的单一方向调节推理行为。2. 自奖励效率强化学习：动态平衡任务准确性和简洁性的强化学习框架，奖励简洁正确的解决方案。

研究结果: 在多个数学推理基准测试中，两种方法显著减少了推理长度，同时保持或提升了任务表现，验证了模型内在效率潜力的可挖掘性。

研究结论: 通过引导和利用模型的内在能力，可以显著提升推理效率，且无需牺牲任务性能。

中文摘要: 近年来，大型推理模型（LRMs）通过模拟人类深思熟虑的思维显著提升了语言模型在复杂问题解决中的能力。然而，这些模型常表现出过度思考（即生成不必要且冗余的内容），从而阻碍效率并增加推理成本。本研究探讨了这种低效的表征和行为根源，揭示LRMs天生具备更简洁推理的潜力。实证分析表明，正确的推理路径长度差异显著，而最短的正确响应通常足够，这表明存在未开发的效率潜力。基于这些发现，我们提出两种轻量级方法以提升LRM效率。首先，我们引入效率引导，这是一种无需训练的激活引导技术，通过模型表示空间中的单一方向调节推理行为。其次，我们开发了自奖励效率强化学习，这是一种动态平衡任务准确性和简洁性的强化学习框架，通过奖励简洁正确的解决方案。在多个数学推理基准测试中对七种LRM主干进行的广泛实验表明，我们的方法显著减少了推理长度，同时保持或提升了任务表现。结果表明，通过以自我引导的方式利用和引导现有模型的内在能力，可以提升推理效率。

</details>


### [128] [SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence](https://arxiv.org/abs/2506.15672)
**中文标题：SwarmAgentic：基于群体智能的全自动化智能体系统生成**

*Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp*

主要分类: cs.AI

摘要简述: SwarmAgentic提出了一种基于群体智能的全自动化多智能体系统生成框架，通过语言驱动探索和反馈引导优化，显著提升了任务执行和协作能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有智能体系统生成框架缺乏完全自主性，无法实现从零开始的智能体生成、自我优化功能及协作，限制了适应性和扩展性。SwarmAgentic旨在填补这一空白。

研究方法: SwarmAgentic通过语言驱动探索构建智能体系统，并利用群体智能（如粒子群优化）对系统级结构进行高效搜索，通过反馈引导更新优化智能体功能和协作。

研究结果: 在六项真实世界的开放任务中，SwarmAgentic仅需任务描述和目标函数即可显著优于基线方法，如在TravelPlanner任务中相对ADAS提升261.8%。

研究结论: SwarmAgentic为全自动化智能体系统设计提供了可扩展的解决方案，将群体智能与多智能体生成相结合，标志着该领域的重要进展。

中文摘要: 大型语言模型的快速发展推动了智能体系统在决策、协调和任务执行方面的进步。然而，现有的智能体系统生成框架缺乏完全自主性，无法实现从零开始的智能体生成、自我优化功能及协作，限制了适应性和扩展性。我们提出了SwarmAgentic，一个全自动化智能体系统生成框架，通过语言驱动探索构建智能体系统，并将智能体功能和协作作为相互依赖的组件进行联合优化。为实现对系统级结构的高效搜索，SwarmAgentic借鉴粒子群优化（PSO）的思想，维护候选系统群体并通过反馈引导更新进行演化。我们在六项涉及高级规划、系统级协调和创造性推理的真实世界开放任务中评估了该方法。仅需任务描述和目标函数，SwarmAgentic在所有基准测试中均优于基线方法，如在TravelPlanner任务中相对ADAS提升261.8%，充分展示了全自动化在结构无约束任务中的有效性。该框架为可扩展和自主的智能体系统设计迈出了重要一步，将群体智能与全自动化系统多智能体生成相结合。代码已公开发布于https://yaoz720.github.io/SwarmAgentic/。

</details>


### [129] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
**中文标题：具身网络代理：为集成代理智能搭建物理与数字领域的桥梁**

*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

主要分类: cs.AI

摘要简述: 本文提出了一种新型AI代理范式——‘具身网络代理’，旨在融合物理与数字领域的智能，通过统一仿真平台和多样化任务基准，揭示了当前AI系统与人类能力之间的显著差距。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI代理通常局限于数字或物理领域，缺乏融合两者的能力，限制了其在需要跨领域智能的任务中的应用。本文旨在解决这一分离问题，推动AI代理在物理与数字领域的无缝集成。

研究方法: 开发了‘具身网络代理’任务环境，这是一个集成了真实3D室内外环境与功能性网络接口的统一仿真平台，并在此基础上构建了包含烹饪、导航、购物等多样化任务的基准测试。

研究结果: 实验结果显示，当前最先进的AI系统在跨领域任务中表现显著落后于人类，突显了具身认知与网络知识访问结合的挑战与机遇。

研究结论: 本文提出的‘具身网络代理’为AI代理在物理与数字领域的融合提供了新方向，同时发布的公开数据集和代码为未来研究奠定了基础。

中文摘要: 当前的AI代理大多处于孤立状态——它们要么在线获取并推理大量数字信息和知识，要么通过具身感知、规划和行动与物理世界互动，但很少同时具备这两种能力。这种分离限制了它们在需要融合物理与数字智能的任务中的表现，例如根据在线食谱烹饪、利用动态地图数据导航或借助网络知识解读现实世界地标。我们提出了‘具身网络代理’，这是一种新型AI代理范式，能够无缝连接具身行为与网络规模推理。为实现这一概念，我们首先开发了‘具身网络代理’任务环境，这是一个集成了真实3D室内外环境与功能性网络接口的统一仿真平台。基于此平台，我们构建并发布了‘具身网络代理基准’，涵盖烹饪、导航、购物、旅游和地理定位等多样化任务，所有任务均需协调物理与数字领域的推理能力，以系统评估跨领域智能。实验结果显示，当前最先进的AI系统与人类能力之间存在显著差距，为具身认知与网络知识访问的交叉研究提出了挑战与机遇。所有数据集、代码和网站均在我们的项目页面公开提供：https://embodied-web-agent.github.io/。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [130] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
**中文标题：基于LabVIEW的精确修订版光学字符识别语音合成**

*Prateek Mehta,Anasuya Patil*

主要分类: cs.SD

摘要简述: 本文开发了一种基于光学字符识别（OCR）的语音合成系统，旨在为视障人士提供准确、可靠且经济高效的阅读解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 视障人士通常依赖盲文书籍和NGO提供的音频资源，但这些方式存在局限性，无法满足个性化阅读需求。语音作为更有效的沟通方式，能够帮助视障人士更便捷地获取信息。

研究方法: 研究采用实验室虚拟仪器工程工作台（LabVIEW）实现OCR技术，将文本转换为语音，开发了一套用户友好的语音合成系统。

研究结果: 系统成功实现了高精度、可靠且低成本的文本转语音功能，为视障人士提供了更灵活的阅读选择。

研究结论: 基于OCR的语音合成系统为视障人士提供了一种高效、经济的阅读辅助工具，具有广泛的应用潜力。

中文摘要: 通过声音提取知识是一种独特的特性。视障人士通常仅依赖盲文书籍和非政府组织提供的音频资源。由于这些方法的局限性，盲人往往无法选择自己喜欢的书籍。对于视障人士而言，语音是比文本更有效的沟通方式，因为他们可以轻松响应声音。本文介绍了一种基于光学字符识别（OCR）的准确、可靠、经济高效且用户友好的语音合成系统的开发。该OCR系统使用实验室虚拟仪器工程工作台（LabVIEW）实现。

</details>


### [131] [SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](https://arxiv.org/abs/2506.15154)
**中文标题：SonicVerse：基于多任务学习的音乐特征感知描述生成**

*Anuradha Chopra,Abhinaba Roy,Dorien Herremans*

主要分类: cs.SD

摘要简述: 本文提出了一种多任务音乐描述模型SonicVerse，通过结合音乐特征检测任务（如调性检测、人声检测等）生成更丰富的音乐描述，同时利用投影架构将音频输入转化为语言标记，显著提升了描述的质量和细节。


<details>
  <summary>详细信息</summary>
研究动机: 音乐数据库中缺乏能够准确反映音乐特征的详细描述，限制了音乐AI研究的进展。本文旨在通过多任务学习模型，结合音乐特征检测任务，生成更丰富、准确的音乐描述。

研究方法: SonicVerse采用多任务学习框架，将音乐描述生成与辅助音乐特征检测任务（如调性检测、人声检测等）结合。通过投影架构将音频输入转化为语言标记，并利用辅助头检测音乐特征，进一步丰富描述输入。此外，还扩展了MusicBench数据集，使用MIRFLEX工具标注音乐特征。

研究结果: 实验结果表明，通过结合音乐特征检测任务，生成的音乐描述在质量和细节上均有显著提升，同时能够为长音乐片段生成时间相关的详细描述。

研究结论: SonicVerse通过多任务学习框架有效提升了音乐描述的质量和细节，为音乐数据库和音乐AI研究提供了有力工具。

中文摘要: 能够准确反映音乐特征的详细描述可以丰富音乐数据库并推动音乐AI研究的发展。本文提出了一种多任务音乐描述模型SonicVerse，它将描述生成与辅助音乐特征检测任务（如调性检测、人声检测等）结合，以直接捕捉低层次声学细节和高层次音乐属性。其核心贡献是一种基于投影的架构，将音频输入转化为语言标记，同时通过专用辅助头检测音乐特征。这些头的输出也被投影为语言标记，以增强描述输入。该框架不仅能为短音乐片段生成丰富、描述性的文本，还能通过链接大型语言模型的输出，为长音乐片段生成时间相关的详细描述。为训练模型，我们使用模块化音乐特征提取工具MIRFLEX对MusicBench数据集进行标注，生成了配对的音频、描述和音乐特征数据。实验结果表明，通过这种方式结合音乐特征，显著提升了生成描述的质量和细节。

</details>


### [132] [pycnet-audio: A Python package to support bioacoustics data processing](https://arxiv.org/abs/2506.14864)
**中文标题：pycnet-audio：一个支持生物声学数据处理的Python工具包**

*Zachary J. Ruff,Damon B. Lesmeister*

主要分类: cs.SD

摘要简述: pycnet-audio是一个Python工具包，旨在支持生物声学数据处理，通过自动化检测目标信号（如野生动物叫声）来应对大规模音频数据的处理需求。


<details>
  <summary>详细信息</summary>
研究动机: 被动声学监测在野生动物研究中日益重要，但大规模音频数据（如数万小时录音）的人工处理不切实际，亟需自动化工具。

研究方法: 围绕PNW-Cnet模型构建，该模型最初用于监测北方斑点猫头鹰等森林猫头鹰，后扩展至约80种森林野生动物及多种人为和环境噪声的检测。

研究结果: pycnet-audio提供了一个实用的声学数据处理流程，支持自动化检测目标信号，适用于大规模生物声学项目。

研究结论: pycnet-audio为生物声学数据处理提供了高效解决方案，尤其适用于大规模被动声学监测项目。

中文摘要: 被动声学监测是一种新兴的野生动物研究方法，利用专用自动录音设备（ARU）进行长时间录音（数周或数月）。这些音频数据需通过测量或分析音频特征（如计算声学指数）或搜索目标信号（如特定物种的叫声、人为或环境噪声）来处理。对于大规模数据（如10^5小时录音），人工处理不现实，需自动化检测方法。pycnet-audio（Ruff 2024）旨在提供实用的声学数据处理流程，基于PNW-Cnet模型（最初由美国林务局开发，用于监测北方斑点猫头鹰等森林猫头鹰）。PNW-Cnet已扩展至检测约80种森林野生动物及多种噪声（Ruff et al. 2021, 2023）。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [133] [PFMBench: Protein Foundation Model Benchmark](https://arxiv.org/abs/2506.14796)
**中文标题：PFMBench：蛋白质基础模型基准测试**

*Zhangyang Gao,Hao Wang,Cheng Tan,Chenrui Xu,Mengdi Liu,Bozhen Hu,Linlin Chao,Xiaoming Zhang,Stan Z. Li*

主要分类: q-bio.BM

摘要简述: 本研究提出了PFMBench，一个全面评估蛋白质基础模型的基准测试，涵盖38个任务和8个关键领域，揭示了任务间的相关性，并提供了标准化的评估协议。


<details>
  <summary>详细信息</summary>
研究动机: 当前蛋白质基础模型研究缺乏统一的评估基准，导致模型间的比较和泛化能力分析受限。PFMBench旨在填补这一空白，为模型评估提供全面支持。

研究方法: 通过17个先进模型在38个任务上的数百次实验，PFMBench分析了任务间的相关性，并开发了标准化的评估流程。

研究结果: PFMBench揭示了任务间的内在关联，识别了表现最佳的模型，并提供了高效的评估方法。

研究结论: PFMBench为蛋白质基础模型研究提供了统一的评估框架，有助于推动未来模型的开发和优化。

中文摘要: 本研究探讨了蛋白质基础模型研究的现状与未来方向。尽管近期进展推动了蛋白质科学与工程的发展，但该领域缺乏一个全面的基准测试以实现公平评估和深入理解。自ESM-1B以来，众多蛋白质基础模型涌现，各自采用独特的数据集和方法。然而，评估往往局限于针对特定模型的有限任务，阻碍了对模型泛化能力和局限性的全面认识。具体而言，研究人员难以理解任务间的关系、评估现有模型的表现，以及确定开发新基础模型的标准。为填补这一空白，我们提出了PFMBench，一个涵盖蛋白质科学8个关键领域、38个任务的全面基准测试。通过对17个先进模型在38个任务上的数百次实验，PFMBench揭示了任务间的内在相关性，识别了表现最佳的模型，并提供了标准化的评估协议。代码发布于\href{https://github.com/biomap-research/PFMBench}{\textcolor{blue}{GitHub}}。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [134] [Efficient Serving of LLM Applications with Probabilistic Demand Modeling](https://arxiv.org/abs/2506.14851)
**中文标题：基于概率需求建模的高效大语言模型应用服务**

*Yifei Liu,Zuo Gan,Zhenghao Gan,Weiye Wang,Chen Chen,Yizhou Shan,Xusheng Chen,Zhenhua Han,Yifei Zhu,Shixuan Sun,Minyi Guo*

主要分类: cs.DC

摘要简述: 本文提出了一种基于概率需求图（PDGraph）的高效大语言模型（LLM）应用服务系统Hermes，通过优化调度顺序和预热后端，显著提升了服务效率，平均完成时间减少70%以上，P95完成时间减少80%以上。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大语言模型（LLM）应用服务系统将资源需求视为黑箱，导致排队顺序不当和后端预热延迟，影响端到端效率。本文旨在通过概率需求建模解决这一问题。

研究方法: 提出概率需求图（PDGraph）模型，用于准确描述LLM应用的资源需求。基于此，开发了Hermes系统，采用Gittins策略优化调度顺序，并利用PDGraph模型在合适时机预热后端。

研究结果: 实验表明，Hermes显著提升了LLM应用的服务效率，平均完成时间减少超过70%，P95完成时间减少超过80%。

研究结论: 通过概率需求建模和智能调度，Hermes能够高效服务LLM应用，为动态需求场景提供了可行的解决方案。

中文摘要: 基于大语言模型（LLM）的应用通过一系列任务解决现实问题，但其动态需求在不同后端上表现多样。现有服务系统将LLM应用的资源需求视为黑箱，导致排队顺序不当和后端预热延迟，从而影响端到端效率。我们发现，LLM应用的资源需求可以通过概率需求图（PDGraph）进行通用且准确的建模。为此，我们提出了Hermes系统，利用PDGraph实现高效的LLM应用服务。面对概率需求描述，Hermes采用Gittins策略确定调度顺序，以最小化应用平均完成时间，并利用PDGraph模型在合适时机预热冷启动后端。通过多样化的LLM应用实验，我们证实Hermes能显著提升服务效率，平均完成时间减少超过70%，P95完成时间减少超过80%。

</details>


### [135] [Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching](https://arxiv.org/abs/2506.14852)
**中文标题：通过测试时计划缓存实现LLM代理的高效低成本服务**

*Qizheng Zhang,Michael Wornow,Kunle Olukotun*

主要分类: cs.DC

摘要简述: 本文提出了一种名为“代理计划缓存”的新方法，通过提取、存储和重用结构化计划模板，显著降低基于LLM的代理应用的服务成本，平均节省46.62%。


<details>
  <summary>详细信息</summary>
研究动机: 基于LLM的代理应用在复杂工作流程中表现出色，但其高昂的规划和推理成本限制了实际应用。现有的缓存技术（如上下文缓存和语义缓存）主要针对聊天机器人，无法满足依赖外部数据或环境上下文的代理应用需求。

研究方法: 作者提出代理计划缓存方法，从已完成代理执行的规划阶段提取结构化计划模板，通过关键词匹配新请求与缓存计划，并利用轻量级模型将模板适配到具体任务上下文中。

研究结果: 实验表明，该方法在多个实际代理应用中平均降低成本46.62%，同时保持性能不变。

研究结论: 代理计划缓存是一种高效且互补现有LLM服务基础设施的解决方案，显著降低了代理应用的服务成本。

中文摘要: 基于LLM的代理应用在复杂工作流程中展现出卓越能力，但由于大量规划和推理需求，成本高昂。现有的LLM缓存技术（如上下文缓存和语义缓存）主要服务于聊天机器人，无法满足依赖外部数据或环境上下文的代理应用需求。我们提出代理计划缓存，这是一种新颖方法，通过从代理应用的规划阶段提取、存储、适配和重用结构化计划模板，以降低服务成本。与传统语义缓存不同，我们的系统在测试时从完成的代理执行中提取计划模板，利用关键词提取匹配新请求与缓存计划，并通过轻量级模型将这些模板适配到具体任务上下文中。在多个实际代理应用中的评估表明，我们的系统平均可降低成本46.62%，同时保持性能，为基于LLM的代理服务提供了一种更高效的解决方案，补充了现有的LLM服务基础设施。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [136] [Deploying and Evaluating Multiple Deep Learning Models on Edge Devices for Diabetic Retinopathy Detection](https://arxiv.org/abs/2506.14834)
**中文标题：在边缘设备上部署和评估多种深度学习模型用于糖尿病视网膜病变检测**

*Akwasi Asare,Dennis Agyemanh Nana Gookyi,Derrick Boateng,Fortunatus Aabangbio Wulnye*

主要分类: eess.IV

摘要简述: 本研究利用Edge Impulse在边缘设备上部署多种深度学习模型，实现糖尿病视网膜病变（DR）的实时检测。通过预处理和优化多种CNN模型，在智能手机和微控制器等硬件上评估性能，MobileNet准确率达96.45%，SqueezeNet模型仅176KB且延迟17ms，为资源有限的医疗场景提供高效解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 糖尿病视网膜病变（DR）是全球糖尿病患者视力受损的主要原因，传统诊断依赖人工检查，耗时且资源密集。本研究旨在通过边缘AI技术提供一种实时、高效的DR检测方案，尤其适用于资源有限的医疗环境。

研究方法: 研究使用Kaggle EyePACS数据集中的3,662张视网膜图像，通过数据增强和归一化预处理。设计并训练了MobileNet、ShuffleNet、SqueezeNet和自定义DNN等CNN模型，优化为TensorFlowLite格式并量化为8位整数，以减少模型大小并提升推理速度。在多种边缘硬件平台上评估性能。

研究结果: MobileNet准确率最高（96.45%），SqueezeNet模型体积最小（176KB）且延迟仅17ms，适合实时应用；ShuffleNet和自定义DNN在资源效率上表现优异，适用于低端设备。

研究结论: 边缘AI技术为DR早期检测提供了可扩展、经济高效的解决方案，特别适用于资源有限的医疗场景，能够实现快速准确的诊断。

中文摘要: 糖尿病视网膜病变（DR）是糖尿病患者视力受损的主要原因，全球约34.6%的糖尿病患者受影响，预计到2045年病例数将达2.42亿。传统DR诊断依赖视网膜眼底图像的人工检查，耗时且资源密集。本研究提出了一种基于Edge Impulse的新方法，在边缘设备上部署多种深度学习模型以实现实时DR检测。研究使用了Kaggle EyePACS数据集中的3,662张视网膜图像，并通过数据增强和归一化进行预处理。利用TensorFlow设计了MobileNet、ShuffleNet、SqueezeNet和自定义深度神经网络（DNN）等多种卷积神经网络（CNN），并优化为TensorFlowLite格式，量化为8位整数以减少模型大小并提升推理速度，同时保持较高准确性。在不同边缘硬件平台（如智能手机和微控制器）上的性能评估中，MobileNet准确率达96.45%，SqueezeNet模型体积仅176KB且延迟为17ms（GPU环境下），ShuffleNet和自定义DNN在资源效率上表现优异。这一边缘AI技术在医疗领域的应用为DR早期检测提供了可扩展、经济高效的解决方案，尤其适用于资源有限的医疗场景。

</details>


### [137] [Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)](https://arxiv.org/abs/2506.14909)
**中文标题：基于面部照片的健康识别基础人工智能模型（FAHR-Face）**

*Fridolin Haugg,Grace Lee,John He,Leonard Nürnberg,Dennis Bontempi,Danielle S. Bitterman,Paul Catalano,Vasco Prudente,Dmitrii Glubokov,Andrew Warrington,Suraj Pai,Dirk De Ruysscher,Christian Guthier,Benjamin H. Kann,Vadim N. Gladyshev,Hugo JWL Aerts,Raymond H. Mak*

主要分类: eess.IV

摘要简述: FAHR-Face是一个基于4000万张面部图像训练的基础AI模型，用于健康识别，包括生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）。模型在公开数据集和癌症患者中表现优异，且具有跨年龄、性别、种族和癌症亚组的普适性。


<details>
  <summary>详细信息</summary>
研究动机: 面部外观为健康监测提供了非侵入性窗口。研究旨在开发一个基础AI模型，通过面部图像捕捉生物衰老和疾病相关死亡风险，为临床提供低成本、可扩展的生物标志物。

研究方法: FAHR-FaceAge通过两阶段年龄平衡微调训练于749,935张公开图像；FAHR-FaceSurvival微调于34,389张癌症患者照片。测试了模型对化妆、姿态、光照等的鲁棒性，并通过临床数据集验证其性能。

研究结果: FAHR-FaceAge在公开数据集上的平均绝对误差为5.1年，优于基准模型；FAHR-FaceSurvival能稳健预测死亡率，最高风险组死亡率是最低组的3.22倍。两者结合提升了预后准确性。

研究结论: 单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物衰老和疾病相关死亡风险，并能利用小规模临床数据集有效训练。

中文摘要: 背景：面部外观为健康监测提供了非侵入性窗口。我们开发了FAHR-Face，一个基于4000万张面部图像训练的基础模型，并针对两项任务进行了微调：生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）。方法：FAHR-FaceAge通过两阶段年龄平衡微调训练于749,935张公开图像；FAHR-FaceSurvival微调于34,389张癌症患者照片。测试了模型对化妆、姿态、光照等的鲁棒性，并通过临床数据集验证其性能。结果：FAHR-FaceAge在公开数据集上的平均绝对误差为5.1年，优于基准模型；FAHR-FaceSurvival能稳健预测死亡率，最高风险组死亡率是最低组的3.22倍（调整后风险比3.22；P<0.001）。这些发现在独立队列中得到验证，且模型在年龄、性别、种族和癌症亚组中具有普适性。两种算法提供了互补的预后信息，显著性映射显示各自依赖不同面部区域。结合FAHR-FaceAge和FAHR-FaceSurvival提升了预后准确性。结论：单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物衰老和疾病相关死亡风险，并能利用小规模临床数据集有效训练。

</details>


### [138] [Empirical Studies of Large Scale Environment Scanning by Consumer Electronics](https://arxiv.org/abs/2506.14771)
**中文标题：消费电子产品大规模环境扫描的实证研究**

*Mengyuan Wang,Yang Liu,Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

主要分类: eess.IV

摘要简述: 本文对消费级3D扫描设备Matterport Pro3在大规模环境重建中的表现进行了实证评估，通过扫描六层建筑（17,567平方米）并分析其性能、局限性和改进方法，展示了其在点云密度和对齐精度上的优势。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估消费级3D扫描设备Matterport Pro3在大规模环境重建中的实际表现，探索其性能、局限性及改进方法，为相关应用提供参考。

研究方法: 研究对六层建筑（17,567平方米）进行了1,099个扫描点的详细扫描，评估了Matterport Pro3的性能，并与iPhone进行了对比分析，同时提出了解决扫描中遇到问题的方案。

研究结果: Matterport Pro3生成的点云密度更高（1,877,324点vs. iPhone的506,961点），对齐精度更高（RMSE为0.0118米），云到云平均距离误差为0.0408米（标准差0.0715米）。

研究结论: Matterport Pro3能够生成适用于大规模应用的高质量3D模型，结合LiDAR和先进对齐技术，展现了其在成本效益和性能之间的平衡。

中文摘要: 本文对消费级3D扫描设备Matterport Pro3在大规模环境重建中的表现进行了实证评估。我们详细扫描了一栋六层建筑（17,567平方米），共1,099个扫描点，评估了设备的有效性、局限性和性能改进。通过提出解决方案解决了扫描中遇到的挑战，并探索了更有效的克服方法。与另一款消费级设备（iPhone）的对比分析显示，Pro3在成本效益和性能之间取得了平衡。Matterport Pro3生成的点云密度更高（1,877,324点vs. iPhone的506,961点），对齐精度更高（RMSE为0.0118米）。两模型间的云到云平均距离误差为0.0408米（标准差0.0715米）。研究表明，Pro3能够生成适用于大规模应用的高质量3D模型，充分利用了LiDAR和先进对齐技术的优势。

</details>


### [139] [Improving Prostate Gland Segmenting Using Transformer based Architectures](https://arxiv.org/abs/2506.14844)
**中文标题：基于Transformer架构的前列腺分割改进研究**

*Shatha Abudalou*

主要分类: eess.IV

摘要简述: 本研究探讨了基于Transformer的架构（UNETR和SwinUNETR）在T2加权MRI图像中前列腺分割的改进效果，发现SwinUNETR在多种训练策略下表现优于传统3D UNet，尤其在减少标签噪声和类别不平衡敏感性方面效果显著。


<details>
  <summary>详细信息</summary>
研究动机: 由于不同读者之间的标注差异和跨站点数据域偏移，T2加权MRI图像的前列腺自动分割面临挑战。本研究旨在验证Transformer模型能否在这种异质性下保持高精度。

研究方法: 研究比较了UNETR和SwinUNETR与传统的3D UNet在前列腺分割中的表现。使用了546个由两位专家标注的T2加权MRI图像，分析了三种训练策略：单队列数据集、5折交叉验证混合队列和基于腺体大小的数据集。超参数通过Optuna优化，测试集来自独立读者群体。

研究结果: 在单读者训练中，SwinUNETR的平均Dice分数为0.816（读者1）和0.860（读者2），优于UNETR和3D UNet。在交叉验证混合训练中，SwinUNETR表现更佳（读者1：0.8583，读者2：0.867）。在基于腺体大小的数据集中，SwinUNETR在较大腺体子集中的Dice分数高达0.902（读者1）和0.894（读者2）。

研究结论: 研究表明，全局和移位窗口自注意力机制能有效减少标签噪声和类别不平衡敏感性，使SwinUNETR的Dice分数比CNN提升高达5分，同时保持计算效率，适合临床部署。

中文摘要: 不同读者之间的标注差异和跨站点数据域偏移对T2加权MRI图像的前列腺自动分割提出了挑战。本研究探讨了Transformer模型能否在这种异质性下保持高精度。我们比较了UNETR和SwinUNETR与之前使用的3D UNet模型在前列腺分割中的表现，基于546个由两位独立专家标注的T2加权MRI图像。分析了三种训练策略：单队列数据集、5折交叉验证混合队列和基于腺体大小的数据集。超参数通过Optuna优化，测试集来自独立读者群体（以Dice相似系数为评价指标）。在单读者训练中，SwinUNETR的平均Dice分数为0.816（读者1）和0.860（读者2），而UNETR为0.8和0.833，3D UNet为0.825和0.851。在交叉验证混合训练中，SwinUNETR的平均Dice分数为0.8583（读者1）和0.867（读者2）。在基于腺体大小的数据集中，SwinUNETR在较大腺体子集中的Dice分数为0.902（读者1）和0.894（读者2），而UNETR表现较差。研究结果表明，全局和移位窗口自注意力机制能有效减少标签噪声和类别不平衡敏感性，使SwinUNETR的Dice分数比CNN提升高达5分，同时保持计算效率，适合临床部署。

</details>


### [140] [Recursive Variational Autoencoders for 3D Blood Vessel Generative Modeling](https://arxiv.org/abs/2506.14914)
**中文标题：递归变分自编码器用于3D血管生成建模**

*Paula Feldman,Miguel Fainstein,Viviana Siless,Claudio Delrieux,Emmanuel Iarussi*

主要分类: eess.IV

摘要简述: 本文提出了一种递归变分神经网络（RvNN），用于生成3D血管模型，能够准确捕捉血管的多样性和复杂性，适用于医疗和手术训练等领域。


<details>
  <summary>详细信息</summary>
研究动机: 解剖树结构在临床诊断和治疗规划中至关重要，但现有方法多为规则驱动，难以捕捉真实解剖数据的多样性和复杂性。因此，需要一种能够生成准确且多样血管模型的新方法。

研究方法: 开发了一种递归变分神经网络（RvNN），利用血管的层次结构，学习低维流形编码分支连接性和几何特征，从而生成新的血管几何模型。

研究结果: 生成的3D血管模型在半径、长度和弯曲度等方面与真实数据高度相似，包括带有动脉瘤的数据集，验证了方法的有效性。

研究结论: RvNN首次成功应用于血管合成，生成的模型准确且多样，为医疗和手术训练等提供了重要工具。

中文摘要: 解剖树结构在临床诊断和治疗规划中具有重要作用。然而，由于其复杂的拓扑和几何特征，准确表示这些结构具有挑战性。现有方法多为规则驱动，虽然能提供一定程度的控制和变化，但无法捕捉真实解剖数据的多样性和复杂性。我们开发了一种递归变分神经网络（RvNN），充分利用血管的层次结构，学习编码分支连接性和目标表面几何特征的低维流形。训练后，RvNN的潜在空间可用于生成新的血管几何模型。通过生成神经网络的强大能力，我们生成了准确且多样的3D血管模型，这对医疗和手术训练、血流动力学模拟等至关重要。这些结果与真实数据高度相似，包括血管半径、长度和弯曲度等方面，甚至适用于带有动脉瘤的数据集。据我们所知，这是首次利用该技术合成血管的研究。

</details>


### [141] [NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal Neurological Disorder Classification](https://arxiv.org/abs/2506.14970)
**中文标题：NeuroMoE：基于Transformer的混合专家框架用于多模态神经疾病分类**

*Wajih Hassan Raza,Aamir Bader Shah,Yu Wen,Yidan Shen,Juan Diego Martinez Lemus,Mya Caryn Schiess,Timothy Michael Ellmore,Renjie Hu,Xin Fu*

主要分类: eess.IV

摘要简述: 本文提出了一种基于Transformer的混合专家框架NeuroMoE，用于多模态神经疾病分类，结合MRI和临床数据，显著提升诊断准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有深度学习方法在多模态MRI和临床数据的整合上表现不佳，导致诊断效果不理想。本文旨在通过提出一种新框架，解决这一问题。

研究方法: 利用专有的多模态临床数据集，提出基于Transformer的混合专家框架，结合解剖MRI、扩散张量成像和功能MRI，通过门控机制动态融合专家输出。

研究结果: 实验表明，该框架在验证集上达到82.47%的准确率，比基线方法提升超过10%，显著区分重叠疾病状态。

研究结论: NeuroMoE框架通过多模态学习显著提升了神经疾病的诊断准确性，展示了在临床数据中的应用潜力。

中文摘要: 多模态磁共振成像（MRI）与临床数据的结合为神经疾病（NDs）的诊断提供了巨大潜力。深度学习（DL）已成为从医学数据中提取有意义模式的有力工具，但现有方法在多模态MRI和临床数据的整合上表现不佳。为解决这一问题，我们利用专为ND研究定制的多模态临床数据集，提出了一种基于Transformer的混合专家（MoE）框架，结合解剖MRI（aMRI）、扩散张量成像（DTI）和功能MRI（fMRI）以及临床评估。该框架通过Transformer编码器捕捉体积MRI数据的空间关系，并利用模态特定专家进行针对性特征提取。自适应融合的门控机制动态整合专家输出，确保最佳预测性能。全面实验及与多种基线的比较表明，我们的多模态方法显著提升了诊断准确性，尤其是在区分重叠疾病状态方面。该框架在验证集上达到82.47%的准确率，比基线方法高出10%以上，凸显了其在临床数据中应用多模态学习以改善ND诊断的潜力。

</details>


### [142] [Classification of Multi-Parametric Body MRI Series Using Deep Learning](https://arxiv.org/abs/2506.15182)
**中文标题：基于深度学习的多参数体部MRI序列分类**

*Boah Kim,Tejas Sudharshan Mathai,Kimberly Helm,Peter A. Pinto,Ronald M. Summers*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的分类模型，用于准确分类8种不同的多参数磁共振成像（mpMRI）序列类型，以提高放射科医生的工作效率。实验表明，DenseNet-121模型在内部和外部数据集上均表现出色，最高F1分数和准确率分别达到0.966和0.972。


<details>
  <summary>详细信息</summary>
研究动机: 多参数磁共振成像（mpMRI）的DICOM头文件常因协议多样性和技术员错误而包含不准确信息，导致放射科医生阅读效率低下。本文旨在通过深度学习模型自动分类mpMRI序列类型，以解决这一问题。

研究方法: 研究使用来自多个机构的mpMRI数据，训练了ResNet、EfficientNet和DenseNet等多种深度学习分类器，比较其性能。最终选择表现最佳的DenseNet-121模型，并研究了不同训练数据量对其性能的影响，同时评估了模型在外部数据集上的表现。

研究结果: DenseNet-121模型在内部数据集上取得了最高的F1分数（0.966）和准确率（0.972）。当训练数据量超过729项研究时，模型准确率超过0.95，且性能随数据量增加而提升。在外部数据集DLDS和CPTAC-UCEC上，模型准确率分别为0.872和0.810。

研究结论: DenseNet-121模型在分类8种mpMRI序列类型的任务中表现出色，适用于内部和外部数据集，为放射科医生提供了高效的工具。

中文摘要: 多参数磁共振成像（mpMRI）检查包含多种不同成像协议获取的序列类型。由于协议多样性和技术员偶尔的错误，这些序列的DICOM头文件常包含不准确信息。为此，本文提出了一种基于深度学习的分类模型，用于分类8种不同的体部mpMRI序列类型，以提高放射科医生的阅读效率。研究使用来自多个机构的mpMRI数据，训练了ResNet、EfficientNet和DenseNet等多种深度学习分类器，并比较了它们的性能。随后，确定了表现最佳的DenseNet-121模型，并研究了不同训练数据量对其性能的影响。此外，模型还在外部数据集上进行了评估。实验结果表明，DenseNet-121模型的F1分数和准确率最高，分别为0.966和0.972（p值<0.05）。当训练数据量超过729项研究时，模型准确率超过0.95，且性能随数据量增加而提升。在外部数据集DLDS和CPTAC-UCEC上，模型准确率分别为0.872和0.810。这些结果表明，DenseNet-121模型在内部和外部数据集上均能高效分类8种体部MRI序列类型。

</details>


### [143] [Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference](https://arxiv.org/abs/2506.15258)
**中文标题：基于同态加密的潜在空间胸部X光分类与隐私保护神经推理**

*Jonghun Kim,Gyeongdeok Jo,Shinyoung Ra,Hyunjin Park*

主要分类: eess.IV

摘要简述: 本文提出了一种基于同态加密（HE）的医疗图像隐私保护分类框架，通过VQGAN压缩图像为潜在表示以减少计算负担，同时保持图像质量。该方法在胸部X光数据集上验证了其可行性和性能。


<details>
  <summary>详细信息</summary>
研究动机: 医疗影像数据包含敏感患者信息，需强隐私保护。传统方法需将数据发送至服务器进行推理，存在隐私风险。同态加密（HE）可在加密数据上直接计算，但计算成本高，尤其对大尺寸图像（如胸部X光）。本研究旨在解决HE推理的高计算成本问题。

研究方法: 使用VQGAN将图像压缩为潜在表示以降低计算负担；用低阶多项式逼近激活函数以平衡精度与效率；引入挤压激励模块优化HE框架；在胸部X光数据集上测试多标签分类任务。

研究结果: 实验表明，压缩因子为8时性能与计算成本达到最优平衡；HE推理虽较慢且性能略有下降，但显示出实际应用潜力。

研究结论: 本研究提出的HE框架在保护医疗图像隐私的同时，显著降低了计算成本，为医疗影像的隐私安全分析提供了可行方案。

中文摘要: 医疗影像数据包含敏感患者信息，需强隐私保护。传统分析需将数据发送至服务器进行推理，而同态加密（HE）可直接在加密数据上计算，但计算成本高，尤其对大尺寸图像（如胸部X光）。本研究提出一种HE推理框架，利用VQGAN将图像压缩为潜在表示，显著降低计算负担并保持图像质量。通过低阶多项式逼近激活函数，平衡精度与效率。实验发现压缩因子为8时性能与计算成本最优。进一步引入挤压激励模块优化HE框架。在两种胸部X光数据集上测试多标签分类任务，结果表明HE推理虽较慢且性能略有差异，但具有实际应用潜力。

</details>


### [144] [FedWSIDD: Federated Whole Slide Image Classification via Dataset Distillation](https://arxiv.org/abs/2506.15365)
**中文标题：FedWSIDD：基于数据集蒸馏的联邦全切片图像分类**

*Haolong Jin,Shenglin Liu,Cong Cong,Qingmin Feng,Yongzhi Liu,Lina Huang,Yingzi Hu*

主要分类: eess.IV

摘要简述: FedWSIDD是一种新型联邦学习方法，通过数据集蒸馏技术解决全切片图像分类中的计算资源异质性和隐私问题，提升分类性能并保护患者隐私。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在医学图像分析中具有潜力，但全切片图像分类面临计算资源异质性和隐私问题，需要一种既能高效协作又能保护隐私的解决方案。

研究方法: FedWSIDD利用数据集蒸馏技术生成合成切片，服务器端聚合并分发这些切片，客户端采用新型蒸馏算法结合染色归一化生成高信息量的合成切片，传输切片而非模型参数。

研究结果: 在CAMELYON16和CAMELYON17等任务上的实验表明，FedWSIDD支持异质本地模型，提升分类性能，同时保护患者隐私。

研究结论: FedWSIDD为复杂全切片图像分类任务提供了高效、灵活的解决方案，兼具隐私保护和性能提升。

中文摘要: 联邦学习（FL）已成为协作医学图像分析的一种有前景的方法，允许多个机构在保护敏感患者数据的同时构建鲁棒的预测模型。在全切片图像（WSI）分类中，FL面临显著挑战，包括参与医疗机构间的计算资源异质性和隐私问题。为解决这些问题，我们提出FedWSIDD，一种新型FL范式，利用数据集蒸馏（DD）学习和传输合成切片。在服务器端，FedWSIDD聚合来自参与中心的合成切片并将其分发给所有中心。在客户端，我们引入了一种针对病理数据集的新型DD算法，将染色归一化融入蒸馏过程，生成一组紧凑且信息量高的合成切片。这些合成切片（而非模型参数）被传输至服务器。通信后，接收到的合成切片与原始切片结合用于本地任务。在CAMELYON16和CAMELYON17等多个WSI分类任务上的广泛实验表明，FedWSIDD为异质本地模型提供了灵活性，提升了本地WSI分类性能，并保护了患者隐私。这使其成为复杂WSI分类任务的高效解决方案。代码可在FedWSIDD获取。

</details>


### [145] [A Real-time Endoscopic Image Denoising System](https://arxiv.org/abs/2506.15395)
**中文标题：一种实时内窥镜图像去噪系统**

*Yu Xing,Shishi Huang,Meng Lv,Guo Chen,Huailiang Wang,Lingzhi Sui*

主要分类: eess.IV

摘要简述: 本文开发了一种实时内窥镜图像去噪系统，通过结合传统图像处理算法与基于学习的技术，有效解决了小型模拟图像传感器在医疗内窥镜中的噪声问题，显著提升了图像质量并实现了实时性能。


<details>
  <summary>详细信息</summary>
研究动机: 小型化内窥镜的模拟图像传感器因感光面积有限、动态范围受限以及电路简化等问题，导致图像噪声显著。本文旨在解决这些噪声问题，提升内窥镜图像的质量。

研究方法: 本文首先建立了医疗内窥镜中模拟图像传感器的综合噪声模型，包括固定模式噪声、周期性带状噪声和混合泊松-高斯噪声。随后提出了一种混合去噪系统，结合传统图像处理算法与先进学习技术，对传感器捕获的原始帧进行处理。

研究结果: 实验表明，该系统在不损失细节或导致色彩失真的情况下有效降低了噪声，并在FPGA平台上实现了实时性能，测试数据集的平均PSNR从21.16提升至33.05。

研究结论: 本文提出的混合去噪系统成功解决了小型模拟图像传感器在内窥镜中的噪声问题，显著提升了图像质量，同时满足了实时处理的需求。

中文摘要: 小型化设计的内窥镜显著提升了操作的灵活性、便携性和诊断能力，同时大幅降低了医疗过程的侵入性。近年来，配备超紧凑模拟图像传感器（尺寸小于1mm x 1mm）的一次性内窥镜为医疗诊断带来了革命性进步。它们减少了可重复使用设备的结构冗余和高额资本支出，消除了因消毒不彻底导致的患者感染风险，并减轻了患者的痛苦。然而，感光面积有限导致每个像素捕获的光子减少，需要更高的光子灵敏度设置以维持足够的亮度。在高对比度的医疗成像场景中，小型传感器的动态范围受限，难以同时捕捉高光和阴影的细节，需要通过额外的局部数字增益进行补偿。此外，简化的电路设计和模拟信号传输引入了额外的噪声源。这些因素共同导致处理后的内窥镜图像存在显著的噪声问题。本文为医疗内窥镜中的模拟图像传感器建立了一个综合噪声模型，涵盖三种主要噪声类型：固定模式噪声、周期性带状噪声和混合泊松-高斯噪声。基于此分析，我们提出了一种混合去噪系统，将传统图像处理算法与基于学习的先进技术相结合，对传感器捕获的原始帧进行处理。实验表明，我们的方法在不损失细节或导致色彩失真的情况下有效降低了噪声，并在FPGA平台上实现了实时性能，测试数据集的平均PSNR从21.16提升至33.05。

</details>


### [146] [Advanced cervical cancer classification: enhancing pap smear images with hybrid PMD Filter-CLAHE](https://arxiv.org/abs/2506.15489)
**中文标题：高级宫颈癌分类：通过混合PMD滤波器-CLAHE增强Pap涂片图像**

*Ach Khozaimi,Isnani Darti,Syaiful Anam,Wuryansari Muharini Kusumawinahyu*

主要分类: eess.IV

摘要简述: 本研究探讨了混合PMD滤波器和CLAHE预处理技术对宫颈癌分类中CNN性能的影响，结果表明该混合方法显著提升了图像质量和分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 宫颈癌在发展中国家仍是重大健康问题，早期检测至关重要。尽管CNN在自动化筛查中表现良好，但其性能依赖于Pap涂片图像质量。本研究旨在通过预处理技术提升图像质量，从而优化CNN分类效果。

研究方法: 研究评估了三种预处理技术：PMD滤波器（降噪）、CLAHE（对比度增强）及提出的混合PMD-CLAHE方法。使用SIPaKMeD数据集，并在ResNet、SqueezeNet等预训练模型上测试效果。

研究结果: 混合PMD-CLAHE方法显著提升了图像质量和CNN性能，最大改进为准确率13.62%、精确率10.04%、召回率13.08%和F1分数14.34%。

研究结论: 提出的混合PMD-CLAHE技术为提升宫颈癌分类性能提供了新思路，尤其在图像预处理领域具有潜在应用价值。

中文摘要: 宫颈癌仍是重大健康问题，尤其在发展中国家。早期检测对有效治疗至关重要。卷积神经网络（CNN）在自动化宫颈癌筛查中表现良好，但其性能依赖于Pap涂片图像质量。本研究探讨了不同预处理技术对CNN分类性能的影响，使用了SIPaKMeD数据集。评估了三种预处理技术：PMD滤波器（降噪）、CLAHE（对比度增强）及提出的混合PMD-CLAHE方法。增强后的图像数据集在ResNet-34、ResNet-50等预训练模型上测试。结果表明，混合PMD-CLAHE预处理可显著提升图像质量和CNN性能，最大改进为准确率13.62%、精确率10.04%、召回率13.08%和F1分数14.34%。该混合技术为提升宫颈癌分类性能提供了新视角。

</details>


### [147] [Automated MRI Tumor Segmentation using hybrid U-Net with Transformer and Efficient Attention](https://arxiv.org/abs/2506.15562)
**中文标题：基于混合U-Net与Transformer及高效注意力的MRI肿瘤自动分割**

*Syed Haider Ali,Asrar Ahmad,Muhammad Ali,Asifullah Khan,Muhammad Shahban,Nadeem Shaukat*

主要分类: eess.IV

摘要简述: 本研究提出了一种结合U-Net、Transformer和高效注意力机制的混合模型，用于自动分割MRI肿瘤图像。通过本地医院数据集训练，模型在有限数据下表现出色，强调了临床部署中本地化模型开发的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI分割模型多基于大型公共数据集，缺乏对本地患者群体的适应性。本研究旨在开发适用于本地医院数据的肿瘤分割模型，以优化放疗计划并提升临床效率。

研究方法: 研究采用混合U-Net-Transformer架构，结合高效注意力模块（如SE块、CBAM和ResNeXt块），并通过数据增强和预训练权重初始化提升模型性能。训练使用双NVIDIA T4 GPU，最大批次为8。

研究结果: 在本地MRI数据集上，模型Dice相似系数为0.764，IoU为0.736，表现出竞争力，验证了本地化模型开发的必要性。

研究结论: 研究表明，结合Transformer和高效注意力的混合模型在有限数据下表现优异，为临床肿瘤分割提供了高效解决方案。

中文摘要: 癌症是一种异常生长，可能局部侵袭并转移至远处器官。放疗计划优化需要准确自动分割肿瘤及周围正常组织。现有基于AI的分割模型多训练于大型公共数据集，缺乏本地患者群体的异质性。尽管这些研究推动了AI医学图像分割的发展，但基于本地数据集的研究对开发并整合AI肿瘤分割模型至医院软件至关重要，以实现高效精准的肿瘤治疗计划与执行。本研究通过计算高效的混合U-Net-Transformer模型，在严格隐私保护下使用本地医院MRI数据集提升肿瘤分割效果。我们开发了稳健的数据流程，实现无缝DICOM提取与预处理，并通过广泛图像增强确保模型在多样化临床环境中的泛化能力，最终形成6080张图像的训练集。新颖架构结合了基于U-Net的卷积神经网络、Transformer瓶颈及互补注意力模块（包括高效注意力、SE块、CBAM和ResNeXt块）。为加速收敛并降低计算需求，我们采用最大批次8，并使用预训练ImageNet权重初始化编码器，通过检查点在双NVIDIA T4 GPU上训练模型以克服Kaggle运行时限制。在本地MRI数据集上的定量评估显示，Dice相似系数为0.764，IoU为0.736，尽管数据有限仍表现出竞争力，凸显了临床部署中本地化模型开发的重要性。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [148] [Omnidirectional Video Super-Resolution using Deep Learning](https://arxiv.org/abs/2506.14803)
**中文标题：基于深度学习的全方位视频超分辨率技术**

*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter W. Eklund,Sunil Aryal*

主要分类: cs.MM

摘要简述: 本文提出了一种名为S3PO的新型深度学习模型，用于解决360度视频超分辨率问题，通过创新的特征提取器和损失函数，显著提升了视频质量，并创建了首个360度视频数据集360VDS。


<details>
  <summary>详细信息</summary>
研究动机: 360度视频在虚拟现实（VR）中广泛应用，但其有限的像素分辨率影响了沉浸式体验。传统的视频超分辨率（VSR）技术无法解决360度视频的球面失真问题，且缺乏相关数据集。本文旨在填补这一空白并改进超分辨率技术。

研究方法: 本文创建了360VDS数据集，并提出S3PO模型，采用循环建模和注意力机制，避免传统VSR的对齐技术。模型包含专门设计的特征提取器和针对球面失真的新型损失函数。

研究结果: S3PO在360度视频数据集上表现优于现有VSR模型和专为360度视频设计的超分辨率模型，并通过逐步消融研究验证了各子组件的有效性。

研究结论: S3PO模型通过创新的设计和优化，显著提升了360度视频的超分辨率效果，为未来研究提供了新的数据集和技术基础。

中文摘要: 全方位视频（或360度视频）在虚拟现实（VR）中广泛用于提供沉浸式和交互式观看体验。然而，360度视频的有限空间分辨率导致每度视角的像素不足，限制了视觉质量。传统的深度学习视频超分辨率（VSR）技术可能提供基于软件的解决方案，但这些技术未解决360度视频信号在等距柱状投影中的失真问题。此外，可用于研究的360度视频数据集有限。为解决这些问题，本文创建了新型360度视频数据集（360VDS），并研究了传统VSR模型在360度视频中的扩展性。本文进一步提出了一种名为“基于比例优化的球面信号超分辨率”（S3PO）的新型深度学习模型。S3PO采用循环建模和注意力机制，摆脱了传统VSR技术（如对齐）的限制。通过专门设计的特征提取器和针对球面失真的新型损失函数，S3PO在360度视频数据集上表现优于大多数现有VSR模型和专为360度视频设计的超分辨率模型。通过逐步消融研究，本文验证了所选架构子组件、针对性训练和优化的影响。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [149] [Advancing Loss Functions in Recommender Systems: A Comparative Study with a Rényi Divergence-Based Solution](https://arxiv.org/abs/2506.15120)
**中文标题：推荐系统中损失函数的改进：基于Rényi散度的解决方案比较研究**

*Shengjia Zhang,Jiawei Chen,Changdong Li,Sheng Zhou,Qihao Shi,Yan Feng,Chun Chen,Can Wang*

主要分类: cs.IR

摘要简述: 本文研究了推荐系统中的损失函数，比较了Softmax Loss和Cosine Contrastive Loss的优缺点，并提出了一种基于Rényi散度的新损失函数DrRL，以解决现有方法的局限性。实验证明DrRL在推荐准确性和鲁棒性上表现优越。


<details>
  <summary>详细信息</summary>
研究动机: 损失函数在推荐系统优化中至关重要，但现有的Softmax Loss和Cosine Contrastive Loss各有优缺点。前者对假阴性样本敏感，后者数据利用率低。因此，需要一种新的损失函数来结合两者的优势并解决其局限性。

研究方法: 本文通过分析Softmax Loss和Cosine Contrastive Loss的理论联系与差异，提出了一种基于Rényi散度的新损失函数DrRL。DrRL在Distributional Robust Optimization框架下结合了两种损失函数的优势。

研究结果: 实验结果表明，DrRL在推荐准确性和鲁棒性上均优于Softmax Loss和Cosine Contrastive Loss，有效解决了假阴性敏感性和数据利用率低的问题。

研究结论: DrRL作为一种新型损失函数，成功结合了Softmax Loss和Cosine Contrastive Loss的优点，并在实验中表现出优越性能，为推荐系统的优化提供了新思路。

中文摘要: 损失函数在优化推荐模型中起着关键作用。在众多损失函数中，Softmax Loss（SL）和Cosine Contrastive Loss（CCL）尤为有效。它们的理论联系与差异值得深入探讨。本研究对这两种损失函数进行了全面分析，得出以下重要结论：1）共同优势——两者均可视为传统损失函数在Distributional Robust Optimization（DRO）框架下的增强，提高了对分布偏移的鲁棒性；2）各自的局限性——由于在DRO优化中使用了不同的分布距离度量，SL对假阴性样本高度敏感，而CCL存在数据利用率低的问题。为解决这些局限性，本研究提出了一种新的损失函数DrRL，通过利用Rényi散度在DRO优化中泛化了SL和CCL。DrRL结合了SL和CCL的优势结构，并能有效缓解其局限性。大量实验验证了DrRL在推荐准确性和鲁棒性上的优越性。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [150] [MedSyn: Enhancing Diagnostics with Human-AI Collaboration](https://arxiv.org/abs/2506.14774)
**中文标题：MedSyn：通过人机协作提升诊断能力**

*Burcu Sayin,Ipek Baris Schlicht,Ngoc Vo Hong,Sara Allievi,Jacopo Staiano,Pasquale Minervini,Andrea Passerini*

主要分类: cs.LG

摘要简述: 本文提出了一种人机协作框架MedSyn，通过多步互动对话提升临床诊断准确性，实验表明开源大语言模型有望成为医生的有效助手。


<details>
  <summary>详细信息</summary>
研究动机: 临床决策复杂且易受认知偏差和不完整信息影响，现有大语言模型（LLMs）的单次或有限交互方式难以满足实际医疗需求。

研究方法: 提出MedSyn框架，医生与LLMs通过多步动态对话协作，医生可质疑LLM建议，LLM则提供替代视角，模拟实验评估开源LLMs的辅助潜力。

研究结果: 实验表明开源LLMs在模拟互动中表现良好，有望成为现实中医生的有效助手。

研究结论: MedSyn框架展示了人机协作在临床决策中的潜力，未来需通过真实医生互动进一步验证其对诊断准确性和患者结局的影响。

中文摘要: 临床决策具有内在复杂性，常受认知偏差、信息不完整和病例模糊性影响。大语言模型（LLMs）作为支持临床决策的工具显示出潜力，但其典型的单次或有限交互使用方式可能忽视现实医疗实践的复杂性。本研究提出了一种混合人机框架MedSyn，医生与LLMs通过多步互动对话优化诊断和治疗决策。与静态决策支持工具不同，MedSyn支持动态交流，医生可质疑LLM建议，而LLM则提供替代视角。通过模拟医生-LLM互动，我们评估了开源LLMs作为医生助手的潜力。结果表明开源LLMs在现实中作为医生助手具有前景。未来工作将涉及真实医生互动，以进一步验证MedSyn在诊断准确性和患者结局方面的实用性。

</details>


### [151] [PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series](https://arxiv.org/abs/2506.14786)
**中文标题：PIPE：基于物理信息的位置编码用于卫星图像与时间序列的对齐**

*Haobo Li,Eunseo Jung,Zixin Chen,Zhaowei Wang,Yueya Wang,Huamin Qu,Alexis Kai Hon Lau*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PIPE的轻量级方法，通过物理信息位置编码将物理信息嵌入视觉语言模型，显著提升了卫星图像与时间序列的对齐和预测精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态方法主要关注文本数据，而忽略了视觉数据（如卫星图像）中的物理信息。这些信息（如时间和地理空间背景）对预测任务至关重要，但现有模型难以有效捕捉。

研究方法: PIPE包含两个关键创新：(1) 物理信息位置索引方案，将物理信息映射为位置ID；(2) 变频率位置编码机制，编码物理变量的频率信息和令牌的顺序信息。

研究结果: 在最大的开源卫星图像数据集上，PIPE在深度学习和气候领域方法中均达到最先进性能，台风强度预测精度比之前工作提升了12%。

研究结论: PIPE通过嵌入物理信息，显著提升了多模态对齐和预测性能，为卫星图像和时间序列的联合分析提供了有效工具。

中文摘要: 多模态时间序列预测在气候科学等领域具有基础性作用，例如利用卫星图像和数值数据预测台风。然而，现有方法主要依赖文本数据，而忽略了视觉数据中的物理信息（如卫星图像的时间和地理空间背景）。为填补这一空白，我们提出了物理信息位置编码（PIPE），一种轻量级方法，将物理信息嵌入视觉语言模型。PIPE包含两项关键创新：(1) 物理信息位置索引方案，将物理信息映射为位置ID；(2) 变频率位置编码机制，编码物理变量的频率信息和令牌的顺序信息。通过保留物理信息和顺序信息，PIPE显著提升了多模态对齐和预测精度。在最大开源卫星图像数据集上的实验表明，PIPE在深度学习和气候领域方法中均达到最先进性能，台风强度预测精度比之前工作提升了12%。代码详见补充材料。

</details>


### [152] [Topology-Aware and Highly Generalizable Deep Reinforcement Learning for Efficient Retrieval in Multi-Deep Storage Systems](https://arxiv.org/abs/2506.14787)
**中文标题：基于拓扑感知和高度泛化的深度强化学习在多深度存储系统中的高效检索**

*Funing Li,Yuan Tian,Ruben Noortwyck,Jifeng Zhou,Liming Kuang,Robert Schulz*

主要分类: cs.LG

摘要简述: 本文提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题。通过结合图神经网络和Transformer模型，有效捕捉系统拓扑结构，显著减少检索延迟。


<details>
  <summary>详细信息</summary>
研究动机: 现代工业和物流环境中，快速配送服务的扩展对高效且高密度的存储系统需求增加。多深度自主车辆存储和检索系统（AVS/RS）虽然提高了存储密度，但面临因通道堵塞导致的检索难题。传统方法将同类物品存储在同一通道，限制了系统的灵活性和适应性。

研究方法: 提出了一种深度强化学习框架，结合图神经网络（GNN）和Transformer模型。GNN编码拓扑和物品特定信息，Transformer将这些信息映射为全局优先级分配，从而优化检索延迟。

研究结果: 大量数值实验表明，所提出的神经网络架构优于启发式方法，训练后的智能体在优化检索延迟方面表现出色。

研究结论: 该框架不仅有效解决了多深度存储系统中的检索问题，还因其强大的泛化能力适用于多种布局的存储系统。

中文摘要: 在现代工业和物流环境中，快速配送服务的迅速扩展对高效且高密度的存储系统需求日益增长。多深度自主车辆存储和检索系统（AVS/RS）为实现更高存储密度提供了可行方案，但在检索操作中因通道堵塞面临重大挑战。传统方法通过将同类物品存储在同一通道来缓解这一问题，但限制了多深度存储系统的灵活性和适应性。

本研究提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题。每个物品关联一个特定截止日期，目标是最小化总延迟。为有效捕捉系统拓扑，我们引入了一种基于图的状态表示，整合了物品属性和多深度仓库的局部拓扑结构。为处理这一表示，我们设计了一种新颖的神经网络架构，结合了图神经网络（GNN）和Transformer模型。GNN将拓扑和物品特定信息编码为所有可直接访问物品的嵌入，而Transformer将这些嵌入映射为全局优先级分配。Transformer的强大泛化能力进一步使我们的方法适用于多种布局的存储系统。

大量数值实验，包括与启发式方法的比较，证明了所提出的神经网络架构的优越性以及训练智能体在优化检索延迟方面的有效性。

</details>


### [153] [Assembly of Experts: Linear-time construction of the Chimera LLM variants with emergent and adaptable behaviors](https://arxiv.org/abs/2506.14794)
**中文标题：专家组装：线性时间构建具有涌现和适应性行为的Chimera LLM变体**

*Henrik Klagges,Robert Dahlke,Fabian Klemm,Benjamin Merkel,Daniel Klingmann,David A. Reiss,Dan Zecha*

主要分类: cs.LG

摘要简述: 论文提出了一种名为“专家组装”（AoE）的线性时间方法，用于从现有的混合专家（MoE）父模型中生成功能强大的子模型变体，通过权重张量插值调整语义特征，显著降低了计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）的预训练需要极高的计算成本（10^13-10^15 FLOPs），效率低下。为了更高效利用预训练模型的巨大投资，研究者开发了AoE方法，以线性时间生成功能强大的子模型变体。

研究方法: AoE方法通过线性时间插值父模型的权重张量，单独调整每个张量以增强或抑制语义特征。通过改变父模型权重的比例，子模型的行为特征可以逐渐变化或突然涌现。

研究结果: 生成的子模型几乎全部功能正常且强大，使得模型空间搜索变得简单。实验构建了DeepSeek R1T“Chimera”混合模型，继承了R1的路由专家张量，但性能接近R1，同时输出令牌减少40%，推理速度接近V3。

研究结论: AoE方法无需微调或蒸馏即可生成功能强大且高效的子模型，展示了紧凑有序的推理能力，为模型优化提供了新思路。

中文摘要: 在预训练中，大型语言模型（LLM）计算一个8位权重需要10^13-10^15 FLOPs，成本极高且效率低下。为了更高效利用预训练模型的巨大投资，我们开发了新的“专家组装”（AoE）方法，以线性时间从现有的混合专家（MoE）父模型中生成功能强大的子模型变体。通过单独插值模型权重张量，可以增强或抑制父模型的语义特征。

通过调整父模型权重的比例，我们发现AoE子模型的某些属性逐渐变化，而其他行为特征则突然涌现。令人惊讶的是，几乎所有生成的模型都功能正常且强大，使得模型空间搜索变得简单。

我们构建了DeepSeek R1T“Chimera”，这是一个671B的开放权重混合模型，结合了DeepSeek的V3-0324和R1模型变体。该子模型仅继承了R1的路由专家张量，但仍达到接近R1的智能水平，同时输出令牌减少约40%，速度接近V3。无需任何微调或蒸馏，Chimera展现出比父模型更紧凑有序的推理能力。

</details>


### [154] [Bound by semanticity: universal laws governing the generalization-identification tradeoff](https://arxiv.org/abs/2506.14797)
**中文标题：语义性约束：泛化与识别权衡的普适规律**

*Marco Nurisso,Jesseba Fernando,Raj Deshpande,Alan Perotti,Raja Marjieh,Steven M. Frankland,Richard L. Lewis,Taylor W. Webb,Declan Campbell,Francesco Vaccarino,Jonathan D. Cohen,Giovanni Petri*

主要分类: cs.LG

摘要简述: 本文揭示了智能系统在表示学习中面临的基本限制：泛化与识别的权衡。通过理论推导和实验验证，证明了有限语义分辨率下的普适性规律，并展示了这些规律在复杂模型中的普遍存在。


<details>
  <summary>详细信息</summary>
研究动机: 智能系统需要同时支持泛化和识别的内部表示，但这两者之间存在根本性权衡。本文旨在揭示这种权衡的普适性规律，并探讨语义分辨率如何影响表示能力。

研究方法: 通过理论分析，推导了有限语义分辨率下泛化概率和识别概率的闭式表达式，并验证了这些规律在简单ReLU网络、卷积神经网络和先进视觉语言模型中的适用性。

研究结果: 研究发现，泛化与识别的权衡受限于普适的帕累托前沿，且多输入处理能力会急剧下降至1/n。实验表明，这些规律在复杂模型中依然成立。

研究结论: 有限语义分辨率是表示学习中的基本约束，不仅存在于简单模型中，也适用于复杂网络和大脑。本文为泛化-识别权衡提供了精确的理论框架。

中文摘要: 智能系统需要同时具备结构化（支持广泛泛化）和选择性（保留输入身份）的内部表示。本文揭示了这种权衡的基本限制：对于任何表示相似性随有限语义分辨率ε衰减的模型，我们推导了其正确泛化概率p_S和识别概率p_I的闭式表达式，并将其固定在独立于输入空间几何的普适帕累托前沿上。扩展分析至噪声和异质空间及n>2输入时，预测了多输入处理能力的急剧1/n崩溃和p_S的非单调最优值。一个端到端训练的最小ReLU网络重现了这些规律：在学习过程中，分辨率边界自组织形成，且实验(p_S,p_I)轨迹与线性衰减相似性的理论曲线高度吻合。最后，我们证明这些限制在两种显著更复杂的场景（卷积神经网络和先进视觉语言模型）中依然存在，确认有限分辨率相似性是基本的信息约束，而非玩具模型产物。这些结果为泛化-识别权衡提供了精确理论，并阐明了语义分辨率如何塑造深度网络和大脑的表示能力。

</details>


### [155] [ss-Mamba: Semantic-Spline Selective State-Space Model](https://arxiv.org/abs/2506.14802)
**中文标题：ss-Mamba：基于语义样条的选择性状态空间模型**

*Zuochen Ye*

主要分类: cs.LG

摘要简述: 本文提出ss-Mamba模型，通过结合语义感知嵌入和自适应样条时间编码，在选择性状态空间框架中提升时间序列预测性能，显著降低计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer模型在时间序列预测中计算复杂度高，且缺乏对语义信息和复杂时间模式的动态捕捉能力。ss-Mamba旨在解决这些问题，提供高效且可解释的预测方案。

研究方法: ss-Mamba基于选择性状态空间模型（Mamba），引入预训练语言模型的语义嵌入和样条KAN网络，动态捕捉复杂季节性和非平稳时间效应。

研究结果: 实验证明，ss-Mamba在准确性、鲁棒性和可解释性上优于传统Transformer模型，同时计算复杂度从二次降至线性。

研究结论: ss-Mamba是一种高效且多功能的时间序列预测模型，为传统Transformer提供了计算高效且性能优越的替代方案。

中文摘要: 我们提出了ss-Mamba，一种新颖的基础模型，通过将语义感知嵌入和自适应样条时间编码整合到选择性状态空间建模框架中，提升了时间序列预测性能。基于Transformer架构的最新成功，ss-Mamba采用Mamba选择性状态空间模型作为高效替代方案，在保持可比性能的同时，将计算复杂度从二次降至线性。通过预训练语言模型初始化的语义索引嵌入，能够通过有意义的语义先验有效泛化到未见过的序列。此外，基于样条的Kolmogorov-Arnold网络（KAN）动态且可解释地捕捉复杂的季节性和非平稳时间效应，提供了对传统时间特征编码的强大增强。大量实验评估证实，ss-Mamba在准确性、鲁棒性和可解释性上表现优异，展示了其作为传统基于Transformer的时间序列预测模型的高效多功能替代方案的能力。

</details>


### [156] [Training with Confidence: Catching Silent Errors in Deep Learning Training with Automated Proactive Checks](https://arxiv.org/abs/2506.14813)
**中文标题：训练有保障：通过自动化主动检查捕捉深度学习训练中的静默错误**

*Yuxuan Jiang,Ziming Zhou,Boyu Xu,Beijie Liu,Runhui Xu,Peng Huang*

主要分类: cs.LG

摘要简述: 本文提出TRAINCHECK框架，通过主动检查方法检测深度学习训练中的静默错误，成功识别多种错误并提供调试帮助。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习训练过程复杂，容易产生难以检测和诊断的静默错误，亟需一种自动化解决方案来主动发现并解决这些问题。

研究方法: TRAINCHECK通过自动推断适用于深度学习训练的不变量，利用这些不变量在训练过程中主动检测静默错误，并提供调试支持。

研究结果: TRAINCHECK在复现的20种真实静默错误中成功检测出18种，并在单个训练迭代内完成检测，同时发现6个流行训练库中的未知错误。

研究结论: TRAINCHECK是一种有效的框架，能够显著提升深度学习训练中静默错误的检测能力，并为调试提供实用支持。

中文摘要: 深度学习（DL）模型的训练过程复杂，容易产生难以检测和诊断的静默错误。本文提出TRAINCHECK框架，采用主动检查方法解决静默训练错误。TRAINCHECK自动推断适用于DL训练的不变量，并利用这些不变量在训练过程中主动检测静默错误，同时提供调试帮助。为评估TRAINCHECK，我们复现了20种真实静默错误，涵盖多种根本原因。TRAINCHECK成功在单个训练迭代内检测出18种错误，并发现6个流行训练库中导致静默错误的未知缺陷。

</details>


### [157] [Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints](https://arxiv.org/abs/2506.14821)
**中文标题：在资源约束下通过工具使用增强视觉语言模型的详细视觉推理能力**

*Sunil Kumar,Bowen Zhao,Leo Dirac,Paulina Varshavskaya*

主要分类: cs.LG

摘要简述: 本文提出了一种通过强化学习（GRPO）训练小规模视觉语言模型（VLMs）使用外部工具（如放大）的方法，以解决资源受限下的详细视觉推理问题。该方法结合了GRPO学习、简单奖励结构、简化工具调用接口等策略，显著提升了模型在视觉问答任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型模型的推理能力取得了显著进展，但视觉语言模型（VLMs）在资源受限时仍难以进行详细的视觉推理。本文旨在通过引入外部工具（如放大）和优化训练策略，提升小规模模型在复杂视觉任务中的表现。

研究方法: 本文采用Group Relative Policy Optimization（GRPO）训练小规模VLMs，结合简单奖励结构、简化工具调用接口、为工具调用结果分配额外token，以及过采样视觉难度较高的训练数据。通过这些策略，模型能够更有效地利用外部工具（如放大）获取详细视觉信息。

研究结果: 与基线模型相比，本文提出的方法在部分视觉问答（VQA）任务中表现更优，得益于通过外部工具获取的详细视觉信息。

研究结论: 本文通过GRPO学习和工具调用优化，成功提升了小规模VLMs在资源受限条件下的详细视觉推理能力，为未来研究提供了实用方向。

中文摘要: 尽管大型模型的推理能力取得了巨大进展，视觉语言模型（VLMs）在资源受限时仍难以进行详细的视觉推理。为解决这一挑战，我们借鉴了Deepseek-r1等方法，采用Group Relative Policy Optimization（GRPO）训练小规模模型，使其能够使用放大等外部工具。通过结合GRPO学习、简单奖励结构、简化工具调用接口、为工具调用结果分配额外token，以及过采样视觉难度较高的训练数据，我们取得了显著效果。与规模相近的基线模型相比，该方法在部分视觉问答（VQA）任务中表现更优，这得益于从外部工具获取的详细视觉信息。

</details>


### [158] [FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models](https://arxiv.org/abs/2506.14824)
**中文标题：FedNano：面向预训练多模态大语言模型的轻量级联邦调优**

*Yao Zhang,Hewei Gao,Haokun Chen,Weiguo Li,Yunpu Ma,Volker Tresp*

主要分类: cs.LG

摘要简述: FedNano是一种轻量级联邦学习框架，通过集中服务器端的大型语言模型（LLM）并引入轻量级客户端模块NanoEdge，解决了多模态大语言模型（MLLMs）在联邦学习中的计算、存储和通信挑战。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在现实场景中面临分布式数据和隐私保护问题，而传统联邦学习方法因模型规模过大无法直接应用于MLLMs。

研究方法: FedNano将LLM集中在服务器端，客户端仅部署轻量级模块NanoEdge，包含模态特定编码器、连接器和低秩适配器NanoAdapters，显著减少存储和通信开销。

研究结果: 实验表明，FedNano将客户端存储需求降低95%，通信开销仅为模型参数的0.01%，并在异构数据和资源限制下优于现有联邦学习基线。

研究结论: FedNano填补了MLLMs规模与联邦学习可行性之间的鸿沟，为可扩展的去中心化多模态AI系统提供了解决方案。

中文摘要: 多模态大语言模型（MLLMs）在多模态推理和跨模态检索等任务中表现出色，但在现实场景中因分布式多模态数据和严格的隐私要求而面临部署挑战。联邦学习（FL）通过无需集中数据的协作模型训练提供了解决方案。然而，为MLLMs实现FL存在重大挑战，包括高计算需求、有限的客户端能力、巨大的通信成本和异构客户端数据。现有FL方法假设客户端部署完整模型，这一假设因MLLMs的巨大规模和通信需求而失效。为解决这些限制，我们提出FedNano，首个将LLM集中在服务器端并引入轻量级模块NanoEdge的FL框架。NanoEdge采用模态特定编码器、连接器和可训练的低秩适配器NanoAdapters。这一设计无需在客户端部署LLM，将客户端存储减少95%，并将通信开销限制为仅模型参数的0.01%。通过仅传输紧凑的NanoAdapter更新，FedNano处理异构客户端数据和资源限制的同时保护隐私。实验表明，FedNano优于先前的FL基线，填补了MLLMs规模与FL可行性之间的鸿沟，实现了可扩展的去中心化多模态AI系统。

</details>


### [159] [Optimization of bi-directional gated loop cell based on multi-head attention mechanism for SSD health state classification model](https://arxiv.org/abs/2506.14830)
**中文标题：基于多头注意力机制的双向门控循环单元优化及其在SSD健康状态分类模型中的应用**

*Zhizhao Wen,Ruoxin Zhang,Chao Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种结合多头注意力机制的BiGRU-MHA混合模型，用于提升SSD健康状态分类的准确性和稳定性。实验显示该模型在训练集和测试集上分别达到92.70%和92.44%的分类准确率，泛化能力强，AUC为0.94。


<details>
  <summary>详细信息</summary>
研究动机: SSD健康状态预测对数据可靠性至关重要，但传统模型存在泛化能力不足的问题。本研究旨在通过结合双向时序建模和多头注意力机制，提升模型的分类性能和泛化能力。

研究方法: 模型创新性地结合了BiGRU网络的双向时序建模能力和多头注意力机制。BiGRU捕捉SSD退化特征的前后依赖关系，多头注意力机制动态分配特征权重，增强对关键健康指标的敏感性。

研究结果: 实验结果表明，模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，性能差距仅0.26%，AUC为0.94，展现了优异的泛化能力和二分类性能。

研究结论: 该研究为SSD健康预测提供了新技术方案，解决了传统模型的泛化瓶颈，具有实际应用价值，可显著降低数据丢失风险并优化维护成本。

中文摘要: 针对SSD健康状态预测在数据可靠性保障中的关键作用，本研究提出了一种结合多头注意力机制的BiGRU-MHA混合模型，以提升存储设备健康分类的准确性和稳定性。该模型创新性地整合了时序特征提取和关键信息聚焦能力。具体而言，利用BiGRU网络的双向时序建模优势，捕捉SSD退化特征的前后依赖关系；同时，多头注意力机制动态分配特征权重，提高模型对关键健康指标的敏感性。实验结果显示，所提模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，性能差距仅为0.26%，表现出优异的泛化能力。进一步通过受试者工作特征（ROC）曲线分析，测试集的曲线下面积（AUC）为0.94，证实了模型的稳健二分类性能。该工作不仅为SSD健康预测提供了新的技术途径，还解决了传统模型的泛化瓶颈，为工业级存储系统的预防性维护提供了可验证的实用方法。结果表明，该模型能通过早期故障预警显著降低数据丢失风险，并帮助优化维护成本，支持云计算数据中心和边缘存储环境中可靠存储系统的智能决策构建。

</details>


### [160] [ETS: Open Vocabulary Electroencephalography-To-Text Decoding and Sentiment Classification](https://arxiv.org/abs/2506.14783)
**中文标题：ETS：开放词汇脑电图到文本解码与情感分类**

*Mohamed Masry,Mohamed Amen,Mohamed Elzyat,Mohamed Hamed,Norhan Magdy,Maram Khaled*

主要分类: cs.LG

摘要简述: 本研究提出ETS框架，结合脑电图（EEG）与眼动追踪数据，解决开放词汇文本生成和情感分类问题，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统非侵入式脑电图（EEG）解码自然语言的方法在开放词汇场景中表现不佳，噪声和变异性问题突出。本研究旨在通过结合EEG与眼动追踪数据，提升开放词汇文本生成和情感分类的性能。

研究方法: 提出ETS框架，整合EEG与同步眼动追踪数据，专注于开放词汇文本生成和情感分类任务。

研究结果: 模型在EEG到文本解码任务中BLEU和Rouge得分表现优异，情感分类任务F1分数提升10%，显著优于基线方法。

研究结论: ETS框架展示了处理多源数据的能力，为高性能开放词汇EEG到文本系统提供了潜力。

中文摘要: 使用非侵入式脑电图（EEG）从大脑活动中解码自然语言在神经科学和机器学习中仍是一个重大挑战，尤其是在开放词汇场景中，传统方法难以应对噪声和变异性问题。以往研究在小规模封闭词汇上取得了高准确率，但在开放词汇上表现不佳。本研究提出ETS框架，整合EEG与同步眼动追踪数据，解决两项关键任务：（1）开放词汇文本生成；（2）感知语言的情感分类。我们的模型在EEG到文本解码任务中BLEU和Rouge得分表现优异，情感分类任务F1分数提升10%，显著优于监督基线方法。此外，我们展示了该模型能够处理来自不同受试者和来源的数据，为高性能开放词汇EEG到文本系统展示了巨大潜力。

</details>


### [161] [Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective](https://arxiv.org/abs/2506.14965)
**中文标题：从跨领域视角重新审视强化学习在大型语言模型推理中的应用**

*Zhoujun Cheng,Shibo Hao,Tianyang Liu,Fan Zhou,Yutao Xie,Feng Yao,Yuexin Bian,Yonghao Zhuang,Nilabjo Dey,Yuheng Zha,Yi Gu,Kun Zhou,Yuqi Wang,Yuan Li,Richard Fan,Jianshu She,Chengqian Gao,Abulhair Saparov,Haonan Li,Taylor W. Killian,Mikhail Yurochkin,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

主要分类: cs.LG

摘要简述: 本文通过跨领域视角重新审视强化学习（RL）在大型语言模型（LLM）推理中的应用，提出Guru数据集和模型，展示RL在不同推理领域的表现差异，并实现公开数据训练的SOTA性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前关于RL提升LLM推理的研究主要集中在数学和代码领域，缺乏对其他推理领域的广泛探索。本文旨在填补这一空白，通过构建多领域数据集和模型，验证RL在通用推理中的潜力。

研究方法: 作者构建了Guru数据集，包含92K个经过验证的跨领域推理示例（数学、代码、科学、逻辑、模拟和表格），并通过领域特定的奖励设计、去重和过滤确保数据质量。基于此，系统研究了RL在不同领域的表现，并训练了Guru-7B和Guru-32B模型。

研究结果: 实验表明，RL在不同领域的表现存在显著差异：预训练常见的领域（如数学、代码、科学）可通过跨领域RL训练受益，而预训练较少的领域（如逻辑、模拟、表格）需领域内训练才能提升性能。Guru模型在17项任务中超越基线7.9%和6.7%，并在复杂任务上显著提升Pass@k性能。

研究结论: RL不仅能激发预训练模型的知识，还能促进新技能的习得，尤其在预训练数据较少的领域。Guru数据集和模型为通用推理研究提供了新工具和基准。

中文摘要: 强化学习（RL）已成为提升大型语言模型（LLM）推理能力的有前景方法，但现有研究多集中于数学和代码领域，限制了对其在通用推理中广泛适用性的理解。关键挑战在于缺乏跨多样推理领域的可靠、可扩展的RL奖励信号。我们提出了Guru，一个包含92K个验证示例的跨领域RL推理数据集，涵盖数学、代码、科学、逻辑、模拟和表格六个领域，通过领域特定奖励设计、去重和过滤确保RL训练的可靠性和有效性。基于Guru，我们系统性地重新审视了RL在LLM推理中的表现，发现不同领域间存在显著差异。例如，尽管先前研究认为RL主要激发预训练模型的已有知识，我们的结果表明更复杂的模式：预训练常见的领域（数学、代码、科学）可通过跨领域RL训练受益，而预训练较少的领域（逻辑、模拟、表格）需领域内训练才能实现显著性能提升，表明RL可能促进真实技能的习得。最后，我们提出了Guru-7B和Guru-32B模型，在公开数据训练的开放模型中实现了SOTA性能，在六领域17项任务评估中分别超越最佳基线7.9%和6.7%。我们还展示了模型能有效提升基础模型的Pass@k性能，尤其在预训练数据中较少出现的复杂任务上。我们发布了数据、模型、训练和评估代码，以促进通用推理研究：https://github.com/LLM360/Reasoning360

</details>


### [162] [Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size](https://arxiv.org/abs/2506.15025)
**中文标题：大型语言模型中嵌入学习率的最优选择：词汇量的影响**

*Soufiane Hayou,Liyuan Liu*

主要分类: cs.LG

摘要简述: 本文研究了词汇量对大型语言模型训练动态的影响，揭示了词汇量增加时训练动态在μP和大词汇（LV）两种机制间的过渡，并提出了LV机制下嵌入学习率与隐藏学习率的最优比例应为Θ(√width)，与μP的预测不同。实验验证了该理论，并在1B模型上展示了其优势。


<details>
  <summary>详细信息</summary>
研究动机: 预训练大型语言模型成本高昂，现有方法如μP通过参数化模型权重和学习率实现了超参数的可迁移性，但在实际应用中存在局限性，尤其是词汇量远大于宽度时。本文旨在分析词汇量对训练动态的影响，填补μP理论的不足。

研究方法: 本文通过理论分析词汇量对训练动态的影响，提出词汇量增加时训练动态在μP和LV机制间的过渡。进一步推导出LV机制下嵌入学习率与隐藏学习率的最优比例应为Θ(√width)，并通过实验验证理论。

研究结果: 研究发现，在LV机制下，嵌入学习率与隐藏学习率的最优比例接近Θ(√width)，与μP预测的Θ(width)不同。实验验证了该理论，并在1B模型上展示了其优势。

研究结论: 本文揭示了词汇量对训练动态的重要影响，提出了LV机制下的最优学习率比例，为大型语言模型的高效训练提供了理论支持。

中文摘要: 预训练大型语言模型是一个成本高昂的过程。为了提高效率，已有多种方法用于优化模型架构/参数化和硬件使用。在参数化方面，μP（最大更新参数化）通过参数化模型权重和学习率，使得超参数可随宽度（嵌入维度）迁移：超参数可在小模型上调试后直接用于更大模型。尽管μP在实践中表现优异，但最近的研究发现其在大型语言模型中的应用存在矛盾现象。μP理论的局限性在于假设输入维度（词汇量）在宽度趋近无穷时固定，而实际中词汇量通常远大于宽度。本文通过理论分析词汇量对训练动态的影响，揭示了随着词汇量增加，训练动态在μP机制和另一种称为大词汇（LV）机制之间过渡的现象。在LV机制中，嵌入学习率与隐藏学习率的最优比例约为Θ(√width)，与μP预测的Θ(width)不同，且与已有实证结果接近。我们通过实验验证了该理论，并在1B模型上展示了所提比例规则的优势。

</details>


### [163] [Determinação Automática de Limiar de Detecção de Ataques em Redes de Computadores Utilizando Autoencoders](https://arxiv.org/abs/2506.14937)
**中文标题：利用自编码器自动确定计算机网络攻击检测阈值**

*Luan Gonçalves Miranda,Pedro Ivo da Cruz,Murilo Bellezoni Loiola*

主要分类: cs.LG

摘要简述: 本文提出了一种利用机器学习算法自动确定自编码器在计算机网络攻击检测中阈值的方法，以解决数据不平衡问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前，使用自编码器的异常检测系统在解决数据不平衡等问题上表现出潜力，但其分类阈值的非标准化直接影响检测性能。因此，本文旨在自动定义这一阈值。

研究方法: 研究评估了三种机器学习算法：K近邻算法、K均值算法和支持向量机，用于自动确定自编码器的分类阈值。

研究结果: 实验结果表明，所提出的方法能够有效优化自编码器在攻击检测中的性能。

研究结论: 通过自动定义分类阈值，本文方法显著提升了自编码器在异常检测中的效果，为网络安全提供了更可靠的解决方案。

中文摘要: 目前，使用自编码器（AE）的异常检测系统等数字安全机制在解决数据不平衡等固有问题上显示出巨大潜力。由于AE使用非标准化的分离阈值对提取的重构误差进行分类，该阈值的定义直接影响检测过程的性能。因此，本文提出利用一些机器学习算法自动定义这一阈值。为此，评估了三种算法：K近邻算法、K均值算法和支持向量机。

</details>


### [164] [Flat Channels to Infinity in Neural Loss Landscapes](https://arxiv.org/abs/2506.14951)
**中文标题：Error**

*Flavio Martinelli,Alexander Van Meegen,Berfin Şimşek,Wulfram Gerstner,Johanni Brea*

主要分类: cs.LG

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [165] [When and How Unlabeled Data Provably Improve In-Context Learning](https://arxiv.org/abs/2506.15329)
**中文标题：未标记数据何时以及如何可证明地提升上下文学习**

*Yingcong Li,Xiangyu Chang,Muti Kara,Xiaofeng Liu,Amit Roy-Chowdhury,Samet Oymak*

主要分类: cs.LG

摘要简述: 本文探讨了在上下文学习（ICL）中，未标记数据如何以及在何种情况下能够提升性能。研究发现，多层或循环的Transformer模型能有效利用未标记数据，而单层线性注意力模型则无法做到。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，研究表明即使在演示数据标签缺失或错误的情况下，上下文学习（ICL）仍然有效。本文旨在从理论上揭示这种能力的机制，并探讨未标记数据如何提升ICL的性能。

研究方法: 研究采用二元高斯混合模型（GMM）生成演示数据，并部分缺失标签。通过理论分析，比较了单层线性注意力模型与多层或循环Transformer模型的表现，发现后者能通过隐式构造多项式形式的估计器有效利用未标记数据。

研究结果: 研究发现，多层或循环Transformer模型能够通过深度相关的多项式表达利用未标记数据，且其性能随深度指数级提升。实验表明，该方法在半监督表格学习任务中显著优于单次推理的标准方法。

研究结论: 本文证明了深度或循环结构的Transformer模型能够有效利用未标记数据提升上下文学习性能，为半监督学习提供了新的理论支持和实践方法。

中文摘要: 最近的研究表明，即使演示数据中存在缺失或错误的标签，上下文学习（ICL）仍然可以高效。为了揭示这一能力的机制，我们研究了一个典型场景，其中演示数据由二元高斯混合模型（GMM）生成，且部分标签缺失。我们提供了全面的理论分析，结果表明：（1）单层线性注意力模型的损失函数能够恢复最优的全监督估计器，但完全无法利用未标记数据；（2）相比之下，多层或循环的Transformer模型能够通过隐式构造形如$\sum_{i\ge 0} a_i (X^\top X)^iX^\top y$的估计器（其中$X$和$y$分别表示特征和部分观测的标签，缺失项设为零）有效利用未标记数据。我们描述了与深度相关的多项式类别，并将其与半监督学习中常用的伪标签迭代算法——期望最大化（EM）联系起来。重要的是，主导多项式幂随深度指数增长，因此轻微的深度或循环即可满足需求。作为理论的应用，我们提出通过循环现成的表格基础模型来增强其半监督能力。在真实数据集上的广泛评估表明，我们的方法在半监督表格学习任务中显著优于标准的单次推理方法。

</details>


### [166] [Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework](https://arxiv.org/abs/2506.15538)
**中文标题：利用PRISM捕捉多义性：一种多概念特征描述框架**

*Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M. -C. Höhne,Oliver Eberle*

主要分类: cs.LG

摘要简述: 本文提出PRISM框架，用于捕捉神经网络特征的多义性，解决了现有方法假设神经元单义性的局限性，显著提升了特征描述的准确性和全面性。


<details>
  <summary>详细信息</summary>
研究动机: 当前神经网络特征描述方法存在两大问题：鲁棒性不足和假设神经元仅编码单一概念（单义性），而实际神经元常具有多义性。这种假设限制了特征描述的表达能力，无法全面捕捉模型内部行为。

研究方法: 本文提出PRISM（多义性特征识别与评分方法）框架，通过为多义性和单义性特征提供更细致的描述，克服了现有方法的局限性。

研究结果: 在语言模型上的实验表明，PRISM生成的特征描述更准确和忠实，显著提升了描述质量和多义性捕捉能力。

研究结论: PRISM框架通过捕捉特征的多义性，显著改进了神经网络特征描述的全面性和准确性，为模型可解释性研究提供了新工具。

中文摘要: 自动化可解释性研究旨在识别神经网络特征编码的概念，以增强对人类模型行为的理解。当前的特征描述方法面临两大挑战：鲁棒性有限，以及假设每个神经元仅编码单一概念（单义性），尽管越来越多的证据表明神经元常具有多义性。这种假设限制了特征描述的表达能力，使其无法全面捕捉模型内部行为。为此，我们提出了多义性特征识别与评分方法（PRISM），这是一种捕捉神经网络特征固有复杂性的新框架。与先前为每个特征分配单一描述的方法不同，PRISM为多义性和单义性特征提供了更细致的描述。我们将PRISM应用于语言模型，并通过与现有方法的广泛基准测试，证明我们的方法能生成更准确和忠实的特征描述，提升了整体描述质量（通过描述评分）和多义性存在时捕捉不同概念的能力（通过多义性评分）。

</details>


### [167] [Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits](https://arxiv.org/abs/2506.14988)
**中文标题：基于探测的多智能体多臂老虎机公平算法**

*Tianyi Xu,Jiaxin Liu,Zizhan Zheng*

主要分类: cs.LG

摘要简述: 本文提出了一种多智能体多臂老虎机框架，通过引入探测机制在保证公平性的同时最大化系统性能。离线与在线场景下分别设计了算法，实验证明其优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 在多智能体多臂老虎机问题中，如何在信息有限的情况下实现公平分配并最大化系统性能是一个关键挑战。本文旨在解决这一问题。

研究方法: 1. 离线场景：利用子模性质设计贪心探测算法，具有性能保证。2. 在线场景：开发了一种算法，在保证公平性的同时实现次线性遗憾。

研究结果: 实验表明，所提方法在合成和真实数据集上均优于基线方法，实现了更好的公平性和效率。

研究结论: 本文提出的探测框架和算法在多智能体多臂老虎机问题中有效平衡了公平性与性能，为实际应用提供了可行方案。

中文摘要: 本文提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平性同时最大化系统整体性能。该场景下的关键挑战在于信息有限时的决策问题。为此，我们引入了一种新颖的探测框架，在分配前策略性地收集选定臂的信息。在离线场景（已知奖励分布）中，利用子模性质设计了一种具有性能保证的贪心探测算法。针对更复杂的在线场景，开发了一种在保证公平性的同时实现次线性遗憾的算法。在合成和真实数据集上的大量实验表明，我们的方法优于基线方法，实现了更好的公平性和效率。

</details>


### [168] [LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](https://arxiv.org/abs/2506.15606)
**中文标题：LoX：低秩外推增强LLM对抗微调的安全性**

*Gabrel J. Perin,Runjin Chen,Xuxi Chen,Nina S. T. Hirata,Zhangyang Wang,Junyuan Hong*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LoX的无训练方法，通过低秩外推增强大语言模型（LLM）的安全性，显著降低微调攻击的成功率，同时保持模型对新任务的适应性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管通过对齐技术提升了LLM的安全性，但后续微调仍可能破坏其安全保护，即使微调数据看似无害。本文旨在解决这一脆弱性问题。

研究方法: 提出低秩外推（LoX）方法，通过外推对齐LLM的安全子空间，增强其对抗微调攻击的鲁棒性，无需额外训练。

研究结果: 实验表明，LoX在面对良性或恶意微调攻击时，攻击成功率（ASR）绝对降低了11%至54%，同时不影响模型的任务适应性。

研究结论: LoX通过将LLM参数移动到更平坦的区域，减少对扰动的敏感性，显著提升了模型的安全性。

中文摘要: 大语言模型（LLM）在现实应用中不可或缺，但其广泛使用引发了显著的安全问题，尤其是在应对社会有害问题时。尽管通过对齐技术提升了模型安全性，但后续微调仍可能破坏这些保护，即使微调数据看似无害。本文实证表明，这种脆弱性源于LLM参数中安全关键的低秩子空间对微调的敏感性。基于此，我们提出了一种无需训练的新方法——低秩外推（LoX），通过外推对齐LLM的安全子空间来增强安全性鲁棒性。实验结果证实了LoX的有效性，显著提升了对抗良性和恶意微调攻击的鲁棒性，同时保持了模型对新任务的适应性。例如，LoX在面对良性和恶意微调攻击时，攻击成功率（ASR）绝对降低了11%至54%。通过分析参数的ASR分布，我们将LoX的成功归因于外推将LLM参数移动到更平坦的区域，从而减少了对扰动的敏感性。代码可在github.com/VITA-Group/LoX获取。

</details>


### [169] [AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning](https://arxiv.org/abs/2506.15651)
**中文标题：AutoRule：基于推理链提取的规则奖励提升偏好学习**

*Tevin Wang,Chenyan Xiong*

主要分类: cs.LG

摘要简述: AutoRule是一种自动化方法，通过从用户偏好中提取规则并转化为奖励，提升强化学习性能。实验显示其在任务中表现优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于规则的奖励方法依赖人工设计规则，效率低下且难以扩展。AutoRule旨在通过自动化提取规则，提升强化学习从人类反馈中的性能。

研究方法: AutoRule分为三个阶段：利用推理模型解释用户偏好，从推理链中提取候选规则，并将其合成为统一规则集。随后，使用语言模型验证器计算规则满足度，作为辅助奖励与学习奖励模型结合优化策略。

研究结果: 实验表明，AutoRule在AlpacaEval2.0上相对基线方法提升了28.6%的胜率，在MT-Bench子集上提升了6.1%的第二轮表现。规则与数据集偏好一致，且减少了奖励滥用现象。

研究结论: AutoRule通过自动化规则提取和验证，显著提升了强化学习性能，同时减少了奖励滥用问题。提取的规则能捕捉不同数据集的独特价值。

中文摘要: 基于规则的奖励为从人类反馈中改进强化学习（RLHF）提供了有前景的策略，但现有方法通常依赖人工规则设计。我们提出了AutoRule，一种完全自动化的方法，用于从偏好反馈中提取规则并将其转化为基于规则的奖励。AutoRule的提取过程分为三个阶段：利用推理模型解释用户偏好，从这些解释的推理链中识别候选规则，并将其合成为统一规则集。利用最终规则集，我们使用语言模型验证器计算每个输出满足的规则比例，将此指标作为辅助奖励与学习奖励模型结合优化策略。在Llama-3-8B模型上使用AutoRule训练，相比仅使用学习奖励模型的GRPO基线，在AlpacaEval2.0上实现了28.6%的相对胜率提升，在MT-Bench子集上实现了6.1%的第二轮表现提升。分析表明，提取的规则与数据集偏好高度一致。AutoRule在两次运行中表现出比学习奖励模型更少的奖励滥用现象。案例研究表明，提取的规则能捕捉不同数据集的独特价值。规则集和代码已开源。

</details>


### [170] [Dense SAE Latents Are Features, Not Bugs](https://arxiv.org/abs/2506.15679)
**中文标题：密集SAE潜在特征是特性而非缺陷**

*Xiaoqing Sun,Alessandro Stolfo,Joshua Engels,Ben Wu,Senthooran Rajamanoharan,Mrinmaya Sachan,Max Tegmark*

主要分类: cs.LG

摘要简述: 研究发现稀疏自编码器（SAE）中的密集潜在特征并非训练噪声，而是具有语义意义的模型表征，对语言模型计算具有功能性作用。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏自编码器（SAE）旨在通过稀疏约束提取语言模型的可解释特征，但许多潜在特征频繁激活（即密集），引发其是否为训练伪影的疑问。本文旨在系统研究密集潜在特征的几何、功能和起源。

研究方法: 首先分析密集潜在特征的几何结构及其在残差流中的重建方向，并通过消融实验验证其固有性；其次提出密集潜在特征的分类学，识别与位置跟踪、上下文绑定等相关的类别；最后分析这些特征在模型各层的演变规律。

研究结果: 密集潜在特征形成对映对，重建残差流中的特定方向，且消融其子空间会抑制新密集特征的出现。分类学揭示了其与位置跟踪、语义绑定等功能的相关性，并在模型各层中呈现从结构特征到语义特征再到输出信号的演变。

研究结论: 密集潜在特征是语言模型计算的功能性组成部分，不应被视为训练噪声。

中文摘要: 稀疏自编码器（SAE）旨在通过稀疏约束从语言模型中提取可解释特征。理想情况下，SAE训练应得到稀疏且语义有意义的潜在特征。然而，许多SAE潜在特征频繁激活（即密集），引发其是否为训练伪影的担忧。本文系统研究了密集潜在特征的几何、功能和起源，表明它们不仅是持续存在的，而且常反映有意义的模型表征。首先，我们发现密集潜在特征倾向于形成对映对，重建残差流中的特定方向，且消融其子空间会抑制新密集特征在重新训练的SAE中出现——表明高密度特征是残差空间的固有属性。其次，我们提出密集潜在特征的分类学，识别与位置跟踪、上下文绑定、熵调节、字母特定输出信号、词性和主成分重建相关的类别。最后，我们分析这些特征在各层的演变，揭示了从早期层的结构特征到中间层的语义特征，再到模型最后层的输出信号的转变。我们的结果表明，密集潜在特征在语言模型计算中具有功能性作用，不应被视为训练噪声。

</details>


### [171] [Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment](https://arxiv.org/abs/2506.15019)
**中文标题：基于锐度正则化的稳定CDE自编码器用于脓毒症治疗的离线强化学习**

*Yue Gao*

主要分类: cs.LG

摘要简述: 本文提出一种稳定的CDE自编码器方法，通过锐度正则化解决离线强化学习在脓毒症治疗中的训练不稳定问题，实验表明该方法能生成与临床评分强相关的表示，并显著提升策略性能。


<details>
  <summary>详细信息</summary>
研究动机: 脓毒症治疗的有效强化学习依赖于从ICU不规则时间序列中学习稳定且具有临床意义的表示。以往研究忽略了序列表示训练不稳定性及其对策略性能的负面影响。

研究方法: 采用控制微分方程（CDE）状态表示，通过早期停止或稳定化方法确保训练稳定性，并通过与临床评分（SOFA、SAPS-II、OASIS）的相关性正则化强制锐度感知表示。

研究结果: 实验显示，稳定的CDE自编码器生成的表示与临床评分强相关，并支持性能优越的强化学习策略（WIS回报>0.9），而不稳定的表示导致策略失败（WIS回报≈0）。

研究结论: 研究为临床强化学习中CDE编码不规则医学时间序列提供了实用指南，强调了序列表示学习中训练稳定性的重要性。

中文摘要: 脓毒症治疗的有效强化学习依赖于从ICU不规则时间序列中学习稳定且具有临床意义的表示。以往研究虽探索了表示学习，但忽略了序列表示训练不稳定性及其对策略性能的负面影响。本文证明，控制微分方程（CDE）状态表示在满足两个关键因素时能实现强化的RL策略：（1）通过早期停止或稳定化方法确保训练稳定性；（2）通过与临床评分（SOFA、SAPS-II、OASIS）的相关性正则化强制锐度感知表示。在MIMIC-III脓毒症队列上的实验表明，稳定的CDE自编码器生成的表示与临床评分强相关，并支持性能优越的RL策略（WIS回报>0.9），而不稳定的CDE表示导致表示退化和策略失败（WIS回报≈0）。潜在空间的可视化显示，稳定的CDE不仅区分了存活与非存活轨迹，还揭示了清晰的临床评分梯度，而不稳定训练则无法捕捉这些模式。这些发现为临床RL中使用CDE编码不规则医学时间序列提供了实用指南，强调了序列表示学习中训练稳定性的重要性。

</details>


### [172] [SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models](https://arxiv.org/abs/2506.15021)
**中文标题：SFT-GO：基于分组优化的大型语言模型监督微调方法**

*Gyuhak Kim,Sumiran Singh Thakur,Su Min Park,Wei Wei,Yujia Bao*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SFT-GO的新方法，通过基于令牌重要性的分组优化改进大型语言模型的监督微调，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的监督微调方法通常将所有令牌视为同等重要，忽略了任务关键信息可能仅集中在部分令牌中的事实。SFT-GO旨在通过分组优化解决这一问题。

研究方法: SFT-GO根据令牌的重要性值对样本中的令牌进行分组，并使用最差组损失与标准交叉熵损失的加权组合优化模型，从而自适应地强调最具挑战性的令牌组。

研究结果: 实验表明，SFT-GO在多种令牌分组策略下均优于基线方法，且在不同数据集和基础模型上表现稳健。

研究结论: SFT-GO通过分组优化显著提升了监督微调的效果，为大型语言模型的性能改进提供了新思路。

中文摘要: 监督微调（SFT）是调整大型语言模型（LLM）以符合人类期望和特定下游任务的关键步骤。然而，现有SFT方法通常将每个训练实例视为均匀序列，对所有令牌赋予相同重要性，忽略了任务关键信息可能仅集中在部分令牌中的事实。为解决这一问题，我们提出了基于分组优化的监督微调方法（SFT-GO）。SFT-GO根据令牌的重要性值对样本中的令牌进行分组，并使用最差组损失与标准交叉熵损失的加权组合优化模型，从而自适应地强调最具挑战性的令牌组并改善学习动态。我们提供了SFT-GO收敛速率的理论分析，证明了其高效性。实验上，我们采用三种不同的令牌分组策略，结果表明SFT-GO训练的模型在多个流行LLM基准测试中均优于基线方法。这些改进在不同数据集和基础模型上均保持一致，证明了我们方法的稳健性和有效性。

</details>


### [173] [CACTUS as a Reliable Tool for Early Classification of Age-related Macular Degeneration](https://arxiv.org/abs/2506.14843)
**中文标题：CACTUS：一种可靠的年龄相关性黄斑变性早期分类工具**

*Luca Gherardini,Imre Lengyel,Tunde Peto,Caroline C. W. Klaverd,Magda A. Meester-Smoord,Johanna Maria Colijnd,EYE-RISK Consortium,E3 Consortium,Jose Sousa*

主要分类: cs.LG

摘要简述: 本文介绍了一种名为CACTUS的工具，用于早期分类年龄相关性黄斑变性（AMD），其通过结合遗传、饮食、临床和人口统计学因素，提供可解释性和灵活性，优于传统机器学习模型。


<details>
  <summary>详细信息</summary>
研究动机: 年龄相关性黄斑变性（AMD）影响数百万老年人，早期诊断至关重要，但现有机器学习模型在数据不完整或有限时表现不佳，且缺乏透明度和可信度。因此，需要一种更可靠的分类工具。

研究方法: 研究团队开发了CACTUS工具，通过整合多维度数据（如遗传、饮食、临床和人口统计学因素），并结合视网膜图像和患者症状报告，提供可解释的分类结果。

研究结果: CACTUS在AMD分类中表现优于标准机器学习模型，能够识别关键因素并提供可信结果，同时帮助消除不相关或有偏见的数据。

研究结论: CACTUS为AMD早期分类提供了一种可靠且可解释的工具，有助于临床决策和减少偏见。

中文摘要: 机器学习（ML）被用于解决疾病分类和预测等任务，但其效果依赖于大量完整数据。然而，医疗数据通常有限或不完整，可能影响模型性能。此外，解决方案的可信度因数据集而异，部分ML模型缺乏透明度，增加了理解和使用的难度。在年龄相关性黄斑变性（AMD）的案例中，早期诊断至关重要，因为目前尚无有效治疗方法逆转病情进展。AMD的诊断需要结合视网膜图像和患者症状报告。为此，我们提出了“综合抽象与分类工具”（CACTUS），旨在改进AMD分期分类。CACTUS具有可解释性和灵活性，优于标准ML模型，通过识别关键因素和提供可信结果来增强决策能力。CACTUS识别的重要特征可与现有医学知识对比。通过剔除不相关或有偏见的数据，我们为临床医生提供了反馈和解决偏见的场景。

</details>


### [174] [Sequential Policy Gradient for Adaptive Hyperparameter Optimization](https://arxiv.org/abs/2506.15051)
**中文标题：自适应超参数优化的序列策略梯度方法**

*Zheng Li,Jerry Cheng,Huanying Helen Gu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SPG的轻量级在线超参数优化方法，通过扩展基础模型生成状态-动作轨迹，显著降低了计算成本，并在多个数据集上实现了性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习方法在神经架构搜索和超参数优化中因高昂的时间和计算成本难以广泛应用，本文旨在解决这一问题。

研究方法: 提出Sequential Policy Gradient（SPG）方法，通过临时模块扩展基础模型，单次前向传递生成状态-动作轨迹，实现轻量级在线优化。

研究结果: 实验表明，SPG在多个数据集（ImageNet、COCO、GLUE等）上显著提升模型性能（+0.2%~7%），同时计算成本极低。

研究结论: SPG是一种高效、低成本的超参数优化方法，适用于工业场景，并在多种任务中表现优异。

中文摘要: 强化学习在神经架构搜索和超参数优化中至关重要，但传统方法因高昂的时间和计算成本阻碍了广泛应用。受DeepSeek-V3多令牌预测架构启发，我们提出了一种轻量级在线超参数优化的新轨迹生成范式——序列策略梯度建模（SPG）。与传统策略梯度方法不同，SPG通过临时模块扩展基础模型，使其能够单次前向传递生成状态-动作（填充）轨迹。实验表明，使用SPG重新训练的模型在原始数据集上性能提升，且优于标准迁移微调。我们在计算机视觉（ImageNet、COCO）、自然语言处理（GLUE、SQuAD）和音频（SUPERB）五个数据集上评估了SPG的工业适用性。该方法在广泛采用的模型中表现一致提升，性能增益达+0.2%~7%，且计算成本极低。完全可复现的代码和预训练模型：https://huggingface.co/UniversalAlgorithmic/SPG。

</details>


### [175] [Singular Value Decomposition on Kronecker Adaptation for Large Language Model](https://arxiv.org/abs/2506.15251)
**中文标题：基于Kronecker适应的奇异值分解在大型语言模型中的应用**

*Yee Hin Chong,Peng Qu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SoKA的参数高效微调方法，结合Kronecker乘积张量分解与SVD驱动的初始化及动态秩选择，显著减少了训练参数数量并提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型预训练Transformer模型在多种任务中表现优异，但全参数微调带来高昂的存储、内存和计算成本。现有参数高效微调方法存在推理延迟、收敛不理想或固定秩选择不匹配任务复杂度等问题。

研究方法: SoKA方法结合Kronecker乘积张量分解与SVD驱动的初始化，通过动态秩选择算法剪枝不重要成分，提取权重更新的主成分到紧凑的Kronecker因子中。

研究结果: 在LLaMA2-7B模型上的实验表明，SoKA仅需0.99M可训练参数，比LoRA/PiSSA少25%，性能相当或更优，且收敛更快、梯度更稳定。

研究结论: SoKA是一种高效、稳健的大规模模型适应方法，显著降低了计算成本并提升了性能。

中文摘要: 大型预训练Transformer模型在多样化的语言和推理任务中取得了最先进的结果，但全参数微调带来了巨大的存储、内存和计算开销。参数高效微调（PEFT）方法通过学习少量任务特定参数来降低这些成本，但现有方法要么引入推理延迟（适配器模块），要么因随机初始化的低秩更新而收敛不理想，或依赖可能不匹配任务复杂度的固定秩选择（基于Kronecker的分解）。
我们提出了SoKA（基于Kronecker适应的奇异值分解），一种新颖的PEFT策略，结合了Kronecker乘积张量分解与SVD驱动的初始化及频谱感知的动态秩选择。我们的Kronecker乘积SVD（KPSVD）过程将权重更新的主成分提取到紧凑的Kronecker因子中，同时通过能量阈值和肘点准则的自适应秩选择算法剪枝不重要成分。
在LLaMA2-7B模型上的实验表明，SoKA仅需0.99M可训练参数，比LoRA/PiSSA少25%，同时性能相当或更优。此外，SoKA表现出更快的收敛速度和更稳定的梯度，突显了其在大规模模型适应中的稳健性和高效性。

</details>


### [176] [Unlocking Post-hoc Dataset Inference with Synthetic Data](https://arxiv.org/abs/2506.15271)
**中文标题：利用合成数据解锁事后数据集推断**

*Bihe Zhao,Pratyush Maini,Franziska Boenisch,Adam Dziedzic*

主要分类: cs.LG

摘要简述: 本文提出了一种通过合成数据解决数据集推断（DI）中私有验证集缺失问题的方法，利用生成的高质量合成数据作为验证集，显著提升了DI的实用性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的训练数据常未经授权从互联网抓取，侵犯了数据所有者的知识产权。数据集推断（DI）可识别训练数据是否被滥用，但现有方法依赖与训练数据分布匹配的私有验证集，实际中难以获取，限制了DI的应用。

研究方法: 通过训练基于后缀补全任务的数据生成器，生成高质量、多样化的合成数据作为验证集，并通过后校准缩小合成数据与真实数据的似然差距。

研究结果: 实验表明，生成的合成数据作为验证集能高置信度检测原始训练数据，同时保持低误报率，为数据版权主张提供了可靠依据。

研究结论: 该方法解决了DI中验证集缺失的难题，增强了数据所有者的维权能力，适用于实际法律纠纷。

中文摘要: 大型语言模型（LLMs）的强大能力主要归功于其海量训练数据，但这些数据常未经授权从互联网抓取，侵犯了数据所有者的知识产权。数据集推断（DI）通过识别可疑数据集是否用于训练，为数据所有者提供了验证手段。然而，现有DI方法需要一组与训练数据分布匹配的私有验证集，实际中此类数据难以获取，严重限制了DI的实用性。本研究通过合成生成所需的验证集解决了这一难题。我们的方法克服了两个关键障碍：（1）通过基于后缀补全任务训练的数据生成器，生成高质量、多样化的合成数据，准确反映原始分布；（2）通过后校准缩小合成数据与真实数据的似然差距。在多样文本数据集上的实验表明，使用生成的合成数据作为验证集，DI能高置信度检测原始训练数据，同时保持低误报率。这一结果为版权所有者提供了数据使用的合法主张依据，并证明了该方法在实际法律纠纷中的可靠性。代码详见：https://github.com/sprintml/PostHocDatasetInference。

</details>


### [177] [Pixel-level Certified Explanations via Randomized Smoothing](https://arxiv.org/abs/2506.15499)
**中文标题：基于随机平滑的像素级认证解释**

*Alaa Anani,Tobias Lorenz,Mario Fritz,Bernt Schiele*

主要分类: cs.LG

摘要简述: 本文提出了一种基于随机平滑的像素级认证解释框架，首次为任何黑盒归因方法提供像素级鲁棒性保证，通过稀疏化和平滑化归因图，将其重新表述为分割问题，并针对ℓ₂有界扰动认证每个像素的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的后验归因方法在解释深度学习预测时存在非鲁棒性问题，微小的输入扰动可能导致归因图显著变化，而预测结果保持不变。这种脆弱性降低了归因方法的可信度，亟需严格的像素级鲁棒性保证。

研究方法: 通过随机平滑技术，将归因图稀疏化和平滑化，将其重新建模为分割问题，并针对ℓ₂有界扰动认证每个像素的重要性。同时提出了三种评估指标，用于衡量认证鲁棒性、定位性和忠实性。

研究结果: 在5个ImageNet模型和12种归因方法上的广泛实验表明，所提出的认证归因方法具有鲁棒性、可解释性和忠实性，适用于下游任务。

研究结论: 本文提出的认证框架为像素级归因提供了鲁棒性保证，增强了归因方法的可信度和实用性，为下游任务提供了可靠支持。

中文摘要: 后验归因方法旨在通过突出影响输入像素来解释深度学习预测。然而，这些解释具有高度非鲁棒性：微小且不可察觉的输入扰动可能显著改变归因图，同时保持预测结果不变。这种脆弱性削弱了其可信度，亟需对像素级归因分数提供严格的鲁棒性保证。我们首次引入了一种基于随机平滑的认证框架，为任何黑盒归因方法提供像素级鲁棒性保证。通过稀疏化和平滑化归因图，我们将任务重新表述为分割问题，并针对ℓ₂有界扰动认证每个像素的重要性。我们还提出了三种评估指标，用于衡量认证鲁棒性、定位性和忠实性。在5个ImageNet模型和12种归因方法上的广泛实验表明，我们的认证归因具有鲁棒性、可解释性和忠实性，能够可靠地用于下游任务。代码见https://github.com/AlaaAnani/certified-attributions。

</details>


### [178] [Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation](https://arxiv.org/abs/2506.15309)
**中文标题：主动学习引导的序列到序列变分自编码器用于多靶点抑制剂生成**

*Júlia Vilalta-Mor,Alexis Molina,Laura Ortega Varga,Isaac Filella-Merce,Victor Guallar*

主要分类: cs.LG

摘要简述: 本文提出了一种结合主动学习与序列到序列变分自编码器的方法，用于生成针对多靶点的抑制剂分子，解决了药物发现中多目标优化的难题。


<details>
  <summary>详细信息</summary>
研究动机: 药物发现中同时优化分子以针对多个治疗靶点面临稀疏奖励和设计约束冲突的挑战，亟需一种高效方法以平衡化学多样性和多靶点亲和力。

研究方法: 采用主动学习范式，结合序列到序列变分自编码器，通过迭代扩展潜在空间的化学可行区域，并逐步基于多靶点对接阈值约束分子生成。

研究结果: 在针对三种冠状病毒主蛋白酶的研究中，该方法成功生成了结构多样的泛抑制剂候选分子，显著提升了有益化学空间的探索效率。

研究结论: 该框架为复杂多药理学景观的高效导航提供了通用路线图，将稀疏奖励的多目标药物设计问题转化为可计算任务。

中文摘要: 在药物发现中，同时优化分子以针对多个治疗靶点仍是一个重大挑战，尤其是由于稀疏奖励和设计约束的冲突。我们提出了一种结构化的主动学习范式，将序列到序列变分自编码器集成到迭代循环中，旨在平衡化学多样性、分子质量和多靶点亲和力。我们的方法交替扩展潜在空间的化学可行区域，并逐步基于日益严格的多靶点对接阈值约束分子。在一项针对三种相关冠状病毒主蛋白酶（SARS-CoV-2、SARS-CoV、MERS-CoV）的概念验证研究中，我们的方法高效生成了结构多样的泛抑制剂候选分子。我们证明，在主动学习流程中精心安排化学过滤器的时机和策略性放置，显著增强了对有益化学空间的探索，将稀疏奖励的多目标药物设计问题转化为可计算任务。因此，我们的框架为高效导航复杂的多药理学景观提供了通用路线图。

</details>


### [179] [Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI](https://arxiv.org/abs/2506.15408)
**中文标题：统一VXAI：可解释AI评估的系统性综述与框架**

*David Dembinsky,Adriano Lucieri,Stanislav Frolov,Hiba Najjar,Ko Watanabe,Andreas Dengel*

主要分类: cs.LG

摘要简述: 本文通过系统性文献综述提出VXAI框架，统一评估可解释AI（XAI）的方法，填补领域内标准化评估协议的空白。


<details>
  <summary>详细信息</summary>
研究动机: 现代AI系统（如深度神经网络）因复杂性和不透明性导致信任问题，可解释AI（XAI）虽提供解释，但缺乏标准化评估方法和共识。本文旨在填补这一空白。

研究方法: 采用PRISMA指南进行系统性文献综述，分析362篇相关文献，提出VXAI框架，包含41个功能相似的指标组和三维分类方案（解释类型、评估情境性和解释质量需求）。

研究结果: VXAI框架是目前最全面且结构化的XAI评估方法，支持系统化指标选择、方法间可比性，并为未来扩展提供灵活基础。

研究结论: VXAI框架为XAI评估提供了统一标准，促进领域内方法比较和未来发展。

中文摘要: 现代AI系统常依赖不透明的黑盒模型（如深度神经网络），其性能源于复杂的架构和数百万学习参数。尽管强大，其复杂性因缺乏透明度而引发信任问题。可解释AI（XAI）通过提供人类可理解的模型行为解释来解决这一问题。然而，为确保这些解释的实用性和可信度，必须对其进行严格评估。尽管XAI方法日益增多，该领域仍缺乏标准化评估协议和共识指标。为填补这一空白，我们遵循PRISMA指南进行系统性文献综述，并引入统一的可解释AI评估框架（VXAI）。我们识别了362篇相关文献，将其贡献归纳为41个功能相似的指标组，并提出一个三维分类方案（解释类型、评估情境性和解释质量需求）。VXAI框架提供了迄今为止最全面且结构化的XAI评估概述，支持系统化指标选择、促进方法间可比性，并为未来扩展提供灵活基础。

</details>


### [180] [Reward Models in Deep Reinforcement Learning: A Survey](https://arxiv.org/abs/2506.15421)
**中文标题：深度强化学习中的奖励模型综述**

*Rui Yu,Shenghua Wan,Yucen Wang,Chen-Xiao Gao,Le Gan,Zongzhang Zhang,De-Chuan Zhan*

主要分类: cs.LG

摘要简述: 本文综述了深度强化学习中的奖励模型技术，涵盖背景、分类、应用及评估方法，并指出未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 奖励模型在强化学习中作为代理目标，指导策略优化，但缺乏系统综述。本文旨在填补这一空白，梳理现有及新兴奖励模型技术。

研究方法: 首先介绍奖励模型的背景与基础知识，随后分类综述近年来的奖励模型方法（基于来源、机制和学习范式），并讨论其应用与评估方法。

研究结果: 系统总结了奖励模型的分类、应用及评估技术，为研究者提供了全面的参考框架。

研究结论: 奖励模型在深度强化学习中至关重要，未来研究应关注其与真实目标的更紧密对齐及优化效率的提升。

中文摘要: 在强化学习（RL）中，智能体持续与环境互动并通过反馈优化行为。奖励模型作为目标代理被引入，以指导策略优化，使得智能体在最大化累积奖励的同时实现任务设计者的意图。近年来，学术界和工业界研究者高度关注开发既能紧密对齐真实目标又能促进策略优化的奖励模型。本文综述了深度强化学习文献中的奖励模型技术，首先概述奖励模型的背景与基础知识，随后分类介绍近年来的奖励模型方法（基于来源、机制和学习范式），并讨论其应用及评估方法。最后，我们指出了奖励模型研究的未来方向。本综述涵盖了成熟与新兴方法，填补了当前文献中奖励模型系统综述的空白。

</details>


### [181] [Zero-Shot Reinforcement Learning Under Partial Observability](https://arxiv.org/abs/2506.15446)
**中文标题：部分可观测性下的零样本强化学习**

*Scott Jeen,Tom Bewley,Jonathan M. Cullen*

主要分类: cs.LG

摘要简述: 本文探讨了在部分可观测环境下，零样本强化学习方法的性能下降问题，并提出基于记忆的架构作为解决方案，实验证明其优于无记忆基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有零样本强化学习方法假设完全可观测马尔可夫状态，但在实际应用中，状态往往是部分可观测的。本文旨在研究部分可观测性对零样本强化学习性能的影响，并提出改进方案。

研究方法: 通过引入基于记忆的架构，解决部分可观测性问题。在状态、奖励和动态变化部分可观测的领域中，评估了该方法的性能。

研究结果: 实验表明，基于记忆的零样本强化学习方法在部分可观测环境下表现优于无记忆基线。

研究结论: 基于记忆的架构能有效缓解部分可观测性对零样本强化学习的影响，提升性能。

中文摘要: 近期研究表明，在特定假设下，零样本强化学习方法可以通过无奖励预训练泛化到任何未见任务。完全可观测马尔可夫状态是此类假设之一，但在许多实际应用中，状态仅为部分可观测。本文探讨了标准零样本强化学习方法在部分可观测性下的性能下降问题，并表明，与单任务强化学习类似，基于记忆的架构是有效解决方案。我们在状态、奖励和动态变化部分可观测的领域中评估了基于记忆的零样本强化学习方法，结果显示其性能优于无记忆基线。代码已开源：https://enjeeneer.io/projects/bfms-with-memory/。

</details>


### [182] [Warping and Matching Subsequences Between Time Series](https://arxiv.org/abs/2506.15452)
**中文标题：时间序列之间的子序列扭曲与匹配**

*Simiao Lin,Wannes Meert,Pieter Robberechts,Hendrik Blockeel*

主要分类: cs.LG

摘要简述: 本文提出了一种新技术，用于简化和可视化时间序列之间的子序列匹配，突出关键变换（如位移、压缩和幅度差异），从而提升时间序列比较的可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 当前时间序列比较方法主要依赖弹性距离度量进行定量分析，但缺乏对子序列结构关系的定性比较。传统可视化方法仅关注点对点对齐，无法清晰展示时间序列之间的位移、加速或减速等结构变化。

研究方法: 提出了一种新颖的技术，通过简化扭曲路径来突出、量化和可视化关键变换（如位移、压缩和幅度差异），从而更清晰地表示子序列之间的匹配关系。

研究结果: 该方法能够更直观地展示时间序列之间的子序列匹配关系，显著提升了时间序列比较的可解释性。

研究结论: 通过简化扭曲路径并可视化关键变换，该方法为时间序列比较提供了更清晰的子序列匹配表示，增强了分析的深度和直观性。

中文摘要: 时间序列比较在聚类和分类等任务中至关重要。尽管允许扭曲的弹性距离度量提供了稳健的定量比较，但缺乏对其的定性分析。传统可视化方法专注于点对点对齐，未能传达子序列层面的更广泛结构关系。这一限制使得难以理解一个时间序列相对于另一个的位移、加速或减速情况。为此，我们提出了一种新技术，通过简化扭曲路径来突出、量化和可视化关键变换（如位移、压缩和幅度差异）。通过更清晰地表示子序列之间的匹配关系，我们的方法提升了时间序列比较的可解释性。

</details>


### [183] [Over-squashing in Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2506.15507)
**中文标题：时空图神经网络中的过度挤压问题**

*Ivan Marisca,Jacob Bamberger,Cesare Alippi,Michael M. Bronstein*

主要分类: cs.LG

摘要简述: 本文研究了时空图神经网络（STGNNs）中的信息传播问题，特别是‘过度挤压’现象，发现其在时空场景下具有独特特性，并提出理论分析和实证验证。


<details>
  <summary>详细信息</summary>
研究动机: 尽管图神经网络（GNNs）在多个领域取得了显著成功，但其信息传播能力存在根本性限制，如‘过度挤压’现象。在静态图中已有研究，但时空图神经网络（STGNNs）中的这一问题尚未被探索。作者旨在填补这一空白，并揭示时空场景下‘过度挤压’的独特特性。

研究方法: 作者首先形式化了时空场景下的‘过度挤压’问题，并通过理论分析比较了其与静态图的差异。研究发现，卷积STGNNs更倾向于传播时间上较远而非较近的信息。此外，作者证明了无论是‘时间-空间’还是‘时间优先-空间后处理’的架构均受此现象影响。

研究结果: 理论分析和实证验证表明，时空场景下的‘过度挤压’问题具有独特性，且卷积STGNNs在信息传播上表现出反直觉的行为。研究结果为高效实现提供了理论依据。

研究结论: 本文揭示了时空图神经网络中‘过度挤压’问题的独特性，为未来设计更有效的STGNNs提供了理论指导和实践启示。

中文摘要: 图神经网络（GNNs）在多个领域取得了显著成功，但最近的理论进展揭示了其信息传播能力的根本性限制，例如‘过度挤压’现象，即远距离节点无法有效交换信息。尽管在静态图中已有广泛研究，但这一问题在时空图神经网络（STGNNs）中尚未被探索。时空维度通过增加需传播的信息量进一步加剧了这一挑战。本文中，我们形式化了时空场景下的‘过度挤压’问题，并展示了其与静态情况的显著差异。分析表明，卷积STGNNs反直觉地倾向于传播时间上较远而非较近的信息。此外，我们证明了无论是‘时间-空间’还是‘时间优先-空间后处理’的架构均受此现象影响，为计算高效实现提供了理论依据。我们在合成和真实数据集上验证了研究结果，为STGNNs的操作动态提供了更深入的见解，并为更有效的设计提供了原则性指导。

</details>


### [184] [RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation](https://arxiv.org/abs/2506.15513)
**中文标题：RePCS：诊断基于LLM的检索增强生成中的数据记忆问题**

*Le Vu Anh,Nguyen Viet Anh,Mehmet Dik,Luong Van Nghia*

主要分类: cs.LG

摘要简述: 本文提出了一种名为RePCS的方法，用于检测基于检索增强生成（RAG）的大型语言模型（LLM）是否依赖记忆的训练数据而非检索到的信息。该方法通过比较两种推理路径的KL散度来判断模型是否有效利用检索内容，无需访问模型内部或重新训练。


<details>
  <summary>详细信息</summary>
研究动机: 检索增强生成（RAG）虽然能更新LLM的响应，但模型可能仍依赖记忆的训练数据，导致输出被污染。因此，需要一种无需模型访问或重新训练的方法来诊断这种行为。

研究方法: RePCS通过比较仅使用查询的推理路径和同时使用查询与检索上下文的推理路径，计算两者输出分布的KL散度。低散度表明检索内容影响小，可能存在记忆行为。该方法无需梯度或内部状态访问，仅需一次额外前向传播。

研究结果: 在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，优于之前最强方法6.5个百分点，且在NVIDIA T4 GPU上延迟开销低于4.7%。

研究结论: RePCS提供了一种轻量级、黑盒化的方法，用于验证RAG系统是否有效利用检索内容，特别适用于安全关键应用。

中文摘要: 检索增强生成（RAG）已成为一种常见策略，用于通过外部信息更新大型语言模型（LLM）的响应。然而，模型可能仍依赖记忆的训练数据，绕过检索的证据，产生被污染的输出。我们提出了检索路径污染评分（RePCS），一种无需模型访问或重新训练的诊断方法。RePCS比较两种推理路径：（i）仅使用查询的参数路径，（ii）同时使用查询和检索上下文的检索增强路径，通过计算其输出分布的Kullback-Leibler（KL）散度。低散度表明检索上下文影响较小，可能存在记忆行为。该方法与模型无关，无需梯度或内部状态访问，仅需一次额外前向传播。我们还推导了PAC式保证，将KL阈值与用户定义的假阳性和假阴性率联系起来。在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，优于之前最强方法6.5个百分点，且在NVIDIA T4 GPU上延迟开销低于4.7%。RePCS提供了一种轻量级、黑盒化的保障，用于验证RAG系统是否有效利用检索内容，特别适用于安全关键应用。

</details>


### [185] [Learning Algorithms in the Limit](https://arxiv.org/abs/2506.15543)
**中文标题：极限条件下的学习算法**

*Hristo Papazov,Nicolas Flammarion*

主要分类: cs.LG

摘要简述: 本文研究了在极限条件下学习可计算函数的问题，通过扩展Gold的归纳推理框架，引入计算观察和受限输入源，克服了传统输入输出观察的局限性，揭示了计算代理观察与有限状态转换器推断的有趣联系。


<details>
  <summary>详细信息</summary>
研究动机: 传统的输入输出观察无法在极限条件下学习一般递归函数，因此需要引入计算复杂性约束或近似时间限制观察，以突破学习障碍。

研究方法: 扩展Gold的归纳推理框架，引入时间限制观察和策略轨迹观察，构建计算代理观察的正式框架，研究可计算函数的学习性。

研究结果: 输入输出观察不足以学习一般递归函数，但通过计算复杂性约束或时间限制观察可以克服这一障碍；策略轨迹观察将学习可计算函数简化为学习有理函数。

研究结论: 本文通过引入新的观察方法，突破了传统学习框架的限制，揭示了计算代理观察与有限状态转换器推断的联系，为可计算函数的学习提供了新视角。

中文摘要: 本文研究了在极限条件下学习可计算函数的问题，通过扩展Gold的归纳推理框架，引入计算观察和受限输入源。与传统输入输出观察互补，我们提出了时间限制观察和策略轨迹观察，以研究在更现实约束下一般递归函数的学习性。虽然输入输出观察不足以在极限条件下学习一般递归函数，但我们通过施加计算复杂性约束或补充近似时间限制观察，克服了这一学习障碍。此外，我们围绕计算代理的观察构建了一个正式框架，并表明从策略轨迹学习可计算函数可简化为从输入和输出学习有理函数，从而揭示了与有限状态转换器推断的有趣联系。在负面结果方面，我们证明了即使对于策略轨迹观察，线性时间可计算函数类也不存在可计算或多项式质量的特征集。

</details>


### [186] [DAILOC: Domain-Incremental Learning for Indoor Localization using Smartphones](https://arxiv.org/abs/2506.15554)
**中文标题：DAILOC：基于智能手机的域增量学习室内定位方法**

*Akhil Singampalli,Danish Gufran,Sudeep Pasricha*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DAILOC的新型域增量学习框架，用于解决Wi-Fi指纹室内定位中因设备异构性和时间变化导致的域偏移问题。通过多级变分自编码器和记忆引导的潜在对齐机制，DAILOC显著提升了定位精度。


<details>
  <summary>详细信息</summary>
研究动机: Wi-Fi指纹室内定位在实际部署中面临设备异构性和时间变化带来的域偏移问题，现有方法通常独立处理这些问题，导致泛化能力差且易受灾难性遗忘影响。本文旨在提出一种联合解决这两种域偏移的框架。

研究方法: DAILOC采用多级变分自编码器分离域偏移与位置相关特征，并引入记忆引导的潜在对齐机制以缓解灾难性遗忘。

研究结果: 实验表明，DAILOC在多个智能手机、建筑和时间实例中表现优异，平均误差降低2.74倍，最差情况误差降低4.6倍。

研究结论: DAILOC通过联合处理设备和时间域偏移，显著提升了室内定位的鲁棒性和准确性，优于现有方法。

中文摘要: 基于Wi-Fi指纹的室内定位在实际部署中因设备异构性和时间变化导致的域偏移问题面临重大挑战。现有方法通常独立处理这些问题，导致泛化能力差且易受灾难性遗忘影响。本文提出DAILOC，一种新型域增量学习框架，联合解决时间和设备引起的域偏移。DAILOC通过多级变分自编码器分离域偏移与位置相关特征，并引入记忆引导的潜在对齐机制以缓解灾难性遗忘。实验表明，DAILOC在多个智能手机、建筑和时间实例中显著优于现有方法，平均误差降低2.74倍，最差情况误差降低4.6倍。

</details>


### [187] [Towards Explainable Indoor Localization: Interpreting Neural Network Learning on Wi-Fi Fingerprints Using Logic Gates](https://arxiv.org/abs/2506.15559)
**中文标题：迈向可解释的室内定位：基于逻辑门解释Wi-Fi指纹的神经网络学习**

*Danish Gufran,Sudeep Pasricha*

主要分类: cs.LG

摘要简述: 本文提出了一种基于逻辑门的新型框架LogNet，用于解释和增强基于深度学习的室内定位系统，解决了现有黑盒模型缺乏可解释性的问题，并在性能和模型效率上取得了显著提升。


<details>
  <summary>详细信息</summary>
研究动机: 现有的深度学习室内定位模型多为黑盒，无法解释预测过程或适应环境动态变化，限制了模型的长期可靠性和适应性。

研究方法: 作者提出LogNet框架，通过逻辑门透明化推理，识别关键接入点（APs）对参考点（RPs）的影响，并分析环境噪声对定位决策的干扰。

研究结果: LogNet在多个真实建筑平面和两年时间变化中验证，不仅解释了模型内部行为，还显著降低了定位误差（1.1x至2.8x）、模型大小（3.4x至43.3x）和延迟（1.5x至3.6x）。

研究结论: LogNet通过提升模型可解释性和性能，为长期稳定的室内定位系统提供了有效解决方案。

中文摘要: 基于深度学习（DL）的室内定位在将Wi-Fi RSS指纹映射到物理位置方面表现出高精度，但现有DL框架多为黑盒模型，难以理解预测过程或模型对实时噪声的响应。这种不可解释性阻碍了我们对环境动态引起的时序变化的理解，以及模型长期可靠性的调整。为此，我们提出LogNet，一种基于逻辑门的新型框架，旨在解释和增强基于DL的室内定位。LogNet通过识别每个参考点（RP）最关键的接入点（APs）并揭示环境噪声如何干扰DL定位决策，实现了透明推理。这种可解释性使我们能够追踪和诊断模型故障，并调整DL系统以实现更稳定的长期部署。在多个真实建筑平面和两年时间变化的评估中，LogNet不仅解释了DL模型的内部行为，还显著提升了性能——定位误差降低1.1x至2.8x，模型大小缩小3.4x至43.3x，延迟降低1.5x至3.6x，优于现有DL模型。

</details>


### [188] [GFLC: Graph-based Fairness-aware Label Correction for Fair Classification](https://arxiv.org/abs/2506.15620)
**中文标题：基于图的公平感知标签校正方法（GFLC）用于公平分类**

*Modar Sulaiman,Kallol Roy*

主要分类: cs.LG

摘要简述: 本文提出了一种基于图的公平感知标签校正方法（GFLC），用于在分类任务中修正标签噪声并保持数据集的公平性，显著提升了模型性能与公平性之间的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能系统在社会各领域（如医疗和法律）的影响日益加深，机器学习中的公平性成为构建可信系统的关键。然而，训练数据中的标签偏差和噪声会影响模型性能和公平性评估，因此需要更鲁棒的公平感知方法。

研究方法: GFLC结合了三个关键组件：预测置信度度量、基于Ricci流优化的图拉普拉斯正则化，以及显式的人口统计公平性激励。通过这些方法，有效修正标签噪声并保持数据集的公平性。

研究结果: 实验结果表明，GFLC在性能与公平性指标之间的权衡上显著优于基线方法，验证了其有效性。

研究结论: GFLC为解决标签噪声和公平性问题提供了一种高效方法，为构建更公平的机器学习系统提供了新思路。

中文摘要: 机器学习（ML）中的公平性对于构建可信赖的人工智能（AI）系统至关重要，尤其是在AI系统日益影响医疗决策和法律判决等社会领域的情况下。然而，用于训练和开发去偏技术的训练数据通常包含有偏和噪声标签，导致标签偏差影响模型性能并扭曲测试阶段的公平性评估。为解决这一问题，本文提出了一种基于图的公平感知标签校正方法（GFLC），通过结合预测置信度度量、基于Ricci流优化的图拉普拉斯正则化以及显式的人口统计公平性激励，有效修正标签噪声并保持数据集的公平性。实验结果表明，GFLC在性能与公平性指标之间的权衡上显著优于基线方法。

</details>


### [189] [Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction](https://arxiv.org/abs/2506.15626)
**中文标题：基于MRI的脑龄预测的联邦学习：一项关于卒中后功能恢复预测的多中心研究**

*Vincent Roca,Marc Tommasi,Paul Andrey,Aurélien Bellet,Markus D. Schirmer,Hilde Henon,Laurent Puy,Julien Ramon,Grégory Kuchcinski,Martin Bretzner,Renaud Lopes*

主要分类: cs.LG

摘要简述: 本研究探讨了联邦学习（FL）在基于MRI的脑龄预测（BrainAGE）中的应用，用于预测缺血性卒中患者的功能恢复。结果显示，FL在无需数据集中化的情况下表现优于单中心模型，且BrainAGE与血管风险因素及卒中后功能恢复显著相关。


<details>
  <summary>详细信息</summary>
研究动机: 脑龄差异（BrainAGE）是反映脑健康的神经影像生物标志物，但训练稳健的BrainAGE模型需要大量数据，而隐私问题限制了数据共享。本研究旨在评估联邦学习在BrainAGE估计中的性能，并探讨其与卒中患者临床表型及功能恢复的关联。

研究方法: 研究使用来自16个医院中心的1674名卒中患者的FLAIR脑影像数据，比较了三种数据管理策略下的模型表现：集中学习（数据集中）、联邦学习（本地训练）和单中心学习。通过逻辑回归分析BrainAGE与血管风险因素及卒中后三个月功能恢复的关联。

研究结果: 集中学习预测最准确，但联邦学习表现优于单中心模型。BrainAGE在糖尿病患者中显著较高，且与卒中后功能恢复显著相关。

研究结论: 联邦学习无需数据集中化即可实现准确的脑龄预测，BrainAGE与血管风险因素及卒中后恢复的强关联表明其在卒中预后模型中的潜力。

中文摘要: 目的：脑龄差异（BrainAGE）是反映脑健康的神经影像生物标志物，但训练稳健的BrainAGE模型需要大量数据，而隐私问题限制了数据共享。本研究评估了联邦学习（FL）在缺血性卒中患者脑龄估计中的性能，并探讨其与临床表型及功能恢复的关联。
方法：我们使用来自16个医院中心的1674名卒中患者的FLAIR脑影像数据，比较了三种数据管理策略下的模型表现：集中学习（数据集中）、联邦学习（本地训练）和单中心学习。通过逻辑回归分析BrainAGE与血管风险因素（如糖尿病、高血压、吸烟）及卒中后三个月功能恢复的关联。
结果：集中学习预测最准确，但联邦学习表现优于单中心模型。BrainAGE在糖尿病患者中显著较高，且与卒中后功能恢复显著相关。
结论：联邦学习无需数据集中化即可实现准确的脑龄预测，BrainAGE与血管风险因素及卒中后恢复的强关联表明其在卒中预后模型中的潜力。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [190] [An Empirical Study of Bugs in Data Visualization Libraries](https://arxiv.org/abs/2506.15084)
**中文标题：数据可视化库中错误的实证研究**

*Weiqi Lu,Yongqiang Tian,Xiaohan Zhong,Haoyang Ma,Zhenyang Xu,Shing-Chi Cheung,Chengnian Sun*

主要分类: cs.SE

摘要简述: 本研究首次全面分析了数据可视化库中的错误，收集了五个常用库的564个错误，系统分析了症状和根源，并提出了一种分类法。研究发现，错误/不准确的图表普遍存在，主要原因是图形计算错误，需进一步开发自动化测试方法。此外，还探索了视觉语言模型（VLM）在检测错误图表中的可行性。


<details>
  <summary>详细信息</summary>
研究动机: 数据可视化库在数据呈现和分析中至关重要，但其错误可能导致误导性图表，影响用户体验和决策。因此，深入了解这些错误的特性对开发者和研究者至关重要。

研究方法: 研究收集了五个广泛使用的数据可视化库中的564个错误，系统分析了其症状和根源，并提出了一种详细的分类法。此外，还探索了视觉语言模型（VLM）在检测错误图表中的效果。

研究结果: 研究发现，错误/不准确的图表在数据可视化库中普遍存在，主要原因是图形计算错误。此外，VLM在检测错误图表中的效果因提示内容而异，效果范围在29%至57%之间。

研究结论: 数据可视化库中的错误需进一步自动化测试方法解决，视觉语言模型在检测错误图表中具有一定潜力，但效果有限。

中文摘要: 数据可视化（DataViz）库在数据呈现、分析和应用开发中扮演着关键角色，其准确性对将数据转化为可视化表示至关重要。错误的可视化可能影响用户体验、扭曲信息传递，并影响用户感知和决策过程。这些库中的视觉错误尤为隐蔽，因为它们可能不会导致明显的崩溃，而是通过图形误导用户对底层数据的理解，从而导致错误决策。因此，深入了解数据可视化库中错误的独特特性对研究人员和开发者检测和修复这些错误至关重要。本研究首次对数据可视化库中的错误进行了全面分析，收集了五个常用库中的564个错误，系统分析了其症状和根源，并提出了一种详细的分类法。研究发现，错误/不准确的图表在数据可视化库中普遍存在，主要原因是图形计算错误，这需要进一步开发自动化测试方法。此外，我们还识别了触发这些错误的八个关键步骤和两个特定于数据可视化库的测试预言，这可能为未来设计有效的自动化测试技术提供启发。随着视觉语言模型（VLM）的最新进展，我们还探索了应用这些模型检测错误/不准确图表的可行性。结果显示，VLM在错误检测中的效果因提示内容而异，范围在29%至57%之间，而增加提示中的信息量并不一定能提高效果。更多发现详见我们的论文。

</details>


### [191] [Uncovering Intention through LLM-Driven Code Snippet Description Generation](https://arxiv.org/abs/2506.15453)
**中文标题：通过LLM驱动的代码片段描述生成揭示意图**

*Yusuf Sulistyo Nugroho,Farah Danisha Salam,Brittany Reid,Raula Gaikovina Kula,Kazumasa Shimari,Kenichi Matsumoto*

主要分类: cs.SE

摘要简述: 本文研究了大型语言模型（LLM）在生成代码片段描述中的表现，发现其能较好识别示例用途，但生成的描述仍有改进空间。


<details>
  <summary>详细信息</summary>
研究动机: 代码片段的清晰文档对开发者和用户至关重要，尤其是第三方库的API文档。随着大型语言模型（LLM）的兴起，研究其如何支持描述生成成为关键目标。

研究方法: 研究使用NPM代码片段数据集（185,412个包，1,024,579个代码片段），从中选取400个样本进行人工分类和LLM（Llama）生成描述对比。

研究结果: 人工分类显示55.5%的原始描述为示例用途，LLM正确识别了79.75%的示例描述，生成描述的平均相似度为0.7173，表明相关性但需改进。

研究结论: 代码片段的文档意图因任务而异，可能是使用说明、安装指南或学习示例。LLM在描述生成中表现良好，但仍有优化空间。

中文摘要: 代码片段的文档化是明确开发者和用户关注重点的关键。例如，使用示例和其他API文档对第三方库尤为重要。随着大型语言模型（LLM）的兴起，研究目标是探究开发者常用的描述类型，并评估LLM（如Llama）在描述生成中的表现。我们使用NPM代码片段数据集（185,412个包，1,024,579个代码片段），从中选取400个样本（及其描述）。首先，人工分类发现55.5%的原始描述为示例用途，凸显了清晰文档的重要性，部分描述未能充分传达意图。其次，LLM正确识别了79.75%的原始描述为“示例”，与人工结果一致，显示出泛化倾向。第三，生成的描述与原始描述的平均相似度为0.7173，表明相关性但需改进。低于0.9的分数表明部分不相关。结果显示，代码片段的文档意图可能因任务而异，包括使用说明、安装指南或学习示例。

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [192] [LLM Agent for Hyper-Parameter Optimization](https://arxiv.org/abs/2506.15167)
**中文标题：基于大型语言模型的超参数优化智能代理**

*Wanzhe Wang,Jianqiu Peng,Menghao Hu,Weihuang Zhong,Tong Zhang,Shuai Wang,Yixin Zhang,Mingjie Shao,Wanli Ni*

主要分类: cs.IT

摘要简述: 本文提出了一种基于大型语言模型（LLM）的智能代理，用于自动优化无人机通信算法中的超参数。通过迭代框架和模型上下文协议（MCP），该代理显著提升了超参数调优的自动化水平和性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前无人机通信算法中的超参数调优方法（如WS-PSO-CM）主要依赖启发式方法，自动化程度低且性能不佳。为了解决这一问题，本文探索了利用LLM代理实现自动化超参数优化的可能性。

研究方法: 首先通过配置文件设定LLM代理的任务、背景和输出格式；随后，代理根据提示需求迭代调用WS-PSO-CM算法进行探索；最终，代理自主终止循环并返回一组超参数。

研究结果: 实验结果表明，LLM代理生成的超参数所实现的最小和速率显著高于人工启发式和随机生成方法，验证了其有效性。

研究结论: 研究表明，具备PSO知识和WS-PSO-CM算法背景的LLM代理能够高效找到高性能超参数，为自动化超参数调优提供了新思路。

中文摘要: 超参数对通信算法的性能至关重要。然而，当前针对无人机轨迹和通信的WS-PSO-CM算法的超参数调优方法主要依赖启发式方法，自动化程度低且性能不理想。本文设计了一种基于大型语言模型（LLM）的智能代理，用于自动优化超参数，采用了迭代框架和模型上下文协议（MCP）。具体而言，首先通过配置文件设定代理的任务、背景和输出格式；随后，代理根据提示需求迭代调用WS-PSO-CM算法进行探索；最终，代理自主终止循环并返回一组超参数。实验结果表明，LLM代理生成的超参数所实现的最小和速率显著高于人工启发式和随机生成方法，表明具备PSO知识和WS-PSO-CM算法背景的LLM代理在寻找高性能超参数方面具有显著优势。

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [193] [Forecasting the spatiotemporal evolution of fluid-induced microearthquakes with deep learning](https://arxiv.org/abs/2506.14923)
**中文标题：基于深度学习的流体诱发微地震时空演化预测**

*Jaehong Chung,Michael Manga,Timothy Kneafsey,Tapan Mukerji,Mengsu Hu*

主要分类: physics.geo-ph

摘要简述: 本文提出了一种基于Transformer的深度学习模型，用于预测流体诱发微地震的时空演化，为增强地热系统等应用提供实时风险评估。


<details>
  <summary>详细信息</summary>
研究动机: 微地震记录了地下流体注入引起的应力状态和渗透性变化，预测其时空演化对增强地热系统、CO₂封存等工程应用至关重要。

研究方法: 采用Transformer深度学习模型，输入水力压裂历史和微地震观测数据，预测累积微地震数量、累积对数地震矩及微地震云的50%和95%分位范围。

研究结果: 在EGS Collab实验数据集上，模型在1秒预测时间范围内R²>0.98，15秒范围内R²>0.88，并通过学习标准差提供不确定性估计。

研究结论: 该模型能实时推断裂缝扩展和渗透性变化，展示了深度学习在改善地震风险评估和指导减灾策略中的潜力。

中文摘要: 地下流体注入产生的微地震（MEQs）记录了储层的应力状态和渗透性变化。预测其完整的时空演化对增强地热系统（EGS）、CO₂封存等地质工程应用至关重要。我们提出了一种基于Transformer的深度学习模型，通过输入水力压裂历史和微地震观测数据，预测四个关键量：累积微地震数量、累积对数地震矩，以及微地震云的50%和95%分位范围（P50、P95）。在EGS Collab实验1数据集上，模型在1秒预测时间范围内对所有目标的R²>0.98，15秒范围内R²>0.88，并通过学习标准差提供不确定性估计。这些准确且量化不确定性的预测能够实时推断裂缝扩展和渗透性变化，展示了深度学习方法在改善地震风险评估和指导未来流体注入减灾策略中的强大潜力。

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [194] [BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models](https://arxiv.org/abs/2506.14861)
**中文标题：BMFM-RNA：构建和评估转录组基础模型的开放框架**

*Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou*

主要分类: q-bio.GN

摘要简述: BMFM-RNA是一个开源、模块化的转录组基础模型框架，支持多样化的预训练和微调目标，并引入新的训练目标WCED，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前转录组基础模型（TFMs）的实现和训练策略多样，难以评估设计选择的影响或协同效应，阻碍了最佳实践的确定和研究的可重复性。

研究方法: 提出BMFM-RNA框架，统一多种TFM预训练和微调目标，并引入新的训练目标WCED，通过自编码器式的CLS瓶颈表示捕获全局表达模式。

研究结果: 在CELLxGENE上预训练的四个模型检查点中，WCED模型在零样本和微调任务中表现优于或匹配scGPT等先进方法。

研究结论: BMFM-RNA为系统化基准测试和社区驱动的TFM训练策略探索提供了可重复的基础，有助于开发更有效的工具以理解细胞生物学。

中文摘要: 转录组基础模型（TFMs）已成为分析细胞和组织基因表达的有力工具，支持细胞类型注释、批次校正和扰动预测等关键任务。然而，近期TFMs的模型实现和训练策略多样性虽具潜力，却难以评估单个设计选择的贡献或其协同效应，阻碍了最佳实践的确定和跨研究结果的可重复性。我们提出了BMFM-RNA，一个开源的模块化软件包，将多种TFM预训练和微调目标统一于单一框架中。利用这一能力，我们引入了一种新的训练目标——全细胞表达解码器（WCED），通过类似自编码器的CLS瓶颈表示捕获全局表达模式。本文描述了该框架、支持的输入表示和训练目标。我们评估了在CELLxGENE上预训练的四个模型检查点，结合了掩码语言建模（MLM）、WCED和多任务学习。通过BMFM-RNA的基准测试功能，我们发现基于WCED的模型在零样本和微调任务中表现优于或匹配scGPT等先进方法，覆盖了十多个数据集。BMFM-RNA作为biomed-multi-omics项目的一部分（https://github.com/BiomedSciAI/biomed-multi-omic），为系统化基准测试和社区驱动的TFM训练策略探索提供了可重复的基础，有助于开发更有效的工具以利用AI最新进展理解细胞生物学。

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [195] [MODS: Multi-source Observations Conditional Diffusion Model for Meteorological State Downscaling](https://arxiv.org/abs/2506.14798)
**中文标题：MODS：多源观测条件扩散模型用于气象状态降尺度**

*Siwei Tu,Jingyi Xu,Weidong Yang,Lei Bai,Ben Fei*

主要分类: physics.ao-ph

摘要简述: 本文提出了一种多源观测条件扩散模型（MODS），用于气象状态降尺度，通过融合多源卫星和地形数据，显著提高了降尺度气象变量的精度。


<details>
  <summary>详细信息</summary>
研究动机: 高分辨率地表气象数据的准确获取对气象预报和模拟至关重要。传统空间插值方法或单一卫星数据无法全面捕捉气象变量变化，导致结果偏离实际。因此，需利用多源数据提升降尺度精度。

研究方法: MODS是一种条件扩散模型，融合了多源卫星数据（GridSat、AMSU-A、HIRS、MHS）和地形数据（GEBCO），并通过多源交叉注意力模块提取潜在特征，结合ERA5再分析数据进行预训练。采样时，引入低分辨率ERA5地图和站点数据作为指导。

研究结果: 实验表明，MODS在将ERA5地图降尺度至6.25 km分辨率时，能够生成更接近真实气象状态的结果，显著提高了保真度。

研究结论: MODS通过多源数据融合和条件扩散模型，有效提升了气象状态降尺度的精度和一致性，为气象预报和模拟提供了更可靠的高分辨率数据。

中文摘要: 高分辨率地表气象条件的准确获取对气象预报和模拟至关重要。直接应用空间插值方法从低分辨率网格场中推导特定位置的气象值，结果往往与实际条件偏差较大。现有降尺度方法主要依赖地球静止卫星与ERA5变量的耦合关系作为条件，但仅使用地球静止卫星的亮温数据无法全面捕捉ERA5图中气象变量的所有变化。为解决这一局限，可利用更广泛的卫星数据，更充分地利用其对各种气象变量的反演效果，从而在不同气象变量上生成更真实的结果。为进一步提高任意位置气象变量降尺度的准确性，我们提出了多源观测降尺度模型（MODS）。它是一种条件扩散模型，融合了多源地球静止卫星GridSat、极轨卫星（AMSU-A、HIRS和MHS）以及地形数据（GEBCO）作为条件，并在ERA5再分析数据集上进行了预训练。训练过程中，通过多源交叉注意力模块分别提取不同条件输入的潜在特征，并将其融合到ERA5图中。通过利用再分析数据与多源大气变量之间的反演关系，MODS生成了更接近真实世界条件的大气状态。在采样时，MODS通过引入低分辨率ERA5地图和站点级气象数据作为指导，增强了降尺度的一致性。实验结果表明，MODS在将ERA5地图降尺度至6.25 km分辨率时，实现了更高的保真度。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [196] [Comparative Analysis of QNN Architectures for Wind Power Prediction: Feature Maps and Ansatz Configurations](https://arxiv.org/abs/2506.14795)
**中文标题：风能预测中量子神经网络架构的比较分析：特征映射与Ansatz配置**

*Batuhan Hangun,Emine Akpinar,Oguz Altun,Onder Eyecioglu*

主要分类: quant-ph

摘要简述: 本研究通过比较12种不同的量子神经网络（QNN）架构，评估其在风能预测中的表现。结果表明，采用Z特征映射的QNN在仅使用4个输入参数时预测准确率高达93%，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 量子机器学习（QML）结合量子计算与机器学习，旨在利用量子力学原理提升传统机器学习性能。然而，由于当前噪声中等规模量子（NISQ）设备的限制，QML的实际优势仍受质疑。本研究旨在通过评估QNN的性能，验证其在风能预测中的潜力。

研究方法: 研究系统地构建并评估了12种不同的QNN配置，结合两种量子特征映射和六种纠缠策略设计ansatz。实验基于风能数据集，比较QNN与传统方法的预测表现。

研究结果: 实验结果显示，采用Z特征映射的QNN在风能预测中表现最佳，准确率达到93%，且仅需4个输入参数。QNN整体优于传统方法。

研究结论: 研究表明，QNN在风能预测等实际任务中具有显著优势，验证了量子机器学习在现实应用中的潜力。

中文摘要: 量子机器学习（QML）是量子计算与机器学习交叉的新兴领域，旨在通过利用量子力学原理（如纠缠和叠加）提升传统机器学习方法。然而，由于当前噪声中等规模量子（NISQ）设备的限制，QML的实际优势仍受质疑。本研究通过全面评估量子神经网络（QNN）——人工神经网络（ANN）的量子对应物，验证其相对于传统方法的有效性。我们系统地构建并评估了12种不同的QNN配置，结合两种独特的量子特征映射和六种纠缠策略设计ansatz。在风能数据集上的实验表明，采用Z特征映射的QNN在仅使用4个输入参数时，风能输出预测准确率高达93%。研究结果表明，QNN在预测任务中优于传统方法，凸显了QML在实际应用中的潜力。

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [197] [Identifiability by common backdoor in summary causal graphs of time series](https://arxiv.org/abs/2506.14862)
**中文标题：时间序列摘要因果图中通过共同后门的可识别性**

*Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier*

主要分类: math.ST

摘要简述: 本文研究时间序列中因果图的干预可识别性问题，重点关注通过共同后门集的识别条件，并提出了判断可识别性的算法。


<details>
  <summary>详细信息</summary>
研究动机: 干预的可识别性问题旨在评估某些干预的总效应是否可以用无干预公式表示，从而仅通过观测数据计算。本文在时间序列背景下，研究多干预和多效应的可识别性，尤其是在仅能获得因果图抽象形式的情况下。

研究方法: 研究聚焦于通过共同后门集的识别性，针对时间序列（包括时间一致性和非一致性的情况），建立了存在共同后门集的条件，并提供了有限复杂度的算法来判断问题是否可识别。

研究结果: 本文确立了时间序列中通过共同后门集实现干预可识别性的条件，并提出了相应的算法支持判断。

研究结论: 通过共同后门集，可以在时间序列中实现干预效应的可识别性，且算法复杂度可控，为实际应用提供了理论支持。

中文摘要: 干预的可识别性问题旨在评估某些给定干预的总效应是否可以用无干预公式表示，从而仅通过观测数据计算。本文在时间序列背景下研究这一问题，考虑多干预和多效应，且仅能获得真实因果图的摘要形式。研究聚焦于通过共同后门集的识别性，针对时间序列（包括时间一致性和非一致性的情况），建立了存在共同后门集的条件，并提供了有限复杂度的算法来判断问题是否可识别。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [198] [Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection](https://arxiv.org/abs/2506.14933)
**中文标题：先解释，后信任：基于图的加密异常检测的LLM增强解释**

*Adriana Watson*

主要分类: cs.CE

摘要简述: 本文提出了一种基于LLM增强解释的图加密异常检测方法，旨在解决加密货币领域日益增长的犯罪问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着去中心化金融（DeFi）的快速发展，加密货币犯罪日益猖獗，但由于技术新颖性，传统检测手段难以应对。因此，亟需自动化工具来检测和解释异常行为。

研究方法: 采用基于图的异常检测方法，并结合大型语言模型（LLM）生成解释，以提高检测结果的可信度和可理解性。

研究结果: 该方法能够有效检测加密货币中的异常行为，并通过LLM生成的解释增强用户对检测结果的信任。

研究结论: 通过结合图检测和LLM解释，该方法为加密货币领域的犯罪检测提供了高效且透明的解决方案。

中文摘要: 近年来，去中心化金融（DeFi）社区在加密货币爱好者的推动下迅速发展，他们对新市场的巨大潜力充满兴趣。然而，加密货币的普及也带来了金融犯罪的新时代。遗憾的是，由于技术的新颖性，抓捕和起诉犯罪者变得尤为困难。因此，有必要实施与政策相关的自动化检测工具，以应对加密货币领域日益增长的犯罪问题。

</details>


<div id='stat.OT'></div>

# stat.OT [[Back]](#toc)

### [199] [Next-Generation Conflict Forecasting: Unleashing Predictive Patterns through Spatiotemporal Learning](https://arxiv.org/abs/2506.14817)
**中文标题：下一代冲突预测：通过时空学习释放预测模式**

*Simon P. von der Maase*

主要分类: stat.OT

摘要简述: 本研究提出了一种新型神经网络架构，用于高时空分辨率预测暴力冲突，涵盖三种类型（国家间、非国家间和单边冲突），并在子国家级（priogrid-month）水平上提前36个月进行预测。模型结合分类与回归任务，生成概率估计和事件预期规模，性能达到最优，并量化预测不确定性。


<details>
  <summary>详细信息</summary>
研究动机: 高时空分辨率的暴力冲突预测是研究者和政策制定者的核心挑战。现有方法依赖手动特征工程，难以捕捉复杂的时空模式。本研究旨在开发一种无需人工干预、仅依赖历史数据的模型，以提升预测精度和实用性。

研究方法: 模型采用蒙特卡洛Dropout LSTM U-Net架构，结合卷积层捕捉空间依赖性和循环结构建模时间动态。无需手动特征工程，仅基于历史冲突数据自主学习时空模式。

研究结果: 模型在所有任务中达到最优性能，生成概率估计和事件规模预测，并提供近似后验分布量化不确定性。其扩展性强，可整合额外数据源并联合预测辅助变量。

研究结论: 该模型不仅预测性能卓越，还具备高度扩展性，适用于早期预警系统、人道主义响应规划和基于证据的和平建设行动。

中文摘要: 在高时空分辨率下预测暴力冲突仍是研究者和政策制定者的核心挑战。本研究提出了一种新型神经网络架构，用于预测三种类型的暴力冲突（国家间、非国家间和单边冲突），并在子国家级（priogrid-month）水平上提前36个月进行预测。模型同时执行分类和回归任务，生成未来事件的概率估计和预期规模。其在所有任务中均达到最优性能，并通过近似后验分布量化预测不确定性。

该架构基于蒙特卡洛Dropout长短期记忆（LSTM）U-Net，结合卷积层捕捉空间依赖性和循环结构建模时间动态。与现有方法不同，它无需手动特征工程，仅依赖历史冲突数据，从而自主学习了暴力冲突背后的复杂时空模式。

除了卓越的预测性能，该模型还具备高度扩展性：可轻松整合额外数据源并联合预测辅助变量。这些能力使其成为早期预警系统、人道主义响应规划和基于证据的和平建设行动的有力工具。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [200] [Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures](https://arxiv.org/abs/2506.15043)
**中文标题：基于CNN-LSTM-GRU架构的高超音速导弹轨迹高级预测**

*Amir Hossein Baradaran*

主要分类: cs.CR

摘要简述: 本文提出了一种结合CNN、LSTM和GRU的混合深度学习模型，用于高精度预测高超音速导弹的复杂轨迹，为防御策略和拦截技术提供了重要支持。


<details>
  <summary>详细信息</summary>
研究动机: 高超音速导弹因其极速和高机动性成为防御领域的重大挑战，准确预测其轨迹对有效拦截至关重要。本文旨在通过深度学习技术提升预测能力。

研究方法: 采用了一种新型混合深度学习架构，结合了CNN、LSTM和GRU的优势，以捕捉高超音速导弹轨迹的时空特征。

研究结果: 所提出的方法能够高精度预测高超音速导弹的复杂轨迹，显著提升了防御系统的预测能力。

研究结论: 研究表明，先进的机器学习技术能够有效增强防御系统的预测能力，为高超音速导弹拦截提供了新的技术支持。

中文摘要: 国防工业的进步对于确保国家安全至关重要，能够有效应对新兴威胁。其中，高超音速导弹因其极速和高机动性成为重大挑战，准确预测其轨迹是实施有效拦截的关键。本文提出了一种新型混合深度学习方法，结合了卷积神经网络（CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）。通过整合这些架构的优势，该方法成功实现了对高超音速导弹复杂轨迹的高精度预测，为防御策略和导弹拦截技术提供了重要贡献。本研究展示了先进机器学习技术在提升防御系统预测能力方面的潜力。

</details>


### [201] [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](https://arxiv.org/abs/2506.15253)
**中文标题：RAS-Eval：现实环境中LLM代理安全性的综合评估基准**

*Yuchuan Fu,Xiaohan Yuan,Dongxia Wang*

主要分类: cs.CR

摘要简述: 本文介绍了RAS-Eval，一个用于评估大型语言模型（LLM）代理在动态环境中安全性的综合基准测试工具。该工具包含80个测试用例和3,802个攻击任务，覆盖11种常见弱点类别。实验结果显示，攻击平均降低了代理任务完成率36.78%，并在学术环境中达到85.65%的成功率。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署，缺乏标准化评估基准成为重要问题。本文旨在填补这一空白，提供一个支持模拟和真实环境工具执行的综合安全评估框架。

研究方法: RAS-Eval包含80个测试用例和3,802个攻击任务，映射到11种常见弱点枚举（CWE）类别。工具支持JSON、LangGraph和模型上下文协议（MCP）格式。作者评估了6种先进LLM模型，分析其在多种场景下的安全漏洞。

研究结果: 实验结果显示，攻击平均降低了代理任务完成率36.78%，并在学术环境中达到85.65%的成功率。此外，安全能力与模型规模相关，大模型表现优于小模型。

研究结论: RAS-Eval揭示了现实世界中LLM代理部署的关键风险，并为未来安全研究提供了基础框架。代码和数据已开源。

中文摘要: 大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署需要强大的安全框架。为解决动态环境中缺乏标准化评估基准的问题，我们提出了RAS-Eval，一个支持模拟和真实工具执行的综合安全基准测试工具。RAS-Eval包含80个测试用例和3,802个攻击任务，覆盖11种常见弱点枚举（CWE）类别，工具支持JSON、LangGraph和模型上下文协议（MCP）格式。我们评估了6种先进LLM模型，结果显示攻击平均降低了代理任务完成率36.78%，并在学术环境中达到85.65%的成功率。值得注意的是，安全能力与模型规模相关，大模型表现优于小模型。我们的研究揭示了现实世界中代理部署的关键风险，并为未来安全研究提供了基础框架。代码和数据可在https://github.com/lanzer-tree/RAS-Eval获取。

</details>


### [202] [Evaluation Pipeline for systematically searching for Anomaly Detection Systems](https://arxiv.org/abs/2506.15388)
**中文标题：系统搜索异常检测系统的评估流程**

*Florian Rokohl,Alexander Lehnert,Marc Reichenbach*

主要分类: cs.CR

摘要简述: 本文提出了一种基于FPGA的异常检测系统，用于实时检测医疗网络中的恶意客户端，满足实时性和功耗限制。


<details>
  <summary>详细信息</summary>
研究动机: 医疗领域的数字化带来了巨大便利，但也成为攻击者的目标，网络安全难以保障。为解决这一问题，作者提出了一种硬件上的异常检测系统。

研究方法: 利用FPGA实现异常检测系统，以满足实时性和功耗限制，并通过整体系统评估提升性能。

研究结果: 系统在实时检测恶意客户端方面表现优异，同时满足了功耗和性能要求。

研究结论: 基于FPGA的异常检测系统为医疗网络安全提供了一种高效解决方案。

中文摘要: 医疗领域的数字化带来了巨大便利，但也使其成为攻击者的目标，网络安全难以保障。为应对网络入侵者，我们提出了一种基于硬件的异常检测系统，用于实时检测恶意客户端。通过使用FPGA，我们满足了实时性和功耗限制。通过提出的整体系统评估，实现了整体系统性能的提升。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [203] [Collaborative Interest-aware Graph Learning for Group Identification](https://arxiv.org/abs/2506.14826)
**中文标题：协同兴趣感知图学习用于群体识别**

*Rui Zhao,Beihong Jin,Beibei Li,Yiyuan Zheng*

主要分类: cs.SI

摘要简述: 本文提出CI4GI模型，通过协同兴趣增强策略和负样本优化方法，解决了现有群体识别方法未能充分建模用户群体和项目兴趣协同演化关系的问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着社交媒体的普及，用户在社交平台上参与群体活动的需求增加，但现有群体识别方法未能充分建模用户群体和项目兴趣的协同演化关系，导致推荐效果不佳。

研究方法: 提出CI4GI模型，设计兴趣增强策略，从用户加入的群体中提取额外兴趣作为补充，并优化负样本识别以减少跨兴趣对齐时的干扰。

研究结果: 在三个真实数据集上的实验表明，CI4GI显著优于现有最优模型。

研究结论: CI4GI通过协同建模用户群体和项目兴趣的演化关系，提升了群体识别的准确性。

中文摘要: 随着社交媒体的流行，越来越多的用户参与在线社交平台的群体活动，这引发了对群体识别（GI）的需求，即向用户推荐群体。我们发现用户受到群体级和项目级兴趣的双重影响，且这两种兴趣存在协同演化关系：加入群体会扩展用户的项目兴趣，进而促使用户加入新的群体，最终两种兴趣趋于动态一致。然而，现有的GI方法未能充分建模这种协同演化关系，忽略了群体级兴趣对项目级兴趣的增强作用，并在跨兴趣对齐时受到假阴性样本的干扰。为了充分建模用户双重兴趣的协同演化关系，我们提出了CI4GI，一种用于群体识别的协同兴趣感知模型。具体而言，我们设计了一种兴趣增强策略，从用户加入的群体交互的项目中识别额外兴趣，作为项目级兴趣的补充。此外，我们采用两个用户兴趣分布之间的距离来优化负样本识别，减少跨兴趣对齐时假阴性样本的干扰。在三个真实数据集上的实验结果表明，CI4GI显著优于现有最优模型。

</details>


### [204] [Detecting Narrative Shifts through Persistent Structures: A Topological Analysis of Media Discourse](https://arxiv.org/abs/2506.14836)
**中文标题：通过持久结构检测叙事转变：媒体话语的拓扑分析**

*Mark M. Bailey,Mark I. Heiligman*

主要分类: cs.SI

摘要简述: 本研究提出了一种基于拓扑学的框架，通过持久同调分析媒体叙事结构的变化，揭示重大事件如何重塑公共话语。研究发现，地缘政治和社会事件与叙事结构的突然重组相关，且语义变化通常从底层（H0）向高层（H1）级联。


<details>
  <summary>详细信息</summary>
研究动机: 如何检测全球事件对公共话语的根本性重塑？本研究旨在通过拓扑学方法，量化媒体叙事结构的变化，从而识别重大事件对公共话语的影响。

研究方法: 研究使用持久同调方法，构建每日名词短语共现图，并通过Vietoris-Rips过滤生成持久图。计算Wasserstein距离和持久熵，以捕捉语义中断和叙事波动。

研究结果: 结果显示，重大事件与H0（连通分量）和H1（环路）的急剧增加相关，表明叙事结构的突然重组。交叉相关分析发现，H0的变化通常先于H1，但俄乌战争中H1熵领先H0，可能反映自上而下的叙事框架。

研究结论: 持久同调提供了一种无监督的数学方法，能够实时检测公共话语的转折点和方向性变化，为计算社会科学提供了新工具。

中文摘要: 如何检测全球事件对公共话语的根本性重塑？本研究引入了一种拓扑框架，利用持久同调识别媒体叙事中的结构变化。通过分析包括俄乌战争（2022年2月）、乔治·弗洛伊德谋杀案（2020年5月）、美国国会大厦骚乱（2021年1月）和哈马斯入侵以色列（2023年10月）在内的国际新闻文章，我们构建了每日名词短语共现图以追踪话语演变。每张图通过Vietoris-Rips过滤嵌入并转化为持久图。随后，我们计算Wasserstein距离和持久熵，以捕捉语义中断和叙事波动。结果显示，重大地缘政治和社会事件与H0（连通分量）和H1（环路）的急剧增加相关，表明叙事结构的突然重组。交叉相关分析揭示了一种典型的滞后模式：H0的变化先于H1的转变，表明语义变化从底层向高层级联。俄乌战争中H1熵领先H0是一个例外，可能反映了自上而下的叙事框架。持久熵进一步区分了紧密聚焦和分散的叙事模式。这些发现表明，持久同调提供了一种数学上严谨的无监督方法，能够在不依赖特定事件先验知识的情况下检测公共注意力的转折点和方向性变化。这种拓扑方法通过实时检测危机、抗议和信息冲击期间的语义重组，推动了计算社会科学的发展。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [205] [DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition](https://arxiv.org/abs/2207.01732)
**中文标题：Deformer：通过耦合可变形局部模式与全局上下文实现鲁棒的端到端语音识别**

*Jiamin Xie,John H. L. Hansen*

主要分类: eess.AS

摘要简述: 本文提出了一种名为Deformer的新型架构，通过引入可变形卷积替代传统CNN中的固定卷积核，以更好地捕捉局部特征与全局上下文的关联，显著提升了端到端语音识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统卷积神经网络（CNN）在语音识别中依赖对称且固定的卷积核，限制了其对非对称局部特征的捕捉能力。本文旨在探索可变形卷积核是否能更有效地结合局部特征与全局注意力机制。

研究方法: 作者在Conformer架构中引入了可变形卷积（Deformer），替代原有的深度卷积层。通过可视化分析，展示了Deformer如何动态调整局部感受野，并与全局注意力机制协同工作。

研究结果: 实验表明，Deformer在WSJ eval92数据集上，无需语言模型时相对WER提升了5.6%，使用语言模型时提升了6.4%。同时，可视化分析揭示了特征关联的增强和网络深度对信息变化的影响。

研究结论: Deformer通过结合可变形局部模式与全局上下文，显著提升了语音识别的鲁棒性，为未来研究提供了新的方向。

中文摘要: 卷积神经网络（CNN）通过利用局部时频模式显著提升了语音识别性能，但传统CNN操作假设这些模式出现在对称且固定的卷积核中。这引发了一个问题：非对称卷积核是否更有效？本研究展示了自适应视图能够发现比固定视图更易于与注意力机制耦合的局部特征。我们在Conformer架构中用可变形卷积替代深度卷积，并将其命名为“Deformer”。通过分析性能最佳的模型，我们可视化了Deformer学习的局部感受野和全局注意力图，并展示了其在语句级别上增强的特征关联。对学习到的卷积核偏移的统计分析揭示了网络深度对特征信息变化的影响。最终，仅在编码器中替换一半的层，Deformer在WSJ eval92数据集上无需语言模型时相对WER提升了5.6%，使用语言模型时提升了6.4%。

</details>


### [206] [Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model](https://arxiv.org/abs/2309.13018)
**中文标题：动态ASR路径：一种自适应掩码方法用于多语言ASR模型的高效剪枝**

*Jiamin Xie,Ke Li,Jinxi Guo,Andros Tjandra,Yuan Shangguan,Leda Sari,Chunyang Wu,Junteng Jia,Jay Mahadeokar,Ozlem Kalinli*

主要分类: eess.AS

摘要简述: 本文提出了一种自适应掩码方法（Dynamic ASR Pathways），用于高效剪枝多语言ASR模型，动态调整子网络结构，优于现有剪枝方法，并减少语言特定剪枝需求。


<details>
  <summary>详细信息</summary>
研究动机: 多语言自动语音识别（ASR）模型的剪枝通常需要多次剪枝和重新训练，效率低下。本文旨在通过自适应掩码方法动态调整子网络结构，避免固定子网络结构的过早决策，从而提高剪枝效率。

研究方法: 提出了一种自适应掩码方法（Dynamic ASR Pathways），用于两种场景：生成稀疏单语言模型或稀疏多语言模型。该方法动态调整子网络，避免固定子网络结构的限制。

研究结果: 实验表明，该方法在生成稀疏单语言模型时优于现有剪枝方法，同时通过动态调整子网络初始化，联合发现并训练更好的多语言模型子网络（路径）。

研究结论: Dynamic ASR Pathways方法通过自适应掩码动态调整子网络，显著提高了剪枝效率，减少了语言特定剪枝的需求，为多语言ASR模型的压缩提供了高效解决方案。

中文摘要: 神经网络剪枝是一种有效压缩多语言自动语音识别（ASR）模型的方法，但通常需要针对每种语言进行多次剪枝和重新训练。本文提出了一种自适应掩码方法，用于两种场景：生成稀疏单语言模型或稀疏多语言模型（称为动态ASR路径）。该方法动态调整子网络，避免对固定子网络结构的过早决策。实验表明，在生成稀疏单语言模型时，该方法优于现有剪枝方法。此外，动态ASR路径通过从不同子网络初始化中自适应调整，联合发现并训练更好的多语言模型子网络（路径），从而减少语言特定剪枝的需求。

</details>


### [207] [MixRep: Hidden Representation Mixup for Low-Resource Speech Recognition](https://arxiv.org/abs/2310.18450)
**中文标题：MixRep：面向低资源语音识别的隐藏表示混合方法**

*Jiamin Xie,John H. L. Hansen*

主要分类: eess.AS

摘要简述: MixRep是一种针对低资源语音识别的简单有效的数据增强方法，通过混合神经网络隐藏表示的特征维度，结合时间轴正则化，显著提升了识别性能。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语音识别（ASR）面临数据不足的挑战，传统方法如SpecAugment虽有效但仍有改进空间。MixRep旨在通过混合隐藏表示的特征维度，结合时间轴正则化，进一步提升低资源ASR的性能。

研究方法: MixRep提出了一种基于混合隐藏表示特征维度的数据增强策略，可应用于声学特征输入和每层输出，并扩展了之前的MixSpeech方法。此外，MixRep结合了时间轴正则化，进一步优化性能。该方法在E2E LAS架构的Conformer编码器中应用，并使用联合CTC损失进行训练。

研究结果: 在WSJ数据集和SWB数据集的子集上实验表明，MixRep在低资源ASR中表现优于其他正则化方法。与SpecAugment基线相比，MixRep在eval92集和eval'2000集的Callhome部分分别实现了6.5%和6.7%的相对WER降低。

研究结论: MixRep通过混合隐藏表示和时间轴正则化，显著提升了低资源语音识别的性能，为数据增强提供了新的思路。

中文摘要: 本文提出MixRep，一种基于混合隐藏表示特征维度的简单有效的数据增强策略，适用于低资源语音识别。MixRep可应用于声学特征输入和每层输出，扩展了之前的MixSpeech方法。此外，我们提出将混合与时间轴正则化结合，实验证明二者互补。MixRep应用于E2E LAS架构的Conformer编码器，并使用联合CTC损失训练。在WSJ数据集和SWB数据集的子集上进行实验，涵盖朗读和电话对话语音。实验结果表明，MixRep在低资源ASR中表现优于其他正则化方法。与SpecAugment基线相比，MixRep在eval92集和eval'2000集的Callhome部分分别实现了6.5%和6.7%的相对WER降低。

</details>


### [208] [Factorized RVQ-GAN For Disentangled Speech Tokenization](https://arxiv.org/abs/2506.15456)
**中文标题：解耦语音标记的因子化RVQ-GAN**

*Sameer Khurana,Dominik Klement,Antoine Laurent,Dominik Bobos,Juraj Novosad,Peter Gazdik,Ellen Zhang,Zili Huang,Amir Hussein,Ricard Marxer,Yoshiki Masuyama,Ryo Aihara,Chiori Hori,Francois G. Germain,Gordon Wichern,Jonathan Le Roux*

主要分类: eess.AS

摘要简述: 本文提出了一种分层音频编解码器（HAC），通过将瓶颈分解为声学、音素和词汇三个层次，结合知识蒸馏目标，实现了语音标记的解耦，并在自然度和重建质量上优于单层次基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有的语音编解码器通常仅关注单一层次的信息（如声学或音素），缺乏对语音多层次结构的统一建模。本文旨在通过分层设计，同时捕捉声学细节和词汇语义，为下游任务提供更丰富的离散语音表示。

研究方法: HAC通过将瓶颈分解为声学、音素和词汇三个层次，利用HuBERT预训练语音编码器提取音素结构，以及LaBSE文本编码器提取词汇线索，结合知识蒸馏目标实现多层次信息的解耦。

研究结果: 实验表明，HAC生成的标记集在英语和多语言数据上均能解耦音素和词汇语义，且在自然度和重建质量上优于单层次基线。

研究结论: HAC作为一种统一的离散语音表示方法，能够桥接声学细节和词汇语义，为语音生成和理解任务提供了潜力。

中文摘要: 我们提出了分层音频编解码器（HAC），这是一种统一的神经语音编解码器，其瓶颈被分解为声学、音素和词汇三个层次。HAC利用两种知识蒸馏目标：一种来自预训练的语音编码器（HuBERT）以提取音素结构，另一种来自基于文本的编码器（LaBSE）以捕捉词汇线索。在英语和多语言数据上的实验表明，HAC的因子化瓶颈生成了解耦的标记集：一个与音素对齐，另一个捕获词汇级语义。定量评估证实，HAC标记在保留自然度的同时提供了可解释的语言信息，在解耦和重建质量上均优于单层次基线。这些发现凸显了HAC作为统一离散语音表示的潜力，能够桥接声学细节和词汇语义，为下游语音生成和理解任务提供支持。

</details>


### [209] [Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition](https://arxiv.org/abs/2506.14973)
**中文标题：方向性思维：面向多说话者定向语音识别的语音大语言模型**

*Jiamin Xie,Ju Lin,Yiteng Huang,Tyler Vuong,Zhaojiang Lin,Zhaojun Yang,Peng Su,Prashant Rawat,Sangeeta Srivastava,Ming Sun,Florian Metze*

主要分类: eess.AS

摘要简述: 本文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制，通过S-DOT和CDDA技术提升模型对方向性的理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLM）在语音识别方面表现出色，但其在多通道音频和空间线索处理方面的能力尚未充分研究。本文旨在填补这一空白，探索如何利用智能设备的麦克风阵列实现更高效的定向语音处理。

研究方法: 提出directional-SpeechLlama模型，结合智能眼镜的麦克风阵列，采用两种关键技术：序列化定向输出训练（S-DOT）和对比方向数据增强（CDDA），以增强模型对方向性信息的理解。

研究结果: 实验结果表明，directional-SpeechLlama能够有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中表现优异。

研究结论: 本文提出的方法为多通道音频处理提供了新的解决方案，展示了智能设备在定向语音识别和声源定位中的潜力。

中文摘要: 近期研究表明，通过音频编码提示大型语言模型（LLM）可实现高效的语音识别能力。然而，语音LLM在理解和处理具有空间线索的多通道音频方面的能力仍是一个研究较少的领域。本文提出directional-SpeechLlama，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制。为增强模型对方向性的理解，我们提出了两种关键技术：序列化定向输出训练（S-DOT）和对比方向数据增强（CDDA）。实验结果表明，directional-SpeechLlama能够有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中表现优异。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [210] [Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](https://arxiv.org/abs/2506.15290)
**中文标题：基于服装感知扩散模型的稀疏松散惯性传感器人体运动捕捉**

*Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz*

主要分类: cs.GR

摘要简述: 本文提出了一种基于稀疏且松散附着惯性传感器（IMU）的全人体姿态估计新任务，并通过基于Transformer的扩散模型和服装感知数据模拟，显著提升了姿态估计的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常假设IMU传感器紧密附着于人体，但在实际场景中这一假设常不成立。本文旨在解决稀疏且松散附着IMU传感器的全人体姿态估计问题，以应对现实场景中的挑战。

研究方法: 通过模拟现有服装感知运动数据集的IMU记录，开发了基于Transformer的扩散模型，用于合成松散IMU数据并估计人体姿态。同时，在训练中引入服装相关参数以增强模型对服装松紧变化的适应性。

研究结果: 实验表明，所提出的扩散模型在模拟和合成数据上训练后，在定量和定性上均优于现有方法，为未来研究提供了新方向。

研究结论: 本文提出的方法在松散附着IMU传感器的人体姿态估计任务中表现出色，结合服装感知数据显著提升了模型的表达能力，为实际应用提供了可靠解决方案。

中文摘要: 稀疏惯性传感器的运动捕捉因其便携性和无遮挡问题而显示出巨大潜力。现有方法通常假设IMU传感器紧密附着于人体，但这一假设在实际场景中常不成立。本文提出了一种基于稀疏松散附着IMU传感器的全人体姿态估计新任务。为解决此任务，我们模拟了现有服装感知运动数据集的IMU记录，并开发了基于Transformer的扩散模型，用于合成松散IMU数据并基于此估计人体姿态。此外，训练中引入服装相关参数有效保持了模型的表达能力，并增强了对服装松紧变化的捕捉能力。实验表明，所提出的扩散模型在模拟和合成数据上训练后，在定量和定性上均优于现有方法，为未来研究开辟了有前景的方向。

</details>


### [211] [One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning](https://arxiv.org/abs/2506.15312)
**中文标题：基于生成扩散先验和指令调优的野外单次人脸素描合成**

*Han Wu,Junyao Li,Kangbo Zhao,Sen Zhang,Yukai Shi,Liang Lin*

主要分类: cs.GR

摘要简述: 本文提出了一种基于扩散模型的单次人脸素描合成方法，通过优化文本指令实现高效生成，并引入新基准数据集OS-Sketch验证其性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸素描合成方法依赖大量训练数据，面临数据稀缺和人工成本高的问题。本文旨在通过扩散模型和指令优化，实现单次学习下的高效素描合成。

研究方法: 利用扩散模型优化文本指令，通过梯度优化生成指令用于推理。引入OS-Sketch数据集，包含400对多样化照片-素描对，用于单次训练和全面评估。

研究结果: 实验表明，该方法能在单次学习下将多种照片转换为逼真且一致的素描，相比其他方法更具便利性和广泛适用性。

研究结论: 提出的方法在单次学习场景下表现出色，解决了数据稀缺问题，并提供了更便捷的素描合成方案。数据集将公开供研究使用。

中文摘要: 人脸素描合成是一种将人脸照片转换为素描的技术。现有研究主要依赖大量照片-素描对进行训练，但这类大规模判别学习方法面临数据稀缺和高人工成本问题。一旦训练数据不足，生成性能会显著下降。本文提出了一种基于扩散模型的单次人脸素描合成方法。我们通过优化扩散模型的文本指令，利用照片-素描对生成梯度优化的指令用于推理。为更真实模拟实际场景并全面评估方法效果，我们引入了新基准数据集OS-Sketch，包含400对多样化照片-素描图像，涵盖不同风格、背景、年龄、性别、表情和光照等。为进行稳健的分布外评估，每次仅用一对图像训练，其余用于推理。大量实验表明，该方法能在单次学习下将多种照片转换为逼真且高度一致的素描，相比其他方法更具便利性和广泛适用性。数据集将发布于：https://github.com/HanWu3125/OS-Sketch

</details>


### [212] [Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards](https://arxiv.org/abs/2506.15684)
**中文标题：Nabla-R2D3：基于2D奖励的高效3D扩散对齐方法**

*Qingming Liu,Zhen Liu,Dinghuai Zhang,Kui Jia*

主要分类: cs.GR

摘要简述: 本文提出Nabla-R2D3，一种基于2D奖励的高效3D扩散模型对齐框架，通过强化学习优化3D生成质量，显著提升模型对齐能力和生成效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D生成模型（如扩散模型）在生成高质量3D资产时仍存在不足，如难以遵循指令、对齐人类偏好或生成逼真纹理和几何。本文旨在通过2D奖励信号优化3D扩散模型，解决这些问题。

研究方法: 基于Nabla-GFlowNet方法，提出Nabla-R2D3框架，通过奖励梯度匹配原理，仅使用2D奖励信号对3D扩散模型进行高效对齐和微调。

研究结果: 实验表明，Nabla-R2D3在少量微调步骤内即可实现更高奖励和更低先验遗忘，优于传统微调基线。

研究结论: Nabla-R2D3为3D生成模型提供了一种高效对齐方法，显著提升了生成质量和指令遵循能力。

中文摘要: 生成高质量且逼真的3D资产一直是3D视觉和计算机图形学中的长期挑战。尽管扩散模型等先进生成模型在3D生成方面取得了显著进展，但由于难以遵循指令、对齐人类偏好或生成逼真纹理、几何和物理属性，它们仍无法匹敌人工设计内容。本文提出Nabla-R2D3，一种基于2D奖励的高效强化学习对齐框架，用于优化3D原生扩散模型。该方法基于近期提出的Nabla-GFlowNet，通过奖励梯度匹配原理实现3D扩散模型的高效微调。大量实验表明，与难以收敛或存在奖励攻击的传统微调基线相比，Nabla-R2D3在少量微调步骤内即可实现更高奖励和更低先验遗忘。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [213] [See What I Mean? CUE: A Cognitive Model of Understanding Explanations](https://arxiv.org/abs/2506.14775)
**中文标题：明白我的意思吗？CUE：一种理解解释的认知模型**

*Tobias Labarta,Nhi Hoang,Katharina Weitz,Wojciech Samek,Sebastian Lapuschkin,Leander Weber*

主要分类: cs.HC

摘要简述: 本文提出CUE模型，研究解释性AI（XAI）的认知可理解性，发现视觉障碍用户在使用热力图时表现相似但信心/努力较低，且优化色彩方案并未改善问题，支持自适应XAI界面的需求。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习系统在关键决策中的作用增强，解释性AI（XAI）的需求日益突出。当前XAI评估多关注技术保真度，而忽略了认知可访问性，尤其是对视觉障碍用户的影响。

研究方法: 提出CUE模型，将解释属性与认知子过程（可读性、可理解性、可解释性）关联。通过实验（N=455）测试不同色彩方案（BWR、Cividis、Coolwarm）的热力图对用户的影响。

研究结果: 实验结果显示，视觉障碍用户的任务表现与普通用户相当，但信心和努力程度较低。优化色彩方案（如Cividis）未改善问题，甚至在某些情况下加剧了差距。

研究结论: 研究挑战了感知优化的假设，支持自适应XAI界面的必要性。CUE模型验证了解释可读性对理解的影响，贡献包括：形式化的认知模型、以人为中心的解释属性定义，以及推动可访问XAI的实证证据。

中文摘要: 随着机器学习系统在关键决策中的作用日益重要，对人类可理解的解释需求也在增长。当前对可解释AI（XAI）的评估往往优先考虑技术保真度，而忽略了认知可访问性，这对用户（尤其是视觉障碍用户）至关重要。我们提出了CUE（Cognitive Understanding of Explanations）模型，将解释属性与认知子过程（可读性、可理解性、可解释性）联系起来。在一项研究中（N=455），测试了不同色彩方案（BWR、Cividis、Coolwarm）的热力图，发现视觉障碍用户的任务表现与普通用户相当，但信心和努力程度较低。出乎意料的是，专注于可访问性的色彩方案（如Cividis）并未缩小差距，有时甚至加剧了问题。这些结果挑战了感知优化的假设，支持自适应XAI界面的需求。它们还通过改变解释可读性影响理解性验证了CUE模型。我们的贡献包括：（1）形式化的解释理解认知模型，（2）以人为中心的解释属性定义，（3）推动可访问、用户定制XAI的实证证据。

</details>


### [214] [WebXAII: an open-source web framework to study human-XAI interaction](https://arxiv.org/abs/2506.14777)
**中文标题：WebXAII：一个用于研究人类与可解释人工智能交互的开源网络框架**

*Jules Leguy,Pierre-Antoine Jean,Felipe Torres Figueroa,Sébastien Harispe*

主要分类: cs.HC

摘要简述: 本文介绍了WebXAII，一个开源网络框架，旨在促进人类与可解释人工智能（XAI）系统的交互研究。该框架通过模块化设计和结构化配置文件，简化实验协议的实现，提升实验的可重用性和可重复性。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能（尤其是机器学习）在各领域的广泛应用，XAI研究迅速扩展。然而，现有研究中的人类-XAI交互界面多为临时开发且未共享，限制了实验的可重用性和可重复性。WebXAII旨在解决这一问题。

研究方法: 设计并实现了WebXAII，一个基于网络的平台，能够完整呈现实验协议并记录参与者响应。实验协议通过通用视图和模块的复合架构实现，灵活性高，且仅需结构化配置文件即可实现，降低编程技能要求。

研究结果: 通过复现一项前沿研究协议，验证了WebXAII的有效性。该框架成功实现了实验协议的模块化呈现和数据记录。

研究结论: WebXAII为人类-XAI交互研究提供了灵活、易用的工具，显著提升了实验的可重用性和可重复性。

中文摘要: 本文介绍了WebXAII，一个开源网络框架，旨在促进人类与可解释人工智能（XAI）系统的交互研究。随着人工智能（尤其是机器学习）在各领域的广泛应用，XAI研究迅速扩展。研究人类与XAI技术交互的学者通常需要临时开发界面，但这些界面往往未与研究成果共享，限制了实验的可重用性和可重复性。为此，我们设计并实现了WebXAII，这是一个基于网络的平台，能够完整呈现实验协议并记录参与者响应。实验协议通过通用视图和模块的复合架构实现，灵活性高，且仅需结构化配置文件即可实现，降低编程技能要求。我们通过复现一项前沿研究协议，验证了WebXAII的有效性。该框架可在https://github.com/PAJEAN/WebXAII获取。

</details>


### [215] [Analyzing Character Representation in Media Content using Multimodal Foundation Model: Effectiveness and Trust](https://arxiv.org/abs/2506.14799)
**中文标题：利用多模态基础模型分析媒体内容中的角色表征：有效性与信任度**

*Evdoxia Taka,Debadyuti Bhattacharya,Joanne Garde-Hansen,Sanjay Sharma,Tanaya Guha*

主要分类: cs.HC

摘要简述: 本文提出了一种基于CLIP多模态基础模型的工具，用于分析媒体内容中角色的性别和年龄分布，并通过用户研究验证其实用性和可信度。结果显示工具总体有用，但用户对AI生成结果的信任度中等偏低。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有研究使用机器学习模型量化媒体内容中角色的性别和年龄分布，但缺乏对公众实用性和信任度的探讨。本文旨在填补这一空白，同时开发一种新的AI工具。

研究方法: 基于CLIP模型分析视觉屏幕数据，量化角色的性别和年龄分布，并设计适合普通观众的可视化工具。通过用户研究评估工具的实用性和AI生成结果的可信度。

研究结果: 用户能够通过可视化工具理解分析结果，认为工具总体有用，但希望增加更多人口统计类别和角色上下文信息。用户对AI模型的信任度中等偏低。

研究结论: AI工具在分析角色分布方面具有实用性，但需改进以提升用户信任度。未来可扩展更多人口统计维度和上下文信息。

中文摘要: 近年来，AI的进步使得大规模自动化分析复杂媒体内容成为可能，并能够生成关于角色性别和年龄等维度的可操作见解。以往研究主要使用多种机器学习模型从音频/视频/文本中量化角色分布，但未考虑受众的参与。我们提出，即使角色的人口统计分布数据可用，其对公众的实际用途如何？公众是否信任AI模型生成的数字？本文通过用户研究探讨这些问题，并提出一种基于AI的角色表征和可视化工具。该工具基于对比语言图像预训练（CLIP）基础模型，分析视觉屏幕数据以量化角色的年龄和性别分布。我们还设计了适合普通观众的可视化方案。随后，通过用户研究验证AI生成结果在选定电影中的实用性和可信度。结果显示，参与者能够通过可视化理解分析结果，并认为工具“总体有用”，但也希望增加更多人口统计类别和角色上下文信息。参与者对AI性别和年龄模型的信任度中等偏低，但并不反对在此背景下使用AI。工具代码、基准测试和用户研究数据详见：https://anonymous.4open.science/r/Character-Representation-Media-FF7B

</details>


### [216] [The Hardness of Achieving Impact in AI for Social Impact Research: A Ground-Level View of Challenges & Opportunities](https://arxiv.org/abs/2506.14829)
**中文标题：AI社会影响研究中实现实际影响的困难：挑战与机遇的基层视角**

*Aditya Majumdar,Wenbo Zhang,Kashvi Prawal,Amulya Yadav*

主要分类: cs.HC

摘要简述: 本文探讨了AI社会影响研究（AI4SI）中实现实际影响的困难，分析了合作、部署和社区认可等多重挑战，并提出了改进策略。


<details>
  <summary>详细信息</summary>
研究动机: 尽管AI4SI项目旨在通过AI解决社会问题（如医疗和社会公正），但实际影响难以实现。本文旨在揭示阻碍AI4SI项目落地的主要因素，并为研究人员和合作组织提供实用指导。

研究方法: 通过半结构化访谈六位领先的AI4SI研究人员，并结合作者自身经验，采用主题分析法识别部署中的关键障碍。

研究结果: 研究发现，结构性与组织性、沟通、协作和操作问题是阻碍AI4SI项目落地的核心挑战。文章总结了改进策略和最佳实践。

研究结论: AI4SI研究面临多重挑战，但通过系统性改进和合作优化，可以提升其社会影响力。本文为相关研究者和组织提供了实用参考。

中文摘要: 为应对联合国可持续发展目标（SDGs），AI社会影响（AI4SI）项目致力于利用AI解决医疗、社会公正等领域的社会问题。然而，尽管AI4SI兴趣日增，实现实际影响仍面临重大挑战。例如，寻找并激励愿意共同设计和部署AI解决方案的合作者往往困难重重。即使建立合作关系，许多AI4SI项目仍止步于概念验证阶段，无法过渡到规模化生产级解决方案。此外，AI4SI研究者面临的独特挑战在更广泛的AI社区中并未得到充分认可，这类工作常被视为应用性为主，不符合核心AI领域对新颖性的传统标准。本文通过诊断阻碍AI4SI合作实现实际影响的多重因素，揭示了AI4SI研究的多样化挑战。基于对六位领先AI4SI研究者的半结构化访谈及作者自身经验，本文试图理解开发和部署社会影响AI解决方案的日常困难。通过主题分析，我们识别出结构性、组织性、沟通、协作和操作问题为部署的核心障碍。尽管没有简单解决方案，我们综合了访谈和自身工作中的最佳实践与可行策略。希望本文能为AI4SI研究者及合作组织提供实用参考，助力更有效开展社会影响AI合作。

</details>


### [217] [Insights Informed Generative AI for Design: Incorporating Real-world Data for Text-to-Image Output](https://arxiv.org/abs/2506.15008)
**中文标题：基于真实世界数据的生成式AI设计洞察：为文本到图像输出融入可持续性指标**

*Richa Gupta,Alexander Htet Kyaw*

主要分类: cs.HC

摘要简述: 本文提出了一种结合DALL-E 3与材料数据集的新方法，通过后处理模块为AI生成的设计图像添加可持续性指标和材料使用数据，帮助设计师评估环境影响并优化设计提示。


<details>
  <summary>详细信息</summary>
研究动机: 生成式AI（如文本到图像模型）在室内建筑设计中的应用虽然快速高效，但缺乏对可持续性和材料使用的实际数据支持。本文旨在通过整合真实世界数据，为设计师提供更全面的决策依据。

研究方法: 研究提出了一种新流程：首先使用DALL-E 3生成设计图像，随后通过后处理模块识别图像中的主要材料，并匹配材料字典中的二氧化碳当量（CO2e）数据。通过三种用户测试（无可持续性提示、提前告知可持续性目标、提供CO2e数据）验证效果。

研究结果: 研究发现，第三种测试（提供CO2e数据）显著提升了设计师对可持续性的关注，但也可能导致决策疲劳和满意度下降。尽管如此，多数参与者表示会将可持续性原则纳入工作流程。

研究结论: 研究展示了在AI辅助设计中平衡设计自由与可持续性约束的重要性，为数据驱动的生态设计提供了可行路径。

中文摘要: 生成式AI，尤其是文本到图像模型，通过将概念快速转化为视觉表现，彻底改变了室内建筑设计。然而，这些模型生成的图像往往缺乏对设计师有用的实际数据。本文提出了一种新方法，将DALL-E 3与材料数据集结合，为AI生成的设计添加可持续性指标和材料使用数据。生成图像后，后处理模块会识别图像中的前十大材料，并从通用材料字典中匹配其二氧化碳当量（CO2e）值。这种方法使设计师能够即时评估环境影响并优化设计提示。我们通过三种用户测试评估系统：（1）在生成AI提示前不提及可持续性；（2）提前告知用户可持续性目标；（3）在生成AI输出中包含CO2e数据。定性和定量分析表明，第三种测试中引入可持续性指标能促进更明智的设计决策，但也可能引发决策疲劳和满意度下降。尽管如此，多数参与者在第三种测试中表示会将可持续性原则纳入工作流程，凸显了整合指标对生态设计的潜在价值。研究结果表明，平衡设计自由与实际约束的重要性，为AI辅助建筑设计提供了更全面的数据驱动解决方案。

</details>


### [218] [Mapping Caregiver Needs to AI Chatbot Design: Strengths and Gaps in Mental Health Support for Alzheimer's and Dementia Caregivers](https://arxiv.org/abs/2506.15047)
**中文标题：将护理者需求映射到AI聊天机器人设计：阿尔茨海默病和痴呆症护理者心理健康支持的优势与不足**

*Jiayue Melissa Shi,Dong Whi Yoo,Keran Wang,Violeta J. Rodriguez,Ravi Karkar,Koustuv Saha*

主要分类: cs.HC

摘要简述: 本文研究了阿尔茨海默病及相关痴呆症（AD/ADRD）家庭护理者的需求，并设计了一款基于GPT-4o的聊天机器人Carey，以提供信息与情感支持。通过访谈和主题分析，揭示了护理者的六大需求及AI技术的优势与不足，并提出了设计建议。


<details>
  <summary>详细信息</summary>
研究动机: AD/ADRD家庭护理者面临巨大的情感和实际挑战，容易产生压力、焦虑和抑郁。尽管生成式AI（如大型语言模型）为心理健康支持提供了新机会，但护理者对这些技术的认知和接受度尚不明确。本研究旨在填补这一空白。

研究方法: 研究开发了基于GPT-4o的聊天机器人Carey，并通过16名家庭护理者的半结构化访谈和场景驱动互动，采用归纳编码和反思性主题分析方法，系统分析了护理者的需求和期望。

研究结果: 研究揭示了护理者的六大需求主题：即时信息获取、情感支持、安全披露空间、危机管理、个性化服务和数据隐私。同时，发现了护理者需求与AI技术之间的微妙矛盾，并提出了AI聊天机器人的优势、不足及设计建议。

研究结论: 研究为设计主动、可信且以护理者为中心的AI系统提供了理论和实践指导，以更好地满足AD/ADRD护理者不断变化的心理健康需求。

中文摘要: 阿尔茨海默病及相关痴呆症（AD/ADRD）的家庭护理者面临巨大的情感和实际挑战，使其更容易产生压力、焦虑和抑郁。尽管生成式AI（尤其是大型语言模型）为心理健康支持提供了新机会，但护理者对这些技术的认知和接受度尚不清楚。为填补这一空白，我们开发了基于GPT-4o的聊天机器人Carey，旨在为AD/ADRD护理者提供信息和情感支持。通过Carey作为技术探针，我们对16名家庭护理者进行了半结构化访谈，基于常见护理压力场景的互动。通过归纳编码和反思性主题分析，我们系统揭示了护理者的需求和期望，涵盖六大主题：即时信息获取、情感支持、安全披露空间、危机管理、个性化服务和数据隐私。针对每个主题，我们还发现了护理者需求与担忧之间的微妙矛盾。我们提出了护理者需求、AI聊天机器人优势、不足及设计建议的映射。研究结果为设计主动、可信且以护理者为中心的AI系统提供了理论和实践指导，以更好地支持AD/ADRD护理者不断变化的心理健康需求。

</details>


### [219] [Accessible Gesture-Driven Augmented Reality Interaction System](https://arxiv.org/abs/2506.15189)
**中文标题：可访问的手势驱动增强现实交互系统**

*Yikan Wang*

主要分类: cs.HC

摘要简述: 本文提出了一种基于手势的增强现实（AR）交互系统，利用深度学习识别手势，并通过联邦学习和强化学习优化交互界面，显著提升了运动障碍用户的任务完成效率和满意度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的增强现实（AR）交互系统依赖精确输入方式，对运动障碍或灵活性受限的用户不友好。本研究旨在通过手势识别和自适应界面设计，提升AR的可访问性和用户体验。

研究方法: 系统结合视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，采用联邦学习保护用户隐私，并通过强化学习优化菜单布局和交互模式。

研究结果: 实验表明，与基线AR系统相比，该系统将运动障碍用户的任务完成效率提高了20%，用户满意度提升了25%。

研究结论: 该研究为AR交互系统提供了更包容和可扩展的解决方案，显著提升了运动障碍用户的可访问性。

中文摘要: 增强现实（AR）提供了沉浸式交互体验，但由于依赖精确输入方式，对运动障碍或灵活性受限的用户仍不友好。本研究提出了一种基于手势的AR交互系统，利用深度学习从可穿戴传感器和摄像头中识别手势，并根据用户能力调整界面。系统采用视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，并通过联邦学习实现隐私保护的模型训练。强化学习用于优化菜单布局和交互模式等界面元素。实验表明，与基线AR系统相比，该系统将运动障碍用户的任务完成效率提高了20%，用户满意度提升了25%。这一方法显著提升了AR的可访问性和可扩展性。关键词：深度学习，联邦学习，手势识别，增强现实，可访问性，人机交互

</details>


### [220] [Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI](https://arxiv.org/abs/2506.15468)
**中文标题：通过Metropolis-Hastings交互实现人类与AI的协同创造学习**

*Ryota Okumura,Tadahiro Taniguchi,Akira Taniguchi,Yoshinobu Hagiwara*

主要分类: cs.HC

摘要简述: 本文提出了一种新型的协同创造学习范式，通过人类与AI（生物与人工代理）相互整合部分感知信息和知识，构建共享的外部表征，即符号涌现。实验基于Metropolis-Hastings命名游戏（MHNG）模型，结果显示MH-based代理显著提升了分类准确性，并实现了更强的共享符号系统收敛。


<details>
  <summary>详细信息</summary>
研究动机: 传统AI教学基于单向知识传递，难以整合不同模态的信息。本文旨在探索人类与AI如何通过动态交互实现感知经验的动态对齐，从而推动共生AI系统的发展。

研究方法: 采用基于Metropolis-Hastings命名游戏（MHNG）的人类-AI交互模型，通过在线实验让69名参与者与三种计算机代理（MH-based、总是接受或总是拒绝）在部分可观测条件下进行联合注意力命名游戏（JA-NG）。

研究结果: 实验表明，与MH-based代理交互的人类-AI组合显著提高了分类准确性，并实现了更强的共享符号系统收敛。人类接受行为与MH衍生的接受概率高度一致。

研究结论: 研究首次通过MHNG交互实证了人类-AI协同创造学习的涌现，为共生AI系统的动态感知对齐提供了新路径。

中文摘要: 我们提出了一种新型的协同创造学习范式，即人类与AI（生物与人工代理）相互整合其部分感知信息和知识，构建共享的外部表征，这一过程我们解释为符号涌现。与传统基于单向知识传递的AI教学不同，该方法解决了整合不同模态信息的挑战。我们通过基于Metropolis-Hastings命名游戏（MHNG）的人类-AI交互模型对这一框架进行了实证测试。在一项在线实验中，69名参与者与三种计算机代理（MH-based、总是接受或总是拒绝）在部分可观测条件下进行了联合注意力命名游戏（JA-NG）。结果显示，与MH-based代理交互的人类-AI组合显著提高了分类准确性，并实现了更强的共享符号系统收敛。此外，人类的接受行为与MH衍生的接受概率高度一致。这些发现首次为基于MHNG交互的人类-AI协同创造学习提供了实证证据，为共生AI系统的动态感知对齐开辟了新途径。

</details>


### [221] [Optimizing Web-Based AI Query Retrieval with GPT Integration in LangChain A CoT-Enhanced Prompt Engineering Approach](https://arxiv.org/abs/2506.15512)
**中文标题：基于LangChain框架的GPT集成优化Web AI查询检索：一种CoT增强的提示工程方法**

*Wenqi Guan,Yang Fang*

主要分类: cs.HC

摘要简述: 本文提出了一种基于LangChain框架集成GPT模型的新方法，通过CoT推理和提示工程优化远程学习资源检索，提升结果的精确性和相关性，以满足学生的个性化需求。


<details>
  <summary>详细信息</summary>
研究动机: 当前远程学习资源的检索缺乏深度上下文信息，无法满足学生对复杂查询的需求。本文旨在通过集成GPT模型和LangChain框架，结合CoT推理和提示工程，提升检索结果的全面性和相关性。

研究方法: 提出了一种在LangChain框架中集成GPT模型的方法，利用CoT（Chain-of-Thought）推理和提示工程技术，优化远程学习资源的检索过程。

研究结果: 实验表明，该方法在用户满意度和学习效果上优于传统大型语言模型（LLMs），提供了更全面且上下文丰富的检索结果。

研究结论: 通过集成GPT模型和LangChain框架，结合CoT推理和提示工程，本文成功提升了远程学习资源检索的精确性和相关性，为个性化学习提供了有效支持。

中文摘要: 大型语言模型为远程学习学生及其他教育活动带来了革命性变化。然而，当前远程学习资源的检索缺乏深度上下文信息，无法为学生提供复杂查询的全面解答。本文提出了一种新颖方法，通过在LangChain框架中集成基于GPT的模型，结合CoT（Chain-of-Thought）推理和提示工程，优化远程学习资源的检索。该框架着重提升检索结果的精确性和相关性，返回最适合学生需求的全面且上下文丰富的解释和资源。我们还评估了该方法相对于传统大型语言模型的有效性，并报告了用户满意度和学习效果的提升。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [222] [Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers](https://arxiv.org/abs/2506.14855)
**中文标题：反馈-MPPI：通过滚动微分实现基于采样的快速MPC——告别低级控制器**

*Tommaso Belvedere,Michael Ziegltrum,Giulio Turrisi,Valerio Modugno*

主要分类: cs.RO

摘要简述: 本文提出了一种名为Feedback-MPPI（F-MPPI）的新型框架，通过引入局部线性反馈增益来增强标准MPPI控制，显著提高了实时性和稳定性，适用于复杂机器人任务。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于采样的MPPI控制在处理非线性动力学和非凸成本方面具有灵活性，但其在高频率实时控制场景中的计算需求限制了应用。本文旨在通过引入局部反馈增益来解决这一问题。

研究方法: F-MPPI框架通过灵敏度分析计算局部线性反馈增益，这些增益类似于基于Riccati的反馈，能够在无需每一步完全重新优化的情况下快速进行闭环修正。

研究结果: 仿真和实际实验（包括四足机器人在不平地形上的动态运动和四旋翼飞行器的激进机动）表明，F-MPPI显著提升了控制性能和稳定性，适合复杂机器人系统的高频操作。

研究结论: F-MPPI通过局部反馈增益的引入，有效解决了标准MPPI的计算瓶颈，为复杂机器人任务提供了高效、稳定的控制方案。

中文摘要: 模型预测路径积分控制（MPPI）是一种强大的基于采样的方法，因其在处理非线性动力学和非凸成本方面的灵活性而适用于复杂机器人任务。然而，其在实时高频机器人控制场景中的应用受限于计算需求。本文提出了反馈-MPPI（F-MPPI），这是一种新颖的框架，通过从灵敏度分析中计算局部线性反馈增益来增强标准MPPI，这些增益受到基于Riccati的反馈（常用于基于梯度的MPC）的启发。这些增益允许在当前状态周围进行快速闭环修正，而无需在每一步进行完全重新优化。我们通过仿真和实际实验（包括四足机器人在不平地形上的动态运动和四旋翼飞行器的激进机动）展示了F-MPPI的有效性。结果表明，引入局部反馈显著提高了控制性能和稳定性，为复杂机器人系统提供了鲁棒的高频操作能力。

</details>


### [223] [FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization](https://arxiv.org/abs/2506.14968)
**中文标题：FEAST：一种面向野外个性化的灵活用餐辅助系统**

*Rajat Kumar Jenamani,Tom Silver,Ben Dodson,Shiqin Tong,Anthony Song,Yuting Yang,Ziang Liu,Benjamin Howe,Aimee Whitneck,Tapomayukh Bhattacharjee*

主要分类: cs.RO

摘要简述: FEAST是一种灵活的用餐辅助系统，旨在满足个性化需求，通过模块化硬件、多样化交互方式和参数化行为树实现适应性、透明性和安全性。


<details>
  <summary>详细信息</summary>
研究动机: 全球数百万人需要用餐辅助，但家庭用餐辅助面临活动多样性、情境复杂性和用户偏好差异等挑战。FEAST旨在通过个性化设计解决这些问题。

研究方法: FEAST采用模块化硬件支持喂食、饮水和擦嘴功能，提供网页界面、头部手势和物理按钮等交互方式，并利用参数化行为树和大语言模型实现安全透明的个性化适配。

研究结果: FEAST在个性化需求上表现优于固定定制基线系统，并通过家庭用户研究和职业治疗师评估验证了其实际适用性和生态效度。

研究结论: FEAST成功实现了灵活、透明和安全的个性化用餐辅助，满足不同用户的独特需求，展现了实际应用潜力。

中文摘要: 物理护理机器人有望改善全球数百万需要用餐辅助的人的生活质量。然而，家庭用餐辅助仍面临活动多样性（如进食、饮水、擦嘴）、情境复杂性（如社交、看电视）、食物种类和用户偏好等挑战。本文提出FEAST，一种可在野外个性化以满足个体护理对象独特需求的灵活用餐辅助系统。通过与两位社区研究人员合作开发，并基于对多样化护理对象的形成性研究，我们的系统遵循适应性、透明性和安全性三大原则。FEAST通过以下方式体现这些原则：（i）模块化硬件支持喂食、饮水和擦嘴功能切换；（ii）多样化交互方法（如网页界面、头部手势和物理按钮）以适应不同功能能力和偏好；（iii）参数化行为树，可通过大语言模型安全透明地适配。我们根据形成性研究确定的个性化需求评估系统，证明FEAST提供广泛透明安全的适配，并优于仅限于固定定制的最先进基线系统。为验证实际适用性，我们与两位护理对象（社区研究人员）进行家庭用户研究，在三种不同场景下各喂食三餐。我们还通过一位此前不熟悉系统的职业治疗师评估FEAST的生态效度。在所有案例中，用户均成功个性化FEAST以满足其需求和偏好。网站：https://emprise.cs.cornell.edu/feast

</details>


### [224] [Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired](https://arxiv.org/abs/2506.14857)
**中文标题：面向视障人士引导的无人机感知避障技术**

*Suman Raj,Swapnil Padhi,Ruchi Bhoot,Prince Modi,Yogesh Simmhan*

主要分类: cs.RO

摘要简述: 本文提出了一种基于感知的无人机路径规划系统，用于辅助视障人士在户外城市环境中导航。系统结合局部感知与全局规划，采用多深度神经网络框架实现无人机和视障人士的避障。实验验证了系统在三种场景下的可行性。


<details>
  <summary>详细信息</summary>
研究动机: 无人机结合机载传感器、机器学习和计算机视觉算法在多个领域（如农业、物流和灾害管理）展现出潜力。本文旨在探索无人机如何辅助视障人士在复杂的户外城市环境中安全导航，解决其出行难题。

研究方法: 提出了一种基于感知的路径规划系统，结合局部感知（用于视障人士周围环境规划）和全局规划（基于GPS和地图）。通过几何问题建模和多深度神经网络框架，实现无人机和视障人士的障碍物避让。

研究结果: 在校园环境中对无人机-人系统进行了实验，验证了系统在三种场景下的可行性：视障人士在人行道行走、靠近停放车辆以及在拥挤街道中导航。

研究结论: 研究表明，基于感知的路径规划系统能够有效辅助视障人士在复杂环境中导航，为无人机在辅助技术中的应用提供了新思路。

中文摘要: 无人机通过机载传感器结合机器学习和计算机视觉算法实现自主导航，已在农业、物流和灾害管理等领域产生影响。本文研究了无人机在辅助视障人士（VIPs）在户外城市环境中导航的应用。具体而言，我们提出了一种基于感知的路径规划系统，该系统结合了针对视障人士周围环境的局部规划器和基于GPS与地图的全局规划器。我们通过几何建模表示问题，并提出了一种基于多深度神经网络的框架，用于无人机和视障人士的障碍物避让。在校园环境中对无人机-人系统进行的评估验证了我们的算法在三种场景下的可行性：视障人士在人行道行走、靠近停放车辆以及在拥挤街道中导航。

</details>


### [225] [Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation](https://arxiv.org/abs/2506.15157)
**中文标题：鲁棒即时策略：利用学生t回归模型实现机器人操作的鲁棒上下文模仿学习**

*Hanbit Oh,Andrea M. Salcedo-Vázquez,Ixchel G. Ramirez-Alpizar,Yukiyasu Domae*

主要分类: cs.RO

摘要简述: 本文提出了一种鲁棒的即时策略（RIP），利用学生t回归模型解决基于大语言模型（LLM）的即时策略在模仿学习中的幻觉问题，显著提高了任务成功率。


<details>
  <summary>详细信息</summary>
研究动机: 模仿学习（IL）通过观察少量人类演示使机器人自主完成任务。然而，基于大语言模型（LLM）的即时策略存在幻觉问题，导致生成的轨迹偏离演示，影响可靠性。

研究方法: RIP算法通过生成多个候选轨迹，并利用学生t分布聚合这些轨迹，从而忽略异常值（幻觉），生成鲁棒的轨迹。

研究结果: 实验表明，RIP在模拟和真实环境中均显著优于现有模仿学习方法，任务成功率至少提高26%，尤其在低数据量的日常任务中表现突出。

研究结论: RIP通过学生t回归模型有效解决了即时策略的幻觉问题，为机器人模仿学习提供了更可靠的解决方案。

中文摘要: 模仿学习（IL）旨在通过观察少量人类演示使机器人自主完成任务。近年来，一种称为上下文模仿学习（In-Context IL）的变体利用现成的大语言模型（LLM）作为即时策略，通过少量演示理解上下文以执行新任务，而无需显式更新大规模演示的网络模型。然而，其在机器人领域的可靠性因幻觉问题（如LLM生成的即时策略偶尔产生偏离演示的轨迹）而受到质疑。为解决这一问题，我们提出了一种新的鲁棒上下文模仿学习算法——鲁棒即时策略（RIP），利用学生t回归模型对抗即时策略的幻觉轨迹，从而生成可靠的轨迹。具体而言，RIP从LLM生成多个候选机器人轨迹，并通过学生t分布聚合这些轨迹，有效忽略异常值（即幻觉），生成鲁棒的轨迹。我们在模拟和真实环境中的实验表明，RIP显著优于现有模仿学习方法，任务成功率至少提高26%，尤其在低数据量的日常任务中表现突出。视频结果见https://sites.google.com/view/robustinstantpolicy。

</details>


### [226] [MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System](https://arxiv.org/abs/2506.15402)
**中文标题：MCOO-SLAM：一种多相机全景物体SLAM系统**

*Miaoxin Pan,Jinnan Li,Yaowen Zhang,Yi Yang,Yufeng Yue*

主要分类: cs.RO

摘要简述: MCOO-SLAM是一种多相机全景物体SLAM系统，通过环绕视角相机配置实现复杂户外场景中的鲁棒、一致且语义丰富的建图。


<details>
  <summary>详细信息</summary>
研究动机: 现有物体级SLAM方法多依赖RGB-D传感器或单目视角，存在视野狭窄、遮挡敏感和深度感知有限等问题，尤其在户外大场景中表现不佳。MCOO-SLAM旨在通过多相机全景配置解决这些问题。

研究方法: MCOO-SLAM整合了点特征和物体级地标，并引入语义-几何-时间融合策略以实现多视角下的鲁棒物体关联。系统还设计了全景闭环模块，支持基于场景描述符的视角无关地点识别，并将地图抽象为分层3D场景图。

研究结果: 实验表明，MCOO-SLAM在真实场景中实现了高精度定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强的鲁棒性。

研究结论: MCOO-SLAM通过多相机全景配置和语义增强，显著提升了物体级SLAM在复杂户外场景中的性能，为下游推理任务提供了结构化支持。

中文摘要: 物体级SLAM提供了结构化且语义丰富的环境表示，使其更易解释并适用于高级机器人任务。然而，现有方法多依赖RGB-D传感器或单目视角，存在视野狭窄、遮挡敏感和深度感知有限等问题，尤其是在大场景或户外环境中。这些限制通常导致系统只能从有限视角观察到物体的部分视图，从而影响物体建模的准确性和数据关联的可靠性。本文提出MCOO-SLAM，一种新型多相机全景物体SLAM系统，充分利用环绕视角相机配置，在复杂户外场景中实现鲁棒、一致且语义丰富的建图。该方法整合了点特征和物体级地标，并引入语义-几何-时间融合策略以实现多视角下的鲁棒物体关联，从而提升一致性和物体建模准确性。此外，设计了全景闭环模块，支持基于场景描述符的视角无关地点识别，并将构建的地图抽象为分层3D场景图以支持下游推理任务。真实场景中的大量实验表明，MCOO-SLAM实现了高精度定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强的鲁棒性。

</details>


### [227] [Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos](https://arxiv.org/abs/2506.15680)
**中文标题：基于粒子-网格神经动力学的RGB-D视频可变形物体模型学习**

*Kaifeng Zhang,Baoyu Li,Kris Hauser,Yunzhu Li*

主要分类: cs.RO

摘要简述: 本文提出了一种结合粒子与空间网格的神经动力学框架，用于从RGB-D视频中学习可变形物体的动态模型，实现了对多种形状和材质物体的建模，并在实验中验证了其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 可变形物体的动态建模因其多样的物理特性和从有限视觉信息中估计状态的困难而具有挑战性。本文旨在通过结合粒子与空间网格的混合表示，解决这些问题。

研究方法: 方法采用粒子表示物体形状，空间网格离散化3D空间以确保空间连续性并提升学习效率。结合高斯溅射进行视觉渲染，实现了完全基于学习的可变形物体数字孪生，并生成3D动作条件视频。

研究结果: 实验表明，该模型能够从稀疏视角的RGB-D记录中学习多种物体（如绳索、布料、毛绒玩具和纸袋）的动态，并在类别级别上泛化到未见过的实例。其性能优于现有基于学习和物理的模拟器，尤其在视角受限的场景中。

研究结论: 本文提出的粒子-网格神经动力学框架为可变形物体的动态建模提供了高效解决方案，并在模型规划中展示了实用性，支持目标驱动的物体操控任务。

中文摘要: 由于可变形物体多样的物理特性以及从有限视觉信息中估计状态的困难，其动态建模具有挑战性。我们通过一种结合物体粒子和空间网格的混合表示的神经动力学框架来解决这些问题。我们的粒子-网格模型捕捉全局形状和运动信息，同时预测密集粒子运动，从而能够建模具有不同形状和材质的物体。粒子表示物体形状，而空间网格将3D空间离散化以确保空间连续性并提升学习效率。结合高斯溅射进行视觉渲染，我们的框架实现了完全基于学习的可变形物体数字孪生，并生成3D动作条件视频。通过实验，我们证明该模型能够从机器人-物体交互的稀疏视角RGB-D记录中学习多种物体（如绳索、布料、毛绒玩具和纸袋）的动态，并在类别级别上泛化到未见过的实例。我们的方法在性能上优于当前最先进的基于学习和物理的模拟器，尤其在视角受限的场景中。此外，我们展示了所学模型在基于模型的规划中的实用性，支持一系列目标驱动的物体操控任务。项目页面见 https://kywind.github.io/pgnd。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [228] [Preparing for the Intelligence Explosion](https://arxiv.org/abs/2506.14863)
**中文标题：为智能爆炸做准备**

*William MacAskill,Fin Moorhouse*

主要分类: cs.CY

摘要简述: 本文探讨了AI加速研究可能带来的技术爆炸，提出了在此期间可能出现的重大挑战（如大规模杀伤性武器、AI专制等），并强调当前需为这些挑战做好准备，而不仅仅是依赖未来AI系统的对齐。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI加速研究能力的提升，技术爆炸可能带来一系列重大挑战和机遇。作者认为这些挑战不能完全依赖未来的AI系统解决，当前需采取行动以应对潜在的复杂局面。

研究方法: 通过分析AI加速研究可能引发的技术爆炸及其后果，作者列举了多个重大挑战（如新型武器、AI专制等），并提出了当前应采取的具体措施。

研究结果: 研究指出，技术爆炸将带来一系列难以逆转的决策和挑战，当前需为这些挑战做好准备，而不仅仅是依赖AI系统的对齐。

研究结论: 作者呼吁当前即开始为技术爆炸带来的复杂局面做准备，强调这不仅关乎AI系统的对齐，还包括应对潜在的重大挑战。

中文摘要: 能够加速研究的AI可能在短短几年内推动一个世纪的技术进步。在此期间，新技术或政治发展将迅速引发一系列具有深远影响且难以逆转的决策，我们称这些发展为重大挑战。这些挑战包括新型大规模杀伤性武器、AI支持的专制政权、争夺外星资源的竞赛，以及值得道德考量的数字生命，同时也包括显著提升生活质量和集体决策能力的机会。我们认为这些挑战不能总是委托给未来的AI系统，并提出了当前可以采取的措施以改善前景。因此，AGI准备不仅关乎确保高级AI系统的对齐，还应从现在开始为智能爆炸带来的广泛且令人困惑的发展做好准备。

</details>


### [229] [Hypothesis Testing for Quantifying LLM-Human Misalignment in Multiple Choice Settings](https://arxiv.org/abs/2506.14997)
**中文标题：基于假设检验的多项选择场景中LLM与人类行为偏差的量化研究**

*Harbin Hong,Sebastian Caldas,Liu Leqi*

主要分类: cs.CY

摘要简述: 本文提出了一种基于假设检验的定量框架，用于评估大型语言模型（LLM）在多项选择调查中与人类行为的偏差，发现某些模型在模拟特定人群（如不同种族、年龄和收入）时表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在社会科学研究（如经济学和市场营销）中的应用日益增多，评估这些模型是否能准确模拟人类行为变得至关重要。本文旨在通过假设检验量化LLM与人类行为的偏差，为相关研究提供科学依据。

研究方法: 作者提出了一种基于假设检验的定量框架，用于评估LLM在多项选择调查中与人类行为的偏差。该框架通过比较LLM模拟的行为与实际人类行为，判断模型是否适合用于模拟特定人群的决策和观点。

研究结果: 研究发现，某些流行的语言模型在模拟特定人群（如不同种族、年龄和收入）时表现不佳，尤其是在争议性问题上的模拟效果较差。这表明这些模型与测试人群的偏差较大。

研究结论: 本文揭示了某些LLM在模拟人类行为时的局限性，强调了在社会科学研究中使用LLM时需要超越简单的模拟，采取更科学的实践方法。

中文摘要: 随着大型语言模型（LLM）在社会科学研究（如经济学和市场营销）中的广泛应用，评估这些模型是否能准确模拟人类行为变得至关重要。本文通过假设检验提出了一种定量框架，用于评估LLM在多项选择调查中与人类行为的偏差。该框架能够科学地判断特定语言模型是否适合用于模拟人类观点、决策及多项选择行为。我们将此框架应用于一种流行的语言模型，用于模拟公众调查中的人群观点，发现该模型在模拟特定子人群（如不同种族、年龄和收入）时表现不佳，尤其是在争议性问题上的模拟效果较差。这引发了关于该语言模型与测试人群的偏差问题，强调了在社会科学研究中使用LLM时需要超越简单的人类行为模拟，采取更科学的实践方法。

</details>


### [230] [Transit for All: Mapping Equitable Bike2Subway Connection using Region Representation Learning](https://arxiv.org/abs/2506.15113)
**中文标题：全民交通：利用区域表示学习绘制公平的自行车与地铁连接图**

*Min Namgung,JangHyeon Lee,Fangyi Ding,Yao-Yi Chiang*

主要分类: cs.CY

摘要简述: 本文提出了一种名为“Transit for All (TFA)”的空间计算框架，旨在通过区域表示学习和加权公共交通可达性指标（wPTAL），指导共享单车系统（BSS）的公平扩展，以减少低收入和少数族裔社区的交通不平等问题。


<details>
  <summary>详细信息</summary>
研究动机: 在纽约市等高密度城市中，低收入和少数族裔社区的公共交通可达性较差。共享单车系统（BSS）可以作为经济实惠的首末公里连接工具，但其在未服务区域的扩展面临需求预测和传统可达性指标的局限性。本文旨在解决这些问题，促进交通公平。

研究方法: TFA框架包含三个部分：(1) 利用区域表示学习整合多模态地理空间数据，预测冷启动站点的共享单车需求；(2) 结合预测需求和传统指标，提出加权公共交通可达性指标（wPTAL）；(3) 基于wPTAL提供新站点布局的战略建议。

研究结果: 以纽约市为例，研究发现wPTAL指导的新站点布局显著减少了低收入和少数族裔社区的交通不平等问题。TFA框架为城市规划者提供了促进交通公平的实用工具。

研究结论: TFA框架通过科学的预测和评估方法，为共享单车系统的公平扩展提供了有效指导，有助于提升未服务社区的生活质量。

中文摘要: 确保公共交通的公平可达性仍然具有挑战性，尤其是在纽约市等高密度城市中，低收入和少数族裔社区的交通可达性往往受限。共享单车系统（BSS）可以通过提供经济实惠的首末公里连接来弥补这些不平等。然而，由于新规划站点（“冷启动”）的共享单车需求不确定，以及传统可达性指标可能忽略实际自行车使用潜力，BSS向未服务区域的战略扩展存在困难。我们提出了“全民交通”（TFA），这是一个空间计算框架，通过三个组成部分指导BSS的公平扩展：(1) 利用整合多模态地理空间数据的区域表示学习，对冷启动站点的共享单车需求进行空间预测；(2) 结合预测需求和传统指标，提出加权公共交通可达性指标（wPTAL）；(3) 基于潜在乘客量和公平性提升，为新站点布局提供战略建议。以纽约市为例，我们发现了历史上未服务社区中低收入和少数族裔社区面临的交通可达性差距。结果显示，wPTAL指导的新站点布局显著减少了与经济及人口因素相关的交通不平等。研究表明，TFA为城市规划者提供了促进交通公平、提升未服务社区生活质量的实用指导。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [231] [Improved Image Reconstruction and Diffusion Parameter Estimation Using a Temporal Convolutional Network Model of Gradient Trajectory Errors](https://arxiv.org/abs/2506.14995)
**中文标题：基于时间卷积网络的梯度轨迹误差模型改进图像重建与扩散参数估计**

*Jonathan B. Martin,Hannah E. Alderson,John C. Gore,Mark D. Does,Kevin D. Harkins*

主要分类: physics.med-ph

摘要简述: 提出了一种基于时间卷积网络的梯度轨迹误差模型，用于改进磁共振图像重建和扩散参数估计，显著提升了图像质量和参数映射准确性。


<details>
  <summary>详细信息</summary>
研究动机: 梯度轨迹误差在非笛卡尔磁共振成像中会导致严重的图像伪影和失真，现有线性方法无法准确预测这些非线性误差，因此需要一种更精确的梯度系统模型。

研究方法: 在小动物成像系统上测量了一组训练梯度波形，并利用时间卷积网络训练模型以预测成像系统产生的梯度波形，随后将预测结果整合到图像重建流程中。

研究结果: 训练后的网络能够准确预测梯度系统的非线性失真，相比名义梯度波形和梯度脉冲响应函数，显著提升了图像质量和扩散参数映射的准确性。

研究结论: 时间卷积网络比现有线性方法更能准确建模梯度系统行为，可用于回顾性校正梯度误差。

中文摘要: 摘要：梯度轨迹误差在磁共振图像中引入了显著的伪影和失真，尤其是在非笛卡尔成像序列中，不完美的梯度波形会大幅降低图像质量。目的：开发一种通用的非线性梯度系统模型，利用卷积网络准确预测梯度失真。方法：在小动物成像系统上测量了一组训练梯度波形，并用于训练时间卷积网络以预测成像系统产生的梯度波形。结果：训练后的网络能够准确预测梯度系统的非线性失真，将梯度波形预测整合到图像重建流程中，相比名义梯度波形和梯度脉冲响应函数，显著提升了图像质量和扩散参数映射。结论：时间卷积网络比现有线性方法更能准确建模梯度系统行为，可用于回顾性校正梯度误差。

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [232] [Intrinsic and Extrinsic Organized Attention: Softmax Invariance and Network Sparsity](https://arxiv.org/abs/2506.15541)
**中文标题：内在与外在组织注意力：Softmax不变性与网络稀疏性**

*Oluwadamilola Fasina,Ruben V. C. Pohle,Pei-Chun Su,Ronald R. Coifman*

主要分类: math.NA

摘要简述: 本文研究了Transformer中自注意力机制的内在（注意力头内部）和外在（注意力头之间）结构，证明了自注意力机制对softmax激活的不变性，并通过分层组织方法分析了网络结构的稀疏性，为模型剪枝和架构比较提供了理论基础。


<details>
  <summary>详细信息</summary>
研究动机: 研究自注意力机制的结构特性，旨在揭示其内在和外在的组织规律，为模型的可解释性和实际应用（如剪枝）提供理论支持。

研究方法: 通过理论分析（利用拟微分计算）证明自注意力机制对softmax的不变性，并采用分层组织方法构建查询、键和注意力头轴的分层树结构，分析网络稀疏性。

研究结果: 发现自注意力机制对softmax具有不变性，网络3-张量的分层组织显示出规律性，可用于模型剪枝和架构比较。

研究结论: 研究为自注意力机制的可解释性分析提供了新视角，并为网络稀疏性和实际应用（如剪枝）提供了方法论支持。

中文摘要: 本文研究了Transformer中自注意力机制的内在（注意力头内部）和外在（注意力头之间）结构。通过拟微分计算，我们获得了自注意力机制对softmax激活不变性的理论证据（并通过计算实例支持），这依赖于注意力头的内在组织。此外，我们利用现有的张量分层组织方法，通过构建查询、键和注意力头轴的分层树结构来研究网络结构。这种组织方式具有重要意义，因为它允许在几何结构上高效执行常见的信号处理任务，其中组织后的网络3-张量表现出规律性。我们通过可视化注意力头的分层树结构和扩散映射嵌入来定性展示这一点，并通过研究网络稀疏性（利用双Haar基和三Haar基对查询、键和注意力头的扩展系数）进行定量分析。为了展示理论和方法的实用性，我们提供了视觉和语言Transformer的计算实例。这些发现的影响有两个方面：（1）为可解释性分析提供了理论支持，并可用于下游可解释性任务；（2）可以利用网络3-张量的组织进行实际应用，如模型剪枝（基于网络稀疏性）和网络架构比较。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [233] [Identifying economic narratives in large text corpora -- An integrated approach using Large Language Models](https://arxiv.org/abs/2506.15041)
**中文标题：识别大规模文本语料库中的经济叙事——一种基于大型语言模型的综合方法**

*Tobias Schmidt,Kai-Robin Lange,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch*

主要分类: econ.GN

摘要简述: 本文探讨了使用大型语言模型（LLMs）从文本中提取经济叙事的有效性，通过分析《华尔街日报》和《纽约时报》关于通胀的文章，发现GPT-4o能提取结构化经济叙事，但复杂文档处理仍不及专家水平。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，经济叙事研究兴趣增长，但现有方法（如BERT）缺乏深层语义理解，难以区分经济叙事提取与传统语义角色标注任务。本文旨在评估LLMs在此任务中的潜力。

研究方法: 研究采用《华尔街日报》和《纽约时报》关于通胀的文章作为语料库，应用严格叙事定义，将GPT-4o输出与专家标注的黄金标准叙事进行对比分析。

研究结果: 结果表明，GPT-4o能提取有效的结构化经济叙事，但在处理复杂文档和叙事时仍不及专家水平。

研究结论: LLMs在经济研究中具有潜力，但需进一步改进以应对复杂任务。本文为未来经济学和社会科学中LLMs的应用提供了指导。

中文摘要: 近年来，人们对经济叙事的兴趣日益增长，提取此类叙事的流程也越来越多。这些流程通常采用最先进的自然语言处理技术（如BERT）来完成此任务。尽管这些模型在叙事提取的基础语言操作上表现良好，但它们缺乏区分经济叙事提取与传统语义角色标注任务所需的深层语义理解。我们通过分析《华尔街日报》和《纽约时报》关于通胀的报纸文章，评估了大型语言模型（LLMs）的优势。我们应用严格的叙事定义，并将GPT-4o的输出与专家标注的黄金标准叙事进行比较。结果表明，GPT-4o能够以结构化格式提取有效的经济叙事，但在处理复杂文档和叙事时仍不及专家水平。鉴于LLMs在经济研究中的新颖性，我们还为未来经济学和社会科学中采用LLMs实现类似目标的研究提供了指导。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [234] [Scaling Intelligence: Designing Data Centers for Next-Gen Language Models](https://arxiv.org/abs/2506.15006)
**中文标题：扩展智能：为下一代语言模型设计数据中心**

*Jesmin Jahan Tithi,Hanjiang Wu,Avishaii Abuhatzera,Fabrizio Petrini*

主要分类: cs.AR

摘要简述: 本文提出了一种数据中心架构的协同设计框架，以支持下一代大规模语言模型（如GPT-4）的高效扩展。通过评估FullFlat网络架构和多种优化策略，研究量化了计算与通信重叠、硬件加速集体操作等对性能和可扩展性的影响，为万亿参数模型的数据中心设计提供了实用指南。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（如GPT-4）参数规模的爆炸性增长（1.8万亿参数），传统数据中心架构在可扩展性、效率和成本效益方面面临挑战。本文旨在通过协同设计框架重新思考数据中心架构，以支持这些模型的快速发展。

研究方法: 研究提出了一种协同设计框架，综合评估了FLOPS、HBM带宽与容量、多种网络拓扑（如两层级与FullFlat光网络）、扩展域规模以及并行化策略。通过引入FullFlat网络架构，实现了节点间的高带宽、低延迟连接。此外，研究还扩展并验证了一种性能建模工具，能够以10%的误差预测LLM运行时间。

研究结果: 研究发现，FullFlat网络架构对性能和可扩展性具有显著提升作用。通过计算与通信重叠、硬件加速集体操作、更大扩展域和内存容量等优化策略，显著提高了模型FLOPS利用率（MFU）和整体吞吐量。研究还揭示了稀疏（专家混合）和密集（基于Transformer）LLM中系统设计选择的影响。

研究结论: 本文为高效支持万亿参数模型的数据中心设计提供了实用见解和路线图，降低了优化复杂性，并支持AI能力的快速演进。协同设计框架和性能建模工具为未来AI数据中心的建设奠定了重要基础。

中文摘要: 大型语言模型（如拥有1.8万亿参数的GPT-4）的爆炸性增长要求对数据中心架构进行彻底重新设计，以确保可扩展性、效率和成本效益。我们的工作提供了一个全面的协同设计框架，联合探索了FLOPS、HBM带宽与容量、多种网络拓扑（两层级与FullFlat光网络）、扩展域规模以及LLM中常用的并行化与优化策略。我们引入并评估了FullFlat网络架构，该架构为所有节点提供统一的高带宽、低延迟连接，并展示了其对性能和可扩展性的变革性影响。通过详细的敏感性分析，我们量化了计算与通信重叠、利用硬件加速集体操作、更大扩展域和更大内存容量的优势。我们的研究涵盖了稀疏（专家混合）和密集（基于Transformer）的LLM，揭示了系统设计选择如何影响模型FLOPS利用率（MFU = 每令牌模型FLOPS × 每秒观察到的令牌数 / 硬件峰值FLOPS）和整体吞吐量。为了协同设计研究，我们扩展并验证了一种性能建模工具，能够以10%的误差预测LLM运行时间。我们的研究结果为设计能够高效支持万亿参数模型、降低优化复杂性并持续推动AI能力快速发展的AI数据中心提供了实用见解和路线图。

</details>


### [235] [J3DAI: A tiny DNN-Based Edge AI Accelerator for 3D-Stacked CMOS Image Sensor](https://arxiv.org/abs/2506.15316)
**中文标题：J3DAI：一种基于微型DNN的边缘AI加速器，用于3D堆叠CMOS图像传感器**

*Benoit Tain,Raphael Millet,Romain Lemaire,Michal Szczepanski,Laurent Alacoque,Emmanuel Pluchart,Sylvain Choisnet,Rohit Prasad,Jerome Chossat,Pascal Pierunek,Pascal Vivet,Sebastien Thuries*

主要分类: cs.AR

摘要简述: 本文介绍了J3DAI，一种基于深度神经网络的微型硬件加速器，专为3层3D堆叠CMOS图像传感器设计，具备高效的边缘AI处理能力，并展示了其性能-功耗-面积（PPA）特性。


<details>
  <summary>详细信息</summary>
研究动机: 随着边缘AI的重要性日益增长，需要一种能够在资源受限的硬件上高效运行AI任务的解决方案。J3DAI旨在通过集成DNN加速器，为CMOS图像传感器提供实时、低延迟且节能的AI处理能力。

研究方法: J3DAI采用了一种基于深度神经网络的硬件加速器设计，结合Aidge软件框架，支持后训练量化以减少内存占用和计算复杂度。该方法专注于优化数字系统的PPA特性。

研究结果: 实验结果表明，J3DAI能够高效处理图像分类和分割等任务，展示了其在边缘AI领域的多功能性和高效性。

研究结论: J3DAI为边缘AI提供了一种创新的解决方案，未来工作将集中于进一步优化架构和探索新应用，以充分发挥其潜力。

中文摘要: 本文介绍了J3DAI，一种基于深度神经网络的微型硬件加速器，专为3层3D堆叠CMOS图像传感器设计，集成了AI芯片和DNN加速器。该加速器能够高效执行图像分类和分割等神经网络任务。本文重点介绍了J3DAI的数字系统，突出了其性能-功耗-面积（PPA）特性，并展示了其在CMOS图像传感器上的先进边缘AI能力。为支持硬件，我们使用了Aidge综合软件框架，该框架支持主机处理器和DNN加速器的编程。Aidge支持后训练量化，显著减少了内存占用和计算复杂度，这对于在资源受限的硬件（如J3DAI）上部署模型至关重要。实验结果表明，这一创新设计在边缘AI领域具有多功能性和高效性，能够处理简单和计算密集型任务。未来工作将集中于进一步优化架构和探索新应用，以充分发挥J3DAI的潜力。随着边缘AI的重要性日益增长，像J3DAI这样的创新将在实现实时、低延迟和节能的边缘AI处理中发挥关键作用。

</details>
