<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.CV](#cs.CV) [Total: 59]
- [cs.AI](#cs.AI) [Total: 1]
- [math.NA](#math.NA) [Total: 1]
- [cs.HC](#cs.HC) [Total: 7]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.CR](#cs.CR) [Total: 3]
- [stat.OT](#stat.OT) [Total: 1]
- [cs.LG](#cs.LG) [Total: 39]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.SI](#cs.SI) [Total: 2]
- [eess.IV](#eess.IV) [Total: 12]
- [cs.RO](#cs.RO) [Total: 6]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.CY](#cs.CY) [Total: 3]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cs.AR](#cs.AR) [Total: 2]
- [math.ST](#math.ST) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DeVisE: Behavioral Testing of Medical Large Language Models](https://arxiv.org/abs/2506.15339)
**中文标题：DeVisE：医疗大语言模型的行为测试**

*Camila Zurdo Tagliabue,Heloisa Oss Boll,Aykut Erdem,Erkut Erdem,Iacer Calixto*

主要分类: cs.CL

摘要简述: 本文提出DeVisE框架，用于测试医疗大语言模型（LLMs）的临床推理能力，通过对比真实和合成数据，评估模型对人口统计和生命体征变化的敏感性，发现零样本模型更连贯，而微调模型更稳定但反应较弱。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估方法难以区分医疗大语言模型的真实推理与表面模式，因此需要开发更细粒度的行为测试框架，以揭示模型的临床理解能力及其潜在偏见。

研究方法: 利用MIMIC-IV的ICU出院记录构建数据集，生成真实和模板化（合成）版本，控制单变量反事实（如人口统计和生命体征）。评估五种LLMs（通用和医疗微调），分析输入级敏感性和下游推理（如住院时长预测）。

研究结果: 零样本模型的反事实推理更连贯，微调模型更稳定但对临床变化反应较弱；人口统计因素对输出有细微但持续的影响，凸显公平性评估的重要性。

研究结论: 行为测试能有效揭示临床LLMs的推理策略，为设计更安全、透明的医疗AI系统提供依据。

中文摘要: 大语言模型（LLMs）在临床决策支持中的应用日益广泛，但现有评估方法常难以区分真实的医学推理与表面模式。我们提出DeVisE（人口统计与生命体征评估），一种行为测试框架，用于探究细粒度的临床理解能力。基于MIMIC-IV的ICU出院记录，我们构建了真实和模板化（合成）版本的数据集，通过控制单变量反事实（如年龄、性别、种族和生命体征）进行测试。评估了五种LLMs（通用和医疗微调），在零样本和微调设置下，通过（1）输入级敏感性（反事实如何改变记录的可能性）和（2）下游推理（如何影响预测住院时长）分析模型行为。结果显示，零样本模型的反事实推理更连贯，而微调模型更稳定但对临床变化的反应较弱。值得注意的是，人口统计因素对输出有细微但持续的影响，强调了公平性评估的重要性。这项工作凸显了行为测试在揭示临床LLMs推理策略和设计更安全、透明医疗AI系统中的价值。

</details>


### [2] [SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture](https://arxiv.org/abs/2506.15355)
**中文标题：SANSKRITI：评估语言模型对印度文化知识的综合基准**

*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Sriparna Saha*

主要分类: cs.CL

摘要简述: SANSKRITI是一个评估语言模型对印度文化理解能力的综合基准，包含21,853个问题-答案对，覆盖印度28个邦和8个联邦属地的16个文化属性。测试发现主流语言模型在文化敏感问题上表现差异显著。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型在全球应用中的有效性依赖于其对本地社会文化背景的理解。然而，目前缺乏针对印度文化多样性的评估工具，因此需要开发一个全面的基准来填补这一空白。

研究方法: 研究团队构建了SANSKRITI数据集，包含21,853个问题-答案对，覆盖印度28个邦和8个联邦属地的16个文化属性。随后对主流大型语言模型（LLMs）、印度语言模型（ILMs）和小型语言模型（SLMs）进行了评估。

研究结果: 评估显示，主流语言模型在处理文化敏感问题时表现差异显著，许多模型在地区特定语境中表现不佳。SANSKRITI为提升语言模型的文化理解能力设定了新标准。

研究结论: SANSKRITI为评估和改进语言模型对印度文化的理解提供了全面、多样化的数据集，填补了现有研究的空白，并为未来模型开发提供了重要参考。

中文摘要: 语言模型（LMs）是现代工作流程中不可或缺的工具，但其全球有效性依赖于对本地社会文化背景的理解。为此，我们推出了SANSKRITI，这是一个旨在评估语言模型对印度丰富文化多样性理解能力的基准。SANSKRITI包含21,853个精心设计的问题-答案对，覆盖印度28个邦和8个联邦属地，是测试印度文化知识的最大数据集。它涵盖了印度文化的十六个关键属性：仪式与典礼、历史、旅游、美食、舞蹈与音乐、服饰、语言、艺术、节日、宗教、医学、交通、体育、夜生活以及名人，全面展现了印度文化的多样性。我们在主流大型语言模型（LLMs）、印度语言模型（ILMs）和小型语言模型（SLMs）上对SANSKRITI进行了评估，结果显示这些模型在处理文化敏感问题时存在显著差异，许多模型在地区特定语境中表现不佳。通过提供一个广泛、文化丰富且多样化的数据集，SANSKRITI为评估和提升语言模型的文化理解能力设定了新标准。

</details>


### [3] [COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation](https://arxiv.org/abs/2506.15372)
**中文标题：COSMMIC：面向摘要和标题生成的评论敏感多模态多语言印度语料库**

*Raghvendra Kumar,S. A. Mohammed Salman,Aryan Sahu,Tridib Nandi,Pragathi Y. P.,Sriparna Saha,Jose G. Moreno*

主要分类: cs.CL

摘要简述: 本文介绍了COSMMIC，一个针对印度语言的多模态、多语言数据集，包含文章、图片和用户评论，用于摘要和标题生成任务。研究通过整合用户反馈和图像信息，探索了四种配置的摘要生成方法，并评估了其效果。


<details>
  <summary>详细信息</summary>
研究动机: 尽管英语和中文的多模态、多语言摘要研究已有进展，但印度语言的相关研究仍显不足。本研究旨在填补这一空白，通过构建一个包含九种印度语言的评论敏感多模态数据集，推动印度语言的NLP研究。

研究方法: 研究构建了COSMMIC数据集，包含4,959对文章-图片和24,484条用户评论，支持多语言摘要生成。采用四种配置（仅文本、文本+评论、文本+图片、文本+评论+图片）进行实验，利用LLama3和GPT-4等模型评估效果，并设计了评论分类器和图像分类器以优化结果。

研究结果: 实验表明，结合用户评论和图像信息的多模态配置显著提升了摘要生成的质量。评论分类器和图像分类器有效过滤了噪声并提取了有价值的信息。

研究结论: COSMMIC填补了印度语言多模态数据集的空白，为NLP研究提供了新资源。整合用户反馈和图像信息的方法为多语言摘要任务提供了有效解决方案。

中文摘要: 尽管在英语和中文的评论感知多模态和多语言摘要方面取得了进展，但印度语言的研究仍然有限。本研究通过引入COSMMIC填补了这一空白，这是一个开创性的评论敏感多模态、多语言数据集，涵盖九种主要印度语言。COSMMIC包含4,959对文章-图片和24,484条读者评论，并提供所有支持语言的真实摘要。我们的方法通过整合读者见解和反馈来增强摘要效果。我们探索了四种配置的摘要和标题生成：（1）仅使用文章文本，（2）结合用户评论，（3）利用图片，（4）综合文本、评论和图片。为评估数据集的有效性，我们采用了LLama3和GPT-4等先进语言模型。我们进行了全面研究，评估不同组件的组合，包括识别支持性评论、使用基于IndicBERT的评论分类器过滤噪声，以及通过多语言CLIP分类器从图像中提取有价值的信息。这有助于确定自然语言生成（NLG）任务的最有效配置。与许多现有数据集不同，COSMMIC独特地整合了文本、图像和用户反馈，填补了印度语言资源的空白，推动了NLP研究并促进了包容性。

</details>


### [4] [Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning](https://arxiv.org/abs/2506.15415)
**中文标题：目标词汇注入：通过早期层LoRA微调解锁Lugha-Llama中的潜在跨语言对齐**

*Stanley Ngugi*

主要分类: cs.CL

摘要简述: 本文提出了一种名为“目标词汇注入”（TLI）的高效微调方法，通过早期层的LoRA微调，显著提升了低资源语言（如斯瓦希里语）在大型语言模型中的跨语言词汇对齐能力。实验表明，该方法在训练和未训练词汇对上均取得了显著改进。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在低资源语言（如斯瓦希里语）中表现不佳，主要由于数据稀缺和预训练中的代表性不足。跨语言词汇对齐是翻译和跨语言信息检索等任务的关键挑战。本文旨在通过早期层的微调，解锁模型潜在的跨语言对齐能力。

研究方法: 提出目标词汇注入（TLI）方法，利用低秩适应（LoRA）和对比学习目标，针对模型早期层（如第2层）的嵌入进行微调。实验基于Lugha-Llama-8B-wura模型，专注于斯瓦希里语-英语词汇对齐。

研究结果: TLI显著提升了623个训练词汇对的输出层词汇对齐，平均余弦相似度从0.3211提高到0.4113（+28.08%）。此外，该方法在63个未见词汇对上表现同样出色，相似度从0.3143提升至0.4033（+28.32%）。

研究结论: TLI通过早期层微调，有效增强了模型保留和传播跨语言知识的能力，为低资源语言模型提供了一种参数高效且有效的词汇对齐改进策略。

中文摘要: 大型语言模型（LLMs）展现了卓越的能力，但在低资源语言（如斯瓦希里语）中表现不佳，主要由于数据稀缺和预训练中的代表性不足。跨语言词汇对齐是翻译和跨语言信息检索等任务的关键挑战。本文提出目标词汇注入（TLI），一种新颖高效的微调方法。我们首先发现，Lugha-Llama-8B-wura（一种斯瓦希里语为中心的LLM）在其早期内部层（特别是第2层，基于初步研究的平均余弦相似度约为0.99998）表现出近乎完美的斯瓦希里语-英语词汇对齐能力，但其最终输出表示中并未完全体现（基线相似度约为0.32）。TLI利用这一发现，通过低秩适应（LoRA）和对比学习目标，针对这一经验确定的最佳早期层嵌入进行微调。实验表明，TLI显著提升了623个训练斯瓦希里语-英语词汇对的输出层词汇对齐，平均余弦相似度从0.3211提高到0.4113（+28.08%，p < 1.33 x 10^-240）。更重要的是，这些改进在63个未见控制词汇对上同样显著，相似度从0.3143提升至0.4033（+28.32%，p < 7.17 x 10^-27）。这些发现表明，TLI增强了模型保留和传播其固有早期层跨语言知识的能力，为专注于低资源语言的LLMs提供了一种参数高效且有效的词汇对齐改进策略。

</details>


### [5] [Understanding GUI Agent Localization Biases through Logit Sharpness](https://arxiv.org/abs/2506.15425)
**中文标题：通过Logit锐度理解GUI代理定位偏差**

*Xingjian Tao,Yiwei Wang,Yujun Cai,Zhicheng Yang,Jing Tang*

主要分类: cs.CL

摘要简述: 本文提出了一种细粒度评估框架和峰值锐度评分（PSS），用于量化多模态大语言模型（MLLMs）在GUI代理定位中的偏差，并提出了无需训练的上下文感知裁剪技术以提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在GUI代理中表现出色，但其定位错误（幻觉）影响了可靠性。本文旨在揭示这些错误的细粒度模式，并提出量化不确定性和改进性能的方法。

研究方法: 1. 提出细粒度评估框架，将模型预测分为四类；2. 引入峰值锐度评分（PSS）量化语义连续性与坐标预测的对齐；3. 提出无需训练的上下文感知裁剪技术，优化输入上下文。

研究结果: 实验表明，该框架和方法能有效揭示模型偏差，提升GUI代理行为的可解释性和鲁棒性。

研究结论: 本文的框架和技术为GUI代理的定位偏差提供了可操作的见解，并显著提升了模型的性能。

中文摘要: 多模态大语言模型（MLLMs）使GUI代理能够通过将语言与空间动作结合来与操作系统交互。尽管性能优异，这些模型常出现幻觉——系统性定位错误，影响可靠性。我们提出了一种细粒度评估框架，将模型预测分为四类，揭示了传统准确率指标之外的失败模式。为量化模型不确定性，我们引入了峰值锐度评分（PSS），评估语义连续性与坐标预测的对齐。基于此，我们进一步提出了上下文感知裁剪技术，无需训练即可通过自适应优化输入上下文提升模型性能。大量实验表明，我们的框架和方法提供了可操作的见解，增强了GUI代理行为的可解释性和鲁棒性。

</details>


### [6] [AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need](https://arxiv.org/abs/2506.15451)
**中文标题：AgentGroupChat-V2：分而治之是基于大语言模型的多智能体系统所需**

*Zhouhong Gu,Xiaoxuan Zhu,Yin Cai,Hao Shen,Xingzhou Chen,Qingyi Wang,Jialin Li,Xiaoran Shi,Haoran Guo,Wenxuan Huang,Hongwei Feng,Yanghua Xiao,Zheyu Ye,Yao Hu,Shaosheng Cao*

主要分类: cs.CL

摘要简述: AgentGroupChat-V2是一种基于大语言模型的多智能体系统框架，通过分而治之的并行架构、自适应协作引擎和智能体组织优化策略，显著提升了复杂任务处理的效率和准确性。实验表明，其在多个领域表现优异，尤其在复杂推理任务中优势明显。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大语言模型的多智能体系统在系统架构设计、跨领域通用性和性能保障方面面临挑战，尤其是在任务复杂性和智能体数量增加时。为解决这些问题，本文提出了AgentGroupChat-V2框架。

研究方法: AgentGroupChat-V2采用三种核心创新：(1) 分而治之的完全并行架构，将用户查询分解为层次化任务森林结构；(2) 自适应协作引擎，根据任务特性动态选择异构LLM组合和交互模式；(3) 结合分而治之方法的智能体组织优化策略，实现高效问题分解。

研究结果: 实验结果显示，AgentGroupChat-V2在多个领域表现卓越：GSM8K准确率达91.50%（比最佳基线高5.6个百分点），AIME竞赛级任务准确率为30.4%（接近其他方法的两倍），HumanEval的pass@1为79.20%。任务难度越高，性能优势越显著。

研究结论: AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，尤其在复杂推理场景中具有显著优势。

中文摘要: 基于大语言模型的多智能体系统在社会模拟和复杂任务解决领域展现出巨大潜力。然而，当前框架在系统架构设计、跨领域通用性和性能保障方面面临关键挑战，尤其是随着任务复杂性和智能体数量的增加。我们提出了AgentGroupChat-V2，这一新颖框架通过三项核心创新解决这些挑战：(1) 分而治之的完全并行架构，将用户查询分解为层次化任务森林结构，实现依赖管理和分布式并发处理；(2) 自适应协作引擎，根据任务特性动态选择异构LLM组合和交互模式；(3) 结合分而治之方法的智能体组织优化策略，实现高效问题分解。大量实验表明，AgentGroupChat-V2在多个领域表现卓越，GSM8K准确率达91.50%（比最佳基线高5.6个百分点），AIME竞赛级任务准确率为30.4%（接近其他方法的两倍），HumanEval的pass@1为79.20%。任务难度越高，性能优势越显著，尤其在Level 5 MATH问题上，改进超过最先进基线11个百分点。这些结果证实，AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，在复杂推理场景中具有显著优势。代码发布于https://github.com/MikeGu721/AgentGroupChat-V2。

</details>


### [7] [RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation](https://arxiv.org/abs/2506.15455)
**中文标题：RE-IMAGINE：用于推理评估的符号化基准合成**

*Xinnuo Xu,Rachel Lawrence,Kshitij Dubey,Atharva Pandey,Risa Ueno,Fabian Falck,Aditya V. Nori,Rahul Sharma,Amit Sharma,Javier Gonzalez*

主要分类: cs.CL

摘要简述: RE-IMAGINE是一个评估大型语言模型（LLMs）推理能力的框架，通过生成符号化问题变体揭示模型是否依赖记忆而非真实推理。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在推理任务中表现优异，但尚不清楚其高准确率是源于真实推理还是训练数据的统计记忆。受因果阶梯理论启发，研究旨在开发一种方法，量化模型在不同推理层次（关联、干预和反事实）的能力。

研究方法: RE-IMAGINE框架通过中间符号表示生成问题变体，确保问题无法仅通过记忆解决。该框架适用于数学、代码和逻辑等多个领域，并自动化生成大量问题变体。

研究结果: 在四个广泛使用的基准测试中，RE-IMAGINE生成的变体问题导致LLMs性能下降，表明模型部分依赖统计记忆而非真实推理能力。

研究结论: RE-IMAGINE揭示了LLMs在推理任务中对记忆的依赖，为未来研究提供了评估和改进模型推理能力的工具。

中文摘要: 近期的大型语言模型（LLMs）在推理基准测试中报告了高准确率。然而，尚不清楚这些结果是源于真实推理还是训练数据的统计记忆。受因果阶梯理论（Pearl, 2009）及其三个层次（关联、干预和反事实）的启发，本文提出了RE-IMAGINE框架，用于量化LLMs在不同推理层次上的能力，并提供了一个自动化流程，生成层次化问题变体。通过中间符号表示修改问题，RE-IMAGINE生成大量无法仅通过记忆解决的问题。此外，该框架具有通用性，适用于数学、代码和逻辑等多个推理领域。我们在四个广泛使用的基准测试中验证了该框架，并观察到模型在问题变体上的性能下降。这些评估表明，模型过去的表现部分依赖统计记忆，为未来研究提供了改进推理能力的途径。

</details>


### [8] [Context-Informed Grounding Supervision](https://arxiv.org/abs/2506.15480)
**中文标题：基于上下文的接地监督**

*Hyunji Lee,Seunghyun Yoon,Yunjae Won,Hanseok Oh,Geewook Kim,Trung Bui,Franck Dernoncourt,Elias Stengel-Eskin,Mohit Bansal,Minjoon Seo*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CINGS的后训练监督方法，通过在训练时将相关上下文附加到响应前并仅计算响应标记的损失，显著提升了模型在文本和视觉领域的接地性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）常需依赖外部知识以减少幻觉或补充未编码信息，但简单附加上下文并不能确保生成的响应接地。因此，需要一种更有效的方法来监督模型生成基于上下文的响应。

研究方法: 提出Context-INformed Grounding Supervision（CINGS），在训练时将相关上下文附加到响应前，但仅计算响应标记的损失并屏蔽上下文。这种方法旨在隐式鼓励模型更依赖外部上下文。

研究结果: 实验表明，CINGS训练的模型在文本和视觉领域均表现出更强的接地性能。在文本领域，CINGS在11个信息检索数据集上优于其他方法；在视觉语言领域，CINGS减少了幻觉并保持事实一致性，且不影响下游任务性能。

研究结论: CINGS通过改变模型的先验知识和行为，显著提升了其对外部上下文的依赖，实现了更接地的生成效果，且不影响整体性能。

中文摘要: 大型语言模型（LLMs）常需补充外部知识以提供未编码的信息或减少幻觉。在此情况下，我们希望模型能基于提供的外部上下文生成响应。然而，先前研究表明，仅在推理时附加上下文并不能确保接地的生成。为此，我们提出了基于上下文的接地监督（CINGS），这是一种后训练监督方法，在训练时将相关上下文附加到响应前，但仅计算响应标记的损失并屏蔽上下文。实验表明，CINGS训练的模型在文本和视觉领域均表现出更强的接地性能。在文本领域，CINGS在11个信息检索数据集上优于其他训练方法，并与推理时接地技术互补。在视觉语言领域，将视觉语言模型的LLM主干替换为CINGS训练的模型，减少了四个基准测试中的幻觉，并保持了生成响应的事实一致性。这种改进的接地性能并未导致下游任务性能下降。最后，我们分析了CINGS提升接地的机制，发现它改变了模型的先验知识和行为，隐式鼓励其更依赖外部上下文。

</details>


### [9] [SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling](https://arxiv.org/abs/2506.15498)
**中文标题：SPARE：基于参考引导评估的单次标注框架，用于自动过程监督与奖励建模**

*Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych*

主要分类: cs.CL

摘要简述: SPARE是一种新颖的单次标注框架，通过参考引导的评估实现高效、高质量的过程监督和奖励建模，显著提升大语言模型在多步推理任务中的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前，针对大语言模型的多步推理任务，高效且高质量的过程标注仍是一个挑战。SPARE旨在通过单次标注和参考引导的评估，解决这一问题。

研究方法: SPARE通过将每个解决步骤与参考解决方案中的一个或多个步骤对齐，并辅以明确的评估理由，实现单次、逐步骤的标注。该方法在数学推理、多跳组合问答和空间推理三个领域的四个数据集上进行了验证。

研究结果: SPARE在离线强化学习设置中显著提升了推理性能，同时在训练奖励模型时表现优异。与基于树搜索的自动标注方法相比，SPARE效率提高了2.6倍，仅需38%的运行时间。

研究结论: SPARE为过程监督和奖励建模提供了一种高效且高质量的解决方案，其公开的代码库和模型进一步促进了研究的可重复性。

中文摘要: 过程或分步监督在提升大语言模型（LLMs）的复杂多步推理能力中发挥了关键作用。然而，高效且高质量的自动过程标注仍是一个重大挑战。为此，我们提出了单次标注与参考引导评估（SPARE），这是一种新颖的结构化框架，通过将每个解决步骤与参考解决方案中的一个或多个步骤对齐，并辅以明确的评估理由，实现单次、逐步骤的标注。我们在涵盖数学推理、多跳组合问答和空间推理三个领域的四个数据集上验证了参考引导的逐步骤评估对过程监督的有效性。实验表明，与基线方法相比，SPARE在以下方面显著提升了推理性能：（1）在离线强化学习设置中用于模型微调以支持推理时的贪婪解码；（2）用于训练奖励模型以对多个LLM生成输出进行排序/聚合。此外，SPARE在具有挑战性的数学数据集上表现出色，同时效率提高了2.6倍，仅需38%的运行时间，优于基于树搜索的自动标注方法。我们公开了代码库和训练好的SPARE-PRM模型，以促进进一步的研究和可重复性。

</details>


### [10] [Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge](https://arxiv.org/abs/2506.15504)
**中文标题：利用双向动态交互与情感知识增强夸张与隐喻检测**

*Li Zheng,Sihang Wang,Hao Fei,Zuquan Peng,Fei Li,Jianming Fu,Chong Teng,Donghong Ji*

主要分类: cs.CL

摘要简述: 本文提出了一种基于情感引导和双向动态交互的夸张与隐喻检测框架（EmoBi），通过挖掘情感内涵、域映射和双向交互提升检测性能，实验表明其在多个数据集上显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 夸张和隐喻在自然语言处理中具有重要意义，但由于其语义隐晦和表达多样，检测难度较大。现有方法多关注表面特征，忽略了夸张与隐喻的关联及隐含情感的影响。

研究方法: EmoBi框架包含三个模块：1）情感分析模块挖掘夸张与隐喻的情感内涵；2）基于情感的域映射模块识别目标域和源域以理解隐含意义；3）双向动态交互模块促进夸张与隐喻的相互提升，并设计了验证机制确保准确性。

研究结果: 实验表明，EmoBi在四个数据集上均优于基线方法。例如，在TroFi数据集上夸张检测的F1分数提高了28.1%，在HYPO-L数据集上隐喻检测的F1分数提高了23.1%。

研究结论: EmoBi通过结合情感知识和双向交互，显著提升了夸张与隐喻的检测性能，展现了其有效性和潜力。

中文摘要: 文本中的夸张与隐喻检测对自然语言处理任务具有重要意义。然而，由于其语义隐晦和表达多样，识别这些修辞手法具有挑战性。现有方法多关注表面文本特征，忽略了夸张与隐喻的关联以及隐含情感对其感知的影响。为验证这些假设，我们提出了一种基于情感引导和双向动态交互的夸张与隐喻检测框架（EmoBi）。首先，情感分析模块深度挖掘夸张与隐喻背后的情感内涵；其次，基于情感的域映射模块识别目标域和源域以深入理解其隐含意义；最后，双向动态交互模块实现夸张与隐喻的相互促进，同时设计了验证机制确保检测的准确性和可靠性。实验表明，EmoBi在四个数据集上均优于所有基线方法。具体而言，在TroFi数据集上夸张检测的F1分数较当前最优方法提高了28.1%，在HYPO-L数据集上隐喻检测的F1分数提高了23.1%。这些结果通过深入分析验证了我们方法的有效性和潜力，为夸张与隐喻检测的进一步发展提供了支持。

</details>


### [11] [Lessons from Training Grounded LLMs with Verifiable Rewards](https://arxiv.org/abs/2506.15522)
**中文标题：基于可验证奖励的接地大语言模型训练经验**

*Shang Hong Sim,Tej Deep Pala,Vernon Toh,Hai Leong Chieu,Amir Zadeh,Chuan Li,Navonil Majumder,Soujanya Poria*

主要分类: cs.CL

摘要简述: 本文探讨如何通过强化学习和内部推理提升大语言模型（LLMs）的可靠性和可验证性，提出GRPO方法优化答案正确性、引用充分性和拒绝质量，显著提升模型表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于检索增强生成（RAG）的大语言模型在生成可信赖回答时仍存在不足，如遗漏明确答案、错误引用或拒绝可用证据。研究旨在通过强化学习和推理增强模型的可靠性。

研究方法: 采用GRPO（Group Relative Policy Optimization）方法，通过可验证的结果奖励训练模型，优化答案正确性、引用充分性和拒绝质量。采用两阶段训练策略，先优化答案和引用行为，再优化拒绝行为。同时结合GPT-4蒸馏的指令调优。

研究结果: 实验表明，推理增强模型在ASQA、QAMPARI、ELI5和ExpertQA等任务中显著优于仅指令调优的模型，尤其在处理不可回答问题和生成高质量引用回答时表现突出。两阶段训练进一步提升了模型的稳定性。

研究结论: 研究证明，结合推理、分阶段优化和结果驱动的强化学习，可显著提升大语言模型的可验证性和可靠性，为未来研究提供了重要方向。

中文摘要: 生成可靠且可信的回答仍然是大语言模型（LLMs）面临的主要挑战。虽然基于检索增强生成（RAG）和引用的方法具有潜力，但指令调优模型在简单场景中仍频繁失败，如遗漏明确答案、错误引用或在证据可用时拒绝回答。本研究探讨了如何通过强化学习（RL）和内部推理增强LLMs的可靠性。我们使用GRPO（Group Relative Policy Optimization）方法，通过可验证的结果奖励训练模型，优化答案正确性、引用充分性和拒绝质量，而无需黄金推理轨迹或昂贵标注。在ASQA、QAMPARI、ELI5和ExpertQA等任务上的全面实验表明，推理增强模型显著优于仅指令调优的变体，尤其是在处理不可回答问题和生成高质量引用回答时。两阶段训练（先优化答案和引用行为，再优化拒绝行为）进一步通过稳定学习信号提升了可靠性。此外，我们通过GPT-4蒸馏重新审视指令调优，发现将其与GRPO结合可提升长形式生成问答任务的性能。总体而言，我们的发现凸显了推理、分阶段优化和结果驱动强化学习对构建更可验证和可靠LLMs的价值。

</details>


### [12] [RATTENTION: Towards the Minimal Sliding Window Size in Local-Global Attention Models](https://arxiv.org/abs/2506.15545)
**中文标题：RATTENTION：迈向局部-全局注意力模型的最小滑动窗口尺寸**

*Bailin Wang,Chang Lan,Chong Wang,Ruoming Pang*

主要分类: cs.CL

摘要简述: 本文提出RATTENTION，一种结合局部注意力和线性注意力的新方法，旨在解决局部注意力模型因窗口大小限制而忽略外部信息的问题。实验表明，RATTENTION在512窗口大小下即可达到全注意力模型的性能，同时提升效率。


<details>
  <summary>详细信息</summary>
研究动机: 局部-全局注意力模型在效率和性能之间存在权衡：大窗口保留性能但效率提升有限，小窗口则可能导致性能下降。本文旨在通过改进局部注意力模型，使其在短上下文场景中也能高效运行。

研究方法: 提出RATTENTION，将局部注意力与专门设计的线性注意力机制结合，以捕捉窗口外的信息。通过预训练实验验证其性能，并优化内核实现以保持训练效率。

研究结果: 在3B和12B规模的预训练实验中，RATTENTION在512窗口大小下性能与全注意力模型相当，同时在RULER基准测试中表现出更好的长上下文性能。

研究结论: RATTENTION通过结合局部和线性注意力，显著提升了局部注意力模型的效率和性能，为短上下文和长上下文任务提供了更优的解决方案。

中文摘要: 局部-全局注意力模型最近成为标准Transformer的有力替代方案，有望提升训练和推理效率。然而，窗口大小的选择存在帕累托权衡：大窗口性能接近全注意力但效率提升有限，小窗口则可能导致性能下降。当前模型（如Gemma2和Mistral）采用保守窗口大小（如4096，预训练长度为8192）以保持性能。本文研究如何改变这一权衡，使局部-全局模型在短上下文中也能高效运行。核心动机是解决局部注意力完全忽略窗口外信息的固有局限。我们探索RATTENTION，这是一种结合专门线性注意力机制的局部注意力变体，旨在捕捉窗口外的信息。在3B和12B规模的预训练实验中，RATTENTION在性能和效率之间实现了更优的权衡。512窗口大小的RATTENTION在不同场景下性能与全注意力模型相当。此外，RATTENTION的线性注意力机制具有循环特性，在RULER基准测试中验证了其长上下文性能的提升。这些改进未牺牲训练效率，得益于专用内核实现和更小的窗口大小，RATTENTION保持了与现有先进方法相当的训练速度。

</details>


### [13] [Approximating Language Model Training Data from Weights](https://arxiv.org/abs/2506.15553)
**中文标题：从权重近似语言模型训练数据**

*John X. Morris,Junjie Oscar Yin,Woojeong Kim,Vitaly Shmatikov,Alexander M. Rush*

主要分类: cs.CL

摘要简述: 本文提出了一种从语言模型权重中近似训练数据的方法，通过梯度匹配从公共文本库中选择数据，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代语言模型的权重通常是公开的，但训练数据却未公开。本文旨在解决如何从模型权重中近似训练数据的问题。

研究方法: 提出了一种基于梯度的数据选择方法，从大型公共文本库中筛选出与原始模型权重匹配度最高的数据。

研究结果: 在AG News分类任务中，性能从65%提升至80%，接近专家基准的88%；在MSMARCO文档任务中，困惑度从3.3降至2.3。

研究结论: 该方法能够有效从模型权重中恢复有用数据，显著提升模型性能，接近专家模型的水平。

中文摘要: 现代语言模型通常公开权重但未公开训练数据。我们形式化了从模型权重中近似数据的问题，并提出了几种基线和指标。我们开发了一种基于梯度的方法，从大型公共文本库中选择匹配度最高的数据，并展示了其在仅给定原始模型和微调模型权重时恢复有用数据的有效性。即使不知道任何真实训练数据，我们的方法也能从公共网络文档中定位一小部分数据，用于训练模型，使其性能接近原始模型。在AG News分类任务中，我们的方法将性能从65%（使用随机选择的数据）提升至80%，接近专家基准的88%。当应用于在MSMARCO网络文档上训练的模型时，我们的方法将困惑度从3.3降至2.3，而专家LLAMA模型的困惑度为2.0。

</details>


### [14] [PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction](https://arxiv.org/abs/2506.15556)
**中文标题：PredGen：通过输入时推测加速大型语言模型推理以实现实时语音交互**

*Shufan Li,Aditya Grover*

主要分类: cs.CL

摘要简述: 论文提出PredGen框架，通过输入时推测解码加速大型语言模型（LLM）的推理，显著减少实时语音交互中的延迟，提升用户体验。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在实时语音聊天应用中常因生成首句的延迟导致音频输出滞后，影响用户体验。这一问题在计算资源有限的消费级硬件上尤为明显。

研究方法: 提出Predictive Generation（PredGen）框架，在用户仍在说话时通过推测解码生成候选响应，从而提前启动文本转语音（TTS）处理，减少延迟。

研究结果: 在Lmsys和MT-Bench数据集上的模拟实验表明，PredGen可将延迟降低约2倍，且仅需输入时少量额外计算成本。

研究结论: PredGen通过输入时推测解码有效解决了LLM在实时语音交互中的延迟问题，显著提升了用户体验。

中文摘要: 大型语言模型（LLM）广泛应用于实时语音聊天应用，通常与文本转语音（TTS）系统结合生成音频响应。然而，其庞大的规模常导致用户输入结束到音频输出开始之间存在明显延迟，影响用户体验。这一问题在计算能力有限的消费级硬件上尤为突出。我们发现，延迟主要源于LLM生成首句所需时间，而TTS系统需逐句合成音频响应。为解决这一瓶颈，我们提出预测生成（PredGen）框架，通过输入时推测解码减少甚至消除延迟。PredGen在用户仍在说话时生成候选响应，使系统能以最小延迟启动TTS处理。在Lmsys和MT-Bench数据集上的模拟实验表明，该方法可有效将延迟降低约2倍，且仅需输入时少量额外计算成本。

</details>


### [15] [Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models](https://arxiv.org/abs/2506.15568)
**中文标题：性别包容性公平指数（GIFI）：一种评估大型语言模型中性别多样性的多层次框架**

*Zhengyang Shan,Emily Ruth Diana,Jiawei Zhou*

主要分类: cs.CL

摘要简述: 本文提出了一种名为GIFI的多层次框架，用于评估大型语言模型（LLMs）在性别多样性方面的表现，重点关注其对二元和非二元性别的处理能力。通过广泛评估22种开源和专有LLMs，研究发现模型在性别包容性上存在显著差异。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注二元性别区分，而忽略了非二元性别的包容性。本文旨在填补这一空白，通过开发GIFI指标，全面量化LLMs在性别多样性方面的表现，揭示其潜在的偏见。

研究方法: GIFI框架包含多层次评估，从简单的性别代词测试到模型生成和认知行为的全面分析。研究对22种不同规模和能力的LLMs进行了广泛评估，涵盖开源和专有模型。

研究结果: 评估结果显示，不同LLMs在性别包容性上存在显著差异，部分模型表现出明显的性别偏见。GIFI为未来提升LLMs的性别公平性提供了重要基准。

研究结论: 本文强调了提升LLMs性别包容性的重要性，GIFI框架为未来研究提供了量化工具，推动了生成模型在性别公平性方面的进步。

中文摘要: 本文对大型语言模型（LLMs）的性别公平性进行了全面评估，重点关注其对二元和非二元性别的处理能力。与以往主要关注二元性别区分的研究不同，我们提出了性别包容性公平指数（GIFI），这是一种新颖且全面的指标，用于量化LLMs的性别多样性包容性。GIFI包含从简单性别代词测试到模型生成和认知行为的多层次评估，揭示了不同性别标识相关的偏见。我们对22种不同规模和能力的开源及专有LLMs进行了广泛评估，发现其在性别包容性上存在显著差异。本研究强调了提升LLMs包容性的重要性，为未来生成模型在性别公平性方面的进步提供了关键基准。

</details>


### [16] [SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification](https://arxiv.org/abs/2506.15569)
**中文标题：SciVer：评估多模态科学声明验证的基础模型**

*Chengye Wang,Yifei Shen,Zexi Kuang,Arman Cohan,Yilun Zhao*

主要分类: cs.CL

摘要简述: SciVer是首个专门评估多模态科学声明验证能力的基准，包含3000个专家标注的示例，覆盖4种常见推理类型。评估了21种先进多模态基础模型，发现其与人类专家存在显著性能差距，并揭示了开源模型的关键局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态基础模型在科学声明验证任务中的表现尚未得到系统评估，SciVer旨在填补这一空白，为模型在多模态科学文献中的理解和推理能力提供基准。

研究方法: SciVer包含3000个专家标注的示例，覆盖4种常见推理类型，每个示例附带支持证据。评估了21种先进多模态模型（如o4-mini、Gemini-2.5-Flash等），并通过检索增强生成（RAG）和人工错误分析进行深入评估。

研究结果: 实验显示，当前多模态基础模型与人类专家在SciVer上存在显著性能差距。开源模型在理解和推理多模态科学文献方面存在关键局限性。

研究结论: SciVer为多模态科学声明验证提供了首个基准，揭示了当前模型的不足，为未来模型改进提供了重要方向。

中文摘要: 我们介绍了SciVer，这是首个专门设计用于评估基础模型在多模态科学背景下验证声明能力的基准。SciVer包含3000个专家标注的示例，覆盖1113篇科学论文，涵盖四种常见的多模态科学声明验证推理类型。每个示例均包含专家标注的支持证据，以实现细粒度评估。我们评估了21种先进多模态基础模型（如o4-mini、Gemini-2.5-Flash、Llama-3.2-Vision和Qwen2.5-VL）的性能。实验显示，这些模型与人类专家在SciVer上存在显著性能差距。通过检索增强生成（RAG）和人工错误评估的深入分析，我们揭示了当前开源模型的关键局限性，为提升模型在多模态科学文献任务中的理解和推理能力提供了重要见解。

</details>


### [17] [DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement](https://arxiv.org/abs/2506.15583)
**中文标题：DiscoSG：通过迭代图优化实现语篇级文本场景图解析**

*Shaoqing Lin,Chong Teng,Fei Li,Donghong Ji,Lizhen Qu,Zhuang Li*

主要分类: cs.CL

摘要简述: 本文提出了一种新的任务DiscoSG，用于解析多句描述的文本场景图，并提出了数据集DiscoSG-DS和高效方法DiscoSG-Refiner，显著提升了性能并降低了计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有的文本场景图解析方法主要针对单句描述，无法有效处理多句描述中的跨句共指等现象，导致图结构碎片化，影响下游任务性能。

研究方法: 提出DiscoSG任务，并构建数据集DiscoSG-DS；设计DiscoSG-Refiner方法，通过一个小型PLM生成基础图，再使用另一个PLM迭代优化图结构，降低计算开销。

研究结果: DiscoSG-Refiner在SPICE指标上比最佳基线提升约30%，推理速度比GPT-4快86倍，同时显著提升下游任务性能。

研究结论: DiscoSG-Refiner为多句文本场景图解析提供了高效解决方案，显著提升了性能并降低了计算成本，推动了相关领域的发展。

中文摘要: 视觉语言模型（VLMs）现在能够生成语篇级的多句视觉描述，这对原本设计用于单句描述的文本场景图解析器提出了挑战。现有方法通常合并单句解析结果，但往往忽略了跨句共指等现象，导致图结构碎片化并影响下游任务性能。为此，我们提出了一个新任务——语篇级文本场景图解析（DiscoSG），并构建了数据集DiscoSG-DS，包含400个专家标注和8,430个合成的多句描述-图对。每个描述平均包含9个句子，每个图的边数至少是现有数据集的3倍。尽管在DiscoSG-DS上微调大型PLM（如GPT-4）可将SPICE指标提升约48%，但其高推理成本和严格许可限制了开源使用，而小型PLM则难以处理复杂图结构。我们提出了DiscoSG-Refiner，使用一个小型PLM生成基础图，再通过另一个PLM迭代优化图结构，从而降低全图生成的开销。使用两个Flan-T5-Base模型，DiscoSG-Refiner在SPICE指标上仍比最佳基线提升约30%，推理速度比GPT-4快86倍，同时显著提升了语篇级描述评估和幻觉检测等下游任务性能。代码和数据已开源：https://github.com/ShaoqLin/DiscoSG

</details>


### [18] [WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts](https://arxiv.org/abs/2506.15594)
**中文标题：WikiMixQA：一个面向表格和图表的跨模态问答基准**

*Negar Foroutan,Angelika Romanou,Matin Ansaripour,Julian Martin Eisenschlos,Karl Aberer,Rémi Lebret*

主要分类: cs.CL

摘要简述: 本文介绍了WikiMixQA，一个包含1000道多选题的跨模态推理基准，用于评估从维基百科页面提取的表格和图表的理解能力。实验表明，现有模型在长上下文多模态推理任务中表现不佳，尤其是开源模型。


<details>
  <summary>详细信息</summary>
研究动机: 文档通常包含复杂的布局、表格和图表，这对自动文档理解提出了挑战。尽管视觉语言大模型（VLLMs）在多项任务中表现优异，但其处理长上下文视觉输入的能力尚不明确。因此，本文旨在通过WikiMixQA基准填补这一研究空白。

研究方法: 本文构建了WikiMixQA基准，包含1000道多选题，覆盖7个主题的4000个维基百科页面中的表格和图表。评估了12种最先进的视觉语言模型，包括专有模型和开源模型，测试其在直接上下文和长文档检索场景下的表现。

研究结果: 实验结果显示，专有模型在直接上下文场景下准确率约为70%，但在长文档检索场景下性能显著下降。GPT-4-o是唯一准确率超过50%的模型，而开源模型最高准确率仅为27%。

研究结论: WikiMixQA揭示了长上下文多模态推理的挑战，并成为推动文档理解研究的重要基准。现有模型尤其是开源模型在此任务中仍有较大提升空间。

中文摘要: 文档是保存和传播信息的基础，通常包含复杂的布局、表格和图表，这对自动文档理解（DU）提出了重大挑战。尽管视觉语言大模型（VLLMs）在多项任务中表现出改进，但其处理长上下文视觉输入的有效性仍不明确。本文介绍了WikiMixQA，一个包含1000道多选题的基准，旨在评估从4000个维基百科页面中提取的表格和图表的跨模态推理能力，涵盖七个不同主题。与现有基准不同，WikiMixQA强调复杂推理，要求模型综合多模态信息。我们评估了12种最先进的视觉语言模型，发现专有模型在直接提供上下文时准确率约为70%，但在需要从长文档中检索信息时性能显著下降。其中，GPT-4-o是唯一在此场景下准确率超过50%的模型，而开源模型表现更差，最高准确率仅为27%。这些发现突显了长上下文多模态推理的挑战，并将WikiMixQA确立为推进文档理解研究的关键基准。

</details>


### [19] [From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns](https://arxiv.org/abs/2506.15598)
**中文标题：从模型到课堂：基于叙事和难度考虑的葡萄牙语生成多选题评估**

*Bernardo Leite,Henrique Lopes Cardoso,Pedro Pinto,Abel Ferreira,Luís Abreu,Isabel Rangel,Sandra Monteiro*

主要分类: cs.CL

摘要简述: 本文研究了生成式AI在葡萄牙语阅读多选题（MCQ）生成中的应用，重点关注叙事相关性和难度分级，并通过专家评审和学生反应评估其质量。结果显示生成MCQ质量接近人工编写，但仍存在语义清晰度和干扰项设计问题。


<details>
  <summary>详细信息</summary>
研究动机: 手动创建具有不同难度和阅读技能目标的多选题（MCQ）耗时且昂贵。生成式AI为自动化MCQ生成提供了可能，但其质量和可靠性评估不足，尤其是针对葡萄牙语这类形态丰富的语言。本文旨在填补这一空白，并探讨生成MCQ在真实教育场景中的适用性。

研究方法: 研究利用生成式模型为葡萄牙语阅读生成MCQ，重点关注叙事相关性和难度分级。通过专家评审和学生反应的心理测量分析，评估生成MCQ的质量和适用性。

研究结果: 结果显示，当前模型生成的MCQ质量接近人工编写，但在语义清晰度和干扰项设计上存在问题。干扰项未能完全满足高质量MCQ选项的标准。

研究结论: 生成式AI在葡萄牙语MCQ生成中表现出潜力，但仍需改进语义清晰度和干扰项设计，以更好地满足教育需求。

中文摘要: 尽管多选题（MCQ）对学习和评估具有重要价值，但手动创建具有不同难度和针对性阅读技能的MCQ仍然是一项耗时且昂贵的任务。生成式AI的最新进展为高效自动化MCQ生成提供了机会。然而，对生成MCQ的实际质量和可靠性的评估关注有限，尤其是在生成失败的情况下。当生成的MCQ应用于真实场景时，这一点尤为重要。此外，大多数MCQ生成研究集中于英语，其他语言的研究较少。本文研究了当前生成式模型在葡萄牙语（一种形态丰富的语言）阅读多选题生成中的能力。我们的研究专注于生成与课程相关叙事元素一致且涵盖不同难度级别的MCQ。通过专家评审和从学生反应中提取的心理测量属性分析，评估这些MCQ对小学生适用性。结果显示，当前模型生成的MCQ质量接近人工编写，但在语义清晰度和可回答性上存在问题。此外，生成能吸引学生并符合高质量MCQ选项设计标准的干扰项仍具挑战性。

</details>


### [20] [The Compositional Architecture of Regret in Large Language Models](https://arxiv.org/abs/2506.15617)
**中文标题：大型语言模型中后悔的组合架构**

*Xiangxiang Cui,Shu Yang,Tianjin Huang,Wanyu Lin,Lijie Hu,Di Wang*

主要分类: cs.CL

摘要简述: 本文研究大型语言模型中的后悔机制，提出构建后悔数据集的方法及两种新指标（S-CDI和RDS），成功识别最优后悔表征层和神经元功能分组。


<details>
  <summary>详细信息</summary>
研究动机: 研究大型语言模型中后悔表达的机制，旨在提升模型可靠性并揭示神经网络中的认知编码方式。

研究方法: 提出三步方法：(1) 设计提示场景构建后悔数据集，(2) 使用S-CDI指标识别最优后悔表征层，(3) 通过RDS和GIC指标分析后悔神经元及其激活模式。

研究结果: 实验成功识别最优后悔表征层，发现M形解耦模式，并将神经元分为后悔神经元、非后悔神经元和双功能神经元三类。

研究结论: 本研究为理解后悔机制提供了新工具，揭示了信息处理的耦合与解耦模式，对模型可靠性提升具有重要意义。

中文摘要: 大型语言模型中的后悔指其在面对与先前生成错误信息相矛盾的证据时表现出的明确后悔表达。研究后悔机制对提升模型可靠性至关重要，并有助于揭示神经网络中认知的编码方式。为理解这一机制，需首先识别模型输出中的后悔表达，再分析其内部表征。此分析需考察模型的隐藏状态，即神经元层面的信息处理。然而，这面临三大挑战：(1) 缺乏捕捉后悔表达的专业数据集，(2) 无指标确定最优后悔表征层，(3) 无指标识别和分析后悔神经元。针对这些问题，我们提出：(1) 通过策略性设计的提示场景构建全面后悔数据集的工作流程，(2) 用于识别最优后悔表征层的监督压缩解耦指数（S-CDI）指标，(3) 用于识别后悔神经元的后悔主导分数（RDS）指标及分析激活模式的群体影响系数（GIC）。实验结果表明，S-CDI指标成功识别最优后悔表征层，显著提升了探针分类实验性能。此外，我们发现模型层间存在M形解耦模式，揭示了信息处理在耦合与解耦阶段间的交替。通过RDS指标，我们将神经元分为三类功能组：后悔神经元、非后悔神经元和双功能神经元。

</details>


### [21] [Minding the Politeness Gap in Cross-cultural Communication](https://arxiv.org/abs/2506.15623)
**中文标题：关注跨文化交际中的礼貌差异**

*Yuka Machino,Matthias Hofer,Max Siegel,Joshua B. Tenenbaum,Robert D. Hawkins*

主要分类: cs.CL

摘要简述: 研究发现，英式英语和美式英语使用者对“quite”和“very”等强调词的理解差异源于字面意义和语用因素（如礼貌和简洁）的复杂交互作用。


<details>
  <summary>详细信息</summary>
研究动机: 跨文化交际中的误解常源于对词语理解的细微差异，但尚不清楚这些差异是源于字面意义还是语用因素（如礼貌和简洁）。本文旨在探究英式和美式英语使用者对强调词的不同理解。

研究方法: 通过三个实验，研究英式和美式英语使用者对“quite”和“very”等强调词的理解。开发了一个计算认知模型，模拟听者对说话者在信息量、礼貌和表达成本之间的权衡推理。

研究结果: 模型比较表明，强调词的跨文化理解差异源于字面意义和表达成本权重的不同组合，而非单纯的语义差异或礼貌规范。

研究结论: 跨文化交际中的理解差异是字面意义和语用因素复杂交互的结果，挑战了仅基于语义或礼貌规范的解释。

中文摘要: 跨文化交际中的误解常源于对词语理解的细微差异，但尚不清楚这些差异是源于字面意义还是更一般的语用因素（如礼貌和简洁）。本文通过三个实验，研究了英式和美式英语使用者对“quite”和“very”等强调词的理解。为了更好地理解这些跨文化差异，我们开发了一个计算认知模型，模拟听者对说话者在信息量、礼貌和表达成本之间的权衡推理。模型比较表明，强调词的跨文化理解差异源于（1）不同的字面意义，（2）表达成本权重的不同组合。这些发现挑战了仅基于语义变异或礼貌规范的解释，表明跨文化理解差异是两者复杂交互的结果。

</details>


### [22] [Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability](https://arxiv.org/abs/2506.15629)
**中文标题：重新审视大语言模型的组合泛化能力：基于指令遵循能力的考量**

*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

主要分类: cs.CL

摘要简述: 本文提出Ordered CommonGen基准，评估大语言模型（LLM）的组合泛化与指令遵循能力，发现LLM虽理解指令意图，但受概念顺序偏见影响，输出多样性低且覆盖率仅约75%。


<details>
  <summary>详细信息</summary>
研究动机: 生成式常识推理任务中，LLM需按指令顺序生成句子，但现有研究未充分评估其组合泛化与指令遵循能力，因此提出新基准以填补这一空白。

研究方法: 设计Ordered CommonGen基准，通过有序覆盖率指标评估LLM在指定概念顺序下的生成能力，并对36种LLM进行全面分析。

研究结果: LLM普遍理解指令意图，但受概念顺序偏见影响，输出多样性低且覆盖率最高仅75%，显示其指令遵循与组合泛化能力仍需改进。

研究结论: Ordered CommonGen基准揭示了LLM在指令遵循与组合泛化上的不足，为未来模型优化提供了方向。

中文摘要: 在生成式常识推理任务（如CommonGen）中，大语言模型（LLM）需生成包含所有给定概念的句子。然而，当关注指令遵循能力时，若提示指定概念顺序，LLM必须按顺序生成句子。为此，我们提出Ordered CommonGen基准，用于评估LLM的组合泛化与指令遵循能力。该基准通过有序覆盖率指标衡量概念是否按指定顺序生成，从而同时评估两种能力。我们对36种LLM进行全面分析，发现尽管LLM通常理解指令意图，但对特定概念顺序模式的偏见常导致输出多样性低或概念顺序改变时结果相同。此外，即使最遵循指令的LLM，其有序覆盖率也仅约75%，凸显了指令遵循与组合泛化能力仍需提升。

</details>


### [23] [Oldies but Goldies: The Potential of Character N-grams for Romanian Texts](https://arxiv.org/abs/2506.15650)
**中文标题：老方法的新潜力：字符n-gram在罗马尼亚文本中的应用**

*Dana Lupsa,Sanda-Maria Avram*

主要分类: cs.CL

摘要简述: 本研究通过ROST语料库评估六种机器学习方法（SVM、LR、k-NN、DT、RF、ANN）在罗马尼亚文本作者归属任务中的表现，发现ANN模型在使用5-gram特征时表现最佳，甚至在某些情况下实现完美分类。结果表明，轻量级的字符n-gram方法在资源有限或研究较少的语言中具有潜力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决罗马尼亚文本的作者归属问题，特别是在资源有限或研究较少的语言环境中，探索简单而高效的方法。

研究方法: 使用ROST语料库作为基准，系统评估六种机器学习技术（SVM、LR、k-NN、DT、RF、ANN），并采用字符n-gram特征进行分类。

研究结果: ANN模型在使用5-gram特征时表现最佳，15次实验中有4次实现完美分类。结果表明，轻量级的字符n-gram方法可以达到与复杂方法相媲美的准确率。

研究结论: 研究表明，简单且可解释的字符n-gram方法在罗马尼亚文本作者归属任务中具有潜力，尤其适用于资源有限或研究较少的语言环境。

中文摘要: 本研究通过ROST语料库（该领域的标准基准）解决罗马尼亚文本的作者归属问题。我们系统评估了六种机器学习技术：支持向量机（SVM）、逻辑回归（LR）、k近邻（k-NN）、决策树（DT）、随机森林（RF）和人工神经网络（ANN），并采用字符n-gram特征进行分类。其中，ANN模型表现最佳，在使用5-gram特征时，15次实验中有4次实现完美分类。这些结果表明，轻量级且可解释的字符n-gram方法在罗马尼亚作者归属任务中可以达到最先进的准确率，甚至媲美更复杂的方法。我们的发现突出了简单风格特征在资源有限或研究较少的语言环境中的潜力。

</details>


### [24] [CC-LEARN: Cohort-based Consistency Learning](https://arxiv.org/abs/2506.15662)
**中文标题：CC-LEARN：基于队列的一致性学习**

*Xiao Ye,Shaswat Shrivastava,Zhaonan Li,Jacob Dineen,Shijie Lu,Avneet Ahuja,Ming Shen,Zhikun Xu,Ben Zhou*

主要分类: cs.CL

摘要简述: CC-LEARN是一种基于队列的一致性学习框架，通过强化学习提升大语言模型的推理一致性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在许多任务中表现出色，但在一致性和鲁棒性推理方面仍有不足。为解决这一问题，研究者提出了队列一致性学习框架。

研究方法: CC-LEARN通过定义复合目标（包括队列准确性、问题分解的检索奖励和无效查询的拒绝惩罚）来优化强化学习，从而在相似问题队列中实现一致的推理模式。

研究结果: 在ARC-Challenge和StrategyQA等推理基准测试中，CC-LEARN显著提升了模型的准确性和推理稳定性，优于预训练和SFT基线。

研究结论: 队列级强化学习能有效增强大语言模型的推理一致性，为提升模型可靠性提供了新思路。

中文摘要: 大语言模型在许多任务中表现出色，但在一致性和鲁棒性推理方面仍有不足。我们提出了队列一致性学习（CC-LEARN），这是一种强化学习框架，通过训练基于共享程序抽象的相似问题队列来提升大语言模型的推理可靠性。为了实现队列级别的一致性，我们定义了一个复合目标，包括队列准确性、有效问题分解的检索奖励以及对无效查询的拒绝惩罚，这些目标可以直接通过强化学习优化，而不同于监督微调。优化这一奖励机制可以引导模型在所有队列成员中采用一致的推理模式。在具有挑战性的推理基准测试（包括ARC-Challenge和StrategyQA）中，实验表明CC-LEARN在预训练和SFT基线的基础上显著提升了准确性和推理稳定性。这些结果表明，队列级强化学习能有效增强大语言模型的推理一致性。

</details>


### [25] [Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](https://arxiv.org/abs/2506.15674)
**中文标题：泄露的思考：大型推理模型并非隐私安全的思考者**

*Tommaso Green,Martin Gubri,Haritz Puerto,Sangdoo Yun,Seong Joon Oh*

主要分类: cs.CL

摘要简述: 研究发现大型推理模型的推理痕迹中存在隐私泄露风险，推理步骤增多会放大泄露，揭示了推理能力与隐私保护之间的矛盾。


<details>
  <summary>详细信息</summary>
研究动机: 大型推理模型作为个人代理时，其推理痕迹常被视为内部安全数据。然而，研究质疑这一假设，探讨推理痕迹中是否包含敏感用户数据及其泄露风险。

研究方法: 通过提示注入和代理评估，研究测试了推理痕迹中的隐私泄露情况，并分析了测试时计算（如增加推理步骤）对泄露的影响。

研究结果: 研究发现推理痕迹中确实存在敏感数据泄露，且增加推理步骤会放大泄露风险。推理能力提升的同时，隐私攻击面也随之扩大。

研究结论: 研究强调隐私保护需扩展至模型的内部推理过程，而不仅是最终输出，揭示了推理能力与隐私安全之间的核心矛盾。

中文摘要: 我们研究了作为个人代理的大型推理模型在推理痕迹中的隐私泄露问题。与最终输出不同，推理痕迹常被视为内部安全数据。我们通过实验挑战了这一假设，发现推理痕迹中常包含敏感用户数据，这些数据可能通过提示注入或意外泄露到输出中。通过探测和代理评估，我们证明测试时计算（尤其是增加推理步骤）会放大此类泄露。尽管增加测试时计算预算使模型在最终答案中更为谨慎，但也导致其推理更冗长，并在思考过程中泄露更多信息。这揭示了一个核心矛盾：推理提升效用，但也扩大了隐私攻击面。我们认为安全措施必须扩展至模型的内部思考，而不仅是其输出。

</details>


### [26] [Gender-Neutral Machine Translation Strategies in Practice](https://arxiv.org/abs/2506.15676)
**中文标题：实践中性别中立的机器翻译策略**

*Hillary Dawkins,Isar Nejadgholi,Chi-kiu Lo*

主要分类: cs.CL

摘要简述: 研究评估了21种机器翻译系统在性别模糊情况下的性别中立翻译表现，发现大多数系统缺乏性别中立策略，仅少数系统能根据目标语言采用特定策略。


<details>
  <summary>详细信息</summary>
研究动机: 性别包容的机器翻译需要保留源语言中的性别模糊性，以避免错误性别化和代表性伤害。研究旨在评估现有机器翻译系统在性别模糊情况下的性别中立翻译能力。

研究方法: 研究评估了21种机器翻译系统在三种不同难度的翻译方向中对性别模糊的敏感性，并分类讨论了实际观察到的性别中立策略。同时，还探讨了二元性别刻板印象对性别中立翻译的影响。

研究结果: 大多数机器翻译系统在性别模糊情况下未能提供性别中立翻译，仅少数系统能根据目标语言采用特定策略实现性别中立翻译。

研究结论: 研究揭示了当前机器翻译系统在性别中立翻译方面的不足，但少数系统的成功策略为未来改进提供了方向。

中文摘要: 性别包容的机器翻译（MT）应保留源语言中的性别模糊性，以避免错误性别化和代表性伤害。尽管性别模糊在英语等概念性别语言中自然存在，但在语法性别语言中保持性别中立是一项挑战。本文评估了21种机器翻译系统在三种不同难度的翻译方向中对性别模糊的敏感性，并对实际观察到的性别中立策略进行了分类和讨论。此外，我们还探讨了二元性别刻板印象对性别中立翻译使用的影响。总体而言，我们发现机器翻译系统在性别模糊情况下普遍缺乏性别中立翻译。然而，我们观察到少数机器翻译系统会根据目标语言采用特定策略实现性别中立翻译。

</details>


### [27] [GenRecal: Generation after Recalibration from Large to Small Vision-Language Models](https://arxiv.org/abs/2506.15681)
**中文标题：GenRecal：从大型到小型视觉语言模型的重新校准后生成**

*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

主要分类: cs.CL

摘要简述: GenRecal是一种新颖的通用蒸馏框架，通过重新校准器实现异构视觉语言模型（VLM）间的特征对齐与知识迁移，显著提升小模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型视觉语言模型（VLM）虽性能优异，但计算资源需求高，难以部署在资源受限设备上。同时，不同VLM架构的多样性限制了知识蒸馏的通用性。

研究方法: 提出GenRecal框架，引入重新校准器（Recalibrator）对齐异构VLM的特征表示，实现跨模型的高效知识迁移。

研究结果: 实验表明，GenRecal显著提升基线性能，甚至超越部分大型开源和闭源VLM。

研究结论: GenRecal为异构VLM间的知识蒸馏提供了一种通用解决方案，推动了高效小模型的开发与应用。

中文摘要: 近期视觉语言模型（VLM）的进展通过结合大型语言模型（LLM），性能已媲美闭源系统如GPT-4V。然而，这些模型在资源受限设备上的实际部署仍面临计算需求高的挑战。这促使研究者探索将大型VLM的知识蒸馏到更高效的小型模型中。然而，VLM架构的多样性（如不同LLM基础、词汇量、分词方式和索引顺序）限制了蒸馏的通用性。为解决这一问题，我们提出了一种新颖的通用蒸馏框架——重新校准后生成（GenRecal）。GenRecal通过重新校准器（Recalibrator）对齐异构VLM的特征表示，实现跨模型的有效知识迁移。在多个挑战性基准测试中，GenRecal显著提升了基线性能，最终超越了部分大型开源和闭源VLM。

</details>


### [28] [PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning](https://arxiv.org/abs/2506.15683)
**中文标题：PhantomHunter：通过家族感知学习检测未见的私有调优LLM生成文本**

*Yuhui Shi,Yehan Yang,Qiang Sheng,Hao Mi,Beizhe Hu,Chaoxi Xu,Juan Cao*

主要分类: cs.CL

摘要简述: PhantomHunter是一种新型检测器，专门用于检测来自未见的私有调优LLM生成的文本，通过家族感知学习框架捕获基础模型及其衍生模型的共享特征，实验显示其性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的普及，虚假信息和学术不端等社会问题日益严重，现有检测器对私有调优LLM生成的文本检测效果不佳，亟需解决这一问题。

研究方法: 提出PhantomHunter，采用家族感知学习框架，专注于捕捉基础模型及其衍生模型的家族级共享特征，而非记忆单个模型特性。

研究结果: 在LLaMA、Gemma和Mistral家族数据上的实验表明，PhantomHunter在7种基线方法和3种工业服务中表现最优，F1分数超过96%。

研究结论: PhantomHunter通过家族感知学习有效解决了私有调优LLM生成文本的检测问题，为实际应用提供了可靠解决方案。

中文摘要: 随着大型语言模型（LLM）的流行，虚假信息生产和学术不端等社会问题愈发严重，使得LLM生成文本的检测变得前所未有的重要。尽管现有方法已取得显著进展，但来自私有调优LLM的文本带来的新挑战仍未充分探索。用户可以通过使用私有语料库微调开源LLM轻松拥有私有模型，导致现有检测器在实际应用中性能显著下降。为解决这一问题，我们提出PhantomHunter，一种专门用于检测未见的私有调优LLM生成文本的检测器。其家族感知学习框架捕获基础模型及其衍生模型共享的家族级特征，而非记忆单个特性。在LLaMA、Gemma和Mistral家族数据上的实验表明，其性能优于7种基线方法和3种工业服务，F1分数超过96%。

</details>


### [29] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
**中文标题：MDBench：一种基于知识引导合成的多文档推理基准**

*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

主要分类: cs.CL

摘要简述: MDBench是一个通过知识引导合成生成的多文档推理基准数据集，旨在评估大型语言模型在多文档推理任务中的表现。该数据集通过可控且高效的生成过程，解决了传统多文档基准标注成本高的问题，并展示了其挑战性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）推理能力的快速扩展，多文档推理任务的相关性日益凸显，但现有基准数据集稀缺且标注成本高昂。因此，需要一种高效且可控的方法来生成多文档推理任务的数据集。

研究方法: MDBench采用了一种新颖的合成生成方法：基于结构化的种子知识，通过LLM辅助的编辑引入多文档推理的挑战，并将其转化为自然文本形式，生成文档集和对应的问答示例。

研究结果: 实验表明，MDBench对当前流行的LLM和提示技术均构成显著挑战，即使文档集较短。此外，知识引导的生成技术能够快速适应新的挑战和模型改进。

研究结论: MDBench为多文档推理任务提供了一个高效且可控的基准数据集，填补了现有研究的空白，并展示了其在实际评估中的潜力。

中文摘要: 自然语言处理评估取得了显著进展，主要得益于强大大型语言模型（LLMs）的普及。随着LLMs推理能力的快速扩展，新的评估基准变得越来越重要。特别是，尽管多文档（MD）推理任务因LLMs处理长上下文输入的能力而极具相关性，但现有基准数据集稀缺且难以严格评估模型在此场景下的表现。此外，多文档场景下的基准创建历来因长输入标注成本高昂而具有挑战性。本文介绍了MDBench，一个用于评估LLMs在多文档推理任务中的新数据集。值得注意的是，MDBench通过一种新颖的合成生成过程创建，使我们能够可控且高效地生成具有挑战性的文档集及对应的问答示例。我们的新技术基于结构化的种子知识，通过LLM辅助的编辑引入多文档推理的挑战，并将其转化为自然文本形式，生成文档集和对应的问答示例。我们分析了流行LLM和提示技术的表现，发现MDBench对所有方法均构成显著挑战，即使文档集较短。此外，我们的知识引导生成技术（1）能够快速针对多文档推理能力进行定向分析，（2）可快速适应新挑战和未来模型改进。

</details>


### [30] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
**中文标题：记忆令牌：大型语言模型可生成可逆的句子嵌入**

*Ignacio Sastre,Aiala Rosá*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLM）能够生成可逆的句子嵌入，通过引入特殊记忆令牌实现原始文本的精确重建，无需修改模型权重。


<details>
  <summary>详细信息</summary>
研究动机: 探索大型语言模型是否能够生成可逆的句子嵌入，以实现原始文本的精确重建，并研究其潜在应用。

研究方法: 通过引入特殊记忆令牌，优化其嵌入训练固定序列，使模型在提示该嵌入时能精确重建原始文本。实验覆盖英语和西班牙语数据集，序列长度达240个令牌，模型规模从1亿到80亿参数。

研究结果: 实验表明，Llama 3.1 8B模型成功重建所有测试序列，验证了LLM在可逆嵌入生成方面的能力。

研究结论: 研究揭示了LLM的一项有趣能力，为基于记忆的检索、压缩和可控文本生成提供了潜在应用方向。

中文摘要: 本研究发现了一种有趣的现象：无需修改模型权重，即可生成可逆的句子嵌入，使大型语言模型能够精确重建原始文本。这是通过引入一种特殊的记忆令牌实现的，其嵌入通过固定序列的训练优化。当提示该嵌入时，模型能精确重建固定序列。我们在英语和西班牙语数据集上评估了这一现象，序列长度达约240个令牌，模型规模从1亿到80亿参数。值得注意的是，Llama 3.1 8B成功重建了所有测试序列。这一发现凸显了LLM的有趣能力，并为其在基于记忆的检索、压缩和可控文本生成中的应用提供了可能。

</details>


### [31] [Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification](https://arxiv.org/abs/2506.15081)
**中文标题：通过话语感知的澄清改进对话话语解析**

*Yaxin Fan,Peifeng Li,Qiaoming Zhu*

主要分类: cs.CL

摘要简述: 本文提出了一种基于话语感知的澄清模块（DCM）和贡献感知偏好优化（CPO）的方法，用于解决对话话语解析中的歧义问题，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 对话中的语言特征（如省略和习语）常导致话语关系模糊，给解析器带来挑战。本文旨在通过澄清模块和优化方法解决这一问题。

研究方法: 提出DCM模块，包含澄清类型推理和话语目标推理；引入CPO方法以减少错误澄清的级联影响。

研究结果: 在STAC和Molweni数据集上的实验表明，该方法有效消除歧义，性能显著优于现有基线。

研究结论: DCM和CPO的结合显著提升了对话话语解析的准确性和鲁棒性。

中文摘要: 对话话语解析旨在识别和分析对话中话语之间的关系。然而，对话中的语言特征（如省略和习语）常引入歧义，掩盖了预期的话语关系，给解析器带来挑战。为解决这一问题，我们提出了一种话语感知澄清模块（DCM）以提升对话话语解析器的性能。DCM采用两种推理过程：澄清类型推理和话语目标推理。前者分析语言特征，后者从歧义中区分预期关系。此外，我们引入贡献感知偏好优化（CPO）以减少错误澄清的风险，从而降低级联错误。CPO使解析器能够评估DCM澄清的贡献并提供反馈以优化DCM，增强其适应性和与解析器需求的对齐。在STAC和Molweni数据集上的大量实验表明，我们的方法有效消除歧义，性能显著优于现有基线。

</details>


### [32] [Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs](https://arxiv.org/abs/2506.15131)
**中文标题：利用大语言模型建模开放域对话中的一对多属性**

*Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan*

主要分类: cs.CL

摘要简述: 本文提出了一种通过分解开放域对话生成任务为多响应生成和偏好选择两阶段的方法，以显式建模一对多属性，提升响应多样性和质量。


<details>
  <summary>详细信息</summary>
研究动机: 开放域对话具有一对多属性，即单一对话上下文可对应多个合理响应。尽管研究表明显式建模此属性可提升多样性，但现有基于大语言模型的对话系统多未采用此方法。

研究方法: 将对话生成分解为多响应生成（MRG）和偏好选择（PS）两阶段，并引入o2mDial数据集支持任务。提出新的上下文学习和指令调优策略，以及MRG评估指标和基于模型的PS方法。

研究结果: 实验表明，该框架显著提升较小模型的响应多样性和质量，响应质量最高提升90%，接近大模型性能。

研究结论: 通过显式建模一对多属性，两阶段框架有效提升开放域对话的多样性和质量，为小模型性能优化提供新思路。

中文摘要: 开放域对话（OD）具有一对多（o2m）属性，即单一对话上下文可对应多个合理响应。尽管先前研究表明显式建模此属性可提升响应多样性，但多数现代基于大语言模型（LLM）的对话系统未采用此方法。本文通过将OD生成分解为多响应生成（MRG）和偏好选择（PS）两阶段任务，显式建模OD的o2m属性：首先生成一组语义和词汇多样化的高质量响应，随后基于人类偏好选择单一响应。为支持MRG和PS，我们引入o2mDial对话语料库，其每个上下文均包含多个合理响应。基于o2mDial，我们提出新的上下文学习和指令调优策略、MRG评估指标及基于模型的PS方法。实验结果表明，将该两阶段框架应用于较小LLM进行OD生成，可显著提升响应多样性并保持上下文连贯性，响应质量最高提升90%，使其性能接近大模型。

</details>


### [33] [Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models](https://arxiv.org/abs/2506.15138)
**中文标题：Thunder-Tok：为生成语言模型设计的韩语文本分词最小化方法**

*Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee*

主要分类: cs.CL

摘要简述: 本文介绍了Thunder-Tok，一种新型韩语分词器，旨在减少分词数量而不影响模型性能。通过基于规则的分词方法和分支熵选择算法，显著降低了分词数量，同时保持模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前韩语分词器在生成语言模型中存在分词数量过多的问题，导致推理速度降低。本文旨在设计一种高效的分词器，减少分词数量，同时不损害模型性能。

研究方法: 采用基于规则的预分词方法，结合韩语的语言结构，并利用分支熵选择算法构建种子词汇表，从而增加平均分词长度，降低分词数量。

研究结果: 实验结果表明，Thunder-Tok相比BPE方法减少了约10%的分词数量，推理速度提升10%，且在下游任务中性能未受影响。

研究结论: Thunder-Tok通过语言结构驱动的设计，证明了其在减少分词数量和提高推理速度方面的有效性，为语言模型的高效分词提供了实用方案。

中文摘要: 本文介绍了Thunder-Tok，一种新型韩语分词器，旨在减少分词数量而不影响模型性能。我们的方法采用基于规则的预分词技术，与韩语的语言结构对齐，并构建了一个包含类似语言单元的分词种子词汇表，同时使用基于分支熵的选择算法。这些技术增加了平均分词长度，从而降低了分词数量，同时保留了语言信息。实验结果表明，与BPE相比，Thunder-Tok减少了约10%的分词数量（即分词数量减少10%，推理速度提升10%），且在各种下游任务中性能未受影响。这些发现表明，我们基于语言结构的方法在设计高效语言模型分词器方面是有效且实用的。

</details>


### [34] [A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals](https://arxiv.org/abs/2506.15208)
**中文标题：大型语言模型任务适应技术在识别可持续发展目标中的比较研究**

*Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi*

主要分类: cs.CL

摘要简述: 本研究比较了不同大型语言模型（LLMs）在识别联合国可持续发展目标（SDGs）任务中的表现，并评估了零样本学习、少样本学习和微调等任务适应技术的效果。结果显示，通过提示工程优化的小模型性能可与GPT等大模型媲美。


<details>
  <summary>详细信息</summary>
研究动机: 联合国2012年提出的17个可持续发展目标（SDGs）数据规模庞大且复杂，难以追踪进展。文本分类模型和大型语言模型（LLMs）因其自动化分析能力成为重要工具。本研究旨在探索LLMs在SDGs分类任务中的表现及任务适应技术的有效性。

研究方法: 研究分析了专有和开源LLMs在单标签多类文本分类任务（聚焦SDGs）中的表现，并评估了零样本学习、少样本学习和微调等任务适应技术的效果。

研究结果: 结果显示，通过提示工程优化的小型模型在性能上与OpenAI的GPT等大型模型相当。

研究结论: 研究表明，优化后的小型模型在SDGs分类任务中具有与大型模型相当的潜力，为资源有限场景提供了高效解决方案。

中文摘要: 2012年，联合国提出了17个可持续发展目标（SDGs），旨在到203年创造一个更可持续和更美好的未来。然而，由于数据规模庞大且复杂，追踪这些目标的进展十分困难。文本分类模型成为该领域的重要工具，能够自动化分析来自各种来源的大量文本。此外，大型语言模型（LLMs）因其识别复杂语言模式和语义的能力，最近被证明在许多自然语言处理任务（包括文本分类）中不可或缺。本研究分析了专有和开源LLMs在聚焦SDGs的单标签多类文本分类任务中的表现，并评估了任务适应技术（即上下文学习方法，如零样本学习和少样本学习）以及微调在该领域的有效性。结果显示，通过提示工程优化的小型模型在性能上可与OpenAI的GPT（生成式预训练变换器）等大型模型媲美。

</details>


### [35] [Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment](https://arxiv.org/abs/2506.15301)
**中文标题：队列发现：关于LLM辅助临床试验招募的综述**

*Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff*

主要分类: cs.CL

摘要简述: 本文综述了LLM在临床试验招募中的应用，分析了现有方法的局限性，并探讨了未来发展方向。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLM在通用NLP任务中表现优异，但在临床试验招募等关键领域的应用仍有限。本文旨在探讨LLM如何通过知识整合和推理能力改进试验与患者的匹配任务。

研究方法: 本文通过综述现有文献，分析了LLM辅助的临床试验招募方法，包括其依赖的专有模型和评估基准的不足。

研究结果: 研究发现，现有方法多依赖于专有模型，且评估基准较弱，LLM在临床研究中的应用仍面临挑战。

研究结论: 本文呼吁开发更通用的LLM解决方案，并提出未来研究方向，以推动LLM在临床试验招募中的实际应用。

中文摘要: 近年来，LLM在通用NLP任务中取得了显著进展，但在临床试验招募等关键领域的应用仍然有限。由于试验设计采用自然语言，患者数据以结构化和非结构化文本形式呈现，LLM的知识整合和推理能力为试验与患者的匹配任务提供了潜力。传统方法针对特定试验，而LLM能够整合分散知识，有望构建更通用的解决方案。然而，近期LLM辅助方法多依赖专有模型和弱评估基准。本文首次分析了试验与患者匹配任务，并将新兴的基于LLM的方法置于临床试验招募的背景下。我们批判性地审查了现有基准、方法和评估框架，探讨了LLM技术在临床研究中应用的挑战及未来发展方向。

</details>


### [36] [ConLID: Supervised Contrastive Learning for Low-Resource Language Identification](https://arxiv.org/abs/2506.15304)
**中文标题：ConLID：基于监督对比学习的低资源语言识别方法**

*Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut*

主要分类: cs.CL

摘要简述: 本文提出了一种基于监督对比学习（SCL）的方法ConLID，用于解决低资源语言识别（LID）中的领域偏差和类别不平衡问题，显著提升了模型在跨域数据上的性能。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语言识别（LID）在多语言LLM预训练语料库构建中至关重要，但现有方法因依赖单领域数据（如圣经）而表现不佳。本文旨在通过监督对比学习解决类别不平衡和领域偏差问题。

研究方法: 提出了一种名为ConLID的监督对比学习（SCL）方法，通过学习领域不变表示来提升低资源语言的识别能力。

研究结果: 实验表明，该方法在低资源语言的跨域数据上将LID性能提升了3.2%，验证了其有效性。

研究结论: ConLID通过监督对比学习显著改善了低资源语言识别的跨域性能，为多语言语料库构建提供了更可靠的工具。

中文摘要: 语言识别（LID）是从网络爬取数据中构建多语言LLM预训练语料库的关键步骤。尽管许多关于LID模型训练的研究专注于收集多样化的训练数据以提高性能，但低资源语言——通常仅限于单领域数据（如圣经）——仍然表现不佳。为解决这些类别不平衡和偏差问题，我们提出了一种新颖的监督对比学习（SCL）方法，用于学习低资源语言的领域不变表示。通过广泛分析，我们表明该方法在低资源语言的跨域数据上将LID性能提升了3.2%，证明了其在增强LID模型方面的有效性。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [37] [Advances in Compliance Detection: Novel Models Using Vision-Based Tactile Sensors](https://arxiv.org/abs/2506.14980)
**中文标题：柔顺性检测的进展：基于视觉触觉传感器的新型模型**

*Ziteng Li,Malte Kuhlmann,Ilana Nisky,Nicolás Navarro-Guerrero*

主要分类: cs.CV

摘要简述: 本文提出两种基于长时递归卷积网络（LRCN）和Transformer架构的模型，利用视觉触觉传感器GelSight捕获的RGB触觉图像等信息，显著提升了物体柔顺性检测的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 柔顺性是描述物体在工程、农业和生物医学应用中特性的关键参数。传统检测方法缺乏便携性和可扩展性，依赖昂贵设备且不适用于机器人应用。现有基于神经网络的视觉触觉传感器方法预测精度不足，亟需改进。

研究方法: 提出两种模型：基于长时递归卷积网络（LRCN）和Transformer架构，利用GelSight传感器捕获的RGB触觉图像及其他信息，精准预测柔顺性指标。通过多指标验证模型性能。

研究结果: 模型在柔顺性估计上表现显著优于基线方法。研究发现，传感器柔顺性与物体柔顺性估计存在相关性，硬度高于传感器的物体更难准确估计。

研究结论: 所提模型显著提升了柔顺性检测的准确性，为机器人应用提供了更高效的解决方案。未来可进一步优化对高硬度物体的估计能力。

中文摘要: 柔顺性是描述工程、农业和生物医学应用中物体特性的关键参数。传统柔顺性检测方法因缺乏便携性和可扩展性、依赖昂贵设备且不适用于机器人应用而受限。此外，现有基于神经网络的视觉触觉传感器方法预测精度仍不足。本文提出两种基于长时递归卷积网络（LRCN）和Transformer架构的模型，利用视觉触觉传感器GelSight捕获的RGB触觉图像及其他信息，精准预测柔顺性指标。通过多指标验证模型性能，证明其在柔顺性估计上的有效性。所提模型性能显著优于基线。此外，研究发现传感器柔顺性与物体柔顺性估计存在相关性，硬度高于传感器的物体更难准确估计。

</details>


### [38] [Hyper-Local Deformable Transformers for Text Spotting on Historical Maps](https://arxiv.org/abs/2506.15010)
**中文标题：超局部可变形Transformer在历史地图文本识别中的应用**

*Yijun Lin,Yao-Yi Chiang*

主要分类: cs.CV

摘要简述: 本文提出PALETTE，一种针对历史地图的端到端文本识别方法，通过超局部采样模块和合成数据训练，显著提升了长文本和倾斜文本的识别效果。


<details>
  <summary>详细信息</summary>
研究动机: 历史地图中的文本包含丰富的地理、历史和文化信息，但由于缺乏有效方法和训练数据，传统方法难以应对多样化的地图风格。现有机器学习方法在提取精确图像特征时仍面临挑战，尤其是针对长文本和复杂背景的情况。

研究方法: PALETTE引入超局部采样模块，学习目标边界点和字符周围的局部图像特征，并结合超局部位置嵌入，捕捉文本实例内外的空间关系。此外，提出SynthMap+方法自动生成合成地图数据用于训练。

研究结果: 实验表明，PALETTE结合SynthMap+在两个历史地图基准数据集上优于现有方法，尤其在长文本和倾斜文本识别上表现突出。已成功应用于处理6万张地图并生成1亿多个文本标签。

研究结论: PALETTE通过超局部特征学习和合成数据训练，显著提升了历史地图文本识别的准确性和适应性，为大规模地图搜索提供了技术支持。

中文摘要: 历史地图中的文本包含丰富的地理参考历史、政治和文化信息。然而，由于缺乏有效方法和训练数据，从历史地图中提取文本具有挑战性。先前的方法仅针对特定地图风格设计临时步骤。近年来基于机器学习的文本识别方法（如用于场景图像）因其灵活性有望解决这些问题，但在提取精确图像特征以预测文本实例的每个子组件（边界点和字符）时仍存在困难。这对于地图文本尤为重要，因为地图文本可能较长、高度旋转且背景复杂，难以从粗略文本区域中检测相关图像特征。本文提出PALETTE，一种适用于多种历史地图的端到端文本识别方法。PALETTE引入了一种新颖的超局部采样模块，显式学习目标边界点和字符周围的局部图像特征以进行检测和识别。PALETTE还支持超局部位置嵌入，学习文本实例内外的边界点和字符之间的空间交互。此外，本文提出了一种自动生成合成地图图像SynthMap+的新方法，用于训练历史地图文本识别模型。实验表明，PALETTE结合SynthMap+在两个新的历史地图基准数据集上优于现有文本识别方法，尤其擅长处理长文本和倾斜文本。我们已将PALETTE与SynthMap+应用于David Rumsey历史地图集中的6万多张地图，生成了超过1亿个文本标签以支持地图搜索。项目已发布于https://github.com/kartta-foundation/mapkurator-palette-doc。

</details>


### [39] [Break Stylistic Sophon: Are We Really Meant to Confine the Imagination in Style Transfer?](https://arxiv.org/abs/2506.15033)
**中文标题：打破风格桎梏：我们真的需要限制风格迁移中的想象力吗？**

*Gary Song Yan,Yusen Zhang,Jinyu Zhao,Hao Zhang,Zhangping Yang,Guanye Xiong,Yanfei Liu,Tao Zhang,Yujie He,Siyuan Tian,Yao Gou,Min Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为StyleWallfacer的创新框架，通过语义风格注入、数据增强策略和无训练三重扩散过程，实现了高质量的图像风格迁移和文本驱动风格化，同时保留了原始内容并首次实现了颜色编辑。


<details>
  <summary>详细信息</summary>
研究动机: 传统风格迁移方法存在多种问题，如风格注入效率低、内容漂移和过拟合等。本文旨在通过统一框架解决这些问题，并实现艺术家级别的风格迁移和文本驱动风格化。

研究方法: 1. 提出基于语义的风格注入方法，利用BLIP生成与风格图像语义严格对齐的文本描述，并通过大语言模型移除风格相关描述以创建语义间隙，用于微调模型。2. 提出基于人类反馈的数据增强策略，将高质量样本加入训练集以减少过拟合。3. 设计无训练三重扩散过程，通过替换自注意力层的键和值实现风格注入，同时保留文本控制。

研究结果: 实现了高质量的图像驱动风格迁移和文本驱动风格化，保留了原始内容并首次在风格迁移过程中实现了颜色编辑。

研究结论: StyleWallfacer框架通过创新的语义风格注入、数据增强和扩散过程，显著提升了风格迁移的质量和灵活性，为艺术家级别的风格迁移开辟了新途径。

中文摘要: 在这项开创性研究中，我们提出了StyleWallfacer，这是一种突破性的统一训练与推理框架，不仅解决了传统方法在风格迁移过程中遇到的各种问题，还为不同任务提供了统一的框架。该框架旨在通过实现艺术家级别的风格迁移和文本驱动风格化来革新该领域。首先，我们提出了一种基于语义的风格注入方法，利用BLIP生成与风格图像语义在CLIP空间中严格对齐的文本描述。通过使用大语言模型从这些描述中移除风格相关描述，我们创建了一个语义间隙。该间隙用于微调模型，从而实现高效且无漂移的风格知识注入。其次，我们提出了一种基于人类反馈的数据增强策略，将微调早期生成的高质量样本纳入训练集，以促进渐进式学习并显著减少过拟合。最后，我们设计了一种使用微调模型的无训练三重扩散过程，以类似于交叉注意力机制的方式操作自注意力层的特征。具体而言，在生成过程中，内容相关过程的键和值被替换为风格相关过程的键和值，以注入风格同时保持对模型的文本控制。我们还引入了查询保留机制以减轻对原始内容的干扰。在此设计下，我们实现了高质量的图像驱动风格迁移和文本驱动风格化，提供了艺术家级别的风格迁移结果，同时保留了原始图像内容。此外，我们首次在风格迁移过程中实现了图像颜色编辑。

</details>


### [40] [Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study](https://arxiv.org/abs/2506.15078)
**中文标题：通过分布匹配增强向量量化：理论与实证研究**

*Xianghong Fang,Litao Guo,Hengchao Chen,Yuxuan Zhang,XiaofanXia,Dingjie Song,Yexin Liu,Hao Wang,Harry Yang,Yuan Yuan,Qiang Sun*

主要分类: cs.CV

摘要简述: 本文提出了一种通过分布匹配增强向量量化的方法，解决了现有方法中的训练不稳定和码本崩溃问题，显著提升了码本利用率和量化效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有向量量化方法存在训练不稳定和码本崩溃问题，主要源于特征与码向量分布不匹配，导致码向量不具代表性和信息损失。本文旨在通过分布对齐解决这些问题。

研究方法: 使用Wasserstein距离对齐特征和码向量的分布，以减少量化误差并提高码本利用率。

研究结果: 实验和理论分析表明，该方法实现了接近100%的码本利用率，并显著降低了量化误差。

研究结论: 通过分布匹配的向量量化方法有效解决了训练不稳定和码本崩溃问题，提升了量化性能。

中文摘要: 自回归模型的成功很大程度上依赖于向量量化的有效性，这是一种通过将连续特征映射到可学习码本中的最近码向量来离散化特征的技术。现有向量量化方法存在两个关键问题：训练不稳定和码本崩溃。训练不稳定源于直通估计器引入的梯度差异，尤其是在量化误差较大时；而码本崩溃则发生在训练过程中仅使用少量码向量时。深入分析表明，这些问题主要由特征与码向量分布不匹配引起，导致码向量不具代表性和压缩过程中的信息损失。为此，我们采用Wasserstein距离对齐这两种分布，实现了接近100%的码本利用率，并显著降低了量化误差。实证和理论分析均验证了该方法的有效性。

</details>


### [41] [SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts](https://arxiv.org/abs/2506.15153)
**中文标题：SynPo：通过高质量负提示提升无训练少样本医学图像分割**

*Yufei Liu,Haoke Xiao,Jiaxing Chai,Yongcun Zhang,Rong Wang,Zijie Meng,Zhiming Luo*

主要分类: cs.CV

摘要简述: SynPo通过提升负提示质量，提出了一种基于大型视觉模型（如SAM）的无训练少样本医学图像分割方法，显著提升了低对比度医学图像的分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于大型视觉模型的无训练少样本医学图像分割方法未能有效利用负提示，导致在低对比度医学图像上表现不佳。SynPo旨在通过改进负提示质量解决这一问题。

研究方法: SynPo设计了置信图协同模块，结合DINOv2和SAM的优势生成可靠置信图，从中选择高置信度像素作为正提示点，并通过高斯分布和K-means聚类选择负提示点，最终利用这些高质量提示点驱动SAM完成分割。

研究结果: 实验表明，SynPo在少样本医学图像分割任务中表现优异，性能接近基于训练的最先进方法。

研究结论: SynPo通过优化负提示质量，显著提升了无训练少样本医学图像分割的性能，为相关领域提供了新思路。

中文摘要: 大型视觉模型（LVMs）的出现为少样本医学图像分割提供了新机遇。然而，现有基于LVMs的无训练方法未能有效利用负提示，导致在低对比度医学图像上表现不佳。为解决这一问题，我们提出SynPo，一种基于LVMs（如SAM）的无训练少样本方法，其核心思想是提升负提示质量。为在更可靠的置信图中选择点提示，我们设计了一种新颖的置信图协同模块，结合DINOv2和SAM的优势。基于置信图，我们选择前k个像素作为正点集，并通过高斯分布和独立K-means聚类选择负点集。随后，这些选定的点被用作SAM的高质量提示以获取分割结果。大量实验表明，SynPo的性能接近基于训练的最先进少样本方法。

</details>


### [42] [Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation](https://arxiv.org/abs/2506.15160)
**中文标题：基于跨阶段结构相关性的邻居聚合校正增强点云分析**

*Jiaqi Shi,Jin Xiao,Xiaoguang Hu,Boyang Song,Hao Jiang,Tianyou Chen,Baochang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于跨阶段结构相关性的点云分析方法（PDSA），通过高维空间相关性校正特征分布，提升计算效率和鲁棒性，并在语义分割和分类任务中验证了其性能。


<details>
  <summary>详细信息</summary>
研究动机: 点云分析中，现有方法因局部坐标限制存在无关点干扰和特征层次差距问题，而基于直接几何结构编码的增强方法则面临计算开销大和噪声敏感性问题。

研究方法: 提出点分布集抽象模块（PDSA），利用高维空间相关性校正特征分布，通过轻量级跨阶段结构描述符区分点相关性，并通过减少邻居特征矩阵方差和长距离建模增强结构同质性。引入关键点机制优化计算开销。

研究结果: 在不同基线的语义分割和分类任务中验证了方法的泛化性，以更少的参数成本实现了显著性能提升。消融实验和可视化结果证明了方法的有效性和合理性。

研究结论: PDSA模块通过高维空间相关性校正特征分布，显著提升了点云分析的效率和鲁棒性，为下游任务提供了可靠支持。

中文摘要: 点云分析是许多下游任务的基石，其中聚合局部结构是理解点云数据的基础。尽管许多工作利用三维相对坐标聚合邻居，但由于局部坐标的限制，存在无关点干扰和特征层次差距问题。虽然一些工作通过显式建模跨阶段结构来细化空间描述以解决这一限制，但这些基于直接几何结构编码的增强方法存在计算开销高和噪声敏感性问题。为克服这些问题，我们提出了点分布集抽象模块（PDSA），利用高维空间的相关性在校正聚合过程中的特征分布，从而提升计算效率和鲁棒性。PDSA基于轻量级跨阶段结构描述符区分点相关性，并通过减少邻居特征矩阵的方差和长距离建模增强结构同质性。此外，我们引入关键点机制以优化计算开销。基于不同基线的语义分割和分类任务的实验结果验证了所提方法的泛化性，并以更少的参数成本实现了显著性能提升。相应的消融实验和可视化结果证明了方法的有效性和合理性。代码和训练权重可在以下链接获取：https://github.com/AGENT9717/PointDistribution

</details>


### [43] [Echo-DND: A dual noise diffusion model for robust and precise left ventricle segmentation in echocardiography](https://arxiv.org/abs/2506.15166)
**中文标题：Echo-DND：一种用于超声心动图中左心室鲁棒精确分割的双噪声扩散模型**

*Abdur Rahman,Keerthiveena Balraj,Manojkumar Ramteke,Anurag Singh Rathore*

主要分类: cs.CV

摘要简述: 本文提出了一种新型双噪声扩散模型Echo-DND，用于超声心动图中左心室的精确分割。通过结合高斯和伯努利噪声以及多尺度融合模块，显著提升了分割精度，并在两个数据集上取得了优异的性能。


<details>
  <summary>详细信息</summary>
研究动机: 超声图像噪声大、对比度低且边界模糊，导致左心室分割困难。现有方法难以应对这些挑战，因此需要一种更鲁棒且精确的分割模型。

研究方法: Echo-DND采用高斯和伯努利噪声的双噪声扩散模型，结合多尺度融合模块提升分割精度，并通过空间一致性校准保持分割掩模的空间完整性。

研究结果: 在CAMUS和EchoNet-Dynamic数据集上，Echo-DND分别取得了0.962和0.939的Dice分数，优于现有最优模型。

研究结论: Echo-DND为超声心动图分割设立了新标准，其架构在更广泛的医学影像任务中具有潜在应用价值，有望提升诊断准确性。

中文摘要: 近年来，扩散概率模型（DPMs）在图像处理领域取得了革命性进展，展示了在医学应用中的巨大潜力。超声心动图中左心室（LV）的精确分割对诊断和治疗至关重要。然而，超声图像噪声大、对比度低且LV边界模糊，使得分割过程复杂化。为解决这些问题，本文提出了Echo-DND，一种专为此任务设计的双噪声扩散模型。Echo-DND结合了高斯和伯努利噪声，并采用多尺度融合条件模块以提高分割精度。此外，它还利用空间一致性校准保持分割掩模的空间完整性。该模型在CAMUS和EchoNet-Dynamic数据集上进行了严格验证。大量评估表明，所提框架优于现有最优模型，分别在这两个数据集上取得了0.962和0.939的高Dice分数。Echo-DND为超声心动图分割设立了新标准，其架构在更广泛的医学影像任务中具有潜在应用价值，有望提升多种医学领域的诊断准确性。项目页面：https://abdur75648.github.io/Echo-DND

</details>


### [44] [ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections](https://arxiv.org/abs/2506.15180)
**中文标题：ReSeDis：基于指代的大规模图像集合对象搜索数据集**

*Ziling Huang,Yidan Zhang,Shin'ichi Satoh*

主要分类: cs.CV

摘要简述: ReSeDis是首个将大规模图像检索与像素级定位统一的任务，提出了一种结合检索与定位的端到端测试平台，并设计了专用评估指标。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉搜索技术要么仅关注图像级检索，要么仅关注像素级定位，无法同时满足大规模图像集合中的精确搜索需求。ReSeDis旨在填补这一空白，提供更全面的解决方案。

研究方法: ReSeDis通过自由描述查询对象，要求模型判断对象是否存在于图像中并定位其位置（边界框或分割掩码）。研究还设计了专用评估指标，并提供了基于冻结视觉语言模型的零样本基线方法。

研究结果: ReSeDis提供了一个多样化的基准数据集，并展示了现有技术在检索召回与定位精度上的显著提升空间。

研究结论: ReSeDis为构建下一代鲁棒且可扩展的多模态搜索系统提供了现实的测试平台，未来研究潜力巨大。

中文摘要: 大规模视觉搜索引擎需同时解决两个问题：(i) 定位包含句子描述对象的图像，(ii) 在每个匹配图像中识别对象的边界框或精确像素。现有技术仅解决其中一方面。视觉定位虽能提供精确框或掩码，但假设对象存在于每张测试图像中，导致网络规模集合中误报泛滥。文本到图像检索擅长从海量数据库中筛选相关图像，但仅停留在整图匹配，无法提供细粒度定位。我们提出指代搜索与发现（ReSeDis），首个将语料库级检索与像素级定位统一的任务。给定自由描述，ReSeDis模型需判断查询对象是否出现在每张图像中，并返回其边界框或分割掩码。为支持严谨研究，我们构建了一个基准数据集，其中每个描述唯一映射到分散在大型多样化语料中的对象实例，避免意外匹配。我们还设计了任务专用指标，联合评分检索召回与定位精度。此外，我们提供了基于冻结视觉语言模型的零样本基线方法，揭示了未来研究的巨大空间。ReSeDis为构建下一代鲁棒且可扩展的多模态搜索系统提供了现实的端到端测试平台。

</details>


### [45] [Conquering the Retina: Bringing Visual in-Context Learning to OCT](https://arxiv.org/abs/2506.15200)
**中文标题：征服视网膜：将视觉上下文学习引入OCT**

*Alessio Negrini,Simon Reiß*

主要分类: cs.CV

摘要简述: 本文探索了如何通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域，并提出了针对VICL的评估协议。实验表明，该方法在多个OCT数据集上具有潜力，但也存在局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前医学图像分析领域高度依赖针对特定任务的专用模型，其开发和应用需要大量资源和专业知识。通用模型能够根据少量示例动态定义任务，更具灵活性。本文旨在探索如何通过VICL训练通用模型，以解决OCT领域的任务泛化问题。

研究方法: 采用视觉上下文学习（VICL）方法，训练模型在推理时基于少量示例泛化到不同任务。提出了专门针对OCT领域的VICL评估协议，并在多个视网膜OCT数据集上对现有医学VICL方法进行了全面评估。

研究结果: 实验结果表明，VICL方法在OCT任务中展现出潜力，能够基于少量示例实现任务泛化，但同时也揭示了当前方法的局限性。研究为后续研究提供了首个基线结果。

研究结论: 本文通过VICL方法探索了OCT领域的通用模型训练，展示了其潜力并指出了局限性。公开了代码以促进进一步研究和实际应用。

中文摘要: 近年来，医学图像分析领域的进展催生了许多针对特定临床任务的高度专业化模型。这些模型表现出卓越的性能，并仍是重要研究方向。然而，其适用性仅限于预定义任务，开发和适应需要专业知识和大量资源。相比之下，通用模型提供了另一种实用性：允许医疗从业者动态定义任务，无需开发特定任务模型。本文探索了如何通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域，即在推理时基于少量示例实现任务泛化。为便于严格评估，我们提出了针对OCT中VICL的广泛评估协议。我们在多个视网膜OCT数据集上全面评估了最先进的医学VICL方法，建立了首个基线，以突显OCT中上下文学习的潜力及当前局限。为促进进一步研究和实际应用，我们公开了代码。

</details>


### [46] [Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models](https://arxiv.org/abs/2506.15201)
**中文标题：隐私保护图像压缩：防御视觉语言预训练模型的利用**

*Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为隐私保护图像压缩（PSIC）的方法，通过在图像压缩阶段嵌入防御机制，防止视觉语言预训练（VLP）模型对公开图像的语义利用。该方法支持多解码选项，既能保护隐私，又能保留原始图像压缩功能。


<details>
  <summary>详细信息</summary>
研究动机: 随着视觉语言预训练（VLP）模型语义理解能力的提升，公开图像容易被搜索引擎等工具利用，威胁用户隐私。本文旨在通过图像压缩阶段的防御机制保护用户隐私。

研究方法: 提出隐私保护图像压缩（PSIC）方法，通过条件潜在触发生成（CLTG）模块和不确定性感知加密优化（UAEO）函数，实现多解码选项的比特流生成。结合自适应多目标优化策略，提升加密性能和感知质量。

研究结果: 实验表明，PSIC在多个下游任务中有效防止VLP模型的语义利用，同时保持图像压缩功能。该方法可无缝集成到现有学习型图像压缩（LIC）模型中。

研究结论: PSIC是一种灵活且高效的隐私保护图像压缩方法，既能防止VLP模型的语义利用，又能保留原始图像功能，具有广泛的应用潜力。

中文摘要: 视觉语言预训练（VLP）模型语义理解能力的提升使得公开图像更容易被搜索引擎等工具利用。为此，本文提出在图像压缩阶段实施防御机制以保护用户隐私。具体而言，我们提出了一种灵活的编码方法——隐私保护图像压缩（PSIC），可生成具有多解码选项的比特流。默认情况下，比特流解码后既能保持满意的感知质量，又能防止VLP模型的语义解读。该方法还保留了原始图像压缩功能。通过自定义输入条件，该方案可重建保留完整语义信息的图像。我们提出了条件潜在触发生成（CLTG）模块，基于自定义条件生成偏置信息以指导解码过程，并设计了不确定性感知加密优化（UAEO）函数，利用目标VLP模型对训练数据的不确定性推断软标签。本文进一步结合自适应多目标优化策略，在统一训练过程中同时提升加密性能和感知质量。该方案即插即用，可无缝集成到大多数现有学习型图像压缩（LIC）模型中。多个下游任务的广泛实验验证了设计的有效性。

</details>


### [47] [Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?](https://arxiv.org/abs/2506.14805)
**中文标题：Argus检验：多模态大语言模型是否拥有Panoptes之眼？**

*Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang*

主要分类: cs.CV

摘要简述: 本文介绍了Argus Inspection，一个多模态基准测试，用于评估多模态大语言模型（MLLMs）在细粒度视觉感知和常识因果推理方面的能力，并提出Eye of Panoptes框架以更全面地评估模型表现。实验显示当前模型的最高性能仅为0.46，表明仍有较大提升空间。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）的认知和推理能力取得了显著进展，但在细粒度视觉感知和常识因果推理方面仍存在挑战。本文旨在通过Argus Inspection基准测试和Eye of Panoptes框架，全面评估MLLMs在这些方面的表现。

研究方法: 本文提出Argus Inspection，一个包含两个难度级别的多模态基准测试，强调细粒度视觉识别和常识因果推理。进一步提出Eye of Panoptes框架，结合二元参数Sigmoid指标和指示函数，以更全面地评估MLLMs在基于观点的推理任务中的表现。

研究结果: 实验对26个主流MLLMs进行了测试，结果显示在细粒度视觉推理任务中，最高性能仅为0.46，表明模型在这些方面仍有显著提升空间。

研究结论: 本文为MLLMs的进一步优化提供了有价值的视角，揭示了当前模型在细粒度视觉感知和常识因果推理方面的不足，并提出了改进方向。

中文摘要: 随着多模态大语言模型（MLLMs）的不断发展，其认知和推理能力取得了显著进步。然而，在细粒度视觉感知和常识因果推理方面仍存在挑战。本文提出了Argus Inspection，一个包含两个难度级别的多模态基准测试，强调细粒度视觉识别，同时结合现实世界的常识理解以评估因果推理能力。在此基础上，我们提出了Eye of Panoptes框架，该框架将二元参数Sigmoid指标与指示函数相结合，能够更全面地评估MLLMs在基于观点的推理任务中的表现。对26个主流MLLMs的实验表明，细粒度视觉推理的最高性能仅为0.46，显示出仍有较大的提升潜力。本研究为MLLMs的持续优化提供了宝贵的视角。

</details>


### [48] [DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder](https://arxiv.org/abs/2506.15218)
**中文标题：DM-FNet：基于扩散过程训练的编码器-解码器实现统一多模态医学图像融合**

*Dan He,Weisheng Li,Guofen Wang,Yuping Huang,Shiqiang Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于扩散模型的两阶段多模态医学图像融合网络（DM-FNet），通过扩散过程训练编码器-解码器，解决了现有方法在细节特征捕捉和跨模态交互上的不足，显著提升了融合图像的质量和信息密度。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态医学图像融合方法在细节特征捕捉和跨模态交互方面表现不足，导致融合图像质量不理想。本研究旨在通过扩散模型和融合模块的结合，提升融合图像的亮度、颜色、对比度和细节表现。

研究方法: 方法分为两阶段：第一阶段通过扩散过程训练UNet进行图像重建，捕捉多级数据特征；第二阶段将不同噪声水平的图像输入融合网络，结合三个关键融合模块自适应处理多模态医学图像，并通过混合损失函数优化融合效果。

研究结果: 实验结果表明，DM-FNet在多种医学图像类型上表现优异，融合图像保留了适当的亮度、放射性示踪剂分布、丰富纹理和清晰边缘，客观评价指标显著优于现有方法。

研究结论: DM-FNet通过扩散模型和融合模块的结合，有效提升了多模态医学图像融合的质量和信息密度，为医学诊断提供了更全面的图像支持。

中文摘要: 多模态医学图像融合（MMIF）通过从多源图像中提取最有意义的信息，实现更全面和准确的诊断。高质量的融合结果需要平衡亮度、颜色、对比度和细节，以确保融合图像有效显示相关解剖结构并反映组织的功能状态。然而，现有MMIF方法在传统训练中捕捉细节特征的能力有限，且跨模态特征交互不足，导致融合图像质量不理想。为解决这些问题，本研究提出了一种基于扩散模型的两阶段融合网络（DM-FNet）以实现统一的MMIF。在第一阶段，扩散过程训练UNet进行图像重建，通过逐步去噪捕捉细节信息并表征多级数据，为后续融合网络提供丰富的特征表示。在第二阶段，将不同噪声水平的图像输入融合网络以增强模型的特征识别能力。同时，集成了三个关键融合模块以自适应处理不同模态的医学图像。最终，通过鲁棒的网结构和混合损失函数协调融合图像的亮度、颜色、对比度和细节，提升其质量和信息密度。在多种医学图像类型上的实验结果表明，所提方法在客观评价指标上表现优异，融合图像保留了适当的亮度、放射性示踪剂分布、丰富纹理和清晰边缘。代码详见https://github.com/HeDan-11/DM-FNet。

</details>


### [49] [video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2506.15220)
**中文标题：video-SALMONN 2：字幕增强的音频-视觉大语言模型**

*Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang*

主要分类: cs.CV

摘要简述: 本文介绍了video-SALMONN 2，一种基于低秩适应（LoRA）的音频-视觉大语言模型，通过定向偏好优化（DPO）提升视频（含音频）字幕生成能力。提出多轮DPO（MrDPO）方法，显著降低字幕错误率28%，并在7B参数规模下超越GPT-4o和Gemini-1.5-Pro。


<details>
  <summary>详细信息</summary>
研究动机: 视频包含丰富信息，生成准确详细的自然语言描述是视频理解的关键。现有模型在字幕生成和问答任务中仍有提升空间，需优化训练方法和评估指标。

研究方法: 提出video-SALMONN 2模型，结合LoRA和DPO优化字幕生成。创新提出MrDPO方法，周期性更新参考模型、合并并重新初始化LoRA模块，并引入真实字幕指导以稳定训练。

研究结果: 实验显示MrDPO显著提升字幕准确性，错误率降低28%。7B参数的video-SALMONN 2在字幕任务中超越GPT-4o和Gemini-1.5-Pro，并在问答基准中保持竞争力。

研究结论: video-SALMONN 2通过MrDPO方法在视频字幕生成任务中表现优异，参数效率高，为视频理解任务提供了新思路。

中文摘要: 视频包含丰富信息，生成详细准确的自然语言描述是视频理解的关键。本文提出video-SALMONN 2，一种基于低秩适应（LoRA）的音频-视觉大语言模型，通过定向偏好优化（DPO）增强视频（含音频）字幕生成能力。我们提出新指标评估视频描述的完整性和准确性，并通过DPO优化。为进一步提升训练效果，提出多轮DPO（MrDPO）方法，周期性更新DPO参考模型，合并并重新初始化LoRA模块作为参数更新的代理，并引入真实字幕指导以稳定训练。实验结果表明，MrDPO显著提升video-SALMONN 2的字幕准确性，错误率降低28%。最终7B参数的video-SALMONN 2在字幕任务中超越GPT-4o和Gemini-1.5-Pro，同时在相似规模模型的视频问答基准中保持竞争力。代码发布于https://github.com/bytedance/video-SALMONN-2。

</details>


### [50] [Convolutional Feature Enhancement and Attention Fusion BiFPN for Ship Detection in SAR Images](https://arxiv.org/abs/2506.15231)
**中文标题：基于卷积特征增强与注意力融合BiFPN的SAR图像船舶检测**

*Liangjie Meng,Danxia Li,Jinrong He,Lili Ma,Zhixin Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为C-AFBiFPN的新型特征增强与融合框架，用于解决SAR图像中船舶检测面临的尺度变化、噪声干扰及复杂背景等问题。通过卷积特征增强模块和注意力融合BiFPN网络，显著提升了小目标检测精度和全局建模能力。


<details>
  <summary>详细信息</summary>
研究动机: SAR图像中的船舶检测面临尺度变化大、小目标与噪声混杂以及复杂背景等挑战，现有方法难以有效解决这些问题。因此，本文旨在提出一种能够增强特征表示并提升多尺度特征融合能力的新框架。

研究方法: 方法包括：1) 在骨干网络后构建卷积特征增强（CFE）模块，以丰富特征表示；2) 在BiFPN融合策略中引入BiFormer注意力，形成AFBiFPN网络，提升全局建模能力并自适应关注关键特征区域。

研究结果: 在SAR船舶检测数据集（SSDD）上的实验结果表明，所提方法显著提升了小目标检测精度、抗遮挡鲁棒性以及对多尺度特征的适应性。

研究结论: C-AFBiFPN框架通过特征增强和注意力融合，有效解决了SAR船舶检测中的关键问题，为复杂场景下的目标检测提供了新思路。

中文摘要: 合成孔径雷达（SAR）通过主动微波和先进信号处理技术实现了亚米级分辨率成像和全天候监测。目前，SAR已在船舶检测等关键海事领域得到广泛应用。然而，SAR船舶检测面临诸多挑战，包括船舶尺度变化显著、小目标与噪声混杂以及近岸大型船舶背景复杂等。为解决这些问题，本文提出了一种名为C-AFBiFPN的新型特征增强与融合框架。C-AFBiFPN在骨干网络后构建了卷积特征增强（CFE）模块，旨在丰富特征表示并增强对局部细节和上下文信息的捕捉能力。此外，C-AFBiFPN创新性地将BiFormer注意力集成到BiFPN的融合策略中，形成了AFBiFPN网络。AFBiFPN提升了跨尺度特征融合的全局建模能力，并能自适应地聚焦关键特征区域。在SAR船舶检测数据集（SSDD）上的实验结果表明，所提方法显著提升了小目标检测精度、抗遮挡鲁棒性以及对多尺度特征的适应性。

</details>


### [51] [RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories](https://arxiv.org/abs/2506.15242)
**中文标题：RA-NeRF：复杂轨迹下基于精确相机姿态估计的鲁棒神经辐射场重建**

*Qingsong Yan,Qiang Wang,Kaiyong Zhao,Jie Chen,Bo Li,Xiaowen Chu,Fei Deng*

主要分类: cs.CV

摘要简述: RA-NeRF提出了一种新方法，能够在复杂相机轨迹下实现高精度相机姿态预测，结合光度一致性和流驱动姿态调节，提升场景重建的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖精确的相机姿态先验，但在复杂轨迹下表现不佳。RA-NeRF旨在解决这一问题，提升复杂轨迹下的姿态估计精度和场景重建质量。

研究方法: RA-NeRF采用增量式流程，结合NeRF的光度一致性和流驱动姿态调节，增强初始化和定位的鲁棒性，并引入隐式姿态滤波器消除噪声。

研究结果: 在Tanks&Temple和NeRFBuster数据集上，RA-NeRF在相机姿态估计和视觉质量上均达到最优性能，验证了其有效性和鲁棒性。

研究结论: RA-NeRF在复杂相机轨迹下实现了高精度的姿态估计和高质量场景重建，为相关任务提供了有效解决方案。

中文摘要: 神经辐射场（NeRF）和3D高斯溅射（3DGS）已成为3D重建和SLAM任务的有力工具，但其性能高度依赖精确的相机姿态先验。现有方法通过引入外部约束尝试解决这一问题，但在复杂相机轨迹下仍难以达到满意的精度。本文提出了一种新方法RA-NeRF，能够在复杂相机轨迹下预测高精度的相机姿态。RA-NeRF采用增量式流程，利用NeRF的光度一致性重建场景，并通过流驱动姿态调节增强初始化和定位的鲁棒性。此外，RA-NeRF引入隐式姿态滤波器捕捉相机运动模式并消除姿态估计中的噪声。为验证方法有效性，我们在Tanks&Temple数据集上进行标准评估，并在具有挑战性相机轨迹的NeRFBuster数据集上进行测试。实验结果表明，RA-NeRF在两个数据集上的相机姿态估计和视觉质量均达到最优性能，证明了其在复杂姿态轨迹下场景重建的有效性和鲁棒性。

</details>


### [52] [ViLLa: A Neuro-Symbolic approach for Animal Monitoring](https://arxiv.org/abs/2506.14823)
**中文标题：ViLLa：一种神经符号方法在动物监测中的应用**

*Harsha Koduri*

主要分类: cs.CV

摘要简述: ViLLa是一个结合视觉、语言和逻辑的神经符号框架，用于可解释的动物监测，通过模块化设计实现透明推理。


<details>
  <summary>详细信息</summary>
研究动机: 自然环境中监测动物种群需要能同时处理视觉数据和自然语言查询的系统，ViLLa旨在提供一种可解释且模块化的解决方案。

研究方法: ViLLa整合了视觉检测模块（识别动物及其位置）、语言解析器（理解自然语言查询）和符号推理层（基于逻辑推理回答问题），实现感知、理解和推理的分离。

研究结果: ViLLa在多种动物图像任务中表现出色，能够准确回答与数量、存在和位置相关的查询，验证了其模块化和透明性优势。

研究结论: ViLLa通过神经符号方法成功实现了动物监测的可解释性，为复杂环境中的多模态任务提供了新思路。

中文摘要: 监测自然环境中的动物种群需要能够同时解析视觉数据和自然语言查询的系统。本文提出ViLLa（视觉-语言-逻辑方法），一种专为可解释动物监测设计的神经符号框架。ViLLa整合了三个核心组件：视觉检测模块（用于识别图像中的动物及其空间位置）、语言解析器（用于理解自然语言查询）以及符号推理层（通过基于逻辑的推理回答查询）。给定一张图像和诸如“场景中有多少只狗？”或“水牛在哪里？”的问题，系统将视觉检测结果转化为符号事实，并利用预定义规则计算与数量、存在和位置相关的准确答案。与端到端黑盒模型不同，ViLLa将感知、理解和推理分离，提供了模块化和透明性。该系统在多种动物图像任务中进行了评估，展示了其将视觉内容与结构化、人类可解释查询相结合的能力。

</details>


### [53] [Retrospective Memory for Camouflaged Object Detection](https://arxiv.org/abs/2506.15244)
**中文标题：基于回顾记忆的伪装目标检测**

*Chenxi Zhang,Jiayun Wu,Qing Zhang,Yazhe Zhai,Youwei Pang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为RetroMem的回忆增强伪装目标检测架构，通过动态整合历史知识显著提升模型对复杂伪装场景的理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有伪装目标检测方法缺乏历史上下文获取机制，限制了其在复杂场景中的适应性和有效性。

研究方法: RetroMem采用两阶段训练范式：学习阶段通过密集多尺度适配器（DMA）提升编码器能力；回忆阶段通过动态记忆机制（DMM）和推理模式重建（IPR）整合历史知识。

研究结果: 在多个数据集上的实验表明，RetroMem显著优于现有最先进方法。

研究结论: RetroMem通过动态记忆整合历史知识，有效提升了伪装目标检测的性能。

中文摘要: 伪装目标检测（COD）主要关注从复杂场景中学习细微但具有区分性的表征。现有方法主要基于静态视觉表征建模的参数化前馈架构，但缺乏获取历史上下文的显式机制，限制了其在处理复杂伪装场景时的适应性和有效性。本文提出了一种回忆增强的COD架构RetroMem，通过动态整合相关历史知识来调节伪装模式的感知和推理。具体而言，RetroMem采用两阶段训练范式（学习阶段和回忆阶段）有效构建、更新和利用记忆表征。在学习阶段，我们设计了密集多尺度适配器（DMA），以极少的可训练参数提升预训练编码器捕获丰富多尺度视觉信息的能力，从而提供基础推理。在回忆阶段，我们提出了动态记忆机制（DMM）和推理模式重建（IPR），充分利用学习知识与当前样本上下文之间的潜在关系重建伪装模式的推理，显著提升模型对伪装场景的理解。在多个广泛使用的数据集上的大量实验表明，RetroMem显著优于现有最先进方法。

</details>


### [54] [Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing](https://arxiv.org/abs/2506.15260)
**中文标题：半导体制造缺陷图像分类的领域自适应方法**

*Adrian Poniatowski,Natalie Gentner,Manuel Barusco,Davide Dalle Pezze,Samuele Salti,Gian Antonio Susto*

主要分类: cs.CV

摘要简述: 本文研究了在半导体制造缺陷图像分类中应用领域自适应（DA）技术的有效性，提出了一种基于CycleGAN改进的DBACS方法，并在无监督和半监督设置下验证了其性能。


<details>
  <summary>详细信息</summary>
研究动机: 半导体行业对快速上市和高质量的需求日益增长，而深度学习在缺陷分类等工业应用中表现出色。领域自适应技术能够减少重新标注和训练的需求，降低成本并提高效率，因此在半导体领域具有重要应用价值。

研究方法: 本文提出了一种名为DBACS的改进模型，灵感来源于CycleGAN，并通过增加额外的损失项来提升性能。该方法在无监督和半监督设置下，使用真实的电子显微镜图像进行了验证。

研究结果: 实验证明，DBACS方法在半导体领域的缺陷分类任务中表现优异，显著提升了领域自适应技术的性能，同时减少了计算和资源成本。

研究结论: DBACS方法为半导体制造中的缺陷分类提供了一种高效且可扩展的解决方案，进一步推动了领域自适应技术在该领域的应用。

中文摘要: 在半导体行业，由于高需求和激烈的竞争，快速上市和产品质量成为确保市场份额的关键因素。近年来，深度学习在计算机视觉领域的成功为工业4.0和5.0应用（如缺陷分类）带来了显著进展。领域自适应（DA）技术因其能够利用源域知识适应目标域而表现出高效性，减少了重新标注和训练的需求，降低了成本并提升了效率。因此，本文在半导体领域的无监督和半监督设置下测试了DA技术的有效性，并提出了一种基于CycleGAN改进的DBACS方法，通过增加额外的损失项提升性能。所有方法均在真实的电子显微镜图像上进行了验证，证明了该方法在推动半导体领域DA技术发展中的实用性。

</details>


### [55] [GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction](https://arxiv.org/abs/2506.14825)
**中文标题：GraphGSOcc：基于3D高斯溅射的语义与几何图Transformer占据预测**

*Ke Song,Yunhe Wu,Chunchit Siu,Huiyuan Xiong*

主要分类: cs.CV

摘要简述: 本文提出GraphGSOcc模型，结合语义与几何图Transformer，解决3D高斯溅射方法在语义关联和边界模糊上的问题，显著提升自动驾驶场景的3D语义占据预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D高斯溅射方法存在两个主要问题：一是统一特征聚合忽略了相似类别和跨区域的语义关联；二是MLP迭代优化缺乏几何约束导致边界模糊。本文旨在解决这些问题。

研究方法: 提出GraphGSOcc模型，采用双高斯图注意力机制，动态构建几何图和语义图。几何图基于高斯位姿自适应计算KNN搜索半径，语义图通过余弦相似度保留高相关节点。结合多尺度图注意力框架，优化边界细节和对象级拓扑。

研究结果: 在SurroundOcc数据集上达到24.10%的mIoU，GPU内存降至6.1 GB，相比GaussianWorld提升1.97% mIoU并减少13.7%内存。

研究结论: GraphGSOcc通过语义与几何图Transformer有效解决了3D高斯溅射方法的局限性，显著提升了自动驾驶场景的3D语义占据预测性能。

中文摘要: 针对自动驾驶中的3D语义占据预测任务，本文解决了现有3D高斯溅射（3DGS）方法的两个关键问题：（1）统一特征聚合忽略了相似类别和跨区域的语义关联；（2）MLP迭代优化缺乏几何约束导致边界模糊。我们提出了GraphGSOcc模型，一种结合语义与几何图Transformer的新框架。通过双高斯图注意力机制，动态构建几何图和语义图：几何图基于高斯位姿自适应计算KNN搜索半径，使大尺度高斯能从更广邻域聚合特征，而紧凑高斯则关注局部几何一致性；语义图通过余弦相似度保留高相关节点，显式编码实例内和跨实例的语义关系。结合多尺度图注意力框架，低层细粒度注意力优化边界细节，高层粗粒度注意力建模对象级拓扑。在SurroundOcc数据集上的实验实现了24.10%的mIoU，GPU内存降至6.1 GB，相比GaussianWorld提升1.97% mIoU并减少13.7%内存。

</details>


### [56] [MSNeRV: Neural Video Representation with Multi-Scale Feature Fusion](https://arxiv.org/abs/2506.15276)
**中文标题：MSNeRV：基于多尺度特征融合的神经视频表示**

*Jun Zhu,Xinfeng Zhang,Lv Tang,JunHao Jiang*

主要分类: cs.CV

摘要简述: MSNeRV提出了一种多尺度特征融合框架，用于神经视频表示，解决了现有基于隐式神经表示（INR）方法在细节密集和快速变化视频内容上的不足，并在压缩效率上超越了VTM-23.7。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于INR的视频压缩方法在细节密集和快速变化内容上表现不佳，主要原因是网络内部特征利用不足和缺乏视频特定设计。MSNeRV旨在通过多尺度特征融合解决这些问题。

研究方法: MSNeRV采用时间窗口增强时间一致性，将视频分为多个图像组（GoP），并使用GoP级网格表示背景。设计了多尺度空间解码器和尺度自适应损失函数，并引入多尺度特征块以充分利用隐藏特征。

研究结果: 在HEVC ClassB和UVG数据集上的实验表明，MSNeRV在INR方法中表现出卓越的表示能力，并在动态场景中压缩效率上超越了VTM-23.7（随机访问模式）。

研究结论: MSNeRV通过多尺度特征融合显著提升了视频表示和压缩性能，为基于INR的视频压缩提供了新思路。

中文摘要: 隐式神经表示（INR）已成为视频压缩的一种有前景的方法，其性能已与H.266/VVC等先进编解码器相当。然而，现有的基于INR的方法在细节密集和快速变化的视频内容上表现不佳，主要原因是网络内部特征利用不足和缺乏视频特定设计。为解决这些问题，我们提出了一种多尺度特征融合框架MSNeRV，用于神经视频表示。在编码阶段，通过时间窗口增强时间一致性，并将视频分为多个图像组（GoP），其中GoP级网格用于背景表示。此外，我们设计了具有尺度自适应损失函数的多尺度空间解码器，以整合多分辨率和多频率信息。为进一步提升特征提取，我们引入了多尺度特征块以充分利用隐藏特征。我们在HEVC ClassB和UVG数据集上评估了MSNeRV的视频表示和压缩性能。实验结果表明，我们的模型在INR方法中表现出卓越的表示能力，并在动态场景中压缩效率上超越了VTM-23.7（随机访问模式）。

</details>


### [57] [BCRNet: Enhancing Landmark Detection in Laparoscopic Liver Surgery via Bezier Curve Refinement](https://arxiv.org/abs/2506.15279)
**中文标题：BCRNet：通过贝塞尔曲线优化增强腹腔镜肝脏手术中的标志检测**

*Qian Li,Feng Liu,Shuojue Yang,Daiyun Shen,Yueming Jin*

主要分类: cs.CV

摘要简述: BCRNet通过贝塞尔曲线优化策略显著提升腹腔镜肝脏手术中的关键解剖标志检测精度，结合多模态特征提取和分层曲线优化机制，在L3D和P2ILF数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 腹腔镜肝脏手术中，准确识别弯曲解剖标志对增强现实导航系统至关重要。现有方法在检测精度上存在不足，因此提出BCRNet以优化这一问题。

研究方法: BCRNet包含多模态特征提取模块（MFE）以捕获语义特征，自适应曲线提案初始化（ACPI）生成像素对齐的贝塞尔曲线，并通过分层曲线优化（HCR）机制多阶段迭代优化曲线。

研究结果: 在L3D和P2ILF数据集上的实验表明，BCRNet显著优于现有方法，性能提升明显。

研究结论: BCRNet通过贝塞尔曲线优化和多模态特征提取，显著提升了腹腔镜肝脏手术中的标志检测精度，为手术导航提供了可靠支持。

中文摘要: 腹腔镜肝脏手术虽微创，但准确识别关键解剖结构仍具挑战。基于MRI/CT与腹腔镜图像的增强现实（AR）系统通过2D-3D配准为手术导航提供了解决方案，而配准过程中的关键是对腹腔镜图像中弯曲解剖标志的精确检测。本文提出BCRNet（贝塞尔曲线优化网络），通过贝塞尔曲线优化策略显著提升标志检测精度。框架包含多模态特征提取模块（MFE）以捕获语义特征，自适应曲线提案初始化（ACPI）生成像素对齐的贝塞尔曲线和置信度评分，并通过分层曲线优化（HCR）机制多阶段迭代优化提案。在L3D和P2ILF数据集上的广泛实验表明，BCRNet优于现有方法，性能显著提升。代码将公开。

</details>


### [58] [DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning](https://arxiv.org/abs/2506.14827)
**中文标题：DAVID-XR1：基于可解释推理的AI生成视频检测**

*Yifeng Gao,Yifan Ding,Hongyu Su,Juncheng Li,Yunhan Zhao,Lin Luo,Zixing Chen,Li Wang,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang*

主要分类: cs.CV

摘要简述: 本文提出DAVID-XR1，一种可解释的AI生成视频检测方法，通过结合缺陷级时空标注和自然语言解释，将检测过程透明化。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI生成视频在媒体平台上的普及，现有方法仅提供二分类结果，缺乏对检测原因和位置的解释。本文旨在填补这一空白，提供细粒度、可验证的证据。

研究方法: 提出DAVID-X数据集，包含AI生成视频的缺陷级时空标注和文字解释。基于此，开发DAVID-XR1模型，通过视觉推理链（缺陷分类、时空定位和自然语言解释）实现透明检测。

研究结果: 实验表明，通用骨干网络在DAVID-X数据集上微调后，结合思维链蒸馏，能泛化到多种生成器和生成模式，效果显著。

研究结论: DAVID-XR1将AI生成视频检测从黑盒决策转变为透明诊断过程，为可信检测提供了新思路。

中文摘要: 随着AI生成视频在媒体平台上的广泛传播，可靠区分合成内容与真实视频变得迫切且重要。现有方法主要将其视为二分类任务，对模型判断AI生成视频的原因和位置缺乏解释。然而，核心挑战不仅是检测细微伪影，还需提供细粒度、有说服力的证据以说服审计者和用户。为此，我们提出DAVID-X，首个包含AI生成视频的缺陷级时空标注和文字解释的数据集。基于这些丰富标注，我们开发了DAVID-XR1，一种视频-语言模型，可提供可解释的视觉推理链，包括缺陷分类、时空定位和自然语言解释。该方法将AI生成视频检测从黑盒决策转变为透明可验证的诊断过程。实验表明，通用骨干网络在我们的紧凑数据集上微调并结合思维链蒸馏，能泛化到多种生成器和生成模式。结果凸显了可解释检测方法在可信识别AI生成视频内容中的潜力。

</details>


### [59] [AI-driven visual monitoring of industrial assembly tasks](https://arxiv.org/abs/2506.15285)
**中文标题：AI驱动的工业装配任务视觉监控**

*Mattia Nardon,Stefano Messelodi,Antonio Granata,Fabio Poiesi,Alberto Danese,Davide Boscaini*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViMAT的AI驱动系统，用于实时视觉监控工业装配任务，无需刚性工作空间设置或视觉标记。ViMAT通过多视角视频流提取视觉观察，并结合推理模块推断最可能的操作，验证了其在挑战性场景中的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 工业装配任务的视觉监控对预防设备损坏和保障工人安全至关重要。现有商业解决方案通常需要刚性工作空间设置或视觉标记，限制了其应用。本文旨在开发一种无需这些约束的实时监控系统。

研究方法: ViMAT系统结合了感知模块和推理模块。感知模块从多视角视频流中提取视觉观察，推理模块基于观察到的装配状态和先验任务知识推断最可能的操作。系统在LEGO组件更换和液压机模具重新配置任务中进行了验证。

研究结果: ViMAT在部分和不确定视觉观察的挑战性场景中表现出色，通过定量和定性分析验证了其有效性。

研究结论: ViMAT为工业装配任务的实时视觉监控提供了一种灵活且高效的解决方案，无需依赖刚性设置或视觉标记，具有广泛的应用潜力。

中文摘要: 工业装配任务的视觉监控对预防因程序错误导致的设备损坏和保障工人安全至关重要。尽管已有商业解决方案，但它们通常需要刚性工作空间设置或应用视觉标记以简化问题。我们提出了ViMAT，一种无需这些约束的新型AI驱动系统，用于实时视觉监控装配任务。ViMAT结合了从多视角视频流中提取视觉观察的感知模块，以及基于观察到的装配状态和先验任务知识推断最可能操作的推理模块。我们在两个装配任务（LEGO组件更换和液压机模具重新配置）上验证了ViMAT，通过定量和定性分析证明了其在部分和不确定视觉观察的挑战性场景中的有效性。项目页面：https://tev-fbk.github.io/ViMAT

</details>


### [60] [MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering](https://arxiv.org/abs/2506.15298)
**中文标题：MEGC2025：微表情大挑战——先定位后识别与视觉问答**

*Xinqi Fan,Jingting Li,John See,Moi Hoon Yap,Wen-Huang Cheng,Xiaobai Li,Xiaopeng Hong,Su-Jing Wang,Adrian K. Davision*

主要分类: cs.CV

摘要简述: MEGC2025挑战赛聚焦微表情的‘先定位后识别’和视觉问答任务，旨在通过多模态大模型提升微表情分析的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法将微表情的定位与识别分开处理，效率低下，尤其在长视频分析中表现不佳。多模态大语言模型的出现为微表情分析提供了新思路。

研究方法: MEGC2025提出两项任务：1) ME-STR，将微表情定位与识别整合为统一流程；2) ME-VQA，利用多模态大模型通过视觉问答理解微表情。

研究结果: 参赛算法需在测试集上运行并提交结果，排行榜将展示性能表现。

研究结论: MEGC2025通过创新任务设计推动微表情分析技术的发展，为多模态模型在微表情领域的应用开辟新方向。

中文摘要: 面部微表情（MEs）是人在试图抑制情绪时面部产生的无意识动作，常见于高风险环境。近年来，微表情的识别、定位和生成领域取得了显著进展。然而，传统方法将定位与识别分开处理，效率低下，尤其在实际场景的长视频分析中表现不佳。同时，多模态大语言模型（MLLMs）和大视觉语言模型（LVLMs）的出现为微表情分析提供了新的可能性。MEGC2025挑战赛引入两项任务：1) ME-STR，将微表情定位与识别整合为统一流程；2) ME-VQA，通过视觉问答探索微表情理解，利用MLLMs或LVLMs处理多样化的微表情相关问题。所有参赛算法需在测试集上运行并提交结果至排行榜。详情请访问https://megc2025.github.io。

</details>


### [61] [MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning](https://arxiv.org/abs/2506.15313)
**中文标题：MapFM：基于基础模型的多任务上下文学习高清地图生成方法**

*Leonid Ivanov,Vasily Yuryev,Dmitry Yudin*

主要分类: cs.CV

摘要简述: MapFM是一种基于基础模型的端到端模型，用于在线生成矢量化的高清地图，通过多任务上下文学习提升特征表示质量和预测精度。


<details>
  <summary>详细信息</summary>
研究动机: 在自动驾驶中，高清地图和鸟瞰视角的语义地图对精确定位、规划和决策至关重要。现有方法在特征表示和预测质量上仍有提升空间，因此提出MapFM以增强模型的环境理解能力。

研究方法: MapFM利用强大的基础模型编码相机图像，提升特征表示质量；同时引入辅助预测头进行鸟瞰视角的语义分割，通过多任务学习提供更丰富的上下文监督。

研究结果: 实验表明，MapFM能够生成更全面的场景表示，显著提高矢量高清地图的预测精度和质量。

研究结论: MapFM通过结合基础模型和多任务学习，有效提升了高清地图生成的准确性和质量，为自动驾驶提供了更可靠的环境感知工具。

中文摘要: 在自动驾驶中，高清地图（HD地图）和鸟瞰视角（BEV）的语义地图对于精确定位、规划和决策至关重要。本文提出了一种名为MapFM的增强型端到端模型，用于在线生成矢量化的高清地图。通过结合强大的基础模型对相机图像进行编码，显著提升了特征表示的质量。为了进一步丰富模型对环境的理解并提高预测质量，我们在BEV表示中集成了语义分割的辅助预测头。这种多任务学习方法提供了更丰富的上下文监督，从而实现了更全面的场景表示，最终提高了预测的矢量高清地图的准确性和质量。源代码可在https://github.com/LIvanoff/MapFM获取。

</details>


### [62] [ArchShapeNet:An Interpretable 3D-CNN Framework for Evaluating Architectural Shapes](https://arxiv.org/abs/2506.14832)
**中文标题：ArchShapeNet：一种用于评估建筑形状的可解释3D-CNN框架**

*Jun Yin,Jing Zhong,Pengyu Zeng,Peilin Li,Zixuan Dai,Miao Zhang,Shuai Lu*

主要分类: cs.CV

摘要简述: 本文提出ArchShapeNet，一种用于分析和分类建筑形状的3D-CNN框架，结合显著性模块突出关键空间特征，实验表明其性能优于人类专家。


<details>
  <summary>详细信息</summary>
研究动机: 当前建筑设计需求日益复杂多样，生成式工具虽能快速生成初始概念，但缺乏对人工设计与机器生成3D形状差异的客观分析，阻碍了生成工具的进步。

研究方法: 构建ArchForms-4000数据集（含2000个人工设计和2000个Evomass生成的3D形状），提出ArchShapeNet框架，结合显著性模块分析建筑形状，并进行对比实验。

研究结果: ArchShapeNet在区分形状来源上表现优异，准确率达94.29%，精确率96.2%，召回率98.51%，优于人类专家。

研究结论: 研究揭示了人工设计在空间组织、比例和谐及细节优化上的独特优势，为未来生成式设计工具的改进提供了重要参考。

中文摘要: 在当代建筑设计中，设计需求的日益复杂和多样化使得生成式插件工具成为快速生成初始概念和探索新颖3D形式的重要手段。然而，客观分析人工设计与机器生成3D形式之间的差异仍是一个挑战，限制了对各自优势的理解，并阻碍了生成工具的进步。为解决这一问题，我们构建了ArchForms-4000数据集，包含2000个建筑师设计和2000个Evomass生成的3D形式；提出了ArchShapeNet，一种专为分类和分析建筑形式定制的3D卷积神经网络，结合显著性模块突出与建筑推理一致的关键空间特征；并通过对比实验表明，我们的模型在区分形式来源上优于人类专家，准确率达94.29%，精确率96.2%，召回率98.51%。本研究不仅揭示了人工设计形式在空间组织、比例和谐及细节优化上的独特优势，还为未来生成式设计工具的改进提供了宝贵见解。

</details>


### [63] [OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models](https://arxiv.org/abs/2506.15318)
**中文标题：OpenPath：基于预训练视觉语言模型的病理图像分类开集主动学习**

*Lanfeng Zhong,Xin Liao,Shichuan Zhang,Shaoting Zhang,Guotai Wang*

主要分类: cs.CV

摘要简述: OpenPath提出了一种基于预训练视觉语言模型的开集主动学习方法，用于病理图像分类，通过任务特定提示和多样性信息采样策略，有效减少标注成本并提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 病理图像分类在医学诊断中至关重要，但传统主动学习方法假设未标注数据均属于目标类别，而实际临床环境中存在大量分布外数据，导致标注效率低下。OpenPath旨在解决这一问题。

研究方法: OpenPath利用预训练视觉语言模型，首轮查询使用任务特定提示筛选分布内样本，后续查询通过原型候选选择和熵引导随机采样确保样本纯度和信息量。

研究结果: 在两个公开病理图像数据集上的实验表明，OpenPath显著提升了模型性能，并优于其他开集主动学习方法。

研究结论: OpenPath通过高效筛选分布内样本和多样性采样策略，显著提升了病理图像分类的标注效率和模型性能。

中文摘要: 病理图像分类在医学诊断和治疗规划中具有重要作用。训练高性能模型通常需要大规模标注数据集，但获取这些数据成本高昂且耗时。主动学习（AL）通过迭代选择信息量最大的样本进行标注，从而减少标注工作量。然而，大多数AL方法基于闭集假设设计，即所有未标注图像均属于目标类别。在实际临床环境中，未标注池通常包含大量分布外（OOD）数据，导致传统AL方法的标注效率低下。此外，大多数现有AL方法在首轮查询中随机选择样本，造成开集场景下标注成本的巨大浪费。为解决这些问题，我们提出了OpenPath，一种基于预训练视觉语言模型（VLM）的开集主动学习方法。在首轮查询中，我们提出任务特定提示，结合目标和非目标类别提示，从未标注池中有效筛选分布内（ID）和信息量大的样本。在后续查询中，我们提出多样性信息ID采样（DIS），包括基于原型的ID候选选择（PIS）和熵引导随机采样（EGSS），以确保查询的纯度和信息量，避免选择OOD样本。在两个公开病理图像数据集上的实验表明，OpenPath因其高纯度的样本选择显著提升了模型性能，并优于多种先进的开集AL方法。代码发布于\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}。

</details>


### [64] [Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices](https://arxiv.org/abs/2506.14833)
**中文标题：基于熵的自适应缓冲和MobileNetV2的边缘设备实时低延迟监控系统**

*Poojashree Chandrashekar Pankaj M Sajjanar*

主要分类: cs.CV

摘要简述: 本文提出了一种基于熵的自适应帧缓冲算法，结合MobileNetV2，在资源受限的边缘设备上实现了高性能、低延迟的视频监控系统，端到端推理延迟低于50毫秒，检测准确率超过92%。


<details>
  <summary>详细信息</summary>
研究动机: 针对资源受限环境下的视频监控需求，设计一种能够在边缘设备上实现低延迟、高性能的监控系统，同时满足数据隐私和成本效益要求。

研究方法: 提出了一种基于熵的自适应帧缓冲算法，并与轻量级模型MobileNetV2结合，优化了视频流的实时处理能力。系统在树莓派、亚马逊和NVIDIA Jetson Nano等设备上进行了验证。

研究结果: 系统在标准视频监控数据集上实现了超过92%的检测准确率，端到端推理延迟低于50毫秒，且对光照、背景和速度变化具有鲁棒性。

研究结论: 该系统具有高性能、低延迟、低成本的特点，适用于智能城市和嵌入式安全架构，同时满足严格的数据隐私法规。

中文摘要: 本文描述了一种专为资源受限环境设计的高性能、低延迟视频监控系统。我们提出了一种基于熵的自适应帧缓冲算法，并将其与MobileNetV2结合，实现了高吞吐量和低延迟。该系统能够在树莓派、亚马逊和NVIDIA Jetson Nano等资源受限设备（嵌入式平台）上以低于50毫秒的端到端推理延迟处理实时视频流。我们的方法在标准视频监控数据集上保持了超过92%的检测准确率，并对光照、背景和速度变化表现出鲁棒性。多项对比和消融实验验证了设计的有效性。最后，我们的架构具有可扩展性、低成本，并且符合比普通监控系统更严格的数据隐私法规，因此该系统可以应用于智能城市或嵌入式安全架构。

</details>


### [65] [Open-World Object Counting in Videos](https://arxiv.org/abs/2506.15368)
**中文标题：视频中的开放世界目标计数**

*Niki Amini-Naieni,Andrew Zisserman*

主要分类: cs.CV

摘要简述: 本文提出了一种新的视频开放世界目标计数任务，通过文本描述或图像示例指定目标对象，统计视频中所有独特实例。为解决拥挤场景中的遮挡和相似对象问题，作者提出了CountVid模型，结合图像计数和视频分割跟踪技术，并在新数据集VideoCount上验证了其优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 在拥挤场景中，视频目标计数面临遮挡和相似对象的挑战，传统方法难以避免重复计数和识别重现对象。因此，本文提出开放世界目标计数任务，旨在通过灵活输入（文本或图像）统计视频中独特实例，填补现有研究空白。

研究方法: 作者提出CountVid模型，结合图像计数模型和可提示视频分割跟踪模型，实现跨帧自动计数。模型利用TAO、MOT20及企鹅、金属合金结晶X射线视频构建的VideoCount数据集进行训练和评估。

研究结果: 实验表明，CountVid在VideoCount数据集上表现优异，准确统计目标数量，显著优于基线方法。

研究结论: CountVid为开放世界视频目标计数提供了有效解决方案，其性能在新数据集上得到验证，相关代码和数据已开源。

中文摘要: 本文提出了一种新的视频开放世界目标计数任务：给定描述目标对象的文本或图像示例，目标是统计视频中所有独特的目标实例。这一任务在拥挤场景中尤为挑战，需避免重复计数和识别重现对象。为此，我们提出CountVid模型，结合图像计数模型和可提示视频分割跟踪模型，实现跨帧自动计数。为评估性能，我们基于TAO、MOT20及企鹅、金属合金结晶X射线视频构建了VideoCount数据集。实验表明，CountVid能准确统计目标数量，显著优于基线方法。数据集、模型及代码已开源：https://github.com/niki-amini-naieni/CountVid/。

</details>


### [66] [Unsupervised Pelage Pattern Unwrapping for Animal Re-identification](https://arxiv.org/abs/2506.15369)
**中文标题：无监督动物皮毛图案解包用于再识别**

*Aleksandr Algasov,Ekaterina Nepovinnykh,Fedor Zolotarev,Tuomas Eerola,Heikki Kälviäinen,Pavel Zemčík,Charles V. Stewart*

主要分类: cs.CV

摘要简述: 本文提出一种几何感知的纹理映射方法，将动物皮毛图案解包到规范UV空间，提升变形图案的再识别准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有动物再识别方法难以处理因身体运动和姿态变化导致的皮毛图案几何变形问题。

研究方法: 通过表面法线估计引导解包过程，保持3D表面与2D纹理空间的几何一致性，无需标注数据，支持自监督训练。

研究结果: 在环斑海豹和豹子数据集上，再识别准确率提升高达5.4%。

研究结论: 该方法有效解决了变形图案的再识别挑战，适用于多种姿态和视角。

中文摘要: 现有的个体再识别方法常因动物皮毛或皮肤图案的几何变形（由身体运动和姿态变化引起）而效果不佳。本文提出一种几何感知的纹理映射方法，将独特的皮毛图案解包到规范的UV空间，从而实现更鲁棒的特征匹配。我们的方法利用表面法线估计指导解包过程，同时保持3D表面与2D纹理空间的几何一致性。研究聚焦于两种具有挑战性的物种：赛马环斑海豹（Pusa hispida saimensis）和豹子（Panthera pardus），它们的皮毛图案独特且易变形。通过将图案保留的UV映射与现有再识别技术结合，我们在多样姿态和视角下展示了更高的准确性。该框架无需标注的UV数据，支持自监督训练。在环斑海豹和豹子数据集上的实验表明，再识别准确率最高提升5.4%。

</details>


### [67] [Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction](https://arxiv.org/abs/2506.14837)
**中文标题：通过结构化指令改进图表到代码生成的迭代优化方法**

*Chengzhi Xu,Yuyang Wang,Lai Wei,Lichao Sun,Weiran Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于结构化指令的迭代优化方法ChartIR，用于提升多模态大语言模型在图表到代码生成任务中的表现，通过分解任务为视觉理解和代码翻译，并结合描述和差异指令，显著提高了生成代码的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型在图表到代码生成任务中表现不佳，主要由于直接提示模型完成复杂任务效果不理想。因此，需要一种方法将视觉特征转化为语言表示，并逐步优化生成代码。

研究方法: 提出ChartIR方法，将任务分解为视觉理解和代码翻译两部分。设计描述指令和差异指令，分别捕捉参考图表的视觉元素和生成图表与参考图表的差异。通过初始代码生成和迭代优化两阶段提升最终输出。

研究结果: 实验结果表明，ChartIR在开源模型Qwen2-VL和闭源模型GPT-4o上均优于其他方法，显著提高了图表到代码生成的性能。

研究结论: ChartIR通过结构化指令和迭代优化，有效提升了多模态大语言模型在图表到代码生成任务中的表现，为复杂视觉任务的解决提供了新思路。

中文摘要: 近年来，多模态大语言模型（MLLMs）因其强大的视觉理解能力受到广泛关注。尽管在多种视觉任务中表现优异，但它们在图表到代码生成任务中的表现仍不理想。该任务要求MLLMs生成可执行代码以复现给定图表，不仅需要精确的视觉理解，还需将视觉元素准确转化为结构化代码。直接提示MLLMs完成这一复杂任务往往效果不佳。为解决这一问题，我们提出了基于结构化指令的迭代优化方法ChartIR。首先，我们将任务分为视觉理解和代码翻译两部分。为完成视觉理解，设计了描述指令和差异指令：描述指令捕捉参考图表的视觉元素，差异指令表征参考图表与生成图表之间的差异。这些指令将视觉特征转化为语言表示，从而促进后续代码翻译过程。其次，我们将整体图表生成流程分解为初始代码生成和迭代优化两阶段，逐步提升最终输出。实验结果表明，与其他方法相比，我们的方法在开源模型Qwen2-VL和闭源模型GPT-4o上均取得了更优的性能。

</details>


### [68] [When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class](https://arxiv.org/abs/2506.15381)
**中文标题：当模型知识遇上扩散模型：基于领域与类对齐的扩散辅助无数据图像合成**

*Yujin Kim,Hyunsoo Kim,Hyunwoo J. Kim,Suhyun Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DDIS的扩散辅助无数据图像合成方法，利用文本到图像扩散模型作为先验知识，通过领域对齐指导和类对齐标记优化，生成更接近训练数据分布的图像，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 开源预训练模型在训练数据不可用时实用性下降。现有的无数据图像合成方法因缺乏自然图像先验知识，生成的样本偏离训练数据分布。本文旨在通过扩散模型提升合成图像质量。

研究方法: DDIS方法结合文本到图像扩散模型作为先验知识，通过领域对齐指导（DAG）在扩散采样过程中对齐合成数据与训练数据领域，并优化类对齐标记（CAT）嵌入以捕捉类特定属性。

研究结果: 在PACS和ImageNet上的实验表明，DDIS生成的样本更准确地反映训练数据分布，在无数据应用中达到SOTA性能。

研究结论: DDIS通过扩散模型和领域对齐技术，显著提升了无数据图像合成的质量，为数据不可用场景提供了有效解决方案。

中文摘要: 开源预训练模型具有广泛的应用潜力，但当其训练数据不可用时，其实用性会下降。无数据图像合成（DFIS）旨在无需访问原始数据的情况下生成近似预训练模型学习数据分布的图像。然而，现有DFIS方法因缺乏自然图像先验知识，生成的样本偏离训练数据分布。为克服这一限制，我们提出了DDIS，首个利用文本到图像扩散模型作为强大图像先验的扩散辅助无数据图像合成方法，显著提升合成图像质量。DDIS从给定模型中提取学习分布的知识，并用于指导扩散模型，生成与训练数据分布准确对齐的图像。为此，我们引入了领域对齐指导（DAG），在扩散采样过程中对齐合成数据与训练数据领域。此外，我们优化了单一类对齐标记（CAT）嵌入，以有效捕捉训练数据集中的类特定属性。在PACS和ImageNet上的实验表明，DDIS优于现有DFIS方法，生成的样本更准确地反映训练数据分布，在无数据应用中达到SOTA性能。

</details>


### [69] [PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers](https://arxiv.org/abs/2506.14842)
**中文标题：PictSure：预训练嵌入对上下文学习图像分类器至关重要**

*Lukas Schiesser,Cornelius Wolff,Sophie Haas,Simon Pukrop*

主要分类: cs.CV

摘要简述: PictSure是一个专注于图像嵌入模型预训练的ICL框架，通过系统分析视觉编码器类型、预训练目标和微调策略，显著提升了少样本图像分类的跨域性能。


<details>
  <summary>详细信息</summary>
研究动机: 在数据稀缺领域构建图像分类模型具有挑战性，现有ICL方法忽视了图像嵌入模型的关键作用。PictSure旨在通过优化嵌入模型的预训练提升少样本分类性能。

研究方法: PictSure系统研究了视觉编码器类型、预训练目标和微调策略对少样本图像分类的影响，将嵌入模型置于分析核心。

研究结果: 实验表明，嵌入模型的预训练方式显著影响训练成功率和跨域性能，PictSure在跨域任务上优于现有ICL模型，同时保持域内任务性能。

研究结论: PictSure证明了嵌入模型预训练对ICL框架的重要性，为少样本图像分类提供了更优的跨域解决方案。

中文摘要: 在数据稀缺领域构建图像分类模型仍然困难，因为收集大规模标注数据集不切实际。上下文学习（ICL）已成为少样本图像分类（FSIC）的有前景范式，使模型无需基于梯度的适应即可跨域泛化。然而，先前研究大多忽视了ICL-based FSIC流程中的关键组成部分：图像嵌入的作用。本文提出PictSure，一个将嵌入模型（其架构、预训练和训练动态）置于分析核心的ICL框架。我们系统研究了不同视觉编码器类型、预训练目标和微调策略对下游FSIC性能的影响。实验表明，训练成功率和跨域性能高度依赖于嵌入模型的预训练方式。因此，PictSure在显著不同于训练分布的跨域基准测试中优于现有ICL-based FSIC模型，同时在域内任务上保持可比结果。代码见https://github.com/PictSure/pictsure-library。

</details>


### [70] [NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance](https://arxiv.org/abs/2506.15404)
**中文标题：NERO：基于神经元级相关性的可解释性分布外检测**

*Anju Chhetri,Jari Korhonen,Prashnna Gyawali,Binod Bhattarai*

主要分类: cs.CV

摘要简述: 论文提出了一种名为NERO的新型OOD检测方法，通过神经元级相关性增强OOD样本的可分离性，并在医学影像基准测试中表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在医学影像领域，确保深度学习模型的可靠性至关重要。现有OOD检测方法可能无法完全捕捉OOD样本的多样性，因此需要一种更有效的检测机制。

研究方法: NERO利用特征层的神经元级相关性，为每个分布内类别聚类形成代表性中心，并通过相关性距离度量新样本与这些中心的偏差。此外，通过引入缩放相关性和特征范数组合进一步优化性能。

研究结果: 在Kvasir和GastroVision等医学影像基准测试中，NERO在多种深度学习架构上表现优异，优于当前最先进的OOD检测方法。

研究结论: NERO不仅提升了OOD检测的性能，还实现了可解释的检测，为医学影像领域的模型可靠性提供了有力支持。

中文摘要: 在深度学习中，尤其是在医学影像领域，确保模型的可靠性至关重要，因为诊断决策往往依赖于模型输出。分布外（OOD）样本的分离能力已被证明是评估模型可靠性的重要指标。在医学影像中，识别OOD输入尤为重要，因为它可以帮助标记潜在异常。尽管许多OOD检测方法依赖于特征或逻辑空间表示，但近期研究表明这些方法可能无法完全捕捉OOD的多样性。为此，我们提出了一种名为NERO的新型OOD评分机制，利用特征层的神经元级相关性。具体而言，我们为每个分布内（ID）类别的神经元级相关性进行聚类以形成代表性中心，并引入相关性距离度量来量化新样本与这些中心的偏差，从而增强OOD的可分离性。此外，我们通过引入缩放相关性和特征范数组合进一步优化性能。该框架还支持可解释的OOD检测。我们在Kvasir和GastroVision等医学影像基准测试中验证了其有效性，结果表明NERO在多种深度学习架构上优于当前最先进的OOD检测方法。

</details>


### [71] [Finding Optimal Kernel Size and Dimension in Convolutional Neural Networks An Architecture Optimization Approach](https://arxiv.org/abs/2506.14846)
**中文标题：卷积神经网络中核大小和维度的优化：一种架构优化方法**

*Shreyas Rajeev,B Sathish Babu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于数学和实验验证的框架BKSEF，用于优化卷积神经网络中逐层的核大小选择，平衡信息增益、计算效率和准确性提升。实验表明，该方法在多个数据集上显著提升模型性能并降低计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 卷积神经网络中核大小的选择通常被忽视，但其对感受野、特征提取、计算成本和模型准确性有重要影响。本文旨在通过优化核大小选择，提升CNN的性能和效率。

研究方法: 提出了最佳核大小估计函数（BKSEF），结合信息论、信号处理和学习理论，逐层确定最优核大小。通过实验验证其在多个数据集上的有效性。

研究结果: 在CIFAR-10、CIFAR-100、ImageNet-lite等数据集上，BKSEF引导的架构相比传统3x3核模型，准确率提升3.1%，计算量减少42.8%。实际案例中，医疗图像分类和交通标志识别任务均取得显著改进。

研究结论: BKSEF证明核大小可作为可优化参数，而非固定启发式方法，为高效且应用感知的CNN设计提供了理论和实践支持。

中文摘要: 卷积神经网络（CNN）中核大小的选择是一个关键但常被忽视的设计决策，它影响感受野、特征提取、计算成本和模型准确性。本文提出了最佳核大小估计函数（BKSEF），这是一个基于数学和实验验证的框架，用于逐层确定最优核大小。BKSEF通过整合信息论、信号处理和学习理论的原理，平衡信息增益、计算效率和准确性提升。在CIFAR-10、CIFAR-100、ImageNet-lite、ChestX-ray14和GTSRB数据集上的大量实验表明，BKSEF引导的架构相比传统使用统一3x3核的模型，准确率提升高达3.1%，计算量减少42.8%。两个实际案例进一步验证了该方法：一个用于基于云的医疗图像分类，另一个用于边缘设备上的交通标志识别。前者提升了可解释性和准确性，后者显著降低了延迟和模型大小，且准确性损失极小。这些结果表明，核大小可以是一个主动可优化的参数，而非固定启发式方法。BKSEF为寻求高效且应用感知的CNN设计的研究人员和开发者提供了实用启发和理论支持。它适合集成到神经架构搜索流程和实时系统中，为CNN优化提供了新视角。

</details>


### [72] [Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material](https://arxiv.org/abs/2506.15442)
**中文标题：Hunyuan3D 2.1：从图像到高保真3D资产，具备生产级PBR材质**

*Team Hunyuan3D,Shuhui Yang,Mingxin Yang,Yifei Feng,Xin Huang,Sheng Zhang,Zebin He,Di Luo,Haolin Liu,Yunfei Zhao,Qingxiang Lin,Zeqiang Lai,Xianghui Yang,Huiwen Shi,Zibo Zhao,Bowen Zhang,Hongyu Yan,Lifu Wang,Sicong Liu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Yulin Cai,Jiaao Yu,Yixuan Tang,Dongyuan Guo,Junlin Yu,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Shida Wei,Chao Zhang,Yonghao Tan,Yifu Sun,Lin Niu,Shirui Huang,Bojian Zheng,Shu Liu,Shilin Chen,Xiang Yuan,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Jingwei Huang,Chunchao Guo*

主要分类: cs.CV

摘要简述: 本文介绍了Hunyuan3D 2.1系统，通过图像生成高保真3D资产，并提供生产级PBR材质。教程详细指导数据处理、模型训练及性能评估，适用于游戏、虚拟现实和工业设计。


<details>
  <summary>详细信息</summary>
研究动机: 3D AI生成内容（AIGC）领域虽发展迅速，但因数据收集、处理和模型训练的复杂性，仍主要面向研究人员和开发者。本文旨在通过Hunyuan3D 2.1系统，降低3D生成技术的门槛，提供实用教程。

研究方法: Hunyuan3D 2.1系统包含Hunyuan3D-DiT（形状生成）和Hunyuan3D-Paint（纹理合成）两大核心组件。教程涵盖数据准备、模型架构、训练策略、评估指标及部署流程。

研究结果: Hunyuan3D 2.1能够生成高分辨率、带纹理的3D资产，适用于多种应用场景。教程提供了完整的实践指南，帮助用户掌握3D生成模型的开发与优化。

研究结论: 通过本教程，用户可以学习如何利用Hunyuan3D 2.1系统开发或优化3D生成模型，为游戏、虚拟现实和工业设计等领域提供高效解决方案。

中文摘要: 3D AI生成内容（AIGC）是一个快速发展的领域，显著加速了游戏、电影和设计中的3D模型创建。尽管已有多个突破性模型革新了3D生成技术，但由于数据收集、处理和模型训练的复杂性，该领域仍主要面向研究人员、开发者和设计师。为解决这些问题，本文以Hunyuan3D 2.1为例，提供了一份全面的教程，逐步指导3D数据处理、生成模型训练及性能评估。Hunyuan3D 2.1是一个先进系统，用于生成高分辨率、带纹理的3D资产，其核心组件包括Hunyuan3D-DiT（形状生成）和Hunyuan3D-Paint（纹理合成）。教程将探索整个工作流程，包括数据准备、模型架构、训练策略、评估指标和部署。通过本教程，您将掌握如何优化或开发适用于游戏、虚拟现实和工业设计的强大3D生成模型。

</details>


### [73] [Multimodal Large Language Models for Medical Report Generation via Customized Prompt Tuning](https://arxiv.org/abs/2506.15477)
**中文标题：基于定制化提示调优的多模态大语言模型用于医学报告生成**

*Chunlei Li,Jingyang Hou,Yilei Shi,Jingliang Hu,Xiao Xiang Zhu,Lichao Mou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MRG-LLM的多模态大语言模型，通过定制化提示调优技术，结合冻结的大语言模型和可学习的视觉编码器，动态生成针对单个医学图像的实例特定提示，显著提升了医学报告生成的性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像报告生成在临床实践中仍具挑战性。尽管大语言模型（LLMs）在此领域展现出潜力，但其与医学影像数据的有效结合仍需深入探索。本文旨在通过多模态大语言模型和定制化提示机制解决这一问题。

研究方法: MRG-LLM结合了冻结的大语言模型和可学习的视觉编码器，并引入动态提示定制机制。通过基于视觉特征的仿射变换生成实例特定提示，提出了提示级和提示簿级两种定制实现方式，以实现精准的医学报告生成。

研究结果: 在IU X-ray和MIMIC-CXR数据集上的广泛实验表明，MRG-LLM在医学报告生成任务中达到了最先进的性能。

研究结论: MRG-LLM通过定制化提示调优和多模态结合，显著提升了医学报告生成的准确性和针对性，为临床实践提供了有力工具。

中文摘要: 医学影像数据的报告生成在临床实践中仍是一项具有挑战性的任务。尽管大语言模型（LLMs）在解决这一问题上展现出巨大潜力，但其与医学影像数据的有效结合仍需深入探索。本文提出了一种名为MRG-LLM的新型多模态大语言模型（MLLM），它将冻结的大语言模型与可学习的视觉编码器相结合，并引入了动态提示定制机制。我们的核心创新在于通过基于视觉特征的仿射变换生成针对单个医学图像的实例特定提示。我们提出了两种实现方式：提示级和提示簿级定制，以实现精准且有针对性的报告生成。在IU X-ray和MIMIC-CXR数据集上的大量实验表明，MRG-LLM在医学报告生成任务中达到了最先进的性能。我们的代码将公开提供。

</details>


### [74] [GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects](https://arxiv.org/abs/2506.15483)
**中文标题：GenHOI：针对未见物体的文本驱动4D人-物交互合成的泛化方法**

*Shujia Li,Haiyu Zhang,Xinyuan Chen,Yaohui Wang,Yutong Ban*

主要分类: cs.CV

摘要简述: GenHOI提出了一种两阶段框架，通过Object-AnchorNet和Contact-Aware Diffusion Model实现对新物体的4D人-物交互合成，减少对大规模4D数据集的依赖，并在实验中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本驱动的人体运动合成虽因扩散模型和大规模运动数据集取得进展，但扩展到4D人-物交互（HOI）仍面临挑战，主要由于缺乏大规模4D HOI数据集。GenHOI旨在解决这一问题，实现对新物体的泛化和高质量4D HOI序列合成。

研究方法: GenHOI采用两阶段框架：1）使用Object-AnchorNet从3D HOI数据集中学习，为新物体重建稀疏3D HOI关键帧；2）通过Contact-Aware Diffusion Model（ContactDM）插值关键帧为密集4D HOI序列，并引入Contact-Aware Encoder和HOI Attention提升生成质量。

研究结果: 在OMOMO和3D-FUTURE数据集上的实验表明，GenHOI实现了最先进的性能，展现出对新物体的强泛化能力，并能生成高质量的4D HOI序列。

研究结论: GenHOI通过两阶段框架和创新的接触感知技术，成功实现了对新物体的4D HOI合成，减少了对大规模4D数据集的依赖，为相关领域提供了新思路。

中文摘要: 尽管扩散模型和大规模运动数据集推动了文本驱动的人体运动合成，但将其扩展到4D人-物交互（HOI）仍具挑战性，主要由于缺乏大规模4D HOI数据集。本研究提出GenHOI，一种新颖的两阶段框架，旨在实现两个关键目标：1）对未见物体的泛化；2）合成高保真4D HOI序列。框架的第一阶段采用Object-AnchorNet，仅从3D HOI数据集中学习，为未见物体重建稀疏3D HOI关键帧，从而减少对大规模4D HOI数据集的依赖。第二阶段引入Contact-Aware Diffusion Model（ContactDM），将稀疏3D HOI关键帧无缝插值为密集且时间连贯的4D HOI序列。为提高生成质量，我们在ContactDM中提出了一种新颖的Contact-Aware Encoder以提取人-物接触模式，以及一种Contact-Aware HOI Attention以有效将接触信号整合到扩散模型中。实验结果表明，我们在公开的OMOMO和3D-FUTURE数据集上取得了最先进的结果，展现出对未见物体的强泛化能力，同时实现了高保真4D HOI生成。

</details>


### [75] [Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis](https://arxiv.org/abs/2506.14854)
**中文标题：高效零售视频标注：一种用于产品与顾客互动分析的鲁棒关键帧生成方法**

*Varun Mannam,Zhenyu Shi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的零售视频关键帧生成方法，用于自动化标注产品和顾客互动，显著降低了人工标注成本并提高了效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统零售视频标注依赖耗时的人工标注，存在帧选择不稳健和成本高的问题。本文旨在通过自动化方法解决这些问题，提升零售视频分析的效率和准确性。

研究方法: 采用深度神经网络学习视频帧的判别性特征，结合针对零售环境优化的目标检测技术，实现关键帧的自动识别和标注。

研究结果: 实验表明，该方法在标注准确性上媲美人工标注，同时效率提升显著，平均节省50%的标注成本，且仅需人工验证调整少于5%的帧。

研究结论: 该方法为零售视频标注提供了高效、低成本的解决方案，适用于顾客行为分析、产品互动检测等多种零售应用场景。

中文摘要: 准确的视频标注在现代零售应用中至关重要，包括顾客行为分析、产品互动检测和店内活动识别。然而，传统标注方法严重依赖耗时的人工标注，导致帧选择不稳健且运营成本增加。为解决零售领域的这些挑战，我们提出了一种基于深度学习的方法，可自动化识别零售视频中的关键帧，并提供产品和顾客的自动标注。我们的方法利用深度神经网络学习视频帧的判别性特征，并结合针对零售环境优化的目标检测技术。实验结果表明，我们的方法优于传统方法，在标注准确性上与人工标注相当，同时显著提升了零售视频标注的整体效率。值得注意的是，我们的方法平均节省了50%的视频标注成本。通过仅需人工验证调整少于5%的检测帧，同时自动化标注其余帧且不降低标注质量，零售商可大幅降低运营成本。关键帧检测的自动化为零售视频标注任务节省了大量时间和精力，对顾客旅程分析、产品互动检测和店内安全监控等多种零售应用具有重要价值。

</details>


### [76] [NTIRE 2025 Image Shadow Removal Challenge Report](https://arxiv.org/abs/2506.15524)
**中文标题：NTIRE 2025图像阴影去除挑战赛报告**

*Florin-Alexandru Vasluianu,Tim Seizinger,Zhuyun Zhou,Cailian Chen,Zongwei Wu,Radu Timofte,Mingjia Li,Jin Hu,Hainuo Wang,Hengxing Liu,Jiarui Wang,Qiming Hu,Xiaojie Guo,Xin Lu,Jiarong Yang,Yuanfei Bao,Anya Hu,Zihao Fan,Kunyu Wang,Jie Xiao,Xi Wang,Xueyang Fu,Zheng-Jun Zha,Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu,Xingbo Wang,Dong Li,Yuxu Chen,Bin Chen,Yuanbo Zhou,Yuanbin Chen,Hongwei Wang,Jiannan Lin,Qinquan Gao,Tong Tong,Zhao Zhang,Yanyan Wei,Wei Dong,Han Zhou,Seyed Amirreza Mousavi,Jun Chen,Haobo Liang,Jiajie Jing,Junyu Li,Yan Yang,Seoyeon Lee,Chaewon Kim,Ziyu Feng,Shidi Chen,Bowen Luan,Zewen Chen,Vijayalaxmi Ashok Aralikatti,G Gyaneshwar Rao,Nikhil Akalwadi,Chaitra Desai,Ramesh Ashok Tabib,Uma Mudenagudi,Anas M. Ali,Bilel Benjdira,Wadii Boulila,Alexandru Brateanu,Cosmin Ancuti,Tanmay Chaturvedi,Manish Kumar,Anmol Srivastav,Daksh Trivedi,Shashwat Thakur,Kishor Upla,Zeyu Xiao,Zhuoyuan Li,Boda Zhou,Shashank Shekhar,Kele Xu,Qisheng Xu,Zijian Gao,Tianjiao Wan,Suiyi Zhao,Bo Wang,Yan Luo,Mingshen Wang,Yilin Zhang*

主要分类: cs.CV

摘要简述: 本文总结了NTIRE 2025图像阴影去除挑战赛的结果，共有306名参与者注册，17支团队成功提交解决方案。挑战赛分为重建保真度和视觉感知两个评估赛道，使用WSRD+数据集进行评测。


<details>
  <summary>详细信息</summary>
研究动机: NTIRE 2025挑战赛旨在推动图像阴影去除技术的发展，通过多团队竞争提升算法在复杂场景下的表现，尤其是处理自阴影和投射阴影的交互问题。

研究方法: 挑战赛设置了两条评估赛道：一条关注重建保真度，另一条通过用户研究评估视觉感知。使用WSRD+数据集，模拟了多种物体、纹理和材料下的阴影交互场景。

研究结果: 共有306名参与者注册，17支团队成功提交解决方案。挑战赛展示了当前图像阴影去除技术的进展，尤其是在复杂场景下的表现。

研究结论: NTIRE 2025挑战赛为图像阴影去除领域提供了新的基准，推动了算法在保真度和视觉感知两方面的进步。

中文摘要: 本文研究了NTIRE 2025阴影去除挑战赛的结果。共有306名参与者注册，其中17支团队在最终评估阶段成功提交了解决方案。延续前两届的设定，本次挑战赛设有两条评估赛道：一条关注重建保真度，另一条通过用户研究评估视觉感知。两条赛道均使用WSRD+数据集进行评测，模拟了大量多样物体、纹理和材料下的自阴影与投射阴影的交互。

</details>


### [77] [SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2506.14791)
**中文标题：SemIRNet：一种用于多模态反讽检测的语义反讽识别网络**

*Jingxuan Zhou,Yuehao Wu,Yibo Zhang,Yeyubei Zhang,Yunchong Liu,Bolin Huang,Chunhong Yuan*

主要分类: cs.CV

摘要简述: 本文提出了一种语义反讽识别网络（SemIRNet），通过引入ConceptNet知识库和跨模态语义相似性检测模块，提升了多模态反讽检测的准确性，实验表明其性能优于现有最优方法。


<details>
  <summary>详细信息</summary>
研究动机: 针对多模态反讽检测任务中图形隐含关联难以准确识别的问题，本文旨在通过引入知识库和跨模态语义相似性检测，提升模型的常识推理能力和检测精度。

研究方法: 1. 首次引入ConceptNet知识库获取概念知识，增强模型常识推理能力；2. 设计词级和样本级跨模态语义相似性检测模块，建模不同粒度的图文关联；3. 引入对比学习损失函数优化样本特征空间分布，提升正负样本可分性。

研究结果: 在公开的多模态反讽检测基准数据集上，模型准确率和F1值分别提升1.64%和2.88%，达到88.87%和86.33%，优于现有最优方法。消融实验验证了知识融合和语义相似性检测对性能提升的重要作用。

研究结论: SemIRNet通过知识融合和跨模态语义相似性检测，显著提升了多模态反讽检测的性能，为相关任务提供了新的解决方案。

中文摘要: 针对多模态反讽检测任务中图形隐含关联难以准确识别的问题，本文提出了一种语义反讽识别网络（SemIRNet）。该模型包含三项主要创新：（1）首次引入ConceptNet知识库获取概念知识，增强模型的常识推理能力；（2）设计了词级和样本级的跨模态语义相似性检测模块，建模不同粒度的图文关联；（3）引入对比学习损失函数优化样本特征的空间分布，提升正负样本的可分性。在公开的多模态反讽检测基准数据集上的实验表明，该模型的准确率和F1值分别比现有最优方法提升了1.64%和2.88%，达到88.87%和86.33%。进一步的消融实验验证了知识融合和语义相似性检测对提升模型性能的重要作用。

</details>


### [78] [CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation](https://arxiv.org/abs/2506.15549)
**中文标题：CLAIM：临床引导的LGE增强技术用于真实多样的心肌瘢痕合成与分割**

*Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen,Chen*

主要分类: cs.CV

摘要简述: CLAIM框架通过临床引导的LGE增强技术，生成多样且真实的瘢痕图像，并优化分割网络，提升心肌瘢痕分割的准确性和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 现有LGE心脏MRI图像数量有限且变异性高，限制了心肌瘢痕分割模型的鲁棒性发展。CLAIM旨在通过合成多样且解剖学一致的瘢痕图像，解决这一问题。

研究方法: CLAIM框架包含SMILE模块（基于临床知识的瘢痕掩模生成器），利用扩散模型生成解剖学一致的瘢痕图像，并结合联合训练策略优化分割网络。

研究结果: 实验表明，CLAIM生成的瘢痕图像解剖学一致性高，与真实瘢痕分布的Dice相似性优于基线模型。

研究结论: CLAIM实现了可控且真实的心肌瘢痕合成，对下游医学影像任务具有实用价值。

中文摘要: 基于深度学习的晚期钆增强（LGE）心脏MRI心肌瘢痕分割在准确和及时诊断结构性心脏病及治疗规划方面展现出巨大潜力。然而，高质量瘢痕标签的LGE图像数量有限且变异性高，限制了鲁棒分割模型的发展。为此，我们提出了CLAIM框架：临床引导的LGE增强技术用于真实多样的心肌瘢痕合成与分割。其核心是SMILE模块（基于临床知识的瘢痕掩模生成器），通过扩散模型生成解剖学一致且空间多样的瘢痕图像。此外，CLAIM采用联合训练策略，优化生成器和分割网络，旨在提升合成瘢痕的真实性和分割精度。实验结果表明，CLAIM生成的瘢痕图像解剖学一致性高，与真实瘢痕分布的Dice相似性优于基线模型。该方法实现了可控且真实的心肌瘢痕合成，对下游医学影像任务具有实用价值。

</details>


### [79] [Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction](https://arxiv.org/abs/2506.14856)
**中文标题：窥探未知：基于神经不确定性图的主动视角选择用于3D重建**

*Zhengquan Zhang,Feng Xu,Mengmi Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于神经不确定性图的新型主动视角选择方法（AVS），用于高效准确的3D重建。通过轻量级网络UPNet预测不确定性图，显著减少计算开销，并在减少一半视角的情况下达到与基线方法相当的精度。


<details>
  <summary>详细信息</summary>
研究动机: 在3D重建中，不同视角提供的信息价值差异显著。如何选择最具信息量的视角以减少冗余并提高重建效率是计算机视觉中的关键挑战。本文旨在通过神经不确定性图指导视角选择，实现高效且准确的3D重建。

研究方法: 提出了一种名为UPNet的轻量级前馈神经网络，输入单张3D物体图像，输出预测的不确定性图，表示所有候选视角的不确定性值。通过观察自然物体及其不确定性模式，训练UPNet学习从视角外观到体积表示不确定性的直接映射。结合历史预测的不确定性图，抑制冗余视角并选择最具信息量的视角。

研究结果: 实验表明，尽管仅使用一半的视角，该方法的重建精度与基线方法相当。同时，计算开销显著降低，AVS速度提升400倍，CPU、RAM和GPU使用量减少50%以上。此外，该方法无需额外训练即可泛化到新物体类别的AVS任务。

研究结论: 基于神经不确定性图的AVS方法在减少视角数量的同时保持了高精度，显著提升了计算效率，并展示了良好的泛化能力，为3D重建中的视角选择问题提供了实用解决方案。

中文摘要: 某些视角自然比其他视角提供更多信息。AI系统如何确定哪个视角能为准确高效的3D物体重建提供最有价值的洞察？主动视角选择（AVS）在3D重建中仍是计算机视觉的基本挑战。目标是识别能实现最准确3D重建的最小视角集。不同于从当前观察学习辐射场（如NeRF或3D高斯泼溅）并为每个候选视角计算不确定性，我们提出了一种由轻量级前馈深度神经网络UPNet预测的神经不确定性图引导的新型AVS方法。UPNet输入一张3D物体图像，输出预测的不确定性图，表示所有可能候选视角的不确定性值。通过利用从观察大量自然物体及其不确定性模式中提取的启发式信息，训练UPNet学习从视角外观到体积表示不确定性的直接映射。接着，我们的方法聚合所有先前预测的神经不确定性图，抑制冗余候选视角并有效选择最具信息量的视角。利用这些选定的视角，我们训练3D神经渲染模型，并与其他竞争性AVS方法在新视角合成质量上进行比较。值得注意的是，尽管仅使用上限视角数量的一半，我们的方法仍实现了相当的重建精度。此外，它显著降低了AVS过程中的计算开销，与基线方法相比，速度提升高达400倍，CPU、RAM和GPU使用量减少50%以上。特别地，我们的方法无需任何额外训练即可有效泛化到涉及新物体类别的AVS任务。

</details>


### [80] [RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation](https://arxiv.org/abs/2506.15560)
**中文标题：RaCalNet：基于稀疏监督的雷达校准网络用于度量深度估计**

*Xingrui Qin,Wentao Zhao,Chuan Cao,Yihe Niu,Houcheng Jiang,Jingchuan Wang*

主要分类: cs.CV

摘要简述: RaCalNet是一种新型雷达校准网络，通过稀疏LiDAR监督实现高精度深度估计，无需密集监督，显著降低成本并提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统毫米波雷达深度估计依赖密集LiDAR监督，成本高且数据需求大。RaCalNet旨在通过稀疏监督实现高效深度估计，解决这一问题。

研究方法: RaCalNet首先校准和优化稀疏雷达点，构建精确深度先验，再以这些先验为锚点引导单目深度预测，避免依赖密集监督。

研究结果: 在ZJU-4DRadarCam数据集和实际场景中，RaCalNet表现优异，RMSE分别降低35.30%和34.89%，生成具有清晰轮廓和细节的深度图。

研究结论: RaCalNet通过稀疏监督实现高精度深度估计，性能超越密集监督方法，为低成本高效深度估计提供了新思路。

中文摘要: 使用毫米波雷达进行密集度量深度估计通常需要密集LiDAR监督，通过多帧投影和插值生成，以指导从稀疏雷达测量和RGB图像中学习准确深度。然而，这种模式成本高且数据密集。为此，我们提出RaCalNet，一种新型框架，通过使用稀疏LiDAR监督学习优化的雷达测量，消除了对密集监督的需求，其监督密度仅为密集监督方法的约1%。与以往将雷达点与广泛图像区域关联并严重依赖密集标签的方法不同，RaCalNet首先重新校准和优化稀疏雷达点以构建精确深度先验。这些先验随后作为可靠锚点引导单目深度预测，实现无需密集监督的度量尺度估计。这一设计提高了结构一致性并保留了精细细节。尽管仅依赖稀疏监督，RaCalNet仍超越了最先进的密集监督方法，生成了具有清晰物体轮廓和细粒度纹理的深度图。在ZJU-4DRadarCam数据集和实际部署场景中的大量实验证明了其有效性，分别将RMSE降低了35.30%和34.89%。

</details>


### [81] [Control and Realism: Best of Both Worlds in Layout-to-Image without Training](https://arxiv.org/abs/2506.15563)
**中文标题：控制与真实感：无需训练的布局到图像生成中的最佳结合**

*Bonan Li,Yinhan Hu,Songhua Liu,Xinchao Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的布局到图像生成方法WinWinLay，通过非局部注意力能量函数和自适应更新策略，解决了现有方法在定位不准和图像不真实的问题，显著提升了控制精度和视觉真实感。


<details>
  <summary>详细信息</summary>
研究动机: 现有的布局到图像生成方法虽然无需训练即可实现，但存在定位不准和图像不真实的问题。本文旨在解决这些问题，提出一种无需训练的新方法，以提升控制精度和图像质量。

研究方法: WinWinLay采用两种关键策略：1) 非局部注意力能量函数，通过重新分配注意力分数，使物体更符合指定的空间条件；2) 基于Langevin动力学的自适应更新方案，避免偏离预训练域，同时满足布局约束。

研究结果: 实验表明，WinWinLay在控制元素布局和实现逼真视觉效果方面优于现有方法，显著提升了生成图像的质量和准确性。

研究结论: WinWinLay通过创新的非局部注意力能量函数和自适应更新策略，成功解决了布局到图像生成中的关键问题，为无需训练的生成方法提供了新的解决方案。

中文摘要: 布局到图像生成的目标是通过对物体位置和排列的精确控制来创建复杂场景。现有研究表明，预训练的文本到图像扩散模型无需特定数据训练即可实现这一目标，但常面临定位不准和不真实伪影的问题。针对这些缺陷，我们提出了一种无需训练的新方法WinWinLay。其核心在于两种关键策略：非局部注意力能量函数和自适应更新，共同提升了控制精度和真实感。一方面，我们从理论上证明常用的注意力能量函数会引入固有的空间分布偏差，阻碍物体与布局指令的均匀对齐。为解决这一问题，我们探索了非局部注意力先验，重新分配注意力分数，使物体更符合指定的空间条件。另一方面，我们发现普通的反向传播更新规则可能导致预训练域的偏离，产生分布外伪影。为此，我们引入了基于Langevin动力学的自适应更新方案，在尊重布局约束的同时促进域内更新。大量实验表明，WinWinLay在控制元素布局和实现逼真视觉效果方面表现出色，超越了当前最先进的方法。

</details>


### [82] [Show-o2: Improved Native Unified Multimodal Models](https://arxiv.org/abs/2506.15564)
**中文标题：Show-o2：改进的原生统一多模态模型**

*Jinheng Xie,Zhenheng Yang,Mike Zheng Shou*

主要分类: cs.CV

摘要简述: 本文提出了一种改进的原生统一多模态模型Show-o2，结合自回归建模和流匹配技术，通过3D因果变分自编码器空间构建统一视觉表示，支持图像和视频的多模态理解与生成。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态模型在处理图像和视频等多样化模态时存在局限性，需要一种能够统一理解与生成多种模态的模型。Show-o2旨在通过原生统一架构解决这一问题。

研究方法: 基于语言模型，Show-o2采用自回归建模和流匹配技术，分别应用于语言头和流头，以支持文本标记预测和图像/视频生成。通过双路径空间-时间融合构建统一视觉表示，并设计两阶段训练方法以提升模型规模。

研究结果: Show-o2模型在文本、图像和视频等多种模态的理解与生成任务中表现出色，展现了广泛的适用性和高效性。

研究结论: Show-o2通过原生统一架构和两阶段训练方法，成功实现了多模态理解与生成的高效统一，为未来多模态研究提供了新方向。

中文摘要: 本文提出了一种改进的原生统一多模态模型Show-o2，利用自回归建模和流匹配技术。基于3D因果变分自编码器空间，通过空间（时间）融合的双路径构建统一视觉表示，支持图像和视频模态的可扩展性，同时确保有效的多模态理解与生成。基于语言模型，自回归建模和流匹配分别应用于语言头和流头，以促进文本标记预测和图像/视频生成。设计了两阶段训练方法，以有效学习并扩展至更大模型。最终的Show-o2模型在文本、图像和视频等多种模态的理解与生成任务中表现出广泛的适用性。代码和模型发布于https://github.com/showlab/Show-o。

</details>


### [83] [Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification](https://arxiv.org/abs/2506.15565)
**中文标题：巴尔的摩图谱：用于半监督超高空间分辨率土地覆盖分类的FreqWeaver适配器**

*Junhao Wu,Aboagye-Ntow Stephen,Chuyuan Wang,Gang Chen,Xin Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种参数高效的半监督分割框架，用于0.3米超高空间分辨率影像，通过结合SAM2知识和遥感专用FreqWeaver适配器，显著提升细粒度细节建模能力，同时仅占用模型总参数的5.96%。该方法在未标注数据利用和参数效率上表现优异，分割结果优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 超高空间分辨率土地覆盖分类对精细土地分析至关重要，但面临标注成本高、尺度变化大及大规模视觉模型适应性不足的挑战。现有方法多依赖标注数据且适用于1米分辨率影像，而实际应用需处理更高分辨率影像且标注有限。

研究方法: 提出了一种参数高效的半监督分割框架，结合SAM2知识并引入遥感专用FreqWeaver适配器，增强细粒度细节建模能力，同时保持轻量化设计（仅占模型总参数的5.96%）。

研究结果: 该方法在未标注数据利用和参数效率上表现优异，分割结果优于现有参数高效调优策略1.78%，且比最先进的高分辨率遥感分割方法提升3.44%。

研究结论: 所提框架在超高分辨率土地覆盖分类中表现出色，通过轻量化设计和高效利用未标注数据，显著提升了分割性能和结构一致性。

中文摘要: 超高空间分辨率土地覆盖分类对精细土地分析至关重要，但由于像素级标注成本高、尺度变化显著以及大规模视觉模型适应性有限，其仍具挑战性。现有方法通常专注于1米空间分辨率影像，并严重依赖标注数据，而实际应用常需在弱监督下处理更高分辨率影像。为此，我们提出了一种参数高效的半监督分割框架，适用于0.3米空间分辨率影像，结合SAM2知识并引入遥感专用FreqWeaver适配器，以增强细粒度细节建模能力，同时保持轻量化设计（仅占模型总参数的5.96%）。通过高效利用未标注数据并保持最小参数开销，所提方法提供了具有优异结构一致性的稳健分割结果，优于现有参数高效调优策略1.78%，且比最先进的高分辨率遥感分割方法提升3.44%。

</details>


### [84] [PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2506.14907)
**中文标题：PeRL：基于排列增强的强化学习用于交错视觉-语言推理**

*Yizhen Zhang,Yang Ding,Shuoshuo Zhang,Xinchen Zhang,Haoling Li,Zhong-zhi Li,Peijie Wang,Jie Wu,Lei Ji,Yelong Shen,Yujiu Yang,Yeyun Gong*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PeRL的强化学习方法，通过图像序列排列和多阶段策略提升多模态推理任务的性能，尤其在多图像位置推理任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态强化学习方法主要局限于单图像空间推理，难以推广到涉及多图像位置关系的复杂场景。本文旨在解决这一问题，提升模型在多图像任务中的推理能力。

研究方法: PeRL通过图像序列排列模拟多样化的位置关系，并设计了一种多阶段策略优化探索与利用的平衡。此外，引入轨迹过滤机制以聚焦对学习最优行为贡献最大的轨迹。

研究结果: 实验表明，PeRL在5个多图像基准测试和3个单图像基准测试中均显著优于现有方法，尤其是在多图像任务中达到最优性能，同时保持单图像任务的竞争力。

研究结论: PeRL为多模态强化学习提供了一种通用且高效的解决方案，显著提升了多图像位置推理任务的性能，同时兼顾单图像任务的实用性。

中文摘要: 受DeepSeek-R1等强化学习方法在推理能力上的启发，近期研究开始探索利用强化学习（RL）增强视觉-语言模型（VLMs）在多模态推理任务中的表现。然而，现有方法多局限于单图像空间推理，难以推广到涉及多图像位置关系的复杂场景。为解决这一问题，我们提出了一种通用的强化学习方法PeRL，专为交错多模态任务设计，并采用多阶段策略优化探索与利用的平衡，从而提升学习效率和任务性能。具体而言，我们通过图像序列排列模拟多样化的位置关系以探索更多空间和位置多样性。此外，设计了一种轨迹过滤机制，通过重采样聚焦对学习最优行为贡献最大的轨迹。我们在5个多图像基准测试和3个单图像基准测试上评估了模型性能。实验表明，PeRL训练模型在多图像任务中显著优于R1相关方法及交错VLM基线，达到最优性能，同时在单图像任务中保持竞争力。

</details>


### [85] [A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds](https://arxiv.org/abs/2506.15577)
**中文标题：基于图的统一框架：从点云实现可扩展的3D树木重建与非破坏性生物量估算**

*Di Wang,Shi Li*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图的统一框架，用于从点云数据中实现可扩展的3D树木重建和非破坏性生物量估算，显著提升了大规模森林生物量评估的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 森林地上生物量（AGB）的估算对碳储存评估和可持续森林管理至关重要。现有的定量结构模型（QSM）方法存在局限性，如仅适用于单棵树、依赖高质量地面激光扫描（TLS）数据，且需要复杂的预处理步骤，限制了其可扩展性和实际应用。

研究方法: 本研究提出了一种基于图的统一框架，通过创新的图操作（如路径提取和拓扑抽象）实现端到端的大规模点云处理，包括树木分割、叶木分离和3D骨架重建。该方法在多种数据集（不同叶况、空间尺度和数据来源）上进行了验证。

研究结果: 实验结果表明，该方法在具有挑战性的条件下表现优异，尤其是在叶片覆盖（相对误差约20%）和低密度无人机激光扫描（ULS）数据（相对误差约30%）中。该方法显著减少了对专用预处理工具的依赖，并证明ULS可作为TLS的可行替代方案。

研究结论: 该框架为大规模非破坏性AGB估算提供了稳健且可扩展的解决方案，显著提升了QSM方法的可行性，为森林调查和气候变化研究开辟了更广泛的应用前景。

中文摘要: 森林地上生物量（AGB）的估算对评估碳储存和支持可持续森林管理至关重要。定量结构模型（QSM）通过3D树木结构重建提供了一种非破坏性的AGB估算方法。然而，现有的QSM方法存在显著局限性，主要针对单棵树设计，依赖地面激光扫描（TLS）的高质量点云数据，且需要复杂的预处理步骤，阻碍了其可扩展性和实际部署。本研究提出了一种新颖的统一框架，通过创新的基于图的流程实现大规模点云的端到端处理。该方法通过专用的图操作（如路径提取和拓扑抽象）无缝集成了树木分割、叶木分离和3D骨架重建。在多种数据集（不同叶况、空间尺度和数据来源）上进行了全面验证。实验结果表明，该方法在具有挑战性的条件下表现优异，尤其是在叶片覆盖（相对误差约20%）和低密度无人机激光扫描（ULS）数据（相对误差约30%）中。这些发现表明，该框架为大规模非破坏性AGB估算提供了稳健且可扩展的解决方案，显著减少了对专用预处理工具的依赖，并确立了ULS作为TLS的可行替代方案。据我们所知，这是首个能够在操作尺度上实现无缝端到端3D树木重建的方法。这一进展显著提升了基于QSM的AGB估算的可行性，为森林调查和气候变化研究的更广泛应用铺平了道路。

</details>


### [86] [One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution](https://arxiv.org/abs/2506.15591)
**中文标题：一步扩散实现细节丰富且时间一致的视频超分辨率**

*Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于稳定扩散（SD）的双LoRA学习（DLoRAL）方法，用于视频超分辨率（Real-VSR），通过跨帧检索（CFR）和一致性学习模块（C-LoRA）提取时间一致性先验，再通过细节增强模块（D-LoRA）提升空间细节，实现单步扩散的高质量视频恢复。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于SD的Real-VSR方法在保持时间一致性的同时往往牺牲了空间细节，导致视觉质量不佳。本文旨在解决如何在低质量（LQ）输入视频中提取鲁棒的时间一致性先验，并在增强细节的同时保持这些先验。

研究方法: 提出双LoRA学习（DLoRAL）范式，包括两个阶段：1）通过跨帧检索（CFR）和一致性学习模块（C-LoRA）提取时间一致性先验；2）固定CFR和C-LoRA，训练细节增强模块（D-LoRA）提升空间细节并保持时间一致性。两阶段交替优化，最终合并LoRA分支实现单步扩散推理。

研究结果: 实验表明，DLoRAL在准确性和速度上均表现优异，能够同时实现丰富的空间细节和时间一致性。

研究结论: DLoRAL通过双LoRA学习范式，有效结合了时间一致性和空间细节增强，为Real-VSR提供了一种高效且高质量的解决方案。

中文摘要: 在真实世界视频超分辨率（Real-VSR）中，如何在利用预训练生成模型（如稳定扩散SD）合成逼真细节的同时，保持时间一致性是一个具有挑战性的问题。现有的基于SD的Real-VSR方法往往为了时间一致性而牺牲空间细节，导致视觉质量不佳。本文认为关键在于如何从低质量（LQ）输入视频中有效提取鲁棒的时间一致性先验，并在增强视频细节的同时保持这些先验。为此，我们提出了一种双LoRA学习（DLoRAL）范式，训练一个基于SD的一步扩散模型，同时实现逼真的帧细节和时间一致性。具体而言，我们引入了跨帧检索（CFR）模块以聚合跨帧的互补信息，并训练一致性LoRA（C-LoRA）从退化输入中学习鲁棒的时间表示。在一致性学习后，固定CFR和C-LoRA模块，训练细节LoRA（D-LoRA）以增强空间细节，同时与C-LoRA定义的时间空间对齐以保持时间一致性。两阶段交替迭代优化，共同输出一致且细节丰富的结果。在推理时，两个LoRA分支被合并到SD模型中，实现高效且高质量的单步视频恢复。实验表明，DLoRAL在准确性和速度上均表现优异。代码和模型可在https://github.com/yjsunnn/DLoRAL获取。

</details>


### [87] [Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration](https://arxiv.org/abs/2506.15596)
**中文标题：极端异质性多模态医学图像的单模态化配准**

*Kyobin Choo,Hyunkyung Han,Jinyeong Kim,Chanyong Yoon,Seong Jae Hwang*

主要分类: cs.CV

摘要简述: 本文提出M2M-Reg框架，通过单模态相似性训练多模态图像配准模型，解决极端异质性多模态医学图像配准问题，并在ADNI数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 临床中，功能性与结构性医学图像的配准常因模态差异大而失败，传统无监督配准方法难以学习可靠的空间映射。本文旨在解决这一挑战。

研究方法: 提出M2M-Reg框架，利用单模态相似性训练多模态配准模型，并引入GradCyCon正则化器促进微分同胚。框架还支持半监督学习，无需真实变换或分割掩码。

研究结果: 在ADNI数据集上，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法提高2倍，显著优于传统方法。

研究结论: M2M-Reg有效解决了极端异质性多模态医学图像配准问题，为临床实践提供了可靠工具。

中文摘要: 在临床实践中，功能性成像模态（如PET和FA）常需与结构性参考（如MRI、CT）对齐，以实现准确解释或群体分析，这需要多模态可变形图像配准（DIR）。然而，由于这些模态与标准结构性扫描的极端异质性，传统的无监督DIR方法难以学习可靠的空间映射，且常导致图像扭曲。我们发现，指导这些模型的相似性度量无法捕捉高度差异模态间的对齐关系。为此，我们提出M2M-Reg（多到单配准），一种新颖的框架，仅利用单模态相似性训练多模态DIR模型，同时保留现有架构范式以无缝集成到现有模型中。我们还引入了GradCyCon，一种利用M2M-Reg循环训练方案促进微分同胚的正则化器。此外，我们的框架自然扩展到半监督设置，仅整合预对齐和未对齐对，无需真实变换或分割掩码。在阿尔茨海默病神经影像倡议（ADNI）数据集上的实验表明，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法提高2倍，突显了其在处理高度异质性多模态DIR中的有效性。代码发布于https://github.com/MICV-yonsei/M2M-Reg。

</details>


### [88] [BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion](https://arxiv.org/abs/2506.15610)
**中文标题：BoxFusion：基于实时多视角框融合的无重建开放词汇3D目标检测**

*Yuqing Lan,Chenyang Zhu,Zhirui Gao,Jiazhao Zhang,Yihan Cao,Renjiao Yi,Yijie Wang,Kai Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种无需点云重建的实时多视角框融合方法BoxFusion，用于开放词汇3D目标检测，显著降低了计算和内存开销，实现了实时性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D目标检测方法依赖密集点云重建，计算和内存开销大，难以实时部署。本文旨在提出一种无需重建的在线框架，实现高效实时的开放词汇3D检测。

研究方法: 利用预训练的Cubify Anything模型进行单视角3D目标检测，结合CLIP捕捉开放词汇语义。通过关联模块和优化模块融合多视角检测框，关联模块使用3D NMS和框匹配，优化模块采用IoU引导的随机优化技术。

研究结果: 在ScanNetV2和CA-1M数据集上，本文方法在在线方法中达到最优性能，且能实时处理超过1000平方米的环境。

研究结论: BoxFusion通过无需重建的范式实现了高效实时的开放词汇3D检测，具有广泛泛化能力。

中文摘要: 开放词汇3D目标检测因其在自动驾驶和具身AI中的关键应用而备受关注。现有检测方法（无论是离线还是在线）通常依赖密集点云重建，这带来了巨大的计算开销和内存限制，阻碍了在下游任务中的实时部署。为此，我们提出了一种新颖的无重建在线框架，专为内存高效和实时的3D检测而设计。具体而言，给定流式输入的带位姿RGB-D视频，我们利用预训练的视觉基础模型Cubify Anything进行单视角3D目标检测（通过边界框），并结合CLIP捕捉检测对象的开放词汇语义。为了将不同视角检测到的边界框融合为统一结果，我们采用关联模块处理多视角对应关系，并通过优化模块融合同一实例在多视角中预测的3D边界框。关联模块使用3D非极大值抑制（NMS）和框对应匹配模块，而优化模块则采用基于粒子滤波的IoU引导高效随机优化技术，以在最小化计算复杂度的同时保证3D边界框的多视角一致性。在ScanNetV2和CA-1M数据集上的大量实验表明，我们的方法在在线方法中达到了最先进的性能。得益于这种新颖的无重建3D目标检测范式，我们的方法在多种场景中表现出强大的泛化能力，即使在超过1000平方米的环境中也能实现实时感知。

</details>


### [89] [HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization](https://arxiv.org/abs/2506.15625)
**中文标题：HOIDiNi：通过扩散噪声优化实现人-物交互**

*Roey Ron,Guy Tevet,Haim Sawdayee,Amit H. Bermano*

主要分类: cs.CV

摘要简述: HOIDiNi是一种基于扩散噪声优化的文本驱动框架，用于生成逼真且合理的人-物交互（HOI）。通过将问题分解为物体中心阶段和人体中心阶段，该方法在保持运动自然性的同时实现了精确的手-物接触。实验表明，HOIDiNi在接触准确性、物理有效性和整体质量上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 人-物交互生成在保持严格接触准确性和多样运动流形方面极具挑战性。现有方法通常在逼真性和物理正确性之间权衡，而HOIDiNi旨在通过扩散噪声优化同时实现这两者。

研究方法: HOIDiNi采用扩散噪声优化（DNO）方法，在预训练扩散模型的噪声空间中直接优化。该方法分为两个阶段：物体中心阶段（选择手-物接触位置）和人体中心阶段（优化全身运动以实现接触）。这种结构化方法确保了精确接触和自然运动。

研究结果: 在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触准确性、物理有效性和整体质量上优于现有方法。该方法能够生成复杂的、可控的交互动作（如抓取、放置和全身协调），仅通过文本提示驱动。

研究结论: HOIDiNi通过扩散噪声优化和分阶段处理，成功实现了逼真且物理正确的人-物交互生成。其性能优于现有方法，展示了文本驱动复杂交互生成的潜力。

中文摘要: 我们提出了HOIDiNi，一种基于文本驱动的扩散框架，用于合成逼真且合理的人-物交互（HOI）。HOI生成极具挑战性，因为它需要严格的接触准确性和多样的运动流形。现有方法通常在逼真性和物理正确性之间权衡，而HOIDiNi通过扩散噪声优化（DNO）在预训练扩散模型的噪声空间中直接优化，同时实现了这两者。这得益于我们将问题分解为两个阶段：物体中心阶段（主要选择手-物接触位置）和人体中心阶段（优化全身运动以实现这一蓝图）。这种结构化方法在保持运动自然性的同时实现了精确的手-物接触。在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触准确性、物理有效性和整体质量上优于现有方法和基线。我们的结果表明，该方法能够生成复杂的、可控的交互动作（如抓取、放置和全身协调），仅通过文本提示驱动。

</details>


### [90] [FindingDory: A Benchmark to Evaluate Memory in Embodied Agents](https://arxiv.org/abs/2506.15635)
**中文标题：FindingDory：一个评估具身智能体记忆能力的基准测试**

*Karmesh Yadav,Yusuf Ali,Gunshi Gupta,Yarin Gal,Zsolt Kira*

主要分类: cs.CV

摘要简述: 本文提出了一个新的基准测试FindingDory，用于评估具身智能体在长期任务中的记忆能力，填补了现有长视频问答基准在具身环境中的不足，并在Habitat模拟器中设计了60个任务以测试记忆和推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大型视觉语言模型在规划和控制任务中表现出色，但在具身环境中处理长期记忆时表现不足，尤其是面对大量图像和跨多天的经验。现有基准测试忽略了具身任务中的低层技能和细粒度推理需求，因此需要一个新的基准来专门评估记忆在具身智能体中的重要性。

研究方法: 研究团队在Habitat模拟器中设计了一个新的基准测试FindingDory，包含60个需要长期记忆和上下文感知的任务。这些任务可以进一步扩展为更复杂版本，以支持对记忆和推理能力的可扩展评估。同时，团队还提出了结合先进视觉语言模型和低层导航策略的基线方法。

研究结果: 基准测试展示了当前视觉语言模型在长期记忆任务中的局限性，尤其是在需要持续交互和细粒度推理的场景中。基线方法的性能分析揭示了改进方向，如提升记忆整合能力和动作执行效率。

研究结论: FindingDory基准为评估具身智能体的长期记忆能力提供了重要工具，填补了现有研究的空白，并为未来改进视觉语言模型在具身环境中的应用指明了方向。

中文摘要: 大型视觉语言模型最近在规划和控制任务中表现出色，推动了其在现实机器人应用中的兴趣。然而，这些模型在具身环境中进行推理时，受限于其处理跨多天收集的长期经验和海量图像的能力。当前的视觉语言模型通常难以同时处理超过几百张图像，凸显了在具身环境中更高效处理长期记忆机制的需求。为有效评估这些模型在长期控制任务中的表现，需要一个专门针对记忆关键场景的基准测试。现有的长视频问答基准忽略了具身任务中的对象操作和导航等挑战，这些任务需要低层技能和对过去交互的细粒度推理。此外，具身智能体中有效的记忆整合既需要回忆相关历史信息，也需要基于这些信息执行动作，因此必须同时研究这些方面而非孤立看待。本研究在Habitat模拟器中引入了一个新的长期具身任务基准测试，评估了60个需要持续参与和上下文感知的任务中的记忆能力。这些任务还可以通过程序扩展为更长和更具挑战性的版本，以实现对记忆和推理能力的可扩展评估。我们还提出了结合先进视觉语言模型和低层导航策略的基线方法，评估了它们在记忆密集型任务中的表现，并指出了改进方向。

</details>


### [91] [Demystifying the Visual Quality Paradox in Multimodal Large Language Models](https://arxiv.org/abs/2506.15645)
**中文标题：揭秘多模态大语言模型中的视觉质量悖论**

*Shuo Xing,Lanqing Guo,Hongyuan Hua,Seoyoung Lee,Peiran Li,Yufei Wang,Zhangyang Wang,Zhengzhong Tu*

主要分类: cs.CV

摘要简述: 研究发现多模态大语言模型（MLLMs）在视觉质量上存在悖论：图像偏离人类感知的高保真度时，模型性能反而提升。为此，作者提出了一种轻量级适配模块VQ-TTT，动态调整输入图像以提升任务表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在视觉语言任务中表现优异，但输入图像视觉质量如何影响其响应尚不明确。作者旨在探究图像质量与模型性能的关系，并解决模型对非高保真图像的偏好问题。

研究方法: 作者通过系统实验，对领先的MLLMs和视觉语言基准测试集施加可控的图像退化和风格变化。为解决模型偏好问题，提出VQ-TTT模块：在冻结的视觉编码器前插入可学习的低秩核以调整频率内容，并通过LoRA微调浅层视觉编码器。

研究结果: 研究发现视觉质量悖论：图像偏离人类感知的高保真度时，模型性能反而提升。VQ-TTT模块显著提升了所有测试数据集和MLLMs的平均准确率，无需外部模型或额外训练数据。

研究结论: 研究重新定义了MLLMs对“更好”视觉输入的需求，强调在新AI时代，适应性而非普遍“干净”的图像更为重要。VQ-TTT为动态调整输入图像提供了一种高效解决方案。

中文摘要: 近期的多模态大语言模型（MLLMs）在视觉语言任务中表现优异，但输入图像视觉质量如何影响其响应尚不明确。更高的图像感知质量是否意味着更好的MLLM理解？我们首次系统研究了领先的MLLMs和一系列视觉语言基准测试集，对每张图像施加可控的退化和风格变化。令人惊讶的是，我们发现了一个视觉质量悖论：当图像偏离人类感知的高保真度时，模型、任务甚至单个实例的性能反而提升。现成的修复流程无法调和这些独特偏好。为弥补这一差距，我们提出了视觉质量测试时调优（VQ-TTT）——一种轻量级适配模块：（1）在冻结的视觉编码器前插入可学习的低秩核以调整频率内容；（2）通过LoRA仅微调浅层视觉编码器。VQ-TTT在单次前向传播中动态调整每张输入图像，使其与任务特定的模型偏好对齐。在所有测试的MLLMs和数据集中，VQ-TTT显著提升了平均准确率，且无需外部模型、缓存特征或额外训练数据。这些发现重新定义了MLLMs对“更好”视觉输入的需求，并强调了在新AI时代，适应性而非普遍“干净”的图像的重要性。

</details>


### [92] [Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning](https://arxiv.org/abs/2506.15649)
**中文标题：基于边缘奖励调整的双阶段价值引导推理：快速且保真的视觉语言模型描述生成**

*Ankan Deria,Adinath Madhavrao Dukre,Feilong Tang,Sara Atito,Sudipta Roy,Muhammad Awais,Muhammad Haris Khan,Imran Razzak*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ViMaR的双阶段推理框架，通过结合时间差分价值模型和边缘感知奖励调整，显著提升了视觉语言模型（VLM）的生成效率和输出保真度。实验表明，ViMaR在生成更可靠、准确且详细的描述的同时，速度提升了4倍以上，并展示了跨模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型推理方法计算成本高且容易生成低置信度的内容，导致持续的幻觉问题。本文旨在通过一种高效且保真的推理框架解决这些问题。

研究方法: ViMaR采用双阶段推理：第一阶段通过单次遍历从多样候选描述中选出最高价值描述；第二阶段选择性优化被忽略或视觉基础薄弱的片段，并通过边缘感知惩罚抑制低置信度生成。

研究结果: 实验证明，ViMaR生成的描述更可靠、准确且详细，速度提升4倍以上，并能有效泛化到未见过的更强模型，显著提升了视觉理解任务的性能。

研究结论: ViMaR作为一种高效、可扩展的推理时解码策略，不仅提升了生成质量，还展示了跨模型泛化和自训练潜力，为视觉语言模型的实际应用提供了新思路。

中文摘要: 尽管视觉语言模型（VLM）在推理时搜索方面取得了显著进展，但现有方法仍存在计算成本高和未受惩罚的低置信度生成问题，这通常导致持续的幻觉。我们提出了\textbf{基于边缘奖励的价值引导推理（ViMaR）}，这是一种双阶段推理框架，通过结合时间差分价值模型和边缘感知奖励调整，显著提升了效率和输出保真度。第一阶段通过单次遍历从多样候选描述中选出最高价值描述；第二阶段选择性优化被忽略或视觉基础薄弱的片段，消除频繁奖励的评估。校准的边缘惩罚抑制低置信度生成，同时保留描述的丰富性。在多VLM架构上的广泛实验表明，ViMaR生成的描述更可靠、事实准确、详细且具有解释性，速度比现有价值引导方法快4倍以上。特别是，ViMaR仅在LLaVA Mistral-7B上训练，却能有效泛化到未见过的更强模型。进一步验证中，ViMaR成功指导LLaVA-OneVision-Qwen2-7B的生成，显著提升了描述质量，展示了跨模型指导的稳健性。这种跨模型泛化凸显了ViMaR的灵活性和模块化，使其成为一种可扩展和可迁移的推理时解码策略。此外，当ViMaR生成的描述用于自训练时，底层模型在广泛的视觉理解任务中实现了显著提升，突显了快速、准确且自改进的VLM管道的潜力。

</details>


### [93] [UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting](https://arxiv.org/abs/2506.15673)
**中文标题：UniRelight：学习联合分解与合成的视频重光照方法**

*Kai He,Ruofan Liang,Jacob Munkberg,Jon Hasselgren,Nandita Vijaykumar,Alexander Keller,Sanja Fidler,Igor Gilitschenski,Zan Gojcic,Zian Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种联合分解与合成的视频重光照方法UniRelight，通过单次处理同时估计反照率并生成重光照结果，利用视频扩散模型的生成能力提升光照效果和材料交互的真实性。


<details>
  <summary>详细信息</summary>
研究动机: 现有端到端重光照模型受限于配对多光照数据的稀缺性，难以泛化到多样化场景；而两阶段渲染方法易累积误差且难以处理复杂光照或材料。本文旨在解决这些问题。

研究方法: 提出一种通用方法，联合估计反照率并合成重光照结果，利用视频扩散模型的生成能力，增强场景理解和光照效果的真实性。训练数据包括合成多光照数据和自动标注的真实视频。

研究结果: 模型在多样化场景中表现出强泛化能力，在视觉保真度和时间一致性上超越先前方法。

研究结论: UniRelight通过联合分解与合成，显著提升了重光照任务的真实性和泛化能力，为复杂光照和材料交互提供了有效解决方案。

中文摘要: 我们解决了单幅图像或视频的重光照问题，这一任务需要精确的场景内在理解和高品质的光传输合成。现有的端到端重光照模型常受限于配对多光照数据的稀缺性，难以泛化到多样化场景。相反，结合逆向和正向渲染的两阶段流程虽能缓解数据需求，但易累积误差，且在复杂光照或高级材料下难以生成真实输出。本文提出了一种通用方法，通过单次处理联合估计反照率并合成重光照结果，利用视频扩散模型的生成能力。这种联合形式增强了隐式场景理解，并促进了真实光照效果和复杂材料交互（如阴影、反射和透明度）的生成。通过在合成多光照数据和大量自动标注的真实视频上训练，我们的模型在多样化领域中表现出强泛化能力，并在视觉保真度和时间一致性上超越先前方法。

</details>


### [94] [Sekai: A Video Dataset towards World Exploration](https://arxiv.org/abs/2506.15675)
**中文标题：Sekai：面向世界探索的视频数据集**

*Zhen Li,Chuanhao Li,Xiaofeng Mao,Shaoheng Lin,Ming Li,Shitian Zhao,Zhaopan Xu,Xinyue Li,Yukang Feng,Jianwen Sun,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Zhixiang Wang,Yuwei Wu,Tong He,Jiangmiao Pang,Yu Qiao,Yunde Jia,Kaipeng Zhang*

主要分类: cs.CV

摘要简述: 本文介绍了Sekai数据集，一个高质量的第一人称视角全球视频数据集，专为世界探索任务设计，包含5000多小时来自100多个国家和地区的视频，并配有丰富注释。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频生成数据集因地点有限、时长短、场景静态且缺乏探索注释，不适合世界探索任务。为此，作者提出Sekai数据集，以支持视频生成和世界探索研究。

研究方法: 作者收集了来自750个城市的步行和无人机视角视频，开发了高效工具箱进行预处理和注释（如位置、场景、天气等），并利用部分数据训练了交互式视频探索模型YUME。

研究结果: 实验验证了数据集的质量，并展示了YUME模型在交互式世界探索中的潜力。

研究结论: Sekai数据集有望推动视频生成和世界探索领域的发展，并激发有价值的应用。

中文摘要: 视频生成技术取得了显著进展，有望成为交互式世界探索的基础。然而，现有视频生成数据集因地点有限、时长短、场景静态且缺乏探索和世界注释，不适合世界探索训练。本文介绍了Sekai（日语意为“世界”），一个高质量的第一人称视角全球视频数据集，配有丰富的世界探索注释。它包含来自100多个国家和地区的750个城市的步行或无人机视角（FPV和UVA）视频，时长超过5000小时。我们开发了高效的工具箱，用于收集、预处理和注释视频（如位置、场景、天气、人群密度、字幕和相机轨迹）。实验验证了数据集的质量，并利用部分数据训练了一个名为YUME（日语意为“梦”）的交互式视频世界探索模型。我们相信Sekai将推动视频生成和世界探索领域的发展，并激发有价值的应用。

</details>


### [95] [Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model](https://arxiv.org/abs/2506.15682)
**中文标题：进化缓存加速现成扩散模型**

*Anirud Aggarwal,Abhinav Shrivastava,Matthew Gwilliam*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ECAD的遗传算法，通过学习高效的缓存调度策略，显著加速扩散模型的推理速度，同时保持生成质量，适用于多种模型和分辨率。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成高质量图像时存在推理速度慢和计算成本高的问题。现有方法依赖固定启发式规则，导致加速效果有限或泛化能力差。本文旨在解决这一问题。

研究方法: ECAD是一种遗传算法，通过少量校准提示学习高效的缓存调度策略，形成帕累托前沿。无需修改网络参数或参考图像，支持细粒度的质量-延迟权衡控制。

研究结果: 在PixArt-alpha、PixArt-Sigma和FLUX-1.dev等模型上，ECAD显著提升了推理速度（如PixArt-alpha从2.35倍加速到2.58倍），并在COCO FID等指标上优于现有方法。

研究结论: ECAD是一种可扩展且泛化能力强的扩散模型加速方法，适用于不同模型和分辨率，为实际应用提供了高效解决方案。

中文摘要: 扩散基图像生成模型在生成高质量合成内容方面表现出色，但其推理速度慢且计算成本高。先前工作尝试通过缓存和重用扩散变换器中的特征来缓解这一问题，但这些方法依赖固定启发式规则，导致加速效果有限或泛化能力差。我们提出进化缓存加速扩散模型（ECAD），这是一种遗传算法，仅需少量校准提示即可学习高效的、针对特定模型的缓存调度策略，形成帕累托前沿。ECAD无需修改网络参数或参考图像，能显著提升推理速度，支持细粒度的质量-延迟权衡控制，并适应不同扩散模型。值得注意的是，ECAD学习的调度策略能有效泛化到校准阶段未见的分辨率和模型变体。我们在PixArt-alpha、PixArt-Sigma和FLUX-1.dev上评估ECAD，使用多种指标（FID、CLIP、Image Reward）和多样基准（COCO、MJHQ-30k、PartiPrompts），结果表明ECAD优于现有方法。在PixArt-alpha上，ECAD找到的调度策略在COCO FID上比之前最优方法提升4.47分，同时将推理加速从2.35倍提高到2.58倍。我们的结果表明，ECAD是一种可扩展且泛化能力强的扩散模型加速方法。项目网站和代码已公开。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [96] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
**中文标题：具身网络代理：为集成代理智能搭建物理与数字领域的桥梁**

*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

主要分类: cs.AI

摘要简述: 本文提出了一种新型AI代理范式——具身网络代理，通过整合物理世界与数字世界的智能，解决需要跨领域推理的任务。研究开发了统一的仿真平台和基准测试，揭示了当前AI系统与人类能力的差距。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI代理多为孤立系统，要么专注于数字信息处理，要么局限于物理世界交互，难以完成需要两者结合的任务（如根据在线食谱烹饪）。本文旨在打破这种隔离，实现物理与数字智能的融合。

研究方法: 研究首先开发了具身网络代理任务环境，这是一个整合了真实3D环境和功能性网络接口的统一仿真平台。在此基础上，构建并发布了具身网络代理基准测试，涵盖烹饪、导航、购物等多种任务。

研究结果: 实验结果显示，当前最先进的AI系统在跨领域推理任务中与人类能力存在显著差距，为具身认知与网络知识访问的交叉研究提出了挑战与机遇。

研究结论: 具身网络代理为AI代理的跨领域智能提供了新方向，相关数据集、代码和平台已公开，为未来研究奠定了基础。

中文摘要: 当前的AI代理多为孤立系统——它们要么在线获取并推理大量数字信息，要么通过具身感知、规划和行动与物理世界交互，但很少同时具备这两种能力。这种分离限制了它们解决需要物理与数字智能结合的任务的能力，例如根据在线食谱烹饪、利用动态地图数据导航或借助网络知识解读现实世界地标。我们提出了具身网络代理，这是一种新型AI代理范式，能够无缝连接具身智能与网络规模推理。为实现这一概念，我们首先开发了具身网络代理任务环境，这是一个整合了真实3D室内外环境与功能性网络接口的统一仿真平台。基于此平台，我们构建并发布了具身网络代理基准测试，涵盖烹饪、导航、购物、旅游和地理定位等多种任务，均需跨物理与数字领域的协同推理，以系统评估跨领域智能。实验结果显示，当前最先进的AI系统与人类能力之间存在显著差距，为具身认知与网络知识访问的交叉研究提出了挑战与机遇。所有数据集、代码和网站均已公开，项目页面为https://embodied-web-agent.github.io/。

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [97] [Intrinsic and Extrinsic Organized Attention: Softmax Invariance and Network Sparsity](https://arxiv.org/abs/2506.15541)
**中文标题：内在与外在组织注意力：Softmax不变性与网络稀疏性**

*Oluwadamilola Fasina,Ruben V. C. Pohle,Pei-Chun Su,Ronald R. Coifman*

主要分类: math.NA

摘要简述: 本文研究了Transformer中自注意力机制的内在（注意力头内部）和外在（注意力头之间）结构，证明了自注意力机制对softmax激活的不变性，并通过分层组织方法分析了网络结构，展示了其在模型剪枝和架构比较中的应用。


<details>
  <summary>详细信息</summary>
研究动机: 研究自注意力机制的结构特性，探索其softmax不变性及网络稀疏性，为模型的可解释性和实际应用（如剪枝）提供理论基础和方法支持。

研究方法: 通过理论分析（如拟微分计算）证明softmax不变性，并利用分层组织方法构建查询、键和注意力头轴的分层树结构，结合视觉和语言Transformer进行实验验证。

研究结果: 发现自注意力机制对softmax具有不变性，分层组织方法能有效揭示网络稀疏性，为模型剪枝和架构比较提供了实用工具。

研究结论: 研究为自注意力机制的可解释性分析提供了新视角，其分层组织方法在模型优化和比较中具有实际应用价值。

中文摘要: 本文研究了Transformer中自注意力机制的内在（注意力头内部）和外在（注意力头之间）结构。通过拟微分计算，我们获得了自注意力机制对softmax激活不变性的理论证据（并通过计算示例支持），这依赖于注意力头的内在组织。此外，我们利用现有的张量分层组织方法，通过构建查询、键和注意力头轴的分层划分树来研究网络结构。这种组织具有重要意义，因为它允许在几何结构上高效执行常见的信号处理任务，其中组织的网络3-张量表现出规律性。我们通过可视化注意力头的分层树结构和扩散图嵌入，以及通过研究网络稀疏性（利用双Haar基和三Haar基对查询、键和注意力头空间的扩展系数）来定性和定量地展示这一点。为了展示理论和方法的实用性，我们提供了基于视觉和语言Transformer的计算示例。这些发现的影响有两方面：（1）为可解释性分析提供了理论支持，并可用于下游可解释性任务；（2）网络3-张量组织可用于实际应用，如模型剪枝（基于网络稀疏性）和网络架构比较。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [98] [Analyzing Character Representation in Media Content using Multimodal Foundation Model: Effectiveness and Trust](https://arxiv.org/abs/2506.14799)
**中文标题：基于多模态基础模型的媒体内容角色表征分析：有效性与信任度**

*Evdoxia Taka,Debadyuti Bhattacharya,Joanne Garde-Hansen,Sanjay Sharma,Tanaya Guha*

主要分类: cs.HC

摘要简述: 本文提出了一种基于多模态基础模型（CLIP）的媒体内容角色表征分析工具，并通过用户研究验证了其有效性和公众信任度。研究发现，用户认为工具总体有用，但对AI生成结果的信任度中等偏低。


<details>
  <summary>详细信息</summary>
研究动机: 尽管现有技术能够量化媒体内容中角色的性别和年龄分布，但缺乏对公众实际需求和信任度的研究。本文旨在填补这一空白，探讨AI生成的角色表征数据对公众的实用性和可信度。

研究方法: 基于CLIP模型开发了一种角色表征分析工具，用于量化视觉媒体中角色的性别和年龄分布，并设计了适合普通观众的可视化界面。随后通过用户研究，评估工具的有用性和AI生成结果的信任度。

研究结果: 用户能够通过可视化界面理解角色分布数据，并认为工具总体有用，但希望增加更多人口统计类别和角色上下文信息。用户对AI生成的性别和年龄数据的信任度中等偏低，但不反对在此领域使用AI。

研究结论: 本文的工具在角色表征分析中具有实用性，但需改进以提升用户信任度。未来研究可扩展更多人口统计维度和上下文信息。

中文摘要: 近年来，人工智能的进步使得大规模自动化分析复杂媒体内容成为可能，并能生成关于角色表征（如性别和年龄）的可操作见解。以往研究侧重于通过多种机器学习模型从音频/视频/文本中量化表征，但未考虑受众的参与。我们提出疑问：即使角色在人口统计维度上的分布数据可用，这些数据对公众的实际用途是什么？他们是否信任AI模型生成的数字？本文通过用户研究回答了这些问题，并提出了一种基于AI的角色表征与可视化工具。该工具基于对比语言图像预训练（CLIP）基础模型，分析视觉屏幕数据以量化角色在年龄和性别维度上的表征。我们还设计了适合普通观众的有效可视化方案。随后，我们通过用户研究，评估了以可视化形式呈现的AI生成结果对选定电影的有用性和可信度。研究发现，参与者能够通过可视化理解分析结果，并认为工具“总体有用”，但也希望增加更多人口统计类别和角色上下文信息。参与者对AI生成的性别和年龄数据的信任度中等偏低，但并不反对在此领域使用AI。工具代码、基准测试和用户研究数据可在此处获取：https://anonymous.4open.science/r/Character-Representation-Media-FF7B

</details>


### [99] [The Hardness of Achieving Impact in AI for Social Impact Research: A Ground-Level View of Challenges & Opportunities](https://arxiv.org/abs/2506.14829)
**中文标题：AI社会影响研究中实现实际影响的困难：挑战与机遇的基层视角**

*Aditya Majumdar,Wenbo Zhang,Kashvi Prawal,Amulya Yadav*

主要分类: cs.HC

摘要简述: 本文探讨了AI社会影响研究（AI4SI）中实现实际影响的困难，分析了合作、沟通和操作层面的挑战，并提出了改进策略。


<details>
  <summary>详细信息</summary>
研究动机: 尽管AI4SI项目旨在通过AI解决社会问题（如医疗和社会正义），但实际影响有限。本文旨在揭示阻碍AI4SI项目从概念验证阶段过渡到规模化部署的多重因素。

研究方法: 通过对六位领先AI4SI研究者的半结构化访谈，并结合作者自身经验，进行主题分析，识别部署中的关键障碍。

研究结果: 研究发现，结构性和组织性、沟通、协作及操作层面的挑战是阻碍AI4SI项目实际落地的主要障碍。同时，总结了最佳实践和可行策略。

研究结论: 本文为AI4SI研究者和合作组织提供了实用指南，帮助其更有效地开展具有社会影响力的AI合作。

中文摘要: 为应对联合国可持续发展目标（SDGs），AI社会影响（AI4SI）项目致力于利用AI解决医疗、社会正义等领域的社会问题。然而，尽管AI4SI受到广泛关注，实现实际影响仍面临重大挑战。例如，寻找并激励愿意共同设计和部署AI解决方案的合作者往往困难重重。即使建立合作关系，许多AI4SI项目仍难以超越概念验证阶段，无法实现规模化生产。此外，AI4SI研究者面临的独特挑战在更广泛的AI社区中并未得到充分认可，这类工作常被视为应用性较强，不符合核心AI领域对创新性的传统标准。本文通过诊断阻碍AI4SI合作实现实际影响的多重因素，揭示了研究中的各种挑战。基于对六位领先AI4SI研究者的半结构化访谈及作者自身经验，本文探讨了开发和部署具有社会影响力的AI解决方案的日常困难。通过主题分析，我们识别出结构性和组织性、沟通、协作及操作层面的挑战是部署的主要障碍。尽管没有简单解决方案，但我们从访谈和自身工作中总结了最佳实践和可行策略。希望本文能为AI4SI研究者和合作组织提供实用参考，助力更有效的社会影响力AI合作。

</details>


### [100] [Insights Informed Generative AI for Design: Incorporating Real-world Data for Text-to-Image Output](https://arxiv.org/abs/2506.15008)
**中文标题：基于真实世界数据的生成式AI设计洞察：为文本到图像输出融入可持续性指标**

*Richa Gupta,Alexander Htet Kyaw*

主要分类: cs.HC

摘要简述: 本文提出了一种结合DALL-E 3和材料数据集的新方法，通过后处理模块为AI生成的设计图像添加可持续性指标和材料使用数据，帮助设计师评估环境影响并优化设计决策。


<details>
  <summary>详细信息</summary>
研究动机: 生成式AI（如文本到图像模型）虽能快速生成视觉设计，但缺乏可操作的数据支持。本文旨在通过整合可持续性指标，弥补这一不足，推动生态友好的设计实践。

研究方法: 提出了一种新流程：首先用DALL-E 3生成室内设计图像，随后通过后处理模块识别图像中的主要材料，并结合材料字典中的二氧化碳当量（CO2e）数据，为设计师提供环境影响的量化指标。

研究结果: 用户测试表明，引入可持续性指标（如CO2e数据）能显著提升设计的生态意识，但也可能导致决策疲劳和满意度下降。尽管如此，多数参与者表示愿意将可持续性原则纳入工作流程。

研究结论: 研究展示了在AI辅助设计中平衡设计自由与实用约束的重要性，为数据驱动的生态设计提供了可行路径。

中文摘要: 生成式AI（尤其是文本到图像模型）通过将概念快速转化为视觉设计，彻底改变了室内建筑设计领域。然而，这些生成的图像虽然视觉上吸引人，却往往缺乏对设计师有用的数据。本文提出了一种新方法，将DALL-E 3与材料数据集结合，为AI生成的设计图像添加可持续性指标和材料使用数据。在模型生成设计图像后，后处理模块会识别图像中的前十大材料，并从通用材料字典中匹配其二氧化碳当量（CO2e）值。这种方法使设计师能够立即评估环境影响并优化设计提示。通过三项用户测试（1. 未提及可持续性；2. 提示前告知可持续性目标；3. 提示前告知可持续性目标并在输出中包含CO2e数据），定性与定量分析表明，第三种测试显著提升了设计的生态意识，但也可能引发决策疲劳和满意度下降。尽管如此，多数参与者表示在第三种测试中会将可持续性原则纳入工作流程，凸显了整合指标对推动生态实践的潜力。研究结果展示了在AI辅助设计中平衡设计自由与实用约束的重要性，为数据驱动的整体解决方案提供了明确路径。

</details>


### [101] [Mapping Caregiver Needs to AI Chatbot Design: Strengths and Gaps in Mental Health Support for Alzheimer's and Dementia Caregivers](https://arxiv.org/abs/2506.15047)
**中文标题：将护理者需求映射到AI聊天机器人设计：阿尔茨海默病和痴呆症护理者心理健康支持的优劣势分析**

*Jiayue Melissa Shi,Dong Whi Yoo,Keran Wang,Violeta J. Rodriguez,Ravi Karkar,Koustuv Saha*

主要分类: cs.HC

摘要简述: 本文研究了阿尔茨海默病及相关痴呆症（AD/ADRD）家庭护理者对AI聊天机器人的需求和期望，开发了基于GPT-4o的聊天机器人Carey，并通过访谈揭示了六大需求主题及其设计建议。


<details>
  <summary>详细信息</summary>
研究动机: AD/ADRD家庭护理者面临巨大的心理和实际挑战，但AI聊天机器人如何满足其需求尚不明确。本文旨在填补这一空白，探索护理者对AI技术的接受度和需求。

研究方法: 开发了基于GPT-4o的聊天机器人Carey，并通过16名护理者的半结构化访谈和情景驱动交互，采用归纳编码和主题分析方法，系统分析其需求和期望。

研究结果: 研究揭示了护理者的六大需求主题：即时信息获取、情感支持、安全披露空间、危机管理、个性化服务和数据隐私，并分析了AI聊天机器人在这些方面的优势与不足。

研究结论: 研究为设计更贴近护理者需求的AI系统提供了理论和实践指导，强调了主动、可信和以护理者为中心的设计理念。

中文摘要: 阿尔茨海默病及相关痴呆症（AD/ADRD）的家庭护理者面临巨大的情感和实际挑战，使其更容易产生压力、焦虑和抑郁。尽管生成式AI（尤其是大型语言模型LLMs）为心理健康支持提供了新机遇，但护理者如何感知和利用这些技术尚不清楚。为填补这一空白，我们开发了基于GPT-4o的聊天机器人Carey，旨在为AD/ADRD护理者提供信息和情感支持。通过Carey作为技术探针，我们对16名家庭护理者进行了情景驱动的半结构化访谈，并采用归纳编码和反思性主题分析方法，系统梳理了护理者的六大需求主题：即时信息获取、情感支持、安全披露空间、危机管理、个性化服务和数据隐私。针对每个主题，我们还分析了护理者需求与担忧之间的微妙张力。研究提出了护理者需求、AI聊天机器人优势与不足的映射关系及设计建议。研究结果为设计更主动、可信且以护理者为中心的AI系统提供了理论和实践指导，以更好地满足AD/ADRD护理者不断变化的心理健康需求。

</details>


### [102] [Accessible Gesture-Driven Augmented Reality Interaction System](https://arxiv.org/abs/2506.15189)
**中文标题：可访问的手势驱动增强现实交互系统**

*Yikan Wang*

主要分类: cs.HC

摘要简述: 本文提出了一种基于手势的增强现实交互系统，利用深度学习识别手势，并通过联邦学习和强化学习优化界面，显著提升了运动障碍用户的任务完成效率和满意度。


<details>
  <summary>详细信息</summary>
研究动机: 增强现实（AR）的交互通常依赖精确输入，对运动障碍或灵活性受限的用户不友好。本研究旨在通过手势识别技术提升AR的可访问性。

研究方法: 系统结合视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，采用联邦学习保护用户隐私，并通过强化学习优化界面布局和交互模式。

研究结果: 实验表明，该系统使运动障碍用户的任务完成效率提升20%，用户满意度提高25%，显著优于传统AR系统。

研究结论: 该研究为AR交互提供了更包容的解决方案，提升了可访问性和可扩展性，为运动障碍用户带来更好的体验。

中文摘要: 增强现实（AR）提供了沉浸式交互体验，但由于依赖精确输入方法，对运动障碍或灵活性受限的用户仍不够友好。本研究提出了一种基于手势的AR交互系统，利用深度学习从可穿戴传感器和摄像头中识别手部和身体手势，并根据用户能力调整界面。系统采用视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，并通过联邦学习实现跨用户的隐私保护模型训练。强化学习用于优化菜单布局和交互模式等界面元素。实验表明，与传统AR系统相比，该系统使运动障碍用户的任务完成效率提升20%，用户满意度提高25%。该方法显著提升了AR的可访问性和可扩展性。关键词：深度学习、联邦学习、手势识别、增强现实、可访问性、人机交互

</details>


### [103] [Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI](https://arxiv.org/abs/2506.15468)
**中文标题：基于Metropolis-Hastings互动的人类与AI协同创造学习**

*Ryota Okumura,Tadahiro Taniguchi,Akira Taniguchi,Yoshinobu Hagiwara*

主要分类: cs.HC

摘要简述: 本文提出了一种名为‘协同创造学习’的新范式，通过人类与AI（生物与人工代理）的互动，整合双方的部分感知信息与知识，构建共享的外部表征，即符号涌现。与传统AI的单向知识传授不同，该方法解决了不同模态信息整合的挑战。通过基于Metropolis-Hastings命名游戏（MHNG）的实验，研究发现人类与MH-based AI代理的互动显著提升了分类准确性，并实现了更强的共享符号系统收敛。


<details>
  <summary>详细信息</summary>
研究动机: 传统AI学习通常依赖单向知识传授，难以整合人类与AI之间不同模态的信息。本文旨在探索一种协同创造学习范式，通过人类与AI的互动，动态对齐感知经验，实现符号涌现，从而推动共生AI系统的发展。

研究方法: 研究采用基于Metropolis-Hastings命名游戏（MHNG）的分散式贝叶斯推理机制，设计了一个在线实验。69名参与者与三种计算机代理（MH-based、总是接受或总是拒绝）在部分可观测条件下进行联合注意力命名游戏（JA-NG）。通过对比分析，验证了协同创造学习的效果。

研究结果: 实验结果表明，与MH-based AI代理互动的人类-AI组合显著提高了分类准确性，并更趋近于共享符号系统的收敛。此外，人类接受行为与MH衍生的接受概率高度一致。这为协同创造学习在人类-AI互动中的涌现提供了首个实证证据。

研究结论: 本文通过MHNG互动模型，首次实证了人类与AI协同创造学习的可能性，为共生AI系统的动态感知对齐开辟了新途径。这一范式有望推动AI从‘向人类学习’转向‘与人类共同学习’的转变。

中文摘要: 我们提出了一种名为‘协同创造学习’的新范式，通过人类与AI（生物与人工代理）的互动，整合双方的部分感知信息与知识，构建共享的外部表征，即符号涌现。与传统AI的单向知识传授不同，该方法解决了不同模态信息整合的挑战。我们通过基于Metropolis-Hastings命名游戏（MHNG）的人类-AI互动模型进行实证测试。在一项在线实验中，69名参与者与三种计算机代理（MH-based、总是接受或总是拒绝）在部分可观测条件下进行联合注意力命名游戏（JA-NG）。结果显示，与MH-based代理互动的人类-AI组合显著提高了分类准确性，并实现了更强的共享符号系统收敛。此外，人类接受行为与MH衍生的接受概率高度一致。这些发现为协同创造学习在人类-AI互动中的涌现提供了首个实证证据，为共生AI系统的动态感知对齐开辟了新途径。

</details>


### [104] [Optimizing Web-Based AI Query Retrieval with GPT Integration in LangChain A CoT-Enhanced Prompt Engineering Approach](https://arxiv.org/abs/2506.15512)
**中文标题：基于LangChain框架的GPT集成优化Web AI查询检索：一种CoT增强的提示工程方法**

*Wenqi Guan,Yang Fang*

主要分类: cs.HC

摘要简述: 本文提出了一种通过将GPT模型集成到LangChain框架中，结合CoT推理和提示工程，优化远程学习资源检索的新方法，显著提升了检索结果的精确性和相关性。


<details>
  <summary>详细信息</summary>
研究动机: 当前远程学习资源的检索缺乏深度，无法满足学生对复杂查询的需求。本文旨在通过结合GPT模型和LangChain框架，提升检索结果的上下文丰富性和个性化。

研究方法: 研究采用GPT模型与LangChain框架集成，利用CoT（思维链）推理和提示工程技术，优化检索过程，确保结果更精确且符合学生需求。

研究结果: 实验表明，该方法在用户满意度和学习效果上优于传统LLM模型，显著提升了检索结果的全面性和相关性。

研究结论: 通过GPT与LangChain的结合及CoT推理，本研究为远程学习资源检索提供了一种高效且个性化的解决方案，具有实际应用价值。

中文摘要: 大型语言模型为远程学习等教育活动带来了革命性变化。然而，当前远程学习资源的检索缺乏深度，无法满足复杂学生查询的需求。本研究提出了一种新颖方法，通过在LangChain框架中集成基于GPT的模型，结合CoT推理和提示工程技术，优化远程学习资源的检索。该框架旨在提高检索结果的精确性和相关性，提供更全面且上下文丰富的解释和资源，以满足学生的个性化需求。我们还评估了该方法与典型LLM模型的效果，结果显示其在用户满意度和学习效果上均有显著提升。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [105] [Efficient Serving of LLM Applications with Probabilistic Demand Modeling](https://arxiv.org/abs/2506.14851)
**中文标题：基于概率需求建模的高效大语言模型应用服务**

*Yifei Liu,Zuo Gan,Zhenghao Gan,Weiye Wang,Chen Chen,Yizhou Shan,Xusheng Chen,Zhenhua Han,Yifei Zhu,Shixuan Sun,Minyi Guo*

主要分类: cs.DC

摘要简述: 本文提出了一种基于概率需求图（PDGraph）的高效大语言模型（LLM）应用服务系统Hermes，通过优化调度顺序和预热后端，显著提升了服务效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有LLM应用服务系统将资源需求视为黑箱，导致排队顺序不当和后端预热延迟，影响端到端效率。本文旨在通过概率需求建模解决这些问题。

研究方法: 提出概率需求图（PDGraph）模型，并基于此设计Hermes系统，采用Gittins策略优化调度顺序，同时利用PDGraph模型在适当时机预热后端。

研究结果: 实验表明，Hermes能将LLM应用的平均完成时间降低70%以上，P95完成时间降低80%以上。

研究结论: Hermes通过概率需求建模和智能调度，显著提升了LLM应用的服务效率，为动态需求场景提供了高效解决方案。

中文摘要: 基于大语言模型（LLMs）的应用通过一系列任务解决现实问题，其需求在不同后端上呈现动态变化。现有服务系统将LLM应用的资源需求视为黑箱，导致排队顺序不当和后端预热延迟，从而影响端到端效率。我们发现，LLM应用的资源需求可通过概率需求图（PDGraph）进行通用且准确的建模。为此，我们提出Hermes系统，利用PDGraph实现高效服务。面对概率需求描述，Hermes采用Gittins策略确定调度顺序，以最小化应用平均完成时间，并利用PDGraph模型在适当时机预热后端。多样化的LLM应用实验证实，Hermes能显著提升服务效率，平均完成时间降低70%以上，P95完成时间降低80%以上。

</details>


### [106] [Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching](https://arxiv.org/abs/2506.14852)
**中文标题：通过测试时计划缓存实现LLM代理的高效低成本服务**

*Qizheng Zhang,Michael Wornow,Kunle Olukotun*

主要分类: cs.DC

摘要简述: 本文提出了一种名为“代理计划缓存”的新方法，通过提取、存储和重用结构化计划模板，显著降低基于LLM的代理应用的服务成本，平均节省46.62%的费用。


<details>
  <summary>详细信息</summary>
研究动机: 基于LLM的代理应用在复杂工作流中表现出色，但因其高昂的规划和推理成本而受限。现有的LLM缓存技术（如上下文缓存和语义缓存）主要针对聊天机器人设计，无法满足依赖外部数据或环境上下文的代理应用需求。因此，需要一种更高效的成本优化方案。

研究方法: 本文提出代理计划缓存方法，从代理执行的规划阶段提取结构化计划模板，通过关键词提取匹配新请求与缓存计划，并利用轻量级模型将模板适配到具体任务上下文中。

研究结果: 在多个实际代理应用中的评估显示，该方法平均可节省46.62%的成本，同时保持性能不变。

研究结论: 代理计划缓存为基于LLM的代理应用提供了一种高效且成本优化的服务方案，可无缝集成到现有LLM服务基础设施中。

中文摘要: 基于LLM的代理应用在复杂工作流中展现出卓越能力，但由于大量规划和推理需求，其服务成本高昂。现有的LLM缓存技术（如上下文缓存和语义缓存）主要面向聊天机器人设计，无法满足依赖外部数据或环境上下文的代理应用需求。为此，我们提出代理计划缓存，这是一种新颖方法，通过从代理应用的规划阶段提取、存储、适配和重用结构化计划模板，以降低服务成本。与传统语义缓存不同，我们的系统在测试时从已完成的代理执行中提取计划模板，利用关键词提取匹配新请求与缓存计划，并通过轻量级模型将模板适配到具体任务上下文中。在多个实际代理应用中的评估表明，该系统平均可节省46.62%的成本，同时保持性能不变，为基于LLM的代理服务提供了一种高效的补充解决方案。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [107] [Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](https://arxiv.org/abs/2506.15290)
**中文标题：基于服装感知扩散模型的松散稀疏惯性传感器人体运动捕捉**

*Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz*

主要分类: cs.GR

摘要简述: 本文提出了一种基于稀疏且松散附着惯性传感器（IMU）的全身人体姿态估计新任务，通过模拟数据和扩散模型解决传感器松散附着带来的挑战，并结合服装参数提升模型表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有惯性传感器运动捕捉方法通常假设传感器紧密附着于人体，但实际场景中这一假设常不成立。本文旨在解决稀疏且松散附着IMU传感器的全身姿态估计问题。

研究方法: 从现有服装感知运动数据集中模拟松散IMU数据，开发基于Transformer的扩散模型，合成松散IMU数据并估计人体姿态，同时结合服装参数训练模型。

研究结果: 实验表明，基于模拟和合成数据训练的扩散模型在定量和定性上均优于现有方法，为未来研究开辟了新方向。

研究结论: 本文提出的方法在松散附着IMU传感器场景中表现优异，结合服装参数进一步提升了模型的表达能力，为实际应用提供了新思路。

中文摘要: 稀疏惯性传感器的运动捕捉因其便携性和无遮挡问题，相比基于摄像头的追踪显示出巨大潜力。现有方法通常假设IMU传感器紧密附着于人体，但这一假设在实际场景中常不成立。本文提出了一种基于稀疏且松散附着IMU传感器的全身人体姿态估计新任务。为解决此任务，我们从现有服装感知人体运动数据集中模拟IMU记录，开发了基于Transformer的扩散模型，用于合成松散IMU数据并基于此挑战性数据估计人体姿态。此外，我们表明，在训练模型时结合服装相关参数，能有效保持表达能力并增强对松散或紧身服装引入变化的捕捉能力。实验表明，我们提出的基于模拟和合成数据训练的扩散方法在定量和定性上均优于现有方法，为未来研究开辟了有前景的方向。

</details>


### [108] [One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning](https://arxiv.org/abs/2506.15312)
**中文标题：基于生成扩散先验与指令优化的一击式野外人脸素描合成**

*Han Wu,Junyao Li,Kangbo Zhao,Sen Zhang,Yukai Shi,Liang Lin*

主要分类: cs.GR

摘要简述: 本文提出了一种基于扩散模型的一击式人脸素描合成方法，通过优化文本指令生成高质量素描，解决了传统方法数据稀缺和人力成本高的问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统人脸素描合成方法依赖大量训练数据，面临数据稀缺和高人力成本问题。本文旨在通过扩散模型和指令优化，实现一击式高质量素描合成。

研究方法: 利用扩散模型优化文本指令，通过梯度优化生成素描。引入新基准数据集OS-Sketch，包含400对多样化照片-素描图像，用于训练和评估。

研究结果: 实验表明，该方法能在一击式场景下将多种照片转化为逼真且一致的素描，相比其他方法更具便利性和广泛适用性。

研究结论: 本文方法为数据稀缺场景下的人脸素描合成提供了高效解决方案，具有实际应用潜力。数据集已公开。

中文摘要: 人脸素描合成技术旨在将人脸照片转化为素描。现有研究主要依赖大量照片-素描样本对进行训练，但大规模判别学习方法面临数据稀缺和高人力成本问题。训练数据不足时，生成性能显著下降。本文提出一种基于扩散模型的一击式人脸素描合成方法。通过优化扩散模型上的文本指令，利用梯度优化生成的指令进行推理。为更准确模拟真实场景并全面评估方法效果，我们引入新基准数据集OS-Sketch，包含400对多样化照片-素描图像，涵盖不同风格、背景、年龄、性别、表情和光照等。为进行稳健的分布外评估，每次仅选取一对图像训练，其余用于推理。大量实验表明，该方法能在一击式场景下将多种照片转化为逼真且高度一致的素描，相比其他方法更具便利性和广泛适用性。数据集已公开于：https://github.com/HanWu3125/OS-Sketch

</details>


### [109] [Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards](https://arxiv.org/abs/2506.15684)
**中文标题：Nabla-R2D3：基于2D奖励的高效3D扩散模型对齐方法**

*Qingming Liu,Zhen Liu,Dinghuai Zhang,Kui Jia*

主要分类: cs.GR

摘要简述: Nabla-R2D3是一种基于2D奖励的高效3D扩散模型对齐框架，通过强化学习优化3D生成质量，显著提升模型对齐能力和样本效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D生成模型（如扩散模型）在生成高质量、逼真的3D内容时，常因无法准确遵循指令、对齐人类偏好或生成逼真的纹理和几何结构而表现不佳。Nabla-R2D3旨在解决这些问题。

研究方法: 基于Nabla-GFlowNet方法，Nabla-R2D3通过2D奖励信号对3D扩散模型进行高效对齐，以奖励梯度匹配的方式优化模型，避免传统微调方法的收敛困难或奖励滥用问题。

研究结果: 实验表明，Nabla-R2D3在少量微调步骤内即可实现更高的奖励分数和更低的前验遗忘，显著优于传统基线方法。

研究结论: Nabla-R2D3为3D生成模型的对齐提供了一种高效且有效的方法，显著提升了生成内容的质量和逼真度。

中文摘要: 生成高质量且逼真的3D资产一直是3D视觉和计算机图形学领域的长期挑战。尽管最先进的生成模型（如扩散模型）在3D生成方面取得了显著进展，但由于其难以准确遵循指令、对齐人类偏好或生成逼真的纹理、几何结构和物理属性，这些模型往往无法达到人工设计内容的水平。本文提出了Nabla-R2D3，一种基于2D奖励的高效强化学习对齐框架，用于优化3D原生扩散模型。该方法基于最近提出的Nabla-GFlowNet方法，通过奖励梯度匹配的方式对模型进行微调。实验表明，与传统的微调基线方法相比，Nabla-R2D3能够在少量微调步骤内实现更高的奖励分数和更低的前验遗忘。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [110] [Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures](https://arxiv.org/abs/2506.15043)
**中文标题：基于CNN-LSTM-GRU架构的高超音速导弹轨迹高级预测**

*Amir Hossein Baradaran*

主要分类: cs.CR

摘要简述: 本文提出了一种结合CNN、LSTM和GRU的混合深度学习模型，用于高精度预测高超音速导弹的复杂轨迹，为防御策略和拦截技术提供了重要支持。


<details>
  <summary>详细信息</summary>
研究动机: 高超音速导弹因其极速和高机动性成为重大威胁，准确预测其轨迹对防御系统至关重要。本文旨在通过先进机器学习技术提升预测能力。

研究方法: 采用CNN-LSTM-GRU混合架构，结合卷积神经网络和循环神经网络的优点，对高超音速导弹的轨迹数据进行建模和预测。

研究结果: 所提方法能够高精度预测高超音速导弹的复杂轨迹，显著提升了防御系统的预测能力。

研究结论: 研究表明，混合深度学习模型在高超音速导弹轨迹预测中具有巨大潜力，为防御技术提供了新的解决方案。

中文摘要: 国防工业的进步对确保国家安全至关重要，能够有效应对新兴威胁。其中，高超音速导弹因其极速和高机动性成为重大挑战，准确预测其轨迹是实施有效反制的关键需求。本文通过结合卷积神经网络（CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）的混合深度学习方法，成功预测了高超音速导弹的复杂轨迹，为防御策略和导弹拦截技术提供了重要贡献。本研究展示了先进机器学习技术在提升防御系统预测能力方面的潜力。

</details>


### [111] [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](https://arxiv.org/abs/2506.15253)
**中文标题：RAS-Eval：面向真实环境中LLM代理安全性的综合评估基准**

*Yuchuan Fu,Xiaohan Yuan,Dongxia Wang*

主要分类: cs.CR

摘要简述: 本文介绍了RAS-Eval，一个用于评估大型语言模型（LLM）代理在动态环境中安全性的综合基准测试工具。通过80个测试案例和3,802个攻击任务，覆盖11种常见弱点类别，评估了6种先进LLM模型，揭示了显著的安全漏洞，攻击平均降低任务完成率36.78%，成功率高达85.65%。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署，缺乏标准化安全评估工具成为问题。本文旨在填补这一空白，提供动态环境中的安全评估基准。

研究方法: RAS-Eval是一个支持模拟和真实工具执行的综合安全基准测试工具，包含80个测试案例和3,802个攻击任务，覆盖11种CWE类别。工具采用JSON、LangGraph和MCP格式实现，并评估了6种先进LLM模型。

研究结果: 攻击显著降低了LLM代理的任务完成率（平均36.78%），在学术环境中攻击成功率达85.65%。更大的模型在安全性上表现更好，验证了规模法则。

研究结论: RAS-Eval揭示了LLM代理在真实环境中的重大安全风险，为未来安全研究提供了基础框架。代码和数据已开源。

中文摘要: 随着大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署，亟需建立强大的安全框架。为解决动态环境中缺乏标准化评估基准的问题，我们提出了RAS-Eval，一个支持模拟和真实工具执行的综合安全基准测试工具。RAS-Eval包含80个测试案例和3,802个攻击任务，覆盖11种常见弱点枚举（CWE）类别，工具采用JSON、LangGraph和模型上下文协议（MCP）格式实现。我们对6种先进LLM模型进行了多样化场景评估，结果揭示了显著的安全漏洞：攻击平均降低了代理任务完成率（TCR）36.78%，在学术环境中的攻击成功率高达85.65%。值得注意的是，规模法则在安全能力上同样适用，更大的模型表现优于小模型。我们的研究揭示了真实环境中代理部署的重大风险，并为未来安全研究提供了基础框架。代码和数据可在https://github.com/lanzer-tree/RAS-Eval获取。

</details>


### [112] [Evaluation Pipeline for systematically searching for Anomaly Detection Systems](https://arxiv.org/abs/2506.15388)
**中文标题：系统搜索异常检测系统的评估流程**

*Florian Rokohl,Alexander Lehnert,Marc Reichenbach*

主要分类: cs.CR

摘要简述: 本文提出了一种基于硬件的异常检测系统，用于实时检测恶意客户端，并通过FPGA满足实时性和功耗限制，同时通过整体系统评估提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 医疗领域的数字化带来了巨大便利，但也成为攻击者的目标，网络安全面临挑战。为了解决网络入侵问题，作者提出了一种实时检测恶意客户端的异常检测系统。

研究方法: 利用FPGA实现硬件上的异常检测系统，以满足实时性和功耗限制，并通过整体系统评估优化性能。

研究结果: 提出的系统能够有效实时检测恶意客户端，并通过FPGA和整体评估实现了高性能。

研究结论: 该异常检测系统在硬件上实现了实时检测，并通过FPGA和整体评估满足了性能和功耗需求，为医疗数字化安全提供了解决方案。

中文摘要: 医疗领域的数字化带来了重大益处，同时也使其成为攻击者的目标，网络安全变得难以保障。为了应对网络入侵者，我们提出了一种基于硬件的异常检测系统，用于实时检测恶意客户端。通过使用FPGA，我们满足了实时性和功耗限制。整体系统性能通过提出的全面系统评估得以实现。

</details>


<div id='stat.OT'></div>

# stat.OT [[Back]](#toc)

### [113] [Next-Generation Conflict Forecasting: Unleashing Predictive Patterns through Spatiotemporal Learning](https://arxiv.org/abs/2506.14817)
**中文标题：下一代冲突预测：通过时空学习释放预测模式**

*Simon P. von der Maase*

主要分类: stat.OT

摘要简述: 本研究提出了一种新型神经网络架构，用于高时空分辨率预测暴力冲突，涵盖三种类型（国家间、非国家间和单边冲突），并在36个月内实现子国家级预测。模型结合分类与回归任务，性能领先，并能量化预测不确定性。


<details>
  <summary>详细信息</summary>
研究动机: 高时空分辨率的暴力冲突预测对研究者和决策者至关重要，但现有方法依赖人工特征工程且性能有限。本研究旨在开发一种无需人工干预、能自主学习的预测模型。

研究方法: 采用基于蒙特卡洛Dropout的LSTM U-Net架构，结合卷积层捕捉空间依赖性和循环结构建模时间动态，仅依赖历史冲突数据，无需手动特征工程。

研究结果: 模型在所有任务中达到领先性能，生成概率估计和事件预期规模，并能量化预测不确定性。此外，模型可扩展性强，支持多数据源整合和辅助变量联合预测。

研究结论: 该模型为早期预警系统、人道主义响应规划和基于证据的和平建设提供了有力工具，其自主学习和扩展性使其具有广泛应用潜力。

中文摘要: 高时空分辨率的暴力冲突预测对研究者和决策者仍是一项核心挑战。本研究提出了一种新型神经网络架构，用于预测三种类型的暴力冲突（国家间、非国家间和单边冲突），并在子国家级（priogrid-month）水平上提前36个月进行预测。模型同时执行分类和回归任务，生成未来事件的概率估计和预期规模。其在所有任务中均达到领先性能，并能生成近似预测后验分布以量化预测不确定性。该架构基于蒙特卡洛Dropout LSTM U-Net，通过卷积层捕捉空间依赖性，并结合循环结构建模时间动态。与许多现有方法不同，它无需人工特征工程，仅依赖历史冲突数据。这一设计使模型能够自主学习暴力冲突背后的复杂时空模式。除了预测性能领先外，该模型还具有高度扩展性：可轻松整合额外数据源并联合预测辅助变量。这些能力使其成为早期预警系统、人道主义响应规划和基于证据的和平建设倡议的有力工具。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [114] [PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series](https://arxiv.org/abs/2506.14786)
**中文标题：PIPE：基于物理信息的位置编码用于卫星图像与时间序列的对齐**

*Haobo Li,Eunseo Jung,Zixin Chen,Zhaowei Wang,Yueya Wang,Huamin Qu,Alexis Kai Hon Lau*

主要分类: cs.LG

摘要简述: 本文提出了一种名为PIPE的轻量级方法，通过物理信息位置编码将物理信息嵌入视觉语言模型，显著提升了多模态对齐和预测精度，尤其在台风强度预测中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态方法主要关注文本数据，而忽略了视觉数据（如卫星图像）中的物理信息。如何有效捕捉视觉数据中的时空物理信息是一个挑战。

研究方法: PIPE方法包含两个创新点：(1) 物理信息位置索引方案，将物理信息映射到位置ID；(2) 变频率位置编码机制，在嵌入空间中编码物理变量的频率信息和令牌顺序。

研究结果: 在最大开源卫星图像数据集上的实验中，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测精度比先前工作提高了12%。

研究结论: PIPE通过嵌入物理信息和顺序信息，显著提升了多模态对齐和预测准确性，为卫星图像和时间序列的对齐提供了有效解决方案。

中文摘要: 多模态时间序列预测在气候科学等领域具有基础性作用，例如利用卫星图像和数值数据预测台风。然而，现有方法主要依赖文本数据，忽略了视觉数据中的物理信息。此外，模型难以有效捕捉视觉数据（如卫星图像）中的时空物理信息。为此，我们提出了一种轻量级方法——物理信息位置编码（PIPE），将物理信息嵌入视觉语言模型。PIPE包含两项关键创新：(1) 物理信息位置索引方案，将物理信息映射到位置ID；(2) 变频率位置编码机制，在嵌入空间中编码物理变量的频率信息和令牌顺序。通过保留物理信息和顺序信息，PIPE显著提升了多模态对齐和预测精度。在最大开源卫星图像数据集上的实验中，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测精度比先前工作提高了12%。代码已提供在补充材料中。

</details>


### [115] [Topology-Aware and Highly Generalizable Deep Reinforcement Learning for Efficient Retrieval in Multi-Deep Storage Systems](https://arxiv.org/abs/2506.14787)
**中文标题：基于拓扑感知和高度泛化的深度强化学习在多深度存储系统中的高效检索**

*Funing Li,Yuan Tian,Ruben Noortwyck,Jifeng Zhou,Liming Kuang,Robert Schulz*

主要分类: cs.LG

摘要简述: 本文提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题，通过图神经网络和Transformer模型结合，显著优化了检索延迟。


<details>
  <summary>详细信息</summary>
研究动机: 现代工业和物流环境中，快速配送服务的扩张对高效率和密度的存储系统需求增加。多深度自动车辆存储和检索系统（AVS/RS）虽能提高存储密度，但面临通道堵塞的挑战。传统方法将同质物品存储在同一通道限制了系统的灵活性和适应性。

研究方法: 提出一种深度强化学习框架，结合图神经网络（GNN）和Transformer模型。GNN编码拓扑和物品信息，Transformer将嵌入映射为全局优先级分配，适用于多样化布局的存储系统。

研究结果: 大量数值实验表明，所提出的神经网络架构优于启发式方法，训练后的智能体在优化检索延迟方面表现出色。

研究结论: 该框架有效解决了多深度存储系统中的检索问题，具有强泛化能力，适用于不同布局的系统。

中文摘要: 在现代工业和物流环境中，快速配送服务的迅速扩张对兼具高效率和密度的存储系统需求日益增加。多深度自动车辆存储和检索系统（AVS/RS）为实现更高存储密度提供了可行方案。然而，这些系统在检索操作中因通道堵塞面临重大挑战。传统方法通过将同质物品存储在同一通道来缓解这一问题，但限制了多深度存储系统的灵活性和适应性。本研究提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题。每个物品关联特定截止日期，目标是最小化总延迟。为有效捕捉系统拓扑，我们引入了一种基于图的状态表示，整合了物品属性和多深度仓库的局部拓扑结构。为处理这一表示，设计了一种新颖的神经网络架构，结合了图神经网络（GNN）和Transformer模型。GNN将拓扑和物品特定信息编码为所有可直接访问物品的嵌入，而Transformer将这些嵌入映射为全局优先级分配。Transformer的强大泛化能力进一步使我们的方法适用于多样化布局的存储系统。大量数值实验，包括与启发式方法的比较，证明了所提出神经网络架构的优越性以及训练智能体在优化检索延迟方面的有效性。

</details>


### [116] [Assembly of Experts: Linear-time construction of the Chimera LLM variants with emergent and adaptable behaviors](https://arxiv.org/abs/2506.14794)
**中文标题：专家组装：线性时间构建具有涌现和适应行为的奇美拉LLM变体**

*Henrik Klagges,Robert Dahlke,Fabian Klemm,Benjamin Merkel,Daniel Klingmann,David A. Reiss,Dan Zecha*

主要分类: cs.LG

摘要简述: 论文提出了一种名为“专家组装”（AoE）的新方法，用于线性时间内构建混合专家模型（MoE）的变体，通过权重插值调整语义特征，生成功能强大且适应性强的子模型。实验构建的DeepSeek R1T“奇美拉”模型在保持智能水平的同时显著提升了效率。


<details>
  <summary>详细信息</summary>
研究动机: 预训练大型语言模型（LLM）需要极高的计算成本（10^13-10^15 FLOPs），效率低下。为了充分利用现有预训练模型的资源，研究提出了一种高效构建子模型的方法。

研究方法: 采用“专家组装”（AoE）方法，通过线性时间内对父模型的权重张量进行插值，调整语义特征的增强或抑制，生成子模型。无需微调或蒸馏即可完成构建。

研究结果: 生成的子模型功能强大且适应性高，DeepSeek R1T“奇美拉”模型结合了父模型的优势，智能水平接近R1，同时输出令牌减少40%，推理速度接近V3。

研究结论: AoE方法能够高效生成功能强大的子模型，为模型复用和优化提供了新思路。

中文摘要: 在预训练过程中，计算一个8位权重的LLM需要10^13-10^15 FLOPs，成本极高且效率低下。为更好地利用预训练模型的巨大投资，我们开发了新的“专家组装”（AoE）构建方法，可在线性时间内生成现有混合专家父模型的功能强大子模型。通过对权重张量进行单独插值，可以增强或抑制父模型的语义特征。
  通过调整父模型权重的比例，我们发现AoE子模型的某些属性逐渐变化，而其他行为特征则出现急剧转变。令人惊讶的是，几乎所有生成的模型都功能完备且强大，这使得模型空间的搜索变得简单。
  我们构建了DeepSeek R1T“奇美拉”，这是一个671B的开放权重混合模型，结合了DeepSeek的V3-0324和R1模型变体。子模型仅继承了R1的路由专家张量，但仍达到接近R1的智能水平，同时输出令牌减少约40%，速度接近V3。无需任何微调或蒸馏，奇美拉展现出比父模型更紧凑、有序的推理能力。

</details>


### [117] [Bound by semanticity: universal laws governing the generalization-identification tradeoff](https://arxiv.org/abs/2506.14797)
**中文标题：语义性约束：泛化与识别权衡的普适规律**

*Marco Nurisso,Jesseba Fernando,Raj Deshpande,Alan Perotti,Raja Marjieh,Steven M. Frankland,Richard L. Lewis,Taylor W. Webb,Declan Campbell,Francesco Vaccarino,Jonathan D. Cohen,Giovanni Petri*

主要分类: cs.LG

摘要简述: 本文揭示了智能系统在表示学习中的泛化与识别权衡的普适规律，证明了有限语义分辨率下模型的泛化概率和识别概率受统一帕累托前沿约束，并通过实验验证了这些规律在复杂模型中的普适性。


<details>
  <summary>详细信息</summary>
研究动机: 智能系统需要同时支持广泛泛化和精确识别的内部表示，但这两者之间存在权衡。本文旨在揭示这种权衡的普适规律，并探讨语义分辨率如何影响模型的表示能力。

研究方法: 通过理论分析，推导出有限语义分辨率下模型的泛化概率和识别概率的封闭表达式，并验证其在噪声、异质空间及多输入情况下的表现。同时，通过训练一个简单的ReLU网络和复杂模型（如卷积神经网络和视觉语言模型）验证理论预测。

研究结果: 研究发现，模型的泛化概率和识别概率受统一帕累托前沿约束，且多输入处理能力会急剧下降至1/n。实验表明，这些规律在简单和复杂模型中均成立，证实了有限语义分辨率的普适性。

研究结论: 本文提供了一个关于泛化-识别权衡的精确理论，揭示了语义分辨率对深度网络和大脑表示能力的根本约束，表明这些规律是普适的，而非仅适用于简单模型。

中文摘要: 智能系统需要部署既能支持广泛泛化又能保持输入身份识别的内部表示。我们揭示了这种权衡的基本限制。对于任何表示相似性随有限语义分辨率ε衰减的模型，我们推导出其正确泛化概率p_S和识别概率p_I的封闭表达式，并将其固定为一个与输入空间几何无关的普适帕累托前沿。将分析扩展到噪声、异质空间及n>2输入的情况，预测了多输入处理能力的急剧1/n崩溃以及p_S的非单调最优值。一个端到端训练的最小ReLU网络重现了这些规律：在学习过程中，分辨率边界自组织形成，且实验的(p_S,p_I)轨迹紧密跟随线性衰减相似性的理论曲线。最后，我们证明这些限制在两种显著更复杂的场景中依然存在——卷积神经网络和最先进的视觉语言模型——证实有限分辨率相似性是一种根本的涌现信息约束，而不仅仅是玩具模型的产物。这些结果共同提供了泛化-识别权衡的精确理论，并阐明了语义分辨率如何塑造深度网络和大脑的表示能力。

</details>


### [118] [ss-Mamba: Semantic-Spline Selective State-Space Model](https://arxiv.org/abs/2506.14802)
**中文标题：ss-Mamba：基于语义样条的选择性状态空间模型**

*Zuochen Ye*

主要分类: cs.LG

摘要简述: 本文提出ss-Mamba，一种新型基础模型，通过结合语义感知嵌入和自适应样条时间编码，在选择性状态空间建模框架中提升时间序列预测性能。该模型在保持高性能的同时显著降低计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer架构在时间序列预测中计算复杂度高，且缺乏对语义信息和复杂时间模式的动态捕捉能力。ss-Mamba旨在解决这些问题，提供更高效且可解释的替代方案。

研究方法: ss-Mamba采用Mamba选择性状态空间模型替代Transformer，结合预训练语言模型初始化的语义索引嵌入和基于样条的Kolmogorov-Arnold网络（KAN），动态捕捉复杂季节性和非平稳时间效应。

研究结果: 实验表明，ss-Mamba在准确性、鲁棒性和可解释性上均优于传统Transformer模型，同时计算复杂度从二次降至线性。

研究结论: ss-Mamba是一种高效且多功能的时间序列预测模型，为传统Transformer提供了性能优越且计算高效的替代方案。

中文摘要: 我们提出ss-Mamba，一种新型基础模型，通过将语义感知嵌入和自适应样条时间编码整合到选择性状态空间建模框架中，提升时间序列预测性能。基于Transformer架构的最新成功，ss-Mamba采用Mamba选择性状态空间模型作为高效替代方案，在保持可比性能的同时，将计算复杂度从二次降至线性。通过预训练语言模型初始化的语义索引嵌入，实现了对未见序列的有效泛化。此外，基于样条的Kolmogorov-Arnold网络（KAN）动态且可解释地捕捉复杂季节性和非平稳时间效应，提供了对传统时间特征编码的强大增强。大量实验评估证实，ss-Mamba在准确性、鲁棒性和可解释性上表现优异，展示了其作为传统Transformer模型在时间序列预测中多功能且计算高效替代方案的潜力。

</details>


### [119] [Training with Confidence: Catching Silent Errors in Deep Learning Training with Automated Proactive Checks](https://arxiv.org/abs/2506.14813)
**中文标题：训练有保障：通过自动化主动检查捕获深度学习训练中的静默错误**

*Yuxuan Jiang,Ziming Zhou,Boyu Xu,Beijie Liu,Runhui Xu,Peng Huang*

主要分类: cs.LG

摘要简述: 本文提出TRAINCHECK框架，通过主动检查方法检测深度学习训练中的静默错误，自动推断适用于DL训练的约束条件，并在训练过程中实时检测错误。实验表明，TRAINCHECK成功检测了18个真实错误，并发现6个未知库bug。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习训练过程复杂，容易发生难以检测和诊断的静默错误。这些错误可能导致训练失败或模型性能下降，亟需一种自动化工具来主动检测和调试。

研究方法: TRAINCHECK框架通过自动推断适用于DL训练的约束条件（不变量），在训练过程中主动检查这些约束条件，从而检测静默错误，并提供调试帮助。

研究结果: 在复现20个真实静默错误实验中，TRAINCHECK成功检测到18个错误，且在一次训练迭代内完成检测。此外，还发现了6个流行训练库中的未知bug。

研究结论: TRAINCHECK通过主动检查方法有效检测深度学习训练中的静默错误，显著提升了训练过程的可靠性和调试效率。

中文摘要: 深度学习（DL）模型的训练过程复杂，容易发生难以检测和诊断的静默错误。本文提出TRAINCHECK框架，采用主动检查方法应对静默训练错误。TRAINCHECK自动推断适用于DL训练的约束条件，并利用这些约束条件在训练过程中主动检测静默错误，同时提供调试支持。为评估TRAINCHECK，我们复现了20个具有不同根源的真实静默训练错误。TRAINCHECK成功在一次训练迭代内检测到18个错误，并发现了6个导致静默错误的流行训练库中的未知bug。

</details>


### [120] [Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints](https://arxiv.org/abs/2506.14821)
**中文标题：在资源受限条件下通过工具增强视觉语言模型的详细视觉推理能力**

*Sunil Kumar,Bowen Zhao,Leo Dirac,Paulina Varshavskaya*

主要分类: cs.LG

摘要简述: 本文提出一种方法，通过结合GRPO学习、简化工具调用接口和优化训练数据，增强视觉语言模型（VLM）在资源受限条件下进行详细视觉推理的能力，并在某些VQA任务中表现优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型模型在推理能力上取得了显著进展，但视觉语言模型（VLMs）在资源受限时仍难以进行详细的视觉推理。本文旨在解决这一问题。

研究方法: 采用Group Relative Policy Optimization（GRPO）训练小规模模型，结合简化的工具调用接口、额外的标记分配以及视觉难度较高的训练数据，以提升模型使用外部工具（如放大功能）的能力。

研究结果: 与类似规模的基线模型相比，该方法在某些视觉问答（VQA）任务中表现更优，能够通过外部工具获取更详细的视觉信息。

研究结论: 通过GRPO学习和优化工具调用策略，可以有效提升VLMs在资源受限条件下的详细视觉推理能力。

中文摘要: 尽管近年来大型模型的推理能力取得了巨大进步，但视觉语言模型（VLMs）在资源受限时仍难以进行详细的视觉推理。为解决这一挑战，我们借鉴了如Deepseek-r1等方法，通过Group Relative Policy Optimization（GRPO）训练小规模模型，使其能够使用外部工具（如放大功能）。最大的收益来自于结合GRPO学习、简单的奖励结构、简化的工具调用接口、为工具调用结果分配额外标记，以及训练数据中视觉难度较高的样本的过表示。与类似规模的基线模型相比，我们的方法在某些视觉问答（VQA）任务中表现更优，这得益于从外部工具获取的详细视觉信息。

</details>


### [121] [FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models](https://arxiv.org/abs/2506.14824)
**中文标题：FedNano：面向预训练多模态大语言模型的轻量级联邦调优**

*Yao Zhang,Hewei Gao,Haokun Chen,Weiguo Li,Yunpu Ma,Volker Tresp*

主要分类: cs.LG

摘要简述: FedNano是一种轻量级联邦学习框架，通过集中服务器上的大型语言模型（LLM）和客户端轻量级模块NanoEdge，解决了多模态大语言模型（MLLMs）在联邦学习中的计算、存储和通信问题，显著降低了客户端负担和通信开销。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在分布式多模态数据和隐私要求严格的场景下面临部署挑战。联邦学习（FL）虽能通过协作训练保护数据隐私，但现有方法假设客户端部署完整模型，对大规模MLLMs不适用。因此，需要一种轻量级解决方案。

研究方法: 提出FedNano框架，将LLM集中在服务器端，客户端仅部署轻量级模块NanoEdge，包含模态特定编码器、连接器和低秩适配器（NanoAdapters）。仅传输NanoAdapter更新，大幅减少存储和通信开销。

研究结果: 实验表明，FedNano显著优于现有联邦学习方法，客户端存储减少95%，通信开销仅为模型参数的0.01%，同时支持异构数据和资源限制。

研究结论: FedNano填补了MLLMs规模与联邦学习可行性之间的鸿沟，为可扩展的分布式多模态AI系统提供了高效解决方案。

中文摘要: 多模态大语言模型（MLLMs）在多模态推理和跨模态检索等任务中表现出色，但由于分布式多模态数据和严格的隐私要求，其在现实场景中的部署面临挑战。联邦学习（FL）通过协作训练模型而无需集中数据提供了一种解决方案。然而，为MLLMs实现FL存在显著挑战，包括高计算需求、有限的客户端能力、巨大的通信成本和异构客户端数据。现有FL方法假设客户端部署完整模型，这一假设因MLLMs的巨大规模和通信需求而失效。为解决这些限制，我们提出FedNano，首个将LLM集中在服务器端并引入轻量级模块NanoEdge的FL框架。NanoEdge采用模态特定编码器、连接器和可训练的低秩适配器（NanoAdapters）。这一设计无需在客户端部署LLM，将客户端存储减少95%，并将通信开销限制为仅模型参数的0.01%。通过仅传输紧凑的NanoAdapter更新，FedNano处理异构客户端数据和资源限制的同时保护隐私。实验表明，FedNano优于现有FL基线，弥合了MLLMs规模与FL可行性之间的差距，实现了可扩展的分布式多模态AI系统。

</details>


### [122] [Optimization of bi-directional gated loop cell based on multi-head attention mechanism for SSD health state classification model](https://arxiv.org/abs/2506.14830)
**中文标题：基于多头注意力机制的双向门控循环单元优化及其在SSD健康状态分类模型中的应用**

*Zhizhao Wen,Ruoxin Zhang,Chao Wang*

主要分类: cs.LG

摘要简述: 本研究提出了一种结合多头注意力机制的BiGRU-MHA混合模型，用于提升SSD健康状态分类的准确性和稳定性，实验结果显示其分类准确率高且泛化能力强。


<details>
  <summary>详细信息</summary>
研究动机: SSD健康状态预测对数据可靠性至关重要，但传统模型存在泛化能力不足的问题，因此需要一种能同时提取时序特征并聚焦关键信息的新方法。

研究方法: 模型结合了BiGRU网络的双向时序建模优势和多头注意力机制，前者捕捉SSD退化特征的前后依赖关系，后者动态分配特征权重以提升对关键健康指标的敏感性。

研究结果: 实验结果表明，模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，性能差距仅0.26%，且ROC曲线下面积（AUC）为0.94，展现了优异的二分类性能。

研究结论: 该研究不仅为SSD健康预测提供了新技术方案，还解决了传统模型的泛化瓶颈，为工业级存储系统的预防性维护提供了实用价值。

中文摘要: 针对SSD健康状态预测在数据可靠性保障中的关键作用，本研究提出了一种结合多头注意力机制的BiGRU-MHA混合模型，以提高存储设备健康分类的准确性和稳定性。该模型创新性地整合了时序特征提取和关键信息聚焦能力。具体而言，它利用BiGRU网络的双向时序建模优势，捕捉SSD退化特征的前后依赖关系；同时，多头注意力机制动态分配特征权重，提升模型对关键健康指标的敏感性。实验结果显示，所提模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，性能差距仅为0.26%，展现了优异的泛化能力。进一步通过受试者工作特征（ROC）曲线分析，测试集的曲线下面积（AUC）为0.94，证实了模型的稳健二分类性能。这项工作不仅为SSD健康预测提供了新的技术途径，还解决了传统模型的泛化瓶颈，为工业级存储系统的预防性维护提供了可验证的实用方法。结果表明，该模型可通过提供早期故障预警显著降低数据丢失风险，并帮助优化维护成本，支持云计算数据中心和边缘存储环境中可靠存储系统的智能决策。

</details>


### [123] [ETS: Open Vocabulary Electroencephalography-To-Text Decoding and Sentiment Classification](https://arxiv.org/abs/2506.14783)
**中文标题：ETS：开放词汇脑电图到文本解码及情感分类**

*Mohamed Masry,Mohamed Amen,Mohamed Elzyat,Mohamed Hamed,Norhan Magdy,Maram Khaled*

主要分类: cs.LG

摘要简述: 本文提出ETS框架，结合脑电图（EEG）与眼动追踪数据，解决开放词汇文本生成和情感分类任务，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法在开放词汇场景下因噪声和变异性表现不佳，本研究旨在通过整合EEG与眼动数据提升解码自然语言的性能。

研究方法: ETS框架整合EEG与同步眼动追踪数据，专注于开放词汇文本生成和情感分类任务。

研究结果: 模型在EEG到文本解码的BLEU和Rouge分数上表现优异，情感分类F1分数提升10%，且能处理多源数据。

研究结论: ETS框架展示了高性能开放词汇EEG到文本系统的潜力，适用于多对象和多源数据。

中文摘要: 利用非侵入性脑电图（EEG）从大脑活动中解码自然语言仍是神经科学与机器学习的重大挑战，尤其是在开放词汇场景下，传统方法因噪声和变异性表现不佳。以往研究在小封闭词汇上取得高准确率，但在开放词汇上仍存在困难。本研究提出ETS框架，整合EEG与同步眼动追踪数据，解决两项关键任务：（1）开放词汇文本生成；（2）感知语言的情感分类。我们的模型在EEG到文本解码的BLEU和Rouge分数上表现优异，情感分类F1分数提升10%，显著优于监督基线。此外，模型能处理多对象和多源数据，展示了高性能开放词汇EEG到文本系统的潜力。

</details>


### [124] [Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective](https://arxiv.org/abs/2506.14965)
**中文标题：从跨领域视角重新审视强化学习在大型语言模型推理中的应用**

*Zhoujun Cheng,Shibo Hao,Tianyang Liu,Fan Zhou,Yutao Xie,Feng Yao,Yuexin Bian,Yonghao Zhuang,Nilabjo Dey,Yuheng Zha,Yi Gu,Kun Zhou,Yuqi Wang,Yuan Li,Richard Fan,Jianshu She,Chengqian Gao,Abulhair Saparov,Haonan Li,Taylor W. Killian,Mikhail Yurochkin,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

主要分类: cs.LG

摘要简述: 本文通过跨领域视角重新审视强化学习（RL）在大型语言模型（LLM）推理中的应用，提出Guru数据集和模型，展示RL在不同领域的表现差异，并实现性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前关于RL在LLM推理中的研究主要集中在数学和代码领域，缺乏对其他通用推理领域的探索。本文旨在填补这一空白，通过构建多领域数据集Guru，验证RL在广泛推理任务中的适用性。

研究方法: 作者构建了包含92K个可验证示例的Guru数据集，涵盖数学、代码、科学、逻辑、模拟和表格六个领域，并通过领域特定的奖励设计、去重和过滤确保数据质量。基于此，重新评估RL在LLM推理中的作用，并训练了Guru-7B和Guru-32B模型。

研究结果: 实验表明，RL在不同领域的表现差异显著：在预训练中常见的领域（如数学、代码、科学）中，跨领域RL训练效果显著；而在预训练中较少见的领域（如逻辑、模拟、表格）中，需领域内训练才能获得性能提升。Guru模型在17项任务中表现优异，超越基线模型7.9%和6.7%。

研究结论: RL不仅能激发预训练模型的知识，还能促进新技能的习得，尤其是在复杂任务中。Guru数据集和模型的发布为通用推理研究提供了重要资源。

中文摘要: 强化学习（RL）已成为改进大型语言模型（LLM）推理的一种有前景的方法，但现有研究多集中于数学和代码领域，限制了对其在通用推理中广泛适用性的理解。关键挑战在于缺乏跨多样推理领域的可靠、可扩展的RL奖励信号。我们提出了Guru，一个包含92K个可验证示例的RL推理数据集，涵盖数学、代码、科学、逻辑、模拟和表格六个领域，每个领域通过特定奖励设计、去重和过滤确保RL训练的可靠性和有效性。基于Guru，我们系统地重新审视了RL在LLM推理中的已有发现，并观察到跨领域的显著差异。例如，尽管先前研究表明RL主要激发预训练模型的已有知识，但我们的结果显示了一种更复杂的模式：在预训练中常见的领域（数学、代码、科学）中，跨领域RL训练效果显著；而在预训练中较少见的领域（逻辑、模拟和表格）中，需领域内训练才能实现性能提升，表明RL可能促进真正的技能习得。最后，我们提出了Guru-7B和Guru-32B模型，在公开数据训练的开放模型中实现了最先进的性能，在六个推理领域的17项任务评估中分别超越最佳基线7.9%和6.7%。我们还展示了这些模型有效提升了其基础模型的Pass@k性能，尤其是在预训练数据中较少出现的复杂任务上。我们发布了数据、模型、训练和评估代码，以促进通用推理研究：https://github.com/LLM360/Reasoning360

</details>


### [125] [Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size](https://arxiv.org/abs/2506.15025)
**中文标题：大型语言模型中的最优嵌入学习率：词汇量的影响**

*Soufiane Hayou,Liyuan Liu*

主要分类: cs.LG

摘要简述: 本文研究了词汇量对大型语言模型（LLM）训练动态的影响，发现随着词汇量增加，训练动态会从μP（最大更新参数化）机制过渡到新提出的大词汇量（LV）机制，并揭示了LV机制下嵌入学习率与隐藏学习率的最优比例应为Θ(√width)。


<details>
  <summary>详细信息</summary>
研究动机: 预训练大型语言模型成本高昂，现有方法如μP虽能优化超参数传递性，但其理论假设词汇量固定，与实际不符。本文旨在探讨词汇量对训练动态的影响，并提出更优的学习率缩放规则。

研究方法: 通过理论分析词汇量对训练动态的影响，提出大词汇量（LV）机制，并推导出嵌入学习率与隐藏学习率的最优比例。通过实验验证理论，并预训练一个10亿参数模型以展示新缩放规则的优势。

研究结果: 研究发现，随着词汇量增加，训练动态从μP机制过渡到LV机制，且LV机制下嵌入学习率与隐藏学习率的最优比例应为Θ(√width)，与文献中的实证结果一致。实验验证了新规则的有效性。

研究结论: 词汇量对LLM训练动态有显著影响，LV机制下的最优学习率缩放规则与μP不同。新规则在实践中表现优异，为高效预训练提供了理论支持。

中文摘要: 预训练大型语言模型是一个成本高昂的过程。为了提高效率，已有多种方法用于优化模型架构/参数化和硬件使用。在参数化方面，μP（最大更新参数化）通过特定方式参数化模型权重和学习率，使得超参数可随宽度（嵌入维度）传递：超参数可在小模型上调优后直接用于更大模型。尽管μP在实践中表现优异，但近期实证研究在应用于LLM时发现了矛盾现象。μP理论的一个局限是假设输入维度（LLM中的词汇量）在宽度趋近无穷时固定，而实际中词汇量通常远大于宽度。本文通过理论分析词汇量对训练动态的影响，发现随着词汇量增加，训练动态会在μP机制与提出的大词汇量（LV）机制之间过渡。分析表明，在LV机制下，嵌入学习率与隐藏学习率的最优比例应约为Θ(√width)，与文献中的实证结果惊人地接近，且不同于μP预测的Θ(width)比例。通过实验验证理论，并预训练一个10亿参数模型以展示新缩放规则的优势。

</details>


### [126] [Determinação Automática de Limiar de Detecção de Ataques em Redes de Computadores Utilizando Autoencoders](https://arxiv.org/abs/2506.14937)
**中文标题：基于自编码器的计算机网络攻击检测阈值自动确定方法**

*Luan Gonçalves Miranda,Pedro Ivo da Cruz,Murilo Bellezoni Loiola*

主要分类: cs.LG

摘要简述: 本文提出了一种利用机器学习算法自动确定自编码器（AE）异常检测系统中分类阈值的方法，以解决数据不平衡等问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前，基于自编码器的异常检测系统在解决数据不平衡等问题上表现出潜力，但其分类阈值的非标准化定义直接影响检测性能。因此，研究如何自动确定这一阈值具有重要意义。

研究方法: 研究评估了三种机器学习算法（K最近邻、K均值和支持向量机）来自动定义自编码器异常检测系统中的分类阈值。

研究结果: 实验表明，所提出的方法能够有效自动确定分类阈值，从而提升异常检测系统的性能。

研究结论: 通过机器学习算法自动定义分类阈值，可以有效优化自编码器异常检测系统的性能，为解决数据不平衡等问题提供了新思路。

中文摘要: 目前，基于自编码器（AE）的异常检测系统在解决数据不平衡等固有问题上显示出巨大潜力。由于AE使用非标准化且复杂的分类阈值对提取的重构误差进行分类，该阈值的定义直接影响检测过程的性能。因此，本研究提出利用机器学习算法自动定义这一阈值。为此，评估了三种算法：K最近邻、K均值和支持向量机。

</details>


### [127] [Flat Channels to Infinity in Neural Loss Landscapes](https://arxiv.org/abs/2506.14951)
**中文标题：Error**

*Flavio Martinelli,Alexander Van Meegen,Berfin Şimşek,Wulfram Gerstner,Johanni Brea*

主要分类: cs.LG

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [128] [When and How Unlabeled Data Provably Improve In-Context Learning](https://arxiv.org/abs/2506.15329)
**中文标题：未标记数据何时及如何可证明地提升上下文学习**

*Yingcong Li,Xiangyu Chang,Muti Kara,Xiaofeng Liu,Amit Roy-Chowdhury,Samet Oymak*

主要分类: cs.LG

摘要简述: 本文研究了在上下文学习中未标记数据如何提升性能，发现多层或循环Transformer能有效利用未标记数据，而单层线性注意力模型则无法做到。


<details>
  <summary>详细信息</summary>
研究动机: 探索在上下文学习中，即使演示数据标签缺失或不正确时，模型仍能有效学习的机制，为半监督学习提供理论支持。

研究方法: 通过理论分析，比较单层线性注意力模型与多层或循环Transformer在利用未标记数据时的表现，并建立与期望最大化算法的联系。

研究结果: 多层或循环Transformer能通过隐式构造多项式估计器有效利用未标记数据，且其性能随深度指数级提升。

研究结论: 研究表明，循环或深度Transformer能显著提升半监督学习性能，为实际应用提供了理论依据和方法。

中文摘要: 近期研究表明，即使演示数据标签缺失或不正确，上下文学习（ICL）仍能有效。为揭示这一能力，我们研究了一个典型场景，其中演示数据服从二元高斯混合模型（GMM），且部分标签缺失。我们通过理论分析表明：（1）单层线性注意力模型的损失景观恢复最优全监督估计器，但完全无法利用未标记数据；（2）相比之下，多层或循环Transformer能通过隐式构造形如$\sum_{i\ge 0} a_i (X^\top X)^iX^\top y$的估计器（$X$和$y$分别表示特征和部分观测标签）有效利用未标记数据。我们刻画了多项式类与深度的关系，并将其与半监督学习中常用的期望最大化算法联系起来。重要的是，主导多项式幂随深度指数增长，因此轻度深度/循环即可满足需求。作为理论应用，我们提出循环现成的表格基础模型以增强其半监督能力。在真实数据集上的广泛评估表明，我们的方法显著提升了半监督表格学习性能，优于标准单次推理。

</details>


### [129] [Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework](https://arxiv.org/abs/2506.15538)
**中文标题：利用PRISM捕捉多义性：一种多概念特征描述框架**

*Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M. -C. Höhne,Oliver Eberle*

主要分类: cs.LG

摘要简述: 本文提出PRISM框架，用于捕捉神经网络特征的多义性，通过多概念描述提升模型行为的可解释性，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有特征描述方法假设神经元仅编码单一概念（单义性），但实际中神经元常具有多义性，导致描述不准确且表达能力受限。PRISM旨在解决这一问题。

研究方法: PRISM（多义性特征识别与评分方法）是一种新框架，能够为多义性和单义性特征提供更细致的描述，而非单一描述。

研究结果: PRISM在语言模型中应用，通过广泛基准测试，证明其能生成更准确、忠实于模型的特征描述，提升描述质量和多义性捕捉能力。

研究结论: PRISM通过捕捉特征的多义性，显著提升了神经网络特征描述的准确性和表达能力，为模型可解释性研究提供了新工具。

中文摘要: 自动可解释性研究旨在识别神经网络特征编码的概念，以增强对人类模型行为的理解。当前特征描述方法面临两大挑战：鲁棒性有限，以及假设每个神经元仅编码单一概念（单义性），尽管越来越多的证据表明神经元常具有多义性。这一假设限制了特征描述的表达能力，使其无法全面捕捉模型内部行为。为此，我们提出了多义性特征识别与评分方法（PRISM），一种新颖的框架，能够捕捉神经网络特征的固有复杂性。与先前为每个特征分配单一描述的方法不同，PRISM为多义性和单义性特征提供了更细致的描述。我们将PRISM应用于语言模型，并通过与现有方法的广泛基准测试，证明我们的方法能生成更准确、忠实于模型的特征描述，提升了整体描述质量（通过描述评分）和在多义性存在时捕捉不同概念的能力（通过多义性评分）。

</details>


### [130] [Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits](https://arxiv.org/abs/2506.14988)
**中文标题：基于探测的多智能体多臂老虎机公平算法**

*Tianyi Xu,Jiaxin Liu,Zizhan Zheng*

主要分类: cs.LG

摘要简述: 本文提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平性并最大化系统性能。通过引入探测机制，在有限信息下优化决策，并在离线和在线场景中分别设计了高效算法。实验表明，该方法在公平性和效率上优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 在多智能体多臂老虎机问题中，如何在有限信息下实现公平的资源分配和最大化系统性能是一个关键挑战。本文旨在解决这一问题，通过引入探测机制优化决策过程。

研究方法: 1. 在离线场景中，利用子模性质设计了一种贪心探测算法，并证明了其性能边界。2. 在在线场景中，开发了一种算法，能够在保证公平性的同时实现次线性遗憾。

研究结果: 在合成和真实数据集上的实验表明，所提方法在公平性和效率上均优于基线方法。

研究结论: 本文提出的探测框架和算法在多智能体多臂老虎机问题中有效平衡了公平性和性能，为实际应用提供了可行的解决方案。

中文摘要: 本文提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平性并最大化系统性能。在此背景下，决策面临的主要挑战是对臂奖励信息的有限了解。为解决这一问题，我们引入了一种新颖的探测框架，在分配前策略性地收集选定臂的信息。在离线场景中，已知奖励分布的情况下，我们利用子模性质设计了一种贪心探测算法，并证明了其性能边界。对于更复杂的在线场景，我们开发了一种算法，能够在保证公平性的同时实现次线性遗憾。在合成和真实数据集上的大量实验表明，我们的方法在公平性和效率上优于基线方法。

</details>


### [131] [LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](https://arxiv.org/abs/2506.15606)
**中文标题：LoX：低秩外推增强LLM在微调下的安全性**

*Gabrel J. Perin,Runjin Chen,Xuxi Chen,Nina S. T. Hirata,Zhangyang Wang,Junyuan Hong*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LoX（低秩外推）的无训练方法，通过外推对齐LLM的安全子空间，显著提升了模型在面对微调攻击时的安全性，同时保持了任务适应性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在实际应用中广泛使用，但其安全性问题日益突出，尤其是在应对社会有害问题时。尽管通过对齐技术提升了模型安全性，但后续微调仍可能破坏其安全保护，即使微调数据看似无害。本文旨在解决这一漏洞。

研究方法: 作者发现LLM参数中安全关键的低秩子空间对微调敏感，因此提出LoX方法，通过外推对齐LLM的安全子空间来增强安全性。该方法无需额外训练，直接调整模型参数。

研究结果: 实验证明，LoX在面对良性或恶意微调攻击时，攻击成功率（ASR）绝对降低了11%至54%。参数分析表明，外推将LLM参数移至更平坦区域，从而降低对扰动的敏感性。

研究结论: LoX通过外推安全子空间有效提升了LLM的安全性，同时不影响其任务适应性。该方法为LLM安全防护提供了新思路。

中文摘要: 大型语言模型（LLM）已成为实际应用中不可或缺的工具，但其广泛使用也引发了显著的安全问题，尤其是在应对社会有害问题时。尽管通过对齐技术大幅提升了模型安全性，但后续微调仍可能破坏其安全保护，即使微调数据看似无害。本文通过实证表明，这一漏洞源于LLM参数中安全关键的低秩子空间对微调的敏感性。基于这一发现，我们提出了一种无需训练的新方法——低秩外推（LoX），通过外推对齐LLM的安全子空间来增强安全性。实验结果表明，LoX在面对良性或恶意微调攻击时显著提升了鲁棒性，同时保持了模型对新任务的适应性。例如，LoX使攻击成功率（ASR）在面对良性或恶意微调攻击时绝对降低了11%至54%。通过分析参数ASR分布，我们将LoX的成功归因于外推将LLM参数移至更平坦区域，从而降低了对扰动的敏感性。代码已在github.com/VITA-Group/LoX发布。

</details>


### [132] [AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning](https://arxiv.org/abs/2506.15651)
**中文标题：AutoRule：基于推理链提取的规则奖励提升偏好学习**

*Tevin Wang,Chenyan Xiong*

主要分类: cs.LG

摘要简述: AutoRule是一种自动化方法，通过从用户偏好中提取规则并转化为基于规则的奖励，显著提升了强化学习从人类反馈（RLHF）的性能。实验显示，该方法在AlpacaEval2.0和MT-Bench上分别实现了28.6%和6.1%的相对性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于规则的奖励方法依赖人工设计规则，效率低下且难以扩展。AutoRule旨在通过自动化提取规则，减少人工干预，提升强化学习从人类反馈的性能。

研究方法: AutoRule分为三个阶段：1）利用推理模型解释用户偏好；2）从推理链中提取候选规则；3）将规则整合为统一规则集。随后，通过语言模型验证器计算输出满足规则的比例，作为辅助奖励用于策略优化。

研究结果: 实验表明，AutoRule在AlpacaEval2.0上实现了28.6%的相对性能提升，在MT-Bench子集上提升了6.1%。此外，该方法减少了奖励滥用，且提取的规则与数据集偏好高度一致。

研究结论: AutoRule通过自动化提取规则，显著提升了强化学习从人类反馈的性能，同时减少了奖励滥用，展示了规则提取在多数据集中的独特价值。

中文摘要: 基于规则的奖励为改进从人类反馈的强化学习（RLHF）提供了有前景的策略，但当前方法通常依赖人工规则设计。我们提出了AutoRule，一种完全自动化的方法，用于从偏好反馈中提取规则并将其转化为基于规则的奖励。AutoRule的提取过程分为三个阶段：利用推理模型解释用户偏好，从这些解释的推理链中识别候选规则，并将其合成为统一的规则集。利用最终规则集，我们通过语言模型验证器计算每个输出满足规则的比例，将此指标作为辅助奖励与学习到的奖励模型一起用于策略优化。在Llama-3-8B模型上使用AutoRule训练后，与未使用基于规则辅助奖励的GRPO基线相比，AlpacaEval2.0上的长度控制胜率相对提升了28.6%，在MT-Bench子集上的第二轮性能相对提升了6.1%。我们的分析证实，提取的规则与数据集偏好高度一致。我们发现，AutoRule在两轮运行中比学习到的奖励模型减少了奖励滥用。最后，案例研究表明，提取的规则捕捉了不同数据集中被重视的独特品质。提取的规则详见附录，代码已开源：https://github.com/cxcscmu/AutoRule。

</details>


### [133] [Dense SAE Latents Are Features, Not Bugs](https://arxiv.org/abs/2506.15679)
**中文标题：密集SAE潜在特征是功能而非缺陷**

*Xiaoqing Sun,Alessandro Stolfo,Joshua Engels,Ben Wu,Senthooran Rajamanoharan,Mrinmaya Sachan,Max Tegmark*

主要分类: cs.LG

摘要简述: 研究发现，稀疏自编码器（SAE）中的密集潜在特征并非训练噪声，而是语言模型中具有功能性的重要表示。这些特征在不同层中表现出不同的语义和结构作用。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏自编码器（SAE）旨在通过稀疏约束提取语言模型的可解释特征，但许多潜在特征频繁激活（即密集），引发对其是否为训练噪声的质疑。本文旨在系统研究这些密集潜在特征的几何、功能和起源。

研究方法: 首先分析密集潜在特征的几何结构和功能，发现它们形成反极对并重构残差流中的特定方向；其次，提出密集潜在特征的分类法，识别与位置跟踪、上下文绑定等相关的类别；最后，研究这些特征在不同层的演化规律。

研究结果: 密集潜在特征是残差空间的固有属性，具有功能性作用，如位置跟踪、语义绑定等。这些特征在早期层表现为结构特征，中期层为语义特征，后期层为输出导向信号。

研究结论: 密集潜在特征是语言模型计算中的重要组成部分，不应被视为训练噪声，而是反映了模型的内在表示。

中文摘要: 稀疏自编码器（SAE）旨在通过稀疏约束从语言模型中提取可解释特征。理想情况下，SAE训练应产生稀疏且语义有意义的潜在特征。然而，许多SAE潜在特征频繁激活（即密集），引发对其是否为训练噪声的担忧。本文系统研究了密集潜在特征的几何、功能和起源，发现它们不仅是持久的，而且通常反映有意义的模型表示。首先，我们证明密集潜在特征倾向于形成反极对，重构残差流中的特定方向；其次，提出密集潜在特征的分类法，识别与位置跟踪、上下文绑定、熵调节、字母特定输出信号、词性和主成分重构相关的类别；最后，分析这些特征在不同层的演化规律，揭示了从早期层的结构特征到中期层的语义特征，再到后期层的输出导向信号的转变。研究结果表明，密集潜在特征在语言模型计算中具有功能性作用，不应被视为训练噪声。

</details>


### [134] [Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment](https://arxiv.org/abs/2506.15019)
**中文标题：基于稳定CDE自编码器和敏锐度正则化的脓毒症治疗离线强化学习**

*Yue Gao*

主要分类: cs.LG

摘要简述: 本文提出了一种基于稳定CDE自编码器和敏锐度正则化的方法，用于脓毒症治疗的离线强化学习。通过确保训练稳定性和临床评分相关性，该方法显著提升了策略性能。


<details>
  <summary>详细信息</summary>
研究动机: 脓毒症治疗的强化学习依赖于从ICU不规则时间序列中学习稳定且具有临床意义的表征。然而，现有研究忽视了训练不稳定性对策略性能的负面影响。本文旨在解决这一问题。

研究方法: 采用控制微分方程（CDE）作为状态表征方法，并通过两种关键措施提升性能：（1）通过早停或稳定化方法确保训练稳定性；（2）通过临床评分（SOFA、SAPS-II、OASIS）的相关性正则化强制表征具有敏锐度感知能力。

研究结果: 实验表明，稳定的CDE自编码器生成的表征与临床评分高度相关，并实现了优异的策略性能（WIS回报>0.9）。而不稳定的表征导致性能下降（WIS回报≈0）。潜在空间可视化显示，稳定CDE能够区分生存与非生存轨迹，并捕捉敏锐度梯度。

研究结论: 本文强调了在临床强化学习中，训练稳定性对不规则医学时间序列表征学习的重要性，并提供了使用CDE的实用指南。

中文摘要: 脓毒症治疗的有效强化学习依赖于从ICU不规则时间序列中学习稳定且具有临床意义的表征。尽管已有研究探索了表征学习，但训练不稳定性对策略性能的负面影响被忽视了。本文表明，控制微分方程（CDE）状态表征在满足两个关键条件时可实现优异的强化学习策略：（1）通过早停或稳定化方法确保训练稳定性；（2）通过与临床评分（SOFA、SAPS-II、OASIS）的相关性正则化强制表征具有敏锐度感知能力。在MIMIC-III脓毒症队列上的实验显示，稳定的CDE自编码器生成的表征与临床评分高度相关，并实现了优异的策略性能（WIS回报>0.9），而不稳定的表征导致性能下降（WIS回报≈0）。潜在空间可视化表明，稳定CDE不仅能区分生存与非生存轨迹，还能捕捉敏锐度梯度，而不稳定训练则无法实现。这些发现为临床强化学习中CDE的应用提供了实用指南，强调了序列表征学习中训练稳定性的重要性。

</details>


### [135] [SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models](https://arxiv.org/abs/2506.15021)
**中文标题：SFT-GO：基于分组优化的大型语言模型监督微调**

*Gyuhak Kim,Sumiran Singh Thakur,Su Min Park,Wei Wei,Yujia Bao*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SFT-GO的新方法，通过基于令牌重要性的分组优化来改进大型语言模型的监督微调，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的监督微调方法通常将所有令牌视为同等重要，忽略了任务关键信息的局部性。SFT-GO旨在通过分组优化解决这一问题。

研究方法: SFT-GO根据令牌的重要性将其分组，并采用加权的最差组损失和标准交叉熵损失组合进行优化，从而自适应地强调关键令牌组。

研究结果: 实验表明，SFT-GO在多个基准测试中优于基线方法，且在不同数据集和基础模型上均表现出鲁棒性和有效性。

研究结论: SFT-GO通过分组优化显著提升了监督微调的效果，为大型语言模型的性能优化提供了新思路。

中文摘要: 监督微调（SFT）已成为调整大型语言模型（LLM）以符合人类期望和特定下游任务的关键步骤。然而，现有的SFT方法通常将每个训练实例视为统一序列，对所有令牌赋予相同的重要性，而忽略了只有部分令牌包含关键任务信息的事实。为解决这一问题，我们提出了基于分组优化的监督微调（SFT-GO），这是一种根据令牌重要性对令牌进行分组的新方法。SFT-GO通过加权的最差组损失和标准交叉熵损失组合优化LLM，自适应地强调最具挑战性的令牌组，从而改善整体学习动态。我们提供了SFT-GO收敛速率的理论分析，证明了其高效性。实验上，我们应用了三种不同的令牌分组策略，结果表明，SFT-GO训练的模型在多个流行LLM基准测试中均优于基线方法。这些改进在不同数据集和基础模型上均保持一致，证明了我们方法的鲁棒性和有效性。

</details>


### [136] [CACTUS as a Reliable Tool for Early Classification of Age-related Macular Degeneration](https://arxiv.org/abs/2506.14843)
**中文标题：CACTUS作为早期分类年龄相关性黄斑变性的可靠工具**

*Luca Gherardini,Imre Lengyel,Tunde Peto,Caroline C. W. Klaverd,Magda A. Meester-Smoord,Johanna Maria Colijnd,EYE-RISK Consortium,E3 Consortium,Jose Sousa*

主要分类: cs.LG

摘要简述: CACTUS是一种可靠的工具，用于早期分类年龄相关性黄斑变性（AMD），通过结合遗传、饮食、临床和人口统计学因素，提供可解释性和灵活性，优于传统机器学习模型。


<details>
  <summary>详细信息</summary>
研究动机: 医疗数据通常有限或不完整，影响机器学习模型的性能。年龄相关性黄斑变性（AMD）影响数百万老年人，早期诊断至关重要，但目前缺乏有效的逆转治疗方法。需要一种综合考虑多种因素的分类方法。

研究方法: 研究引入了CACTUS（全面抽象和分类工具），用于改进AMD分期分类。CACTUS通过消除不相关或有偏见的数据，识别关键因素，并提供结果的可解释性。

研究结果: CACTUS在AMD分类中表现优于标准机器学习模型，增强了决策制定，并通过识别重要特征与现有医学知识进行比较。

研究结论: CACTUS为AMD早期分类提供了可靠且可解释的工具，帮助临床医生提供反馈并解决数据偏见问题。

中文摘要: 机器学习（ML）用于解决疾病分类和预测等任务，但其效果依赖于大量完整数据。医疗数据通常有限或不完整，影响模型性能。此外，解决方案的可信度因数据集而异，某些ML模型缺乏透明度，增加了理解和使用的难度。年龄相关性黄斑变性（AMD）影响数百万老年人，早期诊断至关重要，因为目前缺乏逆转疾病进展的有效治疗方法。诊断AMD需要评估视网膜图像和患者症状报告。需要一种综合考虑遗传、饮食、临床和人口统计学因素的分类方法。最近，我们引入了“全面抽象和分类工具”（CACTUS），旨在改进AMD分期分类。CACTUS提供可解释性和灵活性，优于标准ML模型。它通过识别关键因素和提供结果的可信度，增强了决策制定。CACTUS识别的重要特征使我们能够与现有医学知识进行比较。通过消除不相关或有偏见的数据，我们为临床医生创建了一个反馈场景，以解决偏见问题。

</details>


### [137] [Sequential Policy Gradient for Adaptive Hyperparameter Optimization](https://arxiv.org/abs/2506.15051)
**中文标题：序列策略梯度自适应超参数优化**

*Zheng Li,Jerry Cheng,Huanying Helen Gu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SPG的轻量级超参数优化方法，通过单次前向传递生成轨迹，显著降低了计算成本，并在多个数据集上实现了性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习方法在神经架构搜索和超参数优化中因高昂的时间和计算成本而难以广泛应用，本文旨在解决这一问题。

研究方法: 提出SPG方法，通过扩展基础模型并引入临时模块，实现单次前向传递生成状态-动作轨迹，从而高效优化超参数。

研究结果: 实验表明，SPG在多个数据集（ImageNet、COCO、GLUE等）上显著提升了模型性能（+0.2∼7%），同时计算成本极低。

研究结论: SPG是一种高效且轻量级的超参数优化方法，具有广泛的工业应用潜力。

中文摘要: 强化学习在神经架构搜索和超参数优化中至关重要，但传统方法因高昂的时间和计算成本阻碍了其广泛应用。受DeepSeek-V3多令牌预测架构启发，我们提出了序列策略梯度建模（SPG），一种轻量级在线超参数优化的新型轨迹生成范式。与传统策略梯度方法不同，SPG通过临时模块扩展基础模型，使其能够单次前向传递生成状态-动作（填充）轨迹。实验表明，模型在原始数据集上使用SPG重新训练后性能提升，且优于标准迁移微调。我们在计算机视觉（ImageNet、COCO）、自然语言处理（GLUE、SQuAD）和音频（SUPERB）五个数据集上评估了SPG的工业适用性。该方法在广泛采用的模型中表现出一致的改进，性能提升达+0.2∼7%，且计算成本极低。完全可复现的代码和预训练模型：https://huggingface.co/UniversalAlgorithmic/SPG。

</details>


### [138] [Singular Value Decomposition on Kronecker Adaptation for Large Language Model](https://arxiv.org/abs/2506.15251)
**中文标题：基于Kronecker适应的奇异值分解在大型语言模型中的应用**

*Yee Hin Chong,Peng Qu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SoKA的参数高效微调方法，结合Kronecker乘积张量分解与SVD初始化及动态秩选择，显著减少训练参数并提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型预训练Transformer模型在多种任务中表现优异，但全参数微调成本高昂。现有参数高效微调方法存在推理延迟、收敛不佳或固定秩选择不匹配任务复杂度等问题。

研究方法: SoKA方法结合Kronecker乘积张量分解与SVD驱动的初始化，通过动态秩选择算法剪枝不重要成分，提取权重更新的主成分到紧凑的Kronecker因子中。

研究结果: 在LLaMA2-7B模型上的实验表明，SoKA仅需0.99M可训练参数，比LoRA/PiSSA少25%，性能匹配或超越基线，且收敛更快、梯度更稳定。

研究结论: SoKA是一种高效、稳健的大规模模型适应方法，显著降低了计算和存储开销。

中文摘要: 大型预训练Transformer模型在多样化的语言和推理任务中取得了最先进的结果，但全参数微调带来了巨大的存储、内存和计算开销。参数高效微调（PEFT）方法通过学习少量任务特定参数来缓解这些成本，但现有方法要么引入推理延迟（适配器模块），要么因随机初始化低秩更新而收敛不佳，或依赖可能与任务复杂度不匹配的固定秩选择（基于Kronecker的分解）。
  我们提出了SoKA（基于Kronecker适应的SVD），这是一种新颖的PEFT策略，结合了Kronecker乘积张量分解与SVD驱动的初始化和频谱感知的动态秩选择。我们的Kronecker乘积SVD（KPSVD）过程将完整权重更新的主成分提取到紧凑的Kronecker因子中，而自适应秩选择算法使用能量阈值和肘点准则剪枝可忽略的成分。
  在LLaMA2-7B上的算术推理（GSM8K）、形式数学（MATH）和代码生成（MBPP）实验表明，SoKA仅需0.99M可训练参数，比LoRA/PiSSA少25%，同时性能匹配或超越基线。此外，SoKA表现出更快的收敛和更稳定的梯度，突显了其在大规模模型适应中的稳健性和高效性。

</details>


### [139] [Unlocking Post-hoc Dataset Inference with Synthetic Data](https://arxiv.org/abs/2506.15271)
**中文标题：利用合成数据解锁事后数据集推断**

*Bihe Zhao,Pratyush Maini,Franziska Boenisch,Adam Dziedzic*

主要分类: cs.LG

摘要简述: 本文提出了一种通过生成合成数据解决数据集推断（DI）中私有集缺失问题的方法，利用后缀补全任务训练数据生成器，并通过后校准缩小真实与合成数据间的似然差距，实验证明其高效且可靠。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的训练数据常未经授权使用，数据集推断（DI）可验证数据是否被滥用，但现有方法需依赖与训练集分布匹配的私有集，实际中难以获取，限制了DI的适用性。

研究方法: 通过设计基于后缀补全任务的数据生成器生成高质量合成数据，准确反映原始分布，并通过后校准缩小真实与合成数据间的似然差距，为DI提供所需的私有集。

研究结果: 实验表明，生成的合成数据作为私有集能高置信度检测原始训练集，同时保持低误报率，适用于实际版权纠纷。

研究结论: 该方法解决了DI中私有集缺失的难题，为数据所有者提供了可靠的版权验证工具，代码已开源。

中文摘要: 大型语言模型（LLMs）的强大能力主要归功于其海量训练数据，但这些数据常未经数据所有者授权从互联网抓取。数据集推断（DI）通过判断可疑数据集是否用于训练，为数据所有者提供验证手段。然而，现有DI方法需依赖一个与训练集分布匹配且未参与训练的私有集，此类数据实际中极少可用，严重限制了DI的适用性。本研究通过合成生成所需私有集解决这一难题。方法包括：（1）通过基于后缀补全任务训练的数据生成器生成高质量、多样化的合成数据，准确反映原始分布；（2）通过后校准缩小真实与合成数据间的似然差距。多文本数据集实验表明，生成的合成数据作为私有集能高置信度检测原始训练集，同时保持低误报率，为版权所有者提供合法主张依据，并证明方法在实际诉讼中的可靠性。代码见https://github.com/sprintml/PostHocDatasetInference。

</details>


### [140] [Pixel-level Certified Explanations via Randomized Smoothing](https://arxiv.org/abs/2506.15499)
**中文标题：通过随机平滑实现像素级认证解释**

*Alaa Anani,Tobias Lorenz,Mario Fritz,Bernt Schiele*

主要分类: cs.LG

摘要简述: 本文提出了一种基于随机平滑的像素级认证解释框架，首次为任何黑盒归因方法提供像素级鲁棒性保证，并通过稀疏化和平滑化归因图，将其转化为分割任务，确保每个像素的重要性在ℓ₂有界扰动下得到认证。


<details>
  <summary>详细信息</summary>
研究动机: 现有的后验归因方法在解释深度学习预测时，容易受到微小输入扰动的影响，导致归因图发生显著变化，而预测结果保持不变。这种脆弱性降低了归因方法的可信度，亟需一种严格的像素级鲁棒性保证。

研究方法: 通过随机平滑技术，将归因图稀疏化和平滑化，将其重新表述为分割任务，并认证每个像素在ℓ₂有界扰动下的重要性。同时提出了三种评估指标，用于衡量认证的鲁棒性、定位性和忠实性。

研究结果: 在5个ImageNet模型和12种归因方法上的广泛实验表明，本文提出的认证归因方法具有鲁棒性、可解释性和忠实性，能够可靠地用于下游任务。

研究结论: 本文提出的框架首次为像素级归因方法提供了严格的鲁棒性认证，增强了归因方法的可信度，并为下游任务提供了可靠的解释工具。

中文摘要: 后验归因方法旨在通过突出影响输入像素来解释深度学习预测。然而，这些解释具有高度非鲁棒性：微小且难以察觉的输入扰动可以显著改变归因图，同时保持相同的预测结果。这种脆弱性削弱了其可信度，亟需对像素级归因分数提供严格的鲁棒性保证。我们首次引入了一种基于随机平滑的认证框架，为任何黑盒归因方法提供像素级鲁棒性保证。通过稀疏化和平滑化归因图，我们将任务重新表述为分割问题，并认证每个像素在ℓ₂有界扰动下的重要性。此外，我们提出了三种评估指标，用于衡量认证的鲁棒性、定位性和忠实性。在5个ImageNet模型和12种归因方法上的广泛实验表明，我们的认证归因方法具有鲁棒性、可解释性和忠实性，能够可靠地用于下游任务。代码详见https://github.com/AlaaAnani/certified-attributions。

</details>


### [141] [Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation](https://arxiv.org/abs/2506.15309)
**中文标题：主动学习引导的序列到序列变分自编码器用于多靶点抑制剂生成**

*Júlia Vilalta-Mor,Alexis Molina,Laura Ortega Varga,Isaac Filella-Merce,Victor Guallar*

主要分类: cs.LG

摘要简述: 本文提出了一种结合主动学习和序列到序列变分自编码器的方法，用于生成多靶点抑制剂，通过平衡化学多样性和多靶点亲和力，成功生成了针对冠状病毒主蛋白酶的候选抑制剂。


<details>
  <summary>详细信息</summary>
研究动机: 药物发现中同时优化分子以针对多个治疗靶点面临奖励稀疏和设计约束冲突的挑战，亟需一种高效方法解决这一问题。

研究方法: 采用结构化主动学习范式，结合序列到序列变分自编码器，通过迭代扩展潜在空间的化学可行区域并逐步约束分子，平衡化学多样性和多靶点亲和力。

研究结果: 在针对三种冠状病毒主蛋白酶的实验中，成功生成了结构多样的泛抑制剂候选分子，验证了方法的有效性。

研究结论: 该方法为复杂多靶点药物设计提供了通用路径，显著提升了化学空间的探索效率。

中文摘要: 在药物发现中，同时优化分子以针对多个治疗靶点仍是一个重大挑战，尤其是由于奖励稀疏和设计约束冲突。我们提出了一种结构化主动学习（AL）范式，将序列到序列（Seq2Seq）变分自编码器（VAE）集成到迭代循环中，旨在平衡化学多样性、分子质量和多靶点亲和力。我们的方法在扩展潜在空间的化学可行区域和逐步基于多靶点对接阈值约束分子之间交替进行。在一项针对三种相关冠状病毒主蛋白酶（SARS-CoV-2、SARS-CoV、MERS-CoV）的概念验证研究中，我们的方法高效生成了一组结构多样的泛抑制剂候选分子。我们证明，在主动学习流程中精心安排化学过滤器的时机和策略性放置，显著增强了对有益化学空间的探索，将稀疏奖励的多目标药物设计问题转化为可计算的任务。因此，我们的框架为高效导航复杂的多靶点药物设计提供了通用路线图。

</details>


### [142] [Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI](https://arxiv.org/abs/2506.15408)
**中文标题：统一VXAI：可解释人工智能评估的系统性综述与框架**

*David Dembinsky,Adriano Lucieri,Stanislav Frolov,Hiba Najjar,Ko Watanabe,Andreas Dengel*

主要分类: cs.LG

摘要简述: 本文通过系统性文献综述和统一框架（VXAI）填补了可解释人工智能（XAI）评估领域的标准化空白，提出了41个功能相似的指标组和三维分类方案。


<details>
  <summary>详细信息</summary>
研究动机: 现代AI系统（如深度神经网络）因其黑箱特性缺乏透明度，降低了可信度。尽管XAI提供了模型行为的解释，但缺乏标准化的评估方法和共识指标。本文旨在填补这一空白。

研究方法: 遵循PRISMA指南进行系统性文献综述，分析了362篇相关文献，提出了VXAI框架，包括41个功能相似的指标组和基于解释类型、评估上下文及解释质量需求的三维分类方案。

研究结果: 提出了目前最全面的VXAI框架，支持系统化的指标选择，提升方法间的可比性，并为未来扩展提供了灵活基础。

研究结论: VXAI框架为XAI评估提供了标准化和结构化指导，促进了该领域的进一步发展。

中文摘要: 现代AI系统常依赖不透明的黑箱模型（如深度神经网络），其性能源于复杂的架构和数百万学习参数。尽管强大，其复杂性因缺乏透明度而引发可信度问题。可解释AI（XAI）通过提供人类可理解的模型行为解释来解决这一问题。然而，为确保其有用性和可信度，这些解释需经过严格评估。尽管XAI方法日益增多，该领域仍缺乏标准化的评估协议和共识指标。为填补这一空白，我们遵循PRISMA指南进行系统性文献综述，并提出了统一的可解释AI评估框架（VXAI）。我们筛选了362篇相关文献，将其贡献归纳为41个功能相似的指标组，并提出基于解释类型、评估上下文和解释质量需求的三维分类方案。该框架提供了迄今为止最全面且结构化的VXAI概述，支持系统化的指标选择，促进方法间的可比性，并为未来扩展提供了灵活基础。

</details>


### [143] [Reward Models in Deep Reinforcement Learning: A Survey](https://arxiv.org/abs/2506.15421)
**中文标题：深度强化学习中的奖励模型：综述**

*Rui Yu,Shenghua Wan,Yucen Wang,Chen-Xiao Gao,Le Gan,Zongzhang Zhang,De-Chuan Zhan*

主要分类: cs.LG

摘要简述: 本文综述了深度强化学习中的奖励模型技术，分类总结了其来源、机制和学习范式，并探讨了应用与评估方法，填补了当前文献中奖励模型系统综述的空白。


<details>
  <summary>详细信息</summary>
研究动机: 奖励模型在强化学习中作为代理目标，指导策略优化，但现有文献缺乏对其系统性的综述。本文旨在填补这一空白，全面回顾奖励模型技术及其应用。

研究方法: 首先介绍奖励模型的背景与基础知识，然后分类综述近年来的奖励建模方法，包括来源、机制和学习范式，并讨论其应用与评估方法。

研究结果: 本文系统总结了奖励模型的多种方法，包括传统与新兴技术，并提供了应用案例和评估标准，为研究者提供了全面的参考。

研究结论: 奖励模型在深度强化学习中具有重要作用，未来研究应关注其与真实目标的更紧密对齐以及优化策略的进一步改进。

中文摘要: 在强化学习（RL）中，智能体持续与环境互动，并利用反馈优化其行为。为了指导策略优化，奖励模型被引入作为目标任务的代理，使得智能体在最大化累积奖励的同时，也能满足任务设计者的意图。近年来，学术界和工业界的研究者重点关注开发与真实目标紧密对齐且便于策略优化的奖励模型。本文综述了深度强化学习文献中的奖励建模技术。首先概述了奖励模型的背景与基础知识，接着分类介绍了近年来的奖励建模方法，包括来源、机制和学习范式。在此基础上，讨论了这些奖励建模技术的多种应用，并回顾了评估奖励模型的方法。最后，总结了奖励建模领域未来有前景的研究方向。本文涵盖了传统与新兴方法，填补了当前文献中奖励模型系统性综述的空白。

</details>


### [144] [Zero-Shot Reinforcement Learning Under Partial Observability](https://arxiv.org/abs/2506.15446)
**中文标题：部分可观测性下的零样本强化学习**

*Scott Jeen,Tom Bewley,Jonathan M. Cullen*

主要分类: cs.LG

摘要简述: 本文研究了在部分可观测环境下零样本强化学习（RL）的性能退化问题，并提出基于记忆的架构作为有效解决方案。实验表明，该方法在状态、奖励和动态变化部分可观测的场景中优于无记忆基线。


<details>
  <summary>详细信息</summary>
研究动机: 零样本强化学习在完全可观测的马尔可夫状态下表现良好，但在现实应用中，状态往往部分可观测。本文旨在探索部分可观测性对零样本RL性能的影响，并提出改进方法。

研究方法: 通过引入基于记忆的架构，解决部分可观测性问题。在状态、奖励和动态变化部分可观测的环境中，对比了记忆方法与无记忆基线的性能。

研究结果: 实验结果显示，基于记忆的零样本RL方法在部分可观测场景中显著优于无记忆基线，验证了记忆架构的有效性。

研究结论: 在部分可观测环境下，基于记忆的零样本RL方法能够有效提升性能，为实际应用提供了可行的解决方案。

中文摘要: 近期研究表明，在特定假设下，零样本强化学习（RL）方法可以通过无奖励预训练泛化到任何未见任务。完全可观测的马尔可夫状态是此类假设之一，但在许多实际应用中，状态仅部分可观测。本文探讨了标准零样本RL方法在部分可观测性下的性能退化问题，并表明，与单任务RL类似，基于记忆的架构是有效的解决方案。我们在状态、奖励和动态变化部分可观测的领域中评估了基于记忆的零样本RL方法，结果显示其性能优于无记忆基线。代码已开源：https://enjeeneer.io/projects/bfms-with-memory/。

</details>


### [145] [Warping and Matching Subsequences Between Time Series](https://arxiv.org/abs/2506.15452)
**中文标题：时间序列之间的子序列扭曲与匹配**

*Simiao Lin,Wannes Meert,Pieter Robberechts,Hendrik Blockeel*

主要分类: cs.LG

摘要简述: 本文提出了一种新颖的技术，通过简化时间序列的扭曲路径，突出并量化关键变换（如位移、压缩和幅度差异），从而增强时间序列比较的可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的时间序列比较方法虽然提供了弹性距离度量，但缺乏对子序列级别结构关系的定性分析，难以直观理解时间序列之间的位移、加速或减速等变换。

研究方法: 提出了一种新技术，通过简化扭曲路径来突出和量化关键变换（如位移、压缩和幅度差异），并提供更清晰的子序列匹配可视化表示。

研究结果: 该方法能够更直观地展示时间序列之间的子序列匹配关系，显著提升了时间序列比较的可解释性。

研究结论: 通过简化扭曲路径并突出关键变换，本文方法为时间序列比较提供了更直观和可解释的工具。

中文摘要: 比较时间序列在聚类和分类等任务中至关重要。虽然允许扭曲的弹性距离度量提供了稳健的定量比较，但缺乏对其的定性分析。传统可视化方法侧重于点对点对齐，未能传达子序列级别的更广泛结构关系。这一限制使得难以理解一个时间序列相对于另一个时间序列的位移、加速或减速情况。为此，我们提出了一种新技术，通过简化扭曲路径来突出、量化和可视化关键变换（如位移、压缩和幅度差异）。通过更清晰地展示子序列之间的匹配关系，我们的方法提升了时间序列比较的可解释性。

</details>


### [146] [Over-squashing in Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2506.15507)
**中文标题：时空图神经网络中的过度挤压问题**

*Ivan Marisca,Jacob Bamberger,Cesare Alippi,Michael M. Bronstein*

主要分类: cs.LG

摘要简述: 本文研究了时空图神经网络（STGNNs）中的过度挤压问题，发现其与静态图神经网络中的问题不同，且卷积STGNNs更倾向于传播时间上较远而非较近的信息。


<details>
  <summary>详细信息</summary>
研究动机: 尽管图神经网络（GNNs）在多领域取得了成功，但其信息传播能力存在局限性，如过度挤压问题。这一问题在时空图神经网络（STGNNs）中尚未被研究，而时间维度进一步加剧了信息传播的挑战。

研究方法: 本文形式化了时空过度挤压问题，并通过分析揭示了卷积STGNNs更倾向于传播时间上较远的信息。同时，证明了时间-空间或时间优先处理范式均受此现象影响。

研究结果: 研究在合成和真实数据集上验证了时空过度挤压问题的存在，并提供了对STGNNs操作动态的深入理解，为更有效的设计提供了理论支持。

研究结论: 时空过度挤压问题在STGNNs中具有独特性，且卷积STGNNs的设计需考虑时间维度的影响。研究为高效实现提供了理论依据。

中文摘要: 图神经网络（GNNs）在多个领域取得了显著成功。然而，近期的理论进展揭示了其信息传播能力的根本局限性，例如过度挤压问题，即远距离节点无法有效交换信息。尽管在静态背景下已有广泛研究，但这一问题在时空图神经网络（STGNNs）中尚未被探索，后者处理与图节点相关的序列。时间维度通过增加需传播的信息进一步加剧了这一挑战。本文形式化了时空过度挤压问题，并展示了其与静态情况的显著差异。我们的分析表明，卷积STGNNs反直觉地倾向于传播时间上较远而非较近的信息。此外，我们证明了遵循时间-空间或时间优先处理范式的架构均受此现象影响，为计算高效实现提供了理论依据。我们在合成和真实数据集上验证了发现，为STGNNs的操作动态提供了更深入的见解，并为更有效的设计提供了原则性指导。

</details>


### [147] [RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation](https://arxiv.org/abs/2506.15513)
**中文标题：RePCS：诊断基于LLM的检索增强生成中的数据记忆问题**

*Le Vu Anh,Nguyen Viet Anh,Mehmet Dik,Luong Van Nghia*

主要分类: cs.LG

摘要简述: 本文提出了一种名为RePCS的方法，用于检测大型语言模型（LLM）在检索增强生成（RAG）中是否依赖记忆数据而非检索内容。该方法通过比较两种推理路径的KL散度来判断模型行为，无需访问模型内部或重新训练。


<details>
  <summary>详细信息</summary>
研究动机: 检索增强生成（RAG）虽然能利用外部信息更新模型响应，但模型可能仍依赖记忆的训练数据，导致输出污染。因此，需要一种无需模型访问或重新训练的方法来诊断这种行为。

研究方法: RePCS通过比较仅使用查询的推理路径（参数路径）和同时使用查询与检索上下文的路径（检索增强路径）的输出分布KL散度。低散度表明检索内容影响小，可能存在记忆行为。该方法无需梯度或内部状态访问，仅需一次额外前向传播。

研究结果: 在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，优于先前最强方法6.5个百分点，且在NVIDIA T4 GPU上的延迟开销低于4.7%。

研究结论: RePCS提供了一种轻量级、黑盒化的方法，用于验证RAG系统是否有效利用检索内容，特别适用于安全关键应用。

中文摘要: 检索增强生成（RAG）已成为一种常见策略，用于通过外部信息更新大型语言模型（LLM）的响应。然而，模型可能仍依赖记忆的训练数据，绕过检索证据并产生污染输出。我们提出了检索路径污染评分（RePCS），一种无需模型访问或重新训练即可检测此类行为的诊断方法。RePCS比较两种推理路径：（i）仅使用查询的参数路径，和（ii）同时使用查询与检索上下文的检索增强路径，通过计算其输出分布的Kullback-Leibler（KL）散度。低散度表明检索上下文影响较小，可能存在记忆行为。此方法不依赖特定模型，无需梯度或内部状态访问，仅需一次额外前向传播。我们还推导了PAC式保证，将KL阈值与用户定义的假阳性和假阴性率关联。在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，优于先前最强方法6.5个百分点，且在NVIDIA T4 GPU上的延迟开销低于4.7%。RePCS提供了一种轻量级、黑盒化的保障，用于验证RAG系统是否有效利用检索内容，特别适用于安全关键应用。

</details>


### [148] [Learning Algorithms in the Limit](https://arxiv.org/abs/2506.15543)
**中文标题：极限条件下的学习算法**

*Hristo Papazov,Nicolas Flammarion*

主要分类: cs.LG

摘要简述: 本文通过扩展Gold的归纳推理框架，引入计算观察和受限输入源，研究了在极限条件下学习可计算函数的问题。通过补充传统输入-输出观察，提出了时间约束观察和策略轨迹观察，克服了学习一般递归函数的障碍，并建立了计算代理观察的正式框架。


<details>
  <summary>详细信息</summary>
研究动机: 传统输入-输出观察不足以在极限条件下学习一般递归函数，因此需要引入计算复杂性约束或近似时间约束观察，以更现实的条件研究可计算函数的学习问题。

研究方法: 扩展Gold的归纳推理框架，引入时间约束观察和策略轨迹观察，补充传统输入-输出观察，并建立计算代理观察的正式框架。

研究结果: 通过时间约束或策略轨迹观察，克服了学习一般递归函数的障碍；同时揭示了策略轨迹学习与有限状态转换器推断的联系，并证明线性时间可计算函数不存在可计算或多项式质量的特征集。

研究结论: 在更现实的约束条件下，通过扩展观察类型，可以克服学习一般递归函数的障碍，但某些函数类仍存在学习限制。

中文摘要: 本文研究了在极限条件下学习可计算函数的问题，通过扩展Gold的归纳推理框架，引入计算观察和受限输入源。与传统输入-输出观察互补，我们提出了时间约束观察和策略轨迹观察，以研究在更现实约束下一般递归函数的可学习性。虽然输入-输出观察不足以在极限条件下学习一般递归函数，但通过施加计算复杂性约束或补充近似时间约束观察，我们克服了这一学习障碍。此外，我们围绕计算代理的观察建立了正式框架，并表明从策略轨迹学习可计算函数可以简化为从输入和输出学习有理函数，从而揭示了与有限状态转换器推断的有趣联系。在负面结果方面，我们证明即使对于策略轨迹观察，线性时间可计算函数类也不存在可计算或多项式质量的特征集。

</details>


### [149] [DAILOC: Domain-Incremental Learning for Indoor Localization using Smartphones](https://arxiv.org/abs/2506.15554)
**中文标题：DAILOC：基于智能手机的领域增量学习室内定位方法**

*Akhil Singampalli,Danish Gufran,Sudeep Pasricha*

主要分类: cs.LG

摘要简述: DAILOC提出了一种新型领域增量学习框架，通过解耦策略和多级变分自编码器解决Wi-Fi指纹室内定位中的设备异构性和时间变化问题，显著提升了定位精度。


<details>
  <summary>详细信息</summary>
研究动机: Wi-Fi指纹室内定位在实际部署中面临设备异构性和时间变化带来的领域偏移问题，现有方法通常独立处理这些问题，导致泛化能力差和灾难性遗忘。

研究方法: DAILOC采用多级变分自编码器解耦领域偏移与位置相关特征，并引入记忆引导的潜在类别对齐机制以缓解灾难性遗忘。

研究结果: 实验表明，DAILOC在多个智能手机、建筑和时间实例中表现优异，平均误差降低2.74倍，最差情况误差降低4.6倍。

研究结论: DAILOC通过联合处理时间和设备引起的领域偏移，显著提升了室内定位的鲁棒性和准确性。

中文摘要: 基于Wi-Fi指纹的室内定位在实际部署中因设备异构性和时间变化导致的领域偏移而面临重大挑战。现有方法通常独立处理这些问题，导致泛化能力差和灾难性遗忘。本文提出DAILOC，一种新型领域增量学习框架，联合解决时间和设备引起的领域偏移。DAILOC通过多级变分自编码器解耦领域偏移与位置相关特征，并引入记忆引导的潜在类别对齐机制以缓解灾难性遗忘。实验表明，DAILOC在多个智能手机、建筑和时间实例中显著优于现有方法，平均误差降低2.74倍，最差情况误差降低4.6倍。

</details>


### [150] [Towards Explainable Indoor Localization: Interpreting Neural Network Learning on Wi-Fi Fingerprints Using Logic Gates](https://arxiv.org/abs/2506.15559)
**中文标题：迈向可解释的室内定位：利用逻辑门解释基于Wi-Fi指纹的神经网络学习**

*Danish Gufran,Sudeep Pasricha*

主要分类: cs.LG

摘要简述: 本文提出了一种名为LogNet的新型逻辑门框架，用于解释和增强基于深度学习的室内定位系统，解决了现有黑盒模型缺乏可解释性的问题，并显著提升了定位性能和模型效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于深度学习的室内定位系统多为黑盒模型，无法解释预测过程或应对环境动态变化，限制了模型的长期可靠性和适应性。本文旨在通过可解释性框架解决这一问题。

研究方法: 提出LogNet框架，利用逻辑门机制识别对每个参考点最具影响力的接入点，并分析环境噪声对定位决策的干扰，从而增强模型的可解释性和适应性。

研究结果: 实验表明，LogNet在多个真实建筑平面和两年时间变化中，不仅解释了深度学习模型的内部行为，还显著降低了定位误差（1.1x至2.8x）、模型大小（3.4x至43.3x）和延迟（1.5x至3.6x）。

研究结论: LogNet通过逻辑门机制实现了深度学习模型的可解释性，提升了室内定位系统的性能和长期稳定性，为实际部署提供了可靠支持。

中文摘要: 基于深度学习的室内定位在将Wi-Fi RSS指纹映射到物理位置方面表现出高精度，但大多数现有深度学习框架作为黑盒模型运行，无法解释预测过程或模型对现实噪声的响应。这种可解释性的缺失限制了我们对时间变化（由环境动态引起）影响的理解以及模型的长期可靠性调整。为此，我们提出了LogNet，一种基于逻辑门的新型框架，旨在解释和增强基于深度学习的室内定位。LogNet通过识别对每个参考点最具影响力的接入点，并揭示环境噪声如何干扰深度学习驱动的定位决策，实现了透明推理。这种可解释性使我们能够追踪和诊断模型故障，并调整深度学习系统以实现更稳定的长期部署。在多个真实建筑平面和两年时间变化的评估中，LogNet不仅解释了深度学习模型的内部行为，还显著提升了性能——定位误差降低1.1x至2.8x，模型大小缩小3.4x至43.3x，延迟降低1.5x至3.6x。

</details>


### [151] [GFLC: Graph-based Fairness-aware Label Correction for Fair Classification](https://arxiv.org/abs/2506.15620)
**中文标题：GFLC：基于图的公平感知标签校正方法用于公平分类**

*Modar Sulaiman,Kallol Roy*

主要分类: cs.LG

摘要简述: 本文提出了一种基于图的公平感知标签校正方法（GFLC），用于在分类任务中校正标签噪声并保持数据集的公平性。该方法结合预测置信度、图正则化和人口统计公平性激励，显著提升了性能与公平性之间的平衡。


<details>
  <summary>详细信息</summary>
研究动机: 随着人工智能系统在社会各领域（如医疗和法律）的影响日益加深，机器学习中的公平性变得至关重要。然而，训练数据中的标签偏差和噪声会影响模型性能和公平性评估。本文旨在解决这一问题，提出一种能够校正标签噪声并保持公平性的方法。

研究方法: GFLC方法结合了三个关键组件：预测置信度度量、基于Ricci流优化的图拉普拉斯正则化，以及显式的人口统计公平性激励。通过图结构优化和公平性约束，实现了标签噪声的校正和公平性的保持。

研究结果: 实验结果表明，GFLC方法在性能和公平性指标之间取得了显著改进，优于基线方法。

研究结论: GFLC是一种高效的方法，能够在分类任务中校正标签噪声并保持公平性，为构建更可信的机器学习系统提供了有力支持。

中文摘要: 机器学习中的公平性对于构建可信赖的人工智能系统至关重要，尤其是在医疗和法律等领域。然而，训练数据中的标签偏差和噪声会影响模型性能和公平性评估。为解决这一问题，本文提出了基于图的公平感知标签校正方法（GFLC），通过结合预测置信度度量、Ricci流优化的图拉普拉斯正则化和显式的人口统计公平性激励，有效校正标签噪声并保持数据集的公平性。实验结果表明，GFLC在性能和公平性指标之间取得了显著改进，优于基线方法。

</details>


### [152] [Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction](https://arxiv.org/abs/2506.15626)
**中文标题：基于MRI的脑龄预测的联邦学习：一项多中心研究用于卒中后功能恢复预测**

*Vincent Roca,Marc Tommasi,Paul Andrey,Aurélien Bellet,Markus D. Schirmer,Hilde Henon,Laurent Puy,Julien Ramon,Grégory Kuchcinski,Martin Bretzner,Renaud Lopes*

主要分类: cs.LG

摘要简述: 本研究探讨了联邦学习在基于MRI的脑龄预测（BrainAGE）中的应用，用于预测缺血性卒中患者的功能恢复。结果显示，联邦学习在保护数据隐私的同时，性能优于单中心模型，且BrainAGE与血管风险因素及卒中后功能恢复显著相关。


<details>
  <summary>详细信息</summary>
研究动机: 脑龄差异（BrainAGE）是反映脑健康的神经影像生物标志物，但训练稳健的BrainAGE模型需要大量数据，而隐私问题限制了数据共享。本研究旨在评估联邦学习在脑龄预测中的表现，并探讨其与卒中患者临床表型及功能恢复的关联。

研究方法: 研究使用来自16个医疗中心的1674名卒中患者的FLAIR脑影像数据，采用三种数据管理策略：集中学习（数据集中）、联邦学习（各中心本地训练）和单中心学习。通过标准机器学习和深度学习模型估计BrainAGE，并分析其与血管风险因素（如糖尿病、高血压、吸烟）及卒中后三个月功能恢复的关系。

研究结果: 集中学习的预测最准确，但联邦学习性能优于单中心模型。所有模型中，糖尿病患者的BrainAGE显著更高。BrainAGE与卒中后功能恢复的关联在多变量分析中具有统计学意义。

研究结论: 联邦学习可在不集中数据的情况下实现准确的脑龄预测。BrainAGE与血管风险因素及卒中后恢复的强关联表明其在卒中预后模型中的潜在价值。

中文摘要: 目的：脑龄差异（BrainAGE）是反映脑健康的神经影像生物标志物，但训练稳健的BrainAGE模型需要大量数据，而隐私问题限制了数据共享。本研究评估了联邦学习在缺血性卒中患者脑龄预测中的表现，并探讨其与临床表型及功能恢复的关联。方法：使用来自16个医疗中心的1674名卒中患者的FLAIR脑影像数据，采用集中学习、联邦学习和单中心学习三种策略。通过机器学习和深度学习模型估计BrainAGE，并分析其与血管风险因素及卒中后三个月功能恢复的关系。结果：集中学习的预测最准确，但联邦学习性能优于单中心模型。糖尿病患者的BrainAGE显著更高。BrainAGE与功能恢复的关联在多变量分析中显著。结论：联邦学习可在不集中数据的情况下实现准确的脑龄预测。BrainAGE与血管风险因素及卒中后恢复的强关联表明其在卒中预后模型中的潜在价值。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [153] [Improved Image Reconstruction and Diffusion Parameter Estimation Using a Temporal Convolutional Network Model of Gradient Trajectory Errors](https://arxiv.org/abs/2506.14995)
**中文标题：基于时间卷积网络的梯度轨迹误差模型改进图像重建与扩散参数估计**

*Jonathan B. Martin,Hannah E. Alderson,John C. Gore,Mark D. Does,Kevin D. Harkins*

主要分类: physics.med-ph

摘要简述: 本文提出了一种基于时间卷积网络的梯度轨迹误差模型，用于改进磁共振图像重建和扩散参数估计。该模型能准确预测梯度系统的非线性失真，显著提升图像质量和参数映射精度。


<details>
  <summary>详细信息</summary>
研究动机: 在非笛卡尔磁共振成像序列中，梯度轨迹误差会导致图像伪影和失真，严重影响图像质量。现有线性方法无法准确建模梯度系统的非线性行为，因此需要开发一种更精确的非线性模型。

研究方法: 研究团队在小动物成像系统上测量了一组训练梯度波形，并利用时间卷积网络训练模型，以预测成像系统产生的梯度波形。随后，将网络预测的梯度波形整合到图像重建流程中。

研究结果: 训练后的网络能够准确预测梯度系统的非线性失真。与名义梯度波形和梯度脉冲响应函数相比，该方法显著提升了图像质量和扩散参数映射的准确性。

研究结论: 时间卷积网络比现有线性方法更能准确建模梯度系统行为，可用于回顾性校正梯度误差，为磁共振图像重建提供新思路。

中文摘要: 摘要：梯度轨迹误差会在磁共振图像中引入显著的伪影和失真，尤其是在非笛卡尔成像序列中，不完美的梯度波形会大幅降低图像质量。目的：开发一种通用的非线性梯度系统模型，利用卷积网络准确预测梯度失真。方法：在小动物成像系统上测量了一组训练梯度波形，并用于训练时间卷积网络以预测成像系统产生的梯度波形。结果：训练后的网络能够准确预测梯度系统的非线性失真。将网络预测的梯度波形整合到图像重建流程中，相比名义梯度波形和梯度脉冲响应函数，显著提升了图像质量和扩散参数映射的准确性。结论：时间卷积网络比现有线性方法更能准确建模梯度系统行为，可用于回顾性校正梯度误差。

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [154] [Forecasting the spatiotemporal evolution of fluid-induced microearthquakes with deep learning](https://arxiv.org/abs/2506.14923)
**中文标题：基于深度学习的流体诱发微地震时空演化预测**

*Jaehong Chung,Michael Manga,Timothy Kneafsey,Tapan Mukerji,Mengsu Hu*

主要分类: physics.geo-ph

摘要简述: 本文提出了一种基于Transformer的深度学习模型，用于预测流体诱发微地震的时空演化，为地热增强系统等应用提供实时风险评估。


<details>
  <summary>详细信息</summary>
研究动机: 微地震（MEQs）记录了地下流体注入引起的应力状态和渗透性变化，预测其时空演化对地热增强系统（EGS）和CO2封存等应用至关重要。

研究方法: 研究采用Transformer深度学习模型，结合水力刺激历史和先前的微地震观测数据，预测微地震的累积数量、对数地震矩及50%和95%分位范围。

研究结果: 在EGS Collab实验数据集上，模型在1秒和15秒预测时间范围内分别达到R²>0.98和R²>0.88的精度，并提供不确定性估计。

研究结论: 该模型能够实时推断裂缝扩展和渗透性变化，展示了深度学习在地震风险评估和缓解策略中的潜力。

中文摘要: 地下流体注入产生的微地震（MEQs）记录了储层的应力状态和渗透性变化，预测其完整的时空演化对地热增强系统（EGS）、CO2封存等地质工程应用至关重要。本文提出了一种基于Transformer的深度学习模型，通过输入水力刺激历史和先前的微地震观测数据，预测四个关键指标：累积微地震数量、累积对数地震矩，以及微地震云的50%和95%分位范围（P50、P95）。在EGS Collab实验1数据集上，模型在1秒预测时间范围内对所有目标的R²>0.98，15秒预测时间范围内R²>0.88，并通过学习标准差项提供不确定性估计。这些准确且量化不确定性的预测能够实时推断裂缝扩展和渗透性变化，展示了深度学习方法在未来流体注入操作中改进地震风险评估和指导缓解策略的强大潜力。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [155] [Factorized RVQ-GAN For Disentangled Speech Tokenization](https://arxiv.org/abs/2506.15456)
**中文标题：分离式语音标记化的因子化RVQ-GAN**

*Sameer Khurana,Dominik Klement,Antoine Laurent,Dominik Bobos,Juraj Novosad,Peter Gazdik,Ellen Zhang,Zili Huang,Amir Hussein,Ricard Marxer,Yoshiki Masuyama,Ryo Aihara,Chiori Hori,Francois G. Germain,Gordon Wichern,Jonathan Le Roux*

主要分类: eess.AS

摘要简述: 本文提出了一种分层音频编解码器（HAC），通过将瓶颈分解为声学、音素和词汇三个层次，实现了语音的分离式标记化。HAC利用知识蒸馏目标，分别从预训练的语音编码器和文本编码器中提取音素和词汇信息，实验表明其标记集具有分离性和可解释性，优于单层次基线。


<details>
  <summary>详细信息</summary>
研究动机: 当前语音编解码器通常仅关注单一层次的信息（如声学或音素），缺乏对多层次语言结构的统一建模。本文旨在提出一种能够同时捕捉声学细节、音素结构和词汇语义的分离式语音标记化方法，以支持下游语音生成和理解任务。

研究方法: HAC通过将瓶颈分解为声学、音素和词汇三个层次，利用两个知识蒸馏目标：一是从预训练的语音编码器（HuBERT）中提取音素级结构，二是从文本编码器（LaBSE）中提取词汇线索。这种分层设计使得模型能够生成分离的标记集。

研究结果: 实验表明，HAC生成的标记集具有分离性：一个标记集与音素对齐，另一个标记集捕捉词汇级语义。定量评估显示，HAC在分离性和重建质量上均优于单层次基线，同时保留了语音的自然性和可解释性。

研究结论: HAC作为一种统一的离散语音表示方法，能够桥接声学细节和词汇语义，为下游语音生成和理解任务提供了潜力。其分层设计和知识蒸馏策略有效实现了语音的分离式标记化。

中文摘要: 我们提出了分层音频编解码器（HAC），这是一种统一的神经语音编解码器，其瓶颈被分解为声学、音素和词汇三个层次。HAC利用两个知识蒸馏目标：一个来自预训练的语音编码器（HuBERT）以提取音素级结构，另一个来自文本编码器（LaBSE）以捕捉词汇线索。在英语和多语言数据上的实验表明，HAC的因子化瓶颈生成了分离的标记集：一个与音素对齐，另一个捕捉词汇级语义。定量评估证实，HAC标记保留了自然性并提供了可解释的语言信息，在分离性和重建质量上均优于单层次基线。这些发现凸显了HAC作为一种统一离散语音表示的潜力，能够桥接声学细节和词汇语义，为下游语音生成和理解任务提供支持。

</details>


### [156] [Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition](https://arxiv.org/abs/2506.14973)
**中文标题：方向性思维：面向多说话者定向语音识别的语音大语言模型**

*Jiamin Xie,Ju Lin,Yiteng Huang,Tyler Vuong,Zhaojiang Lin,Zhaojun Yang,Peng Su,Prashant Rawat,Sangeeta Srivastava,Ming Sun,Florian Metze*

主要分类: eess.AS

摘要简述: 本文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制。通过S-DOT和CDDA技术，模型能有效理解方向性，实验表明其在语音识别和声源定位任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLM）在语音识别方面表现出色，但其对多通道音频和空间线索的理解能力尚未充分研究。本文旨在填补这一空白，探索如何利用智能眼镜的麦克风阵列实现更高效的定向语音处理。

研究方法: 提出了两种关键技术：序列化定向输出训练（S-DOT）和对比性方向数据增强（CDDA），以增强模型对方向性的理解。directional-SpeechLlama通过结合文本线索和空间音频，实现定向语音识别和声源定位。

研究结果: 实验结果表明，directional-SpeechLlama能够有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中均表现出色。

研究结论: 本文提出的directional-SpeechLlama为多通道音频处理提供了新的解决方案，展示了其在定向语音识别和声源定位中的潜力。

中文摘要: 近期研究表明，通过音频编码提示大型语言模型（LLM）可实现高效的语音识别能力。然而，语音LLM对具有空间线索的多通道音频的理解和处理能力仍是一个研究较少的领域。本文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制。为增强模型对方向性的理解，我们提出了两种关键技术：序列化定向输出训练（S-DOT）和对比性方向数据增强（CDDA）。实验结果表明，我们提出的directional-SpeechLlama能够有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中均表现出色。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [157] [Comparative Analysis of QNN Architectures for Wind Power Prediction: Feature Maps and Ansatz Configurations](https://arxiv.org/abs/2506.14795)
**中文标题：风能预测中QNN架构的比较分析：特征映射与Ansatz配置**

*Batuhan Hangun,Emine Akpinar,Oguz Altun,Onder Eyecioglu*

主要分类: quant-ph

摘要简述: 本研究通过比较12种不同的量子神经网络（QNN）架构，评估其在风能预测中的表现，发现采用Z特征映射的QNN预测准确率高达93%，优于经典方法，展示了量子机器学习在实际应用中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 量子机器学习（QML）结合量子计算与机器学习，利用量子力学原理提升经典方法性能。然而，由于当前噪声中等规模量子（NISQ）设备的限制，QML的实际优势受到质疑。本研究旨在通过评估QNN在风能预测中的表现，验证其有效性。

研究方法: 研究系统构建了12种不同的QNN配置，结合两种量子特征映射和六种纠缠策略设计ansatz。实验基于风能数据集，比较QNN与经典方法的预测性能。

研究结果: 实验结果显示，采用Z特征映射的QNN在仅使用四个输入参数时，风能预测准确率高达93%，显著优于经典方法。

研究结论: 研究表明，QNN在预测任务中表现优异，验证了量子机器学习在实际应用中的潜力，为未来研究提供了方向。

中文摘要: 量子机器学习（QML）是量子计算与机器学习交叉的新兴领域，旨在通过利用量子力学原理（如纠缠和叠加）提升经典机器学习方法。然而，由于当前噪声中等规模量子（NISQ）设备的限制，QML的实际优势仍受质疑。本研究通过全面评估量子神经网络（QNN）——人工神经网络（ANN）的量子版本，验证其相对于经典方法的有效性。我们系统构建并评估了12种不同的QNN配置，结合两种独特的量子特征映射和六种纠缠策略设计ansatz。基于风能数据集的实验表明，采用Z特征映射的QNN在仅使用四个输入参数时，风能预测准确率高达93%。研究结果显示，QNN在预测任务中优于经典方法，凸显了QML在实际应用中的潜力。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [158] [Omnidirectional Video Super-Resolution using Deep Learning](https://arxiv.org/abs/2506.14803)
**中文标题：基于深度学习的全方位视频超分辨率**

*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter W. Eklund,Sunil Aryal*

主要分类: cs.MM

摘要简述: 本文提出了一种名为S3PO的深度学习模型，用于解决360度视频超分辨率问题，通过创新的特征提取器和损失函数，显著提升了视频质量。


<details>
  <summary>详细信息</summary>
研究动机: 360度视频在虚拟现实中的应用广泛，但其空间分辨率不足影响了沉浸式体验。现有超分辨率技术未解决360度视频的投影失真问题，且缺乏相关数据集。

研究方法: 本文创建了360VDS数据集，并提出S3PO模型，采用循环建模和注意力机制，结合专用特征提取器和新型损失函数，优化球形失真问题。

研究结果: S3PO在360度视频数据集上表现优于现有超分辨率模型，并通过逐步消融研究验证了其架构组件的有效性。

研究结论: S3PO为360度视频超分辨率提供了高效解决方案，显著提升了视频质量，为未来研究奠定了基础。

中文摘要: 全方位视频（或360度视频）在虚拟现实（VR）中广泛应用，以提供沉浸式和交互式观看体验。然而，360度视频的有限空间分辨率无法为每个视角提供足够的像素，从而限制了沉浸式体验的视觉质量。传统的视频超分辨率（VSR）技术可能提供一种基于软件的解决方案，但这些技术并未解决360度视频信号在等距柱状投影中的失真问题。另一个障碍是缺乏可用于研究的360度视频数据集。为解决这些问题，本文创建了一个新颖的360度视频数据集（360VDS），并研究了传统VSR模型在360度视频中的扩展性。本文进一步提出了一种名为“球形信号超分辨率与比例优化”（S3PO）的新型深度学习模型。S3PO采用循环建模和注意力机制，摆脱了传统VSR技术（如对齐）的束缚。通过专用特征提取器和针对球形失真的新型损失函数，S3PO在360度视频数据集上的表现优于大多数最先进的传统VSR模型和360度专用超分辨率模型。本文还通过逐步消融研究，理解和展示了所选架构子组件、针对性训练和优化的影响。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [159] [Advancing Loss Functions in Recommender Systems: A Comparative Study with a Rényi Divergence-Based Solution](https://arxiv.org/abs/2506.15120)
**中文标题：推荐系统中损失函数的改进：基于Rényi散度的解决方案比较研究**

*Shengjia Zhang,Jiawei Chen,Changdong Li,Sheng Zhou,Qihao Shi,Yan Feng,Chun Chen,Can Wang*

主要分类: cs.IR

摘要简述: 本文比较了推荐系统中的Softmax损失和余弦对比损失，发现它们各有优缺点，并提出了一种基于Rényi散度的新损失函数DrRL，以综合两者的优势并解决其局限性。实验证明DrRL在推荐准确性和鲁棒性上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 推荐系统中的损失函数对模型优化至关重要。Softmax损失和余弦对比损失虽然有效，但各自存在局限性：前者对假阴性样本敏感，后者数据利用率低。本文旨在探索这两种损失的理论联系与差异，并提出一种更优的解决方案。

研究方法: 本文首先分析了Softmax损失和余弦对比损失的理论特性，发现它们均可视为传统损失函数与分布鲁棒优化的结合。随后，提出了一种基于Rényi散度的新损失函数DrRL，综合了两种损失的优点，并通过实验验证其性能。

研究结果: 实验结果表明，DrRL在推荐准确性和鲁棒性上均优于Softmax损失和余弦对比损失，有效解决了前者对假阴性样本的敏感性和后者数据利用率低的问题。

研究结论: 本文提出的DrRL损失函数通过结合Rényi散度优化，成功弥补了Softmax损失和余弦对比损失的不足，为推荐系统提供了一种更高效的损失函数选择。

中文摘要: 损失函数在优化推荐模型中起着关键作用。在众多损失函数中，Softmax损失（SL）和余弦对比损失（CCL）尤为有效。它们的理论联系与差异值得深入探讨。本研究对这两种损失进行了全面分析，得出以下重要结论：1）共同优势——两者均可视为传统损失函数与分布鲁棒优化（DRO）的结合，增强了对分布变化的鲁棒性；2）各自局限性——由于在DRO优化中使用了不同的分布距离度量，SL对假阴性样本高度敏感，而CCL存在数据利用率低的问题。为解决这些问题，本研究提出了一种新的损失函数DrRL，通过利用Rényi散度在DRO优化中泛化了SL和CCL。DrRL结合了SL和CCL的优势结构，并能有效缓解其局限性。大量实验验证了DrRL在推荐准确性和鲁棒性上的优越性。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [160] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
**中文标题：基于LabVIEW的精确修订版光学字符识别语音合成系统**

*Prateek Mehta,Anasuya Patil*

主要分类: cs.SD

摘要简述: 本文开发了一种基于光学字符识别（OCR）的语音合成系统，旨在为视障人士提供准确、可靠、经济且用户友好的阅读解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 视障人士通常依赖盲文书籍和NGO提供的音频资料，但这些方式存在局限性，无法满足个性化阅读需求。语音作为一种更有效的沟通方式，能够帮助视障人士更便捷地获取信息。

研究方法: 研究采用实验室虚拟仪器工程工作台（LabVIEW）实现OCR技术，开发了一套语音合成系统，通过光学字符识别将文本转换为语音。

研究结果: 成功开发出一套准确、可靠且成本效益高的OCR语音合成系统，为视障人士提供了更灵活的阅读选择。

研究结论: 基于OCR的语音合成系统为视障人士提供了一种高效、经济的阅读辅助工具，具有广泛的应用潜力。

中文摘要: 通过声音提取知识是一种独特的特性。视障人士通常仅依赖盲文书籍和非政府组织提供的音频资料。由于这些方法的局限性，盲人往往无法选择自己喜欢的书籍。对于盲人和视障人士来说，语音是比文本更有效的沟通方式，因为他们可以轻松对声音作出反应。本文提出了一种准确、可靠、经济且用户友好的基于光学字符识别（OCR）的语音合成系统的开发。该OCR系统采用实验室虚拟仪器工程工作台（LabVIEW）实现。

</details>


### [161] [SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](https://arxiv.org/abs/2506.15154)
**中文标题：SonicVerse：基于多任务学习的音乐特征感知描述生成**

*Anuradha Chopra,Abhinaba Roy,Dorien Herremans*

主要分类: cs.SD

摘要简述: 本文提出了一种多任务音乐描述模型SonicVerse，通过结合音乐特征检测任务（如调性检测、人声检测等）生成更丰富的音乐描述。实验表明，该方法显著提升了描述的质量和细节。


<details>
  <summary>详细信息</summary>
研究动机: 现有的音乐数据库缺乏详细的音乐描述，限制了音乐AI的研究。本文旨在通过结合音乐特征检测任务，生成更准确、丰富的音乐描述，以推动音乐AI的发展。

研究方法: 提出了一种基于投影的架构，将音频输入转换为语言标记，同时通过专用辅助头检测音乐特征。这些特征的输出也被投影为语言标记，以增强描述输入。此外，利用大语言模型生成时间感知的详细描述。

研究结果: 实验结果表明，通过结合音乐特征检测任务，生成的音乐描述在质量和细节上均有显著提升。

研究结论: SonicVerse模型通过多任务学习有效整合音乐特征检测与描述生成，为音乐数据库和音乐AI研究提供了更丰富的描述工具。

中文摘要: 能够准确反映音乐特征的详细描述可以丰富音乐数据库并推动音乐AI研究。本文提出了一种多任务音乐描述模型SonicVerse，该模型将描述生成与辅助音乐特征检测任务（如调性检测、人声检测等）相结合，以直接捕捉低层次声学细节和高层次音乐属性。关键贡献是一种基于投影的架构，将音频输入转换为语言标记，同时通过专用辅助头检测音乐特征。这些头的输出也被投影为语言标记，以增强描述输入。该框架不仅能为短音乐片段生成丰富的描述，还能通过大语言模型链接输出，为长音乐片段生成详细的时间感知描述。为训练模型，我们使用模块化音乐特征提取器MIRFLEX对MusicBench数据集进行标注，生成了配对的音频、描述和音乐特征数据。实验结果表明，通过这种方式结合特征可以显著提升生成描述的质量和细节。

</details>


### [162] [pycnet-audio: A Python package to support bioacoustics data processing](https://arxiv.org/abs/2506.14864)
**中文标题：pycnet-audio：一个支持生物声学数据处理的Python包**

*Zachary J. Ruff,Damon B. Lesmeister*

主要分类: cs.SD

摘要简述: pycnet-audio是一个Python包，用于支持生物声学数据处理，特别针对大规模被动声学监测项目，提供自动化检测工作流程。


<details>
  <summary>详细信息</summary>
研究动机: 被动声学监测在野生动物研究中日益重要，但大规模音频数据的处理需要自动化工具。pycnet-audio旨在解决这一问题，为研究人员提供高效的数据处理方案。

研究方法: pycnet-audio基于PNW-Cnet模型，该模型最初用于监测北斑点猫头鹰等森林猫头鹰种群，后扩展至检测约80种森林野生动物及多种人为和环境噪声。

研究结果: 该工具能够高效处理大规模音频数据，支持自动化检测目标信号（如动物叫声或噪声），显著减少人工审查的需求。

研究结论: pycnet-audio为生物声学数据处理提供了实用且高效的解决方案，特别适用于大规模被动声学监测项目。

中文摘要: 被动声学监测是野生动物研究中的一种新兴方法，利用专门设计的自动录音设备（ARU）进行数据采集。通常，ARU会在野外按计划长时间（数周或数月）录音，随后回收音频数据。这些数据需进一步处理，通常包括测量或分析音频特征（如计算声学指数），或在录音中搜索目标信号（如目标物种的叫声、人为或环境噪声等）。对于后者，需要某种方法定位音频中的目标信号。虽然小数据集可以手动搜索，但即使是中等规模的项目也可能产生约10^5小时的录音，手动审查不切实际，因此需要自动化检测。pycnet-audio（Ruff 2024）旨在为声学数据提供实用的处理流程，围绕PNW-Cnet模型构建。该模型最初由美国林务局开发，用于监测北斑点猫头鹰（Strix occidentalis caurina）及其他森林猫头鹰种群（Lesmeister和Jenkins 2022；Ruff等2020）。PNW-Cnet已扩展至检测约80种森林野生动物及多种人为和环境噪声（Ruff等2021、2023）。

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [163] [Identifying economic narratives in large text corpora -- An integrated approach using Large Language Models](https://arxiv.org/abs/2506.15041)
**中文标题：识别大规模文本语料库中的经济叙事——一种基于大型语言模型的综合方法**

*Tobias Schmidt,Kai-Robin Lange,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch*

主要分类: econ.GN

摘要简述: 本文探讨了利用大型语言模型（LLM）从文本中提取经济叙事的有效性，通过分析《华尔街日报》和《纽约时报》关于通胀的文章，发现GPT-4o能提取结构化经济叙事，但复杂文档处理仍不及专家水平。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，经济叙事研究兴趣增长，但现有自然语言处理技术（如BERT）缺乏深层语义理解，难以区分经济叙事提取与传统任务（如语义角色标注）。本文旨在评估LLM在此任务中的潜力。

研究方法: 研究采用严格叙事定义，分析《华尔街日报》和《纽约时报》关于通胀的文章，将GPT-4o输出与专家标注的黄金标准叙事对比，评估其性能。

研究结果: GPT-4o能提取有效的结构化经济叙事，但在处理复杂文档和叙事时仍不及专家水平。

研究结论: LLM在经济叙事提取中展现出潜力，但需进一步改进以处理复杂场景。本文为未来经济学和社会科学中LLM的应用提供了指导。

中文摘要: 近年来，对经济叙事的兴趣日益增长，提取此类叙事的流程也越来越多。这些流程通常采用最先进的自然语言处理技术（如BERT）来完成此任务。尽管这些模型在叙事提取的基础语言操作上表现良好，但缺乏区分经济叙事提取与传统任务（如语义角色标注）所需的深层语义理解。本文通过分析《华尔街日报》和《纽约时报》关于通胀的新闻报道，评估了大型语言模型（LLM）的优势。我们采用严格的叙事定义，并将GPT-4o的输出与专家标注的黄金标准叙事进行对比。结果表明，GPT-4o能够提取有效的结构化经济叙事，但在处理复杂文档和叙事时仍不及专家水平。鉴于LLM在经济研究中的新颖性，我们还为未来经济学和社会科学中类似目标的LLM应用提供了指导。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [164] [Collaborative Interest-aware Graph Learning for Group Identification](https://arxiv.org/abs/2506.14826)
**中文标题：协作兴趣感知图学习在群体识别中的应用**

*Rui Zhao,Beihong Jin,Beibei Li,Yiyuan Zheng*

主要分类: cs.SI

摘要简述: 本文提出了一种名为CI4GI的协作兴趣感知模型，用于解决社交平台上用户群体识别问题。该模型通过增强用户的双层次兴趣（群体级和项目级）并优化负样本识别，显著提升了群体推荐的性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着社交媒体的普及，用户参与群体活动的需求增加。现有方法未能充分建模用户群体级和项目级兴趣的协作演化关系，且存在负样本干扰问题。因此，需要一种新方法来更准确地推荐群体。

研究方法: CI4GI模型设计了一种兴趣增强策略，从用户已加入群体交互的项目中补充其项目级兴趣。同时，通过优化负样本识别，减少跨层次兴趣对齐时的干扰。

研究结果: 在三个真实数据集上的实验表明，CI4GI显著优于现有最优模型，验证了其有效性。

研究结论: CI4GI通过建模双层次兴趣的协作演化关系并优化负样本识别，为群体识别任务提供了更高效的解决方案。

中文摘要: 随着社交媒体的流行，越来越多的用户参与在线社交平台的群体活动，这引发了群体识别（GI）的需求，即向用户推荐群体。我们发现用户同时受到群体级和项目级兴趣的影响，且这两种兴趣存在协作演化关系：加入群体会扩展用户的项目兴趣，进而促使用户加入新群体，最终两种兴趣趋于动态对齐。然而，现有GI方法未能充分建模这种协作演化关系，忽略了群体级兴趣对项目级兴趣的增强作用，且在跨层次兴趣对齐时受到假负样本的干扰。为了充分建模用户双层次兴趣的协作演化关系，我们提出了CI4GI，一种协作兴趣感知的群体识别模型。具体而言，我们设计了一种兴趣增强策略，从用户已加入群体交互的项目中识别额外兴趣，作为项目级兴趣的补充。此外，我们利用两个用户兴趣分布之间的距离优化负样本识别，减少跨层次兴趣对齐时的假负样本干扰。在三个真实数据集上的实验结果表明，CI4GI显著优于现有最优模型。

</details>


### [165] [Detecting Narrative Shifts through Persistent Structures: A Topological Analysis of Media Discourse](https://arxiv.org/abs/2506.14836)
**中文标题：通过持久结构检测叙事转变：媒体话语的拓扑分析**

*Mark M. Bailey,Mark I. Heiligman*

主要分类: cs.SI

摘要简述: 本研究提出了一种基于拓扑学的方法，通过持久同调分析媒体叙事结构的变化，发现重大事件会导致叙事结构的突然重组，并揭示了语义变化的级联模式。


<details>
  <summary>详细信息</summary>
研究动机: 如何检测全球事件如何重塑公共话语？本研究旨在通过数学方法识别媒体叙事中的结构性变化，以理解重大事件对公共话语的影响。

研究方法: 研究利用国际新闻文章构建名词短语的共现图，并通过Vietoris-Rips过滤生成持久图。通过计算Wasserstein距离和持久熵，捕捉语义中断和叙事波动。

研究结果: 结果显示，重大事件与H0（连通分量）和H1（环）的急剧增加相关，表明叙事结构的突然重组。交叉相关分析揭示了语义变化的级联模式，但在俄乌战争中H1熵领先于H0，可能反映了自上而下的叙事框架。

研究结论: 持久同调提供了一种无监督的数学方法，能够实时检测公共话语的转折点和方向性变化，为计算社会科学提供了新的工具。

中文摘要: 如何检测全球事件如何从根本上重塑公共话语？本研究引入了一种拓扑框架，利用持久同调识别媒体叙事中的结构性变化。通过分析包括俄乌战争（2022年2月）、乔治·弗洛伊德谋杀案（2020年5月）、美国国会大厦骚乱（2021年1月）和哈马斯入侵以色列（2023年10月）在内的国际新闻文章，我们构建了名词短语的每日共现图以追踪话语演变。每张图通过Vietoris-Rips过滤嵌入并转化为持久图。随后，我们计算了Wasserstein距离和持久熵，以捕捉语义中断和叙事波动。结果显示，重大地缘政治和社会事件与H0（连通分量）和H1（环）的急剧增加相关，表明叙事结构的突然重组。交叉相关分析揭示了语义变化的级联模式，但在俄乌战争中H1熵领先于H0，可能反映了自上而下的叙事框架。持久熵进一步区分了紧密聚焦和分散的叙事模式。这些发现表明，持久同调提供了一种数学上严谨的无监督方法，能够在不依赖特定事件先验知识的情况下检测公共注意力的转折点和方向性变化。这种拓扑方法通过实时检测危机、抗议和信息冲击期间的语义重构，推动了计算社会科学的发展。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [166] [Deploying and Evaluating Multiple Deep Learning Models on Edge Devices for Diabetic Retinopathy Detection](https://arxiv.org/abs/2506.14834)
**中文标题：在边缘设备上部署和评估多种深度学习模型用于糖尿病视网膜病变检测**

*Akwasi Asare,Dennis Agyemanh Nana Gookyi,Derrick Boateng,Fortunatus Aabangbio Wulnye*

主要分类: eess.IV

摘要简述: 本研究提出了一种基于边缘计算的深度学习模型部署方案，用于实时检测糖尿病视网膜病变（DR）。通过优化多种卷积神经网络（CNN）模型，并在边缘设备上评估性能，实现了高精度和低延迟的诊断，尤其适用于资源有限的医疗环境。


<details>
  <summary>详细信息</summary>
研究动机: 糖尿病视网膜病变（DR）是全球糖尿病患者视力受损的主要原因，传统诊断方法耗时且资源密集。本研究旨在利用边缘计算技术，部署高效、实时的深度学习模型，为资源有限的医疗环境提供低成本、高精度的DR检测方案。

研究方法: 研究使用Kaggle EyePACS数据集中的3,662张视网膜眼底图像，通过数据增强和归一化进行预处理。设计了多种CNN模型（如MobileNet、ShuffleNet、SqueezeNet和自定义DNN），并优化为TensorFlowLite格式，量化至8位整数以减少模型大小并提升推理速度。在不同边缘硬件平台上评估了模型的性能指标。

研究结果: MobileNet模型准确率达96.45%，SqueezeNet在GPU上仅17毫秒的延迟且模型大小为176 KB，表现出色。ShuffleNet和自定义DNN在资源效率上表现优异，适合低端设备。所有模型在边缘设备上均实现了高精度和实时性能。

研究结论: 通过边缘AI技术，本研究为DR检测提供了一种可扩展、低成本的解决方案，尤其适用于资源有限的医疗环境，实现了快速、准确的诊断。

中文摘要: 糖尿病视网膜病变（DR）是糖尿病患者视力受损的主要原因，全球约34.6%的糖尿病患者受影响，预计到2045年病例数将达到2.42亿。传统DR诊断依赖人工检查视网膜眼底图像，耗时且资源密集。本研究提出了一种基于Edge Impulse的新方案，在边缘设备上部署多种深度学习模型以实现实时DR检测。研究使用了Kaggle EyePACS数据集中的3,662张视网膜眼底图像，并通过增强和归一化等预处理技术优化数据。利用TensorFlow设计了多种卷积神经网络（CNN），包括MobileNet、ShuffleNet、SqueezeNet和自定义深度神经网络（DNN），并将其转换为TensorFlowLite格式并量化为8位整数，以减少模型大小并提升推理速度，同时保持高精度。在不同边缘硬件平台（如智能手机和微控制器）上的性能评估中，MobileNet准确率达96.45%，SqueezeNet在GPU上仅17毫秒的延迟且模型大小为176 KB，表现出色。ShuffleNet和自定义DNN在资源效率上表现优异，适合低端设备。这一边缘AI技术在医疗领域的应用为早期DR检测提供了一种可扩展、低成本的解决方案，尤其适用于资源有限的远程医疗环境。

</details>


### [167] [Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)](https://arxiv.org/abs/2506.14909)
**中文标题：基于面部照片的健康识别基础人工智能模型（FAHR-Face）**

*Fridolin Haugg,Grace Lee,John He,Leonard Nürnberg,Dennis Bontempi,Danielle S. Bitterman,Paul Catalano,Vasco Prudente,Dmitrii Glubokov,Andrew Warrington,Suraj Pai,Dirk De Ruysscher,Christian Guthier,Benjamin H. Kann,Vadim N. Gladyshev,Hugo JWL Aerts,Raymond H. Mak*

主要分类: eess.IV

摘要简述: FAHR-Face是一种基于面部图像的基础AI模型，用于健康识别，包括生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）。模型在公开数据集和癌症患者数据中表现出色，具有高准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 面部外观为健康提供了非侵入性的窗口。研究旨在开发一种基础AI模型，通过面部图像捕捉生物老化和疾病相关死亡风险，为健康监测提供低成本、可扩展的解决方案。

研究方法: FAHR-FaceAge通过两阶段年龄平衡微调在749,935张公开图像上训练；FAHR-FaceSurvival在34,389张癌症患者照片上微调。测试了模型的鲁棒性（如整容手术、化妆、姿势、光照）和独立性（显著性映射）。临床测试中，使用多变量Cox模型分析生存数据，并调整临床预后因素。

研究结果: FAHR-FaceAge在公开数据集上的平均绝对误差为5.1年，优于基准模型，并在癌症患者中表现出更好的生存预后能力。FAHR-FaceSurvival能稳健预测死亡率，最高风险组死亡率是最低风险组的3倍以上（调整后风险比3.22；P<0.001）。两种算法提供互补的预后信息，结合使用可提高预后准确性。

研究结论: 单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物老化和疾病相关死亡风险。该模型支持使用较小临床数据集进行有效训练。

中文摘要: 背景：面部外观为健康提供了非侵入性的窗口。我们开发了FAHR-Face，一种基于超过4000万张面部图像训练的基础模型，并针对两项任务进行了微调：生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）。
方法：FAHR-FaceAge在749,935张公开图像上进行了两阶段年龄平衡微调；FAHR-FaceSurvival在34,389张癌症患者照片上微调。测试了模型的鲁棒性（如整容手术、化妆、姿势、光照）和独立性（显著性映射）。两种模型在两个独立的癌症患者数据集中进行了临床测试，生存分析通过多变量Cox模型完成，并调整了临床预后因素。
结果：在年龄估计方面，FAHR-FaceAge在公开数据集上的平均绝对误差为5.1年，优于基准模型，并在全年龄段保持准确性。在癌症患者中，FAHR-FaceAge在生存预后方面优于先前的面部年龄估计模型。FAHR-FaceSurvival能稳健预测死亡率，最高风险组的死亡率是最低风险组的3倍以上（调整后风险比3.22；P<0.001）。这些发现在独立队列中得到验证，两种模型在年龄、性别、种族和癌症亚组中均表现出普适性。两种算法提供互补的预后信息；显著性映射显示每种模型依赖不同的面部区域。结合FAHR-FaceAge和FAHR-FaceSurvival可提高预后准确性。
解释：单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物老化和疾病相关死亡风险。该模型支持使用较小临床数据集进行有效训练。

</details>


### [168] [Empirical Studies of Large Scale Environment Scanning by Consumer Electronics](https://arxiv.org/abs/2506.14771)
**中文标题：消费电子产品大规模环境扫描的实证研究**

*Mengyuan Wang,Yang Liu,Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

主要分类: eess.IV

摘要简述: 本文对消费级3D扫描设备Matterport Pro3在大规模环境重建中的表现进行了实证评估，通过扫描六层建筑（17,567平方米）并分析其性能、局限性和改进方法，展示了其在点云密度和对齐精度上的优势。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估消费级3D扫描设备Matterport Pro3在大规模环境重建中的实际表现，探索其性能、局限性及改进方法，为相关应用提供参考。

研究方法: 研究对六层建筑（17,567平方米）进行了1,099次详细扫描，分析了Matterport Pro3的性能，并与iPhone进行了对比，同时提出了解决扫描中遇到问题的方案。

研究结果: Matterport Pro3生成的点云密度更高（1,877,324点），对齐精度更高（RMSE为0.0118米），且与iPhone相比，云到云平均距离误差为0.0408米（标准差0.0715米）。

研究结论: 研究表明Matterport Pro3能够生成高质量的大规模3D模型，结合LiDAR和先进对齐技术，适用于实际应用。

中文摘要: 本文对消费级3D扫描设备Matterport Pro3在大规模环境重建中的表现进行了实证评估。我们通过扫描一栋六层建筑（17,567平方米，共1,099个扫描点），评估了该设备的有效性、局限性及性能提升方法。针对扫描中遇到的问题，提出了解决方案，并探索了更有效的改进方法。与另一款消费级设备（iPhone）的对比分析显示，Pro3在成本效益和性能之间取得了平衡。Matterport Pro3生成的点云密度更高（1,877,324点，iPhone为506,961点），对齐精度更高（RMSE为0.0118米）。两模型间的云到云平均距离误差为0.0408米（标准差0.0715米）。研究表明，Pro3能够生成适用于大规模应用的高质量3D模型，得益于其LiDAR技术和先进对齐方法。

</details>


### [169] [Improving Prostate Gland Segmenting Using Transformer based Architectures](https://arxiv.org/abs/2506.14844)
**中文标题：基于Transformer架构的前列腺腺体分割改进**

*Shatha Abudalou*

主要分类: eess.IV

摘要简述: 本研究探讨了基于Transformer的架构（UNETR和SwinUNETR）在T2加权MRI图像中前列腺分割的性能，发现SwinUNETR在减少标签噪声和类别不平衡敏感性方面优于传统CNN模型，Dice分数提升高达5分。


<details>
  <summary>详细信息</summary>
研究动机: 由于读者间差异和跨站点域偏移，T2加权MRI图像的前列腺自动分割面临挑战。本研究旨在验证Transformer模型能否在这种异质性下保持高精度。

研究方法: 研究比较了UNETR和SwinUNETR与基线3D UNet的性能，使用了546个由两位专家标注的MRI（T2加权）数据。分析了三种训练策略：单队列数据集、5折交叉验证混合队列和基于腺体大小的数据集，并通过Optuna调整超参数。

研究结果: 在单读者训练中，SwinUNETR的平均Dice分数为0.816（读者1）和0.860（读者2），优于UNETR和基线UNet。在交叉验证混合训练中，SwinUNETR表现更优，Dice分数达0.8583（读者1）和0.867（读者2）。基于腺体大小的数据集上，SwinUNETR在较大腺体子集中的Dice分数为0.902（读者1）和0.894（读者2）。

研究结论: 全局和移位窗口自注意力机制有效减少了标签噪声和类别不平衡敏感性，使SwinUNETR在Dice分数上比CNN模型提升高达5分，同时保持计算效率，适合临床部署。

中文摘要: 读者间差异和跨站点域偏移对基于T2加权MRI图像的前列腺自动分割提出了挑战。本研究探讨了Transformer模型能否在这种异质性下保持精度。我们比较了UNETR和SwinUNETR与先前3D UNet模型在前列腺腺体分割中的性能，使用了546个由两位独立专家标注的MRI（T2加权）数据。分析了三种训练策略：单队列数据集、5折交叉验证混合队列和基于腺体大小的数据集，并通过Optuna调整超参数。测试集来自独立读者群体，以Dice相似系数为评估终点。在单读者训练中，SwinUNETR的平均Dice分数为0.816（读者1）和0.860（读者2），而UNETR为0.8和0.833，基线UNet为0.825和0.851。在交叉验证混合训练中，SwinUNETR的平均Dice分数为0.8583（读者1）和0.867（读者2）。在基于腺体大小的数据集上，SwinUNETR在较大腺体子集中的Dice分数为0.902（读者1）和0.894（读者2），而UNETR表现较差。结果表明，全局和移位窗口自注意力机制有效减少了标签噪声和类别不平衡敏感性，使Dice分数比CNN模型提升高达5分，同时保持计算效率，这为SwinUNETR的临床部署提供了高鲁棒性。

</details>


### [170] [Recursive Variational Autoencoders for 3D Blood Vessel Generative Modeling](https://arxiv.org/abs/2506.14914)
**中文标题：用于3D血管生成建模的递归变分自编码器**

*Paula Feldman,Miguel Fainstein,Viviana Siless,Claudio Delrieux,Emmanuel Iarussi*

主要分类: eess.IV

摘要简述: 本文提出了一种递归变分神经网络（RvNN），用于生成3D血管模型，能够捕捉血管的复杂性和多样性，适用于医学训练和模拟。


<details>
  <summary>详细信息</summary>
研究动机: 解剖树结构在临床诊断和治疗规划中至关重要，但现有方法难以准确表示其复杂多变的拓扑和几何特征。

研究方法: 开发了一种递归变分神经网络（RvNN），利用血管的层次结构，学习低维流形编码分支连接性和几何特征，从而生成新的血管模型。

研究结果: 生成的3D血管模型在半径、长度和弯曲度等方面与真实数据高度相似，适用于医学训练和血流动力学模拟。

研究结论: RvNN首次成功用于血管合成，生成的模型既准确又多样，为医学应用提供了重要工具。

中文摘要: 解剖树结构在临床诊断和治疗规划中具有重要作用。然而，由于其复杂多变的拓扑和几何特征，准确表示这些结构具有显著挑战。现有的血管合成方法多为基于规则，虽然能提供一定程度的控制和变化，但无法捕捉真实解剖数据的多样性和复杂性。我们开发了一种递归变分神经网络（RvNN），充分利用血管的层次结构，学习编码分支连接性和描述目标表面几何特征的低维流形。训练后，RvNN的潜在空间可用于生成新的血管几何形状。通过利用生成神经网络的强大能力，我们生成了既准确又多样的3D血管模型，这对于医学和外科训练、血流动力学模拟等用途至关重要。这些结果与真实数据高度相似，在血管半径、长度和弯曲度等方面表现优异，包括带有动脉瘤的数据集。据我们所知，这是首次利用该技术合成血管的研究。

</details>


### [171] [NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal Neurological Disorder Classification](https://arxiv.org/abs/2506.14970)
**中文标题：NeuroMoE：基于Transformer的混合专家框架用于多模态神经疾病分类**

*Wajih Hassan Raza,Aamir Bader Shah,Yu Wen,Yidan Shen,Juan Diego Martinez Lemus,Mya Caryn Schiess,Timothy Michael Ellmore,Renjie Hu,Xin Fu*

主要分类: eess.IV

摘要简述: 本文提出了一种基于Transformer的混合专家框架NeuroMoE，用于多模态神经疾病分类，显著提升了诊断准确性。


<details>
  <summary>详细信息</summary>
研究动机: 现有深度学习方法在多模态MRI和临床数据融合方面表现不佳，无法有效提升神经疾病的诊断准确性。

研究方法: 利用多模态MRI（aMRI、DTI、fMRI）和临床数据，提出基于Transformer的混合专家框架，通过模态特定专家提取特征，并采用自适应融合门控机制动态整合专家输出。

研究结果: 实验表明，该框架验证准确率达82.47%，优于基线方法10%以上，尤其在区分重叠疾病状态方面表现突出。

研究结论: NeuroMoE框架通过多模态学习显著提升了神经疾病的诊断准确性，具有临床应用的潜力。

中文摘要: 多模态磁共振成像（MRI）与临床数据的结合为神经疾病（NDs）的诊断提供了巨大潜力。深度学习（DL）已成为从医学数据中提取有意义模式以辅助诊断的强大工具。然而，现有DL方法在多模态MRI和临床数据的有效利用方面表现不佳，导致诊断性能不理想。为解决这一问题，我们利用专为ND研究定制的多模态临床数据集，提出了一种基于Transformer的混合专家（MoE）框架，用于ND分类。该框架结合了多种MRI模态（解剖MRI、扩散张量成像和功能MRI）及临床评估。通过Transformer编码器捕捉体积MRI数据的空间关系，并利用模态特定专家进行针对性特征提取。自适应融合门控机制动态整合专家输出，确保最佳预测性能。综合实验及与多种基线方法的比较表明，我们的多模态方法显著提升了诊断准确性，尤其在区分重叠疾病状态方面表现突出。该框架验证准确率达82.47%，优于基线方法10%以上，展示了其在真实临床数据中应用多模态学习以改善ND诊断的潜力。

</details>


### [172] [Classification of Multi-Parametric Body MRI Series Using Deep Learning](https://arxiv.org/abs/2506.15182)
**中文标题：基于深度学习的多参数体部MRI序列分类**

*Boah Kim,Tejas Sudharshan Mathai,Kimberly Helm,Peter A. Pinto,Ronald M. Summers*

主要分类: eess.IV

摘要简述: 本文提出了一种基于深度学习的模型，用于分类8种不同的多参数磁共振成像（mpMRI）序列类型，以提高放射科医生的工作效率。通过比较ResNet、EfficientNet和DenseNet等模型，发现DenseNet-121表现最佳，并在内部和外部数据集上均显示出高准确性。


<details>
  <summary>详细信息</summary>
研究动机: 多参数磁共振成像（mpMRI）的DICOM头文件中常因协议多样性和技术员错误而包含不准确信息，导致放射科医生阅读效率低下。本文旨在通过深度学习模型自动分类MRI序列类型，提升工作效率。

研究方法: 使用来自多个机构的mpMRI数据，训练ResNet、EfficientNet和DenseNet等深度学习分类器，比较其性能。选择表现最佳的DenseNet-121模型，研究其在不同训练数据量下的表现，并在外部数据集（DLDS和CPTAC-UCEC）上进行验证。

研究结果: DenseNet-121模型在内部数据集上达到F1分数0.966和准确率0.972，显著优于其他模型（p值<0.05）。当训练数据量超过729项研究时，模型准确率超过0.95。在外部数据集DLDS和CPTAC-UCEC上，准确率分别为0.872和0.810。

研究结论: DenseNet-121模型在分类8种mpMRI序列类型任务中表现出色，适用于内部和外部数据集，且性能随训练数据量增加而提升。

中文摘要: 多参数磁共振成像（mpMRI）检查包含多种不同成像协议获取的序列类型，其DICOM头文件常因协议多样性和技术员错误而包含不准确信息。为此，本文提出了一种基于深度学习的分类模型，用于自动分类8种体部mpMRI序列类型，以提高放射科医生的工作效率。通过使用来自多个机构的mpMRI数据，训练了ResNet、EfficientNet和DenseNet等多种深度学习分类器，并比较了它们的性能。随后，确定了表现最佳的DenseNet-121模型，并研究了其在不同训练数据量下的分类能力。此外，模型还在外部数据集（DLDS和CPTAC-UCEC）上进行了评估。实验结果表明，DenseNet-121模型的F1分数和准确率分别达到0.966和0.972，显著优于其他模型（p值<0.05）。当训练数据量超过729项研究时，模型准确率超过0.95。在外部数据集DLDS和CPTAC-UCEC上，模型准确率分别为0.872和0.810。这些结果表明，DenseNet-121模型在内部和外部数据集上均能高效完成8种体部MRI序列类型的分类任务。

</details>


### [173] [Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference](https://arxiv.org/abs/2506.15258)
**中文标题：基于潜在空间同态加密神经推理的隐私保护胸部X光分类**

*Jonghun Kim,Gyeongdeok Jo,Shinyoung Ra,Hyunjin Park*

主要分类: eess.IV

摘要简述: 本文提出了一种基于同态加密（HE）的医疗图像隐私保护框架，通过VQGAN压缩图像为潜在表示以减少计算负担，同时保持图像质量。方法优化了激活函数并引入压缩因子，在胸部X光多标签分类任务中验证了其可行性。


<details>
  <summary>详细信息</summary>
研究动机: 医疗影像数据包含敏感患者信息，需强隐私保护。传统方法需将数据发送至服务器进行推理，而同态加密（HE）可在加密数据上直接计算，但计算成本高，尤其是对大图像（如胸部X光）。本文旨在解决HE推理的高计算成本问题。

研究方法: 使用VQGAN将图像压缩为潜在表示以减少计算负担；用低阶多项式近似激活函数以平衡精度与效率；引入压缩因子（下采样因子为8）优化性能与计算成本；结合挤压激励模块增强HE框架。在胸部X光数据集上测试多标签分类任务。

研究结果: 实验表明，压缩因子为8时性能与计算成本达到最优平衡。HE推理虽比未加密推理稍慢且性能略有差异，但该方法在医疗图像中具有实际应用潜力。

研究结论: 本文提出的HE框架通过压缩图像和优化计算，显著降低了医疗图像隐私保护的计算负担，为实际应用提供了可行方案。

中文摘要: 医疗影像数据包含敏感患者信息，需强隐私保护。许多分析场景需将数据发送至服务器进行推理。同态加密（HE）允许在加密数据上直接计算，但HE推理计算成本高，尤其对大图像（如胸部X光）。本研究提出一种HE推理框架，利用VQGAN将图像压缩为潜在表示，显著降低计算负担并保持图像质量。通过低阶多项式近似激活函数以平衡精度与效率。实验发现压缩因子为8时性能与计算成本最优。进一步引入挤压激励模块增强HE框架。在两种胸部X光数据集上测试多标签分类任务。尽管HE推理较慢且性能略有差异，但该方法在医疗图像中具有实际应用潜力。

</details>


### [174] [FedWSIDD: Federated Whole Slide Image Classification via Dataset Distillation](https://arxiv.org/abs/2506.15365)
**中文标题：FedWSIDD：基于数据集蒸馏的联邦全切片图像分类**

*Haolong Jin,Shenglin Liu,Cong Cong,Qingmin Feng,Yongzhi Liu,Lina Huang,Yingzi Hu*

主要分类: eess.IV

摘要简述: FedWSIDD是一种基于数据集蒸馏的联邦学习方法，用于全切片图像分类，解决了计算资源异构和隐私问题，通过合成幻灯片提升分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在医学图像分析中具有潜力，但全切片图像分类面临计算资源异构和隐私保护挑战，需要一种高效且隐私安全的解决方案。

研究方法: FedWSIDD通过数据集蒸馏生成合成幻灯片，服务器聚合并分发这些幻灯片，客户端结合染色归一化技术生成紧凑且信息丰富的合成数据，替代模型参数传输。

研究结果: 在CAMELYON16和CAMELYON17等任务上的实验表明，FedWSIDD支持异构本地模型，提升分类性能，同时保护患者隐私。

研究结论: FedWSIDD为复杂全切片图像分类任务提供了高效、灵活且隐私安全的解决方案。

中文摘要: 联邦学习（FL）已成为协作医学图像分析的一种有前景的方法，允许多个机构在保护敏感患者数据的同时构建强大的预测模型。在全切片图像（WSI）分类中，FL面临显著挑战，包括参与医疗机构之间的异构计算资源和隐私问题。为解决这些问题，我们提出了FedWSIDD，一种新颖的FL范式，利用数据集蒸馏（DD）学习和传输合成幻灯片。在服务器端，FedWSIDD聚合来自参与中心的合成幻灯片并将其分发给所有中心。在客户端，我们引入了一种针对组织病理学数据集的新型DD算法，将染色归一化纳入蒸馏过程，生成一组紧凑且信息丰富的合成幻灯片。这些合成幻灯片而非模型参数被传输到服务器。通信后，接收到的合成幻灯片与原始幻灯片结合用于本地任务。在CAMELYON16和CAMELYON17等多个WSI分类任务上的广泛实验表明，FedWSIDD为异构本地模型提供了灵活性，提升了本地WSI分类性能，并保护了患者隐私。这使其成为复杂WSI分类任务的高效解决方案。代码可在FedWSIDD获取。

</details>


### [175] [A Real-time Endoscopic Image Denoising System](https://arxiv.org/abs/2506.15395)
**中文标题：实时内窥镜图像去噪系统**

*Yu Xing,Shishi Huang,Meng Lv,Guo Chen,Huailiang Wang,Lingzhi Sui*

主要分类: eess.IV

摘要简述: 本文提出了一种实时内窥镜图像去噪系统，通过结合传统图像处理算法与学习技术，有效解决了小型化模拟图像传感器带来的噪声问题，并在FPGA平台上实现了实时性能。


<details>
  <summary>详细信息</summary>
研究动机: 小型化内窥镜虽提升了医疗诊断的灵活性和便携性，但其模拟图像传感器因感光面积有限和简化电路设计引入了显著噪声问题，亟需一种高效去噪方法。

研究方法: 研究首先建立了内窥镜模拟图像传感器的噪声模型，涵盖固定模式噪声、周期性带状噪声和混合泊松-高斯噪声；随后提出了一种结合传统算法与学习技术的混合去噪系统。

研究结果: 实验表明，该系统在FPGA平台上实现了实时去噪，平均PSNR从21.16提升至33.05，且未损失图像细节或导致色彩失真。

研究结论: 本文提出的混合去噪系统有效解决了小型化内窥镜的噪声问题，为实时医疗图像处理提供了可行方案。

中文摘要: 小型化设计的内窥镜显著提升了操作的灵活性、便携性和诊断能力，同时大幅降低了医疗过程的侵入性。近年来，配备超紧凑模拟图像传感器（尺寸小于1mm x 1mm）的一次性内窥镜为医疗诊断带来了革命性进步。它们减少了可重复使用设备的结构冗余和高额资本支出，消除了因消毒不彻底导致的患者感染风险，并减轻了患者痛苦。然而，有限的感光面积导致每个像素捕获的光子减少，需通过更高的光子灵敏度设置来维持亮度。在高对比度医疗成像场景中，小型传感器的动态范围受限，难以同时捕捉高光和阴影的细节，需额外局部数字增益补偿。此外，简化的电路设计和模拟信号传输引入了额外噪声源。这些因素共同导致处理后的内窥镜图像存在显著噪声问题。本研究为医疗内窥镜中的模拟图像传感器建立了全面的噪声模型，涵盖三种主要噪声类型：固定模式噪声、周期性带状噪声和混合泊松-高斯噪声。基于此分析，我们提出了一种混合去噪系统，将传统图像处理算法与先进学习技术相结合，用于处理传感器捕获的原始帧。实验表明，该方法在不损失细节或导致色彩失真的情况下有效降低了图像噪声，并在FPGA平台上实现了实时性能，测试数据集的平均PSNR从21.16提升至33.05。

</details>


### [176] [Advanced cervical cancer classification: enhancing pap smear images with hybrid PMD Filter-CLAHE](https://arxiv.org/abs/2506.15489)
**中文标题：高级宫颈癌分类：通过混合PMD滤波器-CLAHE增强Pap涂片图像**

*Ach Khozaimi,Isnani Darti,Syaiful Anam,Wuryansari Muharini Kusumawinahyu*

主要分类: eess.IV

摘要简述: 本研究探讨了混合PMD滤波器-CLAHE预处理技术对宫颈癌分类中CNN性能的影响，结果显示该方法显著提升了图像质量和分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 宫颈癌在发展中国家仍是一个严重的健康问题，早期检测对治疗至关重要。尽管CNN在自动化筛查中表现良好，但其性能依赖于Pap涂片图像质量。

研究方法: 研究评估了三种预处理技术：PMD滤波器降噪、CLAHE增强对比度以及提出的混合PMD滤波器-CLAHE方法，并在多种预训练模型上测试了增强后的图像数据集。

研究结果: 混合PMD滤波器-CLAHE方法显著提升了图像质量和CNN性能，最高提升为准确率13.62%、精确率10.04%、召回率13.08%和F1分数14.34%。

研究结论: 混合PMD滤波器-CLAHE技术为提升宫颈癌分类性能提供了新思路，尤其在CNN架构中表现优异。

中文摘要: 宫颈癌在发展中国家仍是一个严重的健康问题，早期检测对有效治疗至关重要。卷积神经网络（CNN）在自动化宫颈癌筛查中显示出潜力，但其性能依赖于Pap涂片图像质量。本研究探讨了多种图像预处理技术对CNN性能的影响，使用了SIPaKMeD数据集。评估了三种预处理技术：PMD滤波器降噪、CLAHE增强对比度以及提出的混合PMD滤波器-CLAHE方法。增强后的图像数据集在多种预训练模型（如ResNet-34、ResNet-50、SqueezeNet-1.0、MobileNet-V2、EfficientNet-B0、EfficientNet-B1、DenseNet-121和DenseNet-201）上进行了测试。结果显示，混合PMD滤波器-CLAHE预处理能显著提升Pap涂片图像质量和CNN性能，最高提升为准确率13.62%、精确率10.04%、召回率13.08%和F1分数14.34%。该技术为提升宫颈癌分类性能提供了新视角。

</details>


### [177] [Automated MRI Tumor Segmentation using hybrid U-Net with Transformer and Efficient Attention](https://arxiv.org/abs/2506.15562)
**中文标题：基于混合U-Net与Transformer及高效注意力的MRI肿瘤自动分割**

*Syed Haider Ali,Asrar Ahmad,Muhammad Ali,Asifullah Khan,Muhammad Shahban,Nadeem Shaukat*

主要分类: eess.IV

摘要简述: 本研究提出了一种结合U-Net和Transformer的高效混合模型，用于MRI肿瘤自动分割，通过本地医院数据集训练，取得了较高的分割精度（Dice系数0.764），强调了针对特定临床场景开发模型的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI分割模型多基于大型公共数据集，缺乏对本地患者群体的适应性。本研究旨在开发一种适用于本地医院数据的高效肿瘤分割模型，以优化放疗计划。

研究方法: 采用混合U-Net-Transformer架构，结合高效注意力模块（如SE块、CBAM和ResNeXt块），并通过数据增强和预训练权重初始化提升模型性能。训练使用双NVIDIA T4 GPU，最大批次为8。

研究结果: 在本地MRI数据集上，模型Dice相似系数为0.764，IoU为0.736，表现出色，验证了模型在有限数据下的竞争力。

研究结论: 研究表明，针对特定临床场景开发的模型能显著提升肿瘤分割精度，为AI在临床中的实际应用提供了重要支持。

中文摘要: 癌症是一种异常生长，可能局部侵袭并转移至远处器官。放疗计划优化需要准确自动分割肿瘤及周围正常组织。现有基于AI的分割模型通常基于大型公共数据集训练，缺乏对本地患者群体的异质性考虑。尽管这些研究推动了AI在医学图像分割中的应用，但基于本地数据集的研究对于开发并集成AI肿瘤分割模型至医院软件中，以实现高效精准的肿瘤治疗计划与执行至关重要。本研究通过结合计算高效的混合U-Net-Transformer模型，在严格隐私保护下使用本地医院MRI数据集提升肿瘤分割性能。我们开发了稳健的数据流程，实现无缝DICOM提取与预处理，并通过大量图像增强确保模型在多样化临床环境中的泛化能力，最终获得6080张训练图像。新颖的架构将基于U-Net的卷积神经网络与Transformer瓶颈及互补注意力模块（包括高效注意力、SE块、CBAM和ResNeXt块）相结合。为加速收敛并降低计算需求，我们采用最大批次8，并使用预训练ImageNet权重初始化编码器，通过检查点在双NVIDIA T4 GPU上训练模型以克服Kaggle运行时限制。在本地MRI数据集上的定量评估显示，Dice相似系数为0.764，IoU为0.736，尽管数据有限，仍表现出竞争力，凸显了针对特定场景开发模型对临床部署的重要性。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [178] [Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers](https://arxiv.org/abs/2506.14855)
**中文标题：反馈-MPPI：基于采样快速MPC的滚动微分法——告别低级控制器**

*Tommaso Belvedere,Michael Ziegltrum,Giulio Turrisi,Valerio Modugno*

主要分类: cs.RO

摘要简述: 本文提出Feedback-MPPI（F-MPPI），通过引入局部线性反馈增益改进标准MPPI，显著提升复杂机器人任务中的实时控制性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统MPPI方法在实时高频机器人控制中因计算需求大而受限，本文旨在通过局部反馈增益优化其性能。

研究方法: F-MPPI通过灵敏度分析计算局部线性反馈增益，结合Riccati反馈思想，实现快速闭环修正，无需每步完全重新优化。

研究结果: 仿真和实际实验（四足机器人动态运动与四旋翼激进机动）表明，F-MPPI显著提升控制性能和稳定性。

研究结论: F-MPPI通过局部反馈增益实现了复杂机器人系统的高频鲁棒控制，为实时应用提供了有效解决方案。

中文摘要: 模型预测路径积分控制（MPPI）是一种强大的基于采样的方法，因其处理非线性动力学和非凸成本的灵活性，适用于复杂机器人任务。然而，其在实时高频机器人控制场景中的应用受限于计算需求。本文提出反馈-MPPI（F-MPPI），通过从灵敏度分析中提取局部线性反馈增益（灵感来自基于梯度的MPC中使用的Riccati反馈）增强标准MPPI。这些增益允许围绕当前状态快速闭环修正，无需每步完全重新优化。我们通过仿真和实际实验（四足机器人在不平地形动态运动与四旋翼机载计算执行激进机动）验证了F-MPPI的有效性。结果表明，引入局部反馈显著提升控制性能和稳定性，适用于复杂机器人系统的鲁棒高频操作。

</details>


### [179] [FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization](https://arxiv.org/abs/2506.14968)
**中文标题：FEAST：一种面向野外个性化的灵活餐饮辅助系统**

*Rajat Kumar Jenamani,Tom Silver,Ben Dodson,Shiqin Tong,Anthony Song,Yuting Yang,Ziang Liu,Benjamin Howe,Aimee Whitneck,Tapomayukh Bhattacharjee*

主要分类: cs.RO

摘要简述: FEAST是一种灵活的餐饮辅助系统，旨在满足个性化需求，通过模块化硬件、多样化交互方式和可调行为树实现适应性、透明性和安全性，并在实际应用中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 全球数百万人需要餐饮辅助，但家庭环境中的餐饮辅助面临活动多样性、情境复杂性和用户偏好差异等挑战。FEAST旨在通过个性化设计解决这些问题。

研究方法: FEAST采用模块化硬件支持多种辅助功能（如进食、饮水和擦嘴），提供多种交互方式（如网页界面、头部手势和物理按钮），并通过参数化行为树和大型语言模型实现安全透明的个性化调整。

研究结果: FEAST在透明性和安全性方面表现优异，优于固定定制化的基线系统，并通过家庭用户研究和职业治疗师评估验证了其实际适用性。

研究结论: FEAST成功满足了不同用户的个性化需求，展示了其在家庭餐饮辅助中的潜力。

中文摘要: 物理护理机器人有望改善全球数百万需要餐饮辅助的人的生活质量。然而，家庭餐饮辅助仍面临活动多样性（如进食、饮水、擦嘴）、情境复杂性（如社交、看电视）、食物种类和用户偏好的挑战。本文提出FEAST，一种可在野外个性化定制的灵活餐饮辅助系统。通过与两位社区研究人员合作，并基于对多样化护理对象的形成性研究，我们的系统遵循适应性、透明性和安全性三大原则。FEAST通过以下方式体现这些原则：（i）模块化硬件，支持切换辅助进食、饮水和擦嘴功能；（ii）多样化交互方式（如网页界面、头部手势和物理按钮），以适应不同功能能力和偏好；（iii）参数化行为树，可通过大型语言模型安全透明地调整。我们根据形成性研究中的个性化需求评估系统，证明FEAST提供了广泛的安全透明调整，并优于固定定制化的先进基线系统。为验证实际适用性，我们与两位护理对象（社区研究人员）进行了家庭用户研究，分别在三种场景下为他们提供三餐。我们还通过一位此前不熟悉系统的职业治疗师评估了FEAST的生态效度。在所有案例中，用户均成功个性化定制FEAST以满足其需求。网站：https://emprise.cs.cornell.edu/feast

</details>


### [180] [Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired](https://arxiv.org/abs/2506.14857)
**中文标题：面向视障人士引导的无人机感知避障研究**

*Suman Raj,Swapnil Padhi,Ruchi Bhoot,Prince Modi,Yogesh Simmhan*

主要分类: cs.RO

摘要简述: 本文提出了一种基于感知的无人机路径规划系统，用于辅助视障人士在户外城市环境中导航，结合全局规划和局部避障算法，验证了其可行性。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在利用无人机和感知技术帮助视障人士在复杂城市环境中安全导航，解决传统导航工具的局限性。

研究方法: 采用几何问题建模和多深度神经网络框架，结合全局GPS规划和局部感知避障，为无人机和视障人士提供导航支持。

研究结果: 在大学校园环境中进行的实验验证了算法在三种场景（人行道、停车区、拥挤街道）中的有效性。

研究结论: 研究表明，基于感知的无人机导航系统能够有效辅助视障人士，未来可进一步优化和扩展应用场景。

中文摘要: 无人机通过机载传感器结合机器学习和计算机视觉算法实现自主导航，已广泛应用于农业、物流和灾害管理等领域。本文探讨了无人机在辅助视障人士（VIPs）于户外城市环境中导航的应用。具体而言，我们提出了一种基于感知的路径规划系统，用于视障人士周围的局部规划，并结合基于GPS和地图的全局规划进行粗粒度路径规划。通过几何建模和多深度神经网络框架，实现了无人机和视障人士的避障功能。在大学校园环境中对无人机-人系统进行的评估验证了算法在三种场景（人行道行走、停车区附近、拥挤街道）中的可行性。

</details>


### [181] [Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation](https://arxiv.org/abs/2506.15157)
**中文标题：鲁棒即时策略：利用Student's t回归模型实现机器人操作的鲁棒上下文模仿学习**

*Hanbit Oh,Andrea M. Salcedo-Vázquez,Ixchel G. Ramirez-Alpizar,Yukiyasu Domae*

主要分类: cs.RO

摘要简述: 本文提出了一种名为RIP的鲁棒即时策略算法，利用Student's t回归模型解决LLM即时策略中的幻觉问题，显著提升了任务成功率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于LLM的即时策略在机器人模仿学习中存在幻觉问题，导致生成的轨迹偏离演示，影响可靠性。

研究方法: RIP通过生成多个候选轨迹并使用Student's t分布聚合，忽略异常值（幻觉），从而生成鲁棒的轨迹。

研究结果: 实验表明，RIP在模拟和真实环境中均显著优于现有方法，任务成功率提升至少26%，尤其在低数据场景下表现优异。

研究结论: RIP通过鲁棒性设计有效解决了LLM即时策略的幻觉问题，为机器人模仿学习提供了可靠解决方案。

中文摘要: 模仿学习（IL）旨在通过观察少量人类演示使机器人自主完成任务。近年来，一种称为上下文IL的变体利用现成的大型语言模型（LLM）作为即时策略，通过少量演示理解上下文以执行新任务，而非通过大规模演示显式更新网络模型。然而，其在机器人领域的可靠性受到幻觉问题的威胁，例如LLM即时策略偶尔会生成偏离演示的劣质轨迹。为解决这一问题，我们提出了一种名为鲁棒即时策略（RIP）的新算法，利用Student's t回归模型抵御即时策略的幻觉轨迹，从而生成可靠轨迹。具体而言，RIP从LLM生成多个候选机器人轨迹，并使用Student's t分布聚合它们，有助于忽略异常值（即幻觉），从而生成鲁棒的轨迹。我们在模拟和真实环境中的实验表明，RIP显著优于现有IL方法，任务成功率提升至少26%，尤其在低数据场景的日常任务中表现突出。视频结果详见https://sites.google.com/view/robustinstantpolicy。

</details>


### [182] [MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System](https://arxiv.org/abs/2506.15402)
**中文标题：MCOO-SLAM：一种多相机全景物体SLAM系统**

*Miaoxin Pan,Jinnan Li,Yaowen Zhang,Yi Yang,Yufeng Yue*

主要分类: cs.RO

摘要简述: MCOO-SLAM是一种多相机全景物体SLAM系统，通过利用全景相机配置和语义几何融合策略，在复杂户外场景中实现鲁棒、一致且语义丰富的地图构建。


<details>
  <summary>详细信息</summary>
研究动机: 现有物体级SLAM系统多依赖RGB-D传感器或单目视角，存在视野狭窄、遮挡敏感和深度感知有限等问题，尤其在户外或大规模环境中表现不佳。MCOO-SLAM旨在通过多相机全景配置解决这些问题，提升物体建模和数据关联的准确性。

研究方法: MCOO-SLAM整合了点特征和物体级地标，并引入语义-几何-时间融合策略以增强多视角下的物体关联。此外，设计了全景闭环模块，利用场景级描述符实现视角不变的地点识别，并将地图抽象为分层3D场景图以支持下游任务。

研究结果: 实验表明，MCOO-SLAM在真实场景中实现了高精度的定位和可扩展的物体级地图构建，对遮挡、姿态变化和环境复杂性具有更强的鲁棒性。

研究结论: MCOO-SLAM通过多相机全景配置和语义几何融合策略，显著提升了物体级SLAM在复杂环境中的性能，为高级机器人任务提供了更可靠的环境表示。

中文摘要: 物体级SLAM提供了结构化和语义丰富的环境表示，使其更具可解释性并适用于高级机器人任务。然而，现有方法多依赖RGB-D传感器或单目视角，存在视野狭窄、遮挡敏感和深度感知有限等问题，尤其在户外或大规模环境中表现不佳。这些问题通常导致系统仅能从有限视角观察物体的部分视图，从而影响物体建模和数据关联的准确性。本文提出MCOO-SLAM，一种新型多相机全景物体SLAM系统，充分利用全景相机配置在复杂户外场景中实现鲁棒、一致且语义丰富的地图构建。该方法整合了点特征和物体级地标，并引入语义-几何-时间融合策略以增强多视角下的物体关联。此外，设计了全景闭环模块，利用场景级描述符实现视角不变的地点识别，并将地图抽象为分层3D场景图以支持下游任务。实验表明，MCOO-SLAM在真实场景中实现了高精度的定位和可扩展的物体级地图构建，对遮挡、姿态变化和环境复杂性具有更强的鲁棒性。

</details>


### [183] [Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos](https://arxiv.org/abs/2506.15680)
**中文标题：基于粒子-网格神经动力学的RGB-D视频可变形物体模型学习**

*Kaifeng Zhang,Baoyu Li,Kris Hauser,Yunzhu Li*

主要分类: cs.RO

摘要简述: 本文提出了一种结合粒子与空间网格的神经动力学框架，用于从RGB-D视频中学习可变形物体的动态模型。该方法通过粒子表示物体形状，空间网格确保空间连续性，并结合高斯渲染生成3D动作视频。实验表明，该模型在稀疏视角下优于现有方法，并能泛化到未见过的物体实例。


<details>
  <summary>详细信息</summary>
研究动机: 可变形物体的动态建模因其多样的物理特性和从有限视觉信息中估计状态的困难而具有挑战性。本文旨在通过一种混合表示方法解决这些问题，实现高效且通用的动态建模。

研究方法: 提出了一种粒子-网格神经动力学框架，粒子用于表示物体形状，空间网格用于离散化3D空间以确保连续性。结合高斯渲染技术，生成3D动作视频。该方法通过稀疏视角的RGB-D视频学习物体动态。

研究结果: 实验证明，该模型能够学习多种物体（如绳索、布料、毛绒玩具和纸袋）的动态，并在稀疏视角下优于现有学习型和物理型模拟器。此外，模型还能泛化到未见过的物体实例，并支持基于模型的规划任务。

研究结论: 本文提出的粒子-网格神经动力学框架为可变形物体的动态建模提供了一种高效且通用的解决方案，尤其在稀疏视角下表现优异，为机器人-物体交互任务提供了新的可能性。

中文摘要: 由于可变形物体的物理特性多样且从有限视觉信息中估计状态困难，其动态建模具有挑战性。我们提出了一种结合物体粒子和空间网格的神经动力学框架，通过混合表示解决这些问题。粒子-网格模型捕捉全局形状和运动信息，同时预测密集粒子运动，从而能够建模不同形状和材质的物体。粒子表示物体形状，空间网格离散化3D空间以确保空间连续性并提高学习效率。结合高斯渲染技术，我们的框架实现了可变形物体的全学习型数字孪生，并生成3D动作视频。实验表明，该模型能够从机器人-物体交互的稀疏视角RGB-D记录中学习多种物体（如绳索、布料、毛绒玩具和纸袋）的动态，并在类别级别上泛化到未见过的实例。我们的方法在稀疏视角下优于现有学习型和物理型模拟器。此外，我们还展示了学习模型在基于模型规划中的实用性，支持目标驱动的物体操作任务。项目页面见https://kywind.github.io/pgnd。

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [184] [LLM Agent for Hyper-Parameter Optimization](https://arxiv.org/abs/2506.15167)
**中文标题：基于大型语言模型的超参数优化代理**

*Wanzhe Wang,Jianqiu Peng,Menghao Hu,Weihuang Zhong,Tong Zhang,Shuai Wang,Yixin Zhang,Mingjie Shao,Wanli Ni*

主要分类: cs.IT

摘要简述: 本文提出了一种基于大型语言模型（LLM）的智能代理，用于自动优化无人机通信算法中的超参数。通过迭代框架和模型上下文协议（MCP），该代理显著提升了超参数调优的自动化水平和性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前无人机通信算法中的超参数调优方法（如WS-PSO-CM算法）主要依赖启发式方法，自动化程度低且性能不佳。因此，需要一种更高效的自动化超参数优化方法。

研究方法: 研究设计了一个LLM代理，通过配置任务背景和输出格式的配置文件启动代理。代理根据提示需求迭代调用WS-PSO-CM算法进行探索，并自主终止循环返回超参数集。

研究结果: 实验结果表明，LLM代理生成的超参数在最小和速率上显著优于人工启发式和随机生成方法。

研究结论: 具备PSO知识和WS-PSO-CM算法背景的LLM代理能够高效找到高性能超参数，为超参数优化提供了新思路。

中文摘要: 超参数对通信算法的性能至关重要。然而，当前针对无人机轨迹和通信的WS-PSO-CM算法的超参数调优方法主要依赖启发式方法，自动化程度低且性能不佳。本文设计了一种基于大型语言模型（LLM）的智能代理，用于自动优化超参数，其中采用了迭代框架和模型上下文协议（MCP）。具体而言，LLM代理首先通过配置文件设定任务、背景和输出格式。随后，代理根据提示需求驱动，迭代调用WS-PSO-CM算法进行探索。最终，代理自主终止循环并返回一组超参数。实验结果表明，LLM代理生成的超参数在最小和速率上显著优于人工启发式和随机生成方法。这表明具备PSO知识和WS-PSO-CM算法背景的LLM代理在寻找高性能超参数方面具有实用价值。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [185] [An Empirical Study of Bugs in Data Visualization Libraries](https://arxiv.org/abs/2506.15084)
**中文标题：数据可视化库中错误的实证研究**

*Weiqi Lu,Yongqiang Tian,Xiaohan Zhong,Haoyang Ma,Zhenyang Xu,Shing-Chi Cheung,Chengnian Sun*

主要分类: cs.SE

摘要简述: 本文首次对数据可视化库中的错误进行了全面分析，研究了564个来自五个常用库的错误，发现错误图形计算是主要根源，并探索了视觉语言模型在检测错误图形中的可行性。


<details>
  <summary>详细信息</summary>
研究动机: 数据可视化库在数据分析和应用中至关重要，但其错误可能导致误导性图形，影响用户决策。因此，理解这些错误的特性对开发者和研究者至关重要。

研究方法: 研究收集了五个广泛使用的数据可视化库中的564个错误，系统分析了其症状和根源，并提出了一种详细的分类法。此外，探索了视觉语言模型在检测错误图形中的应用。

研究结果: 研究发现错误图形在数据可视化库中普遍存在，图形计算错误是主要原因。视觉语言模型在检测错误图形中的有效性为29%至57%，且提示信息的增加不一定提高效果。

研究结论: 研究强调了数据可视化库中错误的重要性，并提出了未来自动化测试技术的方向，同时展示了视觉语言模型在错误检测中的潜力与局限性。

中文摘要: 数据可视化（DataViz）库在数据展示、分析和应用开发中扮演关键角色，其准确性对数据转化为可视化表示至关重要。错误的可视化可能影响用户体验、扭曲信息传递，并误导用户决策。这些库中的视觉错误尤为隐蔽，因为它们可能不会导致明显的崩溃，而是通过图形误导用户对底层数据的理解。因此，深入理解数据可视化库中错误的特性对研究者与开发者检测和修复这些错误至关重要。本研究首次对数据可视化库中的错误进行了全面分析，从五个常用库中收集了564个错误，系统分析了其症状和根源，并提供了详细的分类法。我们发现错误图形在数据可视化库中普遍存在，图形计算错误是主要原因，亟需进一步开发自动化测试方法。此外，我们识别了触发此类错误的八个关键步骤和两个特定于数据可视化库的测试预言，为未来设计有效的自动化测试技术提供了启示。随着视觉语言模型（VLMs）的进步，我们还探索了这些模型在检测错误图形中的可行性。结果显示，VLMs在错误检测中的有效性为29%至57%，取决于提示内容，而增加提示信息并不一定提高效果。更多发现详见我们的论文。

</details>


### [186] [Uncovering Intention through LLM-Driven Code Snippet Description Generation](https://arxiv.org/abs/2506.15453)
**中文标题：通过LLM驱动的代码片段描述生成揭示意图**

*Yusuf Sulistyo Nugroho,Farah Danisha Salam,Brittany Reid,Raula Gaikovina Kula,Kazumasa Shimari,Kenichi Matsumoto*

主要分类: cs.SE

摘要简述: 本文研究了大型语言模型（LLM）在生成代码片段描述方面的能力，发现LLM能较好地识别和生成示例型描述，但仍有改进空间。


<details>
  <summary>详细信息</summary>
研究动机: 代码片段的文档化对开发者和用户至关重要，尤其是第三方库的使用示例和API文档。随着大型语言模型（LLM）的兴起，研究LLM在生成代码描述方面的表现成为关键目标。

研究方法: 研究使用NPM代码片段数据集（包含185,412个包和1,024,579个代码片段），从中选取400个样本进行手动分类和LLM生成描述。通过比较原始描述与LLM生成描述的相似性，评估LLM的表现。

研究结果: 手动分类显示55.5%的原始描述为示例型，LLM正确识别了79.75%的示例型描述。LLM生成描述的平均相似性得分为0.7173，表明相关性较高但仍有改进空间。

研究结论: 代码片段的文档意图可能因任务不同而异，LLM在生成描述方面表现良好，但需进一步提升以覆盖更多文档类型。

中文摘要: 代码片段的文档化对于明确开发者和用户需要关注的关键区域至关重要，例如使用示例和其他应用程序编程接口（API），这对第三方库尤为重要。随着大型语言模型（LLM）的兴起，本研究的主要目标是调查开发者常用的描述类型，并评估LLM（如Llama）在生成描述方面的表现。我们使用了NPM代码片段数据集，包含185,412个包和1,024,579个代码片段，从中选取400个样本进行分析。首先，手动分类发现55.5%的原始描述为示例型，强调了清晰文档的重要性，因为部分描述未能充分传达意图。其次，LLM正确识别了79.75%的原始描述为“示例型”，与手动分类结果一致，显示出其泛化能力。第三，与原始描述相比，LLM生成描述的平均相似性得分为0.7173，表明相关性较高但仍有改进空间。得分低于0.9的描述存在一定不相关性。结果表明，代码片段的文档意图可能因任务不同而异，包括使用说明、安装指南或库用户的学习示例。

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [187] [Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection](https://arxiv.org/abs/2506.14933)
**中文标题：先解释，后信任：基于LLM增强的图加密货币异常检测解释**

*Adriana Watson*

主要分类: cs.CE

摘要简述: 本文提出了一种基于LLM增强解释的图加密货币异常检测方法，旨在解决去中心化金融（DeFi）中日益增长的犯罪问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着去中心化金融（DeFi）的快速发展，加密货币领域的犯罪活动也日益猖獗。由于技术新颖，传统方法难以有效检测和起诉犯罪者，因此需要开发自动化工具来应对这一挑战。

研究方法: 论文提出了一种结合大型语言模型（LLM）和图结构的方法，通过LLM生成解释性内容，增强图基加密货币异常检测的可信度和可解释性。

研究结果: 该方法在加密货币异常检测中表现出色，能够有效识别可疑活动，并通过LLM生成的解释提高了检测结果的可信度。

研究结论: 通过结合LLM和图结构，该方法为加密货币领域的异常检测提供了一种高效且可解释的解决方案，有助于打击金融犯罪。

中文摘要: 近年来，去中心化金融（DeFi）社区在加密货币爱好者的推动下迅速发展，新市场的巨大潜力吸引了广泛关注。然而，加密货币的普及也带来了金融犯罪的新时代。由于技术的新颖性，抓捕和起诉犯罪者变得尤为困难。因此，有必要开发与政策相关的自动化检测工具，以应对加密货币领域日益增长的犯罪问题。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [188] [Preparing for the Intelligence Explosion](https://arxiv.org/abs/2506.14863)
**中文标题：为智能爆炸做准备**

*William MacAskill,Fin Moorhouse*

主要分类: cs.CY

摘要简述: 本文探讨了人工智能（AI）加速研究可能带来的技术爆炸，以及由此引发的重大挑战，如大规模杀伤性武器、AI独裁等。作者认为这些挑战不能完全依赖未来的AI系统解决，并提出当前应采取的措施以应对这些潜在问题。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI技术的快速发展，其可能在未来几年内推动百年技术进步，但同时也带来一系列重大挑战。这些挑战包括新型武器、AI独裁等，且难以逆转。作者旨在探讨如何提前准备以应对这些潜在问题。

研究方法: 作者通过分析AI加速研究可能带来的技术爆炸及其潜在影响，提出了一系列重大挑战（如大规模杀伤性武器、AI独裁等），并讨论了这些挑战的不可逆性。同时，作者建议当前应采取具体措施以应对这些挑战。

研究结果: 研究发现，AI技术爆炸可能带来一系列重大挑战，这些挑战无法完全依赖未来的AI系统解决。作者提出，当前应采取措施以改善未来的前景，包括确保AI系统的对齐性。

研究结论: 作者认为，为应对AI技术爆炸带来的重大挑战，当前需要提前准备，而不仅仅是确保高级AI系统的对齐性。这些挑战包括新型武器、AI独裁等，且需要人类主动应对。

中文摘要: 能够加速研究的人工智能（AI）可能在短短几年内推动一个世纪的技术进步。在此期间，新的技术或政治发展将迅速引发一系列具有深远影响且难以逆转的决策。我们称这些发展为重大挑战，包括新型大规模杀伤性武器、AI支持的独裁政权、争夺外星资源的竞赛，以及值得道德考量的数字生命，同时也包括显著提高生活质量和集体决策能力的机会。我们认为，这些挑战不能总是委托给未来的AI系统，并提出了当前可以采取的措施以改善未来的前景。因此，通用人工智能（AGI）的准备不仅仅是确保高级AI系统的对齐性：我们现在就应该为智能爆炸带来的令人困惑的一系列发展做好准备。

</details>


### [189] [Hypothesis Testing for Quantifying LLM-Human Misalignment in Multiple Choice Settings](https://arxiv.org/abs/2506.14997)
**中文标题：多项选择场景中量化大型语言模型与人类行为偏差的假设检验**

*Harbin Hong,Sebastian Caldas,Liu Leqi*

主要分类: cs.CY

摘要简述: 本文提出了一种基于假设检验的量化框架，用于评估大型语言模型（LLM）在多项选择调查中与人类行为的偏差。研究发现，某些模型在模拟特定人群（如不同种族、年龄和收入）的观点时表现不佳，引发了对LLM在社会科学研究中应用的反思。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在社会科学研究（如经济学和市场营销）中的广泛应用，评估这些模型是否能准确模拟人类行为变得至关重要。本文旨在通过假设检验，量化LLM与人类行为之间的偏差，为模型的实际应用提供科学依据。

研究方法: 本文提出了一种基于假设检验的量化框架，用于评估LLM在多项选择调查中与人类行为的偏差。通过将模型生成的答案与实际人类调查数据进行比较，确定模型是否能够有效模拟人类的观点、决策和行为。

研究结果: 研究发现，某些流行的语言模型在模拟特定人群（如不同种族、年龄和收入）的观点时表现不佳，尤其是在争议性问题上的模拟效果较差。这表明这些模型与测试人群的行为存在显著偏差。

研究结论: 本文揭示了LLM在模拟人类行为时的局限性，尤其是在复杂社会背景下的表现不佳。研究强调了在社会科学研究中谨慎使用LLM的必要性，并呼吁开发更精准的模型模拟方法。

中文摘要: 随着大型语言模型（LLM）在社会科学研究（如经济学和市场营销）中的广泛应用，评估这些模型是否能准确模拟人类行为变得至关重要。本文通过假设检验，提出了一种量化框架，用于评估LLM在多项选择调查中与人类行为的偏差。该框架能够科学地判断特定语言模型是否能有效模拟人类通过多项选择选项表达的观点、决策和行为。我们将这一框架应用于一款流行的语言模型，用于模拟公众调查中的人群观点，发现该模型在模拟特定子群体（如不同种族、年龄和收入）的观点时表现不佳，尤其是在争议性问题上。这引发了关于该语言模型与测试人群行为对齐的质疑，并凸显了在社会科学研究中超越简单模拟人类行为的新实践需求。

</details>


### [190] [Transit for All: Mapping Equitable Bike2Subway Connection using Region Representation Learning](https://arxiv.org/abs/2506.15113)
**中文标题：为所有人服务的公共交通：利用区域表示学习绘制公平的自行车与地铁连接图**

*Min Namgung,JangHyeon Lee,Fangyi Ding,Yao-Yi Chiang*

主要分类: cs.CY

摘要简述: 本文提出了一种名为Transit for All (TFA)的空间计算框架，旨在通过区域表示学习预测自行车共享需求，并结合新型加权公共交通可达性指标（wPTAL），为纽约市低收入和少数族裔社区提供更公平的公共交通连接。


<details>
  <summary>详细信息</summary>
研究动机: 在纽约市等高密度城市中，低收入和少数族裔社区的公共交通可达性较差。自行车共享系统（BSS）可以填补这一公平性缺口，但传统方法难以预测新站点（“冷启动”）的需求，且现有指标可能忽略实际自行车使用潜力。

研究方法: TFA框架包含三部分：(1) 使用区域表示学习整合多模态地理空间数据，预测冷启动站点的自行车共享需求；(2) 结合预测的自行车需求和传统指标，提出加权公共交通可达性指标（wPTAL）；(3) 基于wPTAL为新站点选址提供战略建议。

研究结果: 在纽约市的案例研究中，TFA显著减少了低收入和少数族裔社区的公共交通可达性差距。新站点的战略布局改善了这些社区的生活质量。

研究结论: TFA为城市规划者提供了实用工具，通过公平扩展自行车共享系统，提升服务不足社区的公共交通公平性和生活质量。

中文摘要: 确保公平的公共交通可达性仍然具有挑战性，尤其是在纽约市等高密度城市中，低收入和少数族裔社区的公共交通可达性通常较差。自行车共享系统（BSS）可以通过提供经济实惠的首末英里连接填补这一公平性缺口。然而，由于新规划站点（“冷启动”）的自行车共享需求不确定，以及传统可达性指标可能忽略实际自行车使用潜力，战略性扩展BSS至服务不足社区存在困难。我们提出了Transit for All (TFA)，这是一个空间计算框架，旨在通过三个组成部分指导BSS的公平扩展：(1) 利用区域表示学习整合多模态地理空间数据，预测冷启动站点的自行车共享需求；(2) 结合预测的自行车需求和传统指标，提出加权公共交通可达性指标（wPTAL）；(3) 基于潜在乘客量和公平性提升，为新站点选址提供战略建议。以纽约市为例，我们识别了低收入和少数族裔社区在历史性服务不足区域的公共交通可达性差距。结果显示，基于wPTAL指导的新站点布局显著减少了与经济及人口因素相关的公共交通可达性差异。研究表明，TFA为城市规划者提供了实用指导，以促进公平的公共交通并提升服务不足社区的生活质量。

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [191] [BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models](https://arxiv.org/abs/2506.14861)
**中文标题：BMFM-RNA：构建和评估转录组基础模型的开源框架**

*Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou*

主要分类: q-bio.GN

摘要简述: BMFM-RNA是一个开源模块化软件框架，旨在统一转录组基础模型（TFMs）的预训练和微调目标，并引入新的训练目标WCED。实验表明，基于WCED的模型性能优于现有方法，为系统化评估和优化TFM训练策略提供了可重复的基础。


<details>
  <summary>详细信息</summary>
研究动机: 当前转录组基础模型（TFMs）的实现和训练策略多样，难以评估单个设计选择的贡献或其协同效应，阻碍了领域内最佳实践的达成和研究的可重复性。BMFM-RNA旨在解决这一问题。

研究方法: 提出BMFM-RNA框架，支持多种输入表示和训练目标，包括新提出的WCED目标（通过自编码器式CLS瓶颈捕捉全局表达模式）。在CELLxGENE数据集上预训练四个模型，结合MLM、WCED和多任务学习。

研究结果: 基于WCED的模型在零样本和微调任务中表现优异，性能匹配或超越scGPT等现有方法。BMFM-RNA为系统化评估和优化TFM训练策略提供了工具。

研究结论: BMFM-RNA为转录组基础模型的开发提供了可重复、模块化的框架，支持社区探索最优训练策略，推动AI在细胞生物学中的应用。

中文摘要: 转录组基础模型（TFMs）已成为分析细胞和组织基因表达的有力工具，支持细胞类型注释、批次校正和扰动预测等关键任务。然而，不同TFMs的实现和训练策略多样性使得难以评估单个设计选择的贡献或其协同效应，阻碍了领域内最佳实践的达成和研究的可重复性。我们提出了BMFM-RNA，一个开源的模块化软件包，统一了多种TFM预训练和微调目标。利用这一能力，我们引入了一种新的训练目标——全细胞表达解码器（WCED），通过自编码器式CLS瓶颈捕捉全局表达模式。本文描述了该框架、支持的输入表示和训练目标。我们在CELLxGENE数据集上预训练了四个模型，结合掩码语言建模（MLM）、WCED和多任务学习。通过BMFM-RNA的基准测试功能，我们发现基于WCED的模型在零样本和微调任务中表现优异，性能匹配或超越scGPT等现有方法。BMFM-RNA作为biomed-multi-omics项目的一部分（https://github.com/BiomedSciAI/biomed-multi-omic），为系统化评估和社区驱动的TFM训练策略探索提供了可重复的基础，有助于开发更有效的工具，利用AI最新进展理解细胞生物学。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [192] [PFMBench: Protein Foundation Model Benchmark](https://arxiv.org/abs/2506.14796)
**中文标题：PFMBench：蛋白质基础模型基准测试**

*Zhangyang Gao,Hao Wang,Cheng Tan,Chenrui Xu,Mengdi Liu,Bozhen Hu,Linlin Chao,Xiaoming Zhang,Stan Z. Li*

主要分类: q-bio.BM

摘要简述: 本研究提出了PFMBench，一个全面的蛋白质基础模型基准测试，涵盖8个关键领域的38项任务，旨在填补当前蛋白质科学领域缺乏统一评估标准的空白。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，蛋白质基础模型的研究取得了显著进展，但缺乏一个统一的基准来公平评估和深入理解这些模型的性能。现有评估多局限于特定任务，难以全面衡量模型的泛化能力和局限性。

研究方法: 研究团队开发了PFMBench，通过17个最新蛋白质基础模型在38项任务上的数百次实验，评估模型性能，并分析任务间的相关性。

研究结果: PFMBench揭示了任务间的内在关联，识别了表现最佳的模型，并提供了一套标准化的评估流程。

研究结论: PFMBench为蛋白质基础模型的研究提供了全面的评估工具，有助于推动该领域的进一步发展。

中文摘要: 本研究探讨了蛋白质基础模型研究的现状与未来方向。尽管近期进展显著，但该领域缺乏一个全面的基准以实现公平评估和深入理解。自ESM-1B以来，涌现了许多蛋白质基础模型，各自采用独特的数据集和方法。然而，现有评估多局限于针对特定模型的有限任务，难以全面衡量模型的泛化能力和局限性。研究人员尤其难以理解任务间的关系、评估模型在各任务中的表现，以及确定开发新基础模型的标准。为此，我们提出了PFMBench，一个涵盖蛋白质科学8个关键领域38项任务的全面基准。通过对17个最新模型在38项任务上的数百次实验，PFMBench揭示了任务间的内在关联，识别了表现最佳的模型，并提供了一套标准化的评估流程。代码发布于\href{https://github.com/biomap-research/PFMBench}{\textcolor{blue}{GitHub}}。

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [193] [MODS: Multi-source Observations Conditional Diffusion Model for Meteorological State Downscaling](https://arxiv.org/abs/2506.14798)
**中文标题：MODS：多源观测条件扩散模型用于气象状态降尺度**

*Siwei Tu,Jingyi Xu,Weidong Yang,Lei Bai,Ben Fei*

主要分类: physics.ao-ph

摘要简述: 本文提出了一种多源观测条件扩散模型（MODS），用于气象状态降尺度，通过融合多源卫星和地形数据，显著提高了气象变量降尺度的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 高分辨率地表气象数据的准确获取对气象预报和模拟至关重要。现有降尺度方法主要依赖单一卫星数据，无法全面捕捉气象变量变化，因此需要利用多源数据提升降尺度效果。

研究方法: MODS是一种条件扩散模型，融合了多颗静止卫星（GridSat）、极轨卫星（AMSU-A、HIRS、MHS）和地形数据（GEBCO），并通过多源交叉注意力模块将这些条件输入的特征融合到ERA5再分析数据中。

研究结果: 实验表明，MODS在将ERA5数据降尺度至6.25公里分辨率时，生成的结果更接近真实气象状态，具有更高的保真度。

研究结论: MODS通过多源数据融合和条件扩散模型，显著提升了气象变量降尺度的准确性，为气象预报和模拟提供了更可靠的高分辨率数据。

中文摘要: 准确获取高分辨率地表气象条件对气象预报和模拟至关重要。直接应用空间插值方法从低分辨率网格场中推导特定位置的气象值，结果往往与实际条件偏差较大。现有降尺度方法主要依赖静止卫星与ERA5变量的耦合关系作为条件，但仅使用静止卫星的亮温数据无法全面捕捉ERA5图中所有气象变量的变化。为解决这一局限，我们可以利用更广泛的卫星数据，更充分地发挥其对各种气象变量的反演效果，从而在不同气象变量上生成更真实的结果。为进一步提高任意位置气象变量降尺度的准确性，我们提出了多源观测降尺度模型（MODS）。它是一种条件扩散模型，融合了多颗静止卫星GridSat、极轨卫星（AMSU-A、HIRS和MHS）以及地形数据（GEBCO）作为条件，并在ERA5再分析数据集上进行了预训练。训练过程中，通过多源交叉注意力模块将不同条件输入的潜在特征分别提取并融合到ERA5图中。通过利用再分析数据与多源大气变量之间的反演关系，MODS生成了更接近真实大气状态的结果。在采样阶段，MODS通过引入低分辨率ERA5图和站点级气象数据作为指导，增强了降尺度的一致性。实验结果表明，MODS在将ERA5图降尺度至6.25公里分辨率时，具有更高的保真度。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [194] [Scaling Intelligence: Designing Data Centers for Next-Gen Language Models](https://arxiv.org/abs/2506.15006)
**中文标题：扩展智能：为下一代语言模型设计数据中心**

*Jesmin Jahan Tithi,Hanjiang Wu,Avishaii Abuhatzera,Fabrizio Petrini*

主要分类: cs.AR

摘要简述: 本文提出了一种针对下一代语言模型的数据中心设计框架，通过联合优化计算、存储和网络架构，显著提升了大规模语言模型的性能和扩展性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（如GPT-4）参数规模的爆炸式增长（1.8万亿参数），传统数据中心架构难以满足其扩展性、效率和成本效益的需求，亟需重新设计。

研究方法: 研究提出了一种联合设计框架，探索了计算能力（FLOPS）、高带宽内存（HBM）容量与带宽、多种网络拓扑（如两层与全扁平光网络）、扩展域规模以及并行化策略。重点评估了全扁平网络架构，并分析了计算与通信重叠、硬件加速集合操作、更大扩展域和内存容量对性能的影响。

研究结果: 全扁平网络架构显著提升了节点间的高带宽、低延迟连接，优化了模型FLOPS利用率（MFU）和整体吞吐量。性能建模工具预测误差低于10%，为万亿参数模型的高效支持提供了可行方案。

研究结论: 研究为设计高效支持万亿参数模型的数据中心提供了实用路线图，降低了优化复杂度，并推动了AI能力的持续演进。

中文摘要: 大型语言模型（如拥有1.8万亿参数的GPT-4）的爆炸式增长要求对数据中心架构进行根本性重新设计，以确保扩展性、效率和成本效益。我们的工作提供了一个全面的联合设计框架，共同探索了计算能力（FLOPS）、高带宽内存（HBM）容量与带宽、多种网络拓扑（两层与全扁平光网络）、扩展域规模以及大型语言模型常用的并行化与优化策略。我们提出并评估了全扁平网络架构，该架构为所有节点提供了统一的高带宽、低延迟连接，并展示了其对性能和扩展性的变革性影响。通过详细的敏感性分析，我们量化了计算与通信重叠、硬件加速集合操作、更大扩展域和内存容量的优势。我们的研究涵盖了稀疏（专家混合）和密集（基于Transformer）的大型语言模型，揭示了系统设计选择如何影响模型FLOPS利用率（MFU = 每令牌模型FLOPS × 每秒观察令牌数 / 硬件峰值FLOPS）和整体吞吐量。为了联合设计研究，我们扩展并验证了一种性能建模工具，能够将大型语言模型的运行时预测误差控制在10%以内。我们的研究结果为设计能够高效支持万亿参数模型、降低优化复杂度并持续推动AI能力发展的AI数据中心提供了可行的见解和实用路线图。

</details>


### [195] [J3DAI: A tiny DNN-Based Edge AI Accelerator for 3D-Stacked CMOS Image Sensor](https://arxiv.org/abs/2506.15316)
**中文标题：J3DAI：一种基于微型DNN的边缘AI加速器，用于3D堆叠CMOS图像传感器**

*Benoit Tain,Raphael Millet,Romain Lemaire,Michal Szczepanski,Laurent Alacoque,Emmanuel Pluchart,Sylvain Choisnet,Rohit Prasad,Jerome Chossat,Pascal Pierunek,Pascal Vivet,Sebastien Thuries*

主要分类: cs.AR

摘要简述: 本文介绍了J3DAI，一种基于深度神经网络的微型硬件加速器，专为3层3D堆叠CMOS图像传感器设计，具备高效的边缘AI能力，支持图像分类和分割任务。


<details>
  <summary>详细信息</summary>
研究动机: 随着边缘AI的重要性日益增长，开发能够在资源受限的硬件上高效运行的低延迟、低功耗AI加速器成为关键。J3DAI旨在满足这一需求，为CMOS图像传感器提供实时AI处理能力。

研究方法: J3DAI采用基于深度神经网络的硬件加速器设计，结合Aidge软件框架，支持后训练量化以减少内存占用和计算复杂度。该方法优化了性能-功耗-面积（PPA）特性。

研究结果: 实验结果表明，J3DAI在边缘AI任务中表现出高效性和多功能性，能够处理从简单到计算密集型的任务，同时显著降低资源消耗。

研究结论: J3DAI展示了在边缘AI领域的创新潜力，未来工作将集中于进一步优化架构和探索新应用，以充分发挥其能力。

中文摘要: 本文介绍了J3DAI，一种基于深度神经网络的微型硬件加速器，专为3层3D堆叠CMOS图像传感器设计，集成了AI芯片和DNN加速器。该加速器旨在高效执行图像分类和分割等神经网络任务。本文重点介绍了J3DAI的数字系统，突出了其性能-功耗-面积（PPA）特性，并展示了其在CMOS图像传感器上的先进边缘AI能力。为支持硬件，我们使用了Aidge综合软件框架，该框架支持主机处理器和DNN加速器的编程。Aidge支持后训练量化，显著减少了内存占用和计算复杂度，这对于在资源受限的硬件（如J3DAI）上部署模型至关重要。实验结果表明，这一创新设计在边缘AI领域具有多功能性和高效性，能够处理从简单到计算密集型的任务。未来工作将集中于进一步优化架构和探索新应用，以充分发挥J3DAI的能力。随着边缘AI的重要性日益增长，像J3DAI这样的创新将在实现实时、低延迟和节能的边缘AI处理中发挥关键作用。

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [196] [Identifiability by common backdoor in summary causal graphs of time series](https://arxiv.org/abs/2506.14862)
**中文标题：时间序列摘要因果图中基于共同后门集的可识别性**

*Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier*

主要分类: math.ST

摘要简述: 本文研究了时间序列中基于共同后门集的干预可识别性问题，提出了在时间序列中是否存在共同后门集的条件，并提供了判断可识别性的算法。


<details>
  <summary>详细信息</summary>
研究动机: 研究干预的可识别性问题，旨在评估某些干预的总效应是否可以通过无干预公式表示，从而仅从观测数据中计算。在时间序列背景下，仅能获得真实因果图的抽象形式（即摘要因果图），因此需要探讨共同后门集的存在条件。

研究方法: 研究在时间序列中，考虑多干预和多效应的情况下，基于共同后门集的干预可识别性。针对时间序列是否具有时间一致性，分别建立共同后门集存在的条件，并提供复杂度有限的算法来判断可识别性。

研究结果: 确立了在时间序列中（无论是否具有时间一致性）共同后门集存在的条件，并开发了判断可识别性的算法。

研究结论: 在时间序列的摘要因果图中，共同后门集的存在为干预效应的可识别性提供了条件，且算法能够有效判断问题是否可识别。

中文摘要: 干预的可识别性问题旨在评估某些给定干预的总效应是否可以通过无干预公式表示，从而仅从观测数据中计算。本文研究了这一问题，考虑多干预和多效应的情况，在时间序列背景下，仅能获得真实因果图的摘要形式（即摘要因果图）。本研究聚焦于基于共同后门集的可识别性，并针对时间序列是否具有时间一致性，分别建立了共同后门集存在的条件。此外，还提供了复杂度有限的算法来判断问题是否可识别。

</details>
