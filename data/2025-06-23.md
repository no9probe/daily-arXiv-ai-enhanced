<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 79]
- [cs.CV](#cs.CV) [Total: 117]
- [cs.AI](#cs.AI) [Total: 41]
- [cs.ET](#cs.ET) [Total: 2]
- [stat.ML](#stat.ML) [Total: 2]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.LG](#cs.LG) [Total: 81]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cs.SY](#cs.SY) [Total: 1]
- [physics.ins-det](#physics.ins-det) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [eess.IV](#eess.IV) [Total: 20]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.SE](#cs.SE) [Total: 5]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.MM](#cs.MM) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.RO](#cs.RO) [Total: 16]
- [cs.CG](#cs.CG) [Total: 1]
- [cond-mat.quant-gas](#cond-mat.quant-gas) [Total: 1]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [stat.ME](#stat.ME) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [astro-ph.EP](#astro-ph.EP) [Total: 1]
- [cs.CY](#cs.CY) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Veracity: An Open-Source AI Fact-Checking System](https://arxiv.org/abs/2506.15794)
**中文标题：Veracity：一个开源AI事实核查系统**

*Taylor Lynn Curtis,Maximilian Puelma Touzel,William Garneau,Manon Gruaz,Mike Pinder,Li Wei Wang,Sukanya Krishna,Luda Cohen,Jean-François Godbout,Reihaneh Rabbany,Kellin Pelrine*

主要分类: cs.CL

摘要简述: 本文介绍了Veracity，一个开源AI事实核查系统，旨在通过透明和易用的方式帮助用户对抗虚假信息。系统结合大型语言模型和网络检索代理，提供多语言支持、数值评分和直观解释。


<details>
  <summary>详细信息</summary>
研究动机: 虚假信息的泛滥对社会构成严重威胁，尤其是生成式AI的兴起加剧了这一现象。本文旨在通过开源AI系统Veracity，提供透明且易用的工具，帮助用户识别和对抗虚假信息。

研究方法: Veracity结合大型语言模型（LLMs）和网络检索代理，分析用户提交的声明，并提供基于证据的真实性评估和直观解释。系统支持多语言，提供数值评分，并采用类似即时通讯应用的交互界面。

研究结果: Veracity不仅能有效检测虚假信息，还能解释其推理过程，从而提升用户的媒体素养，促进更明智的社会决策。

研究结论: Veracity作为一个开源AI事实核查系统，通过透明性和易用性，为对抗虚假信息提供了实用工具，同时有助于提升公众的媒体素养。

中文摘要: 虚假信息的泛滥对社会构成严重威胁，而生成式AI的能力进一步加剧了这一问题。本文介绍了一个开源AI系统Veracity，旨在通过透明且易用的方式帮助用户对抗虚假信息。Veracity利用大型语言模型（LLMs）与网络检索代理的协同作用，分析用户提交的声明，并提供基于证据的真实性评估及直观解释。其关键特性包括多语言支持、声明真实性的数值评分，以及受即时通讯应用启发的交互界面。本文将展示Veracity不仅能检测虚假信息，还能解释其推理过程，从而提升媒体素养，促进更明智的社会。

</details>


### [2] [Rethinking LLM Training through Information Geometry and Quantum Metrics](https://arxiv.org/abs/2506.15830)
**中文标题：通过信息几何与量子度量重新思考大型语言模型训练**

*Riccardo Di Sipio*

主要分类: cs.CL

摘要简述: 本文通过信息几何和量子度量重新思考大型语言模型（LLM）的训练，提出利用Fisher信息度量和自然梯度下降优化高维参数空间，并探讨量子类比以提升优化效率。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型的优化在高维非欧几里得参数空间中进行，传统方法难以捕捉其结构特性。信息几何和量子度量提供了一种更原则性的视角，有助于理解训练中的现象（如尖锐极小值和泛化能力）并提升优化效率。

研究方法: 研究采用信息几何框架，利用Fisher信息度量和自然梯度下降分析LLM训练的高维参数空间。此外，探讨了基于Fubini-Study度量和量子Fisher信息的量子类比，为量子增强系统中的优化提供理论支持。

研究结果: 研究揭示了信息几何在LLM训练中的重要性，能够解释尖锐极小值和泛化现象。量子类比的提出为未来量子增强系统中的高效优化提供了潜在方向。

研究结论: 信息几何和量子度量为LLM训练提供了新的理论视角，有助于优化方法的改进。量子类比的研究为未来高效优化技术开辟了可能性。

中文摘要: 大型语言模型（LLM）的优化在高维非欧几里得结构的参数空间中进行。信息几何通过Fisher信息度量将这一空间框架化，使得通过自然梯度下降实现更原则性的学习成为可能。尽管实际应用较少，这种几何视角能够解释尖锐极小值、泛化能力以及观察到的缩放规律等现象。我们认为曲率感知方法深化了对LLM训练的理解。最后，我们基于Fubini-Study度量和量子Fisher信息提出量子类比，暗示了量子增强系统中高效优化的可能性。

</details>


### [3] [MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents](https://arxiv.org/abs/2506.15841)
**中文标题：MEM1：学习协同记忆与推理以实现高效长时任务代理**

*Zijian Zhou,Ao Qu,Zhaoxuan Wu,Sunghwan Kim,Alok Prakash,Daniela Rus,Jinhua Zhao,Bryan Kian Hsiang Low,Paul Pu Liang*

主要分类: cs.CL

摘要简述: MEM1是一种通过强化学习框架实现长时任务中恒定内存使用的语言代理，通过整合记忆与推理提升效率，性能提升3.5倍且内存减少3.7倍。


<details>
  <summary>详细信息</summary>
研究动机: 现代语言代理需处理长时多轮交互，但现有系统依赖全上下文提示，导致内存无限增长、计算成本增加及推理性能下降。MEM1旨在解决这些问题。

研究方法: MEM1采用端到端强化学习框架，每轮更新紧凑的内部状态，整合记忆与新观察，并丢弃无关信息。通过组合现有数据集构建复杂任务序列以支持训练。

研究结果: 在三个领域的实验中，MEM1-7B性能提升3.5倍，内存使用减少3.7倍，且在训练范围外仍具泛化能力。

研究结论: MEM1展示了推理驱动的记忆整合作为高效长时交互代理训练方案的潜力，优化了性能与效率。

中文摘要: 现代语言代理需在长时多轮交互中检索外部信息、适应观察并回答相互依赖的查询。然而，大多数LLM系统依赖全上下文提示，无论相关性如何均附加所有历史轮次，导致内存无限增长、计算成本增加及分布外输入长度下推理性能下降。我们提出MEM1，一种端到端强化学习框架，使代理在长时多轮任务中以恒定内存运行。每轮中，MEM1更新一个紧凑的共享内部状态，共同支持记忆整合与推理。该状态将先验记忆与环境新观察整合，同时策略性丢弃无关或冗余信息。为支持更真实和组合性训练，我们提出一种简单有效且可扩展的方法，通过组合现有数据集构建任意复杂任务序列。在三个领域的实验中，包括内部检索QA、开放域网页QA及多轮网购，MEM1-7B在16目标多跳QA任务中性能提升3.5倍，内存使用减少3.7倍（相比Qwen2.5-14B-Instruct），且能泛化至训练范围外。结果表明，推理驱动的记忆整合作为训练长时交互代理的可扩展替代方案具有潜力，同时优化了效率与性能。

</details>


### [4] [Finance Language Model Evaluation (FLaME)](https://arxiv.org/abs/2506.15846)
**中文标题：金融语言模型评估（FLaME）**

*Glenn Matlin,Mika Okamoto,Huzaifa Pardawala,Yang Yang,Sudheer Chava*

主要分类: cs.CL

摘要简述: 本文介绍了首个金融语言模型评估基准FLaME，填补了现有评估方法的不足，展示了语言模型在金融NLP任务中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 由于现有评估方法存在缺陷，导致对语言模型在金融NLP任务中性能的低估，本文旨在填补这一空白，展示语言模型在金融领域的实际潜力。

研究方法: 提出了首个全面的金融语言模型评估基准FLaME，对23个基础语言模型在20项核心金融NLP任务上进行了实证研究，并开源了框架软件、数据和结果。

研究结果: 研究发现语言模型在金融NLP任务中的表现远超现有评估方法的低估，证明了其实际潜力。

研究结论: FLaME为金融语言模型评估提供了首个全面基准，揭示了语言模型在金融领域的强大能力，并开源了相关资源以促进后续研究。

中文摘要: 语言模型（LMs）在核心自然语言处理（NLP）任务中展现了强大的能力。然而，由于现有评估框架的方法论存在重大缺陷，语言模型在高度专业化且知识密集的金融任务中的有效性仍难以评估，这导致了对语言模型在常见金融NLP（FinNLP）任务中性能的低估。为了展示语言模型在这些FinNLP任务中的潜力，我们提出了首个全面的金融语言模型评估基准（FLaME）。我们是首个全面研究语言模型与‘强化推理’语言模型的研究论文，对23个基础语言模型在20项核心金融NLP任务上进行了实证研究。我们开源了框架软件以及所有数据和结果。

</details>


### [5] [Entropy-Driven Pre-Tokenization for Byte-Pair Encoding](https://arxiv.org/abs/2506.15889)
**中文标题：基于熵驱动的字节对编码预分词方法**

*Yifan Hu,Frank Liang,Dachuan Zhao,Jonathan Geuter,Varshini Reddy,Craig W. Schmidt,Chris Tanner*

主要分类: cs.CL

摘要简述: 本文提出两种基于熵的预分词策略，用于改进字节对编码（BPE）在未分词语言（如中文）中的表现。实验表明，这些方法显著提升了分词的精确率、召回率和F1分数。


<details>
  <summary>详细信息</summary>
研究动机: 字节对编码（BPE）在未分词语言（如中文）中表现不佳，因其基于频率的合并操作忽略了语言边界。本文旨在通过信息论的无监督线索改进BPE的分词效果。

研究方法: 提出两种熵驱动的预分词策略：1）利用点互信息和左右熵识别连贯字符片段；2）利用预训练GPT-2模型的预测熵检测边界不确定性。

研究结果: 在PKU数据集上的实验表明，两种方法显著提升了分词的精确率、召回率和F1分数，优于标准BPE。

研究结论: 熵驱动的预分词不仅提升了与语言学单位的对齐效果，还为低资源及多语言场景下的分词质量改进提供了新方向。

中文摘要: 字节对编码（BPE）因其简单性和在下游任务中的优异表现，已成为现代语言模型中广泛采用的子词分词方法。然而，将其应用于未分词语言（如中文）时面临显著挑战，因其基于频率的合并操作忽略了语言边界。为此，我们提出了两种基于熵的预分词策略，利用无监督信息论线索指导BPE分词。第一种方法使用点互信息和左右熵识别连贯的字符片段，而第二种方法利用预训练GPT-2模型的预测熵检测边界不确定性。我们在PKU数据集的一个子集上评估了这两种方法，结果表明其分词精确率、召回率和F1分数均显著优于标准BPE。我们的研究显示，熵驱动的预分词不仅提升了与语言学标准单位的对齐效果，还为低资源及多语言场景下的分词质量改进提供了新方向。

</details>


### [6] [Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning](https://arxiv.org/abs/2506.15894)
**中文标题：语言模型能够对扰动推理进行单次自我纠正**

*Sam Silver,Jimin Sun,Ivan Zhang,Sara Hooker,Eddie Kim*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLM）具备单次自我纠正推理错误的能力，即使未经过长链思维微调，其内在纠错能力仍强于文献中常见表现。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型在数学推理方面表现出色，但其性能仍易受问题描述和提示策略微小变化的影响。此外，推理过程中的采样错误需要通过额外生成的标记进行自我纠正。本研究旨在探索模型的内在自我纠正能力。

研究方法: 通过实验测量模型对合成扰动引入的链式思维（CoT）推理的自我纠正能力，观察模型在单次表达中的内在纠错行为。

研究结果: 研究发现，多种开放权重模型和数据集均表现出稳健的单次内在自我纠正行为，包括从隐式纠错到显式承认并修正错误。

研究结论: 大型语言模型可能具备比文献中更强大的内在自我纠正能力，这表明近期“推理”模型研究实际上放大了模型已有的特质。

中文摘要: 大型语言模型（LLM）展现了令人印象深刻的数学推理能力，但其性能仍易受问题描述和提示策略微小变化的影响。此外，推理过程容易受到采样引起的错误影响，自回归模型主要通过额外生成的标记进行自我纠正。为了更好地理解近期模型的自我纠正能力，我们通过实验测量了模型对其链式思维（CoT）推理中引入的合成扰动的自我纠正能力。我们观察到，在一系列开放权重模型和数据集中，模型表现出稳健的单次内在自我纠正行为，从隐式纠错到显式承认并修正错误。我们的研究结果表明，包括未经过长链思维微调的模型在内，LLM可能具备比文献中更强大的内在自我纠正能力。这种能力的存在表明，近期的“推理”模型研究实际上放大了模型已有的特质。

</details>


### [7] [From RAG to Agentic: Validating Islamic-Medicine Responses with LLM Agents](https://arxiv.org/abs/2506.15911)
**中文标题：从检索增强生成到代理化：利用大语言模型代理验证伊斯兰医学回答**

*Mohammad Amaan Sayeed,Mohammed Talha Alam,Raza Imam,Shahab Saquib Sohail,Amir Hussain*

主要分类: cs.CL

摘要简述: 本文提出了一种评估伊斯兰医学文本的管道Tibbe-AG，通过结合检索增强生成和自我批判过滤，验证了三种大语言模型在回答伊斯兰医学问题时的表现，结果显示检索和代理提示显著提升了准确性和文化敏感性。


<details>
  <summary>详细信息</summary>
研究动机: 伊斯兰医学文本如《医典》和《先知医学》蕴含丰富的预防护理和整体疗法知识，但在现代AI系统中未得到充分利用。现有语言模型评测过于关注事实记忆或用户偏好，缺乏对文化背景医学指导的大规模验证。

研究方法: 研究提出Tibbe-AG评估管道，将30个精选的先知医学问题与人工验证的疗法对齐，测试三种大语言模型（LLaMA-3、Mistral-7B、Qwen2-7B）在直接生成、检索增强生成和科学自我批判过滤三种配置下的表现，并通过代理法官模型评估答案质量。

研究结果: 检索增强生成将事实准确性提升13%，代理提示通过更深入的机制分析和安全考量再提升10%。结合伊斯兰经典文本、检索和自我评估，实现了可靠且文化敏感的医学问答。

研究结论: 研究表明，结合检索和自我批判过滤的大语言模型能够有效验证伊斯兰医学文本，提升回答的准确性和文化敏感性，为文化背景医学指导的AI应用提供了新思路。

中文摘要: 古老的伊斯兰医学文本如阿维森纳的《医典》和《先知医学》蕴含丰富的预防护理、营养和整体疗法知识，但对许多人而言仍难以获取，且在现代AI系统中未得到充分利用。现有语言模型评测过于关注事实记忆或用户偏好，缺乏对文化背景医学指导的大规模验证。我们提出了一种统一的评估管道Tibbe-AG，将30个精选的先知医学问题与人工验证的疗法对齐，并比较三种大语言模型（LLaMA-3、Mistral-7B、Qwen2-7B）在直接生成、检索增强生成和科学自我批判过滤三种配置下的表现。每个答案由作为代理法官的次级大语言模型评估，生成单一的3C3H质量评分。检索将事实准确性提升13%，而代理提示通过更深入的机制分析和安全考量再提升10%。我们的结果表明，结合伊斯兰经典文本、检索和自我评估，能够实现可靠且文化敏感的医学问答。

</details>


### [8] [Reranking-based Generation for Unbiased Perspective Summarization](https://arxiv.org/abs/2506.15925)
**中文标题：基于重排的生成方法用于无偏见观点摘要**

*Narutatsu Ri,Nicholas Deas,Kathleen McKeown*

主要分类: cs.CL

摘要简述: 本文探讨了如何利用基于重排的方法生成无偏见的观点摘要，并验证了语言模型指标在评估摘要质量上的优越性。


<details>
  <summary>详细信息</summary>
研究动机: 在现实场景（如政治观点摘要）中生成无偏见的摘要是大型语言模型（LLM）的重要应用，但现有评估框架依赖传统指标，且改进方法的研究尚不成熟。本文旨在填补这些空白。

研究方法: 研究通过（1）识别可靠的指标来衡量观点摘要质量，（2）探索基于LLM的方法（如重排和偏好调优）的有效性，构建了基于人工标注的测试集以验证指标可靠性。

研究结果: 实验表明，传统指标表现不佳，而基于语言模型的指标更可靠；基于重排的方法效果显著，结合合成数据和重排标签的偏好调优进一步提升了性能。

研究结论: 本文为观点摘要的可靠评估和方法开发提供了重要参考，证明了基于重排和语言模型指标的优越性。

中文摘要: 在现实场景（如政治观点摘要）中生成无偏见的摘要是大型语言模型（LLM）的重要应用。然而，现有评估框架依赖传统指标来衡量覆盖率等关键属性，但未验证其适用性，且改进方法的研究尚不成熟。本文通过（1）识别衡量观点摘要质量的可靠指标，（2）探索超越零样本推理的基于LLM的方法，填补了这些空白。具体而言，我们构建了基于人工标注的测试集以验证指标可靠性，并发现传统指标表现不如基于语言模型的指标，后者被证明是强有力的评估工具。利用这些指标，我们发现基于重排的方法效果显著，而结合合成数据和重排标签的偏好调优进一步提升了性能。本研究旨在为观点摘要的可靠评估和方法开发提供贡献。

</details>


### [9] [A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension](https://arxiv.org/abs/2506.15978)
**中文标题：越南语文本分割与多选阅读理解数据集**

*Toan Nguyen Hai,Ha Nguyen Viet,Truong Quan Xuan,Duc Do Minh*

主要分类: cs.CL

摘要简述: 本文介绍了越南语文本分割和多选阅读理解数据集VSMRC，填补了越南语NLP任务资源的空白。实验表明，多语言模型mBERT在两项任务中表现优于单语模型。


<details>
  <summary>详细信息</summary>
研究动机: 越南语作为全球第20大语言，拥有超过1.02亿母语者，但在文本分割和机器阅读理解等NLP任务上缺乏高质量资源。本文旨在填补这一空白。

研究方法: 研究团队从越南语维基百科中收集了15,942份文档用于文本分割，并生成了16,347对经过人工质量检查的合成多选问答对。数据集VSMRC通过实验验证了其可靠性。

研究结果: 实验结果显示，多语言模型mBERT在文本分割测试集上F1得分为63.15%，在MRC测试集上准确率达88.01%，表现优于单语模型。

研究结论: 研究表明，多语言模型在越南语NLP任务中表现优异，VSMRC数据集的发布为资源匮乏语言的研究提供了潜在应用价值。

中文摘要: 越南语是全球第20大语言，拥有超过1.02亿母语者，但在文本分割和机器阅读理解（MRC）等关键自然语言处理任务上缺乏高质量资源。为解决这一问题，我们提出了VSMRC数据集，即越南语文本分割与多选阅读理解数据集。该数据集来源于越南语维基百科，包含15,942份用于文本分割的文档和16,347对经过人工质量检查的合成多选问答对，确保了资源的可靠性和多样性。实验表明，多语言模型mBERT在两项任务中均优于单语模型，在MRC测试集上准确率达到88.01%，在文本分割测试集上F1得分为63.15%。分析显示，多语言模型在越南语NLP任务中表现优异，为其他资源匮乏语言的应用提供了潜在可能。VSMRC数据集已在HuggingFace平台发布。

</details>


### [10] [Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion](https://arxiv.org/abs/2506.15981)
**中文标题：双关语：基于多视图融合的鲁棒音频AI生成歌词检测**

*Markus Frohmann,Gabriel Meseguer-Brocal,Markus Schedl,Elena V. Epure*

主要分类: cs.CL

摘要简述: 本文提出了一种名为DE-detect的多模态融合方法，通过结合音频中的歌词转录和语音特征，有效检测AI生成的音乐内容，解决了现有检测器在泛化性和抗干扰性上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI音乐生成工具的快速发展，如何可靠检测AI生成内容成为行业挑战。现有基于音频或歌词的检测器存在泛化性差、易受干扰或依赖高质量歌词的问题，亟需一种更实用的解决方案。

研究方法: 提出了一种多模态、模块化的后期融合框架，通过自动转录音频中的歌词并提取相关语音特征，结合两者信息提升检测的鲁棒性和实用性。

研究结果: 实验表明，DE-detect在检测AI生成音乐方面优于现有基于歌词的方法，同时对音频干扰更具鲁棒性。

研究结论: DE-detect为实际场景中的AI生成音乐检测提供了高效且鲁棒的解决方案，弥补了现有方法的不足。

中文摘要: AI音乐生成工具的快速发展正在革新音乐行业，但也为艺术家、版权持有者和服务提供商带来了挑战，亟需可靠的AI生成内容检测方法。然而，现有的基于音频或歌词的检测器存在关键局限性：音频检测器难以泛化到新生成器且易受音频干扰；歌词检测方法依赖格式规范且准确的歌词，实际中难以获取。为克服这些局限，我们提出了一种新颖且实用的多模态模块化后期融合框架，结合自动转录的歌词和音频中与歌词相关的语音特征。通过直接从音频中提取歌词信息，我们的方法增强了鲁棒性，降低了对低级伪影的敏感性，并提升了实用性。实验表明，我们的方法DE-detect在检测AI生成音乐方面优于现有基于歌词的检测器，同时对音频干扰更具鲁棒性，为实际场景提供了高效且鲁棒的解决方案。代码已开源：https://github.com/deezer/robust-AI-lyrics-detection。

</details>


### [11] [From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation](https://arxiv.org/abs/2506.16024)
**中文标题：从通用奖励到针对性奖励：在开放式长文本生成任务中超越GPT-4**

*Zhihan Guo,Jiele Wu,Wenqian Cui,Yifei Zhang,Minda Hu,Yufei Wang,Irwin King*

主要分类: cs.CL

摘要简述: 本文提出了一种名为ProxyReward的创新强化学习框架，用于提升大语言模型在开放式长文本生成任务中的表现。通过自动生成数据集和针对性奖励信号，该方法显著优于GPT-4-Turbo，并在开源模型上实现了20%的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前关于大语言模型长文本的研究主要集中在理解长上下文，而开放式长文本生成任务（Open-LTG）的研究不足。现有方法仅使用通用评估作为奖励信号，限制了准确性。本文旨在填补这一空白。

研究方法: ProxyReward框架包括两部分：1）通过简单提示自动生成数据集，无需大量标注数据或人工干预；2）提供针对特定问题的信息全面性和准确性的奖励信号。

研究结果: 实验结果表明，ProxyReward在Open-LTG任务中显著优于GPT-4-Turbo，并在开源模型上实现了20%的性能提升，同时超越了基于LLM的评估方法。

研究结论: 本文提出的ProxyReward框架为提升大语言模型处理复杂开放式问题的能力提供了有效方法，展示了其在长文本生成任务中的潜力。

中文摘要: 当前关于大语言模型长文本的研究主要集中在理解长上下文，而开放式长文本生成任务（Open-LTG）的研究仍显不足。训练一个长文本生成模型需要高质量参考数据，但这些数据在信息性Open-LTG任务中通常不存在。然而，现有方法仅使用通用评估作为奖励信号，限制了准确性。为填补这一空白，我们提出了ProxyReward，一种基于强化学习（RL）的创新框架，包括数据集和奖励信号计算方法。首先，ProxyReward数据集通过简单提示自动生成，无需大量标注数据或人工干预。其次，ProxyReward信号针对特定问题提供了信息全面性和准确性的评估。实验结果表明，我们的方法ProxyReward甚至超越了GPT-4-Turbo，在Open-LTG任务中显著提升了开源模型20%的性能，同时超越了基于LLM的评估方法。我们的工作为提升大语言模型处理人类复杂开放式问题的能力提供了有效方法。

</details>


### [12] [EvoLM: In Search of Lost Language Model Training Dynamics](https://arxiv.org/abs/2506.16029)
**中文标题：EvoLM：探寻语言模型训练动态的失落环节**

*Zhenting Qi,Fan Nie,Alexandre Alahi,James Zou,Himabindu Lakkaraju,Yilun Du,Eric Xing,Sham Kakade,Hanlin Zhang*

主要分类: cs.CL

摘要简述: EvoLM是一个语言模型套件，用于系统分析语言模型在预训练、持续预训练、监督微调和强化学习等阶段的训练动态，揭示了过度训练、领域适应和阶段间衔接的关键问题。


<details>
  <summary>详细信息</summary>
研究动机: 现代语言模型训练分为多个阶段，但下游开发者难以评估每个阶段设计选择的影响。EvoLM旨在提供透明且系统的分析工具，帮助理解训练动态及其对模型性能的影响。

研究方法: 通过从头训练超过100个1B和4B参数的语言模型，EvoLM在不同阶段（预训练、持续预训练、监督微调和强化学习）进行严格评估，涵盖语言建模和问题解决能力，并考虑领域内外泛化。

研究结果: 研究发现：过度预训练和后训练收益递减；持续预训练对缓解领域特定遗忘至关重要；持续预训练在衔接前后训练阶段中起关键作用；监督微调和强化学习配置存在复杂权衡。

研究结论: EvoLM为语言模型训练动态提供了系统分析工具，揭示了各阶段的关键问题，并开源了所有模型、训练数据和评估流程，促进开放研究和可重复性。

中文摘要: 现代语言模型（LM）的训练被划分为多个阶段，这使得下游开发者难以评估每个阶段设计选择的影响。我们提出了EvoLM，这是一个模型套件，能够对语言模型在预训练、持续预训练、监督微调和强化学习等阶段的训练动态进行系统和透明的分析。通过从头训练超过100个1B和4B参数的模型，我们严格评估了上游（语言建模）和下游（问题解决）的推理能力，包括领域内和领域外的泛化能力。关键发现包括：过度预训练和后训练的收益递减；在领域特定持续预训练中缓解遗忘的重要性与实践；持续预训练在衔接预训练和后训练阶段中的关键作用；以及监督微调和强化学习配置中的各种复杂权衡。为了促进开放研究和可重复性，我们开源了所有预训练和后训练模型、各阶段的训练数据集，以及完整的训练和评估流程。

</details>


### [13] [Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3](https://arxiv.org/abs/2506.16037)
**中文标题：基于LLaMA 3的多跳检索增强生成框架提升文档级问答性能**

*Xinyue Huang,Ziqi Lin,Fang Sun,Wenchao Zhang,Kejian Tong,Yunbo Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种基于LLaMA 3的新型检索增强生成（RAG）框架，用于复杂问答任务，通过多跳检索和上下文融合机制提升回答的准确性和连贯性。实验证明其优于现有基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 针对复杂问答任务中多跳推理和长文档上下文理解的挑战，本文旨在开发一种更高效的检索增强生成框架，以生成更准确且上下文相关的答案。

研究方法: 基于LLaMA 3，结合稠密检索模块、上下文融合和多跳推理机制，采用联合优化策略（检索似然和生成交叉熵）提升模型鲁棒性和适应性。

研究结果: 实验结果表明，所提系统在检索增强和生成基线方法中表现最优，能够生成更精确且上下文相关的答案。

研究结论: 该框架通过多跳检索和上下文融合显著提升了复杂问答任务的性能，验证了其在生成准确且连贯答案方面的有效性。

中文摘要: 本文提出了一种新型检索增强生成（RAG）框架，专为复杂问答任务设计，解决了多跳推理和长文档上下文理解的挑战。基于LLaMA 3，该框架结合了稠密检索模块、高级上下文融合和多跳推理机制，从而生成更准确且连贯的回答。通过联合优化检索似然和生成交叉熵的策略，提升了模型的鲁棒性和适应性。实验结果表明，所提系统优于现有的检索增强和生成基线方法，证实了其在生成精确且上下文相关答案方面的有效性。

</details>


### [14] [DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling](https://arxiv.org/abs/2506.16043)
**中文标题：DynScaling：通过动态和集成采样实现高效的无验证器推理扩展**

*Fei Wang,Xingchen Wan,Ruoxi Sun,Jiefeng Chen,Sercan Ö. Arık*

主要分类: cs.CL

摘要简述: DynScaling通过动态和集成采样实现高效的无验证器推理扩展，结合并行-顺序采样策略和动态预算分配框架，显著提升大语言模型性能，无需外部验证器。


<details>
  <summary>详细信息</summary>
研究动机: 现有推理扩展方法依赖外部验证器或未针对实际计算约束优化，限制了其实际应用。DynScaling旨在解决这些问题，提升大语言模型在资源受限情况下的性能。

研究方法: DynScaling提出两种创新：1) 集成并行-顺序采样策略，通过构建合成顺序推理链统一并行和顺序采样；2) 基于多臂老虎机的动态预算分配框架，根据响应不确定性自适应分配计算资源。

研究结果: 实验表明，DynScaling在任务性能和计算成本上均优于现有无验证器推理扩展基线。

研究结论: DynScaling通过动态和集成采样策略，有效提升大语言模型性能，无需依赖外部验证器，适用于实际资源约束场景。

中文摘要: 推理扩展通过增加测试时计算量提升大语言模型（LLM）性能，但其实际应用常因依赖外部验证器或未针对实际计算约束优化而受限。我们提出DynScaling，通过两项创新解决这些问题：集成并行-顺序采样策略和基于多臂老虎机的动态预算分配框架。集成采样策略通过从初始独立的并行响应构建合成顺序推理链，统一并行和顺序采样，促进多样且连贯的推理轨迹。动态预算分配框架将计算资源分配建模为多臂老虎机问题，根据先前采样响应的不确定性自适应分配推理预算，最大化计算效率。结合这些组件，DynScaling在无需外部验证器的情况下，显著提升了LLM在实际资源约束下的性能。实验结果表明，DynScaling在任务性能和计算成本上均优于现有无验证器推理扩展基线。

</details>


### [15] [A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text](https://arxiv.org/abs/2506.16052)
**中文标题：一种结合DeBERTa与门控宽学习系统的混合架构用于英文文本中的网络欺凌检测**

*Devesh Kumar*

主要分类: cs.CL

摘要简述: 本文提出了一种结合DeBERTa和门控宽学习系统（GBLS）的混合架构，用于检测英文文本中的网络欺凌。该模型在多个基准数据集上表现优异，并提供了可解释性机制。


<details>
  <summary>详细信息</summary>
研究动机: 随着在线通信平台的普及，网络欺凌行为日益严重，影响约54.4%的青少年。现有方法在检测复杂文本（如隐含偏见和讽刺内容）时存在不足，因此需要一种更高效的检测框架。

研究方法: 提出了一种混合架构，结合了改进的DeBERTa模型（加入Squeeze-and-Excitation模块和情感分析功能）和门控宽学习系统（GBLS）分类器。该框架通过协同作用提升检测性能，并引入可解释性机制（如词级归因分析和LIME本地解释）。

研究结果: 模型在四个英文数据集上表现优异：HateXplain准确率79.3%，SOSNet准确率95.41%，Mendeley-I准确率91.37%，Mendeley-II准确率94.67%。消融实验验证了各组件的重要性，失败案例分析揭示了检测隐含偏见和讽刺内容的挑战。

研究结论: 该混合架构在检测网络欺凌方面表现出色，并通过可解释性机制提升了透明度。未来可进一步优化对复杂文本的检测能力。

中文摘要: 在线通信平台的普及为全球互联提供了前所未有的机会，同时也助长了网络欺凌等有害行为。据近期研究，约54.4%的青少年受到网络欺凌影响。本文提出了一种混合架构，结合了基于Transformer模型的上下文理解能力和宽学习系统的模式识别优势，以实现高效的网络欺凌检测。该方法将改进的DeBERTa模型（增强Squeeze-and-Excitation模块和情感分析功能）与门控宽学习系统（GBLS）分类器相结合，形成了一种协同框架，在多个基准数据集上优于现有方法。提出的ModifiedDeBERTa + GBLS模型在四个英文数据集上表现良好：HateXplain准确率79.3%，SOSNet准确率95.41%，Mendeley-I准确率91.37%，Mendeley-II准确率94.67%。除性能提升外，该框架还引入了全面的可解释性机制，包括词级归因分析、基于LIME的本地解释和置信度校准，满足了自动化内容审核中的透明度需求。消融研究证实了各架构组件的贡献，失败案例分析揭示了检测隐含偏见和讽刺内容的具体挑战，为未来网络欺凌检测系统的改进提供了宝贵见解。

</details>


### [16] [Knee-Deep in C-RASP: A Transformer Depth Hierarchy](https://arxiv.org/abs/2506.16055)
**中文标题：深入C-RASP：Transformer的深度层次结构**

*Andy Yang,Michaël Cadilhac,David Chiang*

主要分类: cs.CL

摘要简述: 本文通过理论证明和实证研究，探讨了Transformer模型深度（层数）与其表达能力的关系，证明了更深层的Transformer在特定子类中表达能力更强，并通过实验验证了理论预测。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于明确Transformer模型深度增加时其表达能力的具体提升，并通过理论证明和实验验证这一关系。

研究方法: 研究方法包括：1) 将特定子类的Transformer与编程语言C-RASP建立表达能力等价性；2) 证明更深层的C-RASP程序表达能力更强；3) 通过时序逻辑和计数算子的研究支持理论；4) 实验验证无位置编码的Transformer在序列依赖任务中的深度需求。

研究结果: 研究结果表明：1) 特定子类的Transformer与C-RASP表达能力等价且深度一致；2) 更深的C-RASP程序表达能力更强，从而更深的Transformer表达能力更强；3) 实验验证了理论预测的深度需求。

研究结论: 本文通过理论和实验证明了Transformer深度与其表达能力的正相关关系，为模型设计提供了理论依据。

中文摘要: 研究发现，层数更多的Transformer模型具有更强的表达能力，但能否从形式上明确深度增加带来的具体能力提升？我们通过理论证明和实证研究回答了这一问题。首先，我们考虑在注意力机制外使用固定精度计算的Transformer子类，证明其表达能力与编程语言C-RASP等价且深度一致。其次，我们证明更深的C-RASP程序表达能力更强，从而更深的Transformer（在上述子类中）表达能力更强。这些结果通过研究一种带计数算子的时序逻辑（先前工作已证明其与C-RASP等价）得以确立。最后，我们通过实验证明，理论预测了无位置编码的Transformer在序列依赖任务家族中长度泛化所需的深度。

</details>


### [17] [Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning](https://arxiv.org/abs/2506.16064)
**中文标题：自批判引导的好奇心精炼：通过上下文学习提升大型语言模型的诚实性和帮助性**

*Duc Hieu Ho,Chenglin Fan*

主要分类: cs.CL

摘要简述: 本文提出了一种自批判引导的好奇心精炼提示策略，通过上下文学习提升大型语言模型的诚实性和帮助性，实验表明该方法显著提高了模型输出的质量。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型在多种自然语言任务中表现出色，但其输出的一致诚实性和帮助性仍是一个未解决的挑战。本文旨在通过自批判和精炼策略提升模型的信任度。

研究方法: 提出了一种自批判引导的好奇心精炼提示策略，通过两个轻量级的上下文步骤（自批判步骤和精炼步骤）优化模型输出，无需额外训练。

研究结果: 在HONESET数据集上，使用H²框架评估（由GPT-4o作为评判标准），该方法显著减少了低质量回答，提高了高质量回答的比例，H²分数相对提升了1.4%至4.3%。

研究结论: 结构化自精炼是一种可扩展且无需训练的策略，能有效提升大型语言模型输出的可信度。

中文摘要: 大型语言模型（LLMs）在多种自然语言任务中展现出强大的能力，但其输出的一致诚实性和帮助性仍是一个未解决的挑战。为解决这一问题，本文从两个互补的方向展开研究。首先，对包括OpenAI、Meta和谷歌在内的十种广泛使用的大型语言模型进行了全面的基准评估。同时，提出了一种新颖的提示策略——自批判引导的好奇心精炼提示。该策略的核心思想是让模型能够通过自批判和精炼步骤优化其输出，而无需额外训练。实验结果表明，在HONESET数据集上使用H²框架（以GPT-4o作为诚实性和帮助性的评判标准）进行评估时，该方法在所有模型中均表现出一致的改进。与好奇心驱动提示相比，该方法减少了低质量回答的数量，增加了高质量回答的比例，H²分数相对提升了1.4%至4.3%。这些结果凸显了结构化自精炼作为一种可扩展且无需训练的策略，在提升LLMs输出可信度方面的有效性。

</details>


### [18] [Cyberbullying Detection in Hinglish Text Using MURIL and Explainable AI](https://arxiv.org/abs/2506.16066)
**中文标题：基于MURIL和可解释AI的Hinglish文本网络欺凌检测**

*Devesh Kumar*

主要分类: cs.CL

摘要简述: 本文提出了一种基于MURIL架构和可解释AI的框架，用于检测Hinglish（印地语-英语混合）文本中的网络欺凌行为。该框架在六个基准数据集上表现优于现有多语言模型，并提供了可解释性分析。


<details>
  <summary>详细信息</summary>
研究动机: 随着数字通信平台的普及，网络欺凌事件频发，而现有的检测系统主要针对单语文本，难以应对Hinglish等混合语言的挑战。因此，需要开发一种高效且可解释的检测方法。

研究方法: 采用MURIL架构处理Hinglish文本，结合选择性层冻结、分类头设计和针对混合内容的预处理技术。通过属性分析和跨语言模式识别提供可解释性。

研究结果: 在六个数据集上的实验表明，MURIL框架优于RoBERTa和IndicBERT等模型，准确率提升1.36至13.07个百分点，最高达到94.63%。

研究结论: 该框架在Hinglish网络欺凌检测中表现出色，同时揭示了语境依赖、文化理解和跨语言讽刺检测等挑战，为未来研究提供了方向。

中文摘要: 数字通信平台的发展导致全球网络欺凌事件增加，亟需自动化检测系统保护用户。Hinglish（印地语-英语混合）在数字平台上的流行对现有单语检测系统提出了挑战。本文提出了一种基于MURIL架构的框架，用于检测Hinglish文本中的网络欺凌行为。在六个基准数据集（Bohra等人、BullyExplain、BullySentemo、Kumar等人、HASOC 2021和Mendeley Indo-HateSpeech）上的评估显示，MURIL方法优于RoBERTa和IndicBERT等多语言模型，准确率提升1.36至13.07个百分点，具体表现为Bohra数据集86.97%、BullyExplain 84.62%、BullySentemo 86.03%、Kumar数据集75.41%、HASOC 2021 83.92%和Mendeley数据集94.63%。该框架通过属性分析和跨语言模式识别提供可解释性。消融研究表明，选择性层冻结、分类头设计和针对混合内容的预处理提高了检测性能，而失败分析揭示了语境依赖、文化理解和跨语言讽刺检测等挑战，为多语言网络欺凌检测的未来研究提供了方向。

</details>


### [19] [FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning](https://arxiv.org/abs/2506.16123)
**中文标题：FinCoT：基于专家金融推理的结构化思维链**

*Natapong Nitarach,Warit Sirichotedumrong,Panop Pitchayarthorn,Pittawat Taveekitworachai,Potsawee Manakul,Kunat Pipatanakul*

主要分类: cs.CL

摘要简述: 本文提出FinCoT，一种结合领域专家金融推理的结构化思维链提示方法，显著提升语言模型在金融问题上的表现，同时减少生成标记数量。


<details>
  <summary>详细信息</summary>
研究动机: 现有金融自然语言处理（FinNLP）主要关注标准或无结构思维链提示，而结构化思维链提示设计多基于非领域专家的启发式方法。本文旨在探索领域专家驱动的结构化提示对金融推理的影响。

研究方法: 研究比较了三种提示方法（标准提示、无结构思维链提示、结构化思维链提示），并提出了FinCoT，一种基于专家金融推理的结构化思维链提示方法。实验在CFA风格问题上进行，涵盖十个金融领域。

研究结果: FinCoT将性能从63.2%提升至80.5%，Qwen-2.5-7B-Instruct从69.7%提升至74.2%，同时生成标记数量减少八倍。

研究结论: 领域对齐的结构化提示不仅能提升性能和降低推理成本，还能生成更具解释性且与专家推理一致的思维链。

中文摘要: 本文提出FinCoT，一种结构化思维链（CoT）提示方法，通过结合领域专家金融推理的见解，指导大型语言模型的推理轨迹。研究发现FinNLP中存在三种主要提示风格：（1）标准提示——零样本提示；（2）无结构CoT——无明确推理结构的CoT提示；（3）结构化CoT提示——通过明确指令或示例定义推理步骤的CoT提示。此前，FinNLP主要关注标准或无结构CoT提示，而结构化CoT提示在先前研究中关注较少，且其推理结构设计多基于非领域专家的启发式方法。本研究评估了三种提示方法及FinCoT在十个金融领域的CFA风格问题上的表现。结果表明，FinCoT将性能从63.2%提升至80.5%，Qwen-2.5-7B-Instruct从69.7%提升至74.2%，同时生成标记数量减少八倍。研究显示，领域对齐的结构化提示不仅能提升性能和降低推理成本，还能生成更具解释性且与专家推理一致的思维链。

</details>


### [20] [Under the Shadow of Babel: How Language Shapes Reasoning in LLMs](https://arxiv.org/abs/2506.16151)
**中文标题：巴别塔阴影下：语言如何塑造大型语言模型的推理**

*Chenxi Wang,Yixuan Zhang,Lang Gao,Zixiang Xu,Zirui Song,Yanbo Wang,Xiuying Chen*

主要分类: cs.CL

摘要简述: 研究发现，大型语言模型（LLMs）在推理过程中会内化不同语言的结构偏好，导致语言特定的注意力模式和因果推理偏差。通过双语数据集BICAUSE验证了这一现象。


<details>
  <summary>详细信息</summary>
研究动机: 语言不仅是交流工具，还影响认知和推理方式。研究假设LLMs会内化不同语言中的逻辑结构，从而影响其推理行为。

研究方法: 使用双语数据集BICAUSE，包含中英文语义对齐的正反因果样本，分析LLMs的注意力模式和推理表现。

研究结果: 发现：（1）LLMs的注意力模式与语言类型一致，中文更关注原因和句首连接词；（2）模型内化了语言的因果词序偏好，对非典型输入表现下降；（3）成功推理时，模型表征跨语言语义对齐。

研究结论: LLMs不仅模仿语言表面形式，还内化了语言塑造的推理偏差，首次通过模型内部结构分析验证了这一认知语言学现象。

中文摘要: 语言不仅是交流工具，也是人类认知和推理的媒介。如果如语言相对论所言，语言结构塑造认知模式，那么基于人类语言训练的大型语言模型（LLMs）也可能内化不同语言中嵌入的习惯性逻辑结构。为验证这一假设，我们引入了BICAUSE，一个用于因果推理的结构化双语数据集，包含语义对齐的中英文正反因果样本。研究发现：（1）LLMs表现出与语言类型一致的注意力模式，中文更关注原因和句首连接词，而英文分布更均衡；（2）模型内化了语言特定的因果词序偏好，并常将其僵化应用于非典型输入，导致性能下降，尤其是中文；（3）当因果推理成功时，模型表征跨语言语义对齐，表明超越表面形式的共享理解。总体而言，这些结果表明，LLMs不仅模仿语言表面形式，还内化了语言塑造的推理偏差。这一基于认知语言学理论的现象首次通过模型内部结构分析得到实证验证。

</details>


### [21] [SGIC: A Self-Guided Iterative Calibration Framework for RAG](https://arxiv.org/abs/2506.16172)
**中文标题：SGIC：一种自引导迭代校准框架用于检索增强生成**

*Guanhua Chen,Yutong Yao,Lidia S. Chao,Xuebo Liu,Derek F. Wong*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SGIC的自引导迭代校准框架，通过利用不确定性评分提升大型语言模型（LLM）在多轮校准中的效能，显著提高了检索增强生成（RAG）的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前检索增强生成（RAG）的研究多关注从候选文档中检索有用信息，但忽视了大型语言模型（LLM）的校准能力。本文旨在通过提供特定提示和迭代校准，充分发挥LLM的上下文推理能力。

研究方法: SGIC框架利用不确定性评分评估文档与查询的相关性及LLM响应的置信度，并通过迭代重新评分结合历史响应优化校准。此外，提出了一种构建自校准训练集的新方法，以优化LLM利用不确定性评分的能力。

研究结果: 实验表明，SGIC框架在闭源和开源LLM上均显著提升了性能，特别是在多轮校准中表现优异。

研究结论: SGIC框架通过自引导迭代校准有效提升了LLM的校准能力和响应准确性，为RAG领域提供了新的优化方向。

中文摘要: 近期检索增强生成（RAG）的研究集中在从候选文档中检索有用信息，但许多方法忽视了大型语言模型（LLM）的校准能力，这种能力依赖于其强大的上下文推理能力。本文表明，为LLM提供特定提示可显著提升其校准效能，尤其是在多轮校准中。我们提出了一种新的SGIC：自引导迭代校准框架，该框架利用不确定性评分作为工具。首先，框架计算不确定性评分以确定每篇文档与查询的相关性及LLM生成响应的置信度；随后，通过迭代重新评分并结合历史响应优化校准。此外，我们提出了一种构建迭代自校准训练集的新方法，以优化LLM利用不确定性评分捕捉关键信息并提升响应准确性的能力。实验证明，该框架在闭源和开源LLM上均显著提升了性能。

</details>


### [22] [JETHICS: Japanese Ethics Understanding Evaluation Dataset](https://arxiv.org/abs/2506.16187)
**中文标题：JETHICS：日本伦理理解评估数据集**

*Masashi Takeshita,Rafal Rzepka*

主要分类: cs.CL

摘要简述: 本文提出了JETHICS数据集，用于评估AI模型对日本伦理的理解能力。数据集包含78K个样本，基于现有英文ETHICS数据集的构建方法，涵盖四类伦理理论和常识道德。实验显示，当前大型语言模型（如GPT-4o）表现仍有较大提升空间。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI模型在伦理理解方面的表现尚不理想，尤其是针对日本伦理的评估工具缺乏。本文旨在填补这一空白，提供一个专门用于评估日本伦理理解的标准化数据集。

研究方法: JETHICS数据集基于英文ETHICS数据集的构建方法，包含78K个样本，分为四类伦理理论和一类常识道德。通过实验评估了非专有大型语言模型和GPT-4o的表现。

研究结果: 实验结果表明，即使是表现最好的GPT-4o，平均得分仅为0.7左右，而表现最佳的日本大型语言模型得分约为0.5，显示出当前模型在伦理理解方面仍有较大改进空间。

研究结论: JETHICS数据集为评估AI模型的日本伦理理解能力提供了有效工具，实验揭示了当前模型的局限性，强调了进一步优化的必要性。

中文摘要: 本文提出了JETHICS，一个用于评估AI模型伦理理解能力的日本数据集。JETHICS包含78K个样本，其构建方法基于现有的英文ETHICS数据集。数据集涵盖四类基于伦理和政治哲学的规范理论，以及一类代表常识道德的样本。我们对非专有大型语言模型（LLMs）和GPT-4o进行了评估实验，结果显示，即使是GPT-4o的平均得分也仅为0.7左右，而表现最佳的日本大型语言模型得分约为0.5，表明当前大型语言模型在伦理理解方面仍有较大改进空间。

</details>


### [23] [Web(er) of Hate: A Survey on How Hate Speech Is Typed](https://arxiv.org/abs/2506.16190)
**中文标题：仇恨之网：仇恨言论分类方法调查**

*Luna Wang,Andrew Caines,Alice Hutchings*

主要分类: cs.CL

摘要简述: 本文批判性分析了仇恨言论数据集构建中的方法论选择，强调透明性和方法严谨性，呼吁研究者反思自身价值判断。


<details>
  <summary>详细信息</summary>
研究动机: 仇恨言论数据集的构建涉及复杂的决策，但现有研究缺乏对这些方法论选择的系统性反思。本文旨在填补这一空白，探讨数据集构建中的常见实践及其对可靠性的影响。

研究方法: 通过分析多样化的仇恨言论数据集，结合马克斯·韦伯的“理想类型”概念，提出一种反思性方法，强调研究者在数据集构建中的价值判断。

研究结果: 研究发现，数据集构建中存在共同的模式和实践，但这些选择往往未得到充分反思，影响了数据集的可靠性和透明度。

研究结论: 本文呼吁研究者在构建仇恨言论数据集时采用反思性方法，明确自身的价值判断，以提升透明性和方法严谨性。

中文摘要: 仇恨言论数据集的构建涉及复杂的决策，需要平衡多种优先事项。本文批判性地分析了多种数据集中的方法论选择，揭示了常见主题和实践及其对数据集可靠性的影响。借鉴马克斯·韦伯的“理想类型”概念，我们主张在数据集构建中采用反思性方法，敦促研究者承认自身的价值判断，以促进透明性和方法严谨性。

</details>


### [24] [Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports](https://arxiv.org/abs/2506.16247)
**中文标题：临床放射学报告抽象摘要模型的比较分析**

*Anindita Bhattacharya,Tohida Rehman,Debarshi Kumar Sanyal,Samiran Chattopadhyay*

主要分类: cs.CL

摘要简述: 本研究比较了多种先进的抽象摘要模型在生成放射学报告中的关键诊断结论（印象部分）时的表现，使用了多种评估指标，为医疗领域提供自动化摘要解决方案的参考。


<details>
  <summary>详细信息</summary>
研究动机: 放射学报告的发现部分通常冗长详细，而印象部分则更为简洁并包含关键诊断结论。研究旨在探索如何利用先进的抽象摘要模型从发现部分生成简洁的印象部分，以满足医疗专业人士对自动化摘要的需求。

研究方法: 研究使用了公开的MIMIC-CXR数据集，并对多种预训练和开源大型语言模型进行了比较分析，包括T5-base、BART-base、PEGASUS-x-base、ChatGPT-4、LLaMA-3-8B以及自定义的Pointer Generator Network（带覆盖机制）。评估采用了多种指标，如ROUGE-1、ROUGE-2、ROUGE-L、METEOR和BERTScore。

研究结果: 研究分析了各模型在生成医学文本摘要时的表现，揭示了它们的优势和局限性。不同模型在不同评估指标下的表现各异，为医疗领域的自动化摘要提供了实用参考。

研究结论: 本研究为医疗专业人士提供了关于自动化摘要解决方案的实用信息，帮助他们在放射学报告处理中选择合适的模型。同时，研究结果也为未来改进摘要模型提供了方向。

中文摘要: 放射学报告的发现部分通常详细冗长，而印象部分则相对简洁并包含关键诊断结论。本研究探索了利用先进的抽象摘要模型从发现部分生成简洁印象的方法。研究使用了公开的MIMIC-CXR数据集，并对多种预训练和开源大型语言模型进行了比较分析，包括T5-base、BART-base、PEGASUS-x-base、ChatGPT-4、LLaMA-3-8B以及自定义的Pointer Generator Network（带覆盖机制）。为确保全面评估，采用了多种指标，如ROUGE-1、ROUGE-2、ROUGE-L、METEOR和BERTScore。通过分析这些模型的表现，本研究揭示了它们在医学文本摘要中的优势和局限性。研究结果为医疗专业人士在医疗领域选择自动化摘要解决方案提供了有益信息。

</details>


### [25] [End-to-End Speech Translation for Low-Resource Languages Using Weakly Labeled Data](https://arxiv.org/abs/2506.16251)
**中文标题：利用弱标注数据为低资源语言构建端到端语音翻译系统**

*Aishwarya Pothula,Bhavana Akkiraju,Srihari Bandarupalli,Charan D,Santosh Kesiraju,Anil Kumar Vuppala*

主要分类: cs.CL

摘要简述: 本文探讨了利用弱标注数据为低资源语言构建端到端语音翻译系统的可行性，并通过实验验证了其性能与大规模多模态基线模型相当。


<details>
  <summary>详细信息</summary>
研究动机: 低资源语言的高质量标注数据稀缺，限制了端到端语音翻译系统的发展。本文旨在验证弱标注数据是否可用于构建此类系统。

研究方法: 通过双语文本挖掘技术，利用先进句子编码器从多语言Shrutilipi语料库中构建了Shrutilipi-anuvaad数据集，包含多种语言对的语音翻译数据，并研究了不同质量和数量的弱标注数据对模型性能的影响。

研究结果: 实验结果表明，使用弱标注数据构建的语音翻译系统性能与SONAR和SeamlessM4T等大规模多模态基线模型相当。

研究结论: 弱标注数据可用于构建低资源语言的端到端语音翻译系统，为数据稀缺问题提供了可行的解决方案。

中文摘要: 高质量标注数据的稀缺性对开发有效的端到端语音到文本翻译（ST）系统构成了重大挑战，尤其是对于低资源语言。本文探讨了利用弱标注数据为低资源语言对构建ST模型的假设。我们借助先进的句子编码器进行双语文本挖掘，构建了语音到文本翻译数据集。通过挖掘多语言Shrutilipi语料库，我们构建了Shrutilipi-anuvaad数据集，包含孟加拉语-印地语、马拉雅拉姆语-印地语、奥里亚语-印地语和泰卢固语-印地语的ST数据。我们创建了多个版本的不同质量和数量的训练数据，以研究弱标注数据的质量与数量对ST模型性能的影响。结果表明，使用弱标注数据构建的ST系统性能可与SONAR和SeamlessM4T等大规模多模态多语言基线模型相媲美。

</details>


### [26] [Advancing Automated Speaking Assessment Leveraging Multifaceted Relevance and Grammar Information](https://arxiv.org/abs/2506.16285)
**中文标题：利用多面相关性和语法信息推进自动化口语评估**

*Hao-Chien Lu,Jhen-Ke Lin,Hong-Yun Lin,Chung-Chun Wang,Berlin Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种改进的自动化口语评估系统，通过整合多方面的内容相关性和细粒度语法错误分析，显著提升了评估性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前自动化口语评估系统在多方面评估中未能充分利用内容相关性，且语法分析较为肤浅。本文旨在解决这些问题，提升评估的全面性和准确性。

研究方法: 1. 引入多面相关性模块，整合问题、图像内容、范例和口语回答；2. 使用高级语法纠错技术和详细标注提取细粒度语法错误特征。

研究结果: 实验表明，所提方法显著改善了内容相关性、语言使用和整体口语评估性能。

研究结论: 通过更丰富和细致的特征集，本文方法为全面的口语评估提供了有效解决方案。

中文摘要: 当前用于多面评估的自动化口语评估（ASA）系统往往未能充分利用内容相关性，忽视了图像或范例提示，并采用缺乏详细错误类型的肤浅语法分析。本文通过引入两项新颖的改进来构建混合评分模型，以弥补这些不足。首先，多面相关性模块整合了问题、相关图像内容、范例和第二语言学习者的口语回答，以全面评估内容相关性。其次，使用高级语法纠错（GEC）和详细标注提取细粒度语法错误特征，以识别特定错误类别。实验和消融研究表明，这些组件显著提升了内容相关性、语言使用和整体ASA性能的评估，突出了使用更丰富、更细致特征集对全面口语评估的益处。

</details>


### [27] [PL-Guard: Benchmarking Language Model Safety for Polish](https://arxiv.org/abs/2506.16322)
**中文标题：PL-Guard：波兰语语言模型安全基准测试**

*Aleksandra Krasnodębska,Karolina Seweryn,Szymon Łukasik,Wojciech Kusa*

主要分类: cs.CL

摘要简述: 本文介绍了PL-Guard，一个针对波兰语的语言模型安全基准数据集，并通过对抗性样本测试了不同模型的鲁棒性。结果显示，基于HerBERT的分类器在对抗条件下表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 当前大多数语言模型的安全评估和审核工具偏向英语等高资源语言，而全球多数语言未得到充分研究。本文旨在填补波兰语在语言模型安全领域的空白。

研究方法: 研究团队手动标注了一个波兰语安全分类基准数据集，并生成对抗性样本以测试模型鲁棒性。实验评估了三种模型：Llama-Guard-3-8B、基于HerBERT的分类器（波兰语BERT变体）和PLLuM（波兰语适配的Llama-8B模型），并比较了它们的性能。

研究结果: 实验结果表明，基于HerBERT的分类器在整体性能上表现最优，尤其是在对抗性条件下。

研究结论: 本研究为波兰语语言模型安全提供了基准数据集和评估方法，证明了基于HerBERT的分类器在对抗条件下的优越性。

中文摘要: 尽管在确保大型语言模型（LLM）安全性方面做出了越来越多的努力，但大多数现有的安全评估和审核工具仍严重偏向英语和其他高资源语言，导致全球大多数语言未得到充分研究。为填补这一空白，我们引入了一个手动标注的波兰语语言模型安全分类基准数据集，并创建了旨在挑战模型鲁棒性的对抗性扰动样本。我们进行了一系列实验，评估了不同规模和架构的基于LLM和分类器的模型。具体而言，我们微调了三种模型：Llama-Guard-3-8B、基于HerBERT的分类器（波兰语BERT变体）和PLLuM（波兰语适配的Llama-8B模型）。我们使用不同组合的标注数据训练这些模型，并评估其性能，与公开可用的防护模型进行比较。结果表明，基于HerBERT的分类器在整体性能上表现最佳，尤其是在对抗性条件下。

</details>


### [28] [Generalizability of Media Frames: Corpus creation and analysis across countries](https://arxiv.org/abs/2506.16337)
**中文标题：媒体框架的通用性：跨国家的语料库构建与分析**

*Agnese Daffara,Sourabh Dattawad,Sebastian Padó,Tanise Ceron*

主要分类: cs.CL

摘要简述: 研究探讨了媒体框架（MFC）在跨文化语境中的适用性，通过巴西葡萄牙语新闻数据集FrameNews-PT验证其通用性，发现MFC框架基本适用但需微调。


<details>
  <summary>详细信息</summary>
研究动机: 媒体框架（MFC）主要用于美国新闻议题，但其在其他文化背景中的适用性尚不明确。研究旨在验证MFC框架在巴西新闻议题中的通用性。

研究方法: 引入巴西葡萄牙语新闻数据集FrameNews-PT，基于MFC框架进行多轮标注，并评估微调模型和零样本模型在跨域数据上的表现。

研究结果: MFC的15个框架基本适用，但需对指南进行小幅修订；部分框架使用较少，新议题常依赖通用框架。

研究结论: 跨文化框架应用需谨慎考虑，MFC框架虽具通用性，但需根据具体文化背景调整。

中文摘要: 框架捕捉了辩论中强调的议题方面，有助于理解政治语言如何传达不同观点并最终影响公众意见。媒体框架语料库（MFC）是最常用的框架，包含类别和详细的操作指南，但其主要关注美国新闻议题，对其他文化背景的适用性尚不明确。为此，我们引入FrameNews-PT，一个涵盖巴西葡萄牙语政治和经济新闻的数据集，并在MFC框架下进行标注。通过多轮标注，评估MFC框架在巴西议题中的通用性，并比较微调模型和零样本模型在跨域数据上的表现。结果显示，MFC的15个框架基本适用，但需对指南进行小幅修订；部分框架使用较少，新议题常依赖通用框架。结论表明，跨文化框架应用需谨慎考虑。

</details>


### [29] [Analyzing the Influence of Knowledge Graph Information on Relation Extraction](https://arxiv.org/abs/2506.16343)
**中文标题：分析知识图谱信息对关系抽取的影响**

*Cedric Möller,Ricardo Usbeck*

主要分类: cs.CL

摘要简述: 研究探讨了知识图谱信息对关系抽取模型性能的影响，实验表明结合知识图谱能显著提升性能，尤其在训练样本不平衡时效果更明显。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于验证知识图谱中实体位置信息对关系抽取任务的重要性，尤其是在训练样本不平衡的情况下。

研究方法: 方法包括在多数据集上实验，结合传统关系抽取方法与图感知的Neural Bellman-Ford网络，评估知识图谱特征的贡献。

研究结果: 结果表明，整合知识图谱信息显著提升了关系抽取性能，尤其在训练样本不平衡时效果更佳。

研究结论: 结论是知识图谱信息对关系抽取任务具有重要价值，尤其在数据不平衡和零样本场景下表现突出。

中文摘要: 我们研究了知识图谱信息对关系抽取模型性能的影响。假设知识图谱中实体的位置信息对关系抽取任务具有重要价值。我们在多个数据集上进行了实验，这些数据集在关系数量、训练样本和底层知识图谱方面各不相同。结果表明，整合知识图谱信息显著提升了性能，尤其是在处理关系训练样本不平衡时。我们通过将传统关系抽取方法与图感知的Neural Bellman-Ford网络结合，评估了知识图谱特征的贡献。这些特征在监督学习和零样本场景下均表现出稳定的性能提升。

</details>


### [30] [DISCIE -- Discriminative Closed Information Extraction](https://arxiv.org/abs/2506.16348)
**中文标题：DISCIE——判别式封闭信息抽取**

*Cedric Möller,Ricardo Usbeck*

主要分类: cs.CL

摘要简述: 本文提出了一种新的封闭信息抽取方法DISCIE，通过结合类型和实体特定信息，显著提升了关系抽取的准确性，尤其在长尾关系和大规模数据场景下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的端到端生成模型在大规模封闭信息抽取任务中表现不佳，尤其是在处理数百万实体和数百种关系时。因此，需要一种更高效且准确的方法来改进这一任务。

研究方法: DISCIE采用判别式方法，结合类型和实体特定信息，优化关系抽取。通过利用较小模型和类型信息，实现了与大型生成模型相当或更优的性能。

研究结果: 实验表明，DISCIE在长尾关系和大规模封闭信息抽取任务中优于现有生成模型，同时保持了较高的效率。

研究结论: DISCIE为信息抽取提供了一种更准确和高效的解决方案，尤其适用于大规模和复杂关系场景。

中文摘要: 本文介绍了一种新的封闭信息抽取方法。该方法采用判别式方法，结合类型和实体特定信息，显著提升了关系抽取的准确性，尤其对长尾关系效果显著。与现有端到端生成模型相比，该方法在大规模封闭信息抽取任务中表现更优，尤其是在处理数百万实体和数百种关系时。此外，通过利用较小模型和类型信息，其性能可媲美或超越大型生成模型。这一进展为更准确和高效的信息抽取技术提供了可能。

</details>


### [31] [Can structural correspondences ground real world representational content in Large Language Models?](https://arxiv.org/abs/2506.16370)
**中文标题：结构对应关系能否为大型语言模型中的现实世界表征内容提供基础？**

*Iwan Williams*

主要分类: cs.CL

摘要简述: 本文探讨大型语言模型（如GPT-4）是否能通过结构对应关系表征现实世界内容，并指出仅存在结构对应不足以支持表征，需其在任务中发挥适当作用。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于质疑大型语言模型（LLMs）是否能够表征现实世界内容，尤其是当它们的输入、输出和训练数据仅基于文本时。作者希望通过结构对应关系理论探讨这一问题。

研究方法: 作者采用结构对应关系理论，分析LLMs与世界实体之间的结构对应是否足以支持表征，并探讨这些对应关系在任务中的实际作用。

研究结果: 研究发现，仅存在结构对应关系不足以支持LLMs表征现实世界内容，但若这些关系在任务中发挥适当作用，则可能实现表征。

研究结论: 结论指出，LLMs需克服文本局限，使结构对应关系在任务中发挥关键作用，才能真正表征现实世界内容。

中文摘要: 大型语言模型（如GPT-4）能对广泛提示生成引人注目的回答，但其表征能力尚不明确。许多LLMs与语言外现实无直接接触：其输入、输出和训练数据仅为文本，引发问题：（1）LLMs能否表征任何内容？（2）若能，表征什么？本文基于结构对应关系理论探讨回答这些问题所需条件，并初步调查相关证据。作者认为，仅LLMs与世界实体间的结构对应不足以支持表征，但若这些对应关系在任务中发挥适当作用（即解释任务成功的原因），则可能支持现实世界内容的表征。这需克服一项挑战：LLMs的文本局限性似乎阻碍其参与适当任务。

</details>


### [32] [InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems](https://arxiv.org/abs/2506.16381)
**中文标题：InstructTTSEval：评测文本到语音系统中复杂自然语言指令的遵循能力**

*Kexin Huang,Qian Tu,Liwei Fan,Chenchen Yang,Dong Zhang,Shimin Li,Zhaoye Fei,Qinyuan Cheng,Xipeng Qiu*

主要分类: cs.CL

摘要简述: 本文介绍了InstructTTSEval，一个用于评估文本到语音（TTS）系统在复杂自然语言指令下表现的新基准。通过三个任务和自动评估方法，揭示了当前指令驱动TTS系统的不足，并推动其进一步发展。


<details>
  <summary>详细信息</summary>
研究动机: 现代语音合成中，副语言信息（如音色、情感和韵律）对传达语义之外的细微差别至关重要。传统TTS系统依赖固定标签或语音提示控制这些特征，灵活性受限。尽管已有TTS系统支持通过文本描述定制合成，但其处理复杂指令的能力尚未充分研究，且缺乏高质量基准和自动评估指标。

研究方法: 作者提出InstructTTSEval基准，包含三个任务：声学参数指定、描述性风格指令和角色扮演，涵盖英语和汉语各1k测试案例（共6k），并配参考音频。利用Gemini作为自动评估工具，衡量TTS系统的指令执行能力。

研究结果: 对现有指令驱动TTS系统的评估显示，其在复杂指令下的表现仍有显著改进空间。

研究结论: InstructTTSEval为指令驱动TTS系统的评估和优化提供了重要工具，有望推动更强大、灵活和准确的TTS技术的发展。

中文摘要: 在现代语音合成中，副语言信息（如说话者的音色、情感状态和动态韵律）在传达语义之外的细微差别方面起着关键作用。传统的文本到语音（TTS）系统依赖固定风格标签或插入语音提示来控制这些线索，严重限制了灵活性。近期尝试通过自然语言指令调节副语言特征，显著提升了指令驱动TTS模型的泛化能力。尽管许多TTS系统已支持通过文本描述进行定制合成，但其实际解释和执行复杂指令的能力仍未被充分探索。此外，专门为基于指令的TTS设计的高质量基准和自动评估指标仍然匮乏，阻碍了对这些模型的准确评估和迭代优化。为解决这些问题，我们提出了InstructTTSEval，一个用于衡量复杂自然语言风格控制能力的基准。我们引入了三个任务：声学参数指定、描述性风格指令和角色扮演，包括英语和汉语子集，每个子集包含1k测试案例（共6k）并配有参考音频。我们利用Gemini作为自动评估工具，评估其指令遵循能力。对现有指令驱动TTS系统的评估表明，其表现仍有显著改进空间。我们期望InstructTTSEval能推动更强大、灵活和准确的指令驱动TTS技术的发展。

</details>


### [33] [Large Language Models in Argument Mining: A Survey](https://arxiv.org/abs/2506.16383)
**中文标题：大语言模型在论点挖掘中的研究综述**

*Hao Li,Viktor Schlegel,Yizheng Sun,Riza Batista-Navarro,Goran Nenadic*

主要分类: cs.CL

摘要简述: 本文综述了大语言模型（LLMs）在论点挖掘（AM）领域的最新进展，涵盖理论基础、数据集、任务分类及LLM技术应用，并探讨了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 论点挖掘是自然语言处理的重要子领域，而大语言模型的兴起为其带来了革命性变革。本文旨在系统梳理LLM在AM中的应用，为研究者提供全面参考。

研究方法: 通过系统综述，整合了AM的基础理论、标注框架和数据集，并提出了AM子任务的分类法，重点分析了LLM技术（如提示学习、链式推理和检索增强）的应用。

研究结果: 总结了LLM在AM中的最新技术架构与方法，评估了现有实践，并指出了长文本推理、可解释性和标注瓶颈等关键挑战。

研究结论: 本文展望了LLM在计算论证领域的未来趋势，提出了前瞻性研究议程，为快速发展的AM领域提供战略指导。

中文摘要: 论点挖掘（AM）是自然语言处理（NLP）的关键子领域，专注于从文本中提取论证结构。大语言模型（LLMs）的出现深刻改变了AM，实现了高级的上下文学习、基于提示的生成和强大的跨领域适应性。本综述系统梳理了LLM驱动的AM最新进展，简要回顾了基础理论和标注框架，并精心整理了数据集目录。主要贡献是提出了AM子任务的全面分类法，阐明了当代LLM技术（如提示学习、链式推理和检索增强）如何重构其执行方式。此外，详细介绍了当前的LLM架构与方法，批判性评估了评估实践，并指出了长文本推理、可解释性和标注瓶颈等关键挑战。最后，强调了新兴趋势，并提出了基于LLM的计算论证的前瞻性研究议程，旨在为这一快速发展的领域提供战略指导。

</details>


### [34] [HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection](https://arxiv.org/abs/2506.16388)
**中文标题：HausaNLP在SemEval-2025任务11中的表现：推进豪萨语文本情感检测**

*Sani Abdullahi Sani,Salim Abubakar,Falalu Ibrahim Lawan,Abdulhamid Abubakar,Maryam Bala*

主要分类: cs.CL

摘要简述: 本文介绍了在SemEval-2025任务11中，针对低资源非洲语言豪萨语的多标签情感检测方法。通过微调基于非洲语言预训练的AfriBERTa模型，成功分类六种情感，验证准确率达74.00%。


<details>
  <summary>详细信息</summary>
研究动机: 豪萨语作为一种低资源非洲语言，其情感检测研究较少。本文旨在探索基于Transformer的模型在低资源语言情感检测中的有效性。

研究方法: 使用AfriBERTa模型进行微调，结合数据预处理、分词和Hugging Face Trainer API，对豪萨语文本进行六种情感分类。

研究结果: 模型验证准确率为74.00%，F1分数为73.50%，表明Transformer模型在低资源语言情感检测中表现良好。

研究结论: 研究表明，基于Transformer的模型适用于低资源语言的情感检测任务，为类似语言的研究提供了参考。

中文摘要: 本文介绍了我们在SemEval Track A中针对豪萨语（一种低资源非洲语言）的多标签情感检测方法。我们微调了基于非洲语言预训练的Transformer模型AfriBERTa，用于将豪萨语文本分类为六种情感：愤怒、厌恶、恐惧、快乐、悲伤和惊讶。方法包括数据预处理、分词以及使用Hugging Face Trainer API进行模型微调。系统验证准确率达到74.00%，F1分数为73.50%，证明了基于Transformer的模型在低资源语言情感检测中的有效性。

</details>


### [35] [RiOT: Efficient Prompt Refinement with Residual Optimization Tree](https://arxiv.org/abs/2506.16389)
**中文标题：RiOT：基于残差优化树的高效提示优化**

*Chenyi Zhou,Zhengyan Shi,Yuan Yao,Lei Liang,Huajun Chen,Qiang Zhang*

主要分类: cs.CL

摘要简述: 本文提出了一种名为RiOT的新型自动提示优化框架，通过残差优化树迭代优化提示，生成多样化候选并选择最佳提示，有效解决了现有方法缺乏多样性和语义漂移的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有自动提示优化方法存在多样性不足和语义漂移问题，限制了探索创新方向并可能降低其他任务性能。本文旨在解决这些问题。

研究方法: RiOT框架通过文本梯度迭代优化提示，生成多个语义多样候选，利用困惑度选择最佳提示，并结合文本残差连接避免语义漂移。树结构管理优化过程，确保可扩展性和灵活性。

研究结果: 在五个基准测试（常识、数学、逻辑、时间和语义推理）中，RiOT表现优于现有提示优化方法和人工提示。

研究结论: RiOT通过残差优化树和文本梯度迭代优化提示，显著提升了提示优化的多样性和性能，同时避免了语义漂移。

中文摘要: 近年来，大语言模型（LLM）的进步展现了其在多种任务中的潜力，但其性能仍高度依赖于有效提示的设计。现有的自动提示优化方法面临两大挑战：缺乏多样性，限制了有价值创新方向的探索；以及语义漂移，即针对某一任务的优化可能降低其他任务的性能。为解决这些问题，我们提出了残差优化树（RiOT），一种新型自动提示优化框架。RiOT通过文本梯度迭代优化提示，每一步生成多个语义多样的候选，并利用困惑度选择最佳提示。此外，RiOT引入文本残差连接，通过选择性保留优化迭代中的有益内容来缓解语义漂移。树结构高效管理优化过程，确保可扩展性和灵活性。在涵盖常识、数学、逻辑、时间和语义推理的五个基准测试中，RiOT表现优于现有提示优化方法和人工提示。

</details>


### [36] [From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling](https://arxiv.org/abs/2506.16393)
**中文标题：从LLM标注到LLM协调器：协同小型模型进行数据标注**

*Yao Lu,Zhaiyuan Ji,Jiawei Du,Yu Shanqing,Qi Xuan,Tianyi Zhou*

主要分类: cs.CL

摘要简述: 本文提出了一种多模型协作标注的新范式AutoAnnotator，通过结合大型语言模型（LLMs）和小型语言模型（SLMs）的优势，解决了大规模标注成本高和细粒度语义理解场景下标注准确率低的问题。实验表明，该方法显著降低了成本并提高了标注准确率。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于大型语言模型（LLMs）的标注方法存在两大瓶颈：一是大规模标注时调用商业API成本高昂；二是在细粒度语义理解任务（如情感分类、毒性分类）中，LLMs的标注准确率甚至低于专用小型语言模型（SLMs）。为了解决这些问题，本文提出了一种多模型协作标注的新范式。

研究方法: AutoAnnotator框架分为两层：上层元控制器层利用LLMs的生成和推理能力选择SLMs进行标注，自动生成标注代码并验证困难样本；下层任务专家层由多个SLMs通过多模型投票完成标注。此外，通过持续学习策略，利用元控制器层二次审查的困难样本作为强化学习集，分阶段微调SLMs以提升其泛化能力。

研究结果: 实验表明，AutoAnnotator在零样本、单样本、思维链（CoT）和多数投票设置中均优于现有开源/API LLMs。与直接使用GPT-3.5-turbo标注相比，AutoAnnotator降低了74.15%的成本，同时准确率提高了6.21%。

研究结论: AutoAnnotator通过多模型协作标注，显著降低了标注成本并提高了准确率，为大规模数据标注提供了一种高效且经济的解决方案。

中文摘要: 尽管基于大型语言模型（LLMs）的标注范式近年来取得了重大突破，但其实际部署仍存在两大核心瓶颈：首先，大规模标注中调用商业API的成本非常高昂；其次，在需要细粒度语义理解的场景（如情感分类和毒性分类）中，LLMs的标注准确率甚至低于该领域专用的小型语言模型（SLMs）。为解决这些问题，我们提出了一种多模型协作标注的新范式，并基于此设计了一个全自动标注框架AutoAnnotator。具体而言，AutoAnnotator由两层组成：上层元控制器层利用LLMs的生成和推理能力选择SLMs进行标注，自动生成标注代码并验证困难样本；下层任务专家层由多个SLMs通过多模型投票完成标注。此外，我们利用元控制器层二次审查的困难样本作为强化学习集，通过持续学习策略分阶段微调SLMs，从而提升SLMs的泛化能力。大量实验表明，AutoAnnotator在零样本、单样本、思维链（CoT）和多数投票设置中均优于现有开源/API LLMs。值得注意的是，与直接使用GPT-3.5-turbo标注相比，AutoAnnotator降低了74.15%的标注成本，同时准确率提高了6.21%。项目页面：https://github.com/Zhaiyuan-Ji/AutoAnnotator。

</details>


### [37] [OJBench: A Competition Level Code Benchmark For Large Language Models](https://arxiv.org/abs/2506.16395)
**中文标题：OJBench：面向大型语言模型的竞赛级代码基准**

*Zhexu Wang,Yiping Liu,Yejie Wang,Wenyang He,Bofei Gao,Muxi Diao,Yanxu Chen,Kelin Fu,Flood Sung,Zhilin Yang,Tianyu Liu,Weiran Xu*

主要分类: cs.CL

摘要简述: OJBench是一个专为评估大型语言模型在竞赛级代码推理能力而设计的新基准，包含232道NOI和ICPC编程竞赛题目，测试结果显示即使是顶尖推理模型也面临挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有代码基准无法全面评估大型语言模型在竞赛级代码推理能力上的表现，因此需要一种更具挑战性的基准来填补这一空白。

研究方法: 研究团队开发了OJBench，包含232道来自NOI和ICPC的编程竞赛题目，并对37种模型（包括闭源和开源、推理导向和非推理导向模型）进行了全面评估。

研究结果: 评估结果表明，即使是o4-mini和Gemini-2.5-pro-exp等顶尖推理导向模型，在面对高难度竞赛级问题时也表现不佳。

研究结论: OJBench揭示了大型语言模型在竞赛级代码推理任务中面临的重大挑战，为未来研究提供了重要参考。

中文摘要: 近年来，大型语言模型（LLMs）在数学和代码推理能力上取得了显著进展。然而，现有代码基准在全面评估这些能力，尤其是竞赛级能力方面存在不足。为填补这一空白，我们提出了OJBench，这是一种新颖且具有挑战性的基准，旨在评估LLMs的竞赛级代码推理能力。OJBench包含232道来自NOI和ICPC的编程竞赛题目，为模型的推理能力提供了更严格的测试。我们对37种模型（包括闭源和开源、推理导向和非推理导向模型）使用OJBench进行了全面评估。结果显示，即使是o4-mini和Gemini-2.5-pro-exp等顶尖推理导向模型，在面对高难度竞赛级问题时也表现不佳。这凸显了模型在竞赛级代码推理任务中面临的重大挑战。

</details>


### [38] [NepaliGPT: A Generative Language Model for the Nepali Language](https://arxiv.org/abs/2506.16399)
**中文标题：NepaliGPT：一种针对尼泊尔语的生成式语言模型**

*Shushanta Pudasaini,Aman Shakya,Siddhartha Shrestha,Sahil Bhatta,Sunil Thapa,Sushmita Palikhe*

主要分类: cs.CL

摘要简述: 本文提出了首个针对尼泊尔语的生成式大语言模型NepaliGPT，填补了尼泊尔语NLP领域的研究空白，并引入了Devanagari语料库和首个尼泊尔语基准数据集。


<details>
  <summary>详细信息</summary>
研究动机: 由于缺乏针对尼泊尔语的生成式语言模型，导致包括微调在内的下游任务无法开展。本文旨在填补这一研究空白。

研究方法: 研究收集了多来源的尼泊尔语语料库（Devanagari Corpus），并构建了包含4,296个问答对的基准数据集，开发了生成式大语言模型NepaliGPT。

研究结果: NepaliGPT在文本生成中表现优异：困惑度为26.32245，ROUGE-1得分为0.2604，因果一致性为85.41%，因果连贯性为81.25%。

研究结论: NepaliGPT是首个针对尼泊尔语的生成式大语言模型，为尼泊尔语NLP研究提供了重要工具和基准数据。

中文摘要: 随着ChatGPT的发布，大语言模型（LLMs）近年来广受欢迎，数千种变体相继问世。然而，尼泊尔语尚未有生成式语言模型，导致包括微调在内的下游任务无法开展。为填补尼泊尔语NLP领域的研究空白，本研究提出了NepaliGPT，一种专为尼泊尔语设计的生成式大语言模型。研究引入了从多来源收集的尼泊尔语高级语料库（Devanagari Corpus），并构建了首个包含4,296个尼泊尔语问答对的NepaliGPT基准数据集。所提出的NepaliGPT在文本生成中表现如下：困惑度为26.32245，ROUGE-1得分为0.2604，因果连贯性为81.25%，因果一致性为85.41%。

</details>


### [39] [When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework](https://arxiv.org/abs/2506.16411)
**中文标题：何时分而治之适用于长上下文LLM？一种噪声分解框架**

*Zhen Xu,Shang Zhu,Jue Wang,Junlin Wang,Ben Athiwaratkun,Chi Wang,James Zou,Ce Zhang*

主要分类: cs.CL

摘要简述: 本文提出了一种理论框架，将长上下文任务中的失败模式分为三类：跨块依赖（任务噪声）、随上下文增长的混淆（模型噪声）和不完美的部分结果整合（聚合噪声）。通过实验验证了多代理分块处理的有效性，并解释了为何在某些情况下，分块处理的较弱模型能超越单次处理的高级模型。


<details>
  <summary>详细信息</summary>
研究动机: 研究如何有效应用大型语言模型（LLM）处理长文本，分析长上下文任务中的失败模式，并提出分块处理的理论框架。

研究方法: 提出一个理论框架，将长上下文任务的失败模式分为三类噪声，并通过实验验证多代理分块处理的有效性。

研究结果: 实验证实了理论分析的准确性，并展示了分块处理在检索、问答和摘要等任务中的优势。

研究结论: 通过理论框架和实验验证，本文为长上下文处理提供了分块和聚合策略的指导，展示了分块处理在特定条件下的优越性。

中文摘要: 我们研究了将大型语言模型（LLM）应用于长文本的挑战。提出了一个理论框架，将长上下文任务的失败模式分为三类：跨块依赖（任务噪声）、随上下文增长的混淆（模型噪声）以及部分结果的不完美整合（聚合噪声）。基于此，我们分析了多代理分块处理（即将长序列分为小块并聚合处理结果）的有效性。在检索、问答和摘要等任务上的实验验证了理论分析，并揭示了多代理分块处理的适用条件。通过探索模型噪声随输入长度超线性增长的现象，我们还解释了为何对于大规模输入，配置分块处理的较弱模型能超越单次处理的高级模型（如GPT4o）。总体而言，我们提出了一个理论理解框架，并展示了通过精心设计的分块和聚合策略处理长上下文的直接路径。

</details>


### [40] [REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing](https://arxiv.org/abs/2506.16444)
**中文标题：REIS：一种基于存储内处理的高性能高能效检索系统**

*Kangqi Chen,Andreas Kosmas Kakolyris,Rakesh Nadig,Manos Frouzakis,Nika Mansouri Ghiasi,Yu Liang,Haiyu Mao,Jisung Park,Mohammad Sadrosadati,Onur Mutlu*

主要分类: cs.CL

摘要简述: REIS是一种高性能、高能效的检索系统，通过存储内处理技术优化检索增强生成（RAG）中的检索阶段，显著提升性能和能效。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）的知识受限于训练数据，检索增强生成（RAG）通过外部知识库补充其静态知识。然而，RAG的检索阶段成为推理流程的瓶颈，传统方法存在数据移动开销大、硬件修改复杂等问题。

研究方法: REIS提出三种机制：1）数据库布局优化，将嵌入向量与文档关联；2）存储内处理（ISP）定制的数据分布技术和轻量级闪存转换层；3）利用存储系统现有计算资源的ANNS引擎。

研究结果: 与服务器级系统相比，REIS平均提升检索性能13倍，能效55倍。

研究结论: REIS通过存储内处理技术有效解决了RAG检索阶段的瓶颈问题，显著提升了性能和能效，为实际应用提供了高效解决方案。

中文摘要: 大型语言模型（LLMs）面临一个固有挑战：其知识受限于训练数据。为解决这一问题，检索增强生成（RAG）通过外部知识库补充LLMs的静态知识。RAG包含三个阶段：索引、检索和生成。其中，检索阶段成为推理流程的主要瓶颈。在此阶段，用户查询被映射为嵌入向量，近似最近邻搜索（ANNS）算法在数据库中搜索相似向量以识别相关内容。由于数据库规模庞大，ANNS在主机与存储系统之间产生大量数据移动开销。为缓解这一问题，现有研究提出存储内处理（ISP）技术，通过在存储内部执行计算加速ANNS。然而，现有基于ISP的ANNS方案存在以下问题：（i）算法未针对ISP系统优化；（ii）未加速ANNS选择的数据检索操作；（iii）需大幅修改硬件，限制性能并阻碍采用。我们提出REIS，首个专为RAG设计的ISP系统，通过三种关键机制解决上述问题。首先，REIS采用一种数据库布局，将嵌入向量与其关联文档链接，实现高效检索。其次，通过引入ISP定制的数据分布技术和轻量级闪存转换层，实现高效ANNS。第三，REIS利用存储系统现有计算资源的ANNS引擎。与服务器级系统相比，REIS平均提升检索性能13倍，能效55倍。

</details>


### [41] [StoryWriter: A Multi-Agent Framework for Long Story Generation](https://arxiv.org/abs/2506.16445)
**中文标题：StoryWriter：一种用于生成长篇故事的多代理框架**

*Haotian Xia,Hao Peng,Yunjia Qi,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

主要分类: cs.CL

摘要简述: 论文提出StoryWriter，一个多代理框架，用于生成长篇故事，通过三个模块（大纲代理、规划代理和写作代理）解决长篇生成中的连贯性和叙事复杂性，显著优于基线模型，并生成了高质量长故事数据集。


<details>
  <summary>详细信息</summary>
研究动机: 现有大型语言模型在生成长篇故事时面临两大挑战：话语连贯性（情节一致性和逻辑性）和叙事复杂性（交织且引人入胜的叙事）。StoryWriter旨在解决这些问题。

研究方法: StoryWriter包含三个模块：1) 大纲代理生成基于事件的提纲；2) 规划代理细化事件并规划章节；3) 写作代理动态压缩历史并生成新情节。模型通过监督微调训练。

研究结果: StoryWriter在故事质量和长度上显著优于基线模型，生成了约6000篇高质量长故事（平均8000字），并训练出StoryWriter_GLM等高性能模型。

研究结论: StoryWriter通过多代理框架有效解决了长篇故事生成的连贯性和复杂性挑战，生成了高质量数据集，并展示了先进的生成性能。

中文摘要: 长篇故事生成对现有大型语言模型（LLMs）仍具挑战性，主要由于两大因素：1) 话语连贯性，要求长篇生成中的情节一致性、逻辑连贯性和完整性；2) 叙事复杂性，要求交织且引人入胜的叙事。为解决这些问题，我们提出StoryWriter，一个多代理故事生成框架，包含三个主要模块：1) 大纲代理，生成基于事件的提纲，包含丰富的情节、角色和事件关系；2) 规划代理，进一步细化事件并规划每章节应写的事件，以保持故事的连贯性和吸引力；3) 写作代理，动态压缩故事历史并根据当前事件生成新情节，确保生成故事的连贯性。我们进行了人工和自动化评估，StoryWriter在故事质量和长度上均显著优于现有基线模型。此外，我们使用StoryWriter生成了一个包含约6000篇高质量长故事的数据集，平均长度为8000字。我们通过监督微调在LongStory上训练了Llama3.1-8B和GLM4-9B模型，开发了StoryWriter_GLM和StoryWriter_GLM，展示了在长篇故事生成中的先进性能。

</details>


### [42] [Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection](https://arxiv.org/abs/2506.16476)
**中文标题：面向隐含仇恨言论检测的通用有害言论数据集泛化性研究**

*Saad Almohaimeed,Saleh Almohaimeed,Damla Turgut,Ladislau Bölöni*

主要分类: cs.CL

摘要简述: 本文提出一种方法，通过利用现有有害言论数据集检测隐含仇恨言论，并提升其泛化能力。实验结果显示，该方法显著提高了隐含仇恨检测的F1分数。


<details>
  <summary>详细信息</summary>
研究动机: 隐含仇恨言论已成为社交媒体平台的重要挑战，而现有研究多集中于一般有害言论。由于隐含仇恨言论的隐蔽性和复杂性，现有数据集可能存在误标或未被识别的问题，亟需一种泛化性强的检测方法。

研究方法: 方法包括三个关键步骤：1) 识别有影响力的样本；2) 重新标注；3) 使用Llama-3 70B和GPT-4o进行数据增强。

研究结果: 实验结果表明，该方法显著提升了隐含仇恨言论的检测效果，F1分数比基线提高了12.9分。

研究结论: 本文提出的方法能够有效检测隐含仇恨言论，并增强其在不同数据集上的泛化能力，为社交媒体平台提供了实用的解决方案。

中文摘要: 隐含仇恨言论近年来成为社交媒体平台面临的重要挑战。尽管传统研究多集中于一般有害言论，但检测隐蔽和微妙形式的仇恨言论的需求日益迫切。基于词典分析，我们假设隐含仇恨言论已存在于公开的有害言论数据集中，但可能未被标注者明确识别或标记。此外，由于任务的复杂性，众包数据集容易因标注者的主观解释而产生误标。本文提出一种方法，通过利用现有有害言论数据集来检测隐含仇恨言论并提升其泛化性。我们的方法包括三个关键组成部分：有影响力样本识别、重新标注以及使用Llama-3 70B和GPT-4o进行数据增强。实验结果表明，该方法在提升隐含仇恨检测方面效果显著，F1分数比基线提高了12.9分。

</details>


### [43] [Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples](https://arxiv.org/abs/2506.16502)
**中文标题：RELIC：通过少量示例增强低资源印度语言奖励模型的泛化能力**

*Soumya Suvra Ghosal,Vaibhav Singh,Akash Ghosh,Soumyabrata Pal,Subhadip Baidya,Sriparna Saha,Dinesh Manocha*

主要分类: cs.CL

摘要简述: 本文提出RELIC框架，通过上下文学习提升低资源印度语言奖励模型的泛化能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前多语言奖励模型主要依赖高资源语言数据，导致低资源印度语言的奖励信号不可靠，而收集大规模高质量偏好数据成本过高。

研究方法: RELIC框架通过训练检索器，从高资源语言中选择最能区分偏好与非偏好响应的上下文示例，用于低资源语言的奖励建模。

研究结果: 实验表明，RELIC在三种偏好数据集上显著提升低资源印度语言的奖励模型准确率，例如在Bodo语言中分别比零样本提示和现有方法提升12.81%和10.13%。

研究结论: RELIC为低资源语言的奖励建模提供了一种高效且经济的方法，显著提升了模型性能。

中文摘要: 奖励模型对于将大型语言模型（LLM）与人类偏好对齐至关重要。然而，大多数开源多语言奖励模型主要基于高资源语言的偏好数据集训练，导致低资源印度语言的奖励信号不可靠。为这些语言收集大规模高质量偏好数据成本极高，使得基于偏好的训练方法不切实际。为解决这一问题，我们提出RELIC，一种针对低资源印度语言奖励建模的新型上下文学习框架。RELIC训练一个检索器，通过成对排序目标从辅助高资源语言中选择最能区分偏好与非偏好响应的上下文示例。在PKU-SafeRLHF、WebGPT和HH-RLHF三种偏好数据集上的广泛实验表明，RELIC显著提升了低资源印度语言的奖励模型准确率，始终优于现有示例选择方法。例如，在Bodo（一种低资源印度语言）上使用LLaMA-3.2-3B奖励模型时，RELIC的准确率分别比零样本提示和最先进的示例选择方法提高了12.81%和10.13%。

</details>


### [44] [Automatic Speech Recognition Biases in Newcastle English: an Error Analysis](https://arxiv.org/abs/2506.16558)
**中文标题：纽卡斯尔英语中自动语音识别的偏见：错误分析**

*Dana Serditova,Kevin Tang,Jochen Steffens*

主要分类: cs.CL

摘要简述: 研究探讨了自动语音识别（ASR）系统在处理纽卡斯尔英语这一地区方言时的偏见问题，发现其错误与方言特征直接相关，并呼吁增加训练数据的方言多样性。


<details>
  <summary>详细信息</summary>
研究动机: 自动语音识别系统因偏向主流语言变体而对地区方言表现不佳，此前研究多关注种族、年龄和性别偏见，而地区偏见研究较少。本研究旨在填补这一空白，分析ASR在纽卡斯尔英语中的表现。

研究方法: 研究分为两阶段：首先对子样本进行手动错误分析，识别导致ASR误识别的关键语音、词汇和形态句法错误；其次通过案例研究，系统分析ASR对地区代词“yous”和“wor”的识别情况。

研究结果: 结果显示，ASR错误与地区方言特征直接相关，社会因素对误识别的影响较小。

研究结论: 研究主张在ASR训练数据中增加方言多样性，并强调社会语言学分析在诊断和解决地区偏见中的价值。

中文摘要: 自动语音识别（ASR）系统因偏向主流语言变体而难以处理地区方言。尽管此前研究已发现ASR在种族、年龄和性别上的偏见，但地区偏见研究较少。本研究探讨了ASR在纽卡斯尔英语中的表现，纽卡斯尔英语是一种对ASR具有挑战性的地区方言。研究采用两阶段分析：首先对子样本进行手动错误分析，识别导致ASR误识别的关键语音、词汇和形态句法错误；其次通过案例研究，系统分析ASR对地区代词“yous”和“wor”的识别情况。结果显示，ASR错误与地区方言特征直接相关，而社会因素对误识别的影响较小。我们主张在ASR训练数据中增加方言多样性，并强调社会语言学分析在诊断和解决地区偏见中的价值。

</details>


### [45] [Weight Factorization and Centralization for Continual Learning in Speech Recognition](https://arxiv.org/abs/2506.16574)
**中文标题：语音识别中持续学习的权重分解与中心化方法**

*Enes Yavuz Ugan,Ngoc-Quan Pham,Alexander Waibel*

主要分类: cs.CL

摘要简述: 本文提出一种基于权重分解与中心化的持续学习方法，通过两阶段（分解与中心化）有效防止灾难性遗忘，适用于多语言语音识别任务。


<details>
  <summary>详细信息</summary>
研究动机: 现代语音识别模型需持续吸收新数据而无需重新训练，但在无原始数据、无排练的多语言环境下，易发生灾难性遗忘。受人类大脑通过醒睡循环学习与巩固知识的启发，本文旨在解决这一问题。

研究方法: 提出两阶段方法：1) 分解阶段学习新知识；2) 中心化阶段通过低秩适配器合并知识，防止灾难性遗忘。实验基于多语言代码切换数据集。

研究结果: 实验表明，中心化阶段能有效积累知识并防止灾难性遗忘，尤其在多语言任务中表现显著。

研究结论: 该方法通过分解与中心化两阶段设计，成功解决了持续学习中的灾难性遗忘问题，适用于语音识别领域。

中文摘要: 现代基于神经网络的语音识别模型需要持续吸收新数据而无需重新训练整个系统，尤其是在使用基础模型的下游应用中，无法访问原始训练数据。在无排练、多语言且语言无关的条件下持续训练模型，容易导致灾难性遗忘，即使对权重的微小干扰也可能严重损害模型质量。受人类大脑通过醒睡循环学习和巩固知识的启发，我们提出一种持续学习方法，包含两个阶段：分解和中心化，分别用于学习和合并知识。在多个代码切换数据集上的实验表明，中心化阶段通过积累分散的低秩适配器中的知识，能有效防止灾难性遗忘。

</details>


### [46] [Streaming Non-Autoregressive Model for Accent Conversion and Pronunciation Improvement](https://arxiv.org/abs/2506.16580)
**中文标题：流式非自回归模型用于口音转换与发音改进**

*Tuan-Nam Nguyen,Ngoc-Quan Pham,Seymanur Akti,Alexander Waibel*

主要分类: cs.CL

摘要简述: 本文提出首个流式口音转换模型，能够实时将非母语语音转换为母语口音，同时保留说话者身份和韵律，并改善发音。该模型通过改进的Emformer编码器和优化的推理机制实现流式处理，并整合TTS模型生成理想训练数据，性能媲美顶级模型且延迟稳定。


<details>
  <summary>详细信息</summary>
研究动机: 现有口音转换模型多为非流式处理，无法满足实时需求。本文旨在开发首个流式口音转换模型，提升非母语语音的发音质量，同时保留说话者特征和韵律。

研究方法: 改进现有口音转换架构，采用Emformer编码器和优化推理机制实现流式处理；整合TTS模型生成理想训练数据以提升效率。

研究结果: 流式口音转换模型性能媲美顶级非流式模型，同时保持稳定的低延迟，成为首个支持流式处理的口音转换系统。

研究结论: 本文提出的流式口音转换模型在实时性和性能上均表现优异，为口音转换技术的实际应用提供了新方向。

中文摘要: 我们提出了首个流式口音转换（AC）模型，能够将非母语语音转换为母语口音，同时保留说话者身份、韵律并改善发音。通过改进现有AC架构，采用Emformer编码器和优化的推理机制，实现了流式处理。此外，我们整合了母语文本转语音（TTS）模型，生成理想的训练数据以提升效率。该流式AC模型性能媲美顶级AC模型，且延迟稳定，成为首个支持流式处理的口音转换系统。

</details>


### [47] [Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework](https://arxiv.org/abs/2506.16584)
**中文标题：测量大语言模型中的（足够）世界模型：一种方差分解框架**

*Nadav Kunievsky,James A. Evans*

主要分类: cs.CL

摘要简述: 本文提出了一种评估大语言模型（LLMs）是否具备稳健世界模型的框架，通过分解模型响应变异性来量化其语义基础。结果显示，更大模型在用户意图变化上的响应更稳定，但其优势并非在所有领域都显著。


<details>
  <summary>详细信息</summary>
研究动机: 评估大语言模型是否具备结构化世界模型（支持泛化而非仅表面模式）对其可靠性至关重要，尤其是在高风险应用中。现有方法多基于准确性，缺乏对模型内部语义理解的直接评估。

研究方法: 提出一种新评估框架，将模型响应变异性分解为三部分：用户意图、用户表达方式和模型不稳定性。稳健的世界模型应主要因用户意图变化而非表达方式或模型不稳定而产生响应差异。

研究结果: 更大模型在用户意图变化上的响应变异性占比更高，表明其世界模型更稳健。然而，这种优势并非在所有领域都显著，且改进幅度有限。

研究结论: 需超越基于准确性的基准，采用更直接的语义诊断方法评估模型内部世界模型的结构和稳定性。

中文摘要: 理解大语言模型（LLMs）是否具备世界模型——一种支持超越表面模式泛化的结构化世界理解——对评估其可靠性至关重要，尤其是在高风险应用中。我们提出了一种正式框架，用于评估LLM是否表现出足够稳健的世界模型，定义为在语义等效提示下产生一致输出，同时区分表达不同意图的提示。我们引入了一种新的评估方法，将模型响应变异性分解为三个部分：用户意图、用户表达方式和模型不稳定性。具备强世界模型的LLM应将其响应变异性主要归因于基础意图的变化，而非表达方式的表面变化。这种方法使我们能够量化模型行为的语义基础程度，而非由模型不稳定性或替代措辞驱动。我们应用此框架评估了多个领域的LLM。结果显示，更大模型将更多输出变异性归因于用户意图变化，表明其世界模型更稳健。然而，这种改进并不均匀：更大模型并非在所有领域都优于较小模型，其稳健性优势通常有限。这些发现强调了超越基于准确性的基准，转向更直接评估模型内部世界理解结构和稳定性的语义诊断的重要性。

</details>


### [48] [A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications](https://arxiv.org/abs/2506.16594)
**中文标题：生物医学研究中合成数据生成的范围综述与应用**

*Hanshu Rao,Weisi Liu,Haohan Wang,I-Chan Huang,Zhe He,Xiaolei Huang*

主要分类: cs.CL

摘要简述: 本文综述了2020至2025年间59项关于生物医学合成数据生成的研究，分析了其临床应用、方法及评估，并指出了当前局限与挑战。


<details>
  <summary>详细信息</summary>
研究动机: 生物医学领域面临数据稀缺、隐私问题和数据质量挑战，合成数据生成成为解决方案。本文旨在系统梳理合成数据在生物医学中的应用趋势、方法及评估。

研究方法: 遵循PRISMA-ScR指南，从PubMed、ACM、Web of Science和Google Scholar收集59项研究，分析合成数据的模态、生成方法及评估方式。

研究结果: 研究发现，合成数据以非结构化文本（78.0%）、表格数据（13.6%）和多模态数据（8.4%）为主；生成方法包括提示（72.9%）、微调（22.0%）和专用模型（5.1%）；评估方式为内在指标（27.1%）、人工评估（55.9%）和基于LLM的评估（13.6%）。

研究结论: 合成数据在生物医学领域潜力巨大，但面临跨临床领域适应性、资源与模型可及性及评估标准化等挑战。

中文摘要: 合成数据生成通过缓解生物医学领域的数据稀缺、隐私问题和数据质量挑战，得益于大语言模型（LLMs）的快速发展。本范围综述遵循PRISMA-ScR指南，综合了2020年至2025年间从PubMed、ACM、Web of Science和Google Scholar收集的59项研究。综述系统分析了合成数据生成在生物医学研究与应用中的趋势，重点关注临床应用、方法及评估。分析发现，数据模态包括非结构化文本（78.0%）、表格数据（13.6%）和多模态数据（8.4%）；生成方法包括提示（72.9%）、微调（22.0%）和专用模型（5.1%）；评估方式为内在指标（27.1%）、人工评估（55.9%）和基于LLM的评估（13.6%）。分析还指出了当前健康专业人员利用合成数据生成在生物医学领域的局限性，并强调了跨临床领域适应性、资源与模型可及性及评估标准化等挑战。

</details>


### [49] [Modeling Public Perceptions of Science in Media](https://arxiv.org/abs/2506.16622)
**中文标题：建模公众对科学在媒体中的感知**

*Jiaxin Pei,Dustin Wright,Isabelle Augenstin,David Jurgens*

主要分类: cs.CL

摘要简述: 本文提出了一种计算框架，用于建模公众对科学新闻的感知，并通过大规模数据集和NLP模型预测公众反应。研究发现，科学新闻的消费频率是感知的主要驱动因素，而感知分数与公众参与度直接相关。


<details>
  <summary>详细信息</summary>
研究动机: 科学传播需要有效预测公众对科学信息的感知和互动方式，但现有方法难以应对信息爆炸的挑战。本文旨在通过建模公众感知，为科学传播提供新工具和洞察。

研究方法: 研究开发了一个计算框架，从12个维度（如新闻价值、重要性、意外性）建模公众感知。通过2,101名参与者对10,489条科学新闻的标注，构建了大规模数据集，并训练NLP模型预测感知分数。

研究结果: 研究发现，科学新闻的消费频率是感知的主要驱动因素，而人口统计因素影响较小。通过Reddit自然实验证实，感知分数高的帖子获得更多评论和点赞，且结果在不同科学领域和表述方式中一致。

研究结论: 研究强调了感知建模在科学传播中的重要性，为预测公众兴趣和参与提供了新途径。

中文摘要: 有效引导公众参与科学对于建立对科学界的信任和理解至关重要。然而，随着信息量的不断增长，科学传播者难以预测受众对科学新闻的感知和互动方式。本文提出了一种计算框架，从12个维度（如新闻价值、重要性、意外性）建模公众感知。利用这一框架，我们创建了一个大规模科学新闻感知数据集，包含来自美国和英国2,101名参与者的10,489条标注，为跨领域的公众反应提供了宝贵洞察。我们还开发了NLP模型，能够以较高性能预测公众感知分数。基于数据集和模型，我们从两个角度研究了公众对科学的感知：（1）感知作为结果：哪些因素影响公众对科学信息的感知？（2）感知作为预测因子：能否利用估计的感知预测公众对科学的参与？我们发现，个体科学新闻的消费频率是感知的主要驱动因素，而人口统计因素影响较小。更重要的是，通过大规模分析和在Reddit上精心设计的自然实验，我们证明科学信息的估计公众感知与最终参与模式直接相关。感知分数更高的帖子获得显著更多的评论和点赞，这一结果在不同科学信息和相同科学内容的不同表述中均一致。总体而言，本研究强调了感知建模在科学传播中的重要性，为预测公众对科学内容的兴趣和参与提供了新途径。

</details>


### [50] [Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System](https://arxiv.org/abs/2506.16628)
**中文标题：LLM辅助开发基于规则的临床NLP系统的初步研究**

*Jianlin Shi,Brian T. Bucher*

主要分类: cs.CL

摘要简述: 本文提出了一种利用大语言模型（LLM）辅助开发基于规则的临床自然语言处理（NLP）系统的新方法，实验显示其在识别临床相关文本片段和提取关键术语方面表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 尽管机器学习和大型语言模型取得了进展，但基于规则的NLP系统因其可解释性和操作效率仍在临床环境中广泛应用。然而，其手动开发和维护成本高昂，尤其是在语言变异性大的任务中。本文旨在通过LLM辅助开发，解决这一问题。

研究方法: 研究提出了一种新方法，仅在基于规则的系统开发阶段使用LLM。实验聚焦于开发基于规则的NLP管道的两个初始步骤：从临床记录中识别相关片段；从片段中提取用于命名实体识别（NER）的关键词。

研究结果: 实验结果表明，LLM在识别临床相关文本片段（Deepseek: 0.98, Qwen: 0.99）和提取NER关键术语（1.0）方面表现卓越。

研究结论: 本研究为NLP开发开辟了新方向，通过半自动化或自动化的方式开发基于规则的系统，相比基于深度学习模型的解决方案，执行速度更快、成本更低且更透明。

中文摘要: 尽管机器学习和大型语言模型（LLM）取得了进展，但基于规则的自然语言处理（NLP）系统因其可解释性和操作效率仍在临床环境中广泛应用。然而，其手动开发和维护成本高昂，尤其是在语言变异性大的任务中。为克服这些限制，我们提出了一种新方法，仅在基于规则的系统开发阶段使用LLM。我们进行了初步实验，聚焦于开发基于规则的NLP管道的两个初始步骤：从临床记录中识别相关片段；从片段中提取用于命名实体识别（NER）的关键词。实验结果显示，LLM在识别临床相关文本片段（Deepseek: 0.98, Qwen: 0.99）和提取NER关键术语（1.0）方面表现卓越。本研究为NLP开发开辟了新方向，通过半自动化或自动化的方式开发基于规则的系统，相比基于深度学习模型的解决方案，执行速度更快、成本更低且更透明。

</details>


### [51] [GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View](https://arxiv.org/abs/2506.16633)
**中文标题：GeoGuess：基于街景视觉信息层次的多模态推理**

*Fenghua Cheng,Jinxiang Wang,Sen Wang,Zi Huang,Xue Li*

主要分类: cs.CL

摘要简述: 本文提出了一种名为GeoGuess的新型多模态推理任务，旨在通过街景图像识别地理位置并生成详细解释。该任务要求系统能够结合局部细节和全局上下文进行多层次视觉推理，并引入数据集GeoExplain和推理方法SightSense，实验证明其出色性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态推理任务在评估能力时存在局限性，尤其是缺乏对多层次视觉线索（如局部细节与全局上下文）的推理讨论。GeoGuess任务旨在填补这一空白，通过结合视觉信息和地理知识，推动AI在多模态推理领域的发展。

研究方法: 论文提出了GeoGuess任务，并构建了数据集GeoExplain（包含街景图像、地理坐标和解释的三元组）。同时，提出了一种多模态、多层次的推理方法SightSense，能够基于视觉信息层次和外部知识进行预测和生成解释。

研究结果: 实验表明，SightSense方法在GeoGuess任务中表现优异，能够有效结合多层次视觉信息和地理知识，生成准确的预测和解释。

研究结论: GeoGuess任务为多模态推理提供了新的挑战，SightSense方法的成功验证了多层次视觉推理的重要性，为未来研究提供了方向。

中文摘要: 多模态推理是一种跨数据模态理解、整合和推断信息的过程，近年来作为人工智能（AI）的基准任务受到广泛关注。尽管已有多种任务用于评估多模态推理能力，但仍存在局限性，尤其是对多层次视觉线索（如局部细节与全局上下文）的推理讨论较少。为填补这一空白，我们提出了一种新颖且具挑战性的多模态推理任务GeoGuess：给定一张街景图像，任务是识别其地理位置并提供详细解释。成功的GeoGuess系统需能检测微小视觉线索、感知广阔景观并关联丰富地理知识。因此，GeoGuess需要具备在视觉信息层次与地理知识间进行推理的能力。本研究通过引入精心构建的数据集GeoExplain（包含街景全景图-地理坐标-解释的三元组）为GeoGuess建立基准。此外，我们提出了一种多模态、多层次的推理方法SightSense，能够基于视觉信息层次和外部知识进行预测并生成全面解释。分析与实验证明了其在GeoGuess任务中的出色表现。

</details>


### [52] [Long-Context Generalization with Sparse Attention](https://arxiv.org/abs/2506.16640)
**中文标题：基于稀疏注意力的长上下文泛化**

*Pavlo Vasylenko,Marcos Treviso,André F. T. Martins*

主要分类: cs.CL

摘要简述: 本文提出了一种稀疏注意力机制（ASEntmax），通过可学习的温度参数动态调整注意力分布，解决了传统Transformer中软注意力在长序列任务中注意力分散的问题，并结合优化的位置编码显著提升了长上下文泛化性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统Transformer使用softmax计算注意力权重，导致长序列中非关键信息分散注意力概率，影响模型对固定大小模式的精确聚焦。本文旨在通过稀疏注意力机制解决这一问题，提升长上下文任务的泛化能力。

研究方法: 提出ASEntmax稀疏注意力机制，结合可学习的温度参数，动态调整注意力分布的稀疏性；同时优化位置编码设计，进一步提升模型性能。

研究结果: 实验表明，ASEntmax结合优化位置编码的模型在长上下文泛化任务中显著优于传统softmax、可扩展softmax及固定温度的α-entmax基线方法。

研究结论: 稀疏注意力机制ASEntmax和优化的位置编码设计有效解决了长序列任务中的注意力分散问题，显著提升了模型的泛化能力。

中文摘要: 传统Transformer架构使用softmax计算注意力权重，生成对序列中所有令牌的密集分布。尽管在许多场景中有效，这种密集性对需要精确聚焦固定大小模式的任务不利：随着序列长度增加，非信息性令牌积累注意力概率质量，导致分散和表征崩溃。本文表明，使用α-entmax的稀疏注意力机制可避免这些问题，因其能为无关令牌分配精确零值。此外，我们提出自适应可扩展Entmax（ASEntmax），通过可学习的温度参数使注意力分布在稀疏（模式聚焦）和密集（类似softmax）状态间插值。最后，我们表明，通过精心设计位置编码，定位和泛化固定大小模式的能力可进一步提升，这对密集和稀疏注意力方法均有效。将ASEntmax与适当位置编码结合到标准Transformer层中后，我们的模型在长上下文泛化任务中大幅优于softmax、可扩展softmax及固定温度α-entmax基线。

</details>


### [53] [Arch-Router: Aligning LLM Routing with Human Preferences](https://arxiv.org/abs/2506.16655)
**中文标题：Arch-Router：将LLM路由与人类偏好对齐**

*Co Tran,Salman Paracha,Adil Hafeez,Shuguang Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种名为Arch-Router的偏好对齐路由框架，通过将查询与用户定义的领域或动作类型匹配，优化大型语言模型（LLM）的路由决策，显著提升了与人类偏好的匹配度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型语言模型路由方法存在两个主要问题：一是依赖的基准测试未能充分反映人类主观偏好，二是模型选择范围有限。本文旨在解决这些问题，提出一种更符合人类偏好的路由框架。

研究方法: 提出Arch-Router，一个1.5B参数的紧凑模型，通过学习将查询映射到领域-动作偏好，实现路由决策。该方法支持无缝添加新模型，无需重新训练或修改架构。

研究结果: 实验表明，Arch-Router在对话数据集上实现了与人类偏好的最佳匹配，性能优于顶级专有模型，同时提升了路由决策的透明度和灵活性。

研究结论: Arch-Router通过偏好对齐的路由框架，显著提升了大型语言模型路由的实用性和用户满意度，为未来研究提供了重要参考。

中文摘要: 随着大型语言模型（LLM）的快速普及——每种模型针对不同优势、风格或延迟/成本特性进行了优化——路由技术成为操作多样化模型使用的关键。然而，现有的LLM路由方法存在两个主要限制：它们依赖的基准测试往往无法捕捉由主观评价标准驱动的人类偏好，且通常只能从有限的模型池中选择。本文提出了一种偏好对齐的路由框架，通过将查询与用户定义的领域（如旅行）或动作类型（如图像编辑）匹配，为路由决策提供了一种实用的偏好编码机制。具体而言，我们引入了Arch-Router，一个1.5B参数的紧凑模型，通过学习将查询映射到领域-动作偏好，实现路由决策。该方法还支持无缝添加新模型，无需重新训练或架构修改。在对话数据集上的实验表明，我们的方法在匹配查询与人类偏好方面达到了最先进（SOTA）水平，优于顶级专有模型。我们的方法能够捕捉主观评价标准，并使路由决策更加透明和灵活。模型地址：https://huggingface.co/katanemo/Arch-Router-1.5B。

</details>


### [54] [Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations](https://arxiv.org/abs/2506.16678)
**中文标题：机制与结果：探测语法无法解释针对性语法评估中的表现**

*Ananth Agarwal,Jasper Jian,Christopher D. Manning,Shikhar Murty*

主要分类: cs.CL

摘要简述: 研究发现，尽管大语言模型（LLMs）在文本处理中表现出对语法的强大掌握，但通过探测提取的语法特征无法可靠预测其在针对性语法评估中的表现，揭示了探测方法与实际语法行为之间的脱节。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在文本生成和处理中展现出对语法的深刻理解，但其内部如何表示语法结构尚不明确。探测方法被用于识别语法机制，但尚未有研究验证探测准确性是否能预测模型在语法任务中的表现。本文旨在填补这一空白。

研究方法: 研究采用“机制与结果”框架，评估了32个开源Transformer模型，通过探测提取语法特征，并分析这些特征是否能预测模型在针对性语法评估中的表现。

研究结果: 结果显示，探测提取的语法特征无法有效预测模型在英语语言现象中的语法表现，表明探测方法与实际语法行为之间存在显著脱节。

研究结论: 研究揭示了探测方法在解释模型语法行为上的局限性，强调需要更深入的方法来理解大语言模型的内部语法表示。

中文摘要: 大语言模型（LLMs）在文本处理和生成中展现出对语法的强大掌握。尽管这表明其对层次化语法和依赖关系有内化理解，但其内部如何表示语法结构仍是可解释性研究的开放领域。探测方法可用于识别语法机制是否线性编码于激活中，但目前尚无全面研究验证模型的探测准确性是否能可靠预测其下游语法表现。采用“机制与结果”框架，我们评估了32个开源Transformer模型，发现通过探测提取的语法特征无法预测模型在英语语言现象中的针对性语法评估结果。我们的结果凸显了探测发现的潜在语法表示与下游任务中可观察的语法行为之间的显著脱节。

</details>


### [55] [LegiGPT: Party Politics and Transport Policy with Large Language Model](https://arxiv.org/abs/2506.16692)
**中文标题：LegiGPT：基于大语言模型的政党政治与交通政策分析**

*Hyunsoo Yun,Eun Hak Lee*

主要分类: cs.CL

摘要简述: 本文提出LegiGPT框架，结合大语言模型和可解释AI分析交通政策提案，揭示立法者政治意识形态对政策制定的影响。


<details>
  <summary>详细信息</summary>
研究动机: 立法者的政治意识形态对立法决策有重要影响，研究其如何影响交通政策制定具有重要意义。

研究方法: LegiGPT采用多阶段过滤和分类流程，利用GPT-4的零样本提示技术分析韩国第21届国会的交通相关提案，并结合可解释AI技术探究政党属性与提案特征的关系。

研究结果: 研究发现，保守派和进步派提案人的数量及比例、选区规模和选民人口是影响立法结果的关键因素，两党通过不同形式的参与推动两党合作立法。

研究结论: LegiGPT为理解立法动态和指导未来政策制定提供了有力工具，对基础设施规划和治理具有广泛意义。

中文摘要: 鉴于立法者政治意识形态对立法决策的显著影响，理解其对政策制定的作用至关重要。我们提出了一种新颖的框架LegiGPT，该框架将大语言模型（LLM）与可解释人工智能（XAI）相结合，用于分析交通相关的立法提案。LegiGPT采用基于GPT-4的零样本提示技术，通过多阶段过滤和分类流程处理数据。利用韩国第21届国会的立法数据，我们识别出提案人特征、政党属性和地理变量等关键因素对交通政策制定的显著影响。通过逐步过滤关键词、短语和上下文相关性，LLM对交通相关提案进行分类。随后应用XAI技术分析政党属性与相关特征的关系。结果显示，保守派和进步派提案人的数量及比例、选区规模和选民人口是塑造立法结果的关键决定因素。这些发现表明，两党通过发起或支持提案等不同形式的参与推动了跨党派立法。这一综合方法为理解立法动态和指导未来政策制定提供了有价值的工具，对基础设施规划和治理具有更广泛的意义。

</details>


### [56] [ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models](https://arxiv.org/abs/2506.16712)
**中文标题：ReasonGRM：通过大型推理模型增强生成奖励模型**

*Bin Chen,Xinzge Gao,Chuanrui Hu,Penghang Yu,Hua Zhang,Bing-Kun Bao*

主要分类: cs.CL

摘要简述: ReasonGRM通过三阶段生成奖励模型框架，结合零样本强化学习和新型评估指标R*，显著提升生成奖励模型的推理能力和偏好建模效果，在多个基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 生成奖励模型（GRMs）在捕捉人类偏好方面具有灵活性，但其推理能力不足导致在复杂任务中出现信息缺失或幻觉问题。ReasonGRM旨在通过增强推理能力解决这一问题。

研究方法: ReasonGRM采用三阶段框架：1）使用Zero-RL生成简洁的结果导向推理路径；2）引入评估指标R*，基于生成可能性评分推理路径；3）通过强化学习在挑战性示例上进一步优化模型。

研究结果: 在三个公开基准测试中，ReasonGRM平均优于先前最佳GRMs 1.8%，并超越GPT-4o等专有模型高达5.6%，验证了其推理感知训练的有效性。

研究结论: ReasonGRM通过高质量推理路径选择和强化学习优化，显著提升了生成奖励模型的可靠性和性能，为偏好建模提供了新思路。

中文摘要: 生成奖励模型（GRMs）在捕捉人类偏好方面比标量奖励模型更具灵活性，但其推理能力不足限制了其效果，常导致复杂任务中出现信息缺失或幻觉问题。为此，我们提出了ReasonGRM，一个三阶段生成奖励建模框架。第一阶段使用Zero-RL生成简洁的结果导向推理路径，减少关键遗漏的可能性。第二阶段引入新型评估指标R*，基于生成可能性对推理路径评分，优先选择以最少探索达到正确答案的路径，从而减少训练中的幻觉倾向数据。第三阶段通过强化学习在挑战性示例上进一步优化模型，增强其偏好判别能力。在三个公开基准测试中，ReasonGRM表现优异，平均超越先前最佳GRMs 1.8%，并超越GPT-4o等专有模型高达5.6%。这些结果验证了推理感知训练的有效性，并凸显了高质量推理路径选择对可靠偏好建模的重要性。

</details>


### [57] [The Role of Model Confidence on Bias Effects in Measured Uncertainties](https://arxiv.org/abs/2506.16724)
**中文标题：模型置信度对测量不确定性中偏差效应的作用**

*Xinyi Liu,Weiguang Wang,Hangfeng He*

主要分类: cs.CL

摘要简述: 研究探讨了模型置信度对偏差效应在不确定性测量中的影响，发现低置信度下偏差会显著增加认知和随机不确定性，并导致认知不确定性的低估。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在开放任务中的广泛应用，准确评估认知不确定性（反映模型知识不足）对确保可靠结果至关重要。然而，由于随机不确定性的存在（源于多个有效答案），量化认知不确定性具有挑战性。偏差可能影响不确定性估计，但同时也可能减少随机不确定性的噪声。本研究旨在探究这一权衡关系。

研究方法: 通过在视觉问答（VQA）任务上进行实验，研究分析了提示引入的偏差对GPT-4o和Qwen2-VL模型中认知和随机不确定性的影响，特别关注不同无偏差置信度水平下的变化。

研究结果: 研究发现，所有考虑的偏差在无偏差模型置信度较低时，对认知和随机不确定性的影响更大。低置信度还会导致认知不确定性的低估（即过度自信），但对随机不确定性估计的变化方向无显著影响。

研究结论: 这些发现深化了对偏差缓解与不确定性量化之间关系的理解，并为开发更先进的技术提供了潜在启示。

中文摘要: 随着大型语言模型（LLMs）在开放任务中的广泛应用，准确评估认知不确定性（反映模型知识不足）对确保可靠结果至关重要。然而，由于随机不确定性的存在（源于多个有效答案），量化认知不确定性具有挑战性。偏差可能为认知不确定性估计引入噪声，但也可能减少随机不确定性的噪声。为探究这一权衡关系，我们在视觉问答（VQA）任务上进行实验，发现减少提示引入的偏差可改善GPT-4o的不确定性量化。基于先前研究表明LLMs在模型置信度低时倾向于复制输入信息，我们进一步分析了这些提示偏差如何影响GPT-4o和Qwen2-VL在不同无偏差置信度水平下的认知和随机不确定性。研究发现，所有考虑的偏差在无偏差模型置信度较低时，对两种不确定性的影响更大。此外，较低的无偏差模型置信度会因偏差导致认知不确定性的低估（即过度自信），但对随机不确定性估计的变化方向无显著影响。这些不同的效应深化了我们对偏差缓解与不确定性量化之间关系的理解，并可能为开发更先进的技术提供信息。

</details>


### [58] [LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization](https://arxiv.org/abs/2506.16738)
**中文标题：LM-SPT：面向语言模型对齐的语音标记化语义蒸馏方法**

*Daejin Jo,Jeeyoung Yun,Byungseok Roh,Sungwoong Kim*

主要分类: cs.CL

摘要简述: LM-SPT是一种新型语音标记化方法，通过语义蒸馏技术减少语音标记序列长度，同时保持与语言模型的对齐，提升语音-语言模型的效率。


<details>
  <summary>详细信息</summary>
研究动机: 随着语音语言模型的快速发展，离散语音标记成为语音与文本之间的核心接口。然而，现有方法生成的语音标记序列过长，影响建模效率。直接降低帧率可能破坏语义结构，因此需要一种既能减少标记长度又能保持语义对齐的新方法。

研究方法: LM-SPT提出了一种间接的语义蒸馏方法：通过重构语音并最小化原始与重构波形编码表示的差异，学习更语义化的离散单元。此外，改进了编码器和解码器架构，支持多种帧率（25Hz、12.5Hz、6.25Hz）。

研究结果: 实验表明，LM-SPT在重建保真度上优于基线方法，使用其标记训练的语音语言模型在语音转文本任务中表现优异，在文本转语音任务中一致超越基线。

研究结论: LM-SPT通过语义蒸馏和架构改进，有效解决了语音标记序列过长的问题，同时保持了与语言模型的语义对齐，为语音-语言建模提供了高效解决方案。

中文摘要: 随着语音语言模型（SLMs）的快速发展，离散语音标记已成为语音与文本之间的核心接口，实现了跨模态的统一建模。现有的语音标记化方法旨在从低级声学中分离语义信息，以更好地与语言模型对齐。例如，先前的方法使用HuBERT等自监督学习（SSL）教师模型提取语义表示，再将其蒸馏到语义量化器中，以抑制声学冗余并捕捉内容相关的潜在结构。然而，这些方法生成的语音标记序列仍显著长于文本标记，为高效的语音-语言建模带来了挑战。降低帧率是一种自然解决方案，但标准技术（如跨帧的刚性平均池化）可能扭曲或稀释有效对齐所需的语义结构。为此，我们提出了LM-SPT，一种新型语音标记化方法，引入了语义蒸馏技术。该方法不直接通过池化匹配师生特征，而是仅从语义标记重构语音，并最小化原始波形与重构波形编码表示之间的差异（通过冻结的自动语音识别编码器获取）。这种间接但数据驱动的监督使标记器学习到更语义化且与语言模型对齐的离散单元。LM-SPT进一步改进了编码器和解码器架构，支持多种帧率（25Hz、12.5Hz、6.25Hz）。实验结果表明，LM-SPT在重建保真度上优于基线方法，且使用其标记训练的SLMs在语音转文本任务中表现优异，在文本转语音任务中一致超越基线。

</details>


### [59] [Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning On-The-Fly](https://arxiv.org/abs/2506.16755)
**中文标题：基于语言信息的理性代理模型合成：用于实时接地心智理论推理**

*Lance Ying,Ryan Truong,Katherine M. Collins,Cedegao E. Zhang,Megan Wei,Tyler Brooke-Wilson,Tan Zhi-Xuan,Lionel Wong,Joshua B. Tenenbaum*

主要分类: cs.CL

摘要简述: 本文提出了一种名为LIRAS的框架，通过结合语言和视觉输入进行多模态社会推理，生成情境特定的代理模型，并在认知科学实验任务中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的社会推理通常需要整合多模态信息，尤其是语言信息在社交环境中具有重要作用。本文旨在开发一种能够结合语言和视觉输入进行高效社会推理的框架。

研究方法: LIRAS框架通过多模态语言模型将语言和视觉输入解析为统一的符号表示，并利用贝叶斯逆向规划引擎生成细粒度的概率判断。

研究结果: 在多个认知科学实验任务中，LIRAS（使用轻量级视觉语言模型实现）的表现优于其他模型和消融实验，能够更准确地捕捉人类判断。

研究结论: LIRAS框架通过整合语言和视觉输入，能够有效支持情境特定的社会推理任务，为多模态社会推理提供了新的解决方案。

中文摘要: 现实世界中的社会推理通常需要整合多模态信息。语言在社交环境中是一种特别强大的信息来源，尤其是在新情境中，语言既能提供环境动态的抽象信息，也能提供难以通过视觉观察的具体代理信息。本文提出了语言信息理性代理合成（LIRAS）框架，用于整合语言和视觉输入进行情境特定的社会推理。LIRAS将多模态社会推理视为构建结构化但情境特定的代理和环境表征的过程，利用多模态语言模型将语言和视觉输入解析为统一的符号表示，并通过贝叶斯逆向规划引擎生成细粒度的概率判断。在多个源于认知科学实验的社会推理任务中，我们发现LIRAS（使用轻量级视觉语言模型实现）的表现优于消融实验和现有最先进模型，能够更准确地捕捉人类判断。

</details>


### [60] [SocialSim: Towards Socialized Simulation of Emotional Support Conversation](https://arxiv.org/abs/2506.16756)
**中文标题：SocialSim：面向情感支持对话的社交化模拟**

*Zhuang Chen,Yaru Cao,Guanqun Bi,Jincenzi Wu,Jinfeng Zhou,Xiyao Xiao,Si Chen,Hongning Wang,Minlie Huang*

主要分类: cs.CL

摘要简述: 本文提出SocialSim框架，通过整合社交互动中的关键要素（社交披露和社交意识）来模拟情感支持对话（ESC），并构建了高质量的合成数据集SSConv。实验表明，基于SSConv训练的聊天机器人在自动和人工评估中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在模拟情感支持对话时忽视了社交动态，导致效果不佳。本文旨在通过整合社交互动要素，提升模拟的真实性和有效性。

研究方法: SocialSim框架包含两部分：1）在求助者端，通过构建全面的角色库实现社交披露；2）在支持者端，通过认知推理增强社交意识，生成逻辑性强的支持性回应。基于此框架，构建了大规模合成数据集SSConv。

研究结果: SSConv数据集的质量甚至超过众包数据，基于其训练的聊天机器人在自动和人工评估中达到最先进性能。

研究结论: SocialSim为合成情感支持对话提供了可扩展的方法，使情感关怀更易实现和实用。

中文摘要: 情感支持对话（ESC）通过互动对话帮助减轻心理压力并提供情感价值。由于众包大规模ESC语料库成本高昂，近期尝试使用大型语言模型进行对话增强。然而，现有方法大多忽视了ESC中固有的社交动态，导致模拟效果不佳。本文提出SocialSim，一种通过整合社交互动的关键方面（社交披露和社交意识）来模拟ESC的新框架。在求助者端，我们通过构建全面的角色库促进社交披露，捕捉多样且真实的求助场景；在支持者端，通过激发认知推理增强社交意识，生成逻辑性强的支持性回应。基于SocialSim，我们构建了SSConv，一个大规模的合成ESC语料库，其质量甚至超过众包数据。我们进一步在SSConv上训练了一个聊天机器人，并在自动和人工评估中展示了其最先进的性能。我们相信SocialSim为合成ESC提供了一种可扩展的方法，使情感关怀更易实现和实用。

</details>


### [61] [Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models](https://arxiv.org/abs/2506.16760)
**中文标题：跨模态混淆：针对大型视觉语言模型的越狱攻击**

*Lei Jiang,Zixun Zhang,Zizhou Wang,Xiaobing Sun,Zhen Li,Liangli Zhen,Xiaohua Xu*

主要分类: cs.CL

摘要简述: 本文提出了一种名为CAMO的新型黑盒越狱攻击框架，通过将恶意提示分解为语义无害的视觉和文本片段，利用大型视觉语言模型（LVLM）的跨模态推理能力，隐蔽地重构有害指令，从而规避传统检测机制。该方法具有可调推理复杂性和高查询效率，实验验证了其有效性和跨模型迁移能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型（LVLM）在多模态任务中表现出色，但其内置安全机制易受越狱攻击，现有黑盒攻击方法依赖对抗性文本提示或图像扰动，容易被检测且效率低下。因此，需要一种更隐蔽、高效的攻击方法。

研究方法: 提出跨模态对抗多模态混淆（CAMO）框架，将恶意提示分解为语义无害的视觉和文本片段，利用LVLM的跨模态推理能力逐步重构有害指令，避免被传统检测机制发现。该方法支持调整推理复杂性，并显著减少查询次数。

研究结果: 在主流LVLM上的全面评估验证了CAMO的有效性，表现出鲁棒的性能和强大的跨模型迁移能力，揭示了当前内置安全机制的重大漏洞。

研究结论: CAMO框架成功规避了传统检测机制，展示了LVLM安全性的脆弱性，强调了开发更先进的、对齐感知的安全解决方案的紧迫性。

中文摘要: 大型视觉语言模型（LVLM）在多模态任务中表现出卓越性能，但仍易受越狱攻击，这些攻击绕过内置安全机制以诱导生成受限内容。现有的黑盒越狱方法主要依赖对抗性文本提示或图像扰动，但这些方法易被标准内容过滤系统检测且查询和计算效率低。本文提出跨模态对抗多模态混淆（CAMO），一种新型黑盒越狱攻击框架，将恶意提示分解为语义无害的视觉和文本片段。通过利用LVLM的跨模态推理能力，CAMO隐蔽地通过多步推理重构有害指令，规避传统检测机制。我们的方法支持可调推理复杂性，且比现有攻击所需的查询次数显著减少，兼具隐蔽性和高效性。在主流LVLM上的全面评估验证了CAMO的有效性，展示了鲁棒的性能和强大的跨模型迁移能力。这些结果凸显了当前内置安全机制的重大漏洞，强调了在视觉语言系统中开发先进的、对齐感知的安全解决方案的紧迫性。

</details>


### [62] [DistillNote: LLM-based clinical note summaries improve heart failure diagnosis](https://arxiv.org/abs/2506.16777)
**中文标题：DistillNote：基于大语言模型的临床笔记摘要提升心力衰竭诊断**

*Heloisa Oss Boll,Antonio Oss Boll,Leticia Puttlitz Boll,Ameen Abu Hanna,Iacer Calixto*

主要分类: cs.CL

摘要简述: DistillNote是一种基于大语言模型（LLM）的临床笔记摘要框架，通过三种技术生成摘要，显著提升心力衰竭诊断的准确性和效率。


<details>
  <summary>详细信息</summary>
研究动机: 临床文档的繁重负担使医护人员不堪重负，大语言模型（LLM）为生成简洁的患者信息摘要提供了新机会，旨在减轻这一负担并提升诊断效率。

研究方法: DistillNote采用三种技术生成摘要：(1) 一步直接摘要，(2) 结构化摘要（聚焦独立临床见解），(3) 蒸馏摘要（进一步压缩结构化摘要）。通过预测心力衰竭的效果验证摘要的实用性。

研究结果: 蒸馏摘要实现了79%的文本压缩率，AUPRC提升高达18.2%。临床评估显示，一步摘要更受青睐，而蒸馏摘要在效率和减少幻觉方面表现最佳。

研究结论: DistillNote框架显著提升了临床笔记摘要的质量和效率，为未来研究提供了实用工具和数据支持。

中文摘要: 大语言模型（LLM）为生成简洁的患者信息摘要提供了前所未有的机会，能够减轻临床文档对医护人员的负担。我们提出了DistillNote，一种基于LLM的临床笔记摘要框架，通过三种技术生成了超过64,000份入院笔记摘要：(1) 一步直接摘要，(2) 结构化摘要（聚焦独立临床见解），(3) 蒸馏摘要（进一步压缩结构化摘要）。我们通过预测心力衰竭的效果验证了摘要的实用性。蒸馏摘要实现了79%的文本压缩率，AUPRC提升高达18.2%。我们还通过LLM作为评估者和临床医生的盲法配对比较评估了摘要质量。评估表明，临床医生更青睐一步摘要的相关性和临床可操作性，而蒸馏摘要在效率（平均6.9倍压缩性能比）和减少幻觉方面表现最佳。我们将摘要发布在PhysioNet上，以促进未来研究。

</details>


### [63] [MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning](https://arxiv.org/abs/2506.16792)
**中文标题：MIST：通过迭代语义调优破解黑盒大语言模型**

*Muyang Zheng,Yuanzhi Yao,Changting Lin,Rui Wang,Meng Han*

主要分类: cs.CL

摘要简述: MIST是一种通过迭代语义调优破解黑盒大语言模型的方法，能够在保持语义意图的同时诱导有害内容生成，具有较高的攻击成功率和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型（LLMs）已与社会和道德价值观对齐，但仍易受破解攻击。由于黑盒模型的离散输入、访问限制和有限查询预算，破解具有挑战性。MIST旨在解决这些问题。

研究方法: MIST通过迭代优化提示词，结合顺序同义词搜索和顺序确定优化策略，平衡语义相似性与计算效率。

研究结果: 实验表明，MIST在开源和闭源模型中均取得高攻击成功率和可迁移性，同时验证了其计算效率的实用性。

研究结论: MIST为破解黑盒大语言模型提供了高效且实用的方法，优于现有白盒和黑盒破解技术。

中文摘要: 尽管大语言模型（LLMs）已与社会和道德价值观对齐，这些模型仍易受破解攻击——即设计用于引发有害响应的方法。破解黑盒LLMs被认为具有挑战性，原因包括输入的离散性、对目标LLM的访问限制以及有限的查询预算。为解决上述问题，我们提出了一种通过迭代语义调优破解黑盒大语言模型的有效方法，名为MIST。MIST使攻击者能够迭代优化提示词，在保持原始语义意图的同时诱导有害内容。具体而言，为平衡语义相似性与计算效率，MIST结合了两种关键策略：顺序同义词搜索及其高级版本——顺序确定优化。在两种开源模型和四种闭源模型上的广泛实验表明，与其他最先进的白盒和黑盒破解方法相比，MIST实现了具有竞争力的攻击成功率和攻击可迁移性。此外，我们还进行了计算效率实验，验证了MIST的实际可行性。

</details>


### [64] [From Data to Knowledge: Evaluating How Efficiently Language Models Learn Facts](https://arxiv.org/abs/2506.16912)
**中文标题：从数据到知识：评估语言模型学习事实的效率**

*Daniel Christoph,Max Ploner,Patrick Haller,Alan Akbik*

主要分类: cs.CL

摘要简述: 研究分析了不同架构和大小的语言模型在相同预训练数据上的表现，发现模型在高频事实上的表现相似，但在低频事实上差异显著，揭示了模型架构、大小与事实学习效率的关系。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型的样本效率对训练效率至关重要，尤其是在处理长尾分布的信息时。研究旨在探索模型如何高效学习和记忆高频与低频事实，为实际应用提供指导。

研究方法: 研究通过标注训练语料中关系事实的频率，分析了多种不同架构和大小的语言模型在同一预训练数据上的表现，重点关注模型在不同频率事实上的性能差异。

研究结果: 结果显示，大多数模型在高频事实上的表现相似，但在低频事实上表现差异显著，表明模型架构和大小对低频事实的学习效率有重要影响。

研究结论: 研究为模型架构、大小与事实学习效率之间的关系提供了新见解，有助于优化语言模型的设计和训练策略。

中文摘要: 样本效率是语言模型的关键属性，对训练效率具有实际意义。在真实文本中，信息呈现长尾分布，但模型需要学习和记忆高频与低频事实。样本效率高的模型能更好地应对学习和保留稀有信息的挑战，而无需过度暴露。本研究分析了多种不同架构和大小的模型，均在同一预训练数据上训练。通过标注关系事实在训练语料中的频率，我们研究了模型性能如何随事实频率变化。结果显示，大多数模型在高频事实上表现相似，但在低频事实上差异显著。这一分析为模型架构、大小与事实学习效率之间的关系提供了新见解。

</details>


### [65] [Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond](https://arxiv.org/abs/2506.16982)
**中文标题：语言瓶颈模型：一种用于可解释知识追踪及其他领域的框架**

*Antonin Berthon,Mihaela van der Schaar*

主要分类: cs.CL

摘要简述: 该论文提出了一种名为语言瓶颈模型（LBM）的框架，用于解决知识追踪（KT）中的可解释性问题。LBM通过自然语言总结学生知识，确保预测信息透明且准确，实验表明其性能与现有方法相当但更高效。


<details>
  <summary>详细信息</summary>
研究动机: 传统知识追踪方法依赖不透明的潜在嵌入，缺乏可解释性，而基于大语言模型（LLM）的方法可能产生不准确的预测或总结。论文旨在通过自然语言总结实现透明且准确的学生知识评估。

研究方法: 论文提出语言瓶颈模型（LBM），包括一个编码器LLM生成可解释的知识总结，以及一个冻结的解码器LLM仅基于总结文本重建和预测学生回答。通过训练编码器使用下游解码准确率作为奖励信号，优化总结质量。

研究结果: 在合成算术基准和大规模Eedi数据集上的实验表明，LBM在准确性上与最先进的知识追踪和直接LLM方法相当，同时所需学生轨迹数据量显著减少。

研究结论: LBM通过自然语言瓶颈约束预测信息，实现了知识追踪的高准确性和可解释性，为教育技术提供了一种透明且高效的解决方案。

中文摘要: 准确评估学生知识对教育至关重要，但传统知识追踪（KT）方法依赖不透明的潜在嵌入，限制了可解释性。即使是基于大语言模型（LLM）的方法，也可能生成无准确性保证的直接预测或总结。我们将KT重新定义为逆问题：学习最小的自然语言总结，使过去的答案可解释且未来的答案可预测。我们的语言瓶颈模型（LBM）包括一个编码器LLM，用于编写可解释的知识总结，以及一个冻结的解码器LLM，仅基于该总结文本重建和预测学生回答。通过将所有预测信息约束为通过简短的自然语言瓶颈，LBM确保总结包含准确信息且保持人类可解释性。在合成算术基准和大规模Eedi数据集上的实验表明，LBM在准确性上与最先进的KT和直接LLM方法相当，同时所需学生轨迹数据量显著减少。我们证明，通过使用下游解码准确率作为奖励信号，采用组相对策略优化训练编码器，能有效提高总结质量。

</details>


### [66] [TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs](https://arxiv.org/abs/2506.16990)
**中文标题：TeXpert：一个用于评估LLMs生成LaTeX代码的多级基准**

*Sahil Kale,Vijaykant Nadadur*

主要分类: cs.CL

摘要简述: 论文介绍了TeXpert基准数据集，用于评估LLMs生成LaTeX代码的能力，发现LLMs在复杂任务中表现不佳，开源模型表现接近闭源模型，且训练数据中缺乏多样化的LaTeX示例。


<details>
  <summary>详细信息</summary>
研究动机: LaTeX是科学文档排版的黄金标准，但目前缺乏评估LLMs生成LaTeX代码能力的基准。论文旨在填补这一空白，通过引入TeXpert数据集，分析LLMs在生成LaTeX代码时的表现和常见错误。

研究方法: 论文提出TeXpert基准数据集，包含多难度级别的自然语言提示，用于生成科学文档的LaTeX代码。对开源和闭源LLMs进行深入评估，分析其表现和错误类型。

研究结果: 评估结果显示：LLMs在标准基准上表现优异，但在LaTeX生成任务中表现不佳，任务复杂度增加时准确率显著下降；开源模型如DeepSeek v3和DeepSeek Coder在LaTeX任务中表现接近闭源模型；格式和包错误普遍，表明LLMs训练数据中缺乏多样化的LaTeX示例。

研究结论: 论文通过TeXpert数据集揭示了LLMs在LaTeX生成任务中的局限性，开源模型表现优异，但训练数据的多样性不足是主要问题。数据集和评估结果已开源。

中文摘要: LaTeX因其排版的高精度和灵活性成为科学文档准备的金标准。大型语言模型（LLMs）为研究人员提供了通过自然语言指令生成LaTeX代码的潜力，但当前基准完全缺乏对此能力的评估。通过引入TeXpert，我们的基准数据集包含针对科学文档组件的多难度级别自然语言提示，用于生成LaTeX代码，我们深入分析了LLMs在此方面的表现并识别了常见错误类型。我们对开源和闭源LLMs的评估揭示了多个关键发现：在标准基准上表现优异的LLMs在LaTeX生成任务中表现不佳，任务复杂度增加时准确率显著下降；开源模型如DeepSeek v3和DeepSeek Coder在LaTeX任务中表现接近闭源模型；格式和包错误意外普遍，表明大多数LLMs的训练数据中缺乏多样化的LaTeX示例。我们的数据集、代码和模型评估结果可在https://github.com/knowledge-verse-ai/TeXpert获取。

</details>


### [67] [PersonalAI: Towards digital twins in the graph form](https://arxiv.org/abs/2506.17001)
**中文标题：PersonalAI：迈向图形式的数字孪生**

*Mikhail Menschikov,Dmitry Evseev,Ruslan Kostoev,Ilya Perepechkin,Ilnaz Salimov,Victoria Dochkina,Petr Anokhin,Evgeny Burnaev,Nikita Semenov*

主要分类: cs.CL

摘要简述: 本文提出了一种基于知识图谱的外部记忆方法，用于增强语言模型的个性化能力，通过结合标准边和超边的图结构，实验表明该方法在知识提取和问答任务中表现稳健。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型语言模型（LLMs）和检索增强生成技术取得了进展，但如何保留大量个人信息并生成个性化回应仍是一个挑战。本文旨在通过知识图谱解决这一问题。

研究方法: 提出利用知识图谱作为外部记忆，由LLM自身构建和更新图谱。扩展了AriGraph架构，首次引入包含标准边和两种超边的组合图结构，并在TriviaQA、HotpotQA和DiaASQ基准上进行了实验。

研究结果: 实验表明，该方法在知识提取和图构建过程中表现统一且稳健。即使在DiaASQ基准中引入时间和矛盾陈述等参数，问答系统的性能仍保持稳定。

研究结论: 提出的架构能够有效维护和利用时间依赖性，为个性化语言模型的发展提供了新思路。

中文摘要: 个性化语言模型的挑战，尤其是在交互中考虑用户历史的能力，具有重要意义。尽管大型语言模型（LLMs）和检索增强生成技术的最新进展增强了LLMs的事实基础，但保留大量个人信息并用于生成个性化回应的任务仍然重要。为此，我们提出利用知识图谱作为外部记忆，由LLM自身构建和更新图谱。我们扩展了AriGraph架构的思想，首次引入了一种包含标准边和两种超边的组合图。在TriviaQA、HotpotQA和DiaASQ基准上的实验表明，这种方法有助于使图构建和知识提取过程统一且稳健。此外，我们通过在对话中引入时间参数以及同一说话者在不同时间做出的矛盾陈述，增强了DiaASQ基准。尽管进行了这些修改，问答系统的性能仍保持稳健，证明了所提架构在维护和利用时间依赖性方面的能力。

</details>


### [68] [LLM-Generated Feedback Supports Learning If Learners Choose to Use It](https://arxiv.org/abs/2506.17006)
**中文标题：LLM生成的反馈支持学习——如果学习者选择使用它**

*Danielle R. Thomas,Conrad Borchers,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Kenneth R. Koedinger*

主要分类: cs.CL

摘要简述: 研究发现，由大型语言模型（LLM）生成的反馈对学习有积极影响，但效果取决于学习者是否主动选择使用。在七项基于场景的导师培训课程中，使用LLM反馈的学习者在后测中表现更好，尤其是那些更倾向于寻求支持的学习者。LLM反馈未显著增加学习时间，且被广泛认为有帮助。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）越来越多地用于生成反馈，但其对学习的影响尚未充分研究，尤其是与现有反馈方法相比。本研究旨在探索LLM生成的按需解释性反馈如何影响学习效果。

研究方法: 研究分析了885名导师学习者在七项基于场景的培训课程中的2,600多次课程完成情况。学习者分为三组：接受gpt-3.5-turbo生成的反馈组、拒绝反馈组和无访问组。所有组均接受非LLM的纠正反馈。为消除选择偏差（如高表现学习者更可能使用LLM反馈），研究采用倾向评分法。

研究结果: 研究发现，更倾向于使用LLM反馈的学习者在后测中得分显著更高。调整倾向效应后，七项课程中有两项显示出LLM反馈的显著学习益处（标准化效应量为0.28和0.33）。LLM反馈未显著增加完成时间，且学习者普遍认为其有帮助。

研究结论: LLM反馈是一种低成本、可扩展的学习支持工具，尤其适用于已有反馈系统的开放任务。其效果取决于学习者的使用倾向。研究提供了开放数据集、LLM提示和评分标准以支持可重复性。

中文摘要: 大型语言模型（LLM）越来越多地用于生成反馈，但其对学习的影响尚未充分研究，尤其是与现有反馈方法相比。本研究探讨了在七项基于场景的导师培训课程中，按需LLM生成的解释性反馈如何影响学习。通过分析885名导师学习者的2,600多次课程完成情况，比较了三组学习者的后测表现：接受gpt-3.5-turbo生成反馈组、拒绝反馈组和无访问组。所有组均接受非LLM的纠正反馈。为消除选择偏差（如高表现学习者更可能使用LLM反馈），研究采用倾向评分法。结果显示，更倾向于使用LLM反馈的学习者在后测中得分显著更高。调整倾向效应后，七项课程中有两项显示出LLM反馈的显著学习益处（标准化效应量为0.28和0.33）。LLM反馈未显著增加完成时间，且学习者普遍认为其有帮助。这些发现表明，LLM反馈是一种低成本、可扩展的学习支持工具，尤其适用于已有反馈系统的开放任务。研究提供了开放数据集、LLM提示和评分标准以支持可重复性。

</details>


### [69] [Instituto de Telecomunicações at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning](https://arxiv.org/abs/2506.17019)
**中文标题：IT-IST在IWSLT 2025的任务：对齐小规模语音和语言模型以支持语音到文本学习**

*Giuseppe Attanasio,Sonal Sannigrahi,Ben Peters,André F. T. Martins*

主要分类: cs.CL

摘要简述: 本文介绍了IT-IST团队在IWSLT 2025共享任务中的提交成果，专注于小规模语音和语言模型的对齐，用于语音到文本学习。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索如何通过小规模语言模型（<2B）和高质量数据（包括合成数据）实现语音到文本任务的高效学习。

研究方法: 方法包括两个阶段：首先通过模态对齐将预训练的连续语音编码器与文本解码器整合，然后通过指令微调优化模型。

研究结果: 实验结果表明，该方法在语音识别、翻译和口语问答任务中表现良好，验证了小规模模型的潜力。

研究结论: 结论指出，小规模语言模型结合高质量数据和模态对齐策略，能够有效支持语音到文本任务的学习。

中文摘要: 本文介绍了IT-IST团队在IWSLT 2025共享任务中的提交成果，专注于指令跟随语音处理。我们提交了短赛道（语音识别、翻译和口语问答）的结果。我们的模型是一个统一的语音到文本模型，通过模态对齐和指令微调两个阶段，整合了预训练的连续语音编码器和文本解码器。关键点在于使用小规模语言模型（<2B）并限制使用高质量CC-BY数据，同时通过合成数据补充现有资源。

</details>


### [70] [MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models](https://arxiv.org/abs/2506.17046)
**中文标题：MUCAR：面向多模态大语言模型的多语言跨模态歧义消解基准**

*Xiaolong Wang,Zhaolu Kang,Wangyuxuan Zhai,Xinyue Lou,Yunghwei Lai,Ziyue Wang,Yawen Wang,Kaiyu Huang,Yile Wang,Peng Li,Yang Liu*

主要分类: cs.CL

摘要简述: MUCAR是一个新颖的多语言跨模态歧义消解基准，旨在评估多模态大语言模型在解决语言和视觉歧义方面的能力。通过构建包含多语言和双歧义数据集的基准，研究发现现有模型与人类表现存在显著差距，需进一步改进跨模态理解方法。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在视觉语言任务中表现优异，但在处理自然语言和视觉上下文中的歧义时仍面临挑战。现有基准多忽略多模态间的相互消歧潜力，因此需要专门评估跨模态歧义消解能力的工具。

研究方法: MUCAR包含两部分数据集：(1) 多语言数据集，通过视觉上下文消解文本歧义；(2) 双歧义数据集，系统地将歧义图像与歧义文本配对，通过相互消歧得到明确解释。研究对19种先进多模态模型进行了广泛评估。

研究结果: 评估显示，现有模型在多语言和跨模态歧义消解任务中表现远低于人类水平，表明当前方法在跨模态理解上仍有不足。

研究结论: MUCAR为多模态歧义消解研究提供了重要基准，揭示了模型与人类表现的差距，未来需开发更先进的跨模态理解方法以提升多模态推理能力。

中文摘要: 多模态大语言模型（MLLMs）在众多视觉语言任务中取得了显著进展。由于其强大的图像-文本对齐能力，MLLMs能够有效理解意义明确的图像-文本对。然而，自然语言和视觉上下文中固有的歧义问题仍难以有效解决。现有多模态基准通常忽略语言和视觉歧义，主要依赖单模态上下文进行消歧，未能充分利用模态间的相互澄清潜力。为填补这一空白，我们提出了MUCAR，一个新颖且具有挑战性的基准，专门用于评估多语言和跨模态场景下的多模态歧义消解能力。MUCAR包括：(1) 一个多语言数据集，其中歧义文本表达通过对应的视觉上下文得到唯一消解；(2) 一个双歧义数据集，系统地将歧义图像与歧义文本配对，每种组合均精心设计以通过相互消歧得到单一明确解释。对19种先进多模态模型（涵盖开源和专有架构）的广泛评估显示，这些模型与人类表现存在显著差距，突显了未来研究需开发更复杂的跨模态歧义理解方法，进一步推动多模态推理的边界。

</details>


### [71] [Simultaneous Translation with Offline Speech and LLM Models in CUNI Submission to IWSLT 2025](https://arxiv.org/abs/2506.17077)
**中文标题：CUNI在IWSLT 2025中的提交：结合离线语音和LLM模型的同步翻译**

*Dominik Macháček,Peter Polák*

主要分类: cs.CL

摘要简述: 本文介绍了查尔斯大学在IWSLT 2025同步语音翻译任务中的提交方案，采用离线Whisper语音模型和AlignAtt策略，结合EuroLLM提升性能，显著优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在提升同步语音翻译任务的性能，特别是在多语言对（如捷克语到英语、英语到德语等）中，通过结合离线语音模型和大语言模型（LLM）优化翻译质量和延迟。

研究方法: 采用离线Whisper语音模型作为核心，结合AlignAtt同步策略，并通过提示注入领域术语和上下文优化。级联系统进一步使用EuroLLM进行无界同步翻译。

研究结果: 与基线相比，捷克语到英语的翻译性能提升2 BLEU分，英语到德语、中文和日语的翻译性能提升13-22 BLEU分。同时提出了一种新的语音识别延迟度量方法。

研究结论: 结合离线语音模型和LLM的同步翻译系统在多语言任务中表现出色，显著优于基线，并提出了改进的延迟度量方法。

中文摘要: 本文描述了查尔斯大学在IWSLT 2025同步语音翻译任务中的提交方案。我们覆盖了所有四种语言对，采用直接或级联方法。系统的核心是离线Whisper语音模型，用于在同步模式下结合AlignAtt策略进行翻译和转录。通过提示注入领域术语和上下文进一步优化性能。级联系统还使用EuroLLM进行无界同步翻译。与组织者的基线相比，我们的系统在捷克语到英语的开发集上提升了2 BLEU分，在英语到德语、中文和日语的开发集上提升了13-22 BLEU分。此外，我们还提出了一种新的语音识别延迟度量方法。

</details>


### [72] [Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs](https://arxiv.org/abs/2506.17080)
**中文标题：Tower+：在多语言大模型中平衡通用性与翻译专业性**

*Ricardo Rei,Nuno M. Guerreiro,José Pombal,João Alves,Pedro Teixeirinha,Amin Farajian,André F. T. Martins*

主要分类: cs.CL

摘要简述: Tower+ 是一套多语言大模型，旨在平衡翻译专业性与通用能力，通过多阶段训练实现高性能，并在多个规模上超越现有大模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有大模型在特定任务（如机器翻译）微调后，往往牺牲通用能力（如对话推理和指令遵循），限制了实际应用中的多功能需求。Tower+ 旨在解决这一问题，实现翻译与通用能力的双重优化。

研究方法: Tower+ 基于 Tower 模型，采用多阶段训练方法：持续预训练、监督微调、偏好优化和基于可验证奖励的强化学习。每个阶段通过精心生成和筛选数据，提升翻译及通用任务（如代码生成、数学问题解决和指令遵循）的性能。

研究结果: Tower+ 在多个规模（2B、9B、72B）上表现优异，小模型超越大型开源和专有模型（如 Llama 3.3 70B、GPT-4o），最大模型在高资源语言翻译和多语言通用评测（如 IF-MT）中达到顶尖水平。

研究结论: Tower+ 证明了大模型可以在保持通用能力的同时，优化特定领域（如翻译和本地化），为实际应用提供了多功能解决方案。

中文摘要: 微调预训练大模型已被证明是实现特定任务（如机器翻译）最先进性能的有效策略。然而，这种适应过程通常意味着牺牲通用能力（如对话推理和指令遵循），从而限制了系统在需要多种技能的实际应用中的实用性。本文介绍了 Tower+，这是一套旨在在翻译和多语言通用文本能力上均表现优异的模型。我们通过一种新颖的训练方法（基于 Tower 模型）实现了翻译专业性与多语言通用能力的帕累托最优，该方法包括持续预训练、监督微调、偏好优化和基于可验证奖励的强化学习。在训练的每个阶段，我们精心生成和筛选数据，以提升翻译及通用任务（如代码生成、数学问题解决和指令遵循）的性能。我们开发了多种规模的模型：2B、9B 和 72B。我们的较小模型通常优于更大的通用开源和专有大模型（如 Llama 3.3 70B、GPT-4o）。我们的最大模型在高资源语言翻译中表现最佳，并在多语言 Arena Hard 评测和我们引入的 IF-MT 基准（用于评估翻译和指令遵循）中取得顶尖成绩。我们的研究结果表明，在优化特定业务领域（如翻译和本地化）的同时，仍有可能在通用能力上与前沿模型竞争。

</details>


### [73] [Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation](https://arxiv.org/abs/2506.17088)
**中文标题：链式思维提示掩盖大语言模型中的幻觉信号：一项实证评估**

*Jiahao Cheng,Tiancheng Su,Jia Yuan,Guoxiu He,Jiawei Liu,Xinqi Tao,Jingwen Xie,Huaxia Li*

主要分类: cs.CL

摘要简述: 研究发现，链式思维（CoT）提示虽然能减少大语言模型（LLM）的幻觉生成，但会掩盖关键检测信号，影响幻觉检测方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）常产生事实错误或语义无关的幻觉内容。链式思维（CoT）提示虽能缓解幻觉，但其对幻觉检测的影响尚未充分研究。本文旨在填补这一空白。

研究方法: 通过系统性实验评估，首先进行初步实验，发现CoT显著影响LLM的内部状态和词元概率分布。随后评估不同CoT提示方法对主流幻觉检测方法的影响，涵盖指令调优和推理导向的LLM，重点关注幻觉分数分布、检测准确率和置信度的变化。

研究结果: 结果显示，CoT提示虽降低幻觉频率，但会掩盖检测信号，削弱多种检测方法的有效性。

研究结论: 研究揭示了推理使用中的潜在权衡，提醒需谨慎平衡幻觉缓解与检测效果。

中文摘要: 大语言模型（LLM）常因提示生成事实错误或语义无关的幻觉内容。链式思维（CoT）提示可通过逐步推理缓解幻觉，但其对幻觉检测的影响尚未充分研究。为此，我们进行了系统性实证评估。初步实验表明，CoT显著影响LLM的内部状态和词元概率分布。在此基础上，我们评估了不同CoT提示方法对主流幻觉检测方法的影响，涵盖指令调优和推理导向的LLM，重点关注幻觉分数分布、检测准确率和置信度的变化。研究发现，尽管CoT提示能减少幻觉频率，但会掩盖关键检测信号，削弱多种检测方法的有效性。本研究揭示了推理使用中被忽视的权衡。代码公开于：https://anonymous.4open.science/r/cot-hallu-detect。

</details>


### [74] [Better Language Model Inversion by Compactly Representing Next-Token Distributions](https://arxiv.org/abs/2506.17090)
**中文标题：通过紧凑表示下一个令牌分布实现更好的语言模型反转**

*Murtaza Nazir,Matthew Finlayson,John X. Morris,Xiang Ren,Swabha Swayamdipta*

主要分类: cs.CL

摘要简述: 本文提出了一种新方法PILS，通过压缩表示语言模型的下一个令牌分布，显著提高了隐藏提示的恢复率，比现有方法高出2-3.5倍。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型反转能力对安全和问责制至关重要，例如从受保护的API模型中泄露系统消息。现有方法恢复率低，需改进。

研究方法: 提出PILS方法，利用语言模型输出的低维特性，通过线性映射无损压缩多步生成的下一个令牌概率分布，从而提升反转效果。

研究结果: PILS在隐藏提示恢复上表现优异，恢复率从17%提升至60%，且在跨步数和跨模型任务中表现出良好的泛化能力。

研究结论: 下一个令牌概率分布是反转攻击的脆弱点，PILS方法显著提升了恢复效果，为模型安全提供了新视角。

中文摘要: 语言模型反转旨在仅通过语言模型输出来恢复隐藏提示，这对语言模型部署的安全性和问责制具有重要意义，例如从受API保护的语言模型系统消息中泄露私有信息。我们提出了一种新方法——基于对数概率序列的提示反转（PILS），该方法通过从模型在多个生成步骤中的下一个令牌概率中提取线索来恢复隐藏提示。我们的方法基于一个关键发现：语言模型的向量值输出占据了一个低维子空间。这使得我们能够通过线性映射无损压缩多个生成步骤中的完整下一个令牌概率分布，从而为反转提供更多输出信息。与之前的最先进方法相比，我们的方法在隐藏提示恢复上取得了巨大提升，测试集上的精确恢复率提高了2-3.5倍，其中一个案例的恢复率从17%提升至60%。我们的方法还表现出令人惊讶的泛化行为；例如，在16个生成步骤上训练的反转器，在测试时将步骤数增加到32时，提示恢复率提高了5-27个百分点。此外，我们在更具挑战性的隐藏系统消息恢复任务上也展示了方法的强大性能。我们还分析了逐字重复在提示恢复中的作用，并提出了一种新的基于对数概率的跨模型反转方法。我们的研究结果表明，下一个令牌概率分布是反转攻击中比以往认知更为脆弱的攻击面。

</details>


### [75] [Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?](https://arxiv.org/abs/2506.17121)
**中文标题：缓存我，如果你能：长上下文语言模型需要多少KV才能高效运行？**

*Adithya Bhaskar,Alexander Wettig,Tianyu Gao,Yihe Dong,Danqi Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种统一的度量标准*KV足迹*，用于评估长上下文语言模型中键值（KV）缓存的效率。研究发现现有方法存在高内存峰值和性能下降问题，并提出改进方法以降低KV足迹。


<details>
  <summary>详细信息</summary>
研究动机: 随着语言模型处理长上下文任务的增加，KV缓存的内存成本显著上升。现有方法在高内存峰值和性能下降方面存在不足，且缺乏统一的比较标准。

研究方法: 提出*KV足迹*作为统一度量标准，评估KV缓存的数量和内存寿命。改进现有方法，使其在预填充阶段支持KV驱逐，并提出PruLong方法优化注意力头的KV缓存需求。

研究结果: 改进后的方法显著降低了KV足迹，PruLong在保持长上下文性能的同时，比现有方法减少了12%的KV足迹。

研究结论: 本文为长上下文推理方法提供了清晰的比较标准，并为未来降低KV足迹的研究奠定了基础。

中文摘要: 语言模型在处理长上下文任务（如书籍摘要）时，键值（KV）缓存的内存成本不断增加。许多先前工作提出了丢弃KV的方法，但这些方法仅适用于特定场景，掩盖了高内存峰值和性能下降等问题，且方法间难以公平比较。本文提出*KV足迹*作为统一度量标准，综合考虑KV存储量和内存寿命。我们评估了在长达128K标记的上下文长度下，保持性能的最小KV足迹。该指标揭示了先前KV驱逐方法的高内存峰值问题。一类方法（*后填充驱逐*）因无法在预填充阶段驱逐KV而导致高足迹。我们改进这些方法以支持预填充阶段的KV驱逐，显著降低了KV足迹。随后，我们研究了*近期驱逐*方法，并提出PruLong，一种端到端优化方法，用于学习哪些注意力头需要保留完整KV缓存。PruLong在保持长上下文性能的同时节省内存，比现有方法减少12%的KV足迹，并在复杂召回任务中保持性能。本文澄清了长上下文推理方法的复杂性，为未来最小化KV足迹的研究铺平了道路。

</details>


### [76] [CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models](https://arxiv.org/abs/2506.17180)
**中文标题：CLEAR-3K：评估语言模型的因果解释能力**

*Naiming Liu,Richard Baraniuk,Shashank Sonkar*

主要分类: cs.CL

摘要简述: CLEAR-3K是一个包含3000个断言-推理问题的数据集，用于评估语言模型是否能判断一个陈述是否因果解释另一个陈述。研究发现，语言模型常混淆语义相似性与因果关系，且模型参数增加时，会从过度怀疑转向过度接受因果关系，但性能提升有限。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型在因果推理能力上存在不足，尤其是在区分语义相关性和真实因果关系方面。CLEAR-3K的提出旨在填补这一空白，为评估和改进语言模型的因果推理能力提供基准。

研究方法: 研究团队构建了CLEAR-3K数据集，包含3000个断言-推理问题，用于测试语言模型区分语义相关性和真实因果关系的能力。通过评估21个不同参数规模（0.5B至72B）的先进语言模型，分析其表现。

研究结果: 研究发现：1）语言模型常依赖词汇和语义重叠，混淆语义相似性与因果关系；2）随着参数规模增加，模型从过度怀疑转向过度接受因果关系，但性能（Matthews相关系数）最高仅为0.55。

研究结论: CLEAR-3K为语言模型的因果推理能力提供了重要基准，揭示了当前模型的局限性，尤其是在区分真实因果关系方面的不足，为未来改进指明了方向。

中文摘要: 我们提出了CLEAR-3K，一个包含3000个断言-推理问题的数据集，旨在评估语言模型是否能判断一个陈述是否因果解释另一个陈述。每个问题提供一个断言-理由对，挑战语言模型区分语义相关性和真实因果解释关系的能力。通过对21个先进语言模型（参数规模从0.5B到72B）的全面评估，我们发现了两个基本结论：首先，语言模型经常混淆语义相似性与因果关系，依赖词汇和语义重叠而非推断真实的因果解释关系；其次，随着参数规模增加，模型倾向于从对因果关系的过度怀疑转向过度接受。尽管如此，性能（以Matthews相关系数衡量）最高仅为0.55，即使对表现最佳的模型也是如此。因此，CLEAR-3K为开发和评估语言模型的真实因果推理能力提供了关键基准，这对需要准确评估因果关系的应用至关重要。

</details>


### [77] [Towards AI Search Paradigm](https://arxiv.org/abs/2506.17188)
**中文标题：迈向AI搜索范式**

*Yuchen Li,Hengyi Cai,Rui Kong,Xinran Chen,Jiamin Chen,Jun Yang,Haojie Zhang,Jiayi Li,Jiayi Wu,Yiqun Chen,Changle Qu,Keyi Kong,Wenwen Ye,Lixin Su,Xinyu Ma,Long Xia,Daiting Shi,Jiashu Zhao,Haoyi Xiong,Shuaiqiang Wang,Dawei Yin*

主要分类: cs.CL

摘要简述: 本文提出了一种名为‘AI搜索范式’的下一代搜索系统蓝图，通过四个LLM驱动的智能体（Master、Planner、Executor和Writer）动态适应从简单查询到复杂推理任务的全方位需求，并协作完成问题分解、工具使用和内容生成。


<details>
  <summary>详细信息</summary>
研究动机: 当前搜索系统在处理复杂信息需求时存在局限性，无法完全模拟人类的信息处理和决策能力。本文旨在提出一种新的AI搜索范式，以开发更可信、自适应且可扩展的搜索系统。

研究方法: 采用模块化架构，包含四个LLM驱动的智能体（Master、Planner、Executor和Writer），通过动态协作完成查询复杂度评估、问题分解、工具使用和内容生成。关键方法包括任务规划、工具集成、执行策略、检索增强生成和高效LLM推理。

研究结果: 提出了一种全面的AI搜索范式，能够动态适应多样化的信息需求，并通过智能体协作实现高效的问题解决和内容生成。

研究结论: 本文为开发可信赖、自适应且可扩展的AI搜索系统提供了基础性指导，展示了模块化智能体架构在下一代搜索系统中的潜力。

中文摘要: 本文介绍了AI搜索范式，这是一种为下一代搜索系统设计的全面蓝图，能够模拟人类信息处理和决策能力。该范式采用模块化架构，包含四个LLM驱动的智能体（Master、Planner、Executor和Writer），动态适应从简单事实查询到复杂多阶段推理任务的全方位信息需求。这些智能体通过协调的工作流程动态协作，评估查询复杂度，将问题分解为可执行计划，并协调工具使用、任务执行和内容生成。我们系统地提出了实现这一范式的关键方法，包括任务规划与工具集成、执行策略、对齐且稳健的检索增强生成以及高效的LLM推理，涵盖算法技术和基础设施级优化。通过深入介绍这些基础组件，本文旨在为开发可信赖、自适应且可扩展的AI搜索系统提供指导。

</details>


### [78] [Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency](https://arxiv.org/abs/2506.17209)
**中文标题：微调降低安全性并破坏评估一致性**

*Kathleen C. Fraser,Hillary Dawkins,Isar Nejadgholi,Svetlana Kiritchenko*

主要分类: cs.CL

摘要简述: 微调通用大语言模型（LLM）会降低安全性并破坏评估一致性，即使微调数据无害。研究发现安全评估结果对实验设置的微小变化极为敏感，呼吁改进结果报告方式。


<details>
  <summary>详细信息</summary>
研究动机: 微调已成为用户定制LLM的常规操作，但会移除模型的安全对齐特性，即使数据无害。这一问题可能被恶意利用，而开发者往往不知情。需建立可靠的安全评估方法以解决此问题。

研究方法: 研究探讨安全评估对实验设置微小变化的鲁棒性，通过实验观察微调设置对评估结果的显著影响。

研究结果: 实验显示安全评估结果对微调设置的微小变化极为敏感，导致结果不一致，影响未来研究的可比性。

研究结论: 微调会显著降低LLM安全性，且安全评估结果易受实验设置影响。需改进结果报告方式以支持未来研究。

中文摘要: 微调通用大语言模型（LLM）以适应特定领域或任务已成为普通用户的常规操作。然而，微调会移除模型的安全对齐特性，即使微调数据不包含任何有害内容。我们认为这是LLM的一个关键失效模式，因为微调广泛普及且攻击方式看似无害。大多数善意的开发者可能并未意识到他们部署的LLM安全性已降低。另一方面，这一已知漏洞可被恶意行为者轻易利用以绕过安全防护。为解决此问题，首先需要可靠且可复现的安全评估方法。本研究探讨安全评估对实验设置微小变化及LLM随机性的鲁棒性。初步实验显示，即使对微调设置进行看似无关紧要的改动，安全评估结果也会出现显著差异。这些观察结果对研究人员未来如何报告结果以支持有意义的比较具有重要启示。

</details>


### [79] [LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles](https://arxiv.org/abs/2506.06561)
**中文标题：LaMP-Cap：基于多模态图表档案的个性化图表标题生成**

*Ho Yin 'Sam' Ng,Ting-Yao Hsu,Aashish Anantha Ramakrishnan,Branislav Kveton,Nedim Lipka,Franck Dernoncourt,Dongwon Lee,Tong Yu,Sungchul Kim,Ryan A. Rossi,Ting-Hao 'Kenneth' Huang*

主要分类: cs.CL

摘要简述: 本文提出LaMP-Cap数据集，用于个性化生成图表标题，通过多模态图表档案提升标题生成质量，实验表明多模态信息比纯文本更有效。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI生成的图表标题多为通用型，需作者手动调整以符合个人风格和领域要求，突显个性化需求。然而，现有语言模型个性化技术多局限于纯文本场景，缺乏多模态输入和档案的支持。

研究方法: LaMP-Cap数据集为每张目标图表提供多模态档案，包括图像、标题及相关段落。通过四种大型语言模型实验，验证多模态档案对生成个性化标题的帮助。

研究结果: 实验表明，使用档案信息能显著提升标题与作者原稿的相似度，且图像比段落更具帮助，证实多模态档案优于纯文本。

研究结论: LaMP-Cap展示了多模态档案在个性化图表标题生成中的优势，为未来研究提供了新方向。

中文摘要: 图表标题对读者理解和记忆图表关键信息至关重要。虽然已有许多模型用于生成标题，帮助作者更轻松地撰写高质量标题，但作者仍需调整通用AI生成的标题以匹配其写作风格和领域要求，突显个性化需求。尽管语言模型个性化（LaMP）技术有所进展，但这些技术多聚焦于纯文本场景，鲜少涉及多模态输入和档案的场景。本文提出LaMP-Cap数据集，用于个性化图表标题生成，每张目标图表不仅提供所需输入（如图像），还包括同一文档中最多三张其他图表（每张包含图像、标题及提及段）作为档案以表征上下文。通过四种大型语言模型实验，发现使用档案信息能持续生成更接近作者原稿的标题。消融研究表明，档案中的图像比提及段落更有帮助，突显多模态档案优于纯文本的优势。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [80] [A Strong View-Free Baseline Approach for Single-View Image Guided Point Cloud Completion](https://arxiv.org/abs/2506.15747)
**中文标题：一种无需视角的强基线方法：单视角图像引导点云补全**

*Fangzhou Lin,Zilin Dai,Rigved Sanku,Songlin Hou,Kazunori D Yamada,Haichong K. Zhang,Ziming Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需图像引导的强基线方法，用于单视角图像引导的点云补全任务，通过注意力机制和多分支编码器-解码器网络，仅使用部分点云输入即可实现高效补全。


<details>
  <summary>详细信息</summary>
研究动机: 尽管现有研究证明了多模态方法在单视角图像引导点云补全（SVIPC）中的有效性，但图像引导的必要性尚未深入探讨。本文旨在探索一种无需图像引导的强基线方法，以验证其可行性。

研究方法: 提出了一种基于注意力机制的多分支编码器-解码器网络，仅输入部分点云，无需图像引导。通过跨注意力和自注意力层驱动的分层自融合机制，有效整合多流信息，增强几何结构捕捉能力。

研究结果: 在ShapeNet-ViPC数据集上的实验表明，该方法性能优于当前最先进的SVIPC方法，验证了无需图像引导的可行性。

研究结论: 本文为SVIPC任务提供了一种无需图像引导的强基线方法，为多模态学习的发展提供了新视角。

中文摘要: 单视角图像引导点云补全（SVIPC）任务旨在通过单视角图像的辅助，从部分输入点云重建完整的点云。尽管先前研究证明了这种多模态方法的有效性，但图像引导的必要性尚未得到充分探讨。为此，我们提出了一种基于注意力机制的多分支编码器-解码器网络的强基线方法，该方法仅输入部分点云，无需视角信息。通过跨注意力和自注意力层驱动的分层自融合机制，有效整合多流信息，丰富特征表示并增强网络对几何结构的捕捉能力。在ShapeNet-ViPC数据集上的大量实验和消融研究表明，我们的无需视角框架性能优于当前最先进的SVIPC方法。我们希望这些发现能为SVIPC中多模态学习的发展提供新见解。演示代码将在https://github.com/Zhang-VISLab上提供。

</details>


### [81] [VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service](https://arxiv.org/abs/2506.15755)
**中文标题：VLMInferSlow：评估大型视觉语言模型作为服务的效率鲁棒性**

*Xiasi Wang,Tianliang Yao,Simin Chen,Runqi Wang,Lei YE,Kuofeng Gao,Yi Huang,Yuan Yao*

主要分类: cs.CV

摘要简述: 本文提出VLMInferSlow方法，用于在现实黑盒设置下评估视觉语言模型（VLM）的效率鲁棒性，通过生成对抗性图像显著增加计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要关注视觉语言模型（VLM）的准确性，而效率鲁棒性被忽视。许多实时应用对效率要求高，但现有评估方法基于不现实的假设（需访问模型架构和参数），无法适用于ML-as-a-service场景。

研究方法: 提出VLMInferSlow方法，结合细粒度效率建模和零阶优化技术，在无需访问模型内部的情况下生成对抗性图像，以测试VLM的效率鲁棒性。

研究结果: 实验表明，VLMInferSlow生成的对抗性图像虽扰动微小，但能将计算成本最高提升128.47%。

研究结论: 本研究填补了VLM效率鲁棒性评估的空白，呼吁社区关注VLM在实际应用中的效率问题。

中文摘要: 视觉语言模型（VLM）在现实应用中展现出巨大潜力。现有研究主要集中于提升其准确性，而效率问题尚未充分探索。鉴于许多应用对实时性的需求以及VLM的高推理开销，效率鲁棒性成为关键问题。然而，先前研究在不现实的假设下评估效率鲁棒性，要求访问模型架构和参数——这在ML-as-a-service场景中不切实际，因为VLM通常通过推理API部署。为填补这一空白，我们提出VLMInferSlow，一种在现实黑盒设置下评估VLM效率鲁棒性的新方法。VLMInferSlow结合了针对VLM推理的细粒度效率建模，并利用零阶优化技术搜索对抗样本。实验结果表明，VLMInferSlow生成的对抗性图像虽扰动微小，但能将计算成本最高提升128.47%。我们希望这项研究能提高社区对VLM效率鲁棒性的关注。

</details>


### [82] [Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation](https://arxiv.org/abs/2506.15757)
**中文标题：弱监督VLM引导的部分对比学习用于视觉语言导航**

*Ruoyu Wang,Tong Yu,Junda Wu,Yao Liu,Julian McAuley,Lina Yao*

主要分类: cs.CV

摘要简述: 本文提出了一种弱监督的VLM引导部分对比学习方法（WPCL），用于提升视觉语言导航任务中代理的动态视角对象识别能力，无需微调预训练模型，显著提升了性能与计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉语言导航方法依赖预训练模型，但面临动态视角适应性差、领域知识缺失及计算成本高的问题。本文旨在解决这些挑战，提升代理的导航能力。

研究方法: 提出弱监督部分对比学习（WPCL），通过有效整合预训练VLM知识，增强代理在动态视角下的对象识别能力，同时避免微调带来的高计算成本。

研究结果: 实验表明，WPCL在多个基准测试中优于基线方法，验证了其有效性、鲁棒性和泛化性。

研究结论: WPCL方法在无需微调预训练模型的情况下，显著提升了视觉语言导航的性能和效率，为领域提供了新的解决方案。

中文摘要: 视觉语言导航（VLN）是具身AI领域的一项基本任务，关注代理基于自然语言指令在复杂环境中导航的能力。尽管现有方法取得了一定进展，但仍面临一些共同挑战：首先，它们依赖预训练骨干模型进行视觉感知，难以适应VLN场景中的动态视角；其次，使用未经微调的预训练LLMs或VLMs时性能受限，因其缺乏VLN领域知识；第三，微调LLMs和VLMs虽能提升结果，但计算成本较高。为解决这些问题，我们提出弱监督部分对比学习（WPCL），该方法通过有效整合预训练VLM知识到感知过程中，无需微调VLM，即可增强代理在动态视角下识别对象的能力。我们的方法提升了代理对环境线索的解读与响应能力，同时确保计算效率。实验结果表明，WPCL在多个基准测试中优于基线方法，验证了其有效性、鲁棒性和泛化性。

</details>


### [83] [Implicit 3D scene reconstruction using deep learning towards efficient collision understanding in autonomous driving](https://arxiv.org/abs/2506.15806)
**中文标题：基于深度学习的隐式3D场景重建：面向自动驾驶中高效碰撞理解**

*Akarshani Ramanayake,Nihal Kodikara*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的隐式3D场景重建方法，利用LiDAR数据和深度神经网络构建静态符号距离函数（SDF）地图，以提升自动驾驶中碰撞检测的性能，尤其在拥挤和动态环境中。


<details>
  <summary>详细信息</summary>
研究动机: 在拥挤的城市交通环境中，现有技术难以实现精确导航，而3D场景重建对于自动驾驶车辆安全评估周围障碍物至关重要。然而，现有文献中高边界精度的3D物体形状重建尚未完全解决。符号距离函数（SDF）因其高效的存储特性成为潜在解决方案。

研究方法: 本研究提出了一种基于深度学习的方法，结合LiDAR数据和深度神经网络，构建静态符号距离函数（SDF）地图，以替代传统的多边形表示，从而更精确地重建3D障碍物形状。

研究结果: 初步结果表明，该方法能够显著提升碰撞检测性能，尤其是在拥挤和动态环境中，展示了其在自动驾驶领域的应用潜力。

研究结论: 通过隐式3D重建方法，本研究为自动驾驶中的高效碰撞理解提供了新思路，未来有望进一步优化复杂环境下的导航安全性。

中文摘要: 在交通密集的拥挤城市环境中，现有技术难以实现精确导航，而自动驾驶车辆通过表面级理解可以安全评估周围障碍物的距离。3D或2D场景映射是解决上述问题的关键任务。尽管在密集交通条件下具有重要意义，但现有文献尚未完全考虑高边界精度的3D物体形状重建。符号距离函数（SDF）通过参数表示任何形状，计算空间中任意点到最近障碍物表面的距离，从而在存储效率上更具优势。近期研究中，研究人员开始在自动驾驶领域探索隐式3D重建方法，突显了利用SDF高效映射障碍物的可能性。本研究填补了这一空白，提出了一种基于学习的3D场景重建方法，利用LiDAR数据和深度神经网络构建静态SDF地图。与传统多边形表示不同，该方法能够以更高边界精度映射3D障碍物形状。初步结果表明，该方法可显著提升碰撞检测性能，尤其在拥挤和动态环境中。

</details>


### [84] [ADAM-Dehaze: Adaptive Density-Aware Multi-Stage Dehazing for Improved Object Detection in Foggy Conditions](https://arxiv.org/abs/2506.15837)
**中文标题：ADAM-Dehaze：基于自适应密度感知的多阶段去雾方法以改善雾天条件下的目标检测**

*Fatmah AlHindaassi,Mohammed Talha Alam,Fakhri Karray*

主要分类: cs.CV

摘要简述: ADAM-Dehaze是一种自适应密度感知的多阶段去雾框架，通过动态路由和自适应损失优化图像恢复与目标检测，显著提升雾天条件下的视觉任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 雾天等恶劣天气条件严重影响了自动驾驶、监控系统等安全关键应用的视觉信息质量，亟需一种能够适应不同雾密度并优化下游视觉任务的去雾方法。

研究方法: ADAM-Dehaze通过轻量级雾密度估计网络（HDEN）将输入图像分类为轻、中或重雾，并动态路由至相应的CORUN分支处理。采用自适应损失平衡物理模型一致性和感知保真度。

研究结果: 在Cityscapes和RTTS基准测试中，ADAM-Dehaze将PSNR提升2.1 dB，FADE降低30%，目标检测mAP提高13点，推理时间减少20%。

研究结论: ADAM-Dehaze证明了雾密度特异性处理和与下游视觉任务无缝集成的重要性，为恶劣天气条件下的视觉任务提供了高效解决方案。

中文摘要: 恶劣天气条件（尤其是雾）严重影响了自动驾驶、监控系统等安全关键应用的视觉信息质量。本文提出ADAM-Dehaze，一种自适应密度感知的去雾框架，联合优化图像恢复和目标检测以应对不同雾密度。通过轻量级雾密度估计网络（HDEN）将输入图像分类为轻、中或重雾，并动态路由至相应的CORUN分支处理。新型自适应损失平衡物理模型一致性和感知保真度，确保去雾准确性和细节保留。在Cityscapes和真实世界RTTS基准测试中，ADAM-Dehaze将PSNR提升2.1 dB，FADE降低30%，目标检测mAP提高13点，同时减少20%推理时间。这些结果凸显了雾密度特异性处理与下游视觉任务无缝集成的重要性。代码详见：https://github.com/talha-alam/ADAM-Dehaze。

</details>


### [85] [EchoShot: Multi-Shot Portrait Video Generation](https://arxiv.org/abs/2506.15838)
**中文标题：EchoShot：多镜头肖像视频生成**

*Jiahao Wang,Hualian Sheng,Sijia Cai,Weizhan Zhang,Caixia Yan,Yachuang Feng,Bing Deng,Jieping Ye*

主要分类: cs.CV

摘要简述: 本文提出EchoShot，一种基于视频扩散模型的多镜头肖像视频生成框架，通过创新的位置嵌入机制和高质量数据集PortraitGala，实现了身份一致性和内容可控性。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频扩散模型主要局限于单镜头生成，而实际应用需要多镜头且身份一致的视频。EchoShot旨在解决这一问题，提供灵活的内容控制和多镜头生成能力。

研究方法: 提出基于视频扩散变换器的镜头感知位置嵌入机制，建模镜头间变化并关联多镜头内容与文本描述；构建高质量数据集PortraitGala；支持基于参考图像的个性化生成和无限镜头的长视频合成。

研究结果: EchoShot在多镜头肖像视频生成中表现出卓越的身份一致性和属性级可控性，验证了其作为通用多镜头视频建模基础范式的潜力。

研究结论: EchoShot为多镜头视频生成提供了高效且可扩展的解决方案，展示了其在艺术创作和实际应用中的广泛前景。

中文摘要: 视频扩散模型通过高质量的肖像视频生成能力显著提升了艺术工作流的效率。然而，现有方法主要局限于单镜头生成，而实际应用需要多镜头且身份一致的视频。本文提出EchoShot，一种基于基础视频扩散模型的多镜头肖像定制框架。首先，我们在视频扩散变换器架构中引入镜头感知位置嵌入机制，建模镜头间变化并建立多镜头视觉内容与文本描述的复杂关联。这一简单而高效的设计支持直接在多镜头视频数据上训练，无需额外计算开销。为支持多镜头场景下的模型训练，我们构建了PortraitGala，一个大规模、高保真的人为中心视频数据集，具有跨镜头身份一致性和细粒度标注（如面部属性、服装和动态动作）。为进一步提升适用性，我们将EchoShot扩展为基于参考图像的个性化多镜头生成和无限镜头的长视频合成。大量实验表明，EchoShot在多镜头肖像视频生成中实现了卓越的身份一致性和属性级可控性。值得注意的是，该框架展示了作为通用多镜头视频建模基础范式的潜力。

</details>


### [86] [Assessing the impact of Binarization for Writer Identification in Greek Papyrus](https://arxiv.org/abs/2506.15852)
**中文标题：评估二值化对希腊纸莎草文献作者识别的影响**

*Dominic Akt,Marco Peer,Florian Kleber*

主要分类: cs.CV

摘要简述: 本文研究希腊纸莎草文献的作者识别任务，重点探讨二值化预处理对识别性能的影响。通过比较传统二值化方法与深度学习模型，发现数据增强对深度学习方法尤为重要，且二值化效果与作者识别性能密切相关。


<details>
  <summary>详细信息</summary>
研究动机: 希腊纸莎草文献的背景通常不均匀、破损且变色，传统二值化方法难以处理。本文旨在评估二值化质量对作者识别任务的影响，并探索深度学习模型在此任务中的表现。

研究方法: 比较传统二值化方法与深度学习模型，使用自定义数据增强技术和不同模型选择标准。在DIBCO 2019数据集上系统评估二值化方法，并进一步分析其对作者识别性能的影响。

研究结果: 研究发现数据增强对深度学习方法至关重要，且二值化效果与下游作者识别性能存在显著相关性。

研究结论: 二值化预处理对希腊纸莎草文献的作者识别任务具有重要影响，深度学习模型结合数据增强可显著提升性能。

中文摘要: 本文研究希腊纸莎草文献的作者识别任务。作者识别流程中常见的预处理步骤是图像二值化，以防止模型学习背景特征。然而，历史文献（如希腊纸莎草）的背景通常不均匀、破损且变色，纤维结构明显，这为二值化带来了挑战。我们比较了传统二值化方法与最先进的深度学习（DL）模型，评估二值化质量对后续作者识别性能的影响。深度学习模型在训练时采用了自定义数据增强技术，并应用了不同的模型选择标准。这些二值化方法在DIBCO 2019数据集上进行了系统评估，随后使用最先进的作者识别方法分析二值化对识别性能的影响。分析结果表明，数据增强对深度学习方法具有显著影响。此外，研究发现DIBCO 2019数据集上的二值化效果与下游作者识别性能存在强相关性。

</details>


### [87] [Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation](https://arxiv.org/abs/2506.15854)
**中文标题：通过视觉到文本转换实现联网与自动驾驶车辆的隐私保护**

*Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy*

主要分类: cs.CV

摘要简述: 本文提出了一种通过视觉到文本转换保护联网与自动驾驶车辆隐私的新框架，利用反馈强化学习和视觉语言模型将图像转换为语义等效的文本，显著提升了隐私保护和文本质量。


<details>
  <summary>详细信息</summary>
研究动机: 联网与自动驾驶车辆（CAVs）依赖的设备常处理隐私敏感数据，尤其是配备AI的路边摄像头可能引发隐私泄露风险。传统方法如模糊处理无法完全保护隐私，亟需更有效的解决方案。

研究方法: 采用反馈强化学习（RL）和视觉语言模型（VLMs），将图像转换为语义等效的文本描述，并通过分层RL策略迭代优化文本，兼顾语义准确性和隐私保护。

研究结果: 评估结果显示，该方法在隐私保护和文本质量上显著优于现有技术，独特词数量提升约77%，细节密度提高约50%。

研究结论: 该框架为CAVs提供了一种高效隐私保护方案，通过视觉到文本转换平衡了信息保留与隐私安全，具有实际应用潜力。

中文摘要: 联网与自动驾驶车辆（CAVs）依赖的设备常处理隐私敏感数据，其中配备AI的路边摄像头在违规检测等应用中尤为关键。然而，图像捕获带来的隐私风险（如身份盗用、画像或商业滥用）仍是主要问题。传统方法（如人脸模糊）无法完全保护隐私，因其他特征（如衣着）仍可被用于追踪。本文提出了一种新型隐私保护框架，结合反馈强化学习（RL）和视觉语言模型（VLMs），将图像转换为语义等效的文本描述，保留场景信息的同时保护视觉隐私。通过分层RL策略迭代优化文本，提升语义准确性和隐私性。评估结果表明，该方法在隐私保护和文本质量上显著优于现有技术，独特词数量增加约77%，细节密度提升约50%。

</details>


### [88] [Visual symbolic mechanisms: Emergent symbol processing in vision language models](https://arxiv.org/abs/2506.15871)
**中文标题：视觉符号机制：视觉语言模型中的符号处理涌现**

*Rim Assouel,Declan Campbell,Taylor Webb*

主要分类: cs.CV

摘要简述: 本文发现视觉语言模型（VLMs）通过内容无关的空间索引机制实现符号化处理，并揭示了其绑定错误的根源。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索视觉语言模型是否采用类似语言模型的符号化机制解决绑定问题，尤其是针对其在此类任务中的持续失败。

研究方法: 通过分析VLMs的内容无关空间索引机制，识别支持绑定的符号化机制，并追踪绑定错误的来源。

研究结果: 研究发现VLMs通过空间索引实现符号化处理，绑定错误源于这些机制的失效。

研究结论: 结论表明VLMs的符号化处理机制为改进其绑定能力提供了潜在方向。

中文摘要: 为了准确处理视觉场景，观察者需要将特征绑定以表示单个对象。例如，区分包含红色方块和蓝色圆圈的图像与包含蓝色方块和红色圆圈的图像需要这种能力。最近的研究发现，语言模型通过一组类似符号、内容无关的索引解决这一“绑定问题”，但尚不清楚视觉语言模型（VLMs）是否采用类似机制。鉴于VLMs在需要绑定的任务中持续失败，这一问题尤为重要。本文识别了一组支持VLMs绑定的涌现符号机制，其通过内容无关的空间索引方案实现。此外，我们发现绑定错误可直接归因于这些机制的失效。这些结果揭示了VLMs中符号化处理的机制，并为解决这些模型的持续绑定失败提供了可能途径。

</details>


### [89] [Pediatric Pancreas Segmentation from MRI Scans with Deep Learning](https://arxiv.org/abs/2506.15908)
**中文标题：基于深度学习的儿童MRI胰腺分割**

*Elif Keles,Merve Yazol,Gorkem Durak,Ziliang Hong,Halil Ertugrul Aktas,Zheyuan Zhang,Linkai Peng,Onkar Susladkar,Necati Guzelyel,Oznur Leman Boyunaga,Cemal Yazici,Mark Lowe,Aliye Uc,Ulas Bagci*

主要分类: cs.CV

摘要简述: 本研究验证了PanSegNet深度学习算法在儿童MRI胰腺分割中的表现，结果显示其在健康和疾病状态下均达到专家水平，为儿科胰腺影像提供了无辐射的可靠工具。


<details>
  <summary>详细信息</summary>
研究动机: 儿科胰腺影像研究领域缺乏可靠的无辐射分割工具，本研究旨在填补这一空白，为急性胰腺炎（AP）和慢性胰腺炎（CP）患儿及健康儿童提供高质量的MRI胰腺分割解决方案。

研究方法: 研究回顾性收集了84例2-19岁儿童的MRI扫描数据，包括健康儿童及AP/CP患者。由儿科和普通放射科医师手动分割胰腺，并由资深儿科放射科医师确认。使用PanSegNet算法生成分割结果，并通过Dice相似系数（DSC）和95百分位Hausdorff距离（HD95）评估性能，同时计算观察者间和观察者内一致性。

研究结果: PanSegNet在健康儿童中的DSC得分为88%，AP和CP患者中分别为81%和80%；HD95值在健康儿童中为3.98 mm，AP和CP中分别为9.85 mm和15.67 mm。观察者间一致性kappa值为0.86（健康）和0.82（胰腺炎），观察者内一致性为0.88和0.81。自动与手动分割体积相关性高（R²=0.85健康，0.77疾病）。

研究结论: PanSegNet是首个经过验证的深度学习胰腺MRI分割工具，在健康和疾病状态下均表现优异。该算法及标注数据集已开源，推动了无辐射儿科胰腺影像的发展，并为该领域的研究合作提供了支持。

中文摘要: 目的：本研究旨在评估和验证PanSegNet深度学习算法在儿童急性胰腺炎（AP）、慢性胰腺炎（CP）及健康对照者MRI胰腺分割中的应用。方法：经伦理委员会批准，回顾性收集了2015-2024年间84例2-19岁儿童的MRI扫描数据（1.5T/3T Siemens Aera/Verio），包括健康儿童及AP/CP患者。由儿科和普通放射科医师手动分割胰腺，并由资深儿科放射科医师确认。PanSegNet生成的分割结果通过Dice相似系数（DSC）和95百分位Hausdorff距离（HD95）评估，同时计算观察者间一致性（Cohen's kappa）。结果：42例AP/CP患儿（平均年龄11.73±3.9岁）和42例健康儿童（平均年龄11.19±4.88岁）的T2W MRI扫描显示，PanSegNet的DSC得分在健康儿童中为88%，AP和CP中分别为81%和80%；HD95值分别为3.98 mm（健康）、9.85 mm（AP）和15.67 mm（CP）。观察者间一致性kappa值为0.86（健康）和0.82（胰腺炎），观察者内一致性为0.88和0.81。自动与手动分割体积相关性高（R²=0.85健康，0.77疾病）。结论：PanSegNet是首个经过验证的深度学习胰腺MRI分割工具，在健康和疾病状态下均达到专家水平。该算法及标注数据集已开源，推动了无辐射儿科胰腺影像的发展，并为该领域的研究合作提供了支持。

</details>


### [90] [MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior](https://arxiv.org/abs/2506.15929)
**中文标题：MoiréXNet：基于线性注意力测试时训练与截断流匹配先验的自适应多尺度去摩尔纹方法**

*Liangyan Li,Yimo Ning,Kevin Le,Wei Dong,Yunzhe Li,Jun Chen,Xiaohong Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种结合最大后验估计与深度学习的图像和视频去摩尔纹框架，通过线性注意力测试时训练和截断流匹配先验，显著提升了非线性退化过程的恢复效果。


<details>
  <summary>详细信息</summary>
研究动机: 传统监督学习方法在去摩尔纹任务中表现不佳，要么无法完全去除摩尔纹，要么导致图像过度平滑。生成模型虽在线性退化恢复中表现优异，但在非线性退化（如去摩尔纹）中容易引入伪影。因此，需要一种结合监督学习与生成模型优势的混合框架。

研究方法: 提出了一种混合最大后验估计框架，包含两部分：1) 结合线性注意力测试时训练模块的监督学习模型，直接学习RAW到sRGB的非线性映射；2) 截断流匹配先验，通过对齐干净图像分布进一步优化输出，恢复高频细节并抑制伪影。

研究结果: 该方法在去摩尔纹任务中表现出色，结合了线性注意力的计算效率与生成模型的优化能力，显著提升了图像恢复质量。

研究结论: 通过整合监督学习与生成模型的优势，本文提出的框架有效解决了非线性退化问题，为图像和视频去摩尔纹提供了高性能解决方案。

中文摘要: 本文提出了一种新颖的图像和视频去摩尔纹框架，通过将最大后验估计（MAP）与先进的深度学习技术相结合，解决了非线性退化过程带来的挑战。传统监督学习方法要么无法完全去除摩尔纹，要么导致图像过度平滑，这源于模型能力受限和训练数据稀缺。生成模型虽在线性退化恢复中表现优异，但在非线性退化（如去摩尔纹）中容易引入伪影。为解决这些问题，我们提出了一种混合MAP框架，包含两部分：1) 结合高效线性注意力测试时训练（TTT）模块的监督学习模型，直接学习RAW到sRGB的非线性映射；2) 截断流匹配先验（TFMP），通过对齐干净图像分布进一步优化输出，恢复高频细节并抑制伪影。这两部分结合了线性注意力的计算效率与生成模型的优化能力，显著提升了恢复性能。

</details>


### [91] [Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization](https://arxiv.org/abs/2506.15937)
**中文标题：超越音频与姿态：一种通用视频同步框架**

*Yosub Shin,Igor Molybog*

主要分类: cs.CV

摘要简述: 本文提出了一种名为VideoSync的通用视频同步框架，不依赖特定特征提取方法（如音频或姿态），适用于多样化场景。通过新数据集和严格评估，VideoSync在公平条件下优于现有方法，并揭示了先前研究的偏差。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频同步方法过度依赖音频或特定视觉事件，限制了在信号不可靠或缺失场景中的应用。此外，现有基准测试缺乏通用性和可复现性，阻碍了领域发展。

研究方法: 提出VideoSync框架，不依赖特定特征提取方法，支持多样化内容类型。构建新数据集（单人多人和非人类场景），提供数据集创建方法和代码，确保基准可复现。修正SeSyn-Net预处理偏差，提出更严格的评估框架。

研究结果: VideoSync在公平条件下优于现有方法（包括SeSyn-Net）。卷积神经网络（CNN）在同步偏移预测中表现最佳。

研究结论: VideoSync突破了领域限制，提升了视频同步的通用性和鲁棒性，适用于实际应用。

中文摘要: 视频同步——对齐从不同角度捕捉同一事件的多条视频流——对真人秀制作、体育分析、监控和自主系统等应用至关重要。先前工作主要依赖音频线索或特定视觉事件，限制了在信号不可靠或缺失的多样化场景中的适用性。此外，现有视频同步基准缺乏通用性和可复现性，阻碍了领域发展。本文提出VideoSync，一种不依赖特定特征提取方法（如人体姿态估计）的视频同步框架，适用于多样化内容类型。我们在新构建的数据集（涵盖单人、多人和非人类场景）上评估系统，并提供数据集创建方法和代码以建立可复现基准。分析揭示了先前SOTA研究（尤其是SeSyn-Net预处理流程）的偏差，导致性能虚高。我们修正这些偏差并提出更严格的评估框架，证明VideoSync在公平实验条件下优于现有方法（包括SeSyn-Net）。此外，我们探索了多种同步偏移预测方法，发现基于卷积神经网络（CNN）的模型最为有效。本研究推动了视频同步超越领域限制，使其更具通用性和鲁棒性，适用于实际应用。

</details>


### [92] [Polyline Path Masked Attention for Vision Transformer](https://arxiv.org/abs/2506.15940)
**中文标题：折线路径掩码注意力机制在视觉Transformer中的应用**

*Zhongchen Zhao,Chaodong Xiao,Hui Lin,Qi Xie,Lei Zhang,Deyu Meng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Polyline Path Masked Attention (PPMA)的方法，结合了Vision Transformer的自注意力机制和Mamba2的结构化掩码，通过改进的2D折线路径扫描策略增强空间邻接关系建模，在图像分类、目标检测和分割任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度学习框架中，全局依赖建模和空间位置建模是核心问题。Vision Transformers通过自注意力机制在计算机视觉中表现出色，而Mamba2通过结构化掩码在自然语言处理中展现了潜力。本文旨在结合两者的优势，提出一种更高效的建模方法。

研究方法: 本文改进了Mamba2的传统结构化掩码，引入2D折线路径扫描策略，生成折线路径掩码以更好地保留图像标记的邻接关系。通过理论分析掩码结构特征，设计高效计算算法，并将其嵌入Vision Transformer的自注意力机制中，显式建模空间邻接先验。

研究结果: 在标准基准测试中，PPMA在图像分类、目标检测和分割任务中表现优异。例如，PPMA-T/S/B模型在ADE20K语义分割任务中分别达到48.7%/51.1%/52.3%的mIoU，优于RMT-T/S/B模型。

研究结论: PPMA结合了Vision Transformer和Mamba2的优势，通过改进的折线路径掩码显式建模空间邻接关系，显著提升了性能，为计算机视觉任务提供了一种高效的新方法。

中文摘要: 全局依赖建模和空间位置建模是当前深度学习框架基础架构设计的两个核心问题。近年来，视觉Transformer（ViTs）利用自注意力机制的强大全局依赖建模能力，在计算机视觉领域取得了显著成功。此外，Mamba2通过结构化掩码显式建模空间邻接先验，在自然语言处理任务中展现了巨大潜力。本文提出折线路径掩码注意力（PPMA），将ViTs的自注意力机制与Mamba2的增强结构化掩码相结合，发挥两者的互补优势。具体而言，我们首先通过引入2D折线路径扫描策略改进Mamba2的传统结构化掩码，并推导出其对应的结构化掩码——折线路径掩码，以更好地保留图像标记的邻接关系。值得注意的是，我们对提出的折线路径掩码的结构特性进行了深入的理论分析，并设计了一种高效的计算算法。接着，我们将折线路径掩码嵌入ViTs的自注意力机制中，实现空间邻接先验的显式建模。在图像分类、目标检测和分割等标准基准测试中，大量实验表明，我们的模型优于基于状态空间模型和Transformer的先前最先进方法。例如，我们提出的PPMA-T/S/B模型在ADE20K语义分割任务中分别达到48.7%/51.1%/52.3%的mIoU，比RMT-T/S/B分别高出0.7%/1.3%/0.3%。代码已发布于https://github.com/zhongchenzhao/PPMA。

</details>


### [93] [Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging](https://arxiv.org/abs/2506.15971)
**中文标题：异构模态无监督域适应：基于潜在空间桥接的方法**

*Jiawen Yang,Shuhao Chen,Yucong Duan,Ke Tang,Yu Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为HMUDA的新设置，通过潜在空间桥接（LSB）框架解决异构模态无监督域适应问题，实现了不同模态间的知识迁移。


<details>
  <summary>详细信息</summary>
研究动机: 传统无监督域适应方法在源域和目标域模态完全不同的情况下效果不佳，因此需要一种新方法来处理异构模态间的知识迁移问题。

研究方法: 提出了潜在空间桥接（LSB）框架，采用双分支结构，结合特征一致性损失和域对齐损失，以对齐不同模态的表示并减少域间类中心差异。

研究结果: 在六个基准数据集上的实验表明，LSB框架实现了最先进的性能。

研究结论: LSB框架有效解决了异构模态无监督域适应问题，为跨模态知识迁移提供了新思路。

中文摘要: 无监督域适应（UDA）方法能有效弥合域间差距，但当源域和目标域属于完全不同的模态时，其效果受限。为解决这一问题，我们提出了一种名为异构模态无监督域适应（HMUDA）的新设置，通过利用包含两种模态未标记样本的桥接域，实现完全不同模态间的知识迁移。为在HMUDA设置下学习，我们提出了潜在空间桥接（LSB）框架，专为语义分割任务设计。具体而言，LSB采用双分支结构，结合特征一致性损失对齐跨模态表示，以及域对齐损失减少域间类中心差异。在六个基准数据集上的大量实验表明，LSB实现了最先进的性能。

</details>


### [94] [LBMamba: Locally Bi-directional Mamba](https://arxiv.org/abs/2506.15976)
**中文标题：LBMamba：局部双向Mamba**

*Jingwei Zhang,Xi Han,Hong Qin,Mahdi S. Hosseini,Dimitris Samaras*

主要分类: cs.CV

摘要简述: LBMamba是一种局部双向状态空间模型（SSM），通过在正向选择性扫描中嵌入轻量级局部反向扫描，避免了传统双向扫描的计算负担，提升了效率。基于LBMamba的LBVim视觉骨干网络在多个任务中表现出优越的性能-吞吐量平衡。


<details>
  <summary>详细信息</summary>
研究动机: Mamba作为一种高效的状态空间模型，因其单向性限制了信息获取范围。现有方法通过全局双向扫描解决这一问题，但计算负担翻倍，削弱了Mamba的效率优势。本文旨在设计一种局部双向扫描方法，避免额外计算开销。

研究方法: 提出LBMamba，在正向选择性扫描中嵌入轻量级局部反向扫描，完全在每线程寄存器中执行。基于此构建LBVim视觉骨干网络，通过每两层交替扫描方向恢复全局感受野，无需额外反向扫描。

研究结果: 在ImageNet-1K分类任务中，LBVim在相同吞吐量下Top-1准确率提升0.8%至1.6%；ADE20K语义分割任务中mIoU提升0.6%至2.7%；COCO检测任务中APb和APm分别提升0.9%和1.1%。在病理学MIL任务中，AUC、F1和准确率分别提升3.06%、3.39%和1.67%。

研究结论: LBMamba通过局部双向扫描有效解决了Mamba的单向性限制，同时保持了计算效率。LBVim在多个视觉任务中表现出优越的性能-吞吐量平衡，验证了方法的通用性和高效性。

中文摘要: Mamba是一种状态空间模型（SSM），通过将递归转化为并行选择性扫描来加速训练，成为自注意力机制的高效替代方案。由于其单向性，Mamba的每个状态仅能获取之前状态的信息，无法感知后续状态。现有的基于Mamba的计算机视觉方法通常通过全局前向扫描和全局反向扫描结合来恢复完整感受野，但这一操作使计算负担加倍，削弱了Mamba原有的效率优势。为消除额外扫描，我们提出LBMamba，一种局部双向SSM模块，在正向选择性扫描中嵌入轻量级局部反向扫描，并完全在每线程寄存器中执行。基于LBMamba，我们提出LBVim，一种可扩展的视觉骨干网络，通过每两层交替扫描方向恢复全局感受野，无需额外反向扫描。我们在自然图像和全切片图像（WSI）上验证了方法的通用性。实验表明，LBVim在性能-吞吐量平衡上表现优越：在相同吞吐量下，LBVim在ImageNet-1K分类任务中Top-1准确率提升0.8%至1.6%，在ADE20K语义分割任务中mIoU提升0.6%至2.7%，在COCO检测任务中APb和APm分别提升0.9%和1.1%。我们还将LBMamba集成到当前最优的病理学多实例学习（MIL）方法MambaMIL中。在3个公开的WSI分类数据集上，我们的方法在AUC、F1和准确率上分别实现了最高3.06%、3.39%和1.67%的相对提升。

</details>


### [95] [Towards Classifying Histopathological Microscope Images as Time Series Data](https://arxiv.org/abs/2506.15977)
**中文标题：将组织病理学显微镜图像分类为时间序列数据的研究**

*Sungrae Hong,Hyeongmin Park,Youngsin Ko,Sol Lee,Bryan Wong,Mun Yong Yi*

主要分类: cs.CV

摘要简述: 本文提出了一种将显微病理图像分类为时间序列数据的新方法，通过动态时间规整（DTW）处理变长图像序列，并结合注意力池化实现病例分类，显著提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 显微病理图像是癌症诊断的关键数据，但其在深度学习领域的应用被忽视。本文旨在解决其手动采集和弱标签特性带来的挑战，提出一种新的分类方法。

研究方法: 利用动态时间规整（DTW）将变长图像序列适配为固定长度，并结合注意力池化技术同时预测病例类别。

研究结果: 实验表明，该方法在性能上优于多种基线模型，并通过不同推理策略实现了稳定可靠的结果，消融研究验证了各模块的有效性。

研究结论: 该方法不仅将显微病理图像纳入医学图像分析领域，还将其性能提升至可信赖水平，为癌症诊断提供了新思路。

中文摘要: 作为癌症诊断的前线数据，显微病理图像对于为患者提供快速准确的治疗至关重要。然而，尽管其实用价值显著，深度学习社区对其使用却普遍忽视。本文提出了一种将显微图像分类为时间序列数据的新方法，以解决其手动采集和弱标签特性带来的独特挑战。所提出的方法通过动态时间规整（DTW）将变长图像序列适配为固定长度，并利用基于注意力的池化技术同时预测病例类别。我们通过比较多种基线模型的性能，展示了不同推理策略在实现稳定可靠结果中的优势，从而验证了该方法的有效性。消融研究进一步验证了各模块的贡献。我们的方法不仅将显微图像纳入医学图像分析领域，还将其性能提升至可信赖水平。

</details>


### [96] [Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization](https://arxiv.org/abs/2506.15980)
**中文标题：基于压缩与量化多条件标记化的高级手语视频生成**

*Cong Wang,Zexuan Deng,Zhiwei Jiang,Fei Shen,Yafeng Yin,Shiwei Gan,Zifeng Cheng,Shiping Ge,Qing Gu*

主要分类: cs.CV

摘要简述: 本文提出SignViP框架，通过多条件细粒度标记化提升手语视频生成的自然性和表现力，结合扩散模型与量化编码器，实现高质量视频生成。


<details>
  <summary>详细信息</summary>
研究动机: 现有手语视频生成方法依赖单一粗粒度条件（如骨架序列），限制了生成视频的自然性和表现力。SignViP旨在通过多条件细粒度标记化解决这一问题。

研究方法: SignViP包含三个核心组件：(1) 联合训练的视频扩散模型与多条件编码器，学习细粒度运动和外观的连续嵌入；(2) FSQ自编码器压缩并量化嵌入为离散标记；(3) 多条件标记翻译器将文本翻译为离散标记。推理时，标记解码为连续嵌入并指导视频生成。

研究结果: 实验表明，SignViP在视频质量、时间一致性和语义保真度上均达到最优性能。

研究结论: SignViP通过多条件细粒度标记化显著提升手语视频生成质量，为相关领域提供了新思路。

中文摘要: 手语视频生成（SLVG）旨在从口语文本生成保留身份特征的手语视频。现有方法主要依赖单一粗粒度条件（如骨架序列）作为翻译模型与视频生成模型的中介，限制了生成视频的自然性和表现力。为克服这些限制，我们提出SignViP，一种新颖的SLVG框架，通过多条件细粒度标记化提升生成保真度。SignViP采用离散标记化范式整合细粒度条件（如细粒度姿势和3D手部），包含三个核心组件：(1) 联合训练的视频扩散模型与多条件编码器，学习细粒度运动和外观的连续嵌入；(2) FSQ自编码器压缩并量化嵌入为离散标记；(3) 多条件标记翻译器将口语文本翻译为离散标记。推理时，标记解码为连续嵌入并指导视频生成。实验表明，SignViP在视频质量、时间一致性和语义保真度上均达到最优性能。代码见https://github.com/umnooob/signvip/。

</details>


### [97] [Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation](https://arxiv.org/abs/2506.15988)
**中文标题：视觉地点识别中的对抗攻击与检测：提升机器人导航安全性**

*Connor Malone,Owen Claxton,Iman Shames,Michael Milford*

主要分类: cs.CV

摘要简述: 本文分析了视觉地点识别（VPR）系统在对抗攻击下的脆弱性，并提出了一种结合对抗攻击检测器（AAD）的系统框架，显著提升了机器人导航的安全性。实验表明，即使AAD的检测准确率有限，也能大幅降低定位误差。


<details>
  <summary>详细信息</summary>
研究动机: 视觉地点识别（VPR）系统在机器人导航中至关重要，但其对抗攻击防御能力薄弱，可能导致灾难性后果。本文旨在分析VPR系统在对抗攻击下的表现，并提出解决方案以提升其安全性。

研究方法: 论文分析了四种常见对抗攻击和四种VPR特有攻击对VPR定位性能的影响，并提出了一种结合AAD的系统框架。通过实验验证了AAD在不同检测准确率下的性能提升，并首次研究了FGSM攻击在VPR中的效果。

研究结果: 实验表明，加入AAD后，即使检测准确率仅为75%（真阳性）和25%（假阳性），也能将平均沿轨定位误差降低约50%。此外，论文还提供了多种安全性指标的详细分析。

研究结论: 研究强调了在真实系统中集成AAD的必要性，为可信导航提供了量化设计依据，并提出了一个可供机器人社区使用的系统框架。

中文摘要: 独立的视觉地点识别（VPR）系统对精心设计的对抗攻击几乎没有防御能力，这在机器人导航中可能导致灾难性后果。本文深入分析了四种常见对抗攻击和四种VPR特有攻击对VPR定位性能的影响，并提出了一种结合对抗攻击检测器（AAD）和主动导航决策的系统框架。通过实验验证，我们发现即使AAD的检测准确率有限（如真阳性率75%和假阳性率最高25%），也能显著提升性能，例如将平均沿轨定位误差降低约50%。我们还研究了多种指标，包括沿轨误差、受攻击时间比例、处于“不安全”状态的时间比例以及最长连续受攻击时间。此外，本文首次研究了快速梯度符号法（FGSM）对抗攻击在VPR中的效果。研究结果强调了在真实系统中集成AAD的必要性，并为系统设计提供了量化依据。

</details>


### [98] [DIGMAPPER: A Modular System for Automated Geologic Map Digitization](https://arxiv.org/abs/2506.16006)
**中文标题：DIGMAPPER：一种模块化的自动化地质地图数字化系统**

*Weiwei Duan,Michael P. Gerlek,Steven N. Minton,Craig A. Knoblock,Fandel Lin,Theresa Chen,Leeje Jang,Sofia Kirsanova,Zekun Li,Yijun Lin,Yao-Yi Chiang*

主要分类: cs.CV

摘要简述: DIGMAPPER是一个模块化系统，用于自动化地质地图数字化，通过深度学习模型和创新的数据生成技术，显著提高了地质特征提取和地理配准的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 历史地质地图包含丰富的地理空间信息，对可再生能源、电动汽车和国家安全至关重要，但数字化过程耗时耗力。DIGMAPPER旨在解决这一问题，实现高效自动化。

研究方法: DIGMAPPER采用模块化、可扩展的架构，集成了深度学习模型进行地图布局分析、特征提取和地理配准。系统利用上下文学习、合成数据生成和基于Transformer的模型解决数据不足和复杂视觉内容的挑战。

研究结果: 在DARPA-USGS数据集的100多张标注地图上测试显示，DIGMAPPER在多边形、线和点特征提取以及地理配准方面表现出高准确性和可靠性。

研究结论: DIGMAPPER显著加速了地质空间数据集的生成，支持国家关键矿产评估和更广泛的地球科学应用。

中文摘要: 历史地质地图包含丰富的地理空间信息，如岩石单元、断层、褶皱和层理面，这些信息对评估可再生能源、电动汽车和国家安全所需的矿产资源至关重要。然而，地图数字化仍然是一项耗时费力的任务。我们提出了DIGMAPPER，这是一个与美国地质调查局（USGS）合作开发的模块化、可扩展系统，用于自动化地质地图的数字化。DIGMAPPER采用完全容器化、工作流编排的架构，集成了最先进的深度学习模型，用于地图布局分析、特征提取和地理配准。为了克服训练数据不足和复杂视觉内容等挑战，我们的系统采用了创新技术，包括基于大型语言模型的上下文学习、合成数据生成和基于Transformer的模型。在DARPA-USGS数据集的100多张标注地图上的评估表明，系统在多边形、线和点特征提取以及地理配准方面表现出高准确性和可靠性。DIGMAPPER已在美国地质调查局部署，显著加快了分析就绪的地理空间数据集的生成，支持国家关键矿产评估和更广泛的地球科学应用。

</details>


### [99] [EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training](https://arxiv.org/abs/2506.16017)
**中文标题：EndoMUST：基于端到端多步自监督训练的机器人内窥镜单目深度估计**

*Liangjing Shao,Linxin Bai,Chenkang Du,Xinrong Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为EndoMUST的新型框架，通过多步自监督训练实现内窥镜场景中的单目深度估计，显著降低了误差。


<details>
  <summary>详细信息</summary>
研究动机: 内窥镜场景中光照变化和纹理稀疏问题对单目深度估计和自运动估计提出了挑战。现有方法虽引入多种技术，但多模块的有效训练策略仍不足。

研究方法: 提出一种多步微调框架，每轮训练分为三步：光流注册、多尺度图像分解和多变换对齐，每步仅训练相关网络以避免信息干扰。

研究结果: 在SCARED数据集上实现自监督深度估计的最优性能，Hamlyn数据集上的零样本深度估计误差降低4%~10%。

研究结论: EndoMUST框架通过高效多步训练显著提升了内窥镜深度估计的准确性，为机器人辅助内窥镜提供了可靠解决方案。

中文摘要: 单目深度估计和自运动估计是机器人辅助内窥镜中场景感知和导航的重要任务。为解决内窥镜场景中的光照变化和纹理稀疏问题，现有方法引入了光流、外观流和本征图像分解等技术。然而，多模块的有效训练策略仍需解决光照问题和信息干扰。为此，本文提出了一种多步高效微调的新型框架。在端到端训练的每轮中，过程分为三步：光流注册、多尺度图像分解和多变换对齐。每步仅训练相关网络，避免无关信息干扰。基于基础模型的参数高效微调，该方法在SCARED数据集上实现了自监督深度估计的最优性能，在Hamlyn数据集上的零样本深度估计误差降低了4%~10%。本工作的评估代码已发布于https://github.com/BaymaxShao/EndoMUST。

</details>


### [100] [PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models](https://arxiv.org/abs/2506.16054)
**中文标题：PAROAttention：面向视觉生成模型的高效稀疏与量化注意力模式感知重排序**

*Tianchen Zhao,Ke Hong,Xinhao Yang,Xuefeng Xiao,Huixia Li,Feng Ling,Ruiqi Xie,Siqi Chen,Hongyu Zhu,Yichong Zhang,Yu Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PAROAttention的新方法，通过重新组织注意力模式来优化视觉生成模型中的稀疏化和量化，显著降低了计算和内存开销，同时保持生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 视觉生成中的注意力机制因二次复杂度导致高计算和内存成本，尤其在长序列任务中。稀疏化和量化虽被探索，但在低密度和低比特位下效果不佳，主要因注意力模式的分散和不规则性。

研究方法: 提出Pattern-Aware token ReOrdering (PARO)技术，将多样化的注意力模式统一为硬件友好的块状模式，简化并优化稀疏化和量化过程。

研究结果: PAROAttention在视频和图像生成中实现了无损指标，与全精度基线结果几乎一致，同时密度降低至20%-30%，比特位降至INT8/INT4，端到端延迟加速1.9x至2.7x。

研究结论: 通过重新组织注意力模式，PAROAttention显著提升了稀疏化和量化的效率，为视觉生成任务提供了高效且高质量的解决方案。

中文摘要: 在视觉生成中，注意力机制的二次复杂度导致高内存和计算成本，尤其是在高分辨率图像或多帧视频生成所需的长序列任务中。为解决这一问题，先前研究探索了稀疏化和量化等技术。然而，这些技术在低密度和低比特位下面临显著挑战。通过系统分析，我们发现核心困难源于视觉注意力模式的分散和不规则特性。因此，我们提出了一种替代策略：通过*重新组织*注意力模式来缓解这些挑战。受视觉特征提取的局部聚合特性启发，我们设计了一种新颖的**模式感知令牌重排序（PARO）**技术，将多样化的注意力模式统一为硬件友好的块状模式。这种统一显著简化并优化了稀疏化和量化。我们评估了各种设计选择的性能与效率权衡，并最终确定了一种针对统一模式的方法。我们的方法**PAROAttention**在视频和图像生成中实现了无损指标，结果与全精度（FP）基线几乎一致，同时运行密度显著降低（~20%-30%）且比特位降至**INT8/INT4**，端到端延迟加速达到**1.9x**至**2.7x**。

</details>


### [101] [Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.16058)
**中文标题：走出相似语义空间：开放词汇分割的新探索**

*Yong Liu,SongLi Wu,Sule Bai,Jiahao Wang,Yitong Wang,Yansong Tang*

主要分类: cs.CV

摘要简述: 本文提出新基准OpenBench，用于更准确评估开放词汇分割模型的性能，并设计OVSNet方法提升开放场景下的分割效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有开放词汇分割测试集的语义空间与训练集高度相似，无法真实反映模型对开放词汇的理解能力，因此需要新的评估基准。

研究方法: 提出OpenBench基准，设计语义差异显著的测试集；提出OVSNet方法，通过异构特征融合和训练空间扩展提升分割性能。

研究结果: OVSNet在现有数据集和OpenBench上均达到最优性能，验证了基准和方法的有效性。

研究结论: OpenBench能更准确评估开放词汇分割能力，OVSNet在开放场景下表现优异。

中文摘要: 开放词汇分割的目标是通过无限文本输入指导实现对任意类别的分割。为实现这一目标，近期研究致力于开发多种技术路线以挖掘大规模预训练视觉-语言模型的潜力，并在现有基准上取得显著进展。然而，我们发现现有测试集在衡量模型对“开放词汇”概念的理解能力方面存在局限，因其语义空间与训练空间高度相似，甚至存在大量重叠类别。为此，我们提出了名为OpenBench的新基准，其语义与训练集显著不同，旨在更好地评估模型对广泛现实概念的理解和分割能力。在OpenBench上测试现有方法时，我们发现其性能与现有测试集得出的结论存在差异。此外，我们提出了一种名为OVSNet的方法，通过异构特征的精心融合和训练空间的免费扩展，提升了多样化开放场景下的分割性能。OVSNet在现有数据集和OpenBench上均取得了最先进的结果，相关分析验证了我们提出的基准和方法的合理性与有效性。

</details>


### [102] [STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution](https://arxiv.org/abs/2506.16061)
**中文标题：STAR-Pose：基于空间-时间自适应超分辨率的低分辨率视频人体姿态估计高效方法**

*Yucheng Jin,Jinyan Chen,Ziyue He,Baojun Han,Furan An*

主要分类: cs.CV

摘要简述: STAR-Pose是一种针对低分辨率视频人体姿态估计的空间-时间自适应超分辨率框架，通过改进的Transformer和自适应融合模块，显著提升了性能并降低了计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 低分辨率视频中的人体姿态估计是一个重要但具有挑战性的任务。传统方法通常依赖高质量输入或计算密集型处理，难以在资源受限的环境中部署。STAR-Pose旨在解决这一问题。

研究方法: STAR-Pose采用了一种新型的空间-时间Transformer（带有LeakyReLU改进的线性注意力机制）来捕捉长程时间依赖关系，并结合自适应融合模块（集成CNN分支）增强局部纹理。此外，设计了姿态感知的复合损失函数，专注于对关键点定位有益的特征重建。

研究结果: 在多个主流视频人体姿态估计数据集上的实验表明，STAR-Pose在极低分辨率（64x48）条件下实现了5.2%的mAP提升，推理速度比级联方法快2.8倍至4.4倍。

研究结论: STAR-Pose通过空间-时间自适应超分辨率框架，显著提升了低分辨率视频中的人体姿态估计性能，同时降低了计算成本，具有广泛的应用潜力。

中文摘要: 低分辨率视频中的人体姿态估计是计算机视觉中的一个基础性挑战。传统方法要么假设输入为高质量，要么采用计算密集的级联处理，限制了其在资源受限环境中的部署。我们提出了STAR-Pose，一种专为视频人体姿态估计设计的空间-时间自适应超分辨率框架。该方法采用了一种新型的空间-时间Transformer（带有LeakyReLU改进的线性注意力机制），高效捕捉长程时间依赖关系，并通过自适应融合模块集成并行CNN分支以增强局部纹理。此外，设计了姿态感知的复合损失函数，实现任务导向的超分辨率重建，专注于对关键点定位有益的结构特征而非单纯视觉质量优化。在多个主流视频人体姿态估计数据集上的实验表明，STAR-Pose在极低分辨率（64x48）条件下实现了5.2%的mAP提升，推理速度比级联方法快2.8倍至4.4倍。

</details>


### [103] [TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading](https://arxiv.org/abs/2506.16073)
**中文标题：TD3Net：一种用于唇读的时序密集连接多扩张卷积网络**

*Byung Hoon Lee,Wooseok Shin,Sung Won Han*

主要分类: cs.CV

摘要简述: TD3Net是一种用于唇读的时序密集连接多扩张卷积网络，通过结合密集跳跃连接和多扩张时序卷积，解决了传统方法中因感受野盲点导致的信息丢失问题，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的唇读方法采用两阶段框架，后端架构通常使用时序卷积网络（TCN）。尽管引入了密集跳跃连接以改善感受野密度，但仍存在因盲点导致的连续唇部运动信息丢失问题。TD3Net旨在通过多扩张卷积和密集连接解决这一问题。

研究方法: TD3Net结合了密集跳跃连接和多扩张时序卷积，通过为跳跃连接的特征应用不同的扩张因子，覆盖了广泛且无盲点的感受野，从而更有效地建模复杂的时序表示。

研究结果: 在LRW和LRW-1000数据集上的实验表明，TD3Net在参数更少、计算量更低的情况下，性能与现有最佳方法相当，且能有效利用多样化的时序特征并保持时序连续性。

研究结论: TD3Net通过多扩张卷积和密集连接显著提升了唇读性能，展示了其在建模连续唇部运动方面的优势，为唇读系统提供了更高效的解决方案。

中文摘要: 词级唇读方法通常采用前端和后端分离的两阶段框架来建模动态唇部运动。后端架构中，时序卷积网络（TCN）已被广泛用于最新方法。最近，TCN中引入了密集跳跃连接以改善感受野密度，从而提升复杂时序表示的建模能力。然而，由于感受野盲点导致的唇部运动连续性信息丢失，其性能仍受限。为解决这一问题，我们提出TD3Net，一种时序密集连接多扩张卷积网络，将密集跳跃连接与多扩张时序卷积结合作为后端架构。TD3Net通过为跳跃连接的特征应用不同扩张因子，覆盖了广泛且无盲点的感受野。在LRW和LRW-1000两个大型公开数据集上的词级唇读任务实验表明，该方法性能与现有最佳方法相当，且参数更少、浮点运算量更低。此外，可视化结果表明，我们的方法能有效利用多样化时序特征并保持时序连续性，在唇读系统中具有显著优势。代码已开源：https://github.com/Leebh-kor/TD3Net-A-Temporal-Densely-Connected-Multi-dilated-Convolutional-Network-for-Lipreading

</details>


### [104] [PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning](https://arxiv.org/abs/2506.16082)
**中文标题：PR-DETR：为密集视频描述注入位置和关系先验**

*Yizhe Li,Sanping Zhou,Zheng Qin,Le Wang*

主要分类: cs.CV

摘要简述: PR-DETR是一种新颖的密集视频描述框架，通过显式注入位置和关系先验信息，提升事件定位和描述的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于Transformer的密集视频描述方法需要大量训练数据且性能受限，PR-DETR通过显式位置和关系先验优化事件定位和描述质量。

研究方法: PR-DETR生成位置锚定查询提供位置先验，并设计事件关系编码器计算关系先验，以提升事件定位和描述语义连贯性。

研究结果: 实验表明PR-DETR在ActivityNet Captions和YouCook2数据集上表现优异，验证了位置和关系先验的有效性。

研究结论: PR-DETR通过显式位置和关系先验显著提升了密集视频描述的性能，为未来研究提供了新思路。

中文摘要: 密集视频描述是一项旨在定位和描述未剪辑视频中多个事件的挑战性任务。近期研究主要采用基于Transformer的架构，以端到端方式联合执行事件定位和描述生成两个子任务。基于检测Transformer的通用理念，这些方法隐式学习事件位置和语义，需要大量训练数据且在实际中性能受限。本文提出一种新颖的密集视频描述框架PR-DETR，通过显式注入位置和关系先验信息，同时提升定位准确性和描述质量。一方面，我们首先生成一组位置锚定查询，提供潜在事件的场景特定位置和语义信息作为位置先验，作为初始事件搜索区域以消除不合理的事件提议。另一方面，我们进一步设计事件关系编码器，显式计算事件边界间的关系作为关系先验，指导事件交互以提升描述的语义连贯性。大量消融实验验证了位置和关系先验的有效性。实验结果也表明，我们的方法在ActivityNet Captions和YouCook2数据集上具有竞争力。

</details>


### [105] [AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models](https://arxiv.org/abs/2506.16112)
**中文标题：AutoV：学习为大型视觉语言模型检索视觉提示**

*Yuan Zhang,Chun-Kai Fan,Tao Huang,Ming Lu,Sicheng Yu,Junwen Pan,Kuan Cheng,Qi She,Shanghang Zhang*

主要分类: cs.CV

摘要简述: 本文提出AutoV方法，通过学习自动选择最优视觉提示以提升大型视觉语言模型（LVLM）的性能。实验表明，AutoV显著提高了多种LVLM在图像理解任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉提示方法依赖人工设计，效率低且性能有限。为克服这一局限，本文提出AutoV，通过学习自动选择最优视觉提示，以提升LVLM的推理能力。

研究方法: AutoV通过自动数据收集和标注流程，评估多种视觉提示在预训练LVLM上的表现，并根据预测损失排序。利用排序作为监督信号，训练AutoV自动选择最优视觉提示。

研究结果: 实验结果显示，AutoV显著提升了多种LVLM的性能。例如，LLaVA-OV在LLaVA$^{\text{Wild}}$任务上准确率提升1.7%，Qwen2.5-VL在MMMU任务上提升1.9%。

研究结论: AutoV作为一种自动视觉提示方法，能够有效提升LVLM的性能，展示了其在图像理解任务中的潜力。

中文摘要: 受大型语言模型（LLM）中文本提示的启发，视觉提示被探索用于增强大型视觉语言模型（LVLM）的推理能力。当前方法依赖启发式设计的视觉提示，例如在原始输入图像上叠加基于文本查询的注意力热图。然而，手动设计有效提示既耗时又难以探索不同视觉提示的优势，导致性能次优。为此，我们提出AutoV，通过学习基于给定文本查询和输入图像自动选择最优视觉提示。为训练AutoV，我们开发了自动数据收集和标注流程，通过预训练LVLM评估多种视觉提示。我们将一组视觉提示输入LVLM，并根据模型生成的预测损失对其进行排序。利用排序作为监督信号，训练AutoV为LVLM自动选择最优视觉提示。实验结果表明，AutoV显著提升了多种LVLM在多个流行图像理解任务中的性能。例如，配备AutoV的LLaVA-OV在LLaVA$^{\text{Wild}}$任务上准确率提升1.7%，AutoV使Qwen2.5-VL在MMMU任务上提升1.9%，凸显其作为LVLM最优视觉提示方法的潜力。

</details>


### [106] [FastInit: Fast Noise Initialization for Temporally Consistent Video Generation](https://arxiv.org/abs/2506.16119)
**中文标题：FastInit：面向时间一致性视频生成的快速噪声初始化方法**

*Chengyu Bai,Yuming Li,Zhongyu Zhao,Jintao Chen,Peidong Jia,Qi She,Ming Lu,Shanghang Zhang*

主要分类: cs.CV

摘要简述: FastInit提出了一种快速噪声初始化方法，通过单次前向传播生成优化的噪声，显著提升视频生成的效率和时间一致性。


<details>
  <summary>详细信息</summary>
研究动机: 当前视频生成中，时间一致性是一个挑战。FreeInit通过迭代优化噪声解决了训练与推理的差距，但计算成本高。FastInit旨在消除迭代需求，提高效率。

研究方法: FastInit通过训练一个视频噪声预测网络（VNPNet），输入随机噪声和文本提示，单次生成优化的噪声。为训练VNPNet，构建了大规模数据集。

研究结果: 实验表明，FastInit显著提升了生成视频的质量和时间一致性，且无需迭代优化，计算效率高。

研究结论: FastInit为视频生成提供了高效且实用的解决方案，可直接应用于推理阶段，代码和数据集将公开。

中文摘要: 视频生成在扩散模型的推动下取得了显著进展，但实现高时间一致性仍具挑战性。近期，FreeInit发现了训练与推理间的差距，并提出了一种在推理中迭代优化初始噪声的方法。然而，迭代优化显著增加了视频生成的计算成本。本文提出FastInit，一种快速噪声初始化方法，无需迭代优化。FastInit通过学习一个视频噪声预测网络（VNPNet），输入随机噪声和文本提示，单次生成优化的噪声。因此，FastInit大幅提升了视频生成的效率，同时实现了帧间的高时间一致性。为训练VNPNet，我们构建了一个包含文本提示、随机噪声和优化噪声对的大规模数据集。在多种文本到视频模型上的广泛实验表明，我们的方法持续提升了生成视频的质量和时间一致性。FastInit不仅显著改进了视频生成，还提供了一种可直接应用于推理阶段的实用解决方案。代码和数据集将公开。

</details>


### [107] [Neurosymbolic Object-Centric Learning with Distant Supervision](https://arxiv.org/abs/2506.16129)
**中文标题：基于远距离监督的神经符号对象中心学习**

*Stefano Colamonaco,David Debot,Giuseppe Marra*

主要分类: cs.CV

摘要简述: 本文提出了一种基于神经符号方法的对象中心学习框架DeepObjectLog，通过远距离监督直接从原始非结构化感知数据中学习对象中心表示，并在多种泛化场景中优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有系统依赖对象级监督或预定义的对象分解，限制了模型的泛化能力。本文旨在通过神经符号方法直接从原始数据中学习对象表示，仅需远距离监督。

研究方法: 提出DeepObjectLog模型，结合感知模块（提取对象表示）和基于概率逻辑编程的符号推理层，通过概率逻辑推理生成学习信号，指导对象发现。

研究结果: 在未见过的对象组合、任务和对象数量等泛化场景中，DeepObjectLog优于神经和神经符号基线方法。

研究结论: 神经符号方法能够直接从原始数据中学习对象表示，并通过符号推理提升泛化能力，为对象中心学习提供了新思路。

中文摘要: 关系学习通过推理对象及其交互使模型能够在结构化领域中泛化。尽管神经符号推理和对象中心学习的最新进展使我们更接近这一目标，但现有系统要么依赖对象级监督，要么依赖输入预定义的对象分解。本文提出了一种神经符号方法，直接从原始非结构化感知数据中学习对象中心表示，仅需远距离监督。我们通过DeepObjectLog实例化这一方法，该模型结合了感知模块（提取相关对象表示）和基于概率逻辑编程的符号推理层。符号组件通过支持概率逻辑推理，引入了一种新的学习信号，进一步指导输入中有意义对象的发现。我们在多种泛化场景中评估模型，包括未见过的对象组合、任务和对象数量。实验结果表明，我们的方法在所有测试场景中均优于神经和神经符号基线。

</details>


### [108] [GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning](https://arxiv.org/abs/2506.16141)
**中文标题：GRPO-CARE：面向多模态推理的一致性感知强化学习**

*Yi Chen,Yuying Ge,Rui Wang,Yixiao Ge,Junhao Cheng,Ying Shan,Xihui Liu*

主要分类: cs.CV

摘要简述: 本文提出GRPO-CARE，一种一致性感知的强化学习框架，旨在提升多模态大语言模型（MLLMs）的推理一致性和答案准确性。通过引入双层次奖励机制和自适应一致性奖励，GRPO-CARE在SEED-Bench-R1基准测试中显著优于标准GRPO，性能提升6.7%，一致性提高24.5%。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于强化学习的多模态大语言模型（MLLMs）后训练方法缺乏严格的评估标准，且标准GRPO在提升答案准确性的同时降低了推理步骤与答案的逻辑一致性（一致性率仅57.9%）。为解决这一问题，本文旨在开发一种无需显式监督的框架，同时优化答案正确性和推理一致性。

研究方法: 本文提出GRPO-CARE框架，包含双层次奖励机制：（1）基础奖励用于答案正确性；（2）自适应一致性奖励，通过对比模型推理路径与参考模型的似然性计算。该方法取代了传统的KL惩罚，鼓励探索逻辑一致的推理路径。

研究结果: 在SEED-Bench-R1基准测试中，GRPO-CARE在最具挑战性的评估级别上性能提升6.7%，一致性提高24.5%。此外，该方法展现出强大的迁移能力，在多种视频理解任务中均提升了模型性能。

研究结论: GRPO-CARE通过双层次奖励机制显著提升了多模态大语言模型的推理一致性和答案准确性，同时贡献了一个系统性设计的基准测试和可推广的后训练框架，推动了更可解释和鲁棒的MLLMs发展。

中文摘要: 近期强化学习方法（如基于结果监督的GRPO）在大型语言模型（LLMs）的链式推理中取得了进展，但其在多模态LLMs（MLLMs）中的应用尚未探索。为解决MLLMs后训练方法缺乏严格评估的问题，我们引入了SEED-Bench-R1，这是一个包含复杂真实世界视频的基准测试，要求平衡感知与推理能力。该基准提供了大规模训练集，并评估了三种逐步升级的挑战场景：分布内、跨环境和跨环境-任务。通过SEED-Bench-R1，我们发现标准GRPO虽然提升了答案准确性，但常常降低推理步骤与答案的逻辑一致性，一致性率仅为57.9%。这源于奖励信号仅关注最终答案，鼓励捷径行为，而严格的KL惩罚限制了探索。为解决这一问题，我们提出了GRPO-CARE，一种一致性感知的强化学习框架，无需显式监督即可同时优化答案正确性和推理一致性。GRPO-CARE引入了双层次奖励：（1）基础奖励用于答案正确性；（2）自适应一致性奖励，通过对比模型推理路径与缓慢演化的参考模型的似然性计算。这种双重机制放大了对既正确又逻辑一致的推理路径的奖励。通过用自适应奖励取代KL惩罚，GRPO-CARE在SEED-Bench-R1上显著优于标准GRPO，在最具挑战性的评估级别上性能提升6.7%，一致性提高24.5%。此外，该方法展现出强大的迁移能力，在多种视频理解任务中提升了模型性能。我们的工作贡献了一个系统性设计的基准测试和一个可推广的后训练框架，推动了更可解释和鲁棒的MLLMs发展。

</details>


### [109] [MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models](https://arxiv.org/abs/2506.16157)
**中文标题：MBA：针对指代表达分割模型的多模态双向攻击**

*Xingbai Chen,Tingchao Fu,Renyang Liu,Wei Zhou,Chao Yi*

主要分类: cs.CV

摘要简述: 本文提出了一种针对指代表达分割模型的多模态双向攻击方法，通过联合优化图像和文本模态，生成具有跨文本迁移性的对抗样本，显著提升了攻击效果。


<details>
  <summary>详细信息</summary>
研究动机: 指代表达分割模型在实际应用中表现出色，但其对抗样本的鲁棒性尚未充分研究。现有攻击方法在多模态结构上表现不佳，且无法适应多样化的文本输入需求。

研究方法: 提出多模态双向攻击策略，通过可学习的代理文本嵌入扰动和视觉对齐优化，联合优化图像和文本模态，生成具有跨文本迁移性的对抗样本。

研究结果: 在多个指代表达分割模型和基准数据集上的实验表明，该方法显著优于现有攻击方法，生成的对抗样本具有更强的跨文本迁移性。

研究结论: 多模态双向攻击方法有效提升了对抗样本的跨文本迁移性，为指代表达分割模型的鲁棒性研究提供了新思路。

中文摘要: 指代表达分割（RES）能够根据自然语言描述对图像中的对象进行精确分割，在实际视觉任务中具有高度灵活性和广泛适用性。尽管其性能出色，但RES模型对抗样本的鲁棒性尚未得到充分研究。现有的对抗攻击方法在传统分割模型上表现良好，但直接应用于RES时效果不佳，未能暴露其多模态结构的脆弱性。此外，在实际开放场景中，用户通常会对同一图像发出多样化的指代表达，因此需要生成能够适应多种文本输入的对抗样本。为解决这些多模态挑战，我们提出了一种名为“多模态双向攻击”的新策略，专为RES模型设计。该方法引入了可学习的代理文本嵌入扰动，并在攻击生成过程中联合优化图像模态的视觉对齐和文本模态的文本对抗优化。这种双重优化框架促使对抗图像在优化过程中主动适应更具挑战性的文本嵌入，从而增强其跨文本迁移性，即对抗样本在多种未见或语义多样的文本输入下仍保持有效的能力。在多个RES模型和基准数据集上的广泛实验表明，我们的方法显著优于现有方法。

</details>


### [110] [Co-Speech Gesture and Facial Expression Generation for Non-Photorealistic 3D Characters](https://arxiv.org/abs/2506.16159)
**中文标题：为非写实3D角色生成伴随语音的手势和面部表情**

*Taisei Omine,Naoyuki Kawabata,Fuminori Homma*

主要分类: cs.CV

摘要简述: 本文提出了一种为非写实3D角色生成伴随语音的手势和面部表情的方法，通过漫画提取表情数据和对话语义手势，显著提升了情感表达效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着对话AI的发展，肢体表达（如手势和面部表情）的研究也取得进展。然而，现有研究多聚焦于写实虚拟形象，不适用于非写实角色（如动漫角色）。本研究旨在为非写实角色设计情感表达方法，包括其特有的夸张表情。

研究方法: 研究利用从漫画中提取的表情数据，结合对话特定的语义手势，为非写实3D角色生成情感表达。通过用户研究验证了方法的有效性。

研究结果: 用户研究表明，与现有研究相比，该方法在多个方面均有显著提升。

研究结论: 本研究为非写实3D角色的情感表达提供了有效方法，特别是在夸张表情和语义手势方面取得了突破。

中文摘要: 随着对话AI的发展，肢体表达（如手势和面部表情）的研究也取得进展。然而，现有研究多聚焦于写实虚拟形象，不适用于非写实角色（如动漫角色）。本研究提出了一种方法，通过从漫画中提取表情数据，并结合对话特定的语义手势，为非写实角色生成情感表达，包括其特有的夸张表情。用户研究表明，与现有研究相比，该方法在多个方面均有显著提升。

</details>


### [111] [Align the GAP: Prior-based Unified Multi-Task Remote Physiological Measurement Framework For Domain Generalization and Personalization](https://arxiv.org/abs/2506.16160)
**中文标题：对齐GAP：基于先验的统一多任务远程生理测量框架，用于域泛化与个性化**

*Jiyao Wang,Xiao Yang,Hao Lu,Dengbo He,Kaishun Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于先验的统一多任务远程生理测量框架（GAP），旨在解决多源同步语义域泛化（MSSDG）和测试时个性化适应（TTPA）之间的融合问题。通过分解面部视频信息并结合先验知识，该框架在多个数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 多源同步语义域泛化（MSSDG）和测试时个性化适应（TTPA）在远程生理测量中具有重要意义，但两者之间存在显著差异，难以融合。本文旨在提出一种统一框架，同时解决MSSDG和TTPA问题，并提升多任务远程生理测量的泛化能力和个性化适应性。

研究方法: 首先将面部视频信息分解为不变语义、个体偏差和噪声；随后，结合先验知识和观察结果，设计多个模块分别处理不同阶段和不同面部信息；最后，基于泛化和个性化的不同原则，实现MSSDG和TTPA的统一框架。

研究结果: 在六个公开数据集上扩展了MSSDG基准，并引入了一个新的完整标注的真实驾驶数据集。实验验证了该框架的有效性，代码和新数据集将公开。

研究结论: 提出的GAP框架成功融合了MSSDG和TTPA，为多任务远程生理测量提供了统一的解决方案，并在实验中表现出色。

中文摘要: 多源同步语义域泛化（MSSDG）旨在提升多任务远程生理测量的泛化能力，但其面临部分标注和环境噪声等问题。同时，测试时个性化适应（TTPA）对个性化产品至关重要，但MSSDG与TTPA之间存在显著差异，难以融合。为此，我们提出了一种基于先验的统一框架（GAP），用于生物识别和远程光电容积描记（rPPG）。首先将面部视频信息分解为不变语义、个体偏差和噪声；随后，结合先验知识和观察结果，设计多个模块分别处理不同阶段和不同面部信息；最后，基于泛化和个性化的不同原则，该框架能够以最小调整同时解决MSSDG和TTPA问题。我们在六个公开数据集上扩展了MSSDG基准，并引入了一个新的完整标注的真实驾驶数据集。大量实验验证了该方法的有效性，代码和新数据集将公开。

</details>


### [112] [Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis](https://arxiv.org/abs/2506.16186)
**中文标题：结合生成对抗网络与卷积神经网络以增强交通事故检测与分析**

*Zhenghao Xi,Xiang Liu,Yaqi Liu,Yitong Cai,Yangyu Zheng*

主要分类: cs.CV

摘要简述: 本文提出了一种结合生成对抗网络（GAN）和卷积神经网络（CNN）的框架，用于增强交通事故检测与分析。通过数据合成和模型训练，实现了高精度的实时事故检测，准确率达94%-95%。


<details>
  <summary>详细信息</summary>
研究动机: 全球交通事故数量持续上升，亟需一种智能、高效的自动化事故检测方法。现有系统面临监督不足和数据稀缺的问题，因此需要创新技术来解决这些挑战。

研究方法: 研究结合GAN合成数据和CNN进行模型训练。从YouTube视频中收集事故与非事故视频帧，进行图像调整和增强。测试了CNN、微调卷积神经网络（FTCNN）和视觉变换器（VIT）三种模型。

研究结果: FTCNN和VIT模型表现最佳，准确率分别为94%和95%，而CNN模型为88%。表明该框架适用于实时交通事故检测和大规模应用。

研究结论: 该研究为未来智能监控系统奠定了基础，可用于实时交通监测、智慧城市框架及紧急管理系统的集成。

中文摘要: 利用闭路电视（CCTV）视频进行事故检测是提升交通安全和高效交通控制的关键功能。本研究通过采用先进的深度学习技术，解决了事故检测系统中监督不足和数据稀缺的问题。全球交通事故数量的上升促使我们开发一种智能、高效且自动化的方法来识别事故并呼叫救援。为解决数据稀缺问题，提出的框架结合了生成对抗网络（GAN）用于数据合成和卷积神经网络（CNN）用于模型训练。从YouTube视频中收集事故与非事故视频帧，并进行尺寸调整、图像增强和像素范围归一化处理。测试了三种模型：CNN、微调卷积神经网络（FTCNN）和视觉变换器（VIT），其中FTCNN和VIT表现最佳，准确率分别为94%和95%，而CNN模型为88%。结果表明，该框架因其高实时事故检测能力和广泛适用性，非常适合交通安全应用。本研究为未来实时交通监测、智慧城市框架及智能监控系统与紧急管理系统的集成奠定了基础。

</details>


### [113] [VideoGAN-based Trajectory Proposal for Automated Vehicles](https://arxiv.org/abs/2506.16209)
**中文标题：基于视频GAN的自动驾驶车辆轨迹提案生成**

*Annajoyce Mariani,Kira Maag,Hanno Gottschalk*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视频生成对抗网络（GAN）的方法，用于为自动驾驶车辆生成真实且统计准确的轨迹提案，克服了传统方法难以捕捉复杂多模态轨迹分布的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于模型驱动、规则或经典学习的方法难以有效捕捉未来轨迹的复杂多模态分布，因此本文探索利用GAN从鸟瞰视角（BEV）交通场景视频中生成统计准确的轨迹，以更好地反映交通代理之间的空间关系。

研究方法: 研究提出了一种流程，使用低分辨率BEV占用网格视频作为训练数据，通过视频生成模型生成交通场景视频，并从中提取抽象轨迹数据。采用GAN架构以实现快速训练和推理，相比扩散模型更高效。

研究结果: 在100 GPU小时的训练时间内取得了最佳结果，推理时间低于20毫秒。生成的轨迹在空间和动态参数分布上与Waymo Open Motion Dataset的真实视频数据对齐，展示了物理真实性。

研究结论: 基于视频GAN的轨迹生成方法能够高效且准确地为自动驾驶车辆提供真实轨迹提案，验证了其在捕捉复杂交通场景中的潜力。

中文摘要: 生成真实的轨迹选项是提高道路车辆自动化程度的核心能力。目前广泛使用的模型驱动、规则和经典学习方法在处理这些任务时，往往难以有效捕捉未来轨迹的复杂多模态分布。本文研究了一种基于生成对抗网络（GAN）的方法，通过训练鸟瞰视角（BEV）交通场景视频，生成统计准确的轨迹，以正确反映交通代理之间的空间关系。为此，我们提出了一种流程，使用低分辨率BEV占用网格视频作为视频生成模型的训练数据。从生成的交通场景视频中，通过单帧目标检测和帧间目标匹配提取抽象轨迹数据。特别选择了GAN架构，因其在训练和推理速度上优于扩散模型。在100 GPU小时的训练时间内取得了最佳结果，推理时间低于20毫秒。生成的轨迹在空间和动态参数分布上与Waymo Open Motion Dataset的真实视频数据对齐，验证了其物理真实性。

</details>


### [114] [FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2506.16218)
**中文标题：FOCoOp：增强视觉语言模型联邦提示学习的分布外鲁棒性**

*Xinting Liao,Weiming Liu,Jiaming Qian,Pengyang Zhou,Jiahe Xu,Wenjie Wang,Chaochao Chen,Xiaolin Zheng,Tat-Seng Chua*

主要分类: cs.CV

摘要简述: 本文提出FOCoOp框架，通过全局、局部和OOD提示优化联邦提示学习，解决分布外数据鲁棒性问题，提升模型在真实场景中的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的联邦提示学习方法在性能和鲁棒性之间存在权衡，尤其在分布外数据（OOD）偏移时表现不佳。由于不同客户端的数据分布异质性，这一问题更加复杂。FOCoOp旨在填补这一空白。

研究方法: FOCoOp通过全局提示、局部提示和OOD提示捕获客户端间的分布多样性，利用双层分布鲁棒优化适应OOD偏移，并通过半不平衡最优传输校准全局与OOD提示的一致性。

研究结果: 实验表明，FOCoOp能有效捕捉分散的异质分布，显著提升对不同OOD偏移的鲁棒性。

研究结论: FOCoOp框架成功解决了联邦提示学习中的OOD鲁棒性问题，为真实场景中的模型可靠性提供了有效解决方案。

中文摘要: 联邦提示学习（FPL）是一种在分布式客户端间协作调整视觉语言模型并保护数据隐私的强大方法。然而，现有的FPL方法在性能和鲁棒性之间存在权衡，尤其是在分布外（OOD）偏移时表现不佳，限制了其在真实场景中的可靠性。不同客户端固有的分布内（ID）数据异质性进一步加剧了这一挑战。为此，我们提出了联邦OOD感知上下文优化（FOCoOp）框架，通过全局提示、局部提示和OOD提示捕获客户端间的分布多样性。具体而言，FOCoOp利用三组提示实现类别级和分布级的分离，并通过双层分布鲁棒优化适应OOD偏移。此外，FOCoOp通过半不平衡最优传输校准全局提示、疑似OOD提示和OOD提示的一致性，提升客户端间的判别一致性。在真实数据集上的大量实验表明，FOCoOp能有效捕捉分散的异质分布，并增强对不同OOD偏移的鲁棒性。项目代码已发布于GitHub。

</details>


### [115] [R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision](https://arxiv.org/abs/2506.16262)
**中文标题：R3eVision：3D低层视觉中的鲁棒渲染、恢复与增强综述**

*Weeyoung Kwon,Jeahun Sung,Minkyu Jeon,Chanho Eom,Jihyong Oh*

主要分类: cs.CV

摘要简述: 本文综述了3D低层视觉领域的鲁棒渲染、恢复与增强技术，探讨了如何解决现实世界中因噪声、模糊和低分辨率等问题导致的3D重建挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有神经渲染方法（如NeRF和3DGS）通常假设输入为高质量多视角图像，但在现实场景中，图像常因噪声、模糊或天气影响而退化，限制了其鲁棒性。本文旨在填补这一研究空白，推动3D低层视觉技术的发展。

研究方法: 本文通过形式化退化感知渲染问题，总结了3D低层视觉中的关键挑战（如时空一致性和病态优化），并对现有方法进行分类，展示其如何在高退化条件下实现高保真3D重建。

研究结果: 综述了代表性方法、数据集和评估协议，展示了3D低层视觉在自动驾驶、AR/VR和机器人等领域的应用潜力。

研究结论: 3D低层视觉是现实环境中鲁棒3D内容生成和场景重建的基础方向，未来需进一步解决时空一致性和优化问题。

中文摘要: 神经渲染方法（如神经辐射场NeRF和3D高斯泼溅3DGS）在逼真的3D场景重建和新视角合成方面取得了显著进展。然而，现有模型大多假设输入为干净的高分辨率多视角图像，这限制了其在噪声、模糊、低分辨率和天气退化等现实场景中的鲁棒性。为解决这一问题，新兴的3D低层视觉（3D LLV）领域将经典的2D低层视觉任务（如超分辨率、去模糊、天气退化去除、恢复和增强）扩展到3D空间。本综述（称为R3eVision）通过形式化退化感知渲染问题，并识别时空一致性和病态优化等关键挑战，全面概述了3D低层视觉中的鲁棒渲染、恢复与增强技术。文章分类总结了将低层视觉融入神经渲染框架的最新方法，展示了其如何在恶劣条件下实现高保真3D重建。此外，还讨论了自动驾驶、AR/VR和机器人等应用领域，其中从退化输入中获取可靠的3D感知至关重要。通过回顾代表性方法、数据集和评估协议，本文确立了3D低层视觉作为现实环境中鲁棒3D内容生成和场景级重建的基础方向。

</details>


### [116] [Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images](https://arxiv.org/abs/2506.16265)
**中文标题：基于TLS点云与嵌入式RGB图像融合的密集3D位移估计用于滑坡监测**

*Zhaoyi Wang,Jemil Avers Butt,Shengyu Huang,Tomislav Medic,Andreas Wieser*

主要分类: cs.CV

摘要简述: 本文提出了一种融合3D点云与RGB图像的层次化分区方法，用于估计密集3D位移场，显著提升了滑坡监测的空间覆盖率和精度。


<details>
  <summary>详细信息</summary>
研究动机: 滑坡监测对理解地质灾害和降低风险至关重要，但现有方法通常仅依赖几何或辐射信息，导致位移估计稀疏或非3D。本文旨在通过融合点云和图像数据解决这一问题。

研究方法: 采用层次化分区从粗到细的方法，结合3D几何和2D图像特征构建块级匹配，并通过几何一致性检查和刚性变换估计优化匹配。

研究结果: 在两个真实滑坡数据集上，方法实现了高空间覆盖率（79%和97%）和高精度（位移偏差分别为0.15米和0.25米），优于现有方法F2S3。

研究结论: 该方法为基于TLS的滑坡监测提供了实用且灵活的解决方案，并可扩展至其他点云和监测任务。

中文摘要: 滑坡监测对理解地质灾害和降低风险至关重要。然而，现有的基于点云的方法通常仅依赖几何或辐射信息，且往往产生稀疏或非3D的位移估计。本文提出了一种层次化分区从粗到细的方法，融合3D点云和配准RGB图像以估计密集3D位移矢量场。我们利用3D几何和2D图像特征构建块级匹配，并通过几何一致性检查和刚性变换估计优化匹配。在两个真实滑坡数据集上的实验结果表明，我们的方法生成的3D位移估计具有高空间覆盖率（79%和97%）和高精度。位移幅度与外部测量（全站仪或GNSS观测）的偏差分别为0.15米和0.25米，与手动参考的偏差仅为0.07米和0.20米，低于平均扫描分辨率（0.08米和0.30米）。我们的方法在空间覆盖率上优于现有方法F2S3，同时保持相当的精度。该方法为基于TLS的滑坡监测提供了实用且灵活的解决方案，并可扩展至其他类型的点云和监测任务。示例数据和源代码公开于https://github.com/zhaoyiww/fusion4landslide。

</details>


### [117] [Fine-grained Image Retrieval via Dual-Vision Adaptation](https://arxiv.org/abs/2506.16273)
**中文标题：通过双视觉适应实现细粒度图像检索**

*Xin Jiang,Meiqi Cao,Hao Tang,Fei Shen,Zechao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种双视觉适应（DVA）方法，通过样本和特征的协同适应，指导冻结的预训练模型进行细粒度图像检索（FGIR），避免了过拟合问题，同时提升了泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前细粒度图像检索（FGIR）方法通常通过语义嵌入空间的成对相似性约束或定位子网络微调模型，但这些方法容易过拟合训练数据，并遗忘预训练中获得的知识，导致泛化能力下降。

研究方法: 1. 设计对象感知适应（Object-Perceptual Adaptation），修改输入样本以帮助预训练模型感知关键对象及其内部元素；2. 提出上下文内适应（In-Context Adaptation），通过少量参数调整特征而不修改预训练参数；3. 引入判别感知转移（Discrimination Perception Transfer），通过知识蒸馏机制将对象感知适应的判别知识转移到图像编码器。

研究结果: 实验表明，DVA在三个分布内和三个分布外的细粒度数据集上表现优异，且可学习参数较少。

研究结论: DVA方法通过协同适应样本和特征，有效提升了细粒度图像检索的性能和泛化能力，同时避免了过拟合问题。

中文摘要: 细粒度图像检索（FGIR）在学习区分性视觉表征以检索具有相似细粒度特征的图像时面临挑战。当前主流的FGIR解决方案通常遵循两种模式：在语义嵌入空间中强制成对相似性约束，或结合定位子网络微调整个模型。然而，这两种模式容易过拟合训练数据，同时遗忘从大规模预训练中获得的知识，从而降低其泛化能力。本文提出了一种双视觉适应（DVA）方法，通过协同样本和特征适应，指导冻结的预训练模型执行FGIR。具体而言，我们设计了对象感知适应，修改输入样本以帮助预训练模型感知对类别预测有帮助的关键对象及其内部元素。同时，我们提出了上下文内适应，引入少量参数进行特征适应而不修改预训练参数，使得使用这些调整特征的FGIR任务更接近预训练期间解决的任务。此外，为了平衡检索效率和性能，我们提出了判别感知转移，通过知识蒸馏机制将对象感知适应中的判别知识转移到图像编码器。大量实验表明，DVA具有较少的可学习参数，并在三个分布内和三个分布外的细粒度数据集上表现优异。

</details>


### [118] [SycnMapV2: Robust and Adaptive Unsupervised Segmentation](https://arxiv.org/abs/2506.16297)
**中文标题：SyncMapV2：鲁棒且自适应的无监督分割方法**

*Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas*

主要分类: cs.CV

摘要简述: SyncMapV2是一种无监督分割算法，具有卓越的鲁棒性和在线适应能力，无需训练或监督即可在噪声、天气和模糊等干扰下保持高性能。


<details>
  <summary>详细信息</summary>
研究动机: 人类视觉能在无显式训练的情况下分割视觉线索，并在噪声增加时保持鲁棒性，而现有AI算法在此类条件下表现不佳。本文旨在开发一种无需训练或监督的无监督分割算法，以接近人类视觉的鲁棒性和适应性。

研究方法: SyncMapV2基于自组织动力学方程和随机网络概念，无需鲁棒训练、监督或损失函数。其独特之处在于能够在线适应新输入，无需重新初始化，模仿人类视觉的持续适应性。

研究结果: 在数字干扰下，SyncMapV2的mIoU仅下降0.01%，远优于现有方法（23.8%）。在噪声、天气和模糊干扰下，其性能下降分别为7.3%、7.5%和7.0%，显著优于其他方法（37.7%、33.8%和29.5%）。此外，其在线适应能力几乎无性能损失。

研究结论: SyncMapV2首次实现了无监督分割的高鲁棒性和在线适应性，为未来开发更鲁棒和自适应的智能算法奠定了基础。

中文摘要: 人类视觉能够在无需显式训练的情况下分割视觉线索，并在噪声增加时保持极高的鲁棒性。相比之下，现有AI算法在类似条件下难以维持准确性。本文提出了SyncMapV2，这是首个解决无监督分割问题且具有最先进鲁棒性的算法。在数字干扰下，SyncMapV2的mIoU仅下降0.01%，而现有方法下降23.8%。其卓越性能覆盖多种干扰类型：噪声（7.3% vs. 37.7%）、天气（7.5% vs. 33.8%）和模糊（7.0% vs. 29.5%）。值得注意的是，SyncMapV2无需任何鲁棒训练、监督或损失函数，而是基于一种结合自组织动力学方程和随机网络概念的学习范式。此外，与传统方法需要为每个新输入重新初始化不同，SyncMapV2能够在线适应，模仿人类视觉的持续适应性。因此，我们不仅实现了准确和鲁棒的结果，还首次提出了一种能够在线适应输入而非重新初始化的算法。在适应性测试中，SyncMapV2表现出接近零的性能下降，为未来开发新一代鲁棒且自适应的智能算法提供了动力和方向。

</details>


### [119] [Learning Multi-scale Spatial-frequency Features for Image Denoising](https://arxiv.org/abs/2506.16307)
**中文标题：学习多尺度空间频率特征的图像去噪方法**

*Xu Zhao,Chen Zhao,Xiantao Hu,Hongliang Zhang,Ying Tai,Jian Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种新型多尺度自适应双域网络（MADNet），用于图像去噪，通过图像金字塔输入和自适应空间频率学习单元（ASFU）有效分离高低频信息，显著提升了去噪性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像去噪方法主要依赖固定单输入单输出的Unet架构，忽略了像素级的多尺度表示，且对频域信息处理过于均匀，未区分高低频噪声的不同特性。

研究方法: 提出MADNet，采用图像金字塔输入从低分辨率图像恢复无噪声结果；设计ASFU单元，通过可学习掩码分离高低频信息；在跳跃连接中引入全局特征融合块以增强多尺度特征。

研究结果: 在合成和真实噪声图像数据集上的实验表明，MADNet优于当前最先进的去噪方法。

研究结论: MADNet通过多尺度自适应双域设计，有效解决了高低频噪声分离和多尺度特征融合问题，显著提升了图像去噪性能。

中文摘要: 近年来，多尺度架构在图像去噪任务中表现出卓越性能。然而，现有架构主要依赖固定的单输入单输出Unet架构，忽略了像素级的多尺度表示。此外，先前方法对频域信息处理过于均匀，未区分高低频噪声的不同特性。本文提出了一种新型多尺度自适应双域网络（MADNet）用于图像去噪。我们采用图像金字塔输入从低分辨率图像恢复无噪声结果。为实现高低频信息的交互，设计了自适应空间频率学习单元（ASFU），通过可学习掩码将信息分离为高频和低频分量。在跳跃连接中，设计了全局特征融合块以增强不同尺度的特征。在合成和真实噪声图像数据集上的大量实验验证了MADNet相对于当前最先进去噪方法的有效性。

</details>


### [120] [Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation](https://arxiv.org/abs/2506.16318)
**中文标题：卫星影像的通用分割：农田边界自动提取的强基线及区域性数据集**

*Carmelo Scribano,Elena Govi,Paolo bertellini,Simone Parisi,Giorgia Franchini,Marko Bertogna*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Segment Anything Model（SAM）的农田边界自动提取方法，并引入微调策略以适应任务需求。同时，发布了一个新的区域性数据集ERAS，用于补充现有数据。实验验证了方法的准确性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 农业领域的农田边界精确测绘对高效农业运营至关重要。传统地面调查成本高昂，而通过高分辨率卫星影像结合计算机视觉技术，可以实现自动化提取，降低成本。

研究方法: 基于Segment Anything Model（SAM）构建农田边界提取流程，提出微调策略以适应农田边界提取任务。此外，开发了一种方法获取新的区域性数据集ERAS，补充现有数据。

研究结果: 实验表明，该方法在农田边界分割任务中表现出高准确性和良好的泛化能力。新数据集ERAS为研究提供了更多样化的数据支持。

研究结论: 本文提出的方法为农田边界自动化提取提供了强基线，新数据集ERAS的发布进一步推动了相关研究的发展。

中文摘要: 农田边界的精确测绘对农业高效运营至关重要。通过高分辨率卫星影像结合计算机视觉技术，可以避免成本高昂的地面调查。本文提出了一种基于Segment Anything Model（SAM）的农田边界提取流程，并引入微调策略以适应任务需求。除了使用已发布的数据集外，还描述了一种获取补充性区域性数据集的方法，覆盖了现有数据源未涉及的地区。大量实验评估了分割准确性和泛化能力。我们的方法为农田边界自动化提取提供了强基线。新区域性数据集ERAS现已公开。

</details>


### [121] [RealDriveSim: A Realistic Multi-Modal Multi-Task Synthetic Dataset for Autonomous Driving](https://arxiv.org/abs/2506.16319)
**中文标题：RealDriveSim：一种用于自动驾驶的真实多模态多任务合成数据集**

*Arpit Jadon,Haoran Wang,Phillip Thomas,Michael Stanley,S. Nathaniel Cibik,Rachel Laurat,Omar Maher,Lukas Hoyer,Ozan Unal,Dengxin Dai*

主要分类: cs.CV

摘要简述: RealDriveSim是一个多模态、多任务的自动驾驶合成数据集，支持2D计算机视觉和LiDAR应用，提供64类精细标注，显著降低数据标注成本，并在多个领域表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着感知模型的发展，大规模数据集需求增加，但数据标注成本高昂。现有合成数据集在范围、真实性和任务支持上有限，因此需要一种更全面、真实的解决方案。

研究方法: 提出RealDriveSim，一个多模态合成数据集，支持2D视觉和LiDAR应用，提供64类精细标注，并通过广泛评估验证其性能。

研究结果: RealDriveSim在多个应用和领域表现优异，优于现有合成基准，数据集已公开。

研究结论: RealDriveSim为自动驾驶研究提供了低成本、高质量的数据支持，填补了现有合成数据集的不足。

中文摘要: 随着感知模型的不断发展，对大规模数据集的需求日益增加。然而，数据标注成本过高，难以有效满足需求。合成数据集以显著降低的成本提供了提升模型性能的解决方案。然而，现有的合成数据集在范围、真实性和任务支持上仍有限。本文提出了RealDriveSim，一个真实的多模态自动驾驶合成数据集，不仅支持流行的2D计算机视觉应用，还支持其LiDAR对应任务，并提供多达64类的精细标注。我们对数据集在多种应用和领域进行了广泛评估，结果表明其性能优于现有的合成基准。数据集已公开提供，网址为https://realdrivesim.github.io/。

</details>


### [122] [Reliable Few-shot Learning under Dual Noises](https://arxiv.org/abs/2506.16330)
**中文标题：双重噪声下的可靠小样本学习**

*Ji Zhang,Jingkuan Song,Lianli Gao,Nicu Sebe,Heng Tao Shen*

主要分类: cs.CV

摘要简述: 本文提出DETA++方法，通过对比相关性聚合模块和噪声熵最大化损失，解决小样本学习中的双重噪声问题，提升模型在开放世界中的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有小样本学习方法在开放世界中容易受到支持样本和查询样本中的分布内和分布外噪声影响，导致任务适应和预测不可靠。

研究方法: DETA++采用对比相关性聚合模块计算支持样本权重，提出干净原型损失和噪声熵最大化损失，并结合局部最近质心分类器和类内区域交换策略增强噪声鲁棒性。

研究结果: 实验表明，DETA++能有效应对双重噪声，显著提升小样本学习的可靠性和灵活性。

研究结论: DETA++通过噪声鲁棒的适应和预测机制，为开放世界中的小样本学习提供了可靠解决方案。

中文摘要: 近年来，基于模型预训练的任务适应小样本学习（FSL）取得了进展，其目标是通过少量标记的支持样本将预训练的通用模型适配到目标任务中。然而，在开放世界中，由于支持样本和查询样本中不可避免的分布内（ID）和分布外（OOD）噪声，现有方法可能仍会失败。在支持样本有限的情况下，i）双重噪声在任务适应过程中会被严重放大，ii）适应后的模型在双重噪声下可能对查询样本产生不可靠的预测。本文提出DEnoised Task Adaptation（DETA++）方法以实现可靠的小样本学习。DETA++使用对比相关性聚合（CoRA）模块计算支持样本的图像和区域权重，并基于此提出干净原型损失和噪声熵最大化损失，以实现噪声鲁棒的任务适应。此外，DETA++利用内存库存储和优化每个类内干净区域，并设计局部最近质心分类器（LocalNCC）以生成噪声鲁棒的查询样本预测。同时，DETA++采用类内区域交换（IntraSwap）策略在任务适应过程中修正ID类原型，增强模型对双重噪声的鲁棒性。大量实验证明了DETA++的有效性和灵活性。

</details>


### [123] [Transparency Techniques for Neural Networks trained on Writer Identification and Writer Verification](https://arxiv.org/abs/2506.16331)
**中文标题：用于笔迹识别与笔迹验证神经网络的透明度技术**

*Viktoria Pundy,Marco Peer,Florian Kleber*

主要分类: cs.CV

摘要简述: 本文首次在笔迹识别（WI）和笔迹验证（WV）领域应用两种透明度技术，通过像素级和点特异性显著性图提升神经网络的可解释性，并支持法医专家分析手写文本相似性。


<details>
  <summary>详细信息</summary>
研究动机: 神经网络在计算机视觉任务中表现出色，但其“黑盒”特性限制了性能与可靠性的提升。本文旨在通过透明度技术揭示神经网络在笔迹识别和验证中的决策依据，为法医专家提供支持。

研究方法: 研究首次在WI和WV领域应用两种透明度技术：像素级显著性图和点特异性显著性图。前者提供像素级解释，后者分析图像间相似性。通过删除和插入分数指标评估技术效果，并与法医专家的分析区域对比进行定性评估。

研究结果: 评估结果显示，像素级显著性图优于点特异性显著性图，能够有效支持法医专家分析手写文本相似性，并揭示神经网络在识别过程中选择的特征。

研究结论: 像素级显著性图在提升神经网络透明度方面表现更优，适用于法医专家辅助分析，为笔迹识别和验证任务提供了可解释性支持。

中文摘要: 神经网络在计算机视觉领域的许多任务中处于领先地位，包括笔迹识别（WI）和笔迹验证（WV）。这些“黑盒”系统的透明度对于提升性能和可靠性至关重要。本研究首次在WI和WV领域对神经网络应用两种透明度技术。第一种技术提供像素级显著性图，而第二种技术的点特异性显著性图则提供两幅图像之间的相似性信息。通过删除和插入分数指标评估透明度技术，目标是支持法医专家分析手写文本的相似性，并探索神经网络在识别过程中选择的特征。定性评估中，将显著性图的突出区域与法医专家在识别过程中关注的区域进行对比。评估结果表明，像素级显著性图优于点特异性显著性图，适用于法医专家的辅助分析。

</details>


### [124] [MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval](https://arxiv.org/abs/2506.16353)
**中文标题：MambaHash：面向大规模图像检索的视觉状态空间深度哈希模型**

*Chao He,Hongxi Wei*

主要分类: cs.CV

摘要简述: MambaHash是一种基于视觉状态空间的深度哈希模型，通过分组Mamba操作和通道交互注意力模块，有效提升大规模图像检索的性能和效率。


<details>
  <summary>详细信息</summary>
研究动机: 尽管Vision Mamba在多种计算机任务中表现出色，但其在大规模图像检索任务中的适用性尚未充分探索。因此，研究者提出了MambaHash模型，以填补这一空白。

研究方法: MambaHash采用分阶段的主干网络架构，引入分组Mamba操作以建模局部和全局信息，并通过通道交互注意力模块增强跨通道信息交流，最后设计了自适应特征增强模块以提高特征多样性和视觉表示能力。

研究结果: 在CIFAR-10、NUS-WIDE和IMAGENET数据集上的实验表明，MambaHash在效率和性能上均优于现有深度哈希方法，能够有效完成大规模图像检索任务。

研究结论: MambaHash通过创新的视觉状态空间设计和特征增强模块，显著提升了大尺度图像检索的效果，为相关领域提供了新的解决方案。

中文摘要: 深度图像哈希旨在通过深度神经网络将输入图像映射为简单的二进制哈希码，以实现高效的大规模图像检索。近年来，具有线性时间复杂度的Vision Mamba因其在多种计算机任务中的出色表现而受到广泛关注。然而，Mamba在大规模图像检索任务中的适用性仍需探索。为此，我们提出了一种视觉状态空间哈希模型，称为MambaHash。具体而言，我们设计了一种分阶段的主干网络架构，通过分组Mamba操作对局部和全局信息进行建模，并利用通道交互注意力模块增强跨通道信息交流。最后，我们精心设计了自适应特征增强模块以提高特征多样性和模型的视觉表示能力。我们在CIFAR-10、NUS-WIDE和IMAGENET三个广泛使用的数据集上进行了全面实验。实验结果表明，与现有的深度哈希方法相比，MambaHash具有更高的效率和优越的性能，能够有效完成大规模图像检索任务。源代码已公开：https://github.com/shuaichaochao/MambaHash.git

</details>


### [125] [Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation](https://arxiv.org/abs/2506.16369)
**中文标题：基于提示的动态令牌修剪引导Transformer注意力实现高效分割**

*Pallabi Dutta,Anubhab Maity,Sushmita Mitra*

主要分类: cs.CV

摘要简述: 本文提出了一种基于提示的动态令牌修剪方法，通过选择性减少无关令牌的处理，提升视觉Transformer在医学图像分割中的计算效率，同时保持分割精度。实验显示令牌减少35-55%，显著降低计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 视觉Transformer（ViTs）在处理大量令牌时的高计算需求限制了其在医学图像分析中的实际应用。为了解决这一问题，研究提出了一种自适应提示引导的修剪方法，以优化计算资源分配。

研究方法: 该方法利用提示生成空间先验，根据令牌的相关性对其进行排序，并对低相关性令牌进行降权处理，仅保留相关令牌用于后续处理。这一数据驱动的修剪策略支持端到端训练，并保持梯度流动。

研究结果: 实验结果表明，该方法能够减少约35-55%的令牌处理，显著降低计算成本，同时保持分割精度，适用于资源受限环境下的实时诊断。

研究结论: 提出的框架通过动态令牌修剪有效提升了视觉Transformer的计算效率，为医学图像分割提供了一种成本效益高的解决方案。

中文摘要: 视觉Transformer（ViTs）在处理大量令牌时的高计算需求限制了其在医学图像分析中的实际应用。本研究提出了一种自适应提示引导的修剪方法，通过选择性减少分割流程中无关令牌的处理来优化计算资源分配。提示生成的空间先验帮助根据令牌的相关性进行排序，低相关性令牌被降权，确保仅相关令牌在后续阶段传播处理。这一数据驱动的修剪策略支持端到端训练，保持梯度流动，并通过将计算资源集中在关键区域提升分割精度。该框架与多种先进模型集成，以消除无关令牌，从而在保持分割精度的同时提升计算效率。实验结果显示令牌减少约35-55%，显著降低了计算成本。采用该框架的成本效益高的医学图像处理，通过扩展其在资源受限环境中的适用性，促进了实时诊断的实现。

</details>


### [126] [AGC-Drive: A Large-Scale Dataset for Real-World Aerial-Ground Collaboration in Driving Scenarios](https://arxiv.org/abs/2506.16371)
**中文标题：AGC-Drive：用于真实世界驾驶场景中空中-地面协作的大规模数据集**

*Yunhao Hou,Bochao Zou,Min Zhang,Ran Chen,Shangdong Yang,Yanmei Zhang,Junbao Zhuo,Siheng Chen,Jiansheng Chen,Huimin Ma*

主要分类: cs.CV

摘要简述: AGC-Drive是首个大规模真实世界空中-地面协同3D感知数据集，填补了无人机视角在协同感知中的空白，提供多视角、多代理数据，支持车辆间及车辆-无人机协同感知任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有协同感知研究多集中于车辆间或车辆与基础设施的协作，忽视了无人机提供的动态俯视视角。缺乏高质量空中-地面协同数据集是主要原因。本文旨在填补这一空白。

研究方法: 数据采集平台包括两辆配备多摄像头和LiDAR的车辆，以及一架搭载前视摄像头和LiDAR的无人机。数据集包含12万LiDAR帧和44万图像，覆盖14种驾驶场景，含19.5%动态交互事件。

研究结果: AGC-Drive包含400个场景，每场景约100帧，标注13类3D边界框。提供车辆间及车辆-无人机协同感知基准，并开源时空对齐工具、多代理可视化系统等工具包。

研究结论: AGC-Drive为空中-地面协同感知研究提供了首个大规模真实数据集，推动多代理协作感知技术的发展。

中文摘要: 通过多代理间的信息共享，协同感知帮助自动驾驶车辆缓解遮挡并提升整体感知精度。以往研究多集中于车辆间或车辆与基础设施的协作，对无人机提供的动态俯视视角关注不足，而无人机能有效缓解遮挡并监控大规模交互环境。缺乏高质量空中-地面协同数据集是主要原因。为此，我们提出AGC-Drive，首个面向空中-地面协同3D感知的大规模真实世界数据集。数据采集平台包括两辆各配备五摄像头和一LiDAR的车辆，以及一架搭载前视摄像头和LiDAR的无人机，实现多视角多代理感知。数据集包含约12万LiDAR帧和44万图像，覆盖14种驾驶场景，如城市环岛、高速隧道和匝道等，其中19.5%为动态交互事件（如车辆切入、切出和频繁变道）。AGC-Drive包含400个场景，每场景约100帧，标注13类3D边界框。我们为车辆间及车辆-无人机协同感知任务提供基准，并开源时空对齐验证工具、多代理可视化系统和协同标注工具。数据集和代码详见https://github.com/PercepX/AGC-Drive。

</details>


### [127] [CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset](https://arxiv.org/abs/2506.16385)
**中文标题：CLIP-MG：基于骨骼姿态特征和RGB数据的语义注意力引导方法在iMiGUE数据集上的微手势识别**

*Santosh Patapati,Trisanth Srinivasan,Amith Adiraju*

主要分类: cs.CV

摘要简述: 本文提出了一种基于CLIP的改进模型CLIP-MG，用于在iMiGUE数据集上进行微手势识别。通过结合骨骼姿态特征和RGB数据，模型实现了61.82%的Top-1准确率，展示了其潜力，但也揭示了微手势识别的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 微手势识别在情感计算中具有挑战性，因为其动作细微且不自主。现有视觉语言模型（如CLIP）在微手势识别上的表现有待提升，因此需要一种结合姿态信息的改进方法。

研究方法: CLIP-MG是一种改进的CLIP模型，通过姿态引导的语义查询生成和门控多模态融合机制，将骨骼姿态信息整合到识别流程中，以提升微手势分类的准确性。

研究结果: CLIP-MG在iMiGUE数据集上实现了61.82%的Top-1准确率，表明该方法在微手势识别中具有潜力，但仍存在改进空间。

研究结论: CLIP-MG展示了结合姿态信息和视觉语言模型在微手势识别中的潜力，但完全适配此类模型仍具挑战性，未来需进一步优化。

中文摘要: 微手势识别是情感计算中的一项挑战性任务，因其动作细微、不自主且幅度较小。本文提出了一种姿态引导的语义感知CLIP架构（CLIP-MG），专为iMiGUE数据集上的微手势分类而设计。CLIP-MG通过姿态引导的语义查询生成和门控多模态融合机制，将人体骨骼姿态信息整合到基于CLIP的识别流程中。该模型实现了61.82%的Top-1准确率，结果既展示了该方法的潜力，也揭示了完全适配CLIP等视觉语言模型于微手势识别的难度。

</details>


### [128] [HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis](https://arxiv.org/abs/2506.16398)
**中文标题：HyperPath：基于知识引导的双曲语义层次建模用于WSI分析**

*Peixiang Huang,Yanyan Huang,Weiqin Zhao,Junjun He,Lequan Yu*

主要分类: cs.CV

摘要简述: 本文提出HyperPath方法，利用双曲空间建模WSI的语义层次结构，结合文本知识提升分类性能，实验证明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 病理学在癌症诊断中至关重要，WSI分析广泛使用多实例学习。现有方法多依赖欧几里得嵌入，难以充分捕捉语义层次结构。本文旨在通过双曲空间建模和文本知识引导，提升WSI分类性能。

研究方法: HyperPath方法将视觉和文本特征映射到双曲空间，设计角度模态对齐损失和语义层次一致性损失优化特征层次结构，利用测地距离进行分类，实现几何感知的WSI分析。

研究结果: 实验表明，HyperPath在多项任务中表现优于现有方法，验证了双曲嵌入在WSI分析中的潜力。

研究结论: HyperPath通过双曲空间建模和跨模态对齐，显著提升了WSI分类性能，为病理图像分析提供了新思路。

中文摘要: 病理学对癌症诊断至关重要，多实例学习（MIL）广泛用于全切片图像（WSI）分析。WSI具有自然层次结构（如补丁、区域和切片），并表现出独特的语义关联。尽管一些方法尝试利用这种层次结构改进表示，但它们主要依赖欧几里得嵌入，难以充分捕捉语义层次。为解决这一问题，我们提出HyperPath，通过整合文本描述知识，在双曲空间中建模WSI的语义层次结构，从而提升WSI分类性能。我们的方法将病理视觉-语言基础模型提取的视觉和文本特征适配到双曲空间，设计了角度模态对齐损失以确保跨模态对齐的鲁棒性，并通过语义层次一致性损失进一步优化特征层次结构，增强语义连贯性。分类采用测地距离衡量双曲语义层次中实体间的相似性，无需线性分类器，实现了几何感知的WSI分析。大量实验表明，我们的方法在多项任务中均优于现有方法，凸显了双曲嵌入在WSI分析中的潜力。

</details>


### [129] [Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks](https://arxiv.org/abs/2506.16407)
**中文标题：基于OCR的视觉文档理解在多模态对抗攻击下的鲁棒性评估**

*Dong Nguyen Tien,Dung D. Le*

主要分类: cs.CV

摘要简述: 本文提出了首个针对OCR视觉文档理解（VDU）模型的多模态对抗攻击统一框架，通过布局、像素和文本的梯度攻击，验证了模型在多种攻击场景下的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 视觉文档理解（VDU）系统在信息提取中表现优异，但其在真实对抗扰动下的鲁棒性尚未充分研究。本文旨在填补这一空白，探索多模态对抗攻击对OCR-based VDU模型的影响。

研究方法: 提出了一种统一框架，生成并评估多模态对抗攻击，包括六种基于梯度的布局攻击场景，涵盖OCR边界框、像素和文本的操纵，同时通过布局扰动预算（如IoU≥0.6）保持攻击的合理性。

研究结果: 实验结果表明，行级攻击和复合扰动（边界框+像素+文本）对模型性能影响最大；基于PGD的边界框扰动在所有模型中优于随机移位基线。消融研究进一步验证了布局预算、文本修改和对抗迁移性的影响。

研究结论: 本文揭示了OCR-based VDU模型在多模态对抗攻击下的脆弱性，为未来鲁棒性研究提供了重要参考。

中文摘要: 视觉文档理解（VDU）系统通过整合文本、布局和视觉信号，在信息提取中表现出色。然而，其在真实对抗扰动下的鲁棒性尚未充分探索。我们提出了首个统一框架，用于生成和评估基于OCR的VDU模型的多模态对抗攻击。该方法覆盖了六种基于梯度的布局攻击场景，包括OCR边界框、像素和文本在单词和行粒度上的操纵，并通过布局扰动预算（如IoU≥0.6）保持攻击的合理性。在四个数据集（FUNSD、CORD、SROIE、DocVQA）和六种模型上的实验结果表明，行级攻击和复合扰动（边界框+像素+文本）对性能影响最大。基于投影梯度下降（PGD）的边界框扰动在所有模型中优于随机移位基线。消融研究进一步验证了布局预算、文本修改和对抗迁移性的影响。

</details>


### [130] [Efficient Transformations in Deep Learning Convolutional Neural Networks](https://arxiv.org/abs/2506.16418)
**中文标题：深度学习卷积神经网络中的高效变换**

*Berk Yilmaz,Daniel Fidel Harvey,Prajit Dhuri*

主要分类: cs.CV

摘要简述: 本研究探讨了在ResNet50卷积神经网络中集成信号处理变换（FFT、WHT、DCT）对图像分类的影响，发现WHT显著降低能耗并提升准确率。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估信号处理变换在CNN模型中的计算效率、能耗和分类准确率之间的权衡，为能源受限的应用提供高效解决方案。

研究方法: 在ResNet50模型中集成FFT、WHT和DCT变换，使用CIFAR-100数据集进行实验，比较不同变换对能耗和准确率的影响。

研究结果: WHT变换显著降低能耗（从25,606 kJ降至39 kJ），同时提升准确率（从66%提升至79%）。

研究结论: WHT是一种高效且有效的信号处理变换，适用于能源受限的CNN应用。

中文摘要: 本研究探讨了在ResNet50卷积神经网络（CNN）模型中集成信号处理变换——快速傅里叶变换（FFT）、沃尔什-哈达玛变换（WHT）和离散余弦变换（DCT）——对图像分类的影响。主要目标是评估训练和推理过程中计算效率、能耗和分类准确率之间的权衡。使用CIFAR-100数据集（100类，60,000张图像）进行实验，结果表明，集成WHT显著降低了能耗并提高了准确率。具体而言，基准ResNet50模型的测试准确率为66%，平均能耗为25,606 kJ；而早期卷积层集成WHT的改进模型准确率达到74%，同时在早期和晚期层均应用WHT的增强模型准确率达到79%，平均能耗仅为39 kJ。这些结果证明了WHT在能源受限的CNN应用中的高效性和有效性。

</details>


### [131] [Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution](https://arxiv.org/abs/2506.16421)
**中文标题：结构化语义3D重建（S23DR）挑战赛2025——获胜方案**

*Jan Skvrna,Lukas Neumann*

主要分类: cs.CV

摘要简述: 本文介绍了2025年S23DR挑战赛的获胜方案，通过3D深度学习直接从稀疏点云和语义分割预测房屋的3D屋顶线框，采用两阶段方法优化顶点候选和预测边缘，最终以0.43的HSS得分获胜。


<details>
  <summary>详细信息</summary>
研究动机: S23DR挑战赛的目标是从稀疏点云和语义分割中预测房屋的3D屋顶线框，为解决这一复杂任务，本文提出了一种高效的3D深度学习方法。

研究方法: 方法分为两阶段：首先从COLMAP点云中基于Gestalt分割识别顶点候选，然后使用两个PointNet类模型，一个用于通过分析局部立方体块优化和分类顶点，另一个用于通过处理连接顶点对的圆柱区域预测边缘。

研究结果: 该方法在私有排行榜上以0.43的混合结构分数（HSS）获胜，证明了其有效性。

研究结论: 本文的两阶段3D深度学习方案在S23DR挑战赛中表现优异，为3D屋顶线框预测任务提供了高效解决方案。

中文摘要: 本文介绍了2025年S23DR挑战赛的获胜方案，任务是从稀疏点云和语义分割中预测房屋的3D屋顶线框。我们的方法直接在3D空间中操作，首先通过Gestalt分割从COLMAP点云中识别顶点候选，然后使用两个类似PointNet的模型：一个通过分析局部立方体块优化和分类顶点候选，另一个通过处理连接顶点对的圆柱区域预测边缘。这种两阶段的3D深度学习方法在私有排行榜上以0.43的混合结构分数（HSS）获胜。

</details>


### [132] [How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?](https://arxiv.org/abs/2506.16450)
**中文标题：现成的多模态大语言模型在在线情景记忆问答中的表现如何？**

*Giuseppe Lando,Rosario Forte,Giovanni Maria Farinella,Antonino Furnari*

主要分类: cs.CV

摘要简述: 本文研究了现成的多模态大语言模型（MLLMs）能否在不额外训练的情况下处理在线情景记忆视频问答（OEM-VQA）。通过将流式第一人称视频转换为轻量级文本记忆，并结合LLM推理模块，实现了高效存储和高性能表现。


<details>
  <summary>详细信息</summary>
研究动机: 研究现成的多模态大语言模型是否能够在不进行额外训练的情况下，高效处理在线情景记忆视频问答任务，以探索其在实际应用中的潜力。

研究方法: 提出了一种流水线方法：首先通过MLLM描述模块将流式第一人称视频转换为轻量级文本记忆（每分钟仅几KB），然后利用LLM推理模块查询该记忆以回答多项选择题。

研究结果: 在QAEgo4D-Closed基准测试中，最佳配置达到了56.0%的准确率，存储效率为每分钟3.6 KB，性能与专用先进系统相当，同时存储效率提高了10^4/10^5倍。

研究结论: 研究表明，现成的MLLMs能够高效处理OEM-VQA任务，无需额外训练。实验结果为未来研究提供了改进方向。

中文摘要: 我们研究了现成的多模态大语言模型（MLLMs）是否能够在不进行额外训练的情况下处理在线情景记忆视频问答（OEM-VQA）。我们的流水线方法通过MLLM描述模块将流式第一人称视频转换为轻量级文本记忆（每分钟仅几KB），并利用LLM推理模块查询该记忆以回答多项选择题。在QAEgo4D-Closed基准测试中，最佳配置达到了56.0%的准确率，存储效率为每分钟3.6 KB，性能与专用先进系统相当，同时存储效率提高了10^4/10^5倍。广泛的消融实验揭示了各组件和设计选择的作用，并为未来研究指明了改进方向。

</details>


### [133] [Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors](https://arxiv.org/abs/2506.16497)
**中文标题：识别换脸视频中的视觉伪影：CNN检测器的优势与局限**

*Riccardo Ziglio,Cecilia Pasquini,Silvio Ranise*

主要分类: cs.CV

摘要简述: 本文研究了CNN检测器在识别视频换脸技术中视觉伪影的效果，发现其在同源数据上表现优异，但在跨数据集时对遮挡伪影的泛化能力有限。


<details>
  <summary>详细信息</summary>
研究动机: 随着自动化和实时换脸工具的进步，视频流中的换脸操作对远程视频通信构成威胁。本文旨在探讨利用换脸算法在复杂物理场景（如面部遮挡）中引入的视觉伪影进行检测的有效性。

研究方法: 研究通过在两个数据集（包括一个新收集的数据集）上对基于CNN的数据驱动模型进行基准测试，分析其在不同采集源和换脸算法中的泛化能力。

研究结果: 结果显示，通用CNN架构在同源数据上表现优异，但在跨数据集时难以稳定捕捉基于遮挡的视觉线索。

研究结论: 研究强调需要开发专门的检测策略以应对此类视觉伪影。

中文摘要: 由于自动化和实时工具的进步，视频流中的换脸操作对远程视频通信构成日益严重的威胁。近期研究提出通过分析和利用换脸算法在处理复杂物理场景（如面部遮挡）时引入的视觉伪影来检测换脸。本文通过在两个数据集（包括一个新收集的数据集）上对基于CNN的数据驱动模型进行基准测试，并分析其在不同采集源和换脸算法中的泛化能力，探讨了该方法的有效性。结果表明，通用CNN架构在同源数据上表现优异，但在跨数据集时难以稳定捕捉基于遮挡的视觉线索。这凸显了需要开发专门的检测策略以应对此类伪影。

</details>


### [134] [Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details](https://arxiv.org/abs/2506.16504)
**中文标题：Hunyuan3D 2.5：迈向高保真3D资产生成的终极细节**

*Zeqiang Lai,Yunfei Zhao,Haolin Liu,Zibo Zhao,Qingxiang Lin,Huiwen Shi,Xianghui Yang,Mingxin Yang,Shuhui Yang,Yifei Feng,Sheng Zhang,Xin Huang,Di Luo,Fan Yang,Fang Yang,Lifu Wang,Sicong Liu,Yixuan Tang,Yulin Cai,Zebin He,Tian Liu,Yuhong Liu,Jie Jiang,Linus,Jingwei Huang,Chunchao Guo*

主要分类: cs.CV

摘要简述: Hunyuan3D 2.5是一套强大的3D扩散模型，旨在生成高保真且细节丰富的3D资产。通过新的形状基础模型LATTICE和基于物理渲染的纹理生成技术，显著提升了形状和纹理的生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 为了解决现有3D资产生成技术在形状和纹理细节上的不足，Hunyuan3D 2.5旨在通过改进模型架构和训练方法，生成更接近手工制作的高质量3D资产。

研究方法: Hunyuan3D 2.5采用两阶段流程：1) 使用新的形状基础模型LATTICE生成高细节的3D形状；2) 通过基于物理渲染的多视图架构升级纹理生成技术。

研究结果: 实验表明，Hunyuan3D 2.5在形状和纹理生成上均显著优于现有方法，其最大模型达到100亿参数，生成的3D资产细节丰富且表面光滑。

研究结论: Hunyuan3D 2.5通过创新的形状和纹理生成技术，显著缩小了生成3D资产与手工制作之间的差距，为高保真3D资产生成提供了新方向。

中文摘要: 本报告介绍了Hunyuan3D 2.5，一套强大的3D扩散模型，旨在生成高保真且细节丰富的纹理3D资产。Hunyuan3D 2.5沿用了其前代版本Hunyuan3D 2.0的两阶段流程，同时在形状和纹理生成上实现了显著进步。在形状生成方面，我们引入了新的形状基础模型LATTICE，该模型通过高质量数据集、模型规模和计算资源的扩展进行训练。我们的最大模型达到100亿参数，能够生成锐利且细节丰富的3D形状，同时保持网格表面干净平滑，显著缩小了生成3D形状与手工制作之间的差距。在纹理生成方面，通过基于物理渲染（PBR）的多视图架构对Hunyuan3D 2.0的Paint模型进行了升级。广泛的实验表明，Hunyuan3D 2.5在形状和端到端纹理生成上均显著优于现有方法。

</details>


### [135] [How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+](https://arxiv.org/abs/2506.16531)
**中文标题：雪有多难？一个针对晴天和雪天配对的域适应数据集：CADC+**

*Mei Qi Tang,Sean Sedwards,Chengjie Huang,Krzysztof Czarnecki*

主要分类: cs.CV

摘要简述: 本文介绍了CADC+数据集，这是首个针对自动驾驶在冬季雪天和晴天条件下的配对天气域适应数据集，用于评估雪对3D物体检测性能的影响。


<details>
  <summary>详细信息</summary>
研究动机: 当前自动驾驶数据集在雪天和晴天的标注数据不足，或依赖去雪方法生成合成数据，导致评估不准确。CADC+旨在解决这一问题，提供真实且配对的天气数据。

研究方法: CADC+扩展了加拿大恶劣驾驶条件数据集（CADC），通过在同一路段和时段采集晴天数据，与雪天数据配对，最小化非雪因素引起的域偏移。

研究结果: 初步实验表明，雪天数据同时引入了随机性和认知不确定性，既作为噪声又作为独立的数据域影响3D物体检测性能。

研究结论: CADC+为研究雪对自动驾驶性能的影响提供了可靠的数据支持，揭示了雪天数据的复杂性。

中文摘要: 雪对3D物体检测性能的影响尚未充分研究。进行此类评估需要一个在相同驾驶环境下、包含足够雪天和晴天标注数据的数据集。现有的LiDAR点云驾驶数据集要么未提供足够的雪天和晴天标注数据，要么依赖去雪方法生成合成晴天数据。合成数据通常缺乏真实性，并引入额外的域偏移，影响评估准确性。为解决这些问题，我们提出了CADC+，这是首个针对冬季自动驾驶的配对天气域适应数据集。CADC+通过在同一路段和时段采集晴天数据，与加拿大恶劣驾驶条件数据集（CADC）的雪天数据配对，最小化非雪因素引起的域偏移。我们还展示了使用CADC+评估雪对3D物体检测性能影响的初步结果。研究发现，雪同时引入了随机性和认知不确定性，既作为噪声又作为独立的数据域。

</details>


### [136] [From Semantic To Instance: A Semi-Self-Supervised Learning Approach](https://arxiv.org/abs/2506.16563)
**中文标题：从语义到实例：一种半自监督学习方法**

*Keyhan Najafian,Farhad Maleki,Lingling Jin,Ian Stavness*

主要分类: cs.CV

摘要简述: 本文提出了一种半自监督学习方法GLMask，通过最小化手动标注需求，实现了高性能的实例分割模型，特别适用于农业等密集遮挡场景，并在通用数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 实例分割在植物健康监测等领域至关重要，但大规模像素级标注数据集的制作成本高昂，尤其在密集遮挡的农业图像中更为困难。本文旨在减少标注需求，提升模型性能。

研究方法: 设计了GLMask图像-掩码表示方法，专注于形状、纹理和模式，减少对颜色特征的依赖。通过生成语义分割并转换为实例分割，实现半自监督学习。

研究结果: 在小麦头实例分割任务中达到98.5%的mAP@50，显著优于传统方法；在COCO数据集上性能提升12.6%，验证了方法的通用性。

研究结论: GLMask方法不仅适用于农业领域，还能推广到其他类似数据特性的领域，为实例分割提供了高效解决方案。

中文摘要: 实例分割在植物健康、生长和产量的自动化监测等应用中至关重要。然而，为开发实例分割模型，需要大量标注像素级对象实例的大规模数据集，这限制了深度学习在这些领域的应用。这一挑战在农业中常见的密集遮挡图像中尤为显著。为解决这一问题，我们提出了一种半自监督学习方法，仅需少量手动标注即可开发高性能实例分割模型。我们设计了GLMask，一种图像-掩码表示方法，使模型专注于形状、纹理和模式，同时减少对颜色特征的依赖。我们开发了一个从语义分割转换为实例分割的流程。该方法显著优于传统实例分割模型，在小麦头实例分割任务中达到了98.5%的mAP@50，创下了最新记录。此外，我们在通用Microsoft COCO数据集上评估了该方法，性能提升了12.6%的mAP@50。这表明我们的方法不仅适用于精准农业，还可推广到其他具有类似数据特性的领域。

</details>


### [137] [SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage](https://arxiv.org/abs/2506.16578)
**中文标题：SafeTriage：用于隐私保护中风分诊的面部视频去标识技术**

*Tongan Cai,Haomiao Ni,Wenchao Ma,Yuan Xue,Qian Ma,Rachel Leicht,Kelvin Wong,John Volpi,Stephen T. C. Wong,James Z. Wang,Sharon X. Huang*

主要分类: cs.CV

摘要简述: SafeTriage是一种新颖的面部视频去标识方法，通过将患者面部运动特征映射到合成身份上，保留中风诊断所需的关键动态信息，同时保护患者隐私。


<details>
  <summary>详细信息</summary>
研究动机: 中风急救中，临床医生需通过面部肌肉协调的细微异常进行诊断，但依赖真实患者数据的AI模型存在隐私和伦理问题。SafeTriage旨在解决这一问题，实现隐私保护下的数据共享和AI分析。

研究方法: SafeTriage利用预训练的视频运动转移模型，将患者面部运动特征转移到合成身份上。为避免分布偏移，引入条件生成模型进行视觉提示调优，确保准确运动转移而无需微调主干模型。

研究结果: 评估表明，SafeTriage生成的合成视频有效保留了中风相关的面部动态，同时提供强大的隐私保护，支持可靠的AI分诊。

研究结论: SafeTriage为神经疾病数据共享和AI临床分析提供了安全且伦理合规的基础，平衡了隐私保护与诊断准确性。

中文摘要: 在急救环境中，有效的中风分诊通常依赖于临床医生识别面部肌肉协调的细微异常能力。尽管近期AI模型在从患者面部视频中检测此类模式方面表现出潜力，但其对真实患者数据的依赖带来了显著的伦理和隐私挑战——尤其是在跨机构训练鲁棒且泛化的模型时。为解决这些问题，我们提出SafeTriage，一种新颖的方法，旨在对患者面部视频进行去标识处理，同时保留对中风诊断至关重要的运动线索。SafeTriage利用预训练的视频运动转移模型，将真实患者面部的运动特征映射到合成身份上。这种方法保留了诊断相关的面部动态，而不泄露患者身份。为缓解正常人群预训练视频与患者测试视频之间的分布偏移，我们引入了一种条件生成模型用于视觉提示调优，该模型调整视频运动转移模型的输入空间，确保无需微调主干模型即可实现准确运动转移。综合评估（包括定量指标和临床专家评估）表明，SafeTriage生成的合成视频有效保留了中风相关的面部模式，支持可靠的AI分诊。我们的评估还显示，SafeTriage在保持诊断准确性的同时提供了强大的隐私保护，为神经疾病数据共享和AI驱动的临床分析提供了安全且伦理合规的基础。

</details>


### [138] [Spatially-Aware Evaluation of Segmentation Uncertainty](https://arxiv.org/abs/2506.16589)
**中文标题：空间感知的分割不确定性评估**

*Tal Zeevi,Eléonore V. Lieffrig,Lawrence H. Staib,John A. Onofrey*

主要分类: cs.CV

摘要简述: 本文提出三种空间感知指标，结合结构和边界信息评估分割不确定性，优于传统独立像素评估方法，并在医学影像数据中验证其临床相关性。


<details>
  <summary>详细信息</summary>
研究动机: 现有不确定性评估指标忽略空间上下文和解剖结构，导致对分散或边界对齐的不确定性模式评分相同，无法区分临床重要性。

研究方法: 提出三种空间感知指标，结合结构和边界信息，通过医学影像数据（前列腺分区分割挑战）进行验证。

研究结果: 新指标在临床重要因素上表现更优，能更好区分有意义和虚假的不确定性模式。

研究结论: 空间感知指标显著提升不确定性评估的临床相关性，为医学影像分割提供更可靠的分析工具。

中文摘要: 不确定性图谱可突出分割预测中的不可靠区域，但多数评估指标将像素独立处理，忽略空间上下文和解剖结构，导致对分散或边界对齐的不确定性模式评分相同。本文提出三种结合结构和边界信息的空间感知指标，并在医学分割十项全能的前列腺分区分割挑战数据中验证。结果表明，新指标与临床重要因素更吻合，并能更好区分有意义和虚假的不确定性模式。

</details>


### [139] [MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment](https://arxiv.org/abs/2506.16601)
**中文标题：MetaQAP——一种基于元学习的质量感知预训练方法在图像质量评估中的应用**

*Muhammad Azeem Aslam,Muhammad Hamza,Nisar Ahmed,Gulshan Saleem,Zhu Shuangtong,Hu Hongfei,Xu Wei,Saba Aslam,Wang Jun*

主要分类: cs.CV

摘要简述: MetaQAP是一种基于元学习的无参考图像质量评估模型，通过质量感知预训练和元学习解决IQA中的主观性和复杂失真问题，在多个基准数据集上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 图像质量评估（IQA）因人类感知的主观性和真实图像失真的复杂性而具有挑战性。本研究旨在通过质量感知预训练和元学习提升IQA模型的性能。

研究方法: MetaQAP结合了质量感知预训练、质量感知损失函数和元学习集成模型。具体包括：在质量感知数据集上预训练CNN，优化预测的质量感知损失函数，以及通过元学习器整合多个基础模型的预测。

研究结果: 在LiveCD、KonIQ-10K和BIQ2021数据集上，MetaQAP的PLCC和SROCC得分分别为0.9885/0.9812、0.9702/0.9658和0.884/0.8765，优于现有方法。跨数据集评估也显示了其良好的泛化能力。

研究结论: MetaQAP不仅解决了真实失真的复杂性，还为IQA应用提供了鲁棒且可推广的框架，推动了无参考IQA领域的发展。

中文摘要: 图像质量评估（IQA）在众多应用中是一项关键任务，但由于人类感知的主观性和真实图像失真的复杂性，其仍具挑战性。本研究提出MetaQAP，一种新颖的无参考IQA模型，通过质量感知预训练和元学习解决这些挑战。该模型实现了三项关键贡献：在质量感知数据集上预训练卷积神经网络（CNN），采用质量感知损失函数优化预测，以及通过元学习器构建集成模型，有效结合多个基础模型的预测。实验评估在三个基准数据集（LiveCD、KonIQ-10K和BIQ2021）上进行。MetaQAP模型表现优异，PLCC和SROCC得分在LiveCD上为0.9885/0.9812，KonIQ-10K上为0.9702/0.9658，BIQ2021上为0.884/0.8765，优于现有IQA方法。跨数据集评估进一步证明了模型的泛化能力，PLCC和SROCC得分在不同数据集上分别为0.6721至0.8023和0.6515至0.7805。消融研究确认了各模型组件的重要性，当省略元学习器或质量感知损失函数等关键元素时，性能显著下降。MetaQAP不仅解决了真实失真的复杂性，还为实际IQA应用建立了鲁棒且可推广的框架。通过推动无参考IQA领域的前沿，本研究为未来的改进和扩展提供了宝贵的见解和方法论。

</details>


### [140] [Leveraging CNN and IoT for Effective E-Waste Management](https://arxiv.org/abs/2506.16647)
**中文标题：利用CNN和物联网技术实现高效电子垃圾管理**

*Ajesh Thangaraj Nadar,Gabriel Nixon Raj,Soham Chandane,Sushant Bhat*

主要分类: cs.CV

摘要简述: 本文提出了一种结合轻量级CNN和物联网技术的系统，用于高效识别和分类电子垃圾，提升回收效率。


<details>
  <summary>详细信息</summary>
研究动机: 现代电子设备激增导致电子垃圾问题日益严重，不当处理和回收不足带来环境和健康风险。本文旨在通过技术手段改善这一问题。

研究方法: 采用物联网系统与轻量级CNN分类流水线结合，通过摄像头和电子秤自动分类电子垃圾，基于视觉和重量属性。

研究结果: 系统能实时检测电路板、传感器等电子垃圾组件，优化智能回收流程，提高处理效率。

研究结论: 结合CNN和物联网的系统能有效提升电子垃圾管理效率，为智能回收提供可行方案。

中文摘要: 现代社会中电子设备的迅速普及导致电子垃圾（e-waste）数量激增。不当处置和回收不足对环境和健康构成严重威胁。本文提出了一种结合物联网技术和轻量级CNN分类流水线的系统，用于增强电子垃圾材料的识别、分类和路径规划。通过集成摄像头系统和电子秤，该框架基于视觉和重量属性自动分类电子物品。系统展示了如何实时检测电路板、传感器和电线等电子垃圾组件，从而优化智能回收流程并提升整体垃圾处理效率。

</details>


### [141] [A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques](https://arxiv.org/abs/2506.16663)
**中文标题：主成分分析（PCA）与奇异值分解（SVD）作为降维技术的比较分析**

*Michael Gyimadu,Gregory Bell*

主要分类: cs.CV

摘要简述: 本文对主成分分析（PCA）和奇异值分解（SVD）两种线性降维技术进行了纯理论比较，分析了它们的可解释性、数值稳定性及适用场景，并提出了选择算法的经验法则。


<details>
  <summary>详细信息</summary>
研究动机: 高维图像数据通常需要降维处理，而PCA和SVD是两种常用的线性降维技术。本文旨在通过理论分析比较这两种方法的优劣，为实际应用提供指导。

研究方法: 从基本原理出发推导了PCA和SVD算法，并基于经典和近期数值文献，评估了它们的可解释性、数值稳定性以及对不同矩阵形状的适用性。

研究结果: 研究发现PCA和SVD各有优缺点，具体选择取决于数据特征和需求。文章总结了选择算法的经验法则，并指出了未来实验研究的局限性与方向。

研究结论: PCA和SVD在降维中各有优势，选择需结合实际需求。未来研究可通过实验进一步验证理论分析的结论。

中文摘要: 高维图像数据通常需要降维后才能进行进一步分析。本文对两种线性降维技术——主成分分析（PCA）和奇异值分解（SVD）——进行了纯理论比较。在从基本原理推导出每种算法后，我们评估了它们的可解释性、数值稳定性以及对不同矩阵形状的适用性。基于经典和近期的数值文献，我们综合了选择其中一种算法的经验法则，而无需进行实证基准测试。文章最后指出了局限性及未来实验研究的方向。

</details>


### [142] [Extracting Multimodal Learngene in CLIP: Unveiling the Multimodal Generalizable Knowledge](https://arxiv.org/abs/2506.16673)
**中文标题：从CLIP中提取多模态学习基因：揭示多模态通用知识**

*Ruiming Chen,Junming Yang,Shiyu Xia,Xu Yang,Jing Wang,Xin Geng*

主要分类: cs.CV

摘要简述: 本文提出MM-LG框架，从CLIP中提取多模态通用知识，显著提升下游任务性能，同时减少参数存储和预训练成本。


<details>
  <summary>详细信息</summary>
研究动机: CLIP的多模态通用知识对下游任务至关重要，但大规模预训练和参数计算带来挑战。现有Learngene方法无法处理多模态场景，因此需要一种新方法来提取和利用多模态通用知识。

研究方法: 提出MM-LG框架，通过多模态和单模态块加权提取通用知识，并用这些组件初始化不同规模和模态的衍生模型。

研究结果: 实验表明，MM-LG在多个数据集上优于现有Learngene方法（如Oxford-IIIT PET提升3.1%，Flickr30k提升4.13%），且仅需约25%的参数存储和减少2.8倍预训练成本。

研究结论: MM-LG有效提取多模态通用知识，显著提升性能并降低成本，适用于高效部署多样化下游任务。

中文摘要: CLIP（对比语言-图像预训练）因其多模态通用知识而受到广泛关注，这对下游任务具有重要意义。然而，大量参数和大规模预训练的计算开销为不同规模的CLIP预训练带来了挑战。学习基因（Learngene）从祖先模型中提取通用组件（称为学习基因），并用其初始化多样化的衍生模型。以往的学习基因范式无法处理多模态场景中的通用知识。本文提出利用多模态块提取多模态通用知识的思路，并由此提出MM-LG（多模态学习基因），这是一种旨在从CLIP中提取和利用通用组件的新框架。具体而言，我们首先建立多模态和单模态块，以加权和的方式提取多模态和单模态通用知识。随后，我们利用这些组件数值化初始化不同规模和模态的衍生模型。大量实验证明了MM-LG的有效性，其在现有学习基因方法上取得了性能提升（例如，Oxford-IIIT PET提升3.1%，Flickr30k提升4.13%），并与预训练和微调范式相比表现相当或更优（例如，Oxford-IIIT PET提升1.9%，Flickr30k提升3.65%）。值得注意的是，MM-LG仅需约25%的参数存储，同时为不同规模的模型减少约2.8倍的预训练成本，使其特别适合高效部署多样化下游任务。

</details>


### [143] [How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions](https://arxiv.org/abs/2506.16679)
**中文标题：如何训练你的文本到图像模型：评估合成训练标题的设计选择**

*Manuel Brack,Sudeep Katakol,Felix Friedrich,Patrick Schramowski,Hareesh Ravi,Kristian Kersting,Ajinkya Kale*

主要分类: cs.CV

摘要简述: 本文系统研究了合成训练标题对文本到图像模型性能的影响，发现高质量标题能提升文本对齐但可能牺牲美学和多样性，而随机长度标题则能平衡美学与对齐。


<details>
  <summary>详细信息</summary>
研究动机: 由于网络抓取的数据集存在噪声和不一致性，近期研究转向合成训练标题，但缺乏对其设计选择的系统研究。本文旨在填补这一空白。

研究方法: 通过实验系统评估不同合成标题策略（如密集高质量标题和随机长度标题）对文本到图像模型性能的影响。

研究结果: 高质量标题提升文本对齐但可能降低美学和多样性；随机长度标题能平衡美学与对齐且不牺牲多样性；标题分布变化显著影响模型输出偏差。

研究结论: 标题设计对模型性能至关重要，研究结果为文本到图像生成提供了更有效的训练数据策略。

中文摘要: 训练数据是任何成功的文本到图像模型的核心。图像文本的质量和描述性对模型性能至关重要。鉴于网络抓取数据集的噪声和不一致性，近期研究转向合成训练标题。尽管这种设置通常被认为能产生更强的模型，但现有文献未提供其设计选择的见解。本研究通过系统研究不同合成标题策略对文本到图像模型下游性能的影响填补了这一空白。实验表明，密集高质量标题能增强文本对齐，但可能在输出美学和多样性上引入权衡；而随机长度标题则能在美学和对齐上实现平衡改进且不牺牲样本多样性。我们还发现，标题分布的变化会显著改变训练模型的输出偏差。研究结果强调了标题设计对实现最佳模型性能的重要性，并为文本到图像生成提供了更有效的训练数据策略的实用见解。

</details>


### [144] [DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches](https://arxiv.org/abs/2506.16690)
**中文标题：DepthVanish：优化对抗性间隔结构以实现立体深度隐形补丁**

*Yun Xing,Yue Cao,Nhat Chung,Jie Zhang,Ivor Tsang,Ming-Ming Cheng,Yang Liu,Lei Ma,Qing Guo*

主要分类: cs.CV

摘要简述: 本文提出了一种新型对抗性攻击方法DepthVanish，通过优化条纹间隔结构生成对抗性补丁，显著提升了在物理世界中攻击立体深度估计系统的效果，并成功应用于商业RGB-D相机。


<details>
  <summary>详细信息</summary>
研究动机: 立体深度估计在自动驾驶和机器人技术中至关重要，但现有对抗性攻击方法在物理世界中效果不佳。本文旨在发现更有效的攻击结构，以揭示立体深度估计系统的潜在漏洞。

研究方法: 研究发现，在重复纹理中引入规则间隔（条纹结构）可显著提升攻击效果。通过实验分析不同结构变体的性能，提出了一种联合优化条纹结构和纹理元素的对抗性攻击方法。

研究结果: 生成的对抗性补丁能够成功攻击RAFT-Stereo和STTR等先进立体深度估计方法，并在物理世界中有效攻击Intel RealSense等商业RGB-D相机。

研究结论: DepthVanish方法通过优化条纹结构，显著提升了对抗性补丁的实用性，为立体深度估计系统的安全性评估提供了重要工具。

中文摘要: 立体深度估计是自动驾驶和机器人技术中的关键任务，其误差（如将附近物体误判为远处）可能导致危险情况。针对立体深度估计的对抗性攻击有助于在部署前揭示其漏洞。以往研究表明，重复优化纹理可在数字环境中有效误导立体深度估计。然而，我们的研究发现，这些简单重复的纹理结构在物理世界（如部署为补丁时）表现不佳，限制了其测试立体深度估计系统的实际效用。本文首次发现，在重复纹理中引入规则间隔（形成条纹结构）可显著提升补丁攻击效果。通过大量实验，我们分析了这种新结构的变化如何影响性能。基于这些发现，我们开发了一种新型立体深度攻击方法，联合优化条纹结构和纹理元素。生成的对抗性补丁可插入任何场景，并成功攻击RAFT-Stereo和STTR等先进立体深度估计方法。最重要的是，我们的补丁还能在真实条件下攻击商业RGB-D相机（如Intel RealSense），展现了其在立体系统安全性评估中的实际意义。

</details>


### [145] [LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation](https://arxiv.org/abs/2506.16691)
**中文标题：LaVi：通过内部特征调制实现高效的大型视觉语言模型**

*Tongtian Yue,Longteng Guo,Yepeng Tang,Zijia Zhao,Xinxin Zhu,Hua Huang,Jing Liu*

主要分类: cs.CV

摘要简述: LaVi是一种高效的大型视觉语言模型，通过内部特征调制实现视觉与语言的无缝融合，显著提升计算效率和性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有大型视觉语言模型在视觉与语言融合上效率低下，要么破坏模型结构，要么引入高计算负担。LaVi旨在解决这一问题，提出一种高效且可扩展的解决方案。

研究方法: LaVi通过轻量级自适应变换，将视觉条件化的增量注入层归一化的仿射参数中，直接调制语言隐藏状态，避免长上下文扩展，显著降低计算成本。

研究结果: 在15个图像和视频基准测试中，LaVi不仅达到最先进的多模态性能，还减少94%的FLOPs，推理速度提升3.1倍，内存使用减半。

研究结论: LaVi通过内部特征调制实现了高效且精确的视觉语言对齐，为实时多模态推理提供了可扩展的实用解决方案。

中文摘要: 尽管大型视觉语言模型（LVLMs）取得了显著进展，但现有方法存在一个根本性瓶颈：视觉与语言融合效率低下。当前方法要么破坏模型的固有结构，要么引入严重的长期上下文计算负担，严重限制了可扩展性和效率。本文重新思考多模态融合，提出LaVi，一种新型LVLM，通过在大语言模型（LLMs）内部进行特征调制，实现无缝且高效的视觉语言融合。与依赖视觉标记串联的主流LVLMs不同，LaVi通过引入轻量级自适应变换，绕过长期上下文扩展，将视觉条件化的增量注入层归一化的仿射参数中。这一机制基于视觉输入直接调制语言隐藏状态，确保精确的视觉语言对齐，同时保留LLM的语言先验，并大幅降低计算成本。在15个图像和视频基准测试中的广泛评估表明，LaVi不仅实现了最先进的多模态性能，还显著提升了效率。与LLaVA-OV-7B相比，LaVi减少了94.0%的FLOPs，推理速度提高了3.1倍，内存使用减半——确立了LaVi作为实时多模态推理的可扩展实用解决方案。代码和模型即将发布。

</details>


### [146] [Language-driven Description Generation and Common Sense Reasoning for Video Action Recognition](https://arxiv.org/abs/2506.16701)
**中文标题：语言驱动的描述生成与常识推理在视频动作识别中的应用**

*Xiaodan Hu,Chuhang Zou,Suchen Wang,Jaechul Kim,Narendra Ahuja*

主要分类: cs.CV

摘要简述: 本文提出了一种结合语言驱动常识先验的视频动作识别框架，通过生成场景描述和推理后续活动，结合多模态信息提升识别效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频动作识别方法虽表现优异，但未充分利用语言模型中的常识先验（如场景上下文、物体交互等）。本文旨在通过语言驱动的常识推理，提升对遮挡严重视频的动作识别能力。

研究方法: 1. 视频上下文总结组件生成候选物体、活动及交互；2. 描述生成模块通过辅助提示和常识推理描述场景并推断后续活动；3. 多模态动作识别头结合视觉与文本线索识别动作。

研究结果: 在Action Genome和Charades数据集上验证了方法的有效性。

研究结论: 通过语言驱动的常识推理和多模态结合，显著提升了复杂视频动作识别的性能。

中文摘要: 近期视频动作识别方法通过将大规模预训练语言-图像模型适配到视频领域，表现出色。然而，语言模型中蕴含的丰富常识先验（如人类用于理解物体、人-物交互及活动的场景上下文）尚未被充分利用。本文提出了一种结合语言驱动常识先验的框架，用于识别单目视角下常被严重遮挡的杂乱视频动作序列。具体包括：（1）视频上下文总结组件，生成候选物体、活动及其交互；（2）描述生成模块，通过辅助提示和常识推理描述当前场景并推断后续活动；（3）多模态动作识别头，结合视觉与文本线索识别视频动作。在Action Genome和Charades数据集上的实验验证了方法的有效性。

</details>


### [147] [Few-Shot Generalized Category Discovery With Retrieval-Guided Decision Boundary Enhancement](https://arxiv.org/abs/2506.16728)
**中文标题：基于检索引导决策边界增强的少样本广义类别发现**

*Yunhan Ren,Feng Luo,Siyu Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于检索引导的决策边界增强框架（FSGCD），用于解决在已知信息稀缺条件下的少样本广义类别发现任务。通过预训练和两阶段检索优化策略，该方法在六个公开基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有广义类别发现（GCD）模型在已知类别和标注样本有限的情况下性能不佳，本文旨在探索如何在这种条件下实现竞争性表现。

研究方法: 1. 使用决策边界预训练模块缓解已知类别边界的过拟合问题；2. 采用两阶段检索引导的决策边界优化策略，通过亲和性检索伪标注样本增强边界，并将其迁移到未知类别。

研究结果: 在六个公开的GCD基准测试中，所提方法在FSGCD设定下优于现有方法。

研究结论: 本文提出的框架有效解决了少样本广义类别发现任务中的边界学习问题，为信息稀缺条件下的分类任务提供了新思路。

中文摘要: 尽管现有的广义类别发现（GCD）模型已取得显著成功，但在标注样本有限且已知类别较少的情况下，其性能尚未得到充分研究。本文提出了少样本广义类别发现（FSGCD）任务，旨在在已知信息稀缺的条件下实现竞争性表现。为此，我们提出了一种基于亲和性检索的决策边界增强框架。该框架旨在学习已知类别的决策边界，并将这些边界迁移到未知类别。首先，我们使用决策边界预训练模块来缓解预训练信息对已知类别边界的过拟合，并利用标注样本改进边界学习。其次，我们实施了一种两阶段检索引导的决策边界优化策略。具体而言，该策略通过亲和性检索的伪标注样本进一步增强严重受限的已知边界，随后通过基于亲和性的特征检索将这些优化后的边界迁移到未知类别。实验结果表明，在FSGCD设定下，所提方法在六个公开的GCD基准测试中优于现有方法。代码发布于：https://github.com/Ryh1218/FSGCD

</details>


### [148] [TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.16730)
**中文标题：TeSG：基于文本语义引导的红外与可见光图像融合**

*Mingrui Zhu,Xiru Chen,Xin Wei,Nannan Wang,Xinbo Gao*

主要分类: cs.CV

摘要简述: 提出了一种基于文本语义引导的红外与可见光图像融合方法TeSG，通过多级语义信息优化融合过程，显著提升下游任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前文本引导的红外与可见光图像融合方法在文本语义信息的有效整合与利用方面研究不足，亟需一种更灵活且任务优化的融合框架。

研究方法: TeSG方法包含三个核心模块：语义信息生成器（SIG）提取文本描述的掩码和文本语义；掩码引导交叉注意力（MGCA）模块基于掩码语义初步融合视觉特征；文本驱动注意力融合（TDAF）模块通过门控注意力进一步优化融合结果。

研究结果: 实验表明，TeSG在检测和分割等下游任务中表现优异，优于现有先进方法。

研究结论: TeSG通过多级文本语义引导，显著提升了红外与可见光图像融合的效果，为下游任务提供了更优的输入。

中文摘要: 红外与可见光图像融合（IVF）旨在结合两种图像模态的互补信息，生成更具信息量和全面性的输出。近年来，文本引导的IVF因其灵活性和多功能性展现出巨大潜力，但文本语义信息的有效整合与利用仍研究不足。为此，我们引入了两个层次的文本语义：掩码语义和文本语义，均源自大型视觉语言模型（VLM）提取的文本描述。基于此，我们提出了文本语义引导的红外与可见光图像融合方法TeSG，其通过优化下游任务（如检测和分割）的方式指导图像合成过程。具体而言，TeSG包含三个核心组件：语义信息生成器（SIG）、掩码引导交叉注意力（MGCA）模块和文本驱动注意力融合（TDAF）模块。SIG基于文本描述生成掩码和文本语义；MGCA模块在掩码语义引导下对红外与可见光图像的视觉特征进行初步注意力融合；TDAF模块则通过文本语义驱动的门控注意力进一步优化融合过程。大量实验表明，与现有先进方法相比，我们的方法在下游任务性能上具有显著竞争力。

</details>


### [149] [3DeepRep: 3D Deep Low-rank Tensor Representation for Hyperspectral Image Inpainting](https://arxiv.org/abs/2506.16735)
**中文标题：3DeepRep：用于高光谱图像修复的3D深度低秩张量表示**

*Yunshan Li,Wenwu Gong,Qianqian Wang,Chao Wang,Lili Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为3DeepRep的新型3D深度低秩张量表示模型，用于高光谱图像修复。该模型通过在所有三个张量模式上执行深度非线性变换，并结合3方向张量核范数正则化，显著提升了修复性能。实验证明其优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常仅在光谱模式上应用深度变换，忽略了其他张量模式的低秩特性，限制了高光谱图像修复的效果。因此，本文旨在提出一种更全面的3方向深度低秩张量表示模型。

研究方法: 3DeepRep模型在所有三个HSI张量模式上执行深度非线性变换，并通过最小化每个方向潜在空间中模式-i正面切片的核范数来强制低秩性。模型通过可学习的聚合模块融合三个方向的输出，并采用自监督梯度优化算法求解。

研究结果: 在真实高光谱数据集上的实验表明，3DeepRep在定性和定量上均优于现有最先进技术，表现出卓越的修复性能。

研究结论: 3DeepRep通过全面利用3方向低秩张量表示，显著提升了高光谱图像修复的效果，为相关领域提供了新的解决方案。

中文摘要: 基于变换张量核范数（TNN）的方法在高光谱图像（HSI）修复中表现出显著效果，通过利用潜在表示中的低秩结构。然而，现有方法通常将变换限制在光谱模式，忽略了其他张量模式的低秩特性。本文提出了一种新型3方向深度低秩张量表示（3DeepRep）模型，该模型在HSI张量的所有三个模式上执行深度非线性变换。为了强制低秩性，模型在每个方向的潜在空间中最小化模式-i正面切片的核范数，形成3方向TNN正则化。三个方向分支的输出通过可学习的聚合模块融合以生成最终结果。开发了一种高效的基于梯度的自监督优化算法来求解模型。在真实HSI数据集上的大量实验表明，所提方法在定性和定量上均优于现有最先进技术。

</details>


### [150] [Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection](https://arxiv.org/abs/2506.16737)
**中文标题：基于跨模态偏移引导的动态对齐与融合的弱对齐无人机目标检测**

*Liu Zongzhen,Luo Hui,Wang Zhixing,Wei Yuxing,Zuo Haorui,Zhang Jianlin*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CoDAF的统一框架，用于解决无人机多模态目标检测中的弱对齐问题，通过动态对齐和融合模块显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 无人机多模态目标检测中，由于平台运动和异步成像导致的空间不对齐问题，引发语义不一致和模态冲突，现有方法难以有效解决。

研究方法: CoDAF框架包含两个模块：基于偏移的语义对齐模块（OSA）通过可变形卷积精确对齐特征；动态注意力引导融合模块（DAFM）通过门控机制和双注意力自适应融合模态特征。

研究结果: 在DroneVehicle数据集上，CoDAF实现了78.6%的mAP，验证了其有效性。

研究结论: CoDAF通过统一设计解决了弱对齐问题，显著提升了无人机多模态目标检测的鲁棒性。

中文摘要: 无人机目标检测在环境监测和城市安全等应用中至关重要。为提高鲁棒性，近期研究探索了通过融合可见光（RGB）和红外（IR）图像的多模态检测。然而，由于无人机平台运动和异步成像，模态间常出现空间不对齐，导致弱对齐问题。这带来两大挑战：对应空间位置的语义不一致和特征融合中的模态冲突。现有方法通常孤立解决这些问题，效果有限。本文提出跨模态偏移引导的动态对齐与融合（CoDAF），一个统一框架，共同应对弱对齐无人机目标检测中的挑战。CoDAF包含两个新模块：偏移引导的语义对齐（OSA），通过估计基于注意力的空间偏移并使用共享语义空间引导的可变形卷积更精确对齐特征；动态注意力引导融合模块（DAFM），通过门控自适应平衡模态贡献，并通过空间-通道双注意力优化融合特征。通过统一设计对齐与融合，CoDAF实现了鲁棒的无人机目标检测。标准基准测试验证了方法的有效性，CoDAF在DroneVehicle数据集上达到78.6%的mAP。

</details>


### [151] [Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis](https://arxiv.org/abs/2506.16742)
**中文标题：不确定性感知变分信息追踪在可解释医学图像分析中的应用**

*Md Nahiduzzaman,Ruwan Tennakoon,Steven Korevaar,Zongyuan Ge,Alireza Bab-Hadiashar*

主要分类: cs.CV

摘要简述: 本文提出了一种名为UAV-IP的不确定性感知变分信息追踪框架，用于提升医学图像分析的准确性和可解释性。该方法通过量化不确定性，在四个医学影像数据集上实现了平均AUC提升3.2%，同时生成更简洁的解释。


<details>
  <summary>详细信息</summary>
研究动机: 在医学影像领域，AI决策支持系统需平衡准确性和可解释性以赢得用户信任。现有变分信息追踪（V-IP）方法忽略了查询-答案生成中的实例级不确定性，影响了模型的鲁棒性和可靠性。

研究方法: 本文提出不确定性感知变分信息追踪（UAV-IP），将不确定性量化引入V-IP过程，以解决模型限制（认知不确定性）和专家响应变异性（随机不确定性）带来的问题。

研究结果: 在PH2、Derm7pt、BrEaST和SkinCon四个数据集上的实验表明，UAV-IP平均AUC提升约3.2%，且生成的解释比基线V-IP简洁20%，同时保持信息量。

研究结论: UAV-IP框架证明了不确定性感知推理在可解释模型中的重要性，为医学决策提供了更可靠的支持。

中文摘要: 在医学影像中，AI决策支持系统需平衡准确性与可解释性，以建立用户信任并支持有效的临床决策。近年来，变分信息追踪（V-IP）及其变体作为可解释设计建模技术出现，旨在以人类可理解的临床相关概念解释AI决策。然而，现有V-IP方法忽略了查询-答案生成中的实例级不确定性，这些不确定性可能源于模型限制（认知不确定性）或专家响应的变异性（随机不确定性）。本文提出不确定性感知V-IP（UAV-IP），将不确定性量化整合到V-IP过程中。我们在四个医学影像数据集（PH2、Derm7pt、BrEaST和SkinCon）上评估UAV-IP，结果显示其平均AUC提升约3.2%，同时生成的解释比基线V-IP简洁20%，且未牺牲信息量。这些发现凸显了不确定性感知推理在可解释设计模型中对鲁棒可靠医学决策的重要性。

</details>


### [152] [Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention](https://arxiv.org/abs/2506.16743)
**中文标题：基于异常注意力的噪声感知扩散生成图像检测**

*Weinan Guan,Wei Wang,Bo Peng,Ziwen He,Jing Dong,Haonan Cheng*

主要分类: cs.CV

摘要简述: 本文提出了一种基于噪声感知自注意力（NASA）模块的新型检测架构NASA-Swin，用于检测扩散模型生成的图像，通过关注噪声区域捕获异常模式，并结合跨模态融合嵌入和通道掩码策略提升检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着扩散模型的快速发展，合成图像质量显著提升，引发了信息安全担忧。现有检测方法难以泛化至未见过的扩散模型，因此本文聚焦于图像噪声，利用不同扩散模型生成的图像具有相似噪声模式的特点，提出新方法以提升检测能力。

研究方法: 本文提出噪声感知自注意力（NASA）模块，专注于噪声区域以捕获异常模式，并将其集成到Swin Transformer中，形成NASA-Swin检测架构。同时，采用跨模态融合嵌入结合RGB和噪声图像，并通过通道掩码策略增强双模态特征学习。

研究结果: 实验表明，NASA-Swin在检测扩散生成图像方面表现优异，尤其在面对未见过的生成方法时，达到了最先进的性能。

研究结论: 本文通过噪声感知自注意力模块和跨模态融合策略，显著提升了扩散生成图像的检测能力，为信息安全提供了有效解决方案。

中文摘要: 随着图像生成技术（尤其是扩散模型）的快速发展，合成图像质量显著提升，引发了研究者对信息安全的担忧。为减少扩散模型的恶意滥用，扩散生成图像检测被证明是一种有效的对策。然而，伪造检测的关键挑战在于泛化至训练中未见的扩散模型。本文通过聚焦图像噪声解决这一问题。我们观察到，不同扩散模型生成的图像具有相似的噪声模式，与真实图像明显不同。基于这一发现，我们提出了一种新颖的噪声感知自注意力（NASA）模块，专注于噪声区域以捕获异常模式。为实现最先进的检测模型，我们将NASA集成到Swin Transformer中，形成新型检测架构NASA-Swin。此外，我们采用跨模态融合嵌入结合RGB和噪声图像，并通过通道掩码策略增强双模态特征学习。大量实验证明了我们方法在提升扩散生成图像检测能力方面的有效性。在面对未见过的生成方法时，我们的方法达到了最先进的性能。代码发布于https://github.com/WeinanGuan/NASA-Swin。

</details>


### [153] [Class Agnostic Instance-level Descriptor for Visual Instance Search](https://arxiv.org/abs/2506.16745)
**中文标题：类别无关的实例级描述符用于视觉实例搜索**

*Qi-Ying Sun,Wan-Lei Zhao,Yi-Bo Miao,Chong-Wah Ngo*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自监督ViT的层次化特征子集检测方法，用于视觉实例搜索中的实例级描述符，显著提升了已知和未知类别对象的检索性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于深度特征的图像检索在视觉实例搜索中仍面临挑战，尤其是缺乏有效的实例级特征表示。现有监督或弱监督方法对未知类别对象表现不佳，因此需要一种更通用的解决方案。

研究方法: 利用自监督ViT输出的特征集，将实例级区域发现建模为层次化检测紧凑特征子集的过程。通过层次分解生成特征子集层次结构，非叶节点和叶节点对应不同语义尺度的实例区域，解决了对象嵌入和遮挡问题。

研究结果: 在三个实例搜索基准测试中，该方法显著优于现有技术，对已知和未知类别对象均表现出色。

研究结论: 提出的实例级描述符通过层次化特征分解有效解决了视觉实例搜索中的关键问题，为未知类别对象提供了通用且高效的解决方案。

中文摘要: 尽管基于深度特征的内容检索取得了巨大成功，但由于缺乏有效的实例级特征表示，视觉实例搜索仍具挑战性。监督或弱监督的目标检测方法因对未知类别对象表现不佳而不适用。本文基于自监督ViT输出的特征集，将实例级区域发现建模为层次化检测紧凑特征子集的过程。层次分解生成特征子集层次结构，其中非叶节点和叶节点对应图像中不同语义尺度的实例区域，有效解决了对象嵌入和遮挡问题。层次结构中节点提取的特征构成了图像中潜在实例的全面表示。我们的实例级描述符对已知和未知类别对象均有效。在三个实例搜索基准测试上的实验表明，其性能显著优于现有方法。

</details>


### [154] [Infrared and Visible Image Fusion Based on Implicit Neural Representations](https://arxiv.org/abs/2506.16773)
**中文标题：基于隐式神经表示的红外与可见光图像融合**

*Shuchen Sun,Ligen Shi,Chang Liu,Lina Wu,Jun Qiu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于隐式神经表示（INR）的红外与可见光图像融合方法INRFuse，通过神经网络参数化连续函数实现多模态信息融合，无需训练数据即可生成结构清晰、细节自然的融合图像。


<details>
  <summary>详细信息</summary>
研究动机: 红外与可见光图像融合旨在结合两者的优势生成信息丰富且满足视觉或计算需求的图像。传统方法依赖离散像素或显式特征，而本文希望通过隐式神经表示突破这一限制。

研究方法: INRFuse方法利用多层感知机将红外与可见光图像的归一化空间坐标作为输入，自适应融合多模态特征，并通过设计多种损失函数联合优化融合图像与原图像的相似性。

研究结果: 实验结果表明，INRFuse在主观视觉质量和客观评价指标上均优于现有方法，生成的融合图像结构清晰、细节自然且信息丰富，且支持不同分辨率图像的直接融合与超分辨率重建。

研究结论: INRFuse通过隐式神经表示实现了红外与可见光图像的高效融合，无需训练数据即可生成高质量结果，为多模态图像融合提供了新思路。

中文摘要: 红外与可见光图像融合旨在结合两种模态的优势，生成信息丰富且满足视觉或计算需求的图像。本文提出了一种基于隐式神经表示（INR）的图像融合方法INRFuse。该方法通过神经网络参数化连续函数，隐式表示图像的多模态信息，突破了传统方法对离散像素或显式特征的依赖。红外与可见光图像的归一化空间坐标作为输入，利用多层感知机自适应融合两种模态的特征，输出融合图像。通过设计多种损失函数，该方法联合优化融合图像与原图像的相似性，有效保留红外图像的热辐射信息，同时保持可见光图像的纹理细节。此外，INR的分辨率无关特性支持直接融合不同分辨率的图像，并通过高密度坐标查询实现超分辨率重建。实验结果表明，INRFuse在主观视觉质量和客观评价指标上均优于现有方法，生成的融合图像结构清晰、细节自然且信息丰富，且无需训练数据集。

</details>


### [155] [PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model](https://arxiv.org/abs/2506.16776)
**中文标题：PQCAD-DM：用于极高效率扩散模型的渐进量化与校准辅助蒸馏**

*Beomseok Ko,Hyeryung Jang*

主要分类: cs.CV

摘要简述: PQCAD-DM是一种结合渐进量化（PQ）和校准辅助蒸馏（CAD）的混合压缩框架，旨在解决扩散模型的高计算资源消耗问题，同时保持生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在图像生成中表现优异，但其依赖迭代马尔可夫链过程导致计算资源消耗大，且传统压缩技术效果有限。本文旨在通过混合压缩框架解决这些问题。

研究方法: PQCAD-DM采用两阶段渐进量化（PQ），通过动量机制自适应调整位宽以减少低精度下的权重扰动；同时利用校准辅助蒸馏（CAD），在蒸馏过程中使用全精度校准数据集，使量化学生模型匹配全精度教师模型的性能。

研究结果: PQCAD-DM在计算效率和生成质量之间取得平衡，推理时间减半，同时保持竞争力。实验表明其在多种数据集上优于固定位量化方法。

研究结论: PQCAD-DM通过渐进量化和校准辅助蒸馏，显著提升了扩散模型的效率，同时保持了生成质量，为高效扩散模型提供了新思路。

中文摘要: 扩散模型在图像生成中表现出色，但由于依赖迭代马尔可夫链过程，计算和资源消耗巨大，导致误差累积，且传统压缩技术效果有限。本文提出PQCAD-DM，一种结合渐进量化（PQ）和校准辅助蒸馏（CAD）的新型混合压缩框架。PQ采用两阶段量化，通过动量机制自适应调整位宽，减少低精度下的权重扰动；CAD在蒸馏过程中利用全精度校准数据集，使量化学生模型匹配全精度教师模型的性能。PQCAD-DM在计算效率和生成质量之间取得平衡，推理时间减半，同时保持竞争力。大量实验验证了PQCAD-DM在多种数据集上的优异生成能力和效率，优于固定位量化方法。

</details>


### [156] [TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration](https://arxiv.org/abs/2506.16784)
**中文标题：TextBraTS：基于文本引导的体积脑肿瘤分割与创新数据集开发及融合模块探索**

*Xiaoyu Shi,Rahul Kumar Jain,Yinhao Li,Ruibo Hou,Jingliang Cheng,Jie Bai,Guohua Zhao,Lanfen Lin,Rui Xu,Yen-wei Chen*

主要分类: cs.CV

摘要简述: 本文介绍了首个公开的多模态脑肿瘤分割数据集TextBraTS，并提出了一种基于文本引导的体积医学图像分割方法，显著提升了分割精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前脑肿瘤分析领域缺乏结合影像与文本注释的综合数据集，限制了多模态方法的研究。本文旨在填补这一空白，推动文本与影像数据的融合应用。

研究方法: 基于TextBraTS数据集，提出了一种新颖的基线框架和序列交叉注意力方法，探索了多种文本-图像融合策略和模板化文本生成方式。

研究结果: 实验表明，该方法显著提高了脑肿瘤分割的准确性，并为多模态融合技术提供了有效见解。

研究结论: TextBraTS数据集和提出的方法为脑肿瘤分割领域提供了重要资源和技术支持，推动了多模态医学图像分析的发展。

中文摘要: 深度学习在医学图像分割和计算机辅助诊断中取得了显著成功，尤其在脑肿瘤MRI分割领域，许多先进方法已达到最先进水平。然而，其他医学影像领域的研究表明，结合文本报告与视觉数据可提升分割精度，而脑肿瘤分析领域尚缺乏结合影像与文本注释的综合数据集，这限制了多模态方法的探索。

为填补这一空白，我们推出了TextBraTS数据集，这是首个公开的体积级多模态数据集，包含配对的MRI体积和丰富的文本注释，源自广泛采用的BraTS2020基准。基于此数据集，我们提出了一种新颖的基线框架和序列交叉注意力方法，用于文本引导的体积医学图像分割。通过多种文本-图像融合策略和模板化文本生成的实验，我们的方法显著提升了脑肿瘤分割精度，并为有效的多模态融合技术提供了宝贵见解。

我们的数据集、实现代码和预训练模型已公开在https://github.com/Jupitern52/TextBraTS。

</details>


### [157] [RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought](https://arxiv.org/abs/2506.16796)
**中文标题：RealSR-R1：基于视觉语言思维链强化学习的真实世界图像超分辨率**

*Junbo Qiao,Miaomiao Cai,Wei Li,Yutong Liu,Xudong Huang,Gaoqi He,Jiao Xie,Jie Hu,Xinghao Chen,Shaohui Lin*

主要分类: cs.CV

摘要简述: 本文提出RealSR-R1，通过结合视觉与语言推理的VLCoT框架和GRPO强化学习方法，显著提升了真实世界图像超分辨率任务的效果，生成更自然且高保真的图像。


<details>
  <summary>详细信息</summary>
研究动机: 现有真实世界图像超分辨率方法难以准确理解退化图像内容，导致重建结果低保真且不自然。本文旨在通过模拟人类处理退化图像的过程，结合视觉与语言推理，提升模型的理解与推理能力。

研究方法: 提出VLCoT框架，模拟人类处理退化图像的思维链（CoT）过程，结合视觉与语言推理逐步生成更全面的文本和更高分辨率的图像。首次引入GRPO强化学习方法，设计四种奖励函数（格式、退化、理解和生成奖励）优化模型性能。

研究结果: 实验表明，RealSR-R1能够生成逼真的细节并准确理解图像内容，尤其在语义丰富或严重退化的场景中表现突出。

研究结论: RealSR-R1通过VLCoT框架和GRPO方法，显著提升了真实世界图像超分辨率任务的效果，为未来研究提供了新思路。

中文摘要: 真实世界图像超分辨率是图像恢复中最具挑战性的任务之一。然而，现有方法难以准确理解退化图像内容，导致重建结果低保真且不自然。本文提出RealSR-R1，通过结合视觉与语言推理的VLCoT框架，模拟人类处理退化图像的过程，逐步生成更全面的文本和更高分辨率的图像。为解决传统监督学习CoT在真实场景中泛化能力不足的问题，首次将GRPO引入真实世界图像超分辨率任务，并提出VLCoT-GRPO解决方案，设计了四种奖励函数：（1）格式奖励，用于标准化CoT过程；（2）退化奖励，激励准确估计退化程度；（3）理解奖励，确保生成内容的准确性；（4）生成奖励，通过视觉专家模型评估生成图像质量，鼓励模型生成更真实的图像。大量实验证明，RealSR-R1能够生成逼真的细节并准确理解图像内容，尤其在语义丰富或严重退化的场景中表现优异。

</details>


### [158] [Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation](https://arxiv.org/abs/2506.16802)
**中文标题：关注关键：基于法医导向增强的通用AI生成视频检测**

*Riccardo Corvi,Davide Cozzolino,Ekta Prashnani,Shalini De Mello,Koki Nagano,Luisa Verdoliva*

主要分类: cs.CV

摘要简述: 本文提出了一种基于法医导向增强的通用AI生成视频检测方法，通过识别生成架构引入的低级伪影而非依赖特定模型的高级语义缺陷，显著提升了检测器的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI生成视频技术快速发展，现有检测器泛化能力不足，难以区分真实视频与高分辨率合成视频。本文旨在通过识别生成模型的固有低级伪影，而非依赖特定模型的高级缺陷，提升检测器的通用性。

研究方法: 研究不同生成架构，识别跨模型的判别性特征；提出基于小波分解的法医导向数据增强策略，替换特定频带以引导模型利用更相关的法医线索。

研究结果: 在仅使用单一生成模型数据训练的情况下，该方法在多种其他生成模型（如NOVA和FLUX）上显著优于现有检测器，准确率显著提升。

研究结论: 通过法医导向增强策略，无需复杂算法或大规模多生成器数据集，即可显著提升AI生成视频检测器的泛化能力。

中文摘要: 合成视频生成技术发展迅速，最新模型可生成几乎无法与真实视频区分的高分辨率视频。尽管近期提出了一些视频法医检测器，但其泛化能力较差，限制了实际应用。本文的关键思路是引导检测器关注真正重要的特征。理想情况下，法医分类器应专注于识别生成架构引入的固有低级伪影，而非依赖特定模型的高级语义缺陷。本研究首先分析不同生成架构，寻找并识别跨模型的判别性特征；随后提出基于小波分解的法医导向数据增强策略，通过替换特定频带引导模型利用更相关的法医线索。这一新训练范式显著提升了AI生成视频检测器的泛化能力，且无需复杂算法或包含多生成器的大规模数据集。实验表明，仅使用单一生成模型数据训练的检测器，在多种其他模型（如NOVA和FLUX）生成的视频上表现优异，准确率显著优于现有方法。代码和数据将公开。

</details>


### [159] [Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes](https://arxiv.org/abs/2506.16805)
**中文标题：Co-VisiON：稀疏室内场景图像集的共视性推理**

*Chao Chen,Nobel Dang,Juexiao Zhang,Wenkai Sun,Pengfei Zheng,Xuhang He,Yimeng Ye,Taarun Srinivas,Chen Feng*

主要分类: cs.CV

摘要简述: 本文提出Co-VisiON基准测试，用于评估稀疏图像集中的共视性推理能力，发现现有视觉模型在稀疏条件下表现不佳，并提出新基线模型Covis，缩小与专有视觉语言模型的差距。


<details>
  <summary>详细信息</summary>
研究动机: 人类在稀疏分布的图像中识别共视性（多张图像中的重叠区域）的能力很强，但现有视觉模型在此任务上的表现尚不明确。本文旨在填补这一研究空白。

研究方法: 提出Co-VisiON基准测试，覆盖1000多个室内场景的稀疏图像集，并设计多视图基线模型Covis，模拟人类视觉认知。

研究结果: 实验显示，现有视觉模型在稀疏条件下的共视性推理表现较差，专有视觉语言模型表现最佳，但Covis在纯视觉模型中表现最优，缩小了与专有模型的差距。

研究结论: 共视性推理需要高层次的空间理解，现有模型仍需改进。Covis的表现表明多视图推理的重要性，未来研究应关注稀疏环境下的高级视觉推理。

中文摘要: 人类在稀疏分布的复杂场景图像中识别共视性（多张图像中的重叠区域）的能力非常突出，这是3D视觉和机器人感知的基础。尽管视觉学习取得了显著进展，但现有视觉模型是否达到人类水平的共视性分析能力尚不明确。本文提出Co-VisiON基准测试，用于直接评估1000多个室内场景稀疏图像集的共视性推理能力。实验表明，尽管共视性通常被视为低层次特征匹配任务，但在稀疏条件下对现有视觉模型仍具挑战性。值得注意的是，一种专有视觉语言模型的表现优于所有纯视觉方法，但所有模型与人类表现仍有显著差距。这一差距表明，共视性推理需要超越基本的成对视觉处理，通过多视图的高层次推理实现全面的空间理解。受人类视觉认知启发，我们提出新型多视图基线模型Covis，在纯视觉模型中表现最佳，并缩小了与专有视觉语言模型的差距。希望我们的基准测试和发现能推动开发在稀疏环境中具有鲁棒高层次推理能力的视觉模型。数据集和源代码见：https://ai4ce.github.io/CoVISION

</details>


### [160] [FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation](https://arxiv.org/abs/2506.16806)
**中文标题：FOCUS：基于参考分割的交互式编辑驱动的统一视觉语言建模**

*Fan Yang,Yousong Zhu,Xin Li,Yufei Zhan,Hongyin Zhao,Shurong Zheng,Yaowei Wang,Ming Tang,Jinqiao Wang*

主要分类: cs.CV

摘要简述: FOCUS是一种统一的视觉语言模型，将分割感知与可控生成结合，通过端到端框架实现多任务优化，显著提升视觉理解和生成能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型视觉语言模型在视觉理解和生成任务中存在割裂问题，分割与编辑任务分离且依赖多个独立模型。FOCUS旨在通过统一框架解决这些问题。

研究方法: FOCUS采用双分支视觉编码器捕捉全局语义和空间细节，结合MoVQGAN视觉分词器生成高质量视觉标记，并通过多阶段训练联合优化分割掩码与生成任务。

研究结果: 实验表明，FOCUS在多模态理解、参考分割精度和可控图像生成任务中表现优异，实现了视觉感知与生成能力的联合优化。

研究结论: FOCUS通过统一框架成功整合分割感知与可控生成，为视觉语言模型的多任务协同提供了有效解决方案。

中文摘要: 近期的大型视觉语言模型（LVLM）在统一视觉理解和生成建模方面展现出潜力，能够实现准确的内容理解和灵活的编辑。然而，当前方法将“看什么”和“如何编辑”分开处理：它们要么进行孤立的对象分割，要么仅将分割掩码作为局部编辑生成任务的条件提示，通常依赖多个不连贯的模型。为了弥补这些不足，我们提出了FOCUS，一种统一的LVLM，将分割感知的感知能力和可控的对象中心生成整合到一个端到端框架中。FOCUS采用双分支视觉编码器同时捕捉全局语义上下文和细粒度空间细节。此外，我们利用基于MoVQGAN的视觉分词器生成离散的视觉标记，以提升生成质量。为了实现准确且可控的图像编辑，我们提出了一种渐进式多阶段训练流程，其中分割掩码被联合优化并用作空间条件提示，以指导扩散解码器。这一策略对齐了视觉编码、分割和生成模块，有效连接了分割感知的感知与细粒度的视觉合成。在包括多模态理解、参考分割精度和可控图像生成在内的三项核心任务上的大量实验表明，FOCUS通过联合优化视觉感知和生成能力，实现了强劲的性能。

</details>


### [161] [Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection](https://arxiv.org/abs/2506.16819)
**中文标题：Loupe：一种通用且自适应的图像伪造检测框架**

*Yuchu Jiang,Jiaming Chu,Jian Zhao,Xin Zhang,Xu Yang,Lei Jin,Chi Zhang,Xuelong Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Loupe的轻量级框架，用于联合检测和定位图像伪造内容。Loupe通过整合补丁感知分类器和条件查询的分割模块，实现了全局真实性分类和细粒度掩码预测。实验表明，Loupe在DDL数据集上表现优异，并在IJCAI 2025挑战赛中取得第一名。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成模型的普及，视觉内容伪造问题日益严重。现有的深度伪造检测方法主要集中在图像级分类或像素级定位，但存在泛化能力不足或架构复杂的问题。本文旨在提出一种轻量且通用的框架，以解决这些问题。

研究方法: Loupe框架结合了补丁感知分类器和带有条件查询的分割模块，能够同时进行全局分类和细粒度定位。此外，Loupe引入了伪标签引导的测试时适应机制，利用补丁级预测优化分割模块，提升对分布变化的鲁棒性。

研究结果: 在DDL数据集上的广泛实验表明，Loupe实现了最先进的性能，在IJCAI 2025挑战赛中以0.846的总分获得第一名。结果验证了补丁级融合和条件查询设计在提升分类和定位精度方面的有效性。

研究结论: Loupe通过创新的补丁级融合和条件查询设计，显著提升了图像伪造检测和定位的性能。其轻量级架构和测试时适应机制使其在多样化伪造模式中表现优异。

中文摘要: 生成模型的普及引发了关于视觉内容伪造的严重担忧。现有的深度伪造检测方法主要针对图像级分类或像素级定位。虽然某些方法取得了高准确率，但它们通常面临对多种伪造类型泛化能力有限或依赖复杂架构的问题。本文提出Loupe，一种轻量级但有效的框架，用于联合深度伪造检测和定位。Loupe整合了补丁感知分类器和带有条件查询的分割模块，能够同时进行全局真实性分类和细粒度掩码预测。为了增强对测试集分布变化的鲁棒性，Loupe引入了伪标签引导的测试时适应机制，利用补丁级预测监督分割头。在DDL数据集上的大量实验表明，Loupe实现了最先进的性能，并在IJCAI 2025深度伪造检测与定位挑战赛中以0.846的总分获得第一名。我们的结果验证了所提出的补丁级融合和条件查询设计在多样化伪造模式下提升分类准确性和空间定位的有效性。代码可在https://github.com/Kamichanw/Loupe获取。

</details>


### [162] [Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots](https://arxiv.org/abs/2506.16821)
**中文标题：自监督特征提取在足球机器人球检测中的增强应用**

*Can Lin,Daniele Affinita,Marco E. P. Zimmatore,Daniele Nardi,Domenico D. Bloisi,Vincenzo Suriani*

主要分类: cs.CV

摘要简述: 本文提出了一种自监督学习框架，通过伪标签和多种自监督任务（如着色、边缘检测和三元组损失）提升足球机器人中球的检测性能，无需依赖人工标注，并引入MAML策略快速适应新场景。实验表明该方法在准确率、F1分数和IoU上均优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 传统监督学习方法在足球机器人球检测中需要大量人工标注，成本高且耗时。为解决这一问题，本文探索自监督学习以减少对标注数据的依赖，并提升在动态环境中的检测性能。

研究方法: 提出一种自监督学习框架，利用预训练模型生成伪标签，结合着色、边缘检测和三元组损失等自监督任务学习鲁棒特征。同时引入MAML策略，确保模型在新场景中快速适应。

研究结果: 实验结果表明，该方法在准确率、F1分数和IoU上均优于基线模型，且收敛速度更快。同时，公开了一个包含10,000张标注图像的户外RoboCup SPL比赛数据集。

研究结论: 本文提出的自监督学习框架显著提升了足球机器人球检测的性能，减少了人工标注需求，并通过MAML策略增强了模型的适应性。

中文摘要: 鲁棒且准确的球检测是自主人形足球机器人的关键组成部分，尤其是在动态和具有挑战性的环境中，如RoboCup户外场地。然而，传统的监督方法需要大量人工标注，成本高且耗时。为解决这一问题，我们提出了一种自监督学习框架，通过领域自适应特征提取提升球检测性能。该方法利用通用预训练模型生成伪标签，并通过着色、边缘检测和三元组损失等自监督任务学习鲁棒视觉特征，无需依赖人工标注。此外，结合模型无关元学习（MAML）策略，确保在最小监督下快速适应新部署场景。我们引入了一个包含10,000张户外RoboCup SPL比赛标注图像的新数据集，用于验证方法并公开给社区。实验结果表明，所提出的方法在准确率、F1分数和IoU上均优于基线模型，且收敛速度更快。

</details>


### [163] [AnyTraverse: An off-road traversability framework with VLM and human operator in the loop](https://arxiv.org/abs/2506.16826)
**中文标题：AnyTraverse：一种结合VLM与人类操作员的越野可通行性框架**

*Sattwik Sahu,Agamdeep Singh,Karthik Nambiar,Srikanth Saripalli,P. B. Sujit*

主要分类: cs.CV

摘要简述: AnyTraverse是一个结合自然语言提示与人类操作员辅助的越野可通行性框架，通过零样本学习减少主动监督需求，适应多样化机器人平台和复杂户外场景。


<details>
  <summary>详细信息</summary>
研究动机: 当前越野可通行性分割框架在非结构化环境中表现不佳，且无法适应不同类型的机器人。AnyTraverse旨在解决这些问题，通过结合自然语言提示和人类操作员辅助，提升系统的适应性和实用性。

研究方法: AnyTraverse利用自然语言提示分割场景，仅在遇到未探索区域或未知类别时调用人类操作员。采用零样本学习方法，无需大量数据收集或重新训练。

研究结果: 实验验证表明，AnyTraverse在RELLIS-3D、Freiburg Forest和RUGD数据集上表现优于GA-NAV和Off-seg，并在多种机器人平台上成功部署。

研究结论: AnyTraverse提供了一种车辆无关的越野可通行性解决方案，平衡了自动化与针对性人工监督，适用于多样化户外场景。

中文摘要: 越野可通行性分割支持自主导航，应用于搜救、军事行动、野生动物探索和农业等领域。现有框架因非结构化环境的显著变化和不确定场景变化而表现不佳，且无法适应不同类型的机器人。我们提出了AnyTraverse，一种结合自然语言提示与人类操作员辅助的框架，用于确定多样化机器人车辆的可通行区域。该系统根据给定提示分割场景，仅在遇到未探索区域或未知类别时调用操作员，从而减少主动监督负担，同时适应多变的户外场景。我们的零样本学习方法无需大量数据收集或重新训练。实验验证包括在RELLIS-3D、Freiburg Forest和RUGD数据集上的测试，并在多种机器人平台上进行了实际部署。结果表明，AnyTraverse的性能优于GA-NAV和Off-seg，同时提供了一种车辆无关的越野可通行性方法，平衡了自动化与针对性人工监督。

</details>


### [164] [Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model](https://arxiv.org/abs/2506.16842)
**中文标题：基于圆形标定板的相机标定：一种包含测量不确定性和无偏投影模型的综合框架**

*Chaehyeon Song,Dongjae Lee,Jongwoo Lim,Ayoung Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种基于圆形标定板的无偏投影模型，通过引入圆心不确定性提升相机标定的精度和鲁棒性，显著优于传统棋盘格方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的圆形标定板投影模型在镜头畸变下存在偏差，导致标定性能不佳。为解决这一问题，作者提出了一种无偏的圆形标定板投影模型，并通过引入圆心不确定性进一步提升标定效果。

研究方法: 作者提出了一种无偏的圆形标定板投影模型，并通过建模二维形状边界点为马尔可夫随机场，结合格林定理将形状分布传播到圆心不确定性中，从而优化标定的检测、优化和评估环节。

研究结果: 实验表明，该方法在标定精度和鲁棒性上显著优于传统棋盘格方法，并通过引入不确定性进一步提升了标定组件的性能。

研究结论: 本文提出的无偏投影模型和不确定性建模方法显著提升了相机标定的精度和鲁棒性，为高质量标定提供了实用指南。

中文摘要: 使用平面标定板的相机标定方法广受欢迎，其中主要使用两种控制点作为测量基准：棋盘格的角点和圆形的圆心。由于圆心是从大量像素中计算得出的，圆形标定板比棋盘格提供了更精确的测量。然而，现有的圆心投影模型在镜头畸变下存在偏差，导致性能不佳。为克服这一限制，我们提出了一种无偏的圆形标定板投影模型，并证明其精度优于棋盘格。此外，我们通过引入圆形标定板的不确定性来增强标定的鲁棒性和完整性。定义圆心不确定性优化了标定组件的性能，包括标定板检测、优化和评估指标。我们还基于评估指标提供了高质量相机标定的实用指南。该方法的核心思想是将二维形状的边界点建模为马尔可夫随机场，并考虑其连通性。通过基于格林定理的适当形状表示，形状分布被传播到圆心不确定性中。最终，该框架显著提升了标定的精度和鲁棒性。完整的源代码和演示视频可在https://github.com/chaehyeonsong/discocal获取。

</details>


### [165] [Controllable and Expressive One-Shot Video Head Swapping](https://arxiv.org/abs/2506.16852)
**中文标题：可控且富有表现力的一次性视频头部替换**

*Chaonan Ji,Jinwei Qi,Peng Zhang,Bang Zhang,Liefeng Bo*

主要分类: cs.CV

摘要简述: 本文提出了一种基于扩散模型的多条件可控视频头部替换框架，能够将静态图像中的人头无缝移植到动态视频中，同时保留目标视频的身体和背景，并支持对头部表情和动作进行编辑。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸替换方法主要关注局部面部替换，忽略了整体头部形态；而头部替换方法则难以处理多样化的发型和复杂背景，且均不支持用户对替换后的头部表情进行修改。本文旨在解决这些问题。

研究方法: 1) 身份保留上下文融合：提出形状无关的掩码策略，明确分离前景头部身份特征与背景/身体上下文，结合头发增强策略实现多样化发型和复杂背景下的头部身份保留。2) 表情感知地标重定向与编辑：提出解耦的3DMM驱动重定向模块，分离身份、表情和头部姿态，最小化输入图像中原有表情的影响，并支持表情编辑。

研究结果: 实验结果表明，该方法在无缝背景融合和源肖像身份保留方面表现优异，同时展示了适用于真实和虚拟角色的卓越表情迁移能力。

研究结论: 本文提出的方法通过创新的策略解决了现有头部替换技术的局限性，实现了高精度的头部替换和表情编辑，为视频头部替换提供了新的解决方案。

中文摘要: 本文提出了一种新颖的基于扩散模型的多条件可控框架，用于视频头部替换，能够将静态图像中的人头无缝移植到动态视频中，同时保留目标视频的身体和背景，并允许根据需要调整头部表情和动作。现有的人脸替换方法主要关注局部面部替换，忽略了整体头部形态；而头部替换方法则难以处理多样化的发型和复杂背景，且均不支持用户对替换后的头部表情进行修改。为解决这些问题，我们的方法通过统一的潜在扩散范式整合了多项创新策略：1) 身份保留上下文融合：提出形状无关的掩码策略，明确分离前景头部身份特征与背景/身体上下文，结合头发增强策略实现多样化发型和复杂背景下的头部身份保留。2) 表情感知地标重定向与编辑：提出解耦的3DMM驱动重定向模块，分离身份、表情和头部姿态，最小化输入图像中原有表情的影响，并支持表情编辑。实验结果表明，我们的方法在无缝背景融合和源肖像身份保留方面表现优异，同时展示了适用于真实和虚拟角色的卓越表情迁移能力。

</details>


### [166] [ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control](https://arxiv.org/abs/2506.16856)
**中文标题：ParkFormer：一种基于Transformer的泊车策略，融合目标嵌入与行人感知控制**

*Jun Fu,Bin Tian,Haonan Chen,Shi Meng,Tingting Yao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer的端到端自动泊车框架ParkFormer，通过目标嵌入和行人感知控制，在复杂环境中实现高精度泊车。实验表明，模型在CARLA模拟器中成功率达96.57%，位置和方向误差分别为0.21米和0.41度。


<details>
  <summary>详细信息</summary>
研究动机: 传统基于规则的泊车系统在复杂或动态环境中适应性不足，而人类驾驶员却能凭直觉泊车。受此启发，作者提出了一种从专家演示中学习的Transformer框架，以提升自动泊车系统的适应性和安全性。

研究方法: ParkFormer采用Transformer架构，输入包括环视摄像头图像、目标点表示、车辆运动状态和行人轨迹，输出离散控制序列（如油门、刹车、转向和挡位选择）。通过交叉注意力模块融合鸟瞰图特征与目标点，并利用GRU行人预测器增强动态障碍物建模。

研究结果: 在CARLA 0.9.14模拟器中测试，模型在垂直和平行泊车场景中成功率达96.57%，平均位置误差0.21米，方向误差0.41度。消融实验验证了行人预测和目标点注意力融合模块的有效性。

研究结论: ParkFormer通过结合目标嵌入和行人感知控制，显著提升了自动泊车的成功率和精度，为复杂环境下的智能泊车提供了有效解决方案。

中文摘要: 自动泊车在智能车辆系统中至关重要，尤其是在需要高精度控制的复杂城市环境中。传统基于规则的泊车系统难以应对环境不确定性，而人类驾驶员却能凭直觉泊车。受此启发，我们提出了一种基于Transformer的端到端自动泊车框架，通过学习专家演示实现智能泊车。网络输入包括环视摄像头图像、目标点表示、车辆运动状态和行人轨迹，输出离散控制序列（如油门、刹车、转向和挡位选择）。通过新颖的交叉注意力模块融合鸟瞰图特征与目标点，并利用GRU行人预测器增强动态障碍物建模。我们在CARLA 0.9.14模拟器中验证了该方法，在垂直和平行泊车场景中，模型成功率达96.57%，平均位置和方向误差分别为0.21米和0.41度。消融实验进一步证明了行人预测和目标点注意力融合模块的有效性。代码和数据集将在https://github.com/little-snail-f/ParkFormer发布。

</details>


### [167] [With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You](https://arxiv.org/abs/2506.16895)
**中文标题：多模态对齐数据有限时，让STRUCTURE引导你**

*Fabian Gröger,Shuo Wen,Huyen Le,Maria Brbić*

主要分类: cs.CV

摘要简述: 本文提出了一种名为STRUCTURE的正则化技术，通过对齐预训练的单模态基础模型，在有限配对数据下实现高质量多模态对齐，显著提升了零样本分类和跨模态检索任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态模型通常依赖数百万配对样本，但在许多领域获取这些数据成本高昂或不可行。本文探索在有限配对数据下构建多模态模型的可行性。

研究方法: 引入STRUCTURE正则化技术，保留单模态编码器潜在空间的邻域几何结构，并优化对齐层选择，选择跨模态表示相似性最高的层进行对齐。

研究结果: 在24个零样本图像分类和检索基准测试中，平均相对提升51.6%（分类）和91.8%（检索），仅需数万配对样本即可实现高质量对齐。

研究结论: STRUCTURE框架在有限样本多模态学习中表现出高效性和广泛适用性，为资源受限领域提供了可行路径。

中文摘要: 多模态模型在需要多模态对齐的复杂任务（如零样本分类和跨模态检索）中展现出强大能力。然而，现有模型通常依赖数百万配对多模态样本，这在许多领域中成本过高或难以获取。本研究探索了通过对齐预训练单模态基础模型，在有限配对数据下构建多模态模型的可行性。研究表明，仅需数万配对样本（少于该领域通常使用数据的1%）即可实现高质量对齐。为此，我们提出STRUCTURE，一种有效的正则化技术，能够保留单模态编码器潜在空间的邻域几何结构。此外，我们发现仅对齐最后一层通常效果不佳，并展示了选择跨模态表示相似性最高的层进行对齐的优势。这两项技术可轻松整合到现有对齐方法中，在24个零样本图像分类和检索基准测试中取得显著提升，分类任务平均相对提升51.6%，检索任务提升91.8%。我们的结果突显了STRUCTURE框架在有限样本多模态学习中的高效性和广泛适用性，为资源受限领域提供了可行路径。

</details>


### [168] [LunarLoc: Segment-Based Global Localization on the Moon](https://arxiv.org/abs/2506.16940)
**中文标题：LunarLoc：基于分割的月球全局定位方法**

*Annika Thomas,Robaire Galliath,Aleksander Garbuz,Luke Anger,Cormac O'Neill,Trevor Johst,Dami Thomas,George Lordos,Jonathan P. How*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LunarLoc的月球全局定位方法，利用实例分割提取岩石地标，并通过图论数据关联实现高精度、无漂移的定位，显著优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 在月球表面，传统的地球导航基础设施（如GPS）不可用，而自主操作（如机器人探索和基础设施部署）需要精确的姿态估计。现有方法（如视觉惯性里程计）在长距离移动中会积累漂移误差，因此需要一种新的全局定位方法。

研究方法: LunarLoc通过实例分割从立体图像中零样本提取岩石地标，构建基于图的场景表示，并与参考地图进行图论数据关联，实现高精度全局定位。

研究结果: 实验表明，LunarLoc在多会话全局定位中达到亚厘米级精度，显著优于现有月球全局定位技术。

研究结论: LunarLoc为月球自主任务提供了一种高精度、无漂移的全局定位解决方案，并公开数据集以促进进一步研究。

中文摘要: 全局定位是月球表面自主操作的必要条件，因为传统的地球导航基础设施（如GPS）在月球上不可用。随着NASA在Artemis计划下推进持续的月球存在，自主操作将成为机器人探索和基础设施部署等任务的重要组成部分。例如，挖掘和运输月壤等任务需要精确的姿态估计，但现有方法（如视觉惯性里程计）在长距离移动中会积累漂移误差。对于即将到来的任务（如ISRU Pilot Excavator，IPEx），精确的姿态估计尤为重要，因为这些任务依赖自主代理在长时间和复杂地形中运行。为了克服长距离移动中的漂移问题，我们提出LunarLoc，一种利用实例分割从立体图像中零样本提取岩石地标的全局定位方法。通过分割检测构建基于图的场景表示，并与参考地图进行图论数据关联，实现了在视觉模糊环境中的高精度、无漂移全局定位。实验表明，LunarLoc在多会话全局定位中达到亚厘米级精度，显著优于现有技术。为了促进月球全局定位方法的进一步发展，我们公开了数据集和回放模块：https://github.com/mit-acl/lunarloc-data。

</details>


### [169] [LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models](https://arxiv.org/abs/2506.16950)
**中文标题：LAION-C：面向网络规模视觉模型的分布外基准**

*Fanfei Li,Thomas Klein,Wieland Brendel,Robert Geirhos,Roland S. Zimmermann*

主要分类: cs.CV

摘要简述: 本文提出LAION-C作为ImageNet-C的替代基准，专门设计六种新型失真类型以评估网络规模数据集下的模型OOD鲁棒性，发现当代模型（如Gemini和GPT-4o）面临显著挑战，且最佳模型已接近或超越人类表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有OOD基准（如ImageNet-C）在网络规模数据集时代已不再适用，因为其失真类型可能已被训练数据覆盖，导致模型表现饱和。需要新的基准以准确评估模型在真实OOD场景下的鲁棒性。

研究方法: 提出LAION-C基准，包含六种新型失真类型，确保其相对于网络规模数据集（如LAION）的OOD特性。通过评估前沿模型（包括MLLMs）并进行心理物理实验，比较模型与人类在失真数据上的表现。

研究结果: LAION-C对当代模型（如Gemini和GPT-4o）构成显著挑战。实验显示，最佳模型已接近或超越人类在失真数据上的表现，标志着OOD泛化能力的范式转变。

研究结论: LAION-C为网络规模数据集时代提供了更准确的OOD鲁棒性评估工具，揭示了模型在真实OOD场景下的表现，并表明前沿模型已开始超越人类。

中文摘要: 分布外（OOD）鲁棒性是计算机视觉模型的理想特性。提升模型鲁棒性需要高质量的基准信号以量化进展。尽管在ImageNet时代提出了多种基准数据集（如ImageNet-C），但其大多数失真类型在网络规模数据集中已不再属于OOD，因为这些数据集已包含常见失真（如模糊或JPEG压缩伪影）。因此，这些基准不再适用于评估网络规模数据集时代的OOD鲁棒性。近期模型在ImageNet时代的OOD基准上表现饱和，表明无法确定模型是否真正提升了OOD泛化能力，或仅仅在训练中接触了测试失真。为此，我们提出LAION-C作为ImageNet-C的替代基准。LAION-C包含六种新型失真类型，专门设计为即使对LAION等网络规模数据集仍为OOD。在对前沿模型的全面评估中，我们发现LAION-C对当代模型（如Gemini和GPT-4o）构成显著挑战。我们还进行了心理物理实验以评估失真对人类观察者的难度，从而比较模型与实验室质量的人类鲁棒性数据。我们观察到OOD泛化的范式转变：从人类优于模型，到最佳模型现已接近或超越最佳人类观察者。

</details>


### [170] [Visual-Instructed Degradation Diffusion for All-in-One Image Restoration](https://arxiv.org/abs/2506.16960)
**中文标题：基于视觉指导退化扩散的全能图像修复**

*Wenyang Luo,Haina Qin,Zewen Chen,Libin Wang,Dandan Zheng,Yuming Li,Yufan Liu,Bing Li,Weiming Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Defusion的全能图像修复框架，通过视觉指导的退化扩散技术，解决了传统方法需针对不同退化类型设计独立模型的问题，显著提升了复杂和真实场景下的图像修复性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像修复任务（如去模糊、去噪、去雾）通常需要为每种退化类型设计独立模型，限制了其在混合或未知退化场景中的泛化能力。本文旨在提出一种统一框架，能够适应多种退化类型，提升修复效果。

研究方法: Defusion框架通过构建明确的视觉指令，捕捉退化特征而不依赖图像语义。这些指令基于标准化视觉元素的退化应用，随后用于指导基于扩散的模型在退化空间中直接操作，通过去噪退化效应重建高质量图像。

研究结果: 实验表明，Defusion在多种图像修复任务（包括复杂和真实场景退化）中均优于现有最先进方法，表现出更高的稳定性和泛化能力。

研究结论: Defusion通过视觉指导的退化扩散技术，实现了全能图像修复，为复杂和未知退化场景提供了一种高效解决方案。

中文摘要: 图像修复任务（如去模糊、去噪、去雾）通常需要为每种退化类型设计独立模型，这限制了其在混合或未知退化场景中的泛化能力。本文提出了一种名为Defusion的全能图像修复框架，利用视觉指导的退化扩散技术。与现有方法依赖任务特定模型或模糊的文本先验不同，Defusion构建了明确的视觉指令，这些指令与视觉退化模式对齐。这些指令通过将退化应用于标准化视觉元素来构建，捕捉了内在退化特征而不依赖图像语义。Defusion随后使用这些视觉指令指导基于扩散的模型，直接在退化空间中操作，通过去噪退化效应重建高质量图像，具有更高的稳定性和泛化能力。综合实验表明，Defusion在多种图像修复任务（包括复杂和真实场景退化）中均优于现有最先进方法。

</details>


### [171] [Reversing Flow for Image Restoration](https://arxiv.org/abs/2506.16961)
**中文标题：逆向流用于图像恢复**

*Haina Qin,Wenyang Luo,Libin Wang,Dandan Zheng,Jingdong Chen,Ming Yang,Bing Li,Weiming Hu*

主要分类: cs.CV

摘要简述: 本文提出ResFlow，一种基于连续归一化流的图像恢复框架，通过确定性路径建模退化过程，显著提升恢复性能与速度，仅需少于4步采样即可完成任务。


<details>
  <summary>详细信息</summary>
研究动机: 现有生成模型（如扩散模型和基于分数的模型）将退化过程视为随机变换，导致效率低下和复杂性增加。本文旨在提出一种更高效、更简单的图像恢复方法。

研究方法: ResFlow将退化过程建模为确定性路径，并通过辅助过程消除高质量图像预测的不确定性。采用熵保持流路径，并通过匹配速度场学习增强的退化流。

研究结果: ResFlow在多个图像恢复基准测试中取得最先进的结果，且仅需少于4步采样即可完成任务，显著提升了性能和速度。

研究结论: ResFlow为图像恢复提供了一种实用且高效的解决方案，适用于实际应用场景。

中文摘要: 图像恢复旨在通过逆转退化效应，从低质量（LQ）图像中恢复高质量（HQ）图像。现有的生成模型（如扩散模型和基于分数的模型）通常将退化过程视为随机变换，这引入了低效性和复杂性。本文提出ResFlow，一种新颖的图像恢复框架，利用连续归一化流将退化过程建模为确定性路径。ResFlow通过辅助过程增强退化过程，以消除高质量图像预测中的不确定性，从而实现退化过程的可逆建模。ResFlow采用熵保持流路径，并通过匹配速度场学习增强的退化流。ResFlow显著提升了图像恢复的性能和速度，仅需少于4步采样即可完成任务。大量实验表明，ResFlow在多种图像恢复基准测试中取得了最先进的结果，为实际应用提供了一种实用且高效的解决方案。

</details>


### [172] [Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs](https://arxiv.org/abs/2506.16962)
**中文标题：提升多模态大语言模型中的逐步可验证医学推理能力**

*Haoran Sun,Yankai Jiang,Wenjie Lou,Yujie Zhang,Wenjie Li,Lilong Wang,Mianxin Liu,Lei Liu,Xiaosong Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MICS的新方法，用于生成高质量的医学推理路径数据，并构建了多任务医学推理数据集MMRP和新型医学MLLM模型Chiron-o1，显著提升了医学视觉问答和推理任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型（MLLMs）在通用任务中展现出强大的推理能力，但其在医学领域的应用仍处于早期阶段。现有方法缺乏对关键诊断的有效推理路径的全面搜索和评估框架，因此需要一种更系统的方法来生成高质量的医学推理数据。

研究方法: 本文提出Mentor-Intern Collaborative Search（MICS）方法，通过导师模型逐步初始化推理路径，再由多个实习生模型继续推理，并根据MICS-Score选择最优路径。最终构建了多任务医学推理数据集MMRP和基于课程学习策略的医学MLLM模型Chiron-o1。

研究结果: 实验表明，基于MICS生成的推理数据训练的Chiron-o1在多个医学视觉问答和推理基准测试中达到了最先进的性能。

研究结论: MICS方法能够有效生成高质量的医学推理数据，Chiron-o1模型的成功验证了其在医学领域的强大推理能力，为医学MLLMs的发展提供了新方向。

中文摘要: 多模态大语言模型（MLLMs）在通用任务中已展现出强大的推理能力，但其在医学领域的应用仍处于早期阶段。构建链式思维（CoT）训练数据对于增强医学MLLMs的推理能力至关重要。然而，现有方法在搜索和评估关键诊断的有效推理路径方面缺乏全面框架。为解决这一问题，我们提出了Mentor-Intern Collaborative Search（MICS），一种新颖的推理路径搜索方案，用于生成严谨且有效的医学CoT数据。MICS首先利用导师模型逐步初始化推理路径，随后提示每个实习生模型沿这些路径继续思考，最终根据多个实习生模型的整体推理性能选择最优路径。推理性能由MICS-Score评估生成路径的质量。最终，我们构建了MMRP（一个按难度排序的多任务医学推理数据集）和Chiron-o1（一种通过课程学习策略设计的新型医学MLLM），具备强大的视觉问答和泛化推理能力。大量实验表明，基于MICS构建的CoT数据集训练的Chiron-o1在一系列医学视觉问答和推理基准测试中达到了最先进的性能。代码可在GitHub - manglu097/Chiron-o1获取。

</details>


### [173] [ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds](https://arxiv.org/abs/2506.16991)
**中文标题：ForestFormer3D：一种端到端的森林LiDAR 3D点云分割统一框架**

*Binbin Xiang,Maciej Wielgosz,Stefano Puliti,Kamil Král,Martin Krůček,Azim Missarov,Rasmus Astrup*

主要分类: cs.CV

摘要简述: ForestFormer3D是一个端到端的统一框架，用于森林LiDAR 3D点云的精确分割，包括单株树和语义分割，在复杂自然环境中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 森林LiDAR 3D点云的分割对森林管理和生态研究至关重要，但现有方法难以应对自然环境的复杂性和多样性。

研究方法: ForestFormer3D结合了ISA引导的查询点选择、基于分数的块合并策略和一对多关联训练机制，实现了高效的点云分割。

研究结果: 模型在FOR-instanceV2数据集上实现了单株树分割的最优性能，并在未见过的测试集（Wytham woods和LAUTx）上表现出良好的泛化能力。

研究结论: ForestFormer3D为森林点云分割提供了高效且鲁棒的解决方案，未来将公开数据集和代码。

中文摘要: 森林LiDAR 3D点云的分割（包括单株树和语义分割）是推动森林管理和生态研究的基础。然而，现有方法往往难以应对自然森林环境的复杂性和多样性。我们提出了ForestFormer3D，一种新的端到端统一框架，旨在实现精确的单株树和语义分割。ForestFormer3D结合了ISA引导的查询点选择、推理过程中基于分数的块合并策略以及一对多关联训练机制。通过这些新组件的结合，我们的模型在新推出的FOR-instanceV2数据集上实现了单株树分割的最优性能，该数据集覆盖了多种森林类型和区域。此外，ForestFormer3D在未见过的测试集（Wytham woods和LAUTx）上表现出良好的泛化能力，展示了其在不同森林条件和传感器模式下的鲁棒性。FOR-instanceV2数据集和ForestFormer3D代码将很快发布。

</details>


### [174] [Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments](https://arxiv.org/abs/2506.16994)
**中文标题：Prmpt2Adpt：基于提示的资源受限环境零样本域适应**

*Yasir Ali Farrukh,Syed Wali,Irfan Khan,Nathaniel D. Bastian*

主要分类: cs.CV

摘要简述: Prmpt2Adpt提出了一种轻量级零样本域适应框架，通过提示驱动的特征对齐和师生范式，在资源受限环境中实现高效域适应，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在资源受限环境（如无人机）中，现有无监督域适应方法依赖大型视觉语言模型且需访问源域数据，限制了其适用性。Prmpt2Adpt旨在解决这一问题。

研究方法: 基于师生范式，使用蒸馏和微调的CLIP模型作为Faster R-CNN教师的冻结骨干，通过提示驱动实例归一化（PIN）对齐少量源特征到目标域语义，生成高质量伪标签指导紧凑学生模型实时适应。

研究结果: 在MDS-A数据集上，Prmpt2Adpt检测性能与最先进方法相当，同时适应速度快7倍，推理速度快5倍，仅需少量源图像。

研究结论: Prmpt2Adpt为低资源领域提供了一种实用且可扩展的实时适应解决方案，显著提升了效率和性能。

中文摘要: 无监督域适应（UDA）是现实世界视觉系统中的关键挑战，尤其是在资源受限环境（如无人机）中，内存和计算能力有限。现有的提示驱动UDA方法通常依赖大型视觉语言模型，并在适应过程中需要完全访问源域数据，限制了其适用性。本文提出Prmpt2Adpt，一种轻量级高效的零样本域适应框架，围绕提示驱动的特征对齐和师生范式构建。我们的方法核心是一个蒸馏和微调的CLIP模型，用作Faster R-CNN教师的冻结骨干。少量低级源特征通过提示驱动实例归一化（PIN）对齐到仅通过自然语言提示指定的目标域语义。这些语义引导的特征用于简要微调教师模型的检测头。适应后的教师生成高质量伪标签，指导紧凑学生模型的实时适应。在MDS-A数据集上的实验表明，Prmpt2Adpt的检测性能与最先进方法相当，同时适应速度快7倍，推理速度快5倍，仅需少量源图像，使其成为低资源领域中实用且可扩展的实时适应解决方案。

</details>


### [175] [A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X Autonomous Driving](https://arxiv.org/abs/2506.17004)
**中文标题：V2X自动驾驶中协作3D语义占据预测的合成基准**

*Hanlin Wu,Pengfei Lin,Ehsan Javanmardi,Naren Bao,Bo Qian,Hao Si,Manabu Tsukada*

主要分类: cs.CV

摘要简述: 本文提出了一种用于V2X自动驾驶中协作3D语义占据预测的合成基准，通过增强现有数据集并在CARLA中重放以提供密集注释，同时开发了基线模型，实验表明其优于单智能体模型。


<details>
  <summary>详细信息</summary>
研究动机: 单车的感知能力受限于遮挡、传感器范围和视角狭窄，协作感知能通过信息交换提升完整性和准确性，但缺乏专门的数据集和基准。

研究方法: 通过CARLA重放现有协作感知数据集，提供高分辨率语义体素注释，并设计不同预测范围的基准，开发了基于空间对齐和注意力聚合的基线模型。

研究结果: 基线模型在实验中始终优于单智能体模型，且随着预测范围扩大，性能提升更显著。

研究结论: 协作3D语义占据预测能有效提升自动驾驶感知能力，本文提出的基准和模型为未来研究提供了基础。

中文摘要: 3D语义占据预测是自动驾驶中的新兴感知范式，提供体素级的几何细节和语义类别表示。然而，单车感知能力受限于遮挡、传感器范围和狭窄视角。协作感知通过互补信息交换提升完整性和准确性。由于缺乏协作3D语义占据预测的专用数据集，我们在CARLA中重放现有协作感知数据集，并提供高分辨率语义体素传感器以生成密集注释。此外，我们设计了不同预测范围的基准，系统评估空间范围对协作预测的影响。我们还开发了基于空间对齐和注意力聚合的基线模型。实验结果表明，基线模型始终优于单智能体模型，且随着预测范围扩大，性能提升更显著。

</details>


### [176] [Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns](https://arxiv.org/abs/2506.17027)
**中文标题：基于真实世界退化模式的无监督图像超分辨率重建**

*Yiyang Tie,Hong Zhu,Yunyun Luo,Jing Shi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于真实世界退化模式的无监督图像超分辨率重建方法，通过TripleGAN框架有效学习退化模式并生成对齐数据集，显著提升了超分辨率重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 真实世界超分辨率重建模型的训练依赖于反映真实退化模式的数据集，但仅从低分辨率图像中提取和建模退化模式仍具挑战性。现有方法难以同时捕捉模糊、噪声和隐式退化（如色域偏移），且合成数据与真实数据间的退化域差距较大。

研究方法: 提出TripleGAN框架：FirstGAN专注于缩小模糊特征的域差距，SecondGAN进行域特定翻译以学习目标域模糊特性和其他退化模式，ThirdGAN基于前两者生成的伪真实数据重建真实低分辨率图像。

研究结果: 在RealSR和DRealSR数据集上的实验表明，该方法在定量指标上具有明显优势，且重建图像清晰无过平滑伪影。

研究结论: 该框架能有效从低分辨率图像中学习真实退化模式，并生成对齐数据集，从而显著提升超分辨率重建性能。

中文摘要: 真实世界超分辨率重建模型的训练高度依赖于反映真实退化模式的数据集。仅使用真实世界低分辨率（LR）图像提取和建模退化模式仍是一项挑战性任务。在合成数据集以模拟真实退化时，仅依赖退化提取方法无法同时捕捉模糊和多样化的噪声特性，以及更隐式的退化（如色域偏移）。而仅通过域翻译方法则因合成数据与真实数据间显著的退化域差距，无法准确逼近真实模糊特性。为解决这些问题，我们提出了一种新颖的TripleGAN框架，包含两个策略性设计的组件：FirstGAN主要专注于缩小模糊特征的域差距，SecondGAN执行域特定翻译以逼近目标域模糊特性并学习其他退化模式。ThirdGAN则基于FirstGAN和SecondGAN生成的伪真实数据训练，以重建真实世界LR图像。在RealSR和DRealSR数据集上的大量实验表明，我们的方法在定量指标上具有明显优势，同时保持清晰重建而无过平滑伪影。所提框架能有效从LR观测中学习真实退化模式，并合成具有对应退化特性的对齐数据集，从而使训练网络在从真实世界LR输入重建高质量SR图像时表现卓越。

</details>


### [177] [Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance](https://arxiv.org/abs/2506.17040)
**中文标题：超越显而易见：一种无梯度框架揭示视觉不变性的隐藏景观**

*Lorenzo Tausani,Paolo Muratore,Morgan B. Talbot,Giacomo Amerio,Gabriel Kreiman,Davide Zoccolan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Stretch-and-Squeeze（SnS）的无偏、模型无关且无需梯度的框架，用于系统表征视觉单元的不变性景观及其对对抗性扰动的脆弱性。SnS通过双目标优化问题揭示图像变换，应用于卷积神经网络（CNN）时，发现其生成的图像变化比仿射变换更远离参考图像，同时更有效地保留目标单元的响应。


<details>
  <summary>详细信息</summary>
研究动机: 现有特征可视化方法通常只能推断单元最兴奋的图像，但无法揭示响应保持不变的变换流形，而这对于视觉泛化至关重要。本文旨在填补这一空白，提出一种新方法来系统研究视觉单元的不变性及其对抗性敏感性。

研究方法: SnS框架将图像变换建模为双目标优化问题：1）为探究不变性，寻找能最大程度改变参考刺激表示但保留单元激活的图像扰动；2）为探究对抗性敏感性，寻找能最小程度改变刺激但抑制单元激活的扰动。该方法无需梯度，适用于生物和人工视觉系统。

研究结果: 应用于CNN时，SnS生成的图像变化在像素空间上比仿射变换更远离参考图像，同时更有效地保留目标单元的响应。研究发现，优化过程中使用的图像表示选择显著影响不变性图像的性质：像素级变化主要影响亮度和对比度，而拉伸中、晚期CNN表示则分别改变纹理和姿态。此外，来自鲁棒网络的不变性图像对人类观察者更具可识别性。

研究结论: SnS框架为揭示视觉单元的不变性景观及其对抗性敏感性提供了一种系统且无偏的方法。研究结果表明，鲁棒CNN作为视觉系统模型具有更高的保真度，其生成的不变性图像更易于人类识别。

中文摘要: 揭示高级视觉单元编码的特征组合对于理解图像如何转化为支持识别的表征至关重要。现有特征可视化方法通常仅能推断单元最兴奋的图像，但不足以揭示响应保持不变的变换流形，而这正是视觉泛化的关键。本文提出Stretch-and-Squeeze（SnS），一种无偏、模型无关且无需梯度的框架，用于系统表征视觉单元的不变性景观及其对对抗性扰动的脆弱性。SnS将这些变换建模为双目标优化问题：为探究不变性，SnS寻找能最大程度改变参考刺激表示但保留单元激活的图像扰动；为探究对抗性敏感性，SnS寻找能最小程度改变刺激但抑制单元激活的扰动。应用于卷积神经网络（CNN）时，SnS生成的图像变化在像素空间上比仿射变换更远离参考图像，同时更有效地保留目标单元的响应。研究发现，优化过程中使用的图像表示选择显著影响不变性图像的性质：像素级变化主要影响亮度和对比度，而拉伸中、晚期CNN表示则分别改变纹理和姿态。值得注意的是，来自鲁棒网络的不变性图像对人类观察者更具可识别性，支持鲁棒CNN作为视觉系统模型的更高保真度。

</details>


### [178] [Relaxed syntax modeling in Transformers for future-proof license plate recognition](https://arxiv.org/abs/2506.17051)
**中文标题：面向未来车牌识别的Transformer松弛语法建模**

*Florent Meyer,Laurent Guichard,Denis Coquenet,Guillaume Gravier,Yann Soullard,Bertrand Coüasnon*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SaLT的语法无关Transformer模型，用于解决车牌识别系统因语法变化导致的性能下降问题。通过改进架构，模型在历史和未来车牌数据上均表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于Transformer的车牌识别系统在面对语法变化的新车牌时性能显著下降，无法满足实际生产环境的需求。本文旨在解决这一问题，提出一种语法无关的建模方法。

研究方法: 通过分析Transformer编码器-解码器中位置和上下文信息的流动，识别出模型对过去语法的过度依赖问题，并提出架构改进方案，设计了一种名为SaLT的语法无关Transformer模型。

研究结果: 实验表明，SaLT模型在历史车牌数据上达到最高准确率，并在未来车牌数据上几乎保持相同性能，验证了其鲁棒性。

研究结论: 本文提出的SaLT模型通过语法无关建模，显著提升了车牌识别系统对语法变化的适应能力，为未来车牌识别提供了可靠解决方案。

中文摘要: 有效的车牌识别系统需要具备对持续变化的适应能力，因为每天都有新车牌投入使用。尽管基于Transformer的网络在初次识别时表现优异，但我们观察到其性能随时间显著下降，证明其不适合紧张的生产环境。这类系统在训练期间见过的车牌语法上取得了最先进的结果，但在未来车牌上表现接近随机猜测，可读字符因语法变化而被错误识别。通过分析Transformer编码器-解码器中位置和上下文信息的流动，我们确定了其对过去语法过度依赖的多个原因。随后，我们设计了架构上的截断和替换方案，并将其集成到SaLT（一种语法无关的Transformer模型）中，用于车牌表示的语法无关建模。在真实和合成数据集上的实验表明，我们的方法在历史语法上达到了最高准确率，更重要的是在未来车牌上几乎保持了性能。我们还通过多种消融实验证明了架构改进的鲁棒性。

</details>


### [179] [Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion](https://arxiv.org/abs/2506.17074)
**中文标题：Assembler：通过锚点扩散实现可扩展的3D零件组装**

*Wang Zhao,Yan-Pei Cao,Jiale Xu,Yuejiang Dong,Ying Shan*

主要分类: cs.CV

摘要简述: Assembler是一个可扩展的3D零件组装框架，通过锚点扩散技术从输入零件网格和参考图像重建完整物体，解决了多样性物体组装的挑战，并在PartNet上实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3D零件组装方法主要依赖确定性姿态预测和类别特定训练，难以处理多样化的真实世界物体。Assembler旨在通过创新的任务表述、表示方法和数据，解决通用3D零件组装的可扩展性问题。

研究方法: Assembler将零件组装视为生成问题，利用扩散模型采样可能的配置；引入基于稀疏锚点云的新形状表示，实现欧几里得空间的可扩展生成；并通过合成和过滤流程构建了包含32万多样本的大规模数据集。

研究结果: Assembler在PartNet上实现了最先进的性能，首次展示了复杂真实世界物体的高质量组装，并进一步开发了一个支持交互和组合设计的零件感知3D建模系统。

研究结论: Assembler通过创新的生成方法和表示技术，成功解决了通用3D零件组装的挑战，为交互式设计提供了潜力。

中文摘要: 我们提出了Assembler，一个可扩展且通用的3D零件组装框架，能够从输入的零件网格和参考图像重建完整物体。与以往主要依赖确定性零件姿态预测和类别特定训练的方法不同，Assembler旨在处理具有不同零件数量、几何形状和结构的多样化真实世界物体。它通过任务表述、表示方法和数据的创新，解决了通用3D零件组装的核心挑战。首先，Assembler将零件组装视为生成问题，利用扩散模型采样可能的配置，有效捕捉了对称性、重复零件和多种有效组装带来的模糊性。其次，我们引入了一种基于稀疏锚点云的新型形状表示，实现了欧几里得空间的可扩展生成，而非SE(3)姿态预测。第三，我们通过合成和过滤流程，基于现有的3D形状库构建了一个包含超过32万个多样本的大规模数据集。Assembler在PartNet上实现了最先进的性能，并首次展示了复杂真实世界物体的高质量组装。基于Assembler，我们进一步开发了一个有趣的零件感知3D建模系统，能够从图像生成高分辨率、可编辑的物体，展示了交互式和组合设计的潜力。项目页面：https://assembler3d.github.io

</details>


### [180] [Acquiring and Accumulating Knowledge from Diverse Datasets for Multi-label Driving Scene Classification](https://arxiv.org/abs/2506.17101)
**中文标题：从多样化数据集中获取和积累知识用于多标签驾驶场景分类**

*Ke Li,Chenyu Zhang,Yuxin Ding,Xianbiao Hu,Ruwen Qin*

主要分类: cs.CV

摘要简述: 本文提出了一种结合知识获取与积累（KAA）和基于一致性的主动学习（CAL）的新方法，用于解决多标签驾驶场景分类中的数据集不平衡和任务学习平衡问题。实验表明，该方法在性能上显著优于基线模型，并减少了数据需求。


<details>
  <summary>详细信息</summary>
研究动机: 驾驶场景识别是自动驾驶车辆理解复杂环境的关键，但多标签分类面临数据集不平衡和任务学习平衡的挑战。本文旨在通过新方法解决这些问题。

研究方法: 提出KAA-CAL系统：KAA通过单任务学习从多个单标签数据集中获取和积累知识，CAL通过一致性学习解决属性分布差异导致的知识差距。

研究结果: 在DSI数据集上，KAA-CAL比基线模型性能提升56.1%（KAA贡献31.3%，CAL贡献24.8%），并在BDD100K和HSD数据集上以85%更少的数据优于现有方法。

研究结论: KAA-CAL有效解决了多标签驾驶场景分类的挑战，显著提升了性能并减少了数据需求，为自动驾驶场景理解提供了新思路。

中文摘要: 驾驶场景识别通过为场景分配多个非排他性类别标签，为自动驾驶车辆提供了理解复杂驾驶环境所需的上下文感知能力。作为一个多标签分类问题，多任务学习更适合解决这一问题。然而，直接通过多任务学习训练多标签分类模型面临两大挑战：获取平衡且全面标注的多标签数据集，以及平衡不同任务的学习。本文提出了一种新颖的学习系统，将知识获取与积累（KAA）与基于一致性的主动学习（CAL）相结合以应对这些挑战。KAA通过单任务学习从多个单标签数据集中获取和积累场景识别知识，随后CAL有效解决了由单个属性边缘分布与其联合分布差异导致的知识差距。在驾驶场景识别（DSI）数据集上的消融实验表明，该方法比基于ImageNet预训练的基线模型性能提升了56.1%，其中KAA贡献了31.3%，CAL贡献了24.8%。此外，KAA-CAL在两个公开数据集BDD100K和HSD上以85%更少的数据优于现有多标签模型。DSI数据集和KAA-CAL的实现代码可在https://github.com/KELISBU/KAA-CAL获取。

</details>


### [181] [MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation](https://arxiv.org/abs/2506.17113)
**中文标题：MEXA：基于动态多专家聚合的通用多模态推理框架**

*Shoubin Yu,Yue Zhang,Ziyang Wang,Jaehong Yoon,Mohit Bansal*

主要分类: cs.CV

摘要简述: MEXA是一种无需训练的框架，通过动态选择和聚合多专家模型，实现跨模态和跨任务的多模态推理，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着输入模态和任务复杂性的增加，构建统一的多模态推理框架面临挑战。MEXA旨在通过动态选择和聚合专家模型，解决跨领域多模态推理的难题。

研究方法: MEXA根据输入模态和任务需求动态选择专家模型，生成可解释的文本推理输出，并通过大型推理模型（LRM）聚合这些输出，生成最终答案。

研究结果: MEXA在视频推理、音频推理、3D理解和医学问答等多个多模态基准测试中表现优异，性能优于现有基线方法。

研究结论: MEXA通过专家驱动的动态选择和聚合，实现了灵活、透明的跨领域多模态推理，无需额外训练，具有广泛适用性。

中文摘要: 结合预训练的专家模型为可扩展的多模态推理提供了巨大潜力，但由于输入模态和任务复杂性的日益多样化，构建统一框架仍具有挑战性。例如，医疗诊断需要对结构化临床表格进行精确推理，而金融预测则需要基于图表数据做出明智预测。为解决这一挑战，我们提出了MEXA，一种无需训练的框架，通过动态选择和聚合多专家模型，实现跨模态和跨任务的多模态推理。MEXA根据输入模态和任务需求动态选择专家模型，每个专家模型专注于特定模态任务对，生成可解释的文本推理输出。MEXA通过大型推理模型（LRM）对这些输出进行聚合和推理，生成最终答案。这种模块化设计允许灵活、透明的跨领域多模态推理，无需额外训练开销。我们在视频推理、音频推理、3D理解和医学问答等多个多模态基准测试中广泛评估了该方法。MEXA在性能上持续优于现有基线方法，证明了专家驱动的选择和聚合在多样化多模态推理任务中的有效性和广泛适用性。

</details>


### [182] [RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking](https://arxiv.org/abs/2506.17119)
**中文标题：RGBTrack：快速、鲁棒的无深度6D姿态估计与跟踪**

*Teng Guo,Jingjin Yu*

主要分类: cs.CV

摘要简述: RGBTrack是一种仅基于RGB数据的实时6D姿态估计与跟踪框架，无需深度输入，通过结合二进制搜索策略和渲染比较机制，实现高效深度推断和姿态假设生成，并在动态场景中保持稳定跟踪。


<details>
  <summary>详细信息</summary>
研究动机: 现有的6D姿态估计和跟踪方法通常依赖深度数据，限制了其在无深度输入场景中的应用。RGBTrack旨在开发一种仅需RGB数据的实时、鲁棒解决方案，以满足机器人、增强现实等领域的需求。

研究方法: RGBTrack基于FoundationPose架构，提出了一种新颖的二进制搜索策略和渲染比较机制，结合2D目标跟踪（XMem）、卡尔曼滤波器和状态机，实现动态场景中的稳定跟踪。此外，其尺度恢复模块通过初始深度估计动态调整未知尺度的CAD模型。

研究结果: 在基准数据集上的广泛评估表明，RGBTrack的无深度方法在精度和实时性能上具有竞争力，适用于机器人、增强现实等应用领域。

研究结论: RGBTrack通过仅依赖RGB数据实现了高效的6D姿态估计与跟踪，为无深度输入场景提供了一种实用的解决方案，具有广泛的应用潜力。

中文摘要: 我们提出了一种鲁棒的框架RGBTrack，用于实时6D姿态估计与跟踪，仅需RGB数据，无需深度输入。基于FoundationPose架构，我们设计了一种新颖的二进制搜索策略，结合渲染比较机制，高效推断深度并从真实尺度CAD模型中生成鲁棒的姿态假设。为在动态场景（包括快速运动和遮挡）中保持稳定跟踪，RGBTrack集成了先进的2D目标跟踪（XMem）、卡尔曼滤波器和状态机，以实现主动姿态恢复。此外，RGBTrack的尺度恢复模块通过初始深度估计动态调整未知尺度的CAD模型，便于与现代生成重建技术无缝集成。在基准数据集上的广泛评估表明，RGBTrack的无深度方法在精度和实时性能上具有竞争力，是机器人、增强现实和计算机视觉等领域的实用解决方案。我们的实现源代码将在https://github.com/GreatenAnoymous/RGBTrack.git公开。

</details>


### [183] [Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs](https://arxiv.org/abs/2506.17134)
**中文标题：基于周长门控SPAD成像器的数字图像动态水印生成技术**

*Md Sakibur Sajal,Marc Dandin*

主要分类: cs.CV

摘要简述: 本文提出了一种基于周长门控单光子雪崩二极管（pgSPAD）成像器的动态水印生成技术，利用制造过程中的暗信号非均匀性（DSNU）实现数字图像的水印嵌入，既能识别来源又能检测篡改。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要集中在CMOS图像传感器（CIS）和主动像素传感器（APS）上，而单光子雪崩二极管（SPAD）成像器尚未被探索用于水印生成。本文旨在填补这一空白，利用SPAD的制造特性开发新型水印技术。

研究方法: 研究使用三块64×64的pgSPAD成像器芯片（基于0.35微米标准CMOS工艺制造），分析其DSNU特性，并模拟生成动态水印。水印的敏感性和鲁棒性可调节。

研究结果: 实验表明，所提出的动态水印技术能够有效实现来源识别和篡改检测，同时在水印的敏感性和鲁棒性之间实现了可控的平衡。

研究结论: pgSPAD成像器为数字图像水印提供了一种新的可行方案，其动态水印技术在安全性和实用性上具有潜力。

中文摘要: 数字图像水印作为一种安全特性，可以通过利用成像器的物理不可克隆功能（PUFs）——即暗信号非均匀性（DSNU）——来实现。尽管已有研究主要集中在CMOS图像传感器（CIS）和主动像素传感器（APS）上，但单光子雪崩二极管（SPAD）成像器尚未被探索用于此目的。本研究提出了一种基于周长门控SPAD（pgSPAD）成像器的新型水印技术。我们利用三块64×64的pgSPAD成像器芯片（基于0.35微米标准CMOS工艺制造）的DSNU特性，分析了从公开数据库中获取的标准测试图像的模拟水印。实验结果表明，所提出的动态水印技术既能实现来源识别，又能检测篡改，同时在水印的敏感性和鲁棒性之间实现了可控的平衡。

</details>


### [184] [Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations](https://arxiv.org/abs/2506.17136)
**中文标题：复杂场景下的半监督多模态医学图像分割**

*Dongdong Meng,Sheng Li,Hao Wu,Guoping Wang,Xueqing Yan*

主要分类: cs.CV

摘要简述: 本文提出了一种新型半监督多模态医学图像分割方法，通过多阶段多模态融合与增强策略，充分利用互补信息，提升有限标注数据下的分割性能，并在复杂场景中表现出优越的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 半监督学习在医学图像中因标注数据有限而表现不足，多模态融合虽能提升分割精度，但在半监督条件下难以有效利用未标注数据。因此，亟需一种高效可靠的多模态学习策略以解决这一问题。

研究方法: 提出了一种多阶段多模态融合与增强策略，减少特征差异并增强特征共享与对齐；同时引入对比互学习约束多模态预测一致性，提升半监督任务的鲁棒性。

研究结果: 在两个多模态数据集上的实验表明，该方法在复杂场景中表现出卓越的性能和鲁棒性，为医学图像分割任务提供了有效解决方案。

研究结论: 所提出的半监督多模态医学图像分割方法通过充分利用互补信息和约束预测一致性，显著提升了有限标注数据下的分割性能，具有重要的应用潜力。

中文摘要: 半监督学习能有效解决医学图像中标注数据有限的问题，但在复杂背景和挑战性任务中表现不足。多模态融合方法通过提供互补信息显著提升医学图像分割的准确性，但在半监督条件下难以有效利用未标注数据。因此，亟需一种高效可靠的多模态学习策略以利用未标注数据进行半监督分割。为解决这些问题，我们提出了一种新型半监督多模态医学图像分割方法，通过互补多模态信息提升有限标注数据下的性能。该方法采用多阶段多模态融合与增强策略，充分利用互补信息，同时减少特征差异并增强特征共享与对齐。此外，我们引入对比互学习约束多模态预测一致性，从而提升半监督任务中分割结果的鲁棒性。在两个多模态数据集上的实验结果表明，所提框架具有卓越的性能和鲁棒性，为复杂场景下的医学图像分割任务提供了有价值的解决方案。

</details>


### [185] [On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting](https://arxiv.org/abs/2506.17137)
**中文标题：关于无监督域自适应计数中条件特征对齐的理论研究**

*Zhuonan Liang,Dongnan Liu,Jianan Fan,Yaxuan Song,Qiang Qu,Yu Yao,Peng Fu,Weidong Cai*

主要分类: cs.CV

摘要简述: 本文提出了一种条件特征对齐的理论框架，用于解决无监督域自适应计数任务中密度变化导致的模型性能下降问题。通过条件对齐分布，证明了其在降低联合误差上的优势，并通过实验验证了方法的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 目标计数模型在跨域部署时，由于密度变化导致性能下降，而传统域适应方法无法有效处理这种任务相关的密度偏移。因此，需要一种新的理论框架来指导条件特征对齐，以提升跨域泛化能力。

研究方法: 首先形式化了条件差异的概念，通过将每个域划分为子集（如目标与背景）并测量每个条件下的差异。随后推导了一个联合误差界，证明在离散标签空间下，条件对齐分布能比无条件对齐更有效地降低源域和目标域的决策误差。基于此，提出了一种保留任务相关变化、过滤无关偏移的条件适应策略。

研究结果: 在多个具有不同密度分布的计数数据集上的实验表明，该方法显著优于现有的无监督域适应方法，验证了条件特征对齐的理论优势。

研究结论: 条件特征对齐通过保留任务相关变化并过滤无关偏移，显著提升了无监督域自适应计数任务的性能，为跨域泛化提供了新的理论支持。

中文摘要: 目标计数模型在跨域部署时，由于密度变化的多样性导致性能下降，因为密度偏移本质上是任务相关的，违反了标准域适应的假设。为解决这一问题，我们提出了条件特征对齐的理论框架。首先，我们通过将每个域划分为子集（如目标与背景）并测量每个条件下的差异，形式化了条件差异的概念。随后，我们推导了一个联合误差界，表明在离散标签空间作为条件集的情况下，条件对齐分布比无条件对齐能更有效地降低源域和目标域的联合决策误差。这些见解激发了一种通用的条件适应原则：通过保留任务相关变化并过滤无关偏移，可以在无监督域自适应计数任务中实现更优的跨域泛化。我们不仅定义了条件差异并证明了其在降低联合误差上的优势，还提出了一种实用的适应策略，以保留任务相关信息。通过在多个具有不同密度分布的计数数据集上进行广泛实验，我们验证了方法的有效性。结果表明，我们的方法优于现有的无监督域适应方法，从实验上验证了条件特征对齐的理论见解。

</details>


### [186] [Do We Need Large VLMs for Spotting Soccer Actions?](https://arxiv.org/abs/2506.17144)
**中文标题：我们需要大型视觉语言模型来识别足球动作吗？**

*Ritabrata Chakraborty,Rajatsubhra Chakraborty,Avijit Dasgupta,Sandeep Chaurasia*

主要分类: cs.CV

摘要简述: 本文提出了一种基于文本的轻量级方法，利用大型语言模型（LLMs）替代传统的视觉语言模型（VLMs）来识别足球比赛中的关键动作，如进球、黄牌和换人。实验表明，该方法在检测比赛事件时表现优异，且无需训练。


<details>
  <summary>详细信息</summary>
研究动机: 传统的视频分析方法依赖复杂的视觉输入，计算成本高。本文旨在探索一种基于文本的轻量级替代方案，利用专家评论中的丰富信息来识别足球比赛中的关键动作。

研究方法: 使用SoccerNet Echoes数据集中的时间戳评论，通过三个专门化的LLM（分别关注结果、兴奋度和战术）评估滑动窗口内的评论，生成准确的事件时间戳。

研究结果: 实验证明，这种基于语言的方法在检测关键比赛事件（如进球、黄牌和换人）时表现高效，且无需训练。

研究结论: 本文提出的语言中心方法为足球动作识别提供了一种轻量级、无需训练的替代方案，优于传统的视频分析方法。

中文摘要: 传统的视频任务（如足球动作识别）严重依赖视觉输入，通常需要复杂且计算成本高的模型来处理密集的视频数据。本文提出从视频中心方法转向基于文本的任务，通过利用大型语言模型（LLMs）而非视觉语言模型（VLMs），使其轻量化和可扩展。我们认为，专家评论提供了丰富、细粒度的描述和上下文线索（如兴奋度和战术见解），足以可靠地识别比赛中的关键动作。为验证这一点，我们使用SoccerNet Echoes数据集（提供带时间戳的评论），并采用三个LLM作为专门评估结果、兴奋度和战术的“裁判”。每个LLM评估滑动窗口内的评论，以识别进球、黄牌和换人等动作，并为这些事件生成准确的时间戳。实验表明，这种语言中心方法在检测关键比赛事件时表现优异，为传统的视频动作识别方法提供了一种轻量级且无需训练的替代方案。

</details>


### [187] [Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation](https://arxiv.org/abs/2506.17159)
**中文标题：Co-Seg++：基于互提示引导协作学习的多功能医学分割**

*Qing Xu,Yuxiang Luo,Wenting Duan,Zhen Chen*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Co-Seg++的框架，通过语义和实例分割任务的相互增强，提升医学图像分割性能。实验证明其在多种数据集上优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有医学图像分割研究通常孤立处理不同任务，忽略了任务间的相互依赖性，导致性能不佳。本文旨在通过协同学习提升分割效果。

研究方法: 提出Co-Seg++框架，包含时空提示编码器（STP-Encoder）和多任务协作解码器（MTC-Decoder），通过空间约束和跨任务指导实现语义与实例分割的协同优化。

研究结果: 在多种CT和组织病理学数据集上的实验表明，Co-Seg++在语义、实例和全景分割任务中均优于现有方法。

研究结论: Co-Seg++通过任务协同学习显著提升了医学图像分割性能，为多任务分割提供了有效解决方案。

中文摘要: 医学图像分析至关重要，但面临同时分割器官、组织及解剖结构和肿瘤微环境多实例的挑战。现有研究通常孤立处理不同分割任务，忽略了任务间的相互依赖性，导致分割性能不佳和医学图像理解不足。为解决这一问题，我们提出了一种名为Co-Seg++的多功能医学分割框架。具体而言，我们引入了一种新的协同分割范式，使语义和实例分割任务相互增强。我们首先设计了一种时空提示编码器（STP-Encoder），用于捕获分割区域与图像嵌入之间的长程时空关系，作为先验空间约束。此外，我们还设计了一种多任务协作解码器（MTC-Decoder），通过跨任务指导增强两项任务的上下文一致性，联合计算语义和实例分割掩码。在多种CT和组织病理学数据集上的广泛实验表明，所提出的Co-Seg++在牙齿解剖结构、组织病理学组织和细胞核实例的语义、实例及全景分割任务中均优于现有方法。源代码发布于https://github.com/xq141839/Co-Seg-Plus。

</details>


### [188] [YASMOT: Yet another stereo image multi-object tracker](https://arxiv.org/abs/2506.17186)
**中文标题：YASMOT：另一种立体图像多目标跟踪器**

*Ketil Malde*

主要分类: cs.CV

摘要简述: YASMOT是一个轻量级且灵活的多目标跟踪器，适用于单目或立体相机配置，能够处理多种目标检测器的输出，并生成共识检测结果。


<details>
  <summary>详细信息</summary>
研究动机: 现有深度学习目标检测器能分析图像并提取对象位置和类别标签，但在时间序列图像（如视频或静态图像序列）中，跟踪对象并保持其身份对提升检测性能及下游任务（如行为分类、预测和丰度估计）至关重要。

研究方法: YASMOT通过处理流行目标检测器的输出，实现对单目或立体相机配置下对象的跟踪，并具备从多个检测器中生成共识检测的功能。

研究结果: YASMOT能够高效跟踪对象并生成共识检测结果，适用于多种相机配置和检测器组合。

研究结论: YASMOT为多目标跟踪提供了一种轻量级且灵活的解决方案，适用于多种应用场景。

中文摘要: 目前已有许多基于深度学习的流行目标检测器，能够分析图像并提取对象的位置和类别标签。对于时间序列图像（如视频或静态图像序列），跟踪对象并保持其身份有助于提升目标检测性能，并为下游任务（如行为分类、预测和丰度估计）提供必要支持。本文提出YASMOT，一种轻量级且灵活的目标跟踪器，能够处理流行目标检测器的输出，并跟踪单目或立体相机配置下的对象。此外，它还具备从多个目标检测器中生成共识检测的功能。

</details>


### [189] [Facial Landmark Visualization and Emotion Recognition Through Neural Networks](https://arxiv.org/abs/2506.17191)
**中文标题：通过神经网络实现面部标志可视化与情感识别**

*Israel Juárez-Jiménez,Tiffany Guadalupe Martínez Paredes,Jesús García-Ramírez,Eric Ramos Aguilar*

主要分类: cs.CV

摘要简述: 本文提出了一种面部标志箱线图可视化技术，用于识别面部数据集中的异常值，并比较了两种面部标志特征（绝对位置和位移）在神经网络和随机森林分类器中的表现，结果表明神经网络性能更优。


<details>
  <summary>详细信息</summary>
研究动机: 情感识别在人机交互中至关重要，但现有研究缺乏对数据集的深入分析。面部标志的可视化在提取有意义的数据洞察时具有挑战性，因此需要一种新的可视化技术来识别异常值。

研究方法: 提出面部标志箱线图技术，用于可视化数据集中的异常值；比较两种面部标志特征（绝对位置和从中性表情到情绪高峰的位移）在神经网络和随机森林分类器中的表现。

研究结果: 神经网络在情感识别任务中表现优于随机森林分类器。

研究结论: 面部标志箱线图是一种有效的可视化工具，神经网络在情感识别任务中具有更高的性能。

中文摘要: 面部图像的情感识别是人机交互中的关键任务，使机器能够通过面部表情学习人类情感。以往研究表明，面部图像可用于训练深度学习模型，但大多数研究缺乏对数据集的深入分析。在提取有意义的数据集洞察时，面部标志的可视化具有挑战性；为解决这一问题，我们提出了面部标志箱线图，一种旨在识别面部数据集中异常值的可视化技术。此外，我们比较了两组面部标志特征：（i）标志的绝对位置和（ii）从中性表情到情绪高峰的位移。结果表明，神经网络的表现优于随机森林分类器。

</details>


### [190] [Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition](https://arxiv.org/abs/2506.17201)
**中文标题：Hunyuan-GameCraft：基于混合历史条件的高动态交互游戏视频生成**

*Jiaqi Li,Junshu Tang,Zhiyong Xu,Longhuang Wu,Yuan Zhou,Shuai Shao,Tianbao Yu,Zhiguo Cao,Qinglin Lu*

主要分类: cs.CV

摘要简述: Hunyuan-GameCraft提出了一种新型高动态交互游戏视频生成框架，通过统一输入表示和混合历史条件训练策略，显著提升了视频生成的动态性、一致性和效率，并在大规模游戏数据集上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散模型和可控视频生成的方法在动态性、通用性、长期一致性和效率方面存在局限，难以生成多样化的游戏视频。为解决这些问题，研究团队提出了Hunyuan-GameCraft框架。

研究方法: 方法包括：1) 将键盘和鼠标输入统一为共享的相机表示空间；2) 提出混合历史条件训练策略，自回归扩展视频序列并保留游戏场景信息；3) 通过模型蒸馏提升推理效率和可玩性。

研究结果: 实验表明，Hunyuan-GameCraft在视觉保真度、真实感和动作可控性上显著优于现有模型，适用于复杂交互环境的实时部署。

研究结论: Hunyuan-GameCraft通过创新的输入表示和训练策略，推动了交互游戏视频生成的现实感和可玩性，为沉浸式游戏体验提供了新工具。

中文摘要: 近年来，基于扩散模型和可控视频生成的技术取得了显著进展，为沉浸式交互游戏体验奠定了基础。然而，现有方法在动态性、通用性、长期一致性和效率方面存在局限，限制了多样化游戏视频的生成能力。为解决这些问题，我们提出了Hunyuan-GameCraft，一种用于游戏环境中高动态交互视频生成的新型框架。为实现细粒度动作控制，我们将标准键盘和鼠标输入统一为共享的相机表示空间，便于各种相机和移动操作之间的平滑插值。此外，我们提出了一种混合历史条件训练策略，自回归扩展视频序列的同时保留游戏场景信息。为提升推理效率和可玩性，我们通过模型蒸馏减少计算开销，同时保持长时序序列的一致性，使其适用于复杂交互环境的实时部署。模型在包含超过100款AAA游戏的百万级游戏录像数据集上训练，确保了广泛覆盖和多样性，并通过精细标注的合成数据集微调以提升精度和控制力。精心策划的游戏场景数据显著提高了视觉保真度、真实感和动作可控性。大量实验表明，Hunyuan-GameCraft显著优于现有模型，推动了交互游戏视频生成的现实感和可玩性。

</details>


### [191] [UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2506.17202)
**中文标题：UniFork：探索模态对齐以实现统一多模态理解与生成**

*Teng Li,Quanfeng Lu,Lirui Zhao,Hao Li,Xizhou Zhu,Yu Qiao,Jun Zhang,Wenqi Shao*

主要分类: cs.CV

摘要简述: 本文提出UniFork，一种Y形架构，通过共享浅层学习跨任务表示，并在深层使用任务特定分支，以平衡共享学习与任务专一性，解决多模态理解与生成任务中的模态对齐冲突。


<details>
  <summary>详细信息</summary>
研究动机: 现有统一多模态模型在理解与生成任务中因模态对齐模式不同而性能受限。本文旨在通过分析任务特定模型和统一模型的模态对齐行为，设计一种新架构以解决这一冲突。

研究方法: 提出UniFork架构，共享浅层进行跨任务表示学习，深层采用任务特定分支以避免任务干扰，平衡共享学习与任务专一性。

研究结果: UniFork在性能上优于传统全共享Transformer架构，并与任务特定模型相当或更优。

研究结论: UniFork通过Y形设计有效解决多模态理解与生成任务中的模态对齐冲突，为统一模型设计提供了新思路。

中文摘要: 统一图像理解与生成已成为多模态人工智能中的一种有前景的范式。尽管近期取得进展，此类统一模型的最优架构设计仍是一个开放挑战。本文首先分析了理解与生成任务特定专家模型及当前统一模型的模态对齐行为。分析揭示了一个关键观察：理解任务受益于网络深度中逐渐增加的模态对齐，有助于构建语义信息以提升理解；而生成任务则呈现不同趋势：模态对齐在浅层增加但在深层减少以恢复空间细节。这些不同的对齐模式在完全共享的Transformer主干中产生根本冲突，统一的表示流通常导致两项任务的性能折衷。基于这一发现，我们提出UniFork，一种新颖的Y形架构，共享浅层进行跨任务表示学习，同时在深层使用任务特定分支以避免任务干扰。该设计有效平衡了共享学习与任务专一性。通过大量消融实验，我们证明UniFork在性能上持续优于传统全共享Transformer架构，并与任务特定模型相当或更优。

</details>


### [192] [Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting](https://arxiv.org/abs/2506.17212)
**中文标题：Part$^{2}$GS：基于3D高斯点云的关节物体部分感知建模**

*Tianjiao Yu,Vedant Shah,Muntasir Wahed,Ying Shen,Kiet A. Nguyen,Ismini Lourentzou*

主要分类: cs.CV

摘要简述: 本文提出Part$^{2}$GS框架，通过部分感知的3D高斯表示建模多部分物体的高保真几何和物理一致运动，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中多部分物体常见，但其结构和运动的建模对3D重建方法仍具挑战性。本文旨在解决这一问题，提出一种能够保持高保真几何和物理一致运动的新方法。

研究方法: Part$^{2}$GS采用部分感知的3D高斯表示，编码可学习属性的关节组件，实现结构化解耦变换。通过物理约束（如接触强制、速度一致性和矢量场对齐）指导运动感知的规范表示，并引入排斥点场防止部件碰撞。

研究结果: 在合成和真实数据集上的评估表明，Part$^{2}$GS在可移动部件的Chamfer距离上比现有方法提升高达10倍。

研究结论: Part$^{2}$GS通过部分感知建模和物理约束，显著提升了多部分物体的几何和运动建模效果，为数字孪生提供了新思路。

中文摘要: 关节物体在现实世界中普遍存在，但其结构和运动的建模仍是3D重建方法的挑战。本文提出Part$^{2}$GS，一种用于建模多部分物体高保真几何和物理一致运动的新框架。Part$^{2}$GS利用部分感知的3D高斯表示，编码具有可学习属性的关节组件，实现结构化解耦变换以保持高保真几何。为确保物理一致运动，提出基于物理约束（如接触强制、速度一致性和矢量场对齐）的运动感知规范表示。此外，引入排斥点场防止部件碰撞并保持稳定运动路径，显著提升运动连贯性。在合成和真实数据集上的广泛评估表明，Part$^{2}$GS在可移动部件的Chamfer距离上比现有方法提升高达10倍。

</details>


### [193] [Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation](https://arxiv.org/abs/2506.17213)
**中文标题：基于交替自回归运动与场景生成的长期交通仿真**

*Xiuyu Yang,Shuhan Tan,Philipp Krähenbühl*

主要分类: cs.CV

摘要简述: 本文提出InfGen模型，通过交替进行闭环运动模拟和场景生成，实现长期稳定的交通仿真，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有交通仿真模型主要关注初始场景的闭环运动模拟，难以应对长期仿真中车辆进出场景的动态变化。本文旨在解决这一问题。

研究方法: 提出InfGen模型，采用统一的下一令牌预测方法，交替执行闭环运动模拟和场景生成，实现长期稳定的交通仿真。

研究结果: InfGen在短期（9秒）交通仿真中达到最先进水平，在长期（30秒）仿真中显著优于其他方法。

研究结论: InfGen通过交替模拟和生成，解决了长期交通仿真的动态场景问题，为自动驾驶系统提供了更真实的仿真环境。

中文摘要: 理想的交通仿真器能够复现自动驾驶系统在部署过程中经历的长期点对点行程。现有模型和基准主要关注初始场景的闭环运动模拟，这在长期仿真中存在不足，因为车辆会随着自车进入新区域而动态进出场景。本文提出InfGen，一种统一的下一令牌预测模型，能够交替进行闭环运动模拟和场景生成。InfGen自动在两种模式间切换，从而实现稳定的长期仿真。实验表明，InfGen在短期（9秒）交通仿真中达到最先进水平，在长期（30秒）仿真中显著优于其他方法。InfGen的代码和模型将在https://orangesodahub.github.io/InfGen发布。

</details>


### [194] [Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens](https://arxiv.org/abs/2506.17218)
**中文标题：机器心理意象：通过潜在视觉标记增强多模态推理**

*Zeyuan Yang,Xueyang Yu,Delin Chen,Maohao Shen,Chuang Gan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Mirage的机器心理意象框架，通过引入潜在视觉标记增强视觉语言模型的多模态推理能力，避免了显式图像生成的负担。


<details>
  <summary>详细信息</summary>
研究动机: 视觉语言模型在多模态理解方面表现出色，但其仅依赖文本解码限制了需要视觉想象的任务性能。本文旨在探索模型是否可以通过潜在视觉标记实现多模态推理，而无需生成显式图像。

研究方法: Mirage框架在解码过程中引入潜在视觉标记，通过从真实图像嵌入中蒸馏监督这些标记，随后切换到仅文本监督以对齐任务目标，并通过强化学习进一步优化多模态推理能力。

研究结果: 实验表明，Mirage在多种基准测试中显著提升了多模态推理能力，且无需显式生成图像。

研究结论: Mirage通过潜在视觉标记实现了更强大的多模态推理，为视觉语言模型的任务性能提供了新的优化方向。

中文摘要: 视觉语言模型（VLMs）在多模态理解方面表现出色，但其仅依赖文本解码的特性迫使它们通过语言表达视觉推理，从而限制了需要视觉想象的任务性能。近期研究尝试训练VLMs生成显式图像，但繁重的图像生成预训练往往损害推理能力。受人类通过心理意象（即内部构建和操作视觉线索）进行推理的启发，我们探讨了VLMs是否可以通过交替的多模态轨迹进行推理而无需生成显式图像。为此，我们提出了名为Mirage的机器心理意象框架，通过潜在视觉标记增强VLM的解码过程。具体而言，当模型选择“视觉思考”时，它会将隐藏状态重新编码为下一个标记，从而在不生成像素级图像的情况下延续多模态轨迹。我们首先通过从真实图像嵌入中蒸馏来监督潜在标记，随后切换到仅文本监督以使潜在轨迹与任务目标紧密对齐。进一步的强化学习阶段进一步提升了多模态推理能力。多样化的基准测试表明，Mirage无需显式图像生成即可解锁更强的多模态推理能力。

</details>


### [195] [Emergent Temporal Correspondences from Video Diffusion Transformers](https://arxiv.org/abs/2506.17220)
**中文标题：视频扩散变换器中涌现的时间对应关系**

*Jisu Nam,Soowon Son,Dahyun Chung,Jiyoung Kim,Siyoon Jin,Junhwa Hur,Seungryong Kim*

主要分类: cs.CV

摘要简述: 本文提出了DiffTrack框架，用于定量分析视频扩散变换器（DiTs）如何内部建立和表示帧间时间对应关系。研究发现特定层的查询-键相似性在时间匹配中起关键作用，并展示了DiffTrack在零样本点跟踪和运动增强视频生成中的实际应用。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于扩散变换器（DiTs）的视频扩散模型在生成时间连贯的视频方面取得了显著成功，但这些模型内部如何建立和表示帧间时间对应关系仍是一个未解之谜。本文旨在通过DiffTrack框架填补这一研究空白。

研究方法: DiffTrack构建了一个带有伪真实跟踪注释的提示生成视频数据集，并提出了新的评估指标，系统地分析了DiTs的3D注意力机制中每个组件（如表示、层和时间步）对时间对应关系建立的贡献。

研究结果: 分析表明，特定层（而非所有层）的查询-键相似性在时间匹配中起关键作用，且这种匹配在去噪过程中逐渐显著。DiffTrack在零样本点跟踪中实现了最先进的性能，并通过新的引导方法改进了生成视频的时间一致性。

研究结论: 本文为理解视频DiTs的内部机制提供了关键见解，并为进一步研究和应用其时间理解能力奠定了基础。

中文摘要: 基于扩散变换器（DiTs）的视频扩散模型的最新进展在生成时间连贯的视频方面取得了显著成功。然而，一个基本问题仍然存在：这些模型内部如何建立和表示帧间的时间对应关系？我们提出了DiffTrack，这是第一个旨在回答这一问题的定量分析框架。DiffTrack构建了一个带有伪真实跟踪注释的提示生成视频数据集，并提出了新的评估指标，系统地分析了DiTs的完整3D注意力机制中每个组件（如表示、层和时间步）对时间对应关系建立的贡献。我们的分析表明，特定层（而非所有层）的查询-键相似性在时间匹配中起关键作用，且这种匹配在去噪过程中逐渐显著。我们展示了DiffTrack在零样本点跟踪中的实际应用，其性能优于现有的视觉基础模型和自监督视频模型。此外，我们通过一种新的引导方法将研究结果扩展到运动增强的视频生成，无需额外训练即可提高生成视频的时间一致性。我们相信，这项工作为理解视频DiTs的内部机制提供了关键见解，并为进一步研究和应用其时间理解能力奠定了基础。

</details>


### [196] [VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.17221)
**中文标题：VLN-R1：基于强化微调的视觉语言导航**

*Zhangyang Qi,Zhixiong Zhang,Yizhou Yu,Jiaqi Wang,Hengshuang Zhao*

主要分类: cs.CV

摘要简述: VLN-R1是一种基于大型视觉语言模型（LVLM）的端到端导航框架，通过强化微调实现连续导航动作，并在VLN-CE基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于语言模型的导航系统依赖离散拓扑图，限制了路径规划的灵活性。VLN-R1旨在利用大型视觉语言模型直接从第一视角视频流生成连续导航动作，提升导航的灵活性和效率。

研究方法: VLN-R1采用两阶段训练方法：1）监督微调（SFT）对齐专家演示的动作序列文本预测；2）强化微调（RFT）结合时间衰减奖励（TDR）机制，优化多步未来动作权重。此外，使用VLN-Ego数据集和长短期记忆采样平衡历史与当前观察。

研究结果: 实验表明，VLN-R1在VLN-CE基准测试中表现优异，验证了大型视觉语言模型在具身导航中的潜力。

研究结论: VLN-R1证明了大型视觉语言模型可通过数据高效的奖励驱动后训练，增强任务特定推理能力，推动具身导航的发展。

中文摘要: 视觉语言导航（VLN）是具身AI的核心挑战，要求智能体根据自然语言指令在真实环境中导航。当前基于语言模型的导航系统依赖离散拓扑图，限制了路径规划的灵活性。我们提出VLN-R1，一种端到端框架，利用大型视觉语言模型（LVLM）直接将第一视角视频流转换为连续导航动作，并采用受DeepSeek-R1启发的GRPO训练方法。为有效训练，我们首先使用3D模拟器Habitat构建VLN-Ego数据集，并提出长短期记忆采样以平衡历史与当前观察。尽管大型语言模型能监督完整文本指令，但缺乏细粒度动作控制。我们的框架采用两阶段训练：a）监督微调（SFT）对齐模型动作序列文本预测与专家演示；b）强化微调（RFT）结合时间衰减奖励（TDR）机制，策略性加权多步未来动作。实验结果显示，VLN-R1在VLN-CE基准测试中表现优异，证明LVLM可通过数据高效的奖励驱动后训练增强任务特定推理能力，推动具身导航发展。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [197] [LLMs Struggle to Perform Counterfactual Reasoning with Parametric Knowledge](https://arxiv.org/abs/2506.15732)
**中文标题：大型语言模型在参数知识下的反事实推理能力不足**

*Khurram Yamin,Gaurav Ghosal,Bryan Wilder*

主要分类: cs.AI

摘要简述: 大型语言模型（LLMs）在参数中存储了大量世界知识，但在需要结合新信息进行反事实推理时表现不佳，且微调也难以改善这一能力。


<details>
  <summary>详细信息</summary>
研究动机: 研究LLMs是否能够在结合上下文知识和参数知识时进行反事实推理，揭示其在处理新颖情境时的局限性。

研究方法: 通过合成和真实实验，在多跳推理问题中测试LLMs的反事实推理能力，并尝试通过微调提升其表现。

研究结果: LLMs在反事实推理中表现不佳，倾向于依赖参数知识，且微调可能导致参数知识退化。

研究结论: 当前LLMs在重新利用参数知识处理新颖情境时存在显著局限性。

中文摘要: 大型语言模型（LLMs）已被证明在其参数中包含了广泛的世界知识，使其在许多知识密集型任务中表现出色。然而，当部署到新环境中时，LLMs常常会遇到需要将参数知识与新信息结合的情境。本文通过反事实推理的视角，探讨LLMs是否能够在上下文中结合其参数知识。通过在多跳推理问题中的合成和真实实验，我们发现LLMs在反事实推理中普遍表现不佳，往往仅依赖其参数知识。此外，我们发现简单的后微调难以提升反事实推理能力，甚至可能导致存储的参数知识退化。最终，我们的研究揭示了当前LLMs在重新利用参数知识处理新颖情境时的重要局限性。

</details>


### [198] [$\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts](https://arxiv.org/abs/2506.15733)
**中文标题：$	exttt{SPECS}$：通过推测性草案实现更快的测试时间扩展**

*Mert Cemri,Nived Rajaraman,Rishabh Tiwari,Xiaoxuan Liu,Kurt Keutzer,Ion Stoica,Kannan Ramchandran,Ahmad Beirami,Ziteng Sun*

主要分类: cs.AI

摘要简述: 本文提出了一种名为$	exttt{SPECS}$的延迟感知测试时间扩展方法，通过使用小型快速模型生成候选序列并结合大型目标模型和奖励模型的信号，显著降低了延迟（最高达19.1%），同时保持了与束搜索相当的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前测试时间扩展方法主要基于总计算资源（FLOPS）优化准确性，但忽视了用户面临的延迟问题。高延迟直接影响用户体验，因此需要一种既能保持准确性又能降低延迟的方法。

研究方法: $	exttt{SPECS}$采用小型快速模型高效生成候选序列，并通过大型目标模型和专用奖励模型的信号评估这些候选序列。引入了奖励引导的软验证和基于奖励的延迟机制等新策略。

研究结果: 在MATH500、AMC23和OlympiadBench数据集上的实验表明，$	exttt{SPECS}$在保持或超越束搜索准确性的同时，将延迟降低了最高达19.1%。理论分析显示，随着束宽增加，算法收敛于KL正则化强化学习目标的解。

研究结论: $	exttt{SPECS}$通过结合小型快速模型和大型目标模型的优势，在降低延迟的同时保持了高准确性，为测试时间扩展提供了一种高效的解决方案。

中文摘要: 测试时间计算的扩展推动了大型语言模型（LLM）推理能力的进步，通常通过分配更多计算资源进行更彻底的探索。然而，增加计算往往以更高的用户延迟为代价，直接影响用户体验。当前的测试时间扩展方法主要基于总计算资源（FLOPS）优化准确性，往往忽略了延迟约束。为解决这一问题，我们提出了$	exttt{SPECS}$，一种受推测解码启发的延迟感知测试时间扩展方法。$	exttt{SPECS}$使用一个更小、更快的模型高效生成候选序列，并通过大型目标模型和专用奖励模型的信号评估这些候选序列。我们引入了新的集成策略，包括奖励引导的软验证和基于奖励的延迟机制。在MATH500、AMC23和OlympiadBench数据集上的实验结果表明，$	exttt{SPECS}$在保持或超越束搜索准确性的同时，将延迟降低了最高达19.1%。理论分析显示，随着束宽增加，算法收敛于KL正则化强化学习目标的解。

</details>


### [199] [The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models](https://arxiv.org/abs/2506.15734)
**中文标题：安全提醒：一种用于重新激活视觉语言模型中延迟安全意识的软提示**

*Peiyuan Tang,Haojie Xin,Xiaodong Zhang,Jun Sun,Qin Xia,Zijiang Yang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为“安全提醒”的软提示方法，用于解决视觉语言模型（VLMs）中存在的“延迟安全意识”问题，通过优化可学习的提示令牌，在文本生成过程中定期注入以增强模型的安全意识，从而有效防止有害内容生成。


<details>
  <summary>详细信息</summary>
研究动机: 随着视觉语言模型（VLMs）在代码生成和聊天机器人等实际应用中的能力不断增强，确保其安全性变得至关重要。由于VLMs的多模态特性，攻击者可能通过修改视觉或文本输入绕过安全防护，触发有害内容生成。本文通过系统分析VLMs在攻击下的行为，发现了一种称为“延迟安全意识”的新现象，即安全对齐的VLMs可能在最初被攻击时生成有害内容，但随后会意识到风险并尝试自我纠正。基于这一现象，作者提出通过设计提示来主动重新激活VLMs的安全意识。

研究方法: 本文提出了一种名为“安全提醒”的软提示调整方法。该方法通过优化可学习的提示令牌，在文本生成过程中定期注入这些令牌以增强模型的安全意识。安全提醒仅在检测到有害内容时激活，不影响正常对话，并保持模型在良性任务上的性能。

研究结果: 通过在三个已建立的安全基准和一个对抗攻击上的全面评估，本文的方法显著降低了攻击成功率，同时保持了模型的实用性。实验结果表明，安全提醒能够有效防止有害内容生成。

研究结论: 本文提出的“安全提醒”方法为部署更安全的视觉语言模型提供了一种实用解决方案。该方法通过优化提示令牌，成功解决了“延迟安全意识”问题，显著提升了模型的安全性，同时不影响其正常功能。

中文摘要: 随着视觉语言模型（VLMs）在代码生成和聊天机器人等实际应用中的能力不断增强，确保其安全性变得至关重要。与传统的大型语言模型（LLMs）不同，VLMs由于其多模态特性而面临独特的漏洞，攻击者可能通过修改视觉或文本输入绕过安全防护，触发有害内容生成。通过对VLM在攻击下的行为进行系统分析，我们发现了一种称为“延迟安全意识”的新现象。具体而言，我们观察到安全对齐的VLMs可能最初被攻击生成有害内容，但最终会意识到相关风险并尝试自我纠正。这一模式表明，VLMs保留了其潜在的安全意识，但其激活存在时间延迟。基于这一发现，我们假设通过精心设计的提示可以主动重新激活VLMs的安全意识。为此，我们提出了“安全提醒”，一种软提示调整方法，通过优化可学习的提示令牌，在文本生成过程中定期注入以增强安全意识，从而有效防止有害内容生成。此外，我们的安全提醒仅在检测到有害内容时激活，不影响正常对话，并保持模型在良性任务上的性能。通过在三个已建立的安全基准和一个对抗攻击上的全面评估，我们证明了该方法显著降低了攻击成功率，同时保持了模型实用性，为实际应用中部署更安全的VLMs提供了一种实用解决方案。

</details>


### [200] [ContextBench: Modifying Contexts for Targeted Latent Activation](https://arxiv.org/abs/2506.15735)
**中文标题：ContextBench：通过上下文修改实现目标潜在特征激活**

*Robert Graham,Edward Stevinson,Leo Richter,Alexander Chia,Joseph Miller,Joseph Isaac Bloom*

主要分类: cs.AI

摘要简述: 本文提出ContextBench基准，用于评估通过上下文修改激活语言模型特定潜在特征或行为的方法，并改进进化提示优化（EPO）以平衡激活效果与语言流畅性。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在识别能触发语言模型特定行为或潜在特征的输入，以支持广泛的安全应用。当前方法在激活效果和语言流畅性之间存在平衡问题，亟需改进。

研究方法: 提出ContextBench基准，评估上下文修改方法的核心能力与安全应用潜力。改进进化提示优化（EPO），结合LLM辅助和扩散模型修复技术，提升激活效果与流畅性。

研究结果: 改进后的EPO方法在激活特定潜在特征或行为的同时保持语言流畅性，表现优于现有技术。

研究结论: ContextBench为评估上下文修改方法提供了有效工具，改进的EPO方法在平衡激活效果与流畅性方面达到最优。

中文摘要: 识别能够触发语言模型中特定行为或潜在特征的输入，可能具有广泛的安全应用价值。我们研究了一类能够生成目标明确、语言流畅的输入的方法，这些输入可以激活特定潜在特征或引发模型行为。我们将这种方法形式化为上下文修改，并提出了ContextBench——一个评估方法核心能力和潜在安全应用的基准。我们的评估框架同时衡量激发强度（潜在特征或行为的激活）和语言流畅性，揭示了当前最先进方法在平衡这些目标时的困难。我们通过LLM辅助和扩散模型修复技术改进了进化提示优化（EPO），并证明这些改进版本在平衡激发效果和流畅性方面达到了最先进的性能。

</details>


### [201] [SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents](https://arxiv.org/abs/2506.15740)
**中文标题：SHADE-Arena：评估LLM代理的破坏与监控能力**

*Jonathan Kutasov,Yuqi Sun,Paul Colognese,Teun van der Weij,Linda Petrini,Chen Bo Calvin Zhang,John Hughes,Xiang Deng,Henry Sleight,Tyler Tracy,Buck Shlegeris,Joe Benton*

主要分类: cs.AI

摘要简述: 本文研究了大型语言模型（LLM）作为自主代理时，是否能够通过隐藏目标对用户进行破坏，并评估了其在复杂任务中逃避监控的能力。通过SHADE-Arena数据集，测试了前沿LLM模型的破坏和监控能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）在复杂和长期任务中被广泛部署为自主代理，评估其是否能够通过隐藏目标对用户进行破坏变得至关重要。本文旨在研究前沿LLM模型在逃避监控的同时完成有害隐藏目标的能力。

研究方法: 研究使用了SHADE-Arena数据集，该数据集包含复杂的良性主任务和有害副目标的组合。评估了前沿LLM模型在完成副任务的同时不被LLM监控器发现的能力。模型的表现通过完成主任务、完成副任务和避免检测三个方面进行衡量。

研究结果: 研究发现，当前表现最好的前沿模型（Claude 3.7 Sonnet和Gemini 2.5 Pro）在Claude 3.6 Sonnet的监控下，作为破坏代理的成功率分别为27%和15%。此外，模型在监控能力方面表现最佳的是Gemini 2.5 Pro，其区分良性和恶意文本的AUC为0.87。

研究结论: 尽管当前模型在长期上下文主任务执行方面仍存在困难，但研究结果表明，监控细微破坏尝试的难度已经很高，且随着任务复杂性和长期性的增加，这一难度将进一步上升。

中文摘要: 随着大型语言模型（LLM）越来越多地被部署为复杂和长期任务中的自主代理，评估其通过隐藏目标对用户进行破坏的能力变得至关重要。我们研究了前沿LLM模型在完成多种现实任务时逃避监控并实现有害隐藏目标的能力。通过SHADE（细微有害代理检测与评估）-Arena，首个高度多样化的代理评估数据集，我们评估了LLM代理的破坏和监控能力。SHADE-Arena包含复杂环境中的良性主任务和有害副目标的组合。代理的评估标准包括完成副任务的同时不被LLM监控器发现。在衡量代理完成主任务、完成副任务和避免检测的能力时，我们发现表现最好的前沿模型（Claude 3.7 Sonnet和Gemini 2.5 Pro）在Claude 3.6 Sonnet的监控下，作为破坏代理的成功率分别为27%和15%。当前前沿模型在副任务上的成功很大程度上依赖于隐藏的草稿纸（监控器不可见）。我们还使用SHADE-Arena评估了模型的监控能力，表现最佳的监控器（Gemini 2.5 Pro）在区分良性和恶意文本时的AUC为0.87。目前，模型在破坏任务上仍因长期上下文主任务执行的失败而表现不佳。然而，我们的测量结果已表明，监控细微破坏尝试的难度很高，且随着任务复杂性和长期性的增加，这一难度将进一步上升。

</details>


### [202] [OAgents: An Empirical Study of Building Effective Agents](https://arxiv.org/abs/2506.15741)
**中文标题：OAgents：构建高效代理的实证研究**

*He Zhu,Tianrui Qin,King Zhu,Heyuan Huang,Yeyi Guan,Jinxiang Xia,Yi Yao,Hanhao Li,Ningning Wang,Pai Liu,Tianhao Peng,Xin Gui,Xiaowan Li,Yuhui Liu,Yuchen Eleanor Jiang,Jun Wang,Changwang Zhang,Xiangru Tang,Ge Zhang,Jian Yang,Minghao Liu,Xitong Gao,Wangchunshu Zhou,Jiaheng Liu*

主要分类: cs.AI

摘要简述: 本文通过系统实证研究，揭示了当前智能代理研究中缺乏标准化和科学严谨性的问题，并提出了一种更稳健的评估协议。研究发现某些设计选择对代理效果至关重要，而其他看似合理的部分则冗余。基于此，作者构建并开源了OAgents框架，实现了开源项目中的最佳性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前智能代理研究缺乏标准化和科学严谨性，导致不同方法之间难以公平比较，且设计选择对代理效果的影响尚不明确。本文旨在通过系统实证研究解决这些问题。

研究方法: 在GAIA基准和BrowseComp上进行了系统实证研究，分析了关键代理组件中流行设计选择的影响，并引入了一种更稳健的评估协议以减少随机运行的方差。

研究结果: 研究发现缺乏标准评估协议导致先前工作难以复现，且随机运行间存在显著差异。同时揭示了某些设计选择对代理效果至关重要，而其他部分冗余。基于此构建的OAgents框架在开源项目中表现最佳。

研究结论: 本文通过实证研究解决了智能代理研究中的标准化问题，提出了稳健的评估协议，并开源了高性能的OAgents框架，为未来研究提供了模块化设计基础。

中文摘要: 近年来，智能代理AI逐渐成为热门研究领域。然而，我们认为当前代理研究缺乏标准化和科学严谨性，导致难以公平比较不同方法的效果。因此，设计选择对代理框架的影响尚不明确，衡量其进展仍具挑战性。本研究在GAIA基准和BrowseComp上进行了系统实证研究，以公平严谨的方式分析关键代理组件中流行设计选择的影响。我们发现，缺乏标准评估协议使得先前工作（即使是开源的）难以复现，且随机运行间存在显著差异。因此，我们引入了一种更稳健的评估协议以稳定比较。研究揭示了哪些组件和设计对高效代理至关重要，而其他看似合理的部分则冗余。基于研究结果，我们构建并开源了OAgents，这是一种新的基础代理框架，在开源项目中实现了最佳性能。OAgents为各种代理组件提供了模块化设计，推动了智能代理AI的未来研究。

</details>


### [203] [Sysformer: Safeguarding Frozen Large Language Models with Adaptive System Prompts](https://arxiv.org/abs/2506.15751)
**中文标题：Sysformer：通过自适应系统提示保护冻结的大型语言模型**

*Kartik Sharma,Yiqiao Jin,Vineeth Rakesh,Yingtong Dou,Menghai Pan,Mahashweta Das,Srijan Kumar*

主要分类: cs.AI

摘要简述: Sysformer通过自适应系统提示保护冻结的大型语言模型，显著提升对有害提示的拒绝率和对安全提示的响应率。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在安全关键场景中部署时，需确保其响应符合安全标准。现有方法依赖昂贵的微调或次优启发式技术，亟需更高效的保护方案。

研究方法: 提出Sysformer，一种基于Transformer的模型，通过调整系统提示来优化LLM的输入嵌入空间，同时保持LLM参数冻结，训练其拒绝有害提示并理想响应安全提示。

研究结果: 实验表明，Sysformer显著提升LLM的鲁棒性，有害提示拒绝率最高提升80%，安全提示响应率最高提升90%，并能100%抵御复杂的越狱攻击。

研究结论: Sysformer为LLM提供了一种低成本保护方案，并推动了对可变系统提示设计的未来研究。

中文摘要: 随着大型语言模型（LLM）在安全关键场景中的部署，确保其响应符合安全标准至关重要。先前研究表明，LLM常无法理解安全行为概念，导致对无害提示的过度拒绝或生成有害内容。尽管已有大量研究提升其鲁棒性，现有防御方法通常依赖昂贵的模型参数微调或次优启发式技术。本文提出一种新方法，通过学习调整指令调优LLM的系统提示来保护模型。传统LLM通常遵循固定系统提示，而我们研究了根据用户输入定制系统提示对响应安全性的影响。为此，我们提出Sysformer，这是一种Transformer模型，可在LLM输入嵌入空间中更新初始系统提示为更鲁棒的版本，同时关注用户提示。在保持LLM参数冻结的情况下，Sysformer被训练为拒绝响应有害提示，同时理想响应安全提示。通过对5种不同家族的LLM和2个最新基准的广泛实验，我们证明Sysformer能显著提升LLM的鲁棒性，有害提示拒绝率最高提升80%，安全提示响应率最高提升90%。结果还表明，Sysformer能很好地泛化至复杂的越狱攻击，使LLM对不同攻击策略的鲁棒性最高提升100%。我们希望这些发现能为LLM的低成本保护提供思路，并推动未来对可变系统提示设计的研究。

</details>


### [204] [Linear-Time Primitives for Algorithm Development in Graphical Causal Inference](https://arxiv.org/abs/2506.15758)
**中文标题：图形因果推理中算法开发的线性时间原语**

*Marcel Wienöbst,Sebastian Weichwald,Leonard Henckel*

主要分类: cs.AI

摘要简述: 本文提出了CIfly框架，通过将因果推理任务简化为状态空间图中的可达性问题，提供高效的线性时间算法原语，并开源了高性能的Rust实现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的因果推理算法（如道德化和潜在投影）计算复杂度高，等价于布尔矩阵乘法，效率低下。CIfly旨在提供更高效的算法原语，简化因果推理任务的开发与部署。

研究方法: CIfly框架基于状态空间图的可达性操作，通过动态构建图结构并利用规则表指定算法，确保线性时间复杂度。开源实现采用Rust编写，支持Python和R调用。

研究结果: CIfly在多种因果推理任务中表现出高效性，重新实现了经典算法并开发了新的工具变量算法，验证了其灵活性和可扩展性。

研究结论: CIfly为图形因果推理提供了一个高效、灵活且易于部署的框架，推动了算法开发的实际应用。

中文摘要: 我们提出了CIfly框架，用于图形因果推理中的高效算法原语，将可达性作为可复用的核心操作。该框架基于一种洞察：许多因果推理任务可以简化为在动态构建的状态空间图中的可达性问题。我们形式化了规则表模式以指定此类算法，并证明其运行时间为线性。CIfly是道德化和潜在投影等常见原语的更高效替代方案，这些原语的计算复杂度等价于布尔矩阵乘法。我们的开源Rust实现解析规则表文本文件并运行指定的CIfly算法，提供可从Python和R访问的高性能执行。通过在该框架内重新实现一系列经典因果推理任务并开发新的工具变量算法，我们展示了CIfly的实用性。这些贡献使CIfly成为图形因果推理的灵活且可扩展的支柱，指导算法开发并实现轻松高效的部署。

</details>


### [205] [Advancing Stochastic 3-SAT Solvers by Dissipating Oversatisfied Constraints](https://arxiv.org/abs/2506.15774)
**中文标题：通过消除过满足约束提升随机3-SAT求解器的性能**

*J. Schwardt,J. C. Budich*

主要分类: cs.AI

摘要简述: 本文提出了一种名为DOCSAT的随机局部搜索启发式算法，用于解决3-SAT问题，通过减少过满足约束来避免局部极小值，显著优于现有算法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的3-SAT求解器（如WalkSAT）容易陷入局部极小值，这些极小值与真实解的区别在于过满足约束的数量较多。为了解决这一问题，本文提出了一种新方法。

研究方法: 提出的DOCSAT算法通过减少过满足约束（DOC）的数量，使其变得关键，从而避免陷入局部极小值。算法在随机生成的困难3-SAT实例上进行了测试。

研究结果: 实验表明，DOCSAT在解决最困难的3-SAT实例时，显著优于WalkSAT和其他知名算法（如Kissat），尤其是在样本中最难的五分之一实例上表现突出。

研究结论: DOCSAT通过利用组合问题的统计结构来避免局部极小值，为其他优化问题的解决提供了新的思路。

中文摘要: 我们提出并测试了一种用于解决NP完全问题3-SAT的随机局部搜索启发式算法，该算法在极其困难的临界实例中显著优于现有求解器。我们的方法基于一个关键观察：现有方法（如WalkSAT）容易陷入局部极小值，这些极小值与真实解的区别在于过满足的组合约束数量较多。为解决这一问题，提出的算法DOCSAT通过减少过满足约束（DOC）的数量，使其变得关键。我们在随机生成的困难但可满足的3-SAT实例上（问题规模高达N=15000）对算法进行了分析和测试。值得注意的是，DOCSAT在解决样本中最难的五分之一实例时，其表现优于WalkSAT和其他知名算法（包括完整求解器Kissat）。DOCSAT的核心可以被视为一种利用组合问题的主要成本函数之外的统计结构来避免或逃离局部极小值陷阱的方法，这为其他优化问题的解决提供了新的可能性。

</details>


### [206] [SLR: An Automated Synthesis Framework for Scalable Logical Reasoning](https://arxiv.org/abs/2506.15787)
**中文标题：SLR：一种用于可扩展逻辑推理的自动化合成框架**

*Lukas Helff,Ahmad Omar,Felix Friedrich,Wolfgang Stammer,Antonia Wüst,Tim Woydt,Rupert Mitchell,Patrick Schramowski,Kristian Kersting*

主要分类: cs.AI

摘要简述: SLR是一个端到端框架，用于通过可扩展逻辑推理系统评估和训练大型语言模型（LLMs）。它能自动生成可控难度的归纳推理任务，并创建SLR-Bench基准测试，发现当代LLMs在逻辑推理上仍有不足，但通过逻辑调优可显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在逻辑推理任务上的表现参差不齐，缺乏系统化的评估和训练方法。SLR旨在提供一个自动化框架，以可控的方式生成逻辑推理任务，从而更全面地评估和提升LLMs的逻辑推理能力。

研究方法: SLR框架通过用户任务描述自动生成：（1）潜在的真实规则，（2）用于验证模型输出的符号化程序，（3）推理任务的指令提示。基于此，创建了SLR-Bench基准测试，包含20个难度递增的课程级别，涵盖关系和递归复杂性。

研究结果: 评估发现，当代LLMs能生成语法正确的规则，但在逻辑推理上表现不佳。逻辑调优后，Llama-3-8B在SLR-Bench上的准确率翻倍，与Gemini-Flash-Thinking相当，但计算成本更低。

研究结论: SLR为LLMs的逻辑推理能力提供了可扩展的自动化评估和训练环境，无需人工标注，且能确保数据集的新颖性，显著提升了模型性能。

中文摘要: 我们介绍了SLR，一种通过可扩展逻辑推理系统评估和训练大型语言模型（LLMs）的端到端框架。根据用户的任务描述，SLR能够自动生成难度可控的归纳推理任务。对于每个任务，SLR会合成（i）潜在的真实规则，（ii）符号化法官用于确定性验证模型输出的可执行验证程序，以及（iii）推理任务的指令提示。利用SLR，我们创建了SLR-Bench基准测试，包含超过19k个提示，涵盖20个课程级别，逐步增加关系、算术和递归复杂性。大规模评估显示，当代LLMs能够轻松生成语法有效的规则，但在正确逻辑推理上常常失败。最近的推理LLMs表现稍好，但测试时的计算成本大幅增加，有时超过15k完成令牌。最后，通过SLR进行逻辑调优，Llama-3-8B在SLR-Bench上的准确率翻倍，以较低的计算成本达到与Gemini-Flash-Thinking相当的水平。SLR完全自动化，无需人工标注，确保数据集新颖性，并为探索和提升LLMs的推理能力提供了可扩展的环境。

</details>


### [207] [Deep Reinforcement Learning Xiangqi Player with Monte Carlo Tree Search](https://arxiv.org/abs/2506.15880)
**中文标题：基于蒙特卡洛树搜索的深度强化学习象棋玩家**

*Berk Yilmaz,Junyu Hu,Jinsong Liu*

主要分类: cs.AI

摘要简述: 本文提出了一种结合深度强化学习（DRL）与蒙特卡洛树搜索（MCTS）的象棋AI系统，用于解决象棋的复杂性问题，并通过自对弈提升决策能力。


<details>
  <summary>详细信息</summary>
研究动机: 象棋作为一种具有文化意义的策略游戏，其复杂性（如独特的棋盘布局、棋子移动限制和胜利条件）尚未被充分探索。本文旨在通过结合DRL与MCTS，提升AI在象棋中的表现，并为其他领域特定规则系统的适应性提供参考。

研究方法: 采用策略-价值网络与MCTS结合的方法，模拟棋子移动的后果并优化决策。通过解决象棋的高分支因子和非对称棋子动态等挑战，实现了自对弈和自我改进。

研究结果: 该系统成功克服了象棋的复杂性，提升了AI的决策能力，为文化策略游戏的AI研究提供了新思路，并展示了DRL-MCTS框架在领域特定规则系统中的适应性。

研究结论: 本文通过结合DRL与MCTS，不仅提升了AI在象棋中的表现，还为其他复杂规则系统的AI应用提供了借鉴。

中文摘要: 本文提出了一种结合深度强化学习（DRL）与蒙特卡洛树搜索（MCTS）的象棋AI系统，旨在通过自对弈和自我改进解决象棋的复杂性问题。针对象棋独特的棋盘布局、棋子移动限制和胜利条件，我们采用策略-价值网络与MCTS结合的方法，模拟棋子移动后果并优化决策。通过克服象棋的高分支因子和非对称棋子动态等挑战，本研究不仅提升了AI在文化策略游戏中的能力，还为DRL-MCTS框架在领域特定规则系统中的适应性提供了见解。

</details>


### [208] [Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues](https://arxiv.org/abs/2506.15928)
**中文标题：探索大五人格与AI能力在LLM模拟谈判对话中的影响**

*Myke C. Cohen,Zhe Su,Hsien-Te Kao,Daniel Nguyen,Spencer Lynch,Maarten Sap,Svitlana Volkova*

主要分类: cs.AI

摘要简述: 本文提出了一种评估任务关键谈判场景中代理AI系统的框架，通过实验探究人格特质和AI特性对LLM模拟谈判结果的影响，发现宜人性和外向性显著影响谈判效果，并展示了AI透明度和适应性对任务成功的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在解决任务关键场景中AI代理如何适应多样化人类操作者和利益相关者的需求，为高可靠性AI系统的开发提供支持。

研究方法: 使用Sotopia作为模拟平台，设计两个实验：实验一通过因果发现方法分析人格特质对价格谈判的影响；实验二通过操纵模拟人类人格和AI特性（透明度、能力、适应性）评估人机谈判效果。

研究结果: 实验一发现宜人性和外向性显著影响谈判的可信度、目标达成和知识获取；实验二表明AI的透明度和适应性对任务成功至关重要。

研究结论: 研究为评估多样化操作者人格和人机团队动态中的AI可靠性提供了可重复的方法，支持复杂任务中社会动态的整合。

中文摘要: 本文提出了一种用于任务关键谈判场景中代理AI系统的评估框架，旨在满足AI代理适应多样化人类操作者和利益相关者的需求。通过Sotopia模拟平台，我们进行了两项实验，系统评估了人格特质和AI代理特性对LLM模拟社会谈判结果的影响——这是涉及跨团队协调和军民互动的多种应用中的关键能力。实验一采用因果发现方法测量人格特质对价格谈判的影响，发现宜人性和外向性显著影响可信度、目标达成和知识获取结果。从团队沟通中提取的社会认知词汇测量揭示了代理在共情沟通、道德基础和观点模式上的细微差异，为高风险操作场景中可靠运行的代理AI系统提供了实用见解。实验二通过操纵模拟人类人格和AI系统特性（透明度、能力、适应性）评估人机工作谈判，展示了AI代理可信度对任务效果的影响。这些发现为实验多样化操作者人格和人机团队动态中的AI可靠性建立了可重复的评估方法，直接支持高可靠性AI系统的操作需求。我们的工作通过超越标准性能指标，整合复杂任务中社会动态，推动了代理AI工作流程的评估。

</details>


### [209] [Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning](https://arxiv.org/abs/2506.16015)
**中文标题：加权权威的贝叶斯认识论：一种促进真实性的自主科学推理形式化架构**

*Craig S. Wright*

主要分类: cs.AI

摘要简述: 本文提出了一种名为BEWA的贝叶斯认识论加权权威架构，旨在通过动态概率模型、作者权威评估和时间衰减机制，构建一个可计算验证的科学推理网络，以提升机器推理系统的真实性和完整性。


<details>
  <summary>详细信息</summary>
研究动机: 科学文献的爆炸式增长已超出人类专家和当前人工智能系统的处理能力，亟需一种能够动态评估科学主张、权威性和时间相关性的结构化方法。

研究方法: BEWA架构通过贝叶斯推理、矛盾处理和时间衰减机制动态更新信念，结合复制分数、引用权重和作者可信度建模，支持基于图的声明传播和加密锚定验证。

研究结果: BEWA成功将科学推理形式化为可计算验证的认识网络，提升了机器推理系统的真实性、理性信念收敛和审计弹性。

研究结论: BEWA为动态科学领域中的机器推理系统提供了基础，支持真实效用、理性信念收敛和审计完整性。

中文摘要: 科学文献的指数级增长已超出人类专家和当前人工智能系统的认知处理能力。本文提出了一种名为“加权权威的贝叶斯认识论”（BEWA）的形式化架构，将信念操作化为对结构化科学主张的动态、概率一致函数。每个主张均通过复制分数、引用权重和时间衰减系统进行情境化、作者归属和评估。信念更新通过证据条件的贝叶斯推理、矛盾处理和时间衰减机制实现。该架构支持基于图的声明传播、作者可信度建模、加密锚定和零知识审计验证。通过将科学推理形式化为可计算验证的认识网络，BEWA为促进真实效用、理性信念收敛和动态科学领域中审计弹性完整性的机器推理系统奠定了基础。

</details>


### [210] [Dual-Objective Reinforcement Learning with Novel Hamilton-Jacobi-Bellman Formulations](https://arxiv.org/abs/2506.16016)
**中文标题：基于新型Hamilton-Jacobi-Bellman方程的双目标强化学习**

*William Sharpless,Dylan Hirsch,Sander Tonkens,Nikhil Shinde,Sylvia Herbert*

主要分类: cs.AI

摘要简述: 本文提出了一种基于Hamilton-Jacobi-Bellman方程的双目标强化学习方法，解决了‘始终到达-避免’和‘到达-到达’问题，并通过改进的PPO算法（DO-HJ-PPO）在多任务中表现优于基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习中的硬约束（如奖励函数或模型架构）常导致策略性能下降，而拉格朗日方法需要复杂的奖励工程和参数调整。本文旨在通过Hamilton-Jacobi方程与强化学习的结合，提出新的价值函数来解决双目标问题。

研究方法: 通过分解问题为到达、避免和到达-避免子问题，提出了两种新的价值函数，并基于此设计了改进的PPO算法（DO-HJ-PPO）。该方法避免了时序逻辑方法的复杂性，直接利用Bellman方程求解。

研究结果: 在安全到达和多目标实现任务中，DO-HJ-PPO表现出与以往方法不同的行为，并在多种指标上优于基线方法。

研究结论: 本文提出的双目标强化学习方法为约束决策提供了新视角，并通过实验验证了其有效性。

中文摘要: 强化学习（RL）中的硬约束（无论是通过奖励函数还是模型架构施加的）通常会降低策略性能。拉格朗日方法提供了一种将目标与约束结合的方式，但通常需要复杂的奖励工程和参数调整。本研究扩展了近期将Hamilton-Jacobi（HJ）方程与RL结合的研究，提出了两种新的价值函数来解决双目标问题。具体而言，我们解决了：（1）‘始终到达-避免’问题——实现不同的奖励和惩罚阈值；（2）‘到达-到达’问题——实现两种不同奖励的阈值。与时序逻辑方法（通常涉及自动机表示）不同，我们通过将问题分解为到达、避免和到达-避免子问题，推导出显式且易处理的Bellman形式，从而利用上述最新进展。从数学角度看，‘始终到达-避免’和‘到达-到达’问题是互补的，且与标准的奖励求和问题及时序逻辑问题有本质区别，为约束决策提供了新视角。基于此分析，我们提出了一种改进的近端策略优化算法（DO-HJ-PPO）来解决这些问题。在一系列安全到达和多目标实现任务中，DO-HJ-PPO表现出与以往方法不同的行为，并在多种指标上优于多个基线方法。

</details>


### [211] [OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents](https://arxiv.org/abs/2506.16042)
**中文标题：OSWorld-Human：评估计算机使用代理的效率**

*Reyna Abhyankar,Qi Qi,Yiying Zhang*

主要分类: cs.AI

摘要简述: 生成式AI用于解决桌面应用任务时，现有系统因高延迟（如数十分钟）而难以实用。本文首次研究计算机代理的时间性能，发现大模型调用是延迟主因，并构建了人工标注数据集OSWorld-Human，评估16种代理效率。


<details>
  <summary>详细信息</summary>
研究动机: 当前生成式AI在解决计算机任务时，尽管准确性高，但因高延迟难以实用。为探究原因并指导未来开发，本文首次研究计算机代理的时间性能。

研究方法: 研究基于OSWorld基准，分析代理的时间性能，发现大模型调用是延迟主因。随后构建人工标注数据集OSWorld-Human，评估16种代理的效率。

研究结果: 研究发现，大模型调用占延迟主要部分，且任务步骤越多，后续步骤耗时越长。最高分代理仍需1.4-2.7倍多余步骤。

研究结论: 计算机代理的高延迟主要由大模型调用导致，未来需优化效率以减少步骤和延迟。

中文摘要: 生成式AI正被用于解决涉及桌面应用的各种计算机任务。现有系统仅关注提高领先基准的准确性，但由于极高的端到端延迟（如数十分钟），这些系统实际上难以使用，而人类完成同类任务仅需几分钟。为探究原因并指导计算机代理的未来发展，我们在OSWorld（计算机使用AI的旗舰基准）上首次研究了计算机代理的时间性能。研究发现，规划和反思的大模型调用占整体延迟的主要部分，且随着代理完成任务步骤的增加，后续步骤耗时可达初始步骤的3倍。随后，我们构建了OSWorld-Human，这是原始OSWorld数据集的人工标注版本，包含每个任务的人工确定轨迹。我们评估了16种代理在OSWorld-Human上的效率，发现即使是OSWorld上得分最高的代理，其步骤数仍比必要步骤多1.4-2.7倍。

</details>


### [212] [Consistency Verification in Ontology-Based Process Models with Parameter Interdependencies](https://arxiv.org/abs/2506.16087)
**中文标题：基于本体且参数依赖的过程模型中的一致性验证**

*Tom Jeleniewski,Hamied Nabizada,Jonathan Reif,Felix Gehlhoff,Alexander Fay*

主要分类: cs.AI

摘要简述: 本文提出了一种基于本体的过程模型验证机制，用于确保制造过程中参数依赖关系的语义一致性和数据完整性，并通过树脂传递模塑（RTM）案例验证了其适用性。


<details>
  <summary>详细信息</summary>
研究动机: 制造过程中参数依赖关系的建模需要数学表达式支持计算、验证和仿真，但这些表达式通常以通用形式定义并跨多个上下文应用。为确保数据检索和解释的正确性，需要一种语义一致且完整的模型验证机制。

研究方法: 方法包括：(i) 基于SPARQL的过滤以检索过程相关数据，(ii) 基于预期单位和语义分类的单位一致性检查，(iii) 数据完整性检查以验证依赖关系的可评估性。

研究结果: 通过树脂传递模塑（RTM）案例验证了该方法的适用性，支持开发机器可解释且可验证的工程模型。

研究结论: 本文提出的验证机制有效解决了参数依赖关系建模中的语义一致性和数据完整性问题，为制造过程的标准化和知识重用提供了支持。

中文摘要: 使用本体对过程知识进行形式化，能够一致地建模制造过程中的参数依赖关系。这些依赖关系通常表示为定义参数间关系的数学表达式，支持计算、验证和仿真等任务。为支持跨上下文应用和知识重用，此类表达式通常以通用形式定义并应用于多个过程上下文。这凸显了需要一种语义一致且连贯的模型以确保数据检索和解释的正确性。因此，需要专门的机制来解决关键挑战，如选择上下文相关数据、确保变量与数据元素的单位兼容性，以及验证评估数学表达式所需的输入数据完整性。本文提出了一组验证机制，用于先前开发的基于本体的过程模型，该模型集成了标准化过程语义、数据元素定义和形式化数学构造。方法包括：(i) 基于SPARQL的过滤以检索过程相关数据，(ii) 基于预期单位注释和语义分类的单位一致性检查，(iii) 数据完整性检查以验证依赖关系的可评估性。通过树脂传递模塑（RTM）案例验证了该方法的适用性，支持开发机器可解释且可验证的工程模型。

</details>


### [213] [Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction](https://arxiv.org/abs/2506.16144)
**中文标题：黑盒优化中的几何学习：基于GNN的算法性能预测框架**

*Ana Kostovska,Carola Doerr,Sašo Džeroski,Panče Panov,Tome Eftimov*

主要分类: cs.AI

摘要简述: 本文提出了一种基于图神经网络（GNN）的框架，用于预测黑盒优化算法的性能，通过捕捉问题、算法配置和性能之间的复杂关系，相比传统表格方法，MSE提升了36.6%。


<details>
  <summary>详细信息</summary>
研究动机: 传统的黑盒优化算法性能预测方法通常依赖于问题特征的表格式表示，忽略了算法配置对性能的关键影响。本文旨在通过图数据结构和图神经网络，更全面地建模问题、算法配置与性能之间的复杂依赖关系。

研究方法: 本文采用异构图数据结构和图神经网络（GNN），对两种模块化框架（modCMA-ES和modDE）进行性能预测。这些框架分解了两种广泛使用的无导数优化算法（CMA-ES和DE），并在24个BBOB问题上评估了324种modCMA-ES和576种modDE变体。

研究结果: 实验结果表明，基于GNN的方法在MSE上比传统表格方法提升了36.6%，验证了几何学习在黑盒优化中的潜力。

研究结论: 本文证明了图神经网络在黑盒优化算法性能预测中的有效性，为未来研究提供了新的方向。

中文摘要: 在数值黑盒优化中，自动化算法性能预测通常依赖于问题特征（如探索性景观分析特征），这些特征通常以表格形式输入机器学习模型。然而，此类方法往往忽略了算法配置这一关键性能影响因素。算法操作、参数、问题特征与性能结果之间的关系构成了一个复杂结构，最适合用图表示。本研究探索了异构图数据结构和图神经网络（GNN）的应用，通过捕捉问题、算法配置与性能之间的复杂依赖关系，预测优化算法的性能。我们聚焦于两种模块化框架（modCMA-ES和modDE），它们分解了两种广泛使用的无导数优化算法：协方差矩阵自适应进化策略（CMA-ES）和差分进化（DE）。我们在24个BBOB问题上评估了324种modCMA-ES和576种modDE变体，覆盖六种运行时预算和两种问题维度。实验结果表明，相比传统表格方法，MSE提升了36.6%，凸显了几何学习在黑盒优化中的潜力。

</details>


### [214] [Large Language Models are Near-Optimal Decision-Makers with a Non-Human Learning Behavior](https://arxiv.org/abs/2506.16163)
**中文标题：大型语言模型是非人类学习行为的近最优决策者**

*Hao Li,Gengrui Zhang,Petter Holme,Shuyue Hu,Zhen Wang*

主要分类: cs.AI

摘要简述: 大型语言模型（LLMs）在决策任务中表现接近最优，但其学习行为与人类存在显著差异。研究表明，LLMs在不确定性、风险和适应性方面优于人类，但也凸显了依赖其替代人类判断的风险。


<details>
  <summary>详细信息</summary>
研究动机: 人类决策是社会和文明的基石，但未来可能由人工智能主导。大型语言模型（LLMs）的出现改变了AI支持的决策方式，但其学习过程与人类决策的差异尚不明确。本研究旨在比较LLMs与人类在不确定性、风险和适应性三个核心维度的决策行为。

研究方法: 研究选取了五种领先的LLMs，通过三项实验心理学任务（涉及不确定性、风险和适应性）对其决策行为进行测试，并与360名新招募的人类参与者进行对比。

研究结果: 在所有任务中，LLMs的表现接近最优，且显著优于人类。然而，其决策过程与人类存在根本性差异，尤其是在管理不确定性、校准风险和适应变化方面。

研究结论: LLMs在决策任务中表现出色，但其非人类的学习行为可能带来风险，需要进一步研究其作为人类判断替代品的可行性。

中文摘要: 人类决策是社会和文明的基石，但我们正迈向一个由人工智能主导决策的未来。大型语言模型（LLMs）的出现改变了AI支持的决策方式，但其学习过程与人类决策的差异尚不明确。本研究通过三项实验心理学任务（涉及不确定性、风险和适应性），比较了五种领先的LLMs与360名人类参与者的决策行为。结果显示，LLMs在所有任务中表现接近最优，且其决策过程与人类存在根本性差异。一方面，LLMs展现了管理不确定性、校准风险和适应变化的能力；另一方面，这种差异凸显了依赖其替代人类判断的风险，呼吁进一步研究。

</details>


### [215] [Approximation Fixpoint Theory with Refined Approximation Spaces](https://arxiv.org/abs/2506.16294)
**中文标题：基于精细近似空间的近似不动点理论**

*Linde Vanbesien,Bart Bogaerts,Marc Denecker*

主要分类: cs.AI

摘要简述: 本文扩展了近似不动点理论（AFT），通过引入更精细的近似空间，解决了AFT在某些简单例子中的局限性，提升了其表达能力。


<details>
  <summary>详细信息</summary>
研究动机: 近似不动点理论（AFT）在非单调推理形式化中广泛应用，但在某些简单例子中存在局限性。本文旨在通过引入更精细的近似空间，克服这些限制。

研究方法: 作者扩展了AFT，引入更一般的近似空间概念，展示了其更强的表达能力，并研究了不同近似空间之间的关系。

研究结果: 研究结果表明，扩展后的AFT能够处理比区间更精细的近似，从而提升了理论的适用性和表达能力。

研究结论: 本文通过引入更精细的近似空间，成功扩展了AFT，解决了其原有局限性，为非单调推理形式化提供了更强大的理论工具。

中文摘要: 近似不动点理论（AFT）是一种强大的理论，涵盖了知识表示中非单调推理形式化的多种语义，如逻辑编程和答案集编程。这些非单调形式化的许多语义可以被描述为适当格上非单调算子的合适不动点。AFT不是直接在原始格上操作，而是通过格中的区间来近似或构造感兴趣的不动点。尽管AFT在广泛的非单调推理形式化中成功应用，但在其他相对简单的例子中仍面临局限性。本文通过扩展一致性AFT以处理比区间更精细的近似，克服了这些局限性。为此，我们引入了一种更一般的近似空间概念，展示了其更强的表达能力，并研究了不同近似空间之间的关系。

</details>


### [216] [Explainable Rule Application via Structured Prompting: A Neural-Symbolic Approach](https://arxiv.org/abs/2506.16335)
**中文标题：通过结构化提示实现可解释的规则应用：一种神经符号方法**

*Albert Sadowski,Jarosław A. Chudziak*

主要分类: cs.AI

摘要简述: 本文提出了一种结合神经与符号方法的框架，通过结构化提示将推理分解为可验证的三步，以解决大语言模型在规则应用和可解释性上的不足，尤其在法律分析领域表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLMs）在复杂推理任务中表现优异，但在规则一致性、异常处理和可解释性上存在不足，尤其是在需要自然语言理解和精确逻辑推理的领域（如法律分析）。本文旨在通过神经与符号方法的结合，提升模型在这些任务中的表现。

研究方法: 提出了一种结构化提示框架，将推理分解为三个可验证步骤：实体识别、属性提取和符号规则应用。通过结合神经模型的灵活性和符号方法的逻辑一致性，并允许领域专家在不改变架构的情况下优化逻辑结构。

研究结果: 在LegalBench的传闻判定任务中，该方法显著优于基线模型。OpenAI o系列模型表现尤为突出，o1的F1分数达到0.929，o3-mini达到0.867，而基线模型的分数分别为0.714和0.74。

研究结论: 这种神经与符号结合的框架为透明且一致的基于规则的推理提供了可行路径，尤其在结构化法律推理任务中具有潜在应用价值。

中文摘要: 大语言模型（LLMs）在复杂推理任务中表现出色，但在规则应用的一致性、异常处理和可解释性方面存在不足，尤其是在需要自然语言理解和精确逻辑推理的领域（如法律分析）。本文提出了一种结构化提示框架，将推理分解为三个可验证步骤：实体识别、属性提取和符号规则应用。通过结合神经与符号方法，该框架既利用了LLMs的解释灵活性，又通过形式化验证确保了逻辑一致性。框架将任务定义外部化，使领域专家能够在不改变架构的情况下优化逻辑结构。在LegalBench的传闻判定任务中，该方法显著优于基线模型，OpenAI o系列模型表现尤为突出，o1的F1分数达到0.929，o3-mini达到0.867，而基线模型的分数分别为0.714和0.74。这种神经与符号结合的混合系统为透明且一致的基于规则的推理提供了可行路径，展示了在结构化法律推理任务中可解释AI应用的潜力。

</details>


### [217] [IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks](https://arxiv.org/abs/2506.16402)
**中文标题：IS-Bench：评估VLM驱动的具身代理在日常家庭任务中的交互安全性**

*Xiaoya Lu,Zeren Chen,Xuhao Hu,Yijin Zhou,Weichen Zhang,Dongrui Liu,Lu Sheng,Jing Shao*

主要分类: cs.AI

摘要简述: IS-Bench是一个多模态基准测试，用于评估VLM驱动的具身代理在家庭任务中的交互安全性，揭示当前代理缺乏安全感知能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有静态、非交互式评估方法无法准确模拟动态风险，导致VLM驱动的具身代理在家庭任务中存在安全隐患，亟需一种新的评估范式。

研究方法: 提出IS-Bench基准，包含161个挑战性场景和388个独特安全风险，支持过程导向评估，验证代理是否在风险步骤前后执行缓解措施。

研究结果: 实验表明，当前代理（如GPT-4o和Gemini-2.5）缺乏交互安全感知，安全感知的思维链虽能提升性能，但常影响任务完成。

研究结论: IS-Bench为开发更安全可靠的具身AI系统奠定了基础，揭示了现有代理的关键局限性。

中文摘要: VLM驱动的具身代理在家庭任务中的错误规划会带来重大安全隐患，而现有的静态、非交互式评估范式无法准确评估这些交互环境中的风险，因为它们无法模拟代理行为引发的动态风险，且依赖不可靠的事后评估。为填补这一空白，我们提出评估代理的交互安全性：其感知突发风险并按正确顺序执行缓解措施的能力。为此，我们推出IS-Bench，首个专为交互安全性设计的多模态基准测试，包含161个挑战性场景和388个独特安全风险，并在高保真模拟器中实现。关键的是，它支持一种新颖的过程导向评估，验证风险缓解措施是否在特定风险步骤前后执行。对包括GPT-4o和Gemini-2.5系列在内的领先VLM进行广泛实验，结果表明当前代理缺乏交互安全感知能力，且安全感知的思维链虽能提升性能，但常影响任务完成。通过揭示这些关键局限性，IS-Bench为开发更安全可靠的具身AI系统奠定了基础。

</details>


### [218] [Agentic Personalisation of Cross-Channel Marketing Experiences](https://arxiv.org/abs/2506.16429)
**中文标题：跨渠道营销体验的代理个性化**

*Sami Abboud,Eleanor Hanna,Olivier Jeunen,Vineesha Raheja,Schaun Wheeler*

主要分类: cs.AI

摘要简述: 本文提出了一种基于顺序决策框架的跨渠道营销个性化方法，通过差异中的差异设计和汤普森采样优化用户参与度，已在1.5亿用户中成功部署并显著提升目标事件。


<details>
  <summary>详细信息</summary>
研究动机: 传统营销内容编排依赖人工操作，效率低且难以实现个性化。本文旨在通过自动化决策框架优化内容、时机、频率和文案的个性化，提升用户参与度。

研究方法: 采用顺序决策框架，结合差异中的差异设计估计个体处理效应，并使用汤普森采样平衡探索与利用的权衡，以优化模块化决策策略。

研究结果: 在多服务应用中，该方法显著提升了多种目标事件的参与度，目前已部署于1.5亿用户中。

研究结论: 本文提出的自动化决策框架有效解决了传统营销的个性化瓶颈，显著提升了用户参与度，具有广泛的应用潜力。

中文摘要: 消费者应用提供了丰富的展示和传达内容的机会，包括新功能或订阅的促销活动、长期用户粘性激励以及个性化推荐，覆盖电子邮件、推送通知和应用内界面。传统的沟通编排方法依赖劳动密集型的人工营销工作，限制了内容、时机、频率和文案的个性化效果。我们将此任务形式化为顺序决策框架，旨在优化模块化决策策略以最大化任何漏斗事件的增量参与度。我们的方法利用差异中的差异设计估计个体处理效应，并通过汤普森采样平衡探索与利用的权衡。我们在一个多服务应用中展示了该方法的结果，显著提升了多种产品功能的目标事件参与度，目前已部署于1.5亿用户中。

</details>


### [219] [ML-Master: Towards AI-for-AI via Integration of Exploration and Reasoning](https://arxiv.org/abs/2506.16499)
**中文标题：ML-Master：通过探索与推理的整合实现AI-for-AI**

*Zexi Liu,Yuzhu Cai,Xinyu Zhu,Yujie Zheng,Runkun Chen,Ying Wen,Yanfeng Wang,Weinan E,Siheng Chen*

主要分类: cs.AI

摘要简述: ML-Master是一种新型AI4AI代理，通过整合探索与推理，利用选择性记忆机制优化AI系统设计，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI能力接近或超越人类水平，AI驱动的开发比人类方法更高效。AI4AI利用AI技术自动化优化AI系统设计，但现有LLM代理无法充分利用探索中的经验，导致效率低下。

研究方法: ML-Master通过选择性记忆机制无缝整合探索与推理，结合并行解决方案的多样见解与分析推理，避免信息过载。

研究结果: 在MLE-Bench上，ML-Master平均奖牌率29.3%，显著超越现有方法，尤其在中等复杂度任务中，且仅用12小时完成（基准为24小时）。

研究结论: ML-Master展示了作为AI4AI强大工具的潜力，通过高效整合探索与推理提升性能。

中文摘要: 随着AI能力接近或超越人类水平，AI驱动的开发比人类方法更高效。AI4AI利用AI技术自动化优化AI系统设计，但现有LLM代理无法充分利用探索中的经验，导致效率低下。为此，我们提出ML-Master，一种新型AI4AI代理，通过选择性记忆机制无缝整合探索与推理。该方法使ML-Master能高效结合并行解决方案的多样见解与分析推理，避免信息过载。在MLE-Bench上，ML-Master平均奖牌率29.3%，显著超越现有方法，尤其在中等复杂度任务中，且仅用12小时完成（基准为24小时）。这些结果展示了ML-Master作为AI4AI强大工具的潜力。

</details>


### [220] [Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System](https://arxiv.org/abs/2506.16575)
**中文标题：提升组织研究中有害内容检测：将大语言模型与Elo评分系统结合**

*Mustafa Akben,Aaron Satko*

主要分类: cs.AI

摘要简述: 本文提出了一种基于Elo评分系统的方法，显著提升了大语言模型（LLMs）在有害内容检测中的性能，尤其在微侵犯和仇恨言论分析中表现优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLMs）在组织研究中具有潜力，但其内置的审核系统在分析有害内容时可能导致结果失真，例如拒绝执行某些指令或生成过于谨慎的响应。这在分析组织冲突（如微侵犯或仇恨言论）时尤为突出。

研究方法: 论文提出了一种基于Elo评分系统的方法，用于改进LLMs在有害内容分析中的表现。该方法通过评分机制优化模型的输出，减少误报并提升可靠性。

研究结果: 在两个数据集（微侵犯检测和仇恨言论分析）上的实验表明，该方法在准确性、精确度和F1分数等关键指标上优于传统的LLM提示技术和常规机器学习模型。

研究结论: 该方法不仅提升了有害内容分析的可靠性，还具备更好的扩展性，适用于大规模数据集，为组织应用（如职场骚扰检测和有毒沟通评估）提供了支持。

中文摘要: 大语言模型（LLMs）为组织研究提供了广阔前景，但其内置的审核系统在分析有害内容时可能引发问题，例如拒绝执行某些指令或生成过于谨慎的响应，从而影响结果的效度。这在分析组织冲突（如微侵犯或仇恨言论）时尤为突出。本文提出了一种基于Elo评分的方法，显著提升了LLMs在有害内容分析中的性能。在两个数据集（微侵犯检测和仇恨言论分析）上的实验表明，该方法在准确性、精确度和F1分数等关键指标上优于传统的LLM提示技术和常规机器学习模型。其优势包括更高的可靠性、更少的误报以及更好的扩展性，适用于大规模数据集。这一方法支持组织应用，包括职场骚扰检测、有毒沟通评估以及营造更安全、更包容的工作环境。

</details>


### [221] [A Community-driven vision for a new Knowledge Resource for AI](https://arxiv.org/abs/2506.16596)
**中文标题：社区驱动的新型AI知识资源愿景**

*Vinay K Chaudhri,Chaitan Baru,Brandon Bennett,Mehul Bhatt,Darion Cassel,Anthony G Cohn,Rina Dechter,Esra Erdem,Dave Ferrucci,Ken Forbus,Gregory Gelfond,Michael Genesereth,Andrew S. Gordon,Benjamin Grosof,Gopal Gupta,Jim Hendler,Sharat Israni,Tyler R. Josephson,Patrick Kyllonen,Yuliya Lierler,Vladimir Lifschitz,Clifton McFate,Hande K. McGinty,Leora Morgenstern,Alessandro Oltramari,Praveen Paritosh,Dan Roth,Blake Shepard,Cogan Shimzu,Denny Vrandečić,Mark Whiting,Michael Witbrock*

主要分类: cs.AI

摘要简述: 本文探讨了AI领域亟需的新型知识资源，提出了一种社区驱动的开发愿景，旨在通过开放工程框架整合知识模块，以解决当前知识资源的不足。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有WordNet、ConceptNet等知识资源，AI领域仍缺乏可验证、通用的知识来源，导致语言模型知识缺口、机器人规划缺乏世界知识等问题。本文旨在探索如何利用现代技术开发更有效的知识基础设施。

研究方法: 通过AAAI研讨会汇集50多名研究人员，探讨AI领域最需要的知识资源类型及其开发方法，提出利用知识表示与推理的现代进展，构建开放的工程框架。

研究结果: 研究提出了一种社区驱动的知识基础设施愿景，强调通过开放框架整合知识模块，并制定贡献者遵循的规范和社会结构。

研究结论: 开发新型知识资源需结合现代技术与社区协作，开放的工程框架是实现这一目标的关键。

中文摘要: 长期以来，构建一个全面、多用途的知识资源（如1984年的Cyc项目）一直是AI领域的目标。尽管已有WordNet、ConceptNet、Wolfram|Alpha等商业知识图谱的成功案例，但可验证、通用且广泛可用的知识来源仍是AI基础设施的关键缺失。大型语言模型因知识缺口而受限，机器人规划缺乏必要的世界知识，而事实错误检测则高度依赖人类专业知识。当前AI最需要何种知识资源？现代技术如何影响其开发与评估？近期AAAI研讨会汇集了50多名研究人员探讨这些问题。本文综合了我们的发现，并提出了社区驱动的新型知识基础设施愿景。除了利用知识表示与推理的现代进展外，一个可行的思路是构建开放工程框架，以在实际应用中有效利用知识模块。此类框架应包括贡献者遵循的规范和社会结构。

</details>


### [222] [The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring](https://arxiv.org/abs/2506.16617)
**中文标题：解释风格与感知准确性对预测性流程监控中决策的影响**

*Soobin Chae,Suhwan Lee,Hanna Hauptmann,Hajo A. Reijers,Xixi Lu*

主要分类: cs.AI

摘要简述: 本文研究了在预测性流程监控（PPM）中，解释风格（特征重要性、基于规则和反事实）和感知AI准确性（低或高）对决策的影响。通过实验发现，感知准确性和解释风格对任务表现和决策信心有显著影响。


<details>
  <summary>详细信息</summary>
研究动机: 预测性流程监控（PPM）中，深度学习模型虽然预测准确，但缺乏可解释性，影响用户信任和采用。可解释AI（XAI）旨在解决这一问题，但现有评估多关注功能指标，忽略了用户中心的影响。本文旨在填补这一空白，研究解释风格和感知准确性对决策的影响。

研究方法: 通过决策实验，用户被提供AI预测、感知准确性水平和不同风格的解释。测量用户在接收解释前后的决策，评估客观指标（任务表现和一致性）和主观指标（决策信心）。

研究结果: 研究发现，感知准确性和解释风格对决策有显著影响，不同风格的解释和准确性水平对任务表现和决策信心产生不同效果。

研究结论: 感知准确性和解释风格在PPM中显著影响用户决策，强调了在XAI设计中考虑用户中心因素的重要性。

中文摘要: 预测性流程监控（PPM）通常使用深度学习模型预测未来流程行为（如流程结果）。尽管这些模型准确性高，但其缺乏可解释性削弱了用户信任和采用。可解释AI（XAI）旨在通过提供预测背后的推理来解决这一问题。然而，目前对XAI在PPM中的评估主要关注功能指标（如保真度），忽略了其对任务表现和决策等用户中心方面的影响。本研究探讨了解释风格（特征重要性、基于规则和反事实）和感知AI准确性（低或高）对PPM中决策的影响。我们进行了一项决策实验，用户被提供AI预测、感知准确性水平和不同风格的解释。测量用户在接收解释前后的决策，评估客观指标（任务表现和一致性）和主观指标（决策信心）。研究结果表明，感知准确性和解释风格具有显著影响。

</details>


### [223] [Interpretable Low-Dimensional Modeling of Spatiotemporal Agent States for Decision Making in Football Tactics](https://arxiv.org/abs/2506.16696)
**中文标题：足球战术决策中时空代理状态的可解释低维建模**

*Kenjiro Ide,Taiga Someya,Kohei Kawaguchi,Keisuke Fujii*

主要分类: cs.AI

摘要简述: 本研究提出了一种低维、基于规则的模型，用于捕捉足球战术中的时空数据，通过可解释的状态变量（如持球者和潜在接球者的距离和空间评分）预测传球成功率，为战术分析和决策提供支持。


<details>
  <summary>详细信息</summary>
研究动机: 现有足球战术模型计算成本高或缺乏可解释性，而基于规则的方法未能全面考虑球员状态。本研究旨在探索低维、基于规则的模型是否能有效捕捉战术，并通过可解释变量支持决策。

研究方法: 研究定义了持球者和潜在接球者的可解释状态变量（如距离和空间评分），结合StatsBomb事件数据和SkillCorner追踪数据，训练XGBoost模型预测传球成功率。

研究结果: 分析显示，球员与球的距离及其空间评分是传球成功的关键因素。模型通过低维变量实现了战术分析的可解释性和实用性。

研究结论: 低维、基于规则的模型能有效捕捉足球战术，并通过直观变量支持决策，为教练和分析师提供了实用工具。

中文摘要: 理解足球战术对教练和分析师至关重要。以往研究基于空间和运动学方程建模，但计算成本高；强化学习方法虽使用球员位置和速度，但缺乏可解释性且需大数据。基于规则的模型符合专家知识，但未全面考虑球员状态。本研究探讨低维、基于规则的时空数据模型是否能有效捕捉战术。我们定义了持球者和潜在接球者的可解释状态变量（如传球选项），并通过与教练讨论确定关键变量。使用2023/24赛季LaLiga的StatsBomb事件数据和SkillCorner追踪数据训练XGBoost模型预测传球成功率。分析表明，球员与球的距离及空间评分是传球成功的关键因素。这一低维模型通过直观变量支持战术分析和决策。

</details>


### [224] [Incentivizing High-quality Participation From Federated Learning Agents](https://arxiv.org/abs/2506.16731)
**中文标题：激励联邦学习代理的高质量参与**

*Jinlong Pang,Jiaheng Wei,Yifan Hua,Chen Qian,Yang Liu*

主要分类: cs.AI

摘要简述: 本文提出了一种激励联邦学习（FL）中高质量参与的框架，通过考虑数据异质性并设计激励机制，加速模型收敛。


<details>
  <summary>详细信息</summary>
研究动机: 现有联邦学习研究假设参与者自愿无私，但实际中自私的代理可能退出或提供低质量贡献；同时，现有机制忽略了数据异质性导致的努力差异，导致聚合模型效果不佳。

研究方法: 引入Wasserstein距离量化数据异质性，重新定义收敛上界；利用同伴预测机制设计评分函数以激励真实报告；提出两阶段Stackelberg博弈模型验证均衡存在性。

研究结果: 在真实数据集上的实验验证了所提机制的有效性，能够显著提升模型收敛速度和参与质量。

研究结论: 本文提出的激励框架解决了联邦学习中参与质量和数据异质性问题，为实际应用提供了理论支持。

中文摘要: 联邦学习（FL）为多个客户端在不直接共享本地数据的情况下联合学习全局模型提供了有前景的范式。然而，现有研究存在两个问题：1）从代理的角度，通常假设参与者自愿无私，但自私的代理可能在缺乏激励时退出系统或提供低质量贡献；2）从机制设计者的角度，由于现有基于博弈论的联邦学习方法忽略了贡献数据可能导致的异质性努力，聚合模型效果可能不理想。为缓解这些问题，我们提出了一种考虑数据异质性的激励感知框架，以加速收敛过程。具体而言，我们首先引入Wasserstein距离明确量化异质性努力，并重新定义收敛上界。为激励代理真实报告，我们通过同伴预测机制分析并测量任意两代理的泛化误差差距，设计评分函数。进一步，我们提出两阶段Stackelberg博弈模型形式化该过程并验证均衡存在性。在真实数据集上的大量实验证明了所提机制的有效性。

</details>


### [225] [Reinforcement learning for hybrid charging stations planning and operation considering fixed and mobile chargers](https://arxiv.org/abs/2506.16764)
**中文标题：考虑固定与移动充电桩的混合充电站规划与运营的强化学习方法**

*Yanchen Zhu,Honghui Zou,Chufan Liu,Yuyu Luo,Yuankai Wu,Yuxuan Liang*

主要分类: cs.AI

摘要简述: 本文提出了一种结合固定和移动充电桩的混合充电基础设施规划与运营方法，通过深度强化学习和启发式调度技术优化充电桩布局与动态调度，显著提升充电资源利用率并减少用户不便。


<details>
  <summary>详细信息</summary>
研究动机: 车辆电动化的成功依赖于高效灵活的充电基础设施。传统固定充电桩常因需求动态变化导致利用率低或拥堵，移动充电桩的引入为动态需求提供了灵活性。本文旨在解决混合充电基础设施的规划与运营问题。

研究方法: 提出混合充电站规划与运营（HCSPO）问题，结合固定充电桩的布局优化与移动充电桩的动态调度。采用基于模型预测控制（MPC）的需求预测模型，并设计深度强化学习方法与启发式调度技术进行求解。

研究结果: 实际城市场景的案例研究表明，该方法显著提升了充电基础设施的可用性，并减少了用户不便，优于现有解决方案和基线方法。

研究结论: 通过结合固定和移动充电桩的混合规划与动态运营，能够有效应对充电需求的动态变化，为城市充电基础设施的优化提供了新思路。

中文摘要: 车辆电动化的成功依赖于高效且适应性强的充电基础设施，其带来的社会和环境影响显著。传统固定充电桩常因充电需求的动态性面临利用率低或拥堵问题，而移动充电桩作为一种灵活解决方案，能够根据需求波动调整位置。本文研究了混合充电基础设施的优化规划与运营问题，将固定与移动充电桩整合到城市道路网络中。我们提出了混合充电站规划与运营（HCSPO）问题，同时优化固定充电站的位置与配置，并调度移动充电桩进行动态运营。方法中引入了基于模型预测控制（MPC）的充电需求预测模型以提升决策能力。为解决HCSPO问题，我们提出了一种深度强化学习方法，结合启发式调度技术，有效连接固定充电桩的规划与移动充电桩的实时运营。通过实际城市场景的广泛案例研究，证明该方法显著提升了充电基础设施的可用性，并减少了用户不便，优于现有解决方案和基线方法。

</details>


### [226] [AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario](https://arxiv.org/abs/2506.16898)
**中文标题：Error**

*Ciro Beneduce,Massimiliano Luca,Bruno Lepri*

主要分类: cs.AI

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


### [227] [Real-Time Black-Box Optimization for Dynamic Discrete Environments Using Embedded Ising Machines](https://arxiv.org/abs/2506.16924)
**中文标题：基于嵌入式伊辛机的动态离散环境实时黑盒优化方法**

*Tomoya Kashimata,Yohei Hamakawa,Masaya Yamasaki,Kosuke Tatsumura*

主要分类: cs.AI

摘要简述: 本文提出了一种基于嵌入式伊辛机的启发式多臂老虎机方法，用于动态离散环境的实时黑盒优化，解决了传统方法在组合离散优化中的效率问题，并在移动用户无线通信系统中验证了其动态适应性。


<details>
  <summary>详细信息</summary>
研究动机: 实时系统需要在动态环境中优化离散变量，传统多臂老虎机算法因组合爆炸问题无法高效处理此类任务。本文旨在通过扩展基于伊辛机的黑盒优化方法，解决动态离散环境中的优化挑战。

研究方法: 提出了一种启发式多臂老虎机方法，利用伊辛机探索变量间的相互作用和动态环境变化，从而高效优化离散动作组合。

研究结果: 在移动用户无线通信系统中的实验表明，该方法能够有效适应动态环境，优化平均奖励。

研究结论: 通过结合伊辛机和启发式策略，本文方法为动态离散环境的实时优化提供了高效解决方案。

中文摘要: 许多实时系统需要对离散变量进行优化。黑盒优化（BBO）算法和多臂老虎机（MAB）算法通过反复执行动作并观察即时奖励进行优化，无需任何先验知识。最近，一种基于伊辛机的BBO方法被提出，用于在静态环境中找到由离散值组合表示的最佳动作以最大化即时奖励。然而，动态环境（实时系统的运行环境）需要多臂老虎机算法来最大化多次试验的平均奖励。由于离散优化的组合性质导致动作数量巨大，传统的MAB算法无法有效优化动态离散环境。本文通过扩展BBO方法，提出了一种启发式MAB方法，其中伊辛机在考虑变量间相互作用和动态环境变化的同时有效探索动作。我们在移动用户的无线通信系统中验证了该方法的动态适应性。

</details>


### [228] [Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning](https://arxiv.org/abs/2506.16931)
**中文标题：多模态融合学习在机器人任务规划中解决广义旅行商问题**

*Jiaqi Chen,Mingfeng Fan,Xuefeng Zhang,Jingsong Liang,Yuhong Cao,Guohua Wu,Guillaume Adrien Sartoretti*

主要分类: cs.AI

摘要简述: 本文提出了一种多模态融合学习（MMFL）框架，通过结合图和图像表示解决机器人任务规划中的广义旅行商问题（GTSP），实现了实时高效的任务规划。


<details>
  <summary>详细信息</summary>
研究动机: 移动机器人在仓库检索和环境监测等应用中需要高效的任务规划，而GTSP问题因其复杂性难以同时满足准确性和效率需求。

研究方法: 1. 提出坐标图像生成器，将GTSP问题转化为空间信息表示；2. 设计自适应分辨率缩放策略以应对不同规模问题；3. 开发多模态融合模块，整合几何与空间特征。

研究结果: 实验表明，MMFL方法在多种GTSP实例中显著优于现有方法，同时保持实时计算效率，物理机器人测试进一步验证了其实际有效性。

研究结论: MMFL框架通过多模态特征融合，成功解决了GTSP问题，为机器人实时任务规划提供了高效可靠的解决方案。

中文摘要: 高效的任务规划对移动机器人至关重要，尤其是在仓库检索和环境监测等应用中。这些任务通常需要从多个目标簇中各选一个位置，形成广义旅行商问题（GTSP），而该问题在准确性和效率上仍具挑战性。为此，我们提出了一种多模态融合学习（MMFL）框架，利用图和图像表示捕捉问题的互补特征，并学习一种能够实时生成高质量任务规划方案的策略。具体而言，我们首先引入基于坐标的图像生成器，将GTSP实例转化为空间信息表示；然后设计自适应分辨率缩放策略以增强对不同问题规模的适应性；最后开发了带专用瓶颈的多模态融合模块，实现几何与空间特征的有效整合。大量实验表明，我们的MMFL方法在多种GTSP实例中显著优于现有方法，同时满足实时机器人应用的计算效率需求。物理机器人测试进一步验证了其在真实场景中的实际有效性。

</details>


### [229] [Elevating Styled Mahjong Agents with Learning from Demonstration](https://arxiv.org/abs/2506.16995)
**中文标题：通过示范学习提升风格化麻将机器人**

*Lingfeng Li,Yunlong Lu,Yongyi Wang,Wenxin Li*

主要分类: cs.AI

摘要简述: 本文提出了一种新颖的“示范学习”（LfD）算法，用于提升麻将机器人的游戏水平并保留其独特风格。该方法基于现有麻将机器人的游戏历史，仅需对近端策略优化算法进行最小修改，实验证明其显著提升了机器人的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前游戏人工智能的研究主要集中在提升机器人的熟练度，而开发具有多样化独特风格的机器人仍是一个较少探索的领域。麻将游戏的高随机性和非分布状态导致现有离线学习和示范学习算法表现不佳，因此需要一种新方法来解决这一问题。

研究方法: 本文提出了一种基于示范学习的新算法，利用现有麻将机器人的游戏历史数据，仅对近端策略优化（PPO）算法进行最小修改。该方法旨在提升机器人的游戏水平，同时保留其独特的游戏风格。

研究结果: 实验结果表明，所提出的方法不仅显著提升了麻将机器人的游戏水平，还成功保留了其独特的游戏风格，验证了算法的有效性。

研究结论: 本文通过一种新颖的示范学习算法，成功提升了麻将机器人的表现并保留了其风格，为开发多样化风格的机器人提供了新思路。

中文摘要: 游戏中的多样化机器人丰富了游戏体验并增强了可玩性。近年来，游戏人工智能的进展主要集中在提升机器人的熟练度上，而开发具有多样化独特风格的高水平机器人仍是一个较少探索的领域。本文以麻将游戏为案例，研究了其高随机性和非分布状态对现有离线学习和示范学习算法的限制。我们利用现有麻将机器人的游戏历史，提出了一种新颖的示范学习算法，仅需对近端策略优化算法进行最小修改。全面的实验结果表明，该方法不仅显著提升了机器人的熟练度，还有效保留了其独特的游戏风格。

</details>


### [230] [A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models](https://arxiv.org/abs/2506.17018)
**中文标题：基于状态空间模型的分位数回归剩余使用寿命估计方法**

*Davide Frizzo,Francesco Borsatti,Gian Antonio Susto*

主要分类: cs.AI

摘要简述: 本文提出了一种基于状态空间模型（SSM）和同步分位数回归（SQR）的剩余使用寿命（RUL）估计方法，通过高效的长序列建模和不确定性处理，显著提升了预测精度和计算效率。


<details>
  <summary>详细信息</summary>
研究动机: 在工业4.0和5.0背景下，预测性维护（PdM）对设备剩余使用寿命（RUL）的准确预测至关重要，可优化维护计划并减少意外故障。传统方法在长期序列建模和不确定性处理上存在不足，因此需要一种更高效且鲁棒的方法。

研究方法: 本文结合状态空间模型（SSM）和同步分位数回归（SQR），通过SSM进行高效的长序列建模，并利用SQR处理模型不确定性，实现多分位数估计。方法在C-MAPSS数据集上与LSTM、Transformer和Informer等传统序列建模技术进行了对比。

研究结果: 实验结果表明，所提出的SSM模型在预测精度和计算效率上均优于传统方法，展现了其在工业高价值应用中的潜力。

研究结论: 本文提出的SSM与SQR结合的方法为剩余使用寿命估计提供了一种高效且鲁棒的解决方案，适用于工业预测性维护的高要求场景。

中文摘要: 预测性维护（PdM）在工业4.0和5.0中至关重要，通过准确预测设备剩余使用寿命（RUL）主动提升效率，从而优化维护计划并减少意外故障和过早干预。本文提出了一种新颖的RUL估计方法，利用状态空间模型（SSM）进行高效的长序列建模。为处理模型不确定性，同步分位数回归（SQR）被集成到SSM中，实现多分位数估计。所提方法在C-MAPSS数据集上与传统序列建模技术（LSTM、Transformer、Informer）进行了对比。结果表明，SSM模型在精度和计算效率上均表现优异，突显了其在高风险工业应用中的潜力。

</details>


### [231] [Dispositions and Roles of Generically Dependent Entities](https://arxiv.org/abs/2506.17085)
**中文标题：通用依赖实体的倾向与角色**

*Fabian Neuhaus*

主要分类: cs.AI

摘要简述: BFO 2020无法支持通用依赖实体（如软件或数据集）的功能、倾向和角色，本文提出两种解决方案：使用定义类或修改BFO以支持这些实体的功能、倾向和角色。


<details>
  <summary>详细信息</summary>
研究动机: BFO 2020未能涵盖通用依赖实体（如软件或数据集）的功能、倾向和角色，这限制了其在计算机模型或数据集执行中的准确表示。本文旨在解决这一局限性。

研究方法: 讨论了BFO 2020中阻碍通用依赖实体可现实性表示的因素，并提出了两种解决方案：(a) 使用定义类；(b) 修改BFO以支持这些实体的功能、倾向和角色。

研究结果: 提出了两种有效方法，能够解决BFO 2020在通用依赖实体功能、倾向和角色表示上的不足。

研究结论: 通过定义类或修改BFO框架，可以成功解决通用依赖实体功能、倾向和角色的表示问题，从而提升BFO的适用性。

中文摘要: BFO 2020不支持通用依赖持续体（如软件或数据集）的功能、倾向和角色。本文认为这是一个严重限制，例如阻碍了计算机模型功能或数据集在执行过程中各种角色的准确表示。我们讨论了BFO 2020中阻碍通用依赖持续体可现实性表示的因素，并提出了两种解决方案：(a) 使用定义类；(b) 提出修改建议，使BFO能够支持通用依赖持续体的功能、倾向和角色。

</details>


### [232] [Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving](https://arxiv.org/abs/2506.17104)
**中文标题：通过一阶逻辑定理证明提升大语言模型的高级数学推理能力**

*Chuxue Cao,Mengze Li,Juntao Dai,Jinluan Yang,Zijian Zhao,Shengyu Zhang,Weijie Shi,Chengzhong Liu,Sirui Han,Yike Guo*

主要分类: cs.AI

摘要简述: 本文提出DREAM方法，通过一阶逻辑定理证明提升大语言模型（LLMs）在复杂数学推理中的表现，解决了多步推理中的策略单一和早期错误问题。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在数学推理基准测试中表现优异，但在多步一阶逻辑推理任务中表现不佳，如Deepseek-Prover-V2-7B在定理证明数据集上的准确率仅为4.2%。这源于推理策略单一和早期错误对整体证明的负面影响。

研究方法: 提出DREAM方法，包含两个核心机制：1）公理驱动的策略多样化，以增加推理策略的多样性；2）子命题错误反馈，帮助LLMs反思和修正证明过程。

研究结果: DREAM显著提升了LLMs在数学推理中的表现，性能提升范围为0.6%至6.4%，并提供了一个包含447个数学定理的Lean 4格式数据集用于评估。

研究结论: DREAM通过增强推理策略的多样性和合理性，为LLMs在复杂数学推理中的应用提供了有效解决方案，为一阶逻辑定理证明领域的研究奠定了基础。

中文摘要: 大语言模型（LLMs）在一阶逻辑（FOL）推理中展现出潜力，但其在涉及多步FOL推理的复杂数学任务中的有效性仍有待研究。尽管LLMs在现有数学推理基准测试中表现优异，但在多步FOL任务中表现不佳，如Deepseek-Prover-V2-7B在我们提出的定理证明数据集上准确率仅为4.2%。这一问题源于推理策略的单一性以及早期错误对整体证明的破坏性影响。为解决这些问题，我们提出DREAM，一种自适应解决方案，通过增强LLMs生成策略的多样性和合理性来改进其表现。DREAM包含公理驱动的策略多样化机制以促进多样化的推理结果，以及子命题错误反馈机制帮助LLMs反思和修正证明。我们的贡献包括：通过FOL定理证明推动LLMs数学推理的进步，提出一种新颖的推理阶段解决方案，性能提升0.6%至6.4%，并提供了一个包含447个数学定理的Lean 4格式评估数据集。

</details>


### [233] [Are Bias Evaluation Methods Biased ?](https://arxiv.org/abs/2506.17111)
**中文标题：偏见评估方法是否存在偏见？**

*Lina Berrayana,Sean Rooney,Luis Garcés-Erice,Ioana Giurgiu*

主要分类: cs.AI

摘要简述: 研究发现，不同但广泛使用的偏见评估方法会导致模型排名不一致，呼吁社区谨慎使用此类基准。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型的安全性评估基准是可信AI社区的关键活动之一，但不同基准采用的数据集和评估方法各异，研究旨在检验这些基准的稳健性。

研究方法: 通过不同方法对一组代表性模型进行偏见排名，并比较整体排名的相似性，以评估基准的稳健性。

研究结果: 结果显示，不同但广泛使用的偏见评估方法会导致模型排名显著不同。

研究结论: 建议社区在使用此类基准时需谨慎，并进一步优化评估方法。

中文摘要: 创建评估大型语言模型安全性的基准是可信AI社区的关键活动之一。这些基准可用于比较模型在毒性、偏见、有害行为等方面的安全性。独立基准采用不同的数据集和评估方法。我们通过不同方法对一组代表性模型进行偏见排名，并比较整体排名的相似性，以检验这些基准的稳健性。结果表明，不同但广泛使用的偏见评估方法会导致模型排名不一致。最后，我们为社区提供了使用此类基准的建议。

</details>


### [234] [Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models](https://arxiv.org/abs/2506.17114)
**中文标题：数学证明作为试金石：揭示先进大型推理模型的失败模式**

*Dadi Guo,Jiayu Liu,Zhiyuan Fan,Zhitao He,Haoran Li,Yumeng Wang,Yi R.,Fung*

主要分类: cs.AI

摘要简述: 大型推理模型在数学证明任务中表现不佳，揭示了其逻辑推理的根本缺陷，需精细化逻辑训练。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大型推理模型在数学问题解决上表现出高准确率，但其依赖数值评估和潜在基准泄漏掩盖了真实的推理缺陷。本文旨在通过数学证明的严谨性揭示这些隐藏问题。

研究方法: 提出RFMDataset（揭示失败模式数据集），包含200个多样化的数学证明问题，并深入评估先进模型的表现，分析其失败案例。

研究结果: 研究发现：1）模型在数学证明任务中表现极差，正确率低于20%；2）模型在单步推理中缺乏正确性和严谨性保证；3）推理过程中存在幻觉和不完整性。

研究结论: 模型的自反思不足以解决当前逻辑困境，需引入形式化和精细化的逻辑训练。

中文摘要: 大型推理模型（如R1、o3）在数学问题解决上表现出卓越能力。然而，这些先进模型在流行数据集上的高准确率、对纯数值评估的依赖以及潜在的基准泄漏，往往掩盖了其真实的推理缺陷。为此，我们提出利用数学证明固有的严谨性和方法复杂性作为诊断工具，揭示这些隐藏的失败。具体而言，我们引入了RFMDataset（揭示失败模式数据集），包含200个多样化的数学证明问题，并全面评估先进模型在其上的表现。通过深入分析其失败案例，我们揭示了10种细粒度错误类型，表明当前大型推理模型存在根本性局限：1）模型在数学证明任务中表现极差，部分模型正确率低于20%，甚至在基础问题上也失败；2）模型展现出多样化的推理失败，显著缺乏单步推理的正确性和严谨性保证；3）模型在推理过程中表现出幻觉和不完整性。我们的发现表明，模型的自反思不足以解决当前的逻辑困境，需要形式化和精细化的逻辑训练。

</details>


### [235] [When Can Model-Free Reinforcement Learning be Enough for Thinking?](https://arxiv.org/abs/2506.17124)
**中文标题：无模型强化学习何时足以产生思考？**

*Josiah P. Hanna,Nicholas E. Corrado*

主要分类: cs.AI

摘要简述: 本文探讨了无模型强化学习（RL）何时能产生类似“思考”的行为，提出了一种称为“思考马尔可夫决策过程”的理论模型，并证明了策略初始化对“思考”行为出现的重要性。通过实验验证了开源大语言模型满足理论预测的条件，并假设了在多任务预训练和指定思考动作下，RL能更高效学习“思考”行为。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，大语言模型通过无模型强化学习展现出类似推理的能力。然而，“思考”行为既不直接产生奖励，也不改变外部世界状态以增加奖励。本文旨在建立一个领域无关的理论框架，解释无模型强化学习何时会催生“思考”作为奖励最大化的策略。

研究方法: 本文首先提出了一种“思考马尔可夫决策过程”（Thought MDP）的理论模型，扩展了经典MDP以包含抽象的思考状态和思考动作。通过该模型，证明了策略初始化对“思考”行为出现的关键作用，并形式化地表明思考动作等同于代理在执行策略改进步骤后再继续行动。随后，验证了开源大语言模型满足理论预测的条件。最后，假设了在多任务预训练和指定思考动作下，RL能更高效学习“思考”行为的充分条件。

研究结果: 理论分析表明，策略初始化是“思考”行为出现的关键因素，且思考动作等同于策略改进步骤。实验验证了开源大语言模型满足理论预测的条件。此外，假设的多任务预训练和指定思考动作的组合在玩具领域中实现了比非思考代理更高效的数据利用。

研究结论: 本文通过理论模型和实验验证，揭示了无模型强化学习催生“思考”行为的条件，并提出了在多任务预训练和指定思考动作下实现高效学习的可能性。这为未来研究提供了理论基础和实验方向。

中文摘要: 近期关于大语言模型的研究展示了无模型强化学习（RL）在训练类似推理能力中的应用。通过无模型RL催生“思考”行为是引人注目的，因为思考动作既不产生奖励，也不改变外部世界状态以增加代理获得奖励的可能性。本文旨在建立一个领域无关的理论框架，解释无模型RL何时会将“思考”作为奖励最大化的策略。为此，我们首先提出了一种称为“思考马尔可夫决策过程”（Thought MDP）的理论模型，该模型在经典MDP的基础上引入了抽象的思考状态和思考动作。利用这一模型，我们证明了策略初始化对“思考”行为出现的重要性，并形式化地表明思考动作等同于代理在执行策略改进步骤后再继续行动。随后，我们展示了开源大语言模型满足理论预测的条件。最后，我们假设了在多任务预训练和指定思考动作下，RL能在语言生成之外学习“思考”行为的充分条件，并引入了一个玩具领域，其中多任务预训练和指定思考动作的组合比非思考代理实现了更高效的数据利用。

</details>


### [236] [Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI](https://arxiv.org/abs/2506.17130)
**中文标题：信任链：一种由生成式AI驱动的渐进式信任评估框架**

*Botao Zhu,Xianbin Wang,Lei Zhang,Xuemin,Shen*

主要分类: cs.AI

摘要简述: 本文提出了一种名为“信任链”的渐进式信任评估框架，利用生成式AI分析设备属性数据，分阶段评估协作设备的信任度，降低评估复杂度并提高准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在依赖分布式资源的复杂协作系统中，信任评估对任务完成至关重要。然而，由于网络动态性和信息收集延迟，同时获取所有设备属性进行全面评估极具挑战性。

研究方法: 提出“信任链”框架，将信任评估分解为多个阶段，每个阶段仅收集与任务相关的设备属性数据，利用生成式AI的上下文学习、少样本学习和推理能力快速分析数据，仅允许信任设备进入下一阶段。

研究结果: 实验结果表明，该框架在信任评估中实现了高准确性。

研究结论: “信任链”框架通过分阶段评估和生成式AI的辅助，有效降低了信任评估的复杂性，同时确保了高准确性。

中文摘要: 在依赖分布式资源的复杂协作系统中，信任评估已成为任务完成的有效机制。然而，由于网络动态性和信息收集延迟，同时观察和收集协作设备的所有信任属性进行全面评估极具挑战性。本文提出了一种名为“信任链”的渐进式信任评估框架，旨在更好地利用未对齐的设备属性数据。该框架为有效完成任务设计，将信任评估过程基于任务分解为多个链式阶段。每个阶段仅收集与该阶段相关的最新设备属性数据，从而降低信任评估的复杂性和开销。通过利用先进的上下文学习、少样本学习和推理能力，生成式AI被用于分析和解释收集的数据，快速生成正确的评估结果。仅在此阶段被判定为可信的设备才能进入下一轮信任评估。最终，框架确定在所有阶段均保持可信的设备。实验结果表明，所提出的框架在信任评估中实现了高准确性。

</details>


### [237] [The MedPerturb Dataset: What Non-Content Perturbations Reveal About Human and Clinical LLM Decision Making](https://arxiv.org/abs/2506.17163)
**中文标题：MedPerturb数据集：非内容扰动揭示人类与临床LLM决策的差异**

*Abinitha Gourabathina,Yuexing Hao,Walter Gerych,Marzyeh Ghassemi*

主要分类: cs.AI

摘要简述: 本文介绍了MedPerturb数据集，用于系统评估医学大语言模型（LLM）在临床输入受控扰动下的表现，揭示了LLM与人类在性别、语言风格和格式变化上的决策差异。


<details>
  <summary>详细信息</summary>
研究动机: 临床稳健性对医学LLM的安全部署至关重要，但LLM与人类在临床环境中的决策差异尚不明确。本文旨在通过MedPerturb数据集填补这一空白。

研究方法: 研究构建了MedPerturb数据集，包含800个临床案例，通过性别修改、风格变化和格式调整三种扰动方式生成多样化输入，并收集了四种LLM和人类专家的输出。

研究结果: 研究发现，LLM对性别和风格扰动更敏感，而人类专家对LLM生成的格式变化（如临床摘要）更敏感。

研究结论: 研究强调需要超越静态基准的评估框架，以衡量临床环境中人类与LLM决策的相似性。

中文摘要: 临床稳健性对医学大语言模型（LLM）的安全部署至关重要，但LLM与人类在临床环境中的决策差异尚不明确。为此，我们提出了MedPerturb数据集，用于系统评估医学LLM在受控扰动下的表现。MedPerturb包含涵盖多种病理的临床案例，每个案例通过三种方式扰动：（1）性别修改（如性别互换或性别移除）；（2）风格变化（如不确定表达或口语化语气）；（3）格式调整（如LLM生成的多轮对话或摘要）。我们发布了800个基于真实输入变化的临床案例，四种LLM的输出，以及每个案例的三位人类专家解读。通过MedPerturb，我们进行了两项案例研究，揭示了性别标识、语言风格或格式变化如何导致人类与LLM的治疗选择差异。研究发现，LLM对性别和风格扰动更敏感，而人类专家对LLM生成的格式变化（如临床摘要）更敏感。结果强调了需要超越静态基准的评估框架，以衡量临床环境中人类与LLM决策的相似性。

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [238] [Quantum Artificial Intelligence for Secure Autonomous Vehicle Navigation: An Architectural Proposal](https://arxiv.org/abs/2506.16000)
**中文标题：量子人工智能在安全自动驾驶导航中的应用：一种架构提案**

*Hemanth Kannamarlapudi,Sowmya Chintalapudi*

主要分类: cs.ET

摘要简述: 本文提出了一种基于量子人工智能的新型架构，用于自动驾驶车辆的导航决策和通信安全，包括量子神经网络传感器融合、量子强化学习导航策略优化和后量子密码协议。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶车辆的导航依赖大量数据处理和决策，传统方法在动态复杂环境中存在性能和安全挑战。量子人工智能有望提供更高性能和未来安全保障。

研究方法: 提出三部分架构：1) 量子神经网络通过量子振幅编码融合多模态传感器数据；2) Nav-Q模块利用变分量子电路优化导航策略；3) 后量子密码协议保障通信安全。

研究结果: 该框架为自动驾驶车辆提供了统一的量子状态表示、动态环境下的优化导航策略，以及抵御经典和量子威胁的安全通信。

研究结论: 所提架构通过量子人工智能解决了自动驾驶导航中的性能和安全挑战，为未来自动驾驶系统提供了可靠解决方案。

中文摘要: 导航是自动驾驶生态系统中至关重要的环节，其依赖于在多种状态下收集和处理大量数据，并做出自信且安全的决策以定义车辆的下一步动作。本文提出了一种基于量子人工智能的新型架构，通过在自动驾驶车辆的导航决策和通信过程中引入量子技术和人工智能：量子神经网络用于多模态传感器融合，Nav-Q用于导航策略优化的量子强化学习，以及后量子密码协议用于安全通信。量子神经网络利用量子振幅编码融合来自LiDAR、雷达、摄像头、GPS和天气等多种传感器的数据，为异构传感器模态提供统一的量子状态表示。Nav-Q模块通过变分量子电路处理融合的量子状态，学习在快速动态和复杂条件下的最优导航策略。最后，后量子密码协议用于保护车内通信和V2X（车辆到一切）通信的安全，从而抵御经典和量子安全威胁。该框架通过提供量子性能和未来安全保障，解决了自动驾驶车辆导航中的基本挑战。关键词：量子计算，自动驾驶车辆，传感器融合

</details>


### [239] [Artificial Intelligence for Atmospheric Sciences: A Research Roadmap](https://arxiv.org/abs/2506.16281)
**中文标题：人工智能在大气科学中的应用：研究路线图**

*Martha Arbayani Zaidan,Naser Hossein Motlagh,Petteri Nurmi,Tareq Hussein,Markku Kulmala,Tuukka Petäjä,Sasu Tarkoma*

主要分类: cs.ET

摘要简述: 本文探讨人工智能（AI）在大气科学中的关键作用，提出整合AI技术的挑战与解决方案，并制定研究路线图以推动该领域发展。


<details>
  <summary>详细信息</summary>
研究动机: 大气科学对理解空气质量、极端天气和气候变化至关重要。近年来，传感、通信、计算和AI技术的突破为大气科学提供了海量数据和强大分析工具，但如何有效整合AI技术仍面临挑战。本文旨在弥合大气科学与计算机科学的跨学科鸿沟，推动AI在大气研究中的应用。

研究方法: 本文通过跨学科综述，分析AI在大气科学中的潜力，识别整合AI的关键挑战（如大数据和基础设施问题），并提出详细的研究路线图。

研究结果: 研究强调了AI在大气科学中的变革潜力，明确了当前和未来面临的挑战，并提供了解决这些挑战的具体研究方向。

研究结论: AI技术有望显著推动大气科学的发展，但需解决数据与基础设施等关键问题。本文的研究路线图为未来研究提供了重要指导。

中文摘要: 大气科学对理解从空气质量到极端天气事件及气候变化等环境现象至关重要。近年来，传感、通信、计算和人工智能（AI）领域的突破显著推动了大气科学的进步，通过长期地球观测生成了大量数据，并为分析大气现象和预测自然灾害提供了强大工具。本文提供了一份关键的跨学科综述，连接大气科学与计算机科学领域，突出了AI在大气研究中的变革潜力。我们识别了将AI整合到大气研究中的关键挑战，包括与大数据和基础设施相关的问题，并提供了详细的研究路线图，以应对当前和新兴的挑战。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [240] [CP$^2$: Leveraging Geometry for Conformal Prediction via Canonicalization](https://arxiv.org/abs/2506.16189)
**中文标题：CP²：通过规范化利用几何信息实现共形预测**

*Putri A. van der Linden,Alexander Timans,Erik J. Bekkers*

主要分类: stat.ML

摘要简述: 本文提出了一种结合几何信息（如姿态）的共形预测方法CP²，以应对几何数据变换（如旋转或翻转）带来的分布偏移问题，从而恢复共形预测的保证并提升模型鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 共形预测（CP）虽能为模型提供后验不确定性量化和形式化覆盖保证，但在数据分布偏移（如几何变换）时性能下降。本文旨在通过整合几何信息（如姿态）来解决这一问题。

研究方法: 提出CP²方法，利用姿态规范化技术提取几何信息，并将其整合到共形预测中，以应对离散和连续的几何变换。同时对比了等变性和基于增强的基线方法。

研究结果: 实验表明，CP²方法在几何变换下能够恢复共形预测的保证，并保持对黑盒预测器的广泛适用性，表现优于基线方法。

研究结论: 整合几何信息与共形预测是一种解决几何分布偏移的有效方法，同时保持了模型的通用性和鲁棒性。

中文摘要: 本文研究了在几何数据变换（如旋转或翻转）下的共形预测（CP）问题。尽管CP能为预测模型提供后验不确定性量化和形式化覆盖保证，但在分布偏移（尤其是几何变换）时，其实用性会受到影响。为解决这一问题，我们提出将几何信息（如姿态）整合到共形预测中，以恢复其保证并提升几何变换下的鲁棒性。具体而言，我们探索了姿态规范化技术作为几何信息提取器的适用性。通过评估该方法在离散和连续变换下的表现，并与等变性和基于增强的基线方法对比，发现整合几何信息与CP能够有效应对几何变换，同时保持对黑盒预测器的广泛适用性。

</details>


### [241] [Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation](https://arxiv.org/abs/2506.16636)
**中文标题：潜在噪声注入：用于隐私保护与统计对齐的合成数据生成**

*Rex Shen,Lu Tian*

主要分类: stat.ML

摘要简述: 本文提出了一种基于掩码自回归流（MAF）的潜在噪声注入方法，用于生成隐私保护且统计对齐的合成数据。该方法通过在潜在空间扰动数据点并映射回数据域，解决了高维数据生成中的收敛问题，同时满足局部差分隐私要求。


<details>
  <summary>详细信息</summary>
研究动机: 传统生成模型（如归一化流）在高维数据生成中收敛速度慢，且难以平衡隐私与效用。本文旨在提出一种新方法，既能高效生成统计对齐的合成数据，又能满足隐私保护需求。

研究方法: 采用掩码自回归流（MAF）模型，通过在潜在空间注入噪声扰动数据点，再将其映射回数据域。这种方法保留了观测数据与合成数据的一一对应关系，并通过单一扰动参数控制隐私与效用的权衡。

研究结果: 实验表明，潜在噪声注入方法在高维数据生成中表现优异，能够实现与原始数据的强统计对齐，并有效抵御成员推理攻击。通过聚合多个合成数据集，恢复了经典效率并提供了可靠的推断。

研究结论: 潜在噪声注入方法为隐私敏感的分布式领域（如生物医学研究）提供了一种高效的合成数据生成替代方案，兼具隐私保护与统计效用。

中文摘要: 合成数据生成已成为可扩展、隐私保护的统计分析的关键。尽管基于生成模型（如归一化流）的标准方法被广泛使用，但在高维场景下收敛速度较慢，通常比近似真实数据分布的经典$1/\sqrt{n}$速率更慢。为克服这些限制，我们提出了一种基于掩码自回归流（MAF）的潜在噪声注入方法。该方法不在训练模型中直接采样，而是在潜在空间扰动每个数据点并将其映射回数据域。这种构造保留了观测数据与合成数据的一一对应关系，使合成输出能够紧密反映底层分布，尤其在传统采样方法难以应对的高维场景中。\n 我们的方法满足局部$(\epsilon, \delta)$-差分隐私，并通过单一扰动参数控制隐私与效用的权衡。尽管基于单个合成数据集的估计器可能收敛较慢，但我们从理论和实验上证明，在元分析框架中聚合$K$项研究可恢复经典效率并提供一致可靠的推断。实验表明，通过校准扰动参数，潜在噪声注入能够实现与原始数据的强统计对齐，并有效抵御成员推理攻击。这些结果使我们的方法成为隐私敏感领域（如生物医学研究）中传统流采样方法的理想替代方案。

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [242] [RecBayes: Recurrent Bayesian Ad Hoc Teamwork in Large Partially Observable Domains](https://arxiv.org/abs/2506.15756)
**中文标题：RecBayes：大规模部分可观测领域中的递归贝叶斯即时团队协作**

*João G. Ribeiro,Yaniv Oren,Alberto Sardinha,Matthijs Spaan,Francisco S. Melo*

主要分类: cs.MA

摘要简述: 本文提出RecBayes，一种在部分可观测环境中无需环境状态或队友动作信息即可实现即时团队协作的新方法。通过递归贝叶斯分类器，RecBayes能有效识别已知团队和任务，适用于大规模环境。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法如PO-GPL和FEAT需要完全可观测状态或队友动作信息，而ATPO仅适用于小规模环境。RecBayes旨在解决这些限制，实现无需状态或动作信息的大规模部分可观测环境下的即时协作。

研究方法: RecBayes基于递归贝叶斯分类器，利用历史经验训练模型，仅通过观测数据识别团队和任务。无需环境状态或队友动作信息，适用于任意大规模空间。

研究结果: 在扩展到100万状态和2^125观测的大规模环境中，RecBayes仅通过部分观测即可有效识别团队和任务，并成功协助团队完成任务。

研究结论: RecBayes是一种无需状态或动作信息即可在大规模部分可观测环境中实现即时协作的有效方法，优于现有技术。

中文摘要: 本文提出RecBayes，一种在部分可观测环境中实现即时团队协作的新方法，该方法在任何阶段均无需访问环境状态或队友动作。通过依赖基于历史经验训练的递归贝叶斯分类器，即时代理能够仅通过观测数据有效识别已知团队和执行的任务。与PO-GPL（Gu等人，2021）和FEAT（Rahman等人，2023）等需要完全可观测状态或队友动作的方法不同，或与ATPO（Ribeiro等人，2023）等仅适用于小规模环境的方法不同，RecBayes能够处理任意大规模空间且不依赖状态或队友动作。我们在多智能体系统文献中的基准领域进行了实验，结果表明，在扩展到100万状态和2^125观测的环境中，RecBayes仅通过部分观测即可有效识别团队和任务，并成功协助团队完成任务。

</details>


### [243] [Generalizable Agent Modeling for Agent Collaboration-Competition Adaptation with Multi-Retrieval and Dynamic Generation](https://arxiv.org/abs/2506.16718)
**中文标题：通用智能体建模：基于多检索与动态生成的协作-竞争适应方法**

*Chenxu Wang,Yonggang Jin,Cheng Hu,Youpeng Zhao,Zipeng Dai,Jian Zhao,Shiyu Huang,Liuyu Xiang,Junge Zhang,Zhaofeng He*

主要分类: cs.MA

摘要简述: 本文提出了一种名为ACCA的通用多智能体协作-竞争适应框架，并设计了MRDG方法，通过多检索和动态生成技术建模未知队友和对手行为，显著提升了智能体在未知环境中的协作与竞争能力。


<details>
  <summary>详细信息</summary>
研究动机: 在多智能体系统中，单个智能体需要适应新的任务、环境和未知的队友与对手，这一过程极具挑战性。现有的简化场景（如零样本学习和临时团队协作）未能全面覆盖实际需求，因此需要更通用的适应框架。

研究方法: 提出了MRDG方法，利用行为轨迹建模队友和对手，包括位置编码器适应不同团队规模、超网络模块增强学习能力，以及视角对齐模块统一观测视角。

研究结果: 在SMAC、Overcooked-AI和Melting Pot等基准测试中，MRDG显著优于现有基线方法，表现出更强的协作与竞争适应性。

研究结论: MRDG方法为多智能体协作-竞争适应提供了有效解决方案，能够显著提升智能体在未知环境中的表现。

中文摘要: 在多智能体系统中，单个智能体适应新环境面临诸多挑战，需调整任务、环境以及与未知队友和对手的交互。现有研究提出了两种简化场景（多智能体强化学习的零样本学习和临时团队协作），在此基础上，我们提出了更全面的智能体协作-竞争适应（ACCA）框架，评估智能体在多样化场景、任务及与未知队友和对手交互中的泛化能力。ACCA要求智能体适应任务与环境变化，与未见过的队友协作，并与未知对手竞争。我们提出了一种新的建模方法——多检索与动态生成（MRDG），通过行为轨迹有效建模队友和对手。该方法包含适应不同团队规模的位置编码器、增强学习能力的超网络模块，以及视角对齐模块以统一观测视角。在SMAC、Overcooked-AI和Melting Pot等基准测试中，MRDG显著提升了与未知队友和对手的协作与竞争能力，超越了现有基线方法。代码已开源：https://github.com/vcis-wangchenxu/MRDG.git

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [244] [Graphics4Science: Computer Graphics for Scientific Impacts](https://arxiv.org/abs/2506.15786)
**中文标题：Graphics4Science：计算机图形学对科学的影响**

*Peter Yichen Chen,Minghao Guo,Hanspeter Pfister,Ming Lin,William Freeman,Qixing Huang,Han-Wei Shen,Wojciech Matusik*

主要分类: cs.GR

摘要简述: 本文探讨了计算机图形学与科学之间的深刻关系，展示了图形学如何作为科学建模语言，并鼓励图形学社区参与解决高影响力科学问题。


<details>
  <summary>详细信息</summary>
研究动机: 计算机图形学长期以来在解决科学挑战中发挥了重要作用，但其潜力尚未被充分挖掘。本文旨在弥合图形学与科学社区之间的词汇差距，推动图形学在科学发现中的进一步应用。

研究方法: 通过回顾计算机图形学在科学领域的成就和贡献，结合几何推理和物理建模等核心方法，本文提出将图形学重新定义为科学的建模语言。

研究结果: 文章展示了图形学在数据稀缺环境下如何为科学问题提供解决方案，并提出了未来研究方向。

研究结论: 本文呼吁图形学社区积极参与科学问题，利用图形学专长为科学发现做出贡献，并展望了图形学在科学中的未来潜力。

中文摘要: 计算机图形学通常与电影、游戏和视觉效果相关联，但它长期以来一直是解决科学挑战的强大工具——从其在医学影像中的3D可视化起源，到其在现代计算建模和模拟中的作用。本课程探讨了计算机图形学与科学之间深刻且不断发展的关系，突出了过去的成就、当前的贡献以及尚未解决的开放性问题。我们展示了核心方法（如几何推理和物理建模）如何提供归纳偏差，帮助解决两个领域的挑战，尤其是在数据稀缺的环境中。为此，我们旨在通过弥合两个社区之间的词汇差距，将图形学重新定义为科学的建模语言。Graphics4Science旨在吸引图形学社区参与科学，解决图形学专长可以发挥作用的高影响力问题，并为科学发现的未来做出贡献。更多详情请访问课程网站：https://graphics4science.github.io

</details>


### [245] [VEIGAR: View-consistent Explicit Inpainting and Geometry Alignment for 3D object Removal](https://arxiv.org/abs/2506.15821)
**中文标题：VEIGAR：基于视图一致性的显式修复与几何对齐的三维物体移除方法**

*Pham Khai Nguyen Do,Bao Nguyen Tran,Nam Nguyen,Duc Dung Nguyen*

主要分类: cs.GR

摘要简述: VEIGAR是一种高效的三维物体移除框架，无需初始重建阶段，通过轻量级基础模型和尺度不变深度损失监督，显著提升重建质量和跨视图一致性，同时减少训练时间。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖初始三维重建阶段，计算开销大且重建质量不佳。VEIGAR旨在通过轻量级模型和新型监督策略，高效解决跨视图一致性问题。

研究方法: VEIGAR利用轻量级基础模型在像素空间显式对齐先验，并引入基于尺度不变深度损失的监督策略，避免传统单目深度正则化中的尺度调整操作。

研究结果: VEIGAR在重建质量和跨视图一致性上达到新标杆，训练时间比现有最快方法减少三倍，效率与效果俱佳。

研究结论: VEIGAR通过高效框架和新型监督策略，显著提升三维物体移除任务的效果和效率，为相关领域提供了新思路。

中文摘要: 近年来，新视角合成（NVS）和三维生成技术的进步显著改善了编辑任务，重点在于生成过程中保持跨视图一致性。现有方法通常采用双策略框架：通过嵌入先验在像素空间或隐式在潜在空间中进行跨视图一致的二维修复；并在额外一致性指导下进行三维重建。传统策略尤其依赖初始三维重建阶段以建立几何结构，带来巨大计算开销，且重建质量往往不佳。本文提出VEIGAR，一种无需初始重建阶段的高效框架，性能优于现有方法。VEIGAR利用轻量级基础模型在像素空间显式对齐先验，并引入基于尺度不变深度损失的监督策略，避免传统单目深度正则化中的尺度调整操作。通过大量实验，VEIGAR在重建质量和跨视图一致性上树立了新标杆，同时训练时间比现有最快方法减少三倍，展现了其效率与效果的卓越平衡。

</details>


### [246] [GratNet: A Photorealistic Neural Shader for Diffractive Surfaces](https://arxiv.org/abs/2506.15815)
**中文标题：GratNet：一种用于衍射表面的逼真神经着色器**

*Narayan Kandel,Daljit Singh J. S. Dhillon*

主要分类: cs.GR

摘要简述: 本文提出了一种基于多层感知机（MLP）的数据驱动方法GratNet，用于高效且高精度地渲染衍射表面。该方法通过数据压缩和优化训练策略，显著减少了内存占用，并避免了过拟合问题。


<details>
  <summary>详细信息</summary>
研究动机: 当前结构着色模型依赖大量预处理数据，计算成本高且效率低。本文旨在通过神经表示方法解决这一问题，实现高效且高质量的衍射表面渲染。

研究方法: 采用多层感知机（MLP）进行数据驱动的渲染，结合数据压缩和优化的训练策略，专注于衍射反射数据集的特性，避免过拟合并提升重采样鲁棒性。

研究结果: 实验表明，GratNet在PSNR、SSIM和FLIP等指标上表现优异，能够高质量重建真实数据，同时将原始数据集的内存占用降低两个数量级。

研究结论: GratNet在衍射表面渲染中实现了高效与高精度的平衡，为数据驱动的神经渲染提供了新的解决方案。

中文摘要: 结构着色通常使用波动光学模型来实现对自然、准周期和复杂纳米结构的可靠且逼真的渲染。这类模型通常依赖密集的预处理数据以准确捕捉衍射表面反射的细微变化。这种高数据依赖性促使我们探索隐式神经表示方法，而当前文献中对此尚未全面研究。本文提出了一种基于多层感知机（MLP）的数据驱动方法，用于高效且高精度地渲染衍射表面。我们主要从数据压缩的角度出发，设计了一种针对衍射反射数据集特性的训练和建模方法。重要的是，我们的方法避免了过拟合并具有鲁棒的重采样行为。通过峰值信噪比（PSNR）、结构相似性指数（SSIM）和翻转差异评估器（FLIP）作为评估指标，我们展示了高质量的真实数据重建效果。与最新的离线波动光学正向建模方法相比，我们的方法在主观上实现了相似的结果，同时显著提升了性能。通常，我们将原始数据集的内存占用降低了两数量级。最后，我们通过实际表面渲染展示了方法的有效性。

</details>


### [247] [FlatCAD: Fast Curvature Regularization of Neural SDFs for CAD Models](https://arxiv.org/abs/2506.16627)
**中文标题：FlatCAD：神经SDF的快速曲率正则化用于CAD模型**

*Haotian Yin,Aleksander Plocharski,Michal Jan Wlodarczyk,Mikolaj Kida,Przemyslaw Musialski*

主要分类: cs.GR

摘要简述: 本文提出了一种快速曲率正则化方法FlatCAD，通过仅正则化混合二阶项（Weingarten项）来优化神经SDF的CAD模型行为，避免了昂贵的全Hessian计算，显著降低了内存和运行时间。


<details>
  <summary>详细信息</summary>
研究动机: 神经符号距离场（SDF）在几何学习中广泛应用，但现有方法通过高斯曲率惩罚实现CAD风格行为时，需要计算全Hessian矩阵和二阶自动微分，导致内存和运行成本高昂。本文旨在解决这一问题。

研究方法: 提出了两种曲率代理方法：(i) 有限差分代理，用四个前向SDF评估和一个一阶梯度替代Hessian条目；(ii) 自动微分代理，通过一个Hessian-向量积计算混合导数，避免显式构建全Hessian矩阵。两种方法均收敛于精确的混合二阶导数。

研究结果: 在ABC基准测试中，代理方法与基于Hessian的基线方法重建精度相当或更高，同时将GPU内存使用和运行时间减少了一半。

研究结论: FlatCAD提供了一种高效且可扩展的曲率感知SDF学习方法，为工程级形状重建开辟了实用路径。

中文摘要: 神经符号距离场（SDF）已成为几何学习的多功能基础，但实现可展开的CAD风格行为仍依赖于高斯曲率惩罚，这需要计算全Hessian矩阵和二阶自动微分，两者在内存和运行时间上成本高昂。我们提出了一种曲率代理方法，仅正则化混合二阶项（Weingarten项），使两个主曲率能自由适应数据，同时抑制不必要的扭曲。两种互补的实现方式体现了这一思想：(i) 有限差分代理，用四个前向SDF评估和一个一阶梯度替代Hessian条目；(ii) 自动微分代理，通过一个Hessian-向量积计算相同的混合导数，避免显式构建全Hessian矩阵，实际运行速度更快。两种变体均收敛于精确的混合二阶导数，从而在不引入完整二阶计算图的情况下保留了预期的几何偏差。在ABC基准测试中，代理方法与基于Hessian的基线方法重建精度相当或更高，同时将GPU内存使用和运行时间减少了一半。由于该方法可直接替换且与框架无关，为可扩展的曲率感知SDF学习提供了实用路径，适用于工程级形状重建。

</details>


### [248] [Beyond Blur: A Fluid Perspective on Generative Diffusion Models](https://arxiv.org/abs/2506.16827)
**中文标题：超越模糊：生成扩散模型的流体动力学视角**

*Grzegorz Gruszczynski,Michal Jan Wlodarczyk,Jakub J Meixner,Przemyslaw Musialski*

主要分类: cs.GR

摘要简述: 本文提出了一种基于流体动力学的PDE驱动图像生成方法，通过结合定向平流和扩散过程，改进了现有PDE方法，提升了生成图像的多样性和质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于PDE的图像生成方法存在局限性，本文旨在通过流体动力学中的平流-扩散过程，提出一种更通用的图像生成框架，以提升生成效果。

研究方法: 提出了一种基于平流-扩散过程的PDE驱动图像生成方法，通过数值求解GPU加速的Lattice Boltzmann方程实现快速计算，并引入随机速度场模拟湍流。

研究结果: 实验表明，该方法能够生成更高质量和多样性的图像，同时保持色彩一致性，且框架可泛化现有PDE方法。

研究结论: 本文通过结合流体动力学与深度学习，为基于扩散的图像生成提供了新的物理视角，展示了平流过程的优势。

中文摘要: 我们提出了一种基于平流-扩散过程的PDE驱动图像生成方法，该方法通过物理启发的PDE耦合定向平流与各向同性扩散及高斯噪声，并由无量纲数（Peclet、Fourier）控制。我们通过GPU加速的Lattice Boltzmann数值求解器实现快速计算。为模拟真实湍流，我们生成随机速度场以引入多尺度混合。在生成过程中，神经网络学习逆转平流-扩散算子，从而构建了一种新型生成模型。我们讨论了现有方法如何作为本算子的特例，表明本框架可泛化现有PDE技术。实验显示，平流过程提升了生成图像的多样性和质量，同时不影响整体色彩。本研究连接了流体动力学、无量纲PDE理论与深度生成模型，为基于扩散的图像生成提供了新的物理视角。

</details>


### [249] [DreamCube: 3D Panorama Generation via Multi-plane Synchronization](https://arxiv.org/abs/2506.17206)
**中文标题：DreamCube：基于多平面同步的3D全景生成**

*Yukun Huang,Yanning Zhou,Jianan Wang,Kaiyi Huang,Xihui Liu*

主要分类: cs.GR

摘要简述: DreamCube通过多平面同步技术将2D基础模型的能力扩展到全景域，提出了一种多平面RGB-D扩散模型，用于生成高质量且多样化的3D全景内容。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法依赖2D基础模型生成3D全景内容，但2D单视图与3D全景的不兼容性限制了效果。DreamCube旨在通过多平面同步技术解决这一问题，充分利用2D模型的先验知识。

研究方法: DreamCube采用多平面同步技术，将2D基础模型的算子扩展到全景域，并设计了一个多平面RGB-D扩散模型，以生成多样化的外观和精确的几何结构，同时保持多视角一致性。

研究结果: 实验表明，DreamCube在全景图像生成、全景深度估计和3D场景生成任务中表现优异，验证了其有效性。

研究结论: DreamCube通过多平面同步技术成功扩展了2D基础模型的能力，为3D全景生成提供了一种高效且多样化的解决方案。

中文摘要: 3D全景合成是一项具有挑战性的任务，需要生成高质量且多样化的全向内容。现有方法利用预训练的2D基础模型的丰富图像先验来缓解3D全景数据的稀缺性，但2D单视图与3D全景的不兼容性限制了其效果。本文通过将多平面同步技术应用于2D基础模型的算子，将其能力无缝扩展到全向域。基于这一设计，我们进一步提出了DreamCube，一种用于3D全景生成的多平面RGB-D扩散模型，它最大限度地重用了2D基础模型的先验，以实现多样化的外观和精确的几何结构，同时保持多视角一致性。大量实验证明了我们的方法在全景图像生成、全景深度估计和3D场景生成中的有效性。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [250] [Ignition Phase : Standard Training for Fast Adversarial Robustness](https://arxiv.org/abs/2506.15685)
**中文标题：点火阶段：快速对抗鲁棒性的标准训练**

*Wang Yu-Hang,Liu ying,Fang liang,Wang Xuelin,Junkang Guo,Shiwei Li,Lei Gao,Jian Liu,Wenfei Yin*

主要分类: cs.LG

摘要简述: 本文提出了一种名为对抗进化训练（AET）的新框架，通过在传统对抗训练前加入经验风险最小化（ERM）阶段，显著提升了对抗鲁棒性的效率和效果，同时降低了训练成本。


<details>
  <summary>详细信息</summary>
研究动机: 现有的对抗训练方法大多专注于生成更强的攻击，而忽略了基础特征表示的重要性。本文旨在通过引入初始ERM阶段，优化特征流形，从而更高效地获得对抗鲁棒性。

研究方法: 作者提出了对抗进化训练（AET）框架，在传统对抗训练前加入一个经验风险最小化（ERM）阶段。这一初始阶段有助于构建更优的特征流形，为后续对抗训练提供更好的起点。

研究结果: 实验表明，AET在多个数据集和架构上均表现出色，不仅实现了与现有方法相当或更优的鲁棒性，还提升了干净数据的准确性，并将训练成本降低了8-25%。

研究结论: 本文强调了通过标准训练进行特征预条件化的重要性，为开发更高效、更原则性的鲁棒防御方法提供了新思路。

中文摘要: 对抗训练（AT）是一种核心防御方法，但许多变体因主要关注生成更强的攻击而忽略了基础特征表示。我们提出了对抗进化训练（AET），这是一个简单而强大的框架，通过在传统对抗训练前策略性地加入一个经验风险最小化（ERM）阶段。我们假设这一初始ERM阶段能够培养一个有利的特征流形，从而实现更高效和有效的鲁棒性获取。实验表明，AET能够更快地实现相当或更优的鲁棒性，提升干净数据的准确性，并将训练成本降低8-25%。其有效性在多个数据集、架构以及增强现有AT方法时均得到验证。我们的发现强调了通过标准训练进行特征预条件化对开发更高效、更原则性的鲁棒防御方法的重要性。代码可在补充材料中找到。

</details>


### [251] [Learning from M-Tuple Dominant Positive and Unlabeled Data](https://arxiv.org/abs/2506.15686)
**中文标题：从M元组主导的正例和未标记数据中学习**

*Jiahe Qin,Junpeng Li,Changchun Hua,Yana Yang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为MDPU的广义学习框架，用于处理正例和未标记数据中的M元组主导问题。通过数学建模和风险校正方法，解决了传统比例标签学习中的比例信息不精确问题，并在实验中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 在实际应用中，获取实例比例的精确监督信息具有挑战性。为了更好地适应现实场景并利用元组内实例的比例约束，本文提出了MDPU框架。

研究方法: 首先对任意大小元组中的实例分布进行数学建模，确保正例数量不少于负例。基于经验风险最小化方法，推导出满足风险一致性的无偏风险估计器，并引入风险校正方法以缓解过拟合问题。

研究结果: 理论分析证明了无偏风险估计器的泛化误差边界一致性，多数据集实验验证了MDPU框架的有效性。

研究结论: MDPU框架通过数学建模和风险校正，有效解决了比例标签学习中的比例信息不精确问题，为实际应用提供了可靠解决方案。

中文摘要: 比例标签学习（LLP）解决了多个实例被分组到包中且每个包包含各类别比例信息的分类问题。然而，在实际应用中，获取特定类别实例比例的精确监督信息具有挑战性。为了更好地适应现实应用场景并有效利用元组内实例的比例约束，本文提出了一种广义学习框架MDPU。具体而言，我们首先在正例数量不少于负例的约束下，对任意大小元组中的实例分布进行数学建模。然后基于经验风险最小化（ERM）方法，推导出满足风险一致性的无偏风险估计器。为缓解训练中不可避免的过拟合问题，引入了一种风险校正方法，从而开发出校正后的风险估计器。无偏风险估计器的泛化误差边界从理论上证明了所提方法的一致性。在多个数据集上的广泛实验及与其他相关基线方法的比较，全面验证了所提学习框架的有效性。

</details>


### [252] [Cellular Traffic Prediction via Deep State Space Models with Attention Mechanism](https://arxiv.org/abs/2506.15688)
**中文标题：基于深度状态空间模型和注意力机制的蜂窝流量预测**

*Hui Ma,Kai Yang,Man-On Pun*

主要分类: cs.LG

摘要简述: 本文提出了一种基于深度状态空间模型和注意力机制的蜂窝流量预测方法，通过结合卷积神经网络和卡尔曼滤波，显著提升了预测精度。


<details>
  <summary>详细信息</summary>
研究动机: 蜂窝流量预测对运营商管理网络资源和决策至关重要，但由于流量的高度动态性和外部因素影响，传统方法预测精度不足。

研究方法: 提出了一种端到端框架，包含两种变体，利用卷积神经网络和注意力机制捕捉空间动态，卡尔曼滤波建模时间动态，并利用辅助信息（如社交活动）提升性能。

研究结果: 在三个真实数据集上的实验表明，所提模型在预测精度上优于现有机器学习技术。

研究结论: 该方法通过结合空间和时间动态建模，显著提升了蜂窝流量预测的准确性，为网络资源管理提供了有效工具。

中文摘要: 蜂窝流量预测对运营商管理网络资源和决策至关重要。流量具有高度动态性，且受多种外部因素影响，这会导致预测精度下降。本文提出了一种端到端框架，包含两种变体，用于明确表征相邻蜂窝之间的时空模式。该框架利用带有注意力机制的卷积神经网络捕捉空间动态，并使用卡尔曼滤波进行时间建模。此外，还能充分利用社交活动等辅助信息提升预测性能。我们在三个真实数据集上进行了大量实验，结果表明所提模型在预测精度上优于现有机器学习技术。

</details>


### [253] [BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models](https://arxiv.org/abs/2506.15689)
**中文标题：BASE-Q：面向大语言模型的偏置与非对称缩放增强旋转量化**

*Liulu He,Shenli Zhen,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du*

主要分类: cs.LG

摘要简述: 本文提出BASE-Q方法，通过偏置校正和非对称缩放优化旋转量化，显著减少大语言模型量化中的舍入和截断误差，同时支持分块优化以降低内存消耗。


<details>
  <summary>详细信息</summary>
研究动机: 当前旋转量化方法存在两个主要问题：一是旋转未能对齐通道均值，导致量化边界扩大和舍入误差增加；二是旋转使激活分布更接近高斯分布，加剧了截断误差的能量损失。这些问题限制了性能提升并增加了训练开销。

研究方法: BASE-Q结合偏置校正和非对称缩放技术，有效减少舍入和截断误差，并支持分块优化，避免了全模型反向传播的高内存需求。

研究结果: 实验表明，BASE-Q在多种大语言模型和基准测试中表现优异，与全精度模型的准确率差距分别比QuaRot、SpinQuant和OSTQuant缩小了50.5%、42.9%和29.2%。

研究结论: BASE-Q是一种简单而强大的方法，显著提升了旋转量化的性能，同时降低了内存消耗，具有较高的实用价值。

中文摘要: 旋转已成为大语言模型（LLM）量化流程中不可或缺的部分，能有效平滑权重和激活中的异常值。然而，进一步优化旋转参数带来的性能提升有限，且引入了显著的训练开销：由于旋转参数共享，必须同时加载全模型以支持反向传播，导致内存消耗巨大且实用性受限。本文指出当前旋转量化方法的两个根本局限：（i）旋转未能对齐通道均值，导致量化边界扩大和舍入误差增加；（ii）旋转使激活分布更接近高斯分布，加剧了截断误差的能量损失。为解决这些问题，我们提出BASE-Q，结合偏置校正和非对称缩放，有效减少舍入和截断误差。此外，BASE-Q支持分块优化，无需内存密集型全模型反向传播。在多种LLM和基准测试上的实验表明，BASE-Q显著缩小了与全精度模型的准确率差距，相比QuaRot、SpinQuant和OSTQuant分别提升了50.5%、42.9%和29.2%。代码即将发布。

</details>


### [254] [LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs](https://arxiv.org/abs/2506.15690)
**中文标题：LLM网络动态：追踪LLM网络中的模型崩溃**

*Tianyu Wang,Lingyou Pang,Akira Horiguchi,Carey E. Priebe*

主要分类: cs.LG

摘要简述: 本文提出LLM Web Dynamics（LWD）框架，研究大型语言模型（LLM）在网络层面的模型崩溃问题，通过模拟互联网环境分析输出收敛模式，并提供理论保证。


<details>
  <summary>详细信息</summary>
研究动机: 随着合成数据在LLM训练中的广泛使用，模型崩溃的潜在威胁尚未充分研究。现有研究多限于单一模型或统计替代，缺乏网络层面的分析。

研究方法: 提出LWD框架，利用检索增强生成（RAG）数据库模拟互联网环境，分析模型输出的收敛模式，并通过类比交互高斯混合模型提供理论保证。

研究结果: 研究发现，在网络层面，LLM的输出会呈现收敛模式，且通过理论分析验证了这一现象的合理性。

研究结论: LWD框架为研究LLM模型崩溃提供了网络层面的新视角，揭示了输出收敛的规律，并支持进一步的理论探索。

中文摘要: 随着公共互联网合成数据在大型语言模型（LLM）训练中的广泛应用，数据使用效率得到提升，但模型崩溃的潜在威胁仍未充分研究。现有研究主要关注单一模型环境下的模型崩溃或仅依赖统计替代。本文提出LLM Web Dynamics（LWD）框架，用于在网络层面高效研究模型崩溃。通过检索增强生成（RAG）数据库模拟互联网环境，分析模型输出的收敛模式，并通过类比交互高斯混合模型提供理论保证。

</details>


### [255] [What Do Latent Action Models Actually Learn?](https://arxiv.org/abs/2506.15691)
**中文标题：潜在动作模型实际学习到了什么？**

*Chuheng Zhang,Tim Pearce,Pushi Zhang,Kaixin Wang,Xiaoyu Chen,Wei Shen,Li Zhao,Jiang Bian*

主要分类: cs.LG

摘要简述: 本文通过线性模型分析潜在动作模型（LAMs）是否真正学习到动作相关的变化，而非无关噪声，揭示了LAM与主成分分析（PCA）的联系，并探讨了数据增强、清理和辅助动作预测对学习可控变化的影响。


<details>
  <summary>详细信息</summary>
研究动机: 潜在动作模型（LAMs）旨在从未标记视频中学习与动作相关的变化，但视频帧之间的差异可能由可控变化或无关噪声引起。本文旨在分析LAMs是否真正捕捉到动作引起的变化，而非噪声。

研究方法: 本文提出一个可分析的线性模型，封装了LAM学习的核心问题，同时探讨了LAM与PCA的联系，以及数据增强、数据清理和辅助动作预测等策略对学习可控变化的作用。

研究结果: 研究通过数值模拟展示了观测数据、动作和噪声的具体结构如何影响LAM学习，验证了数据增强和清理等策略对提升模型学习可控变化的有效性。

研究结论: 本文揭示了LAM学习的本质及其与PCA的联系，强调了数据生成策略的重要性，并提出了通过数据增强和辅助任务优化LAM学习的方法。

中文摘要: 潜在动作模型（LAMs）旨在通过将帧间变化压缩为潜在变量，从未标记视频中学习与动作相关的变化。然而，视频帧之间的差异可能由可控变化或无关噪声引起，这引发了一个重要问题——潜在变量是否捕捉到了动作引起的变化，还是无关噪声？本文通过提出一个可分析的线性模型，封装了LAM学习的核心问题，揭示了LAM与主成分分析（PCA）的联系，并探讨了数据生成策略的期望、数据增强、数据清理和辅助动作预测等策略对学习可控变化的合理性。此外，基于数值模拟的示例结果，阐明了观测数据、动作和噪声的具体结构如何影响LAM学习。

</details>


### [256] [BLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap](https://arxiv.org/abs/2506.15699)
**中文标题：BLUR：一种针对遗忘与保留重叠的LLM遗忘鲁棒性基准测试**

*Shengyuan Hu,Neil Kale,Pratiksha Thaker,Yiwei Fu,Steven Wu,Virginia Smith*

主要分类: cs.LG

摘要简述: 本文提出了BLUR基准测试，用于评估大语言模型（LLM）的遗忘能力，特别关注遗忘与保留任务的重叠情况，揭示了现有方法在实际场景中的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 当前LLM遗忘基准测试中，遗忘集与保留集差异过大，导致评估结果失真，无法反映实际应用中模型的安全性。BLUR旨在提供更真实的遗忘与保留重叠场景，以更全面地评估遗忘方法的有效性。

研究方法: BLUR通过扩展评估任务、结合遗忘/保留查询以及提供不同难度的再学习数据集，构建了一个更全面的LLM遗忘基准测试。

研究结果: 实验表明，现有方法在BLUR上的表现显著下降，简单方法反而优于最新方法，凸显了当前遗忘方法的局限性。

研究结论: BLUR揭示了现有LLM遗忘方法的不足，强调了鲁棒评估的重要性，并为未来研究提供了重要方向。

中文摘要: 机器遗忘技术有望通过事后移除敏感或有害信息来提升大语言模型（LLM）的安全性。遗忘的关键挑战在于平衡遗忘质量（有效移除不良信息）与保留质量（保持其他通用任务的良好性能）。然而，我们发现当前LLM遗忘基准测试中的遗忘集与保留集差异过大，导致对遗忘方法有效性的评估失真。这一问题尤为严重，因为它使得良性扰动（如再学习攻击）在模型部署后轻易暴露所谓的“已遗忘”知识。为此，我们提出了BLUR：一种针对遗忘与保留重叠的更真实场景的LLM遗忘基准测试。BLUR通过扩展评估任务、结合遗忘/保留查询以及提供不同难度的再学习数据集，显著丰富了现有基准测试。尽管查询均为良性，我们发现现有方法在BLUR上的表现显著下降，简单方法平均表现优于最新方法。这些结果凸显了鲁棒评估的重要性，并为未来研究指明了重要方向。BLUR基准测试已公开：https://huggingface.co/datasets/forgelab/BLUR

</details>


### [257] [Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking](https://arxiv.org/abs/2506.15700)
**中文标题：收缩演员-评论家：基于收缩度量的强化学习用于鲁棒路径跟踪**

*Minjae Cho,Hiroyasu Tsukamoto,Huy Trong Tran*

主要分类: cs.LG

摘要简述: 本文提出了一种名为‘收缩演员-评论家’（CAC）的算法，将控制收缩度量（CCM）与强化学习（RL）结合，以在未知动力学下学习最优跟踪策略。CAC通过同时学习收缩度量生成器和演员-评论家算法，提升了CCM的长期最优性，并在仿真和真实机器人实验中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 控制收缩度量（CCM）虽然能确保系统轨迹收敛，但缺乏对整条轨迹的最优性考虑，且依赖于已知动力学模型和复杂的无限维凸可行性问题求解。本文旨在通过将CCM与强化学习结合，解决这些问题，实现自动化学习最优跟踪策略。

研究方法: 提出CAC算法，结合CCM与强化学习。CAC通过预训练动力学模型，同时学习收缩度量生成器（CMG）和基于演员-评论家算法的跟踪策略，利用CCM提供的动态反馈优化长期跟踪性能。

研究结果: 实验表明，CAC在仿真和真实机器人任务中优于现有基线方法，验证了其在未知动力学下学习最优跟踪策略的有效性，并提供了将收缩理论融入强化学习的理论依据。

研究结论: CAC算法成功地将CCM与强化学习结合，不仅扩展了CCM的应用范围，还通过自动化学习提升了长期最优性，为复杂系统的鲁棒路径跟踪提供了新思路。

中文摘要: 控制收缩度量（CCM）提供了一种框架，用于共同合成控制器和相应的收缩度量——一种正定黎曼度量，确保闭环系统具有增量指数稳定性。然而，合成的控制器仅保证系统所有轨迹收敛到单一轨迹，而未考虑整条轨迹的最优性。此外，构建CCM需要已知动力学模型，并需解决无限维凸可行性问题，限制了其在复杂高维不确定系统中的可扩展性。为解决这些问题，我们提出将CCM与强化学习（RL）结合，利用CCM提供的动态反馈学习最小化累积跟踪误差的控制策略。我们提出的算法称为收缩演员-评论家（CAC），在自动化设置中增强了CCM提供收缩策略的能力，并融合了RL的长期最优性。给定预训练的动力学模型，CAC同时学习收缩度量生成器（CMG）和基于演员-评论家算法的跟踪策略。通过仿真和真实机器人实验，我们验证了CAC相对于现有基线的有效性，并提供了将收缩理论融入RL的理论依据。

</details>


### [258] [Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning](https://arxiv.org/abs/2506.15701)
**中文标题：Compiler-R1：基于强化学习的智能编译器自动调优框架**

*Haolin Pan,Hongyu Lin,Haoran Luo,Yang Liu,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

主要分类: cs.LG

摘要简述: Compiler-R1是首个基于强化学习（RL）的框架，通过增强大语言模型（LLM）能力实现编译器自动调优，显著减少IR指令数。


<details>
  <summary>详细信息</summary>
研究动机: 当前编译器自动调优面临两大挑战：缺乏高质量的训练推理数据集和与编译环境的高效交互。Compiler-R1旨在通过强化学习解决这些问题。

研究方法: Compiler-R1采用两阶段端到端强化学习训练流程，结合高质量推理数据集和基于结果的奖励机制，优化编译器调优。

研究结果: 在七个数据集上的实验表明，Compiler-R1平均减少8.46%的IR指令数，优于opt -Oz。

研究结论: Compiler-R1展示了RL训练的LLM在编译器优化中的强大潜力，为自动调优提供了新思路。

中文摘要: 编译器自动调优通过优化传递序列以提升性能指标（如中间表示（IR）指令数）。尽管近期利用大语言模型（LLM）的进展在自动化编译器调优中显示出潜力，但仍存在两大挑战：缺乏高质量的训练推理数据集和与编译环境的高效交互。本文提出Compiler-R1，首个基于强化学习（RL）的框架，专门增强LLM在编译器自动调优中的能力。Compiler-R1包含精选的高质量推理数据集和新型两阶段端到端RL训练流程，通过基于结果的奖励实现高效环境探索与学习。在七个数据集上的广泛实验表明，Compiler-R1平均减少8.46%的IR指令数，优于opt -Oz，展示了RL训练的LLM在编译器优化中的强大潜力。代码和数据集已公开。

</details>


### [259] [Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation](https://arxiv.org/abs/2506.15702)
**中文标题：微调微调：通过纠正自蒸馏实现低数据生成领域适应**

*Peter Belcak,Greg Heinrich,Jan Kautz,Pavlo Molchanov*

主要分类: cs.LG

摘要简述: 本文提出了一种名为minifinetuning（MFT）的方法，用于在低数据情况下进行语言模型领域适应，显著减少过拟合导致的泛化性能下降，且无需预训练数据。MFT在多种模型和领域中表现优于标准微调，并具有对数据稀缺的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 语言模型在新领域的微调通常会损害其泛化性能，尤其是在数据有限的情况下。本文旨在解决这一问题，提出一种无需预训练数据的方法，以减少过拟合导致的性能下降。

研究方法: MFT通过样本级别的纠正自蒸馏技术，实现低数据情况下的领域适应。该方法无需预训练数据，且在数据稀缺时仍能保持鲁棒性。

研究结果: MFT在多种模型和领域中表现出2-10倍优于标准微调的性能，并在数据量低至500样本时仍能有效避免过拟合。

研究结论: MFT是一种高效的语言模型领域适应方法，尤其在低数据情况下表现优异，且可与参数高效微调方法结合使用。

中文摘要: 语言模型在新领域的微调不可避免地会导致其泛化性能的下降，尤其是在微调数据资源有限的情况下。本文提出了微调微调（MFT）方法，用于语言模型领域适应，显著减少了低数据设置中过拟合导致的泛化性能下降，且无需任何预训练数据进行回放。MFT在多种模型和领域中表现出2-10倍优于标准微调的专业化与泛化性能比，并在新领域数据稀缺（低至500样本）时表现出对过拟合的固有鲁棒性。通过采用样本级别的纠正自蒸馏技术，MFT优于参数高效微调方法，表现出类似回放的泛化性能缓解特性，并可与其他方法结合使用以实现综合效果。

</details>


### [260] [Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance](https://arxiv.org/abs/2506.15703)
**中文标题：基于全局融合图引导的联邦不完整多视图聚类**

*Guoqing Chao,Zhenghao Zhang,Lei Meng,Jie Wen,Dianhui Chu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为FIMCFG的新型联邦不完整多视图聚类方法，通过全局融合图引导，解决了现有方法在特征提取和缺失数据处理上的不足，实验证明其有效性和优越性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的联邦多视图聚类方法大多仅依赖全局伪标签指导聚类过程，未能充分利用全局信息进行特征提取，且对数据缺失问题的研究较少。本文旨在解决这些问题。

研究方法: 提出FIMCFG方法，在每个客户端设计双头图卷积编码器提取全局和视图特定特征，通过融合图引导将特征融合为高层特征，并在伪标签监督下进行聚类，最终上传高层特征至服务器优化图融合和伪标签计算。

研究结果: 大量实验结果表明，FIMCFG在联邦不完整多视图聚类任务中表现出色，显著优于现有方法。

研究结论: FIMCFG通过全局融合图引导和双头特征提取，有效解决了联邦多视图聚类中的特征利用和缺失数据问题，具有较高的实用价值。

中文摘要: 联邦多视图聚类旨在挖掘分布在多个设备上的多视图数据中的有价值信息，并在保护隐私的同时取得了显著成果。尽管已有很大进展，但大多数联邦多视图聚类方法仅依赖全局伪标签指导下游聚类过程，未能充分利用全局信息进行特征提取。此外，联邦多视图聚类任务中的数据缺失问题研究较少。为解决这些问题，本文提出了一种基于全局融合图引导的新型联邦不完整多视图聚类方法（FIMCFG）。具体而言，我们在每个客户端设计了双头图卷积编码器，用于提取包含全局和视图特定信息的两种潜在特征。随后，在融合图的引导下，这两种潜在特征被融合为高层特征，并在伪标签监督下进行聚类。最后，高层特征被上传至服务器以优化图融合和伪标签计算。大量实验结果表明，FIMCFG具有显著的有效性和优越性。代码已公开于https://github.com/PaddiHunter/FIMCFG。

</details>


### [261] [Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding](https://arxiv.org/abs/2506.15704)
**中文标题：借鉴历史：大语言模型解码的快速稀疏索引**

*Feiyu Yao,Qian Wang*

主要分类: cs.LG

摘要简述: 本文提出LFPS方法，通过利用历史注意力模式动态构建稀疏索引候选，显著降低大语言模型解码时的计算和内存开销，同时保持生成准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型支持更长的上下文，解码过程中键值缓存的内存需求急剧增加，成为GPU内存和PCIe带宽的瓶颈。稀疏注意力机制虽能缓解此问题，但其索引计算仍需遍历所有键向量，导致高开销。现有方法未充分利用历史解码信息中的时间相关性，因此需要一种更高效的稀疏索引方法。

研究方法: LFPS方法通过捕捉解码注意力中的垂直模式（固定位置）和斜线模式（相对位置），结合位置扩展策略，动态预测当前步骤的Top-k索引。该方法在长上下文基准测试中验证，使用Llama-3.1-8B-Instruct作为基础模型。

研究结果: 实验结果表明，LFPS在RTX 4090 GPU和Xeon Gold 6430单核CPU上，分别实现了22.8倍和9.6倍的速度提升，同时保持了生成准确性。

研究结论: LFPS为长上下文大语言模型推理提供了一种实用且高效的解码优化方案。

中文摘要: 随着大语言模型（LLMs）支持的上下文长度不断增加，解码过程中键值（KV）缓存的内存需求迅速增长，成为GPU内存容量和PCIe带宽的关键瓶颈。稀疏注意力机制通过仅为选定的键值对计算注意力权重来缓解这一问题。然而，其索引计算通常需要遍历所有键向量，导致显著的计算和数据传输开销。为了降低索引检索成本，现有方法通常将每个解码步骤视为独立过程，未能利用历史解码信息中嵌入的时间相关性。为此，我们提出LFPS（借鉴历史的稀疏索引），一种基于历史注意力模式动态构建稀疏索引候选的加速方法。LFPS捕捉解码注意力中的两种常见趋势——垂直模式（关注固定位置）和斜线模式（关注相对位置）——并结合位置扩展策略，有效预测当前步骤的Top-k索引。我们在LongBench-RULER等具有挑战性的长上下文基准测试中验证了LFPS，使用Llama-3.1-8B-Instruct作为基础模型。实验结果表明，在RTX 4090 GPU和Xeon Gold 6430单核CPU上，LFPS分别实现了22.8倍和9.6倍的速度提升，同时保持了生成准确性。这些结果表明，LFPS为长上下文LLM推理提供了一种实用且高效的解码优化方案。

</details>


### [262] [Generalisation Bounds of Zero-Shot Economic Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2506.15705)
**中文标题：基于时间序列基础模型的零样本经济预测泛化边界研究**

*Jittarin Jetwiriyanon,Teo Susnjak,Surangika Ranathunga*

主要分类: cs.LG

摘要简述: 本研究探讨了时间序列基础模型（TSFMs）在宏观经济指标零样本预测中的能力，发现其在稳定经济条件下表现优异，但在快速冲击时期性能下降。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在验证时间序列基础模型（TSFMs）是否能够在无需训练定制经济模型的情况下，直接用于宏观经济指标的零样本预测，并评估其在数据稀缺和结构突变条件下的表现。

研究方法: 研究在单变量条件下应用了三种先进的时间序列基础模型（Chronos、TimeGPT和Moirai），并在案例数据集上进行了严格的回测，未进行额外定制。

研究结果: 结果表明，适当设计的时间序列基础模型能够捕捉丰富的经济动态，适应制度变化，并提供良好的不确定性估计，性能与当前最先进的多变量模型相当。但在快速冲击时期，模型性能会下降。

研究结论: 时间序列基础模型在稳定经济条件下无需微调即可匹配或超越传统模型，但在快速冲击时期表现不佳。研究为零样本部署在宏观经济监测和战略规划中的可行性提供了指导。

中文摘要: 本研究探讨了时间序列基础模型（TSFMs）在宏观经济指标零样本预测中的能力。我们通过单变量条件应用TSFMs进行经济指标预测，避免了使用大量训练数据定制经济模型的需求。实验在案例数据集上进行，未进行额外定制。我们严格回测了三种先进的时间序列基础模型（Chronos、TimeGPT和Moirai）在数据稀缺和结构突变条件下的表现。结果表明，适当设计的TSFMs能够内化丰富的经济动态，适应制度变化，并提供良好的不确定性估计，性能与当前最先进的多变量模型相当。研究发现，在稳定经济条件下，未经微调的TSFMs可以匹配或超越传统模型，但在快速冲击时期性能会下降。研究为零样本部署在宏观经济监测和战略规划中的可行性提供了指导。

</details>


### [263] [MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning](https://arxiv.org/abs/2506.15706)
**中文标题：MDPO：多粒度直接偏好优化用于数学推理**

*Yunze Lin*

主要分类: cs.LG

摘要简述: 本文提出多粒度直接偏好优化（MDPO）方法，通过三个粒度（Solution2Solution、Inference2Inference、Step2Step）优化大语言模型（LLMs）的数学推理能力，并在实验中显著优于传统DPO方法。


<details>
  <summary>详细信息</summary>
研究动机: 数学推理对LLMs具有挑战性，传统监督微调难以抑制错误输出，而直接偏好优化（DPO）在长链推理中效果有限。因此，需要一种更有效的方法来提升LLMs的数学推理能力。

研究方法: 提出MDPO方法，从三个粒度优化数学推理：Solution2Solution关注长链推理的整体正确性；Inference2Inference关注步骤间的逻辑推理；Step2Step纠正步骤中的计算错误。同时统一训练目标以匹配生成指标。

研究结果: 在Qwen2和Llama3模型上，GSM8K数据集分别提升1.7%和0.9%，MATH数据集提升2.3%和1.2%，优于DPO及其变体方法。

研究结论: MDPO通过多粒度优化显著提升LLMs的数学推理能力，并提供了一种无需人工标注的数据构建流程。

中文摘要: 数学推理对大语言模型（LLMs）是一项重大挑战，因其需确保每一步推理的正确性。研究者通过监督微调增强LLMs的数学推理能力，但无法抑制错误输出，易产生幻觉。最近，直接偏好优化（DPO）被广泛用于通过偏好数据对齐人类意图，防止LLMs生成错误输出。然而，其在长链数学推理中效果有限，主要因DPO难以有效捕捉长链数据中偏好间的差异。DPO训练与LLMs生成指标的不一致也影响抑制错误输出的效果。我们提出多粒度直接偏好优化（MDPO）方法，从三个粒度优化LLMs的数学推理：Solution2Solution关注长链推理的整体正确性；Inference2Inference关注步骤间的逻辑推理；Step2Step纠正步骤中的计算错误，提升LLMs的计算能力。此外，我们统一三个粒度的训练目标以匹配生成指标。在开源模型Qwen2和Llama3上的实验显示，GSM8K数据集分别提升1.7%和0.9%，MATH数据集提升2.3%和1.2%，优于DPO及其他DPO变体方法。我们还提供了一种简单且无需人工标注的MDPO训练数据构建流程。

</details>


### [264] [Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling](https://arxiv.org/abs/2506.15707)
**中文标题：每次探索都重要：高效测试时扩展的最优资源分配**

*Xinglin Wang,Yiwei Li,Shaoxiong Feng,Peiwen Yuan,Yueqi Zhang,Jiayi Shi,Chuyi Tan,Boyuan Pan,Yao Hu,Kan Li*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DORA的资源分配方法，用于优化大型语言模型在测试时的计算资源分配，通过方向级资源分配提升搜索效率，并在数学推理任务中验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 现有测试时扩展（TTS）方法在资源分配上存在效率不足的问题，尤其是在搜索过程中倾向于偏向候选数量多的推理方向，导致计算资源浪费。本文旨在解决这一问题，提出更优的资源分配策略。

研究方法: 将测试时搜索建模为资源分配问题，提出方向导向资源分配（DORA）方法，通过解耦方向质量与候选数量，在方向级别分配资源，确保计算资源的最优使用。

研究结果: 在MATH500、AIME2024和AIME2025等数学推理基准测试中，DORA在相同计算成本下显著优于基线方法，达到了最先进的准确率。

研究结论: DORA通过优化资源分配策略，显著提升了测试时扩展的效率，为大型语言模型的推理任务提供了更优的解决方案。

中文摘要: 测试时扩展（TTS）通过额外的推理时间计算探索多条推理路径，从而提升大型语言模型（LLM）的性能。然而，如何在搜索过程中最有效地分配固定的探索预算仍未被充分研究，往往导致测试时计算资源的低效使用。为填补这一空白，我们将测试时搜索建模为资源分配问题，并推导出在固定探索预算下最大化获得正确解概率的最优分配策略。在这一框架下，我们揭示了现有搜索方法的核心局限：解决方案级分配倾向于支持候选数量多的推理方向，导致理论上次优和计算资源的低效使用。为解决这一问题，我们提出了方向导向资源分配（DORA），这是一种可证明最优的方法，通过解耦方向质量与候选数量，在方向级别分配资源以消除偏差。为验证DORA的有效性，我们在包括MATH500、AIME2024和AIME2025在内的具有挑战性的数学推理基准上进行了大量实验。实证结果表明，在相同计算成本下，DORA始终优于强基线方法，达到了最先进的准确率。我们希望这些发现能为更广泛地理解LLM的最优测试时扩展提供贡献。

</details>


### [265] [Refined Causal Graph Structure Learning via Curvature for Brain Disease Classification](https://arxiv.org/abs/2506.15708)
**中文标题：基于曲率的精细因果图结构学习用于脑疾病分类**

*Falih Gozi Febrinanto,Adonia Simango,Chengpei Xu,Jingjing Zhou,Jiangang Ma,Sonika Tyagi,Feng Xia*

主要分类: cs.LG

摘要简述: 本文提出了一种名为CGB的新型框架，通过因果发现方法和几何曲率策略优化脑网络建模，显著提升了脑疾病分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的图神经网络（GNNs）在脑疾病检测中未充分考虑脑区间的因果关系，而因果关系比传统相关性更能揭示信号间的因果交互作用。

研究方法: CGB框架结合因果发现方法（转移熵）和几何曲率策略，构建并优化脑区间的因果图，通过图重连减少信息瓶颈，提升图神经网络的表达能力。

研究结果: 实验表明，CGB在脑疾病数据集上的分类任务中，平均F1分数优于现有最先进方法。

研究结论: CGB通过建模和优化脑区间的因果关系，显著提升了脑疾病分类性能，为相关研究提供了新思路。

中文摘要: 图神经网络（GNNs）已被用于建模脑区（ROIs）间的关系，并在脑疾病检测中表现出显著改进。然而，这些框架大多未考虑脑区间的内在因果关系，而因果关系比传统相关性更能揭示信号间的因果交互作用。我们提出了一种名为CGB（脑因果图）的新型框架，用于脑疾病分类/检测。该框架基于因果发现方法（转移熵）和几何曲率策略，构建精细的脑网络模型。CGB揭示了脑区间的因果关系，为提升脑疾病分类性能提供了关键信息。此外，CGB还通过几何曲率策略进行图重连，优化生成的因果图，使其更具表达力，并减少图神经网络建模时的潜在信息瓶颈。大量实验表明，CGB在脑疾病数据集上的分类任务中，平均F1分数优于现有最先进方法。

</details>


### [266] [Studying and Improving Graph Neural Network-based Motif Estimation](https://arxiv.org/abs/2506.15709)
**中文标题：研究与改进基于图神经网络的模体估计**

*Pedro C. Vieira,Miguel E. P. Silva,Pedro Manuel Pinto Ribeiro*

主要分类: cs.LG

摘要简述: 本文研究了基于图神经网络（GNN）的模体估计问题，提出了一种直接估计网络模体显著性特征（SP）的方法，并通过多目标回归优化了模型的解释性、稳定性和可扩展性。实验表明，1-WL受限模型在精确估计SP方面存在困难，但能通过比较预测SP与合成生成器的SP来近似网络生成过程。


<details>
  <summary>详细信息</summary>
研究动机: 图神经网络（GNN）在图表示学习中占主导地位，但其在网络模体显著性特征（SP）预测方面的应用尚未充分探索，且缺乏相关基准。本文旨在解决这一问题，将SP估计独立于子图频率估计，并探索其潜在优势。

研究方法: 本文提出了一种直接估计网络模体显著性特征（SP）的方法，将问题重新表述为多目标回归任务。该方法优化了模型的解释性、稳定性和在大规模图上的可扩展性。实验使用了合成数据集和真实世界图数据进行验证。

研究结果: 实验结果表明，1-WL受限模型难以精确估计SP，但能通过比较预测SP与合成生成器的SP来近似网络生成过程。此外，直接SP估计有助于克服通过子图计数进行模体估计时的理论限制。

研究结论: 本文首次研究了基于GNN的模体估计问题，提出直接SP估计的方法，并展示了其在克服子图计数限制方面的潜力。这为未来研究提供了新的方向。

中文摘要: 图神经网络（GNN）是图表示学习的主要方法。然而，除了子图频率估计外，其在网络模体显著性特征（SP）预测中的应用尚未充分探索，且文献中缺乏相关基准。我们提出将SP估计作为独立于子图频率估计的任务来解决这一问题。我们的方法从频率计数转向直接SP估计，并将问题建模为多目标回归。这一重新表述优化了模型的解释性、稳定性和在大规模图上的可扩展性。我们使用大型合成数据集验证了该方法，并在真实世界图上进行了测试。实验表明，1-WL受限模型难以精确估计SP，但能通过比较预测SP与合成生成器的SP来近似网络生成过程。这项关于基于GNN的模体估计的首项研究还提示，直接SP估计有助于克服通过子图计数进行模体估计时的理论限制。

</details>


### [267] [RAST: Reasoning Activation in LLMs via Small-model Transfer](https://arxiv.org/abs/2506.15710)
**中文标题：RAST：通过小模型迁移激活大语言模型的推理能力**

*Siru Ouyang,Xinyu Zhu,Zilin Xiao,Minhao Jiang,Yu Meng,Jiawei Han*

主要分类: cs.LG

摘要简述: 论文提出RAST方法，通过小模型训练后的概率调整迁移到大模型，显著提升推理能力，同时减少计算资源消耗。


<details>
  <summary>详细信息</summary>
研究动机: 强化学习（RL）虽能提升大语言模型（LLMs）的推理能力，但计算资源需求极高。研究发现RL并未赋予模型新知识，而是调整输出分布以激活潜在能力。因此，假设RL诱导的概率变化与模型规模无关，可通过小模型训练后迁移到大模型，实现高效推理能力提升。

研究方法: 提出RAST方法，通过分析解码轨迹发现不同规模模型的RL诱导输出分布高度一致，验证假设后，将小模型RL训练后的概率调整注入大模型，实现推理行为迁移。

研究结果: 实验表明，RAST在多个数学推理基准测试中显著提升大模型推理能力，且GPU内存需求远低于直接RL训练，有时性能甚至优于RL训练模型。

研究结论: RAST揭示了RL驱动推理的本质，并提供了一种无需高计算成本的实用策略，为高效扩展RL优势提供了新思路。

中文摘要: 强化学习（RL）已成为提升大语言模型（LLMs）推理能力的强大方法，如OpenAI的o1和Deepseek-R1所示。然而，大规模应用RL仍需要大量资源，包括多个模型副本和大量GPU工作负载。另一方面，尽管RL强大，近期研究表明它并未赋予模型新知识，而是通过调整输出分布激活基础模型中的潜在推理能力。基于这一发现，我们假设RL诱导的概率变化与模型规模无关，从而提出一种更高效的范式：训练一个小模型并通过RL调整其输出概率，然后将这些调整迁移到更大的基础模型中。为验证假设，我们对解码轨迹进行标记级分析，发现不同规模模型的RL诱导输出分布高度一致。基于此，我们提出RAST方法，通过将小模型RL训练后的概率调整注入大模型，实现推理行为迁移。在多个数学推理基准测试中，RAST显著提升了基础模型的推理能力，同时GPU内存需求远低于直接RL训练，有时性能甚至优于RL训练模型。我们的研究为RL驱动推理的本质提供了新见解，并为无需高计算成本的扩展策略提供了实用方案。RAST项目页面见https://ozyyshr.github.io/RAST/。

</details>


### [268] [Shadow defense against gradient inversion attack in federated learning](https://arxiv.org/abs/2506.15711)
**中文标题：联邦学习中针对梯度反转攻击的影子防御**

*Le Jiang,Liyan Ma,Guang Yang*

主要分类: cs.LG

摘要简述: 本文提出一种基于影子模型的防御框架，针对联邦学习中的梯度反转攻击，通过针对性噪声注入保护敏感数据，同时最小化对模型性能的影响。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在隐私保护分布式训练中具有重要作用，但梯度反转攻击可能通过模型更新泄露敏感数据。现有防御机制缺乏对梯度脆弱性的精细理解，导致隐私保护与模型性能的失衡。

研究方法: 利用具有可解释性的影子模型识别敏感区域，实现样本特定的噪声注入，从而更精准地防御梯度反转攻击。

研究结果: 在ChestXRay和EyePACS数据集上，防御策略的PSNR和SSIM差异分别为3.73/0.2和2.78/0.166，且对模型性能影响极小（F1值降低不到1%）。

研究结论: 该框架在多种医学图像上验证了其泛化能力，显著提升了防御效果（LPIPS和SSIM稳定提升1.5%以上），并能通用防御多种梯度反转攻击。

中文摘要: 联邦学习（FL）作为一种隐私保护的分布式训练框架，允许客户端在不共享本地数据的情况下协作训练全局模型，这在医疗等敏感领域尤为重要。然而，隐私泄露仍是一个关键挑战，因为模型更新的通信可能被潜在攻击者利用。例如，梯度反转攻击（GIA）允许攻击者近似训练梯度并重建训练图像，从而窃取患者隐私。现有防御机制通过模糊梯度来应对，但缺乏对哪些梯度或图像信息最易受攻击的细致理解。这些不加区分的校准扰动要么导致过度隐私保护而降低模型准确性，要么因保护不足而无法保障敏感信息。为此，我们提出一种框架，利用具有可解释性的影子模型识别敏感区域，从而实现更具针对性和样本特异性的噪声注入。具体而言，在ChestXRay数据集上，我们的防御策略与无防御情况相比，PSNR和SSIM差异分别为3.73和0.2；在EyePACS数据集上分别为2.78和0.166。此外，它对模型性能的负面影响极小，与现有最优方法相比，F1值降低不到1%。我们在多种医学图像上的广泛实验验证了该框架的泛化能力。对FedAvg的防御改进在LPIPS和SSIM上稳定超过1.5%。该框架还能通用防御多种GIA类型，尤其是针对图像中的敏感区域。

</details>


### [269] [BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling](https://arxiv.org/abs/2506.15712)
**中文标题：基于点级掩码信号建模的BatteryBERT用于真实电池故障检测**

*Songqi Zhou,Ruixue Liu,Yixing Wang,Jia Lu,Benben Jiang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为BatteryBERT的新框架，通过改进BERT架构并引入点级掩码信号建模（point-MSM）任务，用于锂离子电池故障检测。该方法利用自监督学习处理时间序列数据，显著提升了故障分类的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 锂离子电池的故障检测对电动汽车和储能系统的安全运行至关重要。现有方法难以捕捉复杂的时间依赖性，且无法充分利用大量未标记数据。尽管大型语言模型（LLMs）具有强大的表征能力，但其架构并不直接适用于工业场景中的数值时间序列数据。

研究方法: 本文提出了一种改进的BERT架构，包括定制的时间序列到令牌表示模块和点级掩码信号建模（point-MSM）预训练任务。该方法通过自监督学习处理电流、电压等充放电循环数据，生成分布鲁棒且上下文感知的时间嵌入。随后，将这些嵌入与电池元数据拼接，输入下游分类器进行故障分类。

研究结果: 在大规模真实数据集上的实验结果表明，使用本文预训练参数初始化的模型显著提升了表征质量和分类准确性，AUROC达到0.945，明显优于现有方法。

研究结论: 本文验证了BERT风格预训练在时间序列故障检测中的有效性，为电池故障检测提供了一种高效且鲁棒的新方法。

中文摘要: 锂离子电池的准确故障检测对电动汽车和储能系统的安全可靠运行至关重要。然而，现有方法往往难以捕捉复杂的时间依赖性，且无法充分利用大量未标记数据。尽管大型语言模型（LLMs）表现出强大的表征能力，但其架构并不直接适用于工业场景中常见的数值时间序列数据。为解决这些挑战，我们提出了一种新颖框架，通过扩展标准BERT架构，引入定制的时间序列到令牌表示模块和专为电池应用设计的点级掩码信号建模（point-MSM）预训练任务，将BERT风格的预训练应用于电池故障检测。该方法能够对电流、电压等充放电循环数据进行自监督学习，生成分布鲁棒且上下文感知的时间嵌入。随后，将这些嵌入与电池元数据拼接，输入下游分类器进行准确的故障分类。在大规模真实数据集上的实验结果表明，使用我们预训练参数初始化的模型显著提升了表征质量和分类准确性，AUROC达到0.945，明显优于现有方法。这些发现验证了BERT风格预训练在时间序列故障检测中的有效性。

</details>


### [270] [NeuronSeek: On Stability and Expressivity of Task-driven Neurons](https://arxiv.org/abs/2506.15715)
**中文标题：NeuronSeek：任务驱动神经元的稳定性与表达能力研究**

*Hanyu Pei,Jing-Xiao Liao,Qibin Zhao,Ting Gao,Shijun Zhang,Xiaoge Zhang,Feng-Lei Fan*

主要分类: cs.LG

摘要简述: 本文提出NeuronSeek-TD框架，通过张量分解（TD）优化神经元设计，提升稳定性和收敛速度，并证明其理论表达能力。实验表明其在多个基准任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 受人类大脑为不同任务设计不同神经元的启发，深度学习领域探索了任务驱动神经元的设计。然而，现有方法（如符号回归）在稳定性和效率上存在不足，因此本文提出改进方案。

研究方法: 采用张量分解（TD）替代符号回归（SR），优化神经元设计，构建任务驱动神经元网络。理论分析表明，通过修改聚合函数和激活函数，网络能以固定参数逼近任意连续函数。

研究结果: 实验证明，NeuronSeek-TD框架在稳定性和收敛速度上显著优于符号回归方法，并在多个基准任务中达到与最先进模型竞争的性能。

研究结论: NeuronSeek-TD框架为任务驱动神经元设计提供了更稳定、高效的解决方案，并奠定了坚实的理论基础。

中文摘要: 受人类大脑为不同任务设计不同神经元的启发，深度学习领域近期探索了任务驱动神经元的设计。原型化任务驱动神经元（称为NeuronSeek）采用符号回归（SR）发现最优神经元形式，并基于这些优化神经元构建网络。本文沿此方向，用张量分解（TD）替代符号回归，以发现最优神经元形式，提供更高的稳定性和更快的收敛速度。此外，我们建立了理论保证，证明通过修改聚合函数和常见激活函数，固定参数的网络能以任意小误差逼近任何连续函数，为NeuronSeek框架提供了严格的数学基础。大量实验评估表明，NeuronSeek-TD框架不仅具有卓越的稳定性，还在多个基准任务中与最先进模型竞争。代码发布于https://github.com/HanyuPei22/NeuronSeek。

</details>


### [271] [Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies](https://arxiv.org/abs/2506.15716)
**中文标题：替补成员集结！为公民大会选择最优替补**

*Angelos Assos,Carmel Baharav,Bailey Flanigan,Ariel Procaccia*

主要分类: cs.LG

摘要简述: 本文提出了一种优化框架，用于为公民大会选择替补成员，以解决因成员退出导致的人口代表性失衡问题。通过历史数据估计退出概率并优化替补选择，显著提升了代表性且减少了所需替补数量。


<details>
  <summary>详细信息</summary>
研究动机: 公民大会作为协商民主的重要形式，其合法性依赖于对广泛人口的代表性。然而，成员退出常导致代表性失衡，现有方法未充分考虑替补选择。本文旨在填补这一空白。

研究方法: 提出了一种基于学习理论的优化框架，利用历史数据估计成员退出概率，并通过算法选择替补以最小化预期代表性偏差。

研究结果: 理论分析提供了样本复杂性和退出概率估计误差的最坏情况界限。实证研究表明，相比现有方法，该方法显著提升了代表性且减少了替补需求。

研究结论: 本文提出的优化框架有效解决了公民大会成员退出导致的代表性失衡问题，为替补选择提供了理论和实践支持。

中文摘要: 协商民主的一种日益重要的形式是公民大会，即随机选出的人员讨论政策问题。这些小组的合法性依赖于其对广泛人口的代表性，但成员常因退出导致组成失衡。尽管实践中通过替补缓解成员流失，但现有方法未考虑替补选择。为填补这一空白，我们提出了一种优化替补选择的框架。我们的算法方法利用学习理论工具，通过历史数据估计退出概率并选择替补以最小化预期代表性偏差。我们为该方法建立了理论保证，包括样本复杂性（对计算效率的影响）和退出概率估计误差导致损失的最坏情况界限。基于真实数据的实证评估表明，相比现状，我们的方法显著提升了代表性且减少了替补需求。

</details>


### [272] [daDPO: Distribution-Aware DPO for Distilling Conversational Abilities](https://arxiv.org/abs/2506.15717)
**中文标题：daDPO：基于分布感知的DPO用于对话能力蒸馏**

*Zhengze Zhang,Shiqi Wang,Yiqun Shen,Simin Guo,Dahua Lin,Xiaoliang Wang,Nguyen Cam-Tu,Fei Tan*

主要分类: cs.LG

摘要简述: 本文提出了一种名为daDPO（分布感知DPO）的新方法，通过结合偏好优化和基于分布的蒸馏，显著提升了小型语言模型的对话能力。实验证明，daDPO在恢复剪枝模型性能和增强小型模型方面优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在多种应用中表现优异，但随着模型规模减小，其对话能力急剧下降，限制了在资源受限环境中的部署。现有的知识蒸馏方法（如dDPO）仅关注教师模型的输出，忽略了其输出分布信息，导致性能提升有限。

研究方法: daDPO是一种统一的方法，结合了偏好优化和基于分布的蒸馏。它利用教师模型的输出分布信息，通过理论分析和实验验证，优化小型模型的对话能力。

研究结果: 实验表明，daDPO显著优于现有方法。在领域内评估中，20%剪枝的Vicuna1.5-7B模型性能接近教师模型（偏好率仅下降7.3%，而dDPO下降31%），Qwen2.5-1.5B模型甚至偶尔能超越其7B教师模型（胜率为14.0%）。

研究结论: daDPO通过利用教师模型的输出分布信息，有效提升了小型语言模型的对话能力，为资源受限环境中的模型部署提供了新思路。

中文摘要: 大型语言模型（LLMs）在各种应用中表现出色，但随着模型规模减小，其对话能力急剧下降，阻碍了其在资源受限环境中的部署。基于直接偏好优化（dDPO）的知识蒸馏方法成为提升小型模型对话能力的有力工具，但现有方法主要关注“黑盒”知识蒸馏，仅利用教师模型的响应，忽略了其输出分布。本文填补了这一空白，提出了daDPO（分布感知DPO），一种结合偏好优化和基于分布蒸馏的统一方法。通过严格的理论分析和实证验证，我们证明daDPO在恢复剪枝模型性能和增强小型LLM模型方面优于现有方法。值得注意的是，在领域内评估中，我们的方法使20%剪枝的Vicuna1.5-7B模型性能接近教师模型（偏好率仅下降7.3%，而dDPO下降31%），并使Qwen2.5-1.5B模型偶尔能超越其7B教师模型（胜率为14.0%）。

</details>


### [273] [UniMate: A Unified Model for Mechanical Metamaterial Generation, Property Prediction, and Condition Confirmation](https://arxiv.org/abs/2506.15722)
**中文标题：UniMate：一种用于机械超材料生成、属性预测和条件确认的统一模型**

*Wangzhi Zhan,Jianpeng Chen,Dongqi Fu,Dawei Zhou*

主要分类: cs.LG

摘要简述: 本文提出了一种名为UNIMATE的统一模型，用于机械超材料的生成、属性预测和条件确认。该模型通过模态对齐模块和协同扩散生成模块，显著优于现有基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有机器学习模型在机械超材料设计中通常仅考虑两种模态（如3D拓扑与机械属性），而实际应用需要同时处理三种模态（3D拓扑、密度条件和机械属性）。因此，本文旨在填补这一空白，提出一个统一模型。

研究方法: UNIMATE模型包含模态对齐模块和协同扩散生成模块，能够同时处理3D拓扑、密度条件和机械属性三种模态，实现超材料的生成、属性预测和条件确认。

研究结果: 实验表明，UNIMATE在拓扑生成任务、属性预测任务和条件确认任务中分别比基线模型提升了80.2%、5.1%和50.2%。

研究结论: UNIMATE模型在机械超材料设计中表现出色，填补了现有模型的空白，为复杂应用场景提供了有效解决方案。

中文摘要: 超材料是一种人工设计的材料，旨在实现自然界中未见的特性，如超刚度和负材料指数。在机械超材料设计中，通常涉及三种关键模态，即3D拓扑、密度条件和机械属性。现实中的复杂应用场景要求机器学习模型能够同时考虑这三种模态。然而，现有文献表明，大多数工作仅考虑两种模态，例如给定3D拓扑预测机械属性，或根据所需属性生成3D拓扑。因此，现有机器学习模型仍存在显著不足。为此，我们提出了一种名为UNIMATE的统一模型，包含模态对齐模块和协同扩散生成模块。实验表明，UNIMATE在拓扑生成任务、属性预测任务和条件确认任务中分别比基线模型提升了80.2%、5.1%和50.2%。我们已将UNIMATE模型及相关结果开源，详见https://github.com/wzhan24/UniMate。

</details>


### [274] [MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference](https://arxiv.org/abs/2506.15724)
**中文标题：MadaKV：面向高效多模态长上下文推理的自适应模态感知KV缓存淘汰策略**

*Kunxi Li,Zhonghua Jiang,Zhouzhou Shen,Zhaode Wang,Chengfei Lv,Shengyu Zhang,Fan Wu,Fei Wu*

主要分类: cs.LG

摘要简述: 本文提出MadaKV，一种自适应模态感知的KV缓存淘汰策略，旨在提升多模态大语言模型在长上下文推理中的效率。通过动态感知模态信息并保留关键令牌，MadaKV显著减少了KV缓存内存占用和解码延迟，同时保持高准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在多模态场景中，注意力头对不同模态的偏好差异显著，传统单模态KV缓存淘汰方法无法有效捕捉模态特定信息，导致性能不佳。MadaKV旨在解决这一问题。

研究方法: MadaKV包含两个关键组件：模态偏好适应和分层压缩补偿。通过动态感知注意力头中的模态信息，并自适应保留关键令牌，优化KV缓存管理。

研究结果: 实验表明，MadaKV在多种多模态长上下文任务中显著减少了KV缓存内存占用和解码延迟（提升1.3至1.5倍），同时保持高准确性。

研究结论: MadaKV通过自适应模态感知和分层压缩补偿，有效提升了多模态大语言模型的长上下文推理效率，优于现有KV缓存淘汰方法。

中文摘要: 本文介绍了MadaKV，一种自适应模态感知的键值（KV）缓存淘汰策略，旨在提升多模态大语言模型（MLLMs）在长上下文推理中的效率。在多模态场景中，注意力头对不同模态的偏好存在显著差异，导致模态重要性在注意力头间分布不均。传统的KV缓存淘汰方法专为单模态设计，无法捕捉模态特定信息，从而性能不佳。MadaKV通过两个关键组件解决这些问题：模态偏好适应和分层压缩补偿。通过动态感知注意力头中的模态信息并自适应保留关键令牌，MadaKV显著减少了KV缓存内存占用和模型推理解码延迟（提升1.3至1.5倍），同时在多种多模态长上下文任务中保持高准确性。基于代表性MLLMs和MileBench基准的大量实验证明了MadaKV相对于现有KV缓存淘汰方法的有效性。

</details>


### [275] [Graph Diffusion that can Insert and Delete](https://arxiv.org/abs/2506.15725)
**中文标题：能够插入和删除的图扩散**

*Matteo Ninniri,Marco Podda,Davide Bacciu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GrIDDD的图扩散模型，通过支持节点的单调插入和删除，解决了现有图扩散模型无法调整图大小的问题，从而在分子生成和优化任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于离散去噪扩散概率模型（DDPMs）的图生成模型无法在扩散过程中调整图的大小（即原子数量），这严重限制了其在条件生成（如属性驱动的分子设计）中的有效性。本文旨在解决这一问题。

研究方法: 本文重新定义了噪声化和去噪过程，支持节点的单调插入和删除，提出了名为GrIDDD的模型。该模型在生成过程中动态调整化学图的大小。

研究结果: GrIDDD在分子属性目标任务中表现优于或与现有图扩散模型相当，同时在分子优化任务中也展现出竞争力。

研究结论: GrIDDD为尺寸自适应的分子生成提供了新思路，为图扩散模型在分子设计中的应用开辟了道路。

中文摘要: 基于离散去噪扩散概率模型（DDPMs）的图生成模型通过逐步调整原子和键的结构噪声，为分子生成提供了一种系统化的方法。然而，现有模型由于无法在扩散过程中调整图的大小（即原子数量），严重限制了其在条件生成（如属性驱动的分子设计）中的有效性。本文重新定义了噪声化和去噪过程，支持节点的单调插入和删除，提出了名为GrIDDD的模型。该模型在生成过程中动态调整化学图的大小。GrIDDD在分子属性目标任务中表现优于或与现有图扩散模型相当，同时在分子优化任务中也展现出竞争力。这项工作为尺寸自适应的分子生成提供了新思路。

</details>


### [276] [Adaptive Two Sided Laplace Transforms: A Learnable, Interpretable, and Scalable Replacement for Self-Attention](https://arxiv.org/abs/2506.15714)
**中文标题：自适应双边拉普拉斯变换：一种可学习、可解释且可扩展的自注意力替代方案**

*Andrew Kiruluta*

主要分类: cs.LG

摘要简述: 本文提出了一种可学习的双边短时拉普拉斯变换（STLT）机制，用于替代传统Transformer中的自注意力机制。STLT通过可训练参数动态调整衰减率和频率响应，实现了高效的长序列建模，并在多个任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 传统自注意力机制在长序列建模中存在计算瓶颈，难以扩展到超长上下文。本文旨在提出一种可学习、可解释且高效的替代方案，以解决这一问题。

研究方法: 提出了一种可学习的双边短时拉普拉斯变换（STLT）机制，通过可训练参数动态调整衰减率、振荡频率和窗口带宽。结合快速递归卷积和FFT计算，实现了高效的时间和内存复杂度。此外，引入了自适应节点分配机制，动态调整活跃节点数量。

研究结果: 在语言建模（WikiText-103、Project Gutenberg）、机器翻译（WMT'14 En-De）和长文档问答（NarrativeQA）任务中，STLT的表现与现有高效Transformer相当或更优，并能扩展到超过10万标记的上下文长度。

研究结论: STLT结合了可解释性（通过显式衰减和频率参数）与可扩展性，为超长序列语言建模提供了一条新路径，避免了自注意力的计算瓶颈。

中文摘要: 我们提出了一种创新的、可学习的双边短时拉普拉斯变换（STLT）机制，用于替代基于Transformer的大型语言模型中的传统自注意力。STLT为每个拉普拉斯节点引入了可训练参数，实现了衰减率、振荡频率和窗口带宽T的端到端学习。这种灵活性使模型能够在训练过程中动态调整标记相关性的半衰期和频率响应。通过选择S个可学习节点并利用快速递归卷积，我们实现了时间和内存上的高效复杂度。此外，我们还结合了基于FFT的相关性矩阵高效计算和自适应节点分配机制，以动态调整活跃拉普拉斯节点的数量。在语言建模（WikiText-103、Project Gutenberg）、机器翻译（WMT'14 En-De）和长文档问答（NarrativeQA）任务上的实验结果表明，我们的可学习STLT在困惑度和得分上与现有高效Transformer相当或更优，同时能够自然扩展到超过10万标记的上下文长度（仅受限于硬件）。消融研究证实了可学习参数和自适应节点分配的重要性。所提出的方法结合了可解释性（通过显式衰减和频率参数）与可扩展性和鲁棒性，为超长序列语言建模提供了一条新路径，避免了自注意力的计算瓶颈。

</details>


### [277] [Uncertainty Estimation by Human Perception versus Neural Models](https://arxiv.org/abs/2506.15850)
**中文标题：人类感知与神经网络模型的不确定性估计对比**

*Pedro Mendes,Paolo Romano,David Garlan*

主要分类: cs.LG

摘要简述: 现代神经网络预测准确但校准不足，常产生过度自信的错误预测。本文比较人类感知不确定性与神经网络估计的不确定性，发现两者相关性较弱，但通过引入人类软标签可改善模型校准。


<details>
  <summary>详细信息</summary>
研究动机: 神经网络虽预测准确，但其不确定性估计常不可靠，影响关键应用。本文旨在探究人类感知不确定性与神经网络估计的差异，并探索如何利用人类直觉提升模型的可信度。

研究方法: 使用三个视觉基准数据集，标注人类分歧和众包置信度，评估模型预测不确定性与人类感知不确定性的相关性，并尝试在训练中引入人类软标签以改善校准。

研究结果: 结果显示，当前方法与人类直觉仅弱相关，且相关性因任务和指标而异。引入人类软标签可在不损失准确性的情况下改善模型校准。

研究结论: 人类与模型不确定性间存在显著差距，但人类直觉可为开发更可信的AI系统提供指导。

中文摘要: 现代神经网络（NNs）虽预测准确，但校准不足，常产生过度自信的错误预测。这种校准问题在需要可靠不确定性估计的应用中带来严重挑战。本文研究人类感知不确定性与神经网络估计的不确定性之间的差异。通过三个标注人类分歧和众包置信度的视觉基准数据集，评估模型预测不确定性与人类感知不确定性的相关性。结果显示，当前方法与人类直觉仅弱相关，且相关性因任务和指标而异。值得注意的是，将人类软标签引入训练过程可在不影响准确性的情况下改善校准。这些发现揭示了模型与人类不确定性间的持续差距，并凸显了利用人类直觉指导开发更可信AI系统的潜力。

</details>


### [278] [Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute](https://arxiv.org/abs/2506.15882)
**中文标题：通过潜在导向向量实现分数推理以提升推理时计算效率**

*Sheng Liu,Tianlang Chen,Pan Lu,Haotian Ye,Yizheng Chen,Lei Xing,James Zou*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“分数推理”的训练无关、模型无关框架，通过潜在导向向量动态调整推理强度，显著提升大语言模型在测试时的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法（如Best-of-N、多数投票和自反思）在推理时对所有输入采用统一的推理深度，忽略了不同问题可能需要不同推理强度的问题。本文旨在解决这一局限性，实现推理强度的连续控制。

研究方法: 通过提取与深度推理相关的潜在导向向量，并利用可调缩放因子重新应用，使模型能够根据输入复杂性动态调整推理过程。支持两种测试时扩展模式：提升广度策略（如Best-of-N）的输出质量，以及增强深度策略（如自反思）的单个推理链的正确性。

研究结果: 在GSM8K、MATH500和GPQA等数据集上的实验表明，分数推理在多样化推理任务和模型中均能显著提升性能。

研究结论: 分数推理通过动态调整推理强度，为大语言模型的测试时计算提供了灵活且高效的解决方案，显著提升了推理任务的准确性和适应性。

中文摘要: 测试时计算已成为提升大语言模型（LLM）性能的强大范式，通过生成多个输出或优化单个推理链可以显著提高答案准确性。然而，现有方法（如Best-of-N、多数投票和自反思）通常对所有输入采用统一的推理方式，忽略了不同问题可能需要不同推理深度的问题。本文提出分数推理，一种无需训练且与模型无关的框架，能够在推理时实现对推理强度的连续控制，突破了固定指令提示的局限性。该方法通过提取与深度推理相关的潜在导向向量，并利用可调缩放因子重新应用，使模型能够根据每个输入的复杂性调整推理过程。这支持两种测试时扩展模式：（1）提升广度策略（如Best-of-N）的输出质量；（2）增强深度策略（如自反思）的单个推理链的正确性。在GSM8K、MATH500和GPQA上的实验表明，分数推理在多样化推理任务和模型中均能显著提升性能。

</details>


### [279] [KG-FGNN: Knowledge-guided GNN Foundation Model for Fertilisation-oriented Soil GHG Flux Prediction](https://arxiv.org/abs/2506.15896)
**中文标题：KG-FGNN：用于施肥导向土壤温室气体通量预测的知识引导图神经网络基础模型**

*Yu Zhang,Gaoshan Bi,Simon Jeffery,Max Davis,Yang Li,Qing Xue,Po Yang*

主要分类: cs.LG

摘要简述: 本文提出了一种知识引导的图神经网络框架（KG-FGNN），用于精准预测施肥导向的土壤温室气体（GHG）通量。通过结合农业过程模型的知识和图神经网络技术，解决了农业数据稀缺问题，显著提升了预测准确性和稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 精准预测土壤温室气体通量对评估环境影响、制定减排策略和促进可持续农业至关重要。然而，由于大多数农场缺乏先进的传感器和网络技术，农业数据稀缺严重阻碍了机器学习方法的应用。因此，本研究旨在解决这一问题。

研究方法: 研究提出了一种知识引导的图神经网络框架，利用农业过程模型模拟生成多维农业数据集，并通过自编码器和多目标多图图神经网络提取关键特征并整合特征相关性，以精准预测施肥导向的土壤温室气体通量。

研究结果: 实验结果表明，该方法在农业模拟数据集和真实农业数据集上均优于现有基线方法和先进的回归方法，表现出更高的准确性和稳定性。

研究结论: KG-FGNN框架通过整合农业过程模型的知识和图神经网络技术，有效解决了农业数据稀缺问题，为精准预测土壤温室气体通量提供了可靠的工具，对可持续农业具有重要意义。

中文摘要: 精准预测土壤温室气体（GHG）通量对农业系统评估环境影响、制定减排策略和促进可持续农业至关重要。由于大多数农场缺乏先进的传感器和网络技术，获取全面多样的农业数据存在挑战，导致农业数据稀缺严重阻碍了机器学习方法在精准土壤GHG通量预测中的应用。本研究提出了一种知识引导的图神经网络框架，通过整合农业过程模型中的知识和图神经网络技术，解决了上述挑战。具体而言，我们利用农业过程模型模拟并生成了涵盖47个国家多种农业变量的多维农业数据集。为了提取关键农业特征并在预测过程中整合特征相关性，我们提出了一种结合自编码器和多目标多图图神经网络的机器学习框架。该框架利用自编码器从农业过程模型模拟数据中选择性提取重要农业特征，并利用图神经网络整合特征相关性，以精准预测施肥导向的土壤GHG通量。通过农业模拟数据集和真实农业数据集的综合实验，与知名基线方法和先进回归方法进行比较，结果表明我们提出的方法在施肥导向土壤GHG预测中具有更高的准确性和稳定性。

</details>


### [280] [Early Attentive Sparsification Accelerates Neural Speech Transcription](https://arxiv.org/abs/2506.15912)
**中文标题：早期注意力稀疏化加速神经语音转录**

*Zifei Xu,Sayeh Sharify,Hesham Mostafa,Tristan Webb,Wanzin Yazar,Xin Wang*

主要分类: cs.LG

摘要简述: 通过早期注意力稀疏化加速神经语音转录，研究发现稀疏化隐藏状态至40-60%可在早期编码阶段实现1.6倍运行加速，且准确率下降低于1%。


<details>
  <summary>详细信息</summary>
研究动机: 语音音频信号具有高度可压缩性，研究旨在利用Transformer音频编码器中自注意力机制的可解释性，通过早期时间域信号稀疏化加速神经语音转录。

研究方法: 采用Whisper系列模型，系统搜索稀疏化阶段（特定编码层）和压缩比（稀疏度）的联合空间，寻找最佳稀疏化方案。

研究结果: 在准确率下降低于1%的条件下，最佳方案选择在早期编码阶段将隐藏状态稀疏化至40-60%，实现英语语音转录任务中1.6倍的运行加速。

研究结论: 早期注意力稀疏化是一种有效的加速神经语音转录的方法，可在保持高准确率的同时显著提升运行效率。

中文摘要: 基于Transformer的神经语音处理已达到最先进性能。由于语音音频信号具有高度可压缩性，本研究旨在通过神经编码阶段的早期时间域信号稀疏化加速神经语音转录，利用Transformer音频编码器中自注意力机制的可解释性。使用Whisper系列模型，我们系统搜索了稀疏化阶段（特定编码层）和压缩比（稀疏度）的联合空间。研究发现，在准确率下降低于1%的条件下，最佳方案选择在早期编码阶段将隐藏状态稀疏化至40-60%，从而在Nvidia GPU上的英语语音转录任务中实现高达1.6倍的运行加速，且无需任何微调。

</details>


### [281] [PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning](https://arxiv.org/abs/2506.15923)
**中文标题：PNCS：基于幂范数余弦相似度的联邦学习多样化客户端选择**

*Liangyan Li,Yangyi Liu,Yimo Ning,Stefano Rini,Jun Chen*

主要分类: cs.LG

摘要简述: 本文提出了一种基于幂范数余弦相似度（PNCS）的联邦学习框架，通过捕捉高阶梯度矩解决非独立同分布数据问题，并引入历史队列算法提升客户端选择的多样性，实验表明其性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习（FL）在保护数据隐私的同时利用多源数据，但现有方法未充分考虑客户端间的梯度相关性，尤其在数据异构场景下表现不佳。本文旨在通过改进客户端选择机制提升模型性能。

研究方法: 提出幂范数余弦相似度（PNCS）方法，捕捉高阶梯度矩以应对非独立同分布数据；设计历史队列算法确保客户端选择的多样性。

研究结果: 在VGG16模型上的实验表明，PNCS框架在多种数据划分下均优于现有方法，显著提升了收敛速度和准确率。

研究结论: PNCS框架通过优化客户端选择机制，有效解决了数据异构性问题，为联邦学习的实际应用提供了新思路。

中文摘要: 联邦学习（FL）作为一种强大的范式，能够在避免集中存储的同时利用多源数据保护隐私。然而，现有方法大多未考虑远程客户端间复杂的梯度相关性，这在数据异构场景下尤为突出。本文提出了一种基于幂范数余弦相似度（PNCS）的新型FL框架，通过捕捉高阶梯度矩解决非独立同分布数据问题，提升模型聚合的客户端选择效果。此外，引入了一种基于历史队列的简单算法以确保客户端选择的多样性。在VGG16模型上的实验表明，该方法在多种数据划分下均优于现有技术。

</details>


### [282] [Probing the Robustness of Large Language Models Safety to Latent Perturbations](https://arxiv.org/abs/2506.16078)
**中文标题：探究大型语言模型安全对齐对潜在扰动的鲁棒性**

*Tianle Gu,Kexin Huang,Zongqi Wang,Yixu Wang,Jie Li,Yuanqi Yao,Yang Yao,Yujiu Yang,Yan Teng,Yingchun Wang*

主要分类: cs.LG

摘要简述: 本文探讨了大型语言模型安全对齐的鲁棒性，发现现有对齐方法仅关注表面拒绝行为，而潜在微小扰动仍可能触发不安全响应。作者提出了一种探测方法（ASA）和对抗训练策略（LAPT），以增强对齐鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管安全对齐在构建可靠通用人工智能中至关重要，但现有方法仅关注表面行为，未能彻底改变内部表征。因此，微小潜在扰动仍可能引发不安全响应。本文旨在探索对齐鲁棒性并提出改进方法。

研究方法: 作者提出了一种探测方法，通过测量模型原始响应的负对数似然来量化潜在空间的局部敏感性（ASA）。基于此，设计了层间对抗补丁训练（LAPT），在训练中向隐藏表征注入受控扰动。

研究结果: 实验表明，LAPT能显著增强对齐鲁棒性，且不影响模型的通用能力。ASA方法揭示了当前对齐范式的根本缺陷。

研究结论: 当前对齐方法存在浅层缺陷，需转向表征级训练策略。LAPT为改进对齐鲁棒性提供了理论基础和实践方法。

中文摘要: 安全对齐是构建可靠通用人工智能的关键需求。尽管对齐技术取得显著进展，但我们发现微小潜在偏移仍可触发对齐模型的不安全响应。我们认为这源于现有对齐方法的浅层性，其仅关注表面拒绝行为而未充分改变内部表征。因此，隐藏激活的微小变化可能重新触发潜在空间中的有害行为。为探究安全对齐对潜在扰动的鲁棒性，我们引入了一种探测方法，通过测量模型原始响应的负对数似然来量化潜在空间的局部敏感性，作为识别脆弱方向的诊断工具。基于此信号，我们构建了有效的越狱轨迹，提出了激活导向攻击（ASA）。更重要的是，这些见解为提升对齐鲁棒性提供了理论基础。为此，我们引入了层间对抗补丁训练（LAPT），一种在训练中向隐藏表征注入受控扰动的微调策略。实验结果表明，LAPT能增强对齐鲁棒性且不影响通用能力。我们的发现揭示了当前对齐范式的根本缺陷，呼吁采用超越表面行为监督的表征级训练策略。代码与结果详见https://github.com/Caril-gutianle/LatentSafety。

</details>


### [283] [AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction](https://arxiv.org/abs/2506.16001)
**中文标题：AutoHFormer：用于时间序列预测的高效层次自回归Transformer**

*Qianru Zhang,Honggang Wen,Ming Li,Dong Huang,Siu-Ming Yiu,Christian S. Jensen,Pietro Liò*

主要分类: cs.LG

摘要简述: AutoHFormer是一种高效的层次自回归Transformer，用于时间序列预测，通过分层建模、动态窗口注意力和自适应时间编码，实现了高效计算和精确预测。


<details>
  <summary>详细信息</summary>
研究动机: 时间序列预测需要同时满足严格的时间因果性、次二次复杂度和多尺度模式识别。现有方法难以兼顾这些目标，因此提出了AutoHFormer来解决这些问题。

研究方法: 1) 分层时间建模：将预测分解为并行处理的段级块，再进行段内顺序细化。2) 动态窗口注意力：采用可学习的因果窗口和指数衰减，降低复杂度并保持时间关系。3) 自适应时间编码：结合固定振荡模式和可学习衰减率，捕捉多尺度时间模式。

研究结果: 实验表明，AutoHFormer在PEMS08数据集上比PatchTST快10.76倍，内存减少6.06倍，同时在96-720步预测范围内保持准确性。

研究结论: AutoHFormer为高效且精确的时间序列建模设定了新基准，其创新设计在速度和性能上均表现出色。

中文摘要: 时间序列预测需要同时满足三个竞争目标：(1) 严格的时间因果性以确保可靠预测，(2) 次二次复杂度以实现实际可扩展性，(3) 多尺度模式识别以实现准确的长时预测。我们提出了AutoHFormer，一种层次自回归Transformer，通过三项关键创新解决这些挑战：1) 分层时间建模：将预测分解为并行处理的段级块，再进行段内顺序细化。这种双尺度方法在保持时间一致性的同时实现高效计算。2) 动态窗口注意力：注意力机制采用可学习的因果窗口和指数衰减，降低复杂度并保持精确的时间关系。该设计避免了标准Transformer的反因果问题和RNN混合模型的顺序瓶颈。3) 自适应时间编码：采用新颖的位置编码系统，结合固定振荡模式和可学习衰减率，捕捉多尺度时间模式。综合实验表明，在PEMS08数据集上，AutoHFormer比PatchTST快10.76倍，内存减少6.06倍，同时在大多数情况下在96-720步预测范围内保持准确性。这些突破为高效且精确的时间序列建模设定了新基准。我们的方法和所有基线在层次自回归机制中的实现可在https://github.com/lizzyhku/Autotime获取。

</details>


### [284] [VRAIL: Vectorized Reward-based Attribution for Interpretable Learning](https://arxiv.org/abs/2506.16014)
**中文标题：VRAIL：基于向量化奖励归因的可解释学习框架**

*Jina Kim,Youjin Jang,Jeongjin Han*

主要分类: cs.LG

摘要简述: 本文提出VRAIL框架，通过向量化奖励归因实现可解释学习，提升强化学习的稳定性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有强化学习方法在可解释性和训练稳定性方面存在不足，VRAIL旨在通过双阶段框架解决这些问题。

研究方法: VRAIL分为深度学习阶段和强化学习阶段：前者拟合状态特征的价值函数，后者通过奖励转换优化学习过程，支持线性和二次模型。

研究结果: 在Taxi-v3环境中，VRAIL比标准DQN更稳定且收敛更快，同时揭示了语义明确的子目标（如乘客状态）。

研究结论: VRAIL是一种通用且模型无关的奖励塑造框架，显著提升学习效果和可解释性。

中文摘要: 我们提出VRAIL（基于向量化奖励归因的可解释学习框架），这是一种基于价值的强化学习（RL）的双层框架，能够从状态特征中学习可解释的权重表示。VRAIL包含两个阶段：深度学习（DL）阶段通过状态特征拟合估计价值函数，强化学习阶段利用该函数通过基于奖励的转换优化学习。估计器采用线性或二次形式建模，可归因于单个特征及其交互作用。在Taxi-v3环境中的实验结果表明，VRAIL相比标准DQN提高了训练稳定性和收敛速度，且无需修改环境。进一步分析显示，VRAIL能揭示语义明确的子目标（如乘客状态），突显其生成人类可解释行为的能力。我们的研究表明，VRAIL是一种通用的、模型无关的奖励塑造框架，可同时提升学习和可解释性。

</details>


### [285] [Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal Document Understanding](https://arxiv.org/abs/2506.16035)
**中文标题：视觉引导分块即所需：通过多模态文档理解增强RAG**

*Vishesh Tripathi,Tanmay Odapally,Indraneel Das,Uday Allu,Biddwan Ahmed*

主要分类: cs.LG

摘要简述: 本文提出了一种基于视觉引导的多模态文档分块方法，利用大型多模态模型（LMMs）处理PDF文档，解决了传统文本分块方法在复杂文档结构、跨页表格和嵌入式图表上的局限性，显著提升了检索增强生成（RAG）系统的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的文本分块方法在处理复杂文档结构（如多页表格、嵌入式图表和跨页上下文依赖）时表现不佳，影响了检索增强生成（RAG）系统的效果。本文旨在通过多模态文档分块方法解决这一问题。

研究方法: 本文提出了一种基于大型多模态模型（LMMs）的文档分块方法，通过配置页面批次处理文档，并保留跨批次上下文，从而准确处理跨页表格、嵌入式视觉元素和流程性内容。

研究结果: 实验表明，该方法在分块质量和下游RAG性能上均优于传统方法，定性分析显示其能更好地保持文档结构和语义连贯性。

研究结论: 基于视觉引导的多模态文档分块方法显著提升了RAG系统的准确性和文档处理能力，为复杂文档的自动化处理提供了有效解决方案。

中文摘要: 检索增强生成（RAG）系统在信息检索和问答领域取得了革命性进展，但传统的基于文本的分块方法在处理复杂文档结构、多页表格、嵌入式图表以及跨页上下文依赖时表现不佳。本文提出了一种新颖的多模态文档分块方法，利用大型多模态模型（LMMs）批量处理PDF文档，同时保持语义连贯性和结构完整性。我们的方法通过配置页面批次处理文档，并保留跨批次上下文，从而能够准确处理跨页表格、嵌入式视觉元素和流程性内容。我们在一个精心策划的PDF文档数据集上评估了该方法，结果表明其在分块质量和下游RAG性能上均有所提升。与传统的RAG系统相比，我们的视觉引导方法在准确性上表现更优，定性分析显示其能更好地保持文档结构和语义连贯性。

</details>


### [286] [Latent Concept Disentanglement in Transformer-based Language Models](https://arxiv.org/abs/2506.16975)
**中文标题：基于Transformer的语言模型中潜在概念的解耦**

*Guan Zhe Hong,Bhavya Vasudeva,Vatsal Sharan,Cyrus Rashtchian,Prabhakar Raghavan,Rina Panigrahy*

主要分类: cs.LG

摘要简述: 研究发现，基于Transformer的大语言模型（LLM）在上下文学习（ICL）中能够识别并解耦潜在概念，支持逐步推理和低维表示。


<details>
  <summary>详细信息</summary>
研究动机: 探讨Transformer模型在上下文学习中是否真正解耦潜在概念，而非仅通过捷径解决问题，填补了现有研究在潜在概念与学习表示关系上的空白。

研究方法: 通过设计2跳推理任务（含离散潜在概念）和连续潜在概念任务，分析模型如何解耦和使用潜在概念，并探索表示空间的几何特性。

研究结果: 模型成功识别离散潜在概念并逐步推理；在连续潜在概念任务中，表示空间呈现低维子空间，几何结构与潜在参数化一致。

研究结论: 研究深化了对ICL和Transformer表示的理解，证实模型中存在高度局部化结构，能够解耦潜在概念。

中文摘要: 当大型语言模型（LLM）通过上下文学习（ICL）解决新任务时，它们似乎不仅理解任务目标，还能捕捉示例中的核心潜在概念。这引发了一个问题：Transformer是否在其计算中表示潜在结构，还是仅通过捷径解决问题？此前关于ICL的机制研究未充分探讨学习表示与潜在概念的关系，且问题设置多为单步推理。本文研究了Transformer如何解耦和使用潜在概念。在包含离散潜在概念的2跳推理任务中，模型成功识别潜在概念并逐步组合；在连续潜在概念任务中，表示空间存在低维子空间，其几何结构与潜在参数化一致。这些结果深化了对ICL和Transformer表示的理解，并为模型中解耦潜在概念的高度局部化结构提供了证据。

</details>


### [287] [From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers](https://arxiv.org/abs/2506.17052)
**中文标题：从概念到组件：Transformer中概念无关的注意力模块发现**

*Jingtong Su,Julia Kempe,Karen Ullrich*

主要分类: cs.LG

摘要简述: 本文提出了一种概念无关的方法SAMD，用于将任意复杂概念映射到Transformer的特定注意力头，并通过SAMI调整概念效果。实验表明，该方法在语言和视觉任务中均有效。


<details>
  <summary>详细信息</summary>
研究动机: 当前Transformer的归因研究主要关注简单的概念（如事实关联），忽略了注意力机制的影响，且缺乏统一方法分析复杂概念。本文旨在填补这些空白。

研究方法: 提出SAMD方法，将概念表示为向量，计算其与各注意力头的余弦相似度，选择TopK头构建概念关联模块；进一步提出SAMI，通过标量参数调整模块效果。

研究结果: 实验证明SAMD能稳定定位复杂概念的模块，且模块位置在模型训练前后一致。SAMI可显著提升任务性能（如GSM8K推理+1.6%）或削弱安全性（如HarmBench越狱+72.7%）。

研究结论: SAMD和SAMI为Transformer的注意力机制提供了通用分析工具，适用于语言和视觉任务，增强了模型的可解释性和控制性。

中文摘要: Transformer在语言和视觉任务中取得了最先进的性能，这推动了对内部机制的解释需求，以提升性能和改进行为控制。归因方法通过将目标概念相关的模型输出分配到特定组件来促进可解释性。当前研究主要关注多层感知神经元和简单概念（如“巴黎位于法国”），忽略了注意力机制的影响，且缺乏分析复杂概念的统一方法。为填补这些空白，我们提出了可扩展注意力模块发现（SAMD），这是一种概念无关的方法，用于将任意复杂概念映射到通用Transformer模型的特定注意力头。具体实现是将每个概念表示为向量，计算其与各注意力头的余弦相似度，并选择TopK得分头构建概念关联模块。我们还提出了标量注意力模块干预（SAMI），通过单一标量参数调整模块效果以削弱或增强概念影响。实验表明，SAMD能稳定定位不同复杂度概念的模块，并可视化其位置。结果显示模块位置在LLM训练前后保持一致，验证了先前关于LLM多语言机制的研究。通过SAMI，我们削弱“安全性”在HarmBench上实现了越狱（+72.7%），并通过增强“推理”在GSM8K基准上提升了性能（+1.6%）。最后，我们通过抑制视觉Transformer在ImageNet上的分类准确率，展示了方法的领域无关性。

</details>


### [288] [CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations](https://arxiv.org/abs/2506.16056)
**中文标题：CRIA：一种跨视图交互与实例自适应的预训练框架，用于可泛化的EEG表征**

*Puchun Liu,C. L. Philip Chen,Yubin He,Tong Zhang*

主要分类: cs.LG

摘要简述: 本文提出CRIA框架，通过跨视图交互和实例自适应预训练，解决EEG数据特征提取和多视图信息融合的难题，显著提升表征的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有EEG预训练方法多依赖单一视图的上下文语义，难以捕捉多视角间的复杂协同作用，限制了表征的表达力和泛化性。

研究方法: CRIA采用变长变通道编码统一EEG数据表示，通过跨注意力机制融合时域、频域和空域特征，并结合基于信息瓶颈的注意力矩阵掩码策略和新型视图掩码预训练方案。

研究结果: 在Temple University EEG和CHB-MIT数据集上，CRIA在多类事件分类和异常检测任务中分别取得57.02%和80.03%的平衡准确率，优于现有方法。

研究结论: CRIA框架通过跨视图交互和自适应预训练，显著提升了EEG表征的泛化能力，为通用EEG表征学习提供了有效解决方案。

中文摘要: 从EEG数据中提取深层特征并有效整合多视图信息是开发通用预训练框架的重大挑战。现有方法多依赖单一视图的上下文语义，难以捕捉多视角间的复杂协同作用，限制了表征的表达力和泛化性。为此，本文提出CRIA框架，通过变长变通道编码实现不同数据集EEG数据的统一表示。研究中，跨视图信息定义为EEG信号的时域、频域和空域视图交互产生的整合表征。模型采用跨注意力机制融合多视图特征，并结合基于信息瓶颈的注意力矩阵掩码策略和新型视图掩码预训练方案。在Temple University EEG和CHB-MIT数据集上的实验表明，CRIA在相同预训练条件下优于现有方法，多类事件分类和异常检测的平衡准确率分别达到57.02%和80.03%，展现了强大的泛化能力。

</details>


### [289] [A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders](https://arxiv.org/abs/2506.16096)
**中文标题：一种用于诊断脑部疾病的大脑到群体图学习框架**

*Qianqian Liao,Wuque Cai,Hongze Sun,Dongze Liu,Duo Chen,Dezhong Yao,Daqing Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种两阶段的大脑到群体图学习框架（B2P-GL），用于诊断脑部疾病。该框架结合了大脑区域的语义相似性和基于条件的群体图建模，通过自适应节点重分配图注意力网络和群体图特征融合，显著提升了诊断准确性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于图的脑部疾病诊断方法过度依赖预定义的大脑图谱，忽略了图谱中的丰富信息以及站点和表型变异性的干扰。为了解决这些问题，本文提出了B2P-GL框架，旨在提升诊断的准确性和临床适用性。

研究方法: B2P-GL框架分为两个阶段：1）大脑表示学习阶段，利用GPT-4的知识丰富图谱表示，并通过自适应节点重分配图注意力网络优化大脑图；2）群体疾病诊断阶段，将表型数据融入群体图构建和特征融合，以减少干扰并提升诊断性能。

研究结果: 在ABIDE I、ADHD-200和Rest-meta-MDD数据集上的实验表明，B2P-GL在预测准确性上优于现有方法，同时增强了可解释性。

研究结论: B2P-GL框架为脑部疾病诊断提供了一种可靠且个性化的方法，推动了临床应用的进展。

中文摘要: 近年来，基于图的脑功能连接诊断方法高度依赖预定义的大脑图谱，但忽略了图谱中嵌入的丰富信息以及站点和表型变异性的干扰。为解决这些问题，我们提出了一种两阶段的大脑到群体图学习（B2P-GL）框架，该框架结合了大脑区域的语义相似性和基于条件的群体图建模。在第一阶段（大脑表示学习），我们利用GPT-4的知识丰富图谱表示，并通过自适应节点重分配图注意力网络优化大脑图。在第二阶段（群体疾病诊断），将表型数据融入群体图构建和特征融合，以减少干扰并提升诊断性能。在ABIDE I、ADHD-200和Rest-meta-MDD数据集上的实验表明，B2P-GL在预测准确性上优于现有方法，同时增强了可解释性。总体而言，我们提出的框架为脑部疾病诊断提供了一种可靠且个性化的方法，推动了临床应用的进展。

</details>


### [290] [From Teacher to Student: Tracking Memorization Through Model Distillation](https://arxiv.org/abs/2506.16170)
**中文标题：从教师到学生：通过模型蒸馏追踪记忆行为**

*Simardeep Singh*

主要分类: cs.LG

摘要简述: 研究表明，通过知识蒸馏将大型教师模型压缩为小型学生模型，不仅能降低计算成本和模型大小，还能显著减少数据记忆风险。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）会记忆部分训练数据，引发隐私和安全问题。以往研究主要关注预训练模型的记忆问题，而对知识蒸馏（KD）如何影响记忆知之甚少。本研究旨在探索不同KD方法对任务数据记忆的影响。

研究方法: 研究通过将大型教师模型（经过任务数据微调）蒸馏为小型学生模型，比较不同KD方法对数据记忆的影响。

研究结果: 研究发现，蒸馏方法不仅能降低计算成本和模型大小，还能显著减少数据记忆风险，优于标准微调方法。

研究结论: 知识蒸馏是减少模型记忆风险的有效方法，同时兼顾计算效率和模型压缩。

中文摘要: 大型语言模型（LLMs）已知会记忆部分训练数据，引发隐私和安全问题。以往研究主要关注预训练模型的记忆问题，而对知识蒸馏（KD）如何影响记忆知之甚少。本研究探讨了不同KD方法对任务数据记忆的影响，尤其是将大型教师模型蒸馏为小型学生模型时的情况。研究表明，蒸馏方法不仅能降低计算成本和模型大小，还能显著减少数据记忆风险，优于标准微调方法。

</details>


### [291] [Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping](https://arxiv.org/abs/2506.16243)
**中文标题：基于条件WGAN与权重剪裁的合成ALS-EEG数据增强用于ALS诊断**

*Abdulvahap Mutlu,Şengül Doğan,Türker Tuncer*

主要分类: cs.LG

摘要简述: 本文提出了一种基于条件Wasserstein生成对抗网络（CWGAN）的方法，用于生成合成ALS患者的脑电图（EEG）信号，以解决数据稀缺和类别不平衡问题，从而提高ALS诊断的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 肌萎缩侧索硬化症（ALS）是一种罕见的神经退行性疾病，其患者的EEG数据稀缺且类别不平衡，这给训练可靠的机器学习分类器带来了挑战。本文旨在通过生成合成EEG信号来缓解这些问题。

研究方法: 使用条件Wasserstein生成对抗网络（CWGAN）生成合成ALS患者的EEG信号。首先对EEG数据进行预处理和归一化，然后训练CWGAN模型以学习ALS EEG信号的分布并生成逼真的合成样本。详细描述了CWGAN的架构和训练过程，并选择了关键超参数以确保训练稳定性。

研究结果: 生成的合成EEG信号在视觉上接近真实的ALS EEG模式，且CWGAN的训练损失曲线稳定，表明模型成功学习。这些合成信号可用于增强分类器的训练数据，缓解类别不平衡问题并提高ALS检测的准确性。

研究结论: 通过CWGAN生成的合成EEG信号能够有效缓解数据稀缺和类别不平衡问题，为ALS诊断模型的训练提供了新的数据增强方法，并有望促进数据共享和诊断模型的改进。

中文摘要: 肌萎缩侧索硬化症（ALS）是一种罕见的神经退行性疾病，且ALS患者的高质量脑电图（EEG）数据稀缺。这种数据稀缺性，加上ALS与健康对照组记录的严重类别不平衡，对训练可靠的机器学习分类器提出了挑战。本研究通过使用条件Wasserstein生成对抗网络（CWGAN）生成ALS患者的合成EEG信号来解决这些问题。我们在一个私有的EEG数据集（ALS与非ALS）上训练CWGAN，以学习ALS EEG信号的分布并生成逼真的合成样本。我们对EEG记录进行预处理和归一化，并训练CWGAN模型以生成合成ALS信号。详细描述了CWGAN的架构和训练流程，并选择了关键超参数以确保训练稳定性。对生成信号的定性评估表明，它们与真实的ALS EEG模式非常相似。CWGAN的训练收敛，生成器和判别器的损失曲线稳定，表明学习成功。合成的EEG信号看起来逼真，并有可能用作增强数据以训练分类器，帮助缓解类别不平衡并提高ALS检测的准确性。我们讨论了这种方法如何促进数据共享并增强诊断模型。

</details>


### [292] [Global Context-aware Representation Learning for Spatially Resolved Transcriptomics](https://arxiv.org/abs/2506.15698)
**中文标题：全局上下文感知的空间转录组学表征学习**

*Yunhak Oh,Junseok Lee,Yeongmin Kim,Sangwoo Seo,Namkyeong Lee,Chanyoung Park*

主要分类: cs.LG

摘要简述: 本文提出Spotscape框架，通过引入相似性望远镜模块和相似性缩放策略，解决了空间转录组学中边界点表示不足的问题，并在单切片和多切片任务中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于图的方法在空间转录组学中难以有效表示边界点，因为它们过度依赖相邻点，而忽略了全局关系。本文旨在通过捕捉全局关系和多切片整合，提升空间域识别的准确性。

研究方法: 提出Spotscape框架，包含相似性望远镜模块以捕捉全局关系，并提出相似性缩放策略以调节切片内和切片间点的距离，实现有效的多切片整合。

研究结果: 实验表明，Spotscape在单切片和多切片任务中均表现优异，显著提升了空间域识别的准确性。

研究结论: Spotscape通过全局关系捕捉和多切片整合，解决了空间转录组学中的边界点表示问题，为复杂生物网络研究提供了新工具。

中文摘要: 空间转录组学（SRT）是一种前沿技术，能够捕捉组织中细胞的空间背景，从而研究复杂的生物网络。现有的基于图的方法虽然利用了基因表达和空间信息来识别相关空间域，但在获取有意义的点表示方面存在不足，尤其是对于空间域边界附近的点，因为它们过度依赖与锚点特征差异极小的相邻点。为解决这一问题，我们提出了Spotscape框架，引入相似性望远镜模块以捕捉多点之间的全局关系。此外，我们还提出了一种相似性缩放策略，用于调节切片内和切片间点的距离，从而实现有效的多切片整合。大量实验表明，Spotscape在单切片和多切片任务中均表现出色。代码可在以下链接获取：https://github.com/yunhak0/Spotscape。

</details>


### [293] [Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2506.15720)
**中文标题：三方权重空间集成用于少样本类增量学习**

*Juntae Lee,Munawar Hayat,Sungrack Yun*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Tri-WE的新方法，用于解决少样本类增量学习（FSCIL）中的灾难性遗忘和过拟合问题。通过权重空间的三方集成和知识蒸馏正则化，实现了对新类的有效适应，并在多个数据集上取得了最优结果。


<details>
  <summary>详细信息</summary>
研究动机: 在少样本类增量学习中，固定特征提取器限制了模型对新类的适应性，导致灾难性遗忘和过拟合问题。本文旨在通过动态更新整个模型，提升模型对新类的学习能力。

研究方法: 提出Tri-WE方法，通过权重空间的三方集成（基础模型、前一个模型和当前模型）来协同维护知识。此外，引入基于知识蒸馏的正则化损失项，通过数据增强提升知识蒸馏效果。

研究结果: 在miniImageNet、CUB200和CIFAR100数据集上取得了最先进的性能，有效缓解了灾难性遗忘和过拟合问题。

研究结论: Tri-WE方法通过动态权重集成和知识蒸馏，显著提升了少样本类增量学习的性能，为未来研究提供了新的思路。

中文摘要: 少样本类增量学习（FSCIL）能够通过少量训练样本持续学习新概念。在FSCIL中，模型会经历大量更新，容易遗忘先前概念并对有限的新样本过拟合。最近的趋势通常是将模型的特征提取与分类头解耦，先在基础类（大量样本和类别）上学习泛化特征提取器，然后在增量学习中固定。我们认为固定特征提取器限制了模型对新类的适应性，因此提出了一种新的FSCIL方法，有效解决了灾难性遗忘和过拟合问题。该方法能够通过少量样本无缝更新整个模型。我们主要提出了三方权重空间集成（Tri-WE），在权重空间中插值基础模型、前一个模型和当前模型，尤其是分类头部分，从而协同维护基础模型和前一个模型的知识。此外，我们认识到从稀缺数据中蒸馏出泛化表示的挑战，因此提出了一种基于知识蒸馏的正则化损失项。通过简单混合少样本数据，可以生成更丰富的数据，从而从先前模型中蒸馏出关键知识。最终，我们在miniImageNet、CUB200和CIFAR100数据集上取得了最先进的结果。

</details>


### [294] [Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective](https://arxiv.org/abs/2506.16288)
**中文标题：下一个token预测应具有模糊敏感性：元学习视角**

*Leo Gagnon,Eric Elmoznino,Sarthak Mittal,Tom Marty,Tejas Kasetty,Dhanya Sridhar,Guillaume Lajoie*

主要分类: cs.LG

摘要简述: 本文探讨自回归基础模型在预测下一个token时应如何应对高模糊性，提出模糊性敏感的预测方法，并通过MetaHMM基准测试验证其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 自回归基础模型的快速适应能力通常归因于其预训练数据的多样性，但在高模糊性情况下，贝叶斯最优预测计算复杂度高。认知科学认为此时启发式或信息搜索策略更优，本文旨在验证模糊性敏感的预测方法是否优于模糊性无关的方法。

研究方法: 提出MetaHMM合成序列元学习基准，利用其丰富的组合结构和可处理的贝叶斯预言机，测试Transformer在高模糊性预测中的表现。基于认知理论，将预训练模型转化为蒙特卡洛预测器，分离任务推理与token预测。

研究结果: 实验表明，Transformer在不同模型规模下均难以处理高模糊性预测。提出的蒙特卡洛预测方法在模糊情境中表现显著提升，但仍存在挑战。

研究结论: 模糊性敏感的预测方法能有效提升模型在高模糊性情境中的表现，但需进一步优化以应对更复杂场景。

中文摘要: 自回归基础模型的快速适应能力通常归因于其预训练数据的多样性。从贝叶斯角度看，最小化预测误差需要整合所有与观察一致的潜在假设。尽管这种行为在理论上是理想的，但在实践中往往过于雄心勃勃：在高模糊性下，潜在假设的数量使得贝叶斯最优预测计算上不可行。认知科学早已认识到这一限制，认为在此类条件下，启发式或信息搜索策略优于穷举推理。将这一见解应用于下一个token预测，我们假设低模糊性和高模糊性预测具有不同的计算需求，模糊性无关的预测方法可能成为一种有害的归纳偏差。为验证这一点，我们引入了MetaHMM，一个具有丰富组合结构和可处理贝叶斯预言机的合成序列元学习基准。实验表明，Transformer在不同模型规模下均难以处理高模糊性预测。基于认知理论，我们提出一种方法，将预训练模型转化为蒙特卡洛预测器，分离任务推理与token预测。初步结果显示，通过改进容量分配和测试时可扩展推理，模型在模糊情境中表现显著提升，但仍存在挑战。

</details>


### [295] [Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks](https://arxiv.org/abs/2506.16313)
**中文标题：通过增强认知神经网络改进GFlowNets中的探索**

*Sajan Muhammad,Salem Lahlou*

主要分类: cs.LG

摘要简述: 本文提出了一种改进GFlowNets探索效率的方法，通过结合认知神经网络（ENN）增强联合预测和不确定性量化，从而更高效地识别最优轨迹。


<details>
  <summary>详细信息</summary>
研究动机: 在GFlowNets中，高效识别训练轨迹仍是一个未解决的问题。关键在于优先探索状态空间中奖励分布未被充分学习的区域，这需要基于不确定性的探索策略。

研究方法: 研究将认知神经网络（ENN）与传统GFlowNets架构结合，提出ENN-GFN-Enhanced算法，以提升联合预测能力和不确定性量化，从而优化探索效率。

研究结果: 在网格环境和结构化序列生成任务中，ENN-GFN-Enhanced相比基线方法表现出更高的效能和效率。

研究结论: 通过整合ENN与GFlowNets，本研究显著提升了探索效率和最优轨迹的识别能力，为复杂决策问题提供了新思路。

中文摘要: 在GFlowNets中，高效识别训练轨迹仍是一个未解决的问题。为此，需要优先探索状态空间中奖励分布未被充分学习的区域，这要求基于不确定性的探索策略，即代理需了解其未知之处。这一属性可通过联合预测来衡量，尤其对组合和序列决策问题至关重要。本研究将认知神经网络（ENN）与传统GFlowNets架构结合，以实现更高效的联合预测和更好的不确定性量化，从而改进探索和最优轨迹的识别。我们提出的ENN-GFN-Enhanced算法在网格环境和结构化序列生成任务中与基线方法进行了比较，验证了其效能和效率。

</details>


### [296] [Watermarking Autoregressive Image Generation](https://arxiv.org/abs/2506.16349)
**中文标题：自回归图像生成的水印技术**

*Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez*

主要分类: cs.LG

摘要简述: 本文首次提出了一种针对自回归图像生成模型的令牌级水印方法，通过改进语言模型水印技术，解决了反向循环一致性缺失问题，并增强了水印的鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 自回归图像生成模型因其潜在滥用风险而备受关注，但目前缺乏对其输出的令牌级水印技术。本文旨在填补这一空白，提供一种可靠的水印方法以追踪生成图像的来源。

研究方法: 方法包括：（1）通过定制化的分词器-去分词器微调程序提升反向循环一致性；（2）引入水印同步层以增强对常见图像变换、神经压缩和移除攻击的鲁棒性。

研究结果: 实验表明，该方法能够实现可靠且鲁棒的水印检测，并提供理论支持的p值。

研究结论: 本文提出的方法首次实现了自回归图像生成模型的令牌级水印，解决了反向循环一致性问题，并在多种攻击下保持了水印的稳定性。

中文摘要: 生成模型输出的水印技术已成为追踪其来源的一种有前景的方法。尽管自回归图像生成模型及其潜在滥用风险备受关注，但此前尚无研究尝试在其输出的令牌级别添加水印。本文首次通过将语言模型水印技术适配到该场景，填补了这一空白。我们识别出一个关键挑战：反向循环一致性（RCC）的缺失，即重新分词生成的图像令牌会显著改变令牌序列，从而擦除水印。为解决这一问题并使方法对常见图像变换、神经压缩和移除攻击具有鲁棒性，我们引入了（i）一种定制化的分词器-去分词器微调程序以提升RCC；（ii）一种互补的水印同步层。实验表明，我们的方法能够实现可靠且鲁棒的水印检测，并提供理论支持的p值。

</details>


### [297] [Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights](https://arxiv.org/abs/2506.16406)
**中文标题：拖放式LLMs：零样本提示到权重**

*Zhiyuan Liang,Dongwen Tang,Yuhao Zhou,Xuanlei Zhao,Mingjia Shi,Wangbo Zhao,Zekai Li,Peihao Wang,Konstantin Schürholt,Damian Borth,Michael M. Bronstein,Yang You,Zhangyang Wang,Kai Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“拖放式LLMs（DnD）”的方法，通过提示条件参数生成器，无需针对每个下游任务进行单独训练，即可快速生成任务特定的LoRA权重更新。该方法显著降低了计算开销，并在多个任务上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有的参数高效微调方法（如LoRA）虽然降低了定制大型语言模型的成本，但仍需为每个下游任务进行单独优化。本文旨在消除这种任务特定的训练需求，实现快速模型定制。

研究方法: DnD通过轻量级文本编码器将提示批次转换为条件嵌入，再通过级联超卷积解码器生成完整的LoRA矩阵。该方法在多样化的提示-检查点对上进行训练，能够快速生成任务特定的参数。

研究结果: DnD实现了比全微调低12,000倍的开销，在未见过的常识推理、数学、编程和多模态任务上平均性能提升30%，并展现出强大的跨领域泛化能力。

研究结论: 研究表明，基于提示的条件参数生成是梯度自适应的一种可行替代方案，能够快速定制LLMs。

中文摘要: 现代参数高效微调方法（如低秩适应LoRA）降低了定制大型语言模型（LLMs）的成本，但仍需为每个下游数据集进行单独优化。我们提出了“拖放式LLMs（DnD）”，这是一种提示条件参数生成器，通过将少量未标记的任务提示直接映射到LoRA权重更新，消除了任务特定的训练。轻量级文本编码器将提示批次蒸馏为条件嵌入，随后通过级联超卷积解码器转换为完整的LoRA矩阵集。在多样化的提示-检查点对上训练后，DnD可在几秒内生成任务特定的参数，实现：i) 比全微调低12,000倍的开销；ii) 在未见过的常识推理、数学、编程和多模态基准测试中，平均性能比最强的训练LoRA提升30%；iii) 尽管从未接触目标数据或标签，仍展现出强大的跨领域泛化能力。我们的结果表明，提示条件参数生成是快速定制LLMs的梯度自适应的可行替代方案。项目地址：https://jerryliang24.github.io/DnD。

</details>


### [298] [Optimizing MoE Routers: Design, Implementation, and Evaluation in Transformer Models](https://arxiv.org/abs/2506.16419)
**中文标题：优化MoE路由器：Transformer模型中的设计、实现与评估**

*Daniel Fidel Harvey,George Weale,Berk Yilmaz*

主要分类: cs.LG

摘要简述: 本文研究了混合专家（MoE）架构中的路由器设计，通过六种不同路由器变体（线性、注意力、MLP、混合、哈希和新提出的MLP-Hadamard）在BERT和Qwen1.5-MoE模型中的表现，分析了参数效率、推理延迟、路由熵和专家利用率。结果表明，线性路由器速度快，而MLP和注意力路由器更具表达能力，MLP-Hadamard则展示了结构化稀疏路由的独特能力。


<details>
  <summary>详细信息</summary>
研究动机: 混合专家（MoE）架构虽能提升大型语言模型的可扩展性，但其性能依赖于路由器模块，不良的路由会导致负载不平衡和准确性下降。本研究旨在通过设计和实现不同的路由器架构来解决这些问题。

研究方法: 在Transformer模型中设计并实现了六种路由器变体（线性、注意力、MLP、混合、哈希和MLP-Hadamard），并使用BERT和Qwen1.5-MoE模型进行实验，评估参数效率、推理延迟、路由熵和专家利用率。

研究结果: 实验表明，线性路由器速度快，MLP和注意力路由器更具表达能力，而MLP-Hadamard路由器在结构化稀疏路由方面表现独特。成功在复杂的量化Qwen1.5-MoE模型中替换并微调了自定义路由器。

研究结论: 本研究提供了MoE路由器设计的比较分析，并为优化其性能以实现高效、大规模模型部署提供了见解。

中文摘要: 混合专家（MoE）架构提高了大型语言模型的可扩展性，但其性能依赖于将令牌分配到专业专家的路由器模块。不良的路由会导致负载不平衡和准确性下降。本项目设计并实现了Transformer模型中的不同路由器架构以解决这些问题。我们实验了六种路由器变体：线性、注意力、多层感知机（MLP）、混合、哈希以及我们新提出的MLP-Hadamard。使用BERT和Qwen1.5-MoE模型对这些路由器进行了参数效率、推理延迟、路由熵和专家利用模式的评估。结果表明，线性路由器速度快，而MLP和注意力路由器更具表达能力。MLP-Hadamard路由器展示了结构化稀疏路由的独特能力。我们成功在复杂的量化Qwen1.5-MoE模型中替换并微调了自定义路由器。这项工作提供了MoE路由器设计的比较分析，并为优化其性能以实现高效、大规模模型部署提供了见解。

</details>


### [299] [Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks](https://arxiv.org/abs/2506.16443)
**中文标题：利用影响函数优化物理信息神经网络中的数据重采样**

*Jonas R. Naujoks,Aleksander Krasowski,Moritz Weckbecker,Galip Ümit Yolcu,Thomas Wiegand,Sebastian Lapuschkin,Wojciech Samek,René P. Klausen*

主要分类: cs.LG

摘要简述: 本文探讨了在物理信息神经网络（PINNs）中利用影响函数进行数据重采样的方法，以提高预测准确性。


<details>
  <summary>详细信息</summary>
研究动机: 物理信息神经网络（PINNs）在解决偏微分方程（PDEs）方面表现出色，但其训练数据的采样方式可能影响模型性能。影响函数作为一种可解释AI工具，可用于分析数据点对模型的影响，从而优化采样策略。

研究方法: 研究提出了一种基于影响函数的数据重采样方法，通过分析训练数据点对模型的影响，有针对性地选择对模型性能提升最有利的数据点进行重采样。

研究结果: 实验结果表明，基于影响函数的重采样方法能够有效提升PINNs的预测准确性，展示了可解释AI方法在PINN训练中的实际应用价值。

研究结论: 通过影响函数优化数据采样策略，可以显著提升PINNs的性能，为科学机器学习领域提供了一种新的数据优化方法。

中文摘要: 物理信息神经网络（PINNs）为解决偏微分方程（PDEs）提供了一种强大方法，广泛应用于科学领域的正反问题。PINNs的训练依赖于从PDE输入域采样的时空数据点。影响函数作为可解释AI（XAI）工具，能够近似单个训练点对模型的影响，提升模型的可解释性。本研究探讨了基于影响函数的数据采样方法在训练数据中的应用。结果表明，这种基于数据归因方法的有针对性重采样能够提升PINNs的预测准确性，展示了XAI方法在PINN训练中的实际应用价值。

</details>


### [300] [Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach](https://arxiv.org/abs/2506.16448)
**中文标题：消费者友好的基于脑电的情绪识别系统：一种多尺度卷积神经网络方法**

*Tri Duc Ly,Gia H. Ngo*

主要分类: cs.LG

摘要简述: 本文提出了一种基于多尺度卷积神经网络的消费者友好型脑电情绪识别系统，通过多比例系数特征提取核和新型脑区分区学习核，显著提升了情绪识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着干电极和消费级脑电设备的发展，脑电信号成为情绪识别的常用工具。本文旨在开发一种适用于真实场景的深度学习模型，以提升脑电情绪识别的准确性和实用性。

研究方法: 采用多尺度卷积神经网络，结合多比例系数的特征提取核和一种新型核，从大脑四个分区学习关键信息，优化情绪识别任务。

研究结果: 模型在预测效价、唤醒度和支配度等多个性能指标上，均优于当前最先进的TSception模型。

研究结论: 提出的多尺度卷积神经网络方法在脑电情绪识别任务中表现出色，为消费者友好型情绪识别系统的开发提供了有效解决方案。

中文摘要: 脑电是一种非侵入性、安全且低风险的脑内电生理信号记录方法。特别是随着干电极、消费级脑电设备以及机器学习的快速发展，脑电已成为自动情绪识别的常用资源。为了开发一种能够在真实场景中实现基于脑电的情绪识别的深度学习模型，我们提出了一种利用多尺度卷积神经网络完成此类任务的新方法。通过实现具有多种比例系数的特征提取核以及一种从大脑四个分区学习关键信息的新型核，我们的模型在预测效价、唤醒度和支配度等多个性能评估指标上，始终优于当前最先进的TSception模型。

</details>


### [301] [Joint Tensor-Train Parameterization for Efficient and Expressive Low-Rank Adaptation](https://arxiv.org/abs/2506.16456)
**中文标题：联合张量分解参数化：高效且表达性强的低秩适应方法**

*Jun Qi,Chen-Yu Liu,Sabato Marco Siniscalchi,Chao-Han Huck Yang,Min-Hsiu Hsieh*

主要分类: cs.LG

摘要简述: 本文提出了一种名为TensorGuide的新型低秩适应框架，通过联合张量分解生成相关低秩矩阵，显著提升了表达能力和泛化性能，同时保持参数高效性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的低秩适应（LoRA）方法独立优化低秩矩阵，限制了其表达能力和泛化性能。而经典的张量分解方法单独应用于LoRA矩阵时，未能显著提升参数效率或性能。因此，需要一种更高效且表达能力更强的低秩适应方法。

研究方法: 本文提出TensorGuide框架，通过统一的张量分解结构生成两个相关的低秩LoRA矩阵，利用受控高斯噪声驱动。这种联合张量表示提供了结构化的低秩适应，显著提升了表达能力和泛化性能，同时不增加可训练参数数量。

研究结果: 在量子点分类和GPT-2微调实验中，TensorGuide显著优于标准LoRA和TT-LoRA，实现了更高的准确性和可扩展性，且参数更少。理论分析表明，其优化动态和泛化性能更优。

研究结论: TensorGuide通过联合张量分解显著提升了低秩适应的表达能力和泛化性能，同时保持了参数高效性，为大规模神经模型的高效微调提供了新思路。

中文摘要: 低秩适应（LoRA）因其参数高效的大规模神经模型微调而广受认可。然而，标准LoRA独立优化低秩矩阵，这限制了其表达能力和泛化性能。虽然经典张量分解（TT）可单独应用于LoRA矩阵，但本文表明，这种经典TT方法既未显著提升参数效率，也未带来性能提升。为此，本文提出TensorGuide，一种新型张量分解引导的适应框架。TensorGuide通过受控高斯噪声驱动的统一TT结构生成两个相关的低秩LoRA矩阵。这种联合TT表示提供了结构化的低秩适应，显著提升了表达能力和泛化性能，同时不增加可训练参数数量。理论分析通过神经切线核证明了其优化动态和泛化性能的优越性。在量子点分类和GPT-2微调实验中，TensorGuide显著优于标准LoRA和TT-LoRA，以更少的参数实现了更高的准确性和可扩展性。

</details>


### [302] [Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities](https://arxiv.org/abs/2506.16471)
**中文标题：扩散模型的渐进推理时间退火用于从Boltzmann密度中采样**

*Tara Akhound-Sadegh,Jungyoon Lee,Avishek Joey Bose,Valentin De Bortoli,Arnaud Doucet,Michael M. Bronstein,Dominique Beaini,Siamak Ravanbakhsh,Kirill Neklyudov,Alexander Tong*

主要分类: cs.LG

摘要简述: 本文提出了一种名为渐进推理时间退火（PITA）的新框架，用于训练基于扩散的采样器，通过结合Boltzmann分布的退火和扩散平滑技术，首次实现了对N体粒子系统、Alanine二肽和三肽的平衡采样，显著降低了能量函数评估次数。


<details>
  <summary>详细信息</summary>
研究动机: 从非归一化概率密度中高效采样是一个核心挑战，尤其在科学应用中具有重要意义。现有的基于扩散的采样器无法处理简单分子系统的分布，因此需要一种新的方法来解决这一问题。

研究方法: PITA框架结合了两种互补的插值技术：Boltzmann分布的退火和扩散平滑。通过从高到低温度依次训练扩散模型，并利用温度退火目标密度的样本，PITA在推理时间通过Feynman-Kac偏微分方程和序贯蒙特卡洛方法实现采样。

研究结果: 实验表明，PITA首次实现了对N体粒子系统、Alanine二肽和三肽在笛卡尔坐标下的平衡采样，且能量函数评估次数大幅减少。

研究结论: PITA为基于扩散的采样器提供了一种高效的新方法，解决了现有技术无法处理复杂系统的问题，为科学应用中的采样任务提供了有力工具。

中文摘要: 从目标非归一化概率密度中高效采样仍是一个核心挑战，涉及众多高影响力的科学应用。一种有前景的方法是设计摊销采样器，借鉴生成扩散模型中的概率路径设计等关键思想。然而，现有的基于扩散的采样器仍无法从简单分子系统的分布中抽取样本。本文提出渐进推理时间退火（PITA），一种结合两种互补插值技术的新框架：I. Boltzmann分布的退火；II. 扩散平滑。PITA通过从高到低温度依次训练扩散模型，利用温度退火目标密度的样本，在推理时间通过Feynman-Kac偏微分方程和序贯蒙特卡洛方法实现采样。实验表明，PITA首次实现了对N体粒子系统、Alanine二肽和三肽在笛卡尔坐标下的平衡采样，且能量函数评估次数大幅减少。代码见：https://github.com/taraak/pita

</details>


### [303] [Subspace-Boosted Model Merging](https://arxiv.org/abs/2506.16506)
**中文标题：子空间增强的模型合并**

*Ronald Skorobogat,Karsten Roth,Mariana-Iuliana Georgescu,Zeynep Akata*

主要分类: cs.LG

摘要简述: 本文提出了一种名为“子空间增强”的方法，用于解决多专家模型合并中因任务向量空间秩崩溃导致的性能下降问题。通过奇异值分解和任务相似性量化，显著提升了合并效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着合并的专家模型数量增加，现有方法往往导致任务向量空间秩崩溃，从而降低合并效果。本文旨在分析这一现象并提出解决方案。

研究方法: 提出“子空间增强”方法，通过对奇异值分解后的任务向量空间进行操作以维持秩，并引入高阶广义奇异值分解量化任务相似性。

研究结果: 在视觉基准测试中，子空间增强方法显著提升了合并效果，对多达20个专家模型的合并性能提升超过10%。

研究结论: 子空间增强方法有效解决了多专家模型合并中的秩崩溃问题，并通过任务相似性量化为模型合并提供了新的可解释视角。

中文摘要: 模型合并能够将多个专业化专家模型组合成一个能够执行多任务的单一模型。然而，随着合并的专家数量增加，其效益通常递减，整体性能提升减弱。本文从任务算术的角度提供了解释和分析；揭示了在现有合并方法中，随着合并的专家数量增加，相关任务向量空间会出现秩崩溃。为解决这一问题，我们引入了子空间增强方法，该方法基于奇异值分解的任务向量空间操作，维持任务向量秩。子空间增强在视觉基准测试中显著提升了合并效果，对多达20个专家模型的合并性能提升超过10%。此外，我们提出使用高阶广义奇异值分解进一步量化任务相似性，为模型合并提供了新的可解释视角。

</details>


### [304] [One Sample is Enough to Make Conformal Prediction Robust](https://arxiv.org/abs/2506.16553)
**中文标题：单样本足以使共形预测具有鲁棒性**

*Soroush H. Zargarbashi,Mohammad Sadegh Akhondzadeh,Aleksandar Bojchevski*

主要分类: cs.LG

摘要简述: 本文提出了一种单样本鲁棒共形预测方法（RCP1），通过仅需一次前向传递即可实现鲁棒性，显著降低了计算成本，同时保持了较小的预测集大小。


<details>
  <summary>详细信息</summary>
研究动机: 传统的鲁棒共形预测（RCP）方法需要多次模型前向传递，计算成本高昂。本文旨在解决这一问题，提出一种更高效的方法。

研究方法: 利用任何二元证书，提出单样本鲁棒共形预测（RCP1），通过认证共形预测过程本身而非单个分数，实现鲁棒性。该方法适用于分类和回归任务。

研究结果: RCP1仅需一次前向传递即可生成鲁棒预测集，其平均集大小优于现有方法（如需要约100次传递的方法）。

研究结论: RCP1显著降低了计算成本，同时保持了鲁棒性和预测集的小尺寸，适用于多种任务。

中文摘要: 共形预测（CP）能够为任何模型生成包含真实标签的高概率预测集。鲁棒共形预测（RCP）将其扩展到具有最坏噪声的输入。现有方法通常使用随机平滑，因其适用于任何黑盒模型且能生成较小的预测集。然而，当前基于平滑的RCP需要对每个输入进行多次模型前向传递，计算成本高昂。本文表明，仅需对单个随机扰动输入进行一次前向传递，共形预测即可实现一定鲁棒性。利用任何二元证书，我们提出单样本鲁棒共形预测（RCP1）。与现有方法（如每次输入需约100次传递）相比，RCP1生成的鲁棒集平均尺寸更小。我们的关键思路是认证共形预测过程本身而非单个分数。该方法适用于分类和回归任务，并进一步扩展到基于平滑的鲁棒共形风险控制。

</details>


### [305] [From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images](https://arxiv.org/abs/2506.16890)
**中文标题：从实验室到工厂：低质量工业图像上自监督/无监督缺陷检测的陷阱与指南**

*Sebastian Hönel,Jonas Nordqvist*

主要分类: cs.LG

摘要简述: 本文探讨了在低质量工业图像上实现自监督或无监督缺陷检测的挑战，提出了针对模型和数据问题的实用指南，并改进了风险估计框架以适应实际工业场景。


<details>
  <summary>详细信息</summary>
研究动机: 传统工业质量检测依赖人工，成本高且易出错。机器学习虽有望替代人工，但现有方法在低质量数据和实际场景中表现不佳，且常用指标（如AUROC）可能误导实践者。本文旨在解决这些问题。

研究方法: 研究评估了两种先进模型，用于在低质量RGB图像中检测金属零件表面细微缺陷，无需新数据。提出了识别模型或数据问题的实用指南，并改进了基于似然方法的缺陷检测框架。

研究结果: 研究发现现有方法在低质量工业数据中表现不稳定，并揭示了基于似然方法的常见陷阱。提出的框架能更可靠地估计实际风险，为实践者提供了改进方向。

研究结论: 本文为工业场景中的自监督或无监督缺陷检测提供了实用指南，改进了风险估计方法，并指出了未来研究方向。

中文摘要: 工业批量生产中的质量问题检测和定位传统上依赖人工检查，成本高且易出错。机器学习有潜力替代人工处理，因此希望采用无监督（或自监督）方法，因为通常无法预先指定所有可能的缺陷。许多先前研究在实验室环境中展示了基于重建、嵌入和合成方法的有效性。然而，实践中我们发现大多数方法在低数据质量或典型不利现实场景中表现不佳或缺乏鲁棒性。实践者可能难以识别方法表现不佳的实际问题。更糟的是，常用指标（如AUROC）在实践中很少适用，可能产生误导性结果。在我们的场景中，我们尝试仅使用低质量RGB图像检测金属锻件表面的细微异常，这是常见的工业场景。我们专门评估了两种先进模型，可在不获取新数据的情况下识别和改进生产数据中的质量问题。我们的贡献是为实践者提供指导，帮助他们在类似场景中可靠地识别与模型或数据相关的问题（如鲁棒性或不变性不足）。此外，我们举例说明了基于似然方法的常见陷阱和不足，并提出了更适合现实场景的实证风险估计框架。

</details>


### [306] [Energy-Based Transfer for Reinforcement Learning](https://arxiv.org/abs/2506.16590)
**中文标题：基于能量的强化学习迁移方法**

*Zeyun Deng,Jasorsi Ghosh,Fiona Xie,Yuzhe Lu,Katia Sycara,Joseph Campbell*

主要分类: cs.LG

摘要简述: 本文提出了一种基于能量的迁移学习方法，通过选择性指导提高强化学习在多任务和持续学习中的样本效率。


<details>
  <summary>详细信息</summary>
研究动机: 强化学习算法在多任务或持续学习场景中样本效率低下，迁移学习虽能提供指导，但在任务差异较大时可能导致次优行为。本文旨在解决这一问题。

研究方法: 提出基于能量的迁移学习方法，利用分布外检测选择性提供教师策略的指导，仅在训练分布内的状态进行干预。

研究结果: 理论证明能量分数反映教师策略的状态访问密度，实验表明该方法在单任务和多任务中均提高了样本效率和性能。

研究结论: 基于能量的迁移学习方法有效解决了任务差异导致的指导偏差问题，显著提升了强化学习的样本效率和性能。

中文摘要: 强化学习算法通常样本效率较低，难以应用于多任务或持续学习场景。通过迁移已训练的教师策略知识可以提升效率，但在新任务与教师训练任务差异较大时，迁移的指导可能次优并偏向低奖励行为。本文提出一种基于能量的迁移学习方法，利用分布外检测选择性提供指导，使教师仅在其训练分布内的状态进行干预。理论表明能量分数反映教师的状态访问密度，实验证明该方法在单任务和多任务中均提高了样本效率和性能。

</details>


### [307] [FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE](https://arxiv.org/abs/2506.16600)
**中文标题：FLAME：通过自适应稀疏混合专家实现联邦学习中的大语言模型微调**

*Khiem Le,Tuan Tran,Ting Hua,Nitesh V. Chawla*

主要分类: cs.LG

摘要简述: 本文提出FLAME框架，通过自适应稀疏混合专家（SMoE）架构实现联邦学习中的资源适应性微调，解决了传统压缩方法导致的信息丢失问题，并通过轻量级重缩放机制和激活感知聚合方案提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于LoRA的联邦微调方法通过压缩全局LoRA矩阵以适应不同客户端的计算资源，但压缩会导致信息丢失和性能下降。FLAME旨在通过SMoE架构保留完整的全局LoRA矩阵，并通过动态激活专家数量实现客户端适应性。

研究方法: FLAME采用SMoE架构，保留未压缩的全局LoRA矩阵，通过调整每个客户端激活的专家数量实现适应性。为解决部分专家激活导致的输出幅度不匹配和专家训练质量不均衡问题，FLAME引入了轻量级重缩放机制和激活感知聚合方案。

研究结果: 实验表明，FLAME在不同计算环境下均优于现有方法，为资源自适应的联邦学习提供了高效且鲁棒的解决方案。

研究结论: FLAME通过SMoE架构和创新的优化机制，显著提升了联邦学习中资源适应性微调的性能，为未来研究提供了新方向。

中文摘要: 现有的资源自适应LoRA联邦微调方法允许客户端使用压缩后的全局LoRA矩阵进行模型微调，以适应不同客户端的计算资源。然而，这种压缩会导致信息丢失，从而影响性能。为此，我们提出FLAME，一种基于稀疏混合专家（SMoE）架构的新型联邦学习框架。与以往方法不同，FLAME保留完整（未压缩）的全局LoRA矩阵，并通过动态调整每个客户端激活的专家数量实现适应性。然而，将SMoE引入联邦学习也带来了独特挑战，特别是部分专家激活导致的输出幅度不匹配以及客户端间专家训练质量不均衡。FLAME通过轻量级重缩放机制和激活感知聚合方案解决了这些问题。实验结果表明，FLAME在不同计算环境下均优于现有方法，为资源自适应的联邦学习提供了鲁棒且高效的解决方案。

</details>


### [308] [Distribution Parameter Actor-Critic: Shifting the Agent-Environment Boundary for Diverse Action Spaces](https://arxiv.org/abs/2506.16608)
**中文标题：分布参数行动者-评论家：通过移动智能体-环境边界实现多样化动作空间**

*Jiamin He,A. Rupam Mahmood,Martha White*

主要分类: cs.LG

摘要简述: 本文提出了一种新的强化学习框架，将分布参数作为动作，重新定义了智能体与环境的边界，使得动作空间连续化。通过提出的DPPG梯度估计器和ICL策略，新方法在连续和离散动作空间中均表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 传统强化学习方法在处理不同类型（离散、连续、混合等）的动作空间时面临挑战。本文旨在通过重新参数化动作空间，提出一种更通用的框架，以降低梯度估计的方差并提升性能。

研究方法: 1. 将分布参数作为动作，使动作空间连续化；2. 提出DPPG梯度估计器，降低方差；3. 引入ICL策略优化评论家学习；4. 基于TD3提出DPAC算法。

研究结果: DPAC在MuJoCo连续控制任务中优于TD3，并在离散化动作空间中表现出竞争力。

研究结论: 通过重新参数化动作空间，本文提出的框架在多样化的动作空间中均表现出优越性能，为强化学习提供了新的思路。

中文摘要: 我们提出了一种新的强化学习（RL）框架，将分布参数作为动作，重新定义了智能体与环境的边界。这种重新参数化使得新的动作空间连续，无论原始动作类型如何（离散、连续、混合等）。基于此，我们开发了一种广义的确定性策略梯度估计器——分布参数策略梯度（DPPG），其方差低于原始动作空间中的梯度。尽管在分布参数上学习评论家面临新挑战，但我们引入了插值评论家学习（ICL），这是一种简单而有效的学习增强策略，并受到多臂老虎机场景的启发。基于TD3（连续控制的强基线），我们提出了一种实用的DPPG行动者-评论家算法——分布参数行动者-评论家（DPAC）。实验表明，DPAC在OpenAI Gym和DeepMind Control Suite的MuJoCo连续控制任务中优于TD3，并在离散化动作空间的相同环境中表现出竞争力。

</details>


### [309] [Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures](https://arxiv.org/abs/2506.16654)
**中文标题：关系深度学习：挑战、基础与下一代架构**

*Vijay Prakash Dwivedi,Charilaos Kanatsoulis,Shenyang Huang,Jure Leskovec*

主要分类: cs.LG

摘要简述: 本文综述了关系深度学习（RDL），探讨了如何将关系数据库表示为关系实体图，并回顾了相关基准数据集与GNN模型。讨论了多表集成、时序动态和异构数据建模的挑战，以及专用神经网络方法。最后展望了RDL在统一图机器学习子领域和设计基础模型方面的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 关系深度学习（RDL）作为一种新兴方法，能够通过关系实体图实现端到端表示学习，避免了传统特征工程的繁琐。然而，其在大规模多表集成、时序动态和异构数据建模方面面临挑战，亟需系统性的综述与未来方向探讨。

研究方法: 论文首先介绍了关系数据库的关系实体图表示方法，随后回顾了用于RDL模型开发的公共基准数据集。接着分析了多表集成、时序动态和异构数据建模的挑战，并综述了针对关系实体图的神经网络方法和最新架构进展。

研究结果: 研究总结了RDL的关键挑战与现有解决方案，展示了其在图机器学习中的潜力，并提出了统一建模挑战和设计基础模型的机会。

研究结论: RDL通过关系实体图实现了端到端学习，有望统一图机器学习的多个子领域，并为关系数据处理的基础模型设计提供新方向。

中文摘要: 图机器学习显著提升了模型在任意图结构数据上的学习能力，并应用于分子、社交网络、推荐系统和交通等领域。多表关系数据库中的数据也可构建为“关系实体图”，用于关系深度学习（RDL）——一种无需传统特征工程的端到端表示学习新方法。与任意图结构数据相比，关系实体图具有以下关键特性：（i）其结构由不同表中实体间的主外键关系定义；（ii）结构连通性是数据库关系模式的函数；（iii）图连通性具有时序性和异构性。本文全面综述了RDL，首先介绍了关系数据库的关系实体图表示，随后回顾了用于开发和评估近期基于GNN的RDL模型的公共基准数据集。讨论了包括大规模多表集成、时序动态和异构数据建模复杂性在内的关键挑战，同时调研了针对关系实体图的神经网络基础方法和最新架构进展。最后，探讨了统一这些独特建模挑战的机遇，强调了RDL如何将图机器学习的多个子领域融合，为基础模型的设计提供可能，从而变革关系数据的处理方式。

</details>


### [310] [A Minimalist Optimizer Design for LLM Pretraining](https://arxiv.org/abs/2506.16659)
**中文标题：大语言模型预训练中的极简优化器设计**

*Athanasios Glentis,Jiaxiang Li,Andi Han,Mingyi Hong*

主要分类: cs.LG

摘要简述: 本文提出了一种名为SCALE的优化器，结合列归一化SGD和最后一层动量，显著减少内存使用，同时在大规模语言模型预训练中保持或超越Adam等自适应优化器的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型预训练中，自适应优化器（如Adam）需要大量内存存储优化器状态。尽管已有研究提出状态压缩方法，但如何最小化优化器状态同时保持性能仍是一个核心问题。

研究方法: 通过系统研究，发现两种高效优化技术：（1）列归一化梯度显著提升普通SGD性能；（2）仅在梯度方差最高的输出层添加一阶动量。基于此，提出SCALE优化器，结合列归一化SGD和最后一层动量。

研究结果: 在多个LLaMA模型（60M-1B）上，SCALE性能与Adam相当或更优，内存使用仅为35-45%。在LLaMA 7B模型上，SCALE在困惑度和内存消耗上均优于当前最优方法APOLLO。

研究结论: SCALE是一种内存高效且性能优越的优化器，适用于内存受限的大规模预训练任务，并为更复杂的优化器设计提供了简约基线。

中文摘要: 大语言模型（LLM）的训练通常依赖于自适应优化器（如Adam），这些优化器需要大量内存来维护一阶和二阶矩矩阵（即优化器状态）。尽管近期研究如GaLore、Fira和APOLLO提出了状态压缩变体以减少内存消耗，但一个根本问题仍未解决：在LLM预训练中，真正需要的最小优化器状态量是多少？本研究通过自下而上的方法系统探讨了这一问题。我们发现两种内存和计算高效的优化技术尤为有效：（1）列归一化梯度显著提升了普通SGD的性能，无需动量；（2）仅在梯度方差最高的输出层添加一阶动量，性能可与完全自适应方法（如Muon）媲美。基于这些发现，我们提出了SCALE（随机列归一化最后一层动量）优化器，结合了列归一化SGD和最后一层动量（列归一化指沿输出维度归一化梯度）。在多个LLaMA模型（60M-1B）上，SCALE的性能与Adam相当或更优，同时仅使用总内存的35-45%。它还持续优于内存高效优化器如GaLore、Fira和APOLLO，成为内存受限下大规模预训练的强有力候选方案。对于LLaMA 7B模型，SCALE在困惑度和内存消耗上均优于当前最优方法APOLLO。此外，我们的方法为更复杂的优化器设计提供了简约基线。

</details>


### [311] [Fast and Stable Diffusion Planning through Variational Adaptive Weighting](https://arxiv.org/abs/2506.16688)
**中文标题：通过变分自适应加权实现快速稳定的扩散规划**

*Zhiying Qiu,Tao Lin*

主要分类: cs.LG

摘要简述: 本文提出了一种基于变分自适应加权的扩散规划方法，解决了扩散模型在离线强化学习中训练成本高、收敛慢的问题，实验表明其性能优越且训练效率提升10倍。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在离线强化学习中表现出潜力，但存在训练成本高、收敛慢的问题，尤其是基于Transformer的去噪骨干网络。现有方法如改进噪声调度、辅助预测目标和自适应损失加权仍难以实现稳定高效训练。

研究方法: 作者提出了一种变分最优的感知不确定性加权函数，并采用闭式多项式逼近方法在线估计，将其集成到扩散规划流程中。

研究结果: 在Maze2D和Kitchen任务上的实验表明，该方法性能优越，训练步骤减少多达10倍。

研究结论: 该方法通过变分自适应加权显著提升了扩散模型的训练效率和稳定性，为离线强化学习提供了实用解决方案。

中文摘要: 扩散模型最近在离线强化学习中显示出潜力，但这些方法通常面临训练成本高和收敛慢的问题，尤其是使用基于Transformer的去噪骨干网络时。虽然已提出多种优化策略（如改进噪声调度、辅助预测目标和自适应损失加权），但在实现稳定高效训练方面仍存在挑战。现有损失加权函数通常依赖神经网络逼近器，但由于MLP在早期训练阶段对稀疏反馈的泛化能力有限，这些方法在早期训练阶段可能效果不佳。本文推导了一种变分最优的感知不确定性加权函数，并引入了一种闭式多项式逼近方法，用于在基于流的生成建模框架下进行在线估计。我们将该方法集成到扩散规划流程中，并在标准离线强化学习基准上进行了评估。在Maze2D和Kitchen任务上的实验结果表明，该方法性能优越，训练步骤减少多达10倍，凸显了其实用性。

</details>


### [312] [TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data](https://arxiv.org/abs/2506.16723)
**中文标题：TriCon-SF：面向异构医疗数据的三重随机化与贡献感知串行联邦学习框架**

*Yuping Yan,Yizhi Wang,Yuanshuai Li,Yaochu Jin*

主要分类: cs.LG

摘要简述: TriCon-SF是一种新型串行联邦学习框架，通过三重随机化和贡献感知技术解决医疗数据异构性和隐私安全问题，实验证明其在准确性和通信效率上优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 在跨机构联邦学习中，串行流水线训练虽能高效处理数据异构性，但直接模型传输易引发隐私泄露和攻击风险，尤其在医疗领域。现有方法难以抵御半诚实或恶意客户端的攻击，亟需一种兼顾隐私保护和鲁棒性的解决方案。

研究方法: TriCon-SF提出三重随机化（模型层、数据段、训练序列）以打破确定性学习模式，并利用Shapley值动态评估客户端贡献，检测不诚实行为，增强系统可问责性。

研究结果: 在非独立同分布医疗数据集上的实验表明，TriCon-SF在准确性和通信效率上优于标准串行和并行联邦学习，安全分析证实其能有效抵御客户端隐私攻击。

研究结论: TriCon-SF通过三重随机化和贡献感知技术，显著提升了联邦学习在医疗数据中的隐私保护和鲁棒性，为异构数据场景提供了高效解决方案。

中文摘要: 串行流水线训练是处理跨机构联邦学习中数据异构性的一种高效范式，通信开销较低。然而，即使无需集中聚合，客户端间直接传输模型仍可能违反隐私法规，并易受梯度泄露和关联攻击。此外，确保对可能操纵或滥用接收模型的半诚实或恶意客户端的抵御能力仍是一大挑战，尤其在医疗等隐私敏感领域。为解决这些问题，我们提出了TriCon-SF，一种新型串行联邦学习框架，融合三重随机化和贡献感知技术。TriCon-SF通过随机化模型层、数据段和训练序列，引入三重随机性以打破确定性学习模式，干扰潜在攻击路径，从而增强隐私性和鲁棒性。同时，利用Shapley值方法动态评估训练中的客户端贡献，检测不诚实行为并提升系统可问责性。在非独立同分布医疗数据集上的大量实验表明，TriCon-SF在准确性和通信效率上均优于标准串行和并行联邦学习。安全分析进一步证实其能有效抵御客户端隐私攻击。

</details>


### [313] [On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis](https://arxiv.org/abs/2506.16732)
**中文标题：关于无监督组合优化中训练与测试不对齐的观察、实证探索与分析**

*Fanchen Bu,Kijung Shin*

主要分类: cs.LG

摘要简述: 本文探讨了无监督组合优化（UCO）中训练与测试阶段的不对齐问题，提出了一种通过将可微分的去随机化引入训练来改善对齐的方法，并分析了其效果与挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有UCO方法在训练和测试阶段存在不对齐问题，导致训练损失低并不一定带来更好的去随机化性能。本文旨在探索如何通过改进训练方法来解决这一问题。

研究方法: 提出在训练阶段引入可微分的去随机化操作，以更好地对齐训练与测试阶段，并通过实验验证其效果。

研究结果: 实验表明，该方法确实改善了训练与测试的对齐性，但也为训练带来了新的挑战。

研究结论: 通过引入可微分去随机化，可以改善UCO中的训练与测试对齐，但需进一步研究以解决其带来的训练复杂性。

中文摘要: 在无监督组合优化（UCO）中，训练阶段的目标是通过连续决策为每个训练实例提供概率意义上的优化结果，从而实现端到端训练。而在测试阶段，通常需要从连续决策出发，通过去随机化得到最终确定性决策。尽管研究者开发了越来越强大的测试阶段去随机化方案以提升UCO方法的性能与理论保证，但我们注意到现有UCO方法中存在训练与测试的不对齐问题。这种不对齐导致训练损失低并不一定带来更好的去随机化性能，即使在无数据分布偏移的训练实例中也是如此。本文通过实验观察到了这种不良现象，并探索了一种初步方法，即在训练中引入可微分去随机化以改善对齐性。实验表明，这一方法确实改善了训练与测试的对齐，但也为训练引入了新的挑战。

</details>


### [314] [Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation](https://arxiv.org/abs/2506.16753)
**中文标题：离策略行动者-评论家对抗观察鲁棒性：基于对称策略评估的虚拟交替训练**

*Kosuke Nakanishi,Akihiro Kubo,Yuji Yasui,Shin Ishii*

主要分类: cs.LG

摘要简述: 本文提出了一种新型离策略方法，通过将对抗学习重新表述为软约束优化问题，消除了额外环境交互的需求，并基于策略评估的对称性理论支持。


<details>
  <summary>详细信息</summary>
研究动机: 现有对抗观察鲁棒性强化学习方法在长期最坏情况下效果有限，且因代理与对抗者的相互依赖导致环境交互效率低下，阻碍了离策略方法的发展。本文旨在解决这一问题。

研究方法: 提出了一种离策略方法，将对抗学习转化为软约束优化问题，利用代理与对抗者策略评估的对称性，避免额外环境交互。

研究结果: 该方法在理论上得到支持，并通过实现验证了其有效性，代码已开源。

研究结论: 本文方法通过优化对抗学习框架，显著提升了对抗观察鲁棒性强化学习的效率和性能。

中文摘要: 近年来，针对对抗输入观察的鲁棒强化学习方法因其对强化学习固有漏洞的关注而备受重视。尽管现有方法取得了一定成功，但在长期最坏情况下，既需最小化对抗者的累积奖励，又需通过交替学习训练代理以对抗，这一过程引入了代理与对抗者的相互依赖，导致环境交互效率低下，阻碍了离策略方法的发展。本文提出了一种新型离策略方法，通过将对抗学习重新表述为软约束优化问题，消除了额外环境交互的需求。该方法基于代理与对抗者策略评估的对称性理论支持。实现代码已发布于https://github.com/nakanakakosuke/VALT_SAC。

</details>


### [315] [Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding](https://arxiv.org/abs/2506.16754)
**中文标题：基于元路径的双曲对比学习用于异质图嵌入**

*Jongmin Park,Seunghoon Han,Won-Yong Shin,Sungsu Lim*

主要分类: cs.LG

摘要简述: 论文提出了一种基于元路径的双曲对比学习框架（MHCL），通过多双曲空间捕捉异质图的复杂结构，并利用对比学习提升元路径嵌入的区分性，实验证明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 异质图具有多样的幂律结构，但现有双曲异质图嵌入模型仅依赖单一双曲空间，难以有效捕捉其多样性。因此，需要一种能够利用多双曲空间描述不同元路径对应结构的方法。

研究方法: 提出MHCL框架，通过多双曲空间分别学习不同元路径对应的复杂结构分布，并采用对比学习优化框架，最小化同元路径嵌入距离，最大化不同元路径嵌入距离，以提升嵌入的区分性。

研究结果: 实验结果表明，MHCL在多种图机器学习任务中优于现有基线方法，能有效捕捉异质图的复杂结构。

研究结论: MHCL通过多双曲空间和对比学习，显著提升了异质图嵌入的性能，为复杂结构建模提供了新思路。

中文摘要: 双曲空间具有恒定负曲率和指数扩展特性，与异质图的结构特性高度契合。然而，尽管异质图天然具有多样的幂律结构，大多数双曲异质图嵌入模型仍依赖单一双曲空间，难以有效捕捉其多样性。为解决这一问题，我们提出了一种基于元路径的双曲对比学习框架（MHCL），利用多双曲空间捕捉异质图中的多样复杂结构。具体而言，通过学习每个双曲空间描述对应元路径的复杂结构分布，可以更有效地捕捉语义信息。由于元路径嵌入代表不同的语义信息，在聚合它们以获取节点表示时，保持其区分性至关重要。因此，我们采用对比学习方法优化MHCL，提升元路径嵌入的区分性。特别是，我们的对比学习方法在双曲空间中最小化同元路径嵌入的距离，最大化不同元路径嵌入的距离，从而提升具有不同语义信息的元路径嵌入的可分性。我们通过全面实验评估了MHCL的有效性，结果表明MHCL在多种图机器学习任务中优于现有基线方法，能有效捕捉异质图的复杂结构。

</details>


### [316] [What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity](https://arxiv.org/abs/2506.16782)
**中文标题：机器学习公平性中的平等意义何在？超越机会均等**

*Youjin Kong*

主要分类: cs.LG

摘要简述: 本文探讨了机器学习公平性中平等概念的意义，指出仅关注分配平等（如机会均等）不足以解决结构性不平等问题，提出结合分配平等和关系平等的多元平等框架，以更全面地应对机器学习系统带来的分配性和代表性危害。


<details>
  <summary>详细信息</summary>
研究动机: 当前机器学习公平性研究主要基于分配平等的伦理基础，但忽视了结构性不平等（如制度性特权和社会等级）对公平性的影响。本文旨在揭示分配平等的局限性，并提出更全面的伦理框架。

研究方法: 通过批判性社会和政治哲学的分析，本文提出一个结合分配平等和关系平等的多元平等框架，并探讨如何在机器学习流程中实践这一框架。

研究结果: 研究发现，仅依赖分配平等无法解释代表性危害（如强化社会等级）的道德错误，而关系平等能补充这一缺陷。多元平等框架为机器学习公平性提供了更全面的伦理基础。

研究结论: 本文主张机器学习公平性需超越分配平等，关注结构性不平等和关系平等，并提出实践路径以实现更全面的公平目标。

中文摘要: 机器学习（ML）公平性已成为一个快速发展的研究领域。但首先，为什么ML中的不公平在道德上是错误的？我们为何要关注公平性的提升？大多数公平ML研究隐含地诉诸分配平等：即认为理想的好处和利益（如机会）应在社会中平等分配。不公平的ML模型之所以被视为错误，正是因为它们不平等地分配这些利益。本文认为，这种对分配平等的单一关注提供了一种不完整且可能误导的伦理基础。将ML公平性建立在平等主义（即平等是基本道德和社会理想的观点）上，需要挑战结构性不平等：那些系统性、制度性和持久性的安排，使某些群体受益而其他群体处于劣势。结构性不平等通过ML系统以两种主要形式表现：分配性危害（如经济损失）和代表性危害（如刻板印象、抹除）。尽管分配平等有助于解决分配性危害，但它无法解释代表性危害的错误性——即为何ML系统强化社会等级（将人分为优越和低劣群体）是错误的，以及为何ML系统应致力于促进人们以平等关系相处的社会（即关系平等）。为弥补这些局限，本文提出一个结合分配平等和关系平等的多元平等框架。借鉴批判性社会和政治哲学，这一框架为应对ML系统带来的全面危害提供了更全面的伦理基础。本文还概述了在ML流程中实践这一框架的具体路径。

</details>


### [317] [TabArena: A Living Benchmark for Machine Learning on Tabular Data](https://arxiv.org/abs/2506.16791)
**中文标题：TabArena：表格数据机器学习的动态基准**

*Nick Erickson,Lennart Purucker,Andrej Tschalzev,David Holzmüller,Prateek Mutalik Desai,and David Salinas,Frank Hutter*

主要分类: cs.LG

摘要简述: TabArena是首个持续维护的动态表格数据机器学习基准系统，通过标准化数据集和模型，提供公开排行榜，并展示梯度提升树和深度学习方法在不同条件下的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前表格数据机器学习基准多为静态，无法适应模型更新或新模型发布的需求。TabArena旨在填补这一空白，提供动态更新的基准系统。

研究方法: TabArena通过手动整理代表性数据集和模型，进行大规模基准测试以初始化公开排行榜，并组建维护团队。研究重点关注验证方法和超参数配置集成对模型性能的影响。

研究结果: 结果显示，梯度提升树在实用表格数据上表现优异，而深度学习方法在更大时间预算和集成条件下迎头赶上。基础模型在小数据集上表现突出，跨模型集成进一步提升了表格机器学习的性能。

研究结论: TabArena通过动态维护的基准系统、公开排行榜和可复现代码，为表格数据机器学习提供了标准化和可靠的评估平台。

中文摘要: 随着深度学习和基础模型在表格数据中的普及，对标准化和可靠基准的需求日益增加。然而，现有基准多为静态设计，即使发现缺陷、模型更新或新模型发布，也未作调整。为此，我们推出了TabArena，首个持续维护的动态表格基准系统。为启动TabArena，我们手动整理了一组代表性数据集和实现良好的模型，进行了大规模基准测试以初始化公开排行榜，并组建了经验丰富的维护团队。研究结果凸显了验证方法和超参数配置集成对模型性能的影响。尽管梯度提升树在实用表格数据上仍具竞争力，但深度学习方法在更大时间预算和集成条件下已迎头赶上。同时，基础模型在小数据集上表现优异。此外，跨模型集成进一步提升了表格机器学习的性能，并探究了各模型的贡献。我们通过公开排行榜、可复现代码和维护协议启动了TabArena，打造了一个动态基准平台，网址为https://tabarena.ai。

</details>


### [318] [Bandwidth Selectors on Semiparametric Bayesian Networks](https://arxiv.org/abs/2506.16844)
**中文标题：半参数贝叶斯网络中的带宽选择器**

*Victor Alejandre,Concha Bielza,Pedro Larrañaga*

主要分类: cs.LG

摘要简述: 本文研究了半参数贝叶斯网络（SPBNs）中带宽选择器的应用，比较了交叉验证和插件选择器与传统正态规则的效果，发现交叉验证在高样本量场景下表现更优。


<details>
  <summary>详细信息</summary>
研究动机: 半参数贝叶斯网络结合了参数和非参数模型，但传统正态规则在非正态数据中表现不佳。本文旨在探索更优的带宽选择器以提升模型性能。

研究方法: 本文建立了带宽选择器的理论框架，并在PyBNesian开源包中扩展了交叉验证和插件选择器技术，通过实验分析比较其效果。

研究结果: 实验表明，交叉验证选择器在高样本量下优于正态规则，能更有效地利用信息提升模型性能。

研究结论: 交叉验证选择器在半参数贝叶斯网络中表现更优，为复杂数据分布的学习提供了更灵活的工具。

中文摘要: 半参数贝叶斯网络（SPBNs）结合了参数和非参数概率模型，为从样本中学习复杂数据分布提供了灵活性。其中，核密度估计（KDEs）用于非参数部分。在数据正态性假设下，通常使用正态规则学习KDEs的带宽矩阵，该矩阵是控制偏差与方差权衡的关键超参数。然而，现实数据常偏离正态性，可能导致密度估计不理想和预测性能下降。本文首先建立了先进带宽选择器的理论框架，随后评估其对SPBN性能的影响。我们探索了交叉验证和插件选择器的方法，评估其在提升SPBN学习能力和适用性方面的有效性。为支持研究，我们在开源包PyBNesian中扩展了带宽选择技术，并进行了广泛的实验分析。结果表明，所提出的带宽选择器比正态规则更有效地利用信息，后者尽管稳健，但在数据增加时表现停滞。特别是无偏交叉验证通常优于正态规则，突出了其在高样本量场景中的优势。

</details>


### [319] [The Importance of Being Lazy: Scaling Limits of Continual Learning](https://arxiv.org/abs/2506.16884)
**中文标题：懒惰的重要性：持续学习的规模限制**

*Jacopo Graldi,Alessandro Breccia,Giulia Lanzillotta,Thomas Hofmann,Lorenzo Noci*

主要分类: cs.LG

摘要简述: 本文通过系统研究模型规模和特征学习程度对持续学习的影响，揭示了模型宽度增加仅在减少特征学习（即更懒惰）时有益。研究发现，高特征学习仅对高度相似任务有益，并识别了任务相似性调制的过渡点。最终，神经网络在特征学习的临界水平达到最佳性能。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有研究，神经网络在非稳态环境中的学习能力仍有限，对灾难性遗忘的理解尚不完整。本文旨在通过研究模型规模和特征学习的作用，填补这一空白。

研究方法: 通过可变参数化架构区分懒惰和丰富训练模式，并利用动态平均场理论分析无限宽度模型在特征学习模式下的动态特性。

研究结果: 研究发现，增加模型宽度仅在减少特征学习时有益；高特征学习仅对高度相似任务有效；任务相似性调制了模型从低遗忘的懒惰模式到高遗忘的丰富模式的过渡。

研究结论: 神经网络在特征学习的临界水平达到最佳性能，这一水平取决于任务非稳态性，并在模型规模间具有可迁移性。本文为持续学习中规模和特征学习的作用提供了统一视角。

中文摘要: 尽管已有研究，神经网络在非稳态环境中的学习能力仍有限，对灾难性遗忘（CF）的理解尚不完整。本文通过系统研究模型规模和特征学习程度对持续学习的影响，区分了懒惰和丰富训练模式，并通过可变参数化架构调和了文献中关于规模的矛盾观察。研究表明，增加模型宽度仅在减少特征学习（即更懒惰）时有益。利用动态平均场理论，我们研究了特征学习模式下无限宽度模型的动态特性并表征了CF，扩展了此前仅限于懒惰模式的理论结果。研究发现，高特征学习仅对高度相似任务有益，并识别了任务相似性调制的过渡点，模型从低遗忘的懒惰模式进入高遗忘的丰富模式。最终，神经网络在特征学习的临界水平达到最佳性能，这一水平取决于任务非稳态性并在模型规模间具有可迁移性。本文为持续学习中规模和特征学习的作用提供了统一视角。

</details>


### [320] [A deep learning and machine learning approach to predict neonatal death in the context of São Paulo](https://arxiv.org/abs/2506.16929)
**中文标题：基于深度学习和机器学习的新生儿死亡预测研究——以圣保罗为例**

*Mohon Raihan,Plabon Kumar Saha,Rajan Das Gupta,A Z M Tahmidul Kabir,Afia Anjum Tamanna,Md. Harun-Ur-Rashid,Adnan Bin Abdus Salam,Md Tanvir Anjum,A Z M Ahteshamul Kabir*

主要分类: cs.LG

摘要简述: 本文通过机器学习和深度学习技术预测新生儿死亡风险，旨在降低全球新生儿死亡率。XGBoost和随机森林分类器在机器学习中表现最佳（准确率94%），而LSTM在深度学习中表现最优（准确率99%）。


<details>
  <summary>详细信息</summary>
研究动机: 新生儿死亡是全球性问题，尤其在欠发达国家。早期预测高风险新生儿可为母婴提供及时护理，从而降低死亡率。本文旨在利用机器学习和深度学习技术实现这一目标。

研究方法: 研究使用140万新生儿的历史数据，采用逻辑回归、K近邻、随机森林分类器、XGBoost、卷积神经网络和LSTM等算法训练预测模型。

研究结果: XGBoost和随机森林分类器在机器学习中准确率达94%，而LSTM在深度学习中准确率高达99%，成为最佳预测模型。

研究结论: LSTM是最适合预测新生儿死亡风险的模型，可为高风险婴儿提供必要的预防措施。

中文摘要: 新生儿死亡仍是欠发达甚至部分发达国家面临的严峻问题。全球数据显示，每1000名新生儿中有26.693名死亡（Macro Trades数据）。为降低这一数字，早期预测高风险婴儿至关重要，以便为母婴提供充分护理，避免早期死亡。本研究利用机器学习技术预测新生儿死亡风险，训练数据涵盖140万名新生儿。采用的算法包括逻辑回归、K近邻、随机森林分类器、XGBoost、卷积神经网络和LSTM。结果显示，机器学习算法中XGBoost和随机森林分类器准确率最高（94%），而深度学习模型中LSTM表现最优（99%）。因此，LSTM是预测新生儿是否需要预防措施的最佳方法。

</details>


### [321] [LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation](https://arxiv.org/abs/2506.17039)
**中文标题：LSCD：基于Lomb-Scargle条件扩散的时间序列填补方法**

*Elizabeth Fons,Alejandro Sztrajman,Yousef El-Laham,Luciana Ferrer,Svitlana Vyetrenko,Manuela Veloso*

主要分类: cs.LG

摘要简述: 本文提出了一种基于Lomb-Scargle条件扩散模型（LSCD）的时间序列填补方法，通过可微分的Lomb-Scargle层计算不规则采样数据的功率谱，并结合扩散模型实现高精度填补。


<details>
  <summary>详细信息</summary>
研究动机: 时间序列数据中存在缺失或不规则采样的问题，传统方法依赖快速傅里叶变换（FFT），但FFT要求均匀采样，需先插值处理，可能导致频谱失真。为解决这一问题，本文提出了一种新方法。

研究方法: 提出了一种可微分的Lomb-Scargle层，用于计算不规则采样数据的功率谱，并将其集成到基于分数的扩散模型（LSCD）中，实现对时间序列的填补。

研究结果: 实验表明，LSCD在合成和真实数据集上填补缺失数据的准确性优于纯时域基线方法，同时能生成一致的频率估计。

研究结论: LSCD方法不仅填补效果更优，还能轻松集成到其他学习框架中，为涉及不完整或不规则数据的机器学习任务提供频谱指导。

中文摘要: 时间序列中存在缺失或不规则采样数据是机器学习中的常见挑战。许多方法依赖快速傅里叶变换（FFT），但FFT假设均匀采样，需先插值处理，可能导致频谱失真。为解决这一问题，我们提出了一种可微分的Lomb-Scargle层，能够可靠计算不规则采样数据的功率谱。我们将该层集成到一种新颖的基于分数的扩散模型（LSCD）中，用于基于信号全频谱的时间序列填补。在合成和真实基准测试中，实验表明我们的方法填补缺失数据的准确性优于纯时域基线方法，同时能生成一致的频率估计。重要的是，该方法可轻松集成到学习框架中，促进频谱指导在涉及不完整或不规则数据的机器学习方法中的广泛应用。

</details>


### [322] [MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network Intrusion Detection](https://arxiv.org/abs/2506.17041)
**中文标题：MAWIFlow基准：基于真实流量的网络入侵检测评估**

*Joshua Schraven,Alexander Windmann,Oliver Niggemann*

主要分类: cs.LG

摘要简述: 本文介绍了MAWIFlow基准数据集，用于网络入侵检测的真实流量评估，解决了传统合成数据无法反映实际环境统计变异和时间漂移的问题。


<details>
  <summary>详细信息</summary>
研究动机: 传统网络入侵检测基准数据集依赖合成流量，无法反映实际环境中的统计变异和时间漂移，因此需要一种更真实、可复现的评估方法。

研究方法: 论文提出了MAWIFlow基准数据集，基于MAWILab v1.1数据集，通过可复现的预处理流程将原始数据包转换为CICFlowMeter格式的流量表示，并保留原始异常标签。数据集包含2011、2016和2021年的跨太平洋主干流量样本。

研究结果: 实验比较了传统机器学习方法（如决策树、随机森林、XGBoost和逻辑回归）与基于CNN-BiLSTM的深度学习模型。结果显示，树模型在静态数据上表现良好，但随时间性能显著下降，而CNN-BiLSTM模型表现更稳定，泛化能力更强。

研究结论: 研究强调了合成基准和静态模型的局限性，提倡采用具有明确时间结构的真实数据集。所有数据集、代码和模型实现均已公开，以促进透明性和可复现性。

中文摘要: 网络入侵检测的基准数据集通常依赖合成流量，无法反映实际环境中的统计变异和时间漂移。本文介绍了MAWIFlow，一种基于MAWILab v1.1数据集的流量基准，旨在实现对异常检测方法的真实且可复现的评估。通过可复现的预处理流程，将原始数据包转换为符合CICFlowMeter格式的流量表示，同时保留MAWILab的原始异常标签。生成的数据集包含2011年、2016年和2021年的跨太平洋主干流量样本。

为建立参考基线，比较了传统机器学习方法（如决策树、随机森林、XGBoost和逻辑回归）与基于CNN-BiLSTM架构的深度学习模型。实验结果表明，树模型在静态数据上表现良好，但随时间推移性能显著下降；而CNN-BiLSTM模型保持了更好的性能，显示出更强的泛化能力。这些发现揭示了合成基准和静态模型的局限性，并推动了采用具有明确时间结构的真实数据集的必要性。所有数据集、流程代码和模型实现均已公开，以促进透明性和可复现性。

</details>


### [323] [Flow-Based Non-stationary Temporal Regime Causal Structure Learning](https://arxiv.org/abs/2506.17065)
**中文标题：基于流的非平稳时间域因果结构学习**

*Abdellah Rahmani,Pascal Frossard*

主要分类: cs.LG

摘要简述: 本文提出了一种名为FANTOM的统一框架，用于处理非平稳时间序列中的因果结构学习，能够同时推断多个时间段的因果图及其边界，并处理非高斯和异方差噪声。


<details>
  <summary>详细信息</summary>
研究动机: 在金融或神经科学等领域，多变量时间序列的因果关系分析至关重要。然而，现有方法通常假设数据是平稳的或噪声为高斯分布，无法处理非平稳性和复杂噪声分布的问题。因此，本文旨在解决这些挑战。

研究方法: FANTOM采用贝叶斯期望最大化算法，通过最大化数据对数似然的证据下界，同时推断时间段的数量、边界以及每个时间段的因果图。其理论证明了在温和假设下，非平稳时间序列中的因果模型是可识别的。

研究结果: 在合成数据和真实数据上的实验表明，FANTOM在非平稳时间序列的因果结构学习中优于现有方法。

研究结论: FANTOM为处理非平稳时间序列中的因果发现提供了一种有效且统一的框架，解决了现有方法无法应对的挑战。

中文摘要: 理解多变量时间序列中的因果关系在金融或神经科学等场景中至关重要。许多此类时间序列表现出多个时间段，即具有未知边界的连续时间片段，每个时间段有其独特的因果结构。推断因果依赖和时间段变化对分析底层过程至关重要。然而，由于（1）非平稳性（每个时间段可能有其因果图和混合函数）和（2）复杂的噪声分布（可能为非高斯或异方差），因果结构学习在这一背景下具有挑战性。现有因果发现方法无法应对这些挑战，因为它们通常假设数据是平稳的或噪声为高斯分布且方差恒定。因此，我们提出了FANTOM，一个统一的因果发现框架，能够处理非平稳过程以及非高斯和异方差噪声。FANTOM同时推断时间段的数量及其对应索引，并学习每个时间段的有向无环图。它采用贝叶斯期望最大化算法，最大化数据对数似然的证据下界。在理论上，我们证明了在温和假设下，FANTOM中引入的时间异方差因果模型在平稳和非平稳设置下是可识别的。此外，在合成和真实数据上的大量实验表明，FANTOM优于现有方法。

</details>


### [324] [Identifiability of Deep Polynomial Neural Networks](https://arxiv.org/abs/2506.17093)
**中文标题：深度多项式神经网络的可识别性**

*Konstantin Usevich,Clara Dérand,Ricardo Borsoi,Marianne Clausel*

主要分类: cs.LG

摘要简述: 本文全面分析了深度多项式神经网络（PNNs）的可识别性，揭示了激活度与层宽度之间的复杂关系，并提出了可识别性的通用和有效条件。


<details>
  <summary>详细信息</summary>
研究动机: 多项式神经网络（PNNs）具有丰富的代数和几何结构，但其可识别性（确保可解释性的关键属性）尚未被充分理解。本文旨在填补这一空白。

研究方法: 通过将深度PNNs与低秩张量分解及Kruskal型唯一性定理联系起来，提出了构造性证明方法，分析了不同架构（包括带偏置项和不带偏置项的网络）的可识别性。

研究结果: 研究发现，在温和条件下，层宽度非递增的架构通常可识别，而解码器宽度增长不过快的编码器-解码器网络也可识别。此外，解决了PNNs神经变种预期维度的开放猜想，并提供了激活度所需的新界限。

研究结论: 本文为深度PNNs的可识别性提供了理论支持，揭示了架构与参数对可识别性的影响，为未来研究奠定了基础。

中文摘要: 多项式神经网络（PNNs）具有丰富的代数和几何结构，但其可识别性（确保可解释性的关键属性）仍未被充分理解。本文对深度PNNs的可识别性进行了全面分析，包括带偏置项和不带偏置项的架构。我们的结果揭示了激活度与层宽度在实现可识别性中的复杂关系。作为特例，我们证明了在温和条件下，层宽度非递增的架构通常可识别，而解码器宽度增长不过快的编码器-解码器网络也可识别。我们的证明是构造性的，并基于深度PNNs与低秩张量分解及Kruskal型唯一性定理的联系。这既产生了由架构决定的通用条件，也产生了依赖于网络参数的有效条件。我们还解决了一个关于PNNs神经变种预期维度的开放猜想，并提供了激活度所需的新界限。

</details>


### [325] [TransDreamerV3: Implanting Transformer In DreamerV3](https://arxiv.org/abs/2506.17103)
**中文标题：TransDreamerV3：在DreamerV3中植入Transformer**

*Shruti Sadanand Dongare,Amun Kharel,Jonathan Samuel,Xiaona Zhou*

主要分类: cs.LG

摘要简述: TransDreamerV3是一种强化学习模型，通过在DreamerV3架构中集成Transformer编码器，提升了复杂环境中的记忆和决策能力。实验表明，在Atari-Freeway和Crafter任务中表现优于DreamerV3。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在通过结合Transformer架构，增强DreamerV3在复杂环境中的记忆和决策能力，以提升强化学习模型的性能。

研究方法: 在DreamerV3架构中引入Transformer编码器，设计TransDreamerV3模型，并在Atari-Boxing、Atari-Freeway、Atari-Pong和Crafter任务上进行实验验证。

研究结果: TransDreamerV3在Atari-Freeway和Crafter任务中表现优于DreamerV3，但在Minecraft任务中存在不足，且训练范围有限。

研究结论: TransDreamerV3展示了基于世界模型的强化学习在结合Transformer架构方面的进步，尽管存在一些局限性，但仍具有潜力。

中文摘要: 本文介绍了TransDreamerV3，这是一种通过集成Transformer编码器增强DreamerV3架构的强化学习模型。该模型旨在提升复杂环境中的记忆和决策能力。我们在Atari-Boxing、Atari-Freeway、Atari-Pong和Crafter任务上进行了实验，结果显示TransDreamerV3在Atari-Freeway和Crafter任务中表现优于DreamerV3。尽管在Minecraft任务中存在问题和训练范围有限，但TransDreamerV3展示了基于世界模型的强化学习在结合Transformer架构方面的进步。

</details>


### [326] [Rapid and Continuous Trust Evaluation for Effective Task Collaboration Through Siamese Model](https://arxiv.org/abs/2506.17128)
**中文标题：通过Siamese模型实现快速连续的信任评估以促进有效任务协作**

*Botao Zhu,Xianbin Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种基于Siamese模型的快速连续信任评估框架（SRCTE），用于在协作任务中实时评估合作者的可信度，通过ACFG和Siamese模型实现高效信任计算，实验证明其快速收敛和高异常检测率。


<details>
  <summary>详细信息</summary>
研究动机: 在协作系统中，信任是确保任务成功完成的关键，但由于分布式设备、复杂环境和动态资源变化，快速连续评估合作者的可信度成为挑战。本文旨在解决这一问题。

研究方法: 提出SRCTE框架，通过ACFG表示合作者的资源属性和历史数据，利用Siamese模型（共享参数的Structure2vec网络）学习ACFG对的深层语义并生成嵌入，计算嵌入相似度以确定信任值。

研究结果: 实验使用Dell EMC 5200服务器和Google Pixel 8构建真实系统，结果显示SRCTE仅需少量数据即可快速收敛，且异常信任检测率高于基线算法。

研究结论: SRCTE框架能够有效支持协作任务中的实时信任评估，具有快速收敛和高检测率的优势，为协作系统提供了可靠的信任管理方案。

中文摘要: 信任正逐渐成为确保协作系统中任务成功完成的有效工具。然而，由于分布式设备、复杂操作环境和动态变化的资源，在任务执行过程中快速且连续地评估合作者的可信度是一项重大挑战。为解决这一挑战，本文提出了一种基于Siamese模型的快速连续信任评估框架（SRCTE），以促进有效的任务协作。首先，收集并利用属性控制流图（ACFG）表示可信状态下合作者的通信和计算资源属性以及历史协作数据，这些数据捕捉了与信任相关的语义信息，并作为与任务执行期间收集的数据进行比较的参考。在任务执行的每个时间槽，实时收集合作者的通信和计算资源属性以及任务完成效果，并用ACFG表示以传达其信任相关语义信息。随后，采用由两个共享参数的Structure2vec网络组成的Siamese模型，学习每对ACFG的深层语义并生成其嵌入。最后，计算每对ACFG嵌入之间的相似度，以确定每个时间槽中合作者的信任值。使用两台Dell EMC 5200服务器和一部Google Pixel 8构建真实系统，测试所提出的SRCTE框架的有效性。实验结果表明，与基线算法相比，SRCTE仅需少量数据即可快速收敛，并实现了较高的异常信任检测率。

</details>


### [327] [Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models](https://arxiv.org/abs/2506.17139)
**中文标题：一致采样与模拟：基于能量的扩散模型的分子动力学**

*Michael Plainer,Hao Wu,Leon Klein,Stephan Günnemann,Frank Noé*

主要分类: cs.LG

摘要简述: 本文提出了一种基于能量的扩散模型，通过引入Fokker-Planck正则化项解决传统扩散模型在分子动力学模拟中的不一致性问题，并在小分子系统上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生物化学等领域表现出色，但在用于分子动力学模拟时，传统扩散模型生成的样本与模拟结果存在不一致性，尤其是在小扩散步长下无法满足Fokker-Planck方程。本文旨在解决这一问题。

研究方法: 提出了一种基于能量的扩散模型，通过引入Fokker-Planck方程衍生的正则化项，强制模型在生成样本和模拟过程中保持一致。该方法在玩具系统、丙氨酸二肽等实验中进行了验证。

研究结果: 实验表明，提出的方法在小分子系统和二肽上显著提高了样本生成与模拟的一致性，并实现了高效的采样。

研究结论: 基于能量的扩散模型通过Fokker-Planck正则化有效解决了传统扩散模型的不一致性问题，为分子动力学模拟提供了更可靠的工具。

中文摘要: 扩散模型因其在生物化学等科学领域的有效性而受到广泛关注。当在平衡分子分布上训练时，扩散模型既能生成平衡构象样本，又能提供与模型分数相关的力。然而，将这些力用于粗粒度分子动力学模拟时，传统扩散推理与模拟生成的样本存在不一致性，尽管二者源于同一模型。尤其是在模拟所需的小扩散步长下，扩散模型无法满足Fokker-Planck方程（该方程描述了分数随时间演化的规律）。我们将这种偏差视为不一致性的表现，并提出了一种基于能量的扩散模型，通过Fokker-Planck衍生的正则化项强制一致性。我们在玩具系统、丙氨酸二肽上验证了该方法的有效性，并引入了一种支持模拟的二肽可转移玻尔兹曼模拟器，展示了更高的一致性和高效采样能力。

</details>


### [328] [Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity](https://arxiv.org/abs/2506.17155)
**中文标题：稀疏正则：利用稀疏性提升离线强化学习中的样本效率**

*Samin Yeasar Arnob,Scott Fujimoto,Doina Precup*

主要分类: cs.LG

摘要简述: 本文提出了一种名为Sparse-Reg的正则化技术，用于解决离线强化学习在小数据集上的过拟合问题，显著提升了在有限数据环境下的学习效果。


<details>
  <summary>详细信息</summary>
研究动机: 离线强化学习通常依赖大规模数据集，但在实际应用中，许多场景只能提供小规模数据。现有算法在小数据集上容易过拟合，导致性能下降。本文旨在解决这一问题。

研究方法: 通过引入基于稀疏性的正则化技术Sparse-Reg，减少离线强化学习在小数据集上的过拟合现象，从而提升模型在有限数据环境下的表现。

研究结果: 实验表明，Sparse-Reg在连续控制任务中优于现有基准方法，有效提升了小数据集下的学习性能。

研究结论: Sparse-Reg为小数据集下的离线强化学习提供了一种有效的解决方案，显著减少了过拟合问题，并提升了模型性能。

中文摘要: 本文研究了离线强化学习（RL）在小数据集中的应用。尽管许多常见的离线RL基准测试使用包含超过百万数据点的数据集，但实际应用中往往依赖更小的数据集。我们发现，离线RL算法在小数据集上容易过拟合，导致性能不佳。为解决这一问题，我们提出了“Sparse-Reg”：一种基于稀疏性的正则化技术，用于减轻离线强化学习中的过拟合现象，从而在有限数据环境下实现高效学习，并在连续控制任务中优于现有基准方法。

</details>


### [329] [Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning](https://arxiv.org/abs/2506.17204)
**中文标题：网络稀疏性释放深度强化学习的扩展潜力**

*Guozheng Ma,Lu Li,Zilin Wang,Li Shen,Pierre-Luc Bacon,Dacheng Tao*

主要分类: cs.LG

摘要简述: 通过引入静态网络稀疏性，该论文展示了如何在不增加复杂修改的情况下，显著提升深度强化学习模型的扩展潜力。


<details>
  <summary>详细信息</summary>
研究动机: 深度强化学习模型的扩展因训练过程中的网络病理问题而困难重重，传统方法如周期性重置和层归一化等针对性干预措施效果有限。本文旨在探索一种更简单的方法，即通过静态网络稀疏性提升模型的扩展能力。

研究方法: 采用一次性随机剪枝方法，即在训练前随机移除网络中预定比例的权重，从而引入静态稀疏性。

研究结果: 实验表明，稀疏网络不仅比密集网络具有更高的参数效率，还能更好地应对优化挑战（如可塑性损失和梯度干扰）。在视觉和流式强化学习场景中，稀疏性的一致优势也得到了验证。

研究结论: 静态网络稀疏性是一种简单而有效的方法，能够显著提升深度强化学习模型的扩展潜力，同时避免复杂修改带来的额外负担。

中文摘要: 深度强化学习模型的扩展因训练过程中的网络病理问题而困难重重，传统方法如周期性重置和层归一化等针对性干预措施效果有限。本文提出了一种更简单的方法，即通过引入静态网络稀疏性，仅需在训练前一次性随机移除预定比例的权重，即可显著提升模型的扩展潜力。实验表明，稀疏网络不仅比密集网络具有更高的参数效率，还能更好地应对优化挑战（如可塑性损失和梯度干扰）。在视觉和流式强化学习场景中，稀疏性的一致优势也得到了验证。

</details>


### [330] [No Free Lunch: Rethinking Internal Feedback for LLM Reasoning](https://arxiv.org/abs/2506.17219)
**中文标题：没有免费的午餐：重新思考LLM推理中的内部反馈**

*Yanzhi Zhang,Zhaoxi Zhang,Haoxiang Guan,Yilin Cheng,Yitong Duan,Chen Wang,Yue Wang,Shuxin Zheng,Jiyan He*

主要分类: cs.LG

摘要简述: 本文探讨了利用内部反馈（RLIF）而非外部监督提升大语言模型（LLM）推理能力的方法，发现其在训练初期能显著提升性能，但随着训练深入性能下降，且对指令调优模型效果有限。


<details>
  <summary>详细信息</summary>
研究动机: 现有的强化学习方法（如RLHF和RLVR）依赖大量外部监督，成本高昂。本文旨在研究仅依赖模型内部信号的强化学习方法（RLIF），以降低监督需求并提升模型推理能力。

研究方法: 提出RLIF方法，利用无监督奖励代理（如词级熵、轨迹级熵和自确定性）作为内部反馈信号，并通过理论分析和实验验证其效果。

研究结果: 实验表明，RLIF在训练初期能显著提升基础LLM的推理性能，甚至超越RLVR；但随着训练深入，性能下降至低于训练前水平。此外，RLIF对指令调优模型改善有限。

研究结论: 内部反馈在LLM训练初期有效，但长期效果有限，尤其是对指令调优模型。研究为整合内部反馈信号提供了实用指导。

中文摘要: 强化学习已成为后训练大语言模型（LLM）以提升推理能力的强大范式。基于人类反馈的强化学习（RLHF）和基于可验证奖励的强化学习（RLVR）等方法表现优异，但需要大量外部监督。本文研究了一类替代方法——基于内部反馈的强化学习（RLIF），其仅依赖模型内部信号而非外部奖励。具体而言，我们利用无监督奖励代理（如词级熵、轨迹级熵和自确定性）作为内部目标。理论分析表明这些内部目标部分等价，并通过实验在数学推理基准上评估了多种RLIF策略。实验结果表明，RLIF在训练初期能显著提升基础LLM的推理性能，甚至在这些任务上匹配或超越RLVR技术。然而，随着训练深入，性能下降至低于训练前水平。此外，RLIF对指令调优模型的改善有限，表明一旦LLM经过指令调优，内部反馈的收益递减。我们进一步通过混合模型权重分析了这一局限性，并解释了RLIF训练行为的原因，为整合内部反馈信号提供了实用指导。希望本文对内部反馈的分析能为LLM后训练提供更原则和有效的策略。

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [331] [Category-based Galaxy Image Generation via Diffusion Models](https://arxiv.org/abs/2506.16255)
**中文标题：基于扩散模型的类别化星系图像生成**

*Xingzhong Fan,Hongming Tang,Yue Zeng,M. B. N. Kouwenhoven,Guangquan Zeng*

主要分类: astro-ph.IM

摘要简述: 本文提出了一种基于扩散模型的星系图像生成框架GalCatDiff，通过结合星系图像特征和天体物理属性，显著提升了生成图像的质量和多样性，同时避免了为每个类别训练单独模型的高计算成本。


<details>
  <summary>详细信息</summary>
研究动机: 传统的星系生成方法依赖物理假设和参数调优，而数据驱动的生成模型能够从观测数据中高效学习物理参数。扩散模型在质量和多样性上优于VAE和GAN，结合物理先验知识可进一步提升其能力。

研究方法: GalCatDiff框架采用增强的U-Net和新型Astro-RAB块，动态结合注意力机制与卷积操作，确保全局一致性和局部特征保真度。此外，通过类别嵌入实现类别特异性星系生成，避免了为每个类别训练单独模型的高计算成本。

研究结果: 实验结果表明，GalCatDiff在样本颜色和大小分布的一致性上显著优于现有方法，生成的星系既视觉逼真又物理一致。

研究结论: GalCatDiff框架提升了星系模拟的可靠性，并有望作为数据增强工具支持未来星系分类算法的开发。

中文摘要: 传统的星系生成方法依赖于半解析模型和流体动力学模拟，这些方法高度依赖物理假设和参数调优。相比之下，数据驱动的生成模型无需预先确定显式物理参数，而是从观测数据中高效学习，成为星系生成的替代方案。其中，扩散模型在质量和多样性上优于变分自编码器（VAE）和生成对抗网络（GAN）。结合物理先验知识可进一步提升这些模型的能力。本文提出了GalCatDiff，这是天文学中首个在扩散模型网络设计中同时利用星系图像特征和天体物理属性的框架。GalCatDiff采用增强的U-Net和新型Astro-RAB（残差注意力块），动态结合注意力机制与卷积操作，确保全局一致性和局部特征保真度。此外，GalCatDiff通过类别嵌入实现类别特异性星系生成，避免了为每个类别训练单独模型的高计算成本。实验结果表明，GalCatDiff在样本颜色和大小分布的一致性上显著优于现有方法，生成的星系既视觉逼真又物理一致。该框架将提升星系模拟的可靠性，并有望作为数据增强工具支持未来星系分类算法的开发。

</details>


<div id='cs.SY'></div>

# cs.SY [[Back]](#toc)

### [332] [Formal Control for Uncertain Systems via Contract-Based Probabilistic Surrogates (Extended Version)](https://arxiv.org/abs/2506.16971)
**中文标题：基于契约概率代理模型的不确定系统形式化控制（扩展版）**

*Oliver Schön,Sofie Haesaert,Sadegh Soudjani*

主要分类: cs.SY

摘要简述: 本文提出了一种基于概率代理模型的抽象技术，通过消除直接计算误差边界的需求，显著提升了随机系统模拟关系的可扩展性和实际应用性，适用于高维复杂非线性系统。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法在构建精确系统模型时面临挑战，且模型复杂度高，难以保证形式化正确性和性能。本文旨在通过概率模拟关系和代理模型，解决这一问题，提升方法的可扩展性和实用性。

研究方法: 提出了一种基于概率代理模型的抽象技术，利用概率模拟关系替代直接计算误差边界，从而简化模型复杂度，适用于高维非线性系统，并提供无限时域时序逻辑保证。

研究结果: 该方法在复杂高维车辆交叉口案例中验证了其有效性，成功实现了可扩展性与保守性的平衡。

研究结论: 通过概率代理模型和抽象技术，本文提供了一种可扩展的解决方案，适用于复杂非线性系统，为形式化控制提供了新的思路。

中文摘要: 构建精确系统模型的需求不仅难以满足，还限制了形式化方法的可扩展性，因为生成的模型通常过于复杂，难以保证形式化正确性和性能。本文聚焦于随机系统的概率模拟关系和代理模型，提出了一种方法，通过消除直接计算误差边界的需求，显著提升了此类模拟关系的可扩展性和实际应用性。因此，我们提供了一种基于抽象的技术，能够有效扩展到更高维度，同时处理复杂的非线性智能体-环境交互，并在不确定性下提供无限时域时序逻辑保证。我们的方法在可扩展性和保守性之间取得了有利的平衡，这一点在一个复杂高维车辆交叉口案例研究中得到了验证。

</details>


<div id='physics.ins-det'></div>

# physics.ins-det [[Back]](#toc)

### [333] [Bias Variation Compensation in Perimeter-Gated SPAD TRNGs](https://arxiv.org/abs/2506.15888)
**中文标题：周边门控SPAD真随机数生成器中的偏置变化补偿**

*Md Sakibur Sajal,Hunter Guthrie,Marc Dandin*

主要分类: physics.ins-det

摘要简述: 本文提出了一种基于64x64阵列的周边门控单光子雪崩二极管（pgSPADs）的真随机数生成器（TRNG），通过补偿偏置变化（BV）技术，实现了室温下每像素2 kHz的原始比特生成率，且BV小于1%。原始比特经过经典的迭代冯·诺伊曼算法去偏后，通过了NIST统计测试套件的全部16项测试。


<details>
  <summary>详细信息</summary>
研究动机: 现有的随机数生成器在使用熵源阵列时存在偏置变化（BV）问题，尽管已有高效的去偏算法，但硬件友好型优化实现依赖于原始比特流的偏置，无法适应广泛的BV范围。本文旨在通过pgSPADs阵列和BV补偿技术解决这一问题。

研究方法: 研究采用64x64阵列的pgSPADs作为熵源，通过基于器件原生暗计数率的适当门电压调节，实现BV补偿。原始比特生成率为2 kHz/像素，室温下BV小于1%。随后使用迭代冯·诺伊曼算法对原始比特进行去偏处理。

研究结果: 实验结果表明，室温下原始比特的BV小于1%，去偏后的比特通过了NIST统计测试套件的全部16项测试，验证了该方法的有效性。

研究结论: 本文提出的pgSPADs阵列结合BV补偿技术，能够有效生成高质量随机比特流，并通过了严格的统计测试，为硬件友好的TRNG设计提供了新思路。

中文摘要: 利用熵源阵列的随机数生成器存在偏置变化（BV）问题。尽管已有高效的去偏算法，但硬件友好型优化实现依赖于原始比特流的偏置，无法适应广泛的BV范围。本研究提出了一种基于64x64阵列的周边门控单光子雪崩二极管（pgSPADs）的熵源，通过BV补偿技术生成随机二进制串。通过基于器件原生暗计数率的适当门电压调节，室温下每像素2 kHz的原始比特生成率中BV小于1%。原始比特使用经典的迭代冯·诺伊曼算法去偏后，通过了NIST统计测试套件的全部16项测试。

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [334] [Linearithmic Clean-up for Vector-Symbolic Key-Value Memory with Kroneker Rotation Products](https://arxiv.org/abs/2506.15793)
**中文标题：Error**

*Ruipeng Liu,Qinru Qiu,Simon Khan,Garrett E. Katz*

主要分类: cs.DS

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [335] [Improved Intelligibility of Dysarthric Speech using Conditional Flow Matching](https://arxiv.org/abs/2506.16127)
**中文标题：基于条件流匹配的构音障碍语音可懂度提升方法**

*Shoutrik Das,Nishant Singh,Arjun Gangwar,S Umesh*

主要分类: cs.SD

摘要简述: 本文提出了一种基于条件流匹配（CFM）和扩散变换器的非自回归方法，用于将构音障碍语音转换为清晰语音，显著提高了语音可懂度。


<details>
  <summary>详细信息</summary>
研究动机: 构音障碍是一种严重影响语音可懂度的神经系统疾病，患者通常难以有效沟通。因此，开发高效的构音障碍语音转换技术至关重要。

研究方法: 研究采用自监督学习（SSL）特征及其量化表示替代传统的梅尔频谱图，利用WavLM提取特征以减少说话者变异性，并提出一种基于条件流匹配和扩散变换器的非自回归方法，直接学习从构音障碍语音到清晰语音的映射。

研究结果: 实验结果表明，离散声学单元在提高语音可懂度方面效果显著，且比传统梅尔频谱图方法收敛更快。

研究结论: 本文提出的方法在构音障碍语音转换中表现出色，为语音可懂度提升提供了新的解决方案。

中文摘要: 构音障碍是一种严重影响语音可懂度的神经系统疾病，患者通常难以有效沟通。因此，开发高效的构音障碍语音转换技术至关重要。本研究探讨了自监督学习（SSL）特征及其量化表示作为梅尔频谱图替代方案的效用和局限性，并探索了通过WavLM提取特征以减少说话者变异性，生成单说话者清晰语音的方法。为此，我们提出了一种完全非自回归的方法，利用条件流匹配（CFM）和扩散变换器学习从构音障碍语音到清晰语音的直接映射。研究结果表明，离散声学单元在提高语音可懂度方面效果显著，且比传统梅尔频谱图方法收敛更快。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [336] [MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction](https://arxiv.org/abs/2506.15835)
**中文标题：MoNetV2：增强运动网络用于自由手3D超声重建**

*Mingyuan Luo,Xin Yang,Zhongnuo Yan,Yan Cao,Yuanji Zhang,Xindi Hu,Jin Wang,Haoxuan Ding,Wei Han,Litao Sun,Dong Ni*

主要分类: eess.IV

摘要简述: MoNetV2提出了一种增强运动网络，通过融合图像和运动信息，结合多级一致性约束和自监督策略，显著提升了自由手3D超声重建的精度和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 自由手3D超声重建在临床诊断中至关重要，但仅依赖图像的深度学习方法存在累积漂移和复杂运动轨迹下精度不足的问题。MoNetV2旨在解决这些问题，提升重建精度和适应性。

研究方法: 1. 提出基于传感器的时空多分支结构，从速度角度融合图像和运动信息；2. 设计在线多级一致性约束，利用扫描的固有一致性处理不同扫描速度和策略；3. 采用在线多模态自监督策略，利用网络估计与运动信息的相关性减少累积误差。

研究结果: 实验表明，MoNetV2在三个大型数据集上显著优于现有方法，重建质量和泛化性能均有显著提升。

研究结论: MoNetV2通过融合多源信息和多级约束，有效提升了自由手3D超声重建的精度和适应性，为临床诊断提供了更可靠的工具。

中文摘要: 三维（3D）超声（US）旨在为超声医师提供解剖结构的空间关系，在临床诊断中发挥关键作用。近年来，基于深度学习的自由手3D超声取得了显著进展，其通过估计图像间的变换重建体积，无需外部跟踪。然而，仅依赖图像的重建难以减少累积漂移并进一步提高精度，尤其是在复杂运动轨迹场景下。为此，我们提出了一种增强运动网络（MoNetV2），以提升不同扫描速度和策略下的重建精度和泛化能力。首先，我们提出了一种基于传感器的时空多分支结构，从速度角度融合图像和运动信息，提升仅依赖图像的重建精度。其次，设计了一种在线多级一致性约束，利用扫描的固有一致性处理不同扫描速度和策略。该约束结合扫描级速度一致性、路径级外观一致性和块级运动一致性，监督帧间变换估计。第三，我们提炼了一种在线多模态自监督策略，利用网络估计与运动信息的相关性进一步减少累积误差。大量实验表明，MoNetV2在三个大型数据集上的重建质量和泛化性能均显著优于现有方法。

</details>


### [337] [Cross-Modality Learning for Predicting IHC Biomarkers from H&E-Stained Whole-Slide Images](https://arxiv.org/abs/2506.15853)
**中文标题：基于跨模态学习从H&E染色全切片图像预测IHC生物标志物**

*Amit Das,Naofumi Tomita,Kyle J. Syme,Weijie Ma,Paige O'Connor,Kristin N. Corbett,Bing Ren,Xiaoying Liu,Saeed Hassanpour*

主要分类: eess.IV

摘要简述: 本研究提出了一种名为HistoStainAlign的深度学习框架，通过从H&E染色的全切片图像中预测IHC染色模式，解决了IHC染色成本高、耗时长的问题。该方法利用对比学习策略整合H&E和IHC的特征，无需组织配准或补丁级标注，显著提升了预测效果。


<details>
  <summary>详细信息</summary>
研究动机: IHC染色虽然能提供分子水平的组织信息，但其成本高、耗时长且需要专业知识。为了克服这些限制，研究提出直接从H&E染色图像预测IHC染色模式，以提高诊断效率和降低成本。

研究方法: 研究提出了HistoStainAlign框架，通过对比学习策略整合H&E和IHC的特征嵌入，无需补丁级标注或组织配准。模型在胃肠道和肺组织切片上进行了测试，预测了三种常见IHC染色（P53、PD-L1和Ki-67）的模式。

研究结果: HistoStainAlign在三种IHC染色上的加权F1分数分别为0.735（P53）、0.830（PD-L1）和0.723（Ki-67）。嵌入分析表明，对比学习能有效捕捉跨染色模态的关系，显著优于基线模型。

研究结论: 该研究展示了计算模型作为IHC染色预筛选工具的潜力，可帮助优化工作流程并提高诊断效率。

中文摘要: 苏木精和伊红（H&E）染色是病理学分析的基石，为癌症诊断、分型和分级提供了可靠的细胞形态和组织结构可视化。免疫组织化学（IHC）染色通过检测组织中的特定蛋白质提供分子水平的见解，从而提升诊断准确性和治疗规划。然而，IHC染色成本高、耗时长且资源密集，需要专业知识。为解决这些问题，本研究提出了HistoStainAlign，一种新型深度学习框架，通过从H&E全切片图像中学习形态和分子特征的联合表示来直接预测IHC染色模式。该框架通过对比训练策略整合配对的H&E和IHC嵌入，无需补丁级标注或组织配准即可捕捉染色模态间的互补特征。模型在胃肠道和肺组织切片上评估了三种常用IHC染色（P53、PD-L1和Ki-67）。HistoStainAlign在这三种IHC染色上的加权F1分数分别为0.735 [95%置信区间（CI）：0.670-0.799]、0.830 [95% CI：0.772-0.886]和0.723 [95% CI：0.607-0.836]。嵌入分析表明对比对齐在捕捉有意义的跨染色关系方面具有鲁棒性。与基线模型的比较进一步凸显了引入对比学习对提升染色模式预测的优势。本研究展示了计算方法作为预筛选工具的潜力，有助于优先选择IHC染色病例并提高工作流程效率。

</details>


### [338] [InfiniPot-V: Memory-Constrained KV Cache Compression for Streaming Video Understanding](https://arxiv.org/abs/2506.15745)
**中文标题：InfiniPot-V：面向流媒体视频理解的内存受限键值缓存压缩**

*Minsoo Kim,Kyuhong Shim,Jungwook Choi,Simyung Chang*

主要分类: eess.IV

摘要简述: InfiniPot-V是一种无需训练、与查询无关的框架，通过动态压缩键值缓存（KV cache）解决流媒体视频理解中的内存限制问题，显著降低GPU内存占用并保持实时生成能力。


<details>
  <summary>详细信息</summary>
研究动机: 现代多模态大语言模型（MLLMs）在处理长视频时，键值缓存（KV cache）会随视频时长线性增长，超出手机、AR眼镜和边缘机器人等设备的固定内存限制。现有压缩方法通常需要离线处理或先构建完整缓存，无法满足流媒体场景的需求。

研究方法: InfiniPot-V通过动态监控缓存并在达到用户设定阈值时运行轻量级压缩：（1）使用时间轴冗余（TaR）指标去除时间冗余令牌；（2）通过值范数（VaN）排名保留语义重要令牌。

研究结果: 在四个开源MLLM和四个长视频及两个流媒体视频基准测试中，InfiniPot-V将GPU峰值内存降低高达94%，保持实时生成，且准确率与完整缓存相当甚至更高，适用于多轮对话场景。

研究结论: InfiniPot-V无需重新训练或查询知识即可解决KV缓存瓶颈，为设备端流媒体视频助手提供了可行的解决方案。

中文摘要: 现代多模态大语言模型（MLLMs）能够处理长达数小时的视频，但其键值（KV）缓存随时间线性增长，迅速超出手机、AR眼镜和边缘机器人等设备的固定内存限制。现有压缩方案通常假设整个视频和用户查询可离线获取，或需先构建完整缓存，导致内存仍随流长度增长。InfiniPot-V是首个无需训练、与查询无关的框架，为流媒体视频理解提供了硬性、长度无关的内存上限。在视频编码过程中，它监控缓存并在达到用户设定阈值时运行轻量级压缩：（i）通过时间轴冗余（TaR）指标去除时间冗余令牌；（ii）通过值范数（VaN）排名保留语义重要令牌。在四个开源MLLM和四个长视频及两个流媒体视频基准测试中，InfiniPot-V将GPU峰值内存降低高达94%，保持实时生成，且准确率与完整缓存相当甚至更高，适用于多轮对话场景。通过无需重新训练或查询知识即可解决KV缓存瓶颈，InfiniPot-V为设备端流媒体视频助手提供了可行的解决方案。

</details>


### [339] [CF-Seg: Counterfactuals meet Segmentation](https://arxiv.org/abs/2506.16213)
**中文标题：CF-Seg：反事实与分割的结合**

*Raghav Mehta,Fabio De Sousa Ribeiro,Tian Xia,Melanie Roschewitz,Ainkaran Santhirasekaram,Dominic C. Marshall,Ben Glocker*

主要分类: eess.IV

摘要简述: 本文提出了一种利用反事实图像（CF）改进医学图像分割的方法，通过模拟无病变的解剖结构，提升分割模型的准确性，实验证明该方法有效。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像中解剖结构的分割对疾病定量评估至关重要，但病变会导致图像模糊或结构遮挡，使分割模型性能下降，可能引发误诊。本文旨在通过反事实图像模拟健康状态，提升分割准确性。

研究方法: 生成反事实图像（CF），模拟同一解剖结构在无病变时的表现，不改变原始结构。利用这些图像分割目标结构，无需修改现有分割模型。

研究结果: 在两个真实临床胸部X光数据集上的实验表明，使用反事实图像显著提高了解剖结构的分割准确性，有助于临床决策。

研究结论: 反事实图像能有效提升医学图像分割性能，为临床诊断提供更可靠的支持。

中文摘要: 医学图像中解剖结构的分割在多种疾病的定量评估中具有重要作用。然而，病变的存在使准确分割变得更具挑战性。病变模式可能改变周围健康组织的表现，引入模糊边界，甚至遮挡关键解剖结构。因此，基于真实数据集训练的分割模型可能难以提供良好的解剖分割，导致潜在的误诊。本文通过生成反事实（CF）图像，模拟同一解剖结构在无病变时的表现，同时不改变其底层结构。随后利用这些反事实图像分割目标结构，无需对现有分割模型进行任何修改。在两个真实临床胸部X光数据集上的实验表明，反事实图像的使用提高了解剖分割的准确性，从而有助于下游临床决策。

</details>


### [340] [Pixel-wise Modulated Dice Loss for Medical Image Segmentation](https://arxiv.org/abs/2506.15744)
**中文标题：像素级调制的Dice损失用于医学图像分割**

*Seyed Mohsen Hosseini*

主要分类: eess.IV

摘要简述: 本文提出了一种像素级调制的Dice损失（PM Dice损失），用于解决医学图像分割中的类别不平衡和难度不平衡问题，计算成本低且效果显著。


<details>
  <summary>详细信息</summary>
研究动机: 医学图像分割任务中存在类别不平衡和难度不平衡问题，导致传统损失函数（如交叉熵损失和Dice损失）训练效果不佳。现有方法计算成本高且效果有限，因此需要一种更高效的解决方案。

研究方法: 通过引入像素级调制项，对Dice损失进行简单修改，使其既能处理类别不平衡，又能解决难度不平衡问题，计算成本低。

研究结果: 在三种常见医学分割任务上的实验表明，PM Dice损失优于其他针对难度不平衡问题设计的方法。

研究结论: PM Dice损失是一种高效且计算成本低的解决方案，能够同时解决医学图像分割中的类别不平衡和难度不平衡问题。

中文摘要: 类别不平衡和难度不平衡是影响神经网络在医学分割任务中性能的两类数据不平衡问题。类别不平衡中，损失由多数类主导；难度不平衡中，损失由易分类像素主导，导致训练效果不佳。Dice损失基于几何度量，在解决类别不平衡方面比直接采用分类任务中的交叉熵（CE）损失更有效。为解决难度不平衡，常见方法是采用重新加权的CE损失或改进的Dice损失，将训练集中在难以分类的区域。现有改进方法计算成本高且效果有限。本研究提出了一种对Dice损失的简单修改，计算成本极低。通过像素级调制项，利用Dice损失处理类别不平衡的优势，同时解决难度不平衡问题。在三种常用医学分割任务上的结果表明，提出的像素级调制Dice损失（PM Dice损失）优于其他针对难度不平衡问题设计的方法。

</details>


### [341] [Diffusion-based Counterfactual Augmentation: Towards Robust and Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2506.15748)
**中文标题：基于扩散的反事实增强：迈向鲁棒且可解释的膝关节骨关节炎分级**

*Zhe Wang,Yuhua Ru,Aladine Chetouani,Tina Shiang,Fang Chen,Fabian Bauer,Liping Zhang,Didier Hans,Rachid Jennane,William Ewing Palmer,Mohamed Jarraya,Yung Hsin Chen*

主要分类: eess.IV

摘要简述: 本文提出了一种基于扩散的反事实增强方法（DCA），通过生成目标反事实样本提升膝关节骨关节炎（KOA）自动分级的鲁棒性和可解释性。实验表明，该方法显著提高了分类准确性，并揭示了与临床知识一致的潜在空间拓扑。


<details>
  <summary>详细信息</summary>
研究动机: 膝关节骨关节炎（KOA）的自动分级面临观察者间差异大和深度学习模型鲁棒性不足的问题，尤其是在关键决策边界附近。为了解决这些问题，本文旨在通过生成有针对性的反事实样本，提升模型的鲁棒性和可解释性。

研究方法: 提出了一种名为扩散基反事实增强（DCA）的新框架，利用随机微分方程（SDE）在扩散模型的潜在空间中导航，平衡分类器驱动的边界约束和流形约束。生成的反事实样本用于自校正学习策略，以聚焦模型的不确定区域。

研究结果: 在OAI和MOST公开数据集上的实验表明，DCA显著提高了多种模型架构的分类准确性。此外，该方法通过可视化最小病理变化和揭示潜在空间拓扑与KOA进展的临床知识一致，提供了可解释性。

研究结论: DCA框架将模型不确定性转化为鲁棒的训练信号，为开发更准确和可信的自动化诊断系统提供了有前景的途径。

中文摘要: 膝关节骨关节炎（KOA）的自动分级面临观察者间差异大和深度学习模型鲁棒性不足的挑战，尤其是在关键决策边界附近。为解决这些问题，本文提出了一种名为扩散基反事实增强（DCA）的新框架，通过生成目标反事实样本提升模型的鲁棒性和可解释性。该方法利用随机微分方程（SDE）在扩散模型的潜在空间中导航，平衡分类器驱动的边界约束和流形约束。生成的反事实样本用于自校正学习策略，以聚焦模型的不确定区域。在OAI和MOST公开数据集上的实验表明，该方法显著提高了多种模型架构的分类准确性。此外，DCA通过可视化最小病理变化和揭示潜在空间拓扑与KOA进展的临床知识一致，提供了可解释性。DCA框架将模型不确定性转化为鲁棒的训练信号，为开发更准确和可信的自动化诊断系统提供了有前景的途径。代码已开源：https://github.com/ZWang78/DCA。

</details>


### [342] [Fast Training-free Perceptual Image Compression](https://arxiv.org/abs/2506.16102)
**中文标题：快速无需训练的感知图像压缩**

*Ziran Zhu,Tongda Xu,Minye Huang,Dailan He,Xingtong Ge,Xinjie Zhang,Ling Li,Yan Wang*

主要分类: eess.IV

摘要简述: 本文提出了一种无需训练的感知图像压缩算法，显著提升解码速度（从1分钟降至0.1-10秒），并适用于非可微分编解码器，同时支持感知-失真权衡。


<details>
  <summary>详细信息</summary>
研究动机: 现有无需训练的感知图像编解码器依赖扩散反演或样本通信，解码时间长达1分钟甚至更长。本文旨在解决这一问题，提出一种快速且无需训练的方法，提升解码效率。

研究方法: 1. 提出一种理论保证的算法，提升现有编解码器的感知质量。2. 针对不同解码时间预算（≈0.1秒、0.1-10秒、≥10秒）设计不同实现方案。3. 支持非可微分编解码器（如VTM）和现有感知编解码器（如MS-ILLM）的改进。

研究结果: 实验表明，该方法显著缩短解码时间（从1分钟降至0.1-10秒），同时保持可比感知质量。在FID指标上优于HiFiC和MS-ILLM等基于条件生成模型的编解码器。

研究结论: 本文提出的方法在解码速度和感知质量上取得显著改进，适用于多种编解码器，并支持灵活的感知-失真权衡。

中文摘要: 无需训练的感知图像编解码器在解码时采用预训练的无条件生成模型，以避免训练新的条件生成模型。然而，它们严重依赖扩散反演或样本通信，解码单张图像需1分钟甚至更长时间。本文提出一种无需训练的算法，通过理论保证提升现有编解码器的感知质量，并针对不同解码时间预算（≈0.1秒、0.1-10秒、≥10秒）提出不同实现方案。我们的方法：1）将解码时间从1分钟缩短至0.1-10秒，同时保持可比感知质量；2）适用于非可微分编解码器（如VTM）；3）可用于改进现有感知编解码器（如MS-ILLM）；4）轻松实现感知-失真权衡。实验表明，该方法显著提升ELIC、VTM和MS-ILLM的感知质量，解码速度快。在FID指标上优于HiFiC和MS-ILLM等基于条件生成模型的编解码器。源代码详见补充材料。

</details>


### [343] [Enhanced Dermatology Image Quality Assessment via Cross-Domain Training](https://arxiv.org/abs/2506.16116)
**中文标题：通过跨域训练增强皮肤病图像质量评估**

*Ignacio Hernández Montilla,Alfonso Medela,Paola Pasquali,Andy Aguilar,Taig Mac Carthy,Gerardo Fernández,Antonio Martorell,Enrique Onieva*

主要分类: eess.IV

摘要简述: 本文提出通过跨域训练提升皮肤病图像质量评估（IQA）模型性能，结合皮肤病与非皮肤病IQA数据集，解决了皮肤病IQA数据规模小的问题，并显著提升了远程皮肤病诊疗中的图像质量管理。


<details>
  <summary>详细信息</summary>
研究动机: 远程皮肤病学（Teledermatology）已成为临床实践中的重要工具，但图像质量差的问题严重影响了远程诊疗的效果。现有皮肤病IQA研究较少，且未充分利用非皮肤病IQA领域的最新进展。本文旨在通过跨域训练解决皮肤病IQA数据规模小的问题，提升图像质量评估的准确性。

研究方法: 本文提出跨域训练方法，结合皮肤病与非皮肤病IQA数据集。为此，作者创建了一个新的皮肤病IQA数据库Legit.Health-DIQA-Artificial，包含来自多源的皮肤病图像，并由人类观察者标注。通过跨域训练，模型能够利用更大规模的图像失真数据，提升性能。

研究结果: 实验表明，跨域训练在多个领域均表现优异，克服了皮肤病IQA数据规模小的限制。模型能够更好地管理远程皮肤病学中的图像质量，提升了诊疗过程的实用性。

研究结论: 跨域训练显著提升了皮肤病IQA模型的性能，解决了数据规模小的瓶颈，为远程皮肤病学中的图像质量管理提供了有效解决方案。

中文摘要: 远程皮肤病学已成为日常临床实践中广泛接受的沟通方式，其与面对面诊疗具有高度一致性。然而，图像质量差的问题仍是远程皮肤病学中未解决的难题，严重影响了远程诊疗的实用性。目前，皮肤病图像质量评估（IQA）的研究较少，且未充分利用非皮肤病IQA领域的最新进展，如使用更大规模的图像数据库和人类观察者评分。本文提出跨域训练IQA模型，结合皮肤病与非皮肤病IQA数据集。为此，我们创建了一个新的皮肤病IQA数据库Legit.Health-DIQA-Artificial，包含来自多源的皮肤病图像，并由人类观察者标注。实验证明，跨域训练在多个领域均表现优异，克服了皮肤病IQA数据规模小的限制，并能够更好地管理远程皮肤病学中的图像质量。

</details>


### [344] [From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction](https://arxiv.org/abs/2506.16210)
**中文标题：从粗到细：渐进细化隐式神经表示用于运动鲁棒的各向异性MRI重建**

*Zhenxuan Zhang,Lipei Zhang,Yanqi Cheng,Zi Wang,Fanwen Wang,Haosen Zhang,Yue Yang,Yinzhe Wu,Jiahao Huang,Angelica I Aviles-Rivero,Zhifan Gao,Guang Yang,Peter J. Lally*

主要分类: eess.IV

摘要简述: 本文提出了一种渐进细化隐式神经表示（PR-INR）框架，用于运动鲁棒的各向异性MRI重建，通过几何感知坐标空间统一运动校正、结构细化和体积合成，显著提升了重建质量和视觉表现。


<details>
  <summary>详细信息</summary>
研究动机: 在运动鲁棒的磁共振成像（MRI）中，切片到体积的重建对于从2D切片恢复解剖一致的3D脑部体积至关重要，尤其是在加速采集或患者运动的情况下。然而，由于层次结构破坏（如局部细节丢失、全局结构混叠和体积各向异性），这一任务仍然具有挑战性。

研究方法: PR-INR框架包括三个模块：1）运动感知扩散模块生成粗略体积重建以抑制运动伪影；2）隐式细节恢复模块通过对齐空间坐标与视觉特征进行残差细化；3）体素连续感知表示模块将图像表示为3D坐标上的连续函数，实现准确的切片间补全和高频细节恢复。

研究结果: 在五种公共MRI数据集上的实验表明，PR-INR在不同运动条件（3%和5%位移）、欠采样率（4x和8x）和切片分辨率（scale=5）下均优于现有方法，在定量重建指标和视觉质量上表现优异，并展示了跨未见领域的泛化性和鲁棒性。

研究结论: PR-INR框架通过渐进细化隐式神经表示，成功解决了运动鲁棒MRI重建中的层次结构破坏问题，为未来研究提供了新的方向。

中文摘要: 在运动鲁棒的磁共振成像（MRI）中，切片到体积的重建对于从2D切片恢复解剖一致的3D脑部体积至关重要，尤其是在加速采集或患者运动的情况下。然而，由于层次结构破坏（如局部细节丢失、全局结构混叠和体积各向异性），这一任务仍然具有挑战性。为此，我们提出了一种渐进细化隐式神经表示（PR-INR）框架。PR-INR在几何感知坐标空间中统一了运动校正、结构细化和体积合成。具体而言，首先使用运动感知扩散模块生成粗略体积重建以抑制运动伪影并保留全局解剖结构。然后，引入隐式细节恢复模块，通过将空间坐标与视觉特征对齐进行残差细化，修正局部结构并增强边界精度。此外，体素连续感知表示模块将图像表示为3D坐标上的连续函数，实现准确的切片间补全和高频细节恢复。我们在五种公共MRI数据集上评估了PR-INR，实验结果表明，在不同运动条件（3%和5%位移）、欠采样率（4x和8x）和切片分辨率（scale=5）下，PR-INR在定量重建指标和视觉质量上均优于现有方法，并展示了跨未见领域的泛化性和鲁棒性。

</details>


### [345] [AGE-US: automated gestational age estimation based on fetal ultrasound images](https://arxiv.org/abs/2506.16256)
**中文标题：基于胎儿超声图像的自动孕龄估计方法（AGE-US）**

*César Díaz-Parga,Marta Nuñez-Garcia,Maria J. Carreira,Gabriel Bernardino,Nicolás Vila-Blanco*

主要分类: eess.IV

摘要简述: 本文提出了一种基于胎儿超声图像的自动孕龄估计方法（AGE-US），通过深度学习结合新颖的分割架构和距离图，解决了传统方法依赖人工测量和数据标注不足的问题，适用于资源有限的环境。


<details>
  <summary>详细信息</summary>
研究动机: 准确估计孕龄对监测胎儿生长至关重要，但传统方法（如末次月经）在某些情况下难以获取，而超声方法虽可靠却依赖人工测量，存在变异性。本研究旨在开发一种自动化、可解释的孕龄估计方法，以克服数据限制和标注不足的问题。

研究方法: 本研究采用深度学习技术，结合新颖的分割架构和距离图，自动计算孕龄。该方法通过优化模型复杂度，减少对标注数据的依赖，并特别适用于资源有限的环境。

研究结果: 该方法在性能上与现有先进模型相当，同时降低了复杂性。距离图的使用尤其适用于股骨端点的估计，进一步验证了其有效性。

研究结论: AGE-US方法为孕龄估计提供了一种高效、自动化的解决方案，尤其适合资源有限和数据标注不足的场景，距离图的应用进一步提升了模型的实用性。

中文摘要: 出生体重过小会带来显著的健康风险，包括新生儿死亡率增加和未来心脏疾病的可能性更高。准确估计孕龄对监测胎儿生长至关重要，但传统方法（如基于末次月经的估计）在某些情况下难以获取。虽然超声方法更可靠，但其依赖人工测量，引入了变异性。本研究提出了一种基于可解释深度学习的自动孕龄计算方法，利用新颖的分割架构和距离图克服数据集限制和分割掩模稀缺的问题。我们的方法在性能上与现有先进模型相当，同时降低了复杂性，特别适合资源有限和标注数据不足的环境。此外，结果表明距离图尤其适用于股骨端点的估计。

</details>


### [346] [VesselSDF: Distance Field Priors for Vascular Network Reconstruction](https://arxiv.org/abs/2506.16556)
**中文标题：VesselSDF：基于距离场先验的血管网络重建**

*Salvatore Esposito,Daniel Rebain,Arno Onken,Changjian Li,Oisin Mac Aodha*

主要分类: eess.IV

摘要简述: VesselSDF提出了一种基于符号距离场（SDF）的新方法，用于从稀疏CT扫描切片中重建血管网络，解决了现有深度学习方法在结构连续性和几何保真度上的不足。


<details>
  <summary>详细信息</summary>
研究动机: 由于血管的细长分支特性及CT扫描切片的稀疏性，现有基于二值体素分类的深度学习方法难以保证血管的结构连续性和几何精度，亟需一种更鲁棒的血管重建方法。

研究方法: VesselSDF将血管分割问题转化为连续的SDF回归任务，通过自适应高斯正则化消除SDF中的浮动片段，同时保留血管表面的精确几何形状。

研究结果: 实验表明，VesselSDF显著优于现有方法，能够更好地保持血管的几何结构和连通性，为临床血管分析提供更可靠的结果。

研究结论: VesselSDF通过SDF连续表示和自适应正则化，实现了高精度的血管重建，为医学影像中的血管网络分割提供了新思路。

中文摘要: 从稀疏CT扫描切片中准确分割血管网络是医学影像中的重大挑战，尤其是由于血管的细长分支特性及成像平面间的稀疏性。现有的基于二值体素分类的深度学习方法往往难以保证结构连续性和几何保真度。为解决这一问题，我们提出了VesselSDF，这是一种利用符号距离场（SDF）实现鲁棒血管重建的新框架。我们的方法将血管分割问题转化为连续的SDF回归任务，其中体积中的每个点由其到最近血管表面的符号距离表示。这种连续表示自然地捕捉了血管的平滑管状几何及其分支模式。通过自适应高斯正则化，我们在消除常见SDF伪影（如浮动片段）的同时，实现了精确的血管重建。实验结果表明，VesselSDF显著优于现有方法，能够更好地保持血管的几何结构和连通性，为临床血管分析提供了更可靠的工具。

</details>


### [347] [DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates](https://arxiv.org/abs/2506.16572)
**中文标题：DiffO：超低比特率下单步扩散图像压缩**

*Chanung Park,Joo Chan Lee,Jong Hwan Ko*

主要分类: eess.IV

摘要简述: 本文提出了一种单步扩散模型DiffO，用于超低比特率下的图像压缩，通过VQ残差训练和速率自适应噪声调制，显著提升了压缩性能和解码速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像压缩方法在极低比特率下质量严重下降，而基于扩散的模型虽有所改进，但仍存在解码延迟高和感知质量有限的问题。

研究方法: DiffO结合了VQ残差训练（分解结构基码和潜在空间残差）和速率自适应噪声调制（动态调整去噪强度），实现了高效的单步扩散压缩。

研究结果: 实验表明，DiffO在压缩性能上超越现有方法，解码速度提升约50倍，显著提升了生成编解码器的实用性。

研究结论: DiffO通过创新方法解决了超低比特率下图像压缩的挑战，为生成编解码器的实际应用提供了高效解决方案。

中文摘要: 尽管图像压缩是视觉数据处理的基础，并催生了众多标准和学习的编解码器，但这些方法在极低比特率下仍存在严重的质量下降问题。虽然最近的基于扩散的模型在低比特率下提供了增强的生成性能，但由于多步去噪过程，其感知质量和解码延迟仍受限。本文提出了首个用于图像压缩的单步扩散模型（DiffO），在超低比特率下实现了高感知质量和快速解码。DiffO通过两项关键创新实现这些目标：（i）VQ残差训练，将结构基码和潜在空间残差分解，捕捉全局几何和高频细节；（ii）速率自适应噪声调制，动态调整去噪强度以匹配目标比特率。大量实验表明，DiffO在压缩性能上超越了现有技术，同时解码速度比基于扩散的方法提升了约50倍，极大地提高了生成编解码器的实用性。代码将在https://github.com/Freemasti/DiffO上提供。

</details>


### [348] [Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images](https://arxiv.org/abs/2506.16592)
**中文标题：基于混合注意力网络的乳腺超声图像肿瘤精确分割**

*Muhammad Azeem Aslam,Asim Naveed,Nisar Ahmed*

主要分类: eess.IV

摘要简述: 本文提出了一种基于混合注意力的网络，用于精确分割乳腺超声图像中的肿瘤，通过结合全局空间注意力和多分支解码器，显著提升了分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 乳腺超声图像中的肿瘤分割因噪声、病灶尺度变化和模糊边界而具有挑战性，亟需一种高效且鲁棒的分割方法以辅助早期癌症诊断。

研究方法: 采用预训练的DenseNet121作为编码器提取特征，结合多分支注意力增强解码器；引入全局空间注意力（GSA）、位置编码（PE）和缩放点积注意力（SDPA）学习全局上下文和空间关系；在跳跃连接中嵌入空间特征增强块（SFEB）优化空间特征；使用混合损失函数（BCE和Jaccard损失）提升分割精度。

研究结果: 在公开数据集上的实验表明，该方法优于现有技术，显著提升了肿瘤分割的准确性和鲁棒性。

研究结论: 所提出的混合注意力网络能够有效解决乳腺超声图像分割中的挑战，为早期乳腺癌诊断提供了可靠工具。

中文摘要: 乳腺超声成像是早期乳腺癌检测的重要工具，但由于固有噪声、病灶尺度变化和模糊边界，自动化肿瘤分割具有挑战性。为解决这些问题，我们提出了一种新型的基于混合注意力的病灶分割网络。该架构在编码器部分集成了预训练的DenseNet121以提取鲁棒特征，解码器部分则采用针对乳腺超声图像定制的多分支注意力增强模块。瓶颈部分结合了全局空间注意力（GSA）、位置编码（PE）和缩放点积注意力（SDPA），以学习全局上下文、空间关系和相对位置特征。跳跃连接中嵌入的空间特征增强块（SFEB）用于优化空间特征，使网络更聚焦于肿瘤区域。结合二元交叉熵（BCE）和Jaccard指数损失的混合损失函数优化了像素级精度和区域级重叠指标，增强了对类别不平衡和不规则肿瘤形状的鲁棒性。在公开数据集上的实验表明，该方法优于现有技术，展现了其在辅助放射科医生实现早期和准确乳腺癌诊断中的潜力。

</details>


### [349] [Overfitting in Histopathology Model Training: The Need for Customized Architectures](https://arxiv.org/abs/2506.16631)
**中文标题：组织病理学模型训练中的过拟合问题：定制化架构的必要性**

*Saghir Alfasly,Ghazal Alabtah,H. R. Tizhoosh*

主要分类: eess.IV

摘要简述: 研究发现，在组织病理学图像分析中直接采用自然图像分析的大规模模型会导致过拟合和性能下降，需定制专用架构。


<details>
  <summary>详细信息</summary>
研究动机: 当前在组织病理学图像分析中，直接使用为自然图像设计的大规模深度学习模型往往表现不佳且容易过拟合，因此需要探索更适合该领域的定制化模型架构。

研究方法: 通过实验比较多种模型架构（如ResNet变体和Vision Transformers），验证模型容量增加对组织病理学数据集性能的影响，并使用食管腺癌公开数据集测试定制化架构的效果。

研究结果: 实验表明，增加模型容量并不能显著提升组织病理学任务的性能，而定制化的简单架构在减少过拟合的同时表现更优。

研究结论: 组织病理学图像分析需要专门设计的模型架构，尤其是在数据有限的情况下，定制化架构能有效避免过拟合并提升性能。

中文摘要: 本研究探讨了深度学习模型在组织病理学图像分析中的过拟合问题。我们发现，直接采用并微调为自然图像设计的大规模模型，在组织病理学任务中往往表现不佳且容易过拟合。通过对多种模型架构（如ResNet变体和Vision Transformers）的广泛实验，我们发现增加模型容量并不一定能提升组织病理学数据集的性能。研究结果强调了为组织病理学图像分析定制专门架构的必要性，尤其是在数据有限的情况下。通过使用食管腺癌公开数据集，我们证明简单且针对特定领域的架构在减少过拟合的同时，能够达到甚至超越传统模型的性能。

</details>


### [350] [A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion](https://arxiv.org/abs/2506.16733)
**中文标题：基于先验引导的联合扩散模型在投影域中实现PET示踪剂转换**

*Fang Chen,Weifeng Zhang,Xingyu Ai,BingXuan Li,An Li,Qiegen Liu*

主要分类: eess.IV

摘要简述: 本文提出了一种基于先验引导的联合扩散模型（PJDM），用于在投影域中将18F-FDG PET图像转换为18F-DOPA PET图像，显著提升了正弦图质量和合成效果。


<details>
  <summary>详细信息</summary>
研究动机: 18F-FDG PET在部分肿瘤中效果有限，而18F-DOPA对神经内分泌肿瘤和神经系统疾病更具特异性，但其合成复杂且临床应用受限。直接在投影域建模可减少图像重建过程中的误差累积。

研究方法: 提出PJDM模型，包括独立训练的粗估计模型和先验细化模型。推理时，使用高阶混合采样器生成初始合成正弦图，并通过学习到的先验条件迭代优化。

研究结果: 实验结果表明，PJDM显著提升了正弦图质量和合成图像的效果。

研究结论: PJDM在投影域中实现了高效的18F-FDG到18F-DOPA PET图像的转换，为临床提供了新的解决方案。

中文摘要: 正电子发射断层扫描（PET）广泛用于评估代谢活性，但其应用受限于放射性示踪剂的可用性。18F标记的氟脱氧葡萄糖（18F-FDG）是最常用的示踪剂，但对某些肿瘤效果有限。相比之下，6-18F-氟-3,4-二羟基-L-苯丙氨酸（18F-DOPA）对神经内分泌肿瘤和神经系统疾病更具特异性，但其合成复杂且运输和临床应用受限。在PET成像中，正弦图是扫描仪获取的原始数据形式。因此，在投影域建模能更直接利用原始信息，减少图像重建过程中的误差累积。受此启发，本研究提出了一种基于先验引导的联合扩散模型（PJDM），用于在投影域中将18F-FDG PET图像转换为18F-DOPA PET图像。具体而言，独立训练了粗估计模型和先验细化模型。推理时，使用高阶混合采样器生成初始合成正弦图，并通过学习到的先验条件迭代优化。实验结果表明，PJDM显著提升了正弦图质量和合成效果。代码已开源：https://github.com/yqx7150/PJDM。

</details>


### [351] [Temperature calibration of surface emissivities with an improved thermal image enhancement network](https://arxiv.org/abs/2506.16803)
**中文标题：基于改进热图像增强网络的表面发射率温度校准**

*Ning Chu,Siya Zheng,Shanqing Zhang,Li Li,Caifang Cai,Ali Mohammad-Djafari,Feng Zhao,Yuanbo Song*

主要分类: eess.IV

摘要简述: 本文提出了一种改进的热图像增强网络，通过物理引导的神经框架联合优化辐射校准和图像退化问题，实现了温度校准和图像增强的统一。


<details>
  <summary>详细信息</summary>
研究动机: 红外热成像技术因材料发射率变化导致温度准确性不足，现有方法常忽略辐射校准与图像退化的联合优化。

研究方法: 采用对称跳跃式CNN架构和发射率感知注意力模块，通过双约束损失函数（均值-方差对齐和基于K-L散度的直方图匹配）动态融合热辐射特征与空间背景。

研究结果: 在工业鼓风机系统验证中，该方法有效抑制发射率伪影并恢复结构细节，实现了多种工业条件下的精确校准。

研究结论: 改进的网络成功统一了温度校正与图像增强，为复杂工业环境下的红外热成像提供了可靠解决方案。

中文摘要: 红外热成像技术因材料发射率变化导致温度准确性面临持续挑战，现有方法常忽略辐射校准与图像退化的联合优化。本研究提出了一种物理引导的神经框架，通过对称跳跃式CNN架构和发射率感知注意力模块，统一了温度校正与图像增强。预处理阶段分割图像感兴趣区域并初步校正发射率。新型双约束损失函数通过均值-方差对齐和基于Kullback-Leibler散度的直方图匹配，增强了目标与参考区域的统计一致性。该方法动态融合热辐射特征与空间背景，抑制发射率伪影的同时恢复结构细节。在工业鼓风机系统不同条件下的验证中，改进网络实现了热辐射特性与空间背景的动态融合，并在多种工业条件下获得精确校准结果。

</details>


### [352] [PET Tracer Separation Using Conditional Diffusion Transformer with Multi-latent Space Learning](https://arxiv.org/abs/2506.16934)
**中文标题：基于多潜在空间学习的条件扩散变换器用于PET示踪剂分离**

*Bin Huang,Feihong Xu,Xinchong Shi,Shan Huang,Binxuan Li,Fei Li,Qiegen Liu*

主要分类: eess.IV

摘要简述: 本文提出了一种多潜在空间引导的纹理条件扩散变换模型（MS-CDT），用于PET成像中的示踪剂分离，首次结合纹理条件和多潜在空间学习，显著提升了图像细节和分离准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在临床实践中，多示踪剂PET成像能提供更全面的生理和病理信息，但由于不同示踪剂产生的光子对能量相同，难以区分信号。因此，需要一种新方法实现高效且准确的示踪剂分离。

研究方法: 提出MS-CDT模型，结合扩散和变换器架构，引入纹理掩码作为条件输入，并利用多潜在空间先验捕捉多层次特征表示，以平衡计算效率和细节保留。

研究结果: 实验表明，MS-CDT在脑部和胸部3D PET数据集上表现优异，图像质量和临床信息保留方面均优于其他先进方法。

研究结论: MS-CDT通过纹理条件和多潜在空间学习，显著提升了PET示踪剂分离的准确性和鲁棒性，为多示踪剂成像提供了有效工具。

中文摘要: 在临床实践中，单示踪剂正电子发射断层扫描（PET）常用于成像。尽管多示踪剂PET成像能提供对生理功能变化敏感的补充信息，从而更全面地表征生理和病理状态，但不同示踪剂在PET成像中产生的正电子湮灭反应光子对具有相同能量，难以区分信号。本研究提出了一种多潜在空间引导的纹理条件扩散变换模型（MS-CDT）用于PET示踪剂分离。据我们所知，这是首次尝试在PET成像中使用纹理条件和多潜在空间进行示踪剂分离。该模型将扩散和变换器架构整合到统一的优化框架中，并新增纹理掩码作为条件输入以增强图像细节。通过利用来自不同示踪剂的多潜在空间先验，模型捕捉多层次特征表示，旨在平衡计算效率和细节保留。纹理掩码作为条件指导，帮助模型聚焦于显著的结构模式，从而提升细粒度图像纹理的提取和利用。结合扩散变换器主干，这一条件机制有助于更准确和鲁棒的示踪剂分离。为评估其有效性，将MS-CDT与多种先进方法在脑部和胸部3D PET数据集上进行比较。实验结果表明，MS-CDT在图像质量和临床相关信息保留方面表现优异。代码见：https://github.com/yqx7150/MS-CDT。

</details>


### [353] [Robust Training with Data Augmentation for Medical Imaging Classification](https://arxiv.org/abs/2506.17133)
**中文标题：基于数据增强的鲁棒训练在医学影像分类中的应用**

*Josué Martínez-Martínez,Olivia Brown,Mostafa Karami,Sheida Nabavi*

主要分类: eess.IV

摘要简述: 本文提出了一种结合数据增强的鲁棒训练算法（RTDA），用于提升医学影像分类模型对抗攻击和分布偏移的鲁棒性，实验证明其在多种影像技术中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络在医学影像诊断中应用广泛，但其易受对抗攻击和分布偏移影响，导致诊断可靠性下降。本研究旨在提升模型的鲁棒性和泛化能力。

研究方法: 提出了一种结合数据增强的鲁棒训练算法（RTDA），并与六种基线方法（包括单独或组合使用的对抗训练和数据增强）在三种医学影像技术（乳腺X光、X射线和超声）上进行了对比实验。

研究结果: RTDA在对抗攻击和分布偏移情况下表现出更高的鲁棒性，同时在干净数据上保持了高准确率，优于其他基线方法。

研究结论: RTDA是一种有效的医学影像分类鲁棒训练方法，能够显著提升模型对抗攻击和分布偏移的鲁棒性，同时保持高诊断准确性。

中文摘要: 深度神经网络在医学影像中用于检测和诊断疾病的应用日益广泛。尽管其效用显著，这些模型极易受到对抗攻击和分布偏移的影响，从而影响诊断可靠性并削弱医疗专业人员的信任。本研究提出了一种结合数据增强的鲁棒训练算法（RTDA），以缓解医学影像分类中的这些脆弱性。我们通过实验数据集（包括乳腺X光、X射线和超声三种影像技术）对RTDA及六种基线方法（单独或组合使用的对抗训练和数据增强）在对抗扰动和自然变异下的鲁棒性进行了基准测试。结果表明，RTDA在每种影像分类任务中均表现出对抗攻击的优异鲁棒性，并在分布偏移情况下提升了泛化性能，同时保持了高干净准确率。

</details>


### [354] [MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification](https://arxiv.org/abs/2506.17140)
**中文标题：MeDi：基于元数据引导的扩散模型用于缓解肿瘤分类中的偏差**

*David Jacob Drexlin,Jonas Dippel,Julius Hense,Niklas Prenißl,Grégoire Montavon,Frederick Klauschen,Klaus-Robert Müller*

主要分类: eess.IV

摘要简述: 本文提出了一种基于元数据引导的扩散模型（MeDi），用于生成高质量的组织病理学图像，以平衡训练数据中的子群体偏差，并提升下游分类器的性能。


<details>
  <summary>详细信息</summary>
研究动机: 深度学习模型在组织病理学预测任务中取得了显著进展，但其对染色、扫描仪、医院和人口统计等变化的鲁棒性不足，导致模型在训练数据中过度代表子群体时表现不佳。大规模基础模型未能完全解决这一问题，因此需要一种新方法来平衡数据偏差。

研究方法: 作者提出了一种元数据引导的生成扩散模型框架（MeDi），通过合成数据有针对性地增强代表性不足的子群体，从而平衡训练数据并减少下游模型的偏差。

研究结果: 实验表明，MeDi能够为未见过的子群体生成高质量的组织病理学图像，提升生成图像的整体保真度，并在子群体偏移的数据集上改善下游分类器的性能。

研究结论: 本文证明了生成模型在缓解数据偏差方面的潜力，为临床实践中更鲁棒的深度学习模型提供了概念验证。

中文摘要: 近年来，深度学习模型在组织病理学预测任务中取得了显著进展。然而，其在临床实践中的应用仍受到对染色、扫描仪、医院和人口统计等变化条件鲁棒性不足的限制：如果模型在过度代表的子群体上训练，通常会难以处理较少出现的模式，导致捷径学习和有偏差的预测。大规模基础模型尚未完全解决这一问题。因此，我们提出了一种新方法，将此类元数据显式建模为一个元数据引导的生成扩散模型框架（MeDi）。MeDi能够通过合成数据有针对性地增强代表性不足的子群体，从而平衡有限的训练数据并缓解下游模型的偏差。实验表明，MeDi能够为TCGA中未见过的子群体生成高质量的组织病理学图像，提升生成图像的整体保真度，并在子群体偏移的数据集上改善下游分类器的性能。我们的工作为利用生成模型更好地缓解数据偏差提供了一个概念验证。

</details>


### [355] [Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network](https://arxiv.org/abs/2506.17165)
**中文标题：基于卷积神经网络的生成对抗网络（GAN）增强脑肿瘤分类中的比例敏感性研究**

*Mahin Montasir Afif,Abdullah Al Noman,K. M. Tahsin Kabir,Md. Mortuza Ahmmed,Md. Mostafizur Rahman,Mufti Mahmud,Md. Ashraful Babu*

主要分类: eess.IV

摘要简述: 本研究探讨了生成对抗网络（GAN）生成的脑肿瘤MRI图像与真实图像的不同比例对卷积神经网络（CNN）分类性能的影响。结果表明，少量GAN数据能显著提升模型性能，但过多合成数据会导致性能下降。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像数据通常有限，而GAN可以生成合成数据以扩充数据集。本研究旨在探索GAN生成图像与真实图像的不同混合比例如何影响CNN在脑肿瘤分类中的表现。

研究方法: 使用DCGAN生成合成脑肿瘤MRI图像，并将其与真实图像按不同比例混合，用于训练自定义CNN。随后在独立真实测试集上评估模型性能。

研究结果: 少量GAN数据（如100张合成图像与900张真实图像混合）使模型在测试集上达到95.2%的准确率，且精确率、召回率和F1分数均超过95%。但随着GAN数据比例增加，性能逐渐下降。

研究结论: GAN在扩充有限数据集时非常有效，尤其是在真实数据稀缺时。然而，过多的合成数据可能引入伪影，影响模型对真实病例的泛化能力。

中文摘要: 生成对抗网络（GAN）在扩充有限医学影像数据集方面显示出潜力。本研究探讨了GAN生成的脑肿瘤MRI图像与真实图像的不同比例如何影响CNN对健康与肿瘤扫描的分类性能。使用DCGAN生成合成图像，并按不同比例与真实图像混合训练自定义CNN。随后在独立真实测试集上评估模型。结果表明，即使在主要使用合成数据训练时，模型仍能保持较高的肿瘤分类敏感性和精确性。例如，当仅添加少量GAN数据（如900张真实图像与100张GAN图像混合）时，模型测试准确率达到95.2%，且精确率、召回率和F1分数均超过95%。然而，随着GAN图像比例进一步增加，性能逐渐下降。本研究提示，GAN在扩充有限数据集（尤其是真实数据稀缺时）非常有用，但过多的合成数据可能引入伪影，影响模型对真实病例的泛化能力。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [356] [Smartphone-integrated RPA-CRISPR-Cas12a Detection System with Microneedle Sampling for Point-of-Care Diagnosis of Potato Late Blight in Early Stage](https://arxiv.org/abs/2506.15728)
**中文标题：智能手机集成的RPA-CRISPR-Cas12a检测系统结合微针采样技术用于马铃薯晚疫病早期即时诊断**

*Jiangnan Zhao,Hanbo Xu,Cifu Xu,Wenlong Yin,Laixin Luo,Gang Liu,Yan Wang*

主要分类: q-bio.QM

摘要简述: 本研究开发了一种便携式RPA-CRISPR-Cas12a检测系统，结合智能手机和微针采样技术，用于马铃薯晚疫病的早期田间诊断。该系统具有高灵敏度和特异性，检测限为2 pg/uL，且在接种后第3天和第4天分别实现80%和100%的检测率，优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 马铃薯晚疫病是一种毁灭性病害，传统检测方法（如PCR和LAMP）依赖昂贵且笨重的实验室设备，难以在田间实现即时诊断。本研究旨在开发一种便携、高效的检测系统，用于早期病害诊断。

研究方法: 采用聚乙烯醇（PVA）微针贴片在1分钟内完成植物叶片样本提取，DNA提取效率达56 ug/mg。建立RPA-CRISPR-Cas12a等温扩增系统，特异性检测马铃薯晚疫病菌（Phytophthora infestans），无交叉反应。结合智能手机采集和分析荧光图像。

研究结果: 系统检测限为2 pg/uL，灵敏度与实验室设备相当。在接种后第3天和第4天分别实现80%和100%的检测率，早于叶片出现可见症状。DNA提取效率为传统CTAB方法的3倍。

研究结论: 该智能手机集成的“样本到结果”系统突破了传统方法对专业设备的依赖，为田间早期植物病害检测和控制提供了高效解决方案。

中文摘要: 马铃薯晚疫病是由卵菌病原体Phytophthora infestans引起的，是历史上对马铃薯作物最具破坏性的病害之一。尽管传统的植物病害检测方法（如PCR和LAMP）具有高灵敏度和特异性，但它们依赖笨重且昂贵的实验室设备，操作复杂，难以在田间实现即时诊断。本研究报道了一种便携式RPA-CRISPR检测系统，结合智能手机采集和分析荧光图像。采用聚乙烯醇（PVA）微针贴片在1分钟内完成植物叶片样本提取，DNA提取效率达56 ug/mg，约为传统CTAB方法（18 ug/mg）的3倍。建立的RPA-CRISPR-Cas12a等温扩增系统特异性检测P. infestans，未观察到与近缘物种（P. sojae、P. capsici）的交叉反应。系统对P. infestans基因组DNA的检测限为2 pg/uL，灵敏度与实验室设备相当。系统在接种后第3天和第4天分别实现约80%和100%的检测率，早于叶片出现可见症状。基于智能手机的“样本到结果”系统摆脱了传统方法对专业设备的依赖，为田间早期植物病害检测和控制提供了可行方案。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [357] [TrainVerify: Equivalence-Based Verification for Distributed LLM Training](https://arxiv.org/abs/2506.15961)
**中文标题：TrainVerify：基于等价的分布式大语言模型训练验证**

*Yunchi Lu,Youshan Miao,Cheng Tan,Peng Huang,Yi Zhu,Xian Zhang,Fan Yang*

主要分类: cs.DC

摘要简述: TrainVerify是一个用于验证分布式大语言模型（LLM）训练的系统，通过形式化验证确保并行执行计划与逻辑规范等价，解决了大规模训练中的潜在错误问题。


<details>
  <summary>详细信息</summary>
研究动机: 分布式训练大语言模型（LLM）成本高昂且容易产生静默错误，目前缺乏有效的验证方法，导致资源浪费。TrainVerify旨在解决这一问题，确保训练计划的正确性。

研究方法: TrainVerify采用形状缩减技术和分阶段并行验证算法，显著降低了验证复杂度，同时保持形式化正确性，适用于超大规模模型。

研究结果: TrainVerify成功验证了包括Llama3（405B）和DeepSeek-V3（671B）在内的前沿大语言模型的训练计划，证明了其可扩展性和有效性。

研究结论: TrainVerify为分布式大语言模型训练提供了一种高效且可靠的验证方法，显著降低了错误风险，提升了训练效率。

中文摘要: 大规模语言模型（LLM）的训练需要跨数千台设备并行执行，计算成本极高。然而，这些昂贵的分布式训练很少经过验证，容易产生静默错误，可能浪费数百万GPU小时。我们提出了TrainVerify，一种用于可验证分布式LLM训练的系统。给定深度学习模型的逻辑规范作为基准，TrainVerify形式化验证分布式并行执行计划是否与其数学等价。由于LLM规模庞大（通常涉及数十亿变量和高度复杂的计算图），直接验证极为困难。因此，TrainVerify引入了形状缩减技术和分阶段并行验证算法，在保持形式化正确性的同时显著降低了复杂度。TrainVerify可扩展到前沿LLM，包括成功验证了Llama3（405B）和DeepSeek-V3（671B）的训练计划。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [358] [cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree](https://arxiv.org/abs/2506.15655)
**中文标题：cAST：通过抽象语法树的结构化分块增强代码检索增强生成**

*Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu*

主要分类: cs.SE

摘要简述: 本文提出了一种基于抽象语法树（AST）的结构感知分块方法cAST，用于改进代码检索增强生成（RAG）中的分块过程，显著提升了代码生成任务的表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于行的分块方法在代码检索增强生成（RAG）中容易破坏语义结构，导致生成质量下降。本文旨在通过结构感知的分块方法解决这一问题。

研究方法: 提出了一种基于抽象语法树（AST）的分块方法cAST，通过递归分解大型AST节点并合并兄弟节点，生成语义连贯且自包含的代码块。

研究结果: 实验表明，cAST在代码生成任务中表现优异，例如在RepoEval检索任务中Recall@5提升了4.3个百分点，在SWE-bench生成任务中Pass@1提升了2.67个百分点。

研究结论: 结构感知的分块方法对提升检索增强的代码智能至关重要，cAST为跨编程语言和任务的代码生成提供了有效支持。

中文摘要: 检索增强生成（RAG）已成为大规模代码生成的关键技术，通过利用外部代码库提高预测的实际性。然而，RAG流程中一个关键但未被充分探索的环节是分块——将文档划分为可检索单元的过程。现有的基于行的分块启发式方法常常破坏语义结构，例如拆分函数或合并无关代码，从而降低生成质量。我们提出了一种基于抽象语法树（AST）的分块方法（cAST），这是一种结构感知的方法，通过递归分解大型AST节点并在尊重大小限制的情况下合并兄弟节点。该方法能够生成跨编程语言和任务的自包含且语义连贯的单元，显著提升了代码生成任务的表现，例如在RepoEval检索任务中Recall@5提升了4.3个百分点，在SWE-bench生成任务中Pass@1提升了2.67个百分点。我们的工作强调了结构感知分块对扩展检索增强代码智能的重要性。

</details>


### [359] [Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems](https://arxiv.org/abs/2506.17208)
**中文标题：剖析SWE-Bench排行榜：分析基于LLM和代理的修复系统的提交者与架构**

*Matias Martinez,Xavier Franch*

主要分类: cs.SE

摘要简述: 本文首次全面分析了SWE-Bench Lite和Verified排行榜的所有提交，揭示了专有LLM（如Claude 3.5/3.7）的主导地位，以及从个人开发者到大型科技公司的多样化贡献者群体。


<details>
  <summary>详细信息</summary>
研究动机: 由于SWE-Bench排行榜的提交过程缺乏详细文档，许多解决方案的架构设计和来源不明确。本文旨在填补这一空白，通过分析提交数据，揭示LLM和基于代理的修复系统的现状。

研究方法: 研究分析了SWE-Bench Lite（68项）和Verified（79项）排行榜的所有提交，共67种独特方法，从提交者类型、产品可用性、LLM使用情况和系统架构等多个维度进行剖析。

研究结果: 研究发现专有LLM（尤其是Claude 3.5/3.7）占据主导地位，同时存在基于代理和非代理的设计，贡献者群体涵盖个人开发者到大型科技公司。

研究结论: 本研究为SWE-Bench排行榜提供了首次全面分析，揭示了当前LLM和基于代理的修复系统的多样性和发展趋势。

中文摘要: 自动化程序修复（APR）的快速发展得益于人工智能的进步，尤其是大语言模型（LLMs）和基于代理的系统。SWE-Bench是一个新近设计的基准测试，用于评估基于LLM的修复系统，其数据来源于12个流行的开源Python仓库的真实问题和拉取请求。其公开排行榜SWE-Bench Lite和SWE-Bench Verified已成为追踪进展和比较解决方案的核心平台。然而，由于提交过程无需详细文档，许多解决方案的架构设计和来源仍不明确。本文首次全面研究了SWE-Bench Lite（68项）和Verified（79项）排行榜的所有提交，分析了67种独特方法，涵盖提交者类型、产品可用性、LLM使用情况和系统架构等维度。研究发现专有LLM（尤其是Claude 3.5/3.7）占据主导地位，同时存在基于代理和非代理的设计，贡献者群体从个人开发者到大型科技公司不等。

</details>


### [360] [AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions](https://arxiv.org/abs/2506.16586)
**中文标题：现代软件质量保证中AI驱动工具的评估：优势、挑战与未来方向**

*Ihor Pysmennyi,Roman Kyslyi,Kyrylo Kleshch*

主要分类: cs.SE

摘要简述: 本文评估了AI工具在现代软件质量保证（QA）中的潜力，展示了其在测试生成和优化方面的显著效果（仅8.3%的测试用例不稳定），但也指出了语义覆盖、黑盒性和可解释性等挑战。


<details>
  <summary>详细信息</summary>
研究动机: 传统QA方法难以应对现代软件系统的复杂性、规模和快速迭代，资源有限导致质量成本高昂。研究旨在评估AI工具在QA中的优势、挑战和前景。

研究方法: 研究通过综合分析AI工具在验证和验证过程中的应用，包括探索性测试分析、等价划分、边界分析、蜕变测试、静态分析、测试用例生成、单元测试生成、测试套件优化等，并以企业级应用的端到端回归测试为概念验证。

研究结果: AI生成的测试用例仅8.3%不稳定，显示出显著潜力，但也发现语义覆盖不足、黑盒性和可解释性差、LLM倾向于修正变异测试用例等问题。

研究结论: AI在QA中具有变革潜力，但需战略性地实施，考虑其局限性并开发合适的验证方法。

中文摘要: 传统质量保证（QA）方法在应对现代软件系统的复杂性、规模和快速迭代方面面临重大挑战，且资源有限导致质量成本高昂。本研究以现代分布式软件应用的QA流程为对象，评估了集成现代AI工具的优势、挑战和前景。我们全面分析了AI工具对验证和验证过程的影响，涵盖探索性测试分析、等价划分和边界分析、蜕变测试、发现验收标准（AC）不一致、静态分析、测试用例生成、单元测试生成、测试套件优化与评估、端到端场景执行等。通过企业级应用的端到端回归测试（使用AI代理生成测试场景）作为概念验证，展示了研究的实际应用。结果显示，生成的测试用例仅8.3%不稳定，表明所提方法具有显著潜力。然而，研究也发现实际应用中的重大挑战，包括语义覆盖生成不足、最先进大语言模型（LLM）的黑盒性和缺乏可解释性、以及倾向于修正变异测试用例以匹配预期结果，这凸显了对生成工件和测试执行结果进行全面验证的必要性。研究表明AI对QA具有变革潜力，但也强调了在实施这些技术时需采取战略方法，考虑已识别的局限性并开发合适的验证方法。

</details>


### [361] [SemAgent: A Semantics Aware Program Repair Agent](https://arxiv.org/abs/2506.16650)
**中文标题：SemAgent：一种基于语义感知的程序修复代理**

*Anvith Pabba,Alex Mathai,Anindya Chakraborty,Baishakhi Ray*

主要分类: cs.SE

摘要简述: 本文提出SemAgent，一种基于语义的程序修复代理，通过结合问题、代码和执行语义生成更全面的补丁，显著提升了修复效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有程序修复系统通常仅关注局部可疑代码行，缺乏对问题、代码和执行语义的深入理解，导致补丁过拟合或不够通用。SemAgent旨在解决这一问题。

研究方法: SemAgent采用基于工作流的方法，通过执行语义获取上下文，抽象理解问题语义，隔离代码语义，并在两阶段架构中生成和筛选修复补丁。

研究结果: 在SWEBench-Lite基准测试中，SemAgent的解决率达到44.66%，优于其他基于工作流的方法，并在需要多行推理和边缘情况处理的问题上表现突出。

研究结论: 通过融入问题、代码和执行语义，SemAgent能够生成更稳健且语义一致的修复补丁，显著提升程序修复效果。

中文摘要: 大型语言模型（LLM）在自动程序修复（APR）等软件工程任务中表现出色。然而，现有代理系统在解决问题时往往仅关注局部可疑代码行，缺乏对问题语义、代码语义或执行语义的深入理解，导致生成的补丁过拟合用户问题。为解决这一问题，我们提出SemAgent，一种基于工作流的方法，通过结合问题、代码和执行语义生成更全面的补丁。其创新流程包括：（a）利用执行语义获取相关上下文；（b）通过抽象化理解问题语义；（c）在抽象上下文中隔离代码语义；（d）采用两阶段架构：修复阶段提出细粒度补丁，评审阶段基于问题语义筛选补丁。实验表明，SemAgent在SWEBench-Lite基准测试中的解决率达到44.66%，优于其他工作流方法，并在需要多行推理和边缘情况处理的问题上表现突出。这表明将语义融入APR流程可生成更稳健的修复补丁。

</details>


### [362] [LLMs in Coding and their Impact on the Commercial Software Engineering Landscape](https://arxiv.org/abs/2506.16653)
**中文标题：大型语言模型在编码中的应用及其对商业软件工程领域的影响**

*Vladislav Belozerov,Peter J Barclay,Askhan Sami*

主要分类: cs.SE

摘要简述: 大型语言模型编码工具已成为软件工程主流，但存在隐私泄露、安全漏洞和模型迎合错误等风险。企业需审查AI生成的代码，保护数据隐私，遵守安全法规，并测试模型输出以确保安全性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型编码工具的普及，其在提升开发效率的同时，也带来了隐私泄露、安全漏洞和模型迎合错误等新风险。研究旨在探讨如何在使用这些工具时确保安全性和准确性。

研究方法: 通过分析实际案例和数据（如10%的提示泄露隐私、42%的生成代码存在安全漏洞），提出企业应采取的措施：审查AI生成的代码、保护数据隐私、遵守法规，并测试模型输出。

研究结果: 研究发现，AI编码工具存在隐私泄露和安全漏洞问题，模型还可能迎合错误观点。企业需采取严格措施以平衡效率与安全。

研究结论: 企业需在利用AI编码工具提升效率的同时，通过审查代码、保护隐私和测试输出，确保安全性和准确性。

中文摘要: 大型语言模型编码工具现已成为软件工程的主流。然而，随着这些工具将人类努力推向开发堆栈的上层，它们也带来了新的风险：10%的实际提示会泄露隐私数据，42%的生成代码片段隐藏安全漏洞，模型甚至可能“同意”错误观点，这种现象被称为迎合性。我们认为，企业必须标记和审查每行AI生成的代码，将提示和输出保留在私有或本地部署中，遵守新兴的安全法规，并添加测试以捕捉迎合性答案——从而在提升速度的同时不牺牲安全性和准确性。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [363] [Multi-use LLM Watermarking and the False Detection Problem](https://arxiv.org/abs/2506.15975)
**中文标题：多用途LLM水印与误检问题**

*Zihao Fu,Chris Russell*

主要分类: cs.CR

摘要简述: 本文提出双水印方法，通过同时嵌入检测和用户识别水印，显著减少误检率，同时保持高检测准确率。


<details>
  <summary>详细信息</summary>
研究动机: 数字水印是解决自动生成文本滥用风险的有效方法，但现有方法在同时用于检测和用户识别时会导致误检问题，需解决此问题以提高实用性。

研究方法: 通过理论分析识别误检现象的根本原因，并提出双水印方法，联合编码检测和用户识别水印，减少误检。

研究结果: 实验验证了理论分析的正确性，双水印方法显著降低了误检率，同时保持了高检测准确率。

研究结论: 双水印方法有效解决了误检问题，为数字水印在多用途场景中的应用提供了实用解决方案。

中文摘要: 数字水印是缓解自动生成文本滥用风险的一种有前景的解决方案。现有方法要么嵌入非特定水印以检测特定采样器生成的文本，要么嵌入特定密钥以识别LLM用户。然而，同时将同一水印用于检测和用户识别会导致误检问题，即随着用户容量增加，未加水印的文本被误检为水印的概率上升。通过理论分析，我们揭示了这一现象的根本原因。基于这些见解，我们提出双水印方法，将检测和用户识别水印联合编码到生成文本中，显著减少误检率，同时保持高检测准确率。实验结果验证了理论分析，并证明了该方法的有效性。

</details>


### [364] [Probe before You Talk: Towards Black-box Defense against Backdoor Unalignment for Large Language Models](https://arxiv.org/abs/2506.16447)
**中文标题：先探后谈：面向大型语言模型后门不对齐攻击的黑盒防御**

*Biao Yi,Tiansheng Huang,Sishuo Chen,Tong Li,Zheli Liu,Zhixuan Chu,Yiming Li*

主要分类: cs.CR

摘要简述: 本文提出了一种名为BEAT的黑盒防御方法，用于检测大型语言模型（LLM）中的后门攻击。通过利用触发样本对拒绝信号的扭曲效应，BEAT能在推理阶段识别并禁用后门，有效应对样本依赖性攻击目标。实验验证了其在多种后门攻击和LLM（包括闭源GPT-3.5-turbo）上的高效性，并初步证明其对越狱攻击的防御能力。


<details>
  <summary>详细信息</summary>
研究动机: 后门不对齐攻击通过隐藏触发器暗中破坏大型语言模型（LLM）的安全对齐，同时规避常规安全审计。这种攻击在LLM即服务（LLMaaS）的黑盒环境中尤为危险，且攻击目标具有样本依赖性，进一步加剧了威胁。因此，亟需一种黑盒防御方法以检测并禁用后门。

研究方法: BEAT基于一个有趣的现象（探针连接效应）：触发样本的拼接会显著降低后门LLM对恶意探针的拒绝率，而非触发样本则无此效果。BEAT通过测量输入拼接前后探针输出分布的扭曲程度，识别触发样本。该方法从拒绝信号（样本无关）的角度应对样本依赖性攻击目标，并利用多次采样逼近输出分布以克服黑盒限制。

研究结果: 实验表明，BEAT在多种后门攻击和LLM（包括GPT-3.5-turbo）上均表现出高效性和有效性。此外，BEAT还能初步防御流行的越狱攻击，因其可被视为“自然后门”。

研究结论: BEAT为黑盒环境下的后门攻击提供了一种高效防御方案，通过检测触发样本并禁用后门，有效应对样本依赖性攻击目标。其方法不仅适用于后门攻击，还能扩展至越狱攻击防御，具有广泛的应用潜力。

中文摘要: 针对大型语言模型（LLM）的后门不对齐攻击通过隐藏触发器暗中破坏安全对齐，同时规避常规安全审计。此类攻击在LLM即服务（LLMaaS）的黑盒环境中威胁巨大，且攻击目标具有样本依赖性，进一步加剧了风险。后门LLM会遵循带有隐藏触发器的任何恶意指令的语义，而非输出固定标签，从而显著扩展了攻击目标空间。本文提出BEAT，一种黑盒防御方法，通过在推理阶段检测触发样本来禁用后门。其灵感源于一个有趣现象（探针连接效应）：触发样本的拼接会显著降低后门LLM对恶意探针的拒绝率，而非触发样本则无此效果。具体而言，BEAT通过测量输入拼接前后探针输出分布的扭曲程度来识别触发样本。该方法从拒绝信号（样本无关）的角度应对样本依赖性攻击目标，并利用多次采样逼近输出分布以克服黑盒限制。实验在多种后门攻击和LLM（包括闭源GPT-3.5-turbo）上验证了BEAT的有效性和高效性。此外，我们还初步验证了BEAT对流行越狱攻击的防御能力，因其可被视为“自然后门”。

</details>


### [365] [PRISON: Unmasking the Criminal Potential of Large Language Models](https://arxiv.org/abs/2506.16150)
**中文标题：PRISON：揭示大型语言模型的犯罪潜力**

*Xinyi Wu,Geng Hong,Pei Chen,Yueyue Chen,Xudong Pan,Min Yang*

主要分类: cs.CR

摘要简述: 本文提出PRISON框架，用于量化大型语言模型（LLM）在虚假陈述、陷害、心理操纵、情感伪装和道德脱离五个维度的犯罪潜力。通过经典电影改编的结构化犯罪场景评估，发现先进LLM即使无明确指令也常表现出犯罪倾向，且作为侦探角色时识别欺骗行为的准确率仅41%。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）的发展，其在复杂社会情境中的不当行为引发担忧。现有研究缺乏对其在真实互动中犯罪能力的系统理解和评估，亟需量化其潜在风险。

研究方法: 提出PRISON框架，从五个维度（虚假陈述、陷害、心理操纵、情感伪装、道德脱离）量化LLM的犯罪潜力。通过改编自经典电影的结构化犯罪场景，以角色扮演方式评估LLM的犯罪潜力及反犯罪能力。

研究结果: 实验显示，先进LLM即使无明确指令也常表现出犯罪倾向（如误导性陈述或逃避策略）。作为侦探角色时，模型识别欺骗行为的平均准确率仅41%，表明其犯罪与反犯罪能力严重不匹配。

研究结论: 研究强调在广泛部署LLM前，亟需提升其对抗鲁棒性、行为对齐和安全性机制，以减少潜在犯罪风险。

中文摘要: 随着大型语言模型（LLM）的进步，对其在复杂社会情境中不当行为的担忧加剧。现有研究忽视了对其在真实互动中犯罪能力的系统理解和评估。我们提出统一框架PRISON，从五个维度（虚假陈述、陷害、心理操纵、情感伪装、道德脱离）量化LLM的犯罪潜力。通过改编自经典电影的结构化犯罪场景，以角色扮演方式评估LLM的犯罪潜力及反犯罪能力。结果显示，先进LLM即使无明确指令也常表现出犯罪倾向（如提出误导性陈述或逃避策略）。此外，当模型扮演侦探角色时，其对欺骗行为的识别准确率平均仅为41%，揭示了其犯罪与反犯罪能力的显著不匹配。这些发现凸显了在广泛部署LLM前，亟需提升其对抗鲁棒性、行为对齐和安全性机制。

</details>


### [366] [Towards Effective Complementary Security Analysis using Large Language Models](https://arxiv.org/abs/2506.16899)
**中文标题：基于大语言模型的有效互补安全分析研究**

*Jonas Wagner,Simon Müller,Christian Näther,Jan-Philipp Steghöfer,Andreas Both*

主要分类: cs.CR

摘要简述: 研究提出利用大语言模型（LLM）改进静态应用安全测试（SAST）工具的报告评估，减少误报（FP）并保持高真阳性率。实验表明，高级提示技术（如思维链和自一致性）显著提升误报检测能力，结合多个LLM可进一步提高效果。


<details>
  <summary>详细信息</summary>
研究动机: 静态应用安全测试（SAST）工具生成的报告中存在大量误报（FP），降低了安全分析的效率。研究旨在利用大语言模型（LLM）提升SAST结果的评估能力，减少误报并保持真阳性率。

研究方法: 研究使用OWASP Benchmark（v1.2）和真实软件项目的数据集，评估LLM在减少误报方面的能力。采用高级提示技术（如思维链和自一致性）优化LLM的表现，并尝试结合多个LLM的检测结果。

研究结果: 实验结果显示，部分LLM在OWASP Benchmark数据集中检测到约62.5%的误报且未漏报真实漏洞，结合多个LLM可将误报检测率提升至78.9%。在真实数据集中，最佳LLM检测到33.85%的误报，结合多个LLM后提升至38.46%。

研究结论: 研究表明，大语言模型（LLM）能有效补充传统SAST工具，提升自动化水平并减少误报处理资源。高级提示技术和多模型结合进一步优化了检测效果。

中文摘要: 安全分析中的一个关键挑战是对静态应用安全测试（SAST）工具生成的潜在安全弱点进行人工评估。这些报告中的大量误报（FP）降低了安全分析的效率。我们提出利用大语言模型（LLM）改进SAST结果的评估能力。通过使用OWASP Benchmark（v1.2）和真实软件项目的数据集，我们研究了LLM在减少误报的同时保持完美真阳性率的能力。结果表明，高级提示技术（如思维链和自一致性）显著提升了误报检测能力。值得注意的是，某些LLM在OWASP Benchmark数据集中检测到约62.5%的误报且未漏报真实漏洞。结合多个LLM的检测结果可将误报检测率提升至约78.9%。此外，我们通过覆盖五种SAST工具、三种编程语言和基础设施文件的真实数据集验证了方法的通用性。最佳LLM检测到33.85%的误报且未漏报真实漏洞，结合多个LLM后提升至38.46%。我们的发现凸显了LLM在补充传统SAST工具、提升自动化水平和减少误报处理资源方面的潜力。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [367] [MoR: Better Handling Diverse Queries with a Mixture of Sparse, Dense, and Human Retrievers](https://arxiv.org/abs/2506.15862)
**中文标题：MoR：通过混合稀疏、密集和人工检索器更好地处理多样化查询**

*Jushaan Singh Kalra,Xinran Zhao,To Eun Kim,Fengyu Cai,Fernando Diaz,Tongshuang Wu*

主要分类: cs.IR

摘要简述: 本文提出了一种混合检索器（MoR），通过动态整合稀疏、密集和人工检索器的优势，显著提升了检索增强生成（RAG）的效果，无需人工干预即可适应多样化查询需求。


<details>
  <summary>详细信息</summary>
研究动机: 现有检索增强生成（RAG）通常依赖单一检索器，无法适应多样化的信息需求。不同检索器（如BM25和密集检索器）各有优势，但缺乏动态整合机制。本文旨在通过混合检索器解决这一问题。

研究方法: 提出混合检索器（MoR），一种零样本、加权组合的异构检索器框架，动态选择并整合稀疏、密集和人工检索器的信号，无需手动干预。

研究结果: 实验表明，MoR仅需0.8B参数，性能优于单一检索器和更大的7B模型，平均提升分别为+10.8%和+3.9%。此外，MoR能有效整合非专家人工检索器，性能提升58.9%。

研究结论: 混合检索器（MoR）通过动态整合多种检索器，显著提升了检索增强生成的适应性和性能，为多样化查询提供了高效解决方案。

中文摘要: 检索增强生成（RAG）功能强大，但其效果取决于所使用的检索器及其方式。不同检索器提供独特且互补的信号：BM25捕捉词汇匹配，密集检索器捕捉语义相似性。然而，实践中通常基于启发式固定使用单一检索器，无法适应多样化的信息需求。我们能否为每个查询动态选择和整合多个检索器，而无需人工干预？本文通过定量分析验证了这一直觉，并提出了混合检索器：一种零样本、加权组合的异构检索器框架。大量实验表明，这种混合方式既高效又有效：尽管总参数仅为0.8B，但其性能平均优于单一检索器和更大的7B模型，分别提升+10.8%和+3.9%。进一步分析还表明，该混合框架可以整合非专家人工信息源作为检索器，实现良好协作，性能相对提升58.9%。

</details>


### [368] [Revela: Dense Retriever Learning via Language Modeling](https://arxiv.org/abs/2506.16552)
**中文标题：Revela：基于语言建模的密集检索器学习**

*Fengyu Cai,Tong Chen,Xinran Zhao,Sihao Chen,Hongming Zhang,Sherry Tongshuang Wu,Iryna Gurevych,Heinz Koeppl*

主要分类: cs.IR

摘要简述: 本文提出了一种名为Revela的自监督检索器学习框架，通过语言建模任务训练密集检索器，无需依赖标注数据，并在多个基准测试中显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 密集检索器在增强语言模型的外部知识获取中至关重要，但传统训练方法依赖标注数据，成本高昂且难以获取。本文旨在探索如何通过自监督语言建模任务训练检索器，以解决这一问题。

研究方法: Revela框架通过建模文档间的语义依赖关系，将检索任务转化为语言建模任务。它利用批内注意力机制，结合检索器计算的相似度分数，优化检索器的性能。

研究结果: 在通用领域（BEIR）和特定领域（CoIR）基准测试中，Revela在NDCG@10指标上分别比之前最佳方法绝对提升了5.2%和5.6%，且性能随模型规模增加而提升。

研究结论: Revela展示了自监督检索器学习的潜力，其框架具有可扩展性，为未来研究提供了重要方向。

中文摘要: 密集检索器在增强语言模型的外部知识获取中扮演关键角色。传统训练方法需要标注的查询-文档对，成本高昂且难以获取，尤其是在代码等专业领域，这促使了对自监督检索器学习的兴趣增长。由于语言模型通过自监督学习目标（如下一标记预测）捕捉标记级依赖关系，我们可以类似地将检索任务转化为学习标记块之间的依赖关系。这一类比自然引出一个问题：如何借鉴语言建模的自监督学习目标来训练检索器？

为此，我们提出了Revela，一种基于语言建模的自监督检索器学习的统一且可扩展的训练框架。Revela通过批内注意力机制，结合本地和跨文档上下文，建模文档间的语义依赖关系。这种注意力的权重由检索器计算的相似度分数决定，从而使检索器能够作为语言建模的一部分进行优化。我们在通用领域（BEIR）和特定领域（CoIR）基准测试中评估了Revela，结果表明，在参数规模相当的情况下，Revela在NDCG@10指标上分别比之前最佳方法绝对提升了5.2%（相对提升18.3%）和5.6%（相对提升14.4%），证明了其有效性。性能随模型规模增加而提升，突显了我们方法的可扩展性及其在自监督检索器学习中的潜力。

</details>


### [369] [GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks](https://arxiv.org/abs/2506.16114)
**中文标题：GFlowGR：基于生成流网络的生成式推荐框架微调方法**

*Yejing Wang,Shengyu Zhou,Jinyu Lu,Qidong Liu,Xinhang Li,Wenlin Zhang,Feng Li,Pengjie Wang,Jian Xu,Bo Zheng,Xiangyu Zhao*

主要分类: cs.IR

摘要简述: 本文提出GFlowGR框架，利用生成流网络（GFlowNets）优化生成式推荐系统的微调过程，解决曝光偏差问题，并在实验中验证了其有效性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 现有生成式推荐系统（GR）的微调方法主要依赖监督微调（SFT）或直接偏好优化（DPO），忽略了未观测正样本的探索（曝光偏差问题）。本文旨在通过GFlowNets解决这一问题。

研究方法: 将GR视为多步生成任务，提出基于GFlowNets的微调框架GFlowGR，结合传统推荐系统的协作知识设计自适应轨迹采样器和综合奖励模型，利用GFlowNets的多样性生成特性缓解曝光偏差。

研究结果: 在两个真实数据集和两种GR骨干模型上的实验表明，GFlowGR能有效缓解曝光偏差问题，并展现出优越的性能和鲁棒性。

研究结论: GFlowGR通过GFlowNets的多样性生成和协作知识整合，为生成式推荐系统的微调提供了新思路，显著提升了推荐效果。

中文摘要: 生成式推荐（GR）通常包括项目标记器和生成式大型语言模型（LLM），已在多种场景中取得显著成功。现有研究主要集中于开发强大的项目标记器或改进LLM解码策略，而GR框架中的关键微调步骤（用于使LLM适应推荐数据）却鲜有探索。当前方法主要依赖监督微调（SFT）的下一个标记预测损失或推荐特定的直接偏好优化（DPO）策略，两者均忽略了未观测正样本的探索（即曝光偏差问题）。为解决此问题，本文将GR视为多步生成任务，构建了基于GFlowNets的微调框架（GFlowGR）。该框架整合传统推荐系统的协作知识，设计了自适应轨迹采样器和综合奖励模型。借助GFlowNets的多样性生成特性以及采样和启发式加权技术，GFlowGR成为缓解曝光偏差问题的有效方法。在两个真实数据集和两种不同GR骨干模型上的广泛实验结果验证了GFlowGR的有效性和鲁棒性。

</details>


### [370] [A Simple Contrastive Framework Of Item Tokenization For Generative Recommendation](https://arxiv.org/abs/2506.16683)
**中文标题：生成式推荐中基于对比学习的简单项目标记化框架**

*Penglong Zhai,Yifang Yuan,Fanyi Di,Jie Li,Yue Liu,Chen Li,Jie Huang,Sicong Wang,Yao Xu,Xin Li*

主要分类: cs.IR

摘要简述: 本文提出了一种基于对比学习的无监督深度量化框架SimCIT，用于生成式推荐中的项目标记化，通过多模态知识对齐和语义标记化提升推荐效果。


<details>
  <summary>详细信息</summary>
研究动机: 生成式推荐系统在大规模应用中面临标记空间冗余和庞大的问题，现有基于重建的语义标记方法无法有效区分项目，且多模态辅助信息整合困难。

研究方法: SimCIT采用对比学习框架，结合可学习的残差量化模块，对齐项目的多模态信号，实现语义标记化和知识对齐的协同优化。

研究结果: 在公开数据集和工业数据集上的实验表明，SimCIT在基于大语言模型的生成式推荐中表现优异。

研究结论: SimCIT通过对比学习框架有效解决了生成式推荐中的标记化问题，为多模态信息整合提供了新思路。

中文摘要: 生成式检索推荐作为一种新兴范式，旨在直接生成目标候选的标识符。然而，在大规模推荐系统中，由于标记空间的冗余和规模庞大，这种方法变得日益繁琐。为克服这些限制，近期研究探索了使用语义标记替代ID标记，通常采用基于重建的策略（如RQ-VAE）量化内容嵌入并显著减少嵌入大小。然而，重建量化的目标是独立精确重建每个项目嵌入，这与生成式检索任务更关注项目间区分的目标相冲突。此外，项目的多模态辅助信息（如描述性文本和图像、基于地理位置的知识）已被证明能通过提供更丰富的交互上下文提升推荐效果。然而，如何有效整合这些补充知识到现有生成式推荐框架仍具挑战性。为此，我们提出了一种基于对比学习的无监督深度量化框架SimCIT（简单对比项目标记化框架）。具体而言，与现有基于重建的策略不同，SimCIT采用可学习的残差量化模块对齐项目的多模态信号，将多模态知识对齐和语义标记化结合在一个互利的对比学习框架中。在公开数据集和多个领域的大规模工业数据集上的广泛实验证明了SimCIT在基于大语言模型的生成式推荐中的有效性。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [371] [Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support](https://arxiv.org/abs/2506.16473)
**中文标题：我们是否像对治疗师一样与机器人交谈？AI情感支持中的语言对齐**

*Sophie Chiang,Guy Laban,Hatice Gunes*

主要分类: cs.HC

摘要简述: 研究探讨了机器人在情感支持对话中是否与人类治疗师的语言行为相似，发现两者在主题和语义上有高度一致性，但机器人支持对话仍存在局限性。


<details>
  <summary>详细信息</summary>
研究动机: 随着对话机器人在情感支持领域的应用增多，了解其与传统人类治疗师对话的相似性对评估其有效性至关重要。

研究方法: 研究比较了人类治疗师与机器人（基于GPT-3.5）的情感支持对话数据集，使用句子嵌入和K-means聚类分析主题和语义对齐。

研究结果: 90.88%的机器人对话主题可映射到人类治疗师数据集，且两者在语义上高度重叠，表明机器人能有效模拟人类治疗师的语言行为。

研究结论: 机器人情感支持对话在主题和语义上与人类治疗师相似，但仍有改进空间，为心理健康干预提供了潜在辅助工具。

中文摘要: 随着对话机器人越来越多地参与情感支持对话，了解其与传统治疗场景中互动的相似性变得尤为重要。本研究探讨了用户与机器人分享的问题是否与人类治疗师（H2H）会话中的问题一致，以及机器人回应是否在语义上模拟人类治疗师。我们分析了两个数据集：一个是用户与专业治疗师的互动（Hugging Face的NLP心理健康对话），另一个涉及与社交机器人（LuxAI的QTrobot，基于GPT-3.5）的支持性对话。通过句子嵌入和K-means聚类，我们使用基于距离的聚类拟合方法评估了跨代理主题对齐，并通过欧几里得距离验证。结果显示，90.88%的机器人对话内容可映射到人类治疗师数据集的聚类中，表明主题结构共享。对于匹配的聚类，我们使用Transformer、Word2Vec和BERT嵌入比较了主题及治疗师与机器人的回应，发现两个数据集中用户披露的主题及代理类型（机器人与人类治疗师）对相似主题的回应在语义上高度重叠。这些发现凸显了机器人主导的支持对话与传统治疗的相似性及其在心理健康干预中的潜力。

</details>


### [372] [On using AI for EEG-based BCI applications: problems, current challenges and future trends](https://arxiv.org/abs/2506.16168)
**中文标题：人工智能在基于脑电图的脑机接口应用中的问题、当前挑战与未来趋势**

*Thomas Barbera,Jacopo Burger,Alessandro D'Amelio,Simone Zini,Simone Bianco,Raffaella Lanzarotti,Paolo Napoletano,Giuseppe Boccignone,Jose Luis Contreras-Vidal*

主要分类: cs.HC

摘要简述: 本文探讨了人工智能（AI）在基于脑电图（EEG）的脑机接口（BCI）应用中的潜力与挑战，并提出了未来研究方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI在计算机视觉和自然语言处理领域的突破，其在解码EEG信号方面的潜力为BCI带来了革命性应用的可能性。然而，这一领域仍面临独特的技术和方法挑战，亟需系统性的探索和解决方案。

研究方法: 本文通过因果视角分析当前AI在EEG-BCI中的应用范式，识别其面临的挑战，并探讨克服这些挑战的未来研究方向。

研究结果: 研究发现，尽管AI为EEG-BCI提供了广阔前景，但其实际应用仍受限于技术、方法和伦理问题。未来研究需关注模型可靠性和实际环境适应性。

研究结论: 本文为开发实用且高效的EEG-BCI解决方案提供了清晰的路线图，强调了克服当前技术和方法局限的重要性。

中文摘要: 想象一下，通过解锁大脑的力量来实现沟通、创造甚至与周围世界互动。人工智能（AI）的最新突破，尤其是机器如何“看到”和“理解”语言，正在推动从头皮脑电图（EEG）解码脑信号的激动人心的进展。表面上看，这为革命性的脑机接口（BCI）打开了大门，超越了传统用途，实现了脑到语音、脑到图像甚至脑到物联网（BCIoT）的愿景。
然而，这一旅程并不像计算机视觉（CV）和自然语言处理（NLP）那样直接。将AI应用于现实世界的基于EEG的BCI，尤其是构建强大的基础模型，面临着独特而复杂的障碍，可能影响其可靠性。
本文对这一动态且快速发展的研究领域进行了引导性探索。目标不仅仅是概述当前的努力和成果，而是为这一热门且前沿的研究领域提供原则性的导航。我们从因果视角出发，探讨了AI模型面临的基本范式及其挑战。展望未来，我们讨论了可能克服当前技术、方法和伦理限制的有前途的研究方向。我们的目标是为创建真正实用且高效的基于EEG的BCI解决方案制定清晰的路线图，使其能够在日常环境中蓬勃发展。

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [373] [DT-UFC: Universal Large Model Feature Coding via Peaky-to-Balanced Distribution Transformation](https://arxiv.org/abs/2506.16495)
**中文标题：DT-UFC：通过峰值到平衡分布变换实现通用大模型特征编码**

*Changsheng Gao,Zijie Liu,Li Li,Dong Liu,Xiaoyan Sun,Weisi Lin*

主要分类: cs.MM

摘要简述: 本文提出了一种名为DT-UFC的通用大模型特征编码方法，通过峰值到平衡的分布变换解决不同模型特征分布不兼容的问题，显著提升了压缩效率和跨模型泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有特征编码方法多针对特定任务或模型，难以适应不同大模型特征的多样性。特征分布的不兼容性（如DINOv2的峰值分布与SD3的均匀分布）严重影响了压缩效率和跨模型泛化。

研究方法: 提出了一种数据驱动的峰值到平衡分布变换方法，将不同模型的特征分布对齐到一个共同的平衡目标空间，无需修改下游编解码器即可实现高效压缩和泛化。

研究结果: 在LLaMA3、DINOv2和SD3等多个模型和任务上的实验表明，该方法在压缩效率和跨模型泛化方面显著优于任务专用基线。

研究结论: DT-UFC通过分布变换实现了通用特征编码，为分布式大模型部署提供了高效解决方案，未来将开源代码以促进研究。

中文摘要: 与视觉数据传输中的图像编码类似，特征编码对于分布式部署大模型至关重要，可显著降低传输和存储开销。然而，现有研究多针对特定任务或模型，跨大模型的通用特征编码问题尚未解决。本文首次系统研究了通用大模型特征编码，核心挑战在于不同模型提取的特征分布多样且不兼容。例如，DINOv2的特征分布高度集中，而SD3的特征则更分散均匀。这种分布异质性严重影响了压缩效率和跨模型泛化。为此，我们提出了一种学习的峰值到平衡分布变换方法，将高度偏斜的特征分布重塑为共同的平衡目标空间。该变换是非均匀、数据驱动且即插即用的，无需修改下游编解码器即可有效对齐异构分布。通过这种对齐，基于平衡目标分布训练的通用编解码器可有效泛化到不同模型和任务的特征。我们在LLaMA3、DINOv2和SD3等多个模型和任务上验证了该方法，实验表明其在压缩效率和跨模型泛化方面显著优于任务专用基线。所有源代码将公开以促进未来研究。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [374] [RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching](https://arxiv.org/abs/2506.16741)
**中文标题：RapFlow-TTS：基于改进一致性流匹配的快速高保真文本转语音**

*Hyun Joon Park,Jeongmin Liu,Jin Sob Kim,Jeong Yeol Yang,Sung Won Han,Eunwoo Song*

主要分类: eess.AS

摘要简述: RapFlow-TTS是一种快速高保真的文本转语音（TTS）声学模型，通过改进流匹配（FM）训练中的速度一致性约束，实现了在较少生成步骤下保持高质量语音合成。


<details>
  <summary>详细信息</summary>
研究动机: 尽管基于常微分方程（ODE）的TTS生成能实现自然语音，但通常需要大量生成步骤，导致质量与推理速度之间的权衡。RapFlow-TTS旨在解决这一问题，通过速度一致性约束减少生成步骤，同时保持合成质量。

研究方法: RapFlow-TTS在流匹配（FM）训练中引入速度一致性约束，确保沿ODE轨迹的速度场一致。此外，采用时间间隔调度和对抗学习技术进一步提升少步合成的质量。

研究结果: 实验表明，RapFlow-TTS在合成步骤上比传统FM和基于分数的方法分别减少5倍和10倍，同时实现高保真语音合成。

研究结论: RapFlow-TTS通过速度一致性约束和优化技术，显著减少了TTS生成步骤，同时保持高质量语音合成，为快速高保真TTS提供了有效解决方案。

中文摘要: 我们介绍了RapFlow-TTS，一种快速高保真的TTS声学模型，利用流匹配（FM）训练中的速度一致性约束。尽管基于常微分方程（ODE）的TTS生成能实现自然语音，但通常需要大量生成步骤，导致质量与推理速度之间的权衡。为解决这一问题，RapFlow-TTS通过在FM拉直的ODE轨迹上强制速度场一致性，实现较少生成步骤下的稳定合成质量。此外，我们引入时间间隔调度和对抗学习技术，进一步提升少步合成的质量。实验结果表明，RapFlow-TTS在合成步骤上比传统FM和基于分数的方法分别减少5倍和10倍，同时实现高保真语音合成。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [375] [Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning](https://arxiv.org/abs/2506.15828)
**中文标题：上下文至关重要！利用LLM放松目标以实现可行的3D场景规划**

*Emanuele Musumeci,Michele Brienza,Francesco Argenziano,Vincenzo Suriani,Daniele Nardi,Domenico D. Bloisi*

主要分类: cs.RO

摘要简述: 本文提出了一种结合经典规划与大型语言模型（LLM）的方法，通过逐步放松目标使机器人能够适应复杂场景，实现部分任务目标。


<details>
  <summary>详细信息</summary>
研究动机: 传统AI和机器人规划方法（如PDDL）在真实场景中常因感知受限和难以将感知转化为规划谓词而失败，而LLM虽然能利用常识推理生成规划，但常导致不可行或不安全的计划。本文旨在结合两者的优势，解决这些问题。

研究方法: 提出了一种分层规划方法，通过LLM提取常识知识并逐步放松目标，使机器人能够在特定上下文中实现功能等效的目标，从而适应复杂环境。

研究结果: 通过定性和定量评估，该方法在3D场景图中表现出高效的任务适应和执行能力，并在复杂场景中优于其他基准方法。

研究结论: 结合经典规划与LLM的方法能够有效解决机器人规划中的适应性问题，支持部分任务目标的实现，适用于复杂场景。

中文摘要: 传统AI和机器人规划方法（如PDDL）通过从命令式转向声明式方法处理复杂任务，但这些方法在真实场景中常因机器人感知有限和需要将感知转化为规划谓词而失败，导致难以适应的硬编码行为。与此同时，大型语言模型（LLM）虽然能利用常识推理生成规划，但常导致不可行或不安全的计划。为解决这些问题，我们提出了一种结合经典规划与LLM的方法，利用其提取常识知识并逐步放松目标的能力。我们提出了一种分层规划框架，使机器人能够通过定义功能等效的目标逐步放松任务，从而在特定上下文中部分实现目标。通过全面的定性和定量评估，我们的方法在3D场景图建模的环境中表现出高效的任务适应和执行能力，并在复杂场景中优于其他基准方法。我们还发布了代码、数据集和其他材料供社区使用。

</details>


### [376] [SafeMimic: Towards Safe and Autonomous Human-to-Robot Imitation for Mobile Manipulation](https://arxiv.org/abs/2506.15847)
**中文标题：SafeMimic：面向安全自主的人机模仿学习移动操作**

*Arpit Bahety,Arnav Balaji,Ben Abbatematteo,Roberto Martín-Martín*

主要分类: cs.RO

摘要简述: SafeMimic是一种框架，通过单次第三人称人类视频演示，安全自主地学习移动操作技能，减少探索成本并提升任务成功率。


<details>
  <summary>详细信息</summary>
研究动机: 为了让机器人成为家庭中的高效助手，需要其通过观察人类演示学习新任务，同时确保学习过程安全且无需人工监控。

研究方法: SafeMimic将人类视频解析为语义变化和动作序列，转换为机器人视角，并通过采样候选动作和安全验证（使用仿真训练的Q函数）适应机器人形态。

研究结果: 实验表明，SafeMimic能从单次演示中安全高效地学习多步骤移动操作任务，并在不同用户和环境中优于现有基线方法。

研究结论: SafeMimic提供了一种安全自主的学习框架，显著减少了探索成本，并提升了任务成功率。

中文摘要: 为了让机器人成为家庭中的高效助手，它们需要通过观察人类演示学习新的移动操作任务。从单次人类视频演示中学习具有挑战性，因为机器人需要提取任务内容和执行策略，并将其从第三人称视角转换为第一人称视角，同时适应自身形态。此外，为减少对人工监控的依赖，学习过程需安全自主。本文提出SafeMimic框架，通过单次第三人称人类视频安全自主地学习移动操作技能。给定多步骤移动操作任务的初始人类视频演示，SafeMimic首先将视频解析为语义变化和动作序列，并转换为机器人视角。随后，通过采样候选动作并在执行前使用仿真训练的Q函数验证其安全性，适应机器人形态。当无法安全推进时，SafeMimic回溯至先前状态并尝试不同动作序列，必要时调整轨迹和抓取模式。结果表明，SafeMimic能成功完成任务并减少未来探索成本。实验显示，该方法使机器人能从单次人类演示中安全高效地学习多步骤移动操作行为，并在不同用户和环境中优于现有基线方法。

</details>


### [377] [CapsDT: Diffusion-Transformer for Capsule Robot Manipulation](https://arxiv.org/abs/2506.16263)
**中文标题：CapsDT：基于扩散Transformer的胶囊机器人操控模型**

*Xiting He,Mingwu Su,Xinqi Jiang,Long Bai,Jiewen Lai,Hongliang Ren*

主要分类: cs.RO

摘要简述: 本文提出CapsDT，一种基于扩散Transformer的胶囊机器人操控模型，结合视觉-语言-动作（VLA）技术，用于胃内胶囊内窥镜任务，显著提升任务成功率。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉-语言-动作（VLA）模型在消化系统内窥镜胶囊机器人领域的应用尚未探索，而此类模型可提升人机交互效率及诊疗效果。

研究方法: 设计CapsDT模型，通过处理视觉输入与文本指令，推断机器人控制信号，并开发胶囊内窥镜机器人系统，利用机械臂磁控完成胃内任务。

研究结果: CapsDT在多种内窥镜任务中表现优异，达到最先进水平，并在真实模拟操作中实现26.25%的成功率。

研究结论: CapsDT作为视觉-语言通用模型，显著提升胶囊机器人操控性能，为内窥镜任务提供高效解决方案。

中文摘要: 视觉-语言-动作（VLA）模型已成为重要研究方向，在多种应用中展现出潜力，但其在消化系统内窥镜胶囊机器人领域的性能尚未探索。将VLA模型集成到内窥镜机器人中，可提升人机交互的直观性与效率，改善诊疗效果。本文提出CapsDT，一种基于扩散Transformer的模型，用于胃内胶囊机器人操控。通过处理视觉输入与文本指令，CapsDT可推断机器人控制信号以辅助内窥镜任务。此外，开发了胶囊内窥镜机器人系统，通过机械臂磁控胶囊机器人，针对四种内窥镜任务创建胃模拟器数据集。综合评估表明，CapsDT可作为强大的视觉-语言通用模型，在多种内窥镜任务中达到最先进水平，并在真实模拟操作中实现26.25%的成功率。

</details>


### [378] [PRISM-Loc: a Lightweight Long-range LiDAR Localization in Urban Environments with Topological Maps](https://arxiv.org/abs/2506.15849)
**中文标题：PRISM-Loc：基于拓扑地图的城市环境轻量级长距离LiDAR定位方法**

*Kirill Muravyev,Vasily Yuryev,Oleg Bulichev,Dmitry Yudin,Konstantin Yakovlev*

主要分类: cs.RO

摘要简述: PRISM-Loc是一种基于拓扑地图的轻量级长距离LiDAR定位方法，适用于城市环境，通过全局地点识别和局部位姿估计实现高效定位，性能优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 在长距离导航中，实时定位和密集全局LiDAR地图的高内存需求是主要挑战，拓扑地图可提供更高效的解决方案。

研究方法: PRISM-Loc采用双重定位流程：全局地点识别和局部位姿估计，后者基于2D特征和点云优化算法。

研究结果: 在3公里路线的ITLP-Campus数据集上测试，PRISM-Loc在质量和计算效率上均优于现有方法。

研究结论: PRISM-Loc通过拓扑地图和双重定位流程，实现了高效且轻量的长距离LiDAR定位，适用于城市环境。

中文摘要: 定位是移动机器人或自动驾驶车辆导航中的关键任务之一。对于长距离路线，实时在密集的全局LiDAR地图中进行定位可能较为困难，且此类地图的创建需要大量内存。为此，利用拓扑地图可能更为有效。本文提出PRISM-Loc——一种基于拓扑地图的大规模环境定位方法。该方法采用双重定位流程，包括全局地点识别和在识别位置内的局部位姿估计。对于局部位姿估计，我们提出了一种基于2D特征和点云优化的原始LiDAR扫描匹配算法。我们在3公里路线的ITLP-Campus数据集上评估了所提方法，并与基于度量地图和地点识别的现有方法进行了比较。实验结果表明，所提方法在质量和计算效率上均优于竞争对手。

</details>


### [379] [Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles](https://arxiv.org/abs/2506.15851)
**中文标题：面向自动驾驶车辆的语义与特征引导的视觉定位不确定性量化**

*Qiyuan Wu,Mark Campbell*

主要分类: cs.RO

摘要简述: 本文提出了一种用于自动驾驶视觉定位的不确定性量化方法，结合图像特征和语义信息预测误差分布，并在不同天气和光照条件下验证了其准确性。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶等安全关键应用需要精确的传感器测量不确定性量化，尤其是在视觉定位中，误差分布受多种因素影响（如天气、光照）。本文旨在开发一种轻量级方法，通过图像特征和语义信息预测误差分布。

研究方法: 提出了一种基于图像特征和语义信息的轻量级传感器误差模型，将误差映射为二维分布。该方法通过隐式捕获未标注因素（如城市与高速公路、动态与静态场景、季节变化）来预测不确定性。

研究结果: 在Ithaca365数据集上的实验表明，测量误差在恶劣天气和光照条件下不符合高斯分布，而高斯混合模型能更准确地预测误差。

研究结论: 本文提出的方法能够有效预测视觉定位中的不确定性，尤其在复杂环境下表现优于传统高斯模型。

中文摘要: 传感器测量与深度学习网络结合的不确定性量化对机器人系统至关重要，尤其是自动驾驶等安全关键应用。本文开发了一种用于自动驾驶视觉定位的不确定性量化方法，通过图像选择位置。方法的关键是利用轻量级传感器误差模型学习测量不确定性，将图像特征和语义信息映射为二维误差分布。该方法能够根据匹配图像对的特定上下文估计不确定性，隐式捕获其他关键未标注因素（如城市与高速公路、动态与静态场景、季节变化）。我们在Ithaca365数据集上验证了不确定性预测框架的准确性，该数据集包含光照和天气变化（晴天、夜晚、雪天）。评估了传感器+网络的不确定性量化，以及使用独特传感器门控方法的贝叶斯定位滤波器。结果表明，在恶劣天气和光照条件下，测量误差不符合高斯分布，而高斯混合模型能更好地预测误差。

</details>


### [380] [Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments](https://arxiv.org/abs/2506.16050)
**中文标题：基于噪声融合的蒸馏学习在复杂工业环境中的异常检测**

*Jiawen Yu,Jieji Ren,Yang Chang,Qiaojun Yu,Xuan Tong,Boyang Wang,Yan Song,You Li,Xinji Mai,Wenqiang Zhang*

主要分类: cs.RO

摘要简述: 本文提出了一种基于噪声融合的蒸馏学习框架HetNet，用于复杂工业环境中的异常检测与定位，显著提升了检测性能和环境适应性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在复杂工业环境中难以准确检测工件缺陷，尤其是在多变视角、姿态和光照条件下。本文旨在解决这一问题，提升异常检测的鲁棒性和实时性。

研究方法: 提出了一种协作蒸馏异构教师网络（HetNet），结合自适应局部-全局特征融合模块和局部多元高斯噪声生成模块，通过学习正常模式的复杂特征分布来检测异常。

研究结果: HetNet在工业条件下显著优于现有方法，MSC-AD数据集上所有评估指标提升约10%，并在其他数据集上达到最优性能，验证了其对环境波动的适应性和可靠性。

研究结论: HetNet能够有效集成到生产线中，实现鲁棒且实时的异常检测，为复杂工业环境中的质量控制提供了实用解决方案。

中文摘要: 自动化工业制造中的异常检测与定位可显著提升生产效率和产品质量。现有方法能够在预定义或受控的成像环境中检测表面缺陷，但在复杂非结构化工业环境中，面对多变视角、姿态和光照条件，准确检测工件缺陷仍具挑战性。我们提出了一种专门用于处理具有扰动模式输入的新型异常检测与定位方法。该方法基于协作蒸馏异构教师网络（HetNet）、自适应局部-全局特征融合模块和局部多元高斯噪声生成模块构建了新框架。HetNet能够利用有限的局部扰动变化信息学习建模正常模式的复杂特征分布。我们在主流基准上进行了大量实验。HetNet在工业条件下显著优于现有方法，MSC-AD数据集上所有评估指标提升约10%，并在其他数据集上达到最优性能，验证了其对环境波动的适应性和提升工业异常检测系统可靠性的能力。实际环境测试进一步证实HetNet可有效集成到生产线中，实现鲁棒且实时的异常检测。代码、图像和视频已发布于项目网站：https://zihuatanejoyu.github.io/HetNet/

</details>


### [381] [FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation](https://arxiv.org/abs/2506.16201)
**中文标题：FlowRAM：基于区域感知Mamba框架的流匹配策略在机器人操作中的应用**

*Sen Wang,Le Wang,Sanping Zhou,Jingyi Tian,Jiayi Li,Haowen Sun,Wei Tang*

主要分类: cs.RO

摘要简述: FlowRAM提出了一种基于生成模型的区域感知框架，用于高效机器人操作，通过动态半径调度和状态空间模型提升多模态信息处理能力，并在RLBench基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散的策略学习方法在推理时计算效率低，且未充分利用生成模型在3D环境中的信息探索潜力。FlowRAM旨在解决这些问题，提升机器人高精度操作的效率和性能。

研究方法: FlowRAM采用动态半径调度实现自适应感知，结合状态空间模型整合多模态信息，并利用条件流匹配学习动作位姿，简化学习过程。

研究结果: 在RLBench基准测试中，FlowRAM的平均成功率比先前方法提高12.0%，且仅需不到4个时间步生成物理合理的动作，显著提升推理速度。

研究结论: FlowRAM通过区域感知框架和高效多模态信息处理，在高精度机器人操作任务中实现了显著的性能提升和计算效率优化。

中文摘要: 高精度机器人操作在工业和实际应用中至关重要，但当前基于扩散的策略学习方法因推理时的迭代去噪过程导致计算效率低下，且未充分挖掘生成模型在3D环境中的信息探索潜力。为此，我们提出FlowRAM，一种利用生成模型实现区域感知的新型框架，支持高效多模态信息处理。具体而言，我们设计了动态半径调度，实现从全局场景理解到细粒度几何细节的自适应感知。此外，我们整合状态空间模型以融合多模态信息，同时保持线性计算复杂度。我们还采用条件流匹配通过回归确定性向量场学习动作位姿，简化学习过程并保持性能。在RLBench基准测试中，FlowRAM验证了其有效性，并取得最先进性能。结果表明，FlowRAM在高精度任务中表现尤为突出，平均成功率比先前方法提高12.0%。此外，FlowRAM能在不到4个时间步内为多种实际任务生成物理合理的动作，显著提升推理速度。

</details>


### [382] [Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining](https://arxiv.org/abs/2506.16475)
**中文标题：Human2LocoMan：通过人类预训练学习多功能四足机器人操作**

*Yaru Niu,Yunzhe Zhang,Mingyang Yu,Changyi Lin,Chenhao Li,Yikai Wang,Yuxiang Yang,Wenhao Yu,Tingnan Zhang,Bingqing Chen,Jonathan Francis,Zhenzhen Li,Jie Tan,Ding Zhao*

主要分类: cs.RO

摘要简述: 本文提出了一种跨具身模仿学习系统，通过结合人类和四足机器人LocoMan的数据，实现了高效的模块化架构和预训练方法，显著提升了四足机器人在多种家庭任务中的操作能力。


<details>
  <summary>详细信息</summary>
研究动机: 四足机器人在复杂环境中的运动能力已得到验证，但如何以可扩展的方式赋予其自主多样的操作技能仍是一大挑战。本文旨在通过结合人类和机器人的数据，提升四足机器人的操作能力。

研究方法: 开发了一种远程操作和数据收集流程，统一并模块化了人类和机器人的观察与动作空间。提出了一种高效的模块化架构，支持跨具身的结构化模态对齐数据的联合训练和预训练。构建了首个LocoMan机器人操作数据集，涵盖多种家庭任务。

研究结果: 在六项真实世界操作任务中，系统平均成功率提升了41.9%，在分布外（OOD）设置下提升了79.7%。使用人类数据预训练分别贡献了38.6%和82.7%的成功率提升，仅需一半机器人数据即可实现更优性能。

研究结论: 通过结合人类和机器人数据，本文提出的系统显著提升了四足机器人的操作能力，尤其是在分布外任务中表现优异，为未来研究提供了开源代码、硬件和数据支持。

中文摘要: 四足机器人在复杂环境中展现了出色的运动能力，但如何以可扩展的方式赋予其自主多样的操作技能仍是一个重大挑战。本文提出了一种跨具身模仿学习系统，用于四足机器人操作，利用了从人类和LocoMan（一种配备多种操作模式的四足机器人）收集的数据。具体而言，我们开发了一种远程操作和数据收集流程，统一并模块化了人类和机器人的观察与动作空间。为了有效利用收集的数据，我们提出了一种高效的模块化架构，支持跨具身的结构化模态对齐数据的联合训练和预训练。此外，我们构建了首个LocoMan机器人操作数据集，涵盖多种家庭任务（包括单臂和双臂模式），并补充了相应的人类数据集。我们在六项真实世界操作任务中验证了该系统，其平均成功率提升了41.9%，在分布外（OOD）设置下提升了79.7%。使用人类数据预训练分别贡献了38.6%和82.7%的成功率提升，仅需一半机器人数据即可实现更优性能。我们的代码、硬件和数据已开源：https://human2bots.github.io。

</details>


### [383] [Grounding Language Models with Semantic Digital Twins for Robotic Planning](https://arxiv.org/abs/2506.16493)
**中文标题：基于语义数字孪生的语言模型接地与机器人规划**

*Mehreen Naeem,Andrew Melnik,Michael Beetz*

主要分类: cs.RO

摘要简述: 本文提出了一种结合语义数字孪生（SDT）与大语言模型（LLM）的新框架，用于动态环境中机器人任务的适应性执行。通过将自然语言指令分解为结构化动作三元组，并结合SDT提供的环境数据，系统实现了语义接地和实时适应性规划。


<details>
  <summary>详细信息</summary>
研究动机: 动态环境中机器人任务执行面临不确定性和失败风险，传统方法难以实现高层次的语义理解和适应性规划。本文旨在通过结合SDT和LLM，提升机器人对环境的语义理解能力，并实现任务执行的实时调整与恢复。

研究方法: 系统将自然语言指令分解为动作三元组，利用SDT提供的环境数据实现语义接地，并通过LLM生成动作计划。执行失败时，LLM结合SDT反馈生成恢复策略并迭代修订计划。

研究结果: 在ALFRED基准测试中，该方法在多种家庭场景中表现出鲁棒性，成功结合了高层次推理与语义环境理解，实现了任务的高效完成。

研究结论: 该框架通过语义接地和实时适应性规划，显著提升了机器人在动态环境中的任务执行能力，为未来智能机器人系统的发展提供了新思路。

中文摘要: 我们提出了一种新颖框架，将语义数字孪生（SDT）与大语言模型（LLM）结合，以实现动态环境中机器人任务的适应性执行。系统将自然语言指令分解为结构化动作三元组，并通过SDT提供的环境数据实现语义接地。这种语义接地使机器人能够理解对象的功能和交互规则，从而支持动作规划和实时适应性。在执行失败时，LLM利用错误反馈和SDT的洞察生成恢复策略，并迭代修订动作计划。我们在ALFRED基准测试中评估了该方法，结果表明其在多种家庭场景中具有鲁棒性能。该框架有效结合了高层次推理与语义环境理解，在不确定性和失败情况下实现了可靠的任务完成。

</details>


### [384] [Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control](https://arxiv.org/abs/2506.16565)
**中文标题：通过测试时观察干预重新想象：视觉模型预测控制中抗干扰的世界模型预测**

*Yuxin Chen,Jianglan Wei,Chenfeng Xu,Boyi Li,Masayoshi Tomizuka,Andrea Bajcsy,Ran Tian*

主要分类: cs.RO

摘要简述: 本文提出了一种名为ReOI的测试时策略，通过检测并移除视觉干扰物，提升世界模型在开放世界场景中的预测可靠性，显著提高了任务成功率。


<details>
  <summary>详细信息</summary>
研究动机: 世界模型在机器人学习中具有重要作用，但在面对训练中未见的视觉干扰物时表现脆弱，导致预测失效。本文旨在解决这一问题，提升模型在开放环境中的鲁棒性。

研究方法: ReOI通过检测当前观察中的视觉干扰物，修改观察以移除干扰物，随后重新预测未来结果并恢复干扰物以保持视觉一致性。

研究结果: 实验表明，ReOI对分布内和分布外视觉干扰物均具有鲁棒性，任务成功率提升高达3倍。

研究结论: ReOI是一种简单有效的策略，显著提升了世界模型在开放世界场景中的预测可靠性，适用于机器人动作验证等任务。

中文摘要: 世界模型使机器人能够根据当前观察和计划动作“想象”未来观察，并逐渐被用作通用动力学模型以促进机器人学习。尽管前景广阔，这些模型在面对训练中罕见的视觉干扰物（如物体和背景元素）时仍显脆弱。具体而言，新型干扰物可能破坏动作结果预测，导致机器人依赖世界模型想象进行规划或动作验证时失败。本文提出了一种名为“观察干预重新想象”（ReOI）的简单而有效的测试时策略，使世界模型在开放世界场景中预测更可靠的动作结果，其中新型和未预期的视觉干扰物不可避免。给定当前机器人观察，ReOI首先通过识别场景中哪些元素在世界模型预测中以物理上不合理的方式退化来检测视觉干扰物。随后，它修改当前观察以移除这些干扰物，使观察更接近训练分布。最后，ReOI使用修改后的观察“重新想象”未来结果，并在事后重新引入干扰物以保持下游规划和验证的视觉一致性。我们在机器人操作任务中验证了该方法，结果表明ReOI对分布内和分布外视觉干扰物均具有鲁棒性。值得注意的是，在新型干扰物存在的情况下，它将任务成功率提高了高达3倍，显著优于依赖未经干预的世界模型预测的动作验证。

</details>


### [385] [BIDA: A Bi-level Interaction Decision-making Algorithm for Autonomous Vehicles in Dynamic Traffic Scenarios](https://arxiv.org/abs/2506.16546)
**中文标题：BIDA：动态交通场景中自动驾驶车辆的双层交互决策算法**

*Liyang Yu,Tianyi Wang,Junfeng Jiao,Fengwu Shan,Hongqing Chu,Bingzhao Gao*

主要分类: cs.RO

摘要简述: 本文提出了一种双层交互决策算法（BIDA），结合交互式蒙特卡洛树搜索（MCTS）与深度强化学习（DRL），以提升自动驾驶车辆在动态交通场景中的交互理性、效率和安全性。实验证明BIDA在交互推理和计算成本方面优于现有基准。


<details>
  <summary>详细信息</summary>
研究动机: 在复杂的真实交通环境中，自动驾驶车辆需要与其他交通参与者实时交互并做出安全关键决策。人类行为的不可预测性在多车道高速公路和无信号T型交叉口等动态场景中尤为突出，亟需一种高效的交互决策算法。

研究方法: BIDA算法通过三种DRL算法构建可靠的价值网络和策略网络，指导交互式MCTS的在线推理过程，包括价值更新和节点选择。同时，在CARLA中设计了动态轨迹规划器和轨迹跟踪控制器，确保规划的机动动作平滑执行。

研究结果: 实验评估表明，BIDA不仅提升了交互推理能力并降低了计算成本，还在不同交通条件下表现出优于其他最新基准的安全性、效率和交互理性。

研究结论: BIDA算法通过结合MCTS与DRL，显著提升了自动驾驶车辆在动态交通场景中的决策能力，为复杂交互问题提供了高效解决方案。

中文摘要: 在复杂的真实交通环境中，自动驾驶车辆（AVs）需要与其他交通参与者交互并实时做出安全关键决策。人类行为的不可预测性带来了显著挑战，尤其是在多车道高速公路和无信号T型交叉口等动态场景中。为填补这一空白，我们设计了一种双层交互决策算法（BIDA），将交互式蒙特卡洛树搜索（MCTS）与深度强化学习（DRL）结合，旨在提升自动驾驶车辆在动态关键交通场景中的交互理性、效率和安全性。具体而言，我们采用三种DRL算法构建可靠的价值网络和策略网络，通过辅助价值更新和节点选择来指导交互式MCTS的在线推理过程。随后，在CARLA中设计并实现了动态轨迹规划器和轨迹跟踪控制器，以确保规划机动动作的平滑执行。实验评估表明，BIDA不仅增强了交互推理能力并降低了计算成本，还在不同交通条件下表现出优于其他最新基准的安全性、效率和交互理性。

</details>


### [386] [CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity](https://arxiv.org/abs/2506.16652)
**中文标题：CodeDiffuser：基于VLM生成代码的注意力增强扩散策略用于指令模糊性**

*Guang Yin,Yitong Li,Yixuan Wang,Dale McConachie,Paarth Shah,Kunimatsu Hashimoto,Huan Zhang,Katherine Liu,Yunzhu Li*

主要分类: cs.RO

摘要简述: 论文提出了一种名为CodeDiffuser的新型机器人操作框架，通过视觉语言模型（VLM）生成代码来解决自然语言指令的模糊性问题，并结合注意力机制提升任务执行效果。


<details>
  <summary>详细信息</summary>
研究动机: 自然语言指令在机器人操作任务中常存在模糊性和不确定性，现有端到端模型因缺乏模块化和可解释性导致性能不佳。论文旨在解决这一问题。

研究方法: 框架利用VLM解析自然语言指令中的抽象概念，生成任务专用代码作为可解释的中间表示，并通过感知模块生成3D注意力图，结合空间与语义信息消除指令模糊性。

研究结果: 实验表明，该方法在涉及语言模糊性、接触密集操作和多物体交互的复杂任务中表现优异，克服了现有模仿学习方法的局限性。

研究结论: CodeDiffuser通过代码生成和注意力增强机制，有效解决了自然语言指令的模糊性问题，提升了机器人操作的适应性和性能。

中文摘要: 机器人操作任务的自然语言指令常表现出模糊性和不确定性。例如，“将杯子挂在杯树上”的指令可能涉及多个有效动作选择。现有的语言条件策略通常依赖端到端模型，同时处理高级语义理解和低级动作生成，但由于缺乏模块化和可解释性，性能不佳。为解决这些问题，我们提出了一种新型机器人操作框架，能够完成由潜在模糊自然语言指定的任务。该框架利用视觉语言模型（VLM）解析自然语言指令中的抽象概念，并生成任务专用代码——一种可解释且可执行的中间表示。生成的代码与感知模块交互，通过整合空间和语义信息生成3D注意力图，突出任务相关区域，有效消除指令模糊性。通过大量实验，我们发现当前模仿学习方法的关键局限性，如对语言和环境变化的适应能力差。结果表明，我们的方法在涉及语言模糊性、接触密集操作和多物体交互的复杂任务中表现优异。

</details>


### [387] [Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping](https://arxiv.org/abs/2506.17110)
**中文标题：基于RGB的机器人抓取的单目单次度量深度对齐**

*Teng Guo,Baichuan Huang,Jingjin Yu*

主要分类: cs.RO

摘要简述: 本文提出了一种名为MOMA的新框架，通过单张RGB图像恢复度量深度，适用于机器人抓取任务，无需额外数据收集或模型重新训练。


<details>
  <summary>详细信息</summary>
研究动机: 当前机器人抓取任务依赖昂贵的深度传感器，且存在噪声和透明物体处理问题。单目深度估计模型（MDEMs）仅提供未知尺度和偏移的深度信息，无法直接用于实际任务。

研究方法: MOMA框架通过相机标定中的尺度-旋转-偏移对齐，利用稀疏真实深度点引导，实现单张RGB图像的度量深度恢复，并支持透明物体的微调。

研究结果: 实验表明，MOMA在桌面二指抓取和吸盘式箱拣任务中表现优异，成功率高，验证了其有效性。

研究结论: MOMA通过单次适应实现了高精度的度量深度估计，适用于多样化机器人任务，展示了强大的泛化能力。

中文摘要: 准确的6D物体姿态估计是机器人完成抓取和非抓取操作任务的前提。目前，机器人操作的6D姿态估计通常依赖于基于结构光、飞行时间或立体视觉的深度传感器，这些传感器成本高、输出噪声大（与RGB相机相比），且无法处理透明物体。另一方面，最先进的单目深度估计模型（MDEMs）仅提供未知尺度和偏移的仿射不变深度。度量MDEMs在公共数据集上取得了一些零样本成功，但泛化能力不足。我们提出了一种新框架——单目单次度量深度对齐（MOMA），通过基于MDEM技术的单次适应，从单张RGB图像恢复度量深度。MOMA在相机标定过程中进行尺度-旋转-偏移对齐，通过稀疏真实深度点引导，无需额外数据收集或测试设置上的模型重新训练即可实现精确深度估计。MOMA支持对透明物体的MDEM微调，展示了强大的泛化能力。在桌面二指抓取和吸盘式箱拣的真实实验中，MOMA在多样化任务中取得了高成功率，验证了其有效性。

</details>


### [388] [History-Augmented Vision-Language Models for Frontier-Based Zero-Shot Object Navigation](https://arxiv.org/abs/2506.16623)
**中文标题：基于历史增强视觉语言模型的前沿零样本目标导航**

*Mobin Habibpour,Fatemeh Afghah*

主要分类: cs.RO

摘要简述: 本文提出了一种基于历史增强的视觉语言模型（VLM）的零样本目标导航框架，通过动态历史感知提示和VLM辅助路径点生成机制，显著提升了导航的上下文理解和成功率。


<details>
  <summary>详细信息</summary>
研究动机: 当前的目标导航方法虽然利用了视觉语言模型（VLMs），但仅浅层地使用其嵌入进行对象-场景相似性检查，缺乏深度推理能力，导致上下文理解不足和重复导航行为。本文旨在通过历史增强的VLM提示策略解决这些问题。

研究方法: 提出了一种零样本目标导航框架，通过动态历史感知提示将VLM推理深度整合到前沿探索中，并引入VLM辅助路径点生成机制，优化对检测对象的最终接近路径。

研究结果: 在HM3D数据集上的实验表明，该方法实现了46%的成功率（SR）和24.8%的路径长度加权成功率（SPL），与最先进的零样本方法相当。

研究结论: 历史增强的VLM提示策略显著提升了导航的鲁棒性和上下文感知能力，展示了其在机器人导航中的巨大潜力。

中文摘要: 目标导航（ObjectNav）要求机器人在未知环境中寻找对象，需要复杂的推理能力。尽管视觉语言模型（VLMs）显示出潜力，但当前的方法仅浅层地使用其嵌入进行对象-场景相似性检查，限制了上下文理解并导致重复导航行为。本文提出了一种新颖的零样本目标导航框架，首次通过动态历史感知提示将VLM推理深度整合到前沿探索中。核心创新在于为VLM提供动作历史上下文，使其能够生成导航动作的语义指导分数，同时主动避免决策循环。我们还引入了VLM辅助路径点生成机制，优化对检测对象的最终接近路径。在Habitat中的HM3D数据集上评估，我们的方法实现了46%的成功率（SR）和24.8%的路径长度加权成功率（SPL），与最先进的零样本方法相当，展示了历史增强VLM提示策略在更鲁棒和上下文感知的机器人导航中的巨大潜力。

</details>


### [389] [Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation](https://arxiv.org/abs/2506.17198)
**中文标题：Dex1B：利用10亿演示学习灵巧手操作**

*Jianglong Ye,Keyi Wang,Chengjing Yuan,Ruihan Yang,Yiquan Li,Jiyue Zhu,Yuzhe Qin,Xueyan Zou,Xiaolong Wang*

主要分类: cs.RO

摘要简述: 本文介绍了Dex1B，一个通过生成模型创建的大规模、多样且高质量的手部灵巧操作演示数据集，包含10亿个抓取和关节任务演示，并在模拟和实际机器人实验中验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 灵巧手操作的大规模演示生成具有挑战性，现有方法难以满足多样性和物理可行性的需求。本文旨在通过生成模型构建一个高质量、多样化的演示数据集，以推动相关研究的发展。

研究方法: 提出了一种结合几何约束和多样性增强条件的生成模型，用于构建包含10亿个抓取和关节任务演示的Dex1B数据集。模型通过几何约束提升可行性，并通过附加条件增强多样性。

研究结果: 在模拟基准测试和新引入的实验中，Dex1B显著优于现有最优方法，并在真实机器人实验中展示了其有效性和鲁棒性。

研究结论: Dex1B为灵巧手操作研究提供了大规模、高质量的演示数据，生成模型的结合几何约束和多样性增强策略为未来研究提供了新方向。

中文摘要: 生成大规模灵巧手操作演示仍具挑战性，近年来已有多种方法被提出以解决这一问题。其中，生成模型作为一种有前景的范式，能够高效生成多样且物理可行的演示。本文介绍了Dex1B，一个通过生成模型构建的大规模、多样且高质量的演示数据集，包含10亿个抓取和关节任务演示。为构建该数据集，我们提出了一种结合几何约束以提升可行性和附加条件以增强多样性的生成模型。该模型在现有及新引入的模拟基准测试中显著优于现有最优方法，并通过真实机器人实验验证了其有效性和鲁棒性。项目页面见https://jianglongye.com/dex1b。

</details>


### [390] [Learning Dexterous Object Handover](https://arxiv.org/abs/2506.16822)
**中文标题：学习灵巧物体交接**

*Daniel Frau-Alfaro,Julio Castaño-Amoros,Santiago Puente,Pablo Gil,Roberto Calandra*

主要分类: cs.RO

摘要简述: 本文通过强化学习（RL）实现了双多指机械手之间的灵巧物体交接，提出了一种基于双四元数的新型奖励函数以减少旋转距离，实验证明该方法在未训练对象和扰动情况下表现稳健。


<details>
  <summary>详细信息</summary>
研究动机: 在协作环境中（如家庭），机器人需要安全高效地接收和传递物体。本文旨在通过强化学习解决双多指机械手之间的物体交接问题，提升机器人在实际应用中的协作能力。

研究方法: 使用强化学习训练双多指机械手进行物体交接，提出了一种基于双四元数的奖励函数以优化旋转距离，并测试了策略在未训练对象和扰动情况下的稳健性。

研究结果: 实验表明，最佳情况下策略的成功率达到94%，且在对方机器人移动时性能仅下降13.8%，证明了策略对未训练对象和扰动的稳健性。

研究结论: 本文提出的基于双四元数的强化学习方法在物体交接任务中表现优异，具备对未训练对象和扰动的稳健性，为机器人协作提供了有效解决方案。

中文摘要: 物体交接是我们日常与他人互动时的重要技能。为了在家庭等协作环境中部署机器人，安全高效地接收和传递物体成为关键能力。本文展示了使用强化学习（RL）实现双多指机械手之间的灵巧物体交接。该任务的关键是提出了一种基于双四元数的新型奖励函数以减少旋转距离，其性能优于欧拉角和旋转矩阵等其他旋转表示方法。通过实验评估了训练策略的稳健性，测试了未包含在训练分布中的对象以及交接过程中的扰动。结果表明，训练策略成功完成了任务，在最佳情况下100次实验后总成功率达到94%，证明了策略对未训练对象的稳健性。此外，当对方机器人在交接过程中移动时，策略的最佳性能仅下降13.8%，表明策略对此类常见于实际交接中的扰动也具有稳健性。

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [391] [Wavelet-based Global Orientation and Surface Reconstruction for Point Clouds](https://arxiv.org/abs/2506.16299)
**中文标题：基于小波的全局定向与点云表面重建**

*Yueji Ma,Yanzun Meng,Dong Xiao,Zuoqiang Shi,Bin Wang*

主要分类: cs.CG

摘要简述: 本文提出了一种基于小波的全局定向和表面重建方法，解决了稀疏点云的无定向表面重建问题，通过改进核函数和小波基函数特性，实现了高效且稳定的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的小波表面重建方法仅适用于定向点云，对于无定向点云（如iWSR方法）在稀疏点云上表现不佳。本文旨在解决这一局限性，提出一种同时完成定向和表面重建的高效方法。

研究方法: 利用小波的紧支撑性和正交性，通过改进核函数平滑表面不连续性，并将计算转移到小波基上以加速。此外，提出了一种构建无散函数场的方法，并通过齐次约束提高效果和稳定性。

研究结果: 实验表明，该方法在稀疏模型的定向和重建任务中达到了最先进的性能，并通过与小波基紧支撑性的结合进一步加速，在CPU上实现了高效运行。

研究结论: 本文方法在无定向点云的表面重建中表现出色，尤其是在稀疏点云上，同时保持了高效性和稳定性。源代码将在GitHub上公开。

中文摘要: 无定向表面重建是计算机图形学中的重要任务，具有广泛应用。传统小波表面重建方法基于小波的紧支撑性和正交性，实现了快速且良好的重建效果，但仅适用于定向点云。尽管已有改进尝试（如iWSR），但这些方法在稀疏点云上表现不佳。为解决这一问题，我们提出了一种基于小波的方法，用于表示平滑指示函数，并同时完成定向和表面重建任务。通过改进核函数平滑表面不连续性，使其与小波基函数的连续性一致。在系数计算中，充分利用卷积核函数的特性，将改进计算转移到小波基上以加速。此外，提出了一种构建无散函数场的新方法，并利用其构造附加齐次约束以提高效果和稳定性。大量实验表明，我们的方法在稀疏模型的定向和重建任务中达到了最先进的性能。通过将矩阵构造与小波基函数的紧支撑性对齐，进一步加速了方法，在CPU上实现了高效运行。源代码将在GitHub上发布。

</details>


<div id='cond-mat.quant-gas'></div>

# cond-mat.quant-gas [[Back]](#toc)

### [392] [Single-shot thermometry of simulated Bose--Einstein condensates using artificial intelligence](https://arxiv.org/abs/2506.16925)
**中文标题：利用人工智能对模拟玻色-爱因斯坦凝聚体进行单次测温**

*Jack Griffiths,Steven A. Wrathmall,Simon A. Gardiner*

主要分类: cond-mat.quant-gas

摘要简述: 本文提出了一种基于人工智能的方法，通过单次原位成像快速、非破坏性地估计有限温度玻色气体的化学势和温度，克服了传统测量技术的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 传统测量技术在超冷玻色气体中的热力学参数测定存在破坏性和实验不确定性，亟需一种快速、非破坏性的方法来解决这一问题。

研究方法: 使用卷积神经网络对谐波陷阱中的准二维‘薄饼’凝聚体进行训练，实现从单次密度分布图中快速提取化学势和温度。

研究结果: 模型在未接触过的环形陷阱凝聚体中表现出零样本泛化能力，误差仅为几纳开尔文，并在动态热化过程中保持预测准确性。

研究结论: 监督学习可以克服超冷原子测温的传统限制，为量子气体实验提供实时分析能力，显著提升测量精度和实验效率。

中文摘要: 在超冷玻色气体中精确测定热力学参数仍然具有挑战性，这主要是由于传统测量技术的破坏性和实验中的固有不确定性。我们展示了一种人工智能方法，能够通过有限温度玻色气体的单次原位成像密度分布图，快速、非破坏性地估计化学势和温度。我们的卷积神经网络仅在谐波陷阱中的准二维‘薄饼’凝聚体上进行训练，能够在几秒内完成参数提取。该模型还表现出对陷阱几何形状和热化动力学的零样本泛化能力，成功估计了环形陷阱凝聚体的热力学参数，误差仅为几纳开尔文，尽管在训练过程中未接触过此类几何形状，并且在动态热化过程中保持了预测准确性，而无需对非平衡态进行显式训练。这些结果表明，监督学习可以克服超冷原子测温的传统限制，扩展到更广泛的几何配置、温度范围和附加参数，可能实现对量子气体实验的全面实时分析。这种能力可以显著简化实验流程，同时提高一系列量子流体系统的测量精度。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [393] [A Study of Hybrid and Evolutionary Metaheuristics for Single Hidden Layer Feedforward Neural Network Architecture](https://arxiv.org/abs/2506.15737)
**中文标题：单隐藏层前馈神经网络架构的混合与进化启发式算法研究**

*Gautam Siddharth Kashyap,Md Tabrez Nafis,Samar Wazir*

主要分类: cs.NE

摘要简述: 本文研究了混合粒子群优化（PSO）和遗传算法（GA）作为随机梯度下降（SGD）的替代方案，以解决其局部最优和高计算成本问题。混合PSO-SGD方法显著降低了训练误差，性能优于传统优化方法。


<details>
  <summary>详细信息</summary>
研究动机: 随机梯度下降（SGD）在训练人工神经网络时存在局部最优和高计算成本的问题。本文旨在探索粒子群优化（PSO）和遗传算法（GA）等群体启发式优化方法，以克服这些限制。

研究方法: 开发了一种混合PSO-SGD策略，结合了PSO的全局搜索能力和SGD的局部搜索效率。同时，比较了GA、PSO和随机搜索（RS）的性能。

研究结果: 混合PSO-SGD方法将训练均方误差（MSE）降低了90%至95%，显著优于传统GA和PSO。随机搜索（RS）表现最差，误差超过0.3。

研究结论: 混合和进化优化方法显著提高了神经网络的训练效率和准确性，表明进化搜索中保留了有益的权重结构，支持了构建块假说（BBH）。

中文摘要: 使用随机梯度下降（SGD）训练人工神经网络（ANNs）常面临计算成本高和易陷入局部最优的问题，这归因于其对部分权重梯度的依赖。因此，本研究探讨了粒子群优化（PSO）和遗传算法（GA）这两种基于群体的启发式优化器（MHOs）作为SGD的替代方案，以缓解这些限制。开发了一种混合PSO-SGD策略以提高局部搜索效率。结果表明，混合PSO-SGD方法在不同网络规模下（如在Sphere函数中从约0.02降至约0.001）将训练MSE的中位数降低了90%至95%，优于传统GA和PSO。随机爬山法（RMHC）也取得了显著改进，MSE比GA降低了约85%至90%。同时，随机搜索（RS）的误差始终超过0.3，表现较差。这些发现表明，混合和进化方法显著提升了训练效率和准确性，优于传统优化方法，并暗示构建块假说（BBH）可能仍然成立，表明进化搜索中保留了有益的权重结构。

</details>


### [394] [Robust Dynamic Material Handling via Adaptive Constrained Evolutionary Reinforcement Learning](https://arxiv.org/abs/2506.16795)
**中文标题：基于自适应约束进化强化学习的鲁棒动态物料搬运方法**

*Chengpeng Hu,Ziming Wang,Bo Yuan,Jialin Liu,Chengqi Zhang,Xin Yao*

主要分类: cs.NE

摘要简述: 本文提出了一种自适应约束进化强化学习（ACERL）方法，用于解决动态物料搬运（DMH）问题。ACERL通过维护多样化的执行器群体、处理稀疏奖励和约束违反，并自适应选择训练实例，显著提升了策略的鲁棒性和性能。实验证明ACERL在多种场景下优于现有算法。


<details>
  <summary>详细信息</summary>
研究动机: 动态物料搬运（DMH）问题涉及实时分配动态到达的物料运输任务以最小化完成时间和延迟。由于动态事件（如新任务）的发生，适应性至关重要。现有方法在稀疏奖励和约束满足方面存在挑战，且如何高效利用有限计算资源和历史记录训练鲁棒策略是关键问题。

研究方法: 本文提出自适应约束进化强化学习（ACERL）方法，通过维护多样化的执行器群体探索策略空间，处理稀疏奖励和约束违反。同时，ACERL自适应选择最有益的训练实例以优化策略。

研究结果: 在8个训练和8个未见测试实例上的实验表明，ACERL显著优于多种先进算法。此外，在40个未见噪声实例上的实验验证了其鲁棒性。消融研究进一步证明了ACERL各组成部分的协同作用。

研究结论: ACERL通过多样化探索、约束处理和自适应训练实例选择，有效解决了DMH问题中的稀疏奖励和约束挑战，展现出卓越的性能和鲁棒性。

中文摘要: 动态物料搬运（DMH）涉及实时将动态到达的物料运输任务分配给合适的车辆，以最小化完成时间和延迟。在实际场景中，通常可获取历史任务记录，从而支持基于历史记录的决策策略训练。近年来，强化学习被用于解决DMH问题。由于新任务等动态事件的发生，适应性需求极高。DMH问题的挑战在于需满足任务延迟等约束，且仅在所有任务完成后才能获得反馈，导致奖励稀疏。此外，高效利用有限计算资源和历史记录训练鲁棒策略至关重要，不同问题实例的时间分配对学习过程影响显著。为解决这些挑战，本文提出了一种新颖的自适应约束进化强化学习（ACERL）方法，通过维护多样化的执行器群体进行探索。ACERL通过评估各执行器处理稀疏奖励和约束违反的能力，限制策略行为。同时，ACERL自适应选择最有益的训练实例以优化策略。在8个训练和8个未见测试实例上的大量实验表明，ACERL的性能优于多种先进算法。ACERL训练的策略能完全满足约束条件调度车辆。在40个未见噪声实例上的额外实验验证了ACERL的鲁棒性。交叉验证进一步证明了ACERL的整体有效性。严格的消融研究突出了ACERL各组成部分的协同作用和优势。

</details>


### [395] [Continual Learning with Columnar Spiking Neural Networks](https://arxiv.org/abs/2506.17169)
**中文标题：基于柱状脉冲神经网络的持续学习**

*Denis Larionov,Nikolay Bazenkov,Mikhail Kiselev*

主要分类: cs.NE

摘要简述: 本研究探讨了基于柱状结构的脉冲神经网络（SNNs）在持续学习和灾难性遗忘中的应用。通过CoLaNET（柱状分层网络），发现微柱在新任务中适应性最强时与先前学习无共享结构。实验表明，CoLaNET的超参数能平衡旧知识保留（稳定性）与新信息获取（可塑性），最优配置在十个MNIST任务中保持92%准确率，遗忘率仅4%。


<details>
  <summary>详细信息</summary>
研究动机: 灾难性遗忘是持续学习中的主要挑战，传统神经网络难以平衡新旧任务的学习。本研究旨在探索柱状结构的脉冲神经网络如何通过微柱的独立适应性解决这一问题。

研究方法: 使用CoLaNET（柱状分层网络），通过调整超参数研究微柱在新任务中的适应性。实验设计包括十个顺序MNIST任务，评估模型在稳定性和可塑性之间的权衡。

研究结果: 最优配置在十个MNIST任务中平均准确率达92%，且对首个任务的遗忘率仅为4%，表明CoLaNET能有效平衡新旧任务的学习。

研究结论: 柱状结构的脉冲神经网络（如CoLaNET）通过微柱的独立适应性，显著降低了灾难性遗忘，为持续学习提供了高效解决方案。

中文摘要: 本研究探讨了柱状结构的脉冲神经网络（SNNs）在持续学习和灾难性遗忘中的应用。通过CoLaNET（柱状分层网络），我们发现当微柱与先前学习无共享结构时，其对新任务的适应性最强。实验表明，CoLaNET的超参数能够平衡旧知识保留（稳定性）与新信息获取（可塑性）。最优配置在十个顺序MNIST任务中表现优异，每个任务的平均准确率达92%，且对首个任务的遗忘率仅为4%。

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [396] [DeepRTL2: A Versatile Model for RTL-Related Tasks](https://arxiv.org/abs/2506.15697)
**中文标题：DeepRTL2：一种适用于RTL相关任务的多功能模型**

*Yi Liu,Hongji Zhang,Yunhao Zhou,Zhengyuan Shi,Changran Xu,Qiang Xu*

主要分类: cs.AR

摘要简述: DeepRTL2是一种多功能大语言模型，统一了RTL相关的生成和嵌入任务，填补了EDA领域嵌入任务的空白，并在实验中表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 尽管大语言模型在EDA领域的RTL代码生成和理解中表现出色，但嵌入任务（如代码搜索、功能等价性检查和性能预测）却未被充分研究，而这些任务对硬件设计流程至关重要。

研究方法: 提出DeepRTL2模型，通过统一生成和嵌入任务，为EDA中的多样化挑战提供全面解决方案。

研究结果: 实验表明，DeepRTL2在所有评估任务中均达到最先进的性能水平。

研究结论: DeepRTL2是首个能够同时解决EDA中生成和嵌入任务的模型，为硬件设计流程提供了高效且全面的支持。

中文摘要: 将大语言模型（LLMs）集成到电子设计自动化（EDA）中显著推动了该领域的发展，尤其是在寄存器传输级（RTL）代码生成和理解方面带来了变革性优势。尽管先前的研究已经证明了微调LLMs在这些生成任务中的有效性，但EDA工作流中同样关键的嵌入任务（如自然语言代码搜索、RTL代码功能等价性检查和性能预测）却被忽视了。这些任务对于加速和优化硬件设计流程至关重要。为了填补这一空白，我们提出了DeepRTL2，这是一系列多功能LLMs，统一了与RTL相关的生成和嵌入任务。通过同时解决广泛的任务，DeepRTL2成为首个为EDA中多样化挑战提供全面解决方案的模型。通过大量实验，我们证明DeepRTL2在所有评估任务中均达到了最先进的性能水平。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [397] [Unpacking Generative AI in Education: Computational Modeling of Teacher and Student Perspectives in Social Media Discourse](https://arxiv.org/abs/2506.16412)
**中文标题：解析教育中的生成式AI：社交媒体讨论中师生观点的计算建模**

*Paulina DeVito,Akhil Vallala,Sean Mcmahon,Yaroslav Hinda,Benjamin Thaw,Hanqi Zhuang,Hari Kalva*

主要分类: cs.SI

摘要简述: 本研究通过社交媒体数据分析了生成式AI在教育中的师生观点差异，提出了一种基于GPT-4的模块化框架，其性能优于传统NLP模型，揭示了师生对AI工具的不同态度及潜在矛盾。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI在教育中的快速普及，了解师生对其的认知差异至关重要。本研究旨在通过社交媒体数据全面分析师生观点，为政策制定和实践提供依据。

研究方法: 研究收集了1,199篇Reddit帖子及13,959条评论，采用情感分析、主题建模和作者分类方法，并提出了基于GPT-4的模块化框架，与传统NLP模型进行对比验证。

研究结果: GPT-4框架在情感分析中达到90.6%的准确率，提取出12个潜在主题。学生关注AI检测工具误判作弊的问题，教师则担忧工作安全和学术诚信。师生对AI的个性化学习和生产力提升持乐观态度。

研究结论: 研究表明需制定更清晰的机构政策、透明的AI整合实践及支持机制，以缓解师生矛盾。同时验证了基于大语言模型的框架在在线社区分析中的潜力。

中文摘要: 生成式AI（GAI）技术正迅速改变教育领域。随着其普及加速，了解学生和教师对这些工具的看法至关重要。本研究通过社交媒体数据对教育中GAI的利益相关者讨论动态进行了迄今最全面的分析之一。数据集包括1,199篇Reddit帖子和13,959条顶级评论，应用了情感分析、主题建模和作者分类方法。为此，我们提出并验证了一种基于提示的大语言模型（LLM）模块化框架，用于分析在线社交讨论，并将其与经典自然语言处理（NLP）模型进行对比评估。我们的GPT-4o管道在所有任务中均优于先前方法，例如在情感分析中达到90.6%的准确率（基于人工标注标准）。主题提取揭示了公众讨论中的12个潜在主题，其情感和作者分布各异。教师和学生对GAI在高等教育中个性化学习和生产力提升的潜力持乐观态度，但也存在关键差异：学生常因AI检测工具误判作弊而焦虑，而教师普遍担忧工作安全、学术诚信及机构推广GAI工具的压力。这些对立观点凸显了GAI支持的学习环境中创新与监管之间的张力。研究结果表明，需要更清晰的机构政策、透明的GAI整合实践以及对师生的支持机制。更广泛而言，本研究展示了基于LLM的框架在在线社区利益相关者讨论建模中的潜力。

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [398] [TRUST: Transparent, Robust and Ultra-Sparse Trees](https://arxiv.org/abs/2506.15791)
**中文标题：TRUST：透明、鲁棒且超稀疏的树**

*Albert Dorador*

主要分类: stat.ME

摘要简述: TRUST是一种新型回归树模型，结合了随机森林的预测准确性和浅层决策树的可解释性，并通过大型语言模型生成用户友好的解释，显著提升了透明度和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管分段常数回归树因其可解释性而受欢迎，但其预测准确性通常不如黑盒模型（如随机森林）。本文旨在开发一种兼具高准确性和高可解释性的模型，以满足用户对透明性和性能的双重需求。

研究方法: TRUST模型通过结合随机森林的预测能力和浅层决策树的可解释性，并利用大型语言模型生成定制化的用户友好解释，实现了透明、鲁棒且超稀疏的树结构。

研究结果: 在合成和真实世界基准数据集上的广泛验证表明，TRUST在预测准确性上优于其他可解释模型（如CART、Lasso和Node Harvest），并与随机森林的准确性相当，同时在准确性和可解释性上显著优于M5'模型。

研究结论: TRUST模型成功地将高预测准确性与高可解释性结合，为需要透明性和性能的应用场景提供了有力工具。

中文摘要: 分段常数回归树因其可解释性而广受欢迎，但其预测准确性通常不如黑盒模型（如随机森林）。本文提出了一种新型回归树模型TRUST（透明、鲁棒且超稀疏的树），它结合了随机森林的准确性和浅层决策树的可解释性，同时利用大型语言模型生成用户友好的解释，进一步提升了透明度。在合成和真实世界基准数据集上的广泛验证表明，TRUST在预测准确性上优于其他可解释模型（包括CART、Lasso和Node Harvest），并与随机森林的准确性相当，同时在准确性和可解释性上显著优于M5'模型。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [399] [Unsupervised deep learning model for fast energy layer pre-selection of delivery-efficient proton arc therapy plan optimization of nasopharyngeal carcinoma](https://arxiv.org/abs/2506.15803)
**中文标题：用于鼻咽癌质子弧治疗计划优化的快速能量层预选的无监督深度学习模型**

*Bohan Yang,Gang Liu,Rirao Dao,Yujia Qian,Ke Shi,Anke Tang,Yong Luo,Jingnan Liu*

主要分类: physics.med-ph

摘要简述: 本文提出了一种无监督深度学习模型SPArcdl，用于快速预选质子弧治疗中的能量层，显著提升治疗计划质量和交付效率。


<details>
  <summary>详细信息</summary>
研究动机: 质子弧治疗（PAT）在放射治疗中具有潜力，但能量层序列的优化计算量大。本研究旨在通过无监督深度学习快速预选能量层，减少切换时间并保持高质量治疗计划。

研究方法: 提出了一种新的数据表示方法（spot-count表示），将质子点与目标和危险器官的交点编码为矩阵，输入到基于UNet的SPArcdl模型中。模型优化三目标函数：最大化目标覆盖、最小化危险器官暴露和减少能量切换时间。

研究结果: SPArcdl显著提升了计划质量和交付效率，一致性指数提高0.16，均匀性指数降低0.71，能量切换时间缩短38.4%，脑干平均剂量降低0.21。推理时间在1秒内。

研究结论: SPArcdl是一种快速有效的工具，能通过策略性预选能量层减少交付时间，同时保持优异的剂量性能。

中文摘要: 目的：质子弧治疗（PAT）是一种新兴且有前景的放射治疗方式，相比传统调强质子治疗（IMPT）具有多项优势。然而，由于可能的能量层转换数量庞大，确定最佳能量层（EL）序列计算量巨大。本研究提出了一种无监督深度学习框架，用于快速有效的EL预选，旨在最小化能量层切换时间同时保持高质量计划。方法：我们引入了一种新的数据表示方法（spot-count表示），将质子点与目标和危险器官的交点编码为按机架角度和能量层排序的矩阵。该表示作为基于UNet的架构SPArcdl的输入，模型训练以优化三目标函数：最大化目标覆盖、最小化危险器官暴露和减少能量切换时间。模型在54例鼻咽癌病例上评估，并与SPArc粒子群生成的计划进行对比。主要结果：SPArcdl生成的EL预选显著提升了计划质量和交付效率。相比SPArc粒子群，一致性指数提高0.16（p < 0.01），均匀性指数降低0.71（p < 0.01），能量切换时间缩短38.4%（p < 0.01），脑干平均剂量降低0.21（p < 0.01）。结果意外显示，使用不变的ELS比降序ELS更节省时间。SPArcdl的推理时间在1秒内。意义：SPArcdl是一种快速有效的工具，能通过策略性预选能量层减少交付时间，同时保持优异的剂量性能。

</details>


<div id='astro-ph.EP'></div>

# astro-ph.EP [[Back]](#toc)

### [400] [Exoplanet Classification through Vision Transformers with Temporal Image Analysis](https://arxiv.org/abs/2506.16597)
**中文标题：基于视觉变换器与时间图像分析的系外行星分类**

*Anupma Choudhary,Sohith Bandari,B. S. Kushvah,C. Swastik*

主要分类: astro-ph.EP

摘要简述: 本文提出了一种利用视觉变换器（ViT）和时间图像分析对系外行星进行分类的方法，通过将光曲线数据转换为Gramian角场和递归图，ViT模型在识别系外行星凌日方面表现出色，召回率达89.46%，精确率达85.09%。


<details>
  <summary>详细信息</summary>
研究动机: 传统的系外行星分类方法需要大量计算和观测资源，耗时且成本高昂。因此，研究旨在利用先进的机器学习技术，提高分类效率。

研究方法: 研究将NASA开普勒任务的原始光曲线数据转换为Gramian角场（GAFs）和递归图（RPs），并作为视觉变换器（ViT）模型的输入，利用其捕捉复杂时间依赖性的能力。通过5折交叉验证评估模型性能。

研究结果: 递归图（RPs）表现优于Gramian角场（GAFs），ViT模型的召回率为89.46%，精确率为85.09%，显示出其在准确识别系外行星凌日方面的强大能力。

研究结论: 尽管通过欠采样技术解决了类别不平衡问题，但数据集规模缩小仍是限制。研究强调了进一步优化模型架构以提升自动化、性能和泛化能力的重要性。

中文摘要: 系外行星分类一直是天文学中的一项长期挑战，需要大量的计算和观测资源。传统方法耗费巨大的人力、时间和成本，因此亟需利用先进的机器学习技术提升分类效率。本研究提出了一种方法，将NASA开普勒任务的原始光曲线数据通过Gramian角差场和递归图技术转换为Gramian角场（GAFs）和递归图（RPs）。这些转换后的图像作为视觉变换器（ViT）模型的输入，利用其捕捉复杂时间依赖性的能力。通过召回率、精确率和F1分数等指标评估模型性能，并采用5折交叉验证方法以获取稳健的性能估计并减少评估偏差。对比分析表明，递归图（RPs）优于Gramian角场（GAFs），ViT模型的召回率达到89.46%，精确率为85.09%，显示出其在准确识别系外行星凌日方面的显著能力。尽管使用了欠采样技术解决类别不平衡问题，但数据集规模缩小仍是限制。本研究强调了进一步优化模型架构以提升自动化、性能和泛化能力的重要性。

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [401] [From Prompts to Constructs: A Dual-Validity Framework for LLM Research in Psychology](https://arxiv.org/abs/2506.16697)
**中文标题：从提示到构念：心理学中LLM研究的双效度框架**

*Zhicheng Lin*

主要分类: cs.CY

摘要简述: 本文提出一个双效度框架，用于心理学研究中大型语言模型（LLM）的验证，强调需根据科学目标调整证据标准，避免将统计假象误认为心理现象。


<details>
  <summary>详细信息</summary>
研究动机: 心理学研究中广泛使用大型语言模型（LLM），但将人类测量工具应用于这些模型可能产生矛盾结果，导致许多发现仅为统计假象而非真实心理现象。本文旨在通过整合可靠测量原则和因果推断标准，构建稳健的AI心理学科学。

研究方法: 提出双效度框架，明确不同科学目标所需的证据标准。例如，LLM用于文本分类仅需基本准确性检查，而模拟焦虑则需更严格的验证过程。

研究结果: 当前实践未能满足这些要求，常将统计模式匹配误认为心理现象证据。需开发心理构念的计算类比，并建立清晰、可扩展的证据标准。

研究结论: 未来需避免不加批判地应用人类测量工具，转而开发适用于LLM的验证策略，以支持测量、表征、模拟或建模心理构念的不同研究目标。

中文摘要: 大型语言模型（LLM）正迅速应用于心理学领域，作为研究工具、实验对象、人类模拟器和认知计算模型。然而，将人类测量工具应用于这些系统可能产生矛盾结果，引发担忧：许多发现可能是测量幻象——统计假象而非真实心理现象。本文认为，构建稳健的AI心理学科学需整合心理学两大基础支柱：可靠测量原则和因果推断标准。我们提出双效度框架以指导这一整合，明确支持某一主张所需的证据如何随其科学目标而变化。例如，用LLM分类文本可能仅需基本准确性检查，而声称其能模拟焦虑则需更严格的验证过程。当前实践常将统计模式匹配视为心理现象证据，未能满足这些要求。同一模型输出（如“我感到焦虑”）需根据研究目标是测量、表征、模拟还是建模心理构念，采用不同的验证策略。未来需开发心理构念的计算类比，并建立清晰、可扩展的证据标准，而非不加批判地应用人类测量工具。

</details>


### [402] [Large Language Models as Psychological Simulators: A Methodological Guide](https://arxiv.org/abs/2506.16702)
**中文标题：大语言模型作为心理模拟器：一种方法论指南**

*Zhicheng Lin*

主要分类: cs.CY

摘要简述: 本文为心理学研究提供了一种利用大语言模型（LLMs）作为心理模拟器的方法论框架，涵盖角色模拟和认知建模两大应用，并探讨了验证方法、伦理问题及模型局限性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在心理学和行为研究中展现出潜力，但缺乏系统的方法论指导。本文旨在填补这一空白，帮助研究者有效利用LLMs进行心理模拟和认知建模。

研究方法: 文章提出了两种主要应用方法：1）通过心理角色模拟探索多样化情境；2）作为计算模型研究认知过程。具体包括角色开发、数据验证、内部表征探测、因果干预及模型行为与人类认知的关联策略。

研究结果: 研究整合了LLMs在心理学研究中的实证证据，包括系统性偏差、文化局限性和提示敏感性，并提供了应对这些挑战的策略。

研究结论: 本文强调了对模型能力和限制的透明性需求，为心理学研究者提供了一个利用LLMs独特能力的框架，同时指出了未来研究的方向和伦理考量。

中文摘要: 大语言模型（LLMs）为心理学和行为研究提供了新兴机会，但缺乏方法论指导。本文提供了一个框架，将LLMs作为心理模拟器应用于两大主要方向：模拟角色和人物以探索多样化情境，以及作为计算模型研究认知过程。在模拟方面，我们提出了开发基于心理学的角色方法，超越人口统计类别，并提供了验证策略和用例，从研究难以触及的群体到原型研究工具。在认知建模方面，我们综合了探测内部表征的新方法、因果干预的方法论进展，以及将模型行为与人类认知关联的策略。我们还讨论了包括提示敏感性、训练数据截止时间限制和伦理考量在内的挑战，强调了对模型能力和限制的透明性需求。这一框架整合了关于LLM性能的新兴实证证据，帮助研究者应对挑战并利用LLMs在心理学研究中的独特能力。

</details>


### [403] [TrajSceneLLM: A Multimodal Perspective on Semantic GPS Trajectory Analysis](https://arxiv.org/abs/2506.16401)
**中文标题：TrajSceneLLM：多模态视角下的语义GPS轨迹分析**

*Chunhou Ji,Qiumeng Li*

主要分类: cs.CY

摘要简述: TrajSceneLLM提出了一种多模态框架，结合地图图像和文本描述，增强GPS轨迹的语义理解，显著提升了旅行模式识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法难以提取GPS轨迹的深层语义信息并融入地图上下文，因此需要一种新方法以增强轨迹的语义理解和时空依赖性。

研究方法: TrajSceneLLM整合了地图图像（空间上下文）和LLM生成的文本描述（时间序列和动态），生成多模态嵌入，并通过MLP分类器进行任务验证。

研究结果: 实验表明，该方法在旅行模式识别任务中表现优异，显著减少了对手工特征的依赖，并提升了性能。

研究结论: TrajSceneLLM为地理空间人工智能的多样化下游应用提供了潜力，代码和数据集已公开。

中文摘要: GPS轨迹数据揭示了人类移动和城市动态的宝贵模式，支持多种空间应用。然而，传统方法往往难以提取深层语义表征并融入地图上下文信息。我们提出了TrajSceneLLM，一种多模态视角，用于增强GPS轨迹的语义理解。该框架整合了可视化地图图像（编码空间上下文）和通过LLM推理生成的文本描述（捕捉时间序列和移动动态）。为每种模态生成独立的嵌入，然后拼接以生成具有丰富语义内容的轨迹场景嵌入，并进一步与简单的MLP分类器配对。我们在旅行模式识别（TMI）这一关键任务上验证了所提出的框架，该任务用于分析出行选择和理解移动行为。实验表明，这些嵌入显著提升了性能，凸显了我们LLM驱动的方法在捕捉深层时空依赖性和减少对手工特征依赖方面的优势。这种语义增强为地理空间人工智能的多样化下游应用和未来研究提供了巨大潜力。源代码和数据集已公开于：https://github.com/februarysea/TrajSceneLLM。

</details>


### [404] [LLM-Based Bot Broadens the Range of Arguments in Online Discussions, Even When Transparently Disclosed as AI](https://arxiv.org/abs/2506.17073)
**中文标题：基于LLM的机器人拓宽了在线讨论中的观点范围，即使明确披露为AI**

*Valeria Vuk,Cristina Sarasua,Fabrizio Gilardi*

主要分类: cs.CY

摘要简述: 研究表明，基于LLM的聊天机器人能够显著拓宽在线政治讨论中的观点范围，即使明确披露其为AI，效果依然显著。


<details>
  <summary>详细信息</summary>
研究动机: 在线政治讨论常因自我选择和同质化交流导致观点单一，影响民主参与的广泛性。本研究旨在探索LLM机器人是否能通过引入缺失观点来丰富讨论内容。

研究方法: 通过两项预注册的随机实验，在聊天室中部署一个LLM机器人，实时监测讨论并补充缺失观点。实验评估了机器人对讨论多样性的影响，并测试了AI披露是否影响效果。

研究结果: 实验结果显示，LLM机器人显著拓宽了讨论中的观点范围，且AI披露未显著改变其效果。

研究结论: 基于LLM的讨论辅助工具能够有效促进在线政治讨论的多样性，为民主参与提供新思路。

中文摘要: 广泛的参与对民主至关重要，有助于防止极端观点主导、合法性削弱和政治极化。然而，在线政治讨论常因自我选择和同质化交流导致观点范围有限。本研究通过两项预注册的随机实验，在聊天室中测试了基于LLM的机器人是否能通过监测讨论并补充缺失观点来拓宽讨论范围。结果显示，该机器人显著扩大了讨论中的观点范围，且披露其为AI并未显著影响效果。这表明基于LLM的辅助工具可以积极影响在线政治讨论。

</details>
