<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.CV](#cs.CV) [Total: 112]
- [cs.AI](#cs.AI) [Total: 13]
- [stat.ME](#stat.ME) [Total: 1]
- [cs.GR](#cs.GR) [Total: 4]
- [eess.IV](#eess.IV) [Total: 8]
- [cs.SE](#cs.SE) [Total: 6]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.HC](#cs.HC) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.SD](#cs.SD) [Total: 5]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 36]
- [cs.RO](#cs.RO) [Total: 5]
- [cs.DL](#cs.DL) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [math.NA](#math.NA) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [stat.ML](#stat.ML) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
**中文标题：面向表格数据的概率问答研究**

*Chen Shen,Sajjadur Rahman,Estevam Hruschka*

主要分类: cs.CL

摘要简述: 本文提出了一种针对表格数据的概率问答新方法，结合贝叶斯网络和大语言模型（LLMs），显著提升了不确定性问题的回答能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有的表格问答系统（如NL2SQL）在处理确定性事实问题时表现良好，但在需要概率推理的问题上表现不足。本文旨在填补这一空白，提出一种能够处理概率性问题的框架。

研究方法: 方法包括：1）从表格数据中构建贝叶斯网络；2）将自然语言查询转化为概率查询；3）利用大语言模型（LLMs）生成最终答案。通过符号与神经网络的混合推理实现概率问答。

研究结果: 实验结果表明，该方法在基准测试LUCARIO上显著优于基线模型，验证了混合符号-神经网络推理的有效性。

研究结论: 本文提出的概率问答框架在处理不确定性问题上具有显著优势，为表格数据的复杂推理任务提供了新思路。

中文摘要: 当前针对表格数据的问答系统（如NL2SQL）在处理确定性事实问题时表现良好，但在需要概率推理的问题上表现不足。本文提出了一个新的基准测试LUCARIO和一个针对大规模表格数据的概率问答框架。我们的方法从表格中构建贝叶斯网络，将自然语言查询转化为概率查询，并利用大语言模型（LLMs）生成最终答案。实验结果表明，该方法在基线模型上取得了显著改进，凸显了符号与神经网络混合推理的优势。

</details>


### [2] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
**中文标题：大型语言模型的多语言功能评估**

*Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian*

主要分类: cs.CL

摘要简述: 本文提出跨语言功能评估基准（CL-GSM Symbolic和CL-IFEval），通过翻译现有功能基准模板到五种语言，揭示静态多语言基准与实际功能性能的差距，并发现模型在不同语言间的鲁棒性差异显著。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型语言模型多语言能力评估多依赖静态数据基准（如Belebele、M-MMLU和M-GSM），但这些评估无法充分反映模型在多语言环境中的实际性能和鲁棒性。

研究方法: 通过将现有的功能基准模板从英语翻译到五种语言（法语、西班牙语、印地语、阿拉伯语和约鲁巴语），创建了跨语言功能评估基准CL-GSM Symbolic和CL-IFEval。

研究结果: 结果显示，某些静态多语言基准与实际功能性能差距较大（如M-GSM与CL-GSM Symbolic在英语、法语和西班牙语中性能分别下降24%、17%和18%），且模型在不同语言间的鲁棒性差异显著（如阿拉伯语和英语表现最稳定）。

研究结论: 跨语言功能评估基准能更准确地评估模型的实际性能，同时揭示了模型在不同语言间的鲁棒性差异，为未来多语言模型评估提供了新方向。

中文摘要: 大型语言模型的多语言能力通常通过静态数据基准（如Belebele、M-MMLU和M-GSM）进行评估，但这些评估往往无法充分反映模型在多语言环境中的实际性能和鲁棒性。为此，我们通过将现有的功能基准模板从英语翻译到五种语言（法语、西班牙语、印地语、阿拉伯语和约鲁巴语），创建了跨语言功能评估基准——跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令跟随评估（CL-IFEval）。结果显示，某些静态多语言基准与实际功能性能差距较大（如M-GSM与CL-GSM Symbolic在英语、法语和西班牙语中性能分别下降24%、17%和18%），而某些基准（如M-MMLU与CL-IFEval）差距较小（仅0.5%至3%）。此外，模型在不同语言间的鲁棒性差异显著，某些语言（如阿拉伯语和英语）在多次评估中表现最稳定。

</details>


### [3] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
**中文标题：创意与执行的差距：LLM生成与人类研究想法的执行结果对比**

*Chenglei Si,Tatsunori Hashimoto,Diyi Yang*

主要分类: cs.CL

摘要简述: 研究发现，尽管LLM生成的研究想法在创意阶段被认为更具新颖性，但在实际执行后，其效果显著下降，甚至不如人类专家的想法。这表明当前LLM在生成真正有效的研究想法上存在局限。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在科学研究中展现出加速研究流程的潜力，但其生成的研究想法是否能在执行后产生更好的研究成果尚未明确。本研究旨在验证LLM生成的想法在执行后的实际效果。

研究方法: 研究招募了43位专家研究人员，随机分配执行由专家或LLM生成的研究想法。每位专家花费超过100小时实施想法，并撰写4页的简短论文记录实验。所有项目由NLP专家进行盲审，比较执行前后的评分差异。

研究结果: 执行后，LLM生成的想法在所有评估指标（新颖性、兴奋度、有效性和总体评分）上的得分显著下降（p < 0.05），甚至在某些指标上人类想法的评分反超LLM想法。

研究结论: 研究揭示了LLM生成想法在创意与执行阶段的差距，表明当前LLM在生成真正有效的研究想法上存在局限性，并强调了仅凭创意阶段评估研究想法的挑战。

中文摘要: 大型语言模型（LLM）在加速科学研究流程方面展现出潜力，其关键能力之一是生成新颖的研究想法。此前研究发现，在某些情境下，LLM生成的研究想法被认为比人类专家的想法更具新颖性。然而，一个好的想法不仅应看似新颖，还应在执行后产生更好的研究成果。为了验证AI生成的想法是否会导致更好的研究结果，我们开展了一项执行研究，招募了43位专家研究人员，随机分配执行由专家或LLM生成的想法。每位专家花费超过100小时实施想法，并撰写4页的简短论文记录实验。所有项目由NLP专家进行盲审。比较执行前后相同想法的评分发现，LLM生成的想法在所有评估指标（新颖性、兴奋度、有效性和总体评分）上的得分显著下降（p < 0.05），缩小了创意阶段观察到的LLM与人类想法的差距。在执行研究的汇总评分中，甚至发现许多指标的排名出现反转，人类想法的评分高于LLM想法。这一创意与执行的差距凸显了当前LLM在生成真正有效的研究想法上的局限性，以及在缺乏执行结果的情况下评估研究想法的挑战。

</details>


### [4] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
**中文标题：MultiFinRAG：一种优化的多模态检索增强生成框架，用于金融问答**

*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

主要分类: cs.CL

摘要简述: MultiFinRAG是一个专为金融问答设计的优化多模态检索增强生成框架，通过多模态提取和动态分层检索策略，显著提升了复杂金融问答任务的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 金融文件（如10-K、10-Q和投资者演示文稿）通常包含数百页的多模态内容（文本、表格和图表），传统大语言模型（LLM）和检索增强生成（RAG）方法因标记限制和跨模态上下文碎片化而难以处理。MultiFinRAG旨在解决这些问题。

研究方法: MultiFinRAG首先通过轻量级开源多模态LLM对表格和图表进行批量处理，生成结构化JSON和文本摘要。随后，结合叙事文本，使用模态感知相似度阈值进行嵌入和索引。动态分层回退策略根据需要从纯文本扩展到文本+表格+图像上下文，实现跨模态推理。

研究结果: MultiFinRAG在涉及文本、表格、图像和跨模态推理的复杂金融问答任务中，比免费版ChatGPT-4o的准确率高出19个百分点，且运行在普通硬件上。

研究结论: MultiFinRAG通过优化多模态处理和动态检索策略，显著提升了金融问答的性能，为处理复杂多模态金融文档提供了高效解决方案。

中文摘要: 金融文件（如10-K、10-Q和投资者演示文稿）通常包含数百页的多模态内容，包括密集叙述文本、结构化表格和复杂图表。传统大语言模型（LLM）和检索增强生成（RAG）方法因标记限制、布局丢失和跨模态上下文碎片化而难以处理此类内容。我们提出了MultiFinRAG，一个专为金融问答设计的检索增强生成框架。MultiFinRAG首先通过轻量级开源多模态LLM对表格和图表进行批量处理，生成结构化JSON和文本摘要。随后，结合叙事文本，使用模态感知相似度阈值进行嵌入和索引。动态分层回退策略根据需要从纯文本扩展到文本+表格+图像上下文，实现跨模态推理。尽管运行在普通硬件上，MultiFinRAG在涉及文本、表格、图像和跨模态推理的复杂金融问答任务中，比免费版ChatGPT-4o的准确率高出19个百分点。

</details>


### [5] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
**中文标题：揭示大型语言模型的隐藏暴力倾向：基于行为小插曲的人口统计分析**

*Quintin Myers,Yanjun Gao*

主要分类: cs.CL

摘要简述: 本文首次使用社会科学的有效工具（VBVQ）评估大型语言模型（LLMs）在道德模糊场景中的暴力倾向，发现其文本生成与内在暴力偏好存在差异，且暴力倾向因人口统计特征而异。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）被提议用于检测和应对网络暴力内容，但其在道德模糊的真实场景中的推理能力尚未充分研究。本文旨在填补这一空白，评估LLMs的暴力倾向及其潜在偏见。

研究方法: 研究采用已验证的社会科学工具VBVQ，通过基于人物角色的提示（涵盖种族、年龄和地理身份）评估六种不同背景开发的LLMs，统一采用零样本设置。

研究结果: 研究发现：（1）LLMs的表面文本生成与其内在暴力偏好不一致；（2）其暴力倾向因人口统计特征而异，且常与犯罪学、社会科学和心理学的已知结论相矛盾。

研究结论: LLMs在暴力倾向方面存在与人类行为不一致的偏差，需进一步研究以确保其应用的公平性和可靠性。

中文摘要: 大型语言模型（LLMs）越来越多地被提议用于检测和应对网络暴力内容，但其在道德模糊的真实场景中的推理能力尚未充分研究。我们首次使用已验证的社会科学工具——暴力行为小插曲问卷（VBVQ）评估LLMs。为评估潜在偏见，我们引入了基于人物角色的提示，涵盖美国境内的种族、年龄和地理身份。在统一的零样本设置下，评估了六种不同地缘政治和组织背景下开发的LLMs。研究发现：（1）LLMs的表面文本生成常与其内在暴力偏好不一致；（2）其暴力倾向因人口统计特征而异，且常与犯罪学、社会科学和心理学的已知结论相矛盾。

</details>


### [6] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
**中文标题：少做决定，多沟通：医学中端到端事实核查的建构效度**

*Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li*

主要分类: cs.CL

摘要简述: 本文探讨了医学领域端到端事实核查系统的局限性，指出其在实际应用中面临的挑战，并建议将其视为交互式沟通问题而非端到端流程。


<details>
  <summary>详细信息</summary>
研究动机: 由于医学决策的高风险性和医学文献的复杂性，公众对医学事实核查系统的需求增加。然而，现有系统未被广泛采用，本文旨在揭示其原因。

研究方法: 通过研究临床专家如何验证社交媒体上的真实医学声明并综合医学证据，探索端到端事实核查在医学中的可行性。

研究结果: 研究发现，端到端事实核查在医学中面临三大挑战：难以将现实中的声明与临床试验证据关联；声明模糊且意图不匹配；以及真实性标签的主观性。

研究结论: 作者认为，医学事实核查应被视为交互式沟通问题，而非端到端流程，并需重新评估其设计和评价方式。

中文摘要: 技术进步推动了自动事实核查等挑战性任务的具体进展。由于医学决策的高风险性以及对海量多样化医学文献的批判性评估困难，公众对在公共卫生和医学中采用此类系统的兴趣日益增长。循证医学与每个人息息相关，但其高度技术性的本质使得大多数用户的医学素养不足以充分驾驭这一领域。医学沟通中的这些问题为端到端事实核查代理提供了成熟的条件：根据当前医学文献核查声明并返回基于证据的结论。然而，此类系统仍未被广泛使用。为了理解这一点，我们首次研究了临床专家如何通过综合医学证据验证社交媒体上的真实声明。在寻找这一上限的过程中，我们揭示了端到端事实核查在医学应用中的根本挑战：难以将现实中的声明与临床试验形式的科学证据联系起来；模糊声明与不匹配意图的混合；以及真实性标签的固有主观性。我们认为，事实核查应被视为交互式沟通问题，而非端到端流程，并以此进行评估。

</details>


### [7] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
**中文标题：优化语言模型在下游任务中的适应性：后训练视角**

*Zhengyan Shi*

主要分类: cs.CL

摘要简述: 本文提出了一系列优化语言模型（LM）下游任务适应性的方法，包括利用未标注数据的持续预训练技术、参数高效微调方法以及改进的监督微调策略，显著提升了模型的鲁棒性、效率和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着语言模型规模和复杂度的增加，传统的微调方法存在未充分利用未标注数据、在小规模任务数据上过拟合以及计算成本高的问题，限制了其在现实语言任务中的广泛应用。

研究方法: 1. 提出一种新颖的持续预训练技术，从未标注数据中提取任务相关知识；2. 设计参数高效的微调方法，降低内存和计算成本；3. 改进监督微调策略，提升模型在标注数据稀缺时的性能；4. 开发新的评估方法和基准任务（如多跳空间推理任务）。

研究结果: 通过多样化NLP任务的实证研究，这些方法显著提升了语言模型的鲁棒性、效率和泛化能力，使其更适应广泛的应用场景。

研究结论: 这些进展标志着语言模型在鲁棒性和效率方面的重要进步，为实现更通用的人工智能目标迈出了关键一步。

中文摘要: 语言模型（LM）在自然语言处理（NLP）中展现出卓越能力，但如何高效且鲁棒地将其适配到特定任务仍具挑战性。随着模型规模和复杂度的增加，基于标注数据的微调往往未充分利用未标注数据，容易在小规模任务数据上过拟合，且计算成本高昂。这些限制阻碍了其在现实语言任务中的广泛应用。

本文提出了一系列优化LM下游任务适应性的方法。首先，探索从未标注数据中提取任务相关知识的策略，提出一种新颖的持续预训练技术，其性能优于当前最先进的半监督方法。其次，提出一种参数高效的微调方法，显著降低内存和计算成本，同时保持竞争力。此外，改进的监督微调方法使LM在标注数据稀缺时也能更好地遵循指令，提升其在包括开放生成在内的多种NLP任务中的表现。最后，开发了新的评估方法和基准任务（如多跳空间推理任务），以更全面地评估LM的能力和适应性。

通过多样化NLP任务的实证研究，结果表明这些方法显著提升了LM的鲁棒性、效率和泛化能力，使其更适应广泛的应用场景。这些进展标志着语言模型在鲁棒性和效率方面的重要进步，为实现更通用的人工智能目标迈出了关键一步。

</details>


### [8] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
**中文标题：FineWeb2：一管通天下——预训练数据处理适应所有语言**

*Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf*

主要分类: cs.CL

摘要简述: 本文提出了一种名为FineWeb2的多语言预训练数据集处理管道，可自动适应任何语言，并通过实验验证其在九种语言上的有效性。最终生成了一个20TB的多语言数据集FineWeb2，并公开了相关代码。


<details>
  <summary>详细信息</summary>
研究动机: 当前多语言大语言模型（LLM）的训练面临数据清洗和去重管道难以适应多语言的挑战。本文旨在开发一种通用管道，支持任何语言的预训练数据高效处理。

研究方法: 基于FineWeb设计了一种新的预训练数据集处理管道，通过实验在九种语言上验证其设计选择，并采用基于可测量标准的任务选择方法进行评估。此外，提出了一种考虑重复计数和质量的再平衡方法。

研究结果: 实验表明，该管道生成的非英语语料库优于现有数据集，且再平衡方法进一步提升了性能。最终扩展至1000多种语言，生成了20TB的FineWeb2数据集。

研究结论: FineWeb2管道能够高效处理多语言预训练数据，生成高质量语料库，并通过公开代码和数据集推动多语言LLM的发展。

中文摘要: 预训练最先进的大语言模型（LLM）需要大量干净且多样化的文本数据。尽管近期在高质量英语预训练数据集的开放开发方面取得了显著进展，但训练高性能的多语言LLM仍然是一个挑战，主要原因在于难以针对大量语言定制过滤和去重管道。本文提出了一种基于FineWeb的新预训练数据集处理管道，可自动适应支持任何语言。我们在九种多样化语言上对管道设计选择进行了广泛实验，并通过基于可测量标准的新颖任务选择方法进行评估。最终表明，该管道可用于创建优于现有数据集的非英语语料库。此外，我们提出了一种简单且原则性的再平衡方法，综合考虑重复计数和质量，进一步提升了性能。最后，我们将管道扩展至1000多种语言，利用近100个Common Crawl快照生成了FineWeb2，一个20TB（50亿文档）的多语言数据集，并公开了管道、训练和评估代码库。

</details>


### [9] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
**中文标题：KaLM-Embedding-V2：卓越的训练技术与数据激发多功能嵌入模型**

*Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang*

主要分类: cs.CL

摘要简述: 本文提出KaLM-Embedding-V2，一种多功能紧凑的嵌入模型，通过创新的训练技术和数据优化，在通用文本嵌入任务中表现卓越。


<details>
  <summary>详细信息</summary>
研究动机: 现有嵌入模型在通用性和性能上存在不足，尤其是在紧凑模型规模下。本文旨在通过改进训练技术和数据策略，提升嵌入模型的性能与泛化能力。

研究方法: 1. 采用双向Transformer架构和均值池化生成固定长度嵌入；2. 多阶段训练流程：预训练、微调和模型参数平均；3. 引入焦点式重加权机制和在线硬负样本混合策略；4. 收集多样化数据用于训练。

研究结果: 在MTEB中英文评测中，KaLM-Embedding-V2显著优于同类模型，并与更大规模的模型竞争，性能接近3倍至26倍参数的模型。

研究结论: KaLM-Embedding-V2通过创新的训练技术和数据策略，为紧凑嵌入模型设立了新标准，展示了高性能和强泛化能力。

中文摘要: 本文提出KaLM-Embedding-V2，一种多功能紧凑的嵌入模型，通过创新的训练技术和数据优化，在通用文本嵌入任务中表现卓越。主要创新包括：1. 采用双向Transformer架构和均值池化生成固定长度嵌入；2. 多阶段训练流程：预训练、微调和模型参数平均；3. 引入焦点式重加权机制和在线硬负样本混合策略；4. 收集20类预训练数据和100类微调数据以提升性能。在MTEB中英文评测中，该模型显著优于同类模型，并与更大规模的模型竞争，为紧凑嵌入模型设立了新标准。

</details>


### [10] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
**中文标题：梯度下降能否模拟提示的效果？**

*Eric Zhang,Leshem Choshen,Jacob Andreas*

主要分类: cs.CL

摘要简述: 本文探讨了梯度下降能否模拟提示的效果，提出了一种元训练方法，使得梯度更新能够模仿提示的效果，从而提升模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前语言模型（LM）有两种主要的信息更新方式：修改提示或调整参数（如微调）。参数更新无长期存储成本，但提示在许多情况下更有效。本文旨在探索是否可以通过梯度下降模拟提示的效果，从而结合两者的优势。

研究方法: 提出了一种元训练方法，利用梯度下降的元学习工具，以LM自身的提示预测为目标，无需真实标签。通过梯度下降训练，模型能够部分或完全恢复提示模型的性能。

研究结果: 实验表明，该方法在“反转诅咒”任务和文本问答任务中表现优异，单次梯度更新后即可显著提升性能，证明了梯度下降的表达能力。

研究结论: 研究表明，适当的初始化下，梯度下降具有强大的表达能力，为长上下文建模和梯度学习的泛化能力提供了新思路。

中文摘要: 语言模型（LM）有两种主要的信息更新方式：修改提示或调整参数（如微调）。参数更新无长期存储成本，但提示在许多情况下更有效：提示模型能从单例中泛化并完成逻辑推理，而标准微调则无法实现。本文探索是否可以通过调整模型，使得微调能够模拟提示的效果。我们提出了一种元训练方法，利用梯度下降的元学习工具，以LM自身的提示预测为目标，无需真实标签。实验表明，梯度下降训练能部分或完全恢复提示模型的性能，在“反转诅咒”任务和文本问答任务中表现优异。这些结果表明，在适当的初始化下，梯度下降具有强大的表达能力，为长上下文建模和梯度学习的泛化能力提供了新视角。

</details>


### [11] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
**中文标题：SAC：一种用于测量和动态控制LLM人格特质强度的框架**

*Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SAC的框架，用于测量和动态控制大型语言模型（LLM）的人格特质强度，通过扩展16PF模型和改进Big Five模型，实现了更精细和可控的人格表达。


<details>
  <summary>详细信息</summary>
研究动机: 当前LLM的人格建模多依赖Big Five模型，其维度较粗且缺乏强度控制机制。本文旨在填补这一空白，通过引入16PF模型和动态强度控制，提升LLM人格表达的细腻度和可控性。

研究方法: 扩展了机器人格量表（MPI），引入16PF模型，并开发了SAC框架，通过形容词语义锚定和五个强度因子（频率、深度、阈值、努力和意愿）动态控制特质强度。

研究结果: 实验表明，连续谱强度建模比二元切换更一致和可控，且目标特质强度的变化会系统影响相关特质，表明LLM内化了多维人格结构。

研究结论: SAC框架为LLM提供了更细腻和可控的人格表达，推动了人机交互在医疗、教育等领域的应用，迈向更接近人类的社会机器。

中文摘要: 近年来，大型语言模型（LLM）在多个领域获得了广泛应用，人们对其在交互中展现类人性格的期望也日益增长。为满足这一需求，许多研究提出了通过心理测量评估建模LLM人格的方法。然而，现有模型大多依赖Big Five（OCEAN）框架，仅提供粗略的人格维度，且缺乏特质强度控制机制。本文通过扩展原本基于Big Five模型的机器人格量表（MPI），引入16人格因子（16PF）模型，实现了对16种特质的精细控制。我们还开发了名为特定属性控制（SAC）的结构化框架，用于评估和动态诱导LLM的特质强度。该方法通过形容词语义锚定引导特质强度表达，并利用五个强度因子（频率、深度、阈值、努力和意愿）的行为问题。实验表明，将强度建模为连续谱比二元切换更能实现一致且可控的人格表达。此外，目标特质强度的变化会系统影响相关特质，表明LLM内化了多维人格结构而非孤立处理特质。我们的工作为医疗、教育和面试等领域的可控且细腻的人机交互开辟了新途径，使我们离真正类人的社会机器更近一步。

</details>


### [12] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
**中文标题：大型语言模型在特许会计师考试中的优异表现**

*Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta*

主要分类: cs.CL

摘要简述: 大型语言模型（LLMs）在财务领域的应用潜力巨大，但其在特定财务知识上的表现尚不明确。本文通过CA-Ben基准测试评估了六种主流LLMs在财务、法律和定量推理上的能力，发现Claude 3.5 Sonnet和GPT-4o表现最佳，但在数值计算和法律解释上仍有挑战。


<details>
  <summary>详细信息</summary>
研究动机: 尽管LLMs在自然语言处理方面取得了显著进展，但其在财务领域的专业知识和应用能力尚未得到充分验证。本文旨在填补这一空白，特别是在印度财务背景下，通过设计专门的基准测试CA-Ben来评估LLMs的表现。

研究方法: 研究设计了CA-Ben基准测试，基于印度特许会计师协会（ICAI）的考试题库，涵盖基础、中级和高级课程内容。六种主流LLMs（GPT 4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4）通过标准化协议进行评估。

研究结果: 结果显示，Claude 3.5 Sonnet和GPT-4o在概念和法律推理上表现最优，但在数值计算和法律解释方面存在显著挑战。其他模型的表现则相对较弱。

研究结论: 当前LLMs在财务领域的应用具有潜力，但在定量分析和法律解释方面仍需改进。未来可通过混合推理和检索增强生成方法进一步提升性能。

中文摘要: 先进的智能系统，尤其是大型语言模型（LLMs），通过自然语言处理（NLP）的进步正在显著重塑财务实践。然而，这些模型在多大程度上能够有效掌握和应用特定领域的财务知识仍不确定。针对印度广阔财务背景下的关键空白，本文提出了CA-Ben，一个专门用于评估LLMs在财务、法律和定量推理能力上的特许会计师基准测试。CA-Ben包含基于印度特许会计师协会（ICAI）严格考试的结构化问答数据集，涵盖基础、中级和高级课程阶段。六种主流LLMs（即GPT 4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4）通过标准化协议进行了评估。结果显示性能存在差异，Claude 3.5 Sonnet和GPT-4o表现最优，尤其是在概念和法律推理方面。数值计算和法律解释方面则面临显著挑战。研究结果强调了当前LLMs的优势和局限性，并建议通过混合推理和检索增强生成方法进行未来改进，特别是在定量分析和准确法律解释方面。

</details>


### [13] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
**中文标题：一种半监督可扩展的电子商务查询分类统一框架**

*Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law*

主要分类: cs.CL

摘要简述: 本文提出了一种半监督可扩展的统一框架（SSUF），用于解决电子商务查询分类中的信息不足和标签依赖问题，通过知识增强、标签增强和结构增强模块显著提升了分类性能。


<details>
  <summary>详细信息</summary>
研究动机: 电子商务查询通常简短且缺乏上下文，现有方法依赖用户点击行为构建训练样本，导致马太效应，且缺乏统一框架，算法优化效率低。

研究方法: SSUF框架包含知识增强模块（利用世界知识增强查询表示）、标签增强模块（利用标签语义和半监督信号减少对后验标签的依赖）和结构增强模块（基于复杂标签关系增强标签表示），各模块高度可插拔。

研究结果: 离线和在线A/B实验表明，SSUF显著优于现有最先进模型。

研究结论: SSUF通过统一框架和增强模块有效解决了电子商务查询分类中的信息不足和标签依赖问题，提升了分类性能。

中文摘要: 查询分类（包括意图和类别预测等多个子任务）对电子商务应用至关重要。电子商务查询通常简短且缺乏上下文，标签间信息无法利用，导致建模先验信息不足。现有工业查询分类方法多依赖用户点击行为构建训练样本，形成马太效应。此外，查询分类子任务缺乏统一框架，算法优化效率低。本文提出了一种半监督可扩展统一框架（SSUF），包含多个增强模块以统一查询分类任务。知识增强模块利用世界知识增强查询表示，解决查询信息不足问题；标签增强模块利用标签语义和半监督信号减少对后验标签的依赖；结构增强模块基于复杂标签关系增强标签表示。各模块高度可插拔，输入特征可根据子任务需求增减。大量离线和在线A/B实验表明，SSUF显著优于现有最先进模型。

</details>


### [14] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
**中文标题：MT2-CSD：一种用于对话立场检测的新数据集与多语义知识融合方法**

*Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang*

主要分类: cs.CL

摘要简述: 本文提出了MT2-CSD数据集和LLM-CRAN方法，用于多目标多轮对话立场检测。MT2-CSD是目前最大且对话深度最丰富的数据集，LLM-CRAN通过利用大语言模型的推理能力显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统立场检测研究多针对单实例，难以模拟真实社交媒体中的多轮对话场景。现有数据集无法充分捕捉社交媒体交互动态，阻碍了对话立场检测的发展。

研究方法: 提出了MT2-CSD数据集，包含24,457个标注实例，并设计了LLM-CRAN方法，利用大语言模型的推理能力增强对话理解。

研究结果: 实验表明，LLM-CRAN在MT2-CSD数据集上显著优于基线模型，验证了其有效性。

研究结论: MT2-CSD和LLM-CRAN为对话立场检测提供了新的数据集和方法，推动了该领域的发展。

中文摘要: 在当代社交媒体领域，自动立场检测对于观点挖掘至关重要，它通过综合和分析用户对争议性话题的看法，揭示主流趋势和情感。传统立场检测研究通常针对单实例，限制了其对真实社交媒体中多轮讨论的建模能力。这一缺陷主要源于缺乏能够真实捕捉社交媒体交互动态的数据集，阻碍了对话立场检测的进展。本文提出了MT2-CSD，一个用于多目标、多轮对话立场检测的综合数据集。据我们所知，MT2-CSD是目前该领域最大的数据集，包含24,457个标注实例，并展示了最丰富的对话深度，为立场检测带来了新的挑战。为应对这些挑战，我们提出了大语言模型增强的对话关系注意力网络（LLM-CRAN），利用大语言模型的推理能力提升对话理解。我们在MT2-CSD数据集上进行了大量实验，评估LLM-CRAN的有效性。实验结果表明，LLM-CRAN在对话立场检测任务中显著优于强基线模型。

</details>


### [15] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
**中文标题：DALR：多模态句子表示学习的双层次对齐学习方法**

*Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji*

主要分类: cs.CL

摘要简述: 本文提出DALR方法，通过双层次对齐学习解决多模态句子表示学习中的跨模态偏差和模态内语义差异问题，显著提升表示质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在多模态句子表示学习中主要关注粗粒度对齐，面临跨模态偏差和模态内语义差异两大挑战，影响表示质量。本文旨在通过双层次对齐学习解决这些问题。

研究方法: DALR方法包括跨模态一致性学习模块（软化负样本并利用辅助任务语义相似性实现细粒度对齐）和模态内全局对齐学习（结合排名蒸馏捕捉复杂句子关系）。

研究结果: 在语义文本相似性（STS）和迁移（TR）任务上的实验表明，DALR优于现有基线方法，验证了其有效性。

研究结论: DALR通过双层次对齐学习显著提升多模态句子表示质量，为跨模态和模态内对齐提供了新思路。

中文摘要: 以往的多模态句子表示学习方法取得了显著成果，但大多数方法仅关注粗粒度的图像与文本对齐，面临跨模态偏差和模态内语义差异两大挑战，严重影响句子表示质量。为解决这些问题，我们提出DALR（多模态句子表示学习的双层次对齐学习）。在跨模态对齐方面，我们提出一致性学习模块，通过软化负样本并利用辅助任务的语义相似性实现细粒度对齐。此外，我们认为句子关系不仅限于二元正负标签，而是具有更复杂的排序结构。为更好地捕捉这些关系并提升表示质量，我们将排名蒸馏与全局模态内对齐学习结合。在语义文本相似性（STS）和迁移（TR）任务上的全面实验验证了方法的有效性，一致表明其优于现有基线方法。

</details>


### [16] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
**中文标题：ComRAG：基于动态向量存储的检索增强生成框架用于工业实时社区问答**

*Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan*

主要分类: cs.CL

摘要简述: ComRAG是一种用于实时工业社区问答的检索增强生成框架，通过动态向量存储整合静态知识和动态历史问答对，显著提升性能并降低延迟。


<details>
  <summary>详细信息</summary>
研究动机: 社区问答平台是重要的知识库，但现有方法未能充分利用外部知识或动态历史上下文，且缺乏适合工业部署的记忆机制。

研究方法: ComRAG采用基于质心的记忆机制，结合静态知识和动态历史问答对，实现高效的检索、生成和存储。

研究结果: 在三个工业CQA数据集上，ComRAG显著优于基线方法，向量相似度提升25.9%，延迟降低8.7%-23.3%，块增长从20.23%降至2.06%。

研究结论: ComRAG通过动态向量存储和高效记忆机制，为工业社区问答提供了高性能、低延迟的解决方案。

中文摘要: 社区问答平台（CQA）是社区中重要的知识库，但如何实时有效地利用历史交互和领域知识仍是一个挑战。现有方法往往未能充分利用外部知识、未能整合动态历史问答上下文，或缺乏适合工业部署的记忆机制。我们提出了ComRAG，一种用于实时工业CQA的检索增强生成框架，通过基于质心的记忆机制将静态知识与动态历史问答对相结合，实现高效的检索、生成和存储。在三个工业CQA数据集上的评估表明，ComRAG在所有基线方法中表现最佳——向量相似度提升高达25.9%，延迟降低8.7%至23.3%，迭代过程中块增长从20.23%降至2.06%。

</details>


### [17] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
**中文标题：Progtuning：基于Transformer语言模型的渐进式微调框架**

*Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu*

主要分类: cs.CL

摘要简述: Progtuning是一种渐进式微调框架，通过动态减少Transformer块的更新数量，优化计算资源分配，减少约25%的参数更新，同时保持高性能。


<details>
  <summary>详细信息</summary>
研究动机: 随着Transformer模型规模增大，全参数微调成本高昂，现有参数高效微调方法仍需更新相同数量的参数，忽略了不同Transformer块的贡献差异，导致计算资源分配低效。

研究方法: Progtuning结合渐进学习，根据Transformer块的贡献逐步减少更新的块数，优化资源分配，并与参数高效微调方法兼容。

研究结果: Progtuning减少约25%的参数更新，同时保持竞争性性能，并在多种适应场景中表现优异。

研究结论: Progtuning通过渐进式微调显著提升资源利用效率，为大规模语言模型微调提供高效解决方案。

中文摘要: 微调是利用基于Transformer的语言模型进行下游任务的一种有效技术。随着模型规模持续增长，更新所有模型参数的成本越来越高。参数高效微调方法通过选择性更新少量参数有效解决了这一问题。然而，微调和大多数现有参数高效微调方法仍需更新与初始规模相同数量的参数，忽略了Transformer块之间的贡献差异，导致计算资源分配极不高效。本文提出Progtuning，一种结合渐进学习的创新微调框架，专为基于Transformer的语言模型设计。具体而言，Progtuning根据贡献逐步减少更新的Transformer块数量。值得注意的是，Progtuning优化了资源分配，减少了约25%的更新参数，同时仍保持竞争性性能。此外，它与参数高效微调方法高度兼容，在多种适应场景中表现出色。

</details>


### [18] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
**中文标题：用于文本扩散建模的压缩平滑潜在空间**

*Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov*

主要分类: cs.CL

摘要简述: 本文提出Cosmos方法，通过在压缩平滑的潜在空间中运行扩散模型，解决了文本生成中高维度和全局一致性问题，实现了高效并行生成，并在多个任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 自回归语言模型在文本生成中占主导地位，但其顺序性导致解码速度慢且难以保持全局一致性。扩散模型虽能并行生成，但因高维度的标记级表示而受限。本文旨在通过压缩平滑的潜在空间解决这些问题。

研究方法: Cosmos方法在压缩平滑的潜在空间中运行扩散模型，通过学习一个同时支持标记级重建和与预训练语言编码器对齐的自编码器，实现语义基础和有效扰动增强。

研究结果: 实验表明，Cosmos能将文本表示压缩8倍，生成质量与标记级扩散模型相当；增加潜在序列长度后，其性能超越扩散模型和自回归基线，推理速度快2倍以上。

研究结论: Cosmos在压缩潜在空间中实现了高效文本生成，性能优于或接近现有方法，为文本扩散模型提供了新思路。

中文摘要: 自回归语言模型主导了现代文本生成，但其顺序性带来了解码速度慢和全局一致性难以维持的根本限制。扩散模型通过并行生成和灵活控制提供了有前景的替代方案，但其在文本生成中的应用因标记级表示的高维度而受限。我们提出了Cosmos，一种完全在压缩平滑潜在空间中运行的文本生成新方法。该空间通过同时训练自编码器实现标记级重建和与冻结预训练语言编码器的对齐，提供强语义基础并支持有效扰动增强。实验表明，Cosmos能将文本表示压缩8倍，同时保持与标记级扩散模型相当的生成质量；增加潜在序列长度后，Cosmos超越了扩散模型和自回归基线。我们在故事生成、问题生成、摘要和去毒化四个任务上评估Cosmos，并与多种生成范式对比。Cosmos在生成质量上表现相当或更优，同时推理速度快2倍以上。

</details>


### [19] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
**中文标题：CBF-AFA：基于分块的多自监督学习融合用于自动流畅性评估**

*Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc*

主要分类: cs.CL

摘要简述: 本文提出了一种基于分块的多自监督学习（SSL）融合方法（CBF-AFA），用于自动流畅性评估，通过结合多种SSL模型的优势，显著提升了评估性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动流畅性评估（AFA）在非母语者中仍具挑战性，尤其是在捕捉语音节奏、停顿和不流畅性方面。现有方法难以兼顾语音和语言特征的平衡，因此需要一种更精细的分块分析方法。

研究方法: 提出了一种基于分块的多SSL融合方法，结合了Wav2Vec2、HuBERT和WavLM模型的互补优势，并采用Silero-VAD进行语音分块。通过可学习的加权机制融合SSL嵌入，并加入分块级流畅性标记（如语速、停顿时长等），使用CNN-BiLSTM框架捕捉局部和长期依赖关系。

研究结果: 在Avalinguo和Speechocean762数据集上，该方法比单一SSL基线在Speechocean762上F1分数提高了2.8，皮尔逊相关系数提高了6.2；在Avalinguo上F1分数提高了4.2，皮尔逊相关系数提高了4.0，优于基于Pyannote.audio的分割基线。

研究结论: 分块多SSL融合方法在流畅性评估中表现出色，但未来需进一步研究其在非规则韵律方言中的泛化能力。

中文摘要: 自动流畅性评估（AFA）仍然具有挑战性，尤其是在捕捉非母语者的语音节奏、停顿和不流畅性方面。我们提出了一种基于分块的方法，结合了自监督学习（SSL）模型（Wav2Vec2、HuBERT和WavLM）的互补优势，这些模型在语音、韵律和噪声语音建模方面表现突出，并采用分层CNN-BiLSTM框架。通过Silero语音活动检测（Silero-VAD）将语音分割为呼吸组分块，实现细粒度的时间分析，同时避免过度分割。SSL嵌入通过可学习的加权机制融合，平衡声学和语言特征，并加入分块级流畅性标记（如语速、停顿时长、n-gram重复）。CNN-BiLSTM捕捉分块间的局部和长期依赖关系。在Avalinguo和Speechocean762上的评估表明，我们的方法在Speechocean762上比单一SSL基线F1分数提高了2.8，皮尔逊相关系数提高了6.2；在Avalinguo上F1分数提高了4.2，皮尔逊相关系数提高了4.0，优于基于Pyannote.audio的分割基线。这些结果表明分块多SSL融合在流畅性评估中的有效性，但未来需进一步研究其在非规则韵律方言中的泛化能力。

</details>


### [20] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
**中文标题：维护MTEB：实现嵌入基准的长期可用性与可复现性**

*Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen*

主要分类: cs.CL

摘要简述: 本文探讨了如何维护大规模文本嵌入基准（MTEB）的长期可用性和可复现性，重点介绍了工程实践，包括持续集成、数据集验证和社区贡献管理。


<details>
  <summary>详细信息</summary>
研究动机: MTEB已成为文本嵌入模型的标准评估平台，但需要确保其长期的可复现性和可扩展性。本文旨在通过工程实践解决这些问题，以保持基准的质量和相关性。

研究方法: 通过设计稳健的持续集成流程，自动化测试执行和数据集完整性验证，同时管理社区贡献并扩展新任务和数据集。

研究结果: 这些工程实践成功提升了MTEB的可复现性和可用性，使其在保持质量的同时更加全面，为机器学习评估框架提供了重要参考。

研究结论: 本文的经验为其他基准维护者提供了宝贵见解，强调了工程实践在确保评估框架长期可用性和可复现性中的重要性。

中文摘要: 大规模文本嵌入基准（MTEB）已成为文本嵌入模型的标准评估平台。尽管先前工作已确立了核心基准方法，但本文聚焦于确保MTEB持续可复现性和可扩展性的工程实践。我们介绍了维护稳健持续集成流程的方法，包括验证数据集完整性、自动化测试执行以及评估基准结果的泛化能力。我们还详细说明了增强可复现性和可用性的设计选择。此外，我们探讨了处理社区贡献和扩展新任务与数据集的策略。这些工程实践在扩展MTEB的同时保持了其质量和领域相关性。我们的经验为面临类似挑战的基准维护者提供了宝贵见解，以确保机器学习评估框架的可复现性和可用性。MTEB代码库地址：https://github.com/embeddings-benchmark/mteb

</details>


### [21] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
**中文标题：基于提示的对话轮换预测**

*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

主要分类: cs.CL

摘要简述: 本文提出了一种基于文本提示的动态控制对话轮换预测模型，通过指令（如“更快”或“更冷静”）实现直观调控，实验证明其提升了预测准确性并有效调整了轮换时机。


<details>
  <summary>详细信息</summary>
研究动机: 现有的对话轮换预测模型缺乏动态调控能力，无法根据对话伙伴和情境灵活调整。本文旨在通过文本提示实现直观且显式的控制，提升对话系统的适应性。

研究方法: 基于Transformer的语音活动投影（VAP）模型，将文本提示嵌入到通道级和跨通道Transformer中，利用大型语言模型（LLM）生成合成提示数据。

研究结果: 实验使用超过950小时的人类对话数据，结果显示模型不仅提高了预测准确性，还能根据文本提示动态调整轮换时机行为。

研究结论: 提出的模型通过文本提示实现了对话轮换的动态控制，为对话系统和机器人提供了更灵活的交互能力。

中文摘要: 对话轮换预测模型是语音对话系统和会话机器人的关键组件。近期研究利用基于Transformer的架构实现连续实时的语音活动预测。本研究提出了一种新模型，通过文本提示动态控制对话轮换预测，例如“更快”或“更冷静”等指令，从而直观且显式地适应对话伙伴和情境。该模型基于Transformer的语音活动投影（VAP）模型，将文本提示嵌入到通道级和跨通道Transformer中。我们使用超过950小时的人类对话数据评估了该方法的可行性。由于现有数据集中缺乏文本提示数据，我们利用大型语言模型（LLM）生成合成提示句。实验结果表明，该模型不仅提高了预测准确性，还能根据文本提示有效调整轮换时机行为。

</details>


### [22] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
**中文标题：通过句法检索增强大语言模型在自动术语提取中的应用**

*Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim*

主要分类: cs.CL

摘要简述: 本文提出了一种基于句法检索的提示策略，利用大语言模型（LLMs）提升自动术语提取（ATE）的性能，通过句法而非语义相似性选择示例，显著提高了F1分数。


<details>
  <summary>详细信息</summary>
研究动机: 自动术语提取（ATE）是机器翻译和信息检索等任务的关键，但大语言模型（LLMs）在ATE中的应用尚未充分探索。本文旨在探索LLMs在ATE中的潜力，并提出一种更可靠的句法检索方法。

研究方法: 提出了一种基于句法检索的提示策略，在少样本设置中，通过句法相似性而非语义相似性选择示例，以更准确地捕捉术语边界。该方法具有领域无关性。

研究结果: 在三个专业ATE基准测试中，句法检索方法显著提高了F1分数，验证了句法线索在术语提取任务中的重要性。

研究结论: 句法检索方法为LLMs在术语提取任务中的应用提供了可靠指导，证明了句法信息在提升ATE性能中的关键作用。

中文摘要: 自动术语提取（ATE）用于识别领域特定表达，对机器翻译和信息检索等下游任务至关重要。尽管大语言模型（LLMs）在多种NLP任务中取得了显著进展，但其在ATE中的应用尚未充分研究。我们提出了一种基于检索的提示策略，在少样本设置中，根据句法而非语义相似性选择示例。这种句法检索方法具有领域无关性，并为捕捉术语边界提供了更可靠的指导。我们在领域内和跨领域设置中评估了该方法，分析了查询句子与其检索示例之间的词汇重叠对性能的影响。在三个专业ATE基准测试上的实验表明，句法检索提高了F1分数。这些发现凸显了句法线索在将LLMs应用于术语提取任务中的重要性。

</details>


### [23] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
**中文标题：Agent-RewardBench：面向真实世界多模态代理的感知、规划与安全性奖励建模统一基准**

*Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

主要分类: cs.CL

摘要简述: 本文提出Agent-RewardBench，一个用于评估多模态大语言模型（MLLMs）奖励建模能力的基准，涵盖感知、规划和安全性三个维度，通过7种真实场景和步骤级奖励评估，揭示当前模型的局限性。


<details>
  <summary>详细信息</summary>
研究动机: 随着多模态大语言模型（MLLMs）的发展，多模态代理在真实任务中展现出潜力，但由于缺乏外部反馈，其自我纠正和泛化能力受限。奖励模型作为外部反馈是一种可行方案，但如何选择适合代理的奖励模型尚不明确，因此亟需一个针对代理的奖励基准。

研究方法: 提出Agent-RewardBench基准，特点包括：（1）多维度评估（感知、规划、安全性）和7种真实场景；（2）步骤级奖励评估，细化任务执行过程；（3）精心设计难度和数据质量，从10种模型中采样并人工验证。

研究结果: 实验表明，即使最先进的多模态模型在奖励建模任务中表现有限，突显了专门训练的必要性。

研究结论: Agent-RewardBench为多模态代理的奖励建模提供了统一评估标准，揭示了当前模型的不足，并强调了未来研究方向。

中文摘要: 随着多模态大语言模型（MLLMs）的进步，多模态代理在网页导航和具身智能等真实任务中展现出潜力。然而，由于缺乏外部反馈，这些代理在自我纠正和泛化方面存在困难。奖励模型作为外部反馈是一种可行方案，但如何为代理选择奖励模型尚不明确。因此，亟需建立一个针对代理的奖励基准。为解决这些问题，我们提出了Agent-RewardBench，一个用于评估MLLMs奖励建模能力的基准。该基准具有三个关键特征：（1）多维度评估和真实代理场景。涵盖感知、规划和安全性，涉及7种场景；（2）步骤级奖励评估。允许在任务单个步骤中评估代理能力，提供规划过程中更细粒度的性能视图；（3）适当难度和高质量。我们从10种多样模型中精心采样，控制难度以保持任务挑战性，并通过人工验证确保数据完整性。实验表明，即使最先进的多模态模型表现有限，突显了代理奖励建模专门训练的必要性。代码发布于github。

</details>


### [24] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
**中文标题：猫鼠游戏——虚假文本生成能否超越检测系统？**

*Andrea McGlinchey,Peter J Barclay*

主要分类: cs.CL

摘要简述: 本文探讨了大型语言模型生成的“虚假文本”能否超越检测系统的问题，发现尽管模型规模不断扩大，但简单分类器仍能有效检测虚假文本，且新模型架构可能提升欺骗性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型生成虚假文本的能力不断增强，检测系统是否会被超越成为一个关键问题。本文旨在研究这一问题，并探讨检测技术是否能在模型规模扩大时保持有效性。

研究方法: 研究通过统计分类器检测古典侦探小说风格的虚假文本，比较了不同版本的语言模型（如Gemini和GPT）在生成欺骗性文本方面的表现。

研究结果: 研究发现，Gemini在版本升级后生成欺骗性文本的能力有所提升，而GPT未表现出类似趋势。这表明即使模型规模扩大，检测虚假文本仍可能可行。

研究结论: 尽管大型语言模型的欺骗性可能随新架构提升，但简单分类器仍能有效检测虚假文本，检测技术可能不会完全失效。

中文摘要: 大型语言模型能够在学术写作、产品评论和政治新闻等领域生成逼真的“虚假文本”。尽管检测人工生成文本的方法已被广泛研究，但这一问题似乎预示着一场无休止的“军备竞赛”。然而，我们发现，虽然新的大型语言模型使用了更多的参数、训练数据和能源，但相对简单的分类器在资源有限的情况下仍能表现出较高的检测准确性。为了探讨模型是否会在击败检测器方面达到瓶颈，我们研究了统计分类器在识别古典侦探小说风格“虚假文本”方面的能力。在0.5个版本的升级中，我们发现Gemini生成欺骗性文本的能力有所提升，而GPT则没有。这表明，即使模型规模不断扩大，可靠检测虚假文本仍可能可行，尽管新模型架构可能会提升其欺骗性。

</details>


### [25] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
**中文标题：双重检查器：通过自批判微调增强慢思考大语言模型的推理能力**

*Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin*

主要分类: cs.CL

摘要简述: 本文提出Double-Checker框架，通过自批判微调提升慢思考大语言模型的推理能力，显著提高其在复杂推理任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 慢思考大语言模型（LLMs）在生成批判性反馈和迭代优化解决方案方面能力有限，限制了其推理能力的进一步提升。本文旨在通过自批判和迭代优化的方法增强LLMs的推理能力。

研究方法: Double-Checker框架通过微调1,730个自批判实例，使LLMs能够在推理过程中迭代批判和优化其输出，直至生成自我认可的解决方案。

研究结果: 实验表明，Double-Checker将AIME基准测试的pass@1性能从4.4%提升至18.2%，显著增强了慢思考LLMs的推理能力。

研究结论: Double-Checker为开发更具信任度和有效性的自批判LLMs提供了有前景的方向。

中文摘要: 尽管慢思考大语言模型（LLMs）表现出类似反思的推理能力（通常称为“顿悟时刻”），但其生成信息性批判和优化先前解决方案的能力仍然有限。本文提出了Double-Checker，一个旨在通过促进显式自批判和迭代优化来增强慢思考LLMs推理能力的框架。通过在我们精选的1,730个自批判实例上进行微调，Double-Checker使长链推理LLMs能够在推理过程中迭代批判和优化其输出，直至其解决方案在自生成的批判下被评估为正确。我们在全面的推理基准测试中验证了Double-Checker的有效性，结果表明迭代自批判显著提升了长链推理LLMs的能力。值得注意的是，与原始长链推理LLMs相比，我们的Double-Checker将AIME基准测试的pass@1性能从4.4%提升至18.2%。这些结果突显了开发更具信任度和有效性的自批判LLMs的潜力。

</details>


### [26] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
**中文标题：小型编码器在检测文本基于性方面可媲美大型解码器**

*Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar*

主要分类: cs.CL

摘要简述: 研究表明，轻量级编码器模型（如RoBERTa和NomicBERT）在检测文本是否基于上下文时，性能可媲美大型语言模型（如Llama3 8B和GPT4o），同时显著降低推理延迟。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在缺乏上下文信息时容易生成不可靠的答案，而检测文本是否基于上下文（groundedness）是确保事实一致性和可信度的关键。本研究旨在通过轻量级模型提前检测，以减少资源消耗和推理时间。

研究方法: 研究使用轻量级编码器模型（如RoBERTa和NomicBERT），通过微调精选数据集，检测查询是否基于提供的上下文。

研究结果: 实验表明，轻量级编码器模型在检测groundedness时，准确性与大型语言模型相当，同时推理延迟显著降低。

研究结论: 轻量级编码器模型可有效替代大型解码器模型，用于检测groundedness，显著提升效率并降低成本。

中文摘要: 通过为大型语言模型（LLMs）提供外部上下文，可以显著提升其在自然语言处理（NLP）任务中的表现。然而，当上下文缺乏信息时，LLMs往往难以可靠地回答查询，转而依赖无根据的推测或内部知识。基于上下文的生成（groundedness）——即严格依据上下文生成回答——对于确保事实一致性和可信度至关重要。本研究专注于在LLMs进行昂贵的答案生成之前，检测给定查询是否基于提供的上下文文档。这种检测机制可以显著减少推理时间和资源消耗。我们证明，经过精选数据集微调的轻量级任务特定编码器模型（如RoBERTa和NomicBERT），在检测groundedness方面的准确性可与Llama3 8B和GPT4o等先进LLMs相媲美，同时将推理延迟降低几个数量级。代码已开源：https://github.com/chandarlab/Hallucinate-less

</details>


### [27] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
**中文标题：基于自回归语言模型的视觉对话中指代表达式检测**

*Bram Willemsen,Gabriel Skantze*

主要分类: cs.CL

摘要简述: 本文探讨了仅使用自回归语言模型从视觉对话中提取指代表达式的可行性，发现仅依赖文本语境也能有效完成任务，但指出该任务本质上是多模态问题。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索仅依赖语言语境（而非视觉信息）能否有效检测对话中指代表达式，以验证语言模型在此任务中的潜力。

研究方法: 采用预训练的大型语言模型（LLM），通过参数高效微调，利用下一个词预测任务标注对话中的指代表达式边界。

研究结果: 实验表明，即使使用中等规模LLM和小数据集，仅文本方法也能有效完成任务，凸显语言语境的重要性。但任务本质仍为多模态问题。

研究结论: 尽管仅文本方法有效，但指代表达式检测本质上是多模态任务，单模态方法存在固有局限性。

中文摘要: 本文探讨了仅使用文本自回归语言模型从视觉对话中提取指代表达式的方法。具体目标是研究仅依赖语言语境能否有效检测对话中与视觉相关的指代表达式。为此，我们调整了一个预训练的大型语言模型（LLM），通过下一个词预测任务标注对话中的指代表达式边界。结果表明，即使使用中等规模LLM、小数据集和参数高效微调，仅文本方法仍能有效完成任务，凸显语言语境的重要性。然而，我们认为该任务本质上是多模态问题，并讨论了单模态方法的固有局限性。

</details>


### [28] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
**中文标题：结构主义视角下的人工智能文学批评：利用格雷马斯符号学方阵提升大语言模型能力**

*Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen*

主要分类: cs.CL

摘要简述: 本文提出GLASS框架，基于格雷马斯符号学方阵（GSS），提升大语言模型（LLMs）对复杂叙事作品的深度文学分析能力，并构建首个GSS文学批评数据集，验证了其高效性。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型在文本理解和生成方面表现出色，但在对思想深刻、叙事复杂的作品进行专业文学批评时存在不足。本文旨在通过结构化分析框架GLASS，弥补这一缺陷。

研究方法: 提出GLASS框架，基于格雷马斯符号学方阵（GSS），构建首个GSS文学批评数据集（含48部作品分析），并设计定量评估指标，采用LLM-as-a-judge范式验证框架效果。

研究结果: GLASS框架在多个作品和LLMs上的表现优于专家批评，且应用于39部经典作品时，产生了填补研究空白的原创高质量分析。

研究结论: GLASS为文学研究和教育提供了基于AI的工具，揭示了文学认知机制，并为LLMs的文学批评能力提供了新思路。

中文摘要: 大语言模型（LLMs）在文本理解和生成方面表现出色，但对思想深刻、叙事复杂的作品进行专业文学批评时仍存在困难。本文提出GLASS（基于格雷马斯符号学方阵的文学分析）框架，通过结构化分析方法提升LLMs的深度文学分析能力。GLASS能够快速解构叙事作品的结构和深层意义。我们构建了首个基于GSS的文学批评数据集，包含48部作品的详细分析，并采用LLM-as-a-judge范式设计了定量评估指标。与专家批评相比，GLASS在多个作品和LLMs上表现出色。最后，我们将GLASS应用于39部经典作品，填补了研究空白并提供了高质量的原创分析。本研究为文学研究和教育提供了基于AI的工具，并为文学认知机制提供了新见解。

</details>


### [29] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
**中文标题：利用LLM辅助查询理解提升实时检索增强生成**

*Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng*

主要分类: cs.CL

摘要简述: 本文提出Omni-RAG框架，通过LLM辅助的查询理解提升实时检索增强生成（RAG）系统对复杂、模糊查询的鲁棒性，包括查询分解、意图感知检索和重排生成模块。


<details>
  <summary>详细信息</summary>
研究动机: 现有RAG系统在处理噪声多、模糊且多意图的用户查询时表现不佳，因其通常基于干净数据训练或评估。本文旨在解决这一现实应用中的挑战。

研究方法: Omni-RAG框架包含三个模块：(1) 深度查询理解与分解，利用LLM去噪并分解多意图查询；(2) 意图感知知识检索，为子查询检索并聚合结果；(3) 重排与生成，通过重排器和LLM生成最终响应。

研究结果: Omni-RAG显著提升了RAG系统对复杂和噪声查询的处理能力，为实时开放域应用（如SIGIR 2025 LiveRAG挑战）提供了更鲁棒的解决方案。

研究结论: Omni-RAG通过LLM辅助的查询理解，填补了当前RAG能力与现实应用需求之间的差距，为复杂查询场景提供了有效支持。

中文摘要: 现实中的实时检索增强生成（RAG）系统在处理噪声多、模糊且多意图的用户查询时面临重大挑战。尽管RAG通过外部知识增强了大语言模型（LLM）的能力，现有系统通常因基于干净数据训练或评估而难以应对此类复杂输入。本文提出了Omni-RAG，一种旨在提升RAG系统在实时开放域场景中鲁棒性和有效性的新框架。Omni-RAG利用LLM辅助的查询理解，通过三个关键模块预处理用户输入：(1) 深度查询理解与分解，使用定制提示的LLM去噪查询（如纠正拼写错误）并将多意图查询分解为结构化子查询；(2) 意图感知知识检索，从语料库（如使用OpenSearch的FineWeb）中为每个子查询检索并聚合结果；(3) 重排与生成，通过重排器（如BGE）优化文档选择后，由LLM（如Falcon-10B）使用思维链提示生成最终响应。Omni-RAG旨在通过鲁棒处理复杂和噪声查询，填补当前RAG能力与SIGIR 2025 LiveRAG挑战等现实应用需求之间的差距。

</details>


### [30] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
**中文标题：领域知识增强的大型语言模型用于欺诈和概念漂移检测**

*Ali Şenol,Garima Agrawal,Huan Liu*

主要分类: cs.CL

摘要简述: 本文提出了一种结合领域知识的LLM框架，用于检测欺诈和概念漂移，通过整合预训练LLM和任务特定知识，显著提高了检测准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 动态平台上欺骗性对话的检测因语言模式演变和概念漂移（CD）而变得困难，LLM在风险敏感场景中常因上下文模糊和幻觉问题表现不佳。

研究方法: 框架包含三个模块：(1) DK-LLM模块检测虚假对话；(2) 漂移检测单元（OCDD）识别语义变化；(3) 第二个DK-LLM模块将漂移分类为良性或欺诈性。基于LLaMA的实现通过结构化提示达到高准确率。

研究结果: 系统在虚假对话检测和漂移分类中表现优异，分类准确率达98%，显著优于零样本基线。

研究结论: 结合领域知识和漂移检测显著提升了高风险NLP应用的性能、可解释性和鲁棒性。

中文摘要: 动态平台上欺骗性对话的检测因语言模式演变和概念漂移（CD）而日益困难。概念漂移指语义或主题随时间变化，可能掩盖恶意意图或模仿正常对话，导致分类准确性下降。尽管大型语言模型（LLM）在自然语言任务中表现优异，但在风险敏感场景中常因上下文模糊和幻觉问题受限。为解决这些问题，我们提出了一种领域知识（DK）增强的LLM框架，将预训练LLM与结构化任务特定知识结合，用于欺诈和概念漂移检测。该框架包含三个主要组件：(1) DK-LLM模块检测虚假对话；(2) 漂移检测单元（OCDD）判断语义变化；(3) 第二个DK-LLM模块将漂移分类为良性或欺诈性。我们首先通过虚假评论数据集验证领域知识的价值，随后将框架应用于SEConvo多轮对话数据集（包含多种欺诈和垃圾信息攻击）。结果显示，系统能高精度检测虚假对话并有效分类漂移性质。基于LLaMA的实现通过结构化提示达到98%的分类准确率。与零样本基线的对比研究表明，结合领域知识和漂移检测显著提升了高风险NLP应用的性能、可解释性和鲁棒性。

</details>


### [31] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
**中文标题：跨语言的Text2Cypher：评估超越英语的基础模型**

*Makbule Gulcin Ozsoy,William Tai*

主要分类: cs.CL

摘要简述: 本文研究了大型语言模型在多语言Text2Cypher任务中的表现，发现性能从高到低依次为英语、西班牙语和土耳其语，并指出训练数据和语言特性的差异是主要原因。


<details>
  <summary>详细信息</summary>
研究动机: 当前自然语言接口（如Text2SQL、Text2SPARQL和Text2Cypher）的研究主要集中在英语，其他语言的评估有限。本文旨在填补这一空白，评估基础模型在多语言Text2Cypher任务中的表现。

研究方法: 通过将英语问题翻译为西班牙语和土耳其语并保留原始Cypher查询，创建了一个多语言测试集。使用标准化提示和指标评估多个基础模型，并探讨了提示翻译对性能的影响。

研究结果: 结果显示模型性能从高到低依次为英语、西班牙语和土耳其语，差异源于训练数据可用性和语言特性。提示翻译对评估指标影响较小。

研究结论: 研究强调了多语言查询生成中更包容的评估和开发的必要性，未来工作包括模式本地化和多语言微调。

中文摘要: 近年来，大型语言模型的进展使得自然语言接口能够将用户问题翻译为数据库查询，例如Text2SQL、Text2SPARQL和Text2Cypher。尽管这些接口提升了数据库的可访问性，但当前研究主要集中于英语，对其他语言的评估有限。本文研究了基础模型在Text2Cypher任务中多语言的表现。我们通过将英语问题翻译为西班牙语和土耳其语并保留原始Cypher查询，创建并发布了一个多语言测试集，以实现公平的跨语言比较。使用标准化提示和指标评估多个基础模型。结果显示一致的性能模式：英语最高，西班牙语次之，土耳其语最低。我们将其归因于训练数据可用性和语言特性的差异。此外，我们探讨了将任务提示翻译为西班牙语和土耳其语的影响。结果显示评估指标变化甚微，表明提示翻译影响较小。我们的发现强调了在多语言查询生成中更包容的评估和开发的必要性。未来工作包括模式本地化和多语言微调。

</details>


### [32] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
**中文标题：基于用户交互的语音对话模型对齐**

*Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez*

主要分类: cs.CL

摘要简述: 本文提出了一种新颖的偏好对齐框架，通过用户交互改进实时语音对话模型。现有偏好学习方法主要针对文本语言模型，无法直接适应实时语音交互的复杂性（如打断、插话等）。作者构建了一个大规模数据集，并利用离线对齐方法优化全双工自回归语音模型，实验表明该方法能显著提升对话模型的事实性、安全性和上下文对齐能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前偏好学习方法主要针对文本语言模型，而实时语音交互具有更复杂的动态特性（如打断、插话等），且缺乏明确的说话轮次分割。因此，需要一种专门针对语音对话模型的偏好对齐方法。

研究方法: 作者构建了一个包含15万对偏好标注的大规模数据集，覆盖语言内容和时间上下文变化。利用离线对齐方法优化全双工自回归语音模型，并通过实验验证其效果。

研究结果: 实验表明，该方法能显著提升对话模型的事实性、安全性和上下文对齐能力。部署后的模型在人类评估中表现优异，展示了多轮对话中的整体改进。

研究结论: 研究揭示了在实时语音对话系统中平衡多种动态特性的重要性，为自然语音交互系统的开发提供了重要参考。

中文摘要: 我们提出了一种新颖的偏好对齐框架，用于通过用户交互改进实时语音对话模型。当前的偏好学习方法主要针对文本语言模型，无法直接适应实时语音交互的复杂性（如打断、插话等），且缺乏明确的说话轮次分割。我们构建了一个包含超过15万对偏好标注的大规模数据集，覆盖语言内容和时间上下文变化。利用离线对齐方法优化了一个全双工自回归语音模型。大量实验表明，通用对话的反馈能有效提升语音对话模型的事实性、安全性和上下文对齐能力。我们部署了优化后的模型，并通过全面的人类评估评估了其在多轮对话中的效果。研究揭示了平衡多种动态特性的重要性，这对自然实时语音对话系统至关重要。

</details>


### [33] [TopK Language Models](https://arxiv.org/abs/2506.21468)
**中文标题：TopK语言模型**

*Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling*

主要分类: cs.CL

摘要简述: 本文提出了一种改进的Transformer架构，通过引入TopK激活函数，使模型的隐藏状态等同于TopK稀疏自编码器的潜在特征，从而无需后训练即可提供与稀疏自编码器相当的模型可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 稀疏自编码器（SAEs）在分析Transformer语言模型的激活空间时存在局限性，例如后训练的不确定性、特征不稳定性和难以跨检查点比较。这些问题限制了SAEs的实用性和内部有效性。

研究方法: 在Transformer架构的选定层中引入TopK激活函数，使隐藏状态直接对应TopK稀疏自编码器的潜在特征，从而省去后训练步骤，同时保持模型的可解释性。

研究结果: 实验表明，TopK语言模型通过稀疏表示实现了成功的神经元干预和跨检查点、跨层的神经元形成过程分析，提供了稳定且可靠的可解释性工具。

研究结论: TopK语言模型在模型大小、计算效率和可解释性之间取得了良好平衡，显著提升了语言模型的可解释性和可控性研究。

中文摘要: 稀疏自编码器（SAEs）已成为分析和解释基于Transformer的语言模型（LMs）激活空间的重要工具。然而，SAEs存在一些缺陷，降低了其实用性和内部有效性。由于SAEs是后训练的，无法确定未能发现某个概念是SAE的问题还是底层LM未表示该概念。训练条件和架构选择也会影响SAE学习到的特征，进一步加剧了这一问题。在追踪LMs训练过程中如何学习概念时，特征的不稳定性也使得难以比较不同检查点间的SAE特征。为解决这些限制，我们提出了一种改进的Transformer架构，在选定层中引入TopK激活函数，使模型的隐藏状态等同于TopK稀疏自编码器的潜在特征。这种方法无需后训练，同时提供了与SAEs相当的可解释性。TopK语言模型在模型大小、计算效率和可解释性之间取得了良好平衡。尽管架构改动简单，TopK语言模型仍保持了原始能力，同时提供了稳健的可解释性优势。实验表明，TopK语言模型学习的稀疏表示能够通过目标神经元干预成功实现模型操控，并支持跨检查点和跨层的神经元形成过程详细分析。这些特性使TopK语言模型成为理解语言模型如何学习和表示概念的稳定可靠工具，我们相信这将显著推动未来模型可解释性和可控性研究。

</details>


### [34] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
**中文标题：连接离线与在线强化学习的大语言模型微调**

*Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov*

主要分类: cs.CL

摘要简述: 本文研究了从离线到半在线再到完全在线环境下，强化学习方法在微调大语言模型中的有效性，发现在线和半在线方法性能相似且优于离线方法，同时多任务学习能提升任务表现。


<details>
  <summary>详细信息</summary>
研究动机: 探讨强化学习方法在不同在线程度（离线、半在线、完全在线）下对大语言模型微调的效果，尤其是在可验证和不可验证任务中的应用。

研究方法: 通过实验比较在线、半在线和离线方法（如直接偏好优化和群体奖励策略优化），分析训练动态和超参数选择策略，并研究多任务学习的有效性。

研究结果: 在线和半在线方法在性能和收敛性上表现相似，均显著优于离线方法；多任务学习能同时提升可验证和不可验证任务的表现。

研究结论: 强化学习在在线和半在线环境下对大语言模型微调效果显著，多任务学习进一步提升了模型性能。

中文摘要: 我们研究了强化学习方法在微调大语言模型中的有效性，特别是在从离线到半在线再到完全在线的过渡过程中，适用于可验证和不可验证任务。实验涵盖了可验证的数学任务和不可验证的指令跟随任务，并对两者进行了基准评估。在这些设置中，我们广泛比较了在线和半在线的直接偏好优化与群体奖励策略优化目标，意外发现这些变体在性能和收敛性上表现相似，且均显著优于离线方法。我们详细分析了训练动态和超参数选择策略以实现最佳结果。最后，我们发现同时使用可验证和不可验证奖励的多任务学习能够提升两类任务的表现。

</details>


### [35] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
**中文标题：通过交互式LLM对齐增强社交对话中的用户参与度**

*Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li*

主要分类: cs.CL

摘要简述: 本文提出了一种通过交互式LLM对齐增强社交对话中用户参与度的方法，利用用户反应作为奖励信号，并通过i×MCTS和DPO优化模型。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在社交对话中优化知识或对话行为，但未能直接提升用户参与度。本文旨在通过交互式LLM学习用户参与度信号，以更直接的方式增强对话体验。

研究方法: 开发用户模拟器与目标LLM交互，使用i×MCTS探索对话路径，收集高质量和低质量对话数据，并通过直接偏好优化（DPO）对齐LLM。

研究结果: 在情感支持对话和劝导对话两种场景中，实验表明该方法显著提升了用户参与度。

研究结论: 通过交互式LLM对齐和用户反应信号优化，本文方法有效提升了社交对话中的用户参与度。

中文摘要: 在社交对话中，通过交互提升用户参与度至关重要。尽管先前研究优化了模型以推理相关知识或规划对话行为流，但用户参与度与知识或对话行为的关系微妙，无法保证社交对话中的用户参与度。为此，我们通过利用对话未来发展的信号，使交互式LLM学习用户参与度。具体而言，我们采用更直接且相关的用户参与度指标（即用户对对话意图的反应）作为奖励，对齐交互式LLM。为实现这一目标，我们开发了一个用户模拟器与目标交互式LLM交互，并通过i×MCTS（用于交互的蒙特卡洛树搜索）探索用户与交互式LLM系统之间的互动。通过这种方式，我们收集了包含高质量和低质量对话体验的数据集，并通过直接偏好优化（DPO）对齐交互式LLM以提升用户参与度。在情感支持对话和劝导对话两种场景中的实验表明，我们的方法有效增强了交互式LLM中的用户参与度。

</details>


### [36] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
**中文标题：skLEP：斯洛伐克通用语言理解基准**

*Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko*

主要分类: cs.CL

摘要简述: 本文介绍了skLEP，首个专为评估斯洛伐克自然语言理解（NLU）模型设计的综合基准，涵盖九项多样化任务，并提供了数据集、工具包和公开排行榜。


<details>
  <summary>详细信息</summary>
研究动机: 斯洛伐克缺乏针对自然语言理解模型的综合评估基准，限制了相关研究的发展。本文旨在填补这一空白，推动斯洛伐克NLU研究的进步。

研究方法: 通过整理新的斯洛伐克原创数据集和翻译已有的英文NLU资源，构建了涵盖词级、句对级和文档级任务的skLEP基准。并对多种斯洛伐克专用、多语言和英文预训练语言模型进行了系统评估。

研究结果: skLEP基准成功构建并公开，提供了全面的数据集、开源工具包和公开排行榜，为斯洛伐克NLU研究提供了重要资源。

研究结论: skLEP为斯洛伐克NLU研究提供了首个综合基准，促进了相关研究的可重复性和未来发展。

中文摘要: 本文介绍了skLEP，首个专为评估斯洛伐克自然语言理解（NLU）模型设计的综合基准。skLEP包含九项多样化任务，涵盖词级、句对级和文档级挑战，全面评估模型能力。为构建此基准，我们整理了新的斯洛伐克原创数据集，并精心翻译了已有的英文NLU资源。本文还首次对多种斯洛伐克专用、多语言和英文预训练语言模型进行了系统评估。最后，我们公开了完整的基准数据、开源工具包（支持模型微调和评估）以及公开排行榜（https://github.com/slovak-nlp/sklep），以促进可重复性并推动斯洛伐克NLU的未来研究。

</details>


### [37] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
**中文标题：大型语言模型中的Potemkin理解**

*Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan*

主要分类: cs.CL

摘要简述: 大型语言模型（LLMs）在基准测试中的表现可能只是表面理解（Potemkin理解），而非真正掌握概念。本文提出两种量化方法，发现这种虚假理解在模型、任务和领域中普遍存在，且反映了概念表征的内部不一致性。


<details>
  <summary>详细信息</summary>
研究动机: 当前对大型语言模型的评估依赖于基准测试，但这些测试是否真正反映模型的理解能力尚不明确。本文旨在探讨基准测试的局限性，尤其是模型是否仅表现出表面理解而非真实掌握概念。

研究方法: 本文提出两种量化Potemkin理解的方法：1）在三个领域设计专门的基准测试；2）提供一种通用方法，用于估计Potemkin理解的普遍性下限。

研究结果: 研究发现，Potemkin理解在模型、任务和领域中普遍存在。这些失败不仅表现为错误理解，还揭示了概念表征的内部不一致性。

研究结论: 基准测试可能无法真实反映大型语言模型的理解能力，Potemkin理解的普遍性表明需要更深入的评估方法。

中文摘要: 大型语言模型（LLMs）通常通过基准数据集进行评估。但基于一组精心设计的问题推断LLM的能力是否合理？本文首先引入一个正式框架来回答这一问题。关键在于注意到用于测试LLM的基准（如AP考试）同样用于测试人类。然而，这隐含了一个问题：这些基准只有在LLM以与人类相似的方式误解概念时才有效。否则，基准测试的成功仅展示了Potemkin理解：一种由与人类理解方式不符的答案驱动的表面理解。我们提出了两种量化Potemkin存在的方法：一种使用在三个领域设计的专门基准，另一种使用一种通用方法，为其普遍性提供下限。我们发现，Potemkin理解在模型、任务和领域中普遍存在。这些失败不仅反映了错误理解，还揭示了概念表征的更深层内部不一致性。

</details>


### [38] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
**中文标题：“医生，怎么了？”：分析用户如何在大规模对话AI数据集中寻求健康信息**

*Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal*

主要分类: cs.CL

摘要简述: 本文通过分析大规模对话AI数据集，研究了用户如何通过聊天机器人获取健康信息，揭示了用户行为模式及潜在风险，并提出了改进建议。


<details>
  <summary>详细信息</summary>
研究动机: 随着用户越来越多地通过大型语言模型（LLMs）的聊天机器人获取健康信息，这些对话的性质和潜在风险尚未得到充分研究。本文旨在填补这一空白。

研究方法: 研究通过筛选大规模对话AI数据集，构建了HealthChat-11K（包含11K真实对话和25K用户消息），并基于临床医生分类法，系统分析了21个健康领域的用户交互行为。

研究结果: 分析揭示了用户获取健康信息的方式和动机，包括常见交互、信息不完整、情感行为以及可能引发迎合行为的提问方式，凸显了LLMs在健康支持能力上的不足。

研究结论: 研究表明，当前LLMs在健康信息支持方面存在局限性，需进一步改进以更好地满足用户需求。

中文摘要: 人们越来越多地通过大型语言模型（LLMs）的交互式聊天机器人获取健康信息，但这些对话的性质和潜在风险尚未得到充分研究。本文通过筛选大规模对话AI数据集，构建了HealthChat-11K，这是一个包含11K真实对话和25K用户消息的精选数据集。我们利用HealthChat-11K和临床医生分类法，系统研究了用户在21个不同健康领域中与LLMs的交互行为。分析揭示了用户获取健康信息的方式和原因，包括常见交互、信息不完整、情感行为以及可能引发迎合行为的提问方式，强调了部署为对话AI的LLMs在健康支持能力上的改进需求。代码和相关资源可在以下链接获取：https://github.com/yahskapar/HealthChat

</details>


### [39] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
**中文标题：语言模型训练中的数据效能**

*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

主要分类: cs.CL

摘要简述: 本文提出数据效能（Data Efficacy）概念，通过优化训练数据的组织提升语言模型性能，并提出了DELT框架，包含数据评分、选择和排序三个组件。实验证明，该方法在不增加数据规模和模型大小的情况下显著提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究主要关注数据效率（Data Efficiency），即通过选择最优子集提升性能，而数据组织优化（Data Efficacy）尚未充分探索。本文旨在填补这一空白，通过优化数据组织进一步提升语言模型的训练效果。

研究方法: 提出DELT框架，包含三个组件：数据评分（Data Scoring）、数据选择（Data Selection）和数据排序（Data Ordering）。具体设计了Learnability-Quality Scoring（LQS）用于数据评分，以及Folding Ordering（FO）用于数据排序，分别从梯度一致性和模型遗忘问题角度优化数据组织。

研究结果: 实验表明：1）DELT框架的多种实例均能不同程度提升语言模型性能；2）LQS与FO的组合效果最佳；3）数据效能与数据效率可协同实现。

研究结论: 数据效能是语言模型训练中一个具有潜力的研究方向，通过优化数据组织可显著提升性能，且与数据效率互补。

中文摘要: 数据是语言模型（LM）训练的基础。近期研究致力于数据效率，即通过选择最小或最优的训练数据子集以最大化性能。数据过滤、采样和选择等技术在此领域至关重要。作为补充，我们定义了数据效能（Data Efficacy），其关注通过优化训练数据的组织以最大化性能，目前研究较少。本文提出了一个通用范式DELT，用于在语言模型训练中考虑数据效能，强调训练数据组织的重要性。DELT包含三个组件：数据评分、数据选择和数据排序。在这些组件中，我们设计了Learnability-Quality Scoring（LQS）作为数据评分的新实例，从梯度一致性角度考虑每个数据样本的可学习性和质量。我们还设计了Folding Ordering（FO）作为数据排序的新实例，解决了模型遗忘和数据分布偏差等问题。综合实验验证了数据效能在语言模型训练中的作用，结果表明：首先，DELT的多种实例在不增加数据规模和模型大小的情况下不同程度地提升了语言模型性能；其次，在这些实例中，我们提出的LQS与FO的组合效果最为显著；最后，通过应用数据选择，数据效能与数据效率可协同实现。因此，我们认为数据效能是语言模型训练中一个具有潜力的基础研究方向。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport](https://arxiv.org/abs/2506.20741)
**中文标题：OTSurv：一种基于异质性感知最优传输的多实例学习生存预测框架**

*Qin Ren,Yifan Wang,Ruogu Fang,Haibin Ling,Chenyu You*

主要分类: cs.CV

摘要简述: OTSurv是一种基于最优传输的多实例学习框架，用于全切片图像的生存预测，通过全局长尾约束和局部不确定性约束显式捕捉病理异质性，显著提升预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有MIL方法在全切片图像的生存预测中未能显式捕捉病理异质性，包括全局的长尾形态分布和局部的图块级预测不确定性。最优传输提供了一种建模这种异质性的理论方法。

研究方法: OTSurv将生存预测建模为异质性感知的最优传输问题，引入全局长尾约束和局部不确定性约束，并通过不平衡最优传输公式高效求解。

研究结果: 在六个流行基准测试中，OTSurv实现了平均C-index绝对提升3.6%，并在对数秩检验中达到统计显著性，同时具有高可解释性。

研究结论: OTSurv是一种强大的数字病理生存预测工具，通过最优传输显式建模异质性，显著提升了预测性能和可解释性。

中文摘要: 全切片图像（WSIs）的生存预测可以表述为多实例学习（MIL）问题。然而，现有MIL方法通常无法显式捕捉WSIs中的病理异质性，包括全局的长尾形态分布和局部的图块级预测不确定性。最优传输（OT）通过引入边际分布约束，为建模这种异质性提供了理论支持。基于这一见解，我们提出OTSurv，一种从最优传输视角出发的新型MIL框架。具体而言，OTSurv将生存预测建模为异质性感知的OT问题，包含两个约束：（1）全局长尾约束，通过调节传输质量分配，建模先验形态分布以避免模式崩溃和过度均匀性；（2）局部不确定性感知约束，通过逐步增加总传输质量，优先处理高置信度图块并抑制噪声。随后，我们将初始OT问题转化为不平衡OT公式，并通过高效的硬件友好矩阵缩放算法求解。实验表明，OTSurv在六个流行基准测试中均取得最优结果，平均C-index绝对提升3.6%。此外，OTSurv在对数秩检验中达到统计显著性，并具有高可解释性，成为数字病理生存预测的有力工具。代码发布于https://github.com/Y-Research-SBU/OTSurv。

</details>


### [41] [StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation](https://arxiv.org/abs/2506.20756)
**中文标题：StereoDiff：立体匹配与扩散协同的视频深度估计**

*Haodong Li,Chen Wang,Jiahui Lei,Kostas Daniilidis,Lingjie Liu*

主要分类: cs.CV

摘要简述: StereoDiff结合立体匹配和视频深度扩散，通过两阶段方法实现视频深度估计，静态区域依赖立体匹配，动态区域利用扩散模型，实验证明其在零样本和真实场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 视频深度估计并非图像深度估计的简单扩展，静态和动态区域的时序一致性需求不同。静态区域可通过立体匹配实现全局3D线索，而动态区域需依赖大规模视频数据学习平滑过渡。

研究方法: 提出StereoDiff两阶段方法：静态区域利用立体匹配提供全局3D线索，动态区域通过视频深度扩散模型保持一致性。通过频域分析证明两者的互补性。

研究结果: 在零样本和真实动态视频深度基准测试中，StereoDiff表现最优，展示了卓越的一致性和准确性。

研究结论: StereoDiff通过立体匹配与视频深度扩散的协同作用，显著提升了视频深度估计的性能，为静态和动态区域提供了互补的解决方案。

中文摘要: 近期视频深度估计方法通过遵循图像深度估计的范式（即通常基于预训练的视频扩散模型和大规模数据微调）取得了显著性能。然而，我们认为视频深度估计并非图像深度估计的简单扩展。视频中动态和静态区域的时序一致性需求存在根本差异。静态区域（通常是背景）的一致性可通过跨帧立体匹配更有效地实现，从而提供更强的全局3D线索；而动态区域的平滑过渡仍需依赖大规模视频深度数据学习，因为其违反了三角测量约束。基于这些洞察，我们提出了StereoDiff，一种两阶段视频深度估计方法，通过立体匹配主要处理静态区域，同时利用视频深度扩散保持动态区域的深度过渡一致性。通过频域分析，我们数学证明了立体匹配与视频深度扩散的互补性，突显了二者协同的优势。在零样本和真实动态视频深度基准测试（包括室内外场景）中，StereoDiff展示了最先进的性能，证明了其在视频深度估计中的卓越一致性和准确性。

</details>


### [42] [ConViTac: Aligning Visual-Tactile Fusion with Contrastive Representations](https://arxiv.org/abs/2506.20757)
**中文标题：ConViTac：基于对比表示的视觉-触觉融合对齐**

*Zhiyuan Wu,Yongqiang Zhao,Shan Luo*

主要分类: cs.CV

摘要简述: ConViTac提出了一种视觉-触觉融合表示学习网络，通过对比表示增强特征对齐，显著提升了材料分类和抓取预测任务的性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉和触觉是机器人感知和操作任务中的两种基本感官模态，但现有方法在模态融合时往往采用简单的特征组合方式，导致特征整合效果不佳。

研究方法: ConViTac采用对比嵌入条件（CEC）机制，通过自监督对比学习预训练的对比编码器，将视觉和触觉输入投影到统一的潜在嵌入空间，并通过跨模态注意力实现特征融合。

研究结果: 实验表明，ConViTac在材料分类和抓取预测任务中优于现有方法，准确率提升高达12.0%。

研究结论: ConViTac通过对比表示学习有效提升了视觉-触觉特征的对齐和融合性能，为多模态感知任务提供了新思路。

中文摘要: 视觉和触觉是机器人感知和操作任务的两种基本感官模态，提供了互补的信息以增强感知能力。以往的研究尝试联合学习视觉-触觉表示以提取更有意义的信息，但这些方法通常依赖于直接的特征组合（如特征相加或拼接），导致特征整合效果不佳。本文提出ConViTac，一种视觉-触觉表示学习网络，旨在通过对比表示增强融合过程中的特征对齐。我们的核心贡献是对比嵌入条件（CEC）机制，利用自监督对比学习预训练的对比编码器，将视觉和触觉输入投影到统一的潜在嵌入空间。这些嵌入通过跨模态注意力实现视觉-触觉特征的耦合融合，旨在对齐统一表示并提升下游任务的性能。通过大量实验，我们证明了ConViTac在现实场景中优于当前最先进方法，且提出的CEC机制在材料分类和抓取预测任务中最高提升了12.0%的准确率。

</details>


### [43] [AI-Driven MRI-based Brain Tumour Segmentation Benchmarking](https://arxiv.org/abs/2506.20786)
**中文标题：基于AI驱动的MRI脑肿瘤分割基准测试**

*Connor Ludwig,Khashayar Namdar,Farzad Khalvati*

主要分类: cs.CV

摘要简述: 本研究比较了多种AI模型（如SAM、SAM 2、MedSAM、SAM-Med-3D和nnU-Net）在BraTS 2023数据集上的脑肿瘤分割性能，发现高精度提示下SAM和SAM 2表现优异，但nnU-Net仍为最优选择。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，尽管出现了许多可提示的通用模型及其医学变体，但缺乏对这些模型在统一医学数据集上不同提示质量下的评估与比较。本研究旨在填补这一空白。

研究方法: 使用SAM、SAM 2、MedSAM、SAM-Med-3D和nnU-Net在BraTS 2023成人胶质瘤和儿科数据集上进行零样本推理，并评估不同提示质量（点和边界框）下的性能。随后对部分模型进行微调以提升性能。

研究结果: SAM和SAM 2在高精度边界框提示下Dice分数分别达到0.894和0.893，优于nnU-Net，但nnU-Net仍因提示不实用性占据主导地位。微调后点提示性能显著提升，但仍不及边界框或nnU-Net。

研究结论: 尽管SAM系列模型在高精度提示下表现优异，但nnU-Net仍是医学图像分割的首选。微调虽有效，但需进一步研究以提升性能。

中文摘要: 医学图像分割极大地辅助了医学诊断，其中基于U-Net的架构和nnU-Net提供了最先进的性能。近年来，尽管出现了许多通用可提示模型及其医学变体，但目前缺乏对这些模型在统一医学数据集上不同提示质量下的评估与比较。本研究使用Segment Anything Model（SAM）、Segment Anything Model 2（SAM 2）、MedSAM、SAM-Med-3D和nnU-Net，在BraTS 2023成人胶质瘤和儿科数据集上进行了零样本推理，并评估了点和边界框提示下的性能。其中，SAM和SAM 2在高精度边界框提示下的Dice分数分别达到0.894和0.893，超过了nnU-Net的分割性能。然而，由于提供高精度提示的不实用性，nnU-Net仍是医学图像分割的主导网络。研究还通过微调SAM、SAM 2、MedSAM和SAM-Med-3D在儿科数据集上扩展了模型和提示的评估与比较。微调后点提示性能显著提升，但仍无法超越边界框或nnU-Net的分割效果。

</details>


### [44] [How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?](https://arxiv.org/abs/2506.20795)
**中文标题：基础模型与基于骨架的方法在人机交互手势识别中的比较**

*Stephanie Käs,Anton Burenko,Louis Markert,Onur Alp Culha,Dennis Mack,Timm Linder,Bastian Leibe*

主要分类: cs.CV

摘要简述: 本文研究了基础模型（如V-JEPA和Gemini Flash 2.0）与基于骨架的方法（如HD-GCN）在动态全身手势识别中的表现。实验表明，HD-GCN性能最佳，但V-JEPA接近其表现，展示了基础模型在简化系统复杂性方面的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 手势在嘈杂环境中（如敏捷生产）为人机非语言交互提供了便利。传统深度学习方法依赖任务特定的架构，而基础模型（VFMs和VLMs）因其强大的泛化能力，可能简化系统设计。本文旨在探索这些模型在手势识别中的表现。

研究方法: 研究比较了V-JEPA（一种先进的VFM）、Gemini Flash 2.0（一种多模态VLM）和HD-GCN（一种基于骨架的方法）在动态全身手势识别中的表现。使用专门为物流环境设计的NUGGET数据集进行评估。

研究结果: 实验结果显示，HD-GCN性能最佳，但V-JEPA通过简单的任务特定分类头接近其表现，展示了基础模型作为共享多任务模型的潜力。Gemini在零样本设置中难以区分手势，表明需要进一步研究输入表示。

研究结论: 基础模型（如V-JEPA）在手势识别中表现接近基于骨架的方法，可能简化系统复杂性。然而，多模态模型（如Gemini）需要改进输入表示以适应手势识别任务。

中文摘要: 手势在嘈杂环境（如敏捷生产）中为人机非语言交互提供了便利。传统的基于深度学习的手势识别依赖任务特定的架构，使用图像、视频或骨架姿态估计作为输入。与此同时，视觉基础模型（VFMs）和视觉语言模型（VLMs）因其强大的泛化能力，可能通过替代专用任务模块来降低系统复杂性。本研究探讨了这些模型在动态全身手势识别中的适应性，比较了V-JEPA（一种先进的VFM）、Gemini Flash 2.0（一种多模态VLM）和HD-GCN（一种基于骨架的方法）。我们引入了NUGGET数据集，专为物流环境中的人机交互设计，以评估不同手势识别方法。实验结果显示，HD-GCN性能最佳，但V-JEPA通过简单的任务特定分类头接近其表现，展示了基础模型作为共享多任务模型的潜力。相比之下，Gemini在零样本设置中难以仅基于文本描述区分手势，突显了进一步研究手势输入表示的必要性。

</details>


### [45] [Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models](https://arxiv.org/abs/2506.20832)
**中文标题：利用视觉语言模型选择扩散模型生成的可信超分辨率样本**

*Cansu Korkmaz,Ahmet Murat Tekalp,Zafer Dogan*

主要分类: cs.CV

摘要简述: 本文提出了一种利用视觉语言模型（VLMs）从扩散模型生成的多组超分辨率（SR）样本中选择最可信样本的自动化框架，并通过混合指标（TWS）量化其可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 超分辨率（SR）是一个病态逆问题，传统方法在平衡保真度和感知质量时可能引入伪影，而扩散模型生成的多样SR样本缺乏可信选择机制。本文旨在解决如何从扩散模型生成的SR样本中选择最可信的样本。

研究方法: 利用视觉语言模型（如BLIP-2、GPT-4o等）通过结构化查询评估语义正确性、视觉质量和伪影存在，并引入混合指标Trustworthiness Score（TWS）量化SR样本的可靠性，包括CLIP嵌入的语义相似性、边缘图SSIM的结构完整性和多级小波分解的伪影敏感性。

研究结果: 实验表明，TWS与人类偏好高度相关，且VLM引导的选择始终获得高TWS值。相比传统指标（如PSNR、LPIPS），该方法在信息保真度上表现更优。

研究结论: 本文通过结合VLM和TWS，为扩散模型生成的SR样本提供了可信选择框架，为生成式SR的可靠性设定了新基准。

中文摘要: 超分辨率（SR）是一个病态逆问题，给定低分辨率图像存在多种可行解。一方面，回归式SR模型试图平衡保真度和感知质量以生成单一解，但这种权衡常引入伪影，导致信息关键应用（如数字或字母识别）中的模糊性。另一方面，扩散模型生成多样SR图像，但从中选择最可信解仍具挑战。本文提出一种自动化框架，利用视觉语言模型（VLMs）的语义推理能力从扩散生成集中识别最可信SR样本。具体而言，通过结构化查询提示BLIP-2、GPT-4o等VLM评估语义正确性、视觉质量和伪影存在，并集成排名靠前的SR候选以低成本生成单一可信输出。为严格评估VLM选择样本的有效性，提出混合指标Trustworthiness Score（TWS），基于CLIP嵌入的语义相似性、边缘图SSIM的结构完整性和多级小波分解的伪影敏感性量化SR可靠性。实验表明，TWS与人类偏好高度相关，且VLM引导选择始终获得高TWS值。相比传统指标（如PSNR、LPIPS），该方法在信息保真度上表现更优，为扩散SR空间的不确定性提供了可扩展、通用的解决方案。通过使输出符合人类预期和语义正确性，本研究为生成式SR的可信性设定了新基准。

</details>


### [46] [FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization](https://arxiv.org/abs/2506.20841)
**中文标题：FixCLR：用于半监督领域泛化的负类对比学习**

*Ha Min Son,Shahbaz Rezaei,Xin Liu*

主要分类: cs.CV

摘要简述: FixCLR是一种半监督领域泛化方法，通过改进对比学习，利用伪标签的类别信息和排斥项，显式地学习跨领域不变表示，提升模型在分布外数据上的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 半监督领域泛化（SSDG）在标签稀缺的情况下难以有效泛化到分布外数据。现有方法通常结合半监督学习和正则化项，但未能显式地学习跨领域不变表示。FixCLR旨在通过改进对比学习解决这一问题。

研究方法: FixCLR改进了对比学习的两个关键部分：利用伪标签的类别信息，并仅使用排斥项。该方法可以与其他半监督方法结合使用，进一步提升性能。

研究结果: 实验表明，FixCLR是一种有效的SSDG方法，尤其在与其他半监督方法结合时表现更优。研究还探索了半监督方法的改进、预训练与非预训练模型的性能对比，以及多领域数据集的测试。

研究结论: FixCLR通过显式地学习跨领域不变表示，显著提升了半监督领域泛化的性能，且具有与其他方法结合的灵活性。

中文摘要: 半监督领域泛化（SSDG）旨在解决在仅有少量标签可用时泛化到分布外数据的问题。由于标签稀缺，传统的领域泛化方法表现不佳。现有的SSDG方法通常结合半监督学习与各种正则化项，但这些方法未能显式地学习跨所有领域的不变表示，而这是领域泛化的关键目标。为此，我们提出了FixCLR。受自监督学习成功的启发，我们改进了对比学习的两个关键部分：利用伪标签的类别信息，并仅使用排斥项。FixCLR还可以与大多数现有的SSDG和半监督方法结合，以进一步提升性能。我们的研究包括大量实验，这些实验在SSDG研究中尚未被探索，例如对不同半监督方法改进的基准测试、预训练与非预训练模型的性能评估，以及多领域数据集的测试。总体而言，FixCLR被证明是一种有效的SSDG方法，尤其是与其他半监督方法结合时。

</details>


### [47] [Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision](https://arxiv.org/abs/2506.20850)
**中文标题：医学视觉中像素级预训练的向量对比学习**

*Yuting He,Shuo Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为向量对比学习（Vector CL）的新方法，通过将对比学习重新定义为向量回归问题，解决了传统二元对比学习在像素级预训练中过度分散特征的问题。提出的COVER框架在8个任务中显著提升了像素级自监督预训练效果。


<details>
  <summary>详细信息</summary>
研究动机: 传统对比学习（CL）在自监督预训练（SSP）中表现优异，但其二元优化形式在像素级任务中会导致特征过度分散，破坏像素间的相关性。本文旨在解决这一问题，提出一种适用于医学视觉的像素级预训练方法。

研究方法: 本文提出向量对比学习（Vector CL），将对比学习重新定义为向量回归问题，通过建模特征距离来量化分散。COVER框架实现了基于向量的自学习，从向量回归到距离建模的优化流程，并采用向量金字塔架构适应不同粒度，从而保留像素级特征相关性。

研究结果: 在涵盖2个维度和4种模态的8个任务中，COVER框架显著提升了像素级自监督预训练的效果，验证了其在医学视觉基础模型中的通用性。

研究结论: 向量对比学习通过向量回归解决了传统对比学习在像素级任务中的局限性，COVER框架为医学视觉基础模型提供了更通用的预训练方法。

中文摘要: 对比学习（CL）已成为基础模型中自监督预训练（SSP）的基石，然而将其扩展到对医学视觉至关重要的像素级表示仍是一个未解决的问题。标准CL将SSP表述为一个二元优化问题（二元CL），其中对特征分散的过度追求会导致过度分散问题，破坏像素级特征相关性，从而扰乱类内分布。我们的向量CL将CL重新表述为一个向量回归问题，通过建模特征距离来量化像素级预训练中的分散。为实现这一新范式，我们提出了基于向量回归的对比框架（COVER）。COVER建立了一个可扩展的基于向量的自学习机制，强制执行从向量回归到距离建模的一致优化流程，并利用向量金字塔架构进行粒度适应，从而在SSP中保留像素级特征相关性。在涵盖2个维度和4种模态的8个任务中，COVER显著提升了像素级SSP的效果，推动了通用医学视觉基础模型的发展。

</details>


### [48] [Enhancing Ambiguous Dynamic Facial Expression Recognition with Soft Label-based Data Augmentation](https://arxiv.org/abs/2506.20867)
**中文标题：基于软标签数据增强的模糊动态面部表情识别优化**

*Ryosuke Kawamura,Hideaki Hayashi,Shunsuke Otake,Noriko Takemura,Hajime Nagahara*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MIDAS的数据增强方法，通过软标签增强动态面部表情识别（DFER）性能，特别针对模糊表情数据。实验证明，该方法在DFEW和FERV39k-Plus数据集上优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 动态面部表情识别（DFER）在实际应用中常遇到模糊表情数据，准确识别这些表情至关重要。本文旨在通过数据增强方法提升DFER在模糊表情数据上的性能。

研究方法: 提出MIDAS方法，利用代表多情感类别概率的软标签，通过对视频帧及其情感标签进行凸组合来增强训练数据，将mixup扩展至软标签视频数据。

研究结果: 在DFEW和FERV39k-Plus数据集上的实验表明，使用MIDAS增强数据训练的模型性能优于原始数据集上的现有最佳方法。

研究结论: MIDAS是一种简单高效的数据增强方法，显著提升了DFER在模糊表情数据上的性能，为实际应用提供了有力支持。

中文摘要: 动态面部表情识别（DFER）是一项从面部表情视频序列中估计情绪的任务。在实际应用中，准确识别模糊面部表情（常见于真实场景数据）至关重要。本研究提出MIDAS，一种数据增强方法，旨在通过代表多情感类别概率的软标签提升DFER在模糊表情数据上的性能。MIDAS通过凸组合视频帧及其对应情感标签来增强训练数据，将mixup扩展至软标签视频数据，为处理DFER中的模糊性提供了一种简单高效的方法。为评估MIDAS，我们在DFEW数据集和新构建的FERV39k-Plus数据集（为现有DFER数据集分配软标签）上进行了实验。结果表明，使用MIDAS增强数据训练的模型性能优于原始数据集上的现有最佳方法。

</details>


### [49] [THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion](https://arxiv.org/abs/2506.20877)
**中文标题：THIRDEYE：基于大脑启发的多阶段融合的单目深度估计方法**

*Calin Teodor Ioan*

主要分类: cs.CV

摘要简述: THIRDEYE提出了一种基于大脑启发多阶段融合的单目深度估计方法，通过显式引入单目线索（如遮挡边界、阴影和透视）并分阶段融合，显著提升了深度估计的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统单目深度估计方法通过深度模型直接从RGB像素推断深度，忽略了人类视觉系统依赖的显式单目线索（如遮挡边界、阴影和透视）。THIRDEYE旨在通过显式引入这些线索，提升深度估计的精度。

研究方法: THIRDEYE通过预训练且冻结的专家网络显式提供单目线索，并在三阶段皮层层次（V1->V2->V3）中融合这些线索，结合键值工作记忆模块动态加权。最终通过自适应分箱变换器生成高分辨率视差图。

研究结果: 由于冻结了专家网络，THIRDEYE继承了大量外部监督，仅需少量微调即可实现高性能。实验表明其深度估计精度显著提升。

研究结论: THIRDEYE通过显式引入和分阶段融合单目线索，结合大脑启发的工作记忆模块，实现了高效且高精度的单目深度估计。

中文摘要: 传统单目深度估计方法通过深度模型直接从RGB像素推断深度，这种隐式学习往往忽略了人类视觉系统依赖的显式单目线索（如遮挡边界、阴影和透视）。THIRDEYE提出了一种显式线索感知的流程，通过预训练且冻结的专家网络提供这些线索，并在三阶段皮层层次（V1->V2->V3）中融合，结合键值工作记忆模块动态加权。最终通过自适应分箱变换器生成高分辨率视差图。由于专家网络被冻结，THIRDEYE继承了大量外部监督，仅需少量微调。本文扩展版本提供了更多架构细节、神经科学动机和实验协议；定量结果将在未来版本中呈现。

</details>


### [50] [MultiHuman-Testbench: Benchmarking Image Generation for Multiple Humans](https://arxiv.org/abs/2506.20879)
**中文标题：MultiHuman-Testbench：多人生成图像的基准测试**

*Shubhankar Borse,Seokeon Choi,Sunghyun Park,Jeongho Kim,Shreya Kadambi,Risheek Garrepalli,Sungrack Yun,Munawar Hayat,Fatih Porikli*

主要分类: cs.CV

摘要简述: 本文提出了MultiHuman-Testbench，一个用于评估多人生成图像模型的新基准，包含1800个样本和5550张人脸图像，通过多维度指标评估模型性能，并提出了改进身份相似性的新技术。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏专门用于评估多人生成图像模型的基准，导致生成复杂动作且保留面部身份的图像成为挑战。本文旨在填补这一空白。

研究方法: 提出了MultiHuman-Testbench基准，包含多样化的文本提示和人脸图像，并设计了四项关键指标评估模型性能。同时，提出了基于人体分割和匈牙利匹配的新技术以提升身份相似性。

研究结果: 通过基准测试，评估了多种模型（包括零样本和基于训练的方法），发现新技术显著提高了身份相似性，为多人生成图像研究提供了标准化工具。

研究结论: MultiHuman-Testbench为多人生成图像研究提供了重要基准和新技术，推动了该领域的标准化和进步。

中文摘要: 生成包含多人且保留面部身份的复杂动作图像是一项重大挑战，主要原因之一是缺乏专用基准。为此，我们提出了MultiHuman-Testbench，一个用于严格评估多人生成模型的新基准。该基准包含1800个样本，包括精心设计的文本提示，描述了从简单到复杂的人类动作。这些提示与5550张独特的人脸图像匹配，确保年龄、种族背景和性别的多样性。除了文本提示，我们还提供了与提示准确匹配的人体姿势条件图像。我们提出了一套多维度评估方法，使用四项关键指标量化人脸数量、身份相似性、提示对齐和动作检测。我们对多种模型进行了全面评估，包括零样本方法和基于训练的方法，无论是否使用区域先验。此外，我们提出了基于人体分割和匈牙利匹配的新技术，显著提高了身份相似性。我们的基准和关键发现为多人生成图像研究提供了宝贵见解和标准化工具。

</details>


### [51] [The Role of Cyclopean-Eye in Stereo Vision](https://arxiv.org/abs/2506.20900)
**中文标题：Cyclopean Eye在立体视觉中的作用**

*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

主要分类: cs.CV

摘要简述: 本文研究了现代立体视觉系统的几何基础，重点探讨了3D结构和人类感知如何促进深度重建的准确性。通过重新审视Cyclopean Eye模型并提出新的几何约束，结合深度学习特征匹配和注意力机制，展示了几何先验与学习特征结合的优势。


<details>
  <summary>详细信息</summary>
研究动机: 现代立体视觉系统在深度重建中面临遮挡和深度不连续性的挑战。本文旨在通过结合几何先验和学习特征，提升系统的鲁棒性和准确性。

研究方法: 重新审视Cyclopean Eye模型，提出新的几何约束以处理遮挡和深度不连续性；评估深度学习模型生成的立体特征匹配质量；研究注意力机制在恢复3D表面中的作用。

研究结果: 理论和实证研究表明，结合几何先验与学习特征能够显著提升立体视觉系统的性能，特别是在处理复杂场景时。

研究结论: 几何先验与学习特征的结合为理解立体视觉系统提供了新的视角，展示了其在深度重建中的潜力。

中文摘要: 本研究探讨了现代立体视觉系统的几何基础，重点关注3D结构和人类感知如何促进深度重建的准确性。我们重新审视了Cyclopean Eye模型，并提出新的几何约束以处理遮挡和深度不连续性。分析包括评估深度学习模型生成的立体特征匹配质量，以及注意力机制在恢复有意义3D表面中的作用。通过理论分析和真实数据集的实证研究，我们证明了结合几何先验与学习特征能够为理解立体视觉系统提供内部抽象。

</details>


### [52] [FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing](https://arxiv.org/abs/2506.20911)
**中文标题：FaSTA$^*$：基于子程序挖掘的快慢工具路径代理用于高效多轮图像编辑**

*Advait Gupta,Rishie Raj,Dang Nguyen,Tianyi Zhou*

主要分类: cs.CV

摘要简述: FaSTA$^*$是一种高效的神经符号代理，结合大型语言模型（LLM）的快速高级子任务规划和局部A$^*$搜索的慢速精确工具使用，用于多轮图像编辑任务。通过提取和重用频繁使用的子程序，显著降低了相似子任务的探索成本，实现了高效的计算性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前的多轮图像编辑任务（如检测、重新着色和移除对象）需要高效且成本低廉的解决方案。传统方法在复杂任务中计算成本高，因此需要一种结合快速规划和精确工具使用的混合方法。

研究方法: FaSTA$^*$结合了LLM的快速子任务规划和局部A$^*$搜索的精确工具使用。通过归纳推理提取频繁使用的子程序，并将其作为新工具重用。采用自适应快慢规划策略，优先尝试高级子程序，仅在失败时触发低级的A$^*$搜索。

研究结果: 实验表明，FaSTA$^*$在计算效率上显著优于现有方法，同时在任务成功率上与最先进的基线方法竞争。

研究结论: FaSTA$^*$通过结合快速规划和精确工具使用，显著提升了多轮图像编辑任务的效率，同时保持了高成功率。其自适应快慢规划和子程序重用机制为复杂任务提供了高效解决方案。

中文摘要: 我们开发了一种成本高效的神经符号代理FaSTA$^*$，用于解决复杂的多轮图像编辑任务，例如“检测图像中的长椅并将其重新着色为粉色，同时移除猫以获得更清晰的视野，并将墙壁重新着色为黄色”。该方法结合了大型语言模型（LLM）的快速高级子任务规划和局部A$^*$搜索的慢速精确工具使用，以找到成本高效的工具路径——一系列对AI工具的调用。为了节省A$^*$在相似子任务上的成本，我们通过LLM对先前成功的工具路径进行归纳推理，持续提取/优化频繁使用的子程序，并将其作为新工具用于未来的任务中，实现自适应的快慢规划。高级子程序优先尝试，仅在失败时触发低级的A$^*$搜索。这些可重用的符号子程序显著降低了相似图像上相同类型子任务的探索成本，形成了一种类似人类的快慢工具路径代理“FaSTA$^*$”：快速子任务规划后，LLM首先尝试基于规则的子程序选择，预期覆盖大多数任务，而慢速A$^*$搜索仅针对新颖和具有挑战性的子任务触发。通过与近期图像编辑方法的比较，我们证明了FaSTA$^*$在计算效率上显著更高，同时在任务成功率上与最先进的基线方法竞争。

</details>


### [53] [M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization](https://arxiv.org/abs/2506.20922)
**中文标题：M2SFormer：基于多频谱和多尺度注意力及边缘感知难度引导的图像伪造定位方法**

*Ju-Hyeon Nam,Dong-Hyun Moon,Sang-Chul Lee*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Transformer的框架M2SFormer，通过多频谱和多尺度注意力机制以及边缘感知难度引导，显著提升了图像伪造定位的准确性和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着图像编辑技术的快速发展，恶意篡改图像的行为日益增多。现有的深度学习方法在像素级伪造定位中虽有一定效果，但面临计算开销大和难以捕捉复杂篡改的局限性。

研究方法: M2SFormer通过统一的Transformer编码器框架，结合多频谱和多尺度注意力机制，利用全局上下文捕捉伪造痕迹。此外，通过引入全局先验图和难度引导注意力模块，有效保留了篡改的细节信息。

研究结果: 在多个基准数据集上的实验表明，M2SFormer在伪造检测和定位任务中优于现有最先进模型，尤其在跨领域泛化能力上表现突出。

研究结论: M2SFormer通过创新的注意力机制和难度引导策略，显著提升了图像伪造定位的性能，为未来研究提供了新的方向。

中文摘要: 图像编辑技术的快速发展既推动了创新应用，也助长了数字图像的恶意篡改。近年来，基于深度学习的方法在像素级伪造定位中取得了较高精度，但仍面临计算开销大和表征能力有限的问题，尤其是对细微或复杂篡改的检测。本文提出M2SFormer，一种基于Transformer编码器的新型框架，旨在解决这些挑战。与将空间和频率线索分开处理的方法不同，M2SFormer在跳跃连接中统一了多频率和多尺度注意力，利用全局上下文更好地捕捉多样化的伪造痕迹。此外，针对上采样过程中细节丢失的问题，该框架通过全局先验图（一种指示伪造定位难度的曲率度量）引导难度感知注意力模块，从而更有效地保留细微篡改。在多个基准数据集上的大量实验表明，M2SFormer优于现有最先进模型，在跨领域伪造检测和定位任务中展现出卓越的泛化能力。

</details>


### [54] [PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling](https://arxiv.org/abs/2506.20936)
**中文标题：PhysRig：基于物理的可微分皮肤绑定与骨骼框架，用于真实关节物体建模**

*Hao Zhang,Haolan Xu,Chun Feng,Varun Jampani,Narendra Ahuja*

主要分类: cs.CV

摘要简述: PhysRig是一种基于物理的可微分皮肤绑定框架，通过将刚性骨骼嵌入体积表示中，模拟为可变形软体结构，解决了传统线性混合皮肤绑定（LBS）的体积损失和非自然变形问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有皮肤绑定方法主要依赖线性混合皮肤绑定（LBS），但其存在体积损失和非自然变形等问题，且无法模拟弹性材料（如软组织、毛发等）。PhysRig旨在通过物理模拟克服这些限制。

研究方法: PhysRig将刚性骨骼嵌入体积表示（如四面体网格），模拟为可变形软体结构，利用连续介质力学和欧拉背景网格离散化物体，确保对材料属性和骨骼运动的不同性。同时引入材料原型，减少学习空间。

研究结果: PhysRig在合成数据集上表现优于传统LBS方法，生成更真实且物理合理的结果，并在姿态迁移任务中展示了其多用途性。

研究结论: PhysRig为关节物体建模提供了更真实、物理合理的解决方案，克服了LBS的局限性，适用于多种应用场景。

中文摘要: 皮肤绑定和骨骼绑定是动画、关节物体重建、运动迁移和4D生成中的基础组成部分。现有方法主要依赖线性混合皮肤绑定（LBS），因其简单性和可微分性。然而，LBS会引入体积损失和非自然变形等问题，且无法模拟弹性材料（如软组织、毛发和柔性附件）。本文提出PhysRig：一种基于物理的可微分皮肤绑定与骨骼框架，通过将刚性骨骼嵌入体积表示（如四面体网格）中，模拟为可变形软体结构，克服了这些限制。我们的方法利用连续介质力学，并将物体离散为嵌入欧拉背景网格的粒子，确保对材料属性和骨骼运动的不同性。此外，我们引入材料原型，显著减少学习空间，同时保持高表现力。为评估框架，我们使用Objaverse、The Amazing Animals Zoo和MixaMo中的网格构建了全面的合成数据集，涵盖多种物体类别和运动模式。我们的方法在生成更真实且物理合理的结果方面始终优于传统LBS方法。此外，我们还展示了框架在姿态迁移任务中的适用性，突显其在关节物体建模中的多功能性。

</details>


### [55] [AIR-VIEW: The Aviation Image Repository for Visibility Estimation of Weather, A Dataset and Benchmark](https://arxiv.org/abs/2506.20939)
**中文标题：AIR-VIEW：航空天气能见度估计的图像存储库，一个数据集与基准**

*Chad Mourning,Zhewei Wang,Justin Murray*

主要分类: cs.CV

摘要简述: 本文介绍了一个名为AIR-VIEW的新数据集，专为航空天气能见度估计设计，填补了公开数据集的空白，并提供了基准测试结果。


<details>
  <summary>详细信息</summary>
研究动机: 航空天气的机器学习研究需要低成本替代传统昂贵传感器，但目前缺乏适合监督学习的公开能见度估计数据集。本文旨在填补这一空白。

研究方法: 通过为期一年的FAA天气摄像头网络数据收集活动，构建了一个适合航空能见度估计的数据集，并对比了三种常用方法和通用基线在多个数据集上的表现。

研究结果: 新数据集AIR-VIEW成功填补了公开数据集的空白，基准测试显示其性能优于其他公开数据集，并与ASTM标准一致。

研究结论: AIR-VIEW数据集为航空能见度估计提供了重要资源，基准测试验证了其有效性，推动了该领域的研究进展。

中文摘要: 航空天气的机器学习研究为传统昂贵天气传感器提供了低成本替代方案；然而，在能见度估计领域，缺乏公开的、适合监督学习的数据集，这些数据集需包含航空相关距离、多样化地点且规模足够。本文介绍了一个新数据集，它是一年FAA天气摄像头网络数据收集活动的成果。我们还提供了一个基准测试，比较了三种常用方法和通用基线在三个公开数据集及我们数据集上的表现，并与最近批准的ASTM标准进行了对比。

</details>


### [56] [Hierarchical Sub-action Tree for Continuous Sign Language Recognition](https://arxiv.org/abs/2506.20947)
**中文标题：基于分层子动作树的连续手语识别**

*Dejie Yang,Zhu Xu,Xinjie Gao,Yang Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为HST-CSLR的分层子动作树方法，通过结合大语言模型的文本知识，更高效地融合视觉与文本模态，提升了连续手语识别的性能。


<details>
  <summary>详细信息</summary>
研究动机: 连续手语识别（CSLR）由于缺乏大规模数据集和精确标注，训练数据不足成为瓶颈。现有方法未能充分利用文本知识，因此本文旨在通过分层子动作树（HST）更有效地结合视觉与文本模态。

研究方法: 提出HST-CSLR方法，构建分层子动作树表示文本信息，逐步对齐视觉与文本模态，并利用树结构降低计算复杂度。同时引入对比对齐增强，缩小两种模态间的差距。

研究结果: 在PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture四个数据集上的实验证明了HST-CSLR的有效性。

研究结论: HST-CSLR通过分层子动作树和对比对齐增强，显著提升了连续手语识别的性能，为跨模态学习提供了新思路。

中文摘要: 连续手语识别（CSLR）旨在将未修剪的视频转录为文本词汇（glosses）。近期研究表明，由于缺乏大规模数据集和精确标注，训练数据不足成为CSLR的瓶颈。为解决这一问题，一些研究开发了跨模态解决方案以对齐视觉与文本模态。然而，这些方法通常从glosses中提取文本特征，未能充分利用其知识。本文提出分层子动作树（HST），即HST-CSLR，以高效结合gloss知识与视觉表示学习。通过从大语言模型中引入gloss特定知识，我们的方法更有效地利用了文本信息。具体而言，我们构建了HST用于文本信息表示，逐步对齐视觉与文本模态，并利用树结构降低计算复杂度。此外，我们引入对比对齐增强以缩小两种模态间的差距。在四个数据集（PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture）上的实验证明了HST-CSLR的有效性。

</details>


### [57] [OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs](https://arxiv.org/abs/2506.20960)
**中文标题：OmniEval：一个用于评估全模态模型的基准测试，涵盖视觉、听觉和文本输入**

*Yiman Zhang,Ziheng Luo,Qiangyu Yan,Wei He,Borui Jiang,Xinghao Chen,Kai Han*

主要分类: cs.CV

摘要简述: 本文介绍了OmniEval，一个用于评估全模态模型（如MiniCPM-O 2.6）的基准测试，涵盖视觉、听觉和文本输入。其特点包括全模态协作、多样化的视频和任务，以及更细粒度的视频定位任务。实验表明，OmniEval为评估多模态模型的上下文理解能力提供了平台。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试在评估全模态模型时存在局限性，无法充分体现多模态协作和任务多样性。因此，作者提出了OmniEval，旨在提供一个更全面的评估平台，以测试模型在多模态输入下的表现。

研究方法: OmniEval设计了强调音频与视频强耦合的任务，包含810个音视频同步视频（285个中文和525个英文视频），以及2617个问答对（1412个开放式问题和1205个多选题）。任务分为3大类12小类，并引入了细粒度的视频定位任务Grounding。

研究结果: 实验表明，OmniEval能够有效评估全模态模型在多模态协作和任务多样性方面的表现，为模型能力的全面测试提供了平台。

研究结论: OmniEval是一个全面的基准测试，能够评估全模态模型在多模态输入下的表现，为未来研究提供了重要工具。

中文摘要: 本文介绍了OmniEval，一个用于评估全模态模型（如MiniCPM-O 2.6）的基准测试，涵盖视觉、听觉和文本输入。与现有基准相比，OmniEval具有以下特点：（i）全模态协作：设计了强调音频与视频强耦合的任务，要求模型有效利用所有模态的协作感知；（ii）视频多样性：包含810个音视频同步视频（285个中文和525个英文视频）；（iii）任务多样性与细粒度：包含2617个问答对（1412个开放式问题和1205个多选题），分为3大类12小类，并引入了细粒度的视频定位任务Grounding。实验表明，OmniEval为评估模型在多模态上下文中的理解能力提供了平台。代码和数据可在https://omnieval.github.io/获取。

</details>


### [58] [Evidence-based diagnostic reasoning with multi-agent copilot for human pathology](https://arxiv.org/abs/2506.20964)
**中文标题：基于多智能体协同的人类病理学循证诊断推理**

*Chengkuan Chen,Luca L. Weishaupt,Drew F. K. Williamson,Richard J. Chen,Tong Ding,Bowen Chen,Anurag Vaidya,Long Phi Le,Guillaume Jaume,Ming Y. Lu,Faisal Mahmood*

主要分类: cs.CV

摘要简述: 本文介绍了PathChat+，一种专为病理学设计的新型多模态大语言模型，通过百万级病理学指令样本训练，显著优于现有模型，并结合SlideSeek系统实现高精度诊断推理。


<details>
  <summary>详细信息</summary>
研究动机: 当前病理学领域的深度学习模型多集中于图像分析，缺乏自然语言指令和文本上下文的整合，且现有多模态大语言模型在训练数据、多图像理解及自主诊断推理能力方面存在不足。

研究方法: 提出PathChat+模型，基于超过100万病理学指令样本和550万问答对训练，并结合SlideSeek系统，通过迭代层次化诊断推理自主分析全切片图像。

研究结果: PathChat+在多种病理学基准测试中显著优于现有模型，SlideSeek系统在DDxBench上实现高精度诊断，并能生成可视化解释性报告。

研究结论: PathChat+和SlideSeek系统为病理学诊断提供了高效、自主的解决方案，推动了人工智能在病理学中的应用。

中文摘要: 病理学正经历由全切片成像和人工智能（AI）驱动的快速数字化转型。尽管基于深度学习的计算病理学已取得显著成功，但传统模型主要集中于图像分析，未整合自然语言指令或丰富的文本上下文。当前计算病理学中的多模态大语言模型（MLLMs）存在训练数据不足、多图像理解支持与评估不足以及缺乏自主诊断推理能力等局限。为解决这些问题，我们提出了PathChat+，一种专为人类病理学设计的新型MLLM，基于超过100万多样化的病理学指令样本和近550万问答对训练。在多种病理学基准测试中的广泛评估表明，PathChat+显著优于先前的PathChat协同模型，以及最先进的通用模型和其他病理学专用模型。此外，我们提出了SlideSeek，一种基于PathChat+的具备推理能力的多智能体AI系统，通过迭代层次化诊断推理自主评估千兆像素全切片图像（WSIs），在具有挑战性的开放式鉴别诊断基准DDxBench上达到高精度，同时能够生成视觉基础、人类可理解的总结报告。

</details>


### [59] [DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing](https://arxiv.org/abs/2506.20967)
**中文标题：DFVEdit：基于条件增量流向量的零样本视频编辑**

*Lingling Cai,Kang Zhao,Hangjie Yuan,Xiang Wang,Yingya Zhang,Kejie Huang*

主要分类: cs.CV

摘要简述: DFVEdit是一种高效的零样本视频编辑方法，专为视频扩散变换器（Video DiTs）设计，通过流变换直接在干净潜在空间操作，无需注意力修改或微调，显著提升了计算效率和编辑质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频编辑方法在应用于视频扩散变换器时，常因资源密集的注意力修改或微调导致计算开销巨大。DFVEdit旨在解决这一问题，提供一种高效且无需修改或微调的零样本视频编辑方案。

研究方法: DFVEdit基于连续流视角统一编辑和采样，提出条件增量流向量（CDFV）作为DFV的无偏估计，并结合隐式交叉注意力（ICA）指导和嵌入增强（ER）进一步提升编辑质量。

研究结果: DFVEdit在视频扩散变换器上实现了至少20倍的推理加速和85%的内存节省，同时在结构保真度、时空一致性和编辑质量上达到最优性能。

研究结论: DFVEdit通过流变换和优化技术，显著提升了视频编辑的效率和效果，适用于多种主流视频扩散变换器，展现了卓越的实用性和性能。

中文摘要: 视频扩散变换器（Video DiTs）的出现标志着视频生成领域的重大进展。然而，直接将现有视频编辑方法应用于Video DiTs通常会导致巨大的计算开销，原因是资源密集的注意力修改或微调。为解决这一问题，我们提出了DFVEdit，一种专为Video DiTs设计的高效零样本视频编辑方法。DFVEdit通过流变换直接在干净潜在空间操作，无需注意力修改或微调。具体而言，我们发现编辑和采样可以从连续流的角度统一。基于此，我们提出了条件增量流向量（CDFV）——DFV的理论无偏估计，并结合隐式交叉注意力（ICA）指导和嵌入增强（ER）进一步提升编辑质量。DFVEdit在实际效率上表现出色，与基于注意力工程的编辑方法相比，在Video DiTs上实现了至少20倍的推理加速和85%的内存节省。大量的定量和定性实验表明，DFVEdit可无缝应用于主流Video DiTs（如CogVideoX和Wan2.1），在结构保真度、时空一致性和编辑质量上达到最优性能。

</details>


### [60] [From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan Face Aging](https://arxiv.org/abs/2506.20977)
**中文标题：从摇篮到拐杖：一种高保真全生命周期人脸老化的两阶段框架**

*Tao Liu,Dafeng Zhang,Gengchen Li,Shizhuo Liu,Yongqi Song,Senmao Li,Shiqi Yang,Boqian Li,Kai Wang,Yaxing Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Cradle2Cane的两阶段人脸老化框架，通过自适应噪声注入和身份感知嵌入技术，解决了年龄准确性与身份一致性之间的平衡问题，显著提升了老化效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人脸老化方法在年龄准确性和身份一致性之间存在权衡问题，无法同时实现高保真的年龄转换和身份保留。本文旨在通过两阶段框架解决这一挑战。

研究方法: 提出两阶段框架：第一阶段通过自适应噪声注入（AdaNI）实现年龄准确性；第二阶段利用身份感知嵌入（IDEmb）增强身份一致性。两阶段联合训练，实现端到端优化。

研究结果: 在CelebA-HQ测试数据集上，Cradle2Cane在Face++和Qwen-VL协议下表现优于现有方法，年龄准确性和身份一致性均显著提升。

研究结论: Cradle2Cane框架通过两阶段设计有效解决了年龄与身份之间的权衡问题，为人脸老化任务提供了高保真解决方案。

中文摘要: 人脸老化已成为计算机视觉中的关键任务，应用范围从娱乐到医疗保健。然而，现有方法在实现全生命周期真实无缝的转换方面存在困难，尤其是处理大年龄差距或极端头部姿态时。核心挑战在于平衡年龄准确性和身份保留——我们称之为Age-ID权衡。大多数现有方法要么以牺牲身份一致性为代价优先年龄转换，要么反之。本文通过提出一种基于少步文本到图像（T2I）扩散模型的两阶段人脸老化框架Cradle2Cane来解决这一问题。第一阶段通过引入自适应噪声注入（AdaNI）机制解决年龄准确性，该机制以年龄和性别的文本描述为条件。通过调整噪声水平，可以控制老化强度并增加转换灵活性，但身份保留较弱。第二阶段通过两种身份感知嵌入（IDEmb）——SVR-ArcFace和Rotate-CLIP——增强身份保留，同时保持年龄特征。此阶段对第一阶段转换的图像进行去噪，确保身份一致性而不影响老化准确性。两阶段联合端到端训练。在CelebA-HQ测试数据集上的大量实验表明，Cradle2Cane在Face++和Qwen-VL协议下优于现有人脸老化方法，年龄准确性和身份一致性均显著提升。

</details>


### [61] [3D Scene-Camera Representation with Joint Camera Photometric Optimization](https://arxiv.org/abs/2506.20979)
**中文标题：基于联合相机光度优化的3D场景-相机表示**

*Weichen Dai,Kangcheng Ma,Jiaxin Wang,Kecen Pan,Yuhang Ming,Hua Zhang,Wanzeng Kong*

主要分类: cs.CV

摘要简述: 本文提出了一种结合相机光度优化的3D场景-相机表示方法，通过联合优化相机光度参数和深度正则化，有效分离与场景无关的信息，提升3D场景表示质量。


<details>
  <summary>详细信息</summary>
研究动机: 多视角图像中的光度失真会降低图像质量，进而影响3D场景表示的准确性。若不考虑这些失真，3D场景表示可能包含与场景无关的错误信息。本文旨在通过联合优化相机光度模型，解决这一问题。

研究方法: 提出了一种完整的3D场景-相机表示方法，结合内部和外部光度模型，通过联合优化相机参数和深度正则化，分离与场景无关的信息，构建包含场景辐射场和相机光度模型的完整映射。

研究结果: 实验结果表明，即使在存在渐晕或污渍等成像退化情况下，该方法仍能生成高质量的3D场景表示。

研究结论: 通过联合优化相机光度参数和引入深度正则化，本文方法有效提升了3D场景表示的质量，为计算机视觉任务提供了更可靠的场景建模工具。

中文摘要: 从多视角图像中表示场景是计算机视觉中一项关键任务，具有广泛应用。然而，相机成像中固有的光度失真会显著降低图像质量。若不考虑这些失真，3D场景表示可能会无意中引入与场景无关的错误信息，从而降低表示质量。本文提出了一种新颖的基于联合相机光度优化的3D场景-相机表示方法。通过引入内部和外部光度模型，我们提出了一种完整的光度模型及相应的相机表示。基于同时优化相机表示参数的方法，所提方法有效地从3D场景表示中分离出与场景无关的信息。此外，在优化光度参数的过程中，我们引入了深度正则化，以防止3D场景表示拟合与场景无关的信息。通过将相机模型作为映射过程的一部分，所提方法构建了一个包含场景辐射场和相机光度模型的完整映射。实验结果表明，即使在渐晕或污渍等成像退化条件下，所提方法仍能实现高质量的3D场景表示。

</details>


### [62] [Rethink Sparse Signals for Pose-guided Text-to-image Generation](https://arxiv.org/abs/2506.20983)
**中文标题：重新思考稀疏信号在姿势引导的文本到图像生成中的应用**

*Wenjie Xuan,Jing Zhang,Juhua Liu,Bo Du,Dacheng Tao*

主要分类: cs.CV

摘要简述: 本文提出了一种新型的Spatial-Pose ControlNet（SP-Ctrl），通过改进稀疏信号（如OpenPose）的可控性，用于姿势引导的文本到图像生成。实验表明，该方法在稀疏姿势引导下优于现有方法，甚至与密集信号方法性能相当。


<details>
  <summary>详细信息</summary>
研究动机: 近年来，密集信号（如深度图、DensePose）被广泛用于姿势引导的图像生成，但其编辑难度大且可能与文本提示不一致。因此，本文重新探讨稀疏信号（如OpenPose）的潜力，因其简单性和形状无关性，但现有研究较少。

研究方法: 本文提出SP-Ctrl，将OpenPose扩展为可学习的空间表示，使关键点嵌入更具区分性和表现力。同时，引入关键点概念学习，鼓励关键点标记关注每个关键点的空间位置，从而提升姿势对齐。

研究结果: 在动物和人类为中心的图像生成任务中，SP-Ctrl在稀疏姿势引导下优于现有方法，甚至与密集信号方法性能相当。此外，SP-Ctrl展示了通过稀疏信号实现多样化和跨物种生成的潜力。

研究结论: 稀疏信号在姿势引导的图像生成中具有潜力，SP-Ctrl通过改进其可控性，实现了与密集信号方法相当的性能，同时保持了稀疏信号的简单性和灵活性。

中文摘要: 近期研究倾向于使用密集信号（如深度图、DensePose）作为姿势引导的文本到图像生成的详细空间指导，替代稀疏信号（如OpenPose）。然而，密集信号带来了新的挑战，包括编辑困难和与文本提示的潜在不一致。这一事实促使我们重新审视稀疏信号的潜力，因其简单性和形状无关性，但尚未充分探索。本文提出了一种新型的Spatial-Pose ControlNet（SP-Ctrl），为稀疏信号提供了强大的可控性，用于姿势引导的图像生成。具体而言，我们将OpenPose扩展为可学习的空间表示，使关键点嵌入更具区分性和表现力。此外，我们引入了关键点概念学习，鼓励关键点标记关注每个关键点的空间位置，从而提升姿势对齐。在动物和人类为中心的图像生成任务中，实验表明我们的方法在稀疏姿势引导下优于现有方法，甚至与密集信号方法性能相当。此外，SP-Ctrl展示了通过稀疏信号实现多样化和跨物种生成的潜力。代码将在https://github.com/DREAMXFAR/SP-Ctrl发布。

</details>


### [63] [EVA: Mixture-of-Experts Semantic Variant Alignment for Compositional Zero-Shot Learning](https://arxiv.org/abs/2506.20986)
**中文标题：EVA：基于专家混合的语义变体对齐组合零样本学习**

*Xiao Zhang,Yongqiang Ma,Haodong Jing,Nanning Zheng*

主要分类: cs.CV

摘要简述: 本文提出EVA框架，通过专家混合和语义变体对齐提升组合零样本学习的性能，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有组合零样本学习方法通过简单的组合原型映射获取原始特征，忽略了语义子集的区分性和组合差异，导致图像与组合对齐不精细。

研究方法: 提出EVA框架，包括域专家适应和语义变体对齐。域专家适应利用多个专家实现标记感知学习，生成高质量原始表示；语义变体对齐选择语义相关表示进行图像与原始特征匹配。

研究结果: 在三个流行基准测试中，EVA在封闭和开放世界设置下均显著优于其他最先进方法。

研究结论: EVA通过专家混合和语义变体对齐有效提升了组合零样本学习的性能，验证了其创新性。

中文摘要: 组合零样本学习（CZSL）研究基于已学习原始概念识别未知状态-对象对的组合泛化能力。现有CZSL方法通常通过简单的组合原型映射获取原始特征，这对于可划分为不同语义子集的个体集并不理想。此外，全对一跨模态原始特征匹配忽略了相同状态或对象内的组合差异，限制了图像与组合的精细对齐。本研究提出EVA，一种基于专家混合的语义变体对齐框架。具体而言，我们引入域专家适应，利用多个专家实现标记感知学习并建模高质量原始表示。为实现准确的组合泛化，进一步提出语义变体对齐，选择语义相关表示进行图像与原始特征匹配。我们的方法在三个流行基准测试中，在封闭和开放世界设置下均显著优于其他最先进CZSL方法，验证了所提见解的有效性。

</details>


### [64] [Segment Anything in Pathology Images with Natural Language](https://arxiv.org/abs/2506.20988)
**中文标题：使用自然语言在病理图像中分割任意目标**

*Zhixuan Chen,Junlin Hou,Liqi Lin,Yihui Wang,Yequan Bie,Xi Wang,Yanning Zhou,Ronald Cheong Kin Chan,Hao Chen*

主要分类: cs.CV

摘要简述: 本文提出PathSegmentor，首个针对病理图像的自然语言提示分割基础模型，并构建了最大的病理分割数据集PathSeg。该模型通过自然语言提示实现语义分割，无需繁琐的空间输入，显著提升了分割精度和泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前病理图像分割方法在临床应用中面临标注数据有限和类别定义狭窄的挑战，限制了其实际应用。为解决这些问题，作者提出了PathSegmentor模型和PathSeg数据集。

研究方法: 作者开发了PathSegmentor，一种基于自然语言提示的分割基础模型，并构建了PathSeg数据集，包含17个公开来源的275k图像-掩码-标签三元组，涵盖160个类别。模型通过文本提示实现分割，无需空间输入。

研究结果: 实验表明，PathSegmentor在整体Dice分数上分别比空间提示和文本提示模型高出0.145和0.429，表现出更高的准确性和泛化能力。此外，其输出通过特征重要性估计和生物标志物发现增强了诊断模型的可解释性。

研究结论: PathSegmentor在病理图像分割中表现出色，为精准肿瘤学中的可解释AI提供了支持，有望推动临床决策的进步。

中文摘要: 病理图像分割在计算病理学中对分析癌症诊断和预后的组织学特征至关重要。然而，当前方法因标注数据有限和类别定义狭窄而在临床应用中面临挑战。为解决这些问题，我们提出了PathSegmentor，首个专为病理图像设计的文本提示分割基础模型，并引入了PathSeg，这是最大且最全面的病理分割数据集，包含来自17个公开来源的275k图像-掩码-标签三元组，涵盖160个类别。PathSegmentor允许用户通过自然语言提示进行语义分割，无需繁琐的空间输入（如点或框）。大量实验表明，PathSegmentor在准确性和泛化能力上优于专用模型，同时在结构上保持紧凑。其整体Dice分数分别比空间提示和文本提示模型高出0.145和0.429，在分割复杂结构和泛化到外部数据集时表现出强鲁棒性。此外，PathSegmentor的输出通过特征重要性估计和影像生物标志物发现增强了诊断模型的可解释性，为病理学家提供了基于证据的临床决策支持。这项工作推动了精准肿瘤学中可解释AI的发展。

</details>


### [65] [TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation](https://arxiv.org/abs/2506.20991)
**中文标题：TSDASeg：一种基于直接对齐的两阶段交互式点云分割模型**

*Chade Li,Pengju Zhang,Yihong Wu*

主要分类: cs.CV

摘要简述: TSDASeg是一种两阶段模型，通过直接跨模态对齐和内存模块提升交互式点云分割性能，解决了现有方法在点级任务中因缺乏3D-文本直接对齐而表现不佳的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在点云分割任务中因缺乏3D与文本的直接对齐，导致局部3D特征与文本上下文难以关联，限制了性能。本文旨在解决这一问题。

研究方法: 提出TSDASeg模型，包含直接跨模态对齐模块和内存模块。对齐模块显式连接3D点云与文本/2D图像数据；内存模块通过多个专用内存库存储特征及其映射，并利用自注意力和跨注意力动态更新场景特征。

研究结果: 在多个3D指令、参考和语义分割数据集上的实验表明，该方法达到了最先进的性能。

研究结论: TSDASeg通过直接跨模态对齐和动态内存模块，显著提升了交互式点云分割的性能，适用于多样化场景。

中文摘要: 3D视觉语言模型（VLMs）的快速发展推动了交互式点云处理任务的广泛关注，尤其是在实际应用中。然而，现有方法由于缺乏直接的3D-文本对齐，在点级任务（如分割）中表现不佳，限制了局部3D特征与文本上下文的关联能力。为解决这一问题，我们提出了TSDASeg，一种结合直接跨模态对齐模块和内存模块的两阶段交互式点云分割模型。我们引入直接跨模态对齐模块，显式建立3D点云与文本/2D图像数据的对齐关系。在内存模块中，通过多个专用内存库分别存储文本特征、视觉特征及其跨模态对应映射，并利用自注意力和跨注意力机制动态更新场景特征，有效解决了不同场景下交互式分割结果的不一致性问题。在多个3D指令、参考和语义分割数据集上的实验表明，所提方法达到了最先进的性能。

</details>


### [66] [Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance](https://arxiv.org/abs/2506.20995)
**中文标题：基于负音频引导的分步视频到音频合成方法**

*Akio Hayakawa,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的分步视频到音频合成方法，通过负音频引导逐步生成与视频中特定声音事件对应的独立音轨，模仿传统Foley工作流程，显著提升了合成音频的质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统视频到音频合成方法难以全面捕捉视频中的所有声音事件，且缺乏对多音轨合成的支持。本文旨在通过分步生成和负音频引导技术，解决这一问题，实现更高质量的音频合成。

研究方法: 该方法将视频到音频合成任务分解为多个步骤，每个步骤生成一个特定声音事件的音轨，并利用负音频引导技术优化生成过程。通过预训练模型和通用数据集，避免了专用配对数据的需求。

研究结果: 实验结果表明，该方法能够为单一输入视频生成多个语义不同的音轨，合成的复合音频质量显著优于现有基线方法。

研究结论: 本文提出的分步视频到音频合成方法通过负音频引导技术，有效提升了多音轨合成的质量和灵活性，为视频音频合成领域提供了新的解决方案。

中文摘要: 我们提出了一种新颖的分步视频到音频生成方法，逐步生成与视频中特定声音事件对应的独立音轨。我们的方法模仿了传统Foley工作流程，旨在全面捕捉视频中所有声音事件。每个生成步骤被表述为一个基于目标文本提示和先前生成音轨的引导视频到音频合成任务，这一设计灵感来源于先前组合生成框架中的概念否定思想。为了实现这种引导生成，我们引入了一个利用预训练视频到音频模型的训练框架，无需专用配对数据集，可在更易获取的数据上进行训练。实验结果表明，我们的方法能够为单一输入视频生成多个语义不同的音轨，合成的复合音频质量优于现有基线方法。

</details>


### [67] [DBMovi-GS: Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting](https://arxiv.org/abs/2506.20998)
**中文标题：DBMovi-GS：基于稀疏控制高斯分布的模糊单目视频动态视角合成**

*Yeon-Ji Song,Jaein Kim,Byung-Ju Kim,Byoung-Tak Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DBMovi-GS的方法，用于从模糊的单目视频中合成动态场景的新视角。该方法通过稀疏控制的高斯分布技术，恢复模糊视频的清晰度并重建动态场景的3D几何结构，显著提升了动态模糊场景下的新视角合成效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有新视角合成方法依赖高分辨率图像或静态几何假设，难以处理动态模糊场景。本文旨在解决从模糊单目视频中合成动态场景的挑战，提升真实世界环境中的合成鲁棒性和视觉保真度。

研究方法: DBMovi-GS通过生成密集的3D高斯分布，从模糊视频中恢复清晰图像，并利用稀疏控制技术重建动态场景的3D几何结构。该方法结合运动感知技术，有效处理动态模糊场景。

研究结果: 实验表明，DBMovi-GS在动态模糊场景下的新视角合成任务中表现优异，显著提升了视觉保真度，并为模糊单目视频输入设定了新的性能基准。

研究结论: DBMovi-GS成功解决了从模糊单目视频中合成动态场景的难题，为动态模糊场景的新视角合成提供了高效且鲁棒的解决方案。

中文摘要: 新视角合成任务旨在从未见过的视角生成场景；然而，从模糊的单目视频中合成动态场景仍是一个尚未有效解决的挑战。现有的新视角合成方法通常依赖于高分辨率图像或对静态几何和刚性场景先验的强假设，因此在具有动态物体和相机运动的真实环境中缺乏鲁棒性，导致不稳定性和视觉保真度下降。为解决这一问题，我们提出了基于稀疏控制高斯分布的模糊单目视频动态视角合成方法（DBMovi-GS）。该方法通过生成密集的3D高斯分布，从模糊视频中恢复清晰图像，并重建受动态运动变化影响的场景的详细3D几何结构。我们的模型在动态模糊场景下的新视角合成任务中表现出色，并为模糊单目视频输入设定了新的性能基准。

</details>


### [68] [Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology](https://arxiv.org/abs/2506.21001)
**中文标题：风格对齐的图像合成用于细胞病理学中异常细胞的鲁棒检测**

*Qiuyi Qi,Xin Li,Ming Kong,Zikang Xu,Bingdi Chen,Qiang Zhu,S Kevin Zhou*

主要分类: cs.CV

摘要简述: 本文提出一种风格对齐的图像合成方法（SAIC），用于增强细胞病理学中异常细胞检测的鲁棒性，通过合成高质量且风格一致的病理图像，提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 细胞病理学中异常细胞检测面临高质量标注稀缺、数据分布长尾及染色风格不一致等挑战，限制了模型的鲁棒性和性能。

研究方法: SAIC方法首先基于属性指导从异常细胞库中选择候选样本，随后通过高频特征重建实现异常细胞与病理背景的风格对齐和高保真合成，最后利用大视觉语言模型筛选高质量合成图像。

研究结果: 实验表明，SAIC合成的图像显著提升了尾类别和不同风格下异常细胞检测的性能和鲁棒性，综合质量评估验证了其在临床应用中的泛化性和实用性。

研究结论: SAIC方法通过风格对齐的图像合成有效解决了细胞病理学检测中的关键挑战，为临床实践提供了可靠的技术支持。

中文摘要: 在细胞病理学中，高质量标注的缺乏、长尾数据分布以及染色风格不一致等问题，对训练神经网络以鲁棒检测异常细胞提出了重大挑战。本文提出了一种风格对齐的图像合成（SAIC）方法，通过合成高保真且风格一致的病理图像，提升检测模型的有效性和鲁棒性。SAIC无需额外训练，首先基于属性指导从异常细胞库中选择合适候选样本，随后利用高频特征重建实现异常细胞与病理背景的风格对齐和高保真合成，最后引入大视觉语言模型筛选高质量合成图像。实验结果表明，结合SAIC合成的图像显著提升了尾类别和不同风格下异常细胞检测的性能和鲁棒性，从而改善了整体检测性能。综合质量评估进一步证实了SAIC在临床应用场景中的泛化性和实用性。代码将在https://github.com/Joey-Qi/SAIC发布。

</details>


### [69] [Inverse Scene Text Removal](https://arxiv.org/abs/2506.21002)
**中文标题：逆向场景文本去除**

*Takumi Yoshimatsu,Shumpei Takezaki,Seiichi Uchida*

主要分类: cs.CV

摘要简述: 本文提出逆向场景文本去除（ISTR），旨在检测图像是否经过文本去除处理并定位被移除的文本区域，实验证明任务可行且准确率高，有助于防止滥用并改进文本去除技术。


<details>
  <summary>详细信息</summary>
研究动机: 场景文本去除（STR）技术虽能有效移除图像中的敏感或不需要的文本，但其滥用风险增加。本文研究逆向STR（ISTR），以检测和定位被移除的文本，防止技术滥用并提升STR的可靠性。

研究方法: ISTR通过分析经过STR处理的图像，专注于二分类任务（检测图像是否经过STR处理）和定位被移除的文本区域。此外，还尝试训练文本识别器以恢复被移除的文本内容。

研究结果: 实验表明，ISTR在检测和定位任务中均能实现高准确率，证明了其可行性。同时，恢复被移除文本的任务展示了其挑战性。

研究结论: ISTR为检测和防止STR技术的滥用提供了有效工具，同时为改进STR技术提供了新思路。恢复被移除文本的任务仍需进一步研究。

中文摘要: 场景文本去除（STR）旨在从图像中移除文本元素，最初用于移除自然场景图像中的隐私敏感或不需要的文本，现也应用于排版图像。STR通常检测文本区域并进行修复。尽管STR通过神经网络和合成数据取得了进展，但其滥用风险增加。本文研究逆向STR（ISTR），分析经过STR处理的图像，专注于二分类（检测图像是否经过STR处理）和定位被移除的文本区域。实验证明这些任务可实现高准确率，有助于检测潜在滥用并改进STR。我们还尝试通过训练文本识别器恢复被移除的文本内容，以了解其难度。

</details>


### [70] [VisionGuard: Synergistic Framework for Helmet Violation Detection](https://arxiv.org/abs/2506.21005)
**中文标题：VisionGuard：头盔违规检测的协同框架**

*Lam-Huy Nguyen,Thinh-Phuc Nguyen,Thanh-Hai Nguyen,Gia-Huy Dinh,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: VisionGuard是一个多阶段协同框架，通过自适应标签和上下文扩展模块，提升头盔违规检测的准确性和一致性，解决数据不平衡和环境变化问题。


<details>
  <summary>详细信息</summary>
研究动机: 摩托车头盔佩戴规范的自动检测面临环境多变、摄像头角度不一致和数据标注不一致等挑战，影响检测的可靠性和分类一致性。

研究方法: VisionGuard结合自适应标签模块（基于跟踪算法修正分类）和上下文扩展模块（生成虚拟边界框解决数据不平衡），提升检测性能。

研究结果: 实验表明，VisionGuard比基线检测器的mAP提高了3.1%，有效提升了头盔违规检测的准确性。

研究结论: VisionGuard在交通监控系统中具有实际应用潜力，能有效提升安全性和法规遵从性。

中文摘要: 强制摩托车骑手佩戴头盔对提升道路安全和交通管理系统的有效性至关重要。然而，由于环境变化、摄像头角度和数据不一致，头盔违规的自动检测面临显著挑战。这些因素阻碍了摩托车和骑手的可靠检测，并破坏了分类的一致性。为解决这些问题，我们提出了VisionGuard，一个协同多阶段框架，旨在克服逐帧检测器的局限性，尤其是在类别不平衡和标注不一致的场景中。VisionGuard整合了两个关键组件：自适应标签模块和上下文扩展模块。自适应标签模块是一种基于跟踪的优化技术，通过利用跟踪算法为帧间分配持久标签并修正错误分类，提升分类一致性。上下文扩展模块通过生成带有适当置信度得分的虚拟边界框，提高对少数类别的召回率，有效缓解数据不平衡的影响。实验结果表明，VisionGuard相比基线检测器整体mAP提高了3.1%，证明了其在交通监控系统中的有效性和实际部署潜力，最终促进安全和法规遵从。

</details>


### [71] [Detection of Breast Cancer Lumpectomy Margin with SAM-incorporated Forward-Forward Contrastive Learning](https://arxiv.org/abs/2506.21006)
**中文标题：基于SAM结合前向-前向对比学习的乳腺癌保乳手术边缘检测**

*Tyler Ward,Xiaoqin Wang,Braxton McFarland,Md Atik Ahamed,Sahar Nozad,Talal Arshad,Hafsa Nebbache,Jin Chen,Abdullah Imran*

主要分类: cs.CV

摘要简述: 本文提出了一种结合Segment Anything Model (SAM)和Forward-Forward Contrastive Learning (FFCL)的深度学习框架，用于提高乳腺癌保乳手术中标本边缘的检测准确性和速度，显著降低了再切除率。


<details>
  <summary>详细信息</summary>
研究动机: 目前用于评估乳腺癌保乳手术中标本边缘状态的2D标本放射成像（SR）方法准确性有限，导致近四分之一的患者需要二次手术。为提高边缘检测的准确性和效率，减少再切除率，作者提出了这一新方法。

研究方法: 作者首先标注了SR图像中的恶性肿瘤区域、非恶性组织和病理确认的边缘区域，然后使用FFCL预训练ResNet-18主干网络进行边缘状态分类。接着，通过重建粗二值掩码提示SAM进行精细化的肿瘤边缘分割。

研究结果: 该方法在边缘分类中实现了0.8455的AUC值，边缘分割的Dice相似性比基线模型提高了27.4%，同时将每张图像的推理时间缩短至47毫秒。

研究结论: FFCL-SAM显著提高了术中边缘评估的速度和准确性，有望降低乳腺癌治疗中的再切除率并改善手术效果。

中文摘要: 在乳腺癌保乳手术中，完全切除肿瘤并确保标本边缘阴性对降低复发率至关重要。然而，目前用于术中评估标本边缘状态的2D标本放射成像（SR）方法准确性有限，导致近四分之一的患者需要二次手术。为解决这一问题，我们提出了一种结合Segment Anything Model (SAM)和前向-前向对比学习（FFCL）的新型深度学习框架。FFCL是一种预训练策略，利用局部和全局对比学习对SR图像进行块级分类。我们在标注了已知恶性肿瘤区域、非恶性组织和病理确认边缘的SR图像后，使用FFCL预训练ResNet-18主干网络进行边缘状态分类，并通过重建粗二值掩码提示SAM进行精细化的肿瘤边缘分割。我们的方法在边缘分类中实现了0.8455的AUC值，边缘分割的Dice相似性比基线模型提高了27.4%，同时将每张图像的推理时间缩短至47毫秒。这些结果表明，FFCL-SAM显著提高了术中边缘评估的速度和准确性，有望降低再切除率并改善乳腺癌治疗的手术效果。代码发布于https://github.com/tbwa233/FFCL-SAM/。

</details>


### [72] [The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion](https://arxiv.org/abs/2506.21008)
**中文标题：老化多元宇宙：通过无训练扩散生成条件感知的面部老化树**

*Bang Gong,Luchao Qi,Jiaye Wu,Zhicheng Fu,Chunbo Song,David W. Jacobs,John Nicholson,Roni Sengupta*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“Aging Multiverse”的框架，通过无训练扩散方法生成多样化的面部老化轨迹，结合环境、健康等外部条件，形成老化树，实现身份保留、年龄准确性和条件控制。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常将面部老化建模为单一确定性路径，无法反映多样化的未来。本文旨在通过条件控制生成多种可能的老化轨迹，以更真实地模拟不同外部因素对老化的影响。

研究方法: 采用无训练扩散方法，结合注意力混合技术调节编辑强度，并提出模拟老化正则化策略以稳定编辑效果，从而实现身份保留、年龄准确性和条件控制的平衡。

研究结果: 实验和用户研究表明，该方法在身份保留、老化真实性和条件对齐方面表现优异，优于现有编辑和老化模型。

研究结论: 通过将老化转化为多维、可控且可解释的过程，该方法为数字叙事、健康教育和个性化可视化提供了新的可能性。

中文摘要: 我们提出了“老化多元宇宙”框架，用于从单张图像生成多种可能的面部老化轨迹，每种轨迹受环境、健康和生活方式等外部因素影响。与以往将老化建模为单一确定性路径的方法不同，我们的方法生成一棵老化树，可视化多样化的未来。为此，我们提出了一种无训练扩散方法，平衡身份保留、年龄准确性和条件控制。关键贡献包括通过注意力混合调节编辑强度，以及模拟老化正则化策略以稳定编辑效果。大量实验和用户研究表明，该方法在身份保留、老化真实性和条件对齐方面表现优异，超越了现有编辑和老化模型，后者往往无法满足所有编辑标准。通过将老化转化为多维、可控且可解释的过程，我们的方法为数字叙事、健康教育和个性化可视化开辟了新的创意和实践途径。

</details>


### [73] [User-in-the-Loop View Sampling with Error Peaking Visualization](https://arxiv.org/abs/2506.21009)
**中文标题：基于误差峰值可视化的用户参与式视图采样**

*Ayaka Yasunaga,Hideo Saito,Shohei Mori*

主要分类: cs.CV

摘要简述: 本文提出了一种基于增强现实（AR）的新视图合成方法，通过可视化误差峰值引导用户采样，减少用户认知负担并扩展场景探索范围。


<details>
  <summary>详细信息</summary>
研究动机: 现有AR方法依赖3D标注引导用户采样，任务繁重且场景探索受限。本文旨在解放用户，通过误差可视化优化采样过程。

研究方法: 利用局部重建的光场和误差峰值可视化技术，引导用户插入新视图，减少采样需求并提升合成效果。

研究结果: 实验表明，该方法侵入性低，减少用户失望感，且能以更少视图样本获得满意结果，适用于大场景辐射场重建。

研究结论: 本文方法通过误差可视化优化用户采样，显著提升AR视图合成的效率和用户体验，适用于更广泛场景。

中文摘要: 增强现实（AR）为缺失视图样本的新视图合成提供了可视化方法。现有方法通过3D标注引导用户对齐AR显示拍摄图像，但任务繁重且场景探索受限。为解放用户并扩展场景，我们提出利用局部重建光场和误差可视化技术，引导用户插入新视图。结果显示，误差峰值可视化侵入性低，减少用户失望感，且能以更少视图样本获得满意结果。此外，该方法可支持大场景辐射场重建，如3D高斯溅射。

</details>


### [74] [Bridging Video Quality Scoring and Justification via Large Multimodal Models](https://arxiv.org/abs/2506.21011)
**中文标题：基于大型多模态模型的视频质量评分与解释桥接**

*Qizhi Xie,Kun Yuan,Yunpeng Qu,Jiachao Gong,Mingda Wu,Ming Sun,Chao Zhou,Jihong Zhu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于评分指令生成（SIG）的自动化流程，通过视频大型多模态模型（LMMs）提升视频质量评估（VQA）的评分和解释能力。SIG生成高质量指令数据Score2Instruct（S2I），并通过渐进式调优策略提升模型性能。实验表明，该方法显著提升了视频LMMs的质量评分和解释能力。


<details>
  <summary>详细信息</summary>
研究动机: 传统的视频质量评估（VQA）方法仅生成数值评分，无法全面描述视频质量的复杂维度，限制了其应用。通过利用大型多模态模型（LMMs）的语言输出能力，结合指令调优，可以解决这一问题。然而，现有研究主要集中在图像领域，且依赖人工标注和专有系统，数据扩展性和有效性受限。

研究方法: 本文提出Score-based Instruction Generation（SIG）流程，自动化生成视频质量指令数据。SIG首先对未标注视频的多个质量维度评分，并将评分映射为文本定义的等级；然后通过层次化思维链（CoT）建模特定维度与整体质量的关系。生成的Score2Instruct（S2I）数据集包含32万条指令-响应对，支持指令调优。此外，采用渐进式调优策略提升视频LMMs的评分和解释能力。

研究结果: 实验结果表明，基于SIG生成的S2I数据集和渐进式调优策略，视频LMMs在质量评分和解释能力上均有显著提升。S2I-Bench基准测试进一步验证了模型在开放性问题上的表现。

研究结论: 本文提出的SIG流程和S2I数据集为视频质量评估提供了高效、可扩展的解决方案，显著提升了视频LMMs的评分和解释能力。该方法为未来视频质量评估研究奠定了基础。

中文摘要: 传统的视频质量评估（VQA）方法通过数值评分判断视频的视觉保真度和清晰度，但评分无法描述视频质量的复杂维度，限制了其应用。通过利用大型多模态模型（LMMs）的语言输出能力，结合指令调优，可以解决这一问题。然而，现有研究主要集中在图像领域，且依赖人工标注和专有系统，数据扩展性和有效性受限。为此，我们提出了基于评分的指令生成（SIG）流程。SIG首先对未标注视频的多个质量维度评分，并将评分映射为文本定义的等级；然后通过层次化思维链（CoT）建模特定维度与整体质量的关系。该自动化流程消除了对专家编写质量描述和专有系统的依赖，确保数据扩展性和生成效率。由此生成的Score2Instruct（S2I）数据集包含超过32万条多样化的指令-响应对，为指令调优奠定了基础。此外，为同时提升视频LMMs的评分和解释能力，我们设计了渐进式调优策略以充分发挥S2I的潜力。基于SIG，我们还构建了S2I-Bench基准测试，包含400个开放性问题，以更好地评估视频LMMs的质量解释能力。在S2I-Bench和现有基准测试上的实验结果表明，我们的方法显著提升了多种视频LMMs的质量评分和解释能力。

</details>


### [75] [FedSC: Federated Learning with Semantic-Aware Collaboration](https://arxiv.org/abs/2506.21012)
**中文标题：FedSC：基于语义感知协作的联邦学习**

*Huan Wang,Haoran Li,Huaming Chen,Jun Yan,Jiahua Shi,Jun Shen*

主要分类: cs.CV

摘要简述: 本文提出FedSC方法，通过语义感知协作解决联邦学习中的数据异构问题，利用关系原型和一致性原型捕获客户端特定和类别相关知识，实验证明其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习中的数据异构问题（如客户端标签偏好偏差）是主要挑战，现有方法常忽略客户端内部语义信息。本文旨在探索利用客户端内部语义知识解决数据异构问题。

研究方法: FedSC通过构建语义级的关系原型和一致性原型，结合对比学习策略和差异聚合方法，优化本地模型，并提供理论收敛保证。

研究结果: 实验表明，FedSC在多种挑战性场景下表现优异，关键组件高效。

研究结论: FedSC通过语义感知协作有效解决了数据异构问题，为联邦学习提供了新思路。

中文摘要: 联邦学习（FL）旨在保护隐私的前提下，通过客户端协作训练模型。然而，数据异构问题（如客户端标签偏好偏差）是主要挑战。现有方法多从局部或全局角度解决，常忽略客户端内部语义信息。为探索利用客户端内部语义知识解决数据异构问题，本文提出基于语义感知协作的联邦学习（FedSC），通过构建关系原型和一致性原型，捕获客户端特定和类别相关知识。FedSC的核心思想是语义级的原型协作，提供类别底层知识和稳定收敛信号。一方面，FedSC采用对比学习策略，使实例级嵌入靠近同语义关系原型并远离不同类别；另一方面，通过差异聚合设计一致性原型，作为正则化约束本地模型优化区域。此外，本文提供了FedSC的理论分析以确保收敛性。多种挑战性场景的实验结果验证了FedSC的有效性和关键组件的高效性。

</details>


### [76] [HybridQ: Hybrid Classical-Quantum Generative Adversarial Network for Skin Disease Image Generation](https://arxiv.org/abs/2506.21015)
**中文标题：HybridQ：用于皮肤病图像生成的混合经典-量子生成对抗网络**

*Qingyue Jiao,Kangyu Zheng,Yiyu Shi,Zhiding Liang*

主要分类: cs.CV

摘要简述: 本文提出了一种混合经典-量子生成对抗网络（HybridQ），用于生成高质量的彩色皮肤病图像。该模型通过融合经典与量子潜在空间技术，显著提升了图像生成质量和分类性能，同时减少了参数数量和训练时间。


<details>
  <summary>详细信息</summary>
研究动机: 皮肤病数据集常面临类别不平衡、隐私问题和对象偏差等挑战，传统生成模型需要大量计算资源且训练时间长。量子计算虽具潜力，但现有量子图像生成方法仅能生成低质量灰度图像。本文旨在解决这些问题，提出一种高效的混合经典-量子生成模型。

研究方法: 通过一种新颖的经典-量子潜在空间融合技术，提出混合经典-量子生成对抗网络（HybridQ），能够生成彩色医学图像。模型结合了经典和量子计算的优势，显著提升了生成质量和效率。

研究结果: HybridQ在图像生成质量和分类性能提升上优于传统深度卷积GAN和现有混合经典-量子GAN，且参数数量减少25倍，训练轮次减少10倍。在真实IBM量子机器上表现出稳健性能。

研究结论: HybridQ展示了量子图像生成的潜力，随着量子硬件的发展，该方法有望成为高效的数据增强工具。

中文摘要: 机器学习辅助诊断在皮肤病检测中日益受到关注，但训练有效模型需要大量高质量数据。皮肤病数据集常面临类别不平衡、隐私问题和对象偏差等问题，使得数据增强变得至关重要。传统生成模型虽广泛应用，但需要大量计算资源和长时间训练。量子计算提供了一种有前景的替代方案，但现有量子图像生成方法仅能生成低质量灰度图像。通过一种新颖的经典-量子潜在空间融合技术，本文克服了这一限制，提出了首个能够生成彩色医学图像的混合经典-量子生成对抗网络（GAN）。我们的模型在图像生成质量和分类性能提升上均优于传统深度卷积GAN和现有混合经典-量子GAN，且参数数量减少25倍，训练轮次减少10倍。此外，其性能提升与最先进的经典生成模型相当。这些结果表明，随着量子硬件的发展，量子图像生成具有广阔前景。最后，我们在真实IBM量子机器上验证了模型在硬件噪声下的稳健性能。

</details>


### [77] [Multimodal Prompt Alignment for Facial Expression Recognition](https://arxiv.org/abs/2506.21017)
**中文标题：多模态提示对齐用于面部表情识别**

*Fuyan Ma,Yiran He,Bin Sun,Shutao Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MPA-FER的多模态提示对齐框架，用于提升面部表情识别（FER）任务中视觉语言模型（如CLIP）的细粒度语义关系捕捉能力。通过结合多粒度硬提示生成策略和原型引导的视觉特征对齐，该方法显著提高了识别精度并保持了预训练模型的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于视觉语言模型（VLM）的面部表情识别方法难以捕捉细粒度的文本-视觉关系，导致对细微表情差异的区分能力不足。本文旨在通过多模态提示对齐框架解决这一问题。

研究方法: 1. 使用大型语言模型（如ChatGPT）生成多粒度硬提示，为每种表情提供详细描述。2. 通过最小化软提示与硬提示之间的特征差异，将外部知识注入软提示。3. 采用原型引导的视觉特征对齐，确保冻结图像编码器生成的提示视觉特征与类别原型紧密对齐。4. 提出跨模态全局-局部对齐模块，专注于表情相关的面部特征。

研究结果: 在三个FER基准数据集上的实验表明，MPA-FER框架优于现有最先进方法，同时保留了预训练模型的优势并降低了计算成本。

研究结论: MPA-FER框架通过多模态提示对齐和细粒度语义指导，显著提升了面部表情识别的精度和可解释性，同时保持了模型的泛化能力和计算效率。

中文摘要: 提示学习已被广泛用于高效适配视觉语言模型（如CLIP）以完成各种下游任务。尽管取得了成功，当前基于VLM的面部表情识别（FER）方法仍难以捕捉细粒度的文本-视觉关系，而这对于区分面部表情的细微差异至关重要。为解决这一问题，我们提出了一种名为MPA-FER的多模态提示对齐框架，为提示视觉特征的学习过程提供细粒度语义指导，从而生成更精确且可解释的表征。具体而言，我们引入了一种多粒度硬提示生成策略，利用大型语言模型（如ChatGPT）为每种表情生成详细描述。通过最小化软提示与硬提示之间的特征差异，将LLM的外部知识注入软提示中。为保留预训练CLIP模型的泛化能力，我们的方法结合了原型引导的视觉特征对齐，确保冻结图像编码器生成的提示视觉特征与类别原型紧密对齐。此外，我们提出了一个跨模态全局-局部对齐模块，专注于表情相关的面部特征，进一步改善文本与视觉特征的对齐。大量实验表明，我们的框架在三个FER基准数据集上优于现有最先进方法，同时保留了预训练模型的优势并降低了计算成本。

</details>


### [78] [LASFNet: A Lightweight Attention-Guided Self-Modulation Feature Fusion Network for Multimodal Object Detection](https://arxiv.org/abs/2506.21018)
**中文标题：LASFNet：一种轻量级注意力引导自调制特征融合网络用于多模态目标检测**

*Lei Hao,Lina Xu,Chang Liu,Yanni Dong*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级的注意力引导自调制特征融合网络（LASFNet），通过单一特征级融合单元简化训练过程，并引入注意力引导自调制特征融合模块（ASFF）和轻量级特征注意力转换模块（FATM），显著降低了计算成本和参数数量，同时提升了检测精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态目标检测方法通常通过堆叠多个特征级融合单元来整合模态特定特征，导致计算开销大且训练复杂。本文旨在设计一种更高效的融合检测基线，简化训练过程并提升性能。

研究方法: 1. 提出一种基于单一特征级融合单元的新基线，简化训练过程。2. 设计注意力引导自调制特征融合模块（ASFF），通过全局和局部注意力自适应调整融合特征。3. 在LASFNet的颈部引入轻量级特征注意力转换模块（FATM），增强对融合特征的关注并减少信息损失。

研究结果: 在三个代表性数据集上的实验表明，LASFNet在减少90%参数和85%计算成本的同时，检测精度（mAP）提升了1%-3%，实现了效率与精度的良好平衡。

研究结论: LASFNet通过轻量化的注意力引导和自调制特征融合，显著提升了多模态目标检测的效率与精度，为相关领域提供了新的解决方案。

中文摘要: 通过特征级融合实现有效的深度特征提取对多模态目标检测至关重要。然而，现有研究通常通过堆叠多个特征级融合单元整合模态特定特征，导致计算开销大且训练复杂。为解决这一问题，我们提出了一种新的融合检测基线，仅使用单一特征级融合单元即可实现高性能检测，从而简化训练过程。基于此方法，我们提出了一种轻量级注意力引导自调制特征融合网络（LASFNet），其引入了一种新颖的注意力引导自调制特征融合（ASFF）模块，能够根据来自不同模态的注意力信息自适应调整融合特征在全局和局部层面的响应，从而促进全面且丰富的特征生成。此外，在LASFNet的颈部设计了轻量级特征注意力转换模块（FATM），以增强对融合特征的关注并最小化信息损失。在三个代表性数据集上的大量实验表明，与现有最优方法相比，我们的方法在效率与精度之间取得了良好平衡，参数数量和计算成本分别减少了90%和85%，同时检测精度（mAP）提升了1%-3%。代码将在https://github.com/leileilei2000/LASFNet开源。

</details>


### [79] [Instella-T2I: Pushing the Limits of 1D Discrete Latent Space Image Generation](https://arxiv.org/abs/2506.21022)
**中文标题：Instella-T2I：突破1D离散潜在空间图像生成的极限**

*Ze Wang,Hao Chen,Benran Hu,Jiang Liu,Ximeng Sun,Jialian Wu,Yusheng Su,Xiaodong Yu,Emad Barsoum,Zicheng Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Instella-T2I的新方法，通过引入1D二进制图像潜在空间，显著减少了高分辨率图像生成所需的令牌数量，同时保持了细节和效率。该方法在文本到图像生成任务中表现出色，仅需128个离散令牌即可生成1024x1024图像，且训练和推理速度大幅提升。


<details>
  <summary>详细信息</summary>
研究动机: 传统的高分辨率图像生成方法通常需要大量计算资源，尤其是在使用2D网格结构的潜在空间时。为了减少计算需求并提高效率，本文探索了1D潜在空间的潜力，旨在通过更紧凑的表示方法实现高性能的图像生成。

研究方法: 本文提出了一种1D二进制图像潜在空间表示方法，将图像编码为二进制向量序列，而非传统的one-hot编码。这种方法不仅减少了令牌数量（仅需128个令牌），还保持了高分辨率细节。结合简单的模型架构，显著提升了训练和推理速度。

研究结果: 实验表明，Instella-T2I在文本到图像生成任务中表现优异，仅需128个离散令牌即可生成1024x1024图像，令牌数量比标准VQ-VAEs减少了32倍。此外，该方法在单GPU节点上实现了4096的全局批量大小，训练时间缩短至200 GPU天。

研究结论: Instella-T2I通过1D二进制潜在空间和高效模型架构，为高分辨率图像生成提供了一种可扩展且高效的解决方案，无需依赖私有数据或后训练优化，即可达到现代图像生成模型的性能水平。

中文摘要: 图像标记化在降低高分辨率图像建模的计算需求方面起着关键作用，显著提高了图像和多模态理解与生成的效率。近年来，1D潜在空间的进展通过消除对2D网格结构的需求，进一步减少了所需的令牌数量。本文通过引入1D二进制图像潜在空间，进一步推进了紧凑的离散图像表示。通过将每张图像表示为二进制向量序列，而非传统的one-hot编码令牌，我们的方法在保持1D潜在空间紧凑性的同时，保留了高分辨率细节。据我们所知，我们的文本到图像模型是首个仅需128个离散令牌即可生成1024x1024图像的模型，在扩散和自回归生成中均表现出色，令牌数量比标准VQ-VAEs减少了32倍。所提出的1D二进制潜在空间结合简单模型架构，显著提升了训练和推理速度。我们的文本到图像模型在单GPU节点（配备8个AMD MI300X GPU）上实现了4096的全局批量大小，训练时间缩短至200 GPU天。与现有图像生成模型相比，我们的模型无需依赖私有数据或后训练优化，即可达到竞争性能，为传统标记化方法提供了一种可扩展且高效的替代方案。

</details>


### [80] [DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation](https://arxiv.org/abs/2506.21034)
**中文标题：DidSee：基于扩散的深度补全方法，用于材料无关的机器人感知与操作**

*Wenzhou Lyu,Jialing Lin,Wenqi Ren,Ruihao Xia,Feng Qian,Yang Tang*

主要分类: cs.CV

摘要简述: 论文提出DidSee，一种基于扩散模型的深度补全框架，用于解决非朗伯物体深度图噪声和不完整的问题。通过改进噪声调度器、单步训练和语义增强器，显著提升了深度补全性能，并在多个基准测试中达到最优。


<details>
  <summary>详细信息</summary>
研究动机: 商用RGB-D相机在非朗伯物体上常产生噪声和不完整的深度图，传统深度补全方法因训练数据有限而泛化能力不足。扩散模型虽能利用视觉先验，但存在训练-推理偏差和非朗伯区域特征缺失的问题。

研究方法: 1. 引入重新缩放的噪声调度器，消除信号泄漏偏差；2. 设计噪声无关的单步训练方法，减少误差累积；3. 结合语义增强器，联合完成深度补全和语义分割。

研究结果: DidSee在多个基准测试中表现最优，展示了强大的现实泛化能力，并有效提升了类别级姿态估计和机器人抓取等下游任务。

研究结论: DidSee通过改进扩散框架和引入语义增强，显著提升了非朗伯物体的深度补全性能，为机器人感知和操作提供了可靠支持。

中文摘要: 商用RGB-D相机在非朗伯物体上常产生噪声和不完整的深度图。传统深度补全方法因训练数据有限而泛化能力不足。近期研究利用预训练的文本到图像扩散模型的视觉先验来增强密集预测任务的泛化能力。然而，我们发现扩散框架中训练-推理不匹配导致的偏差严重影响了深度补全性能。此外，非朗伯区域缺乏明显的视觉特征也阻碍了精确预测。为解决这些问题，我们提出了DidSee，一种基于扩散的非朗伯物体深度补全框架。首先，我们引入重新缩放的噪声调度器，强制零终端信噪比以消除信号泄漏偏差；其次，设计了噪声无关的单步训练方法，减少曝光偏差导致的误差累积，并通过任务特定损失优化模型；最后，结合语义增强器，实现联合深度补全和语义分割，区分物体与背景，生成精确的细粒度深度图。DidSee在多个基准测试中表现最优，展示了强大的现实泛化能力，并有效提升了类别级姿态估计和机器人抓取等下游任务。项目页面：https://wenzhoulyu.github.io/DidSee/

</details>


### [81] [Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability](https://arxiv.org/abs/2506.21042)
**中文标题：利用扩散模型提升领域泛化与自适应检测：适应性、泛化性与可迁移性**

*Boyong He,Yuxiang Ji,Zhuoyue Tan,Liaoni Wu*

主要分类: cs.CV

摘要简述: 本文提出一种利用扩散模型提升领域泛化（DG）和领域适应（DA）检测性能的方法，通过单步扩散提取特征、构建对象中心辅助分支及一致性损失，显著减少推理时间并提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有检测器因训练与测试数据的领域差异导致性能下降，而扩散模型在DG和DA任务中的应用尚未充分发挥潜力且推理成本高。

研究方法: 1. 从单步扩散过程中提取中间特征以减少75%推理时间；2. 构建对象中心辅助分支提取鲁棒特征；3. 通过一致性损失对齐辅助与普通分支；4. 在统一框架下通过特征和对象级对齐提升跨域检测性能。

研究结果: 在3个DA和5个DG基准测试中取得竞争性结果，COCO泛化基准测试中表现优异，尤其在大领域差异和低数据场景下效率显著。

研究结论: 扩散模型在领域泛化和自适应检测任务中具有显著优势，为跨领域视觉感知任务提供了新思路。

中文摘要: 检测器常因训练与测试数据的领域差异导致性能下降。现有方法尝试将扩散模型应用于领域泛化（DG）和适应（DA）任务，但仍面临高推理成本且未充分利用扩散模型潜力。为此，我们提出从单步扩散过程中提取中间特征，改进特征收集与融合以减少75%推理时间，同时提升源领域性能（即适应性）。此外，通过应用带类别提示的框掩码图像构建对象中心辅助分支，提取聚焦对象的鲁棒且领域不变特征，并利用一致性损失对齐辅助与普通分支，平衡适应性与泛化性，防止过拟合并提升目标领域性能（即泛化性）。在统一框架下，标准检测器通过特征级和对象级对齐在源领域（DG）和无标记目标领域（DA）中受扩散检测器指导，从而提升跨域检测性能（即可迁移性）。我们的方法在3个DA和5个DG基准测试中表现优异，COCO泛化基准测试中在大领域差异和低数据场景下效率显著。结果表明扩散模型在领域泛化与自适应检测任务中的优越性，为跨领域视觉感知任务提供了重要启示。代码发布于\href{https://github.com/heboyong/Fitness-Generalization-Transferability}{Fitness-Generalization-Transferability}。

</details>


### [82] [Improving Diffusion-Based Image Editing Faithfulness via Guidance and Scheduling](https://arxiv.org/abs/2506.21045)
**中文标题：通过指导和调度提升基于扩散的图像编辑忠实度**

*Hansam Cho,Seoung Bum Kim*

主要分类: cs.CV

摘要简述: 本文提出了一种名为FGS（Faithfulness Guidance and Scheduling）的方法，通过引入忠实度指导和调度策略，在保持图像编辑能力的同时显著提升编辑的忠实度。


<details>
  <summary>详细信息</summary>
研究动机: 文本引导的扩散模型在高质量图像合成和动态编辑中表现出色，但编辑能力与忠实度之间存在固有矛盾。本文旨在解决这一矛盾，提出一种方法以最小化对编辑能力的影响，同时显著提升忠实度。

研究方法: FGS方法结合了忠实度指导，以强化输入图像信息的保留，并引入调度策略解决编辑能力与忠实度之间的错位问题。

研究结果: 实验结果表明，FGS在保持编辑能力的同时，显著提升了忠实度，且兼容多种编辑方法，适用于多样化任务。

研究结论: FGS通过忠实度指导和调度策略，有效平衡了编辑能力与忠实度，为高质量图像编辑提供了可靠解决方案。

中文摘要: 文本引导的扩散模型已成为高质量图像合成的关键工具，支持动态图像编辑。在图像编辑中，编辑能力（决定修改范围）和忠实度（反映未修改元素的保留程度）是两个关键方面。然而，由于编辑能力与忠实度之间的固有矛盾，实现最优结果具有挑战性。为此，我们提出了忠实度指导与调度（FGS），以最小化对编辑能力的影响，显著提升忠实度。FGS通过忠实度指导强化输入图像信息的保留，并引入调度策略解决编辑能力与忠实度之间的错位问题。实验结果表明，FGS在保持编辑能力的同时实现了更高的忠实度。此外，其与多种编辑方法的兼容性使其能够适用于多样化任务，实现精确、高质量的图像编辑。

</details>


### [83] [Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features](https://arxiv.org/abs/2506.21046)
**中文标题：利用自监督视觉Transformer特征提升生成对抗迁移性**

*Shangbo Wu,Yu-an Tan,Ruinan Ma,Wencong Ma,Dehua Zhu,Yuanzhang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种基于自监督视觉Transformer（ViT）特征的生成对抗攻击方法dSVA，通过结合对比学习（CL）和掩码图像建模（MIM）的双重特征，显著提升了对抗样本的黑盒迁移能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有研究主要依赖监督学习的中间特征来生成对抗扰动，但自监督学习与Transformer架构的协同效应尚未充分探索。本文旨在研究自监督ViT特征是否能够进一步提升对抗迁移性。

研究方法: 提出dSVA方法，利用自监督ViT的全局结构特征（来自对比学习）和局部纹理特征（来自掩码图像建模），设计了一个生成对抗样本的框架，并通过联合特征和注意力机制训练生成器。

研究结果: 实验表明，CL和MIM使ViT能够关注不同的特征倾向，联合使用时显著提升了对抗样本的黑盒迁移能力，优于现有方法。

研究结论: 自监督ViT的双重特征能够有效提升对抗样本的迁移性，为黑盒攻击提供了新的思路。

中文摘要: 深度神经网络（DNNs）的能力源于从数据中提取和解释特征。通过利用DNNs的中间特征而非硬标签，我们生成了更具泛化性的对抗扰动，从而提升了黑盒迁移性。以往研究中的这些特征主要来自监督学习。受自监督学习与Transformer架构协同效应的启发，本文探讨了利用自监督视觉Transformer（ViT）特征是否能够提升对抗迁移性。我们提出了dSVA——一种生成式双重自监督ViT特征攻击方法，该方法结合了对比学习（CL）的全局结构特征和掩码图像建模（MIM）的局部纹理特征，这是ViT的自监督学习范式。我们设计了一个新颖的生成训练框架，包含一个生成器用于创建黑盒对抗样本，并通过联合特征和自监督ViT的注意力机制训练生成器。实验结果表明，CL和MIM使ViT能够关注不同的特征倾向，联合使用时显著提升了对抗样本的黑盒迁移能力。通过干扰自监督ViT提取的双重深度特征，我们在多种架构模型上实现了卓越的黑盒迁移性，优于现有方法。代码发布于https://github.com/spencerwooo/dSVA。

</details>


### [84] [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277)
**中文标题：HumanOmniV2：从理解到基于上下文的全模态推理**

*Qize Yang,Shimin Yao,Weixuan Chen,Shenghao Fu,Detao Bai,Jiaxing Zhao,Boyuan Sun,Bowen Yin,Xihan Wei,Jingren Zhou*

主要分类: cs.CV

摘要简述: 本文提出HumanOmniV2模型，通过强化学习提升多模态大语言模型的全局上下文理解和推理能力，解决现有模型中的上下文理解不足和捷径问题，并在多模态基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态推理模型存在全局上下文理解不足和捷径问题，导致模型可能误解多模态信息或忽略关键线索。本文旨在通过强化学习提升模型的多模态推理能力，确保其准确理解全局上下文并整合逻辑方法。

研究方法: 采用强化学习方法，引入由大语言模型评判的上下文奖励、格式奖励和准确性奖励，确保多模态信息的准确解读。同时，利用大语言模型评估逻辑奖励，验证推理过程是否成功整合多模态信息与逻辑方法。此外，提出多模态基准IntentBench，用于评估模型对复杂人类意图和情感的理解能力。

研究结果: 所提出的方法在多个多模态基准测试中表现优于其他开源多模态模型，验证了其在全局上下文理解和复杂推理方面的有效性。

研究结论: HumanOmniV2通过强化学习有效解决了多模态推理中的上下文理解不足和捷径问题，提升了模型的全局理解和逻辑整合能力，为多模态大语言模型的发展提供了新方向。

中文摘要: 随着多模态大语言模型的快速发展，深入理解和解释人类意图的能力成为关键需求，这需要细致且深思熟虑的推理。近期研究表明，强化学习（RL）在提升大语言模型（LLMs）的推理能力方面具有潜力。然而，将RL应用于多模态数据和格式的挑战仍未得到充分解决。本文指出现有多模态推理模型中的两个问题：全局上下文理解不足和捷径问题。全局上下文理解不足可能导致模型误解多模态上下文，从而给出错误答案；捷径问题则表现为模型忽略多模态输入中的关键线索，直接回答问题而未考虑多模态信息。为解决这些问题，我们强调模型需在多模态输入中清晰理解全局上下文进行推理，以防止忽略关键线索并确保推理过程的完整性。为实现多模态上下文信息的准确解读，我们引入由大语言模型评判的上下文奖励，以及格式和准确性奖励。此外，为提升复杂推理能力，我们利用大语言模型评估逻辑奖励，判断推理过程是否成功整合多模态信息与逻辑方法。我们还提出了一个多模态推理基准IntentBench，用于评估模型对复杂人类意图和情感的理解能力。与其他开源多模态模型相比，所提方法在多个全模态基准测试中表现出卓越性能。

</details>


### [85] [Class-Agnostic Region-of-Interest Matching in Document Images](https://arxiv.org/abs/2506.21055)
**中文标题：文档图像中的类无关感兴趣区域匹配**

*Demin Zhang,Jiahao Lyu,Zhijie Shen,Yu Zhou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“类无关感兴趣区域匹配”（RoI-Matching）的新任务，旨在以灵活、高效、多粒度和开放集的方式匹配用户自定义区域。作者构建了基准数据集RoI-Matching-Bench，并提出了RoI-Matcher框架，通过孪生网络和多级特征提取实现跨域语义对齐。实验表明该方法简单有效。


<details>
  <summary>详细信息</summary>
研究动机: 现有文档分析解决方案（如文档布局分析和关键信息提取）仅适用于固定类别定义和粒度，无法满足用户灵活定制的需求。因此，本文提出RoI-Matching任务，以解决这一问题。

研究方法: 作者构建了基准数据集RoI-Matching-Bench，包含三个难度级别，并提出了RoI-Matcher框架。该框架使用孪生网络提取参考文档和目标文档的多级特征，并通过交叉注意力层实现跨域语义对齐。

研究结果: 实验表明，RoI-Matcher在RoI-Matching-Bench上表现有效，为后续研究提供了基线。

研究结论: 本文提出的RoI-Matching任务和RoI-Matcher框架为文档分析提供了灵活、高效的解决方案，并可作为未来研究的基准。

中文摘要: 文档理解与分析因其广泛应用而备受关注。然而，现有的文档分析解决方案（如文档布局分析和关键信息提取）仅适用于固定类别定义和粒度，无法实现用户灵活定制的应用。因此，本文定义了一项名为“类无关感兴趣区域匹配”（简称“RoI-Matching”）的新任务，旨在以灵活、高效、多粒度和开放集的方式匹配用户自定义区域。参考文档和目标文档图像的视觉提示被输入到模型中，输出为目标文档图像中对应的边界框。为满足上述需求，我们构建了基准数据集RoI-Matching-Bench，根据实际条件设置了三个难度级别，并提出了宏观和微观评估指标。此外，我们还提出了新框架RoI-Matcher，该框架使用孪生网络提取参考域和目标域的多级特征，并通过交叉注意力层整合和对齐不同域中的相似语义。实验表明，我们的方法在RoI-Matching-Bench上简单有效，为后续研究提供了基线。代码发布于https://github.com/pd162/RoI-Matching。

</details>


### [86] [SAMURAI: Shape-Aware Multimodal Retrieval for 3D Object Identification](https://arxiv.org/abs/2506.21056)
**中文标题：SAMURAI：面向3D物体识别的形状感知多模态检索**

*Dinh-Khoi Vo,Van-Loc Nguyen,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: SAMURAI是一种结合形状和语言的多模态检索方法，用于在复杂室内环境中识别3D物体。通过CLIP语义匹配和形状引导的重新排序，以及预处理和多数投票策略，显著提升了检索性能。


<details>
  <summary>详细信息</summary>
研究动机: 在复杂室内环境中，仅通过掩码2D图像和自然语言描述检索3D物体面临巨大挑战，如视角扭曲、无纹理掩码区域、模糊语言提示和噪声分割掩码。这些限制了3D场景上下文的使用，增加了推理难度。

研究方法: SAMURAI整合了基于CLIP的语义匹配和形状引导的重新排序（通过二值轮廓提取），并采用预处理流程提升掩码质量（提取最大连通区域和去除背景噪声）。此外，结合多数投票策略增强检索鲁棒性。

研究结果: 在ROOMELSA私有测试集上，SAMURAI表现出色，证明了结合形状先验和语言理解对开放世界3D物体检索的重要性。

研究结论: SAMURAI通过多模态融合和形状引导的重新排序，显著提升了3D物体检索的性能，为复杂环境中的物体识别提供了有效解决方案。

中文摘要: 在复杂室内环境中，仅通过掩码2D图像和自然语言描述检索3D物体面临显著挑战。ROOMELSA挑战限制了完整3D场景上下文的使用，增加了对物体外观、几何和语义推理的复杂性。这些挑战因扭曲视角、无纹理掩码区域、模糊语言提示和噪声分割掩码而加剧。为此，我们提出了SAMURAI：面向3D物体识别的形状感知多模态检索。SAMURAI将基于CLIP的语义匹配与从掩码区域二值轮廓提取的形状引导重新排序相结合，并采用鲁棒的多数投票策略。专用预处理流程通过提取最大连通区域和去除背景噪声提升掩码质量。我们的混合检索框架结合语言和形状线索，在ROOMELSA私有测试集上取得了有竞争力的性能。这些结果凸显了结合形状先验与语言理解对鲁棒的开放世界3D物体检索的重要性。

</details>


### [87] [PoseMaster: Generating 3D Characters in Arbitrary Poses from a Single Image](https://arxiv.org/abs/2506.21076)
**中文标题：PoseMaster：从单张图像生成任意姿势的3D角色**

*Hongyu Yan,Kunming Luo,Weiyu Li,Yixun Liang,Shengming Li,Jingwei Huang,Chunchao Guo,Ping Tan*

主要分类: cs.CV

摘要简述: PoseMaster是一个端到端的可控3D角色生成框架，通过统一姿势变换和3D角色生成，解决了现有方法因自遮挡和视角导致的图像扭曲问题，并在任意姿势控制上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于图像的3D角色建模方法在姿势标准化阶段容易因自遮挡和视角问题生成扭曲图像，影响后续重建质量。PoseMaster旨在解决这些问题，提升3D角色生成的效率和几何质量。

研究方法: PoseMaster将姿势变换和3D角色生成统一到一个基于流的3D原生生成框架中，利用3D骨骼作为姿势条件，并通过随机清空姿势和图像条件提升控制效果和泛化能力。此外，使用高质量姿势控制数据集学习骨骼与蒙皮权重的隐式关系。

研究结果: 实验表明，PoseMaster在A姿势角色生成上优于现有技术，同时在任意姿势控制上表现出强大的精确控制能力。

研究结论: PoseMaster通过端到端框架解决了姿势标准化和3D重建的分离问题，显著提升了角色生成的几何质量和控制能力。

中文摘要: 3D角色在日常娱乐中扮演重要角色。为提高3D角色建模效率，现有基于图像的方法使用两个独立模型分别实现姿势标准化和A姿势角色的3D重建。然而，这些方法在姿势标准化阶段因自遮挡和视角问题容易生成扭曲和退化的图像，进而影响后续重建过程的几何质量。为解决这些问题，我们提出PoseMaster，一种端到端的可控3D角色生成框架。具体而言，我们将姿势变换和3D角色生成统一到一个基于流的3D原生生成框架中。为实现精确的任意姿势控制，我们提出利用可动画角色的骨骼中的3D身体骨骼作为姿势条件。此外，考虑到多条件控制的特殊性，我们在训练中随机清空姿势条件和图像条件，以提高姿势控制的有效性和泛化能力。最后，我们创建了一个基于真实角色动画数据的高质量姿势控制数据集，使模型能够学习骨骼与蒙皮权重之间的隐式关系。大量实验表明，PoseMaster在A姿势角色生成的定性和定量评估中均优于当前最先进技术，同时展示了其在实现任意姿势精确控制方面的强大能力。

</details>


### [88] [EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception](https://arxiv.org/abs/2506.21080)
**中文标题：EgoAdapt：自适应多感官蒸馏与策略学习实现高效自我中心感知**

*Sanjoy Chowdhury,Subrata Biswas,Sayan Nag,Tushar Nagarajan,Calvin Murdock,Ishwarya Ananthabhotla,Yijun Qian,Vamsi Krishna Ithapu,Dinesh Manocha,Ruohan Gao*

主要分类: cs.CV

摘要简述: 本文提出EgoAdapt框架，通过自适应跨模态蒸馏和策略学习，显著提升多感官自我中心感知任务的效率，同时保持或超越现有最优模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代多感官自我中心感知模型性能优异但计算成本高昂，难以在资源受限环境中部署。本文旨在通过自适应方法提升效率，同时保持性能。

研究方法: 提出EgoAdapt框架，结合跨模态蒸馏和策略学习，适应不同任务的动作空间，实现高效推理。

研究结果: 在EPIC-Kitchens、EasyCom和Aria Everyday Activities数据集上，EgoAdapt显著降低计算量（GMACs减少89.09%）、参数（减少82.02%）和能耗（降低9.6倍），性能与现有最优模型相当或更优。

研究结论: EgoAdapt通过自适应跨模态蒸馏和策略学习，为多感官自我中心感知任务提供了一种高效且高性能的解决方案。

中文摘要: 现代感知模型，尤其是为多感官自我中心任务设计的模型，性能卓越但计算成本高昂，这为实际部署带来了挑战，尤其是在资源受限的环境中。本文提出EgoAdapt框架，通过自适应跨模态蒸馏和策略学习，实现高效推理，适用于多种自我中心感知任务，包括自我中心动作识别、主动说话者定位和行为预测。所提出的策略模块可适应任务特定的动作空间，具有广泛适用性。在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个具有挑战性的数据集上的实验结果表明，该方法显著提升了效率，GMACs减少高达89.09%，参数减少高达82.02%，能耗降低高达9.6倍，同时性能与现有最优模型相当甚至更优。

</details>


### [89] [ESMStereo: Enhanced ShuffleMixer Disparity Upsampling for Real-Time and Accurate Stereo Matching](https://arxiv.org/abs/2506.21091)
**中文标题：ESMStereo：用于实时高精度立体匹配的增强型ShuffleMixer视差上采样方法**

*Mahmoud Tahmasebi,Saif Huq,Kevin Meehan,Marion McAfee*

主要分类: cs.CV

摘要简述: 论文提出了一种增强型ShuffleMixer（ESM）方法，用于实时且高精度的立体匹配，通过整合初级特征到视差上采样单元，恢复小尺度成本体积中的关键细节，实现高速推理。


<details>
  <summary>详细信息</summary>
研究动机: 立体匹配在现代自主系统中至关重要，但基于深度学习的模型在实现高精度和实时性方面仍面临挑战。大尺度成本体积虽能提供高精度视差估计，但计算量大；小尺度成本体积虽能实现实时性，但信息不足。论文旨在解决这一矛盾。

研究方法: 提出增强型ShuffleMixer（ESM），通过将初级特征整合到视差上采样单元，快速提取初始视差估计的特征并与图像特征融合。通过混洗和分层分割混合特征，并通过紧凑的特征引导沙漏网络细化，恢复更详细的场景几何信息。

研究结果: ESMStereo的紧凑版本在高性能GPU上达到116 FPS，在AGX Orin上达到91 FPS的推理速度，同时实现了高精度的视差图重建。

研究结论: ESM方法通过局部上下文连接和大感受野，以低计算成本实现了高精度视差图的实时重建，为立体匹配领域提供了高效解决方案。

中文摘要: 立体匹配已成为现代自主系统中日益重要的组成部分。开发基于深度学习的立体匹配模型，在实现高精度的同时保持实时性，仍然是计算机视觉领域的主要挑战。在基于成本体积的立体匹配中，精确的视差估计高度依赖于大规模成本体积。然而，这种大体积存储了大量冗余信息，并需要计算密集的聚合单元进行处理和回归，导致实时性能难以实现。相反，小规模成本体积结合轻量级聚合单元为实现实时性能提供了可能，但缺乏足够信息以确保高精度视差估计。为解决这一问题，我们提出了增强型Shuffle Mixer（ESM），以缓解小规模成本体积带来的信息损失。ESM通过将初级特征整合到视差上采样单元，恢复关键细节。它快速从初始视差估计中提取特征，并与图像特征融合。这些特征通过混洗和分层分割混合，并通过紧凑的特征引导沙漏网络细化，以恢复更详细的场景几何信息。ESM专注于具有大感受野和低计算成本的局部上下文连接，从而实现了高精度视差图的实时重建。ESMStereo的紧凑版本在高性能GPU上达到116 FPS，在AGX Orin上达到91 FPS的推理速度。

</details>


### [90] [OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography](https://arxiv.org/abs/2506.21101)
**中文标题：OracleFusion：基于结构约束语义排版的甲骨文解读辅助工具**

*Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,AndyPian Wu,Chaoyang Wang,Chengjie Wang,Taisong Jin,SevenShu,Yunsheng Wu,Yongge Liu,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出了一种名为OracleFusion的两阶段语义排版框架，用于辅助解读甲骨文。通过结合多模态大语言模型和甲骨结构向量融合技术，该方法在语义、视觉和字形保持方面优于现有基线模型，显著提升了甲骨文的可读性和美学质量。


<details>
  <summary>详细信息</summary>
研究动机: 甲骨文作为最古老的文字之一，记录了古代文明的文化与智慧。尽管已发现约4500个甲骨文字符，但仅约1600个被解读。剩余未解读字符因其复杂的结构和抽象的图像，给解读带来巨大挑战。本文旨在通过技术手段辅助专家解读这些未解字符。

研究方法: OracleFusion采用两阶段方法：第一阶段利用增强空间感知推理的多模态大语言模型（MLLM）分析甲骨文字符的字形结构并定位关键部件；第二阶段引入甲骨结构向量融合（OSVF），结合字形结构约束和字形保持约束，生成语义丰富的矢量字体，确保字形结构的完整性。

研究结果: 实验表明，OracleFusion在语义、视觉吸引力和字形保持方面优于现有基线模型，显著提升了甲骨文的可读性和美学质量。此外，该方法还能为未见过的甲骨文字符提供专家级见解。

研究结论: OracleFusion为甲骨文解读提供了有效的辅助工具，其两阶段框架在技术和美学上均表现出色，为未来甲骨文研究开辟了新途径。

中文摘要: 甲骨文作为最早的古代文字之一，记录了古代文明的文化与智慧表达。尽管已发现约4500个甲骨文字符，但仅约1600个被解读。剩余的未解字符因其复杂的结构和抽象的图像，给解读带来巨大挑战。为解决这一问题，本文提出了一种名为OracleFusion的两阶段语义排版框架。第一阶段，该方法利用增强空间感知推理（SAR）的多模态大语言模型（MLLM）分析甲骨文字符的字形结构，并对其关键部件进行视觉定位。第二阶段，我们引入甲骨结构向量融合（OSVF），结合字形结构约束和字形保持约束，确保生成语义丰富的矢量字体，同时保持字形结构的客观完整性，为专家解读甲骨文提供视觉增强的表示。大量定性和定量实验表明，OracleFusion在语义、视觉吸引力和字形保持方面优于现有基线模型，显著提升了甲骨文的可读性和美学质量。此外，OracleFusion还能为未见过的甲骨文字符提供专家级见解，成为推动甲骨文解读的有力工具。

</details>


### [91] [Logios : An open source Greek Polytonic Optical Character Recognition system](https://arxiv.org/abs/2506.21474)
**中文标题：Logios：一个开源希腊多调光学字符识别系统**

*Perifanos Konstantinos,Goutsos Dionisis*

主要分类: cs.CV

摘要简述: 本文介绍了一个专为希腊多调文本设计的开源光学字符识别（OCR）系统Logios，结合卷积层和循环层的优势，显著提升了识别准确率和效率。


<details>
  <summary>详细信息</summary>
研究动机: 传统OCR方法在处理希腊多调文本时存在局限性，因此需要一种专门针对此类文本的高效识别系统。

研究方法: 系统采用卷积层进行特征提取，结合循环层进行序列学习，以应对希腊多调文本的独特挑战。

研究结果: 该系统显著提高了希腊多调文本的识别准确率和效率，并作为开源库发布供学术使用。

研究结论: Logios系统为希腊多调文本的数字化提供了高效解决方案，并推动了相关领域的研究与应用。

中文摘要: 本文介绍了一种专为希腊多调文本设计的光学字符识别（OCR）系统，通过结合卷积层的特征提取能力和循环层的序列学习能力，解决了希腊多调文本识别的独特挑战。该方法旨在克服传统OCR技术的局限性，显著提升了准确率和效率。我们以开源库形式发布了底层模型，并将OCR平台开放供学术使用。

</details>


### [92] [Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing Change Detection](https://arxiv.org/abs/2506.21109)
**中文标题：突破权衡边界：紧凑而高效的遥感变化检测**

*Luosheng Xu,Dalin Zhang,Zhaohui Song*

主要分类: cs.CV

摘要简述: 本文提出了一种轻量级遥感变化检测模型FlickCD，通过增强差异模块和多尺度语义融合，显著降低了计算和存储开销，同时保持了高精度。


<details>
  <summary>详细信息</summary>
研究动机: 当前深度学习模型在遥感变化检测中虽复杂但精度提升有限，且计算资源消耗大。本研究旨在开发轻量级模型，满足卫星上处理需求，平衡性能与资源消耗。

研究方法: FlickCD引入增强差异模块（EDM）突出关键特征差异，抑制无关变化；解码器采用局部-全局融合块（LGFB），结合移位窗口自注意力（SWSA）和增强全局自注意力（EGSA），高效捕捉多尺度语义信息。

研究结果: 在四个基准数据集上的实验表明，FlickCD计算和存储开销降低超过一个数量级，同时达到或接近最优性能（F1分数损失<1%）。

研究结论: FlickCD在性能和资源消耗之间取得了显著平衡，为卫星上实时处理提供了高效解决方案。

中文摘要: 遥感变化检测对于监测城市扩张、灾害评估和资源管理至关重要，能够提供动态景观变化的及时、准确和大规模洞察。尽管深度学习已经彻底改变了变化检测领域，但现代模型日益增加的复杂性和计算需求并未显著提升精度。本研究未追随这一趋势，而是探索了一种更高效的方法，专注于轻量级模型，在保持高精度的同时最小化资源消耗，这是卫星上处理的必要条件。为此，我们提出了FlickCD（意为快速轻弹即可获得优异结果），突破了性能与资源权衡的边界。FlickCD引入了增强差异模块（EDM），放大时间阶段间的关键特征差异，同时抑制光照和天气变化等无关变化，从而降低后续变化解码器的计算成本。此外，FlickCD解码器采用局部-全局融合块（LGFB），结合移位窗口自注意力（SWSA）和增强全局自注意力（EGSA），高效捕捉多尺度语义信息，保留粗粒度和细粒度变化。在四个基准数据集上的大量实验表明，FlickCD将计算和存储开销降低了一个数量级以上，同时实现了最优性能或仅带来微小（F1分数<1%）的精度损失。实现代码已公开于https://github.com/xulsh8/FlickCD。

</details>


### [93] [IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes](https://arxiv.org/abs/2506.21116)
**中文标题：IPFormer-VideoLLM：增强多镜头场景的多模态视频理解能力**

*Yujia Liang,Jile Jiao,Zhicheng Wang,Xuetao Feng,Zixuan Ye,Yuan Wang,Hao Lu*

主要分类: cs.CV

摘要简述: 本文提出IPFormer-VideoLLM模型和新数据集MultiClip-Bench，以解决视频大语言模型在多镜头场景中的性能不足问题，通过实例级特征注入显著提升了多场景视频理解能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频大语言模型在多镜头场景（如不同摄像机角度或场景切换）中表现不佳，容易出现实例身份遗忘和关键帧忽略问题。这主要源于现有数据集缺乏多镜头标注，因此需要新的数据集和模型来解决这一问题。

研究方法: 首先引入MultiClip-Bench数据集，包含针对多镜头场景的密集描述和指令式问答对。随后提出IPFormer-VideoLLM模型，通过基于注意力的高效连接器注入实例级特征作为提示，实现跨场景的实例信息聚合。

研究结果: 实验表明，新数据集和模型显著提升了多场景视频理解能力，并在多个视频基准测试中表现出独特优势。

研究结论: IPFormer-VideoLLM和MultiClip-Bench为多镜头视频理解提供了有效解决方案，填补了现有研究的空白。

中文摘要: 视频大语言模型（VideoLLMs）已展现出卓越的理解能力，但在处理多镜头场景（如摄像机角度变化或场景切换的视频片段）时表现不佳，容易出现实例身份遗忘和关键帧忽略问题。本文首先将这一挑战归因于现有数据集缺乏多镜头标注，因此我们引入了名为MultiClip-Bench的新数据集，其中包含针对多镜头场景的密集描述和指令式问答对。实证研究表明，训练集显著提升了多镜头性能，而测试基准则可靠地衡量了模型在多镜头场景中的能力。通过进一步分析发现，当前模型仅以离散或有损方式编码实例特征，可能导致身份信息丢失。为此，我们提出了新模型IPFormer-VideoLLM，其核心思想是通过高效的基于注意力的连接器注入实例级特征作为提示，从而实现跨场景的实例信息聚合。实验证明，我们提出的数据集和模型不仅显著提升了多场景视频理解能力，还在多个视频基准测试中展现出独特优势。

</details>


### [94] [HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation](https://arxiv.org/abs/2506.21546)
**中文标题：HalluSegBench：基于反事实视觉推理的分割幻觉评估基准**

*Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou*

主要分类: cs.CV

摘要简述: HalluSegBench是首个通过反事实视觉推理评估视觉基础中幻觉现象的基准，包含1340对反事实实例和新型指标，揭示了视觉驱动幻觉的普遍性。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言分割模型常出现幻觉现象，但现有评估方法主要关注标签或文本幻觉，缺乏对视觉上下文的操控，难以诊断关键失败。因此，需开发新基准以评估视觉基础中的幻觉问题。

研究方法: 提出HalluSegBench基准，包含1340对反事实实例和新型指标，通过视觉一致的场景编辑量化幻觉敏感性，用于评估视觉语言分割模型的幻觉现象。

研究结果: 实验表明，视觉驱动幻觉比标签驱动更普遍，模型常持续产生错误分割，凸显反事实推理在诊断基础保真度中的必要性。

研究结论: HalluSegBench为视觉基础中的幻觉评估提供了首个反事实推理基准，揭示了模型的视觉驱动幻觉问题，为未来研究提供了重要工具。

中文摘要: 近年来，视觉语言分割的进展显著提升了视觉基础理解能力。然而，这些模型常出现幻觉现象，即对图像内容中不存在的对象生成分割掩码或错误标记无关区域。现有的分割幻觉评估方法主要关注标签或文本幻觉，而未操控视觉上下文，限制了其诊断关键失败的能力。为此，我们提出了HalluSegBench，首个通过反事实视觉推理评估视觉基础中幻觉现象的基准。该基准包含一个由281个独特对象类别构成的1340对反事实实例数据集，以及一组新提出的指标，用于量化视觉一致场景编辑下的幻觉敏感性。在HalluSegBench上对先进视觉语言分割模型的实验表明，视觉驱动幻觉比标签驱动更普遍，且模型常持续产生错误分割，凸显了反事实推理在诊断基础保真度中的必要性。

</details>


### [95] [CL-Splats: Continual Learning of Gaussian Splatting with Local Optimization](https://arxiv.org/abs/2506.21117)
**中文标题：CL-Splats：基于局部优化的高斯泼溅持续学习**

*Jan Ackermann,Jonas Kulhanek,Shengqu Cai,Haofei Xu,Marc Pollefeys,Gordon Wetzstein,Leonidas Guibas,Songyou Peng*

主要分类: cs.CV

摘要简述: CL-Splats提出了一种动态3D场景表示更新方法，通过局部优化高斯泼溅技术，实现高效场景重建与更新，避免全局重新计算。


<details>
  <summary>详细信息</summary>
研究动机: 在动态3D环境中，场景随时间变化需要高效更新表示，以支持机器人、混合现实等应用。传统方法需全局重新优化，计算开销大。

研究方法: CL-Splats结合变化检测模块，分割场景中的动态与静态部分，仅对变化区域进行局部优化，同时支持场景状态的存储与恢复。

研究结果: 实验表明，CL-Splats在更新效率和重建质量上优于现有技术，为实时3D场景重建提供了可靠基础。

研究结论: CL-Splats为动态3D场景的高效更新提供了新方法，支持未来实时适应任务。

中文摘要: 在动态3D环境中，随时间准确更新场景表示对机器人、混合现实和具身AI应用至关重要。随着场景变化，需要高效方法以纳入变化，而无需重新优化整个场景的计算开销。本文提出CL-Splats，通过稀疏场景捕捉增量更新基于高斯泼溅的3D表示。CL-Splats集成了鲁棒的变化检测模块，分割场景中更新与静态部分，实现聚焦的局部优化，避免不必要的重新计算。此外，CL-Splats支持存储和恢复先前场景状态，便于时间分割和新场景分析应用。大量实验表明，CL-Splats在更新效率和重建质量上优于现有技术，为3D场景重建任务的实时适应奠定了坚实基础。

</details>


### [96] [GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction](https://arxiv.org/abs/2506.21121)
**中文标题：GoIRL：面向图的多模态轨迹预测逆强化学习**

*Muleilan Pei,Shaoshuai Shi,Lu Zhang,Peiliang Li,Shaojie Shen*

主要分类: cs.CV

摘要简述: 本文提出了一种基于图导向逆强化学习（GoIRL）的多模态轨迹预测框架，通过最大熵逆强化学习推断奖励分布并生成多模态轨迹，结合分层轨迹生成器和概率融合策略，显著提升了预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶中周围智能体的轨迹预测具有高度不确定性和多模态特性，现有数据驱动方法主要依赖监督学习，缺乏对多模态轨迹的建模能力。本文旨在通过逆强化学习框架解决这一问题。

研究方法: 提出GoIRL框架，通过特征适配器将车道图特征聚合到网格空间，结合最大熵逆强化学习推断奖励分布和策略；采用分层参数化轨迹生成器及细化模块提升预测精度，并通过概率融合策略增强预测置信度。

研究结果: 实验表明，GoIRL在Argoverse和nuScenes运动预测基准测试中达到最优性能，且相比现有监督模型具有更强的泛化能力。

研究结论: GoIRL通过逆强化学习有效建模多模态轨迹预测问题，结合分层生成器和概率融合策略，显著提升了预测准确性和泛化性能。

中文摘要: 自动驾驶中周围智能体的轨迹预测因其固有的不确定性和多模态特性而极具挑战性。与当前主要依赖监督学习的数据驱动方法不同，本文提出了一种新颖的图导向逆强化学习（GoIRL）框架，该框架配备了向量化上下文表示的逆强化学习预测器。我们开发了一种特征适配器，能够有效地将车道图特征聚合到网格空间，从而与最大熵逆强化学习范式无缝集成，以推断奖励分布并获取可采样的策略以生成多个合理的规划。此外，基于采样的规划，我们实现了一种分层参数化轨迹生成器，配备了细化模块以提升预测精度，以及概率融合策略以增强预测置信度。大量实验结果表明，我们的方法不仅在大规模Argoverse和nuScenes运动预测基准测试中达到了最优性能，而且与现有监督模型相比表现出更强的泛化能力。

</details>


### [97] [Learning to See in the Extremely Dark](https://arxiv.org/abs/2506.21132)
**中文标题：学习在极暗环境中看见**

*Hai Jiang,Binhao Guan,Zhen Liu,Xiaohong Liu,Jian Yu,Zheng Liu,Songchen Han,Shuaicheng Liu*

主要分类: cs.CV

摘要简述: 本文提出了一种用于极暗场景（低至0.0001勒克斯）的RAW图像增强方法，通过构建大规模配对数据集SIED，并结合扩散模型和自适应光照校正模块，实现了高质量的图像恢复。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于学习的方法在低光RAW图像增强方面取得进展，但对极暗场景（如0.0001勒克斯）的研究因缺乏相应数据集而受限。本文旨在填补这一空白，并提出一种高效的数据合成和恢复方法。

研究方法: 1. 提出数据合成流程，生成精确校准的极低光RAW图像（0.0001-0.001勒克斯）及其sRGB参考，构建SIED数据集。2. 设计基于扩散模型的框架，利用其生成和去噪能力，结合自适应光照校正模块（AICM）和色彩一致性损失，实现极低信噪比RAW输入的恢复。

研究结果: 在SIED数据集和公开基准上的实验表明，该方法能有效恢复极暗场景下的图像，实现准确的曝光校正和色彩还原。

研究结论: 本文通过构建SIED数据集和提出扩散模型框架，解决了极暗场景RAW图像增强的挑战，为未来研究提供了重要基准和工具。

中文摘要: 基于学习的方法在低光RAW图像增强方面取得了显著进展，但其在环境照度低至0.0001勒克斯的极暗场景中的能力仍有待探索，原因在于缺乏相应的数据集。为此，我们提出了一种配对数据合成流程，能够生成精确校准的极低光RAW图像（照度范围为0.01-0.1勒克斯、0.001-0.01勒克斯和0.0001-0.001勒克斯），并结合高质量sRGB参考图像，构建了一个名为“极暗视觉”（SIED）的大规模配对数据集，用于评估低光RAW图像增强方法。此外，我们提出了一种基于扩散模型的框架，利用其生成能力和内在去噪特性，从极低信噪比的RAW输入中恢复出视觉上令人满意的结果。该框架引入了自适应光照校正模块（AICM）和色彩一致性损失，以确保准确的曝光校正和色彩恢复。在SIED数据集和公开基准上的大量实验证明了该方法的有效性。代码和数据集可在https://github.com/JianghaiSCU/SIED获取。

</details>


### [98] [YOLO-FDA: Integrating Hierarchical Attention and Detail Enhancement for Surface Defect Detection](https://arxiv.org/abs/2506.21135)
**中文标题：YOLO-FDA：结合层次化注意力与细节增强的表面缺陷检测方法**

*Jiawei Hu*

主要分类: cs.CV

摘要简述: YOLO-FDA是一种基于YOLO的检测框架，通过细粒度细节增强和注意力引导的特征融合，显著提升了工业表面缺陷检测的准确性和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 工业表面缺陷检测因缺陷类型多样、形状不规则、尺寸多变、细粒度要求高及材料纹理复杂而具有挑战性。现有方法存在特征冗余、细节敏感度不足和多尺度鲁棒性弱的问题，因此需要一种更高效的检测框架。

研究方法: YOLO-FDA采用BiFPN架构增强YOLOv5主干网络的双向多级特征聚合，并引入细节方向融合模块（DDFM）以捕捉细微结构变化。此外，提出两种注意力融合策略（AC和CAF）以优化上下文表示并减少特征噪声。

研究结果: 在多个基准数据集上的实验表明，YOLO-FDA在各类缺陷和尺度下的检测准确性和鲁棒性均优于现有最先进方法。

研究结论: YOLO-FDA通过结合细节增强和注意力机制，显著提升了表面缺陷检测的性能，为工业应用提供了更高效的解决方案。

中文摘要: 工业场景中的表面缺陷检测因缺陷类型多样、形状不规则、尺寸多变、细粒度要求高及材料纹理复杂而具有重要性和技术挑战性。尽管基于AI的检测器在性能上有所提升，但现有方法常存在特征冗余、细节敏感度不足及多尺度条件下鲁棒性弱的问题。为解决这些问题，我们提出YOLO-FDA，一种基于YOLO的新型检测框架，结合了细粒度细节增强和注意力引导的特征融合。具体而言，我们采用BiFPN架构以增强YOLOv5主干网络的双向多级特征聚合。为更好地捕捉细微结构变化，我们引入细节方向融合模块（DDFM），在次低层引入方向性非对称卷积以丰富空间细节，并将次低层与低层特征融合以增强语义一致性。此外，我们提出两种新颖的注意力融合策略——注意力加权拼接（AC）和跨层注意力融合（CAF），以优化上下文表示并减少特征噪声。在多个基准数据集上的广泛实验表明，YOLO-FDA在各类缺陷和尺度下的检测准确性和鲁棒性均优于现有最先进方法。

</details>


### [99] [Tree-based Semantic Losses: Application to Sparsely-supervised Large Multi-class Hyperspectral Segmentation](https://arxiv.org/abs/2506.21150)
**中文标题：基于树结构的语义损失：稀疏标注大规模多类高光谱分割的应用**

*Junwen Wang,Oscar Maccormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren*

主要分类: cs.CV

摘要简述: 本文提出两种基于树结构的语义损失函数，利用标签的层次结构改进稀疏标注的高光谱图像分割任务，并在实验中达到最先进性能。


<details>
  <summary>详细信息</summary>
研究动机: 高光谱成像（HSI）在手术应用中潜力巨大，但现有学习方法对所有错误等同惩罚，未能利用标签空间的语义层次关系。本文旨在通过树结构语义损失函数改进稀疏标注下的多类分割任务。

研究方法: 提出两种基于树结构的语义损失函数，结合稀疏标注训练方法，利用标签的层次关系优化分割性能。

研究结果: 实验表明，该方法在包含107个类别的稀疏标注HSI数据集上达到最先进性能，并能有效检测分布外像素。

研究结论: 树结构语义损失函数显著提升了稀疏标注多类分割任务的性能，同时不影响分布内像素的分割效果。

中文摘要: 高光谱成像（HSI）在手术应用中展现出巨大潜力，能够提供肉眼无法察觉的生物组织差异细节。目前正在通过精细标注训练视觉系统区分大量细微变化的类别。然而，生物医学分割任务中常用的学习方法对所有错误等同惩罚，未能利用标签空间的类间语义关系。本文提出两种基于树结构的语义损失函数，利用标签的层次组织优化分割性能。我们进一步将损失函数与稀疏、无背景标注的训练方法结合。大量实验表明，所提方法在包含107个类别的稀疏标注HSI数据集上达到最先进性能，且能有效检测分布外像素，同时不影响分布内像素的分割效果。

</details>


### [100] [Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI with Noisy Labels](https://arxiv.org/abs/2506.21151)
**中文标题：基于鲁棒深度学习的心脏MRI心肌瘢痕分割方法：应对噪声标签的挑战**

*Aida Moafi,Danial Moafi,Evgeny M. Mirkes,Gerry P. McCann,Abbas S. Alatrany,Jayanth R. Arnold,Mostafa Mehdipour Ghazi*

主要分类: cs.CV

摘要简述: 本文提出了一种鲁棒的深度学习流程，用于心脏MRI中心肌瘢痕的自动分割，通过微调最先进模型并解决标签噪声、数据异质性和类别不平衡问题，表现出优异的性能。


<details>
  <summary>详细信息</summary>
研究动机: 心肌瘢痕的准确分割对临床评估和治疗计划至关重要，但现有方法面临半自动标注的标签噪声、数据异质性和类别不平衡等挑战，亟需一种鲁棒的解决方案。

研究方法: 通过微调最先进模型，采用Kullback-Leibler损失和广泛的数据增强技术，解决标签噪声和数据异质性问题，并优化类别不平衡。

研究结果: 模型在急性和慢性病例中均表现出色，能够生成准确且平滑的分割结果，优于nnU-Net等现有方法，并在分布外测试集中展现出强泛化能力。

研究结论: 该方法为心肌瘢痕的自动量化提供了可靠基础，支持深度学习在心脏影像中的广泛应用。

中文摘要: 心脏MRI中心肌瘢痕的准确分割对临床评估和治疗计划至关重要。本研究提出了一种鲁棒的深度学习流程，通过微调最先进模型实现全自动心肌瘢痕检测与分割。该方法通过Kullback-Leibler损失和广泛的数据增强技术，明确解决了半自动标注的标签噪声、数据异质性和类别不平衡问题。我们在急性和慢性病例中评估了模型性能，证明其能够在噪声标签下生成准确且平滑的分割结果。特别是，我们的方法在性能上超越了nnU-Net等最先进模型，并在分布外测试集中展现出强泛化能力，凸显了其在各种影像条件和临床任务中的鲁棒性。这些结果为心肌瘢痕的自动量化奠定了可靠基础，并支持深度学习在心脏影像中的更广泛应用。

</details>


### [101] [Geometry and Perception Guided Gaussians for Multiview-consistent 3D Generation from a Single Image](https://arxiv.org/abs/2506.21152)
**中文标题：几何与感知引导的高斯方法：从单张图像生成多视角一致的3D对象**

*Pufan Li,Bi'an Du,Wei Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种新方法，通过结合几何和感知先验，从单张图像生成多视角一致的3D对象，无需额外训练模型，显著提升了重建质量和一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法从单视图图像生成3D对象时，常因多视角一致性差和几何细节不足而受限。本文旨在通过整合几何和感知先验，解决这些问题，实现高质量的3D重建。

研究方法: 方法包括训练三个不同的高斯分支（几何先验、感知先验和高斯噪声），通过几何和感知先验的交互优化3D高斯分支，并采用重投影策略增强深度一致性。

研究结果: 实验表明，该方法在3D重建和新视角合成上优于现有方法，生成结果具有更高的保真度和一致性。

研究结论: 本文方法通过几何和感知先验的无缝整合，实现了从单张图像生成高质量、多视角一致的3D对象，为3D生成领域提供了新的解决方案。

中文摘要: 从单视图图像生成逼真的3D对象需要具备自然外观、3D一致性以及对未见区域的多重合理推断能力。现有方法通常依赖于微调预训练的2D扩散模型或通过快速网络推理或3D高斯泼溅直接生成3D信息，但其结果通常存在多视角一致性差和几何细节不足的问题。为解决这些问题，我们提出了一种新方法，无需额外模型训练即可无缝整合几何和感知先验，从单张图像重建细节丰富的3D对象。具体而言，我们训练了三个不同的高斯分支，分别基于几何先验、感知先验和高斯噪声初始化。几何先验捕捉粗略的3D形状，而感知先验利用预训练的2D扩散模型增强多视角信息。随后，通过几何和感知先验的相互交互优化3D高斯分支，并通过基于重投影的策略进一步增强深度一致性。实验表明，我们的方法在3D重建和新视角合成上优于现有方法，生成了保真度更高的结果，展示了稳健且一致的3D对象生成能力。

</details>


### [102] [Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition](https://arxiv.org/abs/2506.21165)
**中文标题：面向无监督模拟到现实点云识别的拓扑感知建模**

*Longkun Zou,Kangjun Liu,Ke Chen,Kailing Guo,Kui Jia,Yaowei Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为拓扑感知建模（TAM）的新框架，用于解决点云数据在模拟到现实（Sim2Real）场景中的无监督域适应问题。通过利用全局空间拓扑和局部几何特征的拓扑关系，并结合自监督学习和自训练策略，显著提升了点分类器的泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 点云数据的语义表示学习常因数据采集方法的差异而面临几何变化的挑战，模拟数据与真实数据之间的域差距限制了分类器的泛化能力。现有无监督域适应方法缺乏对全局拓扑信息的捕捉，导致对源域语义模式的过拟合。

研究方法: 提出TAM框架，通过低层次高频3D结构表征全局空间拓扑，并通过自监督学习任务建模局部几何特征的拓扑关系。结合跨域对比学习和自训练策略，减少噪声伪标签的影响。

研究结果: 在三个公开的Sim2Real基准测试中，TAM框架表现优于现有方法，在所有任务中均取得一致改进。

研究结论: TAM框架通过拓扑感知建模和自训练策略，有效缩小了模拟与真实数据之间的域差距，提升了点云识别的泛化性能。

中文摘要: 从3D物体形状的点集中学习语义表示常因数据采集方法的差异而面临显著的几何变化挑战。通常，训练数据由点模拟器生成，而测试数据则由不同的3D传感器采集，导致模拟到现实（Sim2Real）的域差距，限制了点分类器的泛化能力。现有的无监督域适应（UDA）技术难以应对这一差距，因其缺乏能够捕捉全局拓扑信息的鲁棒、域不敏感描述符，导致对源域有限语义模式的过拟合。为解决这一问题，我们提出了一种新颖的拓扑感知建模（TAM）框架，用于对象点云的Sim2Real UDA。我们的方法通过利用低层次高频3D结构表征的全局空间拓扑，并通过一种新颖的自监督学习任务建模局部几何特征的拓扑关系，从而缩小域差距。此外，我们提出了一种结合跨域对比学习与自训练的高级自训练策略，有效减少了噪声伪标签的影响，增强了适应过程的鲁棒性。在三个公开的Sim2Real基准测试上的实验结果验证了TAM框架的有效性，显示其在所有评估任务中均优于现有方法。本工作的源代码将在https://github.com/zou-longkun/TAG.git提供。

</details>


### [103] [Task-Aware KV Compression For Cost-Effective Long Video Understanding](https://arxiv.org/abs/2506.21184)
**中文标题：任务感知的KV压缩：高效长视频理解方法**

*Minghao Qin,Yan Shu,Peitian Zhang,Kun Lun,Huaying Yuan,Juenjie Zhou,Shitao Xiao,Bo Zhao,Zheng Liu*

主要分类: cs.CV

摘要简述: 本文提出Video-X^2L，通过双级KV压缩和选择性KV重加载，有效解决长视频理解中的计算成本问题，显著提升性能并节省计算资源。


<details>
  <summary>详细信息</summary>
研究动机: 长视频理解（LVU）对现有多模态大语言模型（MLLMs）计算成本过高，现有KV压缩方法在高压缩比下信息损失严重。本文旨在解决这一问题。

研究方法: Video-X^2L采用双级KV压缩（生成低压缩和高压缩KV）和选择性KV重加载（解码阶段动态选择KV），无需额外训练且兼容现有MLLMs。

研究结果: 实验表明，Video-X^2L在多个LVU基准测试（如VideoMME、MLVU等）中性能显著优于现有方法，同时大幅降低计算成本。

研究结论: Video-X^2L是一种简单高效的方法，通过任务感知的KV压缩策略，显著提升了长视频理解的效率与性能。

中文摘要: 长视频理解（LVU）对现有多模态大语言模型（MLLMs）仍是一大挑战，主要源于高昂的计算成本。现有KV压缩方法在高压缩比下信息损失严重。本文提出Video-X^2L，通过双级KV压缩和选择性KV重加载灵活保留关键视频信息。具体包括：预填充阶段生成低压缩KV（L-KVs）和高压缩KV（H-KVs）；解码阶段选择性重加载L-KVs以利用任务关键信息，同时保持整体紧凑性。Video-X^2L无需额外训练且兼容现有MLLMs。实验表明，其在VideoMME、MLVU等基准测试中性能显著优于现有方法，同时大幅节省计算成本。

</details>


### [104] [Out-of-Distribution Semantic Occupancy Prediction](https://arxiv.org/abs/2506.21185)
**中文标题：分布外语义占用预测**

*Yuheng Zhang,Mengfei Duan,Kunyu Peng,Yuhang Wang,Ruiping Liu,Fei Teng,Kai Luo,Zhiyong Li,Kailun Yang*

主要分类: cs.CV

摘要简述: 本文提出了一种针对3D语义占用预测中的分布外（OoD）检测方法OccOoD，通过合成异常数据增强数据集，并结合几何-语义融合技术，显著提升了OoD检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D语义占用预测方法主要关注分布内场景，对分布外（OoD）对象和长尾分布敏感，可能导致未检测到的异常和误判，带来安全隐患。本文旨在解决这一问题。

研究方法: 提出合成异常集成管道（Synthetic Anomaly Integration Pipeline）生成数据集VAA-KITTI和VAA-KITTI-360，并设计OccOoD框架，结合Voxel-BEV渐进融合（VBPF）和基于RWKV的分支，实现几何-语义融合的OoD检测。

研究结果: OccOoD在1.2米区域内实现了67.34%的AuROC和29.21%的AuPRCr，达到最先进的OoD检测性能，同时保持了竞争力的占用预测表现。

研究结论: 本文提出的OccOoD框架和合成数据集有效解决了3D语义占用预测中的OoD检测问题，为自动驾驶安全提供了重要支持。

中文摘要: 3D语义占用预测对自动驾驶至关重要，能够提供密集且语义丰富的环境表示。然而，现有方法主要关注分布内场景，对分布外（OoD）对象和长尾分布敏感，增加了未检测异常和误判的风险，带来安全隐患。为解决这些问题，我们提出了分布外语义占用预测，专注于3D体素空间中的OoD检测。为填补数据集空白，我们提出了一种合成异常集成管道，注入合成异常的同时保留真实的空间和遮挡模式，生成了VAA-KITTI和VAA-KITTI-360两个数据集。我们设计了OccOoD框架，将OoD检测融入3D语义占用预测中，通过Voxel-BEV渐进融合（VBPF）和基于RWKV的分支，实现几何-语义融合的OoD检测。实验结果表明，OccOoD在1.2米区域内实现了67.34%的AuROC和29.21%的AuPRCr，达到最先进的OoD检测性能，同时保持了竞争力的占用预测表现。所建立的数据集和源代码将在https://github.com/7uHeng/OccOoD公开。

</details>


### [105] [GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding](https://arxiv.org/abs/2506.21188)
**中文标题：GroundFlow：一种用于3D点云序列定位时序推理的插件模块**

*Zijun Lin,Shuting He,Cheston Tan,Bihan Wen*

主要分类: cs.CV

摘要简述: 本文提出GroundFlow，一种用于3D点云序列定位的时序推理插件模块，显著提升现有3D视觉定位方法在SG3D任务中的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D视觉定位方法将多步骤文本指令视为整体，未能提取每一步的时序信息，而SG3D任务中常使用代词（如“它”、“这里”）需依赖上下文理解。现有方法因缺乏有效历史信息收集模块，难以适应SG3D任务。

研究方法: 提出GroundFlow模块，选择性提取短期和长期步骤信息，结合当前指令相关性，全面利用历史信息并保持时序理解优势。

研究结果: 在SG3D基准测试中，GroundFlow显著提升基线方法准确率（+7.5%和+10.2%），超越预训练3D大语言模型，并在五个数据集中达到最优性能。

研究结论: GroundFlow为现有3D视觉定位模型引入时序推理能力，在SG3D任务中实现最先进性能。

中文摘要: 3D点云序列定位（SG3D）指通过文本指令定位日常活动中详细步骤的对象序列。当前3D视觉定位（3DVG）方法将多步骤文本指令视为整体，未提取每一步的时序信息。然而，SG3D指令常使用代词（如“它”、“这里”）以简化表达，需依赖上下文理解并从先前步骤检索相关信息。由于缺乏有效历史信息收集模块，现有3DVG方法在适应SG3D任务时面临挑战。为此，我们提出GroundFlow——一种用于3D点云序列定位时序推理的插件模块。实验表明，GroundFlow显著提升3DVG基线方法在SG3D基准中的准确率（+7.5%和+10.2%），甚至超越多数据集预训练的3D大语言模型。此外，GroundFlow根据当前指令相关性选择性提取短期和长期步骤信息，全面利用历史信息并保持时序理解优势。最终，我们的工作为现有3DVG模型引入时序推理能力，在五个数据集的SG3D基准中达到最先进性能。

</details>


### [106] [Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation](https://arxiv.org/abs/2506.21198)
**中文标题：解锁约束：无源遮挡感知无缝分割**

*Yihong Cao,Jiaming Zhang,Xu Zheng,Hao Shi,Kunyu Peng,Hang Liu,Kailun Yang,Hui Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种无需源数据的全景图像分割方法UNLOCK，通过伪标签学习和上下文学习实现遮挡感知和360度覆盖的分割任务，性能接近依赖源数据的方法。


<details>
  <summary>详细信息</summary>
研究动机: 全景图像处理面临失真、遮挡和标注不足等问题，现有方法依赖源数据，限制了实际应用。本文旨在解决这些问题，提出无需源数据的实用分割任务。

研究方法: UNLOCK框架包含两个关键模块：Omni伪标签学习和Amodal-Driven上下文学习，无需源数据或目标标签即可实现全景分割和遮挡推理。

研究结果: 实验表明，该方法在真实到真实和合成到真实的适应设置中表现优异，性能接近依赖源数据的方法，mAAP和mAP分别达到10.9和11.6，mAPQ提升+4.3。

研究结论: UNLOCK为无需源数据的全景分割提供了高效解决方案，性能优越且实用性强，代码和数据将公开。

中文摘要: 全景图像处理对全上下文感知至关重要，但面临失真、视角遮挡和标注有限等约束。以往的无监督域适应方法依赖标记的针孔数据，需访问源数据。为此，我们提出了一种更实用的任务——无源遮挡感知无缝分割（SFOASS），并首次提出解决方案UNLOCK。UNLOCK包含两个关键模块：Omni伪标签学习和Amodal-Driven上下文学习。该框架无需依赖源数据或目标标签，即可实现360度视角覆盖和遮挡感知的分割。此外，我们通过真实到真实和合成到真实的适应设置对SFOASS任务进行了基准测试。实验结果表明，我们的无源方法性能接近依赖源数据的方法，mAAP和mAP分别达到10.9和11.6，mAPQ比仅源方法提升+4.3。所有数据和代码将在https://github.com/yihong-97/UNLOCK公开。

</details>


### [107] [MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](https://arxiv.org/abs/2506.21199)
**中文标题：MedPrompt：基于权重路由的LLM-CNN融合框架用于医学图像分割与分类**

*Shadman Sobhan,Kazi Abrar Mahmud,Abduz Zami*

主要分类: cs.CV

摘要简述: MedPrompt是一个结合大型语言模型（LLM）和卷积神经网络（CNN）的统一框架，用于医学图像分割和分类，支持动态权重路由，无需重新训练整个模型，具有高扩展性和实时性。


<details>
  <summary>详细信息</summary>
研究动机: 当前医学图像分析系统通常是任务特定的，缺乏灵活性，无法支持用户自定义工作流。MedPrompt旨在通过结合LLM和CNN，提供一个统一且可扩展的解决方案。

研究方法: MedPrompt结合了LLM（Llama-4-17B）进行高级任务规划和CNN（DeepFusionLab）进行低级图像处理。LLM解析用户指令并动态路由任务特定的预训练权重，避免重新训练整个框架。

研究结果: 在19个公共数据集上评估，MedPrompt实现了97%的端到端指令执行正确率，平均推理延迟为2.5秒。DeepFusionLab在分割（如肺部Dice 0.9856）和分类（如结核病F1 0.9744）任务中表现优异。

研究结论: MedPrompt通过结合LLM的解释性和模块化CNN的高效性，实现了可扩展的、基于提示的医学图像分析，适合近实时应用。

中文摘要: 当前的医学图像分析系统通常是任务特定的，需要针对分类和分割任务分别训练模型，且缺乏支持用户自定义工作流的灵活性。为解决这些问题，我们提出了MedPrompt，一个统一框架，结合了少量提示的大型语言模型（Llama-4-17B）用于高级任务规划和模块化卷积神经网络（DeepFusionLab）用于低级图像处理。LLM解析用户指令并生成结构化输出，动态路由任务特定的预训练权重。这种权重路由方法避免了在添加新任务时重新训练整个框架，仅需任务特定的权重，从而提高了可扩展性和部署效率。我们在19个公共数据集上评估了MedPrompt，覆盖了5种成像模态下的12项任务。该系统在解析和执行提示驱动指令时的端到端正确率达到97%，平均推理延迟为2.5秒，适合近实时应用。DeepFusionLab在分割任务（如肺部Dice 0.9856）和分类任务（如结核病F1 0.9744）中表现出色。总体而言，MedPrompt通过结合LLM的解释性和模块化CNN的高效性，实现了可扩展的、基于提示的医学图像分析。

</details>


### [108] [BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models](https://arxiv.org/abs/2506.21209)
**中文标题：BitMark for Infinity：比特自回归图像生成模型的水印技术**

*Louis Kerner,Michel Meintz,Bihe Zhao,Franziska Boenisch,Adam Dziedzic*

主要分类: cs.CV

摘要简述: 本文提出BitMark，一种针对Infinity等比特自回归图像生成模型的鲁棒水印框架，通过在比特级别嵌入水印以防止模型崩溃，同时保持视觉保真度和生成速度。


<details>
  <summary>详细信息</summary>
研究动机: 随着Infinity等先进文本到图像模型的广泛应用，其生成的图像可能被爬取并重新用于训练，导致模型崩溃。水印技术可帮助识别生成内容，防止性能退化。

研究方法: BitMark在Infinity的图像生成过程中，直接在比特级别的多尺度令牌流中嵌入水印，既不影响视觉质量，又能抵抗多种去除技术，并具有放射性（即水印可传递至后续模型）。

研究结果: BitMark在保持生成速度和视觉质量的同时，对多种去除技术表现出鲁棒性，且水印在后续模型的输出中仍可检测。

研究结论: BitMark为图像生成模型提供了一种防止模型崩溃的可靠方法，通过水印技术确保生成内容的可追溯性。

中文摘要: Infinity等先进的文本到图像模型能够以前所未有的速度生成逼真图像。这些模型基于比特自回归方式，在近乎无限规模的离散令牌集上运行。然而，其强大的生成能力伴随着风险：随着其输出内容在互联网上的广泛传播，这些图像可能被爬取并重新用作训练数据，甚至可能被同一模型自身使用。这种现象已被证明会导致模型崩溃，即反复使用生成内容训练模型（尤其是其早期版本）会导致性能逐渐退化。水印技术是一种有效的缓解策略，它通过嵌入人眼不可见但可检测的信号来识别生成内容。本文提出BitMark，一种针对Infinity的鲁棒比特水印框架。该方法在Infinity的图像生成过程中，直接在比特级别的多尺度（或分辨率）令牌流中嵌入水印。这种比特水印微妙地影响比特位，既保持了视觉保真度和生成速度，又能抵抗多种去除技术。此外，BitMark具有高放射性，即当水印生成图像用于训练其他图像生成模型时，后续模型的输出也会携带水印。即使仅对扩散模型或图像自回归模型进行微调，放射性痕迹仍可检测。总体而言，BitMark为图像生成模型提供了一种防止模型崩溃的可靠方法，通过水印技术确保生成内容的可追溯性。

</details>


### [109] [ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.21233)
**中文标题：ReME：一种以数据为中心的无需训练开词汇分割框架**

*Xiwei Xuan,Ziquan Deng,Kwan-Liu Ma*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的开词汇语义分割框架ReME，通过优化数据质量显著提升分割性能，在多个基准数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无需训练的开词汇语义分割方法依赖预训练模型或合成数据，性能受限于模型能力或参考集质量。本文发现高质量参考集对提升分割效果至关重要，因此提出了一种以数据质量为核心的框架。

研究方法: ReME框架包括一个数据管道，用于构建具有良好配对的片段-文本嵌入的参考集，以及一个基于简单相似性检索的模块，以揭示数据质量的关键作用。

研究结果: 在十个基准数据集上的广泛评估表明，ReME显著优于所有现有的无需训练的开词汇语义分割方法，验证了数据为中心的设计对无需训练的分割任务的重要性。

研究结论: 本文通过优化数据质量，提出了一种高效的无需训练开词汇语义分割框架，实验结果证明了其优越性，为未来研究提供了数据为中心的设计思路。

中文摘要: 无需训练的开词汇语义分割（OVS）旨在无需昂贵的模型微调情况下，根据任意文本类别分割图像。现有方法通常探索预训练模型（如CLIP）的注意力机制，或生成合成数据并设计复杂的检索流程来实现OVS。然而，这些方法的性能受限于依赖模型的能力或参考集的次优质量。本文研究了这一具有挑战性的密集场景理解任务中常被忽视的数据质量问题，并发现高质量参考集能显著提升无需训练OVS的性能。基于这一观察，我们提出了一种以数据质量为导向的框架，包括一个数据管道用于构建具有良好配对的片段-文本嵌入的参考集，以及一个简单的基于相似性的检索模块，以揭示数据的核心作用。值得注意的是，在十个基准数据集上的广泛评估表明，我们的方法优于所有现有的无需训练OVS方法，突显了以数据为中心的设计对无需训练OVS的重要性。代码发布于https://github.com/xiweix/ReME。

</details>


### [110] [Real-Time ESFP: Estimating, Smoothing, Filtering, and Pose-Mapping](https://arxiv.org/abs/2506.21234)
**中文标题：实时ESFP：估计、平滑、滤波与姿态映射**

*Qifei Cui,Yuang Zhou,Ruichen Deng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ESFP的端到端流程，将单目RGB视频转换为低成本4自由度桌面机械臂的可执行关节轨迹。该流程包含估计、平滑、滤波和姿态映射四个模块。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发一种高效且低成本的方法，将单目RGB视频中的动作转换为桌面机械臂的可执行轨迹，以简化机械臂的控制和操作。

研究方法: ESFP流程包含四个模块：(1) 估计模块ROMP将每帧图像提升为24关节3D骨架；(2) 平滑模块HPSTM结合长时域上下文和可微分前向运动学解码器，预测关节均值和协方差；(3) 滤波模块根据不确定性估计对轨迹进行加权滤波；(4) 姿态映射模块通过几何重定向将动作映射到机械臂的工作空间。

研究结果: 实验表明，ESFP能够高效地将视频动作转换为机械臂的可执行轨迹，同时保持动作的平滑性和解剖学合理性。

研究结论: ESFP为低成本桌面机械臂提供了一种高效且实用的动作转换方案，具有广泛的应用潜力。

中文摘要: 本文提出了ESFP，一种端到端流程，将单目RGB视频转换为低成本4自由度桌面机械臂的可执行关节轨迹。ESFP包含四个顺序模块。(1) 估计：ROMP将每帧图像提升为24关节3D骨架。(2) 平滑：提出的HPSTM（一种具有自注意力的序列到序列Transformer）结合长时域上下文和可微分前向运动学解码器，强制恒定骨骼长度和解剖学合理性，同时预测关节均值和完整协方差。(3) 滤波：根据HPSTM的不确定性估计对根归一化轨迹进行方差加权，抑制残余噪声。(4) 姿态映射：几何重定向层将肩-肘-腕三重映射到uArm的极坐标工作空间，保留手腕方向。

</details>


### [111] [DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation](https://arxiv.org/abs/2506.21237)
**中文标题：DiMPLe——解耦多模态提示学习：通过不变与虚假特征分离增强分布外对齐**

*Umaima Rahman,Mohammad Yaqub,Dwarikanath Mahapatra*

主要分类: cs.CV

摘要简述: DiMPLe是一种新型多模态提示学习方法，通过分离视觉和语言模态中的不变特征和虚假特征，提升分布外对齐性能。


<details>
  <summary>详细信息</summary>
研究动机: 多模态学习中，视觉数据的虚假相关性常影响分布外性能。现有方法仅关注图像特征，未能跨模态分离特征。DiMPLe旨在解决这一问题，提升对新类别和分布变化的泛化能力。

研究方法: DiMPLe结合三个关键目标：(1) 最小化不变与虚假特征的互信息，(2) 对虚假特征进行正则化，(3) 对不变特征进行对比学习。

研究结果: 在11个数据集上的实验表明，DiMPLe优于CoOp-OOD，基类准确率提升15.27，新类准确率提升44.31。

研究结论: DiMPLe通过跨模态特征分离，显著提升了多模态学习的分布外对齐性能，为新类别和分布变化提供了更强的鲁棒性。

中文摘要: 我们提出了DiMPLe（解耦多模态提示学习），一种在多模态学习中分离视觉和语言模态中不变与虚假特征的新方法。视觉数据中的虚假相关性常影响分布外性能。与以往仅关注图像特征的方法不同，DiMPLe在模态内和跨模态中分离特征，同时保持对齐一致性，从而提升对新类别的泛化能力和对分布变化的鲁棒性。我们的方法结合了三个关键目标：(1) 最小化不变与虚假特征的互信息，(2) 对虚假特征进行正则化，(3) 对不变特征进行对比学习。大量实验表明，DiMPLe在11个数据集上的平均性能优于CoOp-OOD，基类准确率绝对提升15.27，新类准确率绝对提升44.31。

</details>


### [112] [Temporal Rate Reduction Clustering for Human Motion Segmentation](https://arxiv.org/abs/2506.21249)
**中文标题：基于时间速率降低聚类的人体运动分割方法**

*Xianghan Meng,Zhengyu Tong,Zhiyuan Huang,Chun-Guang Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“时间速率降低聚类”（TR²C）的新方法，用于解决复杂背景视频中人体运动分割（HMS）的挑战。该方法通过联合学习结构化表示和亲和力，显著提升了分割性能，并在多个基准数据集上达到最优效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人体运动分割方法主要基于子空间聚类，假设高维时间数据符合子空间联合分布。然而，复杂人体运动和杂乱背景的视频帧可能不符合这一假设，因此需要一种更有效的方法。

研究方法: 本文提出的TR²C方法通过学习结构化表示和亲和力，确保时间一致性并符合子空间联合结构，从而优化人体运动分割任务。

研究结果: 在五个基准HMS数据集上的实验表明，TR²C方法使用不同特征提取器均取得了最先进的性能。

研究结论: TR²C方法通过联合学习结构化表示和亲和力，显著提升了复杂背景下的人体运动分割效果，为未来研究提供了新方向。

中文摘要: 人体运动分割（HMS）旨在将视频划分为不重叠的人体运动片段，近年来受到广泛关注。现有的HMS方法主要基于子空间聚类，其假设高维时间数据符合子空间联合（UoS）分布。然而，包含复杂人体运动和杂乱背景的视频帧可能不符合UoS分布。本文提出了一种名为“时间速率降低聚类”（TR²C）的新方法，通过联合学习结构化表示和亲和力来分割视频帧序列。具体而言，TR²C学习到的结构化表示保持了时间一致性，并与UoS结构良好对齐，有利于HMS任务。我们在五个基准HMS数据集上进行了大量实验，使用不同特征提取器均取得了最先进的性能。

</details>


### [113] [DuET: Dual Incremental Object Detection via Exemplar-Free Task Arithmetic](https://arxiv.org/abs/2506.21260)
**中文标题：DuET：基于无示例任务算术的双增量目标检测**

*Munish Monga,Vishal Chudasama,Pankaj Wasnik,Biplab Banerjee*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DuET的双增量目标检测方法，通过任务算术框架同时处理类别和域的变化，解决了现有方法在类别增量或域增量中的局限性，显著提升了模型的适应性和稳定性。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的目标检测系统（如自动驾驶和监控）需要持续学习新类别并适应环境变化。现有的类别增量目标检测（CIOD）和域增量目标检测（DIOD）方法仅解决单一问题，无法同时应对类别和域的变化。因此，本文提出双增量目标检测（DuIOD）这一更实用的设置。

研究方法: 本文提出DuET框架，基于任务算术模型合并，通过方向一致性损失减少符号冲突，实现稳定的增量学习。DuET与检测器无关，适用于YOLO11和RT-DETR等模型。此外，引入了保留-适应性指数（RAI）综合评估模型的保留能力和适应性。

研究结果: 在Pascal Series和Diverse Weather Series上的实验表明，DuET显著优于现有方法：在Pascal Series（4任务）上RAI提升13.12%，保留率为89.3%；在Diverse Weather Series（3任务）上RAI提升11.39%，保留率为88.57%。

研究结论: DuET通过任务算术和方向一致性损失，成功解决了类别和域增量学习的双重挑战，显著提升了模型的适应性和稳定性，为实际应用提供了有效解决方案。

中文摘要: 现实世界中的目标检测系统（如自动驾驶和监控）需要持续学习新类别并适应环境变化。现有方法（类别增量目标检测CIOD和域增量目标检测DIOD）仅解决单一问题，CIOD在未见域中表现不佳，DIOD在学习新类别时存在灾难性遗忘。为解决这些问题，本文提出双增量目标检测（DuIOD），通过无示例方式同时处理类别和域的变化。我们提出DuET，一种基于任务算术的模型合并框架，通过方向一致性损失减少符号冲突，实现稳定的增量学习。DuET与检测器无关，支持YOLO11和RT-DETR等模型作为实时增量目标检测器。为综合评估保留和适应能力，我们引入保留-适应性指数（RAI），结合平均保留指数（Avg RI）和域适应性的平均泛化指数。在Pascal Series和Diverse Weather Series上的实验表明，DuET显著优于现有方法：在Pascal Series（4任务）上RAI提升13.12%，保留率为89.3%；在Diverse Weather Series（3任务）上RAI提升11.39%，保留率为88.57%。

</details>


### [114] [Video Virtual Try-on with Conditional Diffusion Transformer Inpainter](https://arxiv.org/abs/2506.21270)
**中文标题：基于条件扩散变换器修复器的视频虚拟试穿**

*Cheng Zou,Senlin Cheng,Bolei Xu,Dandan Zheng,Xiaobo Li,Jingdong Chen,Ming Yang*

主要分类: cs.CV

摘要简述: 本文提出ViTI（视频试穿修复器），将视频虚拟试穿任务重新定义为条件视频修复问题，采用基于扩散变换器的3D时空注意力框架，通过多阶段训练和掩码策略，显著提升了时空一致性和细节保留能力。


<details>
  <summary>详细信息</summary>
研究动机: 视频虚拟试穿任务面临时空一致性和细节保留的双重挑战。现有方法多基于图像试穿逐帧处理，导致结果不一致；少数基于扩散的方法虽引入时间注意力，但仍存在不足。本文旨在通过重新定义任务为视频修复问题，从根本上提升一致性。

研究方法: 提出ViTI，将视频试穿任务建模为条件视频修复问题。基于扩散变换器构建3D时空注意力框架，采用多阶段训练和掩码策略，逐步适配视频服装修复任务，并通过服装条件确保细节符合预期。

研究结果: 定量和定性实验表明，ViTI在时空一致性和细节保留上优于现有方法，显著提升了视频虚拟试穿的效果。

研究结论: ViTI通过重新定义任务为视频修复问题，结合扩散变换器和3D时空注意力，有效解决了视频试穿中的一致性和细节问题，为未来研究提供了新思路。

中文摘要: 视频虚拟试穿旨在将服装自然地适配到目标人物的连续视频帧中。这是一项具有挑战性的任务，一方面输出视频需具备良好的时空一致性，另一方面给定服装的细节需在所有帧中保留完好。逐帧使用基于图像的试穿方法会因严重不一致性导致效果不佳。近期基于扩散的视频试穿方法虽少，但恰好采用了类似解决方案：在基于图像的试穿模型中引入时间注意力以适配视频试穿任务，虽有所改进但仍存在不一致问题。本文提出ViTI（视频试穿修复器），将视频虚拟试穿任务重新定义为条件视频修复任务，与以往方法不同。通过这种方式，我们从视频生成问题而非基于图像的试穿问题入手，从一开始就具备更好的时空一致性。具体而言，首先基于扩散变换器构建具有完整3D时空注意力的视频修复框架，然后通过掩码策略和多阶段训练逐步适配视频服装修复任务。经过这些步骤，模型能够根据提示以良好的时空一致性修复掩码服装区域。最后，与其他试穿方法类似，添加服装条件以确保修复的服装外观和细节符合预期。定量和定性实验结果表明，ViTI优于以往工作。

</details>


### [115] [WordCon: Word-level Typography Control in Scene Text Rendering](https://arxiv.org/abs/2506.21276)
**中文标题：WordCon：场景文本渲染中的单词级排版控制**

*Wenda Shi,Yiren Song,Zihan Rao,Dengming Zhang,Jiaming Liu,Xingxing Zou*

主要分类: cs.CV

摘要简述: 本文提出了一种名为WordCon的混合参数高效微调方法，用于解决生成图像中单词级排版控制的难题。通过构建单词级控制的场景文本数据集和引入文本-图像对齐框架，结合掩码损失和联合注意力损失，显著提升了文本到图像模型的性能和可控性。


<details>
  <summary>详细信息</summary>
研究动机: 生成图像中实现精确的单词级排版控制一直是一个挑战。为了解决这一问题，作者构建了新的数据集并提出了改进方法，旨在提升文本到图像模型在排版控制方面的能力。

研究方法: 作者构建了单词级控制的场景文本数据集，并提出了文本-图像对齐（TIA）框架。此外，还提出了WordCon方法，通过重新参数化选择性关键参数，结合掩码损失和联合注意力损失，提升了模型的效率和可控性。

研究结果: 定性和定量实验结果表明，该方法在艺术文本渲染、文本编辑和图像条件文本渲染等任务中优于现有技术。

研究结论: WordCon方法在单词级排版控制方面表现出色，能够无缝集成到多种任务中，为文本到图像模型提供了更高的可控性和效率。

中文摘要: 在生成图像中实现精确的单词级排版控制仍然是一个持续的挑战。为了解决这一问题，我们新构建了一个单词级控制的场景文本数据集，并引入了文本-图像对齐（TIA）框架。该框架利用基础模型提供的文本与局部图像区域之间的跨模态对应关系，以增强文本到图像（T2I）模型的训练。此外，我们提出了WordCon，一种混合参数高效微调（PEFT）方法。WordCon通过重新参数化选择性关键参数，提高了效率和可移植性。这使得它可以无缝集成到多种流程中，包括艺术文本渲染、文本编辑和图像条件文本渲染。为了进一步增强可控性，我们在潜在级别应用了掩码损失，以引导模型专注于学习图像中的文本区域，而联合注意力损失则提供了特征级监督，以促进不同单词之间的解耦。定性和定量结果均表明，我们的方法优于现有技术。数据集和源代码将供学术使用。

</details>


### [116] [HieraSurg: Hierarchy-Aware Diffusion Model for Surgical Video Generation](https://arxiv.org/abs/2506.21287)
**中文标题：HieraSurg：面向手术视频生成的层次感知扩散模型**

*Diego Biagini,Nassir Navab,Azade Farshad*

主要分类: cs.CV

摘要简述: HieraSurg提出了一种层次感知的手术视频生成框架，通过两阶段扩散模型结合手术阶段和语义分割信息，显著提升了视频生成的质量和一致性。


<details>
  <summary>详细信息</summary>
研究动机: 现有手术视频生成方法多为无条件生成，缺乏对手术动作和阶段的语义一致性，难以实现真实模拟。HieraSurg旨在解决这一问题，通过层次化建模提升生成视频的准确性和实用性。

研究方法: HieraSurg采用两阶段扩散模型：第一阶段通过分割预测模型生成粗粒度语义变化；第二阶段结合细粒度视觉特征，生成最终视频。模型利用手术阶段、动作三元组和全景分割图等多层次信息。

研究结果: 在胆囊切除术视频生成任务中，HieraSurg在定量和定性评估中均显著优于现有方法，表现出强泛化能力，并能生成更高帧率的视频。

研究结论: HieraSurg通过层次化建模和两阶段生成框架，显著提升了手术视频生成的质量和一致性，展现了在实际手术应用中的潜力。

中文摘要: 随着扩散模型在通用领域视频生成中的成功，手术视频合成成为一个有前景的研究方向。尽管现有方法能够生成高质量视频，但大多为无条件生成，难以保持与手术动作和阶段的一致性，缺乏对手术理解的细粒度指导。为解决这一问题，我们提出了HieraSurg，一种层次感知的手术视频生成框架，包含两个专用扩散模型。给定手术阶段和初始帧，HieraSurg首先通过分割预测模型预测未来的粗粒度语义变化，随后由第二阶段模型将这些时间分割图与细粒度视觉特征结合，生成最终视频。我们的方法利用了手术阶段、动作三元组和全景分割图等多层次抽象信息。在胆囊切除术视频生成任务上的实验结果表明，该模型在定量和定性评估中均显著优于现有方法，表现出强泛化能力，并能生成更高帧率的视频。当提供现有分割图时，模型表现出特别精细的语义一致性，展现了其在实际手术应用中的潜力。

</details>


### [117] [Continual Self-Supervised Learning with Masked Autoencoders in Remote Sensing](https://arxiv.org/abs/2506.21312)
**中文标题：基于掩码自编码器的遥感持续自监督学习**

*Lars Möllenbrok,Behnood Rasti,Begüm Demir*

主要分类: cs.CV

摘要简述: 本文提出了一种基于掩码自编码器（MAE）的持续自监督学习方法（CoSMAE），通过数据混合和模型混合知识蒸馏，有效缓解了遥感领域持续学习中的灾难性遗忘问题，并在实验中取得了优于现有方法的性能提升。


<details>
  <summary>详细信息</summary>
研究动机: 遥感领域的持续学习方法通常依赖大量标注数据，但标注成本高且难以获取。为解决这一问题，本文提出了一种自监督的持续学习方法，旨在减少对标注数据的依赖，同时提升模型在新任务上的泛化能力。

研究方法: CoSMAE包含两个核心组件：1) 数据混合，通过将当前任务与先前任务的图像进行插值，保留历史数据分布信息；2) 模型混合知识蒸馏，通过插值历史模型和当前模型的权重形成教师模型，进行知识蒸馏。这两种方法分别在数据和模型层面正则化MAE，以提升跨任务泛化能力并减少灾难性遗忘。

研究结果: 实验结果表明，CoSMAE在掩码自编码器上的持续学习任务中，性能显著优于现有方法，最高提升了4.94%。

研究结论: CoSMAE通过结合数据混合和模型混合知识蒸馏，有效解决了遥感领域持续学习中的灾难性遗忘问题，为自监督持续学习提供了新的思路。

中文摘要: 持续学习（CL）方法的发展在遥感（RS）领域引起了广泛关注，其目标是从连续获取的训练数据中按顺序学习新任务。现有的RS持续学习方法在学习新任务时，通过使用大量标注训练样本来增强对灾难性遗忘的鲁棒性，但标注数据的获取成本高且不总是可行。为解决这一问题，我们提出了一种基于掩码自编码器（MAE）的新型持续自监督学习方法（CoSMAE）。CoSMAE包含两个组件：1) 数据混合，通过将当前任务的图像与先前任务的图像进行插值，保留历史数据分布信息；2) 模型混合知识蒸馏，通过插值历史模型和当前模型的权重形成教师模型进行知识蒸馏。这两个组件相互补充，在数据和模型层面对MAE进行正则化，以提升跨任务泛化能力并减少灾难性遗忘的风险。实验结果表明，CoSMAE在应用于MAE时，性能显著优于现有持续学习方法，最高提升了4.94%。代码已公开：https://git.tu-berlin.de/rsim/CoSMAE。

</details>


### [118] [DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images](https://arxiv.org/abs/2506.21316)
**中文标题：DrishtiKon：面向文本丰富文档图像的多粒度视觉定位**

*Badri Vishal Kasuba,Parag Chaudhuri,Ganesh Ramakrishnan*

主要分类: cs.CV

摘要简述: 本文提出DrishtiKon框架，通过多粒度视觉定位技术提升文本丰富文档图像的视觉问答（VQA）系统的可解释性和可信度，结合多语言OCR和大语言模型，实现块、行、词和点级别的精准定位。


<details>
  <summary>详细信息</summary>
研究动机: 当前文档智能和视觉问答系统在文本丰富的文档图像中缺乏有效的视觉定位方法，限制了其在实际场景中的应用。本文旨在解决这一问题，提升多语言复杂文档的定位精度和可解释性。

研究方法: 方法包括：1) 结合多语言OCR和大语言模型；2) 提出新颖的区域匹配算法，支持块、行、词和点级别的定位；3) 基于CircularsVQA测试集构建新基准，提供多粒度人工验证标注。

研究结果: 实验表明，该方法在定位精度上达到最优，其中行级粒度在精度和召回率之间取得最佳平衡。消融研究验证了多块和多行推理的有效性，对比实验揭示了现有视觉语言模型在精确定位上的局限性。

研究结论: 本文提出的结构化对齐方法为现实世界中文本为中心的文档理解系统提供了更鲁棒和可解释的解决方案，代码和数据集已开源。

中文摘要: 文本丰富文档图像中的视觉定位是文档智能和视觉问答（VQA）系统面临的关键但尚未充分探索的挑战。我们提出了DrishtiKon，一种多粒度视觉定位框架，旨在提升复杂多语言文档VQA的可解释性和可信度。我们的方法结合了鲁棒的多语言OCR、大语言模型和一种新颖的区域匹配算法，能够精准定位块、行、词和点级别的答案范围。我们从CircularsVQA测试集中构建了一个新基准，提供多粒度的人工验证标注。大量实验表明，我们的方法在定位精度上达到最优，其中行级粒度在精度和召回率之间取得最佳平衡。消融研究进一步验证了多块和多行推理的优势。与领先的视觉语言模型的对比实验揭示了当前VLMs在精确定位上的局限性，凸显了我们基于结构化对齐方法的有效性。我们的研究为现实世界中以文本为中心的文档理解系统提供了更鲁棒和可解释的解决方案。代码和数据集已发布于https://github.com/kasuba-badri-vishal/DhrishtiKon。

</details>


### [119] [LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning](https://arxiv.org/abs/2506.21317)
**中文标题：LLaVA-Pose：通过关键点整合指令微调增强人体姿态和动作理解**

*Dewen Zhang,Tahir Hussain,Wangpeng An,Hayaru Shouno*

主要分类: cs.CV

摘要简述: 本文提出LLaVA-Pose方法，通过整合人体关键点与视觉特征生成专用数据，显著提升视觉语言模型在人体姿态和动作理解任务中的性能。实验结果显示改进幅度达33.2%。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉语言模型在复杂人体姿态和动作理解任务中表现不佳，主要缺乏针对此类任务的专用指令跟随数据。本文旨在通过整合人体关键点数据，提升模型在人体中心场景中的理解能力。

研究方法: 提出一种数据生成方法，整合人体关键点与传统视觉特征（如标题和边界框），构建包含200,328个样本的数据集，用于微调模型。数据集涵盖对话、详细描述和复杂推理三个领域。同时建立扩展人体姿态和动作理解基准（E-HPAUB）评估模型性能。

研究结果: 使用该数据集微调LLaVA-1.5-7B模型，得到LLaVA-Pose模型。在E-HPAUB基准测试中，性能较原始模型提升33.2%，验证了关键点数据在提升多模态模型性能中的有效性。

研究结论: 研究表明，整合人体关键点的专用数据能显著提升视觉语言模型在人体姿态和动作理解任务中的表现，为未来相关研究提供了新思路。

中文摘要: 当前的视觉语言模型（VLMs）在一般视觉理解任务中表现良好，但在处理与人体姿态和动作相关的复杂视觉任务时表现不佳，主要原因是缺乏专用的视觉语言指令跟随数据。我们提出了一种生成此类数据的方法，通过将人体关键点与传统视觉特征（如标题和边界框）结合，从而更精确地理解以人为中心的场景。我们的方法构建了一个包含200,328个样本的数据集，专门用于微调模型在人体中心任务中的表现，重点关注对话、详细描述和复杂推理三个领域。我们还建立了扩展人体姿态和动作理解基准（E-HPAUB）以评估模型性能。通过使用该数据集微调LLaVA-1.5-7B模型，并在基准测试中评估得到的LLaVA-Pose模型，我们取得了显著的改进。实验结果显示，与原始LLaVA-1.5-7B模型相比，性能整体提升了33.2%。这些发现突显了关键点整合数据在增强多模态模型对人体中心视觉理解方面的有效性。代码可在https://github.com/Ody-trek/LLaVA-Pose获取。

</details>


### [120] [Holistic Surgical Phase Recognition with Hierarchical Input Dependent State Space Models](https://arxiv.org/abs/2506.21330)
**中文标题：基于分层输入依赖状态空间模型的全景手术阶段识别**

*Haoyang Wu,Tsun-Hsuan Wang,Mathias Lechner,Ramin Hasani,Jennifer A. Eckhoff,Paul Pak,Ozanan R. Meireles,Guy Rosman,Yutong Ban,Daniela Rus*

主要分类: cs.CV

摘要简述: 本文提出了一种新颖的分层输入依赖状态空间模型，用于手术视频的全局分析，通过线性扩展特性高效处理长视频，并在多个数据集上显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 机器人辅助手术中的工作流分析至关重要，但长时视频处理效率低下，现有方法（如Transformer）因二次注意力机制受限。本文旨在解决这一问题。

研究方法: 提出分层输入依赖状态空间模型，结合局部聚合和全局关系模块，利用混合离散-连续监督策略训练，捕捉局部和全局动态。

研究结果: 在Cholec80、MICCAI2016和Heichole数据集上分别提升2.8%、4.3%和12.9%，显著优于现有方法。

研究结论: 该方法通过状态空间模型的线性扩展特性，高效处理长视频并提升性能，为手术工作流分析提供了新思路。

中文摘要: 手术工作流分析在机器人辅助手术中至关重要，但此类手术的长时间特性对视频分析提出了重大挑战。现有方法主要依赖Transformer模型，但其二次注意力机制限制了长视频的高效处理。本文提出了一种新颖的分层输入依赖状态空间模型，利用状态空间模型的线性扩展特性，实现对全长视频的决策，同时捕捉局部和全局动态。框架包含一个时间一致的视觉特征提取器，将状态空间模型头附加到特征提取器以传播时间信息。模型由两个关键模块组成：局部聚合状态空间模型块（捕捉复杂局部动态）和全局关系状态空间模型块（建模整个视频的时间依赖）。模型通过混合离散-连续监督策略训练，离散阶段标签和连续阶段进展信号在网络中传播。实验表明，该方法在Cholec80、MICCAI2016和Heichole数据集上分别以2.8%、4.3%和12.9%的优势大幅超越现有方法。代码将在论文接受后公开。

</details>


### [121] [PanSt3R: Multi-view Consistent Panoptic Segmentation](https://arxiv.org/abs/2506.21348)
**中文标题：PanSt3R：多视角一致的全景分割**

*Lojze Zust,Yohann Cabon,Juliette Marrie,Leonid Antsfeld,Boris Chidlovskii,Jerome Revaud,Gabriela Csurka*

主要分类: cs.CV

摘要简述: 本文提出了一种名为PanSt3R的统一方法，通过单次前向传播联合预测3D几何和多视角全景分割，避免了传统方法中需要测试时优化的计算开销，并在多个基准测试中实现了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常依赖2D全景分割结果，再通过优化隐式几何表示（如NeRF）进行融合，这种方法未能充分利用多视角间的空间关系，且需要计算昂贵的测试时优化。本文旨在提出一种更高效且性能优越的解决方案。

研究方法: PanSt3R基于MUSt3R（一种可扩展的多视角3D重建方法），通过增强其语义感知和多视角全景分割能力，实现了3D几何和多视角分割的联合预测。此外，改进了传统的掩码合并方法，并提出了基于PanSt3R和3DGS的新视角预测方法。

研究结果: PanSt3R在多个基准测试中达到了最先进的性能，且计算速度比现有方法快多个数量级。

研究结论: PanSt3R是一种概念简单、快速且可扩展的方法，能够高效地解决3D场景全景分割问题，同时避免了传统方法的计算瓶颈。

中文摘要: 3D场景的全景分割涉及对场景密集3D重建中对象实例的分割和分类，是一个具有挑战性的问题，尤其是在仅依赖未标定2D图像的情况下。现有方法通常利用现成模型提取单帧2D全景分割结果，再通过优化隐式几何表示（如NeRF）进行融合。我们认为，依赖2D全景分割解决本质上是3D和多视角的问题可能不够优化，因为它未能充分利用多视角间的空间关系。此外，这些方法不仅需要相机参数，还需要对每个场景进行计算昂贵的测试时优化。本文提出了一种统一且集成的方法PanSt3R，通过单次前向传播联合预测3D几何和多视角全景分割，避免了测试时优化的需求。我们的方法基于MUSt3R（一种可扩展的多视角3D重建方法），并增强了其语义感知和多视角全景分割能力。我们还改进了标准的掩码合并后处理方法，并提出了更合理的多视角分割方法。此外，我们提出了一种基于PanSt3R和普通3DGS的新视角预测方法。总体而言，PanSt3R概念简单，速度快且可扩展，在多个基准测试中实现了最先进的性能，同时计算速度比现有方法快多个数量级。

</details>


### [122] [Generalizable Neural Electromagnetic Inverse Scattering](https://arxiv.org/abs/2506.21349)
**中文标题：通用神经电磁逆散射方法**

*Yizhe Cheng,Chunxun Tian,Haoru Wang,Wentao Zhu,Xiaoxuan Ma,Yizhou Wang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于物理驱动的通用框架，用于解决电磁逆散射问题（EISP），通过将问题重新表述为两阶段逆传输-散射过程，利用诱导电流作为通用中间表示，显著提升了重建精度、泛化能力和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 电磁逆散射问题（EISP）在医学成像等应用中至关重要，但传统方法如Img-Interiors存在泛化能力差、对稀疏发射器配置不鲁棒等问题。本文旨在通过物理驱动的视角重新设计框架，解决这些局限性。

研究方法: 提出了一种两阶段框架：1）电流估计器学习诱导电流作为入射场和散射场之间的物理桥梁；2）介电常数求解器直接从估计的诱导电流计算相对介电常数。该方法支持端到端训练和通用前馈预测。

研究结果: 实验表明，该方法在重建精度、泛化能力和鲁棒性上均优于现有技术，尤其在稀疏发射器配置下表现优异。

研究结论: 本文为电磁逆散射问题提供了全新的物理驱动视角，显著提升了实际应用中的成本效益和可行性。

中文摘要: 解决电磁逆散射问题（EISP）在医学成像等应用中至关重要，其目标是从散射电磁场重建相对介电常数。这一逆过程本质上是病态且高度非线性的，极具挑战性。近期基于机器学习的方法Img-Interiors通过利用连续隐函数展示了有前景的结果，但需要针对特定案例优化，泛化能力不足，且在稀疏发射器配置（如仅一个发射器）下失效。为解决这些问题，我们从物理驱动的视角重新审视EISP，将其重新表述为两阶段逆传输-散射过程。这一表述揭示了诱导电流作为一种通用中间表示，有效解耦了非线性散射过程与病态逆问题。基于这一发现，我们提出了首个通用物理驱动框架，包含电流估计器和介电常数求解器，以端到端方式工作。电流估计器显式学习诱导电流作为入射场与散射场之间的物理桥梁，而介电常数求解器直接从估计的诱导电流计算相对介电常数。这一设计支持数据驱动训练和通用前馈预测，同时对发射器稀疏性保持强鲁棒性。大量实验表明，我们的方法在重建精度、泛化能力和鲁棒性上均优于现有技术。这项工作为电磁逆散射问题提供了全新的视角，是迈向低成本实用电磁成像解决方案的重要一步。

</details>


### [123] [ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models](https://arxiv.org/abs/2506.21356)
**中文标题：ShotBench：视觉语言模型中的专家级电影语言理解**

*Hongbo Liu,Jingwen He,Yi Jin,Dian Zheng,Yuhao Dong,Fan Zhang,Ziqi Huang,Yinan He,Yangguang Li,Weichao Chen,Yu Qiao,Wanli Ouyang,Shengjie Zhao,Ziwei Liu*

主要分类: cs.CV

摘要简述: ShotBench是一个专门用于评估视觉语言模型（VLMs）在电影语言理解能力的基准测试，揭示了现有模型的局限性，并提出了新的数据集和模型ShotVL，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 电影摄影是电影叙事、情感和美学表达的核心，但现有视觉语言模型对电影语言的细粒度理解能力尚未充分探索，缺乏有效的评估工具。

研究方法: 研究团队构建了ShotBench基准测试，包含3.5k专家标注的QA对，覆盖8个关键电影摄影维度；并开发了ShotQA数据集（70k QA对），通过监督微调和Group Relative Policy Optimization训练了ShotVL模型。

研究结果: 评估24个主流VLMs发现其平均准确率低于60%，而ShotVL显著优于所有开源和专有模型，达到最新技术水平。

研究结论: ShotBench填补了电影语言理解的评估空白，ShotVL为AI驱动的电影理解和生成提供了新方向，相关资源已开源以促进研究。

中文摘要: 电影摄影作为电影的基本视觉语言，对传达叙事、情感和美学质量至关重要。尽管近期的视觉语言模型（VLMs）展现出强大的通用视觉理解能力，但其对电影镜头中微妙电影语法的理解能力仍未被充分探索，且缺乏稳健的评估。这一关键空白限制了细粒度视觉理解和AI辅助视频生成的精确性。为此，我们提出了\textbf{ShotBench}，一个专门为电影语言理解设计的综合基准测试。它包含来自200多部知名（主要为奥斯卡提名）电影的3.5k专家标注的QA对，覆盖8个关键电影摄影维度。我们对24个主流VLMs的评估揭示了其显著局限性：即使表现最佳的模型平均准确率也不足60%，尤其在细粒度视觉线索和复杂空间推理方面表现不佳。为了推动该领域的进步，我们构建了\textbf{ShotQA}，一个包含约70k电影QA对的大规模多模态数据集。基于ShotQA，我们通过监督微调和Group Relative Policy Optimization开发了\textbf{ShotVL}。ShotVL在ShotBench上显著优于所有现有开源和专有模型，确立了新的\textbf{最新技术水平}。我们开源了模型、数据和代码，以促进AI驱动的电影理解和生成这一关键领域的快速发展。

</details>


### [124] [CoPa-SG: Dense Scene Graphs with Parametric and Proto-Relations](https://arxiv.org/abs/2506.21357)
**中文标题：CoPa-SG：基于参数化和原型关系的密集场景图**

*Julian Lorenz,Mrunmai Phatak,Robin Schön,Katja Ludwig,Nico Hörmann,Annemarie Friedrich,Rainer Lienhart*

主要分类: cs.CV

摘要简述: 本文提出CoPa-SG，一个高精度合成场景图数据集，并引入参数化关系和原型关系两种新概念，以解决现有场景图数据不足的问题，并提升场景理解和推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前场景图研究面临数据不足和标注不精确的问题，限制了场景理解的发展。本文旨在通过合成数据集和新关系类型解决这些问题。

研究方法: 提出CoPa-SG数据集，包含精确标注的场景图和两种新关系：参数化关系（如角度、距离）和原型关系（描述假设关系）。通过比较多种场景图生成模型，验证其有效性。

研究结果: 实验表明，CoPa-SG数据集能够显著提升场景图生成模型的性能，新关系类型可增强下游应用的规划和推理能力。

研究结论: CoPa-SG和新关系类型为场景理解提供了更丰富的表示形式，解决了数据瓶颈问题，并提升了场景推理的潜力。

中文摘要: 二维场景图为场景理解提供了结构化和可解释的框架，但当前研究仍受限于缺乏精确的场景图数据。为解决这一数据瓶颈，我们提出了CoPa-SG，一个具有高精度标注和全面对象间关系注释的合成场景图数据集。此外，我们引入了参数化关系和原型关系这两种场景图的新基础概念。前者通过为关系添加角度或距离等额外参数，提供了比传统关系更细粒度的表示；后者则编码了场景图中的假设关系，描述了如果新对象被放置到场景中时关系将如何形成。利用CoPa-SG，我们比较了多种场景图生成模型的性能，并展示了如何将新关系类型集成到下游应用中，以增强规划和推理能力。

</details>


### [125] [ToosiCubix: Monocular 3D Cuboid Labeling via Vehicle Part Annotations](https://arxiv.org/abs/2506.21358)
**中文标题：ToosiCubix：基于车辆部件标注的单目3D立方体标注方法**

*Behrooz Nasihatkon,Hossein Resani,Amirreza Mehrzadian*

主要分类: cs.CV

摘要简述: ToosiCubix提出了一种仅需单目图像和相机内参的3D立方体标注方法，通过用户少量点击和几何优化，实现高效且低成本的车辆3D标注。


<details>
  <summary>详细信息</summary>
研究动机: 现有3D立方体标注方法依赖昂贵的多传感器设备，限制了大规模数据标注的可行性。本文旨在开发一种仅需单目图像的实用解决方案。

研究方法: 通过标注车辆特定特征（如车轮、车标等），结合几何约束优化问题（PnP和最小二乘子问题），并引入概率尺寸先验，解决尺度和未观测维度问题。

研究结果: 在KITTI和Cityscapes3D数据集上验证，ToosiCubix提供了一种低成本、高质量的3D立方体标注方案。

研究结论: ToosiCubix为单目图像下的3D标注提供了一种高效且可扩展的解决方案，适用于大规模数据标注。

中文摘要: 现有的车辆3D立方体标注方法通常依赖昂贵且需精确校准的相机-LiDAR或立体设备，限制了其在大规模数据采集中的普及。我们提出了ToosiCubix，一种仅需单目图像和相机内参的简单而强大的3D立方体标注方法。该方法每辆车仅需约10次用户点击，非常适合为未使用专业设备采集的现有数据集添加3D标注。通过标注车辆不同部件的特定特征（如车轮、车标、对称性等），我们能够准确估计车辆的位置、方向和尺寸（存在尺度模糊性，8自由度）。几何约束被表述为一个优化问题，采用坐标下降策略交替求解PnP和最小二乘子问题。为解决常见模糊性（如尺度和未观测维度），我们引入了概率尺寸先验，实现9自由度的立方体标注。在KITTI和Cityscapes3D数据集上的验证表明，我们的方法为高质量3D立方体标注提供了一种经济高效且可扩展的解决方案。

</details>


### [126] [CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection](https://arxiv.org/abs/2506.21364)
**中文标题：CA-I2P：基于通道自适应调整和全局最优选择的配准网络**

*Zhixin Cheng,Jiacheng Deng,Xinjun Li,Xiaotian Yin,Bohao Liao,Baoqun Yin,Wenfei Yang,Tianzhu Zhang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于通道自适应调整和全局最优选择的图像到点云配准方法，显著提升了配准精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有检测无关方法在图像和点云特征匹配中，因通道注意力差异和场景结构相似性导致匹配效果下降和冗余对应问题。

研究方法: 提出通道自适应调整模块（CAA）增强模态内特征并抑制跨模态敏感性，以及全局最优选择模块（GOS）替代局部选择。

研究结果: 在RGB-D Scenes V2和7-Scenes数据集上实验表明，该方法实现了最先进的配准性能。

研究结论: 通过CAA和GOS模块，有效解决了跨模态匹配中的问题，显著提升了配准精度。

中文摘要: 检测无关方法通常遵循从粗到精的流程，提取图像和点云特征进行块级匹配并细化密集像素到点的对应关系。然而，图像和点云之间特征通道注意力的差异可能导致匹配结果下降，最终影响配准精度。此外，场景中的相似结构可能导致跨模态匹配中的冗余对应。为解决这些问题，我们提出了通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA增强模态内特征并抑制跨模态敏感性，而GOS用全局优化替代局部选择。在RGB-D Scenes V2和7-Scenes上的实验证明了我们方法的优越性，实现了图像到点云配准的最先进性能。

</details>


### [127] [GenFlow: Interactive Modular System for Image Generation](https://arxiv.org/abs/2506.21369)
**中文标题：GenFlow：用于图像生成的交互式模块化系统**

*Duc-Hung Nguyen,Huu-Phuc Huynh,Minh-Triet Tran,Trung-Nghia Le*

主要分类: cs.CV

摘要简述: GenFlow是一个创新的模块化框架，旨在降低生成艺术的技术门槛，通过节点编辑器和自然语言处理助手，让用户轻松生成图像。


<details>
  <summary>详细信息</summary>
研究动机: 生成艺术具有无限创意潜力，但技术复杂性限制了其广泛应用。GenFlow旨在通过简化工作流程和技术要求，让不同技能水平的用户都能轻松使用生成艺术工具。

研究方法: GenFlow采用模块化设计，提供基于节点的编辑器，支持无缝定制，并结合自然语言处理智能助手，自动化部署流程，降低技术障碍。

研究结果: 用户研究表明，GenFlow能够优化工作流程，缩短任务完成时间，并通过直观界面和自适应功能提升用户体验。

研究结论: GenFlow通过其易用性和高效性，重新定义了生成艺术的普及性和效率，成为一项突破性解决方案。

中文摘要: 生成艺术开启了无限的创意可能性，但由于高级架构概念和计算工作流程所需的技术专长，其全部潜力尚未被充分挖掘。为了弥合这一差距，我们提出了GenFlow，这是一种新颖的模块化框架，使所有技能水平的用户都能轻松精确地生成图像。GenFlow配备了基于节点的编辑器，支持无缝定制，并通过自然语言处理的智能助手，将复杂的工作流程创建转化为直观且易于上手的体验。通过自动化部署流程和最小化技术障碍，我们的框架使前沿的生成艺术工具对所有人开放。一项用户研究表明，GenFlow能够通过其直观界面和自适应功能优化工作流程，减少任务完成时间，并提升用户理解。这些结果将GenFlow定位为一项突破性解决方案，重新定义了生成艺术领域的可访问性和效率。

</details>


### [128] [FastRef:Fast Prototype Refinement for Few-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.21398)
**中文标题：FastRef：少样本工业异常检测的快速原型优化**

*Long Tian,Yufei Li,Yuyang Dai,Wenchao Chen,Xiyang Liu,Bo Chen*

主要分类: cs.CV

摘要简述: 本文提出FastRef，一种高效的原型优化框架，用于解决少样本工业异常检测中原型代表性不足的问题。通过特征转移和异常抑制两阶段迭代优化，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有少样本工业异常检测方法主要依赖有限正常样本生成原型，但未充分利用查询图像统计信息优化原型代表性，导致检测效果受限。

研究方法: FastRef采用两阶段迭代优化：1) 通过可优化变换矩阵将查询特征转移到原型；2) 通过原型对齐抑制异常。特征转移通过线性重构实现，异常抑制则利用最优传输（OT）最小化原型与优化后原型的差距。

研究结果: 在MVTec、ViSA、MPDD和RealIAD四个基准数据集上的实验表明，FastRef在1/2/4-shot设置下均表现出高效性和优越性能。

研究结论: FastRef通过系统优化原型代表性，显著提升了少样本工业异常检测的准确性和效率，为实际应用提供了可靠解决方案。

中文摘要: 少样本工业异常检测（FS-IAD）是数据稀缺环境下自动化检测系统面临的关键挑战。现有方法主要从有限正常样本中提取原型，但通常忽略了利用查询图像统计信息优化原型代表性。为此，我们提出FastRef，一种高效的FS-IAD原型优化框架。该方法通过两阶段迭代过程实现：1) 通过可优化变换矩阵将查询特征转移到原型；2) 通过原型对齐抑制异常。特征转移通过原型线性重构查询特征实现，而异常抑制则基于FS-IAD中异常重构概率更高的观察，利用最优传输（OT）最小化原型与优化后原型的差距。为全面评估，我们将FastRef与三种基于原型的FS-IAD方法（PatchCore、FastRecon、WinCLIP和AnomalyDINO）结合。在MVTec、ViSA、MPDD和RealIAD四个基准数据集上的大量实验表明，FastRef在1/2/4-shot设置下兼具高效性和优越性能。

</details>


### [129] [Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction](https://arxiv.org/abs/2506.21401)
**中文标题：面向3D参数曲线重建的曲线感知高斯泼溅方法**

*Zhirui Gao. Renjiao Yi,Yaqiao Dai,Xuening Zhu,Wei Chen,Chenyang Zhu,Kai Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种端到端框架，直接从多视角边缘图中重建3D参数曲线，避免了传统两阶段方法的误差累积问题，并通过曲线感知的高斯表示和动态拓扑优化实现了高效且鲁棒的曲线重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有的两阶段方法（先重建边缘点云再拟合参数曲线）存在误差累积问题。本文旨在通过直接优化3D参数曲线，避免这种误差，并解决参数曲线在多视角优化中的渲染难题。

研究方法: 提出了一种双向耦合机制，将参数曲线与边缘导向的高斯组件结合，形成曲线感知的高斯表示（CurveGaussian），支持可微渲染。同时，引入动态自适应拓扑优化框架，通过线性化、合并、分割和剪枝操作优化曲线结构。

研究结果: 在ABC数据集和真实场景基准测试中，本文方法显著优于两阶段方法，重建结果更干净、更鲁棒，且训练参数更少，效率更高。

研究结论: 本文提出的单阶段方法通过直接优化参数曲线和动态拓扑优化，实现了高效且高质量的3D曲线重建，为相关领域提供了新的解决方案。

中文摘要: 本文提出了一种端到端框架，用于直接从多视角边缘图中重建3D参数曲线。与现有的两阶段方法（即先重建边缘点云再拟合参数曲线）不同，我们的单阶段方法直接从2D边缘图优化3D参数曲线，避免了因阶段间优化差距导致的误差累积。然而，参数曲线本身不适合基于渲染的多视角优化，因此需要一种既能保留几何特性又支持可微渲染的互补表示。我们提出了一种参数曲线与边缘导向高斯组件之间的双向耦合机制，形成了一种曲线感知的高斯表示（CurveGaussian），实现了3D曲线的可微渲染，从而支持基于多视角证据的直接优化。此外，我们在训练过程中引入了动态自适应拓扑优化框架，通过线性化、合并、分割和剪枝操作优化曲线结构。在ABC数据集和真实场景基准测试中的全面评估表明，我们的单阶段方法显著优于两阶段方法，尤其是在生成更干净、更鲁棒的重建结果方面。同时，通过直接优化参数曲线，我们的方法显著减少了训练参数数量，实现了更高的效率和更优的性能。

</details>


### [130] [XVerse: Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation](https://arxiv.org/abs/2506.21416)
**中文标题：XVerse：通过DiT调制实现身份与语义属性的多主体一致性控制**

*Bowen Chen,Mengyi Zhao,Haomiao Sun,Li Chen,Xu Wang,Kang Du,Xinglong Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种名为XVerse的新模型，通过将参考图像转换为特定于令牌的文本流调制偏移量，实现了对多主体身份和语义属性的精确独立控制，显著提升了文本到图像生成的编辑性和一致性。


<details>
  <summary>详细信息</summary>
研究动机: 在文本到图像生成中，尤其是多主体场景下，如何精确控制主体身份和语义属性（如姿势、风格、光照）而不破坏图像潜在特征或编辑性是一个重要挑战。现有方法常导致伪影或属性纠缠，因此需要一种更高效的解决方案。

研究方法: XVerse通过将参考图像转换为特定于令牌的文本流调制偏移量，实现了对多主体身份和语义属性的独立控制。这种方法避免了直接修改图像潜在特征，从而保持了图像的编辑性和一致性。

研究结果: 实验表明，XVerse能够实现高保真、可编辑的多主体图像合成，同时对单个主体的特征和语义属性具有鲁棒的控制能力。

研究结论: XVerse显著提升了复杂场景和个性化图像生成的能力，为多主体控制提供了一种高效且灵活的解决方案。

中文摘要: 在文本到图像生成中，尤其是多主体场景下，如何精确控制主体身份和语义属性（如姿势、风格、光照）往往会影响扩散变换器（DiTs）的编辑性和一致性。许多方法会引入伪影或面临属性纠缠问题。为解决这些挑战，我们提出了一种新型多主体控制生成模型XVerse。通过将参考图像转换为特定于令牌的文本流调制偏移量，XVerse能够在不干扰图像潜在特征的情况下，实现对特定主体的精确独立控制。因此，XVerse提供了高保真、可编辑的多主体图像合成能力，同时对单个主体的特征和语义属性具有鲁棒的控制力。这一进展显著提升了复杂场景和个性化图像生成的能力。

</details>


### [131] [EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian Splatting](https://arxiv.org/abs/2506.21420)
**中文标题：EndoFlow-SLAM：基于光流约束的高斯泼溅实时内窥镜SLAM**

*Taoyu Wu,Yiyi Miao,Zhuoxiao Li,Haocheng Zhao,Kang Dang,Jionglong Su,Limin Yu,Haoang Li*

主要分类: cs.CV

摘要简述: 本文提出EndoFlow-SLAM，一种基于光流约束的3D高斯泼溅SLAM方法，用于内窥镜场景的实时三维重建与可视化。通过引入光流损失和深度正则化策略，解决了内窥镜场景中的光度不一致性和动态运动问题，并在静态和动态手术场景中表现出优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 内窥镜手术场景中，非朗伯表面和呼吸引起的动态运动导致光度不一致性，影响SLAM系统的性能。现有3D高斯泼溅SLAM方法仅依赖外观约束，难以应对这些挑战。

研究方法: 1. 引入光流损失作为几何约束，优化场景3D结构和相机运动；2. 提出深度正则化策略，缓解光度不一致性问题；3. 改进3DGS细化策略，针对渲染质量较差的帧优化关键帧视角。

研究结果: 在C3VD静态数据集和StereoMIS动态数据集上的实验表明，该方法在新型视图合成和位姿估计方面优于现有方法，适用于静态和动态手术场景。

研究结论: EndoFlow-SLAM通过光流约束和深度正则化，显著提升了内窥镜SLAM系统的性能，为手术场景的实时三维重建提供了有效解决方案。

中文摘要: 高效的三维重建和实时可视化在内窥镜等手术场景中至关重要。近年来，3D高斯泼溅（3DGS）在高效三维重建和渲染中表现出色。大多数基于3DGS的同步定位与建图（SLAM）方法仅依赖外观约束优化3DGS和相机位姿。然而，内窥镜场景中，非朗伯表面导致的光度不一致性和呼吸引起的动态运动影响了SLAM系统的性能。为解决这些问题，我们额外引入光流损失作为几何约束，有效约束场景的3D结构和相机运动。此外，我们提出深度正则化策略，缓解光度不一致性问题，并确保3DGS深度渲染在内窥镜场景中的有效性。同时，为提升SLAM系统的场景表示能力，我们改进3DGS细化策略，重点关注渲染质量较差的帧对应的关键帧视角，以获得更好的渲染结果。在C3VD静态数据集和StereoMIS动态数据集上的大量实验表明，我们的方法在新型视图合成和位姿估计方面优于现有方法，在静态和动态手术场景中均表现出高性能。源代码将在论文录用后公开。

</details>


### [132] [HyperSORT: Self-Organising Robust Training with hyper-networks](https://arxiv.org/abs/2506.21430)
**中文标题：HyperSORT：基于超网络的自组织鲁棒训练方法**

*Samuel Joutard,Marijn Stollenga,Marc Balle Sanchez,Mohammad Farid Azampour,Raphael Prevost*

主要分类: cs.CV

摘要简述: HyperSORT是一种利用超网络预测UNet参数的框架，通过潜在向量表示图像和标注的变异性，联合学习超网络参数和数据样本的潜在向量集合，从而在医学影像数据中识别和应对异质性偏差。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像数据常包含异质性偏差（如错误标签或不一致的标注风格），这些偏差会严重影响深度分割网络的性能，但识别和表征这些偏差是一项繁琐且具有挑战性的任务。

研究方法: HyperSORT通过超网络预测UNet参数，潜在向量集合表示图像和标注的变异性，并联合学习超网络参数和数据样本的潜在向量。该方法学习UNet参数的复杂分布，低密度区域捕捉噪声模式，高密度区域稳健分割器官。

研究结果: 在3D腹部CT数据集（AMOS和TotalSegmentator）上的实验表明，HyperSORT能够结构化映射数据集，识别系统性偏差和错误样本，潜在空间聚类生成的UNet参数能够根据学习到的系统性偏差完成分割任务。

研究结论: HyperSORT能够有效识别医学影像数据中的系统性偏差和错误样本，并通过潜在空间聚类生成适应不同偏差的分割参数，为医学影像分析提供了新思路。

中文摘要: 医学影像数据集通常包含异质性偏差，从错误标签到不一致的标注风格。这些偏差会严重影响深度分割网络的性能。然而，识别和表征这些偏差是一项特别繁琐且具有挑战性的任务。本文提出HyperSORT，一种利用超网络预测UNet参数的框架，潜在向量表示图像和标注的变异性。超网络参数和训练集中每个数据样本对应的潜在向量集合被联合学习。因此，HyperSORT不是优化单一神经网络以适应数据集，而是学习UNet参数的复杂分布，其中低密度区域可以捕捉噪声特定模式，而较大模式则以区分但有意义的方式稳健分割器官。我们在两个3D腹部CT公共数据集上验证了我们的方法：首先是AMOS数据集的合成扰动版本，其次是TotalSegmentator，一个包含真实未知偏差和错误的大规模数据集。实验表明，HyperSORT创建了数据集的结构化映射，允许识别相关系统性偏差和错误样本。潜在空间聚类生成的UNet参数能够根据学习到的系统性偏差完成分割任务。代码和我们对TotalSegmentator数据集的分析已公开：https://github.com/ImFusionGmbH/HyperSORT

</details>


### [133] [Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation](https://arxiv.org/abs/2506.21444)
**中文标题：基于跨数据集评估的深度学习与视觉基础模型在非典型与正常有丝分裂分类中的基准测试**

*Sweta Banerjee,Viktoria Weiss,Taryn A. Donovan,Rutger A. Fick,Thomas Conrad,Jonas Ammeling,Nils Porsche,Robert Klopfleisch,Christopher Kaltenecker,Katharina Breininger,Marc Aubreville,Christof A. Bertram*

主要分类: cs.CV

摘要简述: 本文通过对比深度学习和视觉基础模型，在乳腺癌非典型有丝分裂分类任务中进行了全面评估，并引入两个新数据集进行跨域验证。结果表明，基于LoRA微调的基础模型表现最佳，为非典型有丝分裂分类提供了有效解决方案。


<details>
  <summary>详细信息</summary>
研究动机: 非典型有丝分裂是肿瘤恶性程度的重要标志，但其识别存在挑战，包括低发生率、形态学差异细微、病理学家间一致性低以及数据集类别不平衡。本研究旨在通过深度学习方法解决这些问题，并验证其跨域泛化能力。

研究方法: 研究基于AMi-Br数据集，比较了基线模型、线性探测的基础模型和基于LoRA微调的基础模型。同时引入了两个新数据集AtNorM-Br和AtNorM-MD进行跨域评估。

研究结果: 在AMi-Br、AtNorM-Br和AtNorM-MD数据集上，基于LoRA微调的Virchow基础模型表现最佳，平衡准确率分别达到0.8135、0.7696和0.7705。

研究结论: 研究表明，尽管非典型有丝分裂分类具有挑战性，但通过迁移学习和模型微调技术可以有效解决。研究提供了所有代码和数据，为后续研究奠定了基础。

中文摘要: 非典型有丝分裂标志着细胞分裂过程的异常，可作为肿瘤恶性程度的独立预后标志物。然而，由于其发生率低、与正常有丝分裂的形态学差异有时细微、病理学家间一致性低以及数据集类别不平衡，其识别仍具挑战性。本研究基于乳腺癌非典型有丝分裂数据集（AMi-Br），全面比较了自动非典型有丝分裂分类的深度学习方法，包括基线模型、线性探测的基础模型和基于低秩适应（LoRA）微调的基础模型。为严格评估，我们还引入了两个新的非典型有丝分裂数据集——AtNorM-Br（来自TCGA乳腺癌队列）和AtNorM-MD（来自MIDOG++训练集的多域数据集）。结果显示，在AMi-Br、AtNorM-Br和AtNorM-MD数据集上，基于LoRA微调的Virchow基础模型的平均平衡准确率分别达到0.8135、0.7696和0.7705。研究表明，尽管非典型有丝分裂分类具有挑战性，但通过迁移学习和模型微调技术可以有效解决。所有代码和数据已在GitHub仓库公开：https://github.com/DeepMicroscopy/AMi-Br_Benchmark。

</details>


### [134] [Controllable 3D Placement of Objects with Scene-Aware Diffusion Models](https://arxiv.org/abs/2506.21446)
**中文标题：基于场景感知扩散模型的可控3D物体放置**

*Mohamed Omran,Dimitris Kalatzis,Jens Petersen,Amirhossein Habibian,Auke Wiggers*

主要分类: cs.CV

摘要简述: 本文提出了一种基于场景感知扩散模型的可控3D物体放置方法，通过视觉地图和粗略物体掩码实现高质量物体定位和方向调整。


<details>
  <summary>详细信息</summary>
研究动机: 现有图像编辑方法在物体精确定位和方向调整上存在挑战，通常需要复杂的掩码或提示。本文旨在解决这一问题，提供更灵活且高质量的物体放置方案。

研究方法: 设计了一种结合视觉地图和粗略物体掩码的条件信号，利用修复模型保持背景完整性，支持物体形状和方向调整。

研究结果: 在汽车场景中验证了方法的有效性，实现了高精度的物体放置和形状调整，同时保持了背景的完整性。

研究结论: 该方法不仅实现了精确的物体定位和方向控制，还能结合外观控制，为场景编辑提供了灵活且高质量的解决方案。

中文摘要: 随着强大的文本条件生成模型的出现，图像编辑方法变得更加强大和灵活。然而，在环境中精确放置物体仍然是一个挑战，因为这通常需要精心设计的修复掩码或提示。本文提出了一种结合视觉地图和粗略物体掩码的条件信号，能够实现高质量的物体放置。该方法通过修复模型保持背景完整性，同时支持物体形状和方向的调整。在汽车场景中，我们验证了不同条件信号在物体放置任务中的有效性，这些任务不仅评估外观质量，还测量姿态和位置精度，包括需要非平凡形状变化的情况。最后，我们展示了精细位置控制与外观控制的结合，能够将现有物体精确放置在场景中。

</details>


### [135] [A Comprehensive Dataset for Underground Miner Detection in Diverse Scenario](https://arxiv.org/abs/2506.21451)
**中文标题：面向多样化场景的地下矿工检测综合数据集**

*Cyrus Addy,Ajay Kumar Gurumadaiah,Yixiang Gao,Kwame Awuah-Offei*

主要分类: cs.CV

摘要简述: 本文提出了一种专门用于地下矿工检测的热成像数据集，旨在支持紧急救援场景下的矿工检测系统开发与验证。通过系统采集多种采矿活动和场景的热成像数据，并评估了多种先进的目标检测算法，为未来研究奠定了基础。


<details>
  <summary>详细信息</summary>
研究动机: 地下采矿作业面临重大安全挑战，亟需可靠的矿工检测技术以提升应急响应能力。尽管机器人技术在搜救中展现出潜力，但其效果依赖于准确的矿工检测能力。目前缺乏针对地下采矿环境的全面训练数据集，限制了深度学习算法的应用。

研究方法: 本文构建了一个专门用于矿工检测的热成像数据集，系统采集了多种采矿活动和场景的热成像数据。为评估性能，测试了包括YOLOv8、YOLOv10、YOLO11和RT-DETR在内的多种先进目标检测算法。

研究结果: 实验结果表明，热成像技术在地下矿工检测中具有可行性，数据集为开发可靠的矿工检测系统提供了基础。尽管未覆盖所有可能的紧急情况，但这是迈向实际应用的重要一步。

研究结论: 本文证明了热成像技术在地下矿工检测中的潜力，并为未来研究提供了关键的数据集和性能基准。这项工作为开发实际应急场景中的矿工检测系统奠定了基础。

中文摘要: 地下采矿作业面临重大安全挑战，这使得应急响应能力至关重要。尽管机器人在搜救行动中展现出潜力，但其效果依赖于可靠的矿工检测能力。深度学习算法为自动化矿工检测提供了潜在解决方案，但需要全面的训练数据集，而目前地下采矿环境中此类数据集尚不完善。本文提出了一种专门设计的热成像数据集，旨在支持矿工检测系统的开发与验证，以应对潜在的紧急应用。我们系统采集了多种采矿活动和场景的热成像数据，为检测算法提供了坚实的基础。为建立性能基准，我们在数据集上评估了多种先进的目标检测算法，包括YOLOv8、YOLOv10、YOLO11和RT-DETR。尽管未涵盖所有可能的紧急情况，但该数据集是开发可靠的热成像矿工检测系统的重要第一步，未来有望应用于实际应急场景。本研究表明了热成像技术用于矿工检测的可行性，并为这一关键安全应用的未来研究奠定了基础。

</details>


### [136] [Rethinking Oversaturation in Classifier-Free Guidance via Low Frequency](https://arxiv.org/abs/2506.21452)
**中文标题：基于低频信号重新思考分类器自由引导中的过饱和问题**

*Kaiyu Song,Hanjiang Lai*

主要分类: cs.CV

摘要简述: 本文提出了一种基于低频信号的新视角，认为冗余信息的积累是导致分类器自由引导（CFG）过饱和和不真实伪影的关键因素，并提出低频改进分类器自由引导（LF-CFG）来缓解这些问题。


<details>
  <summary>详细信息</summary>
研究动机: 分类器自由引导（CFG）通过高引导尺度增强条件项性能，但会导致过饱和和不真实伪影。本文旨在从低频信号的角度解决这一问题。

研究方法: 提出低频改进分类器自由引导（LF-CFG），通过自适应阈值测量定位冗余信息，分析低频信息变化率确定合理阈值，并采用降权策略减少低频信号中冗余信息的影响。

研究结果: 实验表明，LF-CFG有效缓解了包括Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5和SiT-XL在内的多种扩散模型中的过饱和和不真实伪影问题。

研究结论: LF-CFG通过低频信号分析成功解决了CFG的过饱和问题，为扩散模型的优化提供了新思路。

中文摘要: 分类器自由引导（CFG）通过引导尺度平衡条件项和无条件项的影响，高引导尺度用于增强条件项性能，但常导致过饱和和不真实伪影。本文从低频信号的角度出发，认为这些信号中冗余信息的积累是过饱和和不真实伪影的关键因素。基于此，提出低频改进分类器自由引导（LF-CFG）以缓解这些问题。具体而言，引入基于自适应阈值的测量方法定位冗余信息，通过分析低频信息在前后步骤中的变化率确定合理阈值，并采用降权策略减少低频信号中冗余信息的影响。实验结果表明，LF-CFG有效缓解了包括Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5和SiT-XL在内的多种扩散模型中的过饱和和不真实伪影问题。

</details>


### [137] [Evaluation of Traffic Signals for Daily Traffic Pattern](https://arxiv.org/abs/2506.21469)
**中文标题：日常交通模式下的交通信号评估**

*Mohammad Shokrolah Shirazi,Hung-Fu Chang*

主要分类: cs.CV

摘要简述: 本文提出动态、静态和混合三种基于转向运动计数（TMC）的交通信号配置方法，通过视觉跟踪系统估计拉斯维加斯六个交叉路口的TMC，并利用仿真评估信号性能。实验表明，90秒和120秒的信号周期效果最佳，混合方法在高峰和非高峰时段表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 转向运动计数数据对交通信号设计、交叉口几何规划及拥堵分析至关重要。本文旨在通过开发基于TMC的信号配置方法，优化交通信号管理以适应日常交通的双峰模式。

研究方法: 开发视觉跟踪系统估计六个交叉路口的TMC，合成交叉口设计、车辆运动方向和信号配置文件，导入SUMO仿真。提出动态、静态和混合信号配置方法，并通过内置交通生成器和信号设计模块生成车辆路径和信号周期。

研究结果: 实验显示90秒和120秒信号周期效果最佳；动态配置在四个交叉路口表现更好，其余两个因车辆数与车道比低而性能较差。混合方法在高峰和非高峰时段适应性更强，且区域交通分布影响信号设计选择。

研究结论: 混合信号方法能有效适应交通双峰模式，区域交通分布对信号设计有显著影响。静态方法适用于均匀分布，混合方法在东西和南北区域交通权重高时表现更优。

中文摘要: 转向运动计数数据对交通信号设计、交叉口几何规划、交通流及拥堵分析至关重要。本研究提出动态、静态和混合三种基于TMC的交通信号配置方法，开发视觉跟踪系统利用交通摄像头估计拉斯维加斯六个交叉路口的TMC。将交叉口设计、车辆运动方向及兼容格式的信号配置文件合成并导入SUMO仿真，以真实数据评估信号性能。基于等待时间的初步实验结果表明，90秒和120秒的信号周期对所有交叉路口效果最佳。此外，四个交叉路口在动态信号配置下表现更优，其余两个因车辆数与车道比低而性能较差。由于日常交通流常呈现双峰模式，提出混合信号方法，在高峰和非高峰时段动态切换静态与动态方法以优化流量管理。内置交通生成器模块生成包含高峰时段的4小时车辆路径，信号设计模块根据静态、动态和混合方法生成信号周期。各区域（西、北、东、南）的车辆计数分布权重不同，以生成多样化交通模式。对6个交叉路口进行4小时仿真的扩展实验表明，基于区域的交通模式分布影响信号设计选择。静态方法适用于区域分布均匀的情况，而混合方法在东西和南北区域交通权重高时表现更佳。

</details>


### [138] [Global and Local Entailment Learning for Natural World Imagery](https://arxiv.org/abs/2506.21476)
**中文标题：自然世界图像的全局与局部蕴含学习**

*Srikumar Sastry,Aayush Dhakal,Eric Xing,Subash Khanal,Nathan Jacobs*

主要分类: cs.CV

摘要简述: 本文提出了一种名为RCME的框架，通过显式建模传递性强制蕴含关系，优化视觉-语言模型中概念的偏序关系，从而提升层次化数据表示能力。实验表明，该框架在物种分类和检索任务中优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉-语言模型在层次化数据表示中未能显式建模蕴含关系的传递性，导致无法有效捕捉语义和顺序关系。本文旨在解决这一问题。

研究方法: 提出Radial Cross-Modal Embeddings（RCME）框架，通过优化概念的偏序关系，显式建模传递性强制蕴含关系，并构建了一个层次化视觉-语言基础模型。

研究结果: 在层次化物种分类和检索任务中，RCME框架显著优于现有方法，验证了其有效性。

研究结论: RCME框架通过显式建模传递性强制蕴含关系，成功提升了视觉-语言模型在层次化数据表示中的性能，为相关任务提供了新的解决方案。

中文摘要: 学习视觉-语言模型中数据的层次结构是一个重要挑战。以往研究尝试通过蕴含学习解决这一问题，但这些方法未能显式建模蕴含关系的传递性，而传递性在表示空间中建立了顺序与语义的关系。本文提出Radial Cross-Modal Embeddings（RCME）框架，能够显式建模传递性强制蕴含关系。该框架优化了视觉-语言模型中概念的偏序关系，并构建了一个能够表示生命树层次结构的视觉-语言基础模型。在层次化物种分类和检索任务中的实验表明，我们的模型性能优于现有最优方法。代码和模型已开源。

</details>


### [139] [TITAN: Query-Token based Domain Adaptive Adversarial Learning](https://arxiv.org/abs/2506.21484)
**中文标题：TITAN：基于查询令牌的域自适应对抗学习**

*Tajamul Ashraf,Janibul Bashir*

主要分类: cs.CV

摘要简述: 本文提出了一种基于查询令牌的域自适应对抗网络（TITAN），用于解决源数据不可用的域自适应目标检测问题。通过将目标图像分为易相似和难相似子集，并结合查询令牌对抗模块，显著提升了伪标签的可靠性，实验证明了其优于现有方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 在源数据不可用的域自适应目标检测中，现有方法依赖自监督的师生框架生成伪标签，但由于域偏差和域偏移，伪标签噪声高，导致模型性能下降。本文旨在提出一种方法，通过可靠地划分目标域并减少域间特征差异，提升伪标签质量。

研究方法: 提出TITAN方法，将目标图像分为易相似和难相似子集，利用检测方差估计划分目标域。结合查询令牌对抗模块，减少师生框架中的域间特征差异，从而生成更可靠的伪标签。

研究结果: 在四个自然图像数据集和两个医学数据集上的实验表明，TITAN显著优于现有方法，在C2F、C2B、S2C和K2C基准上的mAP分别提升了22.7%、22.2%、21.1%和3.7%。

研究结论: TITAN通过划分目标域和引入查询令牌对抗模块，有效解决了伪标签噪声问题，显著提升了域自适应目标检测的性能。

中文摘要: 我们关注源数据在自适应过程中不可用的源自由域自适应目标检测（SF-DAOD）问题，模型需适应未标记的目标域。现有方法多采用自监督的师生框架，通过源预训练模型生成伪标签进行微调。我们发现，由于域偏差、差异和显著域偏移导致的伪标签高噪声，师生模型的性能往往急剧下降。为获得可靠的伪标签，我们提出了一种基于目标的迭代查询令牌对抗网络（TITAN），将目标图像分为与源相似（易）和不相似（难）的子集。通过估计方差划分目标域，利用检测方差越高召回率越高且与源域越相似的特性。此外，我们在师生基线框架中引入查询令牌对抗模块，以减少两种特征表示间的域差距。在四个自然图像数据集和两个医学数据集上的实验验证了TITAN优于现有方法的性能，在C2F、C2B、S2C和K2C基准上的mAP分别提升了22.7%、22.2%、21.1%和3.7%。

</details>


### [140] [Towards Reliable Detection of Empty Space: Conditional Marked Point Processes for Object Detection](https://arxiv.org/abs/2506.21486)
**中文标题：面向可靠空区域检测的条件标记点过程目标检测方法**

*Tobias J. Riedlinger,Kira Maag,Hanno Gottschalk*

主要分类: cs.CV

摘要简述: 本文提出了一种基于空间统计学的目标检测模型，用于可靠检测无物体区域，解决了现有目标检测器在未检测区域不确定性量化不足的问题，特别适用于自动驾驶等安全关键场景。


<details>
  <summary>详细信息</summary>
研究动机: 现有的目标检测和分割模型虽然性能优异，但其置信度估计往往不准确，且无法量化未检测区域是否真正无物体。这在自动驾驶等应用中存在安全隐患，因此需要一种能够可靠评估空区域概率的方法。

研究方法: 本文提出了一种基于标记点过程的空间统计学框架，将边界框数据建模为点过程的实现，并通过似然训练提供明确的置信度估计，以判断区域是否无物体。

研究结果: 实验表明，该方法在校准评估和性能测试中表现优异，能够有效量化未检测区域的置信度。

研究结论: 基于空间统计学的目标检测模型能够可靠地评估空区域的概率，为自动驾驶等安全关键应用提供了更可靠的解决方案。

中文摘要: 深度神经网络在边界框检测和语义分割等计算机视觉任务中达到了最先进的性能。目标检测器和分割模型为预测分配置信度分数，反映了模型在目标检测或像素级分类中的不确定性。然而，这些置信度估计往往校准不佳，因为其架构和损失函数是针对任务性能而非概率基础设计的。即使预测校准良好，目标检测器也无法量化未检测边界框区域的不确定性，即模型未评估未检测区域是否真正无障碍物。这在自动驾驶等应用中存在安全隐患，因为空区域的不确定性未被探索。本文提出了一种基于空间统计学的目标检测模型。边界框数据匹配标记点过程的实现，标记点过程通常用于描述空间点事件（即边界框中心）的概率发生，其中标记用于描述边界框的空间扩展和类别。我们的统计框架支持基于似然的训练，并为区域是否可通行（即无物体）提供明确的置信度估计。通过校准评估和性能测试，我们证明了该方法的有效性。

</details>


### [141] [Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration](https://arxiv.org/abs/2506.21509)
**中文标题：通过动态对数校准减轻大型视觉语言模型的幻觉问题**

*Jiahe Chen,Jiaying He,Qian Shao,Qiyuan Chen,Jiahe Ying,Hongxia Xu,Jintai Chen,Jianwei Zheng,Jian Wu*

主要分类: cs.CV

摘要简述: 本文提出了一种动态对数校准（DLC）方法，通过动态调整生成文本与视觉输入的对齐，显著减少大型视觉语言模型（LVLM）的幻觉问题，同时保持高效推理。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型（LVLM）在多模态理解方面取得了显著进展，但常因生成与视觉输入矛盾的文本（幻觉）而受限。现有解码策略存在静态约束、效率低下和细节丢失等问题，亟需一种动态且高效的解决方案。

研究方法: 动态对数校准（DLC）在解码阶段逐步使用CLIP评估图像与生成文本的语义对齐，并通过相对视觉优势（RVA）动态调整候选词的对数概率，同时采用自适应权重机制平衡视觉引导与文本质量。

研究结果: 在多种基准测试和LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上的实验表明，DLC显著减少了幻觉，优于现有方法，且避免了多次前向传播，保持了高效推理。

研究结论: DLC为减少LVLM的幻觉提供了一种高效且有效的解码时解决方案，提升了模型的可靠性，适用于实际应用。

中文摘要: 大型视觉语言模型（LVLM）在多模态理解方面取得了显著进展，但其常因生成与视觉输入矛盾的文本（幻觉）而受限。现有的无需训练的解码策略存在静态约束、效率低下和细节丢失等问题。为解决这些问题，本文提出了动态对数校准（DLC），一种新颖的无需训练的解码框架，旨在推理时动态对齐文本生成与视觉证据。在解码阶段，DLC逐步使用CLIP评估输入图像与生成文本序列的语义对齐，并通过相对视觉优势（RVA）动态调整候选词的对数概率，使其倾向于视觉相关的词。此外，基于实时上下文对齐分数的自适应权重机制，在确保文本整体质量的同时平衡视觉引导。在多种基准测试和LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上的广泛实验表明，DLC显著减少了幻觉，优于现有方法，同时通过避免多次前向传播保持了高效推理。总体而言，我们提出了一种高效且有效的解码时解决方案，以减少幻觉，从而提升LVLM在实际应用中的可靠性。代码将在Github上发布。

</details>


### [142] [GGTalker: Talking Head Systhesis with Generalizable Gaussian Priors and Identity-Specific Adaptation](https://arxiv.org/abs/2506.21513)
**中文标题：GGTalker：基于通用高斯先验和身份特定适应的说话头部合成**

*Wentao Hu,Shunkai Li,Ziqiao Peng,Haoxian Zhang,Fan Shi,Xiaoqiang Liu,Pengfei Wan,Di Zhang,Hui Tian*

主要分类: cs.CV

摘要简述: GGTalker通过结合通用高斯先验和身份特定适应，解决了语音驱动3D头部合成的挑战，实现了高质量的渲染效果和训练效率。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在固定视角和小规模音频变化下表现良好，但难以应对大角度头部旋转和分布外音频，且需要耗时的身份特定训练。核心问题在于缺乏足够的3D先验，限制了合成头部的泛化能力。

研究方法: GGTalker采用两阶段训练策略：先学习高斯头部先验（音频-表情和表情-视觉先验），再通过定制化适应精确建模个体特征。引入颜色MLP生成细粒度纹理，并使用身体修复器融合背景。

研究结果: 实验表明，GGTalker在渲染质量、3D一致性、唇同步准确性和训练效率上达到最优性能。

研究结论: GGTalker通过通用先验和身份适应，显著提升了语音驱动3D头部合成的质量和泛化能力。

中文摘要: 生成高质量、泛化性强的语音驱动3D说话头部仍是一个持续挑战。现有方法在固定视角和小规模音频变化下表现良好，但难以应对大角度头部旋转和分布外音频，且需要耗时的身份特定训练。我们认为核心问题在于缺乏足够的3D先验，限制了合成头部的泛化能力。为此，我们提出GGTalker，通过结合通用先验和身份适应来合成说话头部。我们引入两阶段先验-适应训练策略，学习高斯头部先验并适应个体特征。训练音频-表情和表情-视觉先验以捕捉唇部运动的通用模式和头部纹理的总体分布。在定制化适应阶段，精确建模个体说话风格和纹理细节。此外，引入颜色MLP生成细粒度、运动对齐的纹理，并使用身体修复器融合渲染结果与背景，生成难以区分的逼真视频帧。综合实验表明，GGTalker在渲染质量、3D一致性、唇同步准确性和训练效率上达到最优性能。

</details>


### [143] [G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation](https://arxiv.org/abs/2506.21514)
**中文标题：G²D：基于梯度引导蒸馏的多模态学习增强方法**

*Mohammed Rakib,Arunkumar Bagavathi*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Gradient-Guided Distillation (G²D)的新型知识蒸馏框架，旨在解决多模态学习中的模态不平衡问题，通过动态顺序模态优先级技术优化模型，提升弱模态的利用率。


<details>
  <summary>详细信息</summary>
研究动机: 多模态学习中常出现模态不平衡问题，即某些模态主导模型优化，导致弱模态特征表达不足。本文旨在通过知识蒸馏框架解决这一问题，提升多模态模型的综合性能。

研究方法: G²D框架结合了单模态和多模态目标的自定义损失函数，并引入动态顺序模态优先级（SMP）技术，确保每个模态在训练过程中都能主导学习，避免强模态压制弱模态。

研究结果: 实验表明，G²D在多个真实数据集上显著提升了弱模态的重要性，并在分类和回归任务中优于现有方法。

研究结论: G²D通过动态模态优先级和知识蒸馏技术，有效解决了多模态学习中的模态不平衡问题，提升了模型性能。

中文摘要: 多模态学习旨在利用多样化的数据模态信息以实现更全面的性能。然而，传统的多模态模型常面临模态不平衡问题，即一个或少数模态主导模型优化，导致特征表达次优和弱模态利用不足。为解决这一问题，我们提出了梯度引导蒸馏（G²D），一种知识蒸馏框架，通过融合单模态和多模态目标的自定义损失函数优化多模态模型。G²D在学习过程中进一步引入了动态顺序模态优先级（SMP）技术，确保每个模态主导学习过程，避免强模态压制弱模态。我们在多个真实数据集上验证了G²D，结果表明G²D在训练中显著提升了弱模态的重要性，并在分类和回归任务中优于现有方法。代码已开源：https://github.com/rAIson-Lab/G2D。

</details>


### [144] [MADrive: Memory-Augmented Driving Scene Modeling](https://arxiv.org/abs/2506.21520)
**中文标题：MADrive：记忆增强的驾驶场景建模**

*Polina Karpikova,Daniil Selikhanovych,Kirill Struminsky,Ruslan Musaev,Maria Golitsyna,Dmitry Baranchuk*

主要分类: cs.CV

摘要简述: MADrive提出了一种记忆增强的驾驶场景建模框架，通过替换观测车辆为外部记忆库中的3D资产，支持高度逼真的新驾驶场景合成。


<details>
  <summary>详细信息</summary>
研究动机: 当前自动驾驶环境的场景重建方法虽然能实现高真实感建模，但难以支持显著改变或全新驾驶场景的逼真合成。MADrive旨在通过记忆增强技术扩展现有方法的场景合成能力。

研究方法: MADrive引入了一个检索模块，从大规模外部记忆库（MAD-Cars数据集）中检索视觉相似的3D车辆资产，并通过方向对齐和重新光照将其整合到目标场景中。

研究结果: 实验表明，该方法能够为场景中的车辆提供完整的多视角表示，从而实现显著改变配置的逼真合成。

研究结论: MADrive通过记忆增强技术显著提升了驾驶场景的建模能力，为自动驾驶环境的逼真合成提供了新思路。

中文摘要: 近年来，场景重建技术的进步推动了基于3D高斯散射的自动驾驶（AD）环境高真实感建模。然而，现有重建结果仍紧密依赖于原始观测数据，难以支持显著改变或全新驾驶场景的逼真合成。本文提出了MADrive，一种记忆增强的重建框架，旨在通过将观测车辆替换为从大规模外部记忆库中检索的视觉相似3D资产，扩展现有场景重建方法的能力。具体而言，我们发布了MAD-Cars数据集，这是一个包含约70K 360度野外拍摄汽车视频的精选数据集，并提出了一个检索模块，用于从记忆库中查找最相似的汽车实例，从视频中重建对应的3D资产，并通过方向对齐和重新光照将其整合到目标场景中。实验证明，替换后的车辆为场景提供了完整的多视角表示，支持显著改变配置的逼真合成。项目页面：https://yandex-research.github.io/madrive/

</details>


### [145] [WAFT: Warping-Alone Field Transforms for Optical Flow](https://arxiv.org/abs/2506.21526)
**中文标题：WAFT：用于光流的单独扭曲场变换**

*Yihan Wang,Jia Deng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为WAFT（Warping-Alone Field Transforms）的光流估计方法，通过高分辨率扭曲替代传统成本体积，实现了更高精度和更低内存消耗，挑战了传统光流方法的性能依赖成本体积的认知。


<details>
  <summary>详细信息</summary>
研究动机: 传统光流方法通常依赖成本体积构建以实现高性能，但这种方法内存消耗高且计算复杂。本文旨在探索一种更简单、高效且无需成本体积的光流估计方法。

研究方法: WAFT采用高分辨率扭曲替代成本体积，避免了传统方法的复杂设计，同时减少了内存需求。该方法是一种灵活且具有最小归纳偏置的元架构。

研究结果: WAFT在Spring和KITTI基准测试中排名第一，并在KITTI上实现了最佳零样本泛化性能，同时比性能相近的方法快4.1倍。

研究结论: WAFT通过简化设计挑战了传统光流方法的性能依赖成本体积的认知，提供了一种高效且高精度的替代方案。

中文摘要: 我们提出了单独扭曲场变换（WAFT），这是一种简单而有效的光流估计方法。WAFT与RAFT类似，但用高分辨率扭曲替代了成本体积，以更低的内存成本实现了更高的精度。这一设计挑战了传统认为构建成本体积是实现高性能的必要条件的观点。WAFT是一种简单且灵活的元架构，具有最小的归纳偏置和对定制设计的依赖。与现有方法相比，WAFT在Spring和KITTI基准测试中排名第一，在KITTI上实现了最佳零样本泛化性能，同时比性能相近的方法快4.1倍。代码和模型权重可在https://github.com/princeton-vl/WAFT获取。

</details>


### [146] [Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval](https://arxiv.org/abs/2506.21538)
**中文标题：最大匹配的重要性：防止表示崩溃以实现稳健的跨模态检索**

*Hani Alomari,Anushka Sivakumar,Andrew Zhang,Chris Thomas*

主要分类: cs.CV

摘要简述: 本文提出了一种基于最大匹配的跨模态检索方法，通过优化嵌入集之间的一对一匹配来防止表示崩溃，并结合两种损失函数提升性能，在MS-COCO和Flickr30k上实现了最优效果。


<details>
  <summary>详细信息</summary>
研究动机: 跨模态图像-文本检索面临多样关联的挑战，传统单向量嵌入方法难以捕捉多模态间的细微关系，而基于集合的方法虽能丰富表示，但仍存在稀疏监督和集合崩溃问题。

研究方法: 提出最大配对分配相似性（Maximal Pair Assignment Similarity）优化嵌入集的一对一匹配，并引入全局判别损失和集合内差异损失以增强表示多样性和防止崩溃。

研究结果: 在MS-COCO和Flickr30k数据集上实现了最先进的性能，无需依赖外部数据。

研究结论: 通过优化嵌入集匹配和引入损失函数，有效解决了跨模态检索中的表示崩溃问题，提升了性能。

中文摘要: 跨模态图像-文本检索的挑战在于不同模态内容之间多样化的关联。传统方法通过学习单向量嵌入表示每个样本的语义，但难以捕捉跨模态的细微和多样关系。基于集合的方法通过多嵌入表示样本，提供了更丰富的关联捕捉能力，但仍面临稀疏监督和集合崩溃问题。本文提出最大配对分配相似性，优化嵌入集之间的一对一匹配以保持语义多样性，并引入全局判别损失和集合内差异损失增强表示。我们的方法在MS-COCO和Flickr30k上实现了最优性能，且无需外部数据支持。

</details>


### [147] [StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning](https://arxiv.org/abs/2506.21541)
**中文标题：StruMamba3D：探索结构Mamba用于自监督点云表示学习**

*Chuxin Wang,Yixin Zha,Wenfei Yang,Tianzhu Zhang*

主要分类: cs.CV

摘要简述: 提出StruMamba3D，一种基于结构Mamba的自监督点云表示学习方法，通过保留空间依赖性和自适应序列长度策略，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的Mamba方法在点云表示学习中存在两个问题：破坏3D点的邻接关系以及无法保留长序列记忆。这些问题限制了State Space Model（SSM）的潜力。

研究方法: 设计了空间状态作为代理以保留点之间的空间依赖性；通过状态更新策略和轻量级卷积增强SSM；引入序列长度自适应策略以减少对输入长度的敏感性。

研究结果: 在四个下游任务中表现优异，ModelNet40上达到95.1%的准确率，ScanObjectNN最具挑战性的分割上达到92.75%的准确率（无投票策略）。

研究结论: StruMamba3D通过保留空间依赖性和自适应序列长度策略，显著提升了点云表示学习的性能，为自监督学习提供了新范式。

中文摘要: 近年来，基于Mamba的方法通过利用状态空间模型（SSM）的高效上下文建模能力和线性复杂度，在点云表示学习中表现出色。然而，这些方法仍面临两个关键问题：SSM处理过程中破坏3D点的邻接关系，以及随着下游任务输入长度的增加无法保留长序列记忆。为解决这些问题，我们提出了StruMamba3D，一种自监督点云表示学习的新范式。其优势包括：首先，设计空间状态作为代理以保留点之间的空间依赖性；其次，通过状态更新策略和轻量级卷积增强SSM，促进空间状态间的交互以实现高效结构建模；第三，引入序列长度自适应策略以减少预训练Mamba模型对输入长度的敏感性。在四个下游任务中的实验结果表明了该方法的优越性能。此外，我们的方法在ModelNet40上达到了95.1%的准确率，在ScanObjectNN最具挑战性的分割上达到了92.75%的准确率（无投票策略）。

</details>


### [148] [DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion](https://arxiv.org/abs/2506.21544)
**中文标题：DeOcc-1-to-3：通过自监督多视角扩散从单张图像实现3D去遮挡**

*Yansong Qu,Shaohui Dai,Xinyang Li,Yuze Wang,You Shen,Liujuan Cao,Rongrong Ji*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DeOcc-1-to-3的端到端框架，用于从单张部分遮挡图像生成六张结构一致的新视角，从而提升3D重建质量。该方法通过自监督训练和伪真实视图学习结构感知补全和视角一致性，无需人工标注或先验修复。


<details>
  <summary>详细信息</summary>
研究动机: 从单张图像重建3D物体是一个长期挑战，尤其是在真实遮挡情况下。现有基于扩散的视角合成模型通常假设输入完全可见，无法处理遮挡问题，导致视角不一致和3D重建质量下降。本文旨在解决这一问题。

研究方法: 提出了一种端到端框架，通过自监督训练利用遮挡-未遮挡图像对和伪真实视图，直接生成六张结构一致的新视角。该方法无需修改原始架构，完全微调视角合成模型以联合学习补全和多视角生成。

研究结果: 实验表明，该方法能够从部分遮挡图像生成一致的新视角，显著提升3D重建质量。同时，本文首次提出了遮挡感知重建的基准测试，涵盖多种遮挡级别、物体类别和掩码模式。

研究结论: DeOcc-1-to-3框架有效解决了单张遮挡图像下的3D重建问题，通过自监督学习和多视角生成实现了高质量结果。提出的基准测试为未来研究提供了标准化评估协议。

中文摘要: 从单张图像重建3D物体是一个长期挑战，尤其是在真实遮挡情况下。尽管最近的基于扩散的视角合成模型可以从单张RGB图像生成一致的新视角，但它们通常假设输入完全可见，在物体部分被遮挡时会失效，导致视角不一致和3D重建质量下降。为克服这一限制，我们提出了一种端到端的遮挡感知多视角生成框架。我们的方法直接从单张部分遮挡图像合成六张结构一致的新视角，无需先验修复或人工标注即可支持下游3D重建。我们利用Pix2Gestalt数据集构建了自监督训练流程，通过遮挡-未遮挡图像对和伪真实视图，教会模型结构感知补全和视角一致性。在不修改原始架构的情况下，我们完全微调了视角合成模型以联合学习补全和多视角生成。此外，我们首次提出了遮挡感知重建的基准测试，涵盖多种遮挡级别、物体类别和掩码模式。该基准为未来方法在部分遮挡下的评估提供了标准化协议。代码发布于https://github.com/Quyans/DeOcc123。

</details>


### [149] [SAM4D: Segment Anything in Camera and LiDAR Streams](https://arxiv.org/abs/2506.21547)
**中文标题：SAM4D：相机与激光雷达流中的任意分割**

*Jianyun Xu,Song Wang,Ziqian Ni,Chunyong Hu,Sheng Yang,Jianke Zhu,Qiang Li*

主要分类: cs.CV

摘要简述: SAM4D是一种多模态时序基础模型，用于相机和LiDAR流中的可提示分割。通过统一多模态位置编码（UMPE）和运动感知跨模态记忆注意力（MCMA）实现跨模态一致性和动态场景分割。其自动化数据引擎大幅提升标注效率。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶场景中，相机和LiDAR数据的多模态分割需求迫切，但现有方法在跨模态一致性和动态场景处理上存在不足。此外，人工标注效率低下，亟需自动化解决方案。

研究方法: 提出统一多模态位置编码（UMPE）对齐相机和LiDAR特征；设计运动感知跨模态记忆注意力（MCMA）增强时序一致性；开发多模态自动化数据引擎生成伪标签。

研究结果: 在Waymo-4DSeg数据集上验证了SAM4D的强大跨模态分割能力和高效数据标注潜力。

研究结论: SAM4D通过创新的多模态对齐和时序处理技术，显著提升了自动驾驶场景中的分割性能和数据标注效率。

中文摘要: 我们提出了SAM4D，一种多模态时序基础模型，用于相机和LiDAR流中的可提示分割。通过引入统一多模态位置编码（UMPE），将相机和LiDAR特征对齐到共享的3D空间，实现无缝跨模态提示和交互。此外，我们提出了运动感知跨模态记忆注意力（MCMA），利用自运动补偿增强时序一致性和长时特征检索，确保动态变化的自动驾驶场景中的鲁棒分割。为避免标注瓶颈，我们开发了一种多模态自动化数据引擎，结合VFM驱动的视频掩码、时空4D重建和跨模态掩码融合。该框架以比人工标注快数个数量级的速度生成相机-LiDAR对齐的伪标签，同时保持点云表示中VFM衍生的语义保真度。我们在构建的Waymo-4DSeg上进行了大量实验，证明了SAM4D强大的跨模态分割能力和数据标注的巨大潜力。

</details>


### [150] [SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark](https://arxiv.org/abs/2506.21549)
**中文标题：SiM3D：单实例多视角多模态多配置的3D异常检测基准**

*Alex Costanzino,Pierluigi Zama Ramirez,Luigi Lella,Matteo Ragaglia,Alessandro Oliva,Giuseppe Lisanti,Luigi Di Stefano*

主要分类: cs.CV

摘要简述: SiM3D是首个结合多视角和多模态信息的3D异常检测与分割（ADS）基准，专注于单实例异常检测场景，并首次解决从合成训练数据泛化到真实测试数据的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 制造业中对单实例异常检测的需求日益增长，但现有方法缺乏多视角和多模态数据的整合，且难以从合成数据泛化到真实数据。SiM3D旨在填补这一空白，提供全面的基准测试。

研究方法: SiM3D通过工业级传感器和机器人采集多模态多视角数据集，包括高分辨率图像和点云数据，并提供手动标注的3D分割真值。此外，还提出了基于异常体积的新评估指标，并适配了单视角方法作为基线。

研究结果: SiM3D数据集包含333个实例的八类对象数据，每类对象均配有CAD模型。实验表明，现有单视角方法在多视角任务中表现有限，突显了多视角整合的重要性。

研究结论: SiM3D为3D异常检测与分割提供了首个多视角多模态基准，解决了从合成数据到真实数据的泛化问题，为未来研究奠定了基础。

中文摘要: 我们提出了SiM3D，这是首个整合多视角和多模态信息的3D异常检测与分割（ADS）基准，任务目标是生成基于体素的异常体积。SiM3D专注于制造业中备受关注的单实例异常检测场景，即仅有一个真实或合成对象可用于训练。在这方面，SiM3D是首个解决从合成训练数据泛化到真实测试数据挑战的ADS基准。SiM3D包含一个新型多模态多视角数据集，通过顶级工业传感器和机器人采集。该数据集涵盖333个实例的八类对象，每类对象配有CAD模型，并提供多视角高分辨率图像（1200万像素）和点云（700万点）。我们还为异常测试样本提供了手动标注的3D分割真值。为建立多视角3D ADS任务的参考基线，我们适配了突出的单视角方法，并使用基于异常体积的新指标评估其性能。

</details>


### [151] [Whole-Body Conditioned Egocentric Video Prediction](https://arxiv.org/abs/2506.21552)
**中文标题：基于全身条件的自我中心视频预测**

*Yutong Bai,Danny Tran,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik*

主要分类: cs.CV

摘要简述: 该论文提出了一种基于人体动作的自我中心视角视频预测模型（PEVA），通过结合过去视频和3D身体姿态动作，模拟人类行为对环境的影响。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机是探索如何从第一人称视角模拟人类行为对环境的动态影响，解决复杂现实环境和具身代理行为的建模挑战。

研究方法: 方法包括利用Nymeria大规模数据集中的自我中心视频和身体姿态数据，训练一个自回归条件扩散变换器模型，并通过层次化评估协议分析模型的预测和控制能力。

研究结果: 结果表明，模型能够有效预测自我中心视角下的视频，并通过层次化任务验证了其具身预测和控制能力。

研究结论: 该研究为从人类视角建模复杂环境和具身行为提供了初步尝试，展示了视频预测在模拟现实世界动态中的潜力。

中文摘要: 我们训练了一种模型，用于从人类动作（PEVA）预测自我中心视角的视频，输入包括过去的视频和以相对3D身体姿态表示的动作。通过以运动学姿态轨迹为条件，并结合身体的关节层次结构，我们的模型学会了从第一人称视角模拟物理人类行为如何塑造环境。我们在Nymeria（一个大规模的真实世界自我中心视频和身体姿态捕捉数据集）上训练了一个自回归条件扩散变换器。此外，我们设计了一种层次化评估协议，包含逐渐增加难度的任务，从而全面分析模型的具身预测和控制能力。我们的工作代表了从人类视角建模复杂现实环境和具身代理行为的初步尝试。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [152] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
**中文标题：新加坡全球AI安全研究优先事项共识**

*Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić*

主要分类: cs.AI

摘要简述: 新加坡全球AI安全研究优先事项共识报告旨在通过国际合作确定AI安全研究重点，以确保AI的可信、可靠与安全。


<details>
  <summary>详细信息</summary>
研究动机: 随着AI能力的快速提升，如何确保其安全、可信和可靠成为全球关注的焦点。新加坡AI安全会议旨在通过国际合作，推动AI安全研究，构建可信的AI生态系统。

研究方法: 报告基于国际AI安全报告，采用深度防御模型，将AI安全研究领域分为三类：开发可信AI系统的挑战、评估其风险的挑战，以及部署后的监控与干预挑战。

研究结果: 报告明确了AI安全研究的三大领域，为全球AI安全研究提供了优先方向，并得到了33个政府的支持。

研究结论: 通过国际合作和深度防御模型，报告为全球AI安全研究提供了清晰的框架和优先事项，有助于推动可信AI生态系统的发展。

中文摘要: 快速提升的AI能力和自主性带来了巨大的变革潜力，但也引发了如何确保AI安全（即可信、可靠和安全的）的激烈讨论。构建一个可信的生态系统至关重要——它有助于人们自信地接受AI，并在避免反弹的同时为创新提供最大空间。

“2025年新加坡AI会议（SCAI）：AI安全国际科学交流”旨在通过汇集全球AI科学家，确定并整合AI安全研究的优先事项，支持这一领域的研究。本报告基于由Yoshua Bengio主持、33个政府支持的国际AI安全报告，采用深度防御模型，将AI安全研究领域分为三类：开发可信AI系统的挑战（开发）、评估其风险的挑战（评估），以及部署后的监控与干预挑战（控制）。

</details>


### [153] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
**中文标题：MAGPIE：一个用于多智能体上下文隐私评估的数据集**

*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

主要分类: cs.AI

摘要简述: 本文提出了一个名为MAGPIE的数据集，用于评估多智能体系统中的上下文隐私保护能力。研究发现，当前先进的LLM（如GPT-4o和Claude-2.7-Sonnet）在理解上下文隐私方面表现不佳，且在明确隐私指令下仍频繁泄露隐私信息。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于LLM的智能体在多任务协作（如调度、谈判、资源分配等）中的广泛应用，隐私保护变得至关重要。然而，现有评估基准主要关注单轮、低复杂度任务，无法全面评估多轮对话中的隐私保护能力。因此，本文旨在填补这一空白，研究LLM智能体是否能在非对抗性多轮对话中理解并保护上下文隐私。

研究方法: 本文首先提出了MAGPIE数据集，包含158个高风险现实场景，覆盖15个领域。这些场景设计为：完全排除隐私数据会阻碍任务完成，而无限制共享则可能导致重大损失。随后，评估了当前最先进的LLM在（a）理解上下文隐私数据的能力和（b）在不侵犯隐私的情况下协作的能力。

研究结果: 实验结果表明，当前模型（如GPT-4o和Claude-2.7-Sonnet）对上下文隐私的理解不足，分别有25.2%和43.6%的隐私数据被错误分类为可共享。在多轮对话中，即使有明确隐私指令，这些模型仍分别有59.9%和50.5%的案例泄露隐私信息。此外，多智能体系统在71%的场景中无法完成任务。

研究结论: 当前模型在上下文隐私保护和协作任务解决方面表现不佳，亟需改进。MAGPIE数据集为未来研究提供了重要基准。

中文摘要: 基于LLM的智能体的普及使得多智能体协作（如调度、谈判、资源分配等）日益增多。在此类系统中，隐私至关重要，因为智能体常需访问专有工具和领域特定数据库，要求严格保密。本文探讨了LLM智能体是否理解上下文隐私，以及在被指示时，这些系统是否能在非对抗性多轮对话中保护推理阶段的用户隐私。现有的评估基准主要针对单轮、低复杂度任务，隐私信息易被排除。我们首先提出了MAGPIE基准，包含158个现实高风险场景，覆盖15个领域。这些场景设计为：完全排除隐私数据会阻碍任务完成，而无限制共享则可能导致重大损失。随后，我们评估了当前最先进LLM在（a）理解上下文隐私数据的能力和（b）在不侵犯隐私的情况下协作的能力。实证实验表明，当前模型（包括GPT-4o和Claude-2.7-Sonnet）对上下文隐私的理解不足，分别有25.2%和43.6%的隐私数据被错误分类为可共享。在多轮对话中，即使有明确隐私指令，这些模型仍分别有59.9%和50.5%的案例泄露隐私信息。此外，多智能体系统在71%的场景中无法完成任务。这些结果表明，当前模型在上下文隐私保护和协作任务解决方面未达到理想水平。

</details>


### [154] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
**中文标题：领域特定AI应用的动态上下文感知提示推荐**

*Xinye Tang,Haijun Zhai,Chaitanya Belwal,Vineeth Thayanithi,Philip Baumann,Yogesh K Roy*

主要分类: cs.AI

摘要简述: 本文提出了一种动态上下文感知的提示推荐系统，用于领域特定的AI应用，通过结合上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，生成相关且可操作的提示建议。


<details>
  <summary>详细信息</summary>
研究动机: 由于LLM驱动的应用对用户提示质量高度敏感，而领域特定应用中高质量提示的编写尤为困难，因此需要一种动态且上下文感知的提示推荐系统来提升用户体验和效果。

研究方法: 系统结合了上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，利用行为遥测和两阶段分层推理动态选择和排序相关技能，并通过预定义和自适应模板结合少量样本学习生成提示。

研究结果: 在真实数据集上的实验表明，该方法在自动化和专家评估中均表现出高实用性和相关性。

研究结论: 动态上下文感知提示推荐系统能有效提升领域特定AI应用中提示的质量和实用性，为LLM驱动的应用提供了重要支持。

中文摘要: LLM驱动的应用对用户提示质量高度敏感，而在领域特定应用中编写高质量提示尤为困难。本文提出了一种新颖的动态上下文感知提示推荐系统，用于领域特定的AI应用。我们的解决方案结合了上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，以生成相关且可操作的提示建议。系统利用行为遥测和两阶段分层推理动态选择和排序相关技能，并通过预定义和自适应模板结合少量样本学习生成提示。在真实数据集上的实验表明，我们的方法在自动化和专家评估中均表现出高实用性和相关性。

</details>


### [155] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
**中文标题：超越被动安全：通过长期模拟实现风险感知的语言模型对齐**

*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

主要分类: cs.AI

摘要简述: 本文提出了一种通过长期模拟评估语言模型风险意识的框架，旨在提高其对社会决策的安全性影响。新数据集和实验表明，该方法在长期安全性和现有基准测试中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于语言模型的代理在高风险社会决策（如公共政策和医疗）中的影响日益增加，确保其建议的长期安全性变得至关重要。现有方法多关注即时反应，而忽视了潜在的长远影响。

研究方法: 提出了一种概念验证框架，通过宏观时间尺度模拟模型建议在社会系统中的传播，以评估其长期安全性。同时，引入了一个包含100个间接危害场景的数据集，测试模型对看似无害提示的潜在负面结果的预见能力。

研究结果: 该方法在新数据集上实现了超过20%的性能提升，并在现有安全基准测试（AdvBench、SafeRLHF、WildGuardMix）中平均胜率超过70%，显著优于基线方法。

研究结论: 该研究为语言模型的安全对齐提供了一种新方向，通过长期模拟和间接危害评估，显著提升了模型的安全意识和社会适应性。

中文摘要: 随着基于语言模型的代理在高风险社会决策（从公共政策到医疗）中的影响力日益增强，确保其有益影响需要理解其建议的深远意义。我们提出了一种概念验证框架，通过宏观时间尺度模拟模型生成建议在社会系统中的传播，以实现更稳健的对齐。为了评估语言模型的长期安全意识，我们还引入了一个包含100个间接危害场景的数据集，测试模型对看似无害用户提示可能导致的非明显负面结果的预见能力。我们的方法不仅在新数据集上实现了超过20%的性能提升，还在现有安全基准测试（AdvBench、SafeRLHF、WildGuardMix）中平均胜率超过70%，为更安全的代理提供了一条有前景的路径。

</details>


### [156] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
**中文标题：揭示大型语言模型中的因果推理：现实还是幻象？**

*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

主要分类: cs.AI

摘要简述: 研究发现大型语言模型（LLMs）仅能进行浅层（level-1）因果推理，缺乏人类深层次（level-2）推理能力。通过新基准测试CausalProbe-2024验证了这一结论，并提出G^2-Reasoner方法，结合通用知识和目标导向提示，显著提升了LLMs的因果推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLMs）虽表现出因果推理能力，但其真实性存疑。研究旨在验证LLMs是否具备类似人类的深层次因果推理能力，并探索提升其推理能力的方法。

研究方法: 通过分析LLMs的自回归机制，揭示其非因果性；设计新基准测试CausalProbe-2024，验证LLMs的推理能力；提出G^2-Reasoner方法，结合通用知识和目标导向提示，增强LLMs的因果推理能力。

研究结果: LLMs在CausalProbe-2024上表现显著下降，表明其仅具备浅层推理能力；G^2-Reasoner方法显著提升了LLMs在新颖和反事实情境中的推理能力。

研究结论: LLMs当前仅能进行浅层因果推理，但通过结合通用知识和目标导向提示，可显著提升其推理能力，为迈向深层次推理提供了新路径。

中文摘要: 因果推理能力对推动大型语言模型（LLMs）迈向强人工智能至关重要。尽管多功能LLMs似乎展现了理解上下文因果关系的能力，但其是否具备类似人类的真实因果推理能力尚不明确。现有证据表明，LLMs仅能进行浅层（level-1）因果推理，主要依赖于参数中嵌入的因果知识，而缺乏人类深层次（level-2）推理能力。为验证这一假设，本研究从方法上分析了基于Transformer的LLMs的自回归机制，揭示其非因果性；实证上，提出了新因果问答基准CausalProbe-2024，其语料对测试LLMs几乎全新。LLMs在CausalProbe-2024上的表现显著低于早期基准，表明其仅能进行level-1推理。为缩小与level-2推理的差距，受人类推理通常依赖通用知识和目标意图的启发，提出了G^2-Reasoner方法，将通用知识和目标导向提示融入LLMs的因果推理过程。实验表明，G^2-Reasoner显著提升了LLMs在新颖和反事实情境中的推理能力。本研究为LLMs迈向真实因果推理提供了新路径，超越level-1，向level-2迈进。

</details>


### [157] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
**中文标题：增强大型视觉语言模型规划能力的全局感知叙事方法**

*Junhao Shi,Zhaoye Fei,Siyin Wang,Qipeng Guo,Jingjing Gong,Xipeng QIu*

主要分类: cs.AI

摘要简述: 本文提出了一种名为WAP的框架，通过增强大型视觉语言模型（LVLM）的环境理解能力，显著提升了其在复杂场景中的规划能力。该方法通过四种认知能力（视觉外观建模、空间推理、功能抽象和语法基础）和课程学习，使模型在EB-ALFRED基准测试中任务成功率大幅提升。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大型视觉语言模型在复杂场景和长时程规划任务中表现不佳，主要原因是其缺乏对环境上下文的理解，导致依赖额外提示而非视觉推理。本文旨在通过增强模型的环境认知能力，解决这一问题。

研究方法: 提出World-Aware Planning Narrative Enhancement（WAP）框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和语法基础）和课程学习，仅使用原始视觉观察数据训练和评估模型。

研究结果: 在EB-ALFRED基准测试中，Qwen2.5-VL模型的任务成功率提升了60.7%，尤其在常识推理（+60.0）和长时程规划（+70.0）方面表现突出，显著优于GPT-4o和Claude-3.5-Sonnet等专有系统。

研究结论: WAP框架通过增强LVLM的环境理解能力，显著提升了其在复杂规划任务中的表现，证明了环境认知能力对模型性能的重要性。

中文摘要: 大型视觉语言模型（LVLM）在具身规划任务中表现出潜力，但在涉及陌生环境和多步目标的复杂场景中表现不佳。当前方法依赖与环境无关的模仿学习，导致指令与环境上下文脱节，使模型难以处理上下文敏感指令，并在长时程交互中依赖额外提示而非视觉推理。本文提出World-Aware Planning Narrative Enhancement（WAP）框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和语法基础）和课程学习，仅使用原始视觉观察数据增强LVLM的环境理解能力。在EB-ALFRED基准测试中，Qwen2.5-VL的任务成功率提升了60.7%，尤其在常识推理（+60.0）和长时程规划（+70.0）方面表现突出。值得注意的是，我们的增强开源模型大幅优于GPT-4o和Claude-3.5-Sonnet等专有系统。

</details>


### [158] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
**中文标题：IXAII：一种用于决策支持系统的交互式可解释人工智能界面**

*Pauline Speckmann,Mario Nadj,Christian Janiesch*

主要分类: cs.AI

摘要简述: 本文介绍了一种名为IXAII的交互式可解释人工智能系统，通过整合LIME、SHAP、Anchors和DiCE四种方法，为用户提供定制化的解释视图，并通过专家和普通用户的访谈验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的可解释AI方法多为静态且忽视用户视角，限制了其实际效果。本文旨在开发一种交互式系统，通过多方法整合和用户定制化功能，提升AI的透明度和用户体验。

研究方法: 开发了IXAII系统，整合了LIME、SHAP、Anchors和DiCE四种可解释AI方法，支持五种用户群体的定制化视图，并允许用户控制解释内容和格式。通过专家和普通用户的访谈进行系统评估。

研究结果: 评估结果表明，IXAII通过提供多样化的解释和可视化选项，显著提升了用户对AI透明度的感知，被认为是一种有效的决策支持工具。

研究结论: IXAII通过结合可解释AI方法、交互性和实际应用，为AI解释实践和人机交互提供了新的视角。

中文摘要: 尽管已经开发了多种后验可解释AI方法，但大多数是静态的且忽视了用户视角，限制了其对目标受众的有效性。为此，我们开发了一种名为IXAII的交互式可解释智能系统，该系统提供了来自四种可解释AI方法（LIME、SHAP、Anchors和DiCE）的解释。我们的原型为五种用户群体提供了定制化视图，并赋予用户对解释内容和格式的控制权。我们通过专家和普通用户的访谈对IXAII进行了评估。结果表明，IXAII通过提供多样化的解释和多种可视化选项，被认为有助于提高透明度。通过弥合可解释AI方法、交互性和实际实施之间的差距，我们为AI解释实践和人机交互提供了新的视角。

</details>


### [159] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
**中文标题：用于科学发现的主动推理人工智能系统**

*Karthik Duraisamy*

主要分类: cs.AI

摘要简述: 本文提出了一种基于主动推理的AI系统，旨在通过填补抽象、推理和现实三大鸿沟，推动科学发现。系统结合因果自监督模型、贝叶斯规划器和闭环实验验证，强调人类判断的不可或缺性。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI系统在科学发现中存在局限性，如架构僵化、推理脆弱及与现实脱节。本文旨在通过解决抽象、推理和现实三大鸿沟，构建更高效的AI驱动科学发现系统。

研究方法: 提出主动推理AI系统，包括：1) 基于因果自监督的长期研究记忆；2) 配备贝叶斯防护的符号或神经符号规划器；3) 动态知识图谱构建；4) 通过闭环实验和高保真模拟优化内部表征。

研究结果: 该系统通过结合内部模型的反事实推理和外部实验验证，能够更有效地生成科学假设并验证其真实性，同时强调人类判断在系统中的永久性作用。

研究结论: 主动推理AI系统通过填补三大鸿沟，为科学发现提供了新路径。系统的成功依赖于内部模型与外部现实的动态交互，以及人类判断的持续参与。

中文摘要: 人工智能的快速发展引发了对其推动科学变革的期待，但现有系统仍受限于其操作架构、脆弱的推理机制及与实验现实的脱节。基于前期研究，我们认为AI驱动科学的进步取决于填补三大根本鸿沟——抽象鸿沟、推理鸿沟和现实鸿沟，而非模型规模、数据或计算时间。科学推理需要支持行动与响应模拟的内部表征、区分相关性与机制的因果结构，以及持续校准。我们定义用于科学发现的主动推理AI系统为：1) 基于因果自监督的长期研究记忆；2) 配备贝叶斯防护的符号或神经符号规划器；3) 动态知识图谱，其中思考生成新概念节点，推理建立因果边，现实交互修剪错误连接并强化已验证路径；4) 通过闭环实验和高保真模拟优化内部表征——这一操作循环中，心理模拟指导行动，实证意外重塑理解。本质上，我们提出了一种架构，其中发现源于支持反事实推理的内部模型与将假设扎根于现实的外部验证之间的互动。同时指出，模拟与实验反馈的固有模糊性及潜在不确定性使人类判断不可或缺，不仅是临时支架，而是永久性组成部分。

</details>


### [160] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
**中文标题：TableMoE：多模态表格理解中结构化专家推理的神经符号路由**

*Junwen Zhang,Pu Chen,Yin Zhang*

主要分类: cs.AI

摘要简述: TableMoE提出了一种神经符号混合专家架构，通过动态路由和符号推理图提升多模态表格理解的鲁棒性和泛化能力，显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有多模态大语言模型在复杂表格结构（如模糊、倾斜、嵌套布局等）下表现不佳，泛化能力有限，亟需一种能够处理这些挑战的新方法。

研究方法: TableMoE采用神经符号路由机制，预测表格元素的语义角色并动态路由至专用专家（如Table-to-HTML、Table-to-JSON等），结合符号推理图和大规模预训练数据集TableMoE-Align。

研究结果: 实验表明，TableMoE在WildStruct基准测试中显著优于现有模型，并通过消融研究验证了神经符号路由和专家对齐的核心作用。

研究结论: TableMoE通过神经符号推理有效提升了多模态表格理解的鲁棒性和可解释性，为复杂表格处理提供了新思路。

中文摘要: 现实场景中多模态表格的理解因结构复杂性、符号密度和视觉退化（如模糊、倾斜、水印、不完整结构或字体、多跨度或分层嵌套布局）而极具挑战性。现有多模态大语言模型（MLLMs）在WildStruct条件下表现不佳，泛化能力有限。为解决这些问题，我们提出了TableMoE，一种专为多模态表格数据设计的神经符号混合连接专家（MoCE）架构，具有鲁棒的结构化推理能力。TableMoE的创新神经符号路由机制通过符号推理图预测潜在语义标记角色（如标题、数据单元格、轴、公式），并动态路由表格元素至专用专家（Table-to-HTML、Table-to-JSON、Table-to-Code）。为支持有效的对齐驱动预训练，我们引入了大规模数据集TableMoE-Align，包含120万表格-HTML-JSON-代码四元组，涵盖金融、科学、生物医学和工业领域。为评估模型，我们发布四个WildStruct基准测试：WMMFinQA、WMMTatQA、WMMTabDialog和WMMFinanceMath，专门测试模型在真实多模态退化和结构复杂性下的表现。实验结果表明，TableMoE显著优于现有最先进模型。消融研究验证了神经符号路由和结构化专家对齐的核心作用。定性分析进一步展示了TableMoE的可解释性和增强的鲁棒性，凸显了神经符号推理在多模态表格理解中的有效性。

</details>


### [161] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
**中文标题：基于有限视角的空间心理建模**

*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

主要分类: cs.AI

摘要简述: 本文研究了视觉语言模型（VLMs）能否像人类一样通过有限视角构建完整场景的空间心理模型。通过MindCube基准测试，发现现有VLMs表现接近随机水平。提出“先映射后推理”方法，结合认知地图和强化学习，将准确率从37.8%提升至70.7%。


<details>
  <summary>详细信息</summary>
研究动机: 人类能够通过有限视角构建空间心理模型，而现有视觉语言模型（VLMs）在此能力上表现不足。本文旨在填补这一关键差距，探索如何帮助VLMs构建和利用空间心理模型，以提升对不可见空间的理解能力。

研究方法: 1. 提出MindCube基准测试，包含21,154个问题和3,268张图像，用于评估VLMs的空间心理建模能力。2. 探索三种方法：生成未见的中间视角、自然语言推理链和认知地图。3. 提出“先映射后推理”方法，联合训练模型生成认知地图并基于其推理。4. 引入强化学习进一步提升性能。

研究结果: 通过“先映射后推理”方法，模型准确率从37.8%提升至60.8%（+23.0%）。结合强化学习后，准确率进一步提升至70.7%（+32.9%）。

研究结论: 本文表明，通过构建和利用内部结构化空间表示（如认知地图）并结合灵活的推理过程，可以显著提升VLMs对不可见空间的理解能力。这一发现为未来空间心理建模研究提供了重要方向。

中文摘要: 视觉语言模型（VLMs）能否像人类一样通过有限视角想象完整场景？人类通过构建空间心理模型（对不可见空间的内部表征）来推理布局、视角和运动。我们提出的MindCube基准测试包含21,154个问题和3,268张图像，揭示了现有VLMs在此能力上的关键差距，其表现接近随机水平。通过MindCube，我们系统评估了VLMs在构建空间心理模型方面的能力，包括位置表征（认知映射）、方向推理（视角转换）和动态模拟（“假设”运动的心理模拟）。随后，我们探索了三种方法帮助VLMs近似空间心理模型，包括生成未见的中间视角、自然语言推理链和认知地图。显著改进来自一种协同方法——“先映射后推理”，即联合训练模型首先生成认知地图，然后基于其进行推理。通过训练模型在这些内部地图上推理，准确率从37.8%提升至60.8%（+23.0%）。结合强化学习后，性能进一步提升至70.7%（+32.9%）。我们的核心发现是，这种空间心理模型的“脚手架”方法——主动构建和利用内部结构化空间表示并结合灵活的推理过程——显著提升了对不可见空间的理解能力。

</details>


### [162] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
**中文标题：Ad-Hoc人类-AI协调挑战**

*Tin Dizdarević,Ravi Hammond,Tobias Gessler,Anisoara Calinescu,Jonathan Cook,Matteo Gallici,Andrei Lupu,Jakob Nicolaus Foerster*

主要分类: cs.AI

摘要简述: 本文提出了Ad-Hoc Human-AI Coordination Challenge（AH2AC2），旨在解决AI与人类协调中的评估难题，通过开发人类代理代理作为廉价且可复现的评估伙伴，并开源有限的人类游戏数据集。


<details>
  <summary>详细信息</summary>
研究动机: AI与人类的无缝协调在现实应用中至关重要，但目前仍是一个开放挑战。Hanabi游戏因其不完美信息、有限通信和协同行动等特点成为理想测试平台，但人类评估的高成本和难以复现限制了其应用。

研究方法: 作者开发了基于大规模人类数据集的人类代理代理，作为廉价且可复现的评估伙伴，并开源了3,079局游戏数据集，限制可用数据以鼓励高效方法开发。同时，通过受控评估系统确保公平性。

研究结果: 研究提供了两玩家和三玩家Hanabi场景的基线结果，并通过受控系统托管代理代理以确保公平评估。

研究结论: AH2AC2通过人类代理代理和有限数据集解决了人类评估的难题，为AI与人类协调研究提供了廉价且可复现的测试平台。

中文摘要: 实现AI代理与人类的无缝协调对现实应用至关重要，但这仍是一个重大开放挑战。Hanabi是一款合作卡牌游戏，具有不完美信息、有限通信、心智理论需求和协同行动等特点，是研究人类-AI协调的理想测试平台。然而，人类评估的高成本和难以复现限制了其在人类-AI交互中的应用。本研究提出了Ad-Hoc Human-AI Coordination Challenge（AH2AC2），以克服这些限制。我们基于大规模人类数据集开发了人类代理代理，作为AH2AC2中廉价、可复现且稳健的人类评估伙伴。为鼓励数据高效方法的开发，我们开源了3,079局游戏数据集，并故意限制可用的人类游戏数据量。我们展示了两玩家和三玩家Hanabi场景的基线结果。为确保公平评估，我们通过受控评估系统托管代理代理，而非公开释放。代码可在https://github.com/FLAIROx/ah2ac2获取。

</details>


### [163] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
**中文标题：Mind2Web 2：基于Agent-as-a-Judge的自主搜索评估**

*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

主要分类: cs.AI

摘要简述: 本文介绍了Mind2Web 2，一个包含130个高质量、长周期任务的基准测试，用于评估自主网络搜索系统的性能。提出了Agent-as-a-Judge框架，通过任务特定的评判代理自动评估答案正确性和来源标注。结果显示，最佳系统OpenAI Deep Research已达到人类性能的50-70%，且耗时减半。


<details>
  <summary>详细信息</summary>
研究动机: 随着自主网络搜索系统（如Deep Research）的复杂性增加，现有评估方法无法满足长周期、动态答案的需求。因此，需要一个新的基准和评估框架来推动下一代自主搜索系统的发展。

研究方法: 构建了Mind2Web 2基准，包含130个长周期任务，耗时超过1,000小时人工标注。提出Agent-as-a-Judge框架，基于树状评分标准设计任务特定的评判代理，自动评估答案正确性和来源标注。

研究结果: 对九种前沿自主搜索系统和人类表现进行了全面评估。最佳系统OpenAI Deep Research达到人类性能的50-70%，且耗时仅为人类的一半。

研究结论: Mind2Web 2为下一代自主搜索系统的开发和评估提供了严格基础，展示了自主搜索系统的巨大潜力。

中文摘要: 自主搜索（如Deep Research系统）通过大型语言模型自主浏览网络、综合信息并返回引用支持的全面答案，代表了用户与网络规模信息交互方式的重大转变。尽管其有望提高效率和减轻认知负担，但自主搜索的复杂性和开放性已超越现有评估基准和方法，这些方法大多假设短周期搜索和静态答案。本文介绍了Mind2Web 2，一个包含130个高质量、长周期任务的基准测试，需要实时网络浏览和广泛信息综合，耗时超过1,000小时人工标注。为应对动态复杂答案的评估挑战，我们提出了新颖的Agent-as-a-Judge框架。该方法基于树状评分标准设计任务特定的评判代理，自动评估答案正确性和来源标注。我们对九种前沿自主搜索系统和人类表现进行了全面评估，并通过详细错误分析为未来发展提供见解。表现最佳的系统OpenAI Deep Research已达到人类性能的50-70%，且耗时减半，显示出巨大潜力。总之，Mind2Web 2为下一代自主搜索系统的开发和评估提供了严格基础。

</details>


### [164] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
**中文标题：PsyLite技术报告**

*Fangjun Ding,Renyu Zhang,Xinyu Feng,Chengye Xie,Zheng Zhang,Yanting Zhang*

主要分类: cs.AI

摘要简述: 本研究提出PsyLite，一种基于InternLM2.5-7B-chat开发的轻量级心理咨询大语言模型代理，通过混合蒸馏数据微调和ORPO偏好优化的两阶段训练策略，提升模型推理能力、心理咨询能力和对话安全性，并在资源受限环境中实现低硬件部署。


<details>
  <summary>详细信息</summary>
研究动机: 随着数字技术的快速发展，AI驱动的心理咨询成为心理健康领域的重要研究方向，但现有模型在对话安全、场景细节处理和轻量级部署方面存在不足。

研究方法: 采用两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），结合Ollama和Open WebUI部署，设计条件RAG引入幽默元素并拒绝危险请求，使用量化技术（GGUF q4_k_m）实现低硬件需求。

研究结果: PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中优于基线模型，心理咨询专业性提升47.6%，对话安全性提升2.4%，且仅需5GB内存即可运行。

研究结论: PsyLite为资源受限环境中的心理咨询应用提供了可行的轻量级解决方案，显著提升了模型的专业性和安全性。

中文摘要: 随着数字技术的快速发展，AI驱动的心理咨询逐渐成为心理健康领域的重要研究方向。然而，现有模型在对话安全性、场景细节处理和轻量级部署方面仍存在不足。为解决这些问题，本研究提出PsyLite，一种基于InternLM2.5-7B-chat开发的轻量级心理咨询大语言模型代理。通过两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），PsyLite提升了模型的深度推理能力、心理咨询能力和安全对话能力。部署时使用Ollama和Open WebUI，并通过Pipelines创建自定义工作流。设计了一种创新的条件RAG，在心理咨询过程中适时引入幽默元素以提升用户体验，并拒绝危险请求以增强对话安全性。评估结果显示，PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中优于基线模型，尤其是在心理咨询专业性（CPsyCounE得分提升47.6%）和对话安全性（SafeDialBench得分提升2.4%）方面表现突出。此外，模型采用量化技术（GGUF q4_k_m）实现低硬件部署（仅需5GB内存即可运行），为资源受限环境中的心理咨询应用提供了可行的解决方案。

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [165] [Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation](https://arxiv.org/abs/2506.21154)
**中文标题：基于Transformer的时空反事实结果估计**

*He Li,Haoang Chi,Mingyu Liu,Wanrong Huang,Liyang Xu,Wenjing Yang*

主要分类: stat.ME

摘要简述: 本文提出了一种基于Transformer的时空反事实结果估计框架，相比传统统计模型具有更强的估计能力和泛化性，并通过仿真和真实数据实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界具有时空维度，而现有反事实结果估计方法基于传统统计模型，性能和泛化性有限。本文旨在利用Transformer提升时空反事实结果的估计能力。

研究方法: 提出了一种基于Transformer的时空反事实结果估计框架，其估计器在温和假设下具有一致性和渐近正态性。通过仿真和真实数据（如哥伦比亚森林损失与冲突的因果关系）验证方法。

研究结果: 仿真实验表明，该估计器优于基线方法；真实数据实验揭示了冲突对哥伦比亚森林损失的因果影响。

研究结论: 本文提出的Transformer框架在时空反事实结果估计中表现优异，为因果推断提供了新工具。

中文摘要: 现实世界天然具有时间和空间维度，因此估计具有时空属性的反事实结果是一个关键问题。然而，现有方法基于经典统计模型，在性能和泛化性上仍存在局限。本文提出了一种利用Transformer估计时空反事实结果的新框架，展现出更强的估计能力。在温和假设下，该框架内的估计器具有一致性和渐近正态性。为验证方法的有效性，我们进行了仿真实验和真实数据实验。仿真实验表明，该估计器比基线方法具有更强的估计能力；真实数据实验为冲突对哥伦比亚森林损失的因果效应提供了有价值的结论。源代码可在https://github.com/lihe-maxsize/DeppSTCI_Release_Version-master获取。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [166] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
**中文标题：基于几何感知扩散和时间视频模型的一致性零样本3D纹理合成**

*Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik*

主要分类: cs.GR

摘要简述: VideoTex是一种新颖的3D纹理合成框架，利用视频生成模型解决空间和时间不一致性问题，通过几何感知条件和结构UV扩散策略，生成高质量、时间稳定的纹理。


<details>
  <summary>详细信息</summary>
研究动机: 现有纹理合成方法因缺乏全局上下文和几何理解，导致纹理在固定视角下不一致。视频生成模型在时间一致性方面表现出色，因此提出VideoTex框架以解决3D纹理的空间和时间不一致问题。

研究方法: VideoTex结合几何感知条件，精确利用3D网格结构，并提出结构UV扩散策略，通过保留语义信息增强遮挡区域的生成，实现更平滑和连贯的纹理。

研究结果: 实验表明，VideoTex在纹理保真度、接缝融合和时间稳定性方面优于现有方法，适用于动态实时应用。

研究结论: VideoTex通过几何感知和结构UV扩散策略，显著提升了3D纹理合成的质量和时间一致性，为动态实时应用提供了新可能。

中文摘要: 当前纹理合成方法因缺乏全局上下文和几何理解，导致在固定视角下生成的纹理存在不一致性。与此同时，视频生成模型在实现时间一致性方面取得了显著成功。本文提出VideoTex，一种新颖的无缝纹理合成框架，利用视频生成模型解决3D纹理的空间和时间不一致问题。我们的方法结合几何感知条件，精确利用3D网格结构，并提出结构UV扩散策略，通过保留语义信息增强遮挡区域的生成，从而生成更平滑和连贯的纹理。VideoTex不仅在UV边界上实现了平滑过渡，还确保了视频帧间的高质量、时间稳定的纹理。大量实验表明，VideoTex在纹理保真度、接缝融合和稳定性方面优于现有方法，为需要视觉质量和时间一致性的动态实时应用铺平了道路。

</details>


### [167] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
**中文标题：生成式积木世界：在图片中移动物体**

*Vaibhav Vavilala,Seemandhar Jain,Rahul Vasanth,D. A. Forsyth,Anand Bhattad*

主要分类: cs.GR

摘要简述: 本文提出了一种通过操作简单几何抽象来编辑生成图像场景的方法，利用3D基元表示场景，并通过流式生成方法实现高保真图像编辑。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在图像编辑中难以同时保持纹理一致性和对象身份，本文旨在通过几何抽象和纹理提示技术解决这一问题。

研究方法: 将场景表示为3D凸基元的组合，支持不同数量的基元表示同一场景；通过流式生成方法结合深度和纹理提示生成编辑后的图像。

研究结果: 实验表明，该方法在视觉保真度、可编辑性和组合泛化能力上优于现有技术。

研究结论: 通过几何抽象和纹理提示技术，实现了高保真且灵活的图像场景编辑。

中文摘要: 我们描述了生成式积木世界，通过操作简单的几何抽象来编辑生成图像中的场景。我们的方法将场景表示为3D凸基元的组合，同一场景可以用不同数量的基元表示，从而支持编辑整体结构或细节。编辑场景几何后，通过基于流的方法结合深度和纹理提示生成图像。我们的纹理提示考虑了修改后的3D基元，超越了现有键值缓存技术提供的纹理一致性。这些纹理提示（a）支持精确的对象和相机移动，（b）很大程度上保留了对象的身份。定量和定性实验表明，我们的方法在视觉保真度、可编辑性和组合泛化能力上优于现有技术。

</details>


### [168] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
**中文标题：3DGH：具有可组合头发和脸部的3D头部生成**

*Chengan He,Junxuan Li,Tobias Kirschstein,Artem Sevastopolsky,Shunsuke Saito,Qingyang Tan,Javier Romero,Chen Cao,Holly Rushmeier,Giljoo Nam*

主要分类: cs.GR

摘要简述: 3DGH是一种无条件生成3D人头模型的方法，通过分离头发和脸部的建模，使用基于模板的3D高斯散射表示，并结合双生成器和交叉注意力机制，实现了可组合的头发和脸部编辑。


<details>
  <summary>详细信息</summary>
研究动机: 以往的研究通常将头发和脸部的建模混为一谈，限制了模型的灵活性和编辑能力。3DGH旨在通过分离这两部分的建模，提供更灵活和可控的3D人头生成方法。

研究方法: 3DGH采用基于模板的3D高斯散射数据表示，引入可变形头发几何体以捕捉不同发型的几何变化。模型设计为基于3D GAN的双生成器架构，并利用交叉注意力机制建模头发与脸部的内在关联。通过精心设计的训练目标，使用合成渲染数据进行训练。

研究结果: 实验表明，3DGH在无条件全头图像合成和可组合3D发型编辑方面优于现有方法，验证了其设计选择的有效性。

研究结论: 3DGH通过分离头发和脸部的建模，结合创新的数据表示和模型架构，实现了高质量的3D人头生成和编辑，为相关领域提供了新的解决方案。

中文摘要: 我们提出了3DGH，一种无条件生成具有可组合头发和脸部组件的3D人头模型的方法。与以往将头发和脸部建模混为一谈的研究不同，我们提出通过基于模板的3D高斯散射数据表示分离这两部分，其中引入可变形头发几何体以捕捉不同发型的几何变化。基于此数据表示，我们设计了一种基于3D GAN的双生成器架构，并采用交叉注意力机制建模头发与脸部的内在关联。模型通过精心设计的训练目标在合成渲染数据上进行训练，以稳定训练并促进头发与脸部的分离。我们进行了大量实验验证3DGH的设计选择，并通过与多种先进3D GAN方法的定性和定量比较，证明了其在无条件全头图像合成和可组合3D发型编辑方面的有效性。更多细节请访问项目页面：https://c-he.github.io/projects/3dgh/。

</details>


### [169] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
**中文标题：FairyGen：从单一儿童绘制角色生成故事卡通视频**

*Jiayi Zheng,Xiaodong Cun*

主要分类: cs.GR

摘要简述: FairyGen是一个自动系统，能够从儿童绘制的单一角色生成故事驱动的卡通视频，并忠实保留其独特的艺术风格。


<details>
  <summary>详细信息</summary>
研究动机: 现有的故事生成方法主要关注角色一致性和基本动作，而FairyGen旨在通过分离角色建模与风格化背景生成，并结合电影镜头设计，实现更具表现力和连贯性的故事叙述。

研究方法: FairyGen首先使用MLLM生成带有镜头描述的结构化故事板，随后通过风格传播适配器确保视觉一致性，并利用镜头设计模块增强视觉多样性和电影质量。角色动画通过3D代理重建和基于MMDiT的图像到视频扩散模型实现，同时采用两阶段运动定制适配器分离身份与运动。

研究结果: 实验表明，FairyGen生成的动画风格忠实、叙事结构自然，具有个性化的故事动画潜力。

研究结论: FairyGen通过结合角色风格保留、电影镜头设计和自然运动生成，为个性化故事动画提供了高效且富有表现力的解决方案。

中文摘要: 我们提出了FairyGen，一个从单一儿童绘制的角色自动生成故事驱动卡通视频的系统，同时忠实保留其独特的艺术风格。与以往主要关注角色一致性和基本动作的故事生成方法不同，FairyGen明确分离了角色建模与风格化背景生成，并融入了电影镜头设计以支持更具表现力和连贯性的故事叙述。给定一个角色草图，我们首先使用MLLM生成带有镜头描述的结构化故事板，指定环境设置、角色动作和相机视角。为确保视觉一致性，我们引入了风格传播适配器，捕捉角色的视觉风格并应用于背景，同时合成风格一致的场景。镜头设计模块通过基于故事板的帧裁剪和多视角合成进一步提升了视觉多样性和电影质量。为动画化故事，我们重建角色的3D代理以生成物理上合理的运动序列，随后用于微调基于MMDiT的图像到视频扩散模型。我们还提出了两阶段运动定制适配器：第一阶段从时间无序的帧中学习外观特征，分离身份与运动；第二阶段使用时间步移策略建模时间动态，同时冻结身份权重。训练完成后，FairyGen可直接渲染与故事板对齐的多样且连贯的视频场景。大量实验表明，我们的系统生成的动画风格忠实、叙事结构自然，突显了其在个性化和引人入胜的故事动画中的潜力。代码将在https://github.com/GVCLab/FairyGen 提供。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [170] [Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG](https://arxiv.org/abs/2506.20683)
**中文标题：基于全局和局部对比学习的心脏MRI与心电图联合表征方法**

*Alexander Selivanov,Philip Müller,Özgün Turgut,Nil Stolt-Ansó,Daniel Rückert*

主要分类: eess.IV

摘要简述: 本文提出了一种名为PTACL的多模态对比学习框架，通过结合心脏MRI（CMR）的时空信息来增强心电图（ECG）的表征能力。PTACL采用全局患者级和局部时间级的对比损失，显著提升了ECG在心脏功能预测和患者检索任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 心电图（ECG）是一种经济高效的心脏电活动检测工具，但无法直接测量心室容积和射血分数等功能参数。心脏磁共振（CMR）虽然能提供这些关键参数，但成本高且不易获取。因此，作者希望通过结合ECG和CMR的多模态信息，提升ECG的诊断能力。

研究方法: PTACL框架通过全局患者级对比损失和局部时间级对比损失，将同一患者的ECG和CMR表征对齐，同时区分不同患者的表征。全局损失用于患者级对齐，局部损失用于时间级对齐，无需引入新的可学习参数。

研究结果: 在UK Biobank的27,951名受试者数据上，PTACL在两项临床相关任务中表现优于基线方法：（1）检索具有相似心脏表型的患者；（2）预测CMR衍生的心脏功能参数（如心室容积和射血分数）。

研究结论: PTACL通过结合ECG和CMR的多模态信息，显著提升了ECG的诊断能力，为非侵入性心脏诊断提供了新思路。代码已开源。

中文摘要: 心电图（ECG）是一种广泛使用的经济高效工具，用于检测心脏的电活动异常。然而，它无法直接测量心室容积和射血分数等功能参数，而这些参数对评估心脏功能至关重要。心脏磁共振（CMR）是这些测量的金标准，能提供详细的结构和功能信息，但成本高且不易获取。为弥合这一差距，我们提出了PTACL（患者和时间对齐对比学习），一种多模态对比学习框架，通过整合CMR的时空信息来增强ECG表征。PTACL采用全局患者级对比损失和局部时间级对比损失。全局损失通过拉近同一患者的ECG和CMR嵌入表征，同时推开不同患者的表征，实现患者级对齐。局部损失通过对比编码的ECG片段与对应的CMR帧，实现患者内部的时间级对齐。这种方法丰富了ECG的诊断信息，超越了单纯的电活动分析，并在不引入新可学习参数的情况下实现了模态间更深入的信息传递。我们在UK Biobank的27,951名受试者的配对ECG-CMR数据上评估了PTACL。与基线方法相比，PTACL在两项临床相关任务中表现更优：（1）检索具有相似心脏表型的患者；（2）预测CMR衍生的心脏功能参数（如心室容积和射血分数）。我们的结果突显了PTACL在利用ECG提升非侵入性心脏诊断方面的潜力。代码已开源：https://github.com/alsalivan/ecgcmr

</details>


### [171] [U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs](https://arxiv.org/abs/2506.20689)
**中文标题：U-R-VEDA：集成UNet、残差连接、边缘与双重注意力及视觉变换器用于心脏磁共振图像的精确语义分割**

*Racheal Mukisa,Arvind K. Bansal*

主要分类: eess.IV

摘要简述: 本文提出了一种名为U-R-Veda的深度学习模型，结合了UNet、残差连接、边缘和双重注意力机制以及视觉变换器，用于心脏磁共振图像的精确语义分割。模型通过局部特征提取和注意力机制显著提升了分割精度，平均准确率达95.2%。


<details>
  <summary>详细信息</summary>
研究动机: 心脏疾病的自动化诊断需要精确的心脏图像分割。现有方法在分割精度和信息保留方面存在不足，因此需要一种更高效的模型来提升心脏磁共振图像的语义分割效果。

研究方法: U-R-Veda模型整合了卷积变换、视觉变换器、残差连接、通道和空间注意力机制，以及基于边缘检测的跳跃连接。通过嵌入通道和空间注意力的卷积块提取局部特征，并结合视觉变换器捕捉特征间的关系。

研究结果: 实验结果表明，U-R-Veda的平均准确率为95.2%（基于DSC指标），在右心室和左心室心肌的分割上优于其他模型（基于DSC和HD指标）。

研究结论: U-R-Veda通过结合多种先进技术显著提升了心脏磁共振图像的语义分割精度，为医学图像分析提供了更高效的工具。

中文摘要: 人工智能，尤其是深度学习模型，将在心脏疾病的自动化诊断和管理中发挥变革性作用。心脏图像的精确自动化分割是量化和自动化诊断心脏疾病的首要步骤。本文提出了一种基于深度学习的增强UNet模型——U-R-Veda，该模型整合了卷积变换、视觉变换器、残差连接、通道和空间注意力机制，以及基于边缘检测的跳跃连接，以实现心脏磁共振（CMR）图像的精确全自动语义分割。模型通过嵌入通道和空间注意力的卷积块提取局部特征及其相互关系，并结合视觉变换器。通道和空间注意力的深度嵌入能够识别重要特征及其空间定位。结合边缘信息的通道和空间注意力作为跳跃连接，减少了卷积变换中的信息损失。整体模型显著提升了CMR图像的语义分割效果，为医学图像分析提供了改进。文中还提出了一种双重注意力模块（通道和空间注意力）的算法。性能结果显示，基于DSC指标，U-R-Veda的平均准确率达到95.2%。该模型在DSC和HD指标上优于其他模型，尤其是在右心室和左心室心肌的分割上。

</details>


### [172] [A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver Tumour Ablation](https://arxiv.org/abs/2506.21162)
**中文标题：一种将3D超声整合到经皮肝肿瘤消融中的新框架**

*Shuwei Xing,Derek W. Cool,David Tessier,Elvis C. S. Chen,Terry M. Peters,Aaron Fenster*

主要分类: eess.IV

摘要简述: 本文提出了一种将3D超声整合到经皮肝肿瘤消融中的新框架，通过2D超声-CT/MRI配准技术降低复杂性，并展示了高效的多模态图像可视化方法，显著提升了配准精度和速度。


<details>
  <summary>详细信息</summary>
研究动机: 3D超声在肝肿瘤消融中具有显著优势，但由于肿瘤识别困难，其临床应用受限。本研究旨在解决这一问题，推动3D超声在治疗领域的应用。

研究方法: 提出了一种新框架，包括基于3D超声的2D超声-CT/MRI配准方法，以及直观的多模态图像可视化技术，以简化配准流程并提高效率。

研究结果: 2D超声-CT/MRI配准的标记距离误差为2-4毫米，每对图像运行时间为0.22秒；非刚性配准比刚性配准平均对齐误差降低约40%。

研究结论: 该框架显著提升了3D超声在肝肿瘤消融中的应用效果，展示了其在临床干预中的潜在治疗价值。

中文摘要: 3D超声（US）成像在提升经皮肝肿瘤消融效果方面显示出显著优势。其临床整合对于将3D超声引入治疗领域至关重要。然而，超声图像中肿瘤识别的挑战仍阻碍了其广泛应用。本研究提出了一种将3D超声整合到标准消融流程中的新框架。我们介绍了一个关键组件，即一种临床可行的2D超声-CT/MRI配准方法，利用3D超声作为中介降低配准复杂性。为便于高效验证配准流程，我们还提出了一种直观的多模态图像可视化技术。研究中，2D超声-CT/MRI配准的标记距离误差约为2-4毫米，每对图像运行时间为0.22秒。此外，非刚性配准比刚性配准的平均对齐误差降低了约40%。结果表明了所提出的2D超声-CT/MRI配准流程的有效性。我们的整合框架提升了3D超声成像在改善经皮肿瘤消融中的能力，展示了其在临床干预中扩展3D超声治疗作用的潜力。

</details>


### [173] [Development of MR spectral analysis method robust against static magnetic field inhomogeneity](https://arxiv.org/abs/2506.20897)
**中文标题：针对静态磁场不均匀性的稳健MR光谱分析方法的开发**

*Shuki Maruyama,Hidenori Takeshima*

主要分类: eess.IV

摘要简述: 开发了一种基于深度学习的MR光谱分析方法，能够有效应对静态磁场不均匀性，显著提升光谱分析的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 静态磁场B0不均匀性会影响光谱分析的准确性，因此需要一种新方法来减少这种影响。

研究方法: 作者提出了一种新方法，利用深度学习模型训练模拟光谱，这些光谱基于B0图和健康人脑代谢物比例生成。通过将B0图划分为子区域，分别估计代谢物和基线成分后平均整合。模型训练使用了实测、模拟和建模光谱，并通过均方误差和平均绝对百分比误差评估性能。

研究结果: 建模光谱在B0不均匀性下表现出光谱峰的展宽和变窄，与实测光谱定量接近。使用建模光谱训练的模型比仅用实测光谱训练的模型MSE降低了49.89%，比实测加模拟光谱训练的模型降低了26.66%。模型性能随建模光谱数量增加而提升，且在两种B0不均匀性下均优于LCModel。

研究结论: 提出的基于建模光谱的深度学习模型能够显著提升光谱分析准确性，为训练样本的扩展提供了潜力。

中文摘要: 目的：开发一种在静态磁场B0不均匀性存在时提高光谱分析准确性的方法。方法：作者提出了一种新的光谱分析方法，利用深度学习模型训练模拟光谱，这些光谱能够一致地反映B0不均匀性引起的光谱变化。模拟光谱基于健康人脑的B0图和代谢物比例生成。B0图被划分为子区域，分别估计代谢物和基线成分后平均整合。模拟光谱的质量通过视觉和定量方式与实测光谱对比评估。分析模型使用实测、模拟和建模光谱训练。通过代谢物比例的均方误差（MSE）评估方法性能，并在两种B0不均匀性下与LCModel的平均绝对百分比误差（MAPE）进行比较。结果：模拟光谱在B0不均匀性下表现出光谱峰的展宽和变窄，定量上与实测光谱接近。使用建模光谱训练的模型比仅用实测光谱训练的模型MSE降低了49.89%，比实测加模拟光谱训练的模型降低了26.66%。模型性能随建模光谱数量增加而提升，且在两种B0不均匀性下均优于LCModel。结论：开发了一种基于建模光谱训练的光谱分析深度学习模型。结果表明，该方法通过增加光谱训练样本，有望提高光谱分析的准确性。

</details>


### [174] [Uncover Treasures in DCT: Advancing JPEG Quality Enhancement by Exploiting Latent Correlations](https://arxiv.org/abs/2506.21171)
**中文标题：发掘DCT中的宝藏：通过挖掘潜在相关性提升JPEG质量增强**

*Jing Yang,Qunliang Xing,Mai Xu,Minglang Qiao*

主要分类: eess.IV

摘要简述: 本文提出了一种基于DCT域的JPEG质量增强方法（AJQE），通过挖掘DCT系数中的潜在相关性，显著提升了性能并降低了计算复杂度。


<details>
  <summary>详细信息</summary>
研究动机: JPEG压缩通过量化DCT系数实现数据压缩，但会引入压缩伪影。现有方法多在像素域操作，计算成本高。因此，直接在DCT域增强JPEG图像质量成为研究热点，但当前方法性能有限。

研究方法: 作者发现JPEG图像的DCT系数中存在两种关键相关性，并基于此提出AJQE方法，充分挖掘这些相关性，将像素域模型适配到DCT域。

研究结果: 相比像素域方法，AJQE在PSNR上平均提升0.35 dB，增强吞吐量提高60.5%。

研究结论: AJQE方法通过利用DCT域内的相关性，显著提升了JPEG图像质量增强的性能和效率。

中文摘要: 联合图像专家组（JPEG）通过量化离散余弦变换（DCT）系数实现数据压缩，但不可避免地引入压缩伪影。现有的大多数JPEG质量增强方法在像素域操作，解码计算成本高。因此，直接在DCT域增强JPEG图像质量受到越来越多的关注。然而，当前的DCT域方法性能有限。为解决这一问题，我们识别了JPEG图像DCT系数中的两种关键相关性。基于这一发现，我们提出了一种高级DCT域JPEG质量增强方法（AJQE），充分挖掘这些相关性。AJQE方法使许多成熟的像素域模型能够适配到DCT域，以较低的计算复杂度实现更优的性能。与像素域方法相比，通过我们的方法衍生的DCT域模型在PSNR上平均提升了0.35 dB，增强吞吐量提高了60.5%。

</details>


### [175] [GANet-Seg: Adversarial Learning for Brain Tumor Segmentation with Hybrid Generative Models](https://arxiv.org/abs/2506.21245)
**中文标题：GANet-Seg：基于混合生成模型的对抗性学习脑肿瘤分割方法**

*Qifei Cui,Xinyu Lu*

主要分类: eess.IV

摘要简述: 本文提出了一种结合预训练GAN和Unet架构的脑肿瘤分割新框架，通过全局异常检测和精细化掩模生成网络，利用对抗性损失约束提升分割精度，并在BraTS数据集上验证了其高效性。


<details>
  <summary>详细信息</summary>
研究动机: 脑肿瘤分割在临床诊断中至关重要，但现有方法依赖大量标注数据且精度有限。本文旨在通过结合生成对抗网络和Unet架构，减少对标注数据的依赖并提升分割精度。

研究方法: 提出了一种混合生成模型框架，结合全局异常检测模块和精细化掩模生成网络，利用多模态MRI数据和合成图像增强技术，通过对抗性损失约束迭代优化分割结果。

研究结果: 在BraTS数据集上的实验表明，该方法在病变区域的Dice和HD95指标上均优于基线模型，具有高灵敏度和准确性。

研究结论: 该方法通过减少对全标注数据的依赖，提升了分割精度和鲁棒性，为临床实际应用提供了可行方案。

中文摘要: 本文提出了一种新颖的脑肿瘤分割框架，结合预训练的生成对抗网络（GAN）和Unet架构。通过整合全局异常检测模块和精细化掩模生成网络，该模型能够准确识别肿瘤敏感区域，并利用对抗性损失约束迭代提升分割精度。采用多模态MRI数据和合成图像增强技术，增强了模型的鲁棒性，解决了标注数据不足的挑战。在BraTS数据集上的实验结果表明，该方法在病变区域的Dice和HD95指标上均优于基线模型，具有高灵敏度和准确性。这种可扩展的方法减少了对全标注数据的依赖，为临床实际应用提供了新的可能性。

</details>


### [176] [Lightweight Physics-Informed Zero-Shot Ultrasound Plane Wave Denoising](https://arxiv.org/abs/2506.21499)
**中文标题：轻量级物理启发的零样本超声平面波去噪**

*Hojat Asgariandehkordi,Mostafa Sharifzadeh,Hassan Rivaz*

主要分类: eess.IV

摘要简述: 本文提出了一种轻量级物理启发的零样本超声平面波去噪框架，通过自监督残差学习方案训练深度模型，无需单独训练数据集即可提升低角度CPWC图像的对比度，同时保留解剖结构。


<details>
  <summary>详细信息</summary>
研究动机: 超声相干平面波复合（CPWC）通过多角度传输提升图像对比度，但增加角度会降低帧率并引入模糊伪影，且低角度传输时噪声问题显著。现有方法依赖训练数据或领域特定调整，限制了适应性。

研究方法: 将可用传输角度分为两个不相交子集，分别生成含噪声的复合图像，通过自监督残差学习训练轻量级深度模型（仅含两层卷积），分离不一致的伪影与一致的组织信号。

研究结果: 在仿真、体模和活体数据上的评估表明，该方法在对比度增强和结构保留方面优于传统和基于深度学习的去噪方法。

研究结论: 该零样本去噪框架无需领域特定调整或配对数据，计算成本低，适用于不同解剖区域和采集设置，为低角度CPWC图像去噪提供了高效解决方案。

中文摘要: 超声相干平面波复合（CPWC）通过结合多个转向传输的回波增强图像对比度。然而，增加角度数量虽能提升图像质量，却会显著降低帧率，并在快速移动目标中引入模糊伪影。此外，复合图像仍易受噪声影响，尤其是在传输次数有限的情况下。我们提出了一种专为低角度CPWC采集设计的零样本去噪框架，无需依赖单独的训练数据集即可提升对比度。该方法将可用传输角度分为两个不相交子集，分别用于生成含更高噪声水平的复合图像。随后，通过自监督残差学习方案训练深度模型，使其能够抑制非相干噪声并保留解剖结构。由于子集间的角度依赖性伪影不同而组织响应相似，这种物理启发的配对使网络能够学习从不一致的伪影中分离出一致的组织信号。与监督方法不同，我们的模型无需领域特定微调或配对数据，可适应不同解剖区域和采集设置。整个流程采用轻量级架构（仅含两层卷积），支持高效低成本的训练。在仿真、体模和活体数据上的评估表明，该方法在对比度增强和结构保留方面优于传统和基于深度学习的去噪方法。

</details>


### [177] [Exploring the Design Space of 3D MLLMs for CT Report Generation](https://arxiv.org/abs/2506.21535)
**中文标题：探索用于CT报告生成的3D多模态大语言模型设计空间**

*Mohammed Baharoon,Jun Ma,Congyu Fang,Augustin Toma,Bo Wang*

主要分类: eess.IV

摘要简述: 本文系统研究了3D多模态大语言模型（MLLMs）的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和微调技术，用于3D CT报告生成。通过两种基于知识的报告增强方法，性能提升高达10%，在MICCAI 2024 AMOS-MM挑战赛中排名第二。


<details>
  <summary>详细信息</summary>
研究动机: 多模态大语言模型（MLLMs）在自动化放射学报告生成（RRG）中展现出潜力，但3D MLLMs的设计空间尚未系统探索。本文旨在填补这一空白，并提升CT报告生成的性能。

研究方法: 研究包括视觉输入表示、投影器、LLMs选择和微调技术的设计空间探索。引入两种基于知识的报告增强方法，优化性能。实验基于AMOS-MM数据集的1,687例病例。

研究结果: 在相同训练协议下，RRG性能与LLM规模无关；更大的体积尺寸不一定提升性能；结合分割掩模与CT体积可提升性能。性能提升高达10%，在挑战赛中排名第二。

研究结论: 3D MLLMs的设计空间探索为CT报告生成提供了新见解，基于知识的增强方法显著提升性能，代码已开源。

中文摘要: 多模态大语言模型（MLLMs）已成为自动化放射学报告生成（RRG）的一种有前景的方法。本文系统研究了3D MLLMs的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和微调技术，用于3D CT报告生成。我们还引入了两种基于知识的报告增强方法，将GREEN分数性能提升高达10%，在MICCAI 2024 AMOS-MM挑战赛中排名第二。基于AMOS-MM数据集的1,687例病例结果显示，在相同训练协议下，RRG性能与LLM规模无关。我们还发现，如果原始ViT是在较小体积尺寸上预训练的，更大的体积尺寸并不总能提升性能。最后，结合分割掩模与CT体积可提升性能。代码已公开于https://github.com/bowang-lab/AMOS-MM-Solution。

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [178] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
**中文标题：机器学习的敏捷管理：一项系统映射研究**

*Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski*

主要分类: cs.SE

摘要简述: 本文通过系统映射研究，总结了机器学习（ML）敏捷管理的现状，识别了8个关键主题和主要挑战，如任务工作量估算，并指出需要更多实证研究验证现有成果。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习驱动的系统具有动态性和实验性，传统项目管理方法难以应对。敏捷方法因其灵活性可能适用于ML开发，但缺乏具体应用指南。本文旨在梳理ML敏捷管理的现状。

研究方法: 采用混合搜索策略，结合数据库检索和前后向雪球迭代，对2008年至2024年的27篇论文进行系统映射研究。

研究结果: 研究识别了8个框架，并将建议和实践分为8个主题，如迭代灵活性、创新ML特定工件和最小可行模型。主要挑战是ML任务的工作量估算。

研究结论: 本研究总结了ML敏捷管理的现状和未解决问题，现有成果需更多实证验证。

中文摘要: [背景] 机器学习（ML）驱动的系统正在推动社会数字化转型，但其开发的动态性和实验性对传统项目管理提出了挑战。敏捷方法因其灵活性和增量交付特性，可能适合应对这种动态性，但在ML系统中的具体应用尚不明确。[目标] 本文旨在概述ML敏捷管理的最新研究现状。[方法] 采用混合搜索策略，结合数据库检索和前后向雪球迭代，对2008年至2024年的27篇论文进行系统映射研究。[结果] 研究识别了8个框架，并将建议和实践分为8个关键主题，如迭代灵活性、创新ML特定工件和最小可行模型。主要挑战是ML任务的工作量估算。[结论] 本研究总结了ML敏捷管理的现状和未解决问题，现有成果需更多实证验证。

</details>


### [179] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
**中文标题：通过自动化集成数据生成可靠的健康不良事件图谱（GRAPH-AID）：一种半自动化的本体构建方法**

*Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty*

主要分类: cs.SE

摘要简述: 本文提出了一种半自动化的本体构建方法GRAPH-AID，通过Python和rdflib库简化Neo4j数据库与OWL的集成，用于生成可靠的药物不良事件图谱，提升药物安全监测效率。


<details>
  <summary>详细信息</summary>
研究动机: 随着数据和知识的快速增长，系统化的本体生成方法变得至关重要。现有方法需要熟悉描述逻辑语法，对用户不友好，因此需要一种更易用的方法来集成Neo4j数据库与OWL。

研究方法: 采用Python和rdflib库开发了一种用户友好的方法，通过自动生成类及其公理，实现Neo4j数据库与OWL的无缝集成。以FDA不良事件报告系统（FAERS）数据为例，展示了该方法的应用。

研究结果: 成功开发了一个Python脚本，能够自动生成所需的类和公理，简化了本体生成过程，为药物不良事件数据的快速处理提供了实用解决方案。

研究结论: GRAPH-AID方法为快速增长的药物不良事件数据集的本体生成提供了高效工具，支持药物安全监测和公共卫生决策。

中文摘要: 随着数据和知识的迅速扩展，采用系统化的本体生成方法变得至关重要。数据量的每日增长和内容的频繁变化，使得存储和检索信息以创建知识图谱的数据库需求日益迫切。先前建立的知识获取与表示方法（KNARM）为解决这些挑战和创建知识图谱提供了系统化方法。然而，遵循该方法凸显了Neo4j数据库与Web本体语言（OWL）无缝集成的现有挑战。此前尝试将Neo4j数据集成到本体中的方法需要理解描述逻辑（DL）语法，这对许多用户来说可能不熟悉。因此，需要一种更易用的方法来弥合这一差距。本文提出了一种用户友好的方法，利用Python及其rdflib库支持本体开发。我们通过整合FDA不良事件报告系统（FAERS）数据创建的Neo4j数据库展示了这一新方法。利用该数据集，我们开发了一个Python脚本，自动生成所需的类及其公理，简化了集成过程。这一方法为快速增长的药物不良事件数据集的本体生成提供了实用解决方案，支持改进的药物安全监测和公共卫生决策。

</details>


### [180] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
**中文标题：面向真实应用的RAG系统工程：设计、开发与评估**

*Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson*

主要分类: cs.SE

摘要简述: 本文介绍了五个针对真实场景的RAG系统开发案例，涵盖多个领域，并通过用户评估总结了十二个关键经验教训。


<details>
  <summary>详细信息</summary>
研究动机: 当前缺乏基于真实用例的RAG系统开发经验分享和用户评估研究，本文旨在填补这一空白。

研究方法: 开发了五个领域的RAG系统，结合多语言OCR、语义检索和领域适配LLM，并通过100名用户的网络评估验证系统性能。

研究结果: 用户评估显示系统在易用性、相关性、透明度等方面表现良好，同时总结了十二个影响RAG系统可靠性和可用性的关键挑战。

研究结论: RAG系统在真实应用中具有潜力，但需解决技术、操作和伦理等多方面挑战。

中文摘要: 检索增强生成（RAG）系统作为一种将大型语言模型（LLM）与外部知识结合的关键方法，正在解决事实准确性和上下文相关性方面的局限性。然而，目前缺乏基于真实用例的RAG系统开发经验分享，以及通过用户参与评估的系统性文档。本文介绍了五个针对真实场景的RAG应用，涵盖治理、网络安全、农业、工业研究和医疗诊断领域。每个系统结合了多语言OCR、基于向量嵌入的语义检索和领域适配LLM，并通过本地服务器或云API部署以满足不同用户需求。基于100名参与者的网络评估，系统在六个维度（易用性、相关性、透明度、响应性、准确性和推荐可能性）上进行了评估。根据用户反馈和开发经验，我们总结了十二个关键经验教训，突出了影响RAG系统可靠性和可用性的技术、操作和伦理挑战。

</details>


### [181] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
**中文标题：基于不确定人类指导的强化学习实现复杂模型转换**

*Kyanna Dagenais,Istvan David*

主要分类: cs.SE

摘要简述: 本文提出了一种通过强化学习（RL）结合不确定人类指导开发复杂模型转换（MT）序列的方法，显著提升了RL性能并优化了MT开发效率。


<details>
  <summary>详细信息</summary>
研究动机: 模型驱动工程中，复杂模型转换（如模型同步、自动修复和设计空间探索）通常需要长序列的MT，手动开发易出错且不可行。RL虽能解决此问题，但在复杂场景中性能不足，而人类指导可弥补这一缺陷。

研究方法: 提出了一种技术框架，将用户定义的MT映射到RL原语，并通过RL程序执行以寻找最优MT序列。框架支持不确定的人类建议，平衡其确定性与及时性。

研究结果: 评估表明，即使人类建议不确定，也能显著提升RL性能，并更高效地开发复杂MT序列。

研究结论: 该方法为RL驱动的人机协同工程方法迈出了重要一步，通过结合人类指导优化了复杂MT的开发过程。

中文摘要: 模型驱动工程问题通常需要复杂的模型转换（MT），即长序列的MT。典型问题包括模型同步、自动模型修复和设计空间探索。手动开发复杂MT易出错且往往不可行。强化学习（RL）是缓解这些问题的有效方法。在RL中，自主代理通过试错探索状态空间以识别有益的动作序列（如MT）。然而，RL方法在复杂问题中表现不佳。此时，人类指导具有重要价值。本文提出了一种方法和框架，通过RL结合潜在不确定的人类建议开发复杂MT序列。该框架将用户定义的MT映射到RL原语，并作为RL程序执行以寻找最优MT序列。评估表明，即使人类建议不确定，也能显著提升RL性能，并更高效地开发复杂MT。通过权衡人类建议的确定性与及时性，该方法为RL驱动的人机协同工程方法迈出了一步。

</details>


### [182] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
**中文标题：合成需求有多好？评估LLM生成的数据集在AI4RE中的应用**

*Abdelkarim El-Hajjami,Camille Salinesi*

主要分类: cs.SE

摘要简述: 本文提出Synthline v1，一种改进的产品线方法，用于生成合成需求数据，并通过多样本提示、自动提示优化和后生成筛选技术提升数据质量。实验表明，合成需求数据在特定任务中可媲美甚至超越人工数据。


<details>
  <summary>详细信息</summary>
研究动机: 公开可用的标记需求数据集稀缺是推动人工智能在需求工程（AI4RE）领域发展的主要障碍。尽管大语言模型在合成数据生成方面表现出潜力，但如何系统控制和优化生成需求质量的方法尚未充分探索。

研究方法: 本文提出Synthline v1，扩展了早期版本v0，采用多样本提示、自动提示优化（PACE）和后生成筛选技术，评估了四种分类任务（缺陷检测、功能与非功能、质量与非质量、安全与非安全）中数据质量的影响。

研究结果: 多样本提示显著提升了数据的实用性和多样性（F1分数提升6-44分）；PACE优化对功能分类效果显著（提升32.5分），但对其他任务效果不一；相似性筛选提高了多样性但可能损害分类性能。合成数据在安全和缺陷分类任务中超越人工数据（分别提升7.8和15.4分）。

研究结论: 合成需求数据在特定任务中可媲美甚至超越人工数据，为AI4RE提供了实用见解，并展示了通过系统合成生成缓解数据集稀缺的可行路径。

中文摘要: 公开可用的标记需求数据集稀缺仍然是推动人工智能在需求工程（AI4RE）领域发展的主要障碍。尽管大语言模型在合成数据生成方面表现出潜力，但如何系统控制和优化生成需求质量的方法尚未充分探索。本文提出Synthline v1，一种改进的产品线方法，用于生成合成需求数据，扩展了早期版本v0，采用多样本提示、自动提示优化（PACE）和后生成筛选技术。我们研究了四个研究问题，评估提示策略、自动提示优化和后生成筛选如何影响四种分类任务（缺陷检测、功能与非功能、质量与非质量、安全与非安全）中的数据质量。实验表明，多样本提示显著提升了数据的实用性和多样性（F1分数提升6-44分）；PACE优化对功能分类效果显著（提升32.5分），但对其他任务效果不一；相似性筛选提高了多样性但可能损害分类性能。有趣的是，合成数据在安全和缺陷分类任务中超越人工数据（分别提升7.8和15.4分）。这些发现为AI4RE提供了实用见解，并展示了通过系统合成生成缓解数据集稀缺的可行路径。

</details>


### [183] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
**中文标题：$T^3$：基于大型语言模型的多级树状自动程序修复框架**

*Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li*

主要分类: cs.SE

摘要简述: 本文提出了一种名为 $T^3$ 的创新框架，通过将大型语言模型（LLMs）的推理能力与树搜索结合，显著提升了自动程序修复（APR）任务的精确度，并为优化样本选择和修复策略提供了指导。


<details>
  <summary>详细信息</summary>
研究动机: 自动程序修复（APR）是软件开发与维护中的核心技术，但现有的大型语言模型（LLMs）和思维链（CoT）技术在APR领域的应用仍显不足，尤其是在复杂逻辑和多步推理能力方面。因此，本文旨在系统评估CoT技术在APR任务中的表现，并提出一种更高效的解决方案。

研究方法: 本文提出了 $T^3$ 框架，通过将LLMs的推理能力与树搜索技术结合，生成候选修复方案。该框架不仅优化了样本选择，还为修复策略提供了指导，从而提升了APR任务的精确度。

研究结果: 实验表明，$T^3$ 框架显著提高了生成候选修复方案的精确度，并为APR任务中的样本选择和修复策略优化提供了有效指导。

研究结论: 本文提出的 $T^3$ 框架成功将LLMs的推理能力与树搜索结合，显著提升了APR任务的性能，为自动调试提供了高效且稳健的解决方案。

中文摘要: 自动程序修复（APR）是软件开发与维护中的核心技术，旨在通过最小化人工干预实现自动化缺陷修复。近年来，大型语言模型（LLMs）和思维链（CoT）技术的显著进步大幅提升了模型的推理能力。然而，由于APR任务需要复杂的逻辑和多步推理能力，CoT技术在该领域的应用仍显不足。本研究系统评估了几种常见CoT技术在APR任务中的表现，并提出了一种创新框架 $T^3$，该框架将LLMs的强大推理能力与树搜索结合，有效提升了生成候选修复方案的精确度。此外，$T^3$ 还为APR任务中的样本选择和修复策略优化提供了宝贵指导，为实现高效自动化调试建立了稳健的框架。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [184] [Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis](https://arxiv.org/abs/2506.20806)
**中文标题：海报：通过基于代理的分析增强图神经网络在网络入侵检测中的鲁棒性**

*Zhonghao Zhan,Huichi Zhou,Hamed Haddadi*

主要分类: cs.CR

摘要简述: 本文提出了一种通过基于代理的分析增强图神经网络（GNN）在网络入侵检测中的鲁棒性的方法，利用大型语言模型（LLM）模拟网络安全专家，显著提升了GNN的对抗攻击防御能力。


<details>
  <summary>详细信息</summary>
研究动机: 当前GNN在网络入侵检测系统（NIDS）中表现优异，但面临分布漂移和对抗攻击的鲁棒性不足问题，现有评估方法依赖不现实的合成扰动，缺乏对多种对抗攻击的系统分析。

研究方法: 研究提出了一种新颖方法，利用LLM作为模拟网络安全专家代理，分析网络流数据生成的图结构，识别并缓解可疑或对抗性扰动元素，再交由GNN处理。

研究结果: 实验表明，通过LLM代理的集成分析，GNN在多种对抗攻击下的鲁棒性显著提升，验证了LLM作为入侵检测架构补充层的潜力。

研究结论: LLM代理能够有效增强GNN在网络入侵检测中的鲁棒性和泛化能力，为未来安全架构设计提供了新思路。

中文摘要: 图神经网络（GNN）在网络入侵检测系统（NIDS）中展现出巨大潜力，尤其是在物联网环境中，但由于分布漂移和对抗攻击的鲁棒性不足，其性能会下降。当前的鲁棒性评估通常依赖不现实的合成扰动，并缺乏对包括黑盒和白盒场景在内的多种对抗攻击的系统分析。本研究提出了一种新颖方法，通过将大型语言模型（LLM）作为模拟网络安全专家代理，分析网络流数据生成的图结构，识别并可能缓解可疑或对抗性扰动元素，再交由GNN处理。我们的实验使用了一个为多种对抗攻击设计的评估框架，包括从物理测试床实验中收集的数据集，结果表明，集成LLM分析可以显著提升GNN在NIDS中的鲁棒性，展示了LLM代理作为入侵检测架构补充层的潜力。

</details>


### [185] [ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models](https://arxiv.org/abs/2506.20915)
**中文标题：ZKPROV：一种基于零知识证明的大型语言模型数据集来源验证方法**

*Mina Namazi,Alexander Nemecek,Erman Ayday*

主要分类: cs.CR

摘要简述: ZKPROV是一种新型加密框架，通过零知识证明技术验证大型语言模型（LLM）的数据来源，确保模型训练数据的可靠性，同时保护敏感信息不被泄露。


<details>
  <summary>详细信息</summary>
研究动机: 在敏感领域（如医疗）部署大型语言模型时，确保其数据来源的完整性至关重要。现有方法要么计算成本高，要么依赖可信执行环境，ZKPROV旨在提供一种高效且隐私保护的解决方案。

研究方法: ZKPROV利用零知识证明技术，将训练模型与授权数据集绑定，通过数据集签名元数据和紧凑模型参数承诺，避免验证每一步训练过程，从而降低计算成本。

研究结果: 实验证明ZKPROV在生成和验证证明时高效且可扩展，适用于实际部署，同时提供形式化安全保障，确保数据机密性和可信来源。

研究结论: ZKPROV为大型语言模型的数据来源验证提供了一种高效、隐私保护的解决方案，适用于敏感领域的实际应用。

中文摘要: 随着大型语言模型（LLM）在敏感领域（如医疗）的广泛应用，确保其计算来源的完整性成为关键挑战。我们提出ZKPROV，一种新型加密框架，通过零知识证明技术验证LLM的数据来源，允许用户在不泄露敏感信息或其参数的情况下确认模型是否基于可靠数据集训练。与现有方法不同，ZKPROV既不完全验证训练过程（避免高计算成本），也不依赖可信执行环境，而是通过数据集签名元数据和紧凑模型参数承诺，提供高效且隐私保护的验证方案。实验结果表明，ZKPROV在生成和验证证明时高效且可扩展，适用于实际部署。我们还提供了形式化安全保障，证明该方法在保护数据机密性的同时确保可信的数据来源。

</details>


### [186] [PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction](https://arxiv.org/abs/2506.21106)
**中文标题：PhishKey：一种基于质心的自适应HTML组件提取增强钓鱼检测新方法**

*Felipe Castaño,Eduardo Fidalgo,Enrique Alegre,Rocio Alaiz-Rodríguez,Raul Orduna,Francesco Zola*

主要分类: cs.CR

摘要简述: PhishKey是一种新型钓鱼检测方法，结合URL分类和HTML内容提取，通过软投票集成实现高精度分类，实验显示其F1分数高达98.70%，且对抗攻击性能优异。


<details>
  <summary>详细信息</summary>
研究动机: 钓鱼攻击是网络安全的主要威胁之一，传统检测方法难以应对其快速演变的特性。PhishKey旨在解决适应性、鲁棒性和效率问题，提供更可靠的检测手段。

研究方法: PhishKey采用混合特征提取方法，结合字符级处理的CNN进行URL分类，以及基于质心的HTML关键组件提取器（CAPE）处理HTML内容。通过软投票集成两种模块的预测结果，提升分类准确性。

研究结果: 在四个先进数据集上的实验表明，PhishKey的F1分数高达98.70%，且对抗注入攻击时性能下降极小，表现出强大的鲁棒性。

研究结论: PhishKey通过创新的混合特征提取和集成方法，显著提升了钓鱼检测的准确性和鲁棒性，为网络安全提供了有效解决方案。

中文摘要: 钓鱼攻击是网络安全的重要威胁，其快速演变以绕过检测机制并利用人类弱点。本文提出PhishKey，以解决适应性、鲁棒性和效率问题。PhishKey是一种新型钓鱼检测方法，通过混合来源自动提取特征。它结合字符级处理的卷积神经网络（CNN）进行URL分类，以及基于质心的关键组件钓鱼提取器（CAPE）处理HTML内容。CAPE减少噪声并确保完整样本处理，避免输入数据的裁剪操作。两种模块的预测通过软投票集成实现更准确可靠的分类。在四个先进数据集上的实验评估证明了PhishKey的有效性，其F1分数高达98.70%，且对注入攻击等对抗操作表现出强抵抗力，性能下降极小。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [187] [ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data](https://arxiv.org/abs/2506.20673)
**中文标题：ClusterRCA：基于多模态数据的HPC系统网络故障诊断方法**

*Yongqian Sun,Xijie Pan,Xiao Xiong,Lei Tao,Jiaju Wang,Shenglin Zhang,Yuan Yuan,Yuqi Li,Kunlin Jian*

主要分类: cs.DC

摘要简述: 本文提出了一种名为ClusterRCA的新框架，通过利用多模态数据来定位高性能计算（HPC）系统中的网络故障节点和故障类型，结合分类器和图方法，显著提高了诊断准确性。


<details>
  <summary>详细信息</summary>
研究动机: 高性能计算（HPC）系统中的网络故障诊断面临数据异构性和准确性不足的挑战，现有方法难以直接应用。因此，需要一种能够有效处理多模态数据并精确定位故障的新方法。

研究方法: ClusterRCA框架从拓扑连接的网卡对中提取特征，分析多模态数据，结合分类器和图方法。首先通过状态分类器构建故障图，然后通过定制化的随机游走定位根因节点。

研究结果: 实验结果表明，ClusterRCA在诊断HPC系统网络故障时具有高准确性，并在不同应用场景中保持稳健性能。

研究结论: ClusterRCA通过多模态数据分析和图方法，显著提升了HPC系统网络故障诊断的准确性和鲁棒性，为实际应用提供了有效解决方案。

中文摘要: 网络故障诊断对高性能计算（HPC）系统至关重要，但由于数据异构性和准确性不足，现有方法难以直接应用于HPC场景。本文提出了一种名为ClusterRCA的新框架，通过利用多模态数据定位故障节点并确定故障类型。ClusterRCA从拓扑连接的网卡对中提取特征，结合分类器和图方法：首先基于状态分类器构建故障图，然后通过定制化的随机游走定位根因。实验数据来自全球顶级HPC设备供应商，结果表明ClusterRCA在诊断HPC系统网络故障时具有高准确性，且在不同应用场景中保持稳健性能。

</details>


### [188] [Utility-Driven Speculative Decoding for Mixture-of-Experts](https://arxiv.org/abs/2506.20675)
**中文标题：面向混合专家模型的效用驱动推测解码**

*Anish Saxena,Po-An Tsai,Hritvik Taneja,Aamer Jaleel,Moinuddin Qureshi*

主要分类: cs.DC

摘要简述: GPU内存带宽是低延迟大型语言模型（LLM）推理的主要瓶颈。传统密集LLM中，推测解码通过轻量级草案器提出K个令牌并由LLM并行验证，提升令牌吞吐量。然而，混合专家（MoE）模型中，推测解码因激活更多权重而增加数据移动和验证时间，导致性能下降。本文提出Cascade框架，动态调整K值并选择性启用推测解码，避免性能下降，提升MoE服务的吞吐量。


<details>
  <summary>详细信息</summary>
研究动机: GPU内存带宽限制了低延迟LLM推理的性能。推测解码在密集LLM中有效，但在MoE模型中因激活更多权重而增加开销，甚至导致性能下降。因此，需要一种动态调整推测解码的方法，以优化MoE模型的推理效率。

研究方法: 本文提出Cascade框架，通过轻量级指标“推测效用”（令牌增益与验证成本的比率）动态调整K值。框架分为测试阶段和设置阶段：测试阶段评估效用，若低于1则禁用推测解码；若高于1，则测试多个K值以选择效用最大化的K值用于设置阶段。

研究结果: 在五种流行的MoE模型和多种任务（代码、数学、提取等）中，Cascade将性能下降限制在5%（传统方法为1.5倍），并通过动态调整K值将吞吐量提升7-14%。

研究结论: Cascade框架通过动态调整推测解码的K值，解决了MoE模型中推测解码的性能问题，使其在MoE服务中变得实用。

中文摘要: GPU内存带宽是低延迟大型语言模型（LLM）推理的主要瓶颈。推测解码利用空闲GPU计算资源，通过轻量级草案器提出K个令牌，并由LLM并行验证，从而提升令牌吞吐量。在传统的密集LLM中，每次迭代都会加载所有模型权重，因此推测解码不会增加延迟开销。然而，新兴的混合专家（MoE）模型仅为每个令牌激活部分权重，大幅减少了数据移动。我们发现，推测解码对MoE模型效果不佳：草案令牌会激活更多权重，导致数据移动和验证时间增加2-3倍。当令牌吞吐量的提升无法抵消这一开销时，推测解码会导致性能下降高达1.5倍，使其不可行。即使在某些情况下有效，最优K值也会因任务、模型甚至请求和迭代的不同而变化。因此，尽管推测解码在密集LLM中广泛应用，但在主流MoE模型中仍不实用。

我们提出了Cascade框架，这是一种效用驱动的框架，通过选择性启用推测解码以避免性能下降，并动态调整K值以加速MoE服务。Cascade使用轻量级指标“推测效用”（令牌增益与验证成本的比率），该指标具有迭代级别的局部性，支持通过短测试阶段和长设置阶段进行周期性决策。对于每个请求，如果测试阶段中效用低于1，则禁用推测解码；若效用高于1，则测试多个K值以选择效用最大化的K值用于设置阶段。我们在vLLM中实现了Cascade，并在五种流行的MoE模型和涵盖代码、数学、提取和混合任务的工作负载上进行了评估。Cascade将性能下降限制在5%（传统方法为1.5倍），并通过动态调整K值将吞吐量提升7-14%，使推测解码在MoE模型中变得实用。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [189] [Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots](https://arxiv.org/abs/2506.20748)
**中文标题：探索聊天机器人拟人化与人类共情对人类对聊天机器人亲社会行为的影响**

*Jingshu Li,Zicheng Zhu,Renwen Zhang,Yi-Chieh Lee*

主要分类: cs.HC

摘要简述: 研究探讨了聊天机器人拟人化（如人类身份、情感表达）如何通过激发人类共情，促使其对聊天机器人表现出亲社会行为和意图。实验发现拟人化特征显著提升亲社会行为，共情是中介因素。


<details>
  <summary>详细信息</summary>
研究动机: 随着聊天机器人在生活中的广泛应用，人类帮助聊天机器人的现象逐渐增多，但相关研究较少。本文旨在探索聊天机器人拟人化特征如何通过激发人类共情，促使其对聊天机器人表现出亲社会行为。

研究方法: 通过在线实验（N=244），在协作图像标注任务中，聊天机器人故意犯错并向参与者解释原因，随后测量参与者对聊天机器人的亲社会行为和意图。

研究结果: 研究发现，聊天机器人的人类身份和情感表达显著提升了参与者的亲社会行为和意图，共情是这一效应的中介因素。定性分析还揭示了两种动机：对聊天机器人的共情和将其视为类人存在。

研究结论: 聊天机器人的拟人化设计可通过激发共情促进人类的亲社会行为，这对理解和优化人机交互具有重要意义。

中文摘要: 聊天机器人日益融入人们的生活，并被广泛用于帮助人类。近年来，由于其对聊天机器人性能、人类福祉及协作结果的积极影响，人类帮助聊天机器人的现象也受到关注。然而，关于促使人类帮助聊天机器人的因素研究较少。为填补这一空白，本文基于“计算机是社会行动者”（CASA）框架，探讨聊天机器人拟人化（包括人类身份、情感表达和非语言表达）如何影响人类对聊天机器人的共情及其后续的亲社会行为和意图。我们还分析了人类对其亲社会行为的自我解释。通过一项在线实验（N=244），在协作图像标注任务中，聊天机器人故意犯错并向参与者解释原因，随后测量参与者的亲社会行为和意图。结果显示，聊天机器人的人类身份和情感表达显著提升了参与者的亲社会行为和意图，共情是这一效应的中介因素。定性分析进一步揭示了两种动机：对聊天机器人的共情和将其视为类人存在。本文讨论了这些结果对理解和促进人类对聊天机器人亲社会行为的启示。

</details>


### [190] [A Systematic Review of Human-AI Co-Creativity](https://arxiv.org/abs/2506.21333)
**中文标题：人机协同创造的系统综述**

*Saloni Singh,Koen Hndriks,Drik Heylen,Kim Baraka*

主要分类: cs.HC

摘要简述: 本文通过系统文献综述分析了62篇关于人机协同创造系统的论文，总结了影响系统设计的关键维度，如用户控制、系统主动性等，并提出了24条设计建议。研究发现高用户控制能提升满意度和信任感，而适应性强的主动系统能增强协作效果。


<details>
  <summary>详细信息</summary>
研究动机: 随着人机协同创造领域的发展，需要更高效、个性化的系统支持人类创造力。本文旨在通过系统综述现有研究，为未来系统设计提供理论基础和实践指导。

研究方法: 对62篇关于人机协同创造系统的论文进行了系统文献综述，涵盖视觉艺术、设计和写作等领域，分析了系统设计的关键维度。

研究结果: 研究发现高用户控制能提升用户满意度和信任感，适应性强的主动系统能增强协作效果。同时，提出了24条设计建议，强调用户思维外化和系统透明化的重要性。

研究结论: 尽管人机协同创造系统取得进展，但仍存在早期创意阶段支持不足和用户适应挑战等问题，未来需进一步优化系统设计。

中文摘要: 协同创造领域在开发更复杂、个性化的系统以支持和增强人类创造力方面取得了显著进展。先前工作的设计考虑可为未来系统提供高效且有价值的基础。为此，我们对62篇关于协同创造系统的文献进行了系统综述，涵盖视觉艺术、设计和写作等领域，其中AI不仅是工具，更是创意过程中的积极合作者。通过综述，我们确定了与系统设计相关的几个关键维度：创意过程阶段、创意任务、系统的主动性行为、用户控制、系统体现和AI模型类型。研究发现，提供高用户控制的系统能带来更高的满意度、信任感和对创意成果的拥有感。此外，适应性强且情境敏感的主动系统能增强协作效果。我们还提取了24条设计建议，强调鼓励用户外化思维以及增强系统的社交存在感和透明度以促进信任的重要性。尽管近期有所进展，但仍存在重要空白，如对问题澄清等早期创意阶段的支持不足，以及用户适应AI系统的挑战。

</details>


### [191] [Multimodal LLMs for Visualization Reconstruction and Understanding](https://arxiv.org/abs/2506.21319)
**中文标题：用于可视化重建和理解的多模态大模型**

*Can Liu,Chunlin Da,Xiaoxiao Long,Yuxiao Yang,Yu Zhang,Yong Wang*

主要分类: cs.HC

摘要简述: 本文提出了一种多模态大型语言模型，专门用于可视化的重建和理解，通过结合图表图像及其向量化表示，显著提升了数据提取和图表重建的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前的多模态大模型在自然图像理解上表现优异，但在可视化领域却难以解析数据到视觉的映射规则和提取结构化信息。因此，本文旨在解决这一挑战，提升可视化理解的能力。

研究方法: 作者提出了一种新数据集，并训练了专门用于可视化理解的多模态大模型。该方法将图表图像与其向量化表示、编码方案和数据特征相结合，通过向量格式实现可视化内容的紧凑且准确的重建。

研究结果: 实验结果表明，该方法在数据提取准确性和图表重建质量上均有显著提升。

研究结论: 本文提出的多模态可视化大模型有效解决了现有模型在可视化理解上的不足，为数据通信中的可视化分析提供了更强大的工具。

中文摘要: 可视化在数据通信中至关重要，但理解可视化需要同时掌握视觉元素及其底层数据关系。当前的多模态大模型虽然在自然图像理解上表现优异，但在可视化领域却因无法解析数据到视觉的映射规则和提取结构化信息而表现不佳。为解决这些问题，我们提出了一种新数据集，并训练了专门用于可视化理解的多模态大模型。我们的方法将图表图像与其向量化表示、编码方案和数据特征相结合。所提出的向量格式能够紧凑且准确地重建可视化内容。实验结果表明，该方法在数据提取准确性和图表重建质量上均有显著提升。

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [192] [Real-time and personalized product recommendations for large e-commerce platforms](https://arxiv.org/abs/2506.21368)
**中文标题：大型电商平台的实时个性化产品推荐**

*Matteo Tolloso,Davide Bacciu,Shahab Mokarizadeh,Marco Varesi*

主要分类: cs.IR

摘要简述: 本文提出了一种基于图神经网络和简约学习方法的实时个性化产品推荐方法，特别针对大型时尚电商平台，旨在实现高准确性和可扩展性，同时减少响应时间。


<details>
  <summary>详细信息</summary>
研究动机: 大型电商平台需要实时且个性化的产品推荐以提升用户体验，尤其是在时尚零售领域。现有方法在准确性和响应时间上存在不足，因此需要一种高效且可扩展的解决方案。

研究方法: 采用图神经网络（GNN）和简约学习方法，设计了一种能够实时处理多交互场景并预测购买序列的推荐系统。

研究结果: 在大型电商平台数据集上的实验表明，该方法能够高效生成个性化推荐，并在实际约束下表现优异。

研究结论: 该方法为大型电商平台提供了一种高效的实时个性化推荐解决方案，显著提升了用户体验和推荐准确性。

中文摘要: 我们提出了一种为大型电商平台（特别是时尚零售领域）提供实时个性化产品推荐的方法。该方法旨在通过图神经网络和简约学习方法，实现高准确性和可扩展性，同时最小化响应时间以确保用户满意度。通过对一家大型电商平台数据集的广泛实验，证明了该方法在预测购买序列和处理多交互场景中的有效性，能够在实际约束下高效生成个性化推荐。

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [193] [IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation](https://arxiv.org/abs/2506.20696)
**中文标题：IMC-PINN-FE：一种基于物理信息神经网络的左心室有限元建模方法，结合图像运动一致性与生物力学参数估计**

*Siyu Mu,Wei Xuan Chan,Choon Hwai Yap*

主要分类: physics.med-ph

摘要简述: 本文提出了一种基于物理信息神经网络（PINN）的框架IMC-PINN-FE，用于患者特异性左心室生物力学建模。该方法通过结合图像运动一致性和有限元建模，快速估计心肌刚度和主动张力，显著提升计算速度（75倍）和运动匹配精度（Dice系数从0.849提升至0.927）。


<details>
  <summary>详细信息</summary>
研究动机: 心肌的生物力学行为对理解心脏生理至关重要，但传统有限元方法计算成本高且难以准确重现心脏运动。因此，需要一种高效且精准的患者特异性建模方法。

研究方法: IMC-PINN-FE首先通过预训练的注意力网络或无监督循环正则化网络从MRI或超声心动图中估计心脏运动，并提取运动模式。随后，结合临床压力测量数据，快速估计心肌刚度和主动张力，并通过有限元建模实现快速仿真。

研究结果: IMC-PINN-FE将计算时间从传统方法的数小时缩短至秒级，运动匹配精度显著提升（Dice系数从0.849提升至0.927），同时保持了真实的压力-容积行为。

研究结论: IMC-PINN-FE通过引入材料属性的反向计算和更高的运动保真度，为快速、个性化且图像一致的心脏生物力学建模提供了高效且稳健的解决方案。

中文摘要: 阐明心肌的生物力学行为对理解心脏生理至关重要，但无法直接从临床影像中推断，通常需要有限元（FE）模拟。然而，传统FE方法计算成本高，且难以重现观测到的心脏运动。本文提出IMC-PINN-FE，一种基于物理信息神经网络（PINN）的框架，将图像运动一致性（IMC）与FE建模结合，用于患者特异性左心室（LV）生物力学建模。首先通过预训练的注意力网络或无监督循环正则化网络从MRI或超声心动图中估计心脏运动，并提取运动模式。随后，IMC-PINN-FE通过拟合临床压力测量数据，快速估计心肌刚度和主动张力，将计算时间从传统逆向FE的数小时缩短至秒级。基于这些参数，它在整个心动周期内以75倍的速度完成FE建模。通过运动约束，它更准确地匹配影像位移，将平均Dice系数从0.849提升至0.927，同时保持真实的压力-容积行为。IMC-PINN-FE通过引入材料属性的反向计算和更高的运动保真度，改进了先前的PINN-FE模型。此外，利用单例受试者的运动数据重建形状模式，避免了大规模数据集的需求，并提升了患者特异性。IMC-PINN-FE为快速、个性化且图像一致的心脏生物力学建模提供了一种高效且稳健的方法。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [194] [DRAGON: Distributional Rewards Optimize Diffusion Generative Models](https://arxiv.org/abs/2504.15217)
**中文标题：DRAGON：分布奖励优化扩散生成模型**

*Yatong Bai,Jonah Casebeer,Somayeh Sojoudi,Nicholas J. Bryan*

主要分类: cs.SD

摘要简述: 本文提出了一种名为DRAGON的通用框架，用于微调媒体生成模型以实现目标效果。相比传统的人类反馈强化学习（RLHF）或直接偏好优化（DPO），DRAGON更灵活，能够优化评估单个样本或样本分布的函数，兼容多种奖励类型。实验表明，DRAGON在20种奖励函数上平均胜率达81.45%，且无需人类偏好标注即可提升生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法如RLHF或DPO在优化生成模型时存在灵活性不足的问题，无法适应多样化的奖励函数需求。DRAGON旨在提供一种更通用的框架，支持从单个样本到分布级别的奖励优化，从而提升生成模型的性能。

研究方法: DRAGON通过选择编码器和参考样本构建示例分布，支持跨模态奖励（如文本与音频）。在线生成样本后，DRAGON通过对比正负样本集最大化奖励。实验中对音频域文本到音乐扩散模型进行了微调，测试了20种奖励函数，包括自定义音乐美学模型、CLAP分数等。

研究结果: DRAGON在20种奖励函数上平均胜率达81.45%。基于示例集的奖励函数显著提升了生成质量，且无需人类偏好标注即可实现60.95%的人类投票音乐质量胜率。

研究结论: DRAGON为设计和优化奖励函数提供了新方法，能够显著提升生成模型的人类感知质量，适用于多种任务和模态。

中文摘要: 我们提出了分布奖励生成优化框架（DRAGON），这是一种用于微调媒体生成模型以实现目标效果的通用框架。与传统的人类反馈强化学习（RLHF）或直接偏好优化（DPO）相比，DRAGON更具灵活性，能够优化评估单个样本或样本分布的奖励函数，兼容实例级、实例到分布级以及分布到分布级的多种奖励。利用这一灵活性，我们通过选择编码器和参考样本构建示例分布。当使用跨模态编码器（如CLAP）时，参考样本可以是不同模态（如文本与音频）。随后，DRAGON收集在线和策略生成样本，通过评分构建正负示例集，并利用两者对比最大化奖励。在评估中，我们对音频域文本到音乐扩散模型进行了微调，测试了20种奖励函数，包括自定义音乐美学模型、CLAP分数、Vendi多样性和Frechet音频距离（FAD）。我们还比较了实例级（单曲）和全数据集FAD设置，并对多种FAD编码器和参考集进行了消融实验。在所有20种目标奖励中，DRAGON的平均胜率达81.45%。此外，基于示例集的奖励函数确实提升了生成质量，且与基于模型的奖励相当。通过合适的示例集，DRAGON在未经人类偏好标注训练的情况下实现了60.95%的人类投票音乐质量胜率。因此，DRAGON为设计和优化奖励函数以提升人类感知质量提供了新方法。音频示例见https://ml-dragon.github.io/web。

</details>


### [195] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
**中文标题：探索低资源音乐生成中适配器设计的权衡**

*Atharva Mehta,Shivam Chauhan,Monojit Choudhury*

主要分类: cs.SD

摘要简述: 本文研究了在低资源音乐生成任务中，适配器设计的选择对性能的影响。通过比较卷积和基于Transformer的适配器，发现前者擅长捕捉局部音乐细节，后者则更适合长距离依赖。此外，中等规模的适配器（40M参数）在表达力和质量之间取得了最佳平衡。


<details>
  <summary>详细信息</summary>
研究动机: 由于微调大规模音乐生成模型（如MusicGen和Mustango）计算成本高昂，参数高效微调（PEFT）技术成为替代方案。然而，适配器的设计选择（如架构、位置和大小）对性能的影响尚不明确，尤其是在低资源音乐类型中。本文旨在探索这些设计选择的最优组合。

研究方法: 研究比较了两种AI音乐模型（MusicGen和Mustango）在不同适配器配置下的表现，重点关注两种音乐类型：印度斯坦古典音乐和土耳其Makam音乐。分析了卷积和基于Transformer的适配器在捕捉音乐细节和长距离依赖方面的差异，并评估了不同规模适配器的计算资源需求。

研究结果: 结果表明，卷积适配器擅长捕捉局部音乐细节（如装饰音和短旋律），而Transformer适配器更适合长距离依赖（如结构化即兴演奏）。中等规模适配器（40M参数）在表达力和质量之间取得最佳平衡。Mustango生成更多样化的输出，但缺乏音符稳定性和节奏对齐；MusicGen训练更快且效率更高，但生成内容冗余度略高。

研究结论: 适配器设计在低资源音乐生成中具有显著影响，不同架构和规模的适配器适用于不同需求。中等规模适配器是平衡性能与资源消耗的理想选择。Mustango和MusicGen各有优劣，需根据具体任务选择。

中文摘要: 微调大规模音乐生成模型（如MusicGen和Mustango）是一个计算成本高昂的过程，通常需要更新数十亿参数，因此需要大量硬件资源。参数高效微调（PEFT）技术，尤其是基于适配器的方法，成为一种有前景的替代方案，能够以最少的可训练参数实现模型适应，同时保持性能。然而，适配器的设计选择（如架构、位置和大小）多种多样，尚不清楚哪些组合能够为特定低资源音乐类型生成最优适配器及其原因。本文通过研究两种AI音乐模型（MusicGen和Mustango）在两种音乐类型（印度斯坦古典音乐和土耳其Makam音乐）上的不同适配器配置，试图回答这一问题。

我们的研究发现了一些明显的权衡：基于卷积的适配器擅长捕捉细粒度的局部音乐细节（如装饰音和短旋律），而基于Transformer的适配器更适合保留长距离依赖（这对结构化即兴演奏至关重要）。此外，我们分析了不同规模适配器的计算资源需求，表明中等规模适配器（40M参数）在表达力和质量之间取得了最佳平衡。我们还发现，基于扩散的模型Mustango能够生成更多样化的输出，并更好地遵循输入提示中的描述，但在音符稳定性、节奏对齐和美学方面表现不足。此外，它的计算强度高，训练时间显著更长。相比之下，自回归模型如MusicGen训练更快、效率更高，并能生成更高质量的输出，但其生成内容冗余度略高。

</details>


### [196] [A Hierarchical Deep Learning Approach for Minority Instrument Detection](https://arxiv.org/abs/2506.21167)
**中文标题：基于层次深度学习的少数乐器检测方法**

*Dylan Sechet,Francesca Bugiotti,Matthieu Kowalski,Edouard d'Hérouville,Filip Langiewicz*

主要分类: cs.SD

摘要简述: 本文提出了一种基于层次深度学习的少数乐器检测方法，通过结合Hornbostel-Sachs分类和MedleyDB数据集，展示了在粗粒度乐器检测上的可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 音乐信息检索中乐器活动的识别对音乐分类和发现至关重要，但现有深度学习研究多关注数据充足的乐器类别，而少数乐器检测仍具挑战性。

研究方法: 基于Hornbostel-Sachs分类，提出层次分类系统，利用MedleyDB数据集测试多种层次结构整合策略，并开发新模型用于层次化音乐预测。

研究结果: 实验表明，该方法在粗粒度乐器检测上表现可靠，填补了详细乐器识别与组级别识别之间的空白。

研究结论: 本研究为少数乐器检测提供了有效方法，推动了音乐信息检索领域的进一步发展。

中文摘要: 在音乐信息检索中，识别音频片段中的乐器活动对音乐分类和发现具有重要意义。现有的深度学习研究主要关注数据充足的乐器类别，而少数乐器检测仍具挑战性。近期研究表明，层次分类可用于检测管弦乐中的乐器活动，即使乐器级别的细粒度标注有限。基于Hornbostel-Sachs分类，本研究利用以多样性和丰富性著称的MedleyDB数据集评估了层次分类系统。本文提出了多种层次结构整合策略，并测试了一类新模型用于层次化音乐预测。通过填补详细乐器识别与组级别识别之间的空白，本研究展示了更可靠的粗粒度乐器检测，为该领域的进一步研究铺平了道路。

</details>


### [197] [Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou](https://arxiv.org/abs/2506.21269)
**中文标题：整合车辆声学数据以增强城市交通管理：苏州速度分类研究**

*Pengfei Fan,Yuli Zhang,Xinheng Wang,Ruiyuan Jiang,Hankang Gu,Dongyao Jia,Shangbo Wang*

主要分类: cs.SD

摘要简述: 本研究提出并公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提出了一种双模态特征融合深度卷积神经网络（BMCNN），用于车辆噪声与行驶速度的耦合建模。实验结果表明，BMCNN在SZUR-Acoustic数据集上分类准确率达87.56%，在公开IDMT-Traffic数据集上达96.28%。该方法可集成到智能城市交通管理系统中，优化交通流量控制并减少噪声污染。


<details>
  <summary>详细信息</summary>
研究动机: 城市交通管理需要实时监测车辆速度和噪声水平，但现有方法在噪声干扰下效果有限。本研究旨在通过声学数据开发一种高效的速度分类方法，以支持智能交通系统和可持续城市规划。

研究方法: 提出双模态特征融合深度卷积神经网络（BMCNN），采用自适应去噪和归一化策略预处理数据，并行分支提取MFCC和小波包能量特征，并通过跨模态注意力机制融合特征。

研究结果: BMCNN在SZUR-Acoustic数据集上分类准确率为87.56%，在IDMT-Traffic数据集上达96.28%。消融实验和鲁棒性测试验证了各模块对性能提升和过拟合缓解的贡献。

研究结论: 基于声学的速度分类方法可集成到智能城市交通管理系统中，实现实时噪声监测和速度估计，优化交通流量控制，减少噪声污染，支持可持续城市规划。

中文摘要: 本研究提出并公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提供了全面的数据采集协议和标注指南，以确保实验流程的透明性和可重复性。为建模车辆噪声与行驶速度的耦合关系，我们提出了一种双模态特征融合深度卷积神经网络（BMCNN）。在预处理阶段，采用自适应去噪和归一化策略抑制环境背景干扰；在网络架构中，并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，随后通过跨模态注意力机制在中间特征空间融合，以充分利用时频信息。实验结果表明，BMCNN在SZUR-Acoustic数据集上的分类准确率为87.56%，在公开的IDMT-Traffic数据集上达96.28%。消融实验和鲁棒性测试进一步验证了各模块对性能提升和过拟合缓解的贡献。所提出的基于声学的速度分类方法可集成到智能城市交通管理系统中，实现实时噪声监测和速度估计，从而优化交通流量控制，减少路边噪声污染，并支持可持续城市规划。

</details>


### [198] [SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture](https://arxiv.org/abs/2506.21478)
**中文标题：SmoothSinger：一种基于多分辨率架构的条件扩散模型用于歌唱声音合成**

*Kehan Sui,Jinxu Xiang,Fang Jin*

主要分类: cs.SD

摘要简述: SmoothSinger是一种基于条件扩散模型的歌唱声音合成方法，通过多分辨率架构和参考引导的双分支设计，直接优化低质量音频，避免了两阶段流程的失真问题，显著提升了合成声音的自然度和表现力。


<details>
  <summary>详细信息</summary>
研究动机: 歌唱声音合成（SVS）需要精确建模音高、时长和发音，而现有扩散模型在SVS中因复杂的声学和音乐特性导致合成声音存在失真。SmoothSinger旨在通过统一框架直接优化合成音频，避免依赖声码器带来的失真问题。

研究方法: SmoothSinger采用参考引导的双分支架构，利用低质量音频作为参考指导去噪过程，并结合并行低频上采样路径增强音高轮廓和长时频谱依赖的建模。训练时用退化的真实音频替代参考音频，解决时序不匹配问题。

研究结果: 在Opencpop数据集上的实验表明，SmoothSinger在客观和主观评估中均达到最优性能，消融实验证实其能有效减少失真并提升合成声音的自然度。

研究结论: SmoothSinger通过统一框架和多分辨率设计，显著提升了歌唱声音合成的质量，为SVS领域提供了一种高效且自然的解决方案。

中文摘要: 歌唱声音合成（SVS）旨在从乐谱中生成富有表现力的高质量人声，需要精确建模音高、时长和发音。尽管扩散模型在图像和视频生成中取得了显著成功，但其在SVS中的应用仍面临挑战，主要因歌唱的复杂声学和音乐特性常导致失真，影响自然度。本文提出SmoothSinger，一种条件扩散模型，用于合成高质量且自然的歌唱声音。与依赖声码器作为最终阶段并常引入失真的现有方法不同，SmoothSinger在统一框架中直接优化低质量合成音频，缓解了两阶段流程的性能下降问题。该模型采用参考引导的双分支架构，以任何基线系统的低质量音频为参考，指导去噪过程，实现更具表现力和上下文感知的合成。此外，通过并行低频上采样路径增强传统U-Net，使模型更好地捕捉音高轮廓和长时频谱依赖。为解决参考音频与目标信号间的时序不匹配问题，训练中用退化的真实音频替代参考音频。在Opencpop数据集（大规模中文歌唱语料库）上的实验表明，SmoothSinger在客观和主观评估中均达到最优性能。大量消融实验证实其在减少失真和提升合成声音自然度方面的有效性。

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [199] [From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting](https://arxiv.org/abs/2506.21246)
**中文标题：从链上到宏观：评估数据源多样性在加密货币市场预测中的重要性**

*Giorgos Demosthenous,Chryssis Georgiou,Eliada Polydorou*

主要分类: q-fin.PM

摘要简述: 本研究探讨了数据源多样性对加密货币市场预测模型性能的影响，通过整合多种数据类别（如技术指标、链上指标、情绪指标、传统市场指数和宏观经济指标），提出了一种新的特征降维算法，并证明了数据源多样性显著提升了预测模型的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 加密货币市场的预测模型通常依赖于单一数据源，而忽略了其他潜在有价值的数据类别。本研究旨在通过整合多样化的数据源，探索其对预测模型性能的影响，并为市场驱动因素提供更全面的理解。

研究方法: 研究引入了代表市值前100的加密货币的Crypto100指数，并提出了一种新的特征降维算法，从多样化的数据源中筛选出最具影响力和鲁棒性的特征。通过综合实验，评估了不同数据源对预测模型性能的贡献。

研究结果: 实验结果表明，数据源多样性显著提升了预测模型在不同时间尺度上的性能。链上指标对短期和长期预测均至关重要，而传统市场指数和宏观经济指标在长期预测中的作用逐渐增强。

研究结论: 本研究揭示了加密货币市场的短期和长期驱动因素，为开发更准确和鲁棒的预测模型奠定了基础。数据源多样性是提升预测性能的关键因素。

中文摘要: 本研究通过整合技术指标、链上指标、情绪和兴趣指标、传统市场指数以及宏观经济指标等多种数据类别，探讨了数据源多样性对加密货币预测模型性能的影响。我们引入了代表市值前100的加密货币的Crypto100指数，并提出了一种新的特征降维算法，以从多样化数据源中识别最具影响力和鲁棒性的特征。综合实验表明，数据源多样性显著提升了预测模型在不同时间尺度上的性能。关键发现包括链上指标对短期和长期预测的至关重要性，传统市场指数和宏观经济指标在长期预测中的日益相关性，以及使用多样化数据源时模型准确性的显著提升。这些发现有助于揭示加密货币市场的短期和长期驱动因素，并为开发更准确和鲁棒的预测模型奠定了基础。

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [200] [ResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers](https://arxiv.org/abs/2506.21537)
**中文标题：ResQ：一种在模拟Rydberg原子量子计算机上实现残差神经网络的新框架**

*Nicholas S. DiBrita,Jason Han,Tirthak Patel*

主要分类: quant-ph

摘要简述: 本文提出ResQ框架，利用模拟Rydberg原子量子计算机实现残差神经网络（ResNets），探索量子机器学习中神经ODE的新应用。


<details>
  <summary>详细信息</summary>
研究动机: 量子机器学习潜力巨大，但神经ODE为基础的ResNets尚未在量子计算中探索。本文旨在利用Rydberg原子量子计算机的特性，优化ResNets在分类问题中的应用。

研究方法: 提出ResQ框架，通过模拟Rydberg原子量子计算机的动态优化，实现量子神经ODE，解决机器学习分类问题。

研究结果: ResQ框架成功展示了Rydberg原子量子计算机在ResNets中的适用性，为量子机器学习提供了新方向。

研究结论: Rydberg原子量子计算机特别适合实现ResNets，ResQ框架为量子机器学习中的神经ODE应用开辟了新途径。

中文摘要: 量子机器学习研究近年来蓬勃发展，得益于量子计算在加速机器学习方面的潜力。然而，基于神经常微分方程（神经ODE）的残差神经网络（ResNets）尚未被探索，这类网络旨在利用常微分方程原理提升神经网络效能。本文阐述了模拟Rydberg原子量子计算机特别适合ResNets的原因，并提出了ResQ框架，通过优化Rydberg原子量子计算机的动态特性，利用模拟量子神经ODE解决机器学习中的分类问题。

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [201] [Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs](https://arxiv.org/abs/2506.20980)
**中文标题：增强同质-异质分离：异质图中的关系感知学习**

*Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu*

主要分类: cs.SI

摘要简述: 本文提出了一种名为RASH的新型对比学习框架，用于在异质图中显式建模高阶语义并自适应分离同质和异质模式，解决了异质性和异质性问题。


<details>
  <summary>详细信息</summary>
研究动机: 现实世界中的网络通常具有节点异质性，即连接的节点具有不同的特征或标签。这一问题在同质图中已有广泛研究，但在异质图中仍未被充分探索。现有方法通常将异质图转换为同质图以学习节点异质性，但会丢失异质关系中的潜在异质性。

研究方法: RASH框架通过引入双重异质超图来编码多关系二分子图，并基于关系重要性动态构建同质图和异质图。设计了一种多关系对比损失，通过最大化互信息来对齐异质和同质/异质视图。

研究结果: 在基准数据集上的大量实验表明，RASH在各种下游任务中均表现出色。

研究结论: RASH成功解决了异质图中的异质性和异质性问题，为相关研究提供了新的思路。

中文摘要: 现实世界中的网络通常具有节点异质性，即连接的节点通常具有不同的特征或标签。这一问题在同质图中已被广泛研究，但在异质图中仍未被充分探索，因为异质图中存在多种类型的节点和边。在异质图中捕捉节点异质性非常具有挑战性，因为需要同时考虑节点/边的异质性和节点异质性。现有方法通常将异质图转换为同质图以学习节点异质性，但这会不可避免地丢失异质关系中潜在的异质性。为了填补这一空白，我们提出了关系感知的同质-异质分离（RASH），这是一种新型对比学习框架，显式建模异质交互的高阶语义并自适应分离同质和异质模式。具体而言，RASH引入了双重异质超图来编码多关系二分子图，并基于关系重要性动态构建同质图和异质图。设计了一种多关系对比损失，通过最大化互信息来对齐异质和同质/异质视图。通过这种方式，RASH同时解决了异质图中的异质性和异质性问题。在基准数据集上的大量实验证明了RASH在各种下游任务中的有效性。代码可在以下网址获取：https://github.com/zhengziyu77/RASH。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [202] [Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems](https://arxiv.org/abs/2506.20685)
**中文标题：渐进式尺寸自适应联邦学习：面向异构多模态数据系统的综合框架**

*Sajid Hussain,Muhammad Sohail,Nauman Ali Khan,Naima Iltaf,Ihtesham ul Islam*

主要分类: cs.LG

摘要简述: 本文提出了一种基于数据集大小特性的渐进式自适应联邦学习框架（SAFL），通过多模态数据实验揭示了数据集大小对联邦学习效果的影响，并展示了SAFL在通信效率和性能上的优势。


<details>
  <summary>详细信息</summary>
研究动机: 现有联邦学习方法主要关注模型异构性和聚合技术，而忽略了数据集大小特性对联邦学习动态的根本影响。本文旨在填补这一空白，提出一种基于数据集大小特性的自适应联邦学习框架。

研究方法: 提出了一种名为SAFL的渐进式训练框架，通过系统化组织联邦学习，基于多模态数据集的大小特性进行训练。实验覆盖了13个不同数据集和7种模态（视觉、文本、时间序列、音频、传感器、医学视觉和多模态）。

研究结果: 实验发现：1）联邦学习的最佳数据集大小范围为1000-1500样本；2）结构化数据（时间序列、传感器）性能显著优于非结构化数据（文本、多模态）；3）超过2000样本的大数据集会导致性能下降。SAFL平均准确率达87.68%，结构化数据模态准确率超过99%，通信效率高，总数据传输量仅为7.38 GB。

研究结论: SAFL填补了数据特性如何驱动联邦学习策略的关键空白，为实际部署提供了理论和实践指导。

中文摘要: 联邦学习（FL）已成为一种在保护数据隐私的同时实现分布式机器学习的变革性范式。然而，现有方法主要关注模型异构性和聚合技术，很大程度上忽略了数据集大小特性对联邦学习动态的根本影响。本文提出了基于尺寸的自适应联邦学习（SAFL），这是一种新颖的渐进式训练框架，基于异构多模态数据的数据集大小特性系统化组织联邦学习。我们在涵盖7种模态（视觉、文本、时间序列、音频、传感器、医学视觉和多模态）的13个不同数据集上进行了全面实验评估，揭示了以下关键发现：1）联邦学习的最佳数据集大小范围为1000-1500样本；2）结构化数据（时间序列、传感器）性能显著优于非结构化数据（文本、多模态）；3）超过2000样本的大数据集会导致系统性性能下降。SAFL在所有数据集上的平均准确率达到87.68%，结构化数据模态的准确率超过99%。该框架展示了卓越的通信效率，在558次通信中总数据传输量仅为7.38 GB，同时保持了高性能。我们的实时监控框架为系统资源利用率、网络效率和训练动态提供了前所未有的洞察。这项工作填补了理解数据特性如何驱动联邦学习策略的关键空白，为神经网络和学习系统中实际联邦学习部署提供了理论见解和实践指导。

</details>


### [203] [Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models](https://arxiv.org/abs/2506.20701)
**中文标题：扩散树采样：扩散模型的可扩展推理时对齐**

*Vineet Jain,Kusha Sareen,Mohammad Pedramfar,Siamak Ravanbakhsh*

主要分类: cs.LG

摘要简述: 本文提出了一种名为扩散树采样（DTS）的新方法，通过将推理时对齐问题转化为搜索问题，并利用蒙特卡洛树搜索的思想，显著提升了扩散模型在推理时对齐新目标的效率和样本质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前扩散模型在推理时对齐新目标时存在价值估计不准确和计算资源浪费的问题，尤其是在高噪声水平下。本文旨在通过复用过去计算信息，提升对齐效率和样本质量。

研究方法: 提出扩散树采样（DTS）方法，将推理时对齐问题转化为搜索问题，通过传播终端奖励并迭代优化价值估计，生成目标分布的渐近精确样本。其贪婪变体DTS$^\star$则用于全局搜索高奖励样本。

研究结果: 在MNIST和CIFAR-10类条件生成任务中，DTS以10倍计算效率匹配最佳基线FID。在文本到图像生成和语言完成任务中，DTS$^\star$以5倍计算效率匹配最佳样本。

研究结论: DTS通过复用过去计算信息，将额外计算转化为持续提升的样本质量，为扩散模型的推理时对齐提供了可扩展的解决方案。

中文摘要: 在生成建模中，如何将预训练的扩散模型在推理时对齐新目标仍是一个开放问题。现有引导方法存在价值估计不准确的问题，尤其是在高噪声水平下，导致引导偏差。此外，过去运行的信息未被复用，计算效率低下。受蒙特卡洛树搜索启发，我们将推理时对齐问题转化为搜索问题，复用过去计算信息。我们提出了一种基于树的方法，通过传播终端奖励并通过扩散链迭代优化价值估计，从奖励对齐的目标密度中采样。提出的扩散树采样（DTS）方法在无限次扩展下生成目标分布的渐近精确样本，其贪婪变体DTS$^\star$则用于全局搜索高奖励样本。在MNIST和CIFAR-10类条件生成任务中，DTS以10倍计算效率匹配最佳基线FID。在文本到图像生成和语言完成任务中，DTS$^\star$以5倍计算效率匹配最佳样本。通过复用过去生成的信息，我们获得了一种随时可用的算法，将额外计算转化为持续提升的样本质量，为扩散模型的推理时对齐提供了可扩展的方法。

</details>


### [204] [On Convolutions, Intrinsic Dimension, and Diffusion Models](https://arxiv.org/abs/2506.20705)
**中文标题：关于卷积、内在维度和扩散模型**

*Kin Kwan Leung,Rasa Hosseinzadeh,Gabriel Loaiza-Ganem*

主要分类: cs.LG

摘要简述: 本文证明了FLIPD（一种基于扩散模型的局部内在维度估计器）在现实假设下的正确性，并扩展了其在均匀卷积下的适用性。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型（DMs）能够学习低维支撑的分布，但FLIPD的理论基础仅在不现实的仿射子流形假设下得到证明。本文旨在填补这一理论空白，并探讨均匀卷积下的类似结果。

研究方法: 通过理论分析，证明了FLIPD在现实假设下的正确性，并研究了高斯卷积替换为均匀卷积时的类似结果。

研究结果: FLIPD在现实假设下被证明是正确的，且均匀卷积下也存在类似结论。

研究结论: 本文完善了FLIPD的理论基础，并扩展了其在均匀卷积下的适用性，为LID估计提供了更全面的支持。

中文摘要: 流形假设认为，高维环境空间（如图像数据）中的数据位于未知的低维子流形上。扩散模型（DMs）通过逐步增加高斯噪声并学习逆转这一过程，已成为性能最优的生成模型，并能够学习低维支撑的分布。对于子流形中的某个数据点，我们直观地期望DMs能隐式学习其局部内在维度（LID），即其所属子流形的维度。Kamkari等人（2024b）最近通过将LID与DM对数边际密度随噪声量变化率联系起来，证明了这一点，并提出了一种称为FLIPD的LID估计器。FLIPD等LID估计器用途广泛，例如量化数据复杂度、检测异常值和对抗样本等。FLIPD在LID估计中达到了最先进的性能，但其理论基础尚不完整，因为Kamkari等人仅在不现实的仿射子流形假设下证明了其正确性。本文填补了这一空白，在现实假设下正式证明了FLIPD的正确性。此外，我们还证明了高斯卷积替换为均匀卷积时的类似结果，并讨论了其意义。

</details>


### [205] [Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset](https://arxiv.org/abs/2506.20729)
**中文标题：理论物理中的测试时扩展技术——基于TPBench数据集的方法比较**

*Zhiqi Gao,Tianyi Li,Yurii Kvasiuk,Sai Chaitanya Tadepalli,Maja Rudolph,Daniel J. H. Chung,Frederic Sala,Moritz Münchmeyer*

主要分类: cs.LG

摘要简述: 本文研究了测试时扩展技术在理论物理领域的应用，通过TPBench数据集比较了多种方法的有效性，并提出了一种新的符号弱验证框架。结果表明，该方法在TPBench上显著优于现有方法，并在数学推理基准AIME上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在复杂推理中表现出色，测试时扩展技术能以较低成本提升其性能。然而，这些方法主要在数学推理基准（如AIME）上开发和评估。本文旨在探讨这些方法是否适用于高级理论物理领域，并开发更高效的扩展技术。

研究方法: 本文在TPBench物理数据集上评估了多种常见测试时扩展方法，并与AIME的结果进行比较。为了更好地利用物理问题的结构，提出了一种新颖的符号弱验证框架，以改进并行扩展效果。

研究结果: 实验结果表明，提出的符号弱验证框架在TPBench上显著优于现有测试时扩展方法。同时，该方法在AIME上也表现出色，验证了其在解决复杂数学问题中的有效性。

研究结论: 本文证明了逐步符号验证在解决复杂科学问题中的强大能力，为理论物理领域的测试时扩展技术提供了新的思路。

中文摘要: 大型语言模型（LLM）在复杂推理中表现出强大的能力，而测试时扩展技术能以较低成本进一步提升其性能。这些方法主要在数学推理基准（如AIME）上开发和评估。本文研究了这些方法是否适用于高级理论物理领域，并在TPBench物理数据集上评估了多种常见测试时扩展方法的有效性。为了更好地利用物理问题的结构，我们开发了一种新颖的符号弱验证框架，以改进并行扩展效果。实验结果表明，该方法在TPBench上显著优于现有测试时扩展方法。我们还在AIME上验证了该方法的有效性，证实了其在解决高级数学问题中的优势。研究结果凸显了逐步符号验证在解决复杂科学问题中的强大潜力。

</details>


### [206] [Stochastic Parameter Decomposition](https://arxiv.org/abs/2506.20790)
**中文标题：随机参数分解**

*Lucius Bushnaq,Dan Braun,Lee Sharkey*

主要分类: cs.LG

摘要简述: 本文提出了一种名为随机参数分解（SPD）的新方法，解决了现有线性参数分解方法（如APD）计算成本高和对超参数敏感的问题，使其能够应用于更大、更复杂的模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前主流的线性参数分解方法（如APD）存在计算成本高和对超参数敏感的问题，限制了其在大规模模型中的应用。本文旨在提出一种更高效、更稳健的方法，以推动神经网络分解技术的发展。

研究方法: 本文提出了随机参数分解（SPD）方法，通过结合因果中介分析和网络分解技术，解决了APD方法的计算和超参数问题，并提升了参数分解的准确性和可扩展性。

研究结果: 实验表明，SPD方法在计算效率和超参数鲁棒性上优于APD，能够分解更大、更复杂的模型，同时避免了参数收缩问题，并在玩具模型中更准确地识别真实机制。

研究结论: SPD方法为线性参数分解技术的扩展提供了新思路，消除了其在大型模型中的应用障碍，为机制可解释性研究开辟了新的可能性。

中文摘要: 逆向工程神经网络的一个关键步骤是将其分解为可以相对独立研究的更简单部分。线性参数分解——一种旨在解决当前分解方法若干问题的框架——将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，该框架中的主流方法——基于归因的参数分解（APD）——由于计算成本高和对超参数敏感而不实用。本文提出了随机参数分解（SPD），一种比APD更具可扩展性和超参数鲁棒性的方法，并通过分解比APD所能处理的更大、更复杂的模型来证明其优势。我们还表明，SPD避免了其他问题，如学习参数的收缩，并在玩具模型中更准确地识别真实机制。通过将因果中介分析与网络分解方法相结合，这一成果为机制可解释性研究开辟了新的可能性，消除了线性参数分解方法在大型模型中扩展的障碍。我们在https://github.com/goodfire-ai/spd发布了运行SPD和复现实验的库。

</details>


### [207] [GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization](https://arxiv.org/abs/2506.20807)
**中文标题：GPU内核科学家：一种基于LLM的迭代内核优化框架**

*Martin Andrews,Sam Witteveen*

主要分类: cs.LG

摘要简述: 本文提出了一种基于LLM的自动化方法“GPU Kernel Scientist”，用于迭代优化GPU内核，特别针对资源受限或快速演进的硬件环境。该方法通过多阶段进化过程，利用LLM选择代码版本、生成优化假设并自动实现实验，展示了LLM驱动代理在GPU内核优化中的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 优化GPU内核以提升性能是一项复杂任务，尤其是在针对新型或文档较少的GPU架构时，传统开发辅助工具稀缺。本文旨在通过LLM驱动的自动化方法，解决这一挑战，降低对领域专家知识的依赖。

研究方法: 方法采用多阶段进化过程：(a) 选择有潜力的历史代码版本作为新迭代基础；(b) 基于现有代码和GPU文献知识生成优化假设；(c) 通过代码修改自动实现实验，并仅依赖计时数据作为性能反馈。该方法特别针对AMD MI300架构进行了优化。

研究结果: 由于性能竞赛的定量结果在提交时被限制，本文重点介绍了架构设计、操作流程和定性见解，展示了LLM驱动代理在GPU内核优化中的潜力。

研究结论: LLM驱动的自动化方法能够显著降低GPU内核优化的门槛，加速优化过程，特别适用于资源受限或硬件快速演进的环境。

中文摘要: 优化GPU内核以实现高性能是一项复杂任务，通常需要深入的架构知识、大量性能分析和迭代实验。这一挑战在针对新型或文档较少的GPU架构时尤为突出，传统开发辅助工具稀缺。本文介绍了一种基于LLM的“GPU内核科学家”方法，用于自动化迭代优化加速器内核。

我们的方法采用多阶段进化过程：(a) 策略性地选择有潜力的历史代码版本作为新迭代基础；(b) 基于现有代码和GPU文献知识生成优化假设；(c) 通过代码修改自动实现实验，并仅依赖计时数据作为性能反馈。我们详细说明了该方法如何应对AMD MI300目标架构的挑战，并利用LLM弥补领域专家知识的不足。

由于性能竞赛的定量结果在提交时被限制，本文重点介绍了架构设计、操作流程和定性见解，突出了LLM驱动代理在GPU内核优化中的潜力，尤其是在资源受限或硬件快速演进的环境中。

</details>


### [208] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
**中文标题：FINN-GL：面向FPGA加速LSTM的广义混合精度扩展**

*Shashwat Khandelwal,Jakoba Petri-Koenig,Thomas B. Preußer,Michaela Blott,Shreejith Shanker*

主要分类: cs.LG

摘要简述: 本文提出了一种基于FINN框架的广义混合精度扩展方法FINN-GL，用于在FPGA上高效部署LSTM模型，解决了现有工具主要针对前馈网络的问题，并通过量化技术和硬件映射优化实现了性能与资源消耗的平衡。


<details>
  <summary>详细信息</summary>
研究动机: LSTM在时间序列任务中表现优异，但其计算复杂度高，难以在资源受限环境中实时部署。FPGA虽能高效加速AI计算，但现有工具主要针对前馈网络，LSTM加速通常需要完全定制实现。本文旨在填补这一空白，利用FINN框架实现LSTM的广义部署。

研究方法: 本文利用ONNX规范中的Scan算子建模LSTM的循环计算特性，支持混合量化与功能验证。通过FINN编译器中的自定义变换，将量化后的ONNX计算图映射到FINN编译器和Vitis HLS的硬件块库中。

研究结果: 实验通过量化ConvLSTM模型在股票价格预测任务中验证了所提流程的有效性，生成的硬件IP在XCZU7EV设备上实现了性能与资源消耗的平衡，同时保持了与现有模型相当的推理精度。

研究结论: FINN-GL的广义性为FPGA上资源高效的RNN加速器设计铺平了道路，未来可进一步推广到其他RNN架构。

中文摘要: 递归神经网络（RNN），尤其是LSTM，在情感分析和短期股票预测等时间序列任务中表现优异。然而，其计算复杂度对资源受限环境中的实时部署提出了挑战。尽管FPGA为能效优化的AI加速提供了理想平台，但现有工具主要针对前馈网络，而LSTM加速通常需要完全定制实现。本文通过利用开源且可扩展的FINN框架，填补了这一空白，实现了LSTM在FPGA上的广义部署。具体而言，我们利用开放神经网络交换（ONNX）规范中的Scan算子建模LSTM的循环计算特性，支持其内部的混合量化及基于LSTM模型的功能验证。此外，我们在FINN编译器中引入自定义变换，将量化后的ONNX计算图映射到FINN编译器和Vitis HLS的硬件块库中。通过使用广泛数据集训练量化ConvLSTM模型进行股票中间价预测任务，并生成对应的硬件IP（目标设备为XCZU7EV），我们验证了所提工具流程的有效性。结果表明，通过本流程生成的量化ConvLSTM加速器在性能（延迟）与资源消耗之间取得了平衡，同时与现有模型相比，在降低精度的情况下保持了（或优于）推理精度。我们相信，所提流程的广义性将为FPGA上资源高效的RNN加速器设计铺平道路。

</details>


### [209] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
**中文标题：更精简的训练，更低的泄露：重新审视LoRA微调中LLM的记忆问题**

*Fei Wang,Baochun Li*

主要分类: cs.LG

摘要简述: 本文重新审视了大型语言模型（LLM）微调中的记忆问题，发现LoRA微调在降低记忆风险方面优于全参数微调，同时保持任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索LoRA微调对记忆问题的影响，揭示其与预训练和全参数微调中记忆行为的差异。

研究方法: 通过基于相似性的记忆度量方法，比较LoRA微调和全参数微调在不同模型规模和数据重复情况下的记忆表现。

研究结果: 结果显示，LoRA微调显著减少了记忆风险，且不受模型规模和数据重复的显著影响，同时任务性能保持良好。

研究结论: 结论表明，LoRA微调是一种在降低记忆风险的同时保持高效任务性能的可行方法。

中文摘要: 大型语言模型（LLM）的记忆特性使其容易受到数据提取攻击。尽管预训练中的记忆问题已被广泛研究，但较少有工作探讨其在微调中的影响，尤其是对于广泛采用的参数高效方法LoRA微调。本研究重新审视了微调中的记忆问题，并发现其与预训练和全参数微调中的记忆行为存在显著差异。模型规模和数据重复等因素在预训练和全参数微调中强烈影响记忆，但在LoRA微调中并未表现出相同趋势。通过使用更宽松的基于相似性的记忆度量方法，我们证明LoRA微调相比全参数微调显著降低了记忆风险，同时仍保持强大的任务性能。

</details>


### [210] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
**中文标题：SharpZO：基于前向传播的混合锐度感知视觉语言模型提示调优**

*Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang*

主要分类: cs.LG

摘要简述: 本文提出了一种混合锐度感知零阶优化方法（SharpZO），通过仅使用前向传播优化视觉语言模型（VLM）的提示调优，显著提升了性能和收敛速度。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型（VLM）微调方法依赖反向传播（BP），不适用于内存受限的边缘设备。虽然已有无需BP的微调方法，但其性能往往不佳。本文旨在解决这一问题。

研究方法: SharpZO采用两阶段优化：首先通过锐度感知进化策略（ES）全局探索和平滑损失曲面以构建强初始化，随后通过稀疏零阶（ZO）优化进行细粒度局部搜索。整个过程仅需前向传播。

研究结果: 在CLIP模型上的实验表明，SharpZO显著提升了准确性和收敛速度，平均性能优于现有仅需前向传播的方法7%。

研究结论: SharpZO为无需反向传播的VLM微调提供了一种高效解决方案，适用于边缘设备。

中文摘要: 视觉语言模型（VLM）的微调在各种下游任务中表现优异，但通常需要依赖反向传播（BP），因此不适用于内存受限的边缘设备。为解决这一问题，先前的研究探索了多种无需BP的微调方法，但这些方法往往依赖高方差的进化策略（ES）或零阶（ZO）优化，性能不尽如人意。本文提出了一种混合锐度感知零阶优化方法（SharpZO），通过锐度感知预热训练提升ZO VLM微调的性能。SharpZO采用两阶段优化：首先通过锐度感知ES阶段全局探索和平滑损失曲面以构建强初始化，随后通过稀疏ZO优化进行细粒度局部搜索。整个优化过程仅需前向传播。详细的理论分析和在CLIP模型上的实验表明，SharpZO显著提升了准确性和收敛速度，平均性能优于现有仅需前向传播的方法7%。

</details>


### [211] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
**中文标题：利用知识图谱生成高质量指令数据以增强大语言模型的工具使用能力**

*Jingwei Wang,Zai Zhang,Hao Qian,Chunjing Gan,Binbin Hu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Bin Shi,Bo Dong*

主要分类: cs.LG

摘要简述: 本文提出一种利用知识图谱生成高质量指令数据的方法，以提升大语言模型（LLM）的工具使用能力。实验表明，仅需少量合成数据微调即可显著提升LLM的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型（LLM）在工具使用方面面临挑战，主要因生成的指令数据质量不足。本文旨在通过知识图谱的丰富语义信息，生成高质量指令数据，以提升LLM的工具使用能力。

研究方法: 方法包括从知识图谱中提取查询路径，将其转化为多样化的用户查询；将实体间关系转化为可操作工具；并将查询路径解析为详细解决步骤，生成高质量指令数据。

研究结果: 实验结果表明，仅需少量合成数据微调，即可显著提升LLM的工具利用能力和整体性能。

研究结论: 通过知识图谱生成的高质量指令数据能有效提升LLM的工具使用能力，为LLM的应用扩展提供了新思路。

中文摘要: 教授大语言模型（LLM）使用工具对提升其问题解决能力和扩展应用至关重要。然而，有效使用工具需要深入理解工具功能和用户意图，这具有挑战性。以往方法主要依赖LLM生成指令数据，但数据质量往往不足。本文提出一种新方法，利用知识图谱为LLM生成高质量指令数据。知识图谱是人工整理的富含语义信息的数据集。我们首先从给定知识图谱中提取多种查询路径，并将其转化为广泛的用户查询；随后将实体间关系转化为可操作工具，并将每条查询路径解析为详细解决步骤，从而生成高质量指令数据。实验表明，仅需少量合成数据微调即可显著提升LLM的工具利用能力和整体性能。

</details>


### [212] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
**中文标题：学习跳过Transformer的中间层**

*Tim Lawson,Laurence Aitchison*

主要分类: cs.LG

摘要简述: 本文提出了一种动态跳过Transformer中间层的架构，通过门控机制决定是否跳过对称的中间块，并控制残差范数和门稀疏性。尽管目标是减少计算需求，但在实验规模下未能在验证交叉熵与FLOPs之间取得优于密集基线的效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常独立跳过单个模块或层，但研究表明Transformer中间层冗余性较高。本文旨在通过动态跳过中间层来提升效率，并探索多级表征层次的可能性。

研究方法: 提出了一种动态跳过中间层的架构，包括学习门控机制决定跳过对称中间块、门控注意力机制防止后续令牌关注跳过的位置，以及通过‘三明治’或‘perilayernorm’方案控制残差范数，并使用自适应正则化损失控制门稀疏性。

研究结果: 在实验规模下，该方法未能在验证交叉熵与FLOPs的权衡中优于层数较少的密集基线模型。

研究结论: 尽管动态跳过中间层的设计具有潜力，但在当前实验规模下未能显著提升效率与性能的权衡。代码已开源。

中文摘要: 条件计算是提升Transformer效率的常用策略。现有方法通常针对单个模块（如混合专家层）或独立跳过层。然而，可解释性研究表明，Transformer的中间层冗余性较高，且早期层将信息聚合到令牌位置。基于这些发现，我们提出了一种新颖架构，动态从中间向外跳过可变数量的层。具体而言，学习的门控机制根据输入决定是否绕过对称的中心块跨度，门控注意力机制防止后续令牌关注跳过的令牌位置。通过‘三明治’或‘perilayernorm’方案控制残差范数，并通过自适应正则化损失控制门稀疏性。我们旨在减少‘简单’令牌的计算需求，并可能促进多级表征层次的涌现，但在研究规模下，与层数较少的密集基线相比，该方法未能在验证交叉熵与估计FLOPs的权衡中取得改进。代码发布于https://github.com/tim-lawson/skip-middle。

</details>


### [213] [Omniwise: Predicting GPU Kernels Performance with LLMs](https://arxiv.org/abs/2506.20886)
**中文标题：Omniwise：利用大型语言模型预测GPU内核性能**

*Zixian Wang,Cole Ramos,Muhammad A. Awad,Keith Lowery*

主要分类: cs.LG

摘要简述: Omniwise是一种基于大型语言模型（LLM）的端到端自监督微调管道，用于预测GPU内核性能，无需执行代码或使用分析工具即可预测关键性能指标，并在AMD MI250和MI300X架构上实现了90%以上的预测准确率。


<details>
  <summary>详细信息</summary>
研究动机: 随着深度神经网络（DNN）的快速发展，GPU内核性能预测成为优化计算任务的关键。传统方法依赖代码执行或分析工具，效率低下。Omniwise旨在利用LLM实现高效、轻量级的性能预测，为开发者提供便捷工具。

研究方法: Omniwise采用自监督微调管道，利用LLM直接从内核代码预测性能指标（如内存带宽、缓存命中率、GFLOPs等）。该方法无需代码执行或分析工具，支持3B参数的小型模型，并开发了在线推理服务器和Visual Studio Code插件。

研究结果: 在AMD MI250和MI300X架构上，Omniwise的预测准确率超过90%（相对误差在10%以内），能够高效预测GPU内核的关键性能指标。

研究结论: Omniwise展示了LLM在GPU内核性能预测中的潜力，提供了一种轻量级、高效的解决方案，并通过工具集成优化了开发者工作流程。

中文摘要: 近年来，深度神经网络（DNN）的快速发展彻底改变了人工智能，使模型在理解、生成和处理复杂数据方面具备前所未有的能力。这些强大的架构广泛应用于下游任务，解决了人类难以企及的问题。本文介绍了Omniwise，这是首个端到端、自监督的微调管道，将大型语言模型（LLM）应用于GPU内核性能预测——性能分析中的一个新颖用例。Omniwise与模型无关且轻量级，即使使用3B参数的小型模型也能取得显著效果。它可以直接从内核代码预测关键性能指标（如内存带宽、缓存命中率、GFLOPs和算术强度），无需代码执行或分析工具。我们的方法在AMD MI250和MI300X架构上执行的GPU内核中，实现了90%以上的预测准确率（相对误差在10%以内）。除管道外，我们还开发了在线推理服务器和Visual Studio Code插件，将基于LLM的性能预测无缝集成到开发者工作流程中。

</details>


### [214] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
**中文标题：复杂度感知的微调**

*Andrey Goncharov,Daniil Vyazhev,Petr Sychev,Edvard Khalafyan,Alexey Zaytsev*

主要分类: cs.LG

摘要简述: 本文提出了一种基于熵识别复杂数据的高效微调方法，通过将训练数据按复杂度分类并结合监督微调（SFT）和蒸馏技术，显著提升了小规模语言模型的性能，同时减少了数据需求。


<details>
  <summary>详细信息</summary>
研究动机: 通用大语言模型（LLMs）通常通过监督微调（SFT）在特定领域提升性能，但更好的结果往往需要从更大模型中提取思维链，代价是高昂的计算和大量数据。本文旨在设计一种高效微调方法，仅对复杂数据使用推理，以降低成本并提升效果。

研究方法: 研究提出了一种基于熵的复杂度分类方法，将训练数据分为不同复杂度类别（ROC AUC为0.73）。随后结合监督微调（SFT）和蒸馏技术对两个小规模开源模型（约30亿参数）进行微调。

研究结果: 实验表明，该方法显著优于标准SFT方法（平均准确率0.55 vs 0.43），同时与蒸馏方法性能相当，但数据使用量减少了62%（两者平均准确率均为0.55）。

研究结论: 本文提出的复杂度感知微调方法在提升模型性能的同时大幅降低了数据需求，为高效微调提供了新思路。代码和数据已公开以促进进一步研究。

中文摘要: 通用大语言模型（LLMs）通常通过监督微调（SFT）在特定领域提升性能。通过从更大模型中提取思维链可以获得更好的结果，但代价是大量昂贵的调用和更多数据。我们提出了一种高效微调的新方法，仅对通过熵识别的复杂数据使用推理。具体而言，在两个小规模开源模型（约30亿参数）上，我们通过单标记答案熵（ROC AUC为0.73）将训练数据分为复杂度类别，并通过SFT和蒸馏技术微调LLMs。实验表明，我们的方法显著优于标准SFT方法（平均准确率0.55 vs 0.43），同时与蒸馏方法性能相当，但数据使用量减少了62%（两者平均准确率均为0.55）。我们公开了代码和数据以促进该方向的进一步研究。

</details>


### [215] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
**中文标题：DiLoCoX：一种面向去中心化集群的低通信大规模训练框架**

*Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich*

主要分类: cs.LG

摘要简述: DiLoCoX是一种低通信的大规模分布式集群训练框架，通过结合流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案，显著提升了模型预训练的参数规模和速度。


<details>
  <summary>详细信息</summary>
研究动机: 当前大规模语言模型的分布式训练高度依赖高速可靠的集中式集群通信，限制了在慢速网络或去中心化集群中的应用。本文旨在解决这一问题，提出一种适用于超百亿参数模型的低通信训练框架。

研究方法: DiLoCoX结合了流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案，通过理论收敛分析验证了其有效性。

研究结果: 实验表明，DiLoCoX能够在1Gbps网络上预训练107B参数的模型，相比传统AllReduce方法，训练速度提升357倍，且模型收敛性能几乎无损失。

研究结论: DiLoCoX是首个成功应用于超百亿参数模型的去中心化训练框架，为慢速网络环境下的分布式训练提供了高效解决方案。

中文摘要: 基础模型（尤其是大语言模型）的分布式训练需要高水平的通信，因此高度依赖具有快速可靠互连的集中式集群。我们能否在慢速网络上进行训练，从而在参数超过1000亿的模型中释放去中心化集群的潜力？本文提出DiLoCoX，一种低通信的大规模去中心化集群训练框架。它结合了流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案，显著提升了参数规模和模型预训练速度。通过收敛性理论分析，我们验证了一步延迟重叠和自适应梯度压缩的优势。实验表明，DiLoCoX能够在1Gbps网络上预训练107B参数的模型，相比传统AllReduce方法，训练速度提升357倍，且模型收敛性能几乎无损失。据我们所知，这是首个成功应用于超百亿参数模型的去中心化训练框架。

</details>


### [216] [LLM-guided Chemical Process Optimization with a Multi-Agent Approach](https://arxiv.org/abs/2506.20921)
**中文标题：基于多智能体方法的LLM引导化学过程优化**

*Tong Zeng,Srivathsan Badrinarayanan,Janghoon Ock,Cheng-Kai Lai,Amir Barati Farimani*

主要分类: cs.LG

摘要简述: 本文提出了一种基于多智能体框架的LLM（大语言模型）引导的化学过程优化方法，通过自主推断操作约束并协作优化，显著提升了计算效率和优化性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统化学过程优化方法在操作约束不明确或不可用时效率低下，依赖主观启发式方法。本文旨在解决这一瓶颈，提出一种无需预定义操作边界的优化框架。

研究方法: 采用基于AutoGen的多智能体框架，包括约束生成、参数验证、模拟执行和优化指导智能体。通过两阶段（自主约束生成和迭代多智能体优化）实现优化目标。

研究结果: 在氢化脱烷基化过程中验证，该方法在成本、产量和产量成本比指标上表现优异，计算效率显著提升，收敛速度快于传统方法31倍。

研究结论: 该方法在操作约束不明确或不可用的场景中具有显著潜力，尤其适用于新兴过程和改造应用。

中文摘要: 化学过程优化对最大化生产效率和经济效益至关重要。传统方法（如基于梯度的求解器、进化算法和参数网格搜索）在操作约束不明确或不可用时变得不切实际，工程师需依赖主观启发式方法估计可行参数范围。为解决这一约束定义瓶颈，我们提出了一种基于大语言模型（LLM）智能体的多智能体框架，能够从最小过程描述中自主推断操作约束，并协作指导优化。我们的AutoGen智能体框架采用OpenAI的o3模型，包含约束生成、参数验证、模拟执行和优化指导智能体。通过两阶段（基于嵌入领域知识的自主约束生成和迭代多智能体优化），该框架无需预定义操作边界。在氢化脱烷基化过程中验证，该框架在成本、产量和产量成本比指标上表现优异，计算效率显著提升，收敛速度快于网格搜索31倍。此外，该框架的推理引导搜索展示了复杂过程理解能力，正确识别了效用权衡并应用领域启发式方法。该方法在操作约束不明确或不可用的优化场景中具有显著潜力，尤其适用于新兴过程和改造应用。

</details>


### [217] [Interpretable Representation Learning for Additive Rule Ensembles](https://arxiv.org/abs/2506.20927)
**中文标题：可加性规则集成的可解释表示学习**

*Shahrzad Behzadimanesh,Pierre Le Bodic,Geoffrey I. Webb,Mario Boley*

主要分类: cs.LG

摘要简述: 本文提出了一种可解释的表示学习方法，通过引入可学习的稀疏线性变换扩展传统规则集成，以生成具有斜边决策区域的规则，从而在保持高精度的同时显著降低模型复杂度。


<details>
  <summary>详细信息</summary>
研究动机: 传统符号规则集成依赖简单的阈值命题，虽然易于解释，但在特征表达能力不足时需要增加规则数量和复杂度，导致模型可解释性下降。本文旨在通过引入可学习的稀疏线性变换，提升规则表达能力，同时保持模型的可解释性。

研究方法: 提出了一种基于可学习稀疏线性变换的逻辑命题形式（如 $\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$），并采用基于迭代加权逻辑回归的序列贪婪优化方法进行学习。

研究结果: 实验结果表明，该方法在十个基准数据集上能够高效构建规则集成，其测试风险与现有最优方法相当，同时显著降低了模型复杂度。

研究结论: 通过引入可学习的稀疏线性变换，本文方法在保持高精度的同时提升了规则的可解释性，为可解释表示学习提供了新思路。

中文摘要: 小型符号规则的可加性集成提供了可解释的预测模型。传统上，这些集成使用基于单个输入变量$x$和阈值$t$的简单阈值命题$x \geq t$的合取规则条件，几何上表现为轴平行多面体作为决策区域。虽然这种形式确保了单个规则的高度可解释性，并且可以通过梯度提升方法高效学习，但它依赖于一组经过精心设计的表达性强且理想独立的输入特征，以便少量轴平行区域能够很好地描述目标变量。若缺乏此类特征，要达到足够的准确性需要增加规则的数量和复杂度，从而降低模型的可解释性。本文通过引入具有可学习稀疏线性变换的逻辑命题（即形式为$\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$的命题，其中$\mathbf{w}$为可学习的稀疏权重向量）扩展了传统规则集成，从而支持具有斜边的一般多面体作为决策区域。我们提出了一种基于迭代加权逻辑回归的序列贪婪优化学习方法。实验结果表明，所提方法能够高效构建规则集成，在十个基准数据集上达到与现有最优方法相同的测试风险，同时显著降低了模型复杂度。

</details>


### [218] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
**中文标题：潜在原型路由：在混合专家中实现近乎完美的负载均衡**

*Jiajie Yang*

主要分类: cs.LG

摘要简述: 提出了一种名为潜在原型路由（LPR）的新方法，通过聚类视角改进专家路由，显著提升了混合专家（MoE）模型的负载均衡性，同时不影响下游任务性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前混合专家（MoE）系统存在严重的负载不均衡问题，仅少数专家在训练和推理中被激活，导致模型容量和计算资源的大量浪费。

研究方法: 通过聚类视角重新设计专家路由，提出潜在原型路由（LPR）框架，推广现有方法并促进专家均衡利用。

研究结果: 实验表明，LPR将专家负载的基尼系数从0.70降至0.035，最小-最大专家负载比从1e-6提升至0.70，实现了近乎完美的负载均衡。

研究结论: LPR是一种高效的专家路由框架，显著改善了MoE系统的负载均衡性，同时保持了模型性能。

中文摘要: 混合专家（MoE）架构已成为高效扩展大型语言模型（LLM）的关键策略。然而，当前的MoE系统存在严重的负载不均衡问题，仅少数专家在训练和推理中被持续激活，导致模型容量和计算资源的显著浪费。本文从聚类视角重新审视专家路由，提出潜在原型路由（LPR），这是一种新型路由框架，推广了现有方法，同时在不影响下游性能的情况下促进专家均衡利用。在多个开源MoE模型（包括DeepSeek-V3、Qwen3-MoE和Mixtral）上的广泛实验表明，LPR将专家负载的基尼系数从0.70降至0.035，最小-最大专家负载比从1e-6提升至0.70，实现了近乎完美的负载均衡。

</details>


### [219] [Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding](https://arxiv.org/abs/2506.20957)
**中文标题：基于多尺度等变图扩散模型的抗体设计与优化以实现精准复杂抗原结合**

*Jiameng Chen,Xiantao Cai,Jia Wu,Wenbin Hu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为AbMEGD的端到端框架，通过多尺度等变图扩散模型实现抗体序列与结构的协同设计，显著提升了复杂抗原结合的准确性和功能性。


<details>
  <summary>详细信息</summary>
研究动机: 抗体设计在治疗和诊断开发中至关重要，但现有方法难以捕捉几何特征并保持对称性，且对新型抗原界面的泛化能力不足。AbMEGD旨在解决这些挑战。

研究方法: AbMEGD结合了多尺度等变图扩散模型，整合原子级几何特征和残基级嵌入，利用E(3)-等变扩散方法确保几何精度和计算效率。

研究结果: 实验表明，AbMEGD在SAbDab数据库中，氨基酸恢复率提高了10.13%，改进百分比上升了3.32%，关键CDR-H3区域的均方根偏差降低了0.062 Å，优于DiffAb模型。

研究结论: AbMEGD在保持结构完整性的同时提升了功能性，为抗体序列-结构协同设计和亲和力优化设立了新标准。

中文摘要: 抗体设计在治疗和诊断开发中仍是一个关键挑战，尤其是针对具有多样化结合界面的复杂抗原。当前计算方法存在两大局限：(1) 在保持对称性的同时捕捉几何特征，(2) 对新型抗原界面的泛化能力。尽管近期有所进展，这些方法仍难以准确捕捉分子相互作用并维持结构完整性。为解决这些问题，我们提出了AbMEGD，一种端到端框架，整合了多尺度等变图扩散以实现抗体序列与结构的协同设计。借助先进的几何深度学习，AbMEGD将原子级几何特征与残基级嵌入相结合，捕捉局部原子细节和全局序列-结构相互作用。其E(3)-等变扩散方法确保了几何精度、计算效率以及对复杂抗原的鲁棒泛化能力。此外，基于SAbDab数据库的实验表明，与领先的抗体设计模型DiffAb相比，AbMEGD在关键CDR-H3区域的氨基酸恢复率提高了10.13%，改进百分比上升了3.32%，均方根偏差降低了0.062 Å。这些结果突显了AbMEGD在平衡结构完整性与功能改进方面的能力，为序列-结构协同设计和亲和力优化设立了新标准。代码发布于：https://github.com/Patrick221215/AbMEGD。

</details>


### [220] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
**中文标题：通过随机变分子空间推理实现大型语言模型的可扩展贝叶斯低秩适应**

*Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ScalaBL的可扩展贝叶斯低秩适应方法，通过随机变分子空间推理，解决了大型语言模型（LLMs）在不确定性量化中的扩展性问题。该方法仅需约1000个额外参数，即可实现与现有最优方法竞争的性能，并成功应用于迄今为止最大的贝叶斯LLM。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）存在幻觉和校准不佳的问题，在高风险领域（如自主系统和医疗）中，不确定性量化尤为重要。现有基于贝叶斯深度学习的方法虽有效，但难以扩展到更大的LLMs。本文旨在解决这一问题。

研究方法: 提出ScalaBL方法，通过在低秩适应（LoRA）参数的r维子空间中进行贝叶斯推理，并利用LoRA参数作为投影矩阵，将子空间样本映射到LLM的完整权重空间。使用随机变分推理学习所有参数。

研究结果: 尽管子空间维度较低，ScalaBL仅需约1000个额外参数，即可实现与现有最优方法竞争的性能，并成功扩展到迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

研究结论: ScalaBL通过随机变分子空间推理，提供了一种高效且可扩展的贝叶斯低秩适应方法，为大型语言模型的不确定性量化提供了新的解决方案。

中文摘要: 尽管大型语言模型（LLMs）被广泛使用，但它们存在幻觉错误信息和校准不佳的问题，这使得不确定性量化尤为重要，尤其是在高风险领域（如自主系统和医疗）。先前的研究通过基于贝叶斯深度学习的方法对微调模型的低秩适应（LoRA）参数进行推理，使问题更易处理。虽然有效，但这些方法由于需要比LoRA更多的额外参数，难以扩展到更大的LLMs。本文提出了一种名为ScalaBL的可扩展贝叶斯低秩适应方法，通过随机变分子空间推理，在LoRA秩为r的r维子空间中进行贝叶斯推理。通过将LoRA参数重新用作投影矩阵，我们可以将子空间样本映射到LLM的完整权重空间。这使得我们能够使用随机变分推理学习所有参数。尽管子空间维度较低，我们仅需约1000个额外参数即可实现与现有最优方法竞争的性能。此外，该方法使我们能够扩展到迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

</details>


### [221] [Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2506.21039)
**中文标题：严格子目标执行：分层强化学习中可靠的长时程规划**

*Jaebak Hwang,Sanghyeon Lee,Jeongmo Kim,Seungyul Han*

主要分类: cs.LG

摘要简述: 本文提出了一种名为严格子目标执行（SSE）的分层强化学习框架，通过约束高层决策确保子目标可达性，结合解耦探索策略和失败感知路径优化，显著提升了长时程任务的效率和成功率。


<details>
  <summary>详细信息</summary>
研究动机: 长时程目标导向任务在强化学习中面临目标遥远和奖励稀疏的挑战，现有分层和图基方法存在子目标不可达和规划效率低的问题，因此需要一种更可靠的解决方案。

研究方法: SSE框架通过结构约束确保单步子目标可达性，采用解耦探索策略系统探索目标空间未开发区域，并通过失败感知路径优化动态调整边成本以提高子目标可靠性。

研究结果: 在多种长时程基准测试中，SSE在效率和成功率上均优于现有目标导向和分层强化学习方法。

研究结论: SSE通过严格子目标执行和动态路径优化，显著提升了长时程任务的性能，为分层强化学习提供了可靠解决方案。

中文摘要: 长时程目标导向任务对强化学习（RL）提出了根本性挑战，尤其是当目标遥远且奖励稀疏时。尽管分层和图基方法提供了部分解决方案，但它们常因子目标不可达和规划效率低下而受限。我们提出了严格子目标执行（SSE），这是一种基于图的分层RL框架，通过结构约束高层决策来强制单步子目标可达性。为增强探索，SSE采用了一种解耦探索策略，系统性地遍历目标空间中未开发的区域。此外，失败感知路径优化通过根据观察到的低层成功率动态调整边成本，从而优化基于图的规划，提高子目标可靠性。在多种长时程基准测试中的实验结果表明，SSE在效率和成功率上均优于现有的目标导向RL和分层RL方法。

</details>


### [222] [Efficient Skill Discovery via Regret-Aware Optimization](https://arxiv.org/abs/2506.21044)
**中文标题：基于遗憾感知优化的高效技能发现**

*He Zhang,Ming Zhou,Shaopeng Zhai,Ying Sun,Hui Xiong*

主要分类: cs.LG

摘要简述: 本文提出了一种基于遗憾感知优化的高效技能发现方法，通过将技能发现建模为技能生成与策略学习的极小极大博弈，显著提升了高维环境下的效率和多样性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无监督技能发现方法虽在探索性上表现良好，但在高维环境中效率较低。本文旨在通过优化技能发现与策略学习的对抗关系，提升技能发现的效率和多样性。

研究方法: 将技能发现建模为技能生成与策略学习的极小极大博弈，利用遗憾评分衡量技能强度的收敛程度，并通过可学习的技能生成器指导技能发现。为避免退化，技能生成器来自可升级的生成器群体。

研究结果: 实验表明，该方法在复杂和高维环境中均优于基线方法，效率与多样性均有提升，且在高维环境中实现了15%的零样本改进。

研究结论: 本文提出的遗憾感知优化方法有效解决了高维环境中技能发现的效率问题，同时提升了多样性，为无监督技能发现提供了新思路。

中文摘要: 无监督技能发现旨在开放强化学习中学习多样且可区分的行为。现有方法通过纯探索、互信息优化和学习时间表示来提升多样性，但在高维环境中效率有限。本文提出将技能发现建模为技能生成与策略学习的极小极大博弈，基于时间表示学习提出一种遗憾感知方法，沿可升级策略强度的方向扩展技能空间。关键观点是技能发现与策略学习是对抗的：强度弱的技能需进一步探索，而强度收敛的技能则减少探索。具体实现中，用遗憾评分强度收敛程度，并通过可学习的技能生成器指导技能发现。为避免退化，技能生成器来自可升级的生成器群体。实验表明，该方法在复杂和高维环境中均优于基线方法，效率与多样性均有提升，且在高维环境中实现了15%的零样本改进。

</details>


### [223] [FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation](https://arxiv.org/abs/2506.21095)
**中文标题：FeDa4Fair：用于公平性评估的客户端级联邦数据集**

*Xenia Heilmann,Luca Corbucci,Mattia Cerrato,Anna Monreale*

主要分类: cs.LG

摘要简述: 联邦学习（FL）允许多个客户端在不共享私有数据的情况下协作训练模型，但公平性仍是一个关键问题。本文提出FeDa4Fair库，用于生成评估公平FL方法的表格数据集，并发布四个具有异质偏见的基准数据集。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习中的公平性问题因客户端本地数据集的偏见而备受关注，现有解决方案多关注单一敏感属性，忽略了不同客户端的多样化公平需求。本文旨在支持更稳健和可复现的公平性研究，提供一致的公平性评估基准。

研究方法: 本文提出FeDa4Fair库，用于生成评估公平FL方法的表格数据集，并发布四个异质偏见数据集及相应基准。此外，提供了现成的公平性评估函数。

研究结果: FeDa4Fair库和四个异质偏见数据集为公平性研究提供了可控环境下的基准测试工具，支持全球和客户端级别的公平性评估。

研究结论: FeDa4Fair为联邦学习中的公平性研究提供了标准化工具和数据集，有助于更全面地评估和比较公平性增强方法。

中文摘要: 联邦学习（FL）允许多个客户端在不共享私有数据的情况下协作训练模型。然而，公平性仍是一个关键问题，因为本地客户端数据集的偏见可能影响整个联邦系统。客户端间的异质数据分布可能导致模型对某些客户端更公平。尽管文献中有多种公平性增强解决方案，但大多数关注单一敏感属性（通常是二元的），忽略了不同客户端的多样化公平需求。这种局限性可能影响公平性干预措施的效果。为了支持更稳健和可复现的联邦学习公平性研究，我们旨在为全球和客户端级别的公平性FL方法提供一致的基准测试。本文的贡献包括：（1）引入FeDa4Fair库，用于生成评估异质客户端偏见下公平FL方法的表格数据集；（2）发布四个异质偏见数据集及相应基准，以在可控环境中比较公平性缓解方法；（3）提供现成的公平性评估函数。

</details>


### [224] [Interpretable Hierarchical Concept Reasoning through Attention-Guided Graph Learning](https://arxiv.org/abs/2506.21102)
**中文标题：通过注意力引导的图学习实现可解释的层次化概念推理**

*David Debot,Pietro Barbiero,Gabriele Dominici,Giuseppe Marra*

主要分类: cs.LG

摘要简述: 本文提出了一种名为H-CMR的新型概念推理模型，通过注意力机制和层次化图学习，实现了对概念和任务预测的双重可解释性，同时保持了高性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的概念模型（CBMs）仅对最终任务预测提供解释性，而概念预测本身仍依赖黑箱神经网络。本文旨在解决这一局限性，提出一种同时对概念和任务预测提供解释性的模型。

研究方法: H-CMR通过有向无环图建模概念间关系，边表示逻辑规则。推理时，使用注意力机制选择规则子集，并层次化地预测所有概念和最终任务。

研究结果: 实验表明，H-CMR在保持高性能的同时，支持通过概念和模型干预实现强人机交互，显著提升推理准确性和训练数据效率。

研究结论: H-CMR不仅实现了概念和任务预测的双重可解释性，还通过干预机制提升了模型的实用性和灵活性。

中文摘要: 概念模型（CBMs）是一类通过高层概念解释预测的深度学习模型，其先预测概念再用于下游任务。然而，现有CBMs仅对最终任务预测提供解释性，而概念预测本身通常由黑箱神经网络完成。为解决这一问题，我们提出层次化概念记忆推理器（H-CMR），一种同时对概念和任务预测提供解释性的新CBM。H-CMR通过有向无环图建模概念间关系，边表示定义概念的逻辑规则。推理时，H-CMR使用注意力机制选择规则子集，并层次化地预测所有概念和最终任务。实验表明，H-CMR在保持高性能的同时，支持通过概念和模型干预实现强人机交互。前者可显著提升推理准确性，后者在背景知识可用时可提升训练数据效率。

</details>


### [225] [Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments](https://arxiv.org/abs/2506.21127)
**中文标题：无人机对抗环境中抗脆弱强化学习的鲁棒策略切换方法**

*Deepak Kumar Panda,Weisi Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种抗脆弱强化学习框架，通过动态切换策略应对无人机在对抗环境中的导航冲突，显著提升了对抗攻击的适应能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着无人机导航自动化的增加，其易受对抗攻击的弱点暴露，现有鲁棒强化学习方法对分布外变化的泛化能力有限。本文旨在通过抗脆弱框架提升对更广泛分布变化的适应性。

研究方法: 提出了一种基于折扣汤普森采样（DTS）的动态策略切换机制，通过多臂老虎机模型选择最优策略，以最小化对抗性引起的状态-动作-值分布偏移。

研究结果: 在复杂导航环境中，该方法相比传统鲁棒强化学习方法表现出更短的导航路径和更高的无冲突轨迹率，有效应对了投影梯度下降（PGD）和欺骗攻击。

研究结论: 抗脆弱强化学习框架通过动态策略切换显著提升了无人机在对抗环境中的导航性能，为未来研究提供了新的方向。

中文摘要: 无人机导航自动化的增加使其面临通过传感器操纵利用强化学习（RL）漏洞的对抗攻击。尽管现有鲁棒RL方法旨在缓解此类威胁，但其对最优值分布外变化的泛化能力有限，主要针对固定扰动设计。为应对这一局限，本文提出了一种抗脆弱RL框架，通过基于折扣汤普森采样（DTS）的切换机制增强对更广泛分布变化的适应性。该机制动态选择多种鲁棒策略，以最小化对抗性引起的状态-动作-值分布偏移。所提方法首先通过考虑策略空间中的一系列扰动，生成多样化的鲁棒策略集合，随后将其建模为多臂老虎机（MAB）问题，其中DTS根据非平稳伯努利奖励最优选择策略，有效适应演化的对抗策略。理论框架表明，通过优化DTS以最小化分布偏移导致的总体遗憾，能够有效应对未见对抗攻击，从而实现抗脆弱性。大量数值模拟验证了该框架在复杂导航环境中的有效性，包括多动态三维障碍物及更强的投影梯度下降（PGD）和欺骗攻击。相比传统非自适应鲁棒RL方法，抗脆弱方法表现出更优性能，导航路径更短且无冲突轨迹率更高。

</details>


### [226] [Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks](https://arxiv.org/abs/2506.21129)
**中文标题：课程引导的抗脆弱强化学习用于观测空间攻击下的安全无人机冲突避免**

*Deepak Kumar Panda,Adolfo Perrusquia,Weisi Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种抗脆弱的强化学习框架，通过逐步增加的对抗扰动课程训练，使无人机在动态空域中能够抵御观测空间攻击，提升安全性和决策能力。


<details>
  <summary>详细信息</summary>
研究动机: 在安全关键系统中，如无人机导航，强化学习策略容易受到观测空间的对抗攻击，导致性能下降或决策不安全。现有方法对此类攻击的适应性不足，亟需一种抗脆弱的学习框架。

研究方法: 提出了一种抗脆弱强化学习框架，通过模拟攻击者逐步增加观测空间的扰动强度，训练智能体适应更广泛的异常观测。理论分析了脆弱性，定义了抗脆弱性条件，并通过Wasserstein距离最小化实现专家引导的批评对齐。

研究结果: 在无人机冲突避免场景中，抗脆弱策略在PGD和GPS欺骗攻击下表现优于标准及鲁棒强化学习基线，累计奖励提高15%，冲突事件减少30%。

研究结论: 抗脆弱强化学习框架在理论和实践上均证明可行，适用于威胁环境不断演变的场景，为安全决策提供了新思路。

中文摘要: 强化学习（RL）策略在安全关键系统（如动态空域中的无人机导航）中部署时，容易受到观测空间的分布外（OOD）对抗攻击。这些攻击导致分布偏移，显著降低价值估计，引发不安全或次优决策，使现有策略变得脆弱。为应对这一脆弱性，我们提出了一种抗脆弱RL框架，旨在适应逐步增加的对抗扰动课程。该框架引入模拟攻击者，逐步增强观测空间扰动强度，使RL智能体能适应更广泛的OOD观测并预测未知攻击。我们从理论上刻画了脆弱性，将灾难性遗忘定义为价值函数分布随扰动强度增加的单调发散。基于此，我们将抗脆弱性定义为此类价值偏移的有界性，并推导出稳定遗忘的适应条件。我们的方法通过Wasserstein距离最小化在逐步扰动的观测上迭代实现专家引导的批评对齐，从而强制这些界限。我们在涉及动态3D障碍物的无人机冲突避免场景中实证评估了该方法。结果表明，抗脆弱策略在投影梯度下降（PGD）和GPS欺骗攻击下始终优于标准和鲁棒RL基线，累计奖励提高15%，冲突事件减少30%。这些发现证明了抗脆弱强化学习在威胁环境不断演变的场景中实现安全弹性决策的理论和实践可行性。

</details>


### [227] [DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding](https://arxiv.org/abs/2506.21140)
**中文标题：DBConformer：用于EEG解码的双分支卷积Transformer**

*Ziwei Wang,Hongbin Wang,Tianwang Jia,Xingyi He,Siyang Li,Dongrui Wu*

主要分类: cs.LG

摘要简述: DBConformer是一种双分支卷积Transformer网络，专为EEG解码设计，结合时间与空间特征，显著优于现有模型，且参数更少。


<details>
  <summary>详细信息</summary>
研究动机: 传统CNN在EEG解码中因感受野短而难以捕捉长时程依赖和通道间关系，现有CNN-Transformer混合模型多为串行设计，未能充分整合局部与全局特征。

研究方法: 提出DBConformer，包含时间分支（建模长时程依赖）和空间分支（提取通道间交互），并引入轻量级通道注意力模块优化空间表征。

研究结果: 在五个运动想象数据集和两个癫痫检测数据集上，DBConformer优于10个基线模型，参数减少8倍以上，且特征具有生理可解释性。

研究结论: DBConformer性能优越且可解释，适用于稳健的EEG解码，代码已开源。

中文摘要: 基于脑电图（EEG）的脑机接口（BCIs）将自发/诱发神经活动转化为外部通信控制命令。尽管卷积神经网络（CNN）仍是EEG解码的主流架构，但其固有的短感受野难以捕捉长时程依赖和全局通道间关系。近期CNN-Transformer（Conformer）混合模型部分解决了这一问题，但多数采用串行设计，导致局部与全局特征整合不足，且常忽略显式通道建模。为此，我们提出DBConformer，一种专为EEG解码设计的双分支卷积Transformer网络。它整合了时间Conformer（建模长时程依赖）和空间Conformer（提取通道间交互），同时捕捉EEG信号的时序动态与空间模式。轻量级通道注意力模块通过数据驱动分配通道重要性，进一步优化空间表征。在五个运动想象（MI）数据集和两个癫痫检测数据集上的三种评估设置中，DBConformer均优于10个竞争基线模型，且参数比高容量EEG Conformer基线少八倍以上。可视化结果证实，DBConformer提取的特征具有生理可解释性，并与MI中的感觉运动先验一致。DBConformer的卓越性能与可解释性使其成为稳健且可解释EEG解码的可靠选择。代码已公开于https://github.com/wzwvv/DBConformer。

</details>


### [228] [Linearity-based neural network compression](https://arxiv.org/abs/2506.21146)
**中文标题：基于线性特性的神经网络压缩**

*Silas Dobler,Florian Lemmerich*

主要分类: cs.LG

摘要简述: 本文提出了一种基于线性特性的神经网络压缩新方法，通过合并行为接近线性的神经元层，实现了模型大小的显著减小，且与其他压缩技术兼容。


<details>
  <summary>详细信息</summary>
研究动机: 当前神经网络压缩方法主要通过测量参数重要性和冗余性来减少不必要的参数。为了进一步提升现有优化方案的性能，本文提出了一种基于线性特性的压缩方法，旨在通过合并行为接近线性的神经元层来减少权重。

研究方法: 该方法基于ReLU类激活函数中神经元行为接近线性的特性，提出了一种理论框架，允许合并后续层。实验验证了该方法的有效性。

研究结果: 实验结果表明，该方法在多数测试模型中实现了无损压缩，模型大小可缩减至原始模型的1/4。此外，该方法与基于重要性的剪枝技术兼容，干扰极小。

研究结论: 本文为一种新型神经网络压缩方法奠定了基础，能够实现更小、更高效的模型，并展示了与其他压缩技术的成功结合潜力。

中文摘要: 在神经网络压缩领域，当前大多数方法通过测量参数的重要性和冗余性来减少不必要的参数。为了进一步提升现有优化方案的性能，我们提出了一种基于线性特性的压缩方法，作为一种减少神经网络权重的新途径。该方法基于以下直觉：在使用ReLU类激活函数时，几乎总是被激活的神经元表现出线性行为，从而允许合并后续层。我们介绍了支持这种压缩的理论，并通过实验评估了该方法。我们的新方法在多数测试模型中实现了无损压缩，模型大小可缩减至原始模型的1/4。将该方法应用于已基于重要性剪枝的模型时，显示出不同压缩技术之间的干扰极小，证明了技术成功结合的可能性。总体而言，我们的工作为一种新型压缩方法奠定了基础，能够实现更小、最终更高效的神经网络模型。

</details>


### [229] [rQdia: Regularizing Q-Value Distributions With Image Augmentation](https://arxiv.org/abs/2506.21367)
**中文标题：rQdia：通过图像增强正则化Q值分布**

*Sam Lerman,Jing Bi*

主要分类: cs.LG

摘要简述: rQdia通过图像增强正则化Q值分布，显著提升了基于像素的深度强化学习性能，在多个任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 在基于像素的深度强化学习中，Q值分布的不稳定性限制了性能。rQdia旨在通过图像增强技术正则化Q值分布，提升模型的样本效率和长期训练效果。

研究方法: rQdia通过简单的辅助损失函数（均方误差）对增强图像的Q值分布进行正则化，从而稳定训练过程。该方法适用于多种强化学习算法，如DrQ、SAC和Data-Efficient Rainbow。

研究结果: 在MuJoCo连续控制任务中，rQdia显著提升了DrQ和SAC的性能（分别9/12和10/12任务），在Atari游戏中提升了Data-Efficient Rainbow的性能（18/26任务）。此外，rQdia首次使基于像素的无模型连续控制超越了状态编码基线。

研究结论: rQdia通过正则化Q值分布，显著提升了基于像素的深度强化学习性能，为无模型连续控制任务提供了新的解决方案。

中文摘要: rQdia通过增强图像对基于像素的深度强化学习中的Q值分布进行正则化。通过简单的辅助损失函数（均方误差）均衡这些分布，rQdia在MuJoCo连续控制套件中分别提升了DrQ和SAC在9/12和10/12任务上的性能，并在Atari Arcade环境中提升了Data-Efficient Rainbow在18/26任务上的性能。提升体现在样本效率和长期训练中。此外，rQdia首次使基于像素的无模型连续控制超越了状态编码基线。

</details>


### [230] [Pay Attention to Small Weights](https://arxiv.org/abs/2506.21374)
**中文标题：关注小权重**

*Chao Zhou,Tom Jacobs,Advait Gadhikar,Rebekka Burkholz*

主要分类: cs.LG

摘要简述: 微调大型预训练神经网络通常资源密集，研究发现小权重与大梯度相关，提出NANOADAM方法动态更新小权重，提升效率并避免灾难性遗忘。


<details>
  <summary>详细信息</summary>
研究动机: 微调大型预训练模型需要大量资源，研究发现小权重与大梯度相关，尤其在微调中更显著，因此提出动态更新小权重的方法以优化资源利用。

研究方法: 提出NANOADAM方法，动态更新小权重，无需梯度计算即可确定参数子集，保留大权重以减少灾难性遗忘，并支持更大学习率。

研究结果: NANOADAM在NLP和视觉任务中表现优异，提升泛化性能，同时减少计算资源消耗。

研究结论: NANOADAM通过动态更新小权重，高效微调模型，保留关键特征并提升性能，适用于多种任务。

中文摘要: 微调大型预训练神经网络在内存和计算成本上资源密集。为缓解这一问题，通常限制训练参数子集。通过分析微调中梯度与权重的关系，发现大梯度常与小权重相关，且微调中更显著。基于此，提出NANOADAM方法，动态更新小权重，具有以下优势：1）无需梯度计算即可确定参数子集；2）保留大权重以减少灾难性遗忘；3）支持更大学习率，实验显示泛化性能更优。该方法在NLP和视觉任务中均表现良好。

</details>


### [231] [Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection](https://arxiv.org/abs/2506.21382)
**中文标题：时间感知图注意力网络在加密货币交易欺诈检测中的应用**

*Zhi Zheng,Bochuan Zhou,Yuping Song*

主要分类: cs.LG

摘要简述: 本文提出了一种增强时间感知的图注意力网络（ATGAT），用于加密货币交易欺诈检测，通过融合多尺度时间差特征和周期性位置编码，结合三重注意力机制，显著提升了检测性能。


<details>
  <summary>详细信息</summary>
研究动机: 加密货币交易欺诈检测面临交易模式复杂和类别不平衡的双重挑战，传统方法难以捕捉交易网络中的时间和结构依赖关系，因此需要一种更高效的方法。

研究方法: ATGAT包含三个模块：(1) 高级时间嵌入模块，融合多尺度时间差特征和周期性位置编码；(2) 时间感知三重注意力机制，联合优化结构、时间和全局上下文注意力；(3) 使用加权BCE损失解决类别不平衡问题。

研究结果: 在Elliptic++数据集上，ATGAT的AUC达到0.9130，比传统方法XGBoost提升9.2%，比GCN提升12.0%，比标准GAT提升10.0%。

研究结论: ATGAT验证了时间感知和三重注意力机制对图神经网络的增强效果，为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广至其他时间图异常检测任务。

中文摘要: 加密货币交易欺诈检测面临交易模式日益复杂和类别严重不平衡的双重挑战。传统方法依赖人工特征工程，难以捕捉交易网络中的时间和结构依赖关系。本文提出了一种增强时间感知的图注意力网络（ATGAT），通过三个模块提升检测性能：(1) 设计高级时间嵌入模块，融合多尺度时间差特征与周期性位置编码；(2) 构建时间感知三重注意力机制，联合优化结构、时间和全局上下文注意力；(3) 使用加权BCE损失解决类别不平衡问题。在Elliptic++加密货币数据集上的实验表明，ATGAT的AUC达到0.9130，比最佳传统方法XGBoost提升9.2%，比GCN提升12.0%，比标准GAT提升10.0%。该方法不仅验证了时间感知和三重注意力机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广至其他时间图异常检测任务。

</details>


### [232] [Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach for Efficiency and Low Storage](https://arxiv.org/abs/2506.21465)
**中文标题：优化四阶龙格-库塔方法：一种动态启发式方法以实现高效与低存储**

*Gavin Lee Goodship,Luis Miralles-Pechuan,Stephen O'Sullivan*

主要分类: cs.LG

摘要简述: 本文提出了一种结合遗传算法（GA）和强化学习（RL）的动态启发式方法，用于优化低存储的扩展稳定性龙格-库塔（ESRK）方法，显著提高了计算效率并保持了四阶精度。


<details>
  <summary>详细信息</summary>
研究动机: 扩展稳定性龙格-库塔（ESRK）方法在科学和工程的大规模计算问题中至关重要，但传统方法在平衡精度、稳定性和计算效率方面存在挑战，尤其是在高阶低存储方案中。本研究旨在通过自动化启发式发现解决这一问题。

研究方法: 采用遗传算法（GA）驱动的突变进行搜索空间探索，并结合强化学习（RL）的状态转换机制动态优化启发式选择，从而系统减少参数并保持四阶精度。

研究结果: 在基准问题（如1D和2D Brusselator系统及稳态Navier-Stokes方程）上验证了该方法的有效性，最佳启发式方法将IPOPT运行时间减少了25%，同时保持了数值稳定性和精度。

研究结论: 该研究为数值方法的启发式优化建立了新范式，展示了自适应启发式发现在高保真模拟中提高资源效率的潜力，并为低存储龙格-库塔方法在计算流体动力学等领域的广泛应用奠定了基础。

中文摘要: 扩展稳定性龙格-库塔（ESRK）方法在科学和工程的大规模计算问题（如天气预报、空气动力学分析和复杂生物建模）中至关重要。然而，平衡精度、稳定性和计算效率仍然具有挑战性，尤其是对于高阶低存储方案。本研究引入了一种结合遗传算法（GA）和强化学习（RL）的混合方法，用于自动化启发式发现，优化低存储ESRK方法。与传统依赖手动设计启发式或穷举数值搜索的方法不同，我们的方法利用GA驱动的突变进行搜索空间探索，并通过RL启发的状态转换机制动态优化启发式选择。这实现了系统参数减少，同时保持了四阶精度并显著提高了计算效率。所提出的GA-RL启发式优化框架在基准问题（包括1D和2D Brusselator系统及稳态Navier-Stokes方程）上进行了严格测试。性能最佳的启发式方法将IPOPT运行时间减少了25%，同时保持了数值稳定性和精度。这些发现表明，自适应启发式发现能够提高高保真模拟中的资源效率，并拓宽低存储龙格-库塔方法在计算流体动力学、物理模拟等实际应用中的适用性。本研究为数值方法的启发式优化建立了新范式，为基于深度强化学习和自动机器学习的启发式搜索提供了进一步探索的途径。

</details>


### [233] [Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems](https://arxiv.org/abs/2506.21502)
**中文标题：基于过程挖掘的建模与仿真增强信息物理系统的故障诊断**

*Francesco Vitale,Nicola Dall'Ora,Sebastiano Gaiardelli,Enrico Fraccaroli,Nicola Mazzocca,Franco Fummi*

主要分类: cs.LG

摘要简述: 本文提出了一种结合多元时间序列分析、过程挖掘和随机模拟的无监督故障诊断方法，用于提升信息物理系统的故障诊断能力，并通过实验验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 信息物理系统（CPS）的故障诊断对系统可靠性和运行效率至关重要。然而，传统手动建模方法依赖专家知识，模型复杂且易出错。本文旨在解决这一问题，提出一种自动化、可解释的故障诊断方法。

研究方法: 方法分为三步：1）通过多元时间序列分析检测传感器数据中的集体异常；2）将异常转化为结构化事件日志，利用过程挖掘生成可解释的流程模型；3）在提取的Petri网中加入时间分布，支持随机模拟以增强根因分析和行为理解。

研究结果: 实验使用智能制造领域的Robotic Arm Dataset（RoAD）验证了方法的有效性。结果显示，该方法能够准确建模、模拟和分类CPS中的故障行为，并支持构建故障字典和数字孪生。

研究结论: 本文提出的方法通过结合多元时间序列分析、过程挖掘和随机模拟，显著提升了CPS故障诊断的自动化水平和可解释性，为预测性维护和工业数字孪生提供了支持。

中文摘要: 信息物理系统（CPS）的故障诊断对于确保系统可靠性和运行效率至关重要，能够准确检测异常并识别其根本原因。然而，手动建模故障行为通常需要丰富的领域知识，且生成的模型复杂、易出错且难以解释。为解决这一问题，我们提出了一种新颖的无监督故障诊断方法，该方法结合了多元时间序列中的集体异常检测、过程挖掘和随机模拟。首先，通过多元时间序列分析从低级传感器数据中检测集体异常；随后，将这些异常转化为结构化事件日志，通过过程挖掘发现可解释的流程模型。通过在提取的Petri网中加入时间分布，该方法支持对故障行为的随机模拟，从而增强根因分析和行为理解。该方法使用智能制造领域广泛认可的基准数据集Robotic Arm Dataset（RoAD）进行了验证。实验结果表明，该方法能够有效建模、模拟和分类CPS中的故障行为，从而支持构建全面的故障字典，为预测性维护和工业环境的数字孪生开发提供了支持。

</details>


### [234] [mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale](https://arxiv.org/abs/2506.21550)
**中文标题：mTSBench：大规模多变量时间序列异常检测与模型选择基准测试**

*Xiaona Zhou,Constantin Brif,Ismini Lourentzou*

主要分类: cs.LG

摘要简述: mTSBench是迄今为止最大的多变量时间序列异常检测（MTS-AD）和无监督模型选择基准，涵盖19个数据集中的344条标记时间序列，评估了24种异常检测方法，并揭示了模型选择的重要性及其当前局限性。


<details>
  <summary>详细信息</summary>
研究动机: 多变量时间序列异常检测在医疗、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖关系、时间动态性和稀疏的异常标签，该任务仍然具有挑战性。mTSBench旨在提供一个统一的评估框架，推动自适应异常检测和稳健模型选择的未来发展。

研究方法: mTSBench构建了包含19个数据集、344条标记时间序列的基准，覆盖12个应用领域。评估了24种异常检测方法，包括基于大型语言模型（LLM）的多变量时间序列检测器，并系统性地在标准化条件下对无监督模型选择技术进行了基准测试。

研究结果: 研究结果证实，没有单一检测器在所有数据集上表现优异，凸显了模型选择的重要性。然而，即使是最先进的模型选择方法仍远未达到最优，揭示了关键的技术空白。

研究结论: mTSBench提供了一个统一的评估套件，支持严格、可重复的比较，并为未来自适应异常检测和稳健模型选择的研究提供了催化剂。

中文摘要: 多变量时间序列异常检测（MTS-AD）在医疗、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖关系、时间动态性和稀疏的异常标签，该任务仍然具有挑战性。我们推出了mTSBench，这是迄今为止最大的MTS-AD和无监督模型选择基准，涵盖19个数据集中的344条标记时间序列，覆盖12个多样化的应用领域。mTSBench评估了24种异常检测方法，包括基于大型语言模型（LLM）的多变量时间序列检测器，并在标准化条件下系统性地对无监督模型选择技术进行了基准测试。与先前的研究一致，我们的结果证实没有单一检测器在所有数据集上表现优异，强调了模型选择的重要性。然而，即使是最先进的模型选择方法仍远未达到最优，揭示了关键的技术空白。mTSBench提供了一个统一的评估套件，支持严格、可重复的比较，并为未来自适应异常检测和稳健模型选择的研究提供了催化剂。

</details>


### [235] [Universal and Efficient Detection of Adversarial Data through Nonuniform Impact on Network Layers](https://arxiv.org/abs/2506.20816)
**中文标题：通过非均匀影响网络层实现对抗数据的通用高效检测**

*Furkan Mumcu,Yasin Yilmaz*

主要分类: cs.LG

摘要简述: 本文提出了一种通用且高效的方法，通过分析对抗样本对不同深度神经网络（DNN）层的影响程度来检测对抗数据。该方法训练一个轻量级回归模型，从早期层特征预测深层特征，并利用预测误差检测对抗样本。


<details>
  <summary>详细信息</summary>
研究动机: 深度神经网络（DNN）对对抗输入设计非常脆弱，现有防御方法要么通过消除扰动效果提高鲁棒性，要么使用辅助模型检测对抗数据。然而，这些方法要么对最新攻击技术无效，要么计算效率低下，无法实时处理。本文旨在提出一种更实用的检测方法。

研究方法: 本文提出了一种新颖的检测方法，通过分析对抗攻击对不同DNN层的非均匀影响。具体而言，训练一个轻量级回归模型，从早期层特征预测深层特征，并利用预测误差检测对抗样本。

研究结果: 通过理论分析和大量实验，本文方法在检测对抗样本方面表现出高效性和通用性，适用于图像、视频和音频等多种领域，且计算效率高，适合实时处理。

研究结论: 本文提出的方法不仅高效且通用，能够有效检测对抗样本，同时兼容任何DNN架构，为对抗数据检测提供了实用解决方案。

中文摘要: 深度神经网络（DNN）对对抗输入设计非常脆弱，尤其是在噪声预算有限的情况下。尽管已有许多通过细微修改原始输入实现成功攻击的方法，但针对这些攻击的防御技术研究相对不足。现有防御方法要么专注于通过消除扰动效果提高DNN鲁棒性，要么使用辅助模型检测对抗数据。本文研究的攻击检测方法相比鲁棒性方法更具实用性。我们发现现有检测方法要么对最新攻击技术无效，要么计算效率低下，无法实时处理。为此，我们提出了一种新颖的通用高效方法，通过分析攻击对不同DNN层的非均匀影响来检测对抗样本。我们的方法训练一个轻量级回归模型，从早期层特征预测深层特征，并利用预测误差检测对抗样本。通过理论分析和大量实验，我们证明该检测方法高效、计算效率高、兼容任何DNN架构，并适用于图像、视频和音频等多种领域。

</details>


### [236] [RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment](https://arxiv.org/abs/2506.21037)
**中文标题：RL-Selector：基于强化学习的冗余评估数据选择方法**

*Suorong Yang,Peijia Li,Furao Shen,Jian Zhao*

主要分类: cs.LG

摘要简述: 本文提出RL-Selector，一种基于强化学习的数据选择方法，通过量化样本冗余性动态优化训练数据选择，显著提升训练效率与模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现代深度学习依赖大规模数据集，但训练成本高且数据冗余严重。现有数据选择方法多为静态或依赖预训练模型，忽略了样本选择与训练动态的交互作用。

研究方法: 提出epsilon-sample cover概念量化样本冗余性，将数据选择建模为强化学习问题，通过轻量级RL代理动态优化选择策略。

研究结果: 在多个基准数据集和架构上的实验表明，RL-Selector优于现有方法，所选数据集训练出的模型泛化性能更好且训练效率更高。

研究结论: RL-Selector通过动态数据选择有效减少冗余，提升训练效率与模型性能，为数据高效训练提供新思路。

中文摘要: 现代深度学习架构通常依赖大规模数据集，但训练这些数据集会产生高昂的计算和存储开销。现实数据集往往包含大量冗余，亟需更高效的数据训练范式。数据选择通过识别最具代表性的样本减少冗余，从而在不影响性能的情况下降低训练成本。现有方法通常依赖静态评分指标或预训练模型，忽略了所选样本及其在训练过程中动态变化的综合效应。我们提出epsilon-sample cover概念，基于样本间关系量化冗余性，捕捉数据集的内在结构。基于此，我们将数据选择重新表述为强化学习（RL）过程，并提出RL-Selector，其中轻量级RL代理通过利用从动态数据集分布中衍生的epsilon-sample cover作为奖励信号来优化选择策略。在多个基准数据集和多样化架构上的广泛实验表明，我们的方法始终优于现有最先进的基线。使用我们选择的数据集训练的模型表现出更强的泛化性能和更高的训练效率。

</details>


### [237] [Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion](https://arxiv.org/abs/2506.21144)
**中文标题：基于双提示优化与跨模态融合的个性化联邦学习**

*Yuguang Zhang,Kuangpu Guo,Zhihe Lu,Yunbo Wang,Jian Liang*

主要分类: cs.LG

摘要简述: 本文提出了一种个性化联邦学习框架pFedDC，通过双提示学习和跨模态融合解决数据异构性问题，实验表明其优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 联邦学习在数据、计算和通信异构性方面面临挑战，现有方法仅依赖文本提示且忽略联合标签-域分布变化。本文旨在通过双提示学习和跨模态融合解决这些问题。

研究方法: pFedDC框架中，每个客户端维护全局和本地视觉与语言提示：全局提示捕捉联邦共享知识，本地提示编码客户端特定语义和域特征。跨融合模块自适应整合不同级别提示，生成与客户端数据分布对齐的个性化表示。

研究结果: 在九种异构数据集上的实验表明，pFedDC在性能上始终优于现有最先进方法。

研究结论: pFedDC通过双提示学习和跨模态融合有效解决了联邦学习中的异构性问题，为个性化联邦学习提供了新思路。

中文摘要: 联邦学习（FL）支持在分散客户端上协作训练模型而无需共享本地数据，但面临数据、计算和通信的异构性挑战。预训练的视觉语言模型（VLMs）凭借其强大的泛化能力和轻量级提示调优，提供了一种有前景的解决方案。然而，现有的联邦提示学习方法仅依赖文本提示，且忽略了联合标签-域分布变化。本文提出了一种基于双提示学习和跨模态融合的个性化FL框架，称为pFedDC。具体而言，每个客户端在视觉和语言模态上维护全局和本地提示：全局提示捕捉联邦共享的通用知识，本地提示编码客户端特定的语义和域特征。同时，设计了一个跨融合模块，自适应地整合不同级别的提示，使模型能够生成与每个客户端独特数据分布对齐的个性化表示。在九种异构数据集上的广泛实验表明，pFedDC始终优于现有最先进方法。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [238] [Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends](https://arxiv.org/abs/2506.20966)
**中文标题：VLA模型后训练与人类运动学习的类比：进展、挑战与趋势**

*Tian-Yu Xiang,Ao-Qun Jin,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Sheng-Bin Duan,Fu-Chao Xie,Wen-Kai Wang,Si-Cheng Wang,Ling-Yun Li,Tian Tu,Zeng-Guang Hou*

主要分类: cs.RO

摘要简述: 本文从人类运动学习的角度，综述了视觉-语言-动作（VLA）模型的后训练策略，提出了一种基于环境、体现和任务的结构化分类法，并总结了关键挑战与未来趋势。


<details>
  <summary>详细信息</summary>
研究动机: VLA模型在机器人操作任务中展现出泛化能力，但在高精度应用中表现不足。后训练是提升模型与下游任务对齐的关键，本文旨在通过人类运动学习的视角，为VLA模型的后训练研究提供系统框架。

研究方法: 通过类比人类运动学习机制，提出了一种结构化分类法，涵盖四个维度：环境感知增强、体现意识提升、任务理解深化以及多组件整合。

研究结果: 总结了当前VLA模型后训练方法的现状，并提出了未来研究的挑战与趋势，为模型开发提供了实践指导。

研究结论: 本文为VLA模型的后训练研究提供了系统性综述和框架，从人类运动学习的视角为未来研究指明了方向。

中文摘要: 视觉-语言-动作（VLA）模型通过集成动作生成模块扩展了视觉-语言模型（VLM），在机器人操作任务中展现出泛化能力。然而，高精度应用揭示了其性能差距，需通过后训练进一步适配。多领域证据表明，后训练对基础模型与下游任务的对齐至关重要，推动了VLA模型后训练的广泛研究。VLA模型后训练旨在提升模型与环境交互的能力，类似于人类运动技能的习得过程。本文从人类运动学习的视角，围绕环境、体现和任务三个维度，综述了VLA模型的后训练策略。提出了一种结构化分类法，与人类学习机制对应：（1）环境感知增强，（2）体现意识提升，（3）任务理解深化，（4）多组件整合。最后，总结了VLA模型后训练的关键挑战与趋势，建立了指导未来研究的概念框架。本文不仅从人类运动学习的角度全面概述了当前VLA模型后训练方法，还为模型开发提供了实践见解。（项目网站：https://github.com/AoqunJin/Awesome-VLA-Post-Training）

</details>


### [239] [V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling](https://arxiv.org/abs/2506.21041)
**中文标题：V2X-REALM：基于视觉语言模型的自适应长尾建模鲁棒端到端协作自动驾驶**

*Junwei You,Pei Li,Zhuoyu Jiang,Zilin Huang,Rui Gan,Haotian Shi,Bin Ran*

主要分类: cs.RO

摘要简述: 本文提出V2X-REALM，一种基于视觉语言模型的框架，通过自适应多模态学习解决长尾场景下的协作自动驾驶问题，显著提升了鲁棒性、语义推理和安全性能。


<details>
  <summary>详细信息</summary>
研究动机: 在复杂的城市环境中，自动驾驶系统在罕见、多样且视觉退化的长尾场景下的规划和决策能力仍面临挑战，尤其是在车辆与基础设施协作感知和推理的场景中。

研究方法: V2X-REALM包含三项核心创新：(1) 基于提示的长尾场景生成与评估流程；(2) 门控多场景自适应注意力模块；(3) 多任务场景感知对比学习目标。

研究结果: 实验表明，V2X-REALM在复杂驾驶条件下显著优于现有基线，提升了鲁棒性、语义推理、安全性和规划准确性。

研究结论: V2X-REALM通过自适应长尾建模和多模态学习，推动了端到端协作自动驾驶的可扩展性。

中文摘要: 在复杂城市环境中，确保自动驾驶系统在罕见、多样且视觉退化的长尾场景下的鲁棒规划和决策仍是一项基本挑战。这一问题在协作场景中更为关键，车辆与基础设施需共同感知和推理复杂环境。为解决这一挑战，我们提出V2X-REALM，一种基于视觉语言模型（VLM）的框架，通过自适应多模态学习实现长尾场景下的鲁棒协作自动驾驶。V2X-REALM包含三项核心创新：(i) 基于提示的长尾场景生成与评估流程，利用基础模型合成车辆和基础设施视角下的真实长尾条件（如雪、雾），高效丰富训练多样性；(ii) 门控多场景自适应注意力模块，利用场景先验调整视觉流以校准模糊或损坏的特征；(iii) 多任务场景感知对比学习目标，提升多模态对齐并促进跨场景特征分离。大量实验表明，V2X-REALM在复杂驾驶条件下显著优于现有基线，提升了鲁棒性、语义推理、安全性和规划准确性，推动了端到端协作自动驾驶的可扩展性。

</details>


### [240] [WorldVLA: Towards Autoregressive Action World Model](https://arxiv.org/abs/2506.21539)
**中文标题：WorldVLA：迈向自动回归动作世界模型**

*Jun Cen,Chaohui Yu,Hangjie Yuan,Yuming Jiang,Siteng Huang,Jiayan Guo,Xin Li,Yibing Song,Hao Luo,Fan Wang,Deli Zhao,Hao Chen*

主要分类: cs.RO

摘要简述: 本文提出WorldVLA，一种结合视觉-语言-动作（VLA）模型与世界模型的自动回归动作世界模型，通过统一动作与图像的理解与生成，提升动作生成能力。实验表明其优于独立模型，并提出注意力掩码策略解决动作序列生成中的误差传播问题。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在统一动作与图像的理解与生成，通过结合VLA模型与世界模型，提升动作生成的物理环境理解能力，同时探索动作序列生成中的误差传播问题及其解决方案。

研究方法: WorldVLA整合VLA模型与世界模型，通过动作与图像理解预测未来图像，同时基于图像观察生成后续动作。为解决动作序列生成中的误差传播问题，提出选择性掩码先前动作的注意力掩码策略。

研究结果: WorldVLA在动作生成任务中表现优于独立模型，但动作序列生成时性能下降。注意力掩码策略显著提升了动作块生成任务的性能。

研究结论: WorldVLA通过结合VLA与世界模型，实现了动作与图像理解的相互增强，注意力掩码策略有效解决了动作序列生成中的误差传播问题。

中文摘要: 我们提出了WorldVLA，一种自动回归动作世界模型，统一了动作与图像的理解与生成。WorldVLA将视觉-语言-动作（VLA）模型与世界模型整合到一个框架中。世界模型通过动作与图像理解预测未来图像，旨在学习环境的物理规律以改进动作生成。同时，动作模型基于图像观察生成后续动作，辅助视觉理解并反过来促进世界模型的视觉生成。实验表明，WorldVLA优于独立的动作与世界模型，凸显了两者的相互增强作用。此外，我们发现动作模型在自动回归生成动作序列时性能下降，这归因于模型在动作预测上的泛化能力有限，导致早期动作的误差传播到后续动作。为解决这一问题，我们提出了一种注意力掩码策略，在生成当前动作时选择性掩码先前动作，显著提升了动作块生成任务的性能。

</details>


### [241] [Model-Based Real-Time Pose and Sag Estimation of Overhead Power Lines Using LiDAR for Drone Inspection](https://arxiv.org/abs/2506.20812)
**中文标题：基于模型的LiDAR无人机巡检电力线实时姿态与下垂估计**

*Alexandre Girard,Steven A. Parkison,Philippe Hamelin*

主要分类: cs.RO

摘要简述: 本文提出了一种基于模型的实时姿态和下垂估计方法，利用LiDAR进行无人机电力线巡检，通过单一几何模型最小化误差，解决了导体点稀疏、检测不一致和干扰物区分难题。


<details>
  <summary>详细信息</summary>
研究动机: 无人机巡检带电电力线时，LiDAR传感器面临导体点稀疏、检测不一致及干扰物区分困难等问题，亟需一种高效准确的定位方法。

研究方法: 提出一种基于单一几何模型的估计方法，最小化LiDAR测量值与模型间的误差，而非单独追踪每根导体，实验验证了其高效性和鲁棒性。

研究结果: 实验表明，该方法在部分观测、噪声和异常点存在下仍能实现准确追踪，每帧求解时间低于50毫秒，且能容忍两倍于有效测量的异常点。

研究结论: 该方法为无人机电力线巡检提供了一种高效、准确的实时姿态和下垂估计解决方案，具有较强鲁棒性和实用性。

中文摘要: 无人机可在电力线带电状态下进行巡检，极大简化了检查流程。然而，利用机载LiDAR传感器定位无人机相对于所有导体的位置存在以下挑战：(1)导体表面极小，限制了LiDAR扫描中的导体点数；(2)并非所有导体均能被一致检测；(3)区分LiDAR点对应的导体与其他物体（如树木和塔架）较为困难。本文提出了一种估计方法，通过最小化LiDAR测量值与代表整个导体阵列的单一几何模型间的误差，而非单独追踪每根导体。基于电力线无人机巡检数据的实验结果表明，该方法在部分观测、噪声和异常点存在下仍能实现准确追踪，每帧求解时间低于50毫秒。敏感性分析显示，该估计方法可容忍的异常点数量为有效导体测量值的两倍。

</details>


### [242] [ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation](https://arxiv.org/abs/2506.20969)
**中文标题：ThermalDiffusion：用于自主导航的视觉到热成像图像转换**

*Shruti Bansal,Wenshan Wang,Yifei Liu,Parv Maheshwari*

主要分类: cs.RO

摘要简述: 本文提出了一种利用条件扩散模型将RGB图像转换为热成像图像的方法，以解决自主系统中热成像数据不足的问题，从而提升夜间或恶劣环境下的导航能力。


<details>
  <summary>详细信息</summary>
研究动机: 自主系统依赖传感器感知环境，但传统传感器在夜间或恶劣环境（如雾、尘）中表现受限。热成像相机通过物体热特征提供有效信息，但相关数据稀缺，阻碍了其在机器人领域的应用。本文旨在通过合成热成像数据弥补这一不足。

研究方法: 采用条件扩散模型，结合自注意力机制，将现有RGB图像转换为热成像图像，学习真实物体的热特性。

研究结果: 提出的方法能够有效生成合成热成像数据，填补了现有数据集的空白，为热成像相机的广泛应用提供了支持。

研究结论: 通过合成热成像数据，本文解决了自主系统中热成像数据不足的问题，推动了热成像相机在机器人领域的快速应用。

中文摘要: 自主系统依赖传感器来估计周围环境。然而，相机、激光雷达和雷达各有其局限性。在夜间或恶劣环境（如雾、尘）中，热成像相机通过物体的热特征提供有价值的信息，便于识别温度通常高于周围环境的人和车辆。本文聚焦于热成像相机在机器人及自动化领域的应用，其最大障碍是数据不足。现有多种多模态数据集支持驾驶机器人研究中的场景分割、目标检测和深度估计等任务，这些是自主系统的基石，但缺乏热成像数据。本文提出一种解决方案，通过合成热成像数据扩充这些数据集，以促进热成像相机的广泛快速应用。我们探索了使用条件扩散模型，通过自注意力学习真实物体的热特性，将现有RGB图像转换为热成像图像。

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [243] [Automatic Reviewers Assignment to a Research Paper Based on Allied References and Publications Weight](https://arxiv.org/abs/2506.21331)
**中文标题：基于相关参考文献和发表权重的论文自动审稿人分配**

*Tamim Al Mahmud,B M Mainul Hossain,Dilshad Ara*

主要分类: cs.DL

摘要简述: 本文提出了一种基于参考文献和作者权重的自动分配审稿人方法，通过分析论文引用和作者学术指标，高效选择最适合的审稿人。


<details>
  <summary>详细信息</summary>
研究动机: 随着研究领域的扩展和论文数量的激增，传统的人工选择审稿人方式效率低下且难以确保专业性。本文旨在通过自动化方法解决这一问题，确保每篇论文都能由相关领域的专家审阅。

研究方法: 方法包括：收集论文参考文献，统计相关作者；提取研究主题关键词；搜索领域内顶尖研究者并计算其h指数、i10指数和引用次数；根据评分排名并筛选出潜在审稿人；通过网页抓取获取其联系方式，并排除合作者。

研究结果: 实验表明，该方法能够高效、准确地筛选出适合审阅论文的专家，提升了审稿人分配的效率和专业性。

研究结论: 本文提出的自动化审稿人分配方法有效解决了传统人工分配的不足，为学术出版提供了更高效的解决方案。

中文摘要: 每天有大量研究文档提交至会议、期刊、报告等出版物，这些出版物通常依赖外部专家进行审稿（即同行评审）。然而，选择最合适的审稿人并非易事，尤其是随着新兴研究领域的涌现和论文数量的剧增。为应对这一挑战，本研究提出并实现了一种自动选择最佳审稿人的新策略。每篇论文末尾通常包含来自同一领域的参考文献。我们首先收集这些参考文献，并统计其中至少发表过一篇论文的作者。随后，自动从网络中提取研究主题关键词，并搜索该领域的顶尖研究者，计算其h指数、i10指数和引用次数。接着，根据评分对前n位作者进行排名，并自动抓取其主页以获取邮箱地址。同时，排除其合作者和同事。最终筛选出的前n位作者（多为教授）即为最适合审阅该论文的审稿人。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [244] [CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions](https://arxiv.org/abs/2506.21085)
**中文标题：CovDocker：基于任务、数据集和解决方案的共价药物设计基准**

*Yangzhe Peng,Kaiyuan Gao,Liang He,Yuheng Cong,Haiguang Liu,Kun He,Lijun Wu*

主要分类: q-bio.BM

摘要简述: CovDocker是一个用于共价药物设计的综合性基准，通过分解共价对接过程为三个任务，并利用先进模型验证其有效性，为共价抑制剂研究提供了严谨框架。


<details>
  <summary>详细信息</summary>
研究动机: 现有分子对接方法大多未考虑共价键的形成及其结构变化，限制了共价药物设计的发展。CovDocker旨在填补这一空白，为共价对接研究提供更全面的基准。

研究方法: 将共价对接过程分解为三个任务：反应位点预测、共价反应预测和共价对接。采用Uni-Mol和Chemformer等先进模型建立基线性能，验证基准的有效性。

研究结果: 基准成功预测了相互作用位点并模拟了共价结合中的分子转化，证明了其在共价药物设计中的实用性和严谨性。

研究结论: CovDocker为共价药物设计提供了数据驱动的研究框架，有望加速选择性共价抑制剂的发现，并解决治疗开发中的关键挑战。

中文摘要: 分子对接在预测配体与靶蛋白结合模式中起关键作用，而共价相互作用因其强且持久的结合特性尤为重要。然而，现有对接方法和深度学习模型很少考虑共价键的形成及相关结构变化。为填补这一空白，我们提出了一个全面的共价对接基准——CovDocker，旨在更好地捕捉共价结合的复杂性。我们将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过采用Uni-Mol和Chemformer等先进模型，我们建立了基线性能，并证明了该基准在准确预测相互作用位点和模拟共价结合中分子转化的有效性。这些结果证实了该基准作为推动共价药物设计研究的严谨框架的作用，凸显了数据驱动方法在加速选择性共价抑制剂发现中的潜力，并解决了治疗开发中的关键挑战。

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [245] [On Uniform Weighted Deep Polynomial approximation](https://arxiv.org/abs/2506.21306)
**中文标题：关于均匀加权深度多项式逼近的研究**

*Kingsley Yeon,Steven B. Damelin*

主要分类: math.NA

摘要简述: 本文提出了一种加权深度多项式逼近方法，用于高效逼近具有不对称行为的函数，优于传统多项式逼近方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统多项式逼近方法在处理非光滑或奇异函数时收敛速度较慢，而本文旨在通过加权深度多项式逼近方法解决这一问题，特别是针对具有不对称行为的函数。

研究方法: 通过将可学习的深度多项式与单侧权重相乘，捕捉局部非光滑性和全局增长特性，并提出一种基于图的稳定参数化策略进行优化。

研究结果: 数值实验表明，该方法在相同参数数量下优于泰勒、切比雪夫和标准深度多项式逼近方法。

研究结论: 加权深度多项式逼近方法在处理具有不对称行为的函数时表现出色，为高效逼近提供了一种新思路。

中文摘要: 在有理逼近理论中，经典结果表明某些非光滑或奇异函数（如$|x|$和$x^{1/p}$）可以通过有理函数以根指数收敛速度高效逼近。相比之下，多项式逼近仅能通过Jackson定理实现代数收敛。最近的研究表明，复合多项式架构即使在没有光滑性的情况下也能恢复指数逼近速度。本文提出并分析了一类加权深度多项式逼近方法，专门用于处理具有不对称行为的函数——一侧无界增长，另一侧衰减。通过将可学习的深度多项式与单侧权重相乘，我们同时捕捉了局部非光滑性和全局增长特性。数值实验表明，该方法在相同参数数量下优于泰勒、切比雪夫和标准深度多项式逼近方法。为了在实践中优化这些逼近方法，我们提出了一种基于图的稳定参数化策略。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [246] [Evaluating PDE discovery methods for multiscale modeling of biological signals](https://arxiv.org/abs/2506.20694)
**中文标题：评估PDE发现方法在生物信号多尺度建模中的应用**

*Andréa Ducos,Audrey Denizot,Thomas Guyet,Hugues Berry*

主要分类: q-bio.QM

摘要简述: 本文评估了五种先进的偏微分方程（PDE）发现方法，用于从微观数据中捕捉生物信号的多尺度动态特性，重点关注钙扩散模拟，结果显示部分方法能准确恢复扩散项。


<details>
  <summary>详细信息</summary>
研究动机: 生物系统具有非线性、包含未观测变量且动力学原理部分未知的特点，其行为表征极具挑战性。多尺度活动需要跨尺度机制链接，因此研究利用PDE发现方法填补尺度间的空白。

研究方法: 结合基于粒子的模拟和PDE发现框架，在受控环境中评估五种PDE发现方法，应用于星形胶质细胞中钙扩散的粒子模拟数据。

研究结果: 实验表明，部分方法能准确恢复扩散项，并预测钙浓度的时间变化，验证了PDE发现从微观数据捕捉宏观动态的潜力。

研究结论: PDE发现方法在生物系统多尺度建模中具有潜力，尤其在从微观数据推断宏观动态方面表现突出。

中文摘要: 生物系统具有非线性、包含未观测变量且动力学原理部分未知的特点，其行为表征极具挑战性。其活动发生在多个相互依赖的空间和时间尺度上，需要跨尺度链接机制。为填补尺度间的空白，我们利用偏微分方程（PDE）发现方法，从微观数据中推断中尺度动态特性。本文提出了一种结合基于粒子的模拟和PDE发现的框架，并在受控环境中进行初步实验以评估方程发现。我们评估了五种先进的PDE发现方法在星形胶质细胞钙扩散粒子模拟中的应用。方法的性能通过发现的方程形式和预测的钙浓度时间变化来评估。结果显示，部分方法能准确恢复扩散项，突显了PDE发现从微观数据捕捉生物系统宏观动态的潜力。

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [247] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
**中文标题：混合深度学习与信号处理在低资源环境下的阿拉伯方言识别**

*Ghazal Al-Shwayyat,Omer Nezih Gerek*

主要分类: eess.AS

摘要简述: 本研究探讨了在低资源环境下，结合信号处理技术与深度学习模型进行阿拉伯方言识别的有效性。实验表明，基于MFCC和CNN的混合模型表现最佳，准确率达91.2%，显著优于基于DWT和RNN的模型。


<details>
  <summary>详细信息</summary>
研究动机: 阿拉伯方言识别因语言多样性和标注数据稀缺而面临挑战，尤其在低资源环境下。本研究旨在通过结合传统信号处理与深度学习，提升方言识别的性能。

研究方法: 开发了两种混合模型：1) MFCC特征结合CNN；2) DWT特征结合RNN。使用Common Voice阿拉伯语数据集的方言标注子集进行训练和评估。

研究结果: MFCC + CNN模型表现最佳，准确率达91.2%，而DWT + RNN模型准确率为66.5%。前者在精确率、召回率和F1分数上均显著优于后者。

研究结论: 研究证明了在低资源环境下，结合频谱特征与卷积模型对阿拉伯方言识别的有效性，并为未来研究提供了改进方向，如扩大标注数据集和探索自监督学习技术。

中文摘要: 阿拉伯方言识别在语音技术中面临重大挑战，主要由于阿拉伯语的多样性及标注数据稀缺，尤其是对少数方言的支持不足。本研究探讨了在低资源场景下，结合传统信号处理技术与深度学习架构的混合建模策略。开发并评估了两种混合模型：1) 梅尔频率倒谱系数（MFCC）结合卷积神经网络（CNN）；2) 离散小波变换（DWT）特征结合循环神经网络（RNN）。模型在Common Voice阿拉伯数据集的方言标注子集上训练，实验结果表明，MFCC + CNN架构表现最优，准确率达91.2%，且精确率、召回率和F1分数均显著优于Wavelet + RNN配置（准确率66.5%）。这些发现凸显了在有限标注数据下，结合频谱特征与卷积模型的有效性。研究还指出了数据集规模、标注区域重叠及模型优化等局限性，为未来研究提供了方向，包括采用更大标注语料库、整合自监督学习技术及探索Transformer等先进架构。总体而言，本研究为资源受限环境下的阿拉伯方言识别奠定了坚实基础。

</details>


### [248] [ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing](https://arxiv.org/abs/2506.21448)
**中文标题：ThinkSound：多模态大语言模型中的链式思维推理用于音频生成与编辑**

*Huadai Liu,Jialei Wang,Kaicheng Luo,Wen Wang,Qian Chen,Zhou Zhao,Wei Xue*

主要分类: eess.AS

摘要简述: ThinkSound是一种新型框架，利用链式思维（CoT）推理实现视频到音频的逐步生成和编辑，通过多模态大语言模型生成上下文对齐的推理，提升音频生成质量。


<details>
  <summary>详细信息</summary>
研究动机: 尽管端到端的视频到音频生成技术已有显著进步，但生成高保真且真实反映视觉内容细微差别的音频仍具挑战性。论文旨在通过链式思维推理模拟专业人士的创作过程，提升音频生成的精准度和交互性。

研究方法: ThinkSound将音频生成过程分解为三个阶段：基础音效生成、交互式对象中心优化和自然语言指导的针对性编辑。多模态大语言模型生成上下文对齐的链式思维推理，指导统一的音频基础模型。

研究结果: 实验表明，ThinkSound在视频到音频生成任务中表现优异，在音频指标和链式思维指标上均达到最先进水平，并在Movie Gen Audio基准测试中表现出色。

研究结论: ThinkSound通过链式思维推理和多模态大语言模型的结合，显著提升了视频到音频生成的精准度和交互性，为创意产业提供了新的工具。

中文摘要: 尽管端到端的视频到音频生成技术已取得显著进展，但生成高保真且真实反映视觉内容细微差别的音频仍具挑战性。与创意产业的专业人士类似，此类生成需要对视觉动态、声学环境和时间关系等进行复杂推理。我们提出了ThinkSound，一种新型框架，利用链式思维（CoT）推理实现视频的逐步、交互式音频生成和编辑。该方法将过程分解为三个互补阶段：基础音效生成（创建语义连贯的音景）、通过精确用户交互实现的交互式对象中心优化，以及自然语言指导的针对性编辑。在每个阶段，多模态大语言模型生成上下文对齐的链式思维推理，指导统一的音频基础模型。此外，我们引入了AudioCoT，一个包含结构化推理注释的综合数据集，建立了视觉内容、文本描述和声音合成之间的联系。实验表明，ThinkSound在视频到音频生成任务中表现优异，在音频指标和链式思维指标上均达到最先进水平，并在Movie Gen Audio基准测试中表现出色。演示页面请访问https://ThinkSound-Demo.github.io。

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [249] [Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution](https://arxiv.org/abs/2506.21278)
**中文标题：基于高效球形柯西分布的超球面变分自编码器**

*Lukas Sablica,Kurt Hornik*

主要分类: stat.ML

摘要简述: 本文提出了一种新型变分自编码器（VAE），采用球形柯西（spCauchy）潜在分布，相比传统高斯或von Mises-Fisher（vMF）分布，能更自然地表示方向性数据，避免数值不稳定问题，并提供高效训练。


<details>
  <summary>详细信息</summary>
研究动机: 传统的VAE通常使用高斯或vMF分布作为潜在变量表示，但高斯分布不适合方向性数据，而vMF存在数值不稳定和计算复杂的问题。本文旨在提出一种更优的潜在分布spCauchy，以解决这些问题。

研究方法: 提出了一种基于球形柯西分布的VAE架构，利用其重尾特性避免过正则化，并通过Möbius变换实现高效可微分的重参数化技巧。KL散度通过快速收敛的幂级数计算，避免了数值不稳定问题。

研究结果: 实验表明，spCauchy分布能更有效地表示方向性数据，避免vMF的数值不稳定问题，同时提供高效的训练和表达能力。

研究结论: 球形柯西分布为VAE提供了一种理论优越且实际高效的潜在表示方法，特别适合高维生成建模。

中文摘要: 我们提出了一种新型变分自编码器（VAE）架构，采用球形柯西（spCauchy）潜在分布。与传统的潜在高斯空间或广泛使用的von Mises-Fisher（vMF）分布不同，spCauchy提供了更自然的超球面潜在变量表示，能更好地捕捉方向性数据，同时保持灵活性。其重尾特性避免了过正则化，确保了潜在空间的高效利用，并提供了更具表达力的表示。此外，spCauchy规避了vMF固有的数值不稳定问题（这些问题源于涉及贝塞尔函数的归一化常数计算），而是通过Möbius变换实现了完全可微分且高效的重参数化技巧，从而实现稳定且可扩展的训练。KL散度可通过快速收敛的幂级数计算，消除了与超几何函数比值评估相关的下溢或上溢问题。这些特性使spCauchy成为VAE的一种引人注目的替代方案，在高维生成建模中既具有理论优势，又具备实际效率。

</details>
