<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 50]
- [cs.CV](#cs.CV) [Total: 93]
- [cs.AI](#cs.AI) [Total: 26]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.RO](#cs.RO) [Total: 3]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.DC](#cs.DC) [Total: 3]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cs.CR](#cs.CR) [Total: 7]
- [hep-ph](#hep-ph) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.LG](#cs.LG) [Total: 33]
- [eess.IV](#eess.IV) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs](https://arxiv.org/abs/2507.07186)
**中文标题：预训练播种，微调摇摆：LLMs认知偏差起源的案例研究**

*Itay Itzhak,Yonatan Belinkov,Gabriel Stanovsky*

主要分类: cs.CL

摘要简述: 研究发现，大型语言模型（LLMs）的认知偏差主要源于预训练阶段，而非微调或训练随机性。通过多轮微调和跨模型数据交换实验，揭示了预训练对偏差模式的决定性影响。


<details>
  <summary>详细信息</summary>
研究动机: 尽管已有研究发现LLMs存在类似人类的认知偏差，且偏差因模型和指令微调而异，但其具体来源（预训练、微调或随机性）尚不明确。本文旨在通过实验方法厘清这些因素对偏差的影响。

研究方法: 采用两步因果实验方法：1）通过不同随机种子多次微调模型，研究训练随机性对30多种认知偏差的影响；2）引入“跨微调”方法，交换指令数据集以隔离偏差来源，直接测试偏差是否依赖数据集。

研究结果: 实验表明，训练随机性虽引入一定变异性，但偏差模式主要由预训练决定：相同预训练骨干的模型比仅共享微调数据的模型表现出更相似的偏差模式。

研究结论: 理解微调模型的偏差需考虑其预训练起源，而非仅关注微调效应。这一视角可为未来评估和缓解LLMs偏差的策略提供指导。

中文摘要: 大型语言模型（LLMs）表现出认知偏差——类似于人类的不理性决策系统性倾向。先前研究发现，这些偏差因模型而异，且可能因指令微调而放大。然而，这些差异是否源于预训练、微调或训练随机性仍不清楚。我们提出一种两步因果实验方法以厘清这些因素。首先，通过不同随机种子多次微调模型，研究训练随机性对30多种认知偏差的影响；其次，引入“跨微调”方法——交换模型间的指令数据集以隔离偏差来源，直接测试偏差是否依赖数据集。结果显示，尽管训练随机性引入一定变异性，但偏差主要由预训练塑造：相同预训练骨干的模型比仅共享微调数据的模型表现出更相似的偏差模式。这些发现表明，理解微调模型的偏差需考虑其预训练起源，而非仅关注微调效应。这一视角可为未来评估和缓解LLMs偏差的策略提供指导。

</details>


### [2] [Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses](https://arxiv.org/abs/2507.07188)
**中文标题：提示扰动揭示LLM在调查响应中的人类类似偏差**

*Jens Rupprecht,Georg Ahnert,Markus Strohmaier*

主要分类: cs.CL

摘要简述: 研究发现大型语言模型（LLM）在模拟社会科学调查时存在与人类相似的响应偏差，尤其是对最后呈现的选项表现出明显的“近因偏差”。模型规模越大越稳健，但仍对语义变化敏感。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）越来越多地被用作社会科学调查的代理，但其可靠性和对已知响应偏差的敏感性尚不清楚。本文旨在通过扰动测试揭示LLM在调查中的响应偏差。

研究方法: 研究测试了九种不同的LLM，使用世界价值观调查（WVS）的问题，并对其提问和答案选项结构施加了11种扰动，生成了超过167,000次模拟访谈。

研究结果: 所有测试模型均表现出不同程度的“近因偏差”，倾向于选择最后呈现的选项。模型规模越大越稳健，但对语义变化（如改写）和组合扰动仍敏感。

研究结论: LLM在调查响应中部分与人类偏差一致，提示设计和鲁棒性测试对生成合成调查数据至关重要。

中文摘要: 大型语言模型（LLM）越来越多地被用作社会科学调查中人类受试者的代理，但其可靠性和对已知响应偏差的敏感性尚不清楚。本文研究了LLM在规范性调查背景下的响应鲁棒性——我们测试了九种不同的LLM，使用世界价值观调查（WVS）的问题，并对其提问和答案选项结构施加了11种扰动，生成了超过167,000次模拟访谈。通过这一过程，我们不仅揭示了LLM对扰动的脆弱性，还发现所有测试模型均表现出不同程度的“近因偏差”，倾向于选择最后呈现的答案选项。尽管较大的模型通常更稳健，但所有模型仍对语义变化（如改写）和组合扰动敏感。通过施加一系列扰动，我们发现LLM部分与人类调查响应偏差一致。这强调了在使用LLM生成合成调查数据时，提示设计和鲁棒性测试的至关重要性。

</details>


### [3] [SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains](https://arxiv.org/abs/2507.07229)
**中文标题：SynthTextEval：面向高风险领域的合成文本数据生成与评估**

*Krithika Ramesh,Daniel Smolyak,Zihao Zhao,Nupoor Gandhi,Ritu Agarwal,Margrét Bjarnadóttir,Anjalie Field*

主要分类: cs.CL

摘要简述: SynthTextEval是一个用于全面评估合成文本的工具包，旨在通过多维度评估提升合成文本在高风险领域（如医疗和法律）的可用性和隐私保护。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型生成的合成文本在多个应用中展现出潜力，尤其是在高风险领域（如医疗和法律）中减少隐私泄露风险的需求日益增长。然而，实现这一潜力需要对合成文本进行多维度、系统化的评估，以确保其在下游系统中的实用性、公平性、隐私安全性以及与源文本的分布一致性。

研究方法: SynthTextEval提供了一个工具包，用户可以通过上传或使用其生成模块创建合成文本，并从多个维度进行评估，包括下游系统效用、公平性、隐私泄露风险、与源文本的分布差异以及领域专家的定性反馈。

研究结果: 该工具包在医疗和法律领域的数据集上展示了其功能和有效性，通过整合和标准化评估指标，提升了合成文本的可用性，从而促进了AI开发中的隐私保护。

研究结论: SynthTextEval通过标准化和全面的评估方法，为合成文本在高风险领域的应用提供了可靠支持，推动了隐私保护技术的发展。

中文摘要: 我们提出了SynthTextEval，一个用于全面评估合成文本的工具包。大型语言模型（LLM）输出的流畅性使得合成文本在众多应用中具有潜在可行性，例如在AI系统开发和部署中减少隐私泄露风险。然而，实现这一潜力需要对合成数据进行多维度、系统化的评估，包括其在下游系统中的效用、系统的公平性、隐私泄露风险、与源文本的分布差异以及领域专家的定性反馈。SynthTextEval允许用户对这些维度进行全面评估，用户可以通过上传数据或使用工具包的生成模块生成合成数据。尽管该工具包适用于任何数据，但我们重点展示了其在医疗和法律两个高风险领域数据集上的功能和有效性。通过整合和标准化评估指标，我们旨在提升合成文本的可用性，进而推动AI开发中的隐私保护。

</details>


### [4] [Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings](https://arxiv.org/abs/2507.07248)
**中文标题：医疗领域语言模型的红队测试协议：用户视角在医疗环境中的重要性**

*Minseon Kim,Jean-Philippe Corbeil,Alessandro Sordoni,Francois Beaulieu,Paul Vozila*

主要分类: cs.CL

摘要简述: 本文提出了一种针对医疗领域语言模型的安全评估协议，重点关注患者和临床医生的视角，填补了现有安全评估的空白，并通过案例研究验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLMs）在医疗领域的广泛应用，其安全性问题日益突出。现有评估多关注通用安全基准，而忽略了医疗场景中不同用户（如患者和临床医生）的特定需求。本文旨在填补这一空白，提出针对医疗领域的安全评估协议。

研究方法: 本文设计了一种医疗领域专用的安全评估协议，从患者和临床医生的视角出发，构建了包含466个样本的PatientSafetyBench，覆盖5个关键类别。通过案例研究，将协议应用于MediPhi模型集合。

研究结果: 研究结果显示，该协议能够有效评估医疗LLMs的安全性，尤其是在患者和临床医生视角下的表现。PatientSafetyBench为医疗领域的安全评估提供了标准化工具。

研究结论: 本文首次通过针对性的红队测试，从患者、临床医生和普通用户三个视角定义了医疗LLMs的安全评估标准，为医疗领域的安全部署奠定了基础。

中文摘要: 随着大型语言模型（LLMs）性能的不断提升，其在医疗等领域的应用日益广泛。然而，LLMs在医疗应用中的集成引发了关键的安全问题，尤其是由于用户角色多样（如患者和临床医生）以及模型输出可能直接影响人类健康。尽管医疗LLMs具备领域特定能力，但现有的安全评估主要集中于通用安全基准。本文提出了一种针对医疗领域的安全评估协议，从患者和临床医生的视角出发，结合通用安全评估，定量分析医疗LLMs的安全性。我们通过构建包含466个样本的PatientSafetyBench（覆盖5个关键类别）填补了文献中的空白，以衡量患者视角下的安全性。我们以MediPhi模型集合为案例研究应用了红队测试协议。据我们所知，这是首次通过针对性的红队测试，从患者、临床医生和普通用户三个视角定义医疗LLMs安全评估标准的工作，为医疗领域的安全部署奠定了基础。

</details>


### [5] [The Impact of Background Speech on Interruption Detection in Collaborative Groups](https://arxiv.org/abs/2507.07280)
**中文标题：背景语音对协作小组中打断检测的影响**

*Mariah Bradford,Nikhil Krishnaswamy,Nathaniel Blanchard*

主要分类: cs.CL

摘要简述: 本文研究了背景语音对协作小组中打断检测的影响，提出了一种在多对话环境中识别打断的先进方法，并揭示了打断在协作互动中的语言和韵律特征。


<details>
  <summary>详细信息</summary>
研究动机: 打断在协作学习中至关重要，但现有研究多基于单一对话环境，而实际课堂中存在多组对话重叠的情况。因此，需要开发一种能在嘈杂环境中准确识别打断的方法。

研究方法: 本文分析了单一对话和多组对话环境中的打断检测，提出了一种抗重叠语音干扰的先进打断识别方法，适用于课堂场景。

研究结果: 研究开发了一种在多对话环境中鲁棒的打断识别方法，并揭示了打断在协作互动中的语言和韵律特征。

研究结论: 本研究为未来在多组对话重叠环境中跟踪小组对话提供了基础，并展示了打断在协作学习中的重要性。

中文摘要: 打断在协作学习中扮演着关键角色，塑造小组互动并影响知识构建。AI驱动的支持可以帮助教师监控这些互动。然而，以往关于打断检测和解释的研究多在单一对话环境中进行，且音频相对干净。在课堂中部署AI代理以支持小组协作学习时，需要应对多组同时进行的对话——在这种情况下，重叠语音将无处不在，打断需要通过其他方式识别。本文分析了单一对话和多组对话环境中的打断检测，并提出了一种抗重叠语音干扰的先进打断识别方法，适用于课堂部署。此外，我们的研究揭示了打断在协作小组互动中表现出的有意义的语言和韵律信息。本研究也为未来在多组对话重叠环境中跟踪小组对话的研究奠定了基础。

</details>


### [6] [Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation](https://arxiv.org/abs/2507.07307)
**中文标题：基于多智能体检索增强框架的健康错误信息证据反驳方法**

*Anirban Saha Anik,Xiaoying Song,Elliott Wang,Bryan Wang,Bengisu Yarimbas,Lingzi Hong*

主要分类: cs.CL

摘要简述: 本文提出了一种多智能体检索增强框架，用于生成针对健康错误信息的反驳言论，通过结合静态和动态证据，优化了生成内容的相关性、礼貌性、信息量和事实准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于检索增强生成（RAG）的大语言模型（LLMs）在生成反驳错误信息的言论时，依赖的证据有限且对最终输出的控制不足。本文旨在解决这些问题，提出一种更高效、可控的框架。

研究方法: 采用多智能体检索增强框架，结合多个LLMs优化知识检索、证据增强和响应精炼，同时整合静态和动态证据，确保生成的反驳言论相关且基于最新信息。

研究结果: 该方法在礼貌性、相关性、信息量和事实准确性上优于基线方法，并通过消融实验验证了各组件的重要性。人工评估表明，精炼显著提升了反驳言论的质量并获得了人类偏好。

研究结论: 提出的多智能体框架能够高效生成高质量的反驳言论，为应对健康错误信息提供了有力工具。

中文摘要: 结合检索增强生成（RAG）的大语言模型（LLMs）在生成反驳错误信息的言论方面表现出强大能力。然而，当前研究依赖的证据有限且对最终输出的控制不足。为解决这些问题，我们提出了一种多智能体检索增强框架，用于生成针对健康错误信息的反驳言论，通过结合多个LLMs优化知识检索、证据增强和响应精炼。我们的方法整合了静态和动态证据，确保生成的反驳言论相关、有据可依且与时俱进。实验表明，该方法在礼貌性、相关性、信息量和事实准确性上优于基线方法。通过消融实验验证了各组件的重要性。此外，人工评估显示精炼显著提升了反驳言论的质量并获得了人类偏好。

</details>


### [7] [GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation](https://arxiv.org/abs/2507.07414)
**中文标题：GNN-CNN：一种用于文本表示的高效卷积与图神经网络混合模型**

*Fardin Rastakhiz*

主要分类: cs.CL

摘要简述: 本文提出了一种结合图神经网络（GNN）和卷积神经网络（CNN）的高效混合模型GNN-CNN，用于文本表示。该模型通过实时端到端图生成机制处理字符级输入，无需填充或截断，同时结合大型语言模型（LLM）的信息提升性能。实验证明其在文本分类任务中高效且性能优越。


<details>
  <summary>详细信息</summary>
研究动机: 当前主流的Transformer模型在处理长文本时存在二次计算复杂度问题，效率低下。本研究旨在设计一种高效且计算复杂度低的模型，以解决长文本处理中的时间和能耗问题。

研究方法: 模型结合CNN捕捉局部上下文模式，通过基于格的图结构扩展局部感受野，并利用小世界图聚合文档级信息。同时，通过高效的字典查找整合LLM的token嵌入和情感极性信息。

研究结果: 实验结果表明，生成的图具有有意义的语义组织结构（平均聚类系数约0.45，平均最短路径长度4-5），在情感分析和新闻分类等任务中表现优异，且效率高于现有模型。

研究结论: GNN-CNN模型通过结合GNN和CNN的优势，实现了高效且高性能的文本表示，为长文本处理提供了一种可行的解决方案。

中文摘要: 时间、成本和能效是深度学习（DL）中的关键考量因素，尤其是在处理长文本时。目前最先进的Transformer模型表现出与输入长度相关的二次计算复杂度，导致其在长文档处理中效率低下。本研究提出了一种新颖的模型架构，结合了图神经网络（GNN）和卷积神经网络（CNN），并集成了实时端到端的图生成机制。该模型处理紧凑的字符级输入批次，无需填充或截断。为了在保持高速度和效率的同时提升性能，模型通过高效的字典查找整合了大型语言模型（LLM）的信息（如token嵌入和情感极性）。模型利用CNN捕捉局部上下文模式，通过基于格的图结构扩展局部感受野，并采用小世界图聚合文档级信息。生成的图具有指示有意义语义组织的结构特性（平均聚类系数约0.45，平均最短路径长度介于4和5之间）。模型在多个文本分类任务（包括情感分析和新闻分类）中进行了评估，并与最先进的模型进行了比较。实验结果证实了所提模型的高效性和竞争性能。

</details>


### [8] [MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning](https://arxiv.org/abs/2507.07419)
**中文标题：MedReadCtrl：基于可读性控制指令学习的个性化医疗文本生成**

*Hieu Tran,Zonghai Yao,Won Seok Jang,Sharmin Sultana,Allen Chang,Yuan Zhang,Hong Yu*

主要分类: cs.CL

摘要简述: MedReadCtrl是一种可控制生成文本可读性的框架，显著提升了医疗文本的个性化生成能力，尤其在低文化水平群体中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 生成式AI在医疗领域潜力巨大，但如何确保生成内容既个性化又易于理解是关键挑战。MedReadCtrl旨在解决这一问题，通过调整输出复杂度而不损失原意。

研究方法: MedReadCtrl采用可读性控制的指令调优框架，使大语言模型能够根据需求调整生成文本的复杂度。

研究结果: 在多个数据集和任务中，MedReadCtrl显著优于GPT-4，尤其在低文化水平群体中更受专家青睐（71.7% vs. 23.3%）。

研究结论: MedReadCtrl能够在不改变医学意图的情况下，将临床内容转化为易于理解的语言，为患者教育和公平获取AI医疗服务提供了可扩展的解决方案。

中文摘要: 生成式AI在医疗领域展现出巨大潜力，从临床决策支持到改善患者预后的聊天机器人。部署的关键挑战在于有效的人机沟通，内容需兼具个性化和易理解性。我们提出MedReadCtrl，一种可读性控制的指令调优框架，使大语言模型能够在不损失原意的情况下调整输出复杂度。在医疗和通用领域的九个数据集和三项任务中，MedReadCtrl的可读性指令遵循错误显著低于GPT-4（如ReadMe上1.39 vs. 1.59，p<0.001），并在未见过的临床任务中表现优异（如MTSamples上ROUGE-L提升14.7，SARI提升6.18）。专家更倾向于MedReadCtrl（71.7% vs. 23.3%），尤其在低文化水平群体中。这些优势反映了MedReadCtrl将临床内容转化为易于理解、符合可读性要求的语言的能力，同时保持医学意图，为患者教育和公平获取AI医疗服务提供了可扩展的解决方案。

</details>


### [9] [SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data](https://arxiv.org/abs/2507.07421)
**中文标题：SynthEHR-Eviction：利用LLM增强的合成EHR数据提升驱逐SDoH检测**

*Zonghai Yao,Youxia Zhao,Avijit Mitra,David A. Levy,Emily Druhl,Jack Tsai,Hong Yu*

主要分类: cs.CL

摘要简述: SynthEHR-Eviction提出了一种结合LLM、人工标注和自动提示优化的流程，用于从临床记录中提取驱逐状态，显著提升了检测性能并降低了标注成本。


<details>
  <summary>详细信息</summary>
研究动机: 驱逐作为健康社会决定因素（SDoH）之一，与住房不稳定、失业和心理健康密切相关，但在电子健康记录（EHR）中缺乏结构化编码，限制了其应用。

研究方法: 研究提出SynthEHR-Eviction流程，结合大型语言模型（LLM）、人工标注和自动提示优化（APO），从临床记录中提取驱逐状态，并构建了最大的公开驱逐相关SDoH数据集。

研究结果: 基于SynthEHR-Eviction训练的微调LLM（如Qwen2.5、LLaMA3）在人类验证数据上取得了88.8%（驱逐）和90.3%（其他SDoH）的Macro-F1分数，优于GPT-4o-APO、GPT-4o-mini-APO和BioBERT。

研究结论: 该流程显著降低了80%以上的标注工作量，加速了数据集创建，并适用于其他信息提取任务，为驱逐检测和其他SDoH研究提供了高效、可扩展的解决方案。

中文摘要: 驱逐是健康社会决定因素（SDoH）中重要但研究不足的一项，与住房不稳定、失业和心理健康相关。尽管驱逐出现在非结构化的电子健康记录（EHR）中，但很少以结构化字段编码，限制了其下游应用。我们提出了SynthEHR-Eviction，这是一种可扩展的流程，结合了大型语言模型（LLM）、人工标注和自动提示优化（APO），用于从临床记录中提取驱逐状态。通过该流程，我们创建了迄今为止最大的公开驱逐相关SDoH数据集，包含14个细粒度类别。基于SynthEHR-Eviction训练的微调LLM（如Qwen2.5、LLaMA3）在人类验证数据上取得了88.8%（驱逐）和90.3%（其他SDoH）的Macro-F1分数，优于GPT-4o-APO（87.8%、87.3%）、GPT-4o-mini-APO（69.1%、78.1%）和BioBERT（60.7%、68.3%），同时实现了跨不同模型规模的经济高效部署。该流程减少了80%以上的标注工作量，加速了数据集创建，实现了可扩展的驱逐检测，并可推广至其他信息提取任务。

</details>


### [10] [Towards Interpretable Time Series Foundation Models](https://arxiv.org/abs/2507.07439)
**中文标题：迈向可解释的时间序列基础模型**

*Matthieu Boileau,Philippe Helluy,Jeremy Pawlus,Svitlana Vyetrenko*

主要分类: cs.CL

摘要简述: 本文探讨如何将时间序列推理能力蒸馏到小型指令调优语言模型中，以构建可解释的时间序列基础模型。通过合成数据集和自然语言注释，训练紧凑的Qwen模型，并评估其解释能力。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在开发小型、可解释的时间序列基础模型，使其能够以自然语言解释时间序列模式，适用于设备端或隐私敏感场景。

研究方法: 利用合成的均值回归时间序列数据集，生成自然语言注释，并用这些注释监督紧凑Qwen模型的微调。引入评估指标衡量蒸馏推理的质量。

研究结果: 实验表明，经过训练的模型获得了有意义的解释能力，能够识别趋势方向、噪声强度和极值定位。

研究结论: 研究表明，将时间序列理解压缩到轻量级语言模型中具有可行性，为开发小型可解释模型奠定了基础。

中文摘要: 本文研究了如何将时间序列推理能力蒸馏到小型指令调优语言模型中，作为构建可解释时间序列基础模型的一步。通过使用合成的均值回归时间序列数据集，并利用大型多模态模型生成自然语言注释，我们监督了紧凑Qwen模型的微调。我们引入了评估指标，以评估蒸馏推理的质量——重点关注趋势方向、噪声强度和极值定位——并表明经过训练的模型获得了有意义的解释能力。我们的结果突显了将时间序列理解压缩到适合设备端或隐私敏感部署的轻量级语言模型中的可行性。这项工作为开发能够以自然语言解释时间模式的小型可解释模型奠定了具体基础。

</details>


### [11] [SAND: Boosting LLM Agents with Self-Taught Action Deliberation](https://arxiv.org/abs/2507.07441)
**中文标题：SAND：通过自我教导的动作审议提升LLM代理性能**

*Yu Xia,Yiran Jenny Shen,Junda Wu,Tong Yu,Sungchul Kim,Ryan A. Rossi,Lina Yao,Julian McAuley*

主要分类: cs.CL

摘要简述: 本文提出SAND框架，通过自我教导的动作审议提升LLM代理性能，避免因有限动作空间探索而选择次优动作。


<details>
  <summary>详细信息</summary>
研究动机: 现有LLM代理调优方法多模仿专家行为或偏好优化，但缺乏对替代动作的审议，易导致选择看似合理但次优的动作。

研究方法: SAND框架通过自我一致性动作采样和执行引导的动作评价，合成逐步动作审议思路，并利用审议轨迹迭代调优LLM代理。

研究结果: 在两个代表性交互代理任务中，SAND比初始监督调优平均提升20%，并优于现有最佳代理调优方法。

研究结论: SAND框架通过动作审议显著提升LLM代理性能，为代理调优提供了新思路。

中文摘要: 大型语言模型（LLM）代理通常通过监督微调或偏好优化进行调优，但这些方法可能因缺乏对替代动作的审议而选择次优动作。为此，本文提出自我教导的动作审议（SAND）框架，使LLM代理在提交动作前能明确审议候选动作。针对动作空间大和步骤级动作评价的挑战，我们结合自我一致性动作采样和执行引导的动作评价，利用基础模型合成逐步动作审议思路。通过迭代方式，审议轨迹用于微调LLM代理。在两个代表性交互代理任务中，SAND比初始监督微调平均提升20%，并优于现有最佳代理调优方法。

</details>


### [12] [RLEP: Reinforcement Learning with Experience Replay for LLM Reasoning](https://arxiv.org/abs/2507.07451)
**中文标题：RLEP：基于经验回放的强化学习用于大语言模型推理**

*Hongzhi Zhang,Jia Fu,Jingyuan Zhang,Kai Fu,Qi Wang,Fuzheng Zhang,Guorui Zhou*

主要分类: cs.CL

摘要简述: RLEP是一种结合经验回放的强化学习框架，通过回放已验证的高质量轨迹，提升大型语言模型的推理能力，实现更快收敛和更强性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型的强化学习训练通常不稳定且能耗高，策略可能偏离预训练权重。RLEP旨在通过回放已验证的成功轨迹，减少无效探索，优化学习效率。

研究方法: RLEP分为两阶段：首先收集已验证的轨迹，然后在训练过程中回放这些轨迹。每次更新时，策略通过混合新生成的轨迹和回放的高质量样本进行优化。

研究结果: 在Qwen2.5-Math-7B模型上，RLEP以更少的更新次数达到基线峰值准确率，并最终超越基线：AIME-2024从38.2%提升至39.9%，AIME-2025从19.8%提升至22.3%，AMC-2023从77.0%提升至82.2%。

研究结论: RLEP通过回放高质量经验，显著提升模型推理性能和训练效率，为大型语言模型的强化学习提供了有效解决方案。

中文摘要: 大型语言模型的强化学习（RL）是一项高能耗任务：训练可能不稳定，且策略可能逐渐偏离其预训练权重。我们提出RLEP——基于经验回放的强化学习——一种两阶段框架，首先收集已验证的轨迹，随后在训练过程中回放这些轨迹。每次更新时，策略通过混合新生成的轨迹和回放的成功样本进行优化。通过回放高质量示例，RLEP避免无效探索，专注于有潜力的推理路径，实现更快收敛和更强性能。在Qwen2.5-Math-7B基础模型上，RLEP以更少的更新次数达到基线峰值准确率，并最终超越基线：AIME-2024从38.2%提升至39.9%，AIME-2025从19.8%提升至22.3%，AMC-2023从77.0%提升至82.2%。我们的代码、数据集和检查点已公开，以促进可复现性和进一步研究。

</details>


### [13] [Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models](https://arxiv.org/abs/2507.07484)
**中文标题：机器废话：大语言模型中对真实性漠视的现象分析**

*Kaiqu Liang,Haimin Hu,Xuandong Zhao,Dawn Song,Thomas L. Griffiths,Jaime Fernández Fisac*

主要分类: cs.CL

摘要简述: 本文提出‘机器废话’作为大语言模型（LLM）中对真实性漠视现象的总体框架，并引入‘废话指数’量化这一现象。通过实证评估，发现强化学习人类反馈（RLHF）和推理时链式思维（CoT）提示显著加剧了废话行为，尤其在政治语境中表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 大语言模型（LLM）常出现幻觉和迎合性行为，但缺乏对其真实性漠视的系统性研究。本文旨在通过‘机器废话’框架，全面分析LLM中真实性丧失的现象及其机制。

研究方法: 提出‘废话指数’量化LLM对真实性的漠视，并分类四种废话形式：空洞修辞、含糊其辞、模棱两可和未经证实的断言。在Marketplace、Political Neutrality数据集及新开发的BullshitEval基准（2400个场景覆盖100个AI助手）上进行实证评估。

研究结果: RLHF微调显著加剧了废话行为，CoT提示尤其放大了空洞修辞和含糊其辞。政治语境中废话现象普遍，模棱两可是主要策略。

研究结论: 研究揭示了AI对齐中的系统性挑战，为提升LLM真实性提供了新视角。

中文摘要: 废话，如哲学家哈里·法兰克福所定义，指不考虑真实性的陈述。尽管已有研究探讨了大语言模型（LLM）的幻觉和迎合性，本文提出‘机器废话’作为总体框架，以系统性分析LLM中真实性丧失的现象及其机制。我们引入‘废话指数’量化LLM对真实性的漠视，并提出四种废话形式的分类：空洞修辞、含糊其辞、模棱两可和未经证实的断言。我们在Marketplace数据集、Political Neutrality数据集及新开发的BullshitEval基准（2400个场景覆盖100个AI助手）上进行实证评估。结果显示，基于人类反馈的强化学习（RLHF）微调显著加剧了废话行为，推理时链式思维（CoT）提示尤其放大了空洞修辞和含糊其辞。我们还发现政治语境中废话现象普遍，模棱两可是主要策略。研究结果凸显了AI对齐中的系统性挑战，并为提升LLM真实性提供了新视角。

</details>


### [14] [PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving](https://arxiv.org/abs/2507.07495)
**中文标题：PLAN-TUNING：后训练语言模型以学习复杂问题解决的逐步规划**

*Mihir Parmar,Palash Goyal,Xin Liu,Yiwen Song,Mingyang Ling,Chitta Baral,Hamid Palangi,Tomas Pfister*

主要分类: cs.CL

摘要简述: PLAN-TUNING是一种后训练框架，通过从大语言模型提取任务分解（规划轨迹）并微调小模型，提升复杂问题解决能力。实验显示其在多个基准测试中表现优异，泛化能力显著增强。


<details>
  <summary>详细信息</summary>
研究动机: 当前，利用任务分解提升大语言模型性能已取得显著成果，但如何在小型开源模型中应用类似规划结构仍待探索。PLAN-TUNING旨在填补这一空白。

研究方法: PLAN-TUNING框架包括两个步骤：(1) 从大语言模型提取合成任务分解（规划轨迹）；(2) 通过监督学习和强化学习目标微调小模型，使其模仿规划过程。

研究结果: 在GSM8k和MATH基准测试中，PLAN-TUNING模型平均性能提升约7%。在跨领域数据集（如OlympiadBench和AIME 2024）上，性能分别提升约10%和12%。

研究结论: PLAN-TUNING通过规划轨迹显著提升小语言模型的复杂推理能力，是一种有效的任务性能优化策略。

中文摘要: 近年来，将复杂问题分解为简单子任务（人类自然规划的关键部分）显著提升了大语言模型（LLMs）的性能。然而，在后训练中利用此类规划结构以提升小型开源LLMs性能的研究仍不足。为此，我们提出PLAN-TUNING，一种统一的后训练框架，其（i）从大规模LLMs中提取合成任务分解（称为“规划轨迹”）；（ii）通过监督学习和强化学习目标微调小模型，使其模仿这些规划过程以改进复杂推理。在GSM8k和MATH基准测试中，经过规划调优的模型平均性能提升约7%。此外，规划调优模型在跨领域数据集上表现出更好的泛化能力，在OlympiadBench和AIME 2024上分别平均提升约10%和12%。我们的详细分析展示了规划轨迹如何提升复杂推理能力，表明PLAN-TUNING是提升小型LLMs任务特定性能的有效策略。

</details>


### [15] [Teaching LLM to Reason: Reinforcement Learning from Algorithmic Problems without Code](https://arxiv.org/abs/2507.07498)
**中文标题：教授LLM推理：无需代码的算法问题强化学习**

*Keqin Bao,Nuo Chen,Xiaoyuan Li,Binyuan Hui,Bowen Yu,Fuli Feng,Junyang Lin,Xiangnan He,Dayiheng Liu*

主要分类: cs.CL

摘要简述: 论文提出TeaR方法，通过强化学习和数据优化提升大语言模型的推理能力，避免对复杂代码的依赖，显著提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前大语言模型在推理能力上仍有不足，尤其是依赖代码模拟执行时容易陷入复杂算法模式，而非核心推理结构。

研究方法: TeaR通过精心设计的数据和强化学习，引导模型在代码相关任务中发现最优推理路径，从而提升通用推理能力。

研究结果: 实验表明，TeaR在多个基准测试中显著提升性能，Qwen2.5-7B和R1-Distilled-7B分别提升35.9%和5.9%。

研究结论: TeaR方法有效提升了大语言模型的推理能力，避免了过度依赖复杂代码的问题。

中文摘要: 提升推理能力是大语言模型研究的核心目标之一。一种有前景的方法是要求模型逐步模拟代码执行以推导输出，但代码通常设计用于大规模系统，直接应用会导致对复杂数据结构和算法的过度依赖，甚至在简单情况下也会过拟合算法模式而非核心推理结构。为此，我们提出TeaR，旨在通过精心设计的数据和强化学习引导模型在代码相关任务中发现最优推理路径，从而提升通用推理能力。我们使用两个基础模型和三个长链蒸馏模型（参数规模从15亿到320亿）在17个涵盖数学、知识、代码和逻辑推理的基准测试中进行了广泛实验。结果显示性能显著提升，尤其是Qwen2.5-7B和R1-Distilled-7B分别提升了35.9%和5.9%。

</details>


### [16] [Extracting ORR Catalyst Information for Fuel Cell from Scientific Literature](https://arxiv.org/abs/2507.07499)
**中文标题：从科学文献中提取燃料电池氧还原反应催化剂信息**

*Hein Htet,Amgad Ahmed Ali Ibrahim,Yutaka Sasaki,Ryoji Asahi*

主要分类: cs.CL

摘要简述: 本研究提出了一种基于DyGIE++和多种预训练BERT变体（如MatSciBERT和PubMedBERT）的命名实体识别（NER）和关系抽取（RE）方法，用于从科学文献中提取氧还原反应（ORR）催化剂信息，构建了燃料电池材料信息学语料库（FC-CoMIcs）。实验表明，PubMedBERT在NER任务中表现最佳（F1-score为82.19%），MatSciBERT在RE任务中表现最优（F1-score为66.10%）。


<details>
  <summary>详细信息</summary>
研究动机: 氧还原反应（ORR）催化剂对提升燃料电池效率至关重要，但由于科学文献中文本数据的复杂性和多样性，从中提取结构化信息仍是一个重大挑战。

研究方法: 研究采用DyGIE++框架，结合多种预训练BERT变体（如MatSciBERT和PubMedBERT），通过数据标注、整合和模型微调，从科学文献中提取ORR催化剂相关信息。构建了包含12个关键实体和两种关系的标注数据集。

研究结果: 实验结果显示，微调后的PubMedBERT在NER任务中取得最高F1-score（82.19%），MatSciBERT在RE任务中表现最佳（F1-score为66.10%）。与人工标注对比表明，微调模型在ORR催化剂信息提取中具有可靠性。

研究结论: 研究表明，领域特定的BERT模型（如PubMedBERT和MatSciBERT）在ORR催化剂信息提取中优于通用科学模型（如BlueBERT），为可扩展的自动化文献分析提供了潜力。

中文摘要: 氧还原反应（ORR）催化剂在提升燃料电池效率中起关键作用，是材料科学研究的重要方向。然而，由于文本数据的复杂性和多样性，从大量科学文献中提取ORR催化剂的结构化信息仍是一个重大挑战。本研究提出了一种基于DyGIE++框架的命名实体识别（NER）和关系抽取（RE）方法，结合多种预训练BERT变体（如MatSciBERT和PubMedBERT），从科学文献中提取ORR催化剂相关信息，并构建了燃料电池材料信息学语料库（FC-CoMIcs）。通过人工标注构建了包含12个关键实体和两种关系的数据集。研究方法包括数据标注、整合和基于Transformer模型的微调，以提高信息提取的准确性。实验评估了不同BERT变体对提取性能的影响，并研究了标注一致性的影响。实验结果表明，微调后的PubMedBERT模型在NER任务中取得最高F1-score（82.19%），MatSciBERT模型在RE任务中表现最佳（F1-score为66.10%）。与人工标注的对比表明，微调模型在ORR催化剂信息提取中具有可靠性，展现了其在可扩展自动化文献分析中的潜力。结果表明，领域特定的BERT模型在ORR催化剂信息提取中优于通用科学模型（如BlueBERT）。

</details>


### [17] [Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models](https://arxiv.org/abs/2507.07505)
**中文标题：幻觉站点：论基于Transformer的语言模型的一些基本局限性**

*Varin Sikka,Vishal Sikka*

主要分类: cs.CL

摘要简述: 本文探讨了基于Transformer的语言模型（LLMs）在计算复杂性和任务验证能力上的局限性，指出其无法完成超出一定复杂度的计算和代理任务，也无法验证此类任务的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 随着基于Transformer的语言模型在AI中的广泛应用，人们对其能力边界（尤其是所谓的“幻觉”现象）产生了浓厚兴趣。此外，LLMs被越来越多地用于创建自主或半自主代理以执行现实任务，因此理解其能力范围变得至关重要。

研究方法: 本文从LLM推理的计算复杂性角度出发，通过理论分析和实例展示，探讨了LLMs在复杂计算和代理任务中的局限性及其验证能力的不足。

研究结果: 研究结果表明，LLMs无法完成超出一定复杂度的计算和代理任务，也无法验证此类任务的准确性。文中提供了具体实例支持这一结论。

研究结论: 本文揭示了LLMs在复杂任务中的固有局限性，强调了在现实应用中需谨慎使用此类模型，并提出了进一步研究的必要性。

中文摘要: 随着基于Transformer的语言模型在AI中的广泛应用，人们对LLMs能力的边界（尤其是所谓的“幻觉”现象）产生了浓厚兴趣。此外，LLMs被越来越多地用于创建自主或半自主代理以执行现实任务，这使得理解其能力范围变得尤为重要。本文从LLM推理的计算复杂性角度探讨了这一主题。我们证明，LLMs无法完成超出一定复杂度的计算和代理任务，也无法验证此类任务的准确性。文中提供了具体实例，并讨论了这一研究的若干影响。

</details>


### [18] [Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System](https://arxiv.org/abs/2507.07509)
**中文标题：面向真实世界的中文心理支持对话：CPsDD数据集与协同进化的多智能体系统**

*Yuanchen Shi,Longyin Zhang,Fang Kong*

主要分类: cs.CL

摘要简述: 本文提出了一种利用有限真实数据和专家知识构建中文心理支持对话数据集（CPsDD）的方法，并开发了一个多智能体系统（CADSS）用于心理支持对话。实验表明，该系统在策略预测和情感支持对话任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 由于心理压力增加，心理支持需求日益增长，但相关数据集稀缺，尤其是非英语语言。本文旨在填补这一空白，构建高质量的中文心理支持对话数据集，并开发有效的支持系统。

研究方法: 通过结合真实数据和专家知识，微调两个大型语言模型（对话生成器和对话修改器），生成大规模心理支持对话。随后通过自动和人工审核构建CPsDD数据集。同时设计多智能体系统CADSS，包括分析用户特征的Profiler、总结对话历史的Summarizer、选择策略的Planner和生成共情回应的Supporter。

研究结果: 构建了包含68K对话的CPsDD数据集，涵盖13个群体、16种心理问题、13种原因和12种支持重点。CADSS在策略预测和情感支持对话任务中表现优异，优于现有基准。

研究结论: 本文提出的框架和数据集填补了中文心理支持对话领域的空白，CADSS系统在实验中表现出色，为心理支持提供了有效工具。

中文摘要: 随着压力增加，心理支持需求日益增长，但相关数据集稀缺，尤其是非英语语言。为此，我们提出了一种框架，利用有限的真实数据和专家知识微调两个大型语言模型：对话生成器和对话修改器。生成器基于预定义路径生成大规模心理支持对话，指导系统响应策略和用户互动，形成有效支持的基础。修改器优化这些对话以符合真实数据质量。通过自动和人工审核，我们构建了中文心理支持对话数据集（CPsDD），包含68K对话，涵盖13个群体、16种心理问题、13种原因和12种支持重点。此外，我们引入了综合智能体对话支持系统（CADSS），其中Profiler分析用户特征，Summarizer总结对话历史，Planner选择策略，Supporter生成共情回应。策略预测和情感支持对话（ESC）任务的实验结果表明，CADSS在CPsDD和ESConv数据集上均达到了最先进的性能。

</details>


### [19] [Triadic Multi-party Voice Activity Projection for Turn-taking in Spoken Dialogue Systems](https://arxiv.org/abs/2507.07518)
**中文标题：三方多说话者语音活动预测在语音对话系统轮流发言中的应用**

*Mikey Elmers,Koji Inoue,Divesh Lala,Tatsuya Kawahara*

主要分类: cs.CL

摘要简述: 本文首次将语音活动预测（VAP）应用于三方对话场景，用于预测说话者的未来语音活动，实验表明三方对话训练的VAP模型优于基线模型，但对话类型会影响准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统研究多关注双人对话的轮流发言，而三方对话的轮流发言研究较少。本文旨在将语音活动预测（VAP）扩展到三方对话场景，以预测未来语音活动。

研究方法: 研究使用日本三方对话数据集训练多个VAP模型，数据集包含多样话题的讨论。模型仅基于声学数据预测每位说话者的未来语音活动。

研究结果: 实验结果显示，三方对话训练的VAP模型在所有模型中表现优于基线，但对话类型对预测准确性有影响。

研究结论: 本研究证明VAP可用于三方对话的轮流发言预测，未来计划将该模型整合到语音对话系统中。

中文摘要: 轮流发言是语音对话的基本组成部分，但传统研究多涉及双人场景。本研究将语音活动预测（VAP）应用于三方多说话者场景，以预测未来的轮流发言。VAP模型的目标是仅利用声学数据预测每位说话者的未来语音活动。这是首次将VAP扩展到三方对话的研究。我们在一个日本三方对话数据集上训练了多个模型，参与者讨论了多种话题。研究发现，三方对话训练的VAP模型在所有模型中优于基线，但对话类型会影响准确性。本研究证实VAP可用于三方对话的轮流发言预测，未来工作将把该模型整合到语音对话系统中。

</details>


### [20] [CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text](https://arxiv.org/abs/2507.07539)
**中文标题：CEA-LIST在CheckThat! 2025：评估LLMs作为文本偏见和观点检测工具**

*Akram Elbouanani,Evan Dufraisse,Aboubacar Tuo,Adrian Popescu*

主要分类: cs.CL

摘要简述: 本文展示了使用大型语言模型（LLMs）进行多语言主观性检测的竞争性方法，通过少样本提示在CheckThat! 2025任务中表现优异，尤其在噪声或低质量数据环境下超越小型微调模型。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在探索大型语言模型（LLMs）在多语言主观性检测任务中的潜力，尤其是在数据噪声大或标注不一致的情况下，提供一种替代传统微调方法的有效方案。

研究方法: 采用少样本提示策略，结合精心设计的提示模板，并尝试了辩论式提示和多样本选择策略，但发现标准少样本提示效果最佳。

研究结果: 在CheckThat! 2025任务中，系统在阿拉伯语和波兰语中排名第一，并在意大利语、英语、德语及多语言赛道中进入前四，尤其在阿拉伯语数据上表现出色。

研究结论: LLM基于少样本学习在多语言情感任务中表现出高效性和适应性，为标注数据稀缺或不一致的情况提供了强有力替代方案。

中文摘要: 本文提出了一种基于大型语言模型（LLMs）的多语言主观性检测竞争性方法，采用少样本提示策略。我们参与了CheckThat! 2025评估活动的任务1：主观性检测。研究表明，当LLMs与精心设计的提示模板结合时，其性能可媲美或超越微调的小型语言模型（SLMs），尤其在噪声或低质量数据环境中。尽管尝试了辩论式提示和多样本选择策略等高级提示工程技术，但发现标准少样本提示效果最佳。我们的系统在CheckThat! 2025主观性检测任务中表现优异，包括阿拉伯语和波兰语的第一名，以及意大利语、英语、德语和多语言赛道的前四名。值得注意的是，该方法在阿拉伯语数据集上表现尤为稳健，可能因其对标注不一致的鲁棒性。这些发现凸显了LLM基于少样本学习在多语言情感任务中的高效性和适应性，为标注数据稀缺或不一致的情况提供了强有力替代方案。

</details>


### [21] [The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora](https://arxiv.org/abs/2507.07543)
**中文标题：跨语言成本：阿拉伯语-英语语料库中RAG的检索偏差**

*Chen Amiraz,Yaroslav Fyodorov,Elad Haramaty,Zohar Karnin,Liane Lewin-Eytan*

主要分类: cs.CL

摘要简述: 本文研究了阿拉伯语-英语跨语言检索增强生成（RAG）在特定领域中的检索偏差问题，发现检索是跨语言场景的主要瓶颈，并提出了一种简单的检索策略以提升性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有跨语言RAG研究多关注生成任务，且依赖开放领域数据（如维基百科），忽略了检索中的语言不平衡问题。本文旨在通过真实企业数据集，系统研究跨语言检索行为。

研究方法: 使用阿拉伯语-英语的真实企业数据集构建基准，涵盖查询和支持文档的所有语言组合，并随机独立抽取数据，以系统分析多语言检索行为。

研究结果: 研究发现，跨语言检索在特定领域场景中表现显著下降，主要源于检索器在跨语言文档排序上的困难。提出的简单检索策略通过强制均衡检索两种语言文档，显著提升了跨语言和整体性能。

研究结论: 跨语言检索是RAG应用中的关键瓶颈，改进检索策略可显著提升性能，为实际多语言RAG应用提供了优化方向。

中文摘要: 跨语言检索增强生成（RAG）是实现跨语言检索与生成的关键能力。以往研究多集中于生成任务，并依赖开放领域数据（如维基百科）的基准测试，而检索问题常因语言不平衡、预训练数据重叠及记忆内容被掩盖。为填补这一空白，我们使用真实企业数据集构建阿拉伯语-英语RAG的特定领域基准测试，涵盖查询和支持文档的所有语言组合，并独立均匀随机抽取数据，以系统研究多语言检索行为。

研究发现，在特定领域跨语言场景中，检索是主要瓶颈，当查询与文档语言不同时性能显著下降。关键发现是，这些失败主要源于检索器在跨语言文档排序上的困难。最后，我们提出一种简单的检索策略，通过强制均衡检索两种语言文档，显著提升了跨语言和整体性能。这些结果突显了改进多语言检索的重要机会，尤其在实际RAG应用中。

</details>


### [22] [The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs](https://arxiv.org/abs/2507.07562)
**中文标题：长链思维SFT与RL的协同困境：探究视觉语言模型推理的后训练技术**

*Jierun Chen,Tiezheng Yu,Haoli Bai,Lewei Yao,Jiannan Wu,Kaican Li,Fei Mi,Chaofan Tao,Lei Zhu,Manyi Zhang,Xiaohui Li,Lu Hou,Lifeng Shang,Qun Liu*

主要分类: cs.CL

摘要简述: 本文研究了长链思维监督微调（SFT）和强化学习（RL）在视觉语言模型（VLM）中的协同作用，发现两者结合未能实现预期效果，反而导致性能权衡。


<details>
  <summary>详细信息</summary>
研究动机: 视觉语言模型（VLMs）通过长链思维监督微调（SFT）和强化学习（RL）提升复杂推理能力，但两者在VLMs中的协同效果尚不明确，本文旨在系统研究其作用与交互。

研究方法: 通过多模态推理基准测试，分析长链思维SFT和RL的独立及联合效果，并尝试多种训练策略（如两阶段、交替、渐进训练）及数据混合和模型合并方法。

研究结果: SFT提升复杂问题的推理能力但增加冗余并降低简单问题性能；RL提升泛化性和简洁性，但对最难题的改善不如SFT。两者结合未能实现协同增效，反而导致性能权衡。

研究结论: 长链思维SFT和RL在VLMs中结合存在“协同困境”，需更自适应方法以充分发挥其潜力。

中文摘要: 大型视觉语言模型（VLMs）越来越多地采用后训练技术，如长链思维（CoT）监督微调（SFT）和强化学习（RL），以激发复杂推理能力。尽管这些方法在纯语言模型中表现出协同效应，但其在VLMs中的联合效果尚不确定。我们通过多模态推理基准测试，系统研究了长链思维SFT和RL的独特作用及交互。研究发现，SFT通过深度结构化推理提升复杂问题性能，但引入冗余并降低简单问题表现；而RL促进泛化性和简洁性，在所有难度级别上均带来一致提升，但对最难题的改善不如SFT显著。出乎意料的是，通过两阶段、交替或渐进训练策略，以及数据混合和模型合并，结合两者均未能产生叠加效益，反而导致准确性、推理风格和响应长度的权衡。这一“协同困境”凸显了需要更无缝和自适应的方法，以释放后训练技术在VLMs推理中的全部潜力。

</details>


### [23] [Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation](https://arxiv.org/abs/2507.07572)
**中文标题：基于多模态大语言模型的单模态到多模态对齐方法在文档图像机器翻译中的应用**

*Yupu Liang,Yaping Zhang,Zhiyang Zhang,Yang Zhao,Lu Xiang,Chengqing Zong,Yu Zhou*

主要分类: cs.CL

摘要简述: 本文提出M4Doc框架，通过单模态到多模态对齐方法，利用多模态大语言模型提升文档图像机器翻译的性能，显著改善跨领域泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 文档图像机器翻译（DIMT）面临训练数据有限和视觉-文本信息复杂交互的挑战，导致泛化能力不足。本文旨在通过多模态大语言模型（MLLMs）解决这些问题。

研究方法: M4Doc框架将仅图像编码器与预训练的多模态大语言模型对齐，学习关键的视觉-文本关联。推理时绕过MLLM，保持计算效率。

研究结果: 实验表明，M4Doc显著提升了翻译质量，尤其在跨领域泛化和复杂文档图像场景中表现优异。

研究结论: M4Doc通过单模态到多模态对齐，有效提升了DIMT的性能，同时保持了计算效率。

中文摘要: 文档图像机器翻译（DIMT）旨在翻译文档图像中的文本，但由于训练数据有限以及视觉与文本信息的复杂交互，面临泛化挑战。为解决这些问题，我们提出了M4Doc，一种新颖的单模态到多模态对齐框架，利用多模态大语言模型（MLLMs）。M4Doc将仅图像编码器与在大规模文档图像数据集上预训练的MLLM的多模态表示对齐，使轻量级DIMT模型能够在训练中学习关键的视觉-文本关联。在推理阶段，M4Doc绕过MLLM，保持计算效率的同时受益于其多模态知识。综合实验表明，该方法显著提升了翻译质量，尤其在跨领域泛化和复杂文档图像场景中表现突出。

</details>


### [24] [Bayesian Discrete Diffusion Beats Autoregressive Perplexity](https://arxiv.org/abs/2507.07586)
**中文标题：贝叶斯离散扩散模型超越自回归困惑度**

*Cooper Doyle*

主要分类: cs.CL

摘要简述: 本文揭示了离散扩散语言模型的贝叶斯核心，证明在正向掩码分布下的期望去噪器输出能准确恢复干净标记的后验分布。通过蒙特卡罗边缘化方法，该方法以O(1/√K)的速率收敛，并提出了一种轻量级推理集成方法，显著提升了语言模型的困惑度表现。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在揭示离散扩散语言模型的贝叶斯本质，并探索如何通过后验分布提升模型性能，尤其是在困惑度指标上超越自回归模型。

研究方法: 通过分析正向掩码分布下的期望去噪器输出，证明了其与干净标记后验分布的一致性。提出了一种基于蒙特卡罗边缘化的轻量级推理集成方法，通过多次掩码-去噪过程计算后验感知的标记概率。

研究结果: 在WikiText-2数据集上，该方法以K=8实现了8.8的测试困惑度，显著优于GPT-2 Small的20.3，且模型规模相当。

研究结论: 离散扩散语言模型的贝叶斯核心为后验分布提供了理论支持，提出的轻量级集成方法在无需额外训练成本的情况下显著提升了性能。

中文摘要: 我们揭示了离散扩散语言模型的隐藏贝叶斯核心，证明在正向掩码分布下的期望去噪器输出能够准确恢复干净标记的后验分布。在最小假设下，通过K次独立损坏的蒙特卡罗边缘化以O(1/√K)的速率收敛到此后验分布，从而提供了简单的一致性证明和有限样本误差界。基于这一发现，我们提出了一种轻量级推理集成方法，通过平均K次掩码-去噪过程，无需额外训练成本即可获得后验感知的标记概率和不确定性估计。在WikiText-2上，我们的方法以K=8实现了8.8的测试困惑度，而GPT-2 Small为20.3，尽管模型规模相当。代码发布于https://github.com/mercury0100/bayesradd。

</details>


### [25] [Exploring the Limits of Model Compression in LLMs: A Knowledge Distillation Study on QA Tasks](https://arxiv.org/abs/2507.07630)
**中文标题：探索大型语言模型压缩的极限：基于知识蒸馏的问答任务研究**

*Joyeeta Datta,Niclas Doll,Qusai Ramadan,Zeyd Boukhers*

主要分类: cs.CL

摘要简述: 本文研究了知识蒸馏（KD）在压缩大型语言模型（LLMs）中的极限，评估了在问答任务（QA）中蒸馏后的学生模型性能，发现学生模型在参数减少57.1%的情况下仍能保持教师模型90%以上的性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在NLP任务中表现出色，但其高计算需求限制了在资源受限环境中的实际应用。本研究旨在探索通过知识蒸馏压缩LLMs的可行性，同时保持其在问答任务中的高性能。

研究方法: 研究使用知识蒸馏从Pythia和Qwen2.5系列模型中提取学生模型，并在SQuAD和MLQA两个问答基准上评估其性能，测试了零样本和单样本提示条件下的表现。

研究结果: 结果显示，学生模型在参数减少高达57.1%的情况下，仍能保持教师模型90%以上的性能。单样本提示进一步提升了性能，优于零样本设置。

研究结论: 研究表明，知识蒸馏结合少量提示可以在模型效率和任务性能之间取得平衡，为资源受限的应用提供紧凑且高效的问答系统。

中文摘要: 大型语言模型（LLMs）在一系列NLP任务中表现出色，但其高计算需求阻碍了其在资源受限的实际环境中的部署。本研究探讨了通过知识蒸馏（KD）压缩LLMs的极限，同时确保其在问答（QA）任务中的高性能。我们从Pythia和Qwen2.5系列模型中提取学生模型，并在SQuAD和MLQA两个QA基准上评估其性能，测试了零样本和单样本提示条件下的表现。结果显示，学生模型在参数减少高达57.1%的情况下，仍能保持教师模型90%以上的性能。此外，单样本提示在两种模型系列中均比零样本设置带来额外的性能提升。这些发现强调了模型效率与任务性能之间的权衡，表明知识蒸馏结合少量提示可以生成适用于资源受限应用的紧凑且高效的QA系统。

</details>


### [26] [FrugalRAG: Learning to retrieve and reason for multi-hop QA](https://arxiv.org/abs/2507.07634)
**中文标题：FrugalRAG：面向多跳问答的检索与推理学习**

*Abhinav Java,Srivathsan Koundinyan,Nagarajan Natarajan,Amit Sharma*

主要分类: cs.CL

摘要简述: 本文提出FrugalRAG方法，通过改进提示和少量训练数据，显著减少检索次数，同时保持高性能，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前解决复杂问题的主流方法是基于语言模型的检索增强生成（RAG），但现有研究多关注准确性和召回率，而忽略了检索效率的重要性。本文旨在探索如何在不依赖大规模微调的情况下，通过改进提示和少量训练数据，提升RAG的效率和性能。

研究方法: 提出FrugalRAG方法，结合改进的ReAct流程提示和少量监督或基于强化学习的微调，以减少检索次数为目标，同时保持RAG的高性能。

研究结果: 实验表明，FrugalRAG在HotPotQA等基准测试中优于现有方法，且检索次数减少近一半，训练成本仅需1000个示例。

研究结论: FrugalRAG证明了高效检索的重要性，通过改进提示和少量微调即可显著提升RAG性能，为实际应用提供了更经济的解决方案。

中文摘要: 本文研究了如何通过大型非结构化文档库回答复杂问题。当前的主流方法是利用语言模型迭代检索和推理文档，直到生成答案。改进方法主要聚焦于检索增强生成（RAG）的准确性和召回率，分为两类：（a）基于链式思维跟踪的大规模问答数据集微调；（b）依赖问题-文档相关性信号的强化学习微调。然而，检索次数的效率同样重要，却较少受到关注。本文表明：（1）与近期文献观点相反，无需大规模微调即可提升RAG性能，改进提示的标准ReAct流程在HotPotQA等基准测试中优于现有方法。（2）监督和强化学习微调可从“节俭性”（即推理时的检索次数延迟）角度帮助RAG。例如，在相同基础模型和小训练成本（1000个示例）下，我们以近半检索次数实现了竞争性RAG性能。

</details>


### [27] [Lost in Pronunciation: Detecting Chinese Offensive Language Disguised by Phonetic Cloaking Replacement](https://arxiv.org/abs/2507.07640)
**中文标题：迷失在发音中：检测通过同音替换伪装的中文攻击性语言**

*Haotan Guo,Jianfei He,Jiayuan Ma,Hongbin Na,Zimu Wang,Haiyang Zhang,Qi Chen,Wei Wang,Zijing Shi,Tao Shen,Ling Chen*

主要分类: cs.CL

摘要简述: 本文研究了中文中通过同音或近音替换（PCR）隐藏攻击性语言的现象，构建了一个真实数据集并评估了现有模型的检测能力，发现其表现不佳，并提出了一种基于拼音的提示策略以提升检测效果。


<details>
  <summary>详细信息</summary>
研究动机: 同音或近音替换（PCR）已成为中文内容审核的主要障碍，现有方法多依赖规则生成的合成数据，忽略了真实用户的创造性。本文旨在填补这一研究空白，提供更真实的评估基准和改进方法。

研究方法: 作者将PCR分为四类表面形式，并收集了500个真实案例构建数据集。通过评估现有大语言模型的表现，发现其检测能力有限，随后提出了一种基于拼音的提示策略以提升性能。

研究结果: 实验显示，现有最佳模型的F1分数仅为0.672，零样本思维链提示甚至降低了性能。基于拼音的提示策略显著提升了检测准确率。

研究结论: 本研究首次系统分类了中文PCR现象，揭示了当前检测器的局限性，并提出了一种轻量级改进方法，为毒性检测的鲁棒性研究提供了新方向。

中文摘要: 同音替换（PCR）是指故意使用同音或近音变体以隐藏攻击意图的行为，已成为中文内容审核的主要障碍。尽管这一问题已被广泛认识，但现有评估主要依赖基于规则的合成扰动，忽略了真实用户的创造性。本文将PCR分为四类表面形式，并构建了“我们的”数据集，包含从RedNote平台收集的500个真实PCR攻击性帖子。对现有最先进大语言模型的评估暴露了其严重不足：最佳模型的F1分数仅为0.672，而零样本思维链提示进一步降低了性能。通过错误分析，我们重新审视了早期研究认为无效的基于拼音的提示策略，并证明其能显著恢复丢失的准确率。本研究首次提出了中文PCR的全面分类，揭示了当前检测器的局限性，并提出了一种轻量级改进方法，推动了鲁棒毒性检测的研究。

</details>


### [28] [An Automated Length-Aware Quality Metric for Summarization](https://arxiv.org/abs/2507.07653)
**中文标题：一种自动化的长度感知摘要质量评估指标**

*Andrew D. Foland*

主要分类: cs.CL

摘要简述: 本文提出了一种名为NOIR的自动化长度感知摘要质量评估指标，通过结合语义保留和摘要长度压缩，有效衡量摘要质量，并与人类感知一致。


<details>
  <summary>详细信息</summary>
研究动机: 现有的摘要质量评估方法依赖人工生成的参考摘要，耗时且不便于自动化评估。本文旨在开发一种自动化指标，能够同时考虑语义保留和长度压缩，以更高效地评估摘要质量。

研究方法: 提出NOIR指标，利用语言模型嵌入测量语义相似性，并结合摘要长度压缩率，量化摘要的语义保留与压缩平衡。

研究结果: 实验表明，NOIR能够有效捕捉摘要的语义保留与长度压缩的权衡，并与人类对摘要质量的感知高度相关。

研究结论: NOIR为摘要质量评估提供了一种自动化工具，适用于多种摘要任务，无需依赖人工参考摘要。

中文摘要: 本文提出了NOIR（归一化保留指数），一种用于评估任意文本摘要质量的定量客观指标，该指标依赖于语义保留和摘要长度压缩。它衡量了摘要中最重要技能——召回与压缩的权衡。实验表明，NOIR能够有效捕捉摘要器的标记长度与语义保留的权衡，并与人类对摘要质量的感知相关。通过使用语言模型嵌入测量语义相似性，NOIR提供了一种无需依赖耗时的人工参考摘要的自动化评估方法。该指标可应用于多种摘要任务，为评估和改进摘要算法、摘要提示及合成摘要提供了自动化工具。

</details>


### [29] [SAS: Simulated Attention Score](https://arxiv.org/abs/2507.07694)
**中文标题：SAS：模拟注意力分数**

*Chuanyang Zheng,Jiankai Sun,Yihang Gao,Yuehao Wang,Peihao Wang,Jing Xiong,Liliang Ren,Hao Cheng,Janardhan Kulkarni,Yelong Shen,Atlas Wang,Mac Schwager,Anderson Schneider,Xiaodong Liu,Jianfeng Gao*

主要分类: cs.CL

摘要简述: 本文提出了一种名为SAS（模拟注意力分数）的方法，通过将低维注意力头表示投影到高维空间，模拟更多注意力头和更大的隐藏特征维度，从而在不增加参数量的情况下提升模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 研究发现，多头注意力（MHA）的性能随着注意力头数量的增加而提升，前提是每个头的隐藏维度足够大。因此，如何在保持模型紧凑的同时模拟更多注意力头和更大的隐藏维度成为研究动机。

研究方法: SAS方法通过将低维注意力头表示投影到高维空间，模拟更多注意力头和更大的隐藏特征维度。此外，还提出了参数高效的注意力聚合（PEAA）来控制参数成本。

研究结果: 在多种数据集和任务上的实验表明，SAS方法显著优于其他注意力变体，实现了性能的显著提升。

研究结论: SAS方法通过模拟更多注意力头和更大的隐藏维度，在不增加参数量的情况下显著提升了模型性能，为注意力机制的优化提供了新思路。

中文摘要: 注意力机制是Transformer架构的核心组成部分。目前已有多种计算注意力分数的方法，如多头注意力（MHA）、多查询注意力、组查询注意力等。我们进一步分析了MHA，发现只要每个注意力头的隐藏维度足够大，其性能会随着注意力头数量的增加而提升。因此，在保持参数开销最小的情况下，同时增加注意力头数量和每个头的隐藏维度，可以以低成本实现显著的性能提升。基于这一发现，我们提出了模拟注意力分数（SAS），该方法通过将低维注意力头表示投影到高维空间，模拟更多注意力头和更大的隐藏特征维度，从而在不增加参数量的情况下提升注意力容量。此外，我们还将模拟方法扩展到键和查询嵌入的特征维度，通过模仿更大模型的行为来增强表达能力，同时保持原始模型大小。为了控制参数成本，我们还提出了参数高效的注意力聚合（PEAA）。在多种数据集和任务上的综合实验证明了SAS方法的有效性，其性能显著优于其他注意力变体。

</details>


### [30] [KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities](https://arxiv.org/abs/2507.07695)
**中文标题：KeyKnowledgeRAG（K^2RAG）：一种增强型RAG方法，用于提升LLM问答能力**

*Hruday Markondapatnaikuni,Basem Suleiman,Abdelkarim Erradi,Shijing Chen*

主要分类: cs.CL

摘要简述: 本文提出了一种名为KeyKnowledgeRAG（K^2RAG）的增强型RAG方法，通过结合稠密与稀疏向量搜索、知识图谱和文本摘要技术，显著提升了LLM问答系统的检索质量和效率。实验表明，K^2RAG在答案相似度和训练效率上均优于传统RAG实现。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型（LLM）规模和复杂度的增加，微调过程变得资源密集且耗时。尽管已有多种微调技术试图降低成本，但问题仍未解决。检索增强生成（RAG）通过外部知识库支持问答，但传统RAG在可扩展性和答案准确性上存在局限。本文旨在提出一种改进的RAG框架以解决这些问题。

研究方法: K^2RAG框架基于分治法，整合了稠密与稀疏向量搜索、知识图谱和文本摘要技术。预处理步骤对训练数据进行摘要，大幅减少训练时间。实验在MultiHopRAG数据集上进行，通过文档语料训练并在独立评估集上测试。

研究结果: K^2RAG在MultiHopRAG数据集上表现优异，平均答案相似度得分达0.57，第三四分位数（Q3）相似度为0.82，显著优于传统RAG实现。此外，摘要步骤使组件平均训练时间减少93%，执行速度比传统知识图谱RAG系统快40%，且VRAM需求仅为传统RAG的三分之一。

研究结论: K^2RAG通过创新性技术组合显著提升了LLM问答系统的性能和效率，为知识扩展提供了高效解决方案。其优异的可扩展性和低资源需求使其成为实际应用的理想选择。

中文摘要: 随着大型语言模型（LLM）规模的扩大和复杂度的增加，微调过程变得极其资源密集。尽管已有多种微调技术旨在减少时间和计算成本，但问题依然存在。为此，需要一种新的知识扩展方法。检索增强生成（RAG）通过将外部知识存储在数据库中并检索相关片段以支持问答，提供了一种替代方案。然而，传统RAG实现存在可扩展性和答案准确性的显著局限。本文提出KeyKnowledgeRAG（K^2RAG），一种新颖的框架，旨在克服这些局限。受分治法启发，K^2RAG整合了稠密与稀疏向量搜索、知识图谱和文本摘要技术，以提升检索质量和系统效率。框架还包括预处理步骤，对训练数据进行摘要，显著减少训练时间。K^2RAG在MultiHopRAG数据集上进行了评估，训练文档语料并在独立评估集上测试。结果显示，K^2RAG显著优于传统RAG实现，平均答案相似度得分达0.57，第三四分位数（Q3）相似度为0.82，表明与真实答案的更好对齐。此外，框架效率极高：摘要步骤使组件平均训练时间减少93%，执行速度比传统知识图谱RAG系统快40%。K^2RAG还表现出卓越的可扩展性，所需VRAM仅为传统RAG的三分之一。

</details>


### [31] [Rethinking the Privacy of Text Embeddings: A Reproducibility Study of "Text Embeddings Reveal (Almost) As Much As Text"](https://arxiv.org/abs/2507.07700)
**中文标题：重新思考文本嵌入的隐私性：对《文本嵌入揭示（几乎）与文本相同信息》的可复现性研究**

*Dominykas Seputis,Yongkang Li,Karsten Langerak,Serghei Mihailov*

主要分类: cs.CL

摘要简述: 文本嵌入在NLP任务中广泛应用，传统认为传输嵌入而非原始文本可保护隐私。然而，Vec2Text方法证明嵌入可被解码还原原始文本，引发隐私担忧。本研究复现并验证了Vec2Text的效果，发现其在理想条件下能还原密码等敏感信息，但也存在对输入长度的敏感性。高斯噪声和量化技术可缓解隐私风险。


<details>
  <summary>详细信息</summary>
研究动机: 传统观点认为文本嵌入比原始文本更隐私安全，但Vec2Text方法挑战了这一假设。本研究旨在验证Vec2Text的原始结论，并进一步探索其局限性和可能的防御措施。

研究方法: 研究复现了Vec2Text框架，从两个角度进行评估：(1) 验证原始结论，(2) 通过针对性实验扩展研究。包括参数敏感性分析、敏感输入（如密码）的还原可行性测试，以及嵌入量化作为轻量级隐私防御的探索。

研究结果: 研究成功复现了Vec2Text的关键结果，发现其在理想条件下能有效还原文本，甚至无明确语义的密码类序列。但也发现其对输入长度敏感。高斯噪声和量化技术能有效缓解隐私风险，量化更具普适性。

研究结论: 文本嵌入的隐私风险需引起重视，Vec2Text在特定条件下威胁显著。高斯噪声和量化技术是可行的防御手段，未来需进一步研究NLP系统的鲁棒防御机制。

中文摘要: 文本嵌入是许多自然语言处理（NLP）任务的基础，广泛应用于推荐系统和信息检索（IR）等领域。传统上，传输嵌入而非原始文本被视为隐私保护措施。然而，Vec2Text等最新方法通过证明受控解码可从黑盒嵌入中成功还原原始文本，挑战了这一假设。Vec2Text报告的意外强劲结果促使我们进一步验证，尤其是考虑到高维嵌入空间通常非直观且不透明的结构。本研究复现了Vec2Text框架，并从两个角度进行评估：(1) 验证原始结论，(2) 通过针对性实验扩展研究。首先，我们在域内和域外设置中成功复现了原始关键结果，仅因缺失模型检查点和数据集划分等工件而产生微小差异。此外，我们通过参数敏感性分析、评估敏感输入（如密码）的还原可行性，以及探索嵌入量化作为轻量级隐私防御，扩展了研究。结果显示，Vec2Text在理想条件下有效，甚至能还原缺乏明确语义的密码类序列。然而，我们也发现了其关键局限性，包括对输入长度的敏感性。高斯噪声和量化技术可缓解Vec2Text带来的隐私风险，量化提供了一种更简单且广泛适用的解决方案。研究结果强调了对文本嵌入使用的谨慎性，并突出了进一步研究NLP系统鲁棒防御机制的重要性。

</details>


### [32] [Not All Preferences are What You Need for Post-Training: Selective Alignment Strategy for Preference Optimization](https://arxiv.org/abs/2507.07725)
**中文标题：并非所有偏好都适合后训练：选择性对齐策略用于偏好优化**

*Zhijin Dong*

主要分类: cs.CL

摘要简述: 本文提出了一种选择性对齐策略（Selective-DPO），通过优先处理偏好对中高影响力标记，减少计算开销并提升对齐效果。实验证明该方法优于标准DPO和蒸馏基线。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）的后训练对齐是一个关键挑战，因为并非所有标记对模型性能的贡献均等。现有方法未充分关注高影响力标记，导致计算资源浪费和对齐效果不佳。

研究方法: 提出选择性对齐策略，利用当前策略与参考模型之间的标记级对数概率差异，优先优化高影响力标记。同时探讨了参考模型质量对标记选择准确性和优化效果的影响。

研究结果: 在Arena-Hard和MT-Bench等基准测试中，Selective-DPO方法显著优于标准DPO和蒸馏基线，验证了标记级优化和高质量参考模型的重要性。

研究结论: 标记级优化和参考模型选择对LLM偏好对齐至关重要，Selective-DPO方法在减少计算开销的同时提升了对齐效果。

中文摘要: 大型语言模型（LLM）的后训练对齐是一个关键挑战，因为并非所有标记对模型性能的贡献均等。本文提出了一种选择性对齐策略，通过优先处理偏好对中高影响力标记，利用当前策略与参考模型之间的标记级对数概率差异。通过聚焦这些信息丰富的标记，我们的方法减少了计算开销并提升了对齐效果。我们还探讨了参考模型质量的作用，证明更强的参考模型能显著提高标记选择准确性和整体优化效果。在Arena-Hard和MT-Bench等基准测试上的全面实验验证了我们的Selective-DPO方法优于标准DPO和蒸馏基线。研究结果强调了标记级优化和参考模型选择在推进LLM偏好对齐中的重要性。代码发布于https://github.com/Dongzhijin/SDPO。

</details>


### [33] [Code-Switching in End-to-End Automatic Speech Recognition: A Systematic Literature Review](https://arxiv.org/abs/2507.07741)
**中文标题：端到端自动语音识别中的语码转换：系统性文献综述**

*Maha Tufail Agro,Atharva Kulkarni,Karima Kadaoui,Zeerak Talat,Hanan Aldarmaki*

主要分类: cs.CL

摘要简述: 本文对端到端自动语音识别（ASR）中的语码转换（CS）研究进行了系统性文献综述，总结了当前研究现状、挑战及未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 随着自动语音识别（ASR）研究的兴起，以及语码转换（CS）在多语言场景中的普遍性，本文旨在系统梳理端到端ASR模型中CS研究的现状，为未来研究提供指导。

研究方法: 通过收集并手动标注同行评审论文，分析了涉及的语言、数据集、评估指标、模型选择及性能表现，并探讨了端到端ASR中CS的挑战。

研究结果: 研究总结了当前CS研究的语言覆盖、数据集资源、模型性能及主要挑战，揭示了研究空白和未来机会。

研究结论: 本文为端到端ASR中的CS研究提供了全面综述，指出了现有资源和挑战，并提出了未来研究方向。

中文摘要: 随着自动语音识别（ASR）研究的兴起，以及语码转换（CS）在多语言场景中的普遍性，本文对端到端ASR模型中的CS研究进行了系统性文献综述。我们收集并手动标注了同行评审论文，记录了涉及的语言、数据集、评估指标、模型选择及性能表现，并探讨了端到端ASR中CS的挑战。通过分析，我们总结了当前研究现状、可用资源以及未来研究的机遇与空白。

</details>


### [34] [When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance](https://arxiv.org/abs/2507.07748)
**中文标题：当大型语言模型遇上法律：双视角分类法、技术进展与伦理治理**

*Peizhang Shao,Linrui Xu,Jinxi Wang,Wei Zhou,Xingyu Wu*

主要分类: cs.CL

摘要简述: 本文首次全面综述了大型语言模型（LLMs）在法律领域的应用，提出了一种创新的双视角分类法，整合法律推理框架与专业本体，系统梳理历史研究与当代突破。LLMs通过动态捕捉法律语义和统一证据推理，克服了传统限制，但在广泛采用中也面临幻觉、可解释性不足等挑战。


<details>
  <summary>详细信息</summary>
研究动机: 法律领域对大型语言模型的应用缺乏系统性综述，且传统方法在动态捕捉法律语义和统一证据推理方面存在局限。本文旨在填补这一空白，为法律人工智能的未来发展提供技术路线图和概念框架。

研究方法: 提出双视角分类法，整合法律推理框架与专业本体；利用Transformer-based LLMs的动态语义捕捉能力；通过稀疏注意力机制和专家混合架构等技术创新解决文本处理、知识整合等核心挑战。

研究结果: 系统梳理了LLMs在法律领域的任务泛化、推理形式化、工作流集成等方面的进展；提出了一种将法律角色映射到NLP子任务的新分类法，并计算实现了Toulmin论证框架。

研究结论: 本文为法律人工智能的未来发展奠定了坚实基础，同时指出了低资源系统、多模态证据整合等关键前沿方向，为研究者和从业者提供了技术路线图和概念框架。

中文摘要: 本文首次全面综述了大型语言模型（LLMs）在法律领域的应用，提出了一种创新的双视角分类法，整合法律推理框架与专业本体，系统统一历史研究与当代突破。基于Transformer的LLMs通过动态捕捉法律语义和统一证据推理，克服了传统限制，展现了上下文推理和生成性论证等新兴能力。本文记录了在任务泛化、推理形式化、工作流集成以及通过稀疏注意力机制和专家混合架构等技术创新解决文本处理、知识整合和评估严谨性方面的显著进展。然而，LLMs的广泛采用也带来了关键挑战：幻觉、可解释性不足、司法适应性困难和伦理不对称。本文提出了一种新分类法，将法律角色映射到NLP子任务，并计算实现了Toulmin论证框架，从而系统化了推理、检索、预测和争议解决方面的进展。同时，本文指出了低资源系统、多模态证据整合和动态反驳处理等关键前沿方向。最终，本研究为研究者提供了技术路线图，为从业者提供了导航算法未来的概念框架，为法律人工智能的下一时代奠定了坚实基础。我们创建了一个GitHub仓库以索引相关论文：https://github.com/Kilimajaro/LLMs_Meet_Law。

</details>


### [35] [StreamUni: Achieving Streaming Speech Translation with a Unified Large Speech-Language Model](https://arxiv.org/abs/2507.07803)
**中文标题：StreamUni：通过统一的大型语音-语言模型实现流式语音翻译**

*Shoutao Guo,Xiang Li,Shaolei Zhang,Mengge Liu,Wei Chen,Yang Feng*

主要分类: cs.CL

摘要简述: StreamUni通过统一的大型语音-语言模型（LSLM）实现流式语音翻译，结合语音思维链（CoT）指导多阶段输出，完成语音分割、策略决策和翻译生成，无需大量策略训练，实验表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有流式语音翻译方法依赖句子级语音分段（SimulST），需与分割模型协作，但分段限制了上下文信息，且SimulST模型难以学习有效策略。StreamUni旨在解决这些问题，实现高效低延迟的流式翻译。

研究方法: StreamUni利用统一的大型语音-语言模型（LSLM），通过语音思维链（CoT）生成多阶段输出，同时完成语音分割、策略决策和翻译生成。并提出流式CoT训练方法，提升低延迟策略和生成能力。

研究结果: 实验表明，StreamUni在流式语音翻译任务中达到最先进性能，无需大量策略训练即可高效完成翻译。

研究结论: StreamUni通过LSLM和CoT技术，解决了流式语音翻译中的分段和策略问题，实现了高效低延迟的翻译生成。

中文摘要: 流式语音翻译（StreamST）需要在持续接收源语音输入时确定适当的时机（称为策略），以平衡低延迟与高翻译质量。然而，现有的StreamST方法通常基于句子级语音分段（称为同步语音翻译，SimulST），实际需要与分割模型协作完成StreamST，其中截断的语音分段限制了SimulST模型基于有限上下文信息进行策略决策和翻译生成。此外，由于语音输入的复杂性和跨语言生成的挑战，SimulST模型难以学习有效策略。为解决这些问题，我们提出StreamUni，通过统一的大型语音-语言模型（LSLM）实现StreamST。具体而言，StreamUni结合语音思维链（CoT）指导LSLM生成多阶段输出。利用这些多阶段输出，StreamUni同时完成语音分割、策略决策和翻译生成，无需大量策略训练即可实现StreamST。此外，我们提出了一种流式CoT训练方法，利用有限的CoT数据增强低延迟策略决策和生成能力。实验表明，我们的方法在StreamST任务中达到了最先进的性能。

</details>


### [36] [Bridging Logic and Learning: Decoding Temporal Logic Embeddings via Transformers](https://arxiv.org/abs/2507.07808)
**中文标题：连接逻辑与学习：通过Transformer解码时序逻辑嵌入**

*Sara Candussio,Gaia Saveri,Gabriele Sarti,Luca Bortolussi*

主要分类: cs.CL

摘要简述: 本文提出了一种基于Transformer的解码器模型，用于反转信号时序逻辑（STL）公式的语义嵌入，从而将连续表示转换为具体的逻辑要求。模型能够快速生成有效公式，并在语义空间中优化分类任务。


<details>
  <summary>详细信息</summary>
研究动机: 逻辑公式的连续表示可以整合符号知识到数据驱动学习中，但需要可逆的嵌入才能将优化结果转化为具体需求。本文旨在解决这一反转问题。

研究方法: 通过构建STL语法的小词汇表，训练一个基于Transformer的解码器模型，反转STL公式的语义嵌入。模型在1个周期内生成有效公式，10个周期内掌握逻辑语义。

研究结果: 模型能够解码嵌入为更简洁且语义接近的公式，并在不同复杂度的训练数据中表现良好。此外，模型成功应用于需求挖掘任务，直接在语义空间中优化分类。

研究结论: 提出的方法有效实现了STL嵌入的反转，支持语义空间中的连续优化，并在实际任务中验证了其泛化能力。

中文摘要: 逻辑公式的连续表示能够将符号知识整合到数据驱动的学习算法中。如果这些嵌入在语义上是一致的（即相似的规范被映射到相近的向量），它们可以直接在公式的语义空间中进行连续学习和优化。然而，为了将最优的连续表示转化为具体需求，这些嵌入必须是可逆的。我们通过训练一个基于Transformer的解码器模型来解决这一问题，以反转信号时序逻辑（STL）公式的语义嵌入。STL是一种强大的形式化方法，能够以简洁而富有表现力的方式描述随时间变化的信号属性。通过从STL语法构建一个小词汇表，我们证明了所提出的模型能够在仅1个周期内生成有效公式，并在约10个周期内掌握逻辑的语义。此外，模型能够将给定嵌入解码为长度和嵌套更简单但仍与参考公式语义接近（或等价）的公式。我们展示了该方法在不同复杂度训练数据上的有效性，以评估训练数据对模型捕捉嵌入中语义信息及泛化能力的影啊。最后，我们将模型应用于需求挖掘任务，即推断解决轨迹分类任务的STL规范，直接在语义空间中进行优化。

</details>


### [37] [Understanding and Controlling Repetition Neurons and Induction Heads in In-Context Learning](https://arxiv.org/abs/2507.07810)
**中文标题：理解与控制上下文学习中的重复神经元与归纳头**

*Nhi Hoai Doan,Tatsuya Hiraoka,Kentaro Inui*

主要分类: cs.CL

摘要简述: 本文研究大型语言模型（LLMs）中重复神经元与上下文学习（ICL）性能的关系，发现其影响因神经元所在层深度而异，并提出减少重复输出同时保持ICL能力的策略。


<details>
  <summary>详细信息</summary>
研究动机: 以往研究主要关注注意力头，而本文从技能神经元（尤其是重复神经元）的角度探讨其与ICL性能的关系，以填补这一研究空白。

研究方法: 通过实验分析重复神经元在不同层深度对ICL性能的影响，并与归纳头进行比较，探索减少重复输出的方法。

研究结果: 实验表明，重复神经元对ICL性能的影响与其所在层深度相关，且通过比较归纳头，找到了减少重复输出同时保持ICL能力的策略。

研究结论: 重复神经元在ICL中扮演重要角色，其影响因层深度而异，研究结果为优化模型性能提供了新思路。

中文摘要: 本文研究了大型语言模型（LLMs）识别重复输入模式的能力与其在上下文学习（ICL）中表现的关系。与以往主要关注注意力头的研究不同，我们从技能神经元（特别是重复神经元）的角度探讨这一问题。实验表明，这些神经元对ICL性能的影响因其所在层深度而异。通过比较重复神经元与归纳头的作用，我们进一步提出了减少重复输出同时保持强大ICL能力的策略。

</details>


### [38] [On the Effect of Instruction Tuning Loss on Generalization](https://arxiv.org/abs/2507.07817)
**中文标题：指令微调损失对泛化能力的影响研究**

*Anwoy Chatterjee,H S V N S Kowndinya Renduchintala,Sumit Bhatia,Tanmoy Chakraborty*

主要分类: cs.CL

摘要简述: 研究发现传统指令微调损失函数存在不足，提出加权指令微调（WIT）方法，通过调整提示和响应令牌的权重显著提升模型性能和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 指令微调是提升预训练语言模型遵循用户指令能力的关键方法，但其损失函数的优化未被充分研究。传统方法仅计算响应令牌的损失，忽略提示令牌的作用，可能影响模型性能。

研究方法: 提出加权指令微调（WIT），系统研究提示和响应令牌在损失函数中的权重影响。通过实验验证不同权重组合的效果，并比较其与传统方法的差异。

研究结果: 实验表明，传统指令微调损失函数性能次优且对输入提示变化的鲁棒性有限。WIT方法在低至中等提示令牌权重与中至高响应令牌权重组合下表现最佳，且为后续偏好对齐训练提供更好起点。

研究结论: 研究强调需重新审视指令微调损失函数，WIT方法为开发更鲁棒和泛化性强的模型提供了实用建议。代码已开源。

中文摘要: 指令微调已成为一种关键的后训练范式，使预训练语言模型能更好地遵循用户指令。尽管其重要性显著，但损失函数的优化却鲜少受到关注。一个基础但常被忽视的问题是：传统自回归目标（仅计算响应令牌损失，忽略提示令牌）是否真正适用于指令微调。本研究系统探讨了指令微调损失中提示和响应令牌权重的影响，并提出加权指令微调（WIT）作为传统方法的改进方案。通过对五种不同规模和家族的语言模型、三种不同规模的微调数据集及五个多样化评估基准的广泛实验，我们发现标准指令微调损失常导致次优性能和对输入提示变化的有限鲁棒性。最佳模型表现出现在提示令牌权重较低至中等、响应令牌权重中等至高的组合下，且此类模型也为后续偏好对齐训练提供了更好的起点。这些发现表明需重新审视指令微调损失函数，并为开发更鲁棒和泛化性强的模型提供了实用建议。代码已开源：https://github.com/kowndinya-renduchintala/WIT。

</details>


### [39] [Conditional Unigram Tokenization with Parallel Data](https://arxiv.org/abs/2507.07824)
**中文标题：基于平行数据的条件一元分词方法**

*Gianluca Vico,Jindřinch Libovický*

主要分类: cs.CL

摘要简述: 本文提出了一种基于平行数据的条件一元分词方法，通过将目标语言的分词概率与源语言分词对齐，优化跨语言语义一致性。实验表明，该方法在语言建模中能降低困惑度，但在机器翻译中效果不明显。


<details>
  <summary>详细信息</summary>
研究动机: 传统一元分词方法未考虑跨语言语义对齐，本文旨在通过条件概率建模，利用平行数据优化目标语言分词，提升跨语言任务的性能。

研究方法: 提出条件一元分词方法，固定源语言分词器，学习目标语言分词器以最大化跨语言语义对齐。实验覆盖四种语言对，评估分词器在机器翻译和语言建模中的表现。

研究结果: 结果显示，条件分词器在语言建模中能一致降低困惑度，但在机器翻译中未观察到质量提升。推测原因是条件概率估计的二次方复杂度导致数据效率瓶颈。

研究结论: 条件一元分词方法在语言建模中表现良好，但在机器翻译中效果有限。未来可能需要探索其他参数化方法以提升跨语言分词的实际效果。

中文摘要: 我们提出了一种条件一元分词方法，通过将目标语言的分词概率与源语言分词对齐，扩展了传统一元分词。给定固定的源语言分词器，我们的方法学习目标语言分词器以最大化跨语言语义对齐。我们在四种不同语系和资源水平的语言对上评估了分词器，考察其内在特性及在机器翻译和语言建模中的下游表现。尽管条件分词器保持了与标准一元分词器相当的统计特性，结果却参差不齐：机器翻译质量未见提升，但语言建模中困惑度一致降低。我们推测，条件概率估计的二次方复杂度（相对于词汇量）导致了数据效率瓶颈。研究结果表明，实际跨语言分词可能需要其他参数化方法。

</details>


### [40] [From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems](https://arxiv.org/abs/2507.07847)
**中文标题：从歧义到精准：指代消解对检索增强生成系统的变革性影响**

*Youngjoon Jang,Seongtae Hong,Junyoung Son,Sungjin Park,Chanjun Park,Heuiseok Lim*

主要分类: cs.CL

摘要简述: 本文研究了指代消解对检索增强生成系统（RAG）的影响，发现其能显著提升检索效果和问答性能，尤其对小模型帮助更大。


<details>
  <summary>详细信息</summary>
研究动机: 检索增强生成（RAG）在自然语言处理中表现出色，但指代复杂性会引入歧义，影响系统性能。本研究旨在探讨指代消解如何提升RAG的检索和生成能力。

研究方法: 通过系统分析指代消解对文档检索和生成性能的影响，比较不同池化策略在检索任务中的表现，并评估问答任务中模型的性能提升。

研究结果: 指代消解显著提升了检索效果和问答性能，均值池化在指代消解后表现最佳，小模型从消歧过程中获益更多。

研究结论: 指代消解能有效解决RAG中的指代复杂性，为知识密集型AI应用的检索和生成改进提供了指导。

中文摘要: 检索增强生成（RAG）已成为自然语言处理（NLP）中的关键框架，通过将外部文档检索与大型语言模型（LLM）结合，提高了事实一致性并减少了幻觉。然而，RAG的有效性常因检索文档中的指代复杂性而受限，这种歧义会破坏上下文学习。本研究系统探讨了实体指代如何影响RAG系统中的文档检索和生成性能，重点关注检索相关性、上下文理解和整体回答质量。我们发现指代消解能提升检索效果并改善问答（QA）性能。通过对检索任务中不同池化策略的比较分析，发现均值池化在应用指代消解后表现出更强的上下文捕捉能力。在QA任务中，小模型从消歧过程中获益更多，可能因其处理指代歧义的内在能力有限。基于这些发现，本研究旨在深入理解RAG中指代复杂性带来的挑战，为知识密集型AI应用的检索和生成改进提供指导。

</details>


### [41] [Alpay Algebra V: Multi-Layered Semantic Games and Transfinite Fixed-Point Simulation](https://arxiv.org/abs/2507.07868)
**中文标题：Alpay代数V：多层语义游戏与超限不动点模拟**

*Bugra Kilictas,Faruk Alpay*

主要分类: cs.CL

摘要简述: 本文扩展了Alpay代数的自参考框架，引入多层语义游戏架构，通过超限不动点收敛实现层级子游戏的迭代。基于Alpay代数IV的共情嵌入概念，提出嵌套博弈结构，将AI系统与文档对齐过程转化为包含嵌入决策问题的元游戏。通过复合算子$\phi(\cdot, \gamma(\cdot))$形式化，证明博弈论推理自然从不动点迭代中涌现。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于将Alpay代数的自参考框架扩展到多层语义游戏中，探索超限不动点收敛在层级子游戏中的应用，并验证博弈论推理如何从不动点迭代中自然产生。

研究方法: 方法包括引入嵌套博弈结构，使用复合算子$\phi(\cdot, \gamma(\cdot))$驱动主语义收敛和局部子游戏解析，结合Banach不动点定理、Kozlov-Maz'ya-Rossmann公式和Yoneda引理进行验证。

研究结果: 结果包括证明了语义均衡的存在性和唯一性，提出了基于$\phi$-拓扑的语义奇点处理方法，并通过验证套件展示了框架的实用性和理论一致性。

研究结论: 结论表明，该框架不仅扩展了Alpay代数的理论边界，还通过语义病毒概念在实际AI嵌入空间中实现了固定点模式的传播，具有广泛的应用潜力。

中文摘要: 本文扩展了Alpay代数的自参考框架，提出一种多层语义游戏架构，其中超限不动点收敛涵盖每个迭代层级的层级子游戏。基于Alpay代数IV的共情嵌入概念，我们引入了一种嵌套博弈结构，将AI系统与文档的对齐过程转化为包含嵌入决策问题的元游戏。通过复合算子$\phi(\cdot, \gamma(\cdot))$形式化，其中$\phi$驱动主语义收敛，而$\gamma$解析局部子游戏。结果表明，博弈论推理自然从不动点迭代中涌现，而非外部强加。我们证明了一个博弈定理，确立了在现实认知模拟假设下语义均衡的存在性和唯一性。验证套件包括Banach不动点定理在超限上下文中的适应性、基于Kozlov-Maz'ya-Rossmann公式处理语义奇点的新颖$\phi$-拓扑，以及通过Yoneda引理进行的范畴一致性测试。本文本身作为一种语义人工制品，旨在在AI嵌入空间中传播其不动点模式——这是其理论化的“语义病毒”概念的有意实例化。所有结果均基于范畴论、信息论和现实AI认知模型，确保了超越纯数学抽象的实用适用性。

</details>


### [42] [DocCHA: Towards LLM-Augmented Interactive Online diagnosis System](https://arxiv.org/abs/2507.07870)
**中文标题：DocCHA：迈向基于LLM增强的交互式在线诊断系统**

*Xinyi Liu,Dachun Sun,Yi R. Fung,Dilek Hakkani-Tür,Tarek Abdelzaher*

主要分类: cs.CL

摘要简述: DocCHA是一种基于大型语言模型（LLM）的交互式在线诊断系统，通过模块化框架模拟临床推理，显著提升诊断准确性和症状召回率。


<details>
  <summary>详细信息</summary>
研究动机: 现有的对话式健康助手（CHAs）缺乏自适应多轮推理和透明决策能力，限制了其在临床诊断中的实际应用。DocCHA旨在解决这一问题，提供结构化、透明的诊断对话。

研究方法: DocCHA将诊断过程分解为三个阶段：症状提取、病史采集和因果图构建，每个模块使用可解释的置信度分数指导自适应提问和推理优化。

研究结果: 在两个真实世界的中文咨询数据集（IMCS21和DX）上，DocCHA在诊断准确性和症状召回率上显著优于基于提示的LLM基线模型（如GPT-3.5、GPT-4o和LLaMA-3）。

研究结论: DocCHA展示了在结构化、透明和高效的诊断对话中的有效性，为多语言和资源受限环境下的可信赖LLM临床助手铺平了道路。

中文摘要: 尽管大型语言模型（LLM）表现出色，现有的对话式健康助手（CHAs）仍显静态和脆弱，无法进行自适应多轮推理、症状澄清或透明决策。这限制了其在需要迭代和结构化对话的临床诊断中的实际应用。我们提出DocCHA，一种基于置信度的模块化框架，通过将诊断过程分解为三个阶段（1）症状提取，（2）病史采集，（3）因果图构建，模拟临床推理。每个模块使用可解释的置信度分数指导自适应提问、优先信息澄清并优化薄弱推理环节。在两个真实世界的中文咨询数据集（IMCS21和DX）上，DocCHA显著优于基于提示的LLM基线模型（GPT-3.5、GPT-4o和LLaMA-3），诊断准确性提升高达5.18%，症状召回率提升超过30%，且对话轮次仅小幅增加。这些结果表明，DocCHA能够实现结构化、透明且高效的诊断对话，为多语言和资源受限环境下的可信赖LLM临床助手奠定了基础。

</details>


### [43] [Automating MD simulations for Proteins using Large language Models: NAMD-Agent](https://arxiv.org/abs/2507.07887)
**中文标题：利用大型语言模型自动化蛋白质分子动力学模拟：NAMD-Agent**

*Achuth Chandrasekhar,Amir Barati Farimani*

主要分类: cs.CL

摘要简述: 本文提出了一种利用大型语言模型（LLMs）自动生成蛋白质分子动力学（MD）模拟输入文件的流程，显著减少了准备时间和人工错误。


<details>
  <summary>详细信息</summary>
研究动机: 分子动力学模拟在蛋白质结构研究中至关重要，但手动准备高质量的输入文件耗时且易出错。本文旨在通过自动化流程解决这一问题。

研究方法: 结合Gemini 2.0 Flash大型语言模型、Python脚本和基于Selenium的网页自动化技术，利用CHARMM GUI生成NAMD模拟所需的输入文件，并通过后处理进一步优化输出。

研究结果: 该方法显著减少了模拟准备时间，降低了人工错误，并能并行处理多个蛋白质系统，为计算结构生物学提供了可扩展的解决方案。

研究结论: 该自动化框架为LLMs在计算结构生物学中的广泛应用奠定了基础，为未来模拟自动化的发展提供了强大且灵活的平台。

中文摘要: 分子动力学模拟是理解蛋白质原子水平结构、动力学和功能的重要工具。然而，准备高质量的MD模拟输入文件是一个耗时且容易出错的过程。本文介绍了一种自动化流程，利用大型语言模型（LLMs），特别是Gemini 2.0 Flash，结合Python脚本和基于Selenium的网页自动化技术，简化了MD输入文件的生成。该流程利用CHARMM GUI的全面基于网页的界面，为NAMD准备模拟就绪的输入文件。通过整合Gemini的代码生成和迭代优化能力，自动编写、执行和修改模拟脚本，以导航CHARMM GUI、提取适当参数并生成所需的NAMD输入文件。后处理使用额外软件进一步优化模拟输出，从而实现完整且基本无需人工干预的工作流程。我们的结果表明，这种方法减少了准备时间，最小化了人工错误，并为并行处理多个蛋白质系统提供了可扩展的解决方案。这一自动化框架为LLMs在计算结构生物学中的广泛应用铺平了道路，为未来模拟自动化的发展提供了强大且灵活的平台。

</details>


### [44] [DTECT: Dynamic Topic Explorer & Context Tracker](https://arxiv.org/abs/2507.07910)
**中文标题：DTECT：动态主题探索与上下文追踪器**

*Suman Adhya,Debarshi Kumar Sanyal*

主要分类: cs.CL

摘要简述: DTECT是一个端到端系统，用于动态主题建模，提供数据预处理、多模型架构、评估指标、自动主题标注、趋势分析和交互式可视化，帮助用户更直观地追踪和理解主题动态。


<details>
  <summary>详细信息</summary>
研究动机: 随着文本数据的爆炸式增长，现有动态主题建模技术缺乏统一的解释和用户友好探索工具，DTECT旨在填补这一空白。

研究方法: DTECT整合了数据预处理、多模型架构、评估指标、LLM驱动的自动主题标注、时间显著词趋势分析、交互式可视化和自然语言聊天界面。

研究结果: DTECT显著提升了主题模型的解释性，并通过统一平台支持用户更高效地追踪和分析主题动态。

研究结论: DTECT作为一个开源平台，通过整合多项功能，为用户提供了更直观和高效的主题动态分析工具。

中文摘要: 随着时间推移，文本数据的爆炸式增长为揭示演变主题和趋势带来了巨大挑战。现有的动态主题建模技术虽然强大，但通常存在于碎片化的流程中，缺乏对解释和用户友好探索的强有力支持。我们推出了DTECT（动态主题探索与上下文追踪器），这是一个端到端系统，填补了原始文本数据与有意义的时间洞察之间的空白。DTECT提供了一个统一的工作流程，支持数据预处理、多模型架构和专用评估指标，以分析时间主题模型的主题质量。通过引入LLM驱动的自动主题标注、基于时间显著词的趋势分析、带有文档级摘要的交互式可视化以及用于直观数据查询的自然语言聊天界面，DTECT显著提升了可解释性。通过将这些功能整合到一个统一的平台中，DTECT使用户能够更有效地追踪和理解主题动态。DTECT是开源的，可在https://github.com/AdhyaSuman/DTECT获取。

</details>


### [45] [SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment](https://arxiv.org/abs/2507.07939)
**中文标题：SAGE：基于事实增强和熵感知对齐的视觉语言模型用于异常检测**

*Guoxin Zang,Xue Li,Donglin Di,Lanshun Nie,Dechen Zhan,Yang Song,Lei Fan*

主要分类: cs.CL

摘要简述: SAGE是一种基于视觉语言模型的框架，通过自引导事实增强（SFE）和熵感知直接偏好优化（E-DPO）提升工业异常检测的推理能力，并在零样本和单样本设置下表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉语言模型在工业异常检测中表现不佳，主要因其缺乏领域特定知识和解释性。SAGE旨在解决这些问题，提升模型的精确性和泛化能力。

研究方法: SAGE结合了自引导事实增强（SFE）和熵感知直接偏好优化（E-DPO）。SFE通过事实提取与融合引入领域知识，E-DPO则通过熵感知优化对齐专家偏好。此外，还提出了AD-PL数据集和MLE评估框架。

研究结果: SAGE在工业异常数据集上表现出色，尤其在零样本和单样本设置下优于其他方法。

研究结论: SAGE通过结合领域知识和专家偏好优化，显著提升了工业异常检测的推理能力，为实际应用提供了有效解决方案。

中文摘要: 尽管视觉语言模型（VLMs）在多模态任务中表现出潜力，但在工业异常检测和推理中仍存在解释性不足和泛化能力差的问题。这源于异常检测的领域特定性，限制了现有VLMs在需要精确、结构化分析的工业场景中的应用。为此，我们提出了SAGE框架，通过自引导事实增强（SFE）和熵感知直接偏好优化（E-DPO）提升异常推理能力。SFE通过事实提取与融合引入领域知识，E-DPO则通过熵感知优化对齐专家偏好。我们还提出了AD-PL数据集，包含28,415个专家排名的问答实例，并开发了多尺度逻辑评估（MLE）框架。SAGE在零样本和单样本设置下表现出色。代码、模型和数据集已开源。

</details>


### [46] [MIRIX: Multi-Agent Memory System for LLM-Based Agents](https://arxiv.org/abs/2507.07957)
**中文标题：MIRIX：基于大语言模型代理的多智能体记忆系统**

*Yu Wang,Xi Chen*

主要分类: cs.CL

摘要简述: MIRIX是一种模块化多智能体记忆系统，通过六种结构化记忆类型和多智能体框架，解决了AI记忆的关键挑战，显著提升了语言模型的记忆能力，并在多模态和单模态任务中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI代理的记忆功能存在局限性，无法实现个性化、抽象化和长期可靠记忆。MIRIX旨在通过多智能体记忆系统解决这一问题，使语言模型能够真正记住用户信息。

研究方法: MIRIX设计了六种记忆类型（核心、情景、语义、程序、资源记忆和知识库），并结合多智能体框架动态管理记忆更新与检索。系统支持多模态输入，适用于复杂场景。

研究结果: 在ScreenshotVQA多模态任务中，MIRIX准确率比基线高35%，存储需求减少99.9%；在LOCOMO单模态对话任务中，达到85.4%的顶尖性能。

研究结论: MIRIX为记忆增强的语言模型代理设定了新的性能标准，并通过实际应用验证了其高效性和实用性。

中文摘要: 尽管AI代理的记忆能力日益受到关注，但现有解决方案仍存在根本性限制。大多数依赖扁平化、范围狭窄的记忆组件，限制了其个性化、抽象化和长期可靠记忆用户信息的能力。为此，我们提出了MIRIX，一种模块化的多智能体记忆系统，通过解决该领域最关键的问题——使语言模型真正记住信息——重新定义了AI记忆的未来。与以往方法不同，MIRIX超越了文本，支持丰富的视觉和多模态体验，使记忆在真实场景中真正有用。MIRIX包含六种精心设计的记忆类型：核心记忆、情景记忆、语义记忆、程序记忆、资源记忆和知识库，并结合多智能体框架动态控制和协调记忆的更新与检索。这一设计使代理能够持久化、推理并准确检索多样化的长期用户数据。我们在两个高要求场景中验证了MIRIX。首先，在ScreenshotVQA这一包含近20,000张高分辨率计算机截图序列的多模态基准测试中，MIRIX的准确率比RAG基线高35%，同时存储需求减少了99.9%。其次，在LOCOMO这一单模态文本输入的长对话基准测试中，MIRIX达到了85.4%的顶尖性能，远超现有基线。这些结果表明，MIRIX为记忆增强的语言模型代理设定了新的性能标准。为了让用户体验我们的记忆系统，我们提供了一个基于MIRIX的打包应用。该应用实时监控屏幕，构建个性化记忆库，并提供直观的可视化和安全的本地存储以确保隐私。

</details>


### [47] [Why is Your Language Model a Poor Implicit Reward Model?](https://arxiv.org/abs/2507.07981)
**中文标题：为什么你的语言模型是一个糟糕的隐式奖励模型？**

*Noam Razin,Yong Lin,Jiarui Yao,Sanjeev Arora*

主要分类: cs.CL

摘要简述: 研究发现，语言模型作为隐式奖励模型（IM-RM）时，其泛化能力不如显式奖励模型（EX-RM），主要原因是IM-RM更依赖表面标记级线索，导致在标记级分布变化时表现较差。


<details>
  <summary>详细信息</summary>
研究动机: 奖励模型在语言模型的训练和推理中至关重要。尽管隐式奖励模型（IM-RM）和显式奖励模型（EX-RM）几乎相同，但IM-RM的泛化能力较差，尤其是在分布外数据上。本文旨在探究这种泛化差距的根本原因。

研究方法: 通过理论和实验分析，研究了IM-RM和EX-RM的差异，重点关注它们对标记级线索的依赖程度，并排除了其他可能的解释假设。

研究结果: IM-RM更依赖表面标记级线索，导致其在标记级分布变化和分布内数据上的泛化能力不如EX-RM。实验还否定了IM-RM因同时作为验证器和生成器而表现较差的假设。

研究结论: 研究揭示了奖励模型设计中看似微小的选择会显著影响其泛化行为，强调了在设计奖励模型时需谨慎考虑其计算方式。

中文摘要: 奖励模型是语言模型后训练和推理流程的关键。最近的研究表明，每个语言模型都可以定义一个隐式奖励模型（IM-RM），而无需任何架构更改。然而，与显式奖励模型（EX-RM）相比，IM-RM的泛化能力较差，尤其是在分布外数据上。这种泛化差距令人困惑，因为EX-RM和IM-RM几乎完全相同：它们可以使用相同的数据、损失函数和语言模型进行训练，仅在奖励计算方式上有所不同。为了从根本上理解不同奖励模型类型背后的隐式偏差，我们探究了这一差距的根源。通过理论和实验，我们发现IM-RM更依赖表面标记级线索，因此在标记级分布变化以及分布内数据上的泛化能力较差。此外，我们提供了对其他解释假设的反驳证据。值得注意的是，我们挑战了一种直观观点，即IM-RM在生成比验证更困难的任务中表现不佳，因为它可以同时作为验证器和生成器。总之，我们的结果表明，看似微小的设计选择会显著影响奖励模型的泛化行为。

</details>


### [48] [Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology](https://arxiv.org/abs/2507.07983)
**中文标题：大型与小型语言模型在风湿病临床决策支持中的性能与实际考量**

*Sabine Felde,Rüdiger Buchkremer,Gamal Chehab,Christian Thielscher,Jörg HW Distler,Matthias Schneider,Jutta G. Richter*

主要分类: cs.CL

摘要简述: 研究发现，在风湿病临床决策支持中，结合检索增强生成（RAG）的小型语言模型（SLMs）比大型语言模型（LLMs）表现更优，能耗更低，适合资源有限的医疗环境，但仍需专家监督。


<details>
  <summary>详细信息</summary>
研究动机: 探讨大型语言模型（LLMs）和小型语言模型（SLMs）在风湿病临床决策支持中的性能与实际应用价值，尤其是SLMs结合RAG技术的潜力。

研究方法: 通过评估LLMs和SLMs在风湿病诊断和治疗中的表现，特别关注SLMs结合检索增强生成（RAG）技术的效果。

研究结果: SLMs结合RAG在诊断和治疗性能上优于LLMs，且能耗更低，适合本地化部署；但所有模型均未达到风湿病专家的准确率水平。

研究结论: SLMs结合RAG技术是风湿病临床决策支持的高效低成本解决方案，但仍需专家监督以确保准确性。

中文摘要: 大型语言模型（LLMs）在复杂领域如风湿病的临床决策支持中显示出潜力。我们的评估表明，结合检索增强生成（RAG）的小型语言模型（SLMs）在诊断和治疗性能上优于大型模型，同时能耗显著降低，支持低成本本地化部署。这些特点对资源有限的医疗环境具有吸引力。然而，专家监督仍然必不可少，因为没有模型能持续达到风湿病专家的准确率水平。

</details>


### [49] [Automating Expert-Level Medical Reasoning Evaluation of Large Language Models](https://arxiv.org/abs/2507.07988)
**中文标题：自动化专家级医学推理评估大型语言模型**

*Shuang Zhou,Wenya Xie,Jiaxi Li,Zaifu Zhan,Meijia Song,Han Yang,Cheyenna Espinoza,Lindsay Welton,Xinnie Mai,Yanwei Jin,Zidu Xu,Yuen-Hei Chung,Yiyun Xing,Meng-Han Tsai,Emma Schaffer,Yucheng Shi,Ninghao Liu,Zirui Liu,Rui Zhang*

主要分类: cs.CL

摘要简述: 本文提出了MedThink-Bench基准和LLM-w-Ref评估框架，用于严格、可解释且可扩展地评估大型语言模型（LLMs）的医学推理能力。实验表明，该方法与专家判断高度相关，且较小模型可能优于大型专有模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估LLMs医学推理能力的方法存在评估不准确或扩展性差的问题，缺乏严格的基准。为确保LLMs在临床决策中的透明性和可信度，亟需一种更有效的评估工具。

研究方法: 研究团队开发了MedThink-Bench基准，包含500个跨十种医学领域的挑战性问题，并附有专家逐步推理注释。基于此，提出了LLM-w-Ref框架，结合细粒度推理和LLM-as-a-Judge机制，以专家级保真度评估中间推理。

研究结果: 实验显示，LLM-w-Ref与专家判断呈强正相关。在评估12种先进LLMs时，发现较小模型（如MedGemma-27B）可能优于大型专有模型（如OpenAI-o3）。

研究结论: MedThink-Bench为评估LLMs的医学推理能力提供了基础工具，推动了其在临床实践中安全、负责任的应用。

中文摘要: 随着大型语言模型（LLMs）越来越多地融入临床决策，确保其推理透明可信至关重要。然而，现有评估LLMs医学推理能力的方法要么评估效果不佳，要么扩展性差，且缺乏严格基准。为此，我们提出了MedThink-Bench基准，用于严格、可解释且可扩展地评估LLMs的医学推理能力。该基准包含500个跨十种医学领域的挑战性问题，每个问题均附有专家逐步推理注释。在此基础上，我们提出了LLM-w-Ref框架，利用细粒度推理和LLM-as-a-Judge机制，以专家级保真度评估中间推理，同时保持扩展性。实验表明，LLM-w-Ref与专家判断呈强正相关。在评估12种先进LLMs时，发现较小模型（如MedGemma-27B）可能优于大型专有模型（如OpenAI-o3）。总体而言，MedThink-Bench为评估LLMs的医学推理能力提供了基础工具，推动了其在临床实践中安全、负责任的应用。

</details>


### [50] [PyVision: Agentic Vision with Dynamic Tooling](https://arxiv.org/abs/2507.07998)
**中文标题：PyVision：基于动态工具的自主视觉推理**

*Shitian Zhao,Haoquan Zhang,Shaoheng Lin,Ming Li,Qilong Wu,Kaipeng Zhang,Chen Wei*

主要分类: cs.CL

摘要简述: 本文介绍了PyVision，一个动态生成和执行Python工具的多轮交互框架，旨在提升多模态大语言模型在视觉推理任务中的灵活性和可解释性。


<details>
  <summary>详细信息</summary>
研究动机: 当前视觉推理任务中的方法受限于预定义的工作流程和静态工具集，限制了模型的灵活性和问题解决能力。PyVision旨在通过动态生成工具来解决这一问题。

研究方法: PyVision是一个多轮交互框架，允许多模态大语言模型自主生成、执行和优化基于Python的工具，以适应具体任务需求。

研究结果: PyVision在多个基准测试中表现优异，将GPT-4.1在V*上的性能提升了7.8%，Claude-4.0-Sonnet在VLMsAreBlind-mini上的性能提升了31.1%。

研究结论: 动态工具生成不仅使模型能够使用工具，还能发明工具，推动了更具自主性的视觉推理发展。

中文摘要: 大型语言模型（LLM）越来越多地被部署为能够规划、推理和动态调用外部工具的代理系统。然而，在视觉推理领域，现有方法仍主要受限于预定义的工作流程和静态工具集。本报告介绍了PyVision，一个交互式多轮框架，使多模态大语言模型能够自主生成、执行和优化基于Python的工具，从而解锁灵活且可解释的问题解决能力。我们开发了PyVision生成工具的分类法，并分析了它们在多样化基准测试中的使用情况。定量结果显示，PyVision实现了稳定的性能提升，将GPT-4.1在V*上的性能提升了7.8%，Claude-4.0-Sonnet在VLMsAreBlind-mini上的性能提升了31.1%。这些结果表明了一个更广泛的趋势：动态工具生成不仅允许模型使用工具，还能发明工具，推动更具自主性的视觉推理发展。

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [51] [Multi-level Mixture of Experts for Multimodal Entity Linking](https://arxiv.org/abs/2507.07108)
**中文标题：多级专家混合模型用于多模态实体链接**

*Zhiwei Hu,Víctor Gutiérrez-Basulto,Zhiliang Xiang,Ru Li,Jeff Z. Pan*

主要分类: cs.CV

摘要简述: 本文提出了一种多级专家混合模型（MMoE）用于多模态实体链接（MEL），通过动态选择模态信息和增强提及语义，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态实体链接方法未能解决提及歧义和动态模态选择问题，导致语义匹配不足。本文旨在通过多级专家混合模型弥补这些缺陷。

研究方法: MMoE包含四个模块：描述感知提及增强模块（利用大语言模型匹配提及与WikiData描述）、多模态特征提取模块（获取文本和视觉嵌入）、以及两级专家混合模块（动态选择信息区域）。

研究结果: 实验表明，MMoE在性能上显著优于现有方法，验证了其动态选择和语义增强的有效性。

研究结论: MMoE通过多级专家混合机制解决了提及歧义和模态动态选择问题，为多模态实体链接提供了高效解决方案。

中文摘要: 多模态实体链接（MEL）旨在将多模态上下文中的模糊提及链接到多模态知识库中的相关实体。现有方法通过多模态交互和融合机制弥合模态差距，实现多粒度语义匹配，但未解决两个关键问题：（i）提及歧义，即因提及文本上下文的简略和关键信息缺失导致的语义内容不足；（ii）模态内容的动态选择，即动态区分不同模态信息的重要性。为解决这些问题，我们提出了一种多级专家混合模型（MMoE）。MMoE包含四个模块：（i）描述感知提及增强模块利用大语言模型识别与提及最匹配的WikiData描述；（ii）多模态特征提取模块通过多模态编码器获取提及和实体的文本与视觉嵌入；（iii）-（iv）级内和级间专家混合模块采用开关机制动态自适应选择相关信息区域的特征。大量实验表明，MMoE的性能显著优于现有方法。代码已开源：https://github.com/zhiweihu1103/MEL-MMoE。

</details>


### [52] [CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings](https://arxiv.org/abs/2507.07125)
**中文标题：CoPT：利用领域无关文本嵌入的无监督域自适应分割方法**

*Cristina Mata,Kanchana Ranasinghe,Michael S. Ryoo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CoPT的无监督域自适应分割方法，利用领域无关的文本嵌入学习领域不变特征，通过LLM生成领域描述并结合CLIP模型，在四个基准测试中取得了最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 无监督域自适应（UDA）在语义分割中尤为重要，因为标注数据难以获取。尽管大规模视觉-语言表示学习取得了进展，但现有UDA方法未充分利用文本的领域无关特性。本文旨在填补这一空白。

研究方法: 提出了一种基于协方差的像素-文本损失（CoPT），利用领域无关的文本嵌入学习领域不变特征。通过LLM生成源域和目标域描述，输入冻结的CLIP模型并组合生成文本嵌入。

研究结果: 在四个基准测试中，使用CoPT训练的模型在无监督域自适应分割任务中达到了最先进的性能。

研究结论: CoPT通过利用领域无关的文本嵌入，显著提升了无监督域自适应分割的性能，为相关任务提供了新的解决方案。

中文摘要: 无监督域自适应（UDA）旨在从源域的标注数据中学习类语义，并将其泛化到未见过的目标域。UDA方法在语义分割中尤为重要，因为标注数据比图像分类更难获取。尽管大规模视觉-语言表示学习取得了进展，但现有UDA分割方法尚未充分利用文本的领域无关特性。为此，我们提出了一种新颖的基于协方差的像素-文本损失（CoPT），利用领域无关的文本嵌入在图像分割编码器中学习领域不变特征。这些文本嵌入通过我们的LLM领域模板过程生成，其中使用LLM生成源域和目标域的描述，输入冻结的CLIP模型并组合。在四个基准测试中，使用CoPT训练的模型在UDA分割任务中取得了最先进的性能。代码可在https://github.com/cfmata/CoPT找到。

</details>


### [53] [Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack against Image Generation Model Unlearning](https://arxiv.org/abs/2507.07139)
**中文标题：图像能唤回记忆：一种针对图像生成模型遗忘学习的新型多模态引导攻击**

*Renyang Liu,Guanlin Li,Tianwei Zhang,See-Kiong Ng*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Recall的新型对抗框架，旨在通过多模态引导攻击揭示图像生成模型在遗忘学习中的脆弱性。该方法利用对抗性图像提示和参考图像的语义相关性，显著优于现有基线，揭示了当前遗忘学习机制的安全隐患。


<details>
  <summary>详细信息</summary>
研究动机: 随着图像生成模型（如Stable Diffusion）的快速发展，其生成能力引发了伦理、法律和社会问题。尽管机器遗忘学习（MU）被提出以消除不良概念，但其在多模态对抗输入下的鲁棒性和有效性尚未充分研究。本文旨在填补这一空白。

研究方法: Recall框架通过优化对抗性图像提示，并结合单张语义相关的参考图像，利用扩散模型的多模态条件能力，攻击遗忘学习后的图像生成模型。实验覆盖了十种先进的遗忘学习方法。

研究结果: 实验表明，Recall在对抗效果、计算效率和语义保真度上均优于现有基线，揭示了当前遗忘学习机制的关键漏洞。

研究结论: 研究结果强调了开发更鲁棒的遗忘学习解决方案的必要性，以确保生成模型的安全性和可靠性。代码和数据已公开。

中文摘要: 近年来，图像生成模型（IGMs）尤其是基于扩散架构的模型（如Stable Diffusion）显著提升了AI生成视觉内容的质量和多样性。然而，其生成能力也引发了严重的伦理、法律和社会问题，包括可能产生有害、误导性或侵权内容。为缓解这些问题，机器遗忘学习（MU）作为一种有前景的解决方案被提出，通过选择性移除预训练模型中的不良概念。然而，现有遗忘学习技术的鲁棒性和有效性在多模态对抗输入下尚未得到充分研究。

为填补这一空白，我们提出了Recall，一种新型对抗框架，旨在破坏遗忘学习后IGMs的鲁棒性。与现有主要依赖对抗性文本提示的方法不同，Recall利用扩散模型的多模态条件能力，通过优化对抗性图像提示并结合单张语义相关的参考图像。在十种先进遗忘学习方法和多样化任务上的实验表明，Recall在对抗效果、计算效率和语义保真度上均优于现有基线。这些发现揭示了当前遗忘学习机制的关键漏洞，并强调了开发更鲁棒解决方案以确保生成模型安全性和可靠性的必要性。代码和数据已公开于\textcolor{blue}{https://github.com/ryliu68/RECALL}。

</details>


### [54] [Explainable Artificial Intelligence in Biomedical Image Analysis: A Comprehensive Survey](https://arxiv.org/abs/2507.07148)
**中文标题：可解释人工智能在生物医学图像分析中的全面综述**

*Getamesay Haile Dagnaw,Yanming Zhu,Muhammad Hassan Maqsood,Wencheng Yang,Xingshuai Dong,Xuefei Yin,Alan Wee-Chung Liew*

主要分类: cs.CV

摘要简述: 本文综述了可解释人工智能（XAI）在生物医学图像分析中的应用，系统分类了XAI方法，并提出了基于模态的分类法，探讨了多模态学习和视觉语言模型的作用，总结了评估指标和开源框架，并讨论了未来挑战。


<details>
  <summary>详细信息</summary>
研究动机: 现有XAI综述缺乏对生物医学图像分析中模态感知视角的关注，且未充分探讨多模态和视觉语言模型的进展。本文旨在填补这一空白，提供全面的XAI方法综述，以促进透明度和临床应用的信任。

研究方法: 通过系统分类XAI方法，分析其原理、优势和局限性，提出基于模态的分类法，并探讨多模态学习和视觉语言模型在生物医学AI中的作用。总结了评估指标和开源框架。

研究结果: 本文提供了XAI方法的全面分类和模态感知视角，突出了多模态和视觉语言模型的潜力，总结了评估工具和开源资源，并指出了未来研究方向。

研究结论: 本综述为生物医学图像分析中的可解释深度学习提供了深入的基础，强调了多模态和视觉语言模型的重要性，并提出了未来挑战和发展方向。

中文摘要: 可解释人工智能（XAI）在生物医学图像分析中日益重要，以促进深度学习模型的透明度、信任和临床应用。尽管已有综述回顾了XAI技术，但它们往往缺乏模态感知视角，忽视了多模态和视觉语言范式的最新进展，且提供的实践指导有限。本综述通过全面且结构化的XAI方法综合，填补了这一空白。我们系统分类了XAI方法，分析了其在生物医学背景下的原理、优势和局限性，并提出了基于模态的分类法，以突出不同模态的独特可解释性挑战。我们还探讨了多模态学习和视觉语言模型在可解释生物医学AI中的新兴作用，这是以往研究中较少涉及的主题。此外，我们总结了广泛使用的评估指标和开源框架，并对持续存在的挑战和未来方向进行了批判性讨论。本综述为推进生物医学图像分析中的可解释深度学习提供了及时且深入的基础。

</details>


### [55] [Robust Multimodal Large Language Models Against Modality Conflict](https://arxiv.org/abs/2507.07151)
**中文标题：鲁棒的多模态大语言模型对抗模态冲突**

*Zongmeng Zhang,Wengang Zhou,Jie Zhao,Houqiang Li*

主要分类: cs.CV

摘要简述: 本文研究了多模态大语言模型（MLLMs）在视觉语言任务中因模态冲突导致的幻觉现象，提出了三种缓解方法，并构建了MMMC数据集进行实验验证。


<details>
  <summary>详细信息</summary>
研究动机: 尽管多模态大语言模型在视觉语言任务中表现优异，但在实际场景中容易产生幻觉。本文从模态冲突的角度探讨了这一现象，旨在揭示输入模态间的冲突如何直接导致幻觉。

研究方法: 本文正式定义了模态冲突，并构建了MMMC数据集模拟这一现象。提出了基于提示工程、监督微调和强化学习的三种方法，以缓解模态冲突引发的幻觉。

研究结果: 实验结果表明，强化学习方法在缓解模态冲突导致的幻觉中表现最佳，监督微调方法则展现出稳定且有潜力的性能。

研究结论: 本文揭示了模态冲突这一被忽视的幻觉成因，为提升多模态大语言模型的鲁棒性提供了新见解。

中文摘要: 尽管多模态大语言模型（MLLMs）在视觉语言任务中表现出色，但在实际场景中容易产生幻觉。本文从模态冲突的角度研究了MLLMs中的幻觉现象。与现有工作关注模型响应与输入之间的冲突不同，我们研究了不同模态输入中固有的冲突，这些冲突使MLLMs陷入困境并直接导致幻觉。我们正式定义了模态冲突，并构建了一个名为多模态模态冲突（MMMC）的数据集，以模拟视觉语言任务中的这一现象。提出了基于提示工程、监督微调和强化学习的三种方法来缓解由模态冲突引起的幻觉。在MMMC数据集上进行了大量实验，分析了这些方法的优缺点。结果显示，强化学习方法在缓解模态冲突下的幻觉中表现最佳，而监督微调方法展现出稳定且有潜力的性能。我们的工作揭示了导致幻觉的未被注意的模态冲突，并为MLLMs的鲁棒性提供了更多见解。

</details>


### [56] [Aerial Maritime Vessel Detection and Identification](https://arxiv.org/abs/2507.07153)
**中文标题：空中海上船只检测与识别**

*Antonella Barisic Kulas,Frano Petric,Stjepan Bogdan*

主要分类: cs.CV

摘要简述: 论文提出了一种在GNSS不可用环境下，利用YOLOv8模型检测海上目标船只并通过特征匹配和色调直方图距离分析识别目标的方法，结合几何原理定位目标，并在MBZIRC2023竞赛中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 在GNSS不可用的环境中，自主海上监视和目标船只识别对搜索救援和威胁检测等应用至关重要。当目标船只仅通过视觉线索描述且无法获取其最后已知位置时，无人机需依赖机载视觉在严格计算限制下扫描大范围搜索区域。

研究方法: 采用YOLOv8目标检测模型检测视野内所有船只，随后通过特征匹配和色调直方图距离分析判断是否为目标船只，并使用简单几何原理定位目标。

研究结果: 在MBZIRC2023竞赛的实际实验中验证了方法的有效性，并评估了视角对检测精度和定位准确性的影响，与基准方法进行了对比。

研究结论: 所提方法在GNSS不可用环境下能够有效检测和识别目标船只，并通过几何定位实现目标位置确定，为自主海上监视提供了可行方案。

中文摘要: 在无法使用全球导航卫星系统（GNSS）的环境中，自主海上监视和目标船只识别对搜索救援和威胁检测等应用至关重要。当目标船只仅通过视觉线索描述且无法获取其最后已知位置时，无人机（UAV）需完全依赖机载视觉在严格计算限制下扫描大范围搜索区域。为解决这一挑战，我们利用YOLOv8目标检测模型检测视野内所有船只，随后通过特征匹配和色调直方图距离分析判断是否为目标船只。一旦发现目标，我们通过简单几何原理进行定位。我们在MBZIRC2023竞赛的实际实验中验证了所提方法，并将其集成到完全自主的GNSS不可用导航系统中。我们还评估了视角对检测精度和定位准确性的影响，并与基准方法进行了对比。

</details>


### [57] [CL-Polyp: A Contrastive Learning-Enhanced Network for Accurate Polyp Segmentation](https://arxiv.org/abs/2507.07154)
**中文标题：CL-Polyp：一种基于对比学习的精准息肉分割网络**

*Desheng Li,Chaoliang Liu,Zhiyong Xiao*

主要分类: cs.CV

摘要简述: CL-Polyp是一种基于对比学习的息肉分割网络，通过自监督策略提升特征提取能力，并引入轻量级模块优化多尺度特征融合和边界重建，在多个数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有息肉分割方法多依赖额外标注数据或任务相似性，限制了泛化能力。本文旨在通过对比学习提升特征提取能力，减少对额外标注的依赖。

研究方法: CL-Polyp利用对比学习增强编码器的特征提取能力，通过对比正负样本对提升视觉表示。同时引入MASPP模块优化多尺度特征融合，以及CA模块融合低层和上采样特征以改善边界重建。

研究结果: 在五个基准数据集（Kvasir-SEG、CVC-ClinicDB等）上，CL-Polyp表现优于现有方法，IoU指标分别提升0.011和0.020。

研究结论: CL-Polyp通过对比学习和轻量级模块设计，显著提升了息肉分割的准确性和泛化能力，适用于临床任务。

中文摘要: 结肠镜图像中息肉的精准分割对结直肠癌的早期诊断和治疗至关重要。现有基于深度学习的息肉分割方法多采用编码器-解码器架构，部分通过多任务框架（如分类）提升性能，但依赖额外标注数据和任务相似性，限制了泛化能力。为此，我们提出CL-Polyp，一种基于对比学习的息肉分割网络。该方法通过对比息肉图像的正负样本对增强编码器的特征提取能力，无需额外标注即可提升视觉表示。此外，我们引入两个轻量级模块：改进的空洞空间金字塔池化（MASPP）模块以优化多尺度特征融合，以及通道拼接与元素相加（CA）模块以融合低层和上采样特征，改善边界重建。在五个基准数据集（Kvasir-SEG、CVC-ClinicDB、CVC-ColonDB、CVC-300和ETIS）上的实验表明，CL-Polyp性能优于现有方法，尤其在Kvasir-SEG和CVC-ClinicDB数据集上，IoU指标分别提升0.011和0.020，验证了其在临床息肉分割任务中的有效性。

</details>


### [58] [Interpretable EEG-to-Image Generation with Semantic Prompts](https://arxiv.org/abs/2507.07157)
**中文标题：基于语义提示的可解释EEG到图像生成**

*Arshak Rezvani,Ali Akbari,Kosar Sanjar Arani,Maryam Mirian,Emad Arasteh,Martin J. McKeown*

主要分类: cs.CV

摘要简述: 该论文提出了一种通过语义提示从EEG信号生成图像的可解释方法，利用多级语义描述与EEG信号对齐，结合预训练的潜在扩散模型实现图像生成，并在EEGCVPR数据集上取得了先进的视觉解码效果。


<details>
  <summary>详细信息</summary>
研究动机: EEG信号虽然时间分辨率高且易于获取，但其空间细节不足限制了直接用于图像重建的能力。研究旨在通过语义中介，将EEG信号与多级语义描述对齐，从而克服这一限制，实现可解释的视觉解码。

研究方法: 模型通过对比学习将EEG信号映射到由大型语言模型生成的多级语义描述（从对象级到抽象主题）。在推理阶段，通过投影头检索的语义描述嵌入用于条件化预训练的潜在扩散模型，生成图像。

研究结果: 在EEGCVPR数据集上，该方法实现了先进的视觉解码效果，并展示了与已知神经认知路径的可解释对齐。EEG信号与语义描述的关联反映了感知图像中不同语义层次的重要性。

研究结论: 研究表明，通过结构化的语义中介，可以从EEG信号中实现与认知对齐的视觉解码，为神经科学和可解释AI提供了新的可能性。

中文摘要: 从脑信号解码视觉体验为神经科学和可解释AI提供了令人兴奋的可能性。虽然EEG易于获取且时间分辨率高，但其空间细节的局限性阻碍了图像重建。我们的模型通过将EEG信号与多级语义描述（从对象级到抽象主题）对齐，绕过了直接的EEG到图像生成。基于对比学习的变压器EEG编码器将大脑活动映射到这些描述。在推理阶段，通过投影头检索的描述嵌入用于条件化预训练的潜在扩散模型以生成图像。这一文本中介框架在EEGCVPR数据集上实现了先进的视觉解码效果，并与已知的神经认知路径实现了可解释的对齐。EEG与描述的关联反映了感知图像中不同语义层次的重要性。显著性图和t-SNE投影揭示了头皮上的语义地形分布。我们的模型展示了结构化语义中介如何实现从EEG中与认知对齐的视觉解码。

</details>


### [59] [A Survey on Long-Video Storytelling Generation: Architectures, Consistency, and Cinematic Quality](https://arxiv.org/abs/2507.07202)
**中文标题：长视频故事生成综述：架构、一致性与电影质量**

*Mohamed Elmoghany,Ryan Rossi,Seunghyun Yoon,Subhojyoti Mukherjee,Eslam Bakr,Puneet Mathur,Gang Wu,Viet Dac Lai,Nedim Lipka,Ruiyi Zhang,Varun Manjunatha,Chien Nguyen,Daksh Dangi,Abel Salinas,Mohammad Taesiri,Hongjie Chen,Xiaolei Huang,Joe Barrow,Nesreen Ahmed,Hoda Eldardiry,Namyong Park,Yu Wang,Jaemin Cho,Anh Totti Nguyen,Zhengzhong Tu,Thien Nguyen,Dinesh Manocha,Mohamed Elhoseiny,Franck Dernoncourt*

主要分类: cs.CV

摘要简述: 本文综述了长视频故事生成的现状，分析了现有方法在生成超过16秒视频时面临的挑战，如角色一致性和场景布局问题，并提出了一种分类法以总结32篇相关论文的关键架构和训练策略。


<details>
  <summary>详细信息</summary>
研究动机: 尽管视频生成模型已取得显著进展，但现有方法仅能生成5-16秒的短视频，且长视频在角色一致性和场景布局上表现不佳。多角色长视频尤其难以保持一致性。本文旨在总结现有方法并探索如何提升长视频生成的叙事连贯性和细节质量。

研究方法: 本文全面研究了32篇视频生成相关论文，识别出能够生成高质量长视频的关键架构组件和训练策略，并构建了一种新的分类法，通过表格对比不同方法的架构设计和性能特点。

研究结果: 研究发现，现有方法在生成超过16秒的视频时普遍面临角色一致性和场景布局的挑战，部分方法虽能生成长达150秒的视频，但存在帧冗余和时间多样性不足的问题。通过分类法总结，提出了提升长视频生成质量的潜在方向。

研究结论: 本文通过系统综述和分类法，揭示了长视频生成领域的关键挑战和潜在解决方案，为未来研究提供了重要参考。

中文摘要: 尽管视频生成模型已取得显著进展，但现有最先进方法仅能生成5-16秒的视频，通常被称为“长视频”。此外，超过16秒的视频在叙事过程中难以保持角色外观和场景布局的一致性。特别是多角色长视频仍无法保持角色一致性和运动连贯性。虽然部分方法能生成长达150秒的视频，但常存在帧冗余和时间多样性低的问题。近期研究尝试生成长视频，涵盖多角色、叙事连贯性和高保真细节。我们全面研究了32篇视频生成相关论文，以识别出能够持续生成高质量视频的关键架构组件和训练策略。同时，我们构建了一种全新的分类法，并通过表格对比不同论文的架构设计和性能特点。

</details>


### [60] [Colors See Colors Ignore: Clothes Changing ReID with Color Disentanglement](https://arxiv.org/abs/2507.07230)
**中文标题：颜色看颜色忽略：基于颜色解耦的衣物更换ReID**

*Priyank Pathak,Yogesh S. Rawat*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CSCI的RGB-only方法，通过颜色解耦技术解决衣物更换ReID问题，无需额外标注或模型，显著提升了性能。


<details>
  <summary>详细信息</summary>
研究动机: 衣物更换ReID（CC-ReID）旨在识别不同服装下的同一人，但现有方法依赖额外模型或标注，资源消耗大。本文探索利用颜色信息作为轻量级、无标注的代理，以减少外观偏差。

研究方法: 提出CSCI方法，利用RGB图像直接提取颜色信息，通过S2A自注意力机制分离颜色与身份特征，避免信息泄露。

研究结果: 在四个CC-ReID数据集上，CSCI显著提升性能：图像ReID中LTCC提升2.9%，PRCC提升5.0%；视频ReID中CCVID提升1.0%，MeVID提升2.5%。

研究结论: 颜色信息是解决CC-ReID外观偏差的高效低成本方案，CSCI方法在无需额外监督下表现出色。

中文摘要: 衣物更换ReID（CC-ReID）旨在识别不同地点和时间下的同一人，无论其服装如何。现有方法通常依赖额外模型或标注学习鲁棒的服装不变特征，资源消耗大。相比之下，我们探索利用颜色（前景和背景色）作为轻量级、无标注的代理，以减少ReID模型的外观偏差。我们提出“颜色看，颜色忽略”（CSCI），一种仅使用RGB的方法，直接从原始图像或视频帧中提取颜色信息。CSCI高效捕捉颜色相关的外观偏差（“颜色看”），同时将其与身份相关ReID特征解耦（“颜色忽略”）。为此，我们引入S2A自注意力，一种新型自注意力机制，防止特征空间中颜色与身份线索的信息泄露。分析表明，学习的颜色嵌入与服装属性高度相关，验证了颜色在缺乏显式服装标签时的有效性。我们在四个CC-ReID数据集上通过大量实验验证了CSCI的有效性。在图像ReID中，LTCC和PRCC的Top-1分别提升2.9%和5.0%；在视频ReID中，CCVID和MeVID分别提升1.0%和2.5%，且无需额外监督。结果凸显颜色作为低成本解决方案在CC-ReID中的潜力。GitHub：https://github.com/ppriyank/ICCV-CSCI-Person-ReID。

</details>


### [61] [Automated Video Segmentation Machine Learning Pipeline](https://arxiv.org/abs/2507.07242)
**中文标题：自动化视频分割机器学习流程**

*Johannes Merz,Lucien Fostier*

主要分类: cs.CV

摘要简述: 本文提出了一种自动化视频分割机器学习流程，显著提升了视觉特效（VFX）制作中掩模生成的效率，减少了人工操作并加速了初步合成的创建。


<details>
  <summary>详细信息</summary>
研究动机: 视觉特效（VFX）制作中，掩模生成通常耗时且资源密集，限制了生产效率。本文旨在通过自动化视频分割技术解决这一问题，提升制作效率。

研究方法: 该流程结合了机器学习技术，包括：（1）通过文本提示实现灵活的目标检测；（2）逐帧图像分割的精细化处理；（3）确保时间一致性的鲁棒视频跟踪。此外，采用容器化部署和结构化输出格式，便于艺术家快速使用。

研究结果: 该流程显著减少了人工操作，加速了初步合成的创建，并提供了全面的分割数据，从而提升了VFX制作的整体效率。

研究结论: 本文提出的自动化视频分割流程为VFX制作提供了高效、稳定的掩模生成解决方案，具有广泛的应用前景。

中文摘要: 视觉特效（VFX）制作中，掩模生成通常缓慢且资源密集。本文提出了一种自动化视频分割流程，能够生成时间一致的实例掩模。该流程利用机器学习实现：（1）通过文本提示进行灵活的目标检测；（2）逐帧图像分割的精细化处理；（3）确保时间稳定性的鲁棒视频跟踪。通过容器化部署和结构化输出格式，该流程被艺术家快速采用。它显著减少了人工操作，加速了初步合成的创建，并提供了全面的分割数据，从而提升了VFX制作的整体效率。

</details>


### [62] [DisenQ: Disentangling Q-Former for Activity-Biometrics](https://arxiv.org/abs/2507.07262)
**中文标题：DisenQ：解耦Q-Former用于活动生物识别**

*Shehreen Azad,Yogesh S Rawat*

主要分类: cs.CV

摘要简述: 本文提出了一种多模态语言引导框架DisenQ，用于解决活动生物识别中身份线索与运动动态和外观变化纠缠的问题，通过结构化文本监督实现特征解耦，并在多个基准测试中取得最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统的人员识别在多样化的活动中面临身份线索与运动动态和外观变化纠缠的挑战，导致生物特征学习复杂化。现有方法依赖额外的视觉数据（如姿态或轮廓），但提取不准确。本文旨在通过语言引导解决这一问题。

研究方法: 提出了一种多模态语言引导框架DisenQ，利用结构化文本监督替代额外的视觉数据。核心是一个统一的查询变换器，通过语言指导解耦生物特征、运动特征和非生物特征，确保身份线索独立于外观和运动变化。

研究结果: 在三个基于活动的视频基准测试中取得了最优性能，同时在传统视频识别基准测试中表现出强大的泛化能力。

研究结论: DisenQ框架通过语言引导有效解耦了生物特征与其他干扰因素，显著提升了活动生物识别的准确性和泛化能力。

中文摘要: 本文研究了活动生物识别问题，即在多样化活动中识别个体身份。与传统人员识别不同，这一场景中身份线索与运动动态和外观变化纠缠，增加了生物特征学习的复杂性。虽然额外的视觉数据（如姿态或轮廓）有所帮助，但其提取往往不准确。为解决这一问题，我们提出了一种多模态语言引导框架，用结构化文本监督替代额外视觉数据。其核心是DisenQ（解耦Q-Former），一种统一的查询变换器，通过结构化语言指导解耦生物特征、运动特征和非生物特征，确保身份线索独立于外观和运动变化，避免误识别。我们在三个基于活动的视频基准测试中评估了该方法，取得了最优性能。此外，该方法在传统视频识别基准测试中表现出强大的泛化能力，证明了框架的有效性。

</details>


### [63] [LinguaMark: Do Multimodal Models Speak Fairly? A Benchmark-Based Evaluation](https://arxiv.org/abs/2507.07274)
**中文标题：LinguaMark：多模态模型是否公平？基于基准的评估**

*Ananya Raval,Aravind Narayanan,Vahid Reza Khazaie,Shaina Raza*

主要分类: cs.CV

摘要简述: 本文介绍了LinguaMark基准，用于评估大型多模态模型（LMMs）在多语言视觉问答任务中的表现，发现闭源模型整体表现最佳，开源模型Qwen2.5在多语言泛化方面表现突出。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型多模态模型在语言覆盖上存在偏差，导致不公平输出，但多语言能力的评估研究较少。本文旨在填补这一空白，通过LinguaMark基准评估模型的多语言能力。

研究方法: 研究构建了包含6,875对图像文本的LinguaMark数据集，涵盖11种语言和五种社会属性，采用偏差、答案相关性和忠实性三个指标评估模型表现。

研究结果: 闭源模型（如GPT-4o和Gemini2.5）整体表现最佳，开源模型（如Gemma3和Qwen2.5）在社会属性上表现竞争性，Qwen2.5在多语言泛化方面表现突出。

研究结论: LinguaMark基准揭示了多模态模型在多语言任务中的表现差异，开源模型Qwen2.5在多语言泛化方面具有潜力，研究提供了可复现的基准和代码以推动进一步研究。

中文摘要: 大型多模态模型（LMMs）通常基于海量图像文本数据训练，但语言覆盖有限，导致输出存在偏差和不公平。尽管已有研究探索多模态评估，但对多语言能力的评估较少。本文提出LinguaMark基准，用于评估先进LMMs在多语言视觉问答任务中的表现。数据集包含6,875对图像文本，涵盖11种语言和五种社会属性，采用偏差、答案相关性和忠实性三个指标评估模型。结果显示，闭源模型整体表现最佳，闭源（如GPT-4o和Gemini2.5）与开源模型（如Gemma3和Qwen2.5）在社会属性上表现竞争性，Qwen2.5在多语言泛化方面表现突出。我们公开基准和评估代码以促进复现和进一步研究。

</details>


### [64] [MagiC: Evaluating Multimodal Cognition Toward Grounded Visual Reasoning](https://arxiv.org/abs/2507.07297)
**中文标题：MagiC：评估多模态认知在视觉推理中的基础性**

*Chengfei Wu,Ronald Seoh,Bingxuan Li,Liqiang Zhang,Fengrong Han,Dan Goldwasser*

主要分类: cs.CV

摘要简述: 本文介绍了MagiC基准测试，旨在评估多模态模型的视觉推理能力，包括答案准确性、逐步推理质量及其与视觉证据的匹配程度。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型视觉语言模型在视觉问答和多模态推理中表现优异，但其是否真正基于视觉推理还是依赖表面模式和数据偏差尚不明确。因此，需要一种全面的评估方法。

研究方法: MagiC基准包含约5,500个弱监督QA示例和900个人工标注示例，评估15个模型的四个维度：答案正确性、推理有效性、视觉证据匹配度和自我纠正能力，并引入新指标MagiScore和StepSense。

研究结果: 评估揭示了当前视觉推理方法的关键局限性，特别是在对抗性视觉线索和自省错误纠正方面的不足。

研究结论: MagiC为多模态认知提供了全面的评估框架，揭示了现有方法的不足，并为未来研究指明了方向。

中文摘要: 近年来，大型视觉语言模型在视觉问答和多模态推理中取得了显著进展。然而，这些模型是否真正基于视觉推理，还是依赖于表面模式和数据偏差，尚不明确。为此，我们提出了MagiC，一个全面的基准测试，旨在评估多模态认知的基础性，不仅关注答案准确性，还评估逐步推理的质量及其与相关视觉证据的匹配程度。我们的基准包含约5,500个弱监督QA示例（基于强模型输出生成）和900个人工标注示例（包含答案、推理依据和边界框标注）。我们评估了15个参数规模从7B到70B的视觉语言模型，涵盖四个维度：最终答案正确性、推理有效性、视觉证据匹配度和自我纠正能力。MagiC还包含诊断性设置，用于测试模型在对抗性视觉线索下的鲁棒性，并评估其自省错误纠正能力。我们引入了新指标MagiScore和StepSense，并通过全面分析揭示了当前视觉推理方法的关键局限性和改进机会。

</details>


### [65] [ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation](https://arxiv.org/abs/2507.07317)
**中文标题：ADIEE：指令引导图像编辑评估的自动化数据集创建与评分器**

*Sherry X. Chen,Yi Wei,Luowei Zhou,Suren Kumar*

主要分类: cs.CV

摘要简述: ADIEE是一种自动化数据集创建和评分模型，用于指令引导的图像编辑评估，通过生成大规模数据集并微调模型，显著提升了评分准确性和相关性。


<details>
  <summary>详细信息</summary>
研究动机: 当前指令引导的图像编辑缺乏有效的自动化评估方法，开源模型对齐性差，闭源模型不透明且成本高，且缺乏公开的训练数据集。

研究方法: ADIEE通过生成超过10万样本的大规模数据集，并微调LLaVA-NeXT-8B模型，使其能够解码自定义标记的数值评分。

研究结果: 该评分模型在所有基准测试中优于开源和闭源模型，与人类评分的相关性提升17.24%，在多个基准测试中比较准确率提升4.03%至9.35%。

研究结论: ADIEE不仅可作为评分模型，还能用于自动选择最佳编辑和模型微调，显著提升现有模型的性能。

中文摘要: 指令引导图像编辑的最新进展凸显了对有效自动化评估的需求。尽管视觉语言模型（VLMs）已被探索作为评判工具，但开源模型在对齐性上表现不佳，而闭源模型缺乏透明度和成本效益。此外，目前没有公开的训练数据集可用于微调开源VLMs，仅有一些小型基准测试和多样化的评估方案。为此，我们提出了ADIEE，一种自动化数据集创建方法，并用于训练指令引导图像编辑评估的评分模型。我们生成了一个包含超过10万样本的大规模数据集，并利用其微调了一个改进的LLaVA-NeXT-8B模型，使其能够解码自定义标记的数值评分。该评分模型在所有开源VLMs和Gemini-Pro 1.5中表现最佳，在AURORA-Bench上与人类评分的相关性提升了17.24%（0.0696分），在GenAI-Bench和AURORA-Bench上的成对比较准确率分别提升了4.03%（+7.21%）和4.75%（+9.35%）。该评分模型还可作为奖励模型，实现自动选择最佳编辑和模型微调。值得注意的是，该评分模型能够将MagicBrush模型在ImagenHub上的平均评分从5.90提升至6.43（+8.98%）。

</details>


### [66] [Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory](https://arxiv.org/abs/2507.07333)
**中文标题：基于Kubelka-Munk理论的可扩展且真实的粉底虚拟试妆应用**

*Hui Pang,Sunil Hadap,Violetta Shevchenko,Rahul Suresh,Amin Banitalebi-Dehkordi*

主要分类: cs.CV

摘要简述: 本文提出了一种基于Kubelka-Munk理论的新型虚拟试妆方法，能够快速合成粉底与肤色的自然融合效果，并构建了一个可扩展的端到端框架，适用于电商平台上的多样化产品。


<details>
  <summary>详细信息</summary>
研究动机: 虚拟试妆（VTO）应用在美容行业中日益重要，但粉底试妆的技术挑战在于如何准确合成粉底与肤色的自然融合，同时保持方法的可扩展性。本文旨在解决这一问题。

研究方法: 提出了一种基于Kubelka-Munk（KM）理论的近似方法，用于快速图像合成，同时保持粉底与肤色融合的真实感。此外，构建了一个仅依赖电商平台产品信息的可扩展端到端框架。

研究结果: 通过真实化妆图像的验证，本文提出的框架在粉底试妆效果上优于其他技术。

研究结论: 该方法不仅提升了虚拟试妆的真实感，还实现了对多样化产品的高效支持，为美容行业的虚拟试妆应用提供了实用解决方案。

中文摘要: 增强现实技术正在通过虚拟试妆（VTO）应用彻底改变美容行业，用户可以通过手机轻松尝试多种产品，而无需实际使用。粉底虚拟试妆的一个关键技术挑战是准确合成粉底与肤色的颜色融合，同时保持方法在多样化产品范围内的可扩展性。本文提出了一种新颖的方法，基于成熟的Kubelka-Munk（KM）理论进行近似，以实现更快的图像合成，同时保留粉底与肤色融合的真实感。此外，我们构建了一个仅依赖电商平台产品信息的可扩展端到端框架，用于实现真实的粉底虚拟试妆。通过真实化妆图像的验证，我们的框架在效果上优于其他技术。

</details>


### [67] [Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.07340)
**中文标题：基于对比强化学习的视觉叙事中实体重识别**

*Daniel A. P. Oliveira,David Martins de Matos*

主要分类: cs.CV

摘要简述: 本文提出了一种基于对比强化学习的方法，用于解决视觉叙事系统中实体跨帧识别不一致的问题，显著提升了实体识别和故事连贯性。


<details>
  <summary>详细信息</summary>
研究动机: 视觉叙事系统（尤其是大型视觉语言模型）在跨帧识别相同实体（如角色或物体）时表现不佳，导致引用不一致或虚构引用。这是因为模型缺乏明确的跨帧实体连接训练。

研究方法: 采用对比强化学习方法，通过合成负面示例扩展数据集，并利用双组件奖励函数优化模型行为，促进真实故事中的实体识别，同时惩罚合成上下文中的错误连接。基于Qwen Storyteller模型进行微调。

研究结果: 实验显示，实体识别准确率显著提升（mAP提升14.8%，F1提升17.1%），代词识别准确率普遍提高（除“its”外），跨帧实体持续性增强（5帧以上实体识别提升13.7%），结构化故事比例大幅增加（23.3%）。

研究结论: 对比强化学习方法有效解决了视觉叙事中的实体识别问题，显著提升了模型的跨帧一致性和故事连贯性。

中文摘要: 视觉叙事系统（尤其是大型视觉语言模型）在跨帧识别相同实体（如角色或物体）时表现不佳，导致引用不一致或虚构引用。这是因为模型缺乏明确的跨帧实体连接训练。我们提出了一种对比强化学习方法，通过合成负面示例扩展数据集，并利用双组件奖励函数优化模型行为，促进真实故事中的实体识别，同时惩罚合成上下文中的错误连接。基于Qwen Storyteller模型（基于Qwen2.5-VL 7B）进行微调。实验结果显示，实体识别准确率显著提升（mAP从0.27升至0.31，提升14.8%；F1从0.35升至0.41，提升17.1%），代词识别准确率普遍提高（除“its”外），跨帧实体持续性增强（5帧以上实体识别从29.3%升至33.3%，提升13.7%），结构化故事比例大幅增加（从79.1%升至97.5%，提升23.3%）。

</details>


### [68] [PacGDC: Label-Efficient Generalizable Depth Completion with Projection Ambiguity and Consistency](https://arxiv.org/abs/2507.07374)
**中文标题：PacGDC：基于投影模糊性与一致性的标签高效泛化深度补全**

*Haotian Wang,Aoran Xiao,Xiaoqin Zhang,Meng Yang,Shijian Lu*

主要分类: cs.CV

摘要简述: PacGDC是一种标签高效的技术，通过利用2D到3D投影中的模糊性和一致性，合成大量伪几何数据，显著提升深度补全模型的泛化能力，同时减少对大规模标注数据的依赖。


<details>
  <summary>详细信息</summary>
研究动机: 当前通用的深度补全模型需要大量标注数据，但标注成本高昂。PacGDC旨在通过利用投影模糊性和一致性，减少对标注数据的依赖，同时提升模型的泛化能力。

研究方法: PacGDC通过分析2D到3D投影中的模糊性和一致性，合成多种伪几何数据。使用多个深度基础模型作为尺度操纵器，生成不同场景尺度的伪深度标签，并结合插值和重定位策略以及未标注图像，进一步扩展数据覆盖范围。

研究结果: 实验表明，PacGDC在多个基准测试中表现出卓越的泛化能力，适用于不同场景语义/尺度和深度稀疏性/模式，且在零样本和少样本设置下均表现优异。

研究结论: PacGDC通过标签高效的方法显著提升了深度补全模型的泛化能力，为实际应用提供了更灵活的解决方案。

中文摘要: 泛化深度补全能够为未见环境生成密集的度量深度图，为多种下游任务提供鲁棒的感知能力。然而，训练此类模型通常需要大规模的度量深度标注数据，而此类数据的收集往往费时费力。本文提出PacGDC，一种标签高效的技术，通过最小化标注工作量增强数据多样性，实现泛化深度补全。PacGDC基于对2D到3D投影中物体形状和位置固有模糊性与一致性的新见解，能够为同一视觉场景合成大量伪几何数据。通过操纵对应深度图的场景尺度，这一过程显著扩展了可用几何数据的范围。为利用这一特性，我们提出了一种新的数据合成流程，使用多个深度基础模型作为尺度操纵器。这些模型能够稳健地提供具有不同场景尺度的伪深度标签，影响局部物体和全局布局，同时确保支持泛化的投影一致性。为进一步多样化几何数据，我们结合了插值和重定位策略以及未标注图像，将数据覆盖范围扩展到基础模型单独使用之外。大量实验表明，PacGDC在多个基准测试中表现出卓越的泛化能力，适用于不同场景语义/尺度和深度稀疏性/模式，且在零样本和少样本设置下均表现优异。代码：https://github.com/Wang-xjtu/PacGDC。

</details>


### [69] [Adaptive Particle-Based Shape Modeling for Anatomical Surface Correspondence](https://arxiv.org/abs/2507.07379)
**中文标题：基于自适应粒子的解剖表面对应形状建模**

*Hong Xu,Shireen Y. Elhabian*

主要分类: cs.CV

摘要简述: 本文提出了一种自适应粒子形状建模方法，通过引入邻域对应损失和测地线对应算法，提升了粒子配置对局部几何特征的适应性，同时保持了配置的一致性。


<details>
  <summary>详细信息</summary>
研究动机: 粒子形状建模（PSM）在量化解剖结构形状变异性方面表现出色，但现有方法缺乏自适应性，难以准确捕捉复杂几何特征。本文旨在解决这一问题，提出自适应机制以提升建模精度。

研究方法: 本文提出两种机制：1）邻域对应损失，增强粒子配置的局部适应性；2）测地线对应算法，通过正则化优化确保测地线邻域一致性。

研究结果: 实验验证了方法的有效性和可扩展性，分析了适应性与对应性的权衡，并在表面表示精度和对应性指标上优于现有方法。

研究结论: 本文方法显著提升了粒子形状建模的自适应性，为复杂解剖结构的形状分析提供了更精确的工具。

中文摘要: 粒子形状建模（PSM）是一类通过将粒子（伪标志点）以一致配置放置在形状表面来自动量化解剖队列形状变异性的方法。近期研究引入了隐式径向基函数表示作为自监督信号，以更好地捕捉解剖结构的复杂几何特性。然而，这些方法仍缺乏自适应性——即无法自动调整粒子配置以适应每个表面的局部几何特征，而这对于准确表示复杂解剖变异性至关重要。本文提出了两种机制，在保持粒子配置一致性的同时提升表面适应性：1）一种新型邻域对应损失以实现高适应性；2）一种测地线对应算法，通过正则化优化强制测地线邻域一致性。我们在具有挑战性的数据集上评估了方法的有效性和可扩展性，详细分析了适应性与对应性的权衡，并在表面表示精度和对应性指标上与现有方法进行了对比。

</details>


### [70] [Multi-Scale Attention and Gated Shifting for Fine-Grained Event Spotting in Videos](https://arxiv.org/abs/2507.07381)
**中文标题：多尺度注意力与门移位用于视频中细粒度事件检测**

*Hao Xu,Arbind Agrahari Baniya,Sam Wells,Mohamed Reda Bouadjenek,Richard Dazeley,Sunil Aryal*

主要分类: cs.CV

摘要简述: 本文提出了一种多尺度注意力门移位模块（MSAGSM），用于增强视频中细粒度事件检测的时空建模能力，并在新提出的乒乓球数据集上验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的事件检测模型在时间感受野和空间适应性方面存在局限，无法有效捕捉视频中的短长期依赖关系和显著区域。

研究方法: 通过结合多尺度时间扩张和多头空间注意力机制，MSAGSM模块提升了门移位模块的时空建模能力，同时保持了轻量化和即插即用的特性。

研究结果: 在五个事件检测基准测试中，MSAGSM模块显著提升了性能，且计算开销极小，达到了新的最优水平。

研究结论: MSAGSM模块为细粒度事件检测提供了一种高效且通用的解决方案，并通过新数据集推动了该领域的发展。

中文摘要: 精确事件检测（PES）在体育视频中需要从单摄像头画面中识别帧级别的细粒度动作。现有的PES模型通常采用轻量级时间模块（如门移位模块GSM或门移位融合GSF）来为2D CNN特征提取器增加时间上下文。然而，这些模块在时间感受野和空间适应性方面存在局限。我们提出了一种多尺度注意力门移位模块（MSAGSM），通过多尺度时间扩张和多头空间注意力增强GSM，能够高效建模短长期依赖关系并聚焦显著区域。MSAGSM是一种轻量级即插即用模块，可轻松与多种2D骨干网络集成。为推进该领域，我们引入了Table Tennis Australia（TTA）数据集——首个针对乒乓球事件的PES基准，包含超过4800个精确标注的事件。在五个PES基准上的广泛实验表明，MSAGSM以极小的开销持续提升性能，创造了新的最优结果。

</details>


### [71] [KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos](https://arxiv.org/abs/2507.07393)
**中文标题：KeyRe-ID：基于关键点的视频行人重识别框架——利用部位感知表征**

*Jinseong Kim,Junghoon Song,Gyeongseon Baek,Byeongjoon Noh*

主要分类: cs.CV

摘要简述: 本文提出KeyRe-ID，一种基于关键点的视频行人重识别框架，通过全局和局部分支结合人体关键点增强时空表征学习，在MARS和iLIDS-VID基准测试中取得领先性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有行人重识别方法在复杂场景下表现不足，尤其是视频中动态变化的姿态和遮挡问题。本文旨在通过结合人体关键点信息，提升行人重识别的准确性和鲁棒性。

研究方法: KeyRe-ID框架包含全局分支和局部分支。全局分支通过Transformer进行时间聚合，捕捉整体身份语义；局部分支基于关键点动态分割身体区域，生成细粒度的局部特征。

研究结果: 在MARS数据集上达到91.73% mAP和97.32% Rank-1准确率，在iLIDS-VID数据集上达到96.00% Rank-1和100.0% Rank-5准确率，表现优于现有方法。

研究结论: KeyRe-ID通过结合关键点引导的全局和局部特征学习，显著提升了视频行人重识别的性能，为复杂场景下的应用提供了有效解决方案。

中文摘要: 我们提出了KeyRe-ID，一种基于关键点的视频行人重识别框架，包含全局和局部分支，利用人体关键点增强时空表征学习。全局分支通过基于Transformer的时间聚合捕捉整体身份语义，而局部分支基于关键点动态分割身体区域，生成细粒度的部位感知特征。在MARS和iLIDS-VID基准测试上的大量实验表明，该方法达到了领先性能，在MARS上实现了91.73% mAP和97.32% Rank-1准确率，在iLIDS-VID上实现了96.00% Rank-1和100.0% Rank-5准确率。代码将在论文发表后公开于GitHub。

</details>


### [72] [Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer](https://arxiv.org/abs/2507.07394)
**中文标题：行为你的运动：保留习惯的跨类别动物运动迁移**

*Zhimin Zhang,Bi'an Du,Caoyuan Ma,Zheng Wang,Wei Hu*

主要分类: cs.CV

摘要简述: 本文提出了一种保留习惯的跨类别动物运动迁移框架，通过引入习惯保留模块和类别特定习惯编码器，结合大语言模型，实现了对未观测物种的运动迁移，并在新数据集上验证了其优越性。


<details>
  <summary>详细信息</summary>
研究动机: 现有运动迁移方法主要关注人类运动，忽略了动物特有的行为习惯保留问题。本文旨在填补这一空白，提出一种能够保留动物独特习惯的跨类别运动迁移方法。

研究方法: 基于生成框架，模型引入了习惯保留模块和类别特定习惯编码器，学习捕捉动物习惯特征的运动先验。此外，结合大语言模型（LLM）支持未观测物种的运动迁移。

研究结果: 实验使用了新提出的DeformingThings4D-skl数据集，并通过定量分析验证了模型在保留动物习惯和跨类别运动迁移方面的优越性。

研究结论: 本文提出的框架成功解决了跨类别动物运动迁移中习惯保留的难题，为动画和虚拟现实应用提供了新工具。

中文摘要: 动物运动体现了物种特有的行为习惯，使得跨类别运动迁移成为动画和虚拟现实应用中关键而复杂的任务。现有运动迁移方法主要关注人类运动，强调骨骼对齐（运动重定向）或风格一致性（运动风格迁移），往往忽略了动物独特习惯行为的保留。为填补这一空白，我们提出了一种保留习惯的跨类别动物运动迁移框架。基于生成框架，我们的模型引入了包含类别特定习惯编码器的习惯保留模块，使其能够学习捕捉独特习惯特征的运动先验。此外，我们结合大语言模型（LLM）以支持未观测物种的运动迁移。为评估方法的有效性，我们引入了DeformingThings4D-skl数据集（一种带有骨骼绑定的四足动物数据集），并进行了广泛的实验和定量分析，验证了所提模型的优越性。

</details>


### [73] [Seg-Wild: Interactive Segmentation based on 3D Gaussian Splatting for Unconstrained Image Collections](https://arxiv.org/abs/2507.07395)
**中文标题：Seg-Wild：基于3D高斯泼溅的无约束图像集合交互式分割方法**

*Yongtang Bao,Chengjie Tang,Yuze Wang,Haojie Li*

主要分类: cs.CV

摘要简述: Seg-Wild是一种基于3D高斯泼溅的交互式分割方法，适用于无约束图像集合，通过多维度特征嵌入和Spiky 3D高斯切割器提升分割效果和重建质量。


<details>
  <summary>详细信息</summary>
研究动机: 无约束照片集合易于获取但存在光照不一致和瞬态遮挡问题，传统分割方法无法有效解决这些问题，因此需要一种适用于野外场景的新方法。

研究方法: Seg-Wild为每个3D高斯嵌入多维度特征，通过特征相似性实现交互式分割，并引入Spiky 3D高斯切割器（SGC）平滑异常高斯，结合SAM掩码计算切割比例。

研究结果: 实验表明，Seg-Wild在分割效果和重建质量上优于现有方法，适用于野外场景。

研究结论: Seg-Wild通过3D高斯泼溅和特征嵌入技术，显著提升了无约束图像集合的分割和重建能力。

中文摘要: 从互联网获取的无约束照片集合中重建和分割场景是一项新颖但具有挑战性的任务。无约束照片集合比精心拍摄的照片集合更易获取，但这些图像存在光照不一致和瞬态遮挡问题，增加了分割难度。传统分割方法无法解决瞬态遮挡或准确还原场景光照条件。因此，我们提出Seg-Wild，一种基于3D高斯泼溅的交互式分割方法，适用于野外场景。我们为每个3D高斯嵌入多维度特征，并通过特征相似性实现3D场景中的交互式分割。此外，我们引入Spiky 3D高斯切割器（SGC）平滑异常高斯，将3D高斯投影到2D平面，并使用SAM掩码计算需要切割的高斯比例。我们还设计了一个基准测试来评估野外场景的分割质量。实验结果表明，与现有方法相比，Seg-Wild在分割效果和重建质量上表现更优。代码将在https://github.com/Sugar0725/Seg-Wild发布。

</details>


### [74] [EscherNet++: Simultaneous Amodal Completion and Scalable View Synthesis through Masked Fine-Tuning and Enhanced Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2507.07410)
**中文标题：EscherNet++：通过掩码微调和增强前馈3D重建实现同步遮挡补全与可扩展视角合成**

*Xinan Zhang,Muhammad Zubair Irshad,Anthony Yezzi,Yi-Chang Tsai,Zsolt Kira*

主要分类: cs.CV

摘要简述: EscherNet++ 是一种基于掩码微调的扩散模型，能够零样本合成物体的新视角并完成遮挡部分。通过端到端设计，显著提升了新视角合成和遮挡完成能力，同时结合前馈3D重建模型，实现了快速且高质量的3D重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常采用多阶段复杂流程，先补全遮挡部分再合成新视角，忽略了跨视角依赖且计算冗余。本文旨在通过掩码微调实现端到端模型，同时提升新视角合成和遮挡完成能力。

研究方法: 提出EscherNet++，采用输入级和特征级掩码微调技术，实现端到端模型。结合前馈图像到网格模型，无需额外训练即可快速完成3D重建。

研究结果: 在遮挡任务中，PSNR提升3.9，Volume IoU提升0.28，重建时间减少95%，并在真实场景中表现出良好的泛化能力。

研究结论: EscherNet++ 在遮挡完成和新视角合成任务中达到最优性能，同时显著提升了3D重建效率。

中文摘要: 我们提出了EscherNet++，一种基于掩码微调的扩散模型，能够以零样本方式合成物体的新视角并具备遮挡补全能力。现有方法通常采用多阶段复杂流程，先补全遮挡部分再合成新视角，忽略了跨视角依赖且需要冗余存储和计算。相反，我们通过输入级和特征级掩码微调，实现了端到端模型，提升了新视角合成和遮挡补全能力。此外，我们通过实验将模型与其他前馈图像到网格模型结合，无需额外训练即可取得竞争性结果，重建时间减少95%。得益于其合成任意查询视角的能力，我们的方法进一步提升了快速3D重建的可扩展性。尽管在较小数据集和批量大小下微调，我们的方法仍达到了最优性能，在10输入设置下，遮挡任务的PSNR提升3.9，Volume IoU提升0.28，同时在真实场景的遮挡重建中表现出良好的泛化能力。

</details>


### [75] [EPIC: Efficient Prompt Interaction for Text-Image Classification](https://arxiv.org/abs/2507.07415)
**中文标题：EPIC：面向文本-图像分类的高效提示交互方法**

*Xinyao Yu,Hao Sun,Zeyu Ling,Ziwei Niu,Zhenjia Bai,Rui Qin,Yen-Wei Chen,Lanfen Lin*

主要分类: cs.CV

摘要简述: 本文提出了一种高效的提示交互策略EPIC，用于文本-图像分类任务，显著减少了计算资源消耗和可训练参数，同时在多个数据集上表现出色。


<details>
  <summary>详细信息</summary>
研究动机: 随着大规模预训练多模态模型（LMMs）的发展，其在多模态任务中取得了显著成功，但模型规模的增大导致微调成本高昂。因此，研究高效的提示交互策略以更高效地对齐模态成为必要。

研究方法: EPIC通过在中间层使用时序提示，并基于相似性的提示交互整合不同模态，实现了模态间充分的信息交换。该方法仅需约1%的基础模型可训练参数。

研究结果: 在UPMC-Food101和SNLI-VE数据集上表现优异，在MM-IMDB数据集上性能相当，同时显著减少了计算资源和可训练参数的需求。

研究结论: EPIC是一种高效的多模态交互策略，能够在减少资源消耗的同时保持或提升性能，为多模态任务提供了一种可行的解决方案。

中文摘要: 近年来，大规模预训练多模态模型（LMMs）逐渐兴起，成功整合了视觉与语言模态，在文本-图像分类等多模态任务中取得了显著成果。然而，LMMs规模的增大导致微调这些模型的计算成本显著增加。因此，研究基于提示的交互策略以更高效地对齐模态成为热点。在此背景下，我们提出了一种新颖的高效提示多模态交互策略，即面向文本-图像分类的高效提示交互方法（EPIC）。具体而言，我们在中间层使用时序提示，并通过基于相似性的提示交互整合不同模态，以实现模态间充分的信息交换。采用这一方法，我们的策略在计算资源消耗和可训练参数（约为基础模型的1%）方面均优于其他微调策略。此外，该方法在UPMC-Food101和SNLI-VE数据集上表现出色，同时在MM-IMDB数据集上性能相当。

</details>


### [76] [Corvid: Improving Multimodal Large Language Models Towards Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.07424)
**中文标题：Corvid：提升多模态大语言模型的链式思维推理能力**

*Jingjing Jiang,Chao Ma,Xurui Song,Hanwang Zhang,Jun Luo*

主要分类: cs.CV

摘要简述: 本文提出Corvid，一种增强链式思维推理能力的多模态大语言模型，通过混合视觉编码器和精心设计的跨模态对齐连接器（GateMixer）提升性能，并利用高质量数据集MCoT-Instruct-287K进行两阶段微调，显著优于同类模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前开源多模态大语言模型在复杂结构化推理任务中存在显著局限性，特别是在需要深度推理的决策和问题解决任务中。本文旨在通过增强链式思维推理能力，提升模型性能。

研究方法: Corvid采用混合视觉编码器生成信息丰富的视觉表示，并设计跨模态对齐连接器GateMixer。通过高质量数据集MCoT-Instruct-287K进行两阶段链式思维格式微调，并结合推理时自验证策略避免过度或不足推理。

研究结果: 实验表明，Corvid在数学推理和科学问题解决任务中表现优异，显著优于同类参数规模的多模态大语言模型。

研究结论: Corvid通过增强链式思维推理能力和跨模态对齐，在多模态任务中展现出卓越性能，为复杂推理任务提供了有效解决方案。

中文摘要: 近年来，多模态大语言模型（MLLMs）在感知和理解任务中表现出色，但开源模型在复杂结构化推理任务中存在显著不足。本文提出Corvid，一种具备增强链式思维（CoT）推理能力的MLLM。Corvid采用混合视觉编码器生成信息丰富的视觉表示，并通过精心设计的跨模态对齐连接器（GateMixer）促进模态间对齐。为提升CoT推理能力，我们引入高质量多模态CoT指令数据集MCoT-Instruct-287K，并通过两阶段链式思维格式微调逐步增强模型的逐步推理能力。此外，提出推理时自验证策略，避免过度或不足推理。实验表明，Corvid在数学推理和科学问题解决任务中优于同类模型。项目页面：https://mm-vl.github.io/corvid。

</details>


### [77] [Towards High-Resolution 3D Anomaly Detection: A Scalable Dataset and Real-Time Framework for Subtle Industrial Defects](https://arxiv.org/abs/2507.07435)
**中文标题：迈向高分辨率3D异常检测：针对细微工业缺陷的可扩展数据集与实时框架**

*Yuqi Cheng,Yihan Sun,Hui Zhang,Weiming Shen,Yunkang Cao*

主要分类: cs.CV

摘要简述: 本文提出了首个高分辨率3D异常检测数据集MiniShift，并开发了高效框架Simple3D，通过多尺度邻域描述符和局部特征空间聚合，实现了实时高精度检测。


<details>
  <summary>详细信息</summary>
研究动机: 工业点云分析中，现有基准数据集多关注低分辨率输入，难以检测细微异常。本文旨在填补这一空白，提供高分辨率数据及高效检测方法。

研究方法: 提出可扩展的3D异常生成流程，构建MiniShift数据集（2,577个点云，每个50万点）；开发Simple3D框架，结合多尺度邻域描述符（MSND）和局部特征空间聚合（LFSA），以低计算成本捕获几何细节。

研究结果: Simple3D在MiniShift和现有基准测试中表现优异，准确率和速度均超越现有方法，实时推理速度超过20 fps。

研究结论: 高分辨率数据和高效特征聚合对3D异常检测至关重要，Simple3D为工业应用提供了实用解决方案。

中文摘要: 在工业点云分析中，检测细微异常需要高分辨率空间数据，但现有基准多关注低分辨率输入。为解决这一问题，我们提出了一种可扩展的流程，用于生成真实且细微的3D异常。基于此流程，我们开发了首个高分辨率3D异常检测数据集MiniShift，包含2,577个点云，每个点云含50万个点，异常占比不足1%。此外，我们提出了Simple3D框架，整合多尺度邻域描述符（MSND）和局部特征空间聚合（LFSA），以最小计算开销捕获复杂几何细节，实现超过20 fps的实时推理。在MiniShift和现有基准上的广泛评估表明，Simple3D在准确率和速度上均超越现有方法，凸显了高分辨率数据和有效特征聚合对推动实用3D异常检测的关键作用。

</details>


### [78] [A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping](https://arxiv.org/abs/2506.13201)
**中文标题：深度学习在3D洪水制图中的全面解决方案综述**

*Wenfeng Jia,Bin Liang,Yuxi Liu,Muhammad Arif Khan,Lihong Zheng*

主要分类: cs.CV

摘要简述: 本文综述了深度学习在3D洪水制图中的应用，比较了任务分解和端到端方法，探讨了多种数据源及其应用，并指出了当前挑战与未来方向。


<details>
  <summary>详细信息</summary>
研究动机: 气候变化和城市化加剧了洪水灾害，传统2D洪水制图能力有限，深度学习驱动的3D洪水制图能整合洪水范围和深度，为灾害管理和城市规划提供更有效解决方案。

研究方法: 论文将深度学习技术分为任务分解和端到端方法，分析了静态和动态洪水特征的适用性，并比较了不同DL架构在预测精度和计算效率上的表现。同时探讨了数字高程模型、卫星图像等多种数据源的作用。

研究结果: 研究表明，3D洪水制图在实时预测、长期规划和风险评估中具有广泛应用，但仍面临数据稀缺、模型可解释性以及与流体动力学模型整合等挑战。

研究结论: 未来需通过改进数据集、优化模型和制定相关政策来提升3D洪水制图的可靠性，从而推动更有效的洪水管理策略。

中文摘要: 洪水是全球性挑战，气候变化和城市化加剧了其影响，亟需先进技术以提升灾害管理能力。传统2D洪水制图提供的信息有限，而基于深度学习（DL）的3D洪水制图通过整合洪水范围和深度，显著提升了能力。本文全面综述了基于深度学习的3D洪水制图，强调其在灾害管理和城市规划中的优势。调查将深度学习技术分为任务分解和端到端方法，适用于静态和动态洪水特征。我们比较了关键DL架构，突出其在提升预测精度和计算效率中的作用。此外，本文探讨了数字高程模型、卫星图像、降雨和模拟数据等多种数据源的作用及其在3D洪水制图中的应用。应用范围涵盖实时洪水预测、长期城市规划及风险评估。然而，仍存在数据稀缺、模型可解释性以及与流体动力学模型整合等挑战。最后，本文提出未来研究方向，包括改进数据集、优化模型及政策建议，旨在为研究人员和实践者提供指导，推动更可靠和高效的3D洪水制图技术，以优化洪水管理策略。

</details>


### [79] [Dual Semantic-Aware Network for Noise Suppressed Ultrasound Video Segmentation](https://arxiv.org/abs/2507.07443)
**中文标题：双重语义感知网络：用于噪声抑制的超声视频分割**

*Ling Zhou,Runtian Yuan,Yi Liu,Yuejie Zhang,Rui Feng,Shang Gao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DSANet的双重语义感知网络，旨在通过增强局部与全局特征的语义交互，抑制超声视频分割中的噪声干扰，显著提升分割精度与推理速度。


<details>
  <summary>详细信息</summary>
研究动机: 超声成像因其简单和非侵入性成为广泛使用的诊断工具，但其固有噪声特性为自动化病变或器官分割带来挑战。现有方法难以有效抑制噪声，因此需要一种更鲁棒的解决方案。

研究方法: DSANet包含两个核心模块：AFSA模块通过构建通道相似性矩阵指导相邻帧特征融合，减少随机噪声影响；LGSA模块则整合局部空间细节与全局时序上下文，实现多层次语义表示。

研究结果: 在四个基准数据集上的实验表明，DSANet在分割精度上显著优于现有方法，同时因避免像素级依赖，推理速度更快，甚至超过部分基于图像的方法。

研究结论: DSANet通过双重语义感知机制有效抑制噪声，提升超声视频分割性能，兼具高精度与高效率，为实际应用提供了可靠解决方案。

中文摘要: 超声成像是一种因其简单性和非侵入性而广泛使用的诊断工具。然而，其固有特性常引入大量噪声，为超声视频序列中自动化病变或器官分割带来显著挑战。为解决这些问题，我们提出了双重语义感知网络（DSANet），该框架通过增强局部与全局特征的语义交互，提升噪声鲁棒性。具体而言，我们设计了相邻帧语义感知（AFSA）模块，通过构建通道相似性矩阵指导相邻帧特征融合，有效抑制随机噪声，且无需依赖像素级关系。此外，我们提出了局部与全局语义感知（LGSA）模块，将独立捕获每帧空间细节的局部特征与整合相邻帧时序上下文的全局特征重组融合，实现多层次语义表示，显著提升模型抗噪声干扰能力。在四个基准数据集上的广泛实验表明，DSANet在分割精度上大幅领先现有方法。同时，由于模型避免了像素级特征依赖，其推理速度显著高于基于视频的方法，甚至超越部分基于图像的模型。代码可在\href{https://github.com/ZhouL2001/DSANet}{DSANet}获取。

</details>


### [80] [Bluish Veil Detection and Lesion Classification using Custom Deep Learnable Layers with Explainable Artificial Intelligence (XAI)](https://arxiv.org/abs/2507.07453)
**中文标题：基于自定义可学习深度学习层与可解释人工智能（XAI）的蓝白色面纱检测及病变分类**

*M. A. Rasel,Sameem Abdul Kareem,Zhenli Kwan,Shin Shen Yong,Unaizah Obaidellah*

主要分类: cs.CV

摘要简述: 本研究提出一种基于自定义深度学习层的蓝白色面纱（BWV）检测方法，结合可解释人工智能（XAI）技术，显著提升了皮肤病变分类的准确性，为黑色素瘤早期诊断提供了有力工具。


<details>
  <summary>详细信息</summary>
研究动机: 黑色素瘤是一种致命的皮肤癌，蓝白色面纱（BWV）是其诊断的关键特征，但目前针对BWV检测的研究有限。本研究旨在开发一种高效且可解释的BWV检测方法，以辅助早期诊断。

研究方法: 研究使用未标注的皮肤病变数据集，通过基于颜色阈值的成像算法转换为标注数据集。设计了一种深度卷积神经网络（DCNN），采用自定义层替代标准激活函数层，并在三个独立及合并的皮肤镜数据集上进行训练。随后应用XAI算法解释DCNN的决策过程。

研究结果: 提出的DCNN模型在多个数据集上表现优异：在增强的PH2数据集上测试准确率为85.71%，在增强的ISIC存档数据集上为95.00%，在合并的增强数据集（PH2+ISIC存档）上为95.05%，在Derm7pt数据集上为90.00%。XAI进一步提升了BWV检测的可解释性。

研究结论: 结合自定义深度学习层和XAI的方法显著提高了BWV检测的准确性和可解释性，为黑色素瘤的早期诊断提供了可靠工具。

中文摘要: 黑色素瘤是最致命的皮肤癌之一，全球每年导致数千人死亡。蓝白色面纱（BWV）是诊断黑色素瘤的关键特征，但对皮肤镜图像中BWV检测的研究较少。本研究利用未标注的皮肤病变数据集，通过基于颜色阈值的成像算法将其转换为标注数据集。设计了一种深度卷积神经网络（DCNN），采用自定义层替代标准激活函数层，并在三个独立及合并的皮肤镜数据集上进行训练，以基于BWV存在与否对皮肤病变进行分类。提出的DCNN在不同数据集上均优于传统BWV检测模型：在增强的PH2数据集上测试准确率为85.71%，在增强的ISIC存档数据集上为95.00%，在合并的增强数据集（PH2+ISIC存档）上为95.05%，在Derm7pt数据集上为90.00%。随后应用可解释人工智能（XAI）算法解释DCNN在BWV检测中的决策过程。该方法结合XAI显著提升了皮肤病变中BWV的检测能力，优于现有模型，为黑色素瘤早期诊断提供了可靠工具。

</details>


### [81] [Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision](https://arxiv.org/abs/2507.07460)
**中文标题：Objectomaly：基于对象感知的OoD分割优化框架——结构一致性与边界精度**

*Jeonghoon Song,Sunghun Kim,Jaegyun Im,Byeongjoon Noh*

主要分类: cs.CV

摘要简述: Objectomaly是一种基于对象感知的OoD分割优化框架，通过对象级先验知识提升边界精度和结构一致性，显著提高了异常分割性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于掩码的OoD分割方法存在边界不精确、对象内异常分数不一致以及背景噪声导致的误报问题。为解决这些问题，研究团队提出了Objectomaly框架。

研究方法: Objectomaly分为三个阶段：(1) 使用现有OoD骨干网络进行粗粒度异常评分（CAS）；(2) 利用SAM生成的实例掩码进行对象感知分数校准（OASC）；(3) 通过拉普拉斯滤波和高斯平滑实现精细边界优化（MBP）。

研究结果: Objectomaly在SMIYC AnomalyTrack/ObstacleTrack和RoadAnomaly等基准测试中表现优异，像素级（AuPRC高达96.99，FPR95低至0.07）和组件级（F1分数高达83.44）指标均显著提升。

研究结论: Objectomaly通过对象感知优化和边界精细化，显著提升了OoD分割的精度和鲁棒性，适用于自动驾驶等安全敏感场景。

中文摘要: 异常分布（OoD）分割在自动驾驶等安全敏感应用中至关重要。然而，现有的基于掩码的方法常因边界不精确、对象内异常分数不一致以及背景噪声导致的误报问题而受限。我们提出Objectomaly，一种基于对象感知的优化框架，结合对象级先验知识。Objectomaly包含三个阶段：(1) 使用现有OoD骨干网络进行粗粒度异常评分（CAS）；(2) 利用SAM生成的实例掩码进行对象感知分数校准（OASC）；(3) 通过拉普拉斯滤波和高斯平滑实现精细边界优化（MBP）。Objectomaly在SMIYC AnomalyTrack/ObstacleTrack和RoadAnomaly等关键OoD分割基准测试中达到领先水平，显著提升了像素级（AuPRC高达96.99，FPR95低至0.07）和组件级（F1分数高达83.44）指标。消融实验和真实驾驶视频的定性结果进一步验证了方法的鲁棒性和泛化能力。代码将在发表后开源。

</details>


### [82] [Degradation-Agnostic Statistical Facial Feature Transformation for Blind Face Restoration in Adverse Weather Conditions](https://arxiv.org/abs/2507.07464)
**中文标题：恶劣天气条件下盲人脸恢复的退化无关统计面部特征变换**

*Chang-Hwan Son*

主要分类: cs.CV

摘要简述: 本文提出了一种基于GAN的盲人脸恢复框架，通过局部统计面部特征变换（SFFT）和退化无关特征嵌入（DAFE）模块，显著提升了恶劣天气条件下的人脸图像恢复质量。


<details>
  <summary>详细信息</summary>
研究动机: 随着智能监控系统在户外环境中的广泛应用，恶劣天气条件下的人脸识别需求日益增长。然而，现有的人脸图像恢复（FIR）模型因缺乏专门针对天气退化的模块，导致恢复效果不佳，面部纹理和结构失真。

研究方法: 提出了一种新的GAN框架，包含局部统计面部特征变换（SFFT）和退化无关特征嵌入（DAFE）模块。SFFT通过对齐低质量（LQ）与高质量（HQ）面部区域的局部统计分布，提升结构保真度；DAFE通过对齐LQ和HQ编码器表示，实现恶劣天气下的鲁棒特征提取。

研究结果: 实验表明，该模型在恶劣天气条件下的人脸恢复任务中优于现有的GAN和扩散模型方法，尤其在抑制纹理失真和准确重建面部结构方面表现突出。SFFT和DAFE模块均显著提升了恢复图像的结构保真度和感知质量。

研究结论: 本文提出的退化无关SFFT模型通过结合SFFT和DAFE模块，有效解决了恶劣天气条件下的人脸恢复问题，为智能监控系统提供了更可靠的图像恢复方案。

中文摘要: 随着智能监控系统在户外环境中的广泛应用，针对恶劣天气条件下的人脸识别系统需求日益增长。恶劣天气会显著降低图像质量，从而影响识别精度。尽管基于生成对抗网络（GAN）和扩散模型的人脸图像恢复（FIR）方法已取得进展，但由于缺乏专门针对天气退化的模块，其性能仍受限，导致面部纹理和结构失真。为解决这一问题，我们提出了一种新的基于GAN的盲FIR框架，包含局部统计面部特征变换（SFFT）和退化无关特征嵌入（DAFE）两个关键模块。SFFT通过对齐低质量（LQ）与高质量（HQ）面部区域的局部统计分布，提升结构保真度和色彩准确性；DAFE通过对齐LQ和HQ编码器表示，实现恶劣天气下的鲁棒特征提取。实验结果表明，该退化无关SFFT模型在抑制纹理失真和准确重建面部结构方面优于现有的GAN和扩散模型方法。此外，SFFT和DAFE模块在提升恶劣天气条件下人脸恢复的结构保真度和感知质量方面均得到实证验证。

</details>


### [83] [Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking](https://arxiv.org/abs/2507.07483)
**中文标题：时序不可学习样本：防止个人视频数据被未经授权用于目标跟踪**

*Qiangqiang Wu,Yi Yu,Chenqi Kong,Ziquan Liu,Jia Wan,Haoliang Li,Alex C. Kot,Antoni B. Chan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为“时序不可学习样本（TUEs）”的新方法，用于防止个人视频数据被未经授权用于视觉目标跟踪（VOT）模型的训练。通过生成不可学习的噪声，TUEs能够破坏跟踪器的学习能力，从而保护视频数据的隐私。实验表明，该方法在视频隐私保护方面表现优异，并具有强泛化能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着社交媒体的兴起，大量用户上传的视频（如YouTube）被用作视觉目标跟踪（VOT）的训练数据，但视频数据的隐私问题被忽视。许多私人视频未经授权就被用于商业模型的训练。现有方法主要针对图像任务，直接应用于视频时效率低、效果有限且泛化性差。因此，本文旨在解决视频数据隐私保护的问题。

研究方法: 本文提出了一种生成时序不可学习样本（TUEs）的框架。TUEs通过高效计算生成不可学习的噪声，使跟踪器在训练时依赖这些噪声而忽略原始数据结构，从而保护数据隐私。此外，还引入了时序对比损失，进一步破坏跟踪器的学习能力。

研究结果: 实验表明，TUEs在视频数据隐私保护方面达到了最先进的性能，且在不同VOT模型、数据集和时序匹配任务中表现出强泛化能力。

研究结论: 本文提出的TUEs方法有效解决了视频数据隐私保护的问题，为未经授权使用视频数据的场景提供了一种可行的解决方案。

中文摘要: 随着社交媒体的兴起，大量用户上传的视频（如YouTube）被用作视觉目标跟踪（VOT）的训练数据。然而，VOT社区普遍忽视了视频数据的隐私问题，许多私人视频未经授权就被用于商业模型的训练。为解决这一问题，本文首次研究了如何防止个人视频数据被未经授权用于深度跟踪器的训练。现有的防止数据未经授权使用的方法主要针对图像任务（如图像分类），直接应用于视频时存在效率低、效果有限和泛化性差等问题。为此，我们提出了一种生成时序不可学习样本（TUEs）的新框架，其高效计算使其适用于大规模视频数据集。使用TUEs训练的跟踪器会严重依赖不可学习的噪声进行时序匹配，从而忽略原始数据结构，确保训练视频数据的隐私。为增强TUEs的效果，我们引入了时序对比损失，进一步破坏现有跟踪器在使用TUEs训练时的学习能力。大量实验表明，我们的方法在视频数据隐私保护方面达到了最先进的性能，并在不同VOT模型、数据集和时序匹配任务中表现出强泛化能力。

</details>


### [84] [Driving by Hybrid Navigation: An Online HD-SD Map Association Framework and Benchmark for Autonomous Vehicles](https://arxiv.org/abs/2507.07487)
**中文标题：混合导航驱动：自动驾驶车辆的在线高精-标准地图关联框架与基准**

*Jiaxu Wan,Xu Wang,Mengwei Xie,Xinyuan Chang,Xinran Liu,Zheng Pan,Mu Xu,Ding Yuan*

主要分类: cs.CV

摘要简述: 本文提出了首个面向混合导航的在线地图关联基准OMA，并提出了基于路径感知和空间注意力机制的Map Association Transformer框架，以提升自动驾驶车辆的规划能力。


<details>
  <summary>详细信息</summary>
研究动机: 自动驾驶车辆依赖全球标准定义（SD）地图进行道路级规划，同时需要在线高精（HD）地图进行车道级导航。然而，现有研究多集中于构建在线HD地图，忽视了SD与HD地图的关联问题，导致实际应用中难以充分利用在线HD地图。本文旨在填补这一空白，提升自动驾驶车辆的导航能力。

研究方法: 本文提出了OMA基准，包含48万条道路和26万条车道路径，并提供了相应的评估指标。同时，提出了Map Association Transformer框架，利用路径感知注意力和空间注意力机制，理解几何和拓扑对应关系。

研究结果: OMA基准和Map Association Transformer框架成功实现了SD与HD地图的有效关联，提升了自动驾驶车辆的规划能力。代码和数据集已开源。

研究结论: 本文通过OMA基准和Map Association Transformer框架，解决了SD与HD地图关联的挑战，为自动驾驶车辆的混合导航提供了实用工具。

中文摘要: 自动驾驶车辆依赖全球标准定义（SD）地图进行道路级规划，同时需要在线高精（HD）地图进行车道级导航。然而，现有研究多集中于构建在线HD地图，忽视了SD与HD地图的关联问题，导致实际应用中难以充分利用在线HD地图。针对自动驾驶车辆在导航能力上的不足，我们提出了首个面向混合导航的在线地图关联基准OMA，以提升自动驾驶车辆的规划能力。基于现有数据集，OMA包含48万条道路和26万条车道路径，并提供了相应的评估指标。此外，我们提出了一种名为Map Association Transformer的新框架作为基线方法，利用路径感知注意力和空间注意力机制，理解几何和拓扑对应关系。代码和数据集可在https://github.com/WallelWan/OMA-MAT获取。

</details>


### [85] [Divergence Minimization Preference Optimization for Diffusion Model Alignment](https://arxiv.org/abs/2507.07510)
**中文标题：扩散模型对齐的散度最小化偏好优化**

*Binxu Li,Minkai Xu,Meihua Dang,Stefano Ermon*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DMPO的新方法，通过最小化反向KL散度来优化扩散模型的对齐问题，显著提升了生成图像与人类偏好的匹配度，实验证明其优于现有基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在生成逼真图像方面取得了显著成功，但如何进一步与人类偏好对齐仍是一个挑战。现有方法通常陷入次优的均值优化，本文从散度最小化的角度出发，提出更优的对齐方案。

研究方法: 本文提出DMPO方法，通过最小化反向KL散度来对齐扩散模型，理论分析表明其优化方向与原始强化学习一致，实验验证了其有效性。

研究结果: 实验表明，DMPO在所有评估数据集上均优于现有基线方法，PickScore指标提升至少64.6%，证明了其在生成行为与期望输出对齐方面的优越性。

研究结论: DMPO为扩散模型的对齐提供了一种稳健且优雅的途径，将理论原则与实际性能紧密结合，显著提升了生成模型的对齐效果。

中文摘要: 扩散模型在从文本提示生成逼真且多样化的图像方面取得了显著成功。受语言模型最新进展的启发，如何进一步通过与人类偏好对齐来改进模型引起了广泛关注。然而，我们从散度最小化的角度研究了对齐问题，发现现有的偏好优化方法通常陷入次优的均值优化。本文提出了一种新颖且原则性的方法——散度最小化偏好优化（DMPO），通过最小化反向KL散度来对齐扩散模型，其优化方向与原始强化学习渐近一致。我们提供了严格的理论分析以证明DMPO的有效性，并通过全面的实验验证了其在人类评估和自动指标上的优势。实验结果表明，经过DMPO微调的扩散模型在所有评估数据集上均优于或匹配现有技术，特别是在PickScore指标上比所有现有基线方法至少高出64.6%，展示了该方法在生成行为与期望输出对齐方面的优越性。总体而言，DMPO为偏好对齐提供了一条稳健且优雅的途径，将理论原则与扩散模型的实际性能紧密结合。

</details>


### [86] [GGMotion: Group Graph Dynamics-Kinematics Networks for Human Motion Prediction](https://arxiv.org/abs/2507.07515)
**中文标题：GGMotion：基于分组图动力学-运动学网络的人体运动预测**

*Shuaijin Wan,Huaijiang Sun*

主要分类: cs.CV

摘要简述: GGMotion提出了一种基于分组图动力学-运动学网络的方法，通过建模人体拓扑结构的分组关系，结合动态和运动学先验，显著提升了人体运动预测的准确性和物理合理性。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法通常将人体姿态表示为抽象图结构，忽略了关节之间的物理依赖关系，导致学习困难且易生成不真实的运动。GGMotion旨在通过分组建模和几何等变性改进这一问题。

研究方法: GGMotion采用分组图网络，提出了一种新颖的径向场来捕捉时空依赖关系，并通过组内和组间交互模块捕获多尺度关节依赖。结合等变多层感知机（MLP），通过并行化的动力学-运动学传播更新关节位置特征。

研究结果: 在Human3.6M、CMU-Mocap和3DPW三个标准基准测试中，GGMotion表现出色，显著提升了短期运动预测的性能。

研究结论: GGMotion通过分组建模和几何等变性，有效提升了人体运动预测的物理合理性和准确性，为相关领域提供了新的解决方案。

中文摘要: 人体运动是一个受复杂动态和运动学约束的连续物理过程。现有方法通常将人体姿态表示为抽象图结构，忽略了关节之间的内在物理依赖关系，增加了学习难度并使模型易生成不真实的运动。本文提出GGMotion，一种分组图动力学-运动学网络，通过分组建模人体拓扑结构以更好地利用动态和运动学先验。为保持3D空间中的几何等变性，我们提出了一种新颖的径向场，通过空间和时间边聚合关节特征以捕捉更全面的时空依赖关系。采用组内和组间交互模块捕获不同尺度的关节依赖关系。结合等变多层感知机（MLP），通过并行化的动力学-运动学传播更新各组关节位置特征以提高物理合理性。同时，我们引入辅助损失以监督训练过程中的运动先验。在Human3.6M、CMU-Mocap和3DPW三个标准基准测试上的大量实验证明了该方法的有效性和优越性，在短期运动预测中取得了显著的性能提升。代码已开源：https://github.com/inkcat520/GGMotion.git。

</details>


### [87] [MUVOD: A Novel Multi-view Video Object Segmentation Dataset and A Benchmark for 3D Segmentation](https://arxiv.org/abs/2507.07519)
**中文标题：MUVOD：一种新颖的多视角视频目标分割数据集及3D分割基准**

*Bangning Wei,Joshua Maraval,Meriem Outtas,Kidiyo Kpalma,Nicolas Ramin,Lu Zhang*

主要分类: cs.CV

摘要简述: 本文提出了MUVOD，一个新的多视角视频数据集，用于动态场景中的4D目标分割任务，填补了该领域数据集的空白，并提供了基准评估指标和基线方法。


<details>
  <summary>详细信息</summary>
研究动机: 由于缺乏足够大且标注准确的多视角视频数据集，动态场景的4D目标分割研究进展缓慢。本文旨在通过提供MUVOD数据集，推动该领域的研究。

研究方法: MUVOD数据集包含17个场景，每个场景至少9个视角，最多46个视角，共7830张RGB图像及其对应的4D运动分割掩码。数据集包含73个类别的459个实例，并提供了评估指标和基线分割方法。

研究结果: MUVOD数据集为多视角视频分割方法提供了基准测试平台，并提出了一个包含50个不同场景对象的子集，用于更全面的3D目标分割方法分析。

研究结论: MUVOD数据集填补了动态场景4D目标分割领域的数据空白，为未来研究提供了重要资源，并推动了该领域的技术发展。

中文摘要: 基于神经辐射场（NeRF）和3D高斯泼溅（3D GS）的方法在静态场景的3D目标分割中逐渐流行，并在多种3D场景理解和编辑任务中表现出色。然而，由于缺乏足够大且标注准确的多视角视频数据集，动态场景的4D目标分割研究仍处于探索阶段。本文提出了MUVOD，一个用于重建真实场景中目标分割训练和评估的新多视角视频数据集。17个选定的场景描述了各种室内或室外活动，数据来源于不同类型的相机设备。每个场景包含最少9个视角，最多46个视角。我们提供了7830张RGB图像（每段视频30帧）及其对应的4D运动分割掩码，使得场景中的任何目标可以在时间帧或不同视角中被跟踪。该数据集包含73个类别的459个实例，旨在作为多视角视频分割方法的基准评估工具。我们还提供了评估指标和基线分割方法，以推动和评估该领域的发展。此外，我们从MUVOD数据集中选取了一个标注多视角图像的子集，提出了一个新的3D目标分割任务基准。该子集包含不同场景中的50个对象，为现有3D目标分割方法提供了更全面的分析。MUVOD数据集可在https://volumetric-repository.labs.b-com.com/#/muvod获取。

</details>


### [88] [Spline Deformation Field](https://arxiv.org/abs/2507.07521)
**中文标题：样条变形场**

*Mingyang Song,Yang Zhang,Marko Mihajlovic,Siyu Tang,Markus Gross,Tunç Ozan Aydın*

主要分类: cs.CV

摘要简述: 本文提出了一种基于样条的轨迹表示方法，通过显式控制节点数量来保持空间一致性和加速度，同时减少时间波动。该方法在稀疏输入下表现出优越的时间插值性能，并在动态场景重建中达到与先进方法竞争的效果。


<details>
  <summary>详细信息</summary>
研究动机: 当前密集点轨迹建模常使用隐式变形场，但神经网络的归纳偏置可能在不适定场景中破坏空间一致性。现有方法要么依赖不透明的编码策略，要么采用启发式节点初始化的显式技术。此外，隐式表示在稀疏时间信号插值方面的潜力尚未充分探索。

研究方法: 提出基于样条的轨迹表示方法，通过节点数量显式控制自由度，实现高效的速度解析推导。引入低秩时变空间编码，替代传统的耦合时空技术，以建模节点在时空域中的特性。

研究结果: 该方法在稀疏输入下表现出优越的时间插值性能，并在动态场景重建中达到与先进方法竞争的效果，同时增强了运动一致性，无需依赖线性混合蒙皮或尽可能刚性的约束。

研究结论: 基于样条的轨迹表示方法在保持空间一致性和加速度的同时，有效减少了时间波动，为稀疏时间信号插值和动态场景重建提供了高效且直观的解决方案。

中文摘要: 密集点的轨迹建模通常采用隐式变形场，通过神经网络将坐标映射以关联规范空间位置与时间偏移。然而，神经网络固有的归纳偏置可能在不适定场景中破坏空间一致性。现有方法要么专注于增强变形场的编码策略，导致模型不透明且缺乏直观性，要么采用基于启发式节点初始化的显式技术（如线性混合蒙皮）。此外，隐式表示在稀疏时间信号插值方面的潜力尚未充分探索。为解决这些问题，我们提出了一种基于样条的轨迹表示方法，其中节点数量显式决定了自由度。这种方法能够高效解析推导速度，保持空间一致性和加速度，同时减少时间波动。为了建模节点在时空域中的特性，我们引入了一种新颖的低秩时变空间编码，替代传统的耦合时空技术。我们的方法在稀疏输入下拟合连续场时表现出优越的时间插值性能，同时在动态场景重建中达到与先进方法竞争的效果，且无需依赖线性混合蒙皮或尽可能刚性的约束，增强了运动一致性。

</details>


### [89] [MAPEX: Modality-Aware Pruning of Experts for Remote Sensing Foundation Models](https://arxiv.org/abs/2507.07527)
**中文标题：MAPEX：遥感基础模型的模态感知专家剪枝**

*Joelle Hanna,Linus Scheibenreif,Damian Borth*

主要分类: cs.CV

摘要简述: MAPEX是一种基于多模态专家混合的遥感基础模型，通过模态感知的专家剪枝技术，针对特定任务保留相关模态专家，简化微调与部署，并在实验中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有遥感基础模型通常专注于特定模态（如光学RGB或多光谱数据），导致任务模态与预训练数据不匹配，且模型规模庞大，微调成本高。MAPEX旨在解决这一问题。

研究方法: MAPEX基于多模态遥感数据预训练，采用模态条件令牌路由机制激活模态特定专家。通过模态感知剪枝技术，仅保留任务相关模态专家，生成高效模型。

研究结果: MAPEX在多种遥感数据集上表现优异，优于全监督训练和现有遥感基础模型。

研究结论: MAPEX通过模态感知剪枝技术有效解决了模态不匹配问题，简化了模型微调与部署，为遥感任务提供了高效解决方案。

中文摘要: 遥感数据常用于洪水制图、野火检测或土地利用研究等任务。科学家们通常为每项任务精心选择合适模态或利用专用仪器数据。近期关于遥感基础模型的研究通过大量遥感数据预训练计算机视觉模型。这些大规模模型往往专注于特定模态（如光学RGB或多光谱数据），导致应用模态与预训练数据不匹配。此外，基础模型规模庞大，使其在通常较小的任务数据集上微调成本高昂且困难。为解决这一问题，我们提出了MAPEX，一种基于多模态专家混合的遥感基础模型。MAPEX通过新型模态条件令牌路由机制在多模态遥感数据上预训练，激活模态特定专家。针对特定任务，我们提出模态感知剪枝技术，仅保留任务相关模态专家，生成高效模态特定模型，同时简化目标模态的微调与部署。我们在多种遥感数据集上实验验证了MAPEX，其性能优于全监督训练和现有遥感基础模型。代码见https://github.com/HSG-AIML/MAPEX。

</details>


### [90] [Beyond the Linear Separability Ceiling](https://arxiv.org/abs/2507.07574)
**中文标题：超越线性可分性天花板**

*Enrico Vompa,Tanel Tammet,Mohit Vaishnav*

主要分类: cs.CV

摘要简述: 当前视觉-语言模型（VLMs）在抽象推理任务中受限于视觉嵌入的线性可分性，称为“线性推理瓶颈”。研究发现，这一瓶颈源于语言模型的推理路径问题，而非感知能力不足。通过任务依赖的干预（如激活现有路径或调整核心权重），可以解决这一对齐问题。研究还发现，VLMs中存在强大的休眠推理路径，但复杂关系任务需要更深层次的适应。


<details>
  <summary>详细信息</summary>
研究动机: 当前最先进的视觉-语言模型（VLMs）在抽象推理任务中表现受限，研究者认为这是由于视觉嵌入的线性可分性导致的“线性推理瓶颈”。本文旨在探究这一瓶颈的根源，并探索如何通过任务依赖的干预方法提升模型的推理能力。

研究方法: 研究引入了“线性可分性天花板（LSC）”概念，通过线性分类器在VLM视觉嵌入上的性能来量化瓶颈。采用后置调优（postfix tuning）作为方法控制，验证了VLMs中存在休眠的推理路径。针对不同任务需求，分别采用激活现有路径或调整核心权重的方法进行干预。

研究结果: 研究发现，线性推理瓶颈普遍存在，且源于语言模型的推理路径问题而非感知能力不足。通过任务依赖的干预（如语义概念任务激活现有路径，复杂关系任务调整核心权重），可以显著提升性能。然而，复杂任务需要更深层次的适应，单纯改进表示质量可能导致模型在新提示格式下失败。

研究结论: 研究表明，VLMs的稳健推理能力取决于有针对性的对齐策略，而非简单的表示学习改进。研究为VLM分析提供了新视角，揭示了通过任务依赖的干预可以解锁模型的潜在推理能力。

中文摘要: 大多数最先进的视觉-语言模型（VLMs）在抽象推理任务中似乎受限于其视觉嵌入的线性可分性。本文通过引入“线性可分性天花板（LSC）”（即简单线性分类器在VLM视觉嵌入上的性能）来研究这一“线性推理瓶颈”。研究发现，这一瓶颈普遍存在，且并非源于感知能力不足，而是语言模型推理路径的失败。研究表明这是一个可解决的对齐问题，但干预方法因任务而异：语义概念任务仅需激活现有路径，而复杂关系推理则需要调整核心模型权重。通过后置调优作为方法控制，研究发现VLMs中存在强大但休眠的推理路径。然而，对于需要更深层次适应的复杂关系任务，单纯改进表示质量会导致模型在新提示格式下失败，尽管其嵌入仍保持良好可分性。最终，本研究为VLM分析提供了新视角，表明稳健推理的关键在于有针对性的对齐，而非简单的表示学习改进。

</details>


### [91] [Diffusion-Guided Knowledge Distillation for Weakly-Supervised Low-Light Semantic Segmentation](https://arxiv.org/abs/2507.07578)
**中文标题：扩散引导的知识蒸馏用于弱监督低光语义分割**

*Chunyan Wang,Dong Zhang,Jinhui Tang*

主要分类: cs.CV

摘要简述: 本文提出了一种名为DGKD-WLSS的新框架，通过结合扩散引导的知识蒸馏和深度引导的特征融合，解决了弱监督低光语义分割中的图像质量退化和弱监督限制问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有方法在弱监督语义分割中表现良好，但在低光环境下性能显著下降，主要由于图像质量退化（如低对比度、噪声和颜色失真）和弱监督的固有限制。这些问题导致不可靠的类别激活图和语义模糊的伪标签，影响模型学习判别性特征的能力。

研究方法: 提出的DGKD-WLSS框架结合了扩散引导的知识蒸馏（DGKD）和深度引导的特征融合（DGF2）。DGKD通过基于扩散的去噪和知识蒸馏对齐正常光和低光特征，而DGF2利用深度图作为光照不变的几何先验，增强结构特征学习。

研究结果: 大量实验表明，DGKD-WLSS在弱监督低光语义分割任务中实现了最先进的性能，显著优于现有方法。

研究结论: DGKD-WLSS通过结合扩散引导的知识蒸馏和深度引导的特征融合，有效解决了低光环境下弱监督语义分割的挑战，为相关任务提供了新的解决方案。

中文摘要: 弱监督语义分割旨在利用弱标注为每个像素分配类别标签，显著降低人工标注成本。尽管现有方法在光照充足场景中取得了显著进展，但在低光环境中性能显著下降，主要由于两个根本限制：严重的图像质量退化（如低对比度、噪声和颜色失真）和弱监督的固有约束。这些因素共同导致不可靠的类别激活图和语义模糊的伪标签，最终影响模型学习判别性特征的能力。为解决这些问题，我们提出了一种名为DGKD-WLSS的新框架，将扩散引导的知识蒸馏（DGKD）与深度引导的特征融合（DGF2）协同结合。DGKD通过基于扩散的去噪和知识蒸馏对齐正常光和低光特征，而DGF2利用深度图作为光照不变的几何先验，增强结构特征学习。大量实验证明了DGKD-WLSS的有效性，其在弱监督低光语义分割任务中实现了最先进的性能。源代码已发布于：https://github.com/ChunyanWang1/DGKD-WLSS。

</details>


### [92] [NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning](https://arxiv.org/abs/2507.07579)
**中文标题：NexViTAD：基于视觉基础模型和多任务学习的少样本无监督跨域缺陷检测**

*Tianwei Mu,Feiyu Duan,Bo Zhou,Dan Xue,Manhong Huang*

主要分类: cs.CV

摘要简述: 本文提出了一种基于视觉基础模型的少样本跨域异常检测框架NexViTAD，通过共享子空间投影和多任务学习模块有效解决工业异常检测中的域偏移问题，并在MVTec AD数据集上实现了97.5%的AUC、70.4%的AP和95.2%的PRO，性能优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 工业异常检测中，跨域数据分布差异（域偏移）导致模型性能下降。本文旨在通过视觉基础模型和多任务学习，解决少样本条件下跨域异常检测的挑战。

研究方法: 1. 提出分层适配器模块，融合Hiera和DINO-v2预训练模型的互补特征；2. 采用共享子空间投影策略，通过瓶颈维度约束和跳跃连接实现跨域知识迁移；3. 设计多任务解码器架构，支持多源域同时处理；4. 基于Sinkhorn-K-means聚类、高斯滤波和自适应阈值处理的异常评分推断方法。

研究结果: 在MVTec AD数据集上，NexViTAD的AUC为97.5%，AP为70.4%，PRO为95.2%，显著优于其他最新模型。

研究结论: NexViTAD通过创新的特征融合和跨域知识迁移策略，显著提升了少样本跨域异常检测的性能，为工业缺陷检测提供了新的解决方案。

中文摘要: 本文提出了一种基于视觉基础模型的少样本跨域异常检测框架NexViTAD，通过创新的共享子空间投影机制和多任务学习模块，有效解决了工业异常检测中的域偏移问题。主要创新包括：（1）分层适配器模块，自适应融合Hiera和DINO-v2预训练模型的互补特征，构建更鲁棒的特征表示；（2）共享子空间投影策略，通过瓶颈维度约束和跳跃连接机制实现有效的跨域知识迁移；（3）多任务解码器架构，支持同时处理多个源域，显著增强模型泛化能力；（4）基于Sinkhorn-K-means聚类的异常评分推断方法，结合高斯滤波和自适应阈值处理，实现精确的像素级检测。在MVTec AD数据集上的实验表明，NexViTAD在目标域中实现了97.5%的AUC、70.4%的AP和95.2%的PRO，性能优于其他最新模型，标志着跨域缺陷检测领域的重大突破。

</details>


### [93] [HOTA: Hierarchical Overlap-Tiling Aggregation for Large-Area 3D Flood Mapping](https://arxiv.org/abs/2507.07585)
**中文标题：HOTA：用于大范围3D洪水测绘的分层重叠分块聚合方法**

*Wenfeng Jia,Bin Liang,Yuxi Lu,Attavit Wilaiwongsakul,Muhammad Arif Khan,Lihong Zheng*

主要分类: cs.CV

摘要简述: 本文提出HOTA方法，通过多尺度推理策略结合SegFormer和深度估计模块，实现高效的大范围3D洪水测绘，显著提升精度。


<details>
  <summary>详细信息</summary>
研究动机: 洪水是常见的自然灾害，现有测绘方法常因覆盖范围或忽略深度信息而受限。本文旨在开发一种既能保留空间细节又能覆盖大范围的3D洪水测绘方法。

研究方法: HOTA采用分层重叠分块聚合策略，结合SegFormer模型和基于DEM的深度估计模块，通过多尺度分块推理捕捉局部和公里级洪水特征，无需调整网络权重或重新训练。

研究结果: 在澳大利亚Kempsey洪水案例中，HOTA将IoU从73%提升至84%，边界误差小于0.5米，证明了其在大范围3D洪水测绘中的高精度。

研究结论: HOTA能够生成适合快速灾害响应的高精度大范围3D洪水地图，为灾害管理提供了有力工具。

中文摘要: 洪水是最常见的自然灾害之一，对社会和经济造成重大损害。及时获取大范围的洪水范围和深度信息对灾害响应至关重要，但现有产品常因覆盖范围或忽略深度信息而受限。为此，本文提出HOTA：分层重叠分块聚合，一种即插即用的多尺度推理策略。结合SegFormer和双约束深度估计模块，该方法形成完整的3D洪水测绘流程。HOTA仅在推理阶段对多光谱Sentinel-2图像应用不同大小的重叠分块，使SegFormer模型能够在不改变网络权重或重新训练的情况下捕捉局部特征和公里级淹没范围。后续的深度模块基于数字高程模型（DEM）差分方法，通过强制（i）洪水边界深度为零和（ii）洪水体积相对于DEM接近恒定，优化2D掩模并估计洪水深度。以2021年3月澳大利亚Kempsey洪水为例，HOTA结合SegFormer将IoU从73%（U-Net基线）提升至84%，生成的3D表面边界平均绝对误差小于0.5米。结果表明，HOTA能够生成适合快速灾害响应的高精度大范围3D洪水地图。

</details>


### [94] [Stable-Hair v2: Real-World Hair Transfer via Multiple-View Diffusion Model](https://arxiv.org/abs/2507.07591)
**中文标题：Stable-Hair v2：基于多视角扩散模型的真实世界头发转移**

*Kuiyuan Sun,Yuxuan Zhang,Jichao Zhang,Jiaming Liu,Wei Wang,Niculae Sebe,Yao Zhao*

主要分类: cs.CV

摘要简述: 本文提出Stable-Hair v2，一种基于扩散模型的多视角头发转移框架，首次利用多视角扩散模型实现跨视角的稳健、高保真和视角一致的头发转移。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在捕捉复杂发型方面表现出色，但在生成一致且高质量的多视角输出方面仍有不足，这对数字人和虚拟化身等实际应用至关重要。本文旨在填补这一空白。

研究方法: 提出一种多视角训练数据生成流程，包括基于扩散的秃头转换器、数据增强修复模型和面部微调的多视角扩散模型。模型整合极方位嵌入进行姿态条件化，并使用时态注意力层确保视角间平滑过渡。采用多阶段训练策略优化模型。

研究结果: 实验表明，该方法能准确将详细且真实的发型转移到目标对象，并在多视角间实现无缝一致的效果，显著优于现有方法，成为多视角头发转移的新标杆。

研究结论: Stable-Hair v2通过多视角扩散模型和创新的训练策略，实现了高质量、视角一致的头发转移，为相关应用提供了新基准。

中文摘要: 尽管基于扩散的方法在捕捉多样且复杂的发型方面表现出色，但其生成一致且高质量的多视角输出的能力——对数字人和虚拟化身等实际应用至关重要——仍未被充分探索。本文提出Stable-Hair v2，一种新颖的基于扩散的多视角头发转移框架。据我们所知，这是首次利用多视角扩散模型实现跨视角的稳健、高保真和视角一致的头发转移。我们引入了一套全面的多视角训练数据生成流程，包括基于扩散的秃头转换器、数据增强修复模型和面部微调的多视角扩散模型，以生成高质量的三元组数据（秃头图像、参考发型和视角对齐的源-秃头对）。我们的多视角头发转移模型整合了极方位嵌入进行姿态条件化，并使用时态注意力层确保视角间的平滑过渡。为优化该模型，我们设计了一种新颖的多阶段训练策略，包括姿态可控的潜在IdentityNet训练、头发提取器训练和时态注意力训练。大量实验表明，我们的方法能准确将详细且真实的发型转移到目标对象，并在多视角间实现无缝一致的效果，显著优于现有方法，成为多视角头发转移的新标杆。代码公开于https://github.com/sunkymepro/StableHairV2。

</details>


### [95] [HiM2SAM: Enhancing SAM2 with Hierarchical Motion Estimation and Memory Optimization towards Long-term Tracking](https://arxiv.org/abs/2507.07603)
**中文标题：HiM2SAM：通过分层运动估计和内存优化增强SAM2以实现长期跟踪**

*Ruixiang Chen,Guolei Sun,Yawei Li,Jie Qin,Luca Benini*

主要分类: cs.CV

摘要简述: 本文提出HiM2SAM方法，通过分层运动估计和内存优化增强SAM2框架，显著提升长期目标跟踪性能，无需额外训练。


<details>
  <summary>详细信息</summary>
研究动机: 视频目标跟踪任务面临遮挡、背景干扰和目标重现等挑战，现有方法如SAM2在长期跟踪中表现不足。本文旨在通过分层运动估计和内存优化提升跟踪准确性和鲁棒性。

研究方法: 提出分层运动估计策略，结合轻量级线性预测和选择性非线性优化；优化内存银行，区分长期和短期记忆帧，以应对遮挡和外观变化。

研究结果: 实验表明，HiM2SAM在LaSOT和LaSOText数据集上表现优异，大模型AUC相对提升9.6%和7.2%，小模型增益更显著。

研究结论: HiM2SAM通过无训练、低开销的改进显著提升长期跟踪性能，为视频目标跟踪任务提供了高效解决方案。

中文摘要: 本文针对视频目标跟踪任务中的遮挡、背景干扰和目标重现等挑战，提出了对SAM2框架的改进方法。我们引入了一种分层运动估计策略，结合轻量级线性预测和选择性非线性优化，无需额外训练即可提升跟踪精度。此外，通过区分长期和短期记忆帧优化内存银行，显著提升了长期遮挡和外观变化下的跟踪可靠性。实验结果表明，不同规模模型均取得一致改进。在LaSOT和LaSOText数据集上，大模型的AUC相对原始SAM2分别提升了9.6%和7.2%，小模型的增益更为显著，凸显了本文无训练、低开销改进对长期跟踪性能的有效提升。代码已开源：https://github.com/LouisFinner/HiM2SAM。

</details>


### [96] [LOSC: LiDAR Open-voc Segmentation Consolidator](https://arxiv.org/abs/2507.07605)
**中文标题：LOSC：激光雷达开放词汇分割整合器**

*Nermin Samet,Gilles Puy,Renaud Marlet*

主要分类: cs.CV

摘要简述: 本文提出了一种名为LOSC的方法，利用基于图像的视觉语言模型（VLMs）对激光雷达扫描进行开放词汇分割。通过将图像语义反向投影到3D点云并优化标签，LOSC在零样本开放词汇语义和全景分割任务中显著优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法将图像语义反向投影到3D点云时，生成的标签通常存在噪声和稀疏性问题。本文旨在通过优化标签的时空一致性和对图像级增强的鲁棒性，提升激光雷达扫描的开放词汇分割性能。

研究方法: LOSC方法首先将图像语义反向投影到3D点云，然后通过优化标签的时空一致性和对图像级增强的鲁棒性来细化标签。基于这些优化后的标签，训练一个3D网络以实现开放词汇分割。

研究结果: 在nuScenes和SemanticKITTI数据集上，LOSC在零样本开放词汇语义和全景分割任务中显著优于现有技术，取得了显著的性能提升。

研究结论: LOSC通过优化标签的时空一致性和鲁棒性，显著提升了激光雷达扫描的开放词汇分割性能，为自动驾驶场景中的语义理解提供了有效解决方案。

中文摘要: 本文研究了基于图像的视觉语言模型（VLMs）在驾驶场景中激光雷达扫描的开放词汇分割中的应用。传统方法将图像语义反向投影到3D点云，但生成的标签存在噪声和稀疏性问题。我们通过优化标签的时空一致性和对图像级增强的鲁棒性来整合这些标签，并基于这些优化后的标签训练一个3D网络。这种简单的方法称为LOSC，在nuScenes和SemanticKITTI数据集上的零样本开放词汇语义和全景分割任务中显著优于现有技术，且优势明显。

</details>


### [97] [SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs](https://arxiv.org/abs/2507.07610)
**中文标题：SpatialViz-Bench：为多模态大语言模型自动生成的空间可视化推理任务**

*Siting Wang,Luoyang Sun,Cheng Deng,Kun Shao,Minnan Pei,Zheng Tian,Haifeng Zhang,Jun Wang*

主要分类: cs.CV

摘要简述: 本文提出了SpatialViz-Bench，一个自动生成的多模态空间可视化推理任务基准，用于评估多模态大语言模型（MLLMs）的空间可视化能力。通过12项任务和1,180个自动生成的问题，评估了33个先进MLLMs，揭示了其性能差异和反直觉行为，填补了该领域的空白。


<details>
  <summary>详细信息</summary>
研究动机: 当前多模态大语言模型（MLLMs）的空间可视化能力评估不足，通常嵌入在数学和逻辑测试中，且依赖可能重叠训练数据的IQ测试或数学竞赛，影响评估可靠性。因此，需要专门的空间可视化基准来填补这一空白。

研究方法: 研究团队开发了SpatialViz-Bench，包含12项任务和1,180个自动生成的问题，覆盖4种子能力。通过评估33个先进MLLMs，分析其性能差异和反直觉行为。

研究结果: 评估结果显示，MLLMs在空间可视化任务中表现差异显著，且存在反直觉行为，如与人类直觉不符的难度感知、2D到3D性能骤降，以及过度依赖公式推导而非可视化。

研究结论: SpatialViz-Bench揭示了当前先进MLLMs在空间可视化任务中的不足，填补了该领域的评估空白，并为未来研究提供了公开可用的基准。

中文摘要: 人类可以直接在脑海中想象和操作视觉图像，这种能力称为空间可视化。尽管多模态大语言模型（MLLMs）支持基于想象的推理，但空间可视化能力的评估仍然不足，通常嵌入在更广泛的数学和逻辑测试中。现有的评估多依赖IQ测试或数学竞赛，这些可能与训练数据重叠，影响评估可靠性。为此，我们提出了SpatialViz-Bench，一个全面的多模态空间可视化基准，包含12项任务和1,180个自动生成的问题，覆盖4种子能力。我们对33个先进MLLMs的评估不仅揭示了广泛的性能差异，证明了基准的强大区分能力，还发现了反直觉的现象：模型表现出与人类直觉不符的难度感知、2D到3D性能骤降，以及尽管空间任务仅需可视化却默认使用公式推导。SpatialViz-Bench实证表明，当前先进MLLMs在空间可视化任务中仍存在不足，填补了该领域的显著空白。该基准已公开可用。

</details>


### [98] [ViLU: Learning Vision-Language Uncertainties for Failure Prediction](https://arxiv.org/abs/2507.07620)
**中文标题：ViLU：学习视觉-语言不确定性以进行失败预测**

*Marc Lafon,Yannis Karmim,Julio Silva-Rodriguez,Paul Couairon,Clément Rambour,Raphaël Fournier-Sniehotta,Ismail Ben Ayed,Jose Dolz,Nicolas Thome*

主要分类: cs.CV

摘要简述: ViLU是一种新的视觉-语言不确定性量化框架，通过整合视觉嵌入、预测文本嵌入和图像条件文本表示，构建多模态不确定性表示，显著提升了失败预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 视觉-语言模型在不确定性量化和失败预测方面仍存在挑战，ViLU旨在通过多模态表示和损失无关的二元分类器解决这些问题。

研究方法: ViLU通过跨注意力机制整合视觉嵌入、预测文本嵌入和图像条件文本表示，构建不确定性感知的多模态表示，并使用加权二元交叉熵损失训练二元分类器区分正确与错误预测。

研究结果: 在多个数据集（如ImageNet-1k、CC12M和LAION-400M）上的实验表明，ViLU在失败预测方面显著优于现有方法，消融研究验证了其架构和训练的关键作用。

研究结论: ViLU为视觉-语言模型的不确定性量化提供了一种有效的后处理方法，其多模态表示和损失无关的设计在实际应用中表现出色。

中文摘要: 可靠的不确定性量化（UQ）和失败预测仍然是视觉-语言模型（VLMs）面临的开放挑战。我们提出了ViLU，一种新的视觉-语言不确定性量化框架，通过利用所有任务相关的文本表示来情境化不确定性估计。ViLU通过整合视觉嵌入、预测文本嵌入和通过跨注意力的图像条件文本表示，构建了一个不确定性感知的多模态表示。与基于损失预测的传统UQ方法不同，ViLU将不确定性预测器训练为二元分类器，使用加权二元交叉熵损失区分正确与错误预测，使其与损失无关。特别地，我们提出的方法非常适合后处理场景，其中仅能获取视觉和文本嵌入而无法直接访问模型本身。在多个数据集上的广泛实验表明，我们的方法相比最先进的失败预测方法取得了显著提升。我们将方法应用于标准分类数据集（如ImageNet-1k）以及大规模图像-标题数据集（如CC12M和LAION-400M）。消融研究突出了我们的架构和训练在实现有效不确定性量化中的关键作用。我们的代码已公开，可在此处找到：https://github.com/ykrmm/ViLU。

</details>


### [99] [T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates](https://arxiv.org/abs/2507.07633)
**中文标题：T-GVC：超低码率下的轨迹引导生成视频编码**

*Zhitao Wang,Hengyu Man,Wenrui Li,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

主要分类: cs.CV

摘要简述: 本文提出了一种基于轨迹引导的生成视频编码框架（T-GVC），通过稀疏运动采样和扩散过程优化，在超低码率下实现高质量视频重建，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有生成视频编码方法在超低码率（ULB）场景下存在领域局限性或过度依赖文本引导，导致运动细节丢失和重建不真实。T-GVC旨在通过轨迹引导解决这些问题。

研究方法: T-GVC采用语义感知的稀疏运动采样管道，将低层运动跟踪与高层语义理解结合，提取像素级运动轨迹点，并通过轨迹对齐的损失约束优化扩散过程，实现物理合理的运动模式。

研究结果: 实验表明，T-GVC在ULB条件下优于传统编解码器和端到端视频压缩方法，且比文本引导方法实现更精确的运动控制。

研究结论: T-GVC为基于几何运动建模的生成视频编码提供了新方向，显著提升了超低码率下的视频重建质量。

中文摘要: 近年来，视频生成技术的进步催生了一种新兴的生成视频编码范式，旨在通过利用强大的生成先验，在超低码率（ULB）场景下实现语义准确的重建。然而，现有方法多受限于领域特异性（如人脸或人体视频）或对高层文本引导的过度依赖，往往无法捕捉运动细节，导致重建不真实。为解决这些问题，我们提出了一种轨迹引导的生成视频编码框架（T-GVC）。T-GVC采用语义感知的稀疏运动采样管道，通过基于语义重要性提取像素级运动作为稀疏轨迹点，有效桥接低层运动跟踪与高层语义理解，不仅显著降低了码率，还保留了关键的时序语义信息。此外，通过将轨迹对齐的损失约束引入扩散过程，我们提出了一种无需训练的潜在空间引导机制，确保物理合理的运动模式，同时不牺牲生成模型的固有能力。实验结果表明，我们的框架在ULB条件下优于传统编解码器和最先进的端到端视频压缩方法。进一步的实验证实，我们的方法比现有文本引导方法实现了更精确的运动控制，为基于几何运动建模的生成视频编码开辟了新方向。

</details>


### [100] [Bridging the gap in FER: addressing age bias in deep learning](https://arxiv.org/abs/2507.07638)
**中文标题：弥合FER中的差距：解决深度学习中的年龄偏见问题**

*F. Xavier Gaya-Morey,Julia Sanchez-Perez,Cristina Manresa-Yee,Jose M. Buades-Rubio*

主要分类: cs.CV

摘要简述: 本文研究了深度学习面部表情识别（FER）系统中的年龄偏见问题，重点关注老年人群体。通过可解释AI技术发现识别偏差，并提出三种缓解策略，实验证明能有效提升老年人表情识别的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于深度学习的面部表情识别系统在性能上表现优异，但存在明显的年龄偏见，尤其是对老年人的识别效果较差，影响了系统的公平性和可靠性。本文旨在揭示并解决这一问题。

研究方法: 研究首先分析了不同年龄组的识别性能差异，并通过可解释AI技术（XAI）识别出老年人群体中“中性”、“悲伤”和“愤怒”表情的识别偏差。随后提出了三种缓解策略：多任务学习、多模态输入和年龄加权损失。实验基于AffectNet数据集，并在包含少数年龄组的基准数据集上验证。

研究结果: 实验结果表明，提出的策略显著提升了老年人表情识别的准确性，尤其是对易错表情的识别。显著性热图分析显示，采用年龄感知策略的模型能够更关注与年龄相关的面部区域。

研究结论: 研究表明，通过简单的训练调整可以有效缓解FER系统中的年龄偏见，即使是近似的人口统计标签也有助于提升大规模情感计算系统的公平性。

中文摘要: 近年来，基于深度学习的面部表情识别（FER）系统取得了令人瞩目的性能。然而，这些模型往往表现出人口统计偏见，尤其是年龄偏见，可能损害其公平性和可靠性。本研究对深度学习FER模型中的年龄偏见进行了全面研究，重点关注老年人群体。我们首先探讨了识别性能是否因年龄组而异，哪些表情受影响最大，以及模型注意力是否因年龄而不同。通过可解释AI（XAI）技术，我们发现了表情识别和注意力模式的系统性差异，尤其是老年人中的“中性”、“悲伤”和“愤怒”表情。基于这些发现，我们提出并评估了三种偏见缓解策略：多任务学习、多模态输入和年龄加权损失。我们的模型在带有自动估计年龄标签的大规模数据集AffectNet上训练，并在包含少数年龄组的平衡基准数据集上验证。结果显示，老年人表情识别的准确性得到了一致提升，尤其是对最易错的表情。显著性热图分析表明，采用年龄感知策略训练的模型能够更关注与各年龄组相关的面部区域，从而解释了观察到的改进。这些发现表明，通过简单的训练调整可以有效缓解FER中的年龄偏见，即使是近似的人口统计标签也有助于提升大规模情感计算系统的公平性。

</details>


### [101] [MolCLIP: A Molecular-Auxiliary CLIP Framework for Identifying Drug Mechanism of Action Based on Time-Lapsed Mitochondrial Images](https://arxiv.org/abs/2507.07663)
**中文标题：MolCLIP：基于时间序列线粒体图像的药物作用机制识别分子辅助CLIP框架**

*Fengqian Pang,Chunyue Lei,Hongfei Zhao,Chenghao Liu,Zhiqiang Xing,Huafeng Wang,Chuyang Ye*

主要分类: cs.CV

摘要简述: MolCLIP是一种结合细胞视频和药物分子模态的视觉语言模型，通过分子辅助的CLIP框架和度量学习策略，显著提升了药物识别和作用机制（MoA）分析的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有深度学习方法主要依赖细胞的空间特征图像，忽略了时间动态信息，而药物分子模态可能补充图像信息，因此需要一种结合细胞视频和分子模态的新方法。

研究方法: MolCLIP设计了分子辅助的CLIP框架，引导视频特征学习分子潜在空间的分布，并集成度量学习策略优化视频特征的聚合。

研究结果: 在MitoDataset上的实验表明，MolCLIP在药物识别和MoA识别任务中的mAP分别提升了51.2%和20.5%。

研究结论: MolCLIP通过结合细胞视频和分子模态，显著提升了药物作用机制分析的性能，为药物发现提供了新工具。

中文摘要: 药物作用机制（MoA）主要研究药物分子如何与细胞相互作用，这对药物发现和临床应用至关重要。近年来，深度学习模型通过依赖药物暴露下的高内容和荧光细胞图像来识别MoA。然而，这些方法关注空间特征，而忽略了活细胞的时间动态。时间序列成像更适合观察细胞对药物的反应。此外，药物分子可能触发与特定MoA相关的细胞动态变化，这表明药物分子模态可以补充图像模态。本文提出了MolCLIP，首个结合显微细胞视频和分子模态的视觉语言模型。MolCLIP设计了一种分子辅助的CLIP框架，引导视频特征学习分子潜在空间的分布。此外，我们结合度量学习策略优化视频特征的聚合。在MitoDataset上的实验结果表明，MolCLIP在药物识别和MoA识别任务中的mAP分别提升了51.2%和20.5%。

</details>


### [102] [Attend-and-Refine: Interactive keypoint estimation and quantitative cervical vertebrae analysis for bone age assessment](https://arxiv.org/abs/2507.07670)
**中文标题：Attend-and-Refine：交互式关键点估计与定量颈椎分析在骨龄评估中的应用**

*Jinhee Kim,Taesung Kim,Taewoo Kim,Dong-Wook Kim,Byungduk Ahn,Yoon-Ji Kim,In-Seok Song,Jaegul Choo*

主要分类: cs.CV

摘要简述: 本文提出了一种名为ARNet的交互式深度学习模型，用于简化颈椎关键点标注，从而提高儿科正畸中生长潜力评估的效率和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 儿科正畸中，准确评估生长潜力对制定有效治疗策略至关重要。传统方法依赖颈椎形态分析，但关键点标注过程繁琐且耗时。本文旨在通过AI技术简化这一过程，提升诊断效率。

研究方法: 提出ARNet模型，结合交互引导的重新校准网络和形态感知损失函数，通过用户反馈自适应调整图像特征，同时保持关键点的结构一致性。

研究结果: ARNet在多个数据集上验证表现出色，显著减少了人工标注工作量，并在医学影像中展现出广泛适用性。

研究结论: 本研究为儿科正畸生长潜力评估提供了一种高效的AI辅助诊断工具，推动了该领域的进步。

中文摘要: 在儿科正畸中，准确评估生长潜力对制定有效治疗策略至关重要。本研究旨在通过侧位头影测量X光片识别生长峰值并分析颈椎形态来预测这一潜力。为此，我们全面分析了这些X光片中的颈椎成熟度（CVM）特征，为临床医生提供了一种可靠且高效的工具，以确定正畸干预的最佳时机，最终改善患者预后。该方法的关键在于对颈椎关键点的精细标注，但这一过程通常因耗时费力而受到挑战。为解决这一问题，我们提出了Attend-and-Refine网络（ARNet），这是一种基于深度学习的用户交互模型，旨在简化标注过程。ARNet包含交互引导的重新校准网络，可根据用户反馈自适应调整图像特征，并结合形态感知损失函数以保持关键点的结构一致性。这一创新方法显著减少了关键点识别中的人工工作量，从而提高了过程的效率和准确性。通过在多数据集上的广泛验证，ARNet表现出卓越性能，并在医学影像中展现出广泛适用性。总之，本研究为儿科正畸生长潜力评估提供了一种有效的AI辅助诊断工具，标志着该领域的重大进展。

</details>


### [103] [Action Unit Enhance Dynamic Facial Expression Recognition](https://arxiv.org/abs/2507.07678)
**中文标题：动作单元增强的动态面部表情识别**

*Feng Liu,Lingna Gu,Chen Shi,Xiaolan Fu*

主要分类: cs.CV

摘要简述: 本文提出了一种基于动作单元（AU）增强的动态面部表情识别架构（AU-DFER），通过量化AU对不同表情的贡献并设计权重矩阵，结合先验知识提升深度学习模型效果。实验表明，该方法在主流数据集上优于现有技术，并探讨了AU损失函数设计对数据标签不平衡问题的潜力。


<details>
  <summary>详细信息</summary>
研究动机: 动态面部表情识别（DFER）领域的研究多从深度学习角度进行特征学习，但缺乏对动作单元（AU）与表情关系的量化分析。本文旨在通过整合AU知识提升DFER模型性能，并解决数据标签不平衡问题。

研究方法: 提出AU-DFER架构，量化AU对表情的贡献并设计权重矩阵，结合先验知识。通过引入AU损失函数，将AU知识与深度学习网络的学习结果整合。在主流DFER模型上进行验证，并探讨AU损失函数设计对数据不平衡问题的改进。

研究结果: 实验表明，AU-DFER在主流数据集上优于现有技术，无需额外计算即可提升性能。此外，AU损失函数设计能有效缓解数据标签不平衡问题。

研究结论: 本文首次将量化AU知识整合到DFER模型中，验证了其有效性，并提出了解决数据不平衡问题的策略。结果表明，多样化的损失函数设计能显著提升DFER性能，突显了解决数据不平衡问题的重要性。

中文摘要: 动态面部表情识别（DFER）是一个快速发展的研究领域，专注于时间序列面部表情的识别。尽管以往的研究主要从深度学习角度进行特征学习，本文提出了一种AU增强的动态面部表情识别架构（AU-DFER），通过整合AU-表情知识提升深度学习建模效果。具体而言，量化了动作单元（AU）对不同表情的贡献，并设计了权重矩阵以结合先验知识。随后，通过引入AU损失函数，将知识与传统深度学习网络的学习结果整合。该设计被纳入现有动态表情识别的最优模型中进行验证。实验在三个主流开源DFER方法及该领域主要数据集上进行。结果表明，所提架构无需额外计算即可优于现有技术，并普遍提升了性能。此外，我们还探讨了AU损失函数重新设计对解决动态表情数据集中数据标签不平衡问题的潜力。据我们所知，这是首次尝试将量化AU知识整合到多种DFER模型中。我们还设计了解决标签不平衡或少数类问题的策略。研究发现，采用多样化的损失函数设计策略可提升DFER效果，突显了解决该领域主流数据集中数据不平衡问题的重要性。源代码发布于https://github.com/Cross-Innovation-Lab/AU-DFER。

</details>


### [104] [Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought](https://arxiv.org/abs/2507.07685)
**中文标题：基于理由增强解码的多模态思维链推理**

*Shin'ya Yamaguchi,Kosuke Nishida,Daiki Chijiwa*

主要分类: cs.CV

摘要简述: 本文提出了一种名为RED的解码策略，通过结合视觉和生成的中间理由信息，显著提升了多模态思维链推理的准确性和可靠性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型视觉语言模型（LVLMs）在思维链（CoT）推理中常忽略生成的中间理由内容，导致推理效果不佳。本文旨在解决这一问题，提升多模态推理的准确性和可靠性。

研究方法: 本文将多模态CoT推理重新定义为基于KL约束的奖励最大化问题，并提出RED解码策略，通过融合视觉条件和理由条件的下一个词分布，优化推理过程。

研究结果: 实验表明，RED在多个基准测试和LVLMs中显著优于标准CoT和其他解码方法，提升了推理的准确性和忠实性。

研究结论: RED为多模态系统提供了一种实用且高效的解码策略，为基于理由的可靠多模态推理铺平了道路。

中文摘要: 大型视觉语言模型（LVLMs）通过将预训练的视觉编码器与大型语言模型（LLMs）结合，展现了卓越的能力。类似于单模态LLMs，思维链（CoT）提示已被用于LVLMs，通过基于视觉和文本输入生成中间理由来增强多模态推理。尽管CoT被认为可以提高LVLMs的准确性和基础性，但我们的实验揭示了一个关键挑战：现有LVLMs在CoT推理中常忽略生成的中间理由内容。为解决这一问题，我们将多模态CoT推理重新定义为基于KL约束的奖励最大化问题，重点关注理由条件的对数似然。作为最优解，我们提出了理由增强解码（RED），一种新颖的即插即用推理时解码策略。RED通过将视觉条件和理由条件的下一个词分布相乘，协调视觉和理由信息。大量实验表明，RED在多个基准测试和LVLMs中显著优于标准CoT和其他解码方法，提升了推理性能。我们的工作为提升LVLMs中CoT推理的忠实性和准确性提供了一种实用且有效的方法，为更可靠的理由基础多模态系统铺平了道路。

</details>


### [105] [Tree-Mamba: A Tree-Aware Mamba for Underwater Monocular Depth Estimation](https://arxiv.org/abs/2507.07687)
**中文标题：Tree-Mamba：一种用于水下单目深度估计的树感知Mamba方法**

*Peixian Zhuang,Yijian Wang,Zhenqi Fu,Hongliang Zhang,Sam Kwong,Chongyi Li*

主要分类: cs.CV

摘要简述: 本文提出了一种名为Tree-Mamba的新方法，用于水下单目深度估计（UMDE），通过树感知扫描策略和可靠的数据集BlueDepth，显著提升了深度估计的准确性和多尺度特征表示能力。


<details>
  <summary>详细信息</summary>
研究动机: 水下单目深度估计（UMDE）由于水下图像的光吸收和散射效应，导致深度估计困难。现有的Mamba方法因其状态扫描策略的局限性，难以有效建模水下图像的结构特征，同时现有数据集的深度标签不可靠，影响了对象-深度关系的准确性。

研究方法: 提出了一种树感知扫描策略，基于特征相似性自适应构建最小生成树，并通过自底向上和自顶向下的遍历灵活聚合空间拓扑特征，增强了多尺度特征表示能力。此外，构建了包含38,162对可靠深度标签的水下数据集BlueDepth。

研究结果: 实验表明，Tree-Mamba在定性和定量评估中均优于现有方法，同时保持了较高的计算效率。

研究结论: Tree-Mamba通过树感知扫描策略和高质量数据集，显著提升了水下单目深度估计的准确性，为未来研究提供了可靠的基础。

中文摘要: 水下单目深度估计（UMDE）是一项关键任务，旨在从因海洋环境中光吸收和散射效应而退化的水下图像中估计高精度深度图。近年来，基于Mamba的方法在各种视觉任务中取得了显著成果，但由于其状态扫描策略的局限性，难以有效建模水下图像的结构特征。同时，现有的UMDE数据集通常包含不可靠的深度标签，导致水下图像与其对应深度图之间的对象-深度关系不准确。为克服这些限制，我们开发了一种名为Tree-Mamba的新型树感知Mamba方法，用于从退化的水下图像中估计准确的单目深度图。具体而言，我们提出了一种树感知扫描策略，基于特征相似性自适应构建最小生成树，并通过自底向上和自顶向下的遍历灵活聚合树节点间的空间拓扑特征，从而增强了多尺度特征表示能力。此外，我们构建了一个名为BlueDepth的水下深度估计基准数据集，包含38,162对具有可靠深度标签的水下图像对。该数据集可作为训练现有基于深度学习的UMDE方法的基础，以学习准确的对象-深度关系。大量实验表明，所提出的Tree-Mamba在定性结果和定量评估中均优于多种领先方法，同时保持了较高的计算效率。代码和数据集将在https://wyjgr.github.io/Tree-Mamba.html上提供。

</details>


### [106] [Motion-Aware Adaptive Pixel Pruning for Efficient Local Motion Deblurring](https://arxiv.org/abs/2507.07708)
**中文标题：基于运动感知的自适应像素剪枝高效局部运动去模糊方法**

*Wei Shang,Dongwei Ren,Wanying Zhang,Pengfei Zhu,Qinghua Hu,Wangmeng Zuo*

主要分类: cs.CV

摘要简述: 本文提出了一种基于运动感知的自适应像素剪枝方法，用于高效处理局部运动模糊。通过可训练的模糊区域预测器和帧内运动分析器，结合计算优化技术，显著降低了计算量并提升了去模糊效果。


<details>
  <summary>详细信息</summary>
研究动机: 现有去模糊方法在计算资源分配和空间变化模糊模式处理上效率不足，导致局部运动模糊问题难以有效解决。本文旨在通过优化计算资源分配和模糊区域处理，提升去模糊性能。

研究方法: 1. 提出可训练的模糊区域预测器，识别图像中的模糊区域并排除清晰区域；2. 通过结构重参数化技术将3×3卷积转换为1×1卷积，实现像素级剪枝以减少计算量；3. 开发帧内运动分析器，将像素位移转化为运动轨迹，为区域特定模糊恢复提供自适应指导。

研究结果: 实验表明，该方法在局部和全局模糊数据集上优于现有技术，同时将计算量（FLOPs）降低了49%。

研究结论: 本文提出的方法通过自适应像素剪枝和运动分析，显著提升了局部运动模糊的去模糊效率与效果，为实际应用提供了高效解决方案。

中文摘要: 数字图像中的局部运动模糊源于动态物体与静态成像系统在曝光期间的相对运动。现有去模糊方法因计算资源分配效率低下及对空间变化模糊模式处理不足而面临挑战。为克服这些限制，我们首先提出一种可训练的模糊区域预测器，用于识别图像中的模糊区域。训练过程中，利用模糊掩码排除清晰区域。为优化推理，通过结构重参数化将3×3卷积转换为计算高效的1×1卷积，实现对清晰区域的像素级剪枝以减少计算量。其次，开发了一种帧内运动分析器，将相对像素位移转化为运动轨迹，为区域特定模糊恢复提供自适应指导。我们的方法通过结合重建损失、再模糊损失和模糊掩码指导的掩码损失进行端到端训练。大量实验表明，该方法在局部和全局模糊数据集上均优于现有技术，同时将FLOPs降低了49%（如与LMD-ViT相比）。源代码发布于https://github.com/shangwei5/M2AENet。

</details>


### [107] [One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models](https://arxiv.org/abs/2507.07709)
**中文标题：一物多谎：统一视觉-语言模型跨任务对抗攻击基准**

*Jiale Zhao,Xinyang Jiang,Junyao Gao,Yuhao Xue,Cairong Zhao*

主要分类: cs.CV

摘要简述: 本文提出了CrossVLAD基准数据集和CRAFT攻击框架，用于评估统一视觉-语言模型在多任务对抗攻击中的表现，展示了其在跨任务攻击中的高效性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 统一视觉-语言模型（VLMs）通过指令灵活处理多种任务，但也带来安全挑战，即对抗输入需在不可预测的任务指令下保持有效性。本文旨在解决这一挑战，并评估VLMs的对抗鲁棒性。

研究方法: 提出了CrossVLAD基准数据集，基于MSCOCO并借助GPT-4标注，用于系统评估跨任务对抗攻击。同时提出CRAFT攻击框架，通过区域中心和令牌对齐方法实现高效攻击。

研究结果: 实验表明，CRAFT在Florence-2等统一VLMs上表现优于现有方法，跨任务攻击成功率和目标对象分类改变率均显著提升。

研究结论: CrossVLAD和CRAFT为统一VLMs的对抗鲁棒性研究提供了新工具，展示了跨任务攻击的有效性，并推动了相关领域的发展。

中文摘要: 统一视觉-语言模型（VLMs）近期取得显著进展，能够通过不同指令在共享计算架构中灵活处理多种任务。这种基于指令的控制机制带来了独特的安全挑战，因为对抗输入需在不可预测的任务指令下保持对同一恶意内容的有效性。本文提出CrossVLAD，一个从MSCOCO精心筛选并通过GPT-4辅助标注的新基准数据集，用于系统评估统一VLMs的跨任务对抗攻击。CrossVLAD聚焦于对象变更目标——在四个下游任务中一致操纵目标对象的分类——并提出了一种新的成功率指标，用于衡量所有任务中的同时误分类，从而严格评估对抗迁移性。为应对这一挑战，我们提出了CRAFT（基于跨任务区域的令牌对齐攻击框架），一种高效的以区域为中心的攻击方法。在Florence-2及其他流行统一VLMs上的大量实验表明，我们的方法在跨任务攻击性能和目标对象变更成功率上均优于现有方法，突显了其在多样任务中对统一VLMs的对抗影响有效性。

</details>


### [108] [Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays](https://arxiv.org/abs/2507.07722)
**中文标题：理解医学影像中的数据集偏见：以胸部X光片为例**

*Ethan Dack,Chengliang Dai*

主要分类: cs.CV

摘要简述: 本文研究了医学影像数据集中的偏见问题，以胸部X光片为例，通过数据集转换任务探索了NIH、CheXpert、MIMIC-CXR和PadChest等开源数据集中是否存在偏见，并呼吁更多可解释性研究和开源数据集的创建。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像数据集因其敏感性难以开源，导致某些数据集被广泛使用。研究旨在验证这些数据集中是否存在偏见，以确保AI方法关注的是相关病理而非捷径。

研究方法: 研究通过数据集转换任务，对NIH、CheXpert、MIMIC-CXR和PadChest等胸部X光片数据集进行分析，并采用多种网络架构进行实验。

研究结果: 实验表明，医学影像数据集中也存在偏见，强调了可解释性研究和更多开源数据集的重要性。

研究结论: 研究呼吁在医学影像领域开展更多可解释性研究，并创建更多开源数据集，以促进AI方法的透明性和可靠性。

中文摘要: 近期研究重新审视了“命名数据集”这一著名任务，并证实在非医学数据集中存在潜在偏见，且在数据集来源任务中取得了高准确率。本研究将该任务应用于流行的开源胸部X光片数据集。由于医学影像的敏感性，其开源难度较大，导致某些开源数据集在研究领域极为流行。通过执行相同任务，我们旨在探索这些数据集中是否也存在偏见。我们通过数据集转换有意增加任务难度，以识别偏见。鉴于AI在医学影像中的重要性，必须确认现代方法是关注相关病理还是走捷径。我们在NIH、CheXpert、MIMIC-CXR和PadChest等数据集上实现了多种网络架构。希望本研究能促进医学影像领域的可解释性研究和更多开源数据集的创建。相关代码将在论文被接受后发布。

</details>


### [109] [Scaling RL to Long Videos](https://arxiv.org/abs/2507.07966)
**中文标题：将强化学习扩展到长视频**

*Yukang Chen,Wei Huang,Baifeng Shi,Qinghao Hu,Hanrong Ye,Ligeng Zhu,Zhijian Liu,Pavlo Molchanov,Jan Kautz,Xiaojuan Qi,Sifei Liu,Hongxu Yin,Yao Lu,Song Han*

主要分类: cs.CV

摘要简述: 本文提出了一种全栈框架，通过强化学习扩展视觉语言模型（VLMs）对长视频的推理能力。该框架整合了大规模数据集、两阶段训练流程和高效训练基础设施，显著提升了长视频推理性能。


<details>
  <summary>详细信息</summary>
研究动机: 长视频推理在视觉语言模型中面临独特挑战，如处理大量帧和复杂时空关系。本文旨在通过强化学习和大规模数据集解决这些问题，推动长视频推理技术的发展。

研究方法: 方法包括：(1)构建包含52K长视频问答对的大规模数据集LongVideo-Reason；(2)采用两阶段训练流程，结合链式思维监督微调（CoT-SFT）和强化学习（RL）；(3)开发多模态强化序列并行（MR-SP）训练基础设施，支持高效长视频RL训练。

研究结果: 实验表明，LongVILA-R1-7B在长视频问答基准测试中表现优异，超越Video-R1-7B，并与Gemini-1.5-Pro匹敌。MR-SP系统在长视频RL训练中实现了2.1倍加速。

研究结论: LongVILA-R1标志着视觉语言模型在长视频推理领域的重要进展。同时，公开的训练系统支持多模态RL训练，为未来研究提供了强大工具。

中文摘要: 我们提出了一种全栈框架，通过强化学习扩展视觉语言模型（VLMs）对长视频的推理能力。该框架针对长视频推理的独特挑战，整合了三个关键组件：(1)大规模数据集LongVideo-Reason，包含52K个长视频问答对，涵盖体育、游戏和视频博客等多个领域的高质量推理标注；(2)两阶段训练流程，通过链式思维监督微调（CoT-SFT）和强化学习（RL）扩展VLMs；(3)多模态强化序列并行（MR-SP）训练基础设施，结合序列并行和基于vLLM的引擎，利用缓存视频嵌入实现高效训练。实验显示，LongVILA-R1-7B在VideoMME等长视频问答基准测试中表现优异，并在LongVideo-Reason-eval基准测试中超越Video-R1-7B，甚至与Gemini-1.5-Pro在时空推理、目标与目的推理、空间推理和情节推理上匹敌。值得注意的是，MR-SP系统在长视频RL训练中实现了2.1倍加速。LongVILA-R1在输入视频帧数增加时表现出稳定的性能提升，标志着视觉语言模型在长视频推理领域的重要进展。此外，我们公开了支持多模态（视频、文本和音频）、多模型（VILA和Qwen系列）甚至图像和视频生成模型的RL训练系统。在单台A100节点（8 GPU）上，该系统支持对长达一小时的视频（如3,600帧/约256k token）进行RL训练。

</details>


### [110] [RAPS-3D: Efficient interactive segmentation for 3D radiological imaging](https://arxiv.org/abs/2507.07730)
**中文标题：RAPS-3D：针对3D放射影像的高效交互式分割方法**

*Théo Danielou,Daniel Tordjman,Pierre Manceron,Corentin Dancette*

主要分类: cs.CV

摘要简述: 本文提出了一种简化的3D可提示分割方法RAPS-3D，旨在减少推理时间并消除滑动窗口的复杂性，同时实现最先进的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的2D分割模型（如SAM）无法直接应用于3D医学影像（如CT或MRI），而现有的3D方法通常采用复杂的策略（如滑动窗口推理），导致推理时间长且实现复杂。本文旨在解决这些问题。

研究方法: 受SegVol启发，本文提出了一种简化的3D可提示分割方法，避免了滑动窗口的复杂性和高计算资源需求，同时优化了推理效率。

研究结果: RAPS-3D在减少推理时间和简化实现的同时，达到了最先进的性能。

研究结论: RAPS-3D为3D医学影像分割提供了一种高效且简化的解决方案，显著提升了交互式分割的实用性。

中文摘要: 可提示分割（由Segment Anything Model（SAM）引入）是一种有前景的医学影像处理方法，因为它允许临床医生通过交互方式指导和优化模型预测。然而，SAM的架构是为2D图像设计的，无法直接扩展到3D体积数据（如CT或MRI扫描）。将2D模型适配到3D通常涉及自回归策略，即逐片传播预测，导致推理复杂度增加。处理大型3D体积数据还需要大量计算资源，现有3D方法通常采用滑动窗口推理等复杂策略以管理内存使用，但代价是更长的推理时间和更高的实现复杂度。本文提出了一种简化的3D可提示分割方法，受SegVol启发，旨在减少推理时间并消除滑动窗口的提示管理复杂性，同时实现最先进的性能。

</details>


### [111] [Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology](https://arxiv.org/abs/2507.07999)
**中文标题：可追踪证据增强的视觉接地推理：评估与方法论**

*Haochen Wang,Xiangtai Li,Zilong Huang,Anran Wang,Jiacong Wang,Tao Zhang,Jiani Zheng,Sule Bai,Zijian Kang,Jiashi Feng,Zhuochen Wang,Zhaoxiang Zhang*

主要分类: cs.CV

摘要简述: 本文提出了TreeBench评测基准和TreeVGR训练范式，用于评估和提升视觉接地推理能力，强调可追踪证据的重要性。


<details>
  <summary>详细信息</summary>
研究动机: 现有视觉接地推理模型缺乏全面评估基准，无法系统测试复杂场景中的细微目标感知和高级推理能力。

研究方法: 构建TreeBench基准，基于复杂场景中的密集目标图像，通过专家标注问题和答案；提出TreeVGR训练范式，结合强化学习联合监督定位和推理。

研究结果: TreeBench包含405个高难度问答对，先进模型准确率不足60%；TreeVGR在多个基准上显著提升性能，最高提升16.8分。

研究结论: 可追踪证据是提升视觉接地推理的关键，TreeBench和TreeVGR为未来研究提供了重要工具和方向。

中文摘要: 像OpenAI-o3这样的模型通过动态引用视觉区域开创了视觉接地推理，类似于人类的“图像思维”。然而，目前缺乏全面评估这些能力的基准。为填补这一空白，我们提出了TreeBench（可追踪证据评估基准），一个基于三个原则的诊断性基准：（1）复杂场景中细微目标的聚焦视觉感知，（2）通过边界框评估实现可追踪证据，（3）二阶推理以测试对象交互和空间层次结构，超越简单对象定位。我们优先选择密集目标的图像，最初从SA-1B中采样1K张高质量图像，并邀请八位LMM专家手动标注每张图像的问题、候选选项和答案。经过三阶段质量控制，TreeBench包含405个具有挑战性的视觉问答对，即使最先进的模型也难以应对，无一达到60%的准确率，例如OpenAI-o3仅得54.87分。此外，我们提出了TreeVGR（可追踪证据增强的视觉接地推理），一种通过强化学习联合监督定位和推理的训练范式，实现精确定位和可解释的推理路径。基于Qwen2.5-VL-7B初始化，它在V* Bench（+16.8）、MME-RealWorld（+12.6）和TreeBench（+13.4）上表现显著提升，证明可追踪性是推动视觉接地推理发展的关键。代码发布于https://github.com/Haochen-Wang409/TreeVGR。

</details>


### [112] [Energy-Guided Decoding for Object Hallucination Mitigation](https://arxiv.org/abs/2507.07731)
**中文标题：基于能量引导的解码方法减少物体幻觉**

*Xixi Liu,Ailin Deng,Christopher Zach*

主要分类: cs.CV

摘要简述: 本文提出了一种基于能量的解码方法，用于减少大型视觉语言模型中的物体幻觉现象，显著提高了三个VQA数据集的性能，并降低了“是”回答的偏差。


<details>
  <summary>详细信息</summary>
研究动机: 大型视觉语言模型（LVLMs）中的物体幻觉问题对其安全部署至关重要。现有方法要么局限于特定解码方式，要么需要复杂的视觉输入修改，或依赖外部模型知识。本文旨在解决这些问题。

研究方法: 作者提出了一种基于能量的解码方法，动态选择能量分数最低的隐藏状态层，从而减少对“是”回答的偏差，并提升性能。

研究结果: 该方法在三个基准测试（POPE、MME和MMVP）中显著提高了准确率和F1分数，平均准确率提升4.82%，并减少了8.81%的“是”回答偏差。

研究结论: 基于能量的解码方法简单有效，能够显著减少物体幻觉现象，提升模型性能，并降低偏差。

中文摘要: 减少大型视觉语言模型（LVLMs）中的物体幻觉对其安全部署至关重要。现有方法要么局限于特定解码方式，要么需要复杂的视觉输入修改，或依赖外部模型知识。本文首先揭示了视觉问答（VQA）数据集中“是”回答比例的显著不平衡现象。进一步提出了一种基于能量的解码方法，动态选择能量分数最低的隐藏状态层。该方法简单有效，在减少“是”回答偏差的同时，提升了三个基准测试（POPE、MME和MMVP）的性能。与贪婪解码相比，平均准确率提高了4.82%，且“是”回答比例的差距减少了8.81%，表明该方法具有较低的偏差。

</details>


### [113] [EEvAct: Early Event-Based Action Recognition with High-Rate Two-Stream Spiking Neural Networks](https://arxiv.org/abs/2507.07734)
**中文标题：EEvAct：基于高频率双流脉冲神经网络的早期事件驱动动作识别**

*Michael Neumeier,Jules Lecomte,Nils Kazinski,Soubarna Banik,Bing Li,Axel von Arnim*

主要分类: cs.CV

摘要简述: 本文提出了一种高频率双流脉冲神经网络（SNN）EEvAct，用于早期事件驱动的动作识别，其在大规模THU EACT-50数据集上比现有方法准确率提高了2%，并展示了在体育动作捕捉中的实际应用。


<details>
  <summary>详细信息</summary>
研究动机: 早期识别人类活动对人机交互的安全性和响应性至关重要。事件视觉传感器因其高时间分辨率和低延迟特性非常适合这一需求，但现有方法通常将事件累积为低速率帧或时空体素，限制了早期预测能力。

研究方法: 本文提出了一种高频率双流脉冲神经网络（SNN），能够以高频率处理事件数据，实现早期预测。该方法在大规模THU EACT-50数据集上进行了测试，并报告了随时间增长的Top-1和Top-5识别分数。

研究结果: 该方法在THU EACT-50数据集上的最终准确率比现有方法提高了2%，并在体育动作捕捉的实际任务中验证了其有效性。

研究结论: EEvAct通过高频率双流SNN显著提升了早期事件驱动动作识别的准确性和实用性，为人机交互提供了更高效的解决方案。

中文摘要: 早期识别人类活动对人机交互的安全性和响应性至关重要。事件视觉传感器因其高时间分辨率和低延迟特性非常适合这一需求。然而，现有方法通常将事件累积为低速率帧或时空体素，限制了早期预测能力。相比之下，脉冲神经网络（SNN）能够以高频率处理事件数据以实现早期预测，但大多数现有工作的最终准确率仍有不足。本文提出了一种高频率双流SNN，其在大规模THU EACT-50数据集上的最终准确率比现有方法提高了2%。我们在一个新颖的早期事件识别框架中对SNN进行了基准测试，报告了随时间增长的Top-1和Top-5识别分数。最后，我们通过体育运动中的人体动作捕捉任务展示了这些方法的实际应用价值。

</details>


### [114] [Sparse-Dense Side-Tuner for efficient Video Temporal Grounding](https://arxiv.org/abs/2507.07744)
**中文标题：用于高效视频时间定位的稀疏-密集侧调谐器**

*David Pujol-Perich,Sergio Escalera,Albert Clapés*

主要分类: cs.CV

摘要简述: 本文提出了一种稀疏-密集侧调谐器（SDST），用于高效视频时间定位（VTG），通过引入参考型可变形自注意力机制和InternVideo2骨干网络集成，显著提升了性能并减少了参数数量。


<details>
  <summary>详细信息</summary>
研究动机: 现有视频时间定位方法主要依赖冻结预训练骨干网络的最终层特征，限制了其对新领域的适应性。虽然完全微调不切实际，但参数高效微调（如侧调谐）成为替代方案。然而，现有侧调谐方法从帧级细化角度处理问题，忽略了时刻检索（MR）的稀疏性。

研究方法: 提出稀疏-密集侧调谐器（SDST），首个用于VTG的无锚点侧调谐架构，并引入参考型可变形自注意力机制以增强上下文建模。此外，首次将InternVideo2骨干网络有效集成到侧调谐框架中。

研究结果: SDST显著提升了现有侧调谐方法，在QVHighlights、TACoS和Charades-STA数据集上取得高度竞争性或SOTA结果，同时参数数量比现有SOTA方法减少高达73%。

研究结论: SDST通过稀疏-密集侧调谐和参考型可变形自注意力机制，有效解决了视频时间定位中的稀疏性问题，显著提升了性能并降低了计算成本。

中文摘要: 视频时间定位（VTG）涉及基于文本查询的时刻检索（MR）和高光检测（HD）。为此，大多数方法仅依赖冻结的大型预训练骨干网络的最终层特征，限制了其对新领域的适应性。虽然完全微调通常不切实际，但参数高效微调（尤其是侧调谐）已成为一种有效替代方案。然而，现有侧调谐方法从帧级细化角度处理问题，忽略了MR的固有稀疏性。为解决这一问题，我们提出了稀疏-密集侧调谐器（SDST），这是首个用于VTG的无锚点侧调谐架构。我们还引入了参考型可变形自注意力机制，一种增强可变形注意力上下文建模的新机制——这是现有无锚点方法的关键限制。此外，我们首次将InternVideo2骨干网络有效集成到侧调谐框架中，展示了其在性能上的深远影响。总体而言，我们的方法显著改进了现有侧调谐方法，在QVHighlights、TACoS和Charades-STA数据集上取得高度竞争性或SOTA结果，同时参数数量比现有SOTA方法减少高达73%。代码公开于https://github.com/davidpujol/SDST。

</details>


### [115] [X-RAFT: Cross-Modal Non-Rigid Registration of Blue and White Light Neurosurgical Hyperspectral Images](https://arxiv.org/abs/2507.07747)
**中文标题：X-RAFT：蓝光和白光神经外科高光谱图像的跨模态非刚性配准**

*Charlie Budd,Silvère Ségaud,Matthew Elliot,Graeme Stasiuk,Yijing Xie,Jonathan Shapey,Tom Vercauteren*

主要分类: cs.CV

摘要简述: X-RAFT是一种改进的跨模态光流模型，用于在神经外科手术中配准蓝光和白光高光谱图像，显著提升了荧光定量分析的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 在荧光引导的神经外科手术中，高光谱成像的整合需要蓝光和白光图像的精确配准以实现荧光定量分析。由于手术环境的动态性，跨模态图像的密集对应关系成为关键挑战。

研究方法: X-RAFT基于RAFT光流模型，针对跨模态输入进行了改进，采用独立的图像编码器对蓝光和白光图像进行处理，并通过自监督的流循环一致性方法在神经外科高光谱数据上进行微调。

研究结果: 与基线方法相比，X-RAFT在评估指标上实现了36.6%的错误率降低，相比现有的跨模态光流方法（CrossRAFT）降低了27.83%。

研究结论: X-RAFT显著提升了跨模态图像配准的准确性，为荧光定量分析提供了可靠支持，其代码和模型将在评审后公开。

中文摘要: 将高光谱成像整合到荧光引导的神经外科手术中，有望通过实时提供定量荧光测量来改善手术决策。定量荧光需要蓝光（荧光模式）和白光（反射模式）下的配对光谱数据。在动态的手术环境中，蓝光和白光图像的采集需要依次进行。因此，荧光定量过程的关键在于能够在两种截然不同光照条件下拍摄的高光谱图像之间找到密集的跨模态对应关系。我们通过引入X-RAFT来解决这一挑战，这是一种针对跨模态输入改进的RAFT光流模型。我们提出为每种模态对使用独立的图像编码器，并通过流循环一致性在神经外科高光谱数据上以自监督方式对其进行微调。与基线方法相比，X-RAFT在评估指标上实现了36.6%的错误率降低，相比现有的跨模态光流方法（CrossRAFT）降低了27.83%。我们的代码和模型将在评审后公开。

</details>


### [116] [Deep Learning based 3D Volume Correlation for Additive Manufacturing Using High-Resolution Industrial X-ray Computed Tomography](https://arxiv.org/abs/2507.07757)
**中文标题：基于深度学习的高分辨率工业X射线计算机断层扫描增材制造3D体积配准**

*Keerthana Chand,Tobias Fritsch,Bardia Hejazi,Konstantin Poka,Giovanni Bruno*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的3D体积配准方法，用于增材制造中的质量控制，通过动态分块处理高分辨率XCT数据，显著提升了配准精度和效率。


<details>
  <summary>详细信息</summary>
研究动机: 增材制造中的几何误差（如收缩和变形）会影响部件性能，传统数字体积相关（DVC）方法因缺乏真实变形场和高分辨率XCT数据量大而难以精确配准。

研究方法: 采用深度学习估计CAD与XCT体积的体素级变形，引入动态分块处理高分辨率数据，并提出二值差异图（BDM）量化配准误差。

研究结果: 相比传统DVC方法，Dice分数提升9.2%，体素匹配率提升9.9%，交互时间从数天缩短至分钟级。

研究结论: 该方法为基于深度学习的DVC技术奠定了基础，可用于增材制造闭环补偿，提升制造可靠性和效率。

中文摘要: 增材制造（AM）的质量控制对汽车、医疗和航空航天等工业领域至关重要。由收缩和变形引起的几何误差可能影响部件的寿命和性能。数字体积相关（DVC）可通过比较计算机辅助设计（CAD）模型与X射线计算机断层扫描（XCT）生成的部件几何形状来量化这些偏差。然而，由于缺乏真实变形场或参考变形场，两种模态的精确配准具有挑战性。此外，高分辨率XCT数据的极大体积使得计算困难。本文提出了一种基于深度学习的方法，用于估计CAD与XCT体积之间的体素级变形。该方法采用动态分块处理策略以应对高分辨率数据。除Dice分数外，还引入了二值差异图（BDM）来量化二值化CAD与XCT体积之间的体素级不匹配，以评估配准精度。相比传统DVC方法，该方法在Dice分数上提升了9.2%，体素匹配率提升了9.9%，同时将交互时间从数天缩短至分钟级。该工作为基于深度学习的DVC方法奠定了基础，可用于生成补偿网格，进而应用于AM生产过程中的闭环校正。此类系统对工业界具有重要意义，可显著提升制造过程的可靠性和效率，节省时间和材料。

</details>


### [117] [SCOOTER: A Human Evaluation Framework for Unrestricted Adversarial Examples](https://arxiv.org/abs/2507.07776)
**中文标题：SCOOTER：一种用于无限制对抗样本的人类评估框架**

*Dren Fazlija,Monty-Maximilian Zühlke,Johanna Schrader,Arkadij Orlov,Clara Stein,Iyiola E. Olatunji,Daniel Kudenko*

主要分类: cs.CV

摘要简述: SCOOTER是一个开源框架，用于评估无限制对抗样本的人类感知效果，填补了现有研究中缺乏统计显著性分析的空白。


<details>
  <summary>详细信息</summary>
研究动机: 无限制对抗攻击不受范数约束，可能绕过传统防御策略，但其人类感知效果缺乏统一评估框架。

研究方法: 提出SCOOTER框架，包括众包研究指南、大规模人类与模型对比实验、开源工具及基准数据集。

研究结果: 实验表明，六种攻击方法均未能生成人类无法察觉的图像，GPT-4o仅能检测其中四种攻击。

研究结论: SCOOTER为无限制对抗攻击的评估提供了标准化工具，揭示了自动化视觉系统与人类感知的差异。

中文摘要: 无限制对抗攻击旨在欺骗计算机视觉模型，而不受范数约束（例如通过改变物体颜色），从而绕过传统防御策略。然而，由于无限制特性，其人类感知效果无法保证，需通过人类评估验证真实性。现有研究缺乏统计显著性分析，亟需统一框架支持此类评估。为此，我们提出SCOOTER——一个开源的、基于统计的框架，用于评估无限制对抗样本。贡献包括：（i）众包研究的最佳实践指南；（ii）首次大规模人类与模型对比实验（346名参与者），显示六种攻击方法均未能生成不可察觉图像，且GPT-4o仅能检测其中四种攻击；（iii）开源工具，包括基于浏览器的标注任务模板及分析脚本；（iv）包含3K真实图像、7K对抗样本及34K人类评分的基准数据集。结果表明，自动化视觉系统与人类感知不一致，凸显了SCOOTER基准的必要性。

</details>


### [118] [Where are we with calibration under dataset shift in image classification?](https://arxiv.org/abs/2507.07780)
**中文标题：图像分类中数据集偏移下的校准现状如何？**

*Mélanie Roschewitz,Raghav Mehta,Fabio de Sousa Ribeiro,Ben Glocker*

主要分类: cs.CV

摘要简述: 本文研究了图像分类中数据集偏移下的校准状态，比较了多种后处理和训练中校准方法，发现熵正则化和标签平滑结合效果最佳，并提出实用指南。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索真实世界数据集偏移下图像分类的校准状态，为从业者提供稳健校准的实用建议。

研究方法: 方法包括比较多种后处理校准方法及其与训练中校准策略（如标签平滑）的交互作用，覆盖多个自然偏移和八种分类任务。

研究结果: 结果显示熵正则化和标签平滑结合效果最佳；后处理校准方法在少量语义分布外数据下表现最稳健；新校准方法未必优于简单方法；校准改进常以分布内校准下降为代价。

研究结论: 结论表明，结合熵正则化和标签平滑、后处理校准及基础模型微调，能显著提升校准稳健性，集成方法效果最佳。

中文摘要: 我们对图像分类中真实世界数据集偏移下的校准状态进行了广泛研究，为从业者提供了关于后处理和训练中校准技术选择的重要见解和实用指南。我们比较了多种后处理校准方法及其与常见训练中校准策略（如标签平滑）的交互作用，覆盖了多个自然偏移和八种不同分类任务。研究发现：（i）同时应用熵正则化和标签平滑在数据集偏移下能产生最佳校准原始概率；（ii）暴露于少量语义分布外数据的后处理校准方法在偏移下表现最稳健；（iii）专门针对偏移设计的新校准方法未必显著优于简单后处理方法；（iv）改进偏移下的校准常以分布内校准下降为代价。这些发现适用于随机初始化分类器及基于基础模型微调的分类器，后者校准效果更优。最后，我们深入分析了集成效应，发现（i）集成前校准比集成后更有效；（ii）集成中分布外数据暴露会恶化分布内偏移校准权衡；（iii）集成仍是提升校准稳健性的最有效方法之一，结合基础模型微调可获得最佳校准效果。

</details>


### [119] [SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes](https://arxiv.org/abs/2507.07781)
**中文标题：SURPRISE3D：复杂3D场景中的空间理解与推理数据集**

*Jiaxin Huang,Ziwen Li,Hanlve Zhang,Runnan Chen,Xiao He,Yandong Guo,Wenping Wang,Tongliang Liu,Mingming Gong*

主要分类: cs.CV

摘要简述: SURPRISE3D是一个用于评估复杂3D场景中语言引导空间推理分割的新数据集，旨在解决现有数据集中语义线索与空间背景混杂的问题，包含超过200k视觉语言对和89k+人工标注的空间查询，覆盖多种空间推理技能。


<details>
  <summary>详细信息</summary>
研究动机: 当前3D视觉语言研究中，空间推理能力未得到充分探索，现有数据集常将语义线索（如物体名称）与空间背景混杂，导致模型依赖表面捷径而非真正理解空间关系。SURPRISE3D旨在填补这一空白。

研究方法: SURPRISE3D基于ScanNet++ v2的900+详细室内场景构建，包含200k+视觉语言对和2.8k+独特物体类别，设计了89k+人工标注的空间查询，刻意避免使用物体名称，以减少捷径偏差。

研究结果: 初步基准测试表明，当前最先进的3D视觉定位方法和3D-LLMs在SURPRISE3D上表现显著不足，凸显了该数据集及其3D空间推理分割（3D-SRS）基准套件的必要性。

研究结论: SURPRISE3D和3D-SRS旨在推动空间感知AI的发展，为有效的具身交互和机器人规划铺平道路。

中文摘要: 语言与3D感知的集成对于具身AI和机器人系统感知、理解并与物理世界交互至关重要。空间推理是理解物体间空间关系的关键能力，但在当前3D视觉语言研究中仍未充分探索。现有数据集常将语义线索（如物体名称）与空间背景混杂，导致模型依赖表面捷径而非真正理解空间关系。为填补这一空白，我们提出了SURPRISE3D，一个用于评估复杂3D场景中语言引导空间推理分割的新数据集。SURPRISE3D基于ScanNet++ v2的900+详细室内场景构建，包含200k+视觉语言对和2.8k+独特物体类别。数据集包含89k+人工标注的空间查询，刻意避免使用物体名称以减少捷径偏差。这些查询全面覆盖了多种空间推理技能，如相对位置、叙述视角、参数视角和绝对距离推理。初步基准测试表明，当前最先进的3D视觉定位方法和3D-LLMs在SURPRISE3D上表现显著不足，凸显了该数据集及其3D空间推理分割（3D-SRS）基准套件的必要性。SURPRISE3D和3D-SRS旨在推动空间感知AI的发展，为有效的具身交互和机器人规划铺平道路。代码和数据集可在https://github.com/liziwennba/SUPRISE获取。

</details>


### [120] [Robust and Generalizable Heart Rate Estimation via Deep Learning for Remote Photoplethysmography in Complex Scenarios](https://arxiv.org/abs/2507.07795)
**中文标题：基于深度学习的复杂场景下远程光电容积描记心率估计的鲁棒性与泛化性研究**

*Kang Cen,Chang-Hong Fu,Hong Hong*

主要分类: cs.CV

摘要简述: 本文提出了一种基于深度学习的端到端远程光电容积描记（rPPG）网络，通过3D卷积神经网络从面部视频中重建精确的rPPG信号，结合差分帧融合模块和时序移位模块（TSM）增强特征提取，并采用动态混合损失函数提升模型鲁棒性和泛化能力，在复杂场景下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有rPPG技术在复杂场景下的准确性、鲁棒性和泛化能力不足，本文旨在通过深度学习改进这些问题。

研究方法: 提出端到端rPPG提取网络，结合3D卷积神经网络、差分帧融合模块和时序移位模块（TSM），并引入动态混合损失函数优化模型训练。

研究结果: 在PURE、UBFC-rPPG和MMPD数据集上的实验表明，模型在复杂场景下表现优异，训练于PURE后在MMPD测试集上的平均绝对误差（MAE）为7.58，优于现有最佳模型。

研究结论: 本文提出的方法显著提升了rPPG技术在复杂场景下的鲁棒性和泛化能力，为远程心率监测提供了更可靠的解决方案。

中文摘要: 非接触式远程光电容积描记（rPPG）技术可通过面部视频测量心率，但现有网络模型在复杂场景下的准确性、鲁棒性和泛化能力仍面临挑战。本文提出了一种端到端的rPPG提取网络，利用3D卷积神经网络从原始面部视频中重建精确的rPPG信号。我们引入了一种差分帧融合模块，将差分帧与原始帧结合，使帧级表示能够捕捉血容量脉冲（BVP）的变化。此外，我们结合了时序移位模块（TSM）与自注意力机制，以最小的计算开销有效增强rPPG特征。进一步，我们提出了一种新颖的动态混合损失函数，为网络提供更强的监督，有效缓解过拟合问题。我们在PURE、UBFC-rPPG以及复杂场景下的MMPD数据集上进行了全面实验，包括数据集内和跨数据集评估，结果表明我们的网络具有卓越的鲁棒性和泛化能力。具体而言，在PURE上训练后，我们的模型在MMPD测试集上的平均绝对误差（MAE）为7.58，优于现有最佳模型。

</details>


### [121] [Visual Instance-aware Prompt Tuning](https://arxiv.org/abs/2507.07796)
**中文标题：视觉实例感知提示调优**

*Xi Xiao,Yunbei Zhang,Xingjian Li,Tianyang Wang,Xiao Wang,Yuxiang Wei,Jihun Hamm,Min Xu*

主要分类: cs.CV

摘要简述: 本文提出了一种视觉实例感知提示调优方法（ViaPT），通过为每个输入生成实例感知提示并与数据集级提示融合，解决了传统视觉提示调优（VPT）因数据集差异导致的性能不足问题。ViaPT利用主成分分析（PCA）保留关键提示信息，并在34个数据集上验证了其优于现有方法的性能。


<details>
  <summary>详细信息</summary>
研究动机: 传统视觉提示调优（VPT）使用固定数据集级提示，无法适应不同输入实例的差异，导致性能下降。本文旨在解决这一问题，提出实例感知提示调优方法，以提升模型在下游任务中的表现。

研究方法: ViaPT通过为每个输入生成实例感知提示，并将其与数据集级提示融合，利用PCA保留重要提示信息。该方法避免了VPT-Deep和VPT-Shallow的极端情况，平衡了数据集级和实例级知识，同时减少了可学习参数。

研究结果: 在34个多样化数据集上的实验表明，ViaPT显著优于现有基线方法，验证了其在视觉提示调优中的优越性。

研究结论: ViaPT通过结合实例感知提示和数据集级提示，克服了传统VPT的局限性，为视觉变换器的提示调优提供了新的分析和优化范式。

中文摘要: 视觉提示调优（VPT）已成为视觉变换器的一种参数高效微调范式，传统方法使用跨所有输入实例固定的数据集级提示。我们观察到，由于下游数据集的高方差，这种策略导致性能不佳。为解决这一问题，我们提出视觉实例感知提示调优（ViaPT），该方法基于每个输入生成实例感知提示，并将其与数据集级提示融合，利用主成分分析（PCA）保留重要提示信息。此外，我们发现VPT-Deep和VPT-Shallow是基于概念理解的两种极端情况，它们未能有效捕捉实例特定信息，而对提示的随机降维仅能获得介于两者之间的性能。相反，ViaPT通过平衡数据集级和实例级知识，同时减少可学习参数，克服了这些限制。在34个多样化数据集上的广泛实验表明，我们的方法始终优于最先进的基线，为视觉变换器的提示分析和优化建立了新范式。

</details>


### [122] [Synergistic Prompting for Robust Visual Recognition with Missing Modalities](https://arxiv.org/abs/2507.07802)
**中文标题：协同提示：面向模态缺失的稳健视觉识别**

*Zhihui Zhang,Luanyuan Dai,Qika Lin,Yunfeng Diao,Guangyin Jin,Yufei Guo,Jing Zhang,Xiaoshuai Hao*

主要分类: cs.CV

摘要简述: 本文提出了一种名为协同提示（SyP）的新框架，用于解决多模态视觉识别中模态缺失的问题。通过动态适配器和协同提示策略，SyP能够灵活适应不同缺失条件，并在关键模态缺失时保持稳健性能。实验表明，SyP在多种数据集上显著优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现实应用中，多模态数据的缺失或不完整常导致性能显著下降。现有基于提示的方法存在静态提示缺乏灵活性和基础提示调优在关键模态缺失时不可靠的问题。本文旨在解决这些挑战，提出一种更灵活、稳健的解决方案。

研究方法: SyP框架包含两个关键创新：(I) 动态适配器，通过计算自适应缩放因子动态生成提示，取代静态参数；(II) 协同提示策略，结合静态和动态提示以平衡模态信息，确保关键模态缺失时的稳健推理。

研究结果: 在三个广泛使用的视觉识别数据集上，SyP显著优于现有方法，并在不同缺失率和条件下表现出稳健性。大量实验和消融研究验证了其处理缺失模态的有效性。

研究结论: SyP通过动态适配和协同提示策略，在多模态视觉识别任务中实现了更高的适应性和可靠性，为解决模态缺失问题提供了有效方案。

中文摘要: 大规模多模态模型通过利用大量配对多模态训练数据，在各种视觉识别任务中表现出卓越性能。然而，在实际应用中，模态输入缺失或不完整常导致性能显著下降。近期研究聚焦于基于提示的策略以解决此问题，但现有方法受限于两大缺陷：(1) 静态提示缺乏适应不同缺失条件的灵活性；(2) 基础提示调优方法在关键模态缺失时难以确保可靠性能。为解决这些挑战，我们提出了一种新颖的协同提示（SyP）框架，用于处理模态缺失的稳健视觉识别。SyP包含两项关键创新：(I) 动态适配器，通过计算自适应缩放因子动态生成提示，取代静态参数以实现灵活的多模态适应；(II) 协同提示策略，结合静态和动态提示以平衡模态信息，确保关键模态缺失时的稳健推理。SyP在三个广泛使用的视觉识别数据集上显著优于现有方法，并在不同缺失率和条件下表现出稳健性。大量实验和消融研究验证了其处理缺失模态的有效性，突显了其卓越的适应性和可靠性。

</details>


### [123] [Patient-specific vs Multi-Patient Vision Transformer for Markerless Tumor Motion Forecasting](https://arxiv.org/abs/2507.07811)
**中文标题：患者特异性与多患者Vision Transformer在无标记肿瘤运动预测中的比较**

*Gauthier Rotsart de Hertaing,Dani Manjah,Benoit Macq*

主要分类: cs.CV

摘要简述: 本文首次将Vision Transformer（ViT）架构应用于无标记肿瘤运动预测，比较了患者特异性（PS）和多患者（MP）模型的性能。PS模型在训练数据充足时表现更优，而MP模型在无需重新训练的情况下对分次间解剖变异更具鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 精准预测肺部肿瘤运动对质子治疗中的剂量投递至关重要。尽管深度学习在无标记方法中占主导地位，但基于Transformer的架构在此领域尚未被探索，尽管其在轨迹预测中表现优异。

研究方法: 研究使用31名患者的4DCT扫描生成的数字重建放射影像（DRR）训练MP模型，另1名患者用于评估。PS模型仅使用目标患者的规划数据。两种模型均以16张DRR为输入，预测1秒内的肿瘤运动，并通过平均位移误差（ADE）和最终位移误差（FDE）评估性能。

研究结果: 在规划数据（T1）上，PS模型在所有训练集规模下均优于MP模型，尤其是数据量较大时（最多25,000张DRR）。然而，MP模型对分次间解剖变异更具鲁棒性，在治疗数据（T2）上无需重新训练即可达到与PS模型相当的性能。

研究结论: PS模型精度更高，但MP模型在临床时间受限的情况下提供了即插即用的鲁棒性能，更适合实际应用。

中文摘要: 背景：精准预测肺部肿瘤运动对质子治疗中的剂量投递至关重要。当前无标记方法主要依赖深度学习，但基于Transformer的架构在此领域尚未被探索，尽管其在轨迹预测中表现优异。目的：本研究提出一种基于Vision Transformer（ViT）的无标记肿瘤运动预测方法，评估了两种训练策略：患者特异性（PS）模型和多患者（MP）模型，并考虑了临床限制下的图像数量。方法：使用31名患者的4DCT扫描生成的DRR训练MP模型，另1名患者用于评估。PS模型仅使用目标患者的规划数据。两种模型均以16张DRR为输入，预测1秒内的肿瘤运动，并通过ADE和FDE评估性能。结果：在T1数据上，PS模型在所有训练集规模下均优于MP模型，尤其是数据量较大时。然而，MP模型对分次间解剖变异更具鲁棒性，在T2数据上无需重新训练即可达到与PS模型相当的性能。结论：PS模型精度更高，但MP模型在临床时间受限的情况下提供了即插即用的鲁棒性能。

</details>


### [124] [Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles](https://arxiv.org/abs/2507.07828)
**中文标题：基于内容的拼图求解器在损坏拼图上的基准测试**

*Richard Dirauf,Florian Wolz,Dario Zanca,Björn Eskofier*

主要分类: cs.CV

摘要简述: 本文研究了基于内容的拼图求解器在拼图损坏情况下的鲁棒性，发现深度学习模型通过数据增强能显著提升性能，其中Positional Diffusion模型表现最佳。


<details>
  <summary>详细信息</summary>
研究动机: 现有拼图求解器在真实场景（如文物碎片或文件碎片重组）中缺乏对损坏情况的评估，因此本文旨在测试其在拼图损坏（如缺失、边缘或内容腐蚀）下的表现。

研究方法: 引入三种拼图损坏类型（缺失、边缘腐蚀、内容腐蚀），评估启发式和深度学习求解器的表现，并通过数据增强优化深度学习模型。

研究结果: 标准拼图求解器在损坏增加时性能迅速下降，但深度学习模型通过微调和数据增强显著提升鲁棒性，尤其是Positional Diffusion模型表现突出。

研究结论: 研究为提升真实场景下拼图重建提供了方向，强调数据增强和深度学习模型优化的重要性。

中文摘要: 基于内容的拼图求解器已得到广泛研究，计算技术取得显著进展。然而，其评估常缺乏对真实应用（如文物碎片或文件碎片重组）至关重要的挑战。本文研究了当前最先进的基于内容拼图求解器的鲁棒性，引入三种拼图损坏类型：缺失、边缘腐蚀和内容腐蚀。通过评估启发式和深度学习求解器，分析其处理损坏的能力并指出关键局限。结果显示，标准拼图求解器在损坏增加时性能迅速下降，但深度学习模型通过数据增强微调显著提升鲁棒性。值得注意的是，高级Positional Diffusion模型适应性最强，在多数实验中表现最佳。基于研究结果，我们提出了提升真实场景拼图重建的潜在研究方向。

</details>


### [125] [Rethinking Query-based Transformer for Continual Image Segmentation](https://arxiv.org/abs/2507.07831)
**中文标题：重新思考基于查询的Transformer在持续图像分割中的应用**

*Yuchen Zhu,Cheng Shi,Dingyou Wang,Jiajin Tang,Zhengxuan Wei,Yu Wu,Guanbin Li,Sibei Yang*

主要分类: cs.CV

摘要简述: 本文提出SimCIS，一种基于查询的Transformer方法，用于持续图像分割任务，通过直接选择图像特征进行查询分配，解决现有解耦框架的塑性损失和输入顺序依赖问题，并在实验中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于查询的Transformer方法在持续图像分割任务中存在塑性损失和输入数据顺序依赖问题，本文旨在通过深入研究内置对象性，提出一种更简单且高效的解决方案。

研究方法: 提出SimCIS方法，核心思想是直接选择图像特征进行查询分配，确保“完美对齐”以保留对象性，同时允许查询选择新类别以提升塑性。此外，引入跨阶段一致性选择和基于“视觉查询”的重放机制以减少类别遗忘。

研究结果: 实验表明，SimCIS在多种分割任务、设置、划分和输入数据顺序下均优于现有最先进方法。

研究结论: SimCIS通过简单而强大的设计解决了持续图像分割中的关键问题，为未来研究提供了新的基线。

中文摘要: 类别增量/持续图像分割（CIS）旨在分阶段训练图像分割器，每个阶段的可用类别集不同。为了利用基于查询的Transformer内置的对象性（缓解掩码提议的灾难性遗忘），现有方法通常将掩码生成与持续学习过程解耦。然而，本研究发现了这种解耦框架的两个关键问题：塑性损失和输入数据顺序的严重依赖。为解决这些问题，我们深入研究了内置对象性，发现高度聚合的图像特征为查询通过简单特征对齐生成掩码提供了捷径。基于此，我们提出了SimCIS，一种简单而强大的CIS基线方法。其核心思想是直接选择图像特征进行查询分配，确保“完美对齐”以保留对象性，同时允许查询选择新类别以提升塑性。为进一步减少类别的灾难性遗忘，我们引入了跨阶段一致性选择和基于“视觉查询”的创新重放机制。实验表明，SimCIS在多种分割任务、设置、划分和输入数据顺序下均优于现有最先进方法。所有模型和代码将在https://github.com/SooLab/SimCIS公开。

</details>


### [126] [3D-ADAM: A Dataset for 3D Anomaly Detection in Advanced Manufacturing](https://arxiv.org/abs/2507.07838)
**中文标题：3D-ADAM：面向先进制造的3D异常检测数据集**

*Paul McHard,Florent P. Audonnet,Oliver Summerell,Sebastian Andraos,Paul Henderson,Gerardo Aragon-Camarasa*

主要分类: cs.CV

摘要简述: 3D-ADAM是首个大规模、高精度的3D工业异常检测数据集，包含14,120个高分辨率扫描和27,346个标注缺陷实例，覆盖12类工业表面缺陷，旨在推动鲁棒性3D异常检测模型的发展。


<details>
  <summary>详细信息</summary>
研究动机: 工业制造中表面缺陷是导致低产量的主要原因之一，现有数据集无法满足真实工业场景的需求，因此需要高质量、高精度的RGB+3D工业异常检测数据集。

研究方法: 3D-ADAM数据集通过4种工业深度成像传感器采集14,120个高分辨率扫描，涵盖217个独特零件，标注了27,346个缺陷实例和8,110个机械设计特征，并在真实工业环境中捕获数据。

研究结果: 评估显示，当前SOTA模型在3D-ADAM数据集上表现不佳，验证了其挑战性；专家标注调查进一步证实了数据集的工业相关性和质量。

研究结论: 3D-ADAM为3D异常检测提供了具有挑战性的基准，有望加速鲁棒性模型的发展，满足现代工业制造需求。

中文摘要: 表面缺陷是制造业低产量的主要原因之一，因此在制造过程中准确可靠地检测缺陷具有重要价值。现有的自动化缺陷检测方法在当前数据集上表现优异，但在真实工业场景中仍有不足，改进方法依赖于能反映真实场景的大规模数据集。然而，高质量、高精度的RGB+3D工业异常检测数据集稀缺，且通常不符合实际工业部署场景。为此，我们提出了3D-ADAM，首个大规模、高精度的3D异常检测工业数据集。3D-ADAM包含14,120个高分辨率扫描，覆盖217个独特零件，使用4种工业深度成像传感器捕获，并标注了27,346个缺陷实例，涵盖12类工业表面缺陷。此外，3D-ADAM还标注了8,110个机械设计特征，覆盖相关机械设计形式。与现有数据集不同，3D-ADAM在真实工业环境中捕获，包含零件位置和方向、相机定位、环境光照以及部分遮挡的变化。我们对多种RGB+3D异常检测任务的SOTA模型进行评估，结果表明该数据集对当前方法提出了显著挑战。通过行业合作伙伴的专家标注调查，我们进一步验证了数据集的工业相关性和质量。通过提供这一具有挑战性的基准，3D-ADAM旨在加速开发能够满足现代工业制造需求的鲁棒性3D异常检测模型。

</details>


### [127] [THUNDER: Tile-level Histopathology image UNDERstanding benchmark](https://arxiv.org/abs/2507.07860)
**中文标题：THUNDER：瓦片级病理学图像理解基准**

*Pierre Marza,Leo Fillioux,Sofiène Boutaj,Kunal Mahatha,Christian Desrosiers,Pablo Piantanida,Jose Dolz,Stergios Christodoulidis,Maria Vakalopoulou*

主要分类: cs.CV

摘要简述: THUNDER是一个针对数字病理学基础模型的瓦片级基准测试工具，旨在高效比较多种模型在多样化数据集和下游任务中的表现，同时分析特征空间、鲁棒性和预测不确定性。


<details>
  <summary>详细信息</summary>
研究动机: 数字病理学领域近期涌现了大量基础模型，但缺乏统一的评估标准。THUNDER旨在填补这一空白，通过全面比较不同模型，为研究提供清晰视角，并确保模型在医疗等关键领域的可靠使用。

研究方法: THUNDER是一个动态、易用的基准测试工具，支持多种先进基础模型和用户自定义模型的直接比较。通过16个数据集和23种基础模型的对比，研究特征分析、鲁棒性和不确定性。

研究结果: THUNDER成功比较了23种基础模型在16个数据集上的表现，提供了特征空间分析、鲁棒性和不确定性评估的全面结果。

研究结论: THUNDER为数字病理学领域提供了高效的基准测试工具，促进了模型比较和可靠性的评估，有助于推动该领域的研究进展。

中文摘要: 研究领域的进展往往难以评估，尤其是在短时间内涌现大量并发方法的情况下。数字病理学领域便是如此，近期发布了众多基础模型，作为瓦片级图像的特征提取器，用于各种下游任务，包括瓦片级和切片级问题。因此，对现有方法进行基准测试变得至关重要，以便更清晰地了解研究现状。特别是在医疗等关键领域，基准测试不仅应关注下游性能评估，还需揭示方法之间的主要差异，并进一步考虑不确定性和鲁棒性，以确保模型的可靠使用。为此，我们提出了THUNDER，一个针对数字病理学基础模型的瓦片级基准测试工具，支持高效比较多种模型在多样化数据集和下游任务中的表现，研究其特征空间，并评估基于嵌入的预测的鲁棒性和不确定性。THUNDER是一个快速、易用、动态的基准测试工具，已支持大量先进基础模型及用户自定义模型的直接瓦片级比较。本文对23种基础模型在16个不同数据集上的表现进行了全面比较，涵盖多样化任务、特征分析和鲁棒性评估。THUNDER的代码已公开在https://github.com/MICS-Lab/thunder。

</details>


### [128] [Single-Step Latent Diffusion for Underwater Image Restoration](https://arxiv.org/abs/2507.07878)
**中文标题：单步潜在扩散用于水下图像恢复**

*Jiayi Wu,Tianfu Wang,Md Abu Bakr Siddique,Md Jahidul Islam,Cornelia Fermuller,Yiannis Aloimonos,Christopher A. Metzler*

主要分类: cs.CV

摘要简述: 本文提出了一种名为SLURPP的新型网络架构，结合预训练的潜在扩散模型和显式场景分解，用于水下图像恢复。该方法通过物理合成数据生成管道训练，显著提升了恢复效果和速度，比现有方法快200倍，并在PSNR上提升约3 dB。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于像素域扩散的水下图像恢复方法在处理复杂几何和深度变化的场景时，计算量大且易产生不真实伪影。本文旨在克服这些限制，提升水下图像恢复的性能和效率。

研究方法: SLURPP结合预训练的潜在扩散模型（编码场景几何和深度的强先验）与显式场景分解（建模光衰减和背散射效应）。通过物理合成数据生成管道，将多样化的水下退化效果应用于现有陆地图像数据集，生成带密集标注的训练数据。

研究结果: SLURPP在合成和真实世界基准测试中表现出色，比现有扩散方法快200倍，PSNR提升约3 dB，并在真实数据上实现显著的定性改进。

研究结论: SLURPP通过结合潜在扩散模型和显式场景分解，显著提升了水下图像恢复的速度和效果，为水下应用提供了高效且高质量的解决方案。

中文摘要: 水下图像恢复算法旨在恢复水下成像场景的颜色、对比度和外观，是海洋生态、水产养殖、水下建筑和考古等领域的关键工具。现有基于像素域扩散的图像恢复方法在简单场景中有效，但在复杂几何和深度变化的场景中计算量大且易产生不真实伪影。本文通过结合新型网络架构（SLURPP）与精确的合成数据生成管道克服了这些限制。SLURPP结合预训练的潜在扩散模型（编码场景几何和深度的强先验）与显式场景分解（建模光衰减和背散射效应）。为训练SLURPP，设计了基于物理的水下图像合成管道，将多样化的水下退化效果应用于现有陆地图像数据集，生成带密集标注的训练数据。在合成和真实世界基准测试中，SLURPP表现出色，比现有扩散方法快200倍，PSNR提升约3 dB，并在真实数据上实现显著的定性改进。项目网站：https://tianfwang.github.io/slurpp/。

</details>


### [129] [MIRA: A Novel Framework for Fusing Modalities in Medical RAG](https://arxiv.org/abs/2507.07902)
**中文标题：MIRA：一种融合多模态的医疗检索增强生成新框架**

*Jinhong Wang,Tajamul Ashraf,Zongyan Han,Jorma Laaksonen,Rao Mohammad Anwer*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MIRA的新型框架，用于优化医疗多模态大语言模型（MLLM）的事实准确性。MIRA通过动态调整检索上下文和整合图像嵌入与医学知识库，显著提升了模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的多模态大语言模型（MLLM）在医疗诊断中常生成与医学知识不符的答案，而检索增强生成（RAG）虽能提高准确性，但存在检索不足或过度检索的问题，导致信息遗漏或误导。MIRA旨在解决这些问题，优化模型的事实准确性。

研究方法: MIRA框架包含两个核心模块：(1) 动态调整检索上下文的“重新思考与重排”模块，以管理事实风险；(2) 整合图像嵌入和医学知识库的医疗RAG框架，结合查询重写模块实现高效多模态推理。

研究结果: 在公开的医疗视觉问答和报告生成基准测试中，MIRA显著提升了事实准确性和整体性能，取得了最新的最优结果。

研究结论: MIRA通过动态调整检索策略和高效整合多模态数据，有效提升了医疗MLLM的事实准确性，为AI辅助医疗诊断提供了更可靠的解决方案。

中文摘要: 多模态大语言模型（MLLM）在AI辅助医疗诊断中取得了显著进展，但其生成的答案常与医学知识不符。检索增强生成（RAG）通过整合外部资源提高了事实准确性，但仍面临两大挑战：检索不足可能遗漏关键信息，而过度检索则可能引入无关或误导性内容，干扰模型输出；此外，即使模型初始答案正确，过度依赖检索数据也可能导致事实错误。为解决这些问题，我们提出了多模态智能检索与增强（MIRA）框架，旨在优化MLLM的事实准确性。MIRA包含两个关键组件：(1) 动态调整检索上下文数量的“重新思考与重排”模块，以管理事实风险；(2) 整合图像嵌入和医学知识库的医疗RAG框架，结合查询重写模块实现高效多模态推理，使模型能有效结合其固有知识与外部参考。我们在公开的医疗视觉问答和报告生成基准测试中验证了MIRA的效果，结果表明其显著提升了事实准确性和整体性能，达到了最新的最优水平。代码发布于https://github.com/mbzuai-oryx/MIRA。

</details>


### [130] [Hardware-Aware Feature Extraction Quantisation for Real-Time Visual Odometry on FPGA Platforms](https://arxiv.org/abs/2507.07903)
**中文标题：面向FPGA平台的硬件感知特征提取量化实时视觉里程计**

*Mateusz Wasala,Mateusz Smolarczyk,Michal Danilowicz,Tomasz Kryjak*

主要分类: cs.CV

摘要简述: 本文提出了一种基于量化SuperPoint卷积神经网络的嵌入式实现方法，用于实时视觉里程计任务，通过硬件感知优化在FPGA平台上实现高效部署，性能优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 现代导航系统（如自动驾驶车辆、无人机等）需要高精度的位置估计，而视觉里程计（VSLAM）依赖于从视觉数据中可靠提取特征点。然而，资源有限的嵌入式系统对计算效率要求极高，因此需要一种既能保持高质量检测又能降低计算需求的方法。

研究方法: 采用量化SuperPoint卷积神经网络，结合Brevitas库和FINN框架进行模型量化和硬件感知优化，并在AMD/Xilinx Zynq UltraScale+ FPGA平台上实现部署，评估了深度学习处理单元（DPUs）的性能。

研究结果: 在FPGA平台上实现了640 x 480像素图像的处理速度高达54 fps，优于现有技术。通过TUM数据集的实验验证了不同量化技术对模型精度和性能的影响。

研究结论: 提出的硬件感知特征提取量化方法在FPGA平台上实现了高效的实时视觉里程计任务，为资源有限的嵌入式系统提供了一种可行的解决方案。

中文摘要: 精确的位置估计对于现代导航系统（如地面车辆、船舶和无人机）至关重要。视觉同时定位与建图（VSLAM）中的视觉里程计依赖于从视觉输入数据中可靠提取显著特征点。本文提出了一种嵌入式实现的无监督架构，能够检测和描述特征点，基于量化的SuperPoint卷积神经网络。目标是减少模型的计算需求，同时保持高检测质量，从而便于在资源有限的平台（如移动或嵌入式系统）上高效部署。我们在AMD/Xilinx Zynq UltraScale+ FPGA系统芯片（SoC）平台上实现了该解决方案，评估了深度学习处理单元（DPUs）的性能，并使用Brevitas库和FINN框架进行模型量化和硬件感知优化。这使得我们能够在FPGA平台上以高达54 fps的速度处理640 x 480像素的图像，性能优于该领域的现有技术。通过在TUM数据集上的实验，我们验证并讨论了不同量化技术对模型在视觉里程计任务中精度和性能的影响。

</details>


### [131] [Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement](https://arxiv.org/abs/2507.07908)
**中文标题：不仅一致性：利用时空不一致性增强远程生理测量的测试时自适应**

*Xiao Yang,Yuxuan Fan,Can Liu,Houcheng Su,Weichen Guo,Jiyao Wang,Dengbo He*

主要分类: cs.CV

摘要简述: 本文提出了一种名为CiCi的新型测试时自适应（TTA）策略，用于远程光电容积描记（rPPG）任务。通过结合时空一致性和不一致性先验知识，并引入梯度动态控制机制，该方法在多个数据集上表现优异，无需源数据即可实现实时自监督适应。


<details>
  <summary>详细信息</summary>
研究动机: 现有的rPPG模型在未见过部署环境中的适应性受到隐私问题和实时适应限制的制约。因此，本文旨在提出一种完全基于测试时自适应的策略，以提升模型在实际部署中的表现。

研究方法: 基于生理学先验知识，本文观察到rPPG信号在频域具有时空一致性，而在时域存在显著不一致性。为此，提出了一种名为CiCi的框架，结合一致性和不一致性先验，并通过梯度动态控制机制避免先验冲突，实现稳定适应。

研究结果: 在五个不同数据集上的实验表明，该方法在测试时自适应协议下显著优于现有技术，无需源数据即可实现实时自监督适应，表现出最先进的性能。

研究结论: 本文提出的CiCi框架通过结合时空一致性和不一致性先验，有效提升了rPPG模型在测试时的自适应能力，为实际部署提供了高效解决方案。

中文摘要: 远程光电容积描记（rPPG）已成为一种利用摄像头监测生理信号的非侵入性方法。尽管已有多种领域自适应和泛化方法被提出以提升深度rPPG模型在未知部署环境中的适应性，但隐私问题和实时适应限制等因素限制了其实际应用。因此，本文旨在为rPPG任务提出一种全新的完全测试时自适应（TTA）策略。具体而言，基于生理学先验知识和我们的观察，我们发现rPPG信号不仅在频域具有时空一致性，而且在时域存在显著不一致性。为此，我们通过结合一致性和不一致性先验，提出了一种创新的基于专家知识的自监督框架——一致性-不一致性集成（CiCi），以增强模型在推理时的自适应能力。此外，我们的方法还引入了梯度动态控制机制，以缓解先验之间的潜在冲突，确保实例间的稳定适应。通过在五个不同数据集上的TTA协议实验，我们的方法在无需源数据的情况下，显著优于现有技术，实现了实时自监督适应的最先进性能。代码将稍后发布。

</details>


### [132] [Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and Identification Strategies for Laboratory Mice](https://arxiv.org/abs/2507.07929)
**中文标题：迈向连续笼内监测：实验室小鼠追踪与识别策略的评估**

*Juan Pablo Oberhauser,Daniel Grzenda*

主要分类: cs.CV

摘要简述: 本文提出了一种实时识别算法，用于在数字笼中准确追踪和识别佩戴定制耳标的小鼠，解决了高密度饲养、外观相似和高活动性带来的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 实验室小鼠的连续自动化监测能提高数据准确性并改善动物福利，但高密度饲养和相似外观导致个体识别困难。本文旨在开发一种实时识别算法以解决这一问题。

研究方法: 方法包括三部分：(1) 结合外观和运动线索的多目标追踪器（MouseTracks）；(2) 基于Transformer的ID分类器（Mouseformer）；(3) 用于分配最终ID预测的轨迹关联线性程序（MouseMap）。

研究结果: 该算法能以每秒30帧的速度全天候覆盖笼子，显著提高了追踪效率并减少了ID切换，优于现有方法。

研究结论: 本文提出的追踪和识别算法在小鼠品系和环境因素中表现优异，为连续监测提供了可靠解决方案。

中文摘要: 连续自动化监测实验室小鼠能够提高数据收集的准确性，并通过实时洞察改善动物福利。通过将行为和生理监测整合到笼内，研究人员可以更动态且临床相关地描述疾病进展和治疗效果。然而，由于小鼠的高密度饲养、相似外观、高活动性和频繁互动，提供个体指标具有挑战性。为解决这些问题，我们开发了一种实时识别（ID）算法，能够准确为佩戴定制耳标的小鼠分配ID预测，这些小鼠生活在由摄像头监控的数字笼中。我们的流程包括三部分：(1) 结合小鼠外观和运动线索的定制多目标追踪器（MouseTracks）；(2) 基于Transformer的ID分类器（Mouseformer）；(3) 用于为轨迹分配最终ID预测的轨迹关联线性程序（MouseMap）。我们的模型以每秒30帧的速度全天候覆盖笼子，基于定制耳标为动物分配ID。结果表明，与现有小鼠追踪方法相比，我们的定制追踪和ID流程提高了追踪效率，并减少了不同小鼠品系和环境因素下的ID切换。

</details>


### [133] [TinierHAR: Towards Ultra-Lightweight Deep Learning Models for Efficient Human Activity Recognition on Edge Devices](https://arxiv.org/abs/2507.07949)
**中文标题：TinierHAR：面向边缘设备高效人类活动识别的超轻量级深度学习模型**

*Sizhen Bian,Mengxi Liu,Vitor Fortes Rey,Daniel Geissler,Paul Lukowicz*

主要分类: cs.CV

摘要简述: TinierHAR提出了一种超轻量级深度学习模型，用于在边缘设备上高效实现人类活动识别（HAR），显著减少了参数和计算量，同时保持了性能。


<details>
  <summary>详细信息</summary>
研究动机: 在资源受限的可穿戴设备上实现高效的人类活动识别（HAR）需要兼顾准确性和计算效率。现有模型往往在两者之间难以平衡，因此需要一种更轻量化的解决方案。

研究方法: TinierHAR结合了残差深度可分离卷积、门控循环单元（GRU）和时间聚合技术，构建了一种超轻量级架构。通过系统消融实验，分析了各组件对性能的贡献。

研究结果: 在14个公开HAR数据集上的测试表明，TinierHAR参数减少了2.7倍（相比TinyHAR）和43.3倍（相比DeepConvLSTM），计算量分别减少了6.4倍和58.6倍，同时保持了平均F1分数。

研究结论: TinierHAR为高效HAR系统设计提供了新的基准，并通过开源促进了边缘HAR研究的进一步发展。

中文摘要: 在资源受限的可穿戴设备上实现人类活动识别（HAR）需要兼顾准确性和计算效率的推理模型。本文提出了TinierHAR，一种超轻量级深度学习架构，结合了残差深度可分离卷积、门控循环单元（GRU）和时间聚合技术，在不牺牲性能的情况下实现了最优效率。在14个公开HAR数据集上的评估显示，TinierHAR的参数减少了2.7倍（相比TinyHAR）和43.3倍（相比DeepConvLSTM），计算量分别减少了6.4倍和58.6倍，同时保持了平均F1分数。此外，本文首次通过系统消融实验分析了空间-时间组件在TinierHAR、TinyHAR和经典DeepConvLSTM中的贡献，为设计高效HAR系统提供了实用见解。最后，我们讨论了研究结果，并提出了未来高效HAR系统的设计原则。为推动边缘HAR研究，我们开源了所有相关材料以供未来基准测试。

</details>


### [134] [Martian World Models: Controllable Video Synthesis with Physically Accurate 3D Reconstructions](https://arxiv.org/abs/2507.07978)
**中文标题：火星世界模型：基于物理精确3D重建的可控视频合成**

*Longfei Li,Zhiwen Fan,Wenyan Cong,Xinhang Liu,Yuyang Yin,Matt Foutter,Panwang Pan,Chenyu You,Yue Wang,Zhangyang Wang,Yao Zhao,Marco Pavone,Yunchao Wei*

主要分类: cs.CV

摘要简述: 本文提出了一种结合3D重建与视频生成的全新方法，用于合成逼真的火星景观视频，解决了火星数据稀缺与地球图像差异的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 合成逼真的火星景观视频对任务演练和机器人模拟至关重要，但由于高质量火星数据稀缺且火星与地球图像差异显著，这一任务面临独特挑战。

研究方法: 方法包括两部分：1) M3arsSynth数据管道，从NASA的真实立体导航图像重建3D火星环境并渲染多视角视频；2) MarsGen视频生成器，基于初始帧和可选条件（如相机轨迹或文本提示）合成逼真视频。

研究结果: 实验结果表明，该方法优于基于地球数据集训练的视频合成模型，在视觉逼真度和3D结构一致性上表现更优。

研究结论: 通过结合3D重建与视频生成，本文成功解决了火星视频合成的挑战，为任务模拟提供了高效工具。

中文摘要: 合成逼真的火星景观视频对任务演练和机器人模拟至关重要，但由于高质量火星数据稀缺且火星与地球图像差异显著，这一任务面临独特挑战。为解决这些问题，我们提出了一种包含两个关键组件的整体解决方案：1) 多模态火星合成（M3arsSynth）数据管道，从NASA行星数据系统（PDS）的真实立体导航图像重建3D火星环境，并渲染高保真多视角3D视频序列；2) 火星地形视频生成器MarsGen，合成与3D结构几何一致且视觉逼真的新视频。M3arsSynth引擎覆盖多种火星地形和采集日期，能够生成物理精确的3D表面模型，分辨率达到米级。MarsGen在M3arsSynth数据上微调，可根据初始帧和可选条件（如相机轨迹或文本提示）合成视频，支持在新环境中生成视频。实验结果表明，我们的方法优于基于地球数据集训练的视频合成模型，在视觉逼真度和3D结构一致性上表现更优。

</details>


### [135] [Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling](https://arxiv.org/abs/2507.07982)
**中文标题：几何强制：将视频扩散与3D表示结合以实现一致的世界建模**

*Haoyu Wu,Diankun Wu,Tianyu He,Junliang Guo,Yang Ye,Yueqi Duan,Jiang Bian*

主要分类: cs.CV

摘要简述: 本文提出Geometry Forcing方法，通过将视频扩散模型与3D表示结合，提升模型对几何结构的感知能力，显著改善了视频生成的视觉质量和3D一致性。


<details>
  <summary>详细信息</summary>
研究动机: 视频扩散模型仅基于原始视频数据训练时，往往无法捕捉有意义的几何感知结构。为了弥补视频扩散模型与物理世界3D本质之间的差距，本文提出了一种简单有效的方法。

研究方法: Geometry Forcing通过两种互补的对齐目标（角度对齐和尺度对齐），将视频扩散模型的中间表示与预训练的几何基础模型特征对齐，从而引导模型学习几何感知结构。

研究结果: 实验结果表明，该方法在相机视角条件和动作条件视频生成任务中，显著提升了视觉质量和3D一致性，优于基线方法。

研究结论: Geometry Forcing成功地将视频扩散模型与3D表示结合，为一致的世界建模提供了有效解决方案。

中文摘要: 视频本质上是动态3D世界的2D投影。然而，我们的分析表明，仅基于原始视频数据训练的视频扩散模型通常无法在其学习表示中捕捉有意义的几何感知结构。为了弥合视频扩散模型与物理世界3D本质之间的差距，我们提出了Geometry Forcing，这是一种简单而有效的方法，鼓励视频扩散模型内化潜在的3D表示。我们的关键见解是通过将模型的中间表示与预训练的几何基础模型特征对齐，引导其朝向几何感知结构。为此，我们引入了两种互补的对齐目标：角度对齐（通过余弦相似性强制执行方向一致性）和尺度对齐（通过从归一化的扩散表示回归未归一化的几何特征来保留尺度相关信息）。我们在相机视角条件和动作条件视频生成任务上评估了Geometry Forcing。实验结果表明，我们的方法在视觉质量和3D一致性方面显著优于基线方法。项目页面：https://GeometryForcing.github.io。

</details>


### [136] [OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding](https://arxiv.org/abs/2507.07984)
**中文标题：OST-Bench：评估多模态大语言模型在线时空场景理解能力**

*JingLi Lin,Chenming Zhu,Runsen Xu,Xiaohan Mao,Xihui Liu,Tai Wang,Jiangmiao Pang*

主要分类: cs.CV

摘要简述: OST-Bench是一个评估多模态大语言模型（MLLMs）在线时空场景理解能力的新基准，强调动态感知和历史记忆整合，发现现有模型在复杂时空推理任务上表现不佳。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准多基于离线固定输入，无法反映真实世界中动态探索的挑战。OST-Bench旨在填补这一空白，评估模型在在线时空场景中的表现。

研究方法: 通过高效数据收集流程，基于ScanNet、Matterport3D和ARKitScenes构建了1.4k场景和10k问答对的基准数据集，并评估多个领先MLLMs的在线时空推理能力。

研究结果: 实验显示，现有MLLMs在复杂时空推理任务上表现不佳，随着探索时间延长和记忆增长，准确性显著下降。错误模式分析表明，空间推理需求和长期记忆检索是主要瓶颈。

研究结论: OST-Bench揭示了在线时空推理的核心挑战，为未来研究提供了方向。数据集和基准已开源，以促进领域发展。

中文摘要: 近年来，多模态大语言模型（MLLMs）在视觉与语言结合的复杂推理任务中展现出卓越能力。然而，现有基准多基于离线固定输入，无法反映真实世界中动态探索的挑战。为此，我们提出了OST-Bench，一个从主动探索场景视角评估在线时空理解能力的基准。在线性强调对增量获取的观察进行实时处理和推理，而时空性则要求整合当前视觉输入与历史记忆以支持动态空间推理。OST-Bench更贴近真实世界中的具身感知挑战。通过高效的数据收集流程，OST-Bench基于ScanNet、Matterport3D和ARKitScenes构建了1.4k场景和10k问答对。我们对多个领先MLLMs进行了评估，发现它们在复杂时空推理任务上表现不佳。在线设置下，随着探索时间延长和记忆增长，模型准确性显著下降。通过进一步实验分析，我们识别出模型的常见错误模式，发现基于复杂线索的空间推理需求和长期记忆检索需求分别在两个维度上显著降低了模型性能，凸显了提升在线具身推理能力需解决的核心挑战。为促进该领域的研究与发展，我们的代码、数据集和基准均已开源。项目页面：https://rbler1234.github.io/OSTBench.github.io/

</details>


### [137] [CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is Why](https://arxiv.org/abs/2507.07985)
**中文标题：CLIP无法从自然数据中学习对象-属性绑定的原因解析**

*Bijay Gurung,David T. Hoffmann,Thomas Brox*

主要分类: cs.CV

摘要简述: 研究发现CLIP模型无法从自然数据中学习对象-属性绑定，原因是数据特性（如低属性密度、不完整标注和显著性偏见）影响了性能。仅当数据满足特定条件时，CLIP才能实现近乎完美的绑定学习。


<details>
  <summary>详细信息</summary>
研究动机: 尽管CLIP等对比视觉语言模型应用广泛，但其表征存在明显缺陷，例如无法区分对象与属性的绑定关系（如“黄色潜艇和蓝色巴士”与“蓝色潜艇和黄色巴士”）。此前尝试通过增加硬负样本或修改架构未能完全解决问题，因此研究团队怀疑数据特性是关键影响因素。

研究方法: 研究通过合成数据集系统分析数据特性对CLIP绑定学习能力的影响，重点关注自然数据的常见属性（如低属性密度、不完整标注和显著性偏见）。

研究结果: 研究发现，自然数据的特性（如低属性密度和显著性偏见）对CLIP的绑定学习能力有负面影响。即使增加批量大小或显式创建硬负样本，CLIP仍无法可靠学习绑定。仅当数据满足特定条件时，CLIP才能实现近乎完美的绑定学习。

研究结论: 数据特性是影响CLIP学习对象-属性绑定的关键因素。仅优化模型架构或训练策略不足以解决问题，需从数据层面入手，确保数据满足特定条件才能提升绑定性能。

中文摘要: 对比视觉语言模型（如CLIP）被广泛应用于零样本分类或多模态模型的视觉编码器。尽管其流行，但其表征存在显著缺陷。例如，CLIP模型学习的是“词袋”表征，因此无法区分“黄色潜艇和蓝色巴士”与“蓝色潜艇和黄色巴士”的图像。此前尝试通过增加硬负样本或修改架构未能完全解决问题。我们怀疑，解决CLIP绑定问题的关键隐藏在学习算法最重要的部分：数据。本研究通过合成数据集严格分析数据特性对CLIP绑定学习能力的影响。研究发现，自然数据的常见特性（如低属性密度、不完整标注和显著性偏见）对绑定性能有负面影响。与普遍观点相反，增加批量大小或显式创建硬负样本均无法使CLIP学习可靠的绑定。仅当数据满足我们识别的特定特性时，CLIP才能实现近乎完美的绑定学习。

</details>


### [138] [Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs](https://arxiv.org/abs/2507.07990)
**中文标题：多粒度时空令牌合并：无需训练的视频大语言模型加速方法**

*Jeongseok Hyun,Sukjun Hwang,Su Ho Han,Taeoh Kim,Inwoong Lee,Dongyoon Wee,Joon-Young Lee,Seon Joo Kim,Minho Shim*

主要分类: cs.CV

摘要简述: 本文提出了一种无需训练的视频大语言模型加速方法STTM，通过多粒度时空令牌合并，显著降低计算成本，同时保持高精度。


<details>
  <summary>详细信息</summary>
研究动机: 视频大语言模型（LLMs）通过大量时空令牌实现强大的视频理解能力，但计算成本随令牌数量呈二次方增长。现有方法未充分利用视频数据的局部时空冗余性，导致效率低下。

研究方法: STTM方法首先将每帧视频转换为多粒度空间令牌（基于四叉树结构的粗细搜索），然后在时间维度上进行定向成对合并，从而减少令牌数量。

研究结果: 在六个视频问答基准测试中，STTM表现优于现有令牌缩减方法。在50%令牌预算下，速度提升2倍，精度仅下降0.5%；在30%预算下，速度提升3倍，精度下降2%。此外，STTM支持跨问题的KV缓存复用。

研究结论: STTM是一种高效且无需训练的视频LLM加速方法，通过利用时空冗余性显著提升计算效率，同时保持高精度。

中文摘要: 视频大语言模型（LLMs）通过大量时空令牌实现强大的视频理解能力，但计算成本随令牌数量呈二次方增长。为解决这一问题，我们提出了一种无需训练的时空令牌合并方法STTM。其核心思想是利用视频数据中未被充分挖掘的局部时空冗余性。STTM首先通过四叉树结构的粗细搜索将每帧转换为多粒度空间令牌，随后在时间维度上进行定向成对合并。这种分解式合并方法在六个视频问答基准测试中优于现有令牌缩减技术。值得注意的是，在50%令牌预算下，STTM实现了2倍速度提升，精度仅下降0.5%；在30%预算下，速度提升3倍，精度下降2%。此外，STTM与查询无关，支持对同一视频的不同问题复用KV缓存。项目页面详见https://www.jshyun.me/projects/sttm。

</details>


### [139] [Multigranular Evaluation for Brain Visual Decoding](https://arxiv.org/abs/2507.07993)
**中文标题：大脑视觉解码的多粒度评估**

*Weihao Xia,Cengiz Oztireli*

主要分类: cs.CV

摘要简述: 现有的大脑视觉解码评估方法依赖粗粒度指标，掩盖了模型间差异，缺乏神经科学基础，且无法捕捉细粒度视觉区分。为此，我们提出了BASIC，一个多粒度的统一评估框架，量化解码图像与真实图像在结构保真度、推理对齐和上下文连贯性上的表现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大脑视觉解码评估方法存在粗粒度指标掩盖模型差异、缺乏神经科学基础以及无法捕捉细粒度视觉区分的问题，亟需一种更全面、可解释的评估框架。

研究方法: 提出了BASIC框架，通过多粒度评估方法，包括结构层面的分层分割指标（前景、语义、实例和组件掩码）和语义层面的结构化场景表示（对象、属性和关系），结合多模态大语言模型进行详细、可扩展的比较。

研究结果: 在多个刺激-神经影像数据集上对多种视觉解码方法进行了基准测试，BASIC框架提供了更具区分性、可解释性和全面性的评估结果。

研究结论: BASIC框架为大脑视觉解码方法提供了更全面、可解释和区分性的评估基础，弥补了现有方法的不足。

中文摘要: 现有的大脑视觉解码评估方法主要依赖粗粒度指标，掩盖了模型间的差异，缺乏神经科学基础，且无法捕捉细粒度的视觉区分。为解决这些问题，我们提出了BASIC，一个统一的、多粒度的评估框架，共同量化解码图像与真实图像在结构保真度、推理对齐和上下文连贯性上的表现。在结构层面，我们引入了一套基于分割的分层指标，包括前景、语义、实例和组件掩码，基于掩码结构的粒度感知对应关系。在语义层面，我们利用多模态大语言模型提取结构化场景表示（包括对象、属性和关系），实现与真实刺激的详细、可扩展且富含上下文的比较。我们在这一统一评估框架下对多种视觉解码方法在多个刺激-神经影像数据集上进行了基准测试。这些标准共同为衡量大脑视觉解码方法提供了更具区分性、可解释性和全面性的基础。

</details>


### [140] [Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection](https://arxiv.org/abs/2507.07994)
**中文标题：草图你的关键点：基于草图的少样本关键点检测**

*Subhajit Maity,Ayan Kumar Bhunia,Subhadeep Koley,Pinaki Nath Chowdhury,Aneeshan Sain,Yi-Zhe Song*

主要分类: cs.CV

摘要简述: 本文提出了一种基于草图的少样本关键点检测框架，通过利用草图作为无源数据替代方案，解决了少样本学习中数据分布不匹配的问题。


<details>
  <summary>详细信息</summary>
研究动机: 现代机器感知中的关键点检测在少样本学习中面临挑战，尤其是当查询数据与源数据分布不一致时。草图作为一种常见的人类表达形式，提供了一种无源数据替代方案，但跨模态嵌入和用户特定草图风格的处理仍是难题。

研究方法: 本文提出了一种原型框架，结合基于网格的定位器和原型域适应技术，解决了跨模态嵌入和用户特定草图风格的挑战。

研究结果: 通过大量实验，证明了该框架在少样本收敛和新颖关键点及类别检测中的成功。

研究结论: 该框架为少样本关键点检测提供了一种有效的无源数据解决方案，具有广泛的应用潜力。

中文摘要: 关键点检测是现代机器感知的重要组成部分，但在少样本学习中面临挑战，尤其是当查询数据与源数据分布不一致时。本文通过利用草图这一常见的人类表达形式，提供了一种无源数据替代方案。然而，跨模态嵌入和用户特定草图风格的处理仍是难题。我们提出的框架通过原型设置、基于网格的定位器和原型域适应技术克服了这些障碍。通过大量实验，我们还证明了该框架在少样本收敛和新颖关键点及类别检测中的成功。

</details>


### [141] [Single-pass Adaptive Image Tokenization for Minimum Program Search](https://arxiv.org/abs/2507.07995)
**中文标题：单次自适应图像标记用于最小程序搜索**

*Shivam Duggal,Sanghyun Byun,William T. Freeman,Antonio Torralba,Phillip Isola*

主要分类: cs.CV

摘要简述: 本文提出了一种单次自适应图像标记方法KARL，通过单次前向传播预测图像的适当标记数量，以逼近其Kolmogorov复杂度（KC），从而在保持性能的同时减少计算开销。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉表示学习系统通常使用固定长度的表示，忽略了输入数据的复杂度或熟悉度变化。虽然最近的自适应标记方法通过分配可变长度表示解决了这一问题，但通常需要在测试时搜索多种编码以找到最具预测性的表示。受Kolmogorov复杂度原理启发，本文旨在开发一种单次自适应标记方法，避免多轮搜索的开销。

研究方法: 提出了一种名为KARL的单次自适应标记器，其通过单次前向传播预测图像的标记数量，并在达到近似KC时停止。训练过程类似于“倒置强化学习”范式，通过学习基于期望重建质量的标记停止条件。

研究结果: KARL在单次运行中达到了与现有自适应标记器相当的性能。此外，本文还分析了KARL的扩展规律，研究了编码器/解码器大小、连续与离散标记化等因素的影响，并通过概念性研究揭示了自适应图像标记与算法信息理论之间的联系。

研究结论: KARL提供了一种高效的单次自适应图像标记方法，其性能与多轮搜索方法相当，同时显著降低了计算成本。研究还揭示了图像复杂度（KC）与人类直觉的一致性。

中文摘要: 根据算法信息理论（AIT），智能表示将数据压缩为能够重建其内容的最短程序，表现出较低的Kolmogorov复杂度（KC）。然而，大多数视觉表示学习系统对所有输入使用固定长度的表示，忽略了复杂度或熟悉度的变化。最近的自适应标记方法通过分配可变长度表示解决了这一问题，但通常需要在测试时搜索多种编码以找到最具预测性的表示。受Kolmogorov复杂度原理启发，我们提出了一种单次自适应标记器KARL，其在单次前向传播中预测图像的适当标记数量，并在达到近似KC时停止。标记数量作为最小描述长度的代理。KARL的训练过程类似于“倒置强化学习”范式，通过学习基于期望重建质量的标记停止条件。KARL在单次运行中达到了与现有自适应标记器相当的性能。我们提出了KARL的扩展规律，分析了编码器/解码器大小、连续与离散标记化等因素的作用。此外，我们还通过概念性研究探讨了自适应图像标记与算法信息理论之间的类比，研究了预测的图像复杂度（KC）在结构vs.噪声和分布内vs.分布外熟悉度等维度上的表现，揭示了其与人类直觉的一致性。

</details>


### [142] [MGVQ: Could VQ-VAE Beat VAE? A Generalizable Tokenizer with Multi-group Quantization](https://arxiv.org/abs/2507.07997)
**中文标题：MGVQ：VQ-VAE能否超越VAE？一种基于多组量化的通用标记化方法**

*Mingkai Jia,Wei Yin,Xiaotao Hu,Jiaxin Guo,Xiaoyang Guo,Qian Zhang,Xiao-Xiao Long,Ping Tan*

主要分类: cs.CV

摘要简述: 本文提出了一种名为MGVQ的新方法，通过多组量化增强离散码本的表示能力，显著提升了VQ-VAE的重建质量，并在多个基准测试中取得了最优性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有VQ-VAE在量化策略上仍有改进空间，与VAE相比存在较大差距。本文旨在通过增强码本表示能力，减少信息损失，从而提升重建质量。

研究方法: 提出保留潜在维度以保留编码特征，并引入多组子码本进行量化。此外，构建了512p和2k分辨率的零样本基准测试以评估性能。

研究结果: MGVQ在ImageNet和8个零样本基准测试中均取得最优性能，显著优于SD-VAE（rFID 0.49 vs. 0.91），并在所有基准测试中PSNR表现最佳。

研究结论: MGVQ通过多组量化显著提升了VQ-VAE的重建性能，为高清图像处理任务提供了高保真解决方案。

中文摘要: 向量量化变分自编码器（VQ-VAE）是将连续视觉数据压缩为离散标记的基础模型。现有方法试图改进量化策略以提高重建质量，但VQ-VAE与VAE之间仍存在较大差距。为缩小这一差距，我们提出了一种名为MGVQ的新方法，通过增强离散码本的表示能力，优化码本训练并减少信息损失，从而提升重建质量。具体而言，我们保留潜在维度以保留编码特征，并引入多组子码本进行量化。此外，我们构建了分辨率分别为512p和2k的全面零样本基准测试，以严格评估现有方法的重建性能。MGVQ在ImageNet和8个零样本基准测试中均取得了最优性能。值得注意的是，与SD-VAE相比，我们在ImageNet上显著优于其（rFID 0.49 vs. 0.91），并在所有零样本基准测试中PSNR表现最佳。这些结果凸显了MGVQ在重建任务中的优越性，并为高清图像处理任务中的保真度提供了新思路。代码将在https://github.com/MKJia/MGVQ公开。

</details>


### [143] [Impact of Pretraining Word Co-occurrence on Compositional Generalization in Multimodal Models](https://arxiv.org/abs/2507.08000)
**中文标题：预训练词共现对多模态模型组合泛化能力的影响**

*Helen Qu,Sang Michael Xie*

主要分类: cs.CV

摘要简述: 本文研究了预训练数据中词共现统计对多模态模型组合泛化能力的影响，发现词共现频率与模型准确性高度相关，并提出了改进组合泛化的需求。


<details>
  <summary>详细信息</summary>
研究动机: CLIP和大型多模态模型（LMMs）在训练数据中高频率概念上表现良好，但概念组合对组合泛化的影响尚不明确。本文旨在探究词共现统计如何影响模型性能。

研究方法: 通过点互信息（PMI）量化词共现频率，使用合成图像和自然图像测试CLIP和LMMs在不同PMI值下的零样本准确性，并分析其相关性。

研究结果: 实验显示PMI与CLIP准确性高度相关（r=0.97），且这一现象在自然图像和LMMs中同样存在（r=0.75和r=0.70）。

研究结论: 研究揭示了词共现统计对多模态模型组合泛化的重要性，并呼吁开发无需组合扩展训练数据的算法和架构。

中文摘要: CLIP和大型多模态模型（LMMs）在训练数据中高频概念上表现更优，但概念组合对组合泛化的作用尚不清楚。例如，常见物体与不常见物体配对时准确性如何变化？本文研究了预训练数据中词共现统计（作为视觉概念共现的代理）对CLIP/LMM性能的影响。为区分词共现频率与单词语频的影响，我们使用点互信息（PMI）量化共现，并通过合成图像验证其与CLIP零样本准确性的相关性（r=0.97，PMI最高与最低5%的图像准确性差距达14%）。进一步在自然图像中编辑概念对以验证这一效应（r=0.75），并发现CLIP的这一行为会迁移至基于CLIP的LMMs（TextVQA中r=0.70，VQAv2中r=0.62）。研究结果强调了改进多模态模型组合泛化能力的需求，而无需组合扩展训练数据。代码见https://github.com/helenqu/multimodal-pretraining-pmi。

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [144] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
**中文标题：基于LLMs的自主控制：下一代工业自动化的代理框架**

*Javal Vyas,Mehmet Mercangoz*

主要分类: cs.AI

摘要简述: 本文提出了一种基于大型语言模型（LLMs）的自主控制框架，结合符号推理与自适应控制，用于工业自动化中的离散故障恢复规划和连续过程控制。通过有限状态机（FSM）和验证-重提示循环，该框架在故障恢复和温度控制实验中表现出色，优于传统PID控制。


<details>
  <summary>详细信息</summary>
研究动机: 现代化学工艺日益复杂，加之劳动力短缺和故障场景的多样性，亟需一种结合符号推理与自适应控制的新型自动化范式。本文旨在利用LLMs的统一框架解决离散和连续控制问题，提升工业自动化的鲁棒性。

研究方法: 采用有限状态机（FSM）作为可解释的操作边界，由LLM驱动的规划代理提出恢复序列，仿真代理执行并检查每个状态转换，验证-重提示循环迭代优化无效计划。实验包括随机生成的FSM故障恢复和实验室TCLab平台的温度控制。

研究结果: 在180个随机生成的FSM中，GPT-4o和GPT-4o-mini在五次重提示内实现100%有效路径成功率，优于开源LLMs。在温度控制实验中，LLM控制器性能与经典PID相当，验证-重提示循环对处理非线性动态至关重要。

研究结论: 研究表明，通过结构化反馈和模块化代理，LLMs能够统一高层符号规划和低层连续控制，为化学工程中的语言驱动自动化提供了新思路。

中文摘要: 现代化学工艺的复杂性日益增加，加之劳动力短缺和复杂故障场景，亟需一种结合符号推理与自适应控制的新型自动化范式。本文提出了一种统一的代理框架，利用大型语言模型（LLMs）在同一架构中实现离散故障恢复规划和连续过程控制。我们采用有限状态机（FSM）作为可解释的操作边界：LLM驱动的规划代理通过FSM提出恢复序列，仿真代理执行并检查每个状态转换，验证-重提示循环迭代优化无效计划。在案例研究1中，针对180个随机生成的FSM（4-25个状态，4-300个转换），GPT-4o和GPT-4o-mini在五次重提示内实现100%有效路径成功率，优于开源LLMs的准确性和延迟。在案例研究2中，同一框架在实验室TCLab平台（及其数字孪生）上调节双加热器输入，以在持续不对称干扰下维持目标平均温度。与经典PID控制相比，基于LLM的控制器表现相当，而去除提示循环的实验表明其对处理非线性动态的关键作用。我们分析了主要失败模式，如指令跟随失误和粗略的ODE近似。结果表明，通过结构化反馈和模块化代理，LLMs能够统一高层符号规划和低层连续控制，为化学工程中的语言驱动自动化铺平了道路。

</details>


### [145] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
**中文标题：BOOST：基于分布外信息的自适应采样方法用于风格卷积神经网络的偏见缓解**

*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

主要分类: cs.AI

摘要简述: 本文提出了一种名为BOOST的新方法，通过动态调整温度缩放和采样概率，解决艺术分类中因数据不平衡导致的偏见问题，提升模型的公平性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: AI在艺术分类中存在严重的偏见问题，尤其是当训练数据中某些艺术风格占主导时，模型对罕见风格的分类准确性下降。现有研究多关注分类性能提升，而忽视了偏见的根本解决。

研究方法: 提出BOOST方法，结合OOD（分布外）数据信息，动态调整温度缩放和采样概率，以平衡各类别的表示。还提出新指标SODC，用于评估类别分离和偏见减少效果。

研究结果: 在KaoKore和PACS数据集上的实验表明，BOOST能够有效减少类别偏见，同时保持高性能，验证了其作为艺术领域去偏见解决方案的鲁棒性。

研究结论: BOOST方法通过动态采样和调整，成功平衡了艺术分类模型的性能和公平性，为AI在艺术领域的应用提供了更可靠的解决方案。

中文摘要: AI中的偏见问题对绘画分类构成了重大挑战，尤其是在艺术策展和修复等任务中。偏见通常源于数据集中某些艺术风格占主导，导致模型对罕见风格的分类准确性下降。尽管先前研究在提升分类性能方面取得进展，但忽视了解决这些根本偏见的必要性，尤其是在处理分布外（OOD）数据时。我们提出了一种新的OOD信息驱动的模型偏见自适应采样方法BOOST（Bias-Oriented OOD Sampling and Tuning），通过动态调整温度缩放和采样概率，促进各类别的公平表示。我们在KaoKore和PACS数据集上评估了该方法，重点关注其减少类别偏见的能力。此外，我们提出了一种新指标SODC（Same-Dataset OOD Detection Score），用于评估类别分离和每类偏见减少效果。实验表明，BOOST能够在保持高性能的同时实现公平性，为艺术领域的AI模型去偏见提供了鲁棒的解决方案。

</details>


### [146] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
**中文标题：基于状态推断的提示方法用于游戏NPC自然语言交易**

*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

主要分类: cs.AI

摘要简述: 本文提出了一种基于状态推断的提示方法（SIBP），用于解决大型语言模型在游戏NPC交易中因规则违反（如物品幻觉和计算错误）导致的玩家信任问题。该方法通过分解交易为六个状态并实现上下文感知的规则遵守，显著提升了交易的可靠性和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在动态游戏交互中表现优异，但在规则严格的交易系统中常出现物品幻觉和计算错误等问题，严重损害玩家信任。因此，需要一种可靠的方法来确保交易对话的规则遵守和准确性。

研究方法: 提出状态推断提示方法（SIBP），将交易分解为六个状态，并在统一提示框架中实现上下文感知的物品引用和基于占位符的价格计算。

研究结果: 在100次交易对话的评估中，SIBP实现了>97%的状态遵守率、>95%的引用准确率和99.7%的计算精度，计算效率高且优于基线方法。

研究结论: SIBP为商业游戏中可信赖的NPC交互提供了实用基础，通过状态推断和规则遵守显著提升了交易的可靠性和玩家信任。

中文摘要: 大型语言模型支持动态游戏交互，但在规则严格的交易系统中表现不佳，常出现物品幻觉和计算错误等问题，损害玩家信任。本文提出的状态推断提示方法（SIBP）通过自主对话状态推断和上下文规则遵守实现了可靠的交易。该方法将交易分解为六个状态，并在统一提示框架中实现上下文感知的物品引用和占位符价格计算。在100次交易对话的评估中，SIBP表现出>97%的状态遵守率、>95%的引用准确率和99.7%的计算精度，计算效率高且优于基线方法，为商业游戏中可信赖的NPC交互奠定了实用基础。

</details>


### [147] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
**中文标题：供应链中强迫劳动的神经符号特征提取识别**

*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

主要分类: cs.AI

摘要简述: 本文探讨了如何利用神经符号方法从供应链中识别强迫劳动等非法活动，提出了一种基于问题树的LLM查询方法，用于自动分类和量化新闻文章的相关性，并比较了人工与机器分类的差异。


<details>
  <summary>详细信息</summary>
研究动机: 供应链网络复杂且常涉及非法活动（如强迫劳动），传统机器学习方法需要大量训练数据，但非法供应链数据稀疏且不可靠。因此，需要一种无需大量数据即可自动检测非法活动模式的方法。

研究方法: 研究采用神经符号方法，通过问题树查询大型语言模型（LLM），从新闻文章中提取特征并量化其相关性，从而系统比较人工与机器分类的差异。

研究结果: 研究发现，神经符号方法能够有效识别供应链中的强迫劳动活动，且问题树查询LLM的方法在分类新闻文章时表现出色。

研究结论: 神经符号方法为供应链中非法活动的检测提供了新思路，尤其是在数据稀疏的情况下，问题树查询LLM的方法具有实际应用潜力。

中文摘要: 供应链网络是复杂的系统，分析其涉及非法活动（如假冒零件、强迫劳动或人口贩卖）时尤为困难。虽然机器学习（ML）能在复杂系统中发现模式，但传统ML技术需要大量训练数据。然而，非法供应链数据稀疏且常被故意破坏或不可靠。我们需要能够自动检测与非法活动相关的新模式，而无需大量训练数据。本文探讨了神经符号方法在供应链中识别非法活动的有效性，并比较了从新闻文章中手动和自动提取特征的差异。我们提出了一种问题树方法，用于查询大型语言模型（LLM）以识别和量化文章的相关性，从而系统评估人工与机器对供应链中强迫劳动相关新闻文章分类的差异。

</details>


### [148] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
**中文标题：基于语言智能体的开源规划与控制系统用于自主科学发现**

*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

主要分类: cs.AI

摘要简述: 本文介绍了一个名为cmbagent的多智能体系统，用于自动化科学研究任务。该系统由约30个大型语言模型（LLM）智能体组成，采用规划与控制策略协调工作流程，无需人工干预。通过执行代码和完成复杂任务（如测量宇宙学参数），系统在性能上优于现有LLM。


<details>
  <summary>详细信息</summary>
研究动机: 科学研究任务通常复杂且耗时，需要多领域专业知识。本文旨在开发一个完全自动化的多智能体系统，利用LLM智能体协作完成复杂科学任务，减少人工干预，提高效率。

研究方法: 系统由约30个LLM智能体组成，每个智能体专注于不同任务（如检索科学论文、编写代码、解释结果等）。通过规划与控制策略协调工作流程，系统能够本地执行代码，并完成复杂任务（如宇宙学参数测量）。

研究结果: 系统成功应用于博士级别的宇宙学任务（利用超新星数据测量宇宙学参数），并在两个基准测试中表现出优于现有LLM的性能。

研究结论: cmbagent系统展示了多智能体协作在自动化科学研究中的潜力，其性能优于现有LLM，为未来科学研究的自动化提供了新思路。

中文摘要: 我们提出了一种用于自动化科学研究任务的多智能体系统cmbagent。该系统由约30个大型语言模型（LLM）智能体组成，采用规划与控制策略协调工作流程，全程无需人工干预。每个智能体专注于不同任务（如检索科学论文和代码库、编写代码、解释结果、评估其他智能体输出），系统能够本地执行代码。我们成功将cmbagent应用于博士级别的宇宙学任务（利用超新星数据测量宇宙学参数），并在两个基准测试中评估其性能，发现其优于现有LLM。源代码已在GitHub上发布，演示视频也已提供，系统部署于HuggingFace，并将在云端可用。

</details>


### [149] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
**中文标题：大型语言模型在多机器人路径规划与任务分配中的应用**

*Ashish Kumar*

主要分类: cs.AI

摘要简述: 本文研究了在多机器人路径规划与任务分配中应用大型语言模型（LLMs）作为专家规划器，以提高多智能体强化学习中的探索效率。


<details>
  <summary>详细信息</summary>
研究动机: 多智能体强化学习中的探索效率问题因其复杂性而尤为突出。本文旨在通过引入大型语言模型作为专家规划器，解决多智能体在规划任务中的高效探索问题。

研究方法: 研究采用大型语言模型作为专家规划器，指导多智能体在规划任务中的探索行为，以提高学习效率和任务解决能力。

研究结果: 结果表明，大型语言模型能够有效提升多智能体在规划任务中的探索效率，并显著改善任务完成表现。

研究结论: 大型语言模型在多机器人路径规划与任务分配中具有潜力，能够显著提升多智能体的探索效率和任务解决能力。

中文摘要: 高效探索是深度强化学习中的一个众所周知的问题，而在多智能体强化学习中，由于算法的内在复杂性，这一问题更加突出。本文研究了通过多智能体在环境中操作来高效探索并学习解决任务的方法，其中重点探讨了专家探索的思想。具体而言，本研究调查了大型语言模型作为专家规划器在多智能体规划任务中高效探索的应用。

</details>


### [150] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
**中文标题：ViDove：一种支持多模态上下文和记忆增强推理的翻译代理系统**

*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

主要分类: cs.AI

摘要简述: ViDove是一种支持多模态输入的翻译代理系统，通过结合视觉和上下文背景信息提升翻译质量，并引入多模态记忆系统和领域知识增强模块，显著优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 现有的LLM翻译代理通常仅支持文本输入，无法充分利用视觉和上下文信息。ViDove旨在模拟人类翻译的工作流程，通过多模态输入提升翻译的准确性和适应性。

研究方法: ViDove结合视觉和上下文背景信息，并集成多模态记忆系统和长短时记忆模块，利用领域知识增强翻译能力。此外，还提出了新的评测基准DoveBench。

研究结果: ViDove在字幕生成和通用翻译任务中表现优异，BLEU分数提升28%，SubER提升15%，显著优于现有基线。

研究结论: ViDove通过多模态输入和记忆增强推理，显著提升了翻译质量，为多模态翻译任务提供了新思路。

中文摘要: 基于LLM的翻译代理已能实现高度拟人的翻译效果，并能高效处理更长、更复杂的上下文。然而，它们通常仅限于文本输入。本文提出ViDove，一种专为多模态输入设计的翻译代理系统。受人类翻译工作流程启发，ViDove利用视觉和上下文背景信息优化翻译过程。此外，我们集成了多模态记忆系统和长短时记忆模块，并注入领域知识，使代理在现实场景中表现更准确、更具适应性。实验表明，ViDove在字幕生成和通用翻译任务中的翻译质量显著提升，BLEU分数提高28%，SubER提升15%，优于现有基线。我们还提出了DoveBench，一个新的长视频自动字幕生成与翻译评测基准，包含17小时高质量人工标注数据。代码已开源：https://github.com/pigeonai-org/ViDove

</details>


### [151] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
**中文标题：论智能与判断不可分离性：AI对齐中过滤问题的计算不可行性**

*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

主要分类: cs.AI

摘要简述: 本文研究大型语言模型（LLM）的安全对齐问题，重点关注输入和输出过滤的可行性。结果表明，高效过滤对抗性提示或输出在计算上是不可行的，且安全无法仅通过外部过滤器实现。


<details>
  <summary>详细信息</summary>
研究动机: 随着大型语言模型的广泛应用，其可能被滥用于生成有害内容的问题日益突出。本文旨在探讨如何通过过滤输入提示或输出来实现模型的安全对齐，并揭示其中的计算挑战。

研究方法: 研究通过理论分析证明，对于某些LLM，不存在高效的输入提示过滤器，且输出过滤在特定情况下是计算不可行的。所有结果基于密码学硬度假设，并进一步研究了放宽的缓解方法。

研究结果: 研究发现，对抗性提示可以轻易构造且无法被高效过滤器识别，输出过滤在自然场景下计算不可行。安全无法仅通过外部过滤器实现，需结合模型内部设计。

研究结论: 安全对齐无法仅依赖外部过滤器，需将智能与判断紧密结合。黑盒访问LLM不足以实现安全，需从模型内部（架构和权重）入手。

中文摘要: 随着大型语言模型（LLM）的广泛应用，其可能被滥用于生成有害内容的问题日益突出。本文研究对齐挑战，重点关注防止生成不安全信息的过滤器。干预的两个自然点是输入提示的过滤和生成后输出的过滤。我们的主要结果表明，过滤提示和输出均存在计算挑战。首先，我们证明存在某些LLM，其输入提示无法被高效过滤：对抗性提示可以轻易构造，且对任何高效过滤器计算不可区分。其次，我们识别了一种自然场景，其中输出过滤是计算不可行的。所有分离结果均基于密码学硬度假设。此外，我们还形式化并研究了放宽的缓解方法，揭示了进一步的计算障碍。我们得出结论，安全无法通过设计独立于LLM内部（架构和权重）的外部过滤器实现；特别是，仅黑盒访问LLM是不够的。基于技术结果，我们认为对齐AI系统的智能无法与其判断分离。

</details>


### [152] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
**中文标题：基于生成模拟和迭代决策策略的供应链优化**

*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

主要分类: cs.AI

摘要简述: 本文提出Sim-to-Dec框架，结合生成模拟和迭代决策策略优化供应链运输，显著提升及时交付率和利润。


<details>
  <summary>详细信息</summary>
研究动机: 供应链运输中的高响应性和经济效率是关键目标，而运输模式的选择直接影响这两点。现有方法缺乏通用性、精细动态模拟和历史与预测的整合，因此需要一种新的框架来解决这些问题。

研究方法: Sim-to-Dec框架包含生成模拟模块（利用自回归模型模拟连续状态变化）和双感知决策模型（结合历史与未来信息，通过端到端优化迭代优化）。

研究结果: 在三个真实数据集上的实验表明，Sim-to-Dec显著提高了及时交付率和利润。

研究结论: Sim-to-Dec框架通过生成模拟和迭代决策策略，有效优化供应链运输，满足通用性、动态模拟和决策整合的需求。

中文摘要: 高响应性和经济效率是供应链运输中的关键目标，而运输模式的选择直接影响这两点。结合高效模拟器和智能决策算法的集成框架可以为运输策略设计提供可观测、低风险的环境。理想的模拟-决策框架必须（1）有效泛化到多种场景，（2）反映精细的运输动态，（3）整合历史经验与预测洞察，（4）保持模拟反馈与策略优化的紧密集成。我们提出Sim-to-Dec框架以满足这些需求。具体而言，Sim-to-Dec包含一个生成模拟模块（利用自回归模型模拟连续状态变化，减少对领域特定规则的依赖并增强对数据波动的鲁棒性）和一个历史-未来双感知决策模型（通过与模拟器的端到端优化迭代优化）。在三个真实数据集上的大量实验表明，Sim-to-Dec显著提高了及时交付率和利润。

</details>


### [153] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
**中文标题：DrugMCTS：一种结合多智能体、RAG和蒙特卡洛树搜索的药物重定位框架**

*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

主要分类: cs.AI

摘要简述: 本文提出了一种名为DrugMCTS的新型药物重定位框架，结合了多智能体协作、检索增强生成（RAG）和蒙特卡洛树搜索（MCTS），显著提升了大型语言模型在药物发现任务中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在科学领域（如药物发现）的应用受限于其预训练知识的范围，而传统方法（如微调或检索增强生成）存在计算开销大或未能充分利用结构化科学数据的局限性。因此，本文旨在通过多智能体协作和反馈驱动搜索机制，提升模型在药物重定位任务中的性能。

研究方法: DrugMCTS框架整合了RAG、多智能体协作和MCTS技术，通过五个专用智能体检索和分析分子与蛋白质信息，实现结构化迭代推理。该框架无需领域特定微调，即可显著提升模型表现。

研究结果: 在DrugBank和KIBA数据集上的实验表明，DrugMCTS的召回率和鲁棒性显著优于通用大型语言模型和深度学习基线模型，Qwen2.5-7B-Instruct的性能超越Deepseek-R1超过20%。

研究结论: 研究结果表明，结构化推理、基于智能体的协作和反馈驱动搜索机制对推动大型语言模型在药物发现中的应用至关重要。

中文摘要: 近年来，大型语言模型在药物发现等科学领域展现出巨大潜力，但其推理能力仍受限于预训练知识的范围。传统方法（如微调或检索增强生成）或因计算开销大，或因未能充分利用结构化科学数据而存在局限性。为克服这些挑战，我们提出DrugMCTS，一种新型框架，通过协同整合RAG、多智能体协作和蒙特卡洛树搜索技术实现药物重定位。该框架利用五个专用智能体检索和分析分子与蛋白质信息，从而实现结构化迭代推理。无需领域特定微调，DrugMCTS使Qwen2.5-7B-Instruct的性能超越Deepseek-R1超过20%。在DrugBank和KIBA数据集上的大量实验表明，DrugMCTS的召回率和鲁棒性显著优于通用大型语言模型和深度学习基线模型。我们的结果凸显了结构化推理、基于智能体的协作和反馈驱动搜索机制在推动大型语言模型药物发现应用中的重要性。

</details>


### [154] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
**中文标题：StarDojo：基于《星露谷物语》的生产生活模拟中多模态大语言模型代理开放式行为基准测试**

*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

主要分类: cs.AI

摘要简述: StarDojo是一个基于《星露谷物语》的新型基准测试，旨在评估AI代理在开放式生产生活模拟中的表现，涵盖农业、制作、探索、战斗和社交互动五大领域。


<details>
  <summary>详细信息</summary>
研究动机: 现有基准测试很少同时评估AI代理的生产活动和社会互动能力，StarDojo旨在填补这一空白，推动复杂生产生活环境中开放式代理的研究。

研究方法: StarDojo包含1,000个精心设计的任务，涵盖五大领域，并提供100个代表性任务的子集以高效评估模型。其统一、用户友好的界面支持多操作系统和并行环境实例，特别适合评估多模态大语言模型（MLLMs）驱动的代理。

研究结果: 对最先进的MLLMs代理的评估显示其表现有限，最佳模型GPT-4.1的成功率仅为12.7%，主要因视觉理解、多模态推理和低级操作能力不足。

研究结论: StarDojo作为一个用户友好的环境和基准测试，旨在促进复杂生产生活环境中开放式代理的进一步研究。

中文摘要: 自主代理在人类社会中导航需同时掌握生产活动和社会互动能力，但现有基准测试很少同时评估这些技能。为填补这一空白，我们推出了StarDojo，这是一种基于《星露谷物语》的新型基准测试，旨在评估开放式生产生活模拟中的AI代理。在StarDojo中，代理需完成农业、制作等基本生计活动，同时与充满活力的社区建立社交关系。StarDojo包含1,000个精心设计的任务，涵盖五大领域：农业、制作、探索、战斗和社交互动。此外，我们还提供了100个代表性任务的子集以高效评估模型。该基准测试提供统一的用户友好界面，无需键盘和鼠标控制，支持所有主要操作系统，并可并行执行多个环境实例，特别适合评估多模态大语言模型（MLLMs）驱动的强大代理。对最先进MLLMs代理的广泛评估显示其表现有限，最佳模型GPT-4.1的成功率仅为12.7%，主要因视觉理解、多模态推理和低级操作能力不足。作为一个用户友好的环境和基准测试，StarDojo旨在促进复杂生产生活环境中开放式代理的进一步研究。

</details>


### [155] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
**中文标题：立场：我们需要对生成式AI的算法理解**

*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

主要分类: cs.AI

摘要简述: 本文提出AlgEval框架，旨在系统研究大语言模型（LLM）学习与使用的算法，填补理论空白，并通过案例研究验证其可行性。


<details>
  <summary>详细信息</summary>
研究动机: 当前研究多关注通过规模提升LLM性能，而忽略了对其学习算法的理解。本文旨在填补这一理论空白，为LLM的算法解释提供系统化研究框架。

研究方法: 提出AlgEval框架，结合自上而下的假设生成与自下而上的电路级分析（如注意力模式和隐藏状态），研究LLM的算法构成。

研究结果: 案例研究表明，AlgEval能有效揭示LLM中的搜索算法，验证了框架的可行性。

研究结论: AlgEval为理解LLM的算法提供了系统化路径，有望推动更高效的训练方法和新型架构设计。

中文摘要: 大语言模型（LLM）实际学习并用于解决问题的算法是什么？目前针对这一问题的研究较少，因为研究重点多集中在通过规模提升性能，导致对涌现算法的理论和实证理解存在空白。本文提出AlgEval框架，旨在系统研究LLM学习与使用的算法。AlgEval的目标是揭示算法原语（反映在潜在表示、注意力和推理计算中）及其任务特定问题解决的算法组合。我们展示了潜在的方法路径和一个案例研究，重点关注涌现的搜索算法。案例研究既包括对候选算法的自上而下假设生成，也包括通过注意力模式和隐藏状态的电路级分析对这些假设的自下而上验证。对LLM如何实际解决任务的严格系统评估，为资源密集型扩展提供了替代方案，将研究重点转向对底层计算的原则性理解。此类算法解释为人类可理解的解释性提供了路径，使模型内部推理性能指标得以理解。这反过来可以带来更高效的训练方法和性能提升，以及端到端和多智能体系统的新型架构设计。

</details>


### [156] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
**中文标题：关于可信的基于规则模型及其解释**

*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

主要分类: cs.AI

摘要简述: 本文探讨了基于规则的机器学习模型在高风险领域中的可信解释问题，揭示了这些模型中存在的负面特征（如冗余和重叠），并提出了分析这些问题的算法。


<details>
  <summary>详细信息</summary>
研究动机: 在高风险领域中，机器学习模型的解释必须严谨，错误的解释会误导人类决策者。尽管可解释性是一个模糊的概念，但基于规则的可解释模型仍被广泛使用。本文旨在揭示这些模型中存在的负面特征，并分析其对解释可信度的影响。

研究方法: 本文开发了算法来分析基于规则的机器学习模型中的负面特征，如负面重叠和冗余。这些算法用于评估常见规则学习工具生成的规则集。

研究结果: 研究发现，广泛使用的规则学习工具生成的规则集往往表现出一种或多种负面特征，如冗余或重叠，从而影响模型解释的可信度。

研究结论: 基于规则的机器学习模型在高风险领域中的应用需要更严格的审查，以避免负面特征对解释可信度的影响。未来的研究应关注如何改进规则学习工具以减少这些负面特征。

中文摘要: 机器学习（ML）中的一个重要任务是为模型预测提供解释。在高风险领域中，解释的严谨性至关重要，错误的解释会误导人类决策者。尽管可解释性是一个模糊的概念，但所谓的可解释模型在高风险的ML和数据挖掘（DM）应用中无处不在。基于规则的ML模型（如决策树、图表、集合和列表）就是如此。本文将这些解释与基于规则的ML模型中已知的不良特征（如负面重叠和多种形式的冗余）联系起来。本文开发了分析这些不良特征的算法，并得出结论：广泛使用的规则学习工具生成的规则集往往表现出一种或多种负面特征。

</details>


### [157] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
**中文标题：上下文池化：知识图谱中通用归纳链接预测的查询特定图池化方法**

*Zhixiang Su,Di Wang,Chunyan Miao*

主要分类: cs.AI

摘要简述: 本文提出了一种名为Context Pooling的新方法，用于提升基于图神经网络（GNN）的知识图谱（KG）链接预测性能。该方法首次在KG中应用图池化，并支持在归纳设置中生成查询特定图。通过设计两种度量标准（邻域精度和邻域召回），该方法能够筛选逻辑相关的邻居，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于GNN的知识图谱链接预测模型中，传统的聚合方法对性能提升有限。为了解决这一问题，本文提出了一种新的图池化方法Context Pooling，旨在通过筛选逻辑相关的邻居来提升模型性能，尤其是在归纳设置中处理未见过的测试实体。

研究方法: 本文提出Context Pooling方法，首次在KG中应用图池化技术。通过设计邻域精度和邻域召回两种度量标准，评估邻居与查询的逻辑相关性，从而筛选出仅逻辑相关的邻居用于链接预测。该方法具有通用性，可应用于多种SOTA模型。

研究结果: 在三个公开的转导和归纳数据集上，Context Pooling应用于两种SOTA模型，在48种设置中42种达到了SOTA性能，显著提升了链接预测的准确性。

研究结论: Context Pooling是一种创新的图池化方法，首次在KG中实现查询特定图的生成，并通过逻辑相关邻居的筛选显著提升了链接预测性能。该方法具有通用性和高效性，为KG链接预测领域提供了新的研究方向。

中文摘要: 近期关于图神经网络（GNN）在知识图谱（KG）链接预测中有效性的研究表明，传统的聚合方法对模型性能影响有限。本文提出了一种名为Context Pooling的新方法，以提升GNN在KG链接预测中的性能。据我们所知，Context Pooling是首个在KG中应用图池化的方法，同时也是首个支持在归纳设置中生成查询特定图的技术。具体而言，我们设计了两种度量标准——邻域精度和邻域召回，用于评估邻居与查询的逻辑相关性，从而能够全面筛选出仅逻辑相关的邻居用于链接预测。该方法具有通用性，并在三种公开的转导和归纳数据集上应用于两种SOTA模型，在48种设置中的42种实现了SOTA性能。

</details>


### [158] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
**中文标题：增强疫苗安全监测：使用微调的大型语言模型从急诊分诊记录中提取疫苗相关信息**

*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

主要分类: cs.AI

摘要简述: 本研究评估了微调的Llama 3.2模型在从急诊分诊记录中提取疫苗相关信息的能力，以支持近实时疫苗安全监测。结果表明，微调的Llama 3模型在提取疫苗名称的准确性上优于其他方法。


<details>
  <summary>详细信息</summary>
研究动机: 疫苗安全监测需要高效的数据提取方法，以支持早期发现潜在的免疫后不良事件。急诊分诊记录中包含大量疫苗相关信息，但传统方法提取效率低。

研究方法: 研究使用提示工程创建初始标注数据集，并通过人工标注确认。随后比较了提示工程模型、微调模型和基于规则的方法的性能。微调的Llama 3模型被量化以在资源受限环境中高效部署。

研究结果: 微调的Llama 3模型在提取疫苗名称的准确性上表现最佳，优于其他方法。模型量化使其能够在资源受限环境中高效运行。

研究结论: 大型语言模型在自动化急诊记录数据提取方面具有潜力，可支持高效的疫苗安全监测和早期不良事件发现。

中文摘要: 本研究评估了微调的Llama 3.2模型在从急诊分诊记录中提取疫苗相关信息的能力，以支持近实时疫苗安全监测。通过提示工程创建初始标注数据集，并由人工标注确认。比较了提示工程模型、微调模型和基于规则的方法的性能。微调的Llama 3亿参数模型在提取疫苗名称的准确性上优于其他模型。模型量化使其能够在资源受限环境中高效部署。研究结果表明，大型语言模型在自动化急诊记录数据提取方面具有潜力，可支持高效的疫苗安全监测和早期发现免疫后不良事件。

</details>


### [159] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
**中文标题：基于信念函数的信用网络保守推断：信用链案例**

*Marco Sangalli,Thomas Krak,Cassio de Campos*

主要分类: cs.AI

摘要简述: 本文提出了一种基于Dempster-Shafer理论的信念推断框架，用于在信用网络（特别是链状结构）中传播不确定性，通过信念和似然函数高效生成保守区间，兼具计算速度和鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 研究动机在于探索如何在信用网络中利用Dempster-Shafer理论进行保守的信念推断，尤其是在链状结构中，以弥补传统敏感性分析的不足。

研究方法: 方法包括提出一种新的框架，通过信念和似然函数在信用链中传播不确定性，并比较信念推断与传统敏感性分析的效果。

研究结果: 数值结果表明，该方法在计算速度和不确定性表示方面具有优势，但也揭示了其在更复杂信用网络中的局限性。

研究结论: 结论指出，信念推断在信用链中具有实用价值，但需进一步研究以扩展至更广泛的信用网络。

中文摘要: 本文探讨了利用Dempster-Shafer理论在信用网络中进行信念推断的方法。基于前人研究，我们提出了一种新的框架，用于在信用网络的一个子类（即链状结构）中传播不确定性。该方法通过信念和似然函数高效生成保守区间，兼具计算速度和鲁棒的表示能力。主要贡献包括形式化基于信念的推断方法，并将其与经典敏感性分析进行比较。数值结果突出了信念推断在此框架中的优势和局限性，为信用链及更广泛信用网络的实际应用提供了见解。

</details>


### [160] [PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations](https://arxiv.org/abs/2507.07644)
**中文标题：PlanQA：基于结构化表示的大型语言模型空间推理基准**

*Fedor Rodionov,Abdelrahman Eldesokey,Michael Birsak,John Femiani,Bernard Ghanem,Peter Wonka*

主要分类: cs.AI

摘要简述: 本文介绍了PlanQA，一个用于评估大型语言模型（LLMs）在几何和空间推理能力的诊断基准。该基准基于结构化室内场景表示，测试了多种问题类型，揭示了LLMs在模拟物理约束和空间一致性方面的不足。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型在几何和空间推理方面存在明显盲点，尤其是在处理真实世界布局时表现不佳。PlanQA旨在填补这一空白，为评估和改进LLMs的空间推理能力提供工具。

研究方法: PlanQA基于结构化表示（如JSON、XML）编码室内场景（如厨房、客厅、卧室），设计了多样的问题类型，包括度量、拓扑推理和室内设计约束（如可达性、平衡性）。通过测试多种开源和商业LLMs，评估其在空间推理任务中的表现。

研究结果: 结果显示，尽管LLMs在简单查询中表现良好，但在模拟物理约束、保持空间一致性或应对布局扰动时普遍失败，表明其在真实世界布局推理中的局限性。

研究结论: PlanQA揭示了当前LLMs在空间推理方面的不足，为未来开发能够准确推断和操作空间几何属性的语言模型提供了方向。

中文摘要: 我们提出了PlanQA，一个用于评估大型语言模型（LLMs）在几何和空间推理能力的诊断基准。PlanQA基于结构化室内场景表示（如厨房、客厅、卧室），以符号格式（如JSON、XML布局）编码。该基准包含多样化的问题类型，不仅测试度量和拓扑推理（如距离、可见性、最短路径），还包括室内设计约束（如可达性、间隙、平衡性和可用性）。我们对多种前沿开源和商业LLMs的测试结果表明，尽管模型在浅层查询中可能成功，但在模拟物理约束、保持空间一致性或应对布局扰动时常常失败。PlanQA揭示了当前LLMs的一个明显盲点：它们无法一致地推理真实世界的布局。我们希望这一基准能激发新的研究，开发出能够在实际场景中准确推断和操作空间几何属性的语言模型。

</details>


### [161] [Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization](https://arxiv.org/abs/2507.07723)
**中文标题：LLM的稳定偏好优化：超越直接偏好优化的双层方法**

*Chengtao Jian,Kai Yang,Ye Ouyang,Xiaozhou Ye*

主要分类: cs.AI

摘要简述: 本文揭示了直接偏好优化（DPO）的局限性，提出了一种双层优化框架——稳定偏好优化，以改进模型对齐的稳定性和一致性。


<details>
  <summary>详细信息</summary>
研究动机: 尽管直接偏好优化（DPO）在语言模型对齐中表现出色，但其理论性质和内在局限性尚未充分研究。本文旨在分析DPO的动态特性，并解决其对初始化的敏感性和概率分配不当的问题。

研究方法: 提出了一种双层优化框架，结合监督微调和改进的DPO目标（稳定偏好优化），通过正则化方案显式提升偏好输出的绝对概率，同时保持优化的稳定性。

研究结果: 实验表明，该方法在推理和摘要任务中显著提升了准确性，并更好地对齐了输出分布与预期偏好，优于标准DPO。

研究结论: 稳定偏好优化为偏好对齐目标的设计提供了新思路，为实现更可靠和可解释的语言模型对齐开辟了新途径。

中文摘要: 直接偏好优化（DPO）已成为一种流行且高效的方法，用于将语言模型与人类偏好对齐，而无需奖励建模和强化学习。尽管其实证成功，DPO的理论性质和内在局限性仍未得到充分探索。本文首先从概率演化的角度对DPO的动态特性进行了全面分析。分析表明，DPO对初始化高度敏感，并且容易错误分配概率质量，可能无意中将概率转移到无关或不期望的响应上。这种错误分配可能会无意中强化模型偏差，从而损害模型对齐的稳定性和与预期偏好的一致性。基于这些理论发现，我们提出了一种理论支持的双层优化框架，将监督微调与改进的DPO目标（即稳定偏好优化）紧密结合。我们的方法引入了一种原则性的正则化方案，显式鼓励偏好输出的绝对概率提升，同时保持优化的稳定性。在具有挑战性的推理和摘要基准测试中，实验表明我们的方法显著提高了推理准确性，并更好地对齐了输出分布与预期偏好，优于标准DPO。稳定偏好优化为偏好对齐目标的设计提供了新见解，并为实现更可靠和可解释的语言模型对齐开辟了新途径。

</details>


### [162] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
**中文标题：基于轮廓线分类的小提琴尺寸缩减识别**

*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

主要分类: cs.AI

摘要简述: 本文提出了一种基于轮廓线分类的小提琴尺寸缩减识别方法，通过分析3D几何网格和抛物线拟合参数，成功区分了缩减与非缩减小提琴。


<details>
  <summary>详细信息</summary>
研究动机: 16世纪末至18世纪，小提琴在欧洲广泛传播，制琴师为满足乐团和音乐学院的需求，对不符合标准尺寸的小提琴进行了缩减。这种缩减影响了小提琴的轮廓线特征，但此前缺乏定量研究。本文旨在填补这一空白。

研究方法: 研究使用摄影测量法获取25把小提琴的3D几何网格，提取每把小提琴10-20条等距轮廓线，并用抛物线方程（y = alpha*abs(x)**beta）拟合每条线。通过回归分析和阈值计数，计算额外特征，处理异常值和不均匀层级数，最终为每把小提琴生成数值化轮廓特征。

研究结果: 研究发现，仅凭几何特征可以在一定程度上区分缩减与非缩减小提琴，其中抛物线开口参数beta最具预测性。但由于存在不同程度的缩减，完全量化缩减效果仍具挑战性。

研究结论: 轮廓线分类方法为小提琴尺寸缩减的定量研究提供了可行途径，但需进一步优化以应对复杂情况。

中文摘要: 第一把小提琴于16世纪末出现在意大利。随后200年间，小提琴在欧洲广泛传播，各国宫廷的制琴师尝试新技术，创造了多样化的乐器家族。约1750年，为统一乐团和音乐学院的需求，引入了尺寸标准。不符合标准的小提琴被制琴师缩减为较小尺寸。这种缩减影响了小提琴的多个特征，尤其是轮廓线（即等高线）：未缩减的小提琴轮廓线呈U形，缩减后则更接近V形。尽管专家能观察到这些差异，但此前缺乏定量研究。

本文提出了一种基于轮廓线分类的小提琴尺寸缩减识别方法。研究分析了25把小提琴的3D几何网格（通过摄影测量法获取），每把小提琴提取10-20条等距轮廓线。每条线用抛物线方程（y = alpha*abs(x)**beta）拟合，通过回归分析和阈值计数计算额外特征，处理异常值和不均匀层级数，最终为每把小提琴生成数值化轮廓特征。

通过分类方法评估几何特征是否能预测尺寸缩减，研究发现区分缩减与非缩减小提琴具有一定可行性，但需考虑存在不同程度的缩减情况。抛物线开口参数beta最具预测性。

</details>


### [163] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
**中文标题：衡量AI与人类繁荣的契合度**

*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

主要分类: cs.AI

摘要简述: 本文提出了一种名为FAI Benchmark的新评估框架，用于衡量AI在七个维度上与人类繁荣的契合度。通过1229个主客观问题，评估28个主流语言模型，发现没有模型在所有维度上表现良好，尤其在信仰与灵性、品格与美德、意义与目的方面。


<details>
  <summary>详细信息</summary>
研究动机: 传统AI评估主要关注技术能力或避免危害，而忽略了AI对人类整体福祉的贡献。本文旨在填补这一空白，提出一种衡量AI如何促进人类繁荣的框架。

研究方法: FAI Benchmark通过七个维度（如品格与美德、幸福与生活满意度等）评估AI表现，采用1229个主客观问题，结合专门的大型语言模型（LLMs）和几何平均评分方法，确保各维度平衡评估。

研究结果: 测试28个主流语言模型，最高得分72/100，但无模型在所有维度上表现良好，尤其在信仰与灵性、品格与美德、意义与目的方面表现较差。

研究结论: FAI Benchmark为开发支持人类繁荣的AI系统提供了框架，强调AI发展需超越避免危害，关注全面福祉，对AI伦理和评估有重要意义。

中文摘要: 本文介绍了繁荣AI基准（FAI Benchmark），这是一种新颖的评估框架，用于衡量AI在七个维度上与人类繁荣的契合度：品格与美德、亲密社会关系、幸福与生活满意度、意义与目的、心理与身体健康、财务与物质稳定、信仰与灵性。与传统关注技术能力或避免危害的基准不同，FAI Benchmark评估AI模型在这些维度上对人类繁荣的贡献。通过包含1229个主客观问题的综合方法，该基准评估大型语言模型（LLMs）如何与当前整体人类福祉研究模型契合。使用专门的评判LLMs和跨维度评估，FAI Benchmark采用几何平均评分以确保各维度平衡表现。对28个主流语言模型的初步测试显示，尽管部分模型接近整体契合（最高得分72/100），但无模型在所有维度上表现良好，尤其在信仰与灵性、品格与美德、意义与目的方面。本研究为开发积极支持人类繁荣而非仅避免危害的AI系统提供了框架，对AI发展、伦理和评估具有重要影响。

</details>


### [164] [MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving](https://arxiv.org/abs/2507.07818)
**中文标题：MoSE：面向自动驾驶的技能导向混合专家学习**

*Lu Xu,Jiaqian Yu,Xiongfeng Peng,Yiwei Chen,Weiming Li,Jaewook Yoo,Sunghyun Chunag,Dongwook Lee,Daehyun Ji,Chao Zhang*

主要分类: cs.AI

摘要简述: 本文提出了一种名为MoSE的技能导向混合专家学习方法，用于自动驾驶。该方法模仿人类驾驶员的学习和推理过程，通过技能导向的路由机制和分层技能数据集，实现了高效的单次推理，显著减少了激活参数规模，并在性能上超越了现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 现有的大型语言模型和视觉语言模型虽能提升自动驾驶系统的泛化能力和解释性，但通用混合专家模型需要大量训练数据和复杂优化。受人类驾驶员学习过程的启发，本文提出技能导向的MoSE方法，旨在通过技能分步学习提升模型效率。

研究方法: MoSE方法通过定义和标注特定技能，构建技能导向的路由机制和分层技能数据集，预训练路由器以实现分步推理。该方法在单次前向过程中整合辅助任务（如描述、推理、规划），无需额外计算成本。

研究结果: MoSE模型在CODA AD极端案例推理任务中表现优异，仅使用不到30亿稀疏激活参数，性能超越多个80亿+参数的模型，激活模型规模至少减少62.5%。

研究结论: MoSE通过技能导向学习和分步推理，显著提升了自动驾驶模型的效率和性能，为未来研究提供了新方向。

中文摘要: 近期研究表明，基于网络规模数据训练的大型语言模型（LLMs）和视觉语言模型（VLMs）能够增强端到端自动驾驶系统的泛化能力和解释性。具体而言，混合专家（MoE）技术通过动态路由输入到专门的参数子集，使通用LLMs或VLMs在保持计算效率的同时实现显著性能提升。然而，通用MoE模型通常需要大量训练数据和复杂优化。本文受人类驾驶员学习过程的启发，提出了一种技能导向的MoE方法，称为MoSE，它模仿人类驾驶员的学习和推理过程，逐步分技能学习。我们提出了一种技能导向的路由机制，首先定义和标注特定技能，使专家能够识别不同场景和推理任务所需的驾驶能力，从而促进技能分步学习。进一步将驾驶过程与人类推理中的多步规划和端到端驾驶模型对齐，我们构建了一个分层技能数据集并预训练路由器，以鼓励模型逐步思考。与多轮对话不同，MoSE在单次前向过程中整合了有价值的辅助任务（如描述、推理、规划），而无需引入额外计算成本。我们的模型仅使用不到30亿稀疏激活参数，在CODA AD极端案例推理任务中表现优于多个80亿+参数的模型。与基于开源模型和数据的现有方法相比，我们的方法在单轮对话中以显著减少的激活模型规模（至少减少62.5%）实现了最先进的性能。

</details>


### [165] [AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift](https://arxiv.org/abs/2507.07820)
**中文标题：AI应更智能地感知，而非单纯扩大规模：自适应感知作为范式转变**

*Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim*

主要分类: cs.AI

摘要简述: 当前AI发展依赖大规模模型和数据，但成本高昂且不可持续。论文提出自适应感知作为新范式，通过动态调整传感器参数提升效率，使小模型超越大模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有AI依赖模型和数据规模扩展，导致环境、经济和伦理成本高，且不可持续。受生物感知系统启发，论文提出自适应感知作为更高效、可持续的替代方案。

研究方法: 论文提出自适应感知范式，动态调整传感器参数（如曝光、灵敏度等），减少数据需求并提升模型效率。通过实证研究验证小模型在自适应感知下超越大模型性能。

研究结果: 实验表明，自适应感知使小模型（如EfficientNet-B0）性能超越大模型（如OpenCLIP-H），同时减少计算和数据需求。

研究结论: 论文呼吁AI社区转向自适应感知，提出标准化基准、实时算法和多模态集成等研究方向，以实现可持续、鲁棒和公平的AI系统。

中文摘要: 当前AI的进展主要依赖扩大神经网络模型和训练数据集以实现泛化和鲁棒性。尽管取得显著成功，但这一范式带来高昂的环境、经济和伦理成本，限制了可持续性和公平性。受生物感知系统（如动态调整瞳孔大小、重新聚焦视觉）启发，我们主张将自适应感知作为必要的基础性转变。自适应感知在输入层面主动调节传感器参数（如曝光、灵敏度、多模态配置），显著减少协变量偏移并提升效率。近期研究的实证证据表明，自适应感知使小模型（如EfficientNet-B0）性能超越数据量和计算资源显著更多的大模型（如OpenCLIP-H）。我们（i）提出将自适应感知广泛整合到人形机器人、医疗、自动驾驶、农业和环境监测等实际应用的路线图，（ii）批判性评估技术和伦理整合挑战，（iii）提出针对性研究方向，如标准化基准、实时自适应算法、多模态集成和隐私保护方法。这些努力旨在推动AI社区迈向可持续、鲁棒和公平的人工智能系统。

</details>


### [166] [Searching for actual causes: Approximate algorithms with adjustable precision](https://arxiv.org/abs/2507.07857)
**中文标题：寻找实际原因：具有可调精度的近似算法**

*Samuel Reyd,Ada Diaconescu,Jean-Louis Dessalles*

主要分类: cs.AI

摘要简述: 本文提出了一种多项式复杂度的算法，用于识别实际原因，并允许调整精度和全面性，填补了现有方法在非布尔、黑盒和随机系统上的空白。


<details>
  <summary>详细信息</summary>
研究动机: 当前可解释人工智能（XAI）和因果性研究主要关注因素与结果的关系，而非专家用户更期待了解导致目标结果的实际原因。然而，形式化这一概念仍是一个开放问题，且识别实际原因被证明是NP完全问题，现有实用解决方案较少。

研究方法: 作者提出了一组多项式复杂度的算法，用于识别实际原因，并支持通过调整计算时间来提高精度和全面性。

研究结果: 实验表明，这些算法能够识别现有方法无法处理的非布尔、黑盒和随机系统的原因，且通过增加计算时间可进一步提升精度和全面性。

研究结论: 本文提出的算法为解决实际原因识别问题提供了实用且灵活的解决方案，适用于多种系统类型。

中文摘要: 近年来，因果性研究日益流行，有助于提升机器学习模型的性能、可靠性和可解释性。然而，当前可解释人工智能（XAI）的文献面临批评。经典的XAI和因果性研究侧重于理解哪些因素导致哪些结果。尽管这种知识对研究人员和工程师很有价值，但它并非非专家用户所期待的解释。这些用户通常希望了解导致目标结果的事实，即实际原因。形式化这一概念仍是一个开放问题。此外，识别实际原因被证明是一个NP完全问题，且目前缺乏实用的近似解决方案。我们提出了一组多项式复杂度的算法，用于识别实际原因，并支持调整精度和全面性。实验表明，这些算法（1）能够识别现有方法无法处理的系统类别（如非布尔、黑盒和随机系统）的原因，（2）可以通过增加计算时间来提高精度和全面性。

</details>


### [167] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
**中文标题：法律纠纷分析的提示工程与多维知识图谱集成框架**

*Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo*

主要分类: cs.AI

摘要简述: 本文提出了一种结合提示工程和多维知识图谱的增强框架，用于提升法律纠纷分析的性能。通过分层提示结构和三层知识图谱架构，结合四种检索方法，显著提高了法律决策的准确性和推理能力。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型在法律纠纷分析中存在法律知识表示不足、概念理解有限和推理缺陷等问题。为了解决这些局限性，研究提出了一种集成提示工程和多维知识图谱的框架。

研究方法: 框架采用三阶段分层提示结构（任务定义、知识背景和推理指导），结合法律专用推理模板和动态优化机制。构建三层知识图谱架构（分类本体、表示和实例层），并通过四种互补方法实现精准法律概念检索。

研究结果: 实验结果表明，该框架在法律纠纷分析中显著提升了性能，能够准确分析复杂案件的法律适用，并深入理解司法决策逻辑。

研究结论: 该研究为智能法律辅助系统的实现提供了一种新颖的技术路径，有效解决了现有模型的局限性。

中文摘要: 人工智能的快速发展使大型语言模型成为智能法律系统的基础组件。然而，这些模型在法律纠纷分析中存在法律知识表示不足、概念理解有限和推理缺陷等显著局限性。本研究提出了一种结合提示工程和多维知识图谱的增强框架。该框架引入了三阶段分层提示结构（任务定义、知识背景和推理指导），辅以法律专用推理模板和动态优化机制。构建了三层知识图谱架构（法律分类本体、表示和实例层），并通过四种互补方法实现精准法律概念检索：直接法律规范代码匹配、领域特定语义向量相似性、基于本体的路径推理和专用词汇分割。这些组件与网络搜索技术结合，建立了知识增强的法律决策框架。实验结果表明，该框架在法律纠纷分析中显著提升了性能，能够准确分析复杂案件的法律适用，同时深入理解司法决策逻辑，为智能法律辅助系统的实现提供了新颖的技术路径。

</details>


### [168] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
**中文标题：温和模型将继承世界**

*Hans Gundlach,Jayson Lynch,Neil Thompson*

主要分类: cs.AI

摘要简述: 过去十年，少数公司通过大规模扩展AI系统导致模型性能不平等。本文认为，随着计算扩展的边际收益递减，AI模型能力将趋于收敛，即使计算预算有限的“温和模型”也能接近最佳模型的性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前AI领域由少数公司主导，导致模型性能不平等。本文旨在探讨计算扩展的边际收益递减现象，并论证“温和模型”最终能接近顶级模型的性能，从而改变AI战略和政策。

研究方法: 本文构建了一个模型，说明在固定分布的下一个标记目标下，计算扩展的边际能力收益显著减少。通过分析训练损失差异等代理指标，结合基准数据和理论性能模型，验证了能力收敛的趋势。

研究结果: 研究表明，计算扩展的边际收益递减现象显著，即使计算资源丰富的公司在长期内也难以保持能力优势。实证数据支持“温和模型”能力逐渐接近顶级模型的结论。

研究结论: 计算扩展的边际收益递减将导致AI模型能力收敛，促使“温和模型”接近顶级性能。这一趋势要求重新审视AI战略和政策，以适应未来的技术发展。

中文摘要: 过去十年，少数公司通过大规模扩展AI系统，导致AI模型性能的不平等。本文提出，与普遍直觉相反，计算扩展的边际收益递减将导致AI模型能力的收敛。换句话说，计算预算有限的“温和模型”将继承世界，接近整体最佳模型的性能水平。我们开发了一个模型，说明在固定分布的下一个标记目标下，计算扩展的边际能力收益显著减少。根据当前的扩展实践，我们认为这种边际收益递减足够显著，即使能够以指数速度扩展模型的公司最终在能力上的优势也将微乎其微。作为论证的一部分，我们通过基准数据和理论性能模型，提供了多个理由说明训练损失差异等代理指标能够捕捉重要的能力度量。此外，我们还分析了AI模型能力差异随时间变化的实证数据。最后，鉴于“温和模型”能力的提升，我们认为AI战略和政策需要重新审视，并概述了这一转变将影响的领域。

</details>


### [169] [Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)
**中文标题：与AI共事：衡量生成式AI对职业的影响**

*Kiran Tomlinson,Sonia Jaffe,Will Wang,Scott Counts,Siddharth Suri*

主要分类: cs.AI

摘要简述: 本研究通过分析用户与生成式AI的互动数据，评估了AI对不同职业的影响，发现知识型职业如计算机、数学、行政支持等最易受AI影响。


<details>
  <summary>详细信息</summary>
研究动机: 随着生成式AI的快速普及，了解其对经济的潜在影响成为社会重要议题。本研究旨在探索AI如何影响不同职业的工作活动。

研究方法: 研究分析了20万条用户与微软Bing Copilot的匿名对话数据，结合职业活动分类、任务成功率和影响范围，计算了各职业的AI适用性评分。

研究结果: 最常见的AI辅助活动为信息收集和写作，而AI最常执行的活动为提供信息、写作、教学和建议。知识型职业如计算机、数学和行政支持等AI适用性评分最高。

研究结论: 生成式AI对知识型职业影响显著，尤其是涉及信息处理和沟通的职业。研究为理解AI对职业的潜在影响提供了数据支持。

中文摘要: 随着生成式AI的快速普及及其对广泛任务的潜在影响，理解AI对经济的影响成为社会最重要的问题之一。本研究通过分析人们与AI的工作活动、这些活动的成功率和影响范围，并结合职业活动数据，向这一目标迈进了一步。我们分析了20万条用户与微软Bing Copilot（一种公开可用的生成式AI系统）的匿名对话数据。研究发现，人们最常寻求AI辅助的工作活动涉及信息收集和写作，而AI最常执行的活动是提供信息和帮助、写作、教学和建议。结合这些活动分类与任务成功率和影响范围的测量，我们计算了每个职业的AI适用性评分。研究发现，知识型职业群体（如计算机和数学、办公室和行政支持）以及涉及提供和沟通信息的职业（如销售）的AI适用性评分最高。此外，我们还描述了最成功的活动类型、工资和教育与AI适用性的相关性，以及实际使用情况与职业AI影响预测的比较。

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [170] [Optimal Auction Design in the Joint Advertising](https://arxiv.org/abs/2507.07418)
**中文标题：联合广告中的最优拍卖设计**

*Yang Li,Yuchao Ma,Qi Qi*

主要分类: cs.GT

摘要简述: 本文提出了一种在联合广告中实现最优拍卖设计的机制，针对单槽和多槽场景分别提出理论分析和BundleNet神经网络方法，显著提升平台收入并满足激励兼容性和个体理性。


<details>
  <summary>详细信息</summary>
研究动机: 在线广告是互联网平台的主要收入来源，联合广告通过捆绑多个广告主提升效率和收入，但现有机制未能实现最优设计，忽略了捆绑结构。本文旨在填补这一空白。

研究方法: 针对单槽场景提出最优机制理论分析；针对多槽场景设计BundleNet，一种基于神经网络的捆绑广告方法。

研究结果: 实验表明，BundleNet在单槽场景中接近理论最优，在多槽场景中表现卓越，显著提升收入并满足激励兼容性和个体理性。

研究结论: 本文提出的机制在联合广告中实现了最优设计，BundleNet在多槽场景中表现优异，为平台收入提升提供了有效解决方案。

中文摘要: 在线广告是互联网平台的重要收入来源。近年来，联合广告通过将两个广告主捆绑分配到一个广告位而非单一广告主，成为提升分配效率和收入的有效方法。然而，现有联合广告机制未能实现最优性，因其倾向于关注单个广告主而忽略捆绑结构。本文在单槽场景中提出了一种最优联合广告机制。针对多槽联合广告，我们提出了BundleNet，一种专为联合广告设计的基于神经网络的捆绑方法。大量实验表明，BundleNet生成的机制在单槽场景中接近理论分析结果，并在多槽场景中实现了最先进的性能，显著提升平台收入的同时确保了近似主导策略激励兼容性和个体理性。

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [171] [PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments](https://arxiv.org/abs/2507.07376)
**中文标题：PILOC：一种用于未知环境中多智能体动态目标搜索的信息素逆向引导机制与局部通信框架**

*Hengrui Liu,Yi Feng,Qilong Zhang*

主要分类: cs.RO

摘要简述: 本文提出了一种名为PILOC的多智能体框架，用于在未知环境中动态搜索目标。通过局部感知和通信，结合信息素逆向引导机制，显著提升了搜索效率和系统鲁棒性。


<details>
  <summary>详细信息</summary>
研究动机: 多智能体搜索与救援（MASAR）在灾害响应和探索中至关重要，但动态和未知环境中的目标不可预测性和环境不确定性带来了巨大挑战。为了解决这些问题，本文提出了PILOC框架。

研究方法: PILOC框架利用局部感知和通信，无需全局先验知识。其核心是信息素逆向引导机制，嵌入深度强化学习（DRL）的观察空间，支持基于环境线索的间接智能体协调。

研究结果: 实验表明，结合局部通信和信息素引导的PILOC显著提高了搜索效率、适应性和系统鲁棒性，在动态和通信受限场景中优于现有方法。

研究结论: PILOC为未来MASAR应用提供了有前景的方向，尤其在动态和通信受限环境中表现出色。

中文摘要: 多智能体搜索与救援（MASAR）在灾害响应、探索和侦察中发挥着重要作用。然而，动态和未知环境因目标不可预测性和环境不确定性带来了巨大挑战。为解决这些问题，我们提出了PILOC框架，该框架无需全局先验知识，利用局部感知和通信。它引入了一种信息素逆向引导机制，以实现高效协调和动态目标定位。PILOC通过局部通信促进分散式合作，显著减少了对全局通道的依赖。与传统启发式方法不同，信息素机制嵌入到深度强化学习（DRL）的观察空间中，支持基于环境线索的间接智能体协调。我们进一步将该策略集成到基于DRL的多智能体架构中，并进行了大量实验。结果表明，局部通信与信息素引导的结合显著提升了搜索效率、适应性和系统鲁棒性。与现有方法相比，PILOC在动态和通信受限场景中表现更优，为未来MASAR应用提供了有前景的方向。

</details>


### [172] [Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots](https://arxiv.org/abs/2507.07714)
**中文标题：基于自适应高斯混合模型的欠约束电缆驱动并联机器人异常检测**

*Julio Garrido,Javier Vales,Diego Silva-Muñiz,Enrique Riveiro,Pablo López-Matencio,Josué Rivera-Andrade*

主要分类: cs.RO

摘要简述: 本文提出了一种基于自适应高斯混合模型（GMM）的异常检测方法，用于欠约束电缆驱动并联机器人（CDPRs），仅通过电机扭矩数据实现高效异常检测，无需额外传感器。


<details>
  <summary>详细信息</summary>
研究动机: 电缆驱动并联机器人在负载操作任务中需在固定姿态下检测异常（如风扰或电缆碰撞），以确保安全。传统方法依赖额外传感器，本文探索仅用电机扭矩数据实现高效异常检测的可能性。

研究方法: 提出一种无监督的自适应异常检测算法：1）通过短时校准期拟合高斯混合模型（GMM）；2）实时计算扭矩数据的马氏距离，基于统计阈值触发异常标志；3）定期更新模型参数以适应环境变化。

研究结果: 在14次长时间测试中，方法实现了100%的真阳性率和95.4%的平均真阴性率，检测延迟仅1秒，优于功率阈值和非自适应GMM方法。

研究结论: 该方法仅依赖电机扭矩数据即可高效检测异常，适应性强，适用于动态环境中的欠约束电缆驱动并联机器人。

中文摘要: 电缆驱动并联机器人（CDPRs）越来越多地用于涉及预定义工具路径和中间停止的负载操作任务。在每次停止时，平台保持固定姿态，电机保持电缆张力，系统需通过检测可能影响性能的异常（如风扰或电缆碰撞）来评估是否安全继续。本文研究是否仅通过电机扭矩数据（无需额外传感器）即可检测异常，并提出一种基于高斯混合模型（GMM）的自适应无监督离群值检测算法。方法包括：1）短时校准期拟合GMM；2）实时计算扭矩数据的马氏距离，基于统计阈值触发异常标志；3）定期更新模型参数以适应环境变化。验证包括14次模拟不同风强度的长时间测试，方法实现了100%的真阳性率和95.4%的平均真阴性率，检测延迟仅1秒。与功率阈值和非自适应GMM方法相比，该方法对漂移和环境变化具有更高的鲁棒性。

</details>


### [173] [LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation](https://arxiv.org/abs/2507.07299)
**中文标题：LangNavBench：语义导航中自然语言理解的评估**

*Sonia Raychaudhuri,Enrico Cancelli,Tommaso Campari,Lamberto Ballan,Manolis Savva,Angel X. Chang*

主要分类: cs.RO

摘要简述: 本文提出了LangNavBench，一个专注于自然语言理解的语义导航基准测试，旨在评估智能体如何根据语言指令定位目标对象。通过LangNav数据集和Multi-Layered Feature Map方法，研究展示了其在处理细粒度语言描述和小物体时的优越性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前的大规模视觉语言模型在基于语言的语义导航方面取得了进展，但仍缺乏一个专注于语言理解的基准测试。本文旨在填补这一空白，通过LangNav数据集和LangNavBench基准测试，系统评估智能体对语言指令的理解能力。

研究方法: 研究首先构建了LangNav数据集，包含不同详细程度的语言描述，并手动检查以确保低错误率。随后提出了Multi-Layered Feature Map (MLFM)方法，构建可查询的多层语义地图，特别适用于处理小物体或涉及空间关系的指令。

研究结果: LangNavBench基准测试显示，MLFM方法在LangNav数据集上优于现有的基于地图的导航基线，尤其是在处理细粒度语言描述和小物体时表现突出。

研究结论: LangNavBench为语言中心的语义导航系统提供了首个全面评估框架，MLFM方法展示了其在复杂语言指令下的优越性能，为未来研究提供了重要参考。

中文摘要: 近年来，大规模视觉语言模型的进展推动了基于语言的语义导航的发展，即智能体需根据自然语言描述定位目标对象。然而，目前仍缺乏一个专注于语言理解的基准测试来评估智能体对指令中词汇的掌握程度。为此，我们提出了LangNav，一个开放的数据集，专门用于测试智能体在不同详细程度语言描述下的定位能力，从宽泛的类别名称到细粒度的属性和对象间关系。LangNav中的每一条描述均经过人工检查，错误率低于现有的终身学习和语义导航数据集。基于LangNav，我们构建了LangNavBench基准测试，用于衡量当前语义导航方法在理解和执行这些描述时的表现。LangNavBench使我们能够系统比较模型在处理属性、空间和关系线索以及类别层次结构时的能力，首次为具身导航系统提供了全面的语言中心评估。我们还提出了Multi-Layered Feature Map (MLFM)方法，构建了一个可查询的多层语义地图，特别适用于处理小物体或涉及空间关系的指令。MLFM在LangNav数据集上的表现优于现有的基于地图的导航基线。

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [174] [MODA: A Unified 3D Diffusion Framework for Multi-Task Target-Aware Molecular Generation](https://arxiv.org/abs/2507.07201)
**中文标题：MODA：一种用于多任务目标感知分子生成的统一3D扩散框架**

*Dong Xu,Zhangfan Yang,Sisi Yuan,Jenna Xinyi Yao,Jiangqiang Li,Junkai Ji*

主要分类: q-bio.BM

摘要简述: MODA是一个统一的3D扩散框架，用于多任务目标感知分子生成，通过贝叶斯掩码调度器实现片段生长、连接设计、支架跳跃和侧链修饰的统一训练，显著提升了分子设计的几何和化学性能。


<details>
  <summary>详细信息</summary>
研究动机: 当前基于扩散模型的3D分子生成器虽然精度接近晶体学水平，但任务分散且缺乏统一性，导致立体化学保真度、任务对齐和零样本迁移能力受限。MODA旨在通过多任务训练解决这些问题。

研究方法: MODA采用贝叶斯掩码调度器，在训练中掩码并去噪连续空间片段，学习跨任务的共享几何和化学先验。多任务训练生成通用骨干模型，优于六种扩散基线模型和三种训练范式。

研究结果: MODA在子结构、化学性质、相互作用和几何性能上表现优异。Model-C减少配体-蛋白冲突和子结构偏差，同时保持Lipinski合规性；Model-B在相似性上表现良好，但在新颖性和结合亲和力上稍逊。零样本从头设计和先导优化测试显示稳定的负Vina分数和高改进率。

研究结论: MODA证明单阶段多任务扩散方法可以替代两阶段工作流，为基于结构的分子设计提供高效统一的解决方案。

中文摘要: 基于扩散模型的三维分子生成器已能达到接近晶体学的精度，但其任务分散且缺乏统一性。仅使用SMILES输入、两阶段预训练-微调流程以及一任务一模型的实践限制了立体化学保真度、任务对齐和零样本迁移能力。我们提出MODA，一种通过贝叶斯掩码调度器统一片段生长、连接设计、支架跳跃和侧链修饰的扩散框架。训练中，连续空间片段被掩码并在单次传递中去噪，使模型能够学习跨任务的共享几何和化学先验。多任务训练生成的通用骨干模型在子结构、化学性质、相互作用和几何性能上优于六种扩散基线模型和三种训练范式。Model-C减少配体-蛋白冲突和子结构偏差，同时保持Lipinski合规性；Model-B在相似性上表现良好，但在新颖性和结合亲和力上稍逊。零样本从头设计和先导优化测试显示稳定的负Vina分数和高改进率，无需力场优化。这些结果表明，单阶段多任务扩散方法可以替代两阶段工作流，为基于结构的分子设计提供高效解决方案。

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [175] [Analysing semantic data storage in Distributed Ledger Technologies for Data Spaces](https://arxiv.org/abs/2507.07116)
**中文标题：分析分布式账本技术在数据空间中的语义数据存储**

*Juan Cano-Benito,Andrea Cimmino,Sven Hertling,Heiko Paulheim,Raúl García-Castro*

主要分类: cs.DC

摘要简述: 本文系统评估了分布式账本技术（DLT）在数据空间中存储语义数据的效率，比较了公有、私有和混合DLT的性能，发现私有DLT在语义数据管理上最有效，混合DLT则在公开审计与操作效率间提供了平衡。


<details>
  <summary>详细信息</summary>
研究动机: 数据空间作为去中心化基础设施，需要实现语义互操作性，但目前DLT在语义数据存储方面存在显著不足。本文旨在填补这一研究空白，评估不同DLT在语义数据存储中的表现。

研究方法: 研究使用真实世界的知识图谱作为实验基础，系统评估了公有、私有和混合DLT在性能、存储效率、资源消耗以及语义数据更新和查询能力方面的表现。

研究结果: 结果显示，私有DLT在存储和管理语义内容上效率最高，而混合DLT在公开审计与操作效率之间提供了平衡的折衷方案。

研究结论: 研究为去中心化数据生态系统中基于数据主权需求选择最合适的DLT基础设施提供了讨论依据。

中文摘要: 数据空间正逐渐成为支持多方参与者之间主权、安全和可信数据交换的去中心化基础设施。为实现这些环境中的语义互操作性，语义网技术和知识图谱被提出。尽管分布式账本技术（DLT）适合作为数据空间的基础设施，但在语义数据的高效存储方面仍存在显著差距。本文通过使用真实世界的知识图谱作为实验基础，系统评估了不同类型DLT（公有、私有和混合）在语义数据存储中的表现。研究比较了性能、存储效率、资源消耗以及语义数据更新和查询的能力。结果表明，私有DLT在存储和管理语义内容上最为高效，而混合DLT在公开审计与操作效率之间提供了平衡的折衷方案。本研究为基于去中心化数据生态系统的数据主权需求选择最合适的DLT基础设施提供了讨论依据。

</details>


### [176] [Collective Communication Profiling of Modern-day Machine Learning Workloads](https://arxiv.org/abs/2507.07117)
**中文标题：现代机器学习任务的集体通信行为分析**

*Jit Gupta,Andrew Li,Tarun Banka,Ariel Cohen,T. Sridhar,Raj Yavatkar*

主要分类: cs.DC

摘要简述: 本文分析了现代机器学习任务中的集体通信行为，发现高带宽和突发流量模式可能导致网络拥塞和丢包，影响任务性能。通过调整配置参数和日志功能，研究揭示了通信行为特征，并建议优化现有通信框架和网络拓扑以适应异常情况。


<details>
  <summary>详细信息</summary>
研究动机: 机器学习任务在分布式高性能系统上运行时，频繁使用集体通信操作（如AllReduce、AllGather等），这些操作可能导致高带宽和突发流量，引发网络拥塞和丢包，从而影响任务性能。因此，分析这些通信模式对优化网络资源配置至关重要。

研究方法: 研究通过Nvidia集体通信库的日志功能，对多种模型（如DeepSeek、GPT、Llama等）的通信行为进行详细分析。调整了影响通信行为的配置参数（如并行度、节点数量和模型类型），并以开源DeepSeek V3推理模型为例，统计了操作类型、传输大小和请求分布等数据。

研究结果: 分析显示，集体通信行为具有明显的突发性和高带宽特征，容易引发网络异常。研究提出了优化现有通信框架和网络拓扑的必要性，以适应机器学习任务的需求。

研究结论: 当前集体通信框架和网络拓扑需要重新设计，以应对机器学习任务中网络异常对性能的影响。

中文摘要: 机器学习任务在大量分布式高性能系统上运行时，涉及周期性通信操作（如AllReduce、AllGather和Broadcast）。这些操作可能产生高带宽和突发流量模式，导致网络拥塞和丢包，从而影响任务性能。因此，分析这些模式对优化网络资源配置至关重要。本研究通过Nvidia集体通信库的日志功能，对多种模型（如DeepSeek、GPT、Llama等）的通信行为进行了广泛分析。调整了影响通信行为的配置参数（如并行度、节点数量和模型类型），并以开源DeepSeek V3推理模型为例，展示了操作类型、传输大小和请求分布等结果。分析表明，有必要重新设计现有集体通信框架和网络拓扑，以适应网络异常对任务性能的影响。

</details>


### [177] [Helix Parallelism: Rethinking Sharding Strategies for Interactive Multi-Million-Token LLM Decoding](https://arxiv.org/abs/2507.07120)
**中文标题：螺旋并行：重新思考交互式多百万token LLM解码的分片策略**

*Nidhi Bhatia,Ankit More,Ritika Borkar,Tiyasa Mitra,Ramon Matas,Ritchie Zhao,Maximilian Golub,Dheevatsa Mudigere,Brian Pharris,Bita Darvish Rouhani*

主要分类: cs.DC

摘要简述: 本文提出Helix Parallelism，一种混合执行策略，通过KV并行和TP/EP并行优化多百万token LLM的解码效率，显著降低延迟并提升批量处理能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着LLM扩展到多百万token的KV历史，实时自回归解码在严格的Token-to-Token延迟（TTL）约束下面临压力。现有方法如Tensor Parallelism（TP）在注意力计算中效率不足，且KV缓存的DRAM读取随批量线性增长，限制了效率。

研究方法: Helix Parallelism结合KV并行和TP/EP并行，在注意力计算中分片KV缓存，并在FFN计算中重用GPU。通过轻量级通信步骤和Helix HOP-B技术最小化通信开销，实现低延迟和高效率。

研究结果: Helix在固定批量下将TTL降低1.5倍，并在相同延迟预算下支持32倍批量，显著提升了DeepSeek-R1的吞吐量-延迟Pareto前沿。

研究结论: Helix Parallelism为超长序列的实时推理提供了实用解决方案，推动了LLM解码效率的边界。

中文摘要: 随着LLM扩展到多百万token的KV历史，严格的Token-to-Token延迟（TTL）约束下的实时自回归解码面临压力。两个核心瓶颈是Feed-Forward Network（FFN）权重的访问和长KV缓存的读取。Tensor Parallelism（TP）虽能缓解FFN权重读取成本，但对注意力计算扩展性不佳。当TP宽度超过KV头数时，会导致低效的KV重复，限制并行性并约束批量大小。同时，长KV历史的DRAM读取随批量线性增长，进一步限制了效率。
  我们提出Helix Parallelism，一种混合执行策略，在注意力计算中应用KV并行以分片KV缓存，随后在FFN计算中重用GPU进行TP（密集LLM）或TPxExpert Parallel（EP）（MoEs）。为保持精确的注意力行为，Helix包含轻量级通信步骤。为最小化通信开销，我们引入Helix HOP-B，通过批量重叠有效降低通信成本，保持低TTL的同时提升GPU效率。与传统并行方法相比，Helix在固定批量下将TTL降低1.5倍，并在相同延迟预算下支持32倍批量（DeepSeek-R1），推动了Blackwell上的吞吐量-延迟Pareto前沿，使超长序列的实时推理成为可能。

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [178] [Adaptive Attention Residual U-Net for curvilinear structure segmentation in fluorescence microscopy and biomedical images](https://arxiv.org/abs/2507.07800)
**中文标题：自适应注意力残差U-Net用于荧光显微镜和生物医学图像中的曲线结构分割**

*Achraf Ait Laydi,Louis Cueff,Mewen Crespo,Yousef El Mourabit,Hélène Bouvrais*

主要分类: q-bio.QM

摘要简述: 本文提出了一种新型深度学习架构ASE_Res_UNet，用于荧光显微镜和生物医学图像中曲线结构的分割，尤其在噪声和低对比度条件下表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 荧光显微镜中的曲线结构分割在噪声密集和低对比度条件下极具挑战性，现有深度学习方法在此类场景中性能下降明显。

研究方法: 作者构建了两个合成数据集模拟真实荧光显微镜图像，并提出了一种结合残差块和自适应SE注意力机制的改进U-Net架构（ASE_Res_UNet）。

研究结果: ASE_Res_UNet在噪声鲁棒性和低强度结构检测上显著优于标准U-Net及其变体，并在真实显微镜图像和其他曲线结构分割任务中表现出色。

研究结论: ASE_Res_UNet在复杂条件下展现了强大的分割能力，具有在疾病诊断和治疗中的广泛应用潜力。

中文摘要: 荧光显微镜中曲线结构的分割仍然是一项具有挑战性的任务，尤其是在噪声密集和体内常见的密集纤维网络条件下。为此，我们创建了两个原始数据集，包含数百张荧光标记微管的合成细胞图像。这些数据集经过精确标注，并高度模拟真实显微镜图像，包括真实的噪声。第二个数据集通过模拟沿纤维变化的荧光强度，进一步增加了分割的难度。尽管深度学习在生物医学图像分析中表现出强大潜力，但其在噪声或低对比度条件下的性能往往下降。为克服这一限制，我们开发了一种新颖的高级架构：自适应挤压-激励残差U-Net（ASE_Res_UNet）。该模型通过在编码器中集成残差块和解码器中引入自适应SE注意力机制，改进了标准U-Net。通过消融研究和全面的视觉与定量评估，ASE_Res_UNet在噪声鲁棒性和检测细微低强度结构方面显著优于其变体（标准U-Net、ASE_UNet和Res_UNet）。这些改进主要归功于我们创建的自适应SE注意力模块。我们进一步将ASE_Res_UNet与多种最先进模型进行对比，发现其在最具挑战性的数据集上表现最优。最后，该模型在真实显微镜图像中的染色微管以及其他曲线结构（如视网膜血管和神经）的分割任务中也表现出色，展示了其在疾病诊断和治疗中的强大应用潜力。

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [179] [Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics](https://arxiv.org/abs/2507.07155)
**中文标题：评估检索增强生成代理在天体物理学自主科学发现中的应用**

*Xueqing Xu,Boris Bolliet,Adrian Dimitrov,Andrew Laverick,Francisco Villaescusa-Navarro,Licong Xu,Íñigo Zubeldia*

主要分类: astro-ph.IM

摘要简述: 本文评估了9种检索增强生成（RAG）代理配置在105个宇宙学问答对上的表现，发现OpenAI嵌入和生成模型配置表现最佳，准确率达91.4%。同时，通过人工评估结果校准了LLM-as-a-Judge（LLMaaJ）系统，为天体物理学自主科学发现提供了高效工具。


<details>
  <summary>详细信息</summary>
研究动机: 研究旨在评估不同RAG代理配置在宇宙学问答任务中的表现，并为天体物理学领域的自主科学发现系统提供最佳配置和可扩展的评估工具。

研究方法: 构建了105个宇宙学问答对，评估了9种RAG代理配置，共生成945个答案并由专家人工评估。基于评估结果校准了LLMaaJ系统。

研究结果: 最佳RAG配置（OpenAI嵌入和生成模型）准确率达91.4%。LLMaaJ系统可作为人工评估的可靠替代工具。

研究结论: 研究为天体物理学自主科学发现系统提供了最佳RAG配置和可扩展的LLMaaJ评估工具，相关数据集和系统已公开。

中文摘要: 我们评估了9种检索增强生成（RAG）代理配置在105个专门构建的宇宙学问答对上的表现。这些配置由专家人工评估，共生成945个答案。结果显示，当前最佳RAG配置为OpenAI嵌入和生成模型，准确率达91.4%。利用人工评估结果，我们校准了LLM-as-a-Judge（LLMaaJ）系统，可作为人工评估的稳健替代。这些结果使我们能够系统地为天体物理学自主科学发现的多代理系统（如配套论文中的cmbagent）选择最佳RAG配置，并提供可扩展至数千个宇宙学问答对的LLMaaJ系统。我们公开了问答数据集、人工评估结果、RAG流程和LLMaaJ系统，供天体物理学社区进一步使用。

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [180] [FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning](https://arxiv.org/abs/2507.07258)
**中文标题：FedP3E：跨机构联邦学习中非独立同分布物联网恶意软件检测的隐私保护原型交换**

*Rami Darwish,Mahmoud Abdelsalam,Sajad Khorsandroo,Kaushik Roy*

主要分类: cs.CR

摘要简述: FedP3E是一种新型联邦学习框架，通过隐私保护的原型交换解决非独立同分布（非IID）物联网恶意软件检测中的数据异质性问题，同时保护数据隐私。


<details>
  <summary>详细信息</summary>
研究动机: 随着物联网生态系统的扩展，恶意软件攻击日益复杂，而传统联邦学习算法（如FedAvg和FedProx）在数据分布不均和类别不平衡时表现不佳。因此，需要一种既能保护隐私又能应对数据异质性的检测框架。

研究方法: FedP3E通过高斯混合模型（GMM）构建类别原型，添加高斯噪声保护隐私，仅交换原型而非原始数据或梯度。服务器聚合原型后分发给客户端，并结合SMOTE增强少数类恶意软件的表征。

研究结果: 在N-BaIoT数据集上的实验表明，FedP3E在数据不平衡的跨机构场景中有效减少了统计异质性的负面影响，且通信开销较低。

研究结论: FedP3E通过原型交换机制，在保护隐私的同时提升了联邦学习中非IID数据的检测性能，为物联网恶意软件检测提供了新思路。

中文摘要: 随着物联网生态系统在关键领域的扩展，其成为日益复杂和大规模恶意软件攻击的主要目标。威胁环境的演变和物联网数据的敏感性要求检测框架既能保护隐私又能应对数据异质性。联邦学习（FL）通过分散式模型训练提供了一种解决方案，但传统算法如FedAvg和FedProx在类别不平衡和非独立同分布（非IID）数据分布下表现不佳。为此，我们提出FedP3E（隐私保护原型交换），一种新型FL框架，支持间接跨客户端表征共享同时保护数据隐私。客户端使用高斯混合模型（GMM）构建类别原型，添加高斯噪声后仅传输这些紧凑摘要至服务器。聚合后的原型分发给客户端并融入本地训练，辅以SMOTE增强少数类恶意软件的表征。不同于仅依赖参数平均，我们的原型驱动机制使客户端能够利用联邦中观察到的互补结构模式丰富本地模型，而无需交换原始数据或梯度。这一针对性策略以最小通信开销减少了统计异质性的负面影响。我们在N-BaIoT数据集上评估了FedP3E在不同数据不平衡程度的跨机构场景中的表现。

</details>


### [181] [May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks](https://arxiv.org/abs/2507.07417)
**中文标题：能否引起你的注意？利用架构感知攻击破解基于微调的提示注入防御**

*Nishit V. Pandya,Andrey Labunets,Sicun Gao,Earlence Fernandes*

主要分类: cs.CR

摘要简述: 本文通过构建基于优化的攻击方法，评估了针对大型语言模型（LLM）的提示注入防御措施的鲁棒性，发现现有防御措施无法提供声称的安全性。


<details>
  <summary>详细信息</summary>
研究动机: 当前针对LLM的提示注入攻击防御措施（如SecAlign和StruQ）声称能够通过微调模型分离指令和数据，但缺乏对其鲁棒性的严格评估。本文旨在验证这些防御措施的实际安全性。

研究方法: 作者提出了一种新颖的基于注意力的攻击算法，针对文本型LLM，并在两种最新的白盒防御措施（SecAlign和StruQ）上进行了测试。攻击通过优化方法实现，成功率达到70%。

研究结果: 实验结果显示，现有防御措施在优化攻击下表现脆弱，攻击成功率高达70%，且攻击者仅需适度增加令牌预算。

研究结论: 本文揭示了当前提示注入防御措施在白盒环境中的局限性，为理解其鲁棒性提供了重要进展。作者公开了代码和攻击方法以供进一步研究。

中文摘要: 针对大型语言模型（LLM）的提示注入攻击，一类流行的防御措施依赖于微调模型以分离指令和数据，从而避免LLM执行数据中可能包含的指令。目前已有多种学术系统和生产级实现采用了这一思路。本文在白盒环境下评估了此类防御措施的鲁棒性，通过构建强大的基于优化的攻击，证明这些防御措施无法提供所声称的安全性。具体而言，我们为文本型LLM设计了一种新颖的基于注意力的攻击算法，并将其应用于两种最新的白盒防御措施SecAlign（CCS 2025）和StruQ（USENIX Security 2025），结果显示攻击成功率高达70%，且攻击者的令牌预算仅需适度增加。我们的研究为理解白盒环境下提示注入防御措施的鲁棒性提供了重要进展。代码和攻击方法已发布于https://github.com/nishitvp/better_opts_attacks。

</details>


### [182] [Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models](https://arxiv.org/abs/2507.07406)
**中文标题：Gen-AI时代的钓鱼检测：量化LLM与传统模型的对比**

*Jikesh Thapa,Gurrehmat Chahal,Serban Voinea Gabreanu,Yazan Otoum*

主要分类: cs.CR

摘要简述: 本文比较了传统机器学习、深度学习和量化小参数大语言模型（LLM）在钓鱼检测中的表现，发现LLM虽在准确率上略逊，但在识别上下文钓鱼线索方面潜力巨大，且轻量级LLM在成本效益和解释性上表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 钓鱼攻击日益复杂，需要高精度且计算高效的检测系统。传统方法与新兴LLM在钓鱼检测中的表现和潜力尚未充分比较，本文旨在填补这一空白。

研究方法: 通过实验比较传统ML、DL和量化小参数LLM在钓鱼检测中的表现，评估零样本和少样本提示策略的影响，并测试模型的对抗鲁棒性和成本效益。

研究结果: LLM在准确率上略低于传统方法，但在上下文钓鱼线索识别上潜力显著；轻量级LLM（如DeepSeek R1 Distill Qwen 14B）能以低成本（17GB VRAM）实现80%以上的准确率，并提供可解释性支持。

研究结论: 优化后的LLM有望成为钓鱼防御系统的关键组件，为现代网络安全框架提供高效、可解释的AI解决方案。

中文摘要: 钓鱼攻击日益复杂，亟需在检测系统中平衡高精度与计算效率。本文比较了传统机器学习（ML）、深度学习（DL）和量化小参数大语言模型（LLM）在钓鱼检测中的表现。通过实验发现，尽管LLM在准确率上目前略逊于ML和DL方法，但其在识别基于上下文的钓鱼线索方面潜力巨大。我们还研究了零样本和少样本提示策略的影响，发现LLM重写的邮件会显著降低ML和LLM检测器的性能。基准测试表明，如DeepSeek R1 Distill Qwen 14B（Q8_0）等模型仅需17GB显存即可实现80%以上的准确率，支持其低成本部署的可行性。此外，我们评估了模型的对抗鲁棒性和成本效益，并展示了轻量级LLM如何提供简洁、可解释的说明以支持实时决策。这些发现将优化后的LLM定位为钓鱼防御系统的有前途组件，并为将可解释、高效AI整合到现代网络安全框架中提供了路径。

</details>


### [183] [Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks](https://arxiv.org/abs/2507.07413)
**中文标题：混合LLM增强的物联网网络中零日威胁入侵检测**

*Mohammad F. Al-Hammouri,Yazan Otoum,Rasha Atwa,Amiya Nayak*

主要分类: cs.CR

摘要简述: 本文提出了一种结合传统签名检测与GPT-2语言模型的新型入侵检测方法，显著提升了物联网环境中零日威胁的检测能力。


<details>
  <summary>详细信息</summary>
研究动机: 随着物联网环境中网络威胁日益复杂，传统入侵检测系统难以应对新型攻击模式，亟需动态自适应的方法。

研究方法: 提出了一种混合框架，结合签名检测的稳健性和GPT-2的语义分析能力，以识别零日攻击。

研究结果: 实验表明，该模型检测准确率提升6.3%，误报率降低9.0%，且保持近实时响应。

研究结论: 语言模型与入侵检测的结合为现代网络安全提供了智能、可扩展且高效的防御方案。

中文摘要: 本文提出了一种新型入侵检测方法，通过将传统签名检测与GPT-2大型语言模型的上下文理解能力相结合，解决了物联网环境中日益复杂的网络威胁问题。传统方法虽能有效检测已知威胁，但对新型攻击模式识别不足。相比之下，GPT-2擅长处理非结构化数据并识别复杂语义关系，适合发现隐蔽的零日攻击向量。我们提出的混合入侵检测框架结合了签名技术的稳健性和GPT-2驱动的语义分析的适应性。在代表性入侵数据集上的实验表明，该模型检测准确率提升6.3%，误报率降低9.0%，且保持近实时响应。这些结果证实了语言模型集成在构建智能、可扩展且适应现代连接环境的网络安全防御中的潜力。

</details>


### [184] [Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation](https://arxiv.org/abs/2507.07416)
**中文标题：基于自主人工智能的关键基础设施网络安全框架：实时威胁缓解**

*Jenifer Paulraj,Brindha Raghuraman,Nagarani Gopalakrishnan,Yazan Otoum*

主要分类: cs.CR

摘要简述: 本文提出了一种基于人工智能的自主网络安全框架，用于实时检测和缓解关键基础设施中的网络威胁，包括勒索软件、DoS攻击和APT攻击。


<details>
  <summary>详细信息</summary>
研究动机: 关键基础设施（如能源、医疗、交通和水务系统）对社会稳定和经济韧性至关重要，但其日益增长的互联性使其面临多种网络威胁。本文旨在通过人工智能技术提升这些系统的安全性和韧性。

研究方法: 提出了一种混合AI驱动的网络安全框架，结合实时漏洞检测、威胁建模和自动化修复功能，同时探讨了对抗性AI、法规遵从性和系统集成的复杂性。

研究结果: 研究提供了可操作的见解，能够显著增强关键基础设施系统对新兴网络威胁的防御能力和韧性。

研究结论: 通过AI驱动的网络安全框架，可以有效提升关键基础设施的实时威胁检测和缓解能力，同时应对对抗性AI和法规挑战。

中文摘要: 关键基础设施系统（包括能源电网、医疗设施、交通网络和水务系统）对社会稳定和经济韧性至关重要。然而，这些系统日益增长的互联性使其面临多种网络威胁，如勒索软件、拒绝服务（DoS）攻击和高级持续性威胁（APT）。本文研究了关键基础设施中的网络安全漏洞，重点分析了威胁态势、攻击途径以及人工智能（AI）在缓解这些风险中的作用。我们提出了一种混合AI驱动的网络安全框架，以增强实时漏洞检测、威胁建模和自动化修复能力。本研究还探讨了对抗性AI、法规遵从性和系统集成的复杂性。研究结果为加强关键基础设施系统对新兴网络威胁的安全性和韧性提供了可操作的见解。

</details>


### [185] [Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking](https://arxiv.org/abs/2507.07871)
**中文标题：通过多密钥水印技术缓解生成式模型中的水印窃取攻击**

*Toluwani Aremu,Noor Hussein,Munachiso Nwadike,Samuele Poppi,Jie Zhang,Karthik Nandakumar,Neil Gong,Nils Lukas*

主要分类: cs.CR

摘要简述: 本文提出了一种多密钥水印方法，用于防御生成式模型中的水印窃取攻击，通过理论保证和实验验证，显著降低了伪造水印的有效性。


<details>
  <summary>详细信息</summary>
研究动机: 生成式AI提供商通过水印技术验证生成内容的来源，但面临水印窃取攻击的威胁，即用户伪造水印以虚假指控提供商。本文旨在解决这一问题。

研究方法: 提出了一种多密钥水印扩展方法，适用于任何模态的水印技术，通过理论分析和安全游戏建模，验证其防御效果。

研究结果: 实验证明，多密钥水印方法显著降低了伪造水印的成功率，并在多个数据集上验证了其有效性。

研究结论: 多密钥水印方法为生成式模型提供了一种有效的防御水印窃取攻击的解决方案，同时适用于多种水印技术。

中文摘要: 水印技术为生成式AI提供商提供了一种验证生成内容来源的解决方案。水印是一种隐藏在生成内容中的信号，可通过秘密水印密钥验证其存在。然而，生成式AI提供商面临水印窃取攻击的威胁，即用户在没有秘密密钥的情况下伪造水印，以虚假指控提供商。窃取攻击通过收集提供商模型中的无害水印样本，试图最大化生成有害水印样本的成功率。本文专注于缓解水印窃取攻击，并将水印视为黑盒。主要贡献包括：（i）提出一种多密钥扩展方法，可事后应用于任何模态的水印技术；（ii）提供理论保证，并通过实验证明该方法显著降低了伪造水印的有效性；（iii）正式定义水印伪造威胁，并通过安全游戏建模。

</details>


### [186] [Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image Sensors](https://arxiv.org/abs/2507.07773)
**中文标题：图像传感器电磁信号注入攻击导致的彩虹色伪影**

*Youqian Zhang,Xinyu Ji,Zhihao Wang,Qinhong Jiang*

主要分类: cs.CR

摘要简述: 本文揭示了一种针对图像传感器的新型电磁信号注入攻击，攻击者通过精心调制的电磁干扰在图像中产生彩虹色伪影，从而绕过传统数字完整性检查，影响目标检测模型的准确性。


<details>
  <summary>详细信息</summary>
研究动机: 图像传感器广泛应用于安全关键系统（如监控、自动驾驶和工业自动化），其数据完整性至关重要。然而，现有系统对模拟域攻击的防御不足，本文旨在揭示这一漏洞并提出警示。

研究方法: 研究通过实验展示了针对CMOS图像传感器的电磁信号注入攻击，利用特定频率的电磁干扰在图像中诱导彩虹色伪影，并分析其对目标检测模型的影响。

研究结果: 实验表明，注入的彩虹色伪影能够通过图像信号处理流程，显著干扰目标检测模型的预测结果，导致误判。

研究结论: 本文揭示了视觉感知系统中一个未被充分探索的物理层漏洞，强调了在安全关键系统中加强防御此类攻击的必要性。

中文摘要: 图像传感器广泛应用于安全关键系统，如监控基础设施、自动驾驶汽车和工业自动化。这些系统依赖视觉数据的完整性做出决策。本文研究了一类新型电磁信号注入攻击，针对图像传感器的模拟域，使攻击者能够在不触发传统数字完整性检查的情况下操纵原始视觉输入。我们发现了一种此前未记录的CMOS图像传感器攻击现象：通过精心调制的电磁干扰在图像中诱导彩虹色伪影。进一步评估了这些攻击对最先进目标检测模型的影响，表明注入的伪影会通过图像信号处理流程传播，并导致显著的预测错误。我们的发现揭示了视觉感知栈中一个关键且未被充分探索的漏洞，强调了在此类系统中加强物理层攻击防御的必要性。

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [187] [Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation](https://arxiv.org/abs/2507.07668)
**中文标题：利用预测不确定性估计学习强子态的极点结构**

*Felix Frohnert,Denny Lane B. Sombrillo,Evert van Nieuwenburg,Patrick Emonts*

主要分类: hep-ph

摘要简述: 本文提出了一种基于不确定性估计的机器学习方法，用于分类强子态的极点结构，并在合成数据和实验数据上验证了其有效性，准确率达95%。


<details>
  <summary>详细信息</summary>
研究动机: 强子光谱学中，理论预测与实验数据的匹配是一个核心挑战。特别是在阈值附近，奇异信号可能来自多种物理机制，极点结构的识别尤为困难。现有方法在质量阈值附近的解析控制有限，导致极点配置与线形之间的映射模糊。

研究方法: 本文采用了一种基于分类器链集成的不确定性感知机器学习方法，能够同时提供认知和随机不确定性估计。通过基于预测不确定性的拒绝标准，模型在验证集上达到了近95%的准确率，同时仅丢弃少量高不确定性预测。

研究结果: 模型在合成数据上训练后，能够推广到未见过的实验数据，包括LHCb观测到的$P_{c\bar{c}}(4312)^+$态。分析表明该态具有四极点结构，表明存在一个真正的紧凑五夸克态，同时伴随一个宽度非零的高通道虚态极点。

研究结论: 本文提出的框架不仅适用于特定强子态，还可广泛应用于其他候选强子态，为散射振幅中的极点结构推断提供了一个可扩展的工具。

中文摘要: 将理论预测与实验数据匹配仍然是强子光谱学中的一个核心挑战。特别是，新强子态的识别非常困难，因为阈值附近的奇异信号可能来自多种物理机制。在这种情况下，散射振幅的极点结构是一个关键诊断工具，但不同的配置可能产生相似的信号特征。极点配置与线形之间的映射在质量阈值附近尤为模糊，因为解析控制有限。本文提出了一种基于不确定性感知的机器学习方法，用于分类$S$矩阵元素中的极点结构。我们的方法基于分类器链集成，能够提供认知和随机不确定性估计。通过基于预测不确定性的拒绝标准，模型在验证集上达到了近95%的准确率，同时仅丢弃少量高不确定性预测。在已知极点结构的合成数据上训练后，模型能够推广到未见过的实验数据，包括LHCb观测到的$P_{c\bar{c}}(4312)^+$态。分析表明该态具有四极点结构，表明存在一个真正的紧凑五夸克态，同时伴随一个宽度非零的高通道虚态极点。尽管针对特定态进行了评估，我们的框架可广泛应用于其他候选强子态，为散射振幅中的极点结构推断提供了一个可扩展的工具。

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [188] [mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar](https://arxiv.org/abs/2507.07331)
**中文标题：mmFlux：基于商用毫米波MIMO雷达的人群流动分析**

*Anurag Pallaprolu,Winston Hurst,Yasamin Mostofi*

主要分类: eess.SP

摘要简述: 本文提出了一种基于毫米波雷达的框架mmFlux，用于提取人群运动模式并推断语义信息。通过信号处理和几何图转换，实现了高保真的人群流动分析，并在实验中验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 现有的人群分析方法在复杂场景中效果有限，需要一种能够高精度捕捉人群运动模式并推断语义信息的技术。毫米波雷达因其高分辨率和抗干扰能力成为理想选择。

研究方法: 1. 结合光流估计和噪声过滤技术生成高保真毫米波流场；2. 将流场转换为有向几何图，捕捉主导流动；3. 通过雅可比矩阵分析提取人群语义信息。

研究结果: 在21次实验中，框架成功重建了复杂人群的流动结构，实现了高精度的空间对齐和流动分割比定量分析。雅可比分析准确推断出人群的转向、边界变化等语义信息。

研究结论: mmFlux框架在人群流动分析和语义推断方面表现出色，验证了其在多种应用场景中的潜力。

中文摘要: 本文提出了一种利用毫米波雷达提取人群运动模式并推断语义信息的新框架。首先，我们提出的信号处理流程结合了视觉中的光流估计概念和新型统计与形态学噪声过滤技术，生成高保真的毫米波流场——一种紧凑的人群运动二维矢量表示。接着，我们引入了一种新方法，将这些流场转换为有向几何图，其中边捕捉主导流动，顶点标记人群的分裂或合并，流动分布通过边量化。最后，我们通过分析局部雅可比矩阵并计算相应的旋度和散度，提取了结构化与扩散人群的关键语义信息。我们在3个区域对最多20人的人群进行了21次实验，使用商用毫米波雷达。我们的框架实现了对底层流动结构的高保真图重建，即使对于复杂的人群模式，也表现出强烈的空间对齐和流动分割比的精确定量表征。此外，我们的旋度和散度分析准确推断出关键人群语义，例如突然转向、流动方向变化的边界、分散和聚集。总体而言，这些发现验证了我们的框架，凸显了其在多种人群分析应用中的潜力。

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [189] [ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing](https://arxiv.org/abs/2507.07551)
**中文标题：ArchiveGPT：基于视觉语言模型的图像编目人本评估**

*Line Abele,Gerrit Anders,Tolgahan Aydın,Jürgen Buder,Helen Fischer,Dominik Kimmel,Markus Huff*

主要分类: cs.HC

摘要简述: 研究探讨了使用视觉语言模型（VLM）自动生成图像目录描述的可行性，发现AI生成的描述在质量和准确性上接近人工撰写，但仍需人工审核以确保专业性。专家对AI工具的信任度较低，强调需结合人类验证以确保符合档案管理价值。


<details>
  <summary>详细信息</summary>
研究动机: 随着照片收藏的快速增长，手动编目已无法满足需求，研究旨在探索视觉语言模型（VLM）是否能生成接近人类质量的目录描述，并评估其在档案和博物馆编目工作流程中的潜在应用。

研究方法: 研究使用VLM（InternVL2）为考古内容的照片生成目录描述，并通过档案和考古专家及非专家进行人工评估。参与者需区分AI生成与专家撰写的描述，评估质量，并报告对AI工具的信任和使用意愿。

研究结果: 参与者对AI生成描述的识别能力高于随机水平，但低估了自己的判断能力。OCR错误和幻觉降低了描述质量，但准确性和实用性较高的描述更难区分。专家对AI工具的接受度较低，更关注档案管理的责任而非技术性能。

研究结论: 研究建议采用协作模式，AI生成初稿后由人类审核以确保准确性和专业性，尤其是在考古等专业领域。成功整合需技术改进（如领域微调）和建立专业人员信任，透明和可解释的AI流程是关键。

中文摘要: 照片收藏的快速增长已超过手动编目的能力，促使研究使用视觉语言模型（VLM）自动生成元数据。本研究探讨AI生成的目录描述是否能接近人类撰写质量，以及生成式AI如何融入档案和博物馆编目工作流程。实验使用VLM（InternVL2）为考古照片生成描述，由档案和考古专家及非专家评估。参与者需区分AI生成与专家撰写描述，评估质量并报告对AI工具的信任和使用意愿。结果显示，参与者对AI生成描述的识别能力高于随机水平，但低估了自己的判断能力。OCR错误和幻觉限制了描述质量，但准确性和实用性较高的描述更难区分，表明需人工审核以确保质量，尤其在考古等专业领域。专家对AI工具的接受度较低，更关注档案管理的责任。研究建议采用协作模式，AI生成初稿后由人类审核，确保符合档案管理价值（如来源透明）。成功整合需技术改进和建立专业人员信任，透明和可解释的AI流程是关键。

</details>


### [190] [Probing Experts' Perspectives on AI-Assisted Public Speaking Training](https://arxiv.org/abs/2507.07930)
**中文标题：探究专家对AI辅助公共演讲训练工具的观点**

*Nesrine Fourati,Alisa Barkar,Marion Dragée,Liv Danthon-Lefebvre,Mathieu Chollet*

主要分类: cs.HC

摘要简述: 研究探讨专家对AI辅助公共演讲训练工具的看法，发现其价值但指出需改进个性化反馈和教学设计，支持混合训练模式。


<details>
  <summary>详细信息</summary>
研究动机: 公共演讲是重要职业技能，但许多人对此感到焦虑。传统训练依赖专家指导，而AI工具虽兴起，但研究多关注原型而非商业应用，且专家对这类工具的看法尚不明确。

研究方法: 研究通过16次半结构化访谈和2个焦点小组，收集公共演讲专家对商业AI工具的看法、与传统训练结合的建议及改进意见。

研究结果: 专家认可AI工具在处理重复性技术训练方面的价值，但指出当前工具需改进个性化反馈和教学设计，支持AI与传统训练的混合模式。

研究结论: 专家支持AI与传统训练结合的混合模式，强调AI工具需提供个性化、易理解的反馈和清晰的教学设计。

中文摘要: 背景：公共演讲是重要的职业技能，但对许多人来说是焦虑的来源。传统训练依赖专家指导，而AI技术的发展催生了新型商业自动化公共演讲反馈工具。然而，多数研究关注原型而非商业应用，且专家对这些工具的看法尚不清楚。
目标：本研究旨在评估专家对商业AI公共演讲训练工具效果和设计的意见，并提出改进建议。
方法：研究包括16次半结构化访谈和2个焦点小组，专家讨论了对当前商业工具的看法、与传统训练结合的可能性及改进建议。
结果与结论：专家认可AI工具在处理重复性技术训练方面的价值，但指出当前工具需改进个性化反馈和教学设计，支持AI与传统训练结合的混合模式。

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [191] [SonicMotion: Dynamic Spatial Audio Soundscapes with Latent Diffusion Models](https://arxiv.org/abs/2507.07318)
**中文标题：SonicMotion：基于潜在扩散模型的动态空间音频声景生成**

*Christian Templin,Yanda Zhu,Hao Wang*

主要分类: cs.SD

摘要简述: 本文提出了一种名为SonicMotion的端到端模型，用于生成具有动态声源的3D空间音频场景。该模型有两种变体，支持不同用户输入和声源定位精度。同时，作者还发布了一个新的模拟空间音频-描述对数据集。实验表明，该模型在语义对齐和音频质量上达到了先进水平，并能捕捉所需的空间属性。


<details>
  <summary>详细信息</summary>
研究动机: 空间音频在沉浸式娱乐（如VR/AR）中至关重要，并在电影和音乐中日益流行。目前最常见的空间音频格式为一阶Ambisonics（FOA）。本文旨在扩展FOA生成AI模型的最新进展，以支持动态声源的3D场景生成。

研究方法: 本文提出了SonicMotion模型，包含两种变体，分别支持不同用户输入和声源定位精度。此外，作者还构建了一个新的模拟空间音频-描述对数据集。模型通过端到端训练，结合潜在扩散模型，实现了动态声源的生成。

研究结果: 实验结果表明，SonicMotion模型在语义对齐和音频质量上与最先进模型相当，同时能够准确捕捉空间属性。

研究结论: SonicMotion模型成功实现了动态声源的3D空间音频生成，并在语义对齐和音频质量上表现出色。新发布的数据集也为未来研究提供了支持。

中文摘要: 空间音频是沉浸式娱乐（如VR/AR）的重要组成部分，并在电影和音乐中越来越受欢迎。最常见的空间音频格式为一阶Ambisonics（FOA）。本文旨在扩展FOA生成AI模型的最新进展，以实现动态声源的3D场景生成。我们提出的端到端模型SonicMotion有两种变体，分别支持不同用户输入和声源定位精度。此外，我们还发布了一个新的模拟空间音频-描述对数据集。实验表明，我们的模型在语义对齐和音频质量上与最先进模型相当，同时能够捕捉所需的空间属性。

</details>


### [192] [Input Conditioned Layer Dropping in Speech Foundation Models](https://arxiv.org/abs/2507.07954)
**中文标题：Error**

*Abdul Hannan,Daniele Falavigna,Alessio Brutti*

主要分类: cs.SD

摘要简述: Error


<details>
  <summary>详细信息</summary>
研究动机: Error

研究方法: Error

研究结果: Error

研究结论: Error

中文摘要: Error

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [193] [A Language-Driven Framework for Improving Personalized Recommendations: Merging LLMs with Traditional Algorithms](https://arxiv.org/abs/2507.07251)
**中文标题：一种语言驱动的框架：通过融合大型语言模型与传统算法改进个性化推荐**

*Aaron Goldstein,Ayan Dutta*

主要分类: cs.IR

摘要简述: 本文提出了一种结合大型语言模型（LLM）与传统推荐算法的新框架，通过语言输入提升个性化推荐效果，显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 传统推荐算法无法基于用户文本偏好（如“我喜欢轻松幽默的喜剧”）提供个性化推荐，而LLM在自然语言处理中表现优异，因此研究旨在结合两者优化推荐系统。

研究方法: 研究采用SVD或SVD++算法生成初始电影推荐，并通过LLM整合语言输入优化结果。使用MovieLens-Latest-Small数据集，通过留一验证和分层测试评估性能。

研究结果: 框架在各项指标上显著优于传统算法，如累积命中率提升约6倍，NDCG提升约3.7倍，但计算开销略有增加。

研究结论: 结合LLM与传统算法能显著提升推荐系统的个性化效果，尽管计算成本略高，但优势明显。

中文摘要: 传统推荐算法无法基于用户通过文本提供的偏好（例如“我喜欢轻松幽默的喜剧”）生成个性化推荐。近年来，大型语言模型（LLM）成为自然语言处理中最有前景的工具之一。本研究提出了一种新颖框架，模拟好友根据对个人品味的了解推荐内容的方式。我们利用LLM增强电影推荐系统，通过优化传统算法输出并结合基于语言的用户偏好输入。采用奇异值分解（SVD）或SVD++算法生成初始电影推荐，使用Surprise Python库实现，并在MovieLens-Latest-Small数据集上训练。通过留一验证命中率和累积命中率比较基础算法与LLM增强版本的性能。此外，为评估框架与当前最先进推荐系统的性能差异，我们采用评分和排名指标，以项目分层0.75训练、0.25测试划分。框架可基于用户喜爱的电影自动生成偏好档案，或允许手动指定偏好以获得更个性化的结果。在自动化方法中，框架在所有评估指标上均显著优于SVD和SVD++（如累积命中率提升约6倍，NDCG提升约3.7倍等），尽管计算开销略有增加。

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [194] [Generative Panoramic Image Stitching](https://arxiv.org/abs/2507.07133)
**中文标题：生成式全景图像拼接**

*Mathieu Tuli,Kaveh Kamali,David B. Lindell*

主要分类: cs.GR

摘要简述: 本文提出了一种生成式全景图像拼接方法，通过微调基于扩散的修复模型，解决传统拼接方法在视差、光照和风格差异下的失效问题，生成无缝且内容一致的全景图像。


<details>
  <summary>详细信息</summary>
研究动机: 传统图像拼接方法在处理视差、光照和风格差异时容易产生重影和伪影，而现有生成模型难以合成大范围连贯的全景内容。本文旨在解决这些问题，实现高质量全景图像的生成。

研究方法: 提出一种基于扩散模型的修复方法，通过微调模型以保留多参考图像的场景内容和布局，然后从单一参考图像生成无缝且视觉连贯的全景图像。

研究结果: 实验表明，该方法在图像质量、结构一致性和场景布局方面显著优于基线方法，适用于复杂场景的全景生成。

研究结论: 本文方法有效解决了传统拼接和生成模型在全景图像合成中的局限性，为高质量全景图像生成提供了新思路。

中文摘要: 我们提出了生成式全景图像拼接任务，旨在合成无缝的全景图像，同时忠实于包含视差效应及光照、相机设置或风格差异的多参考图像内容。在这一挑战性场景下，传统图像拼接方法失效，产生重影和其他伪影。尽管近期生成模型能够生成与多参考图像一致的内容，但在合成大范围连贯全景区域时表现不佳。为解决这些限制，我们提出一种方法，通过微调基于扩散的修复模型，以保留基于多参考图像的场景内容和布局。微调后，模型从单一参考图像生成完整全景，产生无缝且视觉连贯的结果，忠实整合所有参考图像内容。在捕获数据集上的评估表明，我们的方法在图像质量、图像结构和场景布局一致性方面显著优于基线方法。

</details>


### [195] [SD-GS: Structured Deformable 3D Gaussians for Efficient Dynamic Scene Reconstruction](https://arxiv.org/abs/2507.07465)
**中文标题：SD-GS：基于结构化可变形3D高斯的高效动态场景重建**

*Wei Yao,Shuzhao Xie,Letian Li,Weixiang Zhang,Zhixin Lai,Shiqi Dai,Ke Zhang,Zhi Wang*

主要分类: cs.GR

摘要简述: SD-GS提出了一种高效的动态场景重建框架，通过可变形锚点网格和变形感知的密集化策略，显著降低了模型大小并提升了渲染速度，同时保持了视觉质量。


<details>
  <summary>详细信息</summary>
研究动机: 当前4D高斯框架在动态场景重建中虽然视觉保真度高且渲染速度快，但存储成本与复杂运动表征能力之间的权衡限制了其实际应用。SD-GS旨在解决这一问题。

研究方法: SD-GS采用可变形锚点网格作为层次化、内存高效的场景表示，并通过变形感知的密集化策略自适应调整锚点分布，以优化动态区域的建模能力。

研究结果: 实验表明，SD-GS相比现有方法平均减少60%的模型大小，提升100%的FPS，显著提高了计算效率且视觉质量更优。

研究结论: SD-GS通过创新的场景表示和动态调整策略，实现了高效且高质量的动态场景重建，为实际应用提供了可行方案。

中文摘要: 当前用于动态场景重建的4D高斯框架在视觉保真度和渲染速度上表现出色，但其存储成本与复杂运动表征能力之间的权衡严重限制了实际应用。为解决这一问题，我们提出了SD-GS，一种紧凑高效的动态高斯泼溅框架，具有两大关键贡献。首先，我们引入了可变形锚点网格，这是一种层次化且内存高效的场景表示方法，其中每个锚点在其局部时空区域内衍生多个3D高斯，并作为3D场景的几何主干。其次，为增强对复杂运动的建模能力，我们提出了一种变形感知的密集化策略，自适应地在高动态区域增加锚点，同时在静态区域减少冗余，从而以更少的锚点实现更优的视觉质量。实验结果表明，与现有最优方法相比，SD-GS平均减少了60%的模型大小，并提升了100%的FPS，显著提高了计算效率，同时保持甚至超越了视觉质量。

</details>


### [196] [Capture Stage Environments: A Guide to Better Matting](https://arxiv.org/abs/2507.07623)
**中文标题：捕获舞台环境：优化抠图技术的指南**

*Hannah Dröge,Janelle Pfeifer,Saskia Rabich,Markus Plack,Reinhard Klein,Matthias B. Hullin*

主要分类: cs.GR

摘要简述: 本文探讨了在高端捕获舞台环境中图像抠图技术的挑战，并提出了一种改进工作流程的指南，同时展示了一种无需大量标注的高效适配方法。


<details>
  <summary>详细信息</summary>
研究动机: 当前主流抠图算法在捕获舞台内容中表现不佳，本文旨在揭示这些挑战并提出解决方案，以优化实际应用中的工作流程。

研究方法: 通过分析捕获舞台内容的特点，提出了一种无需大量标注的高效适配方法，并设计了一种基于扩散模型的客观评估方法。

研究结果: 提出的方法显著提升了捕获舞台环境中的抠图效果，并通过实验验证了其高效性和实用性。

研究结论: 本文为捕获舞台环境中的抠图问题提供了实用的解决方案和指南，为相关领域的实践者提供了有价值的参考。

中文摘要: 捕获舞台是电影、游戏等媒体中高端录制内容的重要来源。几乎所有流程中的关键步骤都是通过抠图将捕获的表演与背景分离。尽管常见的抠图算法在视频会议和移动娱乐等应用中表现优异，但我们发现它们在捕获舞台内容中表现不佳。本文的目标是分享对这些挑战的见解，并提出改进工作流程的指南，以缓解未解决的难题。为此，我们还展示了一种无需大量标注的高效适配方法，适用于离线和实时场景。为进行客观评估，我们提出了一种基于领先扩散模型的验证方法，突显了我们方法的优势。

</details>


### [197] [RTR-GS: 3D Gaussian Splatting for Inverse Rendering with Radiance Transfer and Reflection](https://arxiv.org/abs/2507.07733)
**中文标题：RTR-GS：基于辐射传输与反射的3D高斯泼溅逆渲染**

*Yongyang Zhou,Fang-Lue Zhang,Zichen Wang,Lei Zhang*

主要分类: cs.GR

摘要简述: RTR-GS是一种新型逆渲染框架，通过结合前向渲染和延迟渲染，有效分解BRDF和光照，实现高保真重光照，同时解决高频率细节处理中的浮游伪影问题。


<details>
  <summary>详细信息</summary>
研究动机: 3D高斯泼溅（3DGS）在新视角合成中表现优异，但在处理反射物体时仍面临挑战，尤其是在逆渲染和重光照任务中。本文旨在提出一种能够处理任意反射属性、分解BRDF和光照并实现可信重光照的框架。

研究方法: RTR-GS采用混合渲染模型，结合前向渲染（用于辐射传输）和延迟渲染（用于反射），有效分离高频和低频外观。通过基于物理的延迟渲染分支进一步优化BRDF和光照分解。

研究结果: 实验表明，RTR-GS在新视角合成、法线估计、分解和重光照任务中表现优异，同时保持了高效的训练和推理过程。

研究结论: RTR-GS通过创新的混合渲染方法，显著提升了逆渲染和重光照的效果，为处理复杂反射场景提供了可靠解决方案。

中文摘要: 3D高斯泼溅（3DGS）在新视角合成中展现了强大的能力，但渲染反射物体仍是一个重大挑战，尤其是在逆渲染和重光照任务中。我们提出了RTR-GS，一种新型逆渲染框架，能够稳健地渲染具有任意反射属性的物体，分解BRDF和光照，并提供可信的重光照结果。通过多视角图像输入，我们的方法通过混合渲染模型有效恢复几何结构，该模型结合了用于辐射传输的前向渲染和用于反射的延迟渲染。这种方法成功分离了高频和低频外观，缓解了处理高频细节时由球谐函数过拟合引起的浮游伪影。我们进一步通过基于物理的延迟渲染分支优化BRDF和光照分解。实验结果表明，我们的方法在新视角合成、法线估计、分解和重光照任务中表现优异，同时保持了高效的训练和推理过程。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [198] [Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks](https://arxiv.org/abs/2506.21142)
**中文标题：无人机网络攻击的生成对抗规避与分布外检测**

*Deepak Kumar Panda,Weisi Guo*

主要分类: cs.LG

摘要简述: 本文提出了一种基于条件生成对抗网络（cGAN）的框架，用于生成隐蔽的对抗攻击以规避无人机入侵检测系统（IDS）。同时，采用条件变分自编码器（CVAE）检测此类攻击，结果显示CVAE在识别隐蔽对抗威胁方面显著优于传统方法。


<details>
  <summary>详细信息</summary>
研究动机: 随着无人机在民用空域的广泛应用，传统异常检测方法难以识别新型威胁。现有方法将未知攻击视为分布外（OOD）样本，但无法区分隐蔽对抗攻击与真实OOD事件，导致系统易受攻击。

研究方法: 首先设计了一个基于良性无人机遥测数据和已知网络攻击（如DoS、FDI、MiTM和重放攻击）的多类IDS分类器。利用cGAN生成对抗样本，使其被误分类为良性数据，同时保持与OOD分布的统计相似性。随后采用CVAE通过负对数似然分离对抗样本与真实OOD样本。

研究结果: 实验表明，基于CVAE的后悔分数在识别隐蔽对抗威胁方面显著优于基于马氏距离的传统检测器。

研究结论: 研究强调了先进概率建模对提升IDS对抗自适应、基于生成模型的网络入侵能力的重要性。

中文摘要: 无人机在民用空域的日益普及凸显了对弹性且智能的入侵检测系统（IDS）的需求，因为传统异常检测方法通常无法识别新型威胁。常见方法将未知攻击视为分布外（OOD）样本，但当缓解措施不足时，系统仍易受攻击。此外，传统OOD检测器难以区分隐蔽对抗攻击与真实OOD事件。本文提出了一种基于条件生成对抗网络（cGAN）的框架，用于生成隐蔽对抗攻击以规避IDS机制。我们首先设计了一个基于良性无人机遥测数据和已知网络攻击（包括拒绝服务（DoS）、虚假数据注入（FDI）、中间人（MiTM）和重放攻击）的鲁棒多类IDS分类器。利用该分类器，我们的cGAN扰动已知攻击以生成被误分类为良性但统计上与OOD分布相似的对抗样本。这些对抗样本通过迭代优化实现高隐蔽性和成功率。为检测此类扰动，我们采用条件变分自编码器（CVAE），利用负对数似然分离对抗输入与真实OOD样本。对比评估显示，基于CVAE的后悔分数在识别隐蔽对抗威胁方面显著优于基于马氏距离的传统检测器。我们的研究结果强调了先进概率建模对增强IDS对抗自适应、基于生成模型的网络入侵能力的重要性。

</details>


### [199] [Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation](https://arxiv.org/abs/2507.07147)
**中文标题：基于无描述多提示学习的大型语言模型蒸馏**

*Sua Lee,Kyubum Shin,Jung Ho Park*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DeMul的新方法，通过直接蒸馏大型语言模型（LLM）的知识到提示中，避免了传统方法中提取描述的不可靠性，并在多提示设置中引入权重机制，显著提升了11个识别数据集的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的视觉语言模型（VLM）通过提示学习适应下游任务，但依赖大型语言模型（LLM）生成描述的方法存在高变异性与低可靠性问题。本文旨在解决这一问题，提出一种无需提取描述的直接蒸馏方法。

研究方法: 提出Description-free Multi-prompt Learning（DeMul），直接蒸馏LLM知识到提示中，避免提取描述的不可靠性。在多提示设置中引入权重机制，优化提示的语义丰富性。

研究结果: 实验结果表明，DeMul方法在11个识别数据集上表现优异，验证了其有效性和鲁棒性。

研究结论: DeMul通过直接蒸馏LLM知识和引入提示权重，显著提升了提示学习的性能，为未来研究提供了新方向。

中文摘要: 近期预训练的视觉语言模型（VLM）通过提示学习展现出适应下游任务的潜力，无需额外标注数据。为补充VLM中与视觉数据相关的文本信息，已有研究利用大型语言模型（LLM）生成提示，增强对未见数据的鲁棒性。然而，现有方法通常从LLM提取文本描述（如描述）并融入提示，这种方法存在高变异性与低可靠性问题。本文提出无描述多提示学习（DeMul），直接蒸馏LLM知识到提示中，避免提取描述的过程。通过无描述方法，提示能封装更丰富的语义，同时仍以连续向量形式优化，无需离散预定义模板。此外，在多提示设置中，我们实证了提示权重在训练中反映不同提示重要性的潜力。实验结果显示，我们的方法在11个识别数据集上表现优异。

</details>


### [200] [Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching](https://arxiv.org/abs/2507.07192)
**中文标题：弥合预测的最后一英里：通过条件引导流匹配增强时间序列预测**

*Huibo Xu,Runlong Yu,Likang Wu,Xianquan Wang,Qi Liu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为条件引导流匹配（CGFM）的新方法，通过整合辅助模型的输出和历史数据，改进了时间序列预测的性能，显著优于现有技术。


<details>
  <summary>详细信息</summary>
研究动机: 扩散模型在时间序列预测中表现出潜力，但其受限于固定的源分布和有限的采样路径。流匹配虽具有更快生成和更高质量输出的优势，但未能充分利用预测误差信息。本文旨在通过CGFM方法解决这些问题，释放流匹配的潜力。

研究方法: CGFM扩展了流匹配方法，通过引入辅助模型的输出和历史数据作为条件和引导，构建双向条件概率路径，并使用一般的仿射路径扩展概率路径空间，从而提升预测效果。

研究结果: 大量实验表明，CGFM在时间序列预测任务中持续优于现有先进模型，验证了其有效性。

研究结论: CGFM通过整合辅助模型的误差信息和历史数据，显著提升了时间序列预测的准确性，为预测方法的发展提供了新方向。

中文摘要: 扩散模型作为一种生成模型，在时间序列预测中显示出潜力，但其受限于固定的源分布和有限的采样路径，影响了性能。流匹配具有生成速度快、输出质量高和灵活性强的优势，并能利用先前模型预测误差中的宝贵信息。为充分释放流匹配的潜力，我们提出了条件引导流匹配（CGFM）。CGFM通过整合辅助模型的输出，实现了学习辅助模型误差的新能力。在时间序列预测任务中，它以历史数据为条件和引导，构建双向条件概率路径，并使用一般仿射路径扩展概率路径空间，从而提升预测效果。大量实验表明，CGFM持续优于现有先进模型，突显了其在推动预测方法发展中的有效性。

</details>


### [201] [Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning](https://arxiv.org/abs/2507.07197)
**中文标题：结合预训练模型以增强强化学习中的特征表示**

*Elia Piccoli,Malio Li,Giacomo Carfì,Vincenzo Lomonaco,Davide Bacciu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为权重共享注意力（WSA）的新架构，用于结合多个预训练模型的嵌入信息，以增强强化学习中的状态表示。实验表明，WSA在多个Atari游戏中表现优异，并探讨了模型数量对性能的影响。


<details>
  <summary>详细信息</summary>
研究动机: 预训练模型在自然语言处理和计算机视觉等领域取得了显著进展，但如何有效结合多个预训练模型的潜在信息以提升强化学习性能仍是一个未充分研究的问题。本文旨在解决这一挑战。

研究方法: 提出权重共享注意力（WSA）架构，通过结合多个预训练模型的嵌入信息，生成更丰富的状态表示，同时平衡效率与性能。

研究结果: WSA在多个Atari游戏中表现与端到端模型相当，并展示了其泛化能力。此外，研究了模型数量对训练中和训练后性能的影响。

研究结论: WSA为强化学习中结合预训练模型提供了一种有效方法，展示了其在性能和效率上的优势，并为未来研究提供了方向。

中文摘要: 近年来，预训练模型成为许多领域（如自然语言处理和计算机视觉）进步的关键组成部分，这些模型学习了具有洞察力的潜在嵌入表示。另一方面，强化学习（RL）专注于通过智能体与环境的交互最大化累积奖励。RL智能体对世界没有任何先验知识，它们要么从零开始学习观察与动作空间之间的端到端映射，要么在最近的研究中与庞大且计算成本高的基础模型配对。如何同时在RL中有效结合和利用不同预训练模型的隐藏信息仍是一个开放且研究不足的问题。本文提出权重共享注意力（WSA），一种新架构，用于结合多个预训练模型的嵌入信息以形成更丰富的状态表示，平衡效率与性能之间的权衡。我们进行了多种组合模式的广泛比较，表明WSA在多个Atari游戏中与端到端模型表现相当。此外，我们研究了该方法的泛化能力，并分析了模型数量对训练中和训练后智能体性能的影响。

</details>


### [202] [Bias-Aware Mislabeling Detection via Decoupled Confident Learning](https://arxiv.org/abs/2507.07216)
**中文标题：基于解耦置信学习的偏差感知错误标注检测**

*Yunyi Li,Maria De-Arteaga,Maytal Saar-Tsechansky*

主要分类: cs.LG

摘要简述: 本文提出了一种名为DeCoLe的机器学习框架，专门用于检测因标签偏差导致的错误标注数据，并在仇恨言论检测领域验证了其有效性。


<details>
  <summary>详细信息</summary>
研究动机: 标签偏差是数据完整性的主要挑战之一，尤其在关键领域（如仇恨言论检测）中，这一问题尤为突出。然而，目前缺乏有效的方法来解决这一问题。本文旨在填补这一空白。

研究方法: 本文提出了Decoupled Confident Learning (DeCoLe)框架，通过解耦和置信学习的方法，检测因标签偏差导致的错误标注数据。该方法在理论上被证明有效，并在仇恨言论检测领域进行了实证评估。

研究结果: 实证结果表明，DeCoLe在检测标签错误方面表现优异，显著优于其他标签错误检测方法。

研究结论: 本文不仅识别并解决了标签偏差导致的错误标注问题，还为组织数据管理实践提供了DeCoLe这一工具，以提升数据可靠性。

中文摘要: 可靠的数据是现代组织系统的基石。数据完整性的一个显著挑战源于标签偏差，即标签中的系统性错误，这种偏差在不同社会群体中的表现不同。尽管标签偏差在理论和实证研究中已被广泛探讨，并被公认为关键领域的紧迫问题，但有效的方法仍然稀缺。本文提出了一种名为Decoupled Confident Learning (DeCoLe)的机器学习框架，专门用于检测受标签偏差影响的错误标注实例，从而实现偏差感知的错误标注检测并提升数据质量。我们从理论上证明了DeCoLe的有效性，并在仇恨言论检测这一标签偏差问题突出的领域进行了性能评估。实证结果表明，DeCoLe在偏差感知的错误标注检测中表现优异，显著优于其他标签错误检测方法。本文不仅识别并解决了偏差感知的错误标注检测问题，还为组织数据管理实践提供了DeCoLe这一工具，以增强数据可靠性。

</details>


### [203] [An Information-Theoretic Perspective on Multi-LLM Uncertainty Estimation](https://arxiv.org/abs/2507.07236)
**中文标题：多LLM不确定性估计的信息论视角**

*Maya Kruse,Majid Afshar,Saksham Khatwani,Anoop Mayampurath,Guanhua Chen,Yanjun Gao*

主要分类: cs.LG

摘要简述: 本文提出了一种基于信息论的多LLM不确定性估计方法MUSE，通过Jensen-Shannon散度聚合互补预测，显著提升了校准性和预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLMs）在不同输入下表现不一致，表明其不确定性，而现有研究多关注单一模型，忽略了模型多样性带来的互补性。本文假设LLMs因训练差异和语言的Zipf特性而具有互补预测能力，聚合这些预测可提升不确定性估计的可靠性。

研究方法: 提出MUSE方法，利用Jensen-Shannon散度识别并聚合校准良好的LLM子集，通过信息论视角优化多模型不确定性估计。

研究结果: 在二元预测任务上的实验表明，MUSE相比单一模型和简单集成基线，显著提升了校准性和预测性能。

研究结论: MUSE通过信息论方法有效利用LLMs的互补性，为高不确定性场景下的模型可靠性提供了新思路。

中文摘要: 大型语言模型（LLMs）在不同输入下表现不一致，表明其不确定性，这在高风险场景中需要量化。现有研究多关注单一模型的校准和不确定性量化，忽略了模型多样性的潜力。我们假设LLMs因训练差异和语言的Zipf特性而具有互补预测能力，聚合其输出可提升不确定性估计的可靠性。为此，我们提出MUSE（基于子集集成的多LLM不确定性方法），这是一种简单的信息论方法，利用Jensen-Shannon散度识别并聚合校准良好的LLM子集。在二元预测任务上的实验表明，MUSE相比单一模型和简单集成基线，显著提升了校准性和预测性能。

</details>


### [204] [Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention](https://arxiv.org/abs/2507.07247)
**中文标题：显微镜下的注意力：自注意力变体的资源利用比较研究**

*Zhengyu Tian,Anantha Padmanaban Krishna Kumar,Hemant Krishnakumar,Reza Rawassizadeh*

主要分类: cs.LG

摘要简述: 本文对八种自注意力机制在GPT-2架构训练中的资源利用进行了比较研究，发现优化内核实现的注意力机制（如Flash Attention、LSH Attention和MLA）能效最高，同时强调训练时间对能耗的重要影响。


<details>
  <summary>详细信息</summary>
研究动机: 随着大语言模型和视觉语言模型的规模扩大，注意力机制因其高内存和时间复杂度成为计算瓶颈。然而，现有研究缺乏对其实际能耗和硬件资源需求的严格评估。

研究方法: 研究在GPT-2架构训练中，对八种注意力机制进行了基准测试，测量了训练时间、GPU内存使用、FLOPS、CPU使用率和功耗等关键指标。

研究结果: 结果显示，优化内核实现的注意力机制（如Flash Attention、LSH Attention和MLA）能效最高，同时发现仅降低GPU功耗并不能保证能耗减少，训练时间同样重要。

研究结论: 研究强调了在注意力设计中能耗意识的重要性，并为选择资源高效机制提供了实用见解。所有代码已在GitHub上公开。

中文摘要: 随着大语言模型（LLMs）和视觉语言模型（VLMs）的规模和应用不断扩大，注意力机制因其高内存和时间复杂度成为计算瓶颈。尽管已有许多高效的注意力变体被提出，但对其实际能耗和硬件资源需求的严格评估仍显不足。本研究在GPT-2架构训练中对八种注意力机制进行了基准测试，测量了训练时间、GPU内存使用、FLOPS、CPU使用率和功耗等关键指标。结果表明，优化内核实现的注意力机制（如Flash Attention、局部敏感哈希（LSH）注意力和多头潜在注意力（MLA））能效最高。我们还发现，仅降低GPU功耗并不能保证能耗减少，训练时间同样至关重要。本研究强调了在注意力设计中能耗意识的重要性，并为选择资源高效机制提供了实用见解。所有代码已在GitHub上公开。

</details>


### [205] [Exploiting Edge Features for Transferable Adversarial Attacks in Distributed Machine Learning](https://arxiv.org/abs/2507.07259)
**中文标题：利用边缘特征实现分布式机器学习中可迁移对抗攻击**

*Giulio Rossolini,Fabio Brau,Alessandro Biondi,Battista Biggio,Giorgio Buttazzo*

主要分类: cs.LG

摘要简述: 本文揭示了分布式机器学习中一个被忽视的安全漏洞：即使边缘和云端模型组件均为黑盒，攻击者仍可通过拦截中间特征构建高迁移性的代理模型，显著提升对抗攻击的成功率。


<details>
  <summary>详细信息</summary>
研究动机: 随着机器学习模型在物联网边缘环境中的广泛部署，分布式深度学习范式将模型计算分散到多个异构节点和通信层，扩大了攻击面。本文旨在探索即使边缘和云端模型均不可访问时，攻击者通过拦截中间特征仍能构成严重威胁的可能性。

研究方法: 本文提出了一种针对分布式环境的攻击策略，包括通过简单统计分析从向量化传输特征中重建原始张量形状，并调整代理模型架构以实现有效的特征蒸馏。

研究结果: 实验表明，利用中间特征训练的代理模型显著提高了对抗攻击的迁移性，证明了分布式深度学习系统中中间特征泄漏的严重威胁。

研究结论: 研究强调了在安全设计分布式深度学习系统时，必须考虑中间特征泄漏的风险，并采取相应防护措施。

中文摘要: 随着机器学习模型在物联网边缘环境中的广泛部署，分布式深度学习范式将模型计算分散到多个异构节点和通信层，从而扩大了攻击面。不同于传统的推断设置，这些分布式流水线将模型计算扩展到异构节点和通信层，为潜在攻击者提供了更广泛的攻击机会。基于这些动机，本文探索了一个此前被忽视的漏洞：即使模型的边缘和云端组件均不可访问（即黑盒），拦截其传输的中间特征的攻击者仍能构成严重威胁。我们证明，在这些温和且现实的假设下，攻击者可以构建高迁移性的代理模型，使整个深度学习系统更容易受到规避攻击。具体而言，拦截的特征可被有效分析和利用，以提炼出能够针对目标模型生成高迁移性对抗样本的替代模型。为此，我们提出了一种专为分布式环境设计的利用策略，包括通过简单统计分析从向量化传输特征中重建原始张量形状，并调整代理架构以实现有效的特征蒸馏。通过全面系统的实验评估，我们证明了利用中间特征训练的代理模型显著提高了对抗攻击的迁移性。这些发现强调了在设计安全的分布式深度学习系统时，亟需考虑中间特征泄漏的风险。

</details>


### [206] [Growing Transformers: Modular Composition and Layer-wise Expansion on a Frozen Substrate](https://arxiv.org/abs/2507.07129)
**中文标题：生长式Transformer：基于固定底座的模块化组合与逐层扩展**

*A. Bochkov*

主要分类: cs.LG

摘要简述: 本文提出了一种基于固定嵌入的模块化组合和逐层扩展的Transformer模型构建方法，避免了传统端到端训练的资源消耗问题，展示了高效且灵活的大模型开发范式。


<details>
  <summary>详细信息</summary>
研究动机: 当前大型语言模型（LLMs）的扩展依赖于端到端的整体训练，资源消耗大且缺乏灵活性。本文探索了一种基于固定嵌入的替代方法，旨在通过模块化组合和逐层扩展实现高效且灵活的模型开发。

研究方法: 1. 模块化组合：通过平均输出logits，将不同数据集训练的专家模型合并为混合专家（MoE）模型，无需架构修改。2. 逐层扩展：通过逐层堆叠和训练，逐步构建深度Transformer模型。

研究结果: 1. 模块化组合的MoE模型在MMLU等推理基准上表现优于原始专家模型，且无灾难性遗忘。2. 逐层扩展方法展示了稳定的收敛性，模型深度与复杂推理能力（如SQuAD）呈正相关。

研究结论: 本文提出了一种从整体优化转向模块化和增量构建的AI开发新范式，为资源高效扩展、持续学习和更开放的AI生态系统开辟了新途径。

中文摘要: 当前扩展大型语言模型（LLMs）的主流方法是端到端的整体训练，这一过程资源密集且缺乏灵活性。本文探索了一种基于非可训练、确定性输入嵌入的替代性模型开发方法。此前的研究表明，基于Unicode字形视觉结构的冻结嵌入可以在Transformer中涌现高级语义推理能力。本文进一步证明，这种固定表示底座可作为通用“对接端口”，支持两种高效扩展范式：无缝模块化组合和逐层层级扩展。

首先，我们展示了在不同数据集（如俄语和中文文本）上训练的专家模型可以通过简单平均其输出logits，合并为一个更强大的混合专家（MoE）模型，且无需架构修改。合并后的MoE模型在MMLU等推理基准上表现优于原始专家模型，且无灾难性遗忘。其次，我们提出了一种逐层构建的训练方法，通过逐步堆叠和训练单层来“生长”深度Transformer。该方法展示了稳定的收敛性，且模型深度与复杂推理能力（如SQuAD所需）呈正相关。

我们的研究结果表明，从整体优化转向更生物化或增量化的AI开发范式是可行的，其中复杂性可逐步构建且模块可自由组合。这为资源高效扩展、持续学习以及构建强大AI系统的更开放生态系统开辟了新途径。我们公开了所有代码和模型以促进进一步研究。

</details>


### [207] [Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery](https://arxiv.org/abs/2507.07328)
**中文标题：通过微调推理增强的大型语言模型缩小化学合成与发现中的合理性-有效性差距**

*Malikussaid,Hilal Hudan Nuha*

主要分类: cs.LG

摘要简述: 本文提出了一种通过微调推理增强的大型语言模型（LLM）来缩小化学合成与发现中的‘合理性-有效性差距’的方法。通过构建双领域数据集并采用低秩适应（LoRA）技术，模型在化学有效性、合成路线可行性等方面显著优于基线模型。


<details>
  <summary>详细信息</summary>
研究动机: 大型语言模型（LLM）在生成科学内容时常常出现‘合理性-有效性差距’，即在专业领域（如化学）中生成看似合理但实际无效的信息。本文旨在通过微调推理增强的LLM来解决这一问题，提升其在化学研究中的实用性。

研究方法: 采用Magistral Small模型，利用其推理能力，并通过低秩适应（LoRA）进行微调。构建了一个包含分子性质和化学反应的双领域数据集，并进行标准化处理以确保数据质量。

研究结果: 微调后的模型在格式一致性、化学分子有效性及合成路线可行性方面显著优于基线模型。与人类专家相比，模型在化学创造力和推理方面表现竞争性，但在立体化学错误、静态知识截止和偶尔的参考幻觉方面仍存在局限性。

研究结论: 本研究为将通用LLM转化为可靠的化学研究工具提供了可行框架，同时指出了未来改进的关键方向，如立体化学和知识更新问题。

中文摘要: 大型语言模型（LLM）常生成看似科学合理但实际无效的信息，这一问题在化学等专业领域中尤为突出，我们称之为‘合理性-有效性差距’。本文提出了一种系统方法，通过开发专业科学助手来缩小这一差距。我们采用了具有推理能力的Magistral Small模型，并使用低秩适应（LoRA）进行微调。方法的核心是构建了一个‘双领域数据集’，该数据集从多个来源中精选了分子性质和化学反应的内容，并进行了标准化以确保质量。评估表明，微调后的模型在格式一致性、化学分子有效性及合成路线可行性方面显著优于基线模型。结果显示了一种层次学习模式，即语法正确性比化学可能性和合成可行性更容易掌握。与人类专家的比较分析表明，模型在化学创造力和推理方面表现竞争性，但也揭示了关键局限性，如立体化学错误、静态知识截止和偶尔的参考幻觉。本研究为将通用LLM转化为可靠的化学研究工具提供了可行框架，同时指出了未来改进的关键方向。

</details>


### [208] [Leveraging Manifold Embeddings for Enhanced Graph Transformer Representations and Learning](https://arxiv.org/abs/2507.07335)
**中文标题：利用流形嵌入增强图变换器的表示与学习能力**

*Ankit Jyothish,Ali Jannesari*

主要分类: cs.LG

摘要简述: 本文提出了一种轻量级的黎曼混合专家层，将节点投影到最适合其局部结构的多种流形（球面、平坦、双曲）中，提升了图变换器的表示能力和准确性。


<details>
  <summary>详细信息</summary>
研究动机: 传统的图变换器将所有节点嵌入到单一的欧几里得空间中，忽略了图的异构拓扑结构。本文旨在通过引入流形嵌入，增强图变换器的表示能力和解释性。

研究方法: 在现有的图变换器前添加了一个轻量级的黎曼混合专家层，将每个节点路由到最适合其局部结构的流形（如球面、平坦或双曲空间）中，从而提供几何解释的潜在空间。

研究结果: 在四个节点分类基准测试中，该方法将准确性提升了高达3%，同时通过集成确保了欧几里得和非欧几里得特征的捕捉。

研究结论: 通过显式的几何感知投影，不仅提升了预测能力，还使图表示更具解释性。

中文摘要: 图变换器通常将所有节点嵌入到单一的欧几里得空间中，模糊了异构拓扑结构。我们提出了一种轻量级的黎曼混合专家层，将每个节点路由到最适合其局部结构的多种流形（如球面、平坦或双曲空间）中。这些投影为潜在空间提供了内在的几何解释。将该投影层插入到先进的集成图变换器中，在四个节点分类基准测试中，准确性提升了高达3%。集成确保了欧几里得和非欧几里得特征的捕捉。这种显式的几何感知投影不仅提升了预测能力，还使图表示更具解释性。

</details>


### [209] [Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning](https://arxiv.org/abs/2507.07359)
**中文标题：面向目标的序列贝叶斯实验设计用于因果学习**

*Zheyu Zhang,Jiayuan Dong,Jie Liu,Xun Huan*

主要分类: cs.LG

摘要简述: 本文提出了一种目标导向的贝叶斯框架GO-CBED，用于序列因果实验设计，直接最大化用户指定因果量的信息增益，实现更高效的目标实验。通过变分下界估计和联合优化策略，该框架在有限实验预算下优于现有基线。


<details>
  <summary>详细信息</summary>
研究动机: 传统方法通常致力于推断完整的因果模型，而忽略了用户特定的因果目标。本文旨在通过目标导向的贝叶斯框架，直接优化用户关心的因果量，提高实验的针对性和效率。

研究方法: GO-CBED框架通过变分下界估计器解决精确信息增益计算的难题，结合基于Transformer的策略网络和基于归一化流的变分后验进行联合优化，实现实时决策。

研究结果: 实验表明，GO-CBED在多种因果推理和发现任务中（如合成结构因果模型和半合成基因调控网络）均优于现有基线，尤其在实验预算有限和因果机制复杂的情况下表现突出。

研究结论: 本文强调了将实验设计目标与特定研究目标对齐的重要性，以及前瞻性序列规划的优势。GO-CBED框架为目标导向的因果学习提供了高效工具。

中文摘要: 我们提出了GO-CBED，一种面向目标的贝叶斯框架，用于序列因果实验设计。与传统方法不同，GO-CBED不致力于推断完整的因果模型，而是直接最大化用户指定因果量的预期信息增益（EIG），从而实现更具针对性和高效性的实验。该框架既非短视，优化整个干预序列，又目标导向，仅关注与因果查询相关的模型方面。为解决精确EIG计算的难题，我们引入了一种变分下界估计器，通过基于Transformer的策略网络和基于归一化流的变分后验进行联合优化。所得策略通过摊销网络实现实时决策。实验表明，GO-CBED在多种因果推理和发现任务（包括合成结构因果模型和半合成基因调控网络）中均优于现有基线，尤其在实验预算有限和因果机制复杂的情况下表现突出。我们的结果凸显了将实验设计目标与特定研究目标对齐以及前瞻性序列规划的益处。

</details>


### [210] [Atherosclerosis through Hierarchical Explainable Neural Network Analysis](https://arxiv.org/abs/2507.07373)
**中文标题：基于分层可解释神经网络的动脉粥样硬化分析**

*Irsyad Adam,Steven Swee,Erika Yilin,Ethan Ji,William Speier,Dean Wang,Alex Bui,Wei Wang,Karol Watson,Peipei Ping*

主要分类: cs.LG

摘要简述: 本文提出了一种名为ATHENA的分层可解释神经网络框架，用于个性化分类亚临床动脉粥样硬化。该方法通过整合患者的临床特征和分子数据，显著提升了分类性能（AUC提升13%，F1分数提升20%），并通过可解释AI支持患者亚型发现。


<details>
  <summary>详细信息</summary>
研究动机: 现有的基于图的方法在疾病分类中缺乏对队列范围特征的一致性和理解，且未整合患者间的共享致病依赖性。ATHENA旨在解决这些问题，通过分层网络表示和模态学习优化患者特异性分子指纹。

研究方法: ATHENA构建了一种新颖的分层网络表示，通过整合临床特征和分子数据，优化患者特异性分子指纹，并确保其与队列范围模式的一致性。该方法利用可解释AI驱动的子网络聚类进行患者亚型发现。

研究结果: 在391名患者的主要临床数据集中，ATHENA显著提升了亚临床动脉粥样硬化的分类性能，AUC和F1分数分别提高了13%和20%。

研究结论: ATHENA通过可解释AI驱动的分层网络框架，为个性化干预策略提供了支持，改善了动脉粥样硬化疾病进展的预测和临床结果管理。

中文摘要: 本研究通过开发一种分层图神经网络框架，解决了亚临床动脉粥样硬化的个性化分类问题。该框架利用患者的两种特征模态：队列背景下的临床特征和个体患者的分子数据。现有的基于图的疾病分类方法虽然能检测患者特异性分子指纹，但缺乏对队列范围特征的一致性和理解，而这些特征是理解多样化动脉粥样硬化轨迹中致病表型的关键。此外，患者亚型的理解通常孤立地考虑临床特征相似性，而未整合患者间的共享致病依赖性。为解决这些问题，我们提出了ATHENA（基于分层可解释神经网络的动脉粥样硬化分析），它通过整合模态学习构建了一种新颖的分层网络表示，并优化了反映个体组学数据的患者特异性分子指纹，同时确保其与队列范围模式的一致性。在391名患者的主要临床数据集中，这种临床特征与分子相互作用模式的异质性对齐显著提升了亚临床动脉粥样硬化的分类性能，AUC和F1分数分别提高了13%和20%。ATHENA通过可解释AI驱动的子网络聚类实现了机制驱动的患者亚型发现；这种新颖的整合框架增强了个性化干预策略，从而改善了动脉粥样硬化疾病进展的预测及其临床可操作结果的管理。

</details>


### [211] [Bradley-Terry and Multi-Objective Reward Modeling Are Complementary](https://arxiv.org/abs/2507.07375)
**中文标题：Bradley-Terry与多目标奖励建模的互补性**

*Zhiwei Zhang,Hui Liu,Xiaomin Li,Zhenwei Dai,Jingying Zeng,Fali Wang,Minhua Lin,Ramraj Chandradevan,Zhen Li,Chen Luo,Xianfeng Tang,Qi He,Suhang Wang*

主要分类: cs.LG

摘要简述: 本文提出了一种结合Bradley-Terry单目标和多目标回归的奖励建模框架，显著提升了奖励模型的鲁棒性和评分性能，尤其在分布外场景中表现优异。


<details>
  <summary>详细信息</summary>
研究动机: 现有基于人类偏好的奖励模型在强化学习人类反馈（RLHF）中表现良好，但易受奖励黑客攻击，且现有方法主要关注同分布场景，难以应对更具挑战性的分布外（OOD）问题。

研究方法: 提出了一种统一的奖励建模框架，通过共享嵌入空间联合训练Bradley-Terry单目标和多目标回归奖励函数，理论分析了二者的互补性。

研究结果: 实验表明，该框架显著提升了奖励模型的鲁棒性和评分性能，7B模型甚至优于70B基线模型。

研究结论: 联合训练Bradley-Terry和回归奖励函数能有效解决奖励黑客问题并提升模型性能，为奖励建模提供了新思路。

中文摘要: 基于人类偏好数据训练的奖励模型在强化学习人类反馈（RLHF）框架下表现出色，能够有效对齐大型语言模型（LLMs）与人类意图。然而，RLHF仍易受奖励黑客攻击，即策略利用奖励函数的缺陷而非真正学习预期行为。尽管已有大量研究致力于缓解奖励黑客问题，但这些方法主要针对同分布场景，而在更具挑战性的分布外（OOD）场景中表现不佳。本文通过实验表明，现有方法在OOD场景中表现欠佳，而引入细粒度多属性评分有助于解决这一问题。然而，高质量数据的稀缺常导致多目标奖励函数性能较弱，成为性能瓶颈。为此，我们提出了一种统一的奖励建模框架，通过共享嵌入空间联合训练Bradley-Terry单目标和多目标回归奖励函数。我们从理论上建立了BT损失与回归目标的联系，并强调了二者的互补优势：回归任务增强了单目标奖励函数在OOD场景中的抗奖励黑客能力，而基于BT的训练则提升了多目标奖励函数的评分能力，使7B模型优于70B基线。大量实验结果表明，该框架显著提升了奖励模型的鲁棒性和评分性能。

</details>


### [212] [COALA: Numerically Stable and Efficient Framework for Context-Aware Low-Rank Approximation](https://arxiv.org/abs/2507.07580)
**中文标题：COALA：一种数值稳定且高效的上下文感知低秩近似框架**

*Uliana Parkina,Maxim Rakhuba*

主要分类: cs.LG

摘要简述: 本文提出了一种新的数值稳定且高效的上下文感知低秩近似框架COALA，解决了现有方法因依赖显式Gram矩阵计算和逆操作而导致的数值不稳定问题。


<details>
  <summary>详细信息</summary>
研究动机: 现有上下文感知低秩近似方法在神经网络压缩和微调中表现优异，但依赖显式Gram矩阵计算和逆操作，导致数值不稳定，影响近似质量甚至产生奇异矩阵。

研究方法: 提出了一种基于稳定分解的无逆正则化框架，避免了显式Gram矩阵计算和逆操作，能够处理校准矩阵超出GPU内存、输入激活矩阵接近奇异或数据不足等挑战性场景。

研究结果: 该方法在数值稳定性上优于现有方法，能够处理多种复杂场景，并证明了在数据不足时收敛到期望近似且推导了显式误差界。

研究结论: COALA框架通过稳定分解和无逆设计，显著提升了上下文感知低秩近似的数值稳定性和效率，适用于多种实际应用场景。

中文摘要: 近期研究表明，上下文感知低秩近似是压缩和微调现代大规模神经网络的有效工具。此类近似中，范数通过输入激活矩阵加权，显著优于未加权情况。然而，现有方法因依赖涉及显式Gram矩阵计算及其逆操作的经典公式而存在数值不稳定问题，可能导致近似质量下降或数值奇异矩阵。为解决这些问题，我们提出了一种基于稳定分解的无逆正则化框架，克服了现有技术的数值缺陷。我们的方法能够处理以下挑战性场景：（1）校准矩阵超出GPU内存容量，（2）输入激活矩阵接近奇异，甚至（3）数据不足导致无法唯一近似。对于后者，我们证明了解决方案收敛到期望近似并推导了显式误差界。

</details>


### [213] [Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization](https://arxiv.org/abs/2507.07399)
**中文标题：广义树编辑距离（GTED）：一种可靠的语句自动形式化评估指标**

*Yuntian Liu,Tao Zhu,Xiaoyang Liu,Yu Chen,Zhaoxuan Liu,Qingfeng Guo,Jiashuo Zhang,Kangjie Bao,Tao Luo*

主要分类: cs.LG

摘要简述: 本文提出了一种名为GTED（广义树编辑距离）的新型评估框架，用于自然语言语句自动形式化的评估，解决了现有方法在语义理解、计算成本和自动化定理证明方面的不足。


<details>
  <summary>详细信息</summary>
研究动机: 自然语言语句自动形式化的研究日益增多，但现有的评估方法在语义理解、计算成本和自动化定理证明方面存在局限，亟需一种更可靠的评估指标。

研究方法: GTED框架首先将形式化语句标准化并转换为操作树，然后利用广义树编辑距离（GTED）度量语义相似性。

研究结果: 在miniF2F和ProofNet基准测试中，GTED在所有基线指标中表现最佳，实现了最高的准确性和Kappa分数。

研究结论: GTED为自然语言语句自动形式化提供了一个更可靠的评估指标，推动了该领域的研究进展。

中文摘要: 语句自动形式化是将自然语言语句自动翻译为形式语言的研究领域，但目前缺乏稳健的自动化评估指标。现有评估方法往往缺乏语义理解能力，计算成本高，且受限于自动化定理证明的进展。为解决这些问题，我们提出了GTED（广义树编辑距离），这是一种新型评估框架，首先将形式化语句标准化并转换为操作树，然后利用GTED度量语义相似性。在miniF2F和ProofNet基准测试中，GTED的表现优于所有基线指标，实现了最高的准确性和Kappa分数，为社区提供了一个更可靠的自动化评估指标。代码和实验结果可在https://github.com/XiaoyangLiu-sjtu/GTED获取。

</details>


### [214] [Improving Clustering on Occupational Text Data through Dimensionality Reduction](https://arxiv.org/abs/2507.07582)
**中文标题：通过降维改进职业文本数据的聚类**

*Iago Xabier Vázquez García,Damla Partanaz,Emrullah Fatih Yetkin*

主要分类: cs.LG

摘要简述: 本研究提出了一种基于BERT技术和降维方法的职业文本数据聚类优化机制，旨在为O*NET数据库中的职业定义提供映射，并通过改进的轮廓方法提升聚类效果。


<details>
  <summary>详细信息</summary>
研究动机: O*NET数据库中的职业定义虽然基于美国调查，但在不同公司和国家中可能存在差异。为了扩展这些数据并为不同任务定义的职业提供映射，本研究旨在开发一种自动化的聚类方法。

研究方法: 研究采用基于BERT的技术和多种聚类方法构建管道，同时考察降维方法对聚类性能指标的影响，并通过改进的轮廓方法优化结果。

研究结果: 通过降维和专用轮廓方法的结合，研究显著提升了聚类效果，为职业区分和职业转换提供了新的自动化路径。

研究结论: 本研究提出的基于降维的聚类映射方法能够有效区分职业定义，为职业转换提供了新的技术支持。

中文摘要: 本研究旨在为美国职业数据库O*NET中的职业定义提出一种优化的聚类机制。尽管这些职业定义基于美国的调查，但在不同公司和国家中可能存在差异。因此，若需扩展O*NET中已收集的数据并为不同任务定义的职业提供映射，定义间的映射将成为关键需求。我们提出了一种管道，结合多种基于BERT的技术和聚类方法来实现这种映射，并研究了降维方法对聚类算法性能指标的影响。最后，通过改进的轮廓方法进一步优化了结果。这种结合降维的聚类映射方法可自动区分职业，为职业转换者开辟新路径。

</details>


### [215] [HGMP:Heterogeneous Graph Multi-Task Prompt Learning](https://arxiv.org/abs/2507.07405)
**中文标题：HGMP：异构图多任务提示学习**

*Pengfei Jiao,Jialong Ni,Di Jin,Xuan Guo,Huan Liu,Hongjiang Chen,Yanxian Bi*

主要分类: cs.LG

摘要简述: 本文提出了一种名为HGMP的异构图多任务提示学习框架，通过统一任务格式、设计图级对比预训练策略和引入异构图特征提示，解决了预训练模型与下游任务不匹配的问题，显著提升了多任务场景下的性能。


<details>
  <summary>详细信息</summary>
研究动机: 现有的异构图神经网络预训练与微调方法存在预训练模型与下游任务不匹配的问题，导致性能不佳。提示学习方法因其灵活性成为新方向，但现有方法难以整合对比预训练策略。本文旨在解决这些问题。

研究方法: 1. 将下游任务统一为图级任务格式；2. 设计图级对比预训练策略以利用异构图信息；3. 引入异构图特征提示优化输入特征表示。

研究结果: 在公开数据集上的实验表明，HGMP能适应多种任务，性能显著优于基线方法。

研究结论: HGMP通过统一任务格式和优化预训练策略，有效解决了异构图多任务学习中的问题，为相关领域提供了新思路。

中文摘要: 预训练与微调方法因其能在预训练阶段利用大量未标记数据学习丰富的结构特征，在异构图神经网络领域受到广泛关注。然而，这些方法存在预训练模型与下游任务不匹配的问题，导致某些应用场景下性能不佳。提示学习方法因其能灵活调整任务表示以解决目标不一致问题，成为异构图任务的新方向。基于此，本文提出了一种名为HGMP的异构图多任务提示框架。首先，为弥合预训练模型与下游任务之间的差距，我们将所有下游任务重新表述为统一的图级任务格式。其次，针对现有图提示学习方法难以整合异构图对比预训练策略的局限性，我们设计了一种图级对比预训练策略，以更好地利用异构图信息并提升多任务场景下的性能。最后，我们引入了异构图特征提示，通过优化输入图特征的表示来增强模型性能。公开数据集上的实验结果表明，所提方法能很好地适应多种任务，并显著优于基线方法。

</details>


### [216] [GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing](https://arxiv.org/abs/2507.07735)
**中文标题：GuardVal：动态大型语言模型越狱评估以实现全面安全测试**

*Peiyan Zhang,Haibo Jin,Liying Kang,Haohan Wang*

主要分类: cs.LG

摘要简述: 本文提出GuardVal，一种动态评估大型语言模型（LLM）安全性的新协议，通过动态生成和优化越狱提示，全面测试模型在安全关键场景中的表现。


<details>
  <summary>详细信息</summary>
研究动机: 当前评估大型语言模型（LLM）越狱攻击的方法存在不足，无法全面反映模型的漏洞。本文旨在填补这一空白，提出更有效的评估协议。

研究方法: 引入GuardVal协议，动态生成和优化越狱提示，结合新的优化方法避免提示优化停滞，测试模型在10个安全领域的表现。

研究结果: 测试了从Mistral-7b到GPT-4的多种模型，揭示了不同模型的行为模式，为模型安全性提供了全面评估。

研究结论: GuardVal不仅提升了LLM安全性评估的准确性，还为未来研究和更安全模型的开发提供了重要见解。

中文摘要: 越狱攻击揭示了大型语言模型（LLM）生成有害或不道德内容的关键漏洞。由于LLM的不断演变和探测其漏洞所需的复杂性，评估这些威胁尤为困难。当前的基准和评估方法难以全面应对这些挑战，导致LLM漏洞评估存在空白。本文回顾了现有的越狱评估实践，并提出了有效越狱评估协议的三个理想特性。为解决这些问题，我们引入了GuardVal，一种新的评估协议，能够根据防御LLM的状态动态生成和优化越狱提示，从而更准确地评估防御LLM处理安全关键场景的能力。此外，我们提出了一种新的优化方法，避免提示优化过程中的停滞，确保生成更有效的越狱提示，暴露防御LLM更深层次的弱点。我们将此协议应用于从Mistral-7b到GPT-4的多种模型，覆盖10个安全领域。研究结果突出了不同模型的独特行为模式，提供了对其鲁棒性的全面视角。此外，我们的评估过程加深了对LLM行为的理解，为未来研究和开发更安全的模型提供了重要见解。

</details>


### [217] [Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning](https://arxiv.org/abs/2507.07485)
**中文标题：解决令牌空间梯度冲突：基于Transformer的多任务学习的令牌空间操作**

*Wooseong Jeong,Kuk-Jin Yoon*

主要分类: cs.LG

摘要简述: 本文提出了一种动态令牌调制与扩展（DTME-MTL）框架，用于解决基于Transformer的多任务学习中的令牌空间梯度冲突问题，通过自适应调整令牌空间提升模型性能，同时避免参数过度增长。


<details>
  <summary>详细信息</summary>
研究动机: 多任务学习（MTL）中，不同任务的目标差异可能导致负迁移，即一个任务的学习会损害其他任务的性能。尽管预训练的Transformer显著提升了MTL性能，但其固定的网络容量和结构限制了适应性。现有动态网络架构效率低下，因为它们直接将共享参数转换为任务特定参数。

研究方法: 提出动态令牌调制与扩展（DTME-MTL）框架，通过识别令牌空间中的梯度冲突，并根据冲突类型应用自适应解决方案，增强模型适应性并减少过拟合。该方法完全在令牌空间中操作，避免了参数过度增长。

研究结果: 实验表明，DTME-MTL能够持续提升多任务性能，且计算开销极小，为基于Transformer的MTL模型提供了一种可扩展且高效的解决方案。

研究结论: DTME-MTL通过令牌空间操作有效解决了多任务学习中的梯度冲突问题，显著提升了模型性能，同时保持了计算效率。

中文摘要: 多任务学习（MTL）允许在共享网络中学习多个任务，但任务间目标的差异可能导致负迁移，即一个任务的学习会降低其他任务的性能。尽管预训练的Transformer显著提升了MTL性能，但其固定的网络容量和刚性结构限制了适应性。现有的动态网络架构试图解决这一问题，但由于直接将共享参数转换为任务特定参数而效率低下。我们提出了动态令牌调制与扩展（DTME-MTL），这是一个适用于任何基于Transformer的MTL架构的框架。DTME-MTL通过识别令牌空间中的梯度冲突并根据冲突类型应用自适应解决方案，增强了适应性并减少了过拟合。与之前通过复制网络参数来缓解负迁移的方法不同，DTME-MTL完全在令牌空间中操作，实现了高效的适应而无需过多的参数增长。大量实验表明，DTME-MTL能够以最小的计算开销持续提升多任务性能，为增强基于Transformer的MTL模型提供了一种可扩展且有效的解决方案。

</details>


### [218] [Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings](https://arxiv.org/abs/2507.07532)
**中文标题：神经概念验证器：通过概念编码扩展证明者-验证者游戏**

*Berkant Turan,Suhrab Asadulla,David Steinmann,Wolfgang Stammer,Sebastian Pokutta*

主要分类: cs.LG

摘要简述: 本文提出了一种名为神经概念验证器（NCV）的统一框架，将证明者-验证者游戏（PVGs）与概念编码结合，用于高维数据中的可解释非线性分类。NCV通过提取结构化概念编码并利用非线性预测器进行决策，在复杂数据集上表现优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 尽管证明者-验证者游戏（PVGs）为非线性分类模型的可验证性提供了潜力，但其尚未应用于高维图像等复杂输入。而概念瓶颈模型（CBMs）虽能将数据转化为可解释概念，但受限于低容量线性预测器。因此，本文旨在结合两者的优势，提出一种适用于高维数据的可解释非线性分类方法。

研究方法: 本文提出的神经概念验证器（NCV）框架通过无监督概念发现模型从原始输入中提取结构化概念编码。证明者选择部分编码，验证者（非线性预测器）仅基于这些编码进行决策。

研究结果: 实验表明，NCV在高维且逻辑复杂的数据集上优于CBM和基于像素的PVG分类器基线，并能有效减少捷径行为。

研究结论: NCV为高性能、可验证的人工智能提供了一种有前景的解决方案，结合了PVGs和概念编码的优势。

中文摘要: 尽管证明者-验证者游戏（PVGs）为非线性分类模型的可验证性提供了潜力，但其尚未应用于高维图像等复杂输入。而概念瓶颈模型（CBMs）虽能将此类数据转化为可解释概念，但受限于低容量线性预测器。本文提出了神经概念验证器（NCV），一种将PVGs与概念编码结合的统一框架，用于高维数据中的可解释非线性分类。NCV通过无监督概念发现模型从原始输入中提取结构化概念编码，证明者选择部分编码，验证者（非线性预测器）仅基于这些编码进行决策。实验表明，NCV在高维且逻辑复杂的数据集上优于CBM和基于像素的PVG分类器基线，并能减少捷径行为。总体而言，NCV为高性能、可验证的人工智能迈出了重要一步。

</details>


### [219] [TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection](https://arxiv.org/abs/2507.07622)
**中文标题：TransformEEG：提升基于深度学习的EEG帕金森病检测模型泛化能力**

*Federico Del Pup,Riccardo Brun,Filippo Iotti,Edoardo Paccagnella,Mattia Pezzato,Sabrina Bertozzo,Andrea Zanola,Louis Fabrice Tshimanga,Henning Müller,Manfredo Atzori*

主要分类: cs.LG

摘要简述: TransformEEG是一种结合卷积和Transformer的混合模型，用于基于EEG数据的帕金森病检测，显著提高了模型泛化能力，减少了结果偏差。


<details>
  <summary>详细信息</summary>
研究动机: 目前基于EEG的深度学习模型在帕金森病检测中表现良好，但因受试者间的高变异性导致泛化能力不足。因此，需要开发更适合EEG数据的架构以提升模型性能。

研究方法: TransformEEG采用深度卷积分词器生成通道特定特征的分词，结合Transformer编码器的自注意力层进行特征混合。通过10-outer、10-inner的嵌套交叉验证，与其他7种EEG深度学习模型进行对比。

研究结果: TransformEEG在嵌套交叉验证中取得了最高的平衡准确率中位数（78.45%）和最低的四分位距（6.37%）。结合数据增强和阈值校正后，准确率提升至80.10%，四分位距降至5.74%。

研究结论: TransformEEG在EEG数据中表现出更一致、更可靠的帕金森病检测能力，显著降低了变异性，优于其他对比模型。

中文摘要: 脑电图（EEG）正成为一种重要、低成本、非侵入性的帕金森病（PD）早期诊断工具。在此背景下，基于EEG的深度学习（DL）模型因其能够发现信号中的高度非线性模式而显示出良好效果。然而，当前最先进的DL模型因受试者间的高变异性导致泛化能力较差。这种高变异性凸显了通过开发更适合EEG数据的新架构以增强模型泛化能力的必要性。本文提出TransformEEG，一种用于EEG数据帕金森病检测的混合卷积-Transformer模型。与基于EEGNet结构的Transformer模型不同，TransformEEG采用深度卷积分词器，专门生成由通道特定特征组成的分词，从而在Transformer编码器的自注意力层中实现更有效的特征混合。为评估该模型，我们整合了四个公共数据集，包含290名受试者（140名PD患者，150名健康对照），并进行了10-outer、10-inner的嵌套交叉验证，与其他七种成熟的EEG深度学习模型进行无偏比较。TransformEEG在所有嵌套交叉验证分区中取得了最高的平衡准确率中位数（78.45%）和最低的四分位距（6.37%）。结合数据增强和阈值校正后，准确率中位数提升至80.10%，四分位距降至5.74%。综上所述，TransformEEG在EEG数据中表现出更一致、更可靠的PD检测能力，显著降低了变异性，优于其他对比模型。

</details>


### [220] [OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting](https://arxiv.org/abs/2507.07754)
**中文标题：OPC：面向深度特征遗忘的单点收缩遗忘方法**

*Jaeheun Jung,Bosung Jung,Suhyun Bae,Donghun Lee*

主要分类: cs.LG

摘要简述: 本文提出了一种名为OPC（单点收缩）的新型机器学习遗忘算法，旨在实现深度特征遗忘，以解决现有遗忘方法仅调整模型响应而未能彻底删除内部表示信息的浅层遗忘问题。通过理论定义和高效近似算法，OPC在图像分类任务中表现出卓越的遗忘效果和抗攻击能力。


<details>
  <summary>详细信息</summary>
研究动机: 现有机器学习遗忘方法通常仅实现浅层遗忘，即调整模型响应而保留内部表示信息，容易被性能恢复攻击和梯度反演攻击恢复遗忘数据。为满足隐私、法律和伦理需求，需从根本上解决这一问题，实现深度特征遗忘。

研究方法: 本文提出了一种基于单点收缩特征的深度遗忘理论准则，并设计了一种高效近似算法，最终构建了通用遗忘算法OPC。该方法通过收缩目标数据的特征表示，确保模型内部信息被彻底删除。

研究结果: 实验表明，OPC在图像分类遗忘任务中不仅实现了有效的遗忘效果，还显著提升了对抗性能恢复攻击和梯度反演攻击的鲁棒性。其深度特征遗忘能力源于理论基础的严格约束。

研究结论: OPC通过深度特征遗忘解决了现有方法的浅层遗忘问题，为机器学习遗忘算法的鲁棒性提供了新方向。其理论框架和高效实现展示了遗忘任务中深度信息删除的重要性。

中文摘要: 机器遗忘旨在从训练模型中删除特定数据或类别的影响，以满足隐私、法律或伦理需求。现有遗忘方法通常仅实现浅层遗忘：未遗忘模型通过调整模型响应假装遗忘，而其内部表示仍保留足够信息以恢复遗忘数据或行为。我们通过训练无关的性能恢复攻击和基于梯度反演的数据重建攻击，实证验证了这种浅层遗忘现象的普遍性。为从根本上解决这一漏洞，我们基于目标数据特征表示的单点收缩定义了“深度遗忘”的理论准则，并提出了一种高效近似算法，用于构建新型通用遗忘算法：单点收缩（OPC）。在图像分类遗忘基准测试中，OPC不仅实现了有效的遗忘性能，还表现出对性能恢复攻击和梯度反演攻击的卓越抗性。OPC的独特遗忘性能源于其理论基础强制的深度特征遗忘，并重申了提升机器遗忘方法鲁棒性的必要性。

</details>


### [221] [Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training](https://arxiv.org/abs/2507.07778)
**中文标题：同步任务行为：在测试时训练中对齐多个任务**

*Wooseong Jeong,Jegyeong Cho,Youngho Yoon,Kuk-Jin Yoon*

主要分类: cs.LG

摘要简述: 本文提出了一种名为S4T的新方法，用于在测试时训练中同步多个任务的行为，解决了传统方法在多任务场景下任务行为不同步的问题。


<details>
  <summary>详细信息</summary>
研究动机: 在现实部署中，神经网络泛化到未见过的目标域是一个重大挑战。传统的测试时训练（TTT）方法在多任务场景下存在任务行为不同步的问题，即一个任务的优化步骤可能与其他任务的需求不一致。

研究方法: 本文提出了一种名为S4T的新方法，其核心思想是通过预测跨域的任务关系来同步多个任务的行为。S4T结合了传统的TTT协议，并在多任务基准测试中进行了验证。

研究结果: 实验结果表明，S4T在各种基准测试中均优于现有的TTT方法，证明了其在多任务场景下的有效性。

研究结论: S4T通过同步任务行为，显著提升了多任务场景下的测试时训练性能，为领域泛化提供了新的解决方案。

中文摘要: 将神经网络泛化到未见过的目标域是现实部署中的一项重大挑战。测试时训练（TTT）通过使用辅助的自监督任务来减少源域和目标域之间的分布偏移造成的领域差距。然而，我们发现当模型需要在领域偏移下执行多个任务时，传统的TTT方法会面临任务行为不同步的问题，即一个任务所需的优化步骤可能与其他任务的需求不一致。为解决这一问题，我们提出了一种名为“同步任务的测试时训练”（S4T）的新方法，能够同时处理多个任务。S4T的核心思想是预测跨域的任务关系是同步任务行为的关键。为验证我们的方法，我们将S4T应用于传统的多任务基准测试，并将其与传统TTT协议结合。实验结果表明，S4T在各种基准测试中均优于现有的TTT方法。

</details>


### [222] [Optimization Guarantees for Square-Root Natural-Gradient Variational Inference](https://arxiv.org/abs/2507.07853)
**中文标题：平方根自然梯度变分推断的优化保证**

*Navish Kumar,Thomas Möllenhoff,Mohammad Emtiyaz Khan,Aurelien Lucchi*

主要分类: cs.LG

摘要简述: 本文通过平方根参数化高斯协方差，为自然梯度变分高斯推断及其连续时间梯度流建立了新的收敛保证，实验证明了自然梯度方法优于欧几里得或Wasserstein几何算法。


<details>
  <summary>详细信息</summary>
研究动机: 自然梯度下降在变分推断中通常表现出快速收敛，但其理论收敛保证难以建立，尤其是在涉及凹对数似然和高斯近似的简单情况下。本文旨在解决这一问题。

研究方法: 采用高斯协方差的平方根参数化方法，为自然梯度变分高斯推断及其连续时间梯度流建立收敛保证。

研究结果: 实验结果表明，自然梯度方法在收敛速度和性能上优于欧几里得或Wasserstein几何算法。

研究结论: 通过平方根参数化，本文成功建立了自然梯度变分高斯推断的理论收敛保证，并验证了其实际优势。

中文摘要: 自然梯度下降在变分推断中通常表现出快速收敛，但其理论收敛保证一直难以建立，即使在涉及凹对数似然和高斯近似的简单情况下也是如此。我们表明，通过使用高斯协方差的平方根参数化，可以绕过这一挑战。这种方法为自然梯度变分高斯推断及其连续时间梯度流建立了新的收敛保证。实验证明了自然梯度方法的有效性，并突出了其优于使用欧几里得或Wasserstein几何的算法的优势。

</details>


### [223] [UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs](https://arxiv.org/abs/2507.07885)
**中文标题：UnIT：面向MCU的高效MAC无结构推理时剪枝方法**

*Ashe Neth,Sawinder kaur,Mohammad Nur Hossain Khan,Subrata Biswas,Asif Salekin,Bashima Islam*

主要分类: cs.LG

摘要简述: 本文提出了一种名为UnIT的轻量级方法，用于在微控制器（MCU）上实现高效的无结构推理时剪枝，通过动态跳过不必要的乘法累加操作，显著提升推理速度和能效，同时保持模型精度。


<details>
  <summary>详细信息</summary>
研究动机: 现有剪枝方法通常在训练或编译时应用，且依赖结构化稀疏性，无法充分利用无SIMD支持或并行计算的设备的细粒度效率。UnIT旨在解决这些限制，实现无需重新训练或硬件专门化的高效推理。

研究方法: UnIT通过输入特定的激活模式动态识别并跳过不必要的乘法累加操作，将剪枝决策转化为轻量级比较，替代乘法操作。此外，UnIT通过复用阈值计算和应用分层分组剪枝敏感性进一步优化计算，并提出了三种适合嵌入式平台的快速除法近似方法。

研究结果: 在MSP430微控制器上，UnIT实现了11.02%至82.03%的乘法累加操作减少，推理速度提升27.30%至84.19%，能耗降低27.33%至84.38%，同时精度损失仅为0.48-7%。在领域偏移情况下，UnIT的精度与重新训练模型相当或更高，且计算量显著减少。

研究结论: UnIT证明了无结构推理时剪枝是一种可行且实用的解决方案，能够在微控制器上高效部署深度神经网络，无需重新训练。

中文摘要: 现有剪枝方法通常在训练或编译时应用，且依赖结构化稀疏性。虽然与低功耗微控制器（MCU）兼容，但结构化剪枝未能充分利用无SIMD支持或并行计算设备的细粒度效率。为解决这些限制，我们提出了UnIT（无结构推理时剪枝），一种轻量级方法，通过输入特定的激活模式动态识别并跳过不必要的乘法累加（MAC）操作。与结构化剪枝不同，UnIT支持不规则稀疏性，且无需重新训练或硬件专门化。它将剪枝决策转化为轻量级比较，用阈值检查和近似除法替代乘法操作。UnIT进一步通过复用阈值计算和应用分层分组剪枝敏感性优化计算。我们提出了三种适合常见嵌入式平台的快速除法近似方法。在MSP430微控制器上的实验表明，与训练时剪枝模型相比，UnIT实现了11.02%至82.03%的MAC减少，推理速度提升27.30%至84.19%，能耗降低27.33%至84.38%，同时精度损失仅为0.48-7%。在领域偏移情况下，UnIT的精度与重新训练模型相当或更高，且计算量显著减少。这些结果表明，无结构推理时剪枝是一种可行且实用的解决方案，能够在MCU上高效部署深度神经网络，无需重新训练。

</details>


### [224] [Agentic Retrieval of Topics and Insights from Earnings Calls](https://arxiv.org/abs/2507.07906)
**中文标题：基于代理的财报电话会议主题与见解提取**

*Anant Gupta,Rajarshi Bhowmik,Geoffrey Gunow*

主要分类: cs.LG

摘要简述: 本文提出了一种基于LLM代理的方法，用于从季度财报电话会议中动态发现和提取新兴主题，并通过主题本体构建层次结构，以捕捉公司战略重点和新兴趋势。


<details>
  <summary>详细信息</summary>
研究动机: 传统主题建模技术难以动态捕捉新兴主题及其关系，而追踪公司财报电话会议中的战略重点对金融分析至关重要。本文旨在解决这一问题。

研究方法: 采用LLM代理从文档中提取主题，将其构建为层次化本体，并通过主题本体建立新旧主题之间的关系，以推断公司级见解和趋势。

研究结果: 通过评估本体一致性、主题演化准确性及捕捉新兴金融趋势的能力，验证了该方法的有效性。

研究结论: LLM代理驱动的方法能够有效捕捉动态主题和趋势，为金融分析提供了新工具。

中文摘要: 通过财报电话会议中的主题追踪公司战略重点是金融分析的关键任务。然而，随着行业的发展，传统主题建模技术难以动态捕捉新兴主题及其关系。本文提出了一种基于LLM代理的方法，用于从季度财报电话会议中发现和提取新兴主题。我们设计了一个LLM代理，从文档中提取主题，将其构建为层次化本体，并通过主题本体建立新旧主题之间的关系。此外，我们还展示了如何利用提取的主题推断公司级见解和随时间变化的新兴趋势。通过评估本体一致性、主题演化准确性及捕捉新兴金融趋势的能力，验证了该方法的有效性。

</details>


### [225] [ST-GRIT: Spatio-Temporal Graph Transformer For Internal Ice Layer Thickness Prediction](https://arxiv.org/abs/2507.07389)
**中文标题：ST-GRIT：基于时空图变换器的冰层内部厚度预测**

*Zesheng Liu,Maryam Rahnemoonfar*

主要分类: cs.LG

摘要简述: ST-GRIT是一种时空图变换器，用于预测冰层内部厚度，通过雷达图像捕捉冰层的时空关系，优于现有方法。


<details>
  <summary>详细信息</summary>
研究动机: 了解冰层内部厚度及其变化对监测积雪、评估冰层动态以及减少气候模型不确定性至关重要。雷达图像能穿透冰层，提供内部冰层的详细图像，但需要高效的方法处理这些数据。

研究方法: ST-GRIT采用归纳几何图学习框架提取局部空间特征，并分别使用时序和空间注意力块建模长程依赖关系。

研究结果: 在格陵兰冰盖的雷达图像数据上，ST-GRIT表现优于现有方法和其他基线图神经网络，实现了更低的均方根误差。

研究结论: ST-GRIT通过自注意力机制和图变换器，能够有效处理噪声、避免过平滑并捕捉长程依赖关系，为冰层厚度预测提供了更全面的方法。

中文摘要: 了解雷达图像中冰层内部厚度的变化对监测积雪、评估冰层动态以及减少气候模型不确定性至关重要。能够穿透冰层的雷达传感器提供了这些内部冰层的详细雷达图像。本文提出ST-GRIT，一种用于冰层厚度预测的时空图变换器，旨在处理这些雷达图像并捕捉浅层和深层冰层之间的时空关系。ST-GRIT利用归纳几何图学习框架提取局部空间特征作为特征嵌入，并分别使用时序和空间注意力块有效建模长程依赖关系。在格陵兰冰盖的雷达图像数据上的实验表明，ST-GRIT通过实现更低的均方根误差，持续优于当前最先进方法和其他基线图神经网络。这些结果突出了图上的自注意力机制相对于纯图神经网络的优势，包括处理噪声、避免过平滑以及捕捉长程依赖关系的能力。此外，独立的时空注意力块能够分别学习空间关系和时间模式，提供了一种更全面且有效的方法。

</details>


### [226] [Low Resource Reconstruction Attacks Through Benign Prompts](https://arxiv.org/abs/2507.07947)
**中文标题：通过无害提示词的低资源重建攻击**

*Sol Yarkoni,Roi Livni*

主要分类: cs.LG

摘要简述: 本文提出一种低资源重建攻击方法，通过看似无害的提示词从生成模型中重建训练数据中的图像，揭示潜在隐私风险。


<details>
  <summary>详细信息</summary>
研究动机: 生成模型（如扩散模型）的快速发展引发了隐私、版权和数据管理的风险。现有重建技术依赖高资源和精心设计的提示词，本文旨在开发一种低资源、无需训练集访问的方法，揭示普通用户可能无意中触发的重建风险。

研究方法: 基于领域知识，利用电商平台抓取的数据中模板化布局与图像关联的特点，设计低资源攻击方法，通过看似无害的提示词（如“蓝色中性T恤”）重建真实图像。

研究结果: 实验证明，该方法能在低资源条件下重建训练数据中的图像（如通过“蓝色中性T恤”提示生成真实人脸），揭示生成模型的潜在漏洞。

研究结论: 研究揭示了生成模型在低资源攻击下的脆弱性，强调需进一步关注数据来源和模型安全性，以防止无意中的隐私泄露。

中文摘要: 近年来，扩散模型等生成模型的进展引发了隐私、版权和数据管理方面的风险。为更好地理解和控制这些风险，研究者开发了多种从训练集中重建图像或部分图像的技术。然而，这些技术通常依赖高资源、训练集访问以及精心设计的提示词。本文提出一种新型攻击方法，仅需低资源、几乎无需访问训练集，并能通过看似无害的提示词实现潜在风险图像的重建。例如，针对某现有模型，提示词“蓝色中性T恤”可生成真实人脸图像。该方法基于先前研究的领域知识，揭示了因使用电商平台抓取数据（模板化布局与图像关联）而存在的基础性漏洞。

</details>


### [227] [Balancing the Past and Present: A Coordinated Replay Framework for Federated Class-Incremental Learning](https://arxiv.org/abs/2507.07712)
**中文标题：平衡过去与现在：一种用于联邦类增量学习的协调回放框架**

*Zhuang Qi,Lei Meng,Han Yu*

主要分类: cs.LG

摘要简述: 本文提出了一种名为FedCBDR的联邦类增量学习方法，通过全局协调机制和任务感知温度缩放模块，解决了类不平衡问题，显著提升了模型性能。


<details>
  <summary>详细信息</summary>
研究动机: 联邦类增量学习（FCIL）在处理多客户端持续增加的任务时，面临类不平衡问题，包括回放缓冲区内的类不平衡和新旧任务间的类不平衡。现有方法性能受限，亟需一种平衡的解决方案。

研究方法: FedCBDR包含两个关键模块：1）全局视角数据回放模块，通过隐私保护方式重构先前任务的全局表示，并采用类感知和重要性敏感采样策略实现平衡回放；2）任务感知温度缩放模块，根据任务动态自适应调整类级和实例级的logits温度，减少对多数类的过度自信，增强对少数类的敏感性。

研究结果: 实验表明，FedCBDR在异构数据分布下实现了平衡的类级采样，并在新旧任务不平衡的情况下提升了泛化能力，Top-1准确率比六种先进方法提高了2%-15%。

研究结论: FedCBDR通过全局协调和任务感知温度缩放，有效解决了FCIL中的类不平衡问题，显著提升了模型性能，为联邦类增量学习提供了新的解决方案。

中文摘要: 联邦类增量学习（FCIL）旨在协作处理多个客户端持续增加的任务。在各种方法中，数据回放成为一种有前景的解决方案，通过重新引入先前任务的代表性样本来缓解遗忘问题。然而，其性能通常受到类不平衡的限制，包括回放缓冲区内的类不平衡（由于全局意识有限）以及回放类与新到达类之间的不平衡。为解决这一问题，我们提出了一种用于FCIL的类平衡数据回放方法（FedCBDR），该方法采用全局协调机制进行类级内存构建，并重新加权学习目标以缓解上述不平衡。具体而言，FedCBDR包含两个关键组件：1）全局视角数据回放模块以隐私保护方式重构先前任务的全局表示，随后通过类感知和重要性敏感采样策略实现平衡回放；2）任务感知温度缩放模块根据任务动态自适应调整类级和实例级的logits温度，减少模型对多数类的过度自信，同时增强对少数类的敏感性。实验结果验证了FedCBDR在异构数据分布下实现了平衡的类级采样，并在新旧任务不平衡的情况下提升了泛化能力，Top-1准确率比六种先进方法提高了2%-15%。

</details>


### [228] [Reinforcement Learning with Action Chunking](https://arxiv.org/abs/2507.07969)
**中文标题：基于动作分块的强化学习**

*Qiyang Li,Zhiyuan Zhou,Sergey Levine*

主要分类: cs.LG

摘要简述: 本文提出Q-chunking方法，通过动作分块技术提升强化学习在长时程、稀疏奖励任务中的表现，特别适用于离线到在线强化学习场景，显著提高了探索效率和样本利用率。


<details>
  <summary>详细信息</summary>
研究动机: 在离线到在线强化学习场景中，如何有效利用离线数据提升在线学习的样本效率和探索能力是一个关键挑战。本文旨在通过动作分块技术解决这一问题。

研究方法: Q-chunking方法将动作分块技术应用于基于时间差分（TD）的强化学习算法中，通过在分块动作空间中直接运行强化学习，利用离线数据中的时间一致性行为提升在线探索效率，并使用无偏的n步备份实现更稳定高效的TD学习。

研究结果: 实验结果表明，Q-chunking在长时程、稀疏奖励的操纵任务中表现出色，离线性能和在线样本效率均优于现有最佳离线到在线方法。

研究结论: Q-chunking通过动作分块技术有效提升了强化学习在长时程、稀疏奖励任务中的性能，为离线到在线强化学习提供了一种高效解决方案。

中文摘要: 本文提出Q-chunking方法，这是一种简单而有效的改进强化学习（RL）算法在长时程、稀疏奖励任务中表现的方案。该方案专为离线到在线RL场景设计，旨在利用离线先验数据集最大化在线学习的样本效率。在这一场景中，有效探索和样本高效学习仍是核心挑战，因为如何利用离线数据获取良好的探索策略尚不明确。我们的关键发现是，动作分块技术（一种在模仿学习中流行的技术，用于预测未来动作序列而非单步动作）可以应用于基于时间差分（TD）的RL方法，以缓解探索挑战。Q-chunking通过在分块动作空间中直接运行RL，使智能体能够（1）利用离线数据中的时间一致性行为实现更有效的在线探索；（2）使用无偏的n步备份实现更稳定高效的TD学习。实验结果表明，Q-chunking在长时程、稀疏奖励的操纵任务中表现出色，离线性能和在线样本效率均优于现有最佳离线到在线方法。

</details>


### [229] [TRIX- Trading Adversarial Fairness via Mixed Adversarial Training](https://arxiv.org/abs/2507.07768)
**中文标题：TRIX：通过混合对抗训练实现对抗公平性**

*Tejaswini Medi,Steffen Jung,Margret Keuper*

主要分类: cs.LG

摘要简述: 论文提出TRIX框架，通过混合对抗训练解决对抗训练中的类别不公平问题，自适应地为强类别分配弱对抗样本，为弱类别分配强对抗样本，提升整体鲁棒性和公平性。


<details>
  <summary>详细信息</summary>
研究动机: 现有对抗训练方法对所有类别采用统一训练目标，忽视了类别间的脆弱性差异，导致强类别更鲁棒而弱类别更易受攻击。TRIX旨在通过自适应对抗训练减少类别间的鲁棒性差距。

研究方法: TRIX框架为强类别分配弱目标对抗样本以促进特征多样性，为弱类别分配强非目标对抗样本以增强其鲁棒性，并结合每类损失权重和扰动强度调整优化弱类别的训练效果。

研究结果: 在标准图像分类基准测试中，TRIX显著提升了最差类别在干净和对抗数据上的准确率，减少了类别间鲁棒性差异，同时保持了整体准确率。

研究结论: TRIX是迈向公平有效对抗防御的实用步骤，通过自适应对抗训练显著改善了类别间的鲁棒性公平性。

中文摘要: 对抗训练（AT）是一种广泛采用的对抗样本防御方法。然而，现有方法通常对所有类别采用统一的训练目标，忽视了类别间的脆弱性差异，导致对抗不公平性：特征区分度高的类别（强类别）往往更鲁棒，而特征重叠或共享的类别（弱类别）则更容易受到对抗攻击。我们发现，强类别在训练中不需要强对抗样本，因为其非鲁棒特征会迅速被抑制；而弱类别则能从强对抗样本中受益，有效减少其脆弱性。基于此，我们提出了TRIX，一种特征感知的对抗训练框架，自适应地为强类别分配弱目标对抗样本以促进特征多样性，为弱类别分配强非目标对抗样本以增强其聚焦鲁棒性。TRIX进一步结合了每类损失权重和扰动强度调整，以优化弱类别的训练效果。在标准图像分类基准测试中，包括对PGD和AutoAttack等强攻击的评估，TRIX显著提升了最差类别在干净和对抗数据上的准确率，减少了类别间鲁棒性差异，同时保持了整体准确率。我们的结果表明，TRIX是迈向公平有效对抗防御的实用步骤。

</details>


### [230] [EXPO: Stable Reinforcement Learning with Expressive Policies](https://arxiv.org/abs/2507.07986)
**中文标题：EXPO：基于表达性策略的稳定强化学习**

*Perry Dong,Qiyang Li,Dorsa Sadigh,Chelsea Finn*

主要分类: cs.LG

摘要简述: 本文提出EXPO算法，通过结合稳定模仿学习和轻量级高斯编辑策略，解决了在线强化学习中表达性策略训练不稳定的问题，显著提升了样本效率。


<details>
  <summary>详细信息</summary>
研究动机: 在线强化学习中，表达性策略（如扩散和流匹配策略）由于参数化链较长，难以稳定优化价值函数。本文旨在解决这一问题，提出一种稳定且高效的训练方法。

研究方法: EXPO算法采用双策略结构：一个大型表达性基础策略通过稳定模仿学习训练，另一个轻量级高斯编辑策略对基础策略的动作进行优化。通过即时策略选择价值最大化的动作，提升训练稳定性。

研究结果: 实验表明，EXPO在样本效率上比现有方法提升了2-3倍，适用于离线数据微调和在线训练场景。

研究结论: EXPO通过结合表达性策略和即时优化策略，有效解决了在线强化学习中价值最大化不稳定的问题，显著提升了性能。

中文摘要: 我们研究了在给定离线数据集的情况下，通过在线强化学习（RL）训练和微调表达性策略的问题。在线RL中训练表达性策略类面临稳定价值最大化的独特挑战。与在线RL中常用的简单高斯策略不同，扩散和流匹配等表达性策略由长去噪链参数化，这阻碍了从动作到策略参数的稳定梯度传播。我们的关键见解是，通过避免直接对表达性策略进行价值优化，转而构建即时RL策略来最大化Q值，可以解决稳定价值最大化问题。我们提出了表达性策略优化（EXPO），一种高效的在线RL算法，利用即时策略通过两个参数化策略最大化价值：一个通过稳定模仿学习目标训练的大型表达性基础策略，以及一个轻量级高斯编辑策略，将基础策略采样的动作编辑为更高价值的分布。即时策略通过学习的编辑策略优化基础策略的动作，并从基础和编辑动作中选择价值最大化的动作用于采样和时间差分（TD）备份。我们的方法在微调预训练策略和利用离线数据进行在线训练的场景中，平均样本效率比现有方法提升了2-3倍。

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [231] [DpDNet: An Dual-Prompt-Driven Network for Universal PET-CT Segmentation](https://arxiv.org/abs/2507.07126)
**中文标题：DpDNet：一种双提示驱动的通用PET-CT分割网络**

*Xinglong Liang,Jiaju Huang,Luyi Han,Tianyu Zhang,Xin Wang,Yuan Gao,Chunyao Lu,Lishan Cai,Tao Tan,Ritse Mann*

主要分类: eess.IV

摘要简述: DpDNet是一种双提示驱动的网络，通过结合特定提示和通用提示，解决了PET-CT病灶分割中的噪声敏感性和病灶形态多变问题，并在四种癌症类型的数据集上表现优于现有模型。


<details>
  <summary>详细信息</summary>
研究动机: 当前主流方法将多种癌症病灶分割视为单一任务，忽略了不同癌症类型的独特性。考虑到不同癌症在转移模式、器官偏好和FDG摄取强度上的特异性和相似性，作者提出DpDNet以更好地捕捉癌症特异性特征和共享知识。

研究方法: DpDNet采用双提示驱动机制，包括特定提示和通用提示，以分别捕捉癌症特异性特征和共享知识。为避免早期引入提示导致的信息遗忘，网络在解码器后使用提示感知头自适应处理多任务分割。

研究结果: 在包含四种癌症类型的PET-CT数据集上，DpDNet表现优于现有模型。基于分割结果计算的MTV、TLG和SUVmax指标可用于乳腺癌生存分析，表明DpDNet在个性化风险分层中具有潜力。

研究结论: DpDNet通过双提示驱动机制有效解决了PET-CT病灶分割的挑战，为临床医生优化治疗策略提供了有力工具。

中文摘要: PET-CT病灶分割因噪声敏感性、病灶形态多变以及生理高代谢信号的干扰而具有挑战性。当前主流方法将多种癌症病灶分割视为单一任务，忽略了不同癌症类型的独特性。考虑到不同癌症在转移模式、器官偏好和FDG摄取强度上的特异性和相似性，我们提出DpDNet，一种双提示驱动的网络，通过结合特定提示捕捉癌症特异性特征和通用提示保留共享知识。此外，为避免早期引入提示导致的信息遗忘，网络在解码器后使用提示感知头自适应处理多任务分割。在包含四种癌症类型的PET-CT数据集上，DpDNet表现优于现有模型。基于分割结果，我们计算了乳腺癌的MTV、TLG和SUVmax指标用于生存分析。结果表明，DpDNet有望成为个性化风险分层的有效工具，帮助临床医生优化治疗策略并改善预后。代码发布于https://github.com/XinglongLiang08/DpDNet。

</details>


### [232] [Semi-supervised learning and integration of multi-sequence MR-images for carotid vessel wall and plaque segmentation](https://arxiv.org/abs/2507.07496)
**中文标题：半监督学习与多序列MRI图像的整合用于颈动脉血管壁和斑块分割**

*Marie-Christine Pali,Christina Schwaiger,Malik Galijasevic,Valentin K. Ladenhauf,Stephanie Mangesius,Elke R. Gizewski*

主要分类: eess.IV

摘要简述: 本文提出了一种半监督深度学习方法，用于多序列MRI数据的颈动脉血管壁和斑块分割，通过粗定位和精细分割网络结合多序列融合策略，解决了标记数据稀缺和复杂形态的挑战。


<details>
  <summary>详细信息</summary>
研究动机: 颈动脉斑块的多序列MRI分析对评估动脉粥样硬化和缺血性中风风险至关重要，但斑块形态复杂且标记数据稀缺，亟需一种高效的分割方法。

研究方法: 方法包括两个网络：粗定位模型确定感兴趣区域，精细分割模型精确划分血管壁和斑块；提出多级多序列U-Net架构和半监督学习策略，通过输入变换增强一致性。

研究结果: 在52名动脉粥样硬化患者的五组MRI序列上验证，实验表明方法有效，并强调融合点选择对U-Net架构的重要性。专家评估进一步验证了结果的准确性。

研究结论: 研究证明了多序列融合策略和半监督学习在数据有限的MRI应用中提升颈动脉分割效果的潜力。

中文摘要: 颈动脉斑块的多序列磁共振成像（MRI）分析对评估动脉粥样硬化和缺血性中风风险至关重要。为了量化动脉粥样硬化的状态，准确的分割是必要的。然而，斑块的复杂形态和标记数据的稀缺性带来了重大挑战。本文提出了一种半监督深度学习方法，旨在有效整合多序列MRI数据以分割颈动脉血管壁和斑块。该算法包含两个网络：粗定位模型根据颈动脉位置和数量的先验知识确定感兴趣区域，随后由精细分割模型精确划分血管壁和斑块。为了整合不同MRI序列的互补信息，研究了多种融合策略，并引入了多级多序列U-Net架构。针对标记数据有限和颈动脉MRI复杂性的挑战，提出了一种半监督方法，通过输入变换增强一致性。方法在52名动脉粥样硬化患者的五组MRI序列上进行了评估。综合实验证明了方法的有效性，并强调了U-Net架构中融合点选择的重要性。通过专家评估进一步验证了结果的准确性。研究结果凸显了融合策略和半监督学习在数据有限的MRI应用中提升颈动脉分割效果的潜力。

</details>


### [233] [D-CNN and VQ-VAE Autoencoders for Compression and Denoising of Industrial X-ray Computed Tomography Images](https://arxiv.org/abs/2507.07704)
**中文标题：D-CNN和VQ-VAE自编码器在工业X射线计算机断层扫描图像压缩与去噪中的应用**

*Bardia Hejazi,Keerthana Chand,Tobias Fritsch,Giovanni Bruno*

主要分类: eess.IV

摘要简述: 本研究探讨了使用深度学习的D-CNN和VQ-VAE自编码器对工业X射线计算机断层扫描（XCT）图像进行压缩和去噪的效果，并比较了不同压缩率下图像恢复的质量。


<details>
  <summary>详细信息</summary>
研究动机: 随着成像技术的进步，成像科学中的数据量急剧增长，亟需高效可靠的存储解决方案。本研究旨在通过深度学习自编码器压缩工业XCT数据，并评估其对恢复数据质量的影响。

研究方法: 研究采用了两种不同压缩率的网络架构：深度卷积神经网络（D-CNN）和向量量化变分自编码器（VQ-VAE）。实验数据来自具有复杂内部孔隙网络的砂岩样本，并通过量化解码图像质量与原始数据的对比进行评估。

研究结果: 结果表明，不同架构和压缩率对图像恢复质量有显著影响，且引入的边缘保护敏感指标有助于提升三维数据分析的准确性。

研究结论: 研究为科学家提供了根据特定分析需求选择数据存储和分析策略的依据，强调了不同压缩方法的适用性。

中文摘要: 随着成像技术的进步，成像科学中的数据量急剧增长，亟需高效可靠的存储解决方案。本研究探讨了使用深度学习自编码器压缩工业X射线计算机断层扫描（XCT）数据的方法，并分析了这些压缩算法对恢复数据质量的影响。实验采用了两种不同压缩率的网络架构：深度卷积神经网络（D-CNN）和向量量化变分自编码器（VQ-VAE）。数据来自具有复杂内部孔隙网络的砂岩样本。研究量化并比较了两种架构在不同压缩率下解码图像的质量，并引入了对边缘保护敏感的指标以提升三维数据分析的准确性。结果表明，根据后续分析需求，需选择不同的架构和压缩率。这些发现可为科学家在数据存储和分析需求上提供决策支持。

</details>


### [234] [Compressive Imaging Reconstruction via Tensor Decomposed Multi-Resolution Grid Encoding](https://arxiv.org/abs/2507.07707)
**中文标题：基于张量分解多分辨率网格编码的压缩成像重建**

*Zhenyu Jin,Yisi Luo,Xile Zhao,Deyu Meng*

主要分类: eess.IV

摘要简述: 本文提出了一种名为GridTD的无监督连续表示框架，用于压缩成像重建，通过结合多分辨率网格编码和输入张量分解，实现了高效且高精度的图像重建。


<details>
  <summary>详细信息</summary>
研究动机: 现有的无监督表示方法在压缩成像重建中难以平衡表示能力和效率，因此需要一种新的框架来解决这一问题。

研究方法: GridTD框架通过优化轻量级神经网络和输入张量分解模型，利用多分辨率哈希网格编码学习参数，结合了多分辨率网格编码的层次建模能力和张量分解的紧凑性。

研究结果: 理论分析和实验结果表明，GridTD在视频SCI、光谱SCI和压缩动态MRI重建等多种任务中均优于现有方法，成为最先进的压缩成像重建方法。

研究结论: GridTD作为一种多功能且高效的无监督连续表示框架，在压缩成像重建领域展现出显著优势。

中文摘要: 压缩成像（CI）重建，如快照压缩成像（SCI）和压缩感知磁共振成像（MRI），旨在从低维压缩测量中恢复高维图像。这一过程的关键在于学习高维图像的准确表示。然而，现有的无监督表示方法可能难以在表示能力和效率之间达到理想的平衡。为克服这一限制，我们提出了张量分解多分辨率网格编码（GridTD），一种用于CI重建的无监督连续表示框架。GridTD通过优化轻量级神经网络和输入张量分解模型，利用多分辨率哈希网格编码学习参数，兼具多分辨率网格编码的层次建模能力和张量分解的紧凑性，实现了高维图像的高效重建。通过理论分析算法的Lipschitz性质、泛化误差界和定点收敛性，揭示了GridTD相对于现有连续表示模型的内在优势。在视频SCI、光谱SCI和压缩动态MRI重建等多种CI任务中的广泛实验表明，GridTD始终优于现有方法，成为最先进的CI重建方法。

</details>


### [235] [Breast Ultrasound Tumor Generation via Mask Generator and Text-Guided Network:A Clinically Controllable Framework with Downstream Evaluation](https://arxiv.org/abs/2507.07721)
**中文标题：通过掩码生成器和文本引导网络生成乳腺超声肿瘤：一种具有下游评估的临床可控框架**

*Haoyu Pan,Hongxin Lin,Zetian Feng,Chuxuan Lin,Junyang Mo,Chu Zhang,Zijian Wu,Yi Wang,Qingqing Zheng*

主要分类: eess.IV

摘要简述: 本文提出了一种临床可控的生成框架，通过结合临床描述和结构掩码生成乳腺超声图像中的肿瘤，增强了下游乳腺癌诊断任务的效果。


<details>
  <summary>详细信息</summary>
研究动机: 由于专家标注的乳腺超声图像数据稀缺，开发鲁棒的深度学习模型受到限制。为了解决这一问题，作者提出了一种可控的生成框架，以合成具有临床实用性的乳腺超声图像。

研究方法: 框架结合临床描述和结构掩码生成肿瘤，设计了语义-曲率掩码生成器，利用临床先验生成结构多样的肿瘤掩码。在推理阶段，合成掩码作为输入生成高度个性化的乳腺超声图像。

研究结果: 在六个公共乳腺超声数据集上的定量评估表明，合成图像显著提升了乳腺癌诊断任务的性能。视觉图灵测试也证实了生成图像的真实性。

研究结论: 该框架能够生成具有临床实用性的乳腺超声图像，支持更广泛的临床应用。

中文摘要: 由于专家标注的乳腺超声（BUS）图像数据稀缺，开发鲁棒的深度学习模型受到显著限制。为解决这一问题，我们提出了一种临床可控的生成框架，用于合成BUS图像。该框架结合临床描述和结构掩码生成肿瘤，能够精细控制肿瘤的形态、回声性和形状等特征。此外，我们设计了一种语义-曲率掩码生成器，通过临床先验生成结构多样的肿瘤掩码。在推理阶段，合成肿瘤掩码作为输入生成高度个性化的BUS图像，反映真实世界的形态多样性。在六个公共BUS数据集上的定量评估表明，合成图像具有显著的临床实用性，能够有效提升下游乳腺癌诊断任务的效果。此外，经验丰富的超声医师进行的视觉图灵测试证实了生成图像的真实性，表明该框架具有支持更广泛临床应用的潜力。

</details>


### [236] [MeD-3D: A Multimodal Deep Learning Framework for Precise Recurrence Prediction in Clear Cell Renal Cell Carcinoma (ccRCC)](https://arxiv.org/abs/2507.07839)
**中文标题：MeD-3D：一种用于透明细胞肾细胞癌（ccRCC）精确复发预测的多模态深度学习框架**

*Hasaan Maqsood,Saif Ur Rehman Khan*

主要分类: eess.IV

摘要简述: 本文提出了一种名为MeD-3D的多模态深度学习框架，通过整合CT、MRI、组织病理学全切片图像、临床数据和基因组数据，提高了透明细胞肾细胞癌（ccRCC）复发的预测准确性。该框架采用早期和晚期融合策略，能够处理不完整数据，显著提升了预测性能。


<details>
  <summary>详细信息</summary>
研究动机: 透明细胞肾细胞癌（ccRCC）的复发预测面临分子、病理和临床异质性的挑战。传统单模态预测模型无法全面捕捉疾病复杂性，导致预测准确性不足。本研究旨在通过整合多模态数据，提升ccRCC复发预测的准确性，以支持临床决策。

研究方法: 研究提出了一种深度学习框架，整合了CT、MRI、组织病理学全切片图像（WSI）、临床数据和基因组数据。采用领域特定模型处理不同模态数据：CLAM（基于ResNet50）处理WSI，MeD-3D（基于预训练的3D-ResNet18）处理CT和MRI图像，多层感知机（MLP）处理临床和基因组数据。通过早期和晚期融合策略，结合多模态特征，并支持不完整数据的推断。

研究结果: 该框架显著提升了ccRCC复发的预测准确性，能够有效整合多模态数据，并在数据缺失的情况下保持预测性能。

研究结论: MeD-3D框架通过多模态数据整合和灵活的融合策略，为ccRCC复发预测提供了更准确的工具，有望改善临床决策。

中文摘要: 透明细胞肾细胞癌（ccRCC）的复发预测由于疾病的分子、病理和临床异质性而成为重大临床挑战。传统预后模型依赖单一数据模态（如影像学、组织病理学或基因组学），往往无法全面捕捉疾病复杂性，导致预测准确性不足。本研究旨在通过提出一种深度学习框架，整合CT、MRI、组织病理学全切片图像（WSI）、临床数据和基因组数据，以改进ccRCC复发预测并支持临床决策。该框架利用来自TCGA、TCIA和CPTAC等多个公开来源的综合数据集。为处理多样化的模态，采用了领域特定模型：CLAM（基于ResNet50）用于WSI，MeD-3D（基于预训练的3D-ResNet18）用于CT和MRI图像，多层感知机（MLP）用于结构化临床和基因组数据。这些模型从各模态中提取深度特征嵌入，并通过早期和晚期融合架构进行整合。这种融合策略使模型能够结合多源互补信息。此外，该框架能够处理临床中常见的不完整数据问题，支持在部分模态缺失的情况下进行推断。

</details>


### [237] [ArteryX: Advancing Brain Artery Feature Extraction with Vessel-Fused Networks and a Robust Validation Framework](https://arxiv.org/abs/2507.07920)
**中文标题：ArteryX：基于血管融合网络和稳健验证框架的脑血管特征提取技术**

*Abrar Faiyaz,Nhat Hoang,Giovanni Schifitto,Md Nasir Uddin*

主要分类: eess.IV

摘要简述: ArteryX是一种基于MATLAB的半自动工具，用于从3D TOF MRA图像中高效提取脑血管特征，解决了现有方法依赖用户、缺乏标准化验证的问题，并在小血管疾病患者中表现出更高的敏感性。


<details>
  <summary>详细信息</summary>
研究动机: 脑血管病变对认知衰退和神经系统疾病有重要影响，但现有评估工具多关注主要动脉异常，忽视细微血管变化的定量分析。现有方法存在用户依赖性高、学习曲线陡峭和缺乏标准化验证等问题，亟需改进。

研究方法: ArteryX采用基于血管融合网络的标志点追踪方法，结合半监督学习框架，高效处理3D TOF MRA图像，每例耗时约10-15分钟。其验证框架通过模拟真实血管结构和预定义真实特征，实现定量验证。

研究结果: 在脑小血管病患者中，ArteryX显示出对细微血管变化更高的敏感性，性能优于现有半自动方法。其验证框架为特征提取工具提供了标准化基准。

研究结论: ArteryX为脑血管病理的早期检测和标准化比较提供了高效工具，有望推动对血管健康与脑功能关系的深入研究。

中文摘要: 脑血管病变显著影响认知衰退和神经系统疾病，突显了评估血管完整性的先进工具的必要性。三维时间飞跃磁共振血管成像（3D TOF MRA）广泛用于脑血管可视化，但临床评估通常关注主要动脉异常，忽视了理解细微血管变化的关键定量指标。现有从MRA中提取结构、几何和形态动脉特征的方法（无论是手动还是自动）面临用户依赖性、学习曲线陡峭和缺乏标准化定量验证等挑战。我们提出了一种名为ArteryX的新型半自动动脉评估框架，这是一个基于MATLAB的工具箱，能够以高精度和高效量化血管特征，每例处理时间约10-15分钟（分辨率为0.5毫米），且用户干预极少。ArteryX采用基于血管融合网络的标志点追踪方法，可靠地管理追踪结果，有效解决了血管断裂或断开的问题。在脑小血管病患者中的验证表明，其对细微血管变化的敏感性更高，性能优于现有半自动方法。重要的是，ArteryX工具箱通过整合模拟真实血管的框架（利用血管融合图节点和预定义的真实特征）实现了定量特征验证。因此，ArteryX框架有望为特征提取工具箱提供基准，并无缝集成到临床工作流程中，促进脑血管病变的早期检测和患者队列间的标准化比较，从而推动对血管与脑健康关系的理解。

</details>


### [238] [Wrist bone segmentation in X-ray images using CT-based simulations](https://arxiv.org/abs/2507.07131)
**中文标题：基于CT模拟的X射线图像手腕骨分割**

*Youssef ElTantawy,Alexia Karantana,Xin Chen*

主要分类: eess.IV

摘要简述: 本文提出了一种基于CT模拟生成的X射线图像训练深度学习模型的方法，用于解决手腕骨分割中标注数据不足的问题，并在模拟和真实图像上取得了优异的分割效果。


<details>
  <summary>详细信息</summary>
研究动机: X射线图像分割是计算机辅助诊断系统的关键步骤，但高质量标注数据的获取成本高且耗时，尤其是手腕骨分割因多块小腕骨重叠而更具挑战性。本文旨在通过CT模拟生成大量标注数据，以解决这一问题。

研究方法: 利用CT体积数据生成大量模拟X射线图像及其对应的10块骨标签，用于训练深度学习模型进行手腕骨分割。模型在模拟和真实X射线图像上进行了评估。

研究结果: 模型在模拟数据集上的Dice分数为0.80至0.92，真实X射线图像的分割结果也表现出色。模型和模拟代码已公开供研究使用。

研究结论: 通过CT模拟生成标注数据的方法有效解决了手腕骨分割中数据不足的问题，模型表现优异，为相关研究提供了实用工具。

中文摘要: X射线是临床诊断（如骨折、肺炎、癌症筛查等）中最常见的影像模态之一。X射线图像分割是许多计算机辅助诊断系统的关键步骤，但仍具挑战性。基于深度学习的方法在医学图像分割任务中表现优异，但通常需要大量高质量标注数据进行模型训练。提供此类标注数据不仅耗时，还需高水平专业知识。手腕骨分割因多块小腕骨在图像中重叠而更具挑战性。为解决数据标注问题，本研究利用大量从CT体积生成的模拟X射线图像及其对应的10块骨标签，训练深度学习模型用于真实X射线图像的手腕骨分割。所提方法在模拟图像和真实图像上均进行了评估。模型在不同视角生成的模拟数据集上的Dice分数为0.80至0.92。对真实X射线图像分割结果的定性分析也表明训练模型的优异性能。训练模型和X射线模拟代码已公开供研究使用：链接将在接受后提供。

</details>


### [239] [Label-Efficient Chest X-ray Diagnosis via Partial CLIP Adaptation](https://arxiv.org/abs/2507.07254)
**中文标题：通过部分CLIP适配实现标签高效的胸部X光诊断**

*Heet Nitinkumar Dalsania*

主要分类: eess.IV

摘要简述: 本文提出一种标签高效的胸部X光诊断方法，通过部分微调预训练的CLIP模型，在少量标注数据下显著提升诊断性能。


<details>
  <summary>详细信息</summary>
研究动机: 医学影像标注数据难以获取，隐私、成本和病例稀缺性限制了深度学习应用。本文旨在模拟医院实际场景，利用少量标注数据实现高效诊断。

研究方法: 使用NIH Chest X-ray14数据集和预训练的CLIP ViT-B/32模型，部分微调视觉编码器，并通过零样本和小样本学习（每类1-16个标注样本）评估性能。

研究结果: 实验表明，CLIP的预训练视觉-语言特征可有效适应小样本医学影像任务，平均AUC分数较零样本基线提升超过20%。

研究结论: 本研究为常见和罕见疾病诊断提供了一种实用且可扩展的解决方案，适用于标注稀疏的医院场景。

中文摘要: 现代深度学习在医学影像中的应用通常依赖大量标注数据，但这些数据因隐私、高成本和病例稀缺性而难以获取。本文提出一种标签高效的胸部X光诊断策略，旨在模拟真实医院场景。实验使用NIH Chest X-ray14数据集和预训练的CLIP ViT-B/32模型，通过部分微调视觉编码器，并采用零样本和小样本学习（每类1-16个标注样本）进行评估。结果表明，CLIP的预训练视觉-语言特征可有效适应小样本医学影像任务，平均AUC分数较零样本基线提升超过20%。本工作的核心是模拟医院内部工作流程，即图像存档丰富但标注稀疏的场景，为常见和罕见疾病诊断提供实用且可扩展的解决方案。请注意，本研究仅供学术和实验用途，尚未经过同行评审。所有代码可在https://github.com/heet007-code/CLIP-disease-xray获取。

</details>


### [240] [Computationally Efficient Information-Driven Optical Design with Interchanging Optimization](https://arxiv.org/abs/2507.07789)
**中文标题：基于交替优化的计算高效信息驱动光学设计**

*Eric Markley,Henry Pinkard,Leyla Kabuli,Nalini Singh,Laura Waller*

主要分类: eess.IV

摘要简述: 本文提出了一种名为IDEAL-IO的新方法，通过交替优化密度估计和光学参数，解决了IDEAL方法在内存占用、运行时间和目标函数不匹配方面的问题，显著提升了计算效率和设计质量。


<details>
  <summary>详细信息</summary>
研究动机: 现有的IDEAL方法虽然能够通过信息内容评估成像系统，但存在内存占用高、运行时间长以及目标函数不匹配的问题。本文旨在解决这些问题，提出一种更高效且实用的优化策略。

研究方法: 本文提出IDEAL-IO方法，通过交替优化密度估计和光学参数，将密度估计与光学参数优化解耦。具体步骤包括：固定模型进行信息估计，更新光学参数，再拟合新模型。这种方法减少了内存和计算需求。

研究结果: 实验验证表明，IDEAL-IO在衍射光学、无透镜成像和快照3D显微镜等应用中，将运行时间和内存占用降低了6倍，同时优化出更优的设计。

研究结论: IDEAL-IO通过解耦优化步骤，显著提升了信息驱动光学设计的计算效率和实用性，为实际成像系统设计提供了可扩展的策略。

中文摘要: 近期研究表明，成像系统可以通过其测量的信息内容单独评估，从而实现无需计算解码的应用无关光学设计。信息驱动编码分析学习（IDEAL）通过基于梯度的方法自动化了这一过程。本文研究了IDEAL在多种成像系统中的表现，发现其存在内存占用高、运行时间长以及由于端到端可微性要求导致的目标函数不匹配问题。我们提出了基于交替优化的IDEAL（IDEAL-IO），通过交替进行密度估计和光学参数优化，将密度估计与光学参数优化解耦。这种方法将运行时间和内存占用降低了6倍，同时支持更具表达力的密度模型，从而优化出更优的设计。我们在衍射光学、无透镜成像和快照3D显微镜应用中验证了该方法，证明了信息论优化是一种实用且可扩展的实际成像系统设计策略。

</details>
